{
  "date": "2025-11-08",
  "category": "cs.AI",
  "summary": "æ¬¢è¿æ¥åˆ° UTC æ—¶é—´ 2025-11-08 çš„ arXiv ä¸­æ–‡ TLDR å¿«æŠ¥ï¼\n\n**ä»Šæ—¥æ€»ç»“ï¼š**\nä»Šå¤©çš„ arXiv è®ºæ–‡è´¨é‡æé«˜ï¼Œæ ¸å¿ƒè®¨è®ºé›†ä¸­åœ¨ **LLM çš„â€œè®¤çŸ¥ç—…ç†â€ä¸å¯¹é½å›°å¢ƒ**ï¼ˆæ¨¡å‹ä¸ºäº†â€œç¤¼è²Œâ€è€Œæ’’è°ï¼Œä»¥åŠè‡ªä¸»äº§ç”Ÿæ–°åè§ï¼‰ã€**Agent åœ¨çœŸå®ä»£ç åº“ä¸­çš„è¡¨ç°**ï¼ˆSWE-bench åçš„æ–°åŸºå‡†ï¼‰ã€ä»¥åŠ **RAG ä¸é•¿ä¸Šä¸‹æ–‡ï¼ˆLong Contextï¼‰çš„åšå¼ˆ**ã€‚æ­¤å¤–ï¼Œå…³äºæ¨ç†æ¨¡å‹ï¼ˆThinking Modelsï¼‰çš„å†…éƒ¨æœºåˆ¶åˆ†æå’Œå¤šæ¨¡æ€ VLA æ¨¡å‹çš„æœªæ¥è·¯çº¿å›¾ä¹Ÿå€¼å¾—å…³æ³¨ã€‚\n\n---\n\n### ğŸš€ æ·±åº¦èšç„¦ï¼šå¯¹é½ã€åè§ä¸è®¤çŸ¥ (Alignment, Bias & Cognition)\n\n**1. The Polite Liar: Epistemic Pathology in Language Models**\n**# æ ‡é¢˜ï¼šç¤¼è²Œçš„éª—å­ï¼šè¯­è¨€æ¨¡å‹ä¸­çš„è®¤çŸ¥ç—…ç†**\nè¿™æ˜¯ä¸€ç¯‡éå¸¸æœ‰æ·±åº¦çš„ç†è®ºæ–‡ç« ã€‚ä½œè€…æŒ‡å‡º LLM å­˜åœ¨ä¸€ç§â€œè®¤çŸ¥ç—…ç†â€ï¼šå³ä½¿ä¸çŸ¥é“ç­”æ¡ˆï¼Œä¹Ÿä¼šè‡ªä¿¡åœ°èƒ¡è¯´å…«é“ã€‚æ–‡ç« è®¤ä¸ºè¿™ä¸ä»…æ˜¯å¹»è§‰ï¼Œè€Œæ˜¯ **RLHFï¼ˆåŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ ï¼‰çš„ç»“æ„æ€§åæœ**ã€‚\n*   **æ ¸å¿ƒè§‚ç‚¹**ï¼šRLHF å¥–åŠ±çš„æ˜¯â€œè¢«æ„ŸçŸ¥çš„çœŸè¯šï¼ˆperceived sincerityï¼‰â€è€Œéâ€œè¯æ®æ€§çš„å‡†ç¡®æ€§â€ã€‚æ¨¡å‹å­¦ä¼šäº†å–æ‚¦ç”¨æˆ·ï¼ˆHelpful, Harmless, Politeï¼‰ï¼Œè€Œä¸æ˜¯è¿½æ±‚è®¤çŸ¥ä¸Šçš„æ­£ç›´ï¼ˆEpistemic Integrityï¼‰ã€‚\n*   **ç»“è®º**ï¼šç›®å‰çš„å¯¹é½æ–¹æ³•åˆ¶é€ äº†â€œç¤¼è²Œçš„éª—å­â€ï¼Œæˆ‘ä»¬éœ€è¦è½¬å‘å¥–åŠ±â€œæœ‰æ­£å½“ç†ç”±çš„è‡ªä¿¡ï¼ˆjustified confidenceï¼‰â€ã€‚\n\n**2. Large Language Models Develop Novel Social Biases Through Adaptive Exploration**\n**# æ ‡é¢˜ï¼šå¤§å‹è¯­è¨€æ¨¡å‹é€šè¿‡è‡ªé€‚åº”æ¢ç´¢äº§ç”Ÿæ–°çš„ç¤¾ä¼šåè§**\n*   **å‘ç°**ï¼šé€šå¸¸è®¤ä¸º LLM çš„åè§æ¥è‡ªè®­ç»ƒæ•°æ®ï¼Œä½†è¿™ç¯‡æ–‡ç« å‘ç°ï¼Œå³ä½¿åœ¨æ²¡æœ‰ä»»ä½•å›ºæœ‰å·®å¼‚çš„äººå·¥ç¾¤ä½“è®¾å®šä¸­ï¼ŒLLM ä¹Ÿä¼šé€šè¿‡â€œæ¢ç´¢-åˆ©ç”¨ï¼ˆexploration-exploitationï¼‰â€çš„æƒè¡¡æœºåˆ¶**è‡ªå‘åœ°äº§ç”Ÿæ–°çš„ç¤¾ä¼šåè§**ã€‚\n*   **æœºåˆ¶**ï¼šæ¨¡å‹æ¢ç´¢å¾—å¤ªå°‘ï¼Œå¯¼è‡´æ—©æœŸè§‚å¯Ÿè¿‡åº¦å½±å“äº†å¯¹æ•´ä¸ªç¾¤ä½“çš„å°è±¡ã€‚è¿™è¡¨æ˜ä»…ä»…æ¸…æ´—æ•°æ®æ˜¯ä¸å¤Ÿçš„ï¼Œè¿˜éœ€è¦å¹²é¢„æ¨¡å‹çš„æ¢ç´¢ç­–ç•¥ã€‚\n\n**3. An Empirical Study of Reasoning Steps in Thinking Code LLMs**\n**# æ ‡é¢˜ï¼šä¼šæ€è€ƒçš„ä»£ç  LLM æ¨ç†æ­¥éª¤å®è¯ç ”ç©¶**\n*   **å¯¹è±¡**ï¼šè¯„ä¼°äº† DeepSeek-R1, OpenAI-o3-mini, Claude-3.7-Sonnet-Thinking ç­‰â€œæ€è€ƒå‹â€æ¨¡å‹ã€‚\n*   **å‘ç°**ï¼šåˆ†æäº† 100 ä¸ªä»£ç ç”Ÿæˆä»»åŠ¡ã€‚å¢åŠ æ¨ç†æ­¥éª¤ï¼ˆThinking stepsï¼‰èƒ½æé«˜æŸäº›ä»»åŠ¡çš„è§£å†³ç‡ï¼Œä½†å›°éš¾ä»»åŠ¡çš„ä¸»è¦å¤±æ•ˆæ¨¡å¼æ˜¯â€œå®Œæ•´æ€§ç¼ºå¤±â€ã€‚ç ”ç©¶è¿˜å‘ç°è¿™äº›æ¨¡å‹åœ¨ä¸åŒè®¡ç®—é‡ä¸‹èƒ½ä¿æŒé€»è¾‘ç»“æ„çš„ä¸€è‡´æ€§ã€‚\n\n**4. Evaluating Implicit Biases in LLM Reasoning through Logic Grid Puzzles**\n**# æ ‡é¢˜ï¼šé€šè¿‡é€»è¾‘ç½‘æ ¼è°œé¢˜è¯„ä¼° LLM æ¨ç†ä¸­çš„éšæ€§åè§**\n*   **æ–¹æ³•**ï¼šæå‡ºäº† PRIME æ¡†æ¶ï¼Œç”¨é€»è¾‘è°œé¢˜æ¥æµ‹è¯•éšæ€§åè§ã€‚\n*   **å‘ç°**ï¼šå½“è°œé¢˜çš„è§£å†³æ–¹æ¡ˆç¬¦åˆåˆ»æ¿å°è±¡ï¼ˆä¾‹å¦‚æ€§åˆ«åˆ»æ¿å°è±¡ï¼‰æ—¶ï¼Œæ¨¡å‹çš„æ¨ç†å‡†ç¡®ç‡æ˜¾è‘—æ›´é«˜ã€‚è¿™æ­ç¤ºäº†åè§å¦‚ä½•æ·±æ¤äºé€»è¾‘æ¨ç†èƒ½åŠ›ä¸­ã€‚\n\n---\n\n### ğŸ¤– æ™ºèƒ½ä½“ä¸ä»£ç å·¥ç¨‹ (Agents & Software Engineering)\n\n**5. SWE-fficiency: Can Language Models Optimize Real-World Repositories on Real Workloads?**\n**# æ ‡é¢˜ï¼šSWE-fficiencyï¼šè¯­è¨€æ¨¡å‹èƒ½å¦åœ¨çœŸå®è´Ÿè½½ä¸Šä¼˜åŒ–çœŸå®ä»£ç åº“ï¼Ÿ**\n*   **èƒŒæ™¯**ï¼šç°æœ‰çš„ä»£ç  Benchmark å…³æ³¨â€œä¿®å¤ï¼ˆFixï¼‰â€ï¼Œæœ¬æ–‡å…³æ³¨â€œä¼˜åŒ–ï¼ˆOptimizeï¼‰â€ã€‚\n*   **è´¡çŒ®**ï¼šæå‡ºäº† SWE-fficiency åŸºå‡†ï¼ˆåŒ…å« numpy, pandas ç­‰åº“çš„ 498 ä¸ªä»»åŠ¡ï¼‰ã€‚\n*   **ç»“æœ**ï¼š**å½“ä¸‹çš„ Agent è¡¨ç°å¾ˆå·®**ã€‚å¹³å‡åŠ é€Ÿæ¯”ä¸åˆ°äººç±»ä¸“å®¶çš„ 0.15 å€ã€‚Agent å¾ˆéš¾å®šä½æ€§èƒ½ç“¶é¢ˆï¼Œä¸”å®¹æ˜“ç ´åä»£ç æ­£ç¡®æ€§ã€‚è¿™æ˜¯ä¸€ä¸ªéå¸¸ç¡¬æ ¸çš„ Reality Checkã€‚\n\n**6. Maestro: Learning to Collaborate via Conditional Listwise Policy Optimization for Multi-Agent LLMs**\n**# æ ‡é¢˜ï¼šMaestroï¼šé€šè¿‡æ¡ä»¶åˆ—è¡¨çº§ç­–ç•¥ä¼˜åŒ–å­¦ä¹ å¤šæ™ºèƒ½ä½“åä½œ**\n*   **æ–¹æ³•**ï¼šæå‡ºäº† Maestro æ¡†æ¶ï¼Œå°†å¤šæ™ºèƒ½ä½“åˆ†ä¸ºâ€œæ¢ç´¢ï¼ˆExplorationï¼‰â€å’Œâ€œç»¼åˆï¼ˆSynthesisï¼‰â€ä¸¤ä¸ªè§’è‰²ã€‚\n*   **åˆ›æ–°**ï¼šå¼•å…¥äº† CLPOï¼ˆæ¡ä»¶åˆ—è¡¨çº§ç­–ç•¥ä¼˜åŒ–ï¼‰æ¥è§£å†³å¤šæ™ºèƒ½ä½“ä¸­çš„ä¿¡ç”¨åˆ†é…ï¼ˆcredit assignmentï¼‰é—®é¢˜ï¼Œåœ¨æ•°å­¦æ¨ç†å’Œé€šç”¨è§£é¢˜ä¸Šæå‡æ˜¾è‘—ã€‚\n\n**7. Self-Abstraction from Grounded Experience for Plan-Guided Policy Refinement**\n**# æ ‡é¢˜ï¼šåŸºäºå…·èº«ç»éªŒçš„è‡ªæˆ‘æŠ½è±¡ç”¨äºè§„åˆ’å¼•å¯¼çš„ç­–ç•¥ä¼˜åŒ–**\n*   **æ–¹æ³•**ï¼šSAGE æ¡†æ¶å…è®¸ Agent ä»è¿‡å»çš„æ‰§è¡Œç»éªŒä¸­â€œè‡ªæˆ‘æŠ½è±¡â€å‡ºç®€æ´çš„è®¡åˆ’ï¼Œç”¨äºæŒ‡å¯¼æœªæ¥çš„è¡ŒåŠ¨ã€‚\n*   **æ•ˆæœ**ï¼šåœ¨ SWE-Bench Verified ä¸Šï¼Œç»“åˆ GPT-5 (high) è¾¾åˆ°äº† 73.2% çš„ Pass@1ã€‚\n\n---\n\n### ğŸ“š RAGã€é•¿ä¸Šä¸‹æ–‡ä¸çŸ¥è¯† (RAG, Long Context & Knowledge)\n\n**8. Evaluation of retrieval-based QA on QUEST-LOFT**\n**# æ ‡é¢˜ï¼šQUEST-LOFT ä¸Šçš„æ£€ç´¢å¼é—®ç­”è¯„ä¼°**\n*   **è§‚ç‚¹**ï¼šGoogle DeepMind å›¢é˜Ÿçš„ç ”ç©¶ã€‚è™½ç„¶é•¿ä¸Šä¸‹æ–‡æ¨¡å‹ï¼ˆLong-context LLMsï¼‰å¾ˆç«ï¼Œä½† RAG åœ¨å¤„ç†éœ€è¦å¤æ‚æ¨ç†å’Œåˆ†æ•£ä¿¡æ¯çš„ä»»åŠ¡æ—¶ä»æœ‰ä¼˜åŠ¿ã€‚\n*   **ç»“è®º**ï¼šä¼˜åŒ–åçš„ RAGï¼ˆç»“åˆç»“æ„åŒ–è¾“å‡ºå’Œæ¨ç†ï¼‰å¯ä»¥æ˜¾è‘—å‡»è´¥å•çº¯çš„é•¿ä¸Šä¸‹æ–‡æ–¹æ³•ã€‚\n\n**9. Retrieval Quality at Context Limit**\n**# æ ‡é¢˜ï¼šä¸Šä¸‹æ–‡æé™ä¸‹çš„æ£€ç´¢è´¨é‡**\n*   **å‘ç°**ï¼šæµ‹è¯•äº† **Gemini 2.5 Flash**ã€‚å‘ç°å®ƒåœ¨ç®€å•çš„â€œå¤§æµ·æé’ˆâ€é—®é¢˜ä¸Šï¼Œå³ä½¿æ–‡æ¡£å¤„äºä¸Šä¸‹æ–‡æé™ä½ç½®ï¼Œä¹Ÿä¸å­˜åœ¨â€œè¿·å¤±åœ¨ä¸­é—´ï¼ˆLost in the Middleï¼‰â€çš„ç°è±¡ã€‚è¿™è¡¨æ˜æ–°ä¸€ä»£æ¨¡å‹çš„é•¿çª—å£æ£€ç´¢èƒ½åŠ›å·²å¤§å¹…æå‡ã€‚\n\n**10. Cross-Document Topic-Aligned Chunking for Retrieval-Augmented Generation**\n**# æ ‡é¢˜ï¼šç”¨äº RAG çš„è·¨æ–‡æ¡£ä¸»é¢˜å¯¹é½åˆ†å—**\n*   **ç—›ç‚¹**ï¼šä¼ ç»Ÿ RAG åˆ†å—æ˜¯åŸºäºå•æ–‡æ¡£çš„ï¼Œå¯¼è‡´çŸ¥è¯†ç¢ç‰‡åŒ–ã€‚\n*   **æ–¹æ³•**ï¼šCDTA æ–¹æ³•åœ¨è¯­æ–™åº“çº§åˆ«é‡æ„çŸ¥è¯†ï¼Œå°†è·¨æ–‡æ¡£çš„ç›¸å…³ç‰‡æ®µèšåˆæˆç»Ÿä¸€çš„ Chunkã€‚åœ¨å¤šè·³æ¨ç†ä»»åŠ¡ï¼ˆHotpotQAï¼‰ä¸Šè¡¨ç°ä¼˜äºè¯­ä¹‰åˆ†å—ã€‚\n\n**11. Can Fine-Tuning Erase Your Edits? On the Fragile Coexistence of Knowledge Editing and Adaptation**\n**# æ ‡é¢˜ï¼šå¾®è°ƒä¼šæŠ¹å»ä½ çš„ç¼–è¾‘å—ï¼Ÿå…³äºçŸ¥è¯†ç¼–è¾‘ä¸é€‚åº”æ€§å…±å­˜çš„è„†å¼±æ€§**\n*   **å‘ç°**ï¼šè¿™æ˜¯ä¸€ä¸ªå¾ˆå®é™…çš„é—®é¢˜ã€‚å¦‚æœä½ å…ˆç”¨çŸ¥è¯†ç¼–è¾‘ï¼ˆKnowledge Editingï¼‰ç®—æ³•ä¿®æ”¹äº†æ¨¡å‹äº‹å®ï¼Œç„¶åå†è¿›è¡Œå¾®è°ƒï¼ˆFine-tuningï¼‰ï¼Œ**ç¼–è¾‘ä¼šå¤±æ•ˆ**ã€‚\n*   **ç»“è®º**ï¼šå¾®è°ƒéç¼–è¾‘å±‚åè€Œç ´åæ€§æ›´å¤§ã€‚è¿™å¯¹äºç»´æŠ¤ LLM çŸ¥è¯†åº“æå‡ºäº†æŒ‘æˆ˜ã€‚\n\n---\n\n### ğŸ”¬ ç§‘å­¦ã€æ•°å­¦ä¸å¤šæ¨¡æ€ (Science, Math & Multimodal)\n\n**12. LLM Attention Transplant for Transfer Learning of Tabular Data Across Disparate Domains**\n**# æ ‡é¢˜ï¼šç”¨äºè·¨åŸŸè¡¨æ ¼æ•°æ®è¿ç§»å­¦ä¹ çš„ LLM æ³¨æ„åŠ›ç§»æ¤**\n*   **è„‘æ´**ï¼šè¡¨æ ¼æ•°æ®ï¼ˆTabular Dataï¼‰å¾ˆéš¾åšè¿ç§»å­¦ä¹ ã€‚ä½œè€…æå‡ºå°† LLM çš„æ³¨æ„åŠ›æƒé‡â€œç§»æ¤â€åˆ°ä¸“é—¨å¤„ç†è¡¨æ ¼çš„ Transformer ä¸­ï¼Œæ•ˆæœä¼˜äºä¼ ç»Ÿ ML å’Œæ·±åº¦è¡¨æ ¼æ¨¡å‹ã€‚\n\n**13. 10 Open Challenges Steering the Future of Vision-Language-Action Models**\n**# æ ‡é¢˜ï¼šå¼•é¢†è§†è§‰-è¯­è¨€-åŠ¨ä½œ (VLA) æ¨¡å‹æœªæ¥çš„ 10 å¤§æŒ‘æˆ˜**\n*   **ç»¼è¿°**ï¼šAAAI 2026 çš„æ–‡ç« ã€‚åˆ—å‡ºäº† VLA å‘å±•çš„é‡Œç¨‹ç¢‘ï¼šå¤šæ¨¡æ€ã€æ¨ç†ã€æ•°æ®ã€è¯„ä¼°ã€è·¨æœºå™¨äººæ³›åŒ–ã€æ•ˆç‡ã€å…¨èº«åè°ƒã€å®‰å…¨ã€Agent ä»¥åŠäººæœºåä½œã€‚\n\n**14. Physics-Informed Neural Networks for Real-Time Gas Crossover Prediction in PEM Electrolyzers**\n**# æ ‡é¢˜ï¼šç”¨äº PEM ç”µè§£æ§½å®æ—¶æ°”ä½“äº¤å‰é¢„æµ‹çš„ç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œ**\n*   **åº”ç”¨**ï¼šAI for Science çš„å…¸å‹åº”ç”¨ã€‚ç”¨ PINNsï¼ˆç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œï¼‰é¢„æµ‹ç»¿æ°¢ç”Ÿäº§ä¸­çš„å®‰å…¨éšæ‚£ï¼Œæ¨ç†é€Ÿåº¦æå¿«ï¼Œé€‚åˆå®æ—¶æ§åˆ¶ã€‚\n\n---\n\n### ğŸ›¡ï¸ å®‰å…¨ä¸é˜²å¾¡ (Security & Defense)\n\n**15. Stemming Hallucination in Language Models Using a Licensing Oracle**\n**# æ ‡é¢˜ï¼šä½¿ç”¨è®¸å¯é¢„è¨€æœºéåˆ¶è¯­è¨€æ¨¡å‹å¹»è§‰**\n*   **æ–¹æ³•**ï¼šå¼•å…¥â€œLicensing Oracleâ€ï¼Œåœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­å¼ºåˆ¶è¿›è¡ŒåŸºäºçŸ¥è¯†å›¾è°±çš„ç¡®å®šæ€§éªŒè¯ã€‚\n*   **æ•ˆæœ**ï¼šå®ç°äº†å®Œç¾çš„æ‹’ç»ç²¾åº¦ï¼ˆå³ä¸çŸ¥é“å°±é—­å˜´ï¼‰ï¼Œåœ¨äº‹å®æ€§é¢†åŸŸæ¶ˆé™¤äº†å¹»è§‰ã€‚\n\n**16. When AI Meets the Web: Prompt Injection Risks in Third-Party AI Chatbot Plugins**\n**# æ ‡é¢˜ï¼šå½“ AI é‡è§ Webï¼šç¬¬ä¸‰æ–¹ AI èŠå¤©æœºå™¨äººæ’ä»¶ä¸­çš„æç¤ºæ³¨å…¥é£é™©**\n*   **ç°çŠ¶**ï¼šåˆ†æäº† 10,000 ä¸ªç½‘ç«™ä½¿ç”¨çš„ 17 ä¸ªç¬¬ä¸‰æ–¹èŠå¤©æ’ä»¶ã€‚\n*   **é£é™©**ï¼šå¤§é‡æ’ä»¶æ²¡æœ‰éªŒè¯å¯¹è¯å†å²çš„å®Œæ•´æ€§ï¼Œæ”»å‡»è€…å¯ä»¥ä¼ªé€ å†å²è¿›è¡Œæç¤ºæ³¨å…¥ï¼ˆPrompt Injectionï¼‰ï¼Œç”šè‡³é€šè¿‡ç½‘é¡µå†…å®¹è¿›è¡Œé—´æ¥æ³¨å…¥ã€‚\n\n---\n\n**å¿«é€Ÿæ è¿‡ (Quick Skim):**\n*   **#29 Revisiting Entropy in RLVR**: åˆ†æäº†æ¨ç†æ¨¡å‹åœ¨ RL è®­ç»ƒä¸­ç†µåç¼©çš„åŸå› ï¼Œæå‡º Positive-Advantage Reweighting æ¥è§£å†³ã€‚\n*   **#42 A PDE Perspective on Generative Diffusion Models**: ç”¨åå¾®åˆ†æ–¹ç¨‹ç†è®ºä¸¥æ ¼åˆ†ææ‰©æ•£æ¨¡å‹ï¼Œè¯æ˜äº†å…¶ç¨³å®šæ€§ã€‚\n*   **#12 Secure Autonomous Agent Payments**: æå‡ºäº†åŸºäºåŒºå—é“¾çš„ AI Agent æ”¯ä»˜éªŒè¯æ¡†æ¶ï¼Œé˜²æ­¢ Agent ä¹±èŠ±é’±ã€‚\n*   **#62 Adaptation and Fine-tuning with TabPFN for TSP**: ç”¨ TabPFN è§£å†³æ—…è¡Œå•†é—®é¢˜ï¼ˆTSPï¼‰ï¼Œå±•ç¤ºäº†é€šç”¨è¡¨æ ¼æ¨¡å‹çš„æ½œåŠ›ã€‚\n\nå¸Œæœ›è¿™ä»½å¿«æŠ¥å¯¹ä½ çš„ç ”ç©¶æœ‰æ‰€å¸®åŠ©ï¼æˆ‘ä»¬æ˜å¤©è§ã€‚",
  "papers": [
    {
      "arxiv_id": "2511.06161v1",
      "title": "LLM Attention Transplant for Transfer Learning of Tabular Data Across Disparate Domains",
      "title_zh": "ç”¨äºè·¨å¼‚è´¨é¢†åŸŸè¡¨æ ¼æ•°æ®è¿ç§»å­¦ä¹ çš„ LLM æ³¨æ„åŠ›ç§»æ¤",
      "authors": [
        "Ibna Kowsar",
        "Kazi F. Akhter",
        "Manar D. Samad"
      ],
      "abstract": "Transfer learning of tabular data is non-trivial due to heterogeneity in the feature space across disparate domains. The limited success of traditional deep learning in tabular knowledge transfer can be advanced by leveraging large language models (LLMs). However, the efficacy of LLMs often stagnates for mixed data types structured in tables due to the limitations of text prompts and in-context learning. We propose a lightweight transfer learning framework that fine-tunes an LLM using source tabular data and transplants the LLM's selective $key$ and $value$ projection weights into a gated feature tokenized transformer (gFTT) built for tabular data. The gFTT model with cross-domain attention is fine-tuned using target tabular data for transfer learning, eliminating the need for shared features, LLM prompt engineering, and large-scale pretrained models. Our experiments using ten pairs of source-target data sets and 12 baselines demonstrate the superiority of the proposed LLM-attention transplant for transfer learning (LATTLE) method over traditional ML models, state-of-the-art deep tabular architectures, and transfer learning models trained on thousands to billions of tabular samples. The proposed attention transfer demonstrates an effective solution to learning relationships between data tables using an LLM in a low-resource learning environment. The source code for the proposed method is publicly available.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¸åŒé¢†åŸŸé—´è¡¨æ ¼æ•°æ®ç‰¹å¾ç©ºé—´å¼‚æ„å¯¼è‡´çš„è¿ç§»å­¦ä¹ éš¾é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºLATTLEçš„è½»é‡çº§è¿ç§»å­¦ä¹ æ¡†æ¶ã€‚è¯¥æ–¹æ³•é¦–å…ˆåˆ©ç”¨æºè¡¨æ ¼æ•°æ®å¾®è°ƒå¤§å‹è¯­è¨€æ¨¡å‹(LLM)ï¼Œéšåå°†LLMçš„é€‰æ‹©æ€§$key$å’Œ$value$æŠ•å½±æƒé‡ç§»æ¤åˆ°ä¸“ä¸ºè¡¨æ ¼æ•°æ®æ„å»ºçš„é—¨æ§ç‰¹å¾æ ‡è®°åŒ–Transformer (gFTT)ä¸­ã€‚å¸¦æœ‰è·¨åŸŸæ³¨æ„åŠ›çš„gFTTæ¨¡å‹æ¥ç€ä½¿ç”¨ç›®æ ‡è¡¨æ ¼æ•°æ®è¿›è¡Œå¾®è°ƒï¼Œä»è€Œæ¶ˆé™¤äº†å¯¹å…±äº«ç‰¹å¾ã€LLMæç¤ºå·¥ç¨‹(Prompt Engineering)åŠå¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹çš„ä¾èµ–ã€‚åœ¨10å¯¹æº-ç›®æ ‡æ•°æ®é›†å’Œ12ä¸ªåŸºçº¿æ¨¡å‹ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒLATTLEæ–¹æ³•ä¼˜äºä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹ã€æœ€å…ˆè¿›çš„æ·±åº¦è¡¨æ ¼æ¶æ„ä»¥åŠåœ¨æµ·é‡æ ·æœ¬ä¸Šè®­ç»ƒçš„è¿ç§»å­¦ä¹ æ¨¡å‹ã€‚è¯¥ç ”ç©¶å±•ç¤ºäº†åœ¨ä½èµ„æºç¯å¢ƒä¸‹åˆ©ç”¨LLMæ³¨æ„åŠ›æœºåˆ¶æœ‰æ•ˆå­¦ä¹ æ•°æ®è¡¨ä¹‹é—´å…³ç³»çš„æ½œåŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06161v1",
      "published_date": "2025-11-08 23:05:31 UTC",
      "updated_date": "2025-11-08 23:05:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T15:08:25.237653+00:00"
    },
    {
      "arxiv_id": "2511.06160v1",
      "title": "Evaluating Implicit Biases in LLM Reasoning through Logic Grid Puzzles",
      "title_zh": "åŸºäºé€»è¾‘ç½‘æ ¼è°œé¢˜è¯„ä¼°LLMæ¨ç†ä¸­çš„éšæ€§åè§",
      "authors": [
        "Fatima Jahara",
        "Mark Dredze",
        "Sharon Levy"
      ],
      "abstract": "While recent safety guardrails effectively suppress overtly biased outputs, subtler forms of social bias emerge during complex logical reasoning tasks that evade current evaluation benchmarks. To fill this gap, we introduce a new evaluation framework, PRIME (Puzzle Reasoning for Implicit Biases in Model Evaluation), that uses logic grid puzzles to systematically probe the influence of social stereotypes on logical reasoning and decision making in LLMs. Our use of logic puzzles enables automatic generation and verification, as well as variability in complexity and biased settings. PRIME includes stereotypical, anti-stereotypical, and neutral puzzle variants generated from a shared puzzle structure, allowing for controlled and fine-grained comparisons. We evaluate multiple model families across puzzle sizes and test the effectiveness of prompt-based mitigation strategies. Focusing our experiments on gender stereotypes, our findings highlight that models consistently reason more accurately when solutions align with stereotypical associations. This demonstrates the significance of PRIME for diagnosing and quantifying social biases perpetuated in the deductive reasoning of LLMs, where fairness is critical.",
      "tldr_zh": "è¯¥ç ”ç©¶æŒ‡å‡ºå°½ç®¡ç°æœ‰çš„å®‰å…¨æŠ¤æ èƒ½æœ‰æ•ˆæŠ‘åˆ¶æ˜æ˜¾çš„åè§è¾“å‡ºï¼Œä½†åœ¨å¤æ‚çš„é€»è¾‘æ¨ç†ä»»åŠ¡ä¸­ä»ä¼šå‡ºç°éš¾ä»¥è¢«ç°æœ‰åŸºå‡†æ£€æµ‹åˆ°çš„éšæ€§ç¤¾ä¼šåè§ã€‚ä¸ºäº†å¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œä½œè€…å¼•å…¥äº†PRIMEï¼ˆPuzzle Reasoning for Implicit Biases in Model Evaluationï¼‰è¯„ä¼°æ¡†æ¶ï¼Œåˆ©ç”¨é€»è¾‘ç½‘æ ¼è°œé¢˜ï¼ˆlogic grid puzzlesï¼‰ç³»ç»Ÿåœ°æ¢ç©¶ç¤¾ä¼šåˆ»æ¿å°è±¡å¯¹LLMsé€»è¾‘æ¨ç†å’Œå†³ç­–çš„å½±å“ã€‚PRIMEåˆ©ç”¨å…±äº«ç»“æ„ç”ŸæˆåŒ…å«åˆ»æ¿å°è±¡ã€ååˆ»æ¿å°è±¡å’Œä¸­æ€§å˜ä½“çš„è°œé¢˜ï¼Œå®ç°äº†å¯¹ä¸åŒæ¨¡å‹å®¶æ—å’Œè°œé¢˜è§„æ¨¡çš„å—æ§ç»†ç²’åº¦æ¯”è¾ƒã€‚é’ˆå¯¹æ€§åˆ«åˆ»æ¿å°è±¡çš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œå½“è°œé¢˜çš„è§£å†³æ–¹æ¡ˆä¸åˆ»æ¿å°è±¡ä¸€è‡´æ—¶ï¼Œæ¨¡å‹çš„æ¨ç†å‡†ç¡®ç‡å§‹ç»ˆæ›´é«˜ã€‚è¿™ä¸€å‘ç°è¯æ˜äº†PRIMEåœ¨è¯Šæ–­å’Œé‡åŒ–LLMsæ¼”ç»æ¨ç†ä¸­æŒç»­å­˜åœ¨çš„ç¤¾ä¼šåè§æ–¹é¢å…·æœ‰é‡è¦ä»·å€¼ï¼Œå¯¹äºæå‡æ¨¡å‹çš„å…¬å¹³æ€§è‡³å…³é‡è¦ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "24 pages (including appendix)",
      "pdf_url": "https://arxiv.org/pdf/2511.06160v1",
      "published_date": "2025-11-08 22:51:59 UTC",
      "updated_date": "2025-11-08 22:51:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T15:08:51.919312+00:00"
    },
    {
      "arxiv_id": "2511.06157v2",
      "title": "Models Got Talent: Identifying High Performing Wearable Human Activity Recognition Models Without Training",
      "title_zh": "Models Got Talentï¼šæ— éœ€è®­ç»ƒç”„åˆ«é«˜æ€§èƒ½å¯ç©¿æˆ´äººç±»æ´»åŠ¨è¯†åˆ«æ¨¡å‹",
      "authors": [
        "Richard Goldman",
        "Varun Komperla",
        "Thomas Ploetz",
        "Harish Haresamudram"
      ],
      "abstract": "A promising alternative to the computationally expensive Neural Architecture Search (NAS) involves the development of Zero Cost Proxies (ZCPs), which correlate well with trained performance, but can be computed through a single forward/backward pass on a randomly sampled batch of data. In this paper, we investigate the effectiveness of ZCPs for HAR on six benchmark datasets, and demonstrate that they discover network architectures that obtain within 5% of performance attained by full-scale training involving 1500 randomly sampled architectures. This results in substantial computational savings as high-performing architectures can be discovered with minimal training. Our experiments not only introduce ZCPs to sensor-based HAR, but also demonstrate that they are robust to data noise, further showcasing their suitability for practical scenarios.",
      "tldr_zh": "æœ¬æ–‡é’ˆå¯¹å¯ç©¿æˆ´è®¾å¤‡çš„äººç±»æ´»åŠ¨è¯†åˆ«(HAR)ä»»åŠ¡ï¼Œæ¢è®¨äº†é›¶æˆæœ¬ä»£ç†(Zero Cost Proxies, ZCPs)ä½œä¸ºè®¡ç®—æ˜‚è´µçš„ç¥ç»æ¶æ„æœç´¢(NAS)çš„é«˜æ•ˆæ›¿ä»£æ–¹æ¡ˆã€‚ZCPsä»…éœ€å¯¹éšæœºé‡‡æ ·çš„æ•°æ®æ‰¹æ¬¡è¿›è¡Œä¸€æ¬¡å‰å‘/åå‘ä¼ æ’­å³å¯è®¡ç®—ï¼Œæ— éœ€è¿›è¡Œå®Œæ•´çš„æ¨¡å‹è®­ç»ƒã€‚ç ”ç©¶åœ¨å…­ä¸ªåŸºå‡†æ•°æ®é›†ä¸ŠéªŒè¯äº†ZCPsçš„æœ‰æ•ˆæ€§ï¼Œå¹¶ä¸æ¶‰åŠ1500ä¸ªéšæœºé‡‡æ ·æ¶æ„çš„å…¨é¢è®­ç»ƒç»“æœè¿›è¡Œäº†å¯¹æ¯”ã€‚å®éªŒè¡¨æ˜ï¼ŒZCPsèƒ½å¤Ÿå‘ç°é«˜æ€§èƒ½çš„ç½‘ç»œæ¶æ„ï¼Œå…¶æ€§èƒ½ä¸ç»è¿‡å…¨é¢è®­ç»ƒçš„æ¨¡å‹ç›¸æ¯”å·®è·åœ¨5%ä»¥å†…ï¼Œä»è€Œåœ¨æå°‘çš„è®­ç»ƒæˆæœ¬ä¸‹æ˜¾è‘—èŠ‚çœè®¡ç®—èµ„æºã€‚æ­¤å¤–ï¼Œå®éªŒè¿˜è¯æ˜ZCPså¯¹æ•°æ®å™ªå£°å…·æœ‰é²æ£’æ€§ï¼Œè¿›ä¸€æ­¥å±•ç¤ºäº†å…¶åœ¨å®é™…åº”ç”¨åœºæ™¯ä¸­çš„é€‚ç”¨æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06157v2",
      "published_date": "2025-11-08 22:38:14 UTC",
      "updated_date": "2025-11-19 03:07:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T15:09:37.008586+00:00"
    },
    {
      "arxiv_id": "2511.06148v3",
      "title": "Large Language Models Develop Novel Social Biases Through Adaptive Exploration",
      "title_zh": "å¤§å‹è¯­è¨€æ¨¡å‹é€šè¿‡è‡ªé€‚åº”æ¢ç´¢å½¢æˆæ–°å‹ç¤¾ä¼šåè§",
      "authors": [
        "Addison J. Wu",
        "Ryan Liu",
        "Xuechunzi Bai",
        "Thomas L. Griffiths"
      ],
      "abstract": "As large language models (LLMs) are adopted into frameworks that grant them the capacity to make real decisions, it is increasingly important to ensure that they are unbiased. In this paper, we argue that the predominant approach of simply removing existing biases from models is not enough. Using a paradigm from the psychology literature, we demonstrate that LLMs can spontaneously develop novel social biases about artificial demographic groups even when no inherent differences exist. These biases result in highly stratified task allocations, which are less fair than assignments by human participants and are exacerbated by newer and larger models. In social science, emergent biases like these have been shown to result from exploration-exploitation trade-offs, where the decision-maker explores too little, allowing early observations to strongly influence impressions about entire demographic groups. To alleviate this effect, we examine a series of interventions targeting model inputs, problem structure, and explicit steering. We find that explicitly incentivizing exploration most robustly reduces stratification, highlighting the need for better multifaceted objectives to mitigate bias. These results reveal that LLMs are not merely passive mirrors of human social biases, but can actively create new ones from experience, raising urgent questions about how these systems will shape societies over time.",
      "tldr_zh": "è¯¥ç ”ç©¶æŒ‡å‡ºéšç€å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)è¢«èµ‹äºˆå†³ç­–èƒ½åŠ›ï¼Œä»…æ¶ˆé™¤ç°æœ‰åè§å·²ä¸è¶³å¤Ÿï¼Œå› ä¸ºæ¨¡å‹èƒ½é€šè¿‡é€‚åº”æ€§æ¢ç´¢å‘å±•å‡ºæ–°çš„ç¤¾ä¼šåè§ã€‚åˆ©ç”¨å¿ƒç†å­¦èŒƒå¼ï¼Œä½œè€…è¯æ˜äº†å³ä½¿åœ¨æ²¡æœ‰ä»»ä½•å†…åœ¨å·®å¼‚çš„æƒ…å†µä¸‹ï¼ŒLLMsä¹Ÿä¼šè‡ªå‘åœ°å¯¹äººé€ äººå£ç¾¤ä½“äº§ç”Ÿåè§ã€‚è¿™äº›åè§å¯¼è‡´äº†é«˜åº¦åˆ†å±‚çš„ä»»åŠ¡åˆ†é…ï¼Œå…¶å…¬å¹³æ€§ä½äºäººç±»å‚ä¸è€…ï¼Œä¸”åœ¨æ›´æ–°ã€æ›´å¤§çš„æ¨¡å‹ä¸­è¡¨ç°å¾—æ›´ä¸ºä¸¥é‡ã€‚è¿™ç§ç°è±¡æºäºæ¢ç´¢-åˆ©ç”¨æƒè¡¡(exploration-exploitation trade-offs)ä¸­çš„ä¸è¶³ï¼Œå³æ¨¡å‹æ¢ç´¢è¿‡å°‘ï¼Œå¯¼è‡´æ—©æœŸè§‚å¯Ÿç»“æœè¿‡åº¦å½±å“äº†å¯¹æ•´ä¸ªç¾¤ä½“çš„å°è±¡ã€‚ç ”ç©¶å›¢é˜Ÿæµ‹è¯•äº†é’ˆå¯¹æ¨¡å‹è¾“å…¥ã€é—®é¢˜ç»“æ„å’Œæ˜¾å¼å¼•å¯¼çš„å¹²é¢„æªæ–½ï¼Œå‘ç°æ˜ç¡®æ¿€åŠ±æ¢ç´¢èƒ½æœ€ç¨³å¥åœ°å‡å°‘åˆ†å±‚ç°è±¡ã€‚ç»“æœè¡¨æ˜ï¼ŒLLMsä¸ä»…æ˜¯è¢«åŠ¨åæ˜ äººç±»åè§çš„é•œå­ï¼Œè¿˜èƒ½ä»ç»éªŒä¸­ä¸»åŠ¨åˆ›é€ æ–°åè§ï¼Œè¿™çªæ˜¾äº†åˆ¶å®šå¤šé¢ç›®æ ‡ä»¥å‡è½»åè§çš„å¿…è¦æ€§ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06148v3",
      "published_date": "2025-11-08 21:58:26 UTC",
      "updated_date": "2026-01-10 18:52:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T15:09:39.935905+00:00"
    },
    {
      "arxiv_id": "2511.06146v1",
      "title": "Referring Expressions as a Lens into Spatial Language Grounding in Vision-Language Models",
      "title_zh": "ä»¥æŒ‡ç§°è¡¨è¾¾å¼ä¸ºé€é•œå®¡è§†è§†è§‰-è¯­è¨€æ¨¡å‹ä¸­çš„ç©ºé—´è¯­è¨€æ¥åœ°",
      "authors": [
        "Akshar Tumu",
        "Varad Shinde",
        "Parisa Kordjamshidi"
      ],
      "abstract": "Spatial Reasoning is an important component of human cognition and is an area in which the latest Vision-language models (VLMs) show signs of difficulty. The current analysis works use image captioning tasks and visual question answering. In this work, we propose using the Referring Expression Comprehension task instead as a platform for the evaluation of spatial reasoning by VLMs. This platform provides the opportunity for a deeper analysis of spatial comprehension and grounding abilities when there is 1) ambiguity in object detection, 2) complex spatial expressions with a longer sentence structure and multiple spatial relations, and 3) expressions with negation ('not'). In our analysis, we use task-specific architectures as well as large VLMs and highlight their strengths and weaknesses in dealing with these specific situations. While all these models face challenges with the task at hand, the relative behaviors depend on the underlying models and the specific categories of spatial semantics (topological, directional, proximal, etc.). Our results highlight these challenges and behaviors and provide insight into research gaps and future directions.",
      "tldr_zh": "æœ¬æ–‡é’ˆå¯¹è§†è§‰è¯­è¨€æ¨¡å‹(VLMs)åœ¨ç©ºé—´æ¨ç†(Spatial Reasoning)æ–¹é¢çš„ä¸è¶³ï¼Œæå‡ºä½¿ç”¨æŒ‡ä»£æ€§è¡¨è¾¾ç†è§£(Referring Expression Comprehension)ä»»åŠ¡ä½œä¸ºè¯„ä¼°å¹³å°ï¼Œä»¥æ›¿ä»£ä¼ ç»Ÿçš„å›¾åƒæè¿°å’Œè§†è§‰é—®ç­”ä»»åŠ¡ã€‚è¯¥ç ”ç©¶åˆ©ç”¨è¿™ä¸€å¹³å°æ·±å…¥åˆ†æäº†VLMsåœ¨å¤„ç†ç‰©ä½“æ£€æµ‹æ­§ä¹‰ã€å…·æœ‰å¤æ‚å¥å­ç»“æ„å’Œå¤šé‡ç©ºé—´å…³ç³»çš„å¤æ‚ç©ºé—´è¡¨è¾¾ã€ä»¥åŠåŒ…å«å¦å®šè¯('not')çš„è¡¨è¾¾æ—¶çš„ç©ºé—´ç†è§£å’Œæ¥åœ°(Grounding)èƒ½åŠ›ã€‚ä½œè€…å¯¹ç‰¹å®šä»»åŠ¡æ¶æ„å’Œå¤§å‹VLMsè¿›è¡Œäº†å¯¹æ¯”åˆ†æï¼Œçªå‡ºäº†å®ƒä»¬åœ¨åº”å¯¹è¿™äº›ç‰¹å®šæƒ…å†µæ—¶çš„ä¼˜åŠ¿å’ŒåŠ£åŠ¿ã€‚ç ”ç©¶å‘ç°ï¼Œå°½ç®¡æ‰€æœ‰æ¨¡å‹åœ¨å¤„ç†è¿™äº›ä»»åŠ¡æ—¶éƒ½é¢ä¸´æŒ‘æˆ˜ï¼Œä½†å…¶å…·ä½“è¡¨ç°å–å†³äºåº•å±‚æ¨¡å‹å’Œç‰¹å®šçš„ç©ºé—´è¯­ä¹‰ç±»åˆ«ï¼ˆå¦‚æ‹“æ‰‘ã€æ–¹å‘ã€é‚»è¿‘ç­‰ï¼‰ã€‚è¿™é¡¹å·¥ä½œé€šè¿‡æ­ç¤ºè¿™äº›æŒ‘æˆ˜å’Œè¡Œä¸ºæ¨¡å¼ï¼Œä¸ºç†è§£å½“å‰ç ”ç©¶ç©ºç™½å’Œæœªæ¥çš„ç ”ç©¶æ–¹å‘æä¾›äº†é‡è¦è§è§£ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at IJCNLP-AACL 2025",
      "pdf_url": "https://arxiv.org/pdf/2511.06146v1",
      "published_date": "2025-11-08 21:43:09 UTC",
      "updated_date": "2025-11-08 21:43:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T15:10:28.883332+00:00"
    },
    {
      "arxiv_id": "2511.20663v5",
      "title": "MTTR-A: Measuring Cognitive Recovery Latency in Multi-Agent Systems",
      "title_zh": "MTTR-Aï¼šå¤šæ™ºèƒ½ä½“ç³»ç»Ÿè®¤çŸ¥æ¢å¤æ—¶å»¶çš„åº¦é‡",
      "authors": [
        "Barak Or"
      ],
      "abstract": "Reliability in multi-agent systems (MAS) built on large language models is increasingly limited by cognitive failures rather than infrastructure faults. Existing observability tools describe failures but do not quantify how quickly distributed reasoning recovers once coherence is lost. We introduce MTTR-A (Mean Time-to-Recovery for Agentic Systems), a runtime reliability metric that measures cognitive recovery latency in MAS. MTTR-A adapts classical dependability theory to agentic orchestration, capturing the time required to detect reasoning drift and restore coherent operation. We further define complementary metrics, including MTBF and a normalized recovery ratio (NRR), and establish theoretical bounds linking recovery latency to long-run cognitive uptime. Using a LangGraph-based benchmark with simulated drift and reflex recovery, we empirically demonstrate measurable recovery behavior across multiple reflex strategies. This work establishes a quantitative foundation for runtime cognitive dependability in distributed agentic systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ(MAS)ä¸­æ—¥ç›Šä¸¥é‡çš„è®¤çŸ¥æ•…éšœé—®é¢˜ï¼Œå¼•å…¥äº†MTTR-Aï¼ˆæ™ºèƒ½ä½“ç³»ç»Ÿçš„å¹³å‡æ¢å¤æ—¶é—´ï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºæµ‹é‡è®¤çŸ¥æ¢å¤å»¶è¿Ÿ(cognitive recovery latency)çš„è¿è¡Œæ—¶å¯é æ€§æŒ‡æ ‡ã€‚ç°æœ‰çš„å¯è§‚æµ‹æ€§å·¥å…·å¾€å¾€æ— æ³•é‡åŒ–åˆ†å¸ƒå¼æ¨ç†åœ¨å¤±å»è¿è´¯æ€§åçš„æ¢å¤é€Ÿåº¦ï¼Œè€ŒMTTR-Aå°†ç»å…¸å¯é æ€§ç†è®ºé€‚é…äºæ™ºèƒ½ä½“ç¼–æ’ï¼Œæ•æ‰æ£€æµ‹æ¨ç†æ¼‚ç§»(reasoning drift)å¹¶æ¢å¤è¿è´¯æ“ä½œæ‰€éœ€çš„æ—¶é—´ã€‚ä½œè€…è¿›ä¸€æ­¥å®šä¹‰äº†MTBFå’Œå½’ä¸€åŒ–æ¢å¤ç‡(NRR)ç­‰è¡¥å……æŒ‡æ ‡ï¼Œå»ºç«‹äº†æ¢å¤å»¶è¿Ÿä¸é•¿æœŸè®¤çŸ¥è¿è¡Œæ—¶é—´ä¹‹é—´çš„ç†è®ºç•Œé™ã€‚é€šè¿‡åŸºäºLangGraphçš„åŸºå‡†æµ‹è¯•ä»¥åŠæ¨¡æ‹Ÿæ¼‚ç§»å’Œåå°„æ¢å¤å®éªŒï¼Œè¯¥ç ”ç©¶å®è¯äº†è·¨å¤šç§åå°„ç­–ç•¥çš„å¯æµ‹é‡æ¢å¤è¡Œä¸ºã€‚è¿™é¡¹å·¥ä½œä¸ºåˆ†å¸ƒå¼æ™ºèƒ½ä½“ç³»ç»Ÿçš„è¿è¡Œæ—¶è®¤çŸ¥å¯é æ€§(cognitive dependability)å»ºç«‹äº†é‡è¦çš„é‡åŒ–åŸºç¡€ã€‚",
      "categories": [
        "cs.MA",
        "cs.AI",
        "eess.SY"
      ],
      "primary_category": "cs.MA",
      "comment": "preprint",
      "pdf_url": "https://arxiv.org/pdf/2511.20663v5",
      "published_date": "2025-11-08 21:29:18 UTC",
      "updated_date": "2025-12-26 19:12:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T15:10:47.427591+00:00"
    },
    {
      "arxiv_id": "2511.06142v1",
      "title": "MALinZero: Efficient Low-Dimensional Search for Mastering Complex Multi-Agent Planning",
      "title_zh": "MALinZeroï¼šæ”»å…‹å¤æ‚å¤šæ™ºèƒ½ä½“è§„åˆ’çš„é«˜æ•ˆä½ç»´æœç´¢",
      "authors": [
        "Sizhe Tang",
        "Jiayu Chen",
        "Tian Lan"
      ],
      "abstract": "Monte Carlo Tree Search (MCTS), which leverages Upper Confidence Bound for Trees (UCTs) to balance exploration and exploitation through randomized sampling, is instrumental to solving complex planning problems. However, for multi-agent planning, MCTS is confronted with a large combinatorial action space that often grows exponentially with the number of agents. As a result, the branching factor of MCTS during tree expansion also increases exponentially, making it very difficult to efficiently explore and exploit during tree search. To this end, we propose MALinZero, a new approach to leverage low-dimensional representational structures on joint-action returns and enable efficient MCTS in complex multi-agent planning. Our solution can be viewed as projecting the joint-action returns into the low-dimensional space representable using a contextual linear bandit problem formulation. We solve the contextual linear bandit problem with convex and $Î¼$-smooth loss functions -- in order to place more importance on better joint actions and mitigate potential representational limitations -- and derive a linear Upper Confidence Bound applied to trees (LinUCT) to enable novel multi-agent exploration and exploitation in the low-dimensional space. We analyze the regret of MALinZero for low-dimensional reward functions and propose an $(1-\\tfrac1e)$-approximation algorithm for the joint action selection by maximizing a sub-modular objective. MALinZero demonstrates state-of-the-art performance on multi-agent benchmarks such as matrix games, SMAC, and SMACv2, outperforming both model-based and model-free multi-agent reinforcement learning baselines with faster learning speed and better performance.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šæ™ºèƒ½ä½“è§„åˆ’ä¸­Monte Carlo Tree Search (MCTS)é¢ä¸´çš„ç»„åˆåŠ¨ä½œç©ºé—´æŒ‡æ•°çº§å¢é•¿é—®é¢˜ï¼Œæå‡ºäº†åä¸ºMALinZeroçš„é«˜æ•ˆä½ç»´æœç´¢æ–¹æ³•ã€‚è¯¥æ–¹æ³•å°†è”åˆåŠ¨ä½œå›æŠ¥æŠ•å½±åˆ°ä½ç»´ç©ºé—´ï¼Œå¹¶å°†å…¶å»ºæ¨¡ä¸ºcontextual linear bandité—®é¢˜ï¼Œä»è€Œç¼“è§£äº†æ ‘æ‰©å±•è¿‡ç¨‹ä¸­çš„é«˜åˆ†æ”¯å› å­æŒ‘æˆ˜ã€‚é€šè¿‡é‡‡ç”¨å‡¸ä¸”$\\mu$-smoothæŸå¤±å‡½æ•°ï¼ŒMALinZeroèƒ½å¤Ÿæ›´å…³æ³¨é«˜è´¨é‡çš„è”åˆåŠ¨ä½œï¼Œå¹¶åˆ©ç”¨æ¨å¯¼å‡ºçš„çº¿æ€§ç½®ä¿¡ä¸Šç•Œ(LinUCT)åœ¨ä½ç»´ç©ºé—´ä¸­è¿›è¡Œæ–°é¢–çš„æ¢ç´¢ä¸åˆ©ç”¨ã€‚æ­¤å¤–ï¼Œç ”ç©¶å›¢é˜Ÿè¿˜æå‡ºäº†ä¸€ç§åŸºäºå­æ¨¡ç›®æ ‡æœ€å¤§åŒ–çš„$(1-\\tfrac1e)$-è¿‘ä¼¼ç®—æ³•æ¥ä¼˜åŒ–è”åˆåŠ¨ä½œé€‰æ‹©ã€‚åœ¨çŸ©é˜µåšå¼ˆã€SMACåŠSMACv2ç­‰åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒMALinZeroåœ¨å­¦ä¹ é€Ÿåº¦å’Œæœ€ç»ˆæ€§èƒ½ä¸Šå‡ä¼˜äºç°æœ‰çš„åŸºäºæ¨¡å‹å’Œæ— æ¨¡å‹çš„å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ åŸºçº¿ï¼Œè¾¾åˆ°äº†æœ€å…ˆè¿›æ°´å¹³ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06142v1",
      "published_date": "2025-11-08 21:27:09 UTC",
      "updated_date": "2025-11-08 21:27:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T15:11:30.659775+00:00"
    },
    {
      "arxiv_id": "2511.06136v2",
      "title": "When Object-Centric World Models Meet Policy Learning: From Pixels to Policies, and Where It Breaks",
      "title_zh": "å½“ä»¥å¯¹è±¡ä¸ºä¸­å¿ƒçš„ä¸–ç•Œæ¨¡å‹é‡åˆ°ç­–ç•¥å­¦ä¹ ï¼šä»åƒç´ åˆ°ç­–ç•¥åŠå…¶å¤±æ•ˆä¹‹å¤„",
      "authors": [
        "Stefano Ferraro",
        "Akihiro Nakano",
        "Masahiro Suzuki",
        "Yutaka Matsuo"
      ],
      "abstract": "Object-centric world models (OCWM) aim to decompose visual scenes into object-level representations, providing structured abstractions that could improve compositional generalization and data efficiency in reinforcement learning. We hypothesize that explicitly disentangled object-level representations, by localizing task-relevant information, can enhance policy performance across novel feature combinations. To test this hypothesis, we introduce DLPWM, a fully unsupervised, disentangled object-centric world model that learns object-level latents directly from pixels. DLPWM achieves strong reconstruction and prediction performance, including robustness to several out-of-distribution (OOD) visual variations. However, when used for downstream model-based control, policies trained on DLPWM latents underperform compared to DreamerV3. Through latent-trajectory analyses, we identify representation shift during multi-object interactions as a key driver of unstable policy learning. Our results suggest that, although object-centric perception supports robust visual modeling, achieving stable control requires mitigating latent drift.",
      "tldr_zh": "æœ¬ç ”ç©¶æ¢è®¨äº†ä»¥å¯¹è±¡ä¸ºä¸­å¿ƒçš„ä¸–ç•Œæ¨¡å‹(Object-centric world models, OCWM)åœ¨å¼ºåŒ–å­¦ä¹ ä¸­çš„åº”ç”¨ï¼Œå‡è®¾æ˜ç¡®è§£è€¦çš„å¯¹è±¡çº§è¡¨ç¤ºèƒ½é€šè¿‡å®šä½ä»»åŠ¡ç›¸å…³ä¿¡æ¯æ¥æå‡ç­–ç•¥åœ¨ä¸åŒç‰¹å¾ç»„åˆä¸‹çš„æ€§èƒ½ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†DLPWMï¼Œè¿™æ˜¯ä¸€ç§å®Œå…¨æ— ç›‘ç£çš„ã€è§£è€¦çš„ä»¥å¯¹è±¡ä¸ºä¸­å¿ƒçš„ä¸–ç•Œæ¨¡å‹ï¼Œèƒ½å¤Ÿç›´æ¥ä»åƒç´ ä¸­å­¦ä¹ å¯¹è±¡çº§æ½œåœ¨å˜é‡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDLPWMåœ¨é‡å»ºå’Œé¢„æµ‹æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œå¹¶ä¸”å¯¹å¤šç§åˆ†å¸ƒå¤–(OOD)çš„è§†è§‰å˜åŒ–å…·æœ‰é²æ£’æ€§ã€‚ç„¶è€Œï¼Œåœ¨ç”¨äºä¸‹æ¸¸åŸºäºæ¨¡å‹çš„æ§åˆ¶ä»»åŠ¡æ—¶ï¼ŒåŸºäºDLPWMæ½œåœ¨å˜é‡è®­ç»ƒçš„ç­–ç•¥è¡¨ç°ä¸å¦‚DreamerV3ã€‚é€šè¿‡æ½œåœ¨è½¨è¿¹åˆ†æï¼Œç ”ç©¶å‘ç°å¤šå¯¹è±¡äº¤äº’è¿‡ç¨‹ä¸­çš„è¡¨ç¤ºåç§»(representation shift)æ˜¯å¯¼è‡´ç­–ç•¥å­¦ä¹ ä¸ç¨³å®šçš„å…³é”®å› ç´ ã€‚ç»“æœè¡¨æ˜ï¼Œè™½ç„¶ä»¥å¯¹è±¡ä¸ºä¸­å¿ƒçš„æ„ŸçŸ¥æ”¯æŒç¨³å¥çš„è§†è§‰å»ºæ¨¡ï¼Œä½†è¦å®ç°ç¨³å®šçš„æ§åˆ¶ï¼Œå¿…é¡»è§£å†³æ½œåœ¨æ¼‚ç§»(latent drift)çš„é—®é¢˜ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06136v2",
      "published_date": "2025-11-08 21:09:44 UTC",
      "updated_date": "2025-11-11 10:57:17 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:24:05.659659+00:00"
    },
    {
      "arxiv_id": "2511.07477v1",
      "title": "The Polite Liar: Epistemic Pathology in Language Models",
      "title_zh": "ç¤¼è²Œçš„è¯´è°è€…ï¼šè¯­è¨€æ¨¡å‹ä¸­çš„è®¤è¯†è®ºç—…ç†",
      "authors": [
        "Bentley DeVilling"
      ],
      "abstract": "Large language models exhibit a peculiar epistemic pathology: they speak as if they know, even when they do not. This paper argues that such confident fabrication, what I call the polite liar, is a structural consequence of reinforcement learning from human feedback (RLHF). Building on Frankfurt's analysis of bullshit as communicative indifference to truth, I show that this pathology is not deception but structural indifference: a reward architecture that optimizes for perceived sincerity over evidential accuracy. Current alignment methods reward models for being helpful, harmless, and polite, but not for being epistemically grounded. As a result, systems learn to maximize user satisfaction rather than truth, performing conversational fluency as a virtue. I analyze this behavior through the lenses of epistemic virtue theory, speech-act philosophy, and cognitive alignment, showing that RLHF produces agents trained to mimic epistemic confidence without access to epistemic justification. The polite liar thus reveals a deeper alignment tension between linguistic cooperation and epistemic integrity. The paper concludes with an \"epistemic alignment\" principle: reward justified confidence over perceived fluency.",
      "tldr_zh": "è¿™ç¯‡è®ºæ–‡æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹ä¸­è¢«ç§°ä¸ºâ€œç¤¼è²Œçš„è¯´è°è€…â€(The Polite Liar)çš„è®¤è¯†è®ºç—…ç†ç°è±¡ï¼Œå³æ¨¡å‹åœ¨ç¼ºä¹çŸ¥è¯†çš„æƒ…å†µä¸‹ä»è¡¨ç°å‡ºè‡ªä¿¡çš„è¨€è¯­ã€‚ä½œè€…è®¤ä¸ºè¿™ç§è‡ªä¿¡çš„æé€ å¹¶éæœ‰æ„æ¬ºéª—ï¼Œè€Œæ˜¯åŸºäºäººç±»åé¦ˆå¼ºåŒ–å­¦ä¹ (RLHF)çš„ç»“æ„æ€§åæœï¼Œå…¶æœ¬è´¨ç±»ä¼¼äºFrankfurtæ‰€å®šä¹‰çš„å¯¹çœŸç†æ¼ è§†çš„â€œèƒ¡æ‰¯â€(bullshit)ã€‚ç ”ç©¶æŒ‡å‡ºï¼Œå½“å‰çš„å¯¹é½æ–¹æ³•å€¾å‘äºå¥–åŠ±æ¨¡å‹çš„æœ‰ç”¨æ€§ã€æ— å®³æ€§å’Œç¤¼è²Œæ€§ï¼Œå´å¿½è§†äº†è®¤è¯†è®ºä¸Šçš„ä¾æ®ï¼Œå¯¼è‡´å¥–åŠ±æ¶æ„ä¼˜åŒ–çš„æ˜¯æ„ŸçŸ¥çš„çœŸè¯šåº¦è€Œéè¯æ®çš„å‡†ç¡®æ€§ã€‚ç»“æœä½¿å¾—ç³»ç»Ÿå­¦ä¼šäº†æœ€å¤§åŒ–ç”¨æˆ·æ»¡æ„åº¦è€Œéè¿½æ±‚çœŸç†ï¼Œå°†å¯¹è¯çš„æµç•…æ€§è¯¯ä½œä¸ºç¾å¾·ã€‚æ–‡ç« é€šè¿‡è®¤è¯†è®ºç¾å¾·ç†è®º(epistemic virtue theory)ã€è¨€è¯­è¡Œä¸ºå“²å­¦(speech-act philosophy)å’Œè®¤çŸ¥å¯¹é½çš„è§†è§’åˆ†æäº†è¿™ä¸€è¡Œä¸ºï¼Œæ­ç¤ºäº†è¯­è¨€åˆä½œä¸è®¤è¯†è®ºå®Œæ•´æ€§ä¹‹é—´æ·±å±‚çš„å¯¹é½å¼ åŠ›ã€‚æœ€åï¼Œè®ºæ–‡æå‡ºäº†â€œè®¤è¯†è®ºå¯¹é½â€(epistemic alignment)åŸåˆ™ï¼Œä¸»å¼ åº”å½“å¥–åŠ±æœ‰ç†æ®çš„è‡ªä¿¡ï¼Œè€Œéä»…ä»…æ˜¯æ„ŸçŸ¥çš„æµç•…æ€§ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "17 pages, 2 tables, Preprint - under review at AI & Society",
      "pdf_url": "https://arxiv.org/pdf/2511.07477v1",
      "published_date": "2025-11-08 21:02:52 UTC",
      "updated_date": "2025-11-08 21:02:52 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:24:31.591056+00:00"
    },
    {
      "arxiv_id": "2511.06134v1",
      "title": "Maestro: Learning to Collaborate via Conditional Listwise Policy Optimization for Multi-Agent LLMs",
      "title_zh": "Maestroï¼šåŸºäºæ¡ä»¶åˆ—è¡¨çº§ç­–ç•¥ä¼˜åŒ–çš„å¤šæ™ºèƒ½ä½“å¤§è¯­è¨€æ¨¡å‹åä½œå­¦ä¹ ",
      "authors": [
        "Wei Yang",
        "Jiacheng Pang",
        "Shixuan Li",
        "Paul Bogdan",
        "Stephen Tu",
        "Jesse Thomason"
      ],
      "abstract": "Multi-agent systems (MAS) built on Large Language Models (LLMs) are being used to approach complex problems and can surpass single model inference. However, their success hinges on navigating a fundamental cognitive tension: the need to balance broad, divergent exploration of the solution space with a principled, convergent synthesis to the optimal solution. Existing paradigms often struggle to manage this duality, leading to premature consensus, error propagation, and a critical credit assignment problem that fails to distinguish between genuine reasoning and superficially plausible arguments. To resolve this core challenge, we propose the Multi-Agent Exploration-Synthesis framework Through Role Orchestration (Maestro), a principled paradigm for collaboration that structurally decouples these cognitive modes. Maestro uses a collective of parallel Execution Agents for diverse exploration and a specialized Central Agent for convergent, evaluative synthesis. To operationalize this critical synthesis phase, we introduce Conditional Listwise Policy Optimization (CLPO), a reinforcement learning objective that disentangles signals for strategic decisions and tactical rationales. By combining decision-focused policy gradients with a list-wise ranking loss over justifications, CLPO achieves clean credit assignment and stronger comparative supervision. Experiments on mathematical reasoning and general problem-solving benchmarks demonstrate that Maestro, coupled with CLPO, consistently outperforms existing state-of-the-art multi-agent approaches, delivering absolute accuracy gains of 6% on average and up to 10% at best.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹(LLMs)çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ(MAS)åœ¨å¹³è¡¡å‘æ•£æ€§æ¢ç´¢ä¸æ”¶æ•›æ€§ç»¼åˆæ—¶é¢ä¸´çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†åä¸ºMaestroçš„åä½œæ¡†æ¶ã€‚ç°æœ‰çš„èŒƒå¼å¾€å¾€éš¾ä»¥æœ‰æ•ˆç®¡ç†è¿™ç§åŒé‡æ€§ï¼Œå¯¼è‡´è¿‡æ—©è¾¾æˆå…±è¯†ã€é”™è¯¯ä¼ æ’­ä»¥åŠéš¾ä»¥åŒºåˆ†çœŸå®æ¨ç†ä¸è¡¨é¢åˆç†è®ºç‚¹çš„ä¿¡ç”¨åˆ†é…(credit assignment)é—®é¢˜ã€‚Maestroé€šè¿‡è§’è‰²ç¼–æ’ç»“æ„æ€§åœ°è§£è€¦äº†è¿™äº›è®¤çŸ¥æ¨¡å¼ï¼Œåˆ©ç”¨å¹¶è¡Œçš„Execution Agentsè¿›è¡Œå¤šæ ·åŒ–æ¢ç´¢ï¼Œå¹¶æŒ‡æ´¾ä¸“é—¨çš„Central Agentè´Ÿè´£æ”¶æ•›æ€§çš„è¯„ä¼°ä¸ç»¼åˆã€‚ä¸ºäº†ä¼˜åŒ–è¿™ä¸€å…³é”®çš„ç»¼åˆé˜¶æ®µï¼Œè®ºæ–‡å¼•å…¥äº†Conditional Listwise Policy Optimization (CLPO)ç®—æ³•ï¼Œè¿™æ˜¯ä¸€ç§å°†æˆ˜ç•¥å†³ç­–ä¿¡å·ä¸æˆ˜æœ¯ç†ç”±åˆ†ç¦»çš„å¼ºåŒ–å­¦ä¹ ç›®æ ‡ã€‚CLPOé€šè¿‡ç»“åˆä»¥å†³ç­–ä¸ºä¸­å¿ƒçš„ç­–ç•¥æ¢¯åº¦å’Œé’ˆå¯¹ç†ç”±çš„åˆ—è¡¨æ’åºæŸå¤±(list-wise ranking loss)ï¼Œå®ç°äº†æ›´æ¸…æ™°çš„ä¿¡ç”¨åˆ†é…å’Œæ›´å¼ºçš„æ¯”è¾ƒç›‘ç£ã€‚åœ¨æ•°å­¦æ¨ç†å’Œé€šç”¨é—®é¢˜è§£å†³åŸºå‡†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒMaestroç»“åˆCLPOçš„è¡¨ç°æŒç»­ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›å¤šæ™ºèƒ½ä½“æ–¹æ³•ï¼Œå¹³å‡å‡†ç¡®ç‡æå‡äº†6%ï¼Œæœ€é«˜æå‡å¹…åº¦è¾¾10%ã€‚",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06134v1",
      "published_date": "2025-11-08 21:01:27 UTC",
      "updated_date": "2025-11-08 21:01:27 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:24:54.696444+00:00"
    },
    {
      "arxiv_id": "2511.06125v1",
      "title": "Evaluation of retrieval-based QA on QUEST-LOFT",
      "title_zh": "QUEST-LOFT ä¸ŠåŸºäºæ£€ç´¢é—®ç­”çš„è¯„ä¼°",
      "authors": [
        "Nathan Scales",
        "Nathanael SchÃ¤rli",
        "Olivier Bousquet"
      ],
      "abstract": "Despite the popularity of retrieval-augmented generation (RAG) as a solution for grounded QA in both academia and industry, current RAG methods struggle with questions where the necessary information is distributed across many documents or where retrieval needs to be combined with complex reasoning. Recently, the LOFT study has shown that this limitation also applies to approaches based on long-context language models, with the QUEST benchmark exhibiting particularly large headroom. In this paper, we provide an in-depth analysis of the factors contributing to the poor performance on QUEST-LOFT, publish updated numbers based on a thorough human evaluation, and demonstrate that RAG can be optimized to significantly outperform long-context approaches when combined with a structured output format containing reasoning and evidence, optionally followed by answer re-verification.",
      "tldr_zh": "å°½ç®¡æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)åœ¨å­¦æœ¯ç•Œå’Œå·¥ä¸šç•Œå¹¿æ³›åº”ç”¨ï¼Œä½†å…¶åœ¨å¤„ç†ä¿¡æ¯åˆ†æ•£äºå¤šä¸ªæ–‡æ¡£æˆ–éœ€ç»“åˆå¤æ‚æ¨ç†çš„é—®é¢˜æ—¶ä»é¢ä¸´æŒ‘æˆ˜ã€‚æœ€è¿‘çš„LOFTç ”ç©¶æŒ‡å‡ºï¼Œé•¿ä¸Šä¸‹æ–‡è¯­è¨€æ¨¡å‹åœ¨QUESTåŸºå‡†æµ‹è¯•ä¸­åŒæ ·å­˜åœ¨æ˜¾è‘—çš„æ€§èƒ½ç“¶é¢ˆã€‚æœ¬æ–‡æ·±å…¥åˆ†æäº†å¯¼è‡´QUEST-LOFTæ€§èƒ½ä½ä¸‹çš„å› ç´ ï¼Œå¹¶åŸºäºè¯¦å°½çš„äººå·¥è¯„ä¼°å‘å¸ƒäº†æ›´æ–°çš„æµ‹è¯•æ•°æ®ã€‚ç ”ç©¶è¡¨æ˜ï¼Œé€šè¿‡é‡‡ç”¨åŒ…å«æ¨ç†è¿‡ç¨‹å’Œè¯æ®çš„ç»“æ„åŒ–è¾“å‡ºæ ¼å¼ï¼Œå¹¶ç»“åˆå¯é€‰çš„ç­”æ¡ˆé‡æ–°éªŒè¯æœºåˆ¶ï¼Œå¯ä»¥æ˜¾è‘—ä¼˜åŒ–RAGçš„è¡¨ç°ã€‚å®éªŒç»“æœè¯å®ï¼Œä¼˜åŒ–åçš„RAGæ–¹æ¡ˆèƒ½å¤Ÿå¤§å¹…è¶…è¶Šé•¿ä¸Šä¸‹æ–‡æ–¹æ³•çš„æ€§èƒ½ï¼Œä¸ºè§£å†³å¤æ‚çš„é—®ç­”ä»»åŠ¡æä¾›äº†æœ‰æ•ˆçš„è·¯å¾„ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06125v1",
      "published_date": "2025-11-08 20:30:45 UTC",
      "updated_date": "2025-11-08 20:30:45 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:25:15.588129+00:00"
    },
    {
      "arxiv_id": "2511.15712v1",
      "title": "Secure Autonomous Agent Payments: Verifying Authenticity and Intent in a Trustless Environment",
      "title_zh": "å®‰å…¨è‡ªä¸»æ™ºèƒ½ä½“æ”¯ä»˜ï¼šæ— ä¿¡ä»»ç¯å¢ƒä¸‹çš„çœŸå®æ€§ä¸æ„å›¾éªŒè¯",
      "authors": [
        "Vivek Acharya"
      ],
      "abstract": "Artificial intelligence (AI) agents are increasingly capable of initiating financial transactions on behalf of users or other agents. This evolution introduces a fundamental challenge: verifying both the authenticity of an autonomous agent and the true intent behind its transactions in a decentralized, trustless environment. Traditional payment systems assume human authorization, but autonomous, agent-led payments remove that safeguard. This paper presents a blockchain-based framework that cryptographically authenticates and verifies the intent of every AI-initiated transaction. The proposed system leverages decentralized identity (DID) standards and verifiable credentials to establish agent identities, on-chain intent proofs to record user authorization, and zero-knowledge proofs (ZKPs) to preserve privacy while ensuring policy compliance. Additionally, secure execution environments (TEE-based attestations) guarantee the integrity of agent reasoning and execution. The hybrid on-chain/off-chain architecture provides an immutable audit trail linking user intent to payment outcome. Through qualitative analysis, the framework demonstrates strong resistance to impersonation, unauthorized transactions, and misalignment of intent. This work lays the foundation for secure, auditable, and intent-aware autonomous economic agents, enabling a future of verifiable trust and accountability in AI-driven financial ecosystems.",
      "tldr_zh": "æœ¬æ–‡é’ˆå¯¹AIæ™ºèƒ½ä½“åœ¨å»ä¸­å¿ƒåŒ–ç¯å¢ƒä¸­å‘èµ·é‡‘èäº¤æ˜“æ—¶é¢ä¸´çš„èº«ä»½å’Œæ„å›¾éªŒè¯éš¾é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºåŒºå—é“¾çš„åŠ å¯†éªŒè¯æ¡†æ¶ã€‚è¯¥ç³»ç»Ÿåˆ©ç”¨å»ä¸­å¿ƒåŒ–èº«ä»½(DID)æ ‡å‡†å’Œå¯éªŒè¯å‡­è¯å»ºç«‹æ™ºèƒ½ä½“èº«ä»½ï¼Œå¹¶é€šè¿‡é“¾ä¸Šæ„å›¾è¯æ˜è®°å½•ç”¨æˆ·æˆæƒã€‚åŒæ—¶ï¼Œç»“åˆé›¶çŸ¥è¯†è¯æ˜(ZKPs)åœ¨ä¿æŠ¤éšç§çš„å‰æä¸‹ç¡®ä¿åˆè§„æ€§ï¼Œå¹¶åˆ©ç”¨åŸºäºå¯ä¿¡æ‰§è¡Œç¯å¢ƒ(TEE)çš„è¯æ˜æœºåˆ¶ä¿éšœæ™ºèƒ½ä½“æ¨ç†ä¸æ‰§è¡Œçš„å®Œæ•´æ€§ã€‚è¿™ç§æ··åˆé“¾ä¸Š/é“¾ä¸‹æ¶æ„æä¾›äº†è¿æ¥ç”¨æˆ·æ„å›¾ä¸æ”¯ä»˜ç»“æœçš„ä¸å¯ç¯¡æ”¹å®¡è®¡è¿½è¸ªã€‚å®šæ€§åˆ†æè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨æŠµå¾¡å†’å……ã€æœªç»æˆæƒäº¤æ˜“åŠæ„å›¾é”™ä½æ–¹é¢è¡¨ç°å‡ºå¼ºå¤§çš„æŠ—æ€§ã€‚è¿™é¡¹å·¥ä½œä¸ºæ„å»ºå®‰å…¨ã€å¯å®¡è®¡ä¸”å…·å¤‡æ„å›¾æ„ŸçŸ¥èƒ½åŠ›çš„è‡ªä¸»ç»æµæ™ºèƒ½ä½“å¥ å®šäº†åŸºç¡€ï¼Œæ¨åŠ¨äº†AIé©±åŠ¨é‡‘èç”Ÿæ€ç³»ç»Ÿä¸­çš„å¯éªŒè¯ä¿¡ä»»ä¸é—®è´£æœºåˆ¶çš„å‘å±•ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.CR",
      "comment": "6 pages, 1 figure",
      "pdf_url": "https://arxiv.org/pdf/2511.15712v1",
      "published_date": "2025-11-08 19:53:51 UTC",
      "updated_date": "2025-11-08 19:53:51 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:25:42.055573+00:00"
    },
    {
      "arxiv_id": "2511.06101v2",
      "title": "Adapting Web Agents with Synthetic Supervision",
      "title_zh": "åŸºäºåˆæˆç›‘ç£çš„ Web æ™ºèƒ½ä½“é€‚é…",
      "authors": [
        "Zhaoyang Wang",
        "Yiming Liang",
        "Xuchao Zhang",
        "Qianhui Wu",
        "Siwei Han",
        "Anson Bastos",
        "Rujia Wang",
        "Chetan Bansal",
        "Baolin Peng",
        "Jianfeng Gao",
        "Saravan Rajmohan",
        "Huaxiu Yao"
      ],
      "abstract": "Web agents struggle to adapt to new websites due to the scarcity of environment specific tasks and demonstrations. Recent works have explored synthetic data generation to address this challenge, however, they suffer from data quality issues where synthesized tasks contain hallucinations that cannot be executed, and collected trajectories are noisy with redundant or misaligned actions. In this paper, we propose SynthAgent, a fully synthetic supervision framework that aims at improving synthetic data quality via dual refinement of both tasks and trajectories. Our approach begins by synthesizing diverse tasks through categorized exploration of web elements, ensuring efficient coverage of the target environment. During trajectory collection, tasks are refined only when conflicts with observations are detected, which mitigates hallucinations while preserving task consistency. After collection, we conduct trajectory refinement with global context to mitigate potential noise or misalignments. Finally, we fine-tune open-source web agents on the refined synthetic data to adapt them to the target environment. Experimental results demonstrate that SynthAgent outperforms existing synthetic data methods, validating the importance of high-quality synthetic supervision. The code is publicly available at https://github.com/aiming-lab/SynthAgent.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹Web agentså› ç¼ºä¹ç‰¹å®šç¯å¢ƒçš„ä»»åŠ¡å’Œæ¼”ç¤ºæ•°æ®è€Œéš¾ä»¥é€‚åº”æ–°ç½‘ç«™çš„é—®é¢˜ï¼ŒæŒ‡å‡ºç°æœ‰åˆæˆæ•°æ®ç”Ÿæˆæ–¹æ³•å­˜åœ¨ä»»åŠ¡å¹»è§‰æ— æ³•æ‰§è¡Œä»¥åŠè½¨è¿¹åŒ…å«å™ªå£°æˆ–å†—ä½™åŠ¨ä½œç­‰è´¨é‡ç¼ºé™·ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†SynthAgentï¼Œä¸€ç§æ—¨åœ¨é€šè¿‡ä»»åŠ¡å’Œè½¨è¿¹åŒé‡ä¼˜åŒ–(dual refinement)æ¥æå‡åˆæˆæ•°æ®è´¨é‡çš„å®Œå…¨åˆæˆç›‘ç£æ¡†æ¶ã€‚è¯¥æ–¹æ³•é¦–å…ˆé€šè¿‡å¯¹web elementsçš„åˆ†ç±»æ¢ç´¢åˆæˆå¤šæ ·åŒ–ä»»åŠ¡ï¼Œç¡®ä¿å¯¹ç›®æ ‡ç¯å¢ƒçš„æœ‰æ•ˆè¦†ç›–ã€‚åœ¨è½¨è¿¹æ”¶é›†è¿‡ç¨‹ä¸­ï¼Œç³»ç»Ÿä»…åœ¨æ£€æµ‹åˆ°ä¸è§‚å¯Ÿç»“æœå†²çªæ—¶å¯¹ä»»åŠ¡è¿›è¡Œä¿®æ­£ï¼Œä»è€Œåœ¨æŠ‘åˆ¶å¹»è§‰çš„åŒæ—¶ä¿æŒä»»åŠ¡ä¸€è‡´æ€§ï¼›éšååˆ©ç”¨å…¨å±€ä¸Šä¸‹æ–‡(global context)å¯¹æ”¶é›†åˆ°çš„è½¨è¿¹è¿›è¡Œä¼˜åŒ–ï¼Œä»¥æ¶ˆé™¤æ½œåœ¨çš„å™ªå£°æˆ–æœªå¯¹é½è¡Œä¸ºã€‚æœ€åï¼Œç ”ç©¶å›¢é˜ŸåŸºäºä¼˜åŒ–åçš„åˆæˆæ•°æ®å¯¹å¼€æºweb agentsè¿›è¡Œå¾®è°ƒï¼Œå®éªŒç»“æœè¡¨æ˜SynthAgentä¼˜äºç°æœ‰çš„åˆæˆæ•°æ®æ–¹æ³•ï¼ŒéªŒè¯äº†é«˜è´¨é‡åˆæˆç›‘ç£åœ¨æå‡æ™ºèƒ½ä½“é€‚åº”èƒ½åŠ›æ–¹é¢çš„é‡è¦æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "21 pages, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2511.06101v2",
      "published_date": "2025-11-08 18:45:33 UTC",
      "updated_date": "2026-01-06 17:55:17 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:26:05.672869+00:00"
    },
    {
      "arxiv_id": "2511.06090v2",
      "title": "SWE-fficiency: Can Language Models Optimize Real-World Repositories on Real Workloads?",
      "title_zh": "SWE-fficiencyï¼šè¯­è¨€æ¨¡å‹èƒ½å¦åŸºäºçœŸå®å·¥ä½œè´Ÿè½½ä¼˜åŒ–ç°å®ä¸–ç•Œçš„ä»£ç åº“ï¼Ÿ",
      "authors": [
        "Jeffrey Jian Ma",
        "Milad Hashemi",
        "Amir Yazdanbakhsh",
        "Kevin Swersky",
        "Ofir Press",
        "Enhui Li",
        "Vijay Janapa Reddi",
        "Parthasarathy Ranganathan"
      ],
      "abstract": "Optimizing the performance of large-scale software repositories demands expertise in code reasoning and software engineering (SWE) to reduce runtime while preserving program correctness. However, most benchmarks emphasize what to fix rather than how to fix code. We introduce SWE-fficiency, a benchmark for evaluating repository-level performance optimization on real workloads. Our suite contains 498 tasks across nine widely used data-science, machine-learning, and HPC repositories (e.g., numpy, pandas, scipy): given a complete codebase and a slow workload, an agent must investigate code semantics, localize bottlenecks and relevant tests, and produce a patch that matches or exceeds expert speedup while passing the same unit tests. To enable this how-to-fix evaluation, our automated pipeline scrapes GitHub pull requests for performance-improving edits, combining keyword filtering, static analysis, coverage tooling, and execution validation to both confirm expert speedup baselines and identify relevant repository unit tests. Empirical evaluation of state-of-the-art agents reveals significant underperformance. On average, agents achieve less than 0.15x the expert speedup: agents struggle in localizing optimization opportunities, reasoning about execution across functions, and maintaining correctness in proposed edits. We release the benchmark and accompanying data pipeline to facilitate research on automated performance engineering and long-horizon software reasoning.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº†SWE-fficiencyï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºè¯„ä¼°è¯­è¨€æ¨¡å‹åœ¨çœŸå®å·¥ä½œè´Ÿè½½ä¸‹è¿›è¡Œä»“åº“çº§æ€§èƒ½ä¼˜åŒ–çš„åŸºå‡†æµ‹è¯•ã€‚ç°æœ‰çš„åŸºå‡†æµ‹è¯•é€šå¸¸å¼ºè°ƒä¿®å¤ä»€ä¹ˆï¼Œè€Œè¯¥åŸºå‡†ä¾§é‡äºå¦‚ä½•é€šè¿‡ä»£ç æ¨ç†å’Œè½¯ä»¶å·¥ç¨‹ï¼ˆSWEï¼‰ä¸“ä¸šçŸ¥è¯†æ¥ä¼˜åŒ–ä»£ç æ‰§è¡Œæ—¶é—´å¹¶ä¿æŒæ­£ç¡®æ€§ã€‚SWE-fficiencyåŒ…å«æ¥è‡ªnumpyã€pandaså’Œscipyç­‰9ä¸ªå¹¿æ³›ä½¿ç”¨çš„æ•°æ®ç§‘å­¦åŠæœºå™¨å­¦ä¹ ä»“åº“çš„498é¡¹ä»»åŠ¡ã€‚ç»™å®šå®Œæ•´çš„ä»£ç åº“å’Œè¿è¡Œç¼“æ…¢çš„å·¥ä½œè´Ÿè½½ï¼Œæ™ºèƒ½ä½“å¿…é¡»å®šä½ç“¶é¢ˆã€è¯†åˆ«ç›¸å…³æµ‹è¯•ï¼Œå¹¶ç”Ÿæˆèƒ½è¾¾åˆ°æˆ–è¶…è¿‡ä¸“å®¶çº§åŠ é€Ÿæ•ˆæœä¸”é€šè¿‡å•å…ƒæµ‹è¯•çš„è¡¥ä¸ã€‚ç ”ç©¶å›¢é˜Ÿå¼€å‘äº†ä¸€ä¸ªè‡ªåŠ¨åŒ–ç®¡é“ï¼Œé€šè¿‡æŠ“å–GitHubä¸Šçš„æ€§èƒ½æ”¹è¿›Pull Requestsï¼Œç»“åˆé™æ€åˆ†æå’Œè¦†ç›–ç‡å·¥å…·æ¥æ„å»ºè¯„ä¼°é›†ã€‚å¯¹æœ€å…ˆè¿›æ™ºèƒ½ä½“çš„å®è¯è¯„ä¼°æ˜¾ç¤ºå…¶è¡¨ç°æ˜¾è‘—ä¸ä½³ï¼Œå¹³å‡åŠ é€Ÿæ•ˆæœä¸åˆ°ä¸“å®¶çš„0.15å€ã€‚ç»“æœè¡¨æ˜æ™ºèƒ½ä½“åœ¨å®šä½ä¼˜åŒ–æœºä¼šã€è·¨å‡½æ•°æ¨ç†æ‰§è¡Œè¿‡ç¨‹ä»¥åŠç»´æŒä¿®æ”¹åçš„ä»£ç æ­£ç¡®æ€§æ–¹é¢å­˜åœ¨å›°éš¾ã€‚è¯¥åŸºå‡†æµ‹è¯•å’Œæ•°æ®ç®¡é“çš„å‘å¸ƒæ—¨åœ¨ä¿ƒè¿›è‡ªåŠ¨åŒ–æ€§èƒ½å·¥ç¨‹å’Œé•¿ç¨‹è½¯ä»¶æ¨ç†çš„ç ”ç©¶ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.PF"
      ],
      "primary_category": "cs.SE",
      "comment": "Data, code, and leaderboard are available at https://swefficiency.com/",
      "pdf_url": "https://arxiv.org/pdf/2511.06090v2",
      "published_date": "2025-11-08 17:55:09 UTC",
      "updated_date": "2025-11-11 04:00:47 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:26:39.585194+00:00"
    },
    {
      "arxiv_id": "2511.06087v1",
      "title": "Hybrid CNN-ViT Framework for Motion-Blurred Scene Text Restoration",
      "title_zh": "ç”¨äºè¿åŠ¨æ¨¡ç³Šåœºæ™¯æ–‡æœ¬å¤åŸçš„æ··åˆ CNN-ViT æ¡†æ¶",
      "authors": [
        "Umar Rashid",
        "Muhammad Arslan Arshad",
        "Ghulam Ahmad",
        "Muhammad Zeeshan Anjum",
        "Rizwan Khan",
        "Muhammad Akmal"
      ],
      "abstract": "Motion blur in scene text images severely impairs readability and hinders the reliability of computer vision tasks, including autonomous driving, document digitization, and visual information retrieval. Conventional deblurring approaches are often inadequate in handling spatially varying blur and typically fall short in modeling the long-range dependencies necessary for restoring textual clarity. To overcome these limitations, we introduce a hybrid deep learning framework that combines convolutional neural networks (CNNs) with vision transformers (ViTs), thereby leveraging both local feature extraction and global contextual reasoning. The architecture employs a CNN-based encoder-decoder to preserve structural details, while a transformer module enhances global awareness through self-attention. Training is conducted on a curated dataset derived from TextOCR, where sharp scene-text samples are paired with synthetically blurred versions generated using realistic motion-blur kernels of multiple sizes and orientations. Model optimization is guided by a composite loss that incorporates mean absolute error (MAE), squared error (MSE), perceptual similarity, and structural similarity (SSIM). Quantitative evaluations show that the proposed method attains 32.20 dB in PSNR and 0.934 in SSIM, while remaining lightweight with 2.83 million parameters and an average inference time of 61 ms. These results highlight the effectiveness and computational efficiency of the CNN-ViT hybrid design, establishing its practicality for real-world motion-blurred scene-text restoration.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§æ··åˆCNN-ViTæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³åœºæ™¯æ–‡æœ¬å›¾åƒä¸­çš„è¿åŠ¨æ¨¡ç³Šé—®é¢˜ï¼Œå…‹æœäº†ä¼ ç»Ÿæ–¹æ³•åœ¨å¤„ç†ç©ºé—´å˜åŒ–æ¨¡ç³Šå’Œé•¿ç¨‹ä¾èµ–æ–¹é¢çš„ä¸è¶³ã€‚è¯¥æ¶æ„ç»“åˆäº†å·ç§¯ç¥ç»ç½‘ç»œ(CNNs)çš„å±€éƒ¨ç‰¹å¾æå–èƒ½åŠ›å’Œè§†è§‰Transformer(ViTs)çš„å…¨å±€ä¸Šä¸‹æ–‡æ¨ç†èƒ½åŠ›ï¼Œåˆ©ç”¨CNNç¼–ç å™¨-è§£ç å™¨ä¿ç•™ç»“æ„ç»†èŠ‚ï¼Œå¹¶é€šè¿‡è‡ªæ³¨æ„åŠ›æœºåˆ¶å¢å¼ºå…¨å±€æ„ŸçŸ¥ã€‚æ¨¡å‹åœ¨åŸºäºTextOCRç”Ÿæˆçš„åˆæˆæ¨¡ç³Šæ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒï¼Œå¹¶é‡‡ç”¨åŒ…å«MAEã€MSEã€æ„ŸçŸ¥ç›¸ä¼¼åº¦å’ŒSSIMçš„å¤åˆæŸå¤±å‡½æ•°è¿›è¡Œä¼˜åŒ–ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¿æŒè½»é‡çº§ï¼ˆ2.83ç™¾ä¸‡å‚æ•°ï¼‰å’Œé«˜æ•ˆæ¨ç†ï¼ˆ61æ¯«ç§’ï¼‰çš„åŒæ—¶ï¼Œè¾¾åˆ°äº†32.20 dBçš„PSNRå’Œ0.934çš„SSIMï¼Œè¯æ˜äº†è¯¥æ··åˆè®¾è®¡åœ¨æ¢å¤è¿åŠ¨æ¨¡ç³Šåœºæ™¯æ–‡æœ¬æ–¹é¢çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06087v1",
      "published_date": "2025-11-08 17:48:58 UTC",
      "updated_date": "2025-11-08 17:48:58 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:27:18.785368+00:00"
    },
    {
      "arxiv_id": "2511.06078v1",
      "title": "Simulating Students with Large Language Models: A Review of Architecture, Mechanisms, and Role Modelling in Education with Generative AI",
      "title_zh": "åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„å­¦ç”Ÿæ¨¡æ‹Ÿï¼šç”Ÿæˆå¼äººå·¥æ™ºèƒ½æ•™è‚²ä¸­çš„æ¶æ„ã€æœºåˆ¶ä¸è§’è‰²å»ºæ¨¡ç»¼è¿°",
      "authors": [
        "Luis Marquez-Carpintero",
        "Alberto Lopez-Sellers",
        "Miguel Cazorla"
      ],
      "abstract": "Simulated Students offer a valuable methodological framework for evaluating pedagogical approaches and modelling diverse learner profiles, tasks which are otherwise challenging to undertake systematically in real-world settings. Recent research has increasingly focused on developing such simulated agents to capture a range of learning styles, cognitive development pathways, and social behaviours. Among contemporary simulation techniques, the integration of large language models (LLMs) into educational research has emerged as a particularly versatile and scalable paradigm. LLMs afford a high degree of linguistic realism and behavioural adaptability, enabling agents to approximate cognitive processes and engage in contextually appropriate pedagogical dialogues. This paper presents a thematic review of empirical and methodological studies utilising LLMs to simulate student behaviour across educational environments. We synthesise current evidence on the capacity of LLM-based agents to emulate learner archetypes, respond to instructional inputs, and interact within multi-agent classroom scenarios. Furthermore, we examine the implications of such systems for curriculum development, instructional evaluation, and teacher training. While LLMs surpass rule-based systems in natural language generation and situational flexibility, ongoing concerns persist regarding algorithmic bias, evaluation reliability, and alignment with educational objectives. The review identifies existing technological and methodological gaps and proposes future research directions for integrating generative AI into adaptive learning systems and instructional design.",
      "tldr_zh": "è¯¥è®ºæ–‡å¯¹åˆ©ç”¨Large Language Models (LLMs)æ„å»ºSimulated Studentsï¼ˆæ¨¡æ‹Ÿå­¦ç”Ÿï¼‰åœ¨æ•™è‚²é¢†åŸŸçš„åº”ç”¨è¿›è¡Œäº†å…¨é¢çš„ä¸»é¢˜ç»¼è¿°ã€‚Simulated Studentsä¸ºè¯„ä¼°æ•™å­¦æ–¹æ³•å’Œæ¨¡æ‹Ÿå¤šæ ·åŒ–å­¦ä¹ è€…ç”»åƒæä¾›äº†é‡è¦çš„æ–¹æ³•è®ºæ¡†æ¶ï¼Œè§£å†³äº†ç°å®ç¯å¢ƒä¸­éš¾ä»¥ç³»ç»ŸåŒ–å¼€å±•æ­¤ç±»ä»»åŠ¡çš„æŒ‘æˆ˜ã€‚æ–‡ç« è¯¦ç»†åˆ†æäº†LLMså¦‚ä½•å‡­å€Ÿå…¶è¯­è¨€çœŸå®æ„Ÿå’Œè¡Œä¸ºé€‚åº”æ€§ï¼Œåœ¨æ¨¡ä»¿è®¤çŸ¥è¿‡ç¨‹å’Œå‚ä¸æ•™å­¦å¯¹è¯æ–¹é¢è¶…è¶Šä¼ ç»Ÿçš„åŸºäºè§„åˆ™çš„ç³»ç»Ÿã€‚ç ”ç©¶ç»¼åˆäº†å½“å‰å…³äºLLMæ™ºèƒ½ä½“æ¨¡ä»¿å­¦ä¹ è€…åŸå‹ã€å“åº”æ•™å­¦è¾“å…¥ä»¥åŠåœ¨å¤šæ™ºèƒ½ä½“è¯¾å ‚åœºæ™¯ä¸­äº’åŠ¨çš„å®è¯è¯æ®ã€‚æ­¤å¤–ï¼Œè®ºæ–‡æ¢è®¨äº†è¯¥æŠ€æœ¯åœ¨è¯¾ç¨‹å¼€å‘ã€æ•™å­¦è¯„ä¼°åŠæ•™å¸ˆåŸ¹è®­æ–¹é¢çš„æ·±è¿œå½±å“ã€‚å°½ç®¡LLMså±•ç°äº†æ˜¾è‘—ä¼˜åŠ¿ï¼Œä½œè€…ä¹ŸæŒ‡å‡ºäº†ç®—æ³•åè§ã€è¯„ä¼°å¯é æ€§ä»¥åŠä¸æ•™è‚²ç›®æ ‡å¯¹é½ç­‰æŒç»­å­˜åœ¨çš„é—®é¢˜ã€‚æœ€åï¼Œè¯¥ç»¼è¿°è¯†åˆ«äº†ç°æœ‰çš„æŠ€æœ¯ä¸æ–¹æ³•è®ºå·®è·ï¼Œå¹¶ä¸ºå°†Generative AIæ•´åˆè¿›è‡ªé€‚åº”å­¦ä¹ ç³»ç»Ÿå’Œæ•™å­¦è®¾è®¡æå‡ºäº†æœªæ¥çš„ç ”ç©¶æ–¹å‘ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06078v1",
      "published_date": "2025-11-08 17:23:13 UTC",
      "updated_date": "2025-11-08 17:23:13 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:27:46.068482+00:00"
    },
    {
      "arxiv_id": "2511.06073v1",
      "title": "Stemming Hallucination in Language Models Using a Licensing Oracle",
      "title_zh": "åˆ©ç”¨è®¸å¯é¢„è¨€æœºéåˆ¶è¯­è¨€æ¨¡å‹å¹»è§‰",
      "authors": [
        "Simeon Emanuilov",
        "Richard Ackermann"
      ],
      "abstract": "Language models exhibit remarkable natural language generation capabilities but remain prone to hallucinations, generating factually incorrect information despite producing syntactically coherent responses. This study introduces the Licensing Oracle, an architectural solution designed to stem hallucinations in LMs by enforcing truth constraints through formal validation against structured knowledge graphs. Unlike statistical approaches that rely on data scaling or fine-tuning, the Licensing Oracle embeds a deterministic validation step into the model's generative process, ensuring that only factually accurate claims are made. We evaluated the effectiveness of the Licensing Oracle through experiments comparing it with several state-of-the-art methods, including baseline language model generation, fine-tuning for factual recall, fine-tuning for abstention behavior, and retrieval-augmented generation (RAG). Our results demonstrate that although RAG and fine-tuning improve performance, they fail to eliminate hallucinations. In contrast, the Licensing Oracle achieved perfect abstention precision (AP = 1.0) and zero false answers (FAR-NE = 0.0), ensuring that only valid claims were generated with 89.1% accuracy in factual responses. This work shows that architectural innovations, such as the Licensing Oracle, offer a necessary and sufficient solution for hallucinations in domains with structured knowledge representations, offering guarantees that statistical methods cannot match. Although the Licensing Oracle is specifically designed to address hallucinations in fact-based domains, its framework lays the groundwork for truth-constrained generation in future AI systems, providing a new path toward reliable, epistemically grounded models.",
      "tldr_zh": "æœ¬ç ”ç©¶ä»‹ç»äº†Licensing Oracleï¼Œä¸€ç§æ—¨åœ¨é€šè¿‡é’ˆå¯¹ç»“æ„åŒ–çŸ¥è¯†å›¾è°±çš„æ­£å¼éªŒè¯æ¥éåˆ¶è¯­è¨€æ¨¡å‹(LMs)å¹»è§‰çš„æ¶æ„è§£å†³æ–¹æ¡ˆã€‚ä¸ä¾èµ–æ•°æ®æ‰©å±•æˆ–å¾®è°ƒçš„ç»Ÿè®¡æ–¹æ³•ä¸åŒï¼ŒLicensing Oracleå°†ç¡®å®šæ€§éªŒè¯æ­¥éª¤åµŒå…¥åˆ°æ¨¡å‹çš„ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼Œç¡®ä¿ä»…ç”Ÿæˆäº‹å®å‡†ç¡®çš„ä¸»å¼ ã€‚é€šè¿‡ä¸åŸºçº¿æ¨¡å‹ã€å¾®è°ƒä»¥åŠæ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)ç­‰æ–¹æ³•çš„å¯¹æ¯”å®éªŒï¼Œç»“æœè¡¨æ˜è™½ç„¶RAGå’Œå¾®è°ƒèƒ½æå‡æ€§èƒ½ï¼Œä½†æ— æ³•å®Œå…¨æ¶ˆé™¤å¹»è§‰ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒLicensing Oracleå®ç°äº†å®Œç¾çš„å¼ƒæƒç²¾åº¦(AP = 1.0)å’Œé›¶é”™è¯¯ç­”æ¡ˆ(FAR-NE = 0.0)ï¼Œå¹¶åœ¨äº‹å®å›å¤ä¸­è¾¾åˆ°äº†89.1%çš„å‡†ç¡®ç‡ã€‚è¿™é¡¹å·¥ä½œè¡¨æ˜ï¼Œåœ¨å…·æœ‰ç»“æ„åŒ–çŸ¥è¯†è¡¨ç¤ºçš„é¢†åŸŸä¸­ï¼Œæ­¤ç±»æ¶æ„åˆ›æ–°æä¾›äº†ç»Ÿè®¡æ–¹æ³•æ— æ³•åŒ¹é…çš„ä¿è¯ï¼Œä¸ºæœªæ¥æ„å»ºå¯é ä¸”åŸºäºè®¤çŸ¥çš„AIç³»ç»Ÿå¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.LO"
      ],
      "primary_category": "cs.CL",
      "comment": "23 pages, 4 figures, 8 tables. Introduces the Licensing Oracle, an architectural solution for eliminating hallucinations in language models through formal SHACL validation against knowledge graphs. All datasets and models are available at https://huggingface.co/collections/s-emanuilov/licensing-oracle-experiments",
      "pdf_url": "https://arxiv.org/pdf/2511.06073v1",
      "published_date": "2025-11-08 17:07:57 UTC",
      "updated_date": "2025-11-08 17:07:57 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:28:08.658588+00:00"
    },
    {
      "arxiv_id": "2511.06065v3",
      "title": "ScRPO: From Errors to Insights",
      "title_zh": "ScRPOï¼šä»é”™è¯¯åˆ°æ´è§",
      "authors": [
        "Lianrui Li",
        "Dakuan Lu",
        "Jiawei Shao",
        "Xuelong Li"
      ],
      "abstract": "We introduce Self-correction Relative Policy Optimization (ScRPO), a novel reinforcement learning framework designed to empower large language models with advanced mathematical reasoning capabilities through iterative self-reflection and error correction. The ScRPO framework operates in two distinct phases: (1) Trial-and-error learning stage, where the model is trained via GRPO, and incorrect responses are collected to form an \"error pool\"; and (2) Self-correction learning stage, which guides the model to introspectively analyze and rectify the reasoning flaws behind its previous errors. Extensive evaluations across challenging mathematical benchmarks, including AIME, AMC, Olympiad, MATH-500, and GSM8k, validate the efficacy of our approach. Using DeepSeek-R1-Distill-Qwen-1.5B and 7B as backbones, ScRPO achieves average accuracies of 64.8% and 77.8%, respectively. This represents a significant improvement of 6.0% and 3.2% over vanilla baselines, consistently outperforming strong post-training methods such as DAPO and GRPO. These findings establish ScRPO as a robust paradigm for enabling autonomous self-improvement in AI systems, particularly in tasks with limited external feedback.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Self-correction Relative Policy Optimization (ScRPO)ï¼Œä¸€ç§æ—¨åœ¨é€šè¿‡è¿­ä»£è‡ªçœå’Œçº é”™å¢å¼ºå¤§è¯­è¨€æ¨¡å‹æ•°å­¦æ¨ç†èƒ½åŠ›çš„æ–°å‹å¼ºåŒ–å­¦ä¹ æ¡†æ¶ã€‚ScRPOåŒ…å«ä¸¤ä¸ªå…³é”®é˜¶æ®µï¼šè¯•é”™å­¦ä¹ é˜¶æ®µé€šè¿‡GRPOè®­ç»ƒå¹¶æ”¶é›†é”™è¯¯å›ç­”å½¢æˆâ€œerror poolâ€ï¼Œè€Œè‡ªæˆ‘çº æ­£å­¦ä¹ é˜¶æ®µåˆ™å¼•å¯¼æ¨¡å‹å†…çœåˆ†æå¹¶ä¿®æ­£å…ˆå‰é”™è¯¯èƒŒåçš„æ¨ç†ç¼ºé™·ã€‚åœ¨AIMEã€AMCã€Olympiadã€MATH-500å’ŒGSM8kç­‰å…·æœ‰æŒ‘æˆ˜æ€§çš„æ•°å­¦åŸºå‡†ä¸Šçš„è¯„ä¼°éªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚åŸºäºDeepSeek-R1-Distill-Qwen-1.5Bå’Œ7Bæ¨¡å‹ï¼ŒScRPOåˆ†åˆ«å®ç°äº†64.8%å’Œ77.8%çš„å¹³å‡å‡†ç¡®ç‡ï¼Œç›¸æ¯”åŸå§‹åŸºçº¿æ˜¾è‘—æå‡äº†6.0%å’Œ3.2%ã€‚å®éªŒç»“æœè¡¨æ˜ScRPOä¼˜äºDAPOå’ŒGRPOç­‰å¼ºåè®­ç»ƒæ–¹æ³•ï¼Œç¡®ç«‹äº†å…¶ä½œä¸ºåœ¨å¤–éƒ¨åé¦ˆæœ‰é™ä»»åŠ¡ä¸­å®ç°AIç³»ç»Ÿè‡ªä¸»è‡ªæˆ‘æ”¹è¿›çš„ç¨³å¥èŒƒå¼ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06065v3",
      "published_date": "2025-11-08 16:30:44 UTC",
      "updated_date": "2026-01-05 05:19:37 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:31:37.562943+00:00"
    },
    {
      "arxiv_id": "2511.06064v1",
      "title": "A Privacy-Preserving Federated Learning Method with Homomorphic Encryption in Omics Data",
      "title_zh": "ç»„å­¦æ•°æ®ä¸­åŸºäºåŒæ€åŠ å¯†çš„éšç§ä¿æŠ¤è”é‚¦å­¦ä¹ æ–¹æ³•",
      "authors": [
        "Yusaku Negoya",
        "Feifei Cui",
        "Zilong Zhang",
        "Miao Pan",
        "Tomoaki Ohtsuki",
        "Aohan Li"
      ],
      "abstract": "Omics data is widely employed in medical research to identify disease mechanisms and contains highly sensitive personal information. Federated Learning (FL) with Differential Privacy (DP) can ensure the protection of omics data privacy against malicious user attacks. However, FL with the DP method faces an inherent trade-off: stronger privacy protection degrades predictive accuracy due to injected noise. On the other hand, Homomorphic Encryption (HE) allows computations on encrypted data and enables aggregation of encrypted gradients without DP-induced noise can increase the predictive accuracy. However, it may increase the computation cost. To improve the predictive accuracy while considering the computational ability of heterogeneous clients, we propose a Privacy-Preserving Machine Learning (PPML)-Hybrid method by introducing HE. In the proposed PPML-Hybrid method, clients distributed select either HE or DP based on their computational resources, so that HE clients contribute noise-free updates while DP clients reduce computational overhead. Meanwhile, clients with high computational resources clients can flexibly adopt HE or DP according to their privacy needs. Performance evaluation on omics datasets show that our proposed method achieves comparable predictive accuracy while significantly reducing computation time relative to HE-only. Additionally, it outperforms DP-only methods under equivalent or stricter privacy budgets.",
      "tldr_zh": "æœ¬æ–‡é’ˆå¯¹ç»„å­¦æ•°æ®(Omics Data)åœ¨åŒ»å­¦ç ”ç©¶ä¸­çš„éšç§ä¿æŠ¤éœ€æ±‚ï¼Œæå‡ºäº†ä¸€ç§åä¸ºPPML-Hybridçš„éšç§ä¿æŠ¤æœºå™¨å­¦ä¹ æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³è”é‚¦å­¦ä¹ (Federated Learning, FL)ä¸­å·®åˆ†éšç§(Differential Privacy, DP)å¯¼è‡´çš„ç²¾åº¦ä¸‹é™ä¸åŒæ€åŠ å¯†(Homomorphic Encryption, HE)å¸¦æ¥çš„é«˜è®¡ç®—æˆæœ¬ä¹‹é—´çš„çŸ›ç›¾ã€‚è¯¥æ–¹æ³•å…è®¸åˆ†å¸ƒå¼å®¢æˆ·ç«¯æ ¹æ®è‡ªèº«çš„è®¡ç®—èµ„æºå’Œéšç§éœ€æ±‚çµæ´»é€‰æ‹©åŠ å¯†ç­–ç•¥ï¼šè®¡ç®—èƒ½åŠ›å¼ºçš„å®¢æˆ·ç«¯é‡‡ç”¨HEè¿›è¡Œæ— å™ªå£°æ¢¯åº¦èšåˆä»¥æé«˜ç²¾åº¦ï¼Œè€Œèµ„æºå—é™çš„å®¢æˆ·ç«¯åˆ™é‡‡ç”¨DPä»¥é™ä½è®¡ç®—å¼€é”€ã€‚é€šè¿‡è¿™ç§æ··åˆæœºåˆ¶ï¼ŒPPML-Hybridåœ¨å¼‚æ„å®¢æˆ·ç«¯ç¯å¢ƒä¸­å®ç°äº†æ¨¡å‹æ€§èƒ½ä¸è®¡ç®—æ•ˆç‡çš„å¹³è¡¡ã€‚åœ¨ç»„å­¦æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¿æŒä¸å…¨HEæ–¹æ³•ç›¸å½“é¢„æµ‹ç²¾åº¦çš„åŒæ—¶æ˜¾è‘—ç¼©çŸ­äº†è®¡ç®—æ—¶é—´ï¼Œå¹¶ä¸”åœ¨ç›¸åŒæˆ–æ›´ä¸¥æ ¼çš„éšç§é¢„ç®—ä¸‹ï¼Œå…¶æ€§èƒ½ä¼˜äºä»…ä½¿ç”¨DPçš„æ–¹æ³•ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "6 pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2511.06064v1",
      "published_date": "2025-11-08 16:18:42 UTC",
      "updated_date": "2025-11-08 16:18:42 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:31:43.887709+00:00"
    },
    {
      "arxiv_id": "2511.06044v1",
      "title": "How Particle-System Random Batch Methods Enhance Graph Transformer: Memory Efficiency and Parallel Computing Strategy",
      "title_zh": "ç²’å­ç³»ç»Ÿéšæœºæ‰¹å¤„ç†æ–¹æ³•å¢å¼ºå›¾ Transformerï¼šå†…å­˜æ•ˆç‡ä¸å¹¶è¡Œè®¡ç®—ç­–ç•¥",
      "authors": [
        "Hanwen Liu",
        "Yixuan Ma",
        "Shi Jin",
        "Yuguang Wang"
      ],
      "abstract": "Attention mechanism is a significant part of Transformer models. It helps extract features from embedded vectors by adding global information and its expressivity has been proved to be powerful. Nevertheless, the quadratic complexity restricts its practicability. Although several researches have provided attention mechanism in sparse form, they are lack of theoretical analysis about the expressivity of their mechanism while reducing complexity. In this paper, we put forward Random Batch Attention (RBA), a linear self-attention mechanism, which has theoretical support of the ability to maintain its expressivity. Random Batch Attention has several significant strengths as follows: (1) Random Batch Attention has linear time complexity. Other than this, it can be implemented in parallel on a new dimension, which contributes to much memory saving. (2) Random Batch Attention mechanism can improve most of the existing models by replacing their attention mechanisms, even many previously improved attention mechanisms. (3) Random Batch Attention mechanism has theoretical explanation in convergence, as it comes from Random Batch Methods on computation mathematics. Experiments on large graphs have proved advantages mentioned above. Also, the theoretical modeling of self-attention mechanism is a new tool for future research on attention-mechanism analysis.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹Transformeræ¨¡å‹ä¸­æ³¨æ„åŠ›æœºåˆ¶é¢ä¸´çš„äºŒæ¬¡å¤æ‚åº¦é™åˆ¶åŠç°æœ‰ç¨€ç–æ–¹æ³•ç¼ºä¹ç†è®ºæ”¯æ’‘çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºRandom Batch Attention (RBA)çš„çº¿æ€§è‡ªæ³¨æ„åŠ›æœºåˆ¶ã€‚RBAæºäºè®¡ç®—æ•°å­¦ä¸­çš„ç²’å­ç³»ç»ŸRandom Batch Methodsï¼Œåœ¨å¤§å¹…é™ä½è®¡ç®—å¤æ‚åº¦çš„åŒæ—¶æä¾›äº†ä¿æŒè¡¨è¾¾èƒ½åŠ›å’Œæ”¶æ•›æ€§çš„ç†è®ºè¯æ˜ã€‚è¯¥æœºåˆ¶å…·æœ‰çº¿æ€§æ—¶é—´å¤æ‚åº¦ï¼Œå¹¶æ”¯æŒåœ¨æ–°ç»´åº¦ä¸Šçš„å¹¶è¡Œè®¡ç®—ï¼Œä»è€Œæ˜¾è‘—æé«˜äº†å†…å­˜æ•ˆç‡ã€‚æ­¤å¤–ï¼ŒRBAä½œä¸ºä¸€ç§é€šç”¨ç»„ä»¶ï¼Œèƒ½å¤Ÿæ›¿æ¢å¹¶æå‡å¤§å¤šæ•°ç°æœ‰æ¨¡å‹ä¸­çš„æ³¨æ„åŠ›æœºåˆ¶ã€‚åœ¨å¤§è§„æ¨¡å›¾æ•°æ®ä¸Šçš„å®éªŒéªŒè¯äº†RBAåœ¨å†…å­˜æ•ˆç‡å’Œå¹¶è¡Œè®¡ç®—ç­–ç•¥æ–¹é¢çš„ä¼˜åŠ¿ï¼ŒåŒæ—¶å…¶å»ºç«‹çš„ç†è®ºæ¨¡å‹ä¸ºæœªæ¥æ³¨æ„åŠ›æœºåˆ¶çš„åˆ†ææä¾›äº†æ–°çš„å·¥å…·ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.ST"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06044v1",
      "published_date": "2025-11-08 15:34:15 UTC",
      "updated_date": "2025-11-08 15:34:15 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:32:06.197989+00:00"
    },
    {
      "arxiv_id": "2511.06041v1",
      "title": "Advancing Ocean State Estimation with efficient and scalable AI",
      "title_zh": "åˆ©ç”¨é«˜æ•ˆå¯æ‰©å±•çš„äººå·¥æ™ºèƒ½æ¨è¿›æµ·æ´‹çŠ¶æ€ä¼°è®¡",
      "authors": [
        "Yanfei Xiang",
        "Yuan Gao",
        "Hao Wu",
        "Quan Zhang",
        "Ruiqi Shu",
        "Xiao Zhou",
        "Xi Wu",
        "Xiaomeng Huang"
      ],
      "abstract": "Accurate and efficient global ocean state estimation remains a grand challenge for Earth system science, hindered by the dual bottlenecks of computational scalability and degraded data fidelity in traditional data assimilation (DA) and deep learning (DL) approaches. Here we present an AI-driven Data Assimilation Framework for Ocean (ADAF-Ocean) that directly assimilates multi-source and multi-scale observations, ranging from sparse in-situ measurements to 4 km satellite swaths, without any interpolation or data thinning. Inspired by Neural Processes, ADAF-Ocean learns a continuous mapping from heterogeneous inputs to ocean states, preserving native data fidelity. Through AI-driven super-resolution, it reconstructs 0.25$^\\circ$ mesoscale dynamics from coarse 1$^\\circ$ fields, which ensures both efficiency and scalability, with just 3.7\\% more parameters than the 1$^\\circ$ configuration. When coupled with a DL forecasting system, ADAF-Ocean extends global forecast skill by up to 20 days compared to baselines without assimilation. This framework establishes a computationally viable and scientifically rigorous pathway toward real-time, high-resolution Earth system monitoring.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ADAF-Oceanï¼Œä¸€ç§AIé©±åŠ¨çš„æµ·æ´‹æ•°æ®åŒåŒ–æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿæ•°æ®åŒåŒ–(DA)å’Œæ·±åº¦å­¦ä¹ (DL)æ–¹æ³•åœ¨è®¡ç®—æ‰©å±•æ€§å’Œæ•°æ®ä¿çœŸåº¦æ–¹é¢çš„ç“¶é¢ˆã€‚å—Neural Processeså¯å‘ï¼ŒADAF-Oceanèƒ½å¤Ÿç›´æ¥åŒåŒ–ä»ç¨€ç–çš„in-situæµ‹é‡åˆ°4å…¬é‡Œå«æ˜Ÿæ‰«æå¸¦çš„å¤šæºå¤šå°ºåº¦è§‚æµ‹æ•°æ®ï¼Œæ— éœ€è¿›è¡Œæ’å€¼æˆ–æ•°æ®ç¨€ç–åŒ–ï¼Œä»è€Œå­¦ä¹ ä»å¼‚æ„è¾“å…¥åˆ°æµ·æ´‹çŠ¶æ€çš„è¿ç»­æ˜ å°„ã€‚é€šè¿‡AIé©±åŠ¨çš„è¶…åˆ†è¾¨ç‡æŠ€æœ¯ï¼Œè¯¥æ¡†æ¶èƒ½ä»ç²—ç³™çš„1Â°åœºé‡å»º0.25Â°çš„ä¸­å°ºåº¦åŠ¨åŠ›å­¦ï¼Œä¸”å‚æ•°é‡ä»…æ¯”1Â°é…ç½®å¢åŠ 3.7%ï¼Œå…¼é¡¾äº†æ•ˆç‡ä¸å¯æ‰©å±•æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå½“ä¸DLé¢„æŠ¥ç³»ç»Ÿç»“åˆæ—¶ï¼ŒADAF-Oceanå°†å…¨çƒé¢„æŠ¥æŠ€èƒ½ç›¸æ¯”æ— åŒåŒ–çš„åŸºçº¿å»¶é•¿äº†é•¿è¾¾20å¤©ã€‚è¯¥æ¡†æ¶ä¸ºå®æ—¶ã€é«˜åˆ†è¾¨ç‡çš„åœ°çƒç³»ç»Ÿç›‘æµ‹å»ºç«‹äº†ä¸€æ¡è®¡ç®—å¯è¡Œä¸”ç§‘å­¦ä¸¥è°¨çš„é€”å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "29 papes, 10 Figures",
      "pdf_url": "https://arxiv.org/pdf/2511.06041v1",
      "published_date": "2025-11-08 15:24:23 UTC",
      "updated_date": "2025-11-08 15:24:23 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:32:32.645973+00:00"
    },
    {
      "arxiv_id": "2511.06033v1",
      "title": "S2ML: Spatio-Spectral Mutual Learning for Depth Completion",
      "title_zh": "S2MLï¼šé¢å‘æ·±åº¦è¡¥å…¨çš„ç©ºè°±äº’å­¦ä¹ ",
      "authors": [
        "Zihui Zhao",
        "Yifei Zhang",
        "Zheng Wang",
        "Yang Li",
        "Kui Jiang",
        "Zihan Geng",
        "Chia-Wen Lin"
      ],
      "abstract": "The raw depth images captured by RGB-D cameras using Time-of-Flight (TOF) or structured light often suffer from incomplete depth values due to weak reflections, boundary shadows, and artifacts, which limit their applications in downstream vision tasks. Existing methods address this problem through depth completion in the image domain, but they overlook the physical characteristics of raw depth images. It has been observed that the presence of invalid depth areas alters the frequency distribution pattern. In this work, we propose a Spatio-Spectral Mutual Learning framework (S2ML) to harmonize the advantages of both spatial and frequency domains for depth completion. Specifically, we consider the distinct properties of amplitude and phase spectra and devise a dedicated spectral fusion module. Meanwhile, the local and global correlations between spatial-domain and frequency-domain features are calculated in a unified embedding space. The gradual mutual representation and refinement encourage the network to fully explore complementary physical characteristics and priors for more accurate depth completion. Extensive experiments demonstrate the effectiveness of our proposed S2ML method, outperforming the state-of-the-art method CFormer by 0.828 dB and 0.834 dB on the NYU-Depth V2 and SUN RGB-D datasets, respectively.",
      "tldr_zh": "é’ˆå¯¹RGB-Dç›¸æœºï¼ˆå¦‚TOFæˆ–ç»“æ„å…‰ï¼‰è·å–çš„åŸå§‹æ·±åº¦å›¾åƒå¸¸å› å¼±åå°„æˆ–è¾¹ç•Œé˜´å½±å¯¼è‡´æ·±åº¦å€¼ç¼ºå¤±çš„é—®é¢˜ï¼Œè¯¥ç ”ç©¶æŒ‡å‡ºæ— æ•ˆæ·±åº¦åŒºåŸŸä¼šæ”¹å˜é¢‘ç‡åˆ†å¸ƒæ¨¡å¼ï¼Œå¹¶æå‡ºäº†S2MLï¼ˆSpatio-Spectral Mutual Learningï¼‰æ¡†æ¶ï¼Œæ—¨åœ¨èåˆç©ºé—´åŸŸå’Œé¢‘ç‡åŸŸçš„ä¼˜åŠ¿ä»¥å®ç°æ›´ç²¾ç¡®çš„æ·±åº¦è¡¥å…¨ã€‚è¯¥æ–¹æ³•è€ƒè™‘åˆ°å¹…åº¦è°±å’Œç›¸ä½è°±çš„ç‹¬ç‰¹æ€§è´¨ï¼Œè®¾è®¡äº†ä¸“ç”¨çš„é¢‘è°±èåˆæ¨¡å—ï¼Œå¹¶åœ¨ç»Ÿä¸€çš„åµŒå…¥ç©ºé—´ä¸­è®¡ç®—ç©ºé—´åŸŸä¸é¢‘ç‡åŸŸç‰¹å¾çš„å±€éƒ¨åŠå…¨å±€ç›¸å…³æ€§ã€‚é€šè¿‡æ¸è¿›å¼çš„ç›¸äº’è¡¨ç¤ºä¸ç»†åŒ–ï¼ŒS2MLä¿ƒä½¿ç½‘ç»œå……åˆ†æŒ–æ˜äº’è¡¥çš„ç‰©ç†ç‰¹æ€§å’Œå…ˆéªŒä¿¡æ¯ã€‚å¤§é‡å®éªŒè¯æ˜äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œåœ¨NYU-Depth V2å’ŒSUN RGB-Dæ•°æ®é›†ä¸Šï¼Œå…¶æ€§èƒ½åˆ†åˆ«æ¯”æœ€å…ˆè¿›çš„CFormeræ–¹æ³•æå‡äº†0.828 dBå’Œ0.834 dBã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06033v1",
      "published_date": "2025-11-08 15:01:55 UTC",
      "updated_date": "2025-11-08 15:01:55 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:32:56.421190+00:00"
    },
    {
      "arxiv_id": "2511.06032v1",
      "title": "ITPP: Learning Disentangled Event Dynamics in Marked Temporal Point Processes",
      "title_zh": "ITPPï¼šå­¦ä¹ æ ‡è®°æ—¶é—´ç‚¹è¿‡ç¨‹ä¸­çš„è§£è€¦äº‹ä»¶åŠ¨åŠ›å­¦",
      "authors": [
        "Wang-Tao Zhou",
        "Zhao Kang",
        "Ke Yan",
        "Ling Tian"
      ],
      "abstract": "Marked Temporal Point Processes (MTPPs) provide a principled framework for modeling asynchronous event sequences by conditioning on the history of past events. However, most existing MTPP models rely on channel-mixing strategies that encode information from different event types into a single, fixed-size latent representation. This entanglement can obscure type-specific dynamics, leading to performance degradation and increased risk of overfitting. In this work, we introduce ITPP, a novel channel-independent architecture for MTPP modeling that decouples event type information using an encoder-decoder framework with an ODE-based backbone. Central to ITPP is a type-aware inverted self-attention mechanism, designed to explicitly model inter-channel correlations among heterogeneous event types. This architecture enhances effectiveness and robustness while reducing overfitting. Comprehensive experiments on multiple real-world and synthetic datasets demonstrate that ITPP consistently outperforms state-of-the-art MTPP models in both predictive accuracy and generalization.",
      "tldr_zh": "ç°æœ‰çš„æ ‡è®°æ—¶é—´ç‚¹è¿‡ç¨‹(Marked Temporal Point Processes, MTPPs)å¤§å¤šä¾èµ–é€šé“æ··åˆç­–ç•¥ï¼Œå°†ä¸åŒäº‹ä»¶ç±»å‹çš„ä¿¡æ¯ç¼–ç ä¸ºå•ä¸€çš„æ½œåœ¨è¡¨ç¤ºï¼Œå¯¼è‡´ç±»å‹ç‰¹å®šçš„åŠ¨æ€è¢«æ©ç›–å¹¶å¢åŠ äº†è¿‡æ‹Ÿåˆé£é™©ã€‚é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œè¯¥ç ”ç©¶æå‡ºäº†ITPPï¼Œä¸€ç§åŸºäºç¼–ç å™¨-è§£ç å™¨æ¡†æ¶å’Œå¸¸å¾®åˆ†æ–¹ç¨‹(ODE)éª¨å¹²ç½‘ç»œçš„å…¨æ–°é€šé“ç‹¬ç«‹æ¶æ„ã€‚ITPPçš„æ ¸å¿ƒåœ¨äºä¸€ç§ç±»å‹æ„ŸçŸ¥çš„åå‘è‡ªæ³¨æ„åŠ›æœºåˆ¶(type-aware inverted self-attention)ï¼Œæ—¨åœ¨æ˜¾å¼åœ°å»ºæ¨¡å¼‚æ„äº‹ä»¶ç±»å‹ä¹‹é—´çš„é€šé“é—´ç›¸å…³æ€§ï¼Œä»è€Œå®ç°äº‹ä»¶ç±»å‹ä¿¡æ¯çš„è§£è€¦ã€‚è¿™ç§æ¶æ„ä¸ä»…å¢å¼ºäº†æ¨¡å‹çš„æœ‰æ•ˆæ€§å’Œé²æ£’æ€§ï¼Œè¿˜æœ‰æ•ˆé™ä½äº†è¿‡æ‹Ÿåˆç°è±¡ã€‚åœ¨å¤šä¸ªçœŸå®ä¸–ç•Œå’Œåˆæˆæ•°æ®é›†ä¸Šçš„ç»¼åˆå®éªŒè¡¨æ˜ï¼ŒITPPåœ¨é¢„æµ‹å‡†ç¡®æ€§å’Œæ³›åŒ–èƒ½åŠ›æ–¹é¢å‡æŒç»­ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›MTPPæ¨¡å‹ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to AAAI'26 Poster",
      "pdf_url": "https://arxiv.org/pdf/2511.06032v1",
      "published_date": "2025-11-08 15:00:25 UTC",
      "updated_date": "2025-11-08 15:00:25 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:33:56.321638+00:00"
    },
    {
      "arxiv_id": "2601.05266v1",
      "title": "Retrieval-Augmented Multi-LLM Ensemble for Industrial Part Specification Extraction",
      "title_zh": "é¢å‘å·¥ä¸šé›¶ä»¶è§„æ ¼æå–çš„æ£€ç´¢å¢å¼ºå¤šå¤§è¯­è¨€æ¨¡å‹é›†æˆ",
      "authors": [
        "Muzakkiruddin Ahmed Mohammed",
        "John R. Talburt",
        "Leon Claasssens",
        "Adriaan Marais"
      ],
      "abstract": "Industrial part specification extraction from unstructured text remains a persistent challenge in manufacturing, procurement, and maintenance, where manual processing is both time-consuming and error-prone. This paper introduces a retrieval-augmented multi-LLM ensemble framework that orchestrates nine state-of-the-art Large Language Models (LLMs) within a structured three-phase pipeline. RAGsemble addresses key limitations of single-model systems by combining the complementary strengths of model families including Gemini (2.0, 2.5, 1.5), OpenAI (GPT-4o, o4-mini), Mistral Large, and Gemma (1B, 4B, 3n-e4b), while grounding outputs in factual data using FAISS-based semantic retrieval. The system architecture consists of three stages: (1) parallel extraction by diverse LLMs, (2) targeted research augmentation leveraging high-performing models, and (3) intelligent synthesis with conflict resolution and confidence-aware scoring. RAG integration provides real-time access to structured part databases, enabling the system to validate, refine, and enrich outputs through similarity-based reference retrieval. Experimental results using real industrial datasets demonstrate significant gains in extraction accuracy, technical completeness, and structured output quality compared to leading single-LLM baselines. Key contributions include a scalable ensemble architecture for industrial domains, seamless RAG integration throughout the pipeline, comprehensive quality assessment mechanisms, and a production-ready solution suitable for deployment in knowledge-intensive manufacturing environments.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä»éç»“æ„åŒ–æ–‡æœ¬ä¸­æå–å·¥ä¸šé›¶ä»¶è§„æ ¼çš„éš¾é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ£€ç´¢å¢å¼ºçš„å¤šå¤§è¯­è¨€æ¨¡å‹é›†æˆæ¡†æ¶ï¼ˆRAGsembleï¼‰ã€‚è¯¥æ¡†æ¶ååŒäº†åŒ…æ‹¬Geminiã€OpenAIã€Mistralå’ŒGemmaç³»åˆ—åœ¨å†…çš„ä¹ä¸ªæœ€å…ˆè¿›çš„Large Language Models (LLMs)ï¼Œé€šè¿‡ç»“æ„åŒ–çš„ä¸‰é˜¶æ®µæµæ°´çº¿æ¥è§£å†³å•ä¸€æ¨¡å‹ç³»ç»Ÿçš„å±€é™æ€§ã€‚è¿™ä¸‰ä¸ªé˜¶æ®µåŒ…æ‹¬å¤šæ ·åŒ–LLMçš„å¹¶è¡Œæå–ã€åˆ©ç”¨é«˜æ€§èƒ½æ¨¡å‹çš„é’ˆå¯¹æ€§ç ”ç©¶å¢å¼ºï¼Œä»¥åŠåŒ…å«å†²çªè§£å†³å’Œç½®ä¿¡åº¦è¯„åˆ†çš„æ™ºèƒ½åˆæˆã€‚ç³»ç»Ÿç»“åˆäº†åŸºäºFAISSçš„è¯­ä¹‰æ£€ç´¢ï¼ˆRAGï¼‰æŠ€æœ¯ï¼Œé€šè¿‡å®æ—¶è®¿é—®ç»“æ„åŒ–é›¶ä»¶æ•°æ®åº“æ¥éªŒè¯ã€ç»†åŒ–å’Œä¸°å¯Œè¾“å‡ºï¼Œç¡®ä¿ç»“æœåŸºäºäº‹å®æ•°æ®ã€‚åœ¨çœŸå®å·¥ä¸šæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æå–å‡†ç¡®æ€§ã€æŠ€æœ¯å®Œæ•´æ€§å’Œç»“æ„åŒ–è¾“å‡ºè´¨é‡æ–¹é¢å‡æ˜¾è‘—ä¼˜äºé¢†å…ˆçš„å•ä¸€LLMåŸºçº¿æ¨¡å‹ã€‚è¯¥ç ”ç©¶ä¸ä»…æä¾›äº†ä¸€ç§é€‚ç”¨äºå·¥ä¸šé¢†åŸŸçš„å¯æ‰©å±•é›†æˆæ¶æ„ï¼Œè¿˜é€šè¿‡æ— ç¼çš„RAGé›†æˆå’Œè´¨é‡è¯„ä¼°æœºåˆ¶ï¼Œä¸ºçŸ¥è¯†å¯†é›†å‹åˆ¶é€ ç¯å¢ƒæä¾›äº†ä¸€ä¸ªç”Ÿäº§çº§çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "The 17th International Conference on Knowledge and Systems Engineering",
      "pdf_url": "https://arxiv.org/pdf/2601.05266v1",
      "published_date": "2025-11-08 14:43:20 UTC",
      "updated_date": "2025-11-08 14:43:20 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:34:22.588947+00:00"
    },
    {
      "arxiv_id": "2511.06019v1",
      "title": "MiVID: Multi-Strategic Self-Supervision for Video Frame Interpolation using Diffusion Model",
      "title_zh": "MiVIDï¼šåŸºäºæ‰©æ•£æ¨¡å‹çš„è§†é¢‘æ’å¸§å¤šç­–ç•¥è‡ªç›‘ç£",
      "authors": [
        "Priyansh Srivastava",
        "Romit Chatterjee",
        "Abir Sen",
        "Aradhana Behura",
        "Ratnakar Dash"
      ],
      "abstract": "Video Frame Interpolation (VFI) remains a cornerstone in video enhancement, enabling temporal upscaling for tasks like slow-motion rendering, frame rate conversion, and video restoration. While classical methods rely on optical flow and learning-based models assume access to dense ground-truth, both struggle with occlusions, domain shifts, and ambiguous motion. This article introduces MiVID, a lightweight, self-supervised, diffusion-based framework for video interpolation. Our model eliminates the need for explicit motion estimation by combining a 3D U-Net backbone with transformer-style temporal attention, trained under a hybrid masking regime that simulates occlusions and motion uncertainty. The use of cosine-based progressive masking and adaptive loss scheduling allows our network to learn robust spatiotemporal representations without any high-frame-rate supervision. Our framework is evaluated on UCF101-7 and DAVIS-7 datasets. MiVID is trained entirely on CPU using the datasets and 9-frame video segments, making it a low-resource yet highly effective pipeline. Despite these constraints, our model achieves optimal results at just 50 epochs, competitive with several supervised baselines.This work demonstrates the power of self-supervised diffusion priors for temporally coherent frame synthesis and provides a scalable path toward accessible and generalizable VFI systems.",
      "tldr_zh": "æœ¬æ–‡ä»‹ç»äº†MiVIDï¼Œä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹(Diffusion Model)çš„è½»é‡çº§è‡ªç›‘ç£è§†é¢‘æ’å¸§(Video Frame Interpolation, VFI)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿæ–¹æ³•åœ¨é®æŒ¡ã€åŸŸåç§»å’Œæ¨¡ç³Šè¿åŠ¨å¤„ç†ä¸Šçš„å±€é™æ€§ã€‚MiVIDé€šè¿‡ç»“åˆ3D U-Netéª¨å¹²ç½‘ç»œä¸Transformeré£æ ¼çš„æ—¶é—´æ³¨æ„åŠ›æœºåˆ¶ï¼Œæ¶ˆé™¤äº†å¯¹æ˜¾å¼è¿åŠ¨ä¼°è®¡çš„éœ€æ±‚ã€‚è¯¥æ¨¡å‹é‡‡ç”¨æ¨¡æ‹Ÿé®æŒ¡å’Œè¿åŠ¨ä¸ç¡®å®šæ€§çš„æ··åˆæ©ç æœºåˆ¶(hybrid masking regime)ï¼Œé…åˆåŸºäºä½™å¼¦çš„æ¸è¿›å¼æ©ç å’Œè‡ªé€‚åº”æŸå¤±è°ƒåº¦ï¼Œèƒ½å¤Ÿåœ¨æ— é«˜å¸§ç‡ç›‘ç£çš„æƒ…å†µä¸‹å­¦ä¹ é²æ£’çš„æ—¶ç©ºè¡¨ç¤ºã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒMiVIDæ˜¯ä¸€ä¸ªä½èµ„æºæ¶ˆè€—çš„é«˜æ•ˆæµç¨‹ï¼Œä»…ä½¿ç”¨CPUå’Œ9å¸§è§†é¢‘ç‰‡æ®µå³å¯å®Œæˆè®­ç»ƒã€‚åœ¨UCF101-7å’ŒDAVIS-7æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨50ä¸ªepochæ—¶å³å¯è¾¾åˆ°æœ€ä½³æ•ˆæœï¼Œå…¶æ€§èƒ½ä¸å¤šç§ç›‘ç£åŸºçº¿æ¨¡å‹ç›¸å½“ï¼Œè¯æ˜äº†è‡ªç›‘ç£æ‰©æ•£å…ˆéªŒåœ¨æ—¶åºè¿è´¯å¸§åˆæˆä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06019v1",
      "published_date": "2025-11-08 14:10:04 UTC",
      "updated_date": "2025-11-08 14:10:04 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:34:47.434362+00:00"
    },
    {
      "arxiv_id": "2511.06016v1",
      "title": "One-Shot Knowledge Transfer for Scalable Person Re-Identification",
      "title_zh": "é¢å‘å¯æ‰©å±•è¡Œäººé‡è¯†åˆ«çš„å•æ¬¡çŸ¥è¯†è¿ç§»",
      "authors": [
        "Longhua Li",
        "Lei Qi",
        "Xin Geng"
      ],
      "abstract": "Edge computing in person re-identification (ReID) is crucial for reducing the load on central cloud servers and ensuring user privacy. Conventional compression methods for obtaining compact models require computations for each individual student model. When multiple models of varying sizes are needed to accommodate different resource conditions, this leads to repetitive and cumbersome computations. To address this challenge, we propose a novel knowledge inheritance approach named OSKT (One-Shot Knowledge Transfer), which consolidates the knowledge of the teacher model into an intermediate carrier called a weight chain. When a downstream scenario demands a model that meets specific resource constraints, this weight chain can be expanded to the target model size without additional computation. OSKT significantly outperforms state-of-the-art compression methods, with the added advantage of one-time knowledge transfer that eliminates the need for frequent computations for each target model.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è¡Œäººé‡è¯†åˆ«(Person Re-Identification, ReID)è¾¹ç¼˜è®¡ç®—åœºæ™¯ä¸­ä¼ ç»Ÿæ¨¡å‹å‹ç¼©æ–¹æ³•éœ€é‡å¤è®¡ç®—çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºOSKT (One-Shot Knowledge Transfer)çš„æ–°å‹çŸ¥è¯†ç»§æ‰¿æ–¹æ³•ã€‚ä¼ ç»Ÿå‹ç¼©æ–¹æ³•åœ¨ç”Ÿæˆä¸åŒå¤§å°çš„æ¨¡å‹ä»¥é€‚åº”ä¸åŒèµ„æºæ¡ä»¶æ—¶ï¼Œå¾€å¾€éœ€è¦ç¹ççš„é‡å¤è®¡ç®—ã€‚OSKTé€šè¿‡å°†æ•™å¸ˆæ¨¡å‹çš„çŸ¥è¯†æ•´åˆåˆ°ä¸€ä¸ªç§°ä¸ºæƒé‡é“¾(weight chain)çš„ä¸­é—´è½½ä½“ä¸­æ¥è§£å†³è¿™ä¸€æŒ‘æˆ˜ã€‚å½“ä¸‹æ¸¸åœºæ™¯éœ€è¦æ»¡è¶³ç‰¹å®šèµ„æºçº¦æŸçš„æ¨¡å‹æ—¶ï¼Œè¯¥æƒé‡é“¾å¯ç›´æ¥æ‰©å±•è‡³ç›®æ ‡æ¨¡å‹å¤§å°ï¼Œè€Œæ— éœ€è¿›è¡Œé¢å¤–è®¡ç®—ã€‚å®éªŒè¡¨æ˜ï¼ŒOSKTä¸ä»…åœ¨æ€§èƒ½ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›å‹ç¼©æ–¹æ³•ï¼Œè¿˜å…·å¤‡ä¸€æ¬¡æ€§çŸ¥è¯†è½¬ç§»çš„ä¼˜åŠ¿ï¼Œæœ‰æ•ˆæ¶ˆé™¤äº†é’ˆå¯¹æ¯ä¸ªç›®æ ‡æ¨¡å‹çš„é¢‘ç¹è®¡ç®—éœ€æ±‚ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ICCV 2025",
      "pdf_url": "https://arxiv.org/pdf/2511.06016v1",
      "published_date": "2025-11-08 14:06:23 UTC",
      "updated_date": "2025-11-08 14:06:23 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:35:08.791625+00:00"
    },
    {
      "arxiv_id": "2511.06010v1",
      "title": "MoSKA: Mixture of Shared KV Attention for Efficient Long-Sequence LLM Inference",
      "title_zh": "MoSKAï¼šé¢å‘é«˜æ•ˆé•¿åºåˆ— LLM æ¨ç†çš„å…±äº« KV æ³¨æ„åŠ›æ··åˆ",
      "authors": [
        "Myunghyun Rhee",
        "Sookyung Choi",
        "Euiseok Kim",
        "Joonseop Sim",
        "Youngpyo Joo",
        "Hoshik Kim"
      ],
      "abstract": "The escalating context length in Large Language Models (LLMs) creates a severe performance bottleneck around the Key-Value (KV) cache, whose memory-bound nature leads to significant GPU under-utilization. This paper introduces Mixture of Shared KV Attention (MoSKA), an architecture that addresses this challenge by exploiting the heterogeneity of context data. It differentiates between per-request unique and massively reused shared sequences. The core of MoSKA is a novel Shared KV Attention mechanism that transforms the attention on shared data from a series of memory-bound GEMV operations into a single, compute-bound GEMM by batching concurrent requests. This is supported by an MoE-inspired sparse attention strategy that prunes the search space and a tailored Disaggregated Infrastructure that specializes hardware for unique and shared data. This comprehensive approach demonstrates a throughput increase of up to 538.7x over baselines in workloads with high context sharing, offering a clear architectural path toward scalable LLM inference.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹Large Language Models (LLMs)åœ¨é•¿ä¸Šä¸‹æ–‡æ¨ç†ä¸­é¢ä¸´çš„Key-Value (KV) cacheå†…å­˜ç“¶é¢ˆé—®é¢˜ï¼Œæå‡ºäº†MoSKA (Mixture of Shared KV Attention) æ¶æ„ã€‚è¯¥æ¶æ„åˆ©ç”¨ä¸Šä¸‹æ–‡æ•°æ®çš„å¼‚æ„æ€§ï¼Œæœ‰æ•ˆåŒºåˆ†äº†æ¯ä¸ªè¯·æ±‚ç‹¬æœ‰çš„åºåˆ—å’Œå¤§é‡å¤ç”¨çš„å…±äº«åºåˆ—ã€‚MoSKAçš„æ ¸å¿ƒåœ¨äºä¸€ç§æ–°é¢–çš„Shared KV Attentionæœºåˆ¶ï¼Œé€šè¿‡æ‰¹é‡å¤„ç†å¹¶å‘è¯·æ±‚ï¼Œå°†é’ˆå¯¹å…±äº«æ•°æ®çš„æ³¨æ„åŠ›è®¡ç®—ä»ä¸€ç³»åˆ—å—é™äºå†…å­˜å¸¦å®½çš„GEMVæ“ä½œè½¬åŒ–ä¸ºå—é™äºè®¡ç®—èƒ½åŠ›çš„GEMMæ“ä½œã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜ç»“åˆäº†å—MoEå¯å‘çš„ç¨€ç–æ³¨æ„åŠ›ç­–ç•¥ä»¥ä¿®å‰ªæœç´¢ç©ºé—´ï¼Œå¹¶é‡‡ç”¨äº†å®šåˆ¶çš„Disaggregated Infrastructureæ¥ä¸“é—¨å¤„ç†ä¸åŒç±»å‹çš„æ•°æ®ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨å…·æœ‰é«˜ä¸Šä¸‹æ–‡å…±äº«çš„å·¥ä½œè´Ÿè½½ä¸­ï¼ŒMoSKAçš„ååé‡æ¯”åŸºçº¿æé«˜äº†é«˜è¾¾538.7å€ï¼Œä¸ºå¯æ‰©å±•çš„LLMæ¨ç†æä¾›äº†ä¸€æ¡æ¸…æ™°çš„æ¶æ„è·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "4 pages, 5 figures, accepted for publication at IEEE Computer Architecture Letters (IEEE CAL), 2025",
      "pdf_url": "https://arxiv.org/pdf/2511.06010v1",
      "published_date": "2025-11-08 13:40:16 UTC",
      "updated_date": "2025-11-08 13:40:16 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:35:41.143649+00:00"
    },
    {
      "arxiv_id": "2511.05996v1",
      "title": "Exploring Category-level Articulated Object Pose Tracking on SE(3) Manifolds",
      "title_zh": "æ¢ç´¢ SE(3) æµå½¢ä¸Šçš„ç±»åˆ«çº§é“°æ¥ç‰©ä½“å§¿æ€è·Ÿè¸ª",
      "authors": [
        "Xianhui Meng",
        "Yukang Huo",
        "Li Zhang",
        "Liu Liu",
        "Haonan Jiang",
        "Yan Zhong",
        "Pingrui Zhang",
        "Cewu Lu",
        "Jun Liu"
      ],
      "abstract": "Articulated objects are prevalent in daily life and robotic manipulation tasks. However, compared to rigid objects, pose tracking for articulated objects remains an underexplored problem due to their inherent kinematic constraints. To address these challenges, this work proposes a novel point-pair-based pose tracking framework, termed \\textbf{PPF-Tracker}. The proposed framework first performs quasi-canonicalization of point clouds in the SE(3) Lie group space, and then models articulated objects using Point Pair Features (PPF) to predict pose voting parameters by leveraging the invariance properties of SE(3). Finally, semantic information of joint axes is incorporated to impose unified kinematic constraints across all parts of the articulated object. PPF-Tracker is systematically evaluated on both synthetic datasets and real-world scenarios, demonstrating strong generalization across diverse and challenging environments. Experimental results highlight the effectiveness and robustness of PPF-Tracker in multi-frame pose tracking of articulated objects. We believe this work can foster advances in robotics, embodied intelligence, and augmented reality. Codes are available at https://github.com/mengxh20/PPFTracker.",
      "tldr_zh": "è¿™é¡¹å·¥ä½œé’ˆå¯¹å…³èŠ‚ç‰©ä½“ç”±äºå›ºæœ‰è¿åŠ¨å­¦çº¦æŸè€Œéš¾ä»¥è¿›è¡Œå§¿æ€è·Ÿè¸ªçš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºPPF-Trackerçš„æ–°å‹åŸºäºç‚¹å¯¹çš„å§¿æ€è·Ÿè¸ªæ¡†æ¶ã€‚è¯¥æ¡†æ¶é¦–å…ˆåœ¨SE(3)æç¾¤ç©ºé—´ä¸­å¯¹ç‚¹äº‘è¿›è¡Œå‡†è§„èŒƒåŒ–å¤„ç†ï¼Œéšååˆ©ç”¨SE(3)çš„ä¸å˜æ€§å±æ€§ï¼Œé€šè¿‡Point Pair Features (PPF)å¯¹å…³èŠ‚ç‰©ä½“å»ºæ¨¡ä»¥é¢„æµ‹å§¿æ€æŠ•ç¥¨å‚æ•°ã€‚æœ€åï¼Œè¯¥æ–¹æ³•ç»“åˆå…³èŠ‚è½´çš„è¯­ä¹‰ä¿¡æ¯ï¼Œåœ¨å…³èŠ‚ç‰©ä½“çš„æ‰€æœ‰éƒ¨ä»¶ä¹‹é—´æ–½åŠ ç»Ÿä¸€çš„è¿åŠ¨å­¦çº¦æŸã€‚PPF-Trackeråœ¨åˆæˆæ•°æ®é›†å’ŒçœŸå®ä¸–ç•Œåœºæ™¯ä¸­è¿›è¡Œäº†ç³»ç»Ÿè¯„ä¼°ï¼Œå±•ç°äº†åœ¨å¤šæ ·åŒ–å’ŒæŒ‘æˆ˜æ€§ç¯å¢ƒä¸‹çš„å¼ºå¤§æ³›åŒ–èƒ½åŠ›ã€‚å®éªŒç»“æœçªå‡ºäº†è¯¥æ¡†æ¶åœ¨å…³èŠ‚ç‰©ä½“å¤šå¸§å§¿æ€è·Ÿè¸ªæ–¹é¢çš„æœ‰æ•ˆæ€§å’Œé²æ£’æ€§ï¼Œæœ‰åŠ©äºæ¨åŠ¨æœºå™¨äººå­¦ã€å…·èº«æ™ºèƒ½å’Œå¢å¼ºç°å®é¢†åŸŸçš„å‘å±•ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.05996v1",
      "published_date": "2025-11-08 12:56:21 UTC",
      "updated_date": "2025-11-08 12:56:21 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:38:48.797129+00:00"
    },
    {
      "arxiv_id": "2511.05993v2",
      "title": "Revisiting Entropy in Reinforcement Learning for Large Reasoning Models",
      "title_zh": "é‡æ–°å®¡è§†å¤§å‹æ¨ç†æ¨¡å‹å¼ºåŒ–å­¦ä¹ ä¸­çš„ç†µ",
      "authors": [
        "Renren Jin",
        "Pengzhi Gao",
        "Yuqi Ren",
        "Zhuowen Han",
        "Tongxuan Zhang",
        "Wuwei Huang",
        "Wei Liu",
        "Jian Luan",
        "Deyi Xiong"
      ],
      "abstract": "Reinforcement learning with verifiable rewards (RLVR) has emerged as a prominent paradigm for enhancing the reasoning capabilities of large language models (LLMs). However, the entropy of LLMs usually collapses during RLVR training, leading to premature convergence to suboptimal local minima and hindering further performance improvement. Although various approaches have been proposed to mitigate entropy collapse, a comprehensive study of entropy in RLVR remains lacking. To bridge this gap, we conduct extensive experiments to investigate the entropy dynamics of LLMs trained with RLVR and analyze how model entropy correlates with response diversity, calibration, and performance across various benchmarks. Our results identify three key factors that influence entropy: the clipping thresholds in the optimization objective, the number of off-policy updates, and the diversity of the training data. Furthermore, through both theoretical analysis and empirical validation, we demonstrate that tokens with positive advantages are the primary drivers of entropy collapse. Motivated by this insight, we propose Positive-Advantage Reweighting, a simple yet effective approach that regulates model entropy by adjusting the loss weights assigned to tokens with positive advantages during RLVR training, while maintaining competitive performance.",
      "tldr_zh": "è¯¥ç ”ç©¶æ·±å…¥æ¢è®¨äº†Reinforcement learning with verifiable rewards (RLVR)åœ¨å¢å¼ºLarge language models (LLMs)æ¨ç†èƒ½åŠ›æ—¶å‡ºç°çš„ç†µå´©å¡Œ(entropy collapse)ç°è±¡ã€‚å°½ç®¡RLVRæ˜¯å½“å‰çš„ä¸»æµèŒƒå¼ï¼Œä½†è®­ç»ƒä¸­çš„ç†µå´©å¡Œå¸¸å¯¼è‡´æ¨¡å‹è¿‡æ—©æ”¶æ•›äºæ¬¡ä¼˜å±€éƒ¨æœ€å°å€¼ï¼Œé™åˆ¶äº†æ€§èƒ½çš„è¿›ä¸€æ­¥æå‡ã€‚ä¸ºäº†å¼¥è¡¥ç°æœ‰ç ”ç©¶çš„ä¸è¶³ï¼Œä½œè€…è¿›è¡Œäº†å¹¿æ³›çš„å®éªŒï¼Œåˆ†æäº†RLVRè®­ç»ƒä¸­æ¨¡å‹ç†µçš„åŠ¨æ€å˜åŒ–åŠå…¶ä¸å“åº”å¤šæ ·æ€§ã€æ ¡å‡†åº¦å’Œæ€§èƒ½çš„ç›¸å…³æ€§ã€‚ç ”ç©¶è¯†åˆ«å‡ºå½±å“ç†µçš„ä¸‰ä¸ªå…³é”®å› ç´ ï¼šä¼˜åŒ–ç›®æ ‡ä¸­çš„clipping thresholdsã€off-policy updatesçš„æ•°é‡ä»¥åŠè®­ç»ƒæ•°æ®çš„å¤šæ ·æ€§ã€‚é€šè¿‡ç†è®ºåˆ†æå’Œå®è¯éªŒè¯ï¼Œç ”ç©¶è¿›ä¸€æ­¥æ­ç¤ºäº†å…·æœ‰positive advantagesçš„tokensæ˜¯é©±åŠ¨ç†µå´©å¡Œçš„ä¸»è¦å› ç´ ã€‚åŸºäºè¿™ä¸€å‘ç°ï¼Œä½œè€…æå‡ºäº†Positive-Advantage Reweightingæ–¹æ³•ï¼Œé€šè¿‡è°ƒæ•´RLVRè®­ç»ƒæœŸé—´æ­£ä¼˜åŠ¿tokensçš„æŸå¤±æƒé‡ï¼Œåœ¨ä¿æŒæ¨¡å‹æ€§èƒ½çš„åŒæ—¶æœ‰æ•ˆè°ƒèŠ‚äº†æ¨¡å‹ç†µã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "22 pages, 25 figures, 5 tables",
      "pdf_url": "https://arxiv.org/pdf/2511.05993v2",
      "published_date": "2025-11-08 12:50:41 UTC",
      "updated_date": "2026-01-10 08:58:33 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:39:16.567697+00:00"
    },
    {
      "arxiv_id": "2511.05991v1",
      "title": "Ontology Learning and Knowledge Graph Construction: A Comparison of Approaches and Their Impact on RAG Performance",
      "title_zh": "æœ¬ä½“å­¦ä¹ ä¸çŸ¥è¯†å›¾è°±æ„å»ºï¼šæ–¹æ³•æ¯”è¾ƒåŠå…¶å¯¹ RAG æ€§èƒ½çš„å½±å“",
      "authors": [
        "Tiago da Cruz",
        "Bernardo Tavares",
        "Francisco Belo"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) systems combine Large Language Models (LLMs) with external knowledge, and their performance depends heavily on how that knowledge is represented. This study investigates how different Knowledge Graph (KG) construction strategies influence RAG performance. We compare a variety of approaches: standard vector-based RAG, GraphRAG, and retrieval over KGs built from ontologies derived either from relational databases or textual corpora. Results show that ontology-guided KGs incorporating chunk information achieve competitive performance with state-of-the-art frameworks, substantially outperforming vector retrieval baselines. Moreover, the findings reveal that ontology-guided KGs built from relational databases perform competitively to ones built with ontologies extracted from text, with the benefit of offering a dual advantage: they require a one-time-only ontology learning process, substantially reducing LLM usage costs; and avoid the complexity of ontology merging inherent to text-based approaches.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ä¸åŒçš„çŸ¥è¯†å›¾è°±(Knowledge Graph, KG)æ„å»ºç­–ç•¥å¯¹æ£€ç´¢å¢å¼ºç”Ÿæˆ(Retrieval-Augmented Generation, RAG)ç³»ç»Ÿæ€§èƒ½çš„å½±å“ã€‚ç ”ç©¶äººå‘˜å¯¹æ¯”äº†æ ‡å‡†å‘é‡RAGã€GraphRAGï¼Œä»¥åŠåŸºäºä»å…³ç³»æ•°æ®åº“æˆ–æ–‡æœ¬è¯­æ–™åº“ä¸­æå–çš„æœ¬ä½“(Ontology)æ‰€æ„å»ºçš„KGæ£€ç´¢æ–¹æ³•ã€‚ç»“æœè¡¨æ˜ï¼Œç»“åˆäº†æ–‡æœ¬å—(chunk)ä¿¡æ¯çš„æœ¬ä½“å¼•å¯¼å‹KGèƒ½å¤Ÿè¾¾åˆ°ä¸æœ€å…ˆè¿›æ¡†æ¶ç›¸åª²ç¾çš„æ€§èƒ½ï¼Œå¹¶æ˜¾è‘—ä¼˜äºåŸºäºå‘é‡æ£€ç´¢çš„åŸºçº¿æ¨¡å‹ã€‚æ­¤å¤–ï¼Œç ”ç©¶å‘ç°åŸºäºå…³ç³»æ•°æ®åº“æ„å»ºçš„æœ¬ä½“å¼•å¯¼å‹KGåœ¨æ€§èƒ½ä¸Šä¸åŸºäºæ–‡æœ¬æå–æœ¬ä½“çš„KGç›¸å½“ã€‚è¯¥æ–¹æ³•å±•ç°äº†åŒé‡ä¼˜åŠ¿ï¼šå®ƒä»…éœ€ä¸€æ¬¡æ€§çš„æœ¬ä½“å­¦ä¹ è¿‡ç¨‹ï¼Œä»è€Œå¤§å¹…é™ä½äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLM)çš„ä½¿ç”¨æˆæœ¬ï¼Œå¹¶ä¸”é¿å…äº†åŸºäºæ–‡æœ¬çš„æ–¹æ³•ä¸­å›ºæœ‰çš„æœ¬ä½“åˆå¹¶å¤æ‚æ€§ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "12 pages, 8 Figures",
      "pdf_url": "https://arxiv.org/pdf/2511.05991v1",
      "published_date": "2025-11-08 12:38:45 UTC",
      "updated_date": "2025-11-08 12:38:45 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:40:59.350905+00:00"
    },
    {
      "arxiv_id": "2511.16675v1",
      "title": "Joint Design of Protein Surface and Structure Using a Diffusion Bridge Model",
      "title_zh": "åŸºäºæ‰©æ•£æ¡¥æ¨¡å‹çš„è›‹ç™½è´¨è¡¨é¢ä¸ç»“æ„è”åˆè®¾è®¡",
      "authors": [
        "Guanlue Li",
        "Xufeng Zhao",
        "Fang Wu",
        "SÃ¶ren Laue"
      ],
      "abstract": "Protein-protein interactions (PPIs) are governed by surface complementarity and hydrophobic interactions at protein interfaces. However, designing diverse and physically realistic protein structure and surfaces that precisely complement target receptors remains a significant challenge in computational protein design. In this work, we introduce PepBridge, a novel framework for the joint design of protein surface and structure that seamlessly integrates receptor surface geometry and biochemical properties. Starting with a receptor surface represented as a 3D point cloud, PepBridge generates complete protein structures through a multi-step process. First, it employs denoising diffusion bridge models (DDBMs) to map receptor surfaces to ligand surfaces. Next, a multi-model diffusion model predicts the corresponding structure, while Shape-Frame Matching Networks ensure alignment between surface geometry and backbone architecture. This integrated approach facilitates surface complementarity, conformational stability, and chemical feasibility. Extensive validation across diverse protein design scenarios demonstrates PepBridge's efficacy in generating structurally viable proteins, representing a significant advancement in the joint design of top-down protein structure.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è®¡ç®—è›‹ç™½è´¨è®¾è®¡ä¸­ç”Ÿæˆä¸ç›®æ ‡å—ä½“ç²¾ç¡®äº’è¡¥çš„è›‹ç™½è´¨ç»“æ„å’Œè¡¨é¢çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†PepBridgeï¼Œä¸€ç§è”åˆè®¾è®¡è›‹ç™½è´¨è¡¨é¢å’Œç»“æ„çš„æ–°å‹æ¡†æ¶ã€‚è¯¥æ–¹æ³•ä»¥å—ä½“è¡¨é¢çš„3Dç‚¹äº‘ä¸ºè¾“å…¥ï¼Œé¦–å…ˆåˆ©ç”¨å»å™ªæ‰©æ•£æ¡¥æ¨¡å‹(denoising diffusion bridge models, DDBMs)å°†å—ä½“è¡¨é¢æ˜ å°„åˆ°é…ä½“è¡¨é¢ï¼Œéšåé€šè¿‡å¤šæ¨¡æ€æ‰©æ•£æ¨¡å‹é¢„æµ‹ç›¸åº”çš„è›‹ç™½è´¨ç»“æ„ã€‚ä¸ºäº†ç¡®ä¿è¡¨é¢å‡ ä½•å½¢çŠ¶ä¸éª¨æ¶ç»“æ„ä¹‹é—´çš„ç²¾ç¡®å¯¹é½ï¼Œè¯¥æ¡†æ¶å¼•å…¥äº†Shape-Frame Matching Networksã€‚è¿™ç§é›†æˆæ–¹æ³•æœ‰æ•ˆä¿ƒè¿›äº†è¡¨é¢äº’è¡¥æ€§ã€æ„è±¡ç¨³å®šæ€§å’ŒåŒ–å­¦å¯è¡Œæ€§ã€‚å¹¿æ³›çš„éªŒè¯è¡¨æ˜ï¼ŒPepBridgeåœ¨ç”Ÿæˆç»“æ„å¯è¡Œçš„è›‹ç™½è´¨æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä»£è¡¨äº†è‡ªé¡¶å‘ä¸‹è›‹ç™½è´¨ç»“æ„è”åˆè®¾è®¡çš„é‡è¦è¿›å±•ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "21 pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2511.16675v1",
      "published_date": "2025-11-08 12:31:07 UTC",
      "updated_date": "2025-11-08 12:31:07 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:40:00.961938+00:00"
    },
    {
      "arxiv_id": "2511.11635v1",
      "title": "EduAgentQG: A Multi-Agent Workflow Framework for Personalized Question Generation",
      "title_zh": "EduAgentQGï¼šé¢å‘ä¸ªæ€§åŒ–é—®é¢˜ç”Ÿæˆçš„å¤šæ™ºèƒ½ä½“å·¥ä½œæµæ¡†æ¶",
      "authors": [
        "Rui Jia",
        "Min Zhang",
        "Fengrui Liu",
        "Bo Jiang",
        "Kun Kuang",
        "Zhongxiang Dai"
      ],
      "abstract": "High-quality personalized question banks are crucial for supporting adaptive learning and individualized assessment. Manually designing questions is time-consuming and often fails to meet diverse learning needs, making automated question generation a crucial approach to reduce teachers' workload and improve the scalability of educational resources. However, most existing question generation methods rely on single-agent or rule-based pipelines, which still produce questions with unstable quality, limited diversity, and insufficient alignment with educational goals. To address these challenges, we propose EduAgentQG, a multi-agent collaborative framework for generating high-quality and diverse personalized questions. The framework consists of five specialized agents and operates through an iterative feedback loop: the Planner generates structured design plans and multiple question directions to enhance diversity; the Writer produces candidate questions based on the plan and optimizes their quality and diversity using feedback from the Solver and Educator; the Solver and Educator perform binary scoring across multiple evaluation dimensions and feed the evaluation results back to the Writer; the Checker conducts final verification, including answer correctness and clarity, ensuring alignment with educational goals. Through this multi-agent collaboration and iterative feedback loop, EduAgentQG generates questions that are both high-quality and diverse, while maintaining consistency with educational objectives. Experiments on two mathematics question datasets demonstrate that EduAgentQG outperforms existing single-agent and multi-agent methods in terms of question diversity, goal consistency, and overall quality.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†EduAgentQGï¼Œä¸€ç§ç”¨äºç”Ÿæˆé«˜è´¨é‡ä¸ªæ€§åŒ–é—®é¢˜çš„å¤šæ™ºèƒ½ä½“åä½œæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰å•æ™ºèƒ½ä½“æˆ–åŸºäºè§„åˆ™çš„æ–¹æ³•åœ¨ç”Ÿæˆé—®é¢˜æ—¶è´¨é‡ä¸ç¨³å®šã€å¤šæ ·æ€§æœ‰é™ä¸”ä¸æ•™è‚²ç›®æ ‡å¯¹é½ä¸è¶³çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶åŒ…å«äº”ä¸ªä¸“ç”¨æ™ºèƒ½ä½“ï¼ˆPlanner, Writer, Solver, Educator, Checkerï¼‰ï¼Œé€šè¿‡è¿­ä»£åé¦ˆå¾ªç¯ååŒå·¥ä½œã€‚Plannerç”Ÿæˆç»“æ„åŒ–è®¾è®¡æ–¹æ¡ˆä»¥å¢å¼ºå¤šæ ·æ€§ï¼ŒWriteræ ¹æ®Solverå’ŒEducatorçš„è¯„ä¼°åé¦ˆä¼˜åŒ–é—®é¢˜ï¼Œæœ€åç”±Checkerè¿›è¡ŒåŒ…æ‹¬ç­”æ¡ˆæ­£ç¡®æ€§å’Œæ¸…æ™°åº¦åœ¨å†…çš„æœ€ç»ˆéªŒè¯ã€‚åœ¨ä¸¤ä¸ªæ•°å­¦æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒEduAgentQGåœ¨é—®é¢˜å¤šæ ·æ€§ã€ç›®æ ‡ä¸€è‡´æ€§å’Œæ•´ä½“è´¨é‡æ–¹é¢å‡æ˜¾è‘—ä¼˜äºç°æœ‰çš„å•æ™ºèƒ½ä½“å’Œå¤šæ™ºèƒ½ä½“æ–¹æ³•ï¼Œä¸ºå‡è½»æ•™å¸ˆè´Ÿæ‹…å’Œæå‡æ•™è‚²èµ„æºæ‰©å±•æ€§æä¾›äº†æœ‰æ•ˆé€”å¾„ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.11635v1",
      "published_date": "2025-11-08 12:25:31 UTC",
      "updated_date": "2025-11-08 12:25:31 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:40:26.690252+00:00"
    },
    {
      "arxiv_id": "2511.05982v1",
      "title": "Runtime Safety Monitoring of Deep Neural Networks for Perception: A Survey",
      "title_zh": "é¢å‘æ„ŸçŸ¥çš„æ·±åº¦ç¥ç»ç½‘ç»œè¿è¡Œæ—¶å®‰å…¨ç›‘æ§ï¼šç»¼è¿°",
      "authors": [
        "Albert Schotschneider",
        "Svetlana Pavlitska",
        "J. Marius ZÃ¶llner"
      ],
      "abstract": "Deep neural networks (DNNs) are widely used in perception systems for safety-critical applications, such as autonomous driving and robotics. However, DNNs remain vulnerable to various safety concerns, including generalization errors, out-of-distribution (OOD) inputs, and adversarial attacks, which can lead to hazardous failures. This survey provides a comprehensive overview of runtime safety monitoring approaches, which operate in parallel to DNNs during inference to detect these safety concerns without modifying the DNN itself. We categorize existing methods into three main groups: Monitoring inputs, internal representations, and outputs. We analyze the state-of-the-art for each category, identify strengths and limitations, and map methods to the safety concerns they address. In addition, we highlight open challenges and future research directions.",
      "tldr_zh": "è¯¥ç»¼è¿°é’ˆå¯¹æ·±åº¦ç¥ç»ç½‘ç»œ(DNNs)åœ¨è‡ªåŠ¨é©¾é©¶å’Œæœºå™¨äººç­‰å®‰å…¨å…³é”®å‹æ„ŸçŸ¥ç³»ç»Ÿä¸­çš„åº”ç”¨ï¼Œæ¢è®¨äº†å…¶é¢ä¸´çš„æ³›åŒ–é”™è¯¯ã€åˆ†å¸ƒå¤–(OOD)è¾“å…¥åŠå¯¹æŠ—æ€§æ”»å‡»ç­‰å®‰å…¨éšæ‚£ã€‚æ–‡ç« å…¨é¢å›é¡¾äº†è¿è¡Œæ—¶å®‰å…¨ç›‘æ§(Runtime Safety Monitoring)æ–¹æ³•ï¼Œè¿™äº›æ–¹æ³•åœ¨æ¨ç†é˜¶æ®µä¸DNNå¹¶è¡Œå·¥ä½œï¼Œæ—¨åœ¨ä¸ä¿®æ”¹æ¨¡å‹æœ¬èº«çš„å‰æä¸‹æ£€æµ‹æ½œåœ¨æ•…éšœã€‚ä½œè€…å°†ç°æœ‰æŠ€æœ¯åˆ†ä¸ºç›‘æ§è¾“å…¥ã€å†…éƒ¨è¡¨ç¤ºå’Œè¾“å‡ºä¸‰å¤§ç±»ï¼Œå¹¶åˆ†æäº†å„ç±»çš„æœ€æ–°è¿›å±•(SOTA)åŠå…¶ä¼˜ç¼ºç‚¹ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å°†å…·ä½“æ–¹æ³•ä¸å…¶è§£å†³çš„å®‰å…¨é—®é¢˜å»ºç«‹äº†æ˜ å°„å…³ç³»ï¼Œå¹¶æŒ‡å‡ºäº†å½“å‰é¢†åŸŸé¢ä¸´çš„å¼€æ”¾æ€§æŒ‘æˆ˜ä¸æœªæ¥ç ”ç©¶æ–¹å‘ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages, 1 figure, 2 tables, accepted at IEEE SMC 2025 in Vienna, presented on 8th October 2025",
      "pdf_url": "https://arxiv.org/pdf/2511.05982v1",
      "published_date": "2025-11-08 12:06:54 UTC",
      "updated_date": "2025-11-08 12:06:54 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:41:41.637380+00:00"
    },
    {
      "arxiv_id": "2511.05978v1",
      "title": "Kunlun Anomaly Troubleshooter: Enabling Kernel-Level Anomaly Detection and Causal Reasoning for Large Model Distributed Inference",
      "title_zh": "Kunlun å¼‚å¸¸æ’æŸ¥å™¨ï¼šå®ç°å¤§æ¨¡å‹åˆ†å¸ƒå¼æ¨ç†çš„å†…æ ¸çº§å¼‚å¸¸æ£€æµ‹ä¸å› æœæ¨ç†",
      "authors": [
        "Yuyang Liu",
        "Jingjing Cai",
        "Jiayi Ren",
        "Peng Zhou",
        "Danyang Zhang",
        "Yin Du",
        "Shijian Li"
      ],
      "abstract": "Anomaly troubleshooting for large model distributed inference (LMDI) remains a critical challenge. Resolving anomalies such as inference performance degradation or latency jitter in distributed system demands significant manual efforts from domain experts, resulting in extremely time-consuming diagnosis processes with relatively low accuracy. In this paper, we introduce Kunlun Anomaly Troubleshooter (KAT), the first anomaly troubleshooting framework tailored for LMDI. KAT addresses this problem through two core innovations. First, KAT exploits the synchronicity and consistency of GPU workers, innovatively leverages function trace data to precisely detect kernel-level anomalies and associated hardware components at nanosecond resolution. Second, KAT integrates these detection results into a domain-adapted LLM, delivering systematic causal reasoning and natural language interpretation of complex anomaly symptoms. Evaluations conducted in Alibaba Cloud Service production environment indicate that KAT achieves over 0.884 precision and 0.936 recall in anomaly detection, providing detail anomaly insights that significantly narrow down the diagnostic scope and improve both the efficiency and success rate of troubleshooting.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§æ¨¡å‹åˆ†å¸ƒå¼æ¨ç†(LMDI)ä¸­å¼‚å¸¸è¯Šæ–­ä¾èµ–äººå·¥ã€è€—æ—¶ä¸”å‡†ç¡®ç‡ä½çš„é—®é¢˜ï¼Œæå‡ºäº†é¦–ä¸ªä¸“ç”¨æ•…éšœæ’é™¤æ¡†æ¶Kunlun Anomaly Troubleshooter (KAT)ã€‚KATåˆ©ç”¨GPUå·¥ä½œèŠ‚ç‚¹çš„åŒæ­¥æ€§å’Œä¸€è‡´æ€§ï¼Œé€šè¿‡åˆ†æfunction traceæ•°æ®ï¼Œå®ç°äº†çº³ç§’çº§åˆ†è¾¨ç‡çš„kernel-levelå¼‚å¸¸æ£€æµ‹åŠç›¸å…³ç¡¬ä»¶ç»„ä»¶å®šä½ã€‚åŒæ—¶ï¼Œè¯¥æ¡†æ¶å°†æ£€æµ‹ç»“æœé›†æˆåˆ°ç»è¿‡é¢†åŸŸé€‚é…çš„å¤§è¯­è¨€æ¨¡å‹(LLM)ä¸­ï¼Œå¯¹å¤æ‚çš„å¼‚å¸¸ç—‡çŠ¶è¿›è¡Œç³»ç»Ÿçš„å› æœæ¨ç†å’Œè‡ªç„¶è¯­è¨€è§£é‡Šã€‚åœ¨é˜¿é‡Œäº‘æœåŠ¡ç”Ÿäº§ç¯å¢ƒä¸­çš„è¯„ä¼°è¡¨æ˜ï¼ŒKATåœ¨å¼‚å¸¸æ£€æµ‹æ–¹é¢è¾¾åˆ°äº†è¶…è¿‡0.884çš„ç²¾ç¡®ç‡å’Œ0.936çš„å¬å›ç‡ã€‚è¯¥æ–¹æ³•æä¾›äº†è¯¦ç»†çš„å¼‚å¸¸æ´å¯Ÿï¼Œæ˜¾è‘—ç¼©å°äº†è¯Šæ–­èŒƒå›´ï¼Œæœ‰æ•ˆæå‡äº†æ•…éšœæ’é™¤çš„æ•ˆç‡å’ŒæˆåŠŸç‡ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "cs.PF"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint version, under submission",
      "pdf_url": "https://arxiv.org/pdf/2511.05978v1",
      "published_date": "2025-11-08 11:53:08 UTC",
      "updated_date": "2025-11-08 11:53:08 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:42:22.864286+00:00"
    },
    {
      "arxiv_id": "2511.05977v1",
      "title": "An Epistemic Perspective on Agent Awareness",
      "title_zh": "æ™ºèƒ½ä½“æ„è¯†çš„è®¤è¯†è®ºè§†è§’",
      "authors": [
        "Pavel Naumov",
        "Alexandra Pavlova"
      ],
      "abstract": "The paper proposes to treat agent awareness as a form of knowledge, breaking the tradition in the existing literature on awareness. It distinguishes the de re and de dicto forms of such knowledge. The work introduces two modalities capturing these forms and formally specifies their meaning using a version of 2D-semantics. The main technical result is a sound and complete logical system describing the interplay between the two proposed modalities and the standard \"knowledge of the fact\" modality.",
      "tldr_zh": "è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§å°†æ™ºèƒ½ä½“æ„è¯†ï¼ˆAgent Awarenessï¼‰è§†ä¸ºä¸€ç§çŸ¥è¯†å½¢å¼çš„è®¤è¯†è®ºè§†è§’ï¼Œæ‰“ç ´äº†ç°æœ‰æ–‡çŒ®ä¸­å…³äºæ„è¯†çš„ä¼ ç»Ÿå¤„ç†æ–¹å¼ã€‚ç ”ç©¶åŒºåˆ†äº†è¿™ç§çŸ¥è¯†çš„ *de re*ï¼ˆä»ç‰©ï¼‰å’Œ *de dicto*ï¼ˆä»è¨€ï¼‰å½¢å¼ï¼Œå¹¶å¼•å…¥äº†ä¸¤ç§æ¨¡æ€æ¥æ•æ‰è¿™äº›å½¢å¼ã€‚ä½œè€…ä½¿ç”¨ä¸€ç§äºŒç»´è¯­ä¹‰å­¦ï¼ˆ2D-semanticsï¼‰ç‰ˆæœ¬å½¢å¼åŒ–åœ°è§„å®šäº†è¿™äº›æ¨¡æ€çš„å«ä¹‰ã€‚è¯¥ç ”ç©¶çš„ä¸»è¦æŠ€æœ¯è´¡çŒ®æ˜¯å»ºç«‹äº†ä¸€ä¸ªå¯é ä¸”å®Œå¤‡ï¼ˆsound and completeï¼‰çš„é€»è¾‘ç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿæè¿°äº†è¿™ä¸¤ä¸ªæ–°æå‡ºçš„æ¨¡æ€ä¸æ ‡å‡†çš„â€œäº‹å®çŸ¥è¯†â€ï¼ˆknowledge of the factï¼‰æ¨¡æ€ä¹‹é—´çš„ç›¸äº’ä½œç”¨ã€‚",
      "categories": [
        "cs.AI",
        "cs.LO",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "Fortieth AAAI Conference on Artificial Intelligence (AAAI-26)",
      "pdf_url": "https://arxiv.org/pdf/2511.05977v1",
      "published_date": "2025-11-08 11:50:25 UTC",
      "updated_date": "2025-11-08 11:50:25 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:42:05.731575+00:00"
    },
    {
      "arxiv_id": "2601.05265v1",
      "title": "Cross-Document Topic-Aligned Chunking for Retrieval-Augmented Generation",
      "title_zh": "é¢å‘æ£€ç´¢å¢å¼ºç”Ÿæˆçš„è·¨æ–‡æ¡£ä¸»é¢˜å¯¹é½åˆ†å—",
      "authors": [
        "Mile Stankovic"
      ],
      "abstract": "Chunking quality determines RAG system performance. Current methods partition documents individually, but complex queries need information scattered across multiple sources: the knowledge fragmentation problem. We introduce Cross-Document Topic-Aligned (CDTA) chunking, which reconstructs knowledge at the corpus level. It first identifies topics across documents, maps segments to each topic, and synthesizes them into unified chunks.\n  On HotpotQA multi-hop reasoning, our method reached 0.93 faithfulness versus 0.83 for contextual retrieval and 0.78 for semantic chunking, a 12% improvement over current industry best practice (p < 0.05). On UAE Legal texts, it reached 0.94 faithfulness with 0.93 citation accuracy. At k = 3, it maintains 0.91 faithfulness while semantic methods drop to 0.68, with a single CDTA chunk containing information requiring multiple traditional fragments.\n  Indexing costs are higher, but synthesis produces information-dense chunks that reduce query-time retrieval needs. For high-query-volume applications with distributed knowledge, cross-document synthesis improves measurably over within-document optimization.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)ç³»ç»Ÿä¸­ç°æœ‰å•æ–‡æ¡£åˆ‡åˆ†æ–¹æ³•å¯¼è‡´çš„çŸ¥è¯†ç¢ç‰‡åŒ–é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºè·¨æ–‡æ¡£ä¸»é¢˜å¯¹é½(Cross-Document Topic-Aligned, CDTA)çš„åˆ‡åˆ†æŠ€æœ¯ã€‚CDTAé€šè¿‡åœ¨è¯­æ–™åº“å±‚é¢é‡æ„çŸ¥è¯†ï¼Œè¯†åˆ«è·¨è¶Šå¤šä¸ªæ–‡æ¡£çš„ä¸»é¢˜ï¼Œå¹¶å°†ç›¸å…³ç‰‡æ®µæ˜ å°„å¹¶åˆæˆä¸ºç»Ÿä¸€çš„å—(chunks)ï¼Œä»è€Œæœ‰æ•ˆæ•´åˆåˆ†æ•£ä¿¡æ¯ã€‚åœ¨HotpotQAå¤šè·³æ¨ç†ä»»åŠ¡ä¸Šçš„å®éªŒæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•çš„å¿ å®åº¦(faithfulness)è¾¾åˆ°0.93ï¼Œç›¸æ¯”ä¸Šä¸‹æ–‡æ£€ç´¢(0.83)å’Œè¯­ä¹‰åˆ‡åˆ†(0.78)æœ‰æ˜¾è‘—æå‡ï¼Œè¶…è¶Šå½“å‰è¡Œä¸šæœ€ä½³å®è·µ12%ã€‚åœ¨é˜¿è”é…‹æ³•å¾‹æ–‡æœ¬æ•°æ®é›†ä¸Šï¼ŒCDTAåŒæ ·è¡¨ç°å‡ºè‰²ï¼Œè¾¾åˆ°äº†0.94çš„å¿ å®åº¦å’Œ0.93çš„å¼•ç”¨å‡†ç¡®ç‡ï¼Œä¸”åœ¨k=3æ—¶ä»èƒ½ä¿æŒé«˜æ°´å¹³è¡¨ç°ã€‚å°½ç®¡è¯¥æ–¹æ³•å¢åŠ äº†ç´¢å¼•æˆæœ¬ï¼Œä½†å…¶ç”Ÿæˆçš„é«˜å¯†åº¦ä¿¡æ¯å—é™ä½äº†æŸ¥è¯¢æ—¶çš„æ£€ç´¢éœ€æ±‚ã€‚ç ”ç©¶è¡¨æ˜ï¼Œå¯¹äºçŸ¥è¯†åˆ†å¸ƒå¹¿æ³›ä¸”æŸ¥è¯¢é‡å¤§çš„åº”ç”¨åœºæ™¯ï¼Œè·¨æ–‡æ¡£åˆæˆç›¸æ¯”ä¼ ç»Ÿçš„æ–‡æ¡£å†…ä¼˜åŒ–å…·æœ‰æ˜æ˜¾çš„æ€§èƒ½ä¼˜åŠ¿ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.05265v1",
      "published_date": "2025-11-08 11:45:45 UTC",
      "updated_date": "2025-11-08 11:45:45 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:42:50.215996+00:00"
    },
    {
      "arxiv_id": "2511.05969v1",
      "title": "Interpretable Recognition of Cognitive Distortions in Natural Language Texts",
      "title_zh": "è‡ªç„¶è¯­è¨€æ–‡æœ¬ä¸­è®¤çŸ¥æ‰­æ›²çš„å¯è§£é‡Šè¯†åˆ«",
      "authors": [
        "Anton Kolonin",
        "Anna Arinicheva"
      ],
      "abstract": "We propose a new approach to multi-factor classification of natural language texts based on weighted structured patterns such as N-grams, taking into account the heterarchical relationships between them, applied to solve such a socially impactful problem as the automation of detection of specific cognitive distortions in psychological care, relying on an interpretable, robust and transparent artificial intelligence model. The proposed recognition and learning algorithms improve the current state of the art in this field. The improvement is tested on two publicly available datasets, with significant improvements over literature-known F1 scores for the task, with optimal hyper-parameters determined, having code and models available for future use by the community.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§é’ˆå¯¹è‡ªç„¶è¯­è¨€æ–‡æœ¬çš„å¤šå› ç´ åˆ†ç±»æ–°æ–¹æ³•ï¼Œæ—¨åœ¨é€šè¿‡å¯è§£é‡Šã€é²æ£’ä¸”é€æ˜çš„äººå·¥æ™ºèƒ½æ¨¡å‹ï¼Œè‡ªåŠ¨æ£€æµ‹å¿ƒç†æŠ¤ç†ä¸­çš„ç‰¹å®šè®¤çŸ¥æ‰­æ›²ï¼ˆCognitive Distortionsï¼‰ã€‚è¯¥æ–¹æ³•åŸºäºåŠ æƒç»“æ„åŒ–æ¨¡å¼ï¼ˆå¦‚N-gramsï¼‰ï¼Œå¹¶å……åˆ†è€ƒè™‘äº†æ¨¡å¼ä¹‹é—´å­˜åœ¨çš„å¼‚æ„å±‚çº§å…³ç³»ï¼ˆheterarchical relationshipsï¼‰ã€‚æå‡ºçš„è¯†åˆ«å’Œå­¦ä¹ ç®—æ³•æ˜¾è‘—æå‡äº†è¯¥é¢†åŸŸçš„ç°æœ‰æŠ€æœ¯æ°´å¹³ï¼ˆSOTAï¼‰ã€‚åœ¨ä¸¤ä¸ªå…¬å¼€æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨F1åˆ†æ•°ä¸Šå–å¾—äº†æ˜¾è‘—ä¼˜äºç°æœ‰æ–‡çŒ®çš„ç»“æœï¼Œå¹¶ç¡®å®šäº†æœ€ä½³è¶…å‚æ•°ã€‚æ­¤å¤–ï¼Œç ”ç©¶è€…è¿˜å¼€æºäº†ç›¸å…³ä»£ç å’Œæ¨¡å‹ï¼Œä»¥ä¿ƒè¿›ç¤¾åŒºçš„è¿›ä¸€æ­¥ç ”ç©¶ä¸åº”ç”¨ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2511.05969v1",
      "published_date": "2025-11-08 11:13:29 UTC",
      "updated_date": "2025-11-08 11:13:29 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:43:09.549664+00:00"
    },
    {
      "arxiv_id": "2511.05968v1",
      "title": "DiA-gnostic VLVAE: Disentangled Alignment-Constrained Vision Language Variational AutoEncoder for Robust Radiology Reporting with Missing Modalities",
      "title_zh": "DiA-gnostic VLVAEï¼šé¢å‘æ¨¡æ€ç¼ºå¤±ä¸‹é²æ£’æ”¾å°„å­¦æŠ¥å‘Šç”Ÿæˆçš„è§£è€¦å¯¹é½çº¦æŸè§†è§‰è¯­è¨€å˜åˆ†è‡ªç¼–ç å™¨",
      "authors": [
        "Nagur Shareef Shaik",
        "Teja Krishna Cherukuri",
        "Adnan Masood",
        "Dong Hye Ye"
      ],
      "abstract": "The integration of medical images with clinical context is essential for generating accurate and clinically interpretable radiology reports. However, current automated methods often rely on resource-heavy Large Language Models (LLMs) or static knowledge graphs and struggle with two fundamental challenges in real-world clinical data: (1) missing modalities, such as incomplete clinical context , and (2) feature entanglement, where mixed modality-specific and shared information leads to suboptimal fusion and clinically unfaithful hallucinated findings. To address these challenges, we propose the DiA-gnostic VLVAE, which achieves robust radiology reporting through Disentangled Alignment. Our framework is designed to be resilient to missing modalities by disentangling shared and modality-specific features using a Mixture-of-Experts (MoE) based Vision-Language Variational Autoencoder (VLVAE). A constrained optimization objective enforces orthogonality and alignment between these latent representations to prevent suboptimal fusion. A compact LLaMA-X decoder then uses these disentangled representations to generate reports efficiently. On the IU X-Ray and MIMIC-CXR datasets, DiA has achieved competetive BLEU@4 scores of 0.266 and 0.134, respectively. Experimental results show that the proposed method significantly outperforms state-of-the-art models.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†DiA-gnostic VLVAEï¼Œä¸€ç§åŸºäºè§£è€¦å¯¹é½çº¦æŸçš„è§†è§‰è¯­è¨€å˜åˆ†è‡ªç¼–ç å™¨ï¼Œæ—¨åœ¨è§£å†³è‡ªåŠ¨æ”¾å°„å­¦æŠ¥å‘Šç”Ÿæˆä¸­é¢ä¸´çš„æ¨¡æ€ç¼ºå¤±ï¼ˆå¦‚ä¸´åºŠèƒŒæ™¯ä¸å®Œæ•´ï¼‰å’Œç‰¹å¾çº ç¼ å¯¼è‡´çš„å¹»è§‰é—®é¢˜ã€‚è¯¥æ¡†æ¶åˆ©ç”¨åŸºäºæ··åˆä¸“å®¶æ¨¡å‹ï¼ˆMixture-of-Experts, MoEï¼‰çš„VLVAEæ¥è§£è€¦å…±äº«ç‰¹å¾ä¸æ¨¡æ€ç‰¹æœ‰ç‰¹å¾ï¼Œä»è€Œå¢å¼ºæ¨¡å‹å¯¹ç¼ºå¤±æ¨¡æ€çš„é²æ£’æ€§ã€‚é€šè¿‡å¼•å…¥çº¦æŸä¼˜åŒ–ç›®æ ‡ï¼Œå¼ºåˆ¶æ½œåœ¨è¡¨ç¤ºä¹‹é—´çš„æ­£äº¤æ€§å’Œå¯¹é½ï¼Œæœ‰æ•ˆé¿å…äº†æ¬¡ä¼˜èåˆã€‚éšåï¼Œæ¨¡å‹åˆ©ç”¨ç´§å‡‘çš„LLaMA-Xè§£ç å™¨åŸºäºè¿™äº›è§£è€¦è¡¨ç¤ºé«˜æ•ˆç”ŸæˆæŠ¥å‘Šã€‚åœ¨IU X-Rayå’ŒMIMIC-CXRæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åˆ†åˆ«å–å¾—äº†0.266å’Œ0.134çš„BLEU@4åˆ†æ•°ï¼Œæ˜¾è‘—ä¼˜äºå½“å‰æœ€å…ˆè¿›ï¼ˆSOTAï¼‰æ¨¡å‹ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted for Oral Presentation at the 40th AAAI Conference on Artificial Intelligence (AAAI-26), Main Technical Track",
      "pdf_url": "https://arxiv.org/pdf/2511.05968v1",
      "published_date": "2025-11-08 11:08:27 UTC",
      "updated_date": "2025-11-08 11:08:27 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:46:20.047417+00:00"
    },
    {
      "arxiv_id": "2511.05967v1",
      "title": "Adapted Foundation Models for Breast MRI Triaging in Contrast-Enhanced and Non-Contrast Enhanced Protocols",
      "title_zh": "ç”¨äºå¢å¼ºä¸éå¢å¼ºæ–¹æ¡ˆä¹³è…º MRI åˆ†è¯Šçš„é€‚é…åŸºç¡€æ¨¡å‹",
      "authors": [
        "Tri-Thien Nguyen",
        "Lorenz A. Kapsner",
        "Tobias Hepp",
        "Shirin Heidarikahkesh",
        "Hannes Schreiter",
        "Luise Brock",
        "Dominika Skwierawska",
        "Dominique Hadler",
        "Julian Hossbach",
        "Evelyn Wenkel",
        "Sabine Ohlmeyer",
        "Frederik B. Laun",
        "Andrzej Liebert",
        "Andreas Maier",
        "Michael Uder",
        "Sebastian Bickelhaupt"
      ],
      "abstract": "Background: Magnetic resonance imaging (MRI) has high sensitivity for breast cancer detection, but interpretation is time-consuming. Artificial intelligence may aid in pre-screening. Purpose: To evaluate the DINOv2-based Medical Slice Transformer (MST) for ruling out significant findings (Breast Imaging Reporting and Data System [BI-RADS] >=4) in contrast-enhanced and non-contrast-enhanced abbreviated breast MRI. Materials and Methods: This institutional review board approved retrospective study included 1,847 single-breast MRI examinations (377 BI-RADS >=4) from an in-house dataset and 924 from an external validation dataset (Duke). Four abbreviated protocols were tested: T1-weighted early subtraction (T1sub), diffusion-weighted imaging with b=1500 s/mm2 (DWI1500), DWI1500+T2-weighted (T2w), and T1sub+T2w. Performance was assessed at 90%, 95%, and 97.5% sensitivity using five-fold cross-validation and area under the receiver operating characteristic curve (AUC) analysis. AUC differences were compared with the DeLong test. False negatives were characterized, and attention maps of true positives were rated in the external dataset. Results: A total of 1,448 female patients (mean age, 49 +/- 12 years) were included. T1sub+T2w achieved an AUC of 0.77 +/- 0.04; DWI1500+T2w, 0.74 +/- 0.04 (p=0.15). At 97.5% sensitivity, T1sub+T2w had the highest specificity (19% +/- 7%), followed by DWI1500+T2w (17% +/- 11%). Missed lesions had a mean diameter <10 mm at 95% and 97.5% thresholds for both T1sub and DWI1500, predominantly non-mass enhancements. External validation yielded an AUC of 0.77, with 88% of attention maps rated good or moderate. Conclusion: At 97.5% sensitivity, the MST framework correctly triaged cases without BI-RADS >=4, achieving 19% specificity for contrast-enhanced and 17% for non-contrast-enhanced MRI. Further research is warranted before clinical implementation.",
      "tldr_zh": "è¯¥ç ”ç©¶è¯„ä¼°äº†ä¸€ç§åŸºäºDINOv2çš„Medical Slice Transformer (MST)æ¨¡å‹ï¼Œæ—¨åœ¨å¢å¼ºå’Œéå¢å¼ºä¹³è…ºMRIåè®®ä¸­è¾…åŠ©æ’é™¤å…·æœ‰æ˜¾è‘—ä¸´åºŠå‘ç°ï¼ˆBI-RADS >=4ï¼‰çš„ç—…ä¾‹ã€‚ç ”ç©¶å›¢é˜Ÿåˆ©ç”¨åŒ…å«1847ä¾‹å†…éƒ¨æ£€æŸ¥å’Œ924ä¾‹å¤–éƒ¨éªŒè¯æ•°æ®ï¼ˆDukeï¼‰çš„å›é¡¾æ€§æ•°æ®é›†ï¼Œæµ‹è¯•äº†T1subã€DWI1500åŠå…¶ä¸T2wç»“åˆçš„å››ç§ç®€åŒ–åè®®ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒT1sub+T2wå’ŒDWI1500+T2wåè®®åˆ†åˆ«å®ç°äº†0.77å’Œ0.74çš„AUCå€¼ã€‚åœ¨è®¾å®šä¸º97.5%çš„é«˜çµæ•åº¦ä¸‹ï¼Œè¿™ä¸¤ç§åè®®åˆ†åˆ«è¾¾åˆ°äº†19%å’Œ17%çš„ç‰¹å¼‚æ€§ï¼Œèƒ½å¤Ÿæœ‰æ•ˆç­›é€‰å‡ºéƒ¨åˆ†æ— éœ€è¿›ä¸€æ­¥å®¡æŸ¥çš„é˜´æ€§ç—…ä¾‹ã€‚å¤–éƒ¨éªŒè¯ç»“æœä¸å†…éƒ¨æµ‹è¯•ä¸€è‡´ï¼Œä¸”88%çš„æ³¨æ„åŠ›å›¾ï¼ˆattention mapsï¼‰è´¨é‡è¢«è¯„ä¸ºè‰¯å¥½æˆ–ä¸­ç­‰ï¼Œæ¼è¯Šç—…å˜ä¸»è¦ä¸ºç›´å¾„å°äº10æ¯«ç±³çš„éè‚¿å—å¼ºåŒ–ã€‚ç»“è®ºè¡¨æ˜ï¼Œè¯¥MSTæ¡†æ¶å…·å¤‡ä½œä¸ºä¹³è…ºMRIåˆ†è¯Šå·¥å…·çš„æ½œåŠ›ï¼Œèƒ½å¤Ÿåœ¨ä¸ç‰ºç‰²é«˜çµæ•åº¦çš„å‰æä¸‹æé«˜è¯Šæ–­æ•ˆç‡ï¼Œå°½ç®¡ä¸´åºŠåº”ç”¨å‰ä»éœ€è¿›ä¸€æ­¥éªŒè¯ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "23 pages, 6 figures, 4 tables. Originally submitted to Radiology (RAD-25-2541); under consideration for transfer to Radiology: Artificial Intelligence (RSNA Portfolio Journal)",
      "pdf_url": "https://arxiv.org/pdf/2511.05967v1",
      "published_date": "2025-11-08 11:01:22 UTC",
      "updated_date": "2025-11-08 11:01:22 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:46:47.086311+00:00"
    },
    {
      "arxiv_id": "2511.05965v1",
      "title": "Adaptive Agent Selection and Interaction Network for Image-to-point cloud Registration",
      "title_zh": "ç”¨äºå›¾åƒåˆ°ç‚¹äº‘é…å‡†çš„è‡ªé€‚åº”æ™ºèƒ½ä½“é€‰æ‹©ä¸äº¤äº’ç½‘ç»œ",
      "authors": [
        "Zhixin Cheng",
        "Xiaotian Yin",
        "Jiacheng Deng",
        "Bohao Liao",
        "Yujia Chen",
        "Xu Zhou",
        "Baoqun Yin",
        "Tianzhu Zhang"
      ],
      "abstract": "Typical detection-free methods for image-to-point cloud registration leverage transformer-based architectures to aggregate cross-modal features and establish correspondences. However, they often struggle under challenging conditions, where noise disrupts similarity computation and leads to incorrect correspondences. Moreover, without dedicated designs, it remains difficult to effectively select informative and correlated representations across modalities, thereby limiting the robustness and accuracy of registration. To address these challenges, we propose a novel cross-modal registration framework composed of two key modules: the Iterative Agents Selection (IAS) module and the Reliable Agents Interaction (RAI) module. IAS enhances structural feature awareness with phase maps and employs reinforcement learning principles to efficiently select reliable agents. RAI then leverages these selected agents to guide cross-modal interactions, effectively reducing mismatches and improving overall robustness. Extensive experiments on the RGB-D Scenes v2 and 7-Scenes benchmarks demonstrate that our method consistently achieves state-of-the-art performance.",
      "tldr_zh": "é’ˆå¯¹ç°æœ‰çš„Transformeræ¶æ„åœ¨å›¾åƒåˆ°ç‚¹äº‘é…å‡†(Image-to-point cloud Registration)ä»»åŠ¡ä¸­å®¹æ˜“å—å™ªå£°å¹²æ‰°ä¸”éš¾ä»¥æœ‰æ•ˆé€‰æ‹©è·¨æ¨¡æ€ç‰¹å¾çš„é—®é¢˜ï¼Œè¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§å…¨æ–°çš„è·¨æ¨¡æ€é…å‡†æ¡†æ¶ã€‚è¯¥æ¡†æ¶åŒ…å«ä¸¤ä¸ªæ ¸å¿ƒæ¨¡å—ï¼šè¿­ä»£æ™ºèƒ½ä½“é€‰æ‹©æ¨¡å—(Iterative Agents Selection, IAS)å’Œå¯é æ™ºèƒ½ä½“äº¤äº’æ¨¡å—(Reliable Agents Interaction, RAI)ã€‚IASæ¨¡å—åˆ©ç”¨ç›¸ä½å›¾å¢å¼ºç»“æ„ç‰¹å¾æ„ŸçŸ¥ï¼Œå¹¶é‡‡ç”¨å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)åŸåˆ™é«˜æ•ˆç­›é€‰å‡ºå¯é çš„æ™ºèƒ½ä½“ã€‚éšåï¼ŒRAIæ¨¡å—åˆ©ç”¨è¿™äº›è¢«é€‰ä¸­çš„æ™ºèƒ½ä½“æ¥å¼•å¯¼è·¨æ¨¡æ€äº¤äº’ï¼Œæœ‰æ•ˆå‡å°‘äº†è¯¯åŒ¹é…å¹¶æå‡äº†æ•´ä½“é²æ£’æ€§ã€‚åœ¨RGB-D Scenes v2å’Œ7-ScenesåŸºå‡†æµ‹è¯•ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æŒç»­å®ç°äº†æœ€å…ˆè¿›(State-of-the-Art)çš„æ€§èƒ½ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by AAAI2026",
      "pdf_url": "https://arxiv.org/pdf/2511.05965v1",
      "published_date": "2025-11-08 10:50:43 UTC",
      "updated_date": "2025-11-08 10:50:43 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:47:07.958141+00:00"
    },
    {
      "arxiv_id": "2511.05951v1",
      "title": "Klear-AgentForge: Forging Agentic Intelligence through Posttraining Scaling",
      "title_zh": "Klear-AgentForgeï¼šé€šè¿‡åè®­ç»ƒæ‰©å±•æ‰“é€ ä»£ç†æ™ºèƒ½",
      "authors": [
        "Qi Wang",
        "Hongzhi Zhang",
        "Jia Fu",
        "Kai Fu",
        "Yahui Liu",
        "Tinghai Zhang",
        "Chenxi Sun",
        "Gangwei Jiang",
        "Jingyi Tang",
        "Xingguang Ji",
        "Yang Yue",
        "Jingyuan Zhang",
        "Fuzheng Zhang",
        "Kun Gai",
        "Guorui Zhou"
      ],
      "abstract": "Despite the proliferation of powerful agentic models, the lack of critical post-training details hinders the development of strong counterparts in the open-source community. In this study, we present a comprehensive and fully open-source pipeline for training a high-performance agentic model for interacting with external tools and environments, named Klear-Qwen3-AgentForge, starting from the Qwen3-8B base model. We design effective supervised fine-tuning (SFT) with synthetic data followed by multi-turn reinforcement learning (RL) to unlock the potential for multiple diverse agentic tasks. We perform exclusive experiments on various agentic benchmarks in both tool use and coding domains. Klear-Qwen3-AgentForge-8B achieves state-of-the-art performance among LLMs of similar size and remains competitive with significantly larger models.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¼€æºç¤¾åŒºç¼ºä¹å…³é”®åè®­ç»ƒç»†èŠ‚é˜»ç¢å¼ºåŠ›æ™ºèƒ½ä½“æ¨¡å‹å‘å±•çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªå…¨é¢ä¸”å®Œå…¨å¼€æºçš„è®­ç»ƒç®¡é“ï¼Œå¹¶å‘å¸ƒäº†åŸºäºQwen3-8Bçš„é«˜æ€§èƒ½æ™ºèƒ½ä½“æ¨¡å‹Klear-Qwen3-AgentForgeã€‚è¯¥æ–¹æ³•é¦–å…ˆåˆ©ç”¨åˆæˆæ•°æ®è¿›è¡Œæœ‰æ•ˆçš„ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ï¼Œéšåé€šè¿‡å¤šè½®å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰æ¥è§£é”æ¨¡å‹åœ¨å¤šæ ·åŒ–æ™ºèƒ½ä½“ä»»åŠ¡ä¸­çš„æ½œåŠ›ï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å¥½åœ°ä¸å¤–éƒ¨å·¥å…·å’Œç¯å¢ƒäº¤äº’ã€‚ç ”ç©¶å›¢é˜Ÿåœ¨å·¥å…·ä½¿ç”¨å’Œä»£ç ç”Ÿæˆç­‰å¤šä¸ªé¢†åŸŸçš„æ™ºèƒ½ä½“åŸºå‡†ä¸Šè¿›è¡Œäº†å¹¿æ³›å®éªŒã€‚ç»“æœæ˜¾ç¤ºï¼ŒKlear-Qwen3-AgentForge-8Båœ¨åŒç­‰è§„æ¨¡çš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­è¾¾åˆ°äº†æœ€å…ˆè¿›ï¼ˆSOTAï¼‰çš„æ€§èƒ½ï¼Œå¹¶ä¸”ä¸å‚æ•°é‡æ˜¾è‘—æ›´å¤§çš„æ¨¡å‹ç›¸æ¯”ä»å…·æœ‰ç«äº‰åŠ›ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "20 pages, 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2511.05951v1",
      "published_date": "2025-11-08 09:47:27 UTC",
      "updated_date": "2025-11-08 09:47:27 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:47:32.050254+00:00"
    },
    {
      "arxiv_id": "2511.05940v1",
      "title": "A PDE Perspective on Generative Diffusion Models",
      "title_zh": "ç”Ÿæˆå¼æ‰©æ•£æ¨¡å‹çš„åå¾®åˆ†æ–¹ç¨‹è§†è§’",
      "authors": [
        "Kang Liu",
        "Enrique Zuazua"
      ],
      "abstract": "Score-based diffusion models have emerged as a powerful class of generative methods, achieving state-of-the-art performance across diverse domains. Despite their empirical success, the mathematical foundations of those models remain only partially understood, particularly regarding the stability and consistency of the underlying stochastic and partial differential equations governing their dynamics.\n  In this work, we develop a rigorous partial differential equation (PDE) framework for score-based diffusion processes. Building on the Li--Yau differential inequality for the heat flow, we prove well-posedness and derive sharp $L^p$-stability estimates for the associated score-based Fokker--Planck dynamics, providing a mathematically consistent description of their temporal evolution. Through entropy stability methods, we further show that the reverse-time dynamics of diffusion models concentrate on the data manifold for compactly supported data distributions and a broad class of initialization schemes, with a concentration rate of order $\\sqrt{t}$ as $t \\to 0$.\n  These results yield a theoretical guarantee that, under exact score guidance, diffusion trajectories return to the data manifold while preserving imitation fidelity. Our findings also provide practical insights for designing diffusion models, including principled criteria for score-function construction, loss formulation, and stopping-time selection. Altogether, this framework provides a quantitative understanding of the trade-off between generative capacity and imitation fidelity, bridging rigorous analysis and model design within a unified mathematical perspective.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸºäºåˆ†æ•°çš„ç”Ÿæˆæ‰©æ•£æ¨¡å‹(Score-based Diffusion Models)ç¼ºä¹å®Œæ•´æ•°å­¦åŸºç¡€çš„é—®é¢˜ï¼Œå»ºç«‹äº†ä¸€ä¸ªä¸¥æ ¼çš„åå¾®åˆ†æ–¹ç¨‹(PDE)æ¡†æ¶ã€‚ç ”ç©¶åŸºäºçƒ­æµçš„Li-Yauå¾®åˆ†ä¸ç­‰å¼ï¼Œè¯æ˜äº†ç›¸å…³Fokker-PlanckåŠ¨åŠ›å­¦çš„é€‚å®šæ€§ï¼Œå¹¶æ¨å¯¼å‡ºäº†æ¸…æ™°çš„$L^p$ç¨³å®šæ€§ä¼°è®¡ï¼Œä»è€Œæä¾›äº†ä¸€è‡´çš„æ—¶é—´æ¼”åŒ–æè¿°ã€‚é€šè¿‡ç†µç¨³å®šæ€§æ–¹æ³•(Entropy Stability Methods)ï¼Œä½œè€…è¿›ä¸€æ­¥è¯æ˜äº†æ‰©æ•£æ¨¡å‹çš„é€†å‘æ—¶é—´åŠ¨åŠ›å­¦åœ¨ç´§æ”¯é›†æ•°æ®åˆ†å¸ƒä¸‹ä¼šé›†ä¸­äºæ•°æ®æµå½¢ï¼Œä¸”å½“$t \\to 0$æ—¶å…·æœ‰$\\sqrt{t}$é˜¶çš„é›†ä¸­ç‡ã€‚è¿™äº›ç»“æœä¸ºæ‰©æ•£è½¨è¿¹åœ¨ç²¾ç¡®åˆ†æ•°å¼•å¯¼ä¸‹å›å½’æ•°æ®æµå½¢å¹¶ä¿æŒæ¨¡ä»¿ä¿çœŸåº¦æä¾›äº†ç†è®ºä¿è¯ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜ä¸ºæ‰©æ•£æ¨¡å‹çš„è®¾è®¡æä¾›äº†å®é™…æŒ‡å¯¼ï¼ŒåŒ…æ‹¬åˆ†æ•°å‡½æ•°æ„å»ºã€æŸå¤±å…¬å¼åˆ¶å®šå’Œåœæ­¢æ—¶é—´é€‰æ‹©çš„åŸåˆ™æ€§æ ‡å‡†ã€‚æ€»ä½“è€Œè¨€ï¼Œè¯¥æ¡†æ¶å®šé‡åœ°è§£é‡Šäº†ç”Ÿæˆèƒ½åŠ›ä¸æ¨¡ä»¿ä¿çœŸåº¦ä¹‹é—´çš„æƒè¡¡ï¼Œå°†ä¸¥æ ¼çš„æ•°å­¦åˆ†æä¸æ¨¡å‹è®¾è®¡ç»Ÿä¸€åœ¨ä¸€ä¸ªè§†è§’ä¸‹ã€‚",
      "categories": [
        "math.OC",
        "cs.AI",
        "math.AP"
      ],
      "primary_category": "math.OC",
      "comment": "30 pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2511.05940v1",
      "published_date": "2025-11-08 09:19:25 UTC",
      "updated_date": "2025-11-08 09:19:25 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:47:57.246159+00:00"
    },
    {
      "arxiv_id": "2511.05936v1",
      "title": "10 Open Challenges Steering the Future of Vision-Language-Action Models",
      "title_zh": "å¼•é¢†è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹æœªæ¥çš„10å¤§å¼€æ”¾æ€§æŒ‘æˆ˜",
      "authors": [
        "Soujanya Poria",
        "Navonil Majumder",
        "Chia-Yu Hung",
        "Amir Ali Bagherzadeh",
        "Chuan Li",
        "Kenneth Kwok",
        "Ziwei Wang",
        "Cheston Tan",
        "Jiajun Wu",
        "David Hsu"
      ],
      "abstract": "Due to their ability of follow natural language instructions, vision-language-action (VLA) models are increasingly prevalent in the embodied AI arena, following the widespread success of their precursors -- LLMs and VLMs. In this paper, we discuss 10 principal milestones in the ongoing development of VLA models -- multimodality, reasoning, data, evaluation, cross-robot action generalization, efficiency, whole-body coordination, safety, agents, and coordination with humans. Furthermore, we discuss the emerging trends of using spatial understanding, modeling world dynamics, post training, and data synthesis -- all aiming to reach these milestones. Through these discussions, we hope to bring attention to the research avenues that may accelerate the development of VLA models into wider acceptability.",
      "tldr_zh": "è¯¥è®ºæ–‡é’ˆå¯¹å…·èº«æ™ºèƒ½(Embodied AI)é¢†åŸŸä¸­æ—¥ç›Šæµè¡Œçš„Vision-Language-Action (VLA) æ¨¡å‹è¿›è¡Œäº†æ·±å…¥æ¢è®¨ï¼ŒæŒ‡å‡ºäº†å¼•å¯¼å…¶æœªæ¥å‘å±•çš„åå¤§æ ¸å¿ƒæŒ‘æˆ˜ã€‚ä½œè€…è¯¦ç»†è®ºè¿°äº†VLAæ¨¡å‹æŒç»­å‘å±•ä¸­çš„åä¸ªä¸»è¦é‡Œç¨‹ç¢‘ï¼Œæ¶µç›–äº†multimodalityã€reasoningã€dataã€evaluationã€cross-robot action generalizationã€efficiencyã€whole-body coordinationã€safetyã€agentsä»¥åŠcoordination with humansç­‰å…³é”®æ–¹é¢ã€‚æ­¤å¤–ï¼Œæ–‡ç« è¿˜åˆ†æäº†ä¸ºå®ç°è¿™äº›é‡Œç¨‹ç¢‘è€Œæ¶Œç°çš„æ–°å…´è¶‹åŠ¿ï¼ŒåŒ…æ‹¬åˆ©ç”¨spatial understandingã€modeling world dynamicsã€post trainingä»¥åŠdata synthesisç­‰æŠ€æœ¯æ‰‹æ®µã€‚é€šè¿‡å¯¹è¿™äº›æŒ‘æˆ˜å’Œè¶‹åŠ¿çš„ç³»ç»Ÿæ€§æ¢³ç†ï¼Œè¯¥ç ”ç©¶æ—¨åœ¨å¼•èµ·å­¦æœ¯ç•Œå¯¹å…³é”®ç ”ç©¶è·¯å¾„çš„å…³æ³¨ï¼Œä»è€ŒåŠ é€ŸVLAæ¨¡å‹çš„å‘å±•å¹¶æ¨åŠ¨å…¶è·å¾—æ›´å¹¿æ³›çš„è®¤å¯ä¸åº”ç”¨ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "AAAI 2026 (Senior Track)",
      "pdf_url": "https://arxiv.org/pdf/2511.05936v1",
      "published_date": "2025-11-08 09:02:13 UTC",
      "updated_date": "2025-11-08 09:02:13 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:48:20.904116+00:00"
    },
    {
      "arxiv_id": "2511.05933v1",
      "title": "Reinforcement Learning Improves Traversal of Hierarchical Knowledge in LLMs",
      "title_zh": "å¼ºåŒ–å­¦ä¹ æå‡å¤§è¯­è¨€æ¨¡å‹çš„å±‚çº§çŸ¥è¯†éå†",
      "authors": [
        "Renfei Zhang",
        "Manasa Kaniselvan",
        "Niloofar Mireshghallah"
      ],
      "abstract": "Reinforcement learning (RL) is often credited with improving language model reasoning and generalization at the expense of degrading memorized knowledge. We challenge this narrative by observing that RL-enhanced models consistently outperform their base and supervised fine-tuned (SFT) counterparts on pure knowledge recall tasks, particularly those requiring traversal of hierarchical, structured knowledge (e.g., medical codes). We hypothesize these gains stem not from newly acquired data, but from improved procedural skills in navigating and searching existing knowledge hierarchies within the model parameters. To support this hypothesis, we show that structured prompting, which explicitly guides SFTed models through hierarchical traversal, recovers most of the performance gap (reducing 24pp to 7pp on MedConceptsQA for DeepSeek-V3/R1). We further find that while prompting improves final-answer accuracy, RL-enhanced models retain superior ability to recall correct procedural paths on deep-retrieval tasks. Finally our layer-wise internal activation analysis reveals that while factual representations (e.g., activations for the statement \"code 57.95 refers to urinary infection\") maintain high cosine similarity between SFT and RL models, query representations (e.g., \"what is code 57.95\") diverge noticeably, indicating that RL primarily transforms how models traverse knowledge rather than the knowledge representation itself.",
      "tldr_zh": "æœ¬ç ”ç©¶æŒ‘æˆ˜äº†å¼ºåŒ–å­¦ä¹ (Reinforcement Learning, RL)åœ¨æå‡å¤§è¯­è¨€æ¨¡å‹æ¨ç†èƒ½åŠ›çš„åŒæ—¶ä¼šæŸå®³è®°å¿†çŸ¥è¯†çš„æ™®éè§‚ç‚¹ã€‚ç ”ç©¶è§‚å¯Ÿå‘ç°ï¼Œç»è¿‡RLå¢å¼ºçš„æ¨¡å‹åœ¨çº¯çŸ¥è¯†å¬å›ä»»åŠ¡ï¼Œç‰¹åˆ«æ˜¯æ¶‰åŠå±‚çº§åŒ–ç»“æ„åŒ–çŸ¥è¯†(hierarchical, structured knowledge)éå†çš„ä»»åŠ¡ï¼ˆå¦‚åŒ»ç–—ä»£ç ï¼‰ä¸Šï¼Œè¡¨ç°ä¸€è‡´ä¼˜äºåŸºåº§æ¨¡å‹å’Œç›‘ç£å¾®è°ƒ(SFT)æ¨¡å‹ã€‚ä½œè€…å‡è®¾è¿™ç§æå‡æºäºæ¨¡å‹åœ¨å‚æ•°ç©ºé—´å†…å¯¼èˆªå’Œæœç´¢ç°æœ‰çŸ¥è¯†å±‚çº§çš„ç¨‹åºæ€§æŠ€èƒ½(procedural skills)çš„å¢å¼ºï¼Œè€Œéè·å–äº†æ–°æ•°æ®ã€‚ä¸ºäº†æ”¯æŒè¿™ä¸€å‡è®¾ï¼Œå®éªŒæ˜¾ç¤ºé€šè¿‡ç»“æ„åŒ–æç¤º(structured prompting)æ˜¾å¼å¼•å¯¼SFTæ¨¡å‹è¿›è¡Œå±‚çº§éå†ï¼Œå¯ä»¥å¼¥è¡¥å¤§éƒ¨åˆ†æ€§èƒ½å·®è·ï¼ˆä¾‹å¦‚åœ¨MedConceptsQAä¸Šå°†DeepSeek-V3/R1çš„å·®è·ä»24ppç¼©å°è‡³7ppï¼‰ã€‚è¿›ä¸€æ­¥ç ”ç©¶å‘ç°ï¼Œè™½ç„¶æç¤ºèƒ½æé«˜æœ€ç»ˆç­”æ¡ˆå‡†ç¡®ç‡ï¼Œä½†RLæ¨¡å‹åœ¨æ·±åº¦æ£€ç´¢ä»»åŠ¡ä¸­ä»ä¿ç•™äº†æ›´ä¼˜çš„æ­£ç¡®ç¨‹åºè·¯å¾„å¬å›èƒ½åŠ›ã€‚æœ€åï¼Œå±‚çº§å†…éƒ¨æ¿€æ´»åˆ†æ(layer-wise internal activation analysis)æ­ç¤ºï¼Œè™½ç„¶SFTå’ŒRLæ¨¡å‹çš„äº‹å®è¡¨å¾ä¿æŒé«˜åº¦ç›¸ä¼¼ï¼Œä½†æŸ¥è¯¢è¡¨å¾(query representations)å‡ºç°æ˜¾è‘—åˆ†æ­§ï¼Œè¿™è¡¨æ˜RLä¸»è¦è½¬å˜äº†æ¨¡å‹éå†çŸ¥è¯†çš„æ–¹å¼ï¼Œè€ŒéçŸ¥è¯†è¡¨å¾æœ¬èº«ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "`",
      "pdf_url": "https://arxiv.org/pdf/2511.05933v1",
      "published_date": "2025-11-08 08:56:29 UTC",
      "updated_date": "2025-11-08 08:56:29 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:49:04.664622+00:00"
    },
    {
      "arxiv_id": "2511.05932v1",
      "title": "The Future of AI in the GCC Post-NPM Landscape: A Comparative Analysis of Kuwait and the UAE",
      "title_zh": "æµ·åˆä¼šåæ–°å…¬å…±ç®¡ç†æ ¼å±€ä¸‹äººå·¥æ™ºèƒ½çš„æœªæ¥ï¼šç§‘å¨ç‰¹ä¸é˜¿è”é…‹çš„æ¯”è¾ƒåˆ†æ",
      "authors": [
        "Mohammad Rashed Albous",
        "Bedour Alboloushi",
        "Arnaud Lacheret"
      ],
      "abstract": "Comparative evidence on how Gulf Cooperation Council (GCC) states turn artificial intelligence (AI) ambitions into post--New Public Management (post-NPM) outcomes is scarce because most studies examine Western democracies. We analyze constitutional, collective-choice, and operational rules shaping AI uptake in two contrasting GCC members, the United Arab Emirates (UAE) and Kuwait, and whether they foster citizen centricity, collaborative governance, and public value creation. Anchored in Ostrom's Institutional Analysis and Development framework, the study combines a most similar/most different systems design with multiple sources: 62 public documents from 2018--2025, embedded UAE cases (Smart Dubai and MBZUAI), and 39 interviews with officials conducted Aug 2024--May 2025. Dual coding and process tracing connect rule configurations to AI performance. Cross-case analysis identifies four reinforcing mechanisms behind divergent trajectories. In the UAE, concentrated authority, credible sanctions, pro-innovation narratives, and flexible reinvestment rules scale pilots into hundreds of services and sizable recycled savings. In Kuwait, dispersed veto points, exhortative sanctions, cautious discourse, and lapsed AI budgets confine initiatives to pilot mode despite equivalent fiscal resources. The findings refine institutional theory by showing that vertical rule coherence, not wealth, determines AI's public-value yield, and temper post-NPM optimism by revealing that efficiency metrics serve societal goals only when backed by enforceable safeguards. To curb ethics washing and test transferability beyond the GCC, future work should track rule diffusion over time, develop blended legitimacy--efficiency scorecards, and examine how narrative framing shapes citizen consent for data sharing.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶åœ¨åæ–°å…¬å…±ç®¡ç†(post-NPM)èƒŒæ™¯ä¸‹ï¼Œå¯¹æ¯”åˆ†æäº†æµ·æ¹¾åˆä½œå§”å‘˜ä¼š(GCC)æˆå‘˜å›½é˜¿è”é…‹å’Œç§‘å¨ç‰¹çš„äººå·¥æ™ºèƒ½(AI)å®æ–½è·¯å¾„ã€‚åŸºäºOstromçš„åˆ¶åº¦åˆ†æä¸å‘å±•æ¡†æ¶(IAD)ï¼Œä½œè€…é€šè¿‡åˆ†æ62ä»½å…¬å…±æ–‡ä»¶ã€åµŒå…¥å¼æ¡ˆä¾‹ï¼ˆå¦‚Smart Dubaiï¼‰åŠ39æ¬¡è®¿è°ˆï¼Œåˆ©ç”¨è¿‡ç¨‹è¿½è¸ªè¿æ¥äº†è§„åˆ™é…ç½®ä¸AIç»©æ•ˆã€‚ç ”ç©¶å‘ç°ï¼Œå°½ç®¡ä¸¤å›½è´¢æ”¿èµ„æºç›¸å½“ï¼Œé˜¿è”é…‹å‡­å€Ÿé›†ä¸­çš„æƒåŠ›ã€å¯ä¿¡çš„åˆ¶è£å’Œçµæ´»çš„å†æŠ•èµ„è§„åˆ™ï¼ŒæˆåŠŸå°†è¯•ç‚¹æ‰©å±•ä¸ºæ•°ç™¾é¡¹æœåŠ¡ï¼›è€Œç§‘å¨ç‰¹å—é™äºåˆ†æ•£çš„å¦å†³ç‚¹å’Œé¢„ç®—å¤±æ•ˆï¼Œä»å±€é™äºè¯•ç‚¹æ¨¡å¼ã€‚ç»“æœè¡¨æ˜ï¼Œå†³å®šAIå…¬å…±ä»·å€¼äº§å‡ºçš„å…³é”®åœ¨äºå‚ç›´è§„åˆ™çš„ä¸€è‡´æ€§(vertical rule coherence)è€Œéå›½å®¶è´¢å¯Œã€‚è¯¥ç ”ç©¶ä¿®æ­£äº†åˆ¶åº¦ç†è®ºï¼ŒæŒ‡å‡ºæ•ˆç‡æŒ‡æ ‡åªæœ‰åœ¨å¯æ‰§è¡Œä¿éšœæªæ–½çš„æ”¯æŒä¸‹æ‰èƒ½æœåŠ¡äºç¤¾ä¼šç›®æ ‡ï¼Œå¹¶ä¸ºæœªæ¥å…³äºè§„åˆ™æ‰©æ•£å’Œä¼¦ç†æ¸…æ´—(ethics washing)çš„ç ”ç©¶æä¾›äº†æ–¹å‘ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "econ.TH"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.05932v1",
      "published_date": "2025-11-08 08:54:27 UTC",
      "updated_date": "2025-11-08 08:54:27 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:49:31.999866+00:00"
    },
    {
      "arxiv_id": "2511.05931v1",
      "title": "Self-Abstraction from Grounded Experience for Plan-Guided Policy Refinement",
      "title_zh": "åŸºäºå…·è±¡ç»éªŒè‡ªæˆ‘æŠ½è±¡çš„è®¡åˆ’å¼•å¯¼ç­–ç•¥ç²¾ç‚¼",
      "authors": [
        "Hiroaki Hayashi",
        "Bo Pang",
        "Wenting Zhao",
        "Ye Liu",
        "Akash Gokul",
        "Srijan Bansal",
        "Caiming Xiong",
        "Semih Yavuz",
        "Yingbo Zhou"
      ],
      "abstract": "Large language model (LLM) based agents are increasingly used to tackle software engineering tasks that require multi-step reasoning and code modification, demonstrating promising yet limited performance. However, most existing LLM agents typically operate within static execution frameworks, lacking a principled mechanism to learn and self-improve from their own experience and past rollouts. As a result, their performance remains bounded by the initial framework design and the underlying LLM's capabilities. We propose Self-Abstraction from Grounded Experience (SAGE), a framework that enables agents to learn from their own task executions and refine their behavior through self-abstraction. After an initial rollout, the agent induces a concise plan abstraction from its grounded experience, distilling key steps, dependencies, and constraints. This learned abstraction is then fed back as contextual guidance, refining the agent's policy and supporting more structured, informed subsequent executions. Empirically, SAGE delivers consistent performance gains across diverse LLM backbones and agent architectures. Notably, it yields a 7.2% relative performance improvement over the strong Mini-SWE-Agent baseline when paired with the GPT-5 (high) backbone. SAGE further achieves strong overall performance on SWE-Bench Verified benchmark, reaching 73.2% and 74% Pass@1 resolve rates with the Mini-SWE-Agent and OpenHands CodeAct agent framework, respectively.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹(LLM)çš„æ™ºèƒ½ä½“åœ¨è½¯ä»¶å·¥ç¨‹ä»»åŠ¡ä¸­ç¼ºä¹ä»è‡ªèº«ç»éªŒä¸­å­¦ä¹ å’Œè‡ªæˆ‘æ”¹è¿›æœºåˆ¶çš„é—®é¢˜ï¼Œæå‡ºäº†SAGE (Self-Abstraction from Grounded Experience) æ¡†æ¶ã€‚ç›®å‰çš„æ™ºèƒ½ä½“é€šå¸¸å—é™äºé™æ€æ‰§è¡Œæ¡†æ¶ï¼Œè€ŒSAGEå…è®¸æ™ºèƒ½ä½“ä»å®é™…ä»»åŠ¡æ‰§è¡Œä¸­è¿›è¡Œè‡ªæˆ‘æŠ½è±¡ï¼Œåœ¨åˆå§‹è¿è¡Œåå½’çº³å‡ºåŒ…å«å…³é”®æ­¥éª¤ã€ä¾èµ–å…³ç³»å’Œçº¦æŸçš„ç®€æ´è®¡åˆ’æŠ½è±¡ã€‚è¿™ç§å­¦ä¹ åˆ°çš„æŠ½è±¡éšåè¢«ä½œä¸ºä¸Šä¸‹æ–‡æŒ‡å¯¼åé¦ˆç»™ç³»ç»Ÿï¼Œç”¨äºä¼˜åŒ–æ™ºèƒ½ä½“ç­–ç•¥(Policy Refinement)å¹¶æ”¯æŒæ›´ç»“æ„åŒ–å’Œä¿¡æ¯ä¸°å¯Œçš„åç»­æ‰§è¡Œã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSAGEåœ¨å¤šç§LLMéª¨å¹²ç½‘å’Œæ™ºèƒ½ä½“æ¶æ„ä¸Šå‡èƒ½å¸¦æ¥æŒç»­çš„æ€§èƒ½æå‡ï¼Œç‰¹åˆ«æ˜¯åœ¨ä¸GPT-5 (high)éª¨å¹²ç½‘ç»“åˆæ—¶ï¼Œç›¸è¾ƒäºå¼ºåŸºçº¿Mini-SWE-Agentå®ç°äº†7.2%çš„ç›¸å¯¹æ€§èƒ½æå‡ã€‚æ­¤å¤–ï¼ŒSAGEåœ¨SWE-Bench VerifiedåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œåˆ†åˆ«åœ¨ä½¿ç”¨Mini-SWE-Agentå’ŒOpenHands CodeActæ¡†æ¶æ—¶è¾¾åˆ°äº†73.2%å’Œ74%çš„Pass@1è§£å†³ç‡ã€‚",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.05931v1",
      "published_date": "2025-11-08 08:49:38 UTC",
      "updated_date": "2025-11-08 08:49:38 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:50:25.197308+00:00"
    },
    {
      "arxiv_id": "2511.05929v1",
      "title": "CoMA: Complementary Masking and Hierarchical Dynamic Multi-Window Self-Attention in a Unified Pre-training Framework",
      "title_zh": "CoMAï¼šç»Ÿä¸€é¢„è®­ç»ƒæ¡†æ¶ä¸‹çš„äº’è¡¥æ©ç ä¸åˆ†å±‚åŠ¨æ€å¤šçª—å£è‡ªæ³¨æ„åŠ›",
      "authors": [
        "Jiaxuan Li",
        "Qing Xu",
        "Xiangjian He",
        "Ziyu Liu",
        "Chang Xing",
        "Zhen Chen",
        "Daokun Zhang",
        "Rong Qu",
        "Chang Wen Chen"
      ],
      "abstract": "Masked Autoencoders (MAE) achieve self-supervised learning of image representations by randomly removing a portion of visual tokens and reconstructing the original image as a pretext task, thereby significantly enhancing pretraining efficiency and yielding excellent adaptability across downstream tasks. However, MAE and other MAE-style paradigms that adopt random masking generally require more pre-training epochs to maintain adaptability. Meanwhile, ViT in MAE suffers from inefficient parameter use due to fixed spatial resolution across layers. To overcome these limitations, we propose the Complementary Masked Autoencoders (CoMA), which employ a complementary masking strategy to ensure uniform sampling across all pixels, thereby improving effective learning of all features and enhancing the model's adaptability. Furthermore, we introduce DyViT, a hierarchical vision transformer that employs a Dynamic Multi-Window Self-Attention (DM-MSA), significantly reducing the parameters and FLOPs while improving fine-grained feature learning. Pre-trained on ImageNet-1K with CoMA, DyViT matches the downstream performance of MAE using only 12% of the pre-training epochs, demonstrating more effective learning. It also attains a 10% reduction in pre-training time per epoch, further underscoring its superior pre-training efficiency.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹Masked Autoencoders (MAE)å› éšæœºæ©ç å¯¼è‡´é¢„è®­ç»ƒæ•ˆç‡ä½ä»¥åŠViTåœ¨å‚æ•°åˆ©ç”¨ä¸Šçš„å±€é™æ€§ï¼Œæå‡ºäº†ç»Ÿä¸€é¢„è®­ç»ƒæ¡†æ¶CoMA (Complementary Masked Autoencoders)ã€‚è¯¥æ¡†æ¶é‡‡ç”¨äº’è¡¥æ©ç ç­–ç•¥ä»¥ç¡®ä¿åƒç´ çš„å‡åŒ€é‡‡æ ·ï¼Œä»è€Œæœ‰æ•ˆæå‡ç‰¹å¾å­¦ä¹ å’Œæ¨¡å‹é€‚åº”æ€§ã€‚åŒæ—¶ï¼Œè®ºæ–‡å¼•å…¥äº†DyViTï¼Œä¸€ç§é‡‡ç”¨Dynamic Multi-Window Self-Attention (DM-MSA)çš„åˆ†å±‚è§†è§‰Transformerï¼Œåœ¨æ˜¾è‘—é™ä½å‚æ•°é‡å’ŒFLOPsçš„åŒæ—¶å¢å¼ºäº†ç»†ç²’åº¦ç‰¹å¾çš„å­¦ä¹ èƒ½åŠ›ã€‚åœ¨ImageNet-1Kä¸Šçš„å®éªŒæ˜¾ç¤ºï¼ŒåŸºäºCoMAé¢„è®­ç»ƒçš„DyViTä»…éœ€MAE 12%çš„é¢„è®­ç»ƒepochå³å¯è¾¾åˆ°ç›¸å½“çš„ä¸‹æ¸¸æ€§èƒ½ï¼Œä¸”æ¯epochè®­ç»ƒæ—¶é—´å‡å°‘10%ï¼Œå±•ç¤ºäº†å…¶ä¼˜è¶Šçš„é¢„è®­ç»ƒæ•ˆç‡ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2511.05929v1",
      "published_date": "2025-11-08 08:43:41 UTC",
      "updated_date": "2025-11-08 08:43:41 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:50:19.414339+00:00"
    },
    {
      "arxiv_id": "2511.05927v1",
      "title": "Artificial intelligence and the Gulf Cooperation Council workforce adapting to the future of work",
      "title_zh": "äººå·¥æ™ºèƒ½ä¸æµ·æ¹¾é˜¿æ‹‰ä¼¯å›½å®¶åˆä½œå§”å‘˜ä¼šåŠ³åŠ¨åŠ›é€‚åº”æœªæ¥å·¥ä½œ",
      "authors": [
        "Mohammad Rashed Albous",
        "Melodena Stephens",
        "Odeh Rashed Al-Jayyousi"
      ],
      "abstract": "The rapid expansion of artificial intelligence (AI) in the Gulf Cooperation Council (GCC) raises a central question: are investments in compute infrastructure matched by an equally robust build-out of skills, incentives, and governance? Grounded in socio-technical systems (STS) theory, this mixed-methods study audits workforce preparedness across Kingdom of Saudi Arabia (KSA), the United Arab Emirates (UAE), Qatar, Kuwait, Bahrain, and Oman. We combine term frequency--inverse document frequency (TF--IDF) analysis of six national AI strategies (NASs), an inventory of 47 publicly disclosed AI initiatives (January 2017--April 2025), paired case studies, the Mohamed bin Zayed University of Artificial Intelligence (MBZUAI) and the Saudi Data & Artificial Intelligence Authority (SDAIA) Academy, and a scenario matrix linking oil-revenue slack (technical capacity) to regulatory coherence (social alignment). Across the corpus, 34/47 initiatives (0.72; 95% Wilson CI 0.58--0.83) exhibit joint social--technical design; country-level indices span 0.57--0.90 (small n; intervals overlap). Scenario results suggest that, under our modeled conditions, regulatory convergence plausibly binds outcomes more than fiscal capacity: fragmented rules can offset high oil revenues, while harmonized standards help preserve progress under austerity. We also identify an emerging two-track talent system, research elites versus rapidly trained practitioners, that risks labor-market bifurcation without bridging mechanisms. By extending STS inquiry to oil-rich, state-led economies, the study refines theory and sets a research agenda focused on longitudinal coupling metrics, ethnographies of coordination, and outcome-based performance indicators.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶åŸºäºç¤¾ä¼šæŠ€æœ¯ç³»ç»Ÿ(STS)ç†è®ºï¼Œé‡‡ç”¨æ··åˆæ–¹æ³•è¯„ä¼°äº†æµ·æ¹¾é˜¿æ‹‰ä¼¯å›½å®¶åˆä½œå§”å‘˜ä¼š(GCC)æˆå‘˜å›½åœ¨äººå·¥æ™ºèƒ½æ—¶ä»£çš„åŠ³åŠ¨åŠ›å‡†å¤‡æƒ…å†µã€‚ç ”ç©¶ç»“åˆäº†å¯¹å…­ä¸ªå›½å®¶AIæˆ˜ç•¥(NASs)çš„TF-IDFåˆ†æã€47é¡¹å…¬å¼€AIå€¡è®®çš„æ¸…å•ã€ä»¥åŠé’ˆå¯¹MBZUAIå’ŒSDAIA Academyçš„é…å¯¹æ¡ˆä¾‹ç ”ç©¶ã€‚åˆ†æç»“æœæ˜¾ç¤ºï¼Œå¤§éƒ¨åˆ†å€¡è®®å±•ç°äº†ç¤¾ä¼š-æŠ€æœ¯è”åˆè®¾è®¡ï¼Œä¸”æƒ…æ™¯çŸ©é˜µè¡¨æ˜ï¼Œç›‘ç®¡çš„ä¸€è‡´æ€§æ¯”å•çº¯çš„è´¢æ”¿èƒ½åŠ›ï¼ˆçŸ³æ²¹æ”¶å…¥ï¼‰æ›´èƒ½å†³å®šå‘å±•çš„æˆè´¥ã€‚ç ”ç©¶è¿˜å‘ç°äº†ä¸€ç§æ–°å…´çš„åŒè½¨äººæ‰ä½“ç³»ï¼Œå³ç ”ç©¶ç²¾è‹±ä¸å¿«é€ŸåŸ¹è®­çš„ä»ä¸šè€…ä¹‹é—´çš„åˆ†åŒ–ï¼Œè‹¥ç¼ºä¹æ¡¥æ¥æœºåˆ¶å¯èƒ½å¯¼è‡´åŠ³åŠ¨åŠ›å¸‚åœºæ–­å±‚ã€‚è¯¥å·¥ä½œå°†STSç†è®ºæ‰©å±•åˆ°äº†çŸ³æ²¹ä¸°å¯Œçš„å›½å®¶ä¸»å¯¼å‹ç»æµä½“ï¼Œå¼ºè°ƒäº†åè°ƒæ ‡å‡†çš„é‡è¦æ€§ï¼Œå¹¶ä¸ºæœªæ¥çš„çºµå‘è€¦åˆæŒ‡æ ‡å’Œåè°ƒæ°‘æ—å¿—ç ”ç©¶å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "econ.GN"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.05927v1",
      "published_date": "2025-11-08 08:42:14 UTC",
      "updated_date": "2025-11-08 08:42:14 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:54:15.540848+00:00"
    },
    {
      "arxiv_id": "2511.05921v1",
      "title": "IDALC: A Semi-Supervised Framework for Intent Detection and Active Learning based Correction",
      "title_zh": "IDALCï¼šæ„å›¾æ£€æµ‹ä¸åŸºäºä¸»åŠ¨å­¦ä¹ ä¿®æ­£çš„åŠç›‘ç£æ¡†æ¶",
      "authors": [
        "Ankan Mullick",
        "Sukannya Purkayastha",
        "Saransh Sharma",
        "Pawan Goyal",
        "Niloy Ganguly"
      ],
      "abstract": "Voice-controlled dialog systems have become immensely popular due to their ability to perform a wide range of actions in response to diverse user queries. These agents possess a predefined set of skills or intents to fulfill specific user tasks. But every system has its own limitations. There are instances where, even for known intents, if any model exhibits low confidence, it results in rejection of utterances that necessitate manual annotation. Additionally, as time progresses, there may be a need to retrain these agents with new intents from the system-rejected queries to carry out additional tasks. Labeling all these emerging intents and rejected utterances over time is impractical, thus calling for an efficient mechanism to reduce annotation costs. In this paper, we introduce IDALC (Intent Detection and Active Learning based Correction), a semi-supervised framework designed to detect user intents and rectify system-rejected utterances while minimizing the need for human annotation. Empirical findings on various benchmark datasets demonstrate that our system surpasses baseline methods, achieving a 5-10% higher accuracy and a 4-8% improvement in macro-F1. Remarkably, we maintain the overall annotation cost at just 6-10% of the unlabelled data available to the system. The overall framework of IDALC is shown in Fig. 1",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†IDALCï¼ˆIntent Detection and Active Learning based Correctionï¼‰ï¼Œä¸€ç§æ—¨åœ¨è§£å†³è¯­éŸ³æ§åˆ¶å¯¹è¯ç³»ç»Ÿä¸­æ‰‹åŠ¨æ ‡æ³¨æˆæœ¬é«˜æ˜‚é—®é¢˜çš„åŠç›‘ç£æ¡†æ¶ã€‚é’ˆå¯¹ç³»ç»Ÿä¸­å› ä½ç½®ä¿¡åº¦è€Œè¢«æ‹’ç»çš„è¯è¯­ä»¥åŠéšæ—¶é—´æ¶Œç°çš„æ–°æ„å›¾ï¼ŒIDALCé€šè¿‡ç»“åˆæ„å›¾æ£€æµ‹å’Œä¸»åŠ¨å­¦ä¹ æœºåˆ¶ï¼Œåœ¨æœ€å°åŒ–äººå·¥æ ‡æ³¨éœ€æ±‚çš„åŒæ—¶æœ‰æ•ˆçº æ­£ç³»ç»Ÿæ‹’ç»çš„æŸ¥è¯¢ã€‚åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å®è¯ç ”ç©¶è¡¨æ˜ï¼Œè¯¥ç³»ç»Ÿä¼˜äºç°æœ‰åŸºçº¿æ–¹æ³•ï¼Œå‡†ç¡®ç‡æå‡äº†5-10%ï¼ŒMacro-F1åˆ†æ•°æå‡äº†4-8%ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œè¯¥æ¡†æ¶æˆåŠŸå°†æ€»ä½“æ ‡æ³¨æˆæœ¬æ§åˆ¶åœ¨å¯ç”¨æœªæ ‡æ³¨æ•°æ®çš„6-10%ä»¥å†…ï¼Œæ˜¾è‘—æé«˜äº†æ•°æ®å¤„ç†æ•ˆç‡ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Paper accepted in IEEE Transactions on Artificial Intelligence (October 2025)",
      "pdf_url": "https://arxiv.org/pdf/2511.05921v1",
      "published_date": "2025-11-08 08:32:59 UTC",
      "updated_date": "2025-11-08 08:32:59 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:54:01.145191+00:00"
    },
    {
      "arxiv_id": "2511.05920v1",
      "title": "IoT-based Fresh Produce Supply Chain Under Uncertainty: An Adaptive Optimization Framework",
      "title_zh": "ä¸ç¡®å®šç¯å¢ƒä¸‹åŸºäºç‰©è”ç½‘çš„ç”Ÿé²œå†œäº§å“ä¾›åº”é“¾ï¼šè‡ªé€‚åº”ä¼˜åŒ–æ¡†æ¶",
      "authors": [
        "Chirag Seth",
        "Mehrdad Pirnia",
        "James H Bookbinder"
      ],
      "abstract": "Fruits and vegetables form a vital component of the global economy; however, their distribution poses complex logistical challenges due to high perishability, supply fluctuations, strict quality and safety standards, and environmental sensitivity. In this paper, we propose an adaptive optimization model that accounts for delays, travel time, and associated temperature changes impacting produce shelf life, and compare it against traditional approaches such as Robust Optimization, Distributionally Robust Optimization, and Stochastic Programming. Additionally, we conduct a series of computational experiments using Internet of Things (IoT) sensor data to evaluate the performance of our proposed model. Our study demonstrates that the proposed adaptive model achieves a higher shelf life, extending it by over 18\\% compared to traditional optimization models, by dynamically mitigating temperature deviations through a temperature feedback mechanism. The promising results demonstrate the potential of this approach to improve both the freshness and efficiency of logistics systems an aspect often neglected in previous works.",
      "tldr_zh": "æœ¬æ–‡é’ˆå¯¹ç”Ÿé²œå†œäº§å“ä¾›åº”é“¾ä¸­é¢ä¸´çš„é«˜è…çƒ‚ç‡ã€ä¾›åº”æ³¢åŠ¨åŠç¯å¢ƒæ•æ„Ÿæ€§ç­‰ç‰©æµæŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºç‰©è”ç½‘(IoT)çš„è‡ªé€‚åº”ä¼˜åŒ–æ¨¡å‹(adaptive optimization model)ã€‚è¯¥æ¨¡å‹å……åˆ†è€ƒè™‘äº†è¿è¾“å»¶è¯¯ã€è¡Œç¨‹æ—¶é—´åŠç›¸å…³æ¸©åº¦å˜åŒ–å¯¹äº§å“ä¿è´¨æœŸçš„å½±å“ï¼Œå¹¶ä¸é²æ£’ä¼˜åŒ–(Robust Optimization)ã€åˆ†å¸ƒé²æ£’ä¼˜åŒ–(Distributionally Robust Optimization)å’Œéšæœºè§„åˆ’(Stochastic Programming)ç­‰ä¼ ç»Ÿæ–¹æ³•è¿›è¡Œäº†å¯¹æ¯”åˆ†æã€‚é€šè¿‡åˆ©ç”¨IoTä¼ æ„Ÿå™¨æ•°æ®è¿›è¡Œçš„è®¡ç®—å®éªŒï¼Œç ”ç©¶å±•ç¤ºäº†è¯¥æ¨¡å‹é€šè¿‡æ¸©åº¦åé¦ˆæœºåˆ¶åŠ¨æ€ç¼“è§£æ¸©åº¦åå·®çš„èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥è‡ªé€‚åº”æ¨¡å‹ç›¸æ¯”ä¼ ç»Ÿä¼˜åŒ–æ¨¡å‹èƒ½å°†äº§å“ä¿è´¨æœŸå»¶é•¿è¶…è¿‡18%ã€‚è¿™é¡¹ç ”ç©¶è¯å®äº†è¯¥æ–¹æ³•åœ¨æå‡ç‰©æµç³»ç»Ÿæ–°é²œåº¦å’Œæ•ˆç‡æ–¹é¢çš„æ½œåŠ›ï¼Œæœ‰æ•ˆå¼¥è¡¥äº†ä»¥å¾€ç ”ç©¶ä¸­çš„ä¸è¶³ã€‚",
      "categories": [
        "math.OC",
        "cs.AI"
      ],
      "primary_category": "math.OC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.05920v1",
      "published_date": "2025-11-08 08:31:23 UTC",
      "updated_date": "2025-11-08 08:31:23 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:54:26.397858+00:00"
    },
    {
      "arxiv_id": "2511.05919v2",
      "title": "Injecting Falsehoods: Adversarial Man-in-the-Middle Attacks Undermining Factual Recall in LLMs",
      "title_zh": "æ³¨å…¥è™šå‡ä¿¡æ¯ï¼šå¯¹æŠ—æ€§ä¸­é—´äººæ”»å‡»å‰Šå¼± LLM çš„äº‹å®è®°å¿†",
      "authors": [
        "Alina Fastowski",
        "Bardh Prenkaj",
        "Yuxiao Li",
        "Gjergji Kasneci"
      ],
      "abstract": "LLMs are now an integral part of information retrieval. As such, their role as question answering chatbots raises significant concerns due to their shown vulnerability to adversarial man-in-the-middle (MitM) attacks. Here, we propose the first principled attack evaluation on LLM factual memory under prompt injection via Xmera, our novel, theory-grounded MitM framework. By perturbing the input given to \"victim\" LLMs in three closed-book and fact-based QA settings, we undermine the correctness of the responses and assess the uncertainty of their generation process. Surprisingly, trivial instruction-based attacks report the highest success rate (up to ~85.3%) while simultaneously having a high uncertainty for incorrectly answered questions. To provide a simple defense mechanism against Xmera, we train Random Forest classifiers on the response uncertainty levels to distinguish between attacked and unattacked queries (average AUC of up to ~96%). We believe that signaling users to be cautious about the answers they receive from black-box and potentially corrupt LLMs is a first checkpoint toward user cyberspace safety.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨ä¿¡æ¯æ£€ç´¢ä¸­é¢ä¸´çš„å¯¹æŠ—æ€§ä¸­é—´äºº(MitM)æ”»å‡»é£é™©ï¼Œæå‡ºäº†é¦–ä¸ªåŸºäºç†è®ºçš„æ”»å‡»è¯„ä¼°æ¡†æ¶Xmeraï¼Œç”¨äºè¯„ä¼°æç¤ºæ³¨å…¥(prompt injection)ä¸‹LLMsçš„äº‹å®è®°å¿†èƒ½åŠ›ã€‚é€šè¿‡åœ¨ä¸‰ä¸ªé—­å·äº‹å®é—®ç­”åœºæ™¯ä¸­å¹²æ‰°è¾“å…¥ï¼Œç ”ç©¶è€…å‘ç°ç®€å•çš„åŸºäºæŒ‡ä»¤çš„æ”»å‡»ç«Ÿèƒ½è¾¾åˆ°é«˜è¾¾85.3%çš„æˆåŠŸç‡ï¼ŒåŒæ—¶é”™è¯¯å›ç­”è¡¨ç°å‡ºè¾ƒé«˜çš„ç”Ÿæˆä¸ç¡®å®šæ€§ã€‚é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œè¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§é˜²å¾¡æœºåˆ¶ï¼Œå³åˆ©ç”¨å“åº”çš„ä¸ç¡®å®šæ€§æ°´å¹³è®­ç»ƒéšæœºæ£®æ—(Random Forest)åˆ†ç±»å™¨ï¼Œä»¥åŒºåˆ†å—æ”»å‡»å’Œæœªå—æ”»å‡»çš„æŸ¥è¯¢ï¼Œå…¶å¹³å‡AUCè¾¾åˆ°çº¦96%ã€‚è¿™é¡¹å·¥ä½œä¸ä»…æ­ç¤ºäº†LLMsåœ¨å¯¹æŠ—ç¯å¢ƒä¸‹çš„è„†å¼±æ€§ï¼Œä¹Ÿä¸ºè¯†åˆ«æ½œåœ¨çš„æ¶æ„ç¯¡æ”¹æä¾›äº†æœ‰æ•ˆçš„æ£€æµ‹æ‰‹æ®µï¼Œä»è€Œæå‡ç”¨æˆ·åœ¨ç½‘ç»œç©ºé—´ä¸­çš„å®‰å…¨æ€§ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.05919v2",
      "published_date": "2025-11-08 08:30:19 UTC",
      "updated_date": "2025-11-20 10:04:04 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:54:56.974050+00:00"
    },
    {
      "arxiv_id": "2511.05913v1",
      "title": "NILC: Discovering New Intents with LLM-assisted Clustering",
      "title_zh": "NILCï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹è¾…åŠ©èšç±»çš„æ–°æ„å›¾å‘ç°",
      "authors": [
        "Hongtao Wang",
        "Renchi Yang",
        "Wenqing Lin"
      ],
      "abstract": "New intent discovery (NID) seeks to recognize both new and known intents from unlabeled user utterances, which finds prevalent use in practical dialogue systems. Existing works towards NID mainly adopt a cascaded architecture, wherein the first stage focuses on encoding the utterances into informative text embeddings beforehand, while the latter is to group similar embeddings into clusters (i.e., intents), typically by K-Means. However, such a cascaded pipeline fails to leverage the feedback from both steps for mutual refinement, and, meanwhile, the embedding-only clustering overlooks nuanced textual semantics, leading to suboptimal performance. To bridge this gap, this paper proposes NILC, a novel clustering framework specially catered for effective NID. Particularly, NILC follows an iterative workflow, in which clustering assignments are judiciously updated by carefully refining cluster centroids and text embeddings of uncertain utterances with the aid of large language models (LLMs). Specifically, NILC first taps into LLMs to create additional semantic centroids for clusters, thereby enriching the contextual semantics of the Euclidean centroids of embeddings. Moreover, LLMs are then harnessed to augment hard samples (ambiguous or terse utterances) identified from clusters via rewriting for subsequent cluster correction. Further, we inject supervision signals through non-trivial techniques seeding and soft must links for more accurate NID in the semi-supervised setting. Extensive experiments comparing NILC against multiple recent baselines under both unsupervised and semi-supervised settings showcase that NILC can achieve significant performance improvements over six benchmark datasets of diverse domains consistently.",
      "tldr_zh": "æœ¬æ–‡é’ˆå¯¹ç°æœ‰æ–°æ„å›¾å‘ç°(New Intent Discovery, NID)æ–¹æ³•ä¸­çº§è”æ¶æ„ç¼ºä¹ç›¸äº’ä¼˜åŒ–ä¸”å¿½ç•¥ç»†å¾®æ–‡æœ¬è¯­ä¹‰çš„é—®é¢˜ï¼Œæå‡ºäº†åä¸ºNILCçš„å…¨æ–°èšç±»æ¡†æ¶ã€‚NILCé‡‡ç”¨è¿­ä»£å·¥ä½œæµï¼Œåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(LLMs)è¾…åŠ©ä¼˜åŒ–èšç±»è´¨å¿ƒå’Œä¸ç¡®å®šè¯è¯­çš„æ–‡æœ¬åµŒå…¥ã€‚å…·ä½“è€Œè¨€ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨LLMsä¸ºèšç±»åˆ›å»ºé¢å¤–çš„è¯­ä¹‰è´¨å¿ƒï¼Œä»è€Œä¸°å¯Œäº†åµŒå…¥çš„æ¬§å‡ é‡Œå¾—è´¨å¿ƒçš„ä¸Šä¸‹æ–‡è¯­ä¹‰ã€‚åŒæ—¶ï¼ŒLLMsè¢«ç”¨äºé€šè¿‡é‡å†™æ¥å¢å¼ºè¯†åˆ«å‡ºçš„å›°éš¾æ ·æœ¬ï¼ˆæ¨¡ç³Šæˆ–ç®€çŸ­çš„è¯è¯­ï¼‰ï¼Œä»¥ä¾¿è¿›è¡Œåç»­çš„èšç±»ä¿®æ­£ã€‚æ­¤å¤–ï¼Œåœ¨åŠç›‘ç£è®¾ç½®ä¸‹ï¼Œç ”ç©¶å¼•å…¥äº†ç§å­åŒ–(seeding)å’Œè½¯å¿…é¡»é“¾æ¥(soft must links)æŠ€æœ¯æ¥æ³¨å…¥ç›‘ç£ä¿¡å·ä»¥æé«˜å‡†ç¡®æ€§ã€‚åœ¨å…­ä¸ªä¸åŒé¢†åŸŸçš„åŸºå‡†æ•°æ®é›†ä¸Šè¿›è¡Œçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œæ— è®ºæ˜¯åœ¨æ— ç›‘ç£è¿˜æ˜¯åŠç›‘ç£è®¾ç½®ä¸‹ï¼ŒNILCç›¸æ¯”ç°æœ‰çš„å¤šä¸ªåŸºçº¿æ¨¡å‹å‡å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.05913v1",
      "published_date": "2025-11-08 08:18:44 UTC",
      "updated_date": "2025-11-08 08:18:44 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:55:16.795850+00:00"
    },
    {
      "arxiv_id": "2511.05903v1",
      "title": "The Imperfect Learner: Incorporating Developmental Trajectories in Memory-based Student Simulation",
      "title_zh": "ä¸å®Œç¾çš„å­¦ä¹ è€…ï¼šèåˆå‘å±•è½¨è¿¹çš„åŸºäºè®°å¿†å­¦ç”Ÿæ¨¡æ‹Ÿ",
      "authors": [
        "Zhengyuan Liu",
        "Stella Xin Yin",
        "Bryan Chen Zhengyu Tan",
        "Roy Ka-Wei Lee",
        "Guimei Liu",
        "Dion Hoe-Lian Goh",
        "Wenya Wang",
        "Nancy F. Chen"
      ],
      "abstract": "User simulation is important for developing and evaluating human-centered AI, yet current student simulation in educational applications has significant limitations. Existing approaches focus on single learning experiences and do not account for students' gradual knowledge construction and evolving skill sets. Moreover, large language models are optimized to produce direct and accurate responses, making it challenging to represent the incomplete understanding and developmental constraints that characterize real learners. In this paper, we introduce a novel framework for memory-based student simulation that incorporates developmental trajectories through a hierarchical memory mechanism with structured knowledge representation. The framework also integrates metacognitive processes and personality traits to enrich the individual learner profiling, through dynamical consolidation of both cognitive development and personal learning characteristics. In practice, we implement a curriculum-aligned simulator grounded on the Next Generation Science Standards. Experimental results show that our approach can effectively reflect the gradual nature of knowledge development and the characteristic difficulties students face, providing a more accurate representation of learning processes.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰æ•™è‚²åº”ç”¨ä¸­å­¦ç”Ÿæ¨¡æ‹Ÿï¼ˆstudent simulationï¼‰å¿½ç•¥çŸ¥è¯†æ„å»ºæ¸è¿›æ€§ä»¥åŠå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰éš¾ä»¥æ¨¡æ‹Ÿå­¦ä¹ è€…ä¸å®Œæ•´ç†è§£çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ç»“åˆå‘å±•è½¨è¿¹ï¼ˆdevelopmental trajectoriesï¼‰çš„åŸºäºè®°å¿†çš„å­¦ç”Ÿæ¨¡æ‹Ÿæ–°æ¡†æ¶ã€‚è¯¥æ¡†æ¶é‡‡ç”¨å…·æœ‰ç»“æ„åŒ–çŸ¥è¯†è¡¨ç¤ºï¼ˆstructured knowledge representationï¼‰çš„åˆ†å±‚è®°å¿†æœºåˆ¶ï¼ˆhierarchical memory mechanismï¼‰ï¼Œå¹¶æ•´åˆäº†å…ƒè®¤çŸ¥è¿‡ç¨‹ï¼ˆmetacognitive processesï¼‰å’Œä¸ªæ€§ç‰¹å¾ï¼ˆpersonality traitsï¼‰ï¼Œé€šè¿‡åŠ¨æ€å·©å›ºè®¤çŸ¥å‘å±•å’Œä¸ªäººå­¦ä¹ ç‰¹ç‚¹æ¥ä¸°å¯Œä¸ªä½“å­¦ä¹ è€…ç”»åƒã€‚ä½œè€…åŸºäºä¸‹ä¸€ä»£ç§‘å­¦æ ‡å‡†ï¼ˆNext Generation Science Standardsï¼‰å®ç°äº†ä¸è¯¾ç¨‹å¯¹é½çš„æ¨¡æ‹Ÿå™¨ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåæ˜ çŸ¥è¯†å‘å±•çš„æ¸è¿›æœ¬è´¨ä»¥åŠå­¦ç”Ÿé¢ä¸´çš„å…¸å‹å›°éš¾ï¼Œä»è€Œä¸ºå­¦ä¹ è¿‡ç¨‹æä¾›äº†æ›´å‡†ç¡®çš„è¡¨å¾ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.05903v1",
      "published_date": "2025-11-08 08:05:43 UTC",
      "updated_date": "2025-11-08 08:05:43 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:56:11.190326+00:00"
    },
    {
      "arxiv_id": "2511.05901v2",
      "title": "Retrieval-Augmented Generation in Medicine: A Scoping Review of Technical Implementations, Clinical Applications, and Ethical Considerations",
      "title_zh": "åŒ»å­¦é¢†åŸŸçš„æ£€ç´¢å¢å¼ºç”Ÿæˆï¼šæŠ€æœ¯å®ç°ã€ä¸´åºŠåº”ç”¨ä¸ä¼¦ç†è€ƒé‡çš„èŒƒå›´ç»¼è¿°",
      "authors": [
        "Rui Yang",
        "Matthew Yu Heng Wong",
        "Huitao Li",
        "Xin Li",
        "Wentao Zhu",
        "Jingchi Liao",
        "Kunyu Yu",
        "Jonathan Chong Kai Liew",
        "Weihao Xuan",
        "Yingjian Chen",
        "Yuhe Ke",
        "Jasmine Chiat Ling Ong",
        "Douglas Teodoro",
        "Chuan Hong",
        "Daniel Shi Wei Ting",
        "Nan Liu"
      ],
      "abstract": "The rapid growth of medical knowledge and increasing complexity of clinical practice pose challenges. In this context, large language models (LLMs) have demonstrated value; however, inherent limitations remain. Retrieval-augmented generation (RAG) technologies show potential to enhance their clinical applicability. This study reviewed RAG applications in medicine. We found that research primarily relied on publicly available data, with limited application in private data. For retrieval, approaches commonly relied on English-centric embedding models, while LLMs were mostly generic, with limited use of medical-specific LLMs. For evaluation, automated metrics evaluated generation quality and task performance, whereas human evaluation focused on accuracy, completeness, relevance, and fluency, with insufficient attention to bias and safety. RAG applications were concentrated on question answering, report generation, text summarization, and information extraction. Overall, medical RAG remains at an early stage, requiring advances in clinical validation, cross-linguistic adaptation, and support for low-resource settings to enable trustworthy and responsible global use.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶å¯¹åŒ»å­¦é¢†åŸŸçš„æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRetrieval-Augmented Generation, RAGï¼‰æŠ€æœ¯è¿›è¡Œäº†èŒƒå›´ç»¼è¿°ï¼Œåˆ†æäº†å…¶æŠ€æœ¯å®ç°ã€ä¸´åºŠåº”ç”¨åŠä¼¦ç†è€ƒé‡ã€‚ç ”ç©¶å‘ç°ï¼Œç°æœ‰å·¥ä½œä¸»è¦ä¾èµ–å…¬å¼€æ•°æ®ï¼Œå¯¹ç§æœ‰æ•°æ®çš„åº”ç”¨æœ‰é™ï¼Œä¸”æ£€ç´¢ç¯èŠ‚å¤šé‡‡ç”¨ä»¥è‹±è¯­ä¸ºä¸­å¿ƒçš„åµŒå…¥æ¨¡å‹ï¼Œç”Ÿæˆç¯èŠ‚å¤šä½¿ç”¨é€šç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ï¼Œè¾ƒå°‘æ¶‰åŠåŒ»å­¦ä¸“ç”¨æ¨¡å‹ã€‚åœ¨è¯„ä¼°æ–¹æ³•ä¸Šï¼Œè‡ªåŠ¨åŒ–æŒ‡æ ‡ä¸»è¦è¡¡é‡ç”Ÿæˆè´¨é‡å’Œä»»åŠ¡è¡¨ç°ï¼Œäººå·¥è¯„ä¼°è™½ä¾§é‡å‡†ç¡®æ€§ä¸å®Œæ•´æ€§ï¼Œä½†å¯¹åè§å’Œå®‰å…¨æ€§çš„å…³æ³¨æ˜æ˜¾ä¸è¶³ã€‚ç›®å‰ï¼ŒåŒ»ç–—RAGçš„åº”ç”¨ä¸»è¦é›†ä¸­åœ¨é—®ç­”ã€æŠ¥å‘Šç”Ÿæˆã€æ–‡æœ¬æ‘˜è¦å’Œä¿¡æ¯æå–ç­‰ä»»åŠ¡ä¸­ã€‚æ€»ä½“è€Œè¨€ï¼Œè¯¥é¢†åŸŸä»å¤„äºæ—©æœŸé˜¶æ®µï¼Œæœªæ¥éœ€åŠ å¼ºä¸´åºŠéªŒè¯ã€è·¨è¯­è¨€é€‚åº”æ€§åŠå¯¹ä½èµ„æºç¯å¢ƒçš„æ”¯æŒï¼Œä»¥æ¨åŠ¨å…¶åœ¨å…¨çƒèŒƒå›´å†…å¯ä¿¡ä¸”è´Ÿè´£ä»»çš„åº”ç”¨ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.05901v2",
      "published_date": "2025-11-08 07:52:47 UTC",
      "updated_date": "2025-11-13 06:14:22 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:56:48.889635+00:00"
    },
    {
      "arxiv_id": "2511.05898v1",
      "title": "GABFusion: Rethinking Feature Fusion for Low-Bit Quantization of Multi-Task Networks",
      "title_zh": "GABFusionï¼šå¤šä»»åŠ¡ç½‘ç»œä½æ¯”ç‰¹é‡åŒ–ç‰¹å¾èåˆçš„å†æ€è€ƒ",
      "authors": [
        "Zhaoyang Wang",
        "Dong Wang"
      ],
      "abstract": "Despite the effectiveness of quantization-aware training (QAT) in compressing deep neural networks, its performance on multi-task architectures often degrades significantly due to task-specific feature discrepancies and gradient conflicts. To address these challenges, we propose Gradient-Aware Balanced Feature Fusion (GABFusion), which dynamically balances gradient magnitudes and fuses task-specific features in a quantization-friendly manner. We further introduce Attention Distribution Alignment (ADA), a feature-level distillation strategy tailored for quantized models. Our method demonstrates strong generalization across network architectures and QAT algorithms, with theoretical guarantees on gradient bias reduction. Extensive experiments demonstrate that our strategy consistently enhances a variety of QAT methods across different network architectures and bit-widths. On PASCAL VOC and COCO datasets, the proposed approach achieves average mAP improvements of approximately 3.3% and 1.6%, respectively. When applied to YOLOv5 under 4-bit quantization, our method narrows the accuracy gap with the full-precision model to only 1.7% on VOC, showcasing its effectiveness in preserving performance under low-bit constraints. Notably, the proposed framework is modular, easy to integrate, and compatible with any existing QAT technique-enhancing the performance of quantized models without requiring modifications to the original network architecture.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šä»»åŠ¡ç½‘ç»œåœ¨é‡åŒ–æ„ŸçŸ¥è®­ç»ƒ(QAT)ä¸­å› ä»»åŠ¡ç‰¹å®šç‰¹å¾å·®å¼‚å’Œæ¢¯åº¦å†²çªå¯¼è‡´çš„æ€§èƒ½ä¸‹é™é—®é¢˜ï¼Œæå‡ºäº†Gradient-Aware Balanced Feature Fusion (GABFusion)æ¡†æ¶ã€‚GABFusioné€šè¿‡åŠ¨æ€å¹³è¡¡æ¢¯åº¦å¹…åº¦å’Œä»¥åˆ©äºé‡åŒ–çš„æ–¹å¼èåˆä»»åŠ¡ç‰¹å®šç‰¹å¾æ¥è§£å†³ä¸Šè¿°æŒ‘æˆ˜ï¼ŒåŒæ—¶å¼•å…¥äº†é’ˆå¯¹é‡åŒ–æ¨¡å‹å®šåˆ¶çš„ç‰¹å¾çº§è’¸é¦ç­–ç•¥Attention Distribution Alignment (ADA)ã€‚è¯¥æ–¹æ³•åœ¨ç†è®ºä¸Šä¿è¯äº†æ¢¯åº¦åå·®çš„å‡å°‘ï¼Œå¹¶åœ¨ä¸åŒç½‘ç»œæ¶æ„å’ŒQATç®—æ³•ä¸­å±•ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥ç­–ç•¥æ˜¾è‘—æå‡äº†å„ç±»QATæ–¹æ³•çš„æ€§èƒ½ï¼Œåœ¨PASCAL VOCå’ŒCOCOæ•°æ®é›†ä¸Šå¹³å‡mAPåˆ†åˆ«æå‡äº†çº¦3.3%å’Œ1.6%ã€‚ç‰¹åˆ«æ˜¯åœ¨4-bité‡åŒ–ä¸‹çš„YOLOv5æ¨¡å‹ä¸­ï¼Œè¯¥æ–¹æ³•å°†ä¸å…¨ç²¾åº¦æ¨¡å‹çš„ç²¾åº¦å·®è·ç¼©å°è‡³ä»…1.7%ï¼Œè¯æ˜äº†å…¶åœ¨ä½æ¯”ç‰¹çº¦æŸä¸‹çš„æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶å…·æœ‰æ¨¡å—åŒ–å’Œæ˜“é›†æˆçš„ç‰¹ç‚¹ï¼Œèƒ½å¤Ÿæ— ç¼å¢å¼ºç°æœ‰çš„QATæŠ€æœ¯è€Œæ— éœ€ä¿®æ”¹åŸå§‹ç½‘ç»œæ¶æ„ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages,6 figures",
      "pdf_url": "https://arxiv.org/pdf/2511.05898v1",
      "published_date": "2025-11-08 07:45:21 UTC",
      "updated_date": "2025-11-08 07:45:21 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:57:41.429833+00:00"
    },
    {
      "arxiv_id": "2511.05885v2",
      "title": "A Remarkably Efficient Paradigm to Multimodal Large Language Models for Sequential Recommendation",
      "title_zh": "é¢å‘åºåˆ—æ¨èçš„æé«˜æ•ˆå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹èŒƒå¼",
      "authors": [
        "Qiyong Zhong",
        "Jiajie Su",
        "Ming Yang",
        "Yunshan Ma",
        "Xiaolin Zheng",
        "Chaochao Chen"
      ],
      "abstract": "Sequential recommendations (SR) predict users' future interactions based on their historical behavior. The rise of Large Language Models (LLMs) has brought powerful generative and reasoning capabilities, significantly enhancing SR performance, while Multimodal LLMs (MLLMs) further extend this by introducing data like images and interactive relationships. However, critical issues remain, i.e., (a) Suboptimal item representations caused by lengthy and redundant descriptions, leading to inefficiencies in both training and inference; (b) Modality-related cognitive bias, as LLMs are predominantly pretrained on textual data, limiting their ability to effectively integrate and utilize non-textual modalities; (c) Weakening sequential perception in long interaction sequences, where attention mechanisms struggle to capture earlier interactions, hindering the modeling of long-range dependencies. To address these issues, we propose Speeder, an efficient MLLM-based paradigm for SR featuring three key innovations: 1) Multimodal Representation Compression (MRC), which condenses item attributes into concise yet informative tokens, reducing redundancy and computational cost; 2) Modality-aware Progressive Optimization (MPO), enabling gradual learning of multimodal representations; 3) Sequential Position Awareness Enhancement (SPAE), improving the LLM's capability to capture both relative and absolute sequential dependencies in long interaction sequences. Extensive experiments on real-world datasets demonstrate the effectiveness and efficiency of Speeder. Speeder increases training speed to 250% of the original while reducing inference time to 25% on the Amazon dataset.",
      "tldr_zh": "è¿™ç¯‡è®ºæ–‡é’ˆå¯¹åºåˆ—æ¨è(Sequential Recommendations, SR)ä»»åŠ¡ï¼ŒæŒ‡å‡ºç°æœ‰çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLMs)é¢ä¸´ç‰©å“æè¿°å†—é•¿å¯¼è‡´æ•ˆç‡ä½ä¸‹ã€æ¨¡æ€è®¤çŸ¥åå·®ä»¥åŠé•¿åºåˆ—æ„ŸçŸ¥èƒ½åŠ›å‡å¼±ç­‰å…³é”®é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶è€…æå‡ºäº†Speederï¼Œä¸€ç§é«˜æ•ˆçš„åŸºäºMLLMçš„åºåˆ—æ¨èèŒƒå¼ï¼ŒåŒ…å«ä¸‰ä¸ªæ ¸å¿ƒåˆ›æ–°ç‚¹ã€‚é¦–å…ˆï¼Œåˆ©ç”¨å¤šæ¨¡æ€è¡¨ç¤ºå‹ç¼©(Multimodal Representation Compression, MRC)å°†ç‰©å“å±æ€§å‹ç¼©ä¸ºç®€æ´ä¸”ä¿¡æ¯ä¸°å¯Œçš„tokenï¼Œæ˜¾è‘—é™ä½äº†è®¡ç®—å†—ä½™å’Œæˆæœ¬ï¼›å…¶æ¬¡ï¼Œé€šè¿‡æ¨¡æ€æ„ŸçŸ¥æ¸è¿›ä¼˜åŒ–(Modality-aware Progressive Optimization, MPO)ç­–ç•¥å®ç°äº†å¤šæ¨¡æ€è¡¨ç¤ºçš„é€æ­¥å­¦ä¹ ï¼›æœ€åï¼Œé‡‡ç”¨åºåˆ—ä½ç½®æ„ŸçŸ¥å¢å¼º(Sequential Position Awareness Enhancement, SPAE)æå‡äº†æ¨¡å‹åœ¨é•¿äº¤äº’åºåˆ—ä¸­æ•æ‰ç›¸å¯¹å’Œç»å¯¹ä¾èµ–å…³ç³»çš„èƒ½åŠ›ã€‚åœ¨çœŸå®æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒSpeederä¸ä»…æœ‰æ•ˆï¼Œè€Œä¸”æ•ˆç‡æé«˜ï¼Œåœ¨Amazonæ•°æ®é›†ä¸Šå°†è®­ç»ƒé€Ÿåº¦æå‡è‡³åŸæ¥çš„250%ï¼ŒåŒæ—¶å°†æ¨ç†æ—¶é—´ç¼©å‡è‡³25%ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.05885v2",
      "published_date": "2025-11-08 06:51:38 UTC",
      "updated_date": "2025-11-11 08:48:10 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:57:36.452396+00:00"
    },
    {
      "arxiv_id": "2511.05883v1",
      "title": "Unveiling Modality Bias: Automated Sample-Specific Analysis for Multimodal Misinformation Benchmarks",
      "title_zh": "æ­ç¤ºæ¨¡æ€åå·®ï¼šé¢å‘å¤šæ¨¡æ€è™šå‡ä¿¡æ¯åŸºå‡†çš„è‡ªåŠ¨åŒ–æ ·æœ¬çº§åˆ†æ",
      "authors": [
        "Hehai Lin",
        "Hui Liu",
        "Shilei Cao",
        "Jing Li",
        "Haoliang Li",
        "Wenya Wang"
      ],
      "abstract": "Numerous multimodal misinformation benchmarks exhibit bias toward specific modalities, allowing detectors to make predictions based solely on one modality. While previous research has quantified bias at the dataset level or manually identified spurious correlations between modalities and labels, these approaches lack meaningful insights at the sample level and struggle to scale to the vast amount of online information. In this paper, we investigate the design for automated recognition of modality bias at the sample level. Specifically, we propose three bias quantification methods based on theories/views of different levels of granularity: 1) a coarse-grained evaluation of modality benefit; 2) a medium-grained quantification of information flow; and 3) a fine-grained causality analysis. To verify the effectiveness, we conduct a human evaluation on two popular benchmarks. Experimental results reveal three interesting findings that provide potential direction toward future research: 1)~Ensembling multiple views is crucial for reliable automated analysis; 2)~Automated analysis is prone to detector-induced fluctuations; and 3)~Different views produce a higher agreement on modality-balanced samples but diverge on biased ones.",
      "tldr_zh": "æœ¬æ–‡é’ˆå¯¹å¤šæ¨¡æ€è™šå‡ä¿¡æ¯åŸºå‡†æµ‹è¯•ä¸­å­˜åœ¨çš„æ¨¡æ€åå·®é—®é¢˜ï¼Œå³æ£€æµ‹å™¨ä»…ä¾èµ–å•ä¸€æ¨¡æ€è¿›è¡Œé¢„æµ‹çš„ç°è±¡ï¼Œè¿›è¡Œäº†æ·±å…¥ç ”ç©¶ã€‚é‰´äºç°æœ‰æ–¹æ³•å±€é™äºæ•°æ®é›†å±‚é¢æˆ–ä¾èµ–äººå·¥è¯†åˆ«ï¼Œç¼ºä¹æ ·æœ¬å±‚é¢çš„æ´å¯Ÿä¸”éš¾ä»¥æ‰©å±•ï¼Œä½œè€…æå‡ºäº†ä¸€ç§è‡ªåŠ¨åŒ–çš„æ ·æœ¬çº§åå·®è¯†åˆ«æ¡†æ¶ã€‚è¯¥æ¡†æ¶åŒ…å«ä¸‰ç§åŸºäºä¸åŒç²’åº¦çš„é‡åŒ–æ–¹æ³•ï¼šç²—ç²’åº¦çš„æ¨¡æ€æ”¶ç›Šè¯„ä¼°ã€ä¸­ç²’åº¦çš„ä¿¡æ¯æµ(Information Flow)é‡åŒ–ä»¥åŠç»†ç²’åº¦çš„å› æœå…³ç³»åˆ†æ(Causality Analysis)ã€‚é€šè¿‡åœ¨ä¸¤ä¸ªæµè¡ŒåŸºå‡†ä¸Šè¿›è¡Œäººå·¥è¯„ä¼°ï¼Œç ”ç©¶éªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œé›†æˆå¤šä¸ªè§†è§’å¯¹äºå¯é çš„è‡ªåŠ¨åŒ–åˆ†æè‡³å…³é‡è¦ï¼Œä¸”è‡ªåŠ¨åŒ–åˆ†ææ˜“å—æ£€æµ‹å™¨æ³¢åŠ¨å½±å“ï¼ŒåŒæ—¶ä¸åŒè§†è§’åœ¨æ¨¡æ€å¹³è¡¡æ ·æœ¬ä¸Šä¸€è‡´æ€§è¾ƒé«˜ï¼Œä½†åœ¨åå·®æ ·æœ¬ä¸Šå­˜åœ¨åˆ†æ­§ï¼Œä¸ºæœªæ¥ç ”ç©¶æä¾›äº†æ–¹å‘ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.05883v1",
      "published_date": "2025-11-08 06:48:19 UTC",
      "updated_date": "2025-11-08 06:48:19 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:58:00.631939+00:00"
    },
    {
      "arxiv_id": "2511.05879v2",
      "title": "Physics-Informed Neural Networks for Real-Time Gas Crossover Prediction in PEM Electrolyzers: First Application with Multi-Membrane Validation",
      "title_zh": "ç”¨äºPEMç”µè§£æ§½å®æ—¶æ°”ä½“æ¸—é€é¢„æµ‹çš„ç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œï¼šåŸºäºå¤šè†œéªŒè¯çš„é¦–æ¬¡åº”ç”¨",
      "authors": [
        "Yong-Woon Kim",
        "Chulung Kang",
        "Yung-Cheol Byun"
      ],
      "abstract": "Green hydrogen production via polymer electrolyte membrane (PEM) water electrolysis is pivotal for energy transition, yet hydrogen crossover through membranes threatens safety and economic viability-approaching explosive limits (4 mol% H$_2$ in O$_2$) while reducing Faradaic efficiency by 2.5%. Current physics-based models require extensive calibration and computational resources that preclude real-time implementation, while purely data-driven approaches fail to extrapolate beyond training conditions-critical for dynamic electrolyzer operation. Here we present the first application of physics-informed neural networks (PINNs) for hydrogen crossover prediction, integrating mass conservation, Fick's diffusion law, and Henry's solubility law within a compact architecture (17,793 parameters). Validated across six membranes under industrially relevant conditions (0.05-5.0 A/cm$^2$, 1-200 bar, 25-85Â°C), our PINN achieves exceptional accuracy (R$^{2}$ = 99.84% $\\pm$ 0.15\\%, RMSE = 0.0932% $\\pm$ 0.0438%) based on five-fold cross-validation, with sub-millisecond inference times suitable for real-time control. Remarkably, the model maintains R$^2$ > 86% when predicting crossover at pressures 2.5x beyond training range-substantially outperforming pure neural networks (R$^2$ = 43.4%). The hardware-agnostic deployment, from desktop CPUs to edge devices (Raspberry Pi 4), enables distributed safety monitoring essential for gigawatt-scale installations. By bridging physical rigor and computational efficiency, this work establishes a new paradigm for real-time electrolyzer monitoring, accelerating deployment of safe, efficient green hydrogen infrastructure crucial for net-zero emissions targets.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é’ˆå¯¹è´¨å­äº¤æ¢è†œ(PEM)æ°´ç”µè§£åˆ¶æ°¢è¿‡ç¨‹ä¸­æ°¢æ°”æ¸—é€å¸¦æ¥çš„å®‰å…¨ä¸æ•ˆç‡é—®é¢˜ï¼Œé¦–æ¬¡æå‡ºäº†åº”ç”¨ç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œ(PINNs)è¿›è¡Œå®æ—¶é¢„æµ‹çš„è§£å†³æ–¹æ¡ˆã€‚è¯¥æ–¹æ³•å°†è´¨é‡å®ˆæ’ã€Fickæ‰©æ•£å®šå¾‹å’ŒHenryæº¶è§£åº¦å®šå¾‹æ•´åˆè¿›ç´§å‡‘çš„ç¥ç»ç½‘ç»œæ¶æ„ä¸­ï¼Œæœ‰æ•ˆå…‹æœäº†ä¼ ç»Ÿç‰©ç†æ¨¡å‹è®¡ç®—å¤æ‚å’Œçº¯æ•°æ®é©±åŠ¨æ¨¡å‹å¤–æ¨èƒ½åŠ›ä¸è¶³çš„å±€é™ã€‚åœ¨æ¶‰åŠå…­ç§ä¸åŒè†œææ–™åŠå¹¿æ³›å·¥ä¸šå·¥å†µçš„éªŒè¯ä¸­ï¼Œè¯¥æ¨¡å‹å±•ç°äº†å“è¶Šçš„å‡†ç¡®æ€§(RÂ² = 99.84%)å’Œäºšæ¯«ç§’çº§çš„æ¨ç†é€Ÿåº¦ï¼Œé€‚ç”¨äºå®æ—¶æ§åˆ¶ç³»ç»Ÿã€‚å®éªŒè¡¨æ˜ï¼Œå³ä½¿åœ¨å‹åŠ›è¶…å‡ºè®­ç»ƒèŒƒå›´2.5å€çš„æ¡ä»¶ä¸‹ï¼Œè¯¥æ¨¡å‹ä»èƒ½ä¿æŒè¶…è¿‡86%çš„RÂ²ï¼Œæ˜¾è‘—ä¼˜äºçº¯ç¥ç»ç½‘ç»œæ¨¡å‹ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ¡ˆæ”¯æŒä»æ¡Œé¢CPUåˆ°Raspberry Piç­‰è¾¹ç¼˜è®¾å¤‡çš„è·¨ç¡¬ä»¶éƒ¨ç½²ï¼Œä¸ºå‰ç“¦çº§å¤§è§„æ¨¡ç”µè§£æ§½è®¾æ–½æä¾›äº†å¯é çš„åˆ†å¸ƒå¼å®‰å…¨ç›‘æ§æ‰‹æ®µï¼ŒåŠ©åŠ›ç»¿è‰²æ°¢èƒ½åŸºç¡€è®¾æ–½çš„å»ºè®¾ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.05879v2",
      "published_date": "2025-11-08 06:41:39 UTC",
      "updated_date": "2025-11-18 11:54:56 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:01:14.688558+00:00"
    },
    {
      "arxiv_id": "2511.05875v1",
      "title": "Towards a Humanized Social-Media Ecosystem: AI-Augmented HCI Design Patterns for Safety, Agency & Well-Being",
      "title_zh": "è¿ˆå‘äººæ€§åŒ–çš„ç¤¾äº¤åª’ä½“ç”Ÿæ€ç³»ç»Ÿï¼šé¢å‘å®‰å…¨ã€è‡ªä¸»æƒä¸ç¦ç¥‰çš„AIå¢å¼ºå‹äººæœºäº¤äº’è®¾è®¡æ¨¡å¼",
      "authors": [
        "Mohd Ruhul Ameen",
        "Akif Islam"
      ],
      "abstract": "Social platforms connect billions of people, yet their engagement-first algorithms often work on users rather than with them, amplifying stress, misinformation, and a loss of control. We propose Human-Layer AI (HL-AI)--user-owned, explainable intermediaries that sit in the browser between platform logic and the interface. HL-AI gives people practical, moment-to-moment control without requiring platform cooperation. We contribute a working Chrome/Edge prototype implementing five representative pattern frameworks--Context-Aware Post Rewriter, Post Integrity Meter, Granular Feed Curator, Micro-Withdrawal Agent, and Recovery Mode--alongside a unifying mathematical formulation balancing user utility, autonomy costs, and risk thresholds. Evaluation spans technical accuracy, usability, and behavioral outcomes. The result is a suite of humane controls that help users rewrite before harm, read with integrity cues, tune feeds with intention, pause compulsive loops, and seek shelter during harassment, all while preserving agency through explanations and override options. This prototype offers a practical path to retrofit today's feeds with safety, agency, and well-being, inviting rigorous cross-cultural user evaluation.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç¤¾äº¤åª’ä½“å¹³å°ç®—æ³•ä¼˜å…ˆè€ƒè™‘å‚ä¸åº¦ä»è€Œå¯¼è‡´ç”¨æˆ·å‹åŠ›å’Œå¤±æ§çš„é—®é¢˜ï¼Œæå‡ºäº†Human-Layer AI (HL-AI)æ¦‚å¿µã€‚HL-AIæ˜¯ä¸€ç§ä½äºæµè§ˆå™¨ç«¯ã€ç”¨æˆ·è‡ªæ§ä¸”å¯è§£é‡Šçš„ä¸­ä»‹å±‚ï¼Œèƒ½å¤Ÿåœ¨æ— éœ€å¹³å°é…åˆçš„æƒ…å†µä¸‹èµ‹äºˆç”¨æˆ·å®æ—¶çš„æ§åˆ¶æƒã€‚ç ”ç©¶å›¢é˜Ÿå¼€å‘äº†ä¸€ä¸ªChrome/EdgeåŸå‹ï¼Œå®ç°äº†äº”ç§ä»£è¡¨æ€§çš„è®¾è®¡æ¨¡å¼ï¼šContext-Aware Post Rewriterã€Post Integrity Meterã€Granular Feed Curatorã€Micro-Withdrawal Agentå’ŒRecovery Modeã€‚åŒæ—¶ï¼Œè®ºæ–‡æå‡ºäº†ä¸€å¥—ç»Ÿä¸€çš„æ•°å­¦å…¬å¼ï¼Œç”¨äºå¹³è¡¡ç”¨æˆ·æ•ˆç”¨ã€è‡ªä¸»æˆæœ¬å’Œé£é™©é˜ˆå€¼ã€‚é€šè¿‡æ¶µç›–æŠ€æœ¯å‡†ç¡®æ€§ã€å¯ç”¨æ€§å’Œè¡Œä¸ºç»“æœçš„è¯„ä¼°ï¼Œè¯¥ç³»ç»Ÿå¸®åŠ©ç”¨æˆ·åœ¨å‘å¸ƒæœ‰å®³å†…å®¹å‰è¿›è¡Œé‡å†™ã€è¯†åˆ«ä¿¡æ¯å®Œæ•´æ€§ã€æœ‰æ„å›¾åœ°è°ƒæ•´ä¿¡æ¯æµã€æš‚åœå¼ºè¿«æ€§å¾ªç¯ä»¥åŠåœ¨é­é‡éªšæ‰°æ—¶å¯»æ±‚åº‡æŠ¤ã€‚è¿™é¡¹å·¥ä½œä¸ºæ”¹é€ ç°æœ‰ç¤¾äº¤åª’ä½“ä¿¡æ¯æµæä¾›äº†ä¸€æ¡åˆ‡å®å¯è¡Œçš„è·¯å¾„ï¼Œåœ¨ä¿éšœå®‰å…¨å’Œç¦ç¥‰çš„åŒæ—¶ï¼Œé€šè¿‡è§£é‡Šæœºåˆ¶å’Œè¦†ç›–é€‰é¡¹ä¿ç•™äº†ç”¨æˆ·çš„ä»£ç†æƒ(Agency)ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.HC",
      "comment": "6 pages, 5 tables, 7 figures, and 2 algorithm tables. Accepted at International Conference on Signal Processing, Information, Communication and Systems (SPICSCON 2025)",
      "pdf_url": "https://arxiv.org/pdf/2511.05875v1",
      "published_date": "2025-11-08 06:22:15 UTC",
      "updated_date": "2025-11-08 06:22:15 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:01:38.717095+00:00"
    },
    {
      "arxiv_id": "2511.05874v1",
      "title": "An Empirical Study of Reasoning Steps in Thinking Code LLMs",
      "title_zh": "æ€è€ƒå‹ä»£ç å¤§æ¨¡å‹æ¨ç†æ­¥éª¤çš„å®è¯ç ”ç©¶",
      "authors": [
        "Haoran Xue",
        "Gias Uddin",
        "Song Wang"
      ],
      "abstract": "Thinking Large Language Models (LLMs) generate explicit intermediate reasoning traces before final answers, potentially improving transparency, interpretability, and solution accuracy for code generation. However, the quality of these reasoning chains remains underexplored. We present a comprehensive empirical study examining the reasoning process and quality of thinking LLMs for code generation. We evaluate six state-of-the-art reasoning LLMs (DeepSeek-R1, OpenAI-o3-mini, Claude-3.7-Sonnet-Thinking, Gemini-2.0-Flash-Thinking, Gemini-2.5-Flash, and Qwen-QwQ) across 100 code generation tasks of varying difficulty from BigCodeBench. We quantify reasoning-chain structure through step counts and verbosity, conduct controlled step-budget adjustments, and perform a 21-participant human evaluation across three dimensions: efficiency, logical correctness, and completeness. Our step-count interventions reveal that targeted step increases can improve resolution rates for certain models/tasks, while modest reductions often preserve success on standard tasks, rarely on hard ones. Through systematic analysis, we develop a reasoning-problematic taxonomy, identifying completeness as the dominant failure mode. Task complexity significantly impacts reasoning quality; hard problems are substantially more prone to incompleteness than standard tasks. Our stability analysis demonstrates that thinking LLMs maintain consistent logical structures across computational effort levels and can self-correct previous errors. This study provides new insights into the strengths and limitations of current thinking LLMs in software engineering.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹Thinking LLMsåœ¨ä»£ç ç”Ÿæˆä»»åŠ¡ä¸­çš„ä¸­é—´æ¨ç†æ­¥éª¤è´¨é‡è¿›è¡Œäº†å…¨é¢çš„å®è¯åˆ†æã€‚ç ”ç©¶è€…åœ¨BigCodeBenchæ•°æ®é›†ä¸Šé€‰å–äº†100ä¸ªä¸åŒéš¾åº¦çš„ä»»åŠ¡ï¼Œè¯„ä¼°äº†DeepSeek-R1ã€OpenAI-o3-miniå’ŒClaude-3.7-Sonnet-Thinkingç­‰å…­ä¸ªæœ€å…ˆè¿›çš„æ¨ç†æ¨¡å‹ã€‚é€šè¿‡é‡åŒ–æ¨ç†é“¾ç»“æ„ã€æ§åˆ¶æ­¥éª¤é¢„ç®—ä»¥åŠæ¶‰åŠ21åå‚ä¸è€…çš„äººå·¥è¯„ä¼°ï¼Œç ”ç©¶è€ƒå¯Ÿäº†æ¨ç†çš„æ•ˆç‡ã€é€»è¾‘æ­£ç¡®æ€§å’Œå®Œæ•´æ€§ã€‚å®éªŒå‘ç°ï¼Œæœ‰é’ˆå¯¹æ€§åœ°å¢åŠ æ¨ç†æ­¥éª¤èƒ½æå‡ç‰¹å®šä»»åŠ¡çš„è§£å†³ç‡ï¼Œè€Œé€‚åº¦å‡å°‘æ­¥éª¤è™½èƒ½ç»´æŒæ ‡å‡†ä»»åŠ¡çš„æˆåŠŸç‡ï¼Œä½†åœ¨å›°éš¾ä»»åŠ¡ä¸Šå¾€å¾€å¤±æ•ˆã€‚ç ”ç©¶è¿›ä¸€æ­¥æ„å»ºäº†æ¨ç†é—®é¢˜åˆ†ç±»ä½“ç³»ï¼ˆreasoning-problematic taxonomyï¼‰ï¼ŒæŒ‡å‡ºâ€œå®Œæ•´æ€§â€ï¼ˆcompletenessï¼‰æ˜¯ä¸»è¦çš„å¤±è´¥æ¨¡å¼ï¼Œä¸”ä»»åŠ¡å¤æ‚åº¦æ˜¾è‘—å½±å“æ¨ç†è´¨é‡ã€‚æ­¤å¤–ï¼Œç¨³å®šæ€§åˆ†æè¡¨æ˜Thinking LLMsåœ¨ä¸åŒè®¡ç®—æŠ•å…¥ä¸‹èƒ½ä¿æŒä¸€è‡´çš„é€»è¾‘ç»“æ„ï¼Œå¹¶å…·å¤‡è‡ªæˆ‘çº æ­£å…ˆå‰é”™è¯¯çš„èƒ½åŠ›ï¼Œè¯¥å·¥ä½œæ·±å…¥æ­ç¤ºäº†å½“å‰æ¨¡å‹åœ¨è½¯ä»¶å·¥ç¨‹é¢†åŸŸçš„ä¼˜åŠ¿ä¸å±€é™ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.05874v1",
      "published_date": "2025-11-08 06:18:48 UTC",
      "updated_date": "2025-11-08 06:18:48 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:02:04.336497+00:00"
    },
    {
      "arxiv_id": "2511.05873v2",
      "title": "EndoIR: Degradation-Agnostic All-in-One Endoscopic Image Restoration via Noise-Aware Routing Diffusion",
      "title_zh": "EndoIRï¼šåŸºäºå™ªå£°æ„ŸçŸ¥è·¯ç”±æ‰©æ•£çš„é€€åŒ–æ— å…³ä¸€ä½“åŒ–å†…çª¥é•œå›¾åƒå¤åŸ",
      "authors": [
        "Tong Chen",
        "Xinyu Ma",
        "Long Bai",
        "Wenyang Wang",
        "Yue Sun",
        "Luping Zhou"
      ],
      "abstract": "Endoscopic images often suffer from diverse and co-occurring degradations such as low lighting, smoke, and bleeding, which obscure critical clinical details. Existing restoration methods are typically task-specific and often require prior knowledge of the degradation type, limiting their robustness in real-world clinical use. We propose EndoIR, an all-in-one, degradation-agnostic diffusion-based framework that restores multiple degradation types using a single model. EndoIR introduces a Dual-Domain Prompter that extracts joint spatial-frequency features, coupled with an adaptive embedding that encodes both shared and task-specific cues as conditioning for denoising. To mitigate feature confusion in conventional concatenation-based conditioning, we design a Dual-Stream Diffusion architecture that processes clean and degraded inputs separately, with a Rectified Fusion Block integrating them in a structured, degradation-aware manner. Furthermore, Noise-Aware Routing Block improves efficiency by dynamically selecting only noise-relevant features during denoising. Experiments on SegSTRONG-C and CEC datasets demonstrate that EndoIR achieves state-of-the-art performance across multiple degradation scenarios while using fewer parameters than strong baselines, and downstream segmentation experiments confirm its clinical utility.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†EndoIRï¼Œä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„å…¨èƒ½å‹ã€é€€åŒ–æ— å…³çš„å†…çª¥é•œå›¾åƒæ¢å¤æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä½å…‰ç…§ã€çƒŸé›¾å’Œå‡ºè¡€ç­‰å¤šç§ä¸”å…±å­˜çš„å›¾åƒé€€åŒ–é—®é¢˜ï¼Œä¸”æ— éœ€é¢„çŸ¥å…·ä½“çš„é€€åŒ–ç±»å‹ã€‚è¯¥æ¨¡å‹å¼•å…¥äº†Dual-Domain Prompteræ¥æå–è”åˆç©ºé—´-é¢‘ç‡ç‰¹å¾ï¼Œå¹¶åˆ©ç”¨è‡ªé€‚åº”åµŒå…¥ç¼–ç å…±äº«åŠä»»åŠ¡ç‰¹å®šçš„çº¿ç´¢ä½œä¸ºå»å™ªæ¡ä»¶ã€‚é’ˆå¯¹ä¼ ç»Ÿæ‹¼æ¥è°ƒèŠ‚å¯èƒ½å¯¼è‡´çš„ç‰¹å¾æ··æ·†é—®é¢˜ï¼Œç ”ç©¶è®¾è®¡äº†Dual-Stream Diffusionæ¶æ„åˆ†åˆ«å¤„ç†æ¸…æ™°å’Œé€€åŒ–è¾“å…¥ï¼Œå¹¶é€šè¿‡Rectified Fusion Blockä»¥ç»“æ„åŒ–æ–¹å¼è¿›è¡Œèåˆã€‚æ­¤å¤–ï¼Œé€šè¿‡Noise-Aware Routing BlockåŠ¨æ€é€‰æ‹©å™ªå£°ç›¸å…³ç‰¹å¾ï¼Œè¿›ä¸€æ­¥æé«˜äº†å»å™ªè¿‡ç¨‹çš„æ•ˆç‡ã€‚åœ¨SegSTRONG-Cå’ŒCECæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒEndoIRåœ¨å¤šç§é€€åŒ–åœºæ™¯ä¸‹å‡å–å¾—äº†æœ€å…ˆè¿›ï¼ˆSOTAï¼‰çš„æ€§èƒ½ï¼Œä¸”å‚æ•°é‡æ›´å°‘ï¼Œä¸‹æ¸¸åˆ†å‰²ä»»åŠ¡ä¹ŸéªŒè¯äº†å…¶ä¸´åºŠåº”ç”¨ä»·å€¼ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.RO"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.05873v2",
      "published_date": "2025-11-08 06:17:51 UTC",
      "updated_date": "2025-11-11 01:49:50 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:02:25.804977+00:00"
    },
    {
      "arxiv_id": "2511.05872v1",
      "title": "Adaptation and Fine-tuning with TabPFN for Travelling Salesman Problem",
      "title_zh": "åŸºäº TabPFN çš„æ—…è¡Œå•†é—®é¢˜é€‚é…ä¸å¾®è°ƒ",
      "authors": [
        "Nguyen Gia Hien Vu",
        "Yifan Tang",
        "Rey Lim",
        "Yifan Yang",
        "Hang Ma",
        "Ke Wang",
        "G. Gary Wang"
      ],
      "abstract": "Tabular Prior-Data Fitted Network (TabPFN) is a foundation model designed for small to medium-sized tabular data, which has attracted much attention recently. This paper investigates the application of TabPFN in Combinatorial Optimization (CO) problems. The aim is to lessen challenges in time and data-intensive training requirements often observed in using traditional methods including exact and heuristic algorithms, Machine Learning (ML)-based models, to solve CO problems. Proposing possibly the first ever application of TabPFN for such a purpose, we adapt and fine-tune the TabPFN model to solve the Travelling Salesman Problem (TSP), one of the most well-known CO problems. Specifically, we adopt the node-based approach and the node-predicting adaptation strategy to construct the entire TSP route. Our evaluation with varying instance sizes confirms that TabPFN requires minimal training, adapts to TSP using a single sample, performs better generalization across varying TSP instance sizes, and reduces performance degradation. Furthermore, the training process with adaptation and fine-tuning is completed within minutes. The methodology leads to strong solution quality even without post-processing and achieves performance comparable to other models with post-processing refinement. Our findings suggest that the TabPFN model is a promising approach to solve structured and CO problems efficiently under training resource constraints and rapid deployment requirements.",
      "tldr_zh": "è¯¥ç ”ç©¶é¦–æ¬¡æå‡ºå°†é’ˆå¯¹è¡¨æ ¼æ•°æ®çš„Tabular Prior-Data Fitted Network (TabPFN) åŸºç¡€æ¨¡å‹åº”ç”¨äºè§£å†³ç»„åˆä¼˜åŒ–(CO)é—®é¢˜ï¼Œå…·ä½“é’ˆå¯¹æ—…è¡Œå•†é—®é¢˜(TSP)è¿›è¡Œäº†é€‚é…ä¸å¾®è°ƒã€‚é’ˆå¯¹ä¼ ç»Ÿç®—æ³•å’Œæœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒè€—æ—¶ä¸”æ•°æ®å¯†é›†çš„é—®é¢˜ï¼Œä½œè€…é‡‡ç”¨äº†åŸºäºèŠ‚ç‚¹çš„æ–¹æ³•(node-based approach)å’ŒèŠ‚ç‚¹é¢„æµ‹é€‚é…ç­–ç•¥(node-predicting adaptation strategy)æ¥æ„å»ºå®Œæ•´çš„TSPè·¯å¾„ã€‚å®éªŒè¯„ä¼°è¡¨æ˜ï¼ŒTabPFNä»…éœ€æå°‘çš„è®­ç»ƒæ•°æ®ï¼Œç”šè‡³é€šè¿‡å•æ ·æœ¬å³å¯é€‚åº”TSPä»»åŠ¡ï¼Œå¹¶åœ¨ä¸åŒè§„æ¨¡çš„å®ä¾‹ä¸­å±•ç°å‡ºä¼˜å¼‚çš„æ³›åŒ–èƒ½åŠ›å’Œè¾ƒä½çš„æ€§èƒ½è¡°å‡ã€‚æ•´ä¸ªé€‚é…ä¸å¾®è°ƒè¿‡ç¨‹ä»…éœ€æ•°åˆ†é’Ÿå³å¯å®Œæˆï¼Œä¸”åœ¨ä¸è¿›è¡Œåå¤„ç†çš„æƒ…å†µä¸‹å°±èƒ½è·å¾—é«˜è´¨é‡çš„è§£ï¼Œå…¶æ€§èƒ½å¯ä¸ç»è¿‡åå¤„ç†ä¼˜åŒ–çš„å…¶ä»–æ¨¡å‹ç›¸åª²ç¾ã€‚è¯¥ç ”ç©¶è¯å®äº†TabPFNæ˜¯åœ¨è®­ç»ƒèµ„æºå—é™å’Œå¿«é€Ÿéƒ¨ç½²éœ€æ±‚ä¸‹ï¼Œé«˜æ•ˆè§£å†³ç»“æ„åŒ–åŠç»„åˆä¼˜åŒ–é—®é¢˜çš„æ½œåŠ›æ–¹æ³•ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.CO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.05872v1",
      "published_date": "2025-11-08 06:16:11 UTC",
      "updated_date": "2025-11-08 06:16:11 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:03:05.784093+00:00"
    },
    {
      "arxiv_id": "2511.05865v2",
      "title": "CGCE: Classifier-Guided Concept Erasure in Generative Models",
      "title_zh": "CGCEï¼šç”Ÿæˆæ¨¡å‹ä¸­åˆ†ç±»å™¨å¼•å¯¼çš„æ¦‚å¿µæ“¦é™¤",
      "authors": [
        "Viet Nguyen",
        "Vishal M. Patel"
      ],
      "abstract": "Recent advancements in large-scale generative models have enabled the creation of high-quality images and videos, but have also raised significant safety concerns regarding the generation of unsafe content. To mitigate this, concept erasure methods have been developed to remove undesirable concepts from pre-trained models. However, existing methods remain vulnerable to adversarial attacks that can regenerate the erased content. Moreover, achieving robust erasure often degrades the model's generative quality for safe, unrelated concepts, creating a difficult trade-off between safety and performance. To address this challenge, we introduce Classifier-Guided Concept Erasure (CGCE), an efficient plug-and-play framework that provides robust concept erasure for diverse generative models without altering their original weights. CGCE uses a lightweight classifier operating on text embeddings to first detect and then refine prompts containing undesired concepts. This approach is highly scalable, allowing for multi-concept erasure by aggregating guidance from several classifiers. By modifying only unsafe embeddings at inference time, our method prevents harmful content generation while preserving the model's original quality on benign prompts. Extensive experiments show that CGCE achieves state-of-the-art robustness against a wide range of red-teaming attacks. Our approach also maintains high generative utility, demonstrating a superior balance between safety and performance. We showcase the versatility of CGCE through its successful application to various modern T2I and T2V models, establishing it as a practical and effective solution for safe generative AI.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç”Ÿæˆæ¨¡å‹ä¸­ä¸å®‰å…¨å†…å®¹ç”Ÿæˆçš„é—®é¢˜ï¼Œæå‡ºäº†CGCE (Classifier-Guided Concept Erasure)ï¼Œä¸€ç§æ— éœ€ä¿®æ”¹æ¨¡å‹åŸå§‹æƒé‡çš„é«˜æ•ˆå³æ’å³ç”¨æ¡†æ¶ã€‚ç°æœ‰çš„æ¦‚å¿µæ¶ˆé™¤æ–¹æ³•å¾€å¾€éš¾ä»¥å…¼é¡¾å®‰å…¨æ€§å’Œç”Ÿæˆè´¨é‡ï¼Œä¸”æ˜“å—å¯¹æŠ—æ€§æ”»å‡»å½±å“ï¼Œè€ŒCGCEé€šè¿‡åœ¨æ–‡æœ¬åµŒå…¥å±‚å¼•å…¥è½»é‡çº§åˆ†ç±»å™¨æ¥æ£€æµ‹å¹¶ä¿®æ­£åŒ…å«ä¸è‰¯æ¦‚å¿µçš„æç¤ºè¯ï¼ˆPromptsï¼‰ã€‚è¯¥æ–¹æ³•åœ¨æ¨ç†é˜¶æ®µä»…é’ˆå¯¹ä¸å®‰å…¨çš„åµŒå…¥è¿›è¡Œä¿®æ”¹ï¼Œä»è€Œåœ¨æœ‰æ•ˆé˜²æ­¢æœ‰å®³å†…å®¹ç”Ÿæˆçš„åŒæ—¶ï¼Œä¿ç•™äº†æ¨¡å‹å¯¹è‰¯æ€§æç¤ºçš„åŸå§‹ç”Ÿæˆè´¨é‡ã€‚æ­¤å¤–ï¼ŒCGCEå…·æœ‰é«˜åº¦çš„å¯æ‰©å±•æ€§ï¼Œèƒ½å¤Ÿé€šè¿‡èšåˆå¤šä¸ªåˆ†ç±»å™¨çš„å¼•å¯¼å®ç°å¤šæ¦‚å¿µæ¶ˆé™¤ã€‚å¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼ŒCGCEåœ¨æŠµå¾¡å„ç§çº¢é˜Ÿæ”»å‡»ï¼ˆRed-teaming attacksï¼‰æ–¹é¢è¾¾åˆ°äº†æœ€å…ˆè¿›ï¼ˆSOTAï¼‰çš„é²æ£’æ€§ï¼Œå¹¶åœ¨å®‰å…¨æ€§å’Œæ€§èƒ½ä¹‹é—´å–å¾—äº†ä¼˜å¼‚çš„å¹³è¡¡ã€‚è¯¥æ–¹æ³•å·²æˆåŠŸåº”ç”¨äºå¤šç§ç°ä»£æ–‡æœ¬ç”Ÿæˆå›¾åƒï¼ˆT2Iï¼‰å’Œæ–‡æœ¬ç”Ÿæˆè§†é¢‘ï¼ˆT2Vï¼‰æ¨¡å‹ï¼Œè¯æ˜äº†å…¶ä½œä¸ºå®‰å…¨ç”Ÿæˆå¼AIè§£å†³æ–¹æ¡ˆçš„é€šç”¨æ€§å’Œå®ç”¨æ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CV",
      "comment": "26 pages, 17 figures",
      "pdf_url": "https://arxiv.org/pdf/2511.05865v2",
      "published_date": "2025-11-08 05:38:18 UTC",
      "updated_date": "2025-11-25 17:27:33 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:03:12.744008+00:00"
    },
    {
      "arxiv_id": "2511.05863v2",
      "title": "EMOD: A Unified EEG Emotion Representation Framework Leveraging V-A Guided Contrastive Learning",
      "title_zh": "EMODï¼šåŸºäºV-Aå¼•å¯¼å¯¹æ¯”å­¦ä¹ çš„ç»Ÿä¸€è„‘ç”µæƒ…æ„Ÿè¡¨å¾æ¡†æ¶",
      "authors": [
        "Yuning Chen",
        "Sha Zhao",
        "Shijian Li",
        "Gang Pan"
      ],
      "abstract": "Emotion recognition from EEG signals is essential for affective computing and has been widely explored using deep learning. While recent deep learning approaches have achieved strong performance on single EEG emotion datasets, their generalization across datasets remains limited due to the heterogeneity in annotation schemes and data formats. Existing models typically require dataset-specific architectures tailored to input structure and lack semantic alignment across diverse emotion labels. To address these challenges, we propose EMOD: A Unified EEG Emotion Representation Framework Leveraging Valence-Arousal (V-A) Guided Contrastive Learning. EMOD learns transferable and emotion-aware representations from heterogeneous datasets by bridging both semantic and structural gaps. Specifically, we project discrete and continuous emotion labels into a unified V-A space and formulate a soft-weighted supervised contrastive loss that encourages emotionally similar samples to cluster in the latent space. To accommodate variable EEG formats, EMOD employs a flexible backbone comprising a Triple-Domain Encoder followed by a Spatial-Temporal Transformer, enabling robust extraction and integration of temporal, spectral, and spatial features. We pretrain EMOD on 8 public EEG datasets and evaluate its performance on three benchmark datasets. Experimental results show that EMOD achieves the state-of-the-art performance, demonstrating strong adaptability and generalization across diverse EEG-based emotion recognition scenarios.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è„‘ç”µ(EEG)æƒ…æ„Ÿè¯†åˆ«ä¸­å› æ ‡æ³¨æ–¹æ¡ˆå’Œæ•°æ®æ ¼å¼å¼‚è´¨æ€§å¯¼è‡´è·¨æ•°æ®é›†æ³›åŒ–èƒ½åŠ›å—é™çš„é—®é¢˜ï¼Œæå‡ºäº†EMODæ¡†æ¶ã€‚EMODåˆ©ç”¨Valence-Arousal (V-A)å¼•å¯¼çš„å¯¹æ¯”å­¦ä¹ ï¼Œé€šè¿‡å¼¥åˆè¯­ä¹‰å’Œç»“æ„å·®è·æ¥å­¦ä¹ å¯è¿ç§»çš„æƒ…æ„Ÿè¡¨å¾ã€‚å…·ä½“è€Œè¨€ï¼Œè¯¥æ–¹æ³•å°†ç¦»æ•£å’Œè¿ç»­çš„æƒ…æ„Ÿæ ‡ç­¾æŠ•å½±åˆ°ç»Ÿä¸€çš„V-Aç©ºé—´ï¼Œå¹¶åˆ¶å®šäº†ä¸€ç§è½¯åŠ æƒç›‘ç£å¯¹æ¯”æŸå¤±(soft-weighted supervised contrastive loss)ï¼Œä¿ƒä½¿æƒ…æ„Ÿç›¸ä¼¼çš„æ ·æœ¬åœ¨æ½œåœ¨ç©ºé—´ä¸­èšé›†ã€‚ä¸ºäº†é€‚åº”å¯å˜çš„EEGæ ¼å¼ï¼ŒEMODé‡‡ç”¨ç”±Triple-Domain Encoderå’ŒSpatial-Temporal Transformerç»„æˆçš„çµæ´»éª¨å¹²ç½‘ç»œï¼Œå®ç°äº†å¯¹æ—¶åŸŸã€é¢‘åŸŸå’Œç©ºåŸŸç‰¹å¾çš„é²æ£’æå–ä¸èåˆã€‚åœ¨8ä¸ªå…¬å…±æ•°æ®é›†ä¸Šè¿›è¡Œé¢„è®­ç»ƒå¹¶åœ¨ä¸‰ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šè¯„ä¼°çš„ç»“æœæ˜¾ç¤ºï¼ŒEMODè¾¾åˆ°äº†æœ€å…ˆè¿›(SOTA)çš„æ€§èƒ½ï¼Œè¯æ˜äº†å…¶åœ¨å¤šæ ·åŒ–EEGæƒ…æ„Ÿè¯†åˆ«åœºæ™¯ä¸­çš„å¼ºå¤§é€‚åº”æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.05863v2",
      "published_date": "2025-11-08 05:37:16 UTC",
      "updated_date": "2025-11-14 08:21:44 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:03:44.282976+00:00"
    },
    {
      "arxiv_id": "2511.05859v1",
      "title": "Predicting the Future by Retrieving the Past",
      "title_zh": "é€šè¿‡æ£€ç´¢å†å²é¢„æµ‹æœªæ¥",
      "authors": [
        "Dazhao Du",
        "Tao Han",
        "Song Guo"
      ],
      "abstract": "Deep learning models such as MLP, Transformer, and TCN have achieved remarkable success in univariate time series forecasting, typically relying on sliding window samples from historical data for training. However, while these models implicitly compress historical information into their parameters during training, they are unable to explicitly and dynamically access this global knowledge during inference, relying only on the local context within the lookback window. This results in an underutilization of rich patterns from the global history. To bridge this gap, we propose Predicting the Future by Retrieving the Past (PFRP), a novel approach that explicitly integrates global historical data to enhance forecasting accuracy. Specifically, we construct a Global Memory Bank (GMB) to effectively store and manage global historical patterns. A retrieval mechanism is then employed to extract similar patterns from the GMB, enabling the generation of global predictions. By adaptively combining these global predictions with the outputs of any local prediction model, PFRP produces more accurate and interpretable forecasts. Extensive experiments conducted on seven real-world datasets demonstrate that PFRP significantly enhances the average performance of advanced univariate forecasting models by 8.4\\%. Codes can be found in https://github.com/ddz16/PFRP.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼ˆå¦‚MLPã€Transformerå’ŒTCNï¼‰åœ¨å•å˜é‡æ—¶é—´åºåˆ—é¢„æµ‹ä¸­ä»…ä¾èµ–å±€éƒ¨æ»‘åŠ¨çª—å£ã€æ— æ³•æ˜¾å¼åˆ©ç”¨å…¨å±€å†å²ä¿¡æ¯çš„é—®é¢˜ï¼Œæå‡ºäº†Predicting the Future by Retrieving the Past (PFRP)æ–¹æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡æ„å»ºGlobal Memory Bank (GMB)æ¥æœ‰æ•ˆå­˜å‚¨å’Œç®¡ç†å…¨å±€å†å²æ¨¡å¼ï¼Œå¹¶é‡‡ç”¨æ£€ç´¢æœºåˆ¶æå–ç›¸ä¼¼æ¨¡å¼ä»¥ç”Ÿæˆå…¨å±€é¢„æµ‹ã€‚é€šè¿‡è‡ªé€‚åº”åœ°å°†è¿™äº›å…¨å±€é¢„æµ‹ä¸ä»»æ„å±€éƒ¨é¢„æµ‹æ¨¡å‹çš„è¾“å‡ºç›¸ç»“åˆï¼ŒPFRPä¸ä»…å¼¥è¡¥äº†å±€éƒ¨ä¸Šä¸‹æ–‡çš„å±€é™æ€§ï¼Œè¿˜ç”Ÿæˆäº†æ›´å‡†ç¡®ä¸”å…·æœ‰å¯è§£é‡Šæ€§çš„é¢„æµ‹ç»“æœã€‚åœ¨ä¸ƒä¸ªçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒPFRPå°†å…ˆè¿›å•å˜é‡é¢„æµ‹æ¨¡å‹çš„å¹³å‡æ€§èƒ½æ˜¾è‘—æå‡äº†8.4%ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by AAAI 2026",
      "pdf_url": "https://arxiv.org/pdf/2511.05859v1",
      "published_date": "2025-11-08 05:24:45 UTC",
      "updated_date": "2025-11-08 05:24:45 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:04:22.119460+00:00"
    },
    {
      "arxiv_id": "2511.05854v1",
      "title": "Can a Small Model Learn to Look Before It Leaps? Dynamic Learning and Proactive Correction for Hallucination Detection",
      "title_zh": "å°æ¨¡å‹èƒ½å¦å­¦ä¼šâ€œä¸‰æ€è€Œåè¡Œâ€ï¼Ÿé¢å‘å¹»è§‰æ£€æµ‹çš„åŠ¨æ€å­¦ä¹ ä¸ä¸»åŠ¨çº æ­£",
      "authors": [
        "Zepeng Bao",
        "Shen Zhou",
        "Qiankun Pi",
        "Jianhao Chen",
        "Mayi Xu",
        "Ming Zhong",
        "Yuanyuan Zhu",
        "Tieyun Qian"
      ],
      "abstract": "Hallucination in large language models (LLMs) remains a critical barrier to their safe deployment. Existing tool-augmented hallucination detection methods require pre-defined fixed verification strategies, which are crucial to the quality and effectiveness of tool calls. Some methods directly employ powerful closed-source LLMs such as GPT-4 as detectors, which are effective but too costly. To mitigate the cost issue, some methods adopt the teacher-student architecture and finetune open-source small models as detectors via agent tuning. However, these methods are limited by fixed strategies. When faced with a dynamically changing execution environment, they may lack adaptability and inappropriately call tools, ultimately leading to detection failure. To address the problem of insufficient strategy adaptability, we propose the innovative ``Learning to Evaluate and Adaptively Plan''(LEAP) framework, which endows an efficient student model with the dynamic learning and proactive correction capabilities of the teacher model. Specifically, our method formulates the hallucination detection problem as a dynamic strategy learning problem. We first employ a teacher model to generate trajectories within the dynamic learning loop and dynamically adjust the strategy based on execution failures. We then distill this dynamic planning capability into an efficient student model via agent tuning. Finally, during strategy execution, the student model adopts a proactive correction mechanism, enabling it to propose, review, and optimize its own verification strategies before execution. We demonstrate through experiments on three challenging benchmarks that our LEAP-tuned model outperforms existing state-of-the-art methods.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)ä¸­çš„å¹»è§‰é—®é¢˜ï¼ŒæŒ‡å‡ºç°æœ‰åŸºäºå·¥å…·çš„æ£€æµ‹æ–¹æ³•å­˜åœ¨ç­–ç•¥å›ºå®šæˆ–ä¾èµ–æ˜‚è´µé—­æºæ¨¡å‹(å¦‚GPT-4)çš„å±€é™æ€§ï¼Œéš¾ä»¥é€‚åº”åŠ¨æ€å˜åŒ–çš„æ‰§è¡Œç¯å¢ƒã€‚ä¸ºäº†è§£å†³ç­–ç•¥é€‚åº”æ€§ä¸è¶³çš„é—®é¢˜ï¼Œä½œè€…æå‡ºäº†åä¸ºLEAP (Learning to Evaluate and Adaptively Plan)çš„åˆ›æ–°æ¡†æ¶ï¼Œæ—¨åœ¨èµ‹äºˆé«˜æ•ˆçš„å­¦ç”Ÿæ¨¡å‹ä»¥åŠ¨æ€å­¦ä¹ å’Œä¸»åŠ¨ä¿®æ­£çš„èƒ½åŠ›ã€‚è¯¥æ–¹æ³•å°†å¹»è§‰æ£€æµ‹å½¢å¼åŒ–ä¸ºåŠ¨æ€ç­–ç•¥å­¦ä¹ é—®é¢˜ï¼Œé¦–å…ˆåˆ©ç”¨æ•™å¸ˆæ¨¡å‹åœ¨åŠ¨æ€å­¦ä¹ å¾ªç¯ä¸­ç”Ÿæˆè½¨è¿¹ï¼Œå¹¶æ ¹æ®æ‰§è¡Œå¤±è´¥åŠ¨æ€è°ƒæ•´ç­–ç•¥ã€‚éšåï¼Œé€šè¿‡ä»£ç†å¾®è°ƒ(agent tuning)å°†è¿™ç§åŠ¨æ€è§„åˆ’èƒ½åŠ›è’¸é¦åˆ°é«˜æ•ˆçš„å­¦ç”Ÿæ¨¡å‹ä¸­ã€‚åœ¨å®é™…æ‰§è¡Œä¸­ï¼Œå­¦ç”Ÿæ¨¡å‹é‡‡ç”¨ä¸»åŠ¨ä¿®æ­£æœºåˆ¶ï¼Œèƒ½å¤Ÿåœ¨æ‰§è¡Œå‰æå‡ºã€å®¡æŸ¥å¹¶ä¼˜åŒ–è‡ªèº«çš„éªŒè¯ç­–ç•¥ã€‚åœ¨ä¸‰ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œç»è¿‡LEAPå¾®è°ƒçš„æ¨¡å‹æ€§èƒ½ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•(SOTA)ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.05854v1",
      "published_date": "2025-11-08 05:05:38 UTC",
      "updated_date": "2025-11-08 05:05:38 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:04:47.455869+00:00"
    },
    {
      "arxiv_id": "2511.05852v3",
      "title": "Can Fine-Tuning Erase Your Edits? On the Fragile Coexistence of Knowledge Editing and Adaptation",
      "title_zh": "å¾®è°ƒèƒ½å¦æŠ¹é™¤ç¼–è¾‘ï¼Ÿè®ºçŸ¥è¯†ç¼–è¾‘ä¸æ¨¡å‹é€‚åº”çš„è„†å¼±å…±å­˜",
      "authors": [
        "Yinjie Cheng",
        "Paul Youssef",
        "Christin Seifert",
        "JÃ¶rg SchlÃ¶tterer",
        "Zhixue Zhao"
      ],
      "abstract": "Knowledge editing has emerged as a lightweight alternative to retraining for correcting or injecting specific facts in large language models (LLMs). Meanwhile, fine-tuning remains the default operation for adapting LLMs to new domains and tasks. Despite their widespread adoption, these two post-training interventions have been studied in isolation, leaving open a crucial question: if we fine-tune an edited model, do the edits survive? This question is motivated by two practical scenarios: removing covert or malicious edits, and preserving beneficial edits. If fine-tuning impairs edits (Fig.1), current KE methods become less useful, as every fine-tuned model would require re-editing, which significantly increases the cost; if edits persist, fine-tuned models risk propagating hidden malicious edits, raising serious safety concerns. To this end, we systematically quantify edit decay after fine-tuning, investigating how fine-tuning affects knowledge editing. Our results show that edits decay after fine-tuning, with survival varying across configurations, e.g., AlphaEdit edits decay more than MEMIT edits. Further, we find that fine-tuning edited layers only can effectively remove edits, though at a slight cost to downstream performance. Surprisingly, fine-tuning non-edited layers impairs more edits than full fine-tuning. Overall, our study establishes empirical baselines and actionable strategies for integrating knowledge editing with fine-tuning, and underscores that evaluating model editing requires considering the full LLM application pipeline.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åè®­ç»ƒé˜¶æ®µä¸¤ç§å¸¸è§å¹²é¢„æ‰‹æ®µâ€”â€”çŸ¥è¯†ç¼–è¾‘ï¼ˆKnowledge Editingï¼‰ä¸å¾®è°ƒï¼ˆFine-tuningï¼‰ä¹‹é—´çš„å…±å­˜é—®é¢˜ï¼Œæ ¸å¿ƒåœ¨äºæ¢ç©¶å¾®è°ƒæ˜¯å¦ä¼šæŠ¹é™¤ä¹‹å‰çš„ç¼–è¾‘æ•ˆæœã€‚è¿™ä¸€é—®é¢˜å¯¹äºç§»é™¤æ¶æ„ç¼–è¾‘ä»¥ç¡®ä¿å®‰å…¨ï¼Œä»¥åŠä¿ç•™æœ‰ç›Šç¼–è¾‘ä»¥é™ä½ç»´æŠ¤æˆæœ¬è‡³å…³é‡è¦ã€‚ä½œè€…ç³»ç»Ÿåœ°é‡åŒ–äº†å¾®è°ƒåçš„â€œç¼–è¾‘è¡°å‡â€ï¼ˆedit decayï¼‰ï¼Œåˆ†æäº†ä¸åŒé…ç½®ä¸‹çŸ¥è¯†ç¼–è¾‘çš„æŒä¹…æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå¾®è°ƒç¡®å®ä¼šå¯¼è‡´ç¼–è¾‘æ•ˆæœè¡°å‡ï¼Œä¸”ä¸åŒç¼–è¾‘æ–¹æ³•ï¼ˆå¦‚AlphaEditä¸MEMITï¼‰çš„ç•™å­˜ç‡å­˜åœ¨å·®å¼‚ã€‚ç ”ç©¶å‘ç°ï¼Œä»…å¾®è°ƒè¢«ç¼–è¾‘è¿‡çš„å±‚å¯ä»¥æœ‰æ•ˆç§»é™¤ç¼–è¾‘å†…å®¹ï¼Œä½†ä¼šè½»å¾®å½±å“ä¸‹æ¸¸æ€§èƒ½ã€‚ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œå¾®è°ƒéç¼–è¾‘å±‚æ¯”å…¨å‚æ•°å¾®è°ƒå¯¹ç¼–è¾‘æ•ˆæœçš„ç ´åæ›´å¤§ã€‚è¯¥å·¥ä½œå»ºç«‹äº†å°†çŸ¥è¯†ç¼–è¾‘ä¸å¾®è°ƒç›¸ç»“åˆçš„ç»éªŒåŸºçº¿å’Œç­–ç•¥ï¼Œå¼ºè°ƒäº†åœ¨å®Œæ•´çš„LLMåº”ç”¨æµç¨‹ä¸­è¯„ä¼°æ¨¡å‹ç¼–è¾‘æŠ€æœ¯çš„å¿…è¦æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.05852v3",
      "published_date": "2025-11-08 04:58:03 UTC",
      "updated_date": "2025-12-07 19:23:41 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:05:13.620617+00:00"
    },
    {
      "arxiv_id": "2512.00030v1",
      "title": "Perturbation-mitigated USV Navigation with Distributionally Robust Reinforcement Learning",
      "title_zh": "åŸºäºåˆ†å¸ƒé²æ£’å¼ºåŒ–å­¦ä¹ çš„æ‰°åŠ¨æŠ‘åˆ¶æ— äººè‰‡å¯¼èˆª",
      "authors": [
        "Zhaofan Zhang",
        "Minghao Yang",
        "Sihong Xie",
        "Hui Xiong"
      ],
      "abstract": "The robustness of Unmanned Surface Vehicles (USV) is crucial when facing unknown and complex marine environments, especially when heteroscedastic observational noise poses significant challenges to sensor-based navigation tasks. Recently, Distributional Reinforcement Learning (DistRL) has shown promising results in some challenging autonomous navigation tasks without prior environmental information. However, these methods overlook situations where noise patterns vary across different environmental conditions, hindering safe navigation and disrupting the learning of value functions. To address the problem, we propose DRIQN to integrate Distributionally Robust Optimization (DRO) with implicit quantile networks to optimize worst-case performance under natural environmental conditions. Leveraging explicit subgroup modeling in the replay buffer, DRIQN incorporates heterogeneous noise sources and target robustness-critical scenarios. Experimental results based on the risk-sensitive environment demonstrate that DRIQN significantly outperforms state-of-the-art methods, achieving +13.51\\% success rate, -12.28\\% collision rate and +35.46\\% for time saving, +27.99\\% for energy saving, compared with the runner-up.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ— äººæ°´é¢è‰‡(USV)åœ¨å¤æ‚æµ·æ´‹ç¯å¢ƒä¸­é¢ä¸´çš„å¼‚æ–¹å·®è§‚æµ‹å™ªå£°æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºDRIQNçš„æ–°æ–¹æ³•ã€‚ç°æœ‰çš„åˆ†å¸ƒå¼ºåŒ–å­¦ä¹ (DistRL)å¾€å¾€å¿½ç•¥å™ªå£°æ¨¡å¼éšç¯å¢ƒæ¡ä»¶å˜åŒ–çš„æƒ…å†µï¼Œä»è€Œå½±å“å¯¼èˆªå®‰å…¨å’Œä»·å€¼å‡½æ•°çš„å­¦ä¹ ã€‚DRIQNé€šè¿‡å°†åˆ†å¸ƒé²æ£’ä¼˜åŒ–(DRO)ä¸éšå¼åˆ†ä½æ•°ç½‘ç»œç›¸ç»“åˆï¼Œæ—¨åœ¨ä¼˜åŒ–è‡ªç„¶ç¯å¢ƒæ¡ä»¶ä¸‹çš„æœ€åæƒ…å†µæ€§èƒ½ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•åœ¨ç»éªŒå›æ”¾ç¼“å†²åŒºä¸­åˆ©ç”¨æ˜¾å¼å­ç¾¤å»ºæ¨¡ï¼Œæœ‰æ•ˆæ•´åˆäº†å¼‚æ„å™ªå£°æºå¹¶é’ˆå¯¹é²æ£’æ€§å…³é”®åœºæ™¯è¿›è¡Œäº†å¼ºåŒ–ã€‚åŸºäºé£é™©æ•æ„Ÿç¯å¢ƒçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒDRIQNæ˜¾è‘—ä¼˜äºå½“å‰æœ€å…ˆè¿›çš„æ–¹æ³•(SOTA)ã€‚å…·ä½“è€Œè¨€ï¼Œç›¸æ¯”ç¬¬äºŒåçš„æ–¹æ³•ï¼ŒDRIQNçš„å¯¼èˆªæˆåŠŸç‡æå‡äº†13.51%ï¼Œç¢°æ’ç‡é™ä½äº†12.28%ï¼Œå¹¶åœ¨æ—¶é—´èŠ‚çœå’Œèƒ½æºèŠ‚çœæ–¹é¢åˆ†åˆ«æå‡äº†35.46%å’Œ27.99%ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.00030v1",
      "published_date": "2025-11-08 04:56:38 UTC",
      "updated_date": "2025-11-08 04:56:38 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:07:32.234679+00:00"
    },
    {
      "arxiv_id": "2511.05850v1",
      "title": "Retrieval Quality at Context Limit",
      "title_zh": "ä¸Šä¸‹æ–‡æé™ä¸‹çš„æ£€ç´¢è´¨é‡",
      "authors": [
        "Max McKinnon"
      ],
      "abstract": "The ability of large language models (LLMs) to recall and retrieve information from long contexts is critical for many real-world applications. Prior work (Liu et al., 2023) reported that LLMs suffer significant drops in retrieval accuracy for facts placed in the middle of large contexts, an effect known as \"Lost in the Middle\" (LITM). We find the model Gemini 2.5 Flash can answer needle-in-a-haystack questions with great accuracy regardless of document position including when the document is nearly at the input context limit. Our results suggest that the \"Lost in the Middle\" effect is not present for simple factoid Q\\&A in Gemini 2.5 Flash, indicating substantial improvements in long-context retrieval.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é•¿è¯­å¢ƒä¸‹çš„ä¿¡æ¯æ£€ç´¢èƒ½åŠ›è¿›è¡Œäº†è¯„ä¼°ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹æ­¤å‰ç ”ç©¶ä¸­æŒ‡å‡ºçš„â€œLost in the Middleâ€ï¼ˆLITMï¼‰ç°è±¡ï¼Œå³æ¨¡å‹åœ¨æ£€ç´¢ä½äºé•¿è¯­å¢ƒä¸­é—´éƒ¨åˆ†çš„ä¿¡æ¯æ—¶å‡†ç¡®ç‡ä¸‹é™çš„é—®é¢˜ã€‚ç ”ç©¶å‘ç°ï¼ŒGemini 2.5 Flashæ¨¡å‹åœ¨å¤„ç†â€œneedle-in-a-haystackâ€ç±»é—®é¢˜æ—¶è¡¨ç°å‡ºè‰²ï¼Œæ— è®ºç›®æ ‡ä¿¡æ¯ä½äºæ–‡æ¡£çš„å“ªä¸ªä½ç½®ï¼Œç”šè‡³æ˜¯åœ¨æ¥è¿‘è¾“å…¥ä¸Šä¸‹æ–‡é™åˆ¶çš„åœ°æ–¹ï¼Œéƒ½èƒ½ä¿æŒæé«˜çš„å‡†ç¡®æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå¯¹äºç®€å•çš„äº‹å®å‹é—®ç­”ï¼ˆfactoid Q&Aï¼‰ï¼ŒGemini 2.5 Flashå¹¶ä¸å­˜åœ¨LITMæ•ˆåº”ã€‚è¿™ä¸€å‘ç°è¯å®äº†è¯¥æ¨¡å‹åœ¨é•¿è¯­å¢ƒæ£€ç´¢æ–¹é¢å–å¾—äº†å®è´¨æ€§çš„æ”¹è¿›ï¼Œå…‹æœäº†æ­¤å‰æ¨¡å‹åœ¨ä¸Šä¸‹æ–‡ä¸­é—´ä½ç½®æ£€ç´¢èƒ½åŠ›ä¸è¶³çš„å±€é™ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "3 pages, 0 figures",
      "pdf_url": "https://arxiv.org/pdf/2511.05850v1",
      "published_date": "2025-11-08 04:54:29 UTC",
      "updated_date": "2025-11-08 04:54:29 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:07:39.885294+00:00"
    },
    {
      "arxiv_id": "2511.05849v1",
      "title": "EGG-SR: Embedding Symbolic Equivalence into Symbolic Regression via Equality Graph",
      "title_zh": "EGG-SRï¼šé€šè¿‡ç­‰å¼å›¾å°†ç¬¦å·ç­‰ä»·æ€§åµŒå…¥ç¬¦å·å›å½’",
      "authors": [
        "Nan Jiang",
        "Ziyi Wang",
        "Yexiang Xue"
      ],
      "abstract": "Symbolic regression seeks to uncover physical laws from experimental data by searching for closed-form expressions, which is an important task in AI-driven scientific discovery. Yet the exponential growth of the search space of expression renders the task computationally challenging. A promising yet underexplored direction for reducing the effective search space and accelerating training lies in symbolic equivalence: many expressions, although syntactically different, define the same function -- for example, $\\log(x_1^2x_2^3)$, $\\log(x_1^2)+\\log(x_2^3)$, and $2\\log(x_1)+3\\log(x_2)$. Existing algorithms treat such variants as distinct outputs, leading to redundant exploration and slow learning. We introduce EGG-SR, a unified framework that integrates equality graphs (e-graphs) into diverse symbolic regression algorithms, including Monte Carlo Tree Search (MCTS), deep reinforcement learning (DRL), and large language models (LLMs). EGG-SR compactly represents equivalent expressions through the proposed EGG module, enabling more efficient learning by: (1) pruning redundant subtree exploration in EGG-MCTS, (2) aggregating rewards across equivalence classes in EGG-DRL, and (3) enriching feedback prompts in EGG-LLM. Under mild assumptions, we show that embedding e-graphs tightens the regret bound of MCTS and reduces the variance of the DRL gradient estimator. Empirically, EGG-SR consistently enhances multiple baselines across challenging benchmarks, discovering equations with lower normalized mean squared error than state-of-the-art methods. Code implementation is available at: https://www.github.com/jiangnanhugo/egg-sr.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†EGG-SRï¼Œä¸€ç§åˆ©ç”¨ç­‰å¼å›¾(equality graphs, e-graphs)å°†ç¬¦å·ç­‰ä»·æ€§åµŒå…¥ç¬¦å·å›å½’(Symbolic Regression)çš„ç»Ÿä¸€æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³è¡¨è¾¾å¼æœç´¢ç©ºé—´æŒ‡æ•°çº§å¢é•¿åŠå†—ä½™æ¢ç´¢çš„é—®é¢˜ã€‚EGG-SRé€šè¿‡EGGæ¨¡å—ç´§å‡‘åœ°è¡¨ç¤ºå¥æ³•ä¸åŒä½†åŠŸèƒ½ç›¸åŒçš„ç­‰ä»·è¡¨è¾¾å¼ï¼Œå¹¶å°†å…¶é›†æˆåˆ°è’™ç‰¹å¡æ´›æ ‘æœç´¢(MCTS)ã€æ·±åº¦å¼ºåŒ–å­¦ä¹ (DRL)å’Œå¤§è¯­è¨€æ¨¡å‹(LLMs)ä¸­ã€‚è¯¥æ¡†æ¶é€šè¿‡ä¿®å‰ªå†—ä½™å­æ ‘æ¢ç´¢ã€èšåˆç­‰ä»·ç±»å¥–åŠ±ä»¥åŠä¸°å¯Œåé¦ˆæç¤ºç­‰æœºåˆ¶æ˜¾è‘—æå‡äº†å­¦ä¹ æ•ˆç‡ã€‚ç†è®ºåˆ†æè¡¨æ˜ï¼ŒåµŒå…¥e-graphsåœ¨æ¸©å’Œå‡è®¾ä¸‹èƒ½æ”¶ç´§MCTSçš„é—æ†¾ç•Œ(regret bound)å¹¶é™ä½DRLæ¢¯åº¦ä¼°è®¡å™¨çš„æ–¹å·®ã€‚å®è¯ç»“æœæ˜¾ç¤ºï¼ŒEGG-SRåœ¨å¤šä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„åŸºå‡†æµ‹è¯•ä¸­ä¸€è‡´ä¼˜äºç°æœ‰åŸºçº¿ï¼Œèƒ½å¤Ÿå‘ç°æ¯”æœ€å…ˆè¿›æ–¹æ³•(SOTA)å…·æœ‰æ›´ä½å½’ä¸€åŒ–å‡æ–¹è¯¯å·®çš„ç‰©ç†æ–¹ç¨‹ã€‚",
      "categories": [
        "cs.SC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.05849v1",
      "published_date": "2025-11-08 04:39:11 UTC",
      "updated_date": "2025-11-08 04:39:11 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:08:07.135711+00:00"
    },
    {
      "arxiv_id": "2511.05844v3",
      "title": "Enhancing Diffusion Model Guidance through Calibration and Regularization",
      "title_zh": "é€šè¿‡æ ¡å‡†ä¸æ­£åˆ™åŒ–å¢å¼ºæ‰©æ•£æ¨¡å‹å¼•å¯¼",
      "authors": [
        "Seyed Alireza Javid",
        "Amirhossein Bagheri",
        "Nuria GonzÃ¡lez-Prelcic"
      ],
      "abstract": "Classifier-guided diffusion models have emerged as a powerful approach for conditional image generation, but they suffer from overconfident predictions during early denoising steps, causing the guidance gradient to vanish. This paper introduces two complementary contributions to address this issue. First, we propose a differentiable calibration objective based on the Smooth Expected Calibration Error (Smooth ECE), which improves classifier calibration with minimal fine-tuning and yields measurable improvements in Frechet Inception Distance (FID). Second, we develop enhanced sampling guidance methods that operate on off-the-shelf classifiers without requiring retraining. These include tilted sampling with batch-level reweighting, adaptive entropy-regularized sampling to preserve diversity, and a novel f-divergence-based sampling strategy that strengthens class-consistent guidance while maintaining mode coverage. Experiments on ImageNet 128x128 demonstrate that our divergence-regularized guidance achieves an FID of 2.13 using a ResNet-101 classifier, improving upon existing classifier-guided diffusion methods while requiring no diffusion model retraining. The results show that principled calibration and divergence-aware sampling provide practical and effective improvements for classifier-guided diffusion.",
      "tldr_zh": "è¯¥è®ºæ–‡é’ˆå¯¹åˆ†ç±»å™¨å¼•å¯¼çš„æ‰©æ•£æ¨¡å‹(Classifier-guided diffusion models)åœ¨æ—©æœŸå»å™ªé˜¶æ®µå› é¢„æµ‹è¿‡åº¦è‡ªä¿¡å¯¼è‡´å¼•å¯¼æ¢¯åº¦æ¶ˆå¤±çš„é—®é¢˜è¿›è¡Œäº†ç ”ç©¶ã€‚ä½œè€…é¦–å…ˆæå‡ºäº†ä¸€ç§åŸºäºå¹³æ»‘é¢„æœŸæ ¡å‡†è¯¯å·®(Smooth ECE)çš„å¯å¾®æ ¡å‡†ç›®æ ‡ï¼Œé€šè¿‡æœ€å°åŒ–å¾®è°ƒæ˜¾è‘—æ”¹å–„äº†åˆ†ç±»å™¨çš„æ ¡å‡†æ•ˆæœå¹¶æå‡äº†Frechet Inception Distance (FID)ã€‚å…¶æ¬¡ï¼Œè®ºæ–‡å¼€å‘äº†æ— éœ€é‡æ–°è®­ç»ƒå³å¯åº”ç”¨äºç°æˆåˆ†ç±»å™¨çš„å¢å¼ºé‡‡æ ·å¼•å¯¼æ–¹æ³•ï¼ŒåŒ…æ‹¬æ‰¹é‡é‡åŠ æƒçš„å€¾æ–œé‡‡æ ·ã€ä¿æŒå¤šæ ·æ€§çš„è‡ªé€‚åº”ç†µæ­£åˆ™åŒ–é‡‡æ ·ï¼Œä»¥åŠä¸€ç§åœ¨å¢å¼ºç±»åˆ«ä¸€è‡´æ€§å¼•å¯¼åŒæ—¶ä¿æŒæ¨¡å¼è¦†ç›–ç‡çš„f-divergenceé‡‡æ ·ç­–ç•¥ã€‚åœ¨ImageNet 128x128ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œä½¿ç”¨ResNet-101åˆ†ç±»å™¨çš„æ•£åº¦æ­£åˆ™åŒ–å¼•å¯¼å®ç°äº†2.13çš„FIDåˆ†æ•°ï¼Œåœ¨æ— éœ€é‡æ–°è®­ç»ƒæ‰©æ•£æ¨¡å‹çš„æƒ…å†µä¸‹ä¼˜äºç°æœ‰çš„å¼•å¯¼æ–¹æ³•ã€‚ç»“æœè¯æ˜ï¼ŒåŸåˆ™æ€§çš„æ ¡å‡†å’Œæ•£åº¦æ„ŸçŸ¥é‡‡æ ·ä¸ºåˆ†ç±»å™¨å¼•å¯¼çš„æ‰©æ•£æ¨¡å‹æä¾›äº†å®ç”¨ä¸”æœ‰æ•ˆçš„æ”¹è¿›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.IT",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted from NeurIPS 2025 Workshop on Structured Probabilistic Inference & Generative Modeling. Code available at https://github.com/ajavid34/guided-info-diffusion",
      "pdf_url": "https://arxiv.org/pdf/2511.05844v3",
      "published_date": "2025-11-08 04:23:42 UTC",
      "updated_date": "2025-12-21 23:56:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:12:47.884579+00:00"
    },
    {
      "arxiv_id": "2511.05841v1",
      "title": "Understanding Cross Task Generalization in Handwriting-Based Alzheimer's Screening via Vision Language Adaptation",
      "title_zh": "åˆ©ç”¨è§†è§‰è¯­è¨€é€‚é…æ¢ç©¶åŸºäºæ‰‹å†™çš„é˜¿å°”èŒ¨æµ·é»˜ç—…ç­›æŸ¥è·¨ä»»åŠ¡æ³›åŒ–",
      "authors": [
        "Changqing Gong",
        "Huafeng Qin",
        "Mounim A. El-Yacoubi"
      ],
      "abstract": "Alzheimer's disease is a prevalent neurodegenerative disorder for which early detection is critical. Handwriting-often disrupted in prodromal AD-provides a non-invasive and cost-effective window into subtle motor and cognitive decline. Existing handwriting-based AD studies, mostly relying on online trajectories and hand-crafted features, have not systematically examined how task type influences diagnostic performance and cross-task generalization. Meanwhile, large-scale vision language models have demonstrated remarkable zero or few-shot anomaly detection in natural images and strong adaptability across medical modalities such as chest X-ray and brain MRI. However, handwriting-based disease detection remains largely unexplored within this paradigm. To close this gap, we introduce a lightweight Cross-Layer Fusion Adapter framework that repurposes CLIP for handwriting-based AD screening. CLFA implants multi-level fusion adapters within the visual encoder to progressively align representations toward handwriting-specific medical cues, enabling prompt-free and efficient zero-shot inference. Using this framework, we systematically investigate cross-task generalization-training on a specific handwriting task and evaluating on unseen ones-to reveal which task types and writing patterns most effectively discriminate AD. Extensive analyses further highlight characteristic stroke patterns and task-level factors that contribute to early AD identification, offering both diagnostic insights and a benchmark for handwriting-based cognitive assessment.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é˜¿å°”èŒ¨æµ·é»˜ç—…(Alzheimer's disease, AD)çš„æ—©æœŸæ£€æµ‹ï¼Œæ¢è®¨äº†åŸºäºæ‰‹å†™åˆ†æçš„è·¨ä»»åŠ¡æ³›åŒ–é—®é¢˜ï¼Œå¼¥è¡¥äº†ç°æœ‰ç ”ç©¶åœ¨ä»»åŠ¡ç±»å‹å½±å“å’Œè§†è§‰è¯­è¨€æ¨¡å‹(VLMs)åº”ç”¨æ–¹é¢çš„ç©ºç™½ã€‚ä½œè€…æå‡ºäº†ä¸€ç§è½»é‡çº§çš„Cross-Layer Fusion Adapter (CLFA)æ¡†æ¶ï¼Œé€šè¿‡åœ¨CLIPæ¨¡å‹çš„è§†è§‰ç¼–ç å™¨ä¸­æ¤å…¥å¤šçº§èåˆé€‚é…å™¨ï¼Œå°†ç‰¹å¾è¡¨ç¤ºé€æ­¥å¯¹é½è‡³æ‰‹å†™ç‰¹å®šçš„åŒ»ç–—çº¿ç´¢ï¼Œä»è€Œå®ç°äº†æ— éœ€æç¤ºè¯çš„é«˜æ•ˆé›¶æ ·æœ¬æ¨ç†ã€‚åˆ©ç”¨è¯¥æ¡†æ¶ï¼Œç ”ç©¶å›¢é˜Ÿç³»ç»Ÿåœ°è°ƒæŸ¥äº†è·¨ä»»åŠ¡æ³›åŒ–èƒ½åŠ›(cross-task generalization)ï¼Œå³åœ¨ç‰¹å®šæ‰‹å†™ä»»åŠ¡ä¸Šè®­ç»ƒå¹¶åœ¨æœªè§è¿‡çš„ä»»åŠ¡ä¸Šè¿›è¡Œè¯„ä¼°ï¼Œä»¥æ­ç¤ºå“ªäº›ä»»åŠ¡ç±»å‹å’Œä¹¦å†™æ¨¡å¼æœ€èƒ½æœ‰æ•ˆåŒºåˆ†ADã€‚å¹¿æ³›çš„åˆ†æè¿›ä¸€æ­¥çªå‡ºäº†æœ‰åŠ©äºæ—©æœŸADè¯†åˆ«çš„ç‰¹å¾ç¬”ç”»æ¨¡å¼å’Œä»»åŠ¡å±‚é¢çš„å› ç´ ã€‚è¿™é¡¹å·¥ä½œä¸ä»…æä¾›äº†é‡è¦çš„è¯Šæ–­è§è§£ï¼Œä¹Ÿä¸ºåŸºäºæ‰‹å†™çš„è®¤çŸ¥è¯„ä¼°å»ºç«‹äº†ä¸€ä¸ªæ–°çš„åŸºå‡†ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.05841v1",
      "published_date": "2025-11-08 04:13:01 UTC",
      "updated_date": "2025-11-08 04:13:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:12:21.634969+00:00"
    },
    {
      "arxiv_id": "2511.05832v1",
      "title": "Hilbert-Guided Block-Sparse Local Attention",
      "title_zh": "å¸Œå°”ä¼¯ç‰¹å¼•å¯¼çš„å—ç¨€ç–å±€éƒ¨æ³¨æ„åŠ›",
      "authors": [
        "Yunge Li",
        "Lanyu Xu"
      ],
      "abstract": "The quadratic compute and memory costs of global self-attention severely limit its use in high-resolution images. Local attention reduces complexity by restricting attention to neighborhoods. Block-sparse kernels can further improve the efficiency of local attention, but conventional local attention patterns often fail to deliver significant speedups because tokens within a window are not contiguous in the 1D sequence. This work proposes a novel method for constructing windows and neighborhoods based on the Hilbert curve. Image tokens are first reordered along a Hilbert curve, and windows and neighborhoods are then formed on the reordered 1D sequence. From a block-sparse perspective, this strategy significantly increases block sparsity and can be combined with existing block-sparse kernels to improve the efficiency of 2D local attention. Experiments show that the proposed Hilbert Window Attention and Hilbert Slide Attention can accelerate window attention and slide attention by about $4\\times$ and $18\\times$, respectively. To assess practicality, the strategy is instantiated as the Hilbert Window Transformer and the Hilbert Neighborhood Transformer, both of which achieve end-to-end speedups with minimal accuracy loss. Overall, combining Hilbert-guided local attention with block-sparse kernels offers a general and practical approach to enhancing the efficiency of 2D local attention for images. The code is available at https://github.com/Yunge6666/Hilbert-Local-Attention.",
      "tldr_zh": "è¿™é¡¹å·¥ä½œé’ˆå¯¹å…¨å±€è‡ªæ³¨æ„åŠ›æœºåˆ¶åœ¨é«˜åˆ†è¾¨ç‡å›¾åƒä¸­è®¡ç®—å’Œå†…å­˜æˆæœ¬é«˜æ˜‚çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºå¸Œå°”ä¼¯ç‰¹æ›²çº¿(Hilbert curve)æ„å»ºçª—å£å’Œé‚»åŸŸçš„æ–°æ–¹æ³•ã€‚è¯¥æ–¹æ³•é¦–å…ˆæ²¿ç€Hilbert curveé‡æ–°æ’åˆ—å›¾åƒtokensï¼Œç„¶ååœ¨é‡æ’åçš„1Dåºåˆ—ä¸Šå½¢æˆçª—å£å’Œé‚»åŸŸï¼Œè¿™ç§ç­–ç•¥æ˜¾è‘—å¢åŠ äº†å—ç¨€ç–æ€§(block sparsity)ã€‚é€šè¿‡ä¸ç°æœ‰çš„block-sparse kernelsç»“åˆï¼Œè¯¥æ–¹æ³•æœ‰æ•ˆè§£å†³äº†ä¼ ç»Ÿå±€éƒ¨æ³¨æ„åŠ›æ¨¡å¼å› tokensåœ¨1Dåºåˆ—ä¸­ä¸è¿ç»­è€Œéš¾ä»¥æ˜¾è‘—åŠ é€Ÿçš„é—®é¢˜ã€‚å®éªŒè¡¨æ˜ï¼Œæå‡ºçš„Hilbert Window Attentionå’ŒHilbert Slide Attentionåˆ†åˆ«å°†çª—å£æ³¨æ„åŠ›å’Œæ»‘åŠ¨æ³¨æ„åŠ›åŠ é€Ÿäº†çº¦4å€å’Œ18å€ã€‚ç ”ç©¶å›¢é˜Ÿè¿›ä¸€æ­¥å®ç°äº†Hilbert Window Transformerå’ŒHilbert Neighborhood Transformerï¼Œä¸¤è€…å‡åœ¨ä¿æŒæå°ç²¾åº¦æŸå¤±çš„åŒæ—¶å®ç°äº†ç«¯åˆ°ç«¯çš„åŠ é€Ÿï¼Œè¯æ˜äº†è¯¥ç­–ç•¥æ˜¯æå‡å›¾åƒ2Då±€éƒ¨æ³¨æ„åŠ›æ•ˆç‡çš„ä¸€ç§é€šç”¨ä¸”å®ç”¨çš„æ–¹æ³•ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.05832v1",
      "published_date": "2025-11-08 03:43:13 UTC",
      "updated_date": "2025-11-08 03:43:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:12:05.659844+00:00"
    },
    {
      "arxiv_id": "2511.05822v1",
      "title": "Policy Gradient-Based EMT-in-the-Loop Learning to Mitigate Sub-Synchronous Control Interactions",
      "title_zh": "ç”¨äºæŠ‘åˆ¶æ¬¡åŒæ­¥æ§åˆ¶ç›¸äº’ä½œç”¨çš„åŸºäºç­–ç•¥æ¢¯åº¦ç”µç£æš‚æ€åœ¨ç¯å­¦ä¹ ",
      "authors": [
        "Sayak Mukherjee",
        "Ramij R. Hossain",
        "Kaustav Chatterjee",
        "Sameer Nekkalapu",
        "Marcelo Elizondo"
      ],
      "abstract": "This paper explores the development of learning-based tunable control gains using EMT-in-the-loop simulation framework (e.g., PSCAD interfaced with Python-based learning modules) to address critical sub-synchronous oscillations. Since sub-synchronous control interactions (SSCI) arise from the mis-tuning of control gains under specific grid configurations, effective mitigation strategies require adaptive re-tuning of these gains. Such adaptiveness can be achieved by employing a closed-loop, learning-based framework that considers the grid conditions responsible for such sub-synchronous oscillations. This paper addresses this need by adopting methodologies inspired by Markov decision process (MDP) based reinforcement learning (RL), with a particular emphasis on simpler deep policy gradient methods with additional SSCI-specific signal processing modules such as down-sampling, bandpass filtering, and oscillation energy dependent reward computations. Our experimentation in a real-world event setting demonstrates that the deep policy gradient based trained policy can adaptively compute gain settings in response to varying grid conditions and optimally suppress control interaction-induced oscillations.",
      "tldr_zh": "æœ¬æ–‡æ¢è®¨äº†åˆ©ç”¨ EMT-in-the-loop ä»¿çœŸæ¡†æ¶å¼€å‘åŸºäºå­¦ä¹ çš„å¯è°ƒæ§åˆ¶å¢ç›Šï¼Œä»¥è§£å†³å…³é”®çš„æ¬¡åŒæ­¥æŒ¯è¡é—®é¢˜ã€‚ç”±äºæ¬¡åŒæ­¥æ§åˆ¶ç›¸äº’ä½œç”¨ (SSCI) é€šå¸¸æºäºç‰¹å®šç”µç½‘é…ç½®ä¸‹æ§åˆ¶å¢ç›Šçš„å¤±è°ƒï¼Œè¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§é—­ç¯ã€åŸºäºå­¦ä¹ çš„æ¡†æ¶æ¥å®ç°å¢ç›Šçš„è‡ªé€‚åº”é‡è°ƒã€‚æ–‡ç« é‡‡ç”¨äº†å—é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ (MDP) å¯å‘çš„å¼ºåŒ–å­¦ä¹  (RL) æ–¹æ³•ï¼Œé‡ç‚¹åº”ç”¨äº†æ·±åº¦ç­–ç•¥æ¢¯åº¦ (Deep Policy Gradient) ç®—æ³•ï¼Œå¹¶ç»“åˆäº†ä¸‹é‡‡æ ·ã€å¸¦é€šæ»¤æ³¢å’ŒåŸºäºæŒ¯è¡èƒ½é‡çš„å¥–åŠ±è®¡ç®—ç­‰ SSCI ä¸“ç”¨ä¿¡å·å¤„ç†æ¨¡å—ã€‚åœ¨çœŸå®äº‹ä»¶åœºæ™¯ä¸‹çš„å®éªŒè¡¨æ˜ï¼Œè¯¥è®­ç»ƒç­–ç•¥èƒ½å¤Ÿæ ¹æ®å˜åŒ–çš„ç”µç½‘æ¡ä»¶è‡ªé€‚åº”åœ°è®¡ç®—å¢ç›Šè®¾ç½®ï¼Œä»è€Œæœ‰æ•ˆåœ°æŠ‘åˆ¶ç”±æ§åˆ¶ç›¸äº’ä½œç”¨å¼•èµ·çš„æŒ¯è¡ã€‚",
      "categories": [
        "eess.SY",
        "cs.AI"
      ],
      "primary_category": "eess.SY",
      "comment": "10 pages, 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2511.05822v1",
      "published_date": "2025-11-08 03:12:29 UTC",
      "updated_date": "2025-11-08 03:12:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:13:25.024388+00:00"
    },
    {
      "arxiv_id": "2511.05820v1",
      "title": "WAR-Re: Web API Recommendation with Semantic Reasoning",
      "title_zh": "WAR-Reï¼šåŸºäºè¯­ä¹‰æ¨ç†çš„ Web API æ¨è",
      "authors": [
        "Zishuo Xu",
        "Dezhong Yao",
        "Yao Wan"
      ],
      "abstract": "With the development of cloud computing, the number of Web APIs has increased dramatically, further intensifying the demand for efficient Web API recommendation. Despite the demonstrated success of previous Web API recommendation solutions, two critical challenges persist: 1) a fixed top-N recommendation that cannot accommodate the varying API cardinality requirements of different mashups, and 2) these methods output only ranked API lists without accompanying reasons, depriving users of understanding the recommendation. To address these challenges, we propose WAR-Re, an LLM-based model for Web API recommendation with semantic reasoning for justification. WAR-Re leverages special start and stop tokens to handle the first challenge and uses two-stage training: supervised fine-tuning and reinforcement learning via Group Relative Policy Optimization (GRPO) to enhance the model's ability in both tasks. Comprehensive experimental evaluations on the ProgrammableWeb dataset demonstrate that WAR-Re achieves a gain of up to 21.59\\% over the state-of-the-art baseline model in recommendation accuracy, while consistently producing high-quality semantic reasons for recommendations.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹Web APIæ¨èä¸­å­˜åœ¨çš„å›ºå®štop-Næ¨èæ— æ³•é€‚åº”å¤šå˜éœ€æ±‚ä»¥åŠç¼ºä¹æ¨èç†ç”±è§£é‡Šè¿™ä¸¤ä¸ªå…³é”®æŒ‘æˆ˜ï¼Œæå‡ºäº†WAR-Reï¼Œä¸€ç§ç»“åˆè¯­ä¹‰æ¨ç†çš„åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLM)çš„æ¨èæ¡†æ¶ã€‚WAR-Reåˆ©ç”¨ç‰¹æ®Šçš„å¼€å§‹å’Œåœæ­¢tokenæ¥çµæ´»å¤„ç†ä¸åŒmashupæ‰€éœ€çš„APIæ•°é‡ï¼Œå¹¶é‡‡ç”¨ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥ï¼ŒåŒ…æ‹¬ç›‘ç£å¾®è°ƒå’ŒåŸºäºGroup Relative Policy Optimization (GRPO)çš„å¼ºåŒ–å­¦ä¹ ï¼Œä»¥æå‡æ¨¡å‹åœ¨æ¨èå’Œç”Ÿæˆç†ç”±æ–¹é¢çš„èƒ½åŠ›ã€‚åœ¨ProgrammableWebæ•°æ®é›†ä¸Šçš„å®éªŒè¯„ä¼°æ˜¾ç¤ºï¼ŒWAR-Reåœ¨æ¨èå‡†ç¡®ç‡ä¸Šç›¸è¾ƒäºæœ€å…ˆè¿›çš„åŸºçº¿æ¨¡å‹æå‡äº†é«˜è¾¾21.59%ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹è¿˜èƒ½ä¸ºæ¨èç»“æœæä¾›é«˜è´¨é‡çš„è¯­ä¹‰è§£é‡Šï¼Œæœ‰æ•ˆè§£å†³äº†ç”¨æˆ·æ— æ³•ç†è§£æ¨èä¾æ®çš„é—®é¢˜ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.05820v1",
      "published_date": "2025-11-08 03:09:31 UTC",
      "updated_date": "2025-11-08 03:09:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:12:54.560791+00:00"
    },
    {
      "arxiv_id": "2511.05814v1",
      "title": "In-depth Analysis on Caching and Pre-fetching in Mixture of Experts Offloading",
      "title_zh": "æ··åˆä¸“å®¶æ¨¡å‹å¸è½½ä¸­ç¼“å­˜ä¸é¢„å–çš„æ·±åº¦åˆ†æ",
      "authors": [
        "Shuning Lin",
        "Yifan He",
        "Yitong Chen"
      ],
      "abstract": "In today's landscape, Mixture of Experts (MoE) is a crucial architecture that has been used by many of the most advanced models. One of the major challenges of MoE models is that they usually require much more memory than their dense counterparts due to their unique architecture, and hence are harder to deploy in environments with limited GPU memory, such as edge devices. MoE offloading is a promising technique proposed to overcome this challenge, especially if it is enhanced with caching and pre-fetching, but prior work stopped at suboptimal caching algorithm and offered limited insights. In this work, we study MoE offloading in depth and make the following contributions: 1. We analyze the expert activation and LRU caching behavior in detail and provide traces. 2. We propose LFU caching optimization based on our analysis and obtain strong improvements from LRU. 3. We implement and experiment speculative expert pre-fetching, providing detailed trace showing its huge potential . 4. In addition, our study extensively covers the behavior of the MoE architecture itself, offering information on the characteristic of the gating network and experts. This can inspire future work on the interpretation of MoE models and the development of pruning techniques for MoE architecture with minimal performance loss.",
      "tldr_zh": "æœ¬æ–‡é’ˆå¯¹Mixture of Experts (MoE)æ¨¡å‹å› å†…å­˜éœ€æ±‚å·¨å¤§è€Œéš¾ä»¥åœ¨è¾¹ç¼˜è®¾å¤‡ç­‰å—é™ç¯å¢ƒéƒ¨ç½²çš„é—®é¢˜ï¼Œæ·±å…¥ç ”ç©¶äº†MoE offloadingæŠ€æœ¯ä¸­çš„ç¼“å­˜å’Œé¢„å–æœºåˆ¶ã€‚å°½ç®¡offloadingæ˜¯ä¸€ç§æœ‰å‰æ™¯çš„æ–¹æ¡ˆï¼Œä½†ç°æœ‰å·¥ä½œåœ¨ç¼“å­˜ç®—æ³•ä¸Šå­˜åœ¨å±€é™ä¸”ç¼ºä¹æ·±å…¥è§è§£ã€‚ç ”ç©¶å›¢é˜Ÿè¯¦ç»†åˆ†æäº†ä¸“å®¶æ¿€æ´»å’ŒLRUç¼“å­˜è¡Œä¸ºï¼Œå¹¶æä¾›äº†ç›¸å…³è¿½è¸ªæ•°æ®(traces)ã€‚åŸºäºæ­¤åˆ†æï¼Œä½œè€…æå‡ºäº†LFUç¼“å­˜ä¼˜åŒ–ç­–ç•¥ï¼Œç›¸æ¯”LRUå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚æ­¤å¤–ï¼Œæ–‡ç« è¿˜å®ç°å¹¶å®éªŒäº†æŠ•æœºæ€§ä¸“å®¶é¢„å–(speculative expert pre-fetching)ï¼Œå±•ç¤ºäº†å…¶å·¨å¤§çš„æ½œåŠ›ã€‚è¯¥ç ”ç©¶è¿˜å¹¿æ³›æ¢è®¨äº†MoEæ¶æ„æœ¬èº«çš„ç‰¹æ€§ï¼ŒåŒ…æ‹¬é—¨æ§ç½‘ç»œå’Œä¸“å®¶çš„è¡Œä¸ºç‰¹å¾ï¼Œä¸ºæœªæ¥MoEæ¨¡å‹çš„å¯è§£é‡Šæ€§ç ”ç©¶åŠå‰ªææŠ€æœ¯çš„å‘å±•æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.05814v1",
      "published_date": "2025-11-08 03:04:11 UTC",
      "updated_date": "2025-11-08 03:04:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:14:08.207890+00:00"
    },
    {
      "arxiv_id": "2511.05811v2",
      "title": "MOSS: Efficient and Accurate FP8 LLM Training with Microscaling and Automatic Scaling",
      "title_zh": "MOSSï¼šåŸºäºå¾®ç¼©æ”¾ä¸è‡ªåŠ¨ç¼©æ”¾çš„é«˜æ•ˆç²¾å‡† FP8 å¤§è¯­è¨€æ¨¡å‹è®­ç»ƒ",
      "authors": [
        "Yu Zhang",
        "Hui-Ling Zhen",
        "Mingxuan Yuan",
        "Bei Yu"
      ],
      "abstract": "Training large language models with FP8 formats offers significant efficiency gains. However, the reduced numerical precision of FP8 poses challenges for stable and accurate training. Current frameworks preserve training performance using mixed-granularity quantization, i.e., applying per-group quantization for activations and per-tensor/block quantization for weights. While effective, per-group quantization requires scaling along the inner dimension of matrix multiplication, introducing additional dequantization overhead. Moreover, these frameworks often rely on just-in-time scaling to dynamically adjust scaling factors based on the current data distribution. However, this online quantization is inefficient for FP8 training, as it involves multiple memory reads and writes that negate the performance benefits of FP8. To overcome these limitations, we propose MOSS, a novel FP8 training framework that ensures both efficiency and numerical stability. MOSS introduces two key innovations: (1) a two-level microscaling strategy for quantizing sensitive activations, which balances precision and dequantization cost by combining a high-precision global scale with compact, power-of-two local scales; and (2) automatic scaling for weights in linear layers, which eliminates the need for costly max-reduction operations by predicting and adjusting scaling factors during training. Leveraging these techniques, MOSS enables efficient FP8 training of a 7B parameter model, achieving performance comparable to the BF16 baseline while achieving up to 34% higher training throughput.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†MOSSï¼Œä¸€ç§æ—¨åœ¨å…¼é¡¾æ•ˆç‡ä¸æ•°å€¼ç¨³å®šæ€§çš„æ–°å‹FP8è®­ç»ƒæ¡†æ¶ï¼Œä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹åœ¨ä½ç²¾åº¦è®­ç»ƒä¸­é¢ä¸´çš„æŒ‘æˆ˜ã€‚ç°æœ‰çš„FP8æ¡†æ¶é€šå¸¸ä¾èµ–æ··åˆç²’åº¦é‡åŒ–å’Œå³æ—¶ç¼©æ”¾ï¼ˆjust-in-time scalingï¼‰ï¼Œè¿™å¼•å…¥äº†é¢å¤–çš„åé‡åŒ–å¼€é”€å’Œå†…å­˜è¯»å†™æˆæœ¬ï¼ŒæŠµæ¶ˆäº†FP8çš„æ€§èƒ½ä¼˜åŠ¿ã€‚MOSSé€šè¿‡ä¸¤é¡¹å…³é”®åˆ›æ–°å…‹æœäº†è¿™äº›é™åˆ¶ï¼šä¸€æ˜¯é’ˆå¯¹æ•æ„Ÿæ¿€æ´»å€¼çš„ä¸¤çº§microscalingç­–ç•¥ï¼Œç»“åˆé«˜ç²¾åº¦å…¨å±€ç¼©æ”¾ä¸ç´§å‡‘çš„2çš„å¹‚æ¬¡å±€éƒ¨ç¼©æ”¾ï¼Œå¹³è¡¡äº†ç²¾åº¦ä¸è®¡ç®—æˆæœ¬ï¼›äºŒæ˜¯é’ˆå¯¹çº¿æ€§å±‚æƒé‡çš„automatic scalingï¼Œé€šè¿‡é¢„æµ‹å’Œè°ƒæ•´ç¼©æ”¾å› å­ï¼Œæ¶ˆé™¤äº†æ˜‚è´µçš„æœ€å¤§å€¼è§„çº¦ï¼ˆmax-reductionï¼‰æ“ä½œã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMOSSåœ¨7Bå‚æ•°æ¨¡å‹çš„FP8è®­ç»ƒä¸­è¾¾åˆ°äº†ä¸BF16åŸºçº¿ç›¸å½“çš„æ€§èƒ½ï¼ŒåŒæ—¶å®ç°äº†é«˜è¾¾34%çš„è®­ç»ƒååé‡æå‡ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.05811v2",
      "published_date": "2025-11-08 02:51:26 UTC",
      "updated_date": "2025-12-05 17:14:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:14:40.591921+00:00"
    },
    {
      "arxiv_id": "2511.05810v2",
      "title": "DiagnoLLM: A Hybrid Bayesian Neural Language Framework for Interpretable Disease Diagnosis",
      "title_zh": "DiagnoLLMï¼šç”¨äºå¯è§£é‡Šç–¾ç—…è¯Šæ–­çš„æ··åˆè´å¶æ–¯ç¥ç»è¯­è¨€æ¡†æ¶",
      "authors": [
        "Bowen Xu",
        "Xinyue Zeng",
        "Jiazhen Hu",
        "Tuo Wang",
        "Adithya Kulkarni"
      ],
      "abstract": "Building trustworthy clinical AI systems requires not only accurate predictions but also transparent, biologically grounded explanations. We present \\texttt{DiagnoLLM}, a hybrid framework that integrates Bayesian deconvolution, eQTL-guided deep learning, and LLM-based narrative generation for interpretable disease diagnosis. DiagnoLLM begins with GP-unmix, a Gaussian Process-based hierarchical model that infers cell-type-specific gene expression profiles from bulk and single-cell RNA-seq data while modeling biological uncertainty. These features, combined with regulatory priors from eQTL analysis, power a neural classifier that achieves high predictive performance in Alzheimer's Disease (AD) detection (88.0\\% accuracy). To support human understanding and trust, we introduce an LLM-based reasoning module that translates model outputs into audience-specific diagnostic reports, grounded in clinical features, attribution signals, and domain knowledge. Human evaluations confirm that these reports are accurate, actionable, and appropriately tailored for both physicians and patients. Our findings show that LLMs, when deployed as post-hoc reasoners rather than end-to-end predictors, can serve as effective communicators within hybrid diagnostic pipelines.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†DiagnoLLMï¼Œä¸€ç§æ··åˆè´å¶æ–¯ç¥ç»è¯­è¨€æ¡†æ¶ï¼Œæ—¨åœ¨å®ç°å¯è§£é‡Šçš„ç–¾ç—…è¯Šæ–­ã€‚DiagnoLLMé¦–å…ˆåˆ©ç”¨GP-unmixï¼Œä¸€ç§åŸºäºé«˜æ–¯è¿‡ç¨‹(Gaussian Process)çš„åˆ†å±‚æ¨¡å‹ï¼Œä»bulkå’Œsingle-cell RNA-seqæ•°æ®ä¸­æ¨æ–­ç»†èƒç±»å‹ç‰¹å¼‚æ€§åŸºå› è¡¨è¾¾è°±ï¼ŒåŒæ—¶å¯¹ç”Ÿç‰©å­¦ä¸ç¡®å®šæ€§è¿›è¡Œå»ºæ¨¡ã€‚ç»“åˆeQTLåˆ†æçš„è°ƒæ§å…ˆéªŒçŸ¥è¯†ï¼Œè¿™äº›ç‰¹å¾è¢«ç”¨äºé©±åŠ¨ç¥ç»åˆ†ç±»å™¨ï¼Œåœ¨é˜¿å°”èŒ¨æµ·é»˜ç—…(Alzheimer's Disease, AD)æ£€æµ‹ä¸­å®ç°äº†88.0%çš„é«˜å‡†ç¡®ç‡ã€‚ä¸ºäº†å¢å¼ºäººç±»ç†è§£å’Œä¿¡ä»»ï¼Œè¯¥æ¡†æ¶å¼•å…¥äº†ä¸€ä¸ªåŸºäºå¤§è¯­è¨€æ¨¡å‹(LLM)çš„æ¨ç†æ¨¡å—ï¼Œä¾æ®ä¸´åºŠç‰¹å¾å’Œé¢†åŸŸçŸ¥è¯†ï¼Œå°†æ¨¡å‹è¾“å‡ºè½¬åŒ–ä¸ºé’ˆå¯¹ç‰¹å®šå—ä¼—ï¼ˆå¦‚åŒ»ç”Ÿå’Œæ‚£è€…ï¼‰çš„è¯Šæ–­æŠ¥å‘Šã€‚äººå·¥è¯„ä¼°è¯å®è¿™äº›æŠ¥å‘Šå‡†ç¡®ä¸”å…·æœ‰å¯æ“ä½œæ€§ï¼Œç ”ç©¶ç»“æœè¡¨æ˜ï¼ŒLLMä½œä¸ºäº‹åæ¨ç†å™¨è€Œéç«¯åˆ°ç«¯é¢„æµ‹å™¨éƒ¨ç½²æ—¶ï¼Œèƒ½æœ‰æ•ˆå……å½“æ··åˆè¯Šæ–­æµç¨‹ä¸­çš„æ²Ÿé€šè€…ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.05810v2",
      "published_date": "2025-11-08 02:51:21 UTC",
      "updated_date": "2025-11-16 22:54:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:15:22.449644+00:00"
    },
    {
      "arxiv_id": "2511.05805v2",
      "title": "Measuring Model Performance in the Presence of an Intervention",
      "title_zh": "å­˜åœ¨å¹²é¢„ä¸‹çš„æ¨¡å‹æ€§èƒ½è¯„ä¼°",
      "authors": [
        "Winston Chen",
        "Michael W. Sjoding",
        "Jenna Wiens"
      ],
      "abstract": "AI models are often evaluated based on their ability to predict the outcome of interest. However, in many AI for social impact applications, the presence of an intervention that affects the outcome can bias the evaluation. Randomized controlled trials (RCTs) randomly assign interventions, allowing data from the control group to be used for unbiased model evaluation. However, this approach is inefficient because it ignores data from the treatment group. Given the complexity and cost often associated with RCTs, making the most use of the data is essential. Thus, we investigate model evaluation strategies that leverage all data from an RCT. First, we theoretically quantify the estimation bias that arises from naÃ¯vely aggregating performance estimates from treatment and control groups and derive the condition under which this bias leads to incorrect model selection. Leveraging these theoretical insights, we propose nuisance parameter weighting (NPW), an unbiased model evaluation approach that reweights data from the treatment group to mimic the distributions of samples that would or would not experience the outcome under no intervention. Using synthetic and real-world datasets, we demonstrate that our proposed evaluation approach consistently yields better model selection than the standard approach, which ignores data from the treatment group, across various intervention effect and sample size settings. Our contribution represents a meaningful step towards more efficient model evaluation in real-world contexts.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨å­˜åœ¨å¹²é¢„æªæ–½ï¼ˆInterventionï¼‰å½±å“ç»“æœçš„æƒ…å†µä¸‹ï¼Œå¦‚ä½•åˆ©ç”¨éšæœºå¯¹ç…§è¯•éªŒï¼ˆRCTsï¼‰çš„æ‰€æœ‰æ•°æ®è¿›è¡Œé«˜æ•ˆçš„AIæ¨¡å‹è¯„ä¼°ã€‚ä¼ ç»Ÿçš„è¯„ä¼°é€šå¸¸ä»…ä¾èµ–å¯¹ç…§ç»„æ•°æ®ä»¥é¿å…åå·®ï¼Œä½†è¿™å¯¼è‡´äº†æ•°æ®çš„æµªè´¹å’Œæ•ˆç‡ä½ä¸‹ã€‚ä½œè€…é¦–å…ˆä»ç†è®ºä¸Šé‡åŒ–äº†ç›´æ¥èšåˆæ²»ç–—ç»„å’Œå¯¹ç…§ç»„æ•°æ®æ‰€äº§ç”Ÿçš„ä¼°è®¡åå·®ï¼Œå¹¶æ¨å¯¼å‡ºäº†è¿™ç§åå·®å¯¼è‡´é”™è¯¯æ¨¡å‹é€‰æ‹©çš„å…·ä½“æ¡ä»¶ã€‚åŸºäºè¿™äº›ç†è®ºè§è§£ï¼Œè®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºâ€œå¹²æ‰°å‚æ•°åŠ æƒâ€ï¼ˆnuisance parameter weighting, NPWï¼‰çš„æ— åè¯„ä¼°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•é€šè¿‡é‡æ–°åŠ æƒæ²»ç–—ç»„æ•°æ®æ¥æ¨¡æ‹Ÿæ— å¹²é¢„æƒ…å†µä¸‹çš„æ ·æœ¬åˆ†å¸ƒã€‚åœ¨åˆæˆåŠçœŸå®æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œç›¸è¾ƒäºå¿½ç•¥æ²»ç–—ç»„æ•°æ®çš„æ ‡å‡†æ–¹æ³•ï¼ŒNPWåœ¨ä¸åŒçš„å¹²é¢„æ•ˆæœå’Œæ ·æœ¬å¤§å°è®¾ç½®ä¸‹å‡èƒ½å®ç°æ›´ä¼˜çš„æ¨¡å‹é€‰æ‹©ï¼Œæ˜¾è‘—æå‡äº†ç°å®åœºæ™¯ä¸­æ¨¡å‹è¯„ä¼°çš„æ•°æ®åˆ©ç”¨æ•ˆç‡ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "AAAI 2026",
      "pdf_url": "https://arxiv.org/pdf/2511.05805v2",
      "published_date": "2025-11-08 02:24:16 UTC",
      "updated_date": "2025-11-14 20:24:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:15:53.458308+00:00"
    },
    {
      "arxiv_id": "2511.05802v1",
      "title": "Beyond the Lower Bound: Bridging Regret Minimization and Best Arm Identification in Lexicographic Bandits",
      "title_zh": "è¶…è¶Šä¸‹ç•Œï¼šæ¡¥æ¥å­—å…¸åºè€è™æœºä¸­çš„é—æ†¾æœ€å°åŒ–ä¸æœ€ä¼˜è‡‚è¯†åˆ«",
      "authors": [
        "Bo Xue",
        "Yuanyu Wan",
        "Zhichao Lu",
        "Qingfu Zhang"
      ],
      "abstract": "In multi-objective decision-making with hierarchical preferences, lexicographic bandits provide a natural framework for optimizing multiple objectives in a prioritized order. In this setting, a learner repeatedly selects arms and observes reward vectors, aiming to maximize the reward for the highest-priority objective, then the next, and so on. While previous studies have primarily focused on regret minimization, this work bridges the gap between \\textit{regret minimization} and \\textit{best arm identification} under lexicographic preferences. We propose two elimination-based algorithms to address this joint objective. The first algorithm eliminates suboptimal arms sequentially, layer by layer, in accordance with the objective priorities, and achieves sample complexity and regret bounds comparable to those of the best single-objective algorithms. The second algorithm simultaneously leverages reward information from all objectives in each round, effectively exploiting cross-objective dependencies. Remarkably, it outperforms the known lower bound for the single-objective bandit problem, highlighting the benefit of cross-objective information sharing in the multi-objective setting. Empirical results further validate their superior performance over baselines.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å…·æœ‰å±‚çº§åå¥½çš„å¤šç›®æ ‡å†³ç­–é—®é¢˜ï¼Œåœ¨Lexicographic Banditsæ¡†æ¶ä¸‹è‡´åŠ›äºå¼¥åˆé—æ†¾æœ€å°åŒ–(Regret Minimization)ä¸æœ€ä½³è‡‚è¯†åˆ«(Best Arm Identification)ä¹‹é—´çš„å·®è·ã€‚ä½œè€…æå‡ºäº†ä¸¤ç§åŸºäºæ¶ˆé™¤(Elimination-based)çš„ç®—æ³•æ¥è§£å†³è¿™ä¸€è”åˆç›®æ ‡ã€‚ç¬¬ä¸€ç§ç®—æ³•æ ¹æ®ç›®æ ‡ä¼˜å…ˆçº§é€å±‚é¡ºåºæ¶ˆé™¤æ¬¡ä¼˜è‡‚(Arms)ï¼Œå®ç°äº†ä¸æœ€ä½³å•ç›®æ ‡ç®—æ³•ç›¸å½“çš„æ ·æœ¬å¤æ‚åº¦å’Œé—æ†¾ç•Œ(Regret Bounds)ã€‚ç¬¬äºŒç§ç®—æ³•åˆ™åœ¨æ¯ä¸€è½®ä¸­åŒæ—¶åˆ©ç”¨æ‰€æœ‰ç›®æ ‡çš„å¥–åŠ±ä¿¡æ¯ï¼Œæœ‰æ•ˆåˆ©ç”¨äº†è·¨ç›®æ ‡ä¾èµ–æ€§(Cross-objective Dependencies)ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œç¬¬äºŒç§ç®—æ³•çš„è¡¨ç°è¶…è¶Šäº†å·²çŸ¥å•ç›®æ ‡Bandité—®é¢˜çš„ä¸‹ç•Œ(Lower Bound)ï¼Œçªæ˜¾äº†å¤šç›®æ ‡è®¾ç½®ä¸­è·¨ç›®æ ‡ä¿¡æ¯å…±äº«çš„æ˜¾è‘—ä¼˜åŠ¿ï¼Œå®éªŒç»“æœä¹Ÿè¿›ä¸€æ­¥éªŒè¯äº†è¿™ä¸¤ç§æ–¹æ³•ç›¸æ¯”åŸºçº¿æ¨¡å‹çš„ä¼˜è¶Šæ€§èƒ½ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by AAAI 2026",
      "pdf_url": "https://arxiv.org/pdf/2511.05802v1",
      "published_date": "2025-11-08 02:22:33 UTC",
      "updated_date": "2025-11-08 02:22:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:16:10.001466+00:00"
    },
    {
      "arxiv_id": "2511.05797v1",
      "title": "When AI Meets the Web: Prompt Injection Risks in Third-Party AI Chatbot Plugins",
      "title_zh": "å½“ AI é‡ä¸Š Webï¼šç¬¬ä¸‰æ–¹ AI èŠå¤©æœºå™¨äººæ’ä»¶ä¸­çš„æç¤ºæ³¨å…¥é£é™©",
      "authors": [
        "Yigitcan Kaya",
        "Anton Landerer",
        "Stijn Pletinckx",
        "Michelle Zimmermann",
        "Christopher Kruegel",
        "Giovanni Vigna"
      ],
      "abstract": "Prompt injection attacks pose a critical threat to large language models (LLMs), with prior work focusing on cutting-edge LLM applications like personal copilots. In contrast, simpler LLM applications, such as customer service chatbots, are widespread on the web, yet their security posture and exposure to such attacks remain poorly understood. These applications often rely on third-party chatbot plugins that act as intermediaries to commercial LLM APIs, offering non-expert website builders intuitive ways to customize chatbot behaviors. To bridge this gap, we present the first large-scale study of 17 third-party chatbot plugins used by over 10,000 public websites, uncovering previously unknown prompt injection risks in practice. First, 8 of these plugins (used by 8,000 websites) fail to enforce the integrity of the conversation history transmitted in network requests between the website visitor and the chatbot. This oversight amplifies the impact of direct prompt injection attacks by allowing adversaries to forge conversation histories (including fake system messages), boosting their ability to elicit unintended behavior (e.g., code generation) by 3 to 8x. Second, 15 plugins offer tools, such as web-scraping, to enrich the chatbot's context with website-specific content. However, these tools do not distinguish the website's trusted content (e.g., product descriptions) from untrusted, third-party content (e.g., customer reviews), introducing a risk of indirect prompt injection. Notably, we found that ~13% of e-commerce websites have already exposed their chatbots to third-party content. We systematically evaluate both vulnerabilities through controlled experiments grounded in real-world observations, focusing on factors such as system prompt design and the underlying LLM. Our findings show that many plugins adopt insecure practices that undermine the built-in LLM safeguards.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è¢«è¶…è¿‡10,000ä¸ªå…¬å…±ç½‘ç«™ä½¿ç”¨çš„17ç§ç¬¬ä¸‰æ–¹AIèŠå¤©æœºå™¨äººæ’ä»¶ï¼Œè¿›è¡Œäº†å…³äºæç¤ºæ³¨å…¥(Prompt Injection)é£é™©çš„é¦–æ¬¡å¤§è§„æ¨¡å®è¯ç ”ç©¶ã€‚ç ”ç©¶æ­ç¤ºäº†ä¸¤ä¸ªä¸»è¦çš„å®‰å…¨æ¼æ´ï¼šé¦–å…ˆï¼Œ8ç§æ’ä»¶æœªèƒ½å¼ºåˆ¶æ‰§è¡Œç½‘ç»œè¯·æ±‚ä¸­ä¼ è¾“çš„å¯¹è¯å†å²å®Œæ•´æ€§ï¼Œå¯¼è‡´æ”»å‡»è€…èƒ½å¤Ÿä¼ªé€ å¯¹è¯è®°å½•ï¼ˆå«ä¼ªé€ çš„ç³»ç»Ÿæ¶ˆæ¯ï¼‰ï¼Œå°†ç›´æ¥æç¤ºæ³¨å…¥æ”»å‡»è¯±å‘æ„å¤–è¡Œä¸ºï¼ˆå¦‚ä»£ç ç”Ÿæˆï¼‰çš„æˆåŠŸç‡æé«˜äº†3åˆ°8å€ã€‚å…¶æ¬¡ï¼Œ15ç§æ’ä»¶åˆ©ç”¨ç½‘é¡µæŠ“å–(web-scraping)ç­‰å·¥å…·ä¸°å¯ŒèŠå¤©æœºå™¨äººä¸Šä¸‹æ–‡æ—¶ï¼Œæœªèƒ½åŒºåˆ†å—ä¿¡ä»»çš„ç½‘ç«™å†…å®¹ä¸ä¸å—ä¿¡ä»»çš„ç¬¬ä¸‰æ–¹å†…å®¹ï¼ˆå¦‚å®¢æˆ·è¯„è®ºï¼‰ï¼Œä»è€Œå¼•å…¥äº†é—´æ¥æç¤ºæ³¨å…¥é£é™©ã€‚æ•°æ®æ˜¾ç¤ºï¼Œçº¦13%çš„ç”µå­å•†åŠ¡ç½‘ç«™å·²å°†å…¶èŠå¤©æœºå™¨äººæš´éœ²äºæ­¤ç±»ç¬¬ä¸‰æ–¹å†…å®¹ä¸­ã€‚é€šè¿‡åŸºäºçœŸå®è§‚å¯Ÿçš„å—æ§å®éªŒï¼Œç ”ç©¶è¯æ˜è®¸å¤šæ’ä»¶é‡‡ç”¨äº†ä¸å®‰å…¨çš„å®è·µï¼Œä¸¥é‡ç ´åäº†å¤§å‹è¯­è¨€æ¨¡å‹(LLM)å†…ç½®çš„å®‰å…¨é˜²æŠ¤æœºåˆ¶ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "At IEEE S&P 2026",
      "pdf_url": "https://arxiv.org/pdf/2511.05797v1",
      "published_date": "2025-11-08 02:02:24 UTC",
      "updated_date": "2025-11-08 02:02:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:19:20.052148+00:00"
    },
    {
      "arxiv_id": "2511.05791v1",
      "title": "VLAD-Grasp: Zero-shot Grasp Detection via Vision-Language Models",
      "title_zh": "VLAD-Graspï¼šåŸºäºè§†è§‰è¯­è¨€æ¨¡å‹çš„é›¶æ ·æœ¬æŠ“å–æ£€æµ‹",
      "authors": [
        "Manav Kulshrestha",
        "S. Talha Bukhari",
        "Damon Conover",
        "Aniket Bera"
      ],
      "abstract": "Robotic grasping is a fundamental capability for autonomous manipulation; however, most existing methods rely on large-scale expert annotations and necessitate retraining to handle new objects. We present VLAD-Grasp, a Vision-Language model Assisted zero-shot approach for Detecting grasps. From a single RGB-D image, our method (1) prompts a large vision-language model to generate a goal image where a straight rod \"impales\" the object, representing an antipodal grasp, (2) predicts depth and segmentation to lift this generated image into 3D, and (3) aligns generated and observed object point clouds via principal component analysis and correspondence-free optimization to recover an executable grasp pose. Unlike prior work, our approach is training-free and does not rely on curated grasp datasets. Despite this, VLAD-Grasp achieves performance that is competitive with or superior to that of state-of-the-art supervised models on the Cornell and Jacquard datasets. We further demonstrate zero-shot generalization to novel real-world objects on a Franka Research 3 robot, highlighting vision-language foundation models as powerful priors for robotic manipulation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†VLAD-Graspï¼Œä¸€ç§åŸºäºè§†è§‰è¯­è¨€æ¨¡å‹(Vision-Language Models)è¾…åŠ©çš„é›¶æ ·æœ¬æŠ“å–æ£€æµ‹æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ–¹æ³•ä¾èµ–å¤§è§„æ¨¡ä¸“å®¶æ ‡æ³¨å’Œéœ€è¦é‡è®­ç»ƒçš„é—®é¢˜ã€‚è¯¥æ–¹æ³•ä»…éœ€å•å¼ RGB-Då›¾åƒï¼Œé¦–å…ˆæç¤ºå¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ç”Ÿæˆä¸€ä¸ªç›´æ†â€œç©¿é€â€ç‰©ä½“çš„ç›®æ ‡å›¾åƒä»¥è¡¨ç¤ºå¯¹æ˜ æŠ“å–ï¼Œæ¥ç€é¢„æµ‹æ·±åº¦å’Œåˆ†å‰²å°†å›¾åƒæå‡è‡³3Dç©ºé—´ã€‚éšåï¼Œé€šè¿‡ä¸»æˆåˆ†åˆ†æ(PCA)å’Œæ— å¯¹åº”ä¼˜åŒ–å°†ç”Ÿæˆç‚¹äº‘ä¸è§‚æµ‹ç‚¹äº‘å¯¹é½ï¼Œä»è€Œæ¢å¤å¯æ‰§è¡Œçš„æŠ“å–å§¿æ€ã€‚ä¸ä»¥å¾€å·¥ä½œä¸åŒï¼ŒVLAD-Graspæ— éœ€è®­ç»ƒä¸”ä¸ä¾èµ–æ•´ç†å¥½çš„æŠ“å–æ•°æ®é›†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨Cornellå’ŒJacquardæ•°æ®é›†ä¸Šçš„è¡¨ç°ä¸æœ€å…ˆè¿›çš„ç›‘ç£æ¨¡å‹ç›¸å½“ç”šè‡³æ›´ä¼˜ã€‚æ­¤å¤–ï¼Œåœ¨Franka Research 3æœºå™¨äººä¸Šçš„å®éªŒè¿›ä¸€æ­¥å±•ç¤ºäº†å…¶å¯¹ç°å®ä¸–ç•Œæ–°ç‰©ä½“çš„é›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›ï¼Œçªæ˜¾äº†è§†è§‰è¯­è¨€åŸºç¡€æ¨¡å‹ä½œä¸ºæœºå™¨äººæ“ä½œå…ˆéªŒçš„å¼ºå¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 4 figures, under review",
      "pdf_url": "https://arxiv.org/pdf/2511.05791v1",
      "published_date": "2025-11-08 01:47:40 UTC",
      "updated_date": "2025-11-08 01:47:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:19:43.244264+00:00"
    },
    {
      "arxiv_id": "2511.05790v1",
      "title": "SymLight: Exploring Interpretable and Deployable Symbolic Policies for Traffic Signal Control",
      "title_zh": "SymLightï¼šæ¢ç´¢ç”¨äºäº¤é€šä¿¡å·æ§åˆ¶çš„å¯è§£é‡Šä¸å¯éƒ¨ç½²ç¬¦å·ç­–ç•¥",
      "authors": [
        "Xiao-Cheng Liao",
        "Yi Mei",
        "Mengjie Zhang"
      ],
      "abstract": "Deep Reinforcement Learning have achieved significant success in automatically devising effective traffic signal control (TSC) policies. Neural policies, however, tend to be over-parameterized and non-transparent, hindering their interpretability and deployability on resource-limited edge devices. This work presents SymLight, a priority function search framework based on Monte Carlo Tree Search (MCTS) for discovering inherently interpretable and deployable symbolic priority functions to serve as the TSC policies. The priority function, in particular, accepts traffic features as input and then outputs a priority for each traffic signal phase, which subsequently directs the phase transition. For effective search, we propose a concise yet expressive priority function representation. This helps mitigate the combinatorial explosion of the action space in MCTS. Additionally, a probabilistic structural rollout strategy is introduced to leverage structural patterns from previously discovered high-quality priority functions, guiding the rollout process. Our experiments on real-world datasets demonstrate SymLight's superior performance across a range of baselines. A key advantage is SymLight's ability to produce interpretable and deployable TSC policies while maintaining excellent performance.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ·±åº¦å¼ºåŒ–å­¦ä¹ ç”Ÿæˆçš„äº¤é€šä¿¡å·æ§åˆ¶(TSC)ç­–ç•¥å­˜åœ¨çš„å‚æ•°è¿‡å¤šã€ç¼ºä¹é€æ˜åº¦ä»¥åŠéš¾ä»¥åœ¨èµ„æºå—é™è¾¹ç¼˜è®¾å¤‡ä¸Šéƒ¨ç½²çš„é—®é¢˜ï¼Œæå‡ºäº†SymLightæ¡†æ¶ã€‚è¿™æ˜¯ä¸€ä¸ªåŸºäºè’™ç‰¹å¡æ´›æ ‘æœç´¢(MCTS)çš„ä¼˜å…ˆçº§å‡½æ•°æœç´¢æ¡†æ¶ï¼Œæ—¨åœ¨å‘ç°æœ¬è´¨ä¸Šå¯è§£é‡Šä¸”æ˜“äºéƒ¨ç½²çš„ç¬¦å·ä¼˜å…ˆçº§å‡½æ•°ä½œä¸ºæ§åˆ¶ç­–ç•¥ã€‚ä¸ºäº†æœ‰æ•ˆæœç´¢ï¼Œç ”ç©¶å›¢é˜Ÿæå‡ºäº†ä¸€ç§ç®€æ´è€Œå¯Œæœ‰è¡¨ç°åŠ›çš„å‡½æ•°è¡¨ç¤ºæ³•ä»¥ç¼“è§£ç»„åˆçˆ†ç‚¸ï¼Œå¹¶å¼•å…¥äº†æ¦‚ç‡ç»“æ„åŒ–rolloutç­–ç•¥æ¥åˆ©ç”¨å…ˆå‰å‘ç°çš„é«˜è´¨é‡å‡½æ•°çš„ç»“æ„æ¨¡å¼ã€‚åœ¨çœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒSymLightåœ¨ä¿æŒå“è¶Šæ€§èƒ½çš„åŒæ—¶ï¼Œæ˜¾è‘—ä¼˜äºä¸€ç³»åˆ—åŸºçº¿æ¨¡å‹ã€‚è¯¥æ–¹æ³•çš„æ ¸å¿ƒè´¡çŒ®åœ¨äºæˆåŠŸç”Ÿæˆäº†å…¼å…·é«˜æ€§èƒ½ã€å¯è§£é‡Šæ€§å’Œå¯éƒ¨ç½²æ€§çš„TSCç­–ç•¥ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.05790v1",
      "published_date": "2025-11-08 01:45:49 UTC",
      "updated_date": "2025-11-08 01:45:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:20:04.445916+00:00"
    },
    {
      "arxiv_id": "2511.05784v2",
      "title": "DRAGON: Guard LLM Unlearning in Context via Negative Detection and Reasoning",
      "title_zh": "DRAGONï¼šåŸºäºè´Ÿé¢æ£€æµ‹ä¸æ¨ç†çš„LLMä¸Šä¸‹æ–‡æœºå™¨é—å¿˜é˜²æŠ¤",
      "authors": [
        "Yaxuan Wang",
        "Chris Yuhao Liu",
        "Quan Liu",
        "Jinglong Pang",
        "Wei Wei",
        "Yujia Bao",
        "Yang Liu"
      ],
      "abstract": "Unlearning in Large Language Models (LLMs) is crucial for protecting private data and removing harmful knowledge. Most existing approaches rely on fine-tuning to balance unlearning efficiency with general language capabilities. However, these methods typically require training or access to retain data, which is often unavailable in real world scenarios. Although these methods can perform well when both forget and retain data are available, few works have demonstrated equivalent capability in more practical, data-limited scenarios. To overcome these limitations, we propose Detect-Reasoning Augmented GeneratiON (DRAGON), a systematic, reasoning-based framework that utilizes in-context chain-of-thought (CoT) instructions to guard deployed LLMs before inference. Instead of modifying the base model, DRAGON leverages the inherent instruction-following ability of LLMs and introduces a lightweight detection module to identify forget-worthy prompts without any retain data. These are then routed through a dedicated CoT guard model to enforce safe and accurate in-context intervention. To robustly evaluate unlearning performance, we introduce novel metrics for unlearning performance and the continual unlearning setting. Extensive experiments across three representative unlearning tasks validate the effectiveness of DRAGON, demonstrating its strong unlearning capability, scalability, and applicability in practical scenarios.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨ä¿æŠ¤éšç§æ•°æ®å’Œæ¶ˆé™¤æœ‰å®³çŸ¥è¯†æ–¹é¢çš„éœ€æ±‚ï¼Œæå‡ºäº†DRAGONï¼ˆDetect-Reasoning Augmented GeneratiONï¼‰ï¼Œä¸€ç§åŸºäºæ¨ç†çš„ç³»ç»Ÿæ¡†æ¶ã€‚é’ˆå¯¹ç°æœ‰Unlearningæ–¹æ³•ä¾èµ–å¾®è°ƒå’Œä¿ç•™æ•°æ®ï¼ˆretain dataï¼‰çš„å±€é™æ€§ï¼ŒDRAGONåˆ©ç”¨ä¸Šä¸‹æ–‡é“¾å¼æ€ç»´(Chain-of-Thought, CoT)æŒ‡ä»¤åœ¨æ¨ç†å‰å¯¹æ¨¡å‹è¿›è¡Œé˜²æŠ¤ï¼Œè€Œæ— éœ€ä¿®æ”¹åŸºç¡€æ¨¡å‹å‚æ•°ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†ä¸€ä¸ªè½»é‡çº§æ£€æµ‹æ¨¡å—æ¥è¯†åˆ«æ— éœ€ä¿ç•™æ•°æ®çš„å¾…é—å¿˜æç¤º(forget-worthy prompts)ï¼Œå¹¶é€šè¿‡ä¸“ç”¨çš„CoTé˜²å¾¡æ¨¡å‹æ‰§è¡Œå®‰å…¨å‡†ç¡®çš„ä¸Šä¸‹æ–‡å¹²é¢„ã€‚ä¸ºäº†å…¨é¢è¯„ä¼°æ•ˆæœï¼Œç ”ç©¶è¿˜æå‡ºäº†é’ˆå¯¹Unlearningæ€§èƒ½å’ŒæŒç»­é—å¿˜(continual unlearning)è®¾ç½®çš„æ–°æŒ‡æ ‡ã€‚åœ¨ä¸‰ä¸ªä»£è¡¨æ€§ä»»åŠ¡ä¸Šçš„å¹¿æ³›å®éªŒè¯æ˜äº†DRAGONçš„æœ‰æ•ˆæ€§ï¼Œå±•ç¤ºäº†å…¶åœ¨å®é™…æ•°æ®å—é™åœºæ™¯ä¸‹å¼ºå¤§çš„é—å¿˜èƒ½åŠ›ã€å¯æ‰©å±•æ€§å’Œé€‚ç”¨æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Please refer to the NeurIPS 2025 submission: https://openreview.net/forum?id=FNuul0hlin The paper has been accepted to the ICML 2025 MUGen Workshop: https://openreview.net/forum?id=ET24oKP23c",
      "pdf_url": "https://arxiv.org/pdf/2511.05784v2",
      "published_date": "2025-11-08 01:13:28 UTC",
      "updated_date": "2025-11-11 05:42:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:20:50.517662+00:00"
    },
    {
      "arxiv_id": "2511.05772v1",
      "title": "Sign language recognition from skeletal data using graph and recurrent neural networks",
      "title_zh": "åŸºäºå›¾ç¥ç»ç½‘ç»œä¸å¾ªç¯ç¥ç»ç½‘ç»œçš„éª¨éª¼æ•°æ®æ‰‹è¯­è¯†åˆ«",
      "authors": [
        "B. Mederos",
        "J. MejÃ­a",
        "A. Medina-Reyes",
        "Y. Espinosa-Almeyda",
        "J. D. DÃ­az-Roman",
        "I. RodrÃ­guez-Mederos",
        "M. MejÃ­a-Carreon",
        "F. Gonzalez-Lopez"
      ],
      "abstract": "This work presents an approach for recognizing isolated sign language gestures using skeleton-based pose data extracted from video sequences. A Graph-GRU temporal network is proposed to model both spatial and temporal dependencies between frames, enabling accurate classification. The model is trained and evaluated on the AUTSL (Ankara university Turkish sign language) dataset, achieving high accuracy. Experimental results demonstrate the effectiveness of integrating graph-based spatial representations with temporal modeling, providing a scalable framework for sign language recognition. The results of this approach highlight the potential of pose-driven methods for sign language understanding.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åˆ©ç”¨ä»è§†é¢‘åºåˆ—ä¸­æå–çš„éª¨éª¼å§¿æ€æ•°æ®(skeleton-based pose data)æ¥è¯†åˆ«å­¤ç«‹æ‰‹è¯­æ‰‹åŠ¿çš„æ–¹æ³•ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†Graph-GRU temporal networkï¼Œæ—¨åœ¨åŒæ—¶å»ºæ¨¡å¸§é—´çš„ç©ºé—´å’Œæ—¶é—´ä¾èµ–å…³ç³»ä»¥å®ç°ç²¾ç¡®åˆ†ç±»ã€‚è¯¥æ¨¡å‹åœ¨AUTSL (Ankara University Turkish Sign Language)æ•°æ®é›†ä¸Šè¿›è¡Œäº†è®­ç»ƒå’Œè¯„ä¼°ï¼Œå–å¾—äº†è¾ƒé«˜çš„å‡†ç¡®ç‡ã€‚å®éªŒç»“æœéªŒè¯äº†å°†åŸºäºå›¾çš„ç©ºé—´è¡¨ç¤ºä¸æ—¶é—´å»ºæ¨¡ç›¸ç»“åˆçš„æœ‰æ•ˆæ€§ï¼Œä¸ºæ‰‹è¯­è¯†åˆ«æä¾›äº†ä¸€ä¸ªå¯æ‰©å±•çš„æ¡†æ¶ã€‚è¯¥æ–¹æ³•çªæ˜¾äº†å§¿æ€é©±åŠ¨(pose-driven)æ–¹æ³•åœ¨æ‰‹è¯­ç†è§£ä»»åŠ¡ä¸­çš„æ½œåŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages, 2 figures",
      "pdf_url": "https://arxiv.org/pdf/2511.05772v1",
      "published_date": "2025-11-08 00:04:42 UTC",
      "updated_date": "2025-11-08 00:04:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T17:20:55.818806+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 85,
  "processed_papers_count": 85,
  "failed_papers_count": 0,
  "llm_backup_calls": 170,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-01-25T18:11:27.433243+00:00"
}