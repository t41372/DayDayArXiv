{
  "date": "2024-09-07",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-09-07 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 和机器学习领域的创新，包括大型语言模型 (LLM) 的优化、强化学习应用、图像处理和生物医疗模型，其中 POINTS 和 Selective Self-Rehearsal 等论文令人印象深刻，它们展示了高效的模型训练和泛化提升；此外，强化学习在云计算和机器人领域的应用也值得关注。\n\n下面，我挑选了其中最具代表性和话题度的论文进行简要讨论，先从 LLM 和 NLP 相关的高影响力论文入手，然后快速概述强化学习、计算机视觉以及其他领域的关键贡献。其他较常规或技术细节较深的论文（如一些纯理论框架或小规模实验）将简略掠过，以控制篇幅。\n\n### LLM 和 NLP 相关论文\n这些论文探讨了语言模型的优化和鲁棒性，提升了模型在实际应用中的性能。\n- **POINTS: Improving Your Vision-language Model with Affordable Strategies（中文：POINTS：一种高效策略提升视觉语言模型）**  \n  这篇论文提出了一种经济高效的框架，使用困惑度过滤数据和模型融合策略，优化视觉语言模型的预训练和微调。核心贡献是通过在1M数据上训练，实现与大型模型相当的性能，同时减少计算开销，适用于图像分类和医疗任务，展示了LLM在资源有限场景下的实用性。\n\n- **Selective Self-Rehearsal: A Fine-Tuning Approach to Improve Generalization in Large Language Models（中文：选择性自重述：一种提升大型语言模型泛化的微调方法）**  \n  作者提出 Selective Self-Rehearsal 框架，通过利用模型自身的正确响应进行微调，减少过拟合。关键发现是，该方法在无答案查询识别任务上显著提升泛化能力，比标准微调减少16.7%的性能下降，适用于教育和医疗领域。\n\n- **Exploring Straightforward Conversational Red-Teaming（中文：探索简单对话红队测试）**  \n  这篇研究使用现成LLM进行对话红队测试，评估模型的安全性。贡献在于发现多轮对话策略能有效识别模型漏洞，但攻击效果会随模型对齐度降低，强调了LLM在实际部署中的伦理风险。\n\n其他NLP论文如 DiVA-DocRE（中文：DiVA-DocRE：一种判别式和语音感知的文档级关系抽取范式），提出了一种高效的文档级关系抽取方法，但由于作者已撤稿，其影响力有限，仅提及其创新性在于将关系抽取转化为判别任务。\n\n### 强化学习和AI优化论文\n强化学习相关论文强调了算法在动态环境中的应用，提升了效率和鲁棒性。\n- **Reward-Directed Score-Based Diffusion Models via q-Learning（中文：基于q学习的奖励导向分数扩散模型）**  \n  这篇论文将强化学习应用于扩散模型，提出一种无需预训练的框架，用于生成高奖励样本。核心发现是通过q学习优化高斯策略，显著提升生成AI的性能，尤其在图像生成任务中，提供了新的RL-AI融合路径。\n\n- **Improving Deep Reinforcement Learning by Reducing the Chain Effect of Value and Policy Churn（中文：通过减少价值和策略波动链式效应提升深度强化学习）**  \n  作者分析了RL中的波动问题，提出 CHAIN 方法减少价值估计和策略更新的连锁效应。贡献在于实验证明，该方法在在线和离线RL任务中提升学习性能，适用于机器人控制和决策系统。\n\n其他如 Reinforcement Learning-Based Adaptive Load Balancing（中文：基于强化学习的自适应负载均衡），快速提到其在云环境中的应用，通过RL优化资源利用，但细节较常规，故从简。\n\n### 计算机视觉和图像处理论文\n这些论文聚焦于模型效率和实际应用。\n- **MoistNet: Machine Vision-based Deep Learning Models for Wood Chip Moisture Content Measurement（中文：MoistNet：基于机器视觉的木材水分测量深度学习模型）**  \n  论文开发了 MoistNetLite 和 MoistNetMax 模型，使用神经架构搜索预测木材水分。关键发现是，模型在RGB图像上达到91%的准确率，提供了一种便携、非破坏性的测量方法，对林业和生物燃料行业有实际影响。\n\n- **FreeAugment: Data Augmentation Search Across All Degrees of Freedom（中文：FreeAugment：跨所有自由度的数据增强搜索）**  \n  这篇论文提出 FreeAugment 框架，全局优化数据增强策略，包括增强类型和顺序。贡献在于实验显示，它在图像基准上超越现有方法，提升模型泛化，核心术语如微分优化和概率分布被保留。\n\n其他视觉论文如 Activation Function Optimization Scheme（中文：激活函数优化方案），提及其通过进化算法优化激活函数，提升图像分类准确率，但不展开。\n\n### 其他领域快速概述\n- **生物和医疗应用**：如 Nearest Neighbor CCP-Based Molecular Sequence Analysis（中文：基于最近邻CCP的分子序列分析），提出高效的序列聚类方法，提升生物数据分类准确率；VidLPRO（中文：VidLPRO：机器人和腹腔镜手术的视频语言预训练框架），在手术视频上实现SOTA性能，但限于专业领域，仅简述其多模态集成优势。\n  \n- **机器人和硬件优化**：Learning to Open and Traverse Doors with a Legged Manipulator（中文：学习使用腿部机械臂开门和穿越），使用强化学习训练机器人处理门操作，成功率达95%，展示了实际部署潜力。\n\n- **其他常规论文**：如 FedModule（中文：FedModule：联邦学习模块化框架），提供联邦学习基准，但作为技术报告，快速掠过；Algorithmic Scenario Generation（中文：算法场景生成作为质量多样性优化），聚焦RL测试，但影响力一般。\n\n总体而言，今天的 arXiv 更新突显了 AI 领域的快速迭代，LLM 和强化学习论文尤其值得跟踪。感兴趣的读者可关注上述关键论文的链接或代码仓库，以深入探索。明天见！",
  "papers": [
    {
      "arxiv_id": "2409.04934v2",
      "title": "Maximizing Relation Extraction Potential: A Data-Centric Study to Unveil Challenges and Opportunities",
      "title_zh": "翻译失败",
      "authors": [
        "Anushka Swarup",
        "Avanti Bhandarkar",
        "Olivia P. Dizon-Paradis",
        "Ronald Wilson",
        "Damon L. Woodard"
      ],
      "abstract": "Relation extraction is a Natural Language Processing task that aims to\nextract relationships from textual data. It is a critical step for information\nextraction. Due to its wide-scale applicability, research in relation\nextraction has rapidly scaled to using highly advanced neural networks. Despite\ntheir computational superiority, modern relation extractors fail to handle\ncomplicated extraction scenarios. However, a comprehensive performance analysis\nof the state-of-the-art extractors that compile these challenges has been\nmissing from the literature, and this paper aims to bridge this gap. The goal\nhas been to investigate the possible data-centric characteristics that impede\nneural relation extraction. Based on extensive experiments conducted using 15\nstate-of-the-art relation extraction algorithms ranging from recurrent\narchitectures to large language models and seven large-scale datasets, this\nresearch suggests that modern relation extractors are not robust to complex\ndata and relation characteristics. It emphasizes pivotal issues, such as\ncontextual ambiguity, correlating relations, long-tail data, and fine-grained\nrelation distributions. In addition, it sets a marker for future directions to\nalleviate these issues, thereby proving to be a critical resource for novice\nand advanced researchers. Efficient handling of the challenges described can\nhave significant implications for the field of information extraction, which is\na critical part of popular systems such as search engines and chatbots. Data\nand relevant code can be found at\n\\url{https://aaig.ece.ufl.edu/projects/relation-extraction}.",
      "tldr_zh": "这篇论文以数据为中心，探讨了关系抽取(Relation Extraction)任务的挑战和机遇，旨在揭示现代神经网络模型在处理复杂文本关系时的局限性。通过对15种最先进的关系抽取算法（从循环架构到大型语言模型）和7个大规模数据集的广泛实验，研究发现这些模型对上下文模糊、相关关系、长尾数据以及细粒度关系分布等数据特征缺乏鲁棒性。论文强调了这些问题的关键影响，并为未来研究提供了方向，以提升信息抽取领域的性能，从而支持应用如搜索引擎和聊天机器人等系统。该研究还公开了数据和代码资源，以促进进一步探索。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "This work has been published to the IEEE Access (2024)",
      "pdf_url": "http://arxiv.org/pdf/2409.04934v2",
      "published_date": "2024-09-07 23:40:47 UTC",
      "updated_date": "2024-11-25 20:16:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:02:53.470849"
    },
    {
      "arxiv_id": "2409.04926v1",
      "title": "A $Δ$-evaluation function for column permutation problems",
      "title_zh": "翻译失败",
      "authors": [
        "Júnior R. Lima",
        "Viníicius Gandra M. Santos",
        "Marco Antonio M. Carvalho"
      ],
      "abstract": "In this study, a new $\\Delta$-evaluation method is introduced for solving a\ncolumn permutation problem defined on a sparse binary matrix with the\nconsecutive ones property. This problem models various $\\mathcal{NP}$-hard\nproblems in graph theory and industrial manufacturing contexts. The\ncomputational experiments compare the processing time of the\n$\\Delta$-evaluation method with two other methods used in well-known local\nsearch procedures. The study considers a comprehensive set of instances of\nwell-known problems, such as Gate Matrix Layout and Minimization of Open\nStacks. The proposed evaluation method is generally competitive and\nparticularly useful for large and dense instances. It can be easily integrated\ninto local search and metaheuristic algorithms to improve solutions without\nsignificantly increasing processing time.",
      "tldr_zh": "本研究引入了一种新的 $Δ$-evaluation 函数，用于解决具有连续 ones 属性的稀疏二进制矩阵上的列置换问题，该问题建模了图论和工业制造中的各种 NP-hard 问题。实验通过比较处理时间，将该方法与其他本地搜索程序中的方法进行评估，涵盖了 Gate Matrix Layout 和 Minimization of Open Stacks 等典型实例。结果显示，$Δ$-evaluation 函数在大型密集实例中表现出色，且易于整合到本地搜索和元启发式算法中，以提升解决方案质量而不显著增加计算开销。",
      "categories": [
        "cs.AI",
        "math.CO",
        "math.OC",
        "90",
        "J.6"
      ],
      "primary_category": "cs.AI",
      "comment": "technical report",
      "pdf_url": "http://arxiv.org/pdf/2409.04926v1",
      "published_date": "2024-09-07 22:50:25 UTC",
      "updated_date": "2024-09-07 22:50:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:03:05.758605"
    },
    {
      "arxiv_id": "2409.04922v1",
      "title": "Nearest Neighbor CCP-Based Molecular Sequence Analysis",
      "title_zh": "基于最近邻 CCP 的分子序列分析",
      "authors": [
        "Sarwan Ali",
        "Prakash Chourasia",
        "Bipin Koirala",
        "Murray Patterson"
      ],
      "abstract": "Molecular sequence analysis is crucial for comprehending several biological\nprocesses, including protein-protein interactions, functional annotation, and\ndisease classification. The large number of sequences and the inherently\ncomplicated nature of protein structures make it challenging to analyze such\ndata. Finding patterns and enhancing subsequent research requires the use of\ndimensionality reduction and feature selection approaches. Recently, a method\ncalled Correlated Clustering and Projection (CCP) has been proposed as an\neffective method for biological sequencing data. The CCP technique is still\ncostly to compute even though it is effective for sequence visualization.\nFurthermore, its utility for classifying molecular sequences is still\nuncertain. To solve these two problems, we present a Nearest Neighbor\nCorrelated Clustering and Projection (CCP-NN)-based technique for efficiently\npreprocessing molecular sequence data. To group related molecular sequences and\nproduce representative supersequences, CCP makes use of sequence-to-sequence\ncorrelations. As opposed to conventional methods, CCP doesn't rely on matrix\ndiagonalization, therefore it can be applied to a range of machine-learning\nproblems. We estimate the density map and compute the correlation using a\nnearest-neighbor search technique. We performed molecular sequence\nclassification using CCP and CCP-NN representations to assess the efficacy of\nour proposed approach. Our findings show that CCP-NN considerably improves\nclassification task accuracy as well as significantly outperforms CCP in terms\nof computational runtime.",
      "tldr_zh": "本研究针对分子序列分析的挑战（如序列数量多和蛋白结构复杂），提出了一种Nearest Neighbor CCP (CCP-NN)方法，用于高效预处理分子序列数据。CCP-NN基于原有Correlated Clustering and Projection (CCP)技术，通过最近邻搜索估计密度图并计算序列相关性，从而分组相关序列并生成代表性超序列，而不依赖矩阵对角化。实验结果显示，CCP-NN在分子序列分类任务中显著提高了准确率，并大幅缩短了计算运行时间，优于传统CCP方法，从而为蛋白质相互作用、功能注释和疾病分类等生物过程提供更有效的工具。",
      "categories": [
        "q-bio.GN",
        "cs.AI",
        "cs.CC",
        "cs.LG"
      ],
      "primary_category": "q-bio.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04922v1",
      "published_date": "2024-09-07 22:06:00 UTC",
      "updated_date": "2024-09-07 22:06:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:03:18.040995"
    },
    {
      "arxiv_id": "2409.04920v1",
      "title": "MoistNet: Machine Vision-based Deep Learning Models for Wood Chip Moisture Content Measurement",
      "title_zh": "翻译失败",
      "authors": [
        "Abdur Rahman",
        "Jason Street",
        "James Wooten",
        "Mohammad Marufuzzaman",
        "Veera G. Gude",
        "Randy Buchanan",
        "Haifeng Wang"
      ],
      "abstract": "Quick and reliable measurement of wood chip moisture content is an\neverlasting problem for numerous forest-reliant industries such as biofuel,\npulp and paper, and bio-refineries. Moisture content is a critical attribute of\nwood chips due to its direct relationship with the final product quality.\nConventional techniques for determining moisture content, such as oven-drying,\npossess some drawbacks in terms of their time-consuming nature, potential\nsample damage, and lack of real-time feasibility. Furthermore, alternative\ntechniques, including NIR spectroscopy, electrical capacitance, X-rays, and\nmicrowaves, have demonstrated potential; nevertheless, they are still\nconstrained by issues related to portability, precision, and the expense of the\nrequired equipment. Hence, there is a need for a moisture content determination\nmethod that is instant, portable, non-destructive, inexpensive, and precise.\nThis study explores the use of deep learning and machine vision to predict\nmoisture content classes from RGB images of wood chips. A large-scale image\ndataset comprising 1,600 RGB images of wood chips has been collected and\nannotated with ground truth labels, utilizing the results of the oven-drying\ntechnique. Two high-performing neural networks, MoistNetLite and MoistNetMax,\nhave been developed leveraging Neural Architecture Search (NAS) and\nhyperparameter optimization. The developed models are evaluated and compared\nwith state-of-the-art deep learning models. Results demonstrate that\nMoistNetLite achieves 87% accuracy with minimal computational overhead, while\nMoistNetMax exhibits exceptional precision with a 91% accuracy in wood chip\nmoisture content class prediction. With improved accuracy and faster prediction\nspeed, our proposed MoistNet models hold great promise for the wood chip\nprocessing industry.",
      "tldr_zh": "本研究针对木屑水分含量测量的问题，指出传统方法如oven-drying耗时、非实时且可能破坏样本，而其他技术如NIR spectroscopy也受限于便携性和成本，提出使用机器视觉和深度学习从RGB图像预测水分含量类别。研究收集了1600张标注图像，并开发了MoistNetLite和MoistNetMax模型，通过Neural Architecture Search (NAS)和超参数优化提升性能。结果显示，MoistNetLite达到87%准确率且计算开销小，MoistNetMax则实现91%准确率，比现有模型更高效，为木屑加工行业提供即时、非破坏性和廉价的测量解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04920v1",
      "published_date": "2024-09-07 22:03:13 UTC",
      "updated_date": "2024-09-07 22:03:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:03:31.450991"
    },
    {
      "arxiv_id": "2409.04915v1",
      "title": "Activation Function Optimization Scheme for Image Classification",
      "title_zh": "图像分类的激活函数优化方案",
      "authors": [
        "Abdur Rahman",
        "Lu He",
        "Haifeng Wang"
      ],
      "abstract": "Activation function has a significant impact on the dynamics, convergence,\nand performance of deep neural networks. The search for a consistent and\nhigh-performing activation function has always been a pursuit during deep\nlearning model development. Existing state-of-the-art activation functions are\nmanually designed with human expertise except for Swish. Swish was developed\nusing a reinforcement learning-based search strategy. In this study, we propose\nan evolutionary approach for optimizing activation functions specifically for\nimage classification tasks, aiming to discover functions that outperform\ncurrent state-of-the-art options. Through this optimization framework, we\nobtain a series of high-performing activation functions denoted as Exponential\nError Linear Unit (EELU). The developed activation functions are evaluated for\nimage classification tasks from two perspectives: (1) five state-of-the-art\nneural network architectures, such as ResNet50, AlexNet, VGG16, MobileNet, and\nCompact Convolutional Transformer which cover computationally heavy to light\nneural networks, and (2) eight standard datasets, including CIFAR10,\nImagenette, MNIST, Fashion MNIST, Beans, Colorectal Histology, CottonWeedID15,\nand TinyImageNet which cover from typical machine vision benchmark,\nagricultural image applications to medical image applications. Finally, we\nstatistically investigate the generalization of the resultant activation\nfunctions developed through the optimization scheme. With a Friedman test, we\nconclude that the optimization scheme is able to generate activation functions\nthat outperform the existing standard ones in 92.8% cases among 28 different\ncases studied, and $-x\\cdot erf(e^{-x})$ is found to be the best activation\nfunction for image classification generated by the optimization scheme.",
      "tldr_zh": "本研究提出了一种进化方法（evolutionary approach）来优化激活函数，针对图像分类任务，以发现优于现有最先进选项（如Swish）的函数。研究开发了Exponential Error Linear Unit (EELU)系列高性能激活函数，并通过五种神经网络架构（ResNet50、AlexNet、VGG16、MobileNet和Compact Convolutional Transformer）和八个标准数据集（CIFAR10、Imagenette、MNIST等）进行评估。结果表明，这些优化函数在92.8%的案例中超越了现有标准激活函数，其中$-x \\cdot erf(e^{-x})$被确定为图像分类的最佳激活函数。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04915v1",
      "published_date": "2024-09-07 21:40:15 UTC",
      "updated_date": "2024-09-07 21:40:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:03:43.749095"
    },
    {
      "arxiv_id": "2409.04909v1",
      "title": "Efficient Training of Transformers for Molecule Property Prediction on Small-scale Datasets",
      "title_zh": "在小规模数据集上用于分子属性预测的Transformer高效训练",
      "authors": [
        "Shivesh Prakash"
      ],
      "abstract": "The blood-brain barrier (BBB) serves as a protective barrier that separates\nthe brain from the circulatory system, regulating the passage of substances\ninto the central nervous system. Assessing the BBB permeability of potential\ndrugs is crucial for effective drug targeting. However, traditional\nexperimental methods for measuring BBB permeability are challenging and\nimpractical for large-scale screening. Consequently, there is a need to develop\ncomputational approaches to predict BBB permeability. This paper proposes a GPS\nTransformer architecture augmented with Self Attention, designed to perform\nwell in the low-data regime. The proposed approach achieved a state-of-the-art\nperformance on the BBB permeability prediction task using the BBBP dataset,\nsurpassing existing models. With a ROC-AUC of 78.8%, the approach sets a\nstate-of-the-art by 5.5%. We demonstrate that standard Self Attention coupled\nwith GPS transformer performs better than other variants of attention coupled\nwith GPS Transformer.",
      "tldr_zh": "该论文针对小规模数据集，提出了一种增强了 Self Attention 的 GPS Transformer 架构，用于高效训练 Transformer 模型预测分子属性，特别是血脑屏障 (BBB) 渗透性。方法通过结合标准 Self Attention 和 GPS Transformer，在 BBBP 数据集上实现了 78.8% 的 ROC-AUC 成绩，比现有模型提高了 5.5%，达到了 state-of-the-art 水平。研究证明，这种注意力机制组合在低数据环境下优于其他变体，为药物筛选提供了一种高效的计算方法。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.CE",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04909v1",
      "published_date": "2024-09-07 21:07:12 UTC",
      "updated_date": "2024-09-07 21:07:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:03:52.964058"
    },
    {
      "arxiv_id": "2409.04896v1",
      "title": "Reinforcement Learning-Based Adaptive Load Balancing for Dynamic Cloud Environments",
      "title_zh": "基于强化学习的自适应负载均衡，用于动态云环境",
      "authors": [
        "Kavish Chawla"
      ],
      "abstract": "Efficient load balancing is crucial in cloud computing environments to ensure\noptimal resource utilization, minimize response times, and prevent server\noverload. Traditional load balancing algorithms, such as round-robin or least\nconnections, are often static and unable to adapt to the dynamic and\nfluctuating nature of cloud workloads. In this paper, we propose a novel\nadaptive load balancing framework using Reinforcement Learning (RL) to address\nthese challenges. The RL-based approach continuously learns and improves the\ndistribution of tasks by observing real-time system performance and making\ndecisions based on traffic patterns and resource availability. Our framework is\ndesigned to dynamically reallocate tasks to minimize latency and ensure\nbalanced resource usage across servers. Experimental results show that the\nproposed RL-based load balancer outperforms traditional algorithms in terms of\nresponse time, resource utilization, and adaptability to changing workloads.\nThese findings highlight the potential of AI-driven solutions for enhancing the\nefficiency and scalability of cloud infrastructures.",
      "tldr_zh": "该论文针对云环境动态负载的挑战，提出了一种基于 Reinforcement Learning (RL) 的自适应负载均衡框架，以解决传统算法（如 round-robin 或 least connections）静态性不足的问题。该框架通过实时观察系统性能、流量模式和资源可用性，持续学习并优化任务分配，从而最小化延迟并平衡服务器资源利用。实验结果显示，该方法在响应时间、资源利用率和适应性方面均优于传统算法，突出了 AI 驱动解决方案提升云基础设施效率和可伸缩性的潜力。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.NI",
        "68M14, 68T05"
      ],
      "primary_category": "cs.DC",
      "comment": "Length: 6 pages (including references) Figures: 3 figures Submission\n  Type: Conference paper Keywords: Reinforcement Learning, Load Balancing,\n  Cloud Computing, Adaptive Algorithms, AI-driven Load Management",
      "pdf_url": "http://arxiv.org/pdf/2409.04896v1",
      "published_date": "2024-09-07 19:40:48 UTC",
      "updated_date": "2024-09-07 19:40:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:04:04.967162"
    },
    {
      "arxiv_id": "2409.04887v1",
      "title": "Defeasible Reasoning on Concepts",
      "title_zh": "翻译失败",
      "authors": [
        "Yiwen Ding",
        "Krishna Manoorkar",
        "Ni Wayan Switrayni",
        "Ruoding Wang"
      ],
      "abstract": "In this paper, we take first steps toward developing defeasible reasoning on\nconcepts in KLM framework. We define generalizations of cumulative reasoning\nsystem C and cumulative reasoning system with loop CL to conceptual setting. We\nalso generalize cumulative models, cumulative ordered models, and preferential\nmodels to conceptual setting and show the soundness and completeness results\nfor these models.",
      "tldr_zh": "这篇论文在 KLM framework 中探索了 Defeasible Reasoning on Concepts 的初步工作，旨在将可推翻推理扩展到概念设置。作者定义了累积推理系统 C 和 CL 的推广版本，并相应推广了 cumulative models、cumulative ordered models 和 preferential models。实验结果证明了这些模型的 soundness 和 completeness，从而为概念层面的推理提供了坚实的理论基础。",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04887v1",
      "published_date": "2024-09-07 19:08:17 UTC",
      "updated_date": "2024-09-07 19:08:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:04:16.289115"
    },
    {
      "arxiv_id": "2409.13717v2",
      "title": "DiVA-DocRE: A Discriminative and Voice-Aware Paradigm for Document-Level Relation Extraction",
      "title_zh": "翻译失败",
      "authors": [
        "Yiheng Wu",
        "Roman Yangarber",
        "Xian Mao"
      ],
      "abstract": "The remarkable capabilities of Large Language Models (LLMs) in text\ncomprehension and generation have revolutionized Information Extraction (IE).\nOne such advancement is in Document-level Relation Triplet Extraction (DocRTE),\na critical task in information systems that aims to extract entities and their\nsemantic relationships from documents. However, existing methods are primarily\ndesigned for Sentence level Relation Triplet Extraction (SentRTE), which\ntypically handles a limited set of relations and triplet facts within a single\nsentence. Additionally, some approaches treat relations as candidate choices\nintegrated into prompt templates, resulting in inefficient processing and\nsuboptimal performance when determining the relation elements in triplets. To\naddress these limitations, we introduce a Discriminative and Voice Aware\nParadigm DiVA. DiVA involves only two steps: performing document-level relation\nextraction (DocRE) and then identifying the subject object entities based on\nthe relation. No additional processing is required simply input the document to\ndirectly obtain the triplets. This streamlined process more accurately reflects\nreal-world scenarios for triplet extraction. Our innovation lies in\ntransforming DocRE into a discriminative task, where the model pays attention\nto each relation and to the often overlooked issue of active vs. passive voice\nwithin the triplet. Our experiments on the Re-DocRED and DocRED datasets\ndemonstrate state-of-the-art results for the DocRTE task.",
      "tldr_zh": "本研究提出了一种区分性和语音感知范式 DiVA，用于文档级关系三元组提取 (DocRTE)，旨在解决现有方法主要针对句子级 (SentRTE) 的局限性，如处理关系效率低下和忽略主动/被动语态问题。DiVA 通过将 DocRE 转化为区分性任务，仅需两步操作：先提取文档级关系，然后基于该关系识别主语和宾语实体，从而简化流程，直接从输入文档中获取三元组，更贴近真实场景。实验在 Re-DocRED 和 DocRED 数据集上展示了 state-of-the-art 结果，证明了该方法的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "After internal discussions among the co-authors, we have decided to\n  withdraw the manuscript due to a change in research direction and a lack of\n  unanimous agreement to proceed with publication at this time",
      "pdf_url": "http://arxiv.org/pdf/2409.13717v2",
      "published_date": "2024-09-07 18:47:38 UTC",
      "updated_date": "2025-04-08 10:43:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:04:29.278850"
    },
    {
      "arxiv_id": "2409.04882v1",
      "title": "Learning to Open and Traverse Doors with a Legged Manipulator",
      "title_zh": "翻译失败",
      "authors": [
        "Mike Zhang",
        "Yuntao Ma",
        "Takahiro Miki",
        "Marco Hutter"
      ],
      "abstract": "Using doors is a longstanding challenge in robotics and is of significant\npractical interest in giving robots greater access to human-centric spaces. The\ntask is challenging due to the need for online adaptation to varying door\nproperties and precise control in manipulating the door panel and navigating\nthrough the confined doorway. To address this, we propose a learning-based\ncontroller for a legged manipulator to open and traverse through doors. The\ncontroller is trained using a teacher-student approach in simulation to learn\nrobust task behaviors as well as estimate crucial door properties during the\ninteraction. Unlike previous works, our approach is a single control policy\nthat can handle both push and pull doors through learned behaviour which infers\nthe opening direction during deployment without prior knowledge. The policy was\ndeployed on the ANYmal legged robot with an arm and achieved a success rate of\n95.0% in repeated trials conducted in an experimental setting. Additional\nexperiments validate the policy's effectiveness and robustness to various doors\nand disturbances. A video overview of the method and experiments can be found\nat youtu.be/tQDZXN_k5NU.",
      "tldr_zh": "本研究针对机器人开门这一挑战，提出了一种基于学习的控制器，用于腿部机械臂（legged manipulator）机器人打开并通过门。该控制器采用教师-学生方法（teacher-student approach）在模拟环境中训练，学习鲁棒任务行为并实时估计门属性，从而处理推门和拉门两种情况，而无需先验知识。创新点在于使用单一控制策略（control policy），通过学习行为推断开门方向，并在ANYmal机器人上部署，实现了95.0%的成功率。实验进一步验证了该策略对各种门类型和干扰的鲁棒性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04882v1",
      "published_date": "2024-09-07 18:27:46 UTC",
      "updated_date": "2024-09-07 18:27:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:04:40.291843"
    },
    {
      "arxiv_id": "2409.04880v1",
      "title": "Towards identifying Source credibility on Information Leakage in Digital Gadget Market",
      "title_zh": "翻译失败",
      "authors": [
        "Neha Kumaru",
        "Garvit Gupta",
        "Shreyas Mongia",
        "Shubham Singh",
        "Ponnurangam Kumaraguru",
        "Arun Balaji Buduru"
      ],
      "abstract": "The use of Social media to share content is on a constant rise. One of the\ncapsize effect of information sharing on Social media includes the spread of\nsensitive information on the public domain. With the digital gadget market\nbecoming highly competitive and ever-evolving, the trend of an increasing\nnumber of sensitive posts leaking information on devices in social media is\nobserved. Many web-blogs on digital gadget market have mushroomed recently,\nmaking the problem of information leak all pervasive. Credible leaks on\nspecifics of an upcoming device can cause a lot of financial damage to the\nrespective organization. Hence, it is crucial to assess the credibility of the\nplatforms that continuously post about a smartphone or digital gadget leaks. In\nthis work, we analyze the headlines of leak web-blog posts and their\ncorresponding official press-release. We first collect 54, 495 leak and\npress-release headlines for different smartphones. We train our custom NER\nmodel to capture the evolving smartphone names with an accuracy of 82.14% on\nmanually annotated results. We further propose a credibility score metric for\nthe web-blog, based on the number of falsified and authentic smartphone leak\nposts.",
      "tldr_zh": "本研究针对数字设备市场的信息泄露问题，探讨了社交媒体上泄露博客的可信度，以防止敏感信息传播导致的财务损失。研究者收集了54,495条智能手机泄露和官方新闻稿标题，并训练了一个自定义NER模型来识别智能手机名称，实现了82.14%的准确率。随后，他们提出了一种基于虚假和真实泄露帖子的可信度评分指标，用于评估博客平台的可靠性。该方法为识别信息来源的可信性提供了实用框架，有助于缓解数字设备市场的信息泄露风险。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04880v1",
      "published_date": "2024-09-07 18:20:33 UTC",
      "updated_date": "2024-09-07 18:20:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:04:52.093187"
    },
    {
      "arxiv_id": "2409.05916v1",
      "title": "Unlocking Potential Binders: Multimodal Pretraining DEL-Fusion for Denoising DNA-Encoded Libraries",
      "title_zh": "翻译失败",
      "authors": [
        "Chunbin Gu",
        "Mutian He",
        "Hanqun Cao",
        "Guangyong Chen",
        "Chang-yu Hsieh",
        "Pheng Ann Heng"
      ],
      "abstract": "In the realm of drug discovery, DNA-encoded library (DEL) screening\ntechnology has emerged as an efficient method for identifying high-affinity\ncompounds. However, DEL screening faces a significant challenge: noise arising\nfrom nonspecific interactions within complex biological systems. Neural\nnetworks trained on DEL libraries have been employed to extract compound\nfeatures, aiming to denoise the data and uncover potential binders to the\ndesired therapeutic target. Nevertheless, the inherent structure of DEL,\nconstrained by the limited diversity of building blocks, impacts the\nperformance of compound encoders. Moreover, existing methods only capture\ncompound features at a single level, further limiting the effectiveness of the\ndenoising strategy. To mitigate these issues, we propose a Multimodal\nPretraining DEL-Fusion model (MPDF) that enhances encoder capabilities through\npretraining and integrates compound features across various scales. We develop\npretraining tasks applying contrastive objectives between different compound\nrepresentations and their text descriptions, enhancing the compound encoders'\nability to acquire generic features. Furthermore, we propose a novel DEL-fusion\nframework that amalgamates compound information at the atomic, submolecular,\nand molecular levels, as captured by various compound encoders. The synergy of\nthese innovations equips MPDF with enriched, multi-scale features, enabling\ncomprehensive downstream denoising. Evaluated on three DEL datasets, MPDF\ndemonstrates superior performance in data processing and analysis for\nvalidation tasks. Notably, MPDF offers novel insights into identifying\nhigh-affinity molecules, paving the way for improved DEL utility in drug\ndiscovery.",
      "tldr_zh": "本研究针对 DNA-encoded library (DEL) 筛选在药物发现中的噪声问题（如非特异性互动），提出 Multimodal Pretraining DEL-Fusion (MPDF) 模型，以提升化合物特征提取的效能。MPDF 通过对比学习任务在不同化合物表示和文本描述之间应用对比目标，增强编码器的泛化能力，并引入 DEL-fusion 框架融合原子、子分子和分子级别的多尺度特征，实现全面的去噪策略。在三个 DEL 数据集上的评估中，MPDF 表现出色，不仅提高了数据处理和分析的准确性，还为识别高亲和力分子提供了新颖见解，从而提升了 DEL 在药物发现中的实用性。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG",
        "q-bio.BM"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.05916v1",
      "published_date": "2024-09-07 17:32:21 UTC",
      "updated_date": "2024-09-07 17:32:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:05:06.923304"
    },
    {
      "arxiv_id": "2409.13715v2",
      "title": "Introducing MeMo: A Multimodal Dataset for Memory Modelling in Multiparty Conversations",
      "title_zh": "引入 MeMo：一个用于多方对话记忆建模的多模态数据集",
      "authors": [
        "Maria Tsfasman",
        "Bernd Dudzik",
        "Kristian Fenech",
        "Andras Lorincz",
        "Catholijn M. Jonker",
        "Catharine Oertel"
      ],
      "abstract": "Conversational memory is the process by which humans encode, retain and\nretrieve verbal, non-verbal and contextual information from a conversation.\nSince human memory is selective, differing recollections of the same events can\nlead to misunderstandings and misalignments within a group. Yet, conversational\nfacilitation systems, aimed at advancing the quality of group interactions,\nusually focus on tracking users' states within an individual session, ignoring\nwhat remains in each participant's memory after the interaction. Understanding\nconversational memory can be used as a source of information on the long-term\ndevelopment of social connections within a group. This paper introduces the\nMeMo corpus, the first conversational dataset annotated with participants'\nmemory retention reports, aimed at facilitating computational modelling of\nhuman conversational memory. The MeMo corpus includes 31 hours of small-group\ndiscussions on Covid-19, repeated 3 times over the term of 2 weeks. It\nintegrates validated behavioural and perceptual measures, audio, video, and\nmultimodal annotations, offering a valuable resource for studying and modelling\nconversational memory and group dynamics. By introducing the MeMo corpus,\nanalysing its validity, and demonstrating its usefulness for future research,\nthis paper aims to pave the way for future research in conversational memory\nmodelling for intelligent system development.",
      "tldr_zh": "这篇论文引入了 MeMo 数据集，这是一个多模态语料库，旨在支持多方对话中记忆建模的计算研究。MeMo 包含 31 小时关于 Covid-19 的小组讨论数据，重复 3 次并跨越 2 周，结合了参与者的记忆保留报告、行为和感知测量、音频、视频以及多模态注释。数据集的分析验证了其有效性，并为未来研究对话记忆和群体动态提供宝贵资源，从而推进智能系统的开发。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.13715v2",
      "published_date": "2024-09-07 16:09:36 UTC",
      "updated_date": "2024-10-15 11:29:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:05:17.744101"
    },
    {
      "arxiv_id": "2409.04849v1",
      "title": "FedModule: A Modular Federated Learning Framework",
      "title_zh": "FedModule：模块化的联邦学习框架",
      "authors": [
        "Chuyi Chen",
        "Zhe Zhang",
        "Yanchao Zhao"
      ],
      "abstract": "Federated learning (FL) has been widely adopted across various applications,\nsuch as healthcare, finance, and smart cities. However, as experimental\nscenarios become more complex, existing FL frameworks and benchmarks have\nstruggled to keep pace. This paper introduces FedModule, a flexible and\nextensible FL experimental framework that has been open-sourced to support\ndiverse FL paradigms and provide comprehensive benchmarks for complex\nexperimental scenarios. FedModule adheres to the \"one code, all scenarios\"\nprinciple and employs a modular design that breaks the FL process into\nindividual components, allowing for the seamless integration of different FL\nparadigms. The framework supports synchronous, asynchronous, and personalized\nfederated learning, with over 20 implemented algorithms. Experiments conducted\non public datasets demonstrate the flexibility and extensibility of FedModule.\nThe framework offers multiple execution modes-including linear, threaded,\nprocess-based, and distributed-enabling users to tailor their setups to various\nexperimental needs. Additionally, FedModule provides extensive logging and\ntesting capabilities, which facilitate detailed performance analysis of FL\nalgorithms. Comparative evaluations against existing FL toolkits, such as\nTensorFlow Federated, PySyft, Flower, and FLGo, highlight FedModule's superior\nscalability, flexibility, and comprehensive benchmark support. By addressing\nthe limitations of current FL frameworks, FedModule marks a significant\nadvancement in FL experimentation, providing researchers and practitioners with\na robust tool for developing and evaluating FL algorithms across a wide range\nof scenarios.",
      "tldr_zh": "本文提出FedModule，一种模块化的Federated Learning (FL) 实验框架，已开源设计，用于支持多样化的FL范式并提供全面基准测试，以应对复杂场景。框架遵循“一码多场景”原则，通过将FL过程分解为独立组件，支持同步、异步和个性化FL等多种模式，并实现了超过20种算法。实验在公共数据集上验证了FedModule的灵活性和可扩展性，其多种执行模式（如线性、线程、进程和分布式）以及日志测试功能优于现有工具如TensorFlow Federated、PySyft、Flower和FLGo。FedModule的出现显著推进了FL实验领域，为研究者和从业者提供了一个强大的算法开发和评估工具。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04849v1",
      "published_date": "2024-09-07 15:03:12 UTC",
      "updated_date": "2024-09-07 15:03:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:05:29.973693"
    },
    {
      "arxiv_id": "2409.04840v2",
      "title": "Sample and Oracle Efficient Reinforcement Learning for MDPs with Linearly-Realizable Value Functions",
      "title_zh": "针对具有线性可实现价值函数",
      "authors": [
        "Zakaria Mhammedi"
      ],
      "abstract": "Designing sample-efficient and computationally feasible reinforcement\nlearning (RL) algorithms is particularly challenging in environments with large\nor infinite state and action spaces. In this paper, we advance this effort by\npresenting an efficient algorithm for Markov Decision Processes (MDPs) where\nthe state-action value function of any policy is linear in a given feature map.\nThis challenging setting can model environments with infinite states and\nactions, strictly generalizes classic linear MDPs, and currently lacks a\ncomputationally efficient algorithm under online access to the MDP.\nSpecifically, we introduce a new RL algorithm that efficiently finds a\nnear-optimal policy in this setting, using a number of episodes and calls to a\ncost-sensitive classification (CSC) oracle that are both polynomial in the\nproblem parameters. Notably, our CSC oracle can be efficiently implemented when\nthe feature dimension is constant, representing a clear improvement over\nstate-of-the-art methods, which require solving non-convex problems with\nhorizon-many variables and can incur computational costs that are exponential\nin the horizon.",
      "tldr_zh": "本论文提出了一种高效的强化学习（Reinforcement Learning）算法，针对马尔可夫决策过程（MDPs），其中策略的状态-动作价值函数在给定特征映射中线性可实现。该算法在无限状态和动作环境中运行，能严格泛化经典线性MDPs，并通过在线访问MDPs来找到近似最优策略，使用episode数和成本敏感分类（CSC）oracle调用均保持多项式级别。相比现有方法，该算法显著提高了计算效率，尤其在特征维度为常数时，避免了解决非凸问题和指数级计算成本，从而提升了RL算法的样本和计算可行性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04840v2",
      "published_date": "2024-09-07 14:38:05 UTC",
      "updated_date": "2024-10-03 16:23:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:05:42.442928"
    },
    {
      "arxiv_id": "2409.04834v2",
      "title": "Reducing Events to Augment Log-based Anomaly Detection Models: An Empirical Study",
      "title_zh": "翻译失败",
      "authors": [
        "Lingzhe Zhang",
        "Tong Jia",
        "Kangjin Wang",
        "Mengxi Jia",
        "Yang Yong",
        "Ying Li"
      ],
      "abstract": "As software systems grow increasingly intricate, the precise detection of\nanomalies have become both essential and challenging. Current log-based anomaly\ndetection methods depend heavily on vast amounts of log data leading to\ninefficient inference and potential misguidance by noise logs. However, the\nquantitative effects of log reduction on the effectiveness of anomaly detection\nremain unexplored. Therefore, we first conduct a comprehensive study on six\ndistinct models spanning three datasets. Through the study, the impact of log\nquantity and their effectiveness in representing anomalies is qualifies,\nuncovering three distinctive log event types that differently influence model\nperformance. Drawing from these insights, we propose LogCleaner: an efficient\nmethodology for the automatic reduction of log events in the context of anomaly\ndetection. Serving as middleware between software systems and models,\nLogCleaner continuously updates and filters anti-events and duplicative-events\nin the raw generated logs. Experimental outcomes highlight LogCleaner's\ncapability to reduce over 70% of log events in anomaly detection, accelerating\nthe model's inference speed by approximately 300%, and universally improving\nthe performance of models for anomaly detection.",
      "tldr_zh": "该研究通过实证分析探讨了日志减少对基于日志的异常检测模型的影响，针对软件系统日志数据量大和噪声干扰的问题，评估了六个模型在三个数据集上的性能。研究发现，三种不同的日志事件类型（包括反事件和重复事件）对模型效果有显著差异，并据此提出 LogCleaner 方法，该方法作为中间件自动过滤冗余日志。实验结果显示，LogCleaner 可减少超过70%的日志事件，提高模型推理速度约300%，并普遍提升异常检测性能。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted By ESEM'24",
      "pdf_url": "http://arxiv.org/pdf/2409.04834v2",
      "published_date": "2024-09-07 14:02:02 UTC",
      "updated_date": "2024-09-15 02:32:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:05:52.719579"
    },
    {
      "arxiv_id": "2409.04833v1",
      "title": "Achieving Peak Performance for Large Language Models: A Systematic Review",
      "title_zh": "实现大型语言模型的峰值性能：系统综述",
      "authors": [
        "Zhyar Rzgar K Rostam",
        "Sándor Szénási",
        "Gábor Kertész"
      ],
      "abstract": "In recent years, large language models (LLMs) have achieved remarkable\nsuccess in natural language processing (NLP). LLMs require an extreme amount of\nparameters to attain high performance. As models grow into the\ntrillion-parameter range, computational and memory costs increase\nsignificantly. This makes it difficult for many researchers to access the\nresources needed to train or apply these models. Optimizing LLM performance\ninvolves two main approaches: fine-tuning pre-trained models for specific tasks\nto achieve state-of-the-art performance, and reducing costs or improving\ntraining time while maintaining similar performance. This paper presents a\nsystematic literature review (SLR) following the Preferred Reporting Items for\nSystematic Reviews and Meta-Analyses (PRISMA) statement. We reviewed 65\npublications out of 983 from 2017 to December 2023, retrieved from 5 databases.\nThe study presents methods to optimize and accelerate LLMs while achieving\ncutting-edge results without sacrificing accuracy. We begin with an overview of\nthe development of language modeling, followed by a detailed explanation of\ncommonly used frameworks and libraries, and a taxonomy for improving and\nspeeding up LLMs based on three classes: LLM training, LLM inference, and\nsystem serving. We then delve into recent optimization and acceleration\nstrategies such as training optimization, hardware optimization, scalability\nand reliability, accompanied by the taxonomy and categorization of these\nstrategies. Finally, we provide an in-depth comparison of each class and\nstrategy, with two case studies on optimizing model training and enhancing\ninference efficiency. These case studies showcase practical approaches to\naddress LLM resource limitations while maintaining performance.",
      "tldr_zh": "这篇论文通过系统文献综述（SLR）方法，审阅了2017-2023年间从5个数据库中选出的65篇相关研究，探讨了优化大型语言模型(LLMs)性能的策略，以应对其高计算和内存成本问题。论文将优化方法分为LLM训练、LLM推理和系统服务三大类，并详细介绍了训练优化、硬件优化、可伸缩性及可靠性等策略。最终，通过比较这些策略并提供两个案例研究（如优化模型训练和提升推理效率），展示了如何在不牺牲准确性的前提下，实现LLMs的加速和资源高效利用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "34 pages, 7 figures, 8 tables. Journal Article: IEEE Access",
      "pdf_url": "http://arxiv.org/pdf/2409.04833v1",
      "published_date": "2024-09-07 13:57:41 UTC",
      "updated_date": "2024-09-07 13:57:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:06:06.119668"
    },
    {
      "arxiv_id": "2409.04832v1",
      "title": "Reward-Directed Score-Based Diffusion Models via q-Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Xuefeng Gao",
        "Jiale Zha",
        "Xun Yu Zhou"
      ],
      "abstract": "We propose a new reinforcement learning (RL) formulation for training\ncontinuous-time score-based diffusion models for generative AI to generate\nsamples that maximize reward functions while keeping the generated\ndistributions close to the unknown target data distributions. Different from\nmost existing studies, our formulation does not involve any pretrained model\nfor the unknown score functions of the noise-perturbed data distributions. We\npresent an entropy-regularized continuous-time RL problem and show that the\noptimal stochastic policy has a Gaussian distribution with a known covariance\nmatrix. Based on this result, we parameterize the mean of Gaussian policies and\ndevelop an actor-critic type (little) q-learning algorithm to solve the RL\nproblem. A key ingredient in our algorithm design is to obtain noisy\nobservations from the unknown score function via a ratio estimator.\nNumerically, we show the effectiveness of our approach by comparing its\nperformance with two state-of-the-art RL methods that fine-tune pretrained\nmodels. Finally, we discuss extensions of our RL formulation to probability\nflow ODE implementation of diffusion models and to conditional diffusion\nmodels.",
      "tldr_zh": "该研究提出了一种新的强化学习（RL）公式，用于训练连续时间基于分数的扩散模型（score-based diffusion models），以生成最大化奖励函数的样本，同时保持生成的分布接近未知目标数据分布。不同于现有方法，该方法不依赖预训练模型，而是通过一个熵正则化的连续时间 RL 问题，证明最优策略为高斯分布，并开发了 actor-critic 类型的 q-learning 算法，利用比率估计器从未知分数函数获取噪声观察。实验结果显示，该方法在性能上优于两种先进的 RL 方法；此外，论文讨论了其扩展到概率流 ODE 和条件扩散模型的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04832v1",
      "published_date": "2024-09-07 13:55:45 UTC",
      "updated_date": "2024-09-07 13:55:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:06:17.066724"
    },
    {
      "arxiv_id": "2409.04831v1",
      "title": "MILE: A Mutation Testing Framework of In-Context Learning Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Zeming Wei",
        "Yihao Zhang",
        "Meng Sun"
      ],
      "abstract": "In-context Learning (ICL) has achieved notable success in the applications of\nlarge language models (LLMs). By adding only a few input-output pairs that\ndemonstrate a new task, the LLM can efficiently learn the task during inference\nwithout modifying the model parameters. Such mysterious ability of LLMs has\nattracted great research interests in understanding, formatting, and improving\nthe in-context demonstrations, while still suffering from drawbacks like\nblack-box mechanisms and sensitivity against the selection of examples. In this\nwork, inspired by the foundations of adopting testing techniques in machine\nlearning (ML) systems, we propose a mutation testing framework designed to\ncharacterize the quality and effectiveness of test data for ICL systems. First,\nwe propose several mutation operators specialized for ICL demonstrations, as\nwell as corresponding mutation scores for ICL test sets. With comprehensive\nexperiments, we showcase the effectiveness of our framework in evaluating the\nreliability and quality of ICL test suites. Our code is available at\nhttps://github.com/weizeming/MILE.",
      "tldr_zh": "该论文提出MILE框架，这是一种针对In-Context Learning (ICL)系统的突变测试框架，用于评估ICL测试数据的质量和有效性。ICL允许大型语言模型(LLMs)通过添加少量输入-输出示例在推理过程中学习新任务，但存在黑箱机制和示例选择敏感性的问题。为此，作者设计了专门的突变操作符和突变分数，以量化ICL测试集的可靠性。通过全面实验，MILE框架证明了其在提升ICL系统测试质量方面的有效性，并提供了开源代码以供进一步研究。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04831v1",
      "published_date": "2024-09-07 13:51:42 UTC",
      "updated_date": "2024-09-07 13:51:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:06:28.549445"
    },
    {
      "arxiv_id": "2409.04829v1",
      "title": "NASH: Neural Architecture and Accelerator Search for Multiplication-Reduced Hybrid Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Xu",
        "Huihong Shi",
        "Zhongfeng Wang"
      ],
      "abstract": "The significant computational cost of multiplications hinders the deployment\nof deep neural networks (DNNs) on edge devices. While multiplication-free\nmodels offer enhanced hardware efficiency, they typically sacrifice accuracy.\nAs a solution, multiplication-reduced hybrid models have emerged to combine the\nbenefits of both approaches. Particularly, prior works, i.e., NASA and NASA-F,\nleverage Neural Architecture Search (NAS) to construct such hybrid models,\nenhancing hardware efficiency while maintaining accuracy. However, they either\nentail costly retraining or encounter gradient conflicts, limiting both search\nefficiency and accuracy. Additionally, they overlook the acceleration\nopportunity introduced by accelerator search, yielding sub-optimal hardware\nperformance. To overcome these limitations, we propose NASH, a Neural\narchitecture and Accelerator Search framework for multiplication-reduced Hybrid\nmodels. Specifically, as for NAS, we propose a tailored zero-shot metric to\npre-identify promising hybrid models before training, enhancing search\nefficiency while alleviating gradient conflicts. Regarding accelerator search,\nwe innovatively introduce coarse-to-fine search to streamline the search\nprocess. Furthermore, we seamlessly integrate these two levels of searches to\nunveil NASH, obtaining the optimal model and accelerator pairing. Experiments\nvalidate our effectiveness, e.g., when compared with the state-of-the-art\nmultiplication-based system, we can achieve $\\uparrow$$2.14\\times$ throughput\nand $\\uparrow$$2.01\\times$ FPS with $\\uparrow$$0.25\\%$ accuracy on CIFAR-100,\nand $\\uparrow$$1.40\\times$ throughput and $\\uparrow$$1.19\\times$ FPS with\n$\\uparrow$$0.56\\%$ accuracy on Tiny-ImageNet. Codes are available at\n\\url{https://github.com/xuyang527/NASH.}",
      "tldr_zh": "该论文提出 NASH 框架，用于优化减少乘法的混合神经模型（Hybrid Models），以解决深度神经网络（DNNs）在边缘设备部署中的高计算成本问题。NASH 结合 Neural Architecture Search (NAS) 和 Accelerator Search，其中 NAS 通过定制的 zero-shot 指标在训练前识别有前景模型，提高搜索效率并缓解梯度冲突，而 Accelerator Search 采用粗到细的方法优化硬件性能。实验结果显示，与最先进的多乘法系统相比，NASH 在 CIFAR-100 上实现了 2.14 倍吞吐量和 2.01 倍 FPS 的提升，同时准确率提高 0.25%；在 Tiny-ImageNet 上，吞吐量提升 1.40 倍、FPS 提升 1.19 倍、准确率提高 0.56%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04829v1",
      "published_date": "2024-09-07 13:42:40 UTC",
      "updated_date": "2024-09-07 13:42:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:06:43.559264"
    },
    {
      "arxiv_id": "2409.04828v3",
      "title": "POINTS: Improving Your Vision-language Model with Affordable Strategies",
      "title_zh": "翻译失败",
      "authors": [
        "Yuan Liu",
        "Zhongyin Zhao",
        "Ziyuan Zhuang",
        "Le Tian",
        "Xiao Zhou",
        "Jie Zhou"
      ],
      "abstract": "In recent years, vision-language models have made significant strides,\nexcelling in tasks like optical character recognition and geometric\nproblem-solving. However, several critical issues remain: 1) Proprietary models\noften lack transparency about their architectures, while open-source models\nneed more detailed ablations of their training strategies. 2) Pre-training data\nin open-source works is under-explored, with datasets added empirically, making\nthe process cumbersome. 3) Fine-tuning often focuses on adding datasets,\nleading to diminishing returns. To address these issues, we propose the\nfollowing contributions: 1) We trained a robust baseline model using the latest\nadvancements in vision-language models, introducing effective improvements and\nconducting comprehensive ablation and validation for each technique. 2)\nInspired by recent work on large language models, we filtered pre-training data\nusing perplexity, selecting the lowest perplexity data for training. This\napproach allowed us to train on a curated 1M dataset, achieving competitive\nperformance. 3) During visual instruction tuning, we used model soup on\ndifferent datasets when adding more datasets yielded marginal improvements.\nThese innovations resulted in a 9B parameter model that performs competitively\nwith state-of-the-art models. Our strategies are efficient and lightweight,\nmaking them easily adoptable by the community.",
      "tldr_zh": "该论文针对视觉语言模型(vision-language models)的透明度不足、预训练数据探索不足以及微调收益递减等问题，提出了可负担的改进策略。研究团队训练了一个稳健基线模型，通过引入最新进展并进行全面消融验证；使用perplexity过滤预训练数据，仅选最低perplexity的1M数据集进行训练；并在视觉指令调优中采用model soup处理不同数据集以优化性能。这些创新导致了一个9B参数模型，其性能与最先进模型相当，且策略高效、轻量级，便于社区采用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "v2",
      "pdf_url": "http://arxiv.org/pdf/2409.04828v3",
      "published_date": "2024-09-07 13:41:37 UTC",
      "updated_date": "2024-11-05 02:32:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:06:57.376989"
    },
    {
      "arxiv_id": "2409.04822v1",
      "title": "Exploring Straightforward Conversational Red-Teaming",
      "title_zh": "翻译失败",
      "authors": [
        "George Kour",
        "Naama Zwerdling",
        "Marcel Zalmanovici",
        "Ateret Anaby-Tavor",
        "Ora Nova Fandina",
        "Eitan Farchi"
      ],
      "abstract": "Large language models (LLMs) are increasingly used in business dialogue\nsystems but they pose security and ethical risks. Multi-turn conversations,\nwhere context influences the model's behavior, can be exploited to produce\nundesired responses. In this paper, we examine the effectiveness of utilizing\noff-the-shelf LLMs in straightforward red-teaming approaches, where an attacker\nLLM aims to elicit undesired output from a target LLM, comparing both\nsingle-turn and conversational red-teaming tactics. Our experiments offer\ninsights into various usage strategies that significantly affect their\nperformance as red teamers. They suggest that off-the-shelf models can act as\neffective red teamers and even adjust their attack strategy based on past\nattempts, although their effectiveness decreases with greater alignment.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）在商业对话系统中的安全和伦理风险，特别是多轮对话中被利用产生 undesired responses 的问题。论文评估了使用 off-the-shelf LLMs 进行简单 red-teaming 的有效性，通过比较 single-turn 和 conversational red-teaming 策略，实验揭示了不同使用策略对性能的影响。结果表明，现成模型可以作为有效的 red teamers，甚至根据过去的尝试调整攻击策略，但其有效性会随着目标模型的 alignment 增强而降低。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04822v1",
      "published_date": "2024-09-07 13:28:01 UTC",
      "updated_date": "2024-09-07 13:28:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:07:11.825958"
    },
    {
      "arxiv_id": "2409.04820v1",
      "title": "FreeAugment: Data Augmentation Search Across All Degrees of Freedom",
      "title_zh": "FreeAugment：数据增强搜索跨越所有自由度",
      "authors": [
        "Tom Bekor",
        "Niv Nayman",
        "Lihi Zelnik-Manor"
      ],
      "abstract": "Data augmentation has become an integral part of deep learning, as it is\nknown to improve the generalization capabilities of neural networks. Since the\nmost effective set of image transformations differs between tasks and domains,\nautomatic data augmentation search aims to alleviate the extreme burden of\nmanually finding the optimal image transformations. However, current methods\nare not able to jointly optimize all degrees of freedom: (1) the number of\ntransformations to be applied, their (2) types, (3) order, and (4) magnitudes.\nMany existing methods risk picking the same transformation more than once,\nlimit the search to two transformations only, or search for the number of\ntransformations exhaustively or iteratively in a myopic manner. Our approach,\nFreeAugment, is the first to achieve global optimization of all four degrees of\nfreedom simultaneously, using a fully differentiable method. It efficiently\nlearns the number of transformations and a probability distribution over their\npermutations, inherently refraining from redundant repetition while sampling.\nOur experiments demonstrate that this joint learning of all degrees of freedom\nsignificantly improves performance, achieving state-of-the-art results on\nvarious natural image benchmarks and beyond across other domains. Project page\nat https://tombekor.github.io/FreeAugment-web",
      "tldr_zh": "这篇论文提出了 FreeAugment，一种新型数据增强搜索方法，能够同时优化所有自由度，包括变换的数量、类型、顺序和幅度，从而解决现有方法的局限性。FreeAugment 通过完全可微的方法实现全局联合学习，高效地学习变换数量和排列概率分布，避免冗余重复。实验结果显示，该方法在各种自然图像基准以及其他领域取得了最先进性能，显著提升了神经网络的泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "math.OC",
        "I.2; I.4"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.04820v1",
      "published_date": "2024-09-07 13:26:12 UTC",
      "updated_date": "2024-09-07 13:26:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:07:19.702115"
    },
    {
      "arxiv_id": "2409.04819v1",
      "title": "Top-GAP: Integrating Size Priors in CNNs for more Interpretability, Robustness, and Bias Mitigation",
      "title_zh": "翻译失败",
      "authors": [
        "Lars Nieradzik",
        "Henrike Stephani",
        "Janis Keuper"
      ],
      "abstract": "This paper introduces Top-GAP, a novel regularization technique that enhances\nthe explainability and robustness of convolutional neural networks. By\nconstraining the spatial size of the learned feature representation, our method\nforces the network to focus on the most salient image regions, effectively\nreducing background influence. Using adversarial attacks and the Effective\nReceptive Field, we show that Top-GAP directs more attention towards object\npixels rather than the background. This leads to enhanced interpretability and\nrobustness. We achieve over 50% robust accuracy on CIFAR-10 with PGD\n$\\epsilon=\\frac{8}{255}$ and $20$ iterations while maintaining the original\nclean accuracy. Furthermore, we see increases of up to 5% accuracy against\ndistribution shifts. Our approach also yields more precise object localization,\nas evidenced by up to 25% improvement in Intersection over Union (IOU) compared\nto methods like GradCAM and Recipro-CAM.",
      "tldr_zh": "这篇论文提出了 Top-GAP，一种在 CNN 中整合大小先验的新正则化技术，旨在提升网络的可解释性、鲁棒性和偏差缓解。\nTop-GAP 通过约束学习特征表示的空间大小，迫使模型重点关注图像中最显著的区域，从而减少背景干扰。\n实验结果显示，该方法在 CIFAR-10 数据集上实现 PGD 对抗攻击 (ε=8/255, 20 iterations) 的鲁棒准确率超过 50%，同时保持原始清洁准确率，并对分布偏移的准确率提高多达 5%。\n此外，Top-GAP 显著改善物体定位精度，IOU 比 GradCAM 和 Recipro-CAM 高出多达 25%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "eXCV Workshop at ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.04819v1",
      "published_date": "2024-09-07 13:24:59 UTC",
      "updated_date": "2024-09-07 13:24:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:07:33.805257"
    },
    {
      "arxiv_id": "2409.04813v2",
      "title": "Generalized Learning of Coefficients in Spectral Graph Convolutional Networks",
      "title_zh": "谱图卷积网络中系数的泛化学习",
      "authors": [
        "Mustafa Coşkun",
        "Ananth Grama",
        "Mehmet Koyutürk"
      ],
      "abstract": "Spectral Graph Convolutional Networks (GCNs) have gained popularity in graph\nmachine learning applications due, in part, to their flexibility in\nspecification of network propagation rules. These propagation rules are often\nconstructed as polynomial filters whose coefficients are learned using label\ninformation during training. In contrast to learned polynomial filters,\nexplicit filter functions are useful in capturing relationships between network\ntopology and distribution of labels across the network. A number of algorithms\nincorporating either approach have been proposed; however the relationship\nbetween filter functions and polynomial approximations is not fully resolved.\nThis is largely due to the ill-conditioned nature of the linear systems that\nmust be solved to derive polynomial approximations of filter functions. To\naddress this challenge, we propose a novel Arnoldi orthonormalization-based\nalgorithm, along with a unifying approach, called G-Arnoldi-GCN that can\nefficiently and effectively approximate a given filter function with a\npolynomial. We evaluate G-Arnoldi-GCN in the context of multi-class node\nclassification across ten datasets with diverse topological characteristics.\nOur experiments show that G-Arnoldi-GCN consistently outperforms\nstate-of-the-art methods when suitable filter functions are employed. Overall,\nG-Arnoldi-GCN opens important new directions in graph machine learning by\nenabling the explicit design and application of diverse filter functions. Code\nlink: https://github.com/mustafaCoskunAgu/GArnoldi-GCN",
      "tldr_zh": "本研究探讨了 Spectral Graph Convolutional Networks (GCNs) 中传播规则的学习问题，特别针对多项式过滤器的系数学习与显式过滤函数的应用。作者提出了一种新型 Arnoldi orthonormalization-based 算法，并开发了统一框架 G-Arnoldi-GCN，能够高效解决多项式逼近过滤函数的病态线性系统问题，从而更好地捕捉网络拓扑与标签分布的关系。在十个多样化数据集上的多类节点分类实验中，G-Arnoldi-GCN 比现有方法表现出色，提升了准确率。该方法为图机器学习开辟新方向，支持显式设计和应用多样过滤函数，代码见 GitHub 链接。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04813v2",
      "published_date": "2024-09-07 12:53:44 UTC",
      "updated_date": "2024-10-01 07:28:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:07:55.423930"
    },
    {
      "arxiv_id": "2409.04808v1",
      "title": "HULLMI: Human vs LLM identification with explainability",
      "title_zh": "翻译失败",
      "authors": [
        "Prathamesh Dinesh Joshi",
        "Sahil Pocker",
        "Raj Abhijit Dandekar",
        "Rajat Dandekar",
        "Sreedath Panat"
      ],
      "abstract": "As LLMs become increasingly proficient at producing human-like responses,\nthere has been a rise of academic and industrial pursuits dedicated to flagging\na given piece of text as \"human\" or \"AI\". Most of these pursuits involve modern\nNLP detectors like T5-Sentinel and RoBERTa-Sentinel, without paying too much\nattention to issues of interpretability and explainability of these models. In\nour study, we provide a comprehensive analysis that shows that traditional ML\nmodels (Naive-Bayes,MLP, Random Forests, XGBoost) perform as well as modern NLP\ndetectors, in human vs AI text detection. We achieve this by implementing a\nrobust testing procedure on diverse datasets, including curated corpora and\nreal-world samples. Subsequently, by employing the explainable AI technique\nLIME, we uncover parts of the input that contribute most to the prediction of\neach model, providing insights into the detection process. Our study\ncontributes to the growing need for developing production-level LLM detection\ntools, which can leverage a wide range of traditional as well as modern NLP\ndetectors we propose. Finally, the LIME techniques we demonstrate also have the\npotential to equip these detection tools with interpretability analysis\nfeatures, making them more reliable and trustworthy in various domains like\neducation, healthcare, and media.",
      "tldr_zh": "本文研究了人类与LLM生成文本的识别问题，通过比较传统ML模型（如Naive-Bayes、MLP、Random Forests、XGBoost）和现代NLP检测器（如T5-Sentinel、RoBERTa-Sentinel），发现传统模型在检测性能上与现代检测器相当。研究采用稳健的测试程序在多样数据集上进行验证，并利用LIME（可解释AI技术）分析输入文本中对预测贡献最大的部分，以提升模型的可解释性。结果表明，这种方法有助于开发可靠的生产级LLM检测工具，并在教育、医疗和媒体等领域提供更可信的文本鉴别支持。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "17 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.04808v1",
      "published_date": "2024-09-07 12:27:25 UTC",
      "updated_date": "2024-09-07 12:27:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:07:56.920862"
    },
    {
      "arxiv_id": "2409.04795v1",
      "title": "Phrase-Level Adversarial Training for Mitigating Bias in Neural Network-based Automatic Essay Scoring",
      "title_zh": "翻译失败",
      "authors": [
        "Haddad Philip",
        "Tsegaye Misikir Tashu"
      ],
      "abstract": "Automatic Essay Scoring (AES) is widely used to evaluate candidates for\neducational purposes. However, due to the lack of representative data, most\nexisting AES systems are not robust, and their scoring predictions are biased\ntowards the most represented data samples. In this study, we propose a\nmodel-agnostic phrase-level method to generate an adversarial essay set to\naddress the biases and robustness of AES models. Specifically, we construct an\nattack test set comprising samples from the original test set and adversarially\ngenerated samples using our proposed method. To evaluate the effectiveness of\nthe attack strategy and data augmentation, we conducted a comprehensive\nanalysis utilizing various neural network scoring models. Experimental results\nshow that the proposed approach significantly improves AES model performance in\nthe presence of adversarial examples and scenarios without such attacks.",
      "tldr_zh": "本研究针对神经网络-based Automatic Essay Scoring (AES) 系统存在的偏差问题，提出了一种模型无关的短语级对抗训练方法，通过生成对抗作文集来提升模型的健壮性和公平性。具体而言，该方法构建了包含原始测试样本和对抗样本的攻击测试集，并对各种神经网络评分模型进行了全面评估。实验结果表明，该方法显著提高了AES模型在面对对抗样本时的性能，同时也改善了无攻击场景下的整体表现。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04795v1",
      "published_date": "2024-09-07 11:22:35 UTC",
      "updated_date": "2024-09-07 11:22:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:08:09.405868"
    },
    {
      "arxiv_id": "2409.04793v1",
      "title": "Action is the primary key: a categorical framework for episode description and logical reasoning",
      "title_zh": "行动是首要关键：一个范畴框架用于事件描述和逻辑推理",
      "authors": [
        "Yoshiki Fukada"
      ],
      "abstract": "This research presents a computational framework for describing and\nrecognizing episodes and for logical reasoning. This framework, named\ncognitive-logs, consists of a set of relational and graph databases.\nCognitive-logs record knowledge, particularly in episodes that consist of\n\"actions\" represented by verbs in natural languages and \"participants\" who\nperform the actions. These objects are connected by arrows (morphisms) that\nlink each action to its participant and link cause to effect. Operations based\non category theory enable comparisons between episodes and deductive\ninferences, including abstractions of stories. One of the goals of this study\nis to develop a database-driven artificial intelligence. This artificial\nintelligence thinks like a human but possesses the accuracy and rigour of a\nmachine. The vast capacities of databases (up to petabyte scales in current\ntechnologies) enable the artificial intelligence to store a greater volume of\nknowledge than neural-network based artificial intelligences. Cognitive-logs\nserve as a model of human cognition and designed with references to cognitive\nlinguistics. Cognitive-logs also have the potential to model various human mind\nactivities.",
      "tldr_zh": "本研究提出了一种名为 cognitive-logs 的计算框架，用于事件描述、识别和逻辑推理。该框架基于关系和图数据库，记录事件中的动作（由动词表示）和参与者，通过 category theory 的 morphisms（箭头）连接动作、参与者和因果关系，支持事件比较、演绎推理以及故事抽象。与神经网络 AI 相比，cognitive-logs 利用数据库的大容量（如 petabyte 级别）存储更多知识，并参考 cognitive linguistics 模拟人类认知，旨在开发一种准确而严谨的数据库驱动 AI。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "26 pages, 18 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2409.04793v1",
      "published_date": "2024-09-07 11:09:47 UTC",
      "updated_date": "2024-09-07 11:09:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:08:20.848878"
    },
    {
      "arxiv_id": "2409.04792v2",
      "title": "Improving Deep Reinforcement Learning by Reducing the Chain Effect of Value and Policy Churn",
      "title_zh": "通过减少价值和策略波动的链式效应来改进深度强化学习",
      "authors": [
        "Hongyao Tang",
        "Glen Berseth"
      ],
      "abstract": "Deep neural networks provide Reinforcement Learning (RL) powerful function\napproximators to address large-scale decision-making problems. However, these\napproximators introduce challenges due to the non-stationary nature of RL\ntraining. One source of the challenges in RL is that output predictions can\nchurn, leading to uncontrolled changes after each batch update for states not\nincluded in the batch. Although such a churn phenomenon exists in each step of\nnetwork training, how churn occurs and impacts RL remains under-explored. In\nthis work, we start by characterizing churn in a view of Generalized Policy\nIteration with function approximation, and we discover a chain effect of churn\nthat leads to a cycle where the churns in value estimation and policy\nimprovement compound and bias the learning dynamics throughout the iteration.\nFurther, we concretize the study and focus on the learning issues caused by the\nchain effect in different settings, including greedy action deviation in\nvalue-based methods, trust region violation in proximal policy optimization,\nand dual bias of policy value in actor-critic methods. We then propose a method\nto reduce the chain effect across different settings, called Churn Approximated\nReductIoN (CHAIN), which can be easily plugged into most existing DRL\nalgorithms. Our experiments demonstrate the effectiveness of our method in both\nreducing churn and improving learning performance across online and offline,\nvalue-based and policy-based RL settings, as well as a scaling setting.",
      "tldr_zh": "该研究分析了深度强化学习（Deep Reinforcement Learning）中价值和策略 churn 的链式效应（Chain Effect），揭示了这种效应如何通过价值估计和策略改进的循环交互，干扰学习动态，导致问题如价值-based 方法中的贪婪动作偏差（greedy action deviation）、近端策略优化（proximal policy optimization）中的信任区域违反，以及演员-评论家方法（actor-critic methods）中的双重偏差。作者提出了一种通用方法 Churn Approximated ReductIoN (CHAIN)，可轻松集成到现有 DRL 算法中，以减少这种链式效应。实验结果显示，CHAIN 在在线和离线、价值-based 和策略-based RL 设置中显著降低了 churn，并提升了学习性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to NeurIPS 2024. Project page:\n  https://bluecontra.github.io/CHAIN",
      "pdf_url": "http://arxiv.org/pdf/2409.04792v2",
      "published_date": "2024-09-07 11:08:20 UTC",
      "updated_date": "2024-12-11 09:40:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:08:32.515858"
    },
    {
      "arxiv_id": "2409.04787v1",
      "title": "Selective Self-Rehearsal: A Fine-Tuning Approach to Improve Generalization in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Sonam Gupta",
        "Yatin Nandwani",
        "Asaf Yehudai",
        "Mayank Mishra",
        "Gaurav Pandey",
        "Dinesh Raghu",
        "Sachindra Joshi"
      ],
      "abstract": "Fine-tuning Large Language Models (LLMs) on specific datasets is a common\npractice to improve performance on target tasks. However, this performance gain\noften leads to overfitting, where the model becomes too specialized in either\nthe task or the characteristics of the training data, resulting in a loss of\ngeneralization. This paper introduces Selective Self-Rehearsal (SSR), a\nfine-tuning approach that achieves performance comparable to the standard\nsupervised fine-tuning (SFT) while improving generalization. SSR leverages the\nfact that there can be multiple valid responses to a query. By utilizing the\nmodel's correct responses, SSR reduces model specialization during the\nfine-tuning stage. SSR first identifies the correct model responses from the\ntraining set by deploying an appropriate LLM as a judge. Then, it fine-tunes\nthe model using the correct model responses and the gold response for the\nremaining samples. The effectiveness of SSR is demonstrated through experiments\non the task of identifying unanswerable queries across various datasets. The\nresults show that standard SFT can lead to an average performance drop of up to\n$16.7\\%$ on multiple benchmarks, such as MMLU and TruthfulQA. In contrast, SSR\nresults in close to $2\\%$ drop on average, indicating better generalization\ncapabilities compared to standard SFT.",
      "tldr_zh": "该论文提出了一种名为 Selective Self-Rehearsal (SSR) 的微调方法，用于提升 Large Language Models (LLMs) 的泛化能力，同时避免标准 Supervised Fine-Tuning (SFT) 导致的过拟合问题。SSR 通过利用模型自身多个有效响应，并借助一个 LLM 作为判断器，识别并使用正确的模型响应来微调剩余样本，从而减少模型在训练数据上的过度专业化。在实验中，SSR 在识别不可回答查询的任务上表现突出，与 SFT 相比，其在 MMLU 和 TruthfulQA 等基准上的性能下降平均仅为 2%，远低于 SFT 的 16.7%，证明了其在保持性能的同时显著改善泛化效果。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.04787v1",
      "published_date": "2024-09-07 10:21:03 UTC",
      "updated_date": "2024-09-07 10:21:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:08:44.705029"
    },
    {
      "arxiv_id": "2409.13714v1",
      "title": "TracrBench: Generating Interpretability Testbeds with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Hannes Thurnherr",
        "Jérémy Scheurer"
      ],
      "abstract": "Achieving a mechanistic understanding of transformer-based language models is\nan open challenge, especially due to their large number of parameters.\nMoreover, the lack of ground truth mappings between model weights and their\nfunctional roles hinders the effective evaluation of interpretability methods,\nimpeding overall progress. Tracr, a method for generating compiled transformers\nwith inherent ground truth mappings in RASP, has been proposed to address this\nissue. However, manually creating a large number of models needed for verifying\ninterpretability methods is labour-intensive and time-consuming. In this work,\nwe present a novel approach for generating interpretability test beds using\nlarge language models (LLMs) and introduce TracrBench, a novel dataset\nconsisting of 121 manually written and LLM-generated, human-validated RASP\nprograms and their corresponding transformer weights. During this process, we\nevaluate the ability of frontier LLMs to autonomously generate RASP programs\nand find that this task poses significant challenges. GPT-4-turbo, with a\n20-shot prompt and best-of-5 sampling, correctly implements only 57 out of 101\ntest programs, necessitating the manual implementation of the remaining\nprograms. With its 121 samples, TracrBench aims to serve as a valuable testbed\nfor evaluating and comparing interpretability methods.",
      "tldr_zh": "该论文探讨了理解 transformer 模型的机制性挑战，特别是参数众多和缺乏 ground truth 映射的问题。作者提出使用大型语言模型 (LLMs) 生成解释性测试床的方法，并引入 TracrBench 数据集，该数据集包含 121 个手动和 LLM 生成的、人类验证的 RASP 程序及其对应的 transformer 权重。实验评估显示，GPT-4-turbo 在 20-shot 提示和 best-of-5 采样下仅正确实现了 101 个测试程序中的 57 个，突显了生成 RASP 程序的难度。TracrBench 作为一种宝贵测试平台，有助于评估和比较各种解释性方法。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages + appendix, 4 figures, ICML Mechanistic Interpretability\n  Workshop",
      "pdf_url": "http://arxiv.org/pdf/2409.13714v1",
      "published_date": "2024-09-07 10:02:51 UTC",
      "updated_date": "2024-09-07 10:02:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:08:59.223928"
    },
    {
      "arxiv_id": "2409.04775v3",
      "title": "Scalable Task Planning via Large Language Models and Structured World Representations",
      "title_zh": "翻译失败",
      "authors": [
        "Rodrigo Pérez-Dattari",
        "Zhaoting Li",
        "Robert Babuška",
        "Jens Kober",
        "Cosimo Della Santina"
      ],
      "abstract": "Planning methods struggle with computational intractability in solving\ntask-level problems in large-scale environments. This work explores leveraging\nthe commonsense knowledge encoded in LLMs to empower planning techniques to\ndeal with these complex scenarios. We achieve this by efficiently using LLMs to\nprune irrelevant components from the planning problem's state space,\nsubstantially simplifying its complexity. We demonstrate the efficacy of this\nsystem through extensive experiments within a household simulation environment,\nalongside real-world validation using a 7-DoF manipulator (video\nhttps://youtu.be/6ro2UOtOQS4).",
      "tldr_zh": "这篇论文探讨了任务规划在大型环境中面临的计算不可行性问题，并提出了一种利用 Large Language Models (LLMs) 的方法来提升规划效率。具体来说，通过 LLMs 的常识知识修剪规划问题状态空间中的无关组件，从而显著简化其复杂性。该方法在家庭模拟环境和真实世界 7-DoF 机械臂实验中得到验证，证明了其在处理复杂任务规划场景中的有效性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "9 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.04775v3",
      "published_date": "2024-09-07 09:30:26 UTC",
      "updated_date": "2025-02-12 20:13:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:09:08.991530"
    },
    {
      "arxiv_id": "2409.04774v1",
      "title": "Untie the Knots: An Efficient Data Augmentation Strategy for Long-Context Pre-Training in Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Junfeng Tian",
        "Da Zheng",
        "Yang Cheng",
        "Rui Wang",
        "Colin Zhang",
        "Debing Zhang"
      ],
      "abstract": "Large language models (LLM) have prioritized expanding the context window\nfrom which models can incorporate more information. However, training models to\nhandle long contexts presents significant challenges. These include the\nscarcity of high-quality natural long-context data, the potential for\nperformance degradation on short-context tasks, and the reduced training\nefficiency associated with attention mechanisms. In this paper, we introduce\nUntie the Knots (\\textbf{UtK}), a novel data augmentation strategy employed\nduring the continue pre-training phase, designed to efficiently enable LLMs to\ngain long-context capabilities without the need to modify the existing data\nmixture. In particular, we chunk the documents, shuffle the chunks, and create\na complex and knotted structure of long texts; LLMs are then trained to untie\nthese knots and identify relevant segments within seemingly chaotic token\nsequences. This approach greatly improves the model's performance by accurately\nattending to relevant information in long context and the training efficiency\nis also largely increased. We conduct extensive experiments on models with 7B\nand 72B parameters, trained on 20 billion tokens, demonstrating that UtK\nachieves 75\\% and 84.5\\% accurracy on RULER at 128K context length,\nsignificantly outperforming other long context strategies. The trained models\nwill open-source for further research.",
      "tldr_zh": "本文提出 Untie the Knots (UtK)，一种高效的数据增强策略，用于提升大型语言模型 (LLM) 在继续预训练阶段的长上下文处理能力，而无需修改现有数据混合。UtK 方法通过将文档分块、洗牌并创建复杂结节化的长文本结构，训练模型学会在混乱的 token 序列中识别和提取相关信息，从而提高注意力机制的准确性和训练效率。实验结果显示，在 7B 和 72B 参数模型上训练 20 亿 tokens 后，UtK 在 128K 上下文长度下的 RULER 任务准确率分别达到 75% 和 84.5%，显著优于其他长上下文策略。训练后的模型将开源，促进进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04774v1",
      "published_date": "2024-09-07 09:28:55 UTC",
      "updated_date": "2024-09-07 09:28:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:09:23.934301"
    },
    {
      "arxiv_id": "2409.04744v2",
      "title": "Reward Guidance for Reinforcement Learning Tasks Based on Large Language Models: The LMGT Framework",
      "title_zh": "基于大语言模型的强化学习任务奖励引导：LMGT 框架",
      "authors": [
        "Yongxin Deng",
        "Xihe Qiu",
        "Jue Chen",
        "Xiaoyu Tan"
      ],
      "abstract": "The inherent uncertainty in the environmental transition model of\nReinforcement Learning (RL) necessitates a delicate balance between exploration\nand exploitation. This balance is crucial for optimizing computational\nresources to accurately estimate expected rewards for the agent. In scenarios\nwith sparse rewards, such as robotic control systems, achieving this balance is\nparticularly challenging. However, given that many environments possess\nextensive prior knowledge, learning from the ground up in such contexts may be\nredundant. To address this issue, we propose Language Model Guided reward\nTuning (LMGT), a novel, sample-efficient framework. LMGT leverages the\ncomprehensive prior knowledge embedded in Large Language Models (LLMs) and\ntheir proficiency in processing non-standard data forms, such as wiki\ntutorials. By utilizing LLM-guided reward shifts, LMGT adeptly balances\nexploration and exploitation, thereby guiding the agent's exploratory behavior\nand enhancing sample efficiency. We have rigorously evaluated LMGT across\nvarious RL tasks and evaluated it in the embodied robotic environment\nHousekeep. Our results demonstrate that LMGT consistently outperforms baseline\nmethods. Furthermore, the findings suggest that our framework can substantially\nreduce the computational resources required during the RL training phase.",
      "tldr_zh": "本研究针对强化学习（RL）中探索与利用的平衡问题，尤其是稀疏奖励场景（如机器人控制系统），提出了一种新型框架 Language Model Guided reward Tuning (LMGT)。LMGT 利用大型语言模型（LLMs）的先验知识和处理非标准数据（如维基教程）的能力，通过 LLM-guided reward shifts 来调整奖励信号，从而提升代理的样本效率并优化探索行为。在各种 RL 任务和 Housekeep 机器人环境中进行评估，结果显示 LMGT 显著优于基线方法，并大幅减少了训练阶段的计算资源需求。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04744v2",
      "published_date": "2024-09-07 07:40:43 UTC",
      "updated_date": "2025-05-02 09:58:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:09:33.274867"
    },
    {
      "arxiv_id": "2409.15329v1",
      "title": "Causality-Driven Reinforcement Learning for Joint Communication and Sensing",
      "title_zh": "因果驱动的强化学习用于联合通信和感知",
      "authors": [
        "Anik Roy",
        "Serene Banerjee",
        "Jishnu Sadasivan",
        "Arnab Sarkar",
        "Soumyajit Dey"
      ],
      "abstract": "The next-generation wireless network, 6G and beyond, envisions to integrate\ncommunication and sensing to overcome interference, improve spectrum\nefficiency, and reduce hardware and power consumption. Massive Multiple-Input\nMultiple Output (mMIMO)-based Joint Communication and Sensing (JCAS) systems\nrealize this integration for 6G applications such as autonomous driving, as it\nrequires accurate environmental sensing and time-critical communication with\nneighboring vehicles. Reinforcement Learning (RL) is used for mMIMO antenna\nbeamforming in the existing literature. However, the huge search space for\nactions associated with antenna beamforming causes the learning process for the\nRL agent to be inefficient due to high beam training overhead. The learning\nprocess does not consider the causal relationship between action space and the\nreward, and gives all actions equal importance. In this work, we explore a\ncausally-aware RL agent which can intervene and discover causal relationships\nfor mMIMO-based JCAS environments, during the training phase. We use a state\ndependent action dimension selection strategy to realize causal discovery for\nRL-based JCAS. Evaluation of the causally-aware RL framework in different JCAS\nscenarios shows the benefit of our proposed framework over baseline methods in\nterms of the beamforming gain.",
      "tldr_zh": "本文提出了一种因果驱动的强化学习（Reinforcement Learning, RL）框架，用于整合通信和感知的联合通信和感知（JCAS）系统，旨在解决6G及后续无线网络中mMIMO（Massive Multiple-Input Multiple Output）天线波束形成的学习效率问题。该框架通过因果感知RL代理在训练阶段干预并发现行动空间与奖励之间的因果关系，并采用状态依赖的行动维度选择策略来优化学习过程。实验结果显示，在不同JCAS场景中，该方法在波束形成增益方面显著优于基线方法，为自动驾驶等应用提供了更高效的解决方案。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "math.IT"
      ],
      "primary_category": "cs.IT",
      "comment": "18 pages, 9 figures, 4 tables, 1 algorithm",
      "pdf_url": "http://arxiv.org/pdf/2409.15329v1",
      "published_date": "2024-09-07 07:15:57 UTC",
      "updated_date": "2024-09-07 07:15:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:09:46.904970"
    },
    {
      "arxiv_id": "2409.04740v1",
      "title": "Up-sampling-only and Adaptive Mesh-based GNN for Simulating Physical Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Fu Lin",
        "Jiasheng Shi",
        "Shijie Luo",
        "Qinpei Zhao",
        "Weixiong Rao",
        "Lei Chen"
      ],
      "abstract": "Traditional simulation of complex mechanical systems relies on numerical\nsolvers of Partial Differential Equations (PDEs), e.g., using the Finite\nElement Method (FEM). The FEM solvers frequently suffer from intensive\ncomputation cost and high running time. Recent graph neural network (GNN)-based\nsimulation models can improve running time meanwhile with acceptable accuracy.\nUnfortunately, they are hard to tailor GNNs for complex mechanical systems,\nincluding such disadvantages as ineffective representation and inefficient\nmessage propagation (MP). To tackle these issues, in this paper, with the\nproposed Up-sampling-only and Adaptive MP techniques, we develop a novel\nhierarchical Mesh Graph Network, namely UA-MGN, for efficient and effective\nmechanical simulation. Evaluation on two synthetic and one real datasets\ndemonstrates the superiority of the UA-MGN. For example, on the Beam dataset,\ncompared to the state-of-the-art MS-MGN, UA-MGN leads to 40.99% lower errors\nbut using only 43.48% fewer network parameters and 4.49% fewer floating point\noperations (FLOPs).",
      "tldr_zh": "本研究针对复杂机械系统的模拟问题，指出传统基于 Partial Differential Equations (PDEs) 的数值求解器（如 Finite Element Method (FEM)）计算成本高、运行时间长，而现有的 Graph Neural Network (GNN)-based 模型虽能加速但存在无效表示和低效消息传播 (MP) 问题。作者提出 Up-sampling-only 和 Adaptive MP 技术，开发了一种新型层次化 Mesh Graph Network（UA-MGN），以实现高效有效的机械模拟。在两个合成数据集和一个真实数据集上的评估中，UA-MGN 表现出优越性，例如在 Beam 数据集上，与最先进模型 MS-MGN 相比，错误率降低 40.99%，同时仅使用 56.52% 的网络参数和 95.51% 的浮点运算 (FLOPs)。这项工作为 GNN 在物理系统模拟中的应用提供了更高效的框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04740v1",
      "published_date": "2024-09-07 07:09:58 UTC",
      "updated_date": "2024-09-07 07:09:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:09:58.196945"
    },
    {
      "arxiv_id": "2409.04732v2",
      "title": "VidLPRO: A $\\underline{Vid}$eo-$\\underline{L}$anguage $\\underline{P}$re-training Framework for $\\underline{Ro}$botic and Laparoscopic Surgery",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammadmahdi Honarmand",
        "Muhammad Abdullah Jamal",
        "Omid Mohareri"
      ],
      "abstract": "We introduce VidLPRO, a novel video-language (VL) pre-training framework\ndesigned specifically for robotic and laparoscopic surgery. While existing\nsurgical VL models primarily rely on contrastive learning, we propose a more\ncomprehensive approach to capture the intricate temporal dynamics and align\nvideo with language. VidLPRO integrates video-text contrastive learning,\nvideo-text matching, and masked language modeling objectives to learn rich VL\nrepresentations. To support this framework, we present GenSurg+, a carefully\ncurated dataset derived from GenSurgery, comprising 17k surgical video clips\npaired with captions generated by GPT-4 using transcripts extracted by the\nWhisper model. This dataset addresses the need for large-scale, high-quality VL\ndata in the surgical domain. Extensive experiments on benchmark datasets,\nincluding Cholec80 and AutoLaparo, demonstrate the efficacy of our approach.\nVidLPRO achieves state-of-the-art performance in zero-shot surgical phase\nrecognition, significantly outperforming existing surgical VL models such as\nSurgVLP and HecVL. Our model demonstrates improvements of up to 21.5\\% in\naccuracy and 15.7% in F1 score, setting a new benchmark in the field. Notably,\nVidLPRO exhibits robust performance even with single-frame inference, while\neffectively scaling with increased temporal context. Ablation studies reveal\nthe impact of frame sampling strategies on model performance and computational\nefficiency. These results underscore VidLPRO's potential as a foundation model\nfor surgical video understanding.",
      "tldr_zh": "本研究提出VidLPRO，一种针对机器人和腹腔镜手术的视频-语言预训练框架，通过整合video-text contrastive learning、video-text matching和masked language modeling等目标，捕捉复杂的时间动态并实现视频与语言的对齐。研究团队构建了GenSurg+数据集，包含17k手术视频片段及其由GPT-4生成的标题，以解决手术领域大规模高质量数据的缺失。在Cholec80和AutoLaparo基准数据集上的实验显示，VidLPRO在zero-shot surgical phase recognition任务中超越现有模型如SurgVLP和HecVL，准确率提升高达21.5%、F1分数提升15.7%，并证明其在单帧推理和扩展时间上下文中的鲁棒性，为手术视频理解的基础模型奠定新基准。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04732v2",
      "published_date": "2024-09-07 06:33:12 UTC",
      "updated_date": "2024-09-11 23:12:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:10:11.181581"
    },
    {
      "arxiv_id": "2409.04723v1",
      "title": "NapTune: Efficient Model Tuning for Mood Classification using Previous Night's Sleep Measures along with Wearable Time-series",
      "title_zh": "NapTune：",
      "authors": [
        "Debaditya Shome",
        "Nasim Montazeri Ghahjaverestan",
        "Ali Etemad"
      ],
      "abstract": "Sleep is known to be a key factor in emotional regulation and overall mental\nhealth. In this study, we explore the integration of sleep measures from the\nprevious night into wearable-based mood recognition. To this end, we propose\nNapTune, a novel prompt-tuning framework that utilizes sleep-related measures\nas additional inputs to a frozen pre-trained wearable time-series encoder by\nadding and training lightweight prompt parameters to each Transformer layer.\nThrough rigorous empirical evaluation, we demonstrate that the inclusion of\nsleep data using NapTune not only improves mood recognition performance across\ndifferent wearable time-series namely ECG, PPG, and EDA, but also makes it more\nsample-efficient. Our method demonstrates significant improvements over the\nbest baselines and unimodal variants. Furthermore, we analyze the impact of\nadding sleep-related measures on recognizing different moods as well as the\ninfluence of individual sleep-related measures.",
      "tldr_zh": "本研究探讨了睡眠数据对情绪调节的影响，提出NapTune框架——一种高效的prompt-tuning方法，将前一晚的睡眠测量作为额外输入，结合wearable时间序列数据（如ECG、PPG和EDA）在预训练Transformer层中添加并训练轻量级提示参数。实验结果显示，NapTune显著提升了情绪识别性能，与最佳基线和单模态变体相比，实现了更高的准确性和样本效率；此外，该框架还分析了睡眠数据对不同情绪识别的影响，以及各睡眠指标的个体作用。总的来说，NapTune为基于wearable设备的心理健康监测提供了更可靠的解决方案。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "Accepted at ICMI 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.04723v1",
      "published_date": "2024-09-07 06:06:04 UTC",
      "updated_date": "2024-09-07 06:06:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:10:21.326626"
    },
    {
      "arxiv_id": "2409.04720v1",
      "title": "A Comprehensive Survey on Evidential Deep Learning and Its Applications",
      "title_zh": "证据深度学习及其应用的全面综述",
      "authors": [
        "Junyu Gao",
        "Mengyuan Chen",
        "Liangyu Xiang",
        "Changsheng Xu"
      ],
      "abstract": "Reliable uncertainty estimation has become a crucial requirement for the\nindustrial deployment of deep learning algorithms, particularly in high-risk\napplications such as autonomous driving and medical diagnosis. However,\nmainstream uncertainty estimation methods, based on deep ensembling or Bayesian\nneural networks, generally impose substantial computational overhead. To\naddress this challenge, a novel paradigm called Evidential Deep Learning (EDL)\nhas emerged, providing reliable uncertainty estimation with minimal additional\ncomputation in a single forward pass. This survey provides a comprehensive\noverview of the current research on EDL, designed to offer readers a broad\nintroduction to the field without assuming prior knowledge. Specifically, we\nfirst delve into the theoretical foundation of EDL, the subjective logic\ntheory, and discuss its distinctions from other uncertainty estimation\nframeworks. We further present existing theoretical advancements in EDL from\nfour perspectives: reformulating the evidence collection process, improving\nuncertainty estimation via OOD samples, delving into various training\nstrategies, and evidential regression networks. Thereafter, we elaborate on its\nextensive applications across various machine learning paradigms and downstream\ntasks. In the end, an outlook on future directions for better performances and\nbroader adoption of EDL is provided, highlighting potential research avenues.",
      "tldr_zh": "这篇论文对Evidential Deep Learning (EDL)进行了全面调查，旨在解决深度学习在高风险应用（如自动驾驶和医疗诊断）中对可靠不确定性估计的需求。EDL基于subjective logic theory，通过单次前向传播提供高效的不确定性评估，相比传统方法如深度集成或Bayesian神经网络，大大降低了计算开销。论文从证据收集过程、处理OOD样本、训练策略和evidential regression networks等四个角度探讨了EDL的理论进展，并阐述了其在各种机器学习范式和下游任务中的广泛应用。最后，论文展望了EDL的未来发展方向，包括提升性能和推广潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04720v1",
      "published_date": "2024-09-07 05:55:06 UTC",
      "updated_date": "2024-09-07 05:55:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:10:33.222712"
    },
    {
      "arxiv_id": "2409.04711v1",
      "title": "Algorithmic Scenario Generation as Quality Diversity Optimization",
      "title_zh": "算法场景生成作为质量多样性优化",
      "authors": [
        "Stefanos Nikolaidis"
      ],
      "abstract": "The increasing complexity of robots and autonomous agents that interact with\npeople highlights the critical need for approaches that systematically test\nthem before deployment. This review paper presents a general framework for\nsolving this problem, describes the insights that we have gained from working\non each component of the framework, and shows how integrating these components\nleads to the discovery of a diverse range of realistic and challenging\nscenarios that reveal previously unknown failures in deployed robotic systems\ninteracting with people.",
      "tldr_zh": "这篇综述论文提出一个通用框架，将算法场景生成视为Quality Diversity Optimization，用于系统测试机器人和自主代理，以应对它们在部署前与人互动的复杂性。框架通过整合各个组件获得的见解，能够生成多样化、真实且具有挑战性的场景，从而揭示部署系统中先前未知的故障。最终，该方法为提升机器人系统的可靠性和安全性提供了重要基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04711v1",
      "published_date": "2024-09-07 05:20:41 UTC",
      "updated_date": "2024-09-07 05:20:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:10:44.515944"
    },
    {
      "arxiv_id": "2409.04707v1",
      "title": "Enhancing Deep Learning with Optimized Gradient Descent: Bridging Numerical Methods and Neural Network Training",
      "title_zh": "通过优化的梯度下降增强深度学习：桥接数值方法与神经网络训练",
      "authors": [
        "Yuhan Ma",
        "Dan Sun",
        "Erdi Gao",
        "Ningjing Sang",
        "Iris Li",
        "Guanming Huang"
      ],
      "abstract": "Optimization theory serves as a pivotal scientific instrument for achieving\noptimal system performance, with its origins in economic applications to\nidentify the best investment strategies for maximizing benefits. Over the\ncenturies, from the geometric inquiries of ancient Greece to the calculus\ncontributions by Newton and Leibniz, optimization theory has significantly\nadvanced. The persistent work of scientists like Lagrange, Cauchy, and von\nNeumann has fortified its progress. The modern era has seen an unprecedented\nexpansion of optimization theory applications, particularly with the growth of\ncomputer science, enabling more sophisticated computational practices and\nwidespread utilization across engineering, decision analysis, and operations\nresearch. This paper delves into the profound relationship between optimization\ntheory and deep learning, highlighting the omnipresence of optimization\nproblems in the latter. We explore the gradient descent algorithm and its\nvariants, which are the cornerstone of optimizing neural networks. The chapter\nintroduces an enhancement to the SGD optimizer, drawing inspiration from\nnumerical optimization methods, aiming to enhance interpretability and\naccuracy. Our experiments on diverse deep learning tasks substantiate the\nimproved algorithm's efficacy. The paper concludes by emphasizing the\ncontinuous development of optimization theory and its expanding role in solving\nintricate problems, enhancing computational capabilities, and informing better\npolicy decisions.",
      "tldr_zh": "本论文探讨了优化理论与深度学习之间的深层联系，强调了gradient descent算法及其变体在神经网络训练中的核心作用。作者提出了一种基于数值优化方法的增强版SGD优化器，旨在提升算法的可解释性和准确性。实验结果显示，该改进优化器在多种深度学习任务中表现出显著效能，最终强调优化理论的持续发展有助于解决复杂问题并提升计算能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04707v1",
      "published_date": "2024-09-07 04:37:20 UTC",
      "updated_date": "2024-09-07 04:37:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:10:57.027217"
    },
    {
      "arxiv_id": "2409.04704v1",
      "title": "A Multi-scenario Attention-based Generative Model for Personalized Blood Pressure Time Series Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Cheng Wan",
        "Chenjie Xie",
        "Longfei Liu",
        "Dan Wu",
        "Ye Li"
      ],
      "abstract": "Continuous blood pressure (BP) monitoring is essential for timely diagnosis\nand intervention in critical care settings. However, BP varies significantly\nacross individuals, this inter-patient variability motivates the development of\npersonalized models tailored to each patient's physiology. In this work, we\npropose a personalized BP forecasting model mainly using electrocardiogram\n(ECG) and photoplethysmogram (PPG) signals. This time-series model incorporates\n2D representation learning to capture complex physiological relationships.\nExperiments are conducted on datasets collected from three diverse scenarios\nwith BP measurements from 60 subjects total. Results demonstrate that the model\nachieves accurate and robust BP forecasts across scenarios within the\nAssociation for the Advancement of Medical Instrumentation (AAMI) standard\ncriteria. This reliable early detection of abnormal fluctuations in BP is\ncrucial for at-risk patients undergoing surgery or intensive care. The proposed\nmodel provides a valuable addition for continuous BP tracking to reduce\nmortality and improve prognosis.",
      "tldr_zh": "该研究提出了一种基于注意力的生成模型，用于个性化血压（BP）时间序列预测，旨在应对个体间变异性问题，主要利用心电图（ECG）和光电容积图（PPG）信号。模型通过2D表示学习捕捉复杂的生理关系，并在三个不同场景的数据集上进行实验，涵盖60名受试者。结果显示，该模型在Association for the Advancement of Medical Instrumentation (AAMI)标准下实现了准确且稳健的BP预测，有助于手术或重症监护中早期检测异常波动，从而降低死亡率并改善患者预后。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "5 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.04704v1",
      "published_date": "2024-09-07 04:24:15 UTC",
      "updated_date": "2024-09-07 04:24:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:11:09.720977"
    },
    {
      "arxiv_id": "2409.04693v1",
      "title": "MuAP: Multi-step Adaptive Prompt Learning for Vision-Language Model with Missing Modality",
      "title_zh": "MuAP：多步自适应提示学习用于具有缺失模态的视觉语言模型",
      "authors": [
        "Ruiting Dai",
        "Yuqiao Tan",
        "Lisi Mo",
        "Tao He",
        "Ke Qin",
        "Shuang Liang"
      ],
      "abstract": "Recently, prompt learning has garnered considerable attention for its success\nin various Vision-Language (VL) tasks. However, existing prompt-based models\nare primarily focused on studying prompt generation and prompt strategies with\ncomplete modality settings, which does not accurately reflect real-world\nscenarios where partial modality information may be missing. In this paper, we\npresent the first comprehensive investigation into prompt learning behavior\nwhen modalities are incomplete, revealing the high sensitivity of prompt-based\nmodels to missing modalities. To this end, we propose a novel Multi-step\nAdaptive Prompt Learning (MuAP) framework, aiming to generate multimodal\nprompts and perform multi-step prompt tuning, which adaptively learns knowledge\nby iteratively aligning modalities. Specifically, we generate multimodal\nprompts for each modality and devise prompt strategies to integrate them into\nthe Transformer model. Subsequently, we sequentially perform prompt tuning from\nsingle-stage and alignment-stage, allowing each modality-prompt to be\nautonomously and adaptively learned, thereby mitigating the imbalance issue\ncaused by only textual prompts that are learnable in previous works. Extensive\nexperiments demonstrate the effectiveness of our MuAP and this model achieves\nsignificant improvements compared to the state-of-the-art on all benchmark\ndatasets",
      "tldr_zh": "该研究发现，现有的提示学习(prompt learning)方法在视觉语言(Vision-Language)任务中对模态缺失高度敏感，因此首次全面调查了这种不完整模态场景下的模型行为。为解决这一问题，论文提出了一种新型 Multi-step Adaptive Prompt Learning (MuAP) 框架，通过生成多模态提示并进行多步提示调整（如单阶段和对齐阶段），实现模态的迭代对齐和自主学习，从而缓解之前只学习文本提示导致的不平衡问题。实验结果显示，MuAP 在所有基准数据集上比最先进模型取得了显著性能提升。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04693v1",
      "published_date": "2024-09-07 03:33:46 UTC",
      "updated_date": "2024-09-07 03:33:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:11:21.079648"
    },
    {
      "arxiv_id": "2409.13712v1",
      "title": "Good Idea or Not, Representation of LLM Could Tell",
      "title_zh": "翻译失败",
      "authors": [
        "Yi Xu",
        "Bo Xue",
        "Shuqian Sheng",
        "Cheng Deng",
        "Jiaxin Ding",
        "Zanwei Shen",
        "Luoyi Fu",
        "Xinbing Wang",
        "Chenghu Zhou"
      ],
      "abstract": "In the ever-expanding landscape of academic research, the proliferation of\nideas presents a significant challenge for researchers: discerning valuable\nideas from the less impactful ones. The ability to efficiently evaluate the\npotential of these ideas is crucial for the advancement of science and paper\nreview. In this work, we focus on idea assessment, which aims to leverage the\nknowledge of large language models to assess the merit of scientific ideas.\nFirst, we investigate existing text evaluation research and define the problem\nof quantitative evaluation of ideas. Second, we curate and release a benchmark\ndataset from nearly four thousand manuscript papers with full texts,\nmeticulously designed to train and evaluate the performance of different\napproaches to this task. Third, we establish a framework for quantifying the\nvalue of ideas by employing representations in a specific layer of large\nlanguage models. Experimental results show that the scores predicted by our\nmethod are relatively consistent with those of humans. Our findings suggest\nthat the representations of large language models hold more potential in\nquantifying the value of ideas than their generative outputs, demonstrating a\npromising avenue for automating the idea assessment process.",
      "tldr_zh": "这篇论文探讨了如何利用大型语言模型 (LLM) 的表示 (representations) 来评估科学想法的价值，以帮助研究者区分有价值的想法和次要想法。研究者首先定义了想法评估问题，并构建了一个基准数据集，包含近4000篇完整论文，用于训练和评估相关方法。其次，他们提出一个框架，通过提取LLM特定层的表示来量化想法的价值。实验结果显示，该方法预测的分数与人类评估高度一致，表明LLM的表示比其生成输出更适合自动化想法评估过程，从而为学术研究效率提升提供新途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.13712v1",
      "published_date": "2024-09-07 02:07:22 UTC",
      "updated_date": "2024-09-07 02:07:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:11:33.024295"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 44,
  "processed_papers_count": 44,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-19T22:11:55.285814"
}