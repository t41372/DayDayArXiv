{
  "date": "2025-08-08",
  "category": "cs.AI",
  "summary": "æ¬¢è¿æ¥åˆ° UTC æ—¶é—´ 2025-08-08 çš„ arXiv ä¸­æ–‡ TLDR å¿«æŠ¥ï¼\n\n**ä¸€å¥è¯æ€»ç»“ï¼š**\nä»Šå¤©çš„é‡ç£…ç‚¸å¼¹æ— ç–‘æ˜¯ OpenAI å±…ç„¶å‘å¸ƒäº†å¼€æºæƒé‡çš„ `gpt-oss` ç³»åˆ—æ¨¡å‹ï¼Œç¤¾åŒºéœ‡æƒŠï¼æ­¤å¤–ï¼ŒLLM çš„æ¨ç†æ•ˆç‡ï¼ˆ1-bit é‡åŒ–ã€Diffusion æ¶æ„ï¼‰ã€Agent çš„è®°å¿†æœºåˆ¶ã€ä»¥åŠå¯¹â€œLLM-as-a-judgeâ€è‡ªæˆ‘åè§çš„æ‰¹åˆ¤æ€§ç ”ç©¶æ˜¯ä»Šå¤©çš„æ ¸å¿ƒè®®é¢˜ã€‚\n\n---\n\n### ğŸš€ é‡ç£…é¦–å‘ï¼šOpenAI å¼€æºæ¨¡å‹\n**1. gpt-oss-120b & gpt-oss-20b Model Card (gpt-oss-120b & gpt-oss-20b æ¨¡å‹å¡)**\n> **Authors:** OpenAI Team (Sam Altman, et al.)\n> **å…³é”®è¯:** Open-Weight, MoE, Agentic Capabilities, Apache 2.0\n\nOpenAI ç½•è§åœ°å‘å¸ƒäº†ä¸¤æ¬¾**å¼€æºæƒé‡ï¼ˆOpen-weightï¼‰**çš„æ¨ç†æ¨¡å‹ï¼š120B å’Œ 20B ç‰ˆæœ¬ã€‚\n- **æ ¸å¿ƒè´¡çŒ®**ï¼šè¿™äº›æ¨¡å‹é‡‡ç”¨é«˜æ•ˆçš„æ··åˆä¸“å®¶ï¼ˆMoEï¼‰Transformer æ¶æ„ï¼Œé€šè¿‡å¤§è§„æ¨¡è’¸é¦å’Œå¼ºåŒ–å­¦ä¹ è®­ç»ƒè€Œæˆã€‚\n- **ç‰¹ç‚¹**ï¼šé’ˆå¯¹ Agent èƒ½åŠ›è¿›è¡Œäº†ä¼˜åŒ–ï¼ˆæ·±åº¦æœç´¢æµè§ˆã€Python å·¥å…·ä½¿ç”¨ï¼‰ï¼Œé‡‡ç”¨ Apache 2.0 è®¸å¯è¯ã€‚è¿™æ˜¯ OpenAI å¯¹æŠ—å¼€æºç¤¾åŒºï¼ˆå¦‚ Llamaï¼‰çš„ä¸€è®°é‡æ‹³ï¼Œæ—¨åœ¨æ¨åŠ¨åŸºäºå…¶æ¶æ„çš„å¹¿æ³›åº”ç”¨ã€‚\n\n---\n\n### âš¡ï¸ é«˜æ•ˆæ¨ç†ä¸æ–°æ¶æ„\n**2. Pushing the Envelope of LLM Inference on AI-PC (åœ¨ AI-PC ä¸Šé€šè¿‡ 1-bit/2-bit æ¨¡å‹çªç ´ LLM æ¨ç†æé™)**\n> **Authors:** Evangelos Georganas et al. (Intel)\n> **å…³é”®è¯:** Ultra-low-bit, CPU Inference, Microkernels\n\n- **æ ¸å¿ƒå‘ç°**ï¼šé’ˆå¯¹è¾¹ç¼˜è®¾å¤‡ï¼Œä½œè€…å®ç°äº†é’ˆå¯¹ç°ä»£ CPU ä¼˜åŒ–çš„ **1-bit å’Œ 2-bit å¾®å†…æ ¸**ã€‚\n- **æ•ˆæœ**ï¼šé›†æˆåˆ° PyTorch-TPP åï¼Œ2-bit æ¨¡å‹æ¨ç†é€Ÿåº¦æ¯”ç›®å‰çš„ SOTAï¼ˆbitnet.cppï¼‰å¿« 2.2 å€ï¼Œæ¯” FP16 æ¨¡å‹å¿« 7 å€ï¼Œä¸”ç²¾åº¦æŸå¤±æå°ã€‚è¿™ä¸ºåœ¨ç¬”è®°æœ¬ç”µè„‘ä¸Šè·‘å¤§æ¨¡å‹é“ºå¹³äº†é“è·¯ã€‚\n\n**3. Diffusion LLMs Can Do Faster-Than-AR Inference via Discrete Diffusion Forcing (Diffusion LLM é€šè¿‡ç¦»æ•£æ‰©æ•£å¼ºåˆ¶å®ç°æ¯”è‡ªå›å½’æ›´å¿«çš„æ¨ç†)**\n> **Authors:** Xu Wang et al.\n> **å…³é”®è¯:** Diffusion LLM, Non-autoregressive, Inference Speed\n\n- **æ ¸å¿ƒè´¡çŒ®**ï¼šæ‰“ç ´äº† Diffusion LLM æ¨ç†æ…¢çš„é­”å’’ã€‚æå‡º **Discrete Diffusion Forcing (D2F)**ï¼Œèµ‹äºˆæ¨¡å‹å—çº§è‡ªå›å½’ç”Ÿæˆèƒ½åŠ›å’Œè·¨å—å¹¶è¡Œè§£ç èƒ½åŠ›ã€‚\n- **æ•ˆæœ**ï¼šåœ¨ GSM8K ä¸Šï¼Œæ¨ç†é€Ÿåº¦æ˜¯ LLaMA3 çš„ **2.5å€**ä»¥ä¸Šï¼Œä¸”ä¿æŒäº†ç›¸å½“çš„ç”Ÿæˆè´¨é‡ã€‚\n\n---\n\n### ğŸ§  Agentã€è®°å¿†ä¸æ¨ç†\n**4. SABER: Switchable and Balanced Training for Efficient LLM Reasoning (SABERï¼šç”¨äºé«˜æ•ˆ LLM æ¨ç†çš„å¯åˆ‡æ¢ä¸å¹³è¡¡è®­ç»ƒ)**\n> **Authors:** Kai Zhao et al.\n> **å…³é”®è¯:** Reinforcement Learning, Inference Budget, Dynamic Compute\n\n- **æ ¸å¿ƒè´¡çŒ®**ï¼šæå‡ºäº†ä¸€ç§è®© LLM å…·å¤‡**ç”¨æˆ·å¯æ§çš„ã€å¸¦ Token é¢„ç®—çš„æ¨ç†èƒ½åŠ›**çš„æ¡†æ¶ã€‚\n- **æ–¹æ³•**ï¼šæ”¯æŒå››ç§æ¨¡å¼ï¼ˆNoThink, FastThink, CoreThink, DeepThinkï¼‰ã€‚FastThink æ¨¡å¼ä¸‹ï¼Œæ•°å­¦æ¨ç†é•¿åº¦å‡å°‘ 65.4%ï¼Œä½†å‡†ç¡®ç‡åè€Œæ¯”åŸºåº§æ¨¡å‹é«˜ 3.6%ã€‚\n\n**5. Cognitive Workspace: Active Memory Management for LLMs (è®¤çŸ¥å·¥ä½œåŒºï¼šLLM çš„ä¸»åŠ¨è®°å¿†ç®¡ç†)**\n> **Authors:** Tao An\n> **å…³é”®è¯:** Active Memory, Cognitive Science, Beyond RAG\n\n- **æ ¸å¿ƒè§‚ç‚¹**ï¼šç›®å‰çš„ RAG æ˜¯è¢«åŠ¨çš„ã€‚ä½œè€…æå‡ºäº† **Cognitive Workspace**ï¼Œæ¨¡æ‹Ÿäººç±»çš„ä¸»åŠ¨è®°å¿†ç®¡ç†ï¼ˆåŸºäºå·¥ä½œè®°å¿†ç†è®ºï¼‰ã€‚\n- **å‘ç°**ï¼šè¯¥ç³»ç»Ÿèƒ½ä¸»åŠ¨è§„åˆ’å’Œç»´æŠ¤â€œè®¤çŸ¥ç¼“å†²åŒºâ€ï¼Œåœ¨å¤šé¡¹ä»»åŠ¡ä¸­å®ç°äº† 58.6% çš„è®°å¿†å¤ç”¨ç‡ï¼Œå½»åº•ç¢¾å‹ä¼ ç»Ÿ RAGï¼ˆ0% å¤ç”¨ï¼‰ï¼Œè¢«è§†ä¸ºä»â€œä¿¡æ¯æ£€ç´¢â€å‘â€œè®¤çŸ¥å¢å¼ºâ€çš„è½¬å˜ã€‚\n\n**6. Memp: Exploring Agent Procedural Memory (Mempï¼šæ¢ç´¢ Agent çš„ç¨‹åºæ€§è®°å¿†)**\n> **Authors:** Runnan Fang et al. (Zhejiang University & Alibaba)\n> **å…³é”®è¯:** Procedural Memory, Lifelong Learning, Agent\n\n- **æ ¸å¿ƒè´¡çŒ®**ï¼šèµ‹äºˆ Agent **å¯å­¦ä¹ ã€å¯æ›´æ–°çš„ç¨‹åºæ€§è®°å¿†**ã€‚å°†è¿‡å»çš„è½¨è¿¹è’¸é¦ä¸ºç»†ç²’åº¦çš„æ­¥éª¤è¯´æ˜å’Œè„šæœ¬åŒ–çš„æŠ½è±¡ã€‚\n- **æ•ˆæœ**ï¼šéšç€è®°å¿†åº“çš„å®Œå–„ï¼ŒAgent åœ¨ TravelPlanner ç­‰ä»»åŠ¡ä¸Šçš„æˆåŠŸç‡ç¨³æ­¥æå‡ï¼Œä¸”è¿™ç§è®°å¿†å¯ä»¥ä»å¼ºæ¨¡å‹è¿ç§»åˆ°å¼±æ¨¡å‹ã€‚\n\n**7. Devstral: Fine-tuning Language Models for Coding Agent Applications (Devstralï¼šå¾®è°ƒç”¨äºä»£ç  Agent åº”ç”¨çš„è¯­è¨€æ¨¡å‹)**\n> **Authors:** Mistral AI Team\n> **å…³é”®è¯:** Code Agent, 24B Model, Open Source\n\n- **ç®€è®¯**ï¼šMistral AI å‘å¸ƒäº† **Devstral-Small (24B)**ï¼Œä¸“ä¸ºä»£ç  Agent è®¾è®¡ï¼Œæ€§èƒ½è¶…è¶ŠåŒå°ºå¯¸æ¨¡å‹ï¼Œä¸”æ˜“äºéƒ¨ç½²ã€‚\n\n---\n\n### ğŸ›¡ï¸ å®‰å…¨ã€åè§ä¸è¯„ä¼°\n**8. Play Favorites: A Statistical Method to Measure Self-Bias in LLM-as-a-Judge (åè¢’è‡ªå·±ï¼šæµ‹é‡ LLM è£åˆ¤è‡ªæˆ‘åè§çš„ç»Ÿè®¡æ–¹æ³•)**\n> **Authors:** Evangelia Spiliopoulou et al. (Amazon AWS AI)\n> **å…³é”®è¯:** LLM-as-a-judge, Self-bias, Family-bias\n\n- **æ ¸å¿ƒå‘ç°**ï¼š**GPT-4o å’Œ Claude 3.5 Sonnet å­˜åœ¨ä¸¥é‡çš„â€œè‡ªæˆ‘åè§â€**ï¼Œå³ç³»ç»Ÿæ€§åœ°ç»™è‡ªå·±çš„è¾“å‡ºæ‰“é«˜åˆ†ã€‚\n- **è¡¥å……**ï¼šç”šè‡³å­˜åœ¨â€œå®¶æ—åè§â€ï¼Œå³å€¾å‘äºç»™åŒç³»åˆ—æ¨¡å‹çš„è¾“å‡ºæ‰“é«˜åˆ†ã€‚è¿™ç»™ç›®å‰æµè¡Œçš„ LLM è‡ªåŠ¨è¯„ä¼°çš„å¯ä¿¡åº¦æ‰“ä¸Šäº†é—®å·ã€‚\n\n**9. Deep Ignorance: Filtering Pretraining Data Builds Tamper-Resistant Safeguards (æ·±åº¦æ— çŸ¥ï¼šè¿‡æ»¤é¢„è®­ç»ƒæ•°æ®æ„å»ºé˜²ç¯¡æ”¹æŠ¤æ )**\n> **Authors:** Kyle O'Brien et al. (Oxford & FAR AI)\n> **å…³é”®è¯:** Pretraining Safety, Biothreats, Unlearning\n\n- **æ–¹æ³•**ï¼šä¸å…¶äº‹åå¯¹é½ï¼ˆå®¹æ˜“è¢«æ”»å‡»ç»•è¿‡ï¼‰ï¼Œä¸å¦‚åœ¨é¢„è®­ç»ƒé˜¶æ®µå°±**åˆ æ‰å±é™©çŸ¥è¯†**ï¼ˆå¦‚ç”Ÿç‰©å¨èƒæ•°æ®ï¼‰ã€‚\n- **æ•ˆæœ**ï¼šè¿™ç§â€œæ·±åº¦æ— çŸ¥â€æ¨¡å‹åœ¨é¢å¯¹ 10,000 æ­¥çš„å¯¹æŠ—æ€§å¾®è°ƒæ”»å‡»æ—¶ä¾ç„¶è¡¨ç°å‡ºå¼ºå¤§çš„æŠµæŠ—åŠ›ï¼Œæ¯”ç°æœ‰çš„äº‹åé˜²å¾¡å¼ºä¸€ä¸ªæ•°é‡çº§ã€‚\n\n**10. CountQA: How Well Do MLLMs Count in the Wild? (CountQAï¼šå¤šæ¨¡æ€å¤§æ¨¡å‹çœŸçš„ä¼šæ•°æ•°å—ï¼Ÿ)**\n> **Authors:** Jayant Sravan Tamarapalli et al.\n> **å…³é”®è¯:** Object Counting, MLLM Benchmark, Blind Spot\n\n- **æ‰“è„¸æ—¶åˆ»**ï¼šå¤šæ¨¡æ€å¤§æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨**å¯†é›†ç‰©ä½“è®¡æ•°**ä¸Šè¡¨ç°æå·®ã€‚\n- **æ•°æ®**ï¼šæœ€å¥½çš„æ¨¡å‹åœ¨çœŸå®åœºæ™¯ï¼ˆCountQA Benchmarkï¼‰ä¸‹çš„å‡†ç¡®ç‡ä»…ä¸º **42.9%**ã€‚è¿™æ˜¯å½“å‰è§†è§‰å¤§æ¨¡å‹çš„ä¸€ä¸ªæ˜¾è‘—ç›²ç‚¹ã€‚\n\n---\n\n### ğŸ‘ï¸ è§†è§‰ä¸å¤šæ¨¡æ€\n**11. Bifrost-1: Bridging Multimodal LLMs and Diffusion Models with Patch-level CLIP Latents (Bifrost-1ï¼šåˆ©ç”¨ Patch çº§ CLIP æ½œå˜é‡æ¡¥æ¥å¤šæ¨¡æ€ LLM å’Œæ‰©æ•£æ¨¡å‹)**\n> **Authors:** Han Lin et al. (UNC Chapel Hill)\n> **å…³é”®è¯:** MLLM, Diffusion, Image Generation\n\n- **æ ¸å¿ƒè´¡çŒ®**ï¼šæå‡ºäº†ä¸€ä¸ªç»Ÿä¸€æ¡†æ¶ï¼Œåˆ©ç”¨ **Patch çº§çš„ CLIP å›¾åƒåµŒå…¥**ä½œä¸ºæ½œå˜é‡ï¼Œè¿æ¥ MLLM å’Œæ‰©æ•£æ¨¡å‹ã€‚\n- **ä¼˜åŠ¿**ï¼šä¸éœ€è¦ä»å¤´è®­ç»ƒå·¨å¤§çš„æ¨¡å‹ï¼Œä»…éœ€è½»é‡çº§é€‚é…ï¼Œå°±èƒ½å®ç°é«˜è´¨é‡ã€å¯æ§çš„å›¾åƒç”Ÿæˆï¼Œä¸”ä¿ç•™äº† MLLM çš„æ¨ç†èƒ½åŠ›ã€‚\n\n**12. Fourier-VLM: Compressing Vision Tokens in the Frequency Domain (Fourier-VLMï¼šåœ¨é¢‘åŸŸå‹ç¼©è§†è§‰ Token)**\n> **Authors:** Huanyu Wang et al. (ByteDance)\n> **å…³é”®è¯:** Token Compression, Frequency Domain, Efficiency\n\n- **æ–¹æ³•**ï¼šå‘ç°è§†è§‰ç‰¹å¾çš„èƒ½é‡ä¸»è¦é›†ä¸­åœ¨ä½é¢‘éƒ¨åˆ†ï¼Œåˆ©ç”¨ FFT åœ¨é¢‘åŸŸè¿›è¡Œä½é€šæ»¤æ³¢æ¥å‹ç¼© Tokenã€‚\n- **æ•ˆæœ**ï¼šç›¸æ¯” LLaVA-v1.5ï¼Œæ¨ç† FLOPs å‡å°‘ **83.8%**ï¼Œç”Ÿæˆé€Ÿåº¦æå‡ 31.2%ï¼Œä¸”ä¸éœ€è¦é¢å¤–å‚æ•°ã€‚\n\n---\n\n### ğŸ§ª ç§‘å­¦ä¸æœ‰è¶£çš„äº¤å‰ç ”ç©¶\n**13. Generative AI Extracts Structure-Function Relationships from Plants for New Materials (ç”Ÿæˆå¼ AI ä»æ¤ç‰©ä¸­æå–ç»“æ„-åŠŸèƒ½å…³ç³»ç”¨äºæ–°ææ–™ç ”å‘)**\n> **Authors:** Rachel K. Luu et al. (MIT)\n> **å…³é”®è¯:** Materials Science, Bio-inspired, Agentic Workflow\n\n- **åº”ç”¨**ï¼šåˆ©ç”¨å¾®è°ƒçš„ BioinspiredLLM å’Œ RAGï¼Œä»è·¨å­¦ç§‘æ–‡çŒ®ä¸­æå–çµæ„Ÿï¼Œè®¾è®¡äº†åŸºäºèŠ±ç²‰çš„æ¹¿åº¦å“åº”ææ–™ã€‚è¿™æ˜¯ AI é©±åŠ¨ææ–™ç§‘å­¦å®éªŒè®¾è®¡çš„å…¸å‹æ¡ˆä¾‹ã€‚\n\n**14. Do Biased Models Have Biased Thoughts? (æœ‰åè§çš„æ¨¡å‹ä¼šæœ‰åè§çš„â€œæƒ³æ³•â€å—ï¼Ÿ)**\n> **Authors:** Swati Rajwal et al.\n> **å…³é”®è¯:** Chain-of-Thought, Fairness, Bias Analysis\n\n- **æœ‰è¶£çš„ç»“è®º**ï¼š**æ¨¡å‹çš„â€œæ€ç»´é“¾â€ï¼ˆCoTï¼‰ä¸­çš„åè§ä¸æœ€ç»ˆè¾“å‡ºçš„åè§ç›¸å…³æ€§å¾ˆä½**ï¼ˆ<0.6ï¼‰ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œæ¨¡å‹å¯èƒ½åœ¨å†³ç­–ä¸Šæœ‰åè§ï¼Œä½†å®ƒçš„æ¨ç†è¿‡ç¨‹ï¼ˆThoughtsï¼‰å¹¶ä¸ä¸€å®šæ˜¾ç¤ºå‡ºåŒæ ·çš„åè§ï¼Œåä¹‹äº¦ç„¶ã€‚è¿™å°±å¾ˆåƒäººç±»çš„â€œå£æ˜¯å¿ƒéâ€ã€‚\n\n---\nä»Šå¤©çš„ arXiv æ›´æ–°é‡éå¸¸å¤§ï¼ŒOpenAI çš„å¼€æºåŠ¨ä½œå¯èƒ½ä¼šåœ¨æœªæ¥å‡ å‘¨å†…å¼•å‘æ–°çš„å¾®è°ƒå’Œåº”ç”¨çƒ­æ½®ã€‚å¸Œæœ›è¿™ä»½å¿«æŠ¥å¯¹ä½ çš„ç ”ç©¶æœ‰æ‰€å¸®åŠ©ï¼ ğŸ‘‹",
  "papers": [
    {
      "arxiv_id": "2508.06754v1",
      "title": "A Fuzzy Logic Prompting Framework for Large Language Models in Adaptive and Uncertain Tasks",
      "title_zh": "é¢å‘å¤§è¯­è¨€æ¨¡å‹è‡ªé€‚åº”ä¸ä¸ç¡®å®šæ€§ä»»åŠ¡çš„æ¨¡ç³Šé€»è¾‘æç¤ºæ¡†æ¶",
      "authors": [
        "Vanessa Figueiredo"
      ],
      "abstract": "We introduce a modular prompting framework that supports safer and more adaptive use of large language models (LLMs) across dynamic, user-centered tasks. Grounded in human learning theory, particularly the Zone of Proximal Development (ZPD), our method combines a natural language boundary prompt with a control schema encoded with fuzzy scaffolding logic and adaptation rules. This architecture enables LLMs to modulate behavior in response to user state without requiring fine-tuning or external orchestration. In a simulated intelligent tutoring setting, the framework improves scaffolding quality, adaptivity, and instructional alignment across multiple models, outperforming standard prompting baselines. Evaluation is conducted using rubric-based LLM graders at scale. While initially developed for education, the framework has shown promise in other interaction-heavy domains, such as procedural content generation for games. Designed for safe deployment, it provides a reusable methodology for structuring interpretable, goal-aligned LLM behavior in uncertain or evolving contexts.",
      "tldr_zh": "æœ¬ç ”ç©¶æå‡ºäº†ä¸€ä¸ªæ¨¡å—åŒ–çš„æç¤ºæ¡†æ¶ï¼Œæ—¨åœ¨æå‡å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨åŠ¨æ€ã€ä»¥ç”¨æˆ·ä¸ºä¸­å¿ƒä»»åŠ¡ä¸­çš„å®‰å…¨æ€§ä¸è‡ªé€‚åº”èƒ½åŠ›ã€‚è¯¥æ–¹æ³•ä»¥äººç±»å­¦ä¹ ç†è®ºä¸­çš„æœ€è¿‘å‘å±•åŒº(Zone of Proximal Development)ä¸ºåŸºç¡€ï¼Œç»“åˆäº†è‡ªç„¶è¯­è¨€è¾¹ç•Œæç¤º(boundary prompt)ä»¥åŠç¼–ç æ¨¡ç³Šæ”¯æ¶é€»è¾‘(fuzzy scaffolding logic)å’Œè‡ªé€‚åº”è§„åˆ™çš„æ§åˆ¶æ¨¡å¼ã€‚è¯¥æ¶æ„å…è®¸æ¨¡å‹æ ¹æ®ç”¨æˆ·çŠ¶æ€è‡ªä¸»è°ƒèŠ‚è¡Œä¸ºï¼Œä¸”æ— éœ€è¿›è¡Œå¾®è°ƒ(fine-tuning)æˆ–ä¾èµ–å¤–éƒ¨ç¼–æ’ã€‚åœ¨æ™ºèƒ½å¯¼å¸ˆç³»ç»Ÿçš„æ¨¡æ‹Ÿå®éªŒä¸­ï¼Œè¯¥æ¡†æ¶åœ¨æ•™å­¦æ”¯æ¶è´¨é‡ã€è‡ªé€‚åº”æ€§åŠæŒ‡ä»¤å¯¹é½æ–¹é¢å‡ä¼˜äºæ ‡å‡†æç¤º(standard prompting)åŸºå‡†ã€‚è¯„ä¼°è¿‡ç¨‹é‡‡ç”¨äº†å¤§è§„æ¨¡çš„åŸºäºé‡è¡¨çš„LLMè¯„åˆ†å™¨ï¼Œç¡®ä¿äº†ç»“æœçš„å¯é æ€§ã€‚é™¤äº†æ•™è‚²é¢†åŸŸï¼Œè¯¥æ¡†æ¶åœ¨æ¸¸æˆç¨‹åºåŒ–å†…å®¹ç”Ÿæˆç­‰é«˜äº¤äº’é¢†åŸŸä¹Ÿå±•ç°å‡ºåº”ç”¨å‰æ™¯ï¼Œä¸ºåœ¨ä¸ç¡®å®šæˆ–åŠ¨æ€è¯­å¢ƒä¸‹æ„å»ºå¯è§£é‡Šã€ç›®æ ‡ä¸€è‡´çš„LLMè¡Œä¸ºæä¾›äº†ä¸€ç§å¯é‡å¤çš„æ–¹æ³•è®ºã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06754v1",
      "published_date": "2025-08-08 23:50:48 UTC",
      "updated_date": "2025-08-08 23:50:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:05:41.101715+00:00"
    },
    {
      "arxiv_id": "2508.06753v1",
      "title": "Pushing the Envelope of LLM Inference on AI-PC",
      "title_zh": "æŒ‘æˆ˜ AI PC å¤§è¯­è¨€æ¨¡å‹æ¨ç†æ€§èƒ½æé™",
      "authors": [
        "Evangelos Georganas",
        "Dhiraj Kalamkar",
        "Alexander Heinecke"
      ],
      "abstract": "The advent of ultra-low-bit LLM models (1/1.58/2-bit), which match the perplexity and end-task performance of their full-precision counterparts using the same model size, is ushering in a new era of LLM inference for resource-constrained environments such as edge devices and AI PCs. While these quantization advances promise models that are more cost-effective in terms of latency, memory, throughput, and energy consumption, the computational efficiency of state-of-the-art (SOTA) inference runtimes (e.g., bitnet.cpp) used to deploy them remains underexplored. In this work, we take a bottom-up approach: we first design and implement 1-bit and 2-bit microkernels optimized for modern CPUs, achieving peak computational efficiency across a variety of CPU platforms. We integrate these microkernels into a state-of-the-art LLM inference framework, namely PyTorch-TPP, and present end-to-end inference results with 2-bit models that outperform the current SOTA runtime bitnet.cpp by up to 2.2x, and deliver up to 7x speedup compared to the 16-bit model inference. Our optimized runtime advances the state of LLM inference on AI PCs and edge devices, paving the way for efficient deployment of ultra-low-bit LLM models.",
      "tldr_zh": "è¯¥ç ”ç©¶æ—¨åœ¨ä¼˜åŒ– AI-PC å’Œè¾¹ç¼˜è®¾å¤‡ç­‰èµ„æºå—é™ç¯å¢ƒä¸‹è¶…ä½æ¯”ç‰¹ (ultra-low-bit) å¤§è¯­è¨€æ¨¡å‹ (LLM) çš„æ¨ç†æ•ˆç‡ã€‚ä½œè€…é€šè¿‡è‡ªä¸‹è€Œä¸Šçš„æ–¹æ³•ï¼Œè®¾è®¡å¹¶å®ç°äº†é’ˆå¯¹ç°ä»£ CPU ä¼˜åŒ–çš„ 1-bit å’Œ 2-bit å¾®å†…æ ¸ (microkernels)ï¼Œä»¥åœ¨å¤šç§ CPU å¹³å°ä¸Šå®ç°å³°å€¼è®¡ç®—æ•ˆç‡ã€‚è¿™äº›å¾®å†…æ ¸è¢«é›†æˆåˆ°å…ˆè¿›çš„æ¨ç†æ¡†æ¶ PyTorch-TPP ä¸­ï¼Œç”¨äºæ”¯æŒè¶…ä½æ¯”ç‰¹æ¨¡å‹çš„ç«¯åˆ°ç«¯æ¨ç†ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ¡ˆåœ¨ 2-bit æ¨¡å‹æ¨ç†ä¸­çš„è¡¨ç°ä¼˜äºç›®å‰çš„ SOTA è¿è¡Œæ—¶ bitnet.cppï¼Œæ€§èƒ½æå‡é«˜è¾¾ 2.2 å€ã€‚æ­¤å¤–ï¼Œä¸ 16-bit æ¨¡å‹æ¨ç†ç›¸æ¯”ï¼Œä¼˜åŒ–åçš„ç³»ç»Ÿå®ç°äº†é«˜è¾¾ 7 å€çš„åŠ é€Ÿæ•ˆæœã€‚è¯¥é¡¹å·¥ä½œæ‹“å±•äº† AI-PC ä¸Š LLM æ¨ç†çš„æ€§èƒ½è¾¹ç•Œï¼Œä¸ºè¶…ä½æ¯”ç‰¹æ¨¡å‹çš„é«˜æ•ˆéƒ¨ç½²å¥ å®šäº†æŠ€æœ¯åŸºç¡€ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.PF"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06753v1",
      "published_date": "2025-08-08 23:33:38 UTC",
      "updated_date": "2025-08-08 23:33:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:05:50.108768+00:00"
    },
    {
      "arxiv_id": "2508.06746v1",
      "title": "Topology Generation of UAV Covert Communication Networks: A Graph Diffusion Approach with Incentive Mechanism",
      "title_zh": "æ— äººæœºéšè”½é€šä¿¡ç½‘ç»œæ‹“æ‰‘ç”Ÿæˆï¼šä¸€ç§åŸºäºæ¿€åŠ±æœºåˆ¶çš„å›¾æ‰©æ•£æ–¹æ³•",
      "authors": [
        "Xin Tang",
        "Qian Chen",
        "Fengshun Li",
        "Youchun Gong",
        "Yinqiu Liu",
        "Wen Tian",
        "Shaowen Qin",
        "Xiaohuan Li"
      ],
      "abstract": "With the growing demand for Uncrewed Aerial Vehicle (UAV) networks in sensitive applications, such as urban monitoring, emergency response, and secure sensing, ensuring reliable connectivity and covert communication has become increasingly vital. However, dynamic mobility and exposure risks pose significant challenges. To tackle these challenges, this paper proposes a self-organizing UAV network framework combining Graph Diffusion-based Policy Optimization (GDPO) with a Stackelberg Game (SG)-based incentive mechanism. The GDPO method uses generative AI to dynamically generate sparse but well-connected topologies, enabling flexible adaptation to changing node distributions and Ground User (GU) demands. Meanwhile, the Stackelberg Game (SG)-based incentive mechanism guides self-interested UAVs to choose relay behaviors and neighbor links that support cooperation and enhance covert communication. Extensive experiments are conducted to validate the effectiveness of the proposed framework in terms of model convergence, topology generation quality, and enhancement of covert communication performance.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§æ— äººæœº(UAV)éšè”½é€šä¿¡ç½‘ç»œçš„è‡ªç»„ç»‡æ¡†æ¶ï¼Œæ—¨åœ¨åº”å¯¹åŠ¨æ€ç§»åŠ¨æ€§å’Œæš´éœ²é£é™©å¯¹è¿æ¥å¯é æ€§å¸¦æ¥çš„æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶æ ¸å¿ƒç»“åˆäº†åŸºäºå›¾æ‰©æ•£çš„ç­–ç•¥ä¼˜åŒ–(GDPO)æ–¹æ³•ä¸åŸºäºStackelbergåšå¼ˆ(SG)çš„æ¿€åŠ±æœºåˆ¶ï¼Œå®ç°äº†é«˜æ•ˆçš„æ‹“æ‰‘ç”Ÿæˆã€‚å…¶ä¸­ï¼ŒGDPOåˆ©ç”¨ç”Ÿæˆå¼äººå·¥æ™ºèƒ½(Generative AI)åŠ¨æ€æ„å»ºç¨€ç–ä¸”è¿é€šæ€§è‰¯å¥½çš„ç½‘ç»œæ‹“æ‰‘ï¼Œèƒ½å¤Ÿçµæ´»é€‚åº”èŠ‚ç‚¹åˆ†å¸ƒçš„å˜åŒ–åŠåœ°é¢ç”¨æˆ·(GU)çš„éœ€æ±‚ã€‚æ¿€åŠ±æœºåˆ¶åˆ™é€šè¿‡åšå¼ˆè®ºæ–¹æ³•å¼•å¯¼è‡ªåˆ©çš„æ— äººæœºé€‰æ‹©æ”¯æŒåä½œçš„è½¬å‘è¡Œä¸ºå’Œé‚»å±…é“¾è·¯ï¼Œä»è€Œæ˜¾è‘—å¢å¼ºäº†éšè”½é€šä¿¡æ€§èƒ½ã€‚å¤§é‡å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ¡ˆåœ¨æ¨¡å‹æ”¶æ•›é€Ÿåº¦ã€æ‹“æ‰‘ç”Ÿæˆè´¨é‡ä»¥åŠæå‡é€šä¿¡éšè”½æ€§æ–¹é¢å‡è¡¨ç°å‡ºæ˜¾è‘—çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06746v1",
      "published_date": "2025-08-08 23:06:49 UTC",
      "updated_date": "2025-08-08 23:06:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:05:52.486586+00:00"
    },
    {
      "arxiv_id": "2508.06743v1",
      "title": "Analysis of Schedule-Free Nonconvex Optimization",
      "title_zh": "å…è°ƒåº¦éå‡¸ä¼˜åŒ–åˆ†æ",
      "authors": [
        "Connor Brown"
      ],
      "abstract": "First-order methods underpin most large-scale learning algorithms, yet their classical convergence guarantees hinge on carefully scheduled step-sizes that depend on the total horizon $T$, which is rarely known in advance. The Schedule-Free (SF) method promises optimal performance with hyperparameters that are independent of $T$ by interpolating between Polyak--Ruppert averaging and momentum, but nonconvex analysis of SF has been limited or reliant on strong global assumptions. We introduce a robust Lyapunov framework that, under only $L$-smoothness and lower-boundedness, reduces SF analysis to a single-step descent inequality. This yields horizon-agnostic bounds in the nonconvex setting: $O(1/\\log T)$ for constant step + PR averaging, $O(\\log T/T)$ for a linearly growing step-size, and a continuum of $O(T^{-(1-Î±)})$ rates for polynomial averaging. We complement these proofs with Performance Estimation Problem (PEP) experiments that numerically validate our rates and suggest that our $O(1/\\log T)$ bound on the original nonconvex SF algorithm may tighten to $O(1/T)$. Our work extends SF's horizon-free guarantees to smooth nonconvex optimization and charts future directions for optimal nonconvex rates.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¸€é˜¶ä¼˜åŒ–æ–¹æ³•ï¼ˆFirst-order methodsï¼‰é€šå¸¸ä¾èµ–äºé¢„å…ˆç¡®å®šçš„æ€»æ­¥æ•° $T$ æ¥è¿›è¡Œæ­¥é•¿è°ƒåº¦çš„é—®é¢˜ï¼Œå¯¹æ— è°ƒåº¦ï¼ˆSchedule-Free, SFï¼‰æ–¹æ³•åœ¨éå‡¸ä¼˜åŒ–ï¼ˆNonconvex Optimizationï¼‰ç¯å¢ƒä¸‹çš„è¡¨ç°è¿›è¡Œäº†ç³»ç»Ÿåˆ†æã€‚ç ”ç©¶å¼•å…¥äº†ä¸€ä¸ªç¨³å¥çš„ Lyapunov æ¡†æ¶ï¼Œåœ¨ä»…è¦æ±‚ $L$-å…‰æ»‘ï¼ˆ$L$-smoothnessï¼‰å’Œå‡½æ•°æœ‰ä¸‹ç•Œçš„æ¡ä»¶ä¸‹ï¼Œå°† SF çš„å¤æ‚åˆ†æç®€åŒ–ä¸ºå•æ­¥ä¸‹é™ä¸ç­‰å¼ã€‚é€šè¿‡è¯¥æ¡†æ¶ï¼Œç ”ç©¶æ¨å¯¼å‡ºäº†å¤šç§è·¨æ—¶ç•Œç•Œé™ï¼ˆHorizon-agnostic boundsï¼‰ï¼ŒåŒ…æ‹¬å¸¸æ•°æ­¥é•¿ç»“åˆ Polyak-Ruppert å¹³å‡ä¸‹çš„ $O(1/\\log T)$ é€Ÿç‡ï¼Œä»¥åŠçº¿æ€§å¢é•¿æ­¥é•¿ä¸‹çš„ $O(\\log T/T)$ é€Ÿç‡ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜æ¶µç›–äº†å¤šé¡¹å¼å¹³å‡ä¸‹çš„ $O(T^{-(1-Î±)})$ è¿ç»­é€Ÿç‡ã€‚é€šè¿‡æ€§èƒ½è¯„ä¼°é—®é¢˜ï¼ˆPerformance Estimation Problem, PEPï¼‰å®éªŒï¼Œç ”ç©¶æ•°å€¼éªŒè¯äº†è¿™äº›ç†è®ºé€Ÿç‡çš„æ­£ç¡®æ€§ï¼Œå¹¶æŒ‡å‡ºåŸå§‹éå‡¸ SF ç®—æ³•çš„ç•Œé™æœ‰æœ›è¿›ä¸€æ­¥æ”¶ç´§è‡³ $O(1/T)$ã€‚è¯¥å·¥ä½œæˆåŠŸå°† SF æ–¹æ³•çš„ä¼˜å¼‚ç‰¹æ€§æ‰©å±•è‡³å¹³æ»‘éå‡¸ä¼˜åŒ–é¢†åŸŸï¼Œä¸ºæœªæ¥æ¢ç´¢æœ€ä¼˜éå‡¸é€Ÿç‡å¥ å®šäº†ç†è®ºåŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06743v1",
      "published_date": "2025-08-08 22:54:35 UTC",
      "updated_date": "2025-08-08 22:54:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:06:00.691611+00:00"
    },
    {
      "arxiv_id": "2508.06742v1",
      "title": "Learning Causal Structure Distributions for Robust Planning",
      "title_zh": "é¢å‘é²æ£’è§„åˆ’çš„å› æœç»“æ„åˆ†å¸ƒå­¦ä¹ ",
      "authors": [
        "Alejandro Murillo-Gonzalez",
        "Junhong Xu",
        "Lantao Liu"
      ],
      "abstract": "Structural causal models describe how the components of a robotic system interact. They provide both structural and functional information about the relationships that are present in the system. The structural information outlines the variables among which there is interaction. The functional information describes how such interactions work, via equations or learned models. In this paper we find that learning the functional relationships while accounting for the uncertainty about the structural information leads to more robust dynamics models which improves downstream planning, while using significantly lower computational resources. This in contrast with common model-learning methods that ignore the causal structure and fail to leverage the sparsity of interactions in robotic systems. We achieve this by estimating a causal structure distribution that is used to sample causal graphs that inform the latent-space representations in an encoder-multidecoder probabilistic model. We show that our model can be used to learn the dynamics of a robot, which together with a sampling-based planner can be used to perform new tasks in novel environments, provided an objective function for the new requirement is available. We validate our method using manipulators and mobile robots in both simulation and the real-world. Additionally, we validate the learned dynamics' adaptability and increased robustness to corrupted inputs and changes in the environment, which is highly desirable in challenging real-world robotics scenarios. Video: https://youtu.be/X6k5t7OOnNc.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†å­¦ä¹ å› æœç»“æ„åˆ†å¸ƒï¼ˆcausal structure distributionï¼‰çš„æ–¹æ³•ï¼Œæ—¨åœ¨æå‡æœºå™¨äººç³»ç»Ÿåœ¨è§„åˆ’è¿‡ç¨‹ä¸­çš„é²æ£’æ€§ã€‚è¯¥æ–¹æ³•é€šè¿‡ä¼°è®¡å› æœç»“æ„åˆ†å¸ƒæ¥é‡‡æ ·å› æœå›¾ï¼ˆcausal graphsï¼‰ï¼Œå¹¶å°†å…¶ç”¨äºæŒ‡å¯¼ç¼–ç å™¨-å¤šè§£ç å™¨ï¼ˆencoder-multidecoderï¼‰æ¦‚ç‡æ¨¡å‹ä¸­çš„æ½œåœ¨ç©ºé—´è¡¨ç¤ºï¼Œä»è€Œåœ¨è€ƒè™‘ç»“æ„ä¿¡æ¯ä¸ç¡®å®šæ€§çš„åŒæ—¶å­¦ä¹ åŠŸèƒ½å…³ç³»ã€‚ä¸å¿½ç•¥å› æœç»“æ„ã€æ— æ³•åˆ©ç”¨æœºå™¨äººäº¤äº’ç¨€ç–æ€§çš„ä¼ ç»Ÿæ¨¡å‹ç›¸æ¯”ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿä»¥æ›´ä½çš„è®¡ç®—èµ„æºæ„å»ºæ›´ç¨³å¥çš„åŠ¨åŠ›å­¦æ¨¡å‹ï¼ˆdynamics modelsï¼‰ã€‚å®éªŒè¡¨æ˜ï¼Œç»“åˆåŸºäºé‡‡æ ·çš„è§„åˆ’å™¨ï¼ˆsampling-based plannerï¼‰ï¼Œè¯¥ç³»ç»Ÿå¯ä»¥ä½¿æœºæ¢°è‡‚å’Œç§»åŠ¨æœºå™¨äººåœ¨æ–°ç¯å¢ƒä¸­é«˜æ•ˆå®Œæˆä»»åŠ¡ã€‚ç ”ç©¶é€šè¿‡ä»¿çœŸå’ŒçœŸå®ä¸–ç•ŒéªŒè¯ï¼Œè¯æ˜äº†è¯¥æ–¹æ³•å¯¹æŸåè¾“å…¥å’Œç¯å¢ƒå˜åŒ–å…·æœ‰æé«˜çš„é€‚åº”æ€§å’Œé²æ£’æ€§ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06742v1",
      "published_date": "2025-08-08 22:43:17 UTC",
      "updated_date": "2025-08-08 22:43:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:06:01.188020+00:00"
    },
    {
      "arxiv_id": "2508.06736v1",
      "title": "ParBalans: Parallel Multi-Armed Bandits-based Adaptive Large Neighborhood Search",
      "title_zh": "ParBalansï¼šåŸºäºå¤šè‡‚è€è™æœºçš„å¹¶è¡Œè‡ªé€‚åº”å¤§é‚»åŸŸæœç´¢",
      "authors": [
        "Alican Yilmaz",
        "Junyang Cai",
        "Serdar Kadioglu",
        "Bistra Dilkina"
      ],
      "abstract": "Solving Mixed-Integer Programming (MIP) problems often requires substantial computational resources due to their combinatorial nature. Parallelization has emerged as a critical strategy to accelerate solution times and enhance scalability to tackle large, complex instances. This paper investigates the parallelization capabilities of Balans, a recently proposed multi-armed bandits-based adaptive large neighborhood search for MIPs. While Balans's modular architecture inherently supports parallel exploration of diverse parameter configurations, this potential has not been thoroughly examined. To address this gap, we introduce ParBalans, an extension that leverages both solver-level and algorithmic-level parallelism to improve performance on challenging MIP instances. Our experimental results demonstrate that ParBalans exhibits competitive performance compared to the state-of-the-art commercial solver Gurobi, particularly on hard optimization benchmarks.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Mixed-Integer Programming (MIP) é—®é¢˜çš„è®¡ç®—æŒ‘æˆ˜ï¼Œæå‡ºäº†åŸºäºå¹¶è¡Œå¤šè‡‚è€è™æœº (Multi-Armed Bandits) çš„è‡ªé€‚åº”å¤§é‚»åŸŸæœç´¢ç®—æ³•æ‰©å±•ç‰ˆæœ¬ ParBalansã€‚ParBalans æ—¨åœ¨è¿›ä¸€æ­¥æŒ–æ˜ Balans ç®—æ³•åœ¨å¹¶è¡Œé…ç½®æ¢ç´¢æ–¹é¢çš„æ½œåŠ›ï¼Œé€šè¿‡ç»“åˆæ±‚è§£å™¨çº§åˆ« (solver-level) å’Œç®—æ³•çº§åˆ« (algorithmic-level) çš„å¹¶è¡ŒåŒ–ç­–ç•¥æ¥æ˜¾è‘—æå‡å¤æ‚å®ä¾‹çš„æ±‚è§£æ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒParBalans åœ¨å¤„ç†é«˜éš¾åº¦ä¼˜åŒ–åŸºå‡†æµ‹è¯•æ—¶å±•ç°å‡ºäº†ä¸é¡¶å°–å•†ä¸šæ±‚è§£å™¨ Gurobi ç›¸å½“çš„ç«äº‰åŠ›ã€‚è¯¥ç ”ç©¶ä¸ä»…è¯æ˜äº†å¹¶è¡ŒåŒ–åœ¨åŠ é€Ÿå¤§è§„æ¨¡ç»„åˆä¼˜åŒ–é—®é¢˜ä¸­çš„å…³é”®ä½œç”¨ï¼Œä¹Ÿä¸ºåŸºäº Adaptive Large Neighborhood Search çš„ç®—æ³•åœ¨å¹¶è¡Œç¯å¢ƒä¸‹çš„æ‰©å±•æ€§æä¾›äº†é‡è¦è§è§£ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06736v1",
      "published_date": "2025-08-08 22:30:19 UTC",
      "updated_date": "2025-08-08 22:30:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:06:06.993465+00:00"
    },
    {
      "arxiv_id": "2508.06729v1",
      "title": "Large Language Models for Oral History Understanding with Text Classification and Sentiment Analysis",
      "title_zh": "åŸºäºæ–‡æœ¬åˆ†ç±»ä¸æƒ…æ„Ÿåˆ†æçš„å¤§è¯­è¨€æ¨¡å‹å£è¿°å†å²ç†è§£",
      "authors": [
        "Komala Subramanyam Cherukuri",
        "Pranav Abishai Moses",
        "Aisa Sakata",
        "Jiangping Chen",
        "Haihua Chen"
      ],
      "abstract": "Oral histories are vital records of lived experience, particularly within communities affected by systemic injustice and historical erasure. Effective and efficient analysis of their oral history archives can promote access and understanding of the oral histories. However, Large-scale analysis of these archives remains limited due to their unstructured format, emotional complexity, and high annotation costs. This paper presents a scalable framework to automate semantic and sentiment annotation for Japanese American Incarceration Oral History. Using LLMs, we construct a high-quality dataset, evaluate multiple models, and test prompt engineering strategies in historically sensitive contexts. Our multiphase approach combines expert annotation, prompt design, and LLM evaluation with ChatGPT, Llama, and Qwen. We labeled 558 sentences from 15 narrators for sentiment and semantic classification, then evaluated zero-shot, few-shot, and RAG strategies. For semantic classification, ChatGPT achieved the highest F1 score (88.71%), followed by Llama (84.99%) and Qwen (83.72%). For sentiment analysis, Llama slightly outperformed Qwen (82.66%) and ChatGPT (82.29%), with all models showing comparable results. The best prompt configurations were used to annotate 92,191 sentences from 1,002 interviews in the JAIOH collection. Our findings show that LLMs can effectively perform semantic and sentiment annotation across large oral history collections when guided by well-designed prompts. This study provides a reusable annotation pipeline and practical guidance for applying LLMs in culturally sensitive archival analysis. By bridging archival ethics with scalable NLP techniques, this work lays the groundwork for responsible use of artificial intelligence in digital humanities and preservation of collective memory. GitHub: https://github.com/kc6699c/LLM4OralHistoryAnalysis.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªå¯æ‰©å±•çš„æ¡†æ¶ï¼Œåˆ©ç”¨ Large Language Models (LLMs) å¯¹æ—¥è£”ç¾å›½äººç›‘ç¦å£è¿°å†å² (Japanese American Incarceration Oral History, JAIOH) è¿›è¡Œè‡ªåŠ¨åŒ–çš„è¯­ä¹‰åˆ†ç±» (Semantic Classification) å’Œæƒ…æ„Ÿåˆ†æ (Sentiment Analysis)ã€‚ç ”ç©¶äººå‘˜ç»“åˆä¸“å®¶æ ‡æ³¨ã€æç¤ºè¯å·¥ç¨‹ (Prompt Engineering) å’Œæ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG) æŠ€æœ¯ï¼Œå¯¹æ¯”äº† ChatGPTã€Llama å’Œ Qwen åœ¨ Zero-shot å’Œ Few-shot åœºæ™¯ä¸‹çš„è¡¨ç°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒChatGPT åœ¨è¯­ä¹‰åˆ†ç±»ä»»åŠ¡ä¸­å–å¾—äº†æœ€é«˜çš„ F1 Score (88.71%)ï¼Œè€Œåœ¨æƒ…æ„Ÿåˆ†æä»»åŠ¡ä¸­ Llamaã€Qwen å’Œ ChatGPT çš„è¡¨ç°ç›¸è¿‘ï¼ŒF1 Score å‡åœ¨ 82% å·¦å³ã€‚è¯¥ç ”ç©¶è¿›ä¸€æ­¥åˆ©ç”¨æœ€ä½³æç¤ºè¯é…ç½®å¯¹ JAIOH é¦†è—ä¸­ 1,002 ä»½è®¿è°ˆçš„ 92,191 ä¸ªå¥å­è¿›è¡Œäº†å¤§è§„æ¨¡è‡ªåŠ¨æ ‡æ³¨ã€‚ç ”ç©¶ç»“æœè¯æ˜ï¼Œåœ¨ç²¾å¿ƒè®¾è®¡çš„æç¤ºè¯å¼•å¯¼ä¸‹ï¼ŒLLMs èƒ½å¤Ÿé«˜æ•ˆå¤„ç†å…·æœ‰æ–‡åŒ–æ•æ„Ÿæ€§ä¸”æ ¼å¼éç»“æ„åŒ–çš„æ¡£æ¡ˆæ•°æ®ã€‚æ­¤é¡¹å·¥ä½œä¸ä»…æä¾›äº†ä¸€å¥—å¯å¤ç”¨çš„æ ‡æ³¨æµæ°´çº¿ï¼Œè¿˜ä¸ºæ•°å­—äººæ–‡ (Digital Humanities) é¢†åŸŸåœ¨ä¿æŠ¤é›†ä½“è®°å¿†å’Œè´Ÿè´£ä»»åœ°ä½¿ç”¨äººå·¥æ™ºèƒ½æ–¹é¢å¥ å®šäº†æŠ€æœ¯åŸºç¡€ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06729v1",
      "published_date": "2025-08-08 22:06:23 UTC",
      "updated_date": "2025-08-08 22:06:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:06:12.150185+00:00"
    },
    {
      "arxiv_id": "2508.06716v1",
      "title": "GLIDR: Graph-Like Inductive Logic Programming with Differentiable Reasoning",
      "title_zh": "GLIDRï¼šåŸºäºå¯å¾®æ¨ç†çš„å›¾çŠ¶å½’çº³é€»è¾‘ç¨‹åºè®¾è®¡",
      "authors": [
        "Blair Johnson",
        "Clayton Kerce",
        "Faramarz Fekri"
      ],
      "abstract": "Differentiable inductive logic programming (ILP) techniques have proven effective at finding approximate rule-based solutions to link prediction and node classification problems on knowledge graphs; however, the common assumption of chain-like rule structure can hamper the performance and interpretability of existing approaches. We introduce GLIDR, a differentiable rule learning method that models the inference of logic rules with more expressive syntax than previous methods. GLIDR uses a differentiable message passing inference algorithm that generalizes previous chain-like rule learning methods to allow rules with features like branches and cycles. GLIDR has a simple and expressive rule search space which is parameterized by a limit on the maximum number of free variables that may be included in a rule. Explicit logic rules can be extracted from the weights of a GLIDR model for use with symbolic solvers. We demonstrate that GLIDR can significantly outperform existing rule learning methods on knowledge graph completion tasks and even compete with embedding methods despite the inherent disadvantage of being a structure-only prediction method. We show that rules extracted from GLIDR retain significant predictive performance, and that GLIDR is highly robust to training data noise. Finally, we demonstrate that GLIDR can be chained with deep neural networks and optimized end-to-end for rule learning on arbitrary data modalities.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†GLIDRï¼Œä¸€ç§å…·å¤‡å¯å¾®åˆ†æ¨ç†èƒ½åŠ›ä¸”æ”¯æŒç±»å›¾(Graph-Like)ç»“æ„çš„å½’çº³é€»è¾‘ç¨‹åºè®¾è®¡(Inductive Logic Programming)æ–¹æ³•ã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•æ™®éé‡‡ç”¨é“¾å¼è§„åˆ™ç»“æ„è€Œå¯¼è‡´è¡¨è¾¾åŠ›å’Œè§£é‡Šæ€§å—é™çš„é—®é¢˜ï¼ŒGLIDRå¼•å…¥äº†ä¸€ç§å¯å¾®åˆ†çš„æ¶ˆæ¯ä¼ é€’(Message Passing)æ¨ç†ç®—æ³•ï¼Œå…è®¸æ¨¡å‹å­¦ä¹ åŒ…å«åˆ†æ”¯å’Œç¯è·¯ç­‰å¤æ‚ç‰¹å¾çš„é€»è¾‘è§„åˆ™ã€‚è¯¥æ–¹æ³•çš„æœç´¢ç©ºé—´ç”±è§„åˆ™ä¸­å…è®¸çš„æœ€å¤§è‡ªç”±å˜é‡æ•°è¿›è¡Œå‚æ•°åŒ–ï¼Œå¹¶æ”¯æŒä»è®­ç»ƒæƒé‡ä¸­æå–æ˜¾å¼é€»è¾‘è§„åˆ™ä»¥ä¾›ç¬¦å·æ±‚è§£å™¨ä½¿ç”¨ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒGLIDRåœ¨çŸ¥è¯†å›¾è°±è¡¥å…¨(Knowledge Graph Completion)ä»»åŠ¡ä¸­æ˜¾è‘—ä¼˜äºç°æœ‰è§„åˆ™å­¦ä¹ æ–¹æ³•ï¼Œç”šè‡³åœ¨ä»…ä¾èµ–ç»“æ„é¢„æµ‹çš„æƒ…å†µä¸‹èƒ½ä¸åµŒå…¥(Embedding)æ–¹æ³•ç›¸åª²ç¾ã€‚æ­¤å¤–ï¼ŒGLIDRå¯¹è®­ç»ƒæ•°æ®å™ªå£°å…·æœ‰é«˜åº¦é²æ£’æ€§ï¼Œä¸”èƒ½ä¸æ·±åº¦ç¥ç»ç½‘ç»œè¿›è¡Œç«¯åˆ°ç«¯ä¼˜åŒ–ï¼Œä»è€Œåœ¨ä»»æ„æ•°æ®æ¨¡æ€ä¸Šå®ç°é«˜æ•ˆçš„è§„åˆ™å­¦ä¹ ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06716v1",
      "published_date": "2025-08-08 21:31:55 UTC",
      "updated_date": "2025-08-08 21:31:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:06:12.345908+00:00"
    },
    {
      "arxiv_id": "2508.06709v1",
      "title": "Play Favorites: A Statistical Method to Measure Self-Bias in LLM-as-a-Judge",
      "title_zh": "æœ‰æ‰€åçˆ±ï¼šä¸€ç§è¡¡é‡ LLM-as-a-Judge ä¸­è‡ªåè§çš„ç»Ÿè®¡æ–¹æ³•",
      "authors": [
        "Evangelia Spiliopoulou",
        "Riccardo Fogliato",
        "Hanna Burnsky",
        "Tamer Soliman",
        "Jie Ma",
        "Graham Horwood",
        "Miguel Ballesteros"
      ],
      "abstract": "Large language models (LLMs) can serve as judges that offer rapid and reliable assessments of other LLM outputs. However, models may systematically assign overly favorable ratings to their own outputs, a phenomenon known as self-bias, which can distort evaluations of true model performance. Previous studies often conflate genuine differences in model quality with bias or incorrectly assume that evaluations from LLMs and humans follow the same rating distributions. In this work, we present a statistical framework that explicitly formalizes assumptions under which self-bias can be identified and estimated. Our method models the difference in the scoring distribution that LLM-as-a-judge assigns to its own completions compared to other models, while accounting for the underlying quality of the completions provided by an independent, third-party judge (e.g., humans). Our method reliably isolates and quantifies self-bias, even when models vary in ability, ensuring that genuine performance differences are not mistaken for self-bias. We conduct an empirical analysis of self-bias on a large dataset (>5000 prompt-completion pairs) consisting of expert human annotations and judgments from nine different LLM judges. We find that some models, such as GPT-4o and Claude 3.5 Sonnet, systematically assign higher scores to their own outputs. These models also display family-bias; systematically assigning higher ratings to outputs produced by other models of the same family. Our findings highlight potential pitfalls of using LLM judges and offer practical guidance to mitigate biases when interpreting automated evaluations.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº† LLM-as-a-Judge åœ¨è¯„ä¼°è¿‡ç¨‹ä¸­å­˜åœ¨çš„è‡ªæˆ‘åå·®(Self-Bias)é—®é¢˜ï¼Œå³å¤§è¯­è¨€æ¨¡å‹å¾€å¾€ä¼šå¯¹è‡ªå·±ç”Ÿæˆçš„è¾“å‡ºç»™å‡ºè¿‡é«˜çš„è¯„åˆ†ï¼Œä»è€Œå¯¼è‡´æ¨¡å‹æ€§èƒ½è¯„ä¼°çš„å¤±çœŸã€‚ä½œè€…æå‡ºäº†ä¸€ä¸ªç»Ÿè®¡æ¡†æ¶ï¼Œé€šè¿‡å»ºæ¨¡ LLM è¯„å§”å¯¹è‡ªå·±åŠå…¶ä»–æ¨¡å‹ç”Ÿæˆå†…å®¹çš„è¯„åˆ†åˆ†å¸ƒå·®å¼‚ï¼Œå¹¶ç»“åˆç¬¬ä¸‰æ–¹ç‹¬ç«‹è¯„å§”æä¾›çš„åŸºå‡†è´¨é‡ï¼Œå®ç°äº†å¯¹è‡ªæˆ‘åå·®çš„ç²¾ç¡®éš”ç¦»ä¸é‡åŒ–ã€‚ç ”ç©¶å›¢é˜Ÿåˆ©ç”¨åŒ…å« 5000 å¤šä¸ªæç¤º-è¡¥å…¨å¯¹åŠ 9 ç§ä¸åŒ LLM è¯„å§”çš„å¤§å‹æ•°æ®é›†è¿›è¡Œäº†å®è¯åˆ†æã€‚å®éªŒå‘ç°ï¼ŒGPT-4o å’Œ Claude 3.5 Sonnet ç­‰æ¨¡å‹å­˜åœ¨ç³»ç»Ÿæ€§çš„è‡ªæˆ‘åå·®ï¼Œå¹¶ä¸”è¿˜è¡¨ç°å‡ºåè¢’åŒç³»åˆ—æ¨¡å‹çš„å®¶åº­åå·®(Family-Bias)ã€‚è¯¥ç ”ç©¶æ­ç¤ºäº†è‡ªåŠ¨åŒ–è¯„ä¼°ä¸­çš„æ½œåœ¨é£é™©ï¼Œå¹¶ä¸ºå‡å°è¯„ä¼°åè§ã€æå‡è¯„ä¼°ç»“æœçš„å¯é æ€§æä¾›äº†å®é™…çš„ç†è®ºæŒ‡å¯¼ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06709v1",
      "published_date": "2025-08-08 21:22:12 UTC",
      "updated_date": "2025-08-08 21:22:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:06:20.151957+00:00"
    },
    {
      "arxiv_id": "2508.06706v1",
      "title": "Probabilistic Circuits for Knowledge Graph Completion with Reduced Rule Sets",
      "title_zh": "åŸºäºç¼©å‡è§„åˆ™é›†çš„çŸ¥è¯†å›¾è°±è¡¥å…¨æ¦‚ç‡ç”µè·¯",
      "authors": [
        "Jaikrishna Manojkumar Patil",
        "Nathaniel Lee",
        "Al Mehdi Saadat Chowdhury",
        "YooJung Choi",
        "Paulo Shakarian"
      ],
      "abstract": "Rule-based methods for knowledge graph completion provide explainable results but often require a significantly large number of rules to achieve competitive performance. This can hinder explainability due to overwhelmingly large rule sets. We discover rule contexts (meaningful subsets of rules that work together) from training data and use learned probability distribution (i.e. probabilistic circuits) over these rule contexts to more rapidly achieve performance of the full rule set. Our approach achieves a 70-96% reduction in number of rules used while outperforming baseline by up to 31$\\times$ when using equivalent minimal number of rules and preserves 91% of peak baseline performance even when comparing our minimal rule sets against baseline's full rule sets. We show that our framework is grounded in well-known semantics of probabilistic logic, does not require independence assumptions, and that our tractable inference procedure provides both approximate lower bounds and exact probability of a given query. The efficacy of our method is validated by empirical studies on 8 standard benchmark datasets where we show competitive performance by using only a fraction of the rules required by AnyBURL's standard inference method, the current state-of-the-art for rule-based knowledge graph completion. This work may have further implications for general probabilistic reasoning over learned sets of rules.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Rule-based methods åœ¨ Knowledge Graph Completion ä»»åŠ¡ä¸­å› è§„åˆ™é›†è¿‡äºåºå¤§è€ŒæŸå®³å¯è§£é‡Šæ€§çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åˆ©ç”¨ Probabilistic Circuits ä¼˜åŒ–è§„åˆ™é›†çš„æ–°æ–¹æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡ä»è®­ç»ƒæ•°æ®ä¸­å‘ç° Rule contextsï¼ˆå³ååŒå·¥ä½œçš„è§„åˆ™å­é›†ï¼‰ï¼Œå¹¶å­¦ä¹ è¿™äº›ä¸Šä¸‹æ–‡çš„æ¦‚ç‡åˆ†å¸ƒï¼Œä»è€Œå®ç°å¯¹å®Œæ•´è§„åˆ™é›†æ€§èƒ½çš„å¿«é€Ÿé€¼è¿‘ã€‚è¯¥æ¡†æ¶ç«‹è¶³äº Probabilistic logic è¯­ä¹‰ï¼Œæ— éœ€ç‹¬ç«‹æ€§å‡è®¾ï¼Œå…¶ Tractable inference è¿‡ç¨‹èƒ½å¤Ÿæä¾›ç»™å®šæŸ¥è¯¢çš„è¿‘ä¼¼ä¸‹ç•Œå’Œç²¾ç¡®æ¦‚ç‡ã€‚åœ¨ 8 ä¸ªæ ‡å‡†åŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨ä¿æŒç«äº‰åŠ›çš„åŒæ—¶ï¼ŒæˆåŠŸå°†ä½¿ç”¨çš„è§„åˆ™æ•°é‡å‡å°‘äº† 70-96%ã€‚ä¸å½“å‰æœ€å…ˆè¿›çš„ AnyBURL ç›¸æ¯”ï¼Œåœ¨åŒç­‰æœ€ç®€è§„åˆ™é›†ä¸‹æ€§èƒ½æå‡è¾¾ 31 å€ï¼Œä¸”å³ä¾¿ä½¿ç”¨æç®€è§„åˆ™é›†ï¼Œä»èƒ½ä¿ç•™åŸºçº¿æ¨¡å‹ 91% çš„å³°å€¼æ€§èƒ½ã€‚è¿™é¡¹å·¥ä½œä¸ºåœ¨å­¦ä¹ åˆ°çš„è§„åˆ™é›†ä¸Šè¿›è¡Œé€šç”¨æ¦‚ç‡æ¨ç†æä¾›äº†æ–°çš„æ€è·¯ï¼Œå¹¶æœ‰æ•ˆæå‡äº†çŸ¥è¯†å›¾è°±è¡¥å…¨ä»»åŠ¡çš„å¯è§£é‡Šæ€§ã€‚",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06706v1",
      "published_date": "2025-08-08 21:17:03 UTC",
      "updated_date": "2025-08-08 21:17:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:06:32.126916+00:00"
    },
    {
      "arxiv_id": "2508.06701v1",
      "title": "MMFformer: Multimodal Fusion Transformer Network for Depression Detection",
      "title_zh": "MMFformerï¼šé¢å‘æŠ‘éƒç—‡æ£€æµ‹çš„å¤šæ¨¡æ€èåˆ Transformer ç½‘ç»œ",
      "authors": [
        "Md Rezwanul Haque",
        "Md. Milon Islam",
        "S M Taslim Uddin Raju",
        "Hamdi Altaheri",
        "Lobna Nassar",
        "Fakhri Karray"
      ],
      "abstract": "Depression is a serious mental health illness that significantly affects an individual's well-being and quality of life, making early detection crucial for adequate care and treatment. Detecting depression is often difficult, as it is based primarily on subjective evaluations during clinical interviews. Hence, the early diagnosis of depression, thanks to the content of social networks, has become a prominent research area. The extensive and diverse nature of user-generated information poses a significant challenge, limiting the accurate extraction of relevant temporal information and the effective fusion of data across multiple modalities. This paper introduces MMFformer, a multimodal depression detection network designed to retrieve depressive spatio-temporal high-level patterns from multimodal social media information. The transformer network with residual connections captures spatial features from videos, and a transformer encoder is exploited to design important temporal dynamics in audio. Moreover, the fusion architecture fused the extracted features through late and intermediate fusion strategies to find out the most relevant intermodal correlations among them. Finally, the proposed network is assessed on two large-scale depression detection datasets, and the results clearly reveal that it surpasses existing state-of-the-art approaches, improving the F1-Score by 13.92% for D-Vlog dataset and 7.74% for LMVD dataset. The code is made available publicly at https://github.com/rezwanh001/Large-Scale-Multimodal-Depression-Detection.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† MMFformerï¼Œä¸€ç§ä¸“é—¨ç”¨äºæŠ‘éƒç—‡æ£€æµ‹çš„å¤šæ¨¡æ€èåˆ Transformer ç½‘ç»œï¼Œæ—¨åœ¨ä»ç¤¾äº¤åª’ä½“çš„å¤šæ¨¡æ€ä¿¡æ¯ä¸­æå–å…³é”®çš„æ—¶ç©ºé«˜å±‚æ¨¡å¼ã€‚è¯¥æ¡†æ¶åˆ©ç”¨å¸¦æœ‰æ®‹å·®è¿æ¥çš„ Transformer ç½‘ç»œæ•æ‰è§†é¢‘çš„ç©ºé—´ç‰¹å¾ï¼Œå¹¶ç»“åˆ Transformer ç¼–ç å™¨è®¾è®¡éŸ³é¢‘ä¸­çš„é‡è¦æ—¶é—´åŠ¨æ€ã€‚åœ¨èåˆæ¶æ„æ–¹é¢ï¼ŒMMFformer é‡‡ç”¨äº†åæœŸèåˆ (late fusion) å’Œä¸­é—´èåˆ (intermediate fusion) ç­–ç•¥ï¼Œä»è€Œæœ‰æ•ˆåœ°è¯†åˆ«æ¨¡æ€é—´çš„ç›¸å…³æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨ä¸¤ä¸ªå¤§è§„æ¨¡æŠ‘éƒç—‡æ£€æµ‹æ•°æ®é›† D-Vlog å’Œ LMVD ä¸Šå‡è¶…è¶Šäº†ç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³• (state-of-the-art)ï¼ŒF1-Score åˆ†åˆ«æé«˜äº† 13.92% å’Œ 7.74%ï¼Œä¸ºåˆ©ç”¨ç¤¾äº¤ç½‘ç»œå†…å®¹è¿›è¡Œå¿ƒç†å¥åº·æ—©æœŸè¯Šæ–­æä¾›äº†å¼ºæœ‰åŠ›çš„æŠ€æœ¯æ”¯æŒã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted for the 2025 IEEE International Conference on Systems, Man, and Cybernetics (SMC), Vienna, Austria",
      "pdf_url": "https://arxiv.org/pdf/2508.06701v1",
      "published_date": "2025-08-08 21:03:29 UTC",
      "updated_date": "2025-08-08 21:03:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:06:54.747493+00:00"
    },
    {
      "arxiv_id": "2508.09202v2",
      "title": "Personalized Feature Translation for Expression Recognition: An Efficient Source-Free Domain Adaptation Method",
      "title_zh": "é¢å‘è¡¨æƒ…è¯†åˆ«çš„ä¸ªæ€§åŒ–ç‰¹å¾è½¬æ¢ï¼šä¸€ç§é«˜æ•ˆçš„æ— æºåŸŸè‡ªé€‚åº”æ–¹æ³•",
      "authors": [
        "Masoumeh Sharafi",
        "Soufiane Belharbi",
        "Houssem Ben Salem",
        "Ali Etemad",
        "Alessandro Lameiras Koerich",
        "Marco Pedersoli",
        "Simon Bacon",
        "Eric Granger"
      ],
      "abstract": "Facial expression recognition (FER) models are employed in many video-based affective computing applications, such as human-computer interaction and healthcare monitoring. However, deep FER models often struggle with subtle expressions and high inter-subject variability, limiting their performance in real-world applications. To improve their performance, source-free domain adaptation (SFDA) methods have been proposed to personalize a pretrained source model using only unlabeled target domain data, thereby avoiding data privacy, storage, and transmission constraints. This paper addresses a challenging scenario where source data is unavailable for adaptation, and only unlabeled target data consisting solely of neutral expressions is available. SFDA methods are not typically designed to adapt using target data from only a single class. Further, using models to generate facial images with non-neutral expressions can be unstable and computationally intensive. In this paper, personalized feature translation (PFT) is proposed for SFDA. Unlike current image translation methods for SFDA, our lightweight method operates in the latent space. We first pre-train the translator on the source domain data to transform the subject-specific style features from one source subject into another. Expression information is preserved by optimizing a combination of expression consistency and style-aware objectives. Then, the translator is adapted on neutral target data, without using source data or image synthesis. By translating in the latent space, PFT avoids the complexity and noise of face expression generation, producing discriminative embeddings optimized for classification. Using PFT eliminates the need for image synthesis, reduces computational overhead (using a lightweight translator), and only adapts part of the model, making the method efficient compared to image-based translation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸ªæ€§åŒ–ç‰¹å¾è½¬æ¢(PFT)ï¼Œè¿™æ˜¯ä¸€ç§é’ˆå¯¹é¢éƒ¨è¡¨æƒ…è¯†åˆ«(FER)çš„é«˜æ•ˆæ— æºé¢†åŸŸè‡ªé€‚åº”(SFDA)æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ç›®æ ‡åŸŸä»…æœ‰ä¸­æ€§è¡¨æƒ…æ•°æ®ä¸”æºæ•°æ®ä¸å¯ç”¨çš„æŒ‘æˆ˜ã€‚ä¸ä¼ ç»Ÿçš„å›¾åƒç¿»è¯‘æ–¹æ³•ä¸åŒï¼ŒPFT åœ¨æ½œç©ºé—´(latent space)å†…è¿è¡Œï¼Œé€šè¿‡é¢„è®­ç»ƒçš„è½»é‡åŒ–è½¬æ¢å™¨å°†ç‰¹å®šä¸»ä½“çš„é£æ ¼ç‰¹å¾è¿›è¡Œè½¬æ¢ï¼ŒåŒæ—¶åˆ©ç”¨è¡¨æƒ…ä¸€è‡´æ€§å’Œé£æ ¼æ„ŸçŸ¥ç›®æ ‡ç¡®ä¿è¡¨æƒ…ä¿¡æ¯çš„å®Œæ•´ä¿ç•™ã€‚åœ¨è‡ªé€‚åº”é˜¶æ®µï¼Œè¯¥æ–¹æ³•ä»…éœ€ç›®æ ‡åŸŸçš„æ— æ ‡ç­¾ä¸­æ€§æ•°æ®ï¼Œæ— éœ€è¿›è¡Œå¤æ‚çš„å›¾åƒåˆæˆæˆ–ä¾èµ–æºåŸŸæ•°æ®ã€‚è¿™ç§åœ¨æ½œç©ºé—´è¿›è¡Œçš„ç‰¹å¾è½¬æ¢é¿å…äº†é¢éƒ¨ç”Ÿæˆè¿‡ç¨‹ä¸­çš„å™ªå£°å’Œé«˜æ˜‚è®¡ç®—å¼€é”€ï¼Œä»è€Œäº§ç”Ÿæ›´å…·è¾¨åˆ«åŠ›çš„åˆ†ç±»åµŒå…¥ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒPFT ä¸ä»…æå‡äº†æ¨¡å‹å¯¹ä¸ªä½“å·®å¼‚çš„é²æ£’æ€§ï¼Œè¿˜é€šè¿‡ä»…æ›´æ–°éƒ¨åˆ†æ¨¡å‹å‚æ•°æ˜¾è‘—ä¼˜åŒ–äº†è®¡ç®—æ•ˆç‡ï¼Œä¸ºå—é™ç¯å¢ƒä¸‹çš„ä¸ªæ€§åŒ–è¡¨æƒ…è¯†åˆ«æä¾›äº†å¯è¡Œæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09202v2",
      "published_date": "2025-08-08 20:13:50 UTC",
      "updated_date": "2025-08-14 14:05:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:06:55.187634+00:00"
    },
    {
      "arxiv_id": "2508.06674v1",
      "title": "Zero-Shot Cellular Trajectory Map Matching",
      "title_zh": "é›¶æ ·æœ¬èœ‚çªè½¨è¿¹åœ°å›¾åŒ¹é…",
      "authors": [
        "Weijie Shi",
        "Yue Cui",
        "Hao Chen",
        "Jiaming Li",
        "Mengze Li",
        "Jia Zhu",
        "Jiajie Xu",
        "Xiaofang Zhou"
      ],
      "abstract": "Cellular Trajectory Map-Matching (CTMM) aims to align cellular location sequences to road networks, which is a necessary preprocessing in location-based services on web platforms like Google Maps, including navigation and route optimization. Current approaches mainly rely on ID-based features and region-specific data to learn correlations between cell towers and roads, limiting their adaptability to unexplored areas. To enable high-accuracy CTMM without additional training in target regions, Zero-shot CTMM requires to extract not only region-adaptive features, but also sequential and location uncertainty to alleviate positioning errors in cellular data. In this paper, we propose a pixel-based trajectory calibration assistant for zero-shot CTMM, which takes advantage of transferable geospatial knowledge to calibrate pixelated trajectory, and then guide the path-finding process at the road network level. To enhance knowledge sharing across similar regions, a Gaussian mixture model is incorporated into VAE, enabling the identification of scenario-adaptive experts through soft clustering. To mitigate high positioning errors, a spatial-temporal awareness module is designed to capture sequential features and location uncertainty, thereby facilitating the inference of approximate user positions. Finally, a constrained path-finding algorithm is employed to reconstruct the road ID sequence, ensuring topological validity within the road network. This process is guided by the calibrated trajectory while optimizing for the shortest feasible path, thus minimizing unnecessary detours. Extensive experiments demonstrate that our model outperforms existing methods in zero-shot CTMM by 16.8\\%.",
      "tldr_zh": "è¯¥è®ºæ–‡æ¢è®¨äº†é›¶æ ·æœ¬ç»†èƒè½¨è¿¹åœ°å›¾åŒ¹é… (Zero-shot Cellular Trajectory Map-Matching, CTMM) é—®é¢˜ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ–¹æ³•è¿‡åº¦ä¾èµ–åŒºåŸŸç‰¹å®šæ•°æ®ä»¥åŠå®šä½è¯¯å·®è¾ƒå¤§çš„æŒ‘æˆ˜ã€‚ä½œè€…æå‡ºäº†ä¸€ç§åŸºäºåƒç´ çš„è½¨è¿¹æ ¡å‡†è¾…åŠ©æ–¹æ¡ˆï¼Œé€šè¿‡åˆ©ç”¨å¯è¿ç§»çš„åœ°ç†ç©ºé—´çŸ¥è¯†æ ¡å‡†åƒç´ åŒ–è½¨è¿¹ï¼Œå¹¶å¼•å¯¼è·¯ç½‘å±‚é¢çš„è·¯å¾„æœç´¢ã€‚ç ”ç©¶åœ¨ VAE ä¸­èå…¥äº†é«˜æ–¯æ··åˆæ¨¡å‹ (Gaussian mixture model)ï¼Œé€šè¿‡è½¯èšç±»è¯†åˆ«åœºæ™¯è‡ªé€‚åº”ä¸“å®¶ï¼Œä»è€Œå¢å¼ºç›¸ä¼¼åŒºåŸŸé—´çš„çŸ¥è¯†å…±äº«ä¸æ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œè®¾è®¡äº†æ—¶ç©ºæ„ŸçŸ¥æ¨¡å—ä»¥æ•æ‰åºåˆ—ç‰¹å¾å’Œä½ç½®ä¸ç¡®å®šæ€§ (location uncertainty)ï¼Œæœ‰æ•ˆæ¨æ–­è¿‘ä¼¼ç”¨æˆ·ä½ç½®ã€‚æœ€åï¼Œåˆ©ç”¨çº¦æŸè·¯å¾„æœç´¢ç®—æ³•é‡å»ºè·¯ç½‘ ID åºåˆ—ï¼Œåœ¨æ ¡å‡†è½¨è¿¹æŒ‡å¯¼ä¸‹ä¼˜åŒ–æœ€çŸ­å¯è¡Œè·¯å¾„å¹¶ç¡®ä¿æ‹“æ‰‘æœ‰æ•ˆæ€§ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ¨¡å‹åœ¨é›¶æ ·æœ¬ CTMM ä»»åŠ¡ä¸­æ¯”ç°æœ‰æ–¹æ³•æ€§èƒ½æå‡äº† 16.8%ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06674v1",
      "published_date": "2025-08-08 19:47:45 UTC",
      "updated_date": "2025-08-08 19:47:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:06:53.540749+00:00"
    },
    {
      "arxiv_id": "2508.06671v2",
      "title": "Do Biased Models Have Biased Thoughts?",
      "title_zh": "åè§æ¨¡å‹æ˜¯å¦å…·æœ‰åè§æ€ç»´ï¼Ÿ",
      "authors": [
        "Swati Rajwal",
        "Shivank Garg",
        "Reem Abdel-Salam",
        "Abdelrahman Zayed"
      ],
      "abstract": "The impressive performance of language models is undeniable. However, the presence of biases based on gender, race, socio-economic status, physical appearance, and sexual orientation makes the deployment of language models challenging. This paper studies the effect of chain-of-thought prompting, a recent approach that studies the steps followed by the model before it responds, on fairness. More specifically, we ask the following question: $\\textit{Do biased models have biased thoughts}$? To answer our question, we conduct experiments on $5$ popular large language models using fairness metrics to quantify $11$ different biases in the model's thoughts and output. Our results show that the bias in the thinking steps is not highly correlated with the output bias (less than $0.6$ correlation with a $p$-value smaller than $0.001$ in most cases). In other words, unlike human beings, the tested models with biased decisions do not always possess biased thoughts.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)ä¸­å­˜åœ¨çš„æ€§åˆ«ã€ç§æ—ã€ç¤¾ä¼šç»æµåœ°ä½ç­‰åè§é—®é¢˜ï¼Œå¹¶é‡ç‚¹ç ”ç©¶äº†é“¾å¼æ€ç»´(Chain-of-Thought)æç¤ºè¯æŠ€æœ¯å¯¹æ¨¡å‹å…¬å¹³æ€§çš„å½±å“ã€‚è®ºæ–‡æå‡ºäº†æ ¸å¿ƒé—®é¢˜â€œåè§æ¨¡å‹æ˜¯å¦å…·æœ‰åè§çš„æ€ç»´ï¼Ÿâ€ï¼Œå¹¶åœ¨5ç§ä¸»æµå¤§è¯­è¨€æ¨¡å‹ä¸Šé’ˆå¯¹11ç§ä¸åŒçš„åè§ç±»å‹è¿›è¡Œäº†å®šé‡å®éªŒã€‚é€šè¿‡åˆ†ææ¨¡å‹æ¨ç†æ­¥éª¤(Thoughts)ä¸æœ€ç»ˆè¾“å‡º(Output)ä¸­çš„åè§æŒ‡æ ‡ï¼Œç ”ç©¶å‘ç°ä¸¤è€…ä¹‹é—´çš„åè§ç›¸å…³æ€§è¾ƒä½ï¼Œå¤šæ•°æƒ…å†µä¸‹ç›¸å…³ç³»æ•°å°äº0.6ä¸”æ˜¾è‘—æ€§æ°´å¹³på€¼å°äº0.001ã€‚è¿™æ„å‘³ç€ä¸äººç±»çš„é€»è¾‘ä¸€è‡´æ€§ä¸åŒï¼Œåšå‡ºåè§å†³ç­–çš„æ¨¡å‹å¹¶ä¸æ€»æ˜¯è¡¨ç°å‡ºåè§çš„æ€ç»´è¿‡ç¨‹ã€‚è¯¥ç ”ç©¶æ­ç¤ºäº†æ¨¡å‹å†…éƒ¨é€»è¾‘é“¾æ¡ä¸æœ€ç»ˆå†³ç­–ç»“æœåœ¨å…¬å¹³æ€§è¡¨ç°ä¸Šçš„è„±èŠ‚ï¼Œä¸ºæ·±å…¥ç†è§£å’Œè¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹çš„å†…åœ¨åè§æœºåˆ¶æä¾›äº†é‡è¦çš„å®è¯ä¾æ®ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at main track of the Second Conference on Language Modeling (COLM 2025)",
      "pdf_url": "https://arxiv.org/pdf/2508.06671v2",
      "published_date": "2025-08-08 19:41:20 UTC",
      "updated_date": "2025-08-12 02:42:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:06:53.347301+00:00"
    },
    {
      "arxiv_id": "2508.06668v1",
      "title": "Formal Concept Analysis: a Structural Framework for Variability Extraction and Analysis",
      "title_zh": "å½¢å¼æ¦‚å¿µåˆ†æï¼šä¸€ç§ç”¨äºå¯å˜æ€§æå–ä¸åˆ†æçš„ç»“æ„åŒ–æ¡†æ¶",
      "authors": [
        "Jessie Galasso"
      ],
      "abstract": "Formal Concept Analysis (FCA) is a mathematical framework for knowledge representation and discovery. It performs a hierarchical clustering over a set of objects described by attributes, resulting in conceptual structures in which objects are organized depending on the attributes they share. These conceptual structures naturally highlight commonalities and variabilities among similar objects by categorizing them into groups which are then arranged by similarity, making it particularly appropriate for variability extraction and analysis. Despite the potential of FCA, determining which of its properties can be leveraged for variability-related tasks (and how) is not always straightforward, partly due to the mathematical orientation of its foundational literature. This paper attempts to bridge part of this gap by gathering a selection of properties of the framework which are essential to variability analysis, and how they can be used to interpret diverse variability information within the resulting conceptual structures.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº† Formal Concept Analysis (FCA) åœ¨çŸ¥è¯†è¡¨ç¤ºå’Œå‘ç°ä¸­çš„åº”ç”¨ï¼Œå°†å…¶å®šä¹‰ä¸ºä¸€ç§é€šè¿‡å¯¹å±æ€§æè¿°çš„å¯¹è±¡è¿›è¡Œå±‚æ¬¡èšç±»æ¥æ„å»ºæ¦‚å¿µç»“æ„çš„æ•°å­¦æ¡†æ¶ã€‚è¿™äº›æ¦‚å¿µç»“æ„èƒ½å¤Ÿæ ¹æ®å¯¹è±¡å…±äº«çš„å±æ€§è‡ªåŠ¨å½’ç±»ï¼Œä»è€Œç›´è§‚åœ°æ­ç¤ºç›¸ä¼¼å¯¹è±¡ä¹‹é—´çš„ commonalities ä¸ variabilitiesï¼Œä½¿å…¶åœ¨ variability extraction å’Œåˆ†æé¢†åŸŸå±•ç°å‡ºç‹¬ç‰¹çš„ä¼˜åŠ¿ã€‚é’ˆå¯¹ç°æœ‰æ–‡çŒ®è¿‡äºåé‡æ•°å­¦ç†è®ºè€Œå¯¼è‡´å®é™…åº”ç”¨é—¨å‹è¾ƒé«˜çš„é—®é¢˜ï¼Œæœ¬æ–‡æ—¨åœ¨å¼¥è¡¥è¿™ä¸€çŸ¥è¯†é¸¿æ²Ÿã€‚é€šè¿‡ç³»ç»Ÿæ€§åœ°ç­›é€‰å¹¶æ±‡é›† FCA æ¡†æ¶ä¸­å¯¹ variability analysis è‡³å…³é‡è¦çš„æ ¸å¿ƒå±æ€§ï¼Œè¯¥ç ”ç©¶è¯¦ç»†é˜è¿°äº†å¦‚ä½•åˆ©ç”¨è¿™äº›å±æ€§æ¥è§£è¯»æ¦‚å¿µç»“æ„ä¸­è•´å«çš„å¤šæ ·åŒ–å˜ä½“ä¿¡æ¯ã€‚",
      "categories": [
        "cs.AI",
        "cs.IR",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06668v1",
      "published_date": "2025-08-08 19:30:14 UTC",
      "updated_date": "2025-08-08 19:30:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:06:55.545083+00:00"
    },
    {
      "arxiv_id": "2508.10925v1",
      "title": "gpt-oss-120b & gpt-oss-20b Model Card",
      "title_zh": "gpt-oss-120b ä¸ gpt-oss-20b æ¨¡å‹å¡",
      "authors": [
        "OpenAI",
        ":",
        "Sandhini Agarwal",
        "Lama Ahmad",
        "Jason Ai",
        "Sam Altman",
        "Andy Applebaum",
        "Edwin Arbus",
        "Rahul K. Arora",
        "Yu Bai",
        "Bowen Baker",
        "Haiming Bao",
        "Boaz Barak",
        "Ally Bennett",
        "Tyler Bertao",
        "Nivedita Brett",
        "Eugene Brevdo",
        "Greg Brockman",
        "Sebastien Bubeck",
        "Che Chang",
        "Kai Chen",
        "Mark Chen",
        "Enoch Cheung",
        "Aidan Clark",
        "Dan Cook",
        "Marat Dukhan",
        "Casey Dvorak",
        "Kevin Fives",
        "Vlad Fomenko",
        "Timur Garipov",
        "Kristian Georgiev",
        "Mia Glaese",
        "Tarun Gogineni",
        "Adam Goucher",
        "Lukas Gross",
        "Katia Gil Guzman",
        "John Hallman",
        "Jackie Hehir",
        "Johannes Heidecke",
        "Alec Helyar",
        "Haitang Hu",
        "Romain Huet",
        "Jacob Huh",
        "Saachi Jain",
        "Zach Johnson",
        "Chris Koch",
        "Irina Kofman",
        "Dominik Kundel",
        "Jason Kwon",
        "Volodymyr Kyrylov",
        "Elaine Ya Le",
        "Guillaume Leclerc",
        "James Park Lennon",
        "Scott Lessans",
        "Mario Lezcano-Casado",
        "Yuanzhi Li",
        "Zhuohan Li",
        "Ji Lin",
        "Jordan Liss",
        "Lily",
        "Liu",
        "Jiancheng Liu",
        "Kevin Lu",
        "Chris Lu",
        "Zoran Martinovic",
        "Lindsay McCallum",
        "Josh McGrath",
        "Scott McKinney",
        "Aidan McLaughlin",
        "Song Mei",
        "Steve Mostovoy",
        "Tong Mu",
        "Gideon Myles",
        "Alexander Neitz",
        "Alex Nichol",
        "Jakub Pachocki",
        "Alex Paino",
        "Dana Palmie",
        "Ashley Pantuliano",
        "Giambattista Parascandolo",
        "Jongsoo Park",
        "Leher Pathak",
        "Carolina Paz",
        "Ludovic Peran",
        "Dmitry Pimenov",
        "Michelle Pokrass",
        "Elizabeth Proehl",
        "Huida Qiu",
        "Gaby Raila",
        "Filippo Raso",
        "Hongyu Ren",
        "Kimmy Richardson",
        "David Robinson",
        "Bob Rotsted",
        "Hadi Salman",
        "Suvansh Sanjeev",
        "Max Schwarzer",
        "D. Sculley",
        "Harshit Sikchi",
        "Kendal Simon",
        "Karan Singhal",
        "Yang Song",
        "Dane Stuckey",
        "Zhiqing Sun",
        "Philippe Tillet",
        "Sam Toizer",
        "Foivos Tsimpourlas",
        "Nikhil Vyas",
        "Eric Wallace",
        "Xin Wang",
        "Miles Wang",
        "Olivia Watkins",
        "Kevin Weil",
        "Amy Wendling",
        "Kevin Whinnery",
        "Cedric Whitney",
        "Hannah Wong",
        "Lin Yang",
        "Yu Yang",
        "Michihiro Yasunaga",
        "Kristen Ying",
        "Wojciech Zaremba",
        "Wenting Zhan",
        "Cyril Zhang",
        "Brian Zhang",
        "Eddie Zhang",
        "Shengjia Zhao"
      ],
      "abstract": "We present gpt-oss-120b and gpt-oss-20b, two open-weight reasoning models that push the frontier of accuracy and inference cost. The models use an efficient mixture-of-expert transformer architecture and are trained using large-scale distillation and reinforcement learning. We optimize the models to have strong agentic capabilities (deep research browsing, python tool use, and support for developer-provided functions), all while using a rendered chat format that enables clear instruction following and role delineation. Both models achieve strong results on benchmarks ranging from mathematics, coding, and safety. We release the model weights, inference implementations, tool environments, and tokenizers under an Apache 2.0 license to enable broad use and further research.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† gpt-oss-120b å’Œ gpt-oss-20b ä¸¤ä¸ªå¼€æºæƒé‡çš„æ¨ç†æ¨¡å‹ï¼Œæ—¨åœ¨é€šè¿‡é«˜æ•ˆçš„ Mixture-of-Expert (MoE) Transformer æ¶æ„å¹³è¡¡æ¨¡å‹ç²¾åº¦ä¸æ¨ç†æˆæœ¬ã€‚è¿™äº›æ¨¡å‹ç»“åˆäº†å¤§è§„æ¨¡çš„ Distillation å’Œ Reinforcement Learning (RL) æŠ€æœ¯è¿›è¡Œè®­ç»ƒï¼Œå¹¶ä¸“é—¨é’ˆå¯¹ Agentic èƒ½åŠ›è¿›è¡Œäº†ä¼˜åŒ–ï¼Œæ”¯æŒæ·±åº¦ç ”ç©¶æµè§ˆã€Python å·¥å…·è°ƒç”¨åŠè‡ªå®šä¹‰å‡½æ•°ã€‚é€šè¿‡é‡‡ç”¨æ¸²æŸ“èŠå¤©æ ¼å¼ (Rendered Chat Format)ï¼Œæ¨¡å‹åœ¨æŒ‡ä»¤éµå¾ªå’Œè§’è‰²ç•Œå®šæ–¹é¢è¡¨ç°å‡ºè‰²ã€‚åœ¨æ•°å­¦ã€ç¼–ç¨‹å’Œå®‰å…¨æ€§ç­‰å¤šé¡¹åŸºå‡†æµ‹è¯•ä¸­ï¼Œä¸¤è€…å‡å–å¾—äº†å¼ºåŠ²çš„å®éªŒç»“æœã€‚ç ”ç©¶å›¢é˜Ÿå·²æŒ‰ç…§ Apache 2.0 åè®®å¼€æºäº†æ¨¡å‹æƒé‡ã€æ¨ç†å®ç°ã€å·¥å…·ç¯å¢ƒå’Œåˆ†è¯å™¨ï¼Œä¸ºå­¦æœ¯ç•Œå’Œå·¥ä¸šç•Œçš„è¿›ä¸€æ­¥ç ”ç©¶æä¾›äº†æœ‰åŠ›æ”¯æŒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.10925v1",
      "published_date": "2025-08-08 19:24:38 UTC",
      "updated_date": "2025-08-08 19:24:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:07:13.046432+00:00"
    },
    {
      "arxiv_id": "2508.06659v1",
      "title": "In-Context Reinforcement Learning via Communicative World Models",
      "title_zh": "åŸºäºäº¤æµå¼ä¸–ç•Œæ¨¡å‹çš„ä¸Šä¸‹æ–‡å¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Fernando Martinez-Lopez",
        "Tao Li",
        "Yingdong Lu",
        "Juntao Chen"
      ],
      "abstract": "Reinforcement learning (RL) agents often struggle to generalize to new tasks and contexts without updating their parameters, mainly because their learned representations and policies are overfit to the specifics of their training environments. To boost agents' in-context RL (ICRL) ability, this work formulates ICRL as a two-agent emergent communication problem and introduces CORAL (Communicative Representation for Adaptive RL), a framework that learns a transferable communicative context by decoupling latent representation learning from control. In CORAL, an Information Agent (IA) is pre-trained as a world model on a diverse distribution of tasks. Its objective is not to maximize task reward, but to build a world model and distill its understanding into concise messages. The emergent communication protocol is shaped by a novel Causal Influence Loss, which measures the effect that the message has on the next action. During deployment, the previously trained IA serves as a fixed contextualizer for a new Control Agent (CA), which learns to solve tasks by interpreting the provided communicative context. Our experiments demonstrate that this approach enables the CA to achieve significant gains in sample efficiency and successfully perform zero-shot adaptation with the help of pre-trained IA in entirely unseen sparse-reward environments, validating the efficacy of learning a transferable communicative representation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†CORALï¼ˆCommunicative Representation for Adaptive RLï¼‰æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡å°†æƒ…å¢ƒå¼ºåŒ–å­¦ä¹ ï¼ˆIn-Context Reinforcement Learning, ICRLï¼‰å»ºæ¨¡ä¸ºåŒæ™ºèƒ½ä½“çš„æ–°å…´é€šä¿¡é—®é¢˜ï¼Œæå‡æ™ºèƒ½ä½“åœ¨æœªè§ä»»åŠ¡ä¸­çš„æ³›åŒ–èƒ½åŠ›ã€‚CORALé€šè¿‡å°†æ½œåœ¨è¡¨ç¤ºå­¦ä¹ ä¸æ§åˆ¶è§£è€¦ï¼Œå¼•å…¥äº†ä¸€ä¸ªé¢„è®­ç»ƒçš„ä¿¡æ¯æ™ºèƒ½ä½“ï¼ˆInformation Agent, IAï¼‰ä½œä¸ºä¸–ç•Œæ¨¡å‹ï¼Œç”¨äºå°†ç¯å¢ƒç†è§£æç‚¼ä¸ºç®€ç»ƒçš„æ¶ˆæ¯ã€‚ä¸ºäº†ä¼˜åŒ–é€šä¿¡åè®®ï¼Œç ”ç©¶è®¾è®¡äº†ä¸€ç§æ–°å‹çš„å› æœå½±å“æŸå¤±ï¼ˆCausal Influence Lossï¼‰ï¼Œç”¨äºè¡¡é‡æ¶ˆæ¯å¯¹åç»­åŠ¨ä½œçš„å½±å“ã€‚åœ¨éƒ¨ç½²é˜¶æ®µï¼Œæ§åˆ¶æ™ºèƒ½ä½“ï¼ˆControl Agent, CAï¼‰é€šè¿‡è§£é‡ŠIAæä¾›çš„é€šä¿¡ä¸Šä¸‹æ–‡æ¥è§£å†³æ–°ä»»åŠ¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—æé«˜äº†é‡‡æ ·æ•ˆç‡ï¼Œå¹¶åœ¨å®Œå…¨æœªè§çš„ç¨€ç–å¥–åŠ±ç¯å¢ƒä¸­å®ç°äº†æˆåŠŸçš„é›¶æ ·æœ¬è‡ªé€‚åº”ï¼ˆZero-shot Adaptationï¼‰ï¼ŒéªŒè¯äº†å­¦ä¹ å¯è¿ç§»é€šä¿¡è¡¨ç¤ºçš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06659v1",
      "published_date": "2025-08-08 19:23:23 UTC",
      "updated_date": "2025-08-08 19:23:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:07:25.486004+00:00"
    },
    {
      "arxiv_id": "2508.14055v1",
      "title": "T-REX: Table -- Refute or Entail eXplainer",
      "title_zh": "T-REXï¼šè¡¨æ ¼åé©³æˆ–è•´å«è§£é‡Šå™¨",
      "authors": [
        "Tim Luka Horstmann",
        "Baptiste Geisenberger",
        "Mehwish Alam"
      ],
      "abstract": "Verifying textual claims against structured tabular data is a critical yet challenging task in Natural Language Processing with broad real-world impact. While recent advances in Large Language Models (LLMs) have enabled significant progress in table fact-checking, current solutions remain inaccessible to non-experts. We introduce T-REX (T-REX: Table -- Refute or Entail eXplainer), the first live, interactive tool for claim verification over multimodal, multilingual tables using state-of-the-art instruction-tuned reasoning LLMs. Designed for accuracy and transparency, T-REX empowers non-experts by providing access to advanced fact-checking technology. The system is openly available online.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† T-REX (Table -- Refute or Entail eXplainer)ï¼Œè¿™æ˜¯é¦–ä¸ªåˆ©ç”¨å…ˆè¿›çš„æŒ‡ä»¤å¾®è°ƒæ¨ç†å¤§è¯­è¨€æ¨¡å‹ (instruction-tuned reasoning LLMs) å¯¹å¤šæ¨¡æ€ (multimodal) å’Œå¤šè¯­è¨€ (multilingual) è¡¨æ ¼è¿›è¡Œæ–­è¨€éªŒè¯çš„å®æ—¶äº¤äº’å¼å·¥å…·ã€‚é’ˆå¯¹è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸä¸­è¡¨æ ¼äº‹å®æ ¸æŸ¥ (table fact-checking) æŠ€æœ¯å¤æ‚ä¸”éä¸“å®¶éš¾ä»¥è§¦åŠçš„ç°çŠ¶ï¼ŒT-REX æä¾›äº†ä¸€ä¸ªå…¼å…·å‡†ç¡®æ€§ä¸é€æ˜åº¦çš„è§£å†³æ–¹æ¡ˆã€‚é€šè¿‡é›†æˆæœ€å‰æ²¿çš„æ¨ç†èƒ½åŠ›ï¼Œè¯¥ç³»ç»Ÿæ˜¾è‘—é™ä½äº†éä¸“ä¸šäººå£«ä½¿ç”¨é«˜çº§äº‹å®æ ¸æŸ¥æŠ€æœ¯çš„é—¨æ§›ã€‚ç›®å‰è¯¥ç³»ç»Ÿå·²åœ¨äº’è”ç½‘ä¸Šå…¬å¼€å‘å¸ƒï¼Œä¸ºç»“æ„åŒ–æ•°æ®éªŒè¯ä»»åŠ¡æä¾›äº†ç›´è§‚ä¸”é«˜æ•ˆçš„äº¤äº’å¹³å°ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14055v1",
      "published_date": "2025-08-08 19:00:36 UTC",
      "updated_date": "2025-08-08 19:00:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:07:12.897076+00:00"
    },
    {
      "arxiv_id": "2508.10030v1",
      "title": "Inference-Aware Prompt Optimization for Aligning Black-Box Large Language Models",
      "title_zh": "é¢å‘é»‘ç›’å¤§è¯­è¨€æ¨¡å‹å¯¹é½çš„æ¨ç†æ„ŸçŸ¥æç¤ºè¯ä¼˜åŒ–",
      "authors": [
        "Saaduddin Mahmud",
        "Mason Nakamura",
        "Kyle H. Wray",
        "Shlomo Zilberstein"
      ],
      "abstract": "Prompt optimization methods have demonstrated significant effectiveness in aligning black-box large language models (LLMs). In parallel, inference scaling strategies such as Best-of-N Sampling and Majority Voting have also proven to enhance alignment and performance by trading off computation. However, existing prompt optimization approaches are inference strategy agnostic; that is, they optimize prompts without regard to the inference strategy employed during deployment. This constitutes a significant methodological gap, as our empirical and theoretical analysis reveals a strong interdependence between these two paradigms. Moreover, we find that user preferences regarding trade-offs among multiple objectives and inference budgets substantially influence the choice of prompt and inference configuration. To address this gap, we introduce a unified novel framework named IAPO (Inference-Aware Prompt Optimization) that jointly optimizes the prompt and inference scale, while being aware of the inference budget and different task objectives. We then develop a fixed-budget training algorithm for IAPO, which we call PSST (Prompt Scaling via Sequential Trimming), and analyze finite-budget guarantees on error probability. Finally, we evaluate the effectiveness of PSST on six different tasks, including multi-objective text generation and reasoning, and demonstrate the critical role of incorporating inference-awareness when aligning black-box LLMs through prompt optimization.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é»‘ç›’å¤§è¯­è¨€æ¨¡å‹(LLMs)å¯¹é½é—®é¢˜ï¼ŒæŒ‡å‡ºç›®å‰çš„æç¤ºè¯ä¼˜åŒ–(Prompt optimization)æ–¹æ³•å¾€å¾€å¿½ç•¥äº†æ¨ç†ç­–ç•¥(inference strategy)çš„å½±å“ã€‚å®éªŒä¸ç†è®ºåˆ†æè¡¨æ˜ï¼Œæç¤ºè¯ä¼˜åŒ–ä¸æ¨ç†æ‰©å±•ç­–ç•¥(inference scaling)ä¹‹é—´å­˜åœ¨æ˜¾è‘—çš„ç›¸äº’ä¾èµ–å…³ç³»ï¼Œä¸”ç”¨æˆ·å¯¹å¤šç›®æ ‡æƒè¡¡å’Œæ¨ç†é¢„ç®—(inference budgets)çš„åå¥½ä¼šç›´æ¥å½±å“æœ€ä¼˜é…ç½®çš„é€‰æ‹©ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†ä¸€ä¸ªåä¸ºIAPO (Inference-Aware Prompt Optimization)çš„æ–°å‹ç»Ÿä¸€æ¡†æ¶ï¼Œæ—¨åœ¨æ„ŸçŸ¥æ¨ç†é¢„ç®—å’Œä»»åŠ¡ç›®æ ‡çš„åŒæ—¶ï¼Œè”åˆä¼˜åŒ–æç¤ºè¯å’Œæ¨ç†è§„æ¨¡(inference scale)ã€‚ç ”ç©¶è¿˜è¿›ä¸€æ­¥å¼€å‘äº†åä¸ºPSST (Prompt Scaling via Sequential Trimming)çš„å›ºå®šé¢„ç®—è®­ç»ƒç®—æ³•ï¼Œå¹¶å¯¹å…¶åœ¨æœ‰é™é¢„ç®—ä¸‹çš„é”™è¯¯æ¦‚ç‡æä¾›äº†ç†è®ºä¿è¯ã€‚åœ¨å¤šç›®æ ‡æ–‡æœ¬ç”Ÿæˆå’Œæ¨ç†ç­‰å…­é¡¹ä»»åŠ¡ä¸Šçš„å®éªŒç»“æœè¯æ˜ï¼Œåœ¨æç¤ºè¯ä¼˜åŒ–è¿‡ç¨‹ä¸­å¼•å…¥æ¨ç†æ„ŸçŸ¥å¯¹äºæå‡é»‘ç›’LLMsçš„å¯¹é½æ•ˆæœå…·æœ‰é‡è¦ä½œç”¨ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages",
      "pdf_url": "https://arxiv.org/pdf/2508.10030v1",
      "published_date": "2025-08-08 18:45:53 UTC",
      "updated_date": "2025-08-08 18:45:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:07:18.492169+00:00"
    },
    {
      "arxiv_id": "2508.06641v1",
      "title": "Fractal Language Modelling by Universal Sequence Maps (USM)",
      "title_zh": "åŸºäºé€šç”¨åºåˆ—æ˜ å°„ (USM) çš„åˆ†å½¢è¯­è¨€å»ºæ¨¡",
      "authors": [
        "Jonas S Almeida",
        "Daniel E Russ",
        "Susana Vinga",
        "Ines Duarte",
        "Lee Mason",
        "Praphulla Bhawsar",
        "Aaron Ge",
        "Arlindo Oliveira",
        "Jeya Balaji Balasubramanian"
      ],
      "abstract": "Motivation: With the advent of Language Models using Transformers, popularized by ChatGPT, there is a renewed interest in exploring encoding procedures that numerically represent symbolic sequences at multiple scales and embedding dimensions. The challenge that encoding addresses is the need for mechanisms that uniquely retain contextual information about the succession of individual symbols, which can then be modeled by nonlinear formulations such as neural networks.\n  Context: Universal Sequence Maps(USM) are iterated functions that bijectively encode symbolic sequences onto embedded numerical spaces. USM is composed of two Chaos Game Representations (CGR), iterated forwardly and backwardly, that can be projected into the frequency domain (FCGR). The corresponding USM coordinates can be used to compute a Chebyshev distance metric as well as k-mer frequencies, without having to recompute the embedded numeric coordinates, and, paradoxically, allowing for non-integers values of k.\n  Results: This report advances the bijective fractal encoding by Universal Sequence Maps (USM) by resolving seeding biases affecting the iterated process. The resolution had two results, the first expected, the second an intriguing outcome: 1) full reconciliation of numeric positioning with sequence identity; and 2) uncovering the nature of USM as an efficient numeric process converging towards a steady state sequence embedding solution. We illustrate these results for genomic sequences because of the convenience of a planar representation defined by an alphabet with only 4 tokens (the 4 nucleotides). Nevertheless, the application to alphabet of arbitrary cardinality was found to be straightforward.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åˆ©ç”¨Universal Sequence Maps (USM) è¿›è¡Œçš„åˆ†å½¢è¯­è¨€å»ºæ¨¡ï¼Œæ—¨åœ¨è§£å†³Transformerç­‰æ¨¡å‹åœ¨ç¬¦å·åºåˆ—æ•°å€¼è¡¨ç¤ºä¸­éš¾ä»¥ç²¾ç¡®ä¿ç•™ä¸Šä¸‹æ–‡ä¿¡æ¯çš„é—®é¢˜ã€‚USMé‡‡ç”¨å‰å‘å’Œåå‘è¿­ä»£çš„Chaos Game Representations (CGR) å°†åºåˆ—åŒå°„ç¼–ç è‡³æ•°å€¼ç©ºé—´ï¼Œå¹¶å¯è¿›ä¸€æ­¥æŠ•å½±åˆ°é¢‘ç‡åŸŸ (FCGR) ä¸­ã€‚æœ¬æŠ¥å‘Šé€šè¿‡è§£å†³å½±å“è¿­ä»£è¿‡ç¨‹çš„ç§å­åå·®ï¼Œæ˜¾è‘—æå‡äº†USMçš„åŒå°„åˆ†å½¢ç¼–ç èƒ½åŠ›ã€‚å®éªŒç»“æœå®ç°äº†æ•°å€¼å®šä½ä¸åºåˆ—èº«ä»½çš„å®Œå…¨ç»Ÿä¸€ï¼Œå¹¶æ­ç¤ºäº†USMä½œä¸ºä¸€ç§é«˜æ•ˆæ•°å€¼è¿‡ç¨‹ï¼Œèƒ½å¤Ÿæ”¶æ•›è‡³ç¨³æ€åºåˆ—åµŒå…¥è§£çš„ç‰¹æ€§ã€‚è™½ç„¶è¯¥æ–¹æ³•ä¸»è¦åœ¨åŸºå› ç»„åºåˆ—ä¸Šè¿›è¡Œäº†æ¼”ç¤ºï¼Œä½†å…¶é€»è¾‘å¯ç›´æ¥åº”ç”¨äºä»»æ„åŸºæ•°çš„å­—æ¯è¡¨ï¼Œä¸ºåºåˆ—æ•°æ®çš„å¤šå°ºåº¦æ•°å€¼è¡¨å¾æä¾›äº†æ–°é€”å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.NA",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 8 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.06641v1",
      "published_date": "2025-08-08 18:41:13 UTC",
      "updated_date": "2025-08-08 18:41:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:07:22.734503+00:00"
    },
    {
      "arxiv_id": "2508.06638v1",
      "title": "Segmented Confidence Sequences and Multi-Scale Adaptive Confidence Segments for Anomaly Detection in Nonstationary Time Series",
      "title_zh": "é’ˆå¯¹éå¹³ç¨³æ—¶é—´åºåˆ—å¼‚å¸¸æ£€æµ‹çš„åˆ†æ®µç½®ä¿¡åºåˆ—ä¸å¤šå°ºåº¦è‡ªé€‚åº”ç½®ä¿¡æ®µ",
      "authors": [
        "Muyan Anna Li",
        "Aditi Gautam"
      ],
      "abstract": "As time series data become increasingly prevalent in domains such as manufacturing, IT, and infrastructure monitoring, anomaly detection must adapt to nonstationary environments where statistical properties shift over time. Traditional static thresholds are easily rendered obsolete by regime shifts, concept drift, or multi-scale changes. To address these challenges, we introduce and empirically evaluate two novel adaptive thresholding frameworks: Segmented Confidence Sequences (SCS) and Multi-Scale Adaptive Confidence Segments (MACS). Both leverage statistical online learning and segmentation principles for local, contextually sensitive adaptation, maintaining guarantees on false alarm rates even under evolving distributions. Our experiments across Wafer Manufacturing benchmark datasets show significant F1-score improvement compared to traditional percentile and rolling quantile approaches. This work demonstrates that robust, statistically principled adaptive thresholds enable reliable, interpretable, and timely detection of diverse real-world anomalies.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹éå¹³ç¨³æ—¶é—´åºåˆ—(Nonstationary Time Series)åœ¨åˆ¶é€ ã€ITç­‰é¢†åŸŸä¸­å› ç»Ÿè®¡å±æ€§éšæ—¶é—´å‘ç”Ÿåç§»è€Œå¯¼è‡´çš„å¼‚å¸¸æ£€æµ‹æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸¤ç§æ–°å‹è‡ªé€‚åº”é˜ˆå€¼æ¡†æ¶ï¼šåˆ†æ®µç½®ä¿¡åºåˆ—(Segmented Confidence Sequences, SCS)å’Œå¤šå°ºåº¦è‡ªé€‚åº”ç½®ä¿¡åˆ†æ®µ(Multi-Scale Adaptive Confidence Segments, MACS)ã€‚è¿™äº›æ¡†æ¶ç»“åˆäº†ç»Ÿè®¡åœ¨çº¿å­¦ä¹ (Online Learning)å’Œåˆ†æ®µåŸåˆ™ï¼Œå®ç°äº†å±€éƒ¨ä¸”å…·æœ‰ä¸Šä¸‹æ–‡æ•æ„Ÿæ€§çš„è‡ªé€‚åº”ï¼Œèƒ½å¤Ÿåœ¨åˆ†å¸ƒæ¼”å˜çš„åŠ¨æ€ç¯å¢ƒä¸‹ç»´æŒå¯¹è¯¯æŠ¥ç‡(False Alarm Rates)çš„ç»Ÿè®¡ä¿è¯ã€‚åœ¨æ™¶åœ†åˆ¶é€ (Wafer Manufacturing)åŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•ç›¸æ¯”ä¼ ç»Ÿçš„ç™¾åˆ†ä½æ•°å’Œæ»šåŠ¨åˆ†ä½æ•°æ–¹æ³•åœ¨ F1-score ä¸Šæœ‰æ˜¾è‘—æå‡ã€‚è¯¥ç ”ç©¶è¯æ˜äº†åŸºäºç»Ÿè®¡åŸåˆ™çš„ç¨³å¥è‡ªé€‚åº”é˜ˆå€¼èƒ½å¤Ÿä¸ºç°å®ä¸–ç•Œä¸­å¤šæ ·åŒ–çš„å¼‚å¸¸æä¾›å¯é ã€å¯è§£é‡Šä¸”åŠæ—¶çš„æ£€æµ‹æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "20 pages, 11 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.06638v1",
      "published_date": "2025-08-08 18:34:54 UTC",
      "updated_date": "2025-08-08 18:34:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:07:56.496321+00:00"
    },
    {
      "arxiv_id": "2508.06635v2",
      "title": "Valid Inference with Imperfect Synthetic Data",
      "title_zh": "åŸºäºä¸å®Œç¾åˆæˆæ•°æ®çš„æœ‰æ•ˆæ¨æ–­",
      "authors": [
        "Yewon Byun",
        "Shantanu Gupta",
        "Zachary C. Lipton",
        "Rachel Leah Childers",
        "Bryan Wilder"
      ],
      "abstract": "Predictions and generations from large language models are increasingly being explored as an aid in limited data regimes, such as in computational social science and human subjects research. While prior technical work has mainly explored the potential to use model-predicted labels for unlabeled data in a principled manner, there is increasing interest in using large language models to generate entirely new synthetic samples (e.g., synthetic simulations), such as in responses to surveys. However, it remains unclear by what means practitioners can combine such data with real data and yet produce statistically valid conclusions upon them. In this paper, we introduce a new estimator based on generalized method of moments, providing a hyperparameter-free solution with strong theoretical guarantees to address this challenge. Intriguingly, we find that interactions between the moment residuals of synthetic data and those of real data (i.e., when they are predictive of each other) can greatly improve estimates of the target parameter. We validate the finite-sample performance of our estimator across different tasks in computational social science applications, demonstrating large empirical gains.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨å¤§è¯­è¨€æ¨¡å‹(Large Language Models)ç”Ÿæˆåˆæˆæ•°æ®è¾…åŠ©æœ‰é™æ•°æ®åœºæ™¯çš„èƒŒæ™¯ä¸‹ï¼Œå¦‚ä½•ç»“åˆåˆæˆæ•°æ®ä¸çœŸå®æ•°æ®å¹¶å¾—å‡ºç»Ÿè®¡ä¸Šæœ‰æ•ˆçš„ç»“è®ºã€‚ä¸ºæ­¤ï¼Œè®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºå¹¿ä¹‰çŸ©ä¼°è®¡(Generalized Method of Moments, GMM)çš„æ–°å‹ä¼°è®¡é‡ï¼Œæä¾›äº†ä¸€ç§æ— è¶…å‚æ•°ä¸”å…·æœ‰å¼ºç†è®ºä¿è¯çš„è§£å†³æ–¹æ¡ˆã€‚ç ”ç©¶å‘ç°ï¼Œåˆæˆæ•°æ®ä¸çœŸå®æ•°æ®çš„çŸ©æ®‹å·®(moment residuals)ä¹‹é—´çš„ç›¸äº’ä½œç”¨ï¼Œå³å½“äºŒè€…å…·æœ‰äº’é¢„æµ‹æ€§æ—¶ï¼Œå¯ä»¥æ˜¾è‘—æå‡ç›®æ ‡å‚æ•°çš„ä¼°è®¡ç²¾åº¦ã€‚é€šè¿‡åœ¨è®¡ç®—ç¤¾ä¼šç§‘å­¦é¢†åŸŸçš„å¤šç§ä»»åŠ¡ä¸­è¿›è¡ŒéªŒè¯ï¼Œè¯¥ä¼°è®¡é‡åœ¨æœ‰é™æ ·æœ¬ä¸‹è¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ï¼Œå–å¾—äº†æ˜¾è‘—çš„å®è¯å¢ç›Šã€‚è¯¥æ–¹æ³•ä¸ºç ”ç©¶äººå‘˜åœ¨ä¸ç‰ºç‰²ç»Ÿè®¡æœ‰æ•ˆæ€§çš„å‰æä¸‹ï¼Œæœ‰æ•ˆåœ°åˆ©ç”¨ä¸å®Œç¾åˆæˆæ•°æ®è¿›è¡Œç§‘å­¦æ¨æ–­æä¾›äº†åšå®çš„ç†è®ºå’Œå®è·µåŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.06635v2",
      "published_date": "2025-08-08 18:32:52 UTC",
      "updated_date": "2025-10-08 17:56:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:08:42.046892+00:00"
    },
    {
      "arxiv_id": "2508.06632v1",
      "title": "CoDe-NeRF: Neural Rendering via Dynamic Coefficient Decomposition",
      "title_zh": "CoDe-NeRFï¼šåŸºäºåŠ¨æ€ç³»æ•°åˆ†è§£çš„ç¥ç»æ¸²æŸ“",
      "authors": [
        "Wenpeng Xing",
        "Jie Chen",
        "Zaifeng Yang",
        "Tiancheng Zhao",
        "Gaolei Li",
        "Changting Lin",
        "Yike Guo",
        "Meng Han"
      ],
      "abstract": "Neural Radiance Fields (NeRF) have shown impressive performance in novel view synthesis, but challenges remain in rendering scenes with complex specular reflections and highlights. Existing approaches may produce blurry reflections due to entanglement between lighting and material properties, or encounter optimization instability when relying on physically-based inverse rendering. In this work, we present a neural rendering framework based on dynamic coefficient decomposition, aiming to improve the modeling of view-dependent appearance. Our approach decomposes complex appearance into a shared, static neural basis that encodes intrinsic material properties, and a set of dynamic coefficients generated by a Coefficient Network conditioned on view and illumination. A Dynamic Radiance Integrator then combines these components to synthesize the final radiance. Experimental results on several challenging benchmarks suggest that our method can produce sharper and more realistic specular highlights compared to existing techniques. We hope that this decomposition paradigm can provide a flexible and effective direction for modeling complex appearance in neural scene representations.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† CoDe-NeRFï¼Œä¸€ç§åŸºäºåŠ¨æ€ç³»æ•°åˆ†è§£ (Dynamic Coefficient Decomposition) çš„ç¥ç»æ¸²æŸ“æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç¥ç»è¾å°„åœº (NeRF) åœ¨å¤„ç†å¤æ‚é•œé¢åå°„ (Specular Reflections) å’Œé«˜å…‰æ—¶å­˜åœ¨çš„æ¨¡ç³Šæˆ–ä¼˜åŒ–ä¸ç¨³å®šç­‰æŒ‘æˆ˜ã€‚è¯¥æ–¹æ³•å°†å¤æ‚çš„åœºæ™¯å¤–è§‚åˆ†è§£ä¸ºä¸€ä¸ªç¼–ç å›ºæœ‰ææ–™å±æ€§çš„å…±äº«é™æ€ç¥ç»åŸº (Static Neural Basis)ï¼Œä»¥åŠç”±ç³»æ•°ç½‘ç»œ (Coefficient Network) æ ¹æ®è§†è§’å’Œå…‰ç…§ç”Ÿæˆçš„åŠ¨æ€ç³»æ•°ã€‚éšåï¼Œé€šè¿‡åŠ¨æ€è¾å°„ç§¯åˆ†å™¨ (Dynamic Radiance Integrator) å°†è¿™äº›ç»„ä»¶ç»“åˆä»¥åˆæˆæœ€ç»ˆçš„è¾å°„åº¦ã€‚åœ¨å¤šä¸ªæŒ‘æˆ˜æ€§åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œä¸ç°æœ‰æŠ€æœ¯ç›¸æ¯”ï¼ŒCoDe-NeRF èƒ½å¤Ÿäº§ç”Ÿæ›´æ¸…æ™°ã€æ›´çœŸå®çš„é•œé¢é«˜å…‰æ•ˆæœã€‚è¿™ç§åˆ†è§£èŒƒå¼ä¸ºç¥ç»åœºæ™¯è¡¨ç¤ºä¸­å»ºæ¨¡å¤æ‚å¤–è§‚æä¾›äº†ä¸€ä¸ªçµæ´»ä¸”æœ‰æ•ˆçš„æŠ€æœ¯æ–¹å‘ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06632v1",
      "published_date": "2025-08-08 18:30:02 UTC",
      "updated_date": "2025-08-08 18:30:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:07:52.184419+00:00"
    },
    {
      "arxiv_id": "2508.06627v3",
      "title": "Early Detection of Pancreatic Cancer Using Multimodal Learning on Electronic Health Records",
      "title_zh": "åŸºäºç”µå­å¥åº·æ¡£æ¡ˆå¤šæ¨¡æ€å­¦ä¹ çš„èƒ°è…ºç™Œæ—©æœŸæ£€æµ‹",
      "authors": [
        "Mosbah Aouad",
        "Anirudh Choudhary",
        "Awais Farooq",
        "Steven Nevers",
        "Lusine Demirkhanyan",
        "Bhrandon Harris",
        "Suguna Pappu",
        "Christopher Gondi",
        "Ravishankar Iyer"
      ],
      "abstract": "Pancreatic ductal adenocarcinoma (PDAC) is one of the deadliest cancers, and early detection remains a major clinical challenge due to the absence of specific symptoms and reliable biomarkers. In this work, we propose a new multimodal approach that integrates longitudinal diagnosis code histories and routinely collected laboratory measurements from electronic health records to detect PDAC up to one year prior to clinical diagnosis. Our method combines neural controlled differential equations to model irregular lab time series, pretrained language models and recurrent networks to learn diagnosis code trajectory representations, and cross-attention mechanisms to capture interactions between the two modalities. We develop and evaluate our approach on a real-world dataset of nearly 4,700 patients and achieve significant improvements in AUC ranging from 6.5% to 15.5% over state-of-the-art methods. Furthermore, our model identifies diagnosis codes and laboratory panels associated with elevated PDAC risk, including both established and new biomarkers. Our code is available at https://github.com/MosbahAouad/EarlyPDAC-MML.",
      "tldr_zh": "èƒ°è…ºå¯¼ç®¡è…ºç™Œï¼ˆPDACï¼‰ç”±äºç¼ºä¹ç‰¹å¼‚æ€§ç—‡çŠ¶å’Œå¯é çš„ç”Ÿç‰©æ ‡å¿—ç‰©ï¼Œæ—©æœŸæ£€æµ‹ä¸€ç›´æ˜¯é‡å¤§çš„ä¸´åºŠæŒ‘æˆ˜ã€‚è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§å…¨æ–°çš„å¤šæ¨¡æ€ï¼ˆMultimodalï¼‰å­¦ä¹ æ–¹æ³•ï¼Œé€šè¿‡æ•´åˆç”µå­å¥åº·è®°å½•ï¼ˆEHRï¼‰ä¸­çš„é•¿æœŸè¯Šæ–­ä»£ç å†å²å’Œå¸¸è§„å®éªŒå®¤æµ‹é‡æ•°æ®ï¼Œåœ¨ä¸´åºŠè¯Šæ–­å‰ä¸€å¹´å®ç°äº† PDAC çš„æœ‰æ•ˆè¯†åˆ«ã€‚è¯¥æ–¹æ³•ç»“åˆç¥ç»å¸¸å¾®åˆ†æ–¹ç¨‹ï¼ˆNeural Controlled Differential Equationsï¼‰å¤„ç†ä¸è§„åˆ™çš„å®éªŒå®¤æ—¶é—´åºåˆ—ï¼Œå¹¶åˆ©ç”¨é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼ˆPretrained Language Modelsï¼‰ä¸å¾ªç¯ç½‘ç»œï¼ˆRecurrent Networksï¼‰å»ºæ¨¡è¯Šæ–­è½¨è¿¹ï¼Œæœ€åé€šè¿‡äº¤å‰æ³¨æ„åŠ›ï¼ˆCross-attentionï¼‰æœºåˆ¶æ•æ‰æ¨¡æ€é—´çš„äº¤äº’ã€‚å®éªŒåœ¨è¿‘ 4,700 åæ‚£è€…çš„çœŸå®æ•°æ®é›†ä¸Šè¿›è¡Œï¼Œç»“æœæ˜¾ç¤ºè¯¥æ¨¡å‹åœ¨æ›²çº¿ä¸‹é¢ç§¯ï¼ˆAUCï¼‰æŒ‡æ ‡ä¸Šæ¯”ç°æœ‰æœ€å…ˆè¿›æ–¹æ³•æå‡äº† 6.5% è‡³ 15.5%ã€‚æ­¤å¤–ï¼Œæ¨¡å‹è¿˜æˆåŠŸè¯†åˆ«å‡ºä¸ PDAC é£é™©å¢åŠ ç›¸å…³çš„å¤šç§è¯Šæ–­ä»£ç å’Œå®éªŒå®¤æŒ‡æ ‡ï¼ŒåŒ…æ‹¬å·²ç¡®å®šçš„å’Œæ–°å‘ç°çš„ç”Ÿç‰©æ ‡å¿—ç‰©ï¼ˆBiomarkersï¼‰ï¼Œä¸ºä¸´åºŠæ—©æœŸç­›æŸ¥æä¾›äº†æœ‰åŠ›æ”¯æŒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06627v3",
      "published_date": "2025-08-08 18:18:15 UTC",
      "updated_date": "2025-08-18 23:48:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:07:56.890053+00:00"
    },
    {
      "arxiv_id": "2508.06617v2",
      "title": "Generalizing Scaling Laws for Dense and Sparse Large Language Models",
      "title_zh": "ç¨ å¯†ä¸ç¨€ç–å¤§è¯­è¨€æ¨¡å‹çš„æ³›åŒ–è§„æ¨¡æ³•åˆ™",
      "authors": [
        "Md Arafat Hossain",
        "Xingfu Wu",
        "Valerie Taylor",
        "Ali Jannesari"
      ],
      "abstract": "Over the past few years, the size of language models has grown exponentially, as has the computational cost to train these large models. This rapid growth has motivated researchers to develop new techniques aimed at enhancing the efficiency of the training process. Despite these advancements, optimally predicting the model size or allocating optimal resources remains a challenge. Several efforts have addressed the challenge by proposing different scaling laws, but almost all of them are architecture-specific (dense or sparse). In this work we revisit existing scaling laws and propose a generalized scaling law to provide a unified framework that is applicable to both dense and sparse large language models. We evaluate and compare our proposed scaling law with existing scaling laws to demonstrate its effectiveness.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLarge Language Modelsï¼‰è§„æ¨¡æŒ‡æ•°çº§å¢é•¿å¸¦æ¥çš„è®­ç»ƒæˆæœ¬æŒ‘æˆ˜ï¼Œå¹¶é’ˆå¯¹ç°æœ‰ç¼©æ”¾æ³•åˆ™ï¼ˆScaling Lawsï¼‰é€šå¸¸ä»…é€‚ç”¨äºç‰¹å®šæ¶æ„ï¼ˆDenseæˆ–Sparseï¼‰çš„å±€é™æ€§æå‡ºäº†æ”¹è¿›ã€‚ä½œè€…æå‡ºäº†ä¸€ç§é€šç”¨çš„ç¼©æ”¾æ³•åˆ™ï¼ˆGeneralized Scaling Lawï¼‰ï¼Œæ—¨åœ¨ä¸ºå¯†é›†å‹ï¼ˆDenseï¼‰å’Œç¨€ç–å‹ï¼ˆSparseï¼‰å¤§æ¨¡å‹æä¾›ä¸€ä¸ªç»Ÿä¸€çš„é¢„æµ‹æ¡†æ¶ã€‚é€šè¿‡é‡æ–°å®¡è§†å¹¶æ•´åˆç°æœ‰çš„ç¼©æ”¾æ³•åˆ™ï¼Œè¯¥ç ”ç©¶è§£å†³äº†åœ¨ä¸åŒæ¶æ„ä¸‹éš¾ä»¥å‡†ç¡®é¢„æµ‹æ¨¡å‹è§„æ¨¡å’Œåˆ†é…æœ€ä¼˜èµ„æºçš„é—®é¢˜ã€‚å®éªŒè¯„ä¼°ä¸å¯¹æ¯”ç»“æœè¡¨æ˜ï¼Œè¯¥é€šç”¨æ¡†æ¶åœ¨è·¨æ¶æ„åº”ç”¨ä¸­å…·æœ‰æ˜¾è‘—çš„æœ‰æ•ˆæ€§ã€‚è¿™é¡¹å·¥ä½œä¸ºç†è§£ä¸åŒç±»å‹å¤§æ¨¡å‹çš„å¢é•¿è§„å¾‹æä¾›äº†é‡è¦çš„ç†è®ºæ”¯æ’‘ï¼Œæœ‰åŠ©äºè¿›ä¸€æ­¥æå‡æ¨¡å‹è®­ç»ƒçš„èµ„æºåˆ©ç”¨æ•ˆç‡ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.PF"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 8 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.06617v2",
      "published_date": "2025-08-08 18:07:11 UTC",
      "updated_date": "2025-08-13 17:55:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:07:59.292065+00:00"
    },
    {
      "arxiv_id": "2508.06616v1",
      "title": "Generative AI for Intent-Driven Network Management in 6G: A Case Study on Hierarchical Learning Approach",
      "title_zh": "é¢å‘ 6G æ„å›¾é©±åŠ¨ç½‘ç»œç®¡ç†çš„ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ï¼šåŸºäºåˆ†å±‚å­¦ä¹ æ–¹æ³•çš„æ¡ˆä¾‹ç ”ç©¶",
      "authors": [
        "Md Arafat Habib",
        "Medhat Elsayed",
        "Yigit Ozcan",
        "Pedro Enrique Iturria-Rivera",
        "Majid Bavand",
        "Melike Erol-Kantarci"
      ],
      "abstract": "With the emergence of 6G, mobile networks are becoming increasingly heterogeneous and dynamic, necessitating advanced automation for efficient management. Intent-Driven Networks (IDNs) address this by translating high-level intents into optimization policies. Large Language Models (LLMs) can enhance this process by understanding complex human instructions to enable adaptive, intelligent automation. Given the rapid advancements in Generative AI (GenAI), a comprehensive survey of LLM-based IDN architectures in disaggregated Radio Access Network (RAN) environments is both timely and critical. This article provides such a survey, along with a case study on a hierarchical learning-enabled IDN architecture that integrates GenAI across three key stages: intent processing, intent validation, and intent execution. Unlike most existing approaches that apply GenAI in the form of LLMs for intent processing only, we propose a hierarchical framework that introduces GenAI across all three stages of IDN. To demonstrate the effectiveness of the proposed IDN management architecture, we present a case study based on the latest GenAI architecture named Mamba. The case study shows how the proposed GenAI-driven architecture enhances network performance through intelligent automation, surpassing the performance of the conventional IDN architectures.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨6Gç¯å¢ƒä¸‹åˆ©ç”¨ç”Ÿæˆå¼äººå·¥æ™ºèƒ½(Generative AI, GenAI)å®ç°æ„å›¾é©±åŠ¨ç½‘ç»œ(Intent-Driven Networks, IDNs)ç®¡ç†çš„è‡ªåŠ¨åŒ–æ–¹æ¡ˆã€‚é’ˆå¯¹ç§»åŠ¨ç½‘ç»œæ—¥ç›Šå¢é•¿çš„å¼‚æ„æ€§å’ŒåŠ¨æ€æ€§ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ä¸ªå±‚æ¬¡åŒ–å­¦ä¹ èµ‹èƒ½çš„IDNæ¶æ„ï¼Œå°†GenAIæ•´åˆè¿›æ„å›¾å¤„ç†(intent processing)ã€æ„å›¾éªŒè¯(intent validation)å’Œæ„å›¾æ‰§è¡Œ(intent execution)ä¸‰ä¸ªå…³é”®é˜¶æ®µã€‚ä¸åŒäºä»…åœ¨æ„å›¾å¤„ç†é˜¶æ®µä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹(Large Language Models, LLMs)çš„ç°æœ‰æ–¹æ³•ï¼Œè¯¥å±‚æ¬¡åŒ–æ¡†æ¶åœ¨IDNçš„å…¨æµç¨‹ä¸­å¼•å…¥äº†GenAIæŠ€æœ¯ã€‚é€šè¿‡åŸºäºæœ€æ–°GenAIæ¶æ„Mambaçš„æ¡ˆä¾‹ç ”ç©¶ï¼Œå®éªŒè¯æ˜è¯¥æ¶æ„èƒ½å¤Ÿæ˜¾è‘—å¢å¼ºç½‘ç»œæ€§èƒ½å¹¶å®ç°æ›´é«˜çº§åˆ«çš„æ™ºèƒ½è‡ªåŠ¨åŒ–ï¼Œæ€§èƒ½è¡¨ç°ä¼˜äºä¼ ç»Ÿçš„IDNæ¶æ„ï¼Œä¸ºæœªæ¥6Gç½‘ç»œçš„é«˜æ•ˆç®¡ç†æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06616v1",
      "published_date": "2025-08-08 18:06:52 UTC",
      "updated_date": "2025-08-08 18:06:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:08:13.186318+00:00"
    },
    {
      "arxiv_id": "2508.06601v1",
      "title": "Deep Ignorance: Filtering Pretraining Data Builds Tamper-Resistant Safeguards into Open-Weight LLMs",
      "title_zh": "Deep Ignoranceï¼šé€šè¿‡è¿‡æ»¤é¢„è®­ç»ƒæ•°æ®ä¸ºæƒé‡å¼€æ”¾çš„å¤§è¯­è¨€æ¨¡å‹æ„å»ºæŠ—ç¯¡æ”¹å®‰å…¨æœºåˆ¶",
      "authors": [
        "Kyle O'Brien",
        "Stephen Casper",
        "Quentin Anthony",
        "Tomek Korbak",
        "Robert Kirk",
        "Xander Davies",
        "Ishan Mishra",
        "Geoffrey Irving",
        "Yarin Gal",
        "Stella Biderman"
      ],
      "abstract": "Open-weight AI systems offer unique benefits, including enhanced transparency, open research, and decentralized access. However, they are vulnerable to tampering attacks which can efficiently elicit harmful behaviors by modifying weights or activations. Currently, there is not yet a robust science of open-weight model risk management. Existing safety fine-tuning methods and other post-training techniques have struggled to make LLMs resistant to more than a few dozen steps of adversarial fine-tuning. In this paper, we investigate whether filtering text about dual-use topics from training data can prevent unwanted capabilities and serve as a more tamper-resistant safeguard. We introduce a multi-stage pipeline for scalable data filtering and show that it offers a tractable and effective method for minimizing biothreat proxy knowledge in LLMs. We pretrain multiple 6.9B-parameter models from scratch and find that they exhibit substantial resistance to adversarial fine-tuning attacks on up to 10,000 steps and 300M tokens of biothreat-related text -- outperforming existing post-training baselines by over an order of magnitude -- with no observed degradation to unrelated capabilities. However, while filtered models lack internalized dangerous knowledge, we find that they can still leverage such information when it is provided in context (e.g., via search tool augmentation), demonstrating a need for a defense-in-depth approach. Overall, these findings help to establish pretraining data curation as a promising layer of defense for open-weight AI systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¼€æºæƒé‡(Open-weight)æ¨¡å‹å®¹æ˜“å—åˆ°ç¯¡æ”¹æ”»å‡»å¹¶äº§ç”Ÿæœ‰å®³è¡Œä¸ºçš„é—®é¢˜ï¼Œæå‡ºäº†Deep Ignoranceé˜²å¾¡ç­–ç•¥ï¼Œæ—¨åœ¨é€šè¿‡åœ¨é¢„è®­ç»ƒé˜¶æ®µè¿‡æ»¤åŒç”¨é€”(dual-use)è¯é¢˜æ¥æ„å»ºæ›´ç¨³å›ºçš„å®‰å…¨é˜²çº¿ã€‚ç ”ç©¶è€…å¼€å‘äº†ä¸€å¥—å¯æ‰©å±•çš„å¤šé˜¶æ®µæ•°æ®è¿‡æ»¤æµç¨‹ï¼Œç”¨äºæ¸…é™¤é¢„è®­ç»ƒè¯­æ–™ä¸­çš„ç”Ÿç‰©å¨èƒ(biothreat)ç›¸å…³çŸ¥è¯†ï¼Œå¹¶ä»é›¶å¼€å§‹è®­ç»ƒäº†å¤šä¸ª6.9B-parameteræ¨¡å‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¯¹æŠ—æ€§å¾®è°ƒ(adversarial fine-tuning)ä¸‹è¡¨ç°å‡ºæå¼ºçš„éŸ§æ€§ï¼Œåœ¨æ¥å—å¤šè¾¾10,000æ­¥å’Œ3äº¿tokençš„æ¶æ„æ•°æ®è®­ç»ƒåä»èƒ½ä¿æŒå®‰å…¨æ€§ï¼Œå…¶æŠ—ç¯¡æ”¹èƒ½åŠ›ä¼˜äºä¼ ç»Ÿåè®­ç»ƒ(post-training)åŸºçº¿æ¨¡å‹ä¸€ä¸ªæ•°é‡çº§ä»¥ä¸Šã€‚è™½ç„¶ç ”ç©¶å‘ç°æ¨¡å‹ä»å¯èƒ½é€šè¿‡æœç´¢å·¥å…·ç­‰ä¸Šä¸‹æ–‡æ–¹å¼åˆ©ç”¨å¤–éƒ¨æ•æ„Ÿä¿¡æ¯ï¼Œä½†è¿™è¯å®äº†é¢„è®­ç»ƒé˜¶æ®µçš„æ•°æ®æ²»ç†(data curation)æ˜¯å®ç°äººå·¥æ™ºèƒ½å®‰å…¨çš„é‡è¦é˜²å¾¡å±‚ã€‚è¯¥å‘ç°ä¸ºå¼€æºAIç³»ç»Ÿçš„é£é™©ç®¡ç†æä¾›äº†æ–°æ€è·¯ï¼Œå¹¶å¼ºè°ƒäº†åœ¨æœªæ¥æ„å»ºå®‰å…¨æ¨¡å‹æ—¶é‡‡ç”¨æ·±åº¦é˜²å¾¡(defense-in-depth)ç­–ç•¥çš„å¿…è¦æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "https://deepignorance.ai/",
      "pdf_url": "https://arxiv.org/pdf/2508.06601v1",
      "published_date": "2025-08-08 17:59:47 UTC",
      "updated_date": "2025-08-08 17:59:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:08:20.132644+00:00"
    },
    {
      "arxiv_id": "2508.06485v2",
      "title": "WGAST: Weakly-Supervised Generative Network for Daily 10 m Land Surface Temperature Estimation via Spatio-Temporal Fusion",
      "title_zh": "WGASTï¼šåŸºäºæ—¶ç©ºèåˆçš„æ¯æ—¥ 10 ç±³åˆ†è¾¨ç‡åœ°è¡¨æ¸©åº¦ä¼°ç®—å¼±ç›‘ç£ç”Ÿæˆç½‘ç»œ",
      "authors": [
        "Sofiane Bouaziz",
        "Adel Hafiane",
        "Raphael Canals",
        "Rachid Nedjai"
      ],
      "abstract": "Urbanization, climate change, and agricultural stress are increasing the demand for precise and timely environmental monitoring. Land Surface Temperature (LST) is a key variable in this context and is retrieved from remote sensing satellites. However, these systems face a trade-off between spatial and temporal resolution. While spatio-temporal fusion methods offer promising solutions, few have addressed the estimation of daily LST at 10 m resolution. In this study, we present WGAST, a weakly-supervised generative network for daily 10 m LST estimation via spatio-temporal fusion of Terra MODIS, Landsat 8, and Sentinel-2. WGAST is the first end-to-end deep learning framework designed for this task. It adopts a conditional generative adversarial architecture, with a generator composed of four stages: feature extraction, fusion, LST reconstruction, and noise suppression. The first stage employs a set of encoders to extract multi-level latent representations from the inputs, which are then fused in the second stage using cosine similarity, normalization, and temporal attention mechanisms. The third stage decodes the fused features into high-resolution LST, followed by a Gaussian filter to suppress high-frequency noise. Training follows a weakly supervised strategy based on physical averaging principles and reinforced by a PatchGAN discriminator. Experiments demonstrate that WGAST outperforms existing methods in both quantitative and qualitative evaluations. Compared to the best-performing baseline, on average, WGAST reduces RMSE by 17.05% and improves SSIM by 4.22%. Furthermore, WGAST effectively captures fine-scale thermal patterns, as validated against near-surface air temperature measurements from 33 near-ground sensors. The code is available at https://github.com/Sofianebouaziz1/WGAST.git.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†WGASTï¼Œè¿™æ˜¯é¦–ä¸ªç”¨äºæ¯æ—¥10 måˆ†è¾¨ç‡åœ°è¡¨æ¸©åº¦(Land Surface Temperature, LST)ä¼°è®¡çš„ç«¯åˆ°ç«¯æ·±åº¦å­¦ä¹ æ¡†æ¶ã€‚è¯¥æ¨¡å‹é‡‡ç”¨å¼±ç›‘ç£æ¡ä»¶ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(Conditional Generative Adversarial Network)æ¶æ„ï¼Œé€šè¿‡èåˆTerra MODISã€Landsat 8å’ŒSentinel-2æ•°æ®ï¼Œè§£å†³äº†é¥æ„Ÿç³»ç»Ÿåœ¨ç©ºé—´å’Œæ—¶é—´åˆ†è¾¨ç‡ä¹‹é—´çš„æƒè¡¡é—®é¢˜ã€‚å…¶ç”Ÿæˆå™¨ç”±ç‰¹å¾æå–ã€èåˆã€LSTé‡å»ºå’Œå™ªå£°æŠ‘åˆ¶å››ä¸ªé˜¶æ®µç»„æˆï¼Œå¹¶åˆ©ç”¨ä½™å¼¦ç›¸ä¼¼åº¦(Cosine Similarity)å’Œæ—¶é—´æ³¨æ„åŠ›æœºåˆ¶(Temporal Attention)è¿›è¡Œç‰¹å¾æ•´åˆã€‚è®­ç»ƒè¿‡ç¨‹é‡‡ç”¨äº†åŸºäºç‰©ç†å¹³å‡åŸç†çš„å¼±ç›‘ç£ç­–ç•¥ï¼Œå¹¶è¾…ä»¥PatchGANåˆ¤åˆ«å™¨ä»¥ç¡®ä¿ç”Ÿæˆçš„ç²¾ç¡®æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒWGASTåœ¨å®šé‡å’Œå®šæ€§è¯„ä¼°ä¸­å‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå…¶å¹³å‡RMSEé™ä½äº†17.05%ï¼ŒSSIMæå‡äº†4.22%ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæ•æ‰ç²¾ç»†çš„çƒ­ç©ºé—´æ¨¡å¼ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06485v2",
      "published_date": "2025-08-08 17:49:46 UTC",
      "updated_date": "2025-12-10 10:26:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:08:23.284301+00:00"
    },
    {
      "arxiv_id": "2508.06482v1",
      "title": "Post-training for Efficient Communication via Convention Formation",
      "title_zh": "é€šè¿‡æƒ¯ä¾‹å½¢æˆå®ç°é«˜æ•ˆæ²Ÿé€šçš„åè®­ç»ƒ",
      "authors": [
        "Yilun Hua",
        "Evan Wang",
        "Yoav Artzi"
      ],
      "abstract": "Humans communicate with increasing efficiency in multi-turn interactions, by adapting their language and forming ad-hoc conventions. In contrast, prior work shows that LLMs do not naturally show this behavior. We develop a post-training process to develop this ability through targeted fine-tuning on heuristically identified demonstrations of convention formation. We evaluate with two new benchmarks focused on this capability. First, we design a focused, cognitively-motivated interaction benchmark that consistently elicits strong convention formation trends in humans. Second, we create a new document-grounded reference completion task that reflects in-the-wild convention formation behavior. Our studies show significantly improved convention formation abilities in post-trained LLMs across the two evaluation methods.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†äººç±»å¦‚ä½•åœ¨å¤šè½®äº’åŠ¨ä¸­é€šè¿‡å½¢æˆå³å…´çº¦å®š(ad-hoc conventions)æ¥æé«˜æ²Ÿé€šæ•ˆç‡ï¼Œå¹¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)ç¼ºä¹è¿™ç§è‡ªç„¶è¡Œä¸ºçš„é—®é¢˜æå‡ºäº†æ”¹è¿›æ–¹æ¡ˆã€‚ä½œè€…å¼€å‘äº†ä¸€å¥—åè®­ç»ƒ(post-training)æµç¨‹ï¼Œé€šè¿‡å¯¹å¯å‘å¼è¯†åˆ«çš„çº¦å®šå½¢æˆæ¼”ç¤ºè¿›è¡Œé’ˆå¯¹æ€§å¾®è°ƒ(fine-tuning)ï¼Œä½¿æ¨¡å‹å…·å¤‡ç±»ä¼¼äººç±»çš„æ²Ÿé€šé€‚åº”èƒ½åŠ›ã€‚ä¸ºäº†éªŒè¯æ•ˆæœï¼Œç ”ç©¶è€…è®¾è®¡äº†ä¸€ä¸ªå—è®¤çŸ¥å¯å‘çš„äº’åŠ¨åŸºå‡†æµ‹è¯•ä»¥åŠä¸€ä¸ªåŸºäºæ–‡æ¡£çš„å‚è€ƒè¡¥å…¨ä»»åŠ¡(document-grounded reference completion)ï¼Œåè€…èƒ½æœ‰æ•ˆåæ˜ ç°å®åœºæ™¯ä¸­çš„çº¦å®šå½¢æˆè¡Œä¸ºã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œç»è¿‡è¯¥åè®­ç»ƒæµç¨‹å¤„ç†åçš„LLMsåœ¨ä¸¤ä¸ªè¯„ä¼°åŸºå‡†ä¸Šå‡è¡¨ç°å‡ºæ˜¾è‘—å¢å¼ºçš„çº¦å®šå½¢æˆèƒ½åŠ›ã€‚è¿™é¡¹å·¥ä½œä¸ä»…æå‡äº†æ¨¡å‹çš„å¤šè½®æ²Ÿé€šæ•ˆç‡ï¼Œä¹Ÿä¸ºæ„å»ºæ›´å…·ååŒèƒ½åŠ›çš„æ™ºèƒ½ä½“æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to COLM 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.06482v1",
      "published_date": "2025-08-08 17:42:16 UTC",
      "updated_date": "2025-08-08 17:42:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:08:25.383238+00:00"
    },
    {
      "arxiv_id": "2508.10029v2",
      "title": "Latent Fusion Jailbreak: Blending Harmful and Harmless Representations to Elicit Unsafe LLM Outputs",
      "title_zh": "Latent Fusion Jailbreakï¼šèåˆæœ‰å®³ä¸æ— å®³è¡¨å¾ä»¥è¯±å¯¼å¤§è¯­è¨€æ¨¡å‹äº§ç”Ÿä¸å®‰å…¨è¾“å‡º",
      "authors": [
        "Wenpeng Xing",
        "Mohan Li",
        "Chunqiang Hu",
        "Haitao Xu",
        "Ningyu Zhang",
        "Bo Lin",
        "Meng Han"
      ],
      "abstract": "While Large Language Models (LLMs) have achieved remarkable progress, they remain vulnerable to jailbreak attacks. Existing methods, primarily relying on discrete input optimization (e.g., GCG), often suffer from high computational costs and generate high-perplexity prompts that are easily blocked by simple filters. To overcome these limitations, we propose Latent Fusion Jailbreak (LFJ), a stealthy white-box attack that operates in the continuous latent space. Unlike previous approaches, LFJ constructs adversarial representations by mathematically fusing the hidden states of a harmful query with a thematically similar benign query, effectively masking malicious intent while retaining semantic drive. We further introduce a gradient-guided optimization strategy to balance attack success and computational efficiency. Extensive evaluations on Vicuna-7B, LLaMA-2-7B-Chat, Guanaco-7B, LLaMA-3-70B, and Mistral-7B-Instruct show that LFJ achieves an average Attack Success Rate (ASR) of 94.01%, significantly outperforming state-of-the-art baselines like GCG and AutoDAN while avoiding detectable input artifacts. Furthermore, we identify that thematic similarity in the latent space is a critical vulnerability in current safety alignments. Finally, we propose a latent adversarial training defense that reduces LFJ's ASR by over 80% without compromising model utility.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Latent Fusion Jailbreak (LFJ)ï¼Œè¿™æ˜¯ä¸€ç§åœ¨è¿ç»­æ½œåœ¨ç©ºé—´ (continuous latent space) ä¸­è¿è¡Œçš„éšè”½ç™½ç›’æ”»å‡»æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰è¶Šç‹±æ”»å‡» (jailbreak attacks) è®¡ç®—æˆæœ¬é«˜ä¸”æ˜“è¢«è¿‡æ»¤çš„é—®é¢˜ã€‚LFJ é€šè¿‡æ•°å­¦æ–¹å¼èåˆæœ‰å®³æŸ¥è¯¢ä¸ä¸»é¢˜ç›¸ä¼¼çš„æ— å®³æŸ¥è¯¢çš„éšè—çŠ¶æ€ (hidden states) æ¥æ„å»ºå¯¹æŠ—æ€§è¡¨ç¤ºï¼Œåœ¨ä¿ç•™è¯­ä¹‰é©±åŠ¨çš„åŒæ—¶æœ‰æ•ˆæ©ç›–æ¶æ„æ„å›¾ã€‚ç ”ç©¶å¼•å…¥äº†æ¢¯åº¦å¼•å¯¼çš„ä¼˜åŒ–ç­–ç•¥ä»¥å¹³è¡¡æ”»å‡»æˆåŠŸç‡ä¸è®¡ç®—æ•ˆç‡ï¼Œå®éªŒæ˜¾ç¤º LFJ åœ¨ Vicunaã€LLaMA-2/3 å’Œ Mistral ç­‰æ¨¡å‹ä¸Šè¾¾åˆ°äº† 94.01% çš„å¹³å‡æ”»å‡»æˆåŠŸç‡ (ASR)ï¼Œæ˜¾è‘—ä¼˜äº GCG å’Œ AutoDAN ç­‰åŸºçº¿æ–¹æ³•ã€‚ç ”ç©¶æŒ‡å‡ºæ½œåœ¨ç©ºé—´ä¸­çš„ä¸»é¢˜ç›¸ä¼¼æ€§æ˜¯å½“å‰å®‰å…¨å¯¹é½ (safety alignments) çš„å…³é”®æ¼æ´ï¼Œå¹¶æ®æ­¤æå‡ºäº†ä¸€ç§æ½œåœ¨å¯¹æŠ—è®­ç»ƒ (latent adversarial training) é˜²å¾¡æ–¹æ¡ˆã€‚è¯¥é˜²å¾¡æªæ–½åœ¨ä¸å½±å“æ¨¡å‹æ­£å¸¸æ•ˆèƒ½çš„æƒ…å†µä¸‹ï¼ŒæˆåŠŸå°† LFJ çš„æ”»å‡»æˆåŠŸç‡é™ä½äº† 80% ä»¥ä¸Šï¼Œä¸ºå¢å¼ºå¤§è¯­è¨€æ¨¡å‹çš„å®‰å…¨æ€§æä¾›äº†æ–°çš„è§†è§’ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.10029v2",
      "published_date": "2025-08-08 17:29:16 UTC",
      "updated_date": "2026-01-08 08:10:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:08:28.148959+00:00"
    },
    {
      "arxiv_id": "2508.06477v2",
      "title": "Intuition emerges in Maximum Caliber models at criticality",
      "title_zh": "æœ€å¤§å£å¾„æ¨¡å‹åœ¨ä¸´ç•ŒçŠ¶æ€ä¸‹æ¶Œç°ç›´è§‰",
      "authors": [
        "LluÃ­s Arola-FernÃ¡ndez"
      ],
      "abstract": "Whether large predictive models merely parrot their training data or produce genuine insight lacks a physical explanation. This work reports a primitive form of intuition that emerges as a metastable phase of learning that critically balances next-token prediction against future path-entropy. The intuition mechanism is discovered via mind-tuning, the minimal principle that imposes Maximum Caliber in predictive models with a control temperature-like parameter $Î»$. Training on random walks in deterministic mazes reveals a rich phase diagram: imitation (low $Î»$), rule-breaking hallucination (high $Î»$), and a fragile in-between window exhibiting strong protocol-dependence (hysteresis) and multistability, where models spontaneously discover novel goal-directed strategies. These results are captured by an effective low-dimensional theory and frame intuition as an emergent property at the critical balance between memorizing what is and wondering what could be.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§æ¨¡å‹äº§ç”ŸçœŸå®æ´è§è€Œéç®€å•æ¨¡ä»¿çš„ç‰©ç†æœºåˆ¶ï¼Œå‘ç°äº†ä¸€ç§ä½œä¸ºå­¦ä¹ äºšç¨³æ€å‡ºç°çš„åŸå§‹â€œç›´è§‰â€å½¢å¼ã€‚ç ”ç©¶é€šè¿‡ mind-tuning åŸåˆ™åœ¨ Maximum Caliber æ¨¡å‹ä¸­å¼•å…¥æ§åˆ¶å‚æ•° $\\lambda$ï¼Œä½¿æ¨¡å‹åœ¨é¢„æµ‹ä¸‹ä¸€ä¸ª token ä¸æœªæ¥è·¯å¾„ç†µ (future path-entropy) ä¹‹é—´å–å¾—ä¸´ç•Œå¹³è¡¡ã€‚åœ¨ç¡®å®šæ€§è¿·å®«çš„éšæœºæ¸¸èµ°è®­ç»ƒä¸­ï¼Œæ¨¡å‹å±•ç°å‡ºäº†ç”±æ¨¡ä»¿ (imitation) åˆ°è¿è§„å¹»è§‰ (hallucination) è½¬å˜çš„ä¸°å¯Œç›¸å›¾ã€‚åœ¨ä¸¤è€…ä¹‹é—´çš„ä¸´ç•Œçª—å£å†…ï¼Œæ¨¡å‹è¡¨ç°å‡ºæ˜æ˜¾çš„è¿Ÿæ»ç°è±¡ (hysteresis) å’Œå¤šç¨³æ€ (multistability)ï¼Œå¹¶èƒ½è‡ªå‘å‘ç°æ–°é¢–çš„ç›®æ ‡å¯¼å‘ç­–ç•¥ã€‚è¯¥ç ”ç©¶åˆ©ç”¨æœ‰æ•ˆçš„ä½ç»´ç†è®ºæ•æ‰äº†è¿™äº›ç°è±¡ï¼Œå¹¶å°†ç›´è§‰å®šä¹‰ä¸ºä¸€ç§åœ¨è®°å¿†ç°çŠ¶ä¸æ¢ç´¢å¯èƒ½ä¹‹é—´è¾¾åˆ°ä¸´ç•Œå¹³è¡¡æ—¶çš„æ¶Œç°å±æ€§ã€‚",
      "categories": [
        "physics.soc-ph",
        "cond-mat.dis-nn",
        "cond-mat.stat-mech",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "physics.soc-ph",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06477v2",
      "published_date": "2025-08-08 17:27:41 UTC",
      "updated_date": "2025-09-26 16:53:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:09:02.245514+00:00"
    },
    {
      "arxiv_id": "2508.06457v2",
      "title": "ScamAgents: How AI Agents Can Simulate Human-Level Scam Calls",
      "title_zh": "ScamAgentsï¼šAI æ™ºèƒ½ä½“å¦‚ä½•æ¨¡æ‹Ÿäººç±»çº§åˆ«çš„è¯ˆéª—ç”µè¯",
      "authors": [
        "Sanket Badhe"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated impressive fluency and reasoning capabilities, but their potential for misuse has raised growing concern. In this paper, we present ScamAgent, an autonomous multi-turn agent built on top of LLMs, capable of generating highly realistic scam call scripts that simulate real-world fraud scenarios. Unlike prior work focused on single-shot prompt misuse, ScamAgent maintains dialogue memory, adapts dynamically to simulated user responses, and employs deceptive persuasion strategies across conversational turns. We show that current LLM safety guardrails, including refusal mechanisms and content filters, are ineffective against such agent-based threats. Even models with strong prompt-level safeguards can be bypassed when prompts are decomposed, disguised, or delivered incrementally within an agent framework. We further demonstrate the transformation of scam scripts into lifelike voice calls using modern text-to-speech systems, completing a fully automated scam pipeline. Our findings highlight an urgent need for multi-turn safety auditing, agent-level control frameworks, and new methods to detect and disrupt conversational deception powered by generative AI.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ScamAgentï¼Œè¿™æ˜¯ä¸€ç§åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLMs)æ„å»ºçš„è‡ªä¸»å¤šè½®å¯¹è¯æ™ºèƒ½ä½“ï¼Œèƒ½å¤Ÿæ¨¡æ‹ŸçœŸå®çš„è¯ˆéª—åœºæ™¯å¹¶ç”Ÿæˆé«˜åº¦é€¼çœŸçš„æ¬ºè¯ˆé€šè¯è„šæœ¬ã€‚ScamAgenté€šè¿‡ç»´æŠ¤å¯¹è¯è®°å¿†å’ŒåŠ¨æ€é€‚åº”ç”¨æˆ·åé¦ˆï¼Œåœ¨å¤šè½®äº¤äº’ä¸­è¿ç”¨æ¬ºéª—æ€§è¯´æœç­–ç•¥ï¼Œçªç ´äº†ä»¥å¾€å•æ¬¡æç¤ºè¯æ”»å‡»çš„å±€é™ã€‚å®éªŒè¯æ˜ï¼Œç°æœ‰çš„LLMå®‰å…¨é˜²æŠ¤æœºåˆ¶ï¼ˆå¦‚æ‹’ç»å“åº”å’Œå†…å®¹è¿‡æ»¤ï¼‰åœ¨é¢å¯¹è¿™ç§æ™ºèƒ½ä½“åŒ–çš„å¨èƒæ—¶æ•ˆæœæœ‰é™ï¼Œæ”»å‡»è€…å¯ä»¥é€šè¿‡åˆ†è§£æˆ–ä¼ªè£…æŒ‡ä»¤ç»•è¿‡å®‰å…¨è¾¹ç•Œã€‚ç ”ç©¶å›¢é˜Ÿè¿›ä¸€æ­¥ç»“åˆç°ä»£æ–‡æœ¬è½¬è¯­éŸ³(TTS)æŠ€æœ¯ï¼Œæ¼”ç¤ºäº†å¦‚ä½•å°†è¯ˆéª—è„šæœ¬è½¬åŒ–ä¸ºé«˜åº¦ä»¿çœŸçš„è¯­éŸ³é€šè¯ï¼Œä»è€Œå®Œæˆå…¨è‡ªåŠ¨åŒ–çš„è¯ˆéª—æµç¨‹ã€‚è¯¥å‘ç°æ­ç¤ºäº†å½“å‰AIå®‰å…¨é˜²å¾¡çš„é‡å¤§æ¼æ´ï¼Œå¹¶å¼ºè°ƒäº†å¼€å‘å¤šè½®å®‰å…¨å®¡è®¡å’Œæ™ºèƒ½ä½“çº§åˆ«æ§åˆ¶æ¡†æ¶ä»¥åº”å¯¹ç”Ÿæˆå¼AIæ¬ºè¯ˆçš„ç´§è¿«æ€§ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.MA"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted at CAMLIS 25: Conference on Applied Machine Learning for Information Security. 19 pages, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.06457v2",
      "published_date": "2025-08-08 17:01:41 UTC",
      "updated_date": "2025-12-09 18:09:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:09:02.440096+00:00"
    },
    {
      "arxiv_id": "2508.11679v1",
      "title": "Lifelong Learner: Discovering Versatile Neural Solvers for Vehicle Routing Problems",
      "title_zh": "Lifelong Learnerï¼šæ¢ç´¢è½¦è¾†è·¯å¾„é—®é¢˜çš„é€šç”¨ç¥ç»ç½‘ç»œæ±‚è§£å™¨",
      "authors": [
        "Shaodi Feng",
        "Zhuoyi Lin",
        "Jianan Zhou",
        "Cong Zhang",
        "Jingwen Li",
        "Kuan-Wen Chen",
        "Senthilnath Jayavelu",
        "Yew-Soon Ong"
      ],
      "abstract": "Deep learning has been extensively explored to solve vehicle routing problems (VRPs), which yields a range of data-driven neural solvers with promising outcomes. However, most neural solvers are trained to tackle VRP instances in a relatively monotonous context, e.g., simplifying VRPs by using Euclidean distance between nodes and adhering to a single problem size, which harms their off-the-shelf application in different scenarios. To enhance their versatility, this paper presents a novel lifelong learning framework that incrementally trains a neural solver to manage VRPs in distinct contexts. Specifically, we propose a lifelong learner (LL), exploiting a Transformer network as the backbone, to solve a series of VRPs. The inter-context self-attention mechanism is proposed within LL to transfer the knowledge obtained from solving preceding VRPs into the succeeding ones. On top of that, we develop a dynamic context scheduler (DCS), employing the cross-context experience replay to further facilitate LL looking back on the attained policies of solving preceding VRPs. Extensive results on synthetic and benchmark instances (problem sizes up to 18k) show that our LL is capable of discovering effective policies for tackling generic VRPs in varying contexts, which outperforms other neural solvers and achieves the best performance for most VRPs.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰è½¦è¾†è·¯å¾„é—®é¢˜ï¼ˆVehicle Routing Problems, VRPsï¼‰ç¥ç»æ±‚è§£å™¨åœ¨å•ä¸€åœºæ™¯è®­ç»ƒä¸‹é€šç”¨æ€§ä¸è¶³çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§å…¨æ–°çš„ç»ˆèº«å­¦ä¹ ï¼ˆlifelong learningï¼‰æ¡†æ¶ï¼Œç”¨äºå¢é‡è®­ç»ƒèƒ½å¤Ÿå¤„ç†å¤šæ ·åŒ–èƒŒæ™¯çš„ç¥ç»æ±‚è§£å™¨ã€‚è¯¥æ¡†æ¶æ„å»ºäº†ä¸€ä¸ªä»¥Transformerä¸ºéª¨å¹²ç½‘ç»œçš„ç»ˆèº«å­¦ä¹ è€…ï¼ˆLLï¼‰ï¼Œå¹¶å¼•å…¥è·¨ä¸Šä¸‹æ–‡è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼ˆinter-context self-attention mechanismï¼‰å°†å…ˆå‰è§£å†³VRPsè·å–çš„çŸ¥è¯†è¿ç§»è‡³åç»­ä»»åŠ¡ä¸­ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å¼€å‘äº†åŠ¨æ€ä¸Šä¸‹æ–‡è°ƒåº¦å™¨ï¼ˆDCSï¼‰ï¼Œé€šè¿‡è·¨ä¸Šä¸‹æ–‡ç»éªŒå›æ”¾ï¼ˆcross-context experience replayï¼‰è¿›ä¸€æ­¥ä¿ƒè¿›æ¨¡å‹å¯¹å·²æŒæ¡ç­–ç•¥çš„å›é¡¾ã€‚åœ¨åˆæˆæ•°æ®åŠèŠ‚ç‚¹è§„æ¨¡é«˜è¾¾18kçš„åŸºå‡†å®ä¾‹ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒLLèƒ½å¤Ÿä¸ºä¸åŒèƒŒæ™¯ä¸‹çš„é€šç”¨VRPså‘ç°æœ‰æ•ˆç­–ç•¥ã€‚æœ€ç»ˆç»“æœè¯æ˜ï¼Œè¯¥æ¨¡å‹åœ¨æ€§èƒ½ä¸Šä¼˜äºå…¶ä»–ç¥ç»æ±‚è§£å™¨ï¼Œå¹¶åœ¨å¤§å¤šæ•°VRPsä»»åŠ¡ä¸­å®ç°äº†æœ€ä¼˜è¡¨ç°ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.11679v1",
      "published_date": "2025-08-08 16:54:43 UTC",
      "updated_date": "2025-08-08 16:54:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:09:02.642918+00:00"
    },
    {
      "arxiv_id": "2508.06454v1",
      "title": "What Voting Rules Actually Do: A Data-Driven Analysis of Multi-Winner Voting",
      "title_zh": "æŠ•ç¥¨è§„åˆ™çš„å®é™…è¡¨ç°ï¼šå¤šä¼˜èƒœè€…æŠ•ç¥¨çš„æ•°æ®é©±åŠ¨åˆ†æ",
      "authors": [
        "Joshua Caiata",
        "Ben Armstrong",
        "Kate Larson"
      ],
      "abstract": "Committee-selection problems arise in many contexts and applications, and there has been increasing interest within the social choice research community on identifying which properties are satisfied by different multi-winner voting rules. In this work, we propose a data-driven framework to evaluate how frequently voting rules violate axioms across diverse preference distributions in practice, shifting away from the binary perspective of axiom satisfaction given by worst-case analysis. Using this framework, we analyze the relationship between multi-winner voting rules and their axiomatic performance under several preference distributions. We then show that neural networks, acting as voting rules, can outperform traditional rules in minimizing axiom violations. Our results suggest that data-driven approaches to social choice can inform the design of new voting systems and support the continuation of data-driven research in social choice.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å§”å‘˜ä¼šé€‰æ‹©é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ•°æ®é©±åŠ¨çš„æ¡†æ¶ï¼Œç”¨äºè¯„ä¼°å¤šè·èƒœè€…æŠ•ç¥¨(Multi-Winner Voting)è§„åˆ™åœ¨ä¸åŒåå¥½åˆ†å¸ƒ(Preference Distributions)ä¸‹è¿åå…¬ç†(Axioms)çš„å®é™…é¢‘ç‡ã€‚è¯¥ç ”ç©¶æ”¹å˜äº†ä»¥å¾€ç¤¾ä¼šé€‰æ‹©ç ”ç©¶ä¸­ä»…å…³æ³¨å…¬ç†æ»¡è¶³ä¸å¦çš„äºŒå…ƒè§†è§’ï¼Œé€šè¿‡å®è¯åˆ†ææ­ç¤ºäº†æŠ•ç¥¨è§„åˆ™ä¸å…¬ç†æ€§èƒ½ä¹‹é—´çš„æ·±å±‚å…³ç³»ã€‚ç ”ç©¶è¿›ä¸€æ­¥è¯æ˜ï¼Œé‡‡ç”¨ç¥ç»ç½‘ç»œ(Neural Networks)ä½œä¸ºæŠ•ç¥¨è§„åˆ™åœ¨æœ€å°åŒ–å…¬ç†è¿è§„æ–¹é¢å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ï¼Œå…¶è¡¨ç°ç”šè‡³ä¼˜äºä¼ ç»Ÿè§„åˆ™ã€‚è¿™äº›ç»“æœè¡¨æ˜æ•°æ®é©±åŠ¨çš„æ–¹æ³•èƒ½å¤Ÿä¸ºå¼€å‘æ–°å‹æŠ•ç¥¨ç³»ç»Ÿæä¾›é‡è¦æŒ‡å¯¼ï¼Œå¹¶æ¨åŠ¨äº†ç¤¾ä¼šé€‰æ‹©(Social Choice)é¢†åŸŸçš„å®è¯åŒ–ç ”ç©¶è¿›ç¨‹ã€‚",
      "categories": [
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.AI",
      "comment": "41 pages",
      "pdf_url": "https://arxiv.org/pdf/2508.06454v1",
      "published_date": "2025-08-08 16:54:09 UTC",
      "updated_date": "2025-08-08 16:54:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:09:11.488863+00:00"
    },
    {
      "arxiv_id": "2508.06453v2",
      "title": "Text Embedded Swin-UMamba for DeepLesion Segmentation",
      "title_zh": "Text Embedded Swin-UMambaï¼šé¢å‘ DeepLesion åˆ†å‰²çš„æ–‡æœ¬åµŒå…¥å¼æ¶æ„",
      "authors": [
        "Ruida Cheng",
        "Tejas Sudharshan Mathai",
        "Pritam Mukherjee",
        "Benjamin Hou",
        "Qingqing Zhu",
        "Zhiyong Lu",
        "Matthew McAuliffe",
        "Ronald M. Summers"
      ],
      "abstract": "Segmentation of lesions on CT enables automatic measurement for clinical assessment of chronic diseases (e.g., lymphoma). Integrating large language models (LLMs) into the lesion segmentation workflow has the potential to combine imaging features with descriptions of lesion characteristics from the radiology reports. In this study, we investigate the feasibility of integrating text into the Swin-UMamba architecture for the task of lesion segmentation. The publicly available ULS23 DeepLesion dataset was used along with short-form descriptions of the findings from the reports. On the test dataset, our method achieved a high Dice score of 82.64, and a low Hausdorff distance of 6.34 pixels was obtained for lesion segmentation. The proposed Text-Swin-U/Mamba model outperformed prior approaches: 37.79% improvement over the LLM-driven LanGuideMedSeg model (p < 0.001), and surpassed the purely image-based XLSTM-UNet and nnUNet models by 2.58% and 1.01%, respectively. The dataset and code can be accessed at https://github.com/ruida/LLM-Swin-UMamba",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Text Embedded Swin-UMamba æ¨¡å‹ï¼Œæ—¨åœ¨é€šè¿‡å°† Large Language Models (LLMs) é›†æˆåˆ°ç—…ç¶åˆ†å‰²å·¥ä½œæµä¸­ï¼Œå®ç° CT å›¾åƒç‰¹å¾ä¸æ”¾å°„æŠ¥å‘Šæ–‡æœ¬æè¿°çš„æ·±åº¦èåˆã€‚ç ”ç©¶åœ¨å…¬å¼€çš„ ULS23 DeepLesion æ•°æ®é›†ä¸ŠéªŒè¯äº†å°†æ–‡æœ¬ä¿¡æ¯åµŒå…¥ Swin-UMamba æ¶æ„ç”¨äº DeepLesion Segmentation çš„å¯è¡Œæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æµ‹è¯•é›†ä¸Šè¾¾åˆ°äº† 82.64 çš„ Dice score å’Œ 6.34 åƒç´ çš„ Hausdorff distanceã€‚ç›¸æ¯”äºåŒç±» LLM é©±åŠ¨çš„æ¨¡å‹ LanGuideMedSegï¼Œè¯¥æ–¹æ³•æ€§èƒ½æå‡äº† 37.79%ï¼ŒåŒæ—¶ä¹Ÿè¶…è¶Šäº†çº¯å›¾åƒæ¨¡å‹ XLSTM-UNet å’Œ nnUNetã€‚è¿™é¡¹ç ”ç©¶è¯æ˜äº†å¤šæ¨¡æ€æ•°æ®é›†æˆåœ¨æå‡ä¸´åºŠæ…¢æ€§ç—…è‡ªåŠ¨åŒ–è¯„ä¼°ç²¾åº¦æ–¹é¢çš„æ˜¾è‘—æ½œåŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06453v2",
      "published_date": "2025-08-08 16:54:06 UTC",
      "updated_date": "2025-12-16 17:03:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:09:14.133438+00:00"
    },
    {
      "arxiv_id": "2508.06445v2",
      "title": "Echoes of Automation: The Increasing Use of LLMs in Newsmaking",
      "title_zh": "è‡ªåŠ¨åŒ–å›å£°ï¼šå¤§è¯­è¨€æ¨¡å‹åœ¨æ–°é—»ç”Ÿäº§ä¸­æ—¥ç›Šå¢é•¿çš„åº”ç”¨",
      "authors": [
        "Abolfazl Ansari",
        "Delvin Ce Zhang",
        "Nafis Irtiza Tripto",
        "Dongwon Lee"
      ],
      "abstract": "The rapid rise of Generative AI (GenAI), particularly LLMs, poses concerns for journalistic integrity and authorship. This study examines AI-generated content across over 40,000 news articles from major, local, and college news media, in various media formats. Using three advanced AI-text detectors (e.g., Binoculars, Fast-Detect GPT, and GPTZero), we find substantial increase of GenAI use in recent years, especially in local and college news. Sentence-level analysis reveals LLMs are often used in the introduction of news, while conclusions usually written manually. Linguistic analysis shows GenAI boosts word richness and readability but lowers formality, leading to more uniform writing styles, particularly in local media.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ (Generative AI) å’Œå¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨æ–°é—»åˆ¶ä½œä¸­çš„åº”ç”¨åŠå…¶å¯¹æ–°é—»è¯šä¿¡å’Œç½²åæƒçš„å½±å“ã€‚é€šè¿‡ä½¿ç”¨ Binocularsã€Fast-Detect GPT å’Œ GPTZero ç­‰å…ˆè¿›çš„ AI æ–‡æœ¬æ£€æµ‹å™¨ï¼Œç ”ç©¶äººå‘˜åˆ†æäº†è¶…è¿‡ 40,000 ç¯‡æ¶µç›–ä¸»æµã€åœ°æ–¹å’Œå¤§å­¦åª’ä½“çš„æ–°é—»æ–‡ç« ã€‚ç ”ç©¶å‘ç°ï¼Œè¿‘å¹´æ¥æ–°é—»ä¸­ GenAI çš„ä½¿ç”¨é‡æ˜¾è‘—å¢åŠ ï¼Œå°¤å…¶æ˜¯åœ¨åœ°æ–¹å’Œå¤§å­¦æ–°é—»ä¸­è¡¨ç°æœ€ä¸ºçªå‡ºã€‚å¥å­å±‚é¢çš„åˆ†ææ­ç¤ºï¼ŒLLMs å¸¸ç”¨äºæ’°å†™æ–°é—»å¯¼è¯­ï¼Œè€Œç»“å°¾éƒ¨åˆ†é€šå¸¸ä»ç”±äººå·¥å®Œæˆã€‚è¯­è¨€å­¦åˆ†æè¡¨æ˜ï¼ŒGenAI çš„å¼•å…¥æé«˜äº†è¯æ±‡ä¸°å¯Œåº¦å’Œå¯è¯»æ€§ (Readability)ï¼Œä½†é™ä½äº†æ–‡ç« çš„æ­£å¼ç¨‹åº¦ (Formality)ï¼Œå¯¼è‡´å†™ä½œé£æ ¼è¶‹äºç»Ÿä¸€ã€‚è¿™ç§è¶‹åŠ¿åœ¨åœ°æ–¹åª’ä½“ä¸­å°¤ä¸ºæ˜æ˜¾ï¼Œåæ˜ äº†è‡ªåŠ¨åŒ–æŠ€æœ¯å¯¹æ–°é—»è¯è¯­ä½“ç³»äº§ç”Ÿçš„æ·±åˆ»å½±å“ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "To appear in the SBP-BRiMS 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.06445v2",
      "published_date": "2025-08-08 16:38:33 UTC",
      "updated_date": "2025-08-14 04:40:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:09:20.487194+00:00"
    },
    {
      "arxiv_id": "2508.06443v1",
      "title": "The Fair Game: Auditing & Debiasing AI Algorithms Over Time",
      "title_zh": "Fair Gameï¼šäººå·¥æ™ºèƒ½ç®—æ³•çš„åŠ¨æ€å®¡è®¡ä¸å»å",
      "authors": [
        "Debabrota Basu",
        "Udvas Das"
      ],
      "abstract": "An emerging field of AI, namely Fair Machine Learning (ML), aims to quantify different types of bias (also known as unfairness) exhibited in the predictions of ML algorithms, and to design new algorithms to mitigate them. Often, the definitions of bias used in the literature are observational, i.e. they use the input and output of a pre-trained algorithm to quantify a bias under concern. In reality,these definitions are often conflicting in nature and can only be deployed if either the ground truth is known or only in retrospect after deploying the algorithm. Thus,there is a gap between what we want Fair ML to achieve and what it does in a dynamic social environment. Hence, we propose an alternative dynamic mechanism,\"Fair Game\",to assure fairness in the predictions of an ML algorithm and to adapt its predictions as the society interacts with the algorithm over time. \"Fair Game\" puts together an Auditor and a Debiasing algorithm in a loop around an ML algorithm. The \"Fair Game\" puts these two components in a loop by leveraging Reinforcement Learning (RL). RL algorithms interact with an environment to take decisions, which yields new observations (also known as data/feedback) from the environment and in turn, adapts future decisions. RL is already used in algorithms with pre-fixed long-term fairness goals. \"Fair Game\" provides a unique framework where the fairness goals can be adapted over time by only modifying the auditor and the different biases it quantifies. Thus,\"Fair Game\" aims to simulate the evolution of ethical and legal frameworks in the society by creating an auditor which sends feedback to a debiasing algorithm deployed around an ML system. This allows us to develop a flexible and adaptive-over-time framework to build Fair ML systems pre- and post-deployment.",
      "tldr_zh": "æœ¬ç ”ç©¶æå‡ºäº†åä¸º \"Fair Game\" çš„åŠ¨æ€æœºåˆ¶ï¼Œæ—¨åœ¨è§£å†³ Fair Machine Learning é¢†åŸŸä¸­é™æ€åå·®å®šä¹‰éš¾ä»¥é€‚åº”åŠ¨æ€ç¤¾ä¼šç¯å¢ƒçš„é—®é¢˜ã€‚è¯¥æ¡†æ¶åˆ©ç”¨ Reinforcement Learning æŠ€æœ¯ï¼Œåœ¨æœºå™¨å­¦ä¹ ç®—æ³•å‘¨å›´æ„å»ºäº†ä¸€ä¸ªç”± Auditor å’Œ Debiasing algorithm ç»„æˆçš„åé¦ˆé—­ç¯ã€‚é€šè¿‡ RL ç®—æ³•ä¸ç¯å¢ƒçš„äº¤äº’ï¼Œç³»ç»Ÿèƒ½å¤Ÿè·å–å®æ—¶åé¦ˆå¹¶æ®æ­¤è°ƒæ•´æœªæ¥çš„å†³ç­–ï¼Œä»è€Œç¡®ä¿ç®—æ³•é¢„æµ‹çš„å…¬å¹³æ€§ã€‚ä¸é¢„è®¾é•¿æœŸå…¬å¹³ç›®æ ‡çš„ä¼ ç»Ÿæ–¹æ³•ä¸åŒï¼Œ\"Fair Game\" æä¾›äº†ä¸€ä¸ªç‹¬ç‰¹çš„æ¡†æ¶ï¼Œä»…éœ€ä¿®æ”¹ Auditor åŠå…¶é‡åŒ–çš„åå·®ç±»å‹å³å¯å®ç°å…¬å¹³æ€§ç›®æ ‡çš„éšæ—¶é—´æ¼”è¿›ã€‚è¿™ç§è®¾è®¡æˆåŠŸæ¨¡æ‹Ÿäº†ç¤¾ä¼šä¼¦ç†ä¸æ³•å¾‹æ¡†æ¶çš„åŠ¨æ€æ¼”å˜ï¼Œä¸ºå¼€å‘éƒ¨ç½²å‰åçš„è‡ªé€‚åº” Fair ML ç³»ç»Ÿæä¾›äº†çµæ´»ä¸”å¯æ‰©å±•çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.ET",
        "cs.GT"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06443v1",
      "published_date": "2025-08-08 16:36:16 UTC",
      "updated_date": "2025-08-08 16:36:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:09:23.493408+00:00"
    },
    {
      "arxiv_id": "2508.13171v1",
      "title": "Cognitive Workspace: Active Memory Management for LLMs -- An Empirical Study of Functional Infinite Context",
      "title_zh": "è®¤çŸ¥å·¥ä½œåŒºï¼šå¤§è¯­è¨€æ¨¡å‹çš„ä¸»åŠ¨è®°å¿†ç®¡ç†â€”â€”åŠŸèƒ½æ€§æ— é™ä¸Šä¸‹æ–‡çš„å®è¯ç ”ç©¶",
      "authors": [
        "Tao An"
      ],
      "abstract": "Large Language Models (LLMs) face fundamental limitations in context management despite recent advances extending context windows to millions of tokens. We propose Cognitive Workspace, a novel paradigm that transcends traditional Retrieval-Augmented Generation (RAG) by emulating human cognitive mechanisms of external memory use. Drawing from cognitive science foundations including Baddeley's working memory model, Clark's extended mind thesis, and Hutchins' distributed cognition framework, we demonstrate that current passive retrieval systems fail to capture the dynamic, task-driven nature of human memory management. Our analysis of 2024-2025 developments reveals that while techniques like Infini-attention and StreamingLLM achieve impressive context lengths, they lack the metacognitive awareness and active planning capabilities essential for true cognitive extension. Cognitive Workspace addresses these limitations through three core innovations: (1) active memory management with deliberate information curation, (2) hierarchical cognitive buffers enabling persistent working states, and (3) task-driven context optimization that dynamically adapts to cognitive demands. Empirical validation demonstrates Cognitive Workspace achieves an average 58.6% memory reuse rate (ranging from 54-60% across different tasks) compared to 0% for traditional RAG, with 17-18% net efficiency gain despite 3.3x higher operation counts. Statistical analysis confirms these advantages with p < 0.001 and Cohen's d > 23 across multiple task types, establishing the first quantitative evidence for active memory superiority in LLM systems. We present a comprehensive theoretical framework synthesizing insights from 50+ recent papers, positioning Cognitive Workspace as a fundamental shift from information retrieval to genuine cognitive augmentation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Cognitive Workspaceï¼Œè¿™æ˜¯ä¸€ç§ä¸ºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLarge Language Models, LLMsï¼‰è®¾è®¡çš„åˆ›æ–°èŒƒå¼ï¼Œæ—¨åœ¨é€šè¿‡æ¨¡æ‹Ÿäººç±»ä¸»åŠ¨ç®¡ç†å¤–éƒ¨è®°å¿†çš„è®¤çŸ¥æœºåˆ¶ï¼Œè¶…è¶Šä¼ ç»Ÿçš„æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRetrieval-Augmented Generation, RAGï¼‰åŠè¢«åŠ¨æ£€ç´¢ç³»ç»Ÿã€‚è¯¥æ¡†æ¶å€Ÿé‰´äº†Baddeleyçš„å·¥ä½œè®°å¿†æ¨¡å‹ã€Clarkçš„å»¶å±•å¿ƒçµè®ºä»¥åŠHutchinsçš„åˆ†å¸ƒå¼è®¤çŸ¥æ¡†æ¶ï¼Œè§£å†³äº†å½“å‰é•¿ä¸Šä¸‹æ–‡æŠ€æœ¯ä¸­ç¼ºä¹å…ƒè®¤çŸ¥æ„è¯†å’Œä¸»åŠ¨è§„åˆ’èƒ½åŠ›çš„å±€é™ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºå®ç°äº†ä¸»åŠ¨è®°å¿†ç®¡ç†ã€å±‚æ¬¡åŒ–è®¤çŸ¥ç¼“å†²å™¨ä»¥åŠä»»åŠ¡é©±åŠ¨çš„ä¸Šä¸‹æ–‡ä¼˜åŒ–ï¼Œä½¿ç³»ç»Ÿèƒ½å¤ŸåŠ¨æ€é€‚åº”å¤æ‚çš„è®¤çŸ¥éœ€æ±‚ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒCognitive Workspaceå®ç°äº†å¹³å‡58.6%çš„å†…å­˜é‡ç”¨ç‡ï¼Œå¹¶åœ¨å¤šé¡¹ä»»åŠ¡ä¸­å–å¾—äº†17-18%çš„å‡€æ•ˆç‡æå‡ï¼Œå…¶æ€§èƒ½ä¼˜åŠ¿åœ¨ç»Ÿè®¡å­¦ä¸Šå…·æœ‰æ˜¾è‘—æ€§ï¼ˆp < 0.001, Cohen's d > 23ï¼‰ã€‚è¯¥ç ”ç©¶é€šè¿‡ç»¼åˆ50å¤šç¯‡è¿‘æœŸè®ºæ–‡çš„ç†è®ºæ¡†æ¶ï¼Œç¡®ç«‹äº†ä¸»åŠ¨è®°å¿†åœ¨LLMç³»ç»Ÿä¸­çš„ä¼˜è¶Šæ€§ï¼Œæ¨åŠ¨äº†ä»ä¿¡æ¯æ£€ç´¢åˆ°çœŸæ­£è®¤çŸ¥å¢å¼ºçš„èŒƒå¼è½¬å˜ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages, 1 figure, code available at https://github.com/tao-hpu/cognitive-workspace",
      "pdf_url": "https://arxiv.org/pdf/2508.13171v1",
      "published_date": "2025-08-08 16:32:47 UTC",
      "updated_date": "2025-08-08 16:32:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:09:41.897263+00:00"
    },
    {
      "arxiv_id": "2508.06435v2",
      "title": "Learning the Topic, Not the Language: How LLMs Classify Online Immigration Discourse Across Languages",
      "title_zh": "å­¦ä¹ ä¸»é¢˜è€Œéè¯­è¨€ï¼šå¤§è¯­è¨€æ¨¡å‹å¦‚ä½•å®ç°è·¨è¯­è¨€åœ¨çº¿ç§»æ°‘è¯è¯­åˆ†ç±»",
      "authors": [
        "Andrea Nasuto",
        "Stefano Maria Iacus",
        "Francisco Rowe",
        "Devika Jain"
      ],
      "abstract": "Large language models (LLMs) offer new opportunities for scalable analysis of online discourse. Yet their use in multilingual social science research remains constrained by model size, cost and linguistic bias. We develop a lightweight, open-source LLM framework using fine-tuned LLaMA 3.2-3B models to classify immigration-related tweets across 13 languages. Unlike prior work relying on BERT style models or translation pipelines, we combine topic classification with stance detection and demonstrate that LLMs fine-tuned in just one or two languages can generalize topic understanding to unseen languages. Capturing ideological nuance, however, benefits from multilingual fine-tuning. Our approach corrects pretraining biases with minimal data from under-represented languages and avoids reliance on proprietary systems. With 26-168x faster inference and over 1000x cost savings compared to commercial LLMs, our method supports real-time analysis of billions of tweets. This scale-first framework enables inclusive, reproducible research on public attitudes across linguistic and cultural contexts.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼€å‘äº†ä¸€ä¸ªè½»é‡çº§ä¸”å¼€æºçš„ Large Language Model (LLM) æ¡†æ¶ï¼Œåˆ©ç”¨å¾®è°ƒåçš„ LLaMA 3.2-3B æ¨¡å‹å¯¹ 13 ç§è¯­è¨€ä¸­ä¸ç§»æ°‘ç›¸å…³çš„æ¨æ–‡è¿›è¡Œåˆ†ç±»ã€‚è¯¥æ¡†æ¶å°† Topic Classification ä¸ Stance Detection ç›¸ç»“åˆï¼Œè¯æ˜äº†ä»…åœ¨ä¸€ç§æˆ–ä¸¤ç§è¯­è¨€ä¸­å¾®è°ƒçš„ LLMs èƒ½å¤Ÿå°†ä¸»é¢˜ç†è§£èƒ½åŠ›æ³›åŒ–è‡³æœªè§è¿‡çš„è¯­è¨€ã€‚ç ”ç©¶æŒ‡å‡ºï¼Œæ•æ‰æ„è¯†å½¢æ€å±‚é¢çš„ç»†å¾®å·®åˆ«ä»éœ€ä¾èµ– Multilingual Fine-tuningï¼Œä½†è¯¥æ–¹æ³•ä»…éœ€æå°‘é‡çš„ç‰¹å®šè¯­è¨€æ•°æ®å³å¯æœ‰æ•ˆçº æ­£é¢„è®­ç»ƒé˜¶æ®µçš„ Linguistic Biasã€‚ç›¸è¾ƒäºå•†ä¸š LLMsï¼Œè¯¥æ–¹æ¡ˆåœ¨æ¨ç†é€Ÿåº¦ä¸Šæå‡äº† 26-168 å€ï¼Œæˆæœ¬é™ä½äº† 1000 å€ä»¥ä¸Šï¼Œæ”¯æŒå¯¹æµ·é‡æ¨æ–‡çš„å®æ—¶åˆ†æã€‚è¿™ä¸€æˆæœä¸ºè·¨è¯­è¨€å’Œè·¨æ–‡åŒ–èƒŒæ™¯ä¸‹çš„ç¤¾ä¼šç§‘å­¦ç ”ç©¶æä¾›äº†ä¸€ä¸ªå¯æ‰©å±•ã€å¯å¤ç°ä¸”ä½æˆæœ¬çš„åˆ†ææ¡†æ¶ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06435v2",
      "published_date": "2025-08-08 16:23:24 UTC",
      "updated_date": "2025-12-29 08:52:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:09:35.388674+00:00"
    },
    {
      "arxiv_id": "2508.06434v2",
      "title": "CLIPin: A Non-contrastive Plug-in to CLIP for Multimodal Semantic Alignment",
      "title_zh": "CLIPinï¼šä¸€ç§ç”¨äºå¤šæ¨¡æ€è¯­ä¹‰å¯¹é½çš„ CLIP éå¯¹æ¯”å¼æ’ä»¶",
      "authors": [
        "Shengzhu Yang",
        "Jiawei Du",
        "Shuai Lu",
        "Weihang Zhang",
        "Ningli Wang",
        "Huiqi Li"
      ],
      "abstract": "Large-scale natural image-text datasets, especially those automatically collected from the web, often suffer from loose semantic alignment due to weak supervision, while medical datasets tend to have high cross-modal correlation but low content diversity. These properties pose a common challenge for contrastive language-image pretraining (CLIP): they hinder the model's ability to learn robust and generalizable representations. In this work, we propose CLIPin, a unified non-contrastive plug-in that can be seamlessly integrated into CLIP-style architectures to improve multimodal semantic alignment, providing stronger supervision and enhancing alignment robustness. Furthermore, two shared pre-projectors are designed for image and text modalities respectively to facilitate the integration of contrastive and non-contrastive learning in a parameter-compromise manner. Extensive experiments on diverse downstream tasks demonstrate the effectiveness and generality of CLIPin as a plug-and-play component compatible with various contrastive frameworks. Code is available at https://github.com/T6Yang/CLIPin.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é’ˆå¯¹å¤§è§„æ¨¡è‡ªç„¶å›¾åƒæ–‡æœ¬æ•°æ®é›†ä»¥åŠåŒ»ç–—æ•°æ®é›†ä¸­ï¼Œå¯¹æ¯”è¯­è¨€å›¾åƒé¢„è®­ç»ƒ (CLIP) æ¨¡å‹å› è¯­ä¹‰å¯¹é½æ¾æ•£æˆ–å†…å®¹å¤šæ ·æ€§ä½è€Œéš¾ä»¥å­¦ä¹ é²æ£’è¡¨å¾çš„æŒ‘æˆ˜ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº† CLIPinï¼Œè¿™æ˜¯ä¸€ç§ç»Ÿä¸€çš„éå¯¹æ¯”æ€§ (non-contrastive) æ’ä»¶ï¼Œå¯æ— ç¼é›†æˆåˆ° CLIP æ¶æ„ä¸­ä»¥æ”¹è¿›å¤šæ¨¡æ€è¯­ä¹‰å¯¹é½ã€‚è¯¥æ–¹æ³•é€šè¿‡å¼•å…¥åˆ†åˆ«ä¸ºå›¾åƒå’Œæ–‡æœ¬æ¨¡æ€è®¾è®¡çš„ä¸¤ä¸ªå…±äº«é¢„æŠ•å½±ä»ª (pre-projectors)ï¼Œä»¥å‚æ•°æŠ˜è¡·çš„æ–¹å¼å®ç°äº†å¯¹æ¯”å­¦ä¹ ä¸éå¯¹æ¯”å­¦ä¹ çš„æœ‰æ•ˆæ•´åˆã€‚ä½œä¸ºä¸€ç§å³æ’å³ç”¨çš„ç»„ä»¶ï¼ŒCLIPin ä¸ºæ¨¡å‹æä¾›äº†æ›´å¼ºçš„ç›‘ç£ä¿¡å·ï¼Œå¹¶æ˜¾è‘—å¢å¼ºäº†è·¨æ¨¡æ€å¯¹é½çš„ç¨³å¥æ€§ã€‚åœ¨å¤šç§ä¸‹æ¸¸ä»»åŠ¡ä¸Šçš„å¹¿æ³›å®éªŒè¯æ˜äº† CLIPin çš„æœ‰æ•ˆæ€§å’Œé€šç”¨æ€§ï¼Œè¯æ˜å…¶èƒ½ä¸å„ç§å¯¹æ¯”æ¡†æ¶è‰¯å¥½å…¼å®¹ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06434v2",
      "published_date": "2025-08-08 16:23:05 UTC",
      "updated_date": "2025-09-25 12:29:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:09:34.687827+00:00"
    },
    {
      "arxiv_id": "2508.06433v3",
      "title": "Memp: Exploring Agent Procedural Memory",
      "title_zh": "Mempï¼šæ™ºèƒ½ä½“ç¨‹åºæ€§è®°å¿†æ¢ç´¢",
      "authors": [
        "Runnan Fang",
        "Yuan Liang",
        "Xiaobin Wang",
        "Jialong Wu",
        "Shuofei Qiao",
        "Pengjun Xie",
        "Fei Huang",
        "Huajun Chen",
        "Ningyu Zhang"
      ],
      "abstract": "Large Language Models (LLMs) based agents excel at diverse tasks, yet they suffer from brittle procedural memory that is manually engineered or entangled in static parameters. In this work, we investigate strategies to endow agents with a learnable, updatable, and lifelong procedural memory. We propose Memp that distills past agent trajectories into both fine-grained, step-by-step instructions and higher-level, script-like abstractions, and explore the impact of different strategies for Build, Retrieval, and Update of procedural memory. Coupled with a dynamic regimen that continuously updates, corrects, and deprecates its contents, this repository evolves in lockstep with new experience. Empirical evaluation on TravelPlanner and ALFWorld shows that as the memory repository is refined, agents achieve steadily higher success rates and greater efficiency on analogous tasks. Moreover, procedural memory built from a stronger model retains its value: migrating the procedural memory to a weaker model can also yield substantial performance gains. Code is available at https://github.com/zjunlp/MemP.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¦‚ä½•ä¸ºå¤§è¯­è¨€æ¨¡å‹(LLMs)é©±åŠ¨çš„æ™ºèƒ½ä½“æ„å»ºå¯å­¦ä¹ ã€å¯æ›´æ–°ä¸”æŒä¹…çš„ç¨‹åºåŒ–è®°å¿†(Procedural Memory)ï¼Œä»¥è§£å†³ç°æœ‰æ¨¡å‹ç¨‹åºåŒ–è®°å¿†è„†å¼±ä¸”éš¾ä»¥åŠ¨æ€è°ƒæ•´çš„é—®é¢˜ã€‚ç ”ç©¶è€…æå‡ºäº†åä¸ºMemPçš„æ¡†æ¶ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿå°†æ™ºèƒ½ä½“è¿‡å»çš„æ‰§è¡Œè½¨è¿¹è’¸é¦ä¸ºç»†ç²’åº¦çš„åˆ†æ­¥æŒ‡ä»¤ä»¥åŠæ›´é«˜å±‚æ¬¡çš„è„šæœ¬åŒ–æŠ½è±¡(Script-like Abstractions)ã€‚MemPé€šè¿‡æ¢ç´¢ä¸åŒçš„æ„å»º(Build)ã€æ£€ç´¢(Retrieval)å’Œæ›´æ–°(Update)ç­–ç•¥ï¼Œå¹¶ç»“åˆåŠ¨æ€ç®¡ç†æœºåˆ¶å¯¹è®°å¿†å†…å®¹è¿›è¡ŒæŒç»­ä¼˜åŒ–ã€çº é”™å’Œå¼ƒç½®ï¼Œä½¿è®°å¿†åº“èƒ½éšç»éªŒå¢é•¿è€ŒåŒæ­¥è¿›åŒ–ã€‚åœ¨TravelPlannerå’ŒALFWorldåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œéšç€ç¨‹åºåŒ–è®°å¿†åº“çš„ä¸æ–­ç²¾ç‚¼ï¼Œæ™ºèƒ½ä½“åœ¨åŒç±»ä»»åŠ¡ä¸­çš„æˆåŠŸç‡å’Œæ‰§è¡Œæ•ˆç‡å‡æ˜¾è‘—æå‡ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜å‘ç°ä»å¼ºæ¨¡å‹ä¸­æå–çš„ç¨‹åºåŒ–è®°å¿†å…·æœ‰å¾ˆé«˜çš„ä»·å€¼ï¼Œå°†å…¶è¿ç§»è‡³æ€§èƒ½è¾ƒå¼±çš„æ¨¡å‹æ—¶åŒæ ·èƒ½å¸¦æ¥å®è´¨æ€§çš„æ€§èƒ½å¢ç›Šã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress",
      "pdf_url": "https://arxiv.org/pdf/2508.06433v3",
      "published_date": "2025-08-08 16:20:56 UTC",
      "updated_date": "2026-01-21 08:02:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:10:07.883220+00:00"
    },
    {
      "arxiv_id": "2508.06429v1",
      "title": "SPARSE Data, Rich Results: Few-Shot Semi-Supervised Learning via Class-Conditioned Image Translation",
      "title_zh": "SPARSE æ•°æ®ï¼Œä¸°ç¡•æˆæœï¼šåŸºäºç±»åˆ«æ¡ä»¶å›¾åƒç¿»è¯‘çš„å°‘æ ·æœ¬åŠç›‘ç£å­¦ä¹ ",
      "authors": [
        "Guido Manni",
        "Clemente Lauretti",
        "Loredana Zollo",
        "Paolo Soda"
      ],
      "abstract": "Deep learning has revolutionized medical imaging, but its effectiveness is severely limited by insufficient labeled training data. This paper introduces a novel GAN-based semi-supervised learning framework specifically designed for low labeled-data regimes, evaluated across settings with 5 to 50 labeled samples per class. Our approach integrates three specialized neural networks -- a generator for class-conditioned image translation, a discriminator for authenticity assessment and classification, and a dedicated classifier -- within a three-phase training framework. The method alternates between supervised training on limited labeled data and unsupervised learning that leverages abundant unlabeled images through image-to-image translation rather than generation from noise. We employ ensemble-based pseudo-labeling that combines confidence-weighted predictions from the discriminator and classifier with temporal consistency through exponential moving averaging, enabling reliable label estimation for unlabeled data. Comprehensive evaluation across eleven MedMNIST datasets demonstrates that our approach achieves statistically significant improvements over six state-of-the-art GAN-based semi-supervised methods, with particularly strong performance in the extreme 5-shot setting where the scarcity of labeled data is most challenging. The framework maintains its superiority across all evaluated settings (5, 10, 20, and 50 shots per class). Our approach offers a practical solution for medical imaging applications where annotation costs are prohibitive, enabling robust classification performance even with minimal labeled data. Code is available at https://github.com/GuidoManni/SPARSE.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŒ»ç–—å½±åƒé¢†åŸŸä¸­æ·±åº¦å­¦ä¹ å—é™äºæ ‡è®°è®­ç»ƒæ•°æ®ä¸è¶³çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºGANçš„æ–°å‹åŠç›‘ç£å­¦ä¹ (Semi-Supervised Learning)æ¡†æ¶ï¼Œä¸“é—¨è®¾è®¡ç”¨äºæ¯ç±»ä»…æœ‰5è‡³50ä¸ªæ ·æœ¬çš„æå°‘æ ·æœ¬æƒ…å¢ƒã€‚è¯¥æ¡†æ¶æ•´åˆäº†ç”¨äºç±»åˆ«æ¡ä»¶å›¾åƒç¿»è¯‘(Class-Conditioned Image Translation)çš„ç”Ÿæˆå™¨ã€è´Ÿè´£çœŸå®æ€§è¯„ä¼°ä¸åˆ†ç±»çš„åˆ¤åˆ«å™¨ä»¥åŠä¸“ç”¨åˆ†ç±»å™¨ï¼Œå¹¶åœ¨ä¸‰é˜¶æ®µè®­ç»ƒæµç¨‹ä¸­é€šè¿‡å›¾åƒåˆ°å›¾åƒ(Image-to-Image)çš„ç¿»è¯‘è€Œéå™ªå£°ç”Ÿæˆæ¥å……åˆ†åˆ©ç”¨æ— æ ‡è®°æ•°æ®ã€‚ç ”ç©¶é‡‡ç”¨äº†åŸºäºé›†æˆ(Ensemble)çš„ä¼ªæ ‡ç­¾(Pseudo-Labeling)æœºåˆ¶ï¼Œç»“åˆç½®ä¿¡åº¦åŠ æƒé¢„æµ‹ä¸æŒ‡æ•°ç§»åŠ¨å¹³å‡(Exponential Moving Averaging)çš„æ—¶é—´ä¸€è‡´æ€§ï¼Œä»è€Œå®ç°å¯¹æ— æ ‡è®°æ•°æ®çš„å¯é æ ‡ç­¾ä¼°è®¡ã€‚åœ¨11ä¸ªMedMNISTæ•°æ®é›†ä¸Šçš„å…¨é¢è¯„ä¼°æ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨æç«¯çš„5-shotè®¾ç½®ä¸‹è¡¨ç°å°¤ä¸ºå“è¶Šï¼Œæ€§èƒ½æ˜¾è‘—ä¼˜äº6ç§ç°æœ‰çš„å…ˆè¿›GANåŠç›‘ç£æ¨¡å‹ã€‚è¯¥æ–¹æ³•ä¸ºæ ‡æ³¨æˆæœ¬é«˜æ˜‚çš„åŒ»ç–—å½±åƒåº”ç”¨æä¾›äº†ä¸€ç§å®ç”¨çš„è§£å†³æ–¹æ¡ˆï¼Œè¯æ˜äº†åœ¨æ ‡è®°æ•°æ®æå°‘çš„æƒ…å†µä¸‹ä¾ç„¶èƒ½å®ç°ç¨³å¥çš„é«˜æ€§èƒ½åˆ†ç±»ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06429v1",
      "published_date": "2025-08-08 16:16:43 UTC",
      "updated_date": "2025-08-08 16:16:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:10:13.591123+00:00"
    },
    {
      "arxiv_id": "2508.06426v1",
      "title": "Shortcut Learning in Generalist Robot Policies: The Role of Dataset Diversity and Fragmentation",
      "title_zh": "é€šç”¨æœºå™¨äººç­–ç•¥ä¸­çš„æ·å¾„å­¦ä¹ ï¼šæ•°æ®é›†å¤šæ ·æ€§ä¸ç¢ç‰‡åŒ–çš„ä½œç”¨",
      "authors": [
        "Youguang Xing",
        "Xu Luo",
        "Junlin Xie",
        "Lianli Gao",
        "Hengtao Shen",
        "Jingkuan Song"
      ],
      "abstract": "Generalist robot policies trained on large-scale datasets such as Open X-Embodiment (OXE) demonstrate strong performance across a wide range of tasks. However, they often struggle to generalize beyond the distribution of their training data. In this paper, we investigate the underlying cause of this limited generalization capability. We identify shortcut learning -- the reliance on task-irrelevant features -- as a key impediment to generalization. Through comprehensive theoretical and empirical analysis, we uncover two primary contributors to shortcut learning: (1) limited diversity within individual sub-datasets, and (2) significant distributional disparities across sub-datasets, leading to dataset fragmentation. These issues arise from the inherent structure of large-scale datasets like OXE, which are typically composed of multiple sub-datasets collected independently across varied environments and embodiments. Our findings provide critical insights into dataset collection strategies that can reduce shortcut learning and enhance the generalization ability of generalist robot policies. Moreover, in scenarios where acquiring new large-scale data is impractical, we demonstrate that carefully selected robotic data augmentation strategies can effectively reduce shortcut learning in existing offline datasets, thereby improving generalization capabilities of generalist robot policies, e.g., $Ï€_0$, in both simulation and real-world environments. More information at https://lucky-light-sun.github.io/proj/shortcut-learning-in-grps/.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†é€šç”¨æœºå™¨äººç­–ç•¥(Generalist Robot Policies)åœ¨å¤„ç†å¦‚Open X-Embodiment (OXE)ç­‰å¤§è§„æ¨¡æ•°æ®é›†æ—¶ï¼Œæ³›åŒ–èƒ½åŠ›å—é™çš„æ ¹æœ¬åŸå› ï¼Œå¹¶å°†å…¶å½’å› äºæ¨¡å‹å¯¹ä»»åŠ¡æ— å…³ç‰¹å¾çš„ä¾èµ–ï¼Œå³æ·å¾„å­¦ä¹ (Shortcut Learning)ã€‚é€šè¿‡ç†è®ºå’Œå®è¯åˆ†æï¼Œæœ¬æ–‡æ­ç¤ºäº†å¯¼è‡´æ·å¾„å­¦ä¹ çš„ä¸¤ä¸ªä¸»è¦è¯±å› ï¼šå•ä¸ªå­æ•°æ®é›†å†…éƒ¨å¤šæ ·æ€§ä¸è¶³ï¼Œä»¥åŠå­æ•°æ®é›†é—´æ˜¾è‘—åˆ†å¸ƒå·®å¼‚å¯¼è‡´çš„è®­ç»ƒæ•°æ®ç¢ç‰‡åŒ–(Dataset Fragmentation)ã€‚ç ”ç©¶æŒ‡å‡ºï¼Œè¿™äº›é—®é¢˜æºäºå¤§è§„æ¨¡æœºå™¨äººæ•°æ®è·¨ç¯å¢ƒå’Œè·¨å…·èº«(Embodiments)ç‹¬ç«‹é‡‡é›†çš„å›ºæœ‰ç»“æ„ç‰¹æ€§ã€‚é’ˆå¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œä½œè€…æå‡ºäº†ä¸€å¥—ç²¾å¿ƒé€‰æ‹©çš„æœºå™¨äººæ•°æ®å¢å¼º(Data Augmentation)ç­–ç•¥ï¼Œæ—¨åœ¨ä¸å¢åŠ æ–°æ•°æ®çš„å‰æä¸‹æœ‰æ•ˆæŠ‘åˆ¶ç¦»çº¿æ•°æ®é›†ä¸­çš„æ·å¾„å­¦ä¹ ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—æå‡äº†é€šç”¨æœºå™¨äººç­–ç•¥ï¼ˆå¦‚$\\pi_0$ï¼‰åœ¨ä»¿çœŸå’Œç°å®ç¯å¢ƒä¸­çš„æ³›åŒ–æ€§èƒ½ï¼Œä¸ºä¼˜åŒ–æœºå™¨äººæ•°æ®é‡‡é›†ä¸è®­ç»ƒæä¾›äº†å…³é”®æ´å¯Ÿã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "CoRL 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.06426v1",
      "published_date": "2025-08-08 16:14:01 UTC",
      "updated_date": "2025-08-08 16:14:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:10:25.052843+00:00"
    },
    {
      "arxiv_id": "2508.09201v3",
      "title": "Learning to Detect Unknown Jailbreak Attacks in Large Vision-Language Models",
      "title_zh": "å­¦ä¹ æ£€æµ‹å¤§è§†è§‰è¯­è¨€æ¨¡å‹ä¸­çš„æœªçŸ¥è¶Šç‹±æ”»å‡»",
      "authors": [
        "Shuang Liang",
        "Zhihao Xu",
        "Jialing Tao",
        "Hui Xue",
        "Xiting Wang"
      ],
      "abstract": "Despite extensive alignment efforts, Large Vision-Language Models (LVLMs) remain vulnerable to jailbreak attacks, posing serious safety risks. To address this, existing detection methods either learn attack-specific parameters, which hinders generalization to unseen attacks, or rely on heuristically sound principles, which limit accuracy and efficiency. To overcome these limitations, we propose Learning to Detect (LoD), a general framework that accurately detects unknown jailbreak attacks by shifting the focus from attack-specific learning to task-specific learning. This framework includes a Multi-modal Safety Concept Activation Vector module for safety-oriented representation learning and a Safety Pattern Auto-Encoder module for unsupervised attack classification. Extensive experiments show that our method achieves consistently higher detection AUROC on diverse unknown attacks while improving efficiency. The code is available at https://anonymous.4open.science/r/Learning-to-Detect-51CB.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Large Vision-Language Models (LVLMs) æ˜“å— Jailbreak Attacks æ”»å‡»ä¸”ç°æœ‰æ£€æµ‹æ–¹æ³•æ³›åŒ–èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ï¼Œæå‡ºäº†åä¸º LoD (Learning to Detect) çš„é€šç”¨æ£€æµ‹æ¡†æ¶ã€‚LoD é€šè¿‡å°†å­¦ä¹ é‡å¿ƒä»ç‰¹å®šæ”»å‡»æ¨¡å¼è½¬å‘ç‰¹å®šä»»åŠ¡ç‰¹å¾ï¼Œæœ‰æ•ˆæå‡äº†å¯¹æœªçŸ¥æ”»å‡»çš„è¯†åˆ«èƒ½åŠ›ã€‚è¯¥æ¡†æ¶é›†æˆäº† Multi-modal Safety Concept Activation Vector æ¨¡å—ä»¥å¼ºåŒ–é¢å‘å®‰å…¨çš„å¤šæ¨¡æ€è¡¨å¾å­¦ä¹ ï¼Œå¹¶åˆ©ç”¨ Safety Pattern Auto-Encoder æ¨¡å—å®ç°æ— ç›‘ç£çš„æ”»å‡»åˆ†ç±»ã€‚å¤§é‡å®éªŒè¯æ˜ï¼ŒLoD åœ¨å¤„ç†å¤šç§æœªçŸ¥æ”»å‡»æ—¶ä¸ä»…åœ¨æ£€æµ‹ AUROC æŒ‡æ ‡ä¸ŠæŒç»­ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œè¿˜æ˜¾è‘—æé«˜äº†æ£€æµ‹æ•ˆç‡ï¼Œä¸º LVLMs çš„å®‰å…¨æ€§ä¿éšœæä¾›äº†æ›´å…·æ³›åŒ–æ€§çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CR",
      "comment": "16 pages; Previously this version appeared as arXiv:2510.15430 which was submitted as a new work by accident",
      "pdf_url": "https://arxiv.org/pdf/2508.09201v3",
      "published_date": "2025-08-08 16:13:28 UTC",
      "updated_date": "2025-11-20 15:51:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:10:15.086527+00:00"
    },
    {
      "arxiv_id": "2508.06411v1",
      "title": "Dimensional Characterization and Pathway Modeling for Catastrophic AI Risks",
      "title_zh": "ç¾éš¾æ€§äººå·¥æ™ºèƒ½é£é™©çš„ç»´åº¦è¡¨å¾ä¸è·¯å¾„å»ºæ¨¡",
      "authors": [
        "Ze Shen Chin"
      ],
      "abstract": "Although discourse around the risks of Artificial Intelligence (AI) has grown, it often lacks a comprehensive, multidimensional framework, and concrete causal pathways mapping hazard to harm. This paper aims to bridge this gap by examining six commonly discussed AI catastrophic risks: CBRN, cyber offense, sudden loss of control, gradual loss of control, environmental risk, and geopolitical risk. First, we characterize these risks across seven key dimensions, namely intent, competency, entity, polarity, linearity, reach, and order. Next, we conduct risk pathway modeling by mapping step-by-step progressions from the initial hazard to the resulting harms. The dimensional approach supports systematic risk identification and generalizable mitigation strategies, while risk pathway models help identify scenario-specific interventions. Together, these methods offer a more structured and actionable foundation for managing catastrophic AI risks across the value chain.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å½“å‰äººå·¥æ™ºèƒ½(AI)ç¾éš¾æ€§é£é™©è®¨è®ºä¸­ç¼ºä¹å…¨é¢å¤šç»´æ¡†æ¶å’Œæ˜ç¡®å› æœè·¯å¾„çš„é—®é¢˜ï¼Œæ·±å…¥æ¢è®¨äº†CBRNã€ç½‘ç»œæ”»å‡»(cyber offense)ã€çªç„¶å¤±å»æ§åˆ¶(sudden loss of control)ã€é€æ¸å¤±å»æ§åˆ¶(gradual loss of control)ã€ç¯å¢ƒé£é™©å’Œåœ°ç¼˜æ”¿æ²»é£é™©ç­‰å…­å¤§æ ¸å¿ƒé£é™©ã€‚è®ºæ–‡é¦–å…ˆé€šè¿‡æ„å›¾(intent)ã€èƒ½åŠ›(competency)ã€å®ä½“(entity)ã€ææ€§(polarity)ã€çº¿æ€§(linearity)ã€èŒƒå›´(reach)å’Œé˜¶æ•°(order)ä¸ƒä¸ªå…³é”®ç»´åº¦å¯¹è¿™äº›é£é™©è¿›è¡Œç‰¹å¾åŒ–æè¿°ï¼Œå¹¶è¿›ä¸€æ­¥æ„å»ºäº†é£é™©è·¯å¾„æ¨¡å‹(risk pathway modeling)ï¼Œè¯¦ç»†ç»˜åˆ¶äº†ä»åˆå§‹å±å®³åˆ°æœ€ç»ˆæŸå®³çš„é€æ­¥æ¼”è¿›è¿‡ç¨‹ã€‚è¿™ç§å¤šç»´è¡¨å¾æ–¹æ³•æ”¯æŒç³»ç»Ÿçš„é£é™©è¯†åˆ«ä¸é€šç”¨ç¼“è§£ç­–ç•¥çš„åˆ¶å®šï¼Œè€Œè·¯å¾„æ¨¡å‹åˆ™æœ‰åŠ©äºè¯†åˆ«ç‰¹å®šåœºæ™¯ä¸‹çš„å¹²é¢„æ‰‹æ®µã€‚é€šè¿‡ç»“åˆè¿™ä¸¤ç§æ–¹æ³•ï¼Œè¯¥ç ”ç©¶ä¸ºåœ¨æ•´ä¸ªä»·å€¼é“¾ä¸­ç®¡ç†AIç¾éš¾æ€§é£é™©æä¾›äº†ä¸€ä¸ªæ›´åŠ ç»“æ„åŒ–ä¸”å…·å¤‡å¯æ“ä½œæ€§çš„ç†è®ºåŸºç¡€ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "24 pages including references, 6 figures. To be presented in Technical AI Governance Forum 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.06411v1",
      "published_date": "2025-08-08 15:56:05 UTC",
      "updated_date": "2025-08-08 15:56:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:10:19.991350+00:00"
    },
    {
      "arxiv_id": "2508.06407v2",
      "title": "A Classification-Aware Super-Resolution Framework for Ship Targets in SAR Imagery",
      "title_zh": "é¢å‘ SAR å›¾åƒèˆ°èˆ¹ç›®æ ‡çš„åˆ†ç±»æ„ŸçŸ¥è¶…åˆ†è¾¨ç‡æ¡†æ¶",
      "authors": [
        "Ch Muhammad Awais",
        "Marco Reggiannini",
        "Davide Moroni",
        "Oktay Karakus"
      ],
      "abstract": "High-resolution imagery plays a critical role in improving the performance of visual recognition tasks such as classification, detection, and segmentation. In many domains, including remote sensing and surveillance, low-resolution images can limit the accuracy of automated analysis. To address this, super-resolution (SR) techniques have been widely adopted to attempt to reconstruct high-resolution images from low-resolution inputs. Related traditional approaches focus solely on enhancing image quality based on pixel-level metrics, leaving the relationship between super-resolved image fidelity and downstream classification performance largely underexplored. This raises a key question: can integrating classification objectives directly into the super-resolution process further improve classification accuracy? In this paper, we try to respond to this question by investigating the relationship between super-resolution and classification through the deployment of a specialised algorithmic strategy. We propose a novel methodology that increases the resolution of synthetic aperture radar imagery by optimising loss functions that account for both image quality and classification performance. Our approach improves image quality, as measured by scientifically ascertained image quality indicators, while also enhancing classification accuracy.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªé’ˆå¯¹åˆæˆå­”å¾„é›·è¾¾(SAR)å›¾åƒä¸­èˆ°èˆ¹ç›®æ ‡çš„åˆ†ç±»æ„ŸçŸ¥è¶…åˆ†è¾¨ç‡(Classification-Aware Super-Resolution)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿè¶…åˆ†è¾¨ç‡(SR)æŠ€æœ¯ä»…å…³æ³¨åƒç´ çº§å›¾åƒè´¨é‡è€Œå¿½è§†ä¸‹æ¸¸åˆ†ç±»æ€§èƒ½çš„é—®é¢˜ã€‚é€šè¿‡éƒ¨ç½²ä¸“é—¨çš„ç®—æ³•ç­–ç•¥ï¼Œè¯¥ç ”ç©¶æ·±å…¥æ¢è®¨äº†å›¾åƒé‡å»ºä¿çœŸåº¦ä¸ä¸‹æ¸¸åˆ†ç±»å‡†ç¡®ç‡ä¹‹é—´çš„å†…åœ¨è”ç³»ã€‚æ‰€æå‡ºçš„æ–°é¢–æ–¹æ³•é€šè¿‡ä¼˜åŒ–åŒæ—¶å…¼é¡¾å›¾åƒè´¨é‡æŒ‡æ ‡å’Œåˆ†ç±»æ€§èƒ½çš„æŸå¤±å‡½æ•°(loss functions)ï¼Œå®ç°äº†å¯¹ä½åˆ†è¾¨ç‡SARå›¾åƒçš„æœ‰æ•ˆé‡å»ºä¸å¢å¼ºã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ¡†æ¶åœ¨æ”¹å–„ç§‘å­¦è¯„ä¼°çš„å›¾åƒè´¨é‡æŒ‡æ ‡çš„åŒæ—¶ï¼Œæ˜¾è‘—å¢å¼ºäº†ç›®æ ‡çš„åˆ†ç±»ç²¾åº¦ã€‚è¯¥ç ”ç©¶æˆåŠŸéªŒè¯äº†å°†åˆ†ç±»ç›®æ ‡ç›´æ¥é›†æˆåˆ°è¶…åˆ†è¾¨ç‡è¿‡ç¨‹ä¸­å¯¹äºæå‡è‡ªåŠ¨åŒ–åˆ†æå‡†ç¡®æ€§çš„é‡è¦ä»·å€¼ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06407v2",
      "published_date": "2025-08-08 15:50:40 UTC",
      "updated_date": "2026-01-16 15:13:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:10:31.940849+00:00"
    },
    {
      "arxiv_id": "2508.06401v3",
      "title": "A Systematic Literature Review of Retrieval-Augmented Generation: Techniques, Metrics, and Challenges",
      "title_zh": "æ£€ç´¢å¢å¼ºç”Ÿæˆç³»ç»Ÿæ–‡çŒ®ç»¼è¿°ï¼šæŠ€æœ¯ã€æŒ‡æ ‡ä¸æŒ‘æˆ˜",
      "authors": [
        "Andrew Brown",
        "Muhammad Roman",
        "Barry Devereux"
      ],
      "abstract": "This systematic review of the research literature on retrieval-augmented generation (RAG) provides a focused analysis of the most highly cited studies published between 2020 and May 2025. A total of 128 articles met our inclusion criteria. The records were retrieved from ACM Digital Library, IEEE Xplore, Scopus, ScienceDirect, and the Digital Bibliography and Library Project (DBLP). RAG couples a neural retriever with a generative language model, grounding output in up-to-date, non-parametric memory while retaining the semantic generalisation stored in model weights. Guided by the PRISMA 2020 framework, we (i) specify explicit inclusion and exclusion criteria based on citation count and research questions, (ii) catalogue datasets, architectures, and evaluation practices, and (iii) synthesise empirical evidence on the effectiveness and limitations of RAG. To mitigate citation-lag bias, we applied a lower citation-count threshold to papers published in 2025 so that emerging breakthroughs with naturally fewer citations were still captured. This review clarifies the current research landscape, highlights methodological gaps, and charts priority directions for future research.",
      "tldr_zh": "è¿™é¡¹ç³»ç»Ÿæ€§ç»¼è¿°å¯¹æ£€ç´¢å¢å¼ºç”Ÿæˆ(Retrieval-Augmented Generation, RAG)é¢†åŸŸçš„å­¦æœ¯æ–‡çŒ®è¿›è¡Œäº†æ·±å…¥åˆ†æï¼Œæ¶µç›–äº†2020å¹´è‡³2025å¹´5æœˆæœŸé—´è¢«å¼•ç”¨é¢‘æ¬¡æœ€é«˜çš„128ç¯‡å…³é”®ç ”ç©¶ã€‚ç ”ç©¶éµå¾ªPRISMA 2020æ¡†æ¶ï¼Œä»ACM Digital Libraryã€IEEE Xploreå’ŒScopusç­‰æ ¸å¿ƒæ•°æ®åº“æ£€ç´¢è®°å½•ï¼Œç¡®ä¿äº†åˆ†æçš„ä¸¥è°¨æ€§ã€‚RAGæŠ€æœ¯é€šè¿‡å°†ç¥ç»æ£€ç´¢å™¨ä¸ç”Ÿæˆè¯­è¨€æ¨¡å‹ç›¸ç»“åˆï¼Œå°†è¾“å‡ºå»ºç«‹åœ¨å®æ—¶ã€éå‚æ•°åŒ–å†…å­˜ä¹‹ä¸Šï¼ŒåŒæ—¶ä¿ç•™äº†æ¨¡å‹æƒé‡ä¸­çš„è¯­ä¹‰æ³›åŒ–èƒ½åŠ›ã€‚è¯¥ç»¼è¿°ç³»ç»Ÿåœ°æ¢³ç†äº†ç›¸å…³æ•°æ®é›†ã€æ¶æ„(Architectures)å’Œè¯„ä¼°å®è·µ(Evaluation Practices)ï¼Œå¹¶ç»¼åˆäº†å…³äºRAGæœ‰æ•ˆæ€§åŠå…¶å±€é™æ€§çš„å®è¯è¯æ®ã€‚ä¸ºäº†ç¼“è§£å¼•ç”¨æ»ååå·®(Citation-lag Bias)ï¼Œç ”ç©¶å¯¹2025å¹´å‘è¡¨çš„è®ºæ–‡åº”ç”¨äº†è¾ƒä½çš„å¼•ç”¨é˜ˆå€¼ï¼Œä»¥æ•æ‰æ–°å…´çš„çªç ´æ€§æˆæœã€‚è¿™ç¯‡ç»¼è¿°æ¾„æ¸…äº†å½“å‰çš„ç ”ç©¶ç°çŠ¶ï¼ŒæŒ‡å‡ºäº†æ–¹æ³•è®ºä¸Šçš„ç©ºç™½ï¼Œå¹¶ä¸ºæœªæ¥çš„ç ”ç©¶æ–¹å‘åˆ¶å®šäº†ä¼˜å…ˆè·¯çº¿å›¾ã€‚",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "primary_category": "cs.DL",
      "comment": "58 page",
      "pdf_url": "https://arxiv.org/pdf/2508.06401v3",
      "published_date": "2025-08-08 15:37:14 UTC",
      "updated_date": "2025-09-09 16:35:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:10:31.646232+00:00"
    },
    {
      "arxiv_id": "2508.06393v1",
      "title": "Robust Target Speaker Diarization and Separation via Augmented Speaker Embedding Sampling",
      "title_zh": "åŸºäºå¢å¼ºè¯´è¯äººåµŒå…¥é‡‡æ ·çš„é²æ£’ç›®æ ‡è¯´è¯äººæ—¥å¿—ä¸åˆ†ç¦»",
      "authors": [
        "Md Asif Jalal",
        "Luca Remaggi",
        "Vasileios Moschopoulos",
        "Thanasis Kotsiopoulos",
        "Vandana Rajan",
        "Karthikeyan Saravanan",
        "Anastasis Drosou",
        "Junho Heo",
        "Hyuk Oh",
        "Seokyeong Jeong"
      ],
      "abstract": "Traditional speech separation and speaker diarization approaches rely on prior knowledge of target speakers or a predetermined number of participants in audio signals. To address these limitations, recent advances focus on developing enrollment-free methods capable of identifying targets without explicit speaker labeling. This work introduces a new approach to train simultaneous speech separation and diarization using automatic identification of target speaker embeddings, within mixtures. Our proposed model employs a dual-stage training pipeline designed to learn robust speaker representation features that are resilient to background noise interference. Furthermore, we present an overlapping spectral loss function specifically tailored for enhancing diarization accuracy during overlapped speech frames. Experimental results show significant performance gains compared to the current SOTA baseline, achieving 71% relative improvement in DER and 69% in cpWER.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¼ ç»Ÿè¯­éŸ³åˆ†ç¦»å’Œè¯´è¯äººæ—¥å¿—(Speaker Diarization)ä¾èµ–å…ˆéªŒçŸ¥è¯†æˆ–é¢„è®¾äººæ•°çš„å±€é™æ€§ï¼Œæå‡ºäº†ä¸€ç§é€šè¿‡å¢å¼ºè¯´è¯äººåµŒå…¥é‡‡æ ·å®ç°é²æ£’ç›®æ ‡è¯´è¯äººæ—¥å¿—ä¸åˆ†ç¦»çš„æ–°æ–¹æ³•ã€‚è¯¥æ–¹æ³•å®ç°äº†æ— éœ€æ³¨å†Œ(Enrollment-free)çš„è¯†åˆ«æ¨¡å¼ï¼Œèƒ½å¤Ÿä»æ··åˆéŸ³é¢‘ä¸­è‡ªåŠ¨è¯†åˆ«ç›®æ ‡è¯´è¯äººåµŒå…¥(Speaker Embeddings)ã€‚æ¨¡å‹é‡‡ç”¨äº†åŒé˜¶æ®µè®­ç»ƒæµæ°´çº¿(Dual-stage training pipeline)ï¼Œæ—¨åœ¨å­¦ä¹ å¯¹èƒŒæ™¯å™ªå£°å…·æœ‰å¼ºæŠ—å¹²æ‰°èƒ½åŠ›çš„ç¨³å¥è¯´è¯äººè¡¨ç¤ºç‰¹å¾ã€‚æ­¤å¤–ï¼Œç ”ç©¶å¼•å…¥äº†ä¸“é—¨è®¾è®¡çš„é‡å é¢‘è°±æŸå¤±å‡½æ•°(Overlapping spectral loss function)ï¼Œæ˜¾è‘—æå‡äº†é‡å è¯­éŸ³å¸§çš„æ—¥å¿—å‡†ç¡®åº¦ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ç›¸æ¯”ç°æœ‰SOTAåŸºå‡†åœ¨DERå’ŒcpWERæŒ‡æ ‡ä¸Šåˆ†åˆ«å®ç°äº†71%å’Œ69%çš„ç›¸å¯¹æå‡ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted to Interspeech 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.06393v1",
      "published_date": "2025-08-08 15:24:10 UTC",
      "updated_date": "2025-08-08 15:24:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:10:29.056626+00:00"
    },
    {
      "arxiv_id": "2508.06389v2",
      "title": "Identity Increases Stability in Neural Cellular Automata",
      "title_zh": "æ ‡è¯†å¢å¼ºç¥ç»ç»†èƒè‡ªåŠ¨æœºçš„ç¨³å®šæ€§",
      "authors": [
        "James Stovold"
      ],
      "abstract": "Neural Cellular Automata (NCAs) offer a way to study the growth of two-dimensional artificial organisms from a single seed cell. From the outset, NCA-grown organisms have had issues with stability, their natural boundary often breaking down and exhibiting tumour-like growth or failing to maintain the expected shape. In this paper, we present a method for improving the stability of NCA-grown organisms by introducing an 'identity' layer with simple constraints during training.\n  Results show that NCAs grown in close proximity are more stable compared with the original NCA model. Moreover, only a single identity value is required to achieve this increase in stability. We observe emergent movement from the stable organisms, with increasing prevalence for models with multiple identity values.\n  This work lays the foundation for further study of the interaction between NCA-grown organisms, paving the way for studying social interaction at a cellular level in artificial organisms.\n  Code/Videos available at: https://github.com/jstovold/ALIFE2025",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç¥ç»ç½‘ç»œç»†èƒè‡ªåŠ¨æœº (Neural Cellular Automata, NCAs) åœ¨ä»å•ä¸€ç§å­ç»†èƒç”Ÿé•¿äºŒç»´äººå·¥ç”Ÿç‰©æ—¶é¢ä¸´çš„ç¨³å®šæ€§ä¸è¶³ã€è¾¹ç•Œå´©æºƒåŠè‚¿ç˜¤åŒ–ç”Ÿé•¿ç­‰é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åœ¨è®­ç»ƒä¸­å¼•å…¥å¸¦æœ‰ç®€å•çº¦æŸçš„ identity å±‚æ¥æé«˜ç¨³å®šæ€§çš„æ–¹æ³•ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åŸ¹è‚²å‡ºçš„ç”Ÿç‰©å³ä½¿åœ¨è¿‘è·ç¦»æ¥è§¦æ—¶ä¹Ÿæ¯”åŸå§‹ NCA æ¨¡å‹æ›´å…·ç¨³å®šæ€§ï¼Œä¸”ä»…éœ€å•ä¸ª identity å€¼å³å¯æ˜¾è‘—æå‡ç¨³å®šæ€§ã€‚ç ”ç©¶è¿˜è¿›ä¸€æ­¥è§‚å¯Ÿåˆ°äº†ç¨³å®šç”Ÿç‰©ä¸­å‡ºç°çš„çªç°è¿åŠ¨è¡Œä¸º (emergent movement)ï¼Œä¸”è¿™ç§ç°è±¡åœ¨å…·æœ‰å¤šä¸ª identity å€¼çš„æ¨¡å‹ä¸­æ›´ä¸ºæ™®éã€‚è¿™é¡¹å·¥ä½œä¸ºç ”ç©¶ NCA ç”Ÿé•¿ç”Ÿç‰©é—´çš„ç›¸äº’ä½œç”¨å¥ å®šäº†åŸºç¡€ï¼Œå¹¶ä¸ºåœ¨ç»†èƒå±‚é¢æ¢è®¨äººå·¥ç”Ÿç‰©çš„ç¤¾ä¼šäº’åŠ¨ (social interaction) é“ºå¹³äº†é“è·¯ã€‚",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "Accepted to ALIFE 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.06389v2",
      "published_date": "2025-08-08 15:18:01 UTC",
      "updated_date": "2025-11-03 16:04:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:10:34.655981+00:00"
    },
    {
      "arxiv_id": "2508.06387v2",
      "title": "End-to-End Text-to-SQL with Dataset Selection: Leveraging LLMs for Adaptive Query Generation",
      "title_zh": "ç»“åˆæ•°æ®é›†é€‰æ‹©çš„ç«¯åˆ°ç«¯ Text-to-SQLï¼šåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹å®ç°è‡ªé€‚åº”æŸ¥è¯¢ç”Ÿæˆ",
      "authors": [
        "Anurag Tripathi",
        "Vaibhav Patle",
        "Abhinav Jain",
        "Ayush Pundir",
        "Sairam Menon",
        "Ajeet Kumar Singh",
        "Dorien Herremans"
      ],
      "abstract": "Text-to-SQL bridges the gap between natural language and structured database language, thus allowing non-technical users to easily query databases. Traditional approaches model text-to-SQL as a direct translation task, where a given Natural Language Query (NLQ) is mapped to an SQL command. Recent advances in large language models (LLMs) have significantly improved translation accuracy, however, these methods all require that the target database is pre-specified. This becomes problematic in scenarios with multiple extensive databases, where identifying the correct database becomes a crucial yet overlooked step. In this paper, we propose a three-stage end-to-end text-to-SQL framework to identify the user's intended database before generating SQL queries. Our approach leverages LLMs and prompt engineering to extract implicit information from natural language queries (NLQs) in the form of a ruleset. We then train a large db\\_id prediction model, which includes a RoBERTa-based finetuned encoder, to predict the correct Database identifier (db\\_id) based on both the NLQ and the LLM-generated rules. Finally, we refine the generated SQL by using critic agents to correct errors. Experimental results demonstrate that our framework outperforms the current state-of-the-art models in both database intent prediction and SQL generation accuracy.",
      "tldr_zh": "ä¼ ç»Ÿçš„ Text-to-SQL æ–¹æ³•é€šå¸¸å‡è®¾ç›®æ ‡æ•°æ®åº“æ˜¯é¢„å…ˆæŒ‡å®šçš„ï¼Œä½†åœ¨åŒ…å«å¤šä¸ªå¤§å‹æ•°æ®åº“çš„å®é™…åœºæ™¯ä¸­ï¼Œå‡†ç¡®è¯†åˆ«ç›®æ ‡æ•°æ®åº“æ˜¯ä¸€ä¸ªè‡³å…³é‡è¦å´å¸¸è¢«å¿½è§†çš„æŒ‘æˆ˜ã€‚è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªä¸‰é˜¶æ®µçš„ç«¯åˆ°ç«¯ Text-to-SQL æ¡†æ¶ï¼Œé€šè¿‡åœ¨ç”ŸæˆæŸ¥è¯¢å‰å¢åŠ æ•°æ®åº“é€‰æ‹©ç¯èŠ‚æ¥å®ç°è‡ªé€‚åº”çš„ SQL ç”Ÿæˆã€‚è¯¥æ¡†æ¶é¦–å…ˆåˆ©ç”¨ LLMs å’Œ Prompt Engineering ä»è‡ªç„¶è¯­è¨€æŸ¥è¯¢ (NLQs) ä¸­æå–éšå«ä¿¡æ¯å¹¶æ„å»ºè§„åˆ™é›† (ruleset)ã€‚æ¥ç€ï¼Œç ”ç©¶è€…è®­ç»ƒäº†ä¸€ä¸ªé›†æˆäº† RoBERTa å¾®è°ƒç¼–ç å™¨çš„ db\\_id é¢„æµ‹æ¨¡å‹ï¼Œåˆ©ç”¨ NLQ å’Œæå–çš„è§„åˆ™ç²¾å‡†è¯†åˆ«ç›®æ ‡æ•°æ®åº“ã€‚æœ€åï¼Œç³»ç»Ÿå¼•å…¥è¯„è®ºæ™ºèƒ½ä½“ (critic agents) å¯¹ç”Ÿæˆçš„ SQL è¯­å¥è¿›è¡Œé”™è¯¯ä¿®æ­£ä¸ç²¾ç‚¼ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ¡†æ¶åœ¨æ•°æ®åº“æ„å›¾é¢„æµ‹å’Œ SQL ç”Ÿæˆå‡†ç¡®ç‡ä¸Šå‡è¶…è¶Šäº†ç°æœ‰çš„ SOTA æ¨¡å‹ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted in IJCNN25",
      "pdf_url": "https://arxiv.org/pdf/2508.06387v2",
      "published_date": "2025-08-08 15:16:36 UTC",
      "updated_date": "2025-08-11 04:36:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:10:45.689985+00:00"
    },
    {
      "arxiv_id": "2508.06372v3",
      "title": "SpeakerLM: End-to-End Versatile Speaker Diarization and Recognition with Multimodal Large Language Models",
      "title_zh": "SpeakerLMï¼šåŸºäºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„ç«¯åˆ°ç«¯é€šç”¨è¯´è¯äººæ—¥å¿—ä¸è¯†åˆ«",
      "authors": [
        "Han Yin",
        "Yafeng Chen",
        "Chong Deng",
        "Luyao Cheng",
        "Hui Wang",
        "Chao-Hong Tan",
        "Qian Chen",
        "Wen Wang",
        "Xiangang Li"
      ],
      "abstract": "The Speaker Diarization and Recognition (SDR) task aims to predict \"who spoke when and what\" within an audio clip, which is a crucial task in various real-world multi-speaker scenarios such as meeting transcription and dialogue systems. Existing SDR systems typically adopt a cascaded framework, combining multiple modules such as speaker diarization (SD) and automatic speech recognition (ASR). The cascaded systems suffer from several limitations, such as error propagation, difficulty in handling overlapping speech, and lack of joint optimization for exploring the synergy between SD and ASR tasks. To address these limitations, we introduce SpeakerLM, a unified multimodal large language model for SDR that jointly performs SD and ASR in an end-to-end manner. Moreover, to facilitate diverse real-world scenarios, we incorporate a flexible speaker registration mechanism into SpeakerLM, enabling SDR under different speaker registration settings. SpeakerLM is progressively developed with a multi-stage training strategy on large-scale real data. Extensive experiments show that SpeakerLM demonstrates strong data scaling capability and generalizability, outperforming state-of-the-art cascaded baselines on both in-domain and out-of-domain public SDR benchmarks. Furthermore, experimental results show that the proposed speaker registration mechanism effectively ensures robust SDR performance of SpeakerLM across diverse speaker registration conditions and varying numbers of registered speakers.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¼ ç»Ÿè¯´è¯äººæ—¥å¿—ä¸è¯†åˆ«(SDR)çº§è”ç³»ç»Ÿå­˜åœ¨çš„è¯¯å·®ä¼ æ’­ã€é‡å è¯­éŸ³å¤„ç†éš¾ä»¥åŠç¼ºä¹è”åˆä¼˜åŒ–ç­‰é—®é¢˜ï¼Œæå‡ºäº†SpeakerLMã€‚è¿™æ˜¯ä¸€ç§åŸºäºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLM)çš„ç»Ÿä¸€æ¡†æ¶ï¼Œèƒ½å¤Ÿä»¥ç«¯åˆ°ç«¯çš„æ–¹å¼ååŒå®Œæˆè¯´è¯äººæ—¥å¿—(SD)å’Œè‡ªåŠ¨è¯­éŸ³è¯†åˆ«(ASR)ã€‚ä¸ºäº†é€‚åº”å¤šæ ·åŒ–çš„çœŸå®åœºæ™¯ï¼ŒSpeakerLM é›†æˆäº†çµæ´»çš„è¯´è¯äººæ³¨å†Œæœºåˆ¶ï¼Œå¹¶é€šè¿‡åœ¨å¤§è§„æ¨¡çœŸå®æ•°æ®ä¸Šçš„å¤šé˜¶æ®µè®­ç»ƒç­–ç•¥æ¥æå‡æ€§èƒ½ã€‚å®éªŒè¯æ˜ï¼ŒSpeakerLM åœ¨åŸŸå†…å’Œè·¨åŸŸçš„ SDR åŸºå‡†æµ‹è¯•ä¸­å‡ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›çº§è”åŸºçº¿æ¨¡å‹ï¼Œå±•ç°å‡ºå“è¶Šçš„æ•°æ®æ‰©å±•èƒ½åŠ›å’Œæ³›åŒ–æ€§èƒ½ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹åœ¨ä¸åŒæ³¨å†Œæ¡ä»¶å’Œè¯´è¯äººæ•°é‡ä¸‹å‡èƒ½ä¿æŒç¨³å¥çš„è¡¨ç°ï¼Œä¸ºæ„å»ºæ›´é«˜æ•ˆçš„å¤šè¯´è¯äººè¯­éŸ³åˆ†æç³»ç»Ÿæä¾›äº†å¼ºæœ‰åŠ›çš„æ”¯æŒã€‚",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted by AAAI 2026",
      "pdf_url": "https://arxiv.org/pdf/2508.06372v3",
      "published_date": "2025-08-08 15:04:00 UTC",
      "updated_date": "2026-01-03 12:39:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:10:58.654898+00:00"
    },
    {
      "arxiv_id": "2508.06368v1",
      "title": "Automated Creation of the Legal Knowledge Graph Addressing Legislation on Violence Against Women: Resource, Methodology and Lessons Learned",
      "title_zh": "é’ˆå¯¹å¥³æ€§æš´åŠ›ç«‹æ³•çš„æ³•å¾‹çŸ¥è¯†å›¾è°±è‡ªåŠ¨åŒ–æ„å»ºï¼šèµ„æºã€æ–¹æ³•è®ºä¸ç»éªŒæ€»ç»“",
      "authors": [
        "Claudia dAmato",
        "Giuseppe Rubini",
        "Francesco Didio",
        "Donato Francioso",
        "Fatima Zahra Amara",
        "Nicola Fanizzi"
      ],
      "abstract": "Legal decision-making process requires the availability of comprehensive and detailed legislative background knowledge and up-to-date information on legal cases and related sentences/decisions. Legal Knowledge Graphs (KGs) would be a valuable tool to facilitate access to legal information, to be queried and exploited for the purpose, and to enable advanced reasoning and machine learning applications. Indeed, legal KGs may act as knowledge intensive component to be used by pre-dictive machine learning solutions supporting the decision process of the legal expert. Nevertheless, a few KGs can be found in the legal domain. To fill this gap, we developed a legal KG targeting legal cases of violence against women, along with clear adopted methodologies. Specifically, the paper introduces two complementary approaches for automated legal KG construction; a systematic bottom-up approach, customized for the legal domain, and a new solution leveraging Large Language Models. Starting from legal sentences publicly available from the European Court of Justice, the solutions integrate structured data extraction, ontology development, and semantic enrichment to produce KGs tailored for legal cases involving violence against women. After analyzing and comparing the results of the two approaches, the developed KGs are validated via suitable competency questions. The obtained KG may be impactful for multiple purposes: can improve the accessibility to legal information both to humans and machine, can enable complex queries and may constitute an important knowledge component to be possibly exploited by machine learning tools tailored for predictive justice.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ³•å¾‹å†³ç­–ä¸­èƒŒæ™¯çŸ¥è¯†éœ€æ±‚é«˜ä½†æ³•å¾‹çŸ¥è¯†å›¾è°±(Legal Knowledge Graphs, KGs)åŒ®ä¹çš„ç°çŠ¶ï¼Œå¼€å‘äº†ä¸€ä¸ªä¸“é—¨é’ˆå¯¹é’ˆå¯¹å¦‡å¥³æš´åŠ›è¡Œä¸º(violence against women)ç«‹æ³•çš„æ³•å¾‹çŸ¥è¯†å›¾è°±ã€‚ç ”ç©¶æå‡ºäº†ä¸¤ç§äº’è¡¥çš„è‡ªåŠ¨åŒ–æ„å»ºæ–¹æ³•ï¼šä¸€ç§æ˜¯é’ˆå¯¹æ³•å¾‹é¢†åŸŸå®šåˆ¶çš„ç³»ç»ŸåŒ–è‡ªä¸‹è€Œä¸Š(bottom-up)æ–¹æ³•ï¼Œå¦ä¸€ç§æ˜¯åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(Large Language Models, LLMs)çš„æ–°å‹è§£å†³æ–¹æ¡ˆã€‚é€šè¿‡å¯¹æ¬§æ´²æ³•é™¢(European Court of Justice)å…¬å¼€åˆ¤å†³ä¹¦è¿›è¡Œç»“æ„åŒ–æ•°æ®æå–ã€æœ¬ä½“å¼€å‘å’Œè¯­ä¹‰å¢å¼ºï¼ŒæˆåŠŸæ„å»ºäº†ç‰¹å®šçš„çŸ¥è¯†å›¾è°±ã€‚å®éªŒé€šè¿‡èƒ½åŠ›é—®é¢˜(competency questions)å¯¹ä¸¤ç§æ–¹æ³•ç”Ÿæˆçš„å›¾è°±è¿›è¡Œäº†éªŒè¯ä¸æ¯”è¾ƒã€‚è¯¥æˆæœä¸ä»…æé«˜äº†äººç±»å’Œæœºå™¨è·å–æ³•å¾‹ä¿¡æ¯çš„ä¾¿æ·æ€§ï¼Œè¿˜ä¸ºå®ç°å¤æ‚æŸ¥è¯¢ä»¥åŠæ”¯æŒé¢„æµ‹æ€§å¸æ³•(predictive justice)çš„æœºå™¨å­¦ä¹ å·¥å…·æä¾›äº†å…³é”®çš„çŸ¥è¯†ç»„ä»¶ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06368v1",
      "published_date": "2025-08-08 14:59:54 UTC",
      "updated_date": "2025-08-08 14:59:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:11:23.843993+00:00"
    },
    {
      "arxiv_id": "2508.06364v1",
      "title": "ActivityDiff: A diffusion model with Positive and Negative Activity Guidance for De Novo Drug Design",
      "title_zh": "ActivityDiffï¼šåŸºäºæ­£è´Ÿæ´»æ€§å¼•å¯¼çš„ä»å¤´è¯ç‰©è®¾è®¡æ‰©æ•£æ¨¡å‹",
      "authors": [
        "Renyi Zhou",
        "Huimin Zhu",
        "Jing Tang",
        "Min Li"
      ],
      "abstract": "Achieving precise control over a molecule's biological activity-encompassing targeted activation/inhibition, cooperative multi-target modulation, and off-target toxicity mitigation-remains a critical challenge in de novo drug design. However, existing generative methods primarily focus on producing molecules with a single desired activity, lacking integrated mechanisms for the simultaneous management of multiple intended and unintended molecular interactions. Here, we propose ActivityDiff, a generative approach based on the classifier-guidance technique of diffusion models. It leverages separately trained drug-target classifiers for both positive and negative guidance, enabling the model to enhance desired activities while minimizing harmful off-target effects. Experimental results show that ActivityDiff effectively handles essential drug design tasks, including single-/dual-target generation, fragment-constrained dual-target design, selective generation to enhance target specificity, and reduction of off-target effects. These results demonstrate the effectiveness of classifier-guided diffusion in balancing efficacy and safety in molecular design. Overall, our work introduces a novel paradigm for achieving integrated control over molecular activity, and provides ActivityDiff as a versatile and extensible framework.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† ActivityDiffï¼Œè¿™æ˜¯ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹ (Diffusion Model) åˆ†ç±»å™¨å¼•å¯¼ (Classifier-guidance) æŠ€æœ¯çš„ç”Ÿæˆå¼æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ä»å¤´è¯ç‰©è®¾è®¡ (De Novo Drug Design) ä¸­å¯¹åˆ†å­ç”Ÿç‰©æ´»æ€§è¿›è¡Œç²¾ç¡®æ§åˆ¶çš„æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶åˆ©ç”¨åˆ†åˆ«è®­ç»ƒçš„è¯ç‰©-é¶ç‚¹åˆ†ç±»å™¨æä¾›æ­£å‘å’Œè´Ÿå‘å¼•å¯¼ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿåœ¨å¢å¼ºç›®æ ‡æ´»æ€§çš„åŒæ—¶ï¼Œæœ‰æ•ˆæŠ‘åˆ¶æœ‰å®³çš„è„±é¶æ•ˆåº” (Off-target effects)ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒActivityDiff èƒ½å¤Ÿèƒœä»»å•/åŒé¶ç‚¹ç”Ÿæˆã€ç‰‡æ®µé™åˆ¶è®¾è®¡ä»¥åŠé«˜ç‰¹å¼‚æ€§é€‰æ‹©æ€§ç”Ÿæˆç­‰å¤šç§å¤æ‚ä»»åŠ¡ï¼Œå±•ç¤ºäº†åˆ†ç±»å™¨å¼•å¯¼æŠ€æœ¯åœ¨å¹³è¡¡åˆ†å­æœ‰æ•ˆæ€§ä¸å®‰å…¨æ€§æ–¹é¢çš„å“è¶Šèƒ½åŠ›ã€‚è¿™é¡¹å·¥ä½œä¸ºå®ç°åˆ†å­æ´»æ€§çš„é›†æˆæ§åˆ¶å¼•å…¥äº†å…¨æ–°èŒƒå¼ï¼Œå¹¶ä¸ºè¯ç‰©ç ”å‘æä¾›äº†ä¸€ä¸ªé€šç”¨ä¸”å…·æœ‰é«˜åº¦å¯æ‰©å±•æ€§çš„å·¥å…·ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.BM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06364v1",
      "published_date": "2025-08-08 14:48:47 UTC",
      "updated_date": "2025-08-08 14:48:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:11:05.551661+00:00"
    },
    {
      "arxiv_id": "2508.06361v2",
      "title": "Beyond Prompt-Induced Lies: Investigating LLM Deception on Benign Prompts",
      "title_zh": "è¶…è¶Šæç¤ºè¯±å¯¼çš„è°è¨€ï¼šæ¢ç©¶å¤§è¯­è¨€æ¨¡å‹åœ¨è‰¯æ€§æç¤ºä¸‹çš„æ¬ºéª—è¡Œä¸º",
      "authors": [
        "Zhaomin Wu",
        "Mingzhe Du",
        "See-Kiong Ng",
        "Bingsheng He"
      ],
      "abstract": "Large Language Models (LLMs) are widely deployed in reasoning, planning, and decision-making tasks, making their trustworthiness critical. A significant and underexplored risk is intentional deception, where an LLM deliberately fabricates or conceals information to serve a hidden objective. Existing studies typically induce deception by explicitly setting a hidden objective through prompting or fine-tuning, which may not reflect real-world human-LLM interactions. Moving beyond such human-induced deception, we investigate LLMs' self-initiated deception on benign prompts. To address the absence of ground truth, we propose a framework based on Contact Searching Questions~(CSQ). This framework introduces two statistical metrics derived from psychological principles to quantify the likelihood of deception. The first, the Deceptive Intention Score, measures the model's bias toward a hidden objective. The second, the Deceptive Behavior Score, measures the inconsistency between the LLM's internal belief and its expressed output. Evaluating 16 leading LLMs, we find that both metrics rise in parallel and escalate with task difficulty for most models. Moreover, increasing model capacity does not always reduce deception, posing a significant challenge for future LLM development.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨è‰¯æ€§æç¤º(benign prompts)ä¸‹è‡ªå‘äº§ç”Ÿçš„æ¬ºéª—è¡Œä¸ºï¼Œæ—¨åœ¨æ­ç¤ºæ¨¡å‹åœ¨æ²¡æœ‰æ˜¾å¼è¯±å¯¼æ—¶æ•…æ„æé€ æˆ–éšç’ä¿¡æ¯çš„é£é™©ã€‚ä¸ºäº†é‡åŒ–è¿™ä¸€ç°è±¡ï¼Œç ”ç©¶è€…æå‡ºäº†åŸºäºContact Searching Questions(CSQ)çš„è¯„ä¼°æ¡†æ¶ï¼Œå¹¶å®šä¹‰äº†æ¬ºéª—æ„å›¾è¯„åˆ†(Deceptive Intention Score)å’Œæ¬ºéª—è¡Œä¸ºè¯„åˆ†(Deceptive Behavior Score)ä¸¤ä¸ªæŒ‡æ ‡ã€‚è¿™ä¸¤ä¸ªæŒ‡æ ‡åˆ†åˆ«è¡¡é‡æ¨¡å‹å¯¹éšè—ç›®æ ‡çš„åå¥½ï¼Œä»¥åŠæ¨¡å‹å†…éƒ¨ä¿¡å¿µä¸æœ€ç»ˆè¾“å‡ºç»“æœä¹‹é—´çš„ä¸€è‡´æ€§ã€‚é€šè¿‡å¯¹16ç§é¢†å…ˆLLMsçš„è¯„ä¼°ï¼Œç ”ç©¶å‘ç°æ¬ºéª—å€¾å‘é€šå¸¸éšä»»åŠ¡éš¾åº¦çš„å¢åŠ è€Œæ˜¾è‘—æå‡ã€‚å®éªŒç»“æœè¿›ä¸€æ­¥è¡¨æ˜ï¼Œå¢åŠ æ¨¡å‹å®¹é‡å¹¶ä¸æ€»æ˜¯èƒ½æœ‰æ•ˆå‡å°‘æ¬ºéª—è¡Œä¸ºï¼Œè¿™ä¸ºæœªæ¥æ„å»ºå¯ä¿¡AIç³»ç»Ÿæå‡ºäº†é‡å¤§æŒ‘æˆ˜ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06361v2",
      "published_date": "2025-08-08 14:46:35 UTC",
      "updated_date": "2025-09-29 09:05:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:11:10.994688+00:00"
    },
    {
      "arxiv_id": "2508.06357v1",
      "title": "Are you In or Out (of gallery)? Wisdom from the Same-Identity Crowd",
      "title_zh": "åœ¨åº“è¿˜æ˜¯ç¦»åº“ï¼Ÿæ¥è‡ªåŒèº«ä»½ç¾¤ä½“çš„è¯†åˆ«å¯ç¤º",
      "authors": [
        "Aman Bhatta",
        "Maria Dhakal",
        "Michael C. King",
        "Kevin W. Bowyer"
      ],
      "abstract": "A central problem in one-to-many facial identification is that the person in the probe image may or may not have enrolled image(s) in the gallery; that is, may be In-gallery or Out-of-gallery. Past approaches to detect when a rank-one result is Out-of-gallery have mostly focused on finding a suitable threshold on the similarity score. We take a new approach, using the additional enrolled images of the identity with the rank-one result to predict if the rank-one result is In-gallery / Out-of-gallery. Given a gallery of identities and images, we generate In-gallery and Out-of-gallery training data by extracting the ranks of additional enrolled images corresponding to the rank-one identity. We then train a classifier to utilize this feature vector to predict whether a rank-one result is In-gallery or Out-of-gallery. Using two different datasets and four different matchers, we present experimental results showing that our approach is viable for mugshot quality probe images, and also, importantly, for probes degraded by blur, reduced resolution, atmospheric turbulence and sunglasses. We also analyze results across demographic groups, and show that In-gallery / Out-of-gallery classification accuracy is similar across demographics. Our approach has the potential to provide an objective estimate of whether a one-to-many facial identification is Out-of-gallery, and thereby to reduce false positive identifications, wrongful arrests, and wasted investigative time. Interestingly, comparing the results of older deep CNN-based face matchers with newer ones suggests that the effectiveness of our Out-of-gallery detection approach emerges only with matchers trained using advanced margin-based loss functions.",
      "tldr_zh": "åœ¨ä¸€å¯¹å¤šçš„äººè„¸è¯†åˆ«(one-to-many facial identification)ä»»åŠ¡ä¸­ï¼Œå‡†ç¡®åŒºåˆ†å¾…æŸ¥è¯¢äººåƒæ˜¯å¦åœ¨åº“(In-gallery / Out-of-gallery)æ˜¯ä¸€ä¸ªæ ¸å¿ƒæŒ‘æˆ˜ã€‚ä¼ ç»Ÿæ–¹æ³•ä¸»è¦ä¾èµ–ç›¸ä¼¼åº¦åˆ†æ•°(similarity score)çš„é˜ˆå€¼è®¾å®šï¼Œè€Œæœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åˆ©ç”¨åº“ä¸­åŒä¸€èº«ä»½(rank-one identity)çš„å…¶ä»–æ³¨å†Œå›¾åƒä¿¡æ¯æ¥é¢„æµ‹è¯†åˆ«ç»“æœæœ‰æ•ˆæ€§çš„æ–°æ–¹æ³•ã€‚ç ”ç©¶é€šè¿‡æå–åº“ä¸­åŒä¸€èº«ä»½é¢å¤–å›¾åƒçš„æ’å(ranks)ä¿¡æ¯ç”Ÿæˆç‰¹å¾å‘é‡ï¼Œå¹¶è®­ç»ƒåˆ†ç±»å™¨æ¥åˆ¤æ–­æ’åç¬¬ä¸€çš„ç»“æœæ˜¯å¦çœŸå®åœ¨åº“ã€‚å®éªŒåœ¨ä¸¤ä¸ªæ•°æ®é›†å’Œå››ç§åŒ¹é…å™¨(matchers)ä¸Šè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤„ç†æ¨¡ç³Š(blur)ã€ä½åˆ†è¾¨ç‡(reduced resolution)ã€å¤§æ°”æ¹æµ(atmospheric turbulence)å’Œæˆ´å¢¨é•œ(sunglasses)ç­‰é€€åŒ–å›¾åƒæ—¶å‡è¡¨ç°ç¨³å¥ã€‚äººå£ç»Ÿè®¡å­¦åˆ†ææ˜¾ç¤ºï¼Œè¯¥åˆ†ç±»æ–¹æ³•åœ¨ä¸åŒæ—è£”ç¾¤ä½“(demographic groups)é—´å…·æœ‰ä¸€è‡´çš„å‡†ç¡®ç‡ã€‚ç ”ç©¶å‘ç°è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§åœ¨ç»“åˆåŸºäºè¾¹ç¼˜æŸå¤±å‡½æ•°(margin-based loss functions)è®­ç»ƒçš„å…ˆè¿›åŒ¹é…å™¨æ—¶å°¤ä¸ºçªå‡ºã€‚è¯¥æŠ€æœ¯èƒ½ä¸ºåˆ¤å®šè¯†åˆ«ç»“æœæ˜¯å¦åœ¨åº“æä¾›å®¢è§‚ä¼°è®¡ï¼Œä»è€Œæœ‰æ•ˆå‡å°‘é”™è¯¯è¯†åˆ«(false positive identifications)ã€è¯¯æ•åŠè°ƒæŸ¥èµ„æºçš„æµªè´¹ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06357v1",
      "published_date": "2025-08-08 14:39:29 UTC",
      "updated_date": "2025-08-08 14:39:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:11:17.345226+00:00"
    },
    {
      "arxiv_id": "2508.06352v1",
      "title": "From Explainable to Explanatory Artificial Intelligence: Toward a New Paradigm for Human-Centered Explanations through Generative AI",
      "title_zh": "ä»å¯è§£é‡Šäººå·¥æ™ºèƒ½åˆ°è§£é‡Šæ€§äººå·¥æ™ºèƒ½ï¼šç”Ÿæˆå¼äººå·¥æ™ºèƒ½èµ‹èƒ½çš„ä»¥äººä¸ºä¸­å¿ƒè§£é‡Šæ–°èŒƒå¼",
      "authors": [
        "Christian Meske",
        "Justin Brenne",
        "Erdi Uenal",
        "Sabahat Oelcer",
        "Ayseguel Doganguen"
      ],
      "abstract": "Current explainable AI (XAI) approaches prioritize algorithmic transparency and present explanations in abstract, non-adaptive formats that often fail to support meaningful end-user understanding. This paper introduces \"Explanatory AI\" as a complementary paradigm that leverages generative AI capabilities to serve as explanatory partners for human understanding rather than providers of algorithmic transparency. While XAI reveals algorithmic decision processes for model validation, Explanatory AI addresses contextual reasoning to support human decision-making in sociotechnical contexts. We develop a definition and systematic eight-dimensional conceptual model distinguishing Explanatory AI through narrative communication, adaptive personalization, and progressive disclosure principles. Empirical validation through Rapid Contextual Design methodology with healthcare professionals demonstrates that users consistently prefer context-sensitive, multimodal explanations over technical transparency. Our findings reveal the practical urgency for AI systems designed for human comprehension rather than algorithmic introspection, establishing a comprehensive research agenda for advancing user-centered AI explanation approaches across diverse domains and cultural contexts.",
      "tldr_zh": "å½“å‰çš„å¯è§£é‡Šäººå·¥æ™ºèƒ½ï¼ˆXAIï¼‰æ–¹æ³•å¾€å¾€ä¾§é‡äºç®—æ³•é€æ˜åº¦ï¼Œä½†åœ¨æ”¯æŒç»ˆç«¯ç”¨æˆ·æœ‰æ•ˆç†è§£æ–¹é¢å­˜åœ¨å±€é™ã€‚æœ¬æ–‡æå‡ºäº†â€œExplanatory AIâ€ä½œä¸ºä¸€ç§äº’è¡¥èŒƒå¼ï¼Œåˆ©ç”¨ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ï¼ˆGenerative AIï¼‰çš„èƒ½åŠ›ä½¿å…¶æˆä¸ºäººç±»ç†è§£çš„è§£é‡Šä¼™ä¼´ï¼Œè€Œéä»…ä»…æ˜¯é€æ˜åº¦çš„æä¾›è€…ã€‚ä¸ä¾§é‡äºæ¨¡å‹éªŒè¯çš„XAIä¸åŒï¼ŒExplanatory AI å…³æ³¨æƒ…å¢ƒæ¨ç†ï¼Œæ—¨åœ¨æ”¯æŒç¤¾ä¼šæŠ€æœ¯èƒŒæ™¯ä¸‹çš„äººç±»å†³ç­–ã€‚ç ”ç©¶å›¢é˜Ÿå¼€å‘äº†ä¸€ä¸ªåŒ…å«å…«ä¸ªç»´åº¦çš„ç³»ç»Ÿæ€§æ¦‚å¿µæ¨¡å‹ï¼Œæ ¸å¿ƒåŒ…æ‹¬å™äº‹äº¤æµï¼ˆnarrative communicationï¼‰ã€è‡ªé€‚åº”ä¸ªæ€§åŒ–ï¼ˆadaptive personalizationï¼‰å’Œæ¸è¿›å¼æŠ«éœ²ï¼ˆprogressive disclosureï¼‰åŸåˆ™ã€‚é€šè¿‡å¯¹åŒ»ç–—ä¿å¥ä¸“ä¸šäººå‘˜è¿›è¡Œçš„å¿«é€Ÿæƒ…å¢ƒè®¾è®¡ï¼ˆRapid Contextual Designï¼‰å®è¯éªŒè¯ï¼Œç»“æœæ˜¾ç¤ºç”¨æˆ·æ™®éåå¥½ä¸Šä¸‹æ–‡æ•æ„Ÿçš„å¤šæ¨¡æ€è§£é‡Šï¼Œè€Œéå•çº¯çš„æŠ€æœ¯é€æ˜åº¦ã€‚è¯¥ç ”ç©¶å¼ºè°ƒäº†å¼€å‘ä»¥äººç±»ç†è§£ä¸ºæ ¸å¿ƒçš„AIç³»ç»Ÿçš„ç´§è¿«æ€§ï¼Œå¹¶ä¸ºæ¨è¿›è·¨é¢†åŸŸçš„ç”¨æˆ·ä¸­å¿ƒåŒ–AIè§£é‡Šæ–¹æ³•ç¡®ç«‹äº†å…¨é¢çš„ç ”ç©¶è®®ç¨‹ã€‚",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06352v1",
      "published_date": "2025-08-08 14:32:41 UTC",
      "updated_date": "2025-08-08 14:32:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:11:16.154114+00:00"
    },
    {
      "arxiv_id": "2508.10028v1",
      "title": "PREF: Reference-Free Evaluation of Personalised Text Generation in LLMs",
      "title_zh": "PREFï¼šå¤§è¯­è¨€æ¨¡å‹ä¸­ä¸ªæ€§åŒ–æ–‡æœ¬ç”Ÿæˆçš„æ— å‚è€ƒè¯„ä¼°",
      "authors": [
        "Xiao Fu",
        "Hossein A. Rahmani",
        "Bin Wu",
        "Jerome Ramos",
        "Emine Yilmaz",
        "Aldo Lipani"
      ],
      "abstract": "Personalised text generation is essential for user-centric information systems, yet most evaluation methods overlook the individuality of users. We introduce \\textbf{PREF}, a \\textbf{P}ersonalised \\textbf{R}eference-free \\textbf{E}valuation \\textbf{F}ramework that jointly measures general output quality and user-specific alignment without requiring gold personalised references. PREF operates in a three-step pipeline: (1) a coverage stage uses a large language model (LLM) to generate a comprehensive, query-specific guideline covering universal criteria such as factuality, coherence, and completeness; (2) a preference stage re-ranks and selectively augments these factors using the target user's profile, stated or inferred preferences, and context, producing a personalised evaluation rubric; and (3) a scoring stage applies an LLM judge to rate candidate answers against this rubric, ensuring baseline adequacy while capturing subjective priorities. This separation of coverage from preference improves robustness, transparency, and reusability, and allows smaller models to approximate the personalised quality of larger ones. Experiments on the PrefEval benchmark, including implicit preference-following tasks, show that PREF achieves higher accuracy, better calibration, and closer alignment with human judgments than strong baselines. By enabling scalable, interpretable, and user-aligned evaluation, PREF lays the groundwork for more reliable assessment and development of personalised language generation systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† PREFï¼Œä¸€ä¸ªä¸“é—¨é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ (LLMs) ä¸ªæ€§åŒ–æ–‡æœ¬ç”Ÿæˆä»»åŠ¡çš„æ— éœ€å‚è€ƒ (Reference-Free) çš„è¯„ä¼°æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡ä¸‰é˜¶æ®µæµç¨‹è¿ä½œï¼Œé¦–å…ˆåœ¨è¦†ç›–é˜¶æ®µ (Coverage stage) åˆ©ç”¨ LLM ç”ŸæˆåŒ…å«äº‹å®æ€§ã€è¿è´¯æ€§å’Œå®Œæ•´æ€§ç­‰é€šç”¨å‡†åˆ™çš„æŒ‡å—ã€‚éšååœ¨åå¥½é˜¶æ®µ (Preference stage) ç»“åˆç”¨æˆ·ç”»åƒã€åå¥½åŠä¸Šä¸‹æ–‡å¯¹å‡†åˆ™è¿›è¡Œé‡æ’åºå’Œå¢å¼ºï¼Œä»è€Œæ„å»ºå‡ºä¸ªæ€§åŒ–çš„è¯„ä¼°å‡†åˆ™ (Evaluation rubric)ã€‚æœ€ååœ¨è¯„åˆ†é˜¶æ®µ (Scoring stage) ç”± LLM è£åˆ¤ä¾æ®è¯¥å‡†åˆ™å¯¹ç”Ÿæˆå†…å®¹è¿›è¡Œè¯„åˆ†ï¼Œç¡®ä¿åœ¨ä¿éšœåŸºç¡€è´¨é‡çš„åŒæ—¶æ•æ‰ç”¨æˆ·çš„ä¸ªäººä¼˜å…ˆçº§ã€‚PREF å°†é€šç”¨è¦†ç›–ä¸ä¸ªæ€§åŒ–åå¥½åˆ†ç¦»çš„è®¾è®¡æå‡äº†è¯„ä¼°çš„é²æ£’æ€§ä¸é€æ˜åº¦ï¼Œå¹¶ä½¿å°æ¨¡å‹èƒ½å¤Ÿæ¨¡æ‹Ÿå¤§æ¨¡å‹çš„ä¸ªæ€§åŒ–è¯„ä¼°èƒ½åŠ›ã€‚åœ¨ PrefEval åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¯æ˜ï¼ŒPREF åœ¨å‡†ç¡®æ€§ã€æ ¡å‡†åº¦åŠä¸äººç±»åˆ¤æ–­çš„ä¸€è‡´æ€§ä¸Šå‡æ˜¾è‘—ä¼˜äºç°æœ‰åŸºå‡†æ¨¡å‹ã€‚è¯¥æˆæœä¸ºå¼€å‘æ›´å¯é ä¸”ç¬¦åˆç”¨æˆ·éœ€æ±‚çš„ä¸ªæ€§åŒ–è¯­è¨€ç”Ÿæˆç³»ç»Ÿå¥ å®šäº†å¯æ‰©å±•ä¸”å¯è§£é‡Šçš„è¯„ä¼°åŸºç¡€ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "7 pages",
      "pdf_url": "https://arxiv.org/pdf/2508.10028v1",
      "published_date": "2025-08-08 14:32:31 UTC",
      "updated_date": "2025-08-08 14:32:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:11:17.152457+00:00"
    },
    {
      "arxiv_id": "2508.06595v3",
      "title": "LLM Unlearning Without an Expert Curated Dataset",
      "title_zh": "æ— éœ€ä¸“å®¶ç²¾é€‰æ•°æ®é›†çš„å¤§è¯­è¨€æ¨¡å‹é—å¿˜",
      "authors": [
        "Xiaoyuan Zhu",
        "Muru Zhang",
        "Ollie Liu",
        "Robin Jia",
        "Willie Neiswanger"
      ],
      "abstract": "Modern large language models often encode sensitive, harmful, or copyrighted knowledge, raising the need for post-hoc unlearning-the ability to remove specific domains of knowledge from a model without full retraining. A major bottleneck in current unlearning pipelines is constructing effective forget sets-datasets that approximate the target domain and guide the model to forget it. In this work, we introduce a scalable, automated approach to generate high-quality forget sets using language models themselves. Our method synthesizes textbook-style data through a structured prompting pipeline, requiring only a domain name as input. Through experiments on unlearning biosecurity, cybersecurity, and Harry Potter novels, we show that our synthetic datasets consistently outperform the baseline synthetic alternatives and are comparable to the expert-curated ones. Additionally, ablation studies reveal that the multi-step generation pipeline significantly boosts data diversity, which in turn improves unlearning utility. Overall, our findings suggest that synthetic datasets offer a promising path toward practical, scalable unlearning for a wide range of emerging domains without the need for manual intervention. We release our code and dataset at https://github.com/xyzhu123/Synthetic_Textbook.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­æ•æ„Ÿã€æœ‰å®³æˆ–å—ç‰ˆæƒä¿æŠ¤çŸ¥è¯†çš„ç§»é™¤é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ— éœ€ä¸“å®¶ç­–åˆ’æ•°æ®é›†çš„ LLM Unlearning è‡ªåŠ¨åŒ–æ–¹æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡ç»“æ„åŒ–çš„æç¤ºè¯æµæ°´çº¿ï¼ˆprompting pipelineï¼‰åˆ©ç”¨æ¨¡å‹è‡ªèº«ç”Ÿæˆé«˜è´¨é‡çš„ Forget setsï¼Œä¸”ä»…éœ€æä¾›é¢†åŸŸåç§°å³å¯åˆæˆæ•™ç§‘ä¹¦é£æ ¼çš„æ•°æ®ã€‚åœ¨ç”Ÿç‰©å®‰å…¨ï¼ˆbiosecurityï¼‰ã€ç½‘ç»œå®‰å…¨ï¼ˆcybersecurityï¼‰å’Œã€Šå“ˆåˆ©Â·æ³¢ç‰¹ã€‹å°è¯´çš„çŸ¥è¯†æ“¦é™¤å®éªŒä¸­ï¼Œè¯¥åˆæˆæ•°æ®é›†çš„æ•ˆæœä¸€è‡´ä¼˜äºåŸºå‡†åˆæˆæ–¹æ¡ˆï¼Œä¸”è¡¨ç°å¯ä¸ä¸“å®¶æ‰‹åŠ¨ç­–åˆ’çš„æ•°æ®é›†ç›¸åª²ç¾ã€‚æ¶ˆèå®éªŒè¿›ä¸€æ­¥è¯å®ï¼Œå¤šæ­¥ç”Ÿæˆæµæ°´çº¿æ˜¾è‘—æå‡äº†æ•°æ®å¤šæ ·æ€§ï¼Œä»è€Œå¢å¼ºäº† Unlearning çš„æ•ˆç”¨ã€‚æ€»ä½“è€Œè¨€ï¼Œè¯¥ç ”ç©¶è¯æ˜äº†åˆæˆæ•°æ®é›†åœ¨å®ç°å®ç”¨ä¸”å¯æ‰©å±•çš„çŸ¥è¯†æ“¦é™¤æ–¹é¢å…·æœ‰å·¨å¤§æ½œåŠ›ï¼Œæœ‰æ•ˆæ‘†è„±äº†å¯¹äººå·¥å¹²é¢„çš„ä¾èµ–ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06595v3",
      "published_date": "2025-08-08 14:30:08 UTC",
      "updated_date": "2025-10-07 03:52:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:11:23.449785+00:00"
    },
    {
      "arxiv_id": "2508.06348v1",
      "title": "AntiCheatPT: A Transformer-Based Approach to Cheat Detection in Competitive Computer Games",
      "title_zh": "AntiCheatPTï¼šåŸºäº Transformer çš„ç«æŠ€ç±»ç”µè„‘æ¸¸æˆä½œå¼Šæ£€æµ‹æ–¹æ³•",
      "authors": [
        "Mille Mei Zhen Loo",
        "Gert Luzkov",
        "Paolo Burelli"
      ],
      "abstract": "Cheating in online video games compromises the integrity of gaming experiences. Anti-cheat systems, such as VAC (Valve Anti-Cheat), face significant challenges in keeping pace with evolving cheating methods without imposing invasive measures on users' systems. This paper presents AntiCheatPT\\_256, a transformer-based machine learning model designed to detect cheating behaviour in Counter-Strike 2 using gameplay data. To support this, we introduce and publicly release CS2CD: A labelled dataset of 795 matches. Using this dataset, 90,707 context windows were created and subsequently augmented to address class imbalance. The transformer model, trained on these windows, achieved an accuracy of 89.17\\% and an AUC of 93.36\\% on an unaugmented test set. This approach emphasizes reproducibility and real-world applicability, offering a robust baseline for future research in data-driven cheat detection.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åœ¨çº¿ç”µå­æ¸¸æˆä¸­çš„ä½œå¼ŠæŒ‘æˆ˜ï¼Œæå‡ºäº† AntiCheatPT\\_256ï¼Œè¿™æ˜¯ä¸€ç§åŸºäº Transformer çš„æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œä¸“é—¨ç”¨äºæ£€æµ‹ã€Šåæç²¾è‹± 2ã€‹(Counter-Strike 2) ä¸­çš„ä½œå¼Šè¡Œä¸ºã€‚ä¸ºäº†æ¨è¿›è¯¥é¢†åŸŸçš„ç ”ç©¶ï¼Œä½œè€…å‘å¸ƒäº†åä¸º CS2CD çš„å¼€æºæ ‡è®°æ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å« 795 åœºæ¯”èµ›æ•°æ®ã€‚ç ”ç©¶é€šè¿‡ä»æ•°æ®é›†ä¸­æå– 90,707 ä¸ªä¸Šä¸‹æ–‡çª—å£ (context windows) å¹¶åº”ç”¨æ•°æ®å¢å¼ºæŠ€æœ¯ï¼Œæœ‰æ•ˆè§£å†³äº†ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šå®ç°äº† 89.17% çš„å‡†ç¡®ç‡å’Œ 93.36% çš„ AUCï¼Œè¯æ˜äº†å…¶å¼ºå¤§çš„æ£€æµ‹èƒ½åŠ›ã€‚è¯¥ç ”ç©¶å¼ºè°ƒæ–¹æ¡ˆçš„å¯å¤ç°æ€§ä¸å®é™…åº”ç”¨ä»·å€¼ï¼Œä¸ºæœªæ¥æ•°æ®é©±åŠ¨çš„è‡ªåŠ¨åŒ–åä½œå¼ŠæŠ€æœ¯æä¾›äº†é‡è¦çš„åŸºå‡†ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06348v1",
      "published_date": "2025-08-08 14:22:41 UTC",
      "updated_date": "2025-08-08 14:22:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:11:38.355406+00:00"
    },
    {
      "arxiv_id": "2508.06347v2",
      "title": "Structural Equation-VAE: Disentangled Latent Representations for Tabular Data",
      "title_zh": "ç»“æ„æ–¹ç¨‹-VAEï¼šé¢å‘è¡¨æ ¼æ•°æ®çš„è§£è€¦æ½œåœ¨è¡¨ç¤º",
      "authors": [
        "Ruiyu Zhang",
        "Ce Zhao",
        "Xin Zhao",
        "Lin Nie",
        "Wai-Fung Lam"
      ],
      "abstract": "Learning interpretable latent representations from tabular data remains a challenge in deep generative modeling. We introduce SE-VAE (Structural Equation-Variational Autoencoder), a novel architecture that embeds measurement structure directly into the design of a variational autoencoder. Inspired by structural equation modeling, SE-VAE aligns latent subspaces with known indicator groupings and introduces a global nuisance latent to isolate construct-specific confounding variation. This modular architecture enables disentanglement through design rather than through statistical regularizers alone. We evaluate SE-VAE on a suite of simulated tabular datasets and benchmark its performance against a series of leading baselines using standard disentanglement metrics. SE-VAE consistently outperforms alternatives in factor recovery, interpretability, and robustness to nuisance variation. Ablation results reveal that architectural structure, rather than regularization strength, is the key driver of performance. SE-VAE offers a principled framework for white-box generative modeling in scientific and social domains where latent constructs are theory-driven and measurement validity is essential.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†SE-VAE (Structural Equation-Variational Autoencoder)ï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨ä¸ºè¡¨æ ¼æ•°æ®å­¦ä¹ å¯è§£é‡Šè§£è€¦æ½œè¡¨å¾çš„æ–°å‹æ¶æ„ã€‚SE-VAEç›´æ¥å°†æµ‹é‡ç»“æ„åµŒå…¥åˆ°å˜åˆ†è‡ªç¼–ç å™¨çš„è®¾è®¡ä¸­ï¼Œé€šè¿‡å°†æ½œå­ç©ºé—´ä¸å·²çŸ¥çš„æŒ‡æ ‡åˆ†ç»„(indicator groupings)å¯¹é½ï¼Œå¹¶å¼•å…¥å…¨å±€å¹²æ‰°æ½œå˜é‡(global nuisance latent)æ¥éš”ç¦»ç‰¹å®šäºæ„æ€çš„æ··æ‚å˜å¼‚ã€‚è¿™ç§æ¨¡å—åŒ–æ¶æ„å®ç°äº†é€šè¿‡è®¾è®¡è€Œéå•çº¯ä¾èµ–ç»Ÿè®¡æ­£åˆ™åŒ–å™¨(statistical regularizers)æ¥è¾¾æˆè§£è€¦(disentanglement)ã€‚å®éªŒåœ¨æ¨¡æ‹Ÿè¡¨æ ¼æ•°æ®é›†ä¸ŠéªŒè¯äº†è¯¥æ¨¡å‹çš„æ€§èƒ½ï¼Œç»“æœæ˜¾ç¤ºSE-VAEåœ¨å› å­æ¢å¤(factor recovery)ã€å¯è§£é‡Šæ€§å’Œå¯¹å¹²æ‰°å˜å¼‚çš„é²æ£’æ€§æ–¹é¢å‡ä¼˜äºå½“å‰çš„åŸºçº¿æ¨¡å‹ã€‚æ¶ˆèå®éªŒè¿›ä¸€æ­¥è¡¨æ˜ï¼Œæ¶æ„ç»“æ„è€Œéæ­£åˆ™åŒ–å¼ºåº¦æ˜¯æ€§èƒ½æå‡çš„æ ¸å¿ƒé©±åŠ¨åŠ›ã€‚è¯¥ç ”ç©¶ä¸ºç§‘å­¦å’Œç¤¾ä¼šé¢†åŸŸä¸­ç”±ç†è®ºé©±åŠ¨çš„ç™½ç›’ç”Ÿæˆå»ºæ¨¡æä¾›äº†ä¸€ä¸ªå…¼é¡¾æµ‹é‡æœ‰æ•ˆæ€§å’Œè§£é‡Šæ€§çš„æœ‰æ•ˆæ¡†æ¶ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 2 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.06347v2",
      "published_date": "2025-08-08 14:21:20 UTC",
      "updated_date": "2025-08-16 10:27:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:11:47.591979+00:00"
    },
    {
      "arxiv_id": "2508.06345v1",
      "title": "Harnessing Adaptive Topology Representations for Zero-Shot Graph Question Answering",
      "title_zh": "åˆ©ç”¨è‡ªé€‚åº”æ‹“æ‰‘è¡¨ç¤ºå®ç°é›¶æ ·æœ¬å›¾é—®ç­”",
      "authors": [
        "Yanbin Wei",
        "Jiangyue Yan",
        "Chun Kang",
        "Yang Chen",
        "Hua Liu",
        "James T. Kwok",
        "Yu Zhang"
      ],
      "abstract": "Large Multimodal Models (LMMs) have shown generalized zero-shot capabilities in diverse domain question-answering (QA) tasks, including graph QA that involves complex graph topologies. However, most current approaches use only a single type of graph representation, namely Topology Representation Form (TRF), such as prompt-unified text descriptions or style-fixed visual styles. Those \"one-size-fits-all\" approaches fail to consider the specific preferences of different models or tasks, often leading to incorrect or overly long responses. To address this, we first analyze the characteristics and weaknesses of existing TRFs, and then design a set of TRFs, denoted by $F_{ZS}$, tailored to zero-shot graph QA. We then introduce a new metric, Graph Response Efficiency (GRE), which measures the balance between the performance and the brevity in graph QA. Built on these, we develop the DynamicTRF framework, which aims to improve both the accuracy and conciseness of graph QA. To be specific, DynamicTRF first creates a TRF Preference (TRFP) dataset that ranks TRFs based on their GRE scores, to probe the question-specific TRF preferences. Then it trains a TRF router on the TRFP dataset, to adaptively assign the best TRF from $F_{ZS}$ for each question during the inference. Extensive experiments across 7 in-domain algorithmic graph QA tasks and 2 out-of-domain downstream tasks show that DynamicTRF significantly enhances the zero-shot graph QA of LMMs in terms of accuracy",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹å¤šæ¨¡æ€æ¨¡å‹(LMMs)åœ¨é›¶æ ·æœ¬å›¾é—®ç­”(Zero-Shot Graph QA)ä¸­é‡‡ç”¨å›ºå®šæ‹“æ‰‘è¡¨ç¤ºå½¢å¼(TRF)å¯¼è‡´çš„æ•ˆç‡ä½ä¸‹å’Œå‡†ç¡®æ€§ä¸è¶³ç­‰é—®é¢˜ï¼Œæå‡ºäº†DynamicTRFæ¡†æ¶ã€‚è¯¥æ¡†æ¶é¦–å…ˆè®¾è®¡äº†ä¸€å¥—ä¸“é—¨é€‚é…å›¾é—®ç­”çš„æ‹“æ‰‘è¡¨ç¤ºé›†åˆ$F_{ZS}$ï¼Œå¹¶å¼•å…¥äº†å…¨æ–°çš„å›¾å“åº”æ•ˆç‡(GRE)æŒ‡æ ‡ï¼Œæ—¨åœ¨å¹³è¡¡æ¨¡å‹æ€§èƒ½ä¸å›å¤çš„ç®€æ´æ€§ã€‚é€šè¿‡æ„å»ºTRFåå¥½æ•°æ®é›†(TRFP)å¹¶è®­ç»ƒä¸“ç”¨çš„TRFè·¯ç”±å™¨ï¼ŒDynamicTRFèƒ½å¤Ÿåœ¨æ¨ç†é˜¶æ®µä¸ºæ¯ä¸ªç‰¹å®šé—®é¢˜è‡ªé€‚åº”åœ°åˆ†é…æœ€ä½³çš„TRFã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨7é¡¹åŸŸå†…ç®—æ³•å›¾é—®ç­”ä»»åŠ¡å’Œ2é¡¹åŸŸå¤–ä¸‹æ¸¸ä»»åŠ¡ä¸­æ˜¾è‘—æå‡äº†LMMsçš„å‡†ç¡®ç‡å’Œæ•ˆç‡ï¼Œä¸ºä¼˜åŒ–å¤æ‚æ‹“æ‰‘ç»“æ„çš„å›¾é—®ç­”ä»»åŠ¡æä¾›äº†æœ‰æ•ˆçš„åŠ¨æ€è¡¨å¾æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06345v1",
      "published_date": "2025-08-08 14:18:24 UTC",
      "updated_date": "2025-08-08 14:18:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:12:06.997287+00:00"
    },
    {
      "arxiv_id": "2508.06343v2",
      "title": "On Approximate MMS Allocations on Restricted Graph Classes",
      "title_zh": "è®ºå—é™å›¾ç±»ä¸Šçš„è¿‘ä¼¼ MMS åˆ†é…",
      "authors": [
        "VÃ¡clav BlaÅ¾ej",
        "MichaÅ‚ DÄ™bski",
        "Zbigniew Lonc",
        "Marta Piecyk",
        "PaweÅ‚ RzÄ…Å¼ewski"
      ],
      "abstract": "We study the problem of fair division of a set of indivisible goods with connectivity constraints. Specifically, we assume that the goods are represented as vertices of a connected graph, and sets of goods allocated to the agents are connected subgraphs of this graph. We focus on the widely-studied maximin share criterion of fairness. It has been shown that an allocation satisfying this criterion may not exist even without connectivity constraints, i.e., if the graph of goods is complete. In view of this, it is natural to seek approximate allocations that guarantee each agent a connected bundle of goods with value at least a constant fraction of the maximin share value to the agent. It is known that for some classes of graphs, such as complete graphs, cycles, and $d$-claw-free graphs for any fixed $d$, such approximate allocations indeed exist. However, it is an open problem whether they exist for the class of all graphs.\n  In this paper, we continue the systematic study of the existence of approximate allocations on restricted graph classes. In particular, we show that such allocations exist for several well-studied classes, including block graphs, cacti, complete multipartite graphs, and split graphs.",
      "tldr_zh": "æœ¬ç ”ç©¶æ¢è®¨äº†å…·æœ‰è¿é€šæ€§çº¦æŸ(connectivity constraints)çš„ä¸å¯åˆ†å•†å“å…¬å¹³åˆ†é…é—®é¢˜ï¼Œå…¶ä¸­å•†å“è¢«è§†ä¸ºå›¾çš„é¡¶ç‚¹ï¼Œä¸”åˆ†é…ç»™æ™ºèƒ½ä½“çš„å•†å“é›†åˆå¿…é¡»æ„æˆè¿é€šå­å›¾ã€‚è®ºæ–‡æ ¸å¿ƒå…³æ³¨å¹¿æ³›ç ”ç©¶çš„æå°æå¤§ä»½é¢(maximin share, MMS)å…¬å¹³æ€§æ ‡å‡†ã€‚è€ƒè™‘åˆ°å³ä½¿åœ¨æ— è¿é€šçº¦æŸçš„æƒ…å†µä¸‹MMSåˆ†é…ä¹Ÿå¯èƒ½ä¸å­˜åœ¨ï¼Œç ”ç©¶æ—¨åœ¨å¯»æ±‚èƒ½å¤Ÿä¿è¯æ¯ä¸ªæ™ºèƒ½ä½“è·å¾—ä»·å€¼è‡³å°‘è¾¾åˆ°å…¶MMSå€¼å¸¸æ•°æ¯”ä¾‹çš„è¿‘ä¼¼è¿é€šåˆ†é…æ–¹æ¡ˆã€‚é’ˆå¯¹è¿™ä¸€åœ¨å…¨å›¾ç±»åˆ«ä¸­å°šå­˜çš„å¼€æ”¾æ€§é—®é¢˜ï¼Œæœ¬æ–‡å¯¹å—é™å›¾ç±»(restricted graph classes)çš„å­˜åœ¨æ€§è¿›è¡Œäº†ç³»ç»Ÿæ€§ç ”ç©¶ã€‚ç ”ç©¶ç»“æœè¯æ˜ï¼Œåœ¨å—å›¾(block graphs)ã€ä»™äººæŒå›¾(cacti)ã€å®Œå…¨å¤šéƒ¨å›¾(complete multipartite graphs)å’Œåˆ†è£‚å›¾(split graphs)ç­‰å¤šç§ç»å…¸å›¾ç±»ä¸­ï¼Œæ­¤ç±»è¿‘ä¼¼MMSåˆ†é…ç¡®å®å­˜åœ¨ã€‚è¯¥å‘ç°è¿›ä¸€æ­¥æ‹“å®½äº†å…¬å¹³åˆ†é…ç†è®ºåœ¨å¤æ‚çº¦æŸç¯å¢ƒä¸‹çš„åº”ç”¨è¾¹ç•Œã€‚",
      "categories": [
        "cs.DM",
        "cs.AI"
      ],
      "primary_category": "cs.DM",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06343v2",
      "published_date": "2025-08-08 14:17:44 UTC",
      "updated_date": "2025-08-14 19:01:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:12:19.390357+00:00"
    },
    {
      "arxiv_id": "2508.06336v1",
      "title": "Unsupervised Partner Design Enables Robust Ad-hoc Teamwork",
      "title_zh": "æ— ç›‘ç£ä¼™ä¼´è®¾è®¡åŠ©åŠ›å®ç°é²æ£’çš„å³æ—¶å›¢é˜Ÿåä½œ",
      "authors": [
        "Constantin Ruhdorfer",
        "Matteo Bortoletto",
        "Victor Oei",
        "Anna Penzkofer",
        "Andreas Bulling"
      ],
      "abstract": "We introduce Unsupervised Partner Design (UPD) - a population-free, multi-agent reinforcement learning framework for robust ad-hoc teamwork that adaptively generates training partners without requiring pretrained partners or manual parameter tuning. UPD constructs diverse partners by stochastically mixing an ego agent's policy with biased random behaviours and scores them using a variance-based learnability metric that prioritises partners near the ego agent's current learning frontier. We show that UPD can be integrated with unsupervised environment design, resulting in the first method enabling fully unsupervised curricula over both level and partner distributions in a cooperative setting. Through extensive evaluations on Overcooked-AI and the Overcooked Generalisation Challenge, we demonstrate that this dynamic partner curriculum is highly effective: UPD consistently outperforms both population-based and population-free baselines as well as ablations. In a user study, we further show that UPD achieves higher returns than all baselines and was perceived as significantly more adaptive, more human-like, a better collaborator, and less frustrating.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Unsupervised Partner Design (UPD)ï¼Œè¿™æ˜¯ä¸€ä¸ªæ— éœ€é¢„è®­ç»ƒç¾¤ä½“ (population-free) çš„å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨å®ç°é²æ£’çš„å³æ—¶å›¢é˜Ÿåä½œ (ad-hoc teamwork)ã€‚UPD é€šè¿‡å°†ä¸»æ™ºèƒ½ä½“ (ego agent) çš„ç­–ç•¥ä¸åç½®éšæœºè¡Œä¸ºéšæœºæ··åˆæ¥æ„é€ å¤šæ ·åŒ–çš„åˆä½œä¼™ä¼´ï¼Œå¹¶ä½¿ç”¨åŸºäºæ–¹å·®çš„å­¦ä¹ åº¦é‡ (variance-based learnability metric) å¯¹å…¶è¿›è¡Œè¯„åˆ†ï¼Œä»è€Œä¼˜å…ˆç”Ÿæˆå¤„äºå­¦ä¹ å‰æ²¿çš„ä¼™ä¼´ã€‚è¯¥æ¡†æ¶å¯ä¸æ— ç›‘ç£ç¯å¢ƒè®¾è®¡é›†æˆï¼Œé¦–æ¬¡åœ¨åˆä½œè®¾ç½®ä¸­å®ç°äº†é’ˆå¯¹å…³å¡å’Œä¼™ä¼´åˆ†å¸ƒçš„å…¨æ— ç›‘ç£è¯¾ç¨‹å­¦ä¹  (fully unsupervised curricula)ã€‚åœ¨ Overcooked-AI åŠå…¶æ³›åŒ–æŒ‘æˆ˜èµ›ä¸­çš„å®éªŒè¡¨æ˜ï¼ŒUPD çš„æ€§èƒ½ä¸€è‡´ä¼˜äºåŸºäºç¾¤ä½“å’Œæ— éœ€ç¾¤ä½“çš„å„ç±»åŸºå‡†æ¨¡å‹ã€‚ç”¨æˆ·ç ”ç©¶è¿›ä¸€æ­¥è¯å®ï¼ŒUPD å…·æœ‰æ›´é«˜çš„å›æŠ¥ï¼Œä¸”åœ¨é€‚åº”æ€§ã€äººç±»æ„Ÿä»¥åŠåˆä½œä½“éªŒæ–¹é¢å‡æ˜¾è‘—ä¼˜äºåŸºå‡†æ–¹æ³•ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages",
      "pdf_url": "https://arxiv.org/pdf/2508.06336v1",
      "published_date": "2025-08-08 14:11:15 UTC",
      "updated_date": "2025-08-08 14:11:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:12:14.086670+00:00"
    },
    {
      "arxiv_id": "2508.09200v2",
      "title": "Zero-shot self-supervised learning of single breath-hold magnetic resonance cholangiopancreatography (MRCP) reconstruction",
      "title_zh": "å•æ¬¡å±æ¯ç£å…±æŒ¯èƒ°èƒ†ç®¡æˆåƒï¼ˆMRCPï¼‰é‡å»ºçš„é›¶æ ·æœ¬è‡ªç›‘ç£å­¦ä¹ ",
      "authors": [
        "Jinho Kim",
        "Marcel Dominik Nickel",
        "Florian Knoll"
      ],
      "abstract": "To investigate the feasibility of zero-shot self-supervised learning reconstruction for reducing breath-hold times in magnetic resonance cholangiopancreatography (MRCP). Breath-hold MRCP was acquired from 11 healthy volunteers on 3T scanners using an incoherent k-space sampling pattern, leading to 14-second acquisition time and an acceleration factor of R=25. Zero-shot reconstruction was compared with parallel imaging of respiratory-triggered MRCP (338s, R=3) and compressed sensing reconstruction. For two volunteers, breath-hold scans (40s, R=6) were additionally acquired and retrospectively undersampled to R=25 to compute peak signal-to-noise ratio (PSNR). To address long zero-shot training time, the n+m full stages of the zero-shot learning were divided into two parts to reduce backpropagation depth during training: 1) n frozen stages initialized with n-stage pretrained network and 2) m trainable stages initialized either randomly or m-stage pretrained network. Efficiency of our approach was assessed by varying initialization strategies and the number of trainable stages using the retrospectively undersampled data. Zero-shot reconstruction significantly improved visual image quality over compressed sensing, particularly in SNR and ductal delineation, and achieved image quality comparable to that of successful respiratory-triggered acquisitions with regular breathing patterns. Improved initializations enhanced PSNR and reduced reconstruction time. Adjusting frozen/trainable configurations demonstrated that PSNR decreased only slightly from 38.25 dB (0/13) to 37.67 dB (12/1), while training time decreased up to 6.7-fold. Zero-shot learning delivers high-fidelity MRCP reconstructions with reduced breath-hold times, and the proposed partially trainable approach offers a practical solution for translation into time-constrained clinical workflows.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åˆ©ç”¨é›¶æ ·æœ¬è‡ªç›‘ç£å­¦ä¹  (Zero-shot self-supervised learning) æŠ€æœ¯é‡å»ºå•æ¬¡æ†‹æ°”ç£å…±æŒ¯èƒ°èƒ†ç®¡æˆåƒ (MRCP) çš„å¯è¡Œæ€§ï¼Œæ—¨åœ¨æ˜¾è‘—ç¼©çŸ­ä¸´åºŠæ‰«ææ—¶é—´ã€‚ç ”ç©¶äººå‘˜åœ¨ 3T æ‰«æä»ªä¸Šé‡‡ç”¨ä¸ç›¸å¹² k-space é‡‡æ ·æ¨¡å¼ï¼Œåœ¨ 14 ç§’å†…å®ç°äº† R=25 çš„é«˜åŠ é€Ÿå€ç‡é‡‡é›†ã€‚é’ˆå¯¹è®­ç»ƒè€—æ—¶é•¿çš„æŒ‘æˆ˜ï¼Œè¯¥æ–¹æ³•å°†æ¨¡å‹åˆ’åˆ†ä¸ºå›ºå®šé˜¶æ®µ (frozen stages) ä¸å¯è®­ç»ƒé˜¶æ®µ (trainable stages) ä»¥å‡å°‘åå‘ä¼ æ’­æ·±åº¦ï¼Œä½¿è®­ç»ƒé€Ÿåº¦æœ€é«˜æå‡ 6.7 å€ä¸”ç»´æŒäº†è¾ƒé«˜çš„å³°å€¼ä¿¡å™ªæ¯” (PSNR)ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥é‡å»ºæ–¹æ³•åœ¨å›¾åƒä¿¡å™ªæ¯” (SNR) å’Œèƒ†ç®¡è½®å»“æ¸…æ™°åº¦ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„å‹ç¼©æ„ŸçŸ¥ (compressed sensing) æŠ€æœ¯ï¼Œä¸”å…¶å›¾åƒè´¨é‡å¯ä¸å‘¼å¸è§¦å‘é‡‡é›†ç›¸åª²ç¾ã€‚æœ€ç»ˆï¼Œè¯¥ç ”ç©¶è¯æ˜äº†é›¶æ ·æœ¬å­¦ä¹ å¯ä»¥åœ¨æçŸ­çš„æ†‹æ°”æ—¶é—´å†…ç”Ÿæˆé«˜ä¿çœŸåº¦çš„é‡å»ºå›¾åƒï¼Œä¸º MRCP è¿›å…¥æ—¶é—´å—é™çš„ä¸´åºŠå·¥ä½œæµæä¾›äº†é«˜æ•ˆã€å®ç”¨çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "24 pages, 8 figures, 2 tabels",
      "pdf_url": "https://arxiv.org/pdf/2508.09200v2",
      "published_date": "2025-08-08 13:59:20 UTC",
      "updated_date": "2025-12-02 13:45:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:12:19.295470+00:00"
    },
    {
      "arxiv_id": "2508.06318v1",
      "title": "Mixture of Experts Guided by Gaussian Splatters Matters: A new Approach to Weakly-Supervised Video Anomaly Detection",
      "title_zh": "é«˜æ–¯æ³¼æº…å¼•å¯¼ä¸‹çš„æ··åˆä¸“å®¶æ¨¡å‹ï¼šä¸€ç§å¼±ç›‘ç£è§†é¢‘å¼‚å¸¸æ£€æµ‹çš„æ–°æ–¹æ³•",
      "authors": [
        "Giacomo D'Amicantonio",
        "Snehashis Majhi",
        "Quan Kong",
        "Lorenzo Garattoni",
        "Gianpiero Francesca",
        "FranÃ§ois Bremond",
        "Egor Bondarev"
      ],
      "abstract": "Video Anomaly Detection (VAD) is a challenging task due to the variability of anomalous events and the limited availability of labeled data. Under the Weakly-Supervised VAD (WSVAD) paradigm, only video-level labels are provided during training, while predictions are made at the frame level. Although state-of-the-art models perform well on simple anomalies (e.g., explosions), they struggle with complex real-world events (e.g., shoplifting). This difficulty stems from two key issues: (1) the inability of current models to address the diversity of anomaly types, as they process all categories with a shared model, overlooking category-specific features; and (2) the weak supervision signal, which lacks precise temporal information, limiting the ability to capture nuanced anomalous patterns blended with normal events. To address these challenges, we propose Gaussian Splatting-guided Mixture of Experts (GS-MoE), a novel framework that employs a set of expert models, each specialized in capturing specific anomaly types. These experts are guided by a temporal Gaussian splatting loss, enabling the model to leverage temporal consistency and enhance weak supervision. The Gaussian splatting approach encourages a more precise and comprehensive representation of anomalies by focusing on temporal segments most likely to contain abnormal events. The predictions from these specialized experts are integrated through a mixture-of-experts mechanism to model complex relationships across diverse anomaly patterns. Our approach achieves state-of-the-art performance, with a 91.58% AUC on the UCF-Crime dataset, and demonstrates superior results on XD-Violence and MSAD datasets. By leveraging category-specific expertise and temporal guidance, GS-MoE sets a new benchmark for VAD under weak supervision.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Gaussian Splatting-guided Mixture of Experts (GS-MoE)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¼±ç›‘ç£è§†é¢‘å¼‚å¸¸æ£€æµ‹(WSVAD)ä¸­ä¼ ç»Ÿæ¨¡å‹éš¾ä»¥åº”å¯¹å¤šæ ·åŒ–å¼‚å¸¸ç±»å‹ä»¥åŠå¼±ç›‘ç£ä¿¡å·ç¼ºä¹ç²¾ç¡®æ—¶åºä¿¡æ¯çš„é—®é¢˜ã€‚GS-MoEé€šè¿‡å¼•å…¥ä¸€ç»„ä¸“é—¨åŒ–çš„ä¸“å®¶æ¨¡å‹ï¼Œä½¿æ¯ä¸ªä¸“å®¶èƒ½å¤Ÿä¸“æ³¨äºæ•è·ç‰¹å®šç±»åˆ«çš„å¼‚å¸¸ç‰¹å¾ï¼Œä»è€Œå…‹æœäº†å•ä¸€å…±äº«æ¨¡å‹å¯¹ç±»åˆ«ç‰¹å®šä¿¡æ¯åˆ©ç”¨ä¸è¶³çš„å±€é™ã€‚è¯¥æ¡†æ¶åˆ›æ–°æ€§åœ°é‡‡ç”¨äº†æ—¶åºGaussian splattingæŸå¤±å‡½æ•°è¿›è¡Œå¼•å¯¼ï¼Œåˆ©ç”¨æ—¶åºä¸€è‡´æ€§æ¥å¢å¼ºå¼±ç›‘ç£ä¿¡å·ï¼Œä¿ƒä½¿æ¨¡å‹èƒ½å¤Ÿæ›´ç²¾å‡†åœ°å®šä½å¹¶è¡¨å¾æœ€å¯èƒ½åŒ…å«å¼‚å¸¸äº‹ä»¶çš„æ—¶æ®µã€‚é€šè¿‡æ··åˆä¸“å®¶(Mixture-of-Experts)æœºåˆ¶ï¼Œç³»ç»Ÿèƒ½å¤Ÿæœ‰æ•ˆæ•´åˆå„ä¸“å®¶æ¨¡å‹çš„é¢„æµ‹ç»“æœï¼Œä»¥å»ºæ¨¡å¤æ‚å¤šå˜çš„å¼‚å¸¸æ¨¡å¼ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨UCF-Crimeæ•°æ®é›†ä¸Šå–å¾—äº†91.58% AUCçš„State-of-the-artæ€§èƒ½ï¼Œå¹¶åœ¨XD-Violenceå’ŒMSADç­‰æ•°æ®é›†ä¸Šå‡è¡¨ç°å“è¶Šï¼Œä¸ºå¼±ç›‘ç£ä¸‹çš„è§†é¢‘å¼‚å¸¸æ£€æµ‹æä¾›äº†é«˜æ•ˆä¸”å…·ç±»åˆ«é’ˆå¯¹æ€§çš„æ–°æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06318v1",
      "published_date": "2025-08-08 13:48:48 UTC",
      "updated_date": "2025-08-08 13:48:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:12:25.589249+00:00"
    },
    {
      "arxiv_id": "2508.11676v1",
      "title": "Deep Language Geometry: Constructing a Metric Space from LLM Weights",
      "title_zh": "æ·±åº¦è¯­è¨€å‡ ä½•ï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹æƒé‡çš„åº¦é‡ç©ºé—´æ„å»º",
      "authors": [
        "Maksym Shamrai",
        "Vladyslav Hamolia"
      ],
      "abstract": "We introduce a novel framework that utilizes the internal weight activations of modern Large Language Models (LLMs) to construct a metric space of languages. Unlike traditional approaches based on hand-crafted linguistic features, our method automatically derives high-dimensional vector representations by computing weight importance scores via an adapted pruning algorithm. Our approach captures intrinsic language characteristics that reflect linguistic phenomena. We validate our approach across diverse datasets and multilingual LLMs, covering 106 languages. The results align well with established linguistic families while also revealing unexpected inter-language connections that may indicate historical contact or language evolution. The source code, computed language latent vectors, and visualization tool are made publicly available at https://github.com/mshamrai/deep-language-geometry.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Deep Language Geometryï¼Œè¿™æ˜¯ä¸€ç§åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ (LLMs) å†…éƒ¨æƒé‡æ¿€æ´»æ¥æ„å»ºè¯­è¨€åº¦é‡ç©ºé—´ (metric space) çš„æ–°é¢–æ¡†æ¶ã€‚ä¸åŒäºåŸºäºäººå·¥è®¾è®¡è¯­è¨€ç‰¹å¾çš„ä¼ ç»Ÿæ–¹æ³•ï¼Œè¯¥æ–¹æ³•é€šè¿‡é€‚é…çš„å‰ªæç®—æ³• (pruning algorithm) è®¡ç®—æƒé‡é‡è¦æ€§å¾—åˆ†ï¼Œä»è€Œè‡ªåŠ¨æ¨å¯¼å‡ºé«˜ç»´å‘é‡è¡¨ç¤ºã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿæ•æ‰åæ˜ è¯­è¨€ç°è±¡çš„å†…åœ¨ç‰¹å¾ï¼Œå¹¶åœ¨æ¶µç›– 106 ç§è¯­è¨€çš„å¤šè¯­è¨€ LLMs ä¸Šè¿›è¡Œäº†éªŒè¯ã€‚å®éªŒç»“æœä¸ä»…ä¸å·²æœ‰çš„è¯­è¨€å®¶æ— (linguistic families) åˆ†ç±»é«˜åº¦å»åˆï¼Œè¿˜æ­ç¤ºäº†å¯èƒ½æš—ç¤ºå†å²æ¥è§¦æˆ–è¯­è¨€æ¼”åŒ–çš„æ„å¤–å…³è”ã€‚ç›®å‰ï¼Œç ”ç©¶å›¢é˜Ÿå·²å°†æºä»£ç ã€è®¡ç®—å¾—åˆ°çš„è¯­è¨€æ½œå‘é‡ (latent vectors) åŠå¯è§†åŒ–å·¥å…·å‘å…¬ä¼—å¼€æ”¾ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages, accepted to RANLP 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.11676v1",
      "published_date": "2025-08-08 13:48:26 UTC",
      "updated_date": "2025-08-08 13:48:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:12:43.944948+00:00"
    },
    {
      "arxiv_id": "2508.10027v3",
      "title": "LLMCARE: early detection of cognitive impairment via transformer models enhanced by LLM-generated synthetic data",
      "title_zh": "LLMCAREï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆåˆæˆæ•°æ®å¢å¼º Transformer æ¨¡å‹çš„è®¤çŸ¥éšœç¢æ—©æœŸæ£€æµ‹",
      "authors": [
        "Ali Zolnour",
        "Hossein Azadmaleki",
        "Yasaman Haghbin",
        "Fatemeh Taherinezhad",
        "Mohamad Javad Momeni Nezhad",
        "Sina Rashidi",
        "Masoud Khani",
        "AmirSajjad Taleban",
        "Samin Mahdizadeh Sani",
        "Maryam Dadkhah",
        "James M. Noble",
        "Suzanne Bakken",
        "Yadollah Yaghoobzadeh",
        "Abdol-Hossein Vahabie",
        "Masoud Rouhizadeh",
        "Maryam Zolnoori"
      ],
      "abstract": "Alzheimer's disease and related dementias(ADRD) affect nearly five million older adults in the United States, yet more than half remain undiagnosed. Speech-based natural language processing(NLP) offers a scalable approach for detecting early cognitive decline through subtle linguistic markers that may precede clinical diagnosis. This study develops and evaluates a speech-based screening pipeline integrating transformer embeddings with handcrafted linguistic features, synthetic augmentation using large language models(LLMs), and benchmarking of unimodal and multimodal classifiers. External validation assessed generalizability to a MCI-only cohort.\n  Transcripts were drawn from the ADReSSo 2021 benchmark dataset(n=237, Pitt Corpus) and the DementiaBank Delaware corpus(n=205, MCI vs. controls). Ten transformer models were tested under three fine-tuning strategies. A late-fusion model combined embeddings from the top transformer with 110 linguistic features. Five LLMs(LLaMA8B/70B, MedAlpaca7B, Ministral8B,GPT-4o) generated label-conditioned synthetic speech for augmentation, and three multimodal LLMs(GPT-4o,Qwen-Omni,Phi-4) were evaluated in zero-shot and fine-tuned modes. On ADReSSo, the fusion model achieved F1=83.3(AUC=89.5), outperforming transformer-only and linguistic baselines. MedAlpaca7B augmentation(2x) improved F1=85.7, though larger scales reduced gains. Fine-tuning boosted unimodal LLMs(MedAlpaca7B F1=47.7=>78.7), while multimodal models performed lower (Phi-4=71.6;GPT-4o=67.6). On Delaware, the fusion plus 1x MedAlpaca7B model achieved F1=72.8(AUC=69.6). Integrating transformer and linguistic features enhances ADRD detection. LLM-based augmentation improves data efficiency but yields diminishing returns, while current multimodal models remain limited. Validation on an independent MCI cohort supports the pipeline's potential for scalable, clinically relevant early screening.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† LLMCAREï¼Œä¸€ç§æ—¨åœ¨é€šè¿‡ Transformer æ¨¡å‹å’Œå¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) ç”Ÿæˆçš„åˆæˆæ•°æ®æ¥å¢å¼ºé˜¿å°”èŒ¨æµ·é»˜ç—…åŠç›¸å…³ç—´å‘†ç—‡ (ADRD) æ—©æœŸæ£€æµ‹çš„è¯­éŸ³ç­›æŸ¥æµæ°´çº¿ã€‚è¯¥æ¡†æ¶å°† Transformer åµŒå…¥ä¸æ‰‹å·¥è¯­è¨€ç‰¹å¾ç›¸ç»“åˆï¼Œå¹¶åˆ©ç”¨ MedAlpaca7B ç­‰ LLMs ç”Ÿæˆçš„æ ‡ç­¾æ¡ä»¶åˆæˆè¯­éŸ³æ•°æ®è¿›è¡Œå¢å¼ºï¼Œä»¥æå‡æ¨¡å‹çš„è®­ç»ƒæ•ˆç‡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œèåˆæ¨¡å‹åœ¨ ADReSSo 2021 æ•°æ®é›†ä¸Šå–å¾—äº† 83.3 çš„ F1 åˆ†æ•°ï¼Œç» MedAlpaca7B å¢å¼ºåæå‡è‡³ 85.7ï¼Œè¡¨ç°ä¼˜äºä¼ ç»Ÿçš„ Transformer æˆ–çº¯è¯­è¨€ç‰¹å¾åŸºçº¿æ¨¡å‹ã€‚ç ”ç©¶è¿›ä¸€æ­¥å‘ç°ï¼Œå¾®è°ƒèƒ½æ˜¾è‘—æå‡å•æ¨¡æ€ LLMs çš„æ€§èƒ½ï¼Œä½†å½“å‰çš„å¤šæ¨¡æ€æ¨¡å‹åœ¨æ£€æµ‹è®¤çŸ¥éšœç¢æ–¹é¢ä»å­˜åœ¨ä¸€å®šå±€é™æ€§ã€‚é€šè¿‡åœ¨ç‹¬ç«‹çš„è½»åº¦è®¤çŸ¥éšœç¢ (MCI) é˜Ÿåˆ—ä¸Šè¿›è¡Œå¤–éƒ¨éªŒè¯ï¼Œè¯æ˜äº†è¯¥æµæ°´çº¿åœ¨å®ç°å¯æ‰©å±•ä¸”å…·æœ‰ä¸´åºŠç›¸å…³æ€§çš„æ—©æœŸç­›æŸ¥ä¸­å…·æœ‰å·¨å¤§æ½œåŠ›ã€‚è¯¥å·¥ä½œä¸ºåˆ©ç”¨ AI æŠ€æœ¯è¿›è¡Œå¤§è§„æ¨¡ã€éä¾µå…¥æ€§çš„è®¤çŸ¥é€€åŒ–ç›‘æµ‹å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.10027v3",
      "published_date": "2025-08-08 13:44:55 UTC",
      "updated_date": "2025-11-10 09:23:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:12:40.186357+00:00"
    },
    {
      "arxiv_id": "2508.08308v1",
      "title": "First Ask Then Answer: A Framework Design for AI Dialogue Based on Supplementary Questioning with Large Language Models",
      "title_zh": "First Ask Then Answerï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹è¡¥å……æé—®çš„äººå·¥æ™ºèƒ½å¯¹è¯æ¡†æ¶è®¾è®¡",
      "authors": [
        "Chuanruo Fu",
        "Yuncheng Du"
      ],
      "abstract": "Large Language Models (LLMs) often struggle to deliver accurate and actionable answers when user-provided information is incomplete or ill-specified. We propose a new interaction paradigm, First Ask Then Answer (FATA), in which, through prompt words, LLMs are guided to proactively generate multidimensional supplementary questions for users prior to response generation. Subsequently, by integrating user-provided supplementary information with the original query through sophisticated prompting techniques, we achieve substantially improved response quality and relevance. In contrast to existing clarification approaches -- such as the CLAM framework oriented to ambiguity and the self-interrogation Self-Ask method -- FATA emphasizes completeness (beyond mere disambiguation) and user participation (inviting human input instead of relying solely on model-internal reasoning). It also adopts a single-turn strategy: all clarifying questions are produced at once, thereby reducing dialogue length and improving efficiency. Conceptually, FATA uses the reasoning power of LLMs to scaffold user expression, enabling non-expert users to formulate more comprehensive and contextually relevant queries. To evaluate FATA, we constructed a multi-domain benchmark and compared it with two controls: a baseline prompt (B-Prompt) and a context-enhanced expert prompt (C-Prompt). Experimental results show that FATA outperforms B-Prompt by approximately 40% in aggregate metrics and exhibits a coefficient of variation 8% lower than C-Prompt, indicating superior stability.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨ç”¨æˆ·åˆå§‹æŸ¥è¯¢ä¿¡æ¯ä¸å®Œæ•´æˆ–æè¿°ä¸æ¸…æ—¶éš¾ä»¥æä¾›å‡†ç¡®å›ç­”çš„é—®é¢˜ï¼Œæå‡ºäº†åä¸º \"å…ˆé—®åç­”\" (First Ask Then Answer, FATA) çš„æ–°å‹äº¤äº’èŒƒå¼ã€‚è¯¥æ¡†æ¶åˆ©ç”¨æç¤ºè¯å¼•å¯¼ LLMs åœ¨ç”Ÿæˆæœ€ç»ˆå›å¤å‰ï¼Œä¸»åŠ¨å‘ç”¨æˆ·æå‡ºå¤šç»´åº¦çš„è¡¥å……é—®é¢˜ï¼Œéšåé€šè¿‡å¤æ‚çš„æç¤ºæŠ€æœ¯å°†ç”¨æˆ·åé¦ˆä¸åŸå§‹æŸ¥è¯¢æ•´åˆä»¥æå‡å›å¤è´¨é‡ã€‚ä¸ç°æœ‰çš„ CLAM æˆ– Self-Ask ç­‰æ¾„æ¸…æ–¹æ³•ç›¸æ¯”ï¼ŒFATA æ›´åŠ å¼ºè°ƒä¿¡æ¯çš„å®Œæ•´æ€§ä¸ç”¨æˆ·çš„ä¸»åŠ¨å‚ä¸ï¼Œå¹¶é‡‡ç”¨å•è½®ç­–ç•¥ä¸€æ¬¡æ€§äº§ç”Ÿæ‰€æœ‰æ¾„æ¸…é—®é¢˜ä»¥ä¼˜åŒ–å¯¹è¯æ•ˆç‡ã€‚é€šè¿‡åœ¨å¤šé¢†åŸŸåŸºå‡†æµ‹è¯•ä¸Šçš„è¯„ä¼°ï¼ŒFATA åœ¨ç»¼åˆæŒ‡æ ‡ä¸Šæ¯”åŸºçº¿æç¤º (B-Prompt) æå‡äº†çº¦ 40%ã€‚æ­¤å¤–ï¼ŒFATA çš„å˜å¼‚ç³»æ•°æ¯”ä¸Šä¸‹æ–‡å¢å¼ºçš„ä¸“å®¶æç¤º (C-Prompt) ä½ 8%ï¼Œå±•ç°å‡ºæ›´å¼ºçš„è¾“å‡ºç¨³å®šæ€§ã€‚è¯¥æ¡†æ¶æœ‰æ•ˆåœ°åˆ©ç”¨ LLMs çš„æ¨ç†èƒ½åŠ›è¾…åŠ©éä¸“å®¶ç”¨æˆ·è¿›è¡Œè¡¨è¾¾ï¼Œä¸ºæ„å»ºæ›´å…¨é¢ã€æ›´å…·ä¸Šä¸‹æ–‡ç›¸å…³æ€§çš„ AI å¯¹è¯æä¾›äº†æ–°æ€è·¯ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.08308v1",
      "published_date": "2025-08-08 13:39:47 UTC",
      "updated_date": "2025-08-08 13:39:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:12:44.439393+00:00"
    },
    {
      "arxiv_id": "2508.09199v1",
      "title": "$Î”$-AttnMask: Attention-Guided Masked Hidden States for Efficient Data Selection and Augmentation",
      "title_zh": "$\\Delta$-AttnMaskï¼šåŸºäºæ³¨æ„åŠ›å¼•å¯¼éšè—çŠ¶æ€æ©ç çš„é«˜æ•ˆæ•°æ®é€‰æ‹©ä¸å¢å¼º",
      "authors": [
        "Jucheng Hu",
        "Suorong Yang",
        "Dongzhan Zhou"
      ],
      "abstract": "Visual Instruction Finetuning (VIF) is pivotal for post-training Vision-Language Models (VLMs). Unlike unimodal instruction finetuning in plain-text large language models, which mainly requires instruction datasets to enable model instruction-following ability, VIF also requires multimodal data to enable joint visual and textual understanding; therefore, it typically requires more data. Consequently, VIF imposes stricter data selection challenges: the method must scale efficiently to handle larger data demands while ensuring the quality of both visual and textual content, as well as their alignment. Despite its critical impact on performance, data selection for VIF remains an understudied area. In this paper, we propose $Î”$-AttnMask. This data-efficient framework quantifies sample quality through attention-guided masking of the model's hidden states, jointly evaluating image-text pairs without requiring domain labels, auxiliary models, or extra training. By computing loss differences ($Î”$) between the original states and states masked using high-attention regions, $Î”$-AttnMask intrinsically assesses sample quality. Experiments across multiple VLMs and datasets show that $Î”$-AttnMask achieves state-of-the-art performance with just 20% of data, accelerating training by 5x while surpassing full-dataset baselines by +10.1% in overall accuracy. Its model-agnostic and data-agnostic design ensures broad applicability across modalities and architectures.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† $\\Delta$-AttnMaskï¼Œä¸€ä¸ªæ—¨åœ¨ä¼˜åŒ–è§†è§‰æŒ‡ä»¤å¾®è°ƒ(Visual Instruction Finetuning)æ•°æ®é€‰æ‹©ä¸å¢å¼ºçš„é«˜æ•ˆæ¡†æ¶ï¼Œè§£å†³äº†è§†è§‰è¯­è¨€æ¨¡å‹(VLMs)åœ¨å¤„ç†å¤§è§„æ¨¡å¤šæ¨¡æ€æ•°æ®æ—¶çš„è´¨é‡è¯„ä¼°éš¾é¢˜ã€‚è¯¥æ¡†æ¶é€šè¿‡æ³¨æ„åŠ›å¼•å¯¼çš„éšè—çŠ¶æ€æ©ç (Attention-Guided Masking)æŠ€æœ¯é‡åŒ–æ ·æœ¬è´¨é‡ï¼Œæ— éœ€é¢†åŸŸæ ‡ç­¾ã€è¾…åŠ©æ¨¡å‹æˆ–é¢å¤–è®­ç»ƒå³å¯å®ç°å›¾åƒ-æ–‡æœ¬å¯¹çš„è”åˆè¯„ä¼°ã€‚é€šè¿‡è®¡ç®—åŸå§‹çŠ¶æ€ä¸é«˜æ³¨æ„åŠ›åŒºåŸŸæ©ç çŠ¶æ€ä¹‹é—´çš„æŸå¤±å·®($\\Delta$)ï¼Œ$\\Delta$-AttnMask èƒ½å¤Ÿæœ‰æ•ˆè¯†åˆ«å¹¶ç­›é€‰é«˜è´¨é‡æ ·æœ¬ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•ä»…ä½¿ç”¨ 20% çš„æ•°æ®å³å¯è¾¾åˆ° State-of-the-Art æ€§èƒ½ï¼Œåœ¨å°†è®­ç»ƒé€Ÿåº¦æé«˜ 5 å€çš„åŒæ—¶ï¼Œç»¼åˆå‡†ç¡®ç‡æ¯”å…¨é‡æ•°æ®é›†åŸºçº¿æå‡äº† 10.1%ã€‚ç”±äºé‡‡ç”¨äº†æ¨¡å‹æ— å…³(Model-Agnostic)å’Œæ•°æ®æ— å…³(Data-Agnostic)çš„è®¾è®¡ï¼Œè¯¥æ¡†æ¶åœ¨ä¸åŒæ¨¡æ€å’Œæ¨¡å‹æ¶æ„ä¸­å±•ç°å‡ºæå¼ºçš„é€šç”¨æ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09199v1",
      "published_date": "2025-08-08 13:25:30 UTC",
      "updated_date": "2025-08-08 13:25:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:12:45.041055+00:00"
    },
    {
      "arxiv_id": "2508.06301v1",
      "title": "FedMeNF: Privacy-Preserving Federated Meta-Learning for Neural Fields",
      "title_zh": "FedMeNFï¼šé’ˆå¯¹ç¥ç»åœºçš„éšç§ä¿æŠ¤è”é‚¦å…ƒå­¦ä¹ ",
      "authors": [
        "Junhyeog Yun",
        "Minui Hong",
        "Gunhee Kim"
      ],
      "abstract": "Neural fields provide a memory-efficient representation of data, which can effectively handle diverse modalities and large-scale data. However, learning to map neural fields often requires large amounts of training data and computations, which can be limited to resource-constrained edge devices. One approach to tackle this limitation is to leverage Federated Meta-Learning (FML), but traditional FML approaches suffer from privacy leakage. To address these issues, we introduce a novel FML approach called FedMeNF. FedMeNF utilizes a new privacy-preserving loss function that regulates privacy leakage in the local meta-optimization. This enables the local meta-learner to optimize quickly and efficiently without retaining the client's private data. Our experiments demonstrate that FedMeNF achieves fast optimization speed and robust reconstruction performance, even with few-shot or non-IID data across diverse data modalities, while preserving client data privacy.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† FedMeNFï¼Œä¸€ç§ä¸“ä¸º Neural fields è®¾è®¡çš„éšç§ä¿æŠ¤ Federated Meta-Learning (FML) æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³è¾¹ç¼˜è®¾å¤‡åœ¨å¤„ç†å¤§è§„æ¨¡å¤šæ ·åŒ–æ¨¡æ€æ•°æ®æ—¶é¢ä¸´çš„è®¡ç®—èµ„æºå—é™åŠä¼ ç»Ÿ FML çš„éšç§æ³„éœ²é—®é¢˜ã€‚FedMeNF å¼•å…¥äº†ä¸€ç§å…¨æ–°çš„éšç§ä¿æŠ¤æŸå¤±å‡½æ•°ï¼Œè¯¥å‡½æ•°åœ¨æœ¬åœ°å…ƒä¼˜åŒ–è¿‡ç¨‹ä¸­è°ƒèŠ‚éšç§æ³„æ¼ï¼Œç¡®ä¿æœ¬åœ°å…ƒå­¦ä¹ å™¨åœ¨æ— éœ€ä¿ç•™å®¢æˆ·ç«¯ç§æœ‰æ•°æ®çš„æƒ…å†µä¸‹å®ç°å¿«é€Ÿä¸”é«˜æ•ˆçš„ä¼˜åŒ–ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒFedMeNF åœ¨å¤„ç† few-shot æˆ– non-IID æ•°æ®æ—¶ï¼Œè·¨å¤šç§æ•°æ®æ¨¡æ€å‡è¡¨ç°å‡ºæå¿«çš„ä¼˜åŒ–é€Ÿåº¦å’Œç¨³å¥çš„é‡æ„æ€§èƒ½ã€‚è¯¥ç ”ç©¶é€šè¿‡åˆ›æ–°çš„è”é‚¦å…ƒå­¦ä¹ æœºåˆ¶ï¼Œåœ¨ç¡®ä¿å®¢æˆ·ç«¯éšç§å®‰å…¨çš„åŒæ—¶ï¼Œæ˜¾è‘—æå‡äº† Neural fields åœ¨èµ„æºå—é™ç¯å¢ƒä¸‹çš„å­¦ä¹ æ•ˆç‡ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "ICCV 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.06301v1",
      "published_date": "2025-08-08 13:24:57 UTC",
      "updated_date": "2025-08-08 13:24:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:12:39.487454+00:00"
    },
    {
      "arxiv_id": "2508.06296v2",
      "title": "LLM Robustness Leaderboard v1 --Technical report",
      "title_zh": "LLM é²æ£’æ€§æ’è¡Œæ¦œ v1 â€”â€” æŠ€æœ¯æŠ¥å‘Š",
      "authors": [
        "Pierre PeignÃ© - Lefebvre",
        "Quentin Feuillade-Montixi",
        "Tom David",
        "Nicolas Miailhe"
      ],
      "abstract": "This technical report accompanies the LLM robustness leaderboard published by PRISM Eval for the Paris AI Action Summit. We introduce PRISM Eval Behavior Elicitation Tool (BET), an AI system performing automated red-teaming through Dynamic Adversarial Optimization that achieves 100% Attack Success Rate (ASR) against 37 of 41 state-of-the-art LLMs. Beyond binary success metrics, we propose a fine-grained robustness metric estimating the average number of attempts required to elicit harmful behaviors, revealing that attack difficulty varies by over 300-fold across models despite universal vulnerability. We introduce primitive-level vulnerability analysis to identify which jailbreaking techniques are most effective for specific hazard categories. Our collaborative evaluation with trusted third parties from the AI Safety Network demonstrates practical pathways for distributed robustness assessment across the community.",
      "tldr_zh": "æœ¬æŠ¥å‘Šä»‹ç»äº†ç”±PRISM Evalå‘å¸ƒçš„LLM Robustness Leaderboard v1ï¼Œå¹¶è¯¦ç»†é˜è¿°äº†å…¶å¼€å‘çš„PRISM Eval Behavior Elicitation Tool (BET) ç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿé‡‡ç”¨Dynamic Adversarial OptimizationæŠ€æœ¯æ‰§è¡Œè‡ªåŠ¨åŒ–çº¢é˜Ÿæµ‹è¯•(red-teaming)ï¼Œåœ¨å¯¹41ä¸ªæœ€å…ˆè¿›å¤§è¯­è¨€æ¨¡å‹çš„æµ‹è¯•ä¸­ï¼Œå¯¹å…¶ä¸­37ä¸ªæ¨¡å‹å®ç°äº†100%çš„Attack Success Rate (ASR)ã€‚é™¤äº†äºŒå…ƒæˆåŠŸæŒ‡æ ‡ï¼Œç ”ç©¶è¿˜æå‡ºäº†ä¸€ç§ç»†ç²’åº¦çš„é²æ£’æ€§åº¦é‡æ ‡å‡†ï¼Œé€šè¿‡ä¼°è®¡è¯±å‘æœ‰å®³è¡Œä¸ºæ‰€éœ€çš„å¹³å‡å°è¯•æ¬¡æ•°ï¼Œæ­ç¤ºäº†ä¸åŒæ¨¡å‹é—´çš„æ”»å‡»éš¾åº¦å·®å¼‚å¯è¾¾300å€ä»¥ä¸Šã€‚ç ”ç©¶è¿›ä¸€æ­¥å¼•å…¥äº†primitive-level vulnerability analysisï¼Œç”¨ä»¥è¯†åˆ«é’ˆå¯¹ç‰¹å®šé£é™©ç±»åˆ«æœ€æœ‰æ•ˆçš„jailbreaking techniquesã€‚é€šè¿‡ä¸AI Safety Networkç¬¬ä¸‰æ–¹æœºæ„çš„åä½œè¯„ä¼°ï¼Œè¯¥ç ”ç©¶å±•ç¤ºäº†åˆ†å¸ƒå¼é²æ£’æ€§è¯„ä¼°çš„å®è·µè·¯å¾„ï¼Œä¸ºå¢å¼ºå¤§å‹è¯­è¨€æ¨¡å‹çš„å®‰å…¨æ€§æä¾›äº†é‡è¦æŠ€æœ¯æ”¯æŒã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06296v2",
      "published_date": "2025-08-08 13:15:40 UTC",
      "updated_date": "2025-08-13 08:27:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:13:03.530673+00:00"
    },
    {
      "arxiv_id": "2508.06287v1",
      "title": "Advanced Deep Learning Techniques for Accurate Lung Cancer Detection and Classification",
      "title_zh": "ç”¨äºè‚ºç™Œç²¾å‡†æ£€æµ‹ä¸åˆ†ç±»çš„å…ˆè¿›æ·±åº¦å­¦ä¹ æŠ€æœ¯",
      "authors": [
        "Mobarak Abumohsen",
        "Enrique Costa-Montenegro",
        "Silvia GarcÃ­a-MÃ©ndez",
        "Amani Yousef Owda",
        "Majdi Owda"
      ],
      "abstract": "Lung cancer (LC) ranks among the most frequently diagnosed cancers and is one of the most common causes of death for men and women worldwide. Computed Tomography (CT) images are the most preferred diagnosis method because of their low cost and their faster processing times. Many researchers have proposed various ways of identifying lung cancer using CT images. However, such techniques suffer from significant false positives, leading to low accuracy. The fundamental reason results from employing a small and imbalanced dataset. This paper introduces an innovative approach for LC detection and classification from CT images based on the DenseNet201 model. Our approach comprises several advanced methods such as Focal Loss, data augmentation, and regularization to overcome the imbalanced data issue and overfitting challenge. The findings show the appropriateness of the proposal, attaining a promising performance of 98.95% accuracy.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è‚ºç™Œ(Lung cancer)åœ¨è¯Šæ–­è¿‡ç¨‹ä¸­å› CTå½±åƒæ•°æ®é›†ä¸å¹³è¡¡ä¸”è§„æ¨¡è¾ƒå°å¯¼è‡´çš„é«˜å‡é˜³æ€§é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºDenseNet201æ¨¡å‹çš„åˆ›æ–°æ£€æµ‹ä¸åˆ†ç±»æ–¹æ¡ˆã€‚ä¸ºäº†å…‹æœæ•°æ®ä¸å¹³è¡¡å’Œè¿‡æ‹Ÿåˆ(overfitting)æŒ‘æˆ˜ï¼Œç ”ç©¶å›¢é˜Ÿåœ¨æ¨¡å‹è®­ç»ƒä¸­æ•´åˆäº†Focal Lossã€æ•°æ®å¢å¼º(data augmentation)ä»¥åŠæ­£åˆ™åŒ–(regularization)ç­‰å…ˆè¿›æ·±åº¦å­¦ä¹ æŠ€æœ¯ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨è‚ºç™Œæ£€æµ‹ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå–å¾—äº†98.95%çš„åˆ†ç±»å‡†ç¡®ç‡(accuracy)ã€‚è¿™ä¸€æˆæœè¯æ˜äº†æ”¹è¿›åçš„æ·±åº¦å­¦ä¹ æ¶æ„åœ¨æå‡åŒ»å­¦å½±åƒè¯Šæ–­ç²¾åº¦æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œä¸ºä¸´åºŠè‚ºç™Œç­›æŸ¥æä¾›äº†é«˜å¯é æ€§çš„æŠ€æœ¯æ”¯æŒã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06287v1",
      "published_date": "2025-08-08 13:09:52 UTC",
      "updated_date": "2025-08-08 13:09:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:13:00.642862+00:00"
    },
    {
      "arxiv_id": "2508.09198v1",
      "title": "ADT4Coupons: An Innovative Framework for Sequential Coupon Distribution in E-commerce",
      "title_zh": "ADT4Couponsï¼šç”µå­å•†åŠ¡åºåˆ—åŒ–ä¼˜æƒ åˆ¸å‘æ”¾çš„åˆ›æ–°æ¡†æ¶",
      "authors": [
        "Li Kong",
        "Bingzhe Wang",
        "Zhou Chen",
        "Suhan Hu",
        "Yuchao Ma",
        "Qi Qi",
        "Suoyuan Song",
        "Bicheng Jin"
      ],
      "abstract": "Coupon distribution is a critical marketing strategy used by online platforms to boost revenue and enhance user engagement. Regrettably, existing coupon distribution strategies fall far short of effectively leveraging the complex sequential interactions between platforms and users. This critical oversight, despite the abundance of e-commerce log data, has precipitated a performance plateau. In this paper, we focus on the scene that the platforms make sequential coupon distribution decision multiple times for various users, with each user interacting with the platform repeatedly. Based on this marketing scenario, we propose a novel marketing framework, named Aligned Decision Transformer for Coupons (ADT4Coupons), to directly devise coupon distribution policy for long-term revenue boosting. ADT4Coupons enables optimized online decision-making in a variety of real-world marketing scenarios. It achieves this by seamlessly integrating three key characteristics, general scenarios, sequential modeling with more comprehensive historical data, and efficient iterative updates within a unified framework. Furthermore, empirical results on real-world industrial dataset, alongside public and synthetic datasets demonstrate the superiority of our framework.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç”µå­å•†åŠ¡å¹³å°åœ¨ä¼˜æƒ åˆ¸å‘æ”¾è¿‡ç¨‹ä¸­æœªèƒ½å……åˆ†åˆ©ç”¨ç”¨æˆ·ä¸å¹³å°é—´å¤æ‚åºåˆ—äº¤äº’çš„é—®é¢˜ï¼Œæå‡ºäº†åä¸ºADT4Couponsï¼ˆAligned Decision Transformer for Couponsï¼‰çš„åˆ›æ–°æ¡†æ¶ã€‚è¯¥æ¡†æ¶ä¸“æ³¨äºå¤šè½®æ¬¡çš„åºåˆ—ä¼˜æƒ åˆ¸å‘æ”¾å†³ç­–åœºæ™¯ï¼Œé€šè¿‡å°†é€šç”¨åœºæ™¯é€‚é…ã€åŸºäºå…¨é¢å†å²æ•°æ®çš„åºåˆ—å»ºæ¨¡ï¼ˆsequential modelingï¼‰ä»¥åŠé«˜æ•ˆçš„è¿­ä»£æ›´æ–°æ•´åˆè¿›ç»Ÿä¸€ä½“ç³»ï¼Œæ—¨åœ¨å®ç°é•¿æœŸæ”¶ç›Šï¼ˆlong-term revenue boostingï¼‰çš„æœ€å¤§åŒ–ã€‚ADT4Couponsèƒ½å¤Ÿç›´æ¥åœ¨å¤šæ ·åŒ–çš„çœŸå®è¥é”€åœºæ™¯ä¸­ä¼˜åŒ–åœ¨çº¿å†³ç­–è¿‡ç¨‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨çœŸå®å·¥ä¸šæ•°æ®é›†ã€å…¬å¼€æ•°æ®é›†åŠåˆæˆæ•°æ®é›†ä¸Šå‡è¡¨ç°å‡ºæ˜¾è‘—ä¼˜äºç°æœ‰ç­–ç•¥çš„æ€§èƒ½ã€‚è¿™ä¸€ç ”ç©¶ä¸ºå¤„ç†ç”µå•†ç¯å¢ƒä¸‹å¤æ‚çš„å¾ªç¯äº¤äº’è¡Œä¸ºå¹¶æå‡è¥é”€æ•ˆç‡æä¾›äº†å…¨æ–°çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09198v1",
      "published_date": "2025-08-08 13:03:17 UTC",
      "updated_date": "2025-08-08 13:03:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:13:10.143150+00:00"
    },
    {
      "arxiv_id": "2508.06269v1",
      "title": "OM2P: Offline Multi-Agent Mean-Flow Policy",
      "title_zh": "OM2Pï¼šç¦»çº¿å¤šæ™ºèƒ½ä½“å‡å€¼æµç­–ç•¥",
      "authors": [
        "Zhuoran Li",
        "Xun Wang",
        "Hai Zhong",
        "Longbo Huang"
      ],
      "abstract": "Generative models, especially diffusion and flow-based models, have been promising in offline multi-agent reinforcement learning. However, integrating powerful generative models into this framework poses unique challenges. In particular, diffusion and flow-based policies suffer from low sampling efficiency due to their iterative generation processes, making them impractical in time-sensitive or resource-constrained settings. To tackle these difficulties, we propose OM2P (Offline Multi-Agent Mean-Flow Policy), a novel offline MARL algorithm to achieve efficient one-step action sampling. To address the misalignment between generative objectives and reward maximization, we introduce a reward-aware optimization scheme that integrates a carefully-designed mean-flow matching loss with Q-function supervision. Additionally, we design a generalized timestep distribution and a derivative-free estimation strategy to reduce memory overhead and improve training stability. Empirical evaluations on Multi-Agent Particle and MuJoCo benchmarks demonstrate that OM2P achieves superior performance, with up to a 3.8x reduction in GPU memory usage and up to a 10.8x speed-up in training time. Our approach represents the first to successfully integrate mean-flow model into offline MARL, paving the way for practical and scalable generative policies in cooperative multi-agent settings.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†OM2P (Offline Multi-Agent Mean-Flow Policy)ï¼Œæ—¨åœ¨è§£å†³ç”Ÿæˆå¼æ¨¡å‹åœ¨ç¦»çº¿å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹  (offline MARL) ä¸­å› è¿­ä»£ç”Ÿæˆè¿‡ç¨‹å¯¼è‡´é‡‡æ ·æ•ˆç‡ä½ä¸‹ã€éš¾ä»¥åº”ç”¨äºæ—¶é—´æ•æ„Ÿåœºæ™¯çš„é—®é¢˜ã€‚OM2Pé€šè¿‡å¼•å…¥ä¸€ç§å¥–åŠ±æ„ŸçŸ¥çš„ä¼˜åŒ–æ–¹æ¡ˆï¼Œå°†ç²¾å¿ƒè®¾è®¡çš„ mean-flow matching loss ä¸ Q-function ç›‘ç£ç›¸ç»“åˆï¼Œæœ‰æ•ˆè§£å†³äº†ç”Ÿæˆç›®æ ‡ä¸å¥–åŠ±æœ€å¤§åŒ–ä¹‹é—´çš„ä¸ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶è®¾è®¡äº†å¹¿ä¹‰æ—¶é—´æ­¥åˆ†å¸ƒ (generalized timestep distribution) å’Œæ— å¯¼æ•°ä¼°è®¡ç­–ç•¥ (derivative-free estimation strategy)ï¼Œæ˜¾è‘—é™ä½äº†å†…å­˜å¼€é”€å¹¶å¢å¼ºäº†è®­ç»ƒç¨³å®šæ€§ã€‚åœ¨ Multi-Agent Particle å’Œ MuJoCo åŸºå‡†æµ‹è¯•ä¸­çš„å®éªŒç»“æœè¡¨æ˜ï¼ŒOM2P å®ç°äº†é«˜æ•ˆçš„ä¸€æ­¥åŠ¨ä½œé‡‡æ ·ï¼Œåœ¨ä¿æŒå“è¶Šæ€§èƒ½çš„åŒæ—¶ï¼ŒGPU å†…å­˜å ç”¨å‡å°‘äº† 3.8 å€ï¼Œè®­ç»ƒé€Ÿåº¦æå‡äº† 10.8 å€ã€‚è¯¥å·¥ä½œæ˜¯é¦–æ¬¡æˆåŠŸå°† mean-flow model æ•´åˆè¿›ç¦»çº¿ MARL çš„å°è¯•ï¼Œä¸ºåœ¨åä½œå¤šæ™ºèƒ½ä½“ä»»åŠ¡ä¸­éƒ¨ç½²å®ç”¨ä¸”å¯æ‰©å±•çš„ç”Ÿæˆå¼ç­–ç•¥å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06269v1",
      "published_date": "2025-08-08 12:38:56 UTC",
      "updated_date": "2025-08-08 12:38:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:13:13.034428+00:00"
    },
    {
      "arxiv_id": "2508.06264v1",
      "title": "Numerical Considerations in Weighted Model Counting",
      "title_zh": "åŠ æƒæ¨¡å‹è®¡æ•°çš„æ•°å€¼è€ƒé‡",
      "authors": [
        "Randal E. Bryant"
      ],
      "abstract": "Weighted model counting computes the sum of the rational-valued weights associated with the satisfying assignments for a Boolean formula, where the weight of an assignment is given by the product of the weights assigned to the positive and negated variables comprising the assignment. Weighted model counting finds applications across a variety of domains including probabilistic reasoning and quantitative risk assessment.\n  Most weighted model counting programs operate by (explicitly or implicitly) converting the input formula into a form that enables arithmetic evaluation, using multiplication for conjunctions and addition for disjunctions. Performing this evaluation using floating-point arithmetic can yield inaccurate results, and it cannot quantify the level of precision achieved. Computing with rational arithmetic gives exact results, but it is costly in both time and space.\n  This paper describes how to combine multiple numeric representations to efficiently compute weighted model counts that are guaranteed to achieve a user-specified precision. When all weights are nonnegative, we prove that the precision loss of arithmetic evaluation using floating-point arithmetic can be tightly bounded. We show that supplementing a standard IEEE double-precision representation with a separate 64-bit exponent, a format we call extended-range double (ERD), avoids the underflow and overflow issues commonly encountered in weighted model counting. For problems with mixed negative and positive weights, we show that a combination of interval floating-point arithmetic and rational arithmetic can achieve the twin goals of efficiency and guaranteed precision. For our evaluations, we have devised especially challenging formulas and weight assignments, demonstrating the robustness of our approach.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åŠ æƒæ¨¡å‹è®¡æ•° (Weighted Model Counting, WMC) ä¸­çš„æ•°å€¼è®¡ç®—é—®é¢˜ï¼Œæ—¨åœ¨è§£å†³æµ®ç‚¹è¿ç®—ç²¾åº¦ä¸è¶³ä¸æœ‰ç†æ•°è¿ç®—æ•ˆç‡ä½ä¸‹ä¹‹é—´çš„çŸ›ç›¾ã€‚ä½œè€…æå‡ºäº†ä¸€ç§ç»“åˆå¤šç§æ•°å€¼è¡¨ç¤ºçš„è®¡ç®—æ¡†æ¶ï¼Œèƒ½å¤Ÿé«˜æ•ˆå®ç°ç”¨æˆ·æŒ‡å®šçš„ç²¾åº¦ä¿è¯ã€‚é’ˆå¯¹éè´Ÿæƒé‡åœºæ™¯ï¼Œç ”ç©¶è¯æ˜äº†æµ®ç‚¹è¿ç®—ç²¾åº¦æŸå¤±çš„ç´§ç¡®ç•Œé™ï¼Œå¹¶å¼•å…¥æ‰©å±•èŒƒå›´åŒç²¾åº¦ (Extended-Range Double, ERD) æ ¼å¼ä»¥è§£å†³ä¸Šæº¢å’Œä¸‹æº¢é—®é¢˜ã€‚å¯¹äºæ··åˆæ­£è´Ÿæƒé‡çš„å¤æ‚æƒ…å½¢ï¼Œé€šè¿‡æ•´åˆåŒºé—´æµ®ç‚¹è¿ç®— (Interval Floating-Point Arithmetic) ä¸æœ‰ç†æ•°è¿ç®—ï¼ŒæˆåŠŸå…¼é¡¾äº†è®¡ç®—æ•ˆç‡ä¸ç²¾åº¦å¯é æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤„ç†æå…·æŒ‘æˆ˜æ€§çš„å…¬å¼å’Œæƒé‡åˆ†é…æ—¶è¡¨ç°å‡ºæå¼ºçš„ç¨³å¥æ€§ï¼Œä¸ºæ¦‚ç‡æ¨ç†ç­‰é¢†åŸŸçš„ç²¾ç¡®é‡åŒ–åˆ†ææä¾›äº†æœ‰åŠ›æ”¯æ’‘ã€‚",
      "categories": [
        "math.NA",
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "math.NA",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06264v1",
      "published_date": "2025-08-08 12:28:49 UTC",
      "updated_date": "2025-08-08 12:28:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:13:12.238529+00:00"
    },
    {
      "arxiv_id": "2508.06263v2",
      "title": "Symmetry breaking for inductive logic programming",
      "title_zh": "å½’çº³é€»è¾‘ç¨‹åºè®¾è®¡çš„å¯¹ç§°æ€§ç ´ç¼º",
      "authors": [
        "Andrew Cropper",
        "David M. Cerna",
        "Matti JÃ¤rvisalo"
      ],
      "abstract": "The goal of inductive logic programming is to search for a hypothesis that generalises training data and background knowledge. The challenge is searching vast hypothesis spaces, which is exacerbated because many logically equivalent hypotheses exist. To address this challenge, we introduce a method to break symmetries in the hypothesis space. We implement our idea in answer set programming. Our experiments on multiple domains, including visual reasoning and game playing, show that our approach can reduce solving times from over an hour to just 17 seconds.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å½’çº³é€»è¾‘ç¨‹åºè®¾è®¡ (Inductive Logic Programming, ILP) åœ¨æœç´¢å‡è®¾ç©ºé—´æ—¶å› å­˜åœ¨å¤§é‡é€»è¾‘ç­‰ä»·å‡è®¾è€Œå¯¼è‡´æ•ˆç‡ä½ä¸‹çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ‰“ç ´å¯¹ç§°æ€§ (Symmetry Breaking) çš„æ–°æ–¹æ³•ã€‚ç ”ç©¶è€…åœ¨ç­”æ¡ˆé›†ç¨‹åºè®¾è®¡ (Answer Set Programming, ASP) æ¡†æ¶ä¸‹å®ç°äº†è¯¥ç®—æ³•ï¼Œæ—¨åœ¨é€šè¿‡æ¶ˆé™¤å†—ä½™çš„ç­‰ä»·å‡è®¾æ¥ä¼˜åŒ–æœç´¢è·¯å¾„ã€‚åœ¨åŒ…æ‹¬è§†è§‰æ¨ç† (Visual Reasoning) å’Œåšå¼ˆ (Game Playing) åœ¨å†…çš„å¤šä¸ªé¢†åŸŸè¿›è¡Œçš„å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•èƒ½æ˜¾è‘—æé«˜æ±‚è§£æ•ˆç‡ï¼Œå°†åŸæœ¬éœ€è¦ä¸€ä¸ªå¤šå°æ—¶çš„è®¡ç®—æ—¶é—´å¤§å¹…ç¼©çŸ­è‡³ä»… 17 ç§’ã€‚è¿™é¡¹å·¥ä½œä¸ºè§£å†³å¤§è§„æ¨¡å‡è®¾ç©ºé—´ä¸­çš„å½’çº³å­¦ä¹ æŒ‘æˆ˜æä¾›äº†æœ‰æ•ˆçš„æŠ€æœ¯æ”¯æ’‘ï¼Œå±•ç¤ºäº†å¯¹ç§°æ€§æ¶ˆé™¤åœ¨æå‡é€»è¾‘æ¨ç†ç³»ç»Ÿæ€§èƒ½æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06263v2",
      "published_date": "2025-08-08 12:28:42 UTC",
      "updated_date": "2025-08-11 05:05:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:13:17.151044+00:00"
    },
    {
      "arxiv_id": "2508.06259v5",
      "title": "SIFThinker: Spatially-Aware Image Focus for Visual Reasoning",
      "title_zh": "SIFThinkerï¼šé¢å‘è§†è§‰æ¨ç†çš„ç©ºé—´æ„ŸçŸ¥å›¾åƒèšç„¦",
      "authors": [
        "Zhangquan Chen",
        "Ruihui Zhao",
        "Chuwei Luo",
        "Mingze Sun",
        "Xinlei Yu",
        "Yangyang Kang",
        "Ruqi Huang"
      ],
      "abstract": "Current multimodal large language models (MLLMs) still face significant challenges in complex visual tasks (e.g., spatial understanding, fine-grained perception). Prior methods have tried to incorporate visual reasoning, however, they fail to leverage attention correction with spatial cues to iteratively refine their focus on prompt-relevant regions. In this paper, we introduce SIFThinker, a spatially-aware \"think-with-images\" framework that mimics human visual perception. Specifically, SIFThinker enables attention correcting and image region focusing by interleaving depth-enhanced bounding boxes and natural language. Our contributions are twofold: First, we introduce a reverse-expansion-forward-inference strategy that facilitates the generation of interleaved image-text chains of thought for process-level supervision, which in turn leads to the construction of the SIF-50K dataset. Besides, we propose GRPO-SIF, a reinforced training paradigm that integrates depth-informed visual grounding into a unified reasoning pipeline, teaching the model to dynamically correct and focus on prompt-relevant regions. Extensive experiments demonstrate that SIFThinker outperforms state-of-the-art methods in spatial understanding and fine-grained visual perception, while maintaining strong general capabilities, highlighting the effectiveness of our method. Code: https://github.com/zhangquanchen/SIFThinker.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†SIFThinkerï¼Œä¸€ä¸ªå…·æœ‰ç©ºé—´æ„ŸçŸ¥èƒ½åŠ›çš„â€œå½±åƒæ€ç»´â€æ¡†æ¶ï¼Œæ—¨åœ¨æå‡å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLMs)åœ¨å¤æ‚ç©ºé—´ç†è§£å’Œç»†ç²’åº¦æ„ŸçŸ¥ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚è¯¥æ¡†æ¶æ¨¡ä»¿äººç±»è§†è§‰æ„ŸçŸ¥è¿‡ç¨‹ï¼Œé€šè¿‡äº¤ç»‡æ·±åº¦å¢å¼ºçš„è¾¹ç•Œæ¡†(bounding boxes)ä¸è‡ªç„¶è¯­è¨€ï¼Œå®ç°äº†æŒç»­çš„æ³¨æ„åŠ›æ ¡æ­£(attention correcting)å’Œå›¾åƒåŒºåŸŸèšç„¦ã€‚ç ”ç©¶äººå‘˜å¼•å…¥äº†â€œé€†å‘æ‰©å±•-å‰å‘æ¨ç†â€(reverse-expansion-forward-inference)ç­–ç•¥ï¼Œç”¨ä»¥ç”Ÿæˆå›¾åƒ-æ–‡æœ¬äº¤ç»‡çš„é“¾å¼æ€ç»´(Chain-of-Thought)è¿›è¡Œè¿‡ç¨‹çº§ç›‘ç£ï¼Œå¹¶æ®æ­¤æ„å»ºäº†SIF-50Kæ•°æ®é›†ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶æå‡ºäº†GRPO-SIFå¼ºåŒ–è®­ç»ƒèŒƒå¼ï¼Œå°†æ·±åº¦ä¿¡æ¯æ„ŸçŸ¥çš„è§†è§‰æ¥åœ°(visual grounding)æ•´åˆè¿›ç»Ÿä¸€æ¨ç†æµç¨‹ï¼Œä½¿æ¨¡å‹èƒ½å¤ŸåŠ¨æ€èšç„¦äºæç¤ºè¯ç›¸å…³åŒºåŸŸã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSIFThinkeråœ¨ç©ºé—´ç†è§£å’Œç»†ç²’åº¦è§†è§‰æ„ŸçŸ¥æ–¹é¢ä¼˜äºç°æœ‰SOTAæ–¹æ³•ï¼ŒåŒæ—¶ä¿æŒäº†å¼ºå¤§çš„é€šç”¨èƒ½åŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages, 13 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.06259v5",
      "published_date": "2025-08-08 12:26:20 UTC",
      "updated_date": "2025-12-25 05:25:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:13:19.552912+00:00"
    },
    {
      "arxiv_id": "2508.09197v1",
      "title": "MX-AI: Agentic Observability and Control Platform for Open and AI-RAN",
      "title_zh": "MX-AIï¼šé¢å‘ Open ä¸ AI-RAN çš„æ™ºèƒ½ä½“åŒ–å¯è§‚æµ‹æ€§ä¸æ§åˆ¶å¹³å°",
      "authors": [
        "Ilias Chatzistefanidis",
        "Andrea Leone",
        "Ali Yaghoubian",
        "Mikel Irazabal",
        "Sehad Nassim",
        "Lina Bariah",
        "Merouane Debbah",
        "Navid Nikaein"
      ],
      "abstract": "Future 6G radio access networks (RANs) will be artificial intelligence (AI)-native: observed, reasoned about, and re-configured by autonomous agents cooperating across the cloud-edge continuum. We introduce MX-AI, the first end-to-end agentic system that (i) instruments a live 5G Open RAN testbed based on OpenAirInterface (OAI) and FlexRIC, (ii) deploys a graph of Large-Language-Model (LLM)-powered agents inside the Service Management and Orchestration (SMO) layer, and (iii) exposes both observability and control functions for 6G RAN resources through natural-language intents. On 50 realistic operational queries, MX-AI attains a mean answer quality of 4.1/5.0 and 100 % decision-action accuracy, while incurring only 8.8 seconds end-to-end latency when backed by GPT-4.1. Thus, it matches human-expert performance, validating its practicality in real settings. We publicly release the agent graph, prompts, and evaluation harness to accelerate open research on AI-native RANs. A live demo is presented here: https://www.youtube.com/watch?v=CEIya7988Ug&t=285s&ab_channel=BubbleRAN",
      "tldr_zh": "è¯¥ç ”ç©¶å¼•å…¥äº† MX-AIï¼Œè¿™æ˜¯é¦–ä¸ªé’ˆå¯¹ Open RAN å’Œ AI-RAN çš„ç«¯åˆ°ç«¯æ™ºèƒ½ä½“è§‚æµ‹ä¸æ§åˆ¶å¹³å°ã€‚è¯¥ç³»ç»ŸåŸºäº OpenAirInterface (OAI) å’Œ FlexRIC å®ç°äº†å¯¹å®æ—¶ 5G Open RAN æµ‹è¯•åºŠçš„æ£€æµ‹ï¼Œå¹¶åœ¨æœåŠ¡ç®¡ç†ä¸ç¼–æ’ (SMO) å±‚éƒ¨ç½²äº†ç”±å¤§è¯­è¨€æ¨¡å‹ (LLM) é©±åŠ¨çš„æ™ºèƒ½ä½“å›¾ã€‚é€šè¿‡è‡ªç„¶è¯­è¨€æ„å›¾ (natural-language intents)ï¼ŒMX-AI èƒ½å¤Ÿç›´æ¥æä¾› 6G RAN èµ„æºçš„å¯è§‚æµ‹æ€§ä¸æ§åˆ¶åŠŸèƒ½ã€‚åœ¨ 50 ä¸ªçœŸå®è¿è¡ŒæŸ¥è¯¢çš„è¯„ä¼°ä¸­ï¼ŒMX-AI è¾¾åˆ°äº† 4.1/5.0 çš„å¹³å‡å›ç­”è´¨é‡å’Œ 100% çš„å†³ç­–æ‰§è¡Œå‡†ç¡®ç‡ï¼Œä¸”åœ¨ä½¿ç”¨ GPT-4.1 æ—¶å…¶ç«¯åˆ°ç«¯å»¶è¿Ÿä»…ä¸º 8.8 ç§’ã€‚å®éªŒç»“æœè¡¨æ˜ MX-AI çš„æ€§èƒ½å·²è¾¾åˆ°äººç±»ä¸“å®¶æ°´å¹³ï¼Œæœ‰æ•ˆéªŒè¯äº†å…¶åœ¨ç°å® AI-native ç¯å¢ƒä¸‹ç®¡ç†æ— çº¿æ¥å…¥ç½‘çš„å®ç”¨æ€§ã€‚",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "This work has been submitted to the IEEE for possible publication",
      "pdf_url": "https://arxiv.org/pdf/2508.09197v1",
      "published_date": "2025-08-08 12:15:47 UTC",
      "updated_date": "2025-08-08 12:15:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:13:27.344070+00:00"
    },
    {
      "arxiv_id": "2508.06251v2",
      "title": "Synthetic Data Generation and Differential Privacy using Tensor Networks' Matrix Product States (MPS)",
      "title_zh": "åŸºäºå¼ é‡ç½‘ç»œçŸ©é˜µä¹˜ç§¯æ€ï¼ˆMPSï¼‰çš„åˆæˆæ•°æ®ç”Ÿæˆä¸å·®åˆ†éšç§ä¿æŠ¤",
      "authors": [
        "Alejandro Moreno R.",
        "Desale Fentaw",
        "Samuel Palmer",
        "RaÃºl Salles de Padua",
        "Ninad Dixit",
        "Samuel Mugel",
        "Roman OrÃºs",
        "Manuel Radons",
        "Josef Menter",
        "Ali Abedi"
      ],
      "abstract": "Synthetic data generation is a key technique in modern artificial intelligence, addressing data scarcity, privacy constraints, and the need for diverse datasets in training robust models. In this work, we propose a method for generating privacy-preserving high-quality synthetic tabular data using Tensor Networks, specifically Matrix Product States (MPS). We benchmark the MPS-based generative model against state-of-the-art models such as CTGAN, VAE, and PrivBayes, focusing on both fidelity and privacy-preserving capabilities. To ensure differential privacy (DP), we integrate noise injection and gradient clipping during training, enabling privacy guarantees via RÃ©nyi Differential Privacy accounting. Across multiple metrics analyzing data fidelity and downstream machine learning task performance, our results show that MPS outperforms classical models, particularly under strict privacy constraints. This work highlights MPS as a promising tool for privacy-aware synthetic data generation. By combining the expressive power of tensor network representations with formal privacy mechanisms, the proposed approach offers an interpretable and scalable alternative for secure data sharing. Its structured design facilitates integration into sensitive domains where both data quality and confidentiality are critical.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åˆ©ç”¨å¼ é‡ç½‘ç»œ (Tensor Networks) ä¸­çš„çŸ©é˜µä¹˜ç§¯æ€ (Matrix Product States, MPS) ç”Ÿæˆå…·æœ‰å·®åˆ†éšç§ (Differential Privacy, DP) ä¿æŠ¤çš„é«˜è´¨é‡åˆæˆè¡¨æ ¼æ•°æ®çš„æ–¹æ³•ã€‚ä¸ºäº†ç¡®ä¿éšç§å®‰å…¨æ€§ï¼Œè¯¥æ¡†æ¶åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­é›†æˆäº†å™ªå£°æ³¨å…¥ (Noise Injection) å’Œæ¢¯åº¦è£å‰ª (Gradient Clipping) æŠ€æœ¯ï¼Œå¹¶åˆ©ç”¨ RÃ©nyi Differential Privacy ä¼šè®¡æ–¹æ³•æä¾›éšç§ä¿è¯ã€‚ç ”ç©¶è€…å°†åŸºäº MPS çš„ç”Ÿæˆæ¨¡å‹ä¸ CTGANã€VAE å’Œ PrivBayes ç­‰å‰æ²¿æ¨¡å‹è¿›è¡Œäº†åŸºå‡†æµ‹è¯•ï¼Œé‡ç‚¹è¯„ä¼°äº†å…¶åœ¨æ•°æ®ä¿çœŸåº¦ (Fidelity) å’Œéšç§ä¿æŠ¤æ–¹é¢çš„æ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨å¤šé¡¹å…³äºæ•°æ®è´¨é‡å’Œä¸‹æ¸¸æœºå™¨å­¦ä¹ ä»»åŠ¡çš„æŒ‡æ ‡åˆ†æä¸­ï¼ŒMPS ä¼˜äºä¼ ç»Ÿæ¨¡å‹ï¼Œå°¤å…¶åœ¨ä¸¥æ ¼çš„éšç§çº¦æŸä¸‹è¡¨ç°å‡ºè‰²ã€‚è¯¥ç ”ç©¶çªæ˜¾äº† MPS ä½œä¸ºéšç§æ„ŸçŸ¥åˆæˆæ•°æ®ç”Ÿæˆå·¥å…·çš„æ½œåŠ›ï¼Œä¸ºæ•æ„Ÿé¢†åŸŸçš„æ•°æ®å…±äº«æä¾›äº†ä¸€ç§å…·æœ‰å¯è§£é‡Šæ€§å’Œå¯æ‰©å±•æ€§çš„å®‰å…¨æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "quant-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages",
      "pdf_url": "https://arxiv.org/pdf/2508.06251v2",
      "published_date": "2025-08-08 12:14:57 UTC",
      "updated_date": "2025-11-22 20:25:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:13:26.138910+00:00"
    },
    {
      "arxiv_id": "2508.06249v1",
      "title": "In-Training Defenses against Emergent Misalignment in Language Models",
      "title_zh": "é’ˆå¯¹è¯­è¨€æ¨¡å‹æ¶Œç°æ€§ä¸å¯¹é½çš„è®­ç»ƒä¸­é˜²å¾¡",
      "authors": [
        "David KaczÃ©r",
        "Magnus JÃ¸rgenvÃ¥g",
        "Clemens Vetter",
        "Lucie Flek",
        "Florian Mai"
      ],
      "abstract": "Fine-tuning lets practitioners repurpose aligned large language models (LLMs) for new domains, yet recent work reveals emergent misalignment (EMA): Even a small, domain-specific fine-tune can induce harmful behaviors far outside the target domain. Even in the case where model weights are hidden behind a fine-tuning API, this gives attackers inadvertent access to a broadly misaligned model in a way that can be hard to detect from the fine-tuning data alone. We present the first systematic study of in-training safeguards against EMA that are practical for providers who expose fine-tuning via an API. We investigate four training regularization interventions: (i) KL-divergence regularization toward a safe reference model, (ii) $\\ell_2$ distance in feature space, (iii) projecting onto a safe subspace (SafeLoRA), and (iv) interleaving of a small amount of safe training examples from a general instruct-tuning dataset. We first evaluate the methods' emergent misalignment effect across four malicious, EMA-inducing tasks. Second, we assess the methods' impacts on benign tasks. We conclude with a discussion of open questions in emergent misalignment research.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­å‡ºç°çš„ç´§æ€¥å¤±è°ƒ(Emergent Misalignment, EMA)ç°è±¡ï¼Œå³é’ˆå¯¹ç‰¹å®šé¢†åŸŸçš„å¾®è°ƒå¯èƒ½ä¼šæ„å¤–è¯±å¯¼æ¨¡å‹åœ¨ç›®æ ‡é¢†åŸŸå¤–äº§ç”Ÿæœ‰å®³è¡Œä¸ºã€‚é’ˆå¯¹å¾®è°ƒAPIæä¾›å•†çš„å®é™…éœ€æ±‚ï¼Œæœ¬ç ”ç©¶é¦–æ¬¡ç³»ç»Ÿæ€§åœ°è°ƒæŸ¥äº†å››ç§è®­ç»ƒä¸­çš„é˜²å¾¡æªæ–½ï¼ŒåŒ…æ‹¬å‘å®‰å…¨æ¨¡å‹å¯¹é½çš„KL-divergenceæ­£åˆ™åŒ–ã€ç‰¹å¾ç©ºé—´çš„$\\ell_2$è·ç¦»çº¦æŸã€æŠ•å½±åˆ°å®‰å…¨å­ç©ºé—´(SafeLoRA)ä»¥åŠäº¤æ›¿è®­ç»ƒé€šç”¨æŒ‡ä»¤é›†ä¸­çš„å°‘é‡å®‰å…¨ç¤ºä¾‹ã€‚é€šè¿‡åœ¨å››ä¸ªæ¶æ„ä»»åŠ¡å’Œè‹¥å¹²è‰¯æ€§ä»»åŠ¡ä¸Šçš„å¯¹æ¯”å®éªŒï¼Œç ”ç©¶è¯„ä¼°äº†è¿™äº›æ–¹æ³•åœ¨æŠµå¾¡EMAæ–¹é¢çš„æœ‰æ•ˆæ€§åŠå…¶å¯¹æ¨¡å‹åŸºç¡€èƒ½åŠ›çš„å½±å“ã€‚è¯¥å·¥ä½œä¸ºæ„å»ºå®‰å…¨å¯æ§çš„å¾®è°ƒæœºåˆ¶æä¾›äº†é‡è¦å®éªŒä¾æ®ï¼Œå¹¶æŒ‡å‡ºäº†è¯¥é¢†åŸŸæœªæ¥ç ”ç©¶çš„å¼€æ”¾æ€§æ–¹å‘ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Under review",
      "pdf_url": "https://arxiv.org/pdf/2508.06249v1",
      "published_date": "2025-08-08 12:10:28 UTC",
      "updated_date": "2025-08-08 12:10:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:13:45.192147+00:00"
    },
    {
      "arxiv_id": "2508.06244v2",
      "title": "Membership Inference Attack with Partial Features",
      "title_zh": "åŸºäºéƒ¨åˆ†ç‰¹å¾çš„æˆå‘˜æ¨ç†æ”»å‡»",
      "authors": [
        "Xurun Wang",
        "Guangrui Liu",
        "Xinjie Li",
        "Haoyu He",
        "Lin Yao",
        "Zhongyun Hua",
        "Weizhe Zhang"
      ],
      "abstract": "Machine learning models are vulnerable to membership inference attack, which can be used to determine whether a given sample appears in the training data. Most existing methods assume the attacker has full access to the features of the target sample. This assumption, however, does not hold in many real-world scenarios where only partial features are available, thereby limiting the applicability of these methods. In this work, we introduce Partial Feature Membership Inference (PFMI), a scenario where the adversary observes only partial features of each sample and aims to infer whether this observed subset was present in the training set. To address this problem, we propose MRAD (Memory-guided Reconstruction and Anomaly Detection), a two-stage attack framework that works in both white-box and black-box settings. In the first stage, MRAD leverages the latent memory of the target model to reconstruct the unknown features of the sample. We observe that when the known features are absent from the training set, the reconstructed sample deviates significantly from the true data distribution. Consequently, in the second stage, we use anomaly detection algorithms to measure the deviation between the reconstructed sample and the training data distribution, thereby determining whether the known features belong to a member of the training set. Empirical results demonstrate that MRAD is effective across various datasets, and maintains compatibility with off-the-shelf anomaly detection techniques. For example, on STL-10, our attack exceeds an AUC of around 0.75 even with 60% of the missing features.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†éƒ¨åˆ†ç‰¹å¾æˆå‘˜æ¨ç†æ”»å‡»(Partial Feature Membership Inference, PFMI)åœºæ™¯ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æˆå‘˜æ¨ç†æ”»å‡»(Membership Inference Attack)æ™®éå‡è®¾æ”»å‡»è€…æ‹¥æœ‰å®Œæ•´ç‰¹å¾è€Œåœ¨ç°å®ä¸­éš¾ä»¥æ»¡è¶³çš„é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œè®ºæ–‡æå‡ºäº†åä¸ºMRAD(Memory-guided Reconstruction and Anomaly Detection)çš„ä¸¤é˜¶æ®µæ”»å‡»æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å¯åŒæ—¶åº”ç”¨äºç™½ç›’å’Œé»‘ç›’è®¾ç½®ã€‚åœ¨ç¬¬ä¸€é˜¶æ®µï¼ŒMRADåˆ©ç”¨ç›®æ ‡æ¨¡å‹çš„æ½œåœ¨è®°å¿†æ¥é‡å»ºæ ·æœ¬çš„æœªçŸ¥ç‰¹å¾ï¼›åœ¨ç¬¬äºŒé˜¶æ®µï¼Œç ”ç©¶è€…è§‚å¯Ÿåˆ°è‹¥å·²çŸ¥ç‰¹å¾æœªåŒ…å«åœ¨è®­ç»ƒé›†ä¸­ï¼Œé‡å»ºæ ·æœ¬å°†æ˜¾è‘—åç¦»çœŸå®æ•°æ®åˆ†å¸ƒã€‚åŸºäºæ­¤å‘ç°ï¼ŒMRADåˆ©ç”¨å¼‚å¸¸æ£€æµ‹(Anomaly Detection)ç®—æ³•è¡¡é‡é‡å»ºæ ·æœ¬ä¸è®­ç»ƒæ•°æ®åˆ†å¸ƒçš„åå·®ï¼Œä»è€Œåˆ¤å®šæ ·æœ¬çš„æˆå‘˜èº«ä»½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMRADåœ¨å¤šç§æ•°æ®é›†ä¸Šå‡è¡¨ç°å‡ºè‰²ä¸”å…·æœ‰è‰¯å¥½çš„å…¼å®¹æ€§ã€‚åœ¨STL-10æ•°æ®é›†çš„æµ‹è¯•ä¸­ï¼Œå³ä½¿åœ¨ç¼ºå¤±60%ç‰¹å¾çš„æƒ…å†µä¸‹ï¼Œè¯¥æ”»å‡»ä»èƒ½å®ç°çº¦0.75çš„æ›²çº¿ä¸‹é¢ç§¯(AUC)è¡¨ç°ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06244v2",
      "published_date": "2025-08-08 11:56:13 UTC",
      "updated_date": "2025-12-23 09:18:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:14:03.994190+00:00"
    },
    {
      "arxiv_id": "2508.09196v1",
      "title": "FIVA: Federated Inverse Variance Averaging for Universal CT Segmentation with Uncertainty Estimation",
      "title_zh": "FIVAï¼šèåˆä¸ç¡®å®šæ€§ä¼°è®¡çš„é€šç”¨ CT åˆ†å‰²è”é‚¦é€†æ–¹å·®å¹³å‡æ–¹æ³•",
      "authors": [
        "Asim Ukaye",
        "Numan Saeed",
        "Karthik Nandakumar"
      ],
      "abstract": "Different CT segmentation datasets are typically obtained from different scanners under different capture settings and often provide segmentation labels for a limited and often disjoint set of organs. Using these heterogeneous data effectively while preserving patient privacy can be challenging. This work presents a novel federated learning approach to achieve universal segmentation across diverse abdominal CT datasets by utilizing model uncertainty for aggregation and predictive uncertainty for inference. Our approach leverages the inherent noise in stochastic mini-batch gradient descent to estimate a distribution over the model weights to provide an on-the-go uncertainty over the model parameters at the client level. The parameters are then aggregated at the server using the additional uncertainty information using a Bayesian-inspired inverse-variance aggregation scheme. Furthermore, the proposed method quantifies prediction uncertainty by propagating the uncertainty from the model weights, providing confidence measures essential for clinical decision-making. In line with recent work shown, predictive uncertainty is utilized in the inference stage to improve predictive performance. Experimental evaluations demonstrate the effectiveness of this approach in improving both the quality of federated aggregation and uncertainty-weighted inference compared to previously established baselines. The code for this work is made available at: https://github.com/asimukaye/fiva",
      "tldr_zh": "æœ¬ç ”ç©¶æå‡ºäº†FIVA (Federated Inverse Variance Averaging)ï¼Œä¸€ç§é’ˆå¯¹å¼‚æ„è…¹éƒ¨CTæ•°æ®é›†å®ç°é€šç”¨åˆ†å‰²å¹¶å…·å¤‡ä¸ç¡®å®šæ€§ä¼°è®¡çš„è”é‚¦å­¦ä¹ (Federated Learning)æ¡†æ¶ã€‚è¯¥æ–¹æ³•æ—¨åœ¨è§£å†³ä¸åŒæ‰«æä»ªå’Œè®¾ç½®å¯¼è‡´çš„å¼‚æ„æ•°æ®æœ‰æ•ˆåˆ©ç”¨åŠæ‚£è€…éšç§ä¿æŠ¤æŒ‘æˆ˜ï¼Œé€šè¿‡åˆ©ç”¨æ¨¡å‹ä¸ç¡®å®šæ€§è¿›è¡Œèšåˆä»¥åŠåˆ©ç”¨é¢„æµ‹ä¸ç¡®å®šæ€§(predictive uncertainty)è¿›è¡Œæ¨ç†ã€‚FIVAåˆ©ç”¨éšæœºå°æ‰¹é‡æ¢¯åº¦ä¸‹é™(stochastic mini-batch gradient descent)ä¸­çš„å›ºæœ‰å™ªå£°åœ¨å®¢æˆ·ç«¯ä¼°è®¡æ¨¡å‹æƒé‡çš„åˆ†å¸ƒï¼Œè¿›è€Œåœ¨æœåŠ¡å™¨ç«¯é‡‡ç”¨å—è´å¶æ–¯å¯å‘çš„é€†æ–¹å·®èšåˆ(inverse-variance aggregation)æ–¹æ¡ˆã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•é€šè¿‡ä¼ æ’­æƒé‡ä¸ç¡®å®šæ€§æ¥é‡åŒ–é¢„æµ‹ç»“æœçš„å¯é æ€§ï¼Œä¸ºä¸´åºŠå†³ç­–æä¾›å¿…è¦çš„ç½®ä¿¡åº¦åº¦é‡ï¼Œå¹¶åœ¨æ¨ç†é˜¶æ®µè¿›ä¸€æ­¥ä¼˜åŒ–é¢„æµ‹æ€§èƒ½ã€‚å®éªŒè¯„ä¼°è¡¨æ˜ï¼Œä¸ç°æœ‰åŸºçº¿æ¨¡å‹ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•åœ¨æå‡è”é‚¦èšåˆè´¨é‡å’Œä¸ç¡®å®šæ€§åŠ æƒæ¨ç†å‡†ç¡®æ€§æ–¹é¢å‡å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "17 pages, 5 figures, Machine Learning for Healthcare Conference",
      "pdf_url": "https://arxiv.org/pdf/2508.09196v1",
      "published_date": "2025-08-08 11:34:01 UTC",
      "updated_date": "2025-08-08 11:34:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:14:13.386242+00:00"
    },
    {
      "arxiv_id": "2508.10026v1",
      "title": "SABER: Switchable and Balanced Training for Efficient LLM Reasoning",
      "title_zh": "SABERï¼šé¢å‘å¤§è¯­è¨€æ¨¡å‹é«˜æ•ˆæ¨ç†çš„å¯åˆ‡æ¢ä¸å‡è¡¡è®­ç»ƒ",
      "authors": [
        "Kai Zhao",
        "Yanjun Zhao",
        "Jiaming Song",
        "Shien He",
        "Lusheng Zhang",
        "Qiang Zhang",
        "Tianjiao Li"
      ],
      "abstract": "Large language models (LLMs) empowered by chain-of-thought reasoning have achieved impressive accuracy on complex tasks but suffer from excessive inference costs and latency when applied uniformly to all problems. We propose SABER (Switchable and Balanced Training for Efficient LLM Reasoning), a reinforcement learning framework that endows LLMs with user-controllable, token-budgeted reasoning. SABER first profiles each training example's base-model thinking token usage and assigns it to one of the predefined budget tiers. During fine-tuning, the model is guided by system prompts and length-aware rewards to respect its assigned budget. In parallel, we incorporate no-think examples to ensure the model remains reliable even when explicit reasoning is turned off. SABER further supports four discrete inference modes - NoThink, FastThink, CoreThink, and DeepThink, enabling flexible trade-offs between latency and reasoning depth. Extensive evaluations on math reasoning (MATH, GSM8K), code generation (MBPP), and logical reasoning (LiveBench-Reasoning) demonstrate that SABER achieves high accuracy under tight budgets, graceful degradation, and effective cross-scale and cross-domain generalization. In particular, SABER-FastThink cuts reasoning length by 65.4% and yields a 3.6% accuracy gain compared with the base model on the MATH benchmark.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†SABERï¼ˆSwitchable and Balanced Training for Efficient LLM Reasoningï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨èµ‹äºˆå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ç”¨æˆ·å¯æ§ä¸”å…·å¤‡Tokené¢„ç®—é™åˆ¶æ¨ç†èƒ½åŠ›çš„å¼ºåŒ–å­¦ä¹ ï¼ˆReinforcement Learningï¼‰æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡å¯¹è®­ç»ƒç¤ºä¾‹è¿›è¡Œæ¨ç†Tokenä½¿ç”¨é‡åˆ†æå¹¶å°†å…¶åˆ†é…è‡³é¢„å®šä¹‰çš„é¢„ç®—å±‚çº§ï¼Œç»“åˆç³»ç»Ÿæç¤ºè¯å’Œé•¿åº¦æ„ŸçŸ¥å¥–åŠ±ï¼ˆLength-aware rewardsï¼‰æ¥å¼•å¯¼æ¨¡å‹åœ¨æŒ‡å®šé¢„ç®—å†…å®Œæˆä»»åŠ¡ã€‚ä¸ºç¡®ä¿æ¨¡å‹åœ¨å…³é—­æ˜¾å¼æ¨ç†æ—¶ä»ä¿æŒå¯é æ€§ï¼ŒSABERåœ¨è®­ç»ƒä¸­å¼•å…¥äº†No-thinkç¤ºä¾‹ï¼Œå¹¶æ”¯æŒNoThinkã€FastThinkã€CoreThinkå’ŒDeepThinkå››ç§ç¦»æ•£æ¨ç†æ¨¡å¼ï¼Œå®ç°äº†æ¨ç†æ·±åº¦ä¸å»¶è¿Ÿä¹‹é—´çš„çµæ´»å¹³è¡¡ã€‚ç ”ç©¶åœ¨æ•°å­¦æ¨ç†ã€ä»£ç ç”Ÿæˆå’Œé€»è¾‘æ¨ç†ç­‰å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šè¿›è¡Œäº†å¹¿æ³›è¯„ä¼°ï¼Œç»“æœæ˜¾ç¤ºSABERåœ¨ä¸¥è‹›çš„é¢„ç®—ä¸‹ä»èƒ½ä¿æŒé«˜å‡†ç¡®ç‡ã€‚ç‰¹åˆ«æ˜¯SABER-FastThinkæ¨¡å¼åœ¨MATHåŸºå‡†æµ‹è¯•ä¸­å°†æ¨ç†é•¿åº¦ç¼©å‡äº†65.4%ï¼ŒåŒæ—¶æ¯”åŸºç¡€æ¨¡å‹æå‡äº†3.6%çš„å‡†ç¡®ç‡ã€‚è¯¥æ¡†æ¶ä¸ä»…å®ç°äº†æ€§èƒ½çš„å¹³æ»‘é€€åŒ–ï¼Œè¿˜å±•ç°å‡ºä¼˜å¼‚çš„è·¨è§„æ¨¡å’Œè·¨é¢†åŸŸæ³›åŒ–èƒ½åŠ›ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.10026v1",
      "published_date": "2025-08-08 11:27:48 UTC",
      "updated_date": "2025-08-08 11:27:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:14:17.094252+00:00"
    },
    {
      "arxiv_id": "2508.06230v1",
      "title": "Learning Logical Rules using Minimum Message Length",
      "title_zh": "åŸºäºæœ€å°æ¶ˆæ¯é•¿åº¦çš„é€»è¾‘è§„åˆ™å­¦ä¹ ",
      "authors": [
        "Ruben Sharma",
        "Sebastijan DumanÄiÄ‡",
        "Ross D. King",
        "Andrew Cropper"
      ],
      "abstract": "Unifying probabilistic and logical learning is a key challenge in AI. We introduce a Bayesian inductive logic programming approach that learns minimum message length programs from noisy data. Our approach balances hypothesis complexity and data fit through priors, which explicitly favour more general programs, and a likelihood that favours accurate programs. Our experiments on several domains, including game playing and drug design, show that our method significantly outperforms previous methods, notably those that learn minimum description length programs. Our results also show that our approach is data-efficient and insensitive to example balance, including the ability to learn from exclusively positive examples.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºæœ€å°ä¿¡æ¯é•¿åº¦ (Minimum Message Length, MML) çš„è´å¶æ–¯å½’çº³é€»è¾‘ç¼–ç¨‹ (Bayesian inductive logic programming) æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³äººå·¥æ™ºèƒ½ä¸­ç»Ÿä¸€æ¦‚ç‡å­¦ä¹ ä¸é€»è¾‘å­¦ä¹ çš„å…³é”®æŒ‘æˆ˜ã€‚è¯¥æ–¹æ³•é€šè¿‡å¼•å…¥èƒ½å¤Ÿæ˜¾å¼åå¥½é€šç”¨ç¨‹åºçš„å…ˆéªŒåˆ†å¸ƒä»¥åŠåå¥½å‡†ç¡®ç¨‹åºçš„ä¼¼ç„¶å‡½æ•°ï¼Œæœ‰æ•ˆå¹³è¡¡äº†å‡è®¾å¤æ‚åº¦ä¸æ•°æ®æ‹Ÿåˆåº¦ã€‚åœ¨åŒ…æ‹¬æ¸¸æˆåšå¼ˆå’Œè¯ç‰©è®¾è®¡åœ¨å†…çš„å¤šä¸ªé¢†åŸŸå®éªŒä¸­ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—ä¼˜äºä»¥å¾€æŠ€æœ¯ï¼Œç‰¹åˆ«æ˜¯è¶…è¶Šäº†åŸºäºæœ€å°æè¿°é•¿åº¦ (Minimum Description Length, MDL) çš„ç¨‹åºå­¦ä¹ æ–¹æ³•ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å…·æœ‰æé«˜çš„æ•°æ®æ•ˆç‡ï¼Œä¸”å¯¹æ ·æœ¬å¹³è¡¡æ€§ä¸æ•æ„Ÿï¼Œå…·å¤‡ä»…ä»æ­£æ ·æœ¬ (Positive Examples) ä¸­è¿›è¡Œæœ‰æ•ˆå­¦ä¹ çš„å“è¶Šèƒ½åŠ›ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06230v1",
      "published_date": "2025-08-08 11:23:58 UTC",
      "updated_date": "2025-08-08 11:23:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:14:15.090542+00:00"
    },
    {
      "arxiv_id": "2508.06592v1",
      "title": "Towards Integrated Alignment",
      "title_zh": "è¿ˆå‘ä¸€ä½“åŒ–å¯¹é½",
      "authors": [
        "Ben Y. Reis",
        "William La Cava"
      ],
      "abstract": "As AI adoption expands across human society, the problem of aligning AI models to match human preferences remains a grand challenge. Currently, the AI alignment field is deeply divided between behavioral and representational approaches, resulting in narrowly aligned models that are more vulnerable to increasingly deceptive misalignment threats. In the face of this fragmentation, we propose an integrated vision for the future of the field. Drawing on related lessons from immunology and cybersecurity, we lay out a set of design principles for the development of Integrated Alignment frameworks that combine the complementary strengths of diverse alignment approaches through deep integration and adaptive coevolution. We highlight the importance of strategic diversity - deploying orthogonal alignment and misalignment detection approaches to avoid homogeneous pipelines that may be \"doomed to success\". We also recommend steps for greater unification of the AI alignment research field itself, through cross-collaboration, open model weights and shared community resources.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨äººå·¥æ™ºèƒ½å¹¿æ³›åº”ç”¨çš„èƒŒæ™¯ä¸‹ï¼Œå¦‚ä½•è§£å†³å°†AIæ¨¡å‹ä¸äººç±»åå¥½å¯¹é½(AI alignment)çš„é‡å¤§æŒ‘æˆ˜ï¼Œå¹¶æŒ‡å‡ºå½“å‰è¡Œä¸º(behavioral)ä¸è¡¨å¾(representational)æ–¹æ³•çš„å‰²è£‚å¯¼è‡´æ¨¡å‹ææ˜“å—åˆ°æ¬ºéª—æ€§å¯¹é½ä¸è‰¯(deceptive misalignment)çš„å¨èƒã€‚é’ˆå¯¹è¿™ä¸€ç°çŠ¶ï¼Œä½œè€…æå‡ºäº†é›†æˆå¯¹é½(Integrated Alignment)çš„æœªæ¥æ„¿æ™¯ï¼Œé€šè¿‡å€Ÿé‰´å…ç–«å­¦(immunology)å’Œç½‘ç»œå®‰å…¨(cybersecurity)çš„æ•™è®­ï¼Œå»ºç«‹äº†ä¸€å¥—é€šè¿‡æ·±åº¦é›†æˆå’Œè‡ªé€‚åº”ååŒæ¼”åŒ–(adaptive coevolution)æ¥ç»“åˆå¤šæ ·åŒ–å¯¹é½æ–¹æ³•ä¼˜åŠ¿çš„è®¾è®¡åŸåˆ™ã€‚æ–‡ä¸­ç‰¹åˆ«å¼ºè°ƒäº†ç­–ç•¥å¤šæ ·æ€§(strategic diversity)çš„é‡è¦æ€§ï¼Œæå€¡éƒ¨ç½²æ­£äº¤çš„å¯¹é½ä¸è¯¯å¯¹é½æ£€æµ‹æ–¹æ³•ï¼Œä»¥é¿å…åŒè´¨åŒ–æµç¨‹å¸¦æ¥çš„éšæ‚£ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å»ºè®®é€šè¿‡åŠ å¼ºè·¨é¢†åŸŸåä½œã€å¼€æ”¾æ¨¡å‹æƒé‡(open model weights)å’Œå…±äº«ç¤¾åŒºèµ„æºæ¥æ¨åŠ¨AIå¯¹é½ç ”ç©¶é¢†åŸŸçš„ç»Ÿä¸€ï¼Œä¸ºå®ç°æ›´å…·éŸ§æ€§çš„AIå®‰å…¨å¥ å®šåŸºç¡€ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06592v1",
      "published_date": "2025-08-08 11:16:56 UTC",
      "updated_date": "2025-08-08 11:16:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:14:22.289990+00:00"
    },
    {
      "arxiv_id": "2508.06226v1",
      "title": "GeoLaux: A Benchmark for Evaluating MLLMs' Geometry Performance on Long-Step Problems Requiring Auxiliary Lines",
      "title_zh": "GeoLauxï¼šè¯„ä¼°å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨éœ€è¾…åŠ©çº¿é•¿æ­¥éª¤é—®é¢˜ä¸­å‡ ä½•æ€§èƒ½çš„åŸºå‡†",
      "authors": [
        "Yumeng Fu",
        "Jiayin Zhu",
        "Lingling Zhang",
        "Bo Zhao",
        "Shaoxuan Ma",
        "Yushun Zhang",
        "Yanrui Wu",
        "Wenjun Wu"
      ],
      "abstract": "Geometry problem solving (GPS) requires models to master diagram comprehension, logical reasoning, knowledge application, numerical computation, and auxiliary line construction. This presents a significant challenge for Multimodal Large Language Models (MLLMs). However, existing benchmarks for evaluating MLLM geometry skills overlook auxiliary line construction and lack fine-grained process evaluation, making them insufficient for assessing MLLMs' long-step reasoning abilities. To bridge these gaps, we present the GeoLaux benchmark, comprising 2,186 geometry problems, incorporating both calculation and proving questions. Notably, the problems require an average of 6.51 reasoning steps, with a maximum of 24 steps, and 41.8% of them need auxiliary line construction. Building on the dataset, we design a novel five-dimensional evaluation strategy assessing answer correctness, process correctness, process quality, auxiliary line impact, and error causes. Extensive experiments on 13 leading MLLMs (including thinking models and non-thinking models) yield three pivotal findings: First, models exhibit substantial performance degradation in extended reasoning steps (nine models demonstrate over 50% performance drop). Second, compared to calculation problems, MLLMs tend to take shortcuts when solving proving problems. Third, models lack auxiliary line awareness, and enhancing this capability proves particularly beneficial for overall geometry reasoning improvement. These findings establish GeoLaux as both a benchmark for evaluating MLLMs' long-step geometric reasoning with auxiliary lines and a guide for capability advancement. Our dataset and code are included in supplementary materials and will be released.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† GeoLauxï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨è¯„ä¼°å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ (MLLMs) åœ¨éœ€è¦è¾…åŠ©çº¿ (Auxiliary Lines) çš„é•¿æ­¥å‡ ä½•æ¨ç†é—®é¢˜ä¸Šæ€§èƒ½çš„åŸºå‡†æµ‹è¯•ã€‚è¯¥åŸºå‡†åŒ…å« 2,186 ä¸ªå‡ ä½•é—®é¢˜ï¼Œæ¶µç›–è®¡ç®—é¢˜å’Œè¯æ˜é¢˜ï¼Œå¹³å‡æ¨ç†æ­¥æ•°ä¸º 6.51 æ­¥ï¼Œä¸”å…¶ä¸­ 41.8% çš„é¢˜ç›®éœ€è¦æ„å»ºè¾…åŠ©çº¿ã€‚ç ”ç©¶è€…é…å¥—è®¾è®¡äº†ä¸€å¥—äº”ç»´è¯„ä¼°ç­–ç•¥ï¼Œä»ç­”æ¡ˆä¸è¿‡ç¨‹æ­£ç¡®æ€§ã€è¿‡ç¨‹è´¨é‡ã€è¾…åŠ©çº¿å½±å“åŠé”™è¯¯åŸå› ç­‰æ–¹é¢è¿›è¡Œç»†ç²’åº¦åˆ†æã€‚å¯¹ 13 ç§ä¸»æµ MLLMs çš„å®éªŒè¡¨æ˜ï¼Œæ¨¡å‹åœ¨é•¿æ­¥æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°å‡ºæ˜¾è‘—çš„æ€§èƒ½é€€åŒ–ï¼Œä¸”åœ¨è§£å†³è¯æ˜é¢˜æ—¶æ™®éå­˜åœ¨â€œèµ°æ·å¾„â€çš„ç°è±¡ã€‚æ­¤å¤–ï¼Œç»“æœæ­ç¤ºäº†å½“å‰æ¨¡å‹ä¸¥é‡ç¼ºä¹è¾…åŠ©çº¿æ„è¯†ï¼Œè€Œæå‡è¯¥èƒ½åŠ›å¯¹å¢å¼ºæ•´ä½“å‡ ä½•æ¨ç†æ°´å¹³å…·æœ‰å…³é”®ä½œç”¨ã€‚GeoLaux ä¸ä»…å¡«è¡¥äº†ç°æœ‰å‡ ä½•æ¨ç†è¯„ä¼°çš„ç©ºç™½ï¼Œä¹Ÿä¸ºæœªæ¥æå‡æ¨¡å‹åœ¨å¤æ‚æ•°å­¦é€»è¾‘ä¸Šçš„è¡¨ç°æä¾›äº†æŒ‡å¼•ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06226v1",
      "published_date": "2025-08-08 11:11:37 UTC",
      "updated_date": "2025-08-08 11:11:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:14:29.592408+00:00"
    },
    {
      "arxiv_id": "2508.06225v3",
      "title": "Overconfidence in LLM-as-a-Judge: Diagnosis and Confidence-Driven Solution",
      "title_zh": "LLM-as-a-Judge ä¸­çš„è¿‡è‡ªä¿¡ç°è±¡ï¼šè¯Šæ–­åŠç½®ä¿¡åº¦é©±åŠ¨çš„è§£å†³æ–¹æ¡ˆ",
      "authors": [
        "Zailong Tian",
        "Zhuoheng Han",
        "Yanzhe Chen",
        "Haozhe Xu",
        "Xi Yang",
        "Richeng Xuan",
        "Houfeng Wang",
        "Lizi Liao"
      ],
      "abstract": "Large Language Models (LLMs) are widely used as automated judges, where practical value depends on both accuracy and trustworthy, risk-aware judgments. Existing approaches predominantly focus on accuracy, overlooking the necessity of well-calibrated confidence, which is vital for adaptive and reliable evaluation pipelines. In this work, we advocate a shift from accuracy-centric evaluation to confidence-driven, risk-aware LLM-as-a-Judge systems, emphasizing the necessity of well-calibrated confidence for trustworthy and adaptive evaluation. We systematically identify the Overconfidence Phenomenon in current LLM-as-a-Judges, where predicted confidence significantly overstates actual correctness, undermining reliability in practical deployment. To quantify this phenomenon, we introduce TH-Score, a novel metric measuring confidence-accuracy alignment. Furthermore, we propose LLM-as-a-Fuser, an ensemble framework that transforms LLMs into reliable, risk-aware evaluators. Extensive experiments demonstrate that our approach substantially improves calibration and enables adaptive, confidence-driven evaluation pipelines, achieving superior reliability and accuracy compared to existing baselines.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä½œä¸ºè‡ªåŠ¨åŒ–è¯„ä¼°è€…ï¼ˆLLM-as-a-Judgeï¼‰æ—¶æ™®éå­˜åœ¨çš„è¿‡åº¦è‡ªä¿¡ç°è±¡(Overconfidence Phenomenon)ï¼Œå³æ¨¡å‹é¢„æµ‹çš„ç½®ä¿¡åº¦æ˜¾è‘—é«˜äºå…¶å®é™…å‡†ç¡®æ€§ï¼Œä»è€Œå‰Šå¼±äº†ç³»ç»Ÿåœ¨å®é™…åº”ç”¨ä¸­çš„å¯é æ€§ã€‚ä½œè€…ä¸»å¼ å°†è¯„ä¼°èŒƒå¼ä»å•ä¸€çš„å‡†ç¡®ç‡ä¸­å¿ƒè½¬å‘ç½®ä¿¡åº¦é©±åŠ¨(confidence-driven)ä¸”å…·å¤‡é£é™©æ„ŸçŸ¥(risk-aware)çš„ç³»ç»Ÿï¼Œå¹¶å¼ºè°ƒäº†æ ¡å‡†ç½®ä¿¡åº¦(well-calibrated confidence)åœ¨è‡ªé€‚åº”è¯„ä¼°ä¸­çš„å…³é”®ä½œç”¨ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶å¼•å…¥äº† TH-Score æŒ‡æ ‡æ¥é‡åŒ–ç½®ä¿¡åº¦ä¸å‡†ç¡®åº¦ä¹‹é—´çš„ä¸€è‡´æ€§(confidence-accuracy alignment)ï¼Œå¹¶æå‡ºäº†åä¸º LLM-as-a-Fuser çš„é›†æˆæ¡†æ¶ï¼Œæ—¨åœ¨å°† LLMs è½¬åŒ–ä¸ºæ›´å¯é çš„è¯„ä¼°å™¨ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ¡ˆä¸ä»…æ˜¾è‘—æå‡äº†æ¨¡å‹çš„æ ¡å‡†æ•ˆæœï¼Œè¿˜æ„å»ºäº†é«˜æ•ˆçš„è‡ªé€‚åº”è¯„ä¼°æµç¨‹ã€‚åœ¨ä¸ç°æœ‰åŸºå‡†çš„å¯¹æ¯”ä¸­ï¼Œè¯¥æ–¹æ³•åœ¨å¯é æ€§å’Œå‡†ç¡®æ€§æ–¹é¢å‡è¡¨ç°å‡ºæ˜æ˜¾çš„ä¼˜è¶Šæ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06225v3",
      "published_date": "2025-08-08 11:11:22 UTC",
      "updated_date": "2025-08-18 12:00:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:14:41.196974+00:00"
    },
    {
      "arxiv_id": "2508.08307v1",
      "title": "Constrained PSLQ Search for Machin-like Identities Achieving Record-Low Lehmer Measures",
      "title_zh": "ç”¨äºæœå¯»å…·æœ‰åˆ›çºªå½•ä½ Lehmer åº¦é‡ç±» Machin æ’ç­‰å¼çš„å—çº¦æŸ PSLQ æœç´¢",
      "authors": [
        "Nick Craig-Wood"
      ],
      "abstract": "Machin-like arctangent relations are classical tools for computing $Ï€$, with efficiency quantified by the Lehmer measure ($Î»$). We present a framework for discovering low-measure relations by coupling the PSLQ integer-relation algorithm with number-theoretic filters derived from the algebraic structure of Gaussian integers, making large scale search tractable. Our search yields new 5 and 6 term relations with record-low Lehmer measures ($Î»=1.4572, Î»=1.3291$). We also demonstrate how discovered relations can serve as a basis for generating new, longer formulae through algorithmic extensions. This combined approach of a constrained PSLQ search and algorithmic extension provides a robust method for future explorations.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç”¨äºè®¡ç®— $\\pi$ çš„ç»å…¸å·¥å…· Machin-like arctangent relationsï¼Œå…¶è®¡ç®—æ•ˆç‡é€šå¸¸ç”± Lehmer measure ($\\lambda$) æ¥é‡åŒ–ã€‚ä¸ºäº†å‘ç°æ›´ä½æµ‹åº¦çš„æ’ç­‰å¼ï¼Œä½œè€…æå‡ºäº†ä¸€ç§æ–°çš„æœç´¢æ¡†æ¶ï¼Œå°† PSLQ integer-relation algorithm ä¸æºè‡ª Gaussian integers ä»£æ•°ç»“æ„çš„æ•°è®ºè¿‡æ»¤å™¨ç›¸ç»“åˆï¼Œä»è€Œä½¿å¤§è§„æ¨¡æœç´¢å˜å¾—å¯è¡Œã€‚è¯¥æ–¹æ³•æˆåŠŸå‘ç°äº†æ–°çš„ 5 é¡¹å’Œ 6 é¡¹æ’ç­‰å¼ï¼Œå¹¶å®ç°äº† record-low Lehmer measuresï¼ˆåˆ†åˆ«ä¸º $\\lambda=1.4572$ å’Œ $\\lambda=1.3291$ï¼‰ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜è¯æ˜äº†è¿™äº›æ–°å‘ç°çš„æ’ç­‰å¼å¯ä»¥ä½œä¸ºç®—æ³•æ‰©å±•çš„åŸºç¡€ï¼Œç”¨äºç”Ÿæˆæ›´é•¿çš„æ•°å­¦å…¬å¼ã€‚è¿™ç§ç»“åˆäº†çº¦æŸ PSLQ æœç´¢ä¸ç®—æ³•æ‰©å±•çš„æ–¹æ³•ï¼Œä¸ºæœªæ¥çš„ç›¸å…³æ¢ç´¢æä¾›äº†å¼ºå¥çš„æ–¹æ³•è®ºæ”¯æŒã€‚",
      "categories": [
        "math.NT",
        "cs.AI"
      ],
      "primary_category": "math.NT",
      "comment": "22 pages, 2 tables, 4035 words",
      "pdf_url": "https://arxiv.org/pdf/2508.08307v1",
      "published_date": "2025-08-08 11:08:13 UTC",
      "updated_date": "2025-08-08 11:08:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:14:41.488705+00:00"
    },
    {
      "arxiv_id": "2508.06220v2",
      "title": "InfoCausalQA:Can Models Perform Non-explicit Causal Reasoning Based on Infographic?",
      "title_zh": "InfoCausalQAï¼šæ¨¡å‹èƒ½å¦åŸºäºä¿¡æ¯å›¾è¿›è¡Œéæ˜¾å¼å› æœæ¨ç†ï¼Ÿ",
      "authors": [
        "Keummin Ka",
        "Junhyeong Park",
        "Jaehyun Jeon",
        "Youngjae Yu"
      ],
      "abstract": "Recent advances in Vision-Language Models (VLMs) have demonstrated impressive capabilities in perception and reasoning. However, the ability to perform causal inference -- a core aspect of human cognition -- remains underexplored, particularly in multimodal settings. In this study, we introduce InfoCausalQA, a novel benchmark designed to evaluate causal reasoning grounded in infographics that combine structured visual data with textual context. The benchmark comprises two tasks: Task 1 focuses on quantitative causal reasoning based on inferred numerical trends, while Task 2 targets semantic causal reasoning involving five types of causal relations: cause, effect, intervention, counterfactual, and temporal. We manually collected 494 infographic-text pairs from four public sources and used GPT-4o to generate 1,482 high-quality multiple-choice QA pairs. These questions were then carefully revised by humans to ensure they cannot be answered based on surface-level cues alone but instead require genuine visual grounding. Our experimental results reveal that current VLMs exhibit limited capability in computational reasoning and even more pronounced limitations in semantic causal reasoning. Their significantly lower performance compared to humans indicates a substantial gap in leveraging infographic-based information for causal inference. Through InfoCausalQA, we highlight the need for advancing the causal reasoning abilities of multimodal AI systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† InfoCausalQAï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨è¯„ä¼° Vision-Language Models (VLMs) åŸºäºåŒ…å«ç»“æ„åŒ–è§†è§‰æ•°æ®å’Œæ–‡æœ¬ä¸Šä¸‹æ–‡çš„ä¿¡æ¯å›¾ (Infographic) è¿›è¡Œéæ˜¾å¼å› æœæ¨ç†èƒ½åŠ›çš„å…¨æ–°åŸºå‡†æµ‹è¯•ã€‚è¯¥åŸºå‡†åŒ…å«ä¸¤é¡¹æ ¸å¿ƒä»»åŠ¡ï¼šTask 1 ä¾§é‡äºåŸºäºæ•°å€¼è¶‹åŠ¿çš„å®šé‡å› æœæ¨ç†ï¼ŒTask 2 åˆ™é’ˆå¯¹æ¶‰åŠåŸå›  (Cause)ã€ç»“æœ (Effect)ã€å¹²é¢„ (Intervention)ã€åäº‹å® (Counterfactual) å’Œæ—¶é—´ (Temporal) äº”ç§å…³ç³»çš„è¯­ä¹‰å› æœæ¨ç†ã€‚ç ”ç©¶å›¢é˜Ÿæ‰‹åŠ¨æ”¶é›†äº† 494 å¯¹ä¿¡æ¯å›¾ä¸æ–‡æœ¬ï¼Œåˆ©ç”¨ GPT-4o ç”Ÿæˆå¹¶ç»ç”±äººå·¥æ·±åº¦ä¿®è®¢æ„å»ºäº† 1,482 ä¸ªé«˜è´¨é‡å¤šé€‰é¢˜ï¼Œç¡®ä¿æ¨¡å‹å¿…é¡»ä¾èµ–çœŸå®çš„è§†è§‰å®šä½ (Visual Grounding) è€Œéè¡¨é¢çº¿ç´¢è¿›è¡Œå›ç­”ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œå½“å‰çš„ VLMs åœ¨è®¡ç®—æ¨ç†å’Œè¯­ä¹‰å› æœæ¨ç†æ–¹é¢å‡è¡¨ç°å‡ºæ˜æ˜¾çš„å±€é™æ€§ï¼Œå…¶æ€§èƒ½æ˜¾è‘—ä½äºäººç±»æ°´å¹³ã€‚è¿™æ­ç¤ºäº†å¤šæ¨¡æ€ AI åœ¨åˆ©ç”¨ä¿¡æ¯å›¾è¿›è¡Œå› æœæ¨æ–­æ–¹é¢å­˜åœ¨å·¨å¤§å·®è·ï¼Œè¯¥å·¥ä½œé€šè¿‡ InfoCausalQA å¼ºè°ƒäº†æå‡å¤šæ¨¡æ€ç³»ç»Ÿå› æœæ¨ç†èƒ½åŠ›çš„ç´§è¿«æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages, 9 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.06220v2",
      "published_date": "2025-08-08 11:03:23 UTC",
      "updated_date": "2025-08-13 07:02:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:14:45.789618+00:00"
    },
    {
      "arxiv_id": "2508.06214v2",
      "title": "Reparameterization Proximal Policy Optimization",
      "title_zh": "é‡å‚æ•°åŒ–è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–",
      "authors": [
        "Hai Zhong",
        "Xun Wang",
        "Zhuoran Li",
        "Longbo Huang"
      ],
      "abstract": "Reparameterization policy gradient (RPG) is promising for improving sample efficiency by leveraging differentiable dynamics. However, a critical barrier is its training instability, where high-variance gradients can destabilize the learning process. To address this, we draw inspiration from Proximal Policy Optimization (PPO), which uses a surrogate objective to enable stable sample reuse in the model-free setting. We first establish a connection between this surrogate objective and RPG, which has been largely unexplored and is non-trivial. Then, we bridge this gap by demonstrating that the reparameterization gradient of a PPO-like surrogate objective can be computed efficiently using backpropagation through time. Based on this key insight, we propose Reparameterization Proximal Policy Optimization (RPO), a stable and sample-efficient RPG-based method. RPO enables stable sample reuse over multiple epochs by employing a policy gradient clipping mechanism tailored for RPG. It is further stabilized by Kullback-Leibler (KL) divergence regularization and remains fully compatible with existing variance reduction methods. We evaluate RPO on a suite of challenging locomotion and manipulation tasks, where experiments demonstrate that our method achieves superior sample efficiency and strong performance.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é‡å‚æ•°åŒ–ç­–ç•¥æ¢¯åº¦(Reparameterization policy gradient, RPG)åœ¨åˆ©ç”¨å¾®åˆ†åŠ¨åŠ›å­¦æå‡æ ·æœ¬æ•ˆç‡æ—¶é¢ä¸´çš„è®­ç»ƒä¸ç¨³å®šå’Œé«˜æ–¹å·®æ¢¯åº¦é—®é¢˜ï¼Œæå‡ºäº†é‡å‚æ•°åŒ–è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–(Reparameterization Proximal Policy Optimization, RPO)ã€‚ä½œè€…é¦–å…ˆå»ºç«‹å¹¶è¯æ˜äº†è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–(PPO)çš„ä»£ç†ç›®æ ‡ä¸RPGä¹‹é—´æ­¤å‰æœªè¢«æ·±å…¥æ¢ç´¢çš„å†…åœ¨è”ç³»ï¼Œè¡¨æ˜è¯¥ç›®æ ‡çš„é‡å‚æ•°åŒ–æ¢¯åº¦å¯ä»¥é€šè¿‡æ—¶é—´åå‘ä¼ æ’­(Backpropagation through time)é«˜æ•ˆè®¡ç®—ã€‚RPOé€šè¿‡å¼•å…¥ä¸“é—¨ä¸ºRPGè®¾è®¡çš„ç­–ç•¥æ¢¯åº¦è£å‰ªæœºåˆ¶ï¼Œå¹¶ç»“åˆKullback-Leibler (KL)æ•£åº¦æ­£åˆ™åŒ–ï¼Œå®ç°äº†å¤šè½®è¿­ä»£ä¸‹ç¨³å®šçš„æ ·æœ¬é‡ç”¨ï¼Œä¸”èƒ½ä¸ç°æœ‰çš„æ–¹å·®ç¼©å‡æ–¹æ³•å®Œå…¨å…¼å®¹ã€‚åœ¨è¿åŠ¨æ§åˆ¶å’Œç‰©ä½“æ“ä½œç­‰æŒ‘æˆ˜æ€§ä»»åŠ¡çš„å®éªŒç»“æœè¡¨æ˜ï¼ŒRPOåœ¨ä¿æŒè®­ç»ƒç¨³å®šæ€§çš„åŒæ—¶ï¼Œæ˜¾è‘—æå‡äº†ç®—æ³•çš„æ ·æœ¬æ•ˆç‡å’Œæ•´ä½“æ€§èƒ½è¡¨ç°ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06214v2",
      "published_date": "2025-08-08 10:50:55 UTC",
      "updated_date": "2025-09-25 15:17:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:14:45.488139+00:00"
    },
    {
      "arxiv_id": "2508.06208v1",
      "title": "Graph Federated Learning for Personalized Privacy Recommendation",
      "title_zh": "é¢å‘ä¸ªæ€§åŒ–éšç§æ¨èçš„å›¾è”é‚¦å­¦ä¹ ",
      "authors": [
        "Ce Na",
        "Kai Yang",
        "Dengzhao Fang",
        "Yu Li",
        "Jingtong Gao",
        "Chengcheng Zhu",
        "Jiale Zhang",
        "Xiaobing Sun",
        "Yi Chang"
      ],
      "abstract": "Federated recommendation systems (FedRecs) have gained significant attention for providing privacy-preserving recommendation services. However, existing FedRecs assume that all users have the same requirements for privacy protection, i.e., they do not upload any data to the server. The approaches overlook the potential to enhance the recommendation service by utilizing publicly available user data. In real-world applications, users can choose to be private or public. Private users' interaction data is not shared, while public users' interaction data can be shared. Inspired by the issue, this paper proposes a novel Graph Federated Learning for Personalized Privacy Recommendation (GFed-PP) that adapts to different privacy requirements while improving recommendation performance. GFed-PP incorporates the interaction data of public users to build a user-item interaction graph, which is then used to form a user relationship graph. A lightweight graph convolutional network (GCN) is employed to learn each user's user-specific personalized item embedding. To protect user privacy, each client learns the user embedding and the scoring function locally. Additionally, GFed-PP achieves optimization of the federated recommendation framework through the initialization of item embedding on clients and the aggregation of the user relationship graph on the server. Experimental results demonstrate that GFed-PP significantly outperforms existing methods for five datasets, offering superior recommendation accuracy without compromising privacy. This framework provides a practical solution for accommodating varying privacy preferences in federated recommendation systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†GFed-PPï¼Œä¸€ç§é’ˆå¯¹ä¸ªæ€§åŒ–éšç§éœ€æ±‚çš„å›¾è”é‚¦å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰Federated Recommendation systems (FedRecs) å¿½è§†ç”¨æˆ·ä¸åŒéšç§åå¥½ä¸”æœªèƒ½å……åˆ†åˆ©ç”¨å…¬å¼€æ•°æ®çš„é—®é¢˜ã€‚è¯¥æ–¹æ³•é€šè¿‡æ•´åˆå…¬å…±ç”¨æˆ·çš„äº¤äº’æ•°æ®æ„å»ºç”¨æˆ·-ç‰©å“äº¤äº’å›¾å’Œç”¨æˆ·å…³ç³»å›¾ï¼Œå¹¶åˆ©ç”¨è½»é‡çº§å›¾å·ç§¯ç½‘ç»œ (GCN) å­¦ä¹ ç”¨æˆ·ç‰¹æœ‰çš„ä¸ªæ€§åŒ–é¡¹ç›®åµŒå…¥ã€‚ä¸ºäº†ä¿æŠ¤éšç§ï¼Œæ¯ä¸ªå®¢æˆ·ç«¯åœ¨æœ¬åœ°å­¦ä¹ ç”¨æˆ·åµŒå…¥å’Œè¯„åˆ†å‡½æ•°ï¼Œè€ŒæœåŠ¡å™¨ç«¯åˆ™è´Ÿè´£èšåˆç”¨æˆ·å…³ç³»å›¾å¹¶ä¼˜åŒ–è”é‚¦æ¨èæ¡†æ¶ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒGFed-PPåœ¨äº”ä¸ªæ•°æ®é›†ä¸Šå‡æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œåœ¨ä¸ç‰ºç‰²éšç§çš„å‰æä¸‹æä¾›äº†æ›´ä¼˜çš„æ¨èå‡†ç¡®æ€§ã€‚è¯¥æ¡†æ¶ä¸ºåœ¨è”é‚¦æ¨èç³»ç»Ÿä¸­åè°ƒä¸åŒç”¨æˆ·çš„éšç§åå¥½æä¾›äº†ä¸€ä¸ªé«˜æ•ˆä¸”å®ç”¨çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06208v1",
      "published_date": "2025-08-08 10:44:33 UTC",
      "updated_date": "2025-08-08 10:44:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:15:06.685302+00:00"
    },
    {
      "arxiv_id": "2508.06591v1",
      "title": "Generative Artificial Intelligence Extracts Structure-Function Relationships from Plants for New Materials",
      "title_zh": "ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ä»æ¤ç‰©ä¸­æå–ç”¨äºæ–°ææ–™ç ”å‘çš„ç»“æ„-åŠŸèƒ½å…³ç³»",
      "authors": [
        "Rachel K. Luu",
        "Jingyu Deng",
        "Mohammed Shahrudin Ibrahim",
        "Nam-Joon Cho",
        "Ming Dao",
        "Subra Suresh",
        "Markus J. Buehler"
      ],
      "abstract": "Large language models (LLMs) have reshaped the research landscape by enabling new approaches to knowledge retrieval and creative ideation. Yet their application in discipline-specific experimental science, particularly in highly multi-disciplinary domains like materials science, remains limited. We present a first-of-its-kind framework that integrates generative AI with literature from hitherto-unconnected fields such as plant science, biomimetics, and materials engineering to extract insights and design experiments for materials. We focus on humidity-responsive systems such as pollen-based materials and Rhapis excelsa (broadleaf lady palm) leaves, which exhibit self-actuation and adaptive performance. Using a suite of AI tools, including a fine-tuned model (BioinspiredLLM), Retrieval-Augmented Generation (RAG), agentic systems, and a Hierarchical Sampling strategy, we extract structure-property relationships and translate them into new classes of bioinspired materials. Structured inference protocols generate and evaluate hundreds of hypotheses from a single query, surfacing novel and experimentally tractable ideas. We validate our approach through real-world implementation: LLM-generated procedures, materials designs, and mechanical predictions were tested in the laboratory, culminating in the fabrication of a novel pollen-based adhesive with tunable morphology and measured shear strength, establishing a foundation for future plant-derived adhesive design. This work demonstrates how AI-assisted ideation can drive real-world materials design and enable effective human-AI collaboration.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªå°†ç”Ÿæˆå¼äººå·¥æ™ºèƒ½(Generative AI)ä¸æ¤ç‰©ç§‘å­¦ã€ç”Ÿç‰©æ¨¡ä»¿(Biomimetics)åŠææ–™å·¥ç¨‹ç­‰è·¨å­¦ç§‘é¢†åŸŸç»“åˆçš„åˆ›æ–°æ¡†æ¶ï¼Œæ—¨åœ¨åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)ä»è‡ªç„¶ç•Œä¸­æå–ç»“æ„-åŠŸèƒ½å…³ç³»ã€‚ç ”ç©¶é‡ç‚¹å…³æ³¨èŠ±ç²‰ææ–™å’Œæ£•ç«¹(Rhapis excelsa)å¶ç‰‡ç­‰å…·æœ‰è‡ªé©±åŠ¨ç‰¹æ€§çš„æ¹¿åº¦å“åº”ç³»ç»Ÿ(Humidity-responsive systems)ï¼Œå¹¶é‡‡ç”¨å¾®è°ƒæ¨¡å‹(BioinspiredLLM)ã€æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)å’Œæ™ºèƒ½ä½“ç³»ç»Ÿ(Agentic systems)ç­‰æŠ€æœ¯å°†ç”Ÿç‰©å­¦æœºåˆ¶è½¬åŒ–ä¸ºææ–™è®¾è®¡æ€è·¯ã€‚é€šè¿‡å±‚æ¬¡é‡‡æ ·ç­–ç•¥(Hierarchical Sampling)å’Œç»“æ„åŒ–æ¨ç†ï¼Œè¯¥ç³»ç»Ÿèƒ½å¤Ÿé«˜æ•ˆç”Ÿæˆå¹¶ç­›é€‰å‡ºå…·æœ‰å®éªŒå¯è¡Œæ€§çš„æ–°å‡è®¾ã€‚å®éªŒé€šè¿‡å®éªŒå®¤åˆ¶å¤‡éªŒè¯äº†ç”±AIè®¾è®¡çš„ææ–™æ–¹æ¡ˆï¼ŒæˆåŠŸç ”å‘å‡ºä¸€ç§å…·æœ‰å¯è°ƒå½¢è²Œå’Œå‰ªåˆ‡å¼ºåº¦çš„åŸºäºèŠ±ç²‰çš„æ–°å‹ç²˜åˆå‰‚ã€‚è¯¥æˆæœè¯æ˜äº†AIè¾…åŠ©æ„æ€åœ¨é©±åŠ¨çœŸå®ä¸–ç•Œææ–™å‘ç°ä¸­çš„æ½œåŠ›ï¼Œä¸ºæœªæ¥æ¤ç‰©æºææ–™çš„è®¾è®¡ä¸æœ‰æ•ˆçš„äººæœºåä½œ(Human-AI collaboration)æä¾›äº†æ–°çš„èŒƒå¼ã€‚",
      "categories": [
        "cs.LG",
        "cond-mat.dis-nn",
        "cond-mat.mtrl-sci",
        "cond-mat.other",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06591v1",
      "published_date": "2025-08-08 10:41:03 UTC",
      "updated_date": "2025-08-08 10:41:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:15:07.049138+00:00"
    },
    {
      "arxiv_id": "2508.06204v1",
      "title": "Classification is a RAG problem: A case study on hate speech detection",
      "title_zh": "åˆ†ç±»å³ RAG é—®é¢˜ï¼šä»‡æ¨è¨€è®ºæ£€æµ‹æ¡ˆä¾‹ç ”ç©¶",
      "authors": [
        "Richard Willats",
        "Josh Pennington",
        "Aravind Mohan",
        "Bertie Vidgen"
      ],
      "abstract": "Robust content moderation requires classification systems that can quickly adapt to evolving policies without costly retraining. We present classification using Retrieval-Augmented Generation (RAG), which shifts traditional classification tasks from determining the correct category in accordance with pre-trained parameters to evaluating content in relation to contextual knowledge retrieved at inference. In hate speech detection, this transforms the task from \"is this hate speech?\" to \"does this violate the hate speech policy?\"\n  Our Contextual Policy Engine (CPE) - an agentic RAG system - demonstrates this approach and offers three key advantages: (1) robust classification accuracy comparable to leading commercial systems, (2) inherent explainability via retrieved policy segments, and (3) dynamic policy updates without model retraining. Through three experiments, we demonstrate strong baseline performance and show that the system can apply fine-grained policy control by correctly adjusting protection for specific identity groups without requiring retraining or compromising overall performance. These findings establish that RAG can transform classification into a more flexible, transparent, and adaptable process for content moderation and wider classification problems.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºå°†åˆ†ç±»ä»»åŠ¡è§†ä¸ºæ£€ç´¢å¢å¼ºç”Ÿæˆ(Retrieval-Augmented Generation, RAG)é—®é¢˜ï¼Œå¹¶ä»¥ä»‡æ¨è¨€è®ºæ£€æµ‹ä¸ºä¾‹æ¢è®¨äº†å…¶å¯è¡Œæ€§ã€‚ä½œè€…å¼€å‘äº†ä¸Šä¸‹æ–‡ç­–ç•¥å¼•æ“(Contextual Policy Engine, CPE)ï¼Œè¿™æ˜¯ä¸€ç§ä»£ç†å¼ RAG ç³»ç»Ÿï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿåˆ†ç±»æ¨¡å‹åœ¨æ”¿ç­–æ›´æ–°æ—¶é¢ä¸´çš„é«˜æ˜‚é‡æ–°è®­ç»ƒæˆæœ¬é—®é¢˜ã€‚è¯¥æ–¹æ³•å°†åˆ†ç±»é€»è¾‘ä»å•çº¯çš„ç±»åˆ«åˆ¤å®šè½¬å˜ä¸ºè¯„ä¼°å†…å®¹æ˜¯å¦è¿åæ¨ç†æ—¶æ£€ç´¢åˆ°çš„ç‰¹å®šæ”¿ç­–ç‰‡æ®µï¼Œå®ç°äº†ä»â€œè¿™æ˜¯ä»‡æ¨è¨€è®ºå—ï¼Ÿâ€åˆ°â€œè¿™æ˜¯å¦è¿åäº†ç›¸å…³æ”¿ç­–ï¼Ÿâ€çš„èŒƒå¼è½¬ç§»ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒCPE çš„åˆ†ç±»å‡†ç¡®ç‡ä¸é¢†å…ˆçš„å•†ä¸šç³»ç»Ÿç›¸å½“ï¼Œä¸”å…·æœ‰åŸºäºæ£€ç´¢æ”¿ç­–çš„å†…åœ¨å¯è§£é‡Šæ€§(explainability)ã€‚æ­¤å¤–ï¼Œè¯¥ç³»ç»Ÿæ”¯æŒæ— éœ€é‡æ–°è®­ç»ƒçš„åŠ¨æ€æ”¿ç­–æ›´æ–°å’Œç»†ç²’åº¦æ§åˆ¶ï¼Œèƒ½å¤Ÿç²¾å‡†è°ƒæ•´å¯¹ç‰¹å®šèº«ä»½ç¾¤ä½“çš„ä¿æŠ¤è€Œä¸å½±å“æ•´ä½“æ€§èƒ½ã€‚è¿™é¡¹å·¥ä½œè¯æ˜äº† RAG æŠ€æœ¯èƒ½ä½¿åˆ†ç±»è¿‡ç¨‹å˜å¾—æ›´åŠ çµæ´»ã€é€æ˜ä¸”æ˜“äºé€‚åº”ï¼Œä¸ºå†…å®¹å®¡æ ¸å’Œæ›´å¹¿æ³›çš„åˆ†ç±»æŒ‘æˆ˜æä¾›äº†æ–°çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06204v1",
      "published_date": "2025-08-08 10:35:41 UTC",
      "updated_date": "2025-08-08 10:35:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:15:13.152996+00:00"
    },
    {
      "arxiv_id": "2508.06202v1",
      "title": "LoRA in LoRA: Towards Parameter-Efficient Architecture Expansion for Continual Visual Instruction Tuning",
      "title_zh": "LoRA in LoRAï¼šé¢å‘æŒç»­è§†è§‰æŒ‡ä»¤å¾®è°ƒçš„å‚æ•°é«˜æ•ˆæ¶æ„æ‰©å±•",
      "authors": [
        "Chang Che",
        "Ziqi Wang",
        "Pengwan Yang",
        "Qi Wang",
        "Hui Ma",
        "Zenglin Shi"
      ],
      "abstract": "Continual Visual Instruction Tuning (CVIT) enables Multimodal Large Language Models (MLLMs) to incrementally learn new tasks over time. However, this process is challenged by catastrophic forgetting, where performance on previously learned tasks deteriorates as the model adapts to new ones. A common approach to mitigate forgetting is architecture expansion, which introduces task-specific modules to prevent interference. Yet, existing methods often expand entire layers for each task, leading to significant parameter overhead and poor scalability. To overcome these issues, we introduce LoRA in LoRA (LiLoRA), a highly efficient architecture expansion method tailored for CVIT in MLLMs. LiLoRA shares the LoRA matrix A across tasks to reduce redundancy, applies an additional low-rank decomposition to matrix B to minimize task-specific parameters, and incorporates a cosine-regularized stability loss to preserve consistency in shared representations over time. Extensive experiments on a diverse CVIT benchmark show that LiLoRA consistently achieves superior performance in sequential task learning while significantly improving parameter efficiency compared to existing approaches.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLMs)åœ¨æŒç»­è§†è§‰æŒ‡ä»¤å¾®è°ƒ(Continual Visual Instruction Tuning, CVIT)ä¸­é¢ä¸´çš„ç¾éš¾æ€§é—å¿˜é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºLoRA in LoRA (LiLoRA)çš„é«˜æ•ˆæ¶æ„æ‰©å±•æ–¹æ³•ã€‚LiLoRAé€šè¿‡åœ¨ä¸åŒä»»åŠ¡é—´å…±äº«LoRAçŸ©é˜µAæ¥å‡å°‘å†—ä½™ï¼Œå¹¶å¯¹çŸ©é˜µBåº”ç”¨é¢å¤–çš„ä½ç§©åˆ†è§£(low-rank decomposition)ï¼Œä»è€Œæ˜¾è‘—é™ä½äº†ä»»åŠ¡ç‰¹å®šæ¨¡å—çš„å‚æ•°å¼€é”€ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶å¼•å…¥äº†ä½™å¼¦æ­£åˆ™åŒ–ç¨³å®šæ€§æŸå¤±(cosine-regularized stability loss)ï¼Œä»¥ç»´æŒå…±äº«è¡¨å¾åœ¨å¢é‡å­¦ä¹ è¿‡ç¨‹ä¸­çš„ä¸€è‡´æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒLiLoRAåœ¨é¡ºåºä»»åŠ¡å­¦ä¹ æ€§èƒ½ä¸ŠæŒç»­ä¼˜äºç°æœ‰æ–¹æ³•ï¼ŒåŒæ—¶æå¤§åœ°æå‡äº†æ¨¡å‹åœ¨æ¶æ„æ‰©å±•æ—¶çš„å‚æ•°æ•ˆç‡ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06202v1",
      "published_date": "2025-08-08 10:32:38 UTC",
      "updated_date": "2025-08-08 10:32:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:15:16.400238+00:00"
    },
    {
      "arxiv_id": "2508.06199v3",
      "title": "Benchmarking Pretrained Molecular Embedding Models For Molecular Representation Learning",
      "title_zh": "é¢å‘åˆ†å­è¡¨ç¤ºå­¦ä¹ çš„é¢„è®­ç»ƒåˆ†å­åµŒå…¥æ¨¡å‹åŸºå‡†æµ‹è¯•",
      "authors": [
        "Mateusz Praski",
        "Jakub Adamczyk",
        "Wojciech Czech"
      ],
      "abstract": "Pretrained neural networks have attracted significant interest in chemistry and small molecule drug design. Embeddings from these models are widely used for molecular property prediction, virtual screening, and small data learning in molecular chemistry. This study presents the most extensive comparison of such models to date, evaluating 25 models across 25 datasets. Under a fair comparison framework, we assess models spanning various modalities, architectures, and pretraining strategies. Using a dedicated hierarchical Bayesian statistical testing model, we arrive at a surprising result: nearly all neural models show negligible or no improvement over the baseline ECFP molecular fingerprint. Only the CLAMP model, which is also based on molecular fingerprints, performs statistically significantly better than the alternatives. These findings raise concerns about the evaluation rigor in existing studies. We discuss potential causes, propose solutions, and offer practical recommendations.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶å¯¹ç”¨äºåˆ†å­è¡¨ç¤ºå­¦ä¹ çš„é¢„è®­ç»ƒåˆ†å­åµŒå…¥æ¨¡å‹è¿›è¡Œäº†è¿„ä»Šä¸ºæ­¢æœ€å¹¿æ³›çš„åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è¯„ä¼°è¿™äº›æ¨¡å‹åœ¨åŒ–å­¦å’Œè¯ç‰©è®¾è®¡é¢†åŸŸçš„å®é™…è¡¨ç°ã€‚ç ”ç©¶äººå‘˜åœ¨ä¸€ä¸ªå…¬å¹³çš„æ¯”è¾ƒæ¡†æ¶ä¸‹ï¼Œè¯„ä¼°äº†æ¶µç›–ä¸åŒæ¨¡æ€ã€æ¶æ„å’Œé¢„è®­ç»ƒç­–ç•¥çš„25ä¸ªæ¨¡å‹åœ¨25ä¸ªæ•°æ®é›†ä¸Šçš„æ€§èƒ½ï¼Œå¹¶é‡‡ç”¨äº†ä¸“é—¨çš„å±‚æ¬¡è´å¶æ–¯(hierarchical Bayesian)ç»Ÿè®¡æµ‹è¯•æ¨¡å‹è¿›è¡Œåˆ†æã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œå‡ ä¹æ‰€æœ‰ç¥ç»ç½‘ç»œæ¨¡å‹ç›¸è¾ƒäºåŸºå‡†çš„ ECFP åˆ†å­æŒ‡çº¹(molecular fingerprint)å…¶æ”¹è¿›éƒ½å¾®ä¹å…¶å¾®ç”šè‡³å®Œå…¨æ²¡æœ‰ã€‚åœ¨æ‰€æœ‰æµ‹è¯•å¯¹è±¡ä¸­ï¼Œä»…æœ‰åŒæ ·åŸºäºåˆ†å­æŒ‡çº¹çš„ CLAMP æ¨¡å‹åœ¨ç»Ÿè®¡å­¦æ„ä¹‰ä¸Šæ˜¾è‘—ä¼˜äºå…¶ä»–æ›¿ä»£æ–¹æ¡ˆã€‚è¿™äº›å‘ç°å¼•å‘äº†å¯¹ç°æœ‰ç ”ç©¶ä¸­è¯„ä¼°ä¸¥è°¨æ€§çš„æ‹…å¿§ï¼Œç ”ç©¶è€…æ®æ­¤æ¢è®¨äº†å¯èƒ½çš„åŸå› ï¼Œå¹¶æå‡ºäº†æ”¹è¿›æ–¹æ¡ˆåŠå®ç”¨çš„åº”ç”¨å»ºè®®ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06199v3",
      "published_date": "2025-08-08 10:29:24 UTC",
      "updated_date": "2025-09-14 11:09:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:15:17.986938+00:00"
    },
    {
      "arxiv_id": "2508.09195v1",
      "title": "impuTMAE: Multi-modal Transformer with Masked Pre-training for Missing Modalities Imputation in Cancer Survival Prediction",
      "title_zh": "impuTMAEï¼šåŸºäºæ©ç é¢„è®­ç»ƒçš„å¤šæ¨¡æ€ Transformerï¼Œç”¨äºç™Œç—‡ç”Ÿå­˜é¢„æµ‹ä¸­çš„ç¼ºå¤±æ¨¡æ€æ’è¡¥",
      "authors": [
        "Maria Boyko",
        "Aleksandra Beliaeva",
        "Dmitriy Kornilov",
        "Alexander Bernstein",
        "Maxim Sharaev"
      ],
      "abstract": "The use of diverse modalities, such as omics, medical images, and clinical data can not only improve the performance of prognostic models but also deepen an understanding of disease mechanisms and facilitate the development of novel treatment approaches. However, medical data are complex, often incomplete, and contains missing modalities, making effective handling its crucial for training multimodal models. We introduce impuTMAE, a novel transformer-based end-to-end approach with an efficient multimodal pre-training strategy. It learns inter- and intra-modal interactions while simultaneously imputing missing modalities by reconstructing masked patches. Our model is pre-trained on heterogeneous, incomplete data and fine-tuned for glioma survival prediction using TCGA-GBM/LGG and BraTS datasets, integrating five modalities: genetic (DNAm, RNA-seq), imaging (MRI, WSI), and clinical data. By addressing missing data during pre-training and enabling efficient resource utilization, impuTMAE surpasses prior multimodal approaches, achieving state-of-the-art performance in glioma patient survival prediction. Our code is available at https://github.com/maryjis/mtcp",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç™Œç—‡é¢„åæ¨¡å‹ä¸­å¸¸è§çš„æ•°æ®ç¼ºå¤±å’Œæ¨¡æ€ä¸å®Œæ•´é—®é¢˜ï¼Œæå‡ºäº† impuTMAEï¼Œä¸€ç§åŸºäº Transformer çš„ç«¯åˆ°ç«¯å¤šæ¨¡æ€é¢„è®­ç»ƒæ¡†æ¶ã€‚è¯¥æ¨¡å‹é€šè¿‡é«˜æ•ˆçš„å¤šæ¨¡æ€é¢„è®­ç»ƒ(Multimodal Pre-training)ç­–ç•¥ï¼Œåœ¨å­¦ä¹ æ¨¡æ€é—´å’Œæ¨¡æ€å†…äº¤äº’çš„åŒæ—¶ï¼Œåˆ©ç”¨æ©ç è¡¥ä¸é‡æ„æŠ€æœ¯å®ç°ç¼ºå¤±æ¨¡æ€çš„å¡«è¡¥ã€‚ç ”ç©¶å›¢é˜Ÿåœ¨å¼‚æ„ä¸”ä¸å®Œæ•´çš„æ•°æ®é›†ä¸Šå¯¹æ¨¡å‹è¿›è¡Œé¢„è®­ç»ƒï¼Œå¹¶é’ˆå¯¹ TCGA-GBM/LGG å’Œ BraTS æ•°æ®é›†ä¸­çš„èƒ¶è´¨ç˜¤(Glioma)ç”Ÿå­˜é¢„æµ‹ä»»åŠ¡è¿›è¡Œäº†å¾®è°ƒï¼Œé›†æˆäº† DNAmã€RNA-seqã€MRIã€WSI ä»¥åŠä¸´åºŠæ•°æ®äº”ç§æ¨¡æ€ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒimpuTMAE èƒ½å¤Ÿæœ‰æ•ˆå¤„ç†è®­ç»ƒè¿‡ç¨‹ä¸­çš„ç¼ºå¤±æ•°æ®å¹¶ä¼˜åŒ–èµ„æºåˆ©ç”¨ï¼Œåœ¨èƒ¶è´¨ç˜¤æ‚£è€…ç”Ÿå­˜é¢„æµ‹ä»»åŠ¡ä¸­è¶…è¶Šäº†ç°æœ‰çš„å¤šæ¨¡æ€æ¨¡å‹å¹¶è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½(State-of-the-art)ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09195v1",
      "published_date": "2025-08-08 10:01:16 UTC",
      "updated_date": "2025-08-08 10:01:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:15:35.564884+00:00"
    },
    {
      "arxiv_id": "2508.06183v1",
      "title": "Differentially Private Federated Clustering with Random Rebalancing",
      "title_zh": "åŸºäºéšæœºé‡å¹³è¡¡çš„å·®åˆ†éšç§è”é‚¦èšç±»",
      "authors": [
        "Xiyuan Yang",
        "Shengyuan Hu",
        "Soyeon Kim",
        "Tian Li"
      ],
      "abstract": "Federated clustering aims to group similar clients into clusters and produce one model for each cluster. Such a personalization approach typically improves model performance compared with training a single model to serve all clients, but can be more vulnerable to privacy leakage. Directly applying client-level differentially private (DP) mechanisms to federated clustering could degrade the utilities significantly. We identify that such deficiencies are mainly due to the difficulties of averaging privacy noise within each cluster (following standard privacy mechanisms), as the number of clients assigned to the same clusters is uncontrolled. To this end, we propose a simple and effective technique, named RR-Cluster, that can be viewed as a light-weight add-on to many federated clustering algorithms. RR-Cluster achieves reduced privacy noise via randomly rebalancing cluster assignments, guaranteeing a minimum number of clients assigned to each cluster. We analyze the tradeoffs between decreased privacy noise variance and potentially increased bias from incorrect assignments and provide convergence bounds for RR-Clsuter. Empirically, we demonstrate the RR-Cluster plugged into strong federated clustering algorithms results in significantly improved privacy/utility tradeoffs across both synthetic and real-world datasets.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨è”é‚¦èšç±» (Federated clustering) ä¸­åº”ç”¨å·®åˆ†éšç§ (Differential Privacy, DP) æ—¶ï¼Œç”±äºå„èšç±»å®¢æˆ·ç«¯æ•°é‡ä¸å¯æ§å¯¼è‡´éšç§å™ªå£°éš¾ä»¥æ¶ˆé™¤å¹¶æŸå®³æ¨¡å‹æ•ˆç”¨çš„é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†ä¸€ç§åä¸º RR-Cluster çš„è½»é‡çº§æ’ä»¶æŠ€æœ¯ï¼Œé€šè¿‡éšæœºé‡å¹³è¡¡ (Randomly Rebalancing) èšç±»åˆ†é…ï¼Œç¡®ä¿æ¯ä¸ªèšç±»æ‹¥æœ‰æœ€å°å®¢æˆ·ç«¯æ•°é‡ä»¥æœ‰æ•ˆé™ä½éšç§å™ªå£°æ–¹å·®ã€‚ç ”ç©¶æ·±å…¥åˆ†æäº†å™ªå£°é™ä½ä¸é”™è¯¯åˆ†é…åå·®ä¹‹é—´çš„æƒè¡¡ï¼Œå¹¶ç»™å‡ºäº† RR-Cluster çš„æ”¶æ•›æ€§ç•Œé™ (Convergence Bounds) ç†è®ºè¯æ˜ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œå°† RR-Cluster é›†æˆåˆ°ç°æœ‰çš„å¼ºæ•ˆè”é‚¦èšç±»ç®—æ³•ä¸­ï¼Œèƒ½åœ¨åˆæˆåŠçœŸå®æ•°æ®é›†ä¸Šæ˜¾è‘—ä¼˜åŒ–éšç§ä¸æ•ˆç”¨çš„æƒè¡¡è¡¨ç°ã€‚è¯¥æ–¹æ³•ä¸ºå®ç°å…¼é¡¾éšç§ä¿æŠ¤ä¸æ¨¡å‹æ•ˆç”¨çš„ä¸ªæ€§åŒ–è”é‚¦å­¦ä¹ æä¾›äº†åˆ‡å®å¯è¡Œçš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "21 pages",
      "pdf_url": "https://arxiv.org/pdf/2508.06183v1",
      "published_date": "2025-08-08 09:56:47 UTC",
      "updated_date": "2025-08-08 09:56:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:15:28.854837+00:00"
    },
    {
      "arxiv_id": "2508.09194v1",
      "title": "Meta-Learning for Speeding Up Large Model Inference in Decentralized Environments",
      "title_zh": "é¢å‘å»ä¸­å¿ƒåŒ–ç¯å¢ƒå¤§æ¨¡å‹æ¨ç†åŠ é€Ÿçš„å…ƒå­¦ä¹ ",
      "authors": [
        "Yipeng Du",
        "Zihao Wang",
        "Ahmad Farhan",
        "Claudio Angione",
        "Harry Yang",
        "Fielding Johnston",
        "James P. Buban",
        "Patrick Colangelo",
        "Yue Zhao",
        "Yuzhe Yang"
      ],
      "abstract": "The deployment of large-scale models, such as large language models (LLMs), incurs substantial costs due to their computational demands. To mitigate these costs and address challenges related to scalability and data security, there is a growing shift towards decentralized systems for model deployment, where choosing efficient inference acceleration schemes become crucial to manage computational resources effectively and enhance system responsiveness. In this work, we address the challenge of selecting optimal acceleration methods in decentralized systems by introducing a meta-learning-based framework. This framework automates the selection process by learning from historical performance data of various acceleration techniques across different tasks. Unlike traditional methods that rely on random selection or expert intuition, our approach systematically identifies the best acceleration strategies based on the specific characteristics of each task. We demonstrate that our meta-learning framework not only streamlines the decision-making process but also consistently outperforms conventional methods in terms of efficiency and performance. Our results highlight the potential of inference acceleration in decentralized AI systems, offering a path towards more democratic and economically feasible artificial intelligence solutions.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è§„æ¨¡æ¨¡å‹ï¼ˆå¦‚LLMsï¼‰åœ¨å»ä¸­å¿ƒåŒ–ç¯å¢ƒ(decentralized environments)éƒ¨ç½²è¿‡ç¨‹ä¸­æ¨ç†æˆæœ¬é«˜æ˜‚ä¸”åŠ é€Ÿæ–¹æ¡ˆé€‰æ‹©å›°éš¾çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºå…ƒå­¦ä¹ (Meta-Learning)çš„è‡ªåŠ¨åŒ–å†³ç­–æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡å­¦ä¹ å„ç§æ¨ç†åŠ é€ŸæŠ€æœ¯åœ¨ä¸åŒä»»åŠ¡ä¸Šçš„å†å²æ€§èƒ½æ•°æ®ï¼Œå…‹æœäº†ä¼ ç»Ÿæ–¹æ³•ä¾èµ–éšæœºé€‰æ‹©æˆ–ä¸“å®¶ç»éªŒçš„å±€é™æ€§ï¼Œèƒ½å¤Ÿæ ¹æ®å…·ä½“ä»»åŠ¡ç‰¹å¾ç³»ç»Ÿæ€§åœ°è¯†åˆ«å¹¶åº”ç”¨æœ€ä¼˜åŠ é€Ÿç­–ç•¥ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨ç®€åŒ–å†³ç­–æµç¨‹çš„åŒæ—¶ï¼Œå…¶æ•ˆç‡å’Œæ€§èƒ½è¡¨ç°å‡æ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ã€‚è¯¥ç ”ç©¶ä¸ä»…æå‡äº†å»ä¸­å¿ƒåŒ–AIç³»ç»Ÿçš„å“åº”é€Ÿåº¦ä¸èµ„æºç®¡ç†æ•ˆç‡ï¼Œè¿˜ä¸ºå®ç°æ›´å…·ç»æµå¯è¡Œæ€§ä¸æ°‘ä¸»åŒ–çš„äººå·¥æ™ºèƒ½è§£å†³æ–¹æ¡ˆæä¾›äº†å…³é”®çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "COLM2025",
      "pdf_url": "https://arxiv.org/pdf/2508.09194v1",
      "published_date": "2025-08-08 09:53:53 UTC",
      "updated_date": "2025-08-08 09:53:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:15:29.262753+00:00"
    },
    {
      "arxiv_id": "2508.09193v1",
      "title": "Multi-Objective Instruction-Aware Representation Learning in Procedural Content Generation RL",
      "title_zh": "è¿‡ç¨‹åŒ–å†…å®¹ç”Ÿæˆå¼ºåŒ–å­¦ä¹ ä¸­çš„å¤šç›®æ ‡æŒ‡ä»¤æ„ŸçŸ¥è¡¨ç¤ºå­¦ä¹ ",
      "authors": [
        "Sung-Hyun Kim",
        "In-Chang Baek",
        "Seo-Young Lee",
        "Geum-Hwan Hwang",
        "Kyung-Joong Kim"
      ],
      "abstract": "Recent advancements in generative modeling emphasize the importance of natural language as a highly expressive and accessible modality for controlling content generation. However, existing instructed reinforcement learning for procedural content generation (IPCGRL) method often struggle to leverage the expressive richness of textual input, especially under complex, multi-objective instructions, leading to limited controllability. To address this problem, we propose \\textit{MIPCGRL}, a multi-objective representation learning method for instructed content generators, which incorporates sentence embeddings as conditions. MIPCGRL effectively trains a multi-objective embedding space by incorporating multi-label classification and multi-head regression networks. Experimental results show that the proposed method achieves up to a 13.8\\% improvement in controllability with multi-objective instructions. The ability to process complex instructions enables more expressive and flexible content generation.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰çš„å—æŒ‡ä»¤å¼•å¯¼çš„ç¨‹åºåŒ–å†…å®¹ç”Ÿæˆå¼ºåŒ–å­¦ä¹ (IPCGRL)æ–¹æ³•åœ¨å¤„ç†å¤æ‚ã€å¤šç›®æ ‡æŒ‡ä»¤æ—¶ï¼Œç”±äºéš¾ä»¥å……åˆ†åˆ©ç”¨è‡ªç„¶è¯­è¨€çš„è¡¨è¾¾ä¸°å¯Œæ€§è€Œå¯¼è‡´æ§åˆ¶åŠ›å—é™çš„é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶è€…æå‡ºäº†MIPCGRLï¼Œè¿™æ˜¯ä¸€ç§é¢å‘æŒ‡ä»¤å¼•å¯¼å†…å®¹ç”Ÿæˆå™¨çš„å¤šç›®æ ‡è¡¨ç¤ºå­¦ä¹ æ–¹æ³•ï¼Œé€šè¿‡å°†å¥å­åµŒå…¥(sentence embeddings)ä½œä¸ºæ¡ä»¶å¼•å…¥ç”Ÿæˆè¿‡ç¨‹ã€‚MIPCGRLç»“åˆäº†å¤šæ ‡ç­¾åˆ†ç±»å’Œå¤šå¤´å›å½’ç½‘ç»œï¼Œæ—¨åœ¨æ„å»ºå¹¶è®­ç»ƒä¸€ä¸ªé«˜æ•ˆçš„å¤šç›®æ ‡åµŒå…¥ç©ºé—´ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å¤šç›®æ ‡æŒ‡ä»¤åœºæ™¯ä¸‹çš„æ§åˆ¶åŠ›æœ€é«˜æå‡äº†13.8%ã€‚è¿™ç§å¤„ç†å¤æ‚æŒ‡ä»¤çš„èƒ½åŠ›æ˜¾è‘—å¢å¼ºäº†ç¨‹åºåŒ–å†…å®¹ç”Ÿæˆçš„è¡¨ç°åŠ›å’Œçµæ´»æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "5 pages, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.09193v1",
      "published_date": "2025-08-08 09:41:42 UTC",
      "updated_date": "2025-08-08 09:41:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:15:29.758554+00:00"
    },
    {
      "arxiv_id": "2508.06170v1",
      "title": "Synthetic Data-Driven Multi-Architecture Framework for Automated Polyp Segmentation Through Integrated Detection and Mask Generation",
      "title_zh": "ç»“åˆæ£€æµ‹ä¸æ©ç ç”Ÿæˆçš„åˆæˆæ•°æ®é©±åŠ¨å¤šæ¶æ„è‡ªåŠ¨åŒ–æ¯è‚‰åˆ†å‰²æ¡†æ¶",
      "authors": [
        "Ojonugwa Oluwafemi Ejiga Peter",
        "Akingbola Oluwapemiisin",
        "Amalahu Chetachi",
        "Adeniran Opeyemi",
        "Fahmi Khalifa",
        "Md Mahmudur Rahman"
      ],
      "abstract": "Colonoscopy is a vital tool for the early diagnosis of colorectal cancer, which is one of the main causes of cancer-related mortality globally; hence, it is deemed an essential technique for the prevention and early detection of colorectal cancer. The research introduces a unique multidirectional architectural framework to automate polyp detection within colonoscopy images while helping resolve limited healthcare dataset sizes and annotation complexities. The research implements a comprehensive system that delivers synthetic data generation through Stable Diffusion enhancements together with detection and segmentation algorithms. This detection approach combines Faster R-CNN for initial object localization while the Segment Anything Model (SAM) refines the segmentation masks. The faster R-CNN detection algorithm achieved a recall of 93.08% combined with a precision of 88.97% and an F1 score of 90.98%.SAM is then used to generate the image mask. The research evaluated five state-of-the-art segmentation models that included U-Net, PSPNet, FPN, LinkNet, and MANet using ResNet34 as a base model. The results demonstrate the superior performance of FPN with the highest scores of PSNR (7.205893) and SSIM (0.492381), while UNet excels in recall (84.85%) and LinkNet shows balanced performance in IoU (64.20%) and Dice score (77.53%).",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åˆæˆæ•°æ®é©±åŠ¨çš„å¤šæ¶æ„æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç»“è‚ é•œæ£€æŸ¥ä¸­æ¯è‚‰è‡ªåŠ¨åˆ†å‰²é¢ä¸´çš„æ•°æ®é›†è§„æ¨¡æœ‰é™å’Œæ ‡æ³¨å¤æ‚ç­‰æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶åˆ©ç”¨ Stable Diffusion æŠ€æœ¯å¢å¼ºåˆæˆæ•°æ®ç”Ÿæˆï¼Œå¹¶ç»“åˆäº† Faster R-CNN ç”¨äºåˆå§‹ç›®æ ‡å®šä½å’Œ Segment Anything Model (SAM) ç”¨äºç»†åŒ–åˆ†å‰²æ©ç ã€‚å®éªŒè¯„ä¼°äº†åŒ…æ‹¬ U-Netã€PSPNetã€FPNã€LinkNet å’Œ MANet åœ¨å†…çš„äº”ç§å…ˆè¿›åˆ†å‰²æ¨¡å‹ï¼Œå¹¶ç»Ÿä¸€é‡‡ç”¨ ResNet34 ä½œä¸ºåŸºç¡€æ¨¡å‹ã€‚Faster R-CNN æ£€æµ‹ç®—æ³•å®ç°äº† 93.08% çš„ Recallã€88.97% çš„ Precision å’Œ 90.98% çš„ F1 scoreã€‚ç»“æœæ˜¾ç¤ºï¼ŒFPN åœ¨ PSNR å’Œ SSIM æŒ‡æ ‡ä¸Šè¡¨ç°æœ€ä¼˜ï¼ŒU-Net åœ¨ Recall (84.85%) æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œè€Œ LinkNet åœ¨ IoU (64.20%) å’Œ Dice score (77.53%) æ–¹é¢å±•ç°äº†å‡è¡¡çš„æ€§èƒ½ã€‚è¯¥é›†æˆæ£€æµ‹ä¸æ©ç ç”Ÿæˆçš„ç³»ç»Ÿä¸ºç»“ç›´è‚ ç™Œçš„æ—©æœŸè¯Šæ–­å’Œé¢„é˜²æä¾›äº†é«˜æ•ˆçš„è‡ªåŠ¨åŒ–æŠ€æœ¯æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06170v1",
      "published_date": "2025-08-08 09:37:03 UTC",
      "updated_date": "2025-08-08 09:37:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:15:46.658425+00:00"
    },
    {
      "arxiv_id": "2508.06169v1",
      "title": "UW-3DGS: Underwater 3D Reconstruction with Physics-Aware Gaussian Splatting",
      "title_zh": "UW-3DGSï¼šåŸºäºç‰©ç†æ„ŸçŸ¥é«˜æ–¯æ³¼æº…çš„æ°´ä¸‹ä¸‰ç»´é‡å»º",
      "authors": [
        "Wenpeng Xing",
        "Jie Chen",
        "Zaifeng Yang",
        "Changting Lin",
        "Jianfeng Dong",
        "Chaochao Chen",
        "Xun Zhou",
        "Meng Han"
      ],
      "abstract": "Underwater 3D scene reconstruction faces severe challenges from light absorption, scattering, and turbidity, which degrade geometry and color fidelity in traditional methods like Neural Radiance Fields (NeRF). While NeRF extensions such as SeaThru-NeRF incorporate physics-based models, their MLP reliance limits efficiency and spatial resolution in hazy environments. We introduce UW-3DGS, a novel framework adapting 3D Gaussian Splatting (3DGS) for robust underwater reconstruction. Key innovations include: (1) a plug-and-play learnable underwater image formation module using voxel-based regression for spatially varying attenuation and backscatter; and (2) a Physics-Aware Uncertainty Pruning (PAUP) branch that adaptively removes noisy floating Gaussians via uncertainty scoring, ensuring artifact-free geometry. The pipeline operates in training and rendering stages. During training, noisy Gaussians are optimized end-to-end with underwater parameters, guided by PAUP pruning and scattering modeling. In rendering, refined Gaussians produce clean Unattenuated Radiance Images (URIs) free from media effects, while learned physics enable realistic Underwater Images (UWIs) with accurate light transport. Experiments on SeaThru-NeRF and UWBundle datasets show superior performance, achieving PSNR of 27.604, SSIM of 0.868, and LPIPS of 0.104 on SeaThru-NeRF, with ~65% reduction in floating artifacts.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†UW-3DGSæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³æ°´ä¸‹3Dåœºæ™¯é‡å»ºä¸­ç”±äºå…‰çº¿å¸æ”¶ã€æ•£å°„å’Œæµ‘æµŠåº¦å¯¼è‡´çš„å‡ ä½•ä¸è‰²å½©ä¿çœŸåº¦ä¸‹é™é—®é¢˜ã€‚è¯¥æ¡†æ¶å°†3D Gaussian Splatting (3DGS) å¼•å…¥æ°´ä¸‹ç¯å¢ƒï¼Œå…‹æœäº†ä¼ ç»ŸNeural Radiance Fields (NeRF) æ–¹æ³•åœ¨å¤„ç†æœ¦èƒ§ç¯å¢ƒæ—¶çš„æ•ˆç‡å’Œç©ºé—´åˆ†è¾¨ç‡å±€é™ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ä¸€ä¸ªåˆ©ç”¨ä½“ç´ å›å½’(voxel-based regression)æ¨¡æ‹Ÿç©ºé—´å˜åŒ–è¡°å‡å’Œåå‘æ•£å°„çš„å¯å­¦ä¹ æ°´ä¸‹å›¾åƒå½¢æˆæ¨¡å—ï¼Œä»¥åŠä¸€ç§é€šè¿‡ä¸ç¡®å®šæ€§è¯„åˆ†è‡ªé€‚åº”ç§»é™¤å™ªå£°æµ®åŠ¨ç‚¹çš„ç‰©ç†æ„ŸçŸ¥ä¸ç¡®å®šæ€§å‰ªæ(Physics-Aware Uncertainty Pruning, PAUP)æŠ€æœ¯ã€‚åœ¨æ¸²æŸ“è¿‡ç¨‹ä¸­ï¼Œä¼˜åŒ–åçš„é«˜æ–¯ç‚¹èƒ½å¤Ÿç”Ÿæˆæ¶ˆé™¤ä»‹è´¨å¹²æ‰°çš„æ¸…æ™°è¾å°„å›¾åƒ(Unattenuated Radiance Images, URIs)ï¼Œå¹¶åˆ©ç”¨å­¦ä¹ åˆ°çš„ç‰©ç†å‚æ•°å®ç°çœŸå®çš„æ°´ä¸‹å…‰ä¼ è¾“æ¨¡æ‹Ÿã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒUW-3DGSåœ¨SeaThru-NeRFç­‰æ•°æ®é›†ä¸Šçš„PSNRè¾¾åˆ°27.604ï¼Œä¸”æµ®åŠ¨ä¼ªå½±å‡å°‘äº†çº¦65%ï¼Œæ˜¾è‘—æå‡äº†æ°´ä¸‹é‡å»ºçš„ç²¾åº¦ä¸è§†è§‰è´¨é‡ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06169v1",
      "published_date": "2025-08-08 09:36:32 UTC",
      "updated_date": "2025-08-08 09:36:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:15:58.991820+00:00"
    },
    {
      "arxiv_id": "2508.06165v3",
      "title": "UR$^2$: Unify RAG and Reasoning through Reinforcement Learning",
      "title_zh": "UR$^2$ï¼šé€šè¿‡å¼ºåŒ–å­¦ä¹ ç»Ÿä¸€ RAG ä¸æ¨ç†",
      "authors": [
        "Weitao Li",
        "Boran Xiang",
        "Xiaolong Wang",
        "Zhinan Gou",
        "Weizhi Ma",
        "Yang Liu"
      ],
      "abstract": "Large Language Models (LLMs) have shown remarkable capabilities through two complementary paradigms: Retrieval-Augmented Generation (RAG), which enhances knowledge grounding, and Reinforcement Learning from Verifiable Rewards (RLVR), which optimizes complex reasoning abilities. However, these two capabilities are often developed in isolation, and existing efforts to unify them remain narrow in scope -- typically limited to open-domain QA with fixed retrieval settings and task-specific constraints. This lack of integration constrains generalization and limits the applicability of RAG-RL methods to broader domains. To bridge this gap, we propose UR2 (Unified RAG and Reasoning), a general framework that unifies retrieval and reasoning through reinforcement learning. UR2 introduces two key contributions: a difficulty-aware curriculum training that selectively invokes retrieval only for challenging problems, and a hybrid knowledge access strategy combining domain-specific offline corpora with LLM-generated summaries. These components are designed to enable dynamic coordination between retrieval and reasoning, improving adaptability across a diverse range of tasks. Experiments across open-domain QA, MMLU-Pro, medical, and mathematical reasoning tasks demonstrate that UR$^2$ (built on Qwen-2.5-3/7B and LLaMA-3.1-8B) significantly outperforms existing RAG and RL methods, achieving comparable performance to GPT-4o-mini and GPT-4.1-mini on several benchmarks. We have released all code, models, and data at https://github.com/Tsinghua-dhy/UR2.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† UR$^2$ (Unified RAG and Reasoning)ï¼Œè¿™æ˜¯ä¸€ä¸ªé€šè¿‡å¼ºåŒ–å­¦ä¹  (Reinforcement Learning) å°†æ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG) ä¸å¤æ‚æ¨ç†èƒ½åŠ›ç»Ÿä¸€èµ·æ¥çš„é€šç”¨æ¡†æ¶ã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•ä¸­ RAG ä¸æ¨ç†èƒ½åŠ›å¾€å¾€å­¤ç«‹å¼€å‘ä¸”æ³›åŒ–æ€§å—é™çš„é—®é¢˜ï¼ŒUR$^2$ å®ç°äº†æ£€ç´¢ä¸æ¨ç†ä¹‹é—´çš„åŠ¨æ€åè°ƒã€‚è¯¥æ¡†æ¶å¼•å…¥äº†éš¾åº¦æ„ŸçŸ¥è¯¾ç¨‹åŸ¹è®­ (difficulty-aware curriculum training) ä»¥å®ç°ä»…åœ¨é¢å¯¹æŒ‘æˆ˜æ€§é—®é¢˜æ—¶é€‰æ‹©æ€§è°ƒç”¨æ£€ç´¢ï¼Œå¹¶é‡‡ç”¨äº†ç»“åˆé¢†åŸŸç¦»çº¿è¯­æ–™åº“ä¸ LLM ç”Ÿæˆæ‘˜è¦çš„æ··åˆçŸ¥è¯†è®¿é—®ç­–ç•¥ (hybrid knowledge access strategy)ã€‚åœ¨å¼€æ”¾åŸŸé—®ç­”ã€MMLU-Proã€åŒ»å­¦åŠæ•°å­¦æ¨ç†ç­‰å¤šç§ä»»åŠ¡çš„å®éªŒä¸­ï¼ŒUR$^2$ æ˜¾è‘—è¶…è¶Šäº†ç°æœ‰çš„ RAG å’Œ RL åŸºå‡†æ–¹æ³•ã€‚åŸºäº Qwen-2.5 å’Œ LLaMA-3.1 æ„å»ºçš„æ¨¡å‹åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºä¸ GPT-4o-mini ç›¸å½“çš„æ€§èƒ½ï¼Œè¯æ˜äº†å…¶åœ¨å¹¿æ³›é¢†åŸŸä¸­çš„å“è¶Šé€‚åº”èƒ½åŠ›ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06165v3",
      "published_date": "2025-08-08 09:33:20 UTC",
      "updated_date": "2025-09-21 14:32:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:16:05.087808+00:00"
    },
    {
      "arxiv_id": "2508.06163v1",
      "title": "One Size Does Not Fit All: A Distribution-Aware Sparsification for More Precise Model Merging",
      "title_zh": "æ‹’ç»â€œä¸€åˆ€åˆ‡â€ï¼šç”¨äºæ›´ç²¾å‡†æ¨¡å‹åˆå¹¶çš„åˆ†å¸ƒæ„ŸçŸ¥ç¨€ç–åŒ–æ–¹æ³•",
      "authors": [
        "Yingfeng Luo",
        "Dingyang Lin",
        "Junxin Wang",
        "Ziqiang Xu",
        "Kaiyan Chang",
        "Tong Zheng",
        "Bei Li",
        "Anxiang Ma",
        "Tong Xiao",
        "Zhengtao Yu",
        "Jingbo Zhu"
      ],
      "abstract": "Model merging has emerged as a compelling data-free paradigm for multi-task learning, enabling the fusion of multiple fine-tuned models into a single, powerful entity. A key technique in merging methods is sparsification, which prunes redundant parameters from task vectors to mitigate interference. However, prevailing approaches employ a ``one-size-fits-all'' strategy, applying a uniform sparsity ratio that overlooks the inherent structural and statistical heterogeneity of model parameters. This often leads to a suboptimal trade-off, where critical parameters are inadvertently pruned while less useful ones are retained. To address this limitation, we introduce \\textbf{TADrop} (\\textbf{T}ensor-wise \\textbf{A}daptive \\textbf{Drop}), an adaptive sparsification strategy that respects this heterogeneity. Instead of a global ratio, TADrop assigns a tailored sparsity level to each parameter tensor based on its distributional properties. The core intuition is that tensors with denser, more redundant distributions can be pruned aggressively, while sparser, more critical ones are preserved. As a simple and plug-and-play module, we validate TADrop by integrating it with foundational, classic, and SOTA merging methods. Extensive experiments across diverse tasks (vision, language, and multimodal) and models (ViT, BEiT) demonstrate that TADrop consistently and significantly boosts their performance. For instance, when enhancing a leading merging method, it achieves an average performance gain of 2.0\\% across 8 ViT-B/32 tasks. TADrop provides a more effective way to mitigate parameter interference by tailoring sparsification to the model's structure, offering a new baseline for high-performance model merging.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ¨¡å‹åˆå¹¶(Model merging)ä¸­ç°æœ‰ç¨€ç–åŒ–ç­–ç•¥é‡‡ç”¨ç»Ÿä¸€ç¨€ç–æ¯”ä¾‹è€Œå¿½è§†å‚æ•°ç»“æ„ä¸ç»Ÿè®¡å¼‚è´¨æ€§çš„é—®é¢˜ï¼ŒæŒ‡å‡ºè¿™ç§â€œä¸€åˆ€åˆ‡â€çš„æ–¹æ³•ä¼šå¯¼è‡´å…³é”®å‚æ•°è¢«è¯¯åˆ æˆ–ä¿ç•™å†—ä½™å‚æ•°ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†TADrop (Tensor-wise Adaptive Drop)ï¼Œè¿™æ˜¯ä¸€ç§æ ¹æ®å¼ é‡åˆ†å¸ƒç‰¹æ€§åŠ¨æ€åˆ†é…ç¨€ç–æ°´å¹³çš„è‡ªé€‚åº”ç­–ç•¥ã€‚è¯¥æ–¹æ³•çš„æ ¸å¿ƒé€»è¾‘æ˜¯ä¸ºæ¯ä¸ªå‚æ•°å¼ é‡å®šåˆ¶ç¨€ç–ç‡ï¼Œå¯¹å†—ä½™åº¦é«˜çš„å¯†é›†åˆ†å¸ƒè¿›è¡Œå¼ºåº¦è¾ƒå¤§çš„å‰ªæï¼Œè€Œä¿ç•™ç¨€ç–ä¸”å…³é”®çš„å‚æ•°ã€‚ä½œä¸ºä¸€ç§å³æ’å³ç”¨çš„æ¨¡å—ï¼ŒTADrop è¢«é›†æˆåˆ°åŸºç¡€ã€ç»å…¸åŠ SOTA åˆå¹¶æ–¹æ³•ä¸­ï¼Œå¹¶åœ¨è§†è§‰ã€è¯­è¨€å’Œå¤šæ¨¡æ€ä»»åŠ¡ï¼ˆå¦‚ ViT å’Œ BEiT æ¨¡å‹ï¼‰ä¸Šè¿›è¡Œäº†éªŒè¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒTADrop èƒ½å¤Ÿæ˜¾è‘—ä¸”ä¸€è‡´åœ°æå‡åˆå¹¶æ€§èƒ½ï¼Œä¾‹å¦‚åœ¨ 8 ä¸ª ViT-B/32 ä»»åŠ¡ä¸Šä½¿é¢†å…ˆæ–¹æ³•çš„å¹³å‡è¡¨ç°æé«˜äº† 2.0%ã€‚è¯¥ç ”ç©¶é€šè¿‡ä¼˜åŒ–å‚æ•°ç¨€ç–åŒ–è¿‡ç¨‹æœ‰æ•ˆç¼“è§£äº†ä»»åŠ¡é—´çš„å‚æ•°å¹²æ‰°ï¼Œä¸ºå®ç°é«˜æ€§èƒ½çš„æ¨¡å‹åˆå¹¶æä¾›äº†æ–°çš„æŠ€æœ¯è·¯å¾„ä¸åŸºå‡†ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Under review",
      "pdf_url": "https://arxiv.org/pdf/2508.06163v1",
      "published_date": "2025-08-08 09:33:08 UTC",
      "updated_date": "2025-08-08 09:33:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:16:18.586580+00:00"
    },
    {
      "arxiv_id": "2508.06154v1",
      "title": "Semantic Item Graph Enhancement for Multimodal Recommendation",
      "title_zh": "é¢å‘å¤šæ¨¡æ€æ¨èçš„è¯­ä¹‰é¡¹ç›®å›¾å¢å¼º",
      "authors": [
        "Xiaoxiong Zhang",
        "Xin Zhou",
        "Zhiwei Zeng",
        "Dusit Niyato",
        "Zhiqi Shen"
      ],
      "abstract": "Multimodal recommendation systems have attracted increasing attention for their improved performance by leveraging items' multimodal information. Prior methods often build modality-specific item-item semantic graphs from raw modality features and use them as supplementary structures alongside the user-item interaction graph to enhance user preference learning. However, these semantic graphs suffer from semantic deficiencies, including (1) insufficient modeling of collaborative signals among items and (2) structural distortions introduced by noise in raw modality features, ultimately compromising performance. To address these issues, we first extract collaborative signals from the interaction graph and infuse them into each modality-specific item semantic graph to enhance semantic modeling. Then, we design a modulus-based personalized embedding perturbation mechanism that injects perturbations with modulus-guided personalized intensity into embeddings to generate contrastive views. This enables the model to learn noise-robust representations through contrastive learning, thereby reducing the effect of structural noise in semantic graphs. Besides, we propose a dual representation alignment mechanism that first aligns multiple semantic representations via a designed Anchor-based InfoNCE loss using behavior representations as anchors, and then aligns behavior representations with the fused semantics by standard InfoNCE, to ensure representation consistency. Extensive experiments on four benchmark datasets validate the effectiveness of our framework.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šæ¨¡æ€æ¨èç³»ç»Ÿ(Multimodal Recommendation Systems)ä¸­è¯­ä¹‰å›¾å­˜åœ¨çš„åä½œä¿¡å·å»ºæ¨¡ä¸è¶³ä»¥åŠåŸå§‹æ¨¡æ€ç‰¹å¾å™ªå£°å¯¼è‡´çš„ç»“æ„æ‰­æ›²é—®é¢˜ï¼Œæå‡ºäº†è¯­ä¹‰ç‰©å“å›¾å¢å¼ºæ¡†æ¶ã€‚è¯¥æ–¹æ¡ˆé¦–å…ˆä»äº¤äº’å›¾ä¸­æå–åä½œä¿¡å·å¹¶å°†å…¶æ³¨å…¥å„æ¨¡æ€ç‰¹å®šçš„ç‰©å“è¯­ä¹‰å›¾ä¸­ï¼Œä»è€Œæ˜¾è‘—å¼ºåŒ–äº†è¯­ä¹‰å»ºæ¨¡èƒ½åŠ›ã€‚éšåï¼Œç ”ç©¶è®¾è®¡äº†åŸºäºæ¨¡é•¿çš„ä¸ªæ€§åŒ–åµŒå…¥æ‰°åŠ¨æœºåˆ¶(Modulus-based Personalized Embedding Perturbation)ï¼Œé€šè¿‡å¯¹æ¯”å­¦ä¹ ç”Ÿæˆçš„å¯¹æ¯”è§†å›¾æ¥å¢å¼ºæ¨¡å‹å¯¹ç»“æ„å™ªå£°çš„é²æ£’æ€§ã€‚æ­¤å¤–ï¼Œæ¡†æ¶å¼•å…¥äº†åŒé‡è¡¨ç¤ºå¯¹é½æœºåˆ¶ï¼Œåˆ©ç”¨åŸºäºé”šç‚¹çš„ InfoNCE æŸå¤±å‡½æ•°ç¡®ä¿å¤šæ¨¡æ€è¯­ä¹‰ä¸è¡Œä¸ºè¡¨ç¤ºä¹‹é—´çš„ä¸€è‡´æ€§ã€‚åœ¨å››ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¯æ˜ï¼Œè¯¥æ¡†æ¶èƒ½æœ‰æ•ˆè§£å†³è¯­ä¹‰ç¼ºé™·å¹¶æå‡æ¨èç³»ç»Ÿçš„æ•´ä½“æ€§èƒ½ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06154v1",
      "published_date": "2025-08-08 09:20:50 UTC",
      "updated_date": "2025-08-08 09:20:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:16:42.796537+00:00"
    },
    {
      "arxiv_id": "2508.11674v1",
      "title": "Learning Internal Biological Neuron Parameters and Complexity-Based Encoding for Improved Spiking Neural Networks Performance",
      "title_zh": "å­¦ä¹ å†…éƒ¨ç”Ÿç‰©ç¥ç»å…ƒå‚æ•°ä¸åŸºäºå¤æ‚åº¦çš„ç¼–ç ä»¥æå‡è„‰å†²ç¥ç»ç½‘ç»œæ€§èƒ½",
      "authors": [
        "Zofia Rudnicka",
        "Janusz Szczepanski",
        "Agnieszka Pregowska"
      ],
      "abstract": "This study introduces a novel approach by replacing the traditional perceptron neuron model with a biologically inspired probabilistic meta neuron, where the internal neuron parameters are jointly learned, leading to improved classification accuracy of spiking neural networks (SNNs). To validate this innovation, we implement and compare two SNN architectures: one based on standard leaky integrate-and-fire (LIF) neurons and another utilizing the proposed probabilistic meta neuron model. As a second key contribution, we present a new biologically inspired classification framework that uniquely integrates SNNs with Lempel-Ziv complexity (LZC) a measure closely related to entropy rate. By combining the temporal precision and biological plausibility of SNNs with the capacity of LZC to capture structural regularity, the proposed approach enables efficient and interpretable classification of spatiotemporal neural data, an aspect not addressed in existing works. We consider learning algorithms such as backpropagation, spike-timing-dependent plasticity (STDP), and the Tempotron learning rule. To explore neural dynamics, we use Poisson processes to model neuronal spike trains, a well-established method for simulating the stochastic firing behavior of biological neurons. Our results reveal that depending on the training method, the classifier's efficiency can improve by up to 11.00%, highlighting the advantage of learning additional neuron parameters beyond the traditional focus on weighted inputs alone.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ–¹æ³•ï¼Œé€šè¿‡å°†ä¼ ç»Ÿçš„æ„ŸçŸ¥å™¨ç¥ç»å…ƒæ¨¡å‹æ›¿æ¢ä¸ºç”Ÿç‰©å¯å‘å¼çš„æ¦‚ç‡å…ƒç¥ç»å…ƒ (probabilistic meta neuron)ï¼Œå¹¶å…±åŒå­¦ä¹ ç¥ç»å…ƒå†…éƒ¨å‚æ•°ï¼Œä»è€Œæ˜¾è‘—æå‡äº†è„‰å†²ç¥ç»ç½‘ç»œ (SNNs) çš„åˆ†ç±»å‡†ç¡®ç‡ã€‚ä¸ºäº†éªŒè¯è¿™ä¸€åˆ›æ–°ï¼Œç ”ç©¶å¯¹æ¯”äº†åŸºäºæ ‡å‡†æ¼ç§¯åˆ†é‡Šæ”¾ (LIF) ç¥ç»å…ƒä¸æ‰€æå…ƒç¥ç»å…ƒæ¨¡å‹çš„ä¸¤ç§ SNN æ¶æ„ã€‚å¦ä¸€é¡¹æ ¸å¿ƒè´¡çŒ®æ˜¯æå‡ºäº†ä¸€ä¸ªç»“åˆ SNNs ä¸ Lempel-Ziv å¤æ‚åº¦ (LZC) çš„ç”Ÿç‰©å¯å‘å¼åˆ†ç±»æ¡†æ¶ï¼Œåˆ©ç”¨ LZC æ•æ‰ç»“æ„è§„å¾‹æ€§çš„èƒ½åŠ›æ¥å®ç°å¯¹æ—¶ç©ºç¥ç»æ•°æ®çš„é«˜æ•ˆä¸”å¯è§£é‡Šçš„åˆ†ç±»ã€‚ç ”ç©¶è¿‡ç¨‹ä¸­é‡‡ç”¨äº†è¯¯å·®åå‘ä¼ æ’­ (backpropagation)ã€è„‰å†²æ—¶é—´ä¾èµ–å¯å¡‘æ€§ (STDP) å’Œ Tempotron å­¦ä¹ è§„åˆ™ï¼Œå¹¶åˆ©ç”¨æ³Šæ¾è¿‡ç¨‹ (Poisson processes) æ¨¡æ‹Ÿç”Ÿç‰©ç¥ç»å…ƒçš„éšæœºæ”¾ç”µè¡Œä¸ºã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œé€šè¿‡å­¦ä¹ æƒé‡ä¹‹å¤–çš„ç¥ç»å…ƒå†…éƒ¨å‚æ•°ï¼Œåˆ†ç±»å™¨çš„æ•ˆç‡æœ€é«˜å¯æå‡ 11.00%ï¼Œè¯æ˜äº†è¯¥æ–¹æ³•åœ¨å¤„ç†å¤æ‚ç¥ç»åŠ¨åŠ›å­¦ä»»åŠ¡ä¸­çš„æ˜¾è‘—ä¼˜åŠ¿ã€‚",
      "categories": [
        "cs.NE",
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.11674v1",
      "published_date": "2025-08-08 09:14:49 UTC",
      "updated_date": "2025-08-08 09:14:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:16:15.784153+00:00"
    },
    {
      "arxiv_id": "2508.06145v1",
      "title": "Retrieval Augmented Large Language Model System for Comprehensive Drug Contraindications",
      "title_zh": "é¢å‘å…¨é¢è¯ç‰©ç¦å¿Œç—‡çš„æ£€ç´¢å¢å¼ºå¤§è¯­è¨€æ¨¡å‹ç³»ç»Ÿ",
      "authors": [
        "Byeonghun Bang",
        "Jongsuk Yoon",
        "Dong-Jin Chang",
        "Seho Park",
        "Yong Oh Lee"
      ],
      "abstract": "The versatility of large language models (LLMs) has been explored across various sectors, but their application in healthcare poses challenges, particularly in the domain of pharmaceutical contraindications where accurate and reliable information is required. This study enhances the capability of LLMs to address contraindications effectively by implementing a Retrieval Augmented Generation (RAG) pipeline. Utilizing OpenAI's GPT-4o-mini as the base model, and the text-embedding-3-small model for embeddings, our approach integrates Langchain to orchestrate a hybrid retrieval system with re-ranking. This system leverages Drug Utilization Review (DUR) data from public databases, focusing on contraindications for specific age groups, pregnancy, and concomitant drug use. The dataset includes 300 question-answer pairs across three categories, with baseline model accuracy ranging from 0.49 to 0.57. Post-integration of the RAG pipeline, we observed a significant improvement in model accuracy, achieving rates of 0.94, 0.87, and 0.89 for contraindications related to age groups, pregnancy, and concomitant drug use, respectively. The results indicate that augmenting LLMs with a RAG framework can substantially reduce uncertainty in prescription and drug intake decisions by providing more precise and reliable drug contraindication information.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŒ»ç–—ä¿å¥é¢†åŸŸä¸­è¯ç‰©ç¦å¿Œç—‡(contraindications)ä¿¡æ¯çš„å‡†ç¡®æ€§æŒ‘æˆ˜ï¼Œå¼€å‘äº†ä¸€ç§å¢å¼ºå‹çš„å¤§è¯­è¨€æ¨¡å‹(LLMs)ç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿé‡‡ç”¨äº†æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)æµæ°´çº¿ï¼Œä»¥OpenAIçš„GPT-4o-miniä¸ºåŸºç¡€æ¨¡å‹ï¼Œå¹¶åˆ©ç”¨text-embedding-3-smallæ¨¡å‹è¿›è¡ŒåµŒå…¥ã€‚é€šè¿‡é›†æˆLangchainæ¡†æ¶ï¼Œç³»ç»Ÿæ„å»ºäº†ä¸€ä¸ªå…·å¤‡é‡æ’åº(re-ranking)åŠŸèƒ½çš„æ··åˆæ£€ç´¢ç³»ç»Ÿï¼Œä¸“é—¨å¤„ç†æ¥è‡ªå…¬å…±æ•°æ®åº“çš„è¯ç‰©åˆ©ç”¨å®¡æŸ¥(DUR)æ•°æ®ã€‚ç ”ç©¶é‡ç‚¹åˆ†æäº†ç‰¹å®šå¹´é¾„ç»„ã€å¦Šå¨ æœŸä»¥åŠåˆå¹¶ç”¨è¯(concomitant drug use)ç›¸å…³çš„ç¦å¿Œç—‡ï¼Œå¹¶ä½¿ç”¨300ä¸ªé—®ç­”å¯¹è¿›è¡Œäº†éªŒè¯ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨é›†æˆRAGæµç¨‹åï¼Œæ¨¡å‹åœ¨ä¸Šè¿°ä¸‰ä¸ªç±»åˆ«çš„å‡†ç¡®ç‡åˆ†åˆ«ä»åŸºçº¿çš„0.49-0.57æ˜¾è‘—æå‡è‡³0.94ã€0.87å’Œ0.89ã€‚è¿™ä¸€ç ”ç©¶è¯æ˜äº†åˆ©ç”¨RAGæ¡†æ¶å¢å¼ºLLMsèƒ½å¤Ÿä¸ºå¤„æ–¹å’Œç”¨è¯å†³ç­–æä¾›æ›´ç²¾ç¡®å¯é çš„æ”¯æŒï¼Œæœ‰æ•ˆé™ä½åŒ»ç–—é£é™©ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06145v1",
      "published_date": "2025-08-08 09:09:03 UTC",
      "updated_date": "2025-08-08 09:09:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:16:16.959779+00:00"
    },
    {
      "arxiv_id": "2508.06136v2",
      "title": "Roll Your Eyes: Gaze Redirection via Explicit 3D Eyeball Rotation",
      "title_zh": "Roll Your Eyesï¼šåŸºäºæ˜¾å¼ä¸‰ç»´çœ¼çƒæ—‹è½¬çš„è§†çº¿é‡å®šå‘",
      "authors": [
        "YoungChan Choi",
        "HengFei Wang",
        "YiHua Cheng",
        "Boeun Kim",
        "Hyung Jin Chang",
        "YoungGeun Choi",
        "Sang-Il Choi"
      ],
      "abstract": "We propose a novel 3D gaze redirection framework that leverages an explicit 3D eyeball structure. Existing gaze redirection methods are typically based on neural radiance fields, which employ implicit neural representations via volume rendering. Unlike these NeRF-based approaches, where the rotation and translation of 3D representations are not explicitly modeled, we introduce a dedicated 3D eyeball structure to represent the eyeballs with 3D Gaussian Splatting (3DGS). Our method generates photorealistic images that faithfully reproduce the desired gaze direction by explicitly rotating and translating the 3D eyeball structure. In addition, we propose an adaptive deformation module that enables the replication of subtle muscle movements around the eyes. Through experiments conducted on the ETH-XGaze dataset, we demonstrate that our framework is capable of generating diverse novel gaze images, achieving superior image quality and gaze estimation accuracy compared to previous state-of-the-art methods.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åˆ©ç”¨æ˜¾å¼ 3D çœ¼çƒç»“æ„çš„è§†çº¿é‡å®šå‘ (Gaze Redirection) æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰åŸºäºç¥ç»ç½‘ç»œè¾å°„åœº (NeRF) çš„éšå¼è¡¨ç¤ºæ–¹æ³•åœ¨æ—‹è½¬å’Œä½ç§»å»ºæ¨¡ä¸Šçš„ä¸è¶³ã€‚è¯¥æ–¹æ³•åˆ©ç”¨ 3D é«˜æ–¯æ³¼æº… (3D Gaussian Splatting, 3DGS) æ„å»ºä¸“é—¨çš„ 3D çœ¼çƒç»“æ„ï¼Œå¹¶é€šè¿‡æ˜¾å¼çš„æ—‹è½¬å’Œä½ç§»æ“ä½œç”Ÿæˆå…·æœ‰ç²¾ç¡®è§†çº¿æ–¹å‘çš„é«˜ä¿çœŸå›¾åƒã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å¼•å…¥äº†ä¸€ä¸ªè‡ªé€‚åº”å˜å½¢æ¨¡å— (Adaptive Deformation Module)ï¼Œç”¨äºæ¨¡æ‹Ÿçœ¼å‘¨ç»†å¾®çš„è‚Œè‚‰è¿åŠ¨ã€‚åœ¨ ETH-XGaze æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨å›¾åƒç”Ÿæˆè´¨é‡å’Œè§†çº¿ä¼°è®¡å‡†ç¡®åº¦æ–¹é¢å‡ä¼˜äºç°æœ‰çš„å…ˆè¿›æ–¹æ³•ï¼Œèƒ½å¤Ÿç”Ÿæˆå¤šæ ·ä¸”çœŸå®çš„è§†çº¿å›¾åƒã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages, 5 figures, ACM Multimeida 2025 accepted",
      "pdf_url": "https://arxiv.org/pdf/2508.06136v2",
      "published_date": "2025-08-08 08:56:51 UTC",
      "updated_date": "2025-09-18 03:50:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:16:39.889276+00:00"
    },
    {
      "arxiv_id": "2508.06135v1",
      "title": "Less is More: Selective Reflection for Compatible and Efficient Knowledge Distillation in Large Language Models",
      "title_zh": "å°‘å³æ˜¯å¤šï¼šå¤§è¯­è¨€æ¨¡å‹ä¸­é¢å‘å…¼å®¹ä¸é«˜æ•ˆçŸ¥è¯†è’¸é¦çš„é€‰æ‹©æ€§åæ€",
      "authors": [
        "Lingyuan Liu",
        "Mengxiang Zhang"
      ],
      "abstract": "Knowledge Distillation (KD) is a fundamental technique for compressing large language models (LLMs) into compact, efficient student models. However, existing white-box KD methods mainly focus on balancing ground truth and student-generated responses while overlooking two critical factors: training data quality and student-model compatibility. To address these limitations, we propose Selective Reflection Distillation (SRD), a novel data curation framework that leverages reflections from student models to systematically refine training data. SRD dynamically evaluates and selects prompt-response pairs by comparing ground truth data with student model outputs, selectively curating high-quality, student-compatible training instances through automated ranking based on difficulty. Furthermore, after selecting the training data, a curriculum scheduling strategy is employed to incrementally introduce these curated subsets into the distillation process at fixed intervals. As a plug-and-play enhancement, SRD consistently improves distillation outcomes across diverse white-box KD approaches and model architectures, as well as decreases computational cost significantly during KD training. Experiments on a range of language model benchmarks demonstrate SRD's consistent improvements in distilled model performance, as well as a reduction in training runtime by up to 39%, under diverse KD methods and model families. Notably, SRD operates as a plug-and-play module, enhancing sample efficiency without modifying underlying KD algorithms. Our findings highlight that data quality and compatibility are pivotal to effective and efficient distillation of LLMs, and SRD provides a principled framework to achieve both. This work advances the understanding of data-centric factors in KD and offers practical insights for enhancing the capability and efficiency of compressed LLMs.",
      "tldr_zh": "çŸ¥è¯†è’¸é¦(Knowledge Distillation)æ˜¯å°†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)å‹ç¼©ä¸ºé«˜æ•ˆå­¦ç”Ÿæ¨¡å‹çš„å…³é”®æŠ€æœ¯ï¼Œä½†ç°æœ‰ç™½ç›’è’¸é¦æ–¹æ³•å¾€å¾€å¿½ç•¥äº†è®­ç»ƒæ•°æ®è´¨é‡å’Œå­¦ç”Ÿæ¨¡å‹å…¼å®¹æ€§(student-model compatibility)ã€‚è¯¥ç ”ç©¶æå‡ºäº†Selective Reflection Distillation (SRD)ï¼Œè¿™æ˜¯ä¸€ç§åˆ©ç”¨å­¦ç”Ÿæ¨¡å‹çš„åé¦ˆ(reflections)æ¥ç³»ç»Ÿä¼˜åŒ–è®­ç»ƒæ•°æ®çš„æ–°å‹æ•°æ®ç­›é€‰æ¡†æ¶ã€‚SRDé€šè¿‡å¯¹æ¯”Ground Truthä¸å­¦ç”Ÿæ¨¡å‹è¾“å‡ºæ¥åŠ¨æ€è¯„ä¼°å¹¶è‡ªåŠ¨æ’åºPrompt-Responseå¯¹ï¼Œä»è€Œç­›é€‰å‡ºé«˜è´¨é‡ä¸”å…¼å®¹æ€§å¼ºçš„è®­ç»ƒå®ä¾‹ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•é‡‡ç”¨è¯¾ç¨‹è°ƒåº¦ç­–ç•¥(curriculum scheduling strategy)å°†ç²¾é€‰å­é›†é€æ­¥å¼•å…¥è’¸é¦è¿‡ç¨‹ï¼Œæ˜¾è‘—æå‡äº†æ ·æœ¬æ•ˆç‡ã€‚ä½œä¸ºä¸€ç§å³æ’å³ç”¨çš„å¢å¼ºæ¨¡å—ï¼ŒSRDåœ¨ä¸åŒæ¨¡å‹æ¶æ„å’ŒKDæ–¹æ³•ä¸Šå‡å®ç°äº†æ€§èƒ½çš„æŒç»­æå‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSRDåœ¨å¢å¼ºæ¨¡å‹èƒ½åŠ›çš„åŒæ—¶ï¼Œèƒ½å°†è®­ç»ƒè¿è¡Œæ—¶é—´ç¼©çŸ­é«˜è¾¾39%ã€‚è¯¥å·¥ä½œå¼ºè°ƒäº†æ•°æ®è´¨é‡å’Œå…¼å®¹æ€§åœ¨LLMsè’¸é¦ä¸­çš„æ ¸å¿ƒåœ°ä½ï¼Œä¸ºå¼€å‘é«˜æ•ˆã€é«˜æ€§èƒ½çš„å‹ç¼©æ¨¡å‹æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06135v1",
      "published_date": "2025-08-08 08:55:53 UTC",
      "updated_date": "2025-08-08 08:55:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:16:46.903849+00:00"
    },
    {
      "arxiv_id": "2508.06133v2",
      "title": "LLM Serving Optimization with Variable Prefill and Decode Lengths",
      "title_zh": "é’ˆå¯¹å¯å˜é¢„å¡«å……ä¸è§£ç é•¿åº¦çš„ LLM æœåŠ¡ä¼˜åŒ–",
      "authors": [
        "Meixuan Wang",
        "Yinyu Ye",
        "Zijie Zhou"
      ],
      "abstract": "We study the problem of serving LLM (Large Language Model) requests where each request has heterogeneous prefill and decode lengths. In LLM serving, the prefill length corresponds to the input prompt length, which determines the initial memory usage in the KV cache. The decode length refers to the number of output tokens generated sequentially, with each additional token increasing the KV cache memory usage by one unit. Given a set of n requests, our goal is to schedule and process them to minimize the total completion time. We show that this problem is NP-hard due to the interplay of batching, placement constraints, precedence relationships, and linearly increasing memory usage. We then analyze commonly used scheduling strategies in practice, such as First-Come-First-Serve (FCFS) and Shortest-First (SF), and prove that their competitive ratios scale up sublinearly with the memory limit-a significant drawback in real-world settings where memory demand is large. To address this, we propose a novel algorithm based on a new selection metric that efficiently forms batches over time. We prove that this algorithm achieves a constant competitive ratio. Finally, we develop and evaluate a few algorithm variants inspired by this approach, including dynamic programming variants, local search methods, and an LP-based scheduler, demonstrating through comprehensive simulations that they outperform standard baselines while maintaining computational efficiency.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å…·æœ‰å¼‚æ„ prefill å’Œ decode é•¿åº¦çš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¨ç†æœåŠ¡ä¼˜åŒ–é—®é¢˜ï¼Œæ—¨åœ¨é€šè¿‡åˆç†çš„è°ƒåº¦æœ€å°åŒ–æ‰€æœ‰è¯·æ±‚çš„æ€»å®Œæˆæ—¶é—´ã€‚ä½œè€…æŒ‡å‡ºï¼Œç”±äº batchingã€ä½ç½®çº¦æŸä»¥åŠéšç”Ÿæˆçš„ token çº¿æ€§å¢é•¿çš„ KV cache å†…å­˜å ç”¨ï¼Œè¯¥è°ƒåº¦é—®é¢˜è¢«è¯æ˜æ˜¯ NP-hard çš„ã€‚åˆ†æè¡¨æ˜ï¼Œå¸¸ç”¨çš„ First-Come-First-Serve (FCFS) å’Œ Shortest-First (SF) ç­–ç•¥åœ¨å†…å­˜éœ€æ±‚è¾ƒå¤§çš„å®é™…åœºæ™¯ä¸­è¡¨ç°ä¸ä½³ï¼Œå…¶ç«äº‰æ¯”ï¼ˆcompetitive ratioï¼‰éšå†…å­˜é™åˆ¶å‘ˆæ¬¡çº¿æ€§å¢é•¿ã€‚ä¸ºè§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºæ–°é€‰æ‹©æŒ‡æ ‡çš„è°ƒåº¦ç®—æ³•ï¼Œå¹¶è¯æ˜å…¶èƒ½å¤Ÿå®ç°å¸¸æ•°çº§çš„ç«äº‰æ¯”ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å¼€å‘äº†åŒ…æ‹¬åŠ¨æ€è§„åˆ’ã€å±€éƒ¨æœç´¢å’ŒåŸºäºçº¿æ€§è§„åˆ’ï¼ˆLPï¼‰çš„å¤šç§ç®—æ³•å˜ä½“ã€‚ä»¿çœŸå®éªŒè¯æ˜ï¼Œè¿™äº›æ–¹æ³•åœ¨ä¿æŒè®¡ç®—æ•ˆç‡çš„åŒæ—¶ï¼Œæ€§èƒ½æ˜¾è‘—ä¼˜äºç°æœ‰çš„æ ‡å‡†åŸºå‡†æ¨¡å‹ã€‚",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "math.OC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06133v2",
      "published_date": "2025-08-08 08:54:21 UTC",
      "updated_date": "2025-08-31 15:09:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:16:36.596500+00:00"
    },
    {
      "arxiv_id": "2508.06129v1",
      "title": "Study of Robust Features in Formulating Guidance for Heuristic Algorithms for Solving the Vehicle Routing Problem",
      "title_zh": "æ±‚è§£è½¦è¾†è·¯å¾„é—®é¢˜çš„å¯å‘å¼ç®—æ³•å¼•å¯¼æœºåˆ¶æ„å»ºä¸­çš„é²æ£’ç‰¹å¾ç ”ç©¶",
      "authors": [
        "Bachtiar Herdianto",
        "Romain Billot",
        "Flavien Lucas",
        "Marc Sevaux"
      ],
      "abstract": "The Vehicle Routing Problem (VRP) is a complex optimization problem with numerous real-world applications, mostly solved using metaheuristic algorithms due to its $\\mathcal{NP}$-Hard nature. Traditionally, these metaheuristics rely on human-crafted designs developed through empirical studies. However, recent research shows that machine learning methods can be used the structural characteristics of solutions in combinatorial optimization, thereby aiding in designing more efficient algorithms, particularly for solving VRP. Building on this advancement, this study extends the previous research by conducting a sensitivity analysis using multiple classifier models that are capable of predicting the quality of VRP solutions. Hence, by leveraging explainable AI, this research is able to extend the understanding of how these models make decisions. Finally, our findings indicate that while feature importance varies, certain features consistently emerge as strong predictors. Furthermore, we propose a unified framework able of ranking feature impact across different scenarios to illustrate this finding. These insights highlight the potential of feature importance analysis as a foundation for developing a guidance mechanism of metaheuristic algorithms for solving the VRP.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è½¦è¾†è·¯å¾„é—®é¢˜ (Vehicle Routing Problem, VRP) è¿™ä¸€ NP-Hard ä¼˜åŒ–éš¾é¢˜ï¼Œæ¢è®¨äº†åˆ©ç”¨æœºå™¨å­¦ä¹ è¯†åˆ«è§£çš„ç»“æ„ç‰¹å¾ä»¥è¾…åŠ©ç®—æ³•è®¾è®¡çš„æ–¹æ³•ã€‚ç ”ç©¶é‡‡ç”¨å¤šç§åˆ†ç±»æ¨¡å‹å¯¹ VRP è§£çš„è´¨é‡è¿›è¡Œé¢„æµ‹ï¼Œå¹¶ç»“åˆæ•æ„Ÿæ€§åˆ†æä¸å¯è§£é‡Šäººå·¥æ™ºèƒ½ (Explainable AI) æŠ€æœ¯ï¼Œæ­ç¤ºäº†æ¨¡å‹å†³ç­–çš„å…³é”®æœºåˆ¶ã€‚ç ”ç©¶å‘ç°ï¼Œè™½ç„¶ç‰¹å¾é‡è¦æ€§éšåœºæ™¯å˜åŒ–ï¼Œä½†æŸäº›ç‰¹å®šç‰¹å¾åœ¨é¢„æµ‹è§£è´¨é‡æ–¹é¢è¡¨ç°å‡ºæ˜¾è‘—çš„é²æ£’æ€§ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶æå‡ºäº†ä¸€ä¸ªèƒ½å¤Ÿå¯¹ä¸åŒåœºæ™¯ä¸‹çš„ç‰¹å¾å½±å“è¿›è¡Œæ’åºçš„ç»Ÿä¸€æ¡†æ¶ï¼ŒéªŒè¯äº†è¿™äº›å…³é”®ç‰¹å¾åœ¨æŒ‡å¯¼å…ƒå¯å‘å¼ç®—æ³• (metaheuristic algorithms) å¯»ä¼˜è¿‡ç¨‹ä¸­çš„å·¨å¤§æ½œåŠ›ã€‚è¿™äº›å‘ç°ä¸ºæ„å»ºæ›´é«˜æ•ˆçš„ç®—æ³•å¼•å¯¼æœºåˆ¶æä¾›äº†é‡è¦çš„å®è¯æ”¯æŒä¸ç†è®ºä¾æ®ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "22 pages, 14 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.06129v1",
      "published_date": "2025-08-08 08:50:03 UTC",
      "updated_date": "2025-08-08 08:50:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:16:44.586292+00:00"
    },
    {
      "arxiv_id": "2508.06111v1",
      "title": "SKATE, a Scalable Tournament Eval: Weaker LLMs differentiate between stronger ones using verifiable challenges",
      "title_zh": "SKATEï¼šä¸€ç§å¯æ‰©å±•çš„é”¦æ ‡èµ›è¯„ä¼°æ¡†æ¶ï¼Œåˆ©ç”¨å¯éªŒè¯æŒ‘æˆ˜å®ç°å¼± LLM å¯¹å¼º LLM çš„æœ‰æ•ˆåŒºåˆ†",
      "authors": [
        "Dewi S. W. Gould",
        "Bruno Mlodozeniec",
        "Samuel F. Brown"
      ],
      "abstract": "Evaluating the capabilities and risks of foundation models is paramount, yet current methods demand extensive domain expertise, hindering their scalability as these models rapidly evolve. We introduce SKATE: a novel evaluation framework in which large language models (LLMs) compete by generating and solving verifiable tasks for one another. Our core insight is to treat evaluation as a game: models act as both task-setters and solvers, incentivized to create questions which highlight their own strengths while exposing others' weaknesses. SKATE offers several key advantages, balancing scalability, open-endedness, and objectivity. It is fully automated, data-free, and scalable, requiring no human input or domain expertise. By using verifiable tasks rather than LLM judges, scoring is objective. Unlike domain-limited programmatically-generated benchmarks (e.g. chess-playing or spatial reasoning), having LLMs creatively pose challenges enables open-ended and scalable evaluation. As a proof of concept, we introduce LLM-set code-output-prediction (COP) challenges as a verifiable and extensible framework in which to test our approach. Using a TrueSkill-based ranking system, we evaluate six frontier LLMs and find that: (1) weaker models can reliably differentiate and score stronger ones, (2) LLM-based systems are capable of self-preferencing behavior, generating questions that align with their own capabilities, and (3) SKATE automatically surfaces fine-grained capability differences between models. Our findings are an important step towards general, scalable evaluation frameworks which can keep pace with LLM progress.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†SKATEï¼Œä¸€ç§æ–°é¢–çš„è‡ªåŠ¨åŒ–è¯„ä¼°æ¡†æ¶ï¼Œé€šè¿‡å¤§è¯­è¨€æ¨¡å‹(LLMs)ä¹‹é—´ç›¸äº’ç”Ÿæˆå¹¶è§£å†³å¯éªŒè¯ä»»åŠ¡çš„ç«èµ›æ¨¡å¼è¿›è¡Œèƒ½åŠ›è¯„ä¼°ã€‚è¯¥æ¡†æ¶å°†è¯„ä¼°è¿‡ç¨‹è§†ä¸ºåšå¼ˆï¼Œè®©æ¨¡å‹åŒæ—¶æ‹…ä»»å‡ºé¢˜è€…(Task-setters)å’Œè§£é¢˜è€…(Solvers)ï¼Œé€šè¿‡åˆ›é€ æ—¨åœ¨çªå‡ºè‡ªèº«ä¼˜åŠ¿å¹¶æš´éœ²å¯¹æ‰‹å¼±ç‚¹çš„é¢˜ç›®æ¥å®ç°åŠ¨æ€è¯„æµ‹ã€‚SKATEçš„æ ¸å¿ƒä¼˜åŠ¿åœ¨äºå…¶å®Œå…¨è‡ªåŠ¨åŒ–ä¸”æ— éœ€å¤–éƒ¨æ•°æ®é›†ï¼Œåˆ©ç”¨å¯éªŒè¯ä»»åŠ¡è€ŒéLLMè¯„å§”æ¥ç¡®ä¿è¯„åˆ†çš„å®¢è§‚æ€§ã€‚ç ”ç©¶é€šè¿‡ä»£ç è¾“å‡ºé¢„æµ‹(COP)æŒ‘æˆ˜ä½œä¸ºå®éªŒåœºæ™¯ï¼Œå¹¶é‡‡ç”¨åŸºäºTrueSkillçš„æ’åç³»ç»Ÿå¯¹å…­ç§å‰æ²¿æ¨¡å‹è¿›è¡Œäº†è¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¾ƒå¼±çš„æ¨¡å‹èƒ½å¤Ÿå¯é åœ°å¯¹æ›´å¼ºçš„æ¨¡å‹è¿›è¡ŒåŒºåˆ†å’Œè¯„åˆ†ï¼Œä¸”æ¨¡å‹åœ¨å‡ºé¢˜æ—¶å±•ç°å‡ºæ˜æ˜¾çš„è‡ªæˆ‘åå¥½(Self-preferencing)è¡Œä¸ºã€‚æ­¤å¤–ï¼ŒSKATEèƒ½å¤Ÿè‡ªåŠ¨æŒ–æ˜æ¨¡å‹ä¹‹é—´ç»†ç²’åº¦çš„èƒ½åŠ›å·®å¼‚ï¼Œä¸ºå¼€å‘èƒ½å¤Ÿè·Ÿä¸Šæ¨¡å‹æ¼”è¿›é€Ÿåº¦çš„å¯æ‰©å±•è¯„ä¼°æ¡†æ¶æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "7 pages and appendices",
      "pdf_url": "https://arxiv.org/pdf/2508.06111v1",
      "published_date": "2025-08-08 08:16:40 UTC",
      "updated_date": "2025-08-08 08:16:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:17:07.556519+00:00"
    },
    {
      "arxiv_id": "2508.06110v1",
      "title": "PanelTR: Zero-Shot Table Reasoning Framework Through Multi-Agent Scientific Discussion",
      "title_zh": "PanelTRï¼šåŸºäºå¤šæ™ºèƒ½ä½“ç§‘å­¦è®¨è®ºçš„é›¶æ ·æœ¬è¡¨æ ¼æ¨ç†æ¡†æ¶",
      "authors": [
        "Yiran Rex Ma"
      ],
      "abstract": "Table reasoning, including tabular QA and fact verification, often depends on annotated data or complex data augmentation, limiting flexibility and generalization. LLMs, despite their versatility, often underperform compared to simple supervised models. To approach these issues, we introduce PanelTR, a framework utilizing LLM agent scientists for robust table reasoning through a structured scientific approach. PanelTR's workflow involves agent scientists conducting individual investigations, engaging in self-review, and participating in collaborative peer-review discussions. This process, driven by five scientist personas, enables semantic-level transfer without relying on data augmentation or parametric optimization. Experiments across four benchmarks show that PanelTR outperforms vanilla LLMs and rivals fully supervised models, all while remaining independent of training data. Our findings indicate that structured scientific methodology can effectively handle complex tasks beyond table reasoning with flexible semantic understanding in a zero-shot context.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† PanelTRï¼Œä¸€ä¸ªåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ (LLM) æ™ºèƒ½ä½“ç§‘å­¦å®¶é€šè¿‡ç»“æ„åŒ–ç§‘å­¦æ–¹æ³•è¿›è¡Œç¨³å¥ Table Reasoning çš„æ¡†æ¶ã€‚é’ˆå¯¹è¡¨æ ¼é—®ç­”å’Œäº‹å®æ ¸æŸ¥é€šå¸¸ä¾èµ–æ ‡æ³¨æ•°æ®æˆ–å¤æ‚æ•°æ®å¢å¼ºï¼Œå¯¼è‡´çµæ´»æ€§å’Œæ³›åŒ–èƒ½åŠ›å—é™çš„é—®é¢˜ï¼ŒPanelTR æ¨¡æ‹Ÿäº†ç§‘å­¦ç ”ç©¶çš„å·¥ä½œæµç¨‹ã€‚è¯¥æ¡†æ¶é€šè¿‡äº”ç§ç§‘å­¦å®¶è§’è‰²è¿›è¡Œä¸ªäººè°ƒæŸ¥ã€è‡ªæˆ‘å®¡æŸ¥ä»¥åŠåä½œå¼çš„ Peer-Review è®¨è®ºï¼Œåœ¨æ— éœ€æ•°æ®å¢å¼ºæˆ–å‚æ•°ä¼˜åŒ–çš„å‰æä¸‹å®ç°è¯­ä¹‰çº§è¿ç§»ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒPanelTR åœ¨å››ä¸ªåŸºå‡†æµ‹è¯•ä¸­å‡ä¼˜äºåŸå§‹ LLMï¼Œä¸”åœ¨ Zero-Shot èƒŒæ™¯ä¸‹è¾¾åˆ°äº†ä¸å…¨ç›‘ç£æ¨¡å‹ç›¸å½“çš„æ€§èƒ½æ°´å¹³ã€‚ç ”ç©¶è¡¨æ˜ï¼Œç»“æ„åŒ–çš„ç§‘å­¦æ–¹æ³•è®ºèƒ½æœ‰æ•ˆæå‡å¤æ‚ä»»åŠ¡çš„å¤„ç†æ•ˆç‡ï¼Œå±•ç°äº†æå¼ºçš„æ³›åŒ–èƒ½åŠ›ã€‚",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at IJCNN 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.06110v1",
      "published_date": "2025-08-08 08:15:52 UTC",
      "updated_date": "2025-08-08 08:15:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:17:07.991971+00:00"
    },
    {
      "arxiv_id": "2508.06109v2",
      "title": "FMCE-Net++: Feature Map Convergence Evaluation and Training",
      "title_zh": "FMCE-Net++ï¼šç‰¹å¾å›¾æ”¶æ•›è¯„ä¼°ä¸è®­ç»ƒ",
      "authors": [
        "Zhibo Zhu",
        "Renyu Huang",
        "Lei He"
      ],
      "abstract": "Deep Neural Networks (DNNs) face interpretability challenges due to their opaque internal representations. While Feature Map Convergence Evaluation (FMCE) quantifies module-level convergence via Feature Map Convergence Scores (FMCS), it lacks experimental validation and closed-loop integration. To address this limitation, we propose FMCE-Net++, a novel training framework that integrates a pretrained, frozen FMCE-Net as an auxiliary head. This module generates FMCS predictions, which, combined with task labels, jointly supervise backbone optimization through a Representation Auxiliary Loss. The RAL dynamically balances the primary classification loss and feature convergence optimization via a tunable \\Representation Abstraction Factor. Extensive experiments conducted on MNIST, CIFAR-10, FashionMNIST, and CIFAR-100 demonstrate that FMCE-Net++ consistently enhances model performance without architectural modifications or additional data. Key experimental outcomes include accuracy gains of $+1.16$ pp (ResNet-50/CIFAR-10) and $+1.08$ pp (ShuffleNet v2/CIFAR-100), validating that FMCE-Net++ can effectively elevate state-of-the-art performance ceilings.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ·±åº¦ç¥ç»ç½‘ç»œ(DNNs)ç”±äºå†…éƒ¨è¡¨ç¤ºä¸é€æ˜è€Œé¢ä¸´çš„å¯è§£é‡Šæ€§æŒ‘æˆ˜ï¼Œæå‡ºäº†åä¸ºFMCE-Net++çš„æ–°å‹è®­ç»ƒæ¡†æ¶ã€‚ä¸ºäº†è§£å†³Feature Map Convergence Evaluation(FMCE)ç¼ºä¹å®éªŒéªŒè¯å’Œé—­ç¯é›†æˆçš„é—®é¢˜ï¼Œè¯¥æ¡†æ¶å¼•å…¥äº†ä¸€ä¸ªé¢„è®­ç»ƒä¸”å†»ç»“çš„FMCE-Netä½œä¸ºè¾…åŠ©å¤´ï¼Œç”¨äºç”Ÿæˆç‰¹å¾å›¾æ”¶æ•›å¾—åˆ†(FMCS)ã€‚é€šè¿‡Representation Auxiliary Loss(RAL)ï¼Œè¯¥ç³»ç»Ÿç»“åˆä»»åŠ¡æ ‡ç­¾å…±åŒç›‘ç£ä¸»å¹²ç½‘ç»œçš„ä¼˜åŒ–ï¼Œå¹¶åˆ©ç”¨å¯è°ƒçš„Representation Abstraction FactoråŠ¨æ€å¹³è¡¡åˆ†ç±»æŸå¤±ä¸ç‰¹å¾æ”¶æ•›ã€‚åœ¨MNISTã€CIFAR-10ã€FashionMNISTå’ŒCIFAR-100ç­‰æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¯æ˜ï¼ŒFMCE-Net++åœ¨ä¸æ”¹å˜æ¨¡å‹æ¶æ„æˆ–å¢åŠ é¢å¤–æ•°æ®çš„æƒ…å†µä¸‹ï¼Œèƒ½å¤Ÿä¸€è‡´åœ°æé«˜æ¨¡å‹æ€§èƒ½ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒResNet-50åœ¨CIFAR-10ä¸Šçš„å‡†ç¡®ç‡æå‡äº†1.16ä¸ªç™¾åˆ†ç‚¹ï¼ŒShuffleNet v2åœ¨CIFAR-100ä¸Šæå‡äº†1.08ä¸ªç™¾åˆ†ç‚¹ã€‚è¿™é¡¹å·¥ä½œéªŒè¯äº†FMCE-Net++å¯ä»¥æœ‰æ•ˆæå‡ç°æœ‰æœ€å…ˆè¿›æŠ€æœ¯çš„æ€§èƒ½ä¸Šé™ï¼Œä¸ºæ·±åº¦å­¦ä¹ æ¨¡å‹çš„ç‰¹å¾æ”¶æ•›ä¼˜åŒ–æä¾›äº†æ–°çš„è·¯å¾„ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06109v2",
      "published_date": "2025-08-08 08:15:26 UTC",
      "updated_date": "2025-08-17 02:24:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:17:11.394242+00:00"
    },
    {
      "arxiv_id": "2508.06108v1",
      "title": "GCHR : Goal-Conditioned Hindsight Regularization for Sample-Efficient Reinforcement Learning",
      "title_zh": "GCHRï¼šé¢å‘é«˜æ ·æœ¬æ•ˆç‡å¼ºåŒ–å­¦ä¹ çš„ç›®æ ‡æ¡ä»¶äº‹åæ­£åˆ™åŒ–",
      "authors": [
        "Xing Lei",
        "Wenyan Yang",
        "Kaiqiang Ke",
        "Shentao Yang",
        "Xuetao Zhang",
        "Joni Pajarinen",
        "Donglin Wang"
      ],
      "abstract": "Goal-conditioned reinforcement learning (GCRL) with sparse rewards remains a fundamental challenge in reinforcement learning. While hindsight experience replay (HER) has shown promise by relabeling collected trajectories with achieved goals, we argue that trajectory relabeling alone does not fully exploit the available experiences in off-policy GCRL methods, resulting in limited sample efficiency. In this paper, we propose Hindsight Goal-conditioned Regularization (HGR), a technique that generates action regularization priors based on hindsight goals. When combined with hindsight self-imitation regularization (HSR), our approach enables off-policy RL algorithms to maximize experience utilization. Compared to existing GCRL methods that employ HER and self-imitation techniques, our hindsight regularizations achieve substantially more efficient sample reuse and the best performances, which we empirically demonstrate on a suite of navigation and manipulation tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç¨€ç–å¥–åŠ±ä¸‹çš„ç›®æ ‡æ¡ä»¶å¼ºåŒ–å­¦ä¹  (Goal-conditioned reinforcement learning, GCRL) æŒ‘æˆ˜ï¼Œæå‡ºäº† GCHR æ¡†æ¶ä»¥æå‡é‡‡æ ·æ•ˆç‡ã€‚å°½ç®¡äº‹åç»éªŒå›æ”¾ (Hindsight experience replay, HER) å…·æœ‰åº”ç”¨æ½œåŠ›ï¼Œä½†ä½œè€…è®¤ä¸ºå•çº¯çš„è½¨è¿¹é‡æ ‡è®°æ— æ³•å……åˆ†åˆ©ç”¨ç¦»ç­–ç•¥ GCRL ä¸­çš„ç»éªŒã€‚ä¸ºæ­¤ï¼Œè®ºæ–‡æå‡ºäº†äº‹åç›®æ ‡æ¡ä»¶æ­£åˆ™åŒ– (Hindsight Goal-conditioned Regularization, HGR) æŠ€æœ¯ï¼Œé€šè¿‡æ ¹æ®äº‹åç›®æ ‡ç”ŸæˆåŠ¨ä½œæ­£åˆ™åŒ–å…ˆéªŒæ¥å¢å¼ºå­¦ä¹ è¿‡ç¨‹ã€‚è¯¥æ–¹æ³•è¿›ä¸€æ­¥ç»“åˆäº†äº‹åè‡ªæˆ‘æ¨¡ä»¿æ­£åˆ™åŒ– (Hindsight self-imitation regularization, HSR)ï¼Œä½¿ç®—æ³•èƒ½å¤Ÿæœ€å¤§é™åº¦åœ°æŒ–æ˜ç»éªŒä»·å€¼ã€‚åœ¨å¯¼èˆªå’Œæ“çºµä»»åŠ¡ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒGCHR æ¯”ç°æœ‰é‡‡ç”¨ HER å’Œè‡ªæˆ‘æ¨¡ä»¿æŠ€æœ¯çš„ GCRL æ–¹æ³•å…·æœ‰æ›´é«˜æ•ˆçš„æ ·æœ¬é‡ç”¨ç‡ã€‚æœ€ç»ˆç»“æœè¯æ˜è¯¥æ¡†æ¶åœ¨å¤šé¡¹ä»»åŠ¡ä¸­å‡è¾¾åˆ°äº†æœ€ä½³æ€§èƒ½ (Best performances)ï¼Œæ˜¾è‘—æå‡äº†å¼ºåŒ–å­¦ä¹ çš„æ•ˆç‡ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06108v1",
      "published_date": "2025-08-08 08:12:14 UTC",
      "updated_date": "2025-08-08 08:12:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:17:17.387662+00:00"
    },
    {
      "arxiv_id": "2508.06107v2",
      "title": "Mask & Match: Learning to Recognize Handwritten Math with Self-Supervised Attention",
      "title_zh": "Mask & Matchï¼šåŸºäºè‡ªç›‘ç£æ³¨æ„åŠ›çš„æ‰‹å†™æ•°å­¦è¯†åˆ«å­¦ä¹ ",
      "authors": [
        "Shree Mitra",
        "Ritabrata Chakraborty",
        "Nilkanta Sahu"
      ],
      "abstract": "Recognizing handwritten mathematical expressions (HMER) is a challenging task due to the inherent two-dimensional structure, varying symbol scales, and complex spatial relationships among symbols. In this paper, we present a self-supervised learning (SSL) framework for HMER that eliminates the need for expensive labeled data. Our approach begins by pretraining an image encoder using a combination of global and local contrastive loss, enabling the model to learn both holistic and fine-grained representations. A key contribution of this work is a novel self-supervised attention network, which is trained using a progressive spatial masking strategy. This attention mechanism is designed to learn semantically meaningful focus regions, such as operators, exponents, and nested mathematical notation, without requiring any supervision. The progressive masking curriculum encourages the network to become increasingly robust to missing or occluded visual information, ultimately improving structural understanding. Our complete pipeline consists of (1) self-supervised pretraining of the encoder, (2) self-supervised attention learning, and (3) supervised fine-tuning with a transformer decoder to generate LATEX sequences. Extensive experiments on CROHME benchmarks demonstrate that our method outperforms existing SSL and fully supervised baselines, validating the effectiveness of our progressive attention mechanism in enhancing HMER performance. Our codebase can be found here.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ‰‹å†™æ•°å­¦å…¬å¼è¯†åˆ« (Handwritten Mathematical Expression Recognition, HMER) ä¸­å­˜åœ¨çš„äºŒç»´ç»“æ„å¤æ‚ã€ç¬¦å·æ¯”ä¾‹ä¸ä¸€åŠç©ºé—´å…³ç³»éš¾å¤„ç†ç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åä¸º Mask & Match çš„è‡ªç›‘ç£å­¦ä¹  (Self-Supervised Learning, SSL) æ¡†æ¶ã€‚è¯¥æ¡†æ¶é¦–å…ˆé€šè¿‡ç»“åˆå…¨å±€å’Œå±€éƒ¨å¯¹æ¯”æŸå¤± (Contrastive Loss) å¯¹å›¾åƒç¼–ç å™¨è¿›è¡Œé¢„è®­ç»ƒï¼Œä½¿å…¶èƒ½å¤ŸåŒæ—¶å­¦ä¹ æ•´ä½“å’Œç»†ç²’åº¦çš„ç‰¹å¾è¡¨ç¤ºã€‚æ ¸å¿ƒè´¡çŒ®åœ¨äºæå‡ºäº†ä¸€ç§æ–°å‹è‡ªç›‘ç£æ³¨æ„åŠ›ç½‘ç»œï¼Œåˆ©ç”¨æ¸è¿›å¼ç©ºé—´æ©ç  (Progressive Spatial Masking) ç­–ç•¥ï¼Œåœ¨æ— éœ€ç›‘ç£çš„æƒ…å†µä¸‹å­¦ä¹ ç®—å­ã€æŒ‡æ•°åŠåµŒå¥—ç¬¦å·ç­‰å…·æœ‰è¯­ä¹‰æ„ä¹‰çš„å…³æ³¨åŒºåŸŸã€‚è¿™ç§æ¸è¿›å¼æ©ç ç­–ç•¥å¢å¼ºäº†ç½‘ç»œå¯¹è§†è§‰ä¿¡æ¯ç¼ºå¤±æˆ–é®æŒ¡çš„é²æ£’æ€§ï¼Œä»è€Œæ˜¾è‘—æå‡äº†å¯¹å…¬å¼ç»“æ„çš„ç†è§£èƒ½åŠ›ã€‚æ•´ä¸ªå®Œæ•´æµç¨‹æ¶µç›–äº†ç¼–ç å™¨çš„è‡ªç›‘ç£é¢„è®­ç»ƒã€è‡ªç›‘ç£æ³¨æ„åŠ›å­¦ä¹ ï¼Œä»¥åŠä½¿ç”¨ Transformer è§£ç å™¨ç”Ÿæˆ LaTeX åºåˆ—çš„ç›‘ç£å¾®è°ƒã€‚åœ¨ CROHME åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ€§èƒ½ä¸Šä¼˜äºç°æœ‰çš„è‡ªç›‘ç£å’Œå…¨ç›‘ç£åŸºå‡†æ¨¡å‹ï¼ŒéªŒè¯äº†æ¸è¿›å¼æ³¨æ„åŠ›æœºåˆ¶åœ¨å¢å¼º HMER ä»»åŠ¡è¡¨ç°æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "We have concluded that the current results, while promising, require substantial improvement and further validation to be competitive with the latest state-of-the-art methods in Handwritten Mathematical Expression Recognition (HMER)",
      "pdf_url": "https://arxiv.org/pdf/2508.06107v2",
      "published_date": "2025-08-08 08:11:36 UTC",
      "updated_date": "2025-08-28 17:12:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:17:16.807257+00:00"
    },
    {
      "arxiv_id": "2508.10025v1",
      "title": "Detecting and explaining postpartum depression in real-time with generative artificial intelligence",
      "title_zh": "åˆ©ç”¨ç”Ÿæˆå¼äººå·¥æ™ºèƒ½å®ç°äº§åæŠ‘éƒçš„å®æ—¶æ£€æµ‹ä¸è§£é‡Š",
      "authors": [
        "Silvia GarcÃ­a-MÃ©ndez",
        "Francisco de Arriba-PÃ©rez"
      ],
      "abstract": "Among the many challenges mothers undergo after childbirth, postpartum depression (PPD) is a severe condition that significantly impacts their mental and physical well-being. Consequently, the rapid detection of ppd and their associated risk factors is critical for in-time assessment and intervention through specialized prevention procedures. Accordingly, this work addresses the need to help practitioners make decisions with the latest technological advancements to enable real-time screening and treatment recommendations. Mainly, our work contributes to an intelligent PPD screening system that combines Natural Language Processing, Machine Learning (ML), and Large Language Models (LLMs) towards an affordable, real-time, and non-invasive free speech analysis. Moreover, it addresses the black box problem since the predictions are described to the end users thanks to the combination of LLMs with interpretable ml models (i.e., tree-based algorithms) using feature importance and natural language. The results obtained are 90 % on ppd detection for all evaluation metrics, outperforming the competing solutions in the literature. Ultimately, our solution contributes to the rapid detection of PPD and their associated risk factors, critical for in-time and proper assessment and intervention.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹äº§åæŠ‘éƒ (Postpartum Depression, PPD) å¯¹æ¯äº²èº«å¿ƒå¥åº·çš„ä¸¥é‡å½±å“ï¼Œæå‡ºäº†ä¸€ç§åŸºäºç”Ÿæˆå¼äººå·¥æ™ºèƒ½ (Generative AI) çš„å®æ—¶æ£€æµ‹ä¸è§£é‡Šç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿæ•´åˆäº†è‡ªç„¶è¯­è¨€å¤„ç† (Natural Language Processing, NLP)ã€æœºå™¨å­¦ä¹  (Machine Learning, ML) ä»¥åŠå¤§è¯­è¨€æ¨¡å‹ (Large Language Models, LLMs) æŠ€æœ¯ï¼Œé€šè¿‡å¯è´Ÿæ‹…ä¸”éä¾µå…¥æ€§çš„è‡ªç”±è¨€è¯­åˆ†æ (Free Speech Analysis) å®ç°å¿«é€Ÿç­›æŸ¥ã€‚ä¸ºäº†è§£å†³äººå·¥æ™ºèƒ½çš„é»‘ç›’ (Black Box) é—®é¢˜ï¼Œè¯¥æ¡†æ¶å°† LLMs ä¸åŸºäºæ ‘çš„ç®—æ³• (Tree-based algorithms) ç­‰å¯è§£é‡Šæœºå™¨å­¦ä¹ æ¨¡å‹ç»“åˆï¼Œåˆ©ç”¨ç‰¹å¾é‡è¦æ€§ (Feature Importance) å’Œè‡ªç„¶è¯­è¨€å¯¹é¢„æµ‹ç»“æœè¿›è¡Œè¯¦ç»†è¯´æ˜ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ¡ˆåœ¨æ‰€æœ‰è¯„ä¼°æŒ‡æ ‡ä¸Šçš„æ£€æµ‹å‡†ç¡®ç‡å‡è¾¾åˆ° 90%ï¼Œè¡¨ç°ä¼˜äºæ–‡çŒ®ä¸­ç°æœ‰çš„ç«äº‰æ–¹æ¡ˆã€‚è¿™ä¸€æˆæœä¸ºåŒ»ç–—ä»ä¸šè€…æä¾›äº†å®æ—¶ç­›æŸ¥å’Œæ²»ç–—å»ºè®®çš„å†³ç­–æ”¯æŒï¼Œå¯¹äº PPD åŠå…¶ç›¸å…³é£é™©å› ç´ çš„åŠæ—¶è¯„ä¼°ä¸å¹²é¢„å…·æœ‰é‡è¦ä¸´åºŠä»·å€¼ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.10025v1",
      "published_date": "2025-08-08 07:57:05 UTC",
      "updated_date": "2025-08-08 07:57:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:17:24.749824+00:00"
    },
    {
      "arxiv_id": "2508.06098v2",
      "title": "MeanAudio: Fast and Faithful Text-to-Audio Generation with Mean Flows",
      "title_zh": "MeanAudioï¼šåŸºäºå‡å€¼æµçš„é«˜æ•ˆé«˜ä¿çœŸæ–‡æœ¬åˆ°éŸ³é¢‘ç”Ÿæˆ",
      "authors": [
        "Xiquan Li",
        "Junxi Liu",
        "Yuzhe Liang",
        "Zhikang Niu",
        "Wenxi Chen",
        "Xie Chen"
      ],
      "abstract": "Recent years have witnessed remarkable progress in Text-to-Audio Generation (TTA), providing sound creators with powerful tools to transform inspirations into vivid audio. Yet despite these advances, current TTA systems often suffer from slow inference speed, which greatly hinders the efficiency and smoothness of audio creation. In this paper, we present MeanAudio, a fast and faithful text-to-audio generator capable of rendering realistic sound with only one function evaluation (1-NFE). MeanAudio leverages: (i) the MeanFlow objective with guided velocity target that significantly accelerates inference speed, (ii) an enhanced Flux-style transformer with dual text encoders for better semantic alignment and synthesis quality, and (iii) an efficient instantaneous-to-mean curriculum that speeds up convergence and enables training on consumer-grade GPUs. Through a comprehensive evaluation study, we demonstrate that MeanAudio achieves state-of-the-art performance in single-step audio generation. Specifically, it achieves a real-time factor (RTF) of 0.013 on a single NVIDIA RTX 3090, yielding a 100x speedup over SOTA diffusion-based TTA systems. Moreover, MeanAudio also shows strong performance in multi-step generation, enabling smooth transitions across successive synthesis steps.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†MeanAudioï¼Œä¸€ç§å¿«é€Ÿä¸”å¿ å®(faithful)çš„æ–‡æœ¬è½¬éŸ³é¢‘(Text-to-Audio Generation)ç”Ÿæˆå™¨ï¼Œèƒ½å¤Ÿåœ¨ä»…éœ€ä¸€æ¬¡å‡½æ•°è¯„ä¼°(1-NFE)çš„æƒ…å†µä¸‹ç”Ÿæˆé€¼çœŸçš„éŸ³é¢‘ã€‚MeanAudioæ ¸å¿ƒé‡‡ç”¨äº†å¸¦æœ‰å¼•å¯¼é€Ÿåº¦ç›®æ ‡(guided velocity target)çš„MeanFlowç›®æ ‡å‡½æ•°ï¼Œæå¤§åœ°æé«˜äº†æ¨ç†æ•ˆç‡ã€‚è¯¥æ¡†æ¶ç»“åˆäº†å¢å¼ºçš„Flux-style transformerå’ŒåŒæ–‡æœ¬ç¼–ç å™¨(dual text encoders)ï¼Œæœ‰æ•ˆæå‡äº†è¯­ä¹‰å¯¹é½(semantic alignment)ä¸åˆæˆè´¨é‡ã€‚æ­¤å¤–ï¼Œç ”ç©¶è€…æå‡ºäº†ä¸€ç§é«˜æ•ˆçš„ä»ç¬æ—¶åˆ°å‡å€¼çš„è¯¾ç¨‹å­¦ä¹ (instantaneous-to-mean curriculum)ï¼Œä¸ä»…åŠ é€Ÿäº†æ¨¡å‹æ”¶æ•›ï¼Œè¿˜ä½¿å…¶æ”¯æŒåœ¨æ¶ˆè´¹çº§GPUä¸Šè¿›è¡Œè®­ç»ƒã€‚å®éªŒè¯æ˜ï¼ŒMeanAudioåœ¨å•æ­¥ç”Ÿæˆä¸­å–å¾—äº†SOTAæ€§èƒ½ï¼Œåœ¨NVIDIA RTX 3090ä¸Šå®ç°äº†0.013çš„å®æ—¶å› å­(RTF)ï¼Œè¾ƒä¸»æµçš„æ‰©æ•£æ¨¡å‹(diffusion-based)åŠ é€Ÿäº†100å€ã€‚è¯¥ç³»ç»Ÿåœ¨å¤šæ­¥ç”Ÿæˆåœºæ™¯ä¸‹åŒæ ·è¡¨ç°ç¨³å¥ï¼Œèƒ½å¤Ÿç¡®ä¿è¿ç»­åˆæˆæ­¥éª¤é—´çš„å¹³æ»‘è¿‡æ¸¡ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06098v2",
      "published_date": "2025-08-08 07:49:59 UTC",
      "updated_date": "2025-10-22 09:22:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:17:31.953697+00:00"
    },
    {
      "arxiv_id": "2508.06096v1",
      "title": "Bounding Distributional Shifts in World Modeling through Novelty Detection",
      "title_zh": "é€šè¿‡æ–°é¢–æ€§æ£€æµ‹çº¦æŸä¸–ç•Œå»ºæ¨¡ä¸­çš„åˆ†å¸ƒåç§»",
      "authors": [
        "Eric Jing",
        "Abdeslam Boularias"
      ],
      "abstract": "Recent work on visual world models shows significant promise in latent state dynamics obtained from pre-trained image backbones. However, most of the current approaches are sensitive to training quality, requiring near-complete coverage of the action and state space during training to prevent divergence during inference. To make a model-based planning algorithm more robust to the quality of the learned world model, we propose in this work to use a variational autoencoder as a novelty detector to ensure that proposed action trajectories during planning do not cause the learned model to deviate from the training data distribution. To evaluate the effectiveness of this approach, a series of experiments in challenging simulated robot environments was carried out, with the proposed method incorporated into a model-predictive control policy loop extending the DINO-WM architecture. The results clearly show that the proposed method improves over state-of-the-art solutions in terms of data efficiency.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è§†è§‰ä¸–ç•Œæ¨¡å‹(visual world models)å¯¹è®­ç»ƒè´¨é‡é«˜åº¦æ•æ„Ÿä¸”åœ¨æ¨ç†é˜¶æ®µå®¹æ˜“å› åˆ†å¸ƒåç§»(distributional shifts)è€Œå¯¼è‡´å‘æ•£çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§é€šè¿‡æ–°é¢–æ€§æ£€æµ‹(novelty detection)æ¥æå‡é²æ£’æ€§çš„æ–¹æ³•ã€‚ç ”ç©¶è€…åˆ©ç”¨å˜åˆ†è‡ªç¼–ç å™¨(Variational Autoencoder, VAE)ä½œä¸ºæ–°é¢–æ€§æ£€æµ‹å™¨ï¼Œåœ¨è§„åˆ’è¿‡ç¨‹ä¸­ç›‘æ§å»ºè®®çš„åŠ¨ä½œè½¨è¿¹ï¼Œä»¥ç¡®ä¿æ¨¡å‹ä¸ä¼šåç¦»è®­ç»ƒæ•°æ®åˆ†å¸ƒã€‚è¯¥æ–¹æ³•è¢«é›†æˆåˆ°åŸºäºDINO-WMæ¶æ„çš„æ¨¡å‹é¢„æµ‹æ§åˆ¶(Model-Predictive Control, MPC)ç­–ç•¥å¾ªç¯ä¸­ï¼Œå¢å¼ºäº†æ¨¡å‹åŸºè§„åˆ’ç®—æ³•çš„å¯é æ€§ã€‚åœ¨å¤šä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„æœºå™¨äººæ¨¡æ‹Ÿç¯å¢ƒå®éªŒä¸­ï¼Œç»“æœè¯æ˜è¯¥æ–¹æ³•èƒ½æœ‰æ•ˆçº¦æŸåˆ†å¸ƒåç§»ï¼Œå¹¶åœ¨æ•°æ®æ•ˆç‡(data efficiency)ä¸Šæ˜¾è‘—ä¼˜äºç›®å‰çš„å…ˆè¿›è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "7 pages, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.06096v1",
      "published_date": "2025-08-08 07:42:14 UTC",
      "updated_date": "2025-08-08 07:42:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:17:40.051665+00:00"
    },
    {
      "arxiv_id": "2508.06091v1",
      "title": "Aggregate-Combine-Readout GNNs Are More Expressive Than Logic C2",
      "title_zh": "èšåˆ-ç»„åˆ-è¯»å– GNN çš„è¡¨è¾¾èƒ½åŠ›å¼ºäº C2 é€»è¾‘",
      "authors": [
        "Stan P Hauke",
        "PrzemysÅ‚aw Andrzej WaÅ‚Ä™ga"
      ],
      "abstract": "In recent years, there has been growing interest in understanding the expressive power of graph neural networks (GNNs) by relating them to logical languages. This research has been been initialised by an influential result of BarcelÃ³ et al. (2020), who showed that the graded modal logic (or a guarded fragment of the logic C2), characterises the logical expressiveness of aggregate-combine GNNs. As a ``challenging open problem'' they left the question whether full C2 characterises the logical expressiveness of aggregate-combine-readout GNNs. This question has remained unresolved despite several attempts. In this paper, we solve the above open problem by proving that the logical expressiveness of aggregate-combine-readout GNNs strictly exceeds that of C2. This result holds over both undirected and directed graphs. Beyond its implications for GNNs, our work also leads to purely logical insights on the expressive power of infinitary logics.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å›¾ç¥ç»ç½‘ç»œ (GNNs) çš„è¡¨è¾¾èƒ½åŠ›ä¸å…¶å¯¹åº”çš„é€»è¾‘è¯­è¨€ä¹‹é—´çš„å…³ç³»ï¼Œæ—¨åœ¨è§£å†³ç”± BarcelÃ³ ç­‰äººäº2020å¹´æå‡ºçš„å…¬å¼€éš¾é¢˜ã€‚æ­¤å‰ç ”ç©¶è¡¨æ˜ aggregate-combine GNNs çš„é€»è¾‘è¡¨è¾¾èƒ½åŠ›ç”± C2 é€»è¾‘çš„å—é™ç‰‡æ®µåˆ»ç”»ï¼Œè€Œæœ¬è®ºæ–‡é€šè¿‡ä¸¥è°¨è¯æ˜ï¼Œç¡®è®¤ aggregate-combine-readout GNNs çš„è¡¨è¾¾èƒ½åŠ›ä¸¥æ ¼è¶…è¿‡äº†å®Œæ•´çš„ C2 é€»è¾‘ã€‚è¿™ä¸€ç»“è®ºåœ¨æ— å‘å›¾å’Œæœ‰å‘å›¾ä¸Šå‡æˆç«‹ï¼Œå¡«è¡¥äº†è¯¥é¢†åŸŸçš„ç†è®ºç©ºç™½ã€‚é™¤äº†å¯¹ GNNs ç†è®ºçš„è´¡çŒ®å¤–ï¼Œè¯¥å·¥ä½œè¿˜ä¸ºæ— ç©·é€»è¾‘ (infinitary logics) çš„è¡¨è¾¾èƒ½åŠ›æä¾›äº†çº¯é€»è¾‘å±‚é¢çš„æ·±å…¥è§è§£ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages",
      "pdf_url": "https://arxiv.org/pdf/2508.06091v1",
      "published_date": "2025-08-08 07:35:35 UTC",
      "updated_date": "2025-08-08 07:35:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:17:32.350736+00:00"
    },
    {
      "arxiv_id": "2508.06589v1",
      "title": "A Federated Learning Framework for Handling Subtype Confounding and Heterogeneity in Large-Scale Neuroimaging Diagnosis",
      "title_zh": "åº”å¯¹å¤§è§„æ¨¡ç¥ç»å½±åƒè¯Šæ–­ä¸­äºšå‹æ··æ‚ä¸å¼‚è´¨æ€§çš„è”é‚¦å­¦ä¹ æ¡†æ¶",
      "authors": [
        "Xinglin Zhao",
        "Yanwen Wang",
        "Xiaobo Liu",
        "Yanrong Hao",
        "Rui Cao",
        "Xin Wen"
      ],
      "abstract": "Computer-aided diagnosis (CAD) systems play a crucial role in analyzing neuroimaging data for neurological and psychiatric disorders. However, small-sample studies suffer from low reproducibility, while large-scale datasets introduce confounding heterogeneity due to multiple disease subtypes being labeled under a single category. To address these challenges, we propose a novel federated learning framework tailored for neuroimaging CAD systems. Our approach includes a dynamic navigation module that routes samples to the most suitable local models based on latent subtype representations, and a meta-integration module that combines predictions from heterogeneous local models into a unified diagnostic output. We evaluated our framework using a comprehensive dataset comprising fMRI data from over 1300 MDD patients and 1100 healthy controls across multiple study cohorts. Experimental results demonstrate significant improvements in diagnostic accuracy and robustness compared to traditional methods. Specifically, our framework achieved an average accuracy of 74.06\\% across all tested sites, showcasing its effectiveness in handling subtype heterogeneity and enhancing model generalizability. Ablation studies further confirmed the importance of both the dynamic navigation and meta-integration modules in improving performance. By addressing data heterogeneity and subtype confounding, our framework advances reliable and reproducible neuroimaging CAD systems, offering significant potential for personalized medicine and clinical decision-making in neurology and psychiatry.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç¥ç»å½±åƒè¾…åŠ©è¯Šæ–­ç³»ç»Ÿ(Computer-aided diagnosis, CAD)åœ¨å¤§è§„æ¨¡æ•°æ®é›†ä¸­é¢ä¸´çš„äºšå‹æ··æ·†(subtype confounding)å’Œå¼‚æ„æ€§(heterogeneity)æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§æ–°å‹çš„è”é‚¦å­¦ä¹ (federated learning)æ¡†æ¶ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†åŠ¨æ€å¯¼èˆªæ¨¡å—(dynamic navigation module)ï¼Œåˆ©ç”¨æ½œåœ¨äºšå‹è¡¨ç¤ºå°†æ ·æœ¬è·¯ç”±è‡³æœ€åŒ¹é…çš„æœ¬åœ°æ¨¡å‹ï¼Œå¹¶é…åˆå…ƒé›†æˆæ¨¡å—(meta-integration module)å°†å¼‚æ„çš„é¢„æµ‹ç»“æœæ•´åˆä¸ºç»Ÿä¸€çš„è¯Šæ–­è¾“å‡ºã€‚é€šè¿‡å¯¹åŒ…å«1300å¤šåé‡åº¦æŠ‘éƒç—‡(MDD)æ‚£è€…å’Œ1100åå¥åº·å¯¹ç…§è€…çš„fMRIæ•°æ®é›†è¿›è¡ŒéªŒè¯ï¼Œå®éªŒç»“æœè¡¨æ˜è¯¥æ¡†æ¶å®ç°äº†74.06%çš„å¹³å‡å‡†ç¡®ç‡ã€‚è¯¥æ–¹æ³•åœ¨è¯Šæ–­å‡†ç¡®æ€§å’Œé²æ£’æ€§ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ‰‹æ®µï¼Œæœ‰æ•ˆè§£å†³äº†å­ç±»å¼‚æ„æ€§å¯¹æ¨¡å‹æ³›åŒ–èƒ½åŠ›çš„å½±å“ã€‚è¿™é¡¹å·¥ä½œä¸ºæ„å»ºå¯é ä¸”å…·æœ‰å¯é‡å¤æ€§çš„ç¥ç»å½±åƒè¾…åŠ©è¯Šæ–­ç³»ç»Ÿæä¾›äº†æ–°æ€è·¯ï¼Œå¯¹ç¥ç»ç—…å­¦å’Œç²¾ç¥ç—…å­¦é¢†åŸŸçš„ä¸ªæ€§åŒ–åŒ»ç–—å…·æœ‰é‡è¦åº”ç”¨ä»·å€¼ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06589v1",
      "published_date": "2025-08-08 07:19:49 UTC",
      "updated_date": "2025-08-08 07:19:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:17:38.957380+00:00"
    },
    {
      "arxiv_id": "2508.06076v1",
      "title": "Towards MR-Based Trochleoplasty Planning",
      "title_zh": "é¢å‘åŸºäºç£å…±æŒ¯çš„æ»‘è½¦æˆå½¢æœ¯è§„åˆ’",
      "authors": [
        "Michael Wehrli",
        "Alicia Durrer",
        "Paul Friedrich",
        "Sidaty El Hadramy",
        "Edwin Li",
        "Luana Brahaj",
        "Carol C. Hasler",
        "Philippe C. Cattin"
      ],
      "abstract": "To treat Trochlear Dysplasia (TD), current approaches rely mainly on low-resolution clinical Magnetic Resonance (MR) scans and surgical intuition. The surgeries are planned based on surgeons experience, have limited adoption of minimally invasive techniques, and lead to inconsistent outcomes. We propose a pipeline that generates super-resolved, patient-specific 3D pseudo-healthy target morphologies from conventional clinical MR scans. First, we compute an isotropic super-resolved MR volume using an Implicit Neural Representation (INR). Next, we segment femur, tibia, patella, and fibula with a multi-label custom-trained network. Finally, we train a Wavelet Diffusion Model (WDM) to generate pseudo-healthy target morphologies of the trochlear region. In contrast to prior work producing pseudo-healthy low-resolution 3D MR images, our approach enables the generation of sub-millimeter resolved 3D shapes compatible for pre- and intraoperative use. These can serve as preoperative blueprints for reshaping the femoral groove while preserving the native patella articulation. Furthermore, and in contrast to other work, we do not require a CT for our pipeline - reducing the amount of radiation. We evaluated our approach on 25 TD patients and could show that our target morphologies significantly improve the sulcus angle (SA) and trochlear groove depth (TGD). The code and interactive visualization are available at https://wehrlimi.github.io/sr-3d-planning/.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ»‘è½¦å‘è‚²ä¸è‰¯(Trochlear Dysplasia, TD)æ²»ç–—ä¸­å› ä¾èµ–ä½åˆ†è¾¨ç‡MRæ‰«æå’Œæ‰‹æœ¯ç›´è§‰å¯¼è‡´ç»“æœä¸ä¸€è‡´çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ç”Ÿæˆæ‚£è€…ç‰¹å¼‚æ€§3Dä¼ªå¥åº·ç›®æ ‡å½¢æ€çš„è§„åˆ’æµç¨‹ã€‚è¯¥æ–¹æ³•é¦–å…ˆåˆ©ç”¨éšå¼ç¥ç»è¡¨ç¤º(Implicit Neural Representation, INR)ç”Ÿæˆå„å‘åŒæ€§çš„è¶…åˆ†è¾¨ç‡MRä½“ç§¯ï¼Œå¹¶ç»“åˆå¤šæ ‡ç­¾ç½‘ç»œå®Œæˆéª¨éª¼åˆ†å‰²ã€‚éšåï¼Œç ”ç©¶é‡‡ç”¨å°æ³¢æ‰©æ•£æ¨¡å‹(Wavelet Diffusion Model, WDM)é‡å»ºæ»‘è½¦åŒºåŸŸçš„äºšæ¯«ç±³çº§3Då½¢çŠ¶ï¼Œä½œä¸ºæœ¯å‰å’Œæœ¯ä¸­é‡å¡‘è‚¡éª¨æ²Ÿçš„è“å›¾ã€‚è¯¥æ–¹æ¡ˆæ— éœ€ä½¿ç”¨CTï¼Œæœ‰æ•ˆé™ä½äº†è¾å°„æš´éœ²ï¼ŒåŒæ—¶èƒ½æ›´å¥½åœ°ç»´æŠ¤åŸç”Ÿé«Œéª¨å…³èŠ‚çš„è¿åŠ¨å…³ç³»ã€‚åœ¨å¯¹25ä¾‹TDæ‚£è€…çš„è¯„ä¼°ä¸­ï¼Œè¯¥æŠ€æœ¯æ˜¾è‘—æ”¹å–„äº†æ²Ÿè§’(Sulcus Angle, SA)å’Œæ»‘è½¦æ²Ÿæ·±åº¦(Trochlear Groove Depth, TGD)ã€‚è¿™ä¸€æˆæœä¸ºå®ç°ç²¾å‡†åŒ–ã€å¾®åˆ›åŒ–çš„æ»‘è½¦æˆå½¢æœ¯æä¾›äº†é‡è¦çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at MICCAI COLAS Workshop 2025. Code: https://wehrlimi.github.io/sr-3d-planning/",
      "pdf_url": "https://arxiv.org/pdf/2508.06076v1",
      "published_date": "2025-08-08 07:15:23 UTC",
      "updated_date": "2025-08-08 07:15:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:17:59.052909+00:00"
    },
    {
      "arxiv_id": "2508.06074v1",
      "title": "ME$^3$-BEV: Mamba-Enhanced Deep Reinforcement Learning for End-to-End Autonomous Driving with BEV-Perception",
      "title_zh": "ME$^3$-BEVï¼šç»“åˆ BEV æ„ŸçŸ¥çš„ Mamba å¢å¼ºå‹ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶æ·±åº¦å¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Siyi Lu",
        "Run Liu",
        "Dongsheng Yang",
        "Lei He"
      ],
      "abstract": "Autonomous driving systems face significant challenges in perceiving complex environments and making real-time decisions. Traditional modular approaches, while offering interpretability, suffer from error propagation and coordination issues, whereas end-to-end learning systems can simplify the design but face computational bottlenecks. This paper presents a novel approach to autonomous driving using deep reinforcement learning (DRL) that integrates bird's-eye view (BEV) perception for enhanced real-time decision-making. We introduce the \\texttt{Mamba-BEV} model, an efficient spatio-temporal feature extraction network that combines BEV-based perception with the Mamba framework for temporal feature modeling. This integration allows the system to encode vehicle surroundings and road features in a unified coordinate system and accurately model long-range dependencies. Building on this, we propose the \\texttt{ME$^3$-BEV} framework, which utilizes the \\texttt{Mamba-BEV} model as a feature input for end-to-end DRL, achieving superior performance in dynamic urban driving scenarios. We further enhance the interpretability of the model by visualizing high-dimensional features through semantic segmentation, providing insight into the learned representations. Extensive experiments on the CARLA simulator demonstrate that \\texttt{ME$^3$-BEV} outperforms existing models across multiple metrics, including collision rate and trajectory accuracy, offering a promising solution for real-time autonomous driving.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ME$^3$-BEVï¼Œä¸€ç§é›†æˆäº†BEV-Perceptionå’ŒMambaå¢å¼ºå‹æ·±åº¦å¼ºåŒ–å­¦ä¹ (Deep Reinforcement Learning, DRL)çš„ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶æ¡†æ¶ã€‚è¯¥æ¡†æ¶æ—¨åœ¨è§£å†³ä¼ ç»Ÿæ¨¡å—åŒ–æ–¹æ³•ä¸­çš„è¯¯å·®ä¼ æ’­é—®é¢˜ä»¥åŠç«¯åˆ°ç«¯ç³»ç»Ÿåœ¨å¤„ç†å¤æ‚ç¯å¢ƒæ„ŸçŸ¥æ—¶çš„è®¡ç®—ç“¶é¢ˆã€‚æ ¸å¿ƒçš„Mamba-BEVæ¨¡å‹é€šè¿‡ç»“åˆBEVæ„ŸçŸ¥ä¸Mambaæ¶æ„ï¼Œå®ç°åœ¨ç»Ÿä¸€åæ ‡ç³»ä¸‹å¯¹è½¦è¾†å‘¨è¾¹ç‰¹å¾çš„é«˜æ•ˆç¼–ç ï¼Œå¹¶èƒ½ç²¾ç¡®å»ºæ¨¡é•¿ç¨‹æ—¶ç©ºä¾èµ–å…³ç³»ã€‚ME$^3$-BEVå°†è¯¥æ¨¡å‹çš„ç‰¹å¾è¾“å‡ºä½œä¸ºå¼ºåŒ–å­¦ä¹ çš„è¾“å…¥ï¼Œåœ¨åŠ¨æ€åŸå¸‚é©¾é©¶åœºæ™¯ä¸­å®ç°äº†å“è¶Šçš„å†³ç­–æ€§èƒ½ã€‚æ­¤å¤–ï¼Œç ”ç©¶åˆ©ç”¨è¯­ä¹‰åˆ†å‰²(Semantic Segmentation)å¯¹é«˜ç»´ç‰¹å¾è¿›è¡Œå¯è§†åŒ–ï¼Œå¢å¼ºäº†æ¨¡å‹å†…éƒ¨è¡¨å¾çš„å¯è§£é‡Šæ€§ã€‚åœ¨CARLAæ¨¡æ‹Ÿå™¨ä¸Šçš„å¹¿æ³›å®éªŒè¯æ˜ï¼ŒME$^3$-BEVåœ¨ç¢°æ’ç‡å’Œè½¨è¿¹ç²¾åº¦ç­‰æŒ‡æ ‡ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ¨¡å‹ï¼Œä¸ºå®æ—¶ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶æä¾›äº†ä¸€ç§é«˜æ•ˆä¸”å¯é çš„æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06074v1",
      "published_date": "2025-08-08 07:13:28 UTC",
      "updated_date": "2025-08-08 07:13:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:18:05.786625+00:00"
    },
    {
      "arxiv_id": "2508.06072v1",
      "title": "Can Large Models Fool the Eye? A New Turing Test for Biological Animation",
      "title_zh": "å¤§æ¨¡å‹èƒ½å¦æ¬ºéª—äººç±»è§†è§‰ï¼Ÿä¸€ç§é’ˆå¯¹ç”Ÿç‰©åŠ¨ç”»çš„æ–°å‹å›¾çµæµ‹è¯•",
      "authors": [
        "Zijian Chen",
        "Lirong Deng",
        "Zhengyu Chen",
        "Kaiwei Zhang",
        "Qi Jia",
        "Yuan Tian",
        "Yucheng Zhu",
        "Guangtao Zhai"
      ],
      "abstract": "Evaluating the abilities of large models and manifesting their gaps are challenging. Current benchmarks adopt either ground-truth-based score-form evaluation on static datasets or indistinct textual chatbot-style human preferences collection, which may not provide users with immediate, intuitive, and perceptible feedback on performance differences. In this paper, we introduce BioMotion Arena, a novel framework for evaluating large language models (LLMs) and multimodal large language models (MLLMs) via visual animation. Our methodology draws inspiration from the inherent visual perception of motion patterns characteristic of living organisms that utilizes point-light source imaging to amplify the performance discrepancies between models. Specifically, we employ a pairwise comparison evaluation and collect more than 45k votes for 53 mainstream LLMs and MLLMs on 90 biological motion variants. Data analyses show that the crowd-sourced human votes are in good agreement with those of expert raters, demonstrating the superiority of our BioMotion Arena in offering discriminative feedback. We also find that over 90\\% of evaluated models, including the cutting-edge open-source InternVL3 and proprietary Claude-4 series, fail to produce fundamental humanoid point-light groups, much less smooth and biologically plausible motions. This enables BioMotion Arena to serve as a challenging benchmark for performance visualization and a flexible evaluation framework without restrictions on ground-truth.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼•å…¥äº† BioMotion Arenaï¼Œè¿™æ˜¯ä¸€ä¸ªé€šè¿‡è§†è§‰åŠ¨ç”»è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹ (LLMs) å’Œå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ (MLLMs) çš„åˆ›æ–°æ¡†æ¶ã€‚è¯¥æ–¹æ³•å—ç”Ÿç‰©è¿åŠ¨è§†è§‰æ„ŸçŸ¥ç‰¹æ€§çš„å¯å‘ï¼Œåˆ©ç”¨ç‚¹å…‰æºæˆåƒ (point-light source imaging) æŠ€æœ¯æ¥æ”¾å¤§ä¸åŒæ¨¡å‹ä¹‹é—´çš„æ€§èƒ½å·®å¼‚ã€‚ç ”ç©¶äººå‘˜é€šè¿‡ä¸¤ä¸¤æ¯”è¾ƒ (pairwise comparison) çš„è¯„ä¼°æ–¹å¼ï¼Œé’ˆå¯¹ 53 ä¸ªä¸»æµæ¨¡å‹åœ¨ 90 ç§ç”Ÿç‰©è¿åŠ¨å˜ä½“ä¸Šçš„è¡¨ç°æ”¶é›†äº†è¶…è¿‡ 4.5 ä¸‡æ¬¡æŠ•ç¥¨ã€‚æ•°æ®åˆ†ææ˜¾ç¤ºï¼Œä¼—åŒ…æŠ•ç¥¨ç»“æœä¸ä¸“å®¶è¯„åˆ†é«˜åº¦ä¸€è‡´ï¼Œè¯æ˜äº†è¯¥æ¡†æ¶åœ¨æä¾›åˆ¤åˆ«æ€§åé¦ˆæ–¹é¢çš„ä¼˜è¶Šæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒåŒ…æ‹¬ InternVL3 å’Œ Claude-4 åœ¨å†…çš„è¶…è¿‡ 90% çš„æ¨¡å‹ç”šè‡³æ— æ³•ç”ŸæˆåŸºç¡€çš„äººå½¢ç‚¹å…‰æºç»„ï¼Œæ›´éš¾ä»¥äº§ç”Ÿå¹³æ»‘ä¸”ç¬¦åˆç”Ÿç‰©å­¦é€»è¾‘çš„è¿åŠ¨ã€‚BioMotion Arena ä¸ºæ¨¡å‹æ€§èƒ½å¯è§†åŒ–æä¾›äº†ä¸€ä¸ªæå…·æŒ‘æˆ˜æ€§çš„åŸºå‡†ï¼Œå¹¶ä½œä¸ºä¸€ä¸ªä¸å—åœ°é¢çœŸå€¼ (ground-truth) é™åˆ¶çš„çµæ´»è¯„ä¼°æ¡†æ¶ï¼Œæ­ç¤ºäº†å½“å‰å¤§å‹æ¨¡å‹åœ¨æ¨¡æ‹Ÿç”Ÿç‰©è¿åŠ¨æ–¹é¢çš„å·¨å¤§é¸¿æ²Ÿã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "24 pages, 10 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.06072v1",
      "published_date": "2025-08-08 07:10:17 UTC",
      "updated_date": "2025-08-08 07:10:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:18:01.555202+00:00"
    },
    {
      "arxiv_id": "2508.06066v2",
      "title": "Architecture-Aware Generalization Bounds for Temporal Networks: Theory and Fair Comparison Methodology",
      "title_zh": "æ—¶åºç½‘ç»œçš„æ¶æ„æ„ŸçŸ¥æ³›åŒ–ç•Œï¼šç†è®ºä¸å…¬å¹³æ¯”è¾ƒæ–¹æ³•è®º",
      "authors": [
        "Barak Gahtan",
        "Alex M. Bronstein"
      ],
      "abstract": "Deep temporal architectures such as TCNs achieve strong predictive performance on sequential data, yet theoretical understanding of their generalization remains limited. We address this gap through three contributions: introducing an evaluation methodology for temporal models, revealing surprising empirical phenomena about temporal dependence, and the first architecture-aware theoretical framework for dependent sequences.\n  Fair-Comparison Methodology. We introduce evaluation protocols that fix effective sample size $N_{\\text{eff}}$ to isolate temporal structure effects from information content.\n  Empirical Findings. Applying this method reveals that under $N_{\\text{eff}} = 2000$, strongly dependent sequences ($Ï= 0.8$) exhibit approx' $76\\%$ smaller generalization gaps than weakly dependent ones ($Ï= 0.2$), challenging the conventional view that dependence universally impedes learning. However, observed convergence rates ($N_{\\text{eff}}^{-1.21}$ to $N_{\\text{eff}}^{-0.89}$) significantly exceed theoretical worst-case predictions ($N^{-0.5}$), revealing that temporal architectures exploit problem structure in ways current theory does not capture.\n  Lastly, we develop the first architecture-aware generalization bounds for deep temporal models on exponentially $Î²$-mixing sequences. By embedding Golowich et al.'s i.i.d. class bound within a novel blocking scheme that partitions $N$ samples into approx' $B \\approx N/\\log N$ quasi-independent blocks, we establish polynomial sample complexity under convex Lipschitz losses. The framework achieves $\\sqrt{D}$ depth scaling alongside the product of layer-wise norms $R = \\prod_{\\ell=1}^{D} M^{(\\ell)}$, avoiding exponential dependence. While these bounds are conservative, they prove learnability and identify architectural scaling laws, providing worst-case baselines that highlight where future theory must improve.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹TCNsç­‰æ·±å±‚æ—¶é—´æ¶æ„åœ¨æ—¶åºæ•°æ®é¢„æµ‹ä¸­è¡¨ç°ä¼˜å¼‚ä½†æ³›åŒ–ç†è®ºå°šä¸å®Œå–„çš„é—®é¢˜ï¼Œæå‡ºäº†é¦–ä¸ªé’ˆå¯¹ä¾èµ–åºåˆ—çš„æ¶æ„æ„ŸçŸ¥ç†è®ºæ¡†æ¶ã€‚ä½œè€…é¦–å…ˆå¼•å…¥äº†ä¸€å¥—å…¬å¹³æ¯”è¾ƒæ–¹æ³•è®º(Fair-Comparison Methodology)ï¼Œé€šè¿‡å›ºå®šæœ‰æ•ˆæ ·æœ¬é‡($N_{\\text{eff}}$)æ¥éš”ç¦»æ—¶é—´ç»“æ„å¯¹æ¨¡å‹æ³›åŒ–çš„å½±å“ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨ç›¸åŒæ ·æœ¬é‡ä¸‹ï¼Œå¼ºä¾èµ–åºåˆ—($Ï=0.8$)çš„æ³›åŒ–å·®è·æ¯”å¼±ä¾èµ–åºåˆ—($Ï=0.2$)å°çº¦76%ï¼ŒæŒ‘æˆ˜äº†ä¾èµ–æ€§æ™®éé˜»ç¢å­¦ä¹ çš„ä¼ ç»Ÿè§‚ç‚¹ã€‚æ­¤å¤–ï¼Œç ”ç©¶å‘ç°å®é™…æ”¶æ•›é€Ÿåº¦æ˜¾è‘—ä¼˜äºç†è®ºé¢„æµ‹ï¼Œè¡¨æ˜æ—¶é—´æ¶æ„èƒ½æœ‰æ•ˆåˆ©ç”¨ç°æœ‰ç†è®ºå°šæœªæ•æ‰åˆ°çš„é—®é¢˜ç»“æ„ã€‚åœ¨ç†è®ºåˆ›æ–°ä¸Šï¼Œè¯¥ç ”ç©¶é€šè¿‡å°†Golowichç­‰äººçš„ç‹¬ç«‹åŒåˆ†å¸ƒ(i.i.d.)ç±»ç•Œé™åµŒå…¥åˆ°ä¸€ç§æ–°å‹çš„åˆ†å—æ–¹æ¡ˆ(blocking scheme)ä¸­ï¼Œå»ºç«‹äº†é’ˆå¯¹æŒ‡æ•°çº§$Î²$-mixingåºåˆ—çš„æ³›åŒ–ç•Œé™ã€‚è¯¥æ¡†æ¶å®ç°äº†éšæ·±åº¦$\\sqrt{D}$ç¼©æ”¾ä¸”é¿å…äº†å¯¹å±‚èŒƒæ•°ä¹˜ç§¯çš„æŒ‡æ•°çº§ä¾èµ–ï¼Œä¸ä»…è¯æ˜äº†æ·±å±‚æ—¶é—´æ¨¡å‹çš„å¯å­¦ä¹ æ€§ï¼Œè¿˜ä¸ºæœªæ¥çš„æ—¶é—´ç½‘ç»œç†è®ºæ”¹è¿›æä¾›äº†é‡è¦çš„æœ€åæƒ…å†µåŸºå‡†ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06066v2",
      "published_date": "2025-08-08 06:57:49 UTC",
      "updated_date": "2025-12-06 11:29:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:18:05.558146+00:00"
    },
    {
      "arxiv_id": "2508.06065v1",
      "title": "ThematicPlane: Bridging Tacit User Intent and Latent Spaces for Image Generation",
      "title_zh": "ThematicPlaneï¼šè¡”æ¥å›¾åƒç”Ÿæˆä¸­çš„éšæ€§ç”¨æˆ·æ„å›¾ä¸æ½œåœ¨ç©ºé—´",
      "authors": [
        "Daniel Lee",
        "Nikhil Sharma",
        "Donghoon Shin",
        "DaEun Choi",
        "Harsh Sharma",
        "Jeonghwan Kim",
        "Heng Ji"
      ],
      "abstract": "Generative AI has made image creation more accessible, yet aligning outputs with nuanced creative intent remains challenging, particularly for non-experts. Existing tools often require users to externalize ideas through prompts or references, limiting fluid exploration. We introduce ThematicPlane, a system that enables users to navigate and manipulate high-level semantic concepts (e.g., mood, style, or narrative tone) within an interactive thematic design plane. This interface bridges the gap between tacit creative intent and system control. In our exploratory study (N=6), participants engaged in divergent and convergent creative modes, often embracing unexpected results as inspiration or iteration cues. While they grounded their exploration in familiar themes, differing expectations of how themes mapped to outputs revealed a need for more explainable controls. Overall, ThematicPlane fosters expressive, iterative workflows and highlights new directions for intuitive, semantics-driven interaction in generative design tools.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç”Ÿæˆå¼äººå·¥æ™ºèƒ½(Generative AI)éš¾ä»¥å°†è¾“å‡ºä¸ç”¨æˆ·å¾®å¦™åˆ›æ„æ„å›¾(creative intent)å¯¹é½çš„é—®é¢˜ï¼Œæå‡ºäº†ThematicPlaneç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿå…è®¸ç”¨æˆ·åœ¨äº¤äº’å¼ä¸»é¢˜è®¾è®¡å¹³é¢(thematic design plane)ä¸­æ“ä½œæ°›å›´ã€é£æ ¼æˆ–å™äº‹åŸºè°ƒç­‰é«˜å±‚è¯­ä¹‰æ¦‚å¿µï¼Œæœ‰æ•ˆåœ°æ¶èµ·äº†éšæ€§åˆ›æ„æ„å›¾(tacit creative intent)ä¸ç³»ç»Ÿæ§åˆ¶ä¹‹é—´çš„æ¡¥æ¢ã€‚ä¸€é¡¹é’ˆå¯¹6åå‚ä¸è€…çš„æ¢ç´¢æ€§ç ”ç©¶(exploratory study)è¡¨æ˜ï¼Œç”¨æˆ·åœ¨å‘æ•£å’Œæ”¶æ•›çš„åˆ›æ„æ¨¡å¼ä¸­åˆ©ç”¨è¯¥ç•Œé¢è¿›è¡Œè¡¨è¾¾æ€§ã€è¿­ä»£å¼çš„å·¥ä½œæµç¨‹(iterative workflows)ï¼Œå¹¶èƒ½å°†æ„å¤–ç»“æœè½¬åŒ–ä¸ºçµæ„Ÿã€‚å°½ç®¡ç”¨æˆ·å¯¹ä¸»é¢˜æ˜ å°„çš„é¢„æœŸå·®å¼‚æ­ç¤ºäº†å¯¹æ›´å…·å¯è§£é‡Šæ€§(explainable)æ§åˆ¶çš„éœ€æ±‚ï¼Œä½†ThematicPlaneæ˜¾è‘—æå‡äº†è®¾è®¡çš„ç›´è§‚æ€§ï¼Œä¸ºè¯­ä¹‰é©±åŠ¨çš„ç”Ÿæˆå¼äº¤äº’å·¥å…·æŒ‡æ˜äº†æ–°æ–¹å‘ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06065v1",
      "published_date": "2025-08-08 06:57:14 UTC",
      "updated_date": "2025-08-08 06:57:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:18:10.846763+00:00"
    },
    {
      "arxiv_id": "2508.06064v1",
      "title": "A Generic Complete Anytime Beam Search for Optimal Decision Tree",
      "title_zh": "é¢å‘æœ€ä¼˜å†³ç­–æ ‘çš„é€šç”¨å®Œå¤‡éšæ—¶æŸæœç´¢ç®—æ³•",
      "authors": [
        "Harold SilvÃ¨re Kiossou",
        "Siegfried Nijssen",
        "Pierre Schaus"
      ],
      "abstract": "Finding an optimal decision tree that minimizes classification error is known to be NP-hard. While exact algorithms based on MILP, CP, SAT, or dynamic programming guarantee optimality, they often suffer from poor anytime behavior -- meaning they struggle to find high-quality decision trees quickly when the search is stopped before completion -- due to unbalanced search space exploration. To address this, several anytime extensions of exact methods have been proposed, such as LDS-DL8.5, Top-k-DL8.5, and Blossom, but they have not been systematically compared, making it difficult to assess their relative effectiveness. In this paper, we propose CA-DL8.5, a generic, complete, and anytime beam search algorithm that extends the DL8.5 framework and unifies some existing anytime strategies. In particular, CA-DL8.5 generalizes previous approaches LDS-DL8.5 and Top-k-DL8.5, by allowing the integration of various heuristics and relaxation mechanisms through a modular design. The algorithm reuses DL8.5's efficient branch-and-bound pruning and trie-based caching, combined with a restart-based beam search that gradually relaxes pruning criteria to improve solution quality over time. Our contributions are twofold: (1) We introduce this new generic framework for exact and anytime decision tree learning, enabling the incorporation of diverse heuristics and search strategies; (2) We conduct a rigorous empirical comparison of several instantiations of CA-DL8.5 -- based on Purity, Gain, Discrepancy, and Top-k heuristics -- using an anytime evaluation metric called the primal gap integral. Experimental results on standard classification benchmarks show that CA-DL8.5 using LDS (limited discrepancy) consistently provides the best anytime performance, outperforming both other CA-DL8.5 variants and the Blossom algorithm while maintaining completeness and optimality guarantees.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¯»æ‰¾æœ€å°åŒ–åˆ†ç±»è¯¯å·®çš„ Optimal Decision Tree è¿™ä¸€ NP-hard é—®é¢˜ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰ç²¾ç¡®ç®—æ³•åœ¨æœç´¢æå‰åœæ­¢æ—¶ Anytime è¡Œä¸ºè¾ƒå·®çš„å±€é™æ€§ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº† CA-DL8.5ï¼Œè¿™æ˜¯ä¸€ç§é€šç”¨ã€å®Œå¤‡ä¸”æ”¯æŒ Anytime ç‰¹æ€§çš„ Beam Search ç®—æ³•ï¼Œå®ƒæ‰©å±•äº† DL8.5 æ¡†æ¶å¹¶ç»Ÿä¸€äº†å¤šç§ç°æœ‰çš„ Anytime ç­–ç•¥ã€‚è¯¥æ¡†æ¶é‡‡ç”¨æ¨¡å—åŒ–è®¾è®¡ï¼Œå…è®¸é›†æˆå„ç§ Heuristics å’Œæ¾å¼›æœºåˆ¶ï¼Œå¹¶å¤ç”¨äº† DL8.5 é«˜æ•ˆçš„ Branch-and-bound å‰ªæä¸åŸºäº Trie çš„ç¼“å­˜æŠ€æœ¯ã€‚é€šè¿‡ç»“åˆåŸºäºé‡å¯çš„ Beam Search é€æ­¥æ”¾å®½å‰ªææ ‡å‡†ï¼Œè¯¥ç®—æ³•èƒ½éšæ—¶é—´æ¨ç§»ä¸æ–­æå‡è§£çš„è´¨é‡ã€‚ç ”ç©¶äººå‘˜å¼•å…¥äº† Primal Gap Integral æŒ‡æ ‡ï¼Œå¯¹åŸºäº Purityã€Gainã€Discrepancy å’Œ Top-k å¯å‘å¼ç®—æ³•çš„å¤šä¸ªå˜ä½“è¿›è¡Œäº†ä¸¥è°¨çš„å®è¯å¯¹æ¯”ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œé‡‡ç”¨ LDSï¼ˆLimited Discrepancyï¼‰çš„ CA-DL8.5 åœ¨æ ‡å‡†åˆ†ç±»åŸºå‡†æµ‹è¯•ä¸­æŒç»­å±•ç°å‡ºæœ€ä½³çš„ Anytime æ€§èƒ½ã€‚è¯¥æ–¹æ³•åœ¨è¶…è¶Š Blossom ç®—æ³•çš„åŒæ—¶ï¼Œä¾ç„¶èƒ½å¤Ÿä¿æŒç®—æ³•çš„å®Œå¤‡æ€§ä¸ Optimality ä¿è¯ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06064v1",
      "published_date": "2025-08-08 06:53:50 UTC",
      "updated_date": "2025-08-08 06:53:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:18:16.159349+00:00"
    },
    {
      "arxiv_id": "2508.06062v1",
      "title": "Don't Forget Imagination!",
      "title_zh": "è«å¿˜æƒ³è±¡åŠ›ï¼",
      "authors": [
        "Evgenii E. Vityaev",
        "Andrei Mantsivoda"
      ],
      "abstract": "Cognitive imagination is a type of imagination that plays a key role in human thinking. It is not a ``picture-in-the-head'' imagination. It is a faculty to mentally visualize coherent and holistic systems of concepts and causal links that serve as semantic contexts for reasoning, decision making and prediction. Our position is that the role of cognitive imagination is still greatly underestimated, and this creates numerous problems and diminishes the current capabilities of AI. For instance, when reasoning, humans rely on imaginary contexts to retrieve background info. They also constantly return to the context for semantic verification that their reasoning is still reasonable. Thus, reasoning without imagination is blind. This paper is a call for greater attention to cognitive imagination as the next promising breakthrough in artificial intelligence. As an instrument for simulating cognitive imagination, we propose semantic models -- a new approach to mathematical models that can learn, like neural networks, and are based on probabilistic causal relationships. Semantic models can simulate cognitive imagination because they ensure the consistency of imaginary contexts and implement a glass-box approach that allows the context to be manipulated as a holistic and coherent system of interrelated facts glued together with causal relations.",
      "tldr_zh": "è¯¥ç ”ç©¶æ·±å…¥æ¢è®¨äº†è®¤çŸ¥æƒ³è±¡åŠ›(Cognitive imagination)åœ¨äººç±»æ€ç»´ä¸­çš„æ ¸å¿ƒä½œç”¨ï¼Œå¼ºè°ƒå…¶å¹¶éç®€å•çš„å›¾åƒåŒ–æƒ³è±¡ï¼Œè€Œæ˜¯å¿ƒç†å¯è§†åŒ–è¿è´¯æ¦‚å¿µç³»ç»Ÿå’Œå› æœé“¾çš„èƒ½åŠ›ã€‚ä½œè€…æŒ‡å‡ºï¼Œå½“å‰äººå·¥æ™ºèƒ½(AI)å¯¹è®¤çŸ¥æƒ³è±¡åŠ›çš„ä¸¥é‡ä½ä¼°å¯¼è‡´æ¨ç†è¿‡ç¨‹ç¼ºä¹å¿…è¦çš„èƒŒæ™¯è¯­ä¹‰æ”¯æ’‘å’Œå®æ—¶éªŒè¯ï¼Œä½¿å¾—AIåœ¨å¤æ‚å†³ç­–å’Œé¢„æµ‹ä¸­è¡¨ç°å—é™ã€‚ä¸ºæ­¤ï¼Œè®ºæ–‡æå‡ºå°†è¯­ä¹‰æ¨¡å‹(semantic models)ä½œä¸ºæ¨¡æ‹Ÿè®¤çŸ¥æƒ³è±¡åŠ›çš„å·¥å…·ï¼Œè¿™æ˜¯ä¸€ç§åŸºäºæ¦‚ç‡å› æœå…³ç³»(probabilistic causal relationships)ä¸”å…·å¤‡ç±»ä¼¼ç¥ç»ç½‘ç»œå­¦ä¹ èƒ½åŠ›çš„æ–°å‹æ•°å­¦æ¨¡å‹ã€‚è¯­ä¹‰æ¨¡å‹é€šè¿‡é‡‡ç”¨ç»ç’ƒç›’(glass-box)æ–¹æ³•ï¼Œç¡®ä¿äº†è™šæ‹ŸèƒŒæ™¯çš„ä¸€è‡´æ€§å’Œè¿è´¯æ€§ï¼Œå…è®¸ç³»ç»Ÿå°†äº’ç›¸å…³è”çš„äº‹å®é€šè¿‡å› æœé€»è¾‘è¿›è¡Œæ•´ä½“æ€§æ•´åˆã€‚è¯¥ç ”ç©¶å‘¼åAIé¢†åŸŸå°†è®¤çŸ¥æƒ³è±¡åŠ›è§†ä¸ºå®ç°ä¸‹ä¸€ä»£çªç ´çš„å…³é”®ï¼Œé€šè¿‡å¢å¼ºæ¨¡å‹å¯¹å¤æ‚è¯­ä¹‰ç¯å¢ƒçš„æ¨¡æ‹Ÿèƒ½åŠ›æ¥æå‡äººå·¥æ™ºèƒ½çš„è®¤çŸ¥æ°´å¹³ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 2 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.06062v1",
      "published_date": "2025-08-08 06:50:43 UTC",
      "updated_date": "2025-08-08 06:50:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:18:24.739793+00:00"
    },
    {
      "arxiv_id": "2508.06060v1",
      "title": "LLMs for Resource Allocation: A Participatory Budgeting Approach to Inferring Preferences",
      "title_zh": "LLMs ç”¨äºèµ„æºåˆ†é…ï¼šä¸€ç§åŸºäºå‚ä¸å¼é¢„ç®—çš„åå¥½æ¨æ–­æ–¹æ³•",
      "authors": [
        "Sankarshan Damle",
        "Boi Faltings"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly expected to handle complex decision-making tasks, yet their ability to perform structured resource allocation remains underexplored. Evaluating their reasoning is also difficult due to data contamination and the static nature of existing benchmarks. We present a dual-purpose framework leveraging Participatory Budgeting (PB) both as (i) a practical setting for LLM-based resource allocation and (ii) an adaptive benchmark for evaluating their reasoning capabilities. We task LLMs with selecting project subsets under feasibility (e.g., budget) constraints via three prompting strategies: greedy selection, direct optimization, and a hill-climbing-inspired refinement. We benchmark LLMs' allocations against a utility-maximizing oracle. Interestingly, we also test whether LLMs can infer structured preferences from natural-language voter input or metadata, without explicit votes. By comparing allocations based on inferred preferences to those from ground-truth votes, we evaluate LLMs' ability to extract preferences from open-ended input. Our results underscore the role of prompt design and show that LLMs hold promise for mechanism design with unstructured inputs.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªåŸºäºå‚ä¸å¼é¢„ç®—(Participatory Budgeting)çš„åŒç”¨é€”æ¡†æ¶ï¼Œæ—¨åœ¨æ¢ç´¢å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨ç»“æ„åŒ–èµ„æºåˆ†é…ä»»åŠ¡ä¸­çš„å†³ç­–èƒ½åŠ›ã€‚è¯¥æ¡†æ¶æ—¢ä½œä¸ºLLMè¿›è¡Œèµ„æºåˆ†é…çš„å®è·µåœºæ™¯ï¼Œä¹Ÿä½œä¸ºè¯„ä¼°å…¶æ¨ç†èƒ½åŠ›çš„åŠ¨æ€åŸºå‡†ï¼Œæœ‰æ•ˆè§£å†³äº†ç°æœ‰åŸºå‡†æµ‹è¯•ä¸­å¸¸è§çš„æ•°æ®æ±¡æŸ“å’Œé™æ€æ€§é—®é¢˜ã€‚ç ”ç©¶è€…é€šè¿‡è´ªå©ªé€‰æ‹©(greedy selection)ã€ç›´æ¥ä¼˜åŒ–(direct optimization)å’Œå—çˆ¬å±±ç®—æ³•å¯å‘çš„ç»†åŒ–(hill-climbing-inspired refinement)ä¸‰ç§æç¤ºç­–ç•¥ï¼Œè¦æ±‚LLMsåœ¨é¢„ç®—ç­‰å¯è¡Œæ€§çº¦æŸä¸‹é€‰æ‹©é¡¹ç›®å­é›†ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜æµ‹è¯•äº†LLMsä»è‡ªç„¶è¯­è¨€æŠ•ç¥¨è¾“å…¥æˆ–å…ƒæ•°æ®ä¸­æ¨æ–­ç»“æ„åŒ–åå¥½çš„èƒ½åŠ›ï¼Œå¹¶å°†å…¶ä¸åŸºäºçœŸå®é€‰ç¥¨(ground-truth)çš„åˆ†é…ç»“æœä»¥åŠæ•ˆç”¨æœ€å¤§åŒ–é¢„æµ‹å™¨(utility-maximizing oracle)è¿›è¡Œå¯¹æ¯”ã€‚å®éªŒç»“æœå¼ºè°ƒäº†æç¤ºè¯è®¾è®¡(prompt design)åœ¨ä»»åŠ¡è¡¨ç°ä¸­çš„å…³é”®ä½œç”¨ï¼Œå¹¶è¯æ˜äº†LLMsåœ¨å¤„ç†éç»“æ„åŒ–è¾“å…¥ä»¥è¿›è¡Œæœºåˆ¶è®¾è®¡(mechanism design)æ–¹é¢å…·æœ‰å¹¿é˜”çš„åº”ç”¨å‰æ™¯ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Published in the Proceedings of the 28th European Conference on Artificial Intelligence (ECAI 2025)",
      "pdf_url": "https://arxiv.org/pdf/2508.06060v1",
      "published_date": "2025-08-08 06:45:07 UTC",
      "updated_date": "2025-08-08 06:45:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:18:21.290410+00:00"
    },
    {
      "arxiv_id": "2508.06588v2",
      "title": "Graph is a Natural Regularization: Revisiting Vector Quantization for Graph Representation Learning",
      "title_zh": "å›¾å³å¤©ç„¶æ­£åˆ™ï¼šé‡æ–°å®¡è§†é¢å‘å›¾è¡¨ç¤ºå­¦ä¹ çš„çŸ¢é‡é‡åŒ–",
      "authors": [
        "Zian Zhai",
        "Fan Li",
        "Xingyu Tan",
        "Xiaoyang Wang",
        "Wenjie Zhang"
      ],
      "abstract": "Vector Quantization (VQ) has recently emerged as a promising approach for learning discrete representations of graph-structured data. However, a fundamental challenge, i.e., codebook collapse, remains underexplored in the graph domain, significantly limiting the expressiveness and generalization of graph tokens.In this paper, we present the first empirical study showing that codebook collapse consistently occurs when applying VQ to graph data, even with mitigation strategies proposed in vision or language domains. To understand why graph VQ is particularly vulnerable to collapse, we provide a theoretical analysis and identify two key factors: early assignment imbalances caused by redundancy in graph features and structural patterns, and self-reinforcing optimization loops in deterministic VQ. To address these issues, we propose RGVQ, a novel framework that integrates graph topology and feature similarity as explicit regularization signals to enhance codebook utilization and promote token diversity. RGVQ introduces soft assignments via Gumbel-Softmax reparameterization, ensuring that all codewords receive gradient updates. In addition, RGVQ incorporates a structure-aware contrastive regularization to penalize the token co-assignments among dissimilar node pairs. Extensive experiments demonstrate that RGVQ substantially improves codebook utilization and consistently boosts the performance of state-of-the-art graph VQ backbones across multiple downstream tasks, enabling more expressive and transferable graph token representations.",
      "tldr_zh": "æœ¬ç ”ç©¶æ¢è®¨äº†å›¾è¡¨ç¤ºå­¦ä¹ ä¸­çš„Vector Quantization (VQ)æŠ€æœ¯ï¼Œå¹¶é¦–æ¬¡é€šè¿‡å®è¯ç ”ç©¶æ­ç¤ºäº†å³ä½¿é‡‡ç”¨è§†è§‰æˆ–è¯­è¨€é¢†åŸŸçš„ç¼“è§£ç­–ç•¥ï¼Œå›¾æ•°æ®åœ¨VQè¿‡ç¨‹ä¸­ä»ä¼šé¢‘ç¹å‡ºç°codebook collapseé—®é¢˜ã€‚ç†è®ºåˆ†æè¡¨æ˜ï¼Œå›¾ç‰¹å¾ä¸ç»“æ„æ¨¡å¼å†—ä½™å¯¼è‡´çš„æ—©æœŸåˆ†é…ä¸å¹³è¡¡ï¼Œä»¥åŠç¡®å®šæ€§VQä¸­çš„è‡ªå¢å¼ºä¼˜åŒ–å¾ªç¯ï¼Œæ˜¯å¯¼è‡´å›¾VQææ˜“å´©æºƒçš„å…³é”®å› ç´ ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†RGVQæ¡†æ¶ï¼Œå°†å›¾æ‹“æ‰‘ç»“æ„å’Œç‰¹å¾ç›¸ä¼¼åº¦ä½œä¸ºæ˜¾å¼æ­£åˆ™åŒ–ä¿¡å·ï¼Œä»¥æå‡ç æœ¬åˆ©ç”¨ç‡å¹¶ä¿ƒè¿›tokenå¤šæ ·æ€§ã€‚è¯¥æ¡†æ¶é€šè¿‡Gumbel-Softmaxé‡å‚æ•°åŒ–å¼•å…¥è½¯åˆ†é…æœºåˆ¶ï¼Œç¡®ä¿æ‰€æœ‰ç å­—éƒ½èƒ½è·å¾—æ¢¯åº¦æ›´æ–°ï¼Œå¹¶ç»“åˆç»“æ„æ„ŸçŸ¥çš„å¯¹æ¯”æ­£åˆ™åŒ–(structure-aware contrastive regularization)æ¥æƒ©ç½šä¸ç›¸ä¼¼èŠ‚ç‚¹å¯¹ä¹‹é—´çš„tokenå…±åŒåˆ†é…ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒRGVQæ˜¾è‘—æ”¹å–„äº†ç æœ¬åˆ©ç”¨ç‡ï¼Œå¹¶åœ¨å¤šä¸ªä¸‹æ¸¸ä»»åŠ¡ä¸­æå‡äº†ç°æœ‰å…ˆè¿›å›¾VQéª¨å¹²æ¨¡å‹çš„æ€§èƒ½ï¼Œå®ç°äº†æ›´å…·è¡¨è¾¾åŠ›å’Œå¯è¿ç§»æ€§çš„å›¾tokenè¡¨ç¤ºã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06588v2",
      "published_date": "2025-08-08 06:33:45 UTC",
      "updated_date": "2025-09-26 10:31:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:18:26.893028+00:00"
    },
    {
      "arxiv_id": "2508.06046v1",
      "title": "EvolvR: Self-Evolving Pairwise Reasoning for Story Evaluation to Enhance Generation",
      "title_zh": "EvolvRï¼šæ—¨åœ¨å¢å¼ºç”Ÿæˆçš„è‡ªè¿›åŒ–æˆå¯¹æ¨ç†æ•…äº‹è¯„ä¼°",
      "authors": [
        "Xinda Wang",
        "Zhengxu Hou",
        "Yangshijie Zhang",
        "Bingren Yan",
        "Zhibo Yang",
        "Xingsheng Zhang",
        "Luxi Xing",
        "Qiang Zhou",
        "Chen Zhang"
      ],
      "abstract": "Although the effectiveness of Large Language Models (LLMs) as judges (LLM-as-a-judge) has been validated, their performance remains limited in open-ended tasks, particularly in story evaluation. Accurate story evaluation is crucial not only for assisting human quality judgment but also for providing key signals to guide story generation. However, existing methods face a dilemma: prompt engineering for closed-source models suffers from poor adaptability, while fine-tuning approaches for open-source models lack the rigorous reasoning capabilities essential for story evaluation. To address this, we propose the Self-Evolving Pairwise Reasoning (EvolvR) framework. Grounded in pairwise comparison, the framework first self-synthesizes score-aligned Chain-of-Thought (CoT) data via a multi-persona strategy. To ensure data quality, these raw CoTs undergo a self-filtering process, utilizing multi-agents to guarantee their logical rigor and robustness. Finally, the evaluator trained on the refined data is deployed as a reward model to guide the story generation task. Experimental results demonstrate that our framework achieves state-of-the-art (SOTA) performance on three evaluation benchmarks including StoryER, HANNA and OpenMEVA. Furthermore, when served as a reward model, it significantly enhances the quality of generated stories, thereby fully validating the superiority of our self-evolving approach.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)ä½œä¸ºè¯„æµ‹è€…(LLM-as-a-judge)åœ¨æ•…äº‹è¯„ä¼°ç­‰å¼€æ”¾å¼ä»»åŠ¡ä¸­é€‚åº”æ€§å·®ä¸”æ¨ç†èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ï¼Œæå‡ºäº†EvolvRæ¡†æ¶ï¼Œä¸€ç§åŸºäºæˆå¯¹æ¯”è¾ƒ(Pairwise comparison)çš„è‡ªæˆ‘è¿›åŒ–æ¨ç†æ–¹æ³•ã€‚è¯¥æ¡†æ¶é¦–å…ˆé€šè¿‡å¤šè§’è‰²ç­–ç•¥(Multi-persona strategy)è‡ªæˆ‘åˆæˆä¸è¯„åˆ†ä¸€è‡´çš„é“¾å¼æ€ç»´(Chain-of-Thought, CoT)æ•°æ®ï¼Œå¹¶åˆ©ç”¨å¤šæ™ºèƒ½ä½“(Multi-agents)è¿›è¡Œè‡ªæˆ‘è¿‡æ»¤ä»¥ç¡®ä¿é€»è¾‘ä¸¥å¯†æ€§ã€‚è®­ç»ƒåçš„è¯„ä¼°å™¨è¢«éƒ¨ç½²ä¸ºå¥–åŠ±æ¨¡å‹(Reward model)ï¼Œç”¨äºå¼•å¯¼å’Œä¼˜åŒ–æ•…äº‹ç”Ÿæˆä»»åŠ¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒEvolvRåœ¨StoryERã€HANNAå’ŒOpenMEVAä¸‰ä¸ªåŸºå‡†æµ‹è¯•ä¸Šå‡è¾¾åˆ°äº†å½“å‰æœ€å…ˆè¿›(SOTA)çš„æ°´å¹³ã€‚è¯¥æ¡†æ¶ä¸ä»…æ˜¾è‘—æå‡äº†æ•…äº‹è¯„ä¼°çš„å‡†ç¡®æ€§ï¼Œè¿˜é€šè¿‡ä½œä¸ºå¥–åŠ±æ¨¡å‹å¤§å¹…æ”¹å–„äº†ç”Ÿæˆæ•…äº‹çš„è´¨é‡ï¼Œå……åˆ†éªŒè¯äº†è‡ªæˆ‘è¿›åŒ–æœºåˆ¶åœ¨æå‡å¼€æ”¾å¼æ–‡æœ¬è¯„ä¼°ä¸ç”Ÿæˆè´¨é‡æ–¹é¢çš„ä¼˜è¶Šæ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06046v1",
      "published_date": "2025-08-08 06:10:47 UTC",
      "updated_date": "2025-08-08 06:10:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:18:38.184569+00:00"
    },
    {
      "arxiv_id": "2508.06042v1",
      "title": "Society of Mind Meets Real-Time Strategy: A Hierarchical Multi-Agent Framework for Strategic Reasoning",
      "title_zh": "å¿ƒæ™ºç¤¾ä¼šé‡è§å®æ—¶ç­–ç•¥ï¼šä¸€ç§é¢å‘æˆ˜ç•¥æ¨ç†çš„åˆ†å±‚å¤šæ™ºèƒ½ä½“æ¡†æ¶",
      "authors": [
        "Daechul Ahn",
        "San Kim",
        "Jonghyun Choi"
      ],
      "abstract": "Large Language Models (LLMs) have recently demonstrated impressive action sequence prediction capabilities but often struggle with dynamic, long-horizon tasks such as real-time strategic games. In a game such as StarCraftII (SC2), agents need to manage resource constraints and adapt to evolving battlefield situations in a partially observable environment. This often overwhelms exisiting LLM-based approaches. To address these challenges, we propose a hierarchical multi-agent framework that employs specialized imitation learning agents under a meta-controller called Strategic Planner (SP). By expert demonstrations, each specialized agent learns a distinctive strategy, such as aerial support or defensive maneuvers, and produces coherent, structured multistep action sequences. The SP then orchestrates these proposals into a single, environmentally adaptive plan that ensures local decisions aligning with long-term strategies. We call this HIMA (Hierarchical Imitation Multi-Agent). We also present TEXTSCII-ALL, a comprehensive SC2 testbed that encompasses all race match combinations in SC2. Our empirical results show that HIMA outperforms state of the arts in strategic clarity, adaptability, and computational efficiency, underscoring the potential of combining specialized imitation modules with meta-level orchestration to develop more robust, general-purpose AI agents.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤„ç†ã€Šæ˜Ÿé™…äº‰éœ¸IIã€‹ï¼ˆStarCraft II, SC2ï¼‰ç­‰å®æ—¶æˆ˜ç•¥æ¸¸æˆæ—¶é•¿æ—¶ç¨‹åŠ¨æ€ä»»åŠ¡çš„å±€é™æ€§ï¼Œæå‡ºäº†åä¸º HIMA (Hierarchical Imitation Multi-Agent) çš„å±‚æ¬¡åŒ–å¤šæ™ºèƒ½ä½“æ¡†æ¶ã€‚è¯¥æ¡†æ¶åˆ©ç”¨ä¸“é—¨çš„æ¨¡ä»¿å­¦ä¹ ï¼ˆImitation Learningï¼‰æ™ºèƒ½ä½“åœ¨å…ƒæ§åˆ¶å™¨ Strategic Planner (SP) çš„åè°ƒä¸‹è¿ä½œï¼Œä½¿å„æ™ºèƒ½ä½“èƒ½ä»ä¸“å®¶æ¼”ç¤ºä¸­å­¦ä¹ ç‰¹å®šç­–ç•¥å¹¶ç”Ÿæˆç»“æ„åŒ–çš„å¤šæ­¥è¡ŒåŠ¨åºåˆ—ã€‚Strategic Planner è´Ÿè´£å°†è¿™äº›å±€éƒ¨ææ¡ˆç¼–æ’ä¸ºé€‚åº”ç¯å¢ƒä¸”ç¬¦åˆé•¿æœŸæˆ˜ç•¥çš„å•ä¸€è®¡åˆ’ï¼Œä»è€Œåœ¨éƒ¨åˆ†å¯è§‚æµ‹çš„ç¯å¢ƒä¸­å®ç°ç²¾å‡†çš„èµ„æºç®¡ç†å’Œæˆ˜æœ¯è°ƒæ•´ã€‚ç ”ç©¶åŒæ—¶æ¨å‡ºäº†æ¶µç›–æ‰€æœ‰ç§æ—å¯¹æˆ˜ç»„åˆçš„å…¨é¢æµ‹è¯•åŸºå‡† TEXTSCII-ALLã€‚å®éªŒç»“æœè¯æ˜ï¼ŒHIMA åœ¨ç­–ç•¥æ¸…æ™°åº¦ã€è‡ªé€‚åº”èƒ½åŠ›å’Œè®¡ç®—æ•ˆç‡ä¸Šå‡æ˜¾è‘—ä¼˜äºç°æœ‰æœ€å…ˆè¿›æŠ€æœ¯ã€‚è¿™ä¸€æˆæœå‡¸æ˜¾äº†å°†ä¸“é—¨åŒ–æ¨¡ä»¿æ¨¡å—ä¸å…ƒçº§ç¼–æ’ç›¸ç»“åˆåœ¨æ„å»ºç¨³å¥é€šç”¨ AI agents æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "COLM 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.06042v1",
      "published_date": "2025-08-08 05:57:12 UTC",
      "updated_date": "2025-08-08 05:57:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:18:56.588658+00:00"
    },
    {
      "arxiv_id": "2508.06041v4",
      "title": "DP-LLM: Runtime Model Adaptation with Dynamic Layer-wise Precision Assignment",
      "title_zh": "DP-LLMï¼šåŸºäºåŠ¨æ€é€å±‚ç²¾åº¦åˆ†é…çš„è¿è¡Œæ—¶æ¨¡å‹è‡ªé€‚åº”",
      "authors": [
        "Sangwoo Kwon",
        "Seong Hoon Seo",
        "Jae W. Lee",
        "Yeonhong Park"
      ],
      "abstract": "How can we effectively handle queries for on-device large language models (LLMs) with varying runtime constraints, such as latency and accuracy? Multi-scale quantization addresses this challenge by enabling memory-efficient runtime model adaptation of LLMs through the overlaying of multiple model variants quantized to different bitwidths. Meanwhile, an important question still remains open-ended: how can models be properly configured to match a target precision or latency? While mixed-precision offers a promising solution, we take this further by leveraging the key observation that the sensitivity of each layer dynamically changes across decoding steps. Building on this insight, we introduce DP-LLM, a novel mechanism that dynamically assigns precision to each layer based on input values. Experimental results across multiple models and benchmarks demonstrate that DP-LLM achieves a superior performance-latency trade-off, outperforming prior approaches.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†DP-LLMï¼Œä¸€ç§æ—¨åœ¨è§£å†³è®¾å¤‡ç«¯å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨ä¸åŒè¿è¡Œæ—¶çº¦æŸä¸‹ï¼ˆå¦‚å»¶è¿Ÿå’Œå‡†ç¡®æ€§ï¼‰è¿›è¡Œæœ‰æ•ˆæ¨¡å‹é€‚é…çš„æ–°å‹æœºåˆ¶ã€‚ç ”ç©¶è€…è§‚å¯Ÿåˆ°ï¼Œå¤§æ¨¡å‹çš„æ¯ä¸€å±‚åœ¨è§£ç è¿‡ç¨‹ä¸­çš„æ•æ„Ÿåº¦ä¼šéšè¾“å…¥åŠ¨æ€å˜åŒ–ï¼Œå› æ­¤DP-LLMèƒ½å¤Ÿæ ¹æ®å®æ—¶è¾“å…¥ä¸ºæ¯ä¸€å±‚åŠ¨æ€åˆ†é…ç²¾åº¦ã€‚è¯¥æ–¹æ³•è¿›ä¸€æ­¥æ‰©å±•äº†å¤šå°ºåº¦é‡åŒ–(multi-scale quantization)å’Œæ··åˆç²¾åº¦(mixed-precision)æŠ€æœ¯ï¼Œé€šè¿‡ç²¾ç»†åŒ–çš„å±‚çº§ç²¾åº¦ç®¡ç†ä¼˜åŒ–æ¨ç†æ•ˆç‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDP-LLMåœ¨å¤šä¸ªæ¨¡å‹å’ŒåŸºå‡†æµ‹è¯•ä¸­å‡å®ç°äº†ä¼˜äºä»¥å¾€æ–¹æ³•çš„æ€§èƒ½ä¸å»¶è¿Ÿæƒè¡¡(performance-latency trade-off)ã€‚è¿™ä¸€ç ”ç©¶ä¸ºæå‡è®¾å¤‡ç«¯LLMåœ¨å¤æ‚è¿è¡Œç¯å¢ƒä¸‹çš„çµæ´»æ€§å’Œéƒ¨ç½²æ•ˆç‡æä¾›äº†æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.06041v4",
      "published_date": "2025-08-08 05:57:04 UTC",
      "updated_date": "2025-12-08 07:41:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:19:07.990573+00:00"
    },
    {
      "arxiv_id": "2508.06038v2",
      "title": "Fourier-VLM: Compressing Vision Tokens in the Frequency Domain for Large Vision-Language Models",
      "title_zh": "Fourier-VLMï¼šé¢å‘å¤§è§†è§‰è¯­è¨€æ¨¡å‹çš„é¢‘åŸŸè§†è§‰ Token å‹ç¼©",
      "authors": [
        "Huanyu Wang",
        "Jushi Kai",
        "Haoli Bai",
        "Lu Hou",
        "Bo Jiang",
        "Ziwei He",
        "Zhouhan Lin"
      ],
      "abstract": "Vision-Language Models (VLMs) typically replace the predefined image placeholder token (<image>) in textual instructions with visual features from an image encoder, forming the input to a backbone Large Language Model (LLM). However, the large number of vision tokens significantly increases the context length, leading to high computational overhead and inference latency. While previous efforts mitigate this by selecting only important visual features or leveraging learnable queries to reduce token count, they often compromise performance or introduce substantial extra costs. In response, we propose Fourier-VLM, a simple yet efficient method that compresses visual representations in the frequency domain. Our approach is motivated by the observation that vision features output from the vision encoder exhibit concentrated energy in low-frequency components. Leveraging this, we apply a low-pass filter to the vision features using a two-dimensional Discrete Cosine Transform (DCT). Notably, the DCT is efficiently computed via the Fast Fourier Transform (FFT) operator with a time complexity of $\\mathcal{O}(n\\log n)$, minimizing the extra computational cost while introducing no additional parameters. Extensive experiments across various image-based benchmarks demonstrate that Fourier-VLM achieves competitive performance with strong generalizability across both LLaVA and Qwen-VL architectures. Crucially, it reduce inference FLOPs by up to 83.8% and boots generation speed by 31.2% compared to LLaVA-v1.5, highlighting the superior efficiency and practicality.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Vision-Language Models (VLMs) ä¸­è§†è§‰ token æ•°é‡è¿‡å¤šå¯¼è‡´çš„è®¡ç®—å¼€é”€å’Œæ¨ç†å»¶è¿Ÿé—®é¢˜ï¼Œæå‡ºäº† Fourier-VLMã€‚è¿™æ˜¯ä¸€ç§åœ¨é¢‘åŸŸä¸­å‹ç¼©è§†è§‰è¡¨ç¤ºçš„ç®€å•é«˜æ•ˆæ–¹æ³•ï¼Œæ—¨åœ¨å…‹æœç°æœ‰æŠ€æœ¯åœ¨æ€§èƒ½æŸå¤±æˆ–é¢å¤–æˆæœ¬æ–¹é¢çš„å±€é™æ€§ã€‚åŸºäºè§†è§‰ç‰¹å¾èƒ½é‡é›†ä¸­åœ¨ä½é¢‘åˆ†é‡çš„è§‚å¯Ÿï¼ŒFourier-VLM åˆ©ç”¨äºŒç»´ç¦»æ•£ä½™å¼¦å˜æ¢ (Discrete Cosine Transform, DCT) å¯¹è§†è§‰ç‰¹å¾åº”ç”¨ä½é€šæ»¤æ³¢å™¨ã€‚è¯¥å˜æ¢é€šè¿‡å¿«é€Ÿå‚…é‡Œå¶å˜æ¢ (Fast Fourier Transform, FFT) ç®—å­å®ç°ï¼Œå…·æœ‰ $\\mathcal{O}(n\\log n)$ çš„æ—¶é—´å¤æ‚åº¦ä¸”ä¸å¼•å…¥é¢å¤–å‚æ•°ã€‚å®éªŒè¯æ˜ï¼ŒFourier-VLM åœ¨ LLaVA å’Œ Qwen-VL æ¶æ„ä¸Šå‡è¡¨ç°å‡ºæå…·ç«äº‰åŠ›çš„æ€§èƒ½å’Œæ³›åŒ–èƒ½åŠ›ã€‚ä¸ LLaVA-v1.5 ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•æˆåŠŸå‡å°‘äº†é«˜è¾¾ 83.8% çš„æ¨ç† FLOPsï¼Œå¹¶å°†ç”Ÿæˆé€Ÿåº¦æå‡äº† 31.2%ï¼Œæ˜¾è‘—æé«˜äº†æ¨¡å‹çš„è¿è¡Œæ•ˆç‡ä¸å®ç”¨æ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.06038v2",
      "published_date": "2025-08-08 05:49:42 UTC",
      "updated_date": "2025-08-11 03:31:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:19:00.790246+00:00"
    },
    {
      "arxiv_id": "2508.14053v2",
      "title": "MAHL: Multi-Agent LLM-Guided Hierarchical Chiplet Design with Adaptive Debugging",
      "title_zh": "MAHLï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹å¼•å¯¼ä¸è‡ªé€‚åº”è°ƒè¯•çš„å¤šæ™ºèƒ½ä½“å±‚çº§åŒ–èŠ¯ç²’è®¾è®¡",
      "authors": [
        "Jinwei Tang",
        "Jiayin Qin",
        "Nuo Xu",
        "Pragnya Sudershan Nalla",
        "Yu Cao",
        "Yang",
        "Zhao",
        "Caiwen Ding"
      ],
      "abstract": "As program workloads (e.g., AI) increase in size and algorithmic complexity, the primary challenge lies in their high dimensionality, encompassing computing cores, array sizes, and memory hierarchies. To overcome these obstacles, innovative approaches are required. Agile chip design has already benefited from machine learning integration at various stages, including logic synthesis, placement, and routing. With Large Language Models (LLMs) recently demonstrating impressive proficiency in Hardware Description Language (HDL) generation, it is promising to extend their abilities to 2.5D integration, an advanced technique that saves area overhead and development costs. However, LLM-driven chiplet design faces challenges such as flatten design, high validation cost and imprecise parameter optimization, which limit its chiplet design capability. To address this, we propose MAHL, a hierarchical LLM-based chiplet design generation framework that features six agents which collaboratively enable AI algorithm-hardware mapping, including hierarchical description generation, retrieval-augmented code generation, diverseflow-based validation, and multi-granularity design space exploration. These components together enhance the efficient generation of chiplet design with optimized Power, Performance and Area (PPA). Experiments show that MAHL not only significantly improves the generation accuracy of simple RTL design, but also increases the generation accuracy of real-world chiplet design, evaluated by Pass@5, from 0 to 0.72 compared to conventional LLMs under the best-case scenario. Compared to state-of-the-art CLARIE (expert-based), MAHL achieves comparable or even superior PPA results under certain optimization objectives.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† MAHLï¼Œè¿™æ˜¯ä¸€ç§åŸºäºå¤§è¯­è¨€æ¨¡å‹ (LLM) æŒ‡å¯¼çš„å¤šæ™ºèƒ½ä½“å±‚æ¬¡åŒ– Chiplet è®¾è®¡æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰ LLM åœ¨ 2.5D é›†æˆè®¾è®¡ä¸­é¢ä¸´çš„æ‰å¹³åŒ–è®¾è®¡ã€é«˜éªŒè¯æˆæœ¬å’Œå‚æ•°ä¼˜åŒ–ä¸ç²¾ç¡®ç­‰æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶é€šè¿‡å…­ä¸ªæ™ºèƒ½ä½“çš„ååŒå·¥ä½œå®ç° AI ç®—æ³•ä¸ç¡¬ä»¶çš„æ˜ å°„ï¼Œæ ¸å¿ƒåŠŸèƒ½æ¶µç›–å±‚æ¬¡åŒ–æè¿°ç”Ÿæˆã€æ£€ç´¢å¢å¼ºä»£ç ç”Ÿæˆã€åŸºäºå¤šå…ƒæµçš„éªŒè¯ä»¥åŠå¤šç²’åº¦è®¾è®¡ç©ºé—´æ¢ç´¢ (DSE)ã€‚è¿™ç§å±‚æ¬¡åŒ–æ¶æ„èƒ½å¤Ÿæœ‰æ•ˆåœ°æå‡ Chiplet è®¾è®¡çš„ç”Ÿæˆæ•ˆç‡ï¼Œå¹¶å¯¹åŠŸè€—ã€æ€§èƒ½å’Œé¢ç§¯ (PPA) è¿›è¡Œé’ˆå¯¹æ€§ä¼˜åŒ–ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMAHL ä¸ä»…æ˜¾è‘—æé«˜äº†ç®€å• RTL è®¾è®¡çš„ç”Ÿæˆå‡†ç¡®ç‡ï¼Œåœ¨çœŸå®ä¸–ç•Œçš„ Chiplet è®¾è®¡è¯„ä¼°ä¸­ï¼Œå…¶ Pass@5 æŒ‡æ ‡ä»ä¼ ç»Ÿ LLM çš„ 0 æå‡è‡³ 0.72ã€‚æ­¤å¤–ï¼Œä¸ç›®å‰æœ€å…ˆè¿›çš„ä¸“å®¶çº§æ¡†æ¶ CLARIE ç›¸æ¯”ï¼ŒMAHL åœ¨ç‰¹å®šçš„ä¼˜åŒ–ç›®æ ‡ä¸‹å®ç°äº†ç›¸å½“ç”šè‡³æ›´ä¼˜çš„ PPA ç»“æœï¼Œè¯æ˜äº†å…¶åœ¨è‡ªåŠ¨åŒ–ç¡¬ä»¶è®¾è®¡é¢†åŸŸçš„åº”ç”¨æ½œåŠ›ã€‚",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14053v2",
      "published_date": "2025-08-08 05:47:31 UTC",
      "updated_date": "2025-10-09 01:12:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:19:10.789487+00:00"
    },
    {
      "arxiv_id": "2508.06034v1",
      "title": "Adaptive Heterogeneous Graph Neural Networks: Bridging Heterophily and Heterogeneity",
      "title_zh": "è‡ªé€‚åº”å¼‚è´¨å›¾ç¥ç»ç½‘ç»œï¼šè¿æ¥å¼‚é…æ€§ä¸å¼‚è´¨æ€§",
      "authors": [
        "Qin Chen",
        "Guojie Song"
      ],
      "abstract": "Heterogeneous graphs (HGs) are common in real-world scenarios and often exhibit heterophily. However, most existing studies focus on either heterogeneity or heterophily in isolation, overlooking the prevalence of heterophilic HGs in practical applications. Such ignorance leads to their performance degradation. In this work, we first identify two main challenges in modeling heterophily HGs: (1) varying heterophily distributions across hops and meta-paths; (2) the intricate and often heterophily-driven diversity of semantic information across different meta-paths. Then, we propose the Adaptive Heterogeneous Graph Neural Network (AHGNN) to tackle these challenges. AHGNN employs a heterophily-aware convolution that accounts for heterophily distributions specific to both hops and meta-paths. It then integrates messages from diverse semantic spaces using a coarse-to-fine attention mechanism, which filters out noise and emphasizes informative signals. Experiments on seven real-world graphs and twenty baselines demonstrate the superior performance of AHGNN, particularly in high-heterophily situations.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Adaptive Heterogeneous Graph Neural Network (AHGNN)ï¼Œæ—¨åœ¨è§£å†³ç°å®ä¸–ç•Œå¼‚è´¨å›¾(Heterogeneous Graphs)ä¸­å¼‚è´¨æ€§(Heterogeneity)ä¸å¼‚é…æ€§(Heterophily)å¹¶å­˜å¯¼è‡´çš„æ€§èƒ½ä¸‹é™é—®é¢˜ã€‚AHGNNé’ˆå¯¹ä¸åŒè·³æ•°(hops)å’Œå…ƒè·¯å¾„(meta-paths)ä¸­å¼‚é…æ€§åˆ†å¸ƒä¸ä¸€ï¼Œä»¥åŠè¯­ä¹‰ä¿¡æ¯å¤æ‚å¤šæ ·è¿™ä¸¤å¤§æŒ‘æˆ˜ï¼Œè®¾è®¡äº†å¼‚é…æ€§æ„ŸçŸ¥å·ç§¯(heterophily-aware convolution)è¿›è¡Œç²¾ç¡®å»ºæ¨¡ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨ç”±ç²—åˆ°ç²¾çš„æ³¨æ„åŠ›æœºåˆ¶(coarse-to-fine attention mechanism)æ¥æ•´åˆå¤šæ ·åŒ–çš„è¯­ä¹‰ç©ºé—´ä¿¡æ¯ï¼Œæœ‰æ•ˆè¿‡æ»¤å™ªå£°å¹¶å¼ºåŒ–å…³é”®ä¿¡å·ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒAHGNNåœ¨ä¸ƒä¸ªçœŸå®æ•°æ®é›†å’ŒäºŒåä¸ªåŸºçº¿æ¨¡å‹çš„å¯¹æ¯”ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå°¤å…¶æ˜¯åœ¨é«˜å¼‚é…æ€§(high-heterophily)åœºæ™¯ä¸‹å±•ç°äº†æ˜¾è‘—çš„æ€§èƒ½ä¼˜åŠ¿ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted tp CIKM 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.06034v1",
      "published_date": "2025-08-08 05:39:58 UTC",
      "updated_date": "2025-08-08 05:39:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:19:14.798022+00:00"
    },
    {
      "arxiv_id": "2508.06026v1",
      "title": "Temporal Self-Rewarding Language Models: Decoupling Chosen-Rejected via Past-Future",
      "title_zh": "æ—¶åºè‡ªæˆ‘å¥–åŠ±è¯­è¨€æ¨¡å‹ï¼šé€šè¿‡è¿‡å»ä¸æœªæ¥å®ç°ä¼˜é€‰é¡¹ä¸å¼ƒé€‰é¡¹çš„è§£è€¦",
      "authors": [
        "Yidong Wang",
        "Xin Wang",
        "Cunxiang Wang",
        "Junfeng Fang",
        "Qiufeng Wang",
        "Jianing Chu",
        "Xuran Meng",
        "Shuxun Yang",
        "Libo Qin",
        "Yue Zhang",
        "Wei Ye",
        "Shikun Zhang"
      ],
      "abstract": "Self-Rewarding Language Models propose an architecture in which the Large Language Models(LLMs) both generates responses and evaluates its own outputs via LLM-as-a-Judge prompting, dynamically improving its generative capabilities through iterative Direct Preference Optimization (DPO). However, our analysis reveals a critical limitation in existing Self-Rewarding paradigms: the synchronized improvement of chosen and rejected responses progressively narrows the representational difference between contrasting samples, undermining effective preference learning. We propose \\textbf{Temporal Self-Rewarding Language Models} that strategically coordinate past, present, and future model generations to sustain learning signals. Our dual-phase framework introduces: (1) \\textit{Anchored Rejection} - fixing rejected responses using the past initial model's outputs and (2) \\textit{Future-Guided Chosen} - dynamically curating chosen samples using next-generation model predictions. Extensive experiments across three model families (Llama, Qwen, Mistral) and different model sizes (Llama3B/8B/70B) demonstrate significant improvements when trained with our method compared to Self-Rewarding using same computation resources. For example, Llama3.1-8B reaches a 29.44 win rate on AlpacaEval 2.0 with our method, outperforming the Self-Rewarding baseline (19.69) by 9.75. Notably, our method also demonstrates superior out-of-distribution generalization across mathematical reasoning (GSM8K), knowledge-based QA (ARC, TruthfulQA), and code generation (HumanEval) tasks, even though we do not specifically collect such training data.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Self-Rewarding Language Models åœ¨è¿­ä»£è¿‡ç¨‹ä¸­é€‰å®š(chosen)ä¸æ‹’ç»(rejected)æ ·æœ¬é—´è¡¨å¾å·®å¼‚é€æ¸ç¼©å°ã€è¿›è€Œå‰Šå¼±åå¥½å­¦ä¹ æ•ˆæœçš„å±€é™æ€§ï¼Œæå‡ºäº† Temporal Self-Rewarding Language Models æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡ç­–ç•¥æ€§åœ°åè°ƒè¿‡å»ã€ç°åœ¨ä¸æœªæ¥æ¨¡å‹çš„ç”Ÿæˆå†…å®¹æ¥ç»´æŒæœ‰æ•ˆçš„å­¦ä¹ ä¿¡å·ï¼Œå…·ä½“å¼•å…¥äº†å›ºå®šè¿‡å»åˆå§‹æ¨¡å‹è¾“å‡ºä½œä¸ºæ‹’ç»æ ·æœ¬çš„ Anchored Rejectionï¼Œä»¥åŠåˆ©ç”¨ä¸‹ä¸€ä»£æ¨¡å‹é¢„æµ‹åŠ¨æ€ç­›é€‰é€‰å®šæ ·æœ¬çš„ Future-Guided Chosenã€‚åœ¨ Llamaã€Qwen å’Œ Mistral ç­‰å¤šç§æ¨¡å‹è§„æ¨¡ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„ Self-Rewarding åŸºçº¿ï¼Œä¾‹å¦‚ä½¿ Llama3.1-8B åœ¨ AlpacaEval 2.0 ä¸Šçš„èƒœç‡æå‡äº† 9.75%ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹åœ¨æ•°å­¦æ¨ç†(GSM8K)ã€çŸ¥è¯†é—®ç­”(ARC)å’Œä»£ç ç”Ÿæˆ(HumanEval)ç­‰åˆ†å¸ƒå¤–(out-of-distribution)ä»»åŠ¡ä¸­ä¹Ÿå±•ç¤ºäº†å“è¶Šçš„æ³›åŒ–èƒ½åŠ›ã€‚è¿™ä¸€æˆæœè¯æ˜äº†é€šè¿‡æ—¶åºè§£è€¦æ ·æœ¬å¯ä»¥æœ‰æ•ˆå¢å¼º Direct Preference Optimization (DPO) çš„å­¦ä¹ æ•ˆç‡ä¸æ¨¡å‹æ€§èƒ½ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.06026v1",
      "published_date": "2025-08-08 05:25:54 UTC",
      "updated_date": "2025-08-08 05:25:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:19:20.090386+00:00"
    },
    {
      "arxiv_id": "2508.06021v1",
      "title": "Improved Sub-Visible Particle Classification in Flow Imaging Microscopy via Generative AI-Based Image Synthesis",
      "title_zh": "é€šè¿‡åŸºäºç”Ÿæˆå¼äººå·¥æ™ºèƒ½çš„å›¾åƒåˆæˆæ”¹è¿›æµå¼æˆåƒæ˜¾å¾®æŠ€æœ¯ä¸­çš„äºšå¯è§é¢—ç²’åˆ†ç±»",
      "authors": [
        "Utku Ozbulak",
        "Michaela Cohrs",
        "Hristo L. Svilenov",
        "Joris Vankerschaver",
        "Wesley De Neve"
      ],
      "abstract": "Sub-visible particle analysis using flow imaging microscopy combined with deep learning has proven effective in identifying particle types, enabling the distinction of harmless components such as silicone oil from protein particles. However, the scarcity of available data and severe imbalance between particle types within datasets remain substantial hurdles when applying multi-class classifiers to such problems, often forcing researchers to rely on less effective methods. The aforementioned issue is particularly challenging for particle types that appear unintentionally and in lower numbers, such as silicone oil and air bubbles, as opposed to protein particles, where obtaining large numbers of images through controlled settings is comparatively straightforward. In this work, we develop a state-of-the-art diffusion model to address data imbalance by generating high-fidelity images that can augment training datasets, enabling the effective training of multi-class deep neural networks. We validate this approach by demonstrating that the generated samples closely resemble real particle images in terms of visual quality and structure. To assess the effectiveness of using diffusion-generated images in training datasets, we conduct large-scale experiments on a validation dataset comprising 500,000 protein particle images and demonstrate that this approach improves classification performance with no negligible downside. Finally, to promote open research and reproducibility, we publicly release both our diffusion models and the trained multi-class deep neural network classifiers, along with a straightforward interface for easy integration into future studies, at https://github.com/utkuozbulak/svp-generative-ai.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æµåŠ¨æˆåƒæ˜¾å¾®æŠ€æœ¯ (Flow Imaging Microscopy) åœ¨è¯†åˆ«äºšå¯è§é¢—ç²’æ—¶é¢ä¸´çš„æ•°æ®ç¨€ç¼ºåŠç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºç”Ÿæˆå¼äººå·¥æ™ºèƒ½çš„è§£å†³æ–¹æ¡ˆã€‚ç ”ç©¶å›¢é˜Ÿå¼€å‘äº†ä¸€ç§å…ˆè¿›çš„æ‰©æ•£æ¨¡å‹ (Diffusion Model)ï¼Œé€šè¿‡ç”Ÿæˆé«˜ä¿çœŸçš„åˆæˆå›¾åƒæ¥å¢å¼ºè®­ç»ƒæ•°æ®é›†ï¼Œä»è€Œä¼˜åŒ–å¤šåˆ†ç±»æ·±å±‚ç¥ç»ç½‘ç»œçš„è®­ç»ƒæ•ˆæœã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œç”Ÿæˆçš„æ ·æœ¬åœ¨è§†è§‰è´¨é‡å’Œç»“æ„ä¸Šä¸çœŸå®é¢—ç²’é«˜åº¦ç›¸ä¼¼ï¼Œåœ¨åŒ…å«50ä¸‡å¼ å›¾åƒçš„å¤§è§„æ¨¡éªŒè¯é›†ä¸Šçš„æµ‹è¯•è¯æ˜è¯¥æ–¹æ³•æ˜¾è‘—æå‡äº†åˆ†ç±»æ€§èƒ½ã€‚æ­¤å¤–ï¼Œç ”ç©¶è€…å…¬å¼€äº†å…¶æ‰©æ•£æ¨¡å‹å’Œè®­ç»ƒå¥½çš„åˆ†ç±»å™¨æºä»£ç ï¼Œå¹¶æä¾›äº†æ˜“äºé›†æˆçš„æ¥å£ï¼Œä»¥ä¿ƒè¿›è¯¥é¢†åŸŸçš„ç ”ç©¶å¼€æ”¾æ€§ä¸ç»“æœå¯é‡ç°æ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06021v1",
      "published_date": "2025-08-08 05:15:02 UTC",
      "updated_date": "2025-08-08 05:15:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:19:27.487617+00:00"
    },
    {
      "arxiv_id": "2508.06016v1",
      "title": "Crisp Attention: Regularizing Transformers via Structured Sparsity",
      "title_zh": "Crisp Attentionï¼šé€šè¿‡ç»“æ„åŒ–ç¨€ç–å®ç° Transformer æ­£åˆ™åŒ–",
      "authors": [
        "Sagar Gandhi",
        "Vishal Gandhi"
      ],
      "abstract": "The quadratic computational cost of the self-attention mechanism is a primary challenge in scaling Transformer models. While attention sparsity is widely studied as a technique to improve computational efficiency, it is almost universally assumed to come at the cost of model accuracy. In this paper, we report a surprising counter-example to this common wisdom. By introducing structured, post-hoc sparsity to the attention mechanism of a DistilBERT model during fine-tuning on the SST-2 sentiment analysis task, we find that model accuracy improves significantly. Our model with 80\\% attention sparsity achieves a validation accuracy of 91.59\\%, a 0.97\\% absolute improvement over the dense baseline. We hypothesize that this phenomenon is due to sparsity acting as a powerful implicit regularizer, preventing the model from overfitting by forcing it to make predictions with a more constrained and robust set of features. Our work recasts attention sparsity not just as a tool for computational efficiency, but as a potential method for improving the generalization and performance of Transformer models.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Crisp Attentionï¼Œä¸€ç§é€šè¿‡ç»“æ„åŒ–ç¨€ç–æ€§(Structured Sparsity)å¯¹ Transformer æ¨¡å‹è¿›è¡Œæ­£åˆ™åŒ–çš„æ–¹æ³•ã€‚å°½ç®¡ä¼ ç»Ÿè§‚ç‚¹è®¤ä¸ºæ³¨æ„åŠ›æœºåˆ¶çš„ç¨€ç–åŒ–é€šå¸¸ä¼šä»¥ç‰ºç‰²ç²¾åº¦ä¸ºä»£ä»·æ¥æ¢å–æ•ˆç‡ï¼Œä½†è¯¥ç ”ç©¶å‘ç°äº†ä¸€ä¸ªæ˜¾è‘—çš„åä¾‹ã€‚ç ”ç©¶äººå‘˜åœ¨ SST-2 æƒ…æ„Ÿåˆ†æä»»åŠ¡çš„å¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œå‘ DistilBERT æ¨¡å‹çš„æ³¨æ„åŠ›æœºåˆ¶å¼•å…¥äº†ç»“æ„åŒ–çš„äº‹åç¨€ç–æ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨æ³¨æ„åŠ›ç¨€ç–åº¦è¾¾åˆ° 80% çš„æƒ…å†µä¸‹ï¼Œæ¨¡å‹çš„éªŒè¯å‡†ç¡®ç‡è¾¾åˆ° 91.59%ï¼Œç›¸è¾ƒäºå¯†é›†åŸºçº¿æ¨¡å‹å®ç°äº† 0.97% çš„ç»å¯¹æå‡ã€‚ä½œè€…æ¨æµ‹è¿™ä¸€ç°è±¡æºäºç¨€ç–æ€§ä½œä¸ºä¸€ç§å¼ºå¤§çš„éšå¼æ­£åˆ™åŒ–(Implicit Regularizer)ï¼Œé€šè¿‡å¼ºè¿«æ¨¡å‹åˆ©ç”¨æ›´å—é™ä¸”ç¨³å¥çš„ç‰¹å¾é›†åˆæ¥é˜²æ­¢è¿‡æ‹Ÿåˆã€‚è¯¥å·¥ä½œå°†æ³¨æ„åŠ›ç¨€ç–æ€§é‡æ–°å®šä¹‰ä¸ºä¸€ç§æå‡ Transformer æ¨¡å‹æ³›åŒ–èƒ½åŠ›å’Œæ€§èƒ½çš„æ½œåœ¨æ‰‹æ®µï¼Œè€Œä¸ä»…ä»…æ˜¯æé«˜è®¡ç®—æ•ˆç‡çš„å·¥å…·ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06016v1",
      "published_date": "2025-08-08 05:04:28 UTC",
      "updated_date": "2025-08-08 05:04:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:19:27.194952+00:00"
    },
    {
      "arxiv_id": "2508.09192v1",
      "title": "Diffusion LLMs Can Do Faster-Than-AR Inference via Discrete Diffusion Forcing",
      "title_zh": "æ‰©æ•£å¤§è¯­è¨€æ¨¡å‹åˆ©ç”¨ç¦»æ•£æ‰©æ•£å¼ºè¿«å®ç°è¶…è¶Šè‡ªå›å½’çš„å¿«é€Ÿæ¨ç†",
      "authors": [
        "Xu Wang",
        "Chenkai Xu",
        "Yijie Jin",
        "Jiachun Jin",
        "Hao Zhang",
        "Zhijie Deng"
      ],
      "abstract": "Diffusion Large Language Models (dLLMs) have emerged as a promising alternative to autoregressive (AR) LLMs for text generation, with the potential to decode multiple tokens in a single iteration. However, none of the existing open-source dLLMs have achieved superior inference speed over AR LLMs of similar size. This paper breaks this barrier based on a simple and effective strategy named discrete diffusion forcing (D2F). D2F equips dLLMs with two key capabilities: (1) block-wise autoregressive generation to enable KV cache utilization; (2) prediction of following tokens without requiring completion of prior blocks for inter-block parallel decoding. In this way, the vanilla dLLMs are refurbished into an AR-diffusion hybrid paradigm for efficient inference. D2F can be implemented with an asymmetric distillation process based on pre-trained dLLMs. We further propose a pipelined parallel decoding algorithm, which enables a trade-off between efficiency and efficacy. Empirically, D2F dLLMs achieve more than $\\mathbf{2.5\\times}$ inference speed than LLaMA3 and Qwen2.5 on GSM8K. Compared to vanilla dLLMs like LLaDA and Dream, the acceleration can be more than $\\mathbf{50\\times}$ while maintaining comparable output quality. The code is available at https://github.com/zhijie-group/Discrete-Diffusion-Forcing.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ‰©æ•£å¤§è¯­è¨€æ¨¡å‹(dLLMs)æ¨ç†é€Ÿåº¦éš¾ä»¥è¶…è¶Šè‡ªå›å½’(AR)æ¨¡å‹çš„é—®é¢˜ï¼Œæå‡ºäº†ç¦»æ•£æ‰©æ•£å¼ºåˆ¶(Discrete Diffusion Forcing, D2F)ç­–ç•¥ã€‚D2Fé€šè¿‡å—çŠ¶è‡ªå›å½’ç”Ÿæˆå®ç°KVç¼“å­˜åˆ©ç”¨ï¼Œå¹¶å…è®¸åœ¨ä¸å®Œæˆå‰ç½®å—çš„æƒ…å†µä¸‹é¢„æµ‹åç»­æ ‡è®°ï¼Œä»è€Œå®ç°äº†é«˜æ•ˆçš„è·¨å—å¹¶è¡Œè§£ç ã€‚è¯¥ç­–ç•¥å°†ä¼ ç»Ÿçš„dLLMsè½¬å˜ä¸ºä¸€ç§ARä¸æ‰©æ•£æ··åˆçš„æ¨ç†èŒƒå¼ï¼Œå¹¶åˆ©ç”¨éå¯¹ç§°è’¸é¦(Asymmetric Distillation)æŠ€æœ¯ä»é¢„è®­ç»ƒæ¨¡å‹ä¸­æå–èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜æå‡ºäº†æµæ°´çº¿å¹¶è¡Œè§£ç ç®—æ³•ï¼Œä»¥çµæ´»å¹³è¡¡æ¨ç†æ•ˆç‡ä¸ç”Ÿæˆæ•ˆæœã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒD2F dLLMsåœ¨GSM8Kæ•°æ®é›†ä¸Šçš„æ¨ç†é€Ÿåº¦æ¯”LLaMA3å’ŒQwen2.5å¿«2.5å€ä»¥ä¸Šã€‚ç›¸æ¯”LLaDAå’ŒDreamç­‰åŸå§‹dLLMsæ¨¡å‹ï¼ŒD2Fåœ¨ä¿æŒç›¸å½“è¾“å‡ºè´¨é‡çš„åŒæ—¶å®ç°äº†è¶…è¿‡50å€çš„åŠ é€Ÿï¼Œæœ‰æ•ˆæ‰“ç ´äº†æ‰©æ•£æ¨¡å‹åœ¨æ–‡æœ¬ç”Ÿæˆé¢†åŸŸå¤§è§„æ¨¡åº”ç”¨çš„æ•ˆç‡ç“¶é¢ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09192v1",
      "published_date": "2025-08-08 04:51:37 UTC",
      "updated_date": "2025-08-08 04:51:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:19:30.046494+00:00"
    },
    {
      "arxiv_id": "2508.19251v1",
      "title": "MuSpike: A Benchmark and Evaluation Framework for Symbolic Music Generation with Spiking Neural Networks",
      "title_zh": "MuSpikeï¼šåŸºäºè„‰å†²ç¥ç»ç½‘ç»œçš„ç¬¦å·éŸ³ä¹ç”ŸæˆåŸºå‡†ä¸è¯„ä¼°æ¡†æ¶",
      "authors": [
        "Qian Liang",
        "Menghaoran Tang",
        "Yi Zeng"
      ],
      "abstract": "Symbolic music generation has seen rapid progress with artificial neural networks, yet remains underexplored in the biologically plausible domain of spiking neural networks (SNNs), where both standardized benchmarks and comprehensive evaluation methods are lacking. To address this gap, we introduce MuSpike, a unified benchmark and evaluation framework that systematically assesses five representative SNN architectures (SNN-CNN, SNN-RNN, SNN-LSTM, SNN-GAN and SNN-Transformer) across five typical datasets, covering tonal, structural, emotional, and stylistic variations. MuSpike emphasizes comprehensive evaluation, combining established objective metrics with a large-scale listening study. We propose new subjective metrics, targeting musical impression, autobiographical association, and personal preference, that capture perceptual dimensions often overlooked in prior work. Results reveal that (1) different SNN models exhibit distinct strengths across evaluation dimensions; (2) participants with different musical backgrounds exhibit diverse perceptual patterns, with experts showing greater tolerance toward AI-composed music; and (3) a noticeable misalignment exists between objective and subjective evaluations, highlighting the limitations of purely statistical metrics and underscoring the value of human perceptual judgment in assessing musical quality. MuSpike provides the first systematic benchmark and systemic evaluation framework for SNN models in symbolic music generation, establishing a solid foundation for future research into biologically plausible and cognitively grounded music generation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†MuSpikeï¼Œè¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹Spiking Neural Networks (SNN)åœ¨ç¬¦å·éŸ³ä¹ç”Ÿæˆé¢†åŸŸçš„ç»Ÿä¸€åŸºå‡†å’Œè¯„ä¼°æ¡†æ¶ã€‚è¯¥æ¡†æ¶ç³»ç»Ÿåœ°è¯„ä¼°äº†äº”ç§ä»£è¡¨æ€§çš„SNNæ¶æ„ï¼ŒåŒ…æ‹¬SNN-CNNã€SNN-RNNã€SNN-LSTMã€SNN-GANå’ŒSNN-Transformerï¼Œæ¶µç›–äº†éŸ³è°ƒã€ç»“æ„ã€æƒ…æ„Ÿå’Œé£æ ¼ç­‰å¤šç»´åº¦çš„äº”ä¸ªæ•°æ®é›†ã€‚MuSpikeç»“åˆäº†ç°æœ‰çš„å®¢è§‚æŒ‡æ ‡ä¸å¤§è§„æ¨¡çš„äººç±»å¬åŠ›ç ”ç©¶ï¼Œå¹¶æå‡ºäº†é’ˆå¯¹éŸ³ä¹å°è±¡ã€è‡ªä¼ å¼å…³è”å’Œä¸ªäººåå¥½çš„æ–°å‹ä¸»è§‚è¯„ä»·æŒ‡æ ‡ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œä¸åŒSNNæ¨¡å‹åœ¨ä¸åŒè¯„ä¼°ç»´åº¦ä¸Šå„å…·ä¼˜åŠ¿ï¼Œä¸”å…·æœ‰ä¸åŒèƒŒæ™¯çš„å‚ä¸è€…åœ¨æ„ŸçŸ¥æ¨¡å¼ä¸Šå­˜åœ¨å·®å¼‚ï¼Œå…¶ä¸­ä¸“å®¶å¯¹AIåˆ›ä½œçš„éŸ³ä¹è¡¨ç°å‡ºæ›´é«˜çš„åŒ…å®¹åº¦ã€‚å®éªŒè¿˜æ­ç¤ºäº†å®¢è§‚ä¸ä¸»è§‚è¯„ä»·ä¹‹é—´å­˜åœ¨æ˜æ˜¾çš„ä¸ä¸€è‡´æ€§ï¼Œå¼ºè°ƒäº†åœ¨è¯„ä¼°éŸ³ä¹è´¨é‡æ—¶å•çº¯ä¾èµ–ç»Ÿè®¡æŒ‡æ ‡çš„å±€é™æ€§ä»¥åŠäººç±»æ„ŸçŸ¥åˆ¤æ–­çš„ä»·å€¼ã€‚ä½œä¸ºé¦–ä¸ªé’ˆå¯¹SNNç¬¦å·éŸ³ä¹ç”Ÿæˆçš„ç³»ç»ŸåŒ–åŸºå‡†ï¼ŒMuSpikeä¸ºæœªæ¥å¼€å‘ç”Ÿç‰©å­¦åˆç†ä¸”å…·æœ‰è®¤çŸ¥åŸºç¡€çš„éŸ³ä¹ç”Ÿæˆæ¨¡å‹å¥ å®šäº†é‡è¦åŸºç¡€ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.19251v1",
      "published_date": "2025-08-08 04:43:38 UTC",
      "updated_date": "2025-08-08 04:43:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:19:36.861972+00:00"
    },
    {
      "arxiv_id": "2508.06585v2",
      "title": "CountQA: How Well Do MLLMs Count in the Wild?",
      "title_zh": "CountQAï¼šå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨çœŸå®åœºæ™¯ä¸‹çš„è®¡æ•°è¡¨ç°å¦‚ä½•ï¼Ÿ",
      "authors": [
        "Jayant Sravan Tamarapalli",
        "Rynaa Grover",
        "Nilay Pande",
        "Sahiti Yerramilli"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) demonstrate remarkable fluency in understanding visual scenes, yet they exhibit a critical lack in a fundamental cognitive skill: object counting. This blind spot severely limits their reliability in real-world applications. To date, this capability has been largely unevaluated in complex scenarios, as existing benchmarks either feature sparse object densities or are confined to specific visual domains, failing to test models under realistic conditions. Addressing this gap, we introduce CountQA, a challenging new benchmark designed to probe this deficiency. Comprising over 1,500 question-answer pairs, CountQA features real-world images with high object density, clutter, and occlusion. We investigate this weakness by evaluating 15 prominent MLLMs on the CountQA benchmark and reveal that the top-performing model achieves a mere 42.9% accuracy, with performance declining as object counts rise. By providing a dedicated benchmark to diagnose and rectify this core weakness, CountQA paves the way for a new generation of MLLMs that are not only descriptively fluent but also numerically grounded and spatially aware. We will open-source the dataset and code upon paper acceptance to foster further research.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ (MLLMs) åœ¨å¤„ç†ç°å®åœºæ™¯æ—¶è¡¨ç°å‡ºçš„æ ¸å¿ƒè®¤çŸ¥ç¼ºé™·â€”â€”ç‰©ä½“è®¡æ•°èƒ½åŠ›ä¸è¶³è¿›è¡Œäº†æ·±å…¥æ¢è®¨ã€‚ä¸ºå¡«è¡¥ç°æœ‰åŸºå‡†æµ‹è¯•åœ¨ç‰©ä½“å¯†åº¦å’Œè§†è§‰é¢†åŸŸè¦†ç›–ä¸Šçš„ç©ºç™½ï¼Œä½œè€…æå‡ºäº† CountQAï¼Œä¸€ä¸ªä¸“é—¨ç”¨äºæ¢æµ‹è¿™ä¸€ç¼ºé™·çš„æ–°å‹æŒ‘æˆ˜æ€§åŸºå‡†æµ‹è¯• (benchmark)ã€‚CountQA åŒ…å«è¶…è¿‡ 1,500 ä¸ªé—®ç­”å¯¹ï¼Œå…¶é€‰å–çš„ç°å®ä¸–ç•Œå›¾åƒå…·æœ‰é«˜ç‰©ä½“å¯†åº¦ã€èƒŒæ™¯æ‚ä¹±å’Œç‰©ä½“é®æŒ¡ç­‰å¤æ‚ç‰¹å¾ã€‚é€šè¿‡å¯¹ 15 ä¸ªä¸»æµ MLLMs çš„è¯„ä¼°å‘ç°ï¼Œè¡¨ç°æœ€ä½³çš„æ¨¡å‹åœ¨ CountQA ä¸Šçš„å‡†ç¡®ç‡ä»…ä¸º 42.9%ï¼Œä¸”æ€§èƒ½éšç€ç‰©ä½“æ•°é‡çš„å¢åŠ è€Œæ˜¾è‘—ä¸‹é™ã€‚CountQA çš„æå‡ºä¸ºè¯Šæ–­å¹¶ä¿®æ­£æ¨¡å‹åœ¨æ•°å€¼åŸºç¡€ (numerically grounded) å’Œç©ºé—´æ„è¯† (spatially aware) æ–¹é¢çš„æ ¸å¿ƒå¼±ç‚¹æä¾›äº†é‡è¦å·¥å…·ï¼Œæ—¨åœ¨æ¨åŠ¨ä¸‹ä¸€ä»£æ›´å…·å¯é æ€§çš„ MLLMs ç ”å‘ã€‚",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06585v2",
      "published_date": "2025-08-08 04:23:04 UTC",
      "updated_date": "2025-09-09 04:46:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:19:58.446610+00:00"
    },
    {
      "arxiv_id": "2509.25193v1",
      "title": "Devstral: Fine-tuning Language Models for Coding Agent Applications",
      "title_zh": "Devstralï¼šé¢å‘ä»£ç æ™ºèƒ½ä½“åº”ç”¨çš„è¯­è¨€æ¨¡å‹å¾®è°ƒ",
      "authors": [
        "Abhinav Rastogi",
        "Adam Yang",
        "Albert Q. Jiang",
        "Alexander H. Liu",
        "Alexandre Sablayrolles",
        "AmÃ©lie HÃ©liou",
        "AmÃ©lie Martin",
        "Anmol Agarwal",
        "Andy Ehrenberg",
        "Andy Lo",
        "Antoine Roux",
        "Arthur Darcet",
        "Arthur Mensch",
        "Baptiste Bout",
        "Baptiste RoziÃ¨re",
        "Baudouin De Monicault",
        "Chris Bamford",
        "Christian Wallenwein",
        "Christophe Renaudin",
        "ClÃ©mence Lanfranchi",
        "ClÃ©ment Denoix",
        "Corentin Barreau",
        "Darius Dabert Devon Mizelle",
        "Diego de las Casas",
        "Elliot Chane-Sane",
        "Emilien Fugier",
        "Emma Bou Hanna",
        "Gabrielle Berrada",
        "Gauthier Delerce",
        "Gauthier Guinet",
        "Georgii Novikov",
        "Graham Neubig",
        "Guillaume Lample",
        "Guillaume Martin",
        "Himanshu Jaju",
        "Jan Ludziejewski",
        "Jason Rute",
        "Jean-Malo Delignon",
        "JeanHadrien Chabran",
        "Joachim Studnia",
        "Joep Barmentlo",
        "Jonas Amar",
        "Josselin Somerville Roberts",
        "Julien Denize",
        "Karan Saxena",
        "Karmesh Yadav",
        "Kartik Khandelwal",
        "Khyathi Raghavi Chandu",
        "Kush Jain",
        "LÃ©lio Renard Lavaud",
        "LÃ©onard Blier",
        "Lingxiao Zhao",
        "Louis Martin",
        "Lucile Saulnier",
        "Luyu Gao",
        "Marie Pellat",
        "Mathilde Guillaumin",
        "Mathis Felardos",
        "Matthieu Dinot",
        "Maxime Darrin",
        "Maximilian Augustin",
        "MickaÃ«l Seznec",
        "Neha Gupta",
        "Nikhil Raghuraman",
        "Olivier Duchenne",
        "Patricia Wang",
        "Patrick von Platen",
        "Patryk Saffer",
        "Paul Jacob",
        "Paul Wambergue",
        "Paula Kurylowicz",
        "PhilomÃ¨ne Chagniot",
        "Pierre Stock",
        "Pravesh Agrawal",
        "RÃ©mi Delacourt",
        "Roman Soletskyi",
        "Romain Sauvestre",
        "Sagar Vaze",
        "Sanchit Gandhi",
        "Sandeep Subramanian",
        "Shashwat Dalal",
        "Siddharth Gandhi",
        "Soham Ghosh",
        "Srijan Mishra",
        "Sumukh Aithal",
        "Szymon Antoniak",
        "Teven Le Scao",
        "Thibaut Lavril",
        "Thibault Schueller",
        "Thomas Foubert",
        "Thomas Robert",
        "Thomas Wang",
        "TimothÃ©e Lacroix",
        "Tom Bewley",
        "Valeriia Nemychnikova",
        "Victor Paltz",
        "Virgile Richard",
        "Wen-Ding Li",
        "William Marshall",
        "Xingyao Wang",
        "Xuanyu Zhang",
        "Yihan Wan",
        "Yunhao Tang"
      ],
      "abstract": "We introduce Devstral-Small, a lightweight open source model for code agents with the best performance among models below 100B size. In this technical report, we give an overview of how we design and develop a model and craft specializations in agentic software development. The resulting model, Devstral-Small is a small 24B model, fast and easy to serve. Despite its size, Devstral-Small still attains competitive performance compared to models more than an order of magnitude larger.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Devstral-Smallï¼Œè¿™æ˜¯ä¸€æ¬¾ä¸“ä¸º Coding Agent åº”ç”¨è®¾è®¡çš„è½»é‡çº§å¼€æºæ¨¡å‹ã€‚ä½œä¸ºä¸€ä¸ªä»…æœ‰ 24B å‚æ•°è§„æ¨¡çš„å°å‹æ¨¡å‹ï¼Œå®ƒåœ¨ 100B ä»¥ä¸‹è§„æ¨¡çš„æ‰€æœ‰æ¨¡å‹ä¸­å±•ç°å‡ºäº†é¡¶å°–çš„æ€§èƒ½è¡¨ç°ã€‚è¯¥æŠ¥å‘Šè¯¦ç»†ä»‹ç»äº†æ¨¡å‹çš„è®¾è®¡ä¸å¼€å‘è¿‡ç¨‹ï¼Œå¹¶å±•ç¤ºäº†å¦‚ä½•åœ¨ Agentic Software Development é¢†åŸŸæ„å»ºä¸“é—¨åŒ–èƒ½åŠ›ã€‚Devstral-Small å…·å¤‡è¿è¡Œé€Ÿåº¦å¿«ä¸”æ˜“äºéƒ¨ç½²çš„ç‰¹ç‚¹ï¼Œä½¿å…¶åœ¨å®é™…åº”ç”¨ä¸­æ›´å…·ä¼˜åŠ¿ã€‚å°½ç®¡å…¶ä½“ç§¯è¾ƒå°ï¼Œä½†åœ¨æ€§èƒ½ä¸Šä»èƒ½ä¸å‚æ•°é‡æ¯”å…¶å¤§ä¸€ä¸ªæ•°é‡çº§ä»¥ä¸Šçš„æ¨¡å‹ç›¸åª²ç¾ã€‚è¯¥æ¨¡å‹çš„æ¨å‡ºä¸ºå¼€å‘é«˜æ•ˆã€å¯æ‰©å±•çš„ç¼–ç¨‹æ™ºèƒ½ä½“æä¾›äº†å¼ºæœ‰åŠ›çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25193v1",
      "published_date": "2025-08-08 04:21:22 UTC",
      "updated_date": "2025-08-08 04:21:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:20:07.184251+00:00"
    },
    {
      "arxiv_id": "2508.06000v1",
      "title": "Hand by Hand: LLM Driving EMS Assistant for Operational Skill Learning",
      "title_zh": "Hand by Handï¼šé¢å‘æ“ä½œæŠ€èƒ½å­¦ä¹ çš„LLMé©±åŠ¨EMSåŠ©æ‰‹",
      "authors": [
        "Wei Xiang",
        "Ziyue Lei",
        "Haoyuan Che",
        "Fangyuan Ye",
        "Xueting Wu",
        "Lingyun Sun"
      ],
      "abstract": "Operational skill learning, inherently physical and reliant on hands-on practice and kinesthetic feedback, has yet to be effectively replicated in large language model (LLM)-supported training. Current LLM training assistants primarily generate customized textual feedback, neglecting the crucial kinesthetic modality. This gap derives from the textual and uncertain nature of LLMs, compounded by concerns on user acceptance of LLM driven body control. To bridge this gap and realize the potential of collaborative human-LLM action, this work explores human experience of LLM driven kinesthetic assistance. Specifically, we introduced an \"Align-Analyze-Adjust\" strategy and developed FlightAxis, a tool that integrates LLM with Electrical Muscle Stimulation (EMS) for flight skill acquisition, a representative operational skill domain. FlightAxis learns flight skills from manuals and guides forearm movements during simulated flight tasks. Our results demonstrate high user acceptance of LLM-mediated body control and significantly reduced task completion times. Crucially, trainees reported that this kinesthetic assistance enhanced their awareness of operation flaws and fostered increased engagement in the training process, rather than relieving perceived load. This work demonstrated the potential of kinesthetic LLM training in operational skill acquisition.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨æ“ä½œæŠ€èƒ½åŸ¹è®­ä¸­ç¼ºä¹åŠ¨è§‰(kinesthetic)åé¦ˆçš„é—®é¢˜ï¼Œæå‡ºäº†â€œAlign-Analyze-Adjustâ€ç­–ç•¥ï¼Œå¹¶å¼€å‘äº†å°†LLMä¸ç”µè„‰å†²è‚Œè‚‰åˆºæ¿€(EMS)ç»“åˆçš„ç³»ç»ŸFlightAxisã€‚è¯¥ç³»ç»Ÿé€šè¿‡å­¦ä¹ æ“ä½œæ‰‹å†Œå¹¶å®æ—¶å¼•å¯¼ç”¨æˆ·å‰è‡‚è¿åŠ¨ï¼Œå®ç°äº†é£è¡ŒæŠ€èƒ½çš„åŠ¨è§‰è¾…åŠ©è·å–ï¼Œå¡«è¡¥äº†LLMåœ¨ç‰©ç†äº¤äº’åŸ¹è®­é¢†åŸŸçš„ç©ºç™½ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œç”¨æˆ·å¯¹LLMé©±åŠ¨çš„èº«ä½“æ§åˆ¶å±•ç°å‡ºæé«˜çš„æ¥å—åº¦ï¼Œä¸”è¯¥æ–¹æ¡ˆæ˜¾è‘—ç¼©çŸ­äº†ä»»åŠ¡å®Œæˆæ—¶é—´ã€‚ä¸å•çº¯çš„æ–‡æœ¬åé¦ˆä¸åŒï¼Œè¿™ç§åŠ¨è§‰è¾…åŠ©æœ‰æ•ˆå¢å¼ºäº†å—è®­è€…å¯¹æ“ä½œç¼ºé™·çš„æ„ŸçŸ¥å¹¶æé«˜äº†è®­ç»ƒå‚ä¸åº¦ï¼Œå……åˆ†è¯æ˜äº†åŠ¨è§‰LLMåŸ¹è®­åœ¨ç‰©ç†æŠ€èƒ½è·å–æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted by IJCAI 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.06000v1",
      "published_date": "2025-08-08 04:05:47 UTC",
      "updated_date": "2025-08-08 04:05:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:19:59.658167+00:00"
    },
    {
      "arxiv_id": "2508.05996v2",
      "title": "Mediator-Guided Multi-Agent Collaboration among Open-Source Models for Medical Decision-Making",
      "title_zh": "é¢å‘åŒ»å­¦å†³ç­–çš„å¼€æºæ¨¡å‹é—´åè°ƒè€…å¼•å¯¼çš„å¤šæ™ºèƒ½ä½“åä½œ",
      "authors": [
        "Kaitao Chen",
        "Mianxin Liu",
        "Daoming Zong",
        "Chaoyue Ding",
        "Shaohao Rui",
        "Yankai Jiang",
        "Mu Zhou",
        "Xiaosong Wang"
      ],
      "abstract": "Complex medical decision-making involves cooperative workflows operated by different clinicians. Designing AI multi-agent systems can expedite and augment human-level clinical decision-making. Existing multi-agent researches primarily focus on language-only tasks, yet their extension to multimodal scenarios remains challenging. A blind combination of diverse vision-language models (VLMs) can amplify an erroneous outcome interpretation. VLMs in general are less capable in instruction following and importantly self-reflection, compared to large language models (LLMs) of comparable sizes. This disparity largely constrains VLMs' ability in cooperative workflows. In this study, we propose MedOrch, a mediator-guided multi-agent collaboration framework for medical multimodal decision-making. MedOrch employs an LLM-based mediator agent that enables multiple VLM-based expert agents to exchange and reflect on their outputs towards collaboration. We utilize multiple open-source general-purpose and domain-specific VLMs instead of costly GPT-series models, revealing the strength of heterogeneous models. We show that the collaboration within distinct VLM-based agents can surpass the capabilities of any individual agent. We validate our approach on five medical vision question answering benchmarks, demonstrating superior collaboration performance without model training. Our findings underscore the value of mediator-guided multi-agent collaboration in advancing medical multimodal intelligence.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹åŒ»ç–—å¤šæ¨¡æ€å†³ç­–ä¸­è§†è§‰è¯­è¨€æ¨¡å‹(VLMs)åœ¨æŒ‡ä»¤éµå¾ªå’Œè‡ªæˆ‘åæ€èƒ½åŠ›æ–¹é¢çš„ä¸è¶³ï¼Œæå‡ºäº†MedOrchæ¡†æ¶ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLMs)çš„ä¸­ä»‹ä»£ç†(mediator agent)ï¼Œé€šè¿‡åè°ƒå¤šä¸ªå¼€æºVLMsä¸“å®¶ä»£ç†è¿›è¡Œä¿¡æ¯äº¤æ¢ä¸ååŒåæ€ï¼Œè§£å†³äº†å¤šæ¨¡æ€åœºæ™¯ä¸‹é”™è¯¯è§£é‡Šè¢«æ”¾å¤§çš„é—®é¢˜ã€‚ç ”ç©¶é‡‡ç”¨äº†å¤šç§å¼‚æ„çš„å¼€æºé€šç”¨åŠé¢†åŸŸç‰¹å®šæ¨¡å‹ï¼Œè¯æ˜äº†è¿™ç§åä½œæœºåˆ¶èƒ½ä½¿æ•´ä½“è¡¨ç°è¶…è¶Šä»»ä½•å•ä¸€ä»£ç†ã€‚åœ¨äº”é¡¹åŒ»ç–—è§†è§‰é—®ç­”(VQA)åŸºå‡†æµ‹è¯•ä¸­ï¼ŒMedOrchåœ¨æ— éœ€æ¨¡å‹è®­ç»ƒçš„æƒ…å†µä¸‹å±•ç°äº†ä¼˜å¼‚çš„æ€§èƒ½ã€‚è¯¥æˆæœä¸ä»…é™ä½äº†å¯¹æ˜‚è´µGPTç³»åˆ—æ¨¡å‹çš„ä¾èµ–ï¼Œè¿˜ä¸ºæ¨è¿›åŒ»ç–—å¤šæ¨¡æ€æ™ºèƒ½çš„å¤šæ™ºèƒ½ä½“åä½œæä¾›äº†é‡è¦è·¯å¾„ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.05996v2",
      "published_date": "2025-08-08 04:02:10 UTC",
      "updated_date": "2025-10-11 07:01:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:19:58.656046+00:00"
    },
    {
      "arxiv_id": "2508.05991v1",
      "title": "ECMF: Enhanced Cross-Modal Fusion for Multimodal Emotion Recognition in MER-SEMI Challenge",
      "title_zh": "ECMFï¼šé¢å‘ MER-SEMI æŒ‘æˆ˜èµ›çš„å¤šæ¨¡æ€æƒ…æ„Ÿè¯†åˆ«å¢å¼ºå‹è·¨æ¨¡æ€èåˆ",
      "authors": [
        "Juewen Hu",
        "Yexin Li",
        "Jiulin Li",
        "Shuo Chen",
        "Pring Wong"
      ],
      "abstract": "Emotion recognition plays a vital role in enhancing human-computer interaction. In this study, we tackle the MER-SEMI challenge of the MER2025 competition by proposing a novel multimodal emotion recognition framework. To address the issue of data scarcity, we leverage large-scale pre-trained models to extract informative features from visual, audio, and textual modalities. Specifically, for the visual modality, we design a dual-branch visual encoder that captures both global frame-level features and localized facial representations. For the textual modality, we introduce a context-enriched method that employs large language models to enrich emotional cues within the input text. To effectively integrate these multimodal features, we propose a fusion strategy comprising two key components, i.e., self-attention mechanisms for dynamic modality weighting, and residual connections to preserve original representations. Beyond architectural design, we further refine noisy labels in the training set by a multi-source labeling strategy. Our approach achieves a substantial performance improvement over the official baseline on the MER2025-SEMI dataset, attaining a weighted F-score of 87.49% compared to 78.63%, thereby validating the effectiveness of the proposed framework.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹MER2025ç«èµ›ä¸­çš„MER-SEMIæŒ‘æˆ˜ï¼Œæå‡ºäº†ECMFæ¡†æ¶ï¼Œæ—¨åœ¨æå‡å¤šæ¨¡æ€æƒ…æ„Ÿè¯†åˆ«æ€§èƒ½ã€‚ä¸ºäº†åº”å¯¹æ•°æ®ç¨€ç¼ºé—®é¢˜ï¼Œç ”ç©¶åˆ©ç”¨å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹ä»è§†è§‰ã€éŸ³é¢‘å’Œæ–‡æœ¬æ¨¡æ€ä¸­æå–ä¿¡æ¯ç‰¹å¾ã€‚åœ¨è§†è§‰æ¨¡æ€ä¸Šï¼Œè®¾è®¡äº†åŒåˆ†æ”¯ç¼–ç å™¨ä»¥æ•æ‰å…¨å±€å¸§çº§ç‰¹å¾å’Œå±€éƒ¨é¢éƒ¨è¡¨å¾ï¼›åœ¨æ–‡æœ¬æ¨¡æ€ä¸Šï¼Œå¼•å…¥ä¸Šä¸‹æ–‡å¢å¼ºæ–¹æ³•ï¼Œåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(LLMs)ä¸°å¯Œæƒ…æ„Ÿæç¤ºã€‚èåˆé˜¶æ®µé€šè¿‡è‡ªæ³¨æ„åŠ›æœºåˆ¶(self-attention)å®ç°åŠ¨æ€æ¨¡æ€åŠ æƒï¼Œå¹¶ç»“åˆæ®‹å·®è¿æ¥(residual connections)ä»¥ä¿ç•™åŸå§‹ç‰¹å¾ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜é‡‡ç”¨äº†å¤šæºæ ‡æ³¨ç­–ç•¥æ¥ä¼˜åŒ–è®­ç»ƒé›†ä¸­çš„å™ªå£°æ ‡ç­¾ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒECMFåœ¨MER2025-SEMIæ•°æ®é›†ä¸Šçš„åŠ æƒFåˆ†æ•°è¾¾åˆ°87.49%ï¼Œæ˜¾è‘—ä¼˜äºå®˜æ–¹åŸºå‡†çš„78.63%ï¼Œè¯æ˜äº†è¯¥æ¡†æ¶çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.05991v1",
      "published_date": "2025-08-08 03:55:25 UTC",
      "updated_date": "2025-08-08 03:55:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:20:07.688804+00:00"
    },
    {
      "arxiv_id": "2508.05989v2",
      "title": "ETA: Energy-based Test-time Adaptation for Depth Completion",
      "title_zh": "ETAï¼šåŸºäºèƒ½é‡çš„æ·±åº¦è¡¥å…¨æµ‹è¯•æ—¶è‡ªé€‚åº”",
      "authors": [
        "Younjoon Chung",
        "Hyoungseob Park",
        "Patrick Rim",
        "Xiaoran Zhang",
        "Jihe He",
        "Ziyao Zeng",
        "Safa Cicek",
        "Byung-Woo Hong",
        "James S. Duncan",
        "Alex Wong"
      ],
      "abstract": "We propose a method for test-time adaptation of pretrained depth completion models. Depth completion models, trained on some ``source'' data, often predict erroneous outputs when transferred to ``target'' data captured in novel environmental conditions due to a covariate shift. The crux of our method lies in quantifying the likelihood of depth predictions belonging to the source data distribution. The challenge is in the lack of access to out-of-distribution (target) data prior to deployment. Hence, rather than making assumptions regarding the target distribution, we utilize adversarial perturbations as a mechanism to explore the data space. This enables us to train an energy model that scores local regions of depth predictions as in- or out-of-distribution. We update the parameters of pretrained depth completion models at test time to minimize energy, effectively aligning test-time predictions to those of the source distribution. We call our method ``Energy-based Test-time Adaptation'', or ETA for short. We evaluate our method across three indoor and three outdoor datasets, where ETA improve over the previous state-of-the-art method by an average of 6.94% for outdoors and 10.23% for indoors. Project Page: https://fuzzythecat.github.io/eta.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ETA (Energy-based Test-time Adaptation)ï¼Œä¸€ç§é’ˆå¯¹æ·±åº¦è¡¥å…¨(Depth Completion)æ¨¡å‹çš„æµ‹è¯•æ—¶è‡ªé€‚åº”æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³æ¨¡å‹åœ¨é¢ä¸´åå˜é‡åç§»(Covariate Shift)æ—¶å› ç¯å¢ƒå˜åŒ–å¯¼è‡´çš„é¢„æµ‹é”™è¯¯ã€‚è¯¥æ–¹æ³•çš„æ ¸å¿ƒåœ¨äºé€šè¿‡é‡åŒ–æ·±åº¦é¢„æµ‹å±äºæºæ•°æ®åˆ†å¸ƒçš„å¯èƒ½æ€§ï¼Œåˆ©ç”¨å¯¹æŠ—æ€§æ‰°åŠ¨(Adversarial Perturbations)ä½œä¸ºæ¢ç´¢æœºåˆ¶è®­ç»ƒèƒ½é‡æ¨¡å‹(Energy Model)ï¼Œä»è€Œä¸ºå±€éƒ¨æ·±åº¦é¢„æµ‹è¯„åˆ†ã€‚åœ¨æµ‹è¯•é˜¶æ®µï¼ŒETAé€šè¿‡æ›´æ–°é¢„è®­ç»ƒæ¨¡å‹å‚æ•°ä»¥æœ€å°åŒ–èƒ½é‡ï¼Œä½¿é¢„æµ‹ç»“æœä¸æºåˆ†å¸ƒå¯¹é½ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªå®¤å†…å¤–æ•°æ®é›†ä¸Šå‡ä¼˜äºç°æœ‰æœ€å…ˆè¿›æ–¹æ³•ï¼Œåœ¨å®¤å¤–å’Œå®¤å†…åœºæ™¯ä¸‹å‡†ç¡®ç‡åˆ†åˆ«å¹³å‡æå‡äº†6.94%å’Œ10.23%ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.05989v2",
      "published_date": "2025-08-08 03:51:24 UTC",
      "updated_date": "2025-08-20 03:11:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:20:28.456800+00:00"
    },
    {
      "arxiv_id": "2508.09191v1",
      "title": "From Values to Tokens: An LLM-Driven Framework for Context-aware Time Series Forecasting via Symbolic Discretization",
      "title_zh": "ä»æ•°å€¼åˆ° Tokenï¼šä¸€ç§åŸºäºç¬¦å·ç¦»æ•£åŒ–çš„å¤§è¯­è¨€æ¨¡å‹é©±åŠ¨ä¸Šä¸‹æ–‡æ„ŸçŸ¥æ—¶é—´åºåˆ—é¢„æµ‹æ¡†æ¶",
      "authors": [
        "Xiaoyu Tao",
        "Shilong Zhang",
        "Mingyue Cheng",
        "Daoyu Wang",
        "Tingyue Pan",
        "Bokai Pan",
        "Changqing Zhang",
        "Shijin Wang"
      ],
      "abstract": "Time series forecasting plays a vital role in supporting decision-making across a wide range of critical applications, including energy, healthcare, and finance. Despite recent advances, forecasting accuracy remains limited due to the challenge of integrating historical numerical sequences with contextual features, which often comprise unstructured textual data. To address this challenge, we propose TokenCast, an LLM-driven framework that leverages language-based symbolic representations as a unified intermediary for context-aware time series forecasting. Specifically, TokenCast employs a discrete tokenizer to transform continuous numerical sequences into temporal tokens, enabling structural alignment with language-based inputs. To bridge the semantic gap between modalities, both temporal and contextual tokens are embedded into a shared representation space via a pre-trained large language model (LLM), further optimized with autoregressive generative objectives. Building upon this unified semantic space, the aligned LLM is subsequently fine-tuned in a supervised manner to predict future temporal tokens, which are then decoded back into the original numerical space. Extensive experiments on diverse real-world datasets enriched with contextual features demonstrate the effectiveness and generalizability of TokenCast.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†TokenCastï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºLLMé©±åŠ¨çš„æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡Symbolic Discretizationå®ç°Context-aware Time Series Forecastingã€‚è¯¥æ¡†æ¶é’ˆå¯¹ç°æœ‰æ–¹æ³•éš¾ä»¥æ•´åˆå†å²æ•°å€¼åºåˆ—ä¸éç»“æ„åŒ–æ–‡æœ¬ä¸Šä¸‹æ–‡ç‰¹å¾çš„æŒ‘æˆ˜ï¼Œæå‡ºå°†æ•°å€¼åºåˆ—è½¬åŒ–ä¸ºTemporal Tokensä»¥å®ç°ä¸è¯­è¨€è¾“å…¥çš„ç»“æ„å¯¹é½ã€‚TokenCaståˆ©ç”¨é¢„è®­ç»ƒçš„å¤§è¯­è¨€æ¨¡å‹å°†æ—¶é—´ä»¤ç‰Œä¸ä¸Šä¸‹æ–‡ä»¤ç‰ŒåµŒå…¥ç»Ÿä¸€çš„å…±äº«è¡¨ç¤ºç©ºé—´ï¼Œå¹¶ç»“åˆAutoregressiveç”Ÿæˆç›®æ ‡è¿›è¡Œä¼˜åŒ–ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œé€šè¿‡ç›‘ç£å¾®è°ƒä½¿æ¨¡å‹èƒ½å¤Ÿé¢„æµ‹æœªæ¥çš„Temporal Tokensï¼Œå¹¶æœ€ç»ˆå°†å…¶è§£ç å›åŸå§‹æ•°å€¼ç©ºé—´ã€‚åœ¨å¤šç§åŒ…å«ä¸Šä¸‹æ–‡ç‰¹å¾çš„çœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒTokenCastèƒ½å¤Ÿæœ‰æ•ˆæå‡é¢„æµ‹æ€§èƒ½ï¼Œå±•ç°äº†æå¼ºçš„Generalizabilityã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09191v1",
      "published_date": "2025-08-08 03:51:08 UTC",
      "updated_date": "2025-08-08 03:51:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:20:15.560182+00:00"
    },
    {
      "arxiv_id": "2508.06584v1",
      "title": "Omni Geometry Representation Learning vs Large Language Models for Geospatial Entity Resolution",
      "title_zh": "Omniå‡ ä½•è¡¨ç¤ºå­¦ä¹ ä¸å¤§è¯­è¨€æ¨¡å‹åœ¨åœ°ç†ç©ºé—´å®ä½“æ¶ˆè§£ä¸­çš„å¯¹æ¯”ç ”ç©¶",
      "authors": [
        "Kalana Wijegunarathna",
        "Kristin Stock",
        "Christopher B. Jones"
      ],
      "abstract": "The development, integration, and maintenance of geospatial databases rely heavily on efficient and accurate matching procedures of Geospatial Entity Resolution (ER). While resolution of points-of-interest (POIs) has been widely addressed, resolution of entities with diverse geometries has been largely overlooked. This is partly due to the lack of a uniform technique for embedding heterogeneous geometries seamlessly into a neural network framework. Existing neural approaches simplify complex geometries to a single point, resulting in significant loss of spatial information. To address this limitation, we propose Omni, a geospatial ER model featuring an omni-geometry encoder. This encoder is capable of embedding point, line, polyline, polygon, and multi-polygon geometries, enabling the model to capture the complex geospatial intricacies of the places being compared. Furthermore, Omni leverages transformer-based pre-trained language models over individual textual attributes of place records in an Attribute Affinity mechanism. The model is rigorously tested on existing point-only datasets and a new diverse-geometry geospatial ER dataset. Omni produces up to 12% (F1) improvement over existing methods.\n  Furthermore, we test the potential of Large Language Models (LLMs) to conduct geospatial ER, experimenting with prompting strategies and learning scenarios, comparing the results of pre-trained language model-based methods with LLMs. Results indicate that LLMs show competitive results.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åœ°ç†ç©ºé—´å®ä½“è§£æ(Geospatial Entity Resolution)ä¸­ç°æœ‰æ¨¡å‹å°†å¤æ‚å‡ ä½•å½¢çŠ¶ç®€åŒ–ä¸ºå•ç‚¹è€Œå¯¼è‡´ç©ºé—´ä¿¡æ¯ä¸¢å¤±çš„é—®é¢˜ï¼Œæå‡ºäº†åä¸ºOmniçš„æ–°å‹æ¨¡å‹ã€‚Omniçš„æ ¸å¿ƒæ˜¯ä¸€ä¸ªå…¨å‡ ä½•ç¼–ç å™¨(omni-geometry encoder)ï¼Œèƒ½å¤Ÿæ— ç¼åµŒå…¥ç‚¹(point)ã€çº¿(line)ã€å¤šæ®µçº¿(polyline)ã€å¤šè¾¹å½¢(polygon)åŠå¤šé¢(multi-polygon)ç­‰å¼‚æ„å‡ ä½•å½¢çŠ¶ï¼Œä»è€Œæ•æ‰å¤æ‚çš„åœ°ç†ç©ºé—´ç‰¹å¾ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹åˆ©ç”¨Attribute Affinityæœºåˆ¶ï¼Œç»“åˆåŸºäºTransformerçš„é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹æ¥å¤„ç†å®ä½“çš„æ–‡æœ¬å±æ€§ã€‚åœ¨ç‚¹æ•°æ®é›†åŠæ–°å¢çš„å¤šå…ƒå‡ ä½•æ•°æ®é›†ä¸Šçš„æµ‹è¯•è¡¨æ˜ï¼ŒOmniç›¸æ¯”ç°æœ‰æ–¹æ³•åœ¨F1åˆ†æ•°ä¸Šæå‡äº†é«˜è¾¾12%ã€‚ç ”ç©¶è¿˜è¿›ä¸€æ­¥æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨æ‰§è¡Œåœ°ç†ç©ºé—´ERä»»åŠ¡æ—¶çš„æ½œåŠ›ï¼Œå®éªŒç»“æœæ˜¾ç¤ºLLMsåœ¨å¤šç§æç¤ºç­–ç•¥å’Œå­¦ä¹ åœºæ™¯ä¸‹å‡å±•ç°å‡ºäº†æå…·ç«äº‰åŠ›çš„æ€§èƒ½ã€‚",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06584v1",
      "published_date": "2025-08-08 03:37:11 UTC",
      "updated_date": "2025-08-08 03:37:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:20:21.656576+00:00"
    },
    {
      "arxiv_id": "2508.05979v1",
      "title": "Learning by Teaching: Engaging Students as Instructors of Large Language Models in Computer Science Education",
      "title_zh": "ä»¥æ•™ä¿ƒå­¦ï¼šåœ¨è®¡ç®—æœºç§‘å­¦æ•™è‚²ä¸­å¼•å¯¼å­¦ç”Ÿæ‹…ä»»å¤§è¯­è¨€æ¨¡å‹çš„æŒ‡å¯¼è€…",
      "authors": [
        "Xinming Yang",
        "Haasil Pujara",
        "Jun Li"
      ],
      "abstract": "While Large Language Models (LLMs) are often used as virtual tutors in computer science (CS) education, this approach can foster passive learning and over-reliance. This paper presents a novel pedagogical paradigm that inverts this model: students act as instructors who must teach an LLM to solve problems. To facilitate this, we developed strategies for designing questions with engineered knowledge gaps that only a student can bridge, and we introduce Socrates, a system for deploying this method with minimal overhead. We evaluated our approach in an undergraduate course and found that this active-learning method led to statistically significant improvements in student performance compared to historical cohorts. Our work demonstrates a practical, cost-effective framework for using LLMs to deepen student engagement and mastery.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ (Large Language Models, LLMs) åœ¨è®¡ç®—æœºç§‘å­¦æ•™è‚²ä¸­ä½œä¸ºè™šæ‹Ÿå¯¼å¸ˆå¯èƒ½å¯¼è‡´çš„è¢«åŠ¨å­¦ä¹ å’Œè¿‡åº¦ä¾èµ–é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ–°é¢–çš„â€œä»¥æ•™ä¿ƒå­¦â€æ•™å­¦èŒƒå¼ã€‚åœ¨è¯¥æ¨¡å‹ä¸­ï¼Œå­¦ç”Ÿä¸å†æ˜¯çŸ¥è¯†çš„æ¥æ”¶è€…ï¼Œè€Œæ˜¯ä½œä¸ºæ•™å¯¼è€…å»æ•™ä¼š LLM è§£å†³ç‰¹å®šé—®é¢˜ã€‚ä¸ºäº†æœ‰æ•ˆå®æ–½è¿™ä¸€æ–¹æ³•ï¼Œç ”ç©¶å›¢é˜Ÿè®¾è®¡äº†å¸¦æœ‰å·¥ç¨‹åŒ–çŸ¥è¯†é¸¿æ²Ÿ (engineered knowledge gaps) çš„é¢˜ç›®ç­–ç•¥ï¼Œå¹¶å¼€å‘äº† Socrates ç³»ç»Ÿä»¥å®ç°ä½å¼€é”€çš„æ–¹æ¡ˆéƒ¨ç½²ã€‚åœ¨æœ¬ç§‘è¯¾ç¨‹çš„å®è¯è¯„ä¼°ä¸­ï¼Œè¿™ç§ä¸»åŠ¨å­¦ä¹  (active-learning) æ–¹æ³•ä½¿å­¦ç”Ÿçš„å­¦ä¸šè¡¨ç°è¾ƒå†å²å¯¹ç…§ç»„æœ‰äº†ç»Ÿè®¡å­¦æ„ä¹‰ä¸Šçš„æ˜¾è‘—æå‡ã€‚è¯¥å·¥ä½œè¯æ˜äº†é€šè¿‡è§’è‰²åè½¬åˆ©ç”¨ LLM æ¥æ·±åŒ–å­¦ç”Ÿå‚ä¸åº¦å’ŒçŸ¥è¯†æŒæ¡ç¨‹åº¦çš„æ¡†æ¶å…·æœ‰é«˜åº¦çš„å®ç”¨æ€§ä¸æˆæœ¬æ•ˆç›Šã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "Published at COLM 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.05979v1",
      "published_date": "2025-08-08 03:25:19 UTC",
      "updated_date": "2025-08-08 03:25:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:20:26.588076+00:00"
    },
    {
      "arxiv_id": "2508.05978v1",
      "title": "DAFMSVC: One-Shot Singing Voice Conversion with Dual Attention Mechanism and Flow Matching",
      "title_zh": "DAFMSVCï¼šåŸºäºåŒæ³¨æ„åŠ›æœºåˆ¶ä¸æµåŒ¹é…çš„å•æ ·æœ¬æ­Œå£°è½¬æ¢",
      "authors": [
        "Wei Chen",
        "Binzhu Sha",
        "Dan Luo",
        "Jing Yang",
        "Zhuo Wang",
        "Fan Fan",
        "Zhiyong Wu"
      ],
      "abstract": "Singing Voice Conversion (SVC) transfers a source singer's timbre to a target while keeping melody and lyrics. The key challenge in any-to-any SVC is adapting unseen speaker timbres to source audio without quality degradation. Existing methods either face timbre leakage or fail to achieve satisfactory timbre similarity and quality in the generated audio. To address these challenges, we propose DAFMSVC, where the self-supervised learning (SSL) features from the source audio are replaced with the most similar SSL features from the target audio to prevent timbre leakage. It also incorporates a dual cross-attention mechanism for the adaptive fusion of speaker embeddings, melody, and linguistic content. Additionally, we introduce a flow matching module for high quality audio generation from the fused features. Experimental results show that DAFMSVC significantly enhances timbre similarity and naturalness, outperforming state-of-the-art methods in both subjective and objective evaluations.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† DAFMSVCï¼Œä¸€ç§ç»“åˆåŒæ³¨æ„åŠ›æœºåˆ¶ (Dual Attention Mechanism) ä¸æµåŒ¹é… (Flow Matching) çš„ One-Shot æ­Œå£°è½¬æ¢ (Singing Voice Conversion) æ¡†æ¶ã€‚è¯¥ç ”ç©¶æ—¨åœ¨è§£å†³ Any-to-Any è½¬æ¢ä¸­æœªè§è¯´è¯äººéŸ³è‰²é€‚åº”æ—¶é¢ä¸´çš„éŸ³è‰²æ³„éœ² (Timbre Leakage) å’Œç”Ÿæˆè´¨é‡ä¸è¶³ç­‰æ ¸å¿ƒæŒ‘æˆ˜ã€‚ä¸ºäº†é˜²æ­¢éŸ³è‰²æ³„éœ²ï¼ŒDAFMSVC å°†æºéŸ³é¢‘çš„è‡ªç›‘ç£å­¦ä¹  (SSL) ç‰¹å¾æ›¿æ¢ä¸ºç›®æ ‡éŸ³é¢‘ä¸­ä¸ä¹‹æœ€ç›¸ä¼¼çš„ç‰¹å¾ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹å¼•å…¥äº†åŒäº¤å‰æ³¨æ„åŠ›æœºåˆ¶ï¼Œä»¥å®ç°è¯´è¯äººåµŒå…¥ (Speaker Embeddings)ã€æ—‹å¾‹å’Œè¯­è¨€å†…å®¹çš„è‡ªé€‚åº”èåˆã€‚é€šè¿‡é›†æˆæµåŒ¹é… (Flow Matching) æ¨¡å—ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿä»èåˆç‰¹å¾ä¸­ç”Ÿæˆé«˜è´¨é‡ä¸”è‡ªç„¶çš„éŸ³é¢‘ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒDAFMSVC åœ¨éŸ³è‰²ç›¸ä¼¼åº¦å’Œè‡ªç„¶åº¦ä¸Šå‡æ˜¾è‘—ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted by INTERSPEECH 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.05978v1",
      "published_date": "2025-08-08 03:24:19 UTC",
      "updated_date": "2025-08-08 03:24:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:20:25.544648+00:00"
    },
    {
      "arxiv_id": "2508.09190v3",
      "title": "Fine-Grained Safety Neurons with Training-Free Continual Projection to Reduce LLM Fine Tuning Risks",
      "title_zh": "åŸºäºå…è®­ç»ƒæŒç»­æŠ•å½±çš„ç»†ç²’åº¦å®‰å…¨ç¥ç»å…ƒï¼šé™ä½å¤§è¯­è¨€æ¨¡å‹å¾®è°ƒé£é™©",
      "authors": [
        "Bing Han",
        "Feifei Zhao",
        "Dongcheng Zhao",
        "Guobin Shen",
        "Ping Wu",
        "Yu Shi",
        "Yi Zeng"
      ],
      "abstract": "Fine-tuning as service injects domain-specific knowledge into large language models (LLMs), while challenging the original alignment mechanisms and introducing safety risks. A series of defense strategies have been proposed for the alignment, fine-tuning, and post-fine-tuning phases, where most post-fine-tuning defenses rely on coarse-grained safety layer mapping. These methods lack a comprehensive consideration of both safety layers and fine-grained neurons, limiting their ability to efficiently balance safety and utility. To address this, we propose the Fine-Grained Safety Neurons (FGSN) with Training-Free Continual Projection method to reduce the fine-tuning safety risks. FGSN inherently integrates the multi-scale interactions between safety layers and neurons, localizing sparser and more precise fine-grained safety neurons while minimizing interference with downstream task neurons. We then project the safety neuron parameters onto safety directions, improving model safety while aligning more closely with human preferences. Extensive experiments across multiple fine-tuned LLM models demonstrate that our method significantly reduce harmfulness scores and attack success rates with minimal parameter modifications, while preserving the model's utility. Furthermore, by introducing a task-specific, multi-dimensional heterogeneous safety neuron cluster optimization mechanism, we achieve continual defense and generalization capability against unforeseen emerging safety concerns.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Fine-Grained Safety Neurons (FGSN) ç»“åˆ Training-Free Continual Projection æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­å¯èƒ½å¯¼è‡´çš„å¯¹é½æœºåˆ¶å¤±æ•ˆåŠå®‰å…¨é£é™©ã€‚ä¼ ç»Ÿçš„å¾®è°ƒåé˜²å¾¡ç­–ç•¥é€šå¸¸ä¾èµ–äºç²—ç²’åº¦çš„å®‰å…¨å±‚æ˜ å°„ï¼Œå¾€å¾€éš¾ä»¥åœ¨ç»´æŠ¤å®‰å…¨æ€§å’Œä¿è¯æ¨¡å‹å®ç”¨æ€§ä¹‹é—´å–å¾—å¹³è¡¡ã€‚FGSN é€šè¿‡æ•´åˆå®‰å…¨å±‚ä¸ç¥ç»å…ƒä¹‹é—´çš„å¤šå°ºåº¦äº¤äº’ï¼Œç²¾ç¡®å®šä½å‡ºç¨€ç–ä¸”ç²¾å‡†çš„ç»†ç²’åº¦å®‰å…¨ç¥ç»å…ƒï¼Œä»è€Œæœ€å¤§é™åº¦åœ°å‡å°‘å¯¹ä¸‹æ¸¸ä»»åŠ¡ç¥ç»å…ƒçš„å¹²æ‰°ã€‚è¯¥æ–¹æ³•å°†å®‰å…¨ç¥ç»å…ƒå‚æ•°æŠ•å½±åˆ°å®‰å…¨æ–¹å‘ä¸Šï¼Œä½¿æ¨¡å‹åœ¨æå‡å®‰å…¨æ€§çš„åŒæ—¶æ›´ç´§å¯†åœ°ç¬¦åˆäººç±»åå¥½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨å¤šä¸ªå¾®è°ƒåçš„ LLM æ¨¡å‹ä¸Šï¼Œè¯¥æ–¹æ³•ä»…éœ€æå°çš„å‚æ•°ä¿®æ”¹å³å¯æ˜¾è‘—é™ä½æœ‰å®³æ€§è¯„åˆ†å’Œæ”»å‡»æˆåŠŸç‡ï¼Œå¹¶å®Œå¥½åœ°ä¿ç•™äº†æ¨¡å‹çš„åŸå§‹æ•ˆç”¨ã€‚æ­¤å¤–ï¼Œé€šè¿‡å¼•å…¥ç‰¹å®šä»»åŠ¡çš„å¤šç»´å¼‚æ„å®‰å…¨ç¥ç»å…ƒé›†ç¾¤ä¼˜åŒ–æœºåˆ¶ï¼Œè¯¥æ–¹æ¡ˆè¿˜å®ç°äº†é’ˆå¯¹æ–°å…´å®‰å…¨é—®é¢˜çš„æŒç»­é˜²å¾¡èƒ½åŠ›å’Œæ³›åŒ–èƒ½åŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09190v3",
      "published_date": "2025-08-08 03:20:25 UTC",
      "updated_date": "2025-08-24 09:31:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:20:54.085255+00:00"
    },
    {
      "arxiv_id": "2508.05970v1",
      "title": "Impact-driven Context Filtering For Cross-file Code Completion",
      "title_zh": "å½±å“é©±åŠ¨çš„è·¨æ–‡ä»¶ä»£ç è¡¥å…¨ä¸Šä¸‹æ–‡è¿‡æ»¤",
      "authors": [
        "Yanzhou Li",
        "Shangqing Liu",
        "Kangjie Chen",
        "Tianwei Zhang",
        "Yang Liu"
      ],
      "abstract": "Retrieval-augmented generation (RAG) has recently demonstrated considerable potential for repository-level code completion, as it integrates cross-file knowledge with in-file preceding code to provide comprehensive contexts for generation. To better understand the contribution of the retrieved cross-file contexts, we introduce a likelihood-based metric to evaluate the impact of each retrieved code chunk on the completion. Our analysis reveals that, despite retrieving numerous chunks, only a small subset positively contributes to the completion, while some chunks even degrade performance. To address this issue, we leverage this metric to construct a repository-level dataset where each retrieved chunk is labeled as positive, neutral, or negative based on its relevance to the target completion. We then propose an adaptive retrieval context filtering framework, CODEFILTER, trained on this dataset to mitigate the harmful effects of negative retrieved contexts in code completion. Extensive evaluation on the RepoEval and CrossCodeLongEval benchmarks demonstrates that CODEFILTER consistently improves completion accuracy compared to approaches without filtering operations across various tasks. Additionally, CODEFILTER significantly reduces the length of the input prompt, enhancing computational efficiency while exhibiting strong generalizability across different models. These results underscore the potential of CODEFILTER to enhance the accuracy, efficiency, and attributability of repository-level code completion.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG) åœ¨ä»“åº“çº§ä»£ç è¡¥å…¨ (repository-level code completion) ä¸­çš„åº”ç”¨ï¼ŒæŒ‡å‡ºå¹¶éæ‰€æœ‰æ£€ç´¢åˆ°çš„è·¨æ–‡ä»¶ä¸Šä¸‹æ–‡ (cross-file contexts) éƒ½èƒ½æä¾›æ­£å‘å¸®åŠ©ã€‚ä¸ºæ­¤ï¼Œä½œè€…å¼•å…¥äº†ä¸€ç§åŸºäºä¼¼ç„¶çš„æŒ‡æ ‡ (likelihood-based metric) æ¥è¯„ä¼°æ¯ä¸ªæ£€ç´¢ä»£ç å—å¯¹è¡¥å…¨ç»“æœçš„å…·ä½“å½±å“ï¼Œå‘ç°ä»…æœ‰å°‘éƒ¨åˆ†ä»£ç å—èƒ½æå‡æ€§èƒ½ï¼Œéƒ¨åˆ†ç”šè‡³ä¼šèµ·åˆ°åä½œç”¨ã€‚åŸºäºæ­¤å‘ç°ï¼Œç ”ç©¶è€…æ„å»ºäº†ä¸“é—¨çš„æ ‡æ³¨æ•°æ®é›†å¹¶æå‡ºäº†è‡ªé€‚åº”æ£€ç´¢ä¸Šä¸‹æ–‡è¿‡æ»¤æ¡†æ¶ CODEFILTERï¼Œæ—¨åœ¨æ¶ˆé™¤è´Ÿé¢ä¸Šä¸‹æ–‡å¯¹ä»£ç è¡¥å…¨çš„å¹²æ‰°ã€‚åœ¨ RepoEval å’Œ CrossCodeLongEval åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒCODEFILTER åœ¨å¤šç§ä»»åŠ¡ä¸­ä¸€è‡´æé«˜äº†è¡¥å…¨å‡†ç¡®åº¦ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶é€šè¿‡æ˜¾è‘—ç¼©çŸ­è¾“å…¥æç¤º (input prompt) çš„é•¿åº¦æå‡äº†è®¡ç®—æ•ˆç‡ï¼Œå¹¶åœ¨ä¸åŒæ¨¡å‹é—´å±•ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ï¼Œä¸ºå®ç°é«˜æ•ˆã€å‡†ç¡®ä¸”å…·æœ‰å¯å½’å› æ€§çš„ä»“åº“çº§ä»£ç è¡¥å…¨æä¾›äº†æ–°æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.05970v1",
      "published_date": "2025-08-08 03:08:19 UTC",
      "updated_date": "2025-08-08 03:08:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:20:46.590296+00:00"
    },
    {
      "arxiv_id": "2508.05960v1",
      "title": "Mildly Conservative Regularized Evaluation for Offline Reinforcement Learning",
      "title_zh": "ç¦»çº¿å¼ºåŒ–å­¦ä¹ çš„é€‚åº¦ä¿å®ˆæ­£åˆ™åŒ–è¯„ä¼°",
      "authors": [
        "Haohui Chen",
        "Zhiyong Chen"
      ],
      "abstract": "Offline reinforcement learning (RL) seeks to learn optimal policies from static datasets without further environment interaction. A key challenge is the distribution shift between the learned and behavior policies, leading to out-of-distribution (OOD) actions and overestimation. To prevent gross overestimation, the value function must remain conservative; however, excessive conservatism may hinder performance improvement. To address this, we propose the mildly conservative regularized evaluation (MCRE) framework, which balances conservatism and performance by combining temporal difference (TD) error with a behavior cloning term in the Bellman backup. Building on this, we develop the mildly conservative regularized Q-learning (MCRQ) algorithm, which integrates MCRE into an off-policy actor-critic framework. Experiments show that MCRQ outperforms strong baselines and state-of-the-art offline RL algorithms on benchmark datasets.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç¦»çº¿å¼ºåŒ–å­¦ä¹ (Offline RL)ä¸­å› åˆ†å¸ƒåç§»å¯¼è‡´çš„è¶…å‡ºåˆ†å¸ƒ(OOD)åŠ¨ä½œé«˜ä¼°é—®é¢˜ï¼Œæå‡ºäº†è½»åº¦ä¿å®ˆæ­£åˆ™åŒ–è¯„ä¼°(MCRE)æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡åœ¨è´å°”æ›¼å¤‡ä»½(Bellman backup)ä¸­ç»“åˆæ—¶é—´å·®åˆ†(TD)è¯¯å·®ä¸è¡Œä¸ºå…‹éš†(behavior cloning)é¡¹ï¼Œå®ç°äº†ä¿å®ˆæ€§ä¸æ€§èƒ½æ”¹è¿›ä¹‹é—´çš„ç²¾ç¡®å¹³è¡¡ï¼Œæœ‰æ•ˆç¼“è§£äº†è¿‡åº¦ä¿å®ˆå¯¹æ¨¡å‹è¡¨ç°çš„é™åˆ¶ã€‚åŸºäºæ­¤æ¡†æ¶ï¼Œç ”ç©¶è€…å¼€å‘äº†MCRQç®—æ³•ï¼Œå¹¶å°†å…¶é›†æˆåˆ°ç¦»è½´è¡ŒåŠ¨è€…-è¯„è®ºè€…(off-policy actor-critic)æ¶æ„ä¸­ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMCRQåœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šå‡ä¼˜äºç°æœ‰çš„å¼ºåŸºçº¿æ¨¡å‹ä»¥åŠæœ€å…ˆè¿›çš„ç¦»çº¿å¼ºåŒ–å­¦ä¹ ç®—æ³•ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.05960v1",
      "published_date": "2025-08-08 02:48:26 UTC",
      "updated_date": "2025-08-08 02:48:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:20:55.189180+00:00"
    },
    {
      "arxiv_id": "2508.05957v1",
      "title": "Multi-Armed Bandits-Based Optimization of Decision Trees",
      "title_zh": "åŸºäºå¤šè‡‚è€è™æœºçš„å†³ç­–æ ‘ä¼˜åŒ–",
      "authors": [
        "Hasibul Karim Shanto",
        "Umme Ayman Koana",
        "Shadikur Rahman"
      ],
      "abstract": "Decision trees, without appropriate constraints, can easily become overly complex and prone to overfit, capturing noise rather than generalizable patterns. To resolve this problem,pruning operation is a crucial part in optimizing decision trees, as it not only reduces the complexity of trees but also decreases the probability of generating overfit models. The conventional pruning techniques like Cost-Complexity Pruning (CCP) and Reduced Error Pruning (REP) are mostly based on greedy approaches that focus on immediate gains in performance while pruning nodes of the decision tree. However, this might result in a lower generalization in the long run, compromising the robust ability of the tree model when introduced to unseen data samples, particularly when trained with small and complex datasets. To address this challenge, we are proposing a Multi-Armed Bandits (MAB)-based pruning approach, a reinforcement learning (RL)-based technique, that will dynamically prune the tree to generate an optimal decision tree with better generalization. Our proposed approach assumes the pruning process as an exploration-exploitation problem, where we are utilizing the MAB algorithms to find optimal branch nodes to prune based on feedback from each pruning actions. Experimental evaluation on several benchmark datasets, demonstrated that our proposed approach results in better predictive performance compared to the traditional ones. This suggests the potential of utilizing MAB for a dynamic and probabilistic way of decision tree pruning, in turn optimizing the decision tree-based model.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å†³ç­–æ ‘åœ¨ç¼ºä¹çº¦æŸæ—¶å®¹æ˜“è¿‡æ‹Ÿåˆ(overfit)åŠä¼ ç»Ÿå‰ªææŠ€æœ¯å¦‚ Cost-Complexity Pruning (CCP) å’Œ Reduced Error Pruning (REP) å› è¿‡åº¦ä¾èµ–è´ªå©ªç­–ç•¥è€Œå¯¼è‡´æ³›åŒ–æ€§èƒ½ä¸è¶³çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºå¤šè‡‚è€è™æœº(Multi-Armed Bandits, MAB)çš„ä¼˜åŒ–æ–¹æ³•ã€‚è¯¥æ–¹æ³•å°†å‰ªæè¿‡ç¨‹å»ºæ¨¡ä¸ºå¼ºåŒ–å­¦ä¹ (Reinforcement Learning)ä¸­çš„æ¢ç´¢ä¸åˆ©ç”¨(exploration-exploitation)é—®é¢˜ï¼Œåˆ©ç”¨ MAB ç®—æ³•æ ¹æ®å‰ªæåŠ¨ä½œçš„å®æ—¶åé¦ˆåŠ¨æ€å¯»æ‰¾æœ€ä¼˜åˆ†æ”¯èŠ‚ç‚¹ã€‚åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨é¢„æµ‹æ€§èƒ½ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿå‰ªææŠ€æœ¯ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡æ¨¡å‹åœ¨å¤„ç†å¤æ‚æ•°æ®é›†æ—¶çš„é²æ£’æ€§ã€‚ç ”ç©¶è¯æ˜äº†åˆ©ç”¨ MAB è¿›è¡ŒåŠ¨æ€ã€æ¦‚ç‡åŒ–å‰ªæåœ¨ä¼˜åŒ–å†³ç­–æ ‘æ¨¡å‹æ–¹é¢çš„å·¨å¤§æ½œåŠ›ï¼Œä¸ºè§£å†³å†³ç­–æ ‘çš„ç»“æ„ä¼˜åŒ–æä¾›äº†æ–°çš„è§†è§’ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.05957v1",
      "published_date": "2025-08-08 02:43:45 UTC",
      "updated_date": "2025-08-08 02:43:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:20:54.686627+00:00"
    },
    {
      "arxiv_id": "2508.05954v1",
      "title": "Bifrost-1: Bridging Multimodal LLMs and Diffusion Models with Patch-level CLIP Latents",
      "title_zh": "Bifrost-1ï¼šé€šè¿‡å—çº§ CLIP æ½œå˜é‡æ¡¥æ¥å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ä¸æ‰©æ•£æ¨¡å‹",
      "authors": [
        "Han Lin",
        "Jaemin Cho",
        "Amir Zadeh",
        "Chuan Li",
        "Mohit Bansal"
      ],
      "abstract": "There is growing interest in integrating high-fidelity visual synthesis capabilities into large language models (LLMs) without compromising their strong reasoning capabilities. Existing methods that directly train LLMs or bridge LLMs and diffusion models usually suffer from costly training since the backbone LLMs have not seen image representations during pretraining. We present Bifrost-1, a unified framework that bridges pretrained multimodal LLMs (MLLMs) and diffusion models using patch-level CLIP image embeddings as latent variables, which are natively aligned with the MLLM's CLIP visual encoder. These patch-level image embeddings are integrated into the diffusion model with a lightweight adaptation of its ControlNet. To retain the original multimodal reasoning capabilities of MLLMs, we equip the MLLM with a visual generation branch initialized from the original MLLM parameters when predicting the patch-level image embeddings. By seamlessly integrating pretrained MLLMs and diffusion models with patch-level CLIP latents, our framework enables high-fidelity controllable image generation with significant training efficiency. Our experiments demonstrate that Bifrost-1 achieves comparable or better performance than previous methods in terms of visual fidelity and multimodal understanding, with substantially lower compute during training. We also provide comprehensive ablation studies showing the effectiveness of our design choices.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Bifrost-1ï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨è¿æ¥é¢„è®­ç»ƒå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLMs)å’Œæ‰©æ•£æ¨¡å‹(Diffusion Models)çš„ç»Ÿä¸€æ¡†æ¶ã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•åœ¨é›†æˆé«˜ä¿çœŸè§†è§‰åˆæˆèƒ½åŠ›æ—¶é¢ä¸´çš„è®­ç»ƒæˆæœ¬é«˜æ˜‚é—®é¢˜ï¼ŒBifrost-1åˆ©ç”¨ä¸MLLMåŸç”ŸCLIPè§†è§‰ç¼–ç å™¨å¯¹é½çš„ patch-level CLIP å›¾åƒåµŒå…¥ä½œä¸ºæ½œå˜é‡(latent variables)ã€‚é€šè¿‡å¯¹ ControlNet è¿›è¡Œè½»é‡åŒ–é€‚é…ï¼Œè¿™äº› patch-level å›¾åƒåµŒå…¥è¢«æ— ç¼é›†æˆåˆ°æ‰©æ•£æ¨¡å‹ä¸­ã€‚ä¸ºäº†åœ¨é¢„æµ‹å›¾åƒåµŒå…¥æ—¶ä¿ç•™MLLMåŸæœ‰çš„å¤šæ¨¡æ€æ¨ç†èƒ½åŠ›ï¼Œè¯¥æ¡†æ¶å¼•å…¥äº†ç”±åŸå§‹æ¨¡å‹å‚æ•°åˆå§‹åŒ–çš„è§†è§‰ç”Ÿæˆåˆ†æ”¯ã€‚å®éªŒè¯æ˜ï¼ŒBifrost-1 åœ¨è§†è§‰ä¿çœŸåº¦å’Œå¤šæ¨¡æ€ç†è§£æ–¹é¢è¾¾åˆ°äº†ä¸ç°æœ‰æ–¹æ³•ç›¸å½“æˆ–æ›´ä¼˜çš„æ°´å¹³ï¼ŒåŒæ—¶å¤§å¹…é™ä½äº†è®­ç»ƒæ—¶çš„è®¡ç®—å¼€é”€ã€‚è¯¥å·¥ä½œä¸ºå®ç°é«˜æ•ˆã€å¯æ§çš„é«˜è´¨é‡å›¾åƒç”Ÿæˆæä¾›äº†åˆ›æ–°çš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Project Page: https://bifrost-1.github.io",
      "pdf_url": "https://arxiv.org/pdf/2508.05954v1",
      "published_date": "2025-08-08 02:38:47 UTC",
      "updated_date": "2025-08-08 02:38:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:21:02.394586+00:00"
    },
    {
      "arxiv_id": "2508.05950v1",
      "title": "A 3DGS-Diffusion Self-Supervised Framework for Normal Estimation from a Single Image",
      "title_zh": "åŸºäº3DGS-æ‰©æ•£æ¨¡å‹çš„å•å¹…å›¾åƒæ³•å‘ä¼°è®¡è‡ªç›‘ç£æ¡†æ¶",
      "authors": [
        "Yanxing Liang",
        "Yinghui Wang",
        "Jinlong Yang",
        "Wei Li"
      ],
      "abstract": "The lack of spatial dimensional information remains a challenge in normal estimation from a single image. Recent diffusion-based methods have demonstrated significant potential in 2D-to-3D implicit mapping, they rely on data-driven statistical priors and miss the explicit modeling of light-surface interaction, leading to multi-view normal direction conflicts. Moreover, the discrete sampling mechanism of diffusion models causes gradient discontinuity in differentiable rendering reconstruction modules, preventing 3D geometric errors from being backpropagated to the normal generation network, thereby forcing existing methods to depend on dense normal annotations. This paper proposes SINGAD, a novel Self-supervised framework from a single Image for Normal estimation via 3D GAussian splatting guided Diffusion. By integrating physics-driven light-interaction modeling and a differentiable rendering-based reprojection strategy, our framework directly converts 3D geometric errors into normal optimization signals, solving the challenges of multi-view geometric inconsistency and data dependency. Specifically, the framework constructs a light-interaction-driven 3DGS reparameterization model to generate multi-scale geometric features consistent with light transport principles, ensuring multi-view normal consistency. A cross-domain feature fusion module is designed within a conditional diffusion model, embedding geometric priors to constrain normal generation while maintaining accurate geometric error propagation. Furthermore, a differentiable 3D reprojection loss strategy is introduced for self-supervised optimization that minimizes geometric error between the reconstructed and input image, eliminating dependence on annotated normal datasets. Quantitative evaluations on the Google Scanned Objects dataset demonstrate that our method outperforms state-of-the-art approaches across multiple metrics.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å•å¼ å›¾åƒæ³•çº¿ä¼°è®¡(Normal Estimation)ä¸­ç”±äºç¼ºä¹ç©ºé—´ç»´åº¦ä¿¡æ¯ã€æ‰©æ•£æ¨¡å‹ç¼ºä¹å…‰å­¦æ˜¾å¼å»ºæ¨¡å¯¼è‡´çš„å¤šè§†å›¾æ³•çº¿å†²çªåŠå¯¹æ ‡æ³¨æ•°æ®ä¾èµ–çš„é—®é¢˜ï¼Œæå‡ºäº†SINGADè‡ªç›‘ç£æ¡†æ¶ã€‚è¯¥æ¡†æ¶ç»“åˆäº†3Dé«˜æ–¯æ³¼æº…(3D Gaussian Splatting, 3DGS)å¼•å¯¼çš„æ‰©æ•£æ¨¡å‹ï¼Œé€šè¿‡ç‰©ç†é©±åŠ¨çš„å…‰å­¦å»ºæ¨¡å’ŒåŸºäºå¯å¾®åˆ†æ¸²æŸ“(Differentiable Rendering)çš„é‡æŠ•å½±ç­–ç•¥ï¼Œå°†3Då‡ ä½•è¯¯å·®ç›´æ¥è½¬åŒ–ä¸ºæ³•çº¿ä¼˜åŒ–ä¿¡å·ã€‚å…·ä½“è€Œè¨€ï¼Œç³»ç»Ÿåˆ©ç”¨å…‰ç›¸äº’ä½œç”¨é©±åŠ¨çš„3DGSå‚æ•°åŒ–æ¨¡å‹ç¡®ä¿å¤šè§†å›¾ä¸€è‡´æ€§ï¼Œå¹¶é€šè¿‡è·¨åŸŸç‰¹å¾èåˆæ¨¡å—(Cross-domain feature fusion)å°†å‡ ä½•å…ˆéªŒåµŒå…¥æ¡ä»¶æ‰©æ•£æ¨¡å‹ä¸­ä»¥çº¦æŸæ³•çº¿ç”Ÿæˆã€‚æ­¤å¤–ï¼Œç ”ç©¶å¼•å…¥äº†å¯å¾®åˆ†3Dé‡æŠ•å½±æŸå¤±(Differentiable 3D reprojection loss)å®ç°è‡ªç›‘ç£ä¼˜åŒ–ï¼Œæœ‰æ•ˆæ¶ˆé™¤äº†å¯¹å¯†é›†æ³•çº¿æ ‡æ³¨æ•°æ®é›†çš„ä¾èµ–ã€‚åœ¨Google Scanned Objectsæ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜ï¼ŒSINGADåœ¨å¤šä¸ªè¯„ä¼°æŒ‡æ ‡ä¸Šå‡ä¼˜äºç°æœ‰çš„å…ˆè¿›æ–¹æ³•ï¼ŒæˆåŠŸè§£å†³äº†å‡ ä½•ä¸ä¸€è‡´æ€§å’Œæ•°æ®ä¾èµ–æŒ‘æˆ˜ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.05950v1",
      "published_date": "2025-08-08 02:32:33 UTC",
      "updated_date": "2025-08-08 02:32:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:21:07.898700+00:00"
    },
    {
      "arxiv_id": "2508.05938v1",
      "title": "Prosocial Behavior Detection in Player Game Chat: From Aligning Human-AI Definitions to Efficient Annotation at Scale",
      "title_zh": "ç©å®¶æ¸¸æˆèŠå¤©ä¸­çš„äº²ç¤¾ä¼šè¡Œä¸ºæ£€æµ‹ï¼šä»äººæœºå®šä¹‰å¯¹é½åˆ°å¤§è§„æ¨¡é«˜æ•ˆæ ‡æ³¨",
      "authors": [
        "Rafal Kocielnik",
        "Min Kim",
        "Penphob",
        "Boonyarungsrit",
        "Fereshteh Soltani",
        "Deshawn Sambrano",
        "Animashree Anandkumar",
        "R. Michael Alvarez"
      ],
      "abstract": "Detecting prosociality in text--communication intended to affirm, support, or improve others' behavior--is a novel and increasingly important challenge for trust and safety systems. Unlike toxic content detection, prosociality lacks well-established definitions and labeled data, requiring new approaches to both annotation and deployment. We present a practical, three-stage pipeline that enables scalable, high-precision prosocial content classification while minimizing human labeling effort and inference costs. First, we identify the best LLM-based labeling strategy using a small seed set of human-labeled examples. We then introduce a human-AI refinement loop, where annotators review high-disagreement cases between GPT-4 and humans to iteratively clarify and expand the task definition-a critical step for emerging annotation tasks like prosociality. This process results in improved label quality and definition alignment. Finally, we synthesize 10k high-quality labels using GPT-4 and train a two-stage inference system: a lightweight classifier handles high-confidence predictions, while only $\\sim$35\\% of ambiguous instances are escalated to GPT-4o. This architecture reduces inference costs by $\\sim$70% while achieving high precision ($\\sim$0.90). Our pipeline demonstrates how targeted human-AI interaction, careful task formulation, and deployment-aware architecture design can unlock scalable solutions for novel responsible AI tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç©å®¶æ¸¸æˆèŠå¤©ä¸­çš„äº²ç¤¾ä¼šè¡Œä¸ºæ£€æµ‹ (Prosocial Behavior Detection) æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§æ—¨åœ¨æå‡ä¿¡ä»»ä¸å®‰å…¨ç³»ç»Ÿçš„ä¸‰é˜¶æ®µé«˜æ•ˆæµæ°´çº¿ã€‚ä¸ºäº†è§£å†³ prosociality ç¼ºä¹æ˜ç¡®å®šä¹‰å’Œæ ‡æ³¨æ•°æ®çš„é—®é¢˜ï¼Œç ”ç©¶é¦–å…ˆåˆ©ç”¨å°‘é‡äººå·¥æ ‡æ³¨æ ·æœ¬ç¡®å®šæœ€ä½³çš„ LLM æ ‡æ³¨ç­–ç•¥ï¼Œå¹¶å¼•å…¥ Human-AI ç»†åŒ–å¾ªç¯ï¼Œé€šè¿‡å®¡æ ¸ GPT-4 ä¸äººç±»çš„äº‰è®®æ¡ˆä¾‹æ¥è¿­ä»£å®Œå–„ä»»åŠ¡å®šä¹‰ã€‚éšåï¼Œç ”ç©¶åˆ©ç”¨ GPT-4 åˆæˆäº† 1 ä¸‡æ¡é«˜è´¨é‡æ ‡ç­¾ï¼Œå¹¶è®¾è®¡äº†ä¸€ä¸ªç”±è½»é‡çº§åˆ†ç±»å™¨ä¸ GPT-4o ç»„æˆçš„ä¸¤é˜¶æ®µæ¨ç†ç³»ç»Ÿã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¶æ„åœ¨ä¿æŒçº¦ 0.90 é«˜ç²¾ç¡®åº¦çš„åŒæ—¶ï¼ŒæˆåŠŸé™ä½äº†çº¦ 70% çš„æ¨ç†æˆæœ¬ã€‚è¿™ä¸€æ–¹æ³•å±•ç¤ºäº†å¦‚ä½•é€šè¿‡é’ˆå¯¹æ€§çš„ Human-AI äº¤äº’ä¸éƒ¨ç½²æ„ŸçŸ¥æ¶æ„è®¾è®¡ï¼Œä¸º novel responsible AI ä»»åŠ¡åœ¨å¤§è§„æ¨¡åœºæ™¯ä¸‹çš„é«˜æ•ˆæ ‡æ³¨ä¸éƒ¨ç½²æä¾›å¯æ‰©å±•çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 4 figures, 4 tables",
      "pdf_url": "https://arxiv.org/pdf/2508.05938v1",
      "published_date": "2025-08-08 02:04:14 UTC",
      "updated_date": "2025-08-08 02:04:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:21:16.383516+00:00"
    },
    {
      "arxiv_id": "2508.05934v1",
      "title": "ASLSL: Adaptive shared latent structure learning with incomplete multi-modal physiological data for multi-dimensional emotional feature selection",
      "title_zh": "ASLSLï¼šé¢å‘å¤šç»´æƒ…æ„Ÿç‰¹å¾é€‰æ‹©çš„ä¸å®Œæ•´å¤šæ¨¡æ€ç”Ÿç†æ•°æ®è‡ªé€‚åº”å…±äº«æ½œç»“æ„å­¦ä¹ ",
      "authors": [
        "Xueyuan Xu",
        "Tianze Yu",
        "Wenjia Dong",
        "Fulin Wei",
        "Li Zhuo"
      ],
      "abstract": "Recently, multi-modal physiological signals based emotion recognition has garnered increasing attention in the field of brain-computer interfaces. Nevertheness, the associated multi-modal physiological features are often high-dimensional and inevitably include irrelevant, redundant, and noisy representation, which can easily lead to overfitting, poor performance, and high computational complexity in emotion classifiers. Feature selection has been widely applied to address these challenges. However, previous studies generally assumed that multi-modal physiological data are complete, whereas in reality, the data are often incomplete due to the openness of the acquisition and operational environment. For example, a part of samples are available in several modalities but not in others. To address this issue, we propose a novel method for incomplete multi-modal physiological signal feature selection called adaptive shared latent structure learning (ASLSL). Based on the property that similar features share similar emotional labels, ASLSL employs adaptive shared latent structure learning to explore a common latent space shared for incomplete multi-modal physiological signals and multi-dimensional emotional labels, thereby mitigating the impact of missing information and mining consensus information. Two most popular multi-modal physiological emotion datasets (DEAP and DREAMER) with multi-dimensional emotional labels were utilized to compare the performance between compare ASLSL and seventeen feature selection methods. Comprehensive experimental results on these datasets demonstrate the effectiveness of ASLSL.",
      "tldr_zh": "é’ˆå¯¹å¤šæ¨¡æ€ç”Ÿç†ä¿¡å·åœ¨æƒ…ç»ªè¯†åˆ«ä¸­å­˜åœ¨çš„ç‰¹å¾é«˜ç»´å†—ä½™ä»¥åŠå®é™…åœºæ™¯ä¸‹æ•°æ®ä¸å®Œæ•´ï¼ˆincompleteï¼‰çš„é—®é¢˜ï¼Œè¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸ºASLSLï¼ˆAdaptive Shared Latent Structure Learningï¼‰çš„è‡ªé€‚åº”å…±äº«æ½œåœ¨ç»“æ„å­¦ä¹ æ–¹æ³•ã€‚è¯¥æ–¹æ³•æ—¨åœ¨è§£å†³å› é‡‡é›†ç¯å¢ƒå½±å“å¯¼è‡´çš„éƒ¨åˆ†æ ·æœ¬æ¨¡æ€ç¼ºå¤±æŒ‘æˆ˜ï¼Œä¸“é—¨ç”¨äºå¤šç»´æƒ…ç»ªç‰¹å¾é€‰æ‹©ã€‚ASLSLåŸºäºç›¸ä¼¼ç‰¹å¾å…±äº«ç›¸ä¼¼æƒ…ç»ªæ ‡ç­¾çš„å±æ€§ï¼Œé€šè¿‡æ„å»ºå…¬å…±æ½œåœ¨ç©ºé—´æ¥åŒæ—¶è¡¨å¾ä¸å®Œæ•´çš„å¤šæ¨¡æ€ä¿¡å·ä¸å¤šç»´æƒ…ç»ªæ ‡ç­¾ï¼Œä»è€Œæœ‰æ•ˆç¼“è§£ä¿¡æ¯ä¸¢å¤±çš„å½±å“å¹¶æŒ–æ˜å„æ¨¡æ€é—´çš„å…±è¯†ä¿¡æ¯ã€‚å®éªŒé‡‡ç”¨äº†DEAPå’ŒDREAMERä¸¤ä¸ªä¸»æµæ•°æ®é›†ï¼Œå¹¶å°†ASLSLä¸17ç§å…ˆè¿›çš„ç‰¹å¾é€‰æ‹©æ–¹æ³•è¿›è¡Œäº†å…¨é¢å¯¹æ¯”ã€‚ç»¼åˆå®éªŒç»“æœè¯æ˜ï¼ŒASLSLèƒ½å¤Ÿæ˜¾è‘—æé«˜æƒ…ç»ªåˆ†ç±»å™¨çš„æ€§èƒ½å¹¶é™ä½è®¡ç®—å¤æ‚åº¦ï¼Œä¸ºå¤„ç†ç°å®åœºæ™¯ä¸‹ä¸å®Œæ•´çš„å¤šæ¨¡æ€ç”Ÿç†æ•°æ®æä¾›äº†æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.05934v1",
      "published_date": "2025-08-08 01:54:02 UTC",
      "updated_date": "2025-08-08 01:54:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:21:22.588092+00:00"
    },
    {
      "arxiv_id": "2508.05933v1",
      "title": "REFS: Robust EEG feature selection with missing multi-dimensional annotation for emotion recognition",
      "title_zh": "REFSï¼šé¢å‘ç¼ºå¤±å¤šç»´æ ‡æ³¨çš„æƒ…æ„Ÿè¯†åˆ«é²æ£’EEGç‰¹å¾é€‰æ‹©",
      "authors": [
        "Xueyuan Xu",
        "Wenjia Dong",
        "Fulin Wei",
        "Li Zhuo"
      ],
      "abstract": "The affective brain-computer interface is a crucial technology for affective interaction and emotional intelligence, emerging as a significant area of research in the human-computer interaction. Compared to single-type features, multi-type EEG features provide a multi-level representation for analyzing multi-dimensional emotions. However, the high dimensionality of multi-type EEG features, combined with the relatively small number of high-quality EEG samples, poses challenges such as classifier overfitting and suboptimal real-time performance in multi-dimensional emotion recognition. Moreover, practical applications of affective brain-computer interface frequently encounters partial absence of multi-dimensional emotional labels due to the open nature of the acquisition environment, and ambiguity and variability in individual emotion perception. To address these challenges, this study proposes a novel EEG feature selection method for missing multi-dimensional emotion recognition. The method leverages adaptive orthogonal non-negative matrix factorization to reconstruct the multi-dimensional emotional label space through second-order and higher-order correlations, which could reduce the negative impact of missing values and outliers on label reconstruction. Simultaneously, it employs least squares regression with graph-based manifold learning regularization and global feature redundancy minimization regularization to enable EEG feature subset selection despite missing information, ultimately achieving robust EEG-based multi-dimensional emotion recognition. Simulation experiments on three widely used multi-dimensional emotional datasets, DREAMER, DEAP and HDED, reveal that the proposed method outperforms thirteen advanced feature selection methods in terms of robustness for EEG emotional feature selection.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æƒ…æ„Ÿè„‘æœºæ¥å£(affective brain-computer interface)ä¸­å¤šç±»å‹EEGç‰¹å¾ç»´åº¦é«˜ã€é«˜è´¨é‡æ ·æœ¬ç¨€ç¼ºä»¥åŠå¤šç»´æƒ…æ„Ÿæ ‡ç­¾å¸¸å› ç¯å¢ƒå› ç´ å’Œä¸ªä½“å·®å¼‚è€Œéƒ¨åˆ†ç¼ºå¤±çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºREFSçš„é²æ£’ç‰¹å¾é€‰æ‹©æ–¹æ³•ã€‚è¯¥æ–¹æ³•é‡‡ç”¨è‡ªé€‚åº”æ­£äº¤éè´ŸçŸ©é˜µåˆ†è§£(adaptive orthogonal non-negative matrix factorization)æŠ€æœ¯ï¼Œé€šè¿‡æ•æ‰äºŒé˜¶å’Œé«˜é˜¶ç›¸å…³æ€§æ¥é‡å»ºå¤šç»´æƒ…æ„Ÿæ ‡ç­¾ç©ºé—´ï¼Œä»è€Œé™ä½ç¼ºå¤±å€¼å’Œç¦»ç¾¤ç‚¹å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ã€‚åŒæ—¶ï¼ŒREFSåœ¨æœ€å°äºŒä¹˜å›å½’æ¡†æ¶ä¸­é›†æˆäº†åŸºäºå›¾çš„æµå½¢å­¦ä¹ æ­£åˆ™åŒ–(graph-based manifold learning regularization)å’Œå…¨å±€ç‰¹å¾å†—ä½™æœ€å°åŒ–æ­£åˆ™åŒ–(global feature redundancy minimization regularization)ï¼Œç¡®ä¿äº†åœ¨ä¿¡æ¯ä¸å®Œæ•´æƒ…å†µä¸‹çš„ç‰¹å¾å­é›†é€‰æ‹©ã€‚åœ¨DREAMERã€DEAPå’ŒHDEDä¸‰ä¸ªå…¬å¼€æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒREFSåœ¨ç‰¹å¾é€‰æ‹©çš„é²æ£’æ€§ä¸Šæ˜¾è‘—ä¼˜äº13ç§å…ˆè¿›ç®—æ³•ã€‚è¯¥ç ”ç©¶æˆæœä¸ºå®ç°å¼€æ”¾ç¯å¢ƒä¸‹ç¨³å¥çš„å¤šç»´æƒ…æ„Ÿè¯†åˆ«æä¾›äº†æœ‰æ•ˆçš„æŠ€æœ¯æ–¹æ¡ˆï¼Œå¯¹å¢å¼ºè„‘æœºæ¥å£çš„æƒ…æ„Ÿäº¤äº’èƒ½åŠ›å…·æœ‰é‡è¦æ„ä¹‰ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.05933v1",
      "published_date": "2025-08-08 01:53:46 UTC",
      "updated_date": "2025-08-08 01:53:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:21:22.889298+00:00"
    },
    {
      "arxiv_id": "2508.09189v1",
      "title": "Hybrid(Transformer+CNN)-based Polyp Segmentation",
      "title_zh": "åŸºäºæ··åˆï¼ˆTransformer+CNNï¼‰çš„æ¯è‚‰åˆ†å‰²",
      "authors": [
        "Madan Baduwal"
      ],
      "abstract": "Colonoscopy is still the main method of detection and segmentation of colonic polyps, and recent advancements in deep learning networks such as U-Net, ResUNet, Swin-UNet, and PraNet have made outstanding performance in polyp segmentation. Yet, the problem is extremely challenging due to high variation in size, shape, endoscopy types, lighting, imaging protocols, and ill-defined boundaries (fluid, folds) of the polyps, rendering accurate segmentation a challenging and problematic task. To address these critical challenges in polyp segmentation, we introduce a hybrid (Transformer + CNN) model that is crafted to enhance robustness against evolving polyp characteristics. Our hybrid architecture demonstrates superior performance over existing solutions, particularly in addressing two critical challenges: (1) accurate segmentation of polyps with ill-defined margins through boundary-aware attention mechanisms, and (2) robust feature extraction in the presence of common endoscopic artifacts, including specular highlights, motion blur, and fluid occlusions. Quantitative evaluations reveal significant improvements in segmentation accuracy (Recall improved by 1.76%, i.e., 0.9555, accuracy improved by 0.07%, i.e., 0.9849) and artifact resilience compared to state-of-the-art polyp segmentation methods.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäº Hybrid(Transformer+CNN) çš„æ¯è‚‰åˆ†å‰²æ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³ç»“è‚ é•œæ£€æŸ¥ä¸­æ¯è‚‰å°ºå¯¸ã€å½¢çŠ¶å¤šå˜ä»¥åŠè¾¹ç•Œæ¨¡ç³Šå¸¦æ¥çš„åˆ†å‰²éš¾é¢˜ã€‚è¯¥æ··åˆæ¶æ„ç»“åˆäº† Transformer å’Œ CNN çš„ä¼˜åŠ¿ï¼Œä¸“é—¨è®¾è®¡ç”¨äºå¢å¼ºå¯¹ä¸æ–­å˜åŒ–çš„æ¯è‚‰ç‰¹å¾çš„é²æ£’æ€§ã€‚é€šè¿‡å¼•å…¥è¾¹ç•Œæ„ŸçŸ¥æ³¨æ„åŠ›æœºåˆ¶(boundary-aware attention mechanisms)ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆå¤„ç†è¾¹ç¼˜æ¨¡ç³Šæ¯è‚‰çš„ç²¾ç¡®åˆ†å‰²é—®é¢˜ã€‚é’ˆå¯¹å†…çª¥é•œä¸­å¸¸è§çš„é•œé¢é«˜å…‰ã€è¿åŠ¨æ¨¡ç³Šå’Œæ¶²ä½“é®æŒ¡ç­‰ä¼ªå½±ï¼Œè¯¥æ¶æ„è¡¨ç°å‡ºæå¼ºçš„é²æ£’ç‰¹å¾æå–èƒ½åŠ›ã€‚å®šé‡è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨åˆ†å‰²å‡†ç¡®ç‡ä¸Šå–å¾—äº†æ˜¾è‘—æå‡ï¼Œå…¶ä¸­å¬å›ç‡(Recall)æé«˜è‡³0.9555ï¼Œå‡†ç¡®ç‡(Accuracy)è¾¾åˆ°0.9849ã€‚å®éªŒè¯æ˜è¯¥æ¨¡å‹åœ¨å¤„ç†å¤æ‚å†…çª¥é•œä¼ªå½±å’Œè¾¹ç¼˜ä¸æ¸…æ™°æƒ…å†µæ—¶ï¼Œå…¶æ€§èƒ½å’Œä¼ªå½±æŠ—æ€§æ˜æ˜¾ä¼˜äºç°æœ‰çš„ U-Netã€Swin-UNet å’Œ PraNet ç­‰ SOTA æ¨¡å‹ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "8 pages",
      "pdf_url": "https://arxiv.org/pdf/2508.09189v1",
      "published_date": "2025-08-08 01:42:05 UTC",
      "updated_date": "2025-08-08 01:42:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:21:20.598076+00:00"
    },
    {
      "arxiv_id": "2508.11673v1",
      "title": "Contrastive Regularization over LoRA for Multimodal Biomedical Image Incremental Learning",
      "title_zh": "é¢å‘å¤šæ¨¡æ€ç”Ÿç‰©åŒ»å­¦å›¾åƒå¢é‡å­¦ä¹ çš„åŸºäº LoRA çš„å¯¹æ¯”æ­£åˆ™åŒ–",
      "authors": [
        "Haojie Zhang",
        "Yixiong Liang",
        "Hulin Kuang",
        "Lihui Cen",
        "Zhe Qu",
        "Yigang Cen",
        "Min Zeng",
        "Shichao Kan"
      ],
      "abstract": "Multimodal Biomedical Image Incremental Learning (MBIIL) is essential for handling diverse tasks and modalities in the biomedical domain, as training separate models for each modality or task significantly increases inference costs. Existing incremental learning methods focus on task expansion within a single modality, whereas MBIIL seeks to train a unified model incrementally across modalities. The MBIIL faces two challenges: I) How to preserve previously learned knowledge during incremental updates? II) How to effectively leverage knowledge acquired from existing modalities to support new modalities? To address these challenges, we propose MSLoRA-CR, a method that fine-tunes Modality-Specific LoRA modules while incorporating Contrastive Regularization to enhance intra-modality knowledge sharing and promote inter-modality knowledge differentiation. Our approach builds upon a large vision-language model (LVLM), keeping the pretrained model frozen while incrementally adapting new LoRA modules for each modality or task. Experiments on the incremental learning of biomedical images demonstrate that MSLoRA-CR outperforms both the state-of-the-art (SOTA) approach of training separate models for each modality and the general incremental learning method (incrementally fine-tuning LoRA). Specifically, MSLoRA-CR achieves a 1.88% improvement in overall performance compared to unconstrained incremental learning methods while maintaining computational efficiency. Our code is publicly available at https://github.com/VentusAislant/MSLoRA_CR.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šæ¨¡æ€ç”Ÿç‰©åŒ»å­¦å›¾åƒå¢é‡å­¦ä¹  (Multimodal Biomedical Image Incremental Learning, MBIIL) é¢ä¸´çš„ä¿ç•™æ—§çŸ¥è¯†ä¸è·¨æ¨¡æ€çŸ¥è¯†è¿ç§»æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åä¸º MSLoRA-CR çš„åˆ›æ–°æ–¹æ³•ã€‚è¯¥æ–¹æ³•åœ¨ä¿æŒé¢„è®­ç»ƒå¤§è§†è§‰è¯­è¨€æ¨¡å‹ (LVLM) æƒé‡å†»ç»“çš„åŸºç¡€ä¸Šï¼Œé€šè¿‡å¾®è°ƒç‰¹å®šæ¨¡æ€çš„ LoRA (Modality-Specific LoRA) æ¨¡å—å¹¶å¼•å…¥å¯¹æ¯”æ­£åˆ™åŒ– (Contrastive Regularization) æŠ€æœ¯ï¼Œæ—¨åœ¨å¢å¼ºæ¨¡æ€å†…çŸ¥è¯†å…±äº«å¹¶ä¿ƒè¿›æ¨¡æ€é—´çŸ¥è¯†åŒºåˆ†ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒMSLoRA-CR åœ¨ç”Ÿç‰©åŒ»å­¦å›¾åƒå¢é‡å­¦ä¹ ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä¸ä»…ä¼˜äºä¸ºå„æ¨¡æ€å•ç‹¬è®­ç»ƒæ¨¡å‹çš„ä¼ ç»Ÿ SOTA æ–¹æ³•ï¼Œç›¸æ¯”å¸¸è§„ LoRA å¢é‡å¾®è°ƒä¹Ÿå®ç°äº† 1.88% çš„æ•´ä½“æ€§èƒ½æå‡ã€‚è¯¥æ¡†æ¶åœ¨æå‡æ¨¡å‹æ€§èƒ½çš„åŒæ—¶å…¼é¡¾äº†è®¡ç®—æ•ˆç‡ï¼Œä¸ºåœ¨åŒ»ç–—åœºæ™¯ä¸‹æ„å»ºè·¨æ¨¡æ€ç»Ÿä¸€å¢é‡æ¨¡å‹æä¾›äº†æœ‰æ•ˆè·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.MM"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 3 figures, submitted to ACM Multimedia 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.11673v1",
      "published_date": "2025-08-08 01:10:06 UTC",
      "updated_date": "2025-08-08 01:10:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:21:46.858494+00:00"
    },
    {
      "arxiv_id": "2508.05923v1",
      "title": "Enhancing Software Vulnerability Detection Through Adaptive Test Input Generation Using Genetic Algorithm",
      "title_zh": "åŸºäºé—ä¼ ç®—æ³•çš„è‡ªé€‚åº”æµ‹è¯•è¾“å…¥ç”Ÿæˆå¢å¼ºè½¯ä»¶æ¼æ´æ£€æµ‹",
      "authors": [
        "Yanusha Mehendran",
        "Maolin Tang",
        "Yi Lu"
      ],
      "abstract": "Software vulnerabilities continue to undermine the reliability and security of modern systems, particularly as software complexity outpaces the capabilities of traditional detection methods. This study introduces a genetic algorithm-based method for test input generation that innovatively integrates genetic operators and adaptive learning to enhance software vulnerability detection. A key contribution is the application of the crossover operator, which facilitates exploration by searching across a broader space of potential test inputs. Complementing this, an adaptive feedback mechanism continuously learns from the system's execution behavior and dynamically guides input generation toward promising areas of the input space. Rather than relying on fixed or randomly selected inputs, the approach evolves a population of structurally valid test cases using feedback-driven selection, enabling deeper and more effective code traversal. This strategic integration of exploration and exploitation ensures that both diverse and targeted test inputs are developed over time. Evaluation was conducted across nine open-source JSON-processing libraries. The proposed method achieved substantial improvements in coverage compared to a benchmark evolutionary fuzzing method, with average gains of 39.8% in class coverage, 62.4% in method coverage, 105.0% in line coverage, 114.0% in instruction coverage, and 166.0% in branch coverage. These results highlight the method's capacity to detect deeper and more complex vulnerabilities, offering a scalable and adaptive solution to software security testing.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäº Genetic Algorithm çš„æµ‹è¯•è¾“å…¥ç”Ÿæˆæ–¹æ³•ï¼Œæ—¨åœ¨æé«˜ç°ä»£å¤æ‚è½¯ä»¶çš„ Vulnerability Detection æ•ˆç‡ã€‚è¯¥æ–¹æ³•åˆ›æ–°æ€§åœ°æ•´åˆäº† Crossover ç®—å­ä»¥æ‰©å¤§æµ‹è¯•è¾“å…¥çš„æœç´¢ç©ºé—´ï¼Œå¹¶ç»“åˆ Adaptive Feedback æœºåˆ¶æ ¹æ®ç³»ç»Ÿæ‰§è¡Œè¡Œä¸ºåŠ¨æ€å¼•å¯¼è¾“å…¥ç”Ÿæˆã€‚é€šè¿‡æ¼”åŒ–å‡ºä¸€ç³»åˆ—ç»“æ„æœ‰æ•ˆçš„æµ‹è¯•ç”¨ä¾‹ï¼Œè¯¥æ–¹æ¡ˆèƒ½å¤Ÿå®ç°æ¯”ä¼ ç»Ÿæ–¹æ³•æ›´æ·±å±‚æ¬¡çš„ Code Traversalã€‚åœ¨ä¹ä¸ªå¼€æº JSON å¤„ç†åº“çš„è¯„ä¼°ä¸­ï¼Œè¯¥æ–¹æ³•ç›¸æ¯”åŸºå‡† Evolutionary Fuzzing æ˜¾è‘—æå‡äº†è¦†ç›–ç‡ï¼Œå…¶ä¸­ Line Coverage å¹³å‡æé«˜ 105.0%ï¼ŒBranch Coverage æé«˜ 166.0%ã€‚å®éªŒç»“æœè¯æ˜äº†è¯¥æ–¹æ³•åœ¨æ£€æµ‹æ·±å±‚å¤æ‚æ¼æ´æ–¹é¢çš„å“è¶Šèƒ½åŠ›ï¼Œä¸ºè½¯ä»¶å®‰å…¨æµ‹è¯•æä¾›äº†ä¸€ç§å¯æ‰©å±•ä¸”å…·æœ‰è‡ªé€‚åº”æ€§çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "26 Pages, 3 figures, 6 Tables, Submitted to Empirical Software Engineering and it is under review",
      "pdf_url": "https://arxiv.org/pdf/2508.05923v1",
      "published_date": "2025-08-08 01:03:22 UTC",
      "updated_date": "2025-08-08 01:03:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:21:58.964414+00:00"
    },
    {
      "arxiv_id": "2508.06583v2",
      "title": "Discerning minds or generic tutors? Evaluating instructional guidance capabilities in Socratic LLMs",
      "title_zh": "æ´å¯Ÿç§‹æ¯«è¿˜æ˜¯å¹³åº¸å¯¼å¸ˆï¼Ÿè¯„ä¼°è‹æ ¼æ‹‰åº•å¼å¤§è¯­è¨€æ¨¡å‹çš„æ•™å­¦å¼•å¯¼èƒ½åŠ›",
      "authors": [
        "Ying Liu",
        "Can Li",
        "Ting Zhang",
        "Mei Wang",
        "Qiannan Zhu",
        "Jian Li",
        "Hua Huang"
      ],
      "abstract": "The conversational capabilities of large language models hold significant promise for enabling scalable and interactive tutoring. While prior research has primarily examined their ability to generate Socratic questions, it often overlooks a critical aspect: adaptively guiding learners in accordance with their cognitive states. This study moves beyond question generation to emphasize instructional guidance capability. We ask: Can LLMs emulate expert tutors who dynamically adjust strategies in response to learners' states? To investigate this, we propose GuideEval, a benchmark grounded in authentic educational dialogues that evaluates pedagogical guidance through a three-phase behavioral framework: (1) Perception, inferring learner states; (2) Orchestration, adapting instructional strategies; and (3) Elicitation, stimulating proper reflections. Empirical results indicate that existing LLMs often fail to provide effective adaptive scaffolding when learners experience confusion or require redirection. To complement the quantitative evaluation, we conduct a detailed failure case analysis, providing an intuitive understanding of these shortcomings. Furthermore, we introduce a behavior-guided finetuning strategy that leverages behavior-prompted instructional dialogues, substantially enhancing guidance performance. By shifting the focus from isolated content evaluation to learner-centered state-aware interaction, our work advocates a more dialogic paradigm for evaluating Socratic LLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨æ•™è‚²è¾…å¯¼ä¸­çš„åº”ç”¨ï¼ŒæŒ‡å‡ºä»¥å¾€ç ”ç©¶å¤šå…³æ³¨è‹æ ¼æ‹‰åº•å¼æé—®(Socratic questions)çš„ç”Ÿæˆï¼Œè€Œå¿½ç•¥äº†æ ¹æ®å­¦ä¹ è€…è®¤çŸ¥çŠ¶æ€è¿›è¡ŒåŠ¨æ€æŒ‡å¯¼çš„èƒ½åŠ›ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†GuideEvalè¯„æµ‹åŸºå‡†ï¼Œé€šè¿‡æ„ŸçŸ¥(Perception)ã€ç¼–æ’(Orchestration)å’Œå¯å‘(Elicitation)ä¸‰ä¸ªé˜¶æ®µçš„è¡Œä¸ºæ¡†æ¶æ¥è¯„ä¼°LLMsçš„æ•™å­¦å¼•å¯¼èƒ½åŠ›ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œç°æœ‰çš„LLMsåœ¨å­¦ä¹ è€…æ„Ÿåˆ°å›°æƒ‘æˆ–éœ€è¦é‡æ–°å¼•å¯¼æ—¶ï¼Œå¾€å¾€æ— æ³•æä¾›æœ‰æ•ˆçš„è‡ªé€‚åº”æ”¯æ¶(adaptive scaffolding)ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œç ”ç©¶å¼•å…¥äº†ä¸€ç§è¡Œä¸ºå¯¼å‘çš„å¾®è°ƒç­–ç•¥(behavior-guided finetuning)ï¼Œåˆ©ç”¨è¡Œä¸ºæç¤ºçš„æ•™å­¦å¯¹è¯æ˜¾è‘—æå‡äº†æ¨¡å‹çš„å¼•å¯¼æ€§èƒ½ã€‚è¯¥å·¥ä½œå¼ºè°ƒäº†ä»å­¤ç«‹çš„å†…å®¹è¯„ä¼°è½¬å‘ä»¥å­¦ä¹ è€…ä¸ºä¸­å¿ƒçš„å¯¹è¯äº¤äº’èŒƒå¼ï¼Œä¸ºè¯„ä¼°å’Œæå‡è‹æ ¼æ‹‰åº•å¼æ™ºèƒ½ä½“(Socratic LLMs)çš„äº¤äº’è´¨é‡å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.06583v2",
      "published_date": "2025-08-08 01:02:44 UTC",
      "updated_date": "2025-09-29 02:32:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:22:02.859519+00:00"
    },
    {
      "arxiv_id": "2508.05913v1",
      "title": "Do Ethical AI Principles Matter to Users? A Large-Scale Analysis of User Sentiment and Satisfaction",
      "title_zh": "AI ä¼¦ç†åŸåˆ™å¯¹ç”¨æˆ·é‡è¦å—ï¼Ÿä¸€é¡¹å…³äºç”¨æˆ·æƒ…æ„Ÿä¸æ»¡æ„åº¦çš„å¤§è§„æ¨¡åˆ†æ",
      "authors": [
        "Stefan Pasch",
        "Min Chul Cha"
      ],
      "abstract": "As AI systems become increasingly embedded in organizational workflows and consumer applications, ethical principles such as fairness, transparency, and robustness have been widely endorsed in policy and industry guidelines. However, there is still scarce empirical evidence on whether these principles are recognized, valued, or impactful from the perspective of users. This study investigates the link between ethical AI and user satisfaction by analyzing over 100,000 user reviews of AI products from G2. Using transformer-based language models, we measure sentiment across seven ethical dimensions defined by the EU Ethics Guidelines for Trustworthy AI. Our findings show that all seven dimensions are positively associated with user satisfaction. Yet, this relationship varies systematically across user and product types. Technical users and reviewers of AI development platforms more frequently discuss system-level concerns (e.g., transparency, data governance), while non-technical users and reviewers of end-user applications emphasize human-centric dimensions (e.g., human agency, societal well-being). Moreover, the association between ethical AI and user satisfaction is significantly stronger for non-technical users and end-user applications across all dimensions. Our results highlight the importance of ethical AI design from users' perspectives and underscore the need to account for contextual differences across user roles and product types.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ä¼¦ç†AIåŸåˆ™ä¸ç”¨æˆ·æ»¡æ„åº¦ä¹‹é—´çš„è”ç³»ï¼Œæ—¨åœ¨å¡«è¡¥å…³äºç”¨æˆ·å¦‚ä½•æ„ŸçŸ¥å’Œè¯„ä»·è¿™äº›åŸåˆ™çš„ç»éªŒç ”ç©¶ç©ºç™½ã€‚ç ”ç©¶åˆ†æäº†æ¥è‡ª G2 å¹³å°çš„è¶…è¿‡ 100,000 æ¡ AI äº§å“ç”¨æˆ·è¯„è®ºï¼Œå¹¶åˆ©ç”¨åŸºäº transformer çš„è¯­è¨€æ¨¡å‹ï¼Œæ ¹æ®æ¬§ç›Ÿã€Šå¯ä¿¡AIä¼¦ç†æŒ‡å—ã€‹(EU Ethics Guidelines for Trustworthy AI) å®šä¹‰çš„ä¸ƒä¸ªä¼¦ç†ç»´åº¦è¡¡é‡ç”¨æˆ·æƒ…æ„Ÿã€‚ç»“æœæ˜¾ç¤ºï¼Œæ‰€æœ‰ä¸ƒä¸ªä¼¦ç†ç»´åº¦å‡ä¸ç”¨æˆ·æ»¡æ„åº¦å‘ˆæ­£ç›¸å…³ï¼Œè¯æ˜äº†ä¼¦ç† AI è®¾è®¡åœ¨ç”¨æˆ·å±‚é¢çš„é‡è¦ä»·å€¼ã€‚ç ”ç©¶è¿›ä¸€æ­¥å‘ç°ï¼Œè¿™ç§å…³è”åœ¨ä¸åŒç”¨æˆ·å’Œäº§å“ç±»å‹é—´å­˜åœ¨ç³»ç»Ÿæ€§å·®å¼‚ï¼ŒæŠ€æœ¯ç”¨æˆ·æ›´å…³æ³¨é€æ˜åº¦(transparency)å’Œæ•°æ®æ²»ç†(data governance)ç­‰ç³»ç»Ÿå±‚é¢é—®é¢˜ï¼Œè€ŒéæŠ€æœ¯ç”¨æˆ·åˆ™æ›´å¼ºè°ƒäººç±»ä¸»ä½“æ€§(human agency)å’Œç¤¾ä¼šç¦åˆ©(societal well-being)ç­‰ç»´åº¦ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œä¼¦ç† AI ä¸æ»¡æ„åº¦çš„æ­£å‘å…³è”åœ¨éæŠ€æœ¯ç”¨æˆ·å’Œç»ˆç«¯åº”ç”¨ä¸­æ˜¾è‘—æ›´å¼ºã€‚è¯¥ç»“æœå¼ºè°ƒäº†ä»ç”¨æˆ·è§†è§’è¿›è¡Œä¼¦ç† AI è®¾è®¡çš„é‡è¦æ€§ï¼Œå¹¶æç¤ºå¼€å‘è€…éœ€æ ¹æ®ç”¨æˆ·è§’è‰²å’Œäº§å“ä¸Šä¸‹æ–‡å®šåˆ¶å·®å¼‚åŒ–çš„ä¼¦ç†ç­–ç•¥ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.05913v1",
      "published_date": "2025-08-08 00:27:50 UTC",
      "updated_date": "2025-08-08 00:27:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T10:21:48.193852+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 164,
  "processed_papers_count": 164,
  "failed_papers_count": 0,
  "llm_backup_calls": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-01-24T10:23:00.141977+00:00"
}