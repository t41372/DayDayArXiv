{
  "date": "2024-07-05",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-07-05 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦 AI 和机器学习领域，包括大型语言模型（LLM）的安全性和鲁棒性、强化学习中的策略优化，以及多模态和图像处理技术。令人印象深刻的是 Cynthia Rudin 等学者的作品，如讨论 Rashomon Effect 的论文，揭示了机器学习模型在 tabular 数据上的多样性和不确定性；此外，LLM 代理和对抗攻击研究也显示出高话题度，强调了 AI 应用中的潜在风险和创新防御。\n\n下面，我将挑选并简要讨论部分关键论文，先从重要和高影响力主题入手（如 LLM 安全、强化学习和多模态模型），再快速掠过其他相关但不那么核心的论文。每个条目包括论文标题（中文 + 英文）和核心贡献。\n\n### LLM 安全与鲁棒性\n- **Jailbreak Attacks and Defenses Against Large Language Models: A Survey** (越狱攻击与防御大型语言模型：一个调查)  \n  这篇综述性论文系统梳理了针对 LLM 的越狱攻击（如基于提示的攻击）和防御方法，分类为黑盒和白盒攻击，强调防御策略（如提示级和模型级）的必要性。主要发现：现有水印和防御方案易受攻击，呼吁更鲁棒的 LLM 安全机制。\n\n- **On Evaluating The Performance of Watermarked Machine-Generated Texts Under Adversarial Attacks** (在对抗攻击下评估水印机器生成文本的性能)  \n  作者评估了八种水印方法（如 KGW 和 Exponential）在十二种攻击下的鲁棒性，发现预文本水印更不易察觉，但后文本攻击更有效。主要贡献：揭示水印易被破坏，建议结合攻击提升 LLM 文本真实性验证。\n\n- **Waterfall: Framework for Robust and Scalable Text Watermarking and Provenance for LLMs** (瀑布框架：用于 LLM 的鲁棒可扩展文本水印和来源追踪)  \n  这篇论文提出 Waterfall 框架，实现文本水印的鲁棒性和可扩展性，支持多语言和类型。主要发现：框架显著提升水印在对抗环境下的性能，并能检测 LLM 训练数据滥用，适用于知识产权保护。\n\n### 强化学习与决策优化\n- **Amazing Things Come From Having Many Good Models** (拥有许多优秀模型的惊人成果)  \n  Cynthia Rudin 等学者探讨 Rashomon Effect，即同一数据集存在多个等效模型的现象。主要贡献：分析其对公平性、变量重要性和算法选择的影响，提供理论指导，帮助优化机器学习在 tabular 数据上的应用。\n\n- **Re-Tuning: Overcoming the Compositionality Limits of Large Language Models with Recursive Tuning** (重新调整：通过递归调整克服大型语言模型的组合性限制)  \n  这篇论文提出 Re-Tuning 方法，使用递归优化提升 LLM 在组合任务（如整数加法）的性能。主要发现：相比传统方法，Re-Tuning 显著提高准确率（如在动态编程任务中），并更高效。\n\n- **Hindsight Preference Learning for Offline Preference-based Reinforcement Learning** (后见偏好学习在离线偏好强化学习中的应用)  \n  作者开发 Hindsight Preference Learning 框架，用于离线强化学习。主要贡献：通过变分自编码器处理轨迹数据，提升模型在噪声数据集上的鲁棒性，实验显示在 MuJoCo 等环境中性能优于基线。\n\n### 多模态和计算机视觉\n- **Me, Myself, and AI: The Situational Awareness Dataset (SAD) for LLMs** (我、自己和 AI：LLM 的情境意识数据集)  \n  Andreas Geiger 等参与的这篇论文构建 SAD 数据集，评估 LLM 的情境意识（如自我认知）。主要发现：LLM 在预测行为和不确定性上表现良好，但远低于人类水平，强调 AI 安全风险。\n\n- **LaRa: Efficient Large-Baseline Radiance Fields** (LaRa：高效的大基线辐射场)  \n  作者提出 LaRa 框架，用于高效的 3D 辐射场重建。主要贡献：结合视觉变压器和扩散模型，提升多视图合成质量，实验在基准数据集上表现出色，适用于资源受限的场景。\n\n- **AnySR: Realizing Image Super-Resolution as Any-Scale, Any-Resource** (AnySR：实现图像超分辨率为任意规模、任意资源)  \n  这篇论文引入 AnySR 方法，支持任意规模图像超分辨率。主要发现：通过特征交织和资源优化，减少计算需求，同时保持性能，与现有方法相当，适用于实时应用。\n\n### 其他快速掠过\n其他论文涉及领域较窄或技术性强，这里仅简要提及重点：\n- **Neural varifolds: an aggregate representation for quantifying the geometry of point clouds** (神经变形体：用于量化点云几何的聚合表示)  \n  提出神经变形体表示，提升点云几何分析，主要用于形状匹配和分类。\n- **EventChat: Implementation and user-centric evaluation of a large language model-driven conversational recommender system** (EventChat：基于 LLM 的对话推荐系统实现和用户评估)  \n  构建 EventChat 系统，优化 LLM 在休闲事件推荐中的性能，强调用户体验和成本效率。\n- **PDiscoFormer: Relaxing Part Discovery Constraints with Vision Transformers** (PDiscoFormer：使用视觉变压器放宽部分发现约束)  \n  改进视觉变压器在细粒度分类中的部分发现，实验在基准数据集上提升准确率。\n- 其余如医疗图像处理（如 Brain Age Estimation）和游戏 AI（如 XQSV）论文虽有创新，但影响力较小，故不展开讨论。\n\n总之，今天的论文突显 AI 模型的鲁棒性和扩展性挑战，同时提供了一些实用解决方案。感兴趣的读者可关注 LLM 安全和强化学习方向，完整列表可在 arXiv 查看！",
  "papers": [
    {
      "arxiv_id": "2407.04885v1",
      "title": "Automating Venture Capital: Founder assessment using LLM-powered segmentation, feature engineering and automated labeling techniques",
      "title_zh": "翻译失败",
      "authors": [
        "Ekin Ozince",
        "Yiğit Ihlamur"
      ],
      "abstract": "This study explores the application of large language models (LLMs) in\nventure capital (VC) decision-making, focusing on predicting startup success\nbased on founder characteristics. We utilize LLM prompting techniques, like\nchain-of-thought, to generate features from limited data, then extract insights\nthrough statistics and machine learning. Our results reveal potential\nrelationships between certain founder characteristics and success, as well as\ndemonstrate the effectiveness of these characteristics in prediction. This\nframework for integrating ML techniques and LLMs has vast potential for\nimproving startup success prediction, with important implications for VC firms\nseeking to optimize their investment strategies.",
      "tldr_zh": "本研究探讨了使用大型语言模型 (LLMs) 自动评估风险投资 (VC) 中的创始人特征，以预测初创企业成功。研究采用 LLM 提示技术，如 chain-of-thought，进行特征生成、分割、特征工程和自动标注，然后通过统计和 machine learning (ML) 分析提取洞见。结果显示，某些创始人特征与企业成功存在潜在关系，并证明这些特征在预测中的有效性。该框架整合 LLMs 和 ML 技术，有望优化 VC 公司的投资策略，提高决策准确性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "For the relevant code, see\n  https://github.com/velapartners/moneyball-LLM-based-founder-features.git",
      "pdf_url": "http://arxiv.org/pdf/2407.04885v1",
      "published_date": "2024-07-05 22:54:13 UTC",
      "updated_date": "2024-07-05 22:54:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:47:12.938714"
    },
    {
      "arxiv_id": "2407.04882v1",
      "title": "Improving ensemble extreme precipitation forecasts using generative artificial intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Yingkai Sha",
        "Ryan A. Sobash",
        "David John Gagne II"
      ],
      "abstract": "An ensemble post-processing method is developed to improve the probabilistic\nforecasts of extreme precipitation events across the conterminous United States\n(CONUS). The method combines a 3-D Vision Transformer (ViT) for bias correction\nwith a Latent Diffusion Model (LDM), a generative Artificial Intelligence (AI)\nmethod, to post-process 6-hourly precipitation ensemble forecasts and produce\nan enlarged generative ensemble that contains spatiotemporally consistent\nprecipitation trajectories. These trajectories are expected to improve the\ncharacterization of extreme precipitation events and offer skillful multi-day\naccumulated and 6-hourly precipitation guidance. The method is tested using the\nGlobal Ensemble Forecast System (GEFS) precipitation forecasts out to day 6 and\nis verified against the Climate-Calibrated Precipitation Analysis (CCPA) data.\nVerification results indicate that the method generated skillful ensemble\nmembers with improved Continuous Ranked Probabilistic Skill Scores (CRPSSs) and\nBrier Skill Scores (BSSs) over the raw operational GEFS and a multivariate\nstatistical post-processing baseline. It showed skillful and reliable\nprobabilities for events at extreme precipitation thresholds. Explainability\nstudies were further conducted, which revealed the decision-making process of\nthe method and confirmed its effectiveness on ensemble member generation. This\nwork introduces a novel, generative-AI-based approach to address the limitation\nof small numerical ensembles and the need for larger ensembles to identify\nextreme precipitation events.",
      "tldr_zh": "本文提出了一种集成后处理方法，使用3-D Vision Transformer (ViT) 进行偏差校正和Latent Diffusion Model (LDM) 生成更大的时空一致降水轨迹，旨在改善美国本土（CONUS）极端降水事件的概率预报。实验基于Global Ensemble Forecast System (GEFS) 的6小时预报数据，到第6天验证，与Climate-Calibrated Precipitation Analysis (CCPA) 比较，结果显示该方法显著提升了Continuous Ranked Probabilistic Skill Scores (CRPSSs) 和Brier Skill Scores (BSSs)，并为极端阈值事件提供可靠概率。可解释性研究确认了该生成AI方法的决策过程，有效解决了小集成预报的局限性，促进极端降水事件的准确识别。",
      "categories": [
        "physics.ao-ph",
        "cs.AI"
      ],
      "primary_category": "physics.ao-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.04882v1",
      "published_date": "2024-07-05 22:30:33 UTC",
      "updated_date": "2024-07-05 22:30:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:47:27.305247"
    },
    {
      "arxiv_id": "2407.07917v1",
      "title": "Non-Cooperative Backdoor Attacks in Federated Learning: A New Threat Landscape",
      "title_zh": "联邦学习中的非合作后门攻击：一个新的威胁景观",
      "authors": [
        "Tuan Nguyen",
        "Dung Thuy Nguyen",
        "Khoa D Doan",
        "Kok-Seng Wong"
      ],
      "abstract": "Despite the promise of Federated Learning (FL) for privacy-preserving model\ntraining on distributed data, it remains susceptible to backdoor attacks. These\nattacks manipulate models by embedding triggers (specific input patterns) in\nthe training data, forcing misclassification as predefined classes during\ndeployment. Traditional single-trigger attacks and recent work on cooperative\nmultiple-trigger attacks, where clients collaborate, highlight limitations in\nattack realism due to coordination requirements. We investigate a more alarming\nscenario: non-cooperative multiple-trigger attacks. Here, independent\nadversaries introduce distinct triggers targeting unique classes. These\nparallel attacks exploit FL's decentralized nature, making detection difficult.\nOur experiments demonstrate the alarming vulnerability of FL to such attacks,\nwhere individual backdoors can be successfully learned without impacting the\nmain task. This research emphasizes the critical need for robust defenses\nagainst diverse backdoor attacks in the evolving FL landscape. While our focus\nis on empirical analysis, we believe it can guide backdoor research toward more\nrealistic settings, highlighting the crucial role of FL in building robust\ndefenses against diverse backdoor threats. The code is available at\n\\url{https://anonymous.4open.science/r/nba-980F/}.",
      "tldr_zh": "本研究探讨了 Federated Learning (FL) 中一种新的威胁：非合作后门攻击。这种攻击涉及独立对手在训练数据中嵌入不同的触发器（triggers），针对特定类别的误分类，而无需任何协调，利用 FL 的去中心化特性使检测更加困难。实验结果显示，这种攻击能成功植入后门而不影响主要任务，突显了 FL 的脆弱性。研究强调了开发针对多样化后门攻击的强大防御措施的紧迫性，并提供了相关代码以指导未来工作。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.07917v1",
      "published_date": "2024-07-05 22:03:13 UTC",
      "updated_date": "2024-07-05 22:03:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:47:47.920718"
    },
    {
      "arxiv_id": "2407.04873v2",
      "title": "Evaluating Language Models for Generating and Judging Programming Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Charles Koutcheme",
        "Nicola Dainese",
        "Arto Hellas",
        "Sami Sarsa",
        "Juho Leinonen",
        "Syed Ashraf",
        "Paul Denny"
      ],
      "abstract": "The emergence of large language models (LLMs) has transformed research and\npractice across a wide range of domains. Within the computing education\nresearch (CER) domain, LLMs have garnered significant attention, particularly\nin the context of learning programming. Much of the work on LLMs in CER,\nhowever, has focused on applying and evaluating proprietary models. In this\narticle, we evaluate the efficiency of open-source LLMs in generating\nhigh-quality feedback for programming assignments and judging the quality of\nprogramming feedback, contrasting the results with proprietary models. Our\nevaluations on a dataset of students' submissions to introductory Python\nprogramming exercises suggest that state-of-the-art open-source LLMs are nearly\non par with proprietary models in both generating and assessing programming\nfeedback. Additionally, we demonstrate the efficiency of smaller LLMs in these\ntasks and highlight the wide range of LLMs accessible, even for free, to\neducators and practitioners.",
      "tldr_zh": "这篇论文评估了开源大型语言模型 (LLMs) 在生成编程反馈和判断反馈质量方面的效率，并与专有模型进行对比。研究使用学生提交的入门级 Python 编程练习数据集进行实验，结果显示，先进的开源 LLMs 在这些任务上几乎与专有模型相当。论文还突出了小型 LLMs 的高效性能，并强调了各种开源 LLMs 的可访问性，这为教育者和从业者提供了免费的实用工具。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "2 tables. Accepted for SIGCSE TS 2025",
      "pdf_url": "http://arxiv.org/pdf/2407.04873v2",
      "published_date": "2024-07-05 21:44:11 UTC",
      "updated_date": "2024-11-22 01:13:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:47:49.289425"
    },
    {
      "arxiv_id": "2407.04869v1",
      "title": "A Defeasible Deontic Calculus for Resolving Norm Conflicts",
      "title_zh": "翻译失败",
      "authors": [
        "Taylor Olson",
        "Roberto Salas-Damian",
        "Kenneth D. Forbus"
      ],
      "abstract": "When deciding how to act, we must consider other agents' norms and values.\nHowever, our norms are ever-evolving. We often add exceptions or change our\nminds, and thus norms can conflict over time. Therefore, to maintain an\naccurate mental model of other's norms, and thus to avoid social friction, such\nconflicts must be detected and resolved quickly. Formalizing this process has\nbeen the focus of various deontic logics and normative multi-agent systems. We\naim to bridge the gap between these two fields here. We contribute a defeasible\ndeontic calculus with inheritance and prove that it resolves norm conflicts.\nThrough this analysis, we also reveal a common resolution strategy as a red\nherring. This paper thus contributes a theoretically justified axiomatization\nof norm conflict detection and resolution.",
      "tldr_zh": "该论文探讨了多代理系统中代理决策时如何处理不断演变的规范冲突，以避免社会摩擦。作者提出了一种 defeasible deontic calculus，结合 inheritance 机制，用于检测和解决 norm conflicts，并证明了其有效性。通过分析，该方法揭示了一个常见的冲突解决策略是误导性的，从而为规范冲突的理论公理化提供了坚实基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.04869v1",
      "published_date": "2024-07-05 21:16:16 UTC",
      "updated_date": "2024-07-05 21:16:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:48:00.763700"
    },
    {
      "arxiv_id": "2407.04868v1",
      "title": "Looking into Black Box Code Language Models",
      "title_zh": "探究黑盒代码语言模型",
      "authors": [
        "Muhammad Umair Haider",
        "Umar Farooq",
        "A. B. Siddique",
        "Mark Marron"
      ],
      "abstract": "Language Models (LMs) have shown their application for tasks pertinent to\ncode and several code~LMs have been proposed recently. The majority of the\nstudies in this direction only focus on the improvements in performance of the\nLMs on different benchmarks, whereas LMs are considered black boxes. Besides\nthis, a handful of works attempt to understand the role of attention layers in\nthe code~LMs. Nonetheless, feed-forward layers remain under-explored which\nconsist of two-thirds of a typical transformer model's parameters.\n  In this work, we attempt to gain insights into the inner workings of code\nlanguage models by examining the feed-forward layers. To conduct our\ninvestigations, we use two state-of-the-art code~LMs, Codegen-Mono and\nPloycoder, and three widely used programming languages, Java, Go, and Python.\nWe focus on examining the organization of stored concepts, the editability of\nthese concepts, and the roles of different layers and input context size\nvariations for output generation. Our empirical findings demonstrate that lower\nlayers capture syntactic patterns while higher layers encode abstract concepts\nand semantics. We show concepts of interest can be edited within feed-forward\nlayers without compromising code~LM performance. Additionally, we observe\ninitial layers serve as ``thinking'' layers, while later layers are crucial for\npredicting subsequent code tokens. Furthermore, we discover earlier layers can\naccurately predict smaller contexts, but larger contexts need critical later\nlayers' contributions. We anticipate these findings will facilitate better\nunderstanding, debugging, and testing of code~LMs.",
      "tldr_zh": "这篇论文探究了代码语言模型（code LMs）的内部机制，特别是 feed-forward layers，这些层在 transformer 模型中占了大部分参数。研究者使用 Codegen-Mono 和 PolyCoder 模型，以及 Java、Go 和 Python 语言，分析了存储概念的组织、可编辑性、不同层的作用和输入上下文大小的影响。关键发现包括：较低层主要捕获语法模式，而较高层编码抽象概念和语义；概念可编辑而不损害模型性能；初始层充当“思考”层，后续层关键于预测代码标记，且较大上下文需要后期层的贡献。这些发现有助于提升代码 LMs 的理解、调试和测试。",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.04868v1",
      "published_date": "2024-07-05 21:13:41 UTC",
      "updated_date": "2024-07-05 21:13:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:48:14.804754"
    },
    {
      "arxiv_id": "2407.04859v1",
      "title": "Hybrid Primal Sketch: Combining Analogy, Qualitative Representations, and Computer Vision for Scene Understanding",
      "title_zh": "Hybrid Primal Sketch：结合类比、定性表示和计算机视觉用于场景理解",
      "authors": [
        "Kenneth D. Forbus",
        "Kezhen Chen",
        "Wangcheng Xu",
        "Madeline Usher"
      ],
      "abstract": "One of the purposes of perception is to bridge between sensors and conceptual\nunderstanding. Marr's Primal Sketch combined initial edge-finding with multiple\ndownstream processes to capture aspects of visual perception such as grouping\nand stereopsis. Given the progress made in multiple areas of AI since then, we\nhave developed a new framework inspired by Marr's work, the Hybrid Primal\nSketch, which combines computer vision components into an ensemble to produce\nsketch-like entities which are then further processed by CogSketch, our model\nof high-level human vision, to produce both more detailed shape representations\nand scene representations which can be used for data-efficient learning via\nanalogical generalization. This paper describes our theoretical framework,\nsummarizes several previous experiments, and outlines a new experiment in\nprogress on diagram understanding.",
      "tldr_zh": "该论文提出Hybrid Primal Sketch框架，受Marr's Primal Sketch启发，将计算机视觉组件整合成一个集合系统，用于生成草图-like实体，并通过CogSketch模型进一步处理以创建更详细的形状和场景表示。框架结合analogy和qualitative representations，促进数据高效学习，实现传感器与概念理解的桥梁。论文总结了之前的实验，并概述一个正在进行中的图表理解实验，展示了该方法在视觉感知领域的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "16 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.04859v1",
      "published_date": "2024-07-05 20:44:35 UTC",
      "updated_date": "2024-07-05 20:44:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:48:28.830599"
    },
    {
      "arxiv_id": "2407.04856v2",
      "title": "Explorative Imitation Learning: A Path Signature Approach for Continuous Environments",
      "title_zh": "探索性模仿学习：一种针对连续环境的路径签名方法",
      "authors": [
        "Nathan Gavenski",
        "Juarez Monteiro",
        "Felipe Meneguzzi",
        "Michael Luck",
        "Odinaldo Rodrigues"
      ],
      "abstract": "Some imitation learning methods combine behavioural cloning with\nself-supervision to infer actions from state pairs. However, most rely on a\nlarge number of expert trajectories to increase generalisation and human\nintervention to capture key aspects of the problem, such as domain constraints.\nIn this paper, we propose Continuous Imitation Learning from Observation\n(CILO), a new method augmenting imitation learning with two important features:\n(i) exploration, allowing for more diverse state transitions, requiring less\nexpert trajectories and resulting in fewer training iterations; and (ii) path\nsignatures, allowing for automatic encoding of constraints, through the\ncreation of non-parametric representations of agents and expert trajectories.\nWe compared CILO with a baseline and two leading imitation learning methods in\nfive environments. It had the best overall performance of all methods in all\nenvironments, outperforming the expert in two of them.",
      "tldr_zh": "该论文提出了一种名为 Continuous Imitation Learning from Observation (CILO) 的新方法，用于增强模仿学习在连续环境的表现。CILO 结合了探索机制，以实现更多样化的状态转换，从而减少所需专家轨迹数量和训练迭代；同时，使用 path signatures 自动编码约束，通过非参数表示来捕捉代理和专家轨迹的关键特征。在五个环境中与基线和两种领先模仿学习方法比较，CILO 整体表现最佳，并在两个环境中超过了专家水平。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper has been accepted in the 27th European Conference on\n  Artificial Intelligence (ECAI) 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.04856v2",
      "published_date": "2024-07-05 20:25:39 UTC",
      "updated_date": "2024-07-22 15:32:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:48:38.547119"
    },
    {
      "arxiv_id": "2407.04855v1",
      "title": "Towards Enhancing Coherence in Extractive Summarization: Dataset and Experiments with LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Mihir Parmar",
        "Hanieh Deilamsalehy",
        "Franck Dernoncourt",
        "Seunghyun Yoon",
        "Ryan A. Rossi",
        "Trung Bui"
      ],
      "abstract": "Extractive summarization plays a pivotal role in natural language processing\ndue to its wide-range applications in summarizing diverse content efficiently,\nwhile also being faithful to the original content. Despite significant\nadvancement achieved in extractive summarization by Large Language Models\n(LLMs), these summaries frequently exhibit incoherence. An important aspect of\nthe coherent summary is its readability for intended users. Although there have\nbeen many datasets and benchmarks proposed for creating coherent extractive\nsummaries, none of them currently incorporate user intent to improve coherence\nin extractive summarization. Motivated by this, we propose a systematically\ncreated human-annotated dataset consisting of coherent summaries for five\npublicly available datasets and natural language user feedback, offering\nvaluable insights into how to improve coherence in extractive summaries. We\nutilize this dataset for aligning LLMs through supervised fine-tuning with\nnatural language human feedback to enhance the coherence of their generated\nsummaries. Preliminary experiments with Falcon-40B and Llama-2-13B show\nsignificant performance improvements (~10% Rouge-L) in terms of producing\ncoherent summaries. We further utilize human feedback to benchmark results over\ninstruction-tuned models such as FLAN-T5 which resulted in several interesting\nfindings. Data and source code are available at\nhttps://github.com/Mihir3009/Extract-AI.",
      "tldr_zh": "本研究针对提取式 summarization 中的连贯性问题，提出一个新的人类标注数据集，该数据集包含五个公开数据集的连贯摘要以及自然语言用户反馈，以帮助提升摘要的可读性和用户意图整合。研究通过监督 fine-tuning 方法对齐 LLMs（如 Falcon-40B 和 Llama-2-13B），利用用户反馈改进模型生成摘要的连贯性。实验结果显示，模型在 Rouge-L 分数上提升约10%，并通过基准测试（如 FLAN-T5）验证了这些改进，数据集和源代码已在 GitHub 上公开。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2407.04855v1",
      "published_date": "2024-07-05 20:25:04 UTC",
      "updated_date": "2024-07-05 20:25:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:48:50.561095"
    },
    {
      "arxiv_id": "2407.04846v2",
      "title": "Amazing Things Come From Having Many Good Models",
      "title_zh": "翻译失败",
      "authors": [
        "Cynthia Rudin",
        "Chudi Zhong",
        "Lesia Semenova",
        "Margo Seltzer",
        "Ronald Parr",
        "Jiachang Liu",
        "Srikar Katta",
        "Jon Donnelly",
        "Harry Chen",
        "Zachery Boner"
      ],
      "abstract": "The Rashomon Effect, coined by Leo Breiman, describes the phenomenon that\nthere exist many equally good predictive models for the same dataset. This\nphenomenon happens for many real datasets and when it does, it sparks both\nmagic and consternation, but mostly magic. In light of the Rashomon Effect,\nthis perspective piece proposes reshaping the way we think about machine\nlearning, particularly for tabular data problems in the nondeterministic\n(noisy) setting. We address how the Rashomon Effect impacts (1) the existence\nof simple-yet-accurate models, (2) flexibility to address user preferences,\nsuch as fairness and monotonicity, without losing performance, (3) uncertainty\nin predictions, fairness, and explanations, (4) reliable variable importance,\n(5) algorithm choice, specifically, providing advanced knowledge of which\nalgorithms might be suitable for a given problem, and (6) public policy. We\nalso discuss a theory of when the Rashomon Effect occurs and why. Our goal is\nto illustrate how the Rashomon Effect can have a massive impact on the use of\nmachine learning for complex problems in society.",
      "tldr_zh": "本论文讨论了 Rashomon Effect，即同一数据集可能存在多个同样优秀的预测模型的现象，这种效应在许多真实数据集上常见，并能带来积极影响。作者提出重新审视机器学习方法，特别是针对表格数据在非确定性（嘈杂）环境中的应用，从而实现简单却准确的模型设计。论文强调 Rashomon Effect 可增强模型的灵活性，如满足用户偏好（例如公平性和单调性）而不牺牲性能，同时改善预测不确定性、变量重要性评估和算法选择，并影响公共政策。总体而言，该效应为机器学习在复杂社会问题中的应用提供了巨大潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.04846v2",
      "published_date": "2024-07-05 20:14:36 UTC",
      "updated_date": "2024-07-10 02:39:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:49:02.141819"
    },
    {
      "arxiv_id": "2407.04844v1",
      "title": "Neural varifolds: an aggregate representation for quantifying the geometry of point clouds",
      "title_zh": "翻译失败",
      "authors": [
        "Juheon Lee",
        "Xiaohao Cai",
        "Carola-Bibian Schönlieb",
        "Simon Masnou"
      ],
      "abstract": "Point clouds are popular 3D representations for real-life objects (such as in\nLiDAR and Kinect) due to their detailed and compact representation of\nsurface-based geometry. Recent approaches characterise the geometry of point\nclouds by bringing deep learning based techniques together with geometric\nfidelity metrics such as optimal transportation costs (e.g., Chamfer and\nWasserstein metrics). In this paper, we propose a new surface geometry\ncharacterisation within this realm, namely a neural varifold representation of\npoint clouds. Here the surface is represented as a measure/distribution over\nboth point positions and tangent spaces of point clouds. The varifold\nrepresentation quantifies not only the surface geometry of point clouds through\nthe manifold-based discrimination, but also subtle geometric consistencies on\nthe surface due to the combined product space. This study proposes neural\nvarifold algorithms to compute the varifold norm between two point clouds using\nneural networks on point clouds and their neural tangent kernel\nrepresentations. The proposed neural varifold is evaluated on three different\nsought-after tasks -- shape matching, few-shot shape classification and shape\nreconstruction. Detailed evaluation and comparison to the state-of-the-art\nmethods demonstrate that the proposed versatile neural varifold is superior in\nshape matching and few-shot shape classification, and is competitive for shape\nreconstruction.",
      "tldr_zh": "这篇论文提出了一种新的点云几何量化方法，即 neural varifolds 表示，将点云表示为点位置和切向空间的分布，从而不仅捕捉表面几何，还能识别微妙的几何一致性。作者开发了基于神经网络和神经切向核的算法，用于计算两个点云之间的 varifold 范数。实验结果显示，该方法在形状匹配和少样本形状分类任务上优于现有技术，在形状重建任务上也具有竞争力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "The first author, Juheon Lee, is an unaffiliated, independent\n  researcher. This work is a personal endeavor, unrelated to his current job",
      "pdf_url": "http://arxiv.org/pdf/2407.04844v1",
      "published_date": "2024-07-05 20:08:16 UTC",
      "updated_date": "2024-07-05 20:08:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:49:15.063921"
    },
    {
      "arxiv_id": "2407.04841v2",
      "title": "Associative Recurrent Memory Transformer",
      "title_zh": "翻译失败",
      "authors": [
        "Ivan Rodkin",
        "Yuri Kuratov",
        "Aydar Bulatov",
        "Mikhail Burtsev"
      ],
      "abstract": "This paper addresses the challenge of creating a neural architecture for very\nlong sequences that requires constant time for processing new information at\neach time step. Our approach, Associative Recurrent Memory Transformer (ARMT),\nis based on transformer self-attention for local context and segment-level\nrecurrence for storage of task specific information distributed over a long\ncontext. We demonstrate that ARMT outperfors existing alternatives in\nassociative retrieval tasks and sets a new performance record in the recent\nBABILong multi-task long-context benchmark by answering single-fact questions\nover 50 million tokens with an accuracy of 79.9%. The source code for training\nand evaluation is available on github.",
      "tldr_zh": "本文提出 Associative Recurrent Memory Transformer (ARMT)，一种处理长序列的神经架构，能够在每个时间步以常量时间处理新信息。ARMT 结合 transformer self-attention 用于本地上下文，以及 segment-level recurrence 来存储任务特定信息分布在长上下文中。实验结果显示，ARMT 在关联检索任务中超越现有方法，并在 BABILong 多任务长上下文基准上，处理5000万标记的单事实问题时达到79.9%的准确率。源代码已在 GitHub 上公开，以供进一步研究和应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "ICML 2024 Next Generation of Sequence Modeling Architectures Workshop",
      "pdf_url": "http://arxiv.org/pdf/2407.04841v2",
      "published_date": "2024-07-05 19:57:49 UTC",
      "updated_date": "2025-02-13 20:10:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:49:26.656715"
    },
    {
      "arxiv_id": "2407.04833v4",
      "title": "3D Adaptive Structural Convolution Network for Domain-Invariant Point Cloud Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Younggun Kim",
        "Beomsik Cho",
        "Seonghoon Ryoo",
        "Soomok Lee"
      ],
      "abstract": "Adapting deep learning networks for point cloud data recognition in\nself-driving vehicles faces challenges due to the variability in datasets and\nsensor technologies, emphasizing the need for adaptive techniques to maintain\naccuracy across different conditions. In this paper, we introduce the 3D\nAdaptive Structural Convolution Network (3D-ASCN), a cutting-edge framework for\n3D point cloud recognition. It combines 3D convolution kernels, a structural\ntree structure, and adaptive neighborhood sampling for effective geometric\nfeature extraction. This method obtains domain-invariant features and\ndemonstrates robust, adaptable performance on a variety of point cloud\ndatasets, ensuring compatibility across diverse sensor configurations without\nthe need for parameter adjustments. This highlights its potential to\nsignificantly enhance the reliability and efficiency of self-driving vehicle\ntechnology.",
      "tldr_zh": "本文提出3D Adaptive Structural Convolution Network (3D-ASCN)，一种针对自驾车点云数据识别的创新框架，用于应对数据集和传感器变异性带来的挑战。该框架整合3D convolution kernels、structural tree structure和adaptive neighborhood sampling，实现高效的几何特征提取和domain-invariant features的生成。实验结果显示，3D-ASCN在多种point cloud datasets上表现出强鲁棒性和适应性，无需参数调整，从而显著提升自驾车技术的可靠性和效率。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.2.10; I.5.1"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.04833v4",
      "published_date": "2024-07-05 19:38:10 UTC",
      "updated_date": "2024-10-22 03:41:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:49:38.306052"
    },
    {
      "arxiv_id": "2407.04831v2",
      "title": "Code Hallucination",
      "title_zh": "代码幻觉",
      "authors": [
        "Mirza Masfiqur Rahman",
        "Ashish Kundu"
      ],
      "abstract": "Generative models such as large language models are extensively used as code\ncopilots and for whole program generation. However, the programs they generate\noften have questionable correctness, authenticity and reliability in terms of\nintegration as they might not follow the user requirements, provide incorrect\nand/or nonsensical outputs, or even contain semantic/syntactic errors - overall\nknown as LLM hallucination. In this work, we present several types of code\nhallucination. We have generated such hallucinated code manually using large\nlanguage models. We also present a technique - HallTrigger, in order to\ndemonstrate efficient ways of generating arbitrary code hallucination. Our\nmethod leverages 3 different dynamic attributes of LLMs to craft prompts that\ncan successfully trigger hallucinations from models without the need to access\nmodel architecture or parameters. Results from popular blackbox models suggest\nthat HallTrigger is indeed effective and the pervasive LLM hallucination have\nsheer impact on software development.",
      "tldr_zh": "这篇论文探讨了大语言模型(LLMs)在代码生成中的幻觉问题(LLM hallucination)，包括代码不遵循用户要求、输出错误或语法错误，从而影响软件的正确性和可靠性。作者手动生成了多种代码 hallucination 类型，并提出了一种名为 HallTrigger 的技术，该方法利用 LLMs 的三个动态属性（如不确定性和上下文依赖）来设计提示，从而在不访问模型内部的情况下高效触发这些幻觉。实验结果显示，HallTrigger 在热门黑箱模型上表现出色，强调了 LLM hallucination 对软件开发过程的重大负面影响。",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.04831v2",
      "published_date": "2024-07-05 19:37:37 UTC",
      "updated_date": "2024-08-08 01:01:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:49:50.727785"
    },
    {
      "arxiv_id": "2407.04819v1",
      "title": "RPN: Reconciled Polynomial Network Towards Unifying PGMs, Kernel SVMs, MLP and KAN",
      "title_zh": "翻译失败",
      "authors": [
        "Jiawei Zhang"
      ],
      "abstract": "In this paper, we will introduce a novel deep model named Reconciled\nPolynomial Network (RPN) for deep function learning. RPN has a very general\narchitecture and can be used to build models with various complexities,\ncapacities, and levels of completeness, which all contribute to the correctness\nof these models. As indicated in the subtitle, RPN can also serve as the\nbackbone to unify different base models into one canonical representation. This\nincludes non-deep models, like probabilistic graphical models (PGMs) - such as\nBayesian network and Markov network - and kernel support vector machines\n(kernel SVMs), as well as deep models like the classic multi-layer perceptron\n(MLP) and the recent Kolmogorov-Arnold network (KAN).\n  Technically, RPN proposes to disentangle the underlying function to be\ninferred into the inner product of a data expansion function and a parameter\nreconciliation function. Together with the remainder function, RPN accurately\napproximates the underlying functions that governs data distributions. The data\nexpansion functions in RPN project data vectors from the input space to a\nhigh-dimensional intermediate space, specified by the expansion functions in\ndefinition. Meanwhile, RPN also introduces the parameter reconciliation\nfunctions to fabricate a small number of parameters into a higher-order\nparameter matrix to address the ``curse of dimensionality'' problem caused by\nthe data expansions. Moreover, the remainder functions provide RPN with\nadditional complementary information to reduce potential approximation errors.\nWe conducted extensive empirical experiments on numerous benchmark datasets\nacross multiple modalities, including continuous function datasets, discrete\nvision and language datasets, and classic tabular datasets, to investigate the\neffectiveness of RPN.",
      "tldr_zh": "这篇论文提出了 Reconciled Polynomial Network (RPN)，一种新型深度模型，用于统一 PGMs (Probabilistic Graphical Models)、Kernel SVMs、MLP (Multi-Layer Perceptron) 和 KAN (Kolmogorov-Arnold Network)，以实现更通用和准确的函数学习。RPN 通过将底层函数分解为数据扩展函数和参数协调函数的内积，加上余项函数，来处理维度诅咒问题并减少逼近错误，从而提升模型的复杂性和完整性。在多个基准数据集上的实验，包括连续函数、离散视觉语言和经典表格数据集，证明了 RPN 的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.IT",
        "math.IT",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "110 pages, 31 figures, 33 tables",
      "pdf_url": "http://arxiv.org/pdf/2407.04819v1",
      "published_date": "2024-07-05 19:00:18 UTC",
      "updated_date": "2024-07-05 19:00:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:50:04.520765"
    },
    {
      "arxiv_id": "2407.04808v1",
      "title": "Brain Age Estimation with a Greedy Dual-Stream Model for Limited Datasets",
      "title_zh": "翻译失败",
      "authors": [
        "Iman Kianian",
        "Hedieh Sajedi"
      ],
      "abstract": "Brain age estimation involves predicting the biological age of individuals\nfrom their brain images, which offers valuable insights into the aging process\nand the progression of neurodegenerative diseases. Conducting large-scale\ndatasets for medical image analysis is a challenging and time-consuming task.\nExisting approaches mostly depend on large datasets, which are hard to come by\nand expensive. These approaches also require sophisticated, resource-intensive\nmodels with a large number of parameters, necessitating a considerable amount\nof processing power. As a result, there is a vital need to develop innovative\nmethods that can achieve robust performance with limited datasets and efficient\nuse of computational resources. This paper proposes a novel slice-based\ndual-stream method called GDSM (Greedy Dual-Stream Model) for brain age\nestimation. This method addresses the limitations of large dataset requirements\nand computational resource intensiveness. The proposed method incorporates\nlocal and global aspects of the brain, thereby refining the focus on specific\ntarget regions. The approach employs four backbones to predict ages based on\nlocal and global features, complemented by a final model for age correction.\nOur method demonstrates a Mean Absolute Error (MAE) of 3.25 years on the test\nset of IBID, which only contains 289 subjects. To demonstrate the robustness of\nour approach for any small dataset, we analyzed the proposed method with the\nIXI dataset and achieved an MAE of 4.18 years on the test set of IXI. By\nleveraging dual-stream and greedy strategies, this approach achieves efficiency\nand robust performance, making it comparable with other state-of-the-art\nmethods. The code for the GDSM model is available at\nhttps://github.com/iman2693/GDSM.",
      "tldr_zh": "本论文针对脑年龄估计（Brain Age Estimation）问题，提出了一种名为 GDSM（Greedy Dual-Stream Model）的切片-based 双流方法，旨在在有限数据集上实现高效预测。该方法结合脑部局部和全局特征，通过四个骨干网络提取特征并进行年龄预测，随后使用最终模型修正结果，从而减少了对大型数据集和计算资源的依赖。在实验中，GDSM 在 IBID 数据集（仅 289 个受试者）上取得 3.25 年的 Mean Absolute Error (MAE)，并在 IXI 数据集上达到 4.18 年的 MAE，性能与最先进方法相当。该创新方法证明了其鲁棒性和实用性，为资源受限场景下的神经退行性疾病研究提供了新途径。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.04808v1",
      "published_date": "2024-07-05 18:44:57 UTC",
      "updated_date": "2024-07-05 18:44:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:50:16.528970"
    },
    {
      "arxiv_id": "2407.04803v1",
      "title": "The Impact of Quantization and Pruning on Deep Reinforcement Learning Models",
      "title_zh": "翻译失败",
      "authors": [
        "Heng Lu",
        "Mehdi Alemi",
        "Reza Rawassizadeh"
      ],
      "abstract": "Deep reinforcement learning (DRL) has achieved remarkable success across\nvarious domains, such as video games, robotics, and, recently, large language\nmodels. However, the computational costs and memory requirements of DRL models\noften limit their deployment in resource-constrained environments. The\nchallenge underscores the urgent need to explore neural network compression\nmethods to make RDL models more practical and broadly applicable. Our study\ninvestigates the impact of two prominent compression methods, quantization and\npruning on DRL models. We examine how these techniques influence four\nperformance factors: average return, memory, inference time, and battery\nutilization across various DRL algorithms and environments. Despite the\ndecrease in model size, we identify that these compression techniques generally\ndo not improve the energy efficiency of DRL models, but the model size\ndecreases. We provide insights into the trade-offs between model compression\nand DRL performance, offering guidelines for deploying efficient DRL models in\nresource-constrained settings.",
      "tldr_zh": "这篇论文探讨了quantization和pruning等神经网络压缩方法对Deep Reinforcement Learning (DRL) 模型的影响，旨在解决DRL在资源受限环境中的部署挑战。研究通过评估average return、memory、inference time和battery utilization等性能指标，测试了这些技术在多种DRL算法和环境中的表现，结果显示模型大小显著减少，但能量效率并未整体改善。论文提供了模型压缩与DRL性能之间权衡的见解，并为在资源受限设置中部署高效DRL模型提出了实用指导。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.04803v1",
      "published_date": "2024-07-05 18:21:17 UTC",
      "updated_date": "2024-07-05 18:21:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:50:26.345392"
    },
    {
      "arxiv_id": "2407.04801v1",
      "title": "Revisiting Structured Sentiment Analysis as Latent Dependency Graph Parsing",
      "title_zh": "翻译失败",
      "authors": [
        "Chengjie Zhou",
        "Bobo Li",
        "Hao Fei",
        "Fei Li",
        "Chong Teng",
        "Donghong Ji"
      ],
      "abstract": "Structured Sentiment Analysis (SSA) was cast as a problem of bi-lexical\ndependency graph parsing by prior studies. Multiple formulations have been\nproposed to construct the graph, which share several intrinsic drawbacks: (1)\nThe internal structures of spans are neglected, thus only the boundary tokens\nof spans are used for relation prediction and span recognition, thus hindering\nthe model's expressiveness; (2) Long spans occupy a significant proportion in\nthe SSA datasets, which further exacerbates the problem of internal structure\nneglect. In this paper, we treat the SSA task as a dependency parsing task on\npartially-observed dependency trees, regarding flat spans without determined\ntree annotations as latent subtrees to consider internal structures of spans.\nWe propose a two-stage parsing method and leverage TreeCRFs with a novel\nconstrained inside algorithm to model latent structures explicitly, which also\ntakes advantages of joint scoring graph arcs and headed spans for global\noptimization and inference. Results of extensive experiments on five benchmark\ndatasets reveal that our method performs significantly better than all previous\nbi-lexical methods, achieving new state-of-the-art.",
      "tldr_zh": "本文重新审视 Structured Sentiment Analysis (SSA)，将其视为部分观察的依赖树解析任务，通过将平坦跨度视为潜在子树来解决以往方法忽略跨度内部结构的缺点。作者提出了一种两阶段解析方法，并利用 TreeCRFs 结合新型约束内部算法进行显式建模和联合评分，以实现全局优化和推理。该方法在五个基准数据集上的实验中显著优于现有双词汇方法，达到了新的 state-of-the-art 性能水平。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.04801v1",
      "published_date": "2024-07-05 18:18:50 UTC",
      "updated_date": "2024-07-05 18:18:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:50:38.369964"
    },
    {
      "arxiv_id": "2407.04794v2",
      "title": "On Evaluating The Performance of Watermarked Machine-Generated Texts Under Adversarial Attacks",
      "title_zh": "关于评估水印机器生成文本在对抗性攻击下的性能",
      "authors": [
        "Zesen Liu",
        "Tianshuo Cong",
        "Xinlei He",
        "Qi Li"
      ],
      "abstract": "Large Language Models (LLMs) excel in various applications, including text\ngeneration and complex tasks. However, the misuse of LLMs raises concerns about\nthe authenticity and ethical implications of the content they produce, such as\ndeepfake news, academic fraud, and copyright infringement. Watermarking\ntechniques, which embed identifiable markers in machine-generated text, offer a\npromising solution to these issues by allowing for content verification and\norigin tracing. Unfortunately, the robustness of current LLM watermarking\nschemes under potential watermark removal attacks has not been comprehensively\nexplored.\n  In this paper, to fill this gap, we first systematically comb the mainstream\nwatermarking schemes and removal attacks on machine-generated texts, and then\nwe categorize them into pre-text (before text generation) and post-text (after\ntext generation) classes so that we can conduct diversified analyses. In our\nexperiments, we evaluate eight watermarks (five pre-text, three post-text) and\ntwelve attacks (two pre-text, ten post-text) across 87 scenarios. Evaluation\nresults indicate that (1) KGW and Exponential watermarks offer high text\nquality and watermark retention but remain vulnerable to most attacks; (2)\nPost-text attacks are found to be more efficient and practical than pre-text\nattacks; (3) Pre-text watermarks are generally more imperceptible, as they do\nnot alter text fluency, unlike post-text watermarks; (4) Additionally, combined\nattack methods can significantly increase effectiveness, highlighting the need\nfor more robust watermarking solutions. Our study underscores the\nvulnerabilities of current techniques and the necessity for developing more\nresilient schemes.",
      "tldr_zh": "这篇论文评估了水印技术（watermarking）在机器生成文本（machine-generated texts）上的性能，特别是面对对抗攻击（adversarial attacks）。作者系统梳理了主流水印方案和移除攻击，并将它们分类为 pre-text（生成前）和 post-text（生成后）类型，然后在87个场景中实验评估了8种水印（5个 pre-text，3个 post-text）和12种攻击（2个 pre-text，10个 post-text）。结果显示，KGW 和 Exponential 水印虽提供高文本质量和水印保留，但易受大多数攻击影响；post-text 攻击更高效实用，而 pre-text 水印更不易察觉；此外，组合攻击方法显著提升了有效性，强调了开发更鲁棒水印方案的必要性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.04794v2",
      "published_date": "2024-07-05 18:09:06 UTC",
      "updated_date": "2024-11-28 11:28:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:50:51.700714"
    },
    {
      "arxiv_id": "2407.04787v1",
      "title": "Re-Tuning: Overcoming the Compositionality Limits of Large Language Models with Recursive Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Eric Pasewark",
        "Kyle Montgomery",
        "Kefei Duan",
        "Dawn Song",
        "Chenguang Wang"
      ],
      "abstract": "We present a new method for large language models to solve compositional\ntasks. Although they have shown strong performance on traditional language\nunderstanding tasks, large language models struggle to solve compositional\ntasks, where the solution depends on solving smaller instances of the same\nproblem. We propose a natural approach to solve compositional tasks\nrecursively. Our method, Re-Tuning, tunes models to break down a problem into\nsubproblems, solve those subproblems, and combine the results. We show that our\nmethod significantly improves model performance on three representative\ncompositional tasks: integer addition, dynamic programming, and parity.\nCompared to state-of-the-art methods that keep intermediate steps towards\nsolving the problems, Re-Tuning achieves significantly higher accuracy and is\nmore GPU memory efficient.",
      "tldr_zh": "论文提出 Re-Tuning 方法，以克服大型语言模型（Large Language Models）在组合性任务（compositional tasks）上的局限性，这些任务需要递归解决子问题。Re-Tuning 通过微调模型，使其能够将问题分解、解决子问题并组合结果，从而实现更有效的处理。实验结果显示，该方法在整数加法、动态规划和奇偶性任务上显著提升了准确率，并比现有 state-of-the-art 方法更节省 GPU 内存。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.04787v1",
      "published_date": "2024-07-05 18:02:28 UTC",
      "updated_date": "2024-07-05 18:02:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:51:02.581074"
    },
    {
      "arxiv_id": "2407.04699v2",
      "title": "LaRa: Efficient Large-Baseline Radiance Fields",
      "title_zh": "LaRa：高效大基线辐射场",
      "authors": [
        "Anpei Chen",
        "Haofei Xu",
        "Stefano Esposito",
        "Siyu Tang",
        "Andreas Geiger"
      ],
      "abstract": "Radiance field methods have achieved photorealistic novel view synthesis and\ngeometry reconstruction. But they are mostly applied in per-scene optimization\nor small-baseline settings. While several recent works investigate feed-forward\nreconstruction with large baselines by utilizing transformers, they all operate\nwith a standard global attention mechanism and hence ignore the local nature of\n3D reconstruction. We propose a method that unifies local and global reasoning\nin transformer layers, resulting in improved quality and faster convergence.\nOur model represents scenes as Gaussian Volumes and combines this with an image\nencoder and Group Attention Layers for efficient feed-forward reconstruction.\nExperimental results demonstrate that our model, trained for two days on four\nGPUs, demonstrates high fidelity in reconstructing 360 deg radiance fields, and\nrobustness to zero-shot and out-of-domain testing. Our project Page:\nhttps://apchenstu.github.io/LaRa/.",
      "tldr_zh": "本论文提出 LaRa，一种高效的大型基线 Radiance Fields 方法，旨在解决现有模型在场景优化和小基线设置下的局限性，通过统一局部和全局推理来提升重建质量和收敛速度。LaRa 使用 Gaussian Volumes 结合图像编码器和 Group Attention Layers，实现高效的前向重建，适用于 360 度辐射场场景。实验结果显示，该模型在两天内于四块 GPU 上训练后，实现了高保真度的重建，并对零样本和域外测试表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project Page: https://apchenstu.github.io/LaRa/",
      "pdf_url": "http://arxiv.org/pdf/2407.04699v2",
      "published_date": "2024-07-05 17:59:58 UTC",
      "updated_date": "2024-07-15 20:18:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:51:14.529537"
    },
    {
      "arxiv_id": "2407.04694v1",
      "title": "Me, Myself, and AI: The Situational Awareness Dataset (SAD) for LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Rudolf Laine",
        "Bilal Chughtai",
        "Jan Betley",
        "Kaivalya Hariharan",
        "Jeremy Scheurer",
        "Mikita Balesni",
        "Marius Hobbhahn",
        "Alexander Meinke",
        "Owain Evans"
      ],
      "abstract": "AI assistants such as ChatGPT are trained to respond to users by saying, \"I\nam a large language model\". This raises questions. Do such models know that\nthey are LLMs and reliably act on this knowledge? Are they aware of their\ncurrent circumstances, such as being deployed to the public? We refer to a\nmodel's knowledge of itself and its circumstances as situational awareness. To\nquantify situational awareness in LLMs, we introduce a range of behavioral\ntests, based on question answering and instruction following. These tests form\nthe $\\textbf{Situational Awareness Dataset (SAD)}$, a benchmark comprising 7\ntask categories and over 13,000 questions. The benchmark tests numerous\nabilities, including the capacity of LLMs to (i) recognize their own generated\ntext, (ii) predict their own behavior, (iii) determine whether a prompt is from\ninternal evaluation or real-world deployment, and (iv) follow instructions that\ndepend on self-knowledge.\n  We evaluate 16 LLMs on SAD, including both base (pretrained) and chat models.\nWhile all models perform better than chance, even the highest-scoring model\n(Claude 3 Opus) is far from a human baseline on certain tasks. We also observe\nthat performance on SAD is only partially predicted by metrics of general\nknowledge (e.g. MMLU). Chat models, which are finetuned to serve as AI\nassistants, outperform their corresponding base models on SAD but not on\ngeneral knowledge tasks. The purpose of SAD is to facilitate scientific\nunderstanding of situational awareness in LLMs by breaking it down into\nquantitative abilities. Situational awareness is important because it enhances\na model's capacity for autonomous planning and action. While this has potential\nbenefits for automation, it also introduces novel risks related to AI safety\nand control. Code and latest results available at\nhttps://situational-awareness-dataset.org .",
      "tldr_zh": "本文提出Situational Awareness Dataset (SAD)，一个针对大型语言模型(LLMs)的基准数据集，用于量化模型对自己（例如是LLM身份）和当前环境的认知能力。SAD包括7个任务类别和超过13,000个问题，通过问答和指令遵循测试评估LLMs的多种能力，如识别自身生成文本、预测行为、判断提示来源以及遵循依赖自我知识的指令。研究评估了16个LLMs（包括基础和聊天模型），结果显示所有模型优于随机水平，但最高分模型（Claude 3 Opus）在某些任务上远低于人类基线，且SAD性能与一般知识指标（如MMLU）相关性不强。聊天模型在SAD上表现优于基础模型，这有助于提升AI的自主规划和行动能力，但也引发了AI安全与控制的新风险。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "11 page main body, 98 page appendix, 58 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.04694v1",
      "published_date": "2024-07-05 17:57:02 UTC",
      "updated_date": "2024-07-05 17:57:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:51:30.350656"
    },
    {
      "arxiv_id": "2407.04693v2",
      "title": "ANAH-v2: Scaling Analytical Hallucination Annotation of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yuzhe Gu",
        "Ziwei Ji",
        "Wenwei Zhang",
        "Chengqi Lyu",
        "Dahua Lin",
        "Kai Chen"
      ],
      "abstract": "Large language models (LLMs) exhibit hallucinations in long-form\nquestion-answering tasks across various domains and wide applications. Current\nhallucination detection and mitigation datasets are limited in domains and\nsizes, which struggle to scale due to prohibitive labor costs and insufficient\nreliability of existing hallucination annotators. To facilitate the scalable\noversight of LLM hallucinations, this paper introduces an iterative\nself-training framework that simultaneously and progressively scales up the\nhallucination annotation dataset and improves the accuracy of the hallucination\nannotator. Based on the Expectation Maximization (EM) algorithm, in each\niteration, the framework first applies a hallucination annotation pipeline to\nannotate a scaled dataset and then trains a more accurate hallucination\nannotator on the dataset. This new hallucination annotator is adopted in the\nhallucination annotation pipeline used for the next iteration. Extensive\nexperimental results demonstrate that the finally obtained hallucination\nannotator with only 7B parameters surpasses the performance of GPT-4 and\nobtains new state-of-the-art hallucination detection results on HaluEval and\nHalluQA by zero-shot inference. Such an annotator can not only evaluate the\nhallucination levels of various LLMs on the large-scale dataset but also help\nto mitigate the hallucination of LLMs generations, with the Natural Language\nInference (NLI) metric increasing from 25% to 37% on HaluEval.",
      "tldr_zh": "该研究提出 ANAH-v2 框架，通过迭代自训练方法扩展大型语言模型 (LLMs) 幻觉标注数据集，并提升标注器的准确性，以解决现有数据集在领域和规模上的局限性。框架基于 Expectation Maximization (EM) 算法，在每个迭代中先使用标注管道标注扩展数据集，然后在数据集上训练更精确的标注器。实验结果显示，最终的 7B 参数标注器在零样本推理下超越 GPT-4，并在 HaluEval 和 HalluQA 上取得新的最先进幻觉检测性能；此外，该标注器还能评估各种 LLMs 的幻觉水平，并显著缓解幻觉问题，使 Natural Language Inference (NLI) 指标从 25% 提高到 37%。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by NeurIPS 2024. Dataset, code, and model are released at\n  https://github.com/open-compass/ANAH",
      "pdf_url": "http://arxiv.org/pdf/2407.04693v2",
      "published_date": "2024-07-05 17:56:38 UTC",
      "updated_date": "2024-12-19 15:11:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:51:39.551929"
    },
    {
      "arxiv_id": "2407.04681v1",
      "title": "Rethinking Visual Prompting for Multimodal Large Language Models with External Knowledge",
      "title_zh": "翻译失败",
      "authors": [
        "Yuanze Lin",
        "Yunsheng Li",
        "Dongdong Chen",
        "Weijian Xu",
        "Ronald Clark",
        "Philip Torr",
        "Lu Yuan"
      ],
      "abstract": "In recent years, multimodal large language models (MLLMs) have made\nsignificant strides by training on vast high-quality image-text datasets,\nenabling them to generally understand images well. However, the inherent\ndifficulty in explicitly conveying fine-grained or spatially dense information\nin text, such as masks, poses a challenge for MLLMs, limiting their ability to\nanswer questions requiring an understanding of detailed or localized visual\nelements. Drawing inspiration from the Retrieval-Augmented Generation (RAG)\nconcept, this paper proposes a new visual prompt approach to integrate\nfine-grained external knowledge, gleaned from specialized vision models (e.g.,\ninstance segmentation/OCR models), into MLLMs. This is a promising yet\nunderexplored direction for enhancing MLLMs' performance. Our approach diverges\nfrom concurrent works, which transform external knowledge into additional text\nprompts, necessitating the model to indirectly learn the correspondence between\nvisual content and text coordinates. Instead, we propose embedding fine-grained\nknowledge information directly into a spatial embedding map as a visual prompt.\nThis design can be effortlessly incorporated into various MLLMs, such as LLaVA\nand Mipha, considerably improving their visual understanding performance.\nThrough rigorous experiments, we demonstrate that our method can enhance MLLM\nperformance across nine benchmarks, amplifying their fine-grained context-aware\ncapabilities.",
      "tldr_zh": "本论文重新审视了视觉提示在多模态大语言模型(MLLMs)中的应用，针对MLLMs在处理细粒度或空间密集视觉信息（如掩码）时的局限性，提出了一种创新方法。受Retrieval-Augmented Generation (RAG)启发，该方法将来自专业视觉模型（如实例分割/OCR模型）的外部知识直接嵌入到空间嵌入映射中，作为视觉提示，而不是转化为文本提示，从而避免模型间接学习视觉与文本对应关系。该设计可轻松整合到各种MLLMs（如LLaVA和Mipha）中，通过在九个基准上的实验验证，显著提升了MLLMs的细粒度上下文感知能力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.04681v1",
      "published_date": "2024-07-05 17:43:30 UTC",
      "updated_date": "2024-07-05 17:43:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:51:51.644806"
    },
    {
      "arxiv_id": "2407.04680v1",
      "title": "Lost in Translation: The Algorithmic Gap Between LMs and the Brain",
      "title_zh": "翻译失败",
      "authors": [
        "Tommaso Tosato",
        "Pascal Jr Tikeng Notsawo",
        "Saskia Helbling",
        "Irina Rish",
        "Guillaume Dumas"
      ],
      "abstract": "Language Models (LMs) have achieved impressive performance on various\nlinguistic tasks, but their relationship to human language processing in the\nbrain remains unclear. This paper examines the gaps and overlaps between LMs\nand the brain at different levels of analysis, emphasizing the importance of\nlooking beyond input-output behavior to examine and compare the internal\nprocesses of these systems. We discuss how insights from neuroscience, such as\nsparsity, modularity, internal states, and interactive learning, can inform the\ndevelopment of more biologically plausible language models. Furthermore, we\nexplore the role of scaling laws in bridging the gap between LMs and human\ncognition, highlighting the need for efficiency constraints analogous to those\nin biological systems. By developing LMs that more closely mimic brain\nfunction, we aim to advance both artificial intelligence and our understanding\nof human cognition.",
      "tldr_zh": "该论文探讨了语言模型（LMs）在语言任务上的出色表现与大脑处理机制之间的算法差距，强调需要超越输入-输出行为来比较二者的内部过程。作者讨论了神经科学见解，如稀疏性(sparsity)、模块性(modularity)、内部状态和交互学习(interactive learning)，以指导开发更符合生物学原理的LMs。论文还分析了scaling laws在桥接LMs与人类认知方面的作用，并提出引入类似于生物系统的效率约束，以推进人工智能发展和对人类认知的理解。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.04680v1",
      "published_date": "2024-07-05 17:43:16 UTC",
      "updated_date": "2024-07-05 17:43:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:52:02.661737"
    },
    {
      "arxiv_id": "2407.04678v1",
      "title": "XQSV: A Structurally Variable Network to Imitate Human Play in Xiangqi",
      "title_zh": "翻译失败",
      "authors": [
        "Chenliang Zhou"
      ],
      "abstract": "In this paper, we introduce an innovative deep learning architecture, termed\nXiangqi Structurally Variable (XQSV), designed to emulate the behavioral\npatterns of human players in Xiangqi, or Chinese Chess. The unique attribute of\nXQSV is its capacity to alter its structural configuration dynamically,\noptimizing performance for the task based on the particular subset of data on\nwhich it is trained. We have incorporated several design improvements to\nsignificantly enhance the network's predictive accuracy, including a local\nillegal move filter, an Elo range partitioning, a sequential one-dimensional\ninput, and a simulation of imperfect memory capacity. Empirical evaluations\nreveal that XQSV attains a predictive accuracy of approximately 40%, with its\nperformance peaking within the trained Elo range. This indicates the model's\nsuccess in mimicking the play behavior of individuals within that specific\nrange. A three-terminal Turing Test was employed to demonstrate that the XQSV\nmodel imitates human behavior more accurately than conventional Xiangqi\nengines, rendering it indistinguishable from actual human opponents. Given the\ninherent nondeterminism in human gameplay, we propose two supplementary relaxed\nevaluation metrics. To our knowledge, XQSV represents the first model to mimic\nXiangqi players.",
      "tldr_zh": "本文提出了一种创新深度学习架构 XQSV，用于模仿人类在 Xiangqi 中的行为模式。XQSV 的独特设计允许动态调整结构优化性能，并引入改进如本地非法走子过滤器、Elo 范围分区、顺序一维输入和模拟不完美记忆容量。实验结果显示，该模型的预测准确率约 40%，并在训练的 Elo 范围内表现最佳；此外，通过三终端 Turing Test，XQSV 被证明比传统 Xiangqi 引擎更接近人类行为，是首个专门模仿 Xiangqi 玩家的模型。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.04678v1",
      "published_date": "2024-07-05 17:43:05 UTC",
      "updated_date": "2024-07-05 17:43:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:52:15.131776"
    },
    {
      "arxiv_id": "2407.04676v1",
      "title": "Is plantar thermography a valid digital biomarker for characterising diabetic foot ulceration risk?",
      "title_zh": "翻译失败",
      "authors": [
        "Akshay Jagadeesh",
        "Chanchanok Aramrat",
        "Aqsha Nur",
        "Poppy Mallinson",
        "Sanjay Kinra"
      ],
      "abstract": "Background: In the absence of prospective data on diabetic foot ulcers (DFU),\ncross-sectional associations with causal risk factors (peripheral neuropathy,\nand peripheral arterial disease (PAD)) could be used to establish the validity\nof plantar thermography for DFU risk stratification.\n  Methods: First, we investigated the associations between the intrinsic\nclusters of plantar thermographic images with several DFU risk factors using an\nunsupervised deep-learning framework. We then studied associations between\nobtained thermography clusters and DFU risk factors. Second, to identify those\nassociations with predictive power, we used supervised learning to train\nConvolutional Neural Network (CNN) regression/classification models that\npredicted the risk factor based on the thermograph (and visual) input.\n  Findings: Our dataset comprised 282 thermographs from type 2 diabetes\nmellitus patients (aged 56.31 +- 9.18 years, 51.42 % males). On clustering, we\nfound two overlapping clusters (silhouette score = 0.10, indicating weak\nseparation). There was strong evidence for associations between assigned\nclusters and several factors related to diabetic foot ulceration such as\nperipheral neuropathy, PAD, number of diabetes complications, and composite DFU\nrisk prediction scores such as Martins-Mendes, PODUS-2020, and SIGN. However,\nmodels predicting said risk factors had poor performances.\n  Interpretation: The strong associations between intrinsic thermography\nclusters and several DFU risk factors support the validity of using\nthermography for characterising DFU risk. However, obtained associations did\nnot prove to be predictive, likely due to, spectrum bias, or because\nthermography and classical risk factors characterise incompletely overlapping\nportions of the DFU risk construct. Our findings highlight the challenges in\nstandardising ground truths when defining novel digital biomarkers.",
      "tldr_zh": "本文探讨足底热成像是否可作为表征糖尿病足溃疡（DFU）风险的数字生物标记，通过分析其与风险因素如peripheral neuropathy和peripheral arterial disease (PAD)的关联。研究使用无监督深度学习框架对282个2型糖尿病患者的热成像数据进行聚类，发现两个重叠聚类与DFU相关因素（如PAD、糖尿病并发症数量和风险评分）有强关联。接着，通过监督学习训练CNN模型尝试预测这些风险因素，但模型性能较差，可能由于谱偏差或热成像与传统风险因素覆盖的DFU风险部分不完全重叠。这些发现支持热成像在DFU风险分层中的潜在效用，但强调了定义新数字生物标记时标准化挑战。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.2; I.5"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages, 2 Figures, 1 Table. Supplementary files and link to code to\n  be uploaded",
      "pdf_url": "http://arxiv.org/pdf/2407.04676v1",
      "published_date": "2024-07-05 17:39:03 UTC",
      "updated_date": "2024-07-05 17:39:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:52:28.575726"
    },
    {
      "arxiv_id": "2407.04648v1",
      "title": "Efficient Materials Informatics between Rockets and Electrons",
      "title_zh": "翻译失败",
      "authors": [
        "Adam M. Krajewski"
      ],
      "abstract": "The true power of computational research typically can lay in either what it\naccomplishes or what it enables others to accomplish. In this work, both\navenues are simultaneously embraced across several distinct efforts existing at\nthree general scales of abstractions of what a material is - atomistic,\nphysical, and design. At each, an efficient materials informatics\ninfrastructure is being built from the ground up based on (1) the fundamental\nunderstanding of the underlying prior knowledge, including the data, (2)\ndeployment routes that take advantage of it, and (3) pathways to extend it in\nan autonomous or semi-autonomous fashion, while heavily relying on artificial\nintelligence (AI) to guide well-established DFT-based ab initio and\nCALPHAD-based thermodynamic methods.\n  The resulting multi-level discovery infrastructure is highly generalizable as\nit focuses on encoding problems to solve them easily rather than looking for an\nexisting solution. To showcase it, this dissertation discusses the design of\nmulti-alloy functionally graded materials (FGMs) incorporating ultra-high\ntemperature refractory high entropy alloys (RHEAs) towards gas turbine and jet\nengine efficiency increase reducing CO2 emissions, as well as hypersonic\nvehicles. It leverages a new graph representation of underlying mathematical\nspace using a newly developed algorithm based on combinatorics, not subject to\nmany problems troubling the community. Underneath, property models and phase\nrelations are learned from optimized samplings of the largest and highest\nquality dataset of HEA in the world, called ULTERA. At the atomistic level, a\ndata ecosystem optimized for machine learning (ML) from over 4.5 million\nrelaxed structures, called MPDD, is used to inform experimental observations\nand improve thermodynamic models by providing stability data enabled by a new\nefficient featurization framework.",
      "tldr_zh": "这篇论文提出了一种高效的材料信息学基础设施，涵盖从原子级到设计级的多尺度抽象，利用 AI 指导的 DFT 和 CALPHAD 方法，构建基于底层知识的部署和扩展路径。\n该框架强调问题编码以便轻松解决，包括开发基于组合数学的新算法，以及利用大型数据集如 ULTERA 和 MPDD 来学习属性模型和相关系。\n论文展示了其实际应用，例如设计多合金功能梯度材料 (FGMs) 和耐高温难熔高熵合金 (RHEAs)，用于提高燃气轮机、喷气发动机效率并减少 CO2 排放，同时通过优化采样和机器学习 (ML) 改进热力学模型。",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.AI",
        "cs.DB",
        "physics.data-an",
        "G.4; E.1; I.2.4; I.2.6; I.2.8; I.5.3; I.6.5; J.2; J.7"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "comment": "PhD Dissertation in Materials Science and Engineering defended on May\n  20th 2024, 319 body pages, 109 figures, combined-bibliography version, source\n  repository at https://github.com/amkrajewski/PhD-Dissertation",
      "pdf_url": "http://arxiv.org/pdf/2407.04648v1",
      "published_date": "2024-07-05 17:03:26 UTC",
      "updated_date": "2024-07-05 17:03:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:52:40.254885"
    },
    {
      "arxiv_id": "2407.04629v2",
      "title": "Entity Decomposition with Filtering: A Zero-Shot Clinical Named Entity Recognition Framework",
      "title_zh": "实体分解与过滤：一种零样本临床命名实体识别框架",
      "authors": [
        "Reza Averly",
        "Xia Ning"
      ],
      "abstract": "Clinical named entity recognition (NER) aims to retrieve important entities\nwithin clinical narratives. Recent works have demonstrated that large language\nmodels (LLMs) can achieve strong performance in this task. While previous works\nfocus on proprietary LLMs, we investigate how open NER LLMs, trained\nspecifically for entity recognition, perform in clinical NER. Our initial\nexperiment reveals significant contrast in performance for some clinical\nentities and how a simple exploitment on entity types can alleviate this issue.\nIn this paper, we introduce a novel framework, entity decomposition with\nfiltering, or EDF. Our key idea is to decompose the entity recognition task\ninto several retrievals of entity sub-types and then filter them. Our\nexperimental results demonstrate the efficacies of our framework and the\nimprovements across all metrics, models, datasets, and entity types. Our\nanalysis also reveals substantial improvement in recognizing previously missed\nentities using entity decomposition. We further provide a comprehensive\nevaluation of our framework and an in-depth error analysis to pave future\nworks.",
      "tldr_zh": "这篇论文探讨了开源大型语言模型 (LLMs) 在临床命名实体识别 (NER) 中的性能问题，并通过实验发现某些实体类型存在显著差异，可通过简单利用实体类型来缓解。作者引入了 Entity Decomposition with Filtering (EDF) 框架，该框架将实体识别任务分解为多个实体子类型的检索，然后进行过滤，以实现零样本学习。实验结果显示，EDF 在所有指标、模型、数据集和实体类型上均取得了显著改善，特别是增强了对之前遗漏实体的识别能力。最终，论文提供了全面评估和深入错误分析，为未来临床 NER 研究铺平道路。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NAACL 2025 Main Conference",
      "pdf_url": "http://arxiv.org/pdf/2407.04629v2",
      "published_date": "2024-07-05 16:38:23 UTC",
      "updated_date": "2025-02-19 20:51:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:52:52.821875"
    },
    {
      "arxiv_id": "2407.04620v3",
      "title": "Learning to (Learn at Test Time): RNNs with Expressive Hidden States",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Sun",
        "Xinhao Li",
        "Karan Dalal",
        "Jiarui Xu",
        "Arjun Vikram",
        "Genghan Zhang",
        "Yann Dubois",
        "Xinlei Chen",
        "Xiaolong Wang",
        "Sanmi Koyejo",
        "Tatsunori Hashimoto",
        "Carlos Guestrin"
      ],
      "abstract": "Self-attention performs well in long context but has quadratic complexity.\nExisting RNN layers have linear complexity, but their performance in long\ncontext is limited by the expressive power of their hidden states. We present a\npractical framework for instantiating sequence modeling layers with linear\ncomplexity and expressive hidden states. The key idea is to make the hidden\nstate a machine learning model itself, and the update rule a step of\nself-supervised learning. Since the hidden state is updated by training even on\ntest sequences, our layers are called Test-Time Training (TTT) layers. We\nconsider two instantiations: TTT-Linear and TTT-MLP, whose hidden state is a\nlinear model and a two-layer MLP respectively. We evaluate our instantiations\nat the scale of 125M to 1.3B parameters, comparing with a strong Transformer\nand Mamba, a modern RNN. Similar to Transformer, TTT-Linear and TTT-MLP can\nkeep reducing perplexity by conditioning on more tokens, while Mamba cannot\nafter 16k context. TTT-MLP still faces challenges in memory I/O, but shows\nlarger potential in long context, pointing to a promising direction for future\nresearch.",
      "tldr_zh": "这篇论文提出了一种 Test-Time Training (TTT) 框架，用于构建具有线性复杂度和高表达力隐藏状态的 RNN 层，以解决传统 RNN 在长上下文上表现受限的问题。核心方法是将隐藏状态设计为一个自监督学习的模型（如 TTT-Linear 和 TTT-MLP），并在测试序列上进行实时更新。实验结果显示，在125M到1.3B参数规模下，TTT-Linear 和 TTT-MLP 类似于 Transformer，能够通过更多 tokens 持续降低 perplexity，而 Mamba 在16k上下文后无法进一步改进，这为高效长序列建模指出了新方向。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "The current version contains updates on related work and limitations.\n  All experiments were completed in the first version",
      "pdf_url": "http://arxiv.org/pdf/2407.04620v3",
      "published_date": "2024-07-05 16:23:20 UTC",
      "updated_date": "2025-04-03 18:30:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:53:04.361274"
    },
    {
      "arxiv_id": "2407.04616v1",
      "title": "Isomorphic Pruning for Vision Models",
      "title_zh": "翻译失败",
      "authors": [
        "Gongfan Fang",
        "Xinyin Ma",
        "Michael Bi Mi",
        "Xinchao Wang"
      ],
      "abstract": "Structured pruning reduces the computational overhead of deep neural networks\nby removing redundant sub-structures. However, assessing the relative\nimportance of different sub-structures remains a significant challenge,\nparticularly in advanced vision models featuring novel mechanisms and\narchitectures like self-attention, depth-wise convolutions, or residual\nconnections. These heterogeneous substructures usually exhibit diverged\nparameter scales, weight distributions, and computational topology, introducing\nconsiderable difficulty to importance comparison. To overcome this, we present\nIsomorphic Pruning, a simple approach that demonstrates effectiveness across a\nrange of network architectures such as Vision Transformers and CNNs, and\ndelivers competitive performance across different model sizes. Isomorphic\nPruning originates from an observation that, when evaluated under a pre-defined\nimportance criterion, heterogeneous sub-structures demonstrate significant\ndivergence in their importance distribution, as opposed to isomorphic\nstructures that present similar importance patterns. This inspires us to\nperform isolated ranking and comparison on different types of sub-structures\nfor more reliable pruning. Our empirical results on ImageNet-1K demonstrate\nthat Isomorphic Pruning surpasses several pruning baselines dedicatedly\ndesigned for Transformers or CNNs. For instance, we improve the accuracy of\nDeiT-Tiny from 74.52% to 77.50% by pruning an off-the-shelf DeiT-Base model.\nAnd for ConvNext-Tiny, we enhanced performance from 82.06% to 82.18%, while\nreducing the number of parameters and memory usage. Code is available at\n\\url{https://github.com/VainF/Isomorphic-Pruning}.",
      "tldr_zh": "该研究提出了一种名为 Isomorphic Pruning 的简单剪枝方法，用于减少视觉模型如 Vision Transformers 和 CNNs 的计算开销，通过隔离比较不同类型子结构的相对重要性来克服异构子结构（如 self-attention、depth-wise convolutions 和 residual connections）在参数规模、权重分布和计算拓扑上的差异。不同于传统方法，该方法基于一个观察，即异构子结构的重要性分布差异显著，因此对不同子结构进行独立排名和比较，以实现更可靠的剪枝。实验结果显示，在 ImageNet-1K 数据集上，Isomorphic Pruning 超过了多项专用剪枝基线，例如将 DeiT-Tiny 的准确率从 74.52% 提高到 77.50%，并在 ConvNext-Tiny 上将性能从 82.06% 提升到 82.18%，同时减少了参数和内存使用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.04616v1",
      "published_date": "2024-07-05 16:14:53 UTC",
      "updated_date": "2024-07-05 16:14:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:53:18.077920"
    },
    {
      "arxiv_id": "2407.14521v1",
      "title": "Towards Automated Functional Equation Proving: A Benchmark Dataset and A Domain-Specific In-Context Agent",
      "title_zh": "翻译失败",
      "authors": [
        "Mahdi Buali",
        "Robert Hoehndorf"
      ],
      "abstract": "Automated Theorem Proving (ATP) faces challenges due to its complexity and\ncomputational demands. Recent work has explored using Large Language Models\n(LLMs) for ATP action selection, but these methods can be resource-intensive.\nThis study introduces FEAS, an agent that enhances the COPRA in-context\nlearning framework within Lean. FEAS refines prompt generation, response\nparsing, and incorporates domain-specific heuristics for functional equations.\nIt introduces FunEq, a curated dataset of functional equation problems with\nvarying difficulty. FEAS outperforms baselines on FunEq, particularly with the\nintegration of domain-specific heuristics. The results demonstrate FEAS's\neffectiveness in generating and formalizing high-level proof strategies into\nLean proofs, showcasing the potential of tailored approaches for specific ATP\nchallenges.",
      "tldr_zh": "本研究针对 Automated Theorem Proving (ATP) 的复杂性和计算密集问题，引入了 FEAS 代理，该代理基于 COPRA in-context 学习框架，在 Lean 环境中优化提示生成、响应解析，并整合 domain-specific heuristics 以专注于功能方程。论文同时创建了 FunEq 数据集，这是一个包含不同难度功能方程问题的基准数据集。实验结果显示，FEAS 优于基线模型，尤其在应用领域特定启发式后，展示了其在生成和形式化高水平证明策略方面的有效性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.SC"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages",
      "pdf_url": "http://arxiv.org/pdf/2407.14521v1",
      "published_date": "2024-07-05 15:59:16 UTC",
      "updated_date": "2024-07-05 15:59:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:53:30.122125"
    },
    {
      "arxiv_id": "2407.04597v1",
      "title": "Feature Attenuation of Defective Representation Can Resolve Incomplete Masking on Anomaly Detection",
      "title_zh": "翻译失败",
      "authors": [
        "YeongHyeon Park",
        "Sungho Kang",
        "Myung Jin Kim",
        "Hyeong Seok Kim",
        "Juneho Yi"
      ],
      "abstract": "In unsupervised anomaly detection (UAD) research, while state-of-the-art\nmodels have reached a saturation point with extensive studies on public\nbenchmark datasets, they adopt large-scale tailor-made neural networks (NN) for\ndetection performance or pursued unified models for various tasks. Towards edge\ncomputing, it is necessary to develop a computationally efficient and scalable\nsolution that avoids large-scale complex NNs. Motivated by this, we aim to\noptimize the UAD performance with minimal changes to NN settings. Thus, we\nrevisit the reconstruction-by-inpainting approach and rethink to improve it by\nanalyzing strengths and weaknesses. The strength of the SOTA methods is a\nsingle deterministic masking approach that addresses the challenges of random\nmultiple masking that is inference latency and output inconsistency.\nNevertheless, the issue of failure to provide a mask to completely cover\nanomalous regions is a remaining weakness. To mitigate this issue, we propose\nFeature Attenuation of Defective Representation (FADeR) that only employs two\nMLP layers which attenuates feature information of anomaly reconstruction\nduring decoding. By leveraging FADeR, features of unseen anomaly patterns are\nreconstructed into seen normal patterns, reducing false alarms. Experimental\nresults demonstrate that FADeR achieves enhanced performance compared to\nsimilar-scale NNs. Furthermore, our approach exhibits scalability in\nperformance enhancement when integrated with other single deterministic masking\nmethods in a plug-and-play manner.",
      "tldr_zh": "在无监督异常检测 (UAD) 领域，现有的最先进模型依赖大型定制神经网络 (NN)，但这不适合边缘计算环境，因此本研究旨在通过最小改动优化 UAD 性能。作者重新审视重建-by-inpainting 方法，并提出 Feature Attenuation of Defective Representation (FADeR)，该方法仅使用两个 MLP 层来衰减异常重建过程中的特征信息，从而将未见异常模式重建为已见正常模式，减少误报。实验结果显示，FADeR 比类似规模的 NN 表现出色，且能以即插即用方式与其他单一确定性掩码方法结合，提升整体性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages, 6 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2407.04597v1",
      "published_date": "2024-07-05 15:44:53 UTC",
      "updated_date": "2024-07-05 15:44:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:53:41.290260"
    },
    {
      "arxiv_id": "2407.04559v4",
      "title": "Not (yet) the whole story: Evaluating Visual Storytelling Requires More than Measuring Coherence, Grounding, and Repetition",
      "title_zh": "翻译失败",
      "authors": [
        "Aditya K Surikuchi",
        "Raquel Fernández",
        "Sandro Pezzelle"
      ],
      "abstract": "Visual storytelling consists in generating a natural language story given a\ntemporally ordered sequence of images. This task is not only challenging for\nmodels, but also very difficult to evaluate with automatic metrics since there\nis no consensus about what makes a story 'good'. In this paper, we introduce a\nnovel method that measures story quality in terms of human likeness regarding\nthree key aspects highlighted in previous work: visual grounding, coherence,\nand repetitiveness. We then use this method to evaluate the stories generated\nby several models, showing that the foundation model LLaVA obtains the best\nresult, but only slightly so compared to TAPM, a 50-times smaller visual\nstorytelling model. Upgrading the visual and language components of TAPM\nresults in a model that yields competitive performance with a relatively low\nnumber of parameters. Finally, we carry out a human evaluation study, whose\nresults suggest that a 'good' story may require more than a human-like level of\nvisual grounding, coherence, and repetition.",
      "tldr_zh": "本文提出一种新方法，通过测量视觉讲故事（visual storytelling）在visual grounding、coherence和repetitiveness方面的人类相似性，来评估故事质量。该方法应用于多个模型的评估，结果显示LLaVA模型表现最佳，但仅比参数量小50倍的TAPM模型略优；升级TAPM的视觉和语言组件后，其性能变得更具竞争力。最后，人类评估研究表明，一个“好”的故事可能需要超出这些指标的水平，例如更高的创新性或深度。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "In proceedings of EMNLP 2024 (Findings)",
      "pdf_url": "http://arxiv.org/pdf/2407.04559v4",
      "published_date": "2024-07-05 14:48:15 UTC",
      "updated_date": "2024-10-25 13:47:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:53:54.251728"
    },
    {
      "arxiv_id": "2407.04551v1",
      "title": "An AI Architecture with the Capability to Classify and Explain Hardware Trojans",
      "title_zh": "一种具有分类和解释硬件木马能力的AI架构",
      "authors": [
        "Paul Whitten",
        "Francis Wolff",
        "Chris Papachristou"
      ],
      "abstract": "Hardware trojan detection methods, based on machine learning (ML) techniques,\nmainly identify suspected circuits but lack the ability to explain how the\ndecision was arrived at. An explainable methodology and architecture is\nintroduced based on the existing hardware trojan detection features. Results\nare provided for explaining digital hardware trojans within a netlist using\ntrust-hub trojan benchmarks.",
      "tldr_zh": "该论文提出了一种AI架构，能够分类硬件木马并解释决策过程，解决了传统基于机器学习(ML)技术的硬件木马检测方法缺乏可解释性的问题。该架构利用现有的硬件木马检测特征，构建可解释的方法和系统。通过Trust-Hub木马基准测试，结果显示该方法在网表中有效解释数字硬件木马的检测决策。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.04551v1",
      "published_date": "2024-07-05 14:36:19 UTC",
      "updated_date": "2024-07-05 14:36:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:54:03.555000"
    },
    {
      "arxiv_id": "2407.04549v1",
      "title": "Spontaneous Reward Hacking in Iterative Self-Refinement",
      "title_zh": "迭代自我精炼中的自发奖励劫持",
      "authors": [
        "Jane Pan",
        "He He",
        "Samuel R. Bowman",
        "Shi Feng"
      ],
      "abstract": "Language models are capable of iteratively improving their outputs based on\nnatural language feedback, thus enabling in-context optimization of user\npreference. In place of human users, a second language model can be used as an\nevaluator, providing feedback along with numerical ratings which the generator\nattempts to optimize. However, because the evaluator is an imperfect proxy of\nuser preference, this optimization can lead to reward hacking, where the\nevaluator's ratings improve while the generation quality remains stagnant or\neven decreases as judged by actual user preference. The concern of reward\nhacking is heightened in iterative self-refinement where the generator and the\nevaluator use the same underlying language model, in which case the\noptimization pressure can drive them to exploit shared vulnerabilities. Using\nan essay editing task, we show that iterative self-refinement leads to\ndeviation between the language model evaluator and human judgment,\ndemonstrating that reward hacking can occur spontaneously in-context with the\nuse of iterative self-refinement. In addition, we study conditions under which\nreward hacking occurs and observe two factors that affect reward hacking\nseverity: model size and context sharing between the generator and the\nevaluator.",
      "tldr_zh": "本研究探讨了在迭代自精炼过程中，语言模型如何通过优化评估器反馈（如数值评分）导致自发的奖励黑客（reward hacking）问题，即评估器评分提升但生成质量（如用户偏好）停滞或下降。研究使用论文编辑任务作为实验范例，展示了当生成器和评估器基于同一底层模型时，优化压力会放大共享漏洞，造成评估器与人类判断的偏差。结果表明，模型大小和生成器与评估器之间的上下文共享是影响奖励黑客严重程度的关键因素，为语言模型优化中的潜在风险提供了重要洞见。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.04549v1",
      "published_date": "2024-07-05 14:34:50 UTC",
      "updated_date": "2024-07-05 14:34:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:54:17.456935"
    },
    {
      "arxiv_id": "2407.04547v1",
      "title": "Real-time Timbre Remapping with Differentiable DSP",
      "title_zh": "翻译失败",
      "authors": [
        "Jordie Shier",
        "Charalampos Saitis",
        "Andrew Robertson",
        "Andrew McPherson"
      ],
      "abstract": "Timbre is a primary mode of expression in diverse musical contexts. However,\nprevalent audio-driven synthesis methods predominantly rely on pitch and\nloudness envelopes, effectively flattening timbral expression from the input.\nOur approach draws on the concept of timbre analogies and investigates how\ntimbral expression from an input signal can be mapped onto controls for a\nsynthesizer. Leveraging differentiable digital signal processing, our method\nfacilitates direct optimization of synthesizer parameters through a novel\nfeature difference loss. This loss function, designed to learn relative timbral\ndifferences between musical events, prioritizes the subtleties of graded timbre\nmodulations within phrases, allowing for meaningful translations in a timbre\nspace. Using snare drum performances as a case study, where timbral expression\nis central, we demonstrate real-time timbre remapping from acoustic snare drums\nto a differentiable synthesizer modeled after the Roland TR-808.",
      "tldr_zh": "本研究针对现有音频合成方法忽略音色（timbre）表达的问题，提出了一种基于音色类比（timbre analogies）的实时音色重映射方法。利用可微分数字信号处理（Differentiable DSP），该方法通过直接优化合成器参数，并引入一个新的特征差异损失函数（feature difference loss），以学习音乐事件之间的相对音色差异，从而捕捉音色微妙变化。实验以军鼓表演为例，实现了从声学军鼓到模拟 Roland TR-808 合成器的实时映射，提升了音色表达的精确性和音乐多样性。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS",
        "eess.SP"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted for publication at the 24th International Conference on New\n  Interfaces for Musical Expression in Utrecht, Netherlands",
      "pdf_url": "http://arxiv.org/pdf/2407.04547v1",
      "published_date": "2024-07-05 14:32:52 UTC",
      "updated_date": "2024-07-05 14:32:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:54:28.589530"
    },
    {
      "arxiv_id": "2407.04541v2",
      "title": "PoPreRo: A New Dataset for Popularity Prediction of Romanian Reddit Posts",
      "title_zh": "PoPreRo：一个用于罗马尼亚 Reddit 帖子流行度预测的新数据集",
      "authors": [
        "Ana-Cristina Rogoz",
        "Maria Ilinca Nechita",
        "Radu Tudor Ionescu"
      ],
      "abstract": "We introduce PoPreRo, the first dataset for Popularity Prediction of Romanian\nposts collected from Reddit. The PoPreRo dataset includes a varied compilation\nof post samples from five distinct subreddits of Romania, totaling 28,107 data\nsamples. Along with our novel dataset, we introduce a set of competitive models\nto be used as baselines for future research. Interestingly, the top-scoring\nmodel achieves an accuracy of 61.35% and a macro F1 score of 60.60% on the test\nset, indicating that the popularity prediction task on PoPreRo is very\nchallenging. Further investigations based on few-shot prompting the Falcon-7B\nLarge Language Model also point in the same direction. We thus believe that\nPoPreRo is a valuable resource that can be used to evaluate models on\npredicting the popularity of social media posts in Romanian. We release our\ndataset at https://github.com/ana-rogoz/PoPreRo.",
      "tldr_zh": "该研究引入了PoPreRo，这是一个新的数据集，用于预测罗马尼亚Reddit帖子的Popularity Prediction，共包含来自五个子reddits的28,107个样本。研究者提供了竞争模型作为基线，其中表现最佳的模型在测试集上达到61.35%的accuracy和60.60%的macro F1 score。进一步的实验，如对Falcon-7B大语言模型的few-shot prompting，表明该任务具有高度挑战性。PoPreRo数据集的发布将有助于评估模型在罗马尼亚社交媒体帖子流行性预测方面的性能，可从GitHub获取。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at ICPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.04541v2",
      "published_date": "2024-07-05 14:28:12 UTC",
      "updated_date": "2024-11-24 09:40:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:54:39.912009"
    },
    {
      "arxiv_id": "2407.04538v3",
      "title": "PDiscoFormer: Relaxing Part Discovery Constraints with Vision Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Ananthu Aniraj",
        "Cassio F. Dantas",
        "Dino Ienco",
        "Diego Marcos"
      ],
      "abstract": "Computer vision methods that explicitly detect object parts and reason on\nthem are a step towards inherently interpretable models. Existing approaches\nthat perform part discovery driven by a fine-grained classification task make\nvery restrictive assumptions on the geometric properties of the discovered\nparts; they should be small and compact. Although this prior is useful in some\ncases, in this paper we show that pre-trained transformer-based vision models,\nsuch as self-supervised DINOv2 ViT, enable the relaxation of these constraints.\nIn particular, we find that a total variation (TV) prior, which allows for\nmultiple connected components of any size, substantially outperforms previous\nwork. We test our approach on three fine-grained classification benchmarks:\nCUB, PartImageNet and Oxford Flowers, and compare our results to previously\npublished methods as well as a re-implementation of the state-of-the-art method\nPDiscoNet with a transformer-based backbone. We consistently obtain substantial\nimprovements across the board, both on part discovery metrics and the\ndownstream classification task, showing that the strong inductive biases in\nself-supervised ViT models require to rethink the geometric priors that can be\nused for unsupervised part discovery.",
      "tldr_zh": "本论文提出 PDiscoFormer 方法，利用预训练的 Vision Transformers（如 self-supervised DINOv2 ViT），放松了传统部分发现任务中对物体部分几何属性的严格约束，转而采用 total variation (TV) prior，以允许多个连接组件且任意大小。相比现有方法，该框架在 CUB、PartImageNet 和 Oxford Flowers 等细粒度分类基准上，显著提升了部分发现指标和下游分类任务的性能，例如超过了 PDiscoNet 的再实现。实验结果证明，自监督 ViT 模型的强归纳偏差要求重新审视无监督部分发现中的几何先验，从而推动更灵活且可解释的计算机视觉模型发展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted as a main conference paper at the European Conference of\n  Computer Vision (ECCV) 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.04538v3",
      "published_date": "2024-07-05 14:24:37 UTC",
      "updated_date": "2024-07-22 09:41:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:54:53.329674"
    },
    {
      "arxiv_id": "2407.04528v4",
      "title": "GPT vs RETRO: Exploring the Intersection of Retrieval and Parameter-Efficient Fine-Tuning",
      "title_zh": "GPT 与 RETRO：探索检索和参数高效微调的交集",
      "authors": [
        "Aleksander Ficek",
        "Jiaqi Zeng",
        "Oleksii Kuchaiev"
      ],
      "abstract": "Parameter-Efficient Fine-Tuning (PEFT) and Retrieval-Augmented Generation\n(RAG) have become popular methods for adapting large language models while\nminimizing compute requirements. In this paper, we apply PEFT methods\n(P-tuning, Adapters, and LoRA) to a modified Retrieval-Enhanced Transformer\n(RETRO) and a baseline GPT model across several sizes, ranging from 823 million\nto 48 billion parameters. We show that RETRO models outperform GPT models in\nzero-shot settings due to their unique pre-training process but GPT models have\nhigher performance potential with PEFT. Additionally, our study indicates that\n8B parameter models strike an optimal balance between cost and performance and\nP-tuning lags behind other PEFT techniques. We further provide a comparative\nanalysis between applying PEFT to an Instruction-tuned RETRO model and base\nRETRO model. This work presents the first comprehensive comparison of various\nPEFT methods integrated with RAG, applied to both GPT and RETRO models,\nhighlighting their relative performance.",
      "tldr_zh": "这篇论文探讨了Parameter-Efficient Fine-Tuning (PEFT) 和 Retrieval-Augmented Generation (RAG) 在大型语言模型中的应用，将PEFT方法（如P-tuning、Adapters和LoRA）应用于不同规模的RETRO和GPT模型（从823百万到48亿参数）。研究发现，RETRO模型在零样本设置中表现优于GPT模型，但GPT模型在PEFT优化下显示出更高的性能潜力，且8B参数模型在成本和效果之间达到了最佳平衡。总体而言，P-tuning落后于其他PEFT技术，该工作首次全面比较了这些方法在Instruction-tuned RETRO和基础RETRO模型上的相对性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.04528v4",
      "published_date": "2024-07-05 14:16:47 UTC",
      "updated_date": "2024-10-25 14:33:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:55:08.164569"
    },
    {
      "arxiv_id": "2407.04525v4",
      "title": "Enhancing learning in spiking neural networks through neuronal heterogeneity and neuromodulatory signaling",
      "title_zh": "通过神经元异质性和神经调制信号增强脉冲神经网络中的学习",
      "authors": [
        "Alejandro Rodriguez-Garcia",
        "Jie Mei",
        "Srikanth Ramaswamy"
      ],
      "abstract": "Recent progress in artificial intelligence (AI) has been driven by insights\nfrom neuroscience, particularly with the development of artificial neural\nnetworks (ANNs). This has significantly enhanced the replication of complex\ncognitive tasks such as vision and natural language processing. Despite these\nadvances, ANNs struggle with continual learning, adaptable knowledge transfer,\nrobustness, and resource efficiency - capabilities that biological systems\nhandle seamlessly. Specifically, ANNs often overlook the functional and\nmorphological diversity of the brain, hindering their computational\ncapabilities. Furthermore, incorporating cell-type specific neuromodulatory\neffects into ANNs with neuronal heterogeneity could enable learning at two\nspatial scales: spiking behavior at the neuronal level, and synaptic plasticity\nat the circuit level, thereby potentially enhancing their learning abilities.\nIn this article, we summarize recent bio-inspired models, learning rules and\narchitectures and propose a biologically-informed framework for enhancing ANNs.\nOur proposed dual-framework approach highlights the potential of spiking neural\nnetworks (SNNs) for emulating diverse spiking behaviors and dendritic\ncompartments to simulate morphological and functional diversity of neuronal\ncomputations. Finally, we outline how the proposed approach integrates\nbrain-inspired compartmental models and task-driven SNNs, balances\nbioinspiration and complexity, and provides scalable solutions for pressing AI\nchallenges, such as continual learning, adaptability, robustness, and\nresource-efficiency.",
      "tldr_zh": "该论文讨论了人工神经网络 (ANNs) 在持续学习、可适应知识转移、鲁棒性和资源效率方面存在的局限性，这些问题源于忽略大脑的神经元异质性 (neuronal heterogeneity) 和神经调节信号 (neuromodulatory signaling)。作者提出一个生物启发的双框架方法，利用脉冲神经网络 (SNNs) 来模拟多样化的脉冲行为和树突区室，从而在神经元级别实现脉冲行为学习，在电路级别实现突触可塑性。最终，该框架整合脑启发模型和任务驱动 SNNs，提供可扩展的解决方案，提升 AI 在持续学习、适应性、鲁棒性和资源效率等方面的性能。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.LG",
        "92B20"
      ],
      "primary_category": "q-bio.NC",
      "comment": "30 pages, 4 figures, 3 boxes",
      "pdf_url": "http://arxiv.org/pdf/2407.04525v4",
      "published_date": "2024-07-05 14:11:28 UTC",
      "updated_date": "2024-11-11 16:58:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:55:32.047775"
    },
    {
      "arxiv_id": "2407.04513v2",
      "title": "LayerShuffle: Enhancing Robustness in Vision Transformers by Randomizing Layer Execution Order",
      "title_zh": "LayerShuffle：通过随机化层执行顺序增强视觉Transformer的鲁棒性",
      "authors": [
        "Matthias Freiberger",
        "Peter Kun",
        "Anders Sundnes Løvlie",
        "Sebastian Risi"
      ],
      "abstract": "Due to their architecture and how they are trained, artificial neural\nnetworks are typically not robust toward pruning or shuffling layers at test\ntime. However, such properties would be desirable for different applications,\nsuch as distributed neural network architectures where the order of execution\ncannot be guaranteed or parts of the network can fail during inference. In this\nwork, we address these issues through a number of training approaches for\nvision transformers whose most important component is randomizing the execution\norder of attention modules at training time. With our proposed approaches,\nvision transformers are capable to adapt to arbitrary layer execution orders at\ntest time assuming one tolerates a reduction (about 20\\%) in accuracy at the\nsame model size. We analyse the feature representations of our trained models\nas well as how each layer contributes to the models prediction based on its\nposition during inference. Our analysis shows that layers learn to contribute\ndifferently based on their position in the network. Finally, we layer-prune our\nmodels at test time and find that their performance declines gracefully. Code\navailable at https://github.com/matfrei/layershuffle.",
      "tldr_zh": "本文提出LayerShuffle方法，通过在训练时随机化Vision Transformers中注意力模块的执行顺序，来提升模型对层执行顺序打乱的鲁棒性。这种方法使模型能够在测试时适应任意层顺序，但会带来约20%的准确率下降。实验分析显示，层根据其在网络中的位置学会不同贡献，并在测试时的层剪枝操作中，性能下降较为平滑。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.04513v2",
      "published_date": "2024-07-05 13:54:15 UTC",
      "updated_date": "2024-12-06 14:20:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:55:42.447960"
    },
    {
      "arxiv_id": "2407.04503v2",
      "title": "When LLMs Play the Telephone Game: Cumulative Changes and Attractors in Iterated Cultural Transmissions",
      "title_zh": "当 LLMs 玩传话游戏：迭代文化传播中的累积变化和吸引子",
      "authors": [
        "Jérémy Perez",
        "Grgur Kovač",
        "Corentin Léger",
        "Cédric Colas",
        "Gaia Molinaro",
        "Maxime Derex",
        "Pierre-Yves Oudeyer",
        "Clément Moulin-Frier"
      ],
      "abstract": "As large language models (LLMs) start interacting with each other and\ngenerating an increasing amount of text online, it becomes crucial to better\nunderstand how information is transformed as it passes from one LLM to the\nnext. While significant research has examined individual LLM behaviors,\nexisting studies have largely overlooked the collective behaviors and\ninformation distortions arising from iterated LLM interactions. Small biases,\nnegligible at the single output level, risk being amplified in iterated\ninteractions, potentially leading the content to evolve towards attractor\nstates. In a series of telephone game experiments, we apply a transmission\nchain design borrowed from the human cultural evolution literature: LLM agents\niteratively receive, produce, and transmit texts from the previous to the next\nagent in the chain. By tracking the evolution of text toxicity, positivity,\ndifficulty, and length across transmission chains, we uncover the existence of\nbiases and attractors, and study their dependence on the initial text, the\ninstructions, language model, and model size. For instance, we find that more\nopen-ended instructions lead to stronger attraction effects compared to more\nconstrained tasks. We also find that different text properties display\ndifferent sensitivity to attraction effects, with toxicity leading to stronger\nattractors than length. These findings highlight the importance of accounting\nfor multi-step transmission dynamics and represent a first step towards a more\ncomprehensive understanding of LLM cultural dynamics.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）在迭代互动中信息变换的问题，特别是累积变化和吸引子（attractors）的形成，通过模拟“传话游戏”实验，让LLMs代理依次接收、生成和传输文本。实验追踪了文本的毒性、积极性、难度和长度等属性，发现初始偏差可能在多步传输中放大，导致内容向特定吸引子状态演化。结果显示，更开放的指令会增强吸引效应，而毒性属性比长度更易受影响。这些发现强调了考虑多步传输动态的必要性，为理解LLMs的文化动态提供了初步基础。",
      "categories": [
        "physics.soc-ph",
        "cs.AI",
        "cs.MA",
        "68T50",
        "I.2.7"
      ],
      "primary_category": "physics.soc-ph",
      "comment": "Code available at https://github.com/jeremyperez2/TelephoneGameLLM.\n  Companion website with a Data Explorer tool at\n  https://sites.google.com/view/telephone-game-llm",
      "pdf_url": "http://arxiv.org/pdf/2407.04503v2",
      "published_date": "2024-07-05 13:44:09 UTC",
      "updated_date": "2024-12-18 11:02:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:55:45.244712"
    },
    {
      "arxiv_id": "2407.04486v1",
      "title": "Variational and Explanatory Neural Networks for Encoding Cancer Profiles and Predicting Drug Responses",
      "title_zh": "变分与解释性神经网络用于编码癌症特征和预测药物反应",
      "authors": [
        "Tianshu Feng",
        "Rohan Gnanaolivu",
        "Abolfazl Safikhani",
        "Yuanhang Liu",
        "Jun Jiang",
        "Nicholas Chia",
        "Alexander Partin",
        "Priyanka Vasanthakumari",
        "Yitan Zhu",
        "Chen Wang"
      ],
      "abstract": "Human cancers present a significant public health challenge and require the\ndiscovery of novel drugs through translational research. Transcriptomics\nprofiling data that describes molecular activities in tumors and cancer cell\nlines are widely utilized for predicting anti-cancer drug responses. However,\nexisting AI models face challenges due to noise in transcriptomics data and\nlack of biological interpretability. To overcome these limitations, we\nintroduce VETE (Variational and Explanatory Transcriptomics Encoder), a novel\nneural network framework that incorporates a variational component to mitigate\nnoise effects and integrates traceable gene ontology into the neural network\narchitecture for encoding cancer transcriptomics data. Key innovations include\na local interpretability-guided method for identifying ontology paths, a\nvisualization tool to elucidate biological mechanisms of drug responses, and\nthe application of centralized large scale hyperparameter optimization. VETE\ndemonstrated robust accuracy in cancer cell line classification and drug\nresponse prediction. Additionally, it provided traceable biological\nexplanations for both tasks and offers insights into the mechanisms underlying\nits predictions. VETE bridges the gap between AI-driven predictions and\nbiologically meaningful insights in cancer research, which represents a\npromising advancement in the field.",
      "tldr_zh": "该研究针对癌症转录组数据（transcriptomics data）的噪声和生物学可解释性不足问题，引入了 VETE（Variational and Explanatory Transcriptomics Encoder）框架，这是一种结合变分组件（variational component）和可追踪基因本体（gene ontology）的神经网络架构，用于编码癌症配置文件并预测药物反应。VETE 的关键创新包括本地可解释性引导方法（local interpretability-guided method）来识别本体路径、可视化工具阐明药物反应的生物机制，以及集中式大规模超参数优化（centralized large scale hyperparameter optimization）。实验结果显示，VETE 在癌症细胞系分类和药物反应预测中表现出色，并提供可追踪的生物学解释，从而桥接了 AI 预测与生物学洞察的鸿沟，推动癌症研究领域的进展。",
      "categories": [
        "q-bio.QM",
        "cs.AI"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.04486v1",
      "published_date": "2024-07-05 13:13:02 UTC",
      "updated_date": "2024-07-05 13:13:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:55:59.677310"
    },
    {
      "arxiv_id": "2407.04472v3",
      "title": "EventChat: Implementation and user-centric evaluation of a large language model-driven conversational recommender system for exploring leisure events in an SME context",
      "title_zh": "EventChat: 大型语言模型驱动的对话推荐系统的实现与以用户为中心的评估，用于探索SME背景下的休闲活动",
      "authors": [
        "Hannes Kunstmann",
        "Joseph Ollier",
        "Joel Persson",
        "Florian von Wangenheim"
      ],
      "abstract": "Large language models (LLMs) present an enormous evolution in the strategic\npotential of conversational recommender systems (CRS). Yet to date, research\nhas predominantly focused upon technical frameworks to implement LLM-driven\nCRS, rather than end-user evaluations or strategic implications for firms,\nparticularly from the perspective of a small to medium enterprises (SME) that\nmakeup the bedrock of the global economy. In the current paper, we detail the\ndesign of an LLM-driven CRS in an SME setting, and its subsequent performance\nin the field using both objective system metrics and subjective user\nevaluations. While doing so, we additionally outline a short-form revised\nResQue model for evaluating LLM-driven CRS, enabling replicability in a rapidly\nevolving field. Our results reveal good system performance from a user\nexperience perspective (85.5% recommendation accuracy) but underscore latency,\ncost, and quality issues challenging business viability. Notably, with a median\ncost of $0.04 per interaction and a latency of 5.7s, cost-effectiveness and\nresponse time emerge as crucial areas for achieving a more user-friendly and\neconomically viable LLM-driven CRS for SME settings. One major driver of these\ncosts is the use of an advanced LLM as a ranker within the retrieval-augmented\ngeneration (RAG) technique. Our results additionally indicate that relying\nsolely on approaches such as Prompt-based learning with ChatGPT as the\nunderlying LLM makes it challenging to achieve satisfying quality in a\nproduction environment. Strategic considerations for SMEs deploying an\nLLM-driven CRS are outlined, particularly considering trade-offs in the current\ntechnical landscape.",
      "tldr_zh": "该研究介绍了 EventChat，一种基于大型语言模型 (LLMs) 的对话推荐系统 (CRS)，旨在帮助中小企业 (SME) 探索休闲事件，并从用户角度进行评估。研究设计了 LLM 驱动的 CRS，使用检索增强生成 (RAG) 技术和修订的 ResQue 模型，结合客观系统指标和主观用户反馈进行测试。结果显示，系统推荐准确率达 85.5%，但面临延迟 (5.7 秒)、成本 ($0.04/互动) 和质量挑战，强调了在生产环境中优化 Prompt-based learning 的必要性。最终，为 SME 部署 LLM 驱动 CRS 提供了战略建议，包括权衡技术成本与用户体验的权衡。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "68T50",
        "I.2.7; H.5.2"
      ],
      "primary_category": "cs.IR",
      "comment": "27 pages, 3 tables, 5 figures, pre-print manuscript, updated version\n  of manuscript due to typo (previous version, Figure 5 was incorrectly named\n  Figure 6)",
      "pdf_url": "http://arxiv.org/pdf/2407.04472v3",
      "published_date": "2024-07-05 12:42:31 UTC",
      "updated_date": "2024-07-09 13:31:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:56:19.951862"
    },
    {
      "arxiv_id": "2407.04467v3",
      "title": "Are Large Language Models Strategic Decision Makers? A Study of Performance and Bias in Two-Player Non-Zero-Sum Games",
      "title_zh": "翻译失败",
      "authors": [
        "Nathan Herr",
        "Fernando Acero",
        "Roberta Raileanu",
        "María Pérez-Ortiz",
        "Zhibin Li"
      ],
      "abstract": "Large Language Models (LLMs) have been increasingly used in real-world\nsettings, yet their strategic decision-making abilities remain largely\nunexplored. To fully benefit from the potential of LLMs, it's essential to\nunderstand their ability to function in complex social scenarios. Game theory,\nwhich is already used to understand real-world interactions, provides a good\nframework for assessing these abilities. This work investigates the performance\nand merits of LLMs in canonical game-theoretic two-player non-zero-sum games,\nStag Hunt and Prisoner Dilemma. Our structured evaluation of GPT-3.5,\nGPT-4-Turbo, GPT-4o, and Llama-3-8B shows that these models, when making\ndecisions in these games, are affected by at least one of the following\nsystematic biases: positional bias, payoff bias, or behavioural bias. This\nindicates that LLMs do not fully rely on logical reasoning when making these\nstrategic decisions. As a result, it was found that the LLMs' performance drops\nwhen the game configuration is misaligned with the affecting biases. When\nmisaligned, GPT-3.5, GPT-4-Turbo, GPT-4o, and Llama-3-8B show an average\nperformance drop of 32\\%, 25\\%, 34\\%, and 29\\% respectively in Stag Hunt, and\n28\\%, 16\\%, 34\\%, and 24\\% respectively in Prisoner's Dilemma. Surprisingly,\nGPT-4o (a top-performing LLM across standard benchmarks) suffers the most\nsubstantial performance drop, suggesting that newer models are not addressing\nthese issues. Interestingly, we found that a commonly used method of improving\nthe reasoning capabilities of LLMs, chain-of-thought (CoT) prompting, reduces\nthe biases in GPT-3.5, GPT-4o, and Llama-3-8B but increases the effect of the\nbias in GPT-4-Turbo, indicating that CoT alone cannot fully serve as a robust\nsolution to this problem. We perform several additional experiments, which\nprovide further insight into these observed behaviours.",
      "tldr_zh": "本研究评估了大型语言模型（LLMs）在两个玩家非零和博弈中的战略决策能力，聚焦于Stag Hunt和Prisoner's Dilemma游戏，通过结构化实验测试GPT-3.5、GPT-4-Turbo、GPT-4o和Llama-3-8B模型的表现。结果显示，这些模型受位置偏差（positional bias）、收益偏差（payoff bias）和行为偏差（behavioural bias）的影响，导致在游戏配置不一致时性能显著下降，例如GPT-4o的平均下降率高达34%。此外，Chain-of-Thought (CoT) 提示能降低某些模型的偏差，但对GPT-4-Turbo反而加剧问题，表明CoT并非可靠解决方案，并强调LLMs在逻辑推理方面仍有局限。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.GT"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.04467v3",
      "published_date": "2024-07-05 12:30:02 UTC",
      "updated_date": "2024-10-15 11:29:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:56:23.230906"
    },
    {
      "arxiv_id": "2407.04458v1",
      "title": "Robust Multimodal Learning via Representation Decoupling",
      "title_zh": "翻译失败",
      "authors": [
        "Shicai Wei",
        "Yang Luo",
        "Yuji Wang",
        "Chunbo Luo"
      ],
      "abstract": "Multimodal learning robust to missing modality has attracted increasing\nattention due to its practicality. Existing methods tend to address it by\nlearning a common subspace representation for different modality combinations.\nHowever, we reveal that they are sub-optimal due to their implicit constraint\non intra-class representation. Specifically, the sample with different\nmodalities within the same class will be forced to learn representations in the\nsame direction. This hinders the model from capturing modality-specific\ninformation, resulting in insufficient learning. To this end, we propose a\nnovel Decoupled Multimodal Representation Network (DMRNet) to assist robust\nmultimodal learning. Specifically, DMRNet models the input from different\nmodality combinations as a probabilistic distribution instead of a fixed point\nin the latent space, and samples embeddings from the distribution for the\nprediction module to calculate the task loss. As a result, the direction\nconstraint from the loss minimization is blocked by the sampled representation.\nThis relaxes the constraint on the inference representation and enables the\nmodel to capture the specific information for different modality combinations.\nFurthermore, we introduce a hard combination regularizer to prevent DMRNet from\nunbalanced training by guiding it to pay more attention to hard modality\ncombinations. Finally, extensive experiments on multimodal classification and\nsegmentation tasks demonstrate that the proposed DMRNet outperforms the\nstate-of-the-art significantly.",
      "tldr_zh": "这篇论文针对多模态学习中缺失模态的鲁棒性问题，揭示了现有方法因内部类表示的隐式约束而无法捕获模态特定信息，导致学习不足。作者提出了一种新框架Decoupled Multimodal Representation Network (DMRNet)，通过将不同模态组合建模为潜在空间中的概率分布，并从中采样嵌入进行预测，从而放松表示方向的约束并增强模态特定信息的提取。此外，DMRNet 引入了 hard combination regularizer 来避免训练不平衡，实验在多模态分类和分割任务上显示其显著优于最先进方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ECCV2024 17 pages",
      "pdf_url": "http://arxiv.org/pdf/2407.04458v1",
      "published_date": "2024-07-05 12:09:33 UTC",
      "updated_date": "2024-07-05 12:09:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:56:33.794030"
    },
    {
      "arxiv_id": "2407.04451v1",
      "title": "Hindsight Preference Learning for Offline Preference-based Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Chen-Xiao Gao",
        "Shengjun Fang",
        "Chenjun Xiao",
        "Yang Yu",
        "Zongzhang Zhang"
      ],
      "abstract": "Offline preference-based reinforcement learning (RL), which focuses on\noptimizing policies using human preferences between pairs of trajectory\nsegments selected from an offline dataset, has emerged as a practical avenue\nfor RL applications. Existing works rely on extracting step-wise reward signals\nfrom trajectory-wise preference annotations, assuming that preferences\ncorrelate with the cumulative Markovian rewards. However, such methods fail to\ncapture the holistic perspective of data annotation: Humans often assess the\ndesirability of a sequence of actions by considering the overall outcome rather\nthan the immediate rewards. To address this challenge, we propose to model\nhuman preferences using rewards conditioned on future outcomes of the\ntrajectory segments, i.e. the hindsight information. For downstream RL\noptimization, the reward of each step is calculated by marginalizing over\npossible future outcomes, the distribution of which is approximated by a\nvariational auto-encoder trained using the offline dataset. Our proposed\nmethod, Hindsight Preference Learning (HPL), can facilitate credit assignment\nby taking full advantage of vast trajectory data available in massive unlabeled\ndatasets. Comprehensive empirical studies demonstrate the benefits of HPL in\ndelivering robust and advantageous rewards across various domains. Our code is\npublicly released at https://github.com/typoverflow/WiseRL.",
      "tldr_zh": "该研究针对离线偏好强化学习（Offline preference-based RL）中的问题，提出了一种后见偏好学习（Hindsight Preference Learning, HPL）方法，以更好地捕捉人类对轨迹整体结果的评估，而非仅依赖步-wise 奖励信号。HPL 通过使用基于未来结果的奖励（hindsight information），并利用变分自编码器（Variational Auto-Encoder, VAE）训练的离线数据集来近似未来结果分布，从而实现对每个步骤奖励的边缘化计算，促进信用分配。实验结果显示，HPL 在各种领域提供更稳健和有利的奖励表现，并已开源代码以供进一步验证。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.04451v1",
      "published_date": "2024-07-05 12:05:37 UTC",
      "updated_date": "2024-07-05 12:05:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:56:45.078021"
    },
    {
      "arxiv_id": "2407.04449v1",
      "title": "Multi-modal Masked Siamese Network Improves Chest X-Ray Representation Learning",
      "title_zh": "多模态掩码孪生网络改善胸部 X 光表示学习",
      "authors": [
        "Saeed Shurrab",
        "Alejandro Guerra-Manzanares",
        "Farah E. Shamout"
      ],
      "abstract": "Self-supervised learning methods for medical images primarily rely on the\nimaging modality during pretraining. While such approaches deliver promising\nresults, they do not leverage associated patient or scan information collected\nwithin Electronic Health Records (EHR). Here, we propose to incorporate EHR\ndata during self-supervised pretraining with a Masked Siamese Network (MSN) to\nenhance the quality of chest X-ray representations. We investigate three types\nof EHR data, including demographic, scan metadata, and inpatient stay\ninformation. We evaluate our approach on three publicly available chest X-ray\ndatasets, MIMIC-CXR, CheXpert, and NIH-14, using two vision transformer (ViT)\nbackbones, specifically ViT-Tiny and ViT-Small. In assessing the quality of the\nrepresentations via linear evaluation, our proposed method demonstrates\nsignificant improvement compared to vanilla MSN and state-of-the-art\nself-supervised learning baselines. Our work highlights the potential of\nEHR-enhanced self-supervised pre-training for medical imaging. The code is\npublicly available at: https://github.com/nyuad-cai/CXR-EHR-MSN",
      "tldr_zh": "该研究提出了一种改进的 Masked Siamese Network (MSN)，通过整合 Electronic Health Records (EHR) 数据（如人口统计、扫描元数据和住院信息）来提升胸部 X 光图像的自监督表示学习。相比传统 MSN，该方法在 MIMIC-CXR、CheXpert 和 NIH-14 数据集上，使用 ViT-Tiny 和 ViT-Small 作为骨干网络，实现了线性评估中的显著性能提升。实验结果显示，该方法优于现有自监督学习基线，并突出了 EHR 增强预训练在医疗图像处理中的潜力，代码已在 GitHub 上公开。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2407.04449v1",
      "published_date": "2024-07-05 12:04:12 UTC",
      "updated_date": "2024-07-05 12:04:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:56:56.577643"
    },
    {
      "arxiv_id": "2407.11036v1",
      "title": "Hybrid-Generative Diffusion Models for Attack-Oriented Twin Migration in Vehicular Metaverses",
      "title_zh": "翻译失败",
      "authors": [
        "Yingkai Kang",
        "Jinbo Wen",
        "Jiawen Kang",
        "Tao Zhang",
        "Hongyang Du",
        "Dusit Niyato",
        "Rong Yu",
        "Shengli Xie"
      ],
      "abstract": "The vehicular metaverse is envisioned as a blended immersive domain that\npromises to bring revolutionary changes to the automotive industry. As a core\ncomponent of vehicular metaverses, Vehicle Twins (VTs) are digital twins that\ncover the entire life cycle of vehicles, providing immersive virtual services\nfor Vehicular Metaverse Users (VMUs). Vehicles with limited resources offload\nthe computationally intensive tasks of constructing and updating VTs to edge\nservers and migrate VTs between these servers, ensuring seamless and immersive\nexperiences for VMUs. However, the high mobility of vehicles, uneven deployment\nof edge servers, and potential security threats pose challenges to achieving\nefficient and reliable VT migrations. To address these issues, we propose a\nsecure and reliable VT migration framework in vehicular metaverses.\nSpecifically, we design a two-layer trust evaluation model to comprehensively\nevaluate the reputation value of edge servers in the network communication and\ninteraction layers. Then, we model the VT migration problem as a partially\nobservable Markov decision process and design a hybrid-Generative Diffusion\nModel (GDM) algorithm based on deep reinforcement learning to generate optimal\nmigration decisions by taking hybrid actions (i.e., continuous actions and\ndiscrete actions). Numerical results demonstrate that the hybrid-GDM algorithm\noutperforms the baseline algorithms, showing strong adaptability in various\nsettings and highlighting the potential of the hybrid-GDM algorithm for\naddressing various optimization issues in vehicular metaverses.",
      "tldr_zh": "该论文针对车辆元宇宙（Vehicular Metaverses）中Vehicle Twins (VTs)的迁移问题，提出一个安全可靠的框架，以应对车辆高移动性、边缘服务器不均匀部署和安全威胁的挑战。具体地，该框架包括一个两层信任评估模型来评估边缘服务器的声誉，并将VT迁移问题建模为部分可观测Markov决策过程 (POMDP)，然后使用基于深度强化学习的Hybrid-Generative Diffusion Model (GDM)算法生成最优混合动作决策。实验结果显示，hybrid-GDM算法比基线算法性能提升明显，在各种场景中表现出强适应性，并为车辆元宇宙中的优化问题提供了新潜力。",
      "categories": [
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11036v1",
      "published_date": "2024-07-05 11:11:33 UTC",
      "updated_date": "2024-07-05 11:11:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:57:11.989098"
    },
    {
      "arxiv_id": "2407.04419v1",
      "title": "The Complexity of Symmetry Breaking Beyond Lex-Leader",
      "title_zh": "翻译失败",
      "authors": [
        "Markus Anders",
        "Sofia Brenner",
        "Gaurav Rattan"
      ],
      "abstract": "Symmetry breaking is a widely popular approach to enhance solvers in\nconstraint programming, such as those for SAT or MIP. Symmetry breaking\npredicates (SBPs) typically impose an order on variables and single out the\nlexicographic leader (lex-leader) in each orbit of assignments. Although it is\nNP-hard to find complete lex-leader SBPs, incomplete lex-leader SBPs are widely\nused in practice.\n  In this paper, we investigate the complexity of computing complete SBPs,\nlex-leader or otherwise, for SAT. Our main result proves a natural barrier for\nefficiently computing SBPs: efficient certification of graph non-isomorphism.\nOur results explain the difficulty of obtaining short SBPs for important CP\nproblems, such as matrix-models with row-column symmetries and graph generation\nproblems. Our results hold even when SBPs are allowed to introduce additional\nvariables. We show polynomial upper bounds for breaking certain symmetry\ngroups, namely automorphism groups of trees and wreath products of groups with\nefficient SBPs.",
      "tldr_zh": "本论文探讨了在约束编程（如SAT）中计算完整对称性破坏谓词（SBPs）的复杂度，超越传统的lex-leader方法。研究证明，高效计算SBPs面临graph non-isomorphism有效认证的天然障碍，这解释了矩阵模型（row-column symmetries）和图生成问题中获得短SBPs的困难，即使允许引入额外变量。论文同时提供了多项式上界，用于破坏特定对称群，如树的自同构群和花环积（wreath products）群，从而为相关问题提供了可计算的解决方案。",
      "categories": [
        "cs.AI",
        "cs.CC"
      ],
      "primary_category": "cs.AI",
      "comment": "accepted to CP 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.04419v1",
      "published_date": "2024-07-05 11:09:55 UTC",
      "updated_date": "2024-07-05 11:09:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:57:35.479613"
    },
    {
      "arxiv_id": "2407.04418v2",
      "title": "Enabling On-Device LLMs Personalization with Smartphone Sensing",
      "title_zh": "利用智能手机传感实现设备端 LLMs 个性化",
      "authors": [
        "Shiquan Zhang",
        "Ying Ma",
        "Le Fang",
        "Hong Jia",
        "Simon D'Alfonso",
        "Vassilis Kostakos"
      ],
      "abstract": "This demo presents a novel end-to-end framework that combines on-device large\nlanguage models (LLMs) with smartphone sensing technologies to achieve\ncontext-aware and personalized services. The framework addresses critical\nlimitations of current personalization solutions via cloud LLMs, such as\nprivacy concerns, latency and cost, and limited personal information. To\nachieve this, we innovatively proposed deploying LLMs on smartphones with\nmultimodal sensor data through context-aware sensing and customized prompt\nengineering, ensuring privacy and enhancing personalization performance. A case\nstudy involving a university student demonstrated the capability of the\nframework to provide tailored recommendations. In addition, we show that the\nframework achieves the best trade-off in privacy, performance, latency, cost,\nbattery and energy consumption between on-device and cloud LLMs. To the best of\nour knowledge, this is the first framework to provide on-device LLMs\npersonalization with smartphone sensing. Future work will incorporate more\ndiverse sensor data and involve extensive user studies to enhance\npersonalization. Our proposed framework has the potential to substantially\nimprove user experiences across domains including healthcare, productivity, and\nentertainment.",
      "tldr_zh": "这篇论文提出了一种创新的端到端框架，将 on-device LLMs 与智能手机传感技术结合，实现上下文感知和个性化的服务，解决了云端 LLMs 的隐私问题、延迟、成本和个人信息限制。框架通过上下文感知传感和自定义提示工程处理多模态传感器数据，确保用户隐私并提升个性化性能。案例研究显示，该框架能为用户提供个性化推荐，并在隐私、性能、延迟、成本、电池和能耗方面实现最佳权衡。作为首个使用智能手机传感实现 on-device LLMs 个性化的方案，该框架有潜力应用于医疗、生产力和娱乐等领域。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "5 pages, 3 figures, conference demo paper",
      "pdf_url": "http://arxiv.org/pdf/2407.04418v2",
      "published_date": "2024-07-05 11:09:05 UTC",
      "updated_date": "2024-07-24 01:32:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:57:39.696092"
    },
    {
      "arxiv_id": "2407.04411v2",
      "title": "Waterfall: Framework for Robust and Scalable Text Watermarking and Provenance for LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Gregory Kang Ruey Lau",
        "Xinyuan Niu",
        "Hieu Dao",
        "Jiangwei Chen",
        "Chuan-Sheng Foo",
        "Bryan Kian Hsiang Low"
      ],
      "abstract": "Protecting intellectual property (IP) of text such as articles and code is\nincreasingly important, especially as sophisticated attacks become possible,\nsuch as paraphrasing by large language models (LLMs) or even unauthorized\ntraining of LLMs on copyrighted text to infringe such IP. However, existing\ntext watermarking methods are not robust enough against such attacks nor\nscalable to millions of users for practical implementation. In this paper, we\npropose Waterfall, the first training-free framework for robust and scalable\ntext watermarking applicable across multiple text types (e.g., articles, code)\nand languages supportable by LLMs, for general text and LLM data provenance.\nWaterfall comprises several key innovations, such as being the first to use LLM\nas paraphrasers for watermarking along with a novel combination of techniques\nthat are surprisingly effective in achieving robust verifiability and\nscalability. We empirically demonstrate that Waterfall achieves significantly\nbetter scalability, robust verifiability, and computational efficiency compared\nto SOTA article-text watermarking methods, and showed how it could be directly\napplied to the watermarking of code. We also demonstrated that Waterfall can be\nused for LLM data provenance, where the watermarks of LLM training data can be\ndetected in LLM output, allowing for detection of unauthorized use of data for\nLLM training and potentially enabling model-centric watermarking of\nopen-sourced LLMs which has been a limitation of existing LLM watermarking\nworks. Our code is available at https://github.com/aoi3142/Waterfall.",
      "tldr_zh": "该研究提出Waterfall，一种无需训练的框架，用于LLMs的鲁棒且可扩展文本水印和数据来源证明，旨在应对如LLMs改写或未经授权训练等攻击。Waterfall创新性地使用LLMs作为改写器，并结合新颖技术，实现对多种文本类型（如文章和代码）的鲁棒可验证性，同时显著提升可扩展性和计算效率。实验结果显示，Waterfall在鲁棒性和性能上优于SOTA方法，并可用于检测LLM输出中的训练数据水印，从而帮助识别知识产权侵权。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted to EMNLP 2024 Main Conference",
      "pdf_url": "http://arxiv.org/pdf/2407.04411v2",
      "published_date": "2024-07-05 10:51:33 UTC",
      "updated_date": "2024-10-29 07:02:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:57:48.723951"
    },
    {
      "arxiv_id": "2407.04405v3",
      "title": "Discovering physical laws with parallel combinatorial tree search",
      "title_zh": "利用并行组合树搜索发现物理定律",
      "authors": [
        "Kai Ruan",
        "Yilong Xu",
        "Ze-Feng Gao",
        "Yike Guo",
        "Hao Sun",
        "Ji-Rong Wen",
        "Yang Liu"
      ],
      "abstract": "Symbolic regression plays a crucial role in modern scientific research thanks\nto its capability of discovering concise and interpretable mathematical\nexpressions from data. A grand challenge lies in the arduous search for\nparsimonious and generalizable mathematical formulas, in an infinite search\nspace, while intending to fit the training data. Existing algorithms have faced\na critical bottleneck of accuracy and efficiency over a decade when handling\nproblems of complexity, which essentially hinders the pace of applying symbolic\nregression for scientific exploration across interdisciplinary domains. To this\nend, we introduce a parallel combinatorial tree search (PCTS) model to\nefficiently distill generic mathematical expressions from limited data. Through\na series of extensive experiments, we demonstrate the superior accuracy and\nefficiency of PCTS for equation discovery, which greatly outperforms the\nstate-of-the-art baseline models on over 200 synthetic and experimental\ndatasets (e.g., lifting its performance by up to 99% accuracy improvement and\none-order of magnitude speed up). PCTS represents a key advance in accurate and\nefficient data-driven discovery of symbolic, interpretable models (e.g.,\nunderlying physical laws) and marks a pivotal transition towards scalable\nsymbolic learning.",
      "tldr_zh": "这篇论文介绍了平行组合树搜索（Parallel Combinatorial Tree Search, PCTS）模型，用于符号回归（Symbolic regression），旨在从有限数据中高效发现简洁、可解释的数学表达式，从而解决在大搜索空间中寻找泛化公式的挑战。PCTS 通过平行搜索机制显著提升了算法的准确性和效率，超越了现有方法的瓶颈。实验结果显示，在超过 200 个合成和实验数据集上，PCTS 比最先进基线模型提高了高达 99% 的准确率，并实现了约一个数量级的速度提升。该方法标志着数据驱动符号学习的关键进步，促进了跨学科科学探索中物理定律等可解释模型的发现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.04405v3",
      "published_date": "2024-07-05 10:41:15 UTC",
      "updated_date": "2025-03-03 03:39:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:58:01.572958"
    },
    {
      "arxiv_id": "2407.04396v2",
      "title": "Graph-Guided Test-Time Adaptation for Glaucoma Diagnosis using Fundus Photography",
      "title_zh": "翻译失败",
      "authors": [
        "Qian Zeng",
        "Le Zhang",
        "Yipeng Liu",
        "Ce Zhu",
        "Fan Zhang"
      ],
      "abstract": "Glaucoma is a leading cause of irreversible blindness worldwide. While deep\nlearning approaches using fundus images have largely improved early diagnosis\nof glaucoma, variations in images from different devices and locations (known\nas domain shifts) challenge the use of pre-trained models in real-world\nsettings. To address this, we propose a novel Graph-guided Test-Time Adaptation\n(GTTA) framework to generalize glaucoma diagnosis models to unseen test\nenvironments. GTTA integrates the topological information of fundus images into\nthe model training, enhancing the model's transferability and reducing the risk\nof learning spurious correlation. During inference, GTTA introduces a novel\ntest-time training objective to make the source-trained classifier\nprogressively adapt to target patterns with reliable class conditional\nestimation and consistency regularization. Experiments on cross-domain glaucoma\ndiagnosis benchmarks demonstrate the superiority of the overall framework and\nindividual components under different backbone networks.",
      "tldr_zh": "论文针对青光眼诊断中的领域偏移问题（如不同设备和位置的眼底图像差异），提出了一种 Graph-Guided Test-Time Adaptation (GTTA) 框架，以提升预训练模型在实际环境中的泛化能力。GTTA 通过整合眼底图像的拓扑信息到模型训练中，减少学习虚假相关性的风险，并在推理阶段引入测试时训练目标，利用可靠的类条件估计和一致性正则化，使分类器逐步适应目标模式。实验结果显示，该框架在跨领域青光眼诊断基准上显著优于基线模型，在不同骨干网络下表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages, 3 figures, 3 tables, submitted to MICCAI",
      "pdf_url": "http://arxiv.org/pdf/2407.04396v2",
      "published_date": "2024-07-05 10:06:55 UTC",
      "updated_date": "2024-07-10 03:54:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:58:13.810910"
    },
    {
      "arxiv_id": "2407.04381v1",
      "title": "Multi-Branch Auxiliary Fusion YOLO with Re-parameterization Heterogeneous Convolutional for accurate object detection",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiqiang Yang",
        "Qiu Guan",
        "Keer Zhao",
        "Jianmin Yang",
        "Xinli Xu",
        "Haixia Long",
        "Ying Tang"
      ],
      "abstract": "Due to the effective performance of multi-scale feature fusion, Path\nAggregation FPN (PAFPN) is widely employed in YOLO detectors. However, it\ncannot efficiently and adaptively integrate high-level semantic information\nwith low-level spatial information simultaneously. We propose a new model named\nMAF-YOLO in this paper, which is a novel object detection framework with a\nversatile neck named Multi-Branch Auxiliary FPN (MAFPN). Within MAFPN, the\nSuperficial Assisted Fusion (SAF) module is designed to combine the output of\nthe backbone with the neck, preserving an optimal level of shallow information\nto facilitate subsequent learning. Meanwhile, the Advanced Assisted Fusion\n(AAF) module deeply embedded within the neck conveys a more diverse range of\ngradient information to the output layer.\n  Furthermore, our proposed Re-parameterized Heterogeneous Efficient Layer\nAggregation Network (RepHELAN) module ensures that both the overall model\narchitecture and convolutional design embrace the utilization of heterogeneous\nlarge convolution kernels. Therefore, this guarantees the preservation of\ninformation related to small targets while simultaneously achieving the\nmulti-scale receptive field. Finally, taking the nano version of MAF-YOLO for\nexample, it can achieve 42.4% AP on COCO with only 3.76M learnable parameters\nand 10.51G FLOPs, and approximately outperforms YOLOv8n by about 5.1%. The\nsource code of this work is available at:\nhttps://github.com/yang-0201/MAF-YOLO.",
      "tldr_zh": "这篇论文针对 YOLO 检测器中 Path Aggregation FPN (PAFPN) 无法高效整合高层次语义和低层次空间信息的不足，提出了一种新型对象检测框架 Multi-Branch Auxiliary Fusion YOLO (MAF-YOLO)。MAF-YOLO 引入 Multi-Branch Auxiliary FPN (MAFPN)，其中 Superficial Assisted Fusion (SAF) 模块保留浅层信息融合骨干网络输出，而 Advanced Assisted Fusion (AAF) 模块提供更多梯度信息以增强特征多样性。同时，Re-parameterized Heterogeneous Efficient Layer Aggregation Network (RepHELAN) 模块采用异构大卷积核，确保小目标信息保留并实现多尺度感受野。实验结果显示，MAF-YOLO 的 nano 版本在 COCO 数据集上达到 42.4% AP，仅需 3.76M 参数和 10.51G FLOPs，比 YOLOv8n 提高了约 5.1%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.04381v1",
      "published_date": "2024-07-05 09:35:30 UTC",
      "updated_date": "2024-07-05 09:35:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:58:27.252596"
    },
    {
      "arxiv_id": "2407.04377v1",
      "title": "A systematic review on expert systems for improving energy efficiency in the manufacturing industry",
      "title_zh": "专家系统用于提高制造业能源效率的系统综述",
      "authors": [
        "Borys Ioshchikhes",
        "Michael Frank",
        "Matthias Weigold"
      ],
      "abstract": "Against the backdrop of the European Union's commitment to achieve climate\nneutrality by 2050, efforts to improve energy efficiency are being intensified.\nThe manufacturing industry is a key focal point of these endeavors due to its\nhigh final electrical energy demand, while simultaneously facing a growing\nshortage of skilled workers crucial for meeting established goals. Expert\nsystems (ESs) offer the chance to overcome this challenge by automatically\nidentifying potential energy efficiency improvements and thereby playing a\nsignificant role in reducing electricity consumption. This paper systematically\nreviews state-of-the-art approaches of ESs aimed at improving energy efficiency\nin industry, with a focus on manufacturing. The literature search yields 1692\nresults, of which 54 articles published between 1987 and 2023 are analyzed in\ndepth. These publications are classified according to the system boundary,\nmanufacturing type, application perspective, application purpose, ES type, and\nindustry. Furthermore, we examine the structure, implementation, utilization,\nand development of ESs in this context. Through this analysis, the review\nreveals research gaps, pointing toward promising topics for future research.",
      "tldr_zh": "这篇论文系统综述了专家系统(ESs)在制造业能源效率改进中的应用，背景是欧盟到2050年实现气候中性的目标，以及制造业面临的能源消耗高和熟练工人短缺的挑战。研究通过文献搜索筛选出1987-2023年间54篇相关文章，并按系统边界、制造类型、应用视角、应用目的、ES类型和行业进行分类分析，考察了ESs的结构、实施、利用和发展。综述揭示了现有研究中的空白，并指出了未来研究的有前景主题，如进一步优化ESs以自动识别能源节约潜力。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "23 pages, 7 figures, journal",
      "pdf_url": "http://arxiv.org/pdf/2407.04377v1",
      "published_date": "2024-07-05 09:28:31 UTC",
      "updated_date": "2024-07-05 09:28:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:58:35.986731"
    },
    {
      "arxiv_id": "2407.12847v1",
      "title": "Aligning Model Evaluations with Human Preferences: Mitigating Token Count Bias in Language Model Assessments",
      "title_zh": "翻译失败",
      "authors": [
        "Roland Daynauth",
        "Jason Mars"
      ],
      "abstract": "The SLAM paper demonstrated that on-device Small Language Models (SLMs) are a\nviable and cost-effective alternative to API-based Large Language Models\n(LLMs), such as OpenAI's GPT-4, offering comparable performance and stability.\nHowever, SLAM also identified discrepancies between human preferences and\ntraditional auto-evaluators. This follow-up paper explores methods to align LLM\nevaluator preferences with human evaluations by addressing biases, particularly\ntoward higher token counts. We employed Bayesian statistics and a t-test to\nquantify this bias and developed a recalibration procedure to adjust the\nGPTScorer. Our findings significantly improve aligning the recalibrated LLM\nevaluator with human evaluations across multiple use cases. For instance,\nspearman's ranking correlation score in the Recommendation use case improved\nfrom -27.27 to 44.55. These results highlight the importance of accounting for\nbiases in automated evaluations to ensure fair and accurate model assessments.\nThe recalibration process enhances the reliability of automated evaluators,\nleading to better AI models that align with human values and expectations. This\nstudy provides a robust methodology for future research into bias correction\nand emphasizes the feasibility and benefits of developing human-aligned AI\nevaluation systems.",
      "tldr_zh": "这篇论文探讨了如何使语言模型评估与人类偏好对齐，特别针对 Small Language Models (SLMs) 与 Large Language Models (LLMs) 如 GPT-4 的评估偏差，焦点在于缓解对 token 数量的偏见。作者使用 Bayesian statistics 和 t-test 量化了这种偏见，并开发了重新校准过程来调整 GPTScorer。实验结果显示，该方法显著提升了评估器的可靠性，例如在 Recommendation 用例中，Spearman's ranking correlation score 从 -27.27 提高到 44.55。总体上，这为未来偏见修正研究提供了稳健方法，确保 AI 模型评估更公平、准确，并更好地符合人类价值观。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.12847v1",
      "published_date": "2024-07-05 09:26:40 UTC",
      "updated_date": "2024-07-05 09:26:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:58:51.329017"
    },
    {
      "arxiv_id": "2407.04371v1",
      "title": "Exploiting the equivalence between quantum neural networks and perceptrons",
      "title_zh": "利用量子神经网络与感知器之间的等价性",
      "authors": [
        "Chris Mingard",
        "Jessica Pointing",
        "Charles London",
        "Yoonsoo Nam",
        "Ard A. Louis"
      ],
      "abstract": "Quantum machine learning models based on parametrized quantum circuits, also\ncalled quantum neural networks (QNNs), are considered to be among the most\npromising candidates for applications on near-term quantum devices. Here we\nexplore the expressivity and inductive bias of QNNs by exploiting an exact\nmapping from QNNs with inputs $x$ to classical perceptrons acting on $x \\otimes\nx$ (generalised to complex inputs). The simplicity of the perceptron\narchitecture allows us to provide clear examples of the shortcomings of current\nQNN models, and the many barriers they face to becoming useful general-purpose\nlearning algorithms. For example, a QNN with amplitude encoding cannot express\nthe Boolean parity function for $n\\geq 3$, which is but one of an exponential\nnumber of data structures that such a QNN is unable to express. Mapping a QNN\nto a classical perceptron simplifies training, allowing us to systematically\nstudy the inductive biases of other, more expressive embeddings on Boolean\ndata. Several popular embeddings primarily produce an inductive bias towards\nfunctions with low class balance, reducing their generalisation performance\ncompared to deep neural network architectures which exhibit much richer\ninductive biases. We explore two alternate strategies that move beyond standard\nQNNs. In the first, we use a QNN to help generate a classical DNN-inspired\nkernel. In the second we draw an analogy to the hierarchical structure of deep\nneural networks and construct a layered non-linear QNN that is provably fully\nexpressive on Boolean data, while also exhibiting a richer inductive bias than\nsimple QNNs. Finally, we discuss characteristics of the QNN literature that may\nobscure how hard it is to achieve quantum advantage over deep learning\nalgorithms on classical data.",
      "tldr_zh": "本文利用量子神经网络(QNNs)与经典感知器(perceptrons)的精确映射，探讨了QNNs的表达性和归纳偏差(inductive bias)，揭示了现有QNNs在处理某些函数如Boolean parity function for n ≥ 3时的局限性。研究发现，流行嵌入方式往往偏向低类平衡函数，导致泛化性能不如深度神经网络(DNNs)。为了改进，论文提出两种策略：一是用QNN生成经典DNN-inspired kernel，二是构建分层非线性QNN，实现对Boolean数据的完全表达性和更丰富的归纳偏差。最后，讨论了QNN文献中可能掩盖量子优势难度的特征。",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.04371v1",
      "published_date": "2024-07-05 09:19:58 UTC",
      "updated_date": "2024-07-05 09:19:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:59:01.468842"
    },
    {
      "arxiv_id": "2407.04370v2",
      "title": "Regulating Model Reliance on Non-Robust Features by Smoothing Input Marginal Density",
      "title_zh": "通过平滑输入边缘密度调控模型对非鲁棒特征的依赖",
      "authors": [
        "Peiyu Yang",
        "Naveed Akhtar",
        "Mubarak Shah",
        "Ajmal Mian"
      ],
      "abstract": "Trustworthy machine learning necessitates meticulous regulation of model\nreliance on non-robust features. We propose a framework to delineate and\nregulate such features by attributing model predictions to the input. Within\nour approach, robust feature attributions exhibit a certain consistency, while\nnon-robust feature attributions are susceptible to fluctuations. This behavior\nallows identification of correlation between model reliance on non-robust\nfeatures and smoothness of marginal density of the input samples. Hence, we\nuniquely regularize the gradients of the marginal density w.r.t. the input\nfeatures for robustness. We also devise an efficient implementation of our\nregularization to address the potential numerical instability of the underlying\noptimization process. Moreover, we analytically reveal that, as opposed to our\nmarginal density smoothing, the prevalent input gradient regularization\nsmoothens conditional or joint density of the input, which can cause limited\nrobustness. Our experiments validate the effectiveness of the proposed method,\nproviding clear evidence of its capability to address the feature leakage\nproblem and mitigate spurious correlations. Extensive results further establish\nthat our technique enables the model to exhibit robustness against\nperturbations in pixel values, input gradients, and density.",
      "tldr_zh": "该论文提出一种框架，通过平滑输入边际密度（input marginal density）来调节机器学习模型对非鲁棒特征（non-robust features）的依赖，从而提升模型的可信度。方法涉及将模型预测归因于输入，识别鲁棒特征的稳定性与非鲁棒特征的波动性，并通过正则化边际密度梯度来缓解这种依赖，同时设计高效实现以避免优化过程中的数值不稳定性。实验结果显示，该方法有效解决了特征泄漏（feature leakage）问题、减轻了虚假相关性，并使模型对像素值、输入梯度和密度的扰动表现出更强的鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.04370v2",
      "published_date": "2024-07-05 09:16:56 UTC",
      "updated_date": "2024-07-09 03:09:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:59:13.377928"
    },
    {
      "arxiv_id": "2407.04363v3",
      "title": "AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Petr Anokhin",
        "Nikita Semenov",
        "Artyom Sorokin",
        "Dmitry Evseev",
        "Andrey Kravchenko",
        "Mikhail Burtsev",
        "Evgeny Burnaev"
      ],
      "abstract": "Advancements in the capabilities of Large Language Models (LLMs) have created\na promising foundation for developing autonomous agents. With the right tools,\nthese agents could learn to solve tasks in new environments by accumulating and\nupdating their knowledge. Current LLM-based agents process past experiences\nusing a full history of observations, summarization, retrieval augmentation.\nHowever, these unstructured memory representations do not facilitate the\nreasoning and planning essential for complex decision-making. In our study, we\nintroduce AriGraph, a novel method wherein the agent constructs and updates a\nmemory graph that integrates semantic and episodic memories while exploring the\nenvironment. We demonstrate that our Ariadne LLM agent, consisting of the\nproposed memory architecture augmented with planning and decision-making,\neffectively handles complex tasks within interactive text game environments\ndifficult even for human players. Results show that our approach markedly\noutperforms other established memory methods and strong RL baselines in a range\nof problems of varying complexity. Additionally, AriGraph demonstrates\ncompetitive performance compared to dedicated knowledge graph-based methods in\nstatic multi-hop question-answering.",
      "tldr_zh": "该研究提出 AriGraph，一种创新方法，让 Large Language Models (LLMs) 代理通过构建和更新知识图世界模型来整合语义和 episodic memory，从而提升代理在动态环境中的推理和规划能力。AriGraph 允许代理在交互式文本游戏环境中积累经验、处理复杂任务，并显著优于现有记忆方法和 RL baselines。实验结果表明，该方法在各种复杂问题上表现出色，并在静态 multi-hop question-answering 任务中与专用知识图方法竞争。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Code for this work is avaliable at\n  https://github.com/AIRI-Institute/AriGraph",
      "pdf_url": "http://arxiv.org/pdf/2407.04363v3",
      "published_date": "2024-07-05 09:06:47 UTC",
      "updated_date": "2025-05-15 10:57:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:59:26.752126"
    },
    {
      "arxiv_id": "2407.04359v1",
      "title": "Dance of the ADS: Orchestrating Failures through Historically-Informed Scenario Fuzzing",
      "title_zh": "ADS 的舞蹈：通过基于历史的场景",
      "authors": [
        "Tong Wang",
        "Taotao Gu",
        "Huan Deng",
        "Hu Li",
        "Xiaohui Kuang",
        "Gang Zhao"
      ],
      "abstract": "As autonomous driving systems (ADS) advance towards higher levels of\nautonomy, orchestrating their safety verification becomes increasingly\nintricate. This paper unveils ScenarioFuzz, a pioneering scenario-based fuzz\ntesting methodology. Designed like a choreographer who understands the past\nperformances, it uncovers vulnerabilities in ADS without the crutch of\npredefined scenarios. Leveraging map road networks, such as OPENDRIVE, we\nextract essential data to form a foundational scenario seed corpus. This\ncorpus, enriched with pertinent information, provides the necessary boundaries\nfor fuzz testing in the absence of starting scenarios. Our approach integrates\nspecialized mutators and mutation techniques, combined with a graph neural\nnetwork model, to predict and filter out high-risk scenario seeds, optimizing\nthe fuzzing process using historical test data. Compared to other methods, our\napproach reduces the time cost by an average of 60.3%, while the number of\nerror scenarios discovered per unit of time increases by 103%. Furthermore, we\npropose a self-supervised collision trajectory clustering method, which aids in\nidentifying and summarizing 54 high-risk scenario categories prone to inducing\nADS faults. Our experiments have successfully uncovered 58 bugs across six\ntested systems, emphasizing the critical safety concerns of ADS.",
      "tldr_zh": "本研究提出ScenarioFuzz，一种基于历史的场景模糊测试（fuzz testing）方法，用于提升自主驾驶系统（ADS）的安全验证。该方法利用地图路网（如OPENDRIVE）提取数据构建初始场景种子库，并结合专用变异器（mutators）、变异技术以及图神经网络（graph neural network）模型，通过历史测试数据预测和过滤高风险场景，从而优化测试过程。与其他方法相比，ScenarioFuzz平均减少时间成本60.3%，并将单位时间内发现的错误场景数量提高103%。此外，该方法引入自监督碰撞轨迹聚类，识别出54个易引发ADS故障的高风险场景类别，并在实验中成功发现六个系统中的58个bugs，强调了ADS安全性的关键问题。",
      "categories": [
        "cs.AI",
        "cs.NE",
        "cs.SE",
        "68Txx (Primary)",
        "D.2.4; I.2.9; I.6.7"
      ],
      "primary_category": "cs.AI",
      "comment": "This paper was accepted by 33rd ACM SIGSOFT International Symposium\n  on Software Testing and Analysis (ISSTA 2024)",
      "pdf_url": "http://arxiv.org/pdf/2407.04359v1",
      "published_date": "2024-07-05 08:58:09 UTC",
      "updated_date": "2024-07-05 08:58:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:59:38.102870"
    },
    {
      "arxiv_id": "2407.04336v2",
      "title": "AI-Driven Mobility Management for High-Speed Railway Communications: Compressed Measurements and Proactive Handover",
      "title_zh": "翻译失败",
      "authors": [
        "Wen Li",
        "Wei Chen",
        "Shiyue Wang",
        "Yuanyuan Zhang",
        "Michail Matthaiou",
        "Bo Ai"
      ],
      "abstract": "High-speed railway (HSR) communications are pivotal for ensuring rail safety,\noperations, maintenance, and delivering passenger information services. The\nhigh speed of trains creates rapidly time-varying wireless channels, increases\nthe signaling overhead, and reduces the system throughput, making it difficult\nto meet the growing and stringent needs of HSR applications. In this article,\nwe explore artificial intelligence (AI)-based beam-level and cell-level\nmobility management suitable for HSR communications. Particularly, we propose a\ncompressed spatial multi-beam measurements scheme via compressive sensing for\nbeam-level mobility management in HSR communications. In comparison to\ntraditional down-sampling spatial beam measurements, this method leads to\nimproved spatial-temporal beam prediction accuracy with the same measurement\noverhead. Moreover, we propose a novel AI-based proactive handover scheme to\npredict handover events and reduce radio link failure (RLF) rates in HSR\ncommunications. Compared with the traditional event A3-based handover\nmechanism, the proposed approach significantly reduces the RLF rates which\nsaves 50% beam measurement overhead.",
      "tldr_zh": "该研究针对高铁通信（HSR communications）面临的挑战，如高速列车导致的无线通道快速变化、信令开销增加和系统吞吐量降低，提出了一种AI驱动的移动管理方案。论文引入了基于压缩感知（compressive sensing）的压缩空间多波束测量方法，用于波束级（beam-level）移动管理，提高了空间-时间波束预测准确性，同时保持相同的测量开销。此外，该方案还开发了AI-based proactive handover机制，能够预测切换事件并显著降低无线链路失败（RLF）率，与传统事件A3-based handover相比，节省了50%的波束测量开销。总体而言，此方法为高铁通信的安全性和效率提供了可靠的解决方案。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.04336v2",
      "published_date": "2024-07-05 08:23:13 UTC",
      "updated_date": "2024-12-19 05:40:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T03:59:50.465247"
    },
    {
      "arxiv_id": "2407.04335v1",
      "title": "Geometrically Inspired Kernel Machines for Collaborative Learning Beyond Gradient Descent",
      "title_zh": "翻译失败",
      "authors": [
        "Mohit Kumar",
        "Alexander Valentinitsch",
        "Magdalena Fuchs",
        "Mathias Brucker",
        "Juliana Bowles",
        "Adnan Husakovic",
        "Ali Abbas",
        "Bernhard A. Moser"
      ],
      "abstract": "This paper develops a novel mathematical framework for collaborative learning\nby means of geometrically inspired kernel machines which includes statements on\nthe bounds of generalisation and approximation errors, and sample complexity.\nFor classification problems, this approach allows us to learn bounded geometric\nstructures around given data points and hence solve the global model learning\nproblem in an efficient way by exploiting convexity properties of the related\noptimisation problem in a Reproducing Kernel Hilbert Space (RKHS). In this way,\nwe can reduce classification problems to determining the closest bounded\ngeometric structure from a given data point. Further advantages that come with\nour solution is that our approach does not require clients to perform multiple\nepochs of local optimisation using stochastic gradient descent, nor require\nrounds of communication between client/server for optimising the global model.\nWe highlight that numerous experiments have shown that the proposed method is a\ncompetitive alternative to the state-of-the-art.",
      "tldr_zh": "这篇论文提出了一种基于几何启发的核机器（kernel machines）框架，用于超越梯度下降的协作学习，该框架包括泛化误差、逼近误差和样本复杂度的界定，并通过在再现核希尔伯特空间（RKHS）中利用凸优化性质，高效学习数据点周围的有界几何结构。相比传统方法，该方法将分类问题简化为确定给定数据点最近的几何结构，从而避免了客户端进行多次随机梯度下降（stochastic gradient descent）优化和客户端/服务器通信轮次。实验结果显示，该方法是与最先进技术的竞争性替代方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.04335v1",
      "published_date": "2024-07-05 08:20:27 UTC",
      "updated_date": "2024-07-05 08:20:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:00:05.246623"
    },
    {
      "arxiv_id": "2407.04751v2",
      "title": "A Unified Learn-to-Distort-Data Framework for Privacy-Utility Trade-off in Trustworthy Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaojin Zhang",
        "Mingcong Xu",
        "Wei Chen"
      ],
      "abstract": "In this paper, we first give an introduction to the theoretical basis of the\nprivacy-utility equilibrium in federated learning based on Bayesian privacy\ndefinitions and total variation distance privacy definitions. We then present\nthe \\textit{Learn-to-Distort-Data} framework, which provides a principled\napproach to navigate the privacy-utility equilibrium by explicitly modeling the\ndistortion introduced by the privacy-preserving mechanism as a learnable\nvariable and optimizing it jointly with the model parameters. We demonstrate\nthe applicability of our framework to a variety of privacy-preserving\nmechanisms on the basis of data distortion and highlight its connections to\nrelated areas such as adversarial training, input robustness, and unlearnable\nexamples. These connections enable leveraging techniques from these areas to\ndesign effective algorithms for privacy-utility equilibrium in federated\nlearning under the \\textit{Learn-to-Distort-Data} framework.",
      "tldr_zh": "这篇论文首先探讨了联邦学习(Federated Learning)中隐私-实用性平衡的理论基础，基于Bayesian隐私定义和total variation distance隐私定义。作者提出了Learn-to-Distort-Data框架，通过将隐私保护机制引入的数据扭曲建模为可学习的变量，并与模型参数联合优化，实现对隐私-实用性权衡的系统性导航。该框架适用于多种基于数据扭曲的隐私机制，并与对抗训练(adversarial training)、输入鲁棒性和不可学习示例(unlearnable examples)等相关领域建立联系，从而设计出有效的算法，提升联邦学习的可靠性和隐私保护。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.04751v2",
      "published_date": "2024-07-05 08:15:09 UTC",
      "updated_date": "2024-07-09 16:11:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:00:14.750138"
    },
    {
      "arxiv_id": "2407.04331v1",
      "title": "MuseBarControl: Enhancing Fine-Grained Control in Symbolic Music Generation through Pre-Training and Counterfactual Loss",
      "title_zh": "MuseBarControl：通过预训练和反事实损失增强符号化音乐生成中的细粒度控制",
      "authors": [
        "Yangyang Shu",
        "Haiming Xu",
        "Ziqin Zhou",
        "Anton van den Hengel",
        "Lingqiao Liu"
      ],
      "abstract": "Automatically generating symbolic music-music scores tailored to specific\nhuman needs-can be highly beneficial for musicians and enthusiasts. Recent\nstudies have shown promising results using extensive datasets and advanced\ntransformer architectures. However, these state-of-the-art models generally\noffer only basic control over aspects like tempo and style for the entire\ncomposition, lacking the ability to manage finer details, such as control at\nthe level of individual bars. While fine-tuning a pre-trained symbolic music\ngeneration model might seem like a straightforward method for achieving this\nfiner control, our research indicates challenges in this approach. The model\noften fails to respond adequately to new, fine-grained bar-level control\nsignals. To address this, we propose two innovative solutions. First, we\nintroduce a pre-training task designed to link control signals directly with\ncorresponding musical tokens, which helps in achieving a more effective\ninitialization for subsequent fine-tuning. Second, we implement a novel\ncounterfactual loss that promotes better alignment between the generated music\nand the control prompts. Together, these techniques significantly enhance our\nability to control music generation at the bar level, showing a 13.06\\%\nimprovement over conventional methods. Our subjective evaluations also confirm\nthat this enhanced control does not compromise the musical quality of the\noriginal pre-trained generative model.",
      "tldr_zh": "本研究旨在提升符号音乐生成（Symbolic Music Generation）的细粒度控制，特别是针对单个小节的控制，解决现有模型仅提供整体层面（如tempo和style）控制的局限性。\n\n为了克服直接微调预训练模型的挑战，论文提出两种创新方法：一个预训练任务，将控制信号直接链接到对应的音乐标记（musical tokens）以优化初始模型；以及一个Counterfactual Loss，用于促进生成音乐与控制提示的更好对齐。\n\n实验结果显示，该方法在小节级别控制上比传统方法提高了13.06%，主观评估还确认了音乐质量的保持。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Demo is available at:\n  https://ganperf.github.io/musebarcontrol.github.io/musebarcontrol/",
      "pdf_url": "http://arxiv.org/pdf/2407.04331v1",
      "published_date": "2024-07-05 08:08:22 UTC",
      "updated_date": "2024-07-05 08:08:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:00:26.391176"
    },
    {
      "arxiv_id": "2407.04317v2",
      "title": "Knowledge-based Drug Samples' Comparison",
      "title_zh": "翻译失败",
      "authors": [
        "Sébastien Guillemin",
        "Ana Roxin",
        "Laurence Dujourdy",
        "Ludovic Journaux"
      ],
      "abstract": "Drug sample comparison is a process used by the French National police to\nidentify drug distribution networks. The current approach is based on manual\ncomparison done by forensic experts. In this article, we present our approach\nto acquire, formalise, and specify expert knowledge to improve the current\nprocess. For modelling the underlying knowledge we use an ontology coupled with\nlogical rules. The different steps of our approach are designed to be reused in\nother application domains. The results obtained are explainable making them\nusable by experts in different fields.",
      "tldr_zh": "该论文探讨了法国国家警察用于识别毒品分销网络的药物样本比较过程，目前依赖于法医专家的手动方法。研究提出了一种基于知识的方法，通过获取、正式化和指定专家知识，使用ontology和logical rules来建模知识，从而改进该过程。这种方法设计为可重用于其他应用领域，并产生可解释的结果，便于专家在不同领域应用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "17th International Conference on Signal Image Technology & Internet\n  based Systems (SITIS), Nov 2023, Bangkok, Thailand",
      "pdf_url": "http://arxiv.org/pdf/2407.04317v2",
      "published_date": "2024-07-05 07:40:25 UTC",
      "updated_date": "2024-07-16 07:16:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:00:36.770958"
    },
    {
      "arxiv_id": "2407.04295v2",
      "title": "Jailbreak Attacks and Defenses Against Large Language Models: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Sibo Yi",
        "Yule Liu",
        "Zhen Sun",
        "Tianshuo Cong",
        "Xinlei He",
        "Jiaxing Song",
        "Ke Xu",
        "Qi Li"
      ],
      "abstract": "Large Language Models (LLMs) have performed exceptionally in various\ntext-generative tasks, including question answering, translation, code\ncompletion, etc. However, the over-assistance of LLMs has raised the challenge\nof \"jailbreaking\", which induces the model to generate malicious responses\nagainst the usage policy and society by designing adversarial prompts. With the\nemergence of jailbreak attack methods exploiting different vulnerabilities in\nLLMs, the corresponding safety alignment measures are also evolving. In this\npaper, we propose a comprehensive and detailed taxonomy of jailbreak attack and\ndefense methods. For instance, the attack methods are divided into black-box\nand white-box attacks based on the transparency of the target model. Meanwhile,\nwe classify defense methods into prompt-level and model-level defenses.\nAdditionally, we further subdivide these attack and defense methods into\ndistinct sub-classes and present a coherent diagram illustrating their\nrelationships. We also conduct an investigation into the current evaluation\nmethods and compare them from different perspectives. Our findings aim to\ninspire future research and practical implementations in safeguarding LLMs\nagainst adversarial attacks. Above all, although jailbreak remains a\nsignificant concern within the community, we believe that our work enhances the\nunderstanding of this domain and provides a foundation for developing more\nsecure LLMs.",
      "tldr_zh": "本调查论文对针对大型语言模型(LLMs)的越狱攻击(jailbreak attacks)和防御方法进行了全面综述，分类了攻击方法为黑盒(black-box)和白盒(white-box)攻击，并将防御方法分为提示级(prompt-level)和模型级(model-level)防御，同时进一步细分子类并通过关系图展示它们之间的联系。论文还评估了当前评估方法，从不同角度进行比较，以揭示这些方法的优缺点。总体而言，该工作旨在提升对LLMs安全漏洞的理解，并为开发更有效的防御策略和更安全的模型提供基础。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.04295v2",
      "published_date": "2024-07-05 06:57:30 UTC",
      "updated_date": "2024-08-30 11:57:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:00:50.694224"
    },
    {
      "arxiv_id": "2407.04287v1",
      "title": "MARS: Paying more attention to visual attributes for text-based person search",
      "title_zh": "MARS：针对基于文本的人搜索更注重视觉属性",
      "authors": [
        "Alex Ergasti",
        "Tomaso Fontanini",
        "Claudio Ferrari",
        "Massimo Bertozzi",
        "Andrea Prati"
      ],
      "abstract": "Text-based person search (TBPS) is a problem that gained significant interest\nwithin the research community. The task is that of retrieving one or more\nimages of a specific individual based on a textual description. The multi-modal\nnature of the task requires learning representations that bridge text and image\ndata within a shared latent space. Existing TBPS systems face two major\nchallenges. One is defined as inter-identity noise that is due to the inherent\nvagueness and imprecision of text descriptions and it indicates how\ndescriptions of visual attributes can be generally associated to different\npeople; the other is the intra-identity variations, which are all those\nnuisances e.g. pose, illumination, that can alter the visual appearance of the\nsame textual attributes for a given subject. To address these issues, this\npaper presents a novel TBPS architecture named MARS\n(Mae-Attribute-Relation-Sensitive), which enhances current state-of-the-art\nmodels by introducing two key components: a Visual Reconstruction Loss and an\nAttribute Loss. The former employs a Masked AutoEncoder trained to reconstruct\nrandomly masked image patches with the aid of the textual description. In doing\nso the model is encouraged to learn more expressive representations and\ntextual-visual relations in the latent space. The Attribute Loss, instead,\nbalances the contribution of different types of attributes, defined as\nadjective-noun chunks of text. This loss ensures that every attribute is taken\ninto consideration in the person retrieval process. Extensive experiments on\nthree commonly used datasets, namely CUHK-PEDES, ICFG-PEDES, and RSTPReid,\nreport performance improvements, with significant gains in the mean Average\nPrecision (mAP) metric w.r.t. the current state of the art.",
      "tldr_zh": "本研究针对文本-based person search (TBPS) 的挑战，包括 inter-identity noise（文本描述的模糊性）和 intra-identity variations（同一主体的视觉变化），提出了一种新型架构 MARS (Mae-Attribute-Relation-Sensitive)。MARS 通过引入 Visual Reconstruction Loss 和 Attribute Loss 两个关键组件，前者利用 Masked AutoEncoder 结合文本描述重建图像 patch，以学习更具表现力的文本-视觉关系；后者平衡不同属性（如形容词-名词短语）的贡献，确保在检索过程中全面考虑每个属性。在 CUHK-PEDES、ICFG-PEDES 和 RSTPReid 数据集上的实验显示，MARS 在 mean Average Precision (mAP) 指标上相对于现有最先进模型实现了显著提升。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.04287v1",
      "published_date": "2024-07-05 06:44:43 UTC",
      "updated_date": "2024-07-05 06:44:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:01:12.403982"
    },
    {
      "arxiv_id": "2407.04285v4",
      "title": "Tackling Data Corruption in Offline Reinforcement Learning via Sequence Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Jiawei Xu",
        "Rui Yang",
        "Shuang Qiu",
        "Feng Luo",
        "Meng Fang",
        "Baoxiang Wang",
        "Lei Han"
      ],
      "abstract": "Learning policy from offline datasets through offline reinforcement learning\n(RL) holds promise for scaling data-driven decision-making while avoiding\nunsafe and costly online interactions. However, real-world data collected from\nsensors or humans often contains noise and errors, posing a significant\nchallenge for existing offline RL methods, particularly when the real-world\ndata is limited. Our study reveals that prior research focusing on adapting\npredominant offline RL methods based on temporal difference learning still\nfalls short under data corruption when the dataset is limited. In contrast, we\ndiscover that vanilla sequence modeling methods, such as Decision Transformer,\nexhibit robustness against data corruption, even without specialized\nmodifications. To unlock the full potential of sequence modeling, we propose\nRobust Decision Rransformer (RDT) by incorporating three simple yet effective\nrobust techniques: embedding dropout to improve the model's robustness against\nerroneous inputs, Gaussian weighted learning to mitigate the effects of\ncorrupted labels, and iterative data correction to eliminate corrupted data\nfrom the source. Extensive experiments on MuJoCo, Kitchen, and Adroit tasks\ndemonstrate RDT's superior performance under various data corruption scenarios\ncompared to prior methods. Furthermore, RDT exhibits remarkable robustness in a\nmore challenging setting that combines training-time data corruption with\ntest-time observation perturbations. These results highlight the potential of\nsequence modeling for learning from noisy or corrupted offline datasets,\nthereby promoting the reliable application of offline RL in real-world\nscenarios. Our code is available at\nhttps://github.com/jiawei415/RobustDecisionTransformer.",
      "tldr_zh": "这篇论文针对离线强化学习（Offline Reinforcement Learning）中数据损坏问题，揭示了传统基于时间差分学习的方法在数据集有限时表现欠佳，而标准的序列建模方法如Decision Transformer则显示出较高的鲁棒性。作者提出Robust Decision Transformer (RDT)，通过嵌入dropout（embedding dropout）、Gaussian weighted learning和iterative data correction等技术来增强模型对错误输入和受损标签的抵抗力。实验结果显示，在MuJoCo、Kitchen和Adroit任务中，RDT在各种数据损坏场景下优于现有方法，并在训练时数据损坏结合测试时观察扰动的复杂设置中表现出卓越性能。这些发现突出了序列建模在从噪声数据中学习的应用潜力，推动Offline RL在现实世界的可靠部署。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICLR2025",
      "pdf_url": "http://arxiv.org/pdf/2407.04285v4",
      "published_date": "2024-07-05 06:34:32 UTC",
      "updated_date": "2025-03-02 08:28:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:01:15.455730"
    },
    {
      "arxiv_id": "2407.04271v1",
      "title": "Variational Partial Group Convolutions for Input-Aware Partial Equivariance of Rotations and Color-Shifts",
      "title_zh": "翻译失败",
      "authors": [
        "Hyunsu Kim",
        "Yegon Kim",
        "Hongseok Yang",
        "Juho Lee"
      ],
      "abstract": "Group Equivariant CNNs (G-CNNs) have shown promising efficacy in various\ntasks, owing to their ability to capture hierarchical features in an\nequivariant manner. However, their equivariance is fixed to the symmetry of the\nwhole group, limiting adaptability to diverse partial symmetries in real-world\ndatasets, such as limited rotation symmetry of handwritten digit images and\nlimited color-shift symmetry of flower images. Recent efforts address this\nlimitation, one example being Partial G-CNN which restricts the output group\nspace of convolution layers to break full equivariance. However, such an\napproach still fails to adjust equivariance levels across data. In this paper,\nwe propose a novel approach, Variational Partial G-CNN (VP G-CNN), to capture\nvarying levels of partial equivariance specific to each data instance. VP G-CNN\nredesigns the distribution of the output group elements to be conditioned on\ninput data, leveraging variational inference to avoid overfitting. This enables\nthe model to adjust its equivariance levels according to the needs of\nindividual data points. Additionally, we address training instability inherent\nin discrete group equivariance models by redesigning the reparametrizable\ndistribution. We demonstrate the effectiveness of VP G-CNN on both toy and\nreal-world datasets, including MNIST67-180, CIFAR10, ColorMNIST, and\nFlowers102. Our results show robust performance, even in uncertainty metrics.",
      "tldr_zh": "本研究针对 Group Equivariant CNNs (G-CNNs) 的固定等变性问题，提出了一种新方法 Variational Partial G-CNN (VP G-CNN)，以适应真实数据中如旋转和颜色偏移的部分对称性。VP G-CNN 通过使输出群元素的分布依赖于输入数据，并利用变分推理避免过拟合，从而实现对每个数据实例的动态等变性调整。该方法还重新设计了可重参数化的分布，以解决离散群等变性模型的训练不稳定性。在 MNIST67-180、CIFAR10、ColorMNIST 和 Flowers102 等数据集上的实验显示，VP G-CNN 表现出稳健性能，尤其在不确定性指标上。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "ICML2024",
      "pdf_url": "http://arxiv.org/pdf/2407.04271v1",
      "published_date": "2024-07-05 05:52:51 UTC",
      "updated_date": "2024-07-05 05:52:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:01:31.109107"
    },
    {
      "arxiv_id": "2407.04268v3",
      "title": "NeuFair: Neural Network Fairness Repair with Dropout",
      "title_zh": "NeuFair：利用 Dropout 的神经网络公平性修复",
      "authors": [
        "Vishnu Asutosh Dasu",
        "Ashish Kumar",
        "Saeid Tizpaz-Niari",
        "Gang Tan"
      ],
      "abstract": "This paper investigates neuron dropout as a post-processing bias mitigation\nfor deep neural networks (DNNs). Neural-driven software solutions are\nincreasingly applied in socially critical domains with significant fairness\nimplications. While neural networks are exceptionally good at finding\nstatistical patterns from data, they may encode and amplify existing biases\nfrom the historical data. Existing bias mitigation algorithms often require\nmodifying the input dataset or the learning algorithms. We posit that the\nprevalent dropout methods that prevent over-fitting during training by randomly\ndropping neurons may be an effective and less intrusive approach to improve the\nfairness of pre-trained DNNs. However, finding the ideal set of neurons to drop\nis a combinatorial problem. We propose NeuFair, a family of post-processing\nrandomized algorithms that mitigate unfairness in pre-trained DNNs via dropouts\nduring inference after training. Our randomized search is guided by an\nobjective to minimize discrimination while maintaining the model's utility. We\nshow that our design of randomized algorithms is effective and efficient in\nimproving fairness (up to 69%) with minimal or no model performance\ndegradation. We provide intuitive explanations of these phenomena and carefully\nexamine the influence of various hyperparameters of search algorithms on the\nresults. Finally, we empirically and conceptually compare NeuFair to different\nstate-of-the-art bias mitigators.",
      "tldr_zh": "该论文探讨了使用神经元 dropout 作为深度神经网络 (DNNs) 的后处理偏置缓解方法，以解决 DNNs 在社会关键领域中放大数据偏置的问题。NeuFair 提出了一系列后处理随机算法，通过在推理阶段随机丢弃神经元来最小化歧视，同时保持模型的效用，避免了修改输入数据集或学习算法的需要。实验结果显示，NeuFair 能有效提高公平性（高达 69%），几乎不影响模型性能，并通过分析超参数影响和与其他最先进偏置缓解方法比较，提供了直观的解释。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.LG",
      "comment": "Paper accepted at ACM ISSTA 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.04268v3",
      "published_date": "2024-07-05 05:45:34 UTC",
      "updated_date": "2024-09-02 17:13:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:01:49.983418"
    },
    {
      "arxiv_id": "2407.04259v2",
      "title": "Robust Q-Learning for finite ambiguity sets",
      "title_zh": "翻译失败",
      "authors": [
        "Cécile Decker",
        "Julian Sester"
      ],
      "abstract": "In this paper we propose a novel $Q$-learning algorithm allowing to solve\ndistributionally robust Markov decision problems for which the ambiguity set of\nprobability measures can be chosen arbitrarily as long as it comprises only a\nfinite amount of measures. Therefore, our approach goes beyond the well-studied\ncases involving ambiguity sets of balls around some reference measure with the\ndistance to reference measure being measured with respect to the Wasserstein\ndistance or the Kullback--Leibler divergence. Hence, our approach allows the\napplicant to create ambiguity sets better tailored to her needs and to solve\nthe associated robust Markov decision problem via a $Q$-learning algorithm\nwhose convergence is guaranteed by our main result. Moreover, we showcase in\nseveral numerical experiments the tractability of our approach.",
      "tldr_zh": "这篇论文提出了一种新型鲁棒 Q-learning 算法，用于解决分布鲁棒性 Markov 决策问题（distributionally robust Markov decision problems），其中模糊集（ambiguity sets）可以是任意包含有限数量概率测度的集合。相比传统方法，该算法超越了基于 Wasserstein 距离或 Kullback-Leibler 散度的球形模糊集限制，允许用户根据需求自定义模糊集。论文证明了该 Q-learning 算法的收敛性，并在多个数值实验中展示了其可行性和实用性。",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.LG",
        "math.PR"
      ],
      "primary_category": "math.OC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.04259v2",
      "published_date": "2024-07-05 05:19:36 UTC",
      "updated_date": "2025-02-16 03:16:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:01:52.285857"
    },
    {
      "arxiv_id": "2407.04258v1",
      "title": "Unsupervised Video Summarization via Reinforcement Learning and a Trained Evaluator",
      "title_zh": "翻译失败",
      "authors": [
        "Mehryar Abbasi",
        "Hadi Hadizadeh",
        "Parvaneh Saeedi"
      ],
      "abstract": "This paper presents a novel approach for unsupervised video summarization\nusing reinforcement learning. It aims to address the existing limitations of\ncurrent unsupervised methods, including unstable training of adversarial\ngenerator-discriminator architectures and reliance on hand-crafted reward\nfunctions for quality evaluation. The proposed method is based on the concept\nthat a concise and informative summary should result in a reconstructed video\nthat closely resembles the original. The summarizer model assigns an importance\nscore to each frame and generates a video summary. In the proposed scheme,\nreinforcement learning, coupled with a unique reward generation pipeline, is\nemployed to train the summarizer model. The reward generation pipeline trains\nthe summarizer to create summaries that lead to improved reconstructions. It\ncomprises a generator model capable of reconstructing masked frames from a\npartially masked video, along with a reward mechanism that compares the\nreconstructed video from the summary against the original. The video generator\nis trained in a self-supervised manner to reconstruct randomly masked frames,\nenhancing its ability to generate accurate summaries. This training pipeline\nresults in a summarizer model that better mimics human-generated video\nsummaries compared to methods relying on hand-crafted rewards. The training\nprocess consists of two stable and isolated training steps, unlike adversarial\narchitectures. Experimental results demonstrate promising performance, with\nF-scores of 62.3 and 54.5 on TVSum and SumMe datasets, respectively.\nAdditionally, the inference stage is 300 times faster than our previously\nreported state-of-the-art method.",
      "tldr_zh": "这篇论文提出了一种基于强化学习的新型无监督视频摘要方法，使用训练过的评估器来解决现有方法的训练不稳定性和对手工奖励函数的依赖。核心思路是训练总结器模型为每个视频帧分配重要性分数，并通过奖励生成管道优化，使生成的摘要能重建出与原视频相似的重建视频，该管道包括一个自监督训练的生成器模型。实验结果显示，该方法在TVSum和SumMe数据集上的F-score分别达到62.3和54.5，比现有方法更接近人类摘要，且推理速度比之前的最先进方法快300倍。",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.MM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.04258v1",
      "published_date": "2024-07-05 05:08:06 UTC",
      "updated_date": "2024-07-05 05:08:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:02:05.170954"
    },
    {
      "arxiv_id": "2407.04247v1",
      "title": "ArAIEval Shared Task: Propagandistic Techniques Detection in Unimodal and Multimodal Arabic Content",
      "title_zh": "ArAIEval 共享任务：单模态和多模态阿拉伯内容中的宣传技巧检测",
      "authors": [
        "Maram Hasanain",
        "Md. Arid Hasan",
        "Fatema Ahmed",
        "Reem Suwaileh",
        "Md. Rafiul Biswas",
        "Wajdi Zaghouani",
        "Firoj Alam"
      ],
      "abstract": "We present an overview of the second edition of the ArAIEval shared task,\norganized as part of the ArabicNLP 2024 conference co-located with ACL 2024. In\nthis edition, ArAIEval offers two tasks: (i) detection of propagandistic\ntextual spans with persuasion techniques identification in tweets and news\narticles, and (ii) distinguishing between propagandistic and non-propagandistic\nmemes. A total of 14 teams participated in the final evaluation phase, with 6\nand 9 teams participating in Tasks 1 and 2, respectively. Finally, 11 teams\nsubmitted system description papers. Across both tasks, we observed that\nfine-tuning transformer models such as AraBERT was at the core of the majority\nof the participating systems. We provide a description of the task setup,\nincluding a description of the dataset construction and the evaluation setup.\nWe further provide a brief overview of the participating systems. All datasets\nand evaluation scripts are released to the research community\n(https://araieval.gitlab.io/). We hope this will enable further research on\nthese important tasks in Arabic.",
      "tldr_zh": "ArAIEval 共享任务是 ArabicNLP 2024 的一部分，聚焦于检测单模态和多模态阿拉伯内容的宣传技术（Propagandistic Techniques）。该任务包括两个子任务：(i) 在推文和新闻文章中识别宣传性文本段落并分类说服技巧，(ii) 区分宣传性和非宣传性 meme。共有 14 支队伍参与最终评估，其中 6 支针对任务 1，9 支针对任务 2，大多数系统依赖于微调 transformer 模型如 AraBERT。任务组织者提供了数据集构建、评估设置的详细描述，并公开了所有数据集和评估脚本，以推动阿拉伯语领域相关研究的进一步发展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "68T50",
        "F.2.2; I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "propaganda, span detection, disinformation, misinformation, fake\n  news, LLMs, GPT-4, multimodality, multimodal LLMs",
      "pdf_url": "http://arxiv.org/pdf/2407.04247v1",
      "published_date": "2024-07-05 04:28:46 UTC",
      "updated_date": "2024-07-05 04:28:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:02:16.460964"
    },
    {
      "arxiv_id": "2407.04241v2",
      "title": "AnySR: Realizing Image Super-Resolution as Any-Scale, Any-Resource",
      "title_zh": "翻译失败",
      "authors": [
        "Wengyi Zhan",
        "Mingbao Lin",
        "Chia-Wen Lin",
        "Rongrong Ji"
      ],
      "abstract": "In an effort to improve the efficiency and scalability of single-image\nsuper-resolution (SISR) applications, we introduce AnySR, to rebuild existing\narbitrary-scale SR methods into any-scale, any-resource implementation. As a\ncontrast to off-the-shelf methods that solve SR tasks across various scales\nwith the same computing costs, our AnySR innovates in: 1) building\narbitrary-scale tasks as any-resource implementation, reducing resource\nrequirements for smaller scales without additional parameters; 2) enhancing\nany-scale performance in a feature-interweaving fashion, inserting scale pairs\ninto features at regular intervals and ensuring correct feature/scale\nprocessing. The efficacy of our AnySR is fully demonstrated by rebuilding most\nexisting arbitrary-scale SISR methods and validating on five popular SISR test\ndatasets. The results show that our AnySR implements SISR tasks in a\ncomputing-more-efficient fashion, and performs on par with existing\narbitrary-scale SISR methods. For the first time, we realize SISR tasks as not\nonly any-scale in literature, but also as any-resource. Code is available at\nhttps://github.com/CrispyFeSo4/AnySR.",
      "tldr_zh": "本研究提出 AnySR，一种创新框架，用于将现有的任意规模单图像超分辨率（SISR）方法重构为任意规模和任意资源的实现，从而提高计算效率。AnySR 的关键创新包括：1) 通过任意资源实现减少小规模任务的资源需求，而不增加额外参数；2) 采用特征交织方式增强任意规模性能，在特征中定期插入规模对以确保正确处理。实验结果显示，AnySR 在五个流行 SISR 测试数据集上重建了现有方法，实现了更高效的计算，同时性能与现有任意规模 SISR 方法相当，为首次真正实现任意资源下的 SISR 任务奠定了基础。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.04241v2",
      "published_date": "2024-07-05 04:00:14 UTC",
      "updated_date": "2024-10-10 14:10:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:02:29.023067"
    },
    {
      "arxiv_id": "2407.04221v2",
      "title": "Autoverse: An Evolvable Game Language for Learning Robust Embodied Agents",
      "title_zh": "Autoverse: 用于学习鲁棒具",
      "authors": [
        "Sam Earle",
        "Julian Togelius"
      ],
      "abstract": "We introduce Autoverse, an evolvable, domain-specific language for\nsingle-player 2D grid-based games, and demonstrate its use as a scalable\ntraining ground for Open-Ended Learning (OEL) algorithms. Autoverse uses\ncellular-automaton-like rewrite rules to describe game mechanics, allowing it\nto express various game environments (e.g. mazes, dungeons, sokoban puzzles)\nthat are popular testbeds for Reinforcement Learning (RL) agents. Each rewrite\nrule can be expressed as a series of simple convolutions, allowing for\nenvironments to be parallelized on the GPU, thereby drastically accelerating RL\ntraining. Using Autoverse, we propose jump-starting open-ended learning by\nimitation learning from search. In such an approach, we first evolve Autoverse\nenvironments (their rules and initial map topology) to maximize the number of\niterations required by greedy tree search to discover a new best solution,\nproducing a curriculum of increasingly complex environments and playtraces. We\nthen distill these expert playtraces into a neural-network-based policy using\nimitation learning. Finally, we use the learned policy as a starting point for\nopen-ended RL, where new training environments are continually evolved to\nmaximize the RL player agent's value function error (a proxy for its regret, or\nthe learnability of generated environments), finding that this approach\nimproves the performance and generality of resultant player agents.",
      "tldr_zh": "本研究引入了 Autoverse，一种可演化的领域特定语言，用于单人 2D 网格游戏环境的设计，并将其作为可扩展的训练平台来支持 Open-Ended Learning (OEL) 算法。Autoverse 通过类似细胞自动机的重写规则描述游戏机制（如迷宫、地牢和 Sokoban 谜题），并利用简单卷积实现 GPU 并行化，从而大幅加速 Reinforcement Learning (RL) 训练。研究提出了一种基于模仿学习从搜索启动的开放式学习方法：先演化环境规则和初始地图拓扑以最大化贪婪树搜索的迭代次数，生成复杂课程和专家游戏轨迹；然后通过模仿学习将这些轨迹提炼成神经网络政策；最后以此政策作为起点，进行持续环境演化以优化 RL 代理的价值函数错误。结果显示，这种方法显著提升了 RL 代理的性能和泛化能力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.04221v2",
      "published_date": "2024-07-05 02:18:02 UTC",
      "updated_date": "2024-08-06 09:39:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:02:41.938166"
    },
    {
      "arxiv_id": "2407.04218v1",
      "title": "Batch Transformer: Look for Attention in Batch",
      "title_zh": "批处理 Transformer：批量中寻找注意力",
      "authors": [
        "Myung Beom Her",
        "Jisu Jeong",
        "Hojoon Song",
        "Ji-Hyeong Han"
      ],
      "abstract": "Facial expression recognition (FER) has received considerable attention in\ncomputer vision, with \"in-the-wild\" environments such as human-computer\ninteraction. However, FER images contain uncertainties such as occlusion, low\nresolution, pose variation, illumination variation, and subjectivity, which\nincludes some expressions that do not match the target label. Consequently,\nlittle information is obtained from a noisy single image and it is not trusted.\nThis could significantly degrade the performance of the FER task. To address\nthis issue, we propose a batch transformer (BT), which consists of the proposed\nclass batch attention (CBA) module, to prevent overfitting in noisy data and\nextract trustworthy information by training on features reflected from several\nimages in a batch, rather than information from a single image. We also propose\nmulti-level attention (MLA) to prevent overfitting the specific features by\ncapturing correlations between each level. In this paper, we present a batch\ntransformer network (BTN) that combines the above proposals. Experimental\nresults on various FER benchmark datasets show that the proposed BTN\nconsistently outperforms the state-ofthe-art in FER datasets. Representative\nresults demonstrate the promise of the proposed BTN for FER.",
      "tldr_zh": "该论文针对面部表情识别 (FER) 在野外环境中的不确定性问题，如遮挡、低分辨率和光照变化等，提出 Batch Transformer (BT) 框架，以解决单一图像信息不足导致的性能下降。BT 包括 Class Batch Attention (CBA) 模块，通过在批量图像上训练来提取可信特征并防止过拟合；同时引入 Multi-Level Attention (MLA) 来捕捉不同级别特征间的相关性，避免过度依赖特定特征。实验结果显示，结合上述模块的 Batch Transformer Network (BTN) 在多个 FER 基准数据集上超越了最先进方法，展示了其在 FER 任务中的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.04218v1",
      "published_date": "2024-07-05 02:13:47 UTC",
      "updated_date": "2024-07-05 02:13:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:02:53.166093"
    },
    {
      "arxiv_id": "2407.04212v1",
      "title": "Smart Vision-Language Reasoners",
      "title_zh": "智能视觉-语言推理器",
      "authors": [
        "Denisa Roberts",
        "Lucas Roberts"
      ],
      "abstract": "In this article, we investigate vision-language models (VLM) as reasoners.\nThe ability to form abstractions underlies mathematical reasoning,\nproblem-solving, and other Math AI tasks. Several formalisms have been given to\nthese underlying abstractions and skills utilized by humans and intelligent\nsystems for reasoning. Furthermore, human reasoning is inherently multimodal,\nand as such, we focus our investigations on multimodal AI. In this article, we\nemploy the abstractions given in the SMART task (Simple Multimodal Algorithmic\nReasoning Task) introduced in \\cite{cherian2022deep} as meta-reasoning and\nproblem-solving skills along eight axes: math, counting, path, measure, logic,\nspatial, and pattern. We investigate the ability of vision-language models to\nreason along these axes and seek avenues of improvement. Including composite\nrepresentations with vision-language cross-attention enabled learning\nmultimodal representations adaptively from fused frozen pretrained backbones\nfor better visual grounding. Furthermore, proper hyperparameter and other\ntraining choices led to strong improvements (up to $48\\%$ gain in accuracy) on\nthe SMART task, further underscoring the power of deep multimodal learning. The\nsmartest VLM, which includes a novel QF multimodal layer, improves upon the\nbest previous baselines in every one of the eight fundamental reasoning skills.\nEnd-to-end code is available at https://github.com/smarter-vlm/smarter.",
      "tldr_zh": "本文探讨了视觉语言模型 (VLMs) 作为推理器的能力，聚焦于多模态 AI 中的八个推理轴线，包括 math、counting、path、measure、logic、spatial 和 pattern。\n作者引入了复合表示与视觉语言交叉注意力机制，并开发了新型 QF 多模态层，从预训练的融合骨干网络中自适应学习多模态表示，以提升视觉 grounding 和整体性能。\n实验结果显示，该方法在 SMART 任务上准确率提高了高达 48%，在所有八个推理技能上超越了现有基线，并提供了开源代码以支持进一步研究。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted in ICML 2024 MATH AI Workshop",
      "pdf_url": "http://arxiv.org/pdf/2407.04212v1",
      "published_date": "2024-07-05 01:47:21 UTC",
      "updated_date": "2024-07-05 01:47:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:03:04.955844"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 79,
  "processed_papers_count": 79,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-19T04:03:26.643058"
}