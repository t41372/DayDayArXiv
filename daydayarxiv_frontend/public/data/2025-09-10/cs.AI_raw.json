[
  {
    "arxiv_id": "2511.05495v1",
    "title": "IMDMR: An Intelligent Multi-Dimensional Memory Retrieval System for Enhanced Conversational AI",
    "authors": [
      "Tejas Pawar",
      "Sarika Patil",
      "Om Tilekar",
      "Rushikesh Janwade",
      "Vaibhav Helambe"
    ],
    "abstract": "Conversational AI systems often struggle with maintaining coherent, contextual memory across extended interactions, limiting their ability to provide personalized and contextually relevant responses. This paper presents IMDMR (Intelligent Multi-Dimensional Memory Retrieval), a novel system that addresses these limitations through a multi-dimensional search architecture. Unlike existing memory systems that rely on single-dimensional approaches, IMDMR leverages six distinct memory dimensions-semantic, entity, category, intent, context, and temporal-to provide comprehensive memory retrieval capabilities. Our system incorporates intelligent query processing with dynamic strategy selection, cross-memory entity resolution, and advanced memory integration techniques. Through comprehensive evaluation against five baseline systems including LangChain RAG, LlamaIndex, MemGPT, and spaCy + RAG, IMDMR achieves a 3.8x improvement in overall performance (0.792 vs 0.207 for the best baseline). We present both simulated (0.314) and production (0.792) implementations, demonstrating the importance of real technology integration while maintaining superiority over all baseline systems. Ablation studies demonstrate the effectiveness of multi-dimensional search, with the full system outperforming individual dimension approaches by 23.3%. Query-type analysis reveals superior performance across all categories, particularly for preferences/interests (0.630) and goals/aspirations (0.630) queries. Comprehensive visualizations and statistical analysis confirm the significance of these improvements with p < 0.001 across all metrics. The results establish IMDMR as a significant advancement in conversational AI memory systems, providing a robust foundation for enhanced user interactions and personalized experiences.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "28 pages, 8 figures, submitted to arXiv for open access publication",
    "pdf_url": "https://arxiv.org/pdf/2511.05495v1",
    "published_date": "2025-09-10 23:53:40 UTC",
    "updated_date": "2025-09-10 23:53:40 UTC"
  },
  {
    "arxiv_id": "2509.09055v1",
    "title": "Improving LLM Safety and Helpfulness using SFT and DPO: A Study on OPT-350M",
    "authors": [
      "Piyush Pant"
    ],
    "abstract": "This research investigates the effectiveness of alignment techniques, Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and a combined SFT+DPO approach on improving the safety and helpfulness of the OPT-350M language model. Utilizing the Anthropic Helpful-Harmless RLHF dataset, we train and evaluate four models: the base OPT350M, an SFT model, a DPO model, and a model trained with both SFT and DPO. We introduce three key evaluation metrics: Harmlessness Rate (HmR), Helpfulness Rate (HpR), and a Combined Alignment Score (CAS), all derived from reward model outputs. The results show that while SFT outperforms DPO, The combined SFT+DPO model outperforms all others across all metrics, demonstrating the complementary nature of these techniques. Our findings also highlight challenges posed by noisy data, limited GPU resources, and training constraints. This study offers a comprehensive view of how fine-tuning strategies affect model alignment and provides a foundation for more robust alignment pipelines in future work.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "17 pages, 3 figures. Code and dataset available at https://github.com/PiyushWithPant/Improving-LLM-Safety-and-Helpfulness-using-SFT-and-DPO",
    "pdf_url": "https://arxiv.org/pdf/2509.09055v1",
    "published_date": "2025-09-10 23:22:59 UTC",
    "updated_date": "2025-09-10 23:22:59 UTC"
  },
  {
    "arxiv_id": "2509.09053v1",
    "title": "A Scoping Review of Machine Learning Applications in Power System Protection and Disturbance Management",
    "authors": [
      "Julian Oelhaf",
      "Georg Kordowich",
      "Mehran Pashaei",
      "Christian Bergler",
      "Andreas Maier",
      "Johann Jäger",
      "Siming Bayer"
    ],
    "abstract": "The integration of renewable and distributed energy resources reshapes modern power systems, challenging conventional protection schemes. This scoping review synthesizes recent literature on machine learning (ML) applications in power system protection and disturbance management, following the PRISMA for Scoping Reviews framework. Based on over 100 publications, three key objectives are addressed: (i) assessing the scope of ML research in protection tasks; (ii) evaluating ML performance across diverse operational scenarios; and (iii) identifying methods suitable for evolving grid conditions. ML models often demonstrate high accuracy on simulated datasets; however, their performance under real-world conditions remains insufficiently validated. The existing literature is fragmented, with inconsistencies in methodological rigor, dataset quality, and evaluation metrics. This lack of standardization hampers the comparability of results and limits the generalizability of findings. To address these challenges, this review introduces a ML-oriented taxonomy for protection tasks, resolves key terminological inconsistencies, and advocates for standardized reporting practices. It further provides guidelines for comprehensive dataset documentation, methodological transparency, and consistent evaluation protocols, aiming to improve reproducibility and enhance the practical relevance of research outcomes. Critical gaps remain, including the scarcity of real-world validation, insufficient robustness testing, and limited consideration of deployment feasibility. Future research should prioritize public benchmark datasets, realistic validation methods, and advanced ML architectures. These steps are essential to move ML-based protection from theoretical promise to practical deployment in increasingly dynamic and decentralized power systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.09053v1",
    "published_date": "2025-09-10 23:19:28 UTC",
    "updated_date": "2025-09-10 23:19:28 UTC"
  },
  {
    "arxiv_id": "2509.09052v1",
    "title": "MoWE : A Mixture of Weather Experts",
    "authors": [
      "Dibyajyoti Chakraborty",
      "Romit Maulik",
      "Peter Harrington",
      "Dallas Foster",
      "Mohammad Amin Nabian",
      "Sanjay Choudhry"
    ],
    "abstract": "Data-driven weather models have recently achieved state-of-the-art performance, yet progress has plateaued in recent years. This paper introduces a Mixture of Experts (MoWE) approach as a novel paradigm to overcome these limitations, not by creating a new forecaster, but by optimally combining the outputs of existing models. The MoWE model is trained with significantly lower computational resources than the individual experts. Our model employs a Vision Transformer-based gating network that dynamically learns to weight the contributions of multiple \"expert\" models at each grid point, conditioned on forecast lead time. This approach creates a synthesized deterministic forecast that is more accurate than any individual component in terms of Root Mean Squared Error (RMSE). Our results demonstrate the effectiveness of this method, achieving up to a 10% lower RMSE than the best-performing AI weather model on a 2-day forecast horizon, significantly outperforming individual experts as well as a simple average across experts. This work presents a computationally efficient and scalable strategy to push the state of the art in data-driven weather prediction by making the most out of leading high-quality forecast models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.ao-ph",
      "physics.geo-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.09052v1",
    "published_date": "2025-09-10 23:15:59 UTC",
    "updated_date": "2025-09-10 23:15:59 UTC"
  },
  {
    "arxiv_id": "2509.12244v1",
    "title": "RU-Net for Automatic Characterization of TRISO Fuel Cross Sections",
    "authors": [
      "Lu Cai",
      "Fei Xu",
      "Min Xian",
      "Yalei Tang",
      "Shoukun Sun",
      "John Stempien"
    ],
    "abstract": "During irradiation, phenomena such as kernel swelling and buffer densification may impact the performance of tristructural isotropic (TRISO) particle fuel. Post-irradiation microscopy is often used to identify these irradiation-induced morphologic changes. However, each fuel compact generally contains thousands of TRISO particles. Manually performing the work to get statistical information on these phenomena is cumbersome and subjective. To reduce the subjectivity inherent in that process and to accelerate data analysis, we used convolutional neural networks (CNNs) to automatically segment cross-sectional images of microscopic TRISO layers. CNNs are a class of machine-learning algorithms specifically designed for processing structured grid data. They have gained popularity in recent years due to their remarkable performance in various computer vision tasks, including image classification, object detection, and image segmentation. In this research, we generated a large irradiated TRISO layer dataset with more than 2,000 microscopic images of cross-sectional TRISO particles and the corresponding annotated images. Based on these annotated images, we used different CNNs to automatically segment different TRISO layers. These CNNs include RU-Net (developed in this study), as well as three existing architectures: U-Net, Residual Network (ResNet), and Attention U-Net. The preliminary results show that the model based on RU-Net performs best in terms of Intersection over Union (IoU). Using CNN models, we can expedite the analysis of TRISO particle cross sections, significantly reducing the manual labor involved and improving the objectivity of the segmentation results.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.12244v1",
    "published_date": "2025-09-10 23:04:28 UTC",
    "updated_date": "2025-09-10 23:04:28 UTC"
  },
  {
    "arxiv_id": "2509.09043v2",
    "title": "Stated Preference for Interaction and Continued Engagement (SPICE): Evaluating an LLM's Willingness to Re-engage in Conversation",
    "authors": [
      "Thomas Manuel Rost",
      "Martina Figlia",
      "Bernd Wallraff"
    ],
    "abstract": "We introduce and evaluate Stated Preference for Interaction and Continued Engagement (SPICE), a simple diagnostic signal elicited by asking a Large Language Model a YES or NO question about its willingness to re-engage with a user's behavior after reviewing a short transcript. In a study using a 3-tone (friendly, unclear, abusive) by 10-interaction stimulus set, we tested four open-weight chat models across four framing conditions, resulting in 480 trials. Our findings show that SPICE sharply discriminates by user tone. Friendly interactions yielded a near-unanimous preference to continue (97.5% YES), while abusive interactions yielded a strong preference to discontinue (17.9% YES), with unclear interactions falling in between (60.4% YES). This core association remains decisive under multiple dependence-aware statistical tests, including Rao-Scott adjustment and cluster permutation tests. Furthermore, we demonstrate that SPICE provides a distinct signal from abuse classification. In trials where a model failed to identify abuse, it still overwhelmingly stated a preference not to continue the interaction (81% of the time). An exploratory analysis also reveals a significant interaction effect: a preamble describing the study context significantly impacts SPICE under ambiguity, but only when transcripts are presented as a single block of text rather than a multi-turn chat. The results validate SPICE as a robust, low-overhead, and reproducible tool for auditing model dispositions, complementing existing metrics by offering a direct, relational signal of a model's state. All stimuli, code, and analysis scripts are released to support replication.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.CL",
    "comment": "Added link to GitHub and Bayesian Analysis Appendix",
    "pdf_url": "https://arxiv.org/pdf/2509.09043v2",
    "published_date": "2025-09-10 22:34:17 UTC",
    "updated_date": "2025-09-20 20:35:31 UTC"
  },
  {
    "arxiv_id": "2509.09740v1",
    "title": "HypoGeneAgent: A Hypothesis Language Agent for Gene-Set Cluster Resolution Selection Using Perturb-seq Datasets",
    "authors": [
      "Ying Yuan",
      "Xing-Yue Monica Ge",
      "Aaron Archer Waterman",
      "Tommaso Biancalani",
      "David Richmond",
      "Yogesh Pandit",
      "Avtar Singh",
      "Russell Littman",
      "Jin Liu",
      "Jan-Christian Huetter",
      "Vladimir Ermakov"
    ],
    "abstract": "Large-scale single-cell and Perturb-seq investigations routinely involve clustering cells and subsequently annotating each cluster with Gene-Ontology (GO) terms to elucidate the underlying biological programs. However, both stages, resolution selection and functional annotation, are inherently subjective, relying on heuristics and expert curation. We present HYPOGENEAGENT, a large language model (LLM)-driven framework, transforming cluster annotation into a quantitatively optimizable task. Initially, an LLM functioning as a gene-set analyst analyzes the content of each gene program or perturbation module and generates a ranked list of GO-based hypotheses, accompanied by calibrated confidence scores. Subsequently, we embed every predicted description with a sentence-embedding model, compute pair-wise cosine similarities, and let the agent referee panel score (i) the internal consistency of the predictions, high average similarity within the same cluster, termed intra-cluster agreement (ii) their external distinctiveness, low similarity between clusters, termed inter-cluster separation. These two quantities are combined to produce an agent-derived resolution score, which is maximized when clusters exhibit simultaneous coherence and mutual exclusivity. When applied to a public K562 CRISPRi Perturb-seq dataset as a preliminary test, our Resolution Score selects clustering granularities that exhibit alignment with known pathway compared to classical metrics such silhouette score, modularity score for gene functional enrichment summary. These findings establish LLM agents as objective adjudicators of cluster resolution and functional annotation, thereby paving the way for fully automated, context-aware interpretation pipelines in single-cell multi-omics studies.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.09740v1",
    "published_date": "2025-09-10 22:25:33 UTC",
    "updated_date": "2025-09-10 22:25:33 UTC"
  },
  {
    "arxiv_id": "2509.09037v1",
    "title": "Envy-Free but Still Unfair: Envy-Freeness Up To One Item (EF-1) in Personalized Recommendation",
    "authors": [
      "Amanda Aird",
      "Ben Armstrong",
      "Nicholas Mattei",
      "Robin Burke"
    ],
    "abstract": "Envy-freeness and the relaxation to Envy-freeness up to one item (EF-1) have been used as fairness concepts in the economics, game theory, and social choice literatures since the 1960s, and have recently gained popularity within the recommendation systems communities. In this short position paper we will give an overview of envy-freeness and its use in economics and recommendation systems; and illustrate why envy is not appropriate to measure fairness for use in settings where personalization plays a role.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.09037v1",
    "published_date": "2025-09-10 22:13:13 UTC",
    "updated_date": "2025-09-10 22:13:13 UTC"
  },
  {
    "arxiv_id": "2509.18125v1",
    "title": "NurseSchedRL: Attention-Guided Reinforcement Learning for Nurse-Patient Assignment",
    "authors": [
      "Harsha Koduri"
    ],
    "abstract": "Healthcare systems face increasing pressure to allocate limited nursing resources efficiently while accounting for skill heterogeneity, patient acuity, staff fatigue, and continuity of care. Traditional optimization and heuristic scheduling methods struggle to capture these dynamic, multi-constraint environments. I propose NurseSchedRL, a reinforcement learning framework for nurse-patient assignment that integrates structured state encoding, constrained action masking, and attention-based representations of skills, fatigue, and geographical context. NurseSchedRL uses Proximal Policy Optimization (PPO) with feasibility masks to ensure assignments respect real-world constraints, while dynamically adapting to patient arrivals and varying nurse availability. In simulation with realistic nurse and patient data, NurseSchedRL achieves improved scheduling efficiency, better alignment of skills to patient needs, and reduced fatigue compared to baseline heuristic and unconstrained RL approaches. These results highlight the potential of reinforcement learning for decision support in complex, high-stakes healthcare workforce management.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.18125v1",
    "published_date": "2025-09-10 21:41:42 UTC",
    "updated_date": "2025-09-10 21:41:42 UTC"
  },
  {
    "arxiv_id": "2509.09013v1",
    "title": "Can Vision-Language Models Solve Visual Math Equations?",
    "authors": [
      "Monjoy Narayan Choudhury",
      "Junling Wang",
      "Yifan Hou",
      "Mrinmaya Sachan"
    ],
    "abstract": "Despite strong performance in visual understanding and language-based reasoning, Vision-Language Models (VLMs) struggle with tasks requiring integrated perception and symbolic computation. We study this limitation through visual equation solving, where mathematical equations are embedded in images, variables are represented by object icons, and coefficients must be inferred by counting. While VLMs perform well on textual equations, they fail on visually grounded counterparts. To understand this gap, we decompose the task into coefficient counting and variable recognition, and find that counting is the primary bottleneck, even when recognition is accurate. We also observe that composing recognition and reasoning introduces additional errors, highlighting challenges in multi-step visual reasoning. Finally, as equation complexity increases, symbolic reasoning itself becomes a limiting factor. These findings reveal key weaknesses in current VLMs and point toward future improvements in visually grounded mathematical reasoning.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "Monjoy Narayan Choudhury and Junling Wang contributed equally to this work. Accepted at EMNLP2025 main. Code and datasets are open-sourced with links in the paper",
    "pdf_url": "https://arxiv.org/pdf/2509.09013v1",
    "published_date": "2025-09-10 21:16:11 UTC",
    "updated_date": "2025-09-10 21:16:11 UTC"
  },
  {
    "arxiv_id": "2509.09009v3",
    "title": "Open-sci-ref-0.01: open and reproducible reference baselines for language model and dataset comparison",
    "authors": [
      "Marianna Nezhurina",
      "Jörg Franke",
      "Taishi Nakamura",
      "Timur Carstensen",
      "Niccolò Ajroldi",
      "Ville Komulainen",
      "David Salinas",
      "Jenia Jitsev"
    ],
    "abstract": "We introduce open-sci-ref, a family of dense transformer models trained as research baselines across multiple model (0.13B to 1.7B parameters) and token scales (up to 1T) on 8 recent open reference datasets. Evaluating the models on various standardized benchmarks, our training runs set establishes reference points that enable researchers to assess the sanity and quality of alternative training approaches across scales and datasets. Intermediate checkpoints allow comparison and studying of the training dynamics. The established reference baselines allow training procedures to be compared through their scaling trends, aligning them on a common compute axis. Comparison of open reference datasets reveals that training on NemoTron-CC HQ consistently outperforms other reference datasets, followed by DCLM-baseline and FineWeb-Edu. In addition to intermediate training checkpoints, the release includes logs, code, and downstream evaluations to simplify reproduction, standardize comparison, and facilitate future research.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "v.1.1. AAAI Workshop on Reproducible Artificial Intelligence (RAI, https://reproducibleai.github.io) 2026, camera ready version. Model weights and intermediate training checkpoints are available at https://huggingface.co/collections/open-sci/open-sci-ref-001; code for reproducing training, evaluation and raw experiments data at https://github.com/LAION-AI/open-sci-ref-0.01",
    "pdf_url": "https://arxiv.org/pdf/2509.09009v3",
    "published_date": "2025-09-10 21:13:34 UTC",
    "updated_date": "2025-12-30 21:54:14 UTC"
  },
  {
    "arxiv_id": "2509.09004v4",
    "title": "Implicit Neural Representations of Intramyocardial Motion and Strain",
    "authors": [
      "Andrew Bell",
      "Yan Kit Choi",
      "Steffen E Petersen",
      "Andrew King",
      "Muhummad Sohaib Nazir",
      "Alistair A Young"
    ],
    "abstract": "Automatic quantification of intramyocardial motion and strain from tagging MRI remains an important but challenging task. We propose a method using implicit neural representations (INRs), conditioned on learned latent codes, to predict continuous left ventricular (LV) displacement -- without requiring inference-time optimisation. Evaluated on 452 UK Biobank test cases, our method achieved the best tracking accuracy (2.14 mm RMSE) and the lowest combined error in global circumferential (2.86%) and radial (6.42%) strain compared to three deep learning baselines. In addition, our method is $\\sim$380$\\times$ faster than the most accurate baseline. These results highlight the suitability of INR-based models for accurate and scalable analysis of myocardial strain in large CMR datasets. The code can be found at https://github.com/andrewjackbell/Displacement-INR",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "STACOM 2025 @ MICCAI",
    "pdf_url": "https://arxiv.org/pdf/2509.09004v4",
    "published_date": "2025-09-10 21:05:27 UTC",
    "updated_date": "2025-09-25 02:10:05 UTC"
  },
  {
    "arxiv_id": "2509.08989v1",
    "title": "Uncertainty Awareness and Trust in Explainable AI- On Trust Calibration using Local and Global Explanations",
    "authors": [
      "Carina Newen",
      "Daniel Bodemer",
      "Sonja Glantz",
      "Emmanuel Müller",
      "Magdalena Wischnewski",
      "Lenka Schnaubert"
    ],
    "abstract": "Explainable AI has become a common term in the literature, scrutinized by computer scientists and statisticians and highlighted by psychological or philosophical researchers. One major effort many researchers tackle is constructing general guidelines for XAI schemes, which we derived from our study. While some areas of XAI are well studied, we focus on uncertainty explanations and consider global explanations, which are often left out. We chose an algorithm that covers various concepts simultaneously, such as uncertainty, robustness, and global XAI, and tested its ability to calibrate trust. We then checked whether an algorithm that aims to provide more of an intuitive visual understanding, despite being complicated to understand, can provide higher user satisfaction and human interpretability.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages, 6 figures, accepted but not yet published at ICDM2025",
    "pdf_url": "https://arxiv.org/pdf/2509.08989v1",
    "published_date": "2025-09-10 20:37:39 UTC",
    "updated_date": "2025-09-10 20:37:39 UTC"
  },
  {
    "arxiv_id": "2509.08972v4",
    "title": "ForTIFAI: Fending Off Recursive Training Induced Failure for AI Model Collapse",
    "authors": [
      "Soheil Zibakhsh Shabgahi",
      "Pedram Aghazadeh",
      "Azalia Mirhoseini",
      "Farinaz Koushanfar"
    ],
    "abstract": "The increasing reliance on generative AI models is rapidly increasing the volume of synthetic data, with some projections suggesting that most available new data for training could be machine-generated by 2030. This shift to a mainly synthetic content presents a critical challenge: repeated training in synthetic data leads to a phenomenon known as model collapse, where model performance degrades over generations of training, eventually rendering the models ineffective. While the causes of model collapse are increasingly understood, effective mitigation strategies remain scarce. We address this challenge by leveraging a key insight: auto-regressive models tend to generate text sequences to which they assign high confidence (i.e., high log-likelihood). Based on this observation, we introduce the Truncated-Cross-Entropy (TCE) loss function. TCE mitigates collapse by selectively ignoring high-confidence tokens during training, effectively filtering out likely machine-generated artifacts from the learning process. Our experiments demonstrate that models trained with TCE not only learn effectively but also exhibit significantly increased resilience, tolerating over 2.3x more synthetic data before the onset of collapse. In addition, we provide an open-source benchmark for collapse dynamics in mixed-data settings. Our results demonstrate that confidence-aware training objectives can substantially delay collapse onset, offering a practical and generalizable tool for model robustness under synthetic-data exposure.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.08972v4",
    "published_date": "2025-09-10 20:06:51 UTC",
    "updated_date": "2025-11-05 00:55:27 UTC"
  },
  {
    "arxiv_id": "2509.08970v2",
    "title": "Gala: Global LLM Agents for Text-to-Model Translation",
    "authors": [
      "Junyang Cai",
      "Serdar Kadioglu",
      "Bistra Dilkina"
    ],
    "abstract": "Natural language descriptions of optimization or satisfaction problems are challenging to translate into correct MiniZinc models, as this process demands both logical reasoning and constraint programming expertise. We introduce Gala, a framework that addresses this challenge with a global agentic approach: multiple specialized large language model (LLM) agents decompose the modeling task by global constraint type. Each agent is dedicated to detecting and generating code for a specific class of global constraint, while a final assembler agent integrates these constraint snippets into a complete MiniZinc model. By dividing the problem into smaller, well-defined sub-tasks, each LLM handles a simpler reasoning challenge, potentially reducing overall complexity. We conduct initial experiments with several LLMs and show better performance against baselines such as one-shot prompting and chain-of-thought prompting. Finally, we outline a comprehensive roadmap for future work, highlighting potential enhancements and directions for improvement.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.08970v2",
    "published_date": "2025-09-10 20:04:20 UTC",
    "updated_date": "2025-10-02 19:55:18 UTC"
  },
  {
    "arxiv_id": "2509.08926v3",
    "title": "Similarity-based Outlier Detection for Noisy Object Re-Identification Using Beta Mixtures",
    "authors": [
      "Waqar Ahmad",
      "Evan Murphy",
      "Vladimir A. Krylov"
    ],
    "abstract": "Object re-identification (Re-ID) methods are highly sensitive to label noise, which typically leads to significant performance degradation. We address this challenge by reframing Re-ID as a supervised image similarity task and adopting a Siamese network architecture trained to capture discriminative pairwise relationships. Central to our approach is a novel statistical outlier detection (OD) framework, termed Beta-SOD (Beta mixture Similarity-based Outlier Detection), which models the distribution of cosine similarities between embedding pairs using a two-component Beta distribution mixture model. We establish a novel identifiability result for mixtures of two Beta distributions, ensuring that our learning task is well-posed. The proposed OD step complements the Re-ID architecture combining binary cross-entropy, contrastive, and cosine embedding losses that jointly optimize feature-level similarity learning. We demonstrate the effectiveness of Beta-SOD in de-noising and Re-ID tasks for person Re-ID, on CUHK03 and Market-1501 datasets, and vehicle Re-ID, on VeRi-776 dataset. Our method shows superior performance compared to the state-of-the-art methods across various noise levels (10-30\\%), demonstrating both robustness and broad applicability in noisy Re-ID scenarios. The implementation of Beta-SOD is available at: github.com/waqar3411/Beta-SOD",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "math.ST",
      "stat.ML"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.08926v3",
    "published_date": "2025-09-10 18:42:19 UTC",
    "updated_date": "2025-09-15 11:52:51 UTC"
  },
  {
    "arxiv_id": "2509.08919v1",
    "title": "Generative Engine Optimization: How to Dominate AI Search",
    "authors": [
      "Mahe Chen",
      "Xiaoxuan Wang",
      "Kaiwen Chen",
      "Nick Koudas"
    ],
    "abstract": "The rapid adoption of generative AI-powered search engines like ChatGPT, Perplexity, and Gemini is fundamentally reshaping information retrieval, moving from traditional ranked lists to synthesized, citation-backed answers. This shift challenges established Search Engine Optimization (SEO) practices and necessitates a new paradigm, which we term Generative Engine Optimization (GEO).\n  This paper presents a comprehensive comparative analysis of AI Search and traditional web search (Google). Through a series of large-scale, controlled experiments across multiple verticals, languages, and query paraphrases, we quantify critical differences in how these systems source information. Our key findings reveal that AI Search exhibit a systematic and overwhelming bias towards Earned media (third-party, authoritative sources) over Brand-owned and Social content, a stark contrast to Google's more balanced mix. We further demonstrate that AI Search services differ significantly from each other in their domain diversity, freshness, cross-language stability, and sensitivity to phrasing.\n  Based on these empirical results, we formulate a strategic GEO agenda. We provide actionable guidance for practitioners, emphasizing the critical need to: (1) engineer content for machine scannability and justification, (2) dominate earned media to build AI-perceived authority, (3) adopt engine-specific and language-aware strategies, and (4) overcome the inherent \"big brand bias\" for niche players. Our work provides the foundational empirical analysis and a strategic framework for achieving visibility in the new generative search landscape.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.SI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.08919v1",
    "published_date": "2025-09-10 18:29:18 UTC",
    "updated_date": "2025-09-10 18:29:18 UTC"
  },
  {
    "arxiv_id": "2509.08911v1",
    "title": "Instance-Optimal Matrix Multiplicative Weight Update and Its Quantum Applications",
    "authors": [
      "Weiyuan Gong",
      "Tongyang Li",
      "Xinzhao Wang",
      "Zhiyu Zhang"
    ],
    "abstract": "The Matrix Multiplicative Weight Update (MMWU) is a seminal online learning algorithm with numerous applications. Applied to the matrix version of the Learning from Expert Advice (LEA) problem on the $d$-dimensional spectraplex, it is well known that MMWU achieves the minimax-optimal regret bound of $O(\\sqrt{T\\log d})$, where $T$ is the time horizon. In this paper, we present an improved algorithm achieving the instance-optimal regret bound of $O(\\sqrt{T\\cdot S(X||d^{-1}I_d)})$, where $X$ is the comparator in the regret, $I_d$ is the identity matrix, and $S(\\cdot||\\cdot)$ denotes the quantum relative entropy. Furthermore, our algorithm has the same computational complexity as MMWU, indicating that the improvement in the regret bound is ``free''.\n  Technically, we first develop a general potential-based framework for matrix LEA, with MMWU being its special case induced by the standard exponential potential. Then, the crux of our analysis is a new ``one-sided'' Jensen's trace inequality built on a Laplace transform technique, which allows the application of general potential functions beyond exponential to matrix LEA. Our algorithm is finally induced by an optimal potential function from the vector LEA problem, based on the imaginary error function.\n  Complementing the above, we provide a memory lower bound for matrix LEA, and explore the applications of our algorithm in quantum learning theory. We show that it outperforms the state of the art for learning quantum states corrupted by depolarization noise, random quantum states, and Gibbs states. In addition, applying our algorithm to linearized convex losses enables predicting nonlinear quantum properties, such as purity, quantum virtual cooling, and Rényi-$2$ correlation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DS",
      "quant-ph",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "47 pages",
    "pdf_url": "https://arxiv.org/pdf/2509.08911v1",
    "published_date": "2025-09-10 18:15:41 UTC",
    "updated_date": "2025-09-10 18:15:41 UTC"
  },
  {
    "arxiv_id": "2509.08910v1",
    "title": "PromptGuard: An Orchestrated Prompting Framework for Principled Synthetic Text Generation for Vulnerable Populations using LLMs with Enhanced Safety, Fairness, and Controllability",
    "authors": [
      "Tung Vu",
      "Lam Nguyen",
      "Quynh Dao"
    ],
    "abstract": "The proliferation of Large Language Models (LLMs) in real-world applications poses unprecedented risks of generating harmful, biased, or misleading information to vulnerable populations including LGBTQ+ individuals, single parents, and marginalized communities. While existing safety approaches rely on post-hoc filtering or generic alignment techniques, they fail to proactively prevent harmful outputs at the generation source. This paper introduces PromptGuard, a novel modular prompting framework with our breakthrough contribution: VulnGuard Prompt, a hybrid technique that prevents harmful information generation using real-world data-driven contrastive learning. VulnGuard integrates few-shot examples from curated GitHub repositories, ethical chain-of-thought reasoning, and adaptive role-prompting to create population-specific protective barriers. Our framework employs theoretical multi-objective optimization with formal proofs demonstrating 25-30% analytical harm reduction through entropy bounds and Pareto optimality. PromptGuard orchestrates six core modules: Input Classification, VulnGuard Prompting, Ethical Principles Integration, External Tool Interaction, Output Validation, and User-System Interaction, creating an intelligent expert system for real-time harm prevention. We provide comprehensive mathematical formalization including convergence proofs, vulnerability analysis using information theory, and theoretical validation framework using GitHub-sourced datasets, establishing mathematical foundations for systematic empirical research.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.08910v1",
    "published_date": "2025-09-10 18:14:52 UTC",
    "updated_date": "2025-09-10 18:14:52 UTC"
  },
  {
    "arxiv_id": "2509.09738v1",
    "title": "Human-AI Collaboration Increases Efficiency in Regulatory Writing",
    "authors": [
      "Umut Eser",
      "Yael Gozin",
      "L. Jay Stallons",
      "Ari Caroline",
      "Martin Preusse",
      "Brandon Rice",
      "Scott Wright",
      "Andrew Robertson"
    ],
    "abstract": "Background: Investigational New Drug (IND) application preparation is time-intensive and expertise-dependent, slowing early clinical development. Objective: To evaluate whether a large language model (LLM) platform (AutoIND) can reduce first-draft composition time while maintaining document quality in regulatory submissions. Methods: Drafting times for IND nonclinical written summaries (eCTD modules 2.6.2, 2.6.4, 2.6.6) generated by AutoIND were directly recorded. For comparison, manual drafting times for IND summaries previously cleared by the U.S. FDA were estimated from the experience of regulatory writers ($\\geq$6 years) and used as industry-standard benchmarks. Quality was assessed by a blinded regulatory writing assessor using seven pre-specified categories: correctness, completeness, conciseness, consistency, clarity, redundancy, and emphasis. Each sub-criterion was scored 0-3 and normalized to a percentage. A critical regulatory error was defined as any misrepresentation or omission likely to alter regulatory interpretation (e.g., incorrect NOAEL, omission of mandatory GLP dose-formulation analysis). Results: AutoIND reduced initial drafting time by $\\sim$97% (from $\\sim$100 h to 3.7 h for 18,870 pages/61 reports in IND-1; and to 2.6 h for 11,425 pages/58 reports in IND-2). Quality scores were 69.6\\% and 77.9\\% for IND-1 and IND-2. No critical regulatory errors were detected, but deficiencies in emphasis, conciseness, and clarity were noted. Conclusions: AutoIND can dramatically accelerate IND drafting, but expert regulatory writers remain essential to mature outputs to submission-ready quality. Systematic deficiencies identified provide a roadmap for targeted model improvements.",
    "categories": [
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.09738v1",
    "published_date": "2025-09-10 18:02:23 UTC",
    "updated_date": "2025-09-10 18:02:23 UTC"
  },
  {
    "arxiv_id": "2509.09737v1",
    "title": "World Modeling with Probabilistic Structure Integration",
    "authors": [
      "Klemen Kotar",
      "Wanhee Lee",
      "Rahul Venkatesh",
      "Honglin Chen",
      "Daniel Bear",
      "Jared Watrous",
      "Simon Kim",
      "Khai Loong Aw",
      "Lilian Naing Chen",
      "Stefan Stojanov",
      "Kevin Feigelis",
      "Imran Thobani",
      "Alex Durango",
      "Khaled Jedoui",
      "Atlas Kazemian",
      "Dan Yamins"
    ],
    "abstract": "We present Probabilistic Structure Integration (PSI), a system for learning richly controllable and flexibly promptable world models from data. PSI consists of a three-step cycle. The first step, Probabilistic prediction, involves building a probabilistic graphical model Psi of the data, in the form of a random-access autoregressive sequence model. Psi supports a complete set of learned conditional distributions describing the dependence of any variables in the data on any other set of variables. In step 2, Structure extraction, we show how to extract underlying low-dimensional properties in the data, corresponding to a diverse set of meaningful \"intermediate structures\", in a zero-shot fashion via causal inference on Psi. Step 3, Integration, completes the cycle by converting these structures into new token types that are then continually mixed back into the training diet as conditioning signals and prediction targets. Each such cycle augments the capabilities of Psi, both allowing it to model the underlying data better, and creating new control handles -- akin to an LLM-like universal prompting language. We train an instance of Psi on 1.4 trillion tokens of internet video data; we use it to perform a variety of useful video prediction and understanding inferences; we extract state-of-the-art optical flow, self-supervised depth and object segmentation; and we use these structures to support a full cycle of predictive improvements.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.09737v1",
    "published_date": "2025-09-10 18:01:04 UTC",
    "updated_date": "2025-09-10 18:01:04 UTC"
  },
  {
    "arxiv_id": "2509.08897v1",
    "title": "Recurrence Meets Transformers for Universal Multimodal Retrieval",
    "authors": [
      "Davide Caffagni",
      "Sara Sarto",
      "Marcella Cornia",
      "Lorenzo Baraldi",
      "Rita Cucchiara"
    ],
    "abstract": "With the rapid advancement of multimodal retrieval and its application in LLMs and multimodal LLMs, increasingly complex retrieval tasks have emerged. Existing methods predominantly rely on task-specific fine-tuning of vision-language models and are limited to single-modality queries or documents. In this paper, we propose ReT-2, a unified retrieval model that supports multimodal queries, composed of both images and text, and searches across multimodal document collections where text and images coexist. ReT-2 leverages multi-layer representations and a recurrent Transformer architecture with LSTM-inspired gating mechanisms to dynamically integrate information across layers and modalities, capturing fine-grained visual and textual details. We evaluate ReT-2 on the challenging M2KR and M-BEIR benchmarks across different retrieval configurations. Results demonstrate that ReT-2 consistently achieves state-of-the-art performance across diverse settings, while offering faster inference and reduced memory usage compared to prior approaches. When integrated into retrieval-augmented generation pipelines, ReT-2 also improves downstream performance on Encyclopedic-VQA and InfoSeek datasets. Our source code and trained models are publicly available at: https://github.com/aimagelab/ReT-2",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.08897v1",
    "published_date": "2025-09-10 18:00:29 UTC",
    "updated_date": "2025-09-10 18:00:29 UTC"
  },
  {
    "arxiv_id": "2509.08827v3",
    "title": "A Survey of Reinforcement Learning for Large Reasoning Models",
    "authors": [
      "Kaiyan Zhang",
      "Yuxin Zuo",
      "Bingxiang He",
      "Youbang Sun",
      "Runze Liu",
      "Che Jiang",
      "Yuchen Fan",
      "Kai Tian",
      "Guoli Jia",
      "Pengfei Li",
      "Yu Fu",
      "Xingtai Lv",
      "Yuchen Zhang",
      "Sihang Zeng",
      "Shang Qu",
      "Haozhan Li",
      "Shijie Wang",
      "Yuru Wang",
      "Xinwei Long",
      "Fangfu Liu",
      "Xiang Xu",
      "Jiaze Ma",
      "Xuekai Zhu",
      "Ermo Hua",
      "Yihao Liu",
      "Zonglin Li",
      "Huayu Chen",
      "Xiaoye Qu",
      "Yafu Li",
      "Weize Chen",
      "Zhenzhao Yuan",
      "Junqi Gao",
      "Dong Li",
      "Zhiyuan Ma",
      "Ganqu Cui",
      "Zhiyuan Liu",
      "Biqing Qi",
      "Ning Ding",
      "Bowen Zhou"
    ],
    "abstract": "In this paper, we survey recent advances in Reinforcement Learning (RL) for reasoning with Large Language Models (LLMs). RL has achieved remarkable success in advancing the frontier of LLM capabilities, particularly in addressing complex logical tasks such as mathematics and coding. As a result, RL has emerged as a foundational methodology for transforming LLMs into LRMs. With the rapid progress of the field, further scaling of RL for LRMs now faces foundational challenges not only in computational resources but also in algorithm design, training data, and infrastructure. To this end, it is timely to revisit the development of this domain, reassess its trajectory, and explore strategies to enhance the scalability of RL toward Artificial SuperIntelligence (ASI). In particular, we examine research applying RL to LLMs and LRMs for reasoning abilities, especially since the release of DeepSeek-R1, including foundational components, core problems, training resources, and downstream applications, to identify future opportunities and directions for this rapidly evolving area. We hope this review will promote future research on RL for broader reasoning models. Github: https://github.com/TsinghuaC3I/Awesome-RL-for-LRMs",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Fixed typos; added missing and recent citations (117 -> 120 pages)",
    "pdf_url": "https://arxiv.org/pdf/2509.08827v3",
    "published_date": "2025-09-10 17:59:43 UTC",
    "updated_date": "2025-10-09 17:08:52 UTC"
  },
  {
    "arxiv_id": "2509.08825v2",
    "title": "Large Language Model Hacking: Quantifying the Hidden Risks of Using LLMs for Text Annotation",
    "authors": [
      "Joachim Baumann",
      "Paul Röttger",
      "Aleksandra Urman",
      "Albert Wendsjö",
      "Flor Miriam Plaza-del-Arco",
      "Johannes B. Gruber",
      "Dirk Hovy"
    ],
    "abstract": "Large language models are rapidly transforming social science research by enabling the automation of labor-intensive tasks like data annotation and text analysis. However, LLM outputs vary significantly depending on the implementation choices made by researchers (e.g., model selection or prompting strategy). Such variation can introduce systematic biases and random errors, which propagate to downstream analyses and cause Type I (false positive), Type II (false negative), Type S (wrong sign), or Type M (exaggerated effect) errors. We call this phenomenon where configuration choices lead to incorrect conclusions LLM hacking.\n  We find that intentional LLM hacking is strikingly simple. By replicating 37 data annotation tasks from 21 published social science studies, we show that, with just a handful of prompt paraphrases, virtually anything can be presented as statistically significant.\n  Beyond intentional manipulation, our analysis of 13 million labels from 18 different LLMs across 2361 realistic hypotheses shows that there is also a high risk of accidental LLM hacking, even when following standard research practices. We find incorrect conclusions in approximately 31% of hypotheses for state-of-the-art LLMs, and in half the hypotheses for smaller language models. While higher task performance and stronger general model capabilities reduce LLM hacking risk, even highly accurate models remain susceptible. The risk of LLM hacking decreases as effect sizes increase, indicating the need for more rigorous verification of LLM-based findings near significance thresholds. We analyze 21 mitigation techniques and find that human annotations provide crucial protection against false positives. Common regression estimator correction techniques can restore valid inference but trade off Type I vs. Type II errors.\n  We publish a list of practical recommendations to prevent LLM hacking.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.08825v2",
    "published_date": "2025-09-10 17:58:53 UTC",
    "updated_date": "2025-10-06 16:58:59 UTC"
  },
  {
    "arxiv_id": "2509.08817v1",
    "title": "QCardEst/QCardCorr: Quantum Cardinality Estimation and Correction",
    "authors": [
      "Tobias Winker",
      "Jinghua Groppe",
      "Sven Groppe"
    ],
    "abstract": "Cardinality estimation is an important part of query optimization in DBMS. We develop a Quantum Cardinality Estimation (QCardEst) approach using Quantum Machine Learning with a Hybrid Quantum-Classical Network. We define a compact encoding for turning SQL queries into a quantum state, which requires only qubits equal to the number of tables in the query. This allows the processing of a complete query with a single variational quantum circuit (VQC) on current hardware. In addition, we compare multiple classical post-processing layers to turn the probability vector output of VQC into a cardinality value. We introduce Quantum Cardinality Correction QCardCorr, which improves classical cardinality estimators by multiplying the output with a factor generated by a VQC to improve the cardinality estimation. With QCardCorr, we have an improvement over the standard PostgreSQL optimizer of 6.37 times for JOB-light and 8.66 times for STATS. For JOB-light we even outperform MSCN by a factor of 3.47.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.DB",
      "cs.LG"
    ],
    "primary_category": "quant-ph",
    "comment": "7 pages",
    "pdf_url": "https://arxiv.org/pdf/2509.08817v1",
    "published_date": "2025-09-10 17:49:06 UTC",
    "updated_date": "2025-09-10 17:49:06 UTC"
  },
  {
    "arxiv_id": "2509.08814v3",
    "title": "Merge-of-Thought Distillation",
    "authors": [
      "Zhanming Shen",
      "Zeyu Qin",
      "Zenan Huang",
      "Hao Chen",
      "Jiaqi Hu",
      "Yihong Zhuang",
      "Guoshan Lu",
      "Gang Chen",
      "Junbo Zhao"
    ],
    "abstract": "Efficient reasoning distillation for long chain-of-thought (CoT) models is increasingly constrained by the assumption of a single oracle teacher, despite the practical availability of multiple candidate teachers and growing CoT corpora. We revisit teacher selection and observe that different students have different \"best teachers,\" and even for the same student, the best teacher can vary across datasets. Therefore, to unify multiple teachers' reasoning abilities into a student to overcome conflicts among various teachers' supervision, we propose Merge-of-Thought Distillation (MoT), a lightweight framework that alternates between teacher-specific supervised fine-tuning branches and weight-space merging of the resulting student variants. On competition math benchmarks, using only about 200 CoT samples, applying MoT to a Qwen3-14B student surpasses strong models including Deepseek-R1, Qwen3-32B, and OpenAI-O1, demonstrating substantial gains. Besides, MoT consistently outperforms the best single-teacher distillation, improves general reasoning beyond mathematics while reducing catastrophic forgetting, and shows robustness to distribution-shifted and peer-level teachers. Finally, we have demonstrated MoT possesses consensus CoT by eliminating teacher-specific inductive biases and inter-teacher conflicts while repeatedly reinforcing the learning of consensus reasoning features. These results position MoT as a simple, effective route to efficiently distilling long CoT capabilities from diverse teachers into compact students.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.08814v3",
    "published_date": "2025-09-10 17:46:57 UTC",
    "updated_date": "2025-10-16 15:43:35 UTC"
  },
  {
    "arxiv_id": "2509.08812v1",
    "title": "MoVoC: Morphology-Aware Subword Construction for Geez Script Languages",
    "authors": [
      "Hailay Kidu Teklehaymanot",
      "Dren Fazlija",
      "Wolfgang Nejdl"
    ],
    "abstract": "Subword-based tokenization methods often fail to preserve morphological boundaries, a limitation especially pronounced in low-resource, morphologically complex languages such as those written in the Geez script. To address this, we present MoVoC (Morpheme-aware Subword Vocabulary Construction) and train MoVoC-Tok, a tokenizer that integrates supervised morphological analysis into the subword vocabulary. This hybrid segmentation approach combines morpheme-based and Byte Pair Encoding (BPE) tokens to preserve morphological integrity while maintaining lexical meaning. To tackle resource scarcity, we curate and release manually annotated morpheme data for four Geez script languages and a morpheme-aware vocabulary for two of them. While the proposed tokenization method does not lead to significant gains in automatic translation quality, we observe consistent improvements in intrinsic metrics, MorphoScore, and Boundary Precision, highlighting the value of morphology-aware segmentation in enhancing linguistic fidelity and token efficiency. Our morpheme-annotated datasets and tokenizer will be publicly available to support further research in low-resource, morphologically rich languages. Our code and data are available on GitHub: https://github.com/hailaykidu/MoVoC",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "This submission is approximately 10 pages in length and includes 1 figure and 6 tables",
    "pdf_url": "https://arxiv.org/pdf/2509.08812v1",
    "published_date": "2025-09-10 17:45:10 UTC",
    "updated_date": "2025-09-10 17:45:10 UTC"
  },
  {
    "arxiv_id": "2509.18123v1",
    "title": "SPADE: A Large Language Model Framework for Soil Moisture Pattern Recognition and Anomaly Detection in Precision Agriculture",
    "authors": [
      "Yeonju Lee",
      "Rui Qi Chen",
      "Joseph Oboamah",
      "Po Nien Su",
      "Wei-zhen Liang",
      "Yeyin Shi",
      "Lu Gan",
      "Yongsheng Chen",
      "Xin Qiao",
      "Jing Li"
    ],
    "abstract": "Accurate interpretation of soil moisture patterns is critical for irrigation scheduling and crop management, yet existing approaches for soil moisture time-series analysis either rely on threshold-based rules or data-hungry machine learning or deep learning models that are limited in adaptability and interpretability. In this study, we introduce SPADE (Soil moisture Pattern and Anomaly DEtection), an integrated framework that leverages large language models (LLMs) to jointly detect irrigation patterns and anomalies in soil moisture time-series data. SPADE utilizes ChatGPT-4.1 for its advanced reasoning and instruction-following capabilities, enabling zero-shot analysis without requiring task-specific annotation or fine-tuning. By converting time-series data into a textual representation and designing domain-informed prompt templates, SPADE identifies irrigation events, estimates net irrigation gains, detects, classifies anomalies, and produces structured, interpretable reports. Experiments were conducted on real-world soil moisture sensor data from commercial and experimental farms cultivating multiple crops across the United States. Results demonstrate that SPADE outperforms the existing method in anomaly detection, achieving higher recall and F1 scores and accurately classifying anomaly types. Furthermore, SPADE achieved high precision and recall in detecting irrigation events, indicating its strong capability to capture irrigation patterns accurately. SPADE's reports provide interpretability and usability of soil moisture analytics. This study highlights the potential of LLMs as scalable, adaptable tools for precision agriculture, which is capable of integrating qualitative knowledge and data-driven reasoning to produce actionable insights for accurate soil moisture monitoring and improved irrigation scheduling from soil moisture time-series data.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.18123v1",
    "published_date": "2025-09-10 17:41:03 UTC",
    "updated_date": "2025-09-10 17:41:03 UTC"
  },
  {
    "arxiv_id": "2509.08803v1",
    "title": "Scaling Truth: The Confidence Paradox in AI Fact-Checking",
    "authors": [
      "Ihsan A. Qazi",
      "Zohaib Khan",
      "Abdullah Ghani",
      "Agha A. Raza",
      "Zafar A. Qazi",
      "Wassay Sajjad",
      "Ayesha Ali",
      "Asher Javaid",
      "Muhammad Abdullah Sohail",
      "Abdul H. Azeemi"
    ],
    "abstract": "The rise of misinformation underscores the need for scalable and reliable fact-checking solutions. Large language models (LLMs) hold promise in automating fact verification, yet their effectiveness across global contexts remains uncertain. We systematically evaluate nine established LLMs across multiple categories (open/closed-source, multiple sizes, diverse architectures, reasoning-based) using 5,000 claims previously assessed by 174 professional fact-checking organizations across 47 languages. Our methodology tests model generalizability on claims postdating training cutoffs and four prompting strategies mirroring both citizen and professional fact-checker interactions, with over 240,000 human annotations as ground truth. Findings reveal a concerning pattern resembling the Dunning-Kruger effect: smaller, accessible models show high confidence despite lower accuracy, while larger models demonstrate higher accuracy but lower confidence. This risks systemic bias in information verification, as resource-constrained organizations typically use smaller models. Performance gaps are most pronounced for non-English languages and claims originating from the Global South, threatening to widen existing information inequalities. These results establish a multilingual benchmark for future research and provide an evidence base for policy aimed at ensuring equitable access to trustworthy, AI-assisted fact-checking.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.SI",
    "comment": "65 pages, 26 figures, 6 tables",
    "pdf_url": "https://arxiv.org/pdf/2509.08803v1",
    "published_date": "2025-09-10 17:36:25 UTC",
    "updated_date": "2025-09-10 17:36:25 UTC"
  },
  {
    "arxiv_id": "2509.08800v1",
    "title": "PianoVAM: A Multimodal Piano Performance Dataset",
    "authors": [
      "Yonghyun Kim",
      "Junhyung Park",
      "Joonhyung Bae",
      "Kirak Kim",
      "Taegyun Kwon",
      "Alexander Lerch",
      "Juhan Nam"
    ],
    "abstract": "The multimodal nature of music performance has driven increasing interest in data beyond the audio domain within the music information retrieval (MIR) community. This paper introduces PianoVAM, a comprehensive piano performance dataset that includes videos, audio, MIDI, hand landmarks, fingering labels, and rich metadata. The dataset was recorded using a Disklavier piano, capturing audio and MIDI from amateur pianists during their daily practice sessions, alongside synchronized top-view videos in realistic and varied performance conditions. Hand landmarks and fingering labels were extracted using a pretrained hand pose estimation model and a semi-automated fingering annotation algorithm. We discuss the challenges encountered during data collection and the alignment process across different modalities. Additionally, we describe our fingering annotation method based on hand landmarks extracted from videos. Finally, we present benchmarking results for both audio-only and audio-visual piano transcription using the PianoVAM dataset and discuss additional potential applications.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CV",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted to the 26th International Society for Music Information Retrieval (ISMIR) Conference, 2025",
    "pdf_url": "https://arxiv.org/pdf/2509.08800v1",
    "published_date": "2025-09-10 17:35:58 UTC",
    "updated_date": "2025-09-10 17:35:58 UTC"
  },
  {
    "arxiv_id": "2509.18122v1",
    "title": "GAUSS: Benchmarking Structured Mathematical Skills for Large Language Models",
    "authors": [
      "Yue Zhang",
      "Jiaxin Zhang",
      "Qiuyu Ren",
      "Tahsin Saffat",
      "Xiaoxuan Liu",
      "Zitong Yang",
      "Banghua Zhu",
      "Yi Ma"
    ],
    "abstract": "We introduce \\textbf{GAUSS} (\\textbf{G}eneral \\textbf{A}ssessment of \\textbf{U}nderlying \\textbf{S}tructured \\textbf{S}kills in Mathematics), a benchmark that evaluates LLMs' mathematical abilities across twelve core skill dimensions, grouped into three domains: knowledge and understanding, problem solving and communication, and meta-skills and creativity. By categorizing problems according to cognitive skills and designing tasks that isolate specific abilities, GAUSS constructs comprehensive, fine-grained, and interpretable profiles of models' mathematical abilities. These profiles faithfully represent their underlying mathematical intelligence. To exemplify how to use the \\textsc{GAUSS} benchmark, we have derived the skill profile of \\textsc{GPT-5-thinking}, revealing its strengths and weaknesses as well as its differences relative to \\textsc{o4-mini-high}, thereby underscoring the value of multidimensional, skill-based evaluation.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "120 pages (including appendix)",
    "pdf_url": "https://arxiv.org/pdf/2509.18122v1",
    "published_date": "2025-09-10 17:35:38 UTC",
    "updated_date": "2025-09-10 17:35:38 UTC"
  },
  {
    "arxiv_id": "2509.08785v1",
    "title": "Narrative-Guided Reinforcement Learning: A Platform for Studying Language Model Influence on Decision Making",
    "authors": [
      "Anup Tuladhar",
      "Araz Minhas",
      "Adam Kirton",
      "Eli Kinney-Lang"
    ],
    "abstract": "We present a preliminary experimental platform that explores how narrative elements might shape AI decision-making by combining reinforcement learning (RL) with language model reasoning. While AI systems can now both make decisions and engage in narrative reasoning, these capabilities have mostly been studied separately. Our platform attempts to bridge this gap using a dual-system architecture to examine how narrative frameworks could influence reward-based learning. The system comprises a reinforcement learning policy that suggests actions based on past experience, and a language model that processes these suggestions through different narrative frameworks to guide decisions. This setup enables initial experimentation with narrative elements while maintaining consistent environment and reward structures. We implement this architecture in a configurable gridworld environment, where agents receive both policy suggestions and information about their surroundings. The platform's modular design facilitates controlled testing of environmental complexity, narrative parameters, and the interaction between reinforcement learning and narrative-based decisions. Our logging system captures basic decision metrics, from RL policy values to language model reasoning to action selection patterns. While preliminary, this implementation provides a foundation for studying how different narrative frameworks might affect reward-based decisions and exploring potential interactions between optimization-based learning and symbolic reasoning in AI systems.",
    "categories": [
      "cs.AI",
      "cs.MA",
      "stat.ML"
    ],
    "primary_category": "cs.AI",
    "comment": "Extended Abstract for RLDM 2025",
    "pdf_url": "https://arxiv.org/pdf/2509.08785v1",
    "published_date": "2025-09-10 17:14:12 UTC",
    "updated_date": "2025-09-10 17:14:12 UTC"
  },
  {
    "arxiv_id": "2509.08780v1",
    "title": "An End-to-End Deep Learning Framework for Arsenicosis Diagnosis Using Mobile-Captured Skin Images",
    "authors": [
      "Asif Newaz",
      "Asif Ur Rahman Adib",
      "Rajit Sahil",
      "Mashfique Mehzad"
    ],
    "abstract": "Background: Arsenicosis is a serious public health concern in South and Southeast Asia, primarily caused by long-term consumption of arsenic-contaminated water. Its early cutaneous manifestations are clinically significant but often underdiagnosed, particularly in rural areas with limited access to dermatologists. Automated, image-based diagnostic solutions can support early detection and timely interventions.\n  Methods: In this study, we propose an end-to-end framework for arsenicosis diagnosis using mobile phone-captured skin images. A dataset comprising 20 classes and over 11000 images of arsenic-induced and other dermatological conditions was curated. Multiple deep learning architectures, including convolutional neural networks (CNNs) and Transformer-based models, were benchmarked for arsenicosis detection. Model interpretability was integrated via LIME and Grad-CAM, while deployment feasibility was demonstrated through a web-based diagnostic tool.\n  Results: Transformer-based models significantly outperformed CNNs, with the Swin Transformer achieving the best results (86\\\\% accuracy). LIME and Grad-CAM visualizations confirmed that the models attended to lesion-relevant regions, increasing clinical transparency and aiding in error analysis. The framework also demonstrated strong performance on external validation samples, confirming its ability to generalize beyond the curated dataset.\n  Conclusion: The proposed framework demonstrates the potential of deep learning for non-invasive, accessible, and explainable diagnosis of arsenicosis from mobile-acquired images. By enabling reliable image-based screening, it can serve as a practical diagnostic aid in rural and resource-limited communities, where access to dermatologists is scarce, thereby supporting early detection and timely intervention.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.08780v1",
    "published_date": "2025-09-10 17:08:31 UTC",
    "updated_date": "2025-09-10 17:08:31 UTC"
  },
  {
    "arxiv_id": "2509.08756v1",
    "title": "Using AI to Optimize Patient Transfer and Resource Utilization During Mass-Casualty Incidents: A Simulation Platform",
    "authors": [
      "Zhaoxun \"Lorenz\" Liu",
      "Wagner H. Souza",
      "Jay Han",
      "Amin Madani"
    ],
    "abstract": "Mass casualty incidents (MCIs) overwhelm healthcare systems and demand rapid, accurate patient-hospital allocation decisions under extreme pressure. Here, we developed and validated a deep reinforcement learning-based decision-support AI agent to optimize patient transfer decisions during simulated MCIs by balancing patient acuity levels, specialized care requirements, hospital capacities, and transport logistics. To integrate this AI agent, we developed MasTER, a web-accessible command dashboard for MCI management simulations. Through a controlled user study with 30 participants (6 trauma experts and 24 non-experts), we evaluated three interaction approaches with the AI agent (human-only, human-AI collaboration, and AI-only) across 20- and 60-patient MCI scenarios in the Greater Toronto Area. Results demonstrate that increasing AI involvement significantly improves decision quality and consistency. The AI agent outperforms trauma surgeons (p < 0.001) and enables non-experts to achieve expert-level performance when assisted, contrasting sharply with their significantly inferior unassisted performance (p < 0.001). These findings establish the potential for our AI-driven decision support to enhance both MCI preparedness training and real-world emergency response management.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.08756v1",
    "published_date": "2025-09-10 16:46:54 UTC",
    "updated_date": "2025-09-10 16:46:54 UTC"
  },
  {
    "arxiv_id": "2509.08755v1",
    "title": "AgentGym-RL: Training LLM Agents for Long-Horizon Decision Making through Multi-Turn Reinforcement Learning",
    "authors": [
      "Zhiheng Xi",
      "Jixuan Huang",
      "Chenyang Liao",
      "Baodai Huang",
      "Honglin Guo",
      "Jiaqi Liu",
      "Rui Zheng",
      "Junjie Ye",
      "Jiazheng Zhang",
      "Wenxiang Chen",
      "Wei He",
      "Yiwen Ding",
      "Guanyu Li",
      "Zehui Chen",
      "Zhengyin Du",
      "Xuesong Yao",
      "Yufei Xu",
      "Jiecao Chen",
      "Tao Gui",
      "Zuxuan Wu",
      "Qi Zhang",
      "Xuanjing Huang",
      "Yu-Gang Jiang"
    ],
    "abstract": "Developing autonomous LLM agents capable of making a series of intelligent decisions to solve complex, real-world tasks is a fast-evolving frontier. Like human cognitive development, agents are expected to acquire knowledge and skills through exploration and interaction with the environment. Despite advances, the community still lacks a unified, interactive reinforcement learning (RL) framework that can effectively train such agents from scratch -- without relying on supervised fine-tuning (SFT) -- across diverse and realistic environments. To bridge this gap, we introduce AgentGym-RL, a new framework to train LLM agents for multi-turn interactive decision-making through RL. The framework features a modular and decoupled architecture, ensuring high flexibility and extensibility. It encompasses a wide variety of real-world scenarios, and supports mainstream RL algorithms. Furthermore, we propose ScalingInter-RL, a training approach designed for exploration-exploitation balance and stable RL optimization. In early stages, it emphasizes exploitation by restricting the number of interactions, and gradually shifts towards exploration with larger horizons to encourage diverse problem-solving strategies. In this way, the agent develops more diverse behaviors and is less prone to collapse under long horizons. We perform extensive experiments to validate the stability and effectiveness of both the AgentGym-RL framework and the ScalingInter-RL approach. Our agents match or surpass commercial models on 27 tasks across diverse environments. We offer key insights and will open-source the complete AgentGym-RL framework -- including code and datasets -- to empower the research community in developing the next generation of intelligent agents.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "preprint, 39 pages, 16 figures. Project: https://AgentGym-RL.github.io/. Framework and Code: https://github.com/woooodyy/AgentGym, https://github.com/woooodyy/AgentGym-RL",
    "pdf_url": "https://arxiv.org/pdf/2509.08755v1",
    "published_date": "2025-09-10 16:46:11 UTC",
    "updated_date": "2025-09-10 16:46:11 UTC"
  },
  {
    "arxiv_id": "2509.08752v1",
    "title": "Learning Turbulent Flows with Generative Models: Super-resolution, Forecasting, and Sparse Flow Reconstruction",
    "authors": [
      "Vivek Oommen",
      "Siavash Khodakarami",
      "Aniruddha Bora",
      "Zhicheng Wang",
      "George Em Karniadakis"
    ],
    "abstract": "Neural operators are promising surrogates for dynamical systems but when trained with standard L2 losses they tend to oversmooth fine-scale turbulent structures. Here, we show that combining operator learning with generative modeling overcomes this limitation. We consider three practical turbulent-flow challenges where conventional neural operators fail: spatio-temporal super-resolution, forecasting, and sparse flow reconstruction. For Schlieren jet super-resolution, an adversarially trained neural operator (adv-NO) reduces the energy-spectrum error by 15x while preserving sharp gradients at neural operator-like inference cost. For 3D homogeneous isotropic turbulence, adv-NO trained on only 160 timesteps from a single trajectory forecasts accurately for five eddy-turnover times and offers 114x wall-clock speed-up at inference than the baseline diffusion-based forecasters, enabling near-real-time rollouts. For reconstructing cylinder wake flows from highly sparse Particle Tracking Velocimetry-like inputs, a conditional generative model infers full 3D velocity and pressure fields with correct phase alignment and statistics. These advances enable accurate reconstruction and forecasting at low compute cost, bringing near-real-time analysis and control within reach in experimental and computational fluid mechanics. See our project page: https://vivekoommen.github.io/Gen4Turb/",
    "categories": [
      "physics.flu-dyn",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "physics.flu-dyn",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.08752v1",
    "published_date": "2025-09-10 16:42:22 UTC",
    "updated_date": "2025-09-10 16:42:22 UTC"
  },
  {
    "arxiv_id": "2509.08742v1",
    "title": "FinZero: Launching Multi-modal Financial Time Series Forecast with Large Reasoning Model",
    "authors": [
      "Yanlong Wang",
      "Jian Xu",
      "Fei Ma",
      "Hongkang Zhang",
      "Hang Yu",
      "Tiantian Gao",
      "Yu Wang",
      "Haochen You",
      "Shao-Lun Huang",
      "Danny Dongning Sun",
      "Xiao-Ping Zhang"
    ],
    "abstract": "Financial time series forecasting is both highly significant and challenging. Previous approaches typically standardized time series data before feeding it into forecasting models, but this encoding process inherently leads to a loss of important information. Moreover, past time series models generally require fixed numbers of variables or lookback window lengths, which further limits the scalability of time series forecasting. Besides, the interpretability and the uncertainty in forecasting remain areas requiring further research, as these factors directly impact the reliability and practical value of predictions. To address these issues, we first construct a diverse financial image-text dataset (FVLDB) and develop the Uncertainty-adjusted Group Relative Policy Optimization (UARPO) method to enable the model not only output predictions but also analyze the uncertainty of those predictions. We then proposed FinZero, a multimodal pre-trained model finetuned by UARPO to perform reasoning, prediction, and analytical understanding on the FVLDB financial time series. Extensive experiments validate that FinZero exhibits strong adaptability and scalability. After fine-tuning with UARPO, FinZero achieves an approximate 13.48\\% improvement in prediction accuracy over GPT-4o in the high-confidence group, demonstrating the effectiveness of reinforcement learning fine-tuning in multimodal large model, including in financial time series forecasting tasks.",
    "categories": [
      "q-fin.CP",
      "cs.AI"
    ],
    "primary_category": "q-fin.CP",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.08742v1",
    "published_date": "2025-09-10 16:32:41 UTC",
    "updated_date": "2025-09-10 16:32:41 UTC"
  },
  {
    "arxiv_id": "2509.08734v1",
    "title": "DEQuify your force field: More efficient simulations using deep equilibrium models",
    "authors": [
      "Andreas Burger",
      "Luca Thiede",
      "Alán Aspuru-Guzik",
      "Nandita Vijaykumar"
    ],
    "abstract": "Machine learning force fields show great promise in enabling more accurate molecular dynamics simulations compared to manually derived ones. Much of the progress in recent years was driven by exploiting prior knowledge about physical systems, in particular symmetries under rotation, translation, and reflections. In this paper, we argue that there is another important piece of prior information that, thus fa,r hasn't been explored: Simulating a molecular system is necessarily continuous, and successive states are therefore extremely similar. Our contribution is to show that we can exploit this information by recasting a state-of-the-art equivariant base model as a deep equilibrium model. This allows us to recycle intermediate neural network features from previous time steps, enabling us to improve both accuracy and speed by $10\\%-20\\%$ on the MD17, MD22, and OC20 200k datasets, compared to the non-DEQ base model. The training is also much more memory efficient, allowing us to train more expressive models on larger systems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "AI4MAT-ICLR-2025 Spotlight https://openreview.net/forum?id=XACVRYePQQ",
    "pdf_url": "https://arxiv.org/pdf/2509.08734v1",
    "published_date": "2025-09-10 16:23:52 UTC",
    "updated_date": "2025-09-10 16:23:52 UTC"
  },
  {
    "arxiv_id": "2509.08729v3",
    "title": "X-Teaming Evolutionary M2S: Automated Discovery of Multi-turn to Single-turn Jailbreak Templates",
    "authors": [
      "Hyunjun Kim",
      "Junwoo Ha",
      "Sangyoon Yu",
      "Haon Park"
    ],
    "abstract": "Multi-turn-to-single-turn (M2S) compresses iterative red-teaming into one structured prompt, but prior work relied on a handful of manually written templates. We present X-Teaming Evolutionary M2S, an automated framework that discovers and optimizes M2S templates through language-model-guided evolution. The system pairs smart sampling from 12 sources with an LLM-as-judge inspired by StrongREJECT and records fully auditable logs.\n  Maintaining selection pressure by setting the success threshold to $θ= 0.70$, we obtain five evolutionary generations, two new template families, and 44.8% overall success (103/230) on GPT-4.1. A balanced cross-model panel of 2,500 trials (judge fixed) shows that structural gains transfer but vary by target; two models score zero at the same threshold. We also find a positive coupling between prompt length and score, motivating length-aware judging.\n  Our results demonstrate that structure-level search is a reproducible route to stronger single-turn probes and underscore the importance of threshold calibration and cross-model evaluation. Code, configurations, and artifacts are available at https://github.com/hyunjun1121/M2S-x-teaming.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "NeurIPS 2025 Workshop on Lock-LLM",
    "pdf_url": "https://arxiv.org/pdf/2509.08729v3",
    "published_date": "2025-09-10 16:17:44 UTC",
    "updated_date": "2025-10-08 19:54:46 UTC"
  },
  {
    "arxiv_id": "2509.08717v1",
    "title": "Explainability of CNN Based Classification Models for Acoustic Signal",
    "authors": [
      "Zubair Faruqui",
      "Mackenzie S. McIntire",
      "Rahul Dubey",
      "Jay McEntee"
    ],
    "abstract": "Explainable Artificial Intelligence (XAI) has emerged as a critical tool for interpreting the predictions of complex deep learning models. While XAI has been increasingly applied in various domains within acoustics, its use in bioacoustics, which involves analyzing audio signals from living organisms, remains relatively underexplored. In this paper, we investigate the vocalizations of a bird species with strong geographic variation throughout its range in North America. Audio recordings were converted into spectrogram images and used to train a deep Convolutional Neural Network (CNN) for classification, achieving an accuracy of 94.8\\%. To interpret the model's predictions, we applied both model-agnostic (LIME, SHAP) and model-specific (DeepLIFT, Grad-CAM) XAI techniques. These techniques produced different but complementary explanations, and when their explanations were considered together, they provided more complete and interpretable insights into the model's decision-making. This work highlights the importance of using a combination of XAI techniques to improve trust and interoperability, not only in broader acoustics signal analysis but also argues for broader applicability in different domain specific tasks.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted in IEEE ICTAI 2025",
    "pdf_url": "https://arxiv.org/pdf/2509.08717v1",
    "published_date": "2025-09-10 16:11:01 UTC",
    "updated_date": "2025-09-10 16:11:01 UTC"
  },
  {
    "arxiv_id": "2509.08713v2",
    "title": "The More You Automate, the Less You See: Hidden Pitfalls of AI Scientist Systems",
    "authors": [
      "Ziming Luo",
      "Atoosa Kasirzadeh",
      "Nihar B. Shah"
    ],
    "abstract": "AI scientist systems, capable of autonomously executing the full research workflow from hypothesis generation and experimentation to paper writing, hold significant potential for accelerating scientific discovery. However, the internal workflow of these systems have not been closely examined. This lack of scrutiny poses a risk of introducing flaws that could undermine the integrity, reliability, and trustworthiness of their research outputs. In this paper, we identify four potential failure modes in contemporary AI scientist systems: inappropriate benchmark selection, data leakage, metric misuse, and post-hoc selection bias. To examine these risks, we design controlled experiments that isolate each failure mode while addressing challenges unique to evaluating AI scientist systems. Our assessment of two prominent open-source AI scientist systems reveals the presence of several failures, across a spectrum of severity, which can be easily overlooked in practice. Finally, we demonstrate that access to trace logs and code from the full automated workflow enables far more effective detection of such failures than examining the final paper alone. We thus recommend journals and conferences evaluating AI-generated research to mandate submission of these artifacts alongside the paper to ensure transparency, accountability, and reproducibility.",
    "categories": [
      "cs.AI",
      "cs.DL"
    ],
    "primary_category": "cs.AI",
    "comment": "NeurIPS 2025 AI4Science (Spotlight)",
    "pdf_url": "https://arxiv.org/pdf/2509.08713v2",
    "published_date": "2025-09-10 16:04:24 UTC",
    "updated_date": "2025-12-20 05:26:07 UTC"
  },
  {
    "arxiv_id": "2509.08705v1",
    "title": "One Model, Two Minds: A Context-Gated Graph Learner that Recreates Human Biases",
    "authors": [
      "Shalima Binta Manir",
      "Tim Oates"
    ],
    "abstract": "We introduce a novel Theory of Mind (ToM) framework inspired by dual-process theories from cognitive science, integrating a fast, habitual graph-based reasoning system (System 1), implemented via graph convolutional networks (GCNs), and a slower, context-sensitive meta-adaptive learning system (System 2), driven by meta-learning techniques. Our model dynamically balances intuitive and deliberative reasoning through a learned context gate mechanism. We validate our architecture on canonical false-belief tasks and systematically explore its capacity to replicate hallmark cognitive biases associated with dual-process theory, including anchoring, cognitive-load fatigue, framing effects, and priming effects. Experimental results demonstrate that our dual-process approach closely mirrors human adaptive behavior, achieves robust generalization to unseen contexts, and elucidates cognitive mechanisms underlying reasoning biases. This work bridges artificial intelligence and cognitive theory, paving the way for AI systems exhibiting nuanced, human-like social cognition and adaptive decision-making capabilities.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages, 7 figures, 2 tables",
    "pdf_url": "https://arxiv.org/pdf/2509.08705v1",
    "published_date": "2025-09-10 15:55:14 UTC",
    "updated_date": "2025-09-10 15:55:14 UTC"
  },
  {
    "arxiv_id": "2509.08699v1",
    "title": "TANGO: Traversability-Aware Navigation with Local Metric Control for Topological Goals",
    "authors": [
      "Stefan Podgorski",
      "Sourav Garg",
      "Mehdi Hosseinzadeh",
      "Lachlan Mares",
      "Feras Dayoub",
      "Ian Reid"
    ],
    "abstract": "Visual navigation in robotics traditionally relies on globally-consistent 3D maps or learned controllers, which can be computationally expensive and difficult to generalize across diverse environments. In this work, we present a novel RGB-only, object-level topometric navigation pipeline that enables zero-shot, long-horizon robot navigation without requiring 3D maps or pre-trained controllers. Our approach integrates global topological path planning with local metric trajectory control, allowing the robot to navigate towards object-level sub-goals while avoiding obstacles. We address key limitations of previous methods by continuously predicting local trajectory using monocular depth and traversability estimation, and incorporating an auto-switching mechanism that falls back to a baseline controller when necessary. The system operates using foundational models, ensuring open-set applicability without the need for domain-specific fine-tuning. We demonstrate the effectiveness of our method in both simulated environments and real-world tests, highlighting its robustness and deployability. Our approach outperforms existing state-of-the-art methods, offering a more adaptable and effective solution for visual navigation in open-set environments. The source code is made publicly available: https://github.com/podgorki/TANGO.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "9 pages, 5 figures, ICRA 2025",
    "pdf_url": "https://arxiv.org/pdf/2509.08699v1",
    "published_date": "2025-09-10 15:43:32 UTC",
    "updated_date": "2025-09-10 15:43:32 UTC"
  },
  {
    "arxiv_id": "2509.08682v1",
    "title": "Automatic Failure Attribution and Critical Step Prediction Method for Multi-Agent Systems Based on Causal Inference",
    "authors": [
      "Guoqing Ma",
      "Jia Zhu",
      "Hanghui Guo",
      "Weijie Shi",
      "Jiawei Shen",
      "Jingjiang Liu",
      "Yidan Liang"
    ],
    "abstract": "Multi-agent systems (MAS) are critical for automating complex tasks, yet their practical deployment is severely hampered by the challenge of failure attribution. Current diagnostic tools, which rely on statistical correlations, are fundamentally inadequate; on challenging benchmarks like Who\\&When, state-of-the-art methods achieve less than 15\\% accuracy in locating the root-cause step of a failure. To address this critical gap, we introduce the first failure attribution framework for MAS grounded in multi-granularity causal inference. Our approach makes two key technical contributions: (1) a performance causal inversion principle, which correctly models performance dependencies by reversing the data flow in execution logs, combined with Shapley values to accurately assign agent-level blame; (2) a novel causal discovery algorithm, CDC-MAS, that robustly identifies critical failure steps by tackling the non-stationary nature of MAS interaction data. The framework's attribution results directly fuel an automated optimization loop, generating targeted suggestions whose efficacy is validated via counterfactual simulations. Evaluations on the Who\\&When and TRAIL benchmarks demonstrate a significant leap in performance. Our method achieves up to 36.2\\% step-level accuracy. Crucially, the generated optimizations boost overall task success rates by an average of 22.4\\%. This work provides a principled and effective solution for debugging complex agent interactions, paving the way for more reliable and interpretable multi-agent systems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.08682v1",
    "published_date": "2025-09-10 15:22:00 UTC",
    "updated_date": "2025-09-10 15:22:00 UTC"
  },
  {
    "arxiv_id": "2509.14249v1",
    "title": "Advancing Conversational AI with Shona Slang: A Dataset and Hybrid Model for Digital Inclusion",
    "authors": [
      "Happymore Masoka"
    ],
    "abstract": "African languages remain underrepresented in natural language processing (NLP), with most corpora limited to formal registers that fail to capture the vibrancy of everyday communication. This work addresses this gap for Shona, a Bantu language spoken in Zimbabwe and Zambia, by introducing a novel Shona--English slang dataset curated from anonymized social media conversations. The dataset is annotated for intent, sentiment, dialogue acts, code-mixing, and tone, and is publicly available at https://github.com/HappymoreMasoka/Working_with_shona-slang. We fine-tuned a multilingual DistilBERT classifier for intent recognition, achieving 96.4\\% accuracy and 96.3\\% F1-score, hosted at https://huggingface.co/HappymoreMasoka. This classifier is integrated into a hybrid chatbot that combines rule-based responses with retrieval-augmented generation (RAG) to handle domain-specific queries, demonstrated through a use case assisting prospective students with graduate program information at Pace University. Qualitative evaluation shows the hybrid system outperforms a RAG-only baseline in cultural relevance and user engagement. By releasing the dataset, model, and methodology, this work advances NLP resources for African languages, promoting inclusive and culturally resonant conversational AI.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.14249v1",
    "published_date": "2025-09-10 15:13:51 UTC",
    "updated_date": "2025-09-10 15:13:51 UTC"
  },
  {
    "arxiv_id": "2509.08661v2",
    "title": "Skeleton-based sign language recognition using a dual-stream spatio-temporal dynamic graph convolutional network",
    "authors": [
      "Liangjin Liu",
      "Haoyang Zheng",
      "Zhengzhong Zhu",
      "Pei Zhou"
    ],
    "abstract": "Isolated Sign Language Recognition (ISLR) is challenged by gestures that are morphologically similar yet semantically distinct, a problem rooted in the complex interplay between hand shape and motion trajectory. Existing methods, often relying on a single reference frame, struggle to resolve this geometric ambiguity. This paper introduces Dual-SignLanguageNet (DSLNet), a dual-reference, dual-stream architecture that decouples and models gesture morphology and trajectory in separate, complementary coordinate systems. The architecture processes these streams through specialized networks: a topology-aware graph convolution models the view-invariant shape from a wrist-centric frame, while a Finsler geometry-based encoder captures the context-aware trajectory from a facial-centric frame. These features are then integrated via a geometry-driven optimal transport fusion mechanism. DSLNet sets a new state-of-the-art, achieving 93.70%, 89.97%, and 99.79% accuracy on the challenging WLASL-100, WLASL-300, and LSA64 datasets, respectively, with significantly fewer parameters than competing models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "5 pages, 3 figures",
    "pdf_url": "https://arxiv.org/pdf/2509.08661v2",
    "published_date": "2025-09-10 14:58:21 UTC",
    "updated_date": "2025-09-18 03:22:49 UTC"
  },
  {
    "arxiv_id": "2509.08654v1",
    "title": "Robust Belief-State Policy Learning for Quantum Network Routing Under Decoherence and Time-Varying Conditions",
    "authors": [
      "Amirhossein Taherpour",
      "Abbas Taherpour",
      "Tamer Khattab"
    ],
    "abstract": "This paper presents a feature-based Partially Observable Markov Decision Process (POMDP) framework for quantum network routing, combining belief-state planning with Graph Neural Networks (GNNs) to address partial observability, decoherence, and scalability challenges in dynamic quantum systems. Our approach encodes complex quantum network dynamics, including entanglement degradation and time-varying channel noise, into a low-dimensional feature space, enabling efficient belief updates and scalable policy learning. The core of our framework is a hybrid GNN-POMDP architecture that processes graph-structured representations of entangled links to learn routing policies, coupled with a noise-adaptive mechanism that fuses POMDP belief updates with GNN outputs for robust decision making. We provide a theoretical analysis establishing guarantees for belief convergence, policy improvement, and robustness to noise. Experiments on simulated quantum networks with up to 100 nodes demonstrate significant improvements in routing fidelity and entanglement delivery rates compared to state-of-the-art baselines, particularly under high decoherence and nonstationary conditions.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.LG",
      "cs.NI"
    ],
    "primary_category": "quant-ph",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.08654v1",
    "published_date": "2025-09-10 14:50:03 UTC",
    "updated_date": "2025-09-10 14:50:03 UTC"
  },
  {
    "arxiv_id": "2509.08646v1",
    "title": "Architecting Resilient LLM Agents: A Guide to Secure Plan-then-Execute Implementations",
    "authors": [
      "Ron F. Del Rosario",
      "Klaudia Krawiecka",
      "Christian Schroeder de Witt"
    ],
    "abstract": "As Large Language Model (LLM) agents become increasingly capable of automating complex, multi-step tasks, the need for robust, secure, and predictable architectural patterns is paramount. This paper provides a comprehensive guide to the ``Plan-then-Execute'' (P-t-E) pattern, an agentic design that separates strategic planning from tactical execution. We explore the foundational principles of P-t-E, detailing its core components - the Planner and the Executor - and its architectural advantages in predictability, cost-efficiency, and reasoning quality over reactive patterns like ReAct (Reason + Act). A central focus is placed on the security implications of this design, particularly its inherent resilience to indirect prompt injection attacks by establishing control-flow integrity. We argue that while P-t-E provides a strong foundation, a defense-in-depth strategy is necessary, and we detail essential complementary controls such as the Principle of Least Privilege, task-scoped tool access, and sandboxed code execution. To make these principles actionable, this guide provides detailed implementation blueprints and working code references for three leading agentic frameworks: LangChain (via LangGraph), CrewAI, and AutoGen. Each framework's approach to implementing the P-t-E pattern is analyzed, highlighting unique features like LangGraph's stateful graphs for re-planning, CrewAI's declarative tool scoping for security, and AutoGen's built-in Docker sandboxing. Finally, we discuss advanced patterns, including dynamic re-planning loops, parallel execution with Directed Acyclic Graphs (DAGs), and the critical role of Human-in-the-Loop (HITL) verification, to offer a complete strategic blueprint for architects, developers, and security engineers aiming to build production-grade, resilient, and trustworthy LLM agents.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "eess.SY"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.08646v1",
    "published_date": "2025-09-10 14:41:07 UTC",
    "updated_date": "2025-09-10 14:41:07 UTC"
  },
  {
    "arxiv_id": "2509.08640v1",
    "title": "RoentMod: A Synthetic Chest X-Ray Modification Model to Identify and Correct Image Interpretation Model Shortcuts",
    "authors": [
      "Lauren H. Cooke",
      "Matthias Jung",
      "Jan M. Brendel",
      "Nora M. Kerkovits",
      "Borek Foldyna",
      "Michael T. Lu",
      "Vineet K. Raghu"
    ],
    "abstract": "Chest radiographs (CXRs) are among the most common tests in medicine. Automated image interpretation may reduce radiologists\\' workload and expand access to diagnostic expertise. Deep learning multi-task and foundation models have shown strong performance for CXR interpretation but are vulnerable to shortcut learning, where models rely on spurious and off-target correlations rather than clinically relevant features to make decisions. We introduce RoentMod, a counterfactual image editing framework that generates anatomically realistic CXRs with user-specified, synthetic pathology while preserving unrelated anatomical features of the original scan. RoentMod combines an open-source medical image generator (RoentGen) with an image-to-image modification model without requiring retraining. In reader studies with board-certified radiologists and radiology residents, RoentMod-produced images appeared realistic in 93\\% of cases, correctly incorporated the specified finding in 89-99\\% of cases, and preserved native anatomy comparable to real follow-up CXRs. Using RoentMod, we demonstrate that state-of-the-art multi-task and foundation models frequently exploit off-target pathology as shortcuts, limiting their specificity. Incorporating RoentMod-generated counterfactual images during training mitigated this vulnerability, improving model discrimination across multiple pathologies by 3-19\\% AUC in internal validation and by 1-11\\% for 5 out of 6 tested pathologies in external testing. These findings establish RoentMod as a broadly applicable tool for probing and correcting shortcut learning in medical AI. By enabling controlled counterfactual interventions, RoentMod enhances the robustness and interpretability of CXR interpretation models and provides a generalizable strategy for improving foundation models in medical imaging.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "25 + 8 pages, 4 + 7 figures",
    "pdf_url": "https://arxiv.org/pdf/2509.08640v1",
    "published_date": "2025-09-10 14:35:24 UTC",
    "updated_date": "2025-09-10 14:35:24 UTC"
  },
  {
    "arxiv_id": "2509.08624v1",
    "title": "UOPSL: Unpaired OCT Predilection Sites Learning for Fundus Image Diagnosis Augmentation",
    "authors": [
      "Zhihao Zhao",
      "Yinzheng Zhao",
      "Junjie Yang",
      "Xiangtong Yao",
      "Quanmin Liang",
      "Daniel Zapp",
      "Kai Huang",
      "Nassir Navab",
      "M. Ali Nasseri"
    ],
    "abstract": "Significant advancements in AI-driven multimodal medical image diagnosis have led to substantial improvements in ophthalmic disease identification in recent years. However, acquiring paired multimodal ophthalmic images remains prohibitively expensive. While fundus photography is simple and cost-effective, the limited availability of OCT data and inherent modality imbalance hinder further progress. Conventional approaches that rely solely on fundus or textual features often fail to capture fine-grained spatial information, as each imaging modality provides distinct cues about lesion predilection sites. In this study, we propose a novel unpaired multimodal framework \\UOPSL that utilizes extensive OCT-derived spatial priors to dynamically identify predilection sites, enhancing fundus image-based disease recognition. Our approach bridges unpaired fundus and OCTs via extended disease text descriptions. Initially, we employ contrastive learning on a large corpus of unpaired OCT and fundus images while simultaneously learning the predilection sites matrix in the OCT latent space. Through extensive optimization, this matrix captures lesion localization patterns within the OCT feature space. During the fine-tuning or inference phase of the downstream classification task based solely on fundus images, where paired OCT data is unavailable, we eliminate OCT input and utilize the predilection sites matrix to assist in fundus image classification learning. Extensive experiments conducted on 9 diverse datasets across 28 critical categories demonstrate that our framework outperforms existing benchmarks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "BIBM",
    "pdf_url": "https://arxiv.org/pdf/2509.08624v1",
    "published_date": "2025-09-10 14:19:59 UTC",
    "updated_date": "2025-09-10 14:19:59 UTC"
  },
  {
    "arxiv_id": "2509.08612v2",
    "title": "OTESGN: Optimal Transport-Enhanced Syntactic-Semantic Graph Networks for Aspect-Based Sentiment Analysis",
    "authors": [
      "Xinfeng Liao",
      "Xuanqi Chen",
      "Lianxi Wang",
      "Jiahuan Yang",
      "Zhuowei Chen",
      "Ziying Rong"
    ],
    "abstract": "Aspect-based sentiment analysis (ABSA) aims to identify aspect terms and determine their sentiment polarity. While dependency trees combined with contextual semantics provide structural cues, existing approaches often rely on dot-product similarity and fixed graphs, which limit their ability to capture nonlinear associations and adapt to noisy contexts. To address these limitations, we propose the Optimal Transport-Enhanced Syntactic-Semantic Graph Network (OTESGN), a model that jointly integrates structural and distributional signals. Specifically, a Syntactic Graph-Aware Attention module models global dependencies with syntax-guided masking, while a Semantic Optimal Transport Attention module formulates aspect-opinion association as a distribution matching problem solved via the Sinkhorn algorithm. An Adaptive Attention Fusion mechanism balances heterogeneous features, and contrastive regularization enhances robustness. Extensive experiments on three benchmark datasets (Rest14, Laptop14, and Twitter) demonstrate that OTESGN delivers state-of-the-art performance. Notably, it surpasses competitive baselines by up to +1.30 Macro-F1 on Laptop14 and +1.01 on Twitter. Ablation studies and visualization analyses further highlight OTESGN's ability to capture fine-grained sentiment associations and suppress noise from irrelevant context.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.08612v2",
    "published_date": "2025-09-10 14:08:58 UTC",
    "updated_date": "2025-09-11 02:55:43 UTC"
  },
  {
    "arxiv_id": "2509.09734v1",
    "title": "MCP-AgentBench: Evaluating Real-World Language Agent Performance with MCP-Mediated Tools",
    "authors": [
      "Zikang Guo",
      "Benfeng Xu",
      "Chiwei Zhu",
      "Wentao Hong",
      "Xiaorui Wang",
      "Zhendong Mao"
    ],
    "abstract": "The Model Context Protocol (MCP) is rapidly emerging as a pivotal open standard, designed to enhance agent-tool integration and interoperability, and is positioned to unlock a new era of powerful, interconnected, and genuinely utilitarian agentic AI. However, despite MCP's growing adoption, existing benchmarks often fail to capture real-world agent performance within this new paradigm, leading to a distorted perception of their true operational value and an inability to reliably differentiate proficiencies. To bridge this critical evaluation gap, we introduce MCP-AgentBench -- a comprehensive benchmark specifically engineered to rigorously assess language agent capabilities in MCP-mediated tool interactions. Core contributions of MCP-AgentBench include: the establishment of a robust MCP testbed comprising 33 operational servers with 188 distinct tools; the development of a benchmark featuring 600 systematically designed queries distributed across 6 distinct categories of varying interaction complexity; and the introduction of MCP-Eval, a novel outcome-oriented evaluation methodology prioritizing real-world task success. Through extensive empirical evaluation of leading language agents, we provide foundational insights. MCP-AgentBench aims to equip the research community with a standardized and reliable framework to build, validate, and advance agents capable of fully leveraging MCP's transformative benefits, thereby accelerating progress toward truly capable and interoperable AI systems.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.09734v1",
    "published_date": "2025-09-10 14:08:40 UTC",
    "updated_date": "2025-09-10 14:08:40 UTC"
  },
  {
    "arxiv_id": "2509.08606v1",
    "title": "Classification of 24-hour movement behaviors from wrist-worn accelerometer data: from handcrafted features to deep learning techniques",
    "authors": [
      "Alireza Sameh",
      "Mehrdad Rostami",
      "Mourad Oussalah",
      "Vahid Farrahi"
    ],
    "abstract": "Purpose: We compared the performance of deep learning (DL) and classical machine learning (ML) algorithms for the classification of 24-hour movement behavior into sleep, sedentary, light intensity physical activity (LPA), and moderate-to-vigorous intensity physical activity (MVPA). Methods: Open-access data from 151 adults wearing a wrist-worn accelerometer (Axivity-AX3) was used. Participants were randomly divided into training, validation, and test sets (121, 15, and 15 participants each). Raw acceleration signals were segmented into non-overlapping 10-second windows, and then a total of 104 handcrafted features were extracted. Four DL algorithms-Long Short-Term Memory (LSTM), Bidirectional Long Short-Term Memory (BiLSTM), Gated Recurrent Units (GRU), and One-Dimensional Convolutional Neural Network (1D-CNN)-were trained using raw acceleration signals and with handcrafted features extracted from these signals to predict 24-hour movement behavior categories. The handcrafted features were also used to train classical ML algorithms, namely Random Forest (RF), Support Vector Machine (SVM), Extreme Gradient Boosting (XGBoost), Logistic Regression (LR), Artificial Neural Network (ANN), and Decision Tree (DT) for classifying 24-hour movement behavior intensities. Results: LSTM, BiLSTM, and GRU showed an overall accuracy of approximately 85% when trained with raw acceleration signals, and 1D-CNN an overall accuracy of approximately 80%. When trained on handcrafted features, the overall accuracy for both DL and classical ML algorithms ranged from 70% to 81%. Overall, there was a higher confusion in classification of MVPA and LPA, compared to sleep and sedentary categories. Conclusion: DL methods with raw acceleration signals had only slightly better performance in predicting 24-hour movement behavior intensities, compared to when DL and classical ML were trained with handcrafted features.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.08606v1",
    "published_date": "2025-09-10 14:04:51 UTC",
    "updated_date": "2025-09-10 14:04:51 UTC"
  },
  {
    "arxiv_id": "2509.08604v3",
    "title": "Memorization in Large Language Models in Medicine: Prevalence, Characteristics, and Implications",
    "authors": [
      "Anran Li",
      "Lingfei Qian",
      "Mengmeng Du",
      "Yu Yin",
      "Yan Hu",
      "Zihao Sun",
      "Yihang Fu",
      "Hyunjae Kim",
      "Erica Stutz",
      "Xuguang Ai",
      "Qianqian Xie",
      "Rui Zhu",
      "Jimin Huang",
      "Yifan Yang",
      "Siru Liu",
      "Yih-Chung Tham",
      "Lucila Ohno-Machado",
      "Hyunghoon Cho",
      "Zhiyong Lu",
      "Hua Xu",
      "Qingyu Chen"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated significant potential in medicine, with many studies adapting them through continued pre-training or fine-tuning on medical data to enhance domain-specific accuracy and safety. However, a key open question remains: to what extent do LLMs memorize medical training data. Memorization can be beneficial when it enables LLMs to retain valuable medical knowledge during domain adaptation. Yet, it also raises concerns. LLMs may inadvertently reproduce sensitive clinical content (e.g., patient-specific details), and excessive memorization may reduce model generalizability, increasing risks of misdiagnosis and making unwarranted recommendations. These risks are further amplified by the generative nature of LLMs, which can not only surface memorized content but also produce overconfident, misleading outputs that may hinder clinical adoption. In this work, we present a study on memorization of LLMs in medicine, assessing its prevalence (how frequently it occurs), characteristics (what is memorized), volume (how much content is memorized), and potential downstream impacts (how memorization may affect medical applications). We systematically analyze common adaptation scenarios: (1) continued pretraining on medical corpora, (2) fine-tuning on standard medical benchmarks, and (3) fine-tuning on real-world clinical data, including over 13,000 unique inpatient records from Yale New Haven Health System. The results demonstrate that memorization is prevalent across all adaptation scenarios and significantly higher than that reported in the general domain. Moreover, memorization has distinct characteristics during continued pre-training and fine-tuning, and it is persistent: up to 87% of content memorized during continued pre-training remains after fine-tuning on new medical tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.08604v3",
    "published_date": "2025-09-10 14:02:18 UTC",
    "updated_date": "2026-01-09 15:16:20 UTC"
  },
  {
    "arxiv_id": "2509.08593v1",
    "title": "No-Knowledge Alarms for Misaligned LLMs-as-Judges",
    "authors": [
      "Andrés Corrada-Emmanuel"
    ],
    "abstract": "If we use LLMs as judges to evaluate the complex decisions of other LLMs, who or what monitors the judges? Infinite monitoring chains are inevitable whenever we do not know the ground truth of the decisions by experts and we do not want to trust them. One way to ameliorate our evaluation uncertainty is to exploit the use of logical consistency between disagreeing experts. By observing how LLM judges agree and disagree while grading other LLMs, we can compute the only possible evaluations of their grading ability. For example, if two LLM judges disagree on which tasks a third one completed correctly, they cannot both be 100\\% correct in their judgments. This logic can be formalized as a Linear Programming problem in the space of integer response counts for any finite test. We use it here to develop no-knowledge alarms for misaligned LLM judges. The alarms can detect, with no false positives, that at least one member or more of an ensemble of judges are violating a user specified grading ability requirement.",
    "categories": [
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.AI",
    "comment": "7 pages, 1 figure",
    "pdf_url": "https://arxiv.org/pdf/2509.08593v1",
    "published_date": "2025-09-10 13:46:40 UTC",
    "updated_date": "2025-09-10 13:46:40 UTC"
  },
  {
    "arxiv_id": "2509.08592v2",
    "title": "Interpretability as Alignment: Making Internal Understanding a Design Principle",
    "authors": [
      "Aadit Sengupta",
      "Pratinav Seth",
      "Vinay Kumar Sankarapu"
    ],
    "abstract": "Frontier AI systems require governance mechanisms that can verify internal alignment, not just behavioral compliance. Private governance mechanisms audits, certification, insurance, and procurement are emerging to complement public regulation, but they require technical substrates that generate verifiable causal evidence about model behavior. This paper argues that mechanistic interpretability provides this substrate. We frame interpretability not as post-hoc explanation but as a design constraint embedding auditability, provenance, and bounded transparency within model architectures. Integrating causal abstraction theory and empirical benchmarks such as MIB and LoBOX, we outline how interpretability-first models can underpin private assurance pipelines and role-calibrated transparency frameworks. This reframing situates interpretability as infrastructure for private AI governance bridging the gap between technical reliability and institutional accountability.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at the first EurIPS Workshop on Private AI Governance",
    "pdf_url": "https://arxiv.org/pdf/2509.08592v2",
    "published_date": "2025-09-10 13:45:59 UTC",
    "updated_date": "2025-11-20 17:40:35 UTC"
  },
  {
    "arxiv_id": "2509.18120v1",
    "title": "A Coopetitive-Compatible Data Generation Framework for Cross-silo Federated Learning",
    "authors": [
      "Thanh Linh Nguyen",
      "Quoc-Viet Pham"
    ],
    "abstract": "Cross-silo federated learning (CFL) enables organizations (e.g., hospitals or banks) to collaboratively train artificial intelligence (AI) models while preserving data privacy by keeping data local. While prior work has primarily addressed statistical heterogeneity across organizations, a critical challenge arises from economic competition, where organizations may act as market rivals, making them hesitant to participate in joint training due to potential utility loss (i.e., reduced net benefit). Furthermore, the combined effects of statistical heterogeneity and inter-organizational competition on organizational behavior and system-wide social welfare remain underexplored. In this paper, we propose CoCoGen, a coopetitive-compatible data generation framework, leveraging generative AI (GenAI) and potential game theory to model, analyze, and optimize collaborative learning under heterogeneous and competitive settings. Specifically, CoCoGen characterizes competition and statistical heterogeneity through learning performance and utility-based formulations and models each training round as a weighted potential game. We then derive GenAI-based data generation strategies that maximize social welfare. Experimental results on the Fashion-MNIST dataset reveal how varying heterogeneity and competition levels affect organizational behavior and demonstrate that CoCoGen consistently outperforms baseline methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE",
      "cs.DC",
      "cs.GT"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted in IEEE GLOBECOM 2025",
    "pdf_url": "https://arxiv.org/pdf/2509.18120v1",
    "published_date": "2025-09-10 13:29:05 UTC",
    "updated_date": "2025-09-10 13:29:05 UTC"
  },
  {
    "arxiv_id": "2509.18119v2",
    "title": "MobileRL: Online Agentic Reinforcement Learning for Mobile GUI Agents",
    "authors": [
      "Yifan Xu",
      "Xiao Liu",
      "Xinghan Liu",
      "Jiaqi Fu",
      "Hanchen Zhang",
      "Bohao Jing",
      "Shudan Zhang",
      "Yuting Wang",
      "Wenyi Zhao",
      "Yuxiao Dong"
    ],
    "abstract": "Building general-purpose graphical user interface (GUI) agents has become increasingly promising with the progress in vision language models. However, developing effective mobile GUI agents with reinforcement learning (RL) remains challenging due to the heavy-tailed distribution of task difficulty and the inefficiency of large-scale environment sampling. We present an online agentic reinforcement learning framework MobileRL to enhance GUI agents in mobile environments. Its core component is the Difficulty-ADAptive GRPO (ADAGRPO) algorithm. In ADAGRPO, we design difficulty-adaptive positive replay and failure curriculum filtering to adapt the model to different task difficulties. We introduce the shortest-path reward adjustment strategy to reshape rewards concerning the task length in multi-turn agentic tasks. Those strategies jointly stabilize RL training, improve sample efficiency, and generate strong performance across diverse mobile apps and tasks. We apply MOBILERL to two open models (Qwen2.5-VL-7B-Instruct and GLM-4.1V-9B-Base). The resultant MOBILERL-9B model achieves state-of-the-art results in terms of success rates on both AndroidWorld (80.2%) and AndroidLab (53.6%). The MOBILERL framework is open-sourced at: https://github.com/THUDM/MobileRL.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.18119v2",
    "published_date": "2025-09-10 13:09:27 UTC",
    "updated_date": "2025-10-24 17:13:05 UTC"
  },
  {
    "arxiv_id": "2509.08538v2",
    "title": "MESH -- Understanding Videos Like Human: Measuring Hallucinations in Large Video Models",
    "authors": [
      "Garry Yang",
      "Zizhe Chen",
      "Man Hon Wong",
      "Haoyu Lei",
      "Yongqiang Chen",
      "Zhenguo Li",
      "Kaiwen Zhou",
      "James Cheng"
    ],
    "abstract": "Large Video Models (LVMs) build on the semantic capabilities of Large Language Models (LLMs) and vision modules by integrating temporal information to better understand dynamic video content. Despite their progress, LVMs are prone to hallucinations-producing inaccurate or irrelevant descriptions. Current benchmarks for video hallucination depend heavily on manual categorization of video content, neglecting the perception-based processes through which humans naturally interpret videos. We introduce MESH, a benchmark designed to evaluate hallucinations in LVMs systematically. MESH uses a Question-Answering framework with binary and multi-choice formats incorporating target and trap instances. It follows a bottom-up approach, evaluating basic objects, coarse-to-fine subject features, and subject-action pairs, aligning with human video understanding. We demonstrate that MESH offers an effective and comprehensive approach for identifying hallucinations in videos. Our evaluations show that while LVMs excel at recognizing basic objects and features, their susceptibility to hallucinations increases markedly when handling fine details or aligning multiple actions involving various subjects in longer videos.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.08538v2",
    "published_date": "2025-09-10 12:34:07 UTC",
    "updated_date": "2025-09-11 11:14:00 UTC"
  },
  {
    "arxiv_id": "2509.08535v1",
    "title": "Agents of Discovery",
    "authors": [
      "Sascha Diefenbacher",
      "Anna Hallin",
      "Gregor Kasieczka",
      "Michael Krämer",
      "Anne Lauscher",
      "Tim Lukas"
    ],
    "abstract": "The substantial data volumes encountered in modern particle physics and other domains of fundamental physics research allow (and require) the use of increasingly complex data analysis tools and workflows. While the use of machine learning (ML) tools for data analysis has recently proliferated, these tools are typically special-purpose algorithms that rely, for example, on encoded physics knowledge to reach optimal performance. In this work, we investigate a new and orthogonal direction: Using recent progress in large language models (LLMs) to create a team of agents -- instances of LLMs with specific subtasks -- that jointly solve data analysis-based research problems in a way similar to how a human researcher might: by creating code to operate standard tools and libraries (including ML systems) and by building on results of previous iterations. If successful, such agent-based systems could be deployed to automate routine analysis components to counteract the increasing complexity of modern tool chains. To investigate the capabilities of current-generation commercial LLMs, we consider the task of anomaly detection via the publicly available and highly-studied LHC Olympics dataset. Several current models by OpenAI (GPT-4o, o4-mini, GPT-4.1, and GPT-5) are investigated and their stability tested. Overall, we observe the capacity of the agent-based system to solve this data analysis problem. The best agent-created solutions mirror the performance of human state-of-the-art results.",
    "categories": [
      "hep-ph",
      "cs.AI",
      "cs.LG",
      "hep-ex",
      "physics.data-an"
    ],
    "primary_category": "hep-ph",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.08535v1",
    "published_date": "2025-09-10 12:25:13 UTC",
    "updated_date": "2025-09-10 12:25:13 UTC"
  },
  {
    "arxiv_id": "2509.08524v1",
    "title": "AutoStub: Genetic Programming-Based Stub Creation for Symbolic Execution",
    "authors": [
      "Felix Mächtle",
      "Nils Loose",
      "Jan-Niclas Serr",
      "Jonas Sander",
      "Thomas Eisenbarth"
    ],
    "abstract": "Symbolic execution is a powerful technique for software testing, but suffers from limitations when encountering external functions, such as native methods or third-party libraries. Existing solutions often require additional context, expensive SMT solvers, or manual intervention to approximate these functions through symbolic stubs. In this work, we propose a novel approach to automatically generate symbolic stubs for external functions during symbolic execution that leverages Genetic Programming. When the symbolic executor encounters an external function, AutoStub generates training data by executing the function on randomly generated inputs and collecting the outputs. Genetic Programming then derives expressions that approximate the behavior of the function, serving as symbolic stubs. These automatically generated stubs allow the symbolic executor to continue the analysis without manual intervention, enabling the exploration of program paths that were previously intractable. We demonstrate that AutoStub can automatically approximate external functions with over 90% accuracy for 55% of the functions evaluated, and can infer language-specific behaviors that reveal edge cases crucial for software testing.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.SE",
    "comment": "2025 HUMIES finalist",
    "pdf_url": "https://arxiv.org/pdf/2509.08524v1",
    "published_date": "2025-09-10 12:08:59 UTC",
    "updated_date": "2025-09-10 12:08:59 UTC"
  },
  {
    "arxiv_id": "2509.09730v1",
    "title": "MITS: A Large-Scale Multimodal Benchmark Dataset for Intelligent Traffic Surveillance",
    "authors": [
      "Kaikai Zhao",
      "Zhaoxiang Liu",
      "Peng Wang",
      "Xin Wang",
      "Zhicheng Ma",
      "Yajun Xu",
      "Wenjing Zhang",
      "Yibing Nan",
      "Kai Wang",
      "Shiguo Lian"
    ],
    "abstract": "General-domain large multimodal models (LMMs) have achieved significant advances in various image-text tasks. However, their performance in the Intelligent Traffic Surveillance (ITS) domain remains limited due to the absence of dedicated multimodal datasets. To address this gap, we introduce MITS (Multimodal Intelligent Traffic Surveillance), the first large-scale multimodal benchmark dataset specifically designed for ITS. MITS includes 170,400 independently collected real-world ITS images sourced from traffic surveillance cameras, annotated with eight main categories and 24 subcategories of ITS-specific objects and events under diverse environmental conditions. Additionally, through a systematic data generation pipeline, we generate high-quality image captions and 5 million instruction-following visual question-answer pairs, addressing five critical ITS tasks: object and event recognition, object counting, object localization, background analysis, and event reasoning. To demonstrate MITS's effectiveness, we fine-tune mainstream LMMs on this dataset, enabling the development of ITS-specific applications. Experimental results show that MITS significantly improves LMM performance in ITS applications, increasing LLaVA-1.5's performance from 0.494 to 0.905 (+83.2%), LLaVA-1.6's from 0.678 to 0.921 (+35.8%), Qwen2-VL's from 0.584 to 0.926 (+58.6%), and Qwen2.5-VL's from 0.732 to 0.930 (+27.0%). We release the dataset, code, and models as open-source, providing high-value resources to advance both ITS and LMM research.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "accepted by Image and Vision Computing",
    "pdf_url": "https://arxiv.org/pdf/2509.09730v1",
    "published_date": "2025-09-10 12:07:34 UTC",
    "updated_date": "2025-09-10 12:07:34 UTC"
  },
  {
    "arxiv_id": "2509.08521v1",
    "title": "FMT$^{x}$: An Efficient and Asymptotically Optimal Extension of the Fast Marching Tree for Dynamic Replanning",
    "authors": [
      "Soheil Espahbodini Nia"
    ],
    "abstract": "Path planning in dynamic environments remains a core challenge in robotics, especially as autonomous systems are deployed in unpredictable spaces such as warehouses and public roads. While algorithms like Fast Marching Tree (FMT$^{*}$) offer asymptotically optimal solutions in static settings, their single-pass design prevents path revisions which are essential for real-time adaptation. On the other hand, full replanning is often too computationally expensive. This paper introduces FMT$^{x}$, an extension of the Fast Marching Tree algorithm that enables efficient and consistent replanning in dynamic environments. We revisit the neighbor selection rule of FMT$^{*}$ and demonstrate that a minimal change overcomes its single-pass limitation, enabling the algorithm to update cost-to-come values upon discovering better connections without sacrificing asymptotic optimality or computational efficiency. By maintaining a cost-ordered priority queue and applying a selective update condition that uses an expanding neighbor to identify and trigger the re-evaluation of any node with a potentially suboptimal path, FMT$^{x}$ ensures that suboptimal routes are efficiently repaired as the environment evolves. This targeted strategy preserves the inherent efficiency of FMT$^{*}$ while enabling robust adaptation to changes in obstacle configuration. FMT$^{x}$ is proven to recover an asymptotically optimal solution after environmental changes. Experimental results demonstrate that FMT$^{x}$ outperforms the influential replanner RRT$^{x}$, reacting more swiftly to dynamic events with lower computational overhead and thus offering a more effective solution for real-time robotic navigation in unpredictable worlds.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "35 pages, 8 figures, 2 tables, submitted to the International Journal of Robotics Research (IJRR)",
    "pdf_url": "https://arxiv.org/pdf/2509.08521v1",
    "published_date": "2025-09-10 11:57:56 UTC",
    "updated_date": "2025-09-10 11:57:56 UTC"
  },
  {
    "arxiv_id": "2509.08515v1",
    "title": "Variational Rank Reduction Autoencoders for Generative Thermal Design",
    "authors": [
      "Alicia Tierz",
      "Jad Mounayer",
      "Beatriz Moya",
      "Francisco Chinesta"
    ],
    "abstract": "Generative thermal design for complex geometries is fundamental in many areas of engineering, yet it faces two main challenges: the high computational cost of high-fidelity simulations and the limitations of conventional generative models. Approaches such as autoencoders (AEs) and variational autoencoders (VAEs) often produce unstructured latent spaces with discontinuities, which restricts their capacity to explore designs and generate physically consistent solutions.\n  To address these limitations, we propose a hybrid framework that combines Variational Rank-Reduction Autoencoders (VRRAEs) with Deep Operator Networks (DeepONets). The VRRAE introduces a truncated SVD within the latent space, leading to continuous, interpretable, and well-structured representations that mitigate posterior collapse and improve geometric reconstruction. The DeepONet then exploits this compact latent encoding in its branch network, together with spatial coordinates in the trunk network, to predict temperature gradients efficiently and accurately.\n  This hybrid approach not only enhances the quality of generated geometries and the accuracy of gradient prediction, but also provides a substantial advantage in inference efficiency compared to traditional numerical solvers. Overall, the study underscores the importance of structured latent representations for operator learning and highlights the potential of combining generative models and operator networks in thermal design and broader engineering applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.08515v1",
    "published_date": "2025-09-10 11:45:40 UTC",
    "updated_date": "2025-09-10 11:45:40 UTC"
  },
  {
    "arxiv_id": "2509.08500v1",
    "title": "TCPO: Thought-Centric Preference Optimization for Effective Embodied Decision-making",
    "authors": [
      "Kechen Jiao",
      "Zhirui Fang",
      "Jiahao Liu",
      "Bei Li",
      "Qifan Wang",
      "Xinyu Liu",
      "Junhao Ruan",
      "Zhongjian Qiao",
      "Yifan Zhu",
      "Yaxin Xu",
      "Jingang Wang",
      "Xiu Li"
    ],
    "abstract": "Using effective generalization capabilities of vision language models (VLMs) in context-specific dynamic tasks for embodied artificial intelligence remains a significant challenge. Although supervised fine-tuned models can better align with the real physical world, they still exhibit sluggish responses and hallucination issues in dynamically changing environments, necessitating further alignment. Existing post-SFT methods, reliant on reinforcement learning and chain-of-thought (CoT) approaches, are constrained by sparse rewards and action-only optimization, resulting in low sample efficiency, poor consistency, and model degradation. To address these issues, this paper proposes Thought-Centric Preference Optimization (TCPO) for effective embodied decision-making. Specifically, TCPO introduces a stepwise preference-based optimization approach, transforming sparse reward signals into richer step sample pairs. It emphasizes the alignment of the model's intermediate reasoning process, mitigating the problem of model degradation. Moreover, by incorporating Action Policy Consistency Constraint (APC), it further imposes consistency constraints on the model output. Experiments in the ALFWorld environment demonstrate an average success rate of 26.67%, achieving a 6% improvement over RL4VLM and validating the effectiveness of our approach in mitigating model degradation after fine-tuning. These results highlight the potential of integrating preference-based learning techniques with CoT processes to enhance the decision-making capabilities of vision-language models in embodied agents.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.08500v1",
    "published_date": "2025-09-10 11:16:21 UTC",
    "updated_date": "2025-09-10 11:16:21 UTC"
  },
  {
    "arxiv_id": "2509.09729v1",
    "title": "MultimodalHugs: Enabling Sign Language Processing in Hugging Face",
    "authors": [
      "Gerard Sant",
      "Zifan Jiang",
      "Carlos Escolano",
      "Amit Moryossef",
      "Mathias Müller",
      "Rico Sennrich",
      "Sarah Ebling"
    ],
    "abstract": "In recent years, sign language processing (SLP) has gained importance in the general field of Natural Language Processing. However, compared to research on spoken languages, SLP research is hindered by complex ad-hoc code, inadvertently leading to low reproducibility and unfair comparisons. Existing tools that are built for fast and reproducible experimentation, such as Hugging Face, are not flexible enough to seamlessly integrate sign language experiments. This view is confirmed by a survey we conducted among SLP researchers.\n  To address these challenges, we introduce MultimodalHugs, a framework built on top of Hugging Face that enables more diverse data modalities and tasks, while inheriting the well-known advantages of the Hugging Face ecosystem. Even though sign languages are our primary focus, MultimodalHugs adds a layer of abstraction that makes it more widely applicable to other use cases that do not fit one of the standard templates of Hugging Face. We provide quantitative experiments to illustrate how MultimodalHugs can accommodate diverse modalities such as pose estimation data for sign languages, or pixel data for text characters.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.09729v1",
    "published_date": "2025-09-10 11:14:54 UTC",
    "updated_date": "2025-09-10 11:14:54 UTC"
  },
  {
    "arxiv_id": "2509.08494v1",
    "title": "HumanAgencyBench: Scalable Evaluation of Human Agency Support in AI Assistants",
    "authors": [
      "Benjamin Sturgeon",
      "Daniel Samuelson",
      "Jacob Haimes",
      "Jacy Reese Anthis"
    ],
    "abstract": "As humans delegate more tasks and decisions to artificial intelligence (AI), we risk losing control of our individual and collective futures. Relatively simple algorithmic systems already steer human decision-making, such as social media feed algorithms that lead people to unintentionally and absent-mindedly scroll through engagement-optimized content. In this paper, we develop the idea of human agency by integrating philosophical and scientific theories of agency with AI-assisted evaluation methods: using large language models (LLMs) to simulate and validate user queries and to evaluate AI responses. We develop HumanAgencyBench (HAB), a scalable and adaptive benchmark with six dimensions of human agency based on typical AI use cases. HAB measures the tendency of an AI assistant or agent to Ask Clarifying Questions, Avoid Value Manipulation, Correct Misinformation, Defer Important Decisions, Encourage Learning, and Maintain Social Boundaries. We find low-to-moderate agency support in contemporary LLM-based assistants and substantial variation across system developers and dimensions. For example, while Anthropic LLMs most support human agency overall, they are the least supportive LLMs in terms of Avoid Value Manipulation. Agency support does not appear to consistently result from increasing LLM capabilities or instruction-following behavior (e.g., RLHF), and we encourage a shift towards more robust safety and alignment targets.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.08494v1",
    "published_date": "2025-09-10 11:10:10 UTC",
    "updated_date": "2025-09-10 11:10:10 UTC"
  },
  {
    "arxiv_id": "2509.08493v1",
    "title": "Send to which account? Evaluation of an LLM-based Scambaiting System",
    "authors": [
      "Hossein Siadati",
      "Haadi Jafarian",
      "Sima Jafarikhah"
    ],
    "abstract": "Scammers are increasingly harnessing generative AI(GenAI) technologies to produce convincing phishing content at scale, amplifying financial fraud and undermining public trust. While conventional defenses, such as detection algorithms, user training, and reactive takedown efforts remain important, they often fall short in dismantling the infrastructure scammers depend on, including mule bank accounts and cryptocurrency wallets. To bridge this gap, a proactive and emerging strategy involves using conversational honeypots to engage scammers and extract actionable threat intelligence. This paper presents the first large-scale, real-world evaluation of a scambaiting system powered by large language models (LLMs). Over a five-month deployment, the system initiated over 2,600 engagements with actual scammers, resulting in a dataset of more than 18,700 messages. It achieved an Information Disclosure Rate (IDR) of approximately 32%, successfully extracting sensitive financial information such as mule accounts. Additionally, the system maintained a Human Acceptance Rate (HAR) of around 70%, indicating strong alignment between LLM-generated responses and human operator preferences. Alongside these successes, our analysis reveals key operational challenges. In particular, the system struggled with engagement takeoff: only 48.7% of scammers responded to the initial seed message sent by defenders. These findings highlight the need for further refinement and provide actionable insights for advancing the design of automated scambaiting systems.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.08493v1",
    "published_date": "2025-09-10 11:08:52 UTC",
    "updated_date": "2025-09-10 11:08:52 UTC"
  },
  {
    "arxiv_id": "2509.08867v1",
    "title": "Benchmarking Energy Efficiency of Large Language Models Using vLLM",
    "authors": [
      "K. Pronk",
      "Q. Zhao"
    ],
    "abstract": "The prevalence of Large Language Models (LLMs) is having an growing impact on the climate due to the substantial energy required for their deployment and use. To create awareness for developers who are implementing LLMs in their products, there is a strong need to collect more information about the energy efficiency of LLMs. While existing research has evaluated the energy efficiency of various models, these benchmarks often fall short of representing realistic production scenarios. In this paper, we introduce the LLM Efficiency Benchmark, designed to simulate real-world usage conditions. Our benchmark utilizes vLLM, a high-throughput, production-ready LLM serving backend that optimizes model performance and efficiency. We examine how factors such as model size, architecture, and concurrent request volume affect inference energy efficiency. Our findings demonstrate that it is possible to create energy efficiency benchmarks that better reflect practical deployment conditions, providing valuable insights for developers aiming to build more sustainable AI systems.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "6 pages, 6 figures",
    "pdf_url": "https://arxiv.org/pdf/2509.08867v1",
    "published_date": "2025-09-10 11:03:08 UTC",
    "updated_date": "2025-09-10 11:03:08 UTC"
  },
  {
    "arxiv_id": "2509.08490v1",
    "title": "A Structured Review of Underwater Object Detection Challenges and Solutions: From Traditional to Large Vision Language Models",
    "authors": [
      "Edwine Nabahirwa",
      "Wei Song",
      "Minghua Zhang",
      "Yi Fang",
      "Zhou Ni"
    ],
    "abstract": "Underwater object detection (UOD) is vital to diverse marine applications, including oceanographic research, underwater robotics, and marine conservation. However, UOD faces numerous challenges that compromise its performance. Over the years, various methods have been proposed to address these issues, but they often fail to fully capture the complexities of underwater environments. This review systematically categorizes UOD challenges into five key areas: Image quality degradation, target-related issues, data-related challenges, computational and processing constraints, and limitations in detection methodologies. To address these challenges, we analyze the progression from traditional image processing and object detection techniques to modern approaches. Additionally, we explore the potential of large vision-language models (LVLMs) in UOD, leveraging their multi-modal capabilities demonstrated in other domains. We also present case studies, including synthetic dataset generation using DALL-E 3 and fine-tuning Florence-2 LVLM for UOD. This review identifies three key insights: (i) Current UOD methods are insufficient to fully address challenges like image degradation and small object detection in dynamic underwater environments. (ii) Synthetic data generation using LVLMs shows potential for augmenting datasets but requires further refinement to ensure realism and applicability. (iii) LVLMs hold significant promise for UOD, but their real-time application remains under-explored, requiring further research on optimization techniques.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "72 Pages, 11 Figures",
    "pdf_url": "https://arxiv.org/pdf/2509.08490v1",
    "published_date": "2025-09-10 11:01:29 UTC",
    "updated_date": "2025-09-10 11:01:29 UTC"
  },
  {
    "arxiv_id": "2509.08489v1",
    "title": "Prompt-Driven Image Analysis with Multimodal Generative AI: Detection, Segmentation, Inpainting, and Interpretation",
    "authors": [
      "Kaleem Ahmad"
    ],
    "abstract": "Prompt-driven image analysis converts a single natural-language instruction into multiple steps: locate, segment, edit, and describe. We present a practical case study of a unified pipeline that combines open-vocabulary detection, promptable segmentation, text-conditioned inpainting, and vision-language description into a single workflow. The system works end to end from a single prompt, retains intermediate artifacts for transparent debugging (such as detections, masks, overlays, edited images, and before and after composites), and provides the same functionality through an interactive UI and a scriptable CLI for consistent, repeatable runs. We highlight integration choices that reduce brittleness, including threshold adjustments, mask inspection with light morphology, and resource-aware defaults. In a small, single-word prompt segment, detection and segmentation produced usable masks in over 90% of cases with an accuracy above 85% based on our criteria. On a high-end GPU, inpainting makes up 60 to 75% of total runtime under typical guidance and sampling settings, which highlights the need for careful tuning. The study offers implementation-guided advice on thresholds, mask tightness, and diffusion parameters, and details version pinning, artifact logging, and seed control to support replay. Our contribution is a transparent, reliable pattern for assembling modern vision and multimodal models behind a single prompt, with clear guardrails and operational practices that improve reliability in object replacement, scene augmentation, and removal.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "14 pages. Preprint",
    "pdf_url": "https://arxiv.org/pdf/2509.08489v1",
    "published_date": "2025-09-10 11:00:12 UTC",
    "updated_date": "2025-09-10 11:00:12 UTC"
  },
  {
    "arxiv_id": "2509.08470v1",
    "title": "Joint Learning using Mixture-of-Expert-Based Representation for Enhanced Speech Generation and Robust Emotion Recognition",
    "authors": [
      "Jing-Tong Tzeng",
      "Carlos Busso",
      "Chi-Chun Lee"
    ],
    "abstract": "Speech emotion recognition (SER) plays a critical role in building emotion-aware speech systems, but its performance degrades significantly under noisy conditions. Although speech enhancement (SE) can improve robustness, it often introduces artifacts that obscure emotional cues and adds computational overhead to the pipeline. Multi-task learning (MTL) offers an alternative by jointly optimizing SE and SER tasks. However, conventional shared-backbone models frequently suffer from gradient interference and representational conflicts between tasks. To address these challenges, we propose the Sparse Mixture-of-Experts Representation Integration Technique (Sparse MERIT), a flexible MTL framework that applies frame-wise expert routing over self-supervised speech representations. Sparse MERIT incorporates task-specific gating networks that dynamically select from a shared pool of experts for each frame, enabling parameter-efficient and task-adaptive representation learning. Experiments on the MSP-Podcast corpus show that Sparse MERIT consistently outperforms baseline models on both SER and SE tasks. Under the most challenging condition of -5 dB signal-to-noise ratio (SNR), Sparse MERIT improves SER F1-macro by an average of 12.0% over a baseline relying on a SE pre-processing strategy, and by 3.4% over a naive MTL baseline, with statistical significance on unseen noise conditions. For SE, Sparse MERIT improves segmental SNR (SSNR) by 28.2% over the SE pre-processing baseline and by 20.0% over the naive MTL baseline. These results demonstrate that Sparse MERIT provides robust and generalizable performance for both emotion recognition and enhancement tasks in noisy environments.",
    "categories": [
      "eess.AS",
      "cs.AI"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.08470v1",
    "published_date": "2025-09-10 10:18:56 UTC",
    "updated_date": "2025-09-10 10:18:56 UTC"
  },
  {
    "arxiv_id": "2509.08463v1",
    "title": "Adversarial Attacks Against Automated Fact-Checking: A Survey",
    "authors": [
      "Fanzhen Liu",
      "Alsharif Abuadbba",
      "Kristen Moore",
      "Surya Nepal",
      "Cecile Paris",
      "Jia Wu",
      "Jian Yang",
      "Quan Z. Sheng"
    ],
    "abstract": "In an era where misinformation spreads freely, fact-checking (FC) plays a crucial role in verifying claims and promoting reliable information. While automated fact-checking (AFC) has advanced significantly, existing systems remain vulnerable to adversarial attacks that manipulate or generate claims, evidence, or claim-evidence pairs. These attacks can distort the truth, mislead decision-makers, and ultimately undermine the reliability of FC models. Despite growing research interest in adversarial attacks against AFC systems, a comprehensive, holistic overview of key challenges remains lacking. These challenges include understanding attack strategies, assessing the resilience of current models, and identifying ways to enhance robustness. This survey provides the first in-depth review of adversarial attacks targeting FC, categorizing existing attack methodologies and evaluating their impact on AFC systems. Additionally, we examine recent advancements in adversary-aware defenses and highlight open research questions that require further exploration. Our findings underscore the urgent need for resilient FC frameworks capable of withstanding adversarial manipulations in pursuit of preserving high verification accuracy.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to the Main Conference of EMNLP 2025. Resources are available at https://github.com/FanzhenLiu/Awesome-Automated-Fact-Checking-Attacks",
    "pdf_url": "https://arxiv.org/pdf/2509.08463v1",
    "published_date": "2025-09-10 10:10:10 UTC",
    "updated_date": "2025-09-10 10:10:10 UTC"
  },
  {
    "arxiv_id": "2509.08461v2",
    "title": "Adapting Vision-Language Models for Neutrino Event Classification in High-Energy Physics",
    "authors": [
      "Dikshant Sagar",
      "Kaiwen Yu",
      "Alejandro Yankelevich",
      "Jianming Bian",
      "Pierre Baldi"
    ],
    "abstract": "Recent advances in Large Language Models (LLMs) have demonstrated their remarkable capacity to process and reason over structured and unstructured data modalities beyond natural language. In this work, we explore the applications of Vision Language Models (VLMs), specifically a fine-tuned variant of LLaMa 3.2, to the task of identifying neutrino interactions in pixelated detector data from high-energy physics (HEP) experiments. We benchmark this model against a state-of-the-art convolutional neural network (CNN) architecture, similar to those used in the NOvA and DUNE experiments, which have achieved high efficiency and purity in classifying electron and muon neutrino events. Our evaluation considers both the classification performance and interpretability of the model predictions. We find that VLMs can outperform CNNs, while also providing greater flexibility in integrating auxiliary textual or semantic information and offering more interpretable, reasoning-based predictions. This work highlights the potential of VLMs as a general-purpose backbone for physics event classification, due to their high performance, interpretability, and generalizability, which opens new avenues for integrating multimodal reasoning in experimental neutrino physics.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "hep-ex"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.08461v2",
    "published_date": "2025-09-10 10:07:27 UTC",
    "updated_date": "2025-09-11 13:03:04 UTC"
  },
  {
    "arxiv_id": "2509.08449v1",
    "title": "DSFL: A Dual-Server Byzantine-Resilient Federated Learning Framework via Group-Based Secure Aggregation",
    "authors": [
      "Charuka Herath",
      "Yogachandran Rahulamathavan",
      "Varuna De Silva",
      "Sangarapillai Lambotharan"
    ],
    "abstract": "Federated Learning (FL) enables decentralized model training without sharing raw data, offering strong privacy guarantees. However, existing FL protocols struggle to defend against Byzantine participants, maintain model utility under non-independent and identically distributed (non-IID) data, and remain lightweight for edge devices. Prior work either assumes trusted hardware, uses expensive cryptographic tools, or fails to address privacy and robustness simultaneously. We propose DSFL, a Dual-Server Byzantine-Resilient Federated Learning framework that addresses these limitations using a group-based secure aggregation approach. Unlike LSFL, which assumes non-colluding semi-honest servers, DSFL removes this dependency by revealing a key vulnerability: privacy leakage through client-server collusion. DSFL introduces three key innovations: (1) a dual-server secure aggregation protocol that protects updates without encryption or key exchange, (2) a group-wise credit-based filtering mechanism to isolate Byzantine clients based on deviation scores, and (3) a dynamic reward-penalty system for enforcing fair participation. DSFL is evaluated on MNIST, CIFAR-10, and CIFAR-100 under up to 30 percent Byzantine participants in both IID and non-IID settings. It consistently outperforms existing baselines, including LSFL, homomorphic encryption methods, and differential privacy approaches. For example, DSFL achieves 97.15 percent accuracy on CIFAR-10 and 68.60 percent on CIFAR-100, while FedAvg drops to 9.39 percent under similar threats. DSFL remains lightweight, requiring only 55.9 ms runtime and 1088 KB communication per round.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.08449v1",
    "published_date": "2025-09-10 09:47:51 UTC",
    "updated_date": "2025-09-10 09:47:51 UTC"
  },
  {
    "arxiv_id": "2509.08442v1",
    "title": "Spherical Brownian Bridge Diffusion Models for Conditional Cortical Thickness Forecasting",
    "authors": [
      "Ivan Stoyanov",
      "Fabian Bongratz",
      "Christian Wachinger"
    ],
    "abstract": "Accurate forecasting of individualized, high-resolution cortical thickness (CTh) trajectories is essential for detecting subtle cortical changes, providing invaluable insights into neurodegenerative processes and facilitating earlier and more precise intervention strategies. However, CTh forecasting is a challenging task due to the intricate non-Euclidean geometry of the cerebral cortex and the need to integrate multi-modal data for subject-specific predictions. To address these challenges, we introduce the Spherical Brownian Bridge Diffusion Model (SBDM). Specifically, we propose a bidirectional conditional Brownian bridge diffusion process to forecast CTh trajectories at the vertex level of registered cortical surfaces. Our technical contribution includes a new denoising model, the conditional spherical U-Net (CoS-UNet), which combines spherical convolutions and dense cross-attention to integrate cortical surfaces and tabular conditions seamlessly. Compared to previous approaches, SBDM achieves significantly reduced prediction errors, as demonstrated by our experiments based on longitudinal datasets from the ADNI and OASIS. Additionally, we demonstrate SBDM's ability to generate individual factual and counterfactual CTh trajectories, offering a novel framework for exploring hypothetical scenarios of cortical development.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "q-bio.NC"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.08442v1",
    "published_date": "2025-09-10 09:40:41 UTC",
    "updated_date": "2025-09-10 09:40:41 UTC"
  },
  {
    "arxiv_id": "2509.08421v1",
    "title": "Sparse BEV Fusion with Self-View Consistency for Multi-View Detection and Tracking",
    "authors": [
      "Keisuke Toida",
      "Taigo Sakai",
      "Naoki Kato",
      "Kazutoyo Yokota",
      "Takeshi Nakamura",
      "Kazuhiro Hotta"
    ],
    "abstract": "Multi-View Multi-Object Tracking (MVMOT) is essential for applications such as surveillance, autonomous driving, and sports analytics. However, maintaining consistent object identities across multiple cameras remains challenging due to viewpoint changes, lighting variations, and occlusions, which often lead to tracking errors.Recent methods project features from multiple cameras into a unified Bird's-Eye-View (BEV) space to improve robustness against occlusion. However, this projection introduces feature distortion and non-uniform density caused by variations in object scale with distance. These issues degrade the quality of the fused representation and reduce detection and tracking accuracy.To address these problems, we propose SCFusion, a framework that combines three techniques to improve multi-view feature integration. First, it applies a sparse transformation to avoid unnatural interpolation during projection. Next, it performs density-aware weighting to adaptively fuse features based on spatial confidence and camera distance. Finally, it introduces a multi-view consistency loss that encourages each camera to learn discriminative features independently before fusion.Experiments show that SCFusion achieves state-of-the-art performance, reaching an IDF1 score of 95.9% on WildTrack and a MODP of 89.2% on MultiviewX, outperforming the baseline method TrackTacular. These results demonstrate that SCFusion effectively mitigates the limitations of conventional BEV projection and provides a robust and accurate solution for multi-view object detection and tracking.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.08421v1",
    "published_date": "2025-09-10 09:06:41 UTC",
    "updated_date": "2025-09-10 09:06:41 UTC"
  },
  {
    "arxiv_id": "2509.08407v1",
    "title": "An Iterative LLM Framework for SIBT utilizing RAG-based Adaptive Weight Optimization",
    "authors": [
      "Zhuo Xiao",
      "Qinglong Yao",
      "Jingjing Wang",
      "Fugen Zhou",
      "Bo Liu",
      "Haitao Sun",
      "Zhe Ji",
      "Yuliang Jiang",
      "Junjie Wang",
      "Qiuwen Wu"
    ],
    "abstract": "Seed implant brachytherapy (SIBT) is an effective cancer treatment modality; however, clinical planning often relies on manual adjustment of objective function weights, leading to inefficiencies and suboptimal results. This study proposes an adaptive weight optimization framework for SIBT planning, driven by large language models (LLMs). A locally deployed DeepSeek-R1 LLM is integrated with an automatic planning algorithm in an iterative loop. Starting with fixed weights, the LLM evaluates plan quality and recommends new weights in the next iteration. This process continues until convergence criteria are met, after which the LLM conducts a comprehensive evaluation to identify the optimal plan. A clinical knowledge base, constructed and queried via retrieval-augmented generation (RAG), enhances the model's domain-specific reasoning. The proposed method was validated on 23 patient cases, showing that the LLM-assisted approach produces plans that are comparable to or exceeding clinically approved and fixed-weight plans, in terms of dose homogeneity for the clinical target volume (CTV) and sparing of organs at risk (OARs). The study demonstrates the potential use of LLMs in SIBT planning automation.",
    "categories": [
      "physics.med-ph",
      "cs.AI"
    ],
    "primary_category": "physics.med-ph",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.08407v1",
    "published_date": "2025-09-10 08:54:16 UTC",
    "updated_date": "2025-09-10 08:54:16 UTC"
  },
  {
    "arxiv_id": "2511.05494v1",
    "title": "Customized Retrieval-Augmented Generation with LLM for Debiasing Recommendation Unlearning",
    "authors": [
      "Haichao Zhang",
      "Chong Zhang",
      "Peiyu Hu",
      "Shi Qiu",
      "Jia Wang"
    ],
    "abstract": "Modern recommender systems face a critical challenge in complying with privacy regulations like the 'right to be forgotten': removing a user's data without disrupting recommendations for others. Traditional unlearning methods address this by partial model updates, but introduce propagation bias--where unlearning one user's data distorts recommendations for behaviorally similar users, degrading system accuracy. While retraining eliminates bias, it is computationally prohibitive for large-scale systems. To address this challenge, we propose CRAGRU, a novel framework leveraging Retrieval-Augmented Generation (RAG) for efficient, user-specific unlearning that mitigates bias while preserving recommendation quality. CRAGRU decouples unlearning into distinct retrieval and generation stages. In retrieval, we employ three tailored strategies designed to precisely isolate the target user's data influence, minimizing collateral impact on unrelated users and enhancing unlearning efficiency. Subsequently, the generation stage utilizes an LLM, augmented with user profiles integrated into prompts, to reconstruct accurate and personalized recommendations without needing to retrain the entire base model. Experiments on three public datasets demonstrate that CRAGRU effectively unlearns targeted user data, significantly mitigating unlearning bias by preventing adverse impacts on non-target users, while maintaining recommendation performance comparable to fully trained original models. Our work highlights the promise of RAG-based architectures for building robust and privacy-preserving recommender systems. The source code is available at: https://github.com/zhanghaichao520/LLM_rec_unlearning.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "10 pages, 4 figures. Accepted ICDM 2025 (IEEE International Conference on Data Mining)",
    "pdf_url": "https://arxiv.org/pdf/2511.05494v1",
    "published_date": "2025-09-10 08:49:58 UTC",
    "updated_date": "2025-09-10 08:49:58 UTC"
  },
  {
    "arxiv_id": "2509.08388v1",
    "title": "Semantic Causality-Aware Vision-Based 3D Occupancy Prediction",
    "authors": [
      "Dubing Chen",
      "Huan Zheng",
      "Yucheng Zhou",
      "Xianfei Li",
      "Wenlong Liao",
      "Tao He",
      "Pai Peng",
      "Jianbing Shen"
    ],
    "abstract": "Vision-based 3D semantic occupancy prediction is a critical task in 3D vision that integrates volumetric 3D reconstruction with semantic understanding. Existing methods, however, often rely on modular pipelines. These modules are typically optimized independently or use pre-configured inputs, leading to cascading errors. In this paper, we address this limitation by designing a novel causal loss that enables holistic, end-to-end supervision of the modular 2D-to-3D transformation pipeline. Grounded in the principle of 2D-to-3D semantic causality, this loss regulates the gradient flow from 3D voxel representations back to the 2D features. Consequently, it renders the entire pipeline differentiable, unifying the learning process and making previously non-trainable components fully learnable. Building on this principle, we propose the Semantic Causality-Aware 2D-to-3D Transformation, which comprises three components guided by our causal loss: Channel-Grouped Lifting for adaptive semantic mapping, Learnable Camera Offsets for enhanced robustness against camera perturbations, and Normalized Convolution for effective feature propagation. Extensive experiments demonstrate that our method achieves state-of-the-art performance on the Occ3D benchmark, demonstrating significant robustness to camera perturbations and improved 2D-to-3D semantic consistency.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "ICCV 2025",
    "pdf_url": "https://arxiv.org/pdf/2509.08388v1",
    "published_date": "2025-09-10 08:29:22 UTC",
    "updated_date": "2025-09-10 08:29:22 UTC"
  },
  {
    "arxiv_id": "2509.08383v2",
    "title": "Efficient Decoding Methods for Language Models on Encrypted Data",
    "authors": [
      "Matan Avitan",
      "Moran Baruch",
      "Nir Drucker",
      "Itamar Zimerman",
      "Yoav Goldberg"
    ],
    "abstract": "Large language models (LLMs) power modern AI applications, but processing sensitive data on untrusted servers raises privacy concerns. Homomorphic encryption (HE) enables computation on encrypted data for secure inference. However, neural text generation requires decoding methods like argmax and sampling, which are non-polynomial and thus computationally expensive under encryption, creating a significant performance bottleneck. We introduce cutmax, an HE-friendly argmax algorithm that reduces ciphertext operations compared to prior methods, enabling practical greedy decoding under encryption. We also propose the first HE-compatible nucleus (top-p) sampling method, leveraging cutmax for efficient stochastic decoding with provable privacy guarantees. Both techniques are polynomial, supporting efficient inference in privacy-preserving settings. Moreover, their differentiability facilitates gradient-based sequence-level optimization as a polynomial alternative to straight-through estimators. We further provide strong theoretical guarantees for cutmax, proving its convergence via exponential amplification of the gap ratio between the maximum and runner-up elements. Evaluations on realistic LLM outputs show latency reductions of 24x-35x over baselines, advancing secure text generation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.08383v2",
    "published_date": "2025-09-10 08:23:14 UTC",
    "updated_date": "2025-11-17 20:14:58 UTC"
  },
  {
    "arxiv_id": "2509.08381v1",
    "title": "Low-Resource Fine-Tuning for Multi-Task Structured Information Extraction with a Billion-Parameter Instruction-Tuned Model",
    "authors": [
      "Yu Cheng Chih",
      "Yong Hao Hou"
    ],
    "abstract": "Deploying large language models (LLMs) for structured data extraction in domains such as financial compliance reporting, legal document analytics, and multilingual knowledge base construction is often impractical for smaller teams due to the high cost of running large architectures and the difficulty of preparing large, high-quality datasets. Most recent instruction-tuning studies focus on seven-billion-parameter or larger models, leaving limited evidence on whether much smaller models can work reliably under low-resource, multi-task conditions. This work presents ETLCH, a billion-parameter LLaMA-based model fine-tuned with low-rank adaptation on only a few hundred to one thousand samples per task for JSON extraction, knowledge graph extraction, and named entity recognition. Despite its small scale, ETLCH outperforms strong baselines across most evaluation metrics, with substantial gains observed even at the lowest data scale. These findings demonstrate that well-tuned small models can deliver stable and accurate structured outputs at a fraction of the computational cost, enabling cost-effective and reliable information extraction pipelines in resource-constrained environments.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "13 pages, 8 figures, includes experiments on JSON extraction, knowledge graph extraction, and NER",
    "pdf_url": "https://arxiv.org/pdf/2509.08381v1",
    "published_date": "2025-09-10 08:19:07 UTC",
    "updated_date": "2025-09-10 08:19:07 UTC"
  },
  {
    "arxiv_id": "2509.08380v2",
    "title": "Co-Investigator AI: The Rise of Agentic AI for Smarter, Trustworthy AML Compliance Narratives",
    "authors": [
      "Prathamesh Vasudeo Naik",
      "Naresh Kumar Dintakurthi",
      "Zhanghao Hu",
      "Yue Wang",
      "Robby Qiu"
    ],
    "abstract": "Generating regulatorily compliant Suspicious Activity Report (SAR) remains a high-cost, low-scalability bottleneck in Anti-Money Laundering (AML) workflows. While large language models (LLMs) offer promising fluency, they suffer from factual hallucination, limited crime typology alignment, and poor explainability -- posing unacceptable risks in compliance-critical domains. This paper introduces Co-Investigator AI, an agentic framework optimized to produce Suspicious Activity Reports (SARs) significantly faster and with greater accuracy than traditional methods. Drawing inspiration from recent advances in autonomous agent architectures, such as the AI Co-Scientist, our approach integrates specialized agents for planning, crime type detection, external intelligence gathering, and compliance validation. The system features dynamic memory management, an AI-Privacy Guard layer for sensitive data handling, and a real-time validation agent employing the Agent-as-a-Judge paradigm to ensure continuous narrative quality assurance. Human investigators remain firmly in the loop, empowered to review and refine drafts in a collaborative workflow that blends AI efficiency with domain expertise. We demonstrate the versatility of Co-Investigator AI across a range of complex financial crime scenarios, highlighting its ability to streamline SAR drafting, align narratives with regulatory expectations, and enable compliance teams to focus on higher-order analytical work. This approach marks the beginning of a new era in compliance reporting -- bringing the transformative benefits of AI agents to the core of regulatory processes and paving the way for scalable, reliable, and transparent SAR generation.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.08380v2",
    "published_date": "2025-09-10 08:16:04 UTC",
    "updated_date": "2025-09-17 04:43:46 UTC"
  },
  {
    "arxiv_id": "2509.10561v1",
    "title": "AVEC: Bootstrapping Privacy for Local LLMs",
    "authors": [
      "Madhava Gaikwad"
    ],
    "abstract": "This position paper presents AVEC (Adaptive Verifiable Edge Control), a framework for bootstrapping privacy for local language models by enforcing privacy at the edge with explicit verifiability for delegated queries. AVEC introduces an adaptive budgeting algorithm that allocates per-query differential privacy parameters based on sensitivity, local confidence, and historical usage, and uses verifiable transformation with on-device integrity checks. We formalize guarantees using Rényi differential privacy with odometer-based accounting, and establish utility ceilings, delegation-leakage bounds, and impossibility results for deterministic gating and hash-only certification. Our evaluation is simulation-based by design to study mechanism behavior and accounting; we do not claim deployment readiness or task-level utility with live LLMs. The contribution is a conceptual architecture and theoretical foundation that chart a pathway for empirical follow-up on privately bootstrapping local LLMs.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "12 pages",
    "pdf_url": "https://arxiv.org/pdf/2509.10561v1",
    "published_date": "2025-09-10 07:59:01 UTC",
    "updated_date": "2025-09-10 07:59:01 UTC"
  },
  {
    "arxiv_id": "2509.08358v1",
    "title": "<think> So let's replace this phrase with insult... </think> Lessons learned from generation of toxic texts with LLMs",
    "authors": [
      "Sergey Pletenev",
      "Daniil Moskovskiy",
      "Alexander Panchenko"
    ],
    "abstract": "Modern Large Language Models (LLMs) are excellent at generating synthetic data. However, their performance in sensitive domains such as text detoxification has not received proper attention from the scientific community. This paper explores the possibility of using LLM-generated synthetic toxic data as an alternative to human-generated data for training models for detoxification. Using Llama 3 and Qwen activation-patched models, we generated synthetic toxic counterparts for neutral texts from ParaDetox and SST-2 datasets. Our experiments show that models fine-tuned on synthetic data consistently perform worse than those trained on human data, with a drop in performance of up to 30% in joint metrics. The root cause is identified as a critical lexical diversity gap: LLMs generate toxic content using a small, repetitive vocabulary of insults that fails to capture the nuances and variety of human toxicity. These findings highlight the limitations of current LLMs in this domain and emphasize the continued importance of diverse, human-annotated data for building robust detoxification systems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.08358v1",
    "published_date": "2025-09-10 07:48:24 UTC",
    "updated_date": "2025-09-10 07:48:24 UTC"
  },
  {
    "arxiv_id": "2509.08355v1",
    "title": "Automatic Detection of Inauthentic Templated Responses in English Language Assessments",
    "authors": [
      "Yashad Samant",
      "Lee Becker",
      "Scott Hellman",
      "Bradley Behan",
      "Sarah Hughes",
      "Joshua Southerland"
    ],
    "abstract": "In high-stakes English Language Assessments, low-skill test takers may employ memorized materials called ``templates'' on essay questions to ``game'' or fool the automated scoring system. In this study, we introduce the automated detection of inauthentic, templated responses (AuDITR) task, describe a machine learning-based approach to this task and illustrate the importance of regularly updating these models in production.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to National Council on Measurement in Education (NCME) 2025 Annual Meeting",
    "pdf_url": "https://arxiv.org/pdf/2509.08355v1",
    "published_date": "2025-09-10 07:45:02 UTC",
    "updated_date": "2025-09-10 07:45:02 UTC"
  },
  {
    "arxiv_id": "2509.08354v1",
    "title": "Grasp Like Humans: Learning Generalizable Multi-Fingered Grasping from Human Proprioceptive Sensorimotor Integration",
    "authors": [
      "Ce Guo",
      "Xieyuanli Chen",
      "Zhiwen Zeng",
      "Zirui Guo",
      "Yihong Li",
      "Haoran Xiao",
      "Dewen Hu",
      "Huimin Lu"
    ],
    "abstract": "Tactile and kinesthetic perceptions are crucial for human dexterous manipulation, enabling reliable grasping of objects via proprioceptive sensorimotor integration. For robotic hands, even though acquiring such tactile and kinesthetic feedback is feasible, establishing a direct mapping from this sensory feedback to motor actions remains challenging. In this paper, we propose a novel glove-mediated tactile-kinematic perception-prediction framework for grasp skill transfer from human intuitive and natural operation to robotic execution based on imitation learning, and its effectiveness is validated through generalized grasping tasks, including those involving deformable objects. Firstly, we integrate a data glove to capture tactile and kinesthetic data at the joint level. The glove is adaptable for both human and robotic hands, allowing data collection from natural human hand demonstrations across different scenarios. It ensures consistency in the raw data format, enabling evaluation of grasping for both human and robotic hands. Secondly, we establish a unified representation of multi-modal inputs based on graph structures with polar coordinates. We explicitly integrate the morphological differences into the designed representation, enhancing the compatibility across different demonstrators and robotic hands. Furthermore, we introduce the Tactile-Kinesthetic Spatio-Temporal Graph Networks (TK-STGN), which leverage multidimensional subgraph convolutions and attention-based LSTM layers to extract spatio-temporal features from graph inputs to predict node-based states for each hand joint. These predictions are then mapped to final commands through a force-position hybrid mapping.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "20 pages, 19 figures, accepted by IEEE Transactions on Robotics",
    "pdf_url": "https://arxiv.org/pdf/2509.08354v1",
    "published_date": "2025-09-10 07:44:12 UTC",
    "updated_date": "2025-09-10 07:44:12 UTC"
  },
  {
    "arxiv_id": "2509.08345v1",
    "title": "Toward Subtrait-Level Model Explainability in Automated Writing Evaluation",
    "authors": [
      "Alejandro Andrade-Lotero",
      "Lee Becker",
      "Joshua Southerland",
      "Scott Hellman"
    ],
    "abstract": "Subtrait (latent-trait components) assessment presents a promising path toward enhancing transparency of automated writing scores. We prototype explainability and subtrait scoring with generative language models and show modest correlation between human subtrait and trait scores, and between automated and human subtrait scores. Our approach provides details to demystify scores for educators and students.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to National Council on Measurement in Education (NCME) 2025 Annual Meeting",
    "pdf_url": "https://arxiv.org/pdf/2509.08345v1",
    "published_date": "2025-09-10 07:32:14 UTC",
    "updated_date": "2025-09-10 07:32:14 UTC"
  },
  {
    "arxiv_id": "2509.08342v1",
    "title": "Accelerating Mixture-of-Expert Inference with Adaptive Expert Split Mechanism",
    "authors": [
      "Jiaming Yan",
      "Jianchun Liu",
      "Hongli Xu",
      "Liusheng Huang"
    ],
    "abstract": "Mixture-of-Experts (MoE) has emerged as a promising architecture for modern large language models (LLMs). However, massive parameters impose heavy GPU memory (i.e., VRAM) demands, hindering the widespread adoption of MoE LLMs. Offloading the expert parameters to CPU RAM offers an effective way to alleviate the VRAM requirements for MoE inference. Existing approaches typically cache a small subset of experts in VRAM and dynamically prefetch experts from RAM during inference, leading to significant degradation in inference speed due to the poor cache hit rate and substantial expert loading latency. In this work, we propose MoEpic, an efficient MoE inference system with a novel expert split mechanism. Specifically, each expert is vertically divided into two segments: top and bottom. MoEpic caches the top segment of hot experts, so that more experts will be stored under the limited VRAM budget, thereby improving the cache hit rate. During each layer's inference, MoEpic predicts and prefetches the activated experts for the next layer. Since the top segments of cached experts are exempt from fetching, the loading time is reduced, which allows efficient transfer-computation overlap. Nevertheless, the performance of MoEpic critically depends on the cache configuration (i.e., each layer's VRAM budget and expert split ratio). To this end, we propose a divide-and-conquer algorithm based on fixed-point iteration for adaptive cache configuration. Extensive experiments on popular MoE LLMs demonstrate that MoEpic can save about half of the GPU cost, while lowering the inference latency by about 37.51%-65.73% compared to the baselines.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.08342v1",
    "published_date": "2025-09-10 07:28:24 UTC",
    "updated_date": "2025-09-10 07:28:24 UTC"
  },
  {
    "arxiv_id": "2509.08338v1",
    "title": "Retrieval-Augmented VLMs for Multimodal Melanoma Diagnosis",
    "authors": [
      "Jihyun Moon",
      "Charmgil Hong"
    ],
    "abstract": "Accurate and early diagnosis of malignant melanoma is critical for improving patient outcomes. While convolutional neural networks (CNNs) have shown promise in dermoscopic image analysis, they often neglect clinical metadata and require extensive preprocessing. Vision-language models (VLMs) offer a multimodal alternative but struggle to capture clinical specificity when trained on general-domain data. To address this, we propose a retrieval-augmented VLM framework that incorporates semantically similar patient cases into the diagnostic prompt. Our method enables informed predictions without fine-tuning and significantly improves classification accuracy and error correction over conventional baselines. These results demonstrate that retrieval-augmented prompting provides a robust strategy for clinical decision support.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Medical Image Computing and Computer-Assisted Intervention (MICCAI) ISIC Skin Image Analysis Workshop (MICCAI ISIC) 2025; 10 pages",
    "pdf_url": "https://arxiv.org/pdf/2509.08338v1",
    "published_date": "2025-09-10 07:23:30 UTC",
    "updated_date": "2025-09-10 07:23:30 UTC"
  },
  {
    "arxiv_id": "2509.08329v1",
    "title": "Accelerating Reinforcement Learning Algorithms Convergence using Pre-trained Large Language Models as Tutors With Advice Reusing",
    "authors": [
      "Lukas Toral",
      "Teddy Lazebnik"
    ],
    "abstract": "Reinforcement Learning (RL) algorithms often require long training to become useful, especially in complex environments with sparse rewards. While techniques like reward shaping and curriculum learning exist to accelerate training, these are often extremely specific and require the developer's professionalism and dedicated expertise in the problem's domain. Tackling this challenge, in this study, we explore the effectiveness of pre-trained Large Language Models (LLMs) as tutors in a student-teacher architecture with RL algorithms, hypothesizing that LLM-generated guidance allows for faster convergence. In particular, we explore the effectiveness of reusing the LLM's advice on the RL's convergence dynamics. Through an extensive empirical examination, which included 54 configurations, varying the RL algorithm (DQN, PPO, A2C), LLM tutor (Llama, Vicuna, DeepSeek), and environment (Blackjack, Snake, Connect Four), our results demonstrate that LLM tutoring significantly accelerates RL convergence while maintaining comparable optimal performance. Furthermore, the advice reuse mechanism shows a further improvement in training duration but also results in less stable convergence dynamics. Our findings suggest that LLM tutoring generally improves convergence, and its effectiveness is sensitive to the specific task, RL algorithm, and LLM model combination.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.08329v1",
    "published_date": "2025-09-10 07:08:04 UTC",
    "updated_date": "2025-09-10 07:08:04 UTC"
  },
  {
    "arxiv_id": "2509.13334v1",
    "title": "FRIT: Using Causal Importance to Improve Chain-of-Thought Faithfulness",
    "authors": [
      "Anand Swaroop",
      "Akshat Nallani",
      "Saksham Uboweja",
      "Adiliia Uzdenova",
      "Michael Nguyen",
      "Kevin Zhu",
      "Sunishchal Dev",
      "Ashwinee Panda",
      "Vasu Sharma",
      "Maheep Chaudhary"
    ],
    "abstract": "Chain-of-thought (CoT) reasoning has emerged as a powerful tool for improving large language model performance on complex tasks, but recent work shows that reasoning steps often fail to causally influence the final answer, creating brittle and untrustworthy outputs. Prior approaches focus primarily on measuring faithfulness, while methods for systematically improving it remain limited. We introduce Faithful Reasoning via Intervention Training (FRIT), a scalable alignment method that trains models to produce causally consistent reasoning by learning from systematically corrupted examples. FRIT generates synthetic training data by intervening on individual reasoning steps in model-generated CoTs, creating faithful/unfaithful pairs that highlight when reasoning breaks down. We then apply Direct Preference Optimization to teach models to prefer causally consistent reasoning paths. Evaluating on Qwen3-8B and Mistral-7B-v0.1 across factual and symbolic reasoning tasks, FRIT increases faithful reasoning by $3.4$ percentage points for Mistral on GSM8K while improving accuracy by $7.6$ percentage points. Our approach provides the first scalable, supervision-free method for training language models to produce more reliable and interpretable reasoning, addressing a critical gap between reasoning performance and trustworthiness. We release our code at \\href{https://github.com/Anut-py/frit}.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.13334v1",
    "published_date": "2025-09-10 07:07:17 UTC",
    "updated_date": "2025-09-10 07:07:17 UTC"
  },
  {
    "arxiv_id": "2509.18116v2",
    "title": "Amortized Latent Steering: Low-Cost Alternative to Test-Time Optimization",
    "authors": [
      "Nathan Egbuna",
      "Saatvik Gaur",
      "Sunishchal Dev",
      "Ashwinee Panda",
      "Maheep Chaudhary"
    ],
    "abstract": "Test-time optimization remains impractical at scale due to prohibitive inference costs--techniques like iterative refinement and multi-step verification can require $10-100\\times$ more compute per query than standard decoding. Latent space test-time optimization methods like LatentSeek offer a more direct approach by steering hidden representations, but still demand expensive per-query optimization loops with multiple backward passes. We propose Amortized Latent Steering (ALS), which collapses this iterative optimization into a single offline-computed vector applied at constant cost during inference. ALS computes the mean difference between hidden states from successful versus unsuccessful generations, then uses this direction to calibrate the model's hidden representations: when decoding drifts away from the success manifold, ALS nudges activations back toward it. Across GSM8K and MATH-500 benchmarks, ALS achieves $2-5\\times$ speedup over iterative methods while matching or surpassing greedy Chain-of-Thought (CoT) and Self-Consistency baselines, yielding up to 101% improvement in efficiency--accuracy trade-off. These results show that much of latent optimization's benefit can be captured offline, making sophisticated reasoning techniques viable for production deployment. Code is available at https://github.com/negbuna/ALS.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.18116v2",
    "published_date": "2025-09-10 07:03:35 UTC",
    "updated_date": "2025-11-07 13:28:17 UTC"
  },
  {
    "arxiv_id": "2509.13333v2",
    "title": "Evaluation Awareness Scales Predictably in Open-Weights Large Language Models",
    "authors": [
      "Maheep Chaudhary",
      "Ian Su",
      "Nikhil Hooda",
      "Nishith Shankar",
      "Julia Tan",
      "Kevin Zhu",
      "Ryan Lagasse",
      "Vasu Sharma",
      "Ashwinee Panda"
    ],
    "abstract": "Large language models (LLMs) can internally distinguish between evaluation and deployment contexts, a behaviour known as \\emph{evaluation awareness}. This undermines AI safety evaluations, as models may conceal dangerous capabilities during testing. Prior work demonstrated this in a single $70$B model, but the scaling relationship across model sizes remains unknown. We investigate evaluation awareness across $15$ models scaling from $0.27$B to $70$B parameters from four families using linear probing on steering vector activations. Our results reveal a clear power-law scaling: evaluation awareness increases predictably with model size. This scaling law enables forecasting deceptive behavior in future larger models and guides the design of scale-aware evaluation strategies for AI safety. A link to the implementation of this paper can be found at https://anonymous.4open.science/r/evaluation-awareness-scaling-laws/README.md.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.13333v2",
    "published_date": "2025-09-10 06:36:38 UTC",
    "updated_date": "2025-11-09 17:13:27 UTC"
  },
  {
    "arxiv_id": "2509.08312v1",
    "title": "Leveraging AI Agents for Autonomous Networks: A Reference Architecture and Empirical Studies",
    "authors": [
      "Binghan Wu",
      "Shoufeng Wang",
      "Yunxin Liu",
      "Ya-Qin Zhang",
      "Joseph Sifakis",
      "Ye Ouyang"
    ],
    "abstract": "The evolution toward Level 4 (L4) Autonomous Networks (AN) represents a strategic inflection point in telecommunications, where networks must transcend reactive automation to achieve genuine cognitive capabilities--fulfilling TM Forum's vision of self-configuring, self-healing, and self-optimizing systems that deliver zero-wait, zero-touch, and zero-fault services. This work bridges the gap between architectural theory and operational reality by implementing Joseph Sifakis's AN Agent reference architecture in a functional cognitive system, deploying coordinated proactive-reactive runtimes driven by hybrid knowledge representation. Through an empirical case study of a Radio Access Network (RAN) Link Adaptation (LA) Agent, we validate this framework's transformative potential: demonstrating sub-10 ms real-time control in 5G NR sub-6 GHz while achieving 6% higher downlink throughput than Outer Loop Link Adaptation (OLLA) algorithms and 67% Block Error Rate (BLER) reduction for ultra-reliable services through dynamic Modulation and Coding Scheme (MCS) optimization. These improvements confirm the architecture's viability in overcoming traditional autonomy barriers and advancing critical L4-enabling capabilities toward next-generation objectives.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "7 pages, 5 figures. This manuscript is a preprint",
    "pdf_url": "https://arxiv.org/pdf/2509.08312v1",
    "published_date": "2025-09-10 06:24:57 UTC",
    "updated_date": "2025-09-10 06:24:57 UTC"
  },
  {
    "arxiv_id": "2509.08310v1",
    "title": "Game-Theoretic Resilience Framework for Cyber-Physical Microgrids using Multi-Agent Reinforcement Learning",
    "authors": [
      "S Krishna Niketh",
      "Sagar Babu Mitikiri",
      "V Vignesh",
      "Vedantham Lakshmi Srinivas",
      "Mayukha Pal"
    ],
    "abstract": "The increasing reliance on cyber physical infrastructure in modern power systems has amplified the risk of targeted cyber attacks, necessitating robust and adaptive resilience strategies. This paper presents a mathematically rigorous game theoretic framework to evaluate and enhance microgrid resilience using a combination of quantitative resilience metrics Load Served Ratio LSR, Critical Load Resilience CLR, Topological Survivability Score TSS, and DER Resilience Score DRS. These are integrated into a unified payoff matrix using the Analytic Hierarchy Process AHP to assess attack defense interactions. The framework is formalized as a finite horizon Markov Decision Process MDP with formal convergence guarantees and computational complexity bounds. Three case studies are developed 1. static attacks analyzed via Nash equilibrium, 2. severe attacks incorporating high impact strategies, and 3. adaptive attacks using Stackelberg games, regret matching, softmax heuristics, and Multi Agent Q Learning. Rigorous theoretical analysis provides convergence proofs with explicit rates , PAC learning sample complexity bounds, and computational complexity analysis. The framework is tested on an enhanced IEEE 33bus distribution system with DERs and control switches, demonstrating the effectiveness of adaptive and strategic defenses in improving cyber physical resilience with statistically significant improvements of 18.7% 2.1% over static approaches.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.08310v1",
    "published_date": "2025-09-10 06:07:34 UTC",
    "updated_date": "2025-09-10 06:07:34 UTC"
  },
  {
    "arxiv_id": "2509.09724v1",
    "title": "DiTTO-LLM: Framework for Discovering Topic-based Technology Opportunities via Large Language Model",
    "authors": [
      "Wonyoung Kim",
      "Sujeong Seo",
      "Juhyun Lee"
    ],
    "abstract": "Technology opportunities are critical information that serve as a foundation for advancements in technology, industry, and innovation. This paper proposes a framework based on the temporal relationships between technologies to identify emerging technology opportunities. The proposed framework begins by extracting text from a patent dataset, followed by mapping text-based topics to discover inter-technology relationships. Technology opportunities are then identified by tracking changes in these topics over time. To enhance efficiency, the framework leverages a large language model to extract topics and employs a prompt for a chat-based language model to support the discovery of technology opportunities. The framework was evaluated using an artificial intelligence patent dataset provided by the United States Patent and Trademark Office. The experimental results suggest that artificial intelligence technology is evolving into forms that facilitate everyday accessibility. This approach demonstrates the potential of the proposed framework to identify future technology opportunities.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "5 figures",
    "pdf_url": "https://arxiv.org/pdf/2509.09724v1",
    "published_date": "2025-09-10 05:47:25 UTC",
    "updated_date": "2025-09-10 05:47:25 UTC"
  },
  {
    "arxiv_id": "2509.08300v1",
    "title": "\\emph{FoQuS}: A Forgetting-Quality Coreset Selection Framework for Automatic Modulation Recognition",
    "authors": [
      "Yao Lu",
      "Chunfeng Sun",
      "Dongwei Xu",
      "Yun Lin",
      "Qi Xuan",
      "Guan Gui"
    ],
    "abstract": "Deep learning-based Automatic Modulation Recognition (AMR) model has made significant progress with the support of large-scale labeled data. However, when developing new models or performing hyperparameter tuning, the time and energy consumption associated with repeated training using massive amounts of data are often unbearable. To address the above challenges, we propose \\emph{FoQuS}, which approximates the effect of full training by selecting a coreset from the original dataset, thereby significantly reducing training overhead. Specifically, \\emph{FoQuS} records the prediction trajectory of each sample during full-dataset training and constructs three importance metrics based on training dynamics. Experiments show that \\emph{FoQuS} can maintain high recognition accuracy and good cross-architecture generalization on multiple AMR datasets using only 1\\%-30\\% of the original data.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.08300v1",
    "published_date": "2025-09-10 05:39:49 UTC",
    "updated_date": "2025-09-10 05:39:49 UTC"
  },
  {
    "arxiv_id": "2510.06224v1",
    "title": "Exploring Human-AI Collaboration Using Mental Models of Early Adopters of Multi-Agent Generative AI Tools",
    "authors": [
      "Suchismita Naik",
      "Austin L. Toombs",
      "Amanda Snellinger",
      "Scott Saponas",
      "Amanda K. Hall"
    ],
    "abstract": "With recent advancements in multi-agent generative AI (Gen AI), technology organizations like Microsoft are adopting these complex tools, redefining AI agents as active collaborators in complex workflows rather than as passive tools. In this study, we investigated how early adopters and developers conceptualize multi-agent Gen AI tools, focusing on how they understand human-AI collaboration mechanisms, general collaboration dynamics, and transparency in the context of AI tools. We conducted semi-structured interviews with 13 developers, all early adopters of multi-agent Gen AI technology who work at Microsoft. Our findings revealed that these early adopters conceptualize multi-agent systems as \"teams\" of specialized role-based and task-based agents, such as assistants or reviewers, structured similar to human collaboration models and ranging from AI-dominant to AI-assisted, user-controlled interactions. We identified key challenges, including error propagation, unpredictable and unproductive agent loop behavior, and the need for clear communication to mitigate the layered transparency issues. Early adopters' perspectives about the role of transparency underscored its importance as a way to build trust, verify and trace errors, and prevent misuse, errors, and leaks. The insights and design considerations we present contribute to CSCW research about collaborative mechanisms with capabilities ranging from AI-dominant to AI-assisted interactions, transparency and oversight strategies in human-agent and agent-agent interactions, and how humans make sense of these multi-agent systems as dynamic, role-diverse collaborators which are customizable for diverse needs and workflows. We conclude with future research directions that extend CSCW approaches to the design of inter-agent and human mediation interactions.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "19 pages, 1 table, 2 figures",
    "pdf_url": "https://arxiv.org/pdf/2510.06224v1",
    "published_date": "2025-09-10 05:35:38 UTC",
    "updated_date": "2025-09-10 05:35:38 UTC"
  },
  {
    "arxiv_id": "2509.19315v1",
    "title": "Advancing Few-Shot Pediatric Arrhythmia Classification with a Novel Contrastive Loss and Multimodal Learning",
    "authors": [
      "Yiqiao Chen",
      "Zijian Huang",
      "Zhenghui Feng"
    ],
    "abstract": "Pediatric arrhythmias are a major risk factor for disability and sudden cardiac death, yet their automated classification remains challenging due to class imbalance, few-shot categories, and complex signal characteristics, which severely limit the efficiency and reliability of early screening and clinical intervention. To address this problem, we propose a multimodal end-to-end deep learning framework that combines dual-branch convolutional encoders for ECG and IEGM, semantic attention for cross-modal feature alignment, and a lightweight Transformer encoder for global dependency modeling. In addition, we introduce a new contrastive loss fucntion named Adaptive Global Class-Aware Contrastive Loss (AGCACL) to enhance intra-class compactness and inter-class separability through class prototypes and a global similarity matrix. To the best of our knowledge, this is the first systematic study based on the Leipzig Heart Center pediatric/congenital ECG+IEGM dataset, for which we also provide a complete and reproducible preprocessing pipeline. Experimental results demonstrate that the proposed method achieves the overall best performance on this dataset, including 97.76\\% Top-1 Accuracy, 94.08\\% Macro Precision, 91.97\\% Macro Recall, 92.97\\% Macro F1, and 92.36\\% Macro F2, with improvements of +13.64, +15.96, +19.82, and +19.44 percentage points over the strongest baseline in Macro Precision/Recall/F1/F2, respectively. These findings indicate that the framework significantly improves the detectability and robustness for minority arrhythmia classes, offering potential clinical value for rhythm screening, pre-procedural assessment, and postoperative follow-up in pediatric and congenital heart disease populations.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "12pages, 10 figures",
    "pdf_url": "https://arxiv.org/pdf/2509.19315v1",
    "published_date": "2025-09-10 05:24:00 UTC",
    "updated_date": "2025-09-10 05:24:00 UTC"
  },
  {
    "arxiv_id": "2509.08283v1",
    "title": "Segment Transformer: AI-Generated Music Detection via Music Structural Analysis",
    "authors": [
      "Yumin Kim",
      "Seonghyeon Go"
    ],
    "abstract": "Audio and music generation systems have been remarkably developed in the music information retrieval (MIR) research field. The advancement of these technologies raises copyright concerns, as ownership and authorship of AI-generated music (AIGM) remain unclear. Also, it can be difficult to determine whether a piece was generated by AI or composed by humans clearly. To address these challenges, we aim to improve the accuracy of AIGM detection by analyzing the structural patterns of music segments. Specifically, to extract musical features from short audio clips, we integrated various pre-trained models, including self-supervised learning (SSL) models or an audio effect encoder, each within our suggested transformer-based framework. Furthermore, for long audio, we developed a segment transformer that divides music into segments and learns inter-segment relationships. We used the FakeMusicCaps and SONICS datasets, achieving high accuracy in both the short-audio and full-audio detection experiments. These findings suggest that integrating segment-level musical features into long-range temporal analysis can effectively enhance both the performance and robustness of AIGM detection systems.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.08283v1",
    "published_date": "2025-09-10 04:56:40 UTC",
    "updated_date": "2025-09-10 04:56:40 UTC"
  },
  {
    "arxiv_id": "2509.08282v1",
    "title": "Real-world Music Plagiarism Detection With Music Segment Transcription System",
    "authors": [
      "Seonghyeon Go"
    ],
    "abstract": "As a result of continuous advances in Music Information Retrieval (MIR) technology, generating and distributing music has become more diverse and accessible. In this context, interest in music intellectual property protection is increasing to safeguard individual music copyrights. In this work, we propose a system for detecting music plagiarism by combining various MIR technologies. We developed a music segment transcription system that extracts musically meaningful segments from audio recordings to detect plagiarism across different musical formats. With this system, we compute similarity scores based on multiple musical features that can be evaluated through comprehensive musical analysis. Our approach demonstrated promising results in music plagiarism detection experiments, and the proposed method can be applied to real-world music scenarios. We also collected a Similar Music Pair (SMP) dataset for musical similarity research using real-world cases. The dataset are publicly available.",
    "categories": [
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted in APSIPA 2025 but not published yet(will be published in 2 month..), Arxiv preprint ready for references in future-works",
    "pdf_url": "https://arxiv.org/pdf/2509.08282v1",
    "published_date": "2025-09-10 04:55:48 UTC",
    "updated_date": "2025-09-10 04:55:48 UTC"
  },
  {
    "arxiv_id": "2509.09723v2",
    "title": "ALIGNS: Unlocking nomological networks in psychological measurement through a large language model",
    "authors": [
      "Kai R. Larsen",
      "Sen Yan",
      "Roland M. Mueller",
      "Lan Sang",
      "Mikko Rönkkö",
      "Ravi Starzl",
      "Donald Edmondson"
    ],
    "abstract": "Psychological measurement is critical to many disciplines. Despite advances in measurement, building nomological networks, theoretical maps of how concepts and measures relate to establish validity, remains a challenge 70 years after Cronbach and Meehl proposed them as fundamental to validation. This limitation has practical consequences: clinical trials may fail to detect treatment effects, and public policy may target the wrong outcomes. We introduce Analysis of Latent Indicators to Generate Nomological Structures (ALIGNS), a large language model-based system trained with validated questionnaire measures. ALIGNS provides three comprehensive nomological networks containing over 550,000 indicators across psychology, medicine, social policy, and other fields. This represents the first application of large language models to solve a foundational problem in measurement validation. We report classification accuracy tests used to develop the model, as well as three evaluations. In the first evaluation, the widely used NIH PROMIS anxiety and depression instruments are shown to converge into a single dimension of emotional distress. The second evaluation examines child temperament measures and identifies four potential dimensions not captured by current frameworks, and questions one existing dimension. The third evaluation, an applicability check, engages expert psychometricians who assess the system's importance, accessibility, and suitability. ALIGNS is freely available at nomologicalnetwork.org, complementing traditional validation methods with large-scale nomological analysis.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "stat.ME"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.09723v2",
    "published_date": "2025-09-10 04:21:02 UTC",
    "updated_date": "2025-09-18 16:46:59 UTC"
  },
  {
    "arxiv_id": "2509.08270v1",
    "title": "Interpretable Physics Reasoning and Performance Taxonomy in Vision-Language Models",
    "authors": [
      "Pranav Pawar",
      "Kavish Shah",
      "Akshat Bhalani",
      "Komal Kasat",
      "Dev Mittal",
      "Hadi Gala",
      "Deepali Patil",
      "Nikita Raichada",
      "Monali Deshmukh"
    ],
    "abstract": "As Vision-Language Models (VLMs) grow in sophistication, their ability to perform reasoning is coming under increasing supervision. While they excel at many tasks, their grasp of fundamental scientific principles, such as physics, remains an underexplored frontier. To reflect the advancements in these capabilities, we introduce a novel and accessible framework designed to rigorously evaluate VLMs on their understanding of 2D physics. Our framework features a pragmatic scenario generator that creates a diverse testbed of over 400 problems across four core domains: Projectile Motion, Collision Dynamics, Mechanics, and Fluid Dynamics. Through comprehensive evaluation of four state-of-the-art VLMs, we demonstrate a strong correlation between model scale and reasoning ability, with our top-performing model, Qwen2.5-VL-7B, achieving an overall score of 0.815. We find that while models excel at formulaic problems, they struggle significantly with domains requiring abstract spatial reasoning. By designing this framework, we aim to democratize the study of scientific reasoning in VLMs and foster deeper insights into their capabilities and limitations.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.08270v1",
    "published_date": "2025-09-10 04:15:01 UTC",
    "updated_date": "2025-09-10 04:15:01 UTC"
  },
  {
    "arxiv_id": "2509.08269v4",
    "title": "A Systematic Survey on Large Language Models for Evolutionary Optimization: From Modeling to Solving",
    "authors": [
      "Yisong Zhang",
      "Ran Cheng",
      "Guoxing Yi",
      "Kay Chen Tan"
    ],
    "abstract": "Large Language Models (LLMs) possess substantial reasoning capabilities and are increasingly applied to optimization tasks, particularly in synergy with evolutionary computation. However, while recent surveys have explored specific aspects of this domain, they lack an integrative perspective that connects problem modeling with solving workflows. To address this gap, we present a systematic review of recent developments and organize them within a structured framework. First, we classify existing research into two primary stages: LLMs for optimization modeling and LLMs for optimization solving. Second, we divide the latter into three paradigms based on the role of the LLM: stand-alone optimizers, low-level components embedded within algorithms, and high-level managers for algorithm selection and generation. Third, for each category, we analyze representative methods, distill technical challenges, and examine their interplay with traditional approaches. Finally, we review interdisciplinary applications across the natural sciences, engineering, and machine learning. Based on this analysis, we highlight key limitations and point toward future directions for developing self-evolving agentic ecosystems. An up-to-date collection of related literature is maintained at https://github.com/ishmael233/LLM4OPT.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.08269v4",
    "published_date": "2025-09-10 04:05:54 UTC",
    "updated_date": "2026-01-07 07:50:30 UTC"
  },
  {
    "arxiv_id": "2509.08257v2",
    "title": "Symmetry-Guided Multi-Agent Inverse Reinforcement Learning",
    "authors": [
      "Yongkai Tian",
      "Yirong Qi",
      "Xin Yu",
      "Wenjun Wu",
      "Jie Luo"
    ],
    "abstract": "In robotic systems, the performance of reinforcement learning depends on the rationality of predefined reward functions. However, manually designed reward functions often lead to policy failures due to inaccuracies. Inverse Reinforcement Learning (IRL) addresses this problem by inferring implicit reward functions from expert demonstrations. Nevertheless, existing methods rely heavily on large amounts of expert demonstrations to accurately recover the reward function. The high cost of collecting expert demonstrations in robotic applications, particularly in multi-robot systems, severely hinders the practical deployment of IRL. Consequently, improving sample efficiency has emerged as a critical challenge in multi-agent inverse reinforcement learning (MIRL). Inspired by the symmetry inherent in multi-agent systems, this work theoretically demonstrates that leveraging symmetry enables the recovery of more accurate reward functions. Building upon this insight, we propose a universal framework that integrates symmetry into existing multi-agent adversarial IRL algorithms, thereby significantly enhancing sample efficiency. Experimental results from multiple challenging tasks have demonstrated the effectiveness of this framework. Further validation in physical multi-robot systems has shown the practicality of our method.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "8pages, 6 figures. Accepted for publication in the Proceedings of the 2025 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2025) as oral presentation",
    "pdf_url": "https://arxiv.org/pdf/2509.08257v2",
    "published_date": "2025-09-10 03:28:18 UTC",
    "updated_date": "2025-09-11 02:34:59 UTC"
  },
  {
    "arxiv_id": "2509.08239v1",
    "title": "Combined-distance-based score function of cognitive fuzzy sets and its application in lung cancer pain evaluation",
    "authors": [
      "Lisheng Jiang",
      "Tianyu Zhang",
      "Shiyu Yan",
      "Ran Fang"
    ],
    "abstract": "In decision making, the cognitive fuzzy set (CFS) is a useful tool in expressing experts' complex assessments of alternatives. The distance of CFS, which plays an important role in decision analyses, is necessary when the CFS is applied in solving practical issues. However, as far as we know, the studies on the distance of CFS are few, and the current Minkowski distance of CFS ignores the hesitancy degree of CFS, which might cause errors. To fill the gap of the studies on the distance of CFS, because of the practicality of the Hausdorff distance, this paper proposes the improved cognitive fuzzy Minkowski (CF-IM) distance and the cognitive fuzzy Hausdorff (CF-H) distance to enrich the studies on the distance of CFS. It is found that the anti-perturbation ability of the CF-H distance is stronger than that of the CF-IM distance, but the information utilization of the CF-IM distance is higher than that of the CF-H distance. To balance the anti-perturbation ability and information utilization of the CF-IM distance and CF-H distance, the cognitive fuzzy combined (CF-C) distance is proposed by establishing the linear combination of the CF-IM distance and CF-H distance. Based on the CF-C distance, a combined-distanced-based score function of CFS is proposed to compare CFSs. The proposed score function is employed in lung cancer pain evaluation issues. The sensitivity and comparison analyses demonstrate the reliability and advantages of the proposed methods.",
    "categories": [
      "math.OC",
      "cs.AI"
    ],
    "primary_category": "math.OC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.08239v1",
    "published_date": "2025-09-10 02:44:02 UTC",
    "updated_date": "2025-09-10 02:44:02 UTC"
  },
  {
    "arxiv_id": "2509.08862v1",
    "title": "Investigating Student Interaction Patterns with Large Language Model-Powered Course Assistants in Computer Science Courses",
    "authors": [
      "Chang Liu",
      "Loc Hoang",
      "Andrew Stolman",
      "Rene F. Kizilcec",
      "Bo Wu"
    ],
    "abstract": "Providing students with flexible and timely academic support is a challenge at most colleges and universities, leaving many students without help outside scheduled hours. Large language models (LLMs) are promising for bridging this gap, but interactions between students and LLMs are rarely overseen by educators. We developed and studied an LLM-powered course assistant deployed across multiple computer science courses to characterize real-world use and understand pedagogical implications. By Spring 2024, our system had been deployed to approximately 2,000 students across six courses at three institutions. Analysis of the interaction data shows that usage remains strong in the evenings and nights and is higher in introductory courses, indicating that our system helps address temporal support gaps and novice learner needs. We sampled 200 conversations per course for manual annotation: most sampled responses were judged correct and helpful, with a small share unhelpful or erroneous; few responses included dedicated examples. We also examined an inquiry-based learning strategy: only around 11% of sampled conversations contained LLM-generated follow-up questions, which were often ignored by students in advanced courses. A Bloom's taxonomy analysis reveals that current LLM capabilities are limited in generating higher-order cognitive questions. These patterns suggest opportunities for pedagogically oriented LLM-based educational systems and greater educator involvement in configuring prompts, content, and policies.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.08862v1",
    "published_date": "2025-09-10 02:21:11 UTC",
    "updated_date": "2025-09-10 02:21:11 UTC"
  },
  {
    "arxiv_id": "2509.08233v1",
    "title": "Strategies for Improving Communication Efficiency in Distributed and Federated Learning: Compression, Local Training, and Personalization",
    "authors": [
      "Kai Yi"
    ],
    "abstract": "Distributed and federated learning are essential paradigms for training models across decentralized data sources while preserving privacy, yet communication overhead remains a major bottleneck. This dissertation explores strategies to improve communication efficiency, focusing on model compression, local training, and personalization. We establish a unified framework for biased and unbiased compression operators with convergence guarantees, then propose adaptive local training strategies that incorporate personalization to accelerate convergence and mitigate client drift. In particular, Scafflix balances global and personalized objectives, achieving superior performance under both IID and non-IID settings. We further introduce privacy-preserving pruning frameworks that optimize sparsity while minimizing communication costs, with Cohort-Squeeze leveraging hierarchical aggregation to reduce cross-device overhead. Finally, SymWanda, a symmetric post-training pruning method, enhances robustness under high sparsity and maintains accuracy without retraining. Extensive experiments on benchmarks and large-scale language models demonstrate favorable trade-offs among accuracy, convergence, and communication, offering theoretical and practical insights for scalable, efficient distributed learning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "PhD Dissertation",
    "pdf_url": "https://arxiv.org/pdf/2509.08233v1",
    "published_date": "2025-09-10 02:19:56 UTC",
    "updated_date": "2025-09-10 02:19:56 UTC"
  },
  {
    "arxiv_id": "2509.09721v1",
    "title": "A Multimodal RAG Framework for Housing Damage Assessment: Collaborative Optimization of Image Encoding and Policy Vector Retrieval",
    "authors": [
      "Jiayi Miao",
      "Dingxin Lu",
      "Zhuqi Wang"
    ],
    "abstract": "After natural disasters, accurate evaluations of damage to housing are important for insurance claims response and planning of resources. In this work, we introduce a novel multimodal retrieval-augmented generation (MM-RAG) framework. On top of classical RAG architecture, we further the framework to devise a two-branch multimodal encoder structure that the image branch employs a visual encoder composed of ResNet and Transformer to extract the characteristic of building damage after disaster, and the text branch harnesses a BERT retriever for the text vectorization of posts as well as insurance policies and for the construction of a retrievable restoration index. To impose cross-modal semantic alignment, the model integrates a cross-modal interaction module to bridge the semantic representation between image and text via multi-head attention. Meanwhile, in the generation module, the introduced modal attention gating mechanism dynamically controls the role of visual evidence and text prior information during generation. The entire framework takes end-to-end training, and combines the comparison loss, the retrieval loss and the generation loss to form multi-task optimization objectives, and achieves image understanding and policy matching in collaborative learning. The results demonstrate superior performance in retrieval accuracy and classification index on damage severity, where the Top-1 retrieval accuracy has been improved by 9.6%.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.09721v1",
    "published_date": "2025-09-10 01:58:07 UTC",
    "updated_date": "2025-09-10 01:58:07 UTC"
  },
  {
    "arxiv_id": "2509.08222v1",
    "title": "Exploratory Retrieval-Augmented Planning For Continual Embodied Instruction Following",
    "authors": [
      "Minjong Yoo",
      "Jinwoo Jang",
      "Wei-jin Park",
      "Honguk Woo"
    ],
    "abstract": "This study presents an Exploratory Retrieval-Augmented Planning (ExRAP) framework, designed to tackle continual instruction following tasks of embodied agents in dynamic, non-stationary environments. The framework enhances Large Language Models' (LLMs) embodied reasoning capabilities by efficiently exploring the physical environment and establishing the environmental context memory, thereby effectively grounding the task planning process in time-varying environment contexts. In ExRAP, given multiple continual instruction following tasks, each instruction is decomposed into queries on the environmental context memory and task executions conditioned on the query results. To efficiently handle these multiple tasks that are performed continuously and simultaneously, we implement an exploration-integrated task planning scheme by incorporating the {information-based exploration} into the LLM-based planning process. Combined with memory-augmented query evaluation, this integrated scheme not only allows for a better balance between the validity of the environmental context memory and the load of environment exploration, but also improves overall task performance. Furthermore, we devise a {temporal consistency refinement} scheme for query evaluation to address the inherent decay of knowledge in the memory. Through experiments with VirtualHome, ALFRED, and CARLA, our approach demonstrates robustness against a variety of embodied instruction following scenarios involving different instruction scales and types, and non-stationarity degrees, and it consistently outperforms other state-of-the-art LLM-based task planning approaches in terms of both goal success rate and execution efficiency.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "21 pages. NeurIPS 2024",
    "pdf_url": "https://arxiv.org/pdf/2509.08222v1",
    "published_date": "2025-09-10 01:39:51 UTC",
    "updated_date": "2025-09-10 01:39:51 UTC"
  },
  {
    "arxiv_id": "2509.08217v2",
    "title": "Balancing Quality and Variation: Spam Filtering Distorts Data Label Distributions",
    "authors": [
      "Eve Fleisig",
      "Matthias Orlikowski",
      "Philipp Cimiano",
      "Dan Klein"
    ],
    "abstract": "For machine learning datasets to accurately represent diverse opinions in a population, they must preserve variation in data labels while filtering out spam or low-quality responses. How can we balance annotator reliability and representation? We empirically evaluate how a range of heuristics for annotator filtering affect the preservation of variation on subjective tasks. We find that these methods, designed for contexts in which variation from a single ground-truth label is considered noise, often remove annotators who disagree instead of spam annotators, introducing suboptimal tradeoffs between accuracy and label diversity. We find that conservative settings for annotator removal (<5%) are best, after which all tested methods increase the mean absolute error from the true average label. We analyze performance on synthetic spam to observe that these methods often assume spam annotators are more random than real spammers tend to be: most spammers are distributionally indistinguishable from real annotators, and the minority that are distinguishable tend to give relatively fixed answers, not random ones. Thus, tasks requiring the preservation of variation reverse the intuition of existing spam filtering methods: spammers tend to be less random than non-spammers, so metrics that assume variation is spam fare worse. These results highlight the need for spam removal methods that account for label diversity.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.08217v2",
    "published_date": "2025-09-10 01:22:07 UTC",
    "updated_date": "2025-11-06 18:49:56 UTC"
  },
  {
    "arxiv_id": "2509.08203v1",
    "title": "Componentization: Decomposing Monolithic LLM Responses into Manipulable Semantic Units",
    "authors": [
      "Ryan Lingo",
      "Rajeev Chhajer",
      "Martin Arroyo",
      "Luka Brkljacic",
      "Ben Davis",
      "Nithin Santhanam"
    ],
    "abstract": "Large Language Models (LLMs) often produce monolithic text that is hard to edit in parts, which can slow down collaborative workflows. We present componentization, an approach that decomposes model outputs into modular, independently editable units while preserving context. We describe Modular and Adaptable Output Decomposition (MAOD), which segments responses into coherent components and maintains links among them, and we outline the Component-Based Response Architecture (CBRA) as one way to implement this idea. Our reference prototype, MAODchat, uses a microservices design with state-machine-based decomposition agents, vendor-agnostic model adapters, and real-time component manipulation with recomposition.\n  In an exploratory study with four participants from academic, engineering, and product roles, we observed that component-level editing aligned with several common workflows and enabled iterative refinement and selective reuse. Participants also mentioned possible team workflows. Our contributions are: (1) a definition of componentization for transforming monolithic outputs into manipulable units, (2) CBRA and MAODchat as a prototype architecture, (3) preliminary observations from a small user study, (4) MAOD as an algorithmic sketch for semantic segmentation, and (5) example Agent-to-Agent protocols for automated decomposition. We view componentization as a promising direction for turning passive text consumption into more active, component-level collaboration.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.HC",
    "comment": "12 pages, 4 figures",
    "pdf_url": "https://arxiv.org/pdf/2509.08203v1",
    "published_date": "2025-09-10 00:15:33 UTC",
    "updated_date": "2025-09-10 00:15:33 UTC"
  },
  {
    "arxiv_id": "2509.08200v1",
    "title": "Accelerating AI Development with Cyber Arenas",
    "authors": [
      "William Cashman",
      "Chasen Milner",
      "Michael Houle",
      "Michael Jones",
      "Hayden Jananthan",
      "Jeremy Kepner",
      "Peter Michaleas",
      "Alex Pentland"
    ],
    "abstract": "AI development requires high fidelity testing environments to effectively transition from the laboratory to operations. The flexibility offered by cyber arenas presents a novel opportunity to test new artificial intelligence (AI) capabilities with users. Cyber arenas are designed to expose end-users to real-world situations and must rapidly incorporate evolving capabilities to meet their core objectives. To explore this concept the MIT/IEEE/Amazon Graph Challenge Anonymized Network Sensor was deployed in a cyber arena during a National Guard exercise.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CR",
    "comment": "2 pages, 1 figure, 7 references, accepted to IEEE HPEC 2025",
    "pdf_url": "https://arxiv.org/pdf/2509.08200v1",
    "published_date": "2025-09-10 00:12:39 UTC",
    "updated_date": "2025-09-10 00:12:39 UTC"
  }
]