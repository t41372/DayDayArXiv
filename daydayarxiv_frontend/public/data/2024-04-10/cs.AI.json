{
  "date": "2024-04-10",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-04-10 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 87 篇论文，主要聚焦 AI 和机器学习领域，包括大型语言模型（LLM）的对话生成、知识图谱推理、生成 AI 的安全性和伦理挑战，以及 AI 在医学和环境中的应用；令人印象深刻的文章包括 OpenAI 团队的对话生成研究（如 Sora 相关）、ACL 和 NeurIPS 接受的逻辑推理模型，以及多模态脑信号处理方法。\n\n### 重点论文讨论\n我将优先讨论最具话题度和影响力的论文，包括 LLM 优化、生成模型创新、AI 伦理和医学应用等领域。相关论文按主题归类，先聊这些，然后快速掠过其他。\n\n#### LLM 和生成模型领域\n这些论文探讨了大型语言模型的改进和应用，涉及对话生成、知识推理和多样性增强，体现了 AI 的前沿进展。\n- **Incremental XAI: Memorable Understanding of AI with Incremental Explanations（渐进式可解释 AI：通过渐进式解释提升 AI 的可记忆理解）**  \n  这篇论文提出了一种渐进式解释框架，用于提升 AI 模型的可解释性和用户记忆效果。主要贡献是通过增量解释（如 Base + Incremental 因素）改善模型忠实度，用户研究显示其在记忆和理解上优于基线方法，适用于复杂 AI 决策场景。\n  \n- **DreamScene360: Text-Driven 3D Scene Generation with Inpainting and Depth Diffusion（DreamScene360：基于文本驱动的 3D 场景生成，使用补全和深度扩散）**  \n  作者包括 Ravi Ramamoorthi 等知名学者。论文引入一种文本到 3D 场景生成方法，使用扩散模型和高保真几何约束。主要发现是通过 Inpainting 和 Depth Diffusion 提升生成质量，用户研究显示其在沉浸式场景生成中优于现有方法，已被 3DV 2025 接受。\n\n- **Infini-attention: Efficient Infinite Context Transformers（Infini-attention：高效的无穷上下文 Transformer）**  \n  作者包括 Tsendsuren Munkhdalai。论文提出 Infini-attention 机制，将压缩记忆融入 Transformer，实现高效长序列处理。主要贡献是减少计算开销，用户实验证明其在长上下文任务中加速推理，同时保持性能。\n\n- **A Foundation Model for Zero-shot Logical Query Reasoning（零样本逻辑查询推理的基础模型）**  \n  作者包括 Jian Tang 和 Zhaocheng Zhu，已被 NeurIPS 2024 接受。论文开发了 UltraQuery 模型，支持零样本知识图谱查询。主要发现是通过词汇无关函数处理投影和逻辑操作，在 23 个数据集上超越基线，显著提升推理效率。\n\n- **GoodDrag: Towards Good Practices for Drag Editing with Diffusion Models（GoodDrag：针对扩散模型的拖拽编辑最佳实践）**  \n  论文提出 AlDD 框架，优化扩散模型的拖拽编辑稳定性。主要贡献是引入信息保留机制和新评估指标（如 Dragging Accuracy Index），实验显示其在图像编辑任务中优于 SOTA 方法。\n\n- **RealmDreamer: Text-Driven 3D Scene Generation with Inpainting and Depth Diffusion（RealmDreamer：基于文本驱动的 3D 场景生成，使用补全和深度扩散）**  \n  作者包括 Jaidev Shriram 和 Ravi Ramamoorthi。论文使用 3D 高斯点云优化文本到 3D 场景生成，主要发现是提升全局一致性和沉浸感，用户研究显示其在多风格生成中领先。\n\n#### AI 伦理和安全领域\n这些论文关注 AI 的潜在风险和治理，尤以生成模型的安全性为热点。\n- **SafeGen: Mitigating Sexually Explicit Content Generation in Text-to-Image Models（SafeGen：缓解文本到图像模型中性内容生成的策略）**  \n  论文提出 SafeGen 框架，文本无关地阻断显性视觉表示。主要贡献是通过文本无关方法（如 TfS 损失）移除不安全内容，实验在多个数据集上实现 99.4% 的移除率，同时保持良性图像质量。\n\n- **PoliTune: Analyzing the Impact of Data Selection and Fine-Tuning on Economic and Political Biases in Large Language Models（PoliTune：分析数据选择和微调对 LLM 经济和政治偏差的影响）**  \n  作者包括 Sherief Reda。论文使用 PEFT 技术微调 LLM 以对齐特定意识形态，主要发现是通过指令微调减少偏差，在多任务上提升鲁棒性，已被 AIES 2024 接受。\n\n- **Sora is Incredible and Scary: Emerging Governance Challenges of Text-to-Video Generative AI Models（Sora 的惊人与可怕：文本到视频生成 AI 模型的治理挑战）**  \n  论文讨论文本到视频模型（如 Sora）的社会影响，主要贡献是识别治理挑战（如版权和环境影响），并提出政策建议，如强制 AI 内容标记。\n\n#### 医学和应用 AI 领域\n这些论文将 AI 应用于实际问题，如医学图像和健康监测，展示了 AI 的实用价值。\n- **UMBRAE: Unified Multimodal Brain Decoding（UMBRAE：统一的 multimodal 脑信号解码）**  \n  作者包括 Raoul de Charette 和 Jing-Hao Xue，已被 ECCV 2024 接受。论文提出跨主体训练策略，支持脑信号的多粒度解码。主要发现是通过变分自编码器提升解码准确性，在新基准 BrainHub 上超越 SOTA。\n\n- **NeuroNet: A Novel Hybrid Self-Supervised Learning Framework for Sleep Stage Classification Using Single-Channel EEG（NeuroNet：基于单通道 EEG 的新型混合自监督学习框架，用于睡眠阶段分类）**  \n  论文引入自监督框架和 Mamba-based 模块，实现高效睡眠阶段分类。主要贡献是使用无标签数据训练，提升性能并减少标注需求，在多个数据集上超越监督方法。\n\n### 其他论文简评\n剩余论文涉及强化学习、图像处理和优化算法等主题，但多数较为技术性或不具话题度，我仅快速掠过。例如：\n- **Learn from Failure: Fine-Tuning LLMs with Trial-and-Error Data for Intuitionistic Propositional Logic Proving（从失败中学习：使用试错数据微调 LLM 用于直觉命题逻辑证明）**，已获 ACL 2024 接受，主要发现是通过试错数据提升定理证明效率。\n- 其他如处理微塑料数据生成（GANsemble）和机器人操作（Interactive Learning）的论文，贡献包括新框架和数据集，但影响力有限，仅在特定领域有应用。\n\n总之，今天的 arXiv 突显 AI 模型的多样性和挑战，LLM 相关创新（如零样本推理和对话生成）最值得关注，建议读者优先探索这些方向。更多细节可查阅 arXiv。",
  "papers": [
    {
      "arxiv_id": "2404.07387v3",
      "title": "BISCUIT: Scaffolding LLM-Generated Code with Ephemeral UIs in Computational Notebooks",
      "title_zh": "翻译失败",
      "authors": [
        "Ruijia Cheng",
        "Titus Barik",
        "Alan Leung",
        "Fred Hohman",
        "Jeffrey Nichols"
      ],
      "abstract": "Programmers frequently engage with machine learning tutorials in\ncomputational notebooks and have been adopting code generation technologies\nbased on large language models (LLMs). However, they encounter difficulties in\nunderstanding and working with code produced by LLMs. To mitigate these\nchallenges, we introduce a novel workflow into computational notebooks that\naugments LLM-based code generation with an additional ephemeral UI step,\noffering users UI scaffolds as an intermediate stage between user prompts and\ncode generation. We present this workflow in BISCUIT, an extension for\nJupyterLab that provides users with ephemeral UIs generated by LLMs based on\nthe context of their code and intentions, scaffolding users to understand,\nguide, and explore with LLM-generated code. Through a user study where 10\nnovices used BISCUIT for machine learning tutorials, we found that BISCUIT\noffers users representations of code to aid their understanding, reduces the\ncomplexity of prompt engineering, and creates a playground for users to explore\ndifferent variables and iterate on their ideas.",
      "tldr_zh": "该研究提出 BISCUIT，一种扩展工具，用于在计算笔记本（computational notebooks）中辅助大型语言模型（LLMs）生成的代码。BISCUIT 通过引入短暂 UI（ephemeral UIs）作为用户提示和代码生成之间的中间步骤，帮助用户更好地理解、指导和探索代码。用户研究显示，在 10 名新手参与的机器学习教程中，BISCUIT 提升了代码表示的可理解性，降低了提示工程（prompt engineering）的复杂性，并为用户提供了探索变量和迭代想法的交互平台。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.07387v3",
      "published_date": "2024-04-10 23:28:09 UTC",
      "updated_date": "2024-07-12 03:23:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:08:49.028811"
    },
    {
      "arxiv_id": "2404.07383v1",
      "title": "Incorporating Explanations into Human-Machine Interfaces for Trust and Situation Awareness in Autonomous Vehicles",
      "title_zh": "将解释融入人机界面以提升自动驾驶车辆中的信任和情境感知",
      "authors": [
        "Shahin Atakishiyev",
        "Mohammad Salameh",
        "Randy Goebel"
      ],
      "abstract": "Autonomous vehicles often make complex decisions via machine learning-based\npredictive models applied to collected sensor data. While this combination of\nmethods provides a foundation for real-time actions, self-driving behavior\nprimarily remains opaque to end users. In this sense, explainability of\nreal-time decisions is a crucial and natural requirement for building trust in\nautonomous vehicles. Moreover, as autonomous vehicles still cause serious\ntraffic accidents for various reasons, timely conveyance of upcoming hazards to\nroad users can help improve scene understanding and prevent potential risks.\nHence, there is also a need to supply autonomous vehicles with user-friendly\ninterfaces for effective human-machine teaming. Motivated by this problem, we\nstudy the role of explainable AI and human-machine interface jointly in\nbuilding trust in vehicle autonomy. We first present a broad context of the\nexplanatory human-machine systems with the \"3W1H\" (what, whom, when, how)\napproach. Based on these findings, we present a situation awareness framework\nfor calibrating users' trust in self-driving behavior. Finally, we perform an\nexperiment on our framework, conduct a user study on it, and validate the\nempirical findings with hypothesis testing.",
      "tldr_zh": "本论文探讨了在自动驾驶车辆中，将解释性 AI 融入人机接口，以提升用户信任和情境感知(Situation Awareness)。研究者采用“3W1H”（what, whom, when, how）方法，构建了一个解释性人机系统框架，用于实时传达决策细节和潜在风险，从而校准用户对自驾行为的信任。通过实验和用户研究，并进行假设测试，验证了该框架能显著改善用户理解和风险预防，为更可靠的人机团队协作提供了基础。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted to IEEE IV-2024",
      "pdf_url": "http://arxiv.org/pdf/2404.07383v1",
      "published_date": "2024-04-10 23:02:13 UTC",
      "updated_date": "2024-04-10 23:02:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:09:01.592143"
    },
    {
      "arxiv_id": "2404.07382v3",
      "title": "Learn from Failure: Fine-Tuning LLMs with Trial-and-Error Data for Intuitionistic Propositional Logic Proving",
      "title_zh": "翻译失败",
      "authors": [
        "Chenyang An",
        "Zhibo Chen",
        "Qihao Ye",
        "Emily First",
        "Letian Peng",
        "Jiayun Zhang",
        "Zihan Wang",
        "Sorin Lerner",
        "Jingbo Shang"
      ],
      "abstract": "Recent advances in Automated Theorem Proving have shown the effectiveness of\nleveraging a (large) language model that generates tactics (i.e. proof steps)\nto search through proof states. The current model, while trained solely on\nsuccessful proof paths, faces a discrepancy at the inference stage, as it must\nsample and try various tactics at each proof state until finding success,\nunlike its training which does not incorporate learning from failed attempts.\nIntuitively, a tactic that leads to a failed search path would indicate that\nsimilar tactics should receive less attention during the following trials. In\nthis paper, we demonstrate the benefit of training models that additionally\nlearn from failed search paths. Facing the lack of such trial-and-error data in\nexisting open-source theorem-proving datasets, we curate a dataset on\nintuitionistic propositional logic theorems and formalize it in Lean, such that\nwe can reliably check the correctness of proofs. We compare our model trained\non relatively short trial-and-error information (TrialMaster) with models\ntrained only on the correct paths and discover that the former solves more\nunseen theorems with lower trial searches.",
      "tldr_zh": "本论文提出了一种从失败中学习的方法，通过使用试错数据（Trial-and-Error Data）细调大型语言模型（LLMs），以提升直觉主义命题逻辑（Intuitionistic Propositional Logic）证明的效率。作者创建了一个新数据集，针对该逻辑的定理，并使用 Lean 形式化来验证证明正确性。相比仅训练于成功证明路径的模型，新模型 TrialMaster 在处理未见定理时，能够减少尝试次数并解决更多问题，从而桥接了训练与推理阶段的差距。",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted as a main conference paper at ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.07382v3",
      "published_date": "2024-04-10 23:01:45 UTC",
      "updated_date": "2024-07-29 20:57:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:09:12.538853"
    },
    {
      "arxiv_id": "2404.08018v1",
      "title": "Analyzing the Performance of Large Language Models on Code Summarization",
      "title_zh": "大型语言模型在代码总结任务中的性能分析",
      "authors": [
        "Rajarshi Haldar",
        "Julia Hockenmaier"
      ],
      "abstract": "Large language models (LLMs) such as Llama 2 perform very well on tasks that\ninvolve both natural language and source code, particularly code summarization\nand code generation. We show that for the task of code summarization, the\nperformance of these models on individual examples often depends on the amount\nof (subword) token overlap between the code and the corresponding reference\nnatural language descriptions in the dataset. This token overlap arises because\nthe reference descriptions in standard datasets (corresponding to docstrings in\nlarge code bases) are often highly similar to the names of the functions they\ndescribe. We also show that this token overlap occurs largely in the function\nnames of the code and compare the relative performance of these models after\nremoving function names versus removing code structure. We also show that using\nmultiple evaluation metrics like BLEU and BERTScore gives us very little\nadditional insight since these metrics are highly correlated with each other.",
      "tldr_zh": "本研究分析了大语言模型 (LLMs) 如 Llama 2 在代码摘要任务中的性能，发现模型的表现往往依赖于代码和参考自然语言描述之间的子词 token overlap。研究表明，这种 token overlap 主要源于数据集中的参考描述（如文档字符串）与函数名称的高度相似性，并通过比较移除函数名称与移除代码结构后的模型性能来量化其影响。最终，论文指出，使用多个评估指标如 BLEU 和 BERTScore 提供有限洞见，因为这些指标之间高度相关，从而强调了评估方法的潜在局限性。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.08018v1",
      "published_date": "2024-04-10 22:42:18 UTC",
      "updated_date": "2024-04-10 22:42:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:09:24.080976"
    },
    {
      "arxiv_id": "2404.07377v1",
      "title": "Deep Generative Sampling in the Dual Divergence Space: A Data-efficient & Interpretative Approach for Generative AI",
      "title_zh": "翻译失败",
      "authors": [
        "Sahil Garg",
        "Anderson Schneider",
        "Anant Raj",
        "Kashif Rasul",
        "Yuriy Nevmyvaka",
        "Sneihil Gopal",
        "Amit Dhurandhar",
        "Guillermo Cecchi",
        "Irina Rish"
      ],
      "abstract": "Building on the remarkable achievements in generative sampling of natural\nimages, we propose an innovative challenge, potentially overly ambitious, which\ninvolves generating samples of entire multivariate time series that resemble\nimages. However, the statistical challenge lies in the small sample size,\nsometimes consisting of a few hundred subjects. This issue is especially\nproblematic for deep generative models that follow the conventional approach of\ngenerating samples from a canonical distribution and then decoding or denoising\nthem to match the true data distribution. In contrast, our method is grounded\nin information theory and aims to implicitly characterize the distribution of\nimages, particularly the (global and local) dependency structure between\npixels. We achieve this by empirically estimating its KL-divergence in the dual\nform with respect to the respective marginal distribution. This enables us to\nperform generative sampling directly in the optimized 1-D dual divergence\nspace. Specifically, in the dual space, training samples representing the data\ndistribution are embedded in the form of various clusters between two end\npoints. In theory, any sample embedded between those two end points is\nin-distribution w.r.t. the data distribution. Our key idea for generating novel\nsamples of images is to interpolate between the clusters via a walk as per\ngradients of the dual function w.r.t. the data dimensions. In addition to the\ndata efficiency gained from direct sampling, we propose an algorithm that\noffers a significant reduction in sample complexity for estimating the\ndivergence of the data distribution with respect to the marginal distribution.\nWe provide strong theoretical guarantees along with an extensive empirical\nevaluation using many real-world datasets from diverse domains, establishing\nthe superiority of our approach w.r.t. state-of-the-art deep learning methods.",
      "tldr_zh": "这篇论文提出了一种基于双重散度空间（dual divergence space）的深度生成采样方法，用于生成 AI，尤其适用于小样本多变量时间序列图像的生成挑战。该方法根植于信息理论，通过估计数据分布相对于边缘分布的 KL-divergence 双重形式，在优化的 1-D 空间中直接采样，实现集群间插值和梯度行走生成新样本。这种数据高效且可解释的算法显著降低了样本复杂度，并通过理论保证和广泛实证评估（如多个真实数据集），证明其在数据效率和性能上优于现有深度学习方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.07377v1",
      "published_date": "2024-04-10 22:35:06 UTC",
      "updated_date": "2024-04-10 22:35:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:09:37.546875"
    },
    {
      "arxiv_id": "2404.07366v1",
      "title": "Differentially Private GANs for Generating Synthetic Indoor Location Data",
      "title_zh": "翻译失败",
      "authors": [
        "Vahideh Moghtadaiee",
        "Mina Alishahi",
        "Milad Rabiei"
      ],
      "abstract": "The advent of location-based services has led to the widespread adoption of\nindoor localization systems, which enable location tracking of individuals\nwithin enclosed spaces such as buildings. While these systems provide numerous\nbenefits such as improved security and personalized services, they also raise\nconcerns regarding privacy violations. As such, there is a growing need for\nprivacy-preserving solutions that can protect users' sensitive location\ninformation while still enabling the functionality of indoor localization\nsystems. In recent years, Differentially Private Generative Adversarial\nNetworks (DPGANs) have emerged as a powerful methodology that aims to protect\nthe privacy of individual data points while generating realistic synthetic data\nsimilar to original data. DPGANs combine the power of generative adversarial\nnetworks (GANs) with the privacy-preserving technique of differential privacy\n(DP). In this paper, we introduce an indoor localization framework employing\nDPGANs in order to generate privacy-preserving indoor location data. We\nevaluate the performance of our framework on a real-world indoor localization\ndataset and demonstrate its effectiveness in preserving privacy while\nmaintaining the accuracy of the localization system.",
      "tldr_zh": "该论文探讨了室内定位系统的隐私问题，提出使用Differentially Private GANs (DPGANs)生成合成室内位置数据，以保护用户敏感信息。DPGANs结合Generative Adversarial Networks (GANs)和differential privacy (DP)技术，实现了隐私保护的同时生成与原始数据相似的合成数据。研究在真实数据集上评估了该框架，证明其有效性，能够维持定位系统的准确性，同时显著提升隐私安全性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.CR",
      "comment": "Submitted to International Journal of Information Security",
      "pdf_url": "http://arxiv.org/pdf/2404.07366v1",
      "published_date": "2024-04-10 21:43:27 UTC",
      "updated_date": "2024-04-10 21:43:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:09:47.135993"
    },
    {
      "arxiv_id": "2404.07356v2",
      "title": "GANsemble for Small and Imbalanced Data Sets: A Baseline for Synthetic Microplastics Data",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Platnick",
        "Sourena Khanzadeh",
        "Alireza Sadeghian",
        "Richard Anthony Valenzano"
      ],
      "abstract": "Microplastic particle ingestion or inhalation by humans is a problem of\ngrowing concern. Unfortunately, current research methods that use machine\nlearning to understand their potential harms are obstructed by a lack of\navailable data. Deep learning techniques in particular are challenged by such\ndomains where only small or imbalanced data sets are available. Overcoming this\nchallenge often involves oversampling underrepresented classes or augmenting\nthe existing data to improve model performance. This paper proposes GANsemble:\na two-module framework connecting data augmentation with conditional generative\nadversarial networks (cGANs) to generate class-conditioned synthetic data.\nFirst, the data chooser module automates augmentation strategy selection by\nsearching for the best data augmentation strategy. Next, the cGAN module uses\nthis strategy to train a cGAN for generating enhanced synthetic data. We\nexperiment with the GANsemble framework on a small and imbalanced microplastics\ndata set. A Microplastic-cGAN (MPcGAN) algorithm is introduced, and baselines\nfor synthetic microplastics (SYMP) data are established in terms of Frechet\nInception Distance (FID) and Inception Scores (IS). We also provide a synthetic\nmicroplastics filter (SYMP-Filter) algorithm to increase the quality of\ngenerated SYMP. Additionally, we show the best amount of oversampling with\naugmentation to fix class imbalance in small microplastics data sets. To our\nknowledge, this study is the first application of generative AI to\nsynthetically create microplastics data.",
      "tldr_zh": "该论文针对微塑料数据稀缺且不平衡的问题，提出GANsemble框架——一个结合数据增强和条件生成对抗网络(cGANs)的双模块系统，用于生成类条件合成数据。具体而言，数据选择模块自动优化增强策略，而cGAN模块据此训练模型生成高质量合成微塑料数据(SYMP)。实验结果显示，GANsemble在小样本微塑料数据集上建立了Frechet Inception Distance (FID)和Inception Scores (IS)基线，并通过Microplastic-cGAN (MPcGAN)和SYMP-Filter算法提升了数据质量，同时确定了最佳过采样策略；此研究首次将生成AI应用于合成微塑料数据领域。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to the 37th Canadian Artificial Intelligence Conference\n  (2024), 12 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.07356v2",
      "published_date": "2024-04-10 21:23:13 UTC",
      "updated_date": "2024-04-30 18:29:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:09:59.768932"
    },
    {
      "arxiv_id": "2404.07353v1",
      "title": "Addressing the Abstraction and Reasoning Corpus via Procedural Example Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Hodel"
      ],
      "abstract": "This work presents code to procedurally generate examples for the ARC\ntraining tasks. For each of the 400 tasks, an example generator following the\ntransformation logic of the original examples was created. In effect, the\nassumed underlying distribution of examples for any given task was reverse\nengineered by implementing a means to sample from it. An attempt was made to\ncover an as large as reasonable space of possible examples for each task. That\nis, whenever the original examples of a given task may be limited in their\ndiversity e.g. by having the dimensions of the grids, the set of symbols or\nnumber of objects constant or within tight bounds, even though the\ntransformation does not require it, such constraints were lifted. Having access\nto not just a few examples per task, as the case for ARC, but instead very\nmany, should enable a wide range of experiments that may be important stepping\nstones towards making leaps on the benchmark.",
      "tldr_zh": "这项研究通过程序化示例生成（procedural example generation）来处理Abstraction and Reasoning Corpus (ARC)，为每个400个任务创建示例生成器，以逆向工程任务的潜在示例分布。生成器遵循原始示例的转换逻辑，但放宽了如网格尺寸、符号集和对象数量的限制，从而覆盖更广泛的示例多样性。该方法使研究者能够获得大量示例，而非ARC中仅有的少数几个，支持进行各种实验，有助于在ARC基准测试中取得进展。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.07353v1",
      "published_date": "2024-04-10 21:16:59 UTC",
      "updated_date": "2024-04-10 21:16:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:10:10.521003"
    },
    {
      "arxiv_id": "2404.07344v2",
      "title": "Interactive Learning of Physical Object Properties Through Robot Manipulation and Database of Object Measurements",
      "title_zh": "翻译失败",
      "authors": [
        "Andrej Kruzliak",
        "Jiri Hartvich",
        "Shubhan P. Patni",
        "Lukas Rustler",
        "Jan Kristof Behrens",
        "Fares J. Abu-Dakka",
        "Krystian Mikolajczyk",
        "Ville Kyrki",
        "Matej Hoffmann"
      ],
      "abstract": "This work presents a framework for automatically extracting physical object\nproperties, such as material composition, mass, volume, and stiffness, through\nrobot manipulation and a database of object measurements. The framework\ninvolves exploratory action selection to maximize learning about objects on a\ntable. A Bayesian network models conditional dependencies between object\nproperties, incorporating prior probability distributions and uncertainty\nassociated with measurement actions. The algorithm selects optimal exploratory\nactions based on expected information gain and updates object properties\nthrough Bayesian inference. Experimental evaluation demonstrates effective\naction selection compared to a baseline and correct termination of the\nexperiments if there is nothing more to be learned. The algorithm proved to\nbehave intelligently when presented with trick objects with material properties\nin conflict with their appearance. The robot pipeline integrates with a logging\nmodule and an online database of objects, containing over 24,000 measurements\nof 63 objects with different grippers. All code and data are publicly\navailable, facilitating automatic digitization of objects and their physical\nproperties through exploratory manipulations.",
      "tldr_zh": "这篇论文提出一个框架，通过机器人操作和物体测量数据库，自动提取物体的物理属性，如材料组成、质量、体积和刚度。框架采用探索性动作选择算法，基于贝叶斯网络(Bayesian network)模型属性间的条件依赖，并通过预期信息增益(expected information gain)和贝叶斯推理(Bayesian inference)优化动作选择和属性更新。实验结果表明，该算法在与基线比较中表现出更高效率，能够智能处理外观与属性冲突的“trick objects”，并与包含超过24,000次测量的在线数据库集成，所有代码和数据均公开可用，促进物体物理属性的自动数字化。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.IT",
        "math.IT",
        "I.2.9"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.07344v2",
      "published_date": "2024-04-10 20:59:59 UTC",
      "updated_date": "2025-02-01 13:38:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:10:25.396853"
    },
    {
      "arxiv_id": "2404.15184v1",
      "title": "Reducing Human-Robot Goal State Divergence with Environment Design",
      "title_zh": "翻译失败",
      "authors": [
        "Kelsey Sikes",
        "Sarah Keren",
        "Sarath Sreedharan"
      ],
      "abstract": "One of the most difficult challenges in creating successful human-AI\ncollaborations is aligning a robot's behavior with a human user's expectations.\nWhen this fails to occur, a robot may misinterpret their specified goals,\nprompting it to perform actions with unanticipated, potentially dangerous side\neffects. To avoid this, we propose a new metric we call Goal State Divergence\n$\\mathcal{(GSD)}$, which represents the difference between a robot's final goal\nstate and the one a human user expected. In cases where $\\mathcal{GSD}$ cannot\nbe directly calculated, we show how it can be approximated using maximal and\nminimal bounds. We then input the $\\mathcal{GSD}$ value into our novel\nhuman-robot goal alignment (HRGA) design problem, which identifies a minimal\nset of environment modifications that can prevent mismatches like this. To show\nthe effectiveness of $\\mathcal{GSD}$ for reducing differences between\nhuman-robot goal states, we empirically evaluate our approach on several\nstandard benchmarks.",
      "tldr_zh": "该研究针对人类-机器人协作中机器人行为与用户期望不一致的问题，提出了一种新指标Goal State Divergence (GSD)，用于量化机器人实际目标状态与人类预期目标状态的差异。作者展示了如何通过最大和最小界限来近似计算GSD，并将其整合到Human-Robot Goal Alignment (HRGA)设计问题中，以识别最小环境修改从而防止目标不匹配。实验结果显示，该方法在多个标准基准上有效降低了人类-机器人目标状态差异，提升了协作安全性。",
      "categories": [
        "cs.AI",
        "I.2.8; I.2.9"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2404.15184v1",
      "published_date": "2024-04-10 20:36:04 UTC",
      "updated_date": "2024-04-10 20:36:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:10:35.198865"
    },
    {
      "arxiv_id": "2404.07315v2",
      "title": "Structured Reinforcement Learning for Media Streaming at the Wireless Edge",
      "title_zh": "结构化强化学习用于无线边缘媒体流媒体",
      "authors": [
        "Archana Bura",
        "Sarat Chandra Bobbili",
        "Shreyas Rameshkumar",
        "Desik Rengarajan",
        "Dileep Kalathil",
        "Srinivas Shakkottai"
      ],
      "abstract": "Media streaming is the dominant application over wireless edge (access)\nnetworks. The increasing softwarization of such networks has led to efforts at\nintelligent control, wherein application-specific actions may be dynamically\ntaken to enhance the user experience. The goal of this work is to develop and\ndemonstrate learning-based policies for optimal decision making to determine\nwhich clients to dynamically prioritize in a video streaming setting. We\nformulate the policy design question as a constrained Markov decision problem\n(CMDP), and observe that by using a Lagrangian relaxation we can decompose it\ninto single-client problems. Further, the optimal policy takes a threshold form\nin the video buffer length, which enables us to design an efficient constrained\nreinforcement learning (CRL) algorithm to learn it. Specifically, we show that\na natural policy gradient (NPG) based algorithm that is derived using the\nstructure of our problem converges to the globally optimal policy. We then\ndevelop a simulation environment for training, and a real-world intelligent\ncontroller attached to a WiFi access point for evaluation. We empirically show\nthat the structured learning approach enables fast learning. Furthermore, such\na structured policy can be easily deployed due to low computational complexity,\nleading to policy execution taking only about 15$\\mu$s. Using YouTube streaming\nexperiments in a resource constrained scenario, we demonstrate that the CRL\napproach can increase quality of experience (QOE) by over 30\\%.",
      "tldr_zh": "本文提出了一种结构化的强化学习方法，用于无线边缘媒体流媒体的智能控制，旨在动态优先级化客户端以提升用户体验。具体地，将问题建模为约束马尔可夫决策问题 (CMDP)，通过拉格朗日松弛分解为单客户端问题，并设计基于自然策略梯度 (NPG) 的约束强化学习 (CRL) 算法，该算法能高效收敛到全局最优阈值策略。实验结果显示，该方法在资源受限的 YouTube 流媒体场景中，实现快速学习、执行时间仅约 15 μs，并将用户体验质量 (QOE) 提高超过 30%。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LG",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "15 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.07315v2",
      "published_date": "2024-04-10 19:25:51 UTC",
      "updated_date": "2024-04-16 22:32:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:10:48.914943"
    },
    {
      "arxiv_id": "2404.08017v1",
      "title": "AI-Guided Feature Segmentation Techniques to Model Features from Single Crystal Diamond Growth",
      "title_zh": "翻译失败",
      "authors": [
        "Rohan Reddy Mekala",
        "Elias Garratt",
        "Matthias Muehle",
        "Arjun Srinivasan",
        "Adam Porter",
        "Mikael Lindvall"
      ],
      "abstract": "Process refinement to consistently produce high-quality material over a large\narea of the grown crystal, enabling various applications from optics crystals\nto quantum detectors, has long been a goal for diamond growth. Machine learning\noffers a promising path toward this goal, but faces challenges such as the\ncomplexity of features within datasets, their time-dependency, and the volume\nof data produced per growth run. Accurate spatial feature extraction from image\nto image for real-time monitoring of diamond growth is crucial yet complicated\ndue to the low-volume and high feature complexity nature of the datasets. This\npaper compares various traditional and machine learning-driven approaches for\nfeature extraction in the diamond growth domain, proposing a novel deep\nlearning-driven semantic segmentation approach to isolate and classify accurate\npixel masks of geometric features like diamond, pocket holder, and background,\nalong with their derivative features based on shape and size. Using an\nannotation-focused human-in-the-loop software architecture for training\ndatasets, with modules for selective data labeling using active learning, data\naugmentations, and model-assisted labeling, our approach achieves effective\nannotation accuracy and drastically reduces labeling time and cost. Deep\nlearning algorithms prove highly efficient in accurately learning complex\nrepresentations from datasets with many features. Our top-performing model,\nbased on the DeeplabV3plus architecture, achieves outstanding accuracy in\nclassifying features of interest, with accuracies of 96.31% for pocket holder,\n98.60% for diamond top, and 91.64% for diamond side features.",
      "tldr_zh": "本研究探讨了使用AI引导的特征分割技术来建模单晶金刚石生长过程中的特征，旨在解决数据集复杂性、时间依赖性和数据量大的挑战，以实现高质量材料的稳定生产。论文比较了传统和机器学习方法，并提出了一种新型深度学习驱动的语义分割方法，用于精确隔离和分类几何特征，如diamond、pocket holder和background，以及基于形状和大小的衍生特征。采用人类在循环(human-in-the-loop)软件架构，包括active learning、数据增强和模型辅助标注，该方法显著提高了标注准确性，同时减少了标注时间和成本。实验结果显示，基于DeeplabV3plus的模型在特征分类中取得了高准确率：pocket holder达96.31%、diamond top达98.60%、diamond side达91.64%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages,4 figures,ACMME 2024. arXiv admin note: substantial text\n  overlap with arXiv:2404.07306",
      "pdf_url": "http://arxiv.org/pdf/2404.08017v1",
      "published_date": "2024-04-10 19:16:08 UTC",
      "updated_date": "2024-04-10 19:16:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:11:00.566070"
    },
    {
      "arxiv_id": "2404.07306v1",
      "title": "AI-Guided Defect Detection Techniques to Model Single Crystal Diamond Growth",
      "title_zh": "翻译失败",
      "authors": [
        "Rohan Reddy Mekala",
        "Elias Garratt",
        "Matthias Muehle",
        "Arjun Srinivasan",
        "Adam Porter",
        "Mikael Lindvall"
      ],
      "abstract": "From a process development perspective, diamond growth via chemical vapor\ndeposition has made significant strides. However, challenges persist in\nachieving high quality and large-area material production. These difficulties\ninclude controlling conditions to maintain uniform growth rates for the entire\ngrowth surface. As growth progresses, various factors or defect states emerge,\naltering the uniform conditions. These changes affect the growth rate and\nresult in the formation of crystalline defects at the microscale. However,\nthere is a distinct lack of methods to identify these defect states and their\ngeometry using images taken during the growth process. This paper details\nseminal work on defect segmentation pipeline using in-situ optical images to\nidentify features that indicate defective states that are visible at the\nmacroscale. Using a semantic segmentation approach as applied in our previous\nwork, these defect states and corresponding derivative features are isolated\nand classified by their pixel masks. Using an annotation focused\nhuman-in-the-loop software architecture to produce training datasets, with\nmodules for selective data labeling using active learning, data augmentations,\nand model-assisted labeling, our approach achieves effective annotation\naccuracy and drastically reduces the time and cost of labeling by orders of\nmagnitude. On the model development front, we found that deep learning-based\nalgorithms are the most efficient. They can accurately learn complex\nrepresentations from feature-rich datasets. Our best-performing model, based on\nthe YOLOV3 and DeeplabV3plus architectures, achieved excellent accuracy for\nspecific features of interest. Specifically, it reached 93.35% accuracy for\ncenter defects, 92.83% for polycrystalline defects, and 91.98% for edge\ndefects.",
      "tldr_zh": "本研究针对化学 vapor deposition（CVD）法生长单晶金刚石的挑战，提出了一种AI引导的缺陷检测技术，以识别生长过程中的微观缺陷状态。方法包括使用语义 segmentation 管道分析 in-situ 光学图像，通过人类-in-the-loop 软件架构结合主动学习、数据增强和模型辅助标注，大大降低了标注时间和成本。实验结果显示，基于 YOLOV3 和 DeeplabV3plus 的最佳模型在缺陷检测中取得了高准确率：中心缺陷93.35%、多晶缺陷92.83%和边缘缺陷91.98%，为高效的单晶金刚石生产提供了关键工具。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages,4 figures,ACMME 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.07306v1",
      "published_date": "2024-04-10 18:58:05 UTC",
      "updated_date": "2024-04-10 18:58:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:11:11.678911"
    },
    {
      "arxiv_id": "2404.17585v2",
      "title": "NeuroNet: A Novel Hybrid Self-Supervised Learning Framework for Sleep Stage Classification Using Single-Channel EEG",
      "title_zh": "NeuroNet: 一种新型混合自监督学习框架，用于单通道EEG的睡眠阶段分类",
      "authors": [
        "Cheol-Hui Lee",
        "Hakseung Kim",
        "Hyun-jee Han",
        "Min-Kyung Jung",
        "Byung C. Yoon",
        "Dong-Joo Kim"
      ],
      "abstract": "The classification of sleep stages is a pivotal aspect of diagnosing sleep\ndisorders and evaluating sleep quality. However, the conventional manual\nscoring process, conducted by clinicians, is time-consuming and prone to human\nbias. Recent advancements in deep learning have substantially propelled the\nautomation of sleep stage classification. Nevertheless, challenges persist,\nincluding the need for large datasets with labels and the inherent biases in\nhuman-generated annotations. This paper introduces NeuroNet, a self-supervised\nlearning (SSL) framework designed to effectively harness unlabeled\nsingle-channel sleep electroencephalogram (EEG) signals by integrating\ncontrastive learning tasks and masked prediction tasks. NeuroNet demonstrates\nsuperior performance over existing SSL methodologies through extensive\nexperimentation conducted across three polysomnography (PSG) datasets.\nAdditionally, this study proposes a Mamba-based temporal context module to\ncapture the relationships among diverse EEG epochs. Combining NeuroNet with the\nMamba-based temporal context module has demonstrated the capability to achieve,\nor even surpass, the performance of the latest supervised learning\nmethodologies, even with a limited amount of labeled data. This study is\nexpected to establish a new benchmark in sleep stage classification, promising\nto guide future research and applications in the field of sleep analysis.",
      "tldr_zh": "这篇论文介绍了 NeuroNet，一种新型混合自监督学习(SSL)框架，用于基于单通道 EEG 信号的睡眠阶段分类，以解决传统手动评分耗时和标注数据不足的问题。NeuroNet 通过整合对比学习任务和掩码预测任务来有效利用无标签 EEG 数据，同时提出一个 Mamba-based temporal context module 来捕捉不同 EEG 时期之间的关系。实验结果显示，在三个多导睡眠图(PSG)数据集上，NeuroNet 优于现有 SSL 方法，并在少量标注数据下达到或超过最新监督学习方法的性能。该框架有望建立睡眠阶段分类的新基准，并指导未来睡眠分析研究。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG",
        "eess.SP"
      ],
      "primary_category": "cs.HC",
      "comment": "14 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.17585v2",
      "published_date": "2024-04-10 18:32:22 UTC",
      "updated_date": "2024-05-13 13:55:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:11:24.891052"
    },
    {
      "arxiv_id": "2404.08700v3",
      "title": "DyKnow: Dynamically Verifying Time-Sensitive Factual Knowledge in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Seyed Mahed Mousavi",
        "Simone Alghisi",
        "Giuseppe Riccardi"
      ],
      "abstract": "LLMs acquire knowledge from massive data snapshots collected at different\ntimestamps. Their knowledge is then commonly evaluated using static benchmarks.\nHowever, factual knowledge is generally subject to time-sensitive changes, and\nstatic benchmarks cannot address those cases. We present an approach to\ndynamically evaluate the knowledge in LLMs and their time-sensitiveness against\nWikidata, a publicly available up-to-date knowledge graph. We evaluate the\ntime-sensitive knowledge in twenty-four private and open-source LLMs, as well\nas the effectiveness of four editing methods in updating the outdated facts.\nOur results show that 1) outdatedness is a critical problem across\nstate-of-the-art LLMs; 2) LLMs output inconsistent answers when prompted with\nslight variations of the question prompt; and 3) the performance of the\nstate-of-the-art knowledge editing algorithms is very limited, as they can not\nreduce the cases of outdatedness and output inconsistency.",
      "tldr_zh": "这篇论文提出了 DyKnow 方法，用于动态评估大型语言模型（LLMs）中时间敏感事实知识的准确性，通过与 Wikidata 知识图谱进行实时比较，解决静态基准的局限性。研究评估了 24 个私有和开源 LLMs，以及四种知识编辑算法的效果，结果显示 LLMs 普遍存在知识过时问题，并在提示轻微变化时输出不一致。总体而言，现有知识编辑算法无法有效减少这些问题，突显了改进 LLMs 时间敏感性的必要性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.08700v3",
      "published_date": "2024-04-10 18:08:59 UTC",
      "updated_date": "2024-10-02 07:26:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:11:35.785379"
    },
    {
      "arxiv_id": "2404.07206v1",
      "title": "GoodDrag: Towards Good Practices for Drag Editing with Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zewei Zhang",
        "Huan Liu",
        "Jun Chen",
        "Xiangyu Xu"
      ],
      "abstract": "In this paper, we introduce GoodDrag, a novel approach to improve the\nstability and image quality of drag editing. Unlike existing methods that\nstruggle with accumulated perturbations and often result in distortions,\nGoodDrag introduces an AlDD framework that alternates between drag and\ndenoising operations within the diffusion process, effectively improving the\nfidelity of the result. We also propose an information-preserving motion\nsupervision operation that maintains the original features of the starting\npoint for precise manipulation and artifact reduction. In addition, we\ncontribute to the benchmarking of drag editing by introducing a new dataset,\nDrag100, and developing dedicated quality assessment metrics, Dragging Accuracy\nIndex and Gemini Score, utilizing Large Multimodal Models. Extensive\nexperiments demonstrate that the proposed GoodDrag compares favorably against\nthe state-of-the-art approaches both qualitatively and quantitatively. The\nproject page is https://gooddrag.github.io.",
      "tldr_zh": "本论文提出GoodDrag，一种新方法，旨在提升基于Diffusion Models的拖拽编辑的稳定性和图像质量，通过AlDD框架在扩散过程中交替进行拖拽和去噪操作，有效减少积累扰动并提高结果保真度。同时，引入信息保留运动监督操作，以保持起点特征，实现精确操控和减少伪影。论文贡献包括构建新数据集Drag100，以及开发专用质量评估指标Dragging Accuracy Index和Gemini Score，利用Large Multimodal Models进行评估。实验结果显示，GoodDrag在定性和定量上均优于现有最先进方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.07206v1",
      "published_date": "2024-04-10 17:59:59 UTC",
      "updated_date": "2024-04-10 17:59:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:11:47.883251"
    },
    {
      "arxiv_id": "2404.07204v1",
      "title": "BRAVE: Broadening the visual encoding of vision-language models",
      "title_zh": "BRAVE：拓宽视觉语言模型的视觉编码",
      "authors": [
        "Oğuzhan Fatih Kar",
        "Alessio Tonioni",
        "Petra Poklukar",
        "Achin Kulshrestha",
        "Amir Zamir",
        "Federico Tombari"
      ],
      "abstract": "Vision-language models (VLMs) are typically composed of a vision encoder,\ne.g. CLIP, and a language model (LM) that interprets the encoded features to\nsolve downstream tasks. Despite remarkable progress, VLMs are subject to\nseveral shortcomings due to the limited capabilities of vision encoders, e.g.\n\"blindness\" to certain image features, visual hallucination, etc. To address\nthese issues, we study broadening the visual encoding capabilities of VLMs. We\nfirst comprehensively benchmark several vision encoders with different\ninductive biases for solving VLM tasks. We observe that there is no single\nencoding configuration that consistently achieves top performance across\ndifferent tasks, and encoders with different biases can perform surprisingly\nsimilarly. Motivated by this, we introduce a method, named BRAVE, that\nconsolidates features from multiple frozen encoders into a more versatile\nrepresentation that can be directly fed as the input to a frozen LM. BRAVE\nachieves state-of-the-art performance on a broad range of captioning and VQA\nbenchmarks and significantly reduces the aforementioned issues of VLMs, while\nrequiring a smaller number of trainable parameters than existing methods and\nhaving a more compressed representation. Our results highlight the potential of\nincorporating different visual biases for a more broad and contextualized\nvisual understanding of VLMs.",
      "tldr_zh": "该论文探讨了视觉语言模型(VLMs)的视觉编码器（如CLIP）存在的局限性，如对某些图像特征的“盲点”和视觉幻觉问题，并通过基准测试发现不同编码器的偏置无法在所有任务中一致领先。作者引入BRAVE方法，将多个冻结编码器的特征整合成一个更通用的表示，直接输入到冻结的语言模型中，从而拓宽VLMs的视觉编码能力。该方法在各种标题生成和VQA基准上实现了最先进性能，同时显著减少了VLMs的缺陷，并采用了更少的训练参数和更压缩的表示。整体结果突出了整合不同视觉偏置的潜力，以实现更广泛和语境化的视觉理解。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page at https://brave-vlms.epfl.ch/",
      "pdf_url": "http://arxiv.org/pdf/2404.07204v1",
      "published_date": "2024-04-10 17:59:45 UTC",
      "updated_date": "2024-04-10 17:59:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:12:00.937044"
    },
    {
      "arxiv_id": "2404.07202v2",
      "title": "UMBRAE: Unified Multimodal Brain Decoding",
      "title_zh": "UMBRAE：统一多模态脑解码",
      "authors": [
        "Weihao Xia",
        "Raoul de Charette",
        "Cengiz Öztireli",
        "Jing-Hao Xue"
      ],
      "abstract": "We address prevailing challenges of the brain-powered research, departing\nfrom the observation that the literature hardly recover accurate spatial\ninformation and require subject-specific models. To address these challenges,\nwe propose UMBRAE, a unified multimodal decoding of brain signals. First, to\nextract instance-level conceptual and spatial details from neural signals, we\nintroduce an efficient universal brain encoder for multimodal-brain alignment\nand recover object descriptions at multiple levels of granularity from\nsubsequent multimodal large language model (MLLM). Second, we introduce a\ncross-subject training strategy mapping subject-specific features to a common\nfeature space. This allows a model to be trained on multiple subjects without\nextra resources, even yielding superior results compared to subject-specific\nmodels. Further, we demonstrate this supports weakly-supervised adaptation to\nnew subjects, with only a fraction of the total training data. Experiments\ndemonstrate that UMBRAE not only achieves superior results in the newly\nintroduced tasks but also outperforms methods in well established tasks. To\nassess our method, we construct and share with the community a comprehensive\nbrain understanding benchmark BrainHub. Our code and benchmark are available at\nhttps://weihaox.github.io/UMBRAE.",
      "tldr_zh": "这篇论文提出了 UMBRAE，一种统一的 multimodal 脑信号解码框架，以解决现有脑研究中空间信息恢复不准确和依赖特定受试者模型的问题。框架包括一个高效的通用脑编码器，用于从神经信号中提取实例级别的概念和空间细节，并结合 multimodal large language model (MLLM) 恢复多粒度对象描述；同时引入跨受试者训练策略，将受试者特征映射到公共空间，实现多受试者训练并支持弱监督适应新受试者，仅需少量数据。实验结果显示，UMBRAE 在新任务中取得优越性能，并在已建立任务中超越基线方法；作者还构建并共享了全面的脑理解基准 BrainHub，并提供了相关代码。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "ECCV 2024. Project: https://weihaox.github.io/UMBRAE",
      "pdf_url": "http://arxiv.org/pdf/2404.07202v2",
      "published_date": "2024-04-10 17:59:20 UTC",
      "updated_date": "2024-07-18 12:30:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:12:13.807739"
    },
    {
      "arxiv_id": "2404.07199v2",
      "title": "RealmDreamer: Text-Driven 3D Scene Generation with Inpainting and Depth Diffusion",
      "title_zh": "翻译失败",
      "authors": [
        "Jaidev Shriram",
        "Alex Trevithick",
        "Lingjie Liu",
        "Ravi Ramamoorthi"
      ],
      "abstract": "We introduce RealmDreamer, a technique for generating forward-facing 3D\nscenes from text descriptions. Our method optimizes a 3D Gaussian Splatting\nrepresentation to match complex text prompts using pretrained diffusion models.\nOur key insight is to leverage 2D inpainting diffusion models conditioned on an\ninitial scene estimate to provide low variance supervision for unknown regions\nduring 3D distillation. In conjunction, we imbue high-fidelity geometry with\ngeometric distillation from a depth diffusion model, conditioned on samples\nfrom the inpainting model. We find that the initialization of the optimization\nis crucial, and provide a principled methodology for doing so. Notably, our\ntechnique doesn't require video or multi-view data and can synthesize various\nhigh-quality 3D scenes in different styles with complex layouts. Further, the\ngenerality of our method allows 3D synthesis from a single image. As measured\nby a comprehensive user study, our method outperforms all existing approaches,\npreferred by 88-95%. Project Page: https://realmdreamer.github.io/",
      "tldr_zh": "该研究提出 RealmDreamer，一种基于文本描述生成前向视角 3D 场景的技术，通过优化 3D Gaussian Splatting 表示来匹配复杂文本提示。核心创新在于利用 2D inpainting diffusion models 提供未知区域的低方差监督，并结合 geometric distillation 从 depth diffusion model 中提取高保真几何。方法不需要视频或多视图数据，能从单张图像合成各种风格和复杂布局的 3D 场景，用户研究显示其优于现有方法，用户偏好率达 88-95%。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Published at 3DV 2025",
      "pdf_url": "http://arxiv.org/pdf/2404.07199v2",
      "published_date": "2024-04-10 17:57:41 UTC",
      "updated_date": "2025-03-11 17:06:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:12:23.533789"
    },
    {
      "arxiv_id": "2404.07198v2",
      "title": "A Foundation Model for Zero-shot Logical Query Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Mikhail Galkin",
        "Jincheng Zhou",
        "Bruno Ribeiro",
        "Jian Tang",
        "Zhaocheng Zhu"
      ],
      "abstract": "Complex logical query answering (CLQA) in knowledge graphs (KGs) goes beyond\nsimple KG completion and aims at answering compositional queries comprised of\nmultiple projections and logical operations. Existing CLQA methods that learn\nparameters bound to certain entity or relation vocabularies can only be applied\nto the graph they are trained on which requires substantial training time\nbefore being deployed on a new graph. Here we present UltraQuery, the first\nfoundation model for inductive reasoning that can zero-shot answer logical\nqueries on any KG. The core idea of UltraQuery is to derive both projections\nand logical operations as vocabulary-independent functions which generalize to\nnew entities and relations in any KG. With the projection operation initialized\nfrom a pre-trained inductive KG reasoning model, UltraQuery can solve CLQA on\nany KG after finetuning on a single dataset. Experimenting on 23 datasets,\nUltraQuery in the zero-shot inference mode shows competitive or better query\nanswering performance than best available baselines and sets a new state of the\nart on 15 of them.",
      "tldr_zh": "本文提出 UltraQuery，这是一个零-shot 逻辑查询推理的基础模型，旨在解决知识图谱（KGs）中复杂逻辑查询回答（CLQA）的问题，能够在任何 KG 上零-shot 进行查询，而无需针对特定实体或关系重新训练。核心方法是将投影和逻辑操作设计为词汇独立的函数，从预训练的归纳 KG 推理模型初始化，并在单个数据集上微调，以实现对新实体和关系的泛化。在 23 个数据集上的实验中，UltraQuery 在零-shot 模式下表现出色，比现有基线模型性能更优，并在 15 个数据集上设置了新的最先进水平。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.07198v2",
      "published_date": "2024-04-10 17:56:07 UTC",
      "updated_date": "2024-10-01 05:52:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:12:36.903207"
    },
    {
      "arxiv_id": "2404.07194v1",
      "title": "VN-EGNN: E(3)-Equivariant Graph Neural Networks with Virtual Nodes Enhance Protein Binding Site Identification",
      "title_zh": "翻译失败",
      "authors": [
        "Florian Sestak",
        "Lisa Schneckenreiter",
        "Johannes Brandstetter",
        "Sepp Hochreiter",
        "Andreas Mayr",
        "Günter Klambauer"
      ],
      "abstract": "Being able to identify regions within or around proteins, to which ligands\ncan potentially bind, is an essential step to develop new drugs. Binding site\nidentification methods can now profit from the availability of large amounts of\n3D structures in protein structure databases or from AlphaFold predictions.\nCurrent binding site identification methods heavily rely on graph neural\nnetworks (GNNs), usually designed to output E(3)-equivariant predictions. Such\nmethods turned out to be very beneficial for physics-related tasks like binding\nenergy or motion trajectory prediction. However, the performance of GNNs at\nbinding site identification is still limited potentially due to the lack of\ndedicated nodes that model hidden geometric entities, such as binding pockets.\nIn this work, we extend E(n)-Equivariant Graph Neural Networks (EGNNs) by\nadding virtual nodes and applying an extended message passing scheme. The\nvirtual nodes in these graphs are dedicated quantities to learn representations\nof binding sites, which leads to improved predictive performance. In our\nexperiments, we show that our proposed method VN-EGNN sets a new\nstate-of-the-art at locating binding site centers on COACH420, HOLO4K and\nPDBbind2020.",
      "tldr_zh": "该研究提出了一种名为 VN-EGNN 的方法，通过在 E(3)-Equivariant Graph Neural Networks (EGNNs) 中添加 virtual nodes 和扩展的消息传递方案，来提升蛋白质结合位点识别的性能。VN-EGNN 的 virtual nodes 专门用于学习隐藏几何实体如结合口袋的表示，从而解决现有 GNNs 在该任务中存在的局限性。在实验中，该方法在 COACH420、HOLO4K 和 PDBbind2020 数据集上实现了定位结合位点中心的 state-of-the-art 性能，显著提高了预测准确性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.BM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.07194v1",
      "published_date": "2024-04-10 17:50:29 UTC",
      "updated_date": "2024-04-10 17:50:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:12:49.499863"
    },
    {
      "arxiv_id": "2404.07185v2",
      "title": "Reward Learning from Suboptimal Demonstrations with Applications in Surgical Electrocautery",
      "title_zh": "翻译失败",
      "authors": [
        "Zohre Karimi",
        "Shing-Hei Ho",
        "Bao Thach",
        "Alan Kuntz",
        "Daniel S. Brown"
      ],
      "abstract": "Automating robotic surgery via learning from demonstration (LfD) techniques\nis extremely challenging. This is because surgical tasks often involve\nsequential decision-making processes with complex interactions of physical\nobjects and have low tolerance for mistakes. Prior works assume that all\ndemonstrations are fully observable and optimal, which might not be practical\nin the real world. This paper introduces a sample-efficient method that learns\na robust reward function from a limited amount of ranked suboptimal\ndemonstrations consisting of partial-view point cloud observations. The method\nthen learns a policy by optimizing the learned reward function using\nreinforcement learning (RL). We show that using a learned reward function to\nobtain a policy is more robust than pure imitation learning. We apply our\napproach on a physical surgical electrocautery task and demonstrate that our\nmethod can perform well even when the provided demonstrations are suboptimal\nand the observations are high-dimensional point clouds. Code and videos\navailable here: https://sites.google.com/view/lfdinelectrocautery",
      "tldr_zh": "该论文针对机器人手术自动化的挑战，提出了一种高效方法，通过从有限的次优演示（包括部分视图点云 observations）中学习稳健的奖励函数，并使用强化学习 (RL) 优化该函数来训练策略。相较于纯模仿学习 (LfD)，这种方法更具鲁棒性，能够处理复杂顺序决策和低容错率任务。在物理手术电凝任务的实际应用中，实验证明即使演示 suboptimal，该方法也能在高维点云观察下实现良好性能。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "In proceedings of the International Symposium on Medical Robotics\n  (ISMR) 2024. Equal contribution from two first authors",
      "pdf_url": "http://arxiv.org/pdf/2404.07185v2",
      "published_date": "2024-04-10 17:40:27 UTC",
      "updated_date": "2024-04-16 00:23:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:13:01.689210"
    },
    {
      "arxiv_id": "2404.07170v1",
      "title": "Worst-Case Convergence Time of ML Algorithms via Extreme Value Theory",
      "title_zh": "翻译失败",
      "authors": [
        "Saeid Tizpaz-Niari",
        "Sriram Sankaranarayanan"
      ],
      "abstract": "This paper leverages the statistics of extreme values to predict the\nworst-case convergence times of machine learning algorithms. Timing is a\ncritical non-functional property of ML systems, and providing the worst-case\nconverge times is essential to guarantee the availability of ML and its\nservices. However, timing properties such as worst-case convergence times\n(WCCT) are difficult to verify since (1) they are not encoded in the syntax or\nsemantics of underlying programming languages of AI, (2) their evaluations\ndepend on both algorithmic implementations and underlying systems, and (3)\ntheir measurements involve uncertainty and noise. Therefore, prevalent formal\nmethods and statistical models fail to provide rich information on the amounts\nand likelihood of WCCT.\n  Our key observation is that the timing information we seek represents the\nextreme tail of execution times. Therefore, extreme value theory (EVT), a\nstatistical discipline that focuses on understanding and predicting the\ndistribution of extreme values in the tail of outcomes, provides an ideal\nframework to model and analyze WCCT in the training and inference phases of ML\nparadigm. Building upon the mathematical tools from EVT, we propose a practical\nframework to predict the worst-case timing properties of ML. Over a set of\nlinear ML training algorithms, we show that EVT achieves a better accuracy for\npredicting WCCTs than relevant statistical methods such as the Bayesian factor.\nOn the set of larger machine learning training algorithms and deep neural\nnetwork inference, we show the feasibility and usefulness of EVT models to\naccurately predict WCCTs, their expected return periods, and their likelihood.",
      "tldr_zh": "这篇论文利用极端值理论（EVT）来预测机器学习（ML）算法的最坏情况收敛时间（WCCT），解决了传统方法在处理执行时间不确定性和噪声方面的难题。作者提出一个基于EVT的框架，专注于分析执行时间分布的极端尾部，以建模ML训练和推理阶段的WCCT。实验结果显示，在线性ML训练算法上，EVT比Bayesian factor等统计方法更准确；在更大规模的ML训练和深度神经网络（DNN）推理中，该框架能有效预测WCCT、预期返回期和可能性，为ML系统的可用性提供可靠保证。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG",
        "cs.PF",
        "cs.PL"
      ],
      "primary_category": "cs.SE",
      "comment": "In 3rd International Conference on AI Engineering: Software\n  Engineering for AI (CAIN 2024)",
      "pdf_url": "http://arxiv.org/pdf/2404.07170v1",
      "published_date": "2024-04-10 17:05:12 UTC",
      "updated_date": "2024-04-10 17:05:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:13:14.349801"
    },
    {
      "arxiv_id": "2404.07168v1",
      "title": "Using Neural Networks to Model Hysteretic Kinematics in Tendon-Actuated Continuum Robots",
      "title_zh": "利用神经网络建模肌腱驱动连续体机器人中的滞回运动学",
      "authors": [
        "Yuan Wang",
        "Max McCandless",
        "Abdulhamit Donder",
        "Giovanni Pittiglio",
        "Behnam Moradkhani",
        "Yash Chitalia",
        "Pierre E. Dupont"
      ],
      "abstract": "The ability to accurately model mechanical hysteretic behavior in\ntendon-actuated continuum robots using deep learning approaches is a growing\narea of interest. In this paper, we investigate the hysteretic response of two\ntypes of tendon-actuated continuum robots and, ultimately, compare three types\nof neural network modeling approaches with both forward and inverse kinematic\nmappings: feedforward neural network (FNN), FNN with a history input buffer,\nand long short-term memory (LSTM) network. We seek to determine which model\nbest captures temporal dependent behavior. We find that, depending on the\nrobot's design, choosing different kinematic inputs can alter whether\nhysteresis is exhibited by the system. Furthermore, we present the results of\nthe model fittings, revealing that, in contrast to the standard FNN, both FNN\nwith a history input buffer and the LSTM model exhibit the capacity to model\nhistorical dependence with comparable performance in capturing rate-dependent\nhysteresis.",
      "tldr_zh": "这篇论文探讨了使用神经网络建模 tendon-actuated continuum robots 中的滞回运动学行为，调查了两种机器人类型的滞回响应，并比较了三种模型在正向和逆向运动学映射中的表现，包括 feedforward neural network (FNN)、带历史输入缓冲的 FNN 和 long short-term memory (LSTM) network。研究发现，不同机器人设计会影响系统是否表现出滞回，而带历史输入缓冲的 FNN 和 LSTM 模型比标准 FNN 更有效地捕捉历史依赖性和速率相关的滞回行为。总之，该工作为改进机器人建模提供了有价值的见解。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "7 pages, 8 figures, conference",
      "pdf_url": "http://arxiv.org/pdf/2404.07168v1",
      "published_date": "2024-04-10 17:04:06 UTC",
      "updated_date": "2024-04-10 17:04:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:13:26.902231"
    },
    {
      "arxiv_id": "2404.07164v2",
      "title": "PIM-Opt: Demystifying Distributed Optimization Algorithms on a Real-World Processing-In-Memory System",
      "title_zh": "翻译失败",
      "authors": [
        "Steve Rhyner",
        "Haocong Luo",
        "Juan Gómez-Luna",
        "Mohammad Sadrosadati",
        "Jiawei Jiang",
        "Ataberk Olgun",
        "Harshita Gupta",
        "Ce Zhang",
        "Onur Mutlu"
      ],
      "abstract": "Modern Machine Learning (ML) training on large-scale datasets is a very\ntime-consuming workload. It relies on the optimization algorithm Stochastic\nGradient Descent (SGD) due to its effectiveness, simplicity, and generalization\nperformance. Processor-centric architectures (e.g., CPUs, GPUs) commonly used\nfor modern ML training workloads based on SGD are bottlenecked by data movement\nbetween the processor and memory units due to the poor data locality in\naccessing large datasets. As a result, processor-centric architectures suffer\nfrom low performance and high energy consumption while executing ML training\nworkloads. Processing-In-Memory (PIM) is a promising solution to alleviate the\ndata movement bottleneck by placing the computation mechanisms inside or near\nmemory.\n  Our goal is to understand the capabilities of popular distributed SGD\nalgorithms on real-world PIM systems to accelerate data-intensive ML training\nworkloads. To this end, we 1) implement several representative centralized\nparallel SGD algorithms on the real-world UPMEM PIM system, 2) rigorously\nevaluate these algorithms for ML training on large-scale datasets in terms of\nperformance, accuracy, and scalability, 3) compare to conventional CPU and GPU\nbaselines, and 4) discuss implications for future PIM hardware and highlight\nthe need for a shift to an algorithm-hardware codesign.\n  Our results demonstrate three major findings: 1) The UPMEM PIM system can be\na viable alternative to state-of-the-art CPUs and GPUs for many memory-bound ML\ntraining workloads, especially when operations and datatypes are natively\nsupported by PIM hardware, 2) it is important to carefully choose the\noptimization algorithms that best fit PIM, and 3) the UPMEM PIM system does not\nscale approximately linearly with the number of nodes for many data-intensive\nML training workloads. We open source all our code to facilitate future\nresearch.",
      "tldr_zh": "本研究探讨了机器学习(ML)训练中Stochastic Gradient Descent (SGD)算法在处理器架构（如CPU和GPU）上因数据移动瓶颈导致的性能和能耗问题，并提出在真实Processing-In-Memory (PIM)系统上实现分布式优化算法作为解决方案。研究团队在UPMEM PIM系统上实现了几种代表性SGD算法，并通过实验评估其在大型数据集上的性能、准确性和可扩展性，与传统CPU和GPU基准进行比较。结果显示，PIM系统在内存密集型ML训练任务中表现出色，尤其当操作和数据类型被硬件原生支持时，但需仔细选择算法，且其扩展性并非线性；论文强调了算法-硬件协同设计的必要性，并开源了所有代码以促进后续研究。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.DC",
        "cs.LG"
      ],
      "primary_category": "cs.AR",
      "comment": "\"PIM-Opt: Demystifying Distributed Optimization Algorithms on a\n  Real-World Processing-In-Memory System\" in Proceedings of the 33rd\n  International Conference on Parallel Architectures and Compilation Techniques\n  (PACT), Long Beach, CA, USA, October 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.07164v2",
      "published_date": "2024-04-10 17:00:04 UTC",
      "updated_date": "2024-09-27 14:32:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:13:38.848962"
    },
    {
      "arxiv_id": "2404.08699v3",
      "title": "PoliTune: Analyzing the Impact of Data Selection and Fine-Tuning on Economic and Political Biases in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmed Agiza",
        "Mohamed Mostagir",
        "Sherief Reda"
      ],
      "abstract": "In an era where language models are increasingly integrated into\ndecision-making and communication, understanding the biases within Large\nLanguage Models (LLMs) becomes imperative, especially when these models are\napplied in the economic and political domains. This work investigates the\nimpact of fine-tuning and data selection on economic and political biases in\nLLMs. In this context, we introduce PoliTune, a fine-tuning methodology to\nexplore the systematic aspects of aligning LLMs with specific ideologies,\nmindful of the biases that arise from their extensive training on diverse\ndatasets. Distinct from earlier efforts that either focus on smaller models or\nentail resource-intensive pre-training, PoliTune employs Parameter-Efficient\nFine-Tuning (PEFT) techniques, which allow for the alignment of LLMs with\ntargeted ideologies by modifying a small subset of parameters. We introduce a\nsystematic method for using the open-source LLM Llama3-70B for dataset\nselection, annotation, and synthesizing a preferences dataset for Direct\nPreference Optimization (DPO) to align the model with a given political\nideology. We assess the effectiveness of PoliTune through both quantitative and\nqualitative evaluations of aligning open-source LLMs (Llama3-8B and Mistral-7B)\nto different ideologies. Our work analyzes the potential of embedding specific\nbiases into LLMs and contributes to the dialogue on the ethical application of\nAI, highlighting the importance of deploying AI in a manner that aligns with\nsocietal values.",
      "tldr_zh": "这篇论文分析了数据选择和微调对大型语言模型 (LLMs) 中经济和政治偏见的影响，引入了 PoliTune 方法作为一种高效微调策略。PoliTune 利用 Parameter-Efficient Fine-Tuning (PEFT) 技术，仅修改少量参数，并通过数据集选择、标注和 Direct Preference Optimization (DPO) 来将模型对齐特定意识形态。实验结果显示，该方法在 Llama3-8B 和 Mistral-7B 模型上有效嵌入目标偏见，并强调了在 AI 伦理应用中确保模型符合社会价值观的重要性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "AIES '24: Proceedings of the 2024 AAAI/ACM Conference on AI, Ethics,\n  and Society",
      "pdf_url": "http://arxiv.org/pdf/2404.08699v3",
      "published_date": "2024-04-10 16:30:09 UTC",
      "updated_date": "2024-07-27 17:22:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:13:50.515028"
    },
    {
      "arxiv_id": "2404.07143v2",
      "title": "Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention",
      "title_zh": "翻译失败",
      "authors": [
        "Tsendsuren Munkhdalai",
        "Manaal Faruqui",
        "Siddharth Gopal"
      ],
      "abstract": "This work introduces an efficient method to scale Transformer-based Large\nLanguage Models (LLMs) to infinitely long inputs with bounded memory and\ncomputation. A key component in our proposed approach is a new attention\ntechnique dubbed Infini-attention. The Infini-attention incorporates a\ncompressive memory into the vanilla attention mechanism and builds in both\nmasked local attention and long-term linear attention mechanisms in a single\nTransformer block. We demonstrate the effectiveness of our approach on\nlong-context language modeling benchmarks, 1M sequence length passkey context\nblock retrieval and 500K length book summarization tasks with 1B and 8B LLMs.\nOur approach introduces minimal bounded memory parameters and enables fast\nstreaming inference for LLMs.",
      "tldr_zh": "该研究提出了一种高效方法，使基于 Transformer 的 Large Language Models (LLMs) 能够处理无限长的输入，同时保持内存和计算资源有限。核心创新是 Infini-attention 机制，该机制将压缩内存融入标准注意力中，并整合 masked local attention 和 long-term linear attention，以支持高效的上下文处理。在长上下文语言建模基准测试、1M 序列长度的 passkey 上下文块检索以及 500K 长度的书籍摘要任务上，使用 1B 和 8B LLMs 的实验显示，该方法显著提升性能，并实现快速流式推理。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 4 figures, 4 tables (v2 adds: background, implementation\n  details, recent citations and acknowledgments)",
      "pdf_url": "http://arxiv.org/pdf/2404.07143v2",
      "published_date": "2024-04-10 16:18:42 UTC",
      "updated_date": "2024-08-09 22:37:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:14:02.998090"
    },
    {
      "arxiv_id": "2404.07139v1",
      "title": "Towards a Game-theoretic Understanding of Explanation-based Membership Inference Attacks",
      "title_zh": "翻译失败",
      "authors": [
        "Kavita Kumari",
        "Murtuza Jadliwala",
        "Sumit Kumar Jha",
        "Anindya Maiti"
      ],
      "abstract": "Model explanations improve the transparency of black-box machine learning\n(ML) models and their decisions; however, they can also be exploited to carry\nout privacy threats such as membership inference attacks (MIA). Existing works\nhave only analyzed MIA in a single \"what if\" interaction scenario between an\nadversary and the target ML model; thus, it does not discern the factors\nimpacting the capabilities of an adversary in launching MIA in repeated\ninteraction settings. Additionally, these works rely on assumptions about the\nadversary's knowledge of the target model's structure and, thus, do not\nguarantee the optimality of the predefined threshold required to distinguish\nthe members from non-members. In this paper, we delve into the domain of\nexplanation-based threshold attacks, where the adversary endeavors to carry out\nMIA attacks by leveraging the variance of explanations through iterative\ninteractions with the system comprising of the target ML model and its\ncorresponding explanation method. We model such interactions by employing a\ncontinuous-time stochastic signaling game framework. In our framework, an\nadversary plays a stopping game, interacting with the system (having imperfect\ninformation about the type of an adversary, i.e., honest or malicious) to\nobtain explanation variance information and computing an optimal threshold to\ndetermine the membership of a datapoint accurately. First, we propose a sound\nmathematical formulation to prove that such an optimal threshold exists, which\ncan be used to launch MIA. Then, we characterize the conditions under which a\nunique Markov perfect equilibrium (or steady state) exists in this dynamic\nsystem. By means of a comprehensive set of simulations of the proposed game\nmodel, we assess different factors that can impact the capability of an\nadversary to launch MIA in such repeated interaction settings.",
      "tldr_zh": "本文使用游戏理论框架分析基于模型解释的成员推理攻击(MIA)，重点探讨攻击者在重复交互场景中的能力，而非现有研究的单一交互假设。该方法构建了一个连续时间随机信号博弈模型，其中攻击者通过迭代交互获取解释方差信息，并计算最优阈值来精确判断数据点成员身份。研究证明了这种最优阈值的存在，表征了独特马尔可夫完美均衡的条件，并通过模拟实验评估了多种因素对MIA成功率的影响，为提升ML模型隐私保护提供了新见解。",
      "categories": [
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.AI",
      "comment": "arXiv admin note: text overlap with arXiv:2202.02659",
      "pdf_url": "http://arxiv.org/pdf/2404.07139v1",
      "published_date": "2024-04-10 16:14:05 UTC",
      "updated_date": "2024-04-10 16:14:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:14:14.458936"
    },
    {
      "arxiv_id": "2404.07135v2",
      "title": "Towards Robustness of Text-to-Visualization Translation against Lexical and Phrasal Variability",
      "title_zh": "翻译失败",
      "authors": [
        "Jinwei Lu",
        "Yuanfeng Song",
        "Haodi Zhang",
        "Chen Zhang",
        "Raymond Chi-Wing Wong"
      ],
      "abstract": "Text-to-Vis is an emerging task in the natural language processing (NLP) area\nthat aims to automatically generate data visualizations from natural language\nquestions (NLQs). Despite their progress, existing text-to-vis models often\nheavily rely on lexical matching between words in the questions and tokens in\ndata schemas. This overreliance on lexical matching may lead to a diminished\nlevel of model robustness against input variations. In this study, we\nthoroughly examine the robustness of current text-to-vis models, an area that\nhas not previously been explored. In particular, we construct the first\nrobustness dataset nvBench-Rob, which contains diverse lexical and phrasal\nvariations based on the original text-to-vis benchmark nvBench. Then, we found\nthat the performance of existing text-to-vis models on this new dataset\ndramatically drops, implying that these methods exhibit inadequate robustness\noverall. Finally, we propose a novel framework based on Retrieval-Augmented\nGeneration (RAG) technique, named GRED, specifically designed to address input\nperturbations in these two variants. The framework consists of three parts:\nNLQ-Retrieval Generator, Visualization Query-Retrieval Retuner and\nAnnotation-based Debugger, which are used to tackle the challenges posed by\nnatural language variants, programming style differences and data schema\nvariants, respectively. Extensive experimental evaluations show that, compared\nto the state-of-the-art model RGVisNet in the Text-to-Vis field, GRED performs\nbetter in terms of model robustness, with a 32% increase in accuracy on the\nproposed nvBench-Rob dataset.",
      "tldr_zh": "本研究探讨了Text-to-Vis任务中模型对词汇和短语变化的鲁棒性问题，指出现有模型过度依赖词汇匹配，导致对输入变异敏感。作者构建了首个鲁棒性数据集nvBench-Rob，并发现现有模型在此数据集上的性能显著下降。随后，提出基于Retrieval-Augmented Generation (RAG)技术的框架GRED，包括NLQ-Retrieval Generator、Visualization Query-Retrieval Retuner和Annotation-based Debugger三个模块，用于处理自然语言变异、编程风格差异和数据模式变异。实验结果显示，GRED相较于最先进模型RGVisNet，在nvBench-Rob数据集上准确率提升32%，显著提高了模型的鲁棒性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.07135v2",
      "published_date": "2024-04-10 16:12:50 UTC",
      "updated_date": "2024-04-11 05:56:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:14:25.659495"
    },
    {
      "arxiv_id": "2404.07124v1",
      "title": "Measuring proximity to standard planes during fetal brain ultrasound scanning",
      "title_zh": "在胎儿大脑超声扫描中测量标准平面的接近度",
      "authors": [
        "Chiara Di Vece",
        "Antonio Cirigliano",
        "Meala Le Lous",
        "Raffaele Napolitano",
        "Anna L. David",
        "Donald Peebles",
        "Pierre Jannin",
        "Francisco Vasconcelos",
        "Danail Stoyanov"
      ],
      "abstract": "This paper introduces a novel pipeline designed to bring ultrasound (US)\nplane pose estimation closer to clinical use for more effective navigation to\nthe standard planes (SPs) in the fetal brain. We propose a semi-supervised\nsegmentation model utilizing both labeled SPs and unlabeled 3D US volume\nslices. Our model enables reliable segmentation across a diverse set of fetal\nbrain images. Furthermore, the model incorporates a classification mechanism to\nidentify the fetal brain precisely. Our model not only filters out frames\nlacking the brain but also generates masks for those containing it, enhancing\nthe relevance of plane pose regression in clinical settings. We focus on fetal\nbrain navigation from 2D ultrasound (US) video analysis and combine this model\nwith a US plane pose regression network to provide sensorless proximity\ndetection to SPs and non-SPs planes; we emphasize the importance of proximity\ndetection to SPs for guiding sonographers, offering a substantial advantage\nover traditional methods by allowing earlier and more precise adjustments\nduring scanning. We demonstrate the practical applicability of our approach\nthrough validation on real fetal scan videos obtained from sonographers of\nvarying expertise levels. Our findings demonstrate the potential of our\napproach to complement existing fetal US technologies and advance prenatal\ndiagnostic practices.",
      "tldr_zh": "本研究提出了一种新管道，用于在胎儿脑部超声（US）扫描中测量接近标准平面（SPs）的距离，从而提升导航效率。该管道包括一个半监督分割模型，利用标记的SPs和未标记的3D US体积切片，实现对多样化胎儿脑部图像的可靠分割，并通过分类机制过滤无脑部帧并生成相关掩码。与US平面姿态回归网络结合后，该方法从2D US视频分析中提供无传感器接近检测，帮助超声医师更早、更精确地调整扫描。实验在真实胎儿扫描视频上验证，证明了该方法的实用性，有望补充现有胎儿US技术和推进产前诊断实践。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.2.0; I.4.0; J.2.0; J.3.0"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.07124v1",
      "published_date": "2024-04-10 16:04:21 UTC",
      "updated_date": "2024-04-10 16:04:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:14:37.798723"
    },
    {
      "arxiv_id": "2404.07123v3",
      "title": "Semantically-correlated memories in a dense associative model",
      "title_zh": "翻译失败",
      "authors": [
        "Thomas F Burns"
      ],
      "abstract": "I introduce a novel associative memory model named Correlated Dense\nAssociative Memory (CDAM), which integrates both auto- and hetero-association\nin a unified framework for continuous-valued memory patterns. Employing an\narbitrary graph structure to semantically link memory patterns, CDAM is\ntheoretically and numerically analysed, revealing four distinct dynamical\nmodes: auto-association, narrow hetero-association, wide hetero-association,\nand neutral quiescence. Drawing inspiration from inhibitory modulation studies,\nI employ anti-Hebbian learning rules to control the range of\nhetero-association, extract multi-scale representations of community structures\nin graphs, and stabilise the recall of temporal sequences. Experimental\ndemonstrations showcase CDAM's efficacy in handling real-world data,\nreplicating a classical neuroscience experiment, performing image retrieval,\nand simulating arbitrary finite automata.",
      "tldr_zh": "本文提出了一种名为 Correlated Dense Associative Memory (CDAM) 的新型关联记忆模型，将 auto-association 和 hetero-association 整合到一个统一的框架中，用于处理连续值的记忆模式，并通过任意图结构实现记忆模式的语义链接。模型的理论和数值分析揭示了四种动态模式：auto-association、narrow hetero-association、wide hetero-association 和 neutral quiescence，同时利用 anti-Hebbian 学习规则来控制 hetero-association 的范围、提取图的多尺度社区结构，并稳定时间序列的回忆。实验结果展示了 CDAM 在真实世界数据处理、复制经典神经科学实验、图像检索以及模拟任意有限自动机的效能。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG",
        "q-bio.NC",
        "68T07, 92B20, 68T01, 00A69",
        "I.2; I.5; I.4; J.2; J.3"
      ],
      "primary_category": "cs.NE",
      "comment": "35 pages, 32 figures; published in ICML2024",
      "pdf_url": "http://arxiv.org/pdf/2404.07123v3",
      "published_date": "2024-04-10 16:04:07 UTC",
      "updated_date": "2024-06-02 08:29:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:14:52.245021"
    },
    {
      "arxiv_id": "2404.07099v1",
      "title": "Rethinking Out-of-Distribution Detection for Reinforcement Learning: Advancing Methods for Evaluation and Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Linas Nasvytis",
        "Kai Sandbrink",
        "Jakob Foerster",
        "Tim Franzmeyer",
        "Christian Schroeder de Witt"
      ],
      "abstract": "While reinforcement learning (RL) algorithms have been successfully applied\nacross numerous sequential decision-making problems, their generalization to\nunforeseen testing environments remains a significant concern. In this paper,\nwe study the problem of out-of-distribution (OOD) detection in RL, which\nfocuses on identifying situations at test time that RL agents have not\nencountered in their training environments. We first propose a clarification of\nterminology for OOD detection in RL, which aligns it with the literature from\nother machine learning domains. We then present new benchmark scenarios for OOD\ndetection, which introduce anomalies with temporal autocorrelation into\ndifferent components of the agent-environment loop. We argue that such\nscenarios have been understudied in the current literature, despite their\nrelevance to real-world situations. Confirming our theoretical predictions, our\nexperimental results suggest that state-of-the-art OOD detectors are not able\nto identify such anomalies. To address this problem, we propose a novel method\nfor OOD detection, which we call DEXTER (Detection via Extraction of Time\nSeries Representations). By treating environment observations as time series\ndata, DEXTER extracts salient time series features, and then leverages an\nensemble of isolation forest algorithms to detect anomalies. We find that\nDEXTER can reliably identify anomalies across benchmark scenarios, exhibiting\nsuperior performance compared to both state-of-the-art OOD detectors and\nhigh-dimensional changepoint detectors adopted from statistics.",
      "tldr_zh": "本论文重新审视强化学习(Reinforcement Learning, RL)中的Out-of-Distribution (OOD)检测问题，强调了RL代理在测试环境中识别未训练情境的重要性，并统一了相关术语以与其它机器学习领域一致。作者提出新的基准场景，这些场景引入了具有时间自相关性的异常到代理-环境循环中，以更好地模拟现实世界情况，但现有最先进的OOD检测器无法有效识别这些异常。针对这一问题，论文引入了DEXTER方法，该方法将环境观察视为时间序列数据，提取关键特征并使用集成隔离森林(Isolation Forest)算法进行异常检测。实验结果显示，DEXTER在基准场景中表现出色，显著优于现有OOD检测器和高维变化点检测器。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted as a full paper to the 23rd International Conference on\n  Autonomous Agents and Multiagent Systems (AAMAS 2024)",
      "pdf_url": "http://arxiv.org/pdf/2404.07099v1",
      "published_date": "2024-04-10 15:39:49 UTC",
      "updated_date": "2024-04-10 15:39:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:15:03.891950"
    },
    {
      "arxiv_id": "2404.08013v1",
      "title": "Enhanced Cooperative Perception for Autonomous Vehicles Using Imperfect Communication",
      "title_zh": "利用不完善通信增强自动驾驶车辆的合作感知",
      "authors": [
        "Ahmad Sarlak",
        "Hazim Alzorgan",
        "Sayed Pedram Haeri Boroujeni",
        "Abolfazl Razi",
        "Rahul Amin"
      ],
      "abstract": "Sharing and joint processing of camera feeds and sensor measurements, known\nas Cooperative Perception (CP), has emerged as a new technique to achieve\nhigher perception qualities. CP can enhance the safety of Autonomous Vehicles\n(AVs) where their individual visual perception quality is compromised by\nadverse weather conditions (haze as foggy weather), low illumination, winding\nroads, and crowded traffic. To cover the limitations of former methods, in this\npaper, we propose a novel approach to realize an optimized CP under constrained\ncommunications. At the core of our approach is recruiting the best helper from\nthe available list of front vehicles to augment the visual range and enhance\nthe Object Detection (OD) accuracy of the ego vehicle. In this two-step\nprocess, we first select the helper vehicles that contribute the most to CP\nbased on their visual range and lowest motion blur. Next, we implement a radio\nblock optimization among the candidate vehicles to further improve\ncommunication efficiency. We specifically focus on pedestrian detection as an\nexemplary scenario. To validate our approach, we used the CARLA simulator to\ncreate a dataset of annotated videos for different driving scenarios where\npedestrian detection is challenging for an AV with compromised vision. Our\nresults demonstrate the efficacy of our two-step optimization process in\nimproving the overall performance of cooperative perception in challenging\nscenarios, substantially improving driving safety under adverse conditions.\nFinally, we note that the networking assumptions are adopted from LTE Release\n14 Mode 4 side-link communication, commonly used for Vehicle-to-Vehicle (V2V)\ncommunication. Nonetheless, our method is flexible and applicable to arbitrary\nV2V communications.",
      "tldr_zh": "本研究提出了一种优化方法，用于在通信受限条件下提升自动驾驶车辆（Autonomous Vehicles, AVs）的协同感知（Cooperative Perception, CP），以应对恶劣天气、低光照和拥挤交通等挑战。核心方法包括两步过程：首先，从前方车辆中选择视觉范围最广且运动模糊最低的“最佳助手”来增强自车辆的物体检测（Object Detection, OD）准确性；其次，对候选车辆进行无线通信块优化，提高通信效率。实验使用 CARLA 模拟器在行人检测场景中验证了该方法，结果显示优化过程显著提高了 CP 性能，提升了29.32%的准确率，从而增强了 AVs 在复杂环境下的驾驶安全。该方法基于 LTE Release 14 Mode 4 的 Vehicle-to-Vehicle (V2V) 通信假设，但具有灵活性，可适用于其他 V2V 系统。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.08013v1",
      "published_date": "2024-04-10 15:37:15 UTC",
      "updated_date": "2024-04-10 15:37:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:15:15.861821"
    },
    {
      "arxiv_id": "2404.07096v1",
      "title": "TransTARec: Time-Adaptive Translating Embedding Model for Next POI Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Yiping Sun"
      ],
      "abstract": "The rapid growth of location acquisition technologies makes\nPoint-of-Interest(POI) recommendation possible due to redundant user check-in\nrecords. In this paper, we focus on next POI recommendation in which next POI\nis based on previous POI. We observe that time plays an important role in next\nPOI recommendation but is neglected in the recent proposed translating\nembedding methods. To tackle this shortage, we propose a time-adaptive\ntranslating embedding model (TransTARec) for next POI recommendation that\nnaturally incorporates temporal influence, sequential dynamics, and user\npreference within a single component. Methodologically, we treat a (previous\ntimestamp, user, next timestamp) triplet as a union translation vector and\ndevelop a neural-based fusion operation to fuse user preference and temporal\ninfluence. The superiority of TransTARec, which is confirmed by extensive\nexperiments on real-world datasets, comes from not only the introduction of\ntemporal influence but also the direct unification with user preference and\nsequential dynamics.",
      "tldr_zh": "本文提出 TransTARec，一种时间自适应翻译嵌入模型，用于下一个 POI 推荐，旨在解决现有方法忽略时间因素的问题。模型通过将 (previous timestamp, user, next timestamp) 三元组视为联合翻译向量，并采用神经网络-based 融合操作，统一整合时间影响、序列动态和用户偏好。实验在真实数据集上验证了 TransTARec 的优越性，不仅归功于时间影响的引入，还在于直接统一了用户偏好和序列动态。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "This paper has been accepted by the 2024 5th International Conference\n  on Computer Engineering and Application (ICCEA 2024)",
      "pdf_url": "http://arxiv.org/pdf/2404.07096v1",
      "published_date": "2024-04-10 15:36:59 UTC",
      "updated_date": "2024-04-10 15:36:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:15:26.672045"
    },
    {
      "arxiv_id": "2404.07091v1",
      "title": "LaTiM: Longitudinal representation learning in continuous-time models to predict disease progression",
      "title_zh": "翻译失败",
      "authors": [
        "Rachid Zeghlache",
        "Pierre-Henri Conze",
        "Mostafa El Habib Daho",
        "Yihao Li",
        "Hugo Le Boité",
        "Ramin Tadayoni",
        "Pascal Massin",
        "Béatrice Cochener",
        "Alireza Rezaei",
        "Ikram Brahim",
        "Gwenolé Quellec",
        "Mathieu Lamard"
      ],
      "abstract": "This work proposes a novel framework for analyzing disease progression using\ntime-aware neural ordinary differential equations (NODE). We introduce a\n\"time-aware head\" in a framework trained through self-supervised learning (SSL)\nto leverage temporal information in latent space for data augmentation. This\napproach effectively integrates NODEs with SSL, offering significant\nperformance improvements compared to traditional methods that lack explicit\ntemporal integration. We demonstrate the effectiveness of our strategy for\ndiabetic retinopathy progression prediction using the OPHDIAT database.\nCompared to the baseline, all NODE architectures achieve statistically\nsignificant improvements in area under the ROC curve (AUC) and Kappa metrics,\nhighlighting the efficacy of pre-training with SSL-inspired approaches.\nAdditionally, our framework promotes stable training for NODEs, a commonly\nencountered challenge in time-aware modeling.",
      "tldr_zh": "本研究提出LaTiM框架，利用时间感知神经常微分方程(NODE)来分析疾病进展，通过引入“time-aware head”并结合自监督学习(SSL)来利用潜在空间中的时间信息进行数据增强。这种方法有效整合NODE与SSL，提供比传统方法显著的性能提升，并在OPHDIAT数据库上针对糖尿病视网膜病变进展预测进行了验证。与基线模型相比，所有NODE架构在ROC曲线下面积(AUC)和Kappa指标上实现了统计显著改善，同时提升了NODE的训练稳定性，为时间感知疾病预测模型提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted to MICCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.07091v1",
      "published_date": "2024-04-10 15:29:29 UTC",
      "updated_date": "2024-04-10 15:29:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:15:38.789377"
    },
    {
      "arxiv_id": "2404.07084v1",
      "title": "Dynamic Generation of Personalities with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jianzhi Liu",
        "Hexiang Gu",
        "Tianyu Zheng",
        "Liuyu Xiang",
        "Huijia Wu",
        "Jie Fu",
        "Zhaofeng He"
      ],
      "abstract": "In the realm of mimicking human deliberation, large language models (LLMs)\nshow promising performance, thereby amplifying the importance of this research\narea. Deliberation is influenced by both logic and personality. However,\nprevious studies predominantly focused on the logic of LLMs, neglecting the\nexploration of personality aspects. In this work, we introduce Dynamic\nPersonality Generation (DPG), a dynamic personality generation method based on\nHypernetworks. Initially, we embed the Big Five personality theory into GPT-4\nto form a personality assessment machine, enabling it to evaluate characters'\npersonality traits from dialogues automatically. We propose a new metric to\nassess personality generation capability based on this evaluation method. Then,\nwe use this personality assessment machine to evaluate dialogues in script\ndata, resulting in a personality-dialogue dataset. Finally, we fine-tune DPG on\nthe personality-dialogue dataset. Experiments prove that DPG's personality\ngeneration capability is stronger after fine-tuning on this dataset than\ntraditional fine-tuning methods, surpassing prompt-based GPT-4.",
      "tldr_zh": "这篇论文提出 Dynamic Personality Generation (DPG)，一种基于 Hypernetworks 的方法，用于在 Large Language Models (LLMs) 中动态生成人格，以弥补现有研究忽略人格影响的不足。研究者将 Big Five personality theory 嵌入 GPT-4，开发出自动评估人物人格特质的机器，并据此创建一个人格-对话数据集。最终，通过在该数据集上微调 DPG，实验证明其人格生成能力比传统微调方法和基于提示的 GPT-4 更强。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.07084v1",
      "published_date": "2024-04-10 15:17:17 UTC",
      "updated_date": "2024-04-10 15:17:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:15:50.653420"
    },
    {
      "arxiv_id": "2404.07066v7",
      "title": "Exploring Concept Depth: How Large Language Models Acquire Knowledge and Concept at Different Layers?",
      "title_zh": "探索概念深度：大型语言模型如何在不同层获取知识和概念？",
      "authors": [
        "Mingyu Jin",
        "Qinkai Yu",
        "Jingyuan Huang",
        "Qingcheng Zeng",
        "Zhenting Wang",
        "Wenyue Hua",
        "Haiyan Zhao",
        "Kai Mei",
        "Yanda Meng",
        "Kaize Ding",
        "Fan Yang",
        "Mengnan Du",
        "Yongfeng Zhang"
      ],
      "abstract": "Large language models (LLMs) have shown remarkable performances across a wide\nrange of tasks. However, the mechanisms by which these models encode tasks of\nvarying complexities remain poorly understood. In this paper, we explore the\nhypothesis that LLMs process concepts of varying complexities in different\nlayers, introducing the idea of \"Concept Depth\" to suggest that more complex\nconcepts are typically acquired in deeper layers. Specifically, we categorize\nconcepts based on their level of abstraction, defining them in the order of\nincreasing complexity within factual, emotional, and inferential tasks. We\nconduct extensive probing experiments using layer-wise representations across\nvarious LLM families (Gemma, LLaMA, Qwen) on various datasets spanning the\nthree domains of tasks. Our findings reveal that models could efficiently\nconduct probing for simpler tasks in shallow layers, and more complex tasks\ntypically necessitate deeper layers for accurate understanding. Additionally,\nwe examine how external factors, such as adding noise to the input and\nquantizing the model weights, might affect layer-wise representations. Our\nfindings suggest that these factors can impede the development of a conceptual\nunderstanding of LLMs until deeper layers are explored. We hope that our\nproposed concept and experimental insights will enhance the understanding of\nthe mechanisms underlying LLMs. Our codes are available at\nhttps://github.com/Luckfort/CD.",
      "tldr_zh": "这篇论文探讨大型语言模型 (LLMs) 如何在不同层获取知识和概念，引入“Concept Depth”的概念，认为更复杂的概念通常在更深层被处理。作者将概念分类为事实性、情感性和推理性任务，并通过层-wise 探测实验，使用 Gemma、LLaMA 和 Qwen 等模型在相关数据集上进行测试。结果显示，简单任务在浅层即可高效处理，而复杂任务需依赖深层表示；此外，外部因素如输入噪声和模型量化会影响层-wise representations，直到深层才能形成完整概念理解。该研究为理解 LLMs 的内部机制提供了重要洞见，并开源了相关代码。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "COLING 2025",
      "pdf_url": "http://arxiv.org/pdf/2404.07066v7",
      "published_date": "2024-04-10 14:56:40 UTC",
      "updated_date": "2025-02-04 23:34:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:16:03.280909"
    },
    {
      "arxiv_id": "2404.07063v1",
      "title": "LaPlaSS: Latent Space Planning for Stochastic Systems",
      "title_zh": "LaPlaSS：用于随机系统的潜在空间规划",
      "authors": [
        "Marlyse Reeves",
        "Brian C. Williams"
      ],
      "abstract": "Autonomous mobile agents often operate in hazardous environments,\nnecessitating an awareness of safety. These agents can have non-linear,\nstochastic dynamics that must be considered during planning to guarantee\nbounded risk. Most state of the art methods require closed-form dynamics to\nverify plan correctness and safety however modern robotic systems often have\ndynamics that are learned from data. Thus, there is a need to perform efficient\ntrajectory planning with guarantees on risk for agents without known dynamics\nmodels. We propose a \"generate-and-test\" approach to risk-bounded planning in\nwhich a planner generates a candidate trajectory using an approximate linear\ndynamics model and a validator assesses the risk of the trajectory, computing\nadditional safety constraints for the planner if the candidate does not satisfy\nthe desired risk bound. To acquire the approximate model, we use a variational\nautoencoder to learn a latent linear dynamics model and encode the planning\nproblem into the latent space to generate the candidate trajectory. The VAE\nalso serves to sample trajectories around the candidate to use in the\nvalidator. We demonstrate that our algorithm, LaPlaSS, is able to generate\ntrajectory plans with bounded risk for a real-world agent with learned dynamics\nand is an order of magnitude more efficient than the state of the art.",
      "tldr_zh": "本文提出 LaPlaSS，一种针对随机系统的潜在空间规划方法，解决自主移动代理在危险环境中进行风险受限轨迹规划的问题，尤其适用于从数据中学习动态模型的机器人系统。该方法采用“生成并测试”策略，使用变分自编码器 (VAE) 学习潜在线性动态模型，在潜在空间中生成候选轨迹，并通过验证器评估风险以添加安全约束。实验结果表明，LaPlaSS 比现有方法高效一个数量级，能为真实世界代理生成风险受限的轨迹规划。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.07063v1",
      "published_date": "2024-04-10 14:52:35 UTC",
      "updated_date": "2024-04-10 14:52:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:16:15.501742"
    },
    {
      "arxiv_id": "2404.07053v1",
      "title": "Meta4XNLI: A Crosslingual Parallel Corpus for Metaphor Detection and Interpretation",
      "title_zh": "Meta4XNLI：一种用于比喻检测和解释的跨语言平行语料库",
      "authors": [
        "Elisa Sanchez-Bayona",
        "Rodrigo Agerri"
      ],
      "abstract": "Metaphors, although occasionally unperceived, are ubiquitous in our everyday\nlanguage. Thus, it is crucial for Language Models to be able to grasp the\nunderlying meaning of this kind of figurative language. In this work, we\npresent Meta4XNLI, a novel parallel dataset for the tasks of metaphor detection\nand interpretation that contains metaphor annotations in both Spanish and\nEnglish. We investigate language models' metaphor identification and\nunderstanding abilities through a series of monolingual and cross-lingual\nexperiments by leveraging our proposed corpus. In order to comprehend how these\nnon-literal expressions affect models' performance, we look over the results\nand perform an error analysis. Additionally, parallel data offers many\npotential opportunities to investigate metaphor transferability between these\nlanguages and the impact of translation on the development of multilingual\nannotated resources.",
      "tldr_zh": "本研究引入了Meta4XNLI，这是一个跨语言平行语料库，包含西班牙语和英语的比喻注释，用于支持Metaphor Detection和Interpretation任务。该语料库通过单语和跨语实验评估语言模型在识别和理解比喻方面的能力，并进行错误分析以探讨非字面表达对模型性能的影响。结果显示，平行数据有助于研究比喻在语言间的可转移性，以及翻译对多语注释资源开发的影响，为提升语言模型处理比喻语言提供宝贵资源。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.07053v1",
      "published_date": "2024-04-10 14:44:48 UTC",
      "updated_date": "2024-04-10 14:44:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:16:24.970565"
    },
    {
      "arxiv_id": "2404.07046v1",
      "title": "Comparison of decision trees with Local Interpretable Model-Agnostic Explanations (LIME) technique and multi-linear regression for explaining support vector regression model in terms of root mean square error (RMSE) values",
      "title_zh": "翻译失败",
      "authors": [
        "Amit Thombre"
      ],
      "abstract": "In this work the decision trees are used for explanation of support vector\nregression model. The decision trees act as a global technique as well as a\nlocal technique. They are compared against the popular technique of LIME which\nis a local explanatory technique and with multi linear regression. It is\nobserved that decision trees give a lower RMSE value when fitted to support\nvector regression as compared to LIME in 87% of the runs over 5 datasets. The\ncomparison of results is statistically significant. Multi linear regression\nalso gives a lower RMSE value when fitted to support vector regression model as\ncompared to LIME in 73% of the runs over 5 datasets but the comparison of\nresults is not statistically significant. Also, when used as a local\nexplanatory technique, decision trees give better performance than LIME and the\ncomparison of results is statistically significant.",
      "tldr_zh": "本研究比较了 decision trees 与 Local Interpretable Model-Agnostic Explanations (LIME) 技术以及 multi-linear regression 在解释 support vector regression (SVR) 模型时的性能，焦点在于 root mean square error (RMSE) 值。decision trees 作为全局和局部解释方法，在 5 个数据集上 87% 的运行中比 LIME 提供了更低的 RMSE 值，且结果统计显著。multi-linear regression 在 73% 的运行中也比 LIME 表现更好，但差异不统计显著；此外，作为局部解释技术，decision trees 的性能优于 LIME，且统计显著。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.07046v1",
      "published_date": "2024-04-10 14:36:35 UTC",
      "updated_date": "2024-04-10 14:36:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:16:38.469716"
    },
    {
      "arxiv_id": "2404.07017v3",
      "title": "Improving Language Model Reasoning with Self-motivated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yunlong Feng",
        "Yang Xu",
        "Libo Qin",
        "Yasheng Wang",
        "Wanxiang Che"
      ],
      "abstract": "Large-scale high-quality training data is important for improving the\nperformance of models. After trained with data that has rationales (reasoning\nsteps), models gain reasoning capability. However, the dataset with\nhigh-quality rationales is relatively scarce due to the high annotation cost.\nTo address this issue, we propose \\textit{Self-motivated Learning} framework.\nThe framework motivates the model itself to automatically generate rationales\non existing datasets. Based on the inherent rank from correctness across\nmultiple rationales, the model learns to generate better rationales, leading to\nhigher reasoning capability. Specifically, we train a reward model with the\nrank to evaluate the quality of rationales, and improve the performance of\nreasoning through reinforcement learning. Experiment results of Llama2 7B on\nmultiple reasoning datasets show that our method significantly improves the\nreasoning ability of models, even outperforming text-davinci-002 in some\ndatasets.",
      "tldr_zh": "这篇论文提出 Self-motivated Learning 框架，以解决高质量推理数据（带有 rationales 的数据集）稀缺问题，允许语言模型自动生成和改进推理步骤。框架通过基于多个 rationales 的正确性排名训练一个 reward model，并应用 reinforcement learning 来提升模型的推理能力。具体来说，实验在 Llama2 7B 模型上显示，该方法显著提高了模型在多个推理数据集上的性能，甚至在某些数据集上超过了 text-davinci-002。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at LREC-COLING 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.07017v3",
      "published_date": "2024-04-10 14:05:44 UTC",
      "updated_date": "2024-04-30 14:38:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:16:51.361918"
    },
    {
      "arxiv_id": "2404.07008v1",
      "title": "Knowledge graphs for empirical concept retrieval",
      "title_zh": "知识图谱用于经验概念检索",
      "authors": [
        "Lenka Tětková",
        "Teresa Karen Scheidt",
        "Maria Mandrup Fogh",
        "Ellen Marie Gaunby Jørgensen",
        "Finn Årup Nielsen",
        "Lars Kai Hansen"
      ],
      "abstract": "Concept-based explainable AI is promising as a tool to improve the\nunderstanding of complex models at the premises of a given user, viz.\\ as a\ntool for personalized explainability. An important class of concept-based\nexplainability methods is constructed with empirically defined concepts,\nindirectly defined through a set of positive and negative examples, as in the\nTCAV approach (Kim et al., 2018). While it is appealing to the user to avoid\nformal definitions of concepts and their operationalization, it can be\nchallenging to establish relevant concept datasets. Here, we address this\nchallenge using general knowledge graphs (such as, e.g., Wikidata or WordNet)\nfor comprehensive concept definition and present a workflow for user-driven\ndata collection in both text and image domains. The concepts derived from\nknowledge graphs are defined interactively, providing an opportunity for\npersonalization and ensuring that the concepts reflect the user's intentions.\nWe test the retrieved concept datasets on two concept-based explainability\nmethods, namely concept activation vectors (CAVs) and concept activation\nregions (CARs) (Crabbe and van der Schaar, 2022). We show that CAVs and CARs\nbased on these empirical concept datasets provide robust and accurate\nexplanations. Importantly, we also find good alignment between the models'\nrepresentations of concepts and the structure of knowledge graphs, i.e., human\nrepresentations. This supports our conclusion that knowledge graph-based\nconcepts are relevant for XAI.",
      "tldr_zh": "该研究探讨了使用知识 graphs 来检索经验概念，以提升概念-based explainable AI 的个性化解释能力。作者提出一种基于知识 graphs（如 Wikidata 或 WordNet）的用户驱动工作流，用于交互式定义概念并收集文本和图像数据，从而解决传统经验概念（如 TCAV 方法）数据集建立的挑战。在测试中，基于这些概念数据集的 CAVs 和 CARs 方法显示出稳健且准确的解释效果，并证明了模型概念表示与知识 graphs 结构（即人类表示）的良好对齐，强化了这种方法在 XAI 中的相关性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint. Accepted to The 2nd World Conference on eXplainable\n  Artificial Intelligence",
      "pdf_url": "http://arxiv.org/pdf/2404.07008v1",
      "published_date": "2024-04-10 13:47:22 UTC",
      "updated_date": "2024-04-10 13:47:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:17:03.371709"
    },
    {
      "arxiv_id": "2404.07005v1",
      "title": "WordDecipher: Enhancing Digital Workspace Communication with Explainable AI for Non-native English Speakers",
      "title_zh": "翻译失败",
      "authors": [
        "Yuexi Chen",
        "Zhicheng Liu"
      ],
      "abstract": "Non-native English speakers (NNES) face challenges in digital workspace\ncommunication (e.g., emails, Slack messages), often inadvertently translating\nexpressions from their native languages, which can lead to awkward or incorrect\nusage. Current AI-assisted writing tools are equipped with fluency enhancement\nand rewriting suggestions; however, NNES may struggle to grasp the subtleties\namong various expressions, making it challenging to choose the one that\naccurately reflects their intent. Such challenges are exacerbated in high-stake\ntext-based communications, where the absence of non-verbal cues heightens the\nrisk of misinterpretation. By leveraging the latest advancements in large\nlanguage models (LLM) and word embeddings, we propose WordDecipher, an\nexplainable AI-assisted writing tool to enhance digital workspace communication\nfor NNES. WordDecipher not only identifies the perceived social intentions\ndetected in users' writing, but also generates rewriting suggestions aligned\nwith users' intended messages, either numerically or by inferring from users'\nwriting in their native language. Then, WordDecipher provides an overview of\nnuances to help NNES make selections. Through a usage scenario, we demonstrate\nhow WordDecipher can significantly enhance an NNES's ability to communicate her\nrequest, showcasing its potential to transform workspace communication for\nNNES.",
      "tldr_zh": "该研究针对非母语英语使用者（NNES）在数字工作场所沟通（如邮件和Slack消息）中的挑战，提出WordDecipher，一种基于大型语言模型（LLM）和词嵌入的可解释AI工具，以解决表达细微差别理解困难和误解风险的问题。WordDecipher能够识别用户写作中的感知社会意图，并生成与用户意图一致的重写建议，包括数字方式或从母语写作中推断。系统还提供细微差别的概述，帮助NNES选择合适的表达。通过实际使用场景演示，该工具显著提升了NNES的沟通能力，展示了其在高风险文本沟通中的潜力。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.HC",
      "comment": "The Third Workshop on Intelligent and Interactive Writing Assistants\n  (In2Writing) at CHI 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.07005v1",
      "published_date": "2024-04-10 13:40:29 UTC",
      "updated_date": "2024-04-10 13:40:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:17:15.996061"
    },
    {
      "arxiv_id": "2404.07001v3",
      "title": "Event Grounded Criminal Court View Generation with Cooperative (Large) Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Linan Yue",
        "Qi Liu",
        "Lili Zhao",
        "Li Wang",
        "Weibo Gao",
        "Yanqing An"
      ],
      "abstract": "With the development of legal intelligence, Criminal Court View Generation\nhas attracted much attention as a crucial task of legal intelligence, which\naims to generate concise and coherent texts that summarize case facts and\nprovide explanations for verdicts. Existing researches explore the key\ninformation in case facts to yield the court views. Most of them employ a\ncoarse-grained approach that partitions the facts into broad segments (e.g.,\nverdict-related sentences) to make predictions. However, this approach fails to\ncapture the complex details present in the case facts, such as various criminal\nelements and legal events. To this end, in this paper, we propose an Event\nGrounded Generation (EGG) method for criminal court view generation with\ncooperative (Large) Language Models, which introduces the fine-grained event\ninformation into the generation. Specifically, we first design a LLMs-based\nextraction method that can extract events in case facts without massive\nannotated events. Then, we incorporate the extracted events into court view\ngeneration by merging case facts and events. Besides, considering the\ncomputational burden posed by the use of LLMs in the extraction phase of EGG,\nwe propose a LLMs-free EGG method that can eliminate the requirement for event\nextraction using LLMs in the inference phase. Extensive experimental results on\na real-world dataset clearly validate the effectiveness of our proposed method.",
      "tldr_zh": "该论文针对Criminal Court View Generation任务，提出了一种Event Grounded Generation (EGG)方法，利用合作的大型语言模型((Large) Language Models)来生成总结案件事实并解释判决的简洁文本。该方法通过基于LLMs的事件提取技术，从案件事实中提取细粒度事件（如犯罪元素和法律事件），并将这些事件整合到生成过程中，以提升对复杂细节的捕捉。为减少计算负担，论文还设计了LLMs-free的EGG变体，在推理阶段无需依赖LLMs。实验结果在真实数据集上验证了该方法的有效性，显著提高了生成文本的质量。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to SIGIR2024",
      "pdf_url": "http://arxiv.org/pdf/2404.07001v3",
      "published_date": "2024-04-10 13:31:07 UTC",
      "updated_date": "2024-04-16 06:34:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:17:28.097738"
    },
    {
      "arxiv_id": "2404.06996v1",
      "title": "XNLIeu: a dataset for cross-lingual NLI in Basque",
      "title_zh": "翻译失败",
      "authors": [
        "Maite Heredia",
        "Julen Etxaniz",
        "Muitze Zulaika",
        "Xabier Saralegi",
        "Jeremy Barnes",
        "Aitor Soroa"
      ],
      "abstract": "XNLI is a popular Natural Language Inference (NLI) benchmark widely used to\nevaluate cross-lingual Natural Language Understanding (NLU) capabilities across\nlanguages. In this paper, we expand XNLI to include Basque, a low-resource\nlanguage that can greatly benefit from transfer-learning approaches. The new\ndataset, dubbed XNLIeu, has been developed by first machine-translating the\nEnglish XNLI corpus into Basque, followed by a manual post-edition step. We\nhave conducted a series of experiments using mono- and multilingual LLMs to\nassess a) the effect of professional post-edition on the MT system; b) the best\ncross-lingual strategy for NLI in Basque; and c) whether the choice of the best\ncross-lingual strategy is influenced by the fact that the dataset is built by\ntranslation. The results show that post-edition is necessary and that the\ntranslate-train cross-lingual strategy obtains better results overall, although\nthe gain is lower when tested in a dataset that has been built natively from\nscratch. Our code and datasets are publicly available under open licenses.",
      "tldr_zh": "本文介绍了 XNLIeu 数据集，这是一个针对低资源语言巴斯克语 (Basque) 的跨语言 Natural Language Inference (NLI) 基准，用于评估跨语言 Natural Language Understanding (NLU) 能力。数据集通过先将英语 XNLI 语料机器翻译成巴斯克语，然后进行手动后编辑来构建。实验使用单语和多语大型语言模型 (LLMs) 表明，后编辑步骤是必要的，且 translate-train 跨语言策略整体表现最佳，尽管其优势在原生数据集上较小。代码和数据集已以开源许可公开可用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NAACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.06996v1",
      "published_date": "2024-04-10 13:19:56 UTC",
      "updated_date": "2024-04-10 13:19:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:17:40.012917"
    },
    {
      "arxiv_id": "2404.06972v1",
      "title": "Toward industrial use of continual learning : new metrics proposal for class incremental learning",
      "title_zh": "翻译失败",
      "authors": [
        "Konaté Mohamed Abbas",
        "Anne-Françoise Yao",
        "Thierry Chateau",
        "Pierre Bouges"
      ],
      "abstract": "In this paper, we investigate continual learning performance metrics used in\nclass incremental learning strategies for continual learning (CL) using some\nhigh performing methods. We investigate especially mean task accuracy. First,\nwe show that it lacks of expressiveness through some simple experiments to\ncapture performance. We show that monitoring average tasks performance is over\noptimistic and can lead to misleading conclusions for future real life\nindustrial uses. Then, we propose first a simple metric, Minimal Incremental\nClass Accuracy (MICA) which gives a fair and more useful evaluation of\ndifferent continual learning methods. Moreover, in order to provide a simple\nway to easily compare different methods performance in continual learning, we\nderive another single scalar metric that take into account the learning\nperformance variation as well as our newly introduced metric.",
      "tldr_zh": "这篇论文探讨了持续学习（continual learning）中类增量学习（class incremental learning）的性能指标问题，特别是均值任务准确率（mean task accuracy）的不足，通过简单实验证明其缺乏表现力和过于乐观，可能导致工业应用中的误导性结论。作者提出了一种新指标Minimal Incremental Class Accuracy (MICA)，用于提供更公平且实用的方法评估不同持续学习策略。此外，他们还导出了另一个单一标量指标，该指标同时考虑学习性能变化和MICA，帮助简化不同方法的比较，推动持续学习在工业领域的实际应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages, Accepted at IJCNN 2023",
      "pdf_url": "http://arxiv.org/pdf/2404.06972v1",
      "published_date": "2024-04-10 12:32:18 UTC",
      "updated_date": "2024-04-10 12:32:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:17:52.370760"
    },
    {
      "arxiv_id": "2404.06971v1",
      "title": "TrajPRed: Trajectory Prediction with Region-based Relation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Chen Zhou",
        "Ghassan AlRegib",
        "Armin Parchami",
        "Kunjan Singh"
      ],
      "abstract": "Forecasting human trajectories in traffic scenes is critical for safety\nwithin mixed or fully autonomous systems. Human future trajectories are driven\nby two major stimuli, social interactions, and stochastic goals. Thus, reliable\nforecasting needs to capture these two stimuli. Edge-based relation modeling\nrepresents social interactions using pairwise correlations from precise\nindividual states. Nevertheless, edge-based relations can be vulnerable under\nperturbations. To alleviate these issues, we propose a region-based relation\nlearning paradigm that models social interactions via region-wise dynamics of\njoint states, i.e., the changes in the density of crowds. In particular,\nregion-wise agent joint information is encoded within convolutional feature\ngrids. Social relations are modeled by relating the temporal changes of local\njoint information from a global perspective. We show that region-based\nrelations are less susceptible to perturbations. In order to account for the\nstochastic individual goals, we exploit a conditional variational autoencoder\nto realize multi-goal estimation and diverse future prediction. Specifically,\nwe perform variational inference via the latent distribution, which is\nconditioned on the correlation between input states and associated target\ngoals. Sampling from the latent distribution enables the framework to reliably\ncapture the stochastic behavior in test data. We integrate multi-goal\nestimation and region-based relation learning to model the two stimuli, social\ninteractions, and stochastic goals, in a prediction framework. We evaluate our\nframework on the ETH-UCY dataset and Stanford Drone Dataset (SDD). We show that\nthe diverse prediction better fits the ground truth when incorporating the\nrelation module. Our framework outperforms the state-of-the-art models on SDD\nby $27.61\\%$/$18.20\\%$ of ADE/FDE metrics.",
      "tldr_zh": "这篇论文提出 TrajPRed 框架，用于在交通场景中预测人类轨迹，通过 region-based relation learning 范式来建模社会互动，即利用卷积特征网格编码区域内人群密度的动态变化，从而提高对干扰的鲁棒性。框架还整合条件变分自编码器（conditional variational autoencoder）来处理随机目标，实现多目标估计和多样化未来预测。实验结果显示，在 ETH-UCY 和 Stanford Drone Dataset (SDD) 上，该框架在 SDD 上比最先进模型提高了 27.61% ADE 和 18.20% FDE 指标，显著提升了预测准确性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.06971v1",
      "published_date": "2024-04-10 12:31:43 UTC",
      "updated_date": "2024-04-10 12:31:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:18:05.014068"
    },
    {
      "arxiv_id": "2404.06962v1",
      "title": "Advancing Real-time Pandemic Forecasting Using Large Language Models: A COVID-19 Case Study",
      "title_zh": "翻译失败",
      "authors": [
        "Hongru Du",
        "Jianan Zhao",
        "Yang Zhao",
        "Shaochong Xu",
        "Xihong Lin",
        "Yiran Chen",
        "Lauren M. Gardner",
        "Hao Frank Yang"
      ],
      "abstract": "Forecasting the short-term spread of an ongoing disease outbreak is a\nformidable challenge due to the complexity of contributing factors, some of\nwhich can be characterized through interlinked, multi-modality variables such\nas epidemiological time series data, viral biology, population demographics,\nand the intersection of public policy and human behavior. Existing forecasting\nmodel frameworks struggle with the multifaceted nature of relevant data and\nrobust results translation, which hinders their performances and the provision\nof actionable insights for public health decision-makers. Our work introduces\nPandemicLLM, a novel framework with multi-modal Large Language Models (LLMs)\nthat reformulates real-time forecasting of disease spread as a text reasoning\nproblem, with the ability to incorporate real-time, complex, non-numerical\ninformation that previously unattainable in traditional forecasting models.\nThis approach, through a unique AI-human cooperative prompt design and time\nseries representation learning, encodes multi-modal data for LLMs. The model is\napplied to the COVID-19 pandemic, and trained to utilize textual public health\npolicies, genomic surveillance, spatial, and epidemiological time series data,\nand is subsequently tested across all 50 states of the U.S. Empirically,\nPandemicLLM is shown to be a high-performing pandemic forecasting framework\nthat effectively captures the impact of emerging variants and can provide\ntimely and accurate predictions. The proposed PandemicLLM opens avenues for\nincorporating various pandemic-related data in heterogeneous formats and\nexhibits performance benefits over existing models. This study illuminates the\npotential of adapting LLMs and representation learning to enhance pandemic\nforecasting, illustrating how AI innovations can strengthen pandemic responses\nand crisis management in the future.",
      "tldr_zh": "该研究提出 PandemicLLM 框架，利用多模态 Large Language Models (LLMs) 将实时疫情传播预测转化为文本推理问题，以解决传统模型在处理多方面数据（如流行病学时间序列、公共卫生政策和基因组监测）时的局限性。框架通过 AI-人类合作提示设计和时间序列表示学习，整合实时复杂信息，并在 COVID-19 案例中训练并测试于美国 50 个州。实验结果显示，PandemicLLM 比现有模型性能更优，能准确捕捉新兴变异株的影响，提供及时预测，并为未来疫情响应和危机管理带来新机遇。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "35 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.06962v1",
      "published_date": "2024-04-10 12:22:03 UTC",
      "updated_date": "2024-04-10 12:22:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:18:15.225771"
    },
    {
      "arxiv_id": "2404.06957v1",
      "title": "Adversarial purification for no-reference image-quality metrics: applicability study and new methods",
      "title_zh": "翻译失败",
      "authors": [
        "Aleksandr Gushchin",
        "Anna Chistyakova",
        "Vladislav Minashkin",
        "Anastasia Antsiferova",
        "Dmitriy Vatolin"
      ],
      "abstract": "Recently, the area of adversarial attacks on image quality metrics has begun\nto be explored, whereas the area of defences remains under-researched. In this\nstudy, we aim to cover that case and check the transferability of adversarial\npurification defences from image classifiers to IQA methods. In this paper, we\napply several widespread attacks on IQA models and examine the success of the\ndefences against them. The purification methodologies covered different\npreprocessing techniques, including geometrical transformations, compression,\ndenoising, and modern neural network-based methods. Also, we address the\nchallenge of assessing the efficacy of a defensive methodology by proposing\nways to estimate output visual quality and the success of neutralizing attacks.\nDefences were tested against attack on three IQA metrics -- Linearity, MetaIQA\nand SPAQ. The code for attacks and defences is available at: (link is hidden\nfor a blind review).",
      "tldr_zh": "本文研究了针对无参考图像质量评估(IQA)模型的对抗净化防御，探讨了将这种防御从图像分类器转移到IQA方法的适用性。作者应用多种常见攻击（如几何变换、压缩、去噪和神经网络-based方法）来测试防御效果，并提出新方式评估输出视觉质量和中和攻击的成功性。实验结果显示，这些防御在Linearity、MetaIQA和SPAQ等IQA指标上有效，提升了模型的鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.06957v1",
      "published_date": "2024-04-10 12:17:25 UTC",
      "updated_date": "2024-04-10 12:17:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:18:27.082792"
    },
    {
      "arxiv_id": "2404.06955v1",
      "title": "Untangling Critical Interaction with AI in Students Written Assessment",
      "title_zh": "在学生书面评估中厘清与",
      "authors": [
        "Antonette Shibani",
        "Simon Knight",
        "Kirsty Kitto",
        "Ajanie Karunanayake",
        "Simon Buckingham Shum"
      ],
      "abstract": "Artificial Intelligence (AI) has become a ubiquitous part of society, but a\nkey challenge exists in ensuring that humans are equipped with the required\ncritical thinking and AI literacy skills to interact with machines effectively\nby understanding their capabilities and limitations. These skills are\nparticularly important for learners to develop in the age of generative AI\nwhere AI tools can demonstrate complex knowledge and ability previously thought\nto be uniquely human. To activate effective human-AI partnerships in writing,\nthis paper provides a first step toward conceptualizing the notion of critical\nlearner interaction with AI. Using both theoretical models and empirical data,\nour preliminary findings suggest a general lack of Deep interaction with AI\nduring the writing process. We believe that the outcomes can lead to better\ntask and tool design in the future for learners to develop deep, critical\nthinking when interacting with AI.",
      "tldr_zh": "该研究探讨了在生成式 AI 时代，确保人类具备批判性思考和 AI literacy 技能的重要性，以有效与 AI 互动，特别是针对学生的写作评估。论文首次概念化了学习者与 AI 的批判性互动框架，通过理论模型和实证数据分析，发现写作过程中普遍缺乏 Deep interaction。研究结果表明，这可指导未来任务和工具设计，帮助培养学习者的深度批判性思考，从而提升 human-AI partnerships。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "I.2; K.3.1"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.06955v1",
      "published_date": "2024-04-10 12:12:50 UTC",
      "updated_date": "2024-04-10 12:12:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:18:38.615891"
    },
    {
      "arxiv_id": "2404.06948v2",
      "title": "MetaCheckGPT -- A Multi-task Hallucination Detector Using LLM Uncertainty and Meta-models",
      "title_zh": "MetaCheckGPT -- 一个使用LLM不确定性和元模型的多任务幻觉检测器",
      "authors": [
        "Rahul Mehta",
        "Andrew Hoblitzell",
        "Jack O'Keefe",
        "Hyeju Jang",
        "Vasudeva Varma"
      ],
      "abstract": "Hallucinations in large language models (LLMs) have recently become a\nsignificant problem. A recent effort in this direction is a shared task at\nSemeval 2024 Task 6, SHROOM, a Shared-task on Hallucinations and Related\nObservable Overgeneration Mistakes. This paper describes our winning solution\nranked 1st and 2nd in the 2 sub-tasks of model agnostic and model aware tracks\nrespectively. We propose a meta-regressor framework of LLMs for model\nevaluation and integration that achieves the highest scores on the leaderboard.\nWe also experiment with various transformer-based models and black box methods\nlike ChatGPT, Vectara, and others. In addition, we perform an error analysis\ncomparing GPT4 against our best model which shows the limitations of the\nformer.",
      "tldr_zh": "本研究提出 MetaCheckGPT，一种多任务幻觉检测器，利用 LLM 不确定性（LLM uncertainty）和 meta-models 来识别大型语言模型（LLMs）中的 hallucinations 问题。\n该框架采用 meta-regressor 结构进行模型评估和集成，实验了各种 transformer-based 模型以及黑盒方法如 ChatGPT 和 Vectara。\n在 Semeval 2024 Task 6 的两个子任务中，系统分别获得模型无关和模型相关赛道的第一和第二名，并通过错误分析突显了其优于 GPT4 的性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T07, 68T50",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "Entry for SemEval-2024 Shared Task 6: SHROOM, a Shared-task on\n  Hallucinations and Related Observable Overgeneration Mistakes",
      "pdf_url": "http://arxiv.org/pdf/2404.06948v2",
      "published_date": "2024-04-10 11:56:01 UTC",
      "updated_date": "2024-04-11 15:39:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:18:51.622095"
    },
    {
      "arxiv_id": "2404.06946v1",
      "title": "A Survey on the Integration of Generative AI for Critical Thinking in Mobile Networks",
      "title_zh": "生成式 AI 在移动网络中用于批判性思维的整合调查",
      "authors": [
        "Athanasios Karapantelakis",
        "Alexandros Nikou",
        "Ajay Kattepur",
        "Jean Martins",
        "Leonid Mokrushin",
        "Swarup Kumar Mohalik",
        "Marin Orlic",
        "Aneta Vulgarakis Feljan"
      ],
      "abstract": "In the near future, mobile networks are expected to broaden their services\nand coverage to accommodate a larger user base and diverse user needs. Thus,\nthey will increasingly rely on artificial intelligence (AI) to manage network\noperation and control costs, undertaking complex decision-making roles. This\nshift will necessitate the application of techniques that incorporate critical\nthinking abilities, including reasoning and planning. Symbolic AI techniques\nalready facilitate critical thinking based on existing knowledge. Yet, their\nuse in telecommunications is hindered by the high cost of mostly manual\ncuration of this knowledge and high computational complexity of reasoning\ntasks. At the same time, there is a spurt of innovations in industries such as\ntelecommunications due to Generative AI (GenAI) technologies, operating\nindependently of human-curated knowledge. However, their capacity for critical\nthinking remains uncertain. This paper aims to address this gap by examining\nthe current status of GenAI algorithms with critical thinking capabilities and\ninvestigating their potential applications in telecom networks. Specifically,\nthe aim of this study is to offer an introduction to the potential utilization\nof GenAI for critical thinking techniques in mobile networks, while also\nestablishing a foundation for future research.",
      "tldr_zh": "本调查探讨了Generative AI (GenAI) 在移动网络中整合以提升批判性思维（包括推理和规划）的潜力。论文指出，传统Symbolic AI 虽能支持批判性思维，但受限于手动知识整理的高成本和计算复杂性，而GenAI 技术则在电信领域迅速创新，却其批判性思维能力仍存不确定性。主要贡献在于，审视了GenAI 算法的当前状态，并分析其在电信网络中的潜在应用，为未来研究奠定基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 3 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2404.06946v1",
      "published_date": "2024-04-10 11:55:33 UTC",
      "updated_date": "2024-04-10 11:55:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:19:02.858264"
    },
    {
      "arxiv_id": "2404.06939v4",
      "title": "Late Breaking Results: Fast System Technology Co-Optimization Framework for Emerging Technology Based on Graph Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Tianliang Ma",
        "Guangxi Fan",
        "Xuguang Sun",
        "Zhihui Deng",
        "Kainlu Low",
        "Leilai Shao"
      ],
      "abstract": "This paper proposes a fast system technology co-optimization (STCO) framework\nthat optimizes power, performance, and area (PPA) for next-generation IC\ndesign, addressing the challenges and opportunities presented by novel\nmaterials and device architectures. We focus on accelerating the technology\nlevel of STCO using AI techniques, by employing graph neural network\n(GNN)-based approaches for both TCAD simulation and cell library\ncharacterization, which are interconnected through a unified compact model,\ncollectively achieving over a 100X speedup over traditional methods. These\nadvancements enable comprehensive STCO iterations with runtime speedups ranging\nfrom 1.9X to 14.1X and supports both emerging and traditional technologies.",
      "tldr_zh": "这篇论文提出了一种快速系统技术协同优化（STCO）框架，用于优化下一代集成电路（IC）设计的功率、性能和面积（PPA），以应对新型材料和设备架构的挑战。框架采用图神经网络（GNN）技术加速 TCAD 模拟和单元库表征，并通过一个统一的紧凑模型将这些过程互联，实现超过 100 倍的整体速度提升。实验结果表明，该框架使 STCO 迭代运行时间加快 1.9X 到 14.1X，同时支持新兴和传统技术。",
      "categories": [
        "cs.ET",
        "cs.AI"
      ],
      "primary_category": "cs.ET",
      "comment": "This article has been accepted by the 61st Design Automation\n  Conference(DAC)",
      "pdf_url": "http://arxiv.org/pdf/2404.06939v4",
      "published_date": "2024-04-10 11:43:26 UTC",
      "updated_date": "2024-10-30 02:44:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:19:15.765234"
    },
    {
      "arxiv_id": "2406.16878v1",
      "title": "Benchmarking Semantic Communications for Image Transmission Over MIMO Interference Channels",
      "title_zh": "语义通信在MIMO干扰信道上图像传输的基准测试",
      "authors": [
        "Yanhu Wang",
        "Shuaishuai Guo",
        "Anming Dong",
        "Hui Zhao"
      ],
      "abstract": "Semantic communications offer promising prospects for enhancing data\ntransmission efficiency. However, existing schemes have predominantly\nconcentrated on point-to-point transmissions. In this paper, we aim to\ninvestigate the validity of this claim in interference scenarios compared to\nbaseline approaches. Specifically, our focus is on general multiple-input\nmultiple-output (MIMO) interference channels, where we propose an\ninterference-robust semantic communication (IRSC) scheme. This scheme involves\nthe development of transceivers based on neural networks (NNs), which integrate\nchannel state information (CSI) either solely at the receiver or at both\ntransmitter and receiver ends. Moreover, we establish a composite loss function\nfor training IRSC transceivers, along with a dynamic mechanism for updating the\nweights of various components in the loss function to enhance system fairness\namong users. Experimental results demonstrate that the proposed IRSC scheme\neffectively learns to mitigate interference and outperforms baseline\napproaches, particularly in low signal-to-noise (SNR) regimes.",
      "tldr_zh": "这篇论文评估了语义通信（Semantic communications）在多输入多输出（MIMO）干扰信道中图像传输的性能，旨在与基线方法比较其在干扰场景下的有效性。研究提出了一种干扰鲁棒语义通信（IRSC）方案，使用基于神经网络（NNs）的收发器整合信道状态信息（CSI），并在收发端实现灵活配置。同时，IRSC 引入了复合损失函数和动态权重更新机制，以提升系统用户公平性。实验结果显示，该方案在低信噪比（SNR）环境中有效缓解干扰，并显著优于基线方法。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16878v1",
      "published_date": "2024-04-10 11:40:22 UTC",
      "updated_date": "2024-04-10 11:40:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:19:28.232851"
    },
    {
      "arxiv_id": "2404.06921v1",
      "title": "GoEX: Perspectives and Designs Towards a Runtime for Autonomous LLM Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Shishir G. Patil",
        "Tianjun Zhang",
        "Vivian Fang",
        "Noppapon C.",
        "Roy Huang",
        "Aaron Hao",
        "Martin Casado",
        "Joseph E. Gonzalez",
        "Raluca Ada Popa",
        "Ion Stoica"
      ],
      "abstract": "Large Language Models (LLMs) are evolving beyond their classical role of\nproviding information within dialogue systems to actively engaging with tools\nand performing actions on real-world applications and services. Today, humans\nverify the correctness and appropriateness of the LLM-generated outputs (e.g.,\ncode, functions, or actions) before putting them into real-world execution.\nThis poses significant challenges as code comprehension is well known to be\nnotoriously difficult. In this paper, we study how humans can efficiently\ncollaborate with, delegate to, and supervise autonomous LLMs in the future. We\nargue that in many cases, \"post-facto validation\" - verifying the correctness\nof a proposed action after seeing the output - is much easier than the\naforementioned \"pre-facto validation\" setting. The core concept behind enabling\na post-facto validation system is the integration of an intuitive undo feature,\nand establishing a damage confinement for the LLM-generated actions as\neffective strategies to mitigate the associated risks. Using this, a human can\nnow either revert the effect of an LLM-generated output or be confident that\nthe potential risk is bounded. We believe this is critical to unlock the\npotential for LLM agents to interact with applications and services with\nlimited (post-facto) human involvement. We describe the design and\nimplementation of our open-source runtime for executing LLM actions, Gorilla\nExecution Engine (GoEX), and present open research questions towards realizing\nthe goal of LLMs and applications interacting with each other with minimal\nhuman supervision. We release GoEX at https://github.com/ShishirPatil/gorilla/.",
      "tldr_zh": "该论文探讨了大型语言模型（LLMs）从对话系统演变为主动与工具交互的演变，并分析了人类在执行LLM生成输出（如代码或动作）前进行验证的挑战。作者提出“post-facto validation”（事后验证）作为更高效的策略，通过整合直观的undo功能和damage confinement（损害限制）机制，允许人类轻松撤销错误或控制风险，从而减少对自治LLM应用的监督。论文介绍了开源运行时GoEX（Gorilla Execution Engine）的设计和实现，并提出了未来研究问题，以实现LLMs与应用间的最小人类干预交互。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.06921v1",
      "published_date": "2024-04-10 11:17:33 UTC",
      "updated_date": "2024-04-10 11:17:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:19:39.959747"
    },
    {
      "arxiv_id": "2404.06910v2",
      "title": "Superposition Prompting: Improving and Accelerating Retrieval-Augmented Generation",
      "title_zh": "Superposition Prompting：改进与加速检索增强生成",
      "authors": [
        "Thomas Merth",
        "Qichen Fu",
        "Mohammad Rastegari",
        "Mahyar Najibi"
      ],
      "abstract": "Despite the successes of large language models (LLMs), they exhibit\nsignificant drawbacks, particularly when processing long contexts. Their\ninference cost scales quadratically with respect to sequence length, making it\nexpensive for deployment in some real-world text processing applications, such\nas retrieval-augmented generation (RAG). Additionally, LLMs also exhibit the\n\"distraction phenomenon\", where irrelevant context in the prompt degrades\noutput quality. To address these drawbacks, we propose a novel RAG prompting\nmethodology, *superposition prompting*, which can be directly applied to\npre-trained transformer-based LLMs *without the need for fine-tuning*. At a\nhigh level, superposition prompting allows the LLM to process input documents\nin parallel *prompt paths*, discarding paths once they are deemed irrelevant.\nWe demonstrate the capability of our method to simultaneously enhance time\nefficiency across a variety of question-answering benchmarks using multiple\npre-trained LLMs. Furthermore, our technique significantly improves accuracy\nwhen the retrieved context is large relative the context the model was trained\non. For example, our approach facilitates a 93x reduction in compute time while\n*improving* accuracy by 43% on the NaturalQuestions-Open dataset with the\nMPT-7B instruction-tuned model over naive RAG.",
      "tldr_zh": "该研究针对大型语言模型（LLMs）在处理长上下文时存在的计算成本高和“distraction phenomenon”（无关上下文降低输出质量）等问题，提出了一种新型检索增强生成（RAG）提示方法——Superposition Prompting。无需微调，该方法允许LLMs在多个平行提示路径中处理输入文档，并动态丢弃无关路径，从而提高效率和准确性。在各种问答基准测试中，Superposition Prompting显著提升了时间效率，例如在使用MPT-7B模型时，在NaturalQuestions-Open数据集上实现了93倍计算时间减少，同时准确率提高了43%。这项技术特别适用于检索上下文较大的场景，为Transformer-based LLMs的实际部署提供了重要改进。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.06910v2",
      "published_date": "2024-04-10 11:03:17 UTC",
      "updated_date": "2024-07-19 17:47:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:19:51.560763"
    },
    {
      "arxiv_id": "2404.06903v2",
      "title": "DreamScene360: Unconstrained Text-to-3D Scene Generation with Panoramic Gaussian Splatting",
      "title_zh": "翻译失败",
      "authors": [
        "Shijie Zhou",
        "Zhiwen Fan",
        "Dejia Xu",
        "Haoran Chang",
        "Pradyumna Chari",
        "Tejas Bharadwaj",
        "Suya You",
        "Zhangyang Wang",
        "Achuta Kadambi"
      ],
      "abstract": "The increasing demand for virtual reality applications has highlighted the\nsignificance of crafting immersive 3D assets. We present a text-to-3D\n360$^{\\circ}$ scene generation pipeline that facilitates the creation of\ncomprehensive 360$^{\\circ}$ scenes for in-the-wild environments in a matter of\nminutes. Our approach utilizes the generative power of a 2D diffusion model and\nprompt self-refinement to create a high-quality and globally coherent panoramic\nimage. This image acts as a preliminary \"flat\" (2D) scene representation.\nSubsequently, it is lifted into 3D Gaussians, employing splatting techniques to\nenable real-time exploration. To produce consistent 3D geometry, our pipeline\nconstructs a spatially coherent structure by aligning the 2D monocular depth\ninto a globally optimized point cloud. This point cloud serves as the initial\nstate for the centroids of 3D Gaussians. In order to address invisible issues\ninherent in single-view inputs, we impose semantic and geometric constraints on\nboth synthesized and input camera views as regularizations. These guide the\noptimization of Gaussians, aiding in the reconstruction of unseen regions. In\nsummary, our method offers a globally consistent 3D scene within a\n360$^{\\circ}$ perspective, providing an enhanced immersive experience over\nexisting techniques. Project website at: http://dreamscene360.github.io/",
      "tldr_zh": "我们提出了DreamScene360，一种不受约束的文本到3D场景生成方法，利用Panoramic Gaussian Splatting技术，在几分钟内创建全面的360° 3D环境。该方法结合2D diffusion模型和提示自精炼生成高质量、全局连贯的全景图像，然后通过将2D单目深度对齐到全局优化的点云，并施加语义和几何约束来优化3D Gaussians，从而重建不可见区域。相比现有技术，该框架显著提升了沉浸式体验，提供更一致的3D几何结构。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.06903v2",
      "published_date": "2024-04-10 10:46:59 UTC",
      "updated_date": "2024-07-25 08:19:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:20:04.169088"
    },
    {
      "arxiv_id": "2404.08695v2",
      "title": "Enhancing Question Answering for Enterprise Knowledge Bases using Large Language Models",
      "title_zh": "利用大型语言模型增强企业知识库的问题回答系统",
      "authors": [
        "Feihu Jiang",
        "Chuan Qin",
        "Kaichun Yao",
        "Chuyu Fang",
        "Fuzhen Zhuang",
        "Hengshu Zhu",
        "Hui Xiong"
      ],
      "abstract": "Efficient knowledge management plays a pivotal role in augmenting both the\noperational efficiency and the innovative capacity of businesses and\norganizations. By indexing knowledge through vectorization, a variety of\nknowledge retrieval methods have emerged, significantly enhancing the efficacy\nof knowledge management systems. Recently, the rapid advancements in generative\nnatural language processing technologies paved the way for generating precise\nand coherent answers after retrieving relevant documents tailored to user\nqueries. However, for enterprise knowledge bases, assembling extensive training\ndata from scratch for knowledge retrieval and generation is a formidable\nchallenge due to the privacy and security policies of private data, frequently\nentailing substantial costs. To address the challenge above, in this paper, we\npropose EKRG, a novel Retrieval-Generation framework based on large language\nmodels (LLMs), expertly designed to enable question-answering for Enterprise\nKnowledge bases with limited annotation costs. Specifically, for the retrieval\nprocess, we first introduce an instruction-tuning method using an LLM to\ngenerate sufficient document-question pairs for training a knowledge retriever.\nThis method, through carefully designed instructions, efficiently generates\ndiverse questions for enterprise knowledge bases, encompassing both\nfact-oriented and solution-oriented knowledge. Additionally, we develop a\nrelevance-aware teacher-student learning strategy to further enhance the\nefficiency of the training process. For the generation process, we propose a\nnovel chain of thought (CoT) based fine-tuning method to empower the LLM-based\ngenerator to adeptly respond to user questions using retrieved documents.\nFinally, extensive experiments on real-world datasets have demonstrated the\neffectiveness of our proposed framework.",
      "tldr_zh": "这篇论文提出 EKRG 框架，利用 Large Language Models (LLMs) 提升企业知识库的问答能力，解决隐私和安全政策导致的训练数据不足问题。框架包括检索过程，通过 instruction-tuning 方法生成多样化的 document-question pairs（涵盖 fact-oriented 和 solution-oriented 知识），并采用 relevance-aware teacher-student learning 策略优化训练效率。在生成过程中，论文引入 chain of thought (CoT) based fine-tuning 方法，使 LLM 基于检索文档生成精确的回答。实验在真实数据集上验证了 EKRG 的有效性，显著降低了标注成本并提高了系统性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "DASFAA 2024 Accepted",
      "pdf_url": "http://arxiv.org/pdf/2404.08695v2",
      "published_date": "2024-04-10 10:38:17 UTC",
      "updated_date": "2024-04-20 05:29:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:20:16.071788"
    },
    {
      "arxiv_id": "2404.06883v2",
      "title": "Research on Detection of Floating Objects in River and Lake Based on AI Intelligent Image Recognition",
      "title_zh": "基于 AI 智能图像识别的河流和湖泊漂浮物体检测研究",
      "authors": [
        "Jingyu Zhang",
        "Ao Xiang",
        "Yu Cheng",
        "Qin Yang",
        "Liyang Wang"
      ],
      "abstract": "With the rapid advancement of artificial intelligence technology, AI-enabled\nimage recognition has emerged as a potent tool for addressing challenges in\ntraditional environmental monitoring. This study focuses on the detection of\nfloating objects in river and lake environments, exploring an innovative\napproach based on deep learning. By intricately analyzing the technical\npathways for detecting static and dynamic features and considering the\ncharacteristics of river and lake debris, a comprehensive image acquisition and\nprocessing workflow has been developed. The study highlights the application\nand performance comparison of three mainstream deep learning models -SSD,\nFaster-RCNN, and YOLOv5- in debris identification. Additionally, a detection\nsystem for floating objects has been designed and implemented, encompassing\nboth hardware platform construction and software framework development. Through\nrigorous experimental validation, the proposed system has demonstrated its\nability to significantly enhance the accuracy and efficiency of debris\ndetection, thus offering a new technological avenue for water quality\nmonitoring in rivers and lakes",
      "tldr_zh": "本研究聚焦于利用人工智能图像识别技术检测河流和湖泊中漂浮物体的挑战，提出了一种基于深度学习的创新方法，包括图像获取和处理工作流。研究比较了SSD、Faster-RCNN和YOLOv5三种主流深度学习模型的表现，并设计了一个涵盖硬件平台和软件框架的完整检测系统。实验验证显示，该系统显著提升了碎片检测的准确性和效率，为河流和湖泊水质监测提供了新的技术途径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.06883v2",
      "published_date": "2024-04-10 10:13:37 UTC",
      "updated_date": "2024-04-19 06:07:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:20:27.262986"
    },
    {
      "arxiv_id": "2406.02480v1",
      "title": "Fairness Evolution in Continual Learning for Medical Imaging",
      "title_zh": "翻译失败",
      "authors": [
        "Marina Ceccon",
        "Davide Dalle Pezze",
        "Alessandro Fabris",
        "Gian Antonio Susto"
      ],
      "abstract": "Deep Learning (DL) has made significant strides in various medical\napplications in recent years, achieving remarkable results. In the field of\nmedical imaging, DL models can assist doctors in disease diagnosis by\nclassifying pathologies in Chest X-ray images. However, training on new data to\nexpand model capabilities and adapt to distribution shifts is a notable\nchallenge these models face. Continual Learning (CL) has emerged as a solution\nto this challenge, enabling models to adapt to new data while retaining\nknowledge gained from previous experiences. Previous studies have analyzed the\nbehavior of CL strategies in medical imaging regarding classification\nperformance. However, when considering models that interact with sensitive\ninformation, such as in the medical domain, it is imperative to disaggregate\nthe performance of socially salient groups. Indeed, DL algorithms can exhibit\nbiases against certain sub-populations, leading to discrepancies in predictive\nperformance across different groups identified by sensitive attributes such as\nage, race/ethnicity, sex/gender, and socioeconomic status. In this study, we go\nbeyond the typical assessment of classification performance in CL and study\nbias evolution over successive tasks with domain-specific fairness metrics.\nSpecifically, we evaluate the CL strategies using the well-known CheXpert (CXP)\nand ChestX-ray14 (NIH) datasets. We consider a class incremental scenario of\nfive tasks with 12 pathologies. We evaluate the Replay, Learning without\nForgetting (LwF), LwF Replay, and Pseudo-Label strategies. LwF and Pseudo-Label\nexhibit optimal classification performance, but when including fairness metrics\nin the evaluation, it is clear that Pseudo-Label is less biased. For this\nreason, this strategy should be preferred when considering real-world scenarios\nin which it is crucial to consider the fairness of the model.",
      "tldr_zh": "本研究探讨了持续学习（Continual Learning, CL）在医疗成像中的公平性演变问题，强调深度学习（DL）模型在处理胸部X光图像分类时，可能对基于年龄、种族、性别等敏感属性的社会群体产生偏见。研究使用CheXpert (CXP)和ChestX-ray14 (NIH)数据集，在一个包含五任务和12个病理的类增量场景下，评估了Replay、Learning without Forgetting (LwF)、LwF Replay和Pseudo-Label等CL策略。结果显示，LwF和Pseudo-Label在分类性能上表现最佳，但Pseudo-Label在公平性指标上更优，因此更适合实际医疗应用以减少偏见。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02480v1",
      "published_date": "2024-04-10 09:48:52 UTC",
      "updated_date": "2024-04-10 09:48:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:20:41.361806"
    },
    {
      "arxiv_id": "2404.06869v1",
      "title": "SleepPPG-Net2: Deep learning generalization for sleep staging from photoplethysmography",
      "title_zh": "翻译失败",
      "authors": [
        "Shirel Attia",
        "Revital Shani Hershkovich",
        "Alissa Tabakhov",
        "Angeleene Ang",
        "Sharon Haimov",
        "Riva Tauman",
        "Joachim A. Behar"
      ],
      "abstract": "Background: Sleep staging is a fundamental component in the diagnosis of\nsleep disorders and the management of sleep health. Traditionally, this\nanalysis is conducted in clinical settings and involves a time-consuming\nscoring procedure. Recent data-driven algorithms for sleep staging, using the\nphotoplethysmogram (PPG) time series, have shown high performance on local test\nsets but lower performance on external datasets due to data drift. Methods:\nThis study aimed to develop a generalizable deep learning model for the task of\nfour class (wake, light, deep, and rapid eye movement (REM)) sleep staging from\nraw PPG physiological time-series. Six sleep datasets, totaling 2,574 patients\nrecordings, were used. In order to create a more generalizable representation,\nwe developed and evaluated a deep learning model called SleepPPG-Net2, which\nemploys a multi-source domain training approach.SleepPPG-Net2 was benchmarked\nagainst two state-of-the-art models. Results: SleepPPG-Net2 showed consistently\nhigher performance over benchmark approaches, with generalization performance\n(Cohen's kappa) improving by up to 19%. Performance disparities were observed\nin relation to age, sex, and sleep apnea severity. Conclusion: SleepPPG-Net2\nsets a new standard for staging sleep from raw PPG time-series.",
      "tldr_zh": "该研究针对睡眠分期任务开发了SleepPPG-Net2，这是一个基于深度学习的模型，使用原始photoplethysmography (PPG)时间序列来区分wake、light、deep和rapid eye movement (REM)四类睡眠阶段。模型采用多源域训练方法，基于六种数据集共2574名患者的数据，以提升泛化性能。相比两个最先进基准模型，SleepPPG-Net2在外部数据集上的Cohen's kappa值提高了多达19%，并揭示了性能与年龄、性别及睡眠呼吸暂停严重程度相关的差异。该模型为从PPG时间序列进行睡眠分期设定了新标准，有助于更可靠的睡眠健康管理。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.06869v1",
      "published_date": "2024-04-10 09:47:34 UTC",
      "updated_date": "2024-04-10 09:47:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:20:54.781721"
    },
    {
      "arxiv_id": "2404.06859v3",
      "title": "Multi-Label Continual Learning for the Medical Domain: A Novel Benchmark",
      "title_zh": "翻译失败",
      "authors": [
        "Marina Ceccon",
        "Davide Dalle Pezze",
        "Alessandro Fabris",
        "Gian Antonio Susto"
      ],
      "abstract": "Despite the critical importance of the medical domain in Deep Learning, most\nof the research in this area solely focuses on training models in static\nenvironments. It is only in recent years that research has begun to address\ndynamic environments and tackle the Catastrophic Forgetting problem through\nContinual Learning (CL) techniques. Previous studies have primarily focused on\nscenarios such as Domain Incremental Learning and Class Incremental Learning,\nwhich do not fully capture the complexity of real-world applications.\nTherefore, in this work, we propose a novel benchmark combining the challenges\nof new class arrivals and domain shifts in a single framework, by considering\nthe New Instances and New Classes (NIC) scenario. This benchmark aims to model\na realistic CL setting for the multi-label classification problem in medical\nimaging. Additionally, it encompasses a greater number of tasks compared to\npreviously tested scenarios. Specifically, our benchmark consists of two\ndatasets (NIH and CXP), nineteen classes, and seven tasks, a stream longer than\nthe previously tested ones. To solve common challenges (e.g., the task\ninference problem) found in the CIL and NIC scenarios, we propose a novel\napproach called Replay Consolidation with Label Propagation (RCLP). Our method\nsurpasses existing approaches, exhibiting superior performance with minimal\nforgetting.",
      "tldr_zh": "本文提出一个新的基准，用于医疗领域的多标签 Continual Learning (CL)，旨在模拟真实动态环境下的挑战，包括新类到达和新实例（NIC 场景），以解决 Catastrophic Forgetting 问题。该基准结合 NIH 和 CXP 两个数据集、19 个类和 7 个任务，比以往场景更复杂全面。针对 Class Incremental Learning (CIL) 和 NIC 中的常见问题，如任务推理问题，我们开发了 Replay Consolidation with Label Propagation (RCLP) 方法，该方法通过重放巩固和标签传播机制提升模型性能。实验结果显示，RCLP 超越现有方法，实现了最小遗忘和优越的分类准确率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.06859v3",
      "published_date": "2024-04-10 09:35:36 UTC",
      "updated_date": "2024-07-18 13:00:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:21:06.605245"
    },
    {
      "arxiv_id": "2404.06828v1",
      "title": "Proposed modified computational model for the amoeba-inspired combinatorial optimization machine",
      "title_zh": "翻译失败",
      "authors": [
        "Yusuke Miyajima",
        "Masahito Mochizuki"
      ],
      "abstract": "A single-celled amoeba can solve the traveling salesman problem through its\nshape-changing dynamics. In this paper, we examine roles of several elements in\na previously proposed computational model of the solution-search process of\namoeba and three modifications towards enhancing the solution-search\npreformance. We find that appropriate modifications can indeed significantly\nimprove the quality of solutions. It is also found that a condition associated\nwith the volume conservation can also be modified in contrast to the naive\nbelief that it is indispensable for the solution-search ability of amoeba. A\nproposed modified model shows much better performance.",
      "tldr_zh": "这篇论文针对变形虫（amoeba）启发的组合优化机器，提出一个修改后的计算模型，以提升其解决 traveling salesman problem 的性能。作者检查了先前模型中的几个关键元素，并进行了三个修改，包括调整体积守恒相关的条件，这些修改被证明能显著改善解决方案质量。研究发现，体积守恒条件并非像传统认知那样不可或缺，最终的修改模型展示了更好的整体性能。",
      "categories": [
        "cs.NE",
        "cond-mat.dis-nn",
        "cs.AI",
        "nlin.CD",
        "stat.CO"
      ],
      "primary_category": "cs.NE",
      "comment": "13 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.06828v1",
      "published_date": "2024-04-10 08:32:29 UTC",
      "updated_date": "2024-04-10 08:32:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:21:17.394811"
    },
    {
      "arxiv_id": "2404.07245v1",
      "title": "Generative Resident Separation and Multi-label Classification for Multi-person Activity Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Xi Chen",
        "Julien Cumin",
        "Fano Ramparany",
        "Dominique Vaufreydaz"
      ],
      "abstract": "This paper presents two models to address the problem of multi-person\nactivity recognition using ambient sensors in a home. The first model, Seq2Res,\nuses a sequence generation approach to separate sensor events from different\nresidents. The second model, BiGRU+Q2L, uses a Query2Label multi-label\nclassifier to predict multiple activities simultaneously. Performances of these\nmodels are compared to a state-of-the-art model in different experimental\nscenarios, using a state-of-the-art dataset of two residents in a home\ninstrumented with ambient sensors. These results lead to a discussion on the\nadvantages and drawbacks of resident separation and multi-label classification\nfor multi-person activity recognition.",
      "tldr_zh": "本论文提出两种模型，用于家庭环境中利用环境传感器进行多人活动识别：Seq2Res 模型采用序列生成方法来分离不同居民的传感器事件；BiGRU+Q2L 模型则使用 Query2Label 多标签分类器来同时预测多个活动。研究者将这些模型与现有最先进模型在多种实验场景中进行比较，基于一个包含两个居民的环境传感器数据集。结果显示了居民分离和多标签分类在多人活动识别中的优缺点，为该领域的改进提供了有益讨论。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "Context and Activity Modeling and Recognition (CoMoReA) Workshop at\n  IEEE International Conference on Pervasive Computing and Communications\n  (PerCom 2024), Mar 2024, Biarritz, France",
      "pdf_url": "http://arxiv.org/pdf/2404.07245v1",
      "published_date": "2024-04-10 07:46:30 UTC",
      "updated_date": "2024-04-10 07:46:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:21:30.089868"
    },
    {
      "arxiv_id": "2404.06787v2",
      "title": "Private Wasserstein Distance",
      "title_zh": "隐私瓦瑟斯坦距离",
      "authors": [
        "Wenqian Li",
        "Yan Pang"
      ],
      "abstract": "Wasserstein distance is a key metric for quantifying data divergence from a\ndistributional perspective. However, its application in privacy-sensitive\nenvironments, where direct sharing of raw data is prohibited, presents\nsignificant challenges. Existing approaches, such as Differential Privacy and\nFederated Optimization, have been employed to estimate the Wasserstein distance\nunder such constraints. However, these methods often fall short when both\naccuracy and security are required. In this study, we explore the inherent\ntriangular properties within the Wasserstein space, leading to a novel solution\nnamed TriangleWad. This approach facilitates the fast computation of the\nWasserstein distance between datasets stored across different entities,\nensuring that raw data remain completely hidden. TriangleWad not only\nstrengthens resistance to potential attacks but also preserves high estimation\naccuracy. Through extensive experiments across various tasks involving both\nimage and text data, we demonstrate its superior performance and significant\npotential for real-world applications.",
      "tldr_zh": "本研究针对Wasserstein distance在隐私敏感环境中的应用挑战，提出了一种新方法TriangleWad，利用Wasserstein空间的三角形属性，实现不同实体间的数据距离快速计算，同时确保原始数据完全隐藏。TriangleWad不仅提升了抵抗潜在攻击的安全性，还保持了高估计准确性。实验结果显示，该方法在图像和文本任务上表现出色，优于现有Differential Privacy和Federated Optimization方法，具有广泛的实际应用潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.06787v2",
      "published_date": "2024-04-10 06:58:58 UTC",
      "updated_date": "2025-02-02 07:21:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:21:41.497929"
    },
    {
      "arxiv_id": "2404.06776v1",
      "title": "Logit Calibration and Feature Contrast for Robust Federated Learning on Non-IID Data",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Qiao",
        "Chaoning Zhang",
        "Apurba Adhikary",
        "Choong Seon Hong"
      ],
      "abstract": "Federated learning (FL) is a privacy-preserving distributed framework for\ncollaborative model training on devices in edge networks. However, challenges\narise due to vulnerability to adversarial examples (AEs) and the\nnon-independent and identically distributed (non-IID) nature of data\ndistribution among devices, hindering the deployment of adversarially robust\nand accurate learning models at the edge. While adversarial training (AT) is\ncommonly acknowledged as an effective defense strategy against adversarial\nattacks in centralized training, we shed light on the adverse effects of\ndirectly applying AT in FL that can severely compromise accuracy, especially in\nnon-IID challenges. Given this limitation, this paper proposes FatCC, which\nincorporates local logit \\underline{C}alibration and global feature\n\\underline{C}ontrast into the vanilla federated adversarial training\n(\\underline{FAT}) process from both logit and feature perspectives. This\napproach can effectively enhance the federated system's robust accuracy (RA)\nand clean accuracy (CA). First, we propose logit calibration, where the logits\nare calibrated during local adversarial updates, thereby improving adversarial\nrobustness. Second, FatCC introduces feature contrast, which involves a global\nalignment term that aligns each local representation with unbiased global\nfeatures, thus further enhancing robustness and accuracy in federated\nadversarial environments. Extensive experiments across multiple datasets\ndemonstrate that FatCC achieves comparable or superior performance gains in\nboth CA and RA compared to other baselines.",
      "tldr_zh": "该论文针对Federated Learning (FL) 在非独立同分布 (non-IID) 数据上的鲁棒性挑战，指出直接应用Adversarial Training (AT) 会降低模型准确性。作者提出FatCC方法，将logit calibration融入本地对抗更新以提升对抗鲁棒性，并引入feature contrast模块，通过全局对齐项使本地表示与全局特征一致，从而改善整体性能。实验结果显示，FatCC在多个数据集上实现了干净准确率 (CA) 和鲁棒准确率 (RA) 的显著提升，优于其他基线方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.06776v1",
      "published_date": "2024-04-10 06:35:25 UTC",
      "updated_date": "2024-04-10 06:35:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:21:54.580183"
    },
    {
      "arxiv_id": "2404.06760v1",
      "title": "DiffusionDialog: A Diffusion Model for Diverse Dialog Generation with Latent Space",
      "title_zh": "DiffusionDialog：一种用于多样化对话生成的扩散模型",
      "authors": [
        "Jianxiang Xiang",
        "Zhenhua Liu",
        "Haodong Liu",
        "Yin Bai",
        "Jia Cheng",
        "Wenliang Chen"
      ],
      "abstract": "In real-life conversations, the content is diverse, and there exists the\none-to-many problem that requires diverse generation. Previous studies\nattempted to introduce discrete or Gaussian-based continuous latent variables\nto address the one-to-many problem, but the diversity is limited. Recently,\ndiffusion models have made breakthroughs in computer vision, and some attempts\nhave been made in natural language processing. In this paper, we propose\nDiffusionDialog, a novel approach to enhance the diversity of dialogue\ngeneration with the help of diffusion model. In our approach, we introduce\ncontinuous latent variables into the diffusion model. The problem of using\nlatent variables in the dialog task is how to build both an effective prior of\nthe latent space and an inferring process to obtain the proper latent given the\ncontext. By combining the encoder and latent-based diffusion model, we encode\nthe response's latent representation in a continuous space as the prior,\ninstead of fixed Gaussian distribution or simply discrete ones. We then infer\nthe latent by denoising step by step with the diffusion model. The experimental\nresults show that our model greatly enhances the diversity of dialog responses\nwhile maintaining coherence. Furthermore, in further analysis, we find that our\ndiffusion model achieves high inference efficiency, which is the main challenge\nof applying diffusion models in natural language processing.",
      "tldr_zh": "这篇论文针对对话生成的多样性问题（one-to-many problem），提出了一种名为DiffusionDialog的模型，利用diffusion model和连续latent variables来增强响应多样性。模型通过结合编码器和基于latent variables的diffusion model，将响应表示编码到连续空间作为先验，并通过逐步去噪过程推断潜在变量。实验结果表明，DiffusionDialog显著提高了对话响应的多样性，同时保持了连贯性，并实现了高效的推理过程，在自然语言处理中克服了diffusion model的常见挑战。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "LREC-COLING 2024 camera ready",
      "pdf_url": "http://arxiv.org/pdf/2404.06760v1",
      "published_date": "2024-04-10 05:56:46 UTC",
      "updated_date": "2024-04-10 05:56:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:22:06.151882"
    },
    {
      "arxiv_id": "2404.06757v1",
      "title": "Language Generation in the Limit",
      "title_zh": "翻译失败",
      "authors": [
        "Jon Kleinberg",
        "Sendhil Mullainathan"
      ],
      "abstract": "Although current large language models are complex, the most basic\nspecifications of the underlying language generation problem itself are simple\nto state: given a finite set of training samples from an unknown language,\nproduce valid new strings from the language that don't already appear in the\ntraining data. Here we ask what we can conclude about language generation using\nonly this specification, without further assumptions. In particular, suppose\nthat an adversary enumerates the strings of an unknown target language L that\nis known only to come from one of a possibly infinite list of candidates. A\ncomputational agent is trying to learn to generate from this language; we say\nthat the agent generates from L in the limit if after some finite point in the\nenumeration of L, the agent is able to produce new elements that come\nexclusively from L and that have not yet been presented by the adversary. Our\nmain result is that there is an agent that is able to generate in the limit for\nevery countable list of candidate languages. This contrasts dramatically with\nnegative results due to Gold and Angluin in a well-studied model of language\nlearning where the goal is to identify an unknown language from samples; the\ndifference between these results suggests that identifying a language is a\nfundamentally different problem than generating from it.",
      "tldr_zh": "这篇论文探讨了语言生成（Language Generation）的极限问题：给定未知语言的有限训练样本，目标是生成新的、未出现过的有效字符串，而不做额外假设。论文假设一个对手枚举未知目标语言 L，该语言来自一个可能无限的可数候选列表，并证明存在一个计算代理，能够在极限（in the limit）条件下，从 L 中产生新的独占元素。相比之下，这与 Gold 和 Angluin 在语言学习模型中关于语言识别的负面结果形成鲜明对比，表明语言生成和语言识别是本质不同的任务。",
      "categories": [
        "cs.DS",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.DS",
      "comment": "24 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.06757v1",
      "published_date": "2024-04-10 05:53:25 UTC",
      "updated_date": "2024-04-10 05:53:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:22:18.365075"
    },
    {
      "arxiv_id": "2404.06756v1",
      "title": "CrimeAlarm: Towards Intensive Intent Dynamics in Fine-grained Crime Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Kaixi Hu",
        "Lin Li",
        "Qing Xie",
        "Xiaohui Tao",
        "Guandong Xu"
      ],
      "abstract": "Granularity and accuracy are two crucial factors for crime event prediction.\nWithin fine-grained event classification, multiple criminal intents may\nalternately exhibit in preceding sequential events, and progress differently in\nnext. Such intensive intent dynamics makes training models hard to capture\nunobserved intents, and thus leads to sub-optimal generalization performance,\nespecially in the intertwining of numerous potential events. To capture\ncomprehensive criminal intents, this paper proposes a fine-grained sequential\ncrime prediction framework, CrimeAlarm, that equips with a novel mutual\ndistillation strategy inspired by curriculum learning. During the early\ntraining phase, spot-shared criminal intents are captured through\nhigh-confidence sequence samples. In the later phase, spot-specific intents are\ngradually learned by increasing the contribution of low-confidence sequences.\nMeanwhile, the output probability distributions are reciprocally learned\nbetween prediction networks to model unobserved criminal intents. Extensive\nexperiments show that CrimeAlarm outperforms state-of-the-art methods in terms\nof NDCG@5, with improvements of 4.51% for the NYC16 and 7.73% for the CHI18 in\naccuracy measures.",
      "tldr_zh": "该研究针对细粒度犯罪事件预测中的意图动态问题，提出了一种名为 CrimeAlarm 的框架，以应对多个犯罪意图在序列事件中交替出现导致的模型泛化性能下降。CrimeAlarm 采用受 curriculum learning 启发的 mutual distillation 策略，在训练早期通过高置信度序列样本捕捉共享的犯罪意图，而在后期逐步增加低置信度序列的贡献来学习特定意图，同时通过预测网络间的输出概率分布相互学习以建模未观察的犯罪意图。实验结果显示，该框架在 NDCG@5 指标上优于现有方法，在 NYC16 数据集上提升 4.51%，在 CHI18 数据集上提升 7.73%。这为提高犯罪预测的准确性和全面性提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by DASFAA 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.06756v1",
      "published_date": "2024-04-10 05:44:28 UTC",
      "updated_date": "2024-04-10 05:44:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:22:30.743893"
    },
    {
      "arxiv_id": "2404.06750v2",
      "title": "Frontier AI Ethics: Anticipating and Evaluating the Societal Impacts of Language Model Agents",
      "title_zh": "前沿 AI 伦理：预测和评估语言模型代理的社会影响",
      "authors": [
        "Seth Lazar"
      ],
      "abstract": "Some have criticised Generative AI Systems for replicating the familiar\npathologies of already widely-deployed AI systems. Other critics highlight how\nthey foreshadow vastly more powerful future systems, which might threaten\nhumanity's survival. The first group says there is nothing new here; the other\nlooks through the present to a perhaps distant horizon. In this paper, I\ninstead pay attention to what makes these particular systems distinctive: both\ntheir remarkable scientific achievement, and the most likely and consequential\nways in which they will change society over the next five to ten years. In\nparticular, I explore the potential societal impacts and normative questions\nraised by the looming prospect of 'Language Model Agents', in which multimodal\nlarge language models (LLMs) form the executive centre of complex, tool-using\nAI systems that can take unsupervised sequences of actions towards some goal.",
      "tldr_zh": "这篇论文探讨了前沿 AI 伦理，聚焦于预测和评估语言模型代理（Language Model Agents）在未来 5 到 10 年的潜在社会影响。作者强调，这些代理系统以多模态大型语言模型（LLMs）为核心，能够执行复杂、无监督的工具使用任务，既代表了显著的科学成就，也可能引发社会变革。论文分析了这些系统可能带来的规范性问题，如社会风险和伦理挑战，从而为更全面的 AI 部署提供见解。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.06750v2",
      "published_date": "2024-04-10 05:34:07 UTC",
      "updated_date": "2024-10-18 09:43:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:22:41.651849"
    },
    {
      "arxiv_id": "2405.06654v1",
      "title": "PROflow: An iterative refinement model for PROTAC-induced structure prediction",
      "title_zh": "PROflow：一种用于PROTAC诱导结构预测的迭代精炼模型",
      "authors": [
        "Bo Qiang",
        "Wenxian Shi",
        "Yuxuan Song",
        "Menghua Wu"
      ],
      "abstract": "Proteolysis targeting chimeras (PROTACs) are small molecules that trigger the\nbreakdown of traditionally ``undruggable'' proteins by binding simultaneously\nto their targets and degradation-associated proteins. A key challenge in their\nrational design is understanding their structural basis of activity. Due to the\nlack of crystal structures (18 in the PDB), existing PROTAC docking methods\nhave been forced to simplify the problem into a distance-constrained\nprotein-protein docking task. To address the data issue, we develop a novel\npseudo-data generation scheme that requires only binary protein-protein\ncomplexes. This new dataset enables PROflow, an iterative refinement model for\nPROTAC-induced structure prediction that models the full PROTAC flexibility\nduring constrained protein-protein docking. PROflow outperforms the\nstate-of-the-art across docking metrics and runtime. Its inference speed\nenables the large-scale screening of PROTAC designs, and computed properties of\npredicted structures achieve statistically significant correlations with\npublished degradation activities.",
      "tldr_zh": "该研究针对蛋白质降解嵌合体（PROTAC）设计中的结构预测挑战，提出了一种新型伪数据生成方案，仅需二元蛋白-蛋白复合物来解决晶体结构数据稀缺的问题（如PDB中仅18个结构）。PROflow模型是一个迭代精炼框架，能够在约束蛋白-蛋白对接中全面模拟PROTAC的柔性，从而提升预测准确性。实验结果显示，PROflow在对接指标和运行时上优于现有最先进方法，并支持大规模PROTAC设计筛选，其预测结构的计算属性与已发表的降解活性表现出统计显著相关性。",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.BM",
      "comment": "Published at the GEM workshop, ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.06654v1",
      "published_date": "2024-04-10 05:29:35 UTC",
      "updated_date": "2024-04-10 05:29:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:22:54.594861"
    },
    {
      "arxiv_id": "2404.06733v1",
      "title": "Incremental XAI: Memorable Understanding of AI with Incremental Explanations",
      "title_zh": "翻译失败",
      "authors": [
        "Jessica Y. Bo",
        "Pan Hao",
        "Brian Y. Lim"
      ],
      "abstract": "Many explainable AI (XAI) techniques strive for interpretability by providing\nconcise salient information, such as sparse linear factors. However, users\neither only see inaccurate global explanations, or highly-varying local\nexplanations. We propose to provide more detailed explanations by leveraging\nthe human cognitive capacity to accumulate knowledge by incrementally receiving\nmore details. Focusing on linear factor explanations (factors $\\times$ values =\noutcome), we introduce Incremental XAI to automatically partition explanations\nfor general and atypical instances by providing Base + Incremental factors to\nhelp users read and remember more faithful explanations. Memorability is\nimproved by reusing base factors and reducing the number of factors shown in\natypical cases. In modeling, formative, and summative user studies, we\nevaluated the faithfulness, memorability and understandability of Incremental\nXAI against baseline explanation methods. This work contributes towards more\nusable explanation that users can better ingrain to facilitate intuitive\nengagement with AI.",
      "tldr_zh": "本论文针对现有可解释 AI (XAI) 技术的局限性（如不准确的全局解释或变化大的局部解释），提出 Incremental XAI 方法，利用人类认知能力通过逐步提供更多细节来提升解释的准确性和记忆性。方法专注于线性因子解释（factors × values = outcome），通过自动分区为一般和异常实例提供 Base + Incremental factors，从而重用基础因素并减少异常情况下显示的因素，以帮助用户更好地阅读和记忆真实解释。在用户研究中，Incremental XAI 展示了更高的 faithfulness（忠诚度）、memorability（记忆性）和understandability（可理解性），从而促进用户与 AI 的直观互动和更易用解释。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "CHI 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.06733v1",
      "published_date": "2024-04-10 04:38:17 UTC",
      "updated_date": "2024-04-10 04:38:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:23:06.712208"
    },
    {
      "arxiv_id": "2404.06731v1",
      "title": "Accuracy of a Large Language Model in Distinguishing Anti- And Pro-vaccination Messages on Social Media: The Case of Human Papillomavirus Vaccination",
      "title_zh": "大型语言模型",
      "authors": [
        "Soojong Kim",
        "Kwanho Kim",
        "Claire Wonjeong Jo"
      ],
      "abstract": "Objective. Vaccination has engendered a spectrum of public opinions, with\nsocial media acting as a crucial platform for health-related discussions. The\nemergence of artificial intelligence technologies, such as large language\nmodels (LLMs), offers a novel opportunity to efficiently investigate public\ndiscourses. This research assesses the accuracy of ChatGPT, a widely used and\nfreely available service built upon an LLM, for sentiment analysis to discern\ndifferent stances toward Human Papillomavirus (HPV) vaccination. Methods.\nMessages related to HPV vaccination were collected from social media supporting\ndifferent message formats: Facebook (long format) and Twitter (short format). A\nselection of 1,000 human-evaluated messages was input into the LLM, which\ngenerated multiple response instances containing its classification results.\nAccuracy was measured for each message as the level of concurrence between\nhuman and machine decisions, ranging between 0 and 1. Results. Average accuracy\nwas notably high when 20 response instances were used to determine the machine\ndecision of each message: .882 (SE = .021) and .750 (SE = .029) for anti- and\npro-vaccination long-form; .773 (SE = .027) and .723 (SE = .029) for anti- and\npro-vaccination short-form, respectively. Using only three or even one instance\ndid not lead to a severe decrease in accuracy. However, for long-form messages,\nthe language model exhibited significantly lower accuracy in categorizing\npro-vaccination messages than anti-vaccination ones. Conclusions. ChatGPT shows\npotential in analyzing public opinions on HPV vaccination using social media\ncontent. However, understanding the characteristics and limitations of a\nlanguage model within specific public health contexts remains imperative.",
      "tldr_zh": "这篇论文评估了 Large Language Model（如 ChatGPT）在区分社交媒体上 HPV 疫苗反方（anti-vaccination）和正方（pro-vaccination）消息的准确性，方法包括从 Facebook 和 Twitter 收集并人工评估的 1000 条消息，并通过多个响应实例计算人类与机器决策的一致性。结果显示，使用 20 个响应实例时，准确率较高：长格式消息的反疫苗准确率为 0.882，亲疫苗为 0.750；短格式消息的反疫苗为 0.773，亲疫苗为 0.723，且减少实例数量不会显著降低准确率，但长格式中亲疫苗消息的分类准确率明显较低。研究结论是，ChatGPT 在分析公众对 HPV 疫苗的意见方面具有潜力，但需考虑其在特定公共卫生背景下的局限性，如潜在偏差。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "Forthcoming in Preventive Medicine Reports",
      "pdf_url": "http://arxiv.org/pdf/2404.06731v1",
      "published_date": "2024-04-10 04:35:54 UTC",
      "updated_date": "2024-04-10 04:35:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:23:20.994010"
    },
    {
      "arxiv_id": "2404.06717v1",
      "title": "Racial/Ethnic Categories in AI and Algorithmic Fairness: Why They Matter and What They Represent",
      "title_zh": "AI 和算法公平性中的种族/民族类别：为什么它们重要以及它们代表什么",
      "authors": [
        "Jennifer Mickel"
      ],
      "abstract": "Racial diversity has become increasingly discussed within the AI and\nalgorithmic fairness literature, yet little attention is focused on justifying\nthe choices of racial categories and understanding how people are racialized\ninto these chosen racial categories. Even less attention is given to how racial\ncategories shift and how the racialization process changes depending on the\ncontext of a dataset or model. An unclear understanding of \\textit{who}\ncomprises the racial categories chosen and \\textit{how} people are racialized\ninto these categories can lead to varying interpretations of these categories.\nThese varying interpretations can lead to harm when the understanding of racial\ncategories and the racialization process is misaligned from the actual\nracialization process and racial categories used. Harm can also arise if the\nracialization process and racial categories used are irrelevant or do not exist\nin the context they are applied.\n  In this paper, we make two contributions. First, we demonstrate how racial\ncategories with unclear assumptions and little justification can lead to\nvarying datasets that poorly represent groups obfuscated or unrepresented by\nthe given racial categories and models that perform poorly on these groups.\nSecond, we develop a framework, CIRCSheets, for documenting the choices and\nassumptions in choosing racial categories and the process of racialization into\nthese categories to facilitate transparency in understanding the processes and\nassumptions made by dataset or model developers when selecting or using these\nracial categories.",
      "tldr_zh": "该论文探讨了AI和算法公平性中种族/民族类别的使用问题，指出当前文献虽强调种族多样性，但往往忽略了这些类别的选择理由和人们被归类(racialization)过程，导致对类别的解读不一致并可能造成伤害。作者首先通过示例证明，不清晰的种族类别假设会产生代表性不足的数据集和在某些群体上表现不佳的模型。论文的主要贡献是开发了CIRCSheets框架，用于记录种族类别的选择假设和归类过程，从而提升数据集或模型开发者的透明度和责任性。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.06717v1",
      "published_date": "2024-04-10 04:04:05 UTC",
      "updated_date": "2024-04-10 04:04:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:23:32.574596"
    },
    {
      "arxiv_id": "2404.08692v1",
      "title": "Apollonion: Profile-centric Dialog Agent",
      "title_zh": "Apollonion：基于用户资料的对话代理",
      "authors": [
        "Shangyu Chen",
        "Zibo Zhao",
        "Yuanyuan Zhao",
        "Xiang Li"
      ],
      "abstract": "The emergence of Large Language Models (LLMs) has innovated the development\nof dialog agents. Specially, a well-trained LLM, as a central process unit, is\ncapable of providing fluent and reasonable response for user's request.\nBesides, auxiliary tools such as external knowledge retrieval, personalized\ncharacter for vivid response, short/long-term memory for ultra long context\nmanagement are developed, completing the usage experience for LLM-based dialog\nagents. However, the above-mentioned techniques does not solve the issue of\n\\textbf{personalization from user perspective}: agents response in a same\nfashion to different users, without consideration of their features, such as\nhabits, interests and past experience. In another words, current implementation\nof dialog agents fail in ``knowing the user''. The capacity of well-description\nand representation of user is under development. In this work, we proposed a\nframework for dialog agent to incorporate user profiling (initialization,\nupdate): user's query and response is analyzed and organized into a structural\nuser profile, which is latter served to provide personal and more precise\nresponse. Besides, we proposed a series of evaluation protocols for\npersonalization: to what extend the response is personal to the different\nusers.\n  The framework is named as \\method{}, inspired by inscription of ``Know\nYourself'' in the temple of Apollo (also known as \\method{}) in Ancient Greek.\nFew works have been conducted on incorporating personalization into LLM,\n\\method{} is a pioneer work on guiding LLM's response to meet individuation via\nthe application of dialog agents, with a set of evaluation methods for\nmeasurement in personalization.",
      "tldr_zh": "该论文指出，现有的基于 Large Language Models (LLMs) 的对话代理虽能提供流畅响应，但忽略了从用户视角的个性化问题，如用户习惯、兴趣和过去经验，导致代理对不同用户响应方式相同。作者提出 Apollonion 框架，该框架通过用户画像的初始化和更新，将用户的查询及响应分析组织成结构化的用户配置文件，从而生成更精确和个性化的响应。同时，该框架引入了一系列评估协议，以量化响应的个性化程度。作为先驱工作，Apollonion 指导 LLMs 在对话代理中实现个性化响应，并为相关研究提供测量方法。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.08692v1",
      "published_date": "2024-04-10 03:32:41 UTC",
      "updated_date": "2024-04-10 03:32:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:23:43.207245"
    },
    {
      "arxiv_id": "2404.06710v3",
      "title": "SpikeNVS: Enhancing Novel View Synthesis from Blurry Images via Spike Camera",
      "title_zh": "翻译失败",
      "authors": [
        "Gaole Dai",
        "Zhenyu Wang",
        "Qinwen Xu",
        "Ming Lu",
        "Wen Chen",
        "Boxin Shi",
        "Shanghang Zhang",
        "Tiejun Huang"
      ],
      "abstract": "One of the most critical factors in achieving sharp Novel View Synthesis\n(NVS) using neural field methods like Neural Radiance Fields (NeRF) and 3D\nGaussian Splatting (3DGS) is the quality of the training images. However,\nConventional RGB cameras are susceptible to motion blur. In contrast,\nneuromorphic cameras like event and spike cameras inherently capture more\ncomprehensive temporal information, which can provide a sharp representation of\nthe scene as additional training data. Recent methods have explored the\nintegration of event cameras to improve the quality of NVS. The event-RGB\napproaches have some limitations, such as high training costs and the inability\nto work effectively in the background. Instead, our study introduces a new\nmethod that uses the spike camera to overcome these limitations. By considering\ntexture reconstruction from spike streams as ground truth, we design the\nTexture from Spike (TfS) loss. Since the spike camera relies on temporal\nintegration instead of temporal differentiation used by event cameras, our\nproposed TfS loss maintains manageable training costs. It handles foreground\nobjects with backgrounds simultaneously. We also provide a real-world dataset\ncaptured with our spike-RGB camera system to facilitate future research\nendeavors. We conduct extensive experiments using synthetic and real-world\ndatasets to demonstrate that our design can enhance novel view synthesis across\nNeRF and 3DGS. The code and dataset will be made available for public access.",
      "tldr_zh": "本研究针对传统RGB相机易受运动模糊影响导致Novel View Synthesis (NVS)质量下降的问题，提出了一种利用Spike Camera的新方法SpikeNVS，以提升神经场方法如Neural Radiance Fields (NeRF)和3D Gaussian Splatting (3DGS)的性能。研究设计了Texture from Spike (TfS)损失函数，将Spike Camera捕获的时序信息作为ground truth，用于纹理重建，从而降低训练成本并同时处理前景和背景对象。实验在合成和真实数据集上验证了该方法的有效性，显著提高了NVS的清晰度，并提供了一个真实世界的spike-RGB数据集以支持未来研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.06710v3",
      "published_date": "2024-04-10 03:31:32 UTC",
      "updated_date": "2024-04-12 14:58:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:23:55.017809"
    },
    {
      "arxiv_id": "2404.06704v1",
      "title": "Convolution-based Probability Gradient Loss for Semantic Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Guohang Shan",
        "Shuangcheng Jia"
      ],
      "abstract": "In this paper, we introduce a novel Convolution-based Probability Gradient\n(CPG) loss for semantic segmentation. It employs convolution kernels similar to\nthe Sobel operator, capable of computing the gradient of pixel intensity in an\nimage. This enables the computation of gradients for both ground-truth and\npredicted category-wise probabilities. It enhances network performance by\nmaximizing the similarity between these two probability gradients. Moreover, to\nspecifically enhance accuracy near the object's boundary, we extract the object\nboundary based on the ground-truth probability gradient and exclusively apply\nthe CPG loss to pixels belonging to boundaries. CPG loss proves to be highly\nconvenient and effective. It establishes pixel relationships through\nconvolution, calculating errors from a distinct dimension compared to\npixel-wise loss functions such as cross-entropy loss. We conduct qualitative\nand quantitative analyses to evaluate the impact of the CPG loss on three\nwell-established networks (DeepLabv3-Resnet50, HRNetV2-OCR, and\nLRASPP_MobileNet_V3_Large) across three standard segmentation datasets\n(Cityscapes, COCO-Stuff, ADE20K). Our extensive experimental results\nconsistently and significantly demonstrate that the CPG loss enhances the mean\nIntersection over Union.",
      "tldr_zh": "本论文提出了一种新颖的损失函数——Convolution-based Probability Gradient (CPG) loss，用于提升语义分割任务的性能。该方法利用类似于 Sobel operator 的卷积核计算 ground-truth 和预测类别概率的梯度，通过最大化这些梯度的相似性来优化网络输出，并特别针对物体边界区域应用 CPG loss，以提高边界像素的准确性。与传统的像素级损失函数（如交叉熵）不同，CPG loss 通过卷积建立像素关系，从新维度计算错误。实验结果显示，在 DeepLabv3-Resnet50、HRNetV2-OCR 和 LRASPP_MobileNet_V3_Large 等网络上，以及 Cityscapes、COCO-Stuff 和 ADE20K 数据集上，CPG loss 显著提高了 mean Intersection over Union (mIoU)。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.06704v1",
      "published_date": "2024-04-10 03:20:33 UTC",
      "updated_date": "2024-04-10 03:20:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:24:07.093297"
    },
    {
      "arxiv_id": "2404.06694v2",
      "title": "How to Craft Backdoors with Unlabeled Data Alone?",
      "title_zh": "如何仅使用无标签数据构建后门？",
      "authors": [
        "Yifei Wang",
        "Wenhan Ma",
        "Stefanie Jegelka",
        "Yisen Wang"
      ],
      "abstract": "Relying only on unlabeled data, Self-supervised learning (SSL) can learn rich\nfeatures in an economical and scalable way. As the drive-horse for building\nfoundation models, SSL has received a lot of attention recently with wide\napplications, which also raises security concerns where backdoor attack is a\nmajor type of threat: if the released dataset is maliciously poisoned,\nbackdoored SSL models can behave badly when triggers are injected to test\nsamples. The goal of this work is to investigate this potential risk. We notice\nthat existing backdoors all require a considerable amount of \\emph{labeled}\ndata that may not be available for SSL. To circumvent this limitation, we\nexplore a more restrictive setting called no-label backdoors, where we only\nhave access to the unlabeled data alone, where the key challenge is how to\nselect the proper poison set without using label information. We propose two\nstrategies for poison selection: clustering-based selection using pseudolabels,\nand contrastive selection derived from the mutual information principle.\nExperiments on CIFAR-10 and ImageNet-100 show that both no-label backdoors are\neffective on many SSL methods and outperform random poisoning by a large\nmargin. Code will be available at https://github.com/PKU-ML/nlb.",
      "tldr_zh": "本研究探讨了在自监督学习(SSL)中，仅使用无标签数据创建后门攻击(no-label backdoors)的潜在风险，以填补现有攻击方法对标签数据依赖的局限。作者提出了两种投毒选择策略：基于聚类的选择，使用伪标签进行样本筛选，以及基于互信息原理的对比选择策略，以有效识别合适的投毒集。实验在CIFAR-10和ImageNet-100数据集上表明，这些方法对多种SSL模型均有效，且显著优于随机投毒策略。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ICLR 2024 Workshop on Navigating and Addressing Data\n  Problems for Foundation Models (DPFM)",
      "pdf_url": "http://arxiv.org/pdf/2404.06694v2",
      "published_date": "2024-04-10 02:54:18 UTC",
      "updated_date": "2024-04-22 21:27:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:24:17.393054"
    },
    {
      "arxiv_id": "2406.04346v1",
      "title": "Automating Patch Set Generation from Code Review Comments Using Large Language Models",
      "title_zh": "使用大型语言模型从代码审查评论中自动化生成补丁集",
      "authors": [
        "Tajmilur Rahman",
        "Rahul Singh",
        "Mir Yousuf Sultan"
      ],
      "abstract": "The advent of Large Language Models (LLMs) has revolutionized various domains\nof artificial intelligence, including the realm of software engineering. In\nthis research, we evaluate the efficacy of pre-trained LLMs in replicating the\ntasks traditionally performed by developers in response to code review\ncomments. We provide code contexts to five popular LLMs and obtain the\nsuggested code-changes (patch sets) derived from real-world code-review\ncomments. The performance of each model is meticulously assessed by comparing\ntheir generated patch sets against the historical data of human-generated\npatch-sets from the same repositories. This comparative analysis aims to\ndetermine the accuracy, relevance, and depth of the LLMs' feedback, thereby\nevaluating their readiness to support developers in responding to code-review\ncomments.\n  Novelty: This particular research area is still immature requiring a\nsubstantial amount of studies yet to be done. No prior research has compared\nthe performance of existing Large Language Models (LLMs) in code-review\ncomments. This in-progress study assesses current LLMs in code review and paves\nthe way for future advancements in automated code quality assurance, reducing\ncontext-switching overhead due to interruptions from code change requests.",
      "tldr_zh": "这篇论文评估了使用大型语言模型 (LLMs) 从代码审查评论中自动生成补丁集 (patch sets) 的效能，旨在辅助开发者完成传统任务。研究方法包括向五个流行 LLMs 提供代码上下文，从真实世界评论中生成建议代码更改，并通过与历史人类生成的补丁集进行比较，评估模型的准确性、相关性和深度。该研究首次比较现有 LLMs 在代码审查中的性能，并为未来的自动代码质量保证铺平道路，减少了开发者因代码更改请求导致的上下文切换开销。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "2 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.04346v1",
      "published_date": "2024-04-10 02:46:08 UTC",
      "updated_date": "2024-04-10 02:46:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:24:32.654195"
    },
    {
      "arxiv_id": "2404.06690v3",
      "title": "CoVoMix: Advancing Zero-Shot Speech Generation for Human-like Multi-talker Conversations",
      "title_zh": "翻译失败",
      "authors": [
        "Leying Zhang",
        "Yao Qian",
        "Long Zhou",
        "Shujie Liu",
        "Dongmei Wang",
        "Xiaofei Wang",
        "Midia Yousefi",
        "Yanmin Qian",
        "Jinyu Li",
        "Lei He",
        "Sheng Zhao",
        "Michael Zeng"
      ],
      "abstract": "Recent advancements in zero-shot text-to-speech (TTS) modeling have led to\nsignificant strides in generating high-fidelity and diverse speech. However,\ndialogue generation, along with achieving human-like naturalness in speech,\ncontinues to be a challenge. In this paper, we introduce CoVoMix:\nConversational Voice Mixture Generation, a novel model for zero-shot,\nhuman-like, multi-speaker, multi-round dialogue speech generation. CoVoMix\nfirst converts dialogue text into multiple streams of discrete tokens, with\neach token stream representing semantic information for individual talkers.\nThese token streams are then fed into a flow-matching based acoustic model to\ngenerate mixed mel-spectrograms. Finally, the speech waveforms are produced\nusing a HiFi-GAN model. Furthermore, we devise a comprehensive set of metrics\nfor measuring the effectiveness of dialogue modeling and generation. Our\nexperimental results show that CoVoMix can generate dialogues that are not only\nhuman-like in their naturalness and coherence but also involve multiple talkers\nengaging in multiple rounds of conversation. This is exemplified by instances\ngenerated in a single channel where one speaker's utterance is seamlessly mixed\nwith another's interjections or laughter, indicating the latter's role as an\nattentive listener. Audio samples are available at https://aka.ms/covomix.",
      "tldr_zh": "本文提出 CoVoMix，一种零样本（zero-shot）语音生成模型，用于实现人类化多说话者多轮对话。模型首先将对话文本转换为多个离散 token 流，每个流代表单个说话者的语义信息，然后使用基于 flow-matching 的声学模型生成混合 mel-spectrograms，最后通过 HiFi-GAN 模型合成语音波形。论文设计了全面的评估指标，实验结果表明 CoVoMix 生成的对话在自然性和连贯性上接近人类，支持多轮互动和无缝语音混合，如插话或笑声。总之，该模型为多说话者对话生成提供了显著改进，并附有音频样本。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "Neural Information Processing Systems 2024, poster",
      "pdf_url": "http://arxiv.org/pdf/2404.06690v3",
      "published_date": "2024-04-10 02:32:58 UTC",
      "updated_date": "2024-12-15 16:30:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:24:44.421767"
    },
    {
      "arxiv_id": "2406.11859v1",
      "title": "\"Sora is Incredible and Scary\": Emerging Governance Challenges of Text-to-Video Generative AI Models",
      "title_zh": "翻译失败",
      "authors": [
        "Kyrie Zhixuan Zhou",
        "Abhinav Choudhry",
        "Ece Gumusel",
        "Madelyn Rose Sanfilippo"
      ],
      "abstract": "Text-to-video generative AI models such as Sora OpenAI have the potential to\ndisrupt multiple industries. In this paper, we report a qualitative social\nmedia analysis aiming to uncover people's perceived impact of and concerns\nabout Sora's integration. We collected and analyzed comments (N=292) under\npopular posts about Sora-generated videos, comparison between Sora videos and\nMidjourney images, and artists' complaints about copyright infringement by\nGenerative AI. We found that people were most concerned about Sora's impact on\ncontent creation-related industries. Emerging governance challenges included\nthe for-profit nature of OpenAI, the blurred boundaries between real and fake\ncontent, human autonomy, data privacy, copyright issues, and environmental\nimpact. Potential regulatory solutions proposed by people included law-enforced\nlabeling of AI content and AI literacy education for the public. Based on the\nfindings, we discuss the importance of gauging people's tech perceptions early\nand propose policy recommendations to regulate Sora before its public release.",
      "tldr_zh": "这篇论文探讨了文本到视频生成AI模型（如Sora）可能对多个行业带来的影响，通过对社交媒体评论（N=292）的定性分析，揭示了人们对Sora的感知和担忧。研究发现，人们最关注Sora对内容创作行业的影响，以及治理挑战包括OpenAI的营利性、真实与假冒内容的界限模糊、人类自治、数据隐私、版权问题和环境影响。作者基于这些发现，强调早期评估公众对技术的感知，并提出政策推荐，如强制法律标签AI内容和推广AI literacy教育，以在Sora公开发布前进行有效监管。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.ET",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11859v1",
      "published_date": "2024-04-10 02:03:59 UTC",
      "updated_date": "2024-04-10 02:03:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:24:57.522167"
    },
    {
      "arxiv_id": "2404.06681v1",
      "title": "Causal Unit Selection using Tractable Arithmetic Circuits",
      "title_zh": "翻译失败",
      "authors": [
        "Haiying Huang",
        "Adnan Darwiche"
      ],
      "abstract": "The unit selection problem aims to find objects, called units, that optimize\na causal objective function which describes the objects' behavior in a causal\ncontext (e.g., selecting customers who are about to churn but would most likely\nchange their mind if encouraged). While early studies focused mainly on\nbounding a specific class of counterfactual objective functions using data,\nmore recent work allows one to find optimal units exactly by reducing the\ncausal objective to a classical objective on a meta-model, and then applying a\nvariant of the classical Variable Elimination (VE) algorithm to the meta-model\n-- assuming a fully specified causal model is available. In practice, however,\nfinding optimal units using this approach can be very expensive because the\nused VE algorithm must be exponential in the constrained treewidth of the\nmeta-model, which is larger and denser than the original model. We address this\ncomputational challenge by introducing a new approach for unit selection that\nis not necessarily limited by the constrained treewidth. This is done through\ncompiling the meta-model into a special class of tractable arithmetic circuits\nthat allows the computation of optimal units in time linear in the circuit\nsize. We finally present empirical results on random causal models that show\norder-of-magnitude speedups based on the proposed method for solving unit\nselection.",
      "tldr_zh": "单位选择问题旨在通过优化因果目标函数来选择对象（如可能改变行为的客户），但现有方法依赖于Variable Elimination (VE)算法，受限于元模型的约束树宽，导致计算效率低下。本文引入一种新方法，将元模型编译成Tractable Arithmetic Circuits，这是一种可处理的算术电路形式，允许在电路大小线性时间内精确计算最优单位。与传统方法相比，这种方法在随机因果模型上的实验显示了数量级的速度提升，为高效的因果决策提供了实用解决方案。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "stat.ME"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.06681v1",
      "published_date": "2024-04-10 02:02:34 UTC",
      "updated_date": "2024-04-10 02:02:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:25:08.593287"
    },
    {
      "arxiv_id": "2404.06679v1",
      "title": "Neural Optimizer Equation, Decay Function, and Learning Rate Schedule Joint Evolution",
      "title_zh": "神经优化器方程、衰减函数和学习率调度的联合进化",
      "authors": [
        "Brandon Morgan",
        "Dean Hougen"
      ],
      "abstract": "A major contributor to the quality of a deep learning model is the selection\nof the optimizer. We propose a new dual-joint search space in the realm of\nneural optimizer search (NOS), along with an integrity check, to automate the\nprocess of finding deep learning optimizers. Our dual-joint search space\nsimultaneously allows for the optimization of not only the update equation, but\nalso internal decay functions and learning rate schedules for optimizers. We\nsearch the space using our proposed mutation-only, particle-based genetic\nalgorithm able to be massively parallelized for our domain-specific problem. We\nevaluate our candidate optimizers on the CIFAR-10 dataset using a small\nConvNet. To assess generalization, the final optimizers were then transferred\nto large-scale image classification on CIFAR- 100 and TinyImageNet, while also\nbeing fine-tuned on Flowers102, Cars196, and Caltech101 using\nEfficientNetV2Small. We found multiple optimizers, learning rate schedules, and\nAdam variants that outperformed Adam, as well as other standard deep learning\noptimizers, across the image classification tasks.",
      "tldr_zh": "该论文提出一个新的双联合搜索空间，用于神经优化器搜索(NOS)，同时优化更新方程、内部衰减函数和学习率调度，以自动化深度学习优化器的发现。研究采用一个突变-only、基于粒子的遗传算法进行搜索，该算法支持大规模并行化，并在CIFAR-10数据集上使用小型ConvNet进行评估。实验结果显示，多个优化器、学习率调度和Adam变体在CIFAR-100、TinyImageNet以及微调EfficientNetV2Small的Flowers102、Cars196和Caltech101任务中，均优于Adam和其他标准优化器，证明了方法的泛化性能。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.06679v1",
      "published_date": "2024-04-10 02:00:24 UTC",
      "updated_date": "2024-04-10 02:00:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:25:21.683628"
    },
    {
      "arxiv_id": "2404.06674v2",
      "title": "VoiceShop: A Unified Speech-to-Speech Framework for Identity-Preserving Zero-Shot Voice Editing",
      "title_zh": "翻译失败",
      "authors": [
        "Philip Anastassiou",
        "Zhenyu Tang",
        "Kainan Peng",
        "Dongya Jia",
        "Jiaxin Li",
        "Ming Tu",
        "Yuping Wang",
        "Yuxuan Wang",
        "Mingbo Ma"
      ],
      "abstract": "We present VoiceShop, a novel speech-to-speech framework that can modify\nmultiple attributes of speech, such as age, gender, accent, and speech style,\nin a single forward pass while preserving the input speaker's timbre. Previous\nworks have been constrained to specialized models that can only edit these\nattributes individually and suffer from the following pitfalls: the magnitude\nof the conversion effect is weak, there is no zero-shot capability for\nout-of-distribution speakers, or the synthesized outputs exhibit undesirable\ntimbre leakage. Our work proposes solutions for each of these issues in a\nsimple modular framework based on a conditional diffusion backbone model with\noptional normalizing flow-based and sequence-to-sequence speaker\nattribute-editing modules, whose components can be combined or removed during\ninference to meet a wide array of tasks without additional model finetuning.\nAudio samples are available at \\url{https://voiceshopai.github.io}.",
      "tldr_zh": "该研究提出了 VoiceShop，一种统一的语音到语音框架，能够在单次前向传递中同时修改语音属性（如年龄、性别、口音和风格），同时保留输入说话者的音色（identity-preserving）。与以往模型不同，VoiceShop 通过条件扩散骨干模型（conditional diffusion backbone）结合可选的 normalizing flow-based 和 sequence-to-sequence 模块，解决了转换效果弱、无零样本（zero-shot）能力以及音色泄漏等问题。框架采用模块化设计，允许在推理时灵活组合或移除组件，而无需额外微调，从而支持广泛的语音编辑任务，并提供了音频样本以展示效果。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.06674v2",
      "published_date": "2024-04-10 01:33:08 UTC",
      "updated_date": "2024-04-11 17:52:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:25:33.642164"
    },
    {
      "arxiv_id": "2404.06668v1",
      "title": "Forecasting the Future with Future Technologies: Advancements in Large Meteorological Models",
      "title_zh": "通过未来技术预测未来：大型气象模型的进展",
      "authors": [
        "Hailong Shu",
        "Yue Wang",
        "Weiwei Song",
        "Huichuang Guo",
        "Zhen Song"
      ],
      "abstract": "The field of meteorological forecasting has undergone a significant\ntransformation with the integration of large models, especially those employing\ndeep learning techniques. This paper reviews the advancements and applications\nof these models in weather prediction, emphasizing their role in transforming\ntraditional forecasting methods. Models like FourCastNet, Pangu-Weather,\nGraphCast, ClimaX, and FengWu have made notable contributions by providing\naccurate, high-resolution forecasts, surpassing the capabilities of traditional\nNumerical Weather Prediction (NWP) models. These models utilize advanced neural\nnetwork architectures, such as Convolutional Neural Networks (CNNs), Graph\nNeural Networks (GNNs), and Transformers, to process diverse meteorological\ndata, enhancing predictive accuracy across various time scales and spatial\nresolutions. The paper addresses challenges in this domain, including data\nacquisition and computational demands, and explores future opportunities for\nmodel optimization and hardware advancements. It underscores the integration of\nartificial intelligence with conventional meteorological techniques, promising\nimproved weather prediction accuracy and a significant contribution to\naddressing climate-related challenges. This synergy positions large models as\npivotal in the evolving landscape of meteorological forecasting.",
      "tldr_zh": "这篇论文回顾了大型气象模型在天气预报领域的进展，特别是利用深度学习技术（如 CNNs、GNNs 和 Transformers）来处理多样气象数据，从而超越传统 Numerical Weather Prediction (NWP) 模型，提供更准确的高分辨率预报。模型如 FourCastNet、Pangu-Weather、GraphCast、ClimaX 和 FengWu 展示了显著贡献，提升了不同时间尺度和空间分辨率的预测性能。论文同时讨论了面临的挑战，包括数据获取和计算需求，并探索了未来机会，如模型优化和硬件进步，以推动人工智能与传统气象技术的融合，助力应对气候相关问题。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.ao-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "5 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.06668v1",
      "published_date": "2024-04-10 00:52:54 UTC",
      "updated_date": "2024-04-10 00:52:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:25:46.430778"
    },
    {
      "arxiv_id": "2404.06666v3",
      "title": "SafeGen: Mitigating Sexually Explicit Content Generation in Text-to-Image Models",
      "title_zh": "SafeGen：缓解文本到图像模型中",
      "authors": [
        "Xinfeng Li",
        "Yuchen Yang",
        "Jiangyi Deng",
        "Chen Yan",
        "Yanjiao Chen",
        "Xiaoyu Ji",
        "Wenyuan Xu"
      ],
      "abstract": "Text-to-image (T2I) models, such as Stable Diffusion, have exhibited\nremarkable performance in generating high-quality images from text descriptions\nin recent years. However, text-to-image models may be tricked into generating\nnot-safe-for-work (NSFW) content, particularly in sexually explicit scenarios.\nExisting countermeasures mostly focus on filtering inappropriate inputs and\noutputs, or suppressing improper text embeddings, which can block sexually\nexplicit content (e.g., naked) but may still be vulnerable to adversarial\nprompts -- inputs that appear innocent but are ill-intended. In this paper, we\npresent SafeGen, a framework to mitigate sexual content generation by\ntext-to-image models in a text-agnostic manner. The key idea is to eliminate\nexplicit visual representations from the model regardless of the text input. In\nthis way, the text-to-image model is resistant to adversarial prompts since\nsuch unsafe visual representations are obstructed from within. Extensive\nexperiments conducted on four datasets and large-scale user studies demonstrate\nSafeGen's effectiveness in mitigating sexually explicit content generation\nwhile preserving the high-fidelity of benign images. SafeGen outperforms eight\nstate-of-the-art baseline methods and achieves 99.4% sexual content removal\nperformance. Furthermore, our constructed benchmark of adversarial prompts\nprovides a basis for future development and evaluation of anti-NSFW-generation\nmethods.",
      "tldr_zh": "该研究针对文本到图像 (T2I) 模型（如 Stable Diffusion）可能生成不安全内容 (NSFW)，尤其是受对抗性提示 (adversarial prompts) 影响的问题，提出 SafeGen 框架。SafeGen 通过文本无关 (text-agnostic) 的方式，从模型内部消除显性视觉表示，从而防止生成性显性内容，无论输入提示如何。实验在四个数据集上进行，并通过大规模用户研究验证，SafeGen 实现了99.4%的性内容去除率，同时保持良性图像的高保真度，并优于八个最先进基线方法。该框架还构建了一个对抗性提示基准，为未来反 NSFW 生成方法的发展提供基础。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.CR"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ACM CCS 2024. Please cite this paper as \"Xinfeng Li,\n  Yuchen Yang, Jiangyi Deng, Chen Yan, Yanjiao Chen, Xiaoyu Ji, Wenyuan Xu.\n  SafeGen: Mitigating Sexually Explicit Content Generation in Text-to-Image\n  Models. In Proceedings of ACM Conference on Computer and Communications\n  Security (CCS), 2024.\"",
      "pdf_url": "http://arxiv.org/pdf/2404.06666v3",
      "published_date": "2024-04-10 00:26:08 UTC",
      "updated_date": "2024-10-17 07:28:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:25:57.627739"
    },
    {
      "arxiv_id": "2404.06664v1",
      "title": "CulturalTeaming: AI-Assisted Interactive Red-Teaming for Challenging LLMs' (Lack of) Multicultural Knowledge",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Ying Chiu",
        "Liwei Jiang",
        "Maria Antoniak",
        "Chan Young Park",
        "Shuyue Stella Li",
        "Mehar Bhatia",
        "Sahithya Ravi",
        "Yulia Tsvetkov",
        "Vered Shwartz",
        "Yejin Choi"
      ],
      "abstract": "Frontier large language models (LLMs) are developed by researchers and\npractitioners with skewed cultural backgrounds and on datasets with skewed\nsources. However, LLMs' (lack of) multicultural knowledge cannot be effectively\nassessed with current methods for developing benchmarks. Existing multicultural\nevaluations primarily rely on expensive and restricted human annotations or\npotentially outdated internet resources. Thus, they struggle to capture the\nintricacy, dynamics, and diversity of cultural norms. LLM-generated benchmarks\nare promising, yet risk propagating the same biases they are meant to measure.\nTo synergize the creativity and expert cultural knowledge of human annotators\nand the scalability and standardizability of LLM-based automation, we introduce\nCulturalTeaming, an interactive red-teaming system that leverages human-AI\ncollaboration to build truly challenging evaluation dataset for assessing the\nmulticultural knowledge of LLMs, while improving annotators' capabilities and\nexperiences. Our study reveals that CulturalTeaming's various modes of AI\nassistance support annotators in creating cultural questions, that modern LLMs\nfail at, in a gamified manner. Importantly, the increased level of AI\nassistance (e.g., LLM-generated revision hints) empowers users to create more\ndifficult questions with enhanced perceived creativity of themselves, shedding\nlight on the promises of involving heavier AI assistance in modern evaluation\ndataset creation procedures. Through a series of 1-hour workshop sessions, we\ngather CULTURALBENCH-V0.1, a compact yet high-quality evaluation dataset with\nusers' red-teaming attempts, that different families of modern LLMs perform\nwith accuracy ranging from 37.7% to 72.2%, revealing a notable gap in LLMs'\nmulticultural proficiency.",
      "tldr_zh": "该研究指出，前沿大语言模型（LLMs）由于开发团队和数据集的文化偏斜，导致多文化知识不足，而现有评估方法难以有效捕捉文化规范的复杂性。论文引入 CulturalTeaming，一种交互式红队测试系统，通过人类-AI 协作（如 LLM 生成的修订提示）来创建更具挑战性的评估数据集，帮助用户在游戏化环境中生成 LLMs 无法回答的文化问题，同时提升用户的创造力。实验结果显示，这种 AI 辅助模式能产生更难的问题，并通过收集的 CULTURALBENCH-V0.1 数据集揭示不同 LLMs 的准确率仅为 37.7% 到 72.2%，突显了 LLMs 在多文化知识方面的显著差距，并为改进评估流程提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint (under review)",
      "pdf_url": "http://arxiv.org/pdf/2404.06664v1",
      "published_date": "2024-04-10 00:25:09 UTC",
      "updated_date": "2024-04-10 00:25:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:26:09.705567"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 87,
  "processed_papers_count": 87,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-17T23:26:36.058845"
}