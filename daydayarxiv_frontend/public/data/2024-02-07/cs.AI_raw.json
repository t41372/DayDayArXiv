[
  {
    "arxiv_id": "2402.05322v1",
    "title": "Learning on Multimodal Graphs: A Survey",
    "authors": [
      "Ciyuan Peng",
      "Jiayuan He",
      "Feng Xia"
    ],
    "abstract": "Multimodal data pervades various domains, including healthcare, social media,\nand transportation, where multimodal graphs play a pivotal role. Machine\nlearning on multimodal graphs, referred to as multimodal graph learning (MGL),\nis essential for successful artificial intelligence (AI) applications. The\nburgeoning research in this field encompasses diverse graph data types and\nmodalities, learning techniques, and application scenarios. This survey paper\nconducts a comparative analysis of existing works in multimodal graph learning,\nelucidating how multimodal learning is achieved across different graph types\nand exploring the characteristics of prevalent learning techniques.\nAdditionally, we delineate significant applications of multimodal graph\nlearning and offer insights into future directions in this domain.\nConsequently, this paper serves as a foundational resource for researchers\nseeking to comprehend existing MGL techniques and their applicability across\ndiverse scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GR",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2402.05322v1",
    "published_date": "2024-02-07 23:50:00 UTC",
    "updated_date": "2024-02-07 23:50:00 UTC"
  },
  {
    "arxiv_id": "2402.05307v1",
    "title": "Three Pathways to Neurosymbolic Reinforcement Learning with Interpretable Model and Policy Networks",
    "authors": [
      "Peter Graf",
      "Patrick Emami"
    ],
    "abstract": "Neurosymbolic AI combines the interpretability, parsimony, and explicit\nreasoning of classical symbolic approaches with the statistical learning of\ndata-driven neural approaches. Models and policies that are simultaneously\ndifferentiable and interpretable may be key enablers of this marriage. This\npaper demonstrates three pathways to implementing such models and policies in a\nreal-world reinforcement learning setting. Specifically, we study a broad class\nof neural networks that build interpretable semantics directly into their\narchitecture. We reveal and highlight both the potential and the essential\ndifficulties of combining logic, simulation, and learning. One lesson is that\nlearning benefits from continuity and differentiability, but classical logic is\ndiscrete and non-differentiable. The relaxation to real-valued, differentiable\nrepresentations presents a trade-off; the more learnable, the less\ninterpretable. Another lesson is that using logic in the context of a numerical\nsimulation involves a non-trivial mapping from raw (e.g., real-valued time\nseries) simulation data to logical predicates. Some open questions this note\nexposes include: What are the limits of rule-based controllers, and how\nlearnable are they? Do the differentiable interpretable approaches discussed\nhere scale to large, complex, uncertain systems? Can we truly achieve\ninterpretability? We highlight these and other themes across the three\napproaches.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05307v1",
    "published_date": "2024-02-07 23:00:24 UTC",
    "updated_date": "2024-02-07 23:00:24 UTC"
  },
  {
    "arxiv_id": "2402.05306v2",
    "title": "Interactive Symbolic Regression through Offline Reinforcement Learning: A Co-Design Framework",
    "authors": [
      "Yuan Tian",
      "Wenqi Zhou",
      "Michele Viscione",
      "Hao Dong",
      "David Kammer",
      "Olga Fink"
    ],
    "abstract": "Symbolic Regression (SR) holds great potential for uncovering underlying\nmathematical and physical relationships from observed data. However, the vast\ncombinatorial space of possible expressions poses significant challenges for\nboth online search methods and pre-trained transformer models. Additionally,\ncurrent state-of-the-art approaches typically do not consider the integration\nof domain experts' prior knowledge and do not support iterative interactions\nwith the model during the equation discovery process. To address these\nchallenges, we propose the Symbolic Q-network (Sym-Q), an advanced interactive\nframework for large-scale symbolic regression. Unlike previous large-scale\ntransformer-based SR approaches, Sym-Q leverages reinforcement learning without\nrelying on a transformer-based decoder. This formulation allows the agent to\nlearn through offline reinforcement learning using any type of tree encoder,\nenabling more efficient training and inference. Furthermore, we propose a\nco-design mechanism, where the reinforcement learning-based Sym-Q facilitates\neffective interaction with domain experts at any stage of the equation\ndiscovery process. Users can dynamically modify generated nodes of the\nexpression, collaborating with the agent to tailor the mathematical expression\nto best fit the problem and align with the assumed physical laws, particularly\nwhen there is prior partial knowledge of the expected behavior. Our experiments\ndemonstrate that the pre-trained Sym-Q surpasses existing SR algorithms on the\nchallenging SSDNC benchmark. Moreover, we experimentally show on real-world\ncases that its performance can be further enhanced by the interactive co-design\nmechanism, with Sym-Q achieving greater performance gains than other\nstate-of-the-art models. Our reproducible code is available at\nhttps://github.com/EPFL-IMOS/Sym-Q.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05306v2",
    "published_date": "2024-02-07 22:53:54 UTC",
    "updated_date": "2025-02-13 00:29:05 UTC"
  },
  {
    "arxiv_id": "2402.16876v1",
    "title": "Advanced Academic Team Worker Recommendation Models",
    "authors": [
      "Mi Wu"
    ],
    "abstract": "Collaborator recommendation is an important task in academic domain. Most of\nthe existing approaches have the assumption that the recommendation system only\nneed to recommend a specific researcher for the task. However, academic\nsuccesses can be owed to productive collaboration of a whole academic team. In\nthis work, we propose a new task: academic team worker recommendation: with a\ngiven status: student, assistant professor or prime professor, research\ninterests and specific task, we can recommend an academic team formed as (prime\nprofessor, assistant professor, student). For this task, we propose a model\nCQBG-R(Citation-Query Blended Graph-Ranking). The key ideas is to combine the\ncontext of the query and the papers with the graph topology to form a new\ngraph(CQBG), which can target at the research interests and the specific\nresearch task for this time. The experiment results show the effectiveness of\nthe proposed method.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.16876v1",
    "published_date": "2024-02-07 22:37:18 UTC",
    "updated_date": "2024-02-07 22:37:18 UTC"
  },
  {
    "arxiv_id": "2402.05301v2",
    "title": "BIKED++: A Multimodal Dataset of 1.4 Million Bicycle Image and Parametric CAD Designs",
    "authors": [
      "Lyle Regenwetter",
      "Yazan Abu Obaideh",
      "Amin Heyrani Nobari",
      "Faez Ahmed"
    ],
    "abstract": "This paper introduces a public dataset of 1.4 million procedurally-generated\nbicycle designs represented parametrically, as JSON files, and as rasterized\nimages. The dataset is created through the use of a rendering engine which\nharnesses the BikeCAD software to generate vector graphics from parametric\ndesigns. This rendering engine is discussed in the paper and also released\npublicly alongside the dataset. Though this dataset has numerous applications,\na principal motivation is the need to train cross-modal predictive models\nbetween parametric and image-based design representations. For example, we\ndemonstrate that a predictive model can be trained to accurately estimate\nContrastive Language-Image Pretraining (CLIP) embeddings from a parametric\nrepresentation directly. This allows similarity relations to be established\nbetween parametric bicycle designs and text strings or reference images.\nTrained predictive models are also made public. The dataset joins the BIKED\ndataset family which includes thousands of mixed-representation human-designed\nbicycle models and several datasets quantifying design performance. The code\nand dataset can be found at:\nhttps://github.com/Lyleregenwetter/BIKED_multimodal/tree/main",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05301v2",
    "published_date": "2024-02-07 22:37:16 UTC",
    "updated_date": "2024-02-09 21:26:40 UTC"
  },
  {
    "arxiv_id": "2402.05979v1",
    "title": "On the Standardization of Behavioral Use Clauses and Their Adoption for Responsible Licensing of AI",
    "authors": [
      "Daniel McDuff",
      "Tim Korjakow",
      "Scott Cambo",
      "Jesse Josua Benjamin",
      "Jenny Lee",
      "Yacine Jernite",
      "Carlos Muñoz Ferrandis",
      "Aaron Gokaslan",
      "Alek Tarkowski",
      "Joseph Lindley",
      "A. Feder Cooper",
      "Danish Contractor"
    ],
    "abstract": "Growing concerns over negligent or malicious uses of AI have increased the\nappetite for tools that help manage the risks of the technology. In 2018,\nlicenses with behaviorial-use clauses (commonly referred to as Responsible AI\nLicenses) were proposed to give developers a framework for releasing AI assets\nwhile specifying their users to mitigate negative applications. As of the end\nof 2023, on the order of 40,000 software and model repositories have adopted\nresponsible AI licenses licenses. Notable models licensed with behavioral use\nclauses include BLOOM (language) and LLaMA2 (language), Stable Diffusion\n(image), and GRID (robotics). This paper explores why and how these licenses\nhave been adopted, and why and how they have been adapted to fit particular use\ncases. We use a mixed-methods methodology of qualitative interviews, clustering\nof license clauses, and quantitative analysis of license adoption. Based on\nthis evidence we take the position that responsible AI licenses need\nstandardization to avoid confusing users or diluting their impact. At the same\ntime, customization of behavioral restrictions is also appropriate in some\ncontexts (e.g., medical domains). We advocate for ``standardized\ncustomization'' that can meet users' needs and can be supported via tooling.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05979v1",
    "published_date": "2024-02-07 22:29:42 UTC",
    "updated_date": "2024-02-07 22:29:42 UTC"
  },
  {
    "arxiv_id": "2402.05978v1",
    "title": "Combining shape and contour features to improve tool wear monitoring in milling processes",
    "authors": [
      "M. T. García-Ordás",
      "E. Alegre-Gutiérrez",
      "V. González-Castro",
      "R. Alaiz-Rodríguez"
    ],
    "abstract": "In this paper, a new system based on combinations of a shape descriptor and a\ncontour descriptor has been proposed for classifying inserts in milling\nprocesses according to their wear level following a computer vision based\napproach. To describe the wear region shape we have proposed a new descriptor\ncalled ShapeFeat and its contour has been characterized using the method\nBORCHIZ that, to the best of our knowledge, achieves the best performance for\ntool wear monitoring following a computer vision-based approach. Results show\nthat the combination of BORCHIZ with ShapeFeat using a late fusion method\nimproves the classification performance significantly, obtaining an accuracy of\n91.44% in the binary classification (i.e. the classification of the wear as\nhigh or low) and 82.90% using three target classes (i.e. classification of the\nwear as high, medium or low). These results outperform the ones obtained by\nboth descriptors used on their own, which achieve accuracies of 88.70 and\n80.67% for two and three classes, respectively, using ShapeFeat and 87.06 and\n80.24% with B-ORCHIZ. This study yielded encouraging results for the\nmanufacturing community in order to classify automatically the inserts in terms\nof their wear for milling processes.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05978v1",
    "published_date": "2024-02-07 22:27:16 UTC",
    "updated_date": "2024-02-07 22:27:16 UTC"
  },
  {
    "arxiv_id": "2402.05977v1",
    "title": "Tool wear monitoring using an online, automatic and low cost system based on local texture",
    "authors": [
      "M. T. García-Ordás",
      "E. Alegre-Gutiérrez",
      "R. Alaiz-Rodríguez",
      "V. González-Castro"
    ],
    "abstract": "In this work we propose a new online, low cost and fast approach based on\ncomputer vision and machine learning to determine whether cutting tools used in\nedge profile milling processes are serviceable or disposable based on their\nwear level. We created a new dataset of 254 images of edge profile cutting\nheads which is, to the best of our knowledge, the first publicly available\ndataset with enough quality for this purpose. All the inserts were segmented\nand their cutting edges were cropped, obtaining 577 images of cutting edges:\n301 functional and 276 disposable. The proposed method is based on (1) dividing\nthe cutting edge image in different regions, called Wear Patches (WP), (2)\ncharacterising each one as worn or serviceable using texture descriptors based\non different variants of Local Binary Patterns (LBP) and (3) determine, based\non the state of these WP, if the cutting edge (and, therefore, the tool) is\nserviceable or disposable. We proposed and assessed five different patch\ndivision configurations. The individual WP were classified by a Support Vector\nMachine (SVM) with an intersection kernel. The best patch division\nconfiguration and texture descriptor for the WP achieves an accuracy of 90.26%\nin the detection of the disposable cutting edges. These results show a very\npromising opportunity for automatic wear monitoring in edge profile milling\nprocesses.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05977v1",
    "published_date": "2024-02-07 22:25:54 UTC",
    "updated_date": "2024-02-07 22:25:54 UTC"
  },
  {
    "arxiv_id": "2402.05976v1",
    "title": "RankSum An unsupervised extractive text summarization based on rank fusion",
    "authors": [
      "A. Joshi",
      "E. Fidalgo",
      "E. Alegre",
      "R. Alaiz-Rodriguez"
    ],
    "abstract": "In this paper, we propose Ranksum, an approach for extractive text\nsummarization of single documents based on the rank fusion of four\nmulti-dimensional sentence features extracted for each sentence: topic\ninformation, semantic content, significant keywords, and position. The Ranksum\nobtains the sentence saliency rankings corresponding to each feature in an\nunsupervised way followed by the weighted fusion of the four scores to rank the\nsentences according to their significance. The scores are generated in\ncompletely unsupervised way, and a labeled document set is required to learn\nthe fusion weights. Since we found that the fusion weights can generalize to\nother datasets, we consider the Ranksum as an unsupervised approach. To\ndetermine topic rank, we employ probabilistic topic models whereas semantic\ninformation is captured using sentence embeddings. To derive rankings using\nsentence embeddings, we utilize Siamese networks to produce abstractive\nsentence representation and then we formulate a novel strategy to arrange them\nin their order of importance. A graph-based strategy is applied to find the\nsignificant keywords and related sentence rankings in the document. We also\nformulate a sentence novelty measure based on bigrams, trigrams, and sentence\nembeddings to eliminate redundant sentences from the summary. The ranks of all\nthe sentences computed for each feature are finally fused to get the final\nscore for each sentence in the document. We evaluate our approach on publicly\navailable summarization datasets CNN/DailyMail and DUC 2002. Experimental\nresults show that our approach outperforms other existing state-of-the-art\nsummarization methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05976v1",
    "published_date": "2024-02-07 22:24:09 UTC",
    "updated_date": "2024-02-07 22:24:09 UTC"
  },
  {
    "arxiv_id": "2402.05296v1",
    "title": "Classifying spam emails using agglomerative hierarchical clustering and a topic-based approach",
    "authors": [
      "F. Janez-Martino",
      "R. Alaiz-Rodriguez",
      "V. Gonzalez-Castro",
      "E. Fidalgo",
      "E. Alegre"
    ],
    "abstract": "Spam emails are unsolicited, annoying and sometimes harmful messages which\nmay contain malware, phishing or hoaxes. Unlike most studies that address the\ndesign of efficient anti-spam filters, we approach the spam email problem from\na different and novel perspective. Focusing on the needs of cybersecurity\nunits, we follow a topic-based approach for addressing the classification of\nspam email into multiple categories. We propose SPEMC-15K-E and SPEMC-15K-S,\ntwo novel datasets with approximately 15K emails each in English and Spanish,\nrespectively, and we label them using agglomerative hierarchical clustering\ninto 11 classes. We evaluate 16 pipelines, combining four text representation\ntechniques -Term Frequency-Inverse Document Frequency (TF-IDF), Bag of Words,\nWord2Vec and BERT- and four classifiers: Support Vector Machine, N\\\"aive Bayes,\nRandom Forest and Logistic Regression. Experimental results show that the\nhighest performance is achieved with TF-IDF and LR for the English dataset,\nwith a F1 score of 0.953 and an accuracy of 94.6%, and while for the Spanish\ndataset, TF-IDF with NB yields a F1 score of 0.945 and 98.5% accuracy.\nRegarding the processing time, TF-IDF with LR leads to the fastest\nclassification, processing an English and Spanish spam email in and on average,\nrespectively.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05296v1",
    "published_date": "2024-02-07 22:19:08 UTC",
    "updated_date": "2024-02-07 22:19:08 UTC"
  },
  {
    "arxiv_id": "2402.05295v1",
    "title": "An information theoretic approach to quantify the stability of feature selection and ranking algorithms",
    "authors": [
      "Alaiz-Rodriguez",
      "R.",
      "Parnell",
      "A. C"
    ],
    "abstract": "Feature selection is a key step when dealing with high dimensional data. In\nparticular, these techniques simplify the process of knowledge discovery from\nthe data by selecting the most relevant features out of the noisy, redundant\nand irrelevant features. A problem that arises in many of these practical\napplications is that the outcome of the feature selection algorithm is not\nstable. Thus, small variations in the data may yield very different feature\nrankings. Assessing the stability of these methods becomes an important issue\nin the previously mentioned situations. We propose an information theoretic\napproach based on the Jensen Shannon divergence to quantify this robustness.\nUnlike other stability measures, this metric is suitable for different\nalgorithm outcomes: full ranked lists, feature subsets as well as the lesser\nstudied partial ranked lists. This generalized metric quantifies the difference\namong a whole set of lists with the same size, following a probabilistic\napproach and being able to give more importance to the disagreements that\nappear at the top of the list. Moreover, it possesses desirable properties\nincluding correction for change, upper lower bounds and conditions for a\ndeterministic selection. We illustrate the use of this stability metric with\ndata generated in a fully controlled way and compare it with popular metrics\nincluding the Spearmans rank correlation and the Kunchevas index on feature\nranking and selection outcomes, respectively. Additionally, experimental\nvalidation of the proposed approach is carried out on a real-world problem of\nfood quality assessment showing its potential to quantify stability from\ndifferent perspectives.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05295v1",
    "published_date": "2024-02-07 22:17:37 UTC",
    "updated_date": "2024-02-07 22:17:37 UTC"
  },
  {
    "arxiv_id": "2402.05294v1",
    "title": "Examining Modality Incongruity in Multimodal Federated Learning for Medical Vision and Language-based Disease Detection",
    "authors": [
      "Pramit Saha",
      "Divyanshu Mishra",
      "Felix Wagner",
      "Konstantinos Kamnitsas",
      "J. Alison Noble"
    ],
    "abstract": "Multimodal Federated Learning (MMFL) utilizes multiple modalities in each\nclient to build a more powerful Federated Learning (FL) model than its unimodal\ncounterpart. However, the impact of missing modality in different clients, also\ncalled modality incongruity, has been greatly overlooked. This paper, for the\nfirst time, analyses the impact of modality incongruity and reveals its\nconnection with data heterogeneity across participating clients. We\nparticularly inspect whether incongruent MMFL with unimodal and multimodal\nclients is more beneficial than unimodal FL. Furthermore, we examine three\npotential routes of addressing this issue. Firstly, we study the effectiveness\nof various self-attention mechanisms towards incongruity-agnostic information\nfusion in MMFL. Secondly, we introduce a modality imputation network (MIN)\npre-trained in a multimodal client for modality translation in unimodal clients\nand investigate its potential towards mitigating the missing modality problem.\nThirdly, we assess the capability of client-level and server-level\nregularization techniques towards mitigating modality incongruity effects.\nExperiments are conducted under several MMFL settings on two publicly available\nreal-world datasets, MIMIC-CXR and Open-I, with Chest X-Ray and radiology\nreports.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "42 pages",
    "pdf_url": "http://arxiv.org/pdf/2402.05294v1",
    "published_date": "2024-02-07 22:16:53 UTC",
    "updated_date": "2024-02-07 22:16:53 UTC"
  },
  {
    "arxiv_id": "2402.16886v2",
    "title": "Using text embedding models as text classifiers with medical data",
    "authors": [
      "Rishabh Goel"
    ],
    "abstract": "The advent of Large Language Models (LLMs) is promising and LLMs have been\napplied to numerous fields. However, it is not trivial to implement LLMs in the\nmedical field, due to the high standards for precision and accuracy. Currently,\nthe diagnosis of medical ailments must be done by hand, as it is costly to\nbuild a sufficiently broad LLM that can diagnose a wide range of diseases.\nHere, we explore the use of vector databases and embedding models as a means of\nencoding and classifying text with medical text data without the need to train\na new model altogether. We used various LLMs to generate the medical data, then\nencoded the data with a text embedding model and stored it in a vector\ndatabase. We hypothesized that higher embedding dimensions coupled with\ndescriptive data in the vector database would lead to better classifications\nand designed a robustness test to test our hypothesis. By using vector\ndatabases and text embedding models to classify a clinician's notes on a\npatient presenting with a certain ailment, we showed that these tools can be\nsuccessful at classifying medical text data. We found that a higher embedding\ndimension did indeed yield better results, however, querying with simple data\nin the database was optimal for performance. We have shown in this study the\napplicability of text embedding models and vector databases on a small scale,\nand our work lays the groundwork for applying these tools on a larger scale.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG",
      "I.2.7; J.3"
    ],
    "primary_category": "cs.IR",
    "comment": "15 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.16886v2",
    "published_date": "2024-02-07 22:15:15 UTC",
    "updated_date": "2024-12-02 21:35:55 UTC"
  },
  {
    "arxiv_id": "2402.05293v1",
    "title": "A comparative study on feature selection for a risk prediction model for colorectal cancer",
    "authors": [
      "N. Cueto-López",
      "M. T. García-Ordás",
      "V. Dávila-Batista",
      "V. Moreno",
      "N. Aragonés",
      "R. Alaiz-Rodríguez"
    ],
    "abstract": "Background and objective\n  Risk prediction models aim at identifying people at higher risk of developing\na target disease. Feature selection is particularly important to improve the\nprediction model performance avoiding overfitting and to identify the leading\ncancer risk (and protective) factors. Assessing the stability of feature\nselection/ranking algorithms becomes an important issue when the aim is to\nanalyze the features with more prediction power. Methods\n  This work is focused on colorectal cancer, assessing several feature ranking\nalgorithms in terms of performance for a set of risk prediction models (Neural\nNetworks, Support Vector Machines (SVM), Logistic Regression, k-Nearest\nNeighbors and Boosted Trees). Additionally, their robustness is evaluated\nfollowing a conventional approach with scalar stability metrics and a visual\napproach proposed in this work to study both similarity among feature ranking\ntechniques as well as their individual stability. A comparative analysis is\ncarried out between the most relevant features found out in this study and\nfeatures provided by the experts according to the state-of-the-art knowledge.\nResults\n  The two best performance results in terms of Area Under the ROC Curve (AUC)\nare achieved with a SVM classifier using the top-41 features selected by the\nSVM wrapper approach (AUC=0.693) and Logistic Regression with the top-40\nfeatures selected by the Pearson (AUC=0.689). Experiments showed that\nperforming feature selection contributes to classification performance with a\n3.9% and 1.9% improvement in AUC for the SVM and Logistic Regression\nclassifier, respectively, with respect to the results using the full feature\nset. The visual approach proposed in this work allows to see that the Neural\nNetwork-based wrapper ranking is the most unstable while the Random Forest is\nthe most stable.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05293v1",
    "published_date": "2024-02-07 22:14:14 UTC",
    "updated_date": "2024-02-07 22:14:14 UTC"
  },
  {
    "arxiv_id": "2402.05290v2",
    "title": "Do Transformer World Models Give Better Policy Gradients?",
    "authors": [
      "Michel Ma",
      "Tianwei Ni",
      "Clement Gehring",
      "Pierluca D'Oro",
      "Pierre-Luc Bacon"
    ],
    "abstract": "A natural approach for reinforcement learning is to predict future rewards by\nunrolling a neural network world model, and to backpropagate through the\nresulting computational graph to learn a policy. However, this method often\nbecomes impractical for long horizons since typical world models induce\nhard-to-optimize loss landscapes. Transformers are known to efficiently\npropagate gradients over long horizons: could they be the solution to this\nproblem? Surprisingly, we show that commonly-used transformer world models\nproduce circuitous gradient paths, which can be detrimental to long-range\npolicy gradients. To tackle this challenge, we propose a class of world models\ncalled Actions World Models (AWMs), designed to provide more direct routes for\ngradient propagation. We integrate such AWMs into a policy gradient framework\nthat underscores the relationship between network architectures and the policy\ngradient updates they inherently represent. We demonstrate that AWMs can\ngenerate optimization landscapes that are easier to navigate even when compared\nto those from the simulator itself. This property allows transformer AWMs to\nproduce better policies than competitive baselines in realistic long-horizon\ntasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Michel Ma and Pierluca D'Oro contributed equally",
    "pdf_url": "http://arxiv.org/pdf/2402.05290v2",
    "published_date": "2024-02-07 22:09:46 UTC",
    "updated_date": "2024-02-11 00:50:25 UTC"
  },
  {
    "arxiv_id": "2402.05271v4",
    "title": "Feature learning as alignment: a structural property of gradient descent in non-linear neural networks",
    "authors": [
      "Daniel Beaglehole",
      "Ioannis Mitliagkas",
      "Atish Agarwala"
    ],
    "abstract": "Understanding the mechanisms through which neural networks extract statistics\nfrom input-label pairs through feature learning is one of the most important\nunsolved problems in supervised learning. Prior works demonstrated that the\ngram matrices of the weights (the neural feature matrices, NFM) and the average\ngradient outer products (AGOP) become correlated during training, in a\nstatement known as the neural feature ansatz (NFA). Through the NFA, the\nauthors introduce mapping with the AGOP as a general mechanism for neural\nfeature learning. However, these works do not provide a theoretical explanation\nfor this correlation or its origins. In this work, we further clarify the\nnature of this correlation, and explain its emergence. We show that this\ncorrelation is equivalent to alignment between the left singular structure of\nthe weight matrices and the newly defined pre-activation tangent features at\neach layer. We further establish that the alignment is driven by the\ninteraction of weight changes induced by SGD with the pre-activation features,\nand analyze the resulting dynamics analytically at early times in terms of\nsimple statistics of the inputs and labels. We prove the derivative alignment\noccurs almost surely in specific high dimensional settings. Finally, we\nintroduce a simple optimization rule motivated by our analysis of the centered\ncorrelation which dramatically increases the NFA correlations at any given\nlayer and improves the quality of features learned.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05271v4",
    "published_date": "2024-02-07 21:31:53 UTC",
    "updated_date": "2024-11-17 22:18:40 UTC"
  },
  {
    "arxiv_id": "2403.08810v1",
    "title": "Comparison of edge computing methods in Internet of Things architectures for efficient estimation of indoor environmental parameters with Machine Learning",
    "authors": [
      "Jose-Carlos Gamazo-Real",
      "Raul Torres Fernandez",
      "Adrian Murillo Armas"
    ],
    "abstract": "The large increase in the number of Internet of Things (IoT) devices have\nrevolutionised the way data is processed, which added to the current trend from\ncloud to edge computing has resulted in the need for efficient and reliable\ndata processing near the data sources using energy-efficient devices. Two\nmethods based on low-cost edge-IoT architectures are proposed to implement\nlightweight Machine Learning (ML) models that estimate indoor environmental\nquality (IEQ) parameters, such as Artificial Neural Networks of Multilayer\nPerceptron type. Their implementation is based on centralised and distributed\nparallel IoT architectures, connected via wireless, which share commercial\noff-the-self modules for data acquisition and sensing, such as sensors for\ntemperature, humidity, illuminance, CO2, and other gases. The centralised\nmethod uses a Graphics Processing Unit and the Message Queuing Telemetry\nTransport protocol, but the distributed method utilises low performance\nARM-based devices and the Message Passing Interface protocol. Although multiple\nIEQ parameters are measured, the training and testing of ML models is\naccomplished with experiments focused on small temperature and illuminance\ndatasets to reduce data processing load, obtained from sudden spikes, square\nprofiles and sawteeth test cases. The results show a high estimation\nperformance with F-score and Accuracy values close to 0.95, and an almost\ntheorical Speedup with a reduction in power consumption close to 37% in the\ndistributed parallel approach. In addition, similar or slightly better\nperformance is achieved compared to equivalent IoT architectures from related\nresearch, but error reduction of 35 to 76% is accomplished with an adequate\nbalance between performance and energy efficiency.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.AR",
      "cs.DC",
      "cs.IT",
      "cs.LG",
      "math.IT"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08810v1",
    "published_date": "2024-02-07 21:15:18 UTC",
    "updated_date": "2024-02-07 21:15:18 UTC"
  },
  {
    "arxiv_id": "2402.07938v2",
    "title": "Large Language User Interfaces: Voice Interactive User Interfaces powered by LLMs",
    "authors": [
      "Syed Mekael Wasti",
      "Ken Q. Pu",
      "Ali Neshati"
    ],
    "abstract": "The evolution of Large Language Models (LLMs) has showcased remarkable\ncapacities for logical reasoning and natural language comprehension. These\ncapabilities can be leveraged in solutions that semantically and textually\nmodel complex problems. In this paper, we present our efforts toward\nconstructing a framework that can serve as an intermediary between a user and\ntheir user interface (UI), enabling dynamic and real-time interactions. We\nemploy a system that stands upon textual semantic mappings of UI components, in\nthe form of annotations. These mappings are stored, parsed, and scaled in a\ncustom data structure, supplementary to an agent-based prompting backend\nengine. Employing textual semantic mappings allows each component to not only\nexplain its role to the engine but also provide expectations. By comprehending\nthe needs of both the user and the components, our LLM engine can classify the\nmost appropriate application, extract relevant parameters, and subsequently\nexecute precise predictions of the user's expected actions. Such an integration\nevolves static user interfaces into highly dynamic and adaptable solutions,\nintroducing a new frontier of intelligent and responsive user experiences.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "I.2.7; I.2.1"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted as peer-reviewed publication",
    "pdf_url": "http://arxiv.org/pdf/2402.07938v2",
    "published_date": "2024-02-07 21:08:49 UTC",
    "updated_date": "2024-04-16 07:39:05 UTC"
  },
  {
    "arxiv_id": "2402.05252v1",
    "title": "Learning Fair Ranking Policies via Differentiable Optimization of Ordered Weighted Averages",
    "authors": [
      "My H. Dinh",
      "James Kotary",
      "Ferdinando Fioretto"
    ],
    "abstract": "Learning to Rank (LTR) is one of the most widely used machine learning\napplications. It is a key component in platforms with profound societal\nimpacts, including job search, healthcare information retrieval, and social\nmedia content feeds. Conventional LTR models have been shown to produce biases\nresults, stimulating a discourse on how to address the disparities introduced\nby ranking systems that solely prioritize user relevance. However, while\nseveral models of fair learning to rank have been proposed, they suffer from\ndeficiencies either in accuracy or efficiency, thus limiting their\napplicability to real-world ranking platforms. This paper shows how\nefficiently-solvable fair ranking models, based on the optimization of Ordered\nWeighted Average (OWA) functions, can be integrated into the training loop of\nan LTR model to achieve favorable balances between fairness, user utility, and\nruntime efficiency. In particular, this paper is the first to show how to\nbackpropagate through constrained optimizations of OWA objectives, enabling\ntheir use in integrated prediction and decision models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05252v1",
    "published_date": "2024-02-07 20:53:53 UTC",
    "updated_date": "2024-02-07 20:53:53 UTC"
  },
  {
    "arxiv_id": "2403.12061v2",
    "title": "Design-Space Exploration of SNN Models using Application-Specific Multi-Core Architectures",
    "authors": [
      "Sanaullah",
      "Shamini Koravuna",
      "Ulrich Rückert",
      "Thorsten Jungeblut"
    ],
    "abstract": "With the motivation and the difficulties that currently exist in\ncomprehending and utilizing the promising features of SNNs, we proposed a novel\nrun-time multi-core architecture-based simulator called \"RAVSim\" (Runtime\nAnalysis and Visualization Simulator), a cutting-edge SNN simulator, developed\nusing LabVIEW and it is publicly available on their website as an official\nmodule. RAVSim is a runtime virtual simulation environment tool that enables\nthe user to interact with the model, observe its behavior of output\nconcentration, and modify the set of parametric values at any time while the\nsimulation is in execution. Recently some popular tools have been presented,\nbut we believe that none of the tools allow users to interact with the model\nsimulation in run time.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "Abstract Presentation in 2023 Neuro-Inspired Computing Elements\n  (NICE) Conference",
    "pdf_url": "http://arxiv.org/pdf/2403.12061v2",
    "published_date": "2024-02-07 20:41:00 UTC",
    "updated_date": "2024-03-25 11:50:42 UTC"
  },
  {
    "arxiv_id": "2402.05232v1",
    "title": "Universal Neural Functionals",
    "authors": [
      "Allan Zhou",
      "Chelsea Finn",
      "James Harrison"
    ],
    "abstract": "A challenging problem in many modern machine learning tasks is to process\nweight-space features, i.e., to transform or extract information from the\nweights and gradients of a neural network. Recent works have developed\npromising weight-space models that are equivariant to the permutation\nsymmetries of simple feedforward networks. However, they are not applicable to\ngeneral architectures, since the permutation symmetries of a weight space can\nbe complicated by recurrence or residual connections. This work proposes an\nalgorithm that automatically constructs permutation equivariant models, which\nwe refer to as universal neural functionals (UNFs), for any weight space. Among\nother applications, we demonstrate how UNFs can be substituted into existing\nlearned optimizer designs, and find promising improvements over prior methods\nwhen optimizing small image classifiers and language models. Our results\nsuggest that learned optimizers can benefit from considering the (symmetry)\nstructure of the weight space they optimize. We open-source our library for\nconstructing UNFs at\nhttps://github.com/AllanYangZhou/universal_neural_functional.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05232v1",
    "published_date": "2024-02-07 20:12:27 UTC",
    "updated_date": "2024-02-07 20:12:27 UTC"
  },
  {
    "arxiv_id": "2402.10940v2",
    "title": "Neural machine translation of clinical procedure codes for medical diagnosis and uncertainty quantification",
    "authors": [
      "Pei-Hung Chung",
      "Shuhan He",
      "Norawit Kijpaisalratana",
      "Abdel-badih el Ariss",
      "Byung-Jun Yoon"
    ],
    "abstract": "A Clinical Decision Support System (CDSS) is designed to enhance clinician\ndecision-making by combining system-generated recommendations with medical\nexpertise. Given the high costs, intensive labor, and time-sensitive nature of\nmedical treatments, there is a pressing need for efficient decision support,\nespecially in complex emergency scenarios. In these scenarios, where\ninformation can be limited, an advanced CDSS framework that leverages AI\n(artificial intelligence) models to effectively reduce diagnostic uncertainty\nhas utility. Such an AI-enabled CDSS framework with quantified uncertainty\npromises to be practical and beneficial in the demanding context of real-world\nmedical care. In this study, we introduce the concept of Medical Entropy,\nquantifying uncertainties in patient outcomes predicted by neural machine\ntranslation based on the ICD-9 code of procedures. Our experimental results not\nonly show strong correlations between procedure and diagnosis sequences based\non the simple ICD-9 code but also demonstrate the promising capacity to model\ntrends of uncertainties during hospitalizations through a data-driven approach.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.10940v2",
    "published_date": "2024-02-07 20:11:56 UTC",
    "updated_date": "2024-10-19 06:35:25 UTC"
  },
  {
    "arxiv_id": "2402.05224v2",
    "title": "VerAs: Verify then Assess STEM Lab Reports",
    "authors": [
      "Berk Atil",
      "Mahsa Sheikhi Karizaki",
      "Rebecca J. Passonneau"
    ],
    "abstract": "With an increasing focus in STEM education on critical thinking skills,\nscience writing plays an ever more important role in curricula that stress\ninquiry skills. A recently published dataset of two sets of college level lab\nreports from an inquiry-based physics curriculum relies on analytic assessment\nrubrics that utilize multiple dimensions, specifying subject matter knowledge\nand general components of good explanations. Each analytic dimension is\nassessed on a 6-point scale, to provide detailed feedback to students that can\nhelp them improve their science writing skills. Manual assessment can be slow,\nand difficult to calibrate for consistency across all students in large\nclasses. While much work exists on automated assessment of open-ended questions\nin STEM subjects, there has been far less work on long-form writing such as lab\nreports. We present an end-to-end neural architecture that has separate\nverifier and assessment modules, inspired by approaches to Open Domain Question\nAnswering (OpenQA). VerAs first verifies whether a report contains any content\nrelevant to a given rubric dimension, and if so, assesses the relevant\nsentences. On the lab reports, VerAs outperforms multiple baselines based on\nOpenQA systems or Automated Essay Scoring (AES). VerAs also performs well on an\nanalytic rubric for middle school physics essays.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "It is accepted to AIED2024!",
    "pdf_url": "http://arxiv.org/pdf/2402.05224v2",
    "published_date": "2024-02-07 20:02:09 UTC",
    "updated_date": "2024-04-25 16:16:36 UTC"
  },
  {
    "arxiv_id": "2402.05201v3",
    "title": "The Effect of Sampling Temperature on Problem Solving in Large Language Models",
    "authors": [
      "Matthew Renze",
      "Erhan Guven"
    ],
    "abstract": "In this research study, we empirically investigate the effect of sampling\ntemperature on the performance of Large Language Models (LLMs) on various\nproblem-solving tasks. We created a multiple-choice question-and-answer (MCQA)\nexam by randomly sampling problems from standard LLM benchmarks. Then, we used\nnine popular LLMs with five prompt-engineering techniques to solve the MCQA\nproblems while increasing the sampling temperature from 0.0 to 1.6. Despite\nanecdotal reports to the contrary, our empirical results indicate that changes\nin temperature from 0.0 to 1.0 do not have a statistically significant impact\non LLM performance for problem-solving tasks. In addition, these results appear\nto generalize across LLMs, prompt-engineering techniques, and problem domains.\nAll code, data, and supplemental materials are available on GitHub at:\nhttps://github.com/matthewrenze/jhu-llm-temperature",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05201v3",
    "published_date": "2024-02-07 19:11:23 UTC",
    "updated_date": "2024-10-02 20:17:49 UTC"
  },
  {
    "arxiv_id": "2402.05200v2",
    "title": "Are LLMs Ready for Real-World Materials Discovery?",
    "authors": [
      "Santiago Miret",
      "N M Anoop Krishnan"
    ],
    "abstract": "Large Language Models (LLMs) create exciting possibilities for powerful\nlanguage processing tools to accelerate research in materials science. While\nLLMs have great potential to accelerate materials understanding and discovery,\nthey currently fall short in being practical materials science tools. In this\nposition paper, we show relevant failure cases of LLMs in materials science\nthat reveal current limitations of LLMs related to comprehending and reasoning\nover complex, interconnected materials science knowledge. Given those\nshortcomings, we outline a framework for developing Materials Science LLMs\n(MatSci-LLMs) that are grounded in materials science knowledge and hypothesis\ngeneration followed by hypothesis testing. The path to attaining performant\nMatSci-LLMs rests in large part on building high-quality, multi-modal datasets\nsourced from scientific literature where various information extraction\nchallenges persist. As such, we describe key materials science information\nextraction challenges which need to be overcome in order to build large-scale,\nmulti-modal datasets that capture valuable materials science knowledge.\nFinally, we outline a roadmap for applying future MatSci-LLMs for real-world\nmaterials discovery via: 1. Automated Knowledge Base Generation; 2. Automated\nIn-Silico Material Design; and 3. MatSci-LLM Integrated Self-Driving Materials\nLaboratories.",
    "categories": [
      "cond-mat.mtrl-sci",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05200v2",
    "published_date": "2024-02-07 19:10:36 UTC",
    "updated_date": "2024-09-25 11:43:59 UTC"
  },
  {
    "arxiv_id": "2402.05188v1",
    "title": "InCoRo: In-Context Learning for Robotics Control with Feedback Loops",
    "authors": [
      "Jiaqiang Ye Zhu",
      "Carla Gomez Cano",
      "David Vazquez Bermudez",
      "Michal Drozdzal"
    ],
    "abstract": "One of the challenges in robotics is to enable robotic units with the\nreasoning capability that would be robust enough to execute complex tasks in\ndynamic environments. Recent advances in LLMs have positioned them as go-to\ntools for simple reasoning tasks, motivating the pioneering work of Liang et\nal. [35] that uses an LLM to translate natural language commands into low-level\nstatic execution plans for robotic units. Using LLMs inside robotics systems\nbrings their generalization to a new level, enabling zero-shot generalization\nto new tasks. This paper extends this prior work to dynamic environments. We\npropose InCoRo, a system that uses a classical robotic feedback loop composed\nof an LLM controller, a scene understanding unit, and a robot. Our system\ncontinuously analyzes the state of the environment and provides adapted\nexecution commands, enabling the robot to adjust to changing environmental\nconditions and correcting for controller errors. Our system does not require\nany iterative optimization to learn to accomplish a task as it leverages\nin-context learning with an off-the-shelf LLM model. Through an extensive\nvalidation process involving two standardized industrial robotic units -- SCARA\nand DELTA types -- we contribute knowledge about these robots, not popular in\nthe community, thereby enriching it. We highlight the generalization\ncapabilities of our system and show that (1) in-context learning in combination\nwith the current state-of-the-art LLMs is an effective way to implement a\nrobotic controller; (2) in static environments, InCoRo surpasses the prior art\nin terms of the success rate; (3) in dynamic environments, we establish new\nstate-of-the-art for the SCARA and DELTA units, respectively. This research\npaves the way towards building reliable, efficient, intelligent autonomous\nsystems that adapt to dynamic environments.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05188v1",
    "published_date": "2024-02-07 19:01:11 UTC",
    "updated_date": "2024-02-07 19:01:11 UTC"
  },
  {
    "arxiv_id": "2402.05111v1",
    "title": "Edu-ConvoKit: An Open-Source Library for Education Conversation Data",
    "authors": [
      "Rose E. Wang",
      "Dorottya Demszky"
    ],
    "abstract": "We introduce Edu-ConvoKit, an open-source library designed to handle\npre-processing, annotation and analysis of conversation data in education.\nResources for analyzing education conversation data are scarce, making the\nresearch challenging to perform and therefore hard to access. We address these\nchallenges with Edu-ConvoKit. Edu-ConvoKit is open-source\n(https://github.com/stanfordnlp/edu-convokit ), pip-installable\n(https://pypi.org/project/edu-convokit/ ), with comprehensive documentation\n(https://edu-convokit.readthedocs.io/en/latest/ ). Our demo video is available\nat: https://youtu.be/zdcI839vAko?si=h9qlnl76ucSuXb8- . We include additional\nresources, such as Colab applications of Edu-ConvoKit to three diverse\neducation datasets and a repository of Edu-ConvoKit related papers, that can be\nfound in our GitHub repository.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "https://github.com/stanfordnlp/edu-convokit\n  https://edu-convokit.readthedocs.io/en/latest/",
    "pdf_url": "http://arxiv.org/pdf/2402.05111v1",
    "published_date": "2024-02-07 18:59:31 UTC",
    "updated_date": "2024-02-07 18:59:31 UTC"
  },
  {
    "arxiv_id": "2402.05164v2",
    "title": "A Resource Model For Neural Scaling Law",
    "authors": [
      "Jinyeop Song",
      "Ziming Liu",
      "Max Tegmark",
      "Jeff Gore"
    ],
    "abstract": "Neural scaling laws characterize how model performance improves as the model\nsize scales up. Inspired by empirical observations, we introduce a resource\nmodel of neural scaling. A task is usually composite hence can be decomposed\ninto many subtasks, which compete for resources (measured by the number of\nneurons allocated to subtasks). On toy problems, we empirically find that: (1)\nThe loss of a subtask is inversely proportional to its allocated neurons. (2)\nWhen multiple subtasks are present in a composite task, the resources acquired\nby each subtask uniformly grow as models get larger, keeping the ratios of\nacquired resources constants. We hypothesize these findings to be generally\ntrue and build a model to predict neural scaling laws for general composite\ntasks, which successfully replicates the neural scaling law of Chinchilla\nmodels reported in arXiv:2203.15556. We believe that the notion of resource\nused in this paper will be a useful tool for characterizing and diagnosing\nneural networks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 8 figures, Published as a workshop paper at ICLR 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.05164v2",
    "published_date": "2024-02-07 18:58:18 UTC",
    "updated_date": "2024-05-15 15:39:38 UTC"
  },
  {
    "arxiv_id": "2402.05106v1",
    "title": "Image captioning for Brazilian Portuguese using GRIT model",
    "authors": [
      "Rafael Silva de Alencar",
      "William Alberto Cruz Castañeda",
      "Marcellus Amadeus"
    ],
    "abstract": "This work presents the early development of a model of image captioning for\nthe Brazilian Portuguese language. We used the GRIT (Grid - and Region-based\nImage captioning Transformer) model to accomplish this work. GRIT is a\nTransformer-only neural architecture that effectively utilizes two visual\nfeatures to generate better captions. The GRIT method emerged as a proposal to\nbe a more efficient way to generate image captioning. In this work, we adapt\nthe GRIT model to be trained in a Brazilian Portuguese dataset to have an image\ncaptioning method for the Brazilian Portuguese Language.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "arXiv admin note: text overlap with arXiv:2207.09666 by other authors",
    "pdf_url": "http://arxiv.org/pdf/2402.05106v1",
    "published_date": "2024-02-07 18:57:37 UTC",
    "updated_date": "2024-02-07 18:57:37 UTC"
  },
  {
    "arxiv_id": "2402.05162v4",
    "title": "Assessing the Brittleness of Safety Alignment via Pruning and Low-Rank Modifications",
    "authors": [
      "Boyi Wei",
      "Kaixuan Huang",
      "Yangsibo Huang",
      "Tinghao Xie",
      "Xiangyu Qi",
      "Mengzhou Xia",
      "Prateek Mittal",
      "Mengdi Wang",
      "Peter Henderson"
    ],
    "abstract": "Large language models (LLMs) show inherent brittleness in their safety\nmechanisms, as evidenced by their susceptibility to jailbreaking and even\nnon-malicious fine-tuning. This study explores this brittleness of safety\nalignment by leveraging pruning and low-rank modifications. We develop methods\nto identify critical regions that are vital for safety guardrails, and that are\ndisentangled from utility-relevant regions at both the neuron and rank levels.\nSurprisingly, the isolated regions we find are sparse, comprising about $3\\%$\nat the parameter level and $2.5\\%$ at the rank level. Removing these regions\ncompromises safety without significantly impacting utility, corroborating the\ninherent brittleness of the model's safety mechanisms. Moreover, we show that\nLLMs remain vulnerable to low-cost fine-tuning attacks even when modifications\nto the safety-critical regions are restricted. These findings underscore the\nurgent need for more robust safety strategies in LLMs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "22 pages, 9 figures. Project page is available at\n  https://boyiwei.com/alignment-attribution/",
    "pdf_url": "http://arxiv.org/pdf/2402.05162v4",
    "published_date": "2024-02-07 18:34:38 UTC",
    "updated_date": "2024-10-24 19:21:52 UTC"
  },
  {
    "arxiv_id": "2402.05070v3",
    "title": "A Roadmap to Pluralistic Alignment",
    "authors": [
      "Taylor Sorensen",
      "Jared Moore",
      "Jillian Fisher",
      "Mitchell Gordon",
      "Niloofar Mireshghallah",
      "Christopher Michael Rytting",
      "Andre Ye",
      "Liwei Jiang",
      "Ximing Lu",
      "Nouha Dziri",
      "Tim Althoff",
      "Yejin Choi"
    ],
    "abstract": "With increased power and prevalence of AI systems, it is ever more critical\nthat AI systems are designed to serve all, i.e., people with diverse values and\nperspectives. However, aligning models to serve pluralistic human values\nremains an open research question. In this piece, we propose a roadmap to\npluralistic alignment, specifically using language models as a test bed. We\nidentify and formalize three possible ways to define and operationalize\npluralism in AI systems: 1) Overton pluralistic models that present a spectrum\nof reasonable responses; 2) Steerably pluralistic models that can steer to\nreflect certain perspectives; and 3) Distributionally pluralistic models that\nare well-calibrated to a given population in distribution. We also formalize\nand discuss three possible classes of pluralistic benchmarks: 1)\nMulti-objective benchmarks, 2) Trade-off steerable benchmarks, which\nincentivize models to steer to arbitrary trade-offs, and 3) Jury-pluralistic\nbenchmarks which explicitly model diverse human ratings. We use this framework\nto argue that current alignment techniques may be fundamentally limited for\npluralistic AI; indeed, we highlight empirical evidence, both from our own\nexperiments and from other work, that standard alignment procedures might\nreduce distributional pluralism in models, motivating the need for further\nresearch on pluralistic alignment.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "comment": "ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.05070v3",
    "published_date": "2024-02-07 18:21:17 UTC",
    "updated_date": "2024-08-20 19:14:31 UTC"
  },
  {
    "arxiv_id": "2402.05160v1",
    "title": "What's documented in AI? Systematic Analysis of 32K AI Model Cards",
    "authors": [
      "Weixin Liang",
      "Nazneen Rajani",
      "Xinyu Yang",
      "Ezinwanne Ozoani",
      "Eric Wu",
      "Yiqun Chen",
      "Daniel Scott Smith",
      "James Zou"
    ],
    "abstract": "The rapid proliferation of AI models has underscored the importance of\nthorough documentation, as it enables users to understand, trust, and\neffectively utilize these models in various applications. Although developers\nare encouraged to produce model cards, it's not clear how much information or\nwhat information these cards contain. In this study, we conduct a comprehensive\nanalysis of 32,111 AI model documentations on Hugging Face, a leading platform\nfor distributing and deploying AI models. Our investigation sheds light on the\nprevailing model card documentation practices. Most of the AI models with\nsubstantial downloads provide model cards, though the cards have uneven\ninformativeness. We find that sections addressing environmental impact,\nlimitations, and evaluation exhibit the lowest filled-out rates, while the\ntraining section is the most consistently filled-out. We analyze the content of\neach section to characterize practitioners' priorities. Interestingly, there\nare substantial discussions of data, sometimes with equal or even greater\nemphasis than the model itself. To evaluate the impact of model cards, we\nconducted an intervention study by adding detailed model cards to 42 popular\nmodels which had no or sparse model cards previously. We find that adding model\ncards is moderately correlated with an increase weekly download rates. Our\nstudy opens up a new perspective for analyzing community norms and practices\nfor model documentation through large-scale data science and linguistics\nanalysis.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05160v1",
    "published_date": "2024-02-07 18:04:32 UTC",
    "updated_date": "2024-02-07 18:04:32 UTC"
  },
  {
    "arxiv_id": "2402.05158v1",
    "title": "Enhancement of Bengali OCR by Specialized Models and Advanced Techniques for Diverse Document Types",
    "authors": [
      "AKM Shahariar Azad Rabby",
      "Hasmot Ali",
      "Md. Majedul Islam",
      "Sheikh Abujar",
      "Fuad Rahman"
    ],
    "abstract": "This research paper presents a unique Bengali OCR system with some\ncapabilities. The system excels in reconstructing document layouts while\npreserving structure, alignment, and images. It incorporates advanced image and\nsignature detection for accurate extraction. Specialized models for word\nsegmentation cater to diverse document types, including computer-composed,\nletterpress, typewriter, and handwritten documents. The system handles static\nand dynamic handwritten inputs, recognizing various writing styles.\nFurthermore, it has the ability to recognize compound characters in Bengali.\nExtensive data collection efforts provide a diverse corpus, while advanced\ntechnical components optimize character and word recognition. Additional\ncontributions include image, logo, signature and table recognition, perspective\ncorrection, layout reconstruction, and a queuing module for efficient and\nscalable processing. The system demonstrates outstanding performance in\nefficient and accurate text extraction and analysis.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, 7 figures, 4 table Link of the paper\n  https://openaccess.thecvf.com/content/WACV2024W/WVLL/html/Rabby_Enhancement_of_Bengali_OCR_by_Specialized_Models_and_Advanced_Techniques_WACVW_2024_paper.html",
    "pdf_url": "http://arxiv.org/pdf/2402.05158v1",
    "published_date": "2024-02-07 18:02:33 UTC",
    "updated_date": "2024-02-07 18:02:33 UTC"
  },
  {
    "arxiv_id": "2402.05048v3",
    "title": "How VADER is your AI? Towards a definition of artificial intelligence systems appropriate for regulation",
    "authors": [
      "Leonardo C. T. Bezerra",
      "Alexander E. I. Brownlee",
      "Luana Ferraz Alvarenga",
      "Renan Cipriano Moioli",
      "Thais Vasconcelos Batista"
    ],
    "abstract": "Artificial intelligence (AI) has driven many information and communication\ntechnology (ICT) breakthroughs. Nonetheless, the scope of ICT systems has\nexpanded far beyond AI since the Turing test proposal. Critically, recent AI\nregulation proposals adopt AI definitions affecting ICT techniques, approaches,\nand systems that are not AI. In some cases, even works from mathematics,\nstatistics, and engineering would be affected. Worryingly, AI misdefinitions\nare observed from Western societies to the Global South. In this paper, we\npropose a framework to score how validated as appropriately-defined for\nregulation (VADER) an AI definition is. Our online, publicly-available VADER\nframework scores the coverage of premises that should underlie AI definitions\nfor regulation, which aim to (i) reproduce principles observed in other\nsuccessful technology regulations, and (ii) include all AI techniques and\napproaches while excluding non-AI works. Regarding the latter, our score is\nbased on a dataset of representative AI, non-AI ICT, and non-ICT examples. We\ndemonstrate our contribution by reviewing the AI regulation proposals of key\nplayers, namely the United States, United Kingdom, European Union, and Brazil.\nImportantly, none of the proposals assessed achieve the appropriateness score,\nranging from a revision need to a concrete risk to ICT systems and works from\nother fields.",
    "categories": [
      "cs.AI",
      "I.2.0"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05048v3",
    "published_date": "2024-02-07 17:41:15 UTC",
    "updated_date": "2025-01-24 15:45:24 UTC"
  },
  {
    "arxiv_id": "2402.05044v4",
    "title": "SALAD-Bench: A Hierarchical and Comprehensive Safety Benchmark for Large Language Models",
    "authors": [
      "Lijun Li",
      "Bowen Dong",
      "Ruohui Wang",
      "Xuhao Hu",
      "Wangmeng Zuo",
      "Dahua Lin",
      "Yu Qiao",
      "Jing Shao"
    ],
    "abstract": "In the rapidly evolving landscape of Large Language Models (LLMs), ensuring\nrobust safety measures is paramount. To meet this crucial need, we propose\n\\emph{SALAD-Bench}, a safety benchmark specifically designed for evaluating\nLLMs, attack, and defense methods. Distinguished by its breadth, SALAD-Bench\ntranscends conventional benchmarks through its large scale, rich diversity,\nintricate taxonomy spanning three levels, and versatile\nfunctionalities.SALAD-Bench is crafted with a meticulous array of questions,\nfrom standard queries to complex ones enriched with attack, defense\nmodifications and multiple-choice. To effectively manage the inherent\ncomplexity, we introduce an innovative evaluators: the LLM-based MD-Judge for\nQA pairs with a particular focus on attack-enhanced queries, ensuring a\nseamless, and reliable evaluation. Above components extend SALAD-Bench from\nstandard LLM safety evaluation to both LLM attack and defense methods\nevaluation, ensuring the joint-purpose utility. Our extensive experiments shed\nlight on the resilience of LLMs against emerging threats and the efficacy of\ncontemporary defense tactics. Data and evaluator are released under\nhttps://github.com/OpenSafetyLab/SALAD-BENCH.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at ACL 2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2402.05044v4",
    "published_date": "2024-02-07 17:33:54 UTC",
    "updated_date": "2024-06-07 12:05:46 UTC"
  },
  {
    "arxiv_id": "2402.05027v3",
    "title": "Towards Generalizability of Multi-Agent Reinforcement Learning in Graphs with Recurrent Message Passing",
    "authors": [
      "Jannis Weil",
      "Zhenghua Bao",
      "Osama Abboud",
      "Tobias Meuser"
    ],
    "abstract": "Graph-based environments pose unique challenges to multi-agent reinforcement\nlearning. In decentralized approaches, agents operate within a given graph and\nmake decisions based on partial or outdated observations. The size of the\nobserved neighborhood limits the generalizability to different graphs and\naffects the reactivity of agents, the quality of the selected actions, and the\ncommunication overhead. This work focuses on generalizability and resolves the\ntrade-off in observed neighborhood size with a continuous information flow in\nthe whole graph. We propose a recurrent message-passing model that iterates\nwith the environment's steps and allows nodes to create a global representation\nof the graph by exchanging messages with their neighbors. Agents receive the\nresulting learned graph observations based on their location in the graph. Our\napproach can be used in a decentralized manner at runtime and in combination\nwith a reinforcement learning algorithm of choice. We evaluate our method\nacross 1000 diverse graphs in the context of routing in communication networks\nand find that it enables agents to generalize and adapt to changes in the\ngraph.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "Accepted at AAMAS 2024, version with appendix; corrected typo in\n  equation (1)",
    "pdf_url": "http://arxiv.org/pdf/2402.05027v3",
    "published_date": "2024-02-07 16:53:09 UTC",
    "updated_date": "2024-06-04 10:16:33 UTC"
  },
  {
    "arxiv_id": "2402.10100v3",
    "title": "Tuning In: Analysis of Audio Classifier Performance in Clinical Settings with Limited Data",
    "authors": [
      "Hamza Mahdi",
      "Eptehal Nashnoush",
      "Rami Saab",
      "Arjun Balachandar",
      "Rishit Dagli",
      "Lucas X. Perri",
      "Houman Khosravani"
    ],
    "abstract": "This study assesses deep learning models for audio classification in a\nclinical setting with the constraint of small datasets reflecting real-world\nprospective data collection. We analyze CNNs, including DenseNet and ConvNeXt,\nalongside transformer models like ViT, SWIN, and AST, and compare them against\npre-trained audio models such as YAMNet and VGGish. Our method highlights the\nbenefits of pre-training on large datasets before fine-tuning on specific\nclinical data. We prospectively collected two first-of-their-kind patient audio\ndatasets from stroke patients. We investigated various preprocessing\ntechniques, finding that RGB and grayscale spectrogram transformations affect\nmodel performance differently based on the priors they learn from pre-training.\nOur findings indicate CNNs can match or exceed transformer models in small\ndataset contexts, with DenseNet-Contrastive and AST models showing notable\nperformance. This study highlights the significance of incremental marginal\ngains through model selection, pre-training, and preprocessing in sound\nclassification; this offers valuable insights for clinical diagnostics that\nrely on audio classification.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "CHIL 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.10100v3",
    "published_date": "2024-02-07 16:41:11 UTC",
    "updated_date": "2024-04-05 21:40:33 UTC"
  },
  {
    "arxiv_id": "2402.05156v1",
    "title": "What About the Data? A Mapping Study on Data Engineering for AI Systems",
    "authors": [
      "Petra Heck"
    ],
    "abstract": "AI systems cannot exist without data. Now that AI models (data science and\nAI) have matured and are readily available to apply in practice, most\norganizations struggle with the data infrastructure to do so. There is a\ngrowing need for data engineers that know how to prepare data for AI systems or\nthat can setup enterprise-wide data architectures for analytical projects. But\nuntil now, the data engineering part of AI engineering has not been getting\nmuch attention, in favor of discussing the modeling part. In this paper we aim\nto change this by perform a mapping study on data engineering for AI systems,\ni.e., AI data engineering. We found 25 relevant papers between January 2019 and\nJune 2023, explaining AI data engineering activities. We identify which life\ncycle phases are covered, which technical solutions or architectures are\nproposed and which lessons learned are presented. We end by an overall\ndiscussion of the papers with implications for practitioners and researchers.\nThis paper creates an overview of the body of knowledge on data engineering for\nAI. This overview is useful for practitioners to identify solutions and best\npractices as well as for researchers to identify gaps.",
    "categories": [
      "cs.DL",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.DL",
    "comment": "Preprint, accepted for CAIN24",
    "pdf_url": "http://arxiv.org/pdf/2402.05156v1",
    "published_date": "2024-02-07 16:31:58 UTC",
    "updated_date": "2024-02-07 16:31:58 UTC"
  },
  {
    "arxiv_id": "2402.05008v2",
    "title": "EfficientViT-SAM: Accelerated Segment Anything Model Without Accuracy Loss",
    "authors": [
      "Zhuoyang Zhang",
      "Han Cai",
      "Song Han"
    ],
    "abstract": "We present EfficientViT-SAM, a new family of accelerated segment anything\nmodels. We retain SAM's lightweight prompt encoder and mask decoder while\nreplacing the heavy image encoder with EfficientViT. For the training, we begin\nwith the knowledge distillation from the SAM-ViT-H image encoder to\nEfficientViT. Subsequently, we conduct end-to-end training on the SA-1B\ndataset. Benefiting from EfficientViT's efficiency and capacity,\nEfficientViT-SAM delivers 48.9x measured TensorRT speedup on A100 GPU over\nSAM-ViT-H without sacrificing performance. Our code and pre-trained models are\nreleased at https://github.com/mit-han-lab/efficientvit.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2024 Workshop (Efficient Large Vision Models)",
    "pdf_url": "http://arxiv.org/pdf/2402.05008v2",
    "published_date": "2024-02-07 16:28:36 UTC",
    "updated_date": "2024-05-16 20:51:52 UTC"
  },
  {
    "arxiv_id": "2402.05007v1",
    "title": "Example-based Explanations for Random Forests using Machine Unlearning",
    "authors": [
      "Tanmay Surve",
      "Romila Pradhan"
    ],
    "abstract": "Tree-based machine learning models, such as decision trees and random\nforests, have been hugely successful in classification tasks primarily because\nof their predictive power in supervised learning tasks and ease of\ninterpretation. Despite their popularity and power, these models have been\nfound to produce unexpected or discriminatory outcomes. Given their\noverwhelming success for most tasks, it is of interest to identify sources of\ntheir unexpected and discriminatory behavior. However, there has not been much\nwork on understanding and debugging tree-based classifiers in the context of\nfairness.\n  We introduce FairDebugger, a system that utilizes recent advances in machine\nunlearning research to identify training data subsets responsible for instances\nof fairness violations in the outcomes of a random forest classifier.\nFairDebugger generates top-$k$ explanations (in the form of coherent training\ndata subsets) for model unfairness. Toward this goal, FairDebugger first\nutilizes machine unlearning to estimate the change in the tree structures of\nthe random forest when parts of the underlying training data are removed, and\nthen leverages the Apriori algorithm from frequent itemset mining to reduce the\nsubset search space. We empirically evaluate our approach on three real-world\ndatasets, and demonstrate that the explanations generated by FairDebugger are\nconsistent with insights from prior studies on these datasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05007v1",
    "published_date": "2024-02-07 16:28:04 UTC",
    "updated_date": "2024-02-07 16:28:04 UTC"
  },
  {
    "arxiv_id": "2402.04979v1",
    "title": "Detection and Pose Estimation of flat, Texture-less Industry Objects on HoloLens using synthetic Training",
    "authors": [
      "Thomas Pöllabauer",
      "Fabian Rücker",
      "Andreas Franek",
      "Felix Gorschlüter"
    ],
    "abstract": "Current state-of-the-art 6d pose estimation is too compute intensive to be\ndeployed on edge devices, such as Microsoft HoloLens (2) or Apple iPad, both\nused for an increasing number of augmented reality applications. The quality of\nAR is greatly dependent on its capabilities to detect and overlay geometry\nwithin the scene. We propose a synthetically trained client-server-based\naugmented reality application, demonstrating state-of-the-art object pose\nestimation of metallic and texture-less industry objects on edge devices.\nSynthetic data enables training without real photographs, i.e. for\nyet-to-be-manufactured objects. Our qualitative evaluation on an AR-assisted\nsorting task, and quantitative evaluation on both renderings, as well as\nreal-world data recorded on HoloLens 2, sheds light on its real-world\napplicability.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Scandinavian Conference on Image Analysis 2023",
    "pdf_url": "http://arxiv.org/pdf/2402.04979v1",
    "published_date": "2024-02-07 15:57:28 UTC",
    "updated_date": "2024-02-07 15:57:28 UTC"
  },
  {
    "arxiv_id": "2402.04978v2",
    "title": "An Enhanced Prompt-Based LLM Reasoning Scheme via Knowledge Graph-Integrated Collaboration",
    "authors": [
      "Yihao Li",
      "Ru Zhang",
      "Jianyi Liu"
    ],
    "abstract": "While Large Language Models (LLMs) demonstrate exceptional performance in a\nmultitude of Natural Language Processing (NLP) tasks, they encounter challenges\nin practical applications, including issues with hallucinations, inadequate\nknowledge updating, and limited transparency in the reasoning process. To\novercome these limitations, this study innovatively proposes a collaborative\ntraining-free reasoning scheme involving tight cooperation between Knowledge\nGraph (KG) and LLMs. This scheme first involves using LLMs to iteratively\nexplore KG, selectively retrieving a task-relevant knowledge subgraph to\nsupport reasoning. The LLMs are then guided to further combine inherent\nimplicit knowledge to reason on the subgraph while explicitly elucidating the\nreasoning process. Through such a cooperative approach, our scheme achieves\nmore reliable knowledge-based reasoning and facilitates the tracing of the\nreasoning results. Experimental results show that our scheme significantly\nprogressed across multiple datasets, notably achieving over a 10% improvement\non the QALD10 dataset compared to the best baseline and the fine-tuned\nstate-of-the-art (SOTA) work. Building on this success, this study hopes to\noffer a valuable reference for future research in the fusion of KG and LLMs,\nthereby enhancing LLMs' proficiency in solving complex issues.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.04978v2",
    "published_date": "2024-02-07 15:56:17 UTC",
    "updated_date": "2024-06-12 16:03:31 UTC"
  },
  {
    "arxiv_id": "2402.04975v1",
    "title": "ChatScratch: An AI-Augmented System Toward Autonomous Visual Programming Learning for Children Aged 6-12",
    "authors": [
      "Liuqing Chen",
      "Shuhong Xiao",
      "Yunnong Chen",
      "Ruoyu Wu",
      "Yaxuan Song",
      "Lingyun Sun"
    ],
    "abstract": "As Computational Thinking (CT) continues to permeate younger age groups in\nK-12 education, established CT platforms such as Scratch face challenges in\ncatering to these younger learners, particularly those in the elementary school\n(ages 6-12). Through formative investigation with Scratch experts, we uncover\nthree key obstacles to children's autonomous Scratch learning: artist's block\nin project planning, bounded creativity in asset creation, and inadequate\ncoding guidance during implementation. To address these barriers, we introduce\nChatScratch, an AI-augmented system to facilitate autonomous programming\nlearning for young children. ChatScratch employs structured interactive\nstoryboards and visual cues to overcome artist's block, integrates digital\ndrawing and advanced image generation technologies to elevate creativity, and\nleverages Scratch-specialized Large Language Models (LLMs) for professional\ncoding guidance. Our study shows that, compared to Scratch, ChatScratch\nefficiently fosters autonomous programming learning, and contributes to the\ncreation of high-quality, personally meaningful Scratch projects for children.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.HC",
    "comment": "29 pages, 7 figures, accepted by CHI 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.04975v1",
    "published_date": "2024-02-07 15:55:51 UTC",
    "updated_date": "2024-02-07 15:55:51 UTC"
  },
  {
    "arxiv_id": "2403.05550v1",
    "title": "Teranga Go!: Carpooling Collaborative Consumption Community with multi-criteria hesitant fuzzy linguistic term set opinions to build confidence and trust",
    "authors": [
      "Rosana Montes",
      "Ana M. Sanchez",
      "Pedro Villar",
      "Francisco Herrera"
    ],
    "abstract": "Classic Delphi and Fuzzy Delphi methods are used to test content validity of\na data collection tools such as questionnaires. Fuzzy Delphi takes the opinion\nissued by judges from a linguistic perspective reducing ambiguity in opinions\nby using fuzzy numbers. We propose an extension named 2-Tuple Fuzzy Linguistic\nDelphi method to deal with scenarios in which judges show different expertise\ndegrees by using fuzzy multigranular semantics of the linguistic terms and to\nobtain intermediate and final results expressed by 2-tuple linguistic values.\nThe key idea of our proposal is to validate the full questionnaire by means of\nthe evaluation of its parts, defining the validity of each item as a Decision\nMaking problem. Taking the opinion of experts, we measure the degree of\nconsensus, the degree of consistency, and the linguistic score of each item, in\norder to detect those items that affect, positively or negatively, the quality\nof the instrument. Considering the real need to evaluate a b-learning\neducational experience with a consensual questionnaire, we present a Decision\nMaking model for questionnaire validation that solve it. Additionally, we\ncontribute to this consensus reaching problem by developing an online tool\nunder GPL v3 license. The software visualizes the collective valuations for\neach iteration and assists to determine which parts of the questionnaire should\nbe modified to reach a consensual solution.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "project at https://github.com/rosanamontes/teranga.go. arXiv admin\n  note: substantial text overlap with arXiv:2402.01775",
    "pdf_url": "http://arxiv.org/pdf/2403.05550v1",
    "published_date": "2024-02-07 15:50:54 UTC",
    "updated_date": "2024-02-07 15:50:54 UTC"
  },
  {
    "arxiv_id": "2402.04971v4",
    "title": "Multi-Sender Persuasion: A Computational Perspective",
    "authors": [
      "Safwan Hossain",
      "Tonghan Wang",
      "Tao Lin",
      "Yiling Chen",
      "David C. Parkes",
      "Haifeng Xu"
    ],
    "abstract": "We consider the multi-sender persuasion problem: multiple players with\ninformational advantage signal to convince a single self-interested actor to\ntake certain actions. This problem generalizes the seminal Bayesian Persuasion\nframework and is ubiquitous in computational economics, multi-agent learning,\nand multi-objective machine learning. The core solution concept here is the\nNash equilibrium of senders' signaling policies. Theoretically, we prove that\nfinding an equilibrium in general is PPAD-Hard; in fact, even computing a\nsender's best response is NP-Hard. Given these intrinsic difficulties, we turn\nto finding local Nash equilibria. We propose a novel differentiable neural\nnetwork to approximate this game's non-linear and discontinuous utilities.\nComplementing this with the extra-gradient algorithm, we discover local\nequilibria that Pareto dominates full-revelation equilibria and those found by\nexisting neural networks. Broadly, our theoretical and empirical contributions\nare of interest to a large class of economic problems.",
    "categories": [
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.04971v4",
    "published_date": "2024-02-07 15:50:20 UTC",
    "updated_date": "2024-06-20 03:02:39 UTC"
  },
  {
    "arxiv_id": "2402.04967v1",
    "title": "Text or Image? What is More Important in Cross-Domain Generalization Capabilities of Hate Meme Detection Models?",
    "authors": [
      "Piush Aggarwal",
      "Jawar Mehrabanian",
      "Weigang Huang",
      "Özge Alacam",
      "Torsten Zesch"
    ],
    "abstract": "This paper delves into the formidable challenge of cross-domain\ngeneralization in multimodal hate meme detection, presenting compelling\nfindings. We provide enough pieces of evidence supporting the hypothesis that\nonly the textual component of hateful memes enables the existing multimodal\nclassifier to generalize across different domains, while the image component\nproves highly sensitive to a specific training dataset. The evidence includes\ndemonstrations showing that hate-text classifiers perform similarly to\nhate-meme classifiers in a zero-shot setting. Simultaneously, the introduction\nof captions generated from images of memes to the hate-meme classifier worsens\nperformance by an average F1 of 0.02. Through blackbox explanations, we\nidentify a substantial contribution of the text modality (average of 83%),\nwhich diminishes with the introduction of meme's image captions (52%).\nAdditionally, our evaluation on a newly created confounder dataset reveals\nhigher performance on text confounders as compared to image confounders with an\naverage $\\Delta$F1 of 0.18.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at EACL'2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2402.04967v1",
    "published_date": "2024-02-07 15:44:55 UTC",
    "updated_date": "2024-02-07 15:44:55 UTC"
  },
  {
    "arxiv_id": "2402.04955v2",
    "title": "Conversational Assistants in Knowledge-Intensive Contexts: An Evaluation of LLM- versus Intent-based Systems",
    "authors": [
      "Samuel Kernan Freire",
      "Chaofan Wang",
      "Evangelos Niforatos"
    ],
    "abstract": "Conversational Assistants (CA) are increasingly supporting human workers in\nknowledge management. Traditionally, CAs respond in specific ways to predefined\nuser intents and conversation patterns. However, this rigidness does not handle\nthe diversity of natural language well. Recent advances in natural language\nprocessing, namely Large Language Models (LLMs), enable CAs to converse in a\nmore flexible, human-like manner, extracting relevant information from texts\nand capturing information from expert humans but introducing new challenges\nsuch as ``hallucinations''. To assess the potential of using LLMs for knowledge\nmanagement tasks, we conducted a user study comparing an LLM-based CA to an\nintent-based system regarding interaction efficiency, user experience,\nworkload, and usability. This revealed that LLM-based CAs exhibited better user\nexperience, task completion rate, usability, and perceived performance than\nintent-based systems, suggesting that switching NLP techniques can be\nbeneficial in the context of knowledge management.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "10 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.04955v2",
    "published_date": "2024-02-07 15:39:07 UTC",
    "updated_date": "2024-07-12 12:31:14 UTC"
  },
  {
    "arxiv_id": "2403.09680v2",
    "title": "Pre-Sorted Tsetlin Machine (The Genetic K-Medoid Method)",
    "authors": [
      "Jordan Morris"
    ],
    "abstract": "This paper proposes a machine learning pre-sort stage to traditional\nsupervised learning using Tsetlin Machines. Initially, K data-points are\nidentified from the dataset using an expedited genetic algorithm to solve the\nmaximum dispersion problem. These are then used as the initial placement to run\nthe K-Medoid clustering algorithm. Finally, an expedited genetic algorithm is\nused to align K independent Tsetlin Machines by maximising hamming distance.\nFor MNIST level classification problems, results demonstrate up to 10%\nimprovement in accuracy, approx. 383X reduction in training time and approx.\n86X reduction in inference time.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG",
      "B.6.0; B.7.0; C.1.0; I.2.6"
    ],
    "primary_category": "cs.NE",
    "comment": "6 pages, 12 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2403.09680v2",
    "published_date": "2024-02-07 15:30:23 UTC",
    "updated_date": "2024-04-08 17:51:31 UTC"
  },
  {
    "arxiv_id": "2402.05154v1",
    "title": "Adaptive Hypergraph Network for Trust Prediction",
    "authors": [
      "Rongwei Xu",
      "Guanfeng Liu",
      "Yan Wang",
      "Xuyun Zhang",
      "Kai Zheng",
      "Xiaofang Zhou"
    ],
    "abstract": "Trust plays an essential role in an individual's decision-making. Traditional\ntrust prediction models rely on pairwise correlations to infer potential\nrelationships between users. However, in the real world, interactions between\nusers are usually complicated rather than pairwise only. Hypergraphs offer a\nflexible approach to modeling these complex high-order correlations (not just\npairwise connections), since hypergraphs can leverage hyperedeges to link more\nthan two nodes. However, most hypergraph-based methods are generic and cannot\nbe well applied to the trust prediction task. In this paper, we propose an\nAdaptive Hypergraph Network for Trust Prediction (AHNTP), a novel approach that\nimproves trust prediction accuracy by using higher-order correlations. AHNTP\nutilizes Motif-based PageRank to capture high-order social influence\ninformation. In addition, it constructs hypergroups from both node-level and\nstructure-level attributes to incorporate complex correlation information.\nFurthermore, AHNTP leverages adaptive hypergraph Graph Convolutional Network\n(GCN) layers and multilayer perceptrons (MLPs) to generate comprehensive user\nembeddings, facilitating trust relationship prediction. To enhance model\ngeneralization and robustness, we introduce a novel supervised contrastive\nlearning loss for optimization. Extensive experiments demonstrate the\nsuperiority of our model over the state-of-the-art approaches in terms of trust\nprediction accuracy. The source code of this work can be accessed via\nhttps://github.com/Sherry-XU1995/AHNTP.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05154v1",
    "published_date": "2024-02-07 15:21:18 UTC",
    "updated_date": "2024-02-07 15:21:18 UTC"
  },
  {
    "arxiv_id": "2402.04938v1",
    "title": "An approach to automated videogame beta testing",
    "authors": [
      "Jennifer Hernández-Bécares",
      "Luis Costero",
      "Pedro Pablo Gómez-Martín"
    ],
    "abstract": "Videogames developed in the 1970s and 1980s were modest programs created in a\ncouple of months by a single person, who played the roles of designer, artist\nand programmer. Since then, videogames have evolved to become a multi-million\ndollar industry. Today, AAA game development involves hundreds of people\nworking together over several years. Management and engineering requirements\nhave changed at the same pace. Although many of the processes have been adapted\nover time, this is not quite true for quality assurance tasks, which are still\ndone mainly manually by human beta testers due to the specific peculiarities of\nvideogames. This paper presents an approach to automate this beta testing.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.04938v1",
    "published_date": "2024-02-07 15:16:21 UTC",
    "updated_date": "2024-02-07 15:16:21 UTC"
  },
  {
    "arxiv_id": "2402.04929v3",
    "title": "Source-Free Domain Adaptation with Diffusion-Guided Source Data Generation",
    "authors": [
      "Shivang Chopra",
      "Suraj Kothawade",
      "Houda Aynaou",
      "Aman Chadha"
    ],
    "abstract": "This paper introduces a novel approach to leverage the generalizability of\nDiffusion Models for Source-Free Domain Adaptation (DM-SFDA). Our proposed\nDMSFDA method involves fine-tuning a pre-trained text-to-image diffusion model\nto generate source domain images using features from the target images to guide\nthe diffusion process. Specifically, the pre-trained diffusion model is\nfine-tuned to generate source samples that minimize entropy and maximize\nconfidence for the pre-trained source model. We then use a diffusion\nmodel-based image mixup strategy to bridge the domain gap between the source\nand target domains. We validate our approach through comprehensive experiments\nacross a range of datasets, including Office-31, Office-Home, and VisDA. The\nresults demonstrate significant improvements in SFDA performance, highlighting\nthe potential of diffusion models in generating contextually relevant,\ndomain-specific images.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "arXiv admin note: substantial text overlap with arXiv:2310.01701",
    "pdf_url": "http://arxiv.org/pdf/2402.04929v3",
    "published_date": "2024-02-07 14:56:13 UTC",
    "updated_date": "2024-06-26 20:57:15 UTC"
  },
  {
    "arxiv_id": "2402.04918v1",
    "title": "Prompting Implicit Discourse Relation Annotation",
    "authors": [
      "Frances Yung",
      "Mansoor Ahmad",
      "Merel Scholman",
      "Vera Demberg"
    ],
    "abstract": "Pre-trained large language models, such as ChatGPT, archive outstanding\nperformance in various reasoning tasks without supervised training and were\nfound to have outperformed crowdsourcing workers. Nonetheless, ChatGPT's\nperformance in the task of implicit discourse relation classification, prompted\nby a standard multiple-choice question, is still far from satisfactory and\nconsiderably inferior to state-of-the-art supervised approaches. This work\ninvestigates several proven prompting techniques to improve ChatGPT's\nrecognition of discourse relations. In particular, we experimented with\nbreaking down the classification task that involves numerous abstract labels\ninto smaller subtasks. Nonetheless, experiment results show that the inference\naccuracy hardly changes even with sophisticated prompt engineering, suggesting\nthat implicit discourse relation classification is not yet resolvable under\nzero-shot or few-shot settings.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "To appear at the Linguistic Annotation Workshop 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.04918v1",
    "published_date": "2024-02-07 14:44:42 UTC",
    "updated_date": "2024-02-07 14:44:42 UTC"
  },
  {
    "arxiv_id": "2402.04898v1",
    "title": "The Strain of Success: A Predictive Model for Injury Risk Mitigation and Team Success in Soccer",
    "authors": [
      "Gregory Everett",
      "Ryan Beal",
      "Tim Matthews",
      "Timothy J. Norman",
      "Sarvapali D. Ramchurn"
    ],
    "abstract": "In this paper, we present a novel sequential team selection model in soccer.\nSpecifically, we model the stochastic process of player injury and\nunavailability using player-specific information learned from real-world soccer\ndata. Monte-Carlo Tree Search is used to select teams for games that optimise\nlong-term team performance across a soccer season by reasoning over player\ninjury probability. We validate our approach compared to benchmark solutions\nfor the 2018/19 English Premier League season. Our model achieves similar\nseason expected points to the benchmark whilst reducing first-team injuries by\n~13% and the money inefficiently spent on injured players by ~11% -\ndemonstrating the potential to reduce costs and improve player welfare in\nreal-world soccer teams.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "19 pages (16 main, 2 references, 1 appendix), 10 figures (9 main, 1\n  appendix). Accepted at the MIT Sloan Sports Analytics Conference 2024\n  Research Paper Competition",
    "pdf_url": "http://arxiv.org/pdf/2402.04898v1",
    "published_date": "2024-02-07 14:28:04 UTC",
    "updated_date": "2024-02-07 14:28:04 UTC"
  },
  {
    "arxiv_id": "2402.04892v2",
    "title": "Probabilistic ML Verification via Weighted Model Integration",
    "authors": [
      "Paolo Morettin",
      "Andrea Passerini",
      "Roberto Sebastiani"
    ],
    "abstract": "In machine learning (ML) verification, the majority of procedures are\nnon-quantitative and therefore cannot be used for verifying probabilistic\nmodels, or be applied in domains where hard guarantees are practically\nunachievable. The probabilistic formal verification (PFV) of ML models is in\nits infancy, with the existing approaches limited to specific ML models,\nproperties, or both. This contrasts with standard formal methods techniques,\nwhose successful adoption in real-world scenarios is also due to their support\nfor a wide range of properties and diverse systems. We propose a unifying\nframework for the PFV of ML systems based on Weighted Model Integration (WMI),\na relatively recent formalism for probabilistic inference with algebraic and\nlogical constraints. Crucially, reducing the PFV of ML models to WMI enables\nthe verification of many properties of interest over a wide range of systems,\naddressing multiple limitations of deterministic verification and ad-hoc\nalgorithms. We substantiate the generality of the approach on prototypical\ntasks involving the verification of group fairness, monotonicity, robustness to\nnoise, probabilistic local robustness and equivalence among predictors. We\ncharacterize the challenges related to the scalability of the approach and,\nthrough our WMI-based perspective, we show how successful scaling techniques in\nthe ML verification literature can be generalized beyond their original scope.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.04892v2",
    "published_date": "2024-02-07 14:24:04 UTC",
    "updated_date": "2024-10-23 09:04:57 UTC"
  },
  {
    "arxiv_id": "2402.10101v1",
    "title": "Deep Learning Based Situation Awareness for Multiple Missiles Evasion",
    "authors": [
      "Edvards Scukins",
      "Markus Klein",
      "Lars Kroon",
      "Petter Ögren"
    ],
    "abstract": "As the effective range of air-to-air missiles increases, it becomes harder\nfor human operators to maintain the situational awareness needed to keep a UAV\nsafe. In this work, we propose a decision support tool to help UAV operators in\nBeyond Visual Range (BVR) air combat scenarios assess the risks of different\noptions and make decisions based on those. Earlier work focused on the threat\nposed by a single missile, and in this work, we extend the ideas to several\nmissile threats. The proposed method uses Deep Neural Networks (DNN) to learn\nfrom high-fidelity simulations to provide the operator with an outcome estimate\nfor a set of different strategies. Our results demonstrate that the proposed\nsystem can manage multiple incoming missiles, evaluate a family of options, and\nrecommend the least risky course of action.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.10101v1",
    "published_date": "2024-02-07 14:21:21 UTC",
    "updated_date": "2024-02-07 14:21:21 UTC"
  },
  {
    "arxiv_id": "2402.04869v2",
    "title": "Learning by Doing: An Online Causal Reinforcement Learning Framework with Causal-Aware Policy",
    "authors": [
      "Ruichu Cai",
      "Siyang Huang",
      "Jie Qiao",
      "Wei Chen",
      "Yan Zeng",
      "Keli Zhang",
      "Fuchun Sun",
      "Yang Yu",
      "Zhifeng Hao"
    ],
    "abstract": "As a key component to intuitive cognition and reasoning solutions in human\nintelligence, causal knowledge provides great potential for reinforcement\nlearning (RL) agents' interpretability towards decision-making by helping\nreduce the searching space. However, there is still a considerable gap in\ndiscovering and incorporating causality into RL, which hinders the rapid\ndevelopment of causal RL. In this paper, we consider explicitly modeling the\ngeneration process of states with the causal graphical model, based on which we\naugment the policy. We formulate the causal structure updating into the RL\ninteraction process with active intervention learning of the environment. To\noptimize the derived objective, we propose a framework with theoretical\nperformance guarantees that alternates between two steps: using interventions\nfor causal structure learning during exploration and using the learned causal\nstructure for policy guidance during exploitation. Due to the lack of public\nbenchmarks that allow direct intervention in the state space, we design the\nroot cause localization task in our simulated fault alarm environment and then\nempirically show the effectiveness and robustness of the proposed method\nagainst state-of-the-art baselines. Theoretical analysis shows that our\nperformance improvement attributes to the virtuous cycle of causal-guided\npolicy learning and causal structure learning, which aligns with our\nexperimental results. Codes are available at\nhttps://github.com/DMIRLAB-Group/FaultAlarm_RL.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by Science China Information Sciences",
    "pdf_url": "http://arxiv.org/pdf/2402.04869v2",
    "published_date": "2024-02-07 14:09:34 UTC",
    "updated_date": "2025-04-24 07:58:03 UTC"
  },
  {
    "arxiv_id": "2402.06673v1",
    "title": "Advancing Explainable AI Toward Human-Like Intelligence: Forging the Path to Artificial Brain",
    "authors": [
      "Yongchen Zhou",
      "Richard Jiang"
    ],
    "abstract": "The intersection of Artificial Intelligence (AI) and neuroscience in\nExplainable AI (XAI) is pivotal for enhancing transparency and interpretability\nin complex decision-making processes. This paper explores the evolution of XAI\nmethodologies, ranging from feature-based to human-centric approaches, and\ndelves into their applications in diverse domains, including healthcare and\nfinance. The challenges in achieving explainability in generative models,\nensuring responsible AI practices, and addressing ethical implications are\ndiscussed. The paper further investigates the potential convergence of XAI with\ncognitive sciences, the development of emotionally intelligent AI, and the\nquest for Human-Like Intelligence (HLI) in AI systems. As AI progresses towards\nArtificial General Intelligence (AGI), considerations of consciousness, ethics,\nand societal impact become paramount. The ongoing pursuit of deciphering the\nmysteries of the brain with AI and the quest for HLI represent transformative\nendeavors, bridging technical advancements with multidisciplinary explorations\nof human cognition.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.06673v1",
    "published_date": "2024-02-07 14:09:11 UTC",
    "updated_date": "2024-02-07 14:09:11 UTC"
  },
  {
    "arxiv_id": "2402.04858v2",
    "title": "CodeIt: Self-Improving Language Models with Prioritized Hindsight Replay",
    "authors": [
      "Natasha Butt",
      "Blazej Manczak",
      "Auke Wiggers",
      "Corrado Rainone",
      "David W. Zhang",
      "Michaël Defferrard",
      "Taco Cohen"
    ],
    "abstract": "Large language models are increasingly solving tasks that are commonly\nbelieved to require human-level reasoning ability. However, these models still\nperform very poorly on benchmarks of general intelligence such as the\nAbstraction and Reasoning Corpus (ARC). In this paper, we approach ARC as a\nprogramming-by-examples problem, and introduce a novel and scalable method for\nlanguage model self-improvement called Code Iteration (CodeIt). Our method\niterates between 1) program sampling and hindsight relabeling, and 2) learning\nfrom prioritized experience replay. By relabeling the goal of an episode (i.e.,\nthe target program output given input) to the realized output produced by the\nsampled program, our method effectively deals with the extreme sparsity of\nrewards in program synthesis. Applying CodeIt to the ARC dataset, we\ndemonstrate that prioritized hindsight replay, along with pre-training and\ndata-augmentation, leads to successful inter-task generalization. CodeIt is the\nfirst neuro-symbolic approach that scales to the full ARC evaluation dataset.\nOur method solves 15% of ARC evaluation tasks, achieving state-of-the-art\nperformance and outperforming existing neural and symbolic baselines. Our code\nis available at https://github.com/Qualcomm-AI-research/codeit .",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "ICML'24 camera-ready version",
    "pdf_url": "http://arxiv.org/pdf/2402.04858v2",
    "published_date": "2024-02-07 13:55:27 UTC",
    "updated_date": "2024-07-01 10:03:33 UTC"
  },
  {
    "arxiv_id": "2402.04856v4",
    "title": "Explaining Learned Reward Functions with Counterfactual Trajectories",
    "authors": [
      "Jan Wehner",
      "Frans Oliehoek",
      "Luciano Cavalcante Siebert"
    ],
    "abstract": "Learning rewards from human behaviour or feedback is a promising approach to\naligning AI systems with human values but fails to consistently extract correct\nreward functions. Interpretability tools could enable users to understand and\nevaluate possible flaws in learned reward functions. We propose Counterfactual\nTrajectory Explanations (CTEs) to interpret reward functions in reinforcement\nlearning by contrasting an original with a counterfactual partial trajectory\nand the rewards they each receive. We derive six quality criteria for CTEs and\npropose a novel Monte-Carlo-based algorithm for generating CTEs that optimises\nthese quality criteria. Finally, we measure how informative the generated\nexplanations are to a proxy-human model by training it on CTEs. CTEs are\ndemonstrably informative for the proxy-human model, increasing the similarity\nbetween its predictions and the reward function on unseen trajectories.\nFurther, it learns to accurately judge differences in rewards between\ntrajectories and generalises to out-of-distribution examples. Although CTEs do\nnot lead to a perfect understanding of the reward, our method, and more\ngenerally the adaptation of XAI methods, are presented as a fruitful approach\nfor interpreting learned reward functions.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.04856v4",
    "published_date": "2024-02-07 13:54:38 UTC",
    "updated_date": "2024-10-15 11:19:53 UTC"
  },
  {
    "arxiv_id": "2402.04838v5",
    "title": "PaDeLLM-NER: Parallel Decoding in Large Language Models for Named Entity Recognition",
    "authors": [
      "Jinghui Lu",
      "Ziwei Yang",
      "Yanjie Wang",
      "Xuejing Liu",
      "Brian Mac Namee",
      "Can Huang"
    ],
    "abstract": "In this study, we aim to reduce generation latency for Named Entity\nRecognition (NER) with Large Language Models (LLMs). The main cause of high\nlatency in LLMs is the sequential decoding process, which autoregressively\ngenerates all labels and mentions for NER, significantly increase the sequence\nlength. To this end, we introduce Parallel Decoding in LLM for NE}\n(PaDeLLM-NER), a approach that integrates seamlessly into existing generative\nmodel frameworks without necessitating additional modules or architectural\nmodifications. PaDeLLM-NER allows for the simultaneous decoding of all\nmentions, thereby reducing generation latency. Experiments reveal that\nPaDeLLM-NER significantly increases inference speed that is 1.76 to 10.22 times\nfaster than the autoregressive approach for both English and Chinese.\nSimultaneously it maintains the quality of predictions as evidenced by the\nperformance that is on par with the state-of-the-art across various datasets.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to Neurips2024",
    "pdf_url": "http://arxiv.org/pdf/2402.04838v5",
    "published_date": "2024-02-07 13:39:38 UTC",
    "updated_date": "2024-11-21 06:52:02 UTC"
  },
  {
    "arxiv_id": "2402.04836v3",
    "title": "On the Completeness of Invariant Geometric Deep Learning Models",
    "authors": [
      "Zian Li",
      "Xiyuan Wang",
      "Shijia Kang",
      "Muhan Zhang"
    ],
    "abstract": "Invariant models, one important class of geometric deep learning models, are\ncapable of generating meaningful geometric representations by leveraging\ninformative geometric features in point clouds. These models are characterized\nby their simplicity, good experimental results and computational efficiency.\nHowever, their theoretical expressive power still remains unclear, restricting\na deeper understanding of the potential of such models. In this work, we\nconcentrate on characterizing the theoretical expressiveness of a wide range of\ninvariant models under fully-connected conditions. We first rigorously\ncharacterize the expressiveness of the most classic invariant model,\nmessage-passing neural networks incorporating distance (DisGNN), restricting\nits unidentifiable cases to be only highly symmetric point clouds. We then\nprove that GeoNGNN, the geometric counterpart of one of the simplest subgraph\ngraph neural networks, can effectively break these corner cases' symmetry and\nthus achieve E(3)-completeness. By leveraging GeoNGNN as a theoretical tool, we\nfurther prove that: 1) most subgraph GNNs developed in traditional graph\nlearning can be seamlessly extended to geometric scenarios with\nE(3)-completeness; 2) DimeNet, GemNet and SphereNet, three well-established\ninvariant models, are also all capable of achieving E(3)-completeness. Our\ntheoretical results fill the gap in the expressive power of invariant models,\ncontributing to a rigorous and comprehensive understanding of their\ncapabilities.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "The Thirteenth International Conference on Learning Representations",
    "pdf_url": "http://arxiv.org/pdf/2402.04836v3",
    "published_date": "2024-02-07 13:32:53 UTC",
    "updated_date": "2025-03-07 15:55:55 UTC"
  },
  {
    "arxiv_id": "2402.04832v1",
    "title": "Structured d-DNNF Is Not Closed Under Negation",
    "authors": [
      "Harry Vinall-Smeeth"
    ],
    "abstract": "Both structured d-DNNF and SDD can be exponentially more succinct than OBDD.\nMoreover, SDD is essentially as tractable as OBDD. But this has left two\nimportant open questions. Firstly, does OBDD support more tractable\ntransformations than structured d-DNNF? And secondly, is structured d-DNNF more\nsuccinct than SDD? In this paper, we answer both questions in the affirmative.\nFor the first question we show that, unlike OBDD, structured d-DNNF does not\nsupport polytime negation, disjunction, or existential quantification\noperations. As a corollary, we deduce that there are functions with an\nequivalent polynomial-sized structured d-DNNF but with no such representation\nas an SDD, thus answering the second question. We also lift this second result\nto arithmetic circuits (AC) to show a succinctness gap between PSDD and the\nmonotone AC analogue to structured d-DNNF.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.04832v1",
    "published_date": "2024-02-07 13:31:59 UTC",
    "updated_date": "2024-02-07 13:31:59 UTC"
  },
  {
    "arxiv_id": "2402.05151v1",
    "title": "CrashFormer: A Multimodal Architecture to Predict the Risk of Crash",
    "authors": [
      "Amin Karimi Monsefi",
      "Pouya Shiri",
      "Ahmad Mohammadshirazi",
      "Nastaran Karimi Monsefi",
      "Ron Davies",
      "Sobhan Moosavi",
      "Rajiv Ramnath"
    ],
    "abstract": "Reducing traffic accidents is a crucial global public safety concern.\nAccident prediction is key to improving traffic safety, enabling proactive\nmeasures to be taken before a crash occurs, and informing safety policies,\nregulations, and targeted interventions. Despite numerous studies on accident\nprediction over the past decades, many have limitations in terms of\ngeneralizability, reproducibility, or feasibility for practical use due to\ninput data or problem formulation. To address existing shortcomings, we propose\nCrashFormer, a multi-modal architecture that utilizes comprehensive (but\nrelatively easy to obtain) inputs such as the history of accidents, weather\ninformation, map images, and demographic information. The model predicts the\nfuture risk of accidents on a reasonably acceptable cadence (i.e., every six\nhours) for a geographical location of 5.161 square kilometers. CrashFormer is\ncomposed of five components: a sequential encoder to utilize historical\naccidents and weather data, an image encoder to use map imagery data, a raw\ndata encoder to utilize demographic information, a feature fusion module for\naggregating the encoded features, and a classifier that accepts the aggregated\ndata and makes predictions accordingly. Results from extensive real-world\nexperiments in 10 major US cities show that CrashFormer outperforms\nstate-of-the-art sequential and non-sequential models by 1.8% in F1-score on\naverage when using ``sparse'' input data.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "The paper is accepted In 1st ACM SIGSPATIAL International Workshop on\n  Advances in Urban-AI (UrbanAI 23), November 13, 2023, Hamburg, Germany",
    "pdf_url": "http://arxiv.org/pdf/2402.05151v1",
    "published_date": "2024-02-07 13:09:23 UTC",
    "updated_date": "2024-02-07 13:09:23 UTC"
  },
  {
    "arxiv_id": "2402.04792v2",
    "title": "Direct Language Model Alignment from Online AI Feedback",
    "authors": [
      "Shangmin Guo",
      "Biao Zhang",
      "Tianlin Liu",
      "Tianqi Liu",
      "Misha Khalman",
      "Felipe Llinares",
      "Alexandre Rame",
      "Thomas Mesnard",
      "Yao Zhao",
      "Bilal Piot",
      "Johan Ferret",
      "Mathieu Blondel"
    ],
    "abstract": "Direct alignment from preferences (DAP) methods, such as DPO, have recently\nemerged as efficient alternatives to reinforcement learning from human feedback\n(RLHF), that do not require a separate reward model. However, the preference\ndatasets used in DAP methods are usually collected ahead of training and never\nupdated, thus the feedback is purely offline. Moreover, responses in these\ndatasets are often sampled from a language model distinct from the one being\naligned, and since the model evolves over training, the alignment phase is\ninevitably off-policy. In this study, we posit that online feedback is key and\nimproves DAP methods. Our method, online AI feedback (OAIF), uses an LLM as\nannotator: on each training iteration, we sample two responses from the current\nmodel and prompt the LLM annotator to choose which one is preferred, thus\nproviding online feedback. Despite its simplicity, we demonstrate via human\nevaluation in several tasks that OAIF outperforms both offline DAP and RLHF\nmethods. We further show that the feedback leveraged in OAIF is easily\ncontrollable, via instruction prompts to the LLM annotator.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "18 pages, 9 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2402.04792v2",
    "published_date": "2024-02-07 12:31:13 UTC",
    "updated_date": "2024-02-29 20:59:17 UTC"
  },
  {
    "arxiv_id": "2402.04788v3",
    "title": "MLLM-as-a-Judge: Assessing Multimodal LLM-as-a-Judge with Vision-Language Benchmark",
    "authors": [
      "Dongping Chen",
      "Ruoxi Chen",
      "Shilin Zhang",
      "Yinuo Liu",
      "Yaochen Wang",
      "Huichi Zhou",
      "Qihui Zhang",
      "Yao Wan",
      "Pan Zhou",
      "Lichao Sun"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) have gained significant attention\nrecently, showing remarkable potential in artificial general intelligence.\nHowever, assessing the utility of MLLMs presents considerable challenges,\nprimarily due to the absence of multimodal benchmarks that align with human\npreferences. Drawing inspiration from the concept of LLM-as-a-Judge within\nLLMs, this paper introduces a novel benchmark, termed MLLM-as-a-Judge, to\nassess the ability of MLLMs in assisting judges across diverse modalities,\nencompassing three distinct tasks: Scoring Evaluation, Pair Comparison, and\nBatch Ranking. Our study reveals that, while MLLMs demonstrate remarkable\nhuman-like discernment in Pair Comparison, there is a significant divergence\nfrom human preferences in Scoring Evaluation and Batch Ranking. Furthermore, a\ncloser examination reveals persistent challenges in the judgment capacities of\nLLMs, including diverse biases, hallucinatory responses, and inconsistencies in\njudgment, even in advanced models such as GPT-4V. These findings emphasize the\npressing need for enhancements and further research efforts to be undertaken\nbefore regarding MLLMs as fully reliable evaluators. In light of this, we\nadvocate for additional efforts dedicated to supporting the continuous\ndevelopment within the domain of MLLM functioning as judges. The code and\ndataset are publicly available at our project homepage:\n\\url{https://mllm-judge.github.io/}.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "ICML 2024 (Oral)",
    "pdf_url": "http://arxiv.org/pdf/2402.04788v3",
    "published_date": "2024-02-07 12:28:32 UTC",
    "updated_date": "2024-06-11 06:21:46 UTC"
  },
  {
    "arxiv_id": "2402.04779v1",
    "title": "StableMask: Refining Causal Masking in Decoder-only Transformer",
    "authors": [
      "Qingyu Yin",
      "Xuzheng He",
      "Xiang Zhuang",
      "Yu Zhao",
      "Jianhua Yao",
      "Xiaoyu Shen",
      "Qiang Zhang"
    ],
    "abstract": "The decoder-only Transformer architecture with causal masking and relative\nposition encoding (RPE) has become the de facto choice in language modeling.\nDespite its exceptional performance across various tasks, we have identified\ntwo limitations: First, it requires all attention scores to be non-zero and sum\nup to 1, even if the current embedding has sufficient self-contained\ninformation. This compels the model to assign disproportional excessive\nattention to specific tokens. Second, RPE-based Transformers are not universal\napproximators due to their limited capacity at encoding absolute positional\ninformation, which limits their application in position-critical tasks. In this\nwork, we propose StableMask: a parameter-free method to address both\nlimitations by refining the causal mask. It introduces pseudo-attention values\nto balance attention distributions and encodes absolute positional information\nvia a progressively decreasing mask ratio. StableMask's effectiveness is\nvalidated both theoretically and empirically, showing significant enhancements\nin language models with parameter sizes ranging from 71M to 1.4B across diverse\ndatasets and encoding methods. We further show that it naturally supports (1)\nefficient extrapolation without special tricks such as StreamingLLM and (2)\neasy integration with existing attention optimization techniques.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2402.04779v1",
    "published_date": "2024-02-07 12:01:02 UTC",
    "updated_date": "2024-02-07 12:01:02 UTC"
  },
  {
    "arxiv_id": "2402.04763v1",
    "title": "Emergence of specialized Collective Behaviors in Evolving Heterogeneous Swarms",
    "authors": [
      "Fuda van Diggelen",
      "Matteo De Carlo",
      "Nicolas Cambier",
      "Eliseo Ferrante",
      "A. E. Eiben"
    ],
    "abstract": "Natural groups of animals, such as swarms of social insects, exhibit\nastonishing degrees of task specialization, useful to address complex tasks and\nto survive. This is supported by phenotypic plasticity: individuals sharing the\nsame genotype that is expressed differently for different classes of\nindividuals, each specializing in one task. In this work, we evolve a swarm of\nsimulated robots with phenotypic plasticity to study the emergence of\nspecialized collective behavior during an emergent perception task. Phenotypic\nplasticity is realized in the form of heterogeneity of behavior by dividing the\ngenotype into two components, with one different neural network controller\nassociated to each component. The whole genotype, expressing the behavior of\nthe whole group through the two components, is subject to evolution with a\nsingle fitness function. We analyse the obtained behaviors and use the insights\nprovided by these results to design an online regulatory mechanism. Our\nexperiments show three main findings: 1) The sub-groups evolve distinct\nemergent behaviors. 2) The effectiveness of the whole swarm depends on the\ninteraction between the two sub-groups, leading to a more robust performance\nthan with singular sub-group behavior. 3) The online regulatory mechanism\nenhances overall performance and scalability.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.04763v1",
    "published_date": "2024-02-07 11:26:53 UTC",
    "updated_date": "2024-02-07 11:26:53 UTC"
  },
  {
    "arxiv_id": "2402.05149v1",
    "title": "FlowPG: Action-constrained Policy Gradient with Normalizing Flows",
    "authors": [
      "Janaka Chathuranga Brahmanage",
      "Jiajing Ling",
      "Akshat Kumar"
    ],
    "abstract": "Action-constrained reinforcement learning (ACRL) is a popular approach for\nsolving safety-critical and resource-allocation related decision making\nproblems. A major challenge in ACRL is to ensure agent taking a valid action\nsatisfying constraints in each RL step. Commonly used approach of using a\nprojection layer on top of the policy network requires solving an optimization\nprogram which can result in longer training time, slow convergence, and zero\ngradient problem. To address this, first we use a normalizing flow model to\nlearn an invertible, differentiable mapping between the feasible action space\nand the support of a simple distribution on a latent variable, such as\nGaussian. Second, learning the flow model requires sampling from the feasible\naction space, which is also challenging. We develop multiple methods, based on\nHamiltonian Monte-Carlo and probabilistic sentential decision diagrams for such\naction sampling for convex and non-convex constraints. Third, we integrate the\nlearned normalizing flow with the DDPG algorithm. By design, a well-trained\nnormalizing flow will transform policy output into a valid action without\nrequiring an optimization solver. Empirically, our approach results in\nsignificantly fewer constraint violations (upto an order-of-magnitude for\nseveral instances) and is multiple times faster on a variety of continuous\ncontrol tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05149v1",
    "published_date": "2024-02-07 11:11:46 UTC",
    "updated_date": "2024-02-07 11:11:46 UTC"
  },
  {
    "arxiv_id": "2402.05148v1",
    "title": "Cost Optimized Scheduling in Modular Electrolysis Plants",
    "authors": [
      "Vincent Henkel",
      "Maximilian Kilthau",
      "Felix Gehlhoff",
      "Lukas Wagner",
      "Alexander Fay"
    ],
    "abstract": "In response to the global shift towards renewable energy resources, the\nproduction of green hydrogen through electrolysis is emerging as a promising\nsolution. Modular electrolysis plants, designed for flexibility and\nscalability, offer a dynamic response to the increasing demand for hydrogen\nwhile accommodating the fluctuations inherent in renewable energy sources.\nHowever, optimizing their operation is challenging, especially when a large\nnumber of electrolysis modules needs to be coordinated, each with potentially\ndifferent characteristics.\n  To address these challenges, this paper presents a decentralized scheduling\nmodel to optimize the operation of modular electrolysis plants using the\nAlternating Direction Method of Multipliers. The model aims to balance hydrogen\nproduction with fluctuating demand, to minimize the marginal Levelized Cost of\nHydrogen (mLCOH), and to ensure adaptability to operational disturbances. A\ncase study validates the accuracy of the model in calculating mLCOH values\nunder nominal load conditions and demonstrates its responsiveness to dynamic\nchanges, such as electrolyzer module malfunctions and scale-up scenarios.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05148v1",
    "published_date": "2024-02-07 09:41:39 UTC",
    "updated_date": "2024-02-07 09:41:39 UTC"
  },
  {
    "arxiv_id": "2402.04699v2",
    "title": "Breaking Free: How to Hack Safety Guardrails in Black-Box Diffusion Models!",
    "authors": [
      "Shashank Kotyan",
      "Po-Yuan Mao",
      "Pin-Yu Chen",
      "Danilo Vasconcellos Vargas"
    ],
    "abstract": "Deep neural networks can be exploited using natural adversarial samples,\nwhich do not impact human perception. Current approaches often rely on deep\nneural networks' white-box nature to generate these adversarial samples or\nsynthetically alter the distribution of adversarial samples compared to the\ntraining distribution. In contrast, we propose EvoSeed, a novel evolutionary\nstrategy-based algorithmic framework for generating photo-realistic natural\nadversarial samples. Our EvoSeed framework uses auxiliary Conditional Diffusion\nand Classifier models to operate in a black-box setting. We employ CMA-ES to\noptimize the search for an initial seed vector, which, when processed by the\nConditional Diffusion Model, results in the natural adversarial sample\nmisclassified by the Classifier Model. Experiments show that generated\nadversarial images are of high image quality, raising concerns about generating\nharmful content bypassing safety classifiers. Our research opens new avenues to\nunderstanding the limitations of current safety mechanisms and the risk of\nplausible attacks against classifier systems using image generation. Project\nWebsite can be accessed at: https://shashankkotyan.github.io/EvoSeed.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.04699v2",
    "published_date": "2024-02-07 09:39:29 UTC",
    "updated_date": "2024-05-23 02:35:45 UTC"
  },
  {
    "arxiv_id": "2402.04678v3",
    "title": "FaithLM: Towards Faithful Explanations for Large Language Models",
    "authors": [
      "Yu-Neng Chuang",
      "Guanchu Wang",
      "Chia-Yuan Chang",
      "Ruixiang Tang",
      "Shaochen Zhong",
      "Fan Yang",
      "Mengnan Du",
      "Xuanting Cai",
      "Xia Hu"
    ],
    "abstract": "Large Language Models (LLMs) have become proficient in addressing complex\ntasks by leveraging their extensive internal knowledge and reasoning\ncapabilities. However, the black-box nature of these models complicates the\ntask of explaining their decision-making processes. While recent advancements\ndemonstrate the potential of leveraging LLMs to self-explain their predictions\nthrough natural language (NL) explanations, their explanations may not\naccurately reflect the LLMs' decision-making process due to a lack of fidelity\noptimization on the derived explanations. Measuring the fidelity of NL\nexplanations is a challenging issue, as it is difficult to manipulate the input\ncontext to mask the semantics of these explanations. To this end, we introduce\nFaithLM to explain the decision of LLMs with NL explanations. Specifically,\nFaithLM designs a method for evaluating the fidelity of NL explanations by\nincorporating the contrary explanations to the query process. Moreover, FaithLM\nconducts an iterative process to improve the fidelity of derived explanations.\nExperiment results on three datasets from multiple domains demonstrate that\nFaithLM can significantly improve the fidelity of derived explanations, which\nalso provides a better alignment with the ground-truth explanations.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.04678v3",
    "published_date": "2024-02-07 09:09:14 UTC",
    "updated_date": "2024-06-26 07:43:11 UTC"
  },
  {
    "arxiv_id": "2402.04676v3",
    "title": "Group Distributionally Robust Dataset Distillation with Risk Minimization",
    "authors": [
      "Saeed Vahidian",
      "Mingyu Wang",
      "Jianyang Gu",
      "Vyacheslav Kungurtsev",
      "Wei Jiang",
      "Yiran Chen"
    ],
    "abstract": "Dataset distillation (DD) has emerged as a widely adopted technique for\ncrafting a synthetic dataset that captures the essential information of a\ntraining dataset, facilitating the training of accurate neural models. Its\napplications span various domains, including transfer learning, federated\nlearning, and neural architecture search. The most popular methods for\nconstructing the synthetic data rely on matching the convergence properties of\ntraining the model with the synthetic dataset and the training dataset.\nHowever, using the empirical loss as the criterion must be thought of as\nauxiliary in the same sense that the training set is an approximate substitute\nfor the population distribution, and the latter is the data of interest. Yet\ndespite its popularity, an aspect that remains unexplored is the relationship\nof DD to its generalization, particularly across uncommon subgroups. That is,\nhow can we ensure that a model trained on the synthetic dataset performs well\nwhen faced with samples from regions with low population density? Here, the\nrepresentativeness and coverage of the dataset become salient over the\nguaranteed training error at inference. Drawing inspiration from\ndistributionally robust optimization, we introduce an algorithm that combines\nclustering with the minimization of a risk measure on the loss to conduct DD.\nWe provide a theoretical rationale for our approach and demonstrate its\neffective generalization and robustness across subgroups through numerical\nexperiments. The source code is available at\nhttps://github.com/Mming11/RobustDatasetDistillation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2402.04676v3",
    "published_date": "2024-02-07 09:03:04 UTC",
    "updated_date": "2025-02-01 19:20:54 UTC"
  },
  {
    "arxiv_id": "2402.05146v1",
    "title": "Compressing Deep Reinforcement Learning Networks with a Dynamic Structured Pruning Method for Autonomous Driving",
    "authors": [
      "Wensheng Su",
      "Zhenni Li",
      "Minrui Xu",
      "Jiawen Kang",
      "Dusit Niyato",
      "Shengli Xie"
    ],
    "abstract": "Deep reinforcement learning (DRL) has shown remarkable success in complex\nautonomous driving scenarios. However, DRL models inevitably bring high memory\nconsumption and computation, which hinders their wide deployment in\nresource-limited autonomous driving devices. Structured Pruning has been\nrecognized as a useful method to compress and accelerate DRL models, but it is\nstill challenging to estimate the contribution of a parameter (i.e., neuron) to\nDRL models. In this paper, we introduce a novel dynamic structured pruning\napproach that gradually removes a DRL model's unimportant neurons during the\ntraining stage. Our method consists of two steps, i.e. training DRL models with\na group sparse regularizer and removing unimportant neurons with a dynamic\npruning threshold. To efficiently train the DRL model with a small number of\nimportant neurons, we employ a neuron-importance group sparse regularizer. In\ncontrast to conventional regularizers, this regularizer imposes a penalty on\nredundant groups of neurons that do not significantly influence the output of\nthe DRL model. Furthermore, we design a novel structured pruning strategy to\ndynamically determine the pruning threshold and gradually remove unimportant\nneurons with a binary mask. Therefore, our method can remove not only redundant\ngroups of neurons of the DRL model but also achieve high and robust\nperformance. Experimental results show that the proposed method is competitive\nwith existing DRL pruning methods on discrete control environments (i.e.,\nCartPole-v1 and LunarLander-v2) and MuJoCo continuous environments (i.e.,\nHopper-v3 and Walker2D-v3). Specifically, our method effectively compresses\n$93\\%$ neurons and $96\\%$ weights of the DRL model in four challenging DRL\nenvironments with slight accuracy degradation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05146v1",
    "published_date": "2024-02-07 09:00:30 UTC",
    "updated_date": "2024-02-07 09:00:30 UTC"
  },
  {
    "arxiv_id": "2402.04660v2",
    "title": "Adversarial Robustness Through Artifact Design",
    "authors": [
      "Tsufit Shua",
      "Liron David",
      "Mahmood Sharif"
    ],
    "abstract": "Adversarial examples arose as a challenge for machine learning. To hinder\nthem, most defenses alter how models are trained (e.g., adversarial training)\nor inference is made (e.g., randomized smoothing). Still, while these\napproaches markedly improve models' adversarial robustness, models remain\nhighly susceptible to adversarial examples. Identifying that, in certain\ndomains such as traffic-sign recognition, objects are implemented per standards\nspecifying how artifacts (e.g., signs) should be designed, we propose a novel\napproach for improving adversarial robustness. Specifically, we offer a method\nto redefine standards, making minor changes to existing ones, to defend against\nadversarial examples. We formulate the problem of artifact design as a robust\noptimization problem, and propose gradient-based and greedy search methods to\nsolve it. We evaluated our approach in the domain of traffic-sign recognition,\nallowing it to alter traffic-sign pictograms (i.e., symbols within the signs)\nand their colors. We found that, combined with adversarial training, our\napproach led to up to 25.18\\% higher robust accuracy compared to\nstate-of-the-art methods against two adversary types, while further increasing\naccuracy on benign inputs. Notably, a user study we conducted showed that\ntraffic signs produced by our approach are also easily recognizable by human\nsubjects.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.04660v2",
    "published_date": "2024-02-07 08:49:33 UTC",
    "updated_date": "2024-10-27 16:09:59 UTC"
  },
  {
    "arxiv_id": "2402.04644v2",
    "title": "LEVI: Generalizable Fine-tuning via Layer-wise Ensemble of Different Views",
    "authors": [
      "Yuji Roh",
      "Qingyun Liu",
      "Huan Gui",
      "Zhe Yuan",
      "Yujin Tang",
      "Steven Euijong Whang",
      "Liang Liu",
      "Shuchao Bi",
      "Lichan Hong",
      "Ed H. Chi",
      "Zhe Zhao"
    ],
    "abstract": "Fine-tuning is becoming widely used for leveraging the power of pre-trained\nfoundation models in new downstream tasks. While there are many successes of\nfine-tuning on various tasks, recent studies have observed challenges in the\ngeneralization of fine-tuned models to unseen distributions (i.e.,\nout-of-distribution; OOD). To improve OOD generalization, some previous studies\nidentify the limitations of fine-tuning data and regulate fine-tuning to\npreserve the general representation learned from pre-training data. However,\npotential limitations in the pre-training data and models are often ignored. In\nthis paper, we contend that overly relying on the pre-trained representation\nmay hinder fine-tuning from learning essential representations for downstream\ntasks and thus hurt its OOD generalization. It can be especially catastrophic\nwhen new tasks are from different (sub)domains compared to pre-training data.\nTo address the issues in both pre-training and fine-tuning data, we propose a\nnovel generalizable fine-tuning method LEVI (Layer-wise Ensemble of different\nVIews), where the pre-trained model is adaptively ensembled layer-wise with a\nsmall task-specific model, while preserving its efficiencies. By combining two\ncomplementing models, LEVI effectively suppresses problematic features in both\nthe fine-tuning data and pre-trained model and preserves useful features for\nnew tasks. Broad experiments with large language and vision models show that\nLEVI greatly improves fine-tuning generalization via emphasizing different\nviews from fine-tuning data and pre-trained features.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "In Proceedings of the 41st International Conference on Machine\n  Learning (ICML), 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.04644v2",
    "published_date": "2024-02-07 08:16:40 UTC",
    "updated_date": "2024-06-18 21:56:54 UTC"
  },
  {
    "arxiv_id": "2402.05144v2",
    "title": "A Bandit Approach with Evolutionary Operators for Model Selection",
    "authors": [
      "Margaux Brégère",
      "Julie Keisler"
    ],
    "abstract": "This work formulates model selection as an infinite-armed bandit problem,\nnamely, a problem in which a decision maker iteratively selects one of an\ninfinite number of fixed choices (i.e., arms) when the properties of each\nchoice are only partially known at the time of allocation and may become better\nunderstood over time, via the attainment of rewards.Here, the arms are machine\nlearning models to train and selecting an arm corresponds to a partial training\nof the model (resource allocation).The reward is the accuracy of the selected\nmodel after its partial training.We aim to identify the best model at the end\nof a finite number of resource allocations and thus consider the best arm\nidentification setup. We propose the algorithm Mutant-UCB that incorporates\noperators from evolutionary algorithms into the UCB-E (Upper Confidence Bound\nExploration) bandit algorithm introduced by Audiber et al.Tests carried out on\nthree open source image classification data sets attest to the relevance of\nthis novel combining approach, which outperforms the state-of-the-art for a\nfixed budget.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG",
      "math.OC"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05144v2",
    "published_date": "2024-02-07 08:01:45 UTC",
    "updated_date": "2024-06-19 07:38:05 UTC"
  },
  {
    "arxiv_id": "2402.10937v1",
    "title": "A Lightweight Inception Boosted U-Net Neural Network for Routability Prediction",
    "authors": [
      "Hailiang Li",
      "Yan Huo",
      "Yan Wang",
      "Xu Yang",
      "Miaohui Hao",
      "Xiao Wang"
    ],
    "abstract": "As the modern CPU, GPU, and NPU chip design complexity and transistor counts\nkeep increasing, and with the relentless shrinking of semiconductor technology\nnodes to nearly 1 nanometer, the placement and routing have gradually become\nthe two most pivotal processes in modern very-large-scale-integrated (VLSI)\ncircuit back-end design. How to evaluate routability efficiently and accurately\nin advance (at the placement and global routing stages) has grown into a\ncrucial research area in the field of artificial intelligence (AI) assisted\nelectronic design automation (EDA). In this paper, we propose a novel U-Net\nvariant model boosted by an Inception embedded module to predict Routing\nCongestion (RC) and Design Rule Checking (DRC) hotspots. Experimental results\non the recently published CircuitNet dataset benchmark show that our proposed\nmethod achieves up to 5% (RC) and 20% (DRC) rate reduction in terms of\nAvg-NRMSE (Average Normalized Root Mean Square Error) compared to the classic\narchitecture. Furthermore, our approach consistently outperforms the prior\nmodel on the SSIM (Structural Similarity Index Measure) metric.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.CE",
      "cs.GT",
      "cs.LG"
    ],
    "primary_category": "cs.AR",
    "comment": "The paper is submitted to the International Symposium of EDA (2024,\n  XiAn, China)",
    "pdf_url": "http://arxiv.org/pdf/2402.10937v1",
    "published_date": "2024-02-07 07:32:03 UTC",
    "updated_date": "2024-02-07 07:32:03 UTC"
  },
  {
    "arxiv_id": "2402.04627v1",
    "title": "SPARQL Generation: an analysis on fine-tuning OpenLLaMA for Question Answering over a Life Science Knowledge Graph",
    "authors": [
      "Julio C. Rangel",
      "Tarcisio Mendes de Farias",
      "Ana Claudia Sima",
      "Norio Kobayashi"
    ],
    "abstract": "The recent success of Large Language Models (LLM) in a wide range of Natural\nLanguage Processing applications opens the path towards novel Question\nAnswering Systems over Knowledge Graphs leveraging LLMs. However, one of the\nmain obstacles preventing their implementation is the scarcity of training data\nfor the task of translating questions into corresponding SPARQL queries,\nparticularly in the case of domain-specific KGs. To overcome this challenge, in\nthis study, we evaluate several strategies for fine-tuning the OpenLlama LLM\nfor question answering over life science knowledge graphs. In particular, we\npropose an end-to-end data augmentation approach for extending a set of\nexisting queries over a given knowledge graph towards a larger dataset of\nsemantically enriched question-to-SPARQL query pairs, enabling fine-tuning even\nfor datasets where these pairs are scarce. In this context, we also investigate\nthe role of semantic \"clues\" in the queries, such as meaningful variable names\nand inline comments. Finally, we evaluate our approach over the real-world Bgee\ngene expression knowledge graph and we show that semantic clues can improve\nmodel performance by up to 33% compared to a baseline with random variable\nnames and no comments included.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.DB",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "comment": "To appear in Proceedings of SWAT4HCLS 2024: Semantic Web Tools and\n  Applications for Healthcare and Life Sciences",
    "pdf_url": "http://arxiv.org/pdf/2402.04627v1",
    "published_date": "2024-02-07 07:24:01 UTC",
    "updated_date": "2024-02-07 07:24:01 UTC"
  },
  {
    "arxiv_id": "2402.04617v2",
    "title": "InfLLM: Training-Free Long-Context Extrapolation for LLMs with an Efficient Context Memory",
    "authors": [
      "Chaojun Xiao",
      "Pengle Zhang",
      "Xu Han",
      "Guangxuan Xiao",
      "Yankai Lin",
      "Zhengyan Zhang",
      "Zhiyuan Liu",
      "Maosong Sun"
    ],
    "abstract": "Large language models (LLMs) have emerged as a cornerstone in real-world\napplications with lengthy streaming inputs (e.g., LLM-driven agents). However,\nexisting LLMs, pre-trained on sequences with a restricted maximum length,\ncannot process longer sequences due to the out-of-domain and distraction\nissues. Common solutions often involve continual pre-training on longer\nsequences, which will introduce expensive computational overhead and\nuncontrollable change in model capabilities. In this paper, we unveil the\nintrinsic capacity of LLMs for understanding extremely long sequences without\nany fine-tuning. To this end, we introduce a training-free memory-based method,\nInfLLM. Specifically, InfLLM stores distant contexts into additional memory\nunits and employs an efficient mechanism to lookup token-relevant units for\nattention computation. Thereby, InfLLM allows LLMs to efficiently process long\nsequences with a limited context window and well capture long-distance\ndependencies. Without any training, InfLLM enables LLMs that are pre-trained on\nsequences consisting of a few thousand tokens to achieve comparable performance\nwith competitive baselines that continually train these LLMs on long sequences.\nEven when the sequence length is scaled to $1,024$K, InfLLM still effectively\ncaptures long-distance dependencies. Our code can be found in\n\\url{https://github.com/thunlp/InfLLM}.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.04617v2",
    "published_date": "2024-02-07 06:50:42 UTC",
    "updated_date": "2024-05-28 12:05:12 UTC"
  },
  {
    "arxiv_id": "2402.04616v3",
    "title": "Beyond Answers: Transferring Reasoning Capabilities to Smaller LLMs Using Multi-Teacher Knowledge Distillation",
    "authors": [
      "Yijun Tian",
      "Yikun Han",
      "Xiusi Chen",
      "Wei Wang",
      "Nitesh V. Chawla"
    ],
    "abstract": "Transferring the reasoning capability from stronger large language models\n(LLMs) to smaller ones has been quite appealing, as smaller LLMs are more\nflexible to deploy with less expense. Among the existing solutions, knowledge\ndistillation stands out due to its outstanding efficiency and generalization.\nHowever, existing methods suffer from several drawbacks, including limited\nknowledge diversity and the lack of rich contextual information. To solve the\nproblems and facilitate the learning of compact language models, we propose\nTinyLLM, a new knowledge distillation paradigm to learn a small student LLM\nfrom multiple large teacher LLMs. In particular, we encourage the student LLM\nto not only generate the correct answers but also understand the rationales\nbehind these answers. Given that different LLMs possess diverse reasoning\nskills, we guide the student model to assimilate knowledge from various teacher\nLLMs. We further introduce an in-context example generator and a\nteacher-forcing Chain-of-Thought strategy to ensure that the rationales are\naccurate and grounded in contextually appropriate scenarios. Extensive\nexperiments on six datasets across two reasoning tasks demonstrate the\nsuperiority of our method. Results show that TinyLLM can outperform large\nteacher LLMs significantly, despite a considerably smaller model size. The\nsource code is available at: https://github.com/YikunHan42/TinyLLM.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by WSDM 2025",
    "pdf_url": "http://arxiv.org/pdf/2402.04616v3",
    "published_date": "2024-02-07 06:48:24 UTC",
    "updated_date": "2024-11-23 04:06:12 UTC"
  },
  {
    "arxiv_id": "2402.04615v3",
    "title": "ScreenAI: A Vision-Language Model for UI and Infographics Understanding",
    "authors": [
      "Gilles Baechler",
      "Srinivas Sunkara",
      "Maria Wang",
      "Fedir Zubach",
      "Hassan Mansoor",
      "Vincent Etter",
      "Victor Cărbune",
      "Jason Lin",
      "Jindong Chen",
      "Abhanshu Sharma"
    ],
    "abstract": "Screen user interfaces (UIs) and infographics, sharing similar visual\nlanguage and design principles, play important roles in human communication and\nhuman-machine interaction. We introduce ScreenAI, a vision-language model that\nspecializes in UI and infographics understanding. Our model improves upon the\nPaLI architecture with the flexible patching strategy of pix2struct and is\ntrained on a unique mixture of datasets. At the heart of this mixture is a\nnovel screen annotation task in which the model has to identify the type and\nlocation of UI elements. We use these text annotations to describe screens to\nLarge Language Models and automatically generate question-answering (QA), UI\nnavigation, and summarization training datasets at scale. We run ablation\nstudies to demonstrate the impact of these design choices. At only 5B\nparameters, ScreenAI achieves new state-of-the-artresults on UI- and\ninfographics-based tasks (Multi-page DocVQA, WebSRC, MoTIF and Widget\nCaptioning), and new best-in-class performance on others (Chart QA, DocVQA, and\nInfographicVQA) compared to models of similar size. Finally, we release three\nnew datasets: one focused on the screen annotation task and two others focused\non question answering.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to International Joint Conference on Artificial Intelligence\n  (IJCAI), 2024. Revision Notes: full version of the paper, including 1)\n  Camera-ready version for IJCAI-24; 2) Appendices that are mentioned, but not\n  included in 1)",
    "pdf_url": "http://arxiv.org/pdf/2402.04615v3",
    "published_date": "2024-02-07 06:42:33 UTC",
    "updated_date": "2024-07-04 07:08:15 UTC"
  },
  {
    "arxiv_id": "2402.09456v2",
    "title": "Optimistic Thompson Sampling for No-Regret Learning in Unknown Games",
    "authors": [
      "Yingru Li",
      "Liangqi Liu",
      "Wenqiang Pu",
      "Hao Liang",
      "Zhi-Quan Luo"
    ],
    "abstract": "This work tackles the complexities of multi-player scenarios in \\emph{unknown\ngames}, where the primary challenge lies in navigating the uncertainty of the\nenvironment through bandit feedback alongside strategic decision-making. We\nintroduce Thompson Sampling (TS)-based algorithms that exploit the information\nof opponents' actions and reward structures, leading to a substantial reduction\nin experimental budgets -- achieving over tenfold improvements compared to\nconventional approaches. Notably, our algorithms demonstrate that, given\nspecific reward structures, the regret bound depends logarithmically on the\ntotal action space, significantly alleviating the curse of multi-player.\nFurthermore, we unveil the \\emph{Optimism-then-NoRegret} (OTN) framework, a\npioneering methodology that seamlessly incorporates our advancements with\nestablished algorithms, showcasing its utility in practical scenarios such as\ntraffic routing and radar sensing in the real world.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GT",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.09456v2",
    "published_date": "2024-02-07 06:10:47 UTC",
    "updated_date": "2024-02-25 04:48:38 UTC"
  },
  {
    "arxiv_id": "2402.04601v2",
    "title": "Alirector: Alignment-Enhanced Chinese Grammatical Error Corrector",
    "authors": [
      "Haihui Yang",
      "Xiaojun Quan"
    ],
    "abstract": "Chinese grammatical error correction (CGEC) faces serious overcorrection\nchallenges when employing autoregressive generative models such as\nsequence-to-sequence (Seq2Seq) models and decoder-only large language models\n(LLMs). While previous methods aim to address overcorrection in Seq2Seq models,\nthey are difficult to adapt to decoder-only LLMs. In this paper, we propose an\nalignment-enhanced corrector for the overcorrection problem that applies to\nboth Seq2Seq models and decoder-only LLMs. Our method first trains a correction\nmodel to generate an initial correction of the source sentence. Then, we\ncombine the source sentence with the initial correction and feed it through an\nalignment model for another round of correction, aiming to enforce the\nalignment model to focus on potential overcorrection. Moreover, to enhance the\nmodel's ability to identify nuances, we further explore the reverse alignment\nof the source sentence and the initial correction. Finally, we transfer the\nalignment knowledge from two alignment models to the correction model,\ninstructing it on how to avoid overcorrection. Experimental results on three\nCGEC datasets demonstrate the effectiveness of our approach in alleviating\novercorrection and improving overall performance. Our code has been made\npublicly available.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to Findings of ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.04601v2",
    "published_date": "2024-02-07 05:56:54 UTC",
    "updated_date": "2024-06-02 15:50:40 UTC"
  },
  {
    "arxiv_id": "2402.04599v2",
    "title": "Meet JEANIE: a Similarity Measure for 3D Skeleton Sequences via Temporal-Viewpoint Alignment",
    "authors": [
      "Lei Wang",
      "Jun Liu",
      "Liang Zheng",
      "Tom Gedeon",
      "Piotr Koniusz"
    ],
    "abstract": "Video sequences exhibit significant nuisance variations (undesired effects)\nof speed of actions, temporal locations, and subjects' poses, leading to\ntemporal-viewpoint misalignment when comparing two sets of frames or evaluating\nthe similarity of two sequences. Thus, we propose Joint tEmporal and cAmera\nviewpoiNt alIgnmEnt (JEANIE) for sequence pairs. In particular, we focus on 3D\nskeleton sequences whose camera and subjects' poses can be easily manipulated\nin 3D. We evaluate JEANIE on skeletal Few-shot Action Recognition (FSAR), where\nmatching well temporal blocks (temporal chunks that make up a sequence) of\nsupport-query sequence pairs (by factoring out nuisance variations) is\nessential due to limited samples of novel classes. Given a query sequence, we\ncreate its several views by simulating several camera locations. For a support\nsequence, we match it with view-simulated query sequences, as in the popular\nDynamic Time Warping (DTW). Specifically, each support temporal block can be\nmatched to the query temporal block with the same or adjacent (next) temporal\nindex, and adjacent camera views to achieve joint local temporal-viewpoint\nwarping. JEANIE selects the smallest distance among matching paths with\ndifferent temporal-viewpoint warping patterns, an advantage over DTW which only\nperforms temporal alignment. We also propose an unsupervised FSAR akin to\nclustering of sequences with JEANIE as a distance measure. JEANIE achieves\nstate-of-the-art results on NTU-60, NTU-120, Kinetics-skeleton and UWA3D\nMultiview Activity II on supervised and unsupervised FSAR, and their\nmeta-learning inspired fusion.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by the International Journal of Computer Vision (IJCV). An\n  extension of our ACCV'22 paper [arXiv:arXiv:2210.16820] which was\n  distinguished by the Sang Uk Lee Best Student Paper Award",
    "pdf_url": "http://arxiv.org/pdf/2402.04599v2",
    "published_date": "2024-02-07 05:47:31 UTC",
    "updated_date": "2024-03-25 13:30:37 UTC"
  },
  {
    "arxiv_id": "2402.04597v1",
    "title": "CMSA algorithm for solving the prioritized pairwise test data generation problem in software product lines",
    "authors": [
      "Javier Ferrer",
      "Francisco Chicano",
      "José Antonio Ortega Toro"
    ],
    "abstract": "In Software Product Lines (SPLs) it may be difficult or even impossible to\ntest all the products of the family because of the large number of valid\nfeature combinations that may exist. Thus, we want to find a minimal subset of\nthe product family that allows us to test all these possible combinations\n(pairwise). Furthermore, when testing a single product is a great effort, it is\ndesirable to first test products composed of a set of priority features. This\nproblem is called Prioritized Pairwise Test Data Generation Problem.\n  State-of-the-art algorithms based on Integer Linear Programming for this\nproblema are faster enough for small and medium instances. However, there\nexists some real instances that are too large to be computed with these\nalgorithms in a reasonable time because of the exponential growth of the number\nof candidate solutions. Also, these heuristics not always lead us to the best\nsolutions. In this work we propose a new approach based on a hybrid\nmetaheuristic algorithm called Construct, Merge, Solve & Adapt. We compare this\nmatheuristic with four algorithms: a Hybrid algorithm based on Integer Linear\nProgramming ((HILP), a Hybrid algorithm based on Integer Nonlinear Programming\n(HINLP), the Parallel Prioritized Genetic Solver (PPGS), and a greedy algorithm\ncalled prioritized-ICPL. The analysis reveals that CMSA results in\nstatistically significantly better quality solutions in most instances and for\nmost levels of weighted coverage, although it requires more execution time.",
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "Preprint of the submitted version of the article in Journal of\n  Heuristics",
    "pdf_url": "http://arxiv.org/pdf/2402.04597v1",
    "published_date": "2024-02-07 05:43:57 UTC",
    "updated_date": "2024-02-07 05:43:57 UTC"
  },
  {
    "arxiv_id": "2402.04596v1",
    "title": "Towards Improved Imbalance Robustness in Continual Multi-Label Learning with Dual Output Spiking Architecture (DOSA)",
    "authors": [
      "Sourav Mishra",
      "Shirin Dora",
      "Suresh Sundaram"
    ],
    "abstract": "Algorithms designed for addressing typical supervised classification problems\ncan only learn from a fixed set of samples and labels, making them unsuitable\nfor the real world, where data arrives as a stream of samples often associated\nwith multiple labels over time. This motivates the study of task-agnostic\ncontinual multi-label learning problems. While algorithms using deep learning\napproaches for continual multi-label learning have been proposed in the recent\nliterature, they tend to be computationally heavy. Although spiking neural\nnetworks (SNNs) offer a computationally efficient alternative to artificial\nneural networks, existing literature has not used SNNs for continual\nmulti-label learning. Also, accurately determining multiple labels with SNNs is\nstill an open research problem. This work proposes a dual output spiking\narchitecture (DOSA) to bridge these research gaps. A novel imbalance-aware loss\nfunction is also proposed, improving the multi-label classification performance\nof the model by making it more robust to data imbalance. A modified F1 score is\npresented to evaluate the effectiveness of the proposed loss function in\nhandling imbalance. Experiments on several benchmark multi-label datasets show\nthat DOSA trained with the proposed loss function shows improved robustness to\ndata imbalance and obtains better continual multi-label learning performance\nthan CIFDM, a previous state-of-the-art algorithm.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 4 figures, 4 tables, 45 references. Submitted to IJCNN 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.04596v1",
    "published_date": "2024-02-07 05:38:53 UTC",
    "updated_date": "2024-02-07 05:38:53 UTC"
  },
  {
    "arxiv_id": "2402.14596v1",
    "title": "The Role of LLMs in Sustainable Smart Cities: Applications, Challenges, and Future Directions",
    "authors": [
      "Amin Ullah",
      "Guilin Qi",
      "Saddam Hussain",
      "Irfan Ullah",
      "Zafar Ali"
    ],
    "abstract": "Smart cities stand as pivotal components in the ongoing pursuit of elevating\nurban living standards, facilitating the rapid expansion of urban areas while\nefficiently managing resources through sustainable and scalable innovations. In\nthis regard, as emerging technologies like Artificial Intelligence (AI), the\nInternet of Things (IoT), big data analytics, and fog and edge computing have\nbecome increasingly prevalent, smart city applications grapple with various\nchallenges, including the potential for unauthorized disclosure of confidential\nand sensitive data. The seamless integration of emerging technologies has\nplayed a vital role in sustaining the dynamic pace of their development. This\npaper explores the substantial potential and applications of Deep Learning\n(DL), Federated Learning (FL), IoT, Blockchain, Natural Language Processing\n(NLP), and large language models (LLMs) in optimizing ICT processes within\nsmart cities. We aim to spotlight the vast potential of these technologies as\nfoundational elements that technically strengthen the realization and\nadvancement of smart cities, underscoring their significance in driving\ninnovation within this transformative urban milieu. Our discourse culminates\nwith an exploration of the formidable challenges that DL, FL, IoT, Blockchain,\nNLP, and LLMs face within these contexts, and we offer insights into potential\nfuture directions.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14596v1",
    "published_date": "2024-02-07 05:22:10 UTC",
    "updated_date": "2024-02-07 05:22:10 UTC"
  },
  {
    "arxiv_id": "2402.04580v2",
    "title": "A Comprehensive Survey of Cross-Domain Policy Transfer for Embodied Agents",
    "authors": [
      "Haoyi Niu",
      "Jianming Hu",
      "Guyue Zhou",
      "Xianyuan Zhan"
    ],
    "abstract": "The burgeoning fields of robot learning and embodied AI have triggered an\nincreasing demand for large quantities of data. However, collecting sufficient\nunbiased data from the target domain remains a challenge due to costly data\ncollection processes and stringent safety requirements. Consequently,\nresearchers often resort to data from easily accessible source domains, such as\nsimulation and laboratory environments, for cost-effective data acquisition and\nrapid model iteration. Nevertheless, the environments and embodiments of these\nsource domains can be quite different from their target domain counterparts,\nunderscoring the need for effective cross-domain policy transfer approaches. In\nthis paper, we conduct a systematic review of existing cross-domain policy\ntransfer methods. Through a nuanced categorization of domain gaps, we\nencapsulate the overarching insights and design considerations of each problem\nsetting. We also provide a high-level discussion about the key methodologies\nused in cross-domain policy transfer problems. Lastly, we summarize the open\nchallenges that lie beyond the capabilities of current paradigms and discuss\npotential future directions in this field.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "IJCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.04580v2",
    "published_date": "2024-02-07 04:43:41 UTC",
    "updated_date": "2024-08-27 14:05:38 UTC"
  },
  {
    "arxiv_id": "2402.04578v4",
    "title": "S-Agents: Self-organizing Agents in Open-ended Environments",
    "authors": [
      "Jiaqi Chen",
      "Yuxian Jiang",
      "Jiachen Lu",
      "Li Zhang"
    ],
    "abstract": "Leveraging large language models (LLMs), autonomous agents have significantly\nimproved, gaining the ability to handle a variety of tasks. In open-ended\nsettings, optimizing collaboration for efficiency and effectiveness demands\nflexible adjustments. Despite this, current research mainly emphasizes fixed,\ntask-oriented workflows and overlooks agent-centric organizational structures.\nDrawing inspiration from human organizational behavior, we introduce a\nself-organizing agent system (S-Agents) with a \"tree of agents\" structure for\ndynamic workflow, an \"hourglass agent architecture\" for balancing information\npriorities, and a \"non-obstructive collaboration\" method to allow asynchronous\ntask execution among agents. This structure can autonomously coordinate a group\nof agents, efficiently addressing the challenges of open and dynamic\nenvironments without human intervention. Our experiments demonstrate that\nS-Agents proficiently execute collaborative building tasks and resource\ncollection in the Minecraft environment, validating their effectiveness.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "ICLR 2024 Workshop on Large Language Model (LLM) Agents",
    "pdf_url": "http://arxiv.org/pdf/2402.04578v4",
    "published_date": "2024-02-07 04:36:31 UTC",
    "updated_date": "2024-09-13 19:40:12 UTC"
  },
  {
    "arxiv_id": "2402.04567v1",
    "title": "OIL-AD: An Anomaly Detection Framework for Sequential Decision Sequences",
    "authors": [
      "Chen Wang",
      "Sarah Erfani",
      "Tansu Alpcan",
      "Christopher Leckie"
    ],
    "abstract": "Anomaly detection in decision-making sequences is a challenging problem due\nto the complexity of normality representation learning and the sequential\nnature of the task. Most existing methods based on Reinforcement Learning (RL)\nare difficult to implement in the real world due to unrealistic assumptions,\nsuch as having access to environment dynamics, reward signals, and online\ninteractions with the environment. To address these limitations, we propose an\nunsupervised method named Offline Imitation Learning based Anomaly Detection\n(OIL-AD), which detects anomalies in decision-making sequences using two\nextracted behaviour features: action optimality and sequential association. Our\noffline learning model is an adaptation of behavioural cloning with a\ntransformer policy network, where we modify the training process to learn a Q\nfunction and a state value function from normal trajectories. We propose that\nthe Q function and the state value function can provide sufficient information\nabout agents' behavioural data, from which we derive two features for anomaly\ndetection. The intuition behind our method is that the action optimality\nfeature derived from the Q function can differentiate the optimal action from\nothers at each local state, and the sequential association feature derived from\nthe state value function has the potential to maintain the temporal\ncorrelations between decisions (state-action pairs). Our experiments show that\nOIL-AD can achieve outstanding online anomaly detection performance with up to\n34.8% improvement in F1 score over comparable baselines.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.04567v1",
    "published_date": "2024-02-07 04:06:53 UTC",
    "updated_date": "2024-02-07 04:06:53 UTC"
  },
  {
    "arxiv_id": "2402.04563v1",
    "title": "Attention Guided CAM: Visual Explanations of Vision Transformer Guided by Self-Attention",
    "authors": [
      "Saebom Leem",
      "Hyunseok Seo"
    ],
    "abstract": "Vision Transformer(ViT) is one of the most widely used models in the computer\nvision field with its great performance on various tasks. In order to fully\nutilize the ViT-based architecture in various applications, proper\nvisualization methods with a decent localization performance are necessary, but\nthese methods employed in CNN-based models are still not available in ViT due\nto its unique structure. In this work, we propose an attention-guided\nvisualization method applied to ViT that provides a high-level semantic\nexplanation for its decision. Our method selectively aggregates the gradients\ndirectly propagated from the classification output to each self-attention,\ncollecting the contribution of image features extracted from each location of\nthe input image. These gradients are additionally guided by the normalized\nself-attention scores, which are the pairwise patch correlation scores. They\nare used to supplement the gradients on the patch-level context information\nefficiently detected by the self-attention mechanism. This approach of our\nmethod provides elaborate high-level semantic explanations with great\nlocalization performance only with the class labels. As a result, our method\noutperforms the previous leading explainability methods of ViT in the\nweakly-supervised localization task and presents great capability in capturing\nthe full instances of the target class object. Meanwhile, our method provides a\nvisualization that faithfully explains the model, which is demonstrated in the\nperturbation comparison test.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "AAAI2024. Code available at\n  https://github.com/LeemSaebom/Attention-Guided-CAM-Visual-Explanations-of-Vision-Transformer-Guided-by-Self-Attention.git",
    "pdf_url": "http://arxiv.org/pdf/2402.04563v1",
    "published_date": "2024-02-07 03:43:56 UTC",
    "updated_date": "2024-02-07 03:43:56 UTC"
  },
  {
    "arxiv_id": "2402.04559v4",
    "title": "Can Large Language Model Agents Simulate Human Trust Behavior?",
    "authors": [
      "Chengxing Xie",
      "Canyu Chen",
      "Feiran Jia",
      "Ziyu Ye",
      "Shiyang Lai",
      "Kai Shu",
      "Jindong Gu",
      "Adel Bibi",
      "Ziniu Hu",
      "David Jurgens",
      "James Evans",
      "Philip Torr",
      "Bernard Ghanem",
      "Guohao Li"
    ],
    "abstract": "Large Language Model (LLM) agents have been increasingly adopted as\nsimulation tools to model humans in social science and role-playing\napplications. However, one fundamental question remains: can LLM agents really\nsimulate human behavior? In this paper, we focus on one critical and elemental\nbehavior in human interactions, trust, and investigate whether LLM agents can\nsimulate human trust behavior. We first find that LLM agents generally exhibit\ntrust behavior, referred to as agent trust, under the framework of Trust Games,\nwhich are widely recognized in behavioral economics. Then, we discover that\nGPT-4 agents manifest high behavioral alignment with humans in terms of trust\nbehavior, indicating the feasibility of simulating human trust behavior with\nLLM agents. In addition, we probe the biases of agent trust and differences in\nagent trust towards other LLM agents and humans. We also explore the intrinsic\nproperties of agent trust under conditions including external manipulations and\nadvanced reasoning strategies. Our study provides new insights into the\nbehaviors of LLM agents and the fundamental analogy between LLMs and humans\nbeyond value alignment. We further illustrate broader implications of our\ndiscoveries for applications where trust is paramount.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to Proceedings of NeurIPS 2024. The first two authors\n  contributed equally. 10 pages for main paper, 56 pages including appendix.\n  Project website: https://agent-trust.camel-ai.org",
    "pdf_url": "http://arxiv.org/pdf/2402.04559v4",
    "published_date": "2024-02-07 03:37:19 UTC",
    "updated_date": "2024-11-01 16:10:41 UTC"
  },
  {
    "arxiv_id": "2402.04539v1",
    "title": "Learning Diverse Policies with Soft Self-Generated Guidance",
    "authors": [
      "Guojian Wang",
      "Faguo Wu",
      "Xiao Zhang",
      "Jianxiang Liu"
    ],
    "abstract": "Reinforcement learning (RL) with sparse and deceptive rewards is challenging\nbecause non-zero rewards are rarely obtained. Hence, the gradient calculated by\nthe agent can be stochastic and without valid information. Recent studies that\nutilize memory buffers of previous experiences can lead to a more efficient\nlearning process. However, existing methods often require these experiences to\nbe successful and may overly exploit them, which can cause the agent to adopt\nsuboptimal behaviors. This paper develops an approach that uses diverse past\ntrajectories for faster and more efficient online RL, even if these\ntrajectories are suboptimal or not highly rewarded. The proposed algorithm\ncombines a policy improvement step with an additional exploration step using\noffline demonstration data. The main contribution of this paper is that by\nregarding diverse past trajectories as guidance, instead of imitating them, our\nmethod directs its policy to follow and expand past trajectories while still\nbeing able to learn without rewards and approach optimality. Furthermore, a\nnovel diversity measurement is introduced to maintain the team's diversity and\nregulate exploration. The proposed algorithm is evaluated on discrete and\ncontinuous control tasks with sparse and deceptive rewards. Compared with the\nexisting RL methods, the experimental results indicate that our proposed\nalgorithm is significantly better than the baseline methods regarding diverse\nexploration and avoiding local optima.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "23 pages, 19 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.04539v1",
    "published_date": "2024-02-07 02:53:50 UTC",
    "updated_date": "2024-02-07 02:53:50 UTC"
  },
  {
    "arxiv_id": "2402.04536v2",
    "title": "Tactile-based Object Retrieval From Granular Media",
    "authors": [
      "Jingxi Xu",
      "Yinsen Jia",
      "Dongxiao Yang",
      "Patrick Meng",
      "Xinyue Zhu",
      "Zihan Guo",
      "Shuran Song",
      "Matei Ciocarlie"
    ],
    "abstract": "We introduce GEOTACT, a robotic manipulation method capable of retrieving\nobjects buried in granular media. This is a challenging task due to the need to\ninteract with granular media, and doing so based exclusively on tactile\nfeedback, since a buried object can be completely hidden from vision. Tactile\nfeedback is in itself challenging in this context, due to ubiquitous contact\nwith the surrounding media, and the inherent noise level induced by the tactile\nreadings. To address these challenges, we use a learning method trained\nend-to-end with simulated sensor noise. We show that our problem formulation\nleads to the natural emergence of learned pushing behaviors that the\nmanipulator uses to reduce uncertainty and funnel the object to a stable grasp\ndespite spurious and noisy tactile readings. We also introduce a training\ncurriculum that enables learning these behaviors in simulation, followed by\nzero-shot transfer to real hardware. To the best of our knowledge, GEOTACT is\nthe first method to reliably retrieve a number of different objects from a\ngranular environment, doing so on real hardware and with integrated tactile\nsensing. Videos and additional information can be found at\nhttps://jxu.ai/geotact.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.04536v2",
    "published_date": "2024-02-07 02:50:56 UTC",
    "updated_date": "2024-02-21 17:31:22 UTC"
  },
  {
    "arxiv_id": "2402.04527v2",
    "title": "RA-Rec: An Efficient ID Representation Alignment Framework for LLM-based Recommendation",
    "authors": [
      "Xiaohan Yu",
      "Li Zhang",
      "Xin Zhao",
      "Yue Wang",
      "Zhongrui Ma"
    ],
    "abstract": "Large language models (LLM) have recently emerged as a powerful tool for a\nvariety of natural language processing tasks, bringing a new surge of combining\nLLM with recommendation systems, termed as LLM-based RS. Current approaches\ngenerally fall into two main paradigms, the ID direct usage paradigm and the ID\ntranslation paradigm, noting their core weakness stems from lacking\nrecommendation knowledge and uniqueness. To address this limitation, we propose\na new paradigm, ID representation, which incorporates pre-trained ID embeddings\ninto LLMs in a complementary manner. In this work, we present RA-Rec, an\nefficient ID representation alignment framework for LLM-based recommendation,\nwhich is compatible with multiple ID-based methods and LLM architectures.\nSpecifically, we treat ID embeddings as soft prompts and design an innovative\nalignment module and an efficient tuning method with tailored data construction\nfor alignment. Extensive experiments demonstrate RA-Rec substantially\noutperforms current state-of-the-art methods, achieving up to 3.0% absolute\nHitRate@100 improvements while utilizing less than 10x training data.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2402.04527v2",
    "published_date": "2024-02-07 02:14:58 UTC",
    "updated_date": "2024-03-19 14:56:54 UTC"
  },
  {
    "arxiv_id": "2402.04520v5",
    "title": "On Computational Limits of Modern Hopfield Models: A Fine-Grained Complexity Analysis",
    "authors": [
      "Jerry Yao-Chieh Hu",
      "Thomas Lin",
      "Zhao Song",
      "Han Liu"
    ],
    "abstract": "We investigate the computational limits of the memory retrieval dynamics of\nmodern Hopfield models from the fine-grained complexity analysis. Our key\ncontribution is the characterization of a phase transition behavior in the\nefficiency of all possible modern Hopfield models based on the norm of\npatterns. Specifically, we establish an upper bound criterion for the norm of\ninput query patterns and memory patterns. Only below this criterion,\nsub-quadratic (efficient) variants of the modern Hopfield model exist, assuming\nthe Strong Exponential Time Hypothesis (SETH). To showcase our theory, we\nprovide a formal example of efficient constructions of modern Hopfield models\nusing low-rank approximation when the efficient criterion holds. This includes\na derivation of a lower bound on the computational time, scaling linearly with\n$\\max\\{$# of stored memory patterns, length of input query sequence$\\}$. In\naddition, we prove its memory retrieval error bound and exponential memory\ncapacity.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at ICML 2024; v2 corrected typos; v3 added clarifications\n  and references; v4,5 updated to camera-ready version",
    "pdf_url": "http://arxiv.org/pdf/2402.04520v5",
    "published_date": "2024-02-07 01:58:21 UTC",
    "updated_date": "2024-06-01 00:49:17 UTC"
  },
  {
    "arxiv_id": "2402.04515v1",
    "title": "A Deep Reinforcement Learning Approach for Adaptive Traffic Routing in Next-gen Networks",
    "authors": [
      "Akshita Abrol",
      "Purnima Murali Mohan",
      "Tram Truong-Huu"
    ],
    "abstract": "Next-gen networks require significant evolution of management to enable\nautomation and adaptively adjust network configuration based on traffic\ndynamics. The advent of software-defined networking (SDN) and programmable\nswitches enables flexibility and programmability. However, traditional\ntechniques that decide traffic policies are usually based on hand-crafted\nprogramming optimization and heuristic algorithms. These techniques make\nnon-realistic assumptions, e.g., considering static network load and topology,\nto obtain tractable solutions, which are inadequate for next-gen networks. In\nthis paper, we design and develop a deep reinforcement learning (DRL) approach\nfor adaptive traffic routing. We design a deep graph convolutional neural\nnetwork (DGCNN) integrated into the DRL framework to learn the traffic behavior\nfrom not only the network topology but also link and node attributes. We adopt\nthe Deep Q-Learning technique to train the DGCNN model in the DRL framework\nwithout the need for a labeled training dataset, enabling the framework to\nquickly adapt to traffic dynamics. The model leverages q-value estimates to\nselect the routing path for every traffic flow request, balancing exploration\nand exploitation. We perform extensive experiments with various traffic\npatterns and compare the performance of the proposed approach with the Open\nShortest Path First (OSPF) protocol. The experimental results show the\neffectiveness and adaptiveness of the proposed framework by increasing the\nnetwork throughput by up to 7.8% and reducing the traffic delay by up to 16.1%\ncompared to OSPF.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "Accepted for publication in the Proceedings of the IEEE International\n  Conference on Communications (IEEE ICC 2024)",
    "pdf_url": "http://arxiv.org/pdf/2402.04515v1",
    "published_date": "2024-02-07 01:48:29 UTC",
    "updated_date": "2024-02-07 01:48:29 UTC"
  },
  {
    "arxiv_id": "2402.05142v1",
    "title": "The Foundations of Computational Management: A Systematic Approach to Task Automation for the Integration of Artificial Intelligence into Existing Workflows",
    "authors": [
      "Tamen Jadad-Garcia",
      "Alejandro R. Jadad"
    ],
    "abstract": "Driven by the rapid ascent of artificial intelligence (AI), organizations are\nat the epicenter of a seismic shift, facing a crucial question: How can AI be\nsuccessfully integrated into existing operations? To help answer it, manage\nexpectations and mitigate frustration, this article introduces Computational\nManagement, a systematic approach to task automation for enhancing the ability\nof organizations to harness AI's potential within existing workflows.\nComputational Management acts as a bridge between the strategic insights of\nmanagement science with the analytical rigor of computational thinking. The\narticle offers three easy step-by-step procedures to begin the process of\nimplementing AI within a workflow. Such procedures focus on task\n(re)formulation, on the assessment of the automation potential of tasks, on the\ncompletion of task specification templates for AI selection and adaptation.\nIncluded in the article there are manual and automated methods, with prompt\nsuggestions for publicly available LLMs, to complete these three procedures.\nThe first procedure, task (re)formulation, focuses on breaking down work\nactivities into basic units, so they can be completed by one agent, involve a\nsingle well-defined action, and produce a distinct outcome. The second, allows\nthe assessment of the granular task and its suitability for automation, using\nthe Task Automation Index to rank tasks based on whether they have standardized\ninput, well-defined rules, repetitiveness, data dependency, and objective\noutputs. The third, focuses on a task specification template which details\ninformation on 16 critical components of tasks, and can be used as a checklist\nto select or adapt the most suitable AI solution for integration into existing\nworkflows. Computational Management provides a roadmap and a toolkit for humans\nand AI to thrive together, while enhancing organizational efficiency and\ninnovation.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "29 pages, 3 appendices",
    "pdf_url": "http://arxiv.org/pdf/2402.05142v1",
    "published_date": "2024-02-07 01:45:14 UTC",
    "updated_date": "2024-02-07 01:45:14 UTC"
  },
  {
    "arxiv_id": "2402.04494v2",
    "title": "Amortized Planning with Large-Scale Transformers: A Case Study on Chess",
    "authors": [
      "Anian Ruoss",
      "Grégoire Delétang",
      "Sourabh Medapati",
      "Jordi Grau-Moya",
      "Li Kevin Wenliang",
      "Elliot Catt",
      "John Reid",
      "Cannada A. Lewis",
      "Joel Veness",
      "Tim Genewein"
    ],
    "abstract": "This paper uses chess, a landmark planning problem in AI, to assess\ntransformers' performance on a planning task where memorization is futile\n$\\unicode{x2013}$ even at a large scale. To this end, we release ChessBench, a\nlarge-scale benchmark dataset of 10 million chess games with legal move and\nvalue annotations (15 billion data points) provided by Stockfish 16, the\nstate-of-the-art chess engine. We train transformers with up to 270 million\nparameters on ChessBench via supervised learning and perform extensive\nablations to assess the impact of dataset size, model size, architecture type,\nand different prediction targets (state-values, action-values, and behavioral\ncloning). Our largest models learn to predict action-values for novel boards\nquite accurately, implying highly non-trivial generalization. Despite\nperforming no explicit search, our resulting chess policy solves challenging\nchess puzzles and achieves a surprisingly strong Lichess blitz Elo of 2895\nagainst humans (grandmaster level). We also compare to Leela Chess Zero and\nAlphaZero (trained without supervision via self-play) with and without search.\nWe show that, although a remarkably good approximation of Stockfish's\nsearch-based algorithm can be distilled into large-scale transformers via\nsupervised learning, perfect distillation is still beyond reach, thus making\nChessBench well-suited for future research.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.04494v2",
    "published_date": "2024-02-07 00:36:24 UTC",
    "updated_date": "2024-10-21 09:37:12 UTC"
  },
  {
    "arxiv_id": "2403.09676v1",
    "title": "Unmasking the Shadows of AI: Investigating Deceptive Capabilities in Large Language Models",
    "authors": [
      "Linge Guo"
    ],
    "abstract": "This research critically navigates the intricate landscape of AI deception,\nconcentrating on deceptive behaviours of Large Language Models (LLMs). My\nobjective is to elucidate this issue, examine the discourse surrounding it, and\nsubsequently delve into its categorization and ramifications. The essay\ninitiates with an evaluation of the AI Safety Summit 2023 (ASS) and\nintroduction of LLMs, emphasising multidimensional biases that underlie their\ndeceptive behaviours.The literature review covers four types of deception\ncategorised: Strategic deception, Imitation, Sycophancy, and Unfaithful\nReasoning, along with the social implications and risks they entail. Lastly, I\ntake an evaluative stance on various aspects related to navigating the\npersistent challenges of the deceptive AI. This encompasses considerations of\ninternational collaborative governance, the reconfigured engagement of\nindividuals with AI, proposal of practical adjustments, and specific elements\nof digital education.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "AI deception, Large Language Models, ChatGPT",
    "pdf_url": "http://arxiv.org/pdf/2403.09676v1",
    "published_date": "2024-02-07 00:21:46 UTC",
    "updated_date": "2024-02-07 00:21:46 UTC"
  }
]