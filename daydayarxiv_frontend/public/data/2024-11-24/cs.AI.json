{
  "date": "2024-11-24",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-11-24 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 51 篇论文，主要聚焦 AI 模型优化（如高效 LLM 推理和多模态处理）、图像生成与医疗诊断等领域，重点包括 eFedLLM 的联邦学习应用、PIANIST 的多代理决策框架，以及 Yisong Yue 等著名学者的参与，令人印象深刻的文章展示了 LLM 在实际应用中的高效性和鲁棒性。\n\n### LLM 和 AI 优化相关论文（重点讨论）\n这些论文突出了 LLM 在推理、安全和效率方面的创新，相关主题紧密，值得优先关注。\n- **eFedLLM: Efficient LLM Inference Based on Federated Learning**（中文：基于联邦学习的高效 LLM 推理；英文：eFedLLM: Efficient LLM Inference Based on Federated Learning）：论文提出了一种基于联邦学习的 LLM 推理框架，利用模型并行训练和激励机制分担计算负载，实现资源优化和恶意活动过滤，主要贡献是提升了 LLM 的可访问性和效率。\n- **PIANIST: Learning Partially Observable World Models with LLMs for Multi-Agent Decision Making**（中文：使用 LLM 学习部分可观测世界模型的多代理决策；英文：PIANIST: Learning Partially Observable World Models with LLMs for Multi-Agent Decision Making）：Yisong Yue 等作者开发了一个零样本框架，将 LLM 用于多代理决策，核心发现是通过分解世界模型提升 MCTS 模拟性能，在游戏任务中无需训练数据即可实现高效决策。\n- **Anda: Unlocking Efficient LLM Inference with a Variable-Length Grouped Activation Data Format**（中文：使用可变长分组激活数据格式解锁高效 LLM 推理；英文：Anda: Unlocking Efficient LLM Inference with a Variable-Length Grouped Activation Data Format）：论文引入自适应数据格式和硬件优化，显著提升 LLM 推理速度和能效，主要发现是平均 2.4 倍加速和 3.1 倍能效改进。\n- **Ensuring Fair LLM Serving Amid Diverse Applications**（中文：在多样应用中确保 LLM 服务公平性；英文：Ensuring Fair LLM Serving Amid Diverse Applications）：作者提出 FairServe 系统，通过请求节流和加权调度机制解决 LLM 服务不公平问题，核心贡献是基于真实数据分析实现公平访问，实验显示优于现有方法。\n- **Generative Prompt Internalization**（中文：生成式提示内部化；英文：Generative Prompt Internalization）：论文开发了一种轻量级方法，使 LLM 无需显式提示即可生成内容，贡献包括数据合成技术提升推理效率。\n\n### 图像处理和医疗诊断论文\n这些论文强调多模态 AI 在实际应用中的潜力，相关主题包括图像生成和诊断改进。\n- **Making Images from Images: Interleaving Denoising and Transformation**（中文：从图像生成图像：交错去噪和变换；英文：Making Images from Images: Interleaving Denoising and Transformation）：论文通过优化算法实现图像区域重排生成新图像，主要发现是结合扩散模型和能量最小化提升生成质量。\n- **Improving Medical Diagnostics with Vision-Language Models: Convex Hull-Based Uncertainty Analysis**（中文：使用视觉语言模型提升医疗诊断：基于凸包的不确定性分析；英文：Improving Medical Diagnostics with Vision-Language Models: Convex Hull-Based Uncertainty Analysis）：作者使用凸包方法量化 VLM 不确定性，核心贡献是提高医疗图像诊断的可靠性和准确性。\n- **TransFair: Transferring Fairness from Ocular Disease Classification to Progression Prediction**（中文：TransFair：从眼部疾病分类向进展预测转移公平性；英文：TransFair: Transferring Fairness from Ocular Disease Classification to Progression Prediction）：论文提出公平性转移框架，优化眼部疾病预测的 demographic 公平，关键发现是减少群体偏差，提升 3D 图像诊断性能。\n\n### 其他值得一提的论文\n其余论文涉及时间序列、机器人和安全领域，但部分较窄或理论导向，这里快速概述。\n- **Bimanual Grasp Synthesis for Dexterous Robot Hands**（中文：双臂抓取合成用于灵巧机器人手；英文：Bimanual Grasp Synthesis for Dexterous Robot Hands）：开发算法优化机器人双臂抓取，贡献包括新数据集和扩散模型，提升抓取成功率。\n- **Hide in Plain Sight: Clean-Label Backdoor for Auditing Membership Inference**（中文：隐蔽式清洁标签后门用于审计成员推断；英文：Hide in Plain Sight: Clean-Label Backdoor for Auditing Membership Inference）：提出隐蔽后门攻击方法，增强隐私审计的鲁棒性。\n- 其他如 **Partial Identifiability and Misspecification in Inverse Reinforcement Learning**（中文：逆强化学习中的部分可识别性和模型错误；英文：Partial Identifiability and Misspecification in Inverse Reinforcement Learning）等，聚焦理论分析，但影响较小，仅量化了强化学习中的模糊性。\n\n总体而言，今天的论文突出了 AI 效率和实际应用的潜力，尤其在 LLM 领域，但也暴露出数据隐私和泛化挑战，读者可关注 eFedLLM 和 PIANIST 等创新工作。更多细节请查阅 arXiv。",
  "papers": [
    {
      "arxiv_id": "2411.16007v1",
      "title": "Performance Implications of Multi-Chiplet Neural Processing Units on Autonomous Driving Perception",
      "title_zh": "翻译失败",
      "authors": [
        "Mohanad Odema",
        "Luke Chen",
        "Hyoukjun Kwon",
        "Mohammad Abdullah Al Faruque"
      ],
      "abstract": "We study the application of emerging chiplet-based Neural Processing Units to\naccelerate vehicular AI perception workloads in constrained automotive\nsettings. The motivation stems from how chiplets technology is becoming\nintegral to emerging vehicular architectures, providing a cost-effective\ntrade-off between performance, modularity, and customization; and from\nperception models being the most computationally demanding workloads in a\nautonomous driving system. Using the Tesla Autopilot perception pipeline as a\ncase study, we first breakdown its constituent models and profile their\nperformance on different chiplet accelerators. From the insights, we propose a\nnovel scheduling strategy to efficiently deploy perception workloads on\nmulti-chip AI accelerators. Our experiments using a standard DNN performance\nsimulator, MAESTRO, show our approach realizes 82% and 2.8x increase in\nthroughput and processing engines utilization compared to monolithic\naccelerator designs.",
      "tldr_zh": "这篇论文探讨了多 chiplet Neural Processing Units 在受限汽车环境下的应用，以加速自动驾驶 AI 感知工作负载，强调其在性能、模块化和自定义方面的成本效益优势。研究以 Tesla Autopilot 的感知管道为例，对其组成部分模型进行性能剖析，并提出一种新型调度策略来高效部署这些工作负载。实验结果显示，使用 MAESTRO 模拟器，该策略相较于单块加速器设计，提高了 82% 的吞吐量和 2.8 倍的处理引擎利用率。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.DC",
        "cs.PF"
      ],
      "primary_category": "cs.AR",
      "comment": "DATE'2025",
      "pdf_url": "http://arxiv.org/pdf/2411.16007v1",
      "published_date": "2024-11-24 22:59:11 UTC",
      "updated_date": "2024-11-24 22:59:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:47:26.908737"
    },
    {
      "arxiv_id": "2411.16003v1",
      "title": "eFedLLM: Efficient LLM Inference Based on Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Shengwen Ding",
        "Chenhui Hu"
      ],
      "abstract": "Large Language Models (LLMs) herald a transformative era in artificial\nintelligence (AI). However, the expansive scale of data and parameters of LLMs\nrequires high-demand computational and memory resources, restricting their\naccessibility to a broader range of users and researchers. This paper\nintroduces an effective approach that enhances the operational efficiency and\naffordability of LLM inference. By utilizing transformer-based federated\nlearning (FL) with model-parallel distributed training, our model efficiently\ndistributes the computational loads and memory requirements across a network of\nparticipants. This strategy permits users, especially those with limited\nresources to train state-of-the-art LLMs collaboratively. We also innovate an\nincentive mechanism within the FL framework, rewarding constructive\ncontributions and filtering out malicious activities, thereby safeguarding the\nintegrity and reliability of the training process. Concurrently, we leverage\nmemory hierarchy strategies and Singular Value Decomposition (SVD) on weight\nmatrices to boost computational and memory efficiencies further. Our results,\nderived from formulaic analyses and numerical calculations, demonstrate\nsignificant optimization of resource use and democratize access to cutting-edge\nLLMs, ensuring that a wide scale of users can both contribute to and benefit\nfrom these advanced models.",
      "tldr_zh": "这篇论文提出了 eFedLLM，一种基于联邦学习 (FL) 的高效大型语言模型 (LLMs) 推理方法，通过变压器模型的并行分布式训练，将计算负载和内存需求分布到多个参与者，从而使资源有限的用户能够协作训练先进的 LLMs。创新点包括引入激励机制来奖励积极贡献并过滤恶意活动，以及利用内存层次策略和奇异值分解 (SVD) 来进一步提升计算和内存效率。实验结果显示，该方法显著优化了资源使用，并实现了 LLMs 的民主化访问，让更多用户能够贡献和受益于这些模型。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.16003v1",
      "published_date": "2024-11-24 22:50:02 UTC",
      "updated_date": "2024-11-24 22:50:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:47:38.608927"
    },
    {
      "arxiv_id": "2411.15998v1",
      "title": "PIANIST: Learning Partially Observable World Models with LLMs for Multi-Agent Decision Making",
      "title_zh": "翻译失败",
      "authors": [
        "Jonathan Light",
        "Sixue Xing",
        "Yuanzhe Liu",
        "Weiqin Chen",
        "Min Cai",
        "Xiusi Chen",
        "Guanzhi Wang",
        "Wei Cheng",
        "Yisong Yue",
        "Ziniu Hu"
      ],
      "abstract": "Effective extraction of the world knowledge in LLMs for complex\ndecision-making tasks remains a challenge. We propose a framework PIANIST for\ndecomposing the world model into seven intuitive components conducive to\nzero-shot LLM generation. Given only the natural language description of the\ngame and how input observations are formatted, our method can generate a\nworking world model for fast and efficient MCTS simulation. We show that our\nmethod works well on two different games that challenge the planning and\ndecision making skills of the agent for both language and non-language based\naction taking, without any training on domain-specific training data or\nexplicitly defined world model.",
      "tldr_zh": "该研究提出 PIANIST 框架，通过将世界模型分解为七个直观组件，利用 LLMs 进行零样本生成，以支持多智能体决策中的规划和模拟。给定游戏的自然语言描述和输入观察格式，该框架能自动生成一个可工作的世界模型，用于高效的 MCTS 模拟。实验结果表明，PIANIST 在两个不同游戏中表现出色，提升了代理的决策技能，而无需任何特定领域训练数据或显式定义的世界模型。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "Published at Language Gamification Workshop 2024 @ NeurIPS",
      "pdf_url": "http://arxiv.org/pdf/2411.15998v1",
      "published_date": "2024-11-24 22:36:34 UTC",
      "updated_date": "2024-11-24 22:36:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:47:50.332270"
    },
    {
      "arxiv_id": "2411.15997v1",
      "title": "Ensuring Fair LLM Serving Amid Diverse Applications",
      "title_zh": "在多样化应用中确保公平的 LLM 服务",
      "authors": [
        "Redwan Ibne Seraj Khan",
        "Kunal Jain",
        "Haiying Shen",
        "Ankur Mallick",
        "Anjaly Parayil",
        "Anoop Kulkarni",
        "Steve Kofsky",
        "Pankhuri Choudhary",
        "Renèe St. Amant",
        "Rujia Wang",
        "Yue Cheng",
        "Ali R. Butt",
        "Victor Rühle",
        "Chetan Bansal",
        "Saravan Rajmohan"
      ],
      "abstract": "In a multi-tenant large language model (LLM) serving platform hosting diverse\napplications, some users may submit an excessive number of requests, causing\nthe service to become unavailable to other users and creating unfairness.\nExisting fairness approaches do not account for variations in token lengths\nacross applications and multiple LLM calls, making them unsuitable for such\nplatforms. To address the fairness challenge, this paper analyzes millions of\nrequests from thousands of users on MS CoPilot, a real-world multi-tenant LLM\nplatform hosted by Microsoft. Our analysis confirms the inadequacy of existing\nmethods and guides the development of FairServe, a system that ensures fair LLM\naccess across diverse applications. FairServe proposes\napplication-characteristic aware request throttling coupled with a weighted\nservice counter based scheduling technique to curb abusive behavior and ensure\nfairness. Our experimental results on real-world traces demonstrate FairServe's\nsuperior performance compared to the state-of-the-art method in ensuring\nfairness. We are actively working on deploying our system in production,\nexpecting to benefit millions of customers world-wide.",
      "tldr_zh": "本研究针对多租户大型语言模型 (LLM) 服务平台中，用户过度提交请求导致的不公平问题进行分析，基于Microsoft CoPilot平台的数百万真实请求数据，揭示了现有公平方法忽略应用间令牌长度差异和多个LLM调用的局限性。论文提出FairServe系统，通过应用特性感知的request throttling和基于加权服务计数器的调度技术，抑制滥用行为并确保跨应用公平访问。实验结果显示，FairServe在真实数据上显著优于现有方法，并在生产环境中部署有望惠及全球数百万用户。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.15997v1",
      "published_date": "2024-11-24 22:35:44 UTC",
      "updated_date": "2024-11-24 22:35:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:48:02.670085"
    },
    {
      "arxiv_id": "2411.15982v1",
      "title": "Anda: Unlocking Efficient LLM Inference with a Variable-Length Grouped Activation Data Format",
      "title_zh": "翻译失败",
      "authors": [
        "Chao Fang",
        "Man Shi",
        "Robin Geens",
        "Arne Symons",
        "Zhongfeng Wang",
        "Marian Verhelst"
      ],
      "abstract": "The widely-used, weight-only quantized large language models (LLMs), which\nleverage low-bit integer (INT) weights and retain floating-point (FP)\nactivations, reduce storage requirements while maintaining accuracy. However,\nthis shifts the energy and latency bottlenecks towards the FP activations that\nare associated with costly memory accesses and computations. Existing LLM\naccelerators focus primarily on computation optimizations, overlooking the\npotential of jointly optimizing FP computations and data movement, particularly\nfor the dominant FP-INT GeMM operations in LLM inference.\n  To address these challenges, we investigate the sensitivity of activation\nprecision across various LLM modules and its impact on overall model accuracy.\nBased on our findings, we first propose the Anda data type: an adaptive data\nformat with group-shared exponent bits and dynamic mantissa bit allocation.\nSecondly, we develop an iterative post-training adaptive precision search\nalgorithm that optimizes the bit-width for different LLM modules to balance\nmodel accuracy, energy efficiency, and inference speed. Lastly, a suite of\nhardware optimization techniques is proposed to maximally exploit the benefits\nof the Anda format. These include a bit-plane-based data organization scheme,\nAnda-enhanced processing units with bit-serial computation, and a runtime\nbit-plane Anda compressor to simultaneously optimize storage, computation, and\nmemory footprints. Our evaluations on FPINT GeMM operations show that Anda\nachieves a 2.4x speedup, 4.0x area efficiency, and 3.1x energy efficiency\nimprovement on average for popular LLMs including OPT, LLaMA, and LLaMA-2\nseries over the GPU-like FP-FP baseline. Anda demonstrates strong adaptability\nacross various application scenarios, accuracy requirements, and system\nperformance, enabling efficient LLM inference across a wide range of deployment\nscenarios.",
      "tldr_zh": "这篇论文针对重量仅量化的LLM推理中，浮点激活带来的能耗和延迟瓶颈，提出Anda数据格式——一种自适应格式，采用组共享指数位和动态尾数位分配，以优化激活精度。论文开发了迭代后训练自适应精度搜索算法，并结合硬件优化技术，如基于位平面的数据组织和Anda增强处理单元，实现存储、计算和内存的全面提升。实验结果显示，Anda在FPINT GeMM操作上比GPU-like基线平均实现2.4x加速、4.0x面积效率和3.1x能效改进，适用于OPT、LLaMA和LLaMA-2等模型的多种部署场景。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AR",
      "comment": "To appear in 2025 IEEE International Symposium on High-Performance\n  Computer Architecture (HPCA 2025)",
      "pdf_url": "http://arxiv.org/pdf/2411.15982v1",
      "published_date": "2024-11-24 20:59:39 UTC",
      "updated_date": "2024-11-24 20:59:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:48:15.267218"
    },
    {
      "arxiv_id": "2411.16763v1",
      "title": "Hide in Plain Sight: Clean-Label Backdoor for Auditing Membership Inference",
      "title_zh": "隐藏在显眼",
      "authors": [
        "Depeng Chen",
        "Hao Chen",
        "Hulin Jin",
        "Jie Cui",
        "Hong Zhong"
      ],
      "abstract": "Membership inference attacks (MIAs) are critical tools for assessing privacy\nrisks and ensuring compliance with regulations like the General Data Protection\nRegulation (GDPR). However, their potential for auditing unauthorized use of\ndata remains under explored. To bridge this gap, we propose a novel clean-label\nbackdoor-based approach for MIAs, designed specifically for robust and stealthy\ndata auditing. Unlike conventional methods that rely on detectable poisoned\nsamples with altered labels, our approach retains natural labels, enhancing\nstealthiness even at low poisoning rates. Our approach employs an optimal\ntrigger generated by a shadow model that mimics the target model's behavior.\nThis design minimizes the feature-space distance between triggered samples and\nthe source class while preserving the original data labels. The result is a\npowerful and undetectable auditing mechanism that overcomes limitations of\nexisting approaches, such as label inconsistencies and visual artifacts in\npoisoned samples. The proposed method enables robust data auditing through\nblack-box access, achieving high attack success rates across diverse datasets\nand model architectures. Additionally, it addresses challenges related to\ntrigger stealthiness and poisoning durability, establishing itself as a\npractical and effective solution for data auditing. Comprehensive experiments\nvalidate the efficacy and generalizability of our approach, outperforming\nseveral baseline methods in both stealth and attack success metrics.",
      "tldr_zh": "该研究提出了一种名为“Hide in Plain Sight”的clean-label backdoor方法，用于Membership Inference Attacks (MIAs)，旨在实现稳健且隐秘的数据审计，从而评估隐私风险和检测未授权数据使用。该方法通过shadow model生成optimal trigger，确保触发样本保留原始标签，同时最小化特征空间距离，避免了传统方法的标签不一致性和视觉伪像问题。实验结果表明，该方法在黑盒访问场景下实现了高攻击成功率，并在多种数据集和模型架构上优于基线方法，证明了其隐秘性和持久性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.16763v1",
      "published_date": "2024-11-24 20:56:18 UTC",
      "updated_date": "2024-11-24 20:56:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:48:27.805912"
    },
    {
      "arxiv_id": "2411.15976v2",
      "title": "DRIVE: Dual-Robustness via Information Variability and Entropic Consistency in Source-Free Unsupervised Domain Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Ruiqiang Xiao",
        "Songning Lai",
        "Yijun Yang",
        "Jiemin Wu",
        "Yutao Yue",
        "Lei Zhu"
      ],
      "abstract": "Adapting machine learning models to new domains without labeled data,\nespecially when source data is inaccessible, is a critical challenge in\napplications like medical imaging, autonomous driving, and remote sensing. This\ntask, known as Source-Free Unsupervised Domain Adaptation (SFUDA), involves\nadapting a pre-trained model to a target domain using only unlabeled target\ndata, which can lead to issues such as overfitting, underfitting, and poor\ngeneralization due to domain discrepancies and noise. Existing SFUDA methods\noften rely on single-model architectures, struggling with uncertainty and\nvariability in the target domain. To address these challenges, we propose DRIVE\n(Dual-Robustness through Information Variability and Entropy), a novel SFUDA\nframework leveraging a dual-model architecture. The two models, initialized\nwith identical weights, work in parallel to capture diverse target domain\ncharacteristics. One model is exposed to perturbations via projection gradient\ndescent (PGD) guided by mutual information, focusing on high-uncertainty\nregions. We also introduce an entropy-aware pseudo-labeling strategy that\nadjusts label weights based on prediction uncertainty, ensuring the model\nfocuses on reliable data while avoiding noisy regions. The adaptation process\nhas two stages: the first aligns the models on stable features using a mutual\ninformation consistency loss, and the second dynamically adjusts the\nperturbation level based on the loss from the first stage, encouraging the\nmodel to explore a broader range of the target domain while preserving existing\nperformance. This enhances generalization capabilities and robustness against\ninterference. Evaluations on standard SFUDA benchmarks show that DRIVE\nconsistently outperforms previous methods, delivering improved adaptation\naccuracy and stability across complex target domains.",
      "tldr_zh": "该论文提出DRIVE框架，用于Source-Free Unsupervised Domain Adaptation (SFUDA)，旨在通过信息变异性和熵一致性提升模型的鲁棒性，以解决无标签目标域中的过拟合和泛化问题。DRIVE采用双模型架构，其中一个模型通过projection gradient descent (PGD)和互信息引导的扰动聚焦高不确定性区域，并引入熵感知伪标签策略来调整标签权重，同时采用两阶段适应过程：第一阶段使用互信息一致性损失对齐模型，第二阶段动态调整扰动水平以探索更广域。实验结果显示，DRIVE在标准SFUDA基准上显著优于现有方法，提高了适应准确性和稳定性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.15976v2",
      "published_date": "2024-11-24 20:35:04 UTC",
      "updated_date": "2024-12-23 09:01:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:48:39.980941"
    },
    {
      "arxiv_id": "2411.15971v1",
      "title": "Advancing Transformative Education: Generative AI as a Catalyst for Equity and Innovation",
      "title_zh": "翻译失败",
      "authors": [
        "Chiranjeevi Bura",
        "Praveen Kumar Myakala"
      ],
      "abstract": "Generative AI is transforming education by enabling personalized learning,\nenhancing administrative efficiency, and fostering creative engagement. This\npaper explores the opportunities and challenges these tools bring to pedagogy,\nproposing actionable frameworks to address existing equity gaps. Ethical\nconsiderations such as algorithmic bias, data privacy, and AI role in human\ncentric education are emphasized. The findings underscore the need for\nresponsible AI integration that ensures accessibility, equity, and innovation\nin educational systems.",
      "tldr_zh": "这篇论文探讨了生成式AI如何推动教育变革，作为促进公平性和创新的催化剂，通过个性化学习、提升行政效率和激发创意参与来实现。该研究提出可操作框架，针对现有公平性差距提供解决方案，同时强调伦理考虑如algorithmic bias、data privacy和AI在人类中心教育中的角色。最终发现强调，需要负责任地整合AI，以确保教育系统的可访问性、公平性和创新发展。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "12 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.15971v1",
      "published_date": "2024-11-24 19:53:48 UTC",
      "updated_date": "2024-11-24 19:53:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:48:51.368804"
    },
    {
      "arxiv_id": "2411.15951v1",
      "title": "Partial Identifiability and Misspecification in Inverse Reinforcement Learning",
      "title_zh": "逆强化学习中的部分可识别性和模型错误指定",
      "authors": [
        "Joar Skalse",
        "Alessandro Abate"
      ],
      "abstract": "The aim of Inverse Reinforcement Learning (IRL) is to infer a reward function\n$R$ from a policy $\\pi$. This problem is difficult, for several reasons. First\nof all, there are typically multiple reward functions which are compatible with\na given policy; this means that the reward function is only *partially\nidentifiable*, and that IRL contains a certain fundamental degree of ambiguity.\nSecondly, in order to infer $R$ from $\\pi$, an IRL algorithm must have a\n*behavioural model* of how $\\pi$ relates to $R$. However, the true relationship\nbetween human preferences and human behaviour is very complex, and practically\nimpossible to fully capture with a simple model. This means that the\nbehavioural model in practice will be *misspecified*, which raises the worry\nthat it might lead to unsound inferences if applied to real-world data. In this\npaper, we provide a comprehensive mathematical analysis of partial\nidentifiability and misspecification in IRL. Specifically, we fully\ncharacterise and quantify the ambiguity of the reward function for all of the\nbehavioural models that are most common in the current IRL literature. We also\nprovide necessary and sufficient conditions that describe precisely how the\nobserved demonstrator policy may differ from each of the standard behavioural\nmodels before that model leads to faulty inferences about the reward function\n$R$. In addition to this, we introduce a cohesive framework for reasoning about\npartial identifiability and misspecification in IRL, together with several\nformal tools that can be used to easily derive the partial identifiability and\nmisspecification robustness of new IRL models, or analyse other kinds of reward\nlearning algorithms.",
      "tldr_zh": "这篇论文探讨了逆强化学习（IRL）中的部分可识别性和模型错配问题，即从策略（π）推断奖励函数（R）时存在的根本模糊性和行为模型的潜在错误。论文通过全面数学分析，量化了常见行为模型下奖励函数的模糊性，并给出了必要和充分条件，精确描述了观察到的策略与模型差异何时会导致不准确的R推断。最终，它引入了一个统一框架和工具，用于分析新IRL模型的部分可识别性及错配鲁棒性，从而为改进奖励学习算法提供基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.15951v1",
      "published_date": "2024-11-24 18:35:46 UTC",
      "updated_date": "2024-11-24 18:35:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:49:02.887592"
    },
    {
      "arxiv_id": "2412.00056v1",
      "title": "Improving Medical Diagnostics with Vision-Language Models: Convex Hull-Based Uncertainty Analysis",
      "title_zh": "使用视觉语言模型改善医疗诊断：基于凸包的不确定性分析",
      "authors": [
        "Ferhat Ozgur Catak",
        "Murat Kuzlu",
        "Taylor Patrick"
      ],
      "abstract": "In recent years, vision-language models (VLMs) have been applied to various\nfields, including healthcare, education, finance, and manufacturing, with\nremarkable performance. However, concerns remain regarding VLMs' consistency\nand uncertainty, particularly in critical applications such as healthcare,\nwhich demand a high level of trust and reliability. This paper proposes a novel\napproach to evaluate uncertainty in VLMs' responses using a convex hull\napproach on a healthcare application for Visual Question Answering (VQA).\nLLM-CXR model is selected as the medical VLM utilized to generate responses for\na given prompt at different temperature settings, i.e., 0.001, 0.25, 0.50,\n0.75, and 1.00. According to the results, the LLM-CXR VLM shows a high\nuncertainty at higher temperature settings. Experimental outcomes emphasize the\nimportance of uncertainty in VLMs' responses, especially in healthcare\napplications.",
      "tldr_zh": "本文提出了一种基于 convex hull 的方法，用于评估 vision-language models (VLMs) 在医疗诊断中的不确定性问题，以提升模型在关键领域的可靠性和信任度。研究以 LLM-CXR 模型为例，在不同温度设置（0.001、0.25、0.50、0.75 和 1.00）下进行 Visual Question Answering (VQA) 实验，结果显示高温设置下模型的不确定性显著增加。实验结果强调了在医疗应用中评估 VLMs 不确定性的重要性，以确保更准确和可信的诊断决策。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.00056v1",
      "published_date": "2024-11-24 17:49:48 UTC",
      "updated_date": "2024-11-24 17:49:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:49:15.028536"
    },
    {
      "arxiv_id": "2411.15927v3",
      "title": "Generative Prompt Internalization",
      "title_zh": "生成式提示内部化",
      "authors": [
        "Haebin Shin",
        "Lei Ji",
        "Yeyun Gong",
        "Sungdong Kim",
        "Eunbi Choi",
        "Minjoon Seo"
      ],
      "abstract": "Prompts used in recent large language model based applications are often\nfixed and lengthy, leading to significant computational overhead. To address\nthis challenge, we propose Generative Prompt Internalization (GenPI), a\nlightweight method that employs a joint training approach. GenPI not only\nreplicates the behavior of models with prompt inputs but also generates the\ncontent of the prompt along with reasons for why the model's behavior should\nchange accordingly. We demonstrate that our approach effectively internalizes\ncomplex prompts across various agent-based application scenarios. For effective\ntraining without interactions with the dedicated environments, we introduce a\ndata synthesis technique that autonomously collects conversational datasets by\nswapping the roles of the agent and environment. This method is especially\nuseful in scenarios where only a predefined prompt is available without a\ncorresponding training dataset. By internalizing complex prompts, Generative\nPrompt Internalization enables high performance and efficient inference without\nthe need for explicit prompts.",
      "tldr_zh": "本研究针对大语言模型应用中固定且冗长的prompts导致的计算开销问题，提出了一种轻量级方法Generative Prompt Internalization (GenPI)，通过joint training实现模型行为的复制和prompt内容生成，同时解释行为变化的原因。GenPI能够在各种基于代理的应用场景中有效内部化复杂prompts，并引入数据合成技术，通过交换代理和环境角色自主收集对话数据集，从而在无专用环境交互的情况下进行高效训练。该方法尤其适用于仅有预定义prompt而无训练数据集的场景，最终实现高性能推理，而无需显式prompts。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL 2025 (Main Conference)",
      "pdf_url": "http://arxiv.org/pdf/2411.15927v3",
      "published_date": "2024-11-24 17:32:20 UTC",
      "updated_date": "2025-03-25 00:38:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:49:26.210830"
    },
    {
      "arxiv_id": "2411.15925v1",
      "title": "Making Images from Images: Interleaving Denoising and Transformation",
      "title_zh": "从图像生成图像：交错去噪和变换",
      "authors": [
        "Shumeet Baluja",
        "David Marwood",
        "Ashwin Baluja"
      ],
      "abstract": "Simply by rearranging the regions of an image, we can create a new image of\nany subject matter. The definition of regions is user definable, ranging from\nregularly and irregularly-shaped blocks, concentric rings, or even individual\npixels. Our method extends and improves recent work in the generation of\noptical illusions by simultaneously learning not only the content of the\nimages, but also the parameterized transformations required to transform the\ndesired images into each other. By learning the image transforms, we allow any\nsource image to be pre-specified; any existing image (e.g. the Mona Lisa) can\nbe transformed to a novel subject. We formulate this process as a constrained\noptimization problem and address it through interleaving the steps of image\ndiffusion with an energy minimization step. Unlike previous methods, increasing\nthe number of regions actually makes the problem easier and improves results.\nWe demonstrate our approach in both pixel and latent spaces. Creative\nextensions, such as using infinite copies of the source image and employing\nmultiple source images, are also given.",
      "tldr_zh": "本研究提出了一种创新方法，通过重新排列图像区域来生成新图像，用户可自定义区域（如块、环或像素）。该方法将图像扩散（denoising）和能量最小化（transformation）步骤交替进行，制定为约束优化问题，同时学习图像内容和参数化变换，从而允许任何现有图像（如蒙娜丽莎）转换为新主题。实验显示，增加区域数量反而简化问题并提升结果，在像素和潜在空间中均有效；此外，还探索了创意扩展，如使用无限拷贝或多个源图像。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.15925v1",
      "published_date": "2024-11-24 17:13:11 UTC",
      "updated_date": "2024-11-24 17:13:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:49:38.012021"
    },
    {
      "arxiv_id": "2411.15923v1",
      "title": "Deep Learning for automated multi-scale functional field boundaries extraction using multi-date Sentinel-2 and PlanetScope imagery: Case Study of Netherlands and Pakistan",
      "title_zh": "翻译失败",
      "authors": [
        "Saba Zahid",
        "Sajid Ghuffar",
        "Obaid-ur-Rehman",
        "Syed Roshaan Ali Shah"
      ],
      "abstract": "This study explores the effectiveness of multi-temporal satellite imagery for\nbetter functional field boundary delineation using deep learning semantic\nsegmentation architecture on two distinct geographical and multi-scale farming\nsystems of Netherlands and Pakistan. Multidate images of April, August and\nOctober 2022 were acquired for PlanetScope and Sentinel-2 in sub regions of\nNetherlands and November 2022, February and March 2023 for selected area of\nDunyapur in Pakistan. For Netherlands, Basic registration crop parcels (BRP)\nvector layer was used as labeled training data. while self-crafted field\nboundary vector data were utilized for Pakistan. Four deep learning models with\nUNET architecture were evaluated using different combinations of multi-date\nimages and NDVI stacks in the Netherlands subregions. A comparative analysis of\nIoU scores assessed the effectiveness of the proposed multi-date NDVI stack\napproach. These findings were then applied for transfer learning, using\npre-trained models from the Netherlands on the selected area in Pakistan.\nAdditionally, separate models were trained using self-crafted field boundary\ndata for Pakistan, and combined models were developed using data from both the\nNetherlands and Pakistan. Results indicate that multi-date NDVI stacks provide\nadditional temporal context, reflecting crop growth over different times of the\nseason. The study underscores the critical role of multi-scale ground\ninformation from diverse geographical areas in developing robust and\nuniversally applicable models for field boundary delineation. The results also\nhighlight the importance of fine spatial resolution for extraction of field\nboundaries in regions with small scale framing. The findings can be extended to\nmulti-scale implementations for improved automatic field boundary delineation\nin heterogeneous agricultural environments.",
      "tldr_zh": "本研究利用多时相 Sentinel-2 和 PlanetScope 图像结合深度学习语义分割（UNET 架构），自动提取多尺度农田边界，并针对荷兰和巴基斯坦的不同农业系统进行案例研究。研究使用多日期图像（如荷兰的2022年4、8、10月和巴基斯坦的2022年11月及2023年2、3月）及 NDVI 堆栈训练模型，评估了四种模型组合，并通过转移学习将荷兰预训练模型应用于巴基斯坦。结果显示，多日期 NDVI 堆栈提供了作物生长的时序上下文，提高了 IoU 分数，模型准确性在不同区域显著提升。研究强调，多尺度地面信息和细空间分辨率（如在小规模农业中）对开发鲁棒的通用模型至关重要，可扩展到异质农业环境的自动边界划分。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "I.2; I.2.10"
      ],
      "primary_category": "cs.CV",
      "comment": "09 pages, To be published",
      "pdf_url": "http://arxiv.org/pdf/2411.15923v1",
      "published_date": "2024-11-24 17:10:36 UTC",
      "updated_date": "2024-11-24 17:10:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:49:53.352766"
    },
    {
      "arxiv_id": "2411.15913v1",
      "title": "A Training-Free Approach for Music Style Transfer with Latent Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Sooyoung Kim",
        "Joonwoo Kwon",
        "Heehwan Wang",
        "Shinjae Yoo",
        "Yuewei Lin",
        "Jiook Cha"
      ],
      "abstract": "Music style transfer, while offering exciting possibilities for personalized\nmusic generation, often requires extensive training or detailed textual\ndescriptions. This paper introduces a novel training-free approach leveraging\npre-trained Latent Diffusion Models (LDMs). By manipulating the self-attention\nfeatures of the LDM, we effectively transfer the style of reference music onto\ncontent music without additional training. Our method achieves superior style\ntransfer and melody preservation compared to existing methods. This work opens\nnew creative avenues for personalized music generation.",
      "tldr_zh": "这篇论文提出了一种无需训练的音乐风格转移方法，利用预训练的 Latent Diffusion Models (LDMs) 来实现个性化音乐生成。方法通过操纵 LDM 的 self-attention features，将参考音乐的风格转移到内容音乐上，同时保持旋律的完整性。与现有方法相比，该方法在风格转移效果和旋律保留方面表现出色。该工作为音乐创作开辟了新的创意途径。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Codes will be released upon acceptance",
      "pdf_url": "http://arxiv.org/pdf/2411.15913v1",
      "published_date": "2024-11-24 16:53:34 UTC",
      "updated_date": "2024-11-24 16:53:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:50:02.296183"
    },
    {
      "arxiv_id": "2411.15903v1",
      "title": "Bimanual Grasp Synthesis for Dexterous Robot Hands",
      "title_zh": "灵巧机器人手的双臂抓取合成",
      "authors": [
        "Yanming Shao",
        "Chenxi Xiao"
      ],
      "abstract": "Humans naturally perform bimanual skills to handle large and heavy objects.\nTo enhance robots' object manipulation capabilities, generating effective\nbimanual grasp poses is essential. Nevertheless, bimanual grasp synthesis for\ndexterous hand manipulators remains underexplored. To bridge this gap, we\npropose the BimanGrasp algorithm for synthesizing bimanual grasps on 3D\nobjects. The BimanGrasp algorithm generates grasp poses by optimizing an energy\nfunction that considers grasp stability and feasibility. Furthermore, the\nsynthesized grasps are verified using the Isaac Gym physics simulation engine.\nThese verified grasp poses form the BimanGrasp-Dataset, the first large-scale\nsynthesized bimanual dexterous hand grasp pose dataset to our knowledge. The\ndataset comprises over 150k verified grasps on 900 objects, facilitating the\nsynthesis of bimanual grasps through a data-driven approach. Last, we propose\nBimanGrasp-DDPM, a diffusion model trained on the BimanGrasp-Dataset. This\nmodel achieved a grasp synthesis success rate of 69.87\\% and significant\nacceleration in computational speed compared to BimanGrasp algorithm.",
      "tldr_zh": "这篇论文针对灵巧机器人手的双手抓取合成问题，提出了 BimanGrasp 算法，通过优化考虑抓取稳定性和可行性的能量函数，在 3D 对象上生成有效的双手抓取姿势，并使用 Isaac Gym 物理模拟引擎进行验证。算法生成的抓取姿势形成了首个大规模数据集 BimanGrasp-Dataset，包含超过15万验证抓取和900个物体，支持数据驱动的抓取合成方法。最后，作者开发了 BimanGrasp-DDPM 扩散模型，在该数据集上训练，实现了69.87%的抓取合成成功率，并显著加速了计算速度 compared to BimanGrasp 算法。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "Published in RA-L 24', 8 pages, 9 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2411.15903v1",
      "published_date": "2024-11-24 16:31:17 UTC",
      "updated_date": "2024-11-24 16:31:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:50:16.429677"
    },
    {
      "arxiv_id": "2411.15895v1",
      "title": "Highly Efficient and Unsupervised Framework for Moving Object Detection in Satellite Videos",
      "title_zh": "高度高效的无监督框架，用于卫星视频中的移动物体检测",
      "authors": [
        "C. Xiao",
        "W. An",
        "Y. Zhang",
        "Z. Su",
        "M. Li",
        "W. Sheng",
        "M. Pietikäinen",
        "L. Liu"
      ],
      "abstract": "Moving object detection in satellite videos (SVMOD) is a challenging task due\nto the extremely dim and small target characteristics. Current learning-based\nmethods extract spatio-temporal information from multi-frame dense\nrepresentation with labor-intensive manual labels to tackle SVMOD, which needs\nhigh annotation costs and contains tremendous computational redundancy due to\nthe severe imbalance between foreground and background regions. In this paper,\nwe propose a highly efficient unsupervised framework for SVMOD. Specifically,\nwe propose a generic unsupervised framework for SVMOD, in which pseudo labels\ngenerated by a traditional method can evolve with the training process to\npromote detection performance. Furthermore, we propose a highly efficient and\neffective sparse convolutional anchor-free detection network by sampling the\ndense multi-frame image form into a sparse spatio-temporal point cloud\nrepresentation and skipping the redundant computation on background regions.\nCoping these two designs, we can achieve both high efficiency (label and\ncomputation efficiency) and effectiveness. Extensive experiments demonstrate\nthat our method can not only process 98.8 frames per second on 1024x1024 images\nbut also achieve state-of-the-art performance. The relabeled dataset and code\nare available at\nhttps://github.com/ChaoXiao12/Moving-object-detection-in-satellite-videos-HiEUM.",
      "tldr_zh": "本论文提出了一种高效的无监督框架，用于卫星视频中移动物体检测（SVMOD），以解决目标暗小和现有方法依赖手动标注的计算冗余问题。该框架包括一个通用无监督模块，通过传统方法生成的伪标签在训练过程中动态演化来提升检测性能，以及一个稀疏卷积无锚点检测网络，将多帧密集图像采样成稀疏时空点云表示，从而跳过背景区域的冗余计算。实验结果显示，该方法在1024x1024图像上实现98.8帧/秒的处理速度，并达到最先进性能，数据集和代码已在GitHub上公开。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.15895v1",
      "published_date": "2024-11-24 16:06:42 UTC",
      "updated_date": "2024-11-24 16:06:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:50:26.801127"
    },
    {
      "arxiv_id": "2411.15894v1",
      "title": "Navigating the Effect of Parametrization for Dimensionality Reduction",
      "title_zh": "翻译失败",
      "authors": [
        "Haiyang Huang",
        "Yingfan Wang",
        "Cynthia Rudin"
      ],
      "abstract": "Parametric dimensionality reduction methods have gained prominence for their\nability to generalize to unseen datasets, an advantage that traditional\napproaches typically lack. Despite their growing popularity, there remains a\nprevalent misconception among practitioners about the equivalence in\nperformance between parametric and non-parametric methods. Here, we show that\nthese methods are not equivalent -- parametric methods retain global structure\nbut lose significant local details. To explain this, we provide evidence that\nparameterized approaches lack the ability to repulse negative pairs, and the\nchoice of loss function also has an impact. Addressing these issues, we\ndeveloped a new parametric method, ParamRepulsor, that incorporates Hard\nNegative Mining and a loss function that applies a strong repulsive force. This\nnew method achieves state-of-the-art performance on local structure\npreservation for parametric methods without sacrificing the fidelity of global\nstructural representation. Our code is available at\nhttps://github.com/hyhuang00/ParamRepulsor.",
      "tldr_zh": "该研究揭示了parametric dimensionality reduction 方法虽然能泛化到新数据集并保留全局结构，但会显著丢失局部细节，与non-parametric方法性能不等价。原因在于这些方法无法有效排斥negative pairs，且损失函数的选择会影响结果。为解决此问题，作者开发了新方法ParamRepulsor，通过引入Hard Negative Mining和强排斥力的损失函数，实现了局部结构保留的state-of-the-art性能，同时保持全局结构的忠实性。该方法的代码已开源在GitHub上。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.15894v1",
      "published_date": "2024-11-24 16:05:08 UTC",
      "updated_date": "2024-11-24 16:05:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:50:38.640946"
    },
    {
      "arxiv_id": "2412.05296v1",
      "title": "Revisiting Your Memory: Reconstruction of Affect-Contextualized Memory via EEG-guided Audiovisual Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Joonwoo Kwon",
        "Heehwan Wang",
        "Jinwoo Lee",
        "Sooyoung Kim",
        "Shinjae Yoo",
        "Yuewei Lin",
        "Jiook Cha"
      ],
      "abstract": "In this paper, we introduce RecallAffectiveMemory, a novel task designed to\nreconstruct autobiographical memories through audio-visual generation guided by\naffect extracted from electroencephalogram (EEG) signals. To support this\npioneering task, we present the EEG-AffectiveMemory dataset, which encompasses\ntextual descriptions, visuals, music, and EEG recordings collected during\nmemory recall from nine participants. Furthermore, we propose RYM (Recall Your\nMemory), a three-stage framework for generating synchronized audio-visual\ncontents while maintaining dynamic personal memory affect trajectories.\nExperimental results indicate that our method can faithfully reconstruct\naffect-contextualized audio-visual memory across all subjects, both\nqualitatively and quantitatively, with participants reporting strong affective\nconcordance between their recalled memories and the generated content. Our\napproaches advance affect decoding research and its practical applications in\npersonalized media creation via neural-based affect comprehension.",
      "tldr_zh": "本研究引入了RecallAffectiveMemory新任务，通过EEG信号提取的情感指导重建自传式记忆，并发布了EEG-AffectiveMemory数据集，包括文本描述、可视化、音乐和九名参与者的EEG记录。作者提出了RYM框架，一个三阶段系统，用于生成同步的音频-视觉内容，同时保持动态的个人记忆情感轨迹。该框架在实验中定性和定量地实现了对情感语境化记忆的忠实重建，参与者反馈显示生成内容与回忆记忆在情感上高度一致。该方法推进了EEG-guided情感解码研究，并为个性化媒体创建提供了实际应用前景。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.AI",
      "comment": "Codes and the dataset will be released upon acceptance",
      "pdf_url": "http://arxiv.org/pdf/2412.05296v1",
      "published_date": "2024-11-24 16:04:03 UTC",
      "updated_date": "2024-11-24 16:04:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:50:50.664969"
    },
    {
      "arxiv_id": "2411.15893v1",
      "title": "Distribution-aware Online Continual Learning for Urban Spatio-Temporal Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Chengxin Wang",
        "Gary Tan",
        "Swagato Barman Roy",
        "Beng Chin Ooi"
      ],
      "abstract": "Urban spatio-temporal (ST) forecasting is crucial for various urban\napplications such as intelligent scheduling and trip planning. Previous studies\nfocus on modeling ST correlations among urban locations in offline settings,\nwhich often neglect the non-stationary nature of urban ST data, particularly,\ndistribution shifts over time. This oversight can lead to degraded performance\nin real-world scenarios. In this paper, we first analyze the distribution\nshifts in urban ST data, and then introduce DOST, a novel online continual\nlearning framework tailored for ST data characteristics. DOST employs an\nadaptive ST network equipped with a variable-independent adapter to address the\nunique distribution shifts at each urban location dynamically. Further, to\naccommodate the gradual nature of these shifts, we also develop an\nawake-hibernate learning strategy that intermittently fine-tunes the adapter\nduring the online phase to reduce computational overhead. This strategy\nintegrates a streaming memory update mechanism designed for urban ST sequential\ndata, enabling effective network adaptation to new patterns while preventing\ncatastrophic forgetting. Experimental results confirm DOST's superiority over\nstate-of-the-art models on four real-world datasets, providing online forecasts\nwithin an average of 0.1 seconds and achieving a 12.89% reduction in forecast\nerrors compared to baseline models.",
      "tldr_zh": "本研究针对城市时空（ST）预测中的分布偏移问题，提出了一种分布感知在线持续学习框架DOST，以提升预测在非平稳数据下的鲁棒性。DOST采用自适应ST网络和variable-independent adapter，动态处理每个城市位置的独特分布偏移，同时引入awake-hibernate学习策略和流式内存更新机制，实现在线阶段间歇性微调以减少计算开销并防止灾难性遗忘。实验结果显示，DOST在四个真实数据集上优于最先进模型，平均预测时间仅为0.1秒，并将预测错误降低了12.89%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.15893v1",
      "published_date": "2024-11-24 16:03:16 UTC",
      "updated_date": "2024-11-24 16:03:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:51:03.003106"
    },
    {
      "arxiv_id": "2411.16761v2",
      "title": "Is 'Right' Right? Enhancing Object Orientation Understanding in Multimodal Large Language Models through Egocentric Instruction Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Ji Hyeok Jung",
        "Eun Tae Kim",
        "Seoyeon Kim",
        "Joo Ho Lee",
        "Bumsoo Kim",
        "Buru Chang"
      ],
      "abstract": "Multimodal large language models (MLLMs) act as essential interfaces,\nconnecting humans with AI technologies in multimodal applications. However,\ncurrent MLLMs face challenges in accurately interpreting object orientation in\nimages due to inconsistent orientation annotations in training data, hindering\nthe development of a coherent orientation understanding. To overcome this, we\npropose egocentric instruction tuning, which aligns MLLMs' orientation\nunderstanding with the user's perspective, based on a consistent annotation\nstandard derived from the user's egocentric viewpoint. We first generate\negocentric instruction data that leverages MLLMs' ability to recognize object\ndetails and applies prior knowledge for orientation understanding. Using this\ndata, we perform instruction tuning to enhance the model's capability for\naccurate orientation interpretation. In addition, we introduce EgoOrientBench,\na benchmark that evaluates MLLMs' orientation understanding across three tasks\nusing images collected from diverse domains. Experimental results on this\nbenchmark show that egocentric instruction tuning significantly improves\norientation understanding without compromising overall MLLM performance. The\ninstruction data and benchmark dataset are available on our project page at\nhttps://github.com/jhCOR/EgoOrientBench.",
      "tldr_zh": "当前的多模态大语言模型 (MLLMs) 在图像中物体方向理解上存在挑战，主要由于训练数据中方向标注的不一致性。论文提出 egocentric instruction tuning 方法，通过从用户视角 (egocentric viewpoint) 生成一致的指令数据，利用 MLLMs 的物体细节识别和先验知识进行微调，从而提升模型的准确性。此外，研究引入了 EgoOrientBench 基准，用于评估 MLLMs 在三个任务上的方向理解能力，实验结果显示该方法显著提高了性能，同时保持了整体模型表现。数据集已公开在项目页面上。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR2025 Camera-ready",
      "pdf_url": "http://arxiv.org/pdf/2411.16761v2",
      "published_date": "2024-11-24 15:07:47 UTC",
      "updated_date": "2025-03-29 09:24:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:51:15.498814"
    },
    {
      "arxiv_id": "2411.16760v1",
      "title": "LibraGrad: Balancing Gradient Flow for Universally Better Vision Transformer Attributions",
      "title_zh": "LibraGrad：平衡梯度流动以实现视觉Transformer归因的普遍提升",
      "authors": [
        "Faridoun Mehri",
        "Mahdieh Soleymani Baghshah",
        "Mohammad Taher Pilehvar"
      ],
      "abstract": "Why do gradient-based explanations struggle with Transformers, and how can we\nimprove them? We identify gradient flow imbalances in Transformers that violate\nFullGrad-completeness, a critical property for attribution faithfulness that\nCNNs naturally possess. To address this issue, we introduce LibraGrad -- a\ntheoretically grounded post-hoc approach that corrects gradient imbalances\nthrough pruning and scaling of backward paths, without changing the forward\npass or adding computational overhead. We evaluate LibraGrad using three metric\nfamilies: Faithfulness, which quantifies prediction changes under perturbations\nof the most and least relevant features; Completeness Error, which measures\nattribution conservation relative to model outputs; and Segmentation AP, which\nassesses alignment with human perception. Extensive experiments across 8\narchitectures, 4 model sizes, and 4 datasets show that LibraGrad universally\nenhances gradient-based methods, outperforming existing white-box methods --\nincluding Transformer-specific approaches -- across all metrics. We demonstrate\nsuperior qualitative results through two complementary evaluations: precise\ntext-prompted region highlighting on CLIP models and accurate class\ndiscrimination between co-occurring animals on ImageNet-finetuned models -- two\nsettings on which existing methods often struggle. LibraGrad is effective even\non the attention-free MLP-Mixer architecture, indicating potential for\nextension to other modern architectures. Our code is freely available at\nhttps://github.com/NightMachinery/LibraGrad.",
      "tldr_zh": "该研究发现，梯度-based 解释在 Transformers 中因梯度流不平衡而违反 FullGrad-completeness 属性，从而影响归因的可靠性。LibraGrad 是一种理论基础坚实的后验方法，通过修剪和缩放后向路径来纠正这些不平衡，而不改变前向传递或增加计算开销。实验在 8 个架构、4 个模型大小和 4 个数据集上评估，使用 Faithfulness、Completeness Error 和 Segmentation AP 等指标，LibraGrad 普遍提升了梯度-based 方法的表现，并在 CLIP 和 ImageNet 微调模型上实现了精确区域突出和动物类别的准确区分，甚至适用于无注意力架构如 MLP-Mixer。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.16760v1",
      "published_date": "2024-11-24 15:02:52 UTC",
      "updated_date": "2024-11-24 15:02:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:51:51.885884"
    },
    {
      "arxiv_id": "2412.07779v1",
      "title": "Evolution of Thought: Diverse and High-Quality Reasoning via Multi-Objective Optimization",
      "title_zh": "Evolution of Thought：通过多目标优化实现多样性和高质量推理",
      "authors": [
        "Biqing Qi",
        "Zhouyi Qian",
        "Yiang Luo",
        "Junqi Gao",
        "Dong Li",
        "Kaiyan Zhang",
        "Bowen Zhou"
      ],
      "abstract": "As multi-modal large language models (MLLMs) are increasingly applied to\ncomplex reasoning tasks, the diversity and quality of reasoning paths become\ncrucial factors affecting their performance. Although current methods aim to\nenhance reasoning quality through path expansion, they often neglect the\ndiversity of reasoning paths and effective information sharing, leading to\nlocal optima and inefficiency. To address these challenges, we propose\nEvolution of Thought (EoT), a multi-objective framework designed to improve\nreasoning by fostering both high-quality and diverse reasoning paths.\nSpecifically, we introduce the Non-dominated Sorting Genetic Algorithm II for\nmulti-objective optimization, utilizing crossover and mutation operators to\npromote greater diversity in reasoning solutions. Additionally, we propose a\nCondensation-Aggregation mechanism to cluster and eliminate redundant paths,\nfacilitate improved information sharing among parent nodes, and ultimately\nenhance both the efficiency and quality of the reasoning process. Validation\nexperiments on various vision-language and language reasoning tasks demonstrate\nthat EoT achieves superior reasoning performance and efficiency compared to\nother competitive baselines. Our study provides a novel perspective on the\ndesign of heuristic reasoning frameworks for MLLMs.",
      "tldr_zh": "本论文提出Evolution of Thought (EoT)，一个多目标优化框架，旨在提升多模态大语言模型(MLLMs)在复杂推理任务中的推理路径多样性和质量，以解决现有方法忽略多样性及信息共享导致的局部最优问题。EoT 利用Non-dominated Sorting Genetic Algorithm II (NSGA-II)的交叉和变异操作来增加解决方案多样性，并引入Condensation-Aggregation机制聚类冗余路径、促进信息共享，从而提高推理效率。实验验证显示，EoT 在各种视觉-语言和语言推理任务上比基线模型表现出更优的性能和效率，为MLLMs的启发式推理框架设计提供了新颖视角。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07779v1",
      "published_date": "2024-11-24 14:59:30 UTC",
      "updated_date": "2024-11-24 14:59:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:51:49.483821"
    },
    {
      "arxiv_id": "2411.15862v4",
      "title": "Do LLMs Really Think Step-by-step In Implicit Reasoning?",
      "title_zh": "LLMs 是否真的在隐式推理中逐步思考？",
      "authors": [
        "Yijiong Yu"
      ],
      "abstract": "It has been well-known that Chain-of-Thought can remarkably enhance LLMs'\nperformance on complex tasks. However, because it also introduces slower\ninference speeds and higher computational costs, many researches have attempted\nto use implicit CoT, which does not need LLMs to explicitly generate the\nintermediate steps. However, the invisible reasoning process leaves us a doubt\nthat, can implicit CoT really be equal to explicit CoT? Therefore, in this\nstudy, we address this question through experiments. We probe the information\nof intermediate steps from the model's hidden states when it is either trained\nor prompted to perform implicit CoT. The results surprisingly indicate that\nwhen prompted, LLMs hardly think about intermediate steps, suggesting they may\njust rely on experience rather than strict step-by-step reasoning. But when\ntrained, they indeed calculate intermediate steps. Moreover, in both\nsituations, we find the effect of using implicit CoT is susceptible to the\nformat of the problem, reaffirming the current deficiency of implicit CoT.",
      "tldr_zh": "本文研究了大型语言模型 (LLMs) 在隐式 Chain-of-Thought (CoT) 中是否真正进行步步推理，通过实验从模型隐藏状态中探测中间步骤信息。结果显示，当使用提示 (prompted) 时，LLMs 几乎不计算中间步骤，而是依赖经验进行推理；但当模型经过训练 (trained) 时，它们确实会处理这些步骤。此外，隐式 CoT 的效果容易受问题格式影响，这突显了其潜在缺陷，并质疑了其与显式 CoT 的等效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "The code is in\n  https://github.com/yuyijiong/if_step_by_step_implicit_CoT",
      "pdf_url": "http://arxiv.org/pdf/2411.15862v4",
      "published_date": "2024-11-24 14:38:59 UTC",
      "updated_date": "2025-01-16 06:07:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:51:51.947989"
    },
    {
      "arxiv_id": "2412.01705v1",
      "title": "Uncertainty-Aware Regularization for Image-to-Image Translation",
      "title_zh": "翻译失败",
      "authors": [
        "Anuja Vats",
        "Ivar Farup",
        "Marius Pedersen",
        "Kiran Raja"
      ],
      "abstract": "The importance of quantifying uncertainty in deep networks has become\nparamount for reliable real-world applications. In this paper, we propose a\nmethod to improve uncertainty estimation in medical Image-to-Image (I2I)\ntranslation. Our model integrates aleatoric uncertainty and employs\nUncertainty-Aware Regularization (UAR) inspired by simple priors to refine\nuncertainty estimates and enhance reconstruction quality. We show that by\nleveraging simple priors on parameters, our approach captures more robust\nuncertainty maps, effectively refining them to indicate precisely where the\nnetwork encounters difficulties, while being less affected by noise. Our\nexperiments demonstrate that UAR not only improves translation performance, but\nalso provides better uncertainty estimations, particularly in the presence of\nnoise and artifacts. We validate our approach using two medical imaging\ndatasets, showcasing its effectiveness in maintaining high confidence in\nfamiliar regions while accurately identifying areas of uncertainty in\nnovel/ambiguous scenarios.",
      "tldr_zh": "该论文强调了在深度网络中量化不确定性的重要性，并提出了一种针对医疗图像到图像（I2I）翻译的改进方法。该方法整合了 aleatoric uncertainty，并引入 Uncertainty-Aware Regularization (UAR)，利用简单先验来优化不确定性估计，提升重建质量，从而更准确地识别网络困难区域并减少噪声影响。实验在两个医疗成像数据集上验证了 UAR 的有效性，不仅提高了翻译性能，还在噪声和伪影环境下提供了更可靠的不确定性估计。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted WACV 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.01705v1",
      "published_date": "2024-11-24 14:05:27 UTC",
      "updated_date": "2024-11-24 14:05:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:52:03.387140"
    },
    {
      "arxiv_id": "2411.15844v1",
      "title": "Unveiling the Superior Paradigm: A Comparative Study of Source-Free Domain Adaptation and Unsupervised Domain Adaptation",
      "title_zh": "揭示优越范式：无源域适应与无监督域适应的比较研究",
      "authors": [
        "Fan Wang",
        "Zhongyi Han",
        "Xingbo Liu",
        "Xin Gao",
        "Yilong Yin"
      ],
      "abstract": "In domain adaptation, there are two popular paradigms: Unsupervised Domain\nAdaptation (UDA), which aligns distributions using source data, and Source-Free\nDomain Adaptation (SFDA), which leverages pre-trained source models without\naccessing source data. Evaluating the superiority of UDA versus SFDA is an open\nand timely question with significant implications for deploying adaptive\nalgorithms in practical applications. In this study, we demonstrate through\npredictive coding theory and extensive experiments on multiple benchmark\ndatasets that SFDA generally outperforms UDA in real-world scenarios.\nSpecifically, SFDA offers advantages in time efficiency, storage requirements,\ntargeted learning objectives, reduced risk of negative transfer, and increased\nrobustness against overfitting. Notably, SFDA is particularly effective in\nmitigating negative transfer when there are substantial distribution\ndiscrepancies between source and target domains. Additionally, we introduce a\nnovel data-model fusion scenario, where data sharing among stakeholders varies\n(e.g., some provide raw data while others provide only models), and reveal that\ntraditional UDA and SFDA methods do not fully exploit their potential in this\ncontext. To address this limitation and capitalize on the strengths of SFDA, we\npropose a novel weight estimation method that effectively integrates available\nsource data into multi-SFDA (MSFDA) approaches, thereby enhancing model\nperformance within this scenario. This work provides a thorough analysis of UDA\nversus SFDA and advances a practical approach to model adaptation across\ndiverse real-world environments.",
      "tldr_zh": "本研究比较了无监督域适应(UDA)和无源域适应(SFDA)两种范式，通过预测编码理论和多个基准数据集的实验证明，SFDA在真实场景中通常优于UDA，尤其在时间效率、存储需求、针对性学习目标、减少负转移风险以及鲁棒性方面表现出色。SFDA特别适用于源域和目标域分布差异较大的情况，能有效缓解负转移问题。该研究还引入了数据-模型融合场景，揭示传统方法未充分利用潜力，并提出了一种新颖的权重估计方法来整合可用源数据，提升多SFDA(MSFDA)方法的性能。该工作为实际应用中的模型适配提供了深入分析和实用进阶方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2411.15844v1",
      "published_date": "2024-11-24 13:49:29 UTC",
      "updated_date": "2024-11-24 13:49:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:52:15.169966"
    },
    {
      "arxiv_id": "2411.15832v2",
      "title": "Creating Scalable AGI: the Open General Intelligence Framework",
      "title_zh": "创建可扩展的 AGI：开放通用智能框架",
      "authors": [
        "Daniel A. Dollinger",
        "Michael Singleton"
      ],
      "abstract": "Recent advancements in Artificial Intelligence (AI), particularly with Large\nLanguage Models (LLMs), have led to significant progress in narrow tasks such\nas image classification, language translation, coding, and writing. However,\nthese models face limitations in reliability and scalability due to their\nsiloed architectures, which are designed to handle only one data modality (data\ntype) at a time. This single modal approach hinders their ability to integrate\nthe complex set of data points required for real-world challenges and\nproblem-solving tasks like medical diagnosis, quality assurance, equipment\ntroubleshooting, and financial decision-making. Addressing these real-world\nchallenges requires a more capable Artificial General Intelligence (AGI)\nsystem. Our primary contribution is the development of the Open General\nIntelligence (OGI) framework, a novel systems architecture that serves as a\nmacro design reference for AGI. The OGI framework adopts a modular approach to\nthe design of intelligent systems, based on the premise that cognition must\noccur across multiple specialized modules that can seamlessly operate as a\nsingle system. OGI integrates these modules using a dynamic processing system\nand a fabric interconnect, enabling real-time adaptability, multi-modal\nintegration, and scalable processing. The OGI framework consists of three key\ncomponents: (1) Overall Macro Design Guidance that directs operational design\nand processing, (2) a Dynamic Processing System that controls routing, primary\ngoals, instructions, and weighting, and (3) Framework Areas, a set of\nspecialized modules that operate cohesively to form a unified cognitive system.\nBy incorporating known principles from human cognition into AI systems, the OGI\nframework aims to overcome the challenges observed in today's intelligent\nsystems, paving the way for more holistic and context-aware problem-solving\ncapabilities.",
      "tldr_zh": "该论文讨论了当前人工智能（AI）如Large Language Models (LLMs)在狭隘任务（如图像分类和语言翻译）上的进展，但这些模型因单一模态架构而面临可靠性与可扩展性挑战，无法有效处理多模态的真实世界问题，如医疗诊断或金融决策。作者的主要贡献是提出Open General Intelligence (OGI)框架，这是一种模块化的AGI系统设计参考，采用动态处理系统和fabric interconnect，实现多模态集成、实时适应和可扩展处理。OGI框架包括三个关键组件：Overall Macro Design Guidance指导整体设计、Dynamic Processing System控制路由和目标，以及Framework Areas的专用模块，这些模块借鉴人类认知原则，形成统一的认知系统，最终提升AI的整体性和上下文感知问题解决能力。",
      "categories": [
        "cs.AI",
        "I.2; C.5"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, IEEE SYSCON 2025 Submission",
      "pdf_url": "http://arxiv.org/pdf/2411.15832v2",
      "published_date": "2024-11-24 13:17:53 UTC",
      "updated_date": "2024-11-27 19:25:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:52:27.520367"
    },
    {
      "arxiv_id": "2411.15831v1",
      "title": "Efficient and Private: Memorisation under differentially private parameter-efficient fine-tuning in language models",
      "title_zh": "翻译失败",
      "authors": [
        "Olivia Ma",
        "Jonathan Passerat-Palmbach",
        "Dmitrii Usynin"
      ],
      "abstract": "Fine-tuning large language models (LLMs) for specific tasks introduces\nprivacy risks, as models may inadvertently memorise and leak sensitive training\ndata. While Differential Privacy (DP) offers a solution to mitigate these\nrisks, it introduces significant computational and performance trade-offs,\nparticularly with standard fine-tuning approaches. Previous work has primarily\nfocused on full-parameter updates, which are computationally intensive and may\nnot fully leverage DPs potential in large models. In this work, we address\nthese shortcomings by investigating Parameter-Efficient Fine-Tuning (PEFT)\nmethods under DP constraints. We show that PEFT methods achieve comparable\nperformance to standard fine-tuning while requiring fewer parameters and\nsignificantly reducing privacy leakage. Furthermore, we incorporate a data\npoisoning experiment involving intentional mislabelling to assess model\nmemorisation and directly measure privacy risks. Our findings indicate that\nPEFT methods not only provide a promising alternative but also serve as a\ncomplementary approach for privacy-preserving, resource-efficient fine-tuning\nof LLMs.",
      "tldr_zh": "该研究探讨了在微调大型语言模型（LLMs）时存在的隐私风险问题，特别是模型可能无意中记忆和泄露敏感训练数据。为缓解此问题，论文引入差分隐私（DP）与参数高效微调（PEFT）方法，相比标准微调，PEFT显著减少参数数量并降低隐私泄露，同时保持可比性能。研究通过数据中毒实验评估模型记忆和隐私风险，发现PEFT不仅是资源高效的替代方案，还能增强隐私保护，为LLMs的细调提供更可靠的框架。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.15831v1",
      "published_date": "2024-11-24 13:17:36 UTC",
      "updated_date": "2024-11-24 13:17:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:52:38.440598"
    },
    {
      "arxiv_id": "2411.15821v2",
      "title": "Is Training Data Quality or Quantity More Impactful to Small Language Model Performance?",
      "title_zh": "训练数据的质量还是数量对小型语言模型性能的影响更大？",
      "authors": [
        "Aryan Sajith",
        "Krishna Chaitanya Rao Kathala"
      ],
      "abstract": "This study investigates the relative impact of training data quality versus\nquantity on the performance of small language models (SLMs), utilizing the\nTinyStories dataset for empirical analysis. Analysis of dataset variations with\nrespect to size (25% and 50% of the original size) and duplication (controlled\nrates of 25%, 50%, 75%, and 100%) were performed. Model performance was\nevaluated based on the validation loss, accuracy, and perplexity metrics.\nResults indicate training data quality plays a more significant role in the\noverall performance of SLMs, especially given scale of this experiment. Minimal\nduplication positively impacted model accuracy (+0.87% increase in accuracy at\n25% duplication) without significantly increasing perplexity (+0.52% increase\ngoing from 0% to 25% duplication) but excessive duplication led to pronounced\nperformance degradation (-40% drop in accuracy at 100% duplication). The\nimplications of this exploration extend beyond just model performance; training\nlarge-scale models imposes significant financial and computational burdens,\nwhich can be prohibitive for organizations, individuals, and the public at\nlarge, especially in developing countries. Additionally, the energy consumption\nassociated with large-scale training raises environmental concerns.\nUnderstanding the relative importance of data quality versus quantity could\ndemocratize AI technology, making advanced models more accessible and\nsustainable for all.",
      "tldr_zh": "本研究探讨了训练数据质量与数量对小型语言模型 (SLMs) 性能的影响，使用 TinyStories 数据集进行实证分析，包括数据集大小（25% 和 50% 的原始大小）和重复率（25%、50%、75%、100%）的变异，并通过验证损失、准确率和困惑度等指标评估模型表现。结果显示，数据质量对 SLMs 性能的影响更大；适度重复（如 25%）可略微提升准确率（+0.87%）且仅小幅增加困惑度（+0.52%），但过度重复（如 100%）会导致显著性能下降（准确率下降 40%）。此发现有助于降低 AI 训练的财务、计算和环境负担，促进 AI 技术的可访问性和可持续性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.15821v2",
      "published_date": "2024-11-24 12:51:50 UTC",
      "updated_date": "2025-03-28 22:38:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:52:51.766902"
    },
    {
      "arxiv_id": "2412.00053v1",
      "title": "LeMoLE: LLM-Enhanced Mixture of Linear Experts for Time Series Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Lingzheng Zhang",
        "Lifeng Shen",
        "Yimin Zheng",
        "Shiyuan Piao",
        "Ziyue Li",
        "Fugee Tsung"
      ],
      "abstract": "Recent research has shown that large language models (LLMs) can be\neffectively used for real-world time series forecasting due to their strong\nnatural language understanding capabilities. However, aligning time series into\nsemantic spaces of LLMs comes with high computational costs and inference\ncomplexity, particularly for long-range time series generation. Building on\nrecent advancements in using linear models for time series, this paper\nintroduces an LLM-enhanced mixture of linear experts for precise and efficient\ntime series forecasting. This approach involves developing a mixture of linear\nexperts with multiple lookback lengths and a new multimodal fusion mechanism.\nThe use of a mixture of linear experts is efficient due to its simplicity,\nwhile the multimodal fusion mechanism adaptively combines multiple linear\nexperts based on the learned features of the text modality from pre-trained\nlarge language models. In experiments, we rethink the need to align time series\nto LLMs by existing time-series large language models and further discuss their\nefficiency and effectiveness in time series forecasting. Our experimental\nresults show that the proposed LeMoLE model presents lower prediction errors\nand higher computational efficiency than existing LLM models.",
      "tldr_zh": "本研究提出LeMoLE模型，这是一种LLM-Enhanced Mixture of Linear Experts，用于精确和高效的时间序列预测，以解决现有LLMs在对齐时间序列时的高计算成本和推理复杂性问题。该模型结合了具有多种回溯长度的混合线性专家，以及一个新的多模态融合机制，该机制利用预训练LLMs的文本模态特征来自适应地整合多个专家。实验结果表明，LeMoLE在预测错误率和计算效率上均优于现有LLM模型，为时间序列预测提供了更高效的替代方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.00053v1",
      "published_date": "2024-11-24 12:40:50 UTC",
      "updated_date": "2024-11-24 12:40:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:53:42.227303"
    },
    {
      "arxiv_id": "2411.15811v3",
      "title": "FastTrackTr:Towards Fast Multi-Object Tracking with Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Pan Liao",
        "Feng Yang",
        "Di Wu",
        "Jinwen Yu",
        "Wenhui Zhao",
        "Bo Liu"
      ],
      "abstract": "Transformer-based multi-object tracking (MOT) methods have captured the\nattention of many researchers in recent years. However, these models often\nsuffer from slow inference speeds due to their structure or other issues. To\naddress this problem, we revisited the Joint Detection and Tracking (JDT)\nmethod by looking back at past approaches. By integrating the original JDT\napproach with some advanced theories, this paper employs an efficient method of\ninformation transfer between frames on the DETR, constructing a fast and novel\nJDT-type MOT framework: FastTrackTr. Thanks to the superiority of this\ninformation transfer method, our approach not only reduces the number of\nqueries required during tracking but also avoids the excessive introduction of\nnetwork structures, ensuring model simplicity. Experimental results indicate\nthat our method has the potential to achieve real-time tracking and exhibits\ncompetitive tracking accuracy across multiple datasets.",
      "tldr_zh": "这篇论文针对 Transformer-based multi-object tracking (MOT) 方法的慢速推理问题，提出了一种新型框架 FastTrackTr。作者通过整合 Joint Detection and Tracking (JDT) 方法与先进理论，在 DETR 基础上实现高效的信息传输，减少查询数量并避免过度引入网络结构，从而保持模型的简单性。实验结果表明，FastTrackTr 实现了实时跟踪，并在多个数据集上展现出竞争性的跟踪准确性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.15811v3",
      "published_date": "2024-11-24 12:34:02 UTC",
      "updated_date": "2025-03-07 03:39:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:55:14.447112"
    },
    {
      "arxiv_id": "2411.15806v2",
      "title": "Broad Critic Deep Actor Reinforcement Learning for Continuous Control",
      "title_zh": "翻译失败",
      "authors": [
        "Shiron Thalagala",
        "Pak Kin Wong",
        "Xiaozheng Wang",
        "Tianang Sun"
      ],
      "abstract": "In the domain of continuous control, deep reinforcement learning (DRL)\ndemonstrates promising results. However, the dependence of DRL on deep neural\nnetworks (DNNs) results in the demand for extensive data and increased\ncomputational cost. To address this issue, a novel hybrid actor-critic\nreinforcement learning (RL) framework is introduced. The proposed framework\nintegrates the broad learning system (BLS) with DNN, aiming to merge the\nstrengths of both distinct architectural paradigms. Specifically, the critic\nnetwork employs BLS for rapid value estimation via ridge regression, while the\nactor network retains the DNN structure to optimize policy gradients. This\nhybrid design is generalizable and can enhance existing actor-critic\nalgorithms. To demonstrate its versatility, the proposed framework is\nintegrated into three widely used actor-critic algorithms -- deep deterministic\npolicy gradient (DDPG), soft actor-critic (SAC), and twin delayed DDPG (TD3),\nresulting in BLS-augmented variants. Experimental results reveal that all\nBLS-enhanced versions surpass their original counterparts in terms of training\nefficiency and accuracy. These improvements highlight the suitability of the\nproposed framework for real-time control scenarios, where computational\nefficiency and rapid adaptation are critical.",
      "tldr_zh": "这篇论文针对深度强化学习（DRL）在连续控制领域的海量数据需求和高计算成本问题，提出了一种新型混合 actor-critic 框架，将广义学习系统（BLS）与深度神经网络（DNN）相结合。框架中，critic 网络使用 BLS 通过岭回归快速估计价值，而 actor 网络保留 DNN 结构以优化策略梯度。该设计可泛化地增强现有算法，如 DDPG、SAC 和 TD3，实验结果显示增强版本在训练效率和准确性上均优于原版。整体框架适用于实时控制场景，提供更高效的适应性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, The final published version is available at:\n  https://ieeexplore.ieee.org/document/10957827 (DOI:\n  10.1109/TNNLS.2025.3554082)",
      "pdf_url": "http://arxiv.org/pdf/2411.15806v2",
      "published_date": "2024-11-24 12:24:46 UTC",
      "updated_date": "2025-04-12 14:53:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:55:26.075804"
    },
    {
      "arxiv_id": "2411.15805v1",
      "title": "Benchmarking Active Learning for NILM",
      "title_zh": "NILM 的主动学习基准测试",
      "authors": [
        "Dhruv Patel",
        "Ankita Kumari Jain",
        "Haikoo Khandor",
        "Xhitij Choudhary",
        "Nipun Batra"
      ],
      "abstract": "Non-intrusive load monitoring (NILM) focuses on disaggregating total\nhousehold power consumption into appliance-specific usage. Many advanced NILM\nmethods are based on neural networks that typically require substantial amounts\nof labeled appliance data, which can be challenging and costly to collect in\nreal-world settings. We hypothesize that appliance data from all households\ndoes not uniformly contribute to NILM model improvements. Thus, we propose an\nactive learning approach to selectively install appliance monitors in a limited\nnumber of houses. This work is the first to benchmark the use of active\nlearning for strategically selecting appliance-level data to optimize NILM\nperformance. We first develop uncertainty-aware neural networks for NILM and\nthen install sensors in homes where disaggregation uncertainty is highest.\nBenchmarking our method on the publicly available Pecan Street Dataport\ndataset, we demonstrate that our approach significantly outperforms a standard\nrandom baseline and achieves performance comparable to models trained on the\nentire dataset. Using this approach, we achieve comparable NILM accuracy with\napproximately 30% of the data, and for a fixed number of sensors, we observe up\nto a 2x reduction in disaggregation errors compared to random sampling.",
      "tldr_zh": "本研究针对非侵入式负载监测(NILM)，提出使用主动学习(active learning)来优化家电数据收集，以减少模型训练所需的数据量。作者开发了不确定性感知的神经网络，用于识别NILM分解中的高不确定性家庭，并优先在这些家庭安装传感器。实验在Pecan Street Dataport数据集上基准测试显示，该方法显著优于随机基准，仅需约30%的数据即可达到与全数据集训练模型相当的准确率，并可将分解错误减少多达2倍。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.15805v1",
      "published_date": "2024-11-24 12:22:59 UTC",
      "updated_date": "2024-11-24 12:22:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:55:37.655949"
    },
    {
      "arxiv_id": "2411.15804v1",
      "title": "LoRA-Mini : Adaptation Matrices Decomposition and Selective Training",
      "title_zh": "翻译失败",
      "authors": [
        "Ayush Singh",
        "Rajdeep Aher",
        "Shivank Garg"
      ],
      "abstract": "The rapid advancements in large language models (LLMs) have revolutionized\nnatural language processing, creating an increased need for efficient,\ntask-specific fine-tuning methods. Traditional fine-tuning of LLMs involves\nupdating a large number of parameters, which is computationally expensive and\nmemory-intensive. Low-Rank Adaptation (LoRA) has emerged as a promising\nsolution, enabling parameter-efficient fine-tuning by reducing the number of\ntrainable parameters. However, while LoRA reduces the number of trainable\nparameters, LoRA modules still create significant storage challenges. We\npropose LoRA-Mini, an optimized adaptation of LoRA that improves parameter\nefficiency by splitting low-rank matrices into four parts, with only the two\ninner matrices being trainable. This approach achieves upto a 20x reduction\ncompared to standard LoRA in the number of trainable parameters while\npreserving performance levels comparable to standard LoRA, addressing both\ncomputational and storage efficiency in LLM fine-tuning.",
      "tldr_zh": "该论文针对大型语言模型(LLMs)的微调问题，提出LoRA-Mini方法，以解决传统微调的计算和存储效率挑战。LoRA-Mini通过将低秩适配矩阵分解成四个部分，仅训练两个内部矩阵，从而将可训练参数比标准LoRA减少高达20倍。实验结果显示，该方法在保持性能水平的同时，大大提升了LLMs微调的计算和存储效率。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.15804v1",
      "published_date": "2024-11-24 12:21:14 UTC",
      "updated_date": "2024-11-24 12:21:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:55:48.855114"
    },
    {
      "arxiv_id": "2411.15802v1",
      "title": "Medical Slice Transformer: Improved Diagnosis and Explainability on 3D Medical Images with DINOv2",
      "title_zh": "翻译失败",
      "authors": [
        "Gustav Müller-Franzes",
        "Firas Khader",
        "Robert Siepmann",
        "Tianyu Han",
        "Jakob Nikolas Kather",
        "Sven Nebelung",
        "Daniel Truhn"
      ],
      "abstract": "MRI and CT are essential clinical cross-sectional imaging techniques for\ndiagnosing complex conditions. However, large 3D datasets with annotations for\ndeep learning are scarce. While methods like DINOv2 are encouraging for 2D\nimage analysis, these methods have not been applied to 3D medical images.\nFurthermore, deep learning models often lack explainability due to their\n\"black-box\" nature. This study aims to extend 2D self-supervised models,\nspecifically DINOv2, to 3D medical imaging while evaluating their potential for\nexplainable outcomes. We introduce the Medical Slice Transformer (MST)\nframework to adapt 2D self-supervised models for 3D medical image analysis. MST\ncombines a Transformer architecture with a 2D feature extractor, i.e., DINOv2.\nWe evaluate its diagnostic performance against a 3D convolutional neural\nnetwork (3D ResNet) across three clinical datasets: breast MRI (651 patients),\nchest CT (722 patients), and knee MRI (1199 patients). Both methods were tested\nfor diagnosing breast cancer, predicting lung nodule dignity, and detecting\nmeniscus tears. Diagnostic performance was assessed by calculating the Area\nUnder the Receiver Operating Characteristic Curve (AUC). Explainability was\nevaluated through a radiologist's qualitative comparison of saliency maps based\non slice and lesion correctness. P-values were calculated using Delong's test.\nMST achieved higher AUC values compared to ResNet across all three datasets:\nbreast (0.94$\\pm$0.01 vs. 0.91$\\pm$0.02, P=0.02), chest (0.95$\\pm$0.01 vs.\n0.92$\\pm$0.02, P=0.13), and knee (0.85$\\pm$0.04 vs. 0.69$\\pm$0.05, P=0.001).\nSaliency maps were consistently more precise and anatomically correct for MST\nthan for ResNet. Self-supervised 2D models like DINOv2 can be effectively\nadapted for 3D medical imaging using MST, offering enhanced diagnostic accuracy\nand explainability compared to convolutional neural networks.",
      "tldr_zh": "这篇论文提出了 Medical Slice Transformer (MST) 框架，将 2D 自监督模型 DINOv2 扩展到 3D 医学图像分析，以解决数据标注稀缺和模型可解释性不足的问题。MST 通过结合 Transformer 架构和 DINOv2 特征提取器，与 3D ResNet 在乳房 MRI（651 患者）、胸部 CT（722 患者）和膝部 MRI（1199 患者）数据集上进行比较，用于诊断乳腺癌、预测肺结节性质和检测半月板撕裂。结果显示，MST 取得了更高的 AUC 值，例如乳房 MRI 为 0.94±0.01 vs. 0.91±0.02 (P=0.02)，并生成更精确的显著性地图，提供更好的解剖学正确性。该框架证明了自监督 2D 模型可有效适应 3D 医学成像，提升诊断准确性和可解释性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.15802v1",
      "published_date": "2024-11-24 12:11:11 UTC",
      "updated_date": "2024-11-24 12:11:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:56:05.144594"
    },
    {
      "arxiv_id": "2411.15801v1",
      "title": "A review on Machine Learning based User-Centric Multimedia Streaming Techniques",
      "title_zh": "基于机器学习的以用户为中心的多媒体流媒体技术综述",
      "authors": [
        "Monalisa Ghosh",
        "Chetna Singhal"
      ],
      "abstract": "The multimedia content and streaming are a major means of information\nexchange in the modern era and there is an increasing demand for such services.\nThis coupled with the advancement of future wireless networks B5G/6G and the\nproliferation of intelligent handheld mobile devices, has facilitated the\navailability of multimedia content to heterogeneous mobile users. Apart from\nthe conventional video, the 360$^o$ videos have gained popularity with the\nemerging virtual reality applications. All formats of videos (conventional and\n360$^o$) undergo processing, compression, and transmission across dynamic\nwireless channels with restricted bandwidth to facilitate the streaming\nservices. This causes video impairments, leading to quality degradation and\nposes challenges in delivering good Quality-of-Experience (QoE) to the viewers.\nThe QoE is a prominent subjective quality measure to assess multimedia\nservices. This requires end-to-end QoE evaluation. Efficient multimedia\nstreaming techniques can improve the service quality while dealing with dynamic\nnetwork and end-user challenges. A paradigm shift in user-centric multimedia\nservices is envisioned with a focus on Machine Learning (ML) based QoE modeling\nand streaming strategies. This survey paper presents a comprehensive overview\nof the overall and continuous, time varying QoE modeling for the purpose of QoE\nmanagement in multimedia services. It also examines the recent research on\nintelligent and adaptive multimedia streaming strategies, with a special\nemphasis on ML based techniques for video (conventional and 360$^o$) streaming.\nThis paper discusses the overall and continuous QoE modeling to optimize the\nend-user viewing experience, efficient video streaming with a focus on\nuser-centric strategies, associated datasets for modeling and streaming, along\nwith existing shortcoming and open challenges.",
      "tldr_zh": "这篇综述论文回顾了机器学习(ML) 在用户中心多媒体流媒体技术中的应用，重点分析了未来无线网络(B5G/6G)和智能设备背景下，多媒体内容（如常规视频和360°视频）的处理、压缩和传输挑战。论文详细探讨了整体和连续的QoE（Quality-of-Experience）建模方法，以及基于ML的智能自适应流媒体策略，以优化端用户体验并应对动态网络问题。最终，它总结了相关数据集、现有缺点（如视频损伤和带宽限制）以及未来的开放挑战，为提升多媒体服务质量提供了全面指导。",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.MM",
      "comment": "Computer Communications",
      "pdf_url": "http://arxiv.org/pdf/2411.15801v1",
      "published_date": "2024-11-24 12:07:47 UTC",
      "updated_date": "2024-11-24 12:07:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:56:15.109011"
    },
    {
      "arxiv_id": "2411.15796v1",
      "title": "Data Lineage Inference: Uncovering Privacy Vulnerabilities of Dataset Pruning",
      "title_zh": "翻译失败",
      "authors": [
        "Qi Li",
        "Cheng-Long Wang",
        "Yinzhi Cao",
        "Di Wang"
      ],
      "abstract": "In this work, we systematically explore the data privacy issues of dataset\npruning in machine learning systems. Our findings reveal, for the first time,\nthat even if data in the redundant set is solely used before model training,\nits pruning-phase membership status can still be detected through attacks.\nSince this is a fully upstream process before model training, traditional model\noutput-based privacy inference methods are completely unsuitable. To address\nthis, we introduce a new task called Data-Centric Membership Inference and\npropose the first ever data-centric privacy inference paradigm named Data\nLineage Inference (DaLI). Under this paradigm, four threshold-based attacks are\nproposed, named WhoDis, CumDis, ArraDis and SpiDis. We show that even without\naccess to downstream models, adversaries can accurately identify the redundant\nset with only limited prior knowledge. Furthermore, we find that different\npruning methods involve varying levels of privacy leakage, and even the same\npruning method can present different privacy risks at different pruning\nfractions. We conducted an in-depth analysis of these phenomena and introduced\na metric called the Brimming score to offer guidance for selecting pruning\nmethods with privacy protection in mind.",
      "tldr_zh": "本研究系统探讨了机器学习系统中数据集修剪（Dataset Pruning）的隐私漏洞，发现即使冗余数据仅在模型训练前使用，其修剪阶段的成员身份仍可通过攻击检测。论文首次引入Data-Centric Membership Inference任务，并提出Data Lineage Inference (DaLI)范式，作为传统模型输出-based隐私推理方法的替代。研究开发了四个基于阈值的攻击方法：WhoDis、CumDis、ArraDis和SpiDis，这些攻击无需访问下游模型，仅凭有限的先验知识即可准确识别冗余集。实验结果显示，不同修剪方法存在不同的隐私泄露水平，且同一方法在不同修剪比例下风险各异；为此，论文引入Brimming score指标，以指导选择具有隐私保护的修剪策略。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.15796v1",
      "published_date": "2024-11-24 11:46:59 UTC",
      "updated_date": "2024-11-24 11:46:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:56:28.105935"
    },
    {
      "arxiv_id": "2411.15778v4",
      "title": "Enhancing the automatic segmentation and analysis of 3D liver vasculature models",
      "title_zh": "翻译失败",
      "authors": [
        "Yassine Machta",
        "Omar Ali",
        "Kevin Hakkakian",
        "Ana Vlasceanu",
        "Amaury Facque",
        "Nicolas Golse",
        "Irene Vignon-Clementel"
      ],
      "abstract": "Surgical assessment of liver cancer patients requires identification of the\nvessel trees from medical images. Specifically, the venous trees - the portal\n(perfusing) and the hepatic (draining) trees are important for understanding\nthe liver anatomy and disease state, and perform surgery planning. This\nresearch aims to improve the 3D segmentation, skeletonization, and subsequent\nanalysis of vessel trees, by creating an automatic pipeline based on deep\nlearning and image processing techniques.\n  The first part of this work explores the impact of differentiable\nskeletonization methods such as ClDice and morphological skeletonization loss,\non the overall liver vessel segmentation performance. To this aim, it studies\nhow to improve vessel tree connectivity.\n  The second part of this study converts a single class vessel segmentation\ninto multi-class ones, separating the two venous trees. It builds on the\nprevious two-class vessel segmentation model, which vessel tree outputs might\nbe entangled, and on connected components and skeleton analyses of the trees.\n  After providing sub-labeling of the specific anatomical branches of each\nvenous tree, these algorithms also enable a morphometric analysis of the vessel\ntrees by extracting various geometrical markers.\n  In conclusion, we propose a method that successfully improves current\nskeletonization methods, for extensive vascular trees that contain vessels of\ndifferent calibers. The separation algorithm creates a clean multi-class\nsegmentation of the vessels, validated by surgeons to provide low error. A new,\npublicly shared high-quality liver vessel dataset of 77 cases is thus created.\nFinally a method to annotate vessel trees according to anatomy is provided,\nenabling a unique liver vessel morphometry analysis.",
      "tldr_zh": "该研究旨在提升3D肝脏血管模型的自动分割和分析，以支持肝癌手术评估，特别是识别门静脉树和肝静脉树。该方法通过基于深度学习和图像处理技术的管道，改进可微骨架化方法（如ClDice和morphological skeletonization loss），以增强血管树连通性和从单类分割转为多类分割，从而分离特定解剖分支。实验结果显示，该算法实现了精确的血管树子标签化和形态测量分析，并创建了一个公开共享的77例高质量肝脏血管数据集，为手术规划提供可靠工具。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "Paper presented at MICCAI 2024 Workshop: ADSMI. This work was done in\n  the context of an internship at Simbiotx, Inria",
      "pdf_url": "http://arxiv.org/pdf/2411.15778v4",
      "published_date": "2024-11-24 10:58:48 UTC",
      "updated_date": "2025-03-19 12:48:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:56:38.667627"
    },
    {
      "arxiv_id": "2411.15758v1",
      "title": "Decoding Urban Industrial Complexity: Enhancing Knowledge-Driven Insights via IndustryScopeGPT",
      "title_zh": "翻译失败",
      "authors": [
        "Siqi Wang",
        "Chao Liang",
        "Yunfan Gao",
        "Yang Liu",
        "Jing Li",
        "Haofen Wang"
      ],
      "abstract": "Industrial parks are critical to urban economic growth. Yet, their\ndevelopment often encounters challenges stemming from imbalances between\nindustrial requirements and urban services, underscoring the need for strategic\nplanning and operations. This paper introduces IndustryScopeKG, a pioneering\nlarge-scale multi-modal, multi-level industrial park knowledge graph, which\nintegrates diverse urban data including street views, corporate,\nsocio-economic, and geospatial information, capturing the complex relationships\nand semantics within industrial parks. Alongside this, we present the\nIndustryScopeGPT framework, which leverages Large Language Models (LLMs) with\nMonte Carlo Tree Search to enhance tool-augmented reasoning and decision-making\nin Industrial Park Planning and Operation (IPPO). Our work significantly\nimproves site recommendation and functional planning, demonstrating the\npotential of combining LLMs with structured datasets to advance industrial park\nmanagement. This approach sets a new benchmark for intelligent IPPO research\nand lays a robust foundation for advancing urban industrial development. The\ndataset and related code are available at\nhttps://github.com/Tongji-KGLLM/IndustryScope.",
      "tldr_zh": "本研究探讨了工业园区的规划和运营（IPPO）面临的挑战，如工业需求与城市服务的不平衡，并引入了 IndustryScopeKG，这是一个大规模的多模态、多层次工业园区知识图谱，整合了街景、企业、社会经济和地理空间数据，以捕捉复杂的园区关系。该框架还推出了 IndustryScopeGPT，利用 Large Language Models (LLMs) 和 Monte Carlo Tree Search 进行工具增强推理，从而提升站点推荐和功能规划的决策能力。实验结果显示，该方法显著提高了工业园区管理的效率，并为智能 IPPO 研究设定了新基准；相关数据集和代码已在 https://github.com/Tongji-KGLLM/IndustryScope 公开。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.SI",
        "I.2.0; I.2.7; H.3.3; H.4.0"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 6 figures, the 32nd ACM International Conference on\n  Multimedia",
      "pdf_url": "http://arxiv.org/pdf/2411.15758v1",
      "published_date": "2024-11-24 08:33:19 UTC",
      "updated_date": "2024-11-24 08:33:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:56:49.462499"
    },
    {
      "arxiv_id": "2411.15743v1",
      "title": "Beyond Data Scarcity: A Frequency-Driven Framework for Zero-Shot Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Liran Nochumsohn",
        "Michal Moshkovitz",
        "Orly Avner",
        "Dotan Di Castro",
        "Omri Azencot"
      ],
      "abstract": "Time series forecasting is critical in numerous real-world applications,\nrequiring accurate predictions of future values based on observed patterns.\nWhile traditional forecasting techniques work well in in-domain scenarios with\nample data, they struggle when data is scarce or not available at all,\nmotivating the emergence of zero-shot and few-shot learning settings. Recent\nadvancements often leverage large-scale foundation models for such tasks, but\nthese methods require extensive data and compute resources, and their\nperformance may be hindered by ineffective learning from the available training\nset. This raises a fundamental question: What factors influence effective\nlearning from data in time series forecasting? Toward addressing this, we\npropose using Fourier analysis to investigate how models learn from synthetic\nand real-world time series data. Our findings reveal that forecasters commonly\nsuffer from poor learning from data with multiple frequencies and poor\ngeneralization to unseen frequencies, which impedes their predictive\nperformance. To alleviate these issues, we present a novel synthetic data\ngeneration framework, designed to enhance real data or replace it completely by\ncreating task-specific frequency information, requiring only the sampling rate\nof the target data. Our approach, Freq-Synth, improves the robustness of both\nfoundation as well as nonfoundation forecast models in zero-shot and few-shot\nsettings, facilitating more reliable time series forecasting under limited data\nscenarios.",
      "tldr_zh": "时间序列预测在数据稀缺场景下表现不佳，传统方法和大型基础模型往往因多频率数据学习不足和对未见频率的泛化差而受限。论文通过Fourier analysis分析了模型从合成和真实时间序列数据中学习的关键因素，发现这些问题严重影响预测准确性。为解决此问题，提出Freq-Synth框架，该框架基于目标数据的采样率生成任务特定的合成数据，用于增强或替换真实数据。实验结果显示，Freq-Synth显著提高了基础和非基础模型在Zero-Shot和Few-Shot设置下的鲁棒性，实现更可靠的预测性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.15743v1",
      "published_date": "2024-11-24 07:44:39 UTC",
      "updated_date": "2024-11-24 07:44:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:57:02.289754"
    },
    {
      "arxiv_id": "2411.15742v1",
      "title": "PEnG: Pose-Enhanced Geo-Localisation",
      "title_zh": "翻译失败",
      "authors": [
        "Tavis Shore",
        "Oscar Mendez",
        "Simon Hadfield"
      ],
      "abstract": "Cross-view Geo-localisation is typically performed at a coarse granularity,\nbecause densely sampled satellite image patches overlap heavily. This heavy\noverlap would make disambiguating patches very challenging. However, by opting\nfor sparsely sampled patches, prior work has placed an artificial upper bound\non the localisation accuracy that is possible. Even a perfect oracle system\ncannot achieve accuracy greater than the average separation of the tiles. To\nsolve this limitation, we propose combining cross-view geo-localisation and\nrelative pose estimation to increase precision to a level practical for\nreal-world application. We develop PEnG, a 2-stage system which first predicts\nthe most likely edges from a city-scale graph representation upon which a query\nimage lies. It then performs relative pose estimation within these edges to\ndetermine a precise position. PEnG presents the first technique to utilise both\nviewpoints available within cross-view geo-localisation datasets to enhance\nprecision to a sub-metre level, with some examples achieving centimetre level\naccuracy. Our proposed ensemble achieves state-of-the-art precision - with\nrelative Top-5m retrieval improvements on previous works of 213%. Decreasing\nthe median euclidean distance error by 96.90% from the previous best of 734m\ndown to 22.77m, when evaluating with 90 degree horizontal FOV images. Code will\nbe made available: tavisshore.co.uk/PEnG",
      "tldr_zh": "该论文针对跨视图地理定位（cross-view geo-localisation）的精度限制问题，提出了一种结合相对姿态估计（relative pose estimation）的创新方法，以实现亚米级甚至厘米级精度。PEnG 是一个两阶段系统：首先从城市规模图表示中预测查询图像最可能的边，然后在这些边内进行相对姿态估计以确定精确位置。该方法首次利用跨视图数据集中的两种视点，显著提升了定位性能，在 Top-5m 检索上比先前工作提高了 213%，并将中位欧氏距离错误从 734m 降至 22.77m。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.15742v1",
      "published_date": "2024-11-24 07:42:50 UTC",
      "updated_date": "2024-11-24 07:42:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:57:13.761990"
    },
    {
      "arxiv_id": "2411.15740v1",
      "title": "LTCF-Net: A Transformer-Enhanced Dual-Channel Fourier Framework for Low-Light Image Restoration",
      "title_zh": "翻译失败",
      "authors": [
        "Gaojing Zhang",
        "Jinglun Feng"
      ],
      "abstract": "We introduce LTCF-Net, a novel network architecture designed for enhancing\nlow-light images. Unlike Retinex-based methods, our approach utilizes two color\nspaces - LAB and YUV - to efficiently separate and process color information,\nby leveraging the separation of luminance from chromatic components in color\nimages. In addition, our model incorporates the Transformer architecture to\ncomprehensively understand image content while maintaining computational\nefficiency. To dynamically balance the brightness in output images, we also\nintroduce a Fourier transform module that adjusts the luminance channel in the\nfrequency domain. This mechanism could uniformly balance brightness across\ndifferent regions while eliminating background noises, and thereby enhancing\nvisual quality. By combining these innovative components, LTCF-Net effectively\nimproves low-light image quality while keeping the model lightweight.\nExperimental results demonstrate that our method outperforms current\nstate-of-the-art approaches across multiple evaluation metrics and datasets,\nachieving more natural color restoration and a balanced brightness\ndistribution.",
      "tldr_zh": "本研究提出LTCF-Net，一种基于Transformer增强的双通道Fourier框架，用于低光照图像恢复。该框架利用LAB和YUV颜色空间分离亮度和色度信息，同时整合Transformer架构来全面理解图像内容，并通过Fourier transform模块在频域调整亮度通道，以动态平衡亮度并消除背景噪声。相比Retinex-based方法，LTCF-Net保持模型轻量级，并在多个数据集上超越现有最先进方法，实现更自然的颜色恢复和平衡的亮度分布。实验结果显示，该方法在多种评估指标上表现出色，提升了图像视觉质量。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.15740v1",
      "published_date": "2024-11-24 07:21:17 UTC",
      "updated_date": "2024-11-24 07:21:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:57:25.258125"
    },
    {
      "arxiv_id": "2411.15737v3",
      "title": "TableTime: Reformulating Time Series Classification as Training-Free Table Understanding with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jiahao Wang",
        "Mingyue Cheng",
        "Qingyang Mao",
        "Yitong Zhou",
        "Feiyang Xu",
        "Xin Li"
      ],
      "abstract": "Large language models (LLMs) have demonstrated their effectiveness in\nmultivariate time series classification (MTSC). Effective adaptation of LLMs\nfor MTSC necessitates informative data representations. Existing LLM-based\nmethods directly encode embeddings for time series within the latent space of\nLLMs from scratch to align with semantic space of LLMs. Despite their\neffectiveness, we reveal that these methods conceal three inherent bottlenecks:\n(1) they struggle to encode temporal and channel-specific information in a\nlossless manner, both of which are critical components of multivariate time\nseries; (2) it is much difficult to align the learned representation space with\nthe semantic space of the LLMs; (3) they require task-specific retraining,\nwhich is both computationally expensive and labor-intensive. To bridge these\ngaps, we propose TableTime, which reformulates MTSC as a table understanding\ntask. Specifically, TableTime introduces the following strategies: (1) convert\nmultivariate time series into a tabular form, thus minimizing information loss\nto the greatest extent; (2) represent tabular time series in text format to\nachieve natural alignment with the semantic space of LLMs; (3) design a\nreasoning framework that integrates contextual text information, neighborhood\nassistance, multi-path inference and problem decomposition to enhance the\nreasoning ability of LLMs and realize zero-shot classification. Extensive\nexperiments performed on 10 publicly representative datasets from UEA archive\nverify the superiorities of the TableTime.",
      "tldr_zh": "这篇论文提出了TableTime方法，将多变量时间序列分类(MTSC)重构为无需训练的表理解任务，以解决现有LLM-based方法在信息编码、对齐语义空间和重训练方面的瓶颈。TableTime的关键策略包括将时间序列转换为表格形式以减少信息损失、使用文本格式实现与LLMs语义空间的自然对齐，并设计一个集成了上下文信息、邻域辅助、多路径推理和问题分解的推理框架，支持零样本分类。在10个公开数据集上的广泛实验验证了TableTime的优越性，展示了其在准确性和效率方面的显著改进。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.15737v3",
      "published_date": "2024-11-24 07:02:32 UTC",
      "updated_date": "2025-02-16 12:03:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:57:38.114000"
    },
    {
      "arxiv_id": "2412.00051v2",
      "title": "TransFair: Transferring Fairness from Ocular Disease Classification to Progression Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Leila Gheisi",
        "Henry Chu",
        "Raju Gottumukkala",
        "Yan Luo",
        "Xingquan Zhu",
        "Mengyu Wang",
        "Min Shi"
      ],
      "abstract": "The use of artificial intelligence (AI) in automated disease classification\nsignificantly reduces healthcare costs and improves the accessibility of\nservices. However, this transformation has given rise to concerns about the\nfairness of AI, which disproportionately affects certain groups, particularly\npatients from underprivileged populations. Recently, a number of methods and\nlarge-scale datasets have been proposed to address group performance\ndisparities. Although these methods have shown effectiveness in disease\nclassification tasks, they may fall short in ensuring fair prediction of\ndisease progression, mainly because of limited longitudinal data with diverse\ndemographics available for training a robust and equitable prediction model. In\nthis paper, we introduce TransFair to enhance demographic fairness in\nprogression prediction for ocular diseases. TransFair aims to transfer a\nfairness-enhanced disease classification model to the task of progression\nprediction with fairness preserved. Specifically, we train a fair EfficientNet,\ntermed FairEN, equipped with a fairness-aware attention mechanism using\nextensive data for ocular disease classification. Subsequently, this fair\nclassification model is adapted to a fair progression prediction model through\nknowledge distillation, which aims to minimize the latent feature distances\nbetween the classification and progression prediction models. We evaluate\nFairEN and TransFair for fairness-enhanced ocular disease classification and\nprogression prediction using both two-dimensional (2D) and 3D retinal images.\nExtensive experiments and comparisons with models with and without considering\nfairness learning show that TransFair effectively enhances demographic equity\nin predicting ocular disease progression.",
      "tldr_zh": "该研究提出 TransFair 框架，旨在将眼部疾病分类任务中的公平性转移到疾病进展预测任务，以解决 AI 在弱势群体中的不公平问题。具体而言，TransFair 通过训练一个公平感知注意力机制的 EfficientNet（FairEN）模型进行疾病分类，随后利用知识蒸馏最小化潜在特征距离，将其适应到公平进展预测模型。实验在 2D 和 3D 视网膜图像上显示，TransFair 比未考虑公平性的模型更有效地提升了人口公平性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.00051v2",
      "published_date": "2024-11-24 06:39:06 UTC",
      "updated_date": "2024-12-03 03:33:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:57:49.797752"
    },
    {
      "arxiv_id": "2411.15731v1",
      "title": "Fusion Matters: Learning Fusion in Deep Click-through Rate Prediction Models",
      "title_zh": "翻译失败",
      "authors": [
        "Kexin Zhang",
        "Fuyuan Lyu",
        "Xing Tang",
        "Dugang Liu",
        "Chen Ma",
        "Kaize Ding",
        "Xiuqiang He",
        "Xue Liu"
      ],
      "abstract": "The evolution of previous Click-Through Rate (CTR) models has mainly been\ndriven by proposing complex components, whether shallow or deep, that are adept\nat modeling feature interactions. However, there has been less focus on\nimproving fusion design. Instead, two naive solutions, stacked and parallel\nfusion, are commonly used. Both solutions rely on pre-determined fusion\nconnections and fixed fusion operations. It has been repetitively observed that\nchanges in fusion design may result in different performances, highlighting the\ncritical role that fusion plays in CTR models. While there have been attempts\nto refine these basic fusion strategies, these efforts have often been\nconstrained to specific settings or dependent on specific components. Neural\narchitecture search has also been introduced to partially deal with fusion\ndesign, but it comes with limitations. The complexity of the search space can\nlead to inefficient and ineffective results. To bridge this gap, we introduce\nOptFusion, a method that automates the learning of fusion, encompassing both\nthe connection learning and the operation selection. We have proposed a\none-shot learning algorithm tackling these tasks concurrently. Our experiments\nare conducted over three large-scale datasets. Extensive experiments prove both\nthe effectiveness and efficiency of OptFusion in improving CTR model\nperformance. Our code implementation is available\nhere\\url{https://github.com/kexin-kxzhang/OptFusion}.",
      "tldr_zh": "本论文探讨了深度点击率（CTR）预测模型中融合设计的优化问题，指出现有模型通常依赖简单的堆叠或并行融合，这些方法使用预定连接和固定操作，导致性能不稳定。作者提出 OptFusion，一种自动化学习融合的方法，包括连接学习和操作选择，并采用 one-shot learning 算法来同时处理这些任务。在三个大规模数据集上的实验证明，OptFusion 显著提高了 CTR 模型的性能，同时兼具有效性和效率，并提供了开源代码实现。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted by WSDM 2025",
      "pdf_url": "http://arxiv.org/pdf/2411.15731v1",
      "published_date": "2024-11-24 06:21:59 UTC",
      "updated_date": "2024-11-24 06:21:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:58:00.761656"
    },
    {
      "arxiv_id": "2411.16754v1",
      "title": "Visual Counter Turing Test (VCT^2): Discovering the Challenges for AI-Generated Image Detection and Introducing Visual AI Index (V_AI)",
      "title_zh": "翻译失败",
      "authors": [
        "Nasrin Imanpour",
        "Shashwat Bajpai",
        "Subhankar Ghosh",
        "Sainath Reddy Sankepally",
        "Abhilekh Borah",
        "Hasnat Md Abdullah",
        "Nishoak Kosaraju",
        "Shreyas Dixit",
        "Ashhar Aziz",
        "Shwetangshu Biswas",
        "Vinija Jain",
        "Aman Chadha",
        "Amit Sheth",
        "Amitava Das"
      ],
      "abstract": "The proliferation of AI techniques for image generation, coupled with their\nincreasing accessibility, has raised significant concerns about the potential\nmisuse of these images to spread misinformation. Recent AI-generated image\ndetection (AGID) methods include CNNDetection, NPR, DM Image Detection, Fake\nImage Detection, DIRE, LASTED, GAN Image Detection, AIDE, SSP, DRCT, RINE,\nOCC-CLIP, De-Fake, and Deep Fake Detection. However, we argue that the current\nstate-of-the-art AGID techniques are inadequate for effectively detecting\ncontemporary AI-generated images and advocate for a comprehensive reevaluation\nof these methods. We introduce the Visual Counter Turing Test (VCT^2), a\nbenchmark comprising ~130K images generated by contemporary text-to-image\nmodels (Stable Diffusion 2.1, Stable Diffusion XL, Stable Diffusion 3, DALL-E\n3, and Midjourney 6). VCT^2 includes two sets of prompts sourced from tweets by\nthe New York Times Twitter account and captions from the MS COCO dataset. We\nalso evaluate the performance of the aforementioned AGID techniques on the\nVCT$^2$ benchmark, highlighting their ineffectiveness in detecting AI-generated\nimages. As image-generative AI models continue to evolve, the need for a\nquantifiable framework to evaluate these models becomes increasingly critical.\nTo meet this need, we propose the Visual AI Index (V_AI), which assesses\ngenerated images from various visual perspectives, including texture complexity\nand object coherence, setting a new standard for evaluating image-generative AI\nmodels. To foster research in this domain, we make our\nhttps://huggingface.co/datasets/anonymous1233/COCO_AI and\nhttps://huggingface.co/datasets/anonymous1233/twitter_AI datasets publicly\navailable.",
      "tldr_zh": "该研究揭示了现有AI生成图像检测(AGID)方法（如CNNDetection和DIRE等）的不足，无法有效识别当代AI生成图像，从而加剧了误传信息风险。论文引入Visual Counter Turing Test (VCT^2)，一个包含约13万张图像的基准，这些图像由Stable Diffusion系列、DALL-E 3和Midjourney 6等模型生成，并基于New York Times Twitter提示和MS COCO数据集进行测试。实验结果显示，现有的AGID技术在VCT^2上表现不佳，突显了检测挑战。作者提出Visual AI Index (V_AI)，一个从纹理复杂度和对象连贯性等视觉角度评估图像生成模型的量化框架，并公开了相关数据集以推动该领域的研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.16754v1",
      "published_date": "2024-11-24 06:03:49 UTC",
      "updated_date": "2024-11-24 06:03:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:58:13.979307"
    },
    {
      "arxiv_id": "2411.16751v1",
      "title": "An investigation into the performances of the Current state-of-the-art Naive Bayes, Non-Bayesian and Deep Learning Based Classifier for Phishing Detection: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Tosin Ige",
        "Christopher Kiekintveld",
        "Aritran Piplai",
        "Amy Waggler",
        "Olukunle Kolade",
        "Bolanle Hafiz Matti"
      ],
      "abstract": "Phishing is one of the most effective ways in which cybercriminals get\nsensitive details such as credentials for online banking, digital wallets,\nstate secrets, and many more from potential victims. They do this by spamming\nusers with malicious URLs with the sole purpose of tricking them into divulging\nsensitive information which is later used for various cybercrimes. In this\nresearch, we did a comprehensive review of current state-of-the-art machine\nlearning and deep learning phishing detection techniques to expose their\nvulnerabilities and future research direction. For better analysis and\nobservation, we split machine learning techniques into Bayesian, non-Bayesian,\nand deep learning. We reviewed the most recent advances in Bayesian and\nnon-Bayesian-based classifiers before exploiting their corresponding weaknesses\nto indicate future research direction. While exploiting weaknesses in both\nBayesian and non-Bayesian classifiers, we also compared each performance with a\ndeep learning classifier. For a proper review of deep learning-based\nclassifiers, we looked at Recurrent Neural Networks (RNN), Convolutional Neural\nNetworks (CNN), and Long Short Term Memory Networks (LSTMs). We did an\nempirical analysis to evaluate the performance of each classifier along with\nmany of the proposed state-of-the-art anti-phishing techniques to identify\nfuture research directions, we also made a series of proposals on how the\nperformance of the under-performing algorithm can improved in addition to a\ntwo-stage prediction model",
      "tldr_zh": "本研究调查了当前最先进的Naive Bayes、Non-Bayesian和Deep Learning Based分类器在钓鱼检测（Phishing Detection）中的性能，通过对机器学习和深度学习技术的全面审查暴露其弱点并探讨未来研究方向。作者将机器学习技术分为Bayesian、Non-Bayesian和Deep Learning类别，审视了这些分类器的最新进展，并通过实证分析比较了RNN、CNN和LSTMs等Deep Learning模型的性能。结果显示，现有分类器存在显著弱点，研究提出了改进低性能算法的建议，以及一个两阶段预测模型，以提升钓鱼检测的准确性和鲁棒性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.16751v1",
      "published_date": "2024-11-24 05:20:09 UTC",
      "updated_date": "2024-11-24 05:20:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:00:16.687571"
    },
    {
      "arxiv_id": "2411.15710v1",
      "title": "Understanding Student Acceptance, Trust, and Attitudes Toward AI-Generated Images for Educational Purposes",
      "title_zh": "翻译失败",
      "authors": [
        "Aung Pyae"
      ],
      "abstract": "Recent advancements in artificial intelligence (AI) have broadened the\napplicability of AI-generated images across various sectors, including the\ncreative industry and design. However, their utilization in educational\ncontexts, particularly among undergraduate students in computer science and\nsoftware engineering, remains underexplored. This study adopts an exploratory\napproach, employing questionnaires and interviews, to assess students'\nacceptance, trust, and positive attitudes towards AI-generated images for\neducational tasks such as presentations, reports, and web design. The results\nreveal high acceptance, trust, and positive attitudes among students who value\nthe ease of use and potential academic benefits. However, concerns regarding\nthe lack of technical precision, where the AI fails to accurately produce\nimages as specified by prompts, moderately impact their practical application\nin detail-oriented educational tasks. These findings suggest a need for\ndeveloping comprehensive guidelines that address ethical considerations and\nintellectual property issues, while also setting quality standards for\nAI-generated images to enhance their educational use. Enhancing the\ncapabilities of AI tools to meet precise user specifications could foster\ncreativity and improve educational outcomes in technical disciplines.",
      "tldr_zh": "这篇论文探讨了计算机科学和软件工程本科生对 AI-generated images 在教育任务（如演示文稿、报告和网页设计）中的接受度、信任和态度。研究采用问卷和访谈的探索性方法，结果显示学生整体高度接受并持积极态度，因为其易用性和潜在学术益处，但AI的缺乏技术精确性（如无法准确响应提示）会影响细节导向任务的应用。论文建议制定全面指南，处理伦理考虑和知识产权问题，同时提升AI工具的精确性，以促进创造力和教育成果。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.15710v1",
      "published_date": "2024-11-24 04:39:48 UTC",
      "updated_date": "2024-11-24 04:39:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:58:37.832114"
    },
    {
      "arxiv_id": "2411.17411v1",
      "title": "Advancing Uncertain Combinatorics through Graphization, Hyperization, and Uncertainization: Fuzzy, Neutrosophic, Soft, Rough, and Beyond",
      "title_zh": "翻译失败",
      "authors": [
        "Takaaki Fujita"
      ],
      "abstract": "To better handle real-world uncertainty, concepts such as fuzzy sets,\nneutrosophic sets, rough sets, and soft sets have been introduced. For example,\nneutrosophic sets, which simultaneously represent truth, indeterminacy, and\nfalsehood, have proven to be valuable tools for modeling uncertainty in complex\nsystems. These set concepts are increasingly studied in graphized forms, and\ngeneralized graph concepts now encompass well-known structures such as\nhypergraphs and superhypergraphs. Furthermore, hyperconcepts and\nsuperhyperconcepts are being actively researched in areas beyond graph theory.\n  Combinatorics, uncertain sets (including fuzzy sets, neutrosophic sets, rough\nsets, soft sets, and plithogenic sets), uncertain graphs, and hyper and\nsuperhyper concepts are active areas of research with significant mathematical\nand practical implications. Recognizing their importance, this paper explores\nnew graph and set concepts, as well as hyper and superhyper concepts, as\ndetailed in the \"Results\" section of \"The Structure of the Paper.\"\nAdditionally, this work aims to consolidate recent findings, providing a\nsurvey-like resource to inform and engage readers.\n  For instance, we extend several graph concepts by introducing Neutrosophic\nOversets, Neutrosophic Undersets, Neutrosophic Offsets, and the Nonstandard\nReal Set. This paper defines a variety of concepts with the goal of inspiring\nnew ideas and serving as a valuable resource for researchers in their academic\npursuits.",
      "tldr_zh": "这篇论文探讨了通过图化(graphization)、超图化(hyperization)和不确定化(uncertainization)来推进不确定组合数学，重点扩展了fuzzy sets、neutrosophic sets、rough sets和soft sets等概念，以更好地处理现实世界的模糊性和不确定性。作者引入了新的概念，如Neutrosophic Oversets、Neutrosophic Undersets、Neutrosophic Offsets和Nonstandard Real Set，并将这些应用于超图(hypergraphs)和超级超图(superhypergraphs)等领域。论文整合了最近的研究成果，提供了一个类似调查的资源，旨在激发新想法并支持学术研究。",
      "categories": [
        "cs.AI",
        "03B52"
      ],
      "primary_category": "cs.AI",
      "comment": "255 pages. 11 figures. Published as a book in 2024. Publisher: Biblio\n  Publishing. ISBN: 978-1-59973-812-3",
      "pdf_url": "http://arxiv.org/pdf/2411.17411v1",
      "published_date": "2024-11-24 04:28:53 UTC",
      "updated_date": "2024-11-24 04:28:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:58:49.361071"
    },
    {
      "arxiv_id": "2411.15707v1",
      "title": "Nimbus: Secure and Efficient Two-Party Inference for Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Zhengyi Li",
        "Kang Yang",
        "Jin Tan",
        "Wen-jie Lu",
        "Haoqi Wu",
        "Xiao Wang",
        "Yu Yu",
        "Derun Zhao",
        "Yancheng Zheng",
        "Minyi Guo",
        "Jingwen Leng"
      ],
      "abstract": "Transformer models have gained significant attention due to their power in\nmachine learning tasks. Their extensive deployment has raised concerns about\nthe potential leakage of sensitive information during inference. However, when\nbeing applied to Transformers, existing approaches based on secure two-party\ncomputation (2PC) bring about efficiency limitations in two folds: (1)\nresource-intensive matrix multiplications in linear layers, and (2) complex\nnon-linear activation functions like $\\mathsf{GELU}$ and $\\mathsf{Softmax}$.\nThis work presents a new two-party inference framework $\\mathsf{Nimbus}$ for\nTransformer models. For the linear layer, we propose a new 2PC paradigm along\nwith an encoding approach to securely compute matrix multiplications based on\nan outer-product insight, which achieves $2.9\\times \\sim 12.5\\times$\nperformance improvements compared to the state-of-the-art (SOTA) protocol. For\nthe non-linear layer, through a new observation of utilizing the input\ndistribution, we propose an approach of low-degree polynomial approximation for\n$\\mathsf{GELU}$ and $\\mathsf{Softmax}$, which improves the performance of the\nSOTA polynomial approximation by $2.9\\times \\sim 4.0\\times$, where the average\naccuracy loss of our approach is 0.08\\% compared to the non-2PC inference\nwithout privacy. Compared with the SOTA two-party inference, $\\mathsf{Nimbus}$\nimproves the end-to-end performance of \\bert{} inference by $2.7\\times \\sim\n4.7\\times$ across different network settings.",
      "tldr_zh": "这篇论文提出Nimbus框架，用于Transformer模型的安全高效双向推断（Two-Party Inference），以解决现有基于安全双方计算（2PC）方法在矩阵乘法和非线性激活函数（如GELU和Softmax）上的效率瓶颈。针对线性层，Nimbus引入新的2PC范式和编码方法，利用外积洞见进行安全矩阵乘法计算，比现有最佳协议（SOTA）性能提升2.9×到12.5×。对于非线性层，通过输入分布观察，提出低度多项式逼近GELU和Softmax的方法，比SOTA逼近快2.9×到4.0×，同时准确性损失仅0.08%。总体结果显示，Nimbus使BERT推断的端到端性能提高2.7×到4.7×，为隐私保护下的Transformer应用提供了更高效的解决方案。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted by NIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.15707v1",
      "published_date": "2024-11-24 04:24:31 UTC",
      "updated_date": "2024-11-24 04:24:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:59:03.981045"
    },
    {
      "arxiv_id": "2411.15700v1",
      "title": "RAMIE: Retrieval-Augmented Multi-task Information Extraction with Large Language Models on Dietary Supplements",
      "title_zh": "RAMIE：检索增强的多任务信息抽取，使用大型",
      "authors": [
        "Zaifu Zhan",
        "Shuang Zhou",
        "Mingchen Li",
        "Rui Zhang"
      ],
      "abstract": "\\textbf{Objective:} We aimed to develop an advanced multi-task large language\nmodel (LLM) framework to extract multiple types of information about dietary\nsupplements (DS) from clinical records.\n  \\textbf{Methods:} We used four core DS information extraction tasks - namely,\nnamed entity recognition (NER: 2,949 clinical sentences), relation extraction\n(RE: 4,892 sentences), triple extraction (TE: 2,949 sentences), and usage\nclassification (UC: 2,460 sentences) as our multitasks. We introduced a novel\nRetrieval-Augmented Multi-task Information Extraction (RAMIE) Framework,\nincluding: 1) employed instruction fine-tuning techniques with task-specific\nprompts, 2) trained LLMs for multiple tasks with improved storage efficiency\nand lower training costs, and 3) incorporated retrieval augmentation generation\n(RAG) techniques by retrieving similar examples from the training set. We\ncompared RAMIE's performance to LLMs with instruction fine-tuning alone and\nconducted an ablation study to assess the contributions of multi-task learning\nand RAG to improved multitasking performance.\n  \\textbf{Results:} With the aid of the RAMIE framework, Llama2-13B achieved an\nF1 score of 87.39 (3.51\\% improvement) on the NER task and demonstrated\noutstanding performance on the RE task with an F1 score of 93.74 (1.15\\%\nimprovement). For the TE task, Llama2-7B scored 79.45 (14.26\\% improvement),\nand MedAlpaca-7B achieved the highest F1 score of 93.45 (0.94\\% improvement) on\nthe UC task. The ablation study revealed that while MTL increased efficiency\nwith a slight trade-off in performance, RAG significantly boosted overall\naccuracy.\n  \\textbf{Conclusion:} This study presents a novel RAMIE framework that\ndemonstrates substantial improvements in multi-task information extraction for\nDS-related data from clinical records. Our framework can potentially be applied\nto other domains.",
      "tldr_zh": "本研究提出了一种名为 RAMIE 的检索增强多任务信息提取框架，利用大型语言模型（LLMs）从临床记录中提取饮食补充剂（DS）相关信息。框架整合了指令微调、多任务学习（包括 NER、RE、TE 和 UC 任务）以及检索增强生成（RAG）技术，以提高提取效率和准确性。实验结果显示，RAMIE 显著提升了模型性能，例如 Llama2-13B 在 NER 任务的 F1 分数提高 3.51%，TE 任务提高 14.26%，而消融研究证实 RAG 对整体准确性的贡献最大。该框架展示了在 DS 领域的信息提取潜力，并可扩展至其他领域。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.15700v1",
      "published_date": "2024-11-24 03:56:43 UTC",
      "updated_date": "2024-11-24 03:56:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:59:13.485575"
    },
    {
      "arxiv_id": "2412.00049v1",
      "title": "A Survey of Recent Advances and Challenges in Deep Audio-Visual Correlation Learning",
      "title_zh": "深度音频-视觉相关性学习的最近进展和挑战综述",
      "authors": [
        "Luis Vilaca",
        "Yi Yu",
        "Paula Vinan"
      ],
      "abstract": "Audio-visual correlation learning aims to capture and understand natural\nphenomena between audio and visual data. The rapid growth of Deep Learning\npropelled the development of proposals that process audio-visual data and can\nbe observed in the number of proposals in the past years. Thus encouraging the\ndevelopment of a comprehensive survey. Besides analyzing the models used in\nthis context, we also discuss some tasks of definition and paradigm applied in\nAI multimedia. In addition, we investigate objective functions frequently used\nand discuss how audio-visual data is exploited in the optimization process,\ni.e., the different methodologies for representing knowledge in the\naudio-visual domain. In fact, we focus on how human-understandable mechanisms,\ni.e., structured knowledge that reflects comprehensible knowledge, can guide\nthe learning process. Most importantly, we provide a summarization of the\nrecent progress of Audio-Visual Correlation Learning (AVCL) and discuss the\nfuture research directions.",
      "tldr_zh": "本文对Deep Audio-Visual Correlation Learning (AVCL)的最新进展和挑战进行了全面调查，分析了深度学习在处理音频-视觉数据方面的模型、任务、范式和目标函数。调查重点探讨了音频-视觉数据在优化过程中的表示方法，以及如何利用结构化知识（如人类可理解的机制）来指导学习过程。最终，该文总结了AVCL的近期进展，并指出了未来研究方向，如增强知识引导和多模态融合的潜力。",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.CV",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.MM",
      "comment": "arXiv admin note: text overlap with arXiv:2202.13673",
      "pdf_url": "http://arxiv.org/pdf/2412.00049v1",
      "published_date": "2024-11-24 03:26:34 UTC",
      "updated_date": "2024-11-24 03:26:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:00:28.395042"
    },
    {
      "arxiv_id": "2411.15685v1",
      "title": "State-Space Large Audio Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Saurabhchand Bhati",
        "Yuan Gong",
        "Leonid Karlinsky",
        "Hilde Kuehne",
        "Rogerio Feris",
        "James Glass"
      ],
      "abstract": "Large Audio Language Models (LALM) combine the audio perception models and\nthe Large Language Models (LLM) and show a remarkable ability to reason about\nthe input audio, infer the meaning, and understand the intent. However, these\nsystems rely on Transformers which scale quadratically with the input sequence\nlengths which poses computational challenges in deploying these systems in\nmemory and time-constrained scenarios. Recently, the state-space models (SSMs)\nhave emerged as an alternative to transformer networks.\n  While there have been successful attempts to replace transformer-based audio\nperception models with state-space ones, state-space-based LALMs remain\nunexplored. First, we begin by replacing the transformer-based audio perception\nmodule and then replace the transformer-based LLM and propose the first\nstate-space-based LALM. Experimental results demonstrate that space-based LALM\ndespite having a significantly lower number of parameters performs\ncompetitively with transformer-based LALMs on close-ended tasks on a variety of\ndatasets.",
      "tldr_zh": "本研究针对 Large Audio Language Models (LALM) 的计算挑战，指出其依赖于 Transformer 架构导致序列长度二次方增长的问题，提出使用 state-space models (SSMs) 作为替代方案。研究首先替换了 Transformer-based 的音频感知模块，然后扩展到 LLM 模块，构建了第一个基于 SSM 的 LALM。实验结果显示，该模型尽管参数数量显著减少，在多种数据集上的闭合任务中，性能与基于 Transformer's LALM 相当。",
      "categories": [
        "eess.AS",
        "cs.AI"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.15685v1",
      "published_date": "2024-11-24 02:21:28 UTC",
      "updated_date": "2024-11-24 02:21:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:02:33.137143"
    },
    {
      "arxiv_id": "2411.15674v1",
      "title": "Quantile deep learning models for multi-step ahead time series prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Jimmy Cheung",
        "Smruthi Rangarajan",
        "Amelia Maddocks",
        "Xizhe Chen",
        "Rohitash Chandra"
      ],
      "abstract": "Uncertainty quantification is crucial in time series prediction, and quantile\nregression offers a valuable mechanism for uncertainty quantification which is\nuseful for extreme value forecasting. Although deep learning models have been\nprominent in multi-step ahead prediction, the development and evaluation of\nquantile deep learning models have been limited. We present a novel quantile\nregression deep learning framework for multi-step time series prediction. In\nthis way, we elevate the capabilities of deep learning models by incorporating\nquantile regression, thus providing a more nuanced understanding of predictive\nvalues. We provide an implementation of prominent deep learning models for\nmulti-step ahead time series prediction and evaluate their performance under\nhigh volatility and extreme conditions. We include multivariate and univariate\nmodelling, strategies and provide a comparison with conventional deep learning\nmodels from the literature. Our models are tested on two cryptocurrencies:\nBitcoin and Ethereum, using daily close-price data and selected benchmark time\nseries datasets. The results show that integrating a quantile loss function\nwith deep learning provides additional predictions for selected quantiles\nwithout a loss in the prediction accuracy when compared to the literature. Our\nquantile model has the ability to handle volatility more effectively and\nprovides additional information for decision-making and uncertainty\nquantification through the use of quantiles when compared to conventional deep\nlearning models.",
      "tldr_zh": "本文提出一个新的分位数回归（quantile regression）深度学习框架，用于多步时间序列预测，以增强不确定性量化能力，特别是针对极端值和高波动场景。该框架将quantile regression整合到深度学习模型中，包括多元和一元建模策略，并与传统模型进行比较。实验结果显示，该模型在比特币、以太坊日收盘价数据以及基准数据集上，提供额外分位数预测而不降低准确性，同时更有效地处理波动，为决策和不确定性量化提供更多信息。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-fin.ST",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.15674v1",
      "published_date": "2024-11-24 00:00:10 UTC",
      "updated_date": "2024-11-24 00:00:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:00:52.527717"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 53,
  "processed_papers_count": 53,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-21T04:02:48.495991"
}