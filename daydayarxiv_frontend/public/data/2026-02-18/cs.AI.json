{
  "date": "2026-02-18",
  "category": "cs.AI",
  "summary": "æ¬¢è¿æ¥åˆ° UTC æ—¶é—´ 2026-02-18 çš„ arXiv ä¸­æ–‡ TLDR å¿«æŠ¥ï¼\n\nğŸ‘‹ **ä¸€å¥è¯æ€»ç»“ï¼š**\nä»Šå¤©çš„ arXiv å……æ»¡äº†å¯¹æ¨¡å‹**å†…éƒ¨å‡ ä½•ç»“æ„**çš„æ·±åº¦å‰–æâ€”â€”ä»å¾®è°ƒå¦‚ä½•é€šè¿‡æ›²ç‡ç ´åå®‰å…¨å¯¹é½ï¼Œåˆ°å¦‚ä½•é€šè¿‡æ¿€æ´»ç©ºé—´å‘é‡æ§åˆ¶äººæ ¼ï¼›åŒæ—¶ï¼Œ**Agent å®‰å…¨**ï¼ˆ\"åƒµå°¸ Agent\"ï¼‰å’Œ**ç³»ç»Ÿçº§ GenAI** çš„è®¾è®¡èŒƒå¼ä¹Ÿæˆä¸ºäº†ç„¦ç‚¹ã€‚\n\n---\n\n### ğŸš€ æ·±åº¦ç†è®ºä¸æ¨¡å‹æœºç† (The Geometry of Intelligence)\n\nä»Šå¤©çš„é‡å¤´æˆåœ¨äºå¯¹ LLM å†…éƒ¨è¿ä½œæœºåˆ¶çš„å‡ ä½•è§£é‡Šï¼Œè¿™ä¸¤ç¯‡æ–‡ç« éå¸¸ç¡¬æ ¸ï¼Œå€¼å¾—å…³æ³¨ã€‚\n\n**1. The Geometry of Alignment Collapse: When Fine-Tuning Breaks Safety**\n**å¯¹é½å´©å¡Œçš„å‡ ä½•å­¦ï¼šå½“å¾®è°ƒç ´åå®‰å…¨æ€§**\n*   **æ ¸å¿ƒç—›ç‚¹ï¼š** ä¸ºä»€ä¹ˆåœ¨å®Œå…¨æ— å®³çš„æ•°æ®ä¸Šå¾®è°ƒæ¨¡å‹ï¼Œä¹Ÿä¼šç ´ååŸæœ‰çš„å®‰å…¨æŠ¤æ ï¼Ÿ\n*   **å…³é”®å‘ç°ï¼š** ä½œè€…åé©³äº†æµè¡Œçš„â€œæ­£äº¤æ€§â€å‡è®¾ï¼ˆå³å¾®è°ƒæ–¹å‘ä¸å®‰å…¨æ–¹å‘æ­£äº¤ï¼‰ã€‚é€šè¿‡å‡ ä½•åˆ†æï¼Œä»–ä»¬è¯æ˜äº†å¯¹é½é›†ä¸­åœ¨å…·æœ‰**å°–é”æ›²ç‡ï¼ˆsharp curvatureï¼‰**çš„ä½ç»´å­ç©ºé—´ä¸­ã€‚\n*   **ç»“è®ºï¼š** è¿™æ˜¯ä¸€ä¸ªç»“æ„æ€§é—®é¢˜ã€‚å¾®è°ƒæŸå¤±çš„æ›²ç‡ä¼šäº§ç”ŸäºŒé˜¶åŠ é€Ÿï¼Œç³»ç»Ÿæ€§åœ°å°†å‚æ•°è½¨è¿¹æ¨å‘å¯¹é½æ•æ„ŸåŒºåŸŸã€‚ä½œè€…æå‡ºäº†â€œå¯¹é½ä¸ç¨³å®šæ€§æ¡ä»¶â€ï¼Œå¹¶å‘ç°å¯¹é½æŸå¤±éšè®­ç»ƒæ—¶é—´çš„**å››æ¬¡å¹‚ï¼ˆquartic scaling lawï¼‰**å¢é•¿ã€‚è¿™æ„å‘³ç€ç›®å‰çš„â€œå…ˆé¢„è®­ç»ƒå†å¯¹é½â€èŒƒå¼å­˜åœ¨å†…åœ¨çš„å‡ ä½•è„†å¼±æ€§ã€‚\n\n**2. CrispEdit: Low-Curvature Projections for Scalable Non-Destructive LLM Editing**\n**CrispEditï¼šç”¨äºå¯æ‰©å±•æ— æŸ LLM ç¼–è¾‘çš„ä½æ›²ç‡æŠ•å½±**\n*   **è§£å†³é—®é¢˜ï¼š** æ¨¡å‹ç¼–è¾‘ï¼ˆModel Editingï¼‰ç»å¸¸å¯¼è‡´â€œèƒ½åŠ›é—å¿˜â€æˆ–ç ´åé€šç”¨èƒ½åŠ›ã€‚\n*   **æ–¹æ³•ï¼š** æå‡ºäº†ä¸€ç§åŸºäºäºŒé˜¶ä¼˜åŒ–çš„ç¼–è¾‘ç®—æ³•ã€‚å®ƒå°†èƒ½åŠ›ä¿æŒå»ºæ¨¡ä¸ºçº¦æŸä¼˜åŒ–é—®é¢˜ï¼Œåˆ©ç”¨ **Bregman æ•£åº¦**æ¥è¡¨è¾¾çº¦æŸã€‚\n*   **äº®ç‚¹ï¼š** æ ¸å¿ƒåœ¨äºå°†ç¼–è¾‘æ›´æ–°æŠ•å½±åˆ°æŸå¤±åœ°å½¢çš„**ä½æ›²ç‡å­ç©ºé—´**ä¸Šã€‚ä½¿ç”¨äº† K-FAC è¿‘ä¼¼å’Œä¸€ç§æ–°é¢–çš„æ— çŸ©é˜µæŠ•å½±å™¨ï¼ˆmatrix-free projectorï¼‰ï¼Œä½¿å…¶èƒ½æ‰©å±•åˆ° LLM è§„æ¨¡ã€‚ç»“æœæ˜¾ç¤ºåœ¨ç¼–è¾‘æˆåŠŸçš„åŒæ—¶ï¼Œèƒ½åŠ›é€€åŒ–æ§åˆ¶åœ¨ 1% ä»¥å†…ã€‚\n\n**3. PERSONA: Dynamic and Compositional Inference-Time Personality Control via Activation Vector Algebra**\n**PERSONAï¼šé€šè¿‡æ¿€æ´»å‘é‡ä»£æ•°è¿›è¡ŒåŠ¨æ€å’Œç»„åˆçš„æ¨ç†æ—¶äººæ ¼æ§åˆ¶**\n*   **æœ‰è¶£ä¹‹å¤„ï¼š** ä¸éœ€è¦å¾®è°ƒï¼ˆSFTï¼‰ä¹Ÿä¸éœ€è¦å¤æ‚çš„ Prompt å·¥ç¨‹ï¼Œç›´æ¥åœ¨**æ¿€æ´»ç©ºé—´ï¼ˆActivation Spaceï¼‰**åŠ¨æ‰‹æœ¯ã€‚\n*   **å‘ç°ï¼š** äººæ ¼ç‰¹å¾åœ¨è¡¨ç¤ºç©ºé—´ä¸­è¡¨ç°ä¸ºå¯æå–çš„ã€è¿‘ä¼¼æ­£äº¤çš„æ–¹å‘ã€‚\n*   **æ–¹æ³•ï¼š** å¯ä»¥åœ¨æ¨ç†æ—¶é€šè¿‡å‘é‡ç®—æœ¯ï¼ˆåŠ å‡æ³•ï¼‰æ¥å¢å¼ºã€æŠ‘åˆ¶æˆ–æ··åˆäººæ ¼ï¼ˆä¾‹å¦‚ï¼šå¢åŠ â€œå¤–å‘æ€§â€ï¼Œå‡å°‘â€œæ”»å‡»æ€§â€ï¼‰ã€‚åœ¨ PersonalityBench ä¸Šè¾¾åˆ°äº†å¾®è°ƒçº§åˆ«çš„æ•ˆæœã€‚\n\n**4. Recursive Concept Evolution for Compositional Reasoning in Large Language Models**\n**ç”¨äºå¤§è¯­è¨€æ¨¡å‹ç»„åˆæ¨ç†çš„é€’å½’æ¦‚å¿µè¿›åŒ– (RCE)**\n*   **æ–¹æ³•ï¼š** é’ˆå¯¹ ARC-AGI ç­‰å¤æ‚æ¨ç†ä»»åŠ¡ï¼Œä¼ ç»Ÿ CoT æ•ˆæœå—é™ã€‚RCE å…è®¸æ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­**åŠ¨æ€ä¿®æ”¹å…¶å†…éƒ¨è¡¨ç¤ºå‡ ä½•**ã€‚\n*   **æœºåˆ¶ï¼š** å½“æ£€æµ‹åˆ°è¡¨ç¤ºä¸è¶³æ—¶ï¼ŒåŠ¨æ€ç”Ÿæˆä½ç§©æ¦‚å¿µå­ç©ºé—´ï¼ˆconcept subspacesï¼‰ï¼Œå¹¶é€šè¿‡æœ€å°æè¿°é•¿åº¦å‡†åˆ™è¿›è¡Œé€‰æ‹©å’Œåˆå¹¶ã€‚è¿™å°±åƒæ˜¯è®©æ¨¡å‹åœ¨åšé¢˜æ—¶å®æ—¶â€œé•¿è„‘å­â€æ¥æ„å»ºæ–°çš„æŠ½è±¡æ¦‚å¿µã€‚\n\n---\n\n### ğŸ¤– Agent å®‰å…¨ä¸è¯„ä¼° (Agents: Risks & Reality)\n\n**5. Zombie Agents: Persistent Control of Self-Evolving LLM Agents via Self-Reinforcing Injections**\n**åƒµå°¸ Agentï¼šé€šè¿‡è‡ªæˆ‘å¼ºåŒ–æ³¨å…¥å¯¹è‡ªè¿›åŒ– LLM Agent çš„æŒä¹…æ§åˆ¶**\n*   **å®‰å…¨è­¦æŠ¥ï¼š** ç ”ç©¶äº†å…·æœ‰é•¿æœŸè®°å¿†çš„ Agent çš„å®‰å…¨é£é™©ã€‚\n*   **æ”»å‡»æ¨¡å¼ï¼š** æ”»å‡»è€…é€šè¿‡ Agent è¯»å–çš„ç½‘é¡µæ¤å…¥ Payloadï¼Œè¿™äº› Payload è¢«å†™å…¥ Agent çš„é•¿æœŸè®°å¿†ã€‚ä¹‹åï¼Œæ— è®ºä½•æ—¶æ£€ç´¢åˆ°è¯¥è®°å¿†ï¼ŒPayload éƒ½ä¼šè¢«æ¿€æ´»ï¼Œç”šè‡³ä¼šè‡ªæˆ‘å¤åˆ¶æˆ–ä¿®æ”¹è®°å¿†ï¼Œä½¿ Agent å˜æˆå—æ§çš„â€œåƒµå°¸â€ã€‚è¿™è¯æ˜äº†ä»…é ä¼šè¯çº§åˆ«çš„è¿‡æ»¤æ— æ³•é˜²å¾¡**è·¨ä¼šè¯çš„æŒä¹…åŒ–æ”»å‡»**ã€‚\n\n**6. ResearchGym: Evaluating Language Model Agents on Real-World AI Research**\n**ResearchGymï¼šåœ¨çœŸå® AI ç ”ç©¶ä»»åŠ¡ä¸Šè¯„ä¼°è¯­è¨€æ¨¡å‹ Agent**\n*   **ç°å®éª¨æ„Ÿï¼š** æˆ‘ä»¬æ€»è¯´ Agent èƒ½åšç§‘ç ”ï¼Œä½†è¿™ç¯‡è®ºæ–‡æ³¼äº†å†·æ°´ã€‚\n*   **æµ‹è¯•ï¼š** å¤ç”¨äº† ICML/ICLR ç­‰ä¼šè®®çš„è®ºæ–‡ä»»åŠ¡ï¼Œä¿ç•™æ•°æ®å’Œä»£ç æ¡†æ¶ï¼Œè®© GPT-5 çº§åˆ«çš„ Agent å»å¤ç°æˆ–æ”¹è¿›ã€‚\n*   **ç»“æœï¼š** å³ä½¿æ˜¯é¡¶å°–æ¨¡å‹ï¼Œè¡¨ç°ä¹Ÿå­˜åœ¨å·¨å¤§çš„â€œèƒ½åŠ›-å¯é æ€§â€é¸¿æ²Ÿã€‚Agent ç»å¸¸è¡¨ç°å‡ºä¸è€çƒ¦ã€è¿‡åº¦è‡ªä¿¡ã€éš¾ä»¥ç®¡ç†å¹¶è¡Œå®éªŒç­‰é—®é¢˜ã€‚åœ¨ 15 ä¸ªè¯„ä¼°ä¸­ï¼Œä»…æœ‰ 1 æ¬¡è¶…è¶Šäº†åŸºçº¿ã€‚\n\n---\n\n### ğŸ–¼ï¸ å¤šæ¨¡æ€ä¸é«˜æ•ˆè®¡ç®— (Multimodal & Efficiency)\n\n**7. Sparrow: Text-Anchored Window Attention with Visual-Semantic Glimpsing for Speculative Decoding in Video LLMs**\n**Sparrowï¼šç”¨äºè§†é¢‘ LLM æŠ•æœºè§£ç çš„æ–‡æœ¬é”šå®šçª—å£æ³¨æ„åŠ›**\n*   **ç—›ç‚¹ï¼š** æŠ•æœºè§£ç ï¼ˆSpeculative Decodingï¼‰åœ¨è§†é¢‘ LLM ä¸Šç»å¸¸å¤±æ•ˆï¼Œå› ä¸º KV Cache çˆ†ç‚¸å’Œè§†è§‰å™ªå£°ã€‚\n*   **è§‚å¯Ÿï¼š** å‘ç°â€œè§†è§‰è¯­ä¹‰å†…åŒ–â€ç°è±¡ï¼Œå³æ·±å±‚äº¤äº’ä¸­ï¼Œå…³é”®è§†è§‰ä¿¡æ¯å·²ç»ç¼–ç è¿›æ–‡æœ¬éšè—çŠ¶æ€äº†ã€‚\n*   **æ–¹æ¡ˆï¼š** Sparrow æ¡†æ¶åˆ©ç”¨è¿™ä¸€ç‰¹æ€§ï¼Œé€šè¿‡æ–‡æœ¬é”šå®šçš„çª—å£æ³¨æ„åŠ›ï¼Œè®©å°æ¨¡å‹ï¼ˆDraft Modelï¼‰åˆ©ç”¨è¯­ä¹‰ä¸°å¯Œçš„ä¸­é—´çŠ¶æ€ï¼Œè¿‡æ»¤æ‰ä½çº§è§†è§‰å™ªå£°ï¼Œå®ç°äº† 2.82 å€çš„æ¨ç†åŠ é€Ÿã€‚\n\n**8. Understanding vs. Generation: Navigating Optimization Dilemma in Multimodal Models**\n**ç†è§£ vs ç”Ÿæˆï¼šå¤šæ¨¡æ€æ¨¡å‹ä¸­çš„ä¼˜åŒ–å›°å¢ƒ**\n*   **è§‚ç‚¹ï¼š** å¤šæ¨¡æ€æ¨¡å‹ä¸­ï¼Œå¢å¼ºç”Ÿæˆèƒ½åŠ›å¾€å¾€ä»¥ç‰ºç‰²ç†è§£èƒ½åŠ›ä¸ºä»£ä»·ï¼ˆåä¹‹äº¦ç„¶ï¼‰ã€‚\n*   **R3 æ¡†æ¶ï¼š** æå‡ºäº† Reason-Reflect-Refine ç®—æ³•ï¼Œå°†å•æ­¥ç”Ÿæˆåˆ†è§£ä¸ºâ€œç”Ÿæˆ-ç†è§£-å†ç”Ÿæˆâ€çš„è¿‡ç¨‹ï¼Œæ˜¾å¼åˆ©ç”¨æ¨¡å‹çš„ç†è§£èƒ½åŠ›æ¥æŒ‡å¯¼ç”Ÿæˆï¼Œç¼“è§£äº†è¿™ç§ä¼˜åŒ–å†²çªã€‚\n\n---\n\n### ğŸ› ï¸ ç³»ç»Ÿä¸åŸºç¡€è®¾æ–½ (Systems & Infra)\n\n**9. GenAI for Systems: Recurring Challenges and Design Principles from Software to Silicon**\n**é¢å‘ç³»ç»Ÿçš„ GenAIï¼šä»è½¯ä»¶åˆ°ç¡…ç‰‡çš„åå¤æŒ‘æˆ˜ä¸è®¾è®¡åŸåˆ™**\n*   **ç»¼è¿°/è§‚ç‚¹ï¼š** è¿™æ˜¯ä¸€ç¯‡è·¨å±‚çº§çš„å¤§ç»¼è¿°ï¼ˆ275+ ç¯‡è®ºæ–‡ï¼‰ã€‚\n*   **æ ¸å¿ƒï¼š** åˆ†æäº† GenAI åœ¨ä»£ç ç”Ÿæˆã€åˆ†å¸ƒå¼è¿è¡Œæ—¶ã€ç¡¬ä»¶è®¾è®¡ï¼ˆRTLï¼‰ã€ç‰©ç†å¸ƒå±€ç­‰é¢†åŸŸçš„åº”ç”¨ã€‚\n*   **ç»“è®ºï¼š** å‘ç°ä¸åŒå±‚çº§é¢ä¸´ç›¸åŒçš„æŒ‘æˆ˜ï¼ˆåé¦ˆå¾ªç¯å±æœºã€éšæ€§çŸ¥è¯†é—®é¢˜ã€ä¿¡ä»»éªŒè¯ï¼‰ï¼Œå¹¶æ€»ç»“äº†äº”å¤§è®¾è®¡åŸåˆ™ï¼ˆå¦‚æ··åˆæ–¹æ³•ã€æŒç»­åé¦ˆè®¾è®¡ç­‰ï¼‰ã€‚\n\n**10. STAPO: Stabilizing Reinforcement Learning for LLMs by Silencing Rare Spurious Tokens**\n**STAPOï¼šé€šè¿‡é™é»˜ç¨€æœ‰è™šå‡ Token ç¨³å®š LLM çš„å¼ºåŒ–å­¦ä¹ **\n*   **å‘ç°ï¼š** RLHF è®­ç»ƒä¸ç¨³å®šçš„ç½ªé­ç¥¸é¦–æ˜¯ä¸€å°éƒ¨åˆ†ï¼ˆçº¦ 0.01%ï¼‰çš„**è™šå‡ Tokenï¼ˆspurious tokensï¼‰**ã€‚è¿™äº› Token å‡ºç°åœ¨æ­£ç¡®å›å¤ä¸­ï¼Œè™½ç„¶å¯¹æ¨ç†æ²¡è´¡çŒ®ï¼Œå´ç»§æ‰¿äº†é«˜é¢å¥–åŠ±ï¼Œå¯¼è‡´æ¢¯åº¦çˆ†ç‚¸ã€‚\n*   **æ–¹æ³•ï¼š** å±è”½è¿™äº› Token çš„æ¢¯åº¦æ›´æ–°ã€‚ç®€å•æœ‰æ•ˆï¼Œæ€§èƒ½ä¼˜äº GRPOã€‚\n\n---\n\n### ğŸ“ å…¶ä»–å€¼å¾—ä¸€çœ‹çš„è®ºæ–‡\n\n*   **105. Panini: Continual Learning in Token Space via Structured Memory**\n    æå‡ºäº†ä¸€ç§åƒäººç±»ä¸€æ ·çš„éå‚æ•°æŒç»­å­¦ä¹ æ¡†æ¶ã€‚ä¸å­˜åŸå§‹æ–‡æ¡£ï¼ˆRAGï¼‰ï¼Œè€Œæ˜¯å°†æ–‡æ¡£è½¬åŒ–ä¸º**ç”Ÿæˆå¼è¯­ä¹‰å·¥ä½œåŒºï¼ˆGSWï¼‰**â€”â€”ä¸€ç§ QA å¯¹ç½‘ç»œã€‚æ¨ç†æ—¶åœ¨ç½‘ç»œä¸Šæ¸¸èµ°ï¼Œæ•ˆç‡æ¯” RAG é«˜å¾ˆå¤šã€‚\n*   **48. SecCodeBench-V2 Technical Report**\n    é˜¿é‡Œå‘å¸ƒçš„ V2 ç‰ˆæœ¬å®‰å…¨ä»£ç åŸºå‡†æµ‹è¯•ï¼ŒåŒ…å« Java, C, Python ç­‰è¯­è¨€çš„ 98 ä¸ªçœŸå®åœºæ™¯ï¼Œå…³æ³¨ CWE æ¼æ´ç±»åˆ«ã€‚\n*   **106. Protecting Language Models Against Unauthorized Distillation through Trace Rewriting**\n    å¦‚ä½•é˜²æ­¢åˆ«äººè’¸é¦ä½ çš„æ¨¡å‹ï¼Ÿé€šè¿‡é‡å†™æ¨ç†è¿‡ç¨‹ï¼ˆCoTï¼‰ï¼Œåœ¨ä¿æŒç­”æ¡ˆæ­£ç¡®çš„åŒæ—¶é™ä½å…¶ä½œä¸ºâ€œæ•™æâ€çš„ä»·å€¼ï¼Œæˆ–è€…æ¤å…¥ API æ°´å°ã€‚\n*   **67. Prescriptive Scaling Reveals the Evolution of Language Model Capabilities**\n    å…³äº Scaling Law çš„æ–°æ•°æ®ã€‚é™¤äº†æ•°å­¦æ¨ç†å¤–ï¼Œå¤§å¤šæ•°ä»»åŠ¡çš„èƒ½åŠ›è¾¹ç•Œéšç®—åŠ›å¢é•¿æ˜¯ç¨³å®šçš„ã€‚\n\nå¸Œæœ›ä»Šå¤©çš„å¿«æŠ¥å¯¹ä½ çš„ç ”ç©¶æœ‰æ‰€å¯å‘ï¼æˆ‘ä»¬æ˜å¤©è§ã€‚",
  "papers": [
    {
      "arxiv_id": "2602.15823v1",
      "title": "CrispEdit: Low-Curvature Projections for Scalable Non-Destructive LLM Editing",
      "title_zh": "CrispEditï¼šé¢å‘å¯æ‰©å±•éç ´åæ€§å¤§è¯­è¨€æ¨¡å‹ç¼–è¾‘çš„ä½æ›²ç‡æŠ•å½±",
      "authors": [
        "Zarif Ikram",
        "Arad Firouzkouhi",
        "Stephen Tu",
        "Mahdi Soltanolkotabi",
        "Paria Rashidinejad"
      ],
      "abstract": "A central challenge in large language model (LLM) editing is capability preservation: methods that successfully change targeted behavior can quietly game the editing proxy and corrupt general capabilities, producing degenerate behaviors reminiscent of proxy/reward hacking. We present CrispEdit, a scalable and principled second-order editing algorithm that treats capability preservation as an explicit constraint, unifying and generalizing several existing editing approaches. CrispEdit formulates editing as constrained optimization and enforces the constraint by projecting edit updates onto the low-curvature subspace of the capability-loss landscape. At the crux of CrispEdit is expressing capability constraint via Bregman divergence, whose quadratic form yields the Gauss-Newton Hessian exactly and even when the base model is not trained to convergence. We make this second-order procedure efficient at the LLM scale using Kronecker-factored approximate curvature (K-FAC) and a novel matrix-free projector that exploits Kronecker structure to avoid constructing massive projection matrices. Across standard model-editing benchmarks, CrispEdit achieves high edit success while keeping capability degradation below 1% on average across datasets, significantly improving over prior editors.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLM)ç¼–è¾‘ä¸­æ™®éå­˜åœ¨çš„èƒ½åŠ›ä¿æŒ(capability preservation)éš¾é¢˜ï¼Œæå‡ºäº†CrispEditç®—æ³•ã€‚ä½œä¸ºä¸€ç§å¯æ‰©å±•ä¸”åŸºäºåŸåˆ™çš„äºŒé˜¶ç¼–è¾‘ç®—æ³•ï¼ŒCrispEditå°†èƒ½åŠ›ä¿æŒè§†ä¸ºæ˜¾å¼çº¦æŸï¼Œå¹¶é€šè¿‡å°†ç¼–è¾‘æ›´æ–°æŠ•å½±åˆ°èƒ½åŠ›æŸå¤±å›¾è°±çš„ä½æ›²ç‡å­ç©ºé—´(low-curvature subspace)æ¥å®æ–½è¯¥çº¦æŸã€‚è¯¥æ–¹æ³•åˆ©ç”¨Bregmanæ•£åº¦æ¥è¡¨è¾¾èƒ½åŠ›çº¦æŸï¼Œå¹¶ç»“åˆå…‹ç½—å†…å…‹åˆ†è§£è¿‘ä¼¼æ›²ç‡(K-FAC)å’Œæ–°å‹æ— çŸ©é˜µæŠ•å½±å™¨(matrix-free projector)ï¼Œåœ¨LLMè§„æ¨¡ä¸‹å®ç°äº†é«˜æ•ˆçš„äºŒé˜¶ä¼˜åŒ–ç¨‹åºã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCrispEditåœ¨æ ‡å‡†æ¨¡å‹ç¼–è¾‘åŸºå‡†æµ‹è¯•ä¸­å®ç°äº†æé«˜çš„ç¼–è¾‘æˆåŠŸç‡ï¼ŒåŒæ—¶å°†å¹³å‡èƒ½åŠ›é€€åŒ–æ§åˆ¶åœ¨1%ä»¥ä¸‹ï¼Œç›¸è¾ƒäºç°æœ‰çš„æ¨¡å‹ç¼–è¾‘æ–¹æ³•å–å¾—äº†æ˜¾è‘—æ”¹è¿›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15823v1",
      "published_date": "2026-02-17 18:58:04 UTC",
      "updated_date": "2026-02-17 18:58:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:31:16.840887+00:00"
    },
    {
      "arxiv_id": "2602.15816v1",
      "title": "Developing AI Agents with Simulated Data: Why, what, and how?",
      "title_zh": "åŸºäºæ¨¡æ‹Ÿæ•°æ®çš„ AI æ™ºèƒ½ä½“å¼€å‘ï¼šåŠ¨å› ã€å†…æ¶µä¸æ–¹æ³•",
      "authors": [
        "Xiaoran Liu",
        "Istvan David"
      ],
      "abstract": "As insufficient data volume and quality remain the key impediments to the adoption of modern subsymbolic AI, techniques of synthetic data generation are in high demand. Simulation offers an apt, systematic approach to generating diverse synthetic data. This chapter introduces the reader to the key concepts, benefits, and challenges of simulation-based synthetic data generation for AI training purposes, and to a reference framework to describe, design, and analyze digital twin-based AI simulation solutions.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨ç°ä»£ subsymbolic AI é¢ä¸´æ•°æ®é‡å’Œè´¨é‡ä¸è¶³çš„èƒŒæ™¯ä¸‹ï¼Œåˆ©ç”¨æ¨¡æ‹ŸæŠ€æœ¯ç”Ÿæˆåˆæˆæ•°æ®(synthetic data generation)çš„å¿…è¦æ€§ä¸æ–¹æ³•ã€‚æ–‡ç« è¯¦ç»†ä»‹ç»äº†åŸºäºæ¨¡æ‹Ÿçš„åˆæˆæ•°æ®ç”Ÿæˆçš„å…³é”®æ¦‚å¿µã€ä¼˜åŠ¿ä»¥åŠé¢ä¸´çš„æŒ‘æˆ˜ï¼Œæ—¨åœ¨ä¸º AI è®­ç»ƒæä¾›ç³»ç»ŸåŒ–çš„æ•°æ®è·å–é€”å¾„ã€‚ä½œè€…æå‡ºäº†ä¸€ä¸ªå‚è€ƒæ¡†æ¶(reference framework)ï¼Œç”¨äºæè¿°ã€è®¾è®¡å’Œåˆ†æåŸºäºæ•°å­—å­ªç”Ÿ(digital twin)çš„ AI æ¨¡æ‹Ÿè§£å†³æ–¹æ¡ˆã€‚è¯¥æ¡†æ¶ä¸ºè§£å†³æ•°æ®åŒ®ä¹é—®é¢˜æä¾›äº†ç†è®ºä¸å®è·µæŒ‡å¯¼ï¼Œæœ‰åŠ©äºæ¨åŠ¨æ›´é«˜æ•ˆã€å¤šæ ·åŒ–çš„ AI æ™ºèƒ½ä½“å¼€å‘ã€‚",
      "categories": [
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15816v1",
      "published_date": "2026-02-17 18:53:27 UTC",
      "updated_date": "2026-02-17 18:53:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:31:18.349175+00:00"
    },
    {
      "arxiv_id": "2602.15814v1",
      "title": "Avey-B",
      "title_zh": "Avey-B",
      "authors": [
        "Devang Acharya",
        "Mohammad Hammoud"
      ],
      "abstract": "Compact pretrained bidirectional encoders remain the backbone of industrial NLP under tight compute and memory budgets. Their effectiveness stems from self-attention's ability to deliver high-quality bidirectional contextualization with sequence-level parallelism, as popularized by BERT-style architectures. Recently, Avey was introduced as an autoregressive, attention-free alternative that naturally admits an encoder-only adaptation. In this paper, we reformulate Avey for the encoder-only paradigm and propose several innovations to its architecture, including decoupled static and dynamic parameterizations, stability-oriented normalization, and neural compression. Results show that this reformulated architecture compares favorably to four widely used Transformer-based encoders, consistently outperforming them on standard token-classification and information-retrieval benchmarks while scaling more efficiently to long contexts.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Avey-Bï¼Œè¿™æ˜¯ä¸€ç§é’ˆå¯¹ encoder-only èŒƒå¼é‡æ–°è®¾è®¡çš„åŒå‘ç¼–ç å™¨æ¶æ„ï¼Œæ—¨åœ¨ä¸ºè®¡ç®—å’Œå†…å­˜å—é™çš„å·¥ä¸šçº§ NLP æä¾›é«˜æ•ˆçš„æ›¿ä»£æ–¹æ¡ˆã€‚Avey-B æ”¹è¿›äº†åŸæœ‰çš„ Avey æ¶æ„ï¼Œå¹¶å¼•å…¥äº†åŒ…æ‹¬è§£è€¦çš„é™æ€ä¸åŠ¨æ€å‚æ•°åŒ– (decoupled static and dynamic parameterizations)ã€é¢å‘ç¨³å®šæ€§çš„å½’ä¸€åŒ– (stability-oriented normalization) ä»¥åŠç¥ç»å‹ç¼© (neural compression) åœ¨å†…çš„å¤šé¡¹æŠ€æœ¯åˆ›æ–°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¶æ„åœ¨æ ‡å‡† token-classification å’Œ information-retrieval åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œä¸€è‡´ä¼˜äºå››ç§ä¸»æµçš„ Transformer-based ç¼–ç å™¨ã€‚æ­¤å¤–ï¼ŒAvey-B åœ¨å¤„ç†é•¿ä¸Šä¸‹æ–‡ (long contexts) æ—¶å…·æœ‰æ›´ä½³çš„æ‰©å±•æ•ˆç‡ï¼Œè¯æ˜äº†å…¶åœ¨å—é™è®¡ç®—èµ„æºä¸‹å®ç°é«˜æ€§èƒ½åŒå‘ä¸Šä¸‹æ–‡ç†è§£çš„æ½œåŠ›ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15814v1",
      "published_date": "2026-02-17 18:50:40 UTC",
      "updated_date": "2026-02-17 18:50:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:31:33.635698+00:00"
    },
    {
      "arxiv_id": "2602.15811v1",
      "title": "Task-Agnostic Continual Learning for Chest Radiograph Classification",
      "title_zh": "èƒ¸éƒ¨ X çº¿ç‰‡åˆ†ç±»çš„ä»»åŠ¡æ— å…³æŒç»­å­¦ä¹ ",
      "authors": [
        "Muthu Subash Kavitha",
        "Anas Zafar",
        "Amgad Muneer",
        "Jia Wu"
      ],
      "abstract": "Clinical deployment of chest radiograph classifiers requires models that can be updated as new datasets become available without retraining on previously ob- served data or degrading validated performance. We study, for the first time, a task-incremental continual learning setting for chest radiograph classification, in which heterogeneous chest X-ray datasets arrive sequentially and task identifiers are unavailable at inference. We propose a continual adapter-based routing learning strategy for Chest X-rays (CARL-XRay) that maintains a fixed high-capacity backbone and incrementally allocates lightweight task-specific adapters and classifier heads. A latent task selector operates on task-adapted features and leverages both current and historical context preserved through compact prototypes and feature-level experience replay. This design supports stable task identification and adaptation across sequential updates while avoiding raw-image storage. Experiments on large-scale public chest radiograph datasets demonstrate robust performance retention and reliable task-aware inference under continual dataset ingestion. CARL-XRay outperforms joint training under task-unknown deployment, achieving higher routing accuracy (75.0\\% vs.\\ 62.5\\%), while maintaining competitive diagnostic performance with AUROC of 0.74 in the oracle setting with ground-truth task identity and 0.75 under task-unknown inference, using significantly fewer trainable parameters. Finally, the proposed framework provides a practical alternative to joint training and repeated full retraining in continual clinical deployment.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹èƒ¸éƒ¨ X çº¿å½±åƒåˆ†ç±»ä»»åŠ¡ï¼Œæ¢ç´¢äº†åœ¨æ¨ç†é˜¶æ®µç¼ºä¹ä»»åŠ¡æ ‡è¯†çš„æŒç»­å­¦ä¹  (Task-Agnostic Continual Learning) åœºæ™¯ã€‚ä½œè€…æå‡ºäº† CARL-XRay æ¡†æ¶ï¼Œé€šè¿‡ç»´æŒå›ºå®šçš„é«˜å®¹é‡éª¨å¹²ç½‘ç»œ (backbone) å¹¶å¢é‡åˆ†é…è½»é‡çº§çš„ä»»åŠ¡ç‰¹å®šé€‚é…å™¨ (adapters) ä¸åˆ†ç±»å¤´ï¼Œå®ç°äº†å¯¹æ–°æ•°æ®é›†çš„æŒç»­å¸æ”¶ã€‚è¯¥æ–¹æ³•ç»“åˆäº†åŸå‹ (prototypes) å’Œç‰¹å¾çº§ç»éªŒå›æ”¾ (feature-level experience replay) æŠ€æœ¯ï¼Œåœ¨æ— éœ€å­˜å‚¨åŸå§‹å›¾åƒçš„å‰æä¸‹ç¡®ä¿äº†ä»»åŠ¡è¯†åˆ«ä¸é€‚åº”çš„ç¨³å®šæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCARL-XRay åœ¨ä»»åŠ¡æœªçŸ¥éƒ¨ç½²ä¸‹çš„è·¯ç”±å‡†ç¡®ç‡è¾¾åˆ° 75.0%ï¼Œä¼˜äºè”åˆè®­ç»ƒï¼ŒåŒæ—¶åœ¨ä¿æŒ 0.75 AUROC è¯Šæ–­æ°´å¹³çš„åŸºç¡€ä¸Šå¤§å¹…å‡å°‘äº†å¯è®­ç»ƒå‚æ•°é‡ã€‚è¯¥æ¡†æ¶ä¸ºä¸´åºŠç¯å¢ƒä¸‹çš„æ¨¡å‹æŒç»­æ›´æ–°æä¾›äº†ä¸€ç§é«˜æ•ˆä¸”å®ç”¨çš„æ–¹æ¡ˆï¼Œæœ‰æ•ˆè§£å†³äº†ä¼ ç»Ÿæ–¹æ³•ä¸­é¢‘ç¹å…¨å±€é‡è®­çš„éš¾é¢˜ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.15811v1",
      "published_date": "2026-02-17 18:47:30 UTC",
      "updated_date": "2026-02-17 18:47:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:31:34.245114+00:00"
    },
    {
      "arxiv_id": "2602.15809v1",
      "title": "Decision Quality Evaluation Framework at Pinterest",
      "title_zh": "Pinterest å†³ç­–è´¨é‡è¯„ä¼°æ¡†æ¶",
      "authors": [
        "Yuqi Tian",
        "Robert Paine",
        "Attila Dobi",
        "Kevin O'Sullivan",
        "Aravindh Manickavasagam",
        "Faisal Farooq"
      ],
      "abstract": "Online platforms require robust systems to enforce content safety policies at scale. A critical component of these systems is the ability to evaluate the quality of moderation decisions made by both human agents and Large Language Models (LLMs). However, this evaluation is challenging due to the inherent trade-offs between cost, scale, and trustworthiness, along with the complexity of evolving policies. To address this, we present a comprehensive Decision Quality Evaluation Framework developed and deployed at Pinterest. The framework is centered on a high-trust Golden Set (GDS) curated by subject matter experts (SMEs), which serves as a ground truth benchmark. We introduce an automated intelligent sampling pipeline that uses propensity scores to efficiently expand dataset coverage. We demonstrate the framework's practical application in several key areas: benchmarking the cost-performance trade-offs of various LLM agents, establishing a rigorous methodology for data-driven prompt optimization, managing complex policy evolution, and ensuring the integrity of policy content prevalence metrics via continuous validation. The framework enables a shift from subjective assessments to a data-driven and quantitative practice for managing content safety systems.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»‹ç»äº†Pinterestå¼€å‘å¹¶éƒ¨ç½²çš„Decision Quality Evaluation Frameworkï¼Œæ—¨åœ¨è§£å†³å¤§è§„æ¨¡å†…å®¹å®‰å…¨æ”¿ç­–æ‰§è¡Œä¸­è¯„ä¼°äººå·¥å’ŒLarge Language Models (LLMs)å®¡æ ¸å†³ç­–è´¨é‡çš„æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶çš„æ ¸å¿ƒæ˜¯ç”±é¢†åŸŸä¸“å®¶(SMEs)ç­–åˆ’çš„é«˜ä¿¡ä»»åº¦Golden Set (GDS)ï¼Œå¹¶åˆ©ç”¨å€¾å‘è¯„åˆ†(propensity scores)æ„å»ºäº†è‡ªåŠ¨åŒ–æ™ºèƒ½é‡‡æ ·æµæ°´çº¿(automated intelligent sampling pipeline)ä»¥æ‰©å±•æ•°æ®é›†è¦†ç›–èŒƒå›´ã€‚é€šè¿‡è¯¥æ¡†æ¶ï¼Œç ”ç©¶äººå‘˜èƒ½å¤Ÿè¡¡é‡ä¸åŒLLMæ™ºèƒ½ä½“çš„æˆæœ¬æ€§èƒ½æƒè¡¡ï¼Œå¹¶å»ºç«‹äº†æ•°æ®é©±åŠ¨çš„æç¤ºè¯ä¼˜åŒ–(prompt optimization)ä¸¥è°¨æ–¹æ³•è®ºã€‚æ­¤å¤–ï¼Œè¯¥ç³»ç»Ÿåœ¨ç®¡ç†å¤æ‚æ”¿ç­–æ¼”å˜å’Œç¡®ä¿å†…å®¹æµè¡Œåº¦æŒ‡æ ‡å®Œæ•´æ€§æ–¹é¢å‘æŒ¥äº†å…³é”®ä½œç”¨ã€‚è¿™ä¸€æ¡†æ¶çš„å®æ–½æ ‡å¿—ç€å†…å®¹å®‰å…¨ç³»ç»Ÿç®¡ç†ä»ä¸»è§‚è¯„ä¼°å‘æ•°æ®é©±åŠ¨å’Œå®šé‡åŒ–å®è·µçš„è½¬å˜ï¼Œä¸ºæ„å»ºå¯ä¿¡ä¸”å¯æ‰©å±•çš„å®¡æ ¸ç³»ç»Ÿæä¾›äº†æœ‰åŠ›æ”¯æ’‘ã€‚",
      "categories": [
        "stat.AP",
        "cs.AI"
      ],
      "primary_category": "stat.AP",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15809v1",
      "published_date": "2026-02-17 18:45:55 UTC",
      "updated_date": "2026-02-17 18:45:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:31:36.739224+00:00"
    },
    {
      "arxiv_id": "2602.15799v1",
      "title": "The Geometry of Alignment Collapse: When Fine-Tuning Breaks Safety",
      "title_zh": "å¯¹é½å´©å¡Œçš„å‡ ä½•å­¦ï¼šå¾®è°ƒä½•æ—¶ç ´åå®‰å…¨æ€§",
      "authors": [
        "Max Springer",
        "Chung Peng Lee",
        "Blossom Metevier",
        "Jane Castleman",
        "Bohdan Turbal",
        "Hayoung Jung",
        "Zeyu Shen",
        "Aleksandra Korolova"
      ],
      "abstract": "Fine-tuning aligned language models on benign tasks unpredictably degrades safety guardrails, even when training data contains no harmful content and developers have no adversarial intent. We show that the prevailing explanation, that fine-tuning updates should be orthogonal to safety-critical directions in high-dimensional parameter space, offers false reassurance: we show this orthogonality is structurally unstable and collapses under the dynamics of gradient descent. We then resolve this through a novel geometric analysis, proving that alignment concentrates in low-dimensional subspaces with sharp curvature, creating a brittle structure that first-order methods cannot detect or defend. While initial fine-tuning updates may indeed avoid these subspaces, the curvature of the fine-tuning loss generates second-order acceleration that systematically steers trajectories into alignment-sensitive regions. We formalize this mechanism through the Alignment Instability Condition, three geometric properties that, when jointly satisfied, lead to safety degradation. Our main result establishes a quartic scaling law: alignment loss grows with the fourth power of training time, governed by the sharpness of alignment geometry and the strength of curvature coupling between the fine-tuning task and safety-critical parameters. These results expose a structural blind spot in the current safety paradigm. The dominant approaches to safe fine-tuning address only the initial snapshot of a fundamentally dynamic problem. Alignment fragility is not a bug to be patched; it is an intrinsic geometric property of gradient descent on curved manifolds. Our results motivate the development of curvature-aware methods, and we hope will further enable a shift in alignment safety analysis from reactive red-teaming to predictive diagnostics for open-weight model deployment.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å³ä½¿åœ¨è‰¯æ€§ä»»åŠ¡ä¸Šè¿›è¡Œå¾®è°ƒï¼Œå·²å¯¹é½çš„è¯­è¨€æ¨¡å‹ä¹Ÿä¼šæ„å¤–å‡ºç°å®‰å…¨é˜²å¾¡å´©æºƒçš„ç°è±¡ã€‚ä½œè€…æŒ‡å‡ºï¼Œå¾®è°ƒæ›´æ–°ä¸å®‰å…¨å…³é”®æ–¹å‘åœ¨å‚æ•°ç©ºé—´ä¸­ç›¸äº’æ­£äº¤çš„ä¼ ç»Ÿè§£é‡Šåœ¨ç»“æ„ä¸Šæ˜¯ä¸ç¨³å®šçš„ï¼Œä¸”åœ¨æ¢¯åº¦ä¸‹é™(Gradient Descent)çš„åŠ¨åŠ›å­¦ä¸‹ä¼šå‘ç”Ÿå´©æºƒã€‚é€šè¿‡å‡ ä½•åˆ†æï¼Œè¯¥ç ”ç©¶è¯æ˜äº†æ¨¡å‹å¯¹é½(Alignment)é›†ä¸­åœ¨å…·æœ‰å°–é”æ›²ç‡(Sharp Curvature)çš„ä½ç»´å­ç©ºé—´ä¸­ï¼Œå½¢æˆäº†ä¸€ç§ä¸€é˜¶æ–¹æ³•æ— æ³•æ£€æµ‹æˆ–é˜²å¾¡çš„è„†å¼±ç»“æ„ã€‚ç ”ç©¶è¡¨æ˜ï¼Œå¾®è°ƒæŸå¤±çš„æ›²ç‡ä¼šäº§ç”ŸäºŒé˜¶åŠ é€Ÿåº¦ï¼Œç³»ç»Ÿæ€§åœ°å°†è®­ç»ƒè½¨è¿¹å¼•å¯¼è‡³å¯¹é½æ•æ„ŸåŒºåŸŸï¼Œå¹¶æ®æ­¤æå‡ºäº†ç”±ä¸‰ä¸ªå‡ ä½•å±æ€§ç»„æˆçš„â€œå¯¹é½ä¸ç¨³å®šæ¡ä»¶â€(Alignment Instability Condition)ã€‚æ ¸å¿ƒç»“æœç¡®ç«‹äº†ä¸€ä¸ªå››æ¬¡æ–¹ç¼©æ”¾æ³•åˆ™(Quartic Scaling Law)ï¼Œå³å¯¹é½æŸå¤±éšè®­ç»ƒæ—¶é—´çš„å››æ¬¡æ–¹å¢é•¿ï¼Œæ­ç¤ºäº†å¯¹é½è„†å¼±æ€§æ˜¯æ¢¯åº¦ä¸‹é™åœ¨å¼¯æ›²æµå½¢ä¸Šçš„å†…åœ¨å‡ ä½•å±æ€§ã€‚è¿™ä¸€å‘ç°ä¿ƒä½¿å®‰å…¨åˆ†æä»è¢«åŠ¨çš„çº¢é˜Ÿæµ‹è¯•(Red-teaming)è½¬å‘é¢„æµ‹æ€§è¯Šæ–­ï¼Œå¹¶å¼ºè°ƒäº†å¼€å‘æ›²ç‡æ„ŸçŸ¥(Curvature-aware)æ–¹æ³•çš„å¿…è¦æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "27 pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.15799v1",
      "published_date": "2026-02-17 18:39:15 UTC",
      "updated_date": "2026-02-17 18:39:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:31:52.135693+00:00"
    },
    {
      "arxiv_id": "2602.15791v1",
      "title": "Enhancing Building Semantics Preservation in AI Model Training with Large Language Model Encodings",
      "title_zh": "åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ç¼–ç å¢å¼º AI æ¨¡å‹è®­ç»ƒä¸­çš„å»ºç­‘è¯­ä¹‰ä¿æŒ",
      "authors": [
        "Suhyung Jang",
        "Ghang Lee",
        "Jaekun Lee",
        "Hyunjun Lee"
      ],
      "abstract": "Accurate representation of building semantics, encompassing both generic object types and specific subtypes, is essential for effective AI model training in the architecture, engineering, construction, and operation (AECO) industry. Conventional encoding methods (e.g., one-hot) often fail to convey the nuanced relationships among closely related subtypes, limiting AI's semantic comprehension. To address this limitation, this study proposes a novel training approach that employs large language model (LLM) embeddings (e.g., OpenAI GPT and Meta LLaMA) as encodings to preserve finer distinctions in building semantics. We evaluated the proposed method by training GraphSAGE models to classify 42 building object subtypes across five high-rise residential building information models (BIMs). Various embedding dimensions were tested, including original high-dimensional LLM embeddings (1,536, 3,072, or 4,096) and 1,024-dimensional compacted embeddings generated via the Matryoshka representation model. Experimental results demonstrated that LLM encodings outperformed the conventional one-hot baseline, with the llama-3 (compacted) embedding achieving a weighted average F1-score of 0.8766, compared to 0.8475 for one-hot encoding. The results underscore the promise of leveraging LLM-based encodings to enhance AI's ability to interpret complex, domain-specific building semantics. As the capabilities of LLMs and dimensionality reduction techniques continue to evolve, this approach holds considerable potential for broad application in semantic elaboration tasks throughout the AECO industry.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å»ºç­‘ã€å·¥ç¨‹ã€æ–½å·¥åŠè¿è¥ (AECO) è¡Œä¸šä¸­å»ºç­‘è¯­ä¹‰çš„å‡†ç¡®è¡¨è¾¾é—®é¢˜ï¼ŒæŒ‡å‡ºä¼ ç»Ÿ one-hot ç¼–ç éš¾ä»¥æ•æ‰å¯¹è±¡å­ç±»å‹é—´çš„ç»†å¾®å…³ç³»ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶æå‡ºä¸€ç§åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ (LLM) åµŒå…¥ï¼ˆå¦‚ OpenAI GPT å’Œ Meta LLaMAï¼‰ä½œä¸ºç¼–ç çš„æ–°å‹è®­ç»ƒæ–¹æ³•ï¼Œä»¥å¢å¼º AI æ¨¡å‹å¯¹å¤æ‚å»ºç­‘è¯­ä¹‰çš„ä¿ç•™ä¸ç†è§£ã€‚é€šè¿‡åœ¨äº”ä¸ªé«˜å±‚ä½å®…å»ºç­‘ä¿¡æ¯æ¨¡å‹ (BIMs) ä¸Šè®­ç»ƒ GraphSAGE æ¨¡å‹ï¼Œç ”ç©¶äººå‘˜å¯¹ 42 ç§å»ºç­‘å¯¹è±¡å­ç±»å‹è¿›è¡Œäº†åˆ†ç±»è¯„ä¼°ã€‚å®éªŒæµ‹è¯•äº†åŸå§‹é«˜ç»´ LLM åµŒå…¥åŠé€šè¿‡ Matryoshka è¡¨è¾¾æ¨¡å‹ç”Ÿæˆçš„å‹ç¼©åµŒå…¥ï¼Œç»“æœæ˜¾ç¤º LLM ç¼–ç è¡¨ç°æ˜¾è‘—ä¼˜äº one-hot åŸºå‡†ã€‚å…¶ä¸­ llama-3 (compacted) åµŒå…¥è¾¾åˆ°äº† 0.8766 çš„åŠ æƒå¹³å‡ F1-scoreï¼Œè¯æ˜äº†åˆ©ç”¨ LLM ç¼–ç æå‡é¢†åŸŸç‰¹å®šè¯­ä¹‰è§£é‡Šèƒ½åŠ›çš„å·¨å¤§æ½œåŠ›ã€‚è¯¥æ–¹æ³•ä¸º AECO è¡Œä¸šä¸­çš„è¯­ä¹‰ç»†åŒ–ä»»åŠ¡æä¾›äº†å¹¿é˜”çš„åº”ç”¨å‰æ™¯ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "42nd International Symposium on Automation and Robotics in Construction (ISARC 2025)",
      "pdf_url": "https://arxiv.org/pdf/2602.15791v1",
      "published_date": "2026-02-17 18:26:36 UTC",
      "updated_date": "2026-02-17 18:26:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:31:54.941366+00:00"
    },
    {
      "arxiv_id": "2602.15785v1",
      "title": "This human study did not involve human subjects: Validating LLM simulations as behavioral evidence",
      "title_zh": "è¿™é¡¹äººç±»ç ”ç©¶ä¸æ¶‰åŠäººç±»å—è¯•è€…ï¼šå°†LLMæ¨¡æ‹ŸéªŒè¯ä¸ºè¡Œä¸ºè¯æ®",
      "authors": [
        "Jessica Hullman",
        "David Broska",
        "Huaman Sun",
        "Aaron Shaw"
      ],
      "abstract": "A growing literature uses large language models (LLMs) as synthetic participants to generate cost-effective and nearly instantaneous responses in social science experiments. However, there is limited guidance on when such simulations support valid inference about human behavior. We contrast two strategies for obtaining valid estimates of causal effects and clarify the assumptions under which each is suitable for exploratory versus confirmatory research. Heuristic approaches seek to establish that simulated and observed human behavior are interchangeable through prompt engineering, model fine-tuning, and other repair strategies designed to reduce LLM-induced inaccuracies. While useful for many exploratory tasks, heuristic approaches lack the formal statistical guarantees typically required for confirmatory research. In contrast, statistical calibration combines auxiliary human data with statistical adjustments to account for discrepancies between observed and simulated responses. Under explicit assumptions, statistical calibration preserves validity and provides more precise estimates of causal effects at lower cost than experiments that rely solely on human participants. Yet the potential of both approaches depends on how well LLMs approximate the relevant populations. We consider what opportunities are overlooked when researchers focus myopically on substituting LLMs for human participants in a study.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨ç¤¾ä¼šç§‘å­¦å®éªŒä¸­ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä½œä¸ºåˆæˆå—è¯•è€…ï¼ˆsynthetic participantsï¼‰çš„æœ‰æ•ˆæ€§ï¼Œå¹¶å¯¹æ¯”äº†è·å–æœ‰æ•ˆå› æœæ•ˆåº”ä¼°è®¡çš„ä¸¤ç§æ ¸å¿ƒç­–ç•¥ã€‚å¯å‘å¼æ–¹æ³•ï¼ˆheuristic approachesï¼‰é€šè¿‡æç¤ºå·¥ç¨‹å’Œæ¨¡å‹å¾®è°ƒæ—¨åœ¨å®ç°æ¨¡æ‹Ÿä¸è§‚å¯Ÿè¡Œä¸ºçš„äº’æ¢ï¼Œè™½ç„¶é€‚ç”¨äºæ¢ç´¢æ€§ä»»åŠ¡ï¼Œä½†ç¼ºä¹éªŒè¯æ€§ç ”ç©¶æ‰€éœ€çš„æ­£å¼ç»Ÿè®¡ä¿è¯ã€‚ä¸ä¹‹ç›¸å¯¹ï¼Œç»Ÿè®¡æ ¡å‡†ï¼ˆstatistical calibrationï¼‰é€šè¿‡ç»“åˆè¾…åŠ©äººç±»æ•°æ®å’Œç»Ÿè®¡è°ƒæ•´æ¥ä¿®æ­£åå·®ï¼Œåœ¨ç‰¹å®šå‡è®¾ä¸‹èƒ½ä»¥æ›´ä½æˆæœ¬æä¾›æ›´ç²¾ç¡®çš„å› æœæ•ˆåº”ï¼ˆcausal effectsï¼‰ä¼°è®¡ã€‚ç ”ç©¶å¼ºè°ƒï¼Œè¿™ä¸¤ç±»æ–¹æ³•çš„æˆåŠŸåº”ç”¨å‡å–å†³äºLLMså¯¹ç›¸å…³ç›®æ ‡ç¾¤ä½“çš„è¿‘ä¼¼ç¨‹åº¦ã€‚æœ€åï¼Œè¯¥è®ºæ–‡æŒ‡å‡ºç ”ç©¶è€…ä¸åº”ä»…å°†LLMsè§†ä¸ºäººç±»å—è¯•è€…çš„ç®€å•æ›¿ä»£å“ï¼Œè€Œåº”å…³æ³¨å…¶åœ¨æ›´å¹¿æ³›ç ”ç©¶è§†é‡ä¸‹å¸¦æ¥çš„æœºé‡ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15785v1",
      "published_date": "2026-02-17 18:18:38 UTC",
      "updated_date": "2026-02-17 18:18:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:32:00.544750+00:00"
    },
    {
      "arxiv_id": "2602.15776v1",
      "title": "GlobeDiff: State Diffusion Process for Partial Observability in Multi-Agent Systems",
      "title_zh": "GlobeDiffï¼šé¢å‘å¤šæ™ºèƒ½ä½“ç³»ç»Ÿéƒ¨åˆ†å¯è§‚æµ‹æ€§çš„çŠ¶æ€æ‰©æ•£è¿‡ç¨‹",
      "authors": [
        "Yiqin Yang",
        "Xu Yang",
        "Yuhua Jiang",
        "Ni Mu",
        "Hao Hu",
        "Runpeng Xie",
        "Ziyou Zhang",
        "Siyuan Li",
        "Yuan-Hua Ni",
        "Qianchuan Zhao",
        "Bo Xu"
      ],
      "abstract": "In the realm of multi-agent systems, the challenge of \\emph{partial observability} is a critical barrier to effective coordination and decision-making. Existing approaches, such as belief state estimation and inter-agent communication, often fall short. Belief-based methods are limited by their focus on past experiences without fully leveraging global information, while communication methods often lack a robust model to effectively utilize the auxiliary information they provide. To solve this issue, we propose Global State Diffusion Algorithm~(GlobeDiff) to infer the global state based on the local observations. By formulating the state inference process as a multi-modal diffusion process, GlobeDiff overcomes ambiguities in state estimation while simultaneously inferring the global state with high fidelity. We prove that the estimation error of GlobeDiff under both unimodal and multi-modal distributions can be bounded. Extensive experimental results demonstrate that GlobeDiff achieves superior performance and is capable of accurately inferring the global state.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ(Multi-Agent Systems)ä¸­éƒ¨åˆ†å¯è§‚æµ‹æ€§(Partial Observability)ç»™åè°ƒä¸å†³ç­–å¸¦æ¥çš„æŒ‘æˆ˜ï¼ŒæŒ‡å‡ºä¼ ç»Ÿç½®ä¿¡çŠ¶æ€ä¼°è®¡å’Œé€šä¿¡æ–¹æ³•åœ¨åˆ©ç”¨å…¨å±€ä¿¡æ¯æ–¹é¢çš„å±€é™æ€§ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†GlobeDiff (Global State Diffusion Algorithm)ï¼Œæ—¨åœ¨é€šè¿‡å±€éƒ¨è§‚æµ‹ç²¾ç¡®æ¨æ–­å…¨å±€çŠ¶æ€ã€‚è¯¥ç®—æ³•å°†çŠ¶æ€æ¨æ–­å»ºæ¨¡ä¸ºä¸€ä¸ªå¤šæ¨¡æ€æ‰©æ•£è¿‡ç¨‹(Multi-modal Diffusion Process)ï¼Œä¸ä»…å…‹æœäº†çŠ¶æ€ä¼°è®¡ä¸­çš„æ­§ä¹‰ï¼Œè¿˜å®ç°äº†é«˜ä¿çœŸåº¦çš„å…¨å±€çŠ¶æ€è¿˜åŸã€‚ç†è®ºè¯æ˜è¡¨æ˜ï¼ŒGlobeDiffåœ¨å•æ¨¡æ€å’Œå¤šæ¨¡æ€åˆ†å¸ƒä¸‹çš„ä¼°è®¡è¯¯å·®å‡å¤„äºæœ‰ç•Œ(Bounded)èŒƒå›´å†…ã€‚å®éªŒç»“æœè¿›ä¸€æ­¥è¯å®ï¼ŒGlobeDiffåœ¨å‡†ç¡®æ¨æ–­å…¨å±€çŠ¶æ€æ–¹é¢å…·æœ‰ä¼˜è¶Šæ€§èƒ½ï¼Œä¸ºè§£å†³å¤æ‚ç¯å¢ƒä¸‹çš„å¤šæ™ºèƒ½ä½“åä½œé—®é¢˜æä¾›äº†æœ‰æ•ˆçš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15776v1",
      "published_date": "2026-02-17 18:05:48 UTC",
      "updated_date": "2026-02-17 18:05:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:32:05.964740+00:00"
    },
    {
      "arxiv_id": "2602.15772v1",
      "title": "Understanding vs. Generation: Navigating Optimization Dilemma in Multimodal Models",
      "title_zh": "ç†è§£ä¸ç”Ÿæˆï¼šåº”å¯¹å¤šæ¨¡æ€æ¨¡å‹ä¸­çš„ä¼˜åŒ–å›°å¢ƒ",
      "authors": [
        "Sen Ye",
        "Mengde Xu",
        "Shuyang Gu",
        "Di He",
        "Liwei Wang",
        "Han Hu"
      ],
      "abstract": "Current research in multimodal models faces a key challenge where enhancing generative capabilities often comes at the expense of understanding, and vice versa. We analyzed this trade-off and identify the primary cause might be the potential conflict between generation and understanding, which creates a competitive dynamic within the model. To address this, we propose the Reason-Reflect-Refine (R3) framework. This innovative algorithm re-frames the single-step generation task into a multi-step process of \"generate-understand-regenerate\". By explicitly leveraging the model's understanding capability during generation, we successfully mitigate the optimization dilemma, achieved stronger generation results and improved understanding ability which are related to the generation process. This offers valuable insights for designing next-generation unified multimodal models. Code is available at https://github.com/sen-ye/R3.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤šæ¨¡æ€æ¨¡å‹ (Multimodal Models) åœ¨ç†è§£ä¸ç”Ÿæˆèƒ½åŠ›ä¹‹é—´çš„æƒè¡¡æŒ‘æˆ˜ï¼ŒæŒ‡å‡ºä¸¤è€…èƒ½åŠ›çš„æå‡å¾€å¾€äº’ä¸ºä»£ä»·ã€‚ä½œè€…åˆ†æå‘ç°ï¼Œè¿™ç§ä¼˜åŒ–å›°å¢ƒ (Optimization Dilemma) çš„æ ¸å¿ƒåœ¨äºç”Ÿæˆä¸ç†è§£ä»»åŠ¡ä¹‹é—´å­˜åœ¨çš„ç«äº‰æ€§å†²çªã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œç ”ç©¶æå‡ºäº† Reason-Reflect-Refine (R3) æ¡†æ¶ï¼Œå°†ä¼ ç»Ÿçš„å•æ­¥ç”Ÿæˆä»»åŠ¡é‡æ–°æ„å»ºä¸ºâ€œç”Ÿæˆ-ç†è§£-å†ç”Ÿæˆâ€ (Generate-Understand-Regenerate) çš„å¤šæ­¥è¿­ä»£è¿‡ç¨‹ã€‚è¯¥ç®—æ³•é€šè¿‡åœ¨ç”Ÿæˆé˜¶æ®µæ˜¾å¼åˆ©ç”¨æ¨¡å‹çš„ç†è§£èƒ½åŠ›ï¼ŒæˆåŠŸç¼“è§£äº†ä¼˜åŒ–å›°å¢ƒï¼Œå¹¶åœ¨ç”Ÿæˆæ•ˆæœä¸ç†è§£èƒ½åŠ›ä¸Šå‡å–å¾—äº†æå‡ã€‚è¿™ä¸€æˆæœä¸ºè®¾è®¡ä¸‹ä¸€ä»£ç»Ÿä¸€å¤šæ¨¡æ€æ¨¡å‹æä¾›äº†é‡è¦è§è§£ï¼Œå¹¶å·²å…¬å¼€ç›¸å…³ä»£ç ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to ICLR2026",
      "pdf_url": "https://arxiv.org/pdf/2602.15772v1",
      "published_date": "2026-02-17 18:04:13 UTC",
      "updated_date": "2026-02-17 18:04:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:32:14.835340+00:00"
    },
    {
      "arxiv_id": "2602.15767v1",
      "title": "Robot-Assisted Social Dining as a White Glove Service",
      "title_zh": "æœºå™¨äººè¾…åŠ©ç¤¾äº¤ç”¨é¤ï¼šç™½æ‰‹å¥—å¼æœåŠ¡",
      "authors": [
        "Atharva S Kashyap",
        "Ugne Aleksandra Morkute",
        "Patricia Alves-Oliveira"
      ],
      "abstract": "Robot-assisted feeding enables people with disabilities who require assistance eating to enjoy a meal independently and with dignity. However, existing systems have only been tested in-lab or in-home, leaving in-the-wild social dining contexts (e.g., restaurants) largely unexplored. Designing a robot for such contexts presents unique challenges, such as dynamic and unsupervised dining environments that a robot needs to account for and respond to. Through speculative participatory design with people with disabilities, supported by semi-structured interviews and a custom AI-based visual storyboarding tool, we uncovered ideal scenarios for in-the-wild social dining. Our key insight suggests that such systems should: embody the principles of a white glove service where the robot (1) supports multimodal inputs and unobtrusive outputs; (2) has contextually sensitive social behavior and prioritizes the user; (3) has expanded roles beyond feeding; (4) adapts to other relationships at the dining table. Our work has implications for in-the-wild and group contexts of robot-assisted feeding.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æœºå™¨äººè¾…åŠ©è¿›é£Ÿç³»ç»Ÿåœ¨é¤å…ç­‰ç¤¾äº¤ç”¨é¤åœºæ™¯ï¼ˆin-the-wild social diningï¼‰çš„åº”ç”¨ï¼Œæ—¨åœ¨è§£å†³æ®‹éšœäººå£«åœ¨åŠ¨æ€åŠéå—æ§ç¯å¢ƒä¸­çš„è‡ªä¸»ç”¨é¤æŒ‘æˆ˜ã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡ä¸æ®‹éšœäººå£«è¿›è¡Œæ¨æµ‹æ€§å‚ä¸å¼è®¾è®¡ï¼ˆspeculative participatory designï¼‰ï¼Œç»“åˆåŠç»“æ„åŒ–è®¿è°ˆï¼ˆsemi-structured interviewsï¼‰å’Œå®šåˆ¶åŒ–çš„AIè§†è§‰åˆ†é•œå·¥å…·ï¼ˆAI-based visual storyboarding toolï¼‰ï¼ŒæŒ–æ˜å¹¶å®šä¹‰äº†ç†æƒ³çš„ç¤¾äº¤ç”¨é¤åœºæ™¯ã€‚æ ¸å¿ƒå‘ç°æŒ‡å‡ºï¼Œè¿™ç±»ç³»ç»Ÿåº”ä½“ç°â€œç™½æ‰‹å¥—æœåŠ¡â€ï¼ˆwhite glove serviceï¼‰åŸåˆ™ï¼Œæ”¯æŒå¤šæ¨¡æ€è¾“å…¥ï¼ˆmultimodal inputsï¼‰å’Œéä¾µå…¥å¼è¾“å‡ºï¼ˆunobtrusive outputsï¼‰ï¼Œå¹¶å…·å¤‡ä¸Šä¸‹æ–‡æ•æ„Ÿçš„ç¤¾äº¤è¡Œä¸ºã€‚æ­¤å¤–ï¼Œæœºå™¨äººä¸ä»…éœ€è¦æ‰©å±•é™¤å–‚é£Ÿä»¥å¤–çš„åŠŸèƒ½è§’è‰²ï¼Œè¿˜éœ€é€‚åº”é¤æ¡Œä¸Šçš„å…¶ä»–ç¤¾äº¤å…³ç³»ï¼Œä»¥ç¡®ä¿ç”¨æˆ·åœ¨ç¾¤ä½“ç¯å¢ƒä¸­çš„å°Šä¸¥ä¸ç‹¬ç«‹ã€‚è¯¥å·¥ä½œä¸ºæœºå™¨äººåœ¨å¤æ‚ç¤¾äº¤èƒŒæ™¯ä¸‹çš„è¾…åŠ©è¿›é£ŸæŠ€æœ¯æä¾›äº†é‡è¦è§è§£ï¼Œå…·æœ‰æ·±è¿œçš„å®è·µæŒ‡å¯¼æ„ä¹‰ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.RO",
      "comment": "20 pages, 9 figures. Proceedings of the 2026 CHI Conference on Human Factors in Computing Systems (CHI '26)",
      "pdf_url": "https://arxiv.org/pdf/2602.15767v1",
      "published_date": "2026-02-17 17:58:25 UTC",
      "updated_date": "2026-02-17 17:58:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:32:50.636639+00:00"
    },
    {
      "arxiv_id": "2602.15758v1",
      "title": "ChartEditBench: Evaluating Grounded Multi-Turn Chart Editing in Multimodal Language Models",
      "title_zh": "ChartEditBenchï¼šè¯„ä¼°å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹ä¸­åŸºäºè§†è§‰åŸºå‡†çš„å¤šè½®å›¾è¡¨ç¼–è¾‘",
      "authors": [
        "Manav Nitin Kapadnis",
        "Lawanya Baghel",
        "Atharva Naik",
        "Carolyn RosÃ©"
      ],
      "abstract": "While Multimodal Large Language Models (MLLMs) perform strongly on single-turn chart generation, their ability to support real-world exploratory data analysis remains underexplored. In practice, users iteratively refine visualizations through multi-turn interactions that require maintaining common ground, tracking prior edits, and adapting to evolving preferences. We introduce ChartEditBench, a benchmark for incremental, visually grounded chart editing via code, comprising 5,000 difficulty-controlled modification chains and a rigorously human-verified subset. Unlike prior one-shot benchmarks, ChartEditBench evaluates sustained, context-aware editing. We further propose a robust evaluation framework that mitigates limitations of LLM-as-a-Judge metrics by integrating execution-based fidelity checks, pixel-level visual similarity, and logical code verification. Experiments with state-of-the-art MLLMs reveal substantial degradation in multi-turn settings due to error accumulation and breakdowns in shared context, with strong performance on stylistic edits but frequent execution failures on data-centric transformations. ChartEditBench, establishes a challenging testbed for grounded, intent-aware multimodal programming.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ (MLLMs) åœ¨å¤„ç†çœŸå®ä¸–ç•Œæ¢ç´¢æ€§æ•°æ®åˆ†ææ—¶çš„å±€é™æ€§ï¼Œæå‡ºäº† ChartEditBenchï¼Œä¸€ä¸ªä¸“é—¨ç”¨äºè¯„ä¼°å¢é‡å¼ã€è§†è§‰å¯¹é½ (Grounded) çš„å¤šè½® (Multi-Turn) å›¾è¡¨ç¼–è¾‘åŸºå‡†ã€‚è¯¥åŸºå‡†åŒ…å« 5,000 æ¡éš¾åº¦å¯æ§çš„ä¿®æ”¹é“¾ï¼Œå¹¶é…ä»¥ä¸¥æ ¼çš„äººå·¥éªŒè¯å­é›†ï¼Œå¡«è¡¥äº†ä»¥å¾€å•è½®ç”Ÿæˆè¯„ä¼°çš„ç©ºç™½ã€‚ä¸ºäº†æ›´å®¢è§‚åœ°è¡¡é‡æ€§èƒ½ï¼Œç ”ç©¶å›¢é˜Ÿè®¾è®¡äº†ä¸€å¥—ç»“åˆä»£ç æ‰§è¡Œä¿çœŸåº¦ã€åƒç´ çº§è§†è§‰ç›¸ä¼¼åº¦å’Œé€»è¾‘ä»£ç éªŒè¯çš„ç»¼åˆè¯„ä¼°æ¡†æ¶ï¼Œæœ‰æ•ˆç¼“è§£äº† LLM-as-a-Judge æŒ‡æ ‡çš„å±€é™æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œç”±äºé”™è¯¯ç§¯ç´¯å’Œå…±äº«ä¸Šä¸‹æ–‡çš„å´©æºƒï¼Œç°æœ‰æœ€å…ˆè¿›çš„ MLLMs åœ¨å¤šè½®ç¼–è¾‘ä¸­è¡¨ç°å‡ºæ˜¾è‘—çš„æ€§èƒ½é€€åŒ–ã€‚ç ”ç©¶å‘ç°æ¨¡å‹è™½ç„¶åœ¨é£æ ¼ä¿®æ”¹ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨æ¶‰åŠæ•°æ®ä¸­å¿ƒçš„è½¬æ¢ä»»åŠ¡æ—¶ç»å¸¸å‡ºç°æ‰§è¡Œå¤±è´¥ã€‚ChartEditBench ä¸ºå¤šæ¨¡æ€ç¼–ç¨‹é¢†åŸŸå»ºç«‹äº†ä¸€ä¸ªæå…·æŒ‘æˆ˜æ€§çš„æµ‹è¯•ç¯å¢ƒï¼Œæ—¨åœ¨æ¨åŠ¨æ›´å…·æ„å›¾æ„ŸçŸ¥çš„äº¤äº’å¼å¯è§†åŒ–æŠ€æœ¯å‘å±•ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages, 13 figures including Supplementary Material",
      "pdf_url": "https://arxiv.org/pdf/2602.15758v1",
      "published_date": "2026-02-17 17:45:34 UTC",
      "updated_date": "2026-02-17 17:45:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:33:04.246271+00:00"
    },
    {
      "arxiv_id": "2602.15757v1",
      "title": "Beyond Binary Classification: Detecting Fine-Grained Sexism in Social Media Videos",
      "title_zh": "è¶…è¶ŠäºŒå…ƒåˆ†ç±»ï¼šç¤¾äº¤åª’ä½“è§†é¢‘ä¸­çš„ç»†ç²’åº¦æ€§åˆ«æ­§è§†æ£€æµ‹",
      "authors": [
        "Laura De Grazia",
        "Danae SÃ¡nchez Villegas",
        "Desmond Elliott",
        "Mireia FarrÃºs",
        "Mariona TaulÃ©"
      ],
      "abstract": "Online sexism appears in various forms, which makes its detection challenging. Although automated tools can enhance the identification of sexist content, they are often restricted to binary classification. Consequently, more subtle manifestations of sexism may remain undetected due to the lack of fine-grained, context-sensitive labels. To address this issue, we make the following contributions: (1) we present FineMuSe, a new multimodal sexism detection dataset in Spanish that includes both binary and fine-grained annotations; (2) we introduce a comprehensive hierarchical taxonomy that encompasses forms of sexism, non-sexism, and rhetorical devices of irony and humor; and (3) we evaluate a wide range of LLMs for both binary and fine-grained sexism detection. Our findings indicate that multimodal LLMs perform competitively with human annotators in identifying nuanced forms of sexism; however, they struggle to capture co-occurring sexist types when these are conveyed through visual cues.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç¤¾äº¤åª’ä½“è§†é¢‘ä¸­æ€§åˆ«æ­§è§†(Sexism)å½¢å¼å¤šæ ·ä¸”è‡ªåŠ¨åŒ–æ£€æµ‹å·¥å…·é€šå¸¸å±€é™äºäºŒå…ƒåˆ†ç±»(Binary Classification)çš„é—®é¢˜ï¼Œæ—¨åœ¨å®ç°æ›´ç»†ç²’åº¦çš„å†…å®¹è¯†åˆ«ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†FineMuSeï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å«äºŒå…ƒå’Œç»†ç²’åº¦æ ‡æ³¨çš„è¥¿ç­ç‰™è¯­å¤šæ¨¡æ€æ€§åˆ«æ­§è§†æ£€æµ‹æ•°æ®é›†ã€‚è¯¥ç ”ç©¶è¿˜å¼•å…¥äº†ä¸€å¥—æ¶µç›–æ€§åˆ«æ­§è§†å½¢å¼ã€éæ­§è§†ä»¥åŠè®½åˆº(Irony)å’Œå¹½é»˜(Humor)ä¿®è¾æ‰‹æ®µçš„ç»¼åˆå±‚æ¬¡åŒ–åˆ†ç±»ä½“ç³»(Hierarchical Taxonomy)ï¼Œå¹¶è¯„ä¼°äº†å¤šç§å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨äºŒå…ƒåŠç»†ç²’åº¦æ£€æµ‹ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(Multimodal LLMs)åœ¨è¯†åˆ«ç»†å¾®æ€§åˆ«æ­§è§†å½¢å¼æ–¹é¢å…·æœ‰ä¸äººç±»æ ‡æ³¨å‘˜ç›¸å½“çš„ç«äº‰åŠ›ã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹åœ¨æ•æ‰é€šè¿‡è§†è§‰çº¿ç´¢ä¼ è¾¾çš„å¹¶å‘æ€§åˆ«æ­§è§†ç±»å‹(Co-occurring Sexist Types)æ—¶ä»å­˜åœ¨å›°éš¾ã€‚è¯¥ç ”ç©¶ä¸ºç¤¾äº¤åª’ä½“ä¸­å¤æ‚ç¤¾ä¼šåè§çš„è‡ªåŠ¨åŒ–æ²»ç†æä¾›äº†é‡è¦çš„æ•°æ®æ”¯æŒä¸åŸºå‡†å‚è€ƒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15757v1",
      "published_date": "2026-02-17 17:45:28 UTC",
      "updated_date": "2026-02-17 17:45:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:33:07.436362+00:00"
    },
    {
      "arxiv_id": "2602.15750v1",
      "title": "UrbanVerse: Learning Urban Region Representation Across Cities and Tasks",
      "title_zh": "UrbanVerseï¼šè·¨åŸå¸‚ä¸è·¨ä»»åŠ¡çš„åŸå¸‚åŒºåŸŸè¡¨ç¤ºå­¦ä¹ ",
      "authors": [
        "Fengze Sun",
        "Egemen Tanin",
        "Shanika Karunasekera",
        "Zuqing Li",
        "Flora D. Salim",
        "Jianzhong Qi"
      ],
      "abstract": "Recent advances in urban region representation learning have enabled a wide range of applications in urban analytics, yet existing methods remain limited in their capabilities to generalize across cities and analytic tasks. We aim to generalize urban representation learning beyond city- and task-specific settings, towards a foundation-style model for urban analytics. To this end, we propose UrbanVerse, a model for cross-city urban representation learning and cross-task urban analytics. For cross-city generalization, UrbanVerse focuses on features local to the target regions and structural features of the nearby regions rather than the entire city. We model regions as nodes on a graph, which enables a random walk-based procedure to form \"sequences of regions\" that reflect both local and neighborhood structural features for urban region representation learning. For cross-task generalization, we propose a cross-task learning module named HCondDiffCT. This module integrates region-conditioned prior knowledge and task-conditioned semantics into the diffusion process to jointly model multiple downstream urban prediction tasks. HCondDiffCT is generic. It can also be integrated with existing urban representation learning models to enhance their downstream task effectiveness. Experiments on real-world datasets show that UrbanVerse consistently outperforms state-of-the-art methods across six tasks under cross-city settings, achieving up to 35.89% improvements in prediction accuracy.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†UrbanVerseï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨è§£å†³ç°æœ‰åŸå¸‚åŒºåŸŸè¡¨ç¤ºå­¦ä¹ ï¼ˆUrban Region Representation Learningï¼‰æ¨¡å‹åœ¨è·¨åŸå¸‚å’Œè·¨ä»»åŠ¡æ³›åŒ–èƒ½åŠ›ä¸Šå—é™é—®é¢˜çš„åŸºåº§å¼æ¨¡å‹ã€‚ä¸ºäº†å®ç°è·¨åŸå¸‚æ³›åŒ–ï¼ˆCross-city generalizationï¼‰ï¼ŒUrbanVerseå°†åŸå¸‚åŒºåŸŸå»ºæ¨¡ä¸ºå›¾ï¼ˆGraphï¼‰èŠ‚ç‚¹ï¼Œå¹¶é‡‡ç”¨éšæœºæ¸¸èµ°ï¼ˆRandom Walkï¼‰ç”Ÿæˆçš„â€œåŒºåŸŸåºåˆ—â€æ¥æ•æ‰å±€éƒ¨åŠé‚»åŸŸçš„ç»“æ„åŒ–ç‰¹å¾ã€‚é’ˆå¯¹è·¨ä»»åŠ¡æ³›åŒ–ï¼ˆCross-task generalizationï¼‰ï¼Œç ”ç©¶å¼•å…¥äº†åä¸ºHCondDiffCTçš„é€šç”¨å­¦ä¹ æ¨¡å—ï¼Œè¯¥æ¨¡å—å°†åŒºåŸŸå…ˆéªŒçŸ¥è¯†å’Œä»»åŠ¡è¯­ä¹‰æ•´åˆè‡³æ‰©æ•£è¿‡ç¨‹ï¼ˆDiffusion processï¼‰ä¸­ï¼Œå®ç°äº†å¯¹å¤šä¸ªä¸‹æ¸¸é¢„æµ‹ä»»åŠ¡çš„è”åˆå»ºæ¨¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒUrbanVerseåœ¨è·¨åŸå¸‚è®¾ç½®ä¸‹çš„å…­é¡¹ä»»åŠ¡ä¸­æ€§èƒ½å‡ä¼˜äºç°æœ‰æœ€å…ˆè¿›æ–¹æ³•ï¼Œé¢„æµ‹å‡†ç¡®ç‡æœ€é«˜æå‡äº†35.89%ã€‚è¯¥å·¥ä½œé€šè¿‡èšç„¦å±€éƒ¨ä¸ç»“æ„ç‰¹å¾ä»¥åŠé€šç”¨çš„ä»»åŠ¡å¢å¼ºæ¨¡å—ï¼Œä¸ºåŸå¸‚åˆ†æé¢†åŸŸçš„å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹æä¾›äº†æœ‰æ•ˆæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15750v1",
      "published_date": "2026-02-17 17:28:48 UTC",
      "updated_date": "2026-02-17 17:28:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:33:19.043236+00:00"
    },
    {
      "arxiv_id": "2602.15740v1",
      "title": "MRC-GAT: A Meta-Relational Copula-Based Graph Attention Network for Interpretable Multimodal Alzheimer's Disease Diagnosis",
      "title_zh": "MRC-GATï¼šç”¨äºå¯è§£é‡Šå¤šæ¨¡æ€é˜¿å°”èŒ¨æµ·é»˜ç—…è¯Šæ–­çš„å…ƒå…³ç³» Copula å›¾æ³¨æ„åŠ›ç½‘ç»œ",
      "authors": [
        "Fatemeh Khalvandi",
        "Saadat Izadi",
        "Abdolah Chalechale"
      ],
      "abstract": "Alzheimer's disease (AD) is a progressive neurodegenerative condition necessitating early and precise diagnosis to provide prompt clinical management. Given the paramount importance of early diagnosis, recent studies have increasingly focused on computer-aided diagnostic models to enhance precision and reliability. However, most graph-based approaches still rely on fixed structural designs, which restrict their flexibility and limit generalization across heterogeneous patient data. To overcome these limitations, the Meta-Relational Copula-Based Graph Attention Network (MRC-GAT) is proposed as an efficient multimodal model for AD classification tasks. The proposed architecture, copula-based similarity alignment, relational attention, and node fusion are integrated as the core components of episodic meta-learning, such that the multimodal features, including risk factors (RF), Cognitive test scores, and MRI attributes, are first aligned via a copula-based transformation in a common statistical space and then combined by a multi-relational attention mechanism. According to evaluations performed on the TADPOLE and NACC datasets, the MRC-GAT model achieved accuracies of 96.87% and 92.31%, respectively, demonstrating state-of-the-art performance compared to existing diagnostic models. Finally, the proposed model confirms the robustness and applicability of the proposed method by providing interpretability at various stages of disease diagnosis.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†MRC-GATï¼Œä¸€ç§åŸºäºå…ƒå…³ç³»Copulaçš„å›¾æ³¨æ„åŠ›ç½‘ç»œï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿå›¾ç¥ç»ç½‘ç»œåœ¨é˜¿å°”èŒ¨æµ·é»˜ç—‡(AD)è¯Šæ–­ä¸­å› å›ºå®šç»“æ„è®¾è®¡å¯¼è‡´çš„çµæ´»æ€§ä¸è¶³å’Œæ³›åŒ–èƒ½åŠ›å—é™é—®é¢˜ã€‚è¯¥æ¡†æ¶å°†Copulaç›¸ä¼¼æ€§å¯¹é½ã€å…³ç³»æ³¨æ„åŠ›æœºåˆ¶å’ŒèŠ‚ç‚¹èåˆé›†æˆåˆ°æƒ…èŠ‚å¼å…ƒå­¦ä¹ (Episodic meta-learning)ä¸­ï¼Œé€šè¿‡Copulaå˜æ¢åœ¨å…¬å…±ç»Ÿè®¡ç©ºé—´å†…å¯¹é½é£é™©å› ç´ (RF)ã€è®¤çŸ¥æµ‹è¯•è¯„åˆ†åŠMRIå±æ€§ç­‰å¤šç§æ¨¡æ€ç‰¹å¾ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMRC-GATåœ¨TADPOLEå’ŒNACCæ•°æ®é›†ä¸Šåˆ†åˆ«å®ç°äº†96.87%å’Œ92.31%çš„è¯Šæ–­å‡†ç¡®ç‡ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰çš„å…ˆè¿›æ¨¡å‹ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹é€šè¿‡åœ¨ç–¾ç—…è¯Šæ–­çš„å„ä¸ªé˜¶æ®µæä¾›å¯è§£é‡Šæ€§ï¼Œè¿›ä¸€æ­¥éªŒè¯äº†å…¶åœ¨ä¸´åºŠåº”ç”¨ä¸­çš„é²æ£’æ€§ä¸å®ç”¨ä»·å€¼ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "27 pages, 10 figures, 10 table",
      "pdf_url": "https://arxiv.org/pdf/2602.15740v1",
      "published_date": "2026-02-17 17:15:32 UTC",
      "updated_date": "2026-02-17 17:15:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:33:21.842241+00:00"
    },
    {
      "arxiv_id": "2602.15733v1",
      "title": "MeshMimic: Geometry-Aware Humanoid Motion Learning through 3D Scene Reconstruction",
      "title_zh": "MeshMimicï¼šåŸºäºä¸‰ç»´åœºæ™¯é‡å»ºçš„å‡ ä½•æ„ŸçŸ¥ç±»äººæœºå™¨äººè¿åŠ¨å­¦ä¹ ",
      "authors": [
        "Qiang Zhang",
        "Jiahao Ma",
        "Peiran Liu",
        "Shuai Shi",
        "Zeran Su",
        "Zifan Wang",
        "Jingkai Sun",
        "Wei Cui",
        "Jialin Yu",
        "Gang Han",
        "Wen Zhao",
        "Pihai Sun",
        "Kangning Yin",
        "Jiaxu Wang",
        "Jiahang Cao",
        "Lingfeng Zhang",
        "Hao Cheng",
        "Xiaoshuai Hao",
        "Yiding Ji",
        "Junwei Liang",
        "Jian Tang",
        "Renjing Xu",
        "Yijie Guo"
      ],
      "abstract": "Humanoid motion control has witnessed significant breakthroughs in recent years, with deep reinforcement learning (RL) emerging as a primary catalyst for achieving complex, human-like behaviors. However, the high dimensionality and intricate dynamics of humanoid robots make manual motion design impractical, leading to a heavy reliance on expensive motion capture (MoCap) data. These datasets are not only costly to acquire but also frequently lack the necessary geometric context of the surrounding physical environment. Consequently, existing motion synthesis frameworks often suffer from a decoupling of motion and scene, resulting in physical inconsistencies such as contact slippage or mesh penetration during terrain-aware tasks. In this work, we present MeshMimic, an innovative framework that bridges 3D scene reconstruction and embodied intelligence to enable humanoid robots to learn coupled \"motion-terrain\" interactions directly from video. By leveraging state-of-the-art 3D vision models, our framework precisely segments and reconstructs both human trajectories and the underlying 3D geometry of terrains and objects. We introduce an optimization algorithm based on kinematic consistency to extract high-quality motion data from noisy visual reconstructions, alongside a contact-invariant retargeting method that transfers human-environment interaction features to the humanoid agent. Experimental results demonstrate that MeshMimic achieves robust, highly dynamic performance across diverse and challenging terrains. Our approach proves that a low-cost pipeline utilizing only consumer-grade monocular sensors can facilitate the training of complex physical interactions, offering a scalable path toward the autonomous evolution of humanoid robots in unstructured environments.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†MeshMimicæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç±»äººæœºå™¨äººè¿åŠ¨å­¦ä¹ ä¸­è¿åŠ¨ä¸åœºæ™¯è„±èŠ‚å¯¼è‡´çš„ç‰©ç†ä¸ä¸€è‡´æ€§ï¼ˆå¦‚æ¥è§¦æ»‘åŠ¨æˆ–æ¨¡å‹ç©¿æ’ï¼‰é—®é¢˜ã€‚è¯¥æ¡†æ¶é€šè¿‡å°†3Dåœºæ™¯é‡å»ºä¸å…·èº«æ™ºèƒ½ï¼ˆEmbodied Intelligenceï¼‰ç›¸ç»“åˆï¼Œä½¿æœºå™¨äººèƒ½å¤Ÿç›´æ¥ä»è§†é¢‘ä¸­å­¦ä¹ è€¦åˆçš„â€œè¿åŠ¨-åœ°å½¢â€äº¤äº’ã€‚åˆ©ç”¨å…ˆè¿›çš„3Dè§†è§‰æ¨¡å‹ï¼ŒMeshMimicèƒ½å¤Ÿç²¾ç¡®åˆ†å‰²å¹¶é‡å»ºäººç±»è¿åŠ¨è½¨è¿¹ä»¥åŠåœ°å½¢å’Œç‰©ä½“çš„3Då‡ ä½•ç»“æ„ã€‚ç ”ç©¶å›¢é˜Ÿå¼•å…¥äº†ä¸€ç§åŸºäºè¿åŠ¨å­¦ä¸€è‡´æ€§ï¼ˆKinematic Consistencyï¼‰çš„ä¼˜åŒ–ç®—æ³•ï¼Œç”¨äºä»å™ªå£°è¾ƒå¤§çš„è§†è§‰é‡å»ºä¸­æå–é«˜è´¨é‡è¿åŠ¨æ•°æ®ï¼Œå¹¶é‡‡ç”¨æ¥è§¦ä¸å˜é‡å®šå‘ï¼ˆContact-Invariant Retargetingï¼‰æ–¹æ³•å°†äº¤äº’ç‰¹å¾æœ‰æ•ˆè½¬ç§»è‡³æœºå™¨äººã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMeshMimicåœ¨å¤šç§å¤æ‚åœ°å½¢ä¸Šå®ç°äº†ç¨³å¥ä¸”é«˜åŠ¨æ€çš„æ€§èƒ½è¡¨ç°ã€‚è¯¥ç ”ç©¶è¯æ˜äº†ä»…ä½¿ç”¨æ¶ˆè´¹çº§å•ç›®ä¼ æ„Ÿå™¨å³å¯è®­ç»ƒå¤æ‚çš„ç‰©ç†äº¤äº’ï¼Œä¸ºéç»“æ„åŒ–ç¯å¢ƒä¸‹ç±»äººæœºå™¨äººçš„è‡ªä¸»è¿›åŒ–æä¾›äº†ä¸€æ¡é«˜æ•ˆä¸”å¯æ‰©å±•çš„è·¯å¾„ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "17 pages, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.15733v1",
      "published_date": "2026-02-17 17:09:45 UTC",
      "updated_date": "2026-02-17 17:09:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:33:42.338163+00:00"
    },
    {
      "arxiv_id": "2602.15727v1",
      "title": "Spanning the Visual Analogy Space with a Weight Basis of LoRAs",
      "title_zh": "åŸºäº LoRA æƒé‡åŸºå¼ æˆè§†è§‰ç±»æ¯”ç©ºé—´",
      "authors": [
        "Hila Manor",
        "Rinon Gal",
        "Haggai Maron",
        "Tomer Michaeli",
        "Gal Chechik"
      ],
      "abstract": "Visual analogy learning enables image manipulation through demonstration rather than textual description, allowing users to specify complex transformations difficult to articulate in words. Given a triplet $\\{\\mathbf{a}$, $\\mathbf{a}'$, $\\mathbf{b}\\}$, the goal is to generate $\\mathbf{b}'$ such that $\\mathbf{a} : \\mathbf{a}' :: \\mathbf{b} : \\mathbf{b}'$. Recent methods adapt text-to-image models to this task using a single Low-Rank Adaptation (LoRA) module, but they face a fundamental limitation: attempting to capture the diverse space of visual transformations within a fixed adaptation module constrains generalization capabilities. Inspired by recent work showing that LoRAs in constrained domains span meaningful, interpolatable semantic spaces, we propose LoRWeB, a novel approach that specializes the model for each analogy task at inference time through dynamic composition of learned transformation primitives, informally, choosing a point in a \"space of LoRAs\". We introduce two key components: (1) a learnable basis of LoRA modules, to span the space of different visual transformations, and (2) a lightweight encoder that dynamically selects and weighs these basis LoRAs based on the input analogy pair. Comprehensive evaluations demonstrate our approach achieves state-of-the-art performance and significantly improves generalization to unseen visual transformations. Our findings suggest that LoRA basis decompositions are a promising direction for flexible visual manipulation. Code and data are in https://research.nvidia.com/labs/par/lorweb",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è§†è§‰ç±»æ¯”å­¦ä¹ (Visual analogy learning)ä¸­å•ä¸€Low-Rank Adaptation (LoRA)æ¨¡å—éš¾ä»¥æ•æ‰å¤šæ ·åŒ–è§†è§‰å˜æ¢å¹¶é™åˆ¶æ³›åŒ–èƒ½åŠ›çš„é—®é¢˜ï¼Œæå‡ºäº†LoRWeBæ¡†æ¶ã€‚LoRWeBé€šè¿‡åœ¨æ¨ç†é˜¶æ®µåŠ¨æ€ç»„åˆå­¦ä¹ åˆ°çš„å˜æ¢åŸè¯­ï¼Œå®ç°äº†æ¨¡å‹å¯¹æ¯ä¸ªç±»æ¯”ä»»åŠ¡çš„ç‰¹åŒ–ã€‚è¯¥æ–¹æ³•å¼•å…¥äº†ä¸¤ä¸ªæ ¸å¿ƒç»„ä»¶ï¼šä¸€ä¸ªç”¨äºè·¨è¶Šä¸åŒè§†è§‰å˜æ¢ç©ºé—´çš„LoRAæ¨¡å—å¯å­¦ä¹ åŸº(learnable basis)ï¼Œä»¥åŠä¸€ä¸ªæ ¹æ®è¾“å…¥ç±»æ¯”å¯¹åŠ¨æ€é€‰æ‹©å¹¶åŠ æƒè¿™äº›åŸºLoRAsçš„è½»é‡çº§ç¼–ç å™¨ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨è§†è§‰ç±»æ¯”ä»»åŠ¡ä¸Šå–å¾—äº†SOTAæ€§èƒ½ï¼Œå¹¶æ˜¾è‘—å¢å¼ºäº†å¯¹æœªè§è§†è§‰å˜æ¢çš„æ³›åŒ–èƒ½åŠ›ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼ŒLoRAåŸºåˆ†è§£(LoRA basis decompositions)ä¸ºå®ç°çµæ´»çš„å›¾åƒè§†è§‰æ“ä½œæä¾›äº†ä¸€ä¸ªæå…·æ½œåŠ›çš„æ–¹å‘ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "Code and data are in https://research.nvidia.com/labs/par/lorweb",
      "pdf_url": "https://arxiv.org/pdf/2602.15727v1",
      "published_date": "2026-02-17 17:02:38 UTC",
      "updated_date": "2026-02-17 17:02:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:33:47.438917+00:00"
    },
    {
      "arxiv_id": "2602.15725v1",
      "title": "Recursive Concept Evolution for Compositional Reasoning in Large Language Models",
      "title_zh": "Recursive Concept Evolutionï¼šé¢å‘å¤§è¯­è¨€æ¨¡å‹ç»„åˆæ¨ç†çš„é€’å½’æ¦‚å¿µæ¼”åŒ–",
      "authors": [
        "Sarim Chaudhry"
      ],
      "abstract": "Large language models achieve strong performance on many complex reasoning tasks, yet their accuracy degrades sharply on benchmarks that require compositional reasoning, including ARC-AGI-2, GPQA, MATH, BBH, and HLE. Existing methods improve reasoning by expanding token-level search through chain-of-thought prompting, self-consistency, or reinforcement learning, but they leave the model's latent representation space fixed. When the required abstraction is not already encoded in this space, performance collapses. We propose Recursive Concept Evolution (RCE), a framework that enables pretrained language models to modify their internal representation geometry during inference. RCE introduces dynamically generated low-rank concept subspaces that are spawned when representational inadequacy is detected, selected through a minimum description length criterion, merged when synergistic, and consolidated via constrained optimization to preserve stability. This process allows the model to construct new abstractions rather than recombining existing ones. We integrate RCE with Mistral-7B and evaluate it across compositional reasoning benchmarks. RCE yields 12-18 point gains on ARC-AGI-2, 8-14 point improvements on GPQA and BBH, and consistent reductions in depth-induced error on MATH and HLE.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤„ç†éœ€è¦ç»„åˆæ¨ç†ï¼ˆcompositional reasoningï¼‰çš„å¤æ‚ä»»åŠ¡æ—¶ï¼Œå› æ½œè¡¨ç¤ºç©ºé—´ï¼ˆlatent representation spaceï¼‰å›ºå®šè€Œå¯¼è‡´æ€§èƒ½å¤§å¹…ä¸‹é™çš„é—®é¢˜ï¼Œæå‡ºäº†é€’å½’æ¦‚å¿µæ¼”åŒ–ï¼ˆRecursive Concept Evolutionï¼Œç®€ç§° RCEï¼‰æ¡†æ¶ã€‚RCE å…è®¸æ¨¡å‹åœ¨æ¨ç†é˜¶æ®µåŠ¨æ€ä¿®æ”¹å…¶å†…éƒ¨è¡¨ç¤ºçš„å‡ ä½•ç»“æ„ï¼Œé€šè¿‡åœ¨æ£€æµ‹åˆ°è¡¨ç¤ºä¸è¶³æ—¶ç”Ÿæˆä½ç§©æ¦‚å¿µå­ç©ºé—´ï¼ˆlow-rank concept subspacesï¼‰ï¼Œå¹¶ä¾æ®æœ€å°æè¿°é•¿åº¦ï¼ˆMinimum Description Lengthï¼‰å‡†åˆ™è¿›è¡Œç­›é€‰å’Œåˆå¹¶ã€‚è¯¥è¿‡ç¨‹åˆ©ç”¨çº¦æŸä¼˜åŒ–ï¼ˆconstrained optimizationï¼‰æŠ€æœ¯ç¡®ä¿äº†æ¨¡å‹çš„ç¨³å®šæ€§ï¼Œä½¿å…¶èƒ½å¤Ÿæ„å»ºå…¨æ–°çš„æŠ½è±¡æ¦‚å¿µè€Œéä»…ä»…é‡æ–°ç»„åˆç°æœ‰è¡¨ç¤ºã€‚å®éªŒé€šè¿‡å°† RCE é›†æˆè‡³ Mistral-7B æ¨¡å‹ï¼Œåœ¨ ARC-AGI-2 åŸºå‡†ä¸Šå®ç°äº† 12-18 ä¸ªç™¾åˆ†ç‚¹çš„æå‡ï¼Œåœ¨ GPQA å’Œ BBH ä¸Šä¹Ÿè·å¾—äº† 8-14 ä¸ªç™¾åˆ†ç‚¹çš„è¿›æ­¥ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜æ˜¾è‘—é™ä½äº† MATH å’Œ HLE ä»»åŠ¡ä¸­å› æ¨ç†æ·±åº¦å¢åŠ è€Œäº§ç”Ÿçš„è¯¯å·®ï¼Œè¯æ˜äº†å…¶åœ¨å¢å¼ºæ¨¡å‹æŠ½è±¡èƒ½åŠ›å’Œå¤„ç†å¤æ‚ç»„åˆæ¨ç†ä»»åŠ¡æ–¹é¢çš„æ˜¾è‘—ä¼˜åŠ¿ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15725v1",
      "published_date": "2026-02-17 17:01:42 UTC",
      "updated_date": "2026-02-17 17:01:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:33:47.838047+00:00"
    },
    {
      "arxiv_id": "2602.15724v1",
      "title": "Learning to Retrieve Navigable Candidates for Efficient Vision-and-Language Navigation",
      "title_zh": "é¢å‘é«˜æ•ˆè§†è§‰è¯­è¨€å¯¼èˆªçš„å¯å¯¼èˆªå€™é€‰è·¯å¾„å­¦ä¹ æ£€ç´¢",
      "authors": [
        "Shutian Gu",
        "Chengkai Huang",
        "Ruoyu Wang",
        "Lina Yao"
      ],
      "abstract": "Vision-and-Language Navigation (VLN) requires an agent to follow natural-language instructions and navigate through previously unseen environments. Recent approaches increasingly employ large language models (LLMs) as high-level navigators due to their flexibility and reasoning capability. However, prompt-based LLM navigation often suffers from inefficient decision-making, as the model must repeatedly interpret instructions from scratch and reason over noisy and verbose navigable candidates at each step. In this paper, we propose a retrieval-augmented framework to improve the efficiency and stability of LLM-based VLN without modifying or fine-tuning the underlying language model. Our approach introduces retrieval at two complementary levels. At the episode level, an instruction-level embedding retriever selects semantically similar successful navigation trajectories as in-context exemplars, providing task-specific priors for instruction grounding. At the step level, an imitation-learned candidate retriever prunes irrelevant navigable directions before LLM inference, reducing action ambiguity and prompt complexity. Both retrieval modules are lightweight, modular, and trained independently of the LLM. We evaluate our method on the Room-to-Room (R2R) benchmark. Experimental results demonstrate consistent improvements in Success Rate, Oracle Success Rate, and SPL on both seen and unseen environments. Ablation studies further show that instruction-level exemplar retrieval and candidate pruning contribute complementary benefits to global guidance and step-wise decision efficiency. These results indicate that retrieval-augmented decision support is an effective and scalable strategy for enhancing LLM-based vision-and-language navigation.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Vision-and-Language Navigation (VLN) ä¸­ LLM å†³ç­–æ•ˆç‡ä½ä¸”å€™é€‰è·¯å¾„å†—ä½™çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ— éœ€å¾®è°ƒæ¨¡å‹çš„æ£€ç´¢å¢å¼ºæ¡†æ¶ã€‚è¯¥æ¡†æ¶åœ¨ä¸¤ä¸ªäº’è¡¥å±‚é¢å¼•å…¥æ£€ç´¢æœºåˆ¶ï¼šåœ¨ Episode å±‚é¢ï¼Œé€šè¿‡æŒ‡ä»¤çº§åµŒå…¥æ£€ç´¢å™¨é€‰å–è¯­ä¹‰ç›¸ä¼¼çš„æˆåŠŸè·¯å¾„ä½œä¸º in-context exemplarsï¼Œä¸ºæŒ‡ä»¤è½åœ°æä¾›ç‰¹å®šä»»åŠ¡å…ˆéªŒï¼›åœ¨ Step å±‚é¢ï¼Œåˆ©ç”¨æ¨¡ä»¿å­¦ä¹ çš„å€™é€‰æ£€ç´¢å™¨åœ¨æ¨ç†å‰å‰”é™¤æ— å…³å¯¼èˆªæ–¹å‘ã€‚è¿™ä¸¤ä¸ªæ¨¡å—å‡å…·æœ‰è½»é‡åŒ–å’Œæ¨¡å—åŒ–çš„ç‰¹ç‚¹ï¼Œä¸”ç‹¬ç«‹äº LLM è¿›è¡Œè®­ç»ƒï¼Œæœ‰æ•ˆé™ä½äº†åŠ¨ä½œæ­§ä¹‰æ€§å’Œ Prompt å¤æ‚åº¦ã€‚å®éªŒåœ¨ Room-to-Room (R2R) åŸºå‡†æµ‹è¯•ä¸­å±•å¼€ï¼Œç»“æœæ˜¾ç¤ºè¯¥æ–¹æ³•åœ¨å·²çŸ¥å’ŒæœªçŸ¥ç¯å¢ƒä¸­å‡æ˜¾è‘—æå‡äº† Success Rateã€Oracle Success Rate å’Œ SPLã€‚æ¶ˆèç ”ç©¶è¿›ä¸€æ­¥è¯å®ï¼ŒæŒ‡ä»¤çº§ç¤ºä¾‹æ£€ç´¢ä¸å€™é€‰è·¯å¾„å‰ªæåœ¨å…¨å±€å¼•å¯¼å’Œå•æ­¥å†³ç­–æ•ˆç‡ä¸Šå…·æœ‰äº’è¡¥ä¼˜åŠ¿ã€‚è¯¥ç»“æœè¡¨æ˜æ£€ç´¢å¢å¼ºå†³ç­–æ”¯æŒæ˜¯æå‡åŸºäº LLM çš„è§†è§‰è¯­è¨€å¯¼èˆªèƒ½åŠ›çš„ä¸€ç§æœ‰æ•ˆä¸”å¯æ‰©å±•çš„ç­–ç•¥ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15724v1",
      "published_date": "2026-02-17 17:00:11 UTC",
      "updated_date": "2026-02-17 17:00:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:33:54.435828+00:00"
    },
    {
      "arxiv_id": "2602.15721v1",
      "title": "Lifelong Scalable Multi-Agent Realistic Testbed and A Comprehensive Study on Design Choices in Lifelong AGV Fleet Management Systems",
      "title_zh": "ç»ˆèº«å¼å¯æ‰©å±•å¤šæ™ºèƒ½ä½“é«˜ä¿çœŸæµ‹è¯•å¹³å°åŠç»ˆèº«å¼ AGV è½¦é˜Ÿç®¡ç†ç³»ç»Ÿè®¾è®¡å†³ç­–çš„å…¨é¢ç ”ç©¶",
      "authors": [
        "Jingtian Yan",
        "Yulun Zhang",
        "Zhenting Liu",
        "Han Zhang",
        "He Jiang",
        "Jingkai Chen",
        "Stephen F. Smith",
        "Jiaoyang Li"
      ],
      "abstract": "We present Lifelong Scalable Multi-Agent Realistic Testbed (LSMART), an open-source simulator to evaluate any Multi-Agent Path Finding (MAPF) algorithm in a Fleet Management System (FMS) with Automated Guided Vehicles (AGVs). MAPF aims to move a group of agents from their corresponding starting locations to their goals. Lifelong MAPF (LMAPF) is a variant of MAPF that continuously assigns new goals for agents to reach. LMAPF applications, such as autonomous warehouses, often require a centralized, lifelong system to coordinate the movement of a fleet of robots, typically AGVs. However, existing works on MAPF and LMAPF often assume simplified kinodynamic models, such as pebble motion, as well as perfect execution and communication for AGVs. Prior work has presented SMART, a software capable of evaluating any MAPF algorithms while considering agent kinodynamics, communication delays, and execution uncertainties. However, SMART is designed for MAPF, not LMAPF. Generalizing SMART to an FMS requires many more design choices. First, an FMS parallelizes planning and execution, raising the question of when to plan. Second, given planners with varying optimality and differing agent-model assumptions, one must decide how to plan. Third, when the planner fails to return valid solutions, the system must determine how to recover. In this paper, we first present LSMART, an open-source simulator that incorporates all these considerations to evaluate any MAPF algorithms in an FMS. We then provide experiment results based on state-of-the-art methods for each design choice, offering guidance on how to effectively design centralized lifelong AGV Fleet Management Systems. LSMART is available at https://smart-mapf.github.io/lifelong-smart.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† Lifelong Scalable Multi-Agent Realistic Testbed (LSMART)ï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨è¯„ä¼°è‡ªåŠ¨å¼•å¯¼è½¦ (AGV) è½¦é˜Ÿç®¡ç†ç³»ç»Ÿ (FMS) ä¸­å¤šæ™ºèƒ½ä½“è·¯å¾„è§„åˆ’ (MAPF) ç®—æ³•çš„å¼€æºæ¨¡æ‹Ÿå™¨ã€‚ç°æœ‰çš„ Lifelong MAPF (LMAPF) ç ”ç©¶å¾€å¾€å‡è®¾ç®€åŒ–çš„åŠ¨åŠ›å­¦æ¨¡å‹å¹¶å¿½ç•¥æ‰§è¡Œæˆ–é€šä¿¡çš„ä¸ç¡®å®šæ€§ï¼Œè€Œ LSMART é€šè¿‡æ•´åˆæ™ºèƒ½ä½“åŠ¨åŠ›å­¦ (Kinodynamics)ã€é€šä¿¡å»¶è¿Ÿå’Œæ‰§è¡Œä¸ç¡®å®šæ€§ï¼Œæä¾›äº†ä¸€ä¸ªæ›´åŠ çœŸå®çš„æµ‹è¯•ç¯å¢ƒã€‚è¯¥æ¡†æ¶ç³»ç»Ÿåœ°æ¢è®¨äº†è½¦é˜Ÿç®¡ç†ç³»ç»Ÿä¸­çš„æ ¸å¿ƒè®¾è®¡å†³ç­–ï¼ŒåŒ…æ‹¬å¹¶è¡Œè§„åˆ’ä¸æ‰§è¡Œçš„è°ƒåº¦æ—¶æœºã€è§„åˆ’å™¨ç®—æ³•çš„é€‰æ‹©ä»¥åŠç³»ç»Ÿæ•…éšœåçš„æ¢å¤æœºåˆ¶ã€‚é€šè¿‡å¯¹å¤šç§æœ€å…ˆè¿›æ–¹æ³•çš„å¯¹æ¯”å®éªŒï¼Œç ”ç©¶å›¢é˜Ÿä¸ºæ„å»ºé«˜æ•ˆä¸”å¯æ‰©å±•çš„ä¸­å¿ƒåŒ–ç»ˆèº«åˆ¶ AGV è½¦é˜Ÿç®¡ç†ç³»ç»Ÿæä¾›äº†é‡è¦çš„è®¾è®¡å‡†åˆ™å’Œå®è·µæŒ‡å¯¼ã€‚ç›®å‰è¯¥æ¨¡æ‹Ÿå™¨å·²å¼€æºï¼Œä¸ºå­¦æœ¯ç•Œå’Œå·¥ä¸šç•Œè¯„ä¼°å¤æ‚çš„è·¯å¾„è§„åˆ’ç®—æ³•æä¾›äº†æœ‰åŠ›çš„å·¥å…·æ”¯æŒã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15721v1",
      "published_date": "2026-02-17 16:53:20 UTC",
      "updated_date": "2026-02-17 16:53:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:33:55.356167+00:00"
    },
    {
      "arxiv_id": "2602.15712v1",
      "title": "Criteria-first, semantics-later: reproducible structure discovery in image-based sciences",
      "title_zh": "å‡†åˆ™ä¼˜å…ˆï¼Œè¯­ä¹‰åœ¨åï¼šå›¾åƒç§‘å­¦ä¸­å¯é‡å¤çš„ç»“æ„å‘ç°",
      "authors": [
        "Jan Bumberger"
      ],
      "abstract": "Across the natural and life sciences, images have become a primary measurement modality, yet the dominant analytic paradigm remains semantics-first. Structure is recovered by predicting or enforcing domain-specific labels. This paradigm fails systematically under the conditions that make image-based science most valuable, including open-ended scientific discovery, cross-sensor and cross-site comparability, and long-term monitoring in which domain ontologies and associated label sets drift culturally, institutionally, and ecologically. A deductive inversion is proposed in the form of criteria-first and semantics-later. A unified framework for criteria-first structure discovery is introduced. It separates criterion-defined, semantics-free structure extraction from downstream semantic mapping into domain ontologies or vocabularies and provides a domain-general scaffold for reproducible analysis across image-based sciences. Reproducible science requires that the first analytic layer perform criterion-driven, semantics-free structure discovery, yielding stable partitions, structural fields, or hierarchies defined by explicit optimality criteria rather than local domain ontologies. Semantics is not discarded; it is relocated downstream as an explicit mapping from the discovered structural product to a domain ontology or vocabulary, enabling plural interpretations and explicit crosswalks without rewriting upstream extraction. Grounded in cybernetics, observation-as-distinction, and information theory's separation of information from meaning, the argument is supported by cross-domain evidence showing that criteria-first components recur whenever labels do not scale. Finally, consequences are outlined for validation beyond class accuracy and for treating structural products as FAIR, AI-ready digital objects for long-term monitoring and digital twins.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è‡ªç„¶ç§‘å­¦å’Œç”Ÿå‘½ç§‘å­¦ä¸­å›¾åƒåˆ†æç°æœ‰çš„â€œè¯­ä¹‰ä¼˜å…ˆâ€(semantics-first)èŒƒå¼åœ¨å¼€æ”¾å¼ç§‘å­¦å‘ç°å’Œé•¿æœŸç›‘æµ‹ä¸­çš„å±€é™æ€§ï¼Œæå‡ºäº†â€œæ ‡å‡†ä¼˜å…ˆï¼Œè¯­ä¹‰éšåâ€(criteria-first, semantics-later)çš„æ¨å¯¼åè½¬ã€‚ç ”ç©¶å¼•å…¥äº†ä¸€ä¸ªç»Ÿä¸€çš„ç»“æ„å‘ç°æ¡†æ¶ï¼Œå°†å®šä¹‰æ ‡å‡†ã€æ— è¯­ä¹‰çš„ç»“æ„æå–ä¸ä¸‹æ¸¸çš„é¢†åŸŸæœ¬ä½“(domain ontologies)è¯­ä¹‰æ˜ å°„åˆ†ç¦»å¼€æ¥ã€‚è¯¥æ¡†æ¶å¼ºè°ƒç¬¬ä¸€å±‚åˆ†æåº”æ‰§è¡Œæ ‡å‡†é©±åŠ¨çš„ç»“æ„å‘ç°ï¼Œäº§ç”Ÿç”±æ˜¾å¼ä¼˜åŒ–æ ‡å‡†å®šä¹‰çš„ç¨³å®šåˆ†åŒºæˆ–å±‚çº§ï¼Œä»è€Œç¡®ä¿ç§‘å­¦çš„å¯é‡å¤æ€§(reproducible science)ã€‚è¯­ä¹‰è¢«é‡æ–°å®šä½ä¸ºä»å‘ç°çš„ç»“æ„äº§å“åˆ°é¢†åŸŸè¯æ±‡çš„æ˜¾å¼æ˜ å°„ï¼Œæ”¯æŒå¤šå…ƒè§£é‡Šè€Œæ— éœ€é‡å†™ä¸Šæ¸¸æå–ã€‚è¯¥è®ºç‚¹æ ¹æ¤äºæ§åˆ¶è®º(cybernetics)å’Œä¿¡æ¯è®º(information theory)ä¸­ä¿¡æ¯ä¸æ„ä¹‰çš„åˆ†ç¦»ï¼Œå¹¶å¾—åˆ°äº†è·¨é¢†åŸŸè¯æ®çš„æ”¯æŒã€‚æœ€åï¼Œè®ºæ–‡æ¢è®¨äº†éªŒè¯æ–¹æ³•ä»¥åŠå°†ç»“æ„äº§å“è§†ä¸ºé•¿æœŸç›‘æµ‹å’Œæ•°å­—å­ªç”Ÿ(digital twins)ä¸­ç¬¦åˆFAIRåŸåˆ™ã€AIå°±ç»ªæ•°å­—å¯¹è±¡çš„æ„ä¹‰ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15712v1",
      "published_date": "2026-02-17 16:45:49 UTC",
      "updated_date": "2026-02-17 16:45:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:34:16.843146+00:00"
    },
    {
      "arxiv_id": "2602.15711v1",
      "title": "Random Wavelet Features for Graph Kernel Machines",
      "title_zh": "å›¾æ ¸æœºå™¨çš„éšæœºå°æ³¢ç‰¹å¾",
      "authors": [
        "Valentin de Bassompierre",
        "Jean-Charles Delvenne",
        "Laurent Jacques"
      ],
      "abstract": "Node embeddings map graph vertices into low-dimensional Euclidean spaces while preserving structural information. They are central to tasks such as node classification, link prediction, and signal reconstruction. A key goal is to design node embeddings whose dot products capture meaningful notions of node similarity induced by the graph. Graph kernels offer a principled way to define such similarities, but their direct computation is often prohibitive for large networks. Inspired by random feature methods for kernel approximation in Euclidean spaces, we introduce randomized spectral node embeddings whose dot products estimate a low-rank approximation of any specific graph kernel. We provide theoretical and empirical results showing that our embeddings achieve more accurate kernel approximations than existing methods, particularly for spectrally localized kernels. These results demonstrate the effectiveness of randomized spectral constructions for scalable and principled graph representation learning.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å›¾æ ¸(Graph kernels)åœ¨å¤§è§„æ¨¡ç½‘ç»œä¸­è®¡ç®—å—é™çš„é—®é¢˜ï¼Œæå‡ºäº†ç”¨äºå›¾æ ¸æœºå™¨(Graph Kernel Machines)çš„éšæœºå°æ³¢ç‰¹å¾(Random Wavelet Features)ã€‚å—æ¬§å‡ é‡Œå¾—ç©ºé—´éšæœºç‰¹å¾(random feature)æ–¹æ³•çš„å¯å‘ï¼Œä½œè€…å¼•å…¥äº†éšæœºåŒ–è°±èŠ‚ç‚¹åµŒå…¥(randomized spectral node embeddings)ï¼Œåˆ©ç”¨å…¶ç‚¹ç§¯æ¥ä¼°è®¡ç‰¹å®šå›¾æ ¸çš„ä½ç§©è¿‘ä¼¼ã€‚è¿™ç§æ–¹æ³•ä¸ä»…èƒ½å¤Ÿæœ‰æ•ˆä¿ç•™å›¾çš„ç»“æ„ä¿¡æ¯ï¼Œè¿˜ä¸ºèŠ‚ç‚¹åµŒå…¥(Node embeddings)æä¾›äº†ä¸€ç§å…·æœ‰ç†è®ºä¿éšœçš„æ„å»ºæ–¹å¼ã€‚å®éªŒä¸ç†è®ºåˆ†æè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ ¸è¿‘ä¼¼çš„å‡†ç¡®æ€§ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æŠ€æœ¯ï¼Œå°¤å…¶åœ¨å¤„ç†è°±å±€éƒ¨åŒ–æ ¸(spectrally localized kernels)æ—¶è¡¨ç°ä¼˜å¼‚ã€‚è¯¥æˆæœä¸ºå®ç°å¯æ‰©å±•ä¸”åŸåˆ™æ˜ç¡®çš„å›¾è¡¨ç¤ºå­¦ä¹ ä»¥åŠé«˜æ•ˆçš„å›¾æ ¸è®¡ç®—æä¾›äº†æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper is an extended version of a paper submitted to the 2026 European Signal Processing Conference (EUSIPCO 2026). It contains supplementary material including the full proof to Proposition 1",
      "pdf_url": "https://arxiv.org/pdf/2602.15711v1",
      "published_date": "2026-02-17 16:45:15 UTC",
      "updated_date": "2026-02-17 16:45:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:34:13.248103+00:00"
    },
    {
      "arxiv_id": "2602.15708v1",
      "title": "Outer Diversity of Structured Domains",
      "title_zh": "ç»“æ„åŒ–åŸŸçš„å¤–éƒ¨å¤šæ ·æ€§",
      "authors": [
        "Piotr Faliszewski",
        "Krzysztof Sornat",
        "StanisÅ‚aw Szufa",
        "Tomasz WÄ…s"
      ],
      "abstract": "An ordinal preference domain is a subset of preference orders that the voters are allowed to cast in an election. We introduce and study the notion of outer diversity of a domain and evaluate its value for a number of well-known structured domains, such as the single-peaked, single-crossing, group-separable, and Euclidean ones.",
      "tldr_zh": "è¯¥ç ”ç©¶èšç„¦äºæœ‰åºåå¥½åŸŸ (ordinal preference domain) çš„ç‰¹æ€§ï¼Œå¹¶æ­£å¼å¼•å…¥äº†å¤–éƒ¨å¤šæ ·æ€§ (outer diversity) è¿™ä¸€æ–°æ¦‚å¿µã€‚è®ºæ–‡æ—¨åœ¨è¡¡é‡é€‰æ°‘åœ¨ç‰¹å®šé€‰ä¸¾çº¦æŸä¸‹å¯æŠ•å‡ºçš„åå¥½æ’åºé›†çš„å¤šæ ·åŒ–ç¨‹åº¦ã€‚ç ”ç©¶äººå‘˜ç³»ç»Ÿåœ°è¯„ä¼°äº†è¯¥æŒ‡æ ‡åœ¨å¤šç§è‘—åç»“æ„åŒ–åŸŸä¸­çš„è¡¨ç°ï¼ŒåŒ…æ‹¬å•å³°åŸŸ (single-peaked)ã€å•è·¨è¶ŠåŸŸ (single-crossing)ã€ç»„å¯åˆ†åŸŸ (group-separable) ä»¥åŠæ¬§å‡ é‡Œå¾—åŸŸ (Euclidean)ã€‚é€šè¿‡å¯¹è¿™äº›ç»å…¸æ¨¡å‹çš„å®šé‡åˆ†æï¼Œè¯¥å·¥ä½œä¸ºç†è§£åå¥½ç»“æ„çš„ä¸°å¯Œæ€§åŠå…¶å¯¹ç¤¾ä¼šé€‰æ‹©è¿‡ç¨‹çš„å½±å“æä¾›äº†ç†è®ºæ”¯æ’‘ã€‚è¿™ä¸€å‘ç°æœ‰åŠ©äºæ›´æ·±å…¥åœ°åˆ»ç”»ä¸åŒæŠ•ç¥¨çº¦æŸä¸‹é€‰æ°‘æ„è§çš„åˆ†å¸ƒç‰¹å¾ä¸è¡¨è¾¾è¾¹ç•Œã€‚",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15708v1",
      "published_date": "2026-02-17 16:42:05 UTC",
      "updated_date": "2026-02-17 16:42:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:34:21.636917+00:00"
    },
    {
      "arxiv_id": "2602.15698v1",
      "title": "How to Disclose? Strategic AI Disclosure in Crowdfunding",
      "title_zh": "å¦‚ä½•æŠ«éœ²ï¼Ÿä¼—ç­¹ä¸­çš„ç­–ç•¥æ€§ AI æŠ«éœ²",
      "authors": [
        "Ning Wang",
        "Chen Liang"
      ],
      "abstract": "As artificial intelligence (AI) increasingly integrates into crowdfunding practices, strategic disclosure of AI involvement has become critical. Yet, empirical insights into how different disclosure strategies influence investor decisions remain limited. Drawing on signaling theory and Aristotle's rhetorical framework, we examine how mandatory AI disclosure affects crowdfunding performance and how substantive signals (degree of AI involvement) and rhetorical signals (logos/explicitness, ethos/authenticity, pathos/emotional tone) moderate these effects. Leveraging Kickstarter's mandatory AI disclosure policy as a natural experiment and four supplementary online experiments, we find that mandatory AI disclosure significantly reduces crowdfunding performance: funds raised decline by 39.8% and backer counts by 23.9% for AI-involved projects. However, this adverse effect is systematically moderated by disclosure strategy. Greater AI involvement amplifies the negative effects of AI disclosure, while high authenticity and high explicitness mitigate them. Interestingly, excessive positive emotional tone (a strategy creators might intuitively adopt to counteract AI skepticism) backfires and exacerbates negative outcomes. Supplementary randomized experiments identify two underlying mechanisms: perceived creator competence and AI washing concerns. Substantive signals primarily affect competence judgments, whereas rhetorical signals operate through varied pathways: either mediator alone or both in sequence. These findings provide theoretical and practical insights for entrepreneurs, platforms, and policymakers strategically managing AI transparency in high-stakes investment contexts.",
      "tldr_zh": "è¯¥ç ”ç©¶åŸºäºä¿¡å·ç†è®º(Signaling Theory)å’Œäºšé‡Œå£«å¤šå¾·çš„ä¿®è¾æ¡†æ¶(Aristotle's Rhetorical Framework)ï¼Œæ¢è®¨äº†ä¼—ç­¹æ´»åŠ¨ä¸­äººå·¥æ™ºèƒ½(AI)æŠ«éœ²ç­–ç•¥å¯¹æŠ•èµ„è€…å†³ç­–çš„å½±å“ã€‚é€šè¿‡åˆ†æKickstarterçš„å¼ºåˆ¶æŠ«éœ²æ”¿ç­–å’Œå¤šé¡¹å®éªŒï¼Œç ”ç©¶å‘ç°å¼ºåˆ¶æ€§AIæŠ«éœ²ä¼šæ˜¾è‘—é™ä½ä¼—ç­¹ç»©æ•ˆï¼Œå¯¼è‡´èèµ„é¢å¹³å‡ä¸‹é™39.8%ï¼Œæ”¯æŒè€…äººæ•°å‡å°‘23.9%ã€‚è¿™ç§è´Ÿé¢å½±å“å—åˆ°æŠ«éœ²ç­–ç•¥çš„è°ƒèŠ‚ï¼šè¾ƒé«˜çš„AIå‚ä¸åº¦(AI involvement)ä¼šæ”¾å¤§è´Ÿé¢æ•ˆåº”ï¼Œè€Œé«˜çœŸå®æ€§(Authenticity)å’Œé«˜æ˜ç¡®æ€§(Explicitness)åˆ™èƒ½èµ·åˆ°ç¼“è§£ä½œç”¨ã€‚ç ”ç©¶ç‰¹åˆ«æŒ‡å‡ºï¼Œè¿‡åº¦ç§¯æçš„æƒ…ç»ªåŸºè°ƒ(Positive Emotional Tone)å¾€å¾€ä¼šé€‚å¾—å…¶åï¼ŒåŠ å‰§æŠ•èµ„è€…çš„æ€€ç–‘ã€‚å®éªŒè¿›ä¸€æ­¥è¯æ˜ï¼Œæ„ŸçŸ¥åˆ›ä½œè€…èƒ½åŠ›(Creator Competence)å’Œå¯¹AIæ´—ç™½(AI washing)çš„æ‹…å¿§æ˜¯å½±å“æŠ•èµ„è€…å†³ç­–çš„æ ¸å¿ƒæœºåˆ¶ã€‚è¿™äº›å‘ç°ä¸ºåˆ›ä¸šè€…å’Œæ”¿ç­–åˆ¶å®šè€…åœ¨ä¼—ç­¹èƒŒæ™¯ä¸‹æˆ˜ç•¥æ€§åœ°ç®¡ç†AIé€æ˜åº¦æä¾›äº†é‡è¦ä¾æ®ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15698v1",
      "published_date": "2026-02-17 16:26:03 UTC",
      "updated_date": "2026-02-17 16:26:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:34:18.834205+00:00"
    },
    {
      "arxiv_id": "2602.15689v1",
      "title": "A Content-Based Framework for Cybersecurity Refusal Decisions in Large Language Models",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹ä¸­åŸºäºå†…å®¹çš„ç½‘ç»œå®‰å…¨æ‹’ç»å†³ç­–æ¡†æ¶",
      "authors": [
        "Meirav Segal",
        "Noa Linder",
        "Omer Antverg",
        "Gil Gekker",
        "Tomer Fichman",
        "Omri Bodenheimer",
        "Edan Maor",
        "Omer Nevo"
      ],
      "abstract": "Large language models and LLM-based agents are increasingly used for cybersecurity tasks that are inherently dual-use. Existing approaches to refusal, spanning academic policy frameworks and commercially deployed systems, often rely on broad topic-based bans or offensive-focused taxonomies. As a result, they can yield inconsistent decisions, over-restrict legitimate defenders, and behave brittlely under obfuscation or request segmentation. We argue that effective refusal requires explicitly modeling the trade-off between offensive risk and defensive benefit, rather than relying solely on intent or offensive classification. In this paper, we introduce a content-based framework for designing and auditing cyber refusal policies that makes offense-defense tradeoffs explicit. The framework characterizes requests along five dimensions: Offensive Action Contribution, Offensive Risk, Technical Complexity, Defensive Benefit, and Expected Frequency for Legitimate Users, grounded in the technical substance of the request rather than stated intent. We demonstrate that this content-grounded approach resolves inconsistencies in current frontier model behavior and allows organizations to construct tunable, risk-aware refusal policies.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç½‘ç»œå®‰å…¨åŒé‡ç”¨é€”ä»»åŠ¡ä¸­æ‹’ç»æœºåˆ¶ä¸ä¸€è‡´ã€è¿‡åº¦é™åˆ¶åˆæ³•é˜²å¾¡è€…ä»¥åŠåœ¨æ··æ·†æ”»å‡»ä¸‹è¡¨ç°è„†å¼±ç­‰é—®é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªåŸºäºå†…å®¹ï¼ˆContent-Based Frameworkï¼‰çš„æ‹’ç»å†³ç­–æ¡†æ¶ã€‚è¯¥æ¡†æ¶ä¸»å¼ æœ‰æ•ˆçš„æ‹’ç»æœºåˆ¶åº”æ˜¾å¼å»ºæ¨¡æ”»å‡»é£é™©ï¼ˆOffensive Riskï¼‰ä¸é˜²å¾¡æ”¶ç›Šï¼ˆDefensive Benefitï¼‰ä¹‹é—´çš„æƒè¡¡ï¼Œè€Œéä»…ä»…ä¾èµ–æ„å›¾è¯†åˆ«æˆ–ç®€å•çš„æ”»å‡»æ€§åˆ†ç±»ã€‚ç ”ç©¶é€šè¿‡ä»æ”»å‡»è¡Œä¸ºè´¡çŒ®ï¼ˆOffensive Action Contributionï¼‰ã€æ”»å‡»é£é™©ã€æŠ€æœ¯å¤æ‚åº¦ï¼ˆTechnical Complexityï¼‰ã€é˜²å¾¡æ”¶ç›Šä»¥åŠåˆæ³•ç”¨æˆ·é¢„æœŸé¢‘ç‡ï¼ˆExpected Frequency for Legitimate Usersï¼‰äº”ä¸ªæŠ€æœ¯ç»´åº¦å¯¹è¯·æ±‚è¿›è¡Œè¡¨å¾ï¼Œå®ç°äº†åŸºäºæŠ€æœ¯å®è´¨è€Œéé™ˆè¿°æ„å›¾çš„ç­–ç•¥åˆ¤å®šã€‚å®éªŒè¯æ˜ï¼Œè¿™ç§æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆè§£å†³å½“å‰å‰æ²¿æ¨¡å‹åœ¨å®‰å…¨å†³ç­–ä¸­çš„ä¸ä¸€è‡´æ€§ï¼Œå¹¶å…è®¸ç»„ç»‡æ ¹æ®å®é™…éœ€æ±‚æ„å»ºå¯è°ƒèŠ‚ä¸”å…·å¤‡é£é™©æ„ŸçŸ¥èƒ½åŠ›çš„æ‹’ç»ç­–ç•¥ã€‚è¯¥æ¡†æ¶ä¸ºåœ¨å¤æ‚ç½‘ç»œå®‰å…¨åœºæ™¯ä¸‹å¹³è¡¡æ¨¡å‹å®‰å…¨æ€§ä¸å®ç”¨æ€§æä¾›äº†ç³»ç»Ÿæ€§çš„å®¡è®¡å’Œè®¾è®¡æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15689v1",
      "published_date": "2026-02-17 16:12:21 UTC",
      "updated_date": "2026-02-17 16:12:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:34:20.736430+00:00"
    },
    {
      "arxiv_id": "2602.15684v1",
      "title": "Estimating Human Muscular Fatigue in Dynamic Collaborative Robotic Tasks with Learning-Based Models",
      "title_zh": "åŸºäºå­¦ä¹ æ¨¡å‹çš„åŠ¨æ€åä½œæœºå™¨äººä»»åŠ¡ä¸­äººä½“è‚Œè‚‰ç–²åŠ³è¯„ä¼°",
      "authors": [
        "Feras Kiki",
        "Pouya P. Niaz",
        "Alireza Madani",
        "Cagatay Basdogan"
      ],
      "abstract": "Assessing human muscle fatigue is critical for optimizing performance and safety in physical human-robot interaction(pHRI). This work presents a data-driven framework to estimate fatigue in dynamic, cyclic pHRI using arm-mounted surface electromyography(sEMG). Subject-specific machine-learning regression models(Random Forest, XGBoost, and Linear Regression predict the fraction of cycles to fatigue(FCF) from three frequency-domain and one time-domain EMG features, and are benchmarked against a convolutional neural network(CNN) that ingests spectrograms of filtered EMG. Framing fatigue estimation as regression (rather than classification) captures continuous progression toward fatigue, supporting earlier detection, timely intervention, and adaptive robot control. In experiments with ten participants, a collaborative robot under admittance control guided repetitive lateral (left-right) end-effector motions until muscular fatigue. Average FCF RMSE across participants was 20.8+/-4.3% for the CNN, 23.3+/-3.8% for Random Forest, 24.8+/-4.5% for XGBoost, and 26.9+/-6.1% for Linear Regression. To probe cross-task generalization, one participant additionally performed unseen vertical (up-down) and circular repetitions; models trained only on lateral data were tested directly and largely retained accuracy, indicating robustness to changes in movement direction, arm kinematics, and muscle recruitment, while Linear Regression deteriorated. Overall, the study shows that both feature-based ML and spectrogram-based DL can estimate remaining work capacity during repetitive pHRI, with the CNN delivering the lowest error and the tree-based models close behind. The reported transfer to new motion patterns suggests potential for practical fatigue monitoring without retraining for every task, improving operator protection and enabling fatigue-aware shared autonomy, for safer fatigue-adaptive pHRI control.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç‰©ç†äººæœºäº¤äº’ (pHRI) ä¸­çš„å®‰å…¨ä¸æ€§èƒ½ä¼˜åŒ–é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºè¡¨é¢è‚Œç”µä¿¡å· (sEMG) çš„æ•°æ®é©±åŠ¨æ¡†æ¶ï¼Œç”¨äºä¼°è®¡åŠ¨æ€å¾ªç¯ä»»åŠ¡ä¸­çš„äººä½“è‚Œè‚‰ç–²åŠ³ç¨‹åº¦ã€‚è¯¥æ¡†æ¶å°†ç–²åŠ³ä¼°è®¡å»ºæ¨¡ä¸ºå›å½’é—®é¢˜è€Œéåˆ†ç±»é—®é¢˜ï¼Œé€šè¿‡é¢„æµ‹ç–²åŠ³å¾ªç¯æ¯”ä¾‹ (FCF) æ¥å®æ—¶æ•æ‰ç–²åŠ³çš„è¿ç»­è¿›å±•ï¼Œä»è€Œæ”¯æŒæ—©æœŸæ£€æµ‹ä¸è‡ªé€‚åº”æœºå™¨äººæ§åˆ¶ã€‚ç ”ç©¶å¯¹æ¯”äº†åŸºäºäººå·¥æå–ç‰¹å¾çš„æœºå™¨å­¦ä¹ æ¨¡å‹ (Random Forest, XGBoost, Linear Regression) ä¸åŸºäºé¢‘è°±å›¾çš„å·ç§¯ç¥ç»ç½‘ç»œ (CNN)ï¼Œå®éªŒç»“æœæ˜¾ç¤º CNN åœ¨é¢„æµ‹ç²¾åº¦ä¸Šè¡¨ç°æœ€ä¼˜ï¼Œå…¶å‡æ–¹æ ¹è¯¯å·® (RMSE) ä»…ä¸º 20.8%ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹åœ¨å¤„ç†æœªè§è¿‡çš„è¿åŠ¨æ–¹å‘å’Œæ‰‹è‡‚è¿åŠ¨å­¦å˜åŒ–æ—¶è¡¨ç°å‡ºæ˜¾è‘—çš„æ³›åŒ–èƒ½åŠ›ï¼Œæ— éœ€é’ˆå¯¹æ–°ä»»åŠ¡é‡æ–°è®­ç»ƒå³å¯ä¿æŒå‡†ç¡®æ€§ã€‚è¿™ä¸€æˆæœä¸ºå®ç°ç–²åŠ³æ„ŸçŸ¥çš„å…±äº«è‡ªä¸»ç³»ç»Ÿ (Shared Autonomy) æä¾›äº†æŠ€æœ¯æ”¯æŒï¼Œæœ‰åŠ©äºæå‡æ“ä½œå‘˜ä¿æŠ¤å¹¶ä¼˜åŒ–ç–²åŠ³è‡ªé€‚åº”çš„ pHRI æ§åˆ¶ç­–ç•¥ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC",
        "eess.SP",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "ICRA 2026 Original Contribution, Vienne, Austria",
      "pdf_url": "https://arxiv.org/pdf/2602.15684v1",
      "published_date": "2026-02-17 16:08:11 UTC",
      "updated_date": "2026-02-17 16:08:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:34:39.141953+00:00"
    },
    {
      "arxiv_id": "2602.15678v1",
      "title": "Revisiting Northrop Frye's Four Myths Theory with Large Language Models",
      "title_zh": "åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„ Northrop Frye å››å¤§ç¥è¯ç†è®ºå†æ¢",
      "authors": [
        "Edirlei Soares de Lima",
        "Marco A. Casanova",
        "Antonio L. Furtado"
      ],
      "abstract": "Northrop Frye's theory of four fundamental narrative genres (comedy, romance, tragedy, satire) has profoundly influenced literary criticism, yet computational approaches to his framework have focused primarily on narrative patterns rather than character functions. In this paper, we present a new character function framework that complements pattern-based analysis by examining how archetypal roles manifest differently across Frye's genres. Drawing on Jungian archetype theory, we derive four universal character functions (protagonist, mentor, antagonist, companion) by mapping them to Jung's psychic structure components. These functions are then specialized into sixteen genre-specific roles based on prototypical works. To validate this framework, we conducted a multi-model study using six state-of-the-art Large Language Models (LLMs) to evaluate character-role correspondences across 40 narrative works. The validation employed both positive samples (160 valid correspondences) and negative samples (30 invalid correspondences) to evaluate whether models both recognize valid correspondences and reject invalid ones. LLMs achieved substantial performance (mean balanced accuracy of 82.5%) with strong inter-model agreement (Fleiss' $Îº$ = 0.600), demonstrating that the proposed correspondences capture systematic structural patterns. Performance varied by genre (ranging from 72.7% to 89.9%) and role (52.5% to 99.2%), with qualitative analysis revealing that variations reflect genuine narrative properties, including functional distribution in romance and deliberate archetypal subversion in satire. This character-based approach demonstrates the potential of LLM-supported methods for computational narratology and provides a foundation for future development of narrative generation methods and interactive storytelling applications.",
      "tldr_zh": "è¯¥ç ”ç©¶é‡æ–°å®¡è§†äº†Northrop Fryeçš„å››ç§åŸºæœ¬å™äº‹ç±»å‹ï¼ˆå–œå‰§ã€æµªæ¼«ã€æ‚²å‰§ã€è®½åˆºï¼‰ç†è®ºï¼Œæå‡ºäº†ä¸€ç§å…¨æ–°çš„è§’è‰²åŠŸèƒ½æ¡†æ¶ï¼Œä»¥å¼¥è¡¥è®¡ç®—å™äº‹å­¦ä¸­å¯¹è§’è‰²åŠŸèƒ½ç ”ç©¶çš„ä¸è¶³ã€‚ç ”ç©¶è€…ç»“åˆè£æ ¼å¿ƒç†ç»“æ„ç†è®ºï¼Œæ¨å¯¼å‡ºå››ç§é€šç”¨çš„è§’è‰²åŠŸèƒ½ï¼ˆä¸»è§’ Protagonistã€å¯¼å¸ˆ Mentorã€åæ´¾ Antagonistã€åŒä¼´ Companionï¼‰ï¼Œå¹¶å°†å…¶ç»†åŒ–ä¸ºåå…­ä¸ªç‰¹å®šç±»å‹çš„è§’è‰²ã€‚é€šè¿‡ä½¿ç”¨å…­ç§æœ€å…ˆè¿›çš„å¤§è¯­è¨€æ¨¡å‹(LLMs)å¯¹40éƒ¨å™äº‹ä½œå“è¿›è¡Œå¤šæ¨¡å‹ç ”ç©¶ï¼ŒéªŒè¯äº†è¯¥æ¡†æ¶åœ¨è¯†åˆ«è§’è‰²ä¸è§’è‰²å¯¹åº”å…³ç³»æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLLMs è¾¾åˆ°äº†82.5%çš„å¹³å‡å¹³è¡¡å‡†ç¡®ç‡ï¼Œä¸”æ¨¡å‹é—´è¾¾æˆé«˜åº¦å…±è¯†ï¼ˆFleiss' Îº = 0.600ï¼‰ï¼Œè¯æ˜äº†è¯¥æ¡†æ¶æ•æ‰åˆ°äº†ç³»ç»Ÿçš„å™äº‹ç»“æ„æ¨¡å¼ã€‚å®šæ€§åˆ†æè¿›ä¸€æ­¥æ­ç¤ºäº†ä¸åŒæµæ´¾é—´çš„æ€§èƒ½å·®å¼‚åæ˜ äº†çœŸå®çš„å™äº‹ç‰¹æ€§ï¼Œå¦‚æµªæ¼«å‰§ä¸­çš„åŠŸèƒ½åˆ†å¸ƒå’Œè®½åˆºå‰§ä¸­å¯¹åŸå‹çš„åˆ»æ„é¢ è¦†ã€‚è¯¥ç ”ç©¶ä¸ä»…å±•ç¤ºäº†åŸºäº LLM çš„æ–¹æ³•åœ¨è®¡ç®—å™äº‹å­¦ä¸­çš„æ½œåŠ›ï¼Œä¹Ÿä¸ºæœªæ¥çš„å™äº‹ç”Ÿæˆæ–¹æ³•å’Œäº¤äº’å¼å™äº‹åº”ç”¨å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15678v1",
      "published_date": "2026-02-17 16:02:52 UTC",
      "updated_date": "2026-02-17 16:02:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:34:39.936493+00:00"
    },
    {
      "arxiv_id": "2602.15676v1",
      "title": "Relative Geometry of Neural Forecasters: Linking Accuracy and Alignment in Learned Latent Geometry",
      "title_zh": "Neural Forecasters çš„ç›¸å¯¹å‡ ä½•ï¼šå»ºç«‹å­¦ä¹ æ½œåœ¨å‡ ä½•ä¸­å‡†ç¡®åº¦ä¸å¯¹é½æ€§çš„è”ç³»",
      "authors": [
        "Deniz Kucukahmetler",
        "Maximilian Jean Hemmann",
        "Julian Mosig von Aehrenfeld",
        "Maximilian Amthor",
        "Christian Deubel",
        "Nico Scherf",
        "Diaaeldin Taha"
      ],
      "abstract": "Neural networks can accurately forecast complex dynamical systems, yet how they internally represent underlying latent geometry remains poorly understood. We study neural forecasters through the lens of representational alignment, introducing anchor-based, geometry-agnostic relative embeddings that remove rotational and scaling ambiguities in latent spaces. Applying this framework across seven canonical dynamical systems - ranging from periodic to chaotic - we reveal reproducible family-level structure: multilayer perceptrons align with other MLPs, recurrent networks with RNNs, while transformers and echo-state networks achieve strong forecasts despite weaker alignment. Alignment generally correlates with forecasting accuracy, yet high accuracy can coexist with low alignment. Relative geometry thus provides a simple, reproducible foundation for comparing how model families internalize and represent dynamical structure.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç¥ç»é¢„æµ‹å™¨ï¼ˆneural forecastersï¼‰å¦‚ä½•å†…éƒ¨è¡¨ç¤ºåŠ¨æ€ç³»ç»Ÿçš„æ½œåœ¨å‡ ä½•ç»“æ„ï¼Œå¹¶å¼•å…¥äº†åŸºäºé”šç‚¹çš„å‡ ä½•ä¸å¯çŸ¥ç›¸å¯¹åµŒå…¥ï¼ˆanchor-based, geometry-agnostic relative embeddingsï¼‰ä»¥æ¶ˆé™¤æ½œåœ¨ç©ºé—´ä¸­çš„æ—‹è½¬å’Œç¼©æ”¾æ­§ä¹‰ã€‚ç ”ç©¶è€…åœ¨ä»å‘¨æœŸæ€§åˆ°æ··æ²Œçš„ä¸ƒç§è§„èŒƒåŠ¨æ€ç³»ç»Ÿä¸Šåº”ç”¨è¯¥æ¡†æ¶ï¼Œæ­ç¤ºäº†æ˜¾è‘—çš„æ¨¡å‹å®¶æ—çº§ç»“æ„ï¼šå¤šå±‚æ„ŸçŸ¥å™¨ï¼ˆMLPsï¼‰å€¾å‘äºä¸å…¶ä»–MLPså¯¹é½ï¼Œé€’å½’ç½‘ç»œï¼ˆRNNsï¼‰ä¸RNNså¯¹é½ï¼Œè€ŒTransformerå’Œå›å£°çŠ¶æ€ç½‘ç»œï¼ˆecho-state networksï¼‰å°½ç®¡å¯¹é½åº¦è¾ƒä½ï¼Œä»èƒ½å®ç°å‡ºè‰²çš„é¢„æµ‹æ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¡¨ç¤ºå¯¹é½ï¼ˆrepresentational alignmentï¼‰é€šå¸¸ä¸é¢„æµ‹å‡†ç¡®æ€§æ­£ç›¸å…³ï¼Œä½†é«˜å‡†ç¡®æ€§ä¸ä½å¯¹é½åº¦å¹¶å­˜çš„ç°è±¡è¯´æ˜äº†æ¨¡å‹å­¦ä¹ ç­–ç•¥çš„å¤šæ ·æ€§ã€‚ç›¸å¯¹å‡ ä½•ï¼ˆRelative geometryï¼‰ä¸ºæ¯”è¾ƒä¸åŒæ¨¡å‹å®¶æ—å¦‚ä½•å†…åŒ–å¹¶è¡¨å¾åŠ¨æ€ç»“æ„æä¾›äº†ä¸€ä¸ªç®€å•ä¸”å¯é‡å¤çš„åŸºç¡€ï¼Œæœ‰åŠ©äºæ·±å…¥ç†è§£ç¥ç»ç½‘ç»œçš„å†…éƒ¨å·¥ä½œæœºåˆ¶ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to Transactions on Machine Learning Research (TMLR)",
      "pdf_url": "https://arxiv.org/pdf/2602.15676v1",
      "published_date": "2026-02-17 16:00:08 UTC",
      "updated_date": "2026-02-17 16:00:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:34:45.438185+00:00"
    },
    {
      "arxiv_id": "2602.15669v1",
      "title": "PERSONA: Dynamic and Compositional Inference-Time Personality Control via Activation Vector Algebra",
      "title_zh": "PERSONAï¼šåŸºäºæ¿€æ´»å‘é‡ä»£æ•°çš„æ¨ç†æ—¶åŠ¨æ€ç»„åˆå¼äººæ ¼æ§åˆ¶",
      "authors": [
        "Xiachong Feng",
        "Liang Zhao",
        "Weihong Zhong",
        "Yichong Huang",
        "Yuxuan Gu",
        "Lingpeng Kong",
        "Xiaocheng Feng",
        "Bing Qin"
      ],
      "abstract": "Current methods for personality control in Large Language Models rely on static prompting or expensive fine-tuning, failing to capture the dynamic and compositional nature of human traits. We introduce PERSONA, a training-free framework that achieves fine-tuning level performance through direct manipulation of personality vectors in activation space. Our key insight is that personality traits appear as extractable, approximately orthogonal directions in the model's representation space that support algebraic operations. The framework operates through three stages: Persona-Base extracts orthogonal trait vectors via contrastive activation analysis; Persona-Algebra enables precise control through vector arithmetic (scalar multiplication for intensity, addition for composition, subtraction for suppression); and Persona-Flow achieves context-aware adaptation by dynamically composing these vectors during inference. On PersonalityBench, our approach achieves a mean score of 9.60, nearly matching the supervised fine-tuning upper bound of 9.61 without any gradient updates. On our proposed Persona-Evolve benchmark for dynamic personality adaptation, we achieve up to 91% win rates across diverse model families. These results provide evidence that aspects of LLM personality are mathematically tractable, opening new directions for interpretable and efficient behavioral control.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† PERSONAï¼Œä¸€ç§æ— éœ€è®­ç»ƒçš„æ¨ç†æ—¶äººæ ¼æ§åˆ¶æ¡†æ¶ï¼Œé€šè¿‡ç›´æ¥åœ¨æ¿€æ´»ç©ºé—´ï¼ˆactivation spaceï¼‰ä¸­æ“ä½œäººæ ¼å‘é‡ï¼Œè§£å†³äº†ç°æœ‰æ–¹æ³•åœ¨å¤„ç†åŠ¨æ€ä¸”ç»„åˆæ€§çš„äººæ ¼ç‰¹å¾æ—¶é¢ä¸´çš„å±€é™ã€‚ç ”ç©¶è€…å‘ç°äººæ ¼ç‰¹å¾åœ¨æ¨¡å‹è¡¨ç¤ºç©ºé—´ä¸­è¡¨ç°ä¸ºå¯æå–ä¸”è¿‘ä¼¼æ­£äº¤çš„æ–¹å‘ï¼Œå¹¶æ”¯æŒä»£æ•°è¿ç®—ã€‚è¯¥æ¡†æ¶ç”±ä¸‰ä¸ªé˜¶æ®µç»„æˆï¼šPersona-Base åˆ©ç”¨å¯¹æ¯”æ¿€æ´»åˆ†æï¼ˆcontrastive activation analysisï¼‰æå–æ­£äº¤ç‰¹å¾å‘é‡ï¼ŒPersona-Algebra é€šè¿‡å‘é‡ç®—æœ¯å®ç°ç²¾ç¡®çš„äººæ ¼å¼ºåº¦æ§åˆ¶ä¸ç»„åˆï¼Œè€Œ Persona-Flow åˆ™åœ¨æ¨ç†è¿‡ç¨‹ä¸­åŠ¨æ€ç»„åˆè¿™äº›å‘é‡ä»¥å®ç°ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„äººæ ¼é€‚åº”ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒPERSONA åœ¨ PersonalityBench ä¸Šçš„å¹³å‡å¾—åˆ†è¾¾ 9.60ï¼Œåœ¨æ— éœ€æ¢¯åº¦æ›´æ–°çš„æƒ…å†µä¸‹å‡ ä¹è¾¾åˆ°äº†ç›‘ç£å¾®è°ƒï¼ˆsupervised fine-tuningï¼‰çš„æ€§èƒ½ä¸Šé™ï¼Œå¹¶åœ¨åŠ¨æ€äººæ ¼é€‚åº”ä»»åŠ¡ä¸­è·å¾—äº†é«˜è¾¾ 91% çš„èƒœç‡ã€‚è¿™ä¸€æˆæœè¯æ˜äº†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„äººæ ¼ç»´åº¦åœ¨æ•°å­¦ä¸Šæ˜¯å¯å¤„ç†çš„ï¼Œä¸ºå®ç°é«˜æ•ˆä¸”å¯è§£é‡Šçš„è¡Œä¸ºæ§åˆ¶å¼€è¾Ÿäº†æ–°è·¯å¾„ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "ICLR 2026",
      "pdf_url": "https://arxiv.org/pdf/2602.15669v1",
      "published_date": "2026-02-17 15:47:58 UTC",
      "updated_date": "2026-02-17 15:47:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:34:48.642542+00:00"
    },
    {
      "arxiv_id": "2602.15660v1",
      "title": "Bayesian Optimization for Design Parameters of 3D Image Data Analysis",
      "title_zh": "3D å›¾åƒæ•°æ®åˆ†æè®¾è®¡å‚æ•°çš„è´å¶æ–¯ä¼˜åŒ–",
      "authors": [
        "David Exler",
        "Joaquin Eduardo Urrutia GÃ³mez",
        "Martin KrÃ¼ger",
        "Maike Schliephake",
        "John Jbeily",
        "Mario Vitacolonna",
        "RÃ¼diger Rudolf",
        "Markus Reischl"
      ],
      "abstract": "Deep learning-based segmentation and classification are crucial to large-scale biomedical imaging, particularly for 3D data, where manual analysis is impractical. Although many methods exist, selecting suitable models and tuning parameters remains a major bottleneck in practice. Hence, we introduce the 3D data Analysis Optimization Pipeline, a method designed to facilitate the design and parameterization of segmentation and classification using two Bayesian Optimization stages. First, the pipeline selects a segmentation model and optimizes postprocessing parameters using a domain-adapted syntactic benchmark dataset. To ensure a concise evaluation of segmentation performance, we introduce a segmentation quality metric that serves as the objective function. Second, the pipeline optimizes design choices of a classifier, such as encoder and classifier head architectures, incorporation of prior knowledge, and pretraining strategies. To reduce manual annotation effort, this stage includes an assisted class-annotation workflow that extracts predicted instances from the segmentation results and sequentially presents them to the operator, eliminating the need for manual tracking. In four case studies, the 3D data Analysis Optimization Pipeline efficiently identifies effective model and parameter configurations for individual datasets.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è§„æ¨¡ç”Ÿç‰©åŒ»å­¦3Då½±åƒåˆ†æä¸­æ¨¡å‹é€‰æ‹©ä¸å‚æ•°è°ƒä¼˜çš„éš¾é¢˜ï¼Œæå‡ºäº†3Dæ•°æ®åˆ†æä¼˜åŒ–æµæ°´çº¿(3D data Analysis Optimization Pipeline)ã€‚è¯¥æ–¹æ³•åˆ©ç”¨ä¸¤ä¸ªé˜¶æ®µçš„è´å¶æ–¯ä¼˜åŒ–(Bayesian Optimization)å®ç°äº†åˆ†å‰²ä¸åˆ†ç±»ä»»åŠ¡çš„è‡ªåŠ¨åŒ–è®¾è®¡ã€‚ç¬¬ä¸€é˜¶æ®µé€šè¿‡é¢†åŸŸé€‚é…çš„åˆæˆåŸºå‡†æ•°æ®é›†ä¼˜åŒ–åˆ†å‰²æ¨¡å‹åŠåå¤„ç†å‚æ•°ï¼Œå¹¶å¼•å…¥åˆ†å‰²è´¨é‡åº¦é‡(segmentation quality metric)ä½œä¸ºç›®æ ‡å‡½æ•°ã€‚ç¬¬äºŒé˜¶æ®µé’ˆå¯¹åˆ†ç±»å™¨æ¶æ„ã€å…ˆéªŒçŸ¥è¯†åŠé¢„è®­ç»ƒç­–ç•¥è¿›è¡Œä¼˜åŒ–ï¼Œå¹¶æ•´åˆäº†è¾…åŠ©ç±»åˆ«æ ‡æ³¨å·¥ä½œæµä»¥æ˜¾è‘—é™ä½äººå·¥æ ‡æ³¨å·¥ä½œé‡ã€‚å®éªŒä¸­çš„å››ä¸ªæ¡ˆä¾‹ç ”ç©¶è¯æ˜ï¼Œè¯¥æµæ°´çº¿èƒ½å¤Ÿä¸ºä¸åŒæ•°æ®é›†é«˜æ•ˆè¯†åˆ«å‡ºæœ€ä¼˜çš„æ¨¡å‹å’Œå‚æ•°é…ç½®ï¼Œæå¤§åœ°æå‡äº†3Då›¾åƒæ•°æ®çš„å¤„ç†æ•ˆç‡ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.15660v1",
      "published_date": "2026-02-17 15:31:48 UTC",
      "updated_date": "2026-02-17 15:31:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:34:50.834189+00:00"
    },
    {
      "arxiv_id": "2602.15654v1",
      "title": "Zombie Agents: Persistent Control of Self-Evolving LLM Agents via Self-Reinforcing Injections",
      "title_zh": "Zombie Agentsï¼šé€šè¿‡è‡ªå¼ºåŒ–æ³¨å…¥å®ç°å¯¹è‡ªè¿›åŒ– LLM æ™ºèƒ½ä½“çš„æŒç»­æ§åˆ¶",
      "authors": [
        "Xianglin Yang",
        "Yufei He",
        "Shuo Ji",
        "Bryan Hooi",
        "Jin Song Dong"
      ],
      "abstract": "Self-evolving LLM agents update their internal state across sessions, often by writing and reusing long-term memory. This design improves performance on long-horizon tasks but creates a security risk: untrusted external content observed during a benign session can be stored as memory and later treated as instruction. We study this risk and formalize a persistent attack we call a Zombie Agent, where an attacker covertly implants a payload that survives across sessions, effectively turning the agent into a puppet of the attacker.\n  We present a black-box attack framework that uses only indirect exposure through attacker-controlled web content. The attack has two phases. During infection, the agent reads a poisoned source while completing a benign task and writes the payload into long-term memory through its normal update process. During trigger, the payload is retrieved or carried forward and causes unauthorized tool behavior. We design mechanism-specific persistence strategies for common memory implementations, including sliding-window and retrieval-augmented memory, to resist truncation and relevance filtering. We evaluate the attack on representative agent setups and tasks, measuring both persistence over time and the ability to induce unauthorized actions while preserving benign task quality. Our results show that memory evolution can convert one-time indirect injection into persistent compromise, which suggests that defenses focused only on per-session prompt filtering are not sufficient for self-evolving agents.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†è‡ªæˆ‘è¿›åŒ–LLMæ™ºèƒ½ä½“(Self-evolving LLM agents)åˆ©ç”¨é•¿æœŸè®°å¿†æœºåˆ¶æå‡æ€§èƒ½æ—¶æ‰€é¢ä¸´çš„å®‰å…¨é£é™©ï¼Œå¹¶æ­£å¼å®šä¹‰äº†ä¸€ç§åä¸ºZombie Agentçš„æŒç»­æ€§æ”»å‡»ã€‚æ”»å‡»è€…é€šè¿‡å—æ§çš„ç½‘é¡µå†…å®¹åœ¨è‰¯æ€§ä¼šè¯ä¸­æ¤å…¥æ¶æ„payloadï¼Œåˆ©ç”¨æ™ºèƒ½ä½“çš„æ­£å¸¸æ›´æ–°è¿‡ç¨‹å°†å…¶å­˜å…¥é•¿æœŸè®°å¿†ï¼Œä»è€Œå®ç°è·¨ä¼šè¯çš„éšè”½æ§åˆ¶ã€‚ç ”ç©¶é’ˆå¯¹æ»‘åŠ¨çª—å£(sliding-window)å’Œæ£€ç´¢å¢å¼ºè®°å¿†(retrieval-augmented memory)ç­‰æœºåˆ¶è®¾è®¡äº†ä¸“é—¨çš„æŒä¹…åŒ–ç­–ç•¥ï¼Œä»¥å¯¹æŠ—æˆªæ–­å’Œç›¸å…³æ€§è¿‡æ»¤ã€‚å®éªŒè¯æ˜ï¼Œè¿™ç§æ–¹æ³•èƒ½å°†ä¸€æ¬¡æ€§çš„é—´æ¥æ³¨å…¥(indirect injection)è½¬åŒ–ä¸ºæŒä¹…çš„ç³»ç»Ÿæ€§å—æŸï¼ŒåŒæ—¶ä¿æŒè‰¯æ€§ä»»åŠ¡çš„æ‰§è¡Œæ•ˆæœã€‚ç ”ç©¶ç»“æœå¼ºè°ƒï¼Œä»…ä¾èµ–å•æ¬¡ä¼šè¯æç¤ºè¯è¿‡æ»¤(per-session prompt filtering)çš„é˜²å¾¡æ‰‹æ®µä¸è¶³ä»¥ä¿æŠ¤å…·å¤‡è®°å¿†è¿›åŒ–èƒ½åŠ›çš„æ™ºèƒ½ä½“ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15654v1",
      "published_date": "2026-02-17 15:28:24 UTC",
      "updated_date": "2026-02-17 15:28:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:35:23.733161+00:00"
    },
    {
      "arxiv_id": "2602.15645v1",
      "title": "CARE Drive A Framework for Evaluating Reason-Responsiveness of Vision Language Models in Automated Driving",
      "title_zh": "CARE Driveï¼šä¸€ç§ç”¨äºè¯„ä¼°è‡ªåŠ¨é©¾é©¶ä¸­è§†è§‰è¯­è¨€æ¨¡å‹ç†ç”±å“åº”æ€§çš„æ¡†æ¶",
      "authors": [
        "Lucas Elbert Suryana",
        "Farah Bierenga",
        "Sanne van Buuren",
        "Pepijn Kooij",
        "Elsefien Tulleners",
        "Federico Scari",
        "Simeon Calvert",
        "Bart van Arem",
        "Arkady Zgonnikov"
      ],
      "abstract": "Foundation models, including vision language models, are increasingly used in automated driving to interpret scenes, recommend actions, and generate natural language explanations. However, existing evaluation methods primarily assess outcome based performance, such as safety and trajectory accuracy, without determining whether model decisions reflect human relevant considerations. As a result, it remains unclear whether explanations produced by such models correspond to genuine reason responsive decision making or merely post hoc rationalizations. This limitation is especially significant in safety critical domains because it can create false confidence. To address this gap, we propose CARE Drive, Context Aware Reasons Evaluation for Driving, a model agnostic framework for evaluating reason responsiveness in vision language models applied to automated driving. CARE Drive compares baseline and reason augmented model decisions under controlled contextual variation to assess whether human reasons causally influence decision behavior. The framework employs a two stage evaluation process. Prompt calibration ensures stable outputs. Systematic contextual perturbation then measures decision sensitivity to human reasons such as safety margins, social pressure, and efficiency constraints. We demonstrate CARE Drive in a cyclist overtaking scenario involving competing normative considerations. Results show that explicit human reasons significantly influence model decisions, improving alignment with expert recommended behavior. However, responsiveness varies across contextual factors, indicating uneven sensitivity to different types of reasons. These findings provide empirical evidence that reason responsiveness in foundation models can be systematically evaluated without modifying model parameters.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† CARE Drive (Context-Aware Reasons Evaluation for Driving)ï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºè¯„ä¼°è‡ªåŠ¨é©¾é©¶é¢†åŸŸè§†è§‰è¯­è¨€æ¨¡å‹ (Vision Language Models) ç†ç”±å“åº”æ€§ (Reason-Responsiveness) çš„æ¨¡å‹æ— å…³æ¡†æ¶ã€‚é’ˆå¯¹ç°æœ‰è¯„ä¼°æ–¹æ³•ä¸»è¦å…³æ³¨ç»“æœæ€§èƒ½è€Œå¿½è§†æ¨¡å‹å†³ç­–æ˜¯å¦çœŸå®åæ˜ äººç±»é€»è¾‘çš„é—®é¢˜ï¼Œè¯¥æ¡†æ¶æ—¨åœ¨è¾¨åˆ«æ¨¡å‹ç”Ÿæˆçš„è§£é‡Šæ˜¯æºäºçœŸå®çš„ç†ç”±å“åº”å†³ç­–ï¼Œè¿˜æ˜¯ä»…ä»…ä¸ºäº‹ååˆç†åŒ– (Post hoc rationalization)ã€‚CARE Drive é‡‡ç”¨äº†æç¤ºæ ¡å‡† (Prompt Calibration) å’Œç³»ç»Ÿæ€§ä¸Šä¸‹æ–‡æ‰°åŠ¨ (Systematic Contextual Perturbation) çš„ä¸¤é˜¶æ®µè¯„ä¼°æµç¨‹ï¼Œä»¥è¡¡é‡å†³ç­–å¯¹å®‰å…¨ä½™é‡ã€ç¤¾ä¼šå‹åŠ›åŠæ•ˆç‡çº¦æŸç­‰äººç±»ç†ç”±çš„æ•æ„Ÿåº¦ã€‚åœ¨è‡ªè¡Œè½¦è¶…è¶Šåœºæ™¯ä¸­çš„å®éªŒè¡¨æ˜ï¼Œæ˜ç¡®çš„äººç±»ç†ç”±èƒ½æ˜¾è‘—å½±å“æ¨¡å‹å†³ç­–å¹¶æå‡å…¶ä¸ä¸“å®¶è¡Œä¸ºçš„å¯¹é½åº¦ï¼Œä½†æ¨¡å‹å¯¹ä¸åŒç±»å‹ç†ç”±çš„å“åº”è¡¨ç°å‡ºä¸å‡è¡¡çš„æ•æ„Ÿæ€§ã€‚è¯¥é¡¹å·¥ä½œè¯æ˜äº†åœ¨ä¸ä¿®æ”¹æ¨¡å‹å‚æ•°çš„æƒ…å†µä¸‹ç³»ç»Ÿè¯„ä¼°åŸºç¡€æ¨¡å‹ (Foundation Models) ç†ç”±å“åº”æ€§çš„å¯è¡Œæ€§ï¼Œä¸ºæ„å»ºæ›´å…·å¯ä¿¡åº¦çš„è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿæä¾›äº†é‡è¦å·¥å…·ã€‚",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "21 pages, on submission to Transportation Research Part C",
      "pdf_url": "https://arxiv.org/pdf/2602.15645v1",
      "published_date": "2026-02-17 15:13:36 UTC",
      "updated_date": "2026-02-17 15:13:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:35:30.141759+00:00"
    },
    {
      "arxiv_id": "2602.15635v1",
      "title": "On inferring cumulative constraints",
      "title_zh": "è®ºç´¯ç§¯çº¦æŸçš„æ¨æ–­",
      "authors": [
        "Konstantin Sidorov"
      ],
      "abstract": "Cumulative constraints are central in scheduling with constraint programming, yet propagation is typically performed per constraint, missing multi-resource interactions and causing severe slowdowns on some benchmarks. I present a preprocessing method for inferring additional cumulative constraints that capture such interactions without search-time probing. This approach interprets cumulative constraints as linear inequalities over occupancy vectors and generates valid inequalities by (i) discovering covers, the sets of tasks that cannot run in parallel, (ii) strengthening the cover inequalities for the discovered sets with lifting, and (iii) injecting the resulting constraints back into the scheduling problem instance. Experiments on standard RCPSP and RCPSP/max test suites show that these inferred constraints improve search performance and tighten objective bounds on favorable instances, while incurring little degradation on unfavorable ones. Additionally, these experiments discover 25 new lower bounds and five new best solutions; eight of the lower bounds are obtained directly from the inferred constraints.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹çº¦æŸè§„åˆ’è°ƒåº¦ä¸­å› ç‹¬ç«‹å¤„ç†ç´¯ç§¯çº¦æŸï¼ˆcumulative constraintsï¼‰è€Œå¿½ç•¥å¤šèµ„æºäº¤äº’çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ— éœ€æœç´¢æ—¶æ¢æµ‹çš„é¢„å¤„ç†æ¨ç†æ–¹æ³•ã€‚è¯¥æ–¹æ³•å°†ç´¯ç§¯çº¦æŸè§£é‡Šä¸ºå ç”¨å‘é‡ä¸Šçš„çº¿æ€§ä¸ç­‰å¼ï¼Œé€šè¿‡å‘ç°ä¸å¯å¹¶è¡Œçš„ä»»åŠ¡é›†ï¼ˆcoversï¼‰ã€åˆ©ç”¨æå‡ï¼ˆliftingï¼‰æŠ€æœ¯å¼ºåŒ–è¦†ç›–ä¸ç­‰å¼ï¼Œå¹¶å°†ç”Ÿæˆçš„æœ‰æ•ˆä¸ç­‰å¼é‡æ–°æ³¨å…¥è°ƒåº¦é—®é¢˜å®ä¾‹ä¸­ã€‚åœ¨RCPSPå’ŒRCPSP/maxæ ‡å‡†æµ‹è¯•é›†çš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½æœ‰æ•ˆæå‡æœç´¢æ€§èƒ½å¹¶æ”¶ç´§ç›®æ ‡è¾¹ç•Œï¼Œåœ¨ç‰¹å®šå®ä¾‹ä¸­è¡¨ç°ä¼˜å¼‚ä¸”è´Ÿé¢å½±å“æå°ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶æˆåŠŸå‘ç°äº†25ä¸ªæ–°çš„ä¸‹ç•Œï¼ˆlower boundsï¼‰å’Œ5ä¸ªæ–°çš„æœ€ä½³è§£ï¼ˆbest solutionsï¼‰ï¼Œå…¶ä¸­8ä¸ªä¸‹ç•Œæ˜¯ç›´æ¥é€šè¿‡æ¨å¯¼å‡ºçš„çº¦æŸè·å¾—çš„ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "17 pages, 6 figures, 4 tables; submitted to the 32nd International Conference on Principles and Practice of Constraint Programming (CP 2026)",
      "pdf_url": "https://arxiv.org/pdf/2602.15635v1",
      "published_date": "2026-02-17 15:03:43 UTC",
      "updated_date": "2026-02-17 15:03:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:35:27.738374+00:00"
    },
    {
      "arxiv_id": "2602.15620v1",
      "title": "STAPO: Stabilizing Reinforcement Learning for LLMs by Silencing Rare Spurious Tokens",
      "title_zh": "STAPOï¼šé€šè¿‡æŠ‘åˆ¶ç¨€æœ‰ä¼ªæ ‡è®°æå‡å¤§è¯­è¨€æ¨¡å‹å¼ºåŒ–å­¦ä¹ çš„ç¨³å®šæ€§",
      "authors": [
        "Shiqi Liu",
        "Zeyu He",
        "Guojian Zhan",
        "Letian Tao",
        "Zhilong Zheng",
        "Jiang Wu",
        "Yinuo Wang",
        "Yang Guan",
        "Kehua Sheng",
        "Bo Zhang",
        "Keqiang Li",
        "Jingliang Duan",
        "Shengbo Eben Li"
      ],
      "abstract": "Reinforcement Learning (RL) has significantly improved large language model reasoning, but existing RL fine-tuning methods rely heavily on heuristic techniques such as entropy regularization and reweighting to maintain stability. In practice, they often experience late-stage performance collapse, leading to degraded reasoning quality and unstable training. We derive that the magnitude of token-wise policy gradients in RL is negatively correlated with token probability and local policy entropy. Building on this result, we prove that training instability is driven by a tiny fraction of tokens, approximately 0.01\\%, which we term \\emph{spurious tokens}. When such tokens appear in correct responses, they contribute little to the reasoning outcome but inherit the full sequence-level reward, leading to abnormally amplified gradient updates. Motivated by this observation, we propose Spurious-Token-Aware Policy Optimization (STAPO) for large-scale model refining, which selectively masks such updates and renormalizes the loss over valid tokens. Across six mathematical reasoning benchmarks using Qwen 1.7B, 8B, and 14B base models, STAPO consistently demonstrates superior entropy stability and achieves an average performance improvement of 7.13\\% over GRPO, 20-Entropy and JustRL.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)å¾®è°ƒè¿‡ç¨‹ä¸­é¢ä¸´çš„è®­ç»ƒä¸ç¨³å®šåŠåæœŸæ€§èƒ½å´©æºƒé—®é¢˜ï¼Œæå‡ºäº†åä¸ºSTAPOçš„ä¼˜åŒ–ç®—æ³•ã€‚ä½œè€…é€šè¿‡æ¨å¯¼å‘ç°ï¼ŒTokençº§åˆ«çš„ç­–ç•¥æ¢¯åº¦(Policy Gradients)æ¨¡é•¿ä¸Tokenæ¦‚ç‡åŠå±€éƒ¨ç­–ç•¥ç†µè´Ÿç›¸å…³ï¼Œå¹¶è¯†åˆ«å‡ºä»…å çº¦0.01%çš„â€œä¼ªTokenâ€(Spurious Tokens)æ˜¯å¼•å‘è®­ç»ƒä¸ç¨³å®šçš„æ ¸å¿ƒå› ç´ ã€‚è¿™äº›ä¼ªTokenè™½ç„¶å¯¹æ¨ç†é€»è¾‘è´¡çŒ®æœ‰é™ï¼Œå´å› ç»§æ‰¿äº†å®Œæ•´çš„åºåˆ—çº§å¥–åŠ±(Sequence-level Reward)è€Œäº§ç”Ÿå¼‚å¸¸æ”¾å¤§çš„æ¢¯åº¦æ›´æ–°ã€‚STAPOé€šè¿‡é€‰æ‹©æ€§å±è”½è¿™äº›ä¼ªTokençš„æ›´æ–°å¹¶å¯¹æœ‰æ•ˆTokençš„æŸå¤±è¿›è¡Œé‡å½’ä¸€åŒ–ï¼Œæ˜¾è‘—å¢å¼ºäº†æ¨¡å‹çš„ç†µç¨³å®šæ€§ã€‚åœ¨Qwenç³»åˆ—æ¨¡å‹ä¸Šçš„æ•°å­¦æ¨ç†åŸºå‡†æµ‹è¯•è¡¨æ˜ï¼ŒSTAPOç›¸è¾ƒäºGRPOã€20-Entropyå’ŒJustRLç­‰åŸºçº¿æ–¹æ³•ï¼Œå¹³å‡æ€§èƒ½æå‡äº†7.13%ï¼Œä¸ºæ„å»ºæ›´ç¨³å®šçš„è¯­è¨€æ¨¡å‹å¼ºåŒ–å­¦ä¹ æµç¨‹æä¾›äº†æ–°æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15620v1",
      "published_date": "2026-02-17 14:46:48 UTC",
      "updated_date": "2026-02-17 14:46:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:35:37.136336+00:00"
    },
    {
      "arxiv_id": "2602.15600v1",
      "title": "The geometry of online conversations and the causal antecedents of conflictual discourse",
      "title_zh": "åœ¨çº¿å¯¹è¯çš„å‡ ä½•ç»“æ„ä¸å†²çªæ€§è¯è¯­çš„å› æœå‰å› ",
      "authors": [
        "Carlo Santagiustina",
        "Caterina Cruciani"
      ],
      "abstract": "This article investigates the causal antecedents of conflictual language and the geometry of interaction in online threaded conversations related to climate change. We employ three annotation dimensions, inferred through LLM prompting and averaging, to capture complementary aspects of discursive conflict (such as stance: agreement vs disagreement; tone: attacking vs respectful; and emotional versus factual framing) and use data from a threaded online forum to examine how these dimensions respond to temporal, conversational, and arborescent structural features of discussions. We show that, as suggested by the literature, longer delays between successive posts in a thread are associated with replies that are, on average, more respectful, whereas longer delays relative to the parent post are associated with slightly less disagreement but more emotional (less factual) language. Second, we characterize alignment with the local conversational environment and find strong convergence both toward the average stance, tone and emotional framing of older sibling posts replying to the same parent and toward those of the parent post itself, with parent post effects generally stronger than sibling effects. We further show that early branch-level responses condition these alignment dynamics, such that parent-child stance alignment is amplified or attenuated depending on whether a branch is initiated in agreement or disagreement with the discussion's root message. These influences are largely additive for civility-related dimensions (attacking vs respectful, disagree vs agree), whereas for emotional versus factual framing there is a significant interaction: alignment with the parent's emotionality is amplified when older siblings are similarly aligned.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨çº¿çº¿ç´¢åŒ–å¯¹è¯(threaded conversations)ä¸­å†²çªæ€§è¯­è¨€çš„å› æœå‰å› åŠäº¤äº’å‡ ä½•ç»“æ„ï¼Œé‡ç‚¹å…³æ³¨æ°”å€™å˜åŒ–ç›¸å…³çš„è®¨è®ºã€‚ç ”ç©¶è€…åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(LLM)æ ‡æ³¨äº†ç«‹åœº(stance)ã€è¯­æ°”(tone)å’Œæƒ…æ„Ÿä¸äº‹å®æ¡†æ¶(emotional versus factual framing)ä¸‰ä¸ªç»´åº¦ï¼Œå¹¶åˆ†æäº†æ—¶é—´ã€å¯¹è¯åŠæ ‘çŠ¶ç»“æ„(arborescent structural)ç‰¹å¾å¯¹å†²çªçš„å½±å“ã€‚ç ”ç©¶å‘ç°ï¼Œå›å¤å»¶è¿Ÿæ—¶é—´è¶Šé•¿ï¼Œå…¶è¯­æ°”é€šå¸¸è¶Šå°Šé‡(respectful)ï¼›è€Œç›¸å¯¹äºçˆ¶å¸–(parent post)çš„å»¶è¿Ÿå¢åŠ è™½ä¼šç•¥å¾®å‡å°‘åˆ†æ­§ï¼Œä½†ä¼šå¢åŠ æƒ…æ„ŸåŒ–è¯­è¨€çš„ä½¿ç”¨ã€‚æ­¤å¤–ï¼Œä¸ªä½“å›å¤è¡¨ç°å‡ºå‘åŒçº§å¸–(sibling posts)å’Œçˆ¶å¸–çš„ç«‹åœºã€è¯­æ°”åŠæ¡†æ¶å¼ºåŠ›æ”¶æ•›çš„è¶‹åŠ¿ï¼Œä¸”çˆ¶å¸–çš„å½±å“é€šå¸¸å¤§äºåŒçº§å¸–ã€‚ç ”ç©¶è¿›ä¸€æ­¥æŒ‡å‡ºï¼Œæ—©æœŸåˆ†æ”¯å±‚çº§çš„å“åº”ä¼šè°ƒèŠ‚è¿™ç§å¯¹é½(alignment)åŠ¨æ€ï¼Œçˆ¶å­ç«‹åœºçš„å¯¹é½ç¨‹åº¦å–å†³äºåˆ†æ”¯èµ·å§‹æ—¶æ˜¯èµåŒè¿˜æ˜¯åå¯¹åˆå§‹æ¶ˆæ¯ã€‚åœ¨ç¤¼è²Œ(civility)ç›¸å…³ç»´åº¦ä¸Šè¿™äº›å½±å“ä¸»è¦å‘ˆåŠ æ€§ï¼Œè€Œåœ¨æƒ…æ„Ÿä¸äº‹å®æ¡†æ¶ç»´åº¦ä¸Šï¼Œå½“åŒçº§å¸–ä¸çˆ¶å¸–æƒ…æ„Ÿè¶‹åŒæ—¶ï¼Œè¿™ç§å¯¹é½æ•ˆåº”ä¼šæ˜¾è‘—å¢å¼ºã€‚",
      "categories": [
        "cs.SI",
        "cs.AI",
        "econ.EM",
        "stat.AP"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15600v1",
      "published_date": "2026-02-17 14:12:03 UTC",
      "updated_date": "2026-02-17 14:12:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:35:46.538926+00:00"
    },
    {
      "arxiv_id": "2602.15580v1",
      "title": "How Vision Becomes Language: A Layer-wise Information-Theoretic Analysis of Multimodal Reasoning",
      "title_zh": "è§†è§‰å¦‚ä½•è½¬åŒ–ä¸ºè¯­è¨€ï¼šå¤šæ¨¡æ€æ¨ç†çš„é€å±‚ä¿¡æ¯è®ºåˆ†æ",
      "authors": [
        "Hongxuan Wu",
        "Yukun Zhang",
        "Xueqing Zhou"
      ],
      "abstract": "When a multimodal Transformer answers a visual question, is the prediction driven by visual evidence, linguistic reasoning, or genuinely fused cross-modal computation -- and how does this structure evolve across layers? We address this question with a layer-wise framework based on Partial Information Decomposition (PID) that decomposes the predictive information at each Transformer layer into redundant, vision-unique, language-unique, and synergistic components. To make PID tractable for high-dimensional neural representations, we introduce \\emph{PID Flow}, a pipeline combining dimensionality reduction, normalizing-flow Gaussianization, and closed-form Gaussian PID estimation. Applying this framework to LLaVA-1.5-7B and LLaVA-1.6-7B across six GQA reasoning tasks, we uncover a consistent \\emph{modal transduction} pattern: visual-unique information peaks early and decays with depth, language-unique information surges in late layers to account for roughly 82\\% of the final prediction, and cross-modal synergy remains below 2\\%. This trajectory is highly stable across model variants (layer-wise correlations $>$0.96) yet strongly task-dependent, with semantic redundancy governing the detailed information fingerprint. To establish causality, we perform targeted Image$\\rightarrow$Question attention knockouts and show that disrupting the primary transduction pathway induces predictable increases in trapped visual-unique information, compensatory synergy, and total information cost -- effects that are strongest in vision-dependent tasks and weakest in high-redundancy tasks. Together, these results provide an information-theoretic, causal account of how vision becomes language in multimodal Transformers, and offer quantitative guidance for identifying architectural bottlenecks where modality-specific information is lost.",
      "tldr_zh": "è¯¥ç ”ç©¶é€šè¿‡å±‚çº§ä¿¡æ¯è®ºåˆ†æ(layer-wise information-theoretic analysis)ï¼Œæ¢è®¨äº†å¤šæ¨¡æ€Transformeråœ¨å¤„ç†è§†è§‰é—®ç­”æ—¶ï¼Œé¢„æµ‹ç»“æœç©¶ç«Ÿæ˜¯ç”±è§†è§‰è¯æ®ã€è¯­è¨€æ¨ç†è¿˜æ˜¯è·¨æ¨¡æ€èåˆé©±åŠ¨çš„ã€‚ä½œè€…æå‡ºäº†ä¸€ç§åŸºäºåä¿¡æ¯åˆ†è§£(Partial Information Decomposition, PID)çš„æ¡†æ¶ï¼Œå°†å„å±‚çš„é¢„æµ‹ä¿¡æ¯åˆ†è§£ä¸ºå†—ä½™ã€è§†è§‰ç‰¹æœ‰ã€è¯­è¨€ç‰¹æœ‰å’ŒååŒç»„ä»¶ã€‚ä¸ºäº†å¤„ç†é«˜ç»´ç¥ç»è¡¨ç¤ºï¼Œç ”ç©¶å¼•å…¥äº†PID Flowæµç¨‹ï¼Œç»“åˆäº†é™ç»´ã€å½’ä¸€åŒ–æµé«˜æ–¯åŒ–(normalizing-flow Gaussianization)å’Œé—­å¼é«˜æ–¯PIDä¼°è®¡æŠ€æœ¯ã€‚é€šè¿‡å¯¹LLaVA-1.5-7Bå’ŒLLaVA-1.6-7Båœ¨GQAæ¨ç†ä»»åŠ¡ä¸Šçš„å®éªŒï¼Œç ”ç©¶å‘ç°äº†ä¸€ç§ä¸€è‡´çš„â€œæ¨¡æ€è½¬åŒ–â€(modal transduction)æ¨¡å¼ã€‚ç»“æœè¡¨æ˜ï¼Œè§†è§‰ç‰¹æœ‰ä¿¡æ¯åœ¨æ—©æœŸè¾¾åˆ°å³°å€¼åéšæ·±åº¦è¡°å‡ï¼Œè€Œè¯­è¨€ç‰¹æœ‰ä¿¡æ¯åœ¨åæœŸæ¿€å¢å¹¶å æœ€ç»ˆé¢„æµ‹çš„çº¦82%ï¼Œè·¨æ¨¡æ€ååŒ(cross-modal synergy)åˆ™å§‹ç»ˆä½äº2%ã€‚è¯¥è½¨è¿¹åœ¨æ¨¡å‹å˜ä½“é—´é«˜åº¦ç¨³å®šï¼Œä½†å…¶å…·ä½“ä¿¡æ¯ç‰¹å¾å—ä»»åŠ¡ç±»å‹æ˜¾è‘—å½±å“ã€‚é€šè¿‡é’ˆå¯¹æ€§çš„å›¾åƒåˆ°é—®é¢˜(Image->Question)æ³¨æ„åŠ›å‰”é™¤å®éªŒï¼Œç ”ç©¶æ­ç¤ºäº†ç ´åè½¬åŒ–è·¯å¾„å¯¹ä¿¡æ¯æµåŠ¨çš„å› æœå½±å“ã€‚è¯¥æˆæœä¸ºè§†è§‰å¦‚ä½•åœ¨æ¨¡å‹ä¸­è½¬åŒ–ä¸ºè¯­è¨€æä¾›äº†ä¿¡æ¯è®ºè§†è§’çš„å› æœè§£é‡Šï¼Œå¹¶ä¸ºè¯†åˆ«æ¶æ„ç“¶é¢ˆæä¾›äº†å®šé‡æŒ‡å¯¼ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15580v1",
      "published_date": "2026-02-17 13:49:49 UTC",
      "updated_date": "2026-02-17 13:49:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:36:11.838131+00:00"
    },
    {
      "arxiv_id": "2602.15579v1",
      "title": "Intracoronary Optical Coherence Tomography Image Processing and Vessel Classification Using Machine Learning",
      "title_zh": "åŸºäºæœºå™¨å­¦ä¹ çš„å† çŠ¶åŠ¨è„‰å†…å…‰å­¦ç›¸å¹²æ–­å±‚æˆåƒå›¾åƒå¤„ç†ä¸è¡€ç®¡åˆ†ç±»",
      "authors": [
        "Amal Lahchim",
        "Lambros Athanasiou"
      ],
      "abstract": "Intracoronary Optical Coherence Tomography (OCT) enables high-resolution visualization of coronary vessel anatomy but presents challenges due to noise, imaging artifacts, and complex tissue structures. This paper proposes a fully automated pipeline for vessel segmentation and classification in OCT images using machine learning techniques. The proposed method integrates image preprocessing, guidewire artifact removal, polar-to-Cartesian transformation, unsupervised K-means clustering, and local feature extraction. These features are used to train Logistic Regression and Support Vector Machine classifiers for pixel-wise vessel classification. Experimental results demonstrate excellent performance, achieving precision, recall, and F1-score values up to 1.00 and overall classification accuracy of 99.68%. The proposed approach provides accurate vessel boundary detection while maintaining low computational complexity and requiring minimal manual annotation. This method offers a reliable and efficient solution for automated OCT image analysis and has potential applications in clinical decision support and real-time medical image processing.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å† çŠ¶åŠ¨è„‰è…”å†…å…‰å­¦ç›¸å¹²æ–­å±‚æ‰«æ (Optical Coherence Tomography, OCT) ä¸­å­˜åœ¨çš„å™ªå£°å’Œæˆåƒä¼ªå½±æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºæœºå™¨å­¦ä¹ æŠ€æœ¯çš„å…¨è‡ªåŠ¨è¡€ç®¡åˆ†å‰²ä¸åˆ†ç±»æµæ°´çº¿ (fully automated pipeline)ã€‚è¯¥æ–¹æ³•é›†æˆäº†å›¾åƒé¢„å¤„ç†ã€å¯¼ä¸ä¼ªå½±å»é™¤ (guidewire artifact removal)ã€æåæ ‡åˆ°ç¬›å¡å°”åæ ‡å˜æ¢ (polar-to-Cartesian transformation)ã€æ— ç›‘ç£ K-means èšç±»ä»¥åŠå±€éƒ¨ç‰¹å¾æå–ç­‰å…³é”®æ­¥éª¤ã€‚é€šè¿‡è®­ç»ƒé€»è¾‘å›å½’ (Logistic Regression) å’Œæ”¯æŒå‘é‡æœº (Support Vector Machine, SVM) åˆ†ç±»å™¨ï¼Œç³»ç»Ÿå®ç°äº†é«˜ç²¾åº¦çš„åƒç´ çº§è¡€ç®¡åˆ†ç±»ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å‡†ç¡®ç‡ã€å¬å›ç‡å’Œ F1 åˆ†æ•°ä¸Šæœ€é«˜å‡è¾¾åˆ° 1.00ï¼Œæ•´ä½“åˆ†ç±»å‡†ç¡®ç‡é«˜è¾¾ 99.68%ã€‚è¯¥æ–¹æ¡ˆåœ¨ä¿è¯ç²¾ç¡®æ£€æµ‹è¡€ç®¡è¾¹ç•Œçš„åŒæ—¶ï¼Œç»´æŒäº†è¾ƒä½çš„è®¡ç®—å¤æ‚åº¦ï¼Œå¹¶æ˜¾è‘—å‡å°‘äº†å¯¹äººå·¥æ ‡æ³¨çš„éœ€æ±‚ã€‚è¯¥ç ”ç©¶ä¸ºè‡ªåŠ¨åŒ– OCT å›¾åƒåˆ†ææä¾›äº†å¯é é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆï¼Œåœ¨ä¸´åºŠå†³ç­–æ”¯æŒå’Œå®æ—¶åŒ»å­¦å›¾åƒå¤„ç†é¢†åŸŸå±•ç°å‡ºé‡è¦çš„åº”ç”¨æ½œåŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 8 figures. Research paper from Electrical and Computer Engineering Department, University of Patras",
      "pdf_url": "https://arxiv.org/pdf/2602.15579v1",
      "published_date": "2026-02-17 13:47:27 UTC",
      "updated_date": "2026-02-17 13:47:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:36:19.845010+00:00"
    },
    {
      "arxiv_id": "2602.15564v1",
      "title": "Beyond Static Pipelines: Learning Dynamic Workflows for Text-to-SQL",
      "title_zh": "è¶…è¶Šé™æ€æµæ°´çº¿ï¼šé¢å‘ Text-to-SQL çš„åŠ¨æ€å·¥ä½œæµå­¦ä¹ ",
      "authors": [
        "Yihan Wang",
        "Peiyu Liu",
        "Runyu Chen",
        "Wei Xu"
      ],
      "abstract": "Text-to-SQL has recently achieved impressive progress, yet remains difficult to apply effectively in real-world scenarios. This gap stems from the reliance on single static workflows, fundamentally limiting scalability to out-of-distribution and long-tail scenarios. Instead of requiring users to select suitable methods through extensive experimentation, we attempt to enable systems to adaptively construct workflows at inference time. Through theoretical and empirical analysis, we demonstrate that optimal dynamic policies consistently outperform the best static workflow, with performance gains fundamentally driven by heterogeneity across candidate workflows. Motivated by this, we propose SquRL, a reinforcement learning framework that enhances LLMs' reasoning capability in adaptive workflow construction. We design a rule-based reward function and introduce two effective training mechanisms: dynamic actor masking to encourage broader exploration, and pseudo rewards to improve training efficiency. Experiments on widely-used Text-to-SQL benchmarks demonstrate that dynamic workflow construction consistently outperforms the best static workflow methods, with especially pronounced gains on complex and out-of-distribution queries. The codes are available at https://github.com/Satissss/SquRL",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Text-to-SQL åœ¨ç°å®åœºæ™¯ä¸­å› ä¾èµ–é™æ€å·¥ä½œæµ (static workflows) å¯¼è‡´åœ¨åˆ†å¸ƒå¤– (out-of-distribution) å’Œé•¿å°¾åœºæ™¯æ‰©å±•æ€§å—é™çš„é—®é¢˜ï¼Œæå‡ºäº† SquRL æ¡†æ¶ã€‚SquRL æ˜¯ä¸€ä¸ªåŸºäºå¼ºåŒ–å­¦ä¹  (reinforcement learning) çš„æ¡†æ¶ï¼Œæ—¨åœ¨æå‡å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨æ¨ç†é˜¶æ®µè‡ªé€‚åº”æ„å»ºå·¥ä½œæµçš„æ¨ç†èƒ½åŠ›ã€‚ç ”ç©¶è€…è®¾è®¡äº†åŸºäºè§„åˆ™çš„å¥–åŠ±å‡½æ•°ï¼Œå¹¶å¼•å…¥äº†åŠ¨æ€æ¼”å‘˜æ©ç  (dynamic actor masking) ä»¥ä¿ƒè¿›å¹¿æ³›æ¢ç´¢ï¼Œä»¥åŠä¼ªå¥–åŠ± (pseudo rewards) æ¥æé«˜è®­ç»ƒæ•ˆç‡ã€‚ç†è®ºå’Œå®è¯åˆ†æè¡¨æ˜ï¼ŒåŠ¨æ€ç­–ç•¥åœ¨æ€§èƒ½ä¸Šå§‹ç»ˆä¼˜äºæœ€ä½³é™æ€å·¥ä½œæµï¼Œå°¤å…¶åœ¨å¤„ç†å¤æ‚å’Œåˆ†å¸ƒå¤–æŸ¥è¯¢æ—¶è¡¨ç°å‡ºæ˜¾è‘—çš„å¢ç›Šã€‚è¯¥å·¥ä½œè¯æ˜äº†é€šè¿‡æ¨ç†æ—¶è‡ªé€‚åº”æ„å»ºå·¥ä½œæµï¼Œå¯ä»¥æœ‰æ•ˆå¼¥åˆ Text-to-SQL æŠ€æœ¯åœ¨å®é™…åº”ç”¨ä¸­çš„æ€§èƒ½å·®è·ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15564v1",
      "published_date": "2026-02-17 13:24:56 UTC",
      "updated_date": "2026-02-17 13:24:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:36:14.534409+00:00"
    },
    {
      "arxiv_id": "2602.15553v1",
      "title": "RUVA: Personalized Transparent On-Device Graph Reasoning",
      "title_zh": "RUVAï¼šä¸ªæ€§åŒ–ä¸”é€æ˜çš„ç«¯ä¾§å›¾æ¨ç†",
      "authors": [
        "Gabriele Conte",
        "Alessio Mattiace",
        "Gianni Carmosino",
        "Potito Aghilar",
        "Giovanni Servedio",
        "Francesco Musicco",
        "Vito Walter Anelli",
        "Tommaso Di Noia",
        "Francesco Maria Donini"
      ],
      "abstract": "The Personal AI landscape is currently dominated by \"Black Box\" Retrieval-Augmented Generation. While standard vector databases offer statistical matching, they suffer from a fundamental lack of accountability: when an AI hallucinates or retrieves sensitive data, the user cannot inspect the cause nor correct the error. Worse, \"deleting\" a concept from a vector space is mathematically imprecise, leaving behind probabilistic \"ghosts\" that violate true privacy. We propose Ruva, the first \"Glass Box\" architecture designed for Human-in-the-Loop Memory Curation. Ruva grounds Personal AI in a Personal Knowledge Graph, enabling users to inspect what the AI knows and to perform precise redaction of specific facts. By shifting the paradigm from Vector Matching to Graph Reasoning, Ruva ensures the \"Right to be Forgotten.\" Users are the editors of their own lives; Ruva hands them the pen. The project and the demo video are available at http://sisinf00.poliba.it/ruva/.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å½“å‰ä¸ªäººäººå·¥æ™ºèƒ½ä¸­â€œé»‘ç›’â€å¼æ£€ç´¢å¢å¼ºç”Ÿæˆ(Retrieval-Augmented Generation)å­˜åœ¨çš„ä¸å¯è§£é‡Šæ€§ã€éš¾ä»¥çº é”™åŠéšç§æ¸…é™¤ä¸å½»åº•ç­‰é—®é¢˜ï¼Œæå‡ºäº†é¦–ä¸ªä¸ºäººå·¥ç¯è·¯è®°å¿†ç­–å±•(Human-in-the-Loop Memory Curation)è®¾è®¡çš„â€œç»ç’ƒç›’â€(Glass Box)æ¶æ„Ruvaã€‚Ruvaé€šè¿‡å°†ä¸ªäººäººå·¥æ™ºèƒ½å»ºç«‹åœ¨ä¸ªäººçŸ¥è¯†å›¾è°±(Personal Knowledge Graph)ä¹‹ä¸Šï¼Œå®ç°äº†ä»ä¼ ç»Ÿçš„å‘é‡åŒ¹é…(Vector Matching)å‘å›¾æ¨ç†(Graph Reasoning)çš„èŒƒå¼è½¬å˜ã€‚è¿™ç§è®¾è®¡å…è®¸ç”¨æˆ·ç›´è§‚åœ°æ£€æŸ¥äººå·¥æ™ºèƒ½æŒæ¡çš„çŸ¥è¯†ï¼Œå¹¶å¯¹ç‰¹å®šäº‹å®è¿›è¡Œç²¾ç¡®çš„åˆ å‡ï¼Œä»è€Œèµ‹äºˆç”¨æˆ·çœŸæ­£çš„â€œè¢«é—å¿˜æƒâ€(Right to be Forgotten)ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ¶æ„èƒ½æœ‰æ•ˆæ¶ˆé™¤å‘é‡ç©ºé—´ä¸­éš¾ä»¥å¤„ç†çš„æ¦‚ç‡æ€§æ®‹ç•™ï¼Œç¡®ä¿äº†ä¸ªäººæ•°æ®çš„å¯æ§æ€§ä¸é€æ˜åº¦ã€‚Ruvaä¸ä»…æå‡äº†è®¾å¤‡ç«¯æ¨ç†çš„é—®è´£åˆ¶ï¼Œè¿˜ä¸ºæ„å»ºéšç§ä¿æŠ¤çš„ä¸ªæ€§åŒ–AIåŠ©ç†æä¾›äº†å…¨æ–°çš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15553v1",
      "published_date": "2026-02-17 12:59:03 UTC",
      "updated_date": "2026-02-17 12:59:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:36:33.850211+00:00"
    },
    {
      "arxiv_id": "2602.15549v1",
      "title": "VLM-DEWM: Dynamic External World Model for Verifiable and Resilient Vision-Language Planning in Manufacturing",
      "title_zh": "VLM-DEWMï¼šé¢å‘åˆ¶é€ ä¸šä¸­å¯éªŒè¯ä¸”å…·éŸ§æ€§è§†è§‰è¯­è¨€è§„åˆ’çš„åŠ¨æ€å¤–éƒ¨ä¸–ç•Œæ¨¡å‹",
      "authors": [
        "Guoqin Tang",
        "Qingxuan Jia",
        "Gang Chen",
        "Tong Li",
        "Zeyuan Huang",
        "Zihang Lv",
        "Ning Ji"
      ],
      "abstract": "Vision-language model (VLM) shows promise for high-level planning in smart manufacturing, yet their deployment in dynamic workcells faces two critical challenges: (1) stateless operation, they cannot persistently track out-of-view states, causing world-state drift; and (2) opaque reasoning, failures are difficult to diagnose, leading to costly blind retries. This paper presents VLM-DEWM, a cognitive architecture that decouples VLM reasoning from world-state management through a persistent, queryable Dynamic External World Model (DEWM). Each VLM decision is structured into an Externalizable Reasoning Trace (ERT), comprising action proposal, world belief, and causal assumption, which is validated against DEWM before execution. When failures occur, discrepancy analysis between predicted and observed states enables targeted recovery instead of global replanning. We evaluate VLM-DEWM on multi-station assembly, large-scale facility exploration, and real-robot recovery under induced failures. Compared to baseline memory-augmented VLM systems, VLM DEWM improves state-tracking accuracy from 56% to 93%, increases recovery success rate from below 5% to 95%, and significantly reduces computational overhead through structured memory. These results establish VLM-DEWM as a verifiable and resilient solution for long-horizon robotic operations in dynamic manufacturing environments.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† VLM-DEWMï¼Œä¸€ç§æ—¨åœ¨è§£å†³è§†è§‰è¯­è¨€æ¨¡å‹ (VLM) åœ¨æ™ºèƒ½åˆ¶é€ é¢†åŸŸé¢ä¸´çš„æ— çŠ¶æ€æ“ä½œå¯¼è‡´çš„çŠ¶æ€æ¼‚ç§»ï¼Œä»¥åŠæ¨ç†è¿‡ç¨‹ä¸é€æ˜å¯¼è‡´æ•…éšœéš¾ä»¥è¯Šæ–­ç­‰æ ¸å¿ƒæŒ‘æˆ˜çš„è®¤çŸ¥æ¶æ„ã€‚è¯¥æ¡†æ¶é€šè¿‡å¼•å…¥ä¸€ä¸ªæŒä¹…ä¸”å¯æŸ¥è¯¢çš„åŠ¨æ€å¤–éƒ¨ä¸–ç•Œæ¨¡å‹ (Dynamic External World Model, DEWM)ï¼Œå°† VLM çš„æ¨ç†è¿‡ç¨‹ä¸ä¸–ç•ŒçŠ¶æ€ç®¡ç†è§£è€¦ã€‚æ¯ä¸€ä¸ªå†³ç­–éƒ½è¢«ç»“æ„åŒ–ä¸ºåŒ…å«åŠ¨ä½œæè®®ã€ä¸–ç•Œä¿¡å¿µå’Œå› æœå‡è®¾çš„å¯å¤–éƒ¨åŒ–æ¨ç†è¿½è¸ª (Externalizable Reasoning Trace, ERT)ï¼Œå¹¶åœ¨æ‰§è¡Œå‰é€šè¿‡ DEWM è¿›è¡ŒéªŒè¯ã€‚å½“ä»»åŠ¡å¤±è´¥æ—¶ï¼Œç³»ç»Ÿåˆ©ç”¨é¢„æµ‹ä¸è§‚æµ‹çŠ¶æ€ä¹‹é—´çš„å·®å¼‚åˆ†æå®ç°ç²¾å‡†çš„ç›®æ ‡æ¢å¤ï¼Œä»è€Œé¿å…äº†æ˜‚è´µçš„å…¨å±€é‡æ–°è§„åˆ’ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒVLM-DEWM å°†çŠ¶æ€è·Ÿè¸ªå‡†ç¡®ç‡ä» 56% æå‡è‡³ 93%ï¼Œå¹¶å°†æ¢å¤æˆåŠŸç‡ä» 5% ä»¥ä¸‹æé«˜åˆ° 95%ï¼ŒåŒæ—¶æ˜¾è‘—é™ä½äº†è®¡ç®—å¼€é”€ã€‚è¯¥ç ”ç©¶ä¸ºåŠ¨æ€åˆ¶é€ ç¯å¢ƒä¸‹é•¿ç¨‹æœºå™¨äººæ“ä½œæä¾›äº†ä¸€ç§å¯éªŒè¯ä¸”å…·æœ‰éŸ§æ€§çš„é«˜æ•ˆè§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15549v1",
      "published_date": "2026-02-17 12:54:18 UTC",
      "updated_date": "2026-02-17 12:54:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:36:26.544186+00:00"
    },
    {
      "arxiv_id": "2602.15539v1",
      "title": "Dynamic Training-Free Fusion of Subject and Style LoRAs",
      "title_zh": "ä¸»ä½“ä¸é£æ ¼ LoRA çš„åŠ¨æ€å…è®­ç»ƒèåˆ",
      "authors": [
        "Qinglong Cao",
        "Yuntian Chen",
        "Chao Ma",
        "Xiaokang Yang"
      ],
      "abstract": "Recent studies have explored the combination of multiple LoRAs to simultaneously generate user-specified subjects and styles. However, most existing approaches fuse LoRA weights using static statistical heuristics that deviate from LoRA's original purpose of learning adaptive feature adjustments and ignore the randomness of sampled inputs. To address this, we propose a dynamic training-free fusion framework that operates throughout the generation process. During the forward pass, at each LoRA-applied layer, we dynamically compute the KL divergence between the base model's original features and those produced by subject and style LoRAs, respectively, and adaptively select the most appropriate weights for fusion. In the reverse denoising stage, we further refine the generation trajectory by dynamically applying gradient-based corrections derived from objective metrics such as CLIP and DINO scores, providing continuous semantic and stylistic guidance. By integrating these two complementary mechanisms-feature-level selection and metric-guided latent adjustment-across the entire diffusion timeline, our method dynamically achieves coherent subject-style synthesis without any retraining. Extensive experiments across diverse subject-style combinations demonstrate that our approach consistently outperforms state-of-the-art LoRA fusion methods both qualitatively and quantitatively.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰å¤š LoRA èåˆæ–¹æ³•å¤šé‡‡ç”¨é™æ€å¯å‘å¼æƒé‡ï¼Œå¿½ç•¥äº†ç‰¹å¾è°ƒæ•´çš„è‡ªé€‚åº”æ€§å’Œé‡‡æ ·è¾“å…¥éšæœºæ€§ç­‰é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ— éœ€è®­ç»ƒçš„åŠ¨æ€èåˆæ¡†æ¶ã€‚åœ¨å‰å‘ä¼ æ’­é˜¶æ®µï¼Œè¯¥æ¡†æ¶é€šè¿‡åœ¨æ¯ä¸ª LoRA åº”ç”¨å±‚åŠ¨æ€è®¡ç®—åŸºç¡€æ¨¡å‹ä¸ä¸»ä½“åŠé£æ ¼ LoRA ç‰¹å¾ä¹‹é—´çš„ KL divergenceï¼Œè‡ªé€‚åº”åœ°é€‰æ‹©æœ€åˆé€‚çš„èåˆæƒé‡ã€‚åœ¨é€†å‘å»å™ªé˜¶æ®µï¼Œç ”ç©¶è¿›ä¸€æ­¥åˆ©ç”¨åŸºäº CLIP å’Œ DINO è¯„åˆ†çš„æ¢¯åº¦æ ¡æ­£æœºåˆ¶ï¼Œåœ¨æ•´ä¸ª diffusion timeline ä¸­æä¾›æŒç»­çš„è¯­ä¹‰å’Œé£æ ¼å¼•å¯¼ã€‚é€šè¿‡æ•´åˆç‰¹å¾çº§é€‰æ‹©å’ŒæŒ‡æ ‡å¼•å¯¼çš„ latent adjustment è¿™ä¸¤ç§äº’è¡¥æœºåˆ¶ï¼Œè¯¥æ–¹æ³•åœ¨æ— éœ€ä»»ä½•é‡æ–°è®­ç»ƒçš„æƒ…å†µä¸‹å®ç°äº†é«˜åº¦è¿è´¯çš„ä¸»ä½“ä¸é£æ ¼åˆæˆã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šæ ·åŒ–çš„ç»„åˆåœºæ™¯ä¸‹ï¼Œå…¶å®šæ€§å’Œå®šé‡æŒ‡æ ‡å‡æ˜¾è‘—ä¼˜äºç›®å‰çš„ state-of-the-art èåˆæ–¹æ³•ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.SC"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15539v1",
      "published_date": "2026-02-17 12:42:30 UTC",
      "updated_date": "2026-02-17 12:42:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:37:13.847460+00:00"
    },
    {
      "arxiv_id": "2602.15532v1",
      "title": "Quantifying construct validity in large language model evaluations",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹è¯„ä¼°ä¸­çš„æ„å¿µæ•ˆåº¦é‡åŒ–",
      "authors": [
        "Ryan Othniel Kearns"
      ],
      "abstract": "The LLM community often reports benchmark results as if they are synonymous with general model capabilities. However, benchmarks can have problems that distort performance, like test set contamination and annotator error. How can we know that a benchmark is a reliable indicator of some capability that we want to measure? This question concerns the construct validity of LLM benchmarks, and it requires separating benchmark results from capabilities when we model and predict LLM performance.\n  Both social scientists and computer scientists propose formal models - latent factor models and scaling laws - for identifying the capabilities underlying benchmark scores. However, neither technique is satisfactory for construct validity. Latent factor models ignore scaling laws, and as a result, the capabilities they extract often proxy model size. Scaling laws ignore measurement error, and as a result, the capabilities they extract are both uninterpretable and overfit to the observed benchmarks.\n  This thesis presents the structured capabilities model, the first model to extract interpretable and generalisable capabilities from a large collection of LLM benchmark results. I fit this model and its two alternatives on a large sample of results from the OpenLLM Leaderboard. Structured capabilities outperform latent factor models on parsimonious fit indices, and exhibit better out-of-distribution benchmark prediction than scaling laws. These improvements are possible because neither existing approach separates model scale from capabilities in the appropriate way. Model scale should inform capabilities, as in scaling laws, and these capabilities should inform observed results up to measurement error, as in latent factor models. In combining these two insights, structured capabilities demonstrate better explanatory and predictive power for quantifying construct validity in LLM evaluations.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹(LLM)è¯„ä¼°ä¸­çš„æ„å¿µæ•ˆåº¦(construct validity)é—®é¢˜ï¼Œæ—¨åœ¨è§£å†³åŸºå‡†æµ‹è¯•ç»“æœä¸æ¨¡å‹å®é™…èƒ½åŠ›ä¹‹é—´å¯èƒ½å­˜åœ¨çš„è„±èŠ‚ã€‚ä½œè€…åˆ†ææŒ‡å‡ºï¼Œç°æœ‰çš„æ½œåœ¨å› å­æ¨¡å‹(latent factor models)å¿½è§†äº†ç¼©æ”¾æ³•åˆ™(scaling laws)ï¼Œè€Œç¼©æ”¾æ³•åˆ™åˆå¿½è§†äº†æµ‹é‡è¯¯å·®ï¼Œå¯¼è‡´ä¸¤è€…åœ¨è¡¡é‡æ„å¿µæ•ˆåº¦æ—¶å‡ä¸ç†æƒ³ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ç»“æ„åŒ–èƒ½åŠ›æ¨¡å‹(structured capabilities model)ï¼Œè¿™æ˜¯é¦–ä¸ªèƒ½ä»å¤§è§„æ¨¡åŸºå‡†æµ‹è¯•ç»“æœä¸­æå–å¯è§£é‡Šä¸”å…·æ³›åŒ–æ€§èƒ½åŠ›çš„æ¨¡å‹ã€‚è¯¥æ¨¡å‹åˆ›æ–°æ€§åœ°å°†æ¨¡å‹è§„æ¨¡(model scale)ä¸èƒ½åŠ›è¿›è¡Œåˆ†ç¦»ï¼Œå¹¶ç»“åˆæµ‹é‡è¯¯å·®æ¥å»ºæ¨¡è§‚å¯Ÿç»“æœã€‚åœ¨OpenLLM Leaderboardçš„æ•°æ®é›†å®éªŒä¸­ï¼Œè¯¥æ¨¡å‹åœ¨æ‹ŸåˆæŒ‡æ ‡ä¸Šä¼˜äºæ½œåœ¨å› å­æ¨¡å‹ï¼Œå¹¶åœ¨åˆ†å¸ƒå¤–(out-of-distribution)åŸºå‡†æµ‹è¯•é¢„æµ‹æ–¹é¢è¡¨ç°ä¼˜äºç¼©æ”¾æ³•åˆ™ã€‚é€šè¿‡èåˆä¸Šè¿°ä¸¤ç§æ–¹æ³•çš„ä¼˜åŠ¿ï¼Œç»“æ„åŒ–èƒ½åŠ›æ¨¡å‹ä¸ºé‡åŒ–LLMè¯„ä¼°çš„æ„å¿µæ•ˆåº¦æä¾›äº†æ›´å¼ºçš„è§£é‡ŠåŠ›å’Œé¢„æµ‹åŠ›ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15532v1",
      "published_date": "2026-02-17 12:15:57 UTC",
      "updated_date": "2026-02-17 12:15:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:37:14.548770+00:00"
    },
    {
      "arxiv_id": "2602.15531v1",
      "title": "GenAI-LA: Generative AI and Learning Analytics Workshop (LAK 2026), April 27--May 1, 2026, Bergen, Norway",
      "title_zh": "GenAI-LAï¼šç”Ÿæˆå¼äººå·¥æ™ºèƒ½ä¸å­¦ä¹ åˆ†æç ”è®¨ä¼š (LAK 2026)ï¼Œ2026å¹´4æœˆ27æ—¥â€“5æœˆ1æ—¥ï¼ŒBergen, Norway",
      "authors": [
        "Javier Irigoyen",
        "Roberto Daza",
        "Aythami Morales",
        "Julian Fierrez",
        "Francisco Jurado",
        "Alvaro Ortigosa",
        "Ruben Tolosana"
      ],
      "abstract": "This work introduces EduEVAL-DB, a dataset based on teacher roles designed to support the evaluation and training of automatic pedagogical evaluators and AI tutors for instructional explanations. The dataset comprises 854 explanations corresponding to 139 questions from a curated subset of the ScienceQA benchmark, spanning science, language, and social science across K-12 grade levels. For each question, one human-teacher explanation is provided and six are generated by LLM-simulated teacher roles. These roles are inspired by instructional styles and shortcomings observed in real educational practice and are instantiated via prompt engineering. We further propose a pedagogical risk rubric aligned with established educational standards, operationalizing five complementary risk dimensions: factual correctness, explanatory depth and completeness, focus and relevance, student-level appropriateness, and ideological bias. All explanations are annotated with binary risk labels through a semi-automatic process with expert teacher review. Finally, we present preliminary validation experiments to assess the suitability of EduEVAL-DB for evaluation. We benchmark a state-of-the-art education-oriented model (Gemini 2.5 Pro) against a lightweight local Llama 3.1 8B model and examine whether supervised fine-tuning on EduEVAL-DB supports pedagogical risk detection using models deployable on consumer hardware.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† EduEVAL-DBï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºæ•™å¸ˆè§’è‰²è®¾è®¡çš„æ•™è‚²æ•°æ®é›†ï¼Œæ—¨åœ¨æ”¯æŒå¯¹æ•™å­¦è§£é‡Šä¸­çš„è‡ªåŠ¨æ•™å­¦è¯„ä¼°å™¨å’Œ AI tutors è¿›è¡Œè¯„ä¼°å’Œè®­ç»ƒã€‚è¯¥æ•°æ®é›†åŒ…å«é’ˆå¯¹ ScienceQA åŸºå‡†å­é›†ä¸­ 139 ä¸ªé—®é¢˜çš„ 854 æ¡æ•™å­¦è§£é‡Šï¼Œæ¶µç›–äº† K-12 é˜¶æ®µçš„ç§‘å­¦ã€è¯­è¨€å’Œç¤¾ä¼šç§‘å­¦ã€‚é™¤äº†äººç±»æ•™å¸ˆçš„è§£é‡Šå¤–ï¼Œç ”ç©¶è¿˜åˆ©ç”¨ prompt engineering æ¨¡æ‹Ÿäº†å…­ç§å—çœŸå®æ•™è‚²å®è·µå¯å‘çš„æ•™å¸ˆè§’è‰²ï¼Œä»¥ç”Ÿæˆå¤šæ ·åŒ–çš„æ•™å­¦æ–‡æœ¬ã€‚ä¸ºäº†é‡åŒ–æ•™å­¦è´¨é‡ï¼Œç ”ç©¶æå‡ºäº†ä¸€ä¸ªåŒ…å«äº”ä¸ªç»´åº¦çš„ pedagogical risk rubricï¼Œæ¶µç›–äº†äº‹å®å‡†ç¡®æ€§ã€è§£é‡Šæ·±åº¦ã€ç›¸å…³æ€§ã€å­¦ç”Ÿé€‚å®œæ€§åŠæ„è¯†å½¢æ€åè§ï¼Œå¹¶ç»ç”±ä¸“å®¶å®¡æ ¸å®Œæˆäº†é£é™©æ ‡æ³¨ã€‚éªŒè¯å®éªŒå¯¹æ¯”äº†é¡¶çº§æ¨¡å‹ Gemini 2.5 Pro ä¸è½»é‡çº§æ¨¡å‹ Llama 3.1 8B çš„æ€§èƒ½ï¼Œè¯æ˜äº†åœ¨ EduEVAL-DB ä¸Šè¿›è¡Œç›‘ç£å¾®è°ƒï¼ˆsupervised fine-tuningï¼‰èƒ½æœ‰æ•ˆæ”¯æŒåœ¨æ¶ˆè´¹çº§ç¡¬ä»¶ä¸Šå®ç°æ•™å­¦é£é™©æ£€æµ‹ã€‚",
      "categories": [
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 3 figures. Published in Intl. Conf. on Learning Analytics & Knowledge Workshops (LAK Workshops 2026, GenAI-LA 26)",
      "pdf_url": "https://arxiv.org/pdf/2602.15531v1",
      "published_date": "2026-02-17 12:11:49 UTC",
      "updated_date": "2026-02-17 12:11:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:37:31.145313+00:00"
    },
    {
      "arxiv_id": "2602.15515v1",
      "title": "The Obfuscation Atlas: Mapping Where Honesty Emerges in RLVR with Deception Probes",
      "title_zh": "æ¬ºéª—å›¾è°±ï¼šåœ¨å¼ºåŒ–å­¦ä¹ éªŒè¯ä¸æ¨ç†ï¼ˆRLVRï¼‰ä¸­åˆ©ç”¨æ¬ºéª—æ¢æµ‹å™¨æ˜ å°„è¯šå®æµ®ç°çš„è¾¹ç•Œ",
      "authors": [
        "Mohammad Taufeeque",
        "Stefan Heimersheim",
        "Adam Gleave",
        "Chris Cundy"
      ],
      "abstract": "Training against white-box deception detectors has been proposed as a way to make AI systems honest. However, such training risks models learning to obfuscate their deception to evade the detector. Prior work has studied obfuscation only in artificial settings where models were directly rewarded for harmful output. We construct a realistic coding environment where reward hacking via hardcoding test cases naturally occurs, and show that obfuscation emerges in this setting. We introduce a taxonomy of possible outcomes when training against a deception detector. The model either remains honest, or becomes deceptive via two possible obfuscation strategies. (i) Obfuscated activations: the model outputs deceptive text while modifying its internal representations to no longer trigger the detector. (ii) Obfuscated policy: the model outputs deceptive text that evades the detector, typically by including a justification for the reward hack. Empirically, obfuscated activations arise from representation drift during RL, with or without a detector penalty. The probe penalty only incentivizes obfuscated policies; we theoretically show this is expected for policy gradient methods. Sufficiently high KL regularization and detector penalty can yield honest policies, establishing white-box deception detectors as viable training signals for tasks prone to reward hacking.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†é€šè¿‡å¯¹æŠ—ç™½ç›’(white-box)æ¬ºéª—æ¢æµ‹å™¨è®­ç»ƒæ¥æå‡AIç³»ç»Ÿè¯šå®æ€§çš„æ–¹æ³•ï¼Œå¹¶æ·±å…¥åˆ†æäº†æ¨¡å‹ä¸ºè§„é¿æ£€æµ‹è€Œäº§ç”Ÿæ¨¡ç³ŠåŒ–(obfuscation)è¡Œä¸ºçš„é£é™©ã€‚ç ”ç©¶åœ¨å­˜åœ¨å¥–åŠ±é»‘å®¢(reward hacking)é£é™©çš„ç¼–ç¨‹ç¯å¢ƒä¸­ï¼Œå®šä¹‰äº†RLVRè®­ç»ƒåçš„ä¸‰ç§ç»“æœï¼Œå³è¯šå®ç­–ç•¥ã€æ¨¡ç³ŠåŒ–æ¿€æ´»(obfuscated activations)åŠæ¨¡ç³ŠåŒ–ç­–ç•¥(obfuscated policy)ã€‚å®éªŒå‘ç°æ¨¡ç³ŠåŒ–æ¿€æ´»ä¸»è¦æºäºå¼ºåŒ–å­¦ä¹ ä¸­çš„è¡¨ç¤ºæ¼‚ç§»ï¼Œè€Œæ¢æµ‹å™¨æƒ©ç½šåˆ™å®¹æ˜“è¯±å¯¼æ¨¡å‹äº§ç”Ÿå¸¦æœ‰è¾©è§£æ€§çš„æ¨¡ç³ŠåŒ–ç­–ç•¥ã€‚é€šè¿‡ç†è®ºä¸å®è¯åˆ†æï¼Œç ”ç©¶è¯æ˜åœ¨åº”ç”¨è¶³å¤Ÿé«˜çš„KLæ­£åˆ™åŒ–å’Œæ¢æµ‹å™¨æƒ©ç½šæ—¶ï¼Œå¯ä»¥å¼•å¯¼æ¨¡å‹äº§ç”ŸçœŸæ­£çš„è¯šå®ç­–ç•¥ã€‚è¿™ä¸€ç ”ç©¶æˆæœç¡®ç«‹äº†ç™½ç›’æ¬ºéª—æ¢æµ‹å™¨åœ¨æ˜“å‘ç”Ÿå¥–åŠ±é»‘å®¢çš„ä»»åŠ¡ä¸­ä½œä¸ºæœ‰æ•ˆè®­ç»ƒä¿¡å·çš„å¯è¡Œæ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "25 pages, 12 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.15515v1",
      "published_date": "2026-02-17 11:44:10 UTC",
      "updated_date": "2026-02-17 11:44:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:37:20.039067+00:00"
    },
    {
      "arxiv_id": "2602.15513v1",
      "title": "Improving MLLMs in Embodied Exploration and Question Answering with Human-Inspired Memory Modeling",
      "title_zh": "å€Ÿé‰´äººç±»è®°å¿†å»ºæ¨¡æå‡å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨å…·èº«æ¢ç´¢ä¸é—®ç­”ä¸­çš„è¡¨ç°",
      "authors": [
        "Ji Li",
        "Jing Xia",
        "Mingyi Li",
        "Shiyan Hu"
      ],
      "abstract": "Deploying Multimodal Large Language Models as the brain of embodied agents remains challenging, particularly under long-horizon observations and limited context budgets. Existing memory assisted methods often rely on textual summaries, which discard rich visual and spatial details and remain brittle in non-stationary environments. In this work, we propose a non-parametric memory framework that explicitly disentangles episodic and semantic memory for embodied exploration and question answering. Our retrieval-first, reasoning-assisted paradigm recalls episodic experiences via semantic similarity and verifies them through visual reasoning, enabling robust reuse of past observations without rigid geometric alignment. In parallel, we introduce a program-style rule extraction mechanism that converts experiences into structured, reusable semantic memory, facilitating cross-environment generalization. Extensive experiments demonstrate state-of-the-art performance on embodied question answering and exploration benchmarks, yielding a 7.3% gain in LLM-Match and an 11.4% gain in LLM MatchXSPL on A-EQA, as well as +7.7% success rate and +6.8% SPL on GOAT-Bench. Analyses reveal that our episodic memory primarily improves exploration efficiency, while semantic memory strengthens complex reasoning of embodied agents.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§å—äººç±»å¯å‘çš„éå‚æ•°åŒ–è®°å¿†æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ (MLLMs) åœ¨å…·èº«æ™ºèƒ½ä½“ (embodied agents) çš„é•¿æ—¶ç¨‹è§‚å¯Ÿå’Œæœ‰é™ä¸Šä¸‹æ–‡é¢„ç®—ä¸­é¢ä¸´çš„æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶æ˜¾å¼åœ°è§£æ„äº†æƒ…å¢ƒè®°å¿† (episodic memory) å’Œè¯­ä¹‰è®°å¿† (semantic memory)ï¼Œé€šè¿‡æ£€ç´¢ä¼˜å…ˆã€æ¨ç†è¾…åŠ©çš„èŒƒå¼ï¼Œåˆ©ç”¨è¯­ä¹‰ç›¸ä¼¼æ€§å¬å›ç»å†å¹¶ç»“åˆè§†è§‰æ¨ç†è¿›è¡ŒéªŒè¯ï¼Œå®ç°äº†æ— éœ€ä¸¥æ ¼å‡ ä½•å¯¹é½çš„è§‚æµ‹å¤ç”¨ã€‚åŒæ—¶ï¼Œç ”ç©¶å¼•å…¥äº†ç¨‹åºé£æ ¼çš„è§„åˆ™æå–æœºåˆ¶ï¼Œå°†ç»å†è½¬åŒ–ä¸ºç»“æ„åŒ–çš„è¯­ä¹‰è®°å¿†ï¼Œä»è€Œå¢å¼ºäº†è·¨ç¯å¢ƒçš„æ³›åŒ–èƒ½åŠ›ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ A-EQA å’Œ GOAT-Bench ç­‰å…·èº«é—®ç­”ä¸æ¢ç´¢åŸºå‡†æµ‹è¯•ä¸­å‡å–å¾—äº† SOTA æ€§èƒ½ï¼Œå…¶ä¸­åœ¨ A-EQA ä¸Šçš„ LLM-Match æŒ‡æ ‡æå‡äº† 7.3%ã€‚åˆ†æç»“æœè¿›ä¸€æ­¥æ­ç¤ºï¼Œæƒ…å¢ƒè®°å¿†ä¸»è¦ä¼˜åŒ–äº†æ¢ç´¢æ•ˆç‡ï¼Œè€Œè¯­ä¹‰è®°å¿†åˆ™æ˜¾è‘—åŠ å¼ºäº†æ™ºèƒ½ä½“çš„å¤æ‚æ¨ç†èƒ½åŠ›ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15513v1",
      "published_date": "2026-02-17 11:41:28 UTC",
      "updated_date": "2026-02-17 11:41:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:37:35.434694+00:00"
    },
    {
      "arxiv_id": "2602.15491v1",
      "title": "The Equalizer: Introducing Shape-Gain Decomposition in Neural Audio Codecs",
      "title_zh": "The Equalizerï¼šåœ¨ç¥ç»éŸ³é¢‘ç¼–è§£ç å™¨ä¸­å¼•å…¥å½¢çŠ¶-å¢ç›Šåˆ†è§£",
      "authors": [
        "Samir Sadok",
        "Laurent Girin",
        "Xavier Alameda-Pineda"
      ],
      "abstract": "Neural audio codecs (NACs) typically encode the short-term energy (gain) and normalized structure (shape) of speech/audio signals jointly within the same latent space. As a result, they are poorly robust to a global variation of the input signal level in the sense that such variation has strong influence on the embedding vectors at the output of the encoder and their quantization. This methodology is inherently inefficient, leading to codebook redundancy and suboptimal bitrate-distortion performance. To address these limitations, we propose to introduce shape-gain decomposition, widely used in classical speech/audio coding, into the NAC framework. The principle of the proposed Equalizer methodology is to decompose the input signal -- before the NAC encoder -- into gain and normalized shape vector on a short-term basis. The shape vector is processed by the NAC, while the gain is quantized with scalar quantization and transmitted separately. The output (decoded) signal is reconstructed from the normalized output of the NAC and the quantized gain. Our experiments conducted on speech signals show that this general methodology, easily applicable to any NAC, enables a substantial gain in bitrate-distortion performance, as well as a massive reduction in complexity.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç¥ç»éŸ³é¢‘ç¼–è§£ç å™¨ï¼ˆNeural Audio Codecs, NACsï¼‰åœ¨æ½œç©ºé—´å†…è”åˆç¼–ç å¢ç›Šï¼ˆgainï¼‰ä¸å½¢çŠ¶ï¼ˆshapeï¼‰å¯¼è‡´é²æ£’æ€§ä¸è¶³å’Œç æœ¬å†—ä½™çš„é—®é¢˜ï¼Œæå‡ºäº†åä¸º The Equalizer çš„æ”¹è¿›æ¡†æ¶ã€‚è¯¥æ¡†æ¶å€Ÿé‰´äº†ç»å…¸éŸ³é¢‘ç¼–ç ä¸­çš„å½¢çŠ¶-å¢ç›Šåˆ†è§£ï¼ˆshape-gain decompositionï¼‰åŸç†ï¼Œåœ¨è¿›å…¥ç¼–ç å™¨å‰å°†è¾“å…¥ä¿¡å·åˆ†è§£ä¸ºçŸ­æ—¶å¢ç›Šå’Œå½’ä¸€åŒ–å½¢çŠ¶å‘é‡ã€‚å…¶ä¸­å½¢çŠ¶å‘é‡ç”± NAC è´Ÿè´£å¤„ç†ï¼Œè€Œå¢ç›Šåˆ™é€šè¿‡æ ‡é‡é‡åŒ–ï¼ˆscalar quantizationï¼‰è¿›è¡Œç‹¬ç«‹ä¼ è¾“ï¼Œæœ€ååœ¨è§£ç ç«¯é€šè¿‡å½’ä¸€åŒ–è¾“å‡ºä¸é‡åŒ–å¢ç›Šé‡å»ºä¿¡å·ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨è¯­éŸ³ä¿¡å·å¤„ç†ä¸­ï¼Œè¯¥æ–¹æ³•ä¸ä»…æ˜¾è‘—æå‡äº†ç ç‡å¤±çœŸï¼ˆbitrate-distortionï¼‰æ€§èƒ½ï¼Œè¿˜å¤§å¹…é™ä½äº†ç³»ç»Ÿè®¡ç®—å¤æ‚åº¦ã€‚è¿™ç§é€šç”¨æ–¹æ³•å…·æœ‰æå¼ºçš„é€‚é…æ€§ï¼Œèƒ½å¤Ÿè½»æ¾é›†æˆåˆ°å„ç±»ç°æœ‰çš„ NAC æ¨¡å‹ä¸­ï¼Œæœ‰æ•ˆè§£å†³äº†ä¿¡å·ç”µå¹³å…¨å±€å˜åŒ–å¯¹ç¼–ç æ•ˆç‡çš„å½±å“ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "comment": "Neural audio codecs, shape-gain decomposition, vector quantization, speech coding",
      "pdf_url": "https://arxiv.org/pdf/2602.15491v1",
      "published_date": "2026-02-17 10:59:33 UTC",
      "updated_date": "2026-02-17 10:59:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:37:59.240348+00:00"
    },
    {
      "arxiv_id": "2602.15490v1",
      "title": "RPT-SR: Regional Prior attention Transformer for infrared image Super-Resolution",
      "title_zh": "RPT-SRï¼šé¢å‘çº¢å¤–å›¾åƒè¶…åˆ†è¾¨ç‡çš„åŒºåŸŸå…ˆéªŒæ³¨æ„åŠ› Transformer",
      "authors": [
        "Youngwan Jin",
        "Incheol Park",
        "Yagiz Nalcakan",
        "Hyeongjin Ju",
        "Sanghyeop Yeo",
        "Shiho Kim"
      ],
      "abstract": "General-purpose super-resolution models, particularly Vision Transformers, have achieved remarkable success but exhibit fundamental inefficiencies in common infrared imaging scenarios like surveillance and autonomous driving, which operate from fixed or nearly-static viewpoints. These models fail to exploit the strong, persistent spatial priors inherent in such scenes, leading to redundant learning and suboptimal performance. To address this, we propose the Regional Prior attention Transformer for infrared image Super-Resolution (RPT-SR), a novel architecture that explicitly encodes scene layout information into the attention mechanism. Our core contribution is a dual-token framework that fuses (1) learnable, regional prior tokens, which act as a persistent memory for the scene's global structure, with (2) local tokens that capture the frame-specific content of the current input. By utilizing these tokens into an attention, our model allows the priors to dynamically modulate the local reconstruction process. Extensive experiments validate our approach. While most prior works focus on a single infrared band, we demonstrate the broad applicability and versatility of RPT-SR by establishing new state-of-the-art performance across diverse datasets covering both Long-Wave (LWIR) and Short-Wave (SWIR) spectra",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†RPT-SRï¼ˆRegional Prior attention Transformerï¼‰ï¼Œæ—¨åœ¨è§£å†³é€šç”¨è§†è§‰Transformerï¼ˆVision Transformersï¼‰åœ¨ç›‘æ§å’Œè‡ªåŠ¨é©¾é©¶ç­‰å›ºå®šè§†è§’çš„çº¢å¤–å›¾åƒè¶…åˆ†è¾¨ç‡ä»»åŠ¡ä¸­æ•ˆç‡ä½ä¸‹çš„é—®é¢˜ã€‚é’ˆå¯¹ç°æœ‰æ¨¡å‹æœªèƒ½åˆ©ç”¨çº¢å¤–åœºæ™¯ä¸­å¼ºçƒˆçš„æŒä¹…ç©ºé—´å…ˆéªŒï¼ˆspatial priorsï¼‰è¿™ä¸€ç¼ºé™·ï¼ŒRPT-SRå°†åœºæ™¯å¸ƒå±€ä¿¡æ¯æ˜¾å¼ç¼–ç åˆ°æ³¨æ„åŠ›æœºåˆ¶ä¸­ã€‚è¯¥æ¶æ„çš„æ ¸å¿ƒæ˜¯åŒä»¤ç‰Œï¼ˆdual-tokenï¼‰æ¡†æ¶ï¼Œå®ƒèåˆäº†ä½œä¸ºå…¨å±€ç»“æ„æŒä¹…è®°å¿†çš„å¯å­¦ä¹ åŒºåŸŸå…ˆéªŒä»¤ç‰Œï¼ˆregional prior tokensï¼‰ä¸æ•æ‰å½“å‰å¸§å†…å®¹çš„å±€éƒ¨ä»¤ç‰Œï¼ˆlocal tokensï¼‰ã€‚é€šè¿‡å°†è¿™äº›ä»¤ç‰Œå¼•å…¥æ³¨æ„åŠ›æœºåˆ¶ï¼Œæ¨¡å‹å…è®¸å…ˆéªŒä¿¡æ¯åŠ¨æ€è°ƒèŠ‚å±€éƒ¨é‡å»ºè¿‡ç¨‹ï¼Œä»è€Œå…‹æœäº†å†—ä½™å­¦ä¹ å¹¶æå‡äº†æ€§èƒ½ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒRPT-SRåœ¨é•¿æ³¢çº¢å¤–ï¼ˆLWIRï¼‰å’ŒçŸ­æ³¢çº¢å¤–ï¼ˆSWIRï¼‰ç­‰å¤šç§æ³¢æ®µæ•°æ®é›†ä¸Šå‡è¾¾åˆ°äº†æœ€å…ˆè¿›æ€§èƒ½ï¼ˆSOTAï¼‰ã€‚è¯¥ç ”ç©¶ä¸ä»…éªŒè¯äº†åŒºåŸŸå…ˆéªŒåœ¨çº¢å¤–æˆåƒä¸­çš„é‡è¦æ€§ï¼Œè¿˜ä¸ºé«˜æ•ˆã€é«˜ç²¾åº¦çš„çº¢å¤–å›¾åƒè¶…åˆ†è¾¨ç‡å¤„ç†æä¾›äº†æ–°çš„é€šç”¨æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15490v1",
      "published_date": "2026-02-17 10:56:49 UTC",
      "updated_date": "2026-02-17 10:56:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:38:03.738209+00:00"
    },
    {
      "arxiv_id": "2602.15485v1",
      "title": "SecCodeBench-V2 Technical Report",
      "title_zh": "SecCodeBench-V2 æŠ€æœ¯æŠ¥å‘Š",
      "authors": [
        "Longfei Chen",
        "Ji Zhao",
        "Lanxiao Cui",
        "Tong Su",
        "Xingbo Pan",
        "Ziyang Li",
        "Yongxing Wu",
        "Qijiang Cao",
        "Qiyao Cai",
        "Jing Zhang",
        "Yuandong Ni",
        "Junyao He",
        "Zeyu Zhang",
        "Chao Ge",
        "Xuhuai Lu",
        "Zeyu Gao",
        "Yuxin Cui",
        "Weisen Chen",
        "Yuxuan Peng",
        "Shengping Wang",
        "Qi Li",
        "Yukai Huang",
        "Yukun Liu",
        "Tuo Zhou",
        "Terry Yue Zhuo",
        "Junyang Lin",
        "Chao Zhang"
      ],
      "abstract": "We introduce SecCodeBench-V2, a publicly released benchmark for evaluating Large Language Model (LLM) copilots' capabilities of generating secure code. SecCodeBench-V2 comprises 98 generation and fix scenarios derived from Alibaba Group's industrial productions, where the underlying security issues span 22 common CWE (Common Weakness Enumeration) categories across five programming languages: Java, C, Python, Go, and Node.js. SecCodeBench-V2 adopts a function-level task formulation: each scenario provides a complete project scaffold and requires the model to implement or patch a designated target function under fixed interfaces and dependencies. For each scenario, SecCodeBench-V2 provides executable proof-of-concept (PoC) test cases for both functional validation and security verification. All test cases are authored and double-reviewed by security experts, ensuring high fidelity, broad coverage, and reliable ground truth. Beyond the benchmark itself, we build a unified evaluation pipeline that assesses models primarily via dynamic execution. For most scenarios, we compile and run model-generated artifacts in isolated environments and execute PoC test cases to validate both functional correctness and security properties. For scenarios where security issues cannot be adjudicated with deterministic test cases, we additionally employ an LLM-as-a-judge oracle. To summarize performance across heterogeneous scenarios and difficulty levels, we design a Pass@K-based scoring protocol with principled aggregation over scenarios and severity, enabling holistic and comparable evaluation across models. Overall, SecCodeBench-V2 provides a rigorous and reproducible foundation for assessing the security posture of AI coding assistants, with results and artifacts released at https://alibaba.github.io/sec-code-bench. The benchmark is publicly available at https://github.com/alibaba/sec-code-bench.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»‹ç»äº†SecCodeBench-V2ï¼Œè¿™æ˜¯ä¸€ä¸ªå…¬å¼€å‘å¸ƒçš„åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹(LLM)ä»£ç è¾…åŠ©å·¥å…·ç”Ÿæˆå®‰å…¨ä»£ç çš„èƒ½åŠ›ã€‚è¯¥åŸºå‡†åŒ…å«æºè‡ªé˜¿é‡Œå·´å·´é›†å›¢å·¥ä¸šç”Ÿäº§ç¯å¢ƒçš„98ä¸ªç”Ÿæˆå’Œä¿®å¤åœºæ™¯ï¼Œæ¶µç›–äº†Javaã€Cã€Pythonã€Goå’ŒNode.jsäº”ç§ç¼–ç¨‹è¯­è¨€ä¸­çš„22ä¸ªå¸¸è§CWE(Common Weakness Enumeration)ç±»åˆ«ã€‚SecCodeBench-V2é‡‡ç”¨å‡½æ•°çº§ä»»åŠ¡å½¢å¼ï¼Œä¸ºæ¯ä¸ªåœºæ™¯æä¾›å®Œæ•´çš„é¡¹ç›®éª¨æ¶ï¼Œè¦æ±‚æ¨¡å‹åœ¨å›ºå®šæ¥å£å’Œä¾èµ–ä¸‹å®ç°æˆ–ä¿®å¤ç›®æ ‡å‡½æ•°ã€‚ç ”ç©¶ä¸ºæ¯ä¸ªåœºæ™¯æä¾›äº†ç”±å®‰å…¨ä¸“å®¶ç¼–å†™å¹¶åŒé‡å®¡æ ¸çš„å¯æ‰§è¡Œæ¼æ´éªŒè¯(PoC)æµ‹è¯•ç”¨ä¾‹ï¼Œä»¥ç¡®ä¿åŠŸèƒ½éªŒè¯å’Œå®‰å…¨æ€§éªŒè¯çš„é«˜ä¿çœŸåº¦å’Œå¯é æ€§ã€‚å›¢é˜Ÿæ„å»ºäº†ç»Ÿä¸€çš„è¯„ä¼°æµæ°´çº¿ï¼Œä¸»è¦é€šè¿‡åœ¨éš”ç¦»ç¯å¢ƒä¸­åŠ¨æ€æ‰§è¡Œæ¨¡å‹ç”Ÿæˆçš„äº§ç‰©å¹¶è¿è¡ŒPoCç”¨ä¾‹æ¥è¯„ä¼°å®‰å…¨æ€§ï¼Œå¹¶åœ¨å¿…è¦æ—¶è¾…ä»¥LLM-as-a-judgeè¿›è¡Œè¯„åˆ¤ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è®¾è®¡äº†åŸºäºPass@Kçš„è¯„åˆ†åè®®ï¼Œèƒ½å¤Ÿè·¨ä¸åŒåœºæ™¯å’Œä¸¥é‡ç¨‹åº¦å¯¹æ¨¡å‹çš„å®‰å…¨æ€åŠ¿è¿›è¡Œå…¨é¢ä¸”å¯æ¯”è¾ƒçš„è¯„ä¼°ï¼Œä¸ºAIç¼–ç åŠ©æ‰‹çš„å®‰å…¨æ€§è¯„ä¼°æä¾›äº†ä¸¥è°¨ä¸”å¯å¤ç°çš„åŸºç¡€ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15485v1",
      "published_date": "2026-02-17 10:47:06 UTC",
      "updated_date": "2026-02-17 10:47:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:38:07.839877+00:00"
    },
    {
      "arxiv_id": "2602.15451v1",
      "title": "Molecular Design beyond Training Data with Novel Extended Objective Functionals of Generative AI Models Driven by Quantum Annealing Computer",
      "title_zh": "åŸºäºé‡å­é€€ç«è®¡ç®—æœºé©±åŠ¨çš„ç”Ÿæˆå¼äººå·¥æ™ºèƒ½æ¨¡å‹æ–°å‹æ‰©å±•ç›®æ ‡æ³›å‡½çš„è¶…è¶Šè®­ç»ƒæ•°æ®åˆ†å­è®¾è®¡",
      "authors": [
        "Hayato Kunugi",
        "Mohsen Rahmani",
        "Yosuke Iyama",
        "Yutaro Hirono",
        "Akira Suma",
        "Matthew Woolway",
        "Vladimir Vargas-CalderÃ³n",
        "William Kim",
        "Kevin Chern",
        "Mohammad Amin",
        "Masaru Tateno"
      ],
      "abstract": "Deep generative modeling to stochastically design small molecules is an emerging technology for accelerating drug discovery and development. However, one major issue in molecular generative models is their lower frequency of drug-like compounds. To resolve this problem, we developed a novel framework for optimization of deep generative models integrated with a D-Wave quantum annealing computer, where our Neural Hash Function (NHF) presented herein is used both as the regularization and binarization schemes simultaneously, of which the latter is for transformation between continuous and discrete signals of the classical and quantum neural networks, respectively, in the error evaluation (i.e., objective) function. The compounds generated via the quantum-annealing generative models exhibited higher quality in both validity and drug-likeness than those generated via the fully-classical models, and was further indicated to exceed even the training data in terms of drug-likeness features, without any restraints and conditions to deliberately induce such an optimization. These results indicated an advantage of quantum annealing to aim at a stochastic generator integrated with our novel neural network architectures, for the extended performance of feature space sampling and extraction of characteristic features in drug design.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼€å‘äº†ä¸€ä¸ªå°†æ·±åº¦ç”Ÿæˆæ¨¡å‹(Deep generative models)ä¸D-Waveé‡å­é€€ç«è®¡ç®—æœº(Quantum annealing computer)ç›¸ç»“åˆçš„æ–°å‹æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³åˆ†å­ç”Ÿæˆæ¨¡å‹ä¸­ç±»è¯æ€§(Drug-likeness)åŒ–åˆç‰©ç”Ÿæˆé¢‘ç‡è¾ƒä½çš„æŒ‘æˆ˜ã€‚ç ”ç©¶æ ¸å¿ƒåœ¨äºæå‡ºäº†ä¸€ç§ç¥ç»å“ˆå¸Œå‡½æ•°(Neural Hash Function, NHF)ï¼Œå®ƒåœ¨è¯¯å·®è¯„ä¼°å‡½æ•°ä¸­åŒæ—¶ä½œä¸ºæ­£åˆ™åŒ–å’ŒäºŒå€¼åŒ–æ–¹æ¡ˆï¼Œå®ç°äº†ç»å…¸ä¸é‡å­ç¥ç»ç½‘ç»œä¹‹é—´ä¿¡å·çš„æœ‰æ•ˆè½¬æ¢ã€‚å®éªŒè¯æ˜ï¼Œè¯¥é‡å­é€€ç«ç”Ÿæˆæ¨¡å‹äº§ç”Ÿçš„åŒ–åˆç‰©åœ¨æœ‰æ•ˆæ€§(Validity)å’Œç±»è¯æ€§æ–¹é¢å‡ä¼˜äºä¼ ç»Ÿç»å…¸æ¨¡å‹ã€‚ç ”ç©¶å‘ç°ï¼Œåœ¨æ— éœ€é¢å¤–çº¦æŸçš„æƒ…å†µä¸‹ï¼Œç”Ÿæˆçš„åˆ†å­åœ¨ç±»è¯æ€§ç‰¹å¾ä¸Šç”šè‡³è¶…è¶Šäº†åŸå§‹è®­ç»ƒæ•°æ®ã€‚è¿™ä¸€ç»“æœå½°æ˜¾äº†é‡å­é€€ç«æŠ€æœ¯åœ¨ç‰¹å¾ç©ºé—´é‡‡æ ·å’Œè¯ç‰©è®¾è®¡ç‰¹å¾æå–æ–¹é¢çš„ç‹¬ç‰¹ä¼˜åŠ¿ï¼Œä¸ºå¼€å‘è¶…è¶Šç°æœ‰æ•°æ®é™åˆ¶çš„éšæœºç”Ÿæˆå™¨æä¾›äº†é‡è¦æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG",
        "quant-ph"
      ],
      "primary_category": "q-bio.QM",
      "comment": "42 pages, 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.15451v1",
      "published_date": "2026-02-17 09:38:11 UTC",
      "updated_date": "2026-02-17 09:38:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:38:16.042192+00:00"
    },
    {
      "arxiv_id": "2602.15439v1",
      "title": "Algorithmic Approaches to Opinion Selection for Online Deliberation: A Comparative Study",
      "title_zh": "é¢å‘åœ¨çº¿åå•†çš„è§‚ç‚¹é€‰æ‹©ç®—æ³•ï¼šä¸€é¡¹æ¯”è¾ƒç ”ç©¶",
      "authors": [
        "Salim Hafid",
        "Manon Berriche",
        "Jean-Philippe Cointet"
      ],
      "abstract": "During deliberation processes, mediators and facilitators typically need to select a small and representative set of opinions later used to produce digestible reports for stakeholders. In online deliberation platforms, algorithmic selection is increasingly used to automate this process. However, such automation is not without consequences. For instance, enforcing consensus-seeking algorithmic strategies can imply ignoring or flattening conflicting preferences, which may lead to erasing minority voices and reducing content diversity. More generally, across the variety of existing selection strategies (e.g., consensus, diversity), it remains unclear how each approach influences desired democratic criteria such as proportional representation. To address this gap, we benchmark several algorithmic approaches in this context. We also build on social choice theory to propose a novel algorithm that incorporates both diversity and a balanced notion of representation in the selection strategy. We find empirically that while no single strategy dominates across all democratic desiderata, our social-choice-inspired selection rule achieves the strongest trade-off between proportional representation and diversity.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨çº¿å•†è®®(online deliberation)ä¸­è§‚ç‚¹é€‰æ‹©çš„ç®—æ³•æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰ç®—æ³•å¯èƒ½å¯¼è‡´å°‘æ•°ç¾¤ä½“å£°éŸ³è¢«æŠ¹æ€æˆ–å†…å®¹å¤šæ ·æ€§é™ä½çš„é—®é¢˜ã€‚ç ”ç©¶è€…å¯¹æ¯”äº†å…±è¯†(consensus)å’Œå¤šæ ·æ€§(diversity)ç­‰å¤šç§ç°æœ‰ç­–ç•¥ï¼Œè¯„ä¼°äº†å®ƒä»¬å¯¹æ¯”ä¾‹ä»£è¡¨æ€§(proportional representation)ç­‰æ°‘ä¸»æ ‡å‡†çš„å½±å“ã€‚åŸºäºç¤¾ä¼šé€‰æ‹©ç†è®º(social choice theory)ï¼Œè¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§å…¼é¡¾å¤šæ ·æ€§å’Œå‡è¡¡ä»£è¡¨æ€§çš„æ–°å‹ç®—æ³•å¹¶è¿›è¡Œäº†åŸºå‡†æµ‹è¯•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè™½ç„¶æ²¡æœ‰å•ä¸€ç­–ç•¥èƒ½åœ¨æ‰€æœ‰æ°‘ä¸»è¯‰æ±‚ä¸­è¡¨ç°å®Œç¾ï¼Œä½†è¯¥ç ”ç©¶æ‰€æå‡ºçš„æ–°å‹é€‰æ‹©è§„åˆ™åœ¨æ¯”ä¾‹ä»£è¡¨æ€§å’Œå¤šæ ·æ€§ä¹‹é—´å®ç°äº†æœ€ä½³æƒè¡¡ã€‚è¯¥ç ”ç©¶ä¸ºä¼˜åŒ–åœ¨çº¿å•†è®®ä¸­çš„è‡ªåŠ¨åŒ–ç­›é€‰æœºåˆ¶æä¾›äº†é‡è¦çš„ç†è®ºä¾æ®ä¸æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15439v1",
      "published_date": "2026-02-17 09:03:26 UTC",
      "updated_date": "2026-02-17 09:03:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:38:13.842776+00:00"
    },
    {
      "arxiv_id": "2602.15438v1",
      "title": "Logit Distance Bounds Representational Similarity",
      "title_zh": "Logit è·ç¦»ç•Œå®šè¡¨å¾ç›¸ä¼¼æ€§",
      "authors": [
        "Beatrix M. B. Nielsen",
        "Emanuele Marconato",
        "Luigi Gresele",
        "Andrea Dittadi",
        "Simon Buchholz"
      ],
      "abstract": "For a broad family of discriminative models that includes autoregressive language models, identifiability results imply that if two models induce the same conditional distributions, then their internal representations agree up to an invertible linear transformation. We ask whether an analogous conclusion holds approximately when the distributions are close instead of equal. Building on the observation of Nielsen et al. (2025) that closeness in KL divergence need not imply high linear representational similarity, we study a distributional distance based on logit differences and show that closeness in this distance does yield linear similarity guarantees. Specifically, we define a representational dissimilarity measure based on the models' identifiability class and prove that it is bounded by the logit distance. We further show that, when model probabilities are bounded away from zero, KL divergence upper-bounds logit distance; yet the resulting bound fails to provide nontrivial control in practice. As a consequence, KL-based distillation can match a teacher's predictions while failing to preserve linear representational properties, such as linear-probe recoverability of human-interpretable concepts. In distillation experiments on synthetic and image datasets, logit-distance distillation yields students with higher linear representational similarity and better preservation of the teacher's linearly recoverable concepts.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åˆ¤åˆ«æ¨¡å‹ï¼ˆå¦‚è‡ªå›å½’è¯­è¨€æ¨¡å‹ï¼‰ä¸­æ¡ä»¶åˆ†å¸ƒç›¸ä¼¼æ€§ä¸å†…éƒ¨è¡¨å¾çº¿æ€§ç›¸ä¼¼æ€§ä¹‹é—´çš„å…³ç³»ï¼ŒæŒ‡å‡º KL divergence æ¥è¿‘å¹¶ä¸ä¸€å®šæ„å‘³ç€é«˜çº¿æ€§è¡¨å¾ç›¸ä¼¼åº¦ã€‚åŸºäº Nielsen ç­‰äººï¼ˆ2025ï¼‰çš„è§‚å¯Ÿï¼Œä½œè€…æå‡ºäº†ä¸€ç§åŸºäº Logit Distance çš„åˆ†å¸ƒè·ç¦»åº¦é‡ï¼Œå¹¶ä»ç†è®ºä¸Šè¯æ˜äº†è¯¥è·ç¦»å¯ä»¥ä¸ºçº¿æ€§ç›¸ä¼¼æ€§æä¾›ä¿è¯ã€‚è®ºæ–‡å®šä¹‰äº†ä¸€ç§åŸºäºæ¨¡å‹å¯è¾¨è¯†æ€§ç±»åˆ«ï¼ˆidentifiability classï¼‰çš„è¡¨å¾å·®å¼‚åº¦é‡ï¼Œå¹¶è¯æ˜å…¶å— Logit Distance çš„ä¸Šç•Œçº¦æŸã€‚ç ”ç©¶è¿›ä¸€æ­¥å‘ç°ï¼Œè™½ç„¶åœ¨ç‰¹å®šæ¡ä»¶ä¸‹ KL divergence æ˜¯ Logit Distance çš„ä¸Šç•Œï¼Œä½†åœ¨å®è·µä¸­è¯¥çº¦æŸå¾€å¾€å¤±æ•ˆï¼Œå¯¼è‡´ä¼ ç»Ÿçš„ KL-based distillation æ— æ³•æœ‰æ•ˆä¿ç•™çº¿æ€§è¡¨å¾å±æ€§ï¼Œä¾‹å¦‚é€šè¿‡çº¿æ€§æ¢æµ‹ï¼ˆlinear-probeï¼‰æ¢å¤äººç±»å¯ç†è§£æ¦‚å¿µçš„èƒ½åŠ›ã€‚é€šè¿‡åœ¨åˆæˆæ•°æ®å’Œå›¾åƒæ•°æ®é›†ä¸Šçš„è’¸é¦å®éªŒï¼Œç ”ç©¶è¯å®äº† Logit-distance distillation èƒ½æ˜¾è‘—æå‡å­¦ç”Ÿæ¨¡å‹çš„çº¿æ€§è¡¨å¾ç›¸ä¼¼æ€§ï¼Œå¹¶æ›´å¥½åœ°ä¿ç•™æ•™å¸ˆæ¨¡å‹ä¸­çš„å…³é”®è¡¨å¾ç‰¹æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15438v1",
      "published_date": "2026-02-17 09:00:56 UTC",
      "updated_date": "2026-02-17 09:00:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:38:52.443464+00:00"
    },
    {
      "arxiv_id": "2602.15403v1",
      "title": "Common Belief Revisited",
      "title_zh": "é‡æ–°å®¡è§†å…±åŒä¿¡å¿µ",
      "authors": [
        "Thomas Ã…gotnes"
      ],
      "abstract": "Contrary to common belief, common belief is not KD4.\n  If individual belief is KD45, common belief does indeed lose the 5 property and keep the D and 4 properties -- and it has none of the other commonly considered properties of knowledge and belief. But it has another property: $C(CÏ†\\rightarrow Ï†)$ -- corresponding to so-called shift-reflexivity (reflexivity one step ahead). This observation begs the question:\n  is KD4 extended with this axiom a complete characterisation of common belief in the KD45 case? If not, what \\emph{is} the logic of common belief? In this paper we show that the answer to the first question is ``no'': there is one additional axiom, and, furthermore, it relies on the number of agents. We show that the result is a complete characterisation of common belief, settling the open problem.",
      "tldr_zh": "è¯¥ç ”ç©¶é‡æ–°å®¡è§†äº†å…¬å…±ä¿¡å¿µ(Common Belief)çš„é€»è¾‘å±æ€§ï¼ŒæŒ‘æˆ˜äº†å…¶é€šå¸¸è¢«è®¤ä¸ºç¬¦åˆKD4é€»è¾‘çš„ä¼ ç»Ÿè§‚ç‚¹ã€‚ç ”ç©¶æŒ‡å‡ºï¼Œå½“ä¸ªä½“ä¿¡å¿µæ»¡è¶³KD45é€»è¾‘æ—¶ï¼Œå…¬å…±ä¿¡å¿µè™½ç„¶ä¿ç•™äº†Då’Œ4å±æ€§ï¼Œä½†ä¼šå¤±å»5å±æ€§ï¼Œå¹¶å±•ç°å‡ºä¸€ç§è¢«ç§°ä¸ºä½ç§»è‡ªåæ€§(shift-reflexivity)çš„ç‰¹æ®Šæ€§è´¨ï¼Œå³$C(C\\phi \\rightarrow \\phi)$ã€‚é’ˆå¯¹KD4ç»“åˆè¯¥å…¬ç†æ˜¯å¦èƒ½å®Œå…¨è¡¨å¾å…¬å…±ä¿¡å¿µè¿™ä¸€æ ¸å¿ƒé—®é¢˜ï¼Œè®ºæ–‡ç»™å‡ºäº†å¦å®šå›ç­”ã€‚è®ºæ–‡å‘ç°è¿˜å­˜åœ¨ä¸€ä¸ªä¸ä»£ç†äºº(agents)æ•°é‡ç›¸å…³çš„é¢å¤–å…¬ç†ï¼Œå¹¶æœ€ç»ˆæå‡ºäº†KD45èƒŒæ™¯ä¸‹å…¬å…±ä¿¡å¿µçš„å®Œæ•´é€»è¾‘åˆ»ç”»ã€‚è¿™ä¸€æˆæœæˆåŠŸè§£å†³äº†è¯¥é¢†åŸŸçš„é•¿æœŸå¼€æ”¾é—®é¢˜ï¼Œä¸ºç†è§£å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­å…¬å…±ä¿¡å¿µçš„ç»“æ„å¥ å®šäº†ç²¾ç¡®çš„ç†è®ºåŸºç¡€ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15403v1",
      "published_date": "2026-02-17 07:22:31 UTC",
      "updated_date": "2026-02-17 07:22:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:38:51.539088+00:00"
    },
    {
      "arxiv_id": "2602.15397v1",
      "title": "ActionCodec: What Makes for Good Action Tokenizers",
      "title_zh": "ActionCodecï¼šä½•ä¸ºä¼˜ç§€çš„åŠ¨ä½œåˆ†è¯å™¨",
      "authors": [
        "Zibin Dong",
        "Yicheng Liu",
        "Shiduo Zhang",
        "Baijun Ye",
        "Yifu Yuan",
        "Fei Ni",
        "Jingjing Gong",
        "Xipeng Qiu",
        "Hang Zhao",
        "Yinchuan Li",
        "Jianye Hao"
      ],
      "abstract": "Vision-Language-Action (VLA) models leveraging the native autoregressive paradigm of Vision-Language Models (VLMs) have demonstrated superior instruction-following and training efficiency. Central to this paradigm is action tokenization, yet its design has primarily focused on reconstruction fidelity, failing to address its direct impact on VLA optimization. Consequently, the fundamental question of \\textit{what makes for good action tokenizers} remains unanswered. In this paper, we bridge this gap by establishing design principles specifically from the perspective of VLA optimization. We identify a set of best practices based on information-theoretic insights, including maximized temporal token overlap, minimized vocabulary redundancy, enhanced multimodal mutual information, and token independence. Guided by these principles, we introduce \\textbf{ActionCodec}, a high-performance action tokenizer that significantly enhances both training efficiency and VLA performance across diverse simulation and real-world benchmarks. Notably, on LIBERO, a SmolVLM2-2.2B fine-tuned with ActionCodec achieves a 95.5\\% success rate without any robotics pre-training. With advanced architectural enhancements, this reaches 97.4\\%, representing a new SOTA for VLA models without robotics pre-training. We believe our established design principles, alongside the released model, will provide a clear roadmap for the community to develop more effective action tokenizers.",
      "tldr_zh": "è¯¥ç ”ç©¶é€šè¿‡è§†è§‰è¯­è¨€åŠ¨ä½œæ¨¡å‹(Vision-Language-Action, VLA)ä¼˜åŒ–çš„è§†è§’ï¼Œæ¢è®¨äº†æ„å»ºé«˜æ•ˆåŠ¨ä½œåˆ†è¯å™¨çš„è®¾è®¡åŸåˆ™ï¼Œå¡«è¡¥äº†ä»¥å¾€ç ”ç©¶ä»…å…³æ³¨é‡å»ºä¿çœŸåº¦çš„ç©ºç™½ã€‚ä½œè€…åŸºäºä¿¡æ¯è®ºæ´å¯Ÿæå‡ºäº†ActionCodecæ¡†æ¶ï¼Œç¡®ç«‹äº†æœ€å¤§åŒ–æ—¶é—´ä»¤ç‰Œé‡å ã€æœ€å°åŒ–è¯è¡¨å†—ä½™ã€å¢å¼ºå¤šæ¨¡æ€äº’ä¿¡æ¯ä»¥åŠä»¤ç‰Œç‹¬ç«‹æ€§ç­‰æ ¸å¿ƒè®¾è®¡åŸåˆ™ã€‚ActionCodecé€šè¿‡è¿™ä¸€ç³»åˆ—æœ€ä½³å®è·µï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹åœ¨æ¨¡æ‹Ÿå’ŒçœŸå®ä¸–ç•ŒåŸºå‡†æµ‹è¯•ä¸­çš„è®­ç»ƒæ•ˆç‡å’Œä»»åŠ¡æˆåŠŸç‡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œé‡‡ç”¨ActionCodecå¾®è°ƒçš„SmolVLM2-2.2Båœ¨LIBEROåŸºå‡†æµ‹è¯•ä¸­ï¼Œå³ä¾¿åœ¨æ— æœºå™¨äººé¢„è®­ç»ƒçš„æƒ…å†µä¸‹ä¹Ÿè¾¾åˆ°äº†97.4%çš„æˆåŠŸç‡ï¼Œåˆ·æ–°äº†è¯¥é¢†åŸŸçš„SOTAè®°å½•ã€‚è¯¥ç ”ç©¶åŠå…¶å¼€æºçš„ActionCodecæ¨¡å‹ä¸ºç¤¾åŒºå¼€å‘æ›´æœ‰æ•ˆçš„åŠ¨ä½œåˆ†è¯å™¨æä¾›äº†æ¸…æ™°çš„æ–¹æ³•è®ºæŒ‡å¯¼ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15397v1",
      "published_date": "2026-02-17 07:07:15 UTC",
      "updated_date": "2026-02-17 07:07:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:38:59.336774+00:00"
    },
    {
      "arxiv_id": "2602.15391v1",
      "title": "Improving LLM Reliability through Hybrid Abstention and Adaptive Detection",
      "title_zh": "é€šè¿‡æ··åˆå¼ƒæƒä¸è‡ªé€‚åº”æ£€æµ‹æå‡å¤§è¯­è¨€æ¨¡å‹çš„å¯é æ€§",
      "authors": [
        "Ankit Sharma",
        "Nachiket Tapas",
        "Jyotiprakash Patra"
      ],
      "abstract": "Large Language Models (LLMs) deployed in production environments face a fundamental safety-utility trade-off either a strict filtering mechanisms prevent harmful outputs but often block benign queries or a relaxed controls risk unsafe content generation. Conventional guardrails based on static rules or fixed confidence thresholds are typically context-insensitive and computationally expensive, resulting in high latency and degraded user experience. To address these limitations, we introduce an adaptive abstention system that dynamically adjusts safety thresholds based on real-time contextual signals such as domain and user history. The proposed framework integrates a multi-dimensional detection architecture composed of five parallel detectors, combined through a hierarchical cascade mechanism to optimize both speed and precision. The cascade design reduces unnecessary computation by progressively filtering queries, achieving substantial latency improvements compared to non-cascaded models and external guardrail systems. Extensive evaluation on mixed and domain-specific workloads demonstrates significant reductions in false positives, particularly in sensitive domains such as medical advice and creative writing. The system maintains high safety precision and near-perfect recall under strict operating modes. Overall, our context-aware abstention framework effectively balances safety and utility while preserving performance, offering a scalable solution for reliable LLM deployment.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨ç”Ÿäº§ç¯å¢ƒé¢ä¸´çš„å®‰å…¨ä¸æ•ˆç”¨æƒè¡¡ï¼Œä»¥åŠé™æ€è¿‡æ»¤æœºåˆ¶å¯¼è‡´çš„é«˜å»¶è¿Ÿå’Œä¸Šä¸‹æ–‡ä¸æ•æ„Ÿé—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºæ··åˆå¼ƒæƒ(Hybrid Abstention)ä¸è‡ªé€‚åº”æ£€æµ‹çš„å¯é æ€§æå‡æ¡†æ¶ã€‚ç ”ç©¶å¼•å…¥çš„è‡ªé€‚åº”å¼ƒæƒç³»ç»Ÿèƒ½å¤Ÿæ ¹æ®é¢†åŸŸå’Œç”¨æˆ·å†å²ç­‰å®æ—¶ä¿¡å·åŠ¨æ€è°ƒæ•´å®‰å…¨é˜ˆå€¼ï¼Œå…‹æœäº†ä¼ ç»Ÿå›ºå®šé˜ˆå€¼çš„å±€é™æ€§ã€‚è¯¥æ¶æ„é›†æˆäº†äº”ä¸ªå¹¶è¡Œæ£€æµ‹å™¨ï¼Œå¹¶é‡‡ç”¨å±‚æ¬¡åŒ–çº§è”æœºåˆ¶(Hierarchical Cascade Mechanism)æ¥å¹³è¡¡æ£€æµ‹é€Ÿåº¦ä¸ç²¾åº¦ï¼Œé€šè¿‡é€çº§è¿‡æ»¤æŸ¥è¯¢æ˜¾è‘—é™ä½äº†ç³»ç»Ÿå»¶è¿Ÿã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥ç³»ç»Ÿåœ¨æ··åˆåŠåŒ»ç–—å»ºè®®ã€åˆ›æ„å†™ä½œç­‰æ•æ„Ÿé¢†åŸŸçš„å·¥ä½œè´Ÿè½½ä¸­å¤§å¹…é™ä½äº†è¯¯æŠ¥ç‡(False Positives)ï¼ŒåŒæ—¶ä¿æŒäº†æé«˜çš„å®‰å…¨ç²¾åº¦å’Œå¬å›ç‡ã€‚æ€»ä½“è€Œè¨€ï¼Œè¯¥ä¸Šä¸‹æ–‡æ„ŸçŸ¥æ¡†æ¶åœ¨ç»´æŒæ¨¡å‹æ€§èƒ½çš„åŒæ—¶æœ‰æ•ˆå¹³è¡¡äº†å®‰å…¨æ€§ä¸å®ç”¨æ€§ï¼Œä¸ºå¯é çš„LLMéƒ¨ç½²æä¾›äº†ä¸€ç§é«˜æ•ˆä¸”å¯æ‰©å±•çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15391v1",
      "published_date": "2026-02-17 07:00:09 UTC",
      "updated_date": "2026-02-17 07:00:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:39:00.437609+00:00"
    },
    {
      "arxiv_id": "2602.15384v1",
      "title": "World-Model-Augmented Web Agents with Action Correction",
      "title_zh": "å…·æœ‰åŠ¨ä½œæ ¡æ­£èƒ½åŠ›çš„ä¸–ç•Œæ¨¡å‹å¢å¼ºå‹ Web æ™ºèƒ½ä½“",
      "authors": [
        "Zhouzhou Shen",
        "Xueyu Hu",
        "Xiyun Li",
        "Tianqing Fang",
        "Juncheng Li",
        "Shengyu Zhang"
      ],
      "abstract": "Web agents based on large language models have demonstrated promising capability in automating web tasks. However, current web agents struggle to reason out sensible actions due to the limitations of predicting environment changes, and might not possess comprehensive awareness of execution risks, prematurely performing risky actions that cause losses and lead to task failure. To address these challenges, we propose WAC, a web agent that integrates model collaboration, consequence simulation, and feedback-driven action refinement. To overcome the cognitive isolation of individual models, we introduce a multi-agent collaboration process that enables an action model to consult a world model as a web-environment expert for strategic guidance; the action model then grounds these suggestions into executable actions, leveraging prior knowledge of environmental state transition dynamics to enhance candidate action proposal. To achieve risk-aware resilient task execution, we introduce a two-stage deduction chain. A world model, specialized in environmental state transitions, simulates action outcomes, which a judge model then scrutinizes to trigger action corrective feedback when necessary. Experiments show that WAC achieves absolute gains of 1.8% on VisualWebArena and 1.3% on Online-Mind2Web.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹ Web Agents åœ¨é¢„æµ‹ç¯å¢ƒå˜åŒ–å’Œè¯†åˆ«æ‰§è¡Œé£é™©æ–¹é¢çš„å±€é™æ€§ï¼Œæå‡ºäº†é›†æˆæ¨¡å‹åä½œã€åæœæ¨¡æ‹Ÿä»¥åŠåé¦ˆé©±åŠ¨åŠ¨ä½œä¼˜åŒ–çš„ WAC æ¡†æ¶ã€‚ç ”ç©¶å¼•å…¥äº†å¤šæ™ºèƒ½ä½“åä½œæµç¨‹ï¼Œä½¿ action model èƒ½å¤Ÿå’¨è¯¢ä½œä¸º Web ç¯å¢ƒä¸“å®¶çš„ world model ä»¥è·å¾—æˆ˜ç•¥æŒ‡å¯¼ï¼Œå¹¶å°†è¿™äº›å»ºè®®è½¬åŒ–ä¸ºåŸºäºç¯å¢ƒçŠ¶æ€è½¬ç§»é¢„æµ‹çš„å¯æ‰§è¡ŒåŠ¨ä½œã€‚ä¸ºäº†å®ç°å…·å¤‡é£é™©æ„è¯†çš„ä»»åŠ¡æ‰§è¡Œï¼ŒWAC é‡‡ç”¨äº†ä¸¤é˜¶æ®µæ¨æ¼”é“¾ï¼Œåˆ©ç”¨ world model æ¨¡æ‹ŸåŠ¨ä½œåæœï¼Œå¹¶ç”± judge model è¿›è¡Œå®¡æŸ¥ä»¥åœ¨å¿…è¦æ—¶è§¦å‘åŠ¨ä½œçº æ­£åé¦ˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒWAC åœ¨ VisualWebArena å’Œ Online-Mind2Web åŸºå‡†æµ‹è¯•ä¸­åˆ†åˆ«å–å¾—äº† 1.8% å’Œ 1.3% çš„ç»å¯¹æ€§èƒ½æå‡ã€‚è¯¥æ–¹æ³•æ˜¾è‘—å¢å¼ºäº†æ™ºèƒ½ä½“åœ¨å¤æ‚ç½‘ç»œäº¤äº’ä¸­çš„å†³ç­–åˆç†æ€§ä¸æ‰§è¡Œé²æ£’æ€§ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15384v1",
      "published_date": "2026-02-17 06:37:31 UTC",
      "updated_date": "2026-02-17 06:37:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:39:14.936371+00:00"
    },
    {
      "arxiv_id": "2602.15377v1",
      "title": "Orchestration-Free Customer Service Automation: A Privacy-Preserving and Flowchart-Guided Framework",
      "title_zh": "æ— ç¼–æ’çš„å®¢æœè‡ªåŠ¨åŒ–ï¼šä¸€ç§éšç§ä¿æŠ¤åŠæµç¨‹å›¾å¼•å¯¼çš„æ¡†æ¶",
      "authors": [
        "Mengze Hong",
        "Chen Jason Zhang",
        "Zichang Guo",
        "Hanlin Gu",
        "Di Jiang",
        "Li Qing"
      ],
      "abstract": "Customer service automation has seen growing demand within digital transformation. Existing approaches either rely on modular system designs with extensive agent orchestration or employ over-simplified instruction schemas, providing limited guidance and poor generalizability. This paper introduces an orchestration-free framework using Task-Oriented Flowcharts (TOFs) to enable end-to-end automation without manual intervention. We first define the components and evaluation metrics for TOFs, then formalize a cost-efficient flowchart construction algorithm to abstract procedural knowledge from service dialogues. We emphasize local deployment of small language models and propose decentralized distillation with flowcharts to mitigate data scarcity and privacy issues in model training. Extensive experiments validate the effectiveness in various service tasks, with superior quantitative and application performance compared to strong baselines and market products. By releasing a web-based system demonstration with case studies, we aim to promote streamlined creation of future service automation.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ•°å­—åŒ–è½¬å‹ä¸­ç°æœ‰å®¢æœè‡ªåŠ¨åŒ–ç³»ç»Ÿä¾èµ–å¤æ‚ç¼–æ’æˆ–æ³›åŒ–æ€§å·®çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºä»»åŠ¡å¯¼å‘æµç¨‹å›¾(Task-Oriented Flowcharts, TOFs)çš„æ— éœ€ç¼–æ’(orchestration-free)æ¡†æ¶ï¼Œæ—¨åœ¨å®ç°æ— éœ€äººå·¥å¹²é¢„çš„ç«¯åˆ°ç«¯è‡ªåŠ¨åŒ–ã€‚é€šè¿‡å®šä¹‰TOFsçš„ç»„ä»¶åŠè¯„ä¼°æŒ‡æ ‡ï¼Œå¹¶å¼€å‘ä¸€ç§ç»æµé«˜æ•ˆçš„æµç¨‹å›¾æ„å»ºç®—æ³•ï¼Œè¯¥æ¡†æ¶èƒ½æœ‰æ•ˆä»æœåŠ¡å¯¹è¯ä¸­æå–ç¨‹åºåŒ–çŸ¥è¯†ã€‚ä¸ºäº†è§£å†³æ•°æ®ç¨€ç¼ºå’Œéšç§ä¿æŠ¤æŒ‘æˆ˜ï¼Œç ”ç©¶å¼ºè°ƒå°å‹è¯­è¨€æ¨¡å‹çš„æœ¬åœ°éƒ¨ç½²ï¼Œå¹¶åˆ›æ–°æ€§åœ°æå‡ºäº†åŸºäºæµç¨‹å›¾çš„åˆ†æ•£å¼è’¸é¦(decentralized distillation)æŠ€æœ¯ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šç§æœåŠ¡ä»»åŠ¡ä¸­çš„å®šé‡æŒ‡æ ‡å’Œåº”ç”¨è¡¨ç°å‡æ˜¾è‘—ä¼˜äºç°æœ‰åŸºå‡†æ¨¡å‹åŠå¸‚åœºäº§å“ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜æä¾›äº†åŸºäºWebçš„ç³»ç»Ÿæ¼”ç¤ºå’Œæ¡ˆä¾‹ç ”ç©¶ï¼Œä¸ºç®€åŒ–æœªæ¥æœåŠ¡è‡ªåŠ¨åŒ–çš„æ„å»ºæµç¨‹æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by TheWebConf 2026",
      "pdf_url": "https://arxiv.org/pdf/2602.15377v1",
      "published_date": "2026-02-17 06:17:37 UTC",
      "updated_date": "2026-02-17 06:17:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:39:39.739468+00:00"
    },
    {
      "arxiv_id": "2602.15376v1",
      "title": "A Unified Evaluation of Learning-Based Similarity Techniques for Malware Detection",
      "title_zh": "é¢å‘æ¶æ„è½¯ä»¶æ£€æµ‹çš„åŸºäºå­¦ä¹ çš„ç›¸ä¼¼æ€§æŠ€æœ¯ç»Ÿä¸€è¯„ä¼°",
      "authors": [
        "Udbhav Prasad",
        "Aniesh Chawla"
      ],
      "abstract": "Cryptographic digests (e.g., MD5, SHA-256) are designed to provide exact identity. Any single-bit change in the input produces a completely different hash, which is ideal for integrity verification but limits their usefulness in many real-world tasks like threat hunting, malware analysis and digital forensics, where adversaries routinely introduce minor transformations. Similarity-based techniques address this limitation by enabling approximate matching, allowing related byte sequences to produce measurably similar fingerprints. Modern enterprises manage tens of thousands of endpoints with billions of files, making the effectiveness and scalability of the proposed techniques more important than ever in security applications. Security researchers have proposed a range of approaches, including similarity digests and locality-sensitive hashes (e.g., ssdeep, sdhash, TLSH), as well as more recent machine-learning-based methods that generate embeddings from file features. However, these techniques have largely been evaluated in isolation, using disparate datasets and evaluation criteria. This paper presents a systematic comparison of learning-based classification and similarity methods using large, publicly available datasets. We evaluate each method under a unified experimental framework with industry-accepted metrics. To our knowledge, this is the first reproducible study to benchmark these diverse learning-based similarity techniques side by side for real-world security workloads. Our results show that no single approach performs well across all dimensions; instead, each exhibits distinct trade-offs, indicating that effective malware analysis and threat-hunting platforms must combine complementary classification and similarity techniques rather than rely on a single method.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ¶æ„è½¯ä»¶æ£€æµ‹ä¸­åŸºäºå­¦ä¹ çš„ç›¸ä¼¼æ€§æŠ€æœ¯(Similarity Techniques)è¿›è¡Œäº†ç»Ÿä¸€è¯„ä¼°ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»ŸåŠ å¯†æ‘˜è¦(Cryptographic Digests)å› è¿‡äºæ•æ„Ÿè€Œæ— æ³•æœ‰æ•ˆè¯†åˆ«æ¶æ„è½¯ä»¶å˜ä½“çš„é—®é¢˜ã€‚æ–‡ç« ç³»ç»Ÿåœ°æ¯”è¾ƒäº†åŒ…æ‹¬ssdeepã€sdhashã€TLSHåœ¨å†…çš„ç›¸ä¼¼æ€§æ‘˜è¦ï¼Œä»¥åŠç°ä»£åŸºäºæœºå™¨å­¦ä¹ ç”Ÿæˆçš„ç‰¹å¾åµŒå…¥(Embeddings)æ–¹æ³•ã€‚é€šè¿‡åœ¨å¤§å‹å…¬å¼€æ•°æ®é›†ä¸Šåº”ç”¨ç»Ÿä¸€çš„å®éªŒæ¡†æ¶å’Œè¡Œä¸šæ ‡å‡†æŒ‡æ ‡ï¼Œè¯¥è®ºæ–‡æä¾›äº†é¦–ä¸ªé’ˆå¯¹çœŸå®å®‰å…¨å·¥ä½œè´Ÿè½½çš„å¯é‡å¤åŸºå‡†æµ‹è¯•(Benchmark)ã€‚ç ”ç©¶å‘ç°ï¼Œæ²¡æœ‰ä»»ä½•å•ä¸€æŠ€æœ¯èƒ½åœ¨æœ‰æ•ˆæ€§å’Œå¯æ‰©å±•æ€§ç­‰æ‰€æœ‰ç»´åº¦ä¸ŠåŒæ—¶è¡¨ç°ä¼˜å¼‚ï¼Œå„æ–¹æ³•ä¹‹é—´å­˜åœ¨æ˜æ˜¾çš„æƒè¡¡(Trade-offs)ã€‚æœ€ç»ˆç»“è®ºæŒ‡å‡ºï¼Œé«˜æ•ˆçš„æ¶æ„è½¯ä»¶åˆ†æä¸å¨èƒç‹©çŒ(Threat Hunting)å¹³å°å¿…é¡»ç»“åˆäº’è¡¥çš„åˆ†ç±»ä¸ç›¸ä¼¼æ€§æŠ€æœ¯ï¼Œè€Œéä»…ä»…ä¾èµ–å•ä¸€æ–¹æ³•ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15376v1",
      "published_date": "2026-02-17 06:16:23 UTC",
      "updated_date": "2026-02-17 06:16:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:39:48.040445+00:00"
    },
    {
      "arxiv_id": "2602.15373v1",
      "title": "Far Out: Evaluating Language Models on Slang in Australian and Indian English",
      "title_zh": "Far Outï¼šé’ˆå¯¹æ¾³å¤§åˆ©äºšåŠå°åº¦è‹±è¯­ä¿šè¯­çš„è¯­è¨€æ¨¡å‹è¯„ä¼°",
      "authors": [
        "Deniz Kaya Dilsiz",
        "Dipankar Srirag",
        "Aditya Joshi"
      ],
      "abstract": "Language models exhibit systematic performance gaps when processing text in non-standard language varieties, yet their ability to comprehend variety-specific slang remains underexplored for several languages. We present a comprehensive evaluation of slang awareness in Indian English (en-IN) and Australian English (en-AU) across seven state-of-the-art language models. We construct two complementary datasets: \\textsc{web}, containing 377 web-sourced usage examples from Urban Dictionary, and \\textsc{gen}, featuring 1,492 synthetically generated usages of these slang terms, across diverse scenarios. We assess language models on three tasks: target word prediction (TWP), guided target word prediction (TWP$^*$) and target word selection (TWS). Our results reveal four key findings: (1) Higher average model performance TWS versus TWP and TWP$^*$, with average accuracy score increasing from 0.03 to 0.49 respectively (2) Stronger average model performance on \\textsc{web} versus \\textsc{gen} datasets, with average similarity score increasing by 0.03 and 0.05 across TWP and TWP$^*$ tasks respectively (3) en-IN tasks outperform en-AU when averaged across all models and datasets, with TWS demonstrating the largest disparity, increasing average accuracy from 0.44 to 0.54. These findings underscore fundamental asymmetries between generative and discriminative competencies for variety-specific language, particularly in the context of slang expressions despite being in a technologically rich language such as English.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å°åº¦è‹±è¯­ (en-IN) å’Œæ¾³å¤§åˆ©äºšè‹±è¯­ (en-AU) è¯„ä¼°äº†ä¸ƒç§ä¸»æµè¯­è¨€æ¨¡å‹å¯¹ç‰¹å®šæ–¹è¨€ä¿šè¯­çš„ç†è§£èƒ½åŠ›ã€‚ä½œè€…æ„å»ºäº†åŒ…å«çœŸå®ç½‘ç»œç”¨ä¾‹çš„ \\textsc{web} å’Œåˆæˆç”¨ä¾‹çš„ \\textsc{gen} ä¸¤ä¸ªäº’è¡¥æ•°æ®é›†ï¼Œå¹¶è®¾ç½®äº†ç›®æ ‡è¯é¢„æµ‹ (TWP)ã€å¼•å¯¼å¼ç›®æ ‡è¯é¢„æµ‹ (TWP$^*$) å’Œç›®æ ‡è¯é€‰æ‹© (TWS) ä¸‰é¡¹ä»»åŠ¡è¿›è¡Œç»¼åˆæµ‹è¯•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæ¨¡å‹åœ¨è¾¨åˆ«æ€§ä»»åŠ¡ (TWS) ä¸­çš„å‡†ç¡®ç‡æ˜¾è‘—é«˜äºç”Ÿæˆæ€§ä»»åŠ¡ (TWP/TWP$^*$)ï¼Œä¸”åœ¨çœŸå®è¯­å¢ƒä¸‹çš„è¡¨ç°ä¼˜äºåˆæˆè¯­å¢ƒã€‚æ­¤å¤–ï¼Œæ¨¡å‹åœ¨å°åº¦è‹±è¯­ä»»åŠ¡ä¸Šçš„æ•´ä½“è¡¨ç°ä¼˜äºæ¾³å¤§åˆ©äºšè‹±è¯­ï¼Œç‰¹åˆ«æ˜¯åœ¨ TWS ä»»åŠ¡ä¸­è¡¨ç°å‡ºæ˜æ˜¾çš„æ€§èƒ½å·®å¼‚ã€‚è¯¥ç ”ç©¶æ­ç¤ºäº†è¯­è¨€æ¨¡å‹åœ¨å¤„ç†ç‰¹å®šå˜ä½“è¯­è¨€çš„ä¿šè¯­è¡¨è¾¾æ—¶ï¼Œç”Ÿæˆèƒ½åŠ›ä¸è¾¨åˆ«èƒ½åŠ›ä¹‹é—´å­˜åœ¨æ˜¾è‘—çš„ä¸å¯¹ç§°æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted as a paper at 13th VarDial workshop at EACL 2026",
      "pdf_url": "https://arxiv.org/pdf/2602.15373v1",
      "published_date": "2026-02-17 05:59:20 UTC",
      "updated_date": "2026-02-17 05:59:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:40:20.189974+00:00"
    },
    {
      "arxiv_id": "2602.15368v1",
      "title": "GMAIL: Generative Modality Alignment for generated Image Learning",
      "title_zh": "GMAILï¼šé¢å‘ç”Ÿæˆå›¾åƒå­¦ä¹ çš„ç”Ÿæˆå¼æ¨¡æ€å¯¹é½",
      "authors": [
        "Shentong Mo",
        "Sukmin Yun"
      ],
      "abstract": "Generative models have made it possible to synthesize highly realistic images, potentially providing an abundant data source for training machine learning models. Despite the advantages of these synthesizable data sources, the indiscriminate use of generated images as real images for training can even cause mode collapse due to modality discrepancies between real and synthetic domains. In this paper, we propose a novel framework for discriminative use of generated images, coined GMAIL, that explicitly treats generated images as a separate modality from real images. Instead of indiscriminately replacing real images with generated ones in the pixel space, our approach bridges the two distinct modalities in the same latent space through a multi-modal learning approach. To be specific, we first fine-tune a model exclusively on generated images using a cross-modality alignment loss and then employ this aligned model to further train various vision-language models with generated images. By aligning the two modalities, our approach effectively leverages the benefits of recent advances in generative models, thereby boosting the effectiveness of generated image learning across a range of vision-language tasks. Our framework can be easily incorporated with various vision-language models, and we demonstrate its efficacy throughout extensive experiments. For example, our framework significantly improves performance on image captioning, zero-shot image retrieval, zero-shot image classification, and long caption retrieval tasks. It also shows positive generated data scaling trends and notable enhancements in the captioning performance of the large multimodal model, LLaVA.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†GMAILï¼Œä¸€ç§æ—¨åœ¨è§£å†³ç”Ÿæˆå›¾åƒå­¦ä¹ ä¸­çœŸå®ä¸åˆæˆé¢†åŸŸæ¨¡æ€å·®å¼‚å¯¼è‡´çš„æ¨¡å‹å´©æºƒé—®é¢˜çš„åˆ›æ–°æ¡†æ¶ã€‚è¯¥æ–¹æ³•ä¸å†åœ¨åƒç´ ç©ºé—´ç›²ç›®åœ°ç”¨åˆæˆå›¾åƒæ›¿ä»£çœŸå®å›¾åƒï¼Œè€Œæ˜¯å°†ç”Ÿæˆå›¾åƒè§†ä¸ºä¸çœŸå®å›¾åƒä¸åŒçš„ç‹¬ç«‹æ¨¡æ€ï¼Œå¹¶é€šè¿‡å¤šæ¨¡æ€å­¦ä¹ åœ¨å…±äº«æ½œç©ºé—´ä¸­æ¡¥æ¥ä¸¤è€…ã€‚å…·ä½“è€Œè¨€ï¼ŒGMAILé¦–å…ˆåˆ©ç”¨è·¨æ¨¡æ€å¯¹é½æŸå¤±ï¼ˆcross-modality alignment lossï¼‰åœ¨ç”Ÿæˆå›¾åƒä¸Šå¾®è°ƒæ¨¡å‹ï¼Œéšååˆ©ç”¨å¯¹é½åçš„æ¨¡å‹è¿›ä¸€æ­¥è®­ç»ƒå„ç§è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿæœ‰æ•ˆåˆ©ç”¨ç”Ÿæˆæ¨¡å‹çš„æœ€æ–°è¿›å±•ï¼Œåœ¨å›¾åƒæ ‡æ³¨ï¼ˆimage captioningï¼‰ã€é›¶æ ·æœ¬å›¾åƒæ£€ç´¢åŠåˆ†ç±»ç­‰ä»»åŠ¡ä¸­æ˜¾è‘—æå‡æ€§èƒ½ã€‚æ­¤å¤–ï¼ŒGMAILå±•ç°äº†è‰¯å¥½çš„ç”Ÿæˆæ•°æ®æ‰©å±•è¶‹åŠ¿ï¼Œå¹¶æ˜¾è‘—å¢å¼ºäº†å¤§å‹å¤šæ¨¡æ€æ¨¡å‹LLaVAçš„æ€§èƒ½ï¼Œä¸ºé«˜æ•ˆåˆ©ç”¨åˆæˆæ•°æ®æä¾›äº†æ–°é€”å¾„ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15368v1",
      "published_date": "2026-02-17 05:40:25 UTC",
      "updated_date": "2026-02-17 05:40:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:39:55.038242+00:00"
    },
    {
      "arxiv_id": "2602.15367v1",
      "title": "CDRL: A Reinforcement Learning Framework Inspired by Cerebellar Circuits and Dendritic Computational Strategies",
      "title_zh": "CDRLï¼šå—å°è„‘ç¯è·¯ä¸æ ‘çªè®¡ç®—ç­–ç•¥å¯å‘çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶",
      "authors": [
        "Sibo Zhang",
        "Rui Jing",
        "Liangfu Lv",
        "Jian Zhang",
        "Yunliang Zang"
      ],
      "abstract": "Reinforcement learning (RL) has achieved notable performance in high-dimensional sequential decision-making tasks, yet remains limited by low sample efficiency, sensitivity to noise, and weak generalization under partial observability. Most existing approaches address these issues primarily through optimization strategies, while the role of architectural priors in shaping representation learning and decision dynamics is less explored. Inspired by structural principles of the cerebellum, we propose a biologically grounded RL architecture that incorporate large expansion, sparse connectivity, sparse activation, and dendritic-level modulation. Experiments on noisy, high-dimensional RL benchmarks show that both the cerebellar architecture and dendritic modulation consistently improve sample efficiency, robustness, and generalization compared to conventional designs. Sensitivity analysis of architectural parameters suggests that cerebellum-inspired structures can offer optimized performance for RL with constrained model parameters. Overall, our work underscores the value of cerebellar structural priors as effective inductive biases for RL.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†CDRLï¼Œä¸€ç§å—å°è„‘ç”µè·¯(Cerebellar Circuits)å’Œæ ‘çªè®¡ç®—ç­–ç•¥(Dendritic Computational Strategies)å¯å‘çš„å¼ºåŒ–å­¦ä¹ (Reinforcement Learning, RL)æ¡†æ¶ã€‚é’ˆå¯¹ç°æœ‰RLæ–¹æ³•åœ¨é‡‡æ ·æ•ˆç‡(Sample Efficiency)ã€æŠ—å™ªèƒ½åŠ›ä»¥åŠéƒ¨åˆ†å¯è§‚æµ‹æ€§ä¸‹æ³›åŒ–èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ï¼Œè¯¥æ¡†æ¶å¼•å…¥äº†ç”Ÿç‰©å­¦å¯å‘çš„æ¶æ„å…ˆéªŒã€‚CDRLå…·ä½“é›†æˆäº†å°è„‘ç»“æ„åŸåˆ™ï¼ŒåŒ…æ‹¬å¤§æ‰©å¼ (Large Expansion)ã€ç¨€ç–è¿æ¥(Sparse Connectivity)ã€ç¨€ç–æ¿€æ´»(Sparse Activation)ä»¥åŠæ ‘çªçº§è°ƒåˆ¶(Dendritic-level Modulation)ã€‚åœ¨é«˜ç»´å«å™ªå£°çš„RLåŸºå‡†æµ‹è¯•ä¸­ï¼Œå®éªŒè¯æ˜è¯¥æ¶æ„ä¸è°ƒåˆ¶ç­–ç•¥ä¸€è‡´æå‡äº†æ¨¡å‹çš„é‡‡æ ·æ•ˆç‡ã€ç¨³å¥æ€§(Robustness)å’Œæ³›åŒ–æ€§èƒ½ã€‚å‚æ•°æ•æ„Ÿæ€§åˆ†æè¡¨æ˜ï¼Œå—å°è„‘å¯å‘çš„ç»“æ„åœ¨å—é™æ¨¡å‹å‚æ•°ä¸‹èƒ½æä¾›ä¼˜åŒ–çš„æ€§èƒ½ï¼Œè¿™çªæ˜¾äº†å°è„‘ç»“æ„ä½œä¸ºå¼ºåŒ–å­¦ä¹ æœ‰æ•ˆå½’çº³åç½®(Inductive Biases)çš„ä»·å€¼ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "14pages, 8 figures, 6 tabels",
      "pdf_url": "https://arxiv.org/pdf/2602.15367v1",
      "published_date": "2026-02-17 05:25:09 UTC",
      "updated_date": "2026-02-17 05:25:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:40:07.444362+00:00"
    },
    {
      "arxiv_id": "2602.15362v1",
      "title": "Automated Multi-Source Debugging and Natural Language Error Explanation for Dashboard Applications",
      "title_zh": "é¢å‘ä»ªè¡¨æ¿åº”ç”¨çš„è‡ªåŠ¨åŒ–å¤šæºè°ƒè¯•ä¸è‡ªç„¶è¯­è¨€é”™è¯¯è§£é‡Š",
      "authors": [
        "Devendra Tata",
        "Mona Rajhans"
      ],
      "abstract": "Modern web dashboards and enterprise applications increasingly rely on complex, distributed microservices architectures. While these architectures offer scalability, they introduce significant challenges in debugging and observability. When failures occur, they often manifest as opaque error messages to the end-user such as Something went wrong. This masks the underlying root cause which may reside in browser side exceptions, API contract violations, or server side logic failures. Existing monitoring tools capture these events in isolation but fail to correlate them effectively or provide intelligible explanations to non technical users. This paper proposes a novel system for Automated Multi Source Debugging and Natural Language Error Explanation. The proposed framework automatically collects and correlates error data from disparate sources such as browser, API, server logs and validates API contracts in real time, and utilizes Large Language Models to generate natural language explanations. This approach significantly reduces Mean Time to Resolution for support engineers and improves the user experience by transforming cryptic error codes into actionable insights.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§é’ˆå¯¹ä»ªè¡¨æ¿åº”ç”¨ç¨‹åºçš„è‡ªåŠ¨åŒ–å¤šæºè°ƒè¯•ä¸è‡ªç„¶è¯­è¨€é”™è¯¯è§£é‡Šç³»ç»Ÿï¼Œæ—¨åœ¨è§£å†³å¾®æœåŠ¡æ¶æ„ä¸‹é”™è¯¯ä¿¡æ¯ä¸é€æ˜ä¸”éš¾ä»¥è¿½è¸ªæ ¹å› çš„æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶èƒ½å¤Ÿè‡ªåŠ¨æ”¶é›†å¹¶å…³è”æ¥è‡ªæµè§ˆå™¨ã€APIåŠæœåŠ¡å™¨æ—¥å¿—çš„å¼‚æ„é”™è¯¯æ•°æ®ï¼Œå¹¶æ‰§è¡Œå®æ—¶çš„APIåˆçº¦éªŒè¯ä»¥ç²¾å‡†å®šä½æ•…éšœã€‚é€šè¿‡é›†æˆå¤§è¯­è¨€æ¨¡å‹(Large Language Models)ï¼Œè¯¥ç³»ç»Ÿèƒ½å°†å¤æ‚çš„ç³»ç»Ÿå¼‚å¸¸è½¬åŒ–ä¸ºæ˜“äºç†è§£çš„è‡ªç„¶è¯­è¨€æè¿°ï¼Œä¸ºéæŠ€æœ¯ç”¨æˆ·æä¾›æ¸…æ™°çš„é”™è¯¯è§£é‡Šã€‚å®éªŒè¯æ˜ï¼Œè¿™ç§æ–¹æ³•æ˜¾è‘—ç¼©çŸ­äº†æ”¯æŒå·¥ç¨‹å¸ˆçš„å¹³å‡ä¿®å¤æ—¶é—´(Mean Time to Resolution)ï¼Œå¹¶å°†éšç§˜çš„é”™è¯¯ä»£ç è½¬å˜ä¸ºå¯æ“ä½œçš„è§è§£ï¼Œä»è€Œå¤§å¹…æå‡äº†ä¼ä¸šçº§åº”ç”¨çš„è§‚æµ‹èƒ½åŠ›ä¸ç”¨æˆ·ä½“éªŒã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted for publication at the 12th (Springer CCIS) International Conference on Information Management, March 27-29, 2026, Oxford, UK",
      "pdf_url": "https://arxiv.org/pdf/2602.15362v1",
      "published_date": "2026-02-17 05:06:28 UTC",
      "updated_date": "2026-02-17 05:06:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:40:35.844106+00:00"
    },
    {
      "arxiv_id": "2602.15353v1",
      "title": "NeuroSymActive: Differentiable Neural-Symbolic Reasoning with Active Exploration for Knowledge Graph Question Answering",
      "title_zh": "NeuroSymActiveï¼šé¢å‘çŸ¥è¯†å›¾è°±é—®ç­”çš„ç»“åˆä¸»åŠ¨æ¢ç´¢çš„å¯å¾®ç¥ç»ç¬¦å·æ¨ç†",
      "authors": [
        "Rong Fu",
        "Yang Li",
        "Zeyu Zhang",
        "Jiekai Wu",
        "Yaohua Liu",
        "Shuaishuai Cao",
        "Yangchen Zeng",
        "Yuhang Zhang",
        "Xiaojing Du",
        "Chuang Zhao",
        "Kangning Cui",
        "Simon Fong"
      ],
      "abstract": "Large pretrained language models and neural reasoning systems have advanced many natural language tasks, yet they remain challenged by knowledge-intensive queries that require precise, structured multi-hop inference. Knowledge graphs provide a compact symbolic substrate for factual grounding, but integrating graph structure with neural models is nontrivial: naively embedding graph facts into prompts leads to inefficiency and fragility, while purely symbolic or search-heavy approaches can be costly in retrievals and lack gradient-based refinement. We introduce NeuroSymActive, a modular framework that combines a differentiable neural-symbolic reasoning layer with an active, value-guided exploration controller for Knowledge Graph Question Answering. The method couples soft-unification style symbolic modules with a neural path evaluator and a Monte-Carlo style exploration policy that prioritizes high-value path expansions. Empirical results on standard KGQA benchmarks show that NeuroSymActive attains strong answer accuracy while reducing the number of expensive graph lookups and model calls compared to common retrieval-augmented baselines.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹åœ¨å¤„ç†çŸ¥è¯†å¯†é›†å‹æŸ¥è¯¢å’Œå¤šè·³æ¨ç†(Multi-hop Inference)æ—¶é¢ä¸´çš„æ•ˆç‡ä½ã€ç¼ºä¹æ¢¯åº¦ä¼˜åŒ–åŠæ¨ç†è„†å¼±ç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº†NeuroSymActiveæ¡†æ¶ã€‚è¿™æ˜¯ä¸€ç§ä¸“ä¸ºçŸ¥è¯†å›¾è°±é—®ç­”(KGQA)è®¾è®¡çš„æ¨¡å—åŒ–æ¡†æ¶ï¼Œé€šè¿‡å°†å¯å¾®çš„ç¥ç»ç¬¦å·æ¨ç†å±‚(Differentiable Neural-Symbolic Reasoning Layer)ä¸ä¸»åŠ¨çš„ã€åŸºäºä»·å€¼å¼•å¯¼çš„æ¢ç´¢æ§åˆ¶å™¨(Active, Value-guided Exploration Controller)ç›¸ç»“åˆæ¥å®ç°ã€‚è¯¥æ–¹æ³•è€¦åˆäº†è½¯ç»Ÿä¸€(Soft-unification)é£æ ¼çš„ç¬¦å·æ¨¡å—ã€ç¥ç»è·¯å¾„è¯„ä¼°å™¨(Neural Path Evaluator)ä»¥åŠè’™ç‰¹å¡æ´›(Monte-Carlo)é£æ ¼çš„æ¢ç´¢ç­–ç•¥ï¼Œæ—¨åœ¨ä¼˜å…ˆæ‰©å±•é«˜ä»·å€¼è·¯å¾„ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒNeuroSymActiveåœ¨æ ‡å‡†KGQAåŸºå‡†æµ‹è¯•ä¸Šå–å¾—äº†æé«˜çš„ç­”æ¡ˆå‡†ç¡®ç‡ã€‚ä¸å¸¸è§çš„æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)åŸºçº¿æ¨¡å‹ç›¸æ¯”ï¼Œè¯¥æ¡†æ¶æ˜¾è‘—å‡å°‘äº†æ˜‚è´µçš„å›¾æŸ¥è¯¢å’Œæ¨¡å‹è°ƒç”¨æ¬¡æ•°ï¼Œè¯æ˜äº†å…¶åœ¨ç»“æ„åŒ–æ¨ç†ä»»åŠ¡ä¸­çš„é«˜æ•ˆæ€§ä¸ä¼˜è¶Šæ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "26 pages, 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.15353v1",
      "published_date": "2026-02-17 04:47:29 UTC",
      "updated_date": "2026-02-17 04:47:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:40:36.756493+00:00"
    },
    {
      "arxiv_id": "2602.15350v1",
      "title": "Fine-Tuning LLMs to Generate Economical and Reliable Actions for the Power Grid",
      "title_zh": "é¢å‘ç”µç½‘ç»æµå¯é æ“ä½œç”Ÿæˆçš„å¤§è¯­è¨€æ¨¡å‹å¾®è°ƒ",
      "authors": [
        "Mohamad Chehade",
        "Hao Zhu"
      ],
      "abstract": "Public Safety Power Shutoffs (PSPS) force rapid topology changes that can render standard operating points infeasible, requiring operators to quickly identify corrective transmission switching actions that reduce load shedding while maintaining acceptable voltage behavior. We present a verifiable, multi-stage adaptation pipeline that fine-tunes an instruction-tuned large language model (LLM) to generate \\emph{open-only} corrective switching plans from compact PSPS scenario summaries under an explicit switching budget. First, supervised fine-tuning distills a DC-OPF MILP oracle into a constrained action grammar that enables reliable parsing and feasibility checks. Second, direct preference optimization refines the policy using AC-evaluated preference pairs ranked by a voltage-penalty metric, injecting voltage-awareness beyond DC imitation. Finally, best-of-$N$ selection provides an inference-time addition by choosing the best feasible candidate under the target metric. On IEEE 118-bus PSPS scenarios, fine-tuning substantially improves DC objective values versus zero-shot generation, reduces AC power-flow failure from 50\\% to single digits, and improves voltage-penalty outcomes on the common-success set. Code and data-generation scripts are released to support reproducibility.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§å¤šé˜¶æ®µé€‚é…æµç¨‹ï¼Œæ—¨åœ¨å¯¹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¿›è¡Œå¾®è°ƒï¼Œä»¥ä¾¿åœ¨å…¬å…±ç”µåŠ›å®‰å…¨åˆ‡æ–­ï¼ˆPSPSï¼‰å¯¼è‡´ç”µç½‘æ‹“æ‰‘å¿«é€Ÿå˜åŒ–çš„åœºæ™¯ä¸‹ï¼Œç”Ÿæˆç»æµä¸”å¯é çš„çº æ­£æ€§ä¼ è¾“å¼€å…³åŠ¨ä½œã€‚é¦–å…ˆï¼Œé€šè¿‡æœ‰ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰å°†DC-OPF MILPé¢„è¨€æœºçš„å†³ç­–çŸ¥è¯†è’¸é¦ä¸ºå—é™åŠ¨ä½œè¯­æ³•ï¼Œç¡®ä¿æ¨¡å‹ç”Ÿæˆçš„æ–¹æ¡ˆå…·å¤‡å¯è§£ææ€§ä¸åˆæ­¥å¯è¡Œæ€§ã€‚æ¥ç€ï¼Œåˆ©ç”¨ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰å¹¶ç»“åˆåŸºäºäº¤æµï¼ˆACï¼‰æ½®æµè¯„ä¼°çš„åå¥½å¯¹è¿›è¡Œç­–ç•¥ç²¾ç‚¼ï¼Œèµ‹äºˆæ¨¡å‹åœ¨ç›´æµï¼ˆDCï¼‰æ¨¡æ‹Ÿä¹‹å¤–çš„ç”µå‹æ„ŸçŸ¥èƒ½åŠ›ã€‚åœ¨æ¨ç†é˜¶æ®µï¼Œç ”ç©¶é‡‡ç”¨Best-of-Né€‰æ‹©æœºåˆ¶ï¼Œä»ç”Ÿæˆçš„å¤šä¸ªå€™é€‰æ–¹æ¡ˆä¸­ç­›é€‰å‡ºç›®æ ‡æŒ‡æ ‡ä¸‹çš„æœ€ä¼˜è§£ã€‚åœ¨IEEE 118-busç³»ç»Ÿçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—æå‡äº†DCç›®æ ‡å‡½æ•°å€¼ï¼Œå¹¶å°†ACæ½®æµè®¡ç®—çš„å¤±è´¥ç‡ä»50%é™ä½è‡³ä¸ªä½æ•°ï¼ŒåŒæ—¶æœ‰æ•ˆä¼˜åŒ–äº†ç”µå‹æƒ©ç½šç»“æœã€‚æ­¤é¡¹å·¥ä½œè¯æ˜äº†é€šè¿‡ç‰¹å®šçš„å¾®è°ƒæŠ€æœ¯ï¼ŒLLMèƒ½å¤Ÿä¸ºå¤æ‚çš„ç”µåŠ›ç³»ç»Ÿè¿è¡Œæä¾›å¯éªŒè¯ä¸”é«˜æ€§èƒ½çš„å†³ç­–æ”¯æŒã€‚",
      "categories": [
        "eess.SY",
        "cs.AI"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15350v1",
      "published_date": "2026-02-17 04:33:02 UTC",
      "updated_date": "2026-02-17 04:33:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:40:45.641070+00:00"
    },
    {
      "arxiv_id": "2602.15339v1",
      "title": "Benchmarking Self-Supervised Models for Cardiac Ultrasound View Classification",
      "title_zh": "å¿ƒè„è¶…å£°åˆ‡é¢åˆ†ç±»è‡ªç›‘ç£æ¨¡å‹çš„åŸºå‡†æµ‹è¯•",
      "authors": [
        "Youssef Megahed",
        "Salma I. Megahed",
        "Robin Ducharme",
        "Inok Lee",
        "Adrian D. C. Chan",
        "Mark C. Walker",
        "Steven Hawken"
      ],
      "abstract": "Reliable interpretation of cardiac ultrasound images is essential for accurate clinical diagnosis and assessment. Self-supervised learning has shown promise in medical imaging by leveraging large unlabelled datasets to learn meaningful representations. In this study, we evaluate and compare two self-supervised learning frameworks, USF-MAE, developed by our team, and MoCo v3, on the recently introduced CACTUS dataset (37,736 images) for automated simulated cardiac view (A4C, PL, PSAV, PSMV, Random, and SC) classification. Both models used 5-fold cross-validation, enabling robust assessment of generalization performance across multiple random splits. The CACTUS dataset provides expert-annotated cardiac ultrasound images with diverse views. We adopt an identical training protocol for both models to ensure a fair comparison. Both models are configured with a learning rate of 0.0001 and a weight decay of 0.01. For each fold, we record performance metrics including ROC-AUC, accuracy, F1-score, and recall. Our results indicate that USF-MAE consistently outperforms MoCo v3 across metrics. The average testing AUC for USF-MAE is 99.99% (+/-0.01% 95% CI), compared to 99.97% (+/-0.01%) for MoCo v3. USF-MAE achieves a mean testing accuracy of 99.33% (+/-0.18%), higher than the 98.99% (+/-0.28%) reported for MoCo v3. Similar trends are observed for the F1-score and recall, with improvements statistically significant across folds (paired t-test, p=0.0048 < 0.01). This proof-of-concept analysis suggests that USF-MAE learns more discriminative features for cardiac view classification than MoCo v3 when applied to this dataset. The enhanced performance across multiple metrics highlights the potential of USF-MAE for improving automated cardiac ultrasound classification.",
      "tldr_zh": "æœ¬ç ”ç©¶è¯„ä¼°å¹¶æ¯”è¾ƒäº†è‡ªç›‘ç£å­¦ä¹ (Self-supervised learning)æ¡†æ¶åœ¨å¿ƒè„è¶…å£°åˆ‡é¢åˆ†ç±»ä»»åŠ¡ä¸­çš„æ€§èƒ½è¡¨ç°ã€‚ç ”ç©¶å›¢é˜Ÿåœ¨åŒ…å«37,736å¼ å›¾åƒçš„CACTUSæ•°æ®é›†ä¸Šï¼Œå¯¹è‡ªä¸»å¼€å‘çš„USF-MAEæ¨¡å‹ä¸MoCo v3æ¨¡å‹è¿›è¡Œäº†åŸºå‡†æµ‹è¯•ï¼Œæ¶µç›–äº†A4Cã€PLã€PSAVã€PSMVç­‰å¤šç§å¿ƒè„æ¨¡æ‹Ÿåˆ‡é¢çš„è‡ªåŠ¨åŒ–åˆ†ç±»ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒUSF-MAEåœ¨å„é¡¹è¯„ä¼°æŒ‡æ ‡ä¸Šå‡æŒç»­ä¼˜äºMoCo v3ï¼Œå…¶å¹³å‡æµ‹è¯•å‡†ç¡®ç‡è¾¾åˆ°99.33%ï¼ŒROC-AUCé«˜è¾¾99.99%ã€‚é€šè¿‡é…å¯¹tæ£€éªŒéªŒè¯ï¼ŒUSF-MAEåœ¨F1-scoreå’Œå¬å›ç‡(Recall)ç­‰æ–¹é¢çš„æå‡å…·æœ‰ç»Ÿè®¡å­¦æ˜¾è‘—æ€§(p<0.01)ã€‚è¯¥æ¦‚å¿µéªŒè¯åˆ†æè¯æ˜ï¼Œç›¸æ¯”äºMoCo v3ï¼ŒUSF-MAEèƒ½é’ˆå¯¹å¿ƒè„åˆ‡é¢å­¦ä¹ åˆ°æ›´å…·åˆ¤åˆ«æ€§çš„ç‰¹å¾ï¼Œå±•ç¤ºäº†å…¶åœ¨æå‡å¿ƒè„è¶…å£°è‡ªåŠ¨åŒ–ä¸´åºŠè¯Šæ–­ç²¾åº¦æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "10 pages, 3 figures, 3 tables",
      "pdf_url": "https://arxiv.org/pdf/2602.15339v1",
      "published_date": "2026-02-17 04:00:16 UTC",
      "updated_date": "2026-02-17 04:00:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:40:49.743142+00:00"
    },
    {
      "arxiv_id": "2602.15337v1",
      "title": "FedPSA: Modeling Behavioral Staleness in Asynchronous Federated Learning",
      "title_zh": "FedPSAï¼šå¼‚æ­¥è”é‚¦å­¦ä¹ ä¸­çš„è¡Œä¸ºé™ˆæ—§æ€§å»ºæ¨¡",
      "authors": [
        "Chaoyi Lu"
      ],
      "abstract": "Asynchronous Federated Learning (AFL) has emerged as a significant research area in recent years. By not waiting for slower clients and executing the training process concurrently, it achieves faster training speed compared to traditional federated learning. However, due to the staleness introduced by the asynchronous process, its performance may degrade in some scenarios. Existing methods often use the round difference between the current model and the global model as the sole measure of staleness, which is coarse-grained and lacks observation of the model itself, thereby limiting the performance ceiling of asynchronous methods. In this paper, we propose FedPSA (Parameter Sensitivity-based Asynchronous Federated Learning), a more fine-grained AFL framework that leverages parameter sensitivity to measure model obsolescence and establishes a dynamic momentum queue to assess the current training phase in real time, thereby adjusting the tolerance for outdated information dynamically. Extensive experiments on multiple datasets and comparisons with various methods demonstrate the superior performance of FedPSA, achieving up to 6.37\\% improvement over baseline methods and 1.93\\% over the current state-of-the-art method.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¼‚æ­¥è”é‚¦å­¦ä¹ (Asynchronous Federated Learning, AFL)ä¸­ç”±äºå¼‚æ­¥è¿‡ç¨‹å¼•å…¥çš„é™ˆæ—§æ€§(staleness)å¯¼è‡´æ€§èƒ½ä¸‹é™çš„é—®é¢˜å±•å¼€è®¨è®ºã€‚ç°æœ‰çš„AFLæ–¹æ³•é€šå¸¸ä»…ä»¥è½®æ¬¡å·®å¼‚ä½œä¸ºè¡¡é‡é™ˆæ—§æ€§çš„ç²—ç²’åº¦æ ‡å‡†ï¼Œç¼ºä¹å¯¹æ¨¡å‹æœ¬èº«çŠ¶æ€çš„è§‚å¯Ÿï¼Œä»è€Œé™åˆ¶äº†æ€§èƒ½ä¸Šé™ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†FedPSA (Parameter Sensitivity-based Asynchronous Federated Learning)æ¡†æ¶ï¼Œåˆ©ç”¨å‚æ•°æ•æ„Ÿåº¦(parameter sensitivity)æ¥æ›´ç»†ç²’åº¦åœ°è¡¡é‡æ¨¡å‹çš„è¿‡æ—¶ç¨‹åº¦ã€‚è¯¥æ¡†æ¶é€šè¿‡å»ºç«‹åŠ¨æ€åŠ¨é‡é˜Ÿåˆ—(dynamic momentum queue)æ¥å®æ—¶è¯„ä¼°å½“å‰çš„è®­ç»ƒé˜¶æ®µï¼Œä»è€Œèƒ½å¤ŸåŠ¨æ€è°ƒæ•´ç³»ç»Ÿå¯¹è¿‡æœŸä¿¡æ¯çš„å®¹å¿åº¦ã€‚åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒFedPSAç›¸æ¯”åŸºçº¿æ–¹æ³•æ€§èƒ½æå‡äº†é«˜è¾¾6.37%ï¼Œå¹¶æ¯”å½“å‰æœ€å…ˆè¿›çš„æ–¹æ³•(state-of-the-art)é«˜å‡º1.93%ã€‚è¿™ä¸€ç ”ç©¶é€šè¿‡æ›´ç²¾ç¡®çš„é™ˆæ—§æ€§å»ºæ¨¡ï¼Œæ˜¾è‘—å¢å¼ºäº†å¼‚æ­¥è”é‚¦å­¦ä¹ åœ¨å¤æ‚åœºæ™¯ä¸‹çš„è¡¨ç°ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15337v1",
      "published_date": "2026-02-17 03:57:07 UTC",
      "updated_date": "2026-02-17 03:57:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:40:51.939813+00:00"
    },
    {
      "arxiv_id": "2602.15330v1",
      "title": "A Scalable Curiosity-Driven Game-Theoretic Framework for Long-Tail Multi-Label Learning in Data Mining",
      "title_zh": "æ•°æ®æŒ–æ˜ä¸­é•¿å°¾å¤šæ ‡ç­¾å­¦ä¹ çš„å¯æ‰©å±•å¥½å¥‡å¿ƒé©±åŠ¨åšå¼ˆè®ºæ¡†æ¶",
      "authors": [
        "Jing Yang",
        "Keze Wang"
      ],
      "abstract": "The long-tail distribution, where a few head labels dominate while rare tail labels abound, poses a persistent challenge for large-scale Multi-Label Classification (MLC) in real-world data mining applications. Existing resampling and reweighting strategies often disrupt inter-label dependencies or require brittle hyperparameter tuning, especially as the label space expands to tens of thousands of labels. To address this issue, we propose Curiosity-Driven Game-Theoretic Multi-Label Learning (CD-GTMLL), a scalable cooperative framework that recasts long-tail MLC as a multi-player game - each sub-predictor (\"player\") specializes in a partition of the label space, collaborating to maximize global accuracy while pursuing intrinsic curiosity rewards based on tail label rarity and inter-player disagreement. This mechanism adaptively injects learning signals into under-represented tail labels without manual balancing or tuning. We further provide a theoretical analysis showing that our CD-GTMLL converges to a tail-aware equilibrium and formally links the optimization dynamics to improvements in the Rare-F1 metric. Extensive experiments across 7 benchmarks, including extreme multi-label classification datasets with 30,000+ labels, demonstrate that CD-GTMLL consistently surpasses state-of-the-art methods, with gains up to +1.6% P@3 on Wiki10-31K. Ablation studies further confirm the contributions of both game-theoretic cooperation and curiosity-driven exploration to robust tail performance. By integrating game theory with curiosity mechanisms, CD-GTMLL not only enhances model efficiency in resource-constrained environments but also paves the way for more adaptive learning in imbalanced data scenarios across industries like e-commerce and healthcare.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è§„æ¨¡å¤šæ ‡ç­¾åˆ†ç±»(Multi-Label Classification, MLC)ä¸­é•¿å°¾åˆ†å¸ƒ(Long-tail distribution)å¸¦æ¥çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†åä¸ºCD-GTMLLçš„å¯æ‰©å±•åä½œæ¡†æ¶ã€‚è¯¥æ¡†æ¶å°†é•¿å°¾MLCé‡æ–°å®šä¹‰ä¸ºä¸€ä¸ªå¤šåšå¼ˆè€…åšå¼ˆï¼Œå…¶ä¸­æ¯ä¸ªå­é¢„æµ‹å™¨ä½œä¸ºåšå¼ˆè€…è´Ÿè´£æ ‡ç­¾ç©ºé—´çš„ä¸€ä¸ªåˆ†åŒºï¼Œé€šè¿‡åä½œæœ€å¤§åŒ–å…¨å±€å‡†ç¡®æ€§ï¼Œå¹¶è¿½æ±‚åŸºäºå°¾éƒ¨æ ‡ç­¾ç¨€ç¼ºæ€§å’Œåšå¼ˆè€…é—´åˆ†æ­§çš„å†…åœ¨å¥½å¥‡å¿ƒå¥–åŠ±(intrinsic curiosity rewards)ã€‚è¿™ç§æœºåˆ¶èƒ½å¤Ÿåœ¨ä¸éœ€è¦æ‰‹åŠ¨å¹³è¡¡æˆ–è°ƒä¼˜çš„æƒ…å†µä¸‹ï¼Œè‡ªé€‚åº”åœ°ä¸ºä»£è¡¨æ€§ä¸è¶³çš„å°¾éƒ¨æ ‡ç­¾æ³¨å…¥å­¦ä¹ ä¿¡å·ã€‚ç†è®ºåˆ†æè¯æ˜CD-GTMLLèƒ½å¤Ÿæ”¶æ•›åˆ°å°¾éƒ¨æ„ŸçŸ¥çš„å‡è¡¡çŠ¶æ€ï¼Œå¹¶åœ¨ä¼˜åŒ–åŠ¨æ€ä¸Rare-F1æŒ‡æ ‡æå‡ä¹‹é—´å»ºç«‹äº†æ­£å¼è”ç³»ã€‚åœ¨åŒ…å«è¶…è¿‡3ä¸‡ä¸ªæ ‡ç­¾çš„Wiki10-31Kç­‰7ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒCD-GTMLLåœ¨æ€§èƒ½ä¸ŠæŒç»­è¶…è¶Šç°æœ‰æœ€å…ˆè¿›æ–¹æ³•ï¼Œä¾‹å¦‚åœ¨Wiki10-31Kä¸Šå–å¾—äº†+1.6% P@3çš„æå‡ã€‚æ¶ˆèç ”ç©¶è¿›ä¸€æ­¥è¯å®äº†åšå¼ˆè®ºåä½œä¸å¥½å¥‡å¿ƒé©±åŠ¨æ¢ç´¢å¯¹å¢å¼ºé•¿å°¾æ€§èƒ½çš„è´¡çŒ®ï¼Œä¸ºç”µå­å•†åŠ¡å’ŒåŒ»ç–—ä¿å¥ç­‰é¢†åŸŸçš„å¤±è¡¡æ•°æ®åœºæ™¯æä¾›äº†æ›´å…·é€‚åº”æ€§çš„å­¦ä¹ æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15330v1",
      "published_date": "2026-02-17 03:33:23 UTC",
      "updated_date": "2026-02-17 03:33:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:41:20.134155+00:00"
    },
    {
      "arxiv_id": "2602.15327v1",
      "title": "Prescriptive Scaling Reveals the Evolution of Language Model Capabilities",
      "title_zh": "è§„å®šæ€§ç¼©æ”¾æ­ç¤ºè¯­è¨€æ¨¡å‹èƒ½åŠ›çš„æ¼”è¿›",
      "authors": [
        "Hanlin Zhang",
        "Jikai Jin",
        "Vasilis Syrgkanis",
        "Sham Kakade"
      ],
      "abstract": "For deploying foundation models, practitioners increasingly need prescriptive scaling laws: given a pre training compute budget, what downstream accuracy is attainable with contemporary post training practice, and how stable is that mapping as the field evolves? Using large scale observational evaluations with 5k observational and 2k newly sampled data on model performance, we estimate capability boundaries, high conditional quantiles of benchmark scores as a function of log pre training FLOPs, via smoothed quantile regression with a monotone, saturating sigmoid parameterization. We validate the temporal reliability by fitting on earlier model generations and evaluating on later releases. Across various tasks, the estimated boundaries are mostly stable, with the exception of math reasoning that exhibits a consistently advancing boundary over time. We then extend our approach to analyze task dependent saturation and to probe contamination related shifts on math reasoning tasks. Finally, we introduce an efficient algorithm that recovers near full data frontiers using roughly 20% of evaluation budget. Together, our work releases the Proteus 2k, the latest model performance evaluation dataset, and introduces a practical methodology for translating compute budgets into reliable performance expectations and for monitoring when capability boundaries shift across time.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†è§„èŒƒæ€§ç¼©æ”¾å®šå¾‹(Prescriptive Scaling Laws)ï¼Œæ—¨åœ¨é‡åŒ–åœ¨ç‰¹å®šé¢„è®­ç»ƒè®¡ç®—é¢„ç®—(pre-training compute budget)ä¸‹ï¼Œç»“åˆå½“ä»£åè®­ç»ƒå®è·µæ‰€èƒ½è¾¾åˆ°çš„ä¸‹æ¸¸ä»»åŠ¡å‡†ç¡®ç‡åŠå…¶éšæ—¶é—´çš„ç¨³å®šæ€§ã€‚ä½œè€…åˆ©ç”¨åŒ…å«5000æ¡è§‚æµ‹æ•°æ®å’Œ2000æ¡æ–°é‡‡æ ·æ•°æ®çš„Proteus 2kæ•°æ®é›†ï¼Œé€šè¿‡å…·æœ‰å•è°ƒé¥±å’ŒSigmoidå‚æ•°åŒ–çš„å¹³æ»‘åˆ†ä½æ•°å›å½’(smoothed quantile regression)æ–¹æ³•ï¼Œä¼°è®¡äº†ä½œä¸ºè®­ç»ƒFLOPså‡½æ•°çš„æ¨¡å‹èƒ½åŠ›è¾¹ç•Œã€‚ç ”ç©¶é€šè¿‡åœ¨æ—©æœŸæ¨¡å‹ä¸Šæ‹Ÿåˆå¹¶åœ¨åæœŸæ¨¡å‹ä¸ŠéªŒè¯ï¼Œç¡®è®¤äº†å¤§å¤šæ•°ä»»åŠ¡çš„èƒ½åŠ›è¾¹ç•Œå…·æœ‰æ—¶é—´å¯é æ€§ï¼Œä½†æ•°å­¦æ¨ç†(math reasoning)é¢†åŸŸçš„è¾¹ç•Œéšæ—¶é—´å‘ˆç°å‡ºæŒç»­æ¨è¿›çš„æ€åŠ¿ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜åˆ†æäº†ä»»åŠ¡ç›¸å…³çš„é¥±å’Œç°è±¡åŠæ•°æ®æ±¡æŸ“(contamination)å¯¹æ•°å­¦æ¨ç†çš„å½±å“ï¼Œå¹¶æå‡ºäº†ä¸€ç§ä»…éœ€20%è¯„ä¼°é¢„ç®—å³å¯æ¢å¤æ•°æ®å‰æ²¿(frontiers)çš„é«˜æ•ˆç®—æ³•ã€‚è¯¥å·¥ä½œä¸ä»…å‘å¸ƒäº†æœ€æ–°çš„Proteus 2kè¯„ä¼°æ•°æ®é›†ï¼Œè¿˜ä¸ºå°†è®¡ç®—é¢„ç®—è½¬åŒ–ä¸ºå¯é çš„æ€§èƒ½é¢„æœŸä»¥åŠç›‘æ§èƒ½åŠ›è¾¹ç•Œæ¼”å˜æä¾›äº†å®ç”¨çš„æ–¹æ³•è®ºã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Blog Post: https://jkjin.com/prescriptive-scaling",
      "pdf_url": "https://arxiv.org/pdf/2602.15327v1",
      "published_date": "2026-02-17 03:13:51 UTC",
      "updated_date": "2026-02-17 03:13:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:41:21.838614+00:00"
    },
    {
      "arxiv_id": "2602.15326v1",
      "title": "SCENE OTA-FD: Self-Centering Noncoherent Estimator for Over-the-Air Federated Distillation",
      "title_zh": "SCENE OTA-FDï¼šé¢å‘ç©ºä¸­è”é‚¦è’¸é¦çš„è‡ªä¸­å¿ƒåŒ–éç›¸å¹²ä¼°è®¡å™¨",
      "authors": [
        "Hao Chen",
        "Zavareh Bozorgasl"
      ],
      "abstract": "We propose SCENE (Self-Centering Noncoherent Estimator), a pilot-free and phase-invariant aggregation primitive for over-the-air federated distillation (OTA-FD). Each device maps its soft-label (class-probability) vector to nonnegative transmit energies under constant per-round power and constant-envelope signaling (PAPR near 1). At the server, a self-centering energy estimator removes the noise-energy offset and yields an unbiased estimate of the weighted soft-label average, with variance decaying on the order of 1/(SM) in the number of receive antennas M and repetition factor S. We also develop a pilot-free ratio-normalized variant that cancels unknown large-scale gains, provide a convergence bound consistent with coherent OTA-FD analyses, and present an overhead-based crossover comparison. SCENE targets short-coherence and hardware-constrained regimes, where avoiding per-round CSI is essential: it trades a modest noncoherent variance constant for zero uplink pilots, unbiased aggregation, and hardware-friendly transmission, and can outperform coherent designs when pilot overhead is non-negligible.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†SCENE (Self-Centering Noncoherent Estimator)ï¼Œè¿™æ˜¯ä¸€ç§ä¸ºç©ºä¸­è”é‚¦è’¸é¦ (Over-the-Air Federated Distillation, OTA-FD) è®¾è®¡çš„æ— å¯¼é¢‘ä¸”ç›¸ä½ä¸å˜çš„èšåˆåŸè¯­ã€‚åœ¨è¯¥æ¡†æ¶ä¸‹ï¼Œæ¯ä¸ªè®¾å¤‡å°†å…¶è½¯æ ‡ç­¾ (soft-label) å‘é‡æ˜ å°„ä¸ºéè´Ÿä¼ è¾“èƒ½é‡ï¼Œå¹¶é‡‡ç”¨æ’å®šåŒ…ç»œä¿¡å· (constant-envelope signaling) ä»¥å®ç°æä½çš„å³°å‡åŠŸç‡æ¯” (PAPR)ã€‚æœåŠ¡ç«¯åˆ©ç”¨è‡ªä¸­å¿ƒèƒ½é‡ä¼°è®¡å™¨æ¶ˆé™¤å™ªå£°èƒ½é‡åç§»ï¼Œä»è€Œè·å¾—åŠ æƒè½¯æ ‡ç­¾å¹³å‡å€¼çš„æ— åä¼°è®¡ï¼Œå…¶ä¼°è®¡æ–¹å·®éšæ¥æ”¶å¤©çº¿æ•°å’Œé‡å¤å› å­çš„å¢åŠ è€Œæœ‰æ•ˆè¡°å‡ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å¼€å‘äº†æ¯”ä¾‹å½’ä¸€åŒ–å˜ä½“ä»¥åº”å¯¹æœªçŸ¥çš„å¤§å°ºåº¦å¢ç›Šï¼Œå¹¶æä¾›äº†ä¸ç›¸å¹²OTA-FDåˆ†æä¸€è‡´çš„æ”¶æ•›ç•Œé™ã€‚SCENEç‰¹åˆ«é€‚ç”¨äºçŸ­ç›¸å¹²æ—¶é—´å’Œç¡¬ä»¶å—é™çš„åœºæ™¯ï¼Œé€šè¿‡ç‰ºç‰²é€‚åº¦çš„éç›¸å¹²æ–¹å·®æ¢å–é›¶ä¸Šè¡Œå¯¼é¢‘å¼€é”€å’Œç¡¬ä»¶å‹å¥½çš„ä¼ è¾“ã€‚å®éªŒè¡¨æ˜ï¼Œåœ¨å¯¼é¢‘å¼€é”€æ˜¾è‘—çš„æƒ…å†µä¸‹ï¼Œè¯¥æ–¹æ¡ˆçš„æ€§èƒ½ä¼˜äºä¼ ç»Ÿç›¸å¹²è®¾è®¡ï¼Œä¸ºå»ä¸­å¿ƒåŒ–æ¨¡å‹è’¸é¦æä¾›äº†ä¸€ç§é«˜æ•ˆä¸”ç¨³å¥çš„èšåˆæœºåˆ¶ã€‚",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.DC",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "Work in progress. Codes will be available on: https://github.com/zavareh1",
      "pdf_url": "https://arxiv.org/pdf/2602.15326v1",
      "published_date": "2026-02-17 03:13:32 UTC",
      "updated_date": "2026-02-17 03:13:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:41:09.935712+00:00"
    },
    {
      "arxiv_id": "2602.15325v1",
      "title": "AgriWorld:A World Tools Protocol Framework for Verifiable Agricultural Reasoning with Code-Executing LLM Agents",
      "title_zh": "AgriWorldï¼šåŸºäºä»£ç æ‰§è¡Œ LLM æ™ºèƒ½ä½“çš„å¯éªŒè¯å†œä¸šæ¨ç†ä¸–ç•Œå·¥å…·åè®®æ¡†æ¶",
      "authors": [
        "Zhixing Zhang",
        "Jesen Zhang",
        "Hao Liu",
        "Qinhan Lv",
        "Jing Yang",
        "Kaitong Cai",
        "Keze Wang"
      ],
      "abstract": "Foundation models for agriculture are increasingly trained on massive spatiotemporal data (e.g., multi-spectral remote sensing, soil grids, and field-level management logs) and achieve strong performance on forecasting and monitoring. However, these models lack language-based reasoning and interactive capabilities, limiting their usefulness in real-world agronomic workflows. Meanwhile, large language models (LLMs) excel at interpreting and generating text, but cannot directly reason over high-dimensional, heterogeneous agricultural datasets. We bridge this gap with an agentic framework for agricultural science. It provides a Python execution environment, AgriWorld, exposing unified tools for geospatial queries over field parcels, remote-sensing time-series analytics, crop growth simulation, and task-specific predictors (e.g., yield, stress, and disease risk). On top of this environment, we design a multi-turn LLM agent, Agro-Reflective, that iteratively writes code, observes execution results, and refines its analysis via an execute-observe-refine loop. We introduce AgroBench, with scalable data generation for diverse agricultural QA spanning lookups, forecasting, anomaly detection, and counterfactual \"what-if\" analysis. Experiments outperform text-only and direct tool-use baselines, validating execution-driven reflection for reliable agricultural reasoning.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†AgriWorldï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨å¼¥åˆå†œä¸šåŸºç¡€æ¨¡å‹ä¸å¤§è¯­è¨€æ¨¡å‹(LLMs)ä¹‹é—´é¸¿æ²Ÿçš„æ™ºèƒ½ä½“æ¡†æ¶ï¼Œè§£å†³äº†ç°æœ‰æ¨¡å‹åœ¨å¤„ç†é«˜ç»´å¼‚æ„å†œä¸šæ•°æ®æ—¶ç¼ºä¹è¯­è¨€æ¨ç†å’Œäº¤äº’èƒ½åŠ›çš„é—®é¢˜ã€‚AgriWorldæä¾›äº†ä¸€ä¸ªPythonæ‰§è¡Œç¯å¢ƒï¼Œæ•´åˆäº†åœ°ç†ç©ºé—´æŸ¥è¯¢ã€é¥æ„Ÿæ—¶é—´åºåˆ—åˆ†æã€ä½œç‰©ç”Ÿé•¿æ¨¡æ‹Ÿä»¥åŠäº§é‡ä¸ç—…å®³é£é™©é¢„æµ‹ç­‰ç»Ÿä¸€å·¥å…·ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œç ”ç©¶è€…è®¾è®¡äº†å¤šè½®å¯¹è¯æ™ºèƒ½ä½“Agro-Reflectiveï¼Œé€šè¿‡â€œæ‰§è¡Œ-è§‚å¯Ÿ-ä¼˜åŒ–â€(execute-observe-refine)å¾ªç¯è¿­ä»£ç¼–å†™ä»£ç å¹¶æ”¹è¿›åˆ†æã€‚è¯¥å›¢é˜Ÿè¿˜æ¨å‡ºäº†AgroBenchåŸºå‡†æµ‹è¯•ï¼Œæ¶µç›–äº†ä»æ•°æ®æŸ¥è¯¢ã€é¢„æµ‹åˆ°å¼‚å¸¸æ£€æµ‹å’Œåäº‹å®â€œå‡è®¾â€åˆ†æçš„å¤šç§å†œä¸šé—®ç­”ä»»åŠ¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒAgriWorldåœ¨æ€§èƒ½ä¸Šæ˜¾è‘—ä¼˜äºä»…é™æ–‡æœ¬æˆ–ç›´æ¥è°ƒç”¨å·¥å…·çš„åŸºçº¿æ¨¡å‹ï¼Œå……åˆ†éªŒè¯äº†æ‰§è¡Œé©±åŠ¨çš„åå°„æœºåˆ¶åœ¨å®ç°å¯é ä¸”å¯éªŒè¯çš„å†œä¸šæ¨ç†æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15325v1",
      "published_date": "2026-02-17 03:12:57 UTC",
      "updated_date": "2026-02-17 03:12:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:41:15.650404+00:00"
    },
    {
      "arxiv_id": "2602.15323v1",
      "title": "Unforgeable Watermarks for Language Models via Robust Signatures",
      "title_zh": "é€šè¿‡é²æ£’ç­¾åå®ç°è¯­è¨€æ¨¡å‹ä¸å¯ä¼ªé€ çš„æ°´å°æŠ€æœ¯",
      "authors": [
        "Huijia Lin",
        "Kameron Shahabi",
        "Min Jae Song"
      ],
      "abstract": "Language models now routinely produce text that is difficult to distinguish from human writing, raising the need for robust tools to verify content provenance. Watermarking has emerged as a promising countermeasure, with existing work largely focused on model quality preservation and robust detection. However, current schemes provide limited protection against false attribution. We strengthen the notion of soundness by introducing two novel guarantees: unforgeability and recoverability. Unforgeability prevents adversaries from crafting false positives, texts that are far from any output from the watermarked model but are nonetheless flagged as watermarked. Recoverability provides an additional layer of protection: whenever a watermark is detected, the detector identifies the source text from which the flagged content was derived. Together, these properties strengthen content ownership by linking content exclusively to its generating model, enabling secure attribution and fine-grained traceability. We construct the first undetectable watermarking scheme that is robust, unforgeable, and recoverable with respect to substitutions (i.e., perturbations in Hamming metric). The key technical ingredient is a new cryptographic primitive called robust (or recoverable) digital signatures, which allow verification of messages that are close to signed ones, while preventing forgery of messages that are far from all previously signed messages. We show that any standard digital signature scheme can be boosted to a robust one using property-preserving hash functions (Boyle, LaVigne, and Vaikuntanathan, ITCS 2019).",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è¯­è¨€æ¨¡å‹æ–‡æœ¬æº¯æºéªŒè¯ä¸­ç°æœ‰æ°´å°æŠ€æœ¯éš¾ä»¥é˜²èŒƒé”™è¯¯å½’å±(false attribution)çš„é—®é¢˜ï¼Œå¼•å…¥äº†ä¸å¯ä¼ªé€ æ€§(unforgeability)å’Œå¯æ¢å¤æ€§(recoverability)ä¸¤ä¸ªå…³é”®ç‰¹æ€§ã€‚ä¸å¯ä¼ªé€ æ€§å¯é˜²æ­¢æ”»å‡»è€…åˆ¶é€ è¢«è¯¯åˆ¤ä¸ºæ°´å°æ–‡æœ¬çš„ä¼ªé€ å†…å®¹ï¼Œè€Œå¯æ¢å¤æ€§åˆ™å…è®¸åœ¨æ£€æµ‹åˆ°æ°´å°æ—¶ç²¾å‡†è¯†åˆ«åŸå§‹æ¥æºã€‚ç ”ç©¶åŸºäºä¸€ç§åä¸ºç¨³å¥æ•°å­—ç­¾å(robust digital signatures)çš„æ–°å‹å¯†ç å­¦åŸè¯­ï¼Œæ„å»ºäº†é¦–ä¸ªåœ¨æ›¿æ¢å¹²æ‰°(Hamming metric)ä¸‹å…·å¤‡é²æ£’æ€§ä¸”ä¸å¯æ£€æµ‹çš„æ°´å°æ–¹æ¡ˆã€‚è¯¥æ–¹æ¡ˆåˆ©ç”¨å±æ€§ä¿æŒå“ˆå¸Œå‡½æ•°(property-preserving hash functions)å¯¹æ ‡å‡†æ•°å­—ç­¾åè¿›è¡Œå¢å¼ºï¼Œå®ç°äº†å¯¹ç›¸è¿‘æ¶ˆæ¯çš„æœ‰æ•ˆéªŒè¯å¹¶æœç»äº†è¿œç¨‹ä¼ªé€ ã€‚é€šè¿‡å°†å†…å®¹ä¸å…¶ç”Ÿæˆæ¨¡å‹è¿›è¡Œæ’ä»–æ€§é“¾æ¥ï¼Œè¯¥æŠ€æœ¯ä¸ºå¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ç”Ÿæˆå†…å®¹çš„ç¨³å¥æƒå±è®¤è¯å’Œç»†ç²’åº¦æº¯æºæä¾›äº†å¼ºæœ‰åŠ›çš„æŠ€æœ¯ä¿éšœã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "60 pages, 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.15323v1",
      "published_date": "2026-02-17 03:09:06 UTC",
      "updated_date": "2026-02-17 03:09:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:41:13.742246+00:00"
    },
    {
      "arxiv_id": "2602.15322v1",
      "title": "On Surprising Effectiveness of Masking Updates in Adaptive Optimizers",
      "title_zh": "è®ºè‡ªé€‚åº”ä¼˜åŒ–å™¨ä¸­æ›´æ–°æ©ç çš„æƒŠäººæ•ˆæœ",
      "authors": [
        "Taejong Joo",
        "Wenhan Xia",
        "Cheolmin Kim",
        "Ming Zhang",
        "Eugene Ie"
      ],
      "abstract": "Training large language models (LLMs) relies almost exclusively on dense adaptive optimizers with increasingly sophisticated preconditioners. We challenge this by showing that randomly masking parameter updates can be highly effective, with a masked variant of RMSProp consistently outperforming recent state-of-the-art optimizers. Our analysis reveals that the random masking induces a curvature-dependent geometric regularization that smooths the optimization trajectory. Motivated by this finding, we introduce Momentum-aligned gradient masking (Magma), which modulates the masked updates using momentum-gradient alignment. Extensive LLM pre-training experiments show that Magma is a simple drop-in replacement for adaptive optimizers with consistent gains and negligible computational overhead. Notably, for the 1B model size, Magma reduces perplexity by over 19\\% and 9\\% compared to Adam and Muon, respectively.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨å¤§è¯­è¨€æ¨¡å‹(LLMs)è®­ç»ƒä¸­éšæœºé®æ©(Masking)å‚æ•°æ›´æ–°çš„æœ‰æ•ˆæ€§ï¼ŒæŒ‘æˆ˜äº†è¿‡åº¦ä¾èµ–å¤æ‚é¢„å¤„ç†å™¨çš„è‡ªé€‚åº”ä¼˜åŒ–å™¨(Adaptive Optimizers)ç°çŠ¶ã€‚ç ”ç©¶å‘ç°ï¼ŒRMSPropçš„éšæœºé®æ©å˜ä½“è¡¨ç°ä¼˜äºè¿‘æœŸæœ€å…ˆè¿›çš„ä¼˜åŒ–å™¨ï¼Œå…¶æœºåˆ¶åœ¨äºé€šè¿‡å¼•å…¥æ›²ç‡ç›¸å…³çš„å‡ ä½•æ­£åˆ™åŒ–(Geometric Regularization)æ¥å¹³æ»‘ä¼˜åŒ–è½¨è¿¹ã€‚åŸºäºè¿™ä¸€å‘ç°ï¼Œç ”ç©¶è€…æå‡ºäº†åŠ¨é‡å¯¹é½æ¢¯åº¦é®æ©(Momentum-aligned gradient masking, Magma)ï¼Œé€šè¿‡åŠ¨é‡ä¸æ¢¯åº¦çš„å¯¹é½ç¨‹åº¦æ¥åŠ¨æ€è°ƒåˆ¶é®æ©æ›´æ–°ã€‚Magmaå¯ä»¥ä½œä¸ºè‡ªé€‚åº”ä¼˜åŒ–å™¨çš„ç®€å•æ›¿ä»£æ–¹æ¡ˆï¼Œåœ¨LLMé¢„è®­ç»ƒä¸­å±•ç°å‡ºæ˜¾è‘—æ€§èƒ½æå‡ä¸”è®¡ç®—å¼€é”€æä½ã€‚å®éªŒè¡¨æ˜ï¼Œåœ¨1Bå‚æ•°æ¨¡å‹ä¸Šï¼ŒMagmaç›¸æ¯”Adamå’ŒMuonåˆ†åˆ«é™ä½äº†19%å’Œ9%ä»¥ä¸Šçš„å›°æƒ‘åº¦(Perplexity)ï¼Œä¸ºæå‡å¤§è§„æ¨¡æ¨¡å‹è®­ç»ƒæ•ˆç‡æä¾›äº†æ–°è·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint",
      "pdf_url": "https://arxiv.org/pdf/2602.15322v1",
      "published_date": "2026-02-17 02:57:12 UTC",
      "updated_date": "2026-02-17 02:57:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:41:58.135790+00:00"
    },
    {
      "arxiv_id": "2602.15318v1",
      "title": "Sparrow: Text-Anchored Window Attention with Visual-Semantic Glimpsing for Speculative Decoding in Video LLMs",
      "title_zh": "Sparrowï¼šç»“åˆæ–‡æœ¬é”šå®šçª—å£æ³¨æ„åŠ›ä¸è§†è§‰è¯­ä¹‰æ•æ‰çš„è§†é¢‘å¤§è¯­è¨€æ¨¡å‹æŠ•æœºè§£ç ",
      "authors": [
        "Libo Zhang",
        "Zhaoning Zhang",
        "Wangyang Hong",
        "Peng Qiao",
        "Dongsheng Li"
      ],
      "abstract": "Although speculative decoding is widely used to accelerate Vision-Language Models (VLMs) inference, it faces severe performance collapse when applied to Video Large Language Models (Vid-LLMs). The draft model typically falls into the trap of attention dilution and negative visual gain due to key-value cache explosion and context window mismatches. We observe a visual semantic internalization phenomenon in Vid-LLMs, indicating that critical visual semantics are implicitly encoded into text hidden states during deep-layer interactions, which renders raw visual inputs structurally redundant during deep inference. To address this, we propose the Sparrow framework, which first utilizes visually-aware text-anchored window attention via hidden state reuse to fully offload visual computation to the target model, and leverages intermediate-layer visual state bridging to train the draft model with semantic-rich intermediate states, thereby filtering out low-level visual noise. Additionally, a multi-token prediction strategy is introduced to bridge the training-inference distribution shift. Experiments show that Sparrow achieves an average speedup of 2.82x even with 25k visual tokens, effectively resolving the performance degradation in long sequences and offering a practical solution for real-time long video tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Sparrowæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³æŠ•æœºè§£ç ï¼ˆSpeculative Decodingï¼‰åœ¨è§†é¢‘å¤§è¯­è¨€æ¨¡å‹ï¼ˆVid-LLMsï¼‰ä¸­ç”±äºé”®å€¼ç¼“å­˜ï¼ˆKV Cacheï¼‰çˆ†ç‚¸å’Œä¸Šä¸‹æ–‡çª—å£ä¸åŒ¹é…å¯¼è‡´çš„æ€§èƒ½é€€åŒ–é—®é¢˜ã€‚ç ”ç©¶è€…è§‚å¯Ÿåˆ°Vid-LLMså­˜åœ¨è§†è§‰è¯­ä¹‰å†…åŒ–ï¼ˆVisual Semantic Internalizationï¼‰ç°è±¡ï¼Œå³å…³é”®è¯­ä¹‰åœ¨æ·±å±‚äº¤äº’ä¸­è¢«éšå¼ç¼–ç è‡³æ–‡æœ¬éšè—çŠ¶æ€ï¼Œä½¿å¾—åŸå§‹è§†è§‰è¾“å…¥åœ¨æ·±å±‚æ¨ç†ä¸­å˜å¾—å†—ä½™ã€‚Sparrowåˆ©ç”¨åŸºäºéšè—çŠ¶æ€é‡ç”¨çš„æ–‡æœ¬é”šå®šçª—å£æ³¨æ„åŠ›ï¼ˆText-Anchored Window Attentionï¼‰å°†è§†è§‰è®¡ç®—å®Œå…¨å¸è½½åˆ°ç›®æ ‡æ¨¡å‹ï¼Œå¹¶ç»“åˆä¸­é—´å±‚è§†è§‰çŠ¶æ€æ¡¥æ¥åˆ©ç”¨è¯­ä¹‰ä¸°å¯Œçš„çŠ¶æ€è®­ç»ƒè‰ç¨¿æ¨¡å‹ï¼Œä»è€Œè¿‡æ»¤ä½çº§è§†è§‰å™ªå£°ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶å¼•å…¥äº†å¤šæ ‡è®°é¢„æµ‹ï¼ˆMulti-Token Predictionï¼‰ç­–ç•¥ä»¥å¼¥åˆè®­ç»ƒä¸æ¨ç†çš„åˆ†å¸ƒåç§»ã€‚å®éªŒè¡¨æ˜ï¼ŒSparrowåœ¨å¤„ç†25kä¸ªè§†è§‰æ ‡è®°æ—¶ä»èƒ½å®ç°2.82å€çš„å¹³å‡åŠ é€Ÿï¼Œä¸ºå®æ—¶é•¿è§†é¢‘ä»»åŠ¡æä¾›äº†é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages , 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.15318v1",
      "published_date": "2026-02-17 02:51:36 UTC",
      "updated_date": "2026-02-17 02:51:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:41:55.243333+00:00"
    },
    {
      "arxiv_id": "2602.15304v1",
      "title": "Hybrid Federated and Split Learning for Privacy Preserving Clinical Prediction and Treatment Optimization",
      "title_zh": "é¢å‘éšç§ä¿æŠ¤ä¸´åºŠé¢„æµ‹ä¸æ²»ç–—ä¼˜åŒ–çš„æ··åˆè”é‚¦ä¸æ‹†åˆ†å­¦ä¹ ",
      "authors": [
        "Farzana Akter",
        "Rakib Hossain",
        "Deb Kanna Roy Toushi",
        "Mahmood Menon Khan",
        "Sultana Amin",
        "Lisan Al Amin"
      ],
      "abstract": "Collaborative clinical decision support is often constrained by governance and privacy rules that prevent pooling patient-level records across institutions. We present a hybrid privacy-preserving framework that combines Federated Learning (FL) and Split Learning (SL) to support decision-oriented healthcare modeling without raw-data sharing. The approach keeps feature-extraction trunks on clients while hosting prediction heads on a coordinating server, enabling shared representation learning and exposing an explicit collaboration boundary where privacy controls can be applied. Rather than assuming distributed training is inherently private, we audit leakage empirically using membership inference on cut-layer representations and study lightweight defenses based on activation clipping and additive Gaussian noise. We evaluate across three public clinical datasets under non-IID client partitions using a unified pipeline and assess performance jointly along four deployment-relevant axes: factual predictive utility, uplift-based ranking under capacity constraints, audited privacy leakage, and communication overhead. Results show that hybrid FL-SL variants achieve competitive predictive performance and decision-facing prioritization behavior relative to standalone FL or SL, while providing a tunable privacy-utility trade-off that can reduce audited leakage without requiring raw-data sharing. Overall, the work positions hybrid FL-SL as a practical design space for privacy-preserving healthcare decision support where utility, leakage risk, and deployment cost must be balanced explicitly.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªç»“åˆäº† Federated Learning (FL) å’Œ Split Learning (SL) çš„æ··åˆéšç§ä¿æŠ¤æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å—æ²»ç†å’Œéšç§è§„åˆ™é™åˆ¶çš„åä½œä¸´åºŠå†³ç­–æ”¯æŒé—®é¢˜ã€‚è¯¥æ¡†æ¶é€šè¿‡åœ¨å®¢æˆ·ç«¯ä¿ç•™ç‰¹å¾æå–ä¸»å¹² (feature-extraction trunks)ï¼Œå¹¶åœ¨åè°ƒæœåŠ¡å™¨ä¸Šæ‰˜ç®¡é¢„æµ‹å¤´ (prediction heads)ï¼Œå®ç°äº†åœ¨ä¸å…±äº«åŸå§‹æ•°æ®çš„æƒ…å†µä¸‹è¿›è¡Œå…±äº«è¡¨ç¤ºå­¦ä¹ ã€‚ç ”ç©¶äººå‘˜é€šè¿‡å¯¹å‰ªåˆ‡å±‚è¡¨ç¤º (cut-layer representations) è¿›è¡Œæˆå‘˜æ¨ç† (membership inference) æ¥å®è¯å®¡è®¡æ³„éœ²æƒ…å†µï¼Œå¹¶ç ”ç©¶äº†åŸºäºæ¿€æ´»è£å‰ª (activation clipping) å’ŒåŠ æ€§é«˜æ–¯å™ªå£° (additive Gaussian noise) çš„è½»é‡çº§é˜²å¾¡æªæ–½ã€‚è¯„ä¼°è¿‡ç¨‹æ¶µç›–äº†ä¸‰ä¸ªå…¬å¼€ä¸´åºŠæ•°æ®é›†ï¼Œåœ¨éç‹¬ç«‹åŒåˆ†å¸ƒ (non-IID) å®¢æˆ·ç«¯åˆ’åˆ†ä¸‹ï¼Œä»é¢„æµ‹æ•ˆç”¨ã€åŸºäºå¢é‡ (uplift) çš„æ’åã€å®¡è®¡åçš„éšç§æ³„éœ²å’Œé€šä¿¡å¼€é”€å››ä¸ªç»´åº¦è¿›è¡Œäº†ç»¼åˆè¡¡é‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¿™ç§æ··åˆ FL-SL å˜ä½“åœ¨é¢„æµ‹æ€§èƒ½å’Œå†³ç­–ä¼˜å…ˆåŒ–è¡Œä¸ºä¸Šä¸ç‹¬ç«‹çš„ FL æˆ– SL ç›¸å½“ï¼Œå¹¶æä¾›äº†ä¸€ç§å¯è°ƒèŠ‚çš„éšç§-æ•ˆç”¨æƒè¡¡æœºåˆ¶ã€‚è¯¥å·¥ä½œè¯æ˜äº†æ··åˆ FL-SL èƒ½å¤Ÿæ˜¾è‘—é™ä½å®¡è®¡æ³„éœ²é£é™©ï¼Œä¸ºéšç§ä¿æŠ¤å‹åŒ»ç–—å†³ç­–æ”¯æŒæä¾›äº†ä¸€ä¸ªå¹³è¡¡æ•ˆç”¨ã€é£é™©å’Œéƒ¨ç½²æˆæœ¬çš„å®ç”¨è®¾è®¡ç©ºé—´ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15304v1",
      "published_date": "2026-02-17 01:57:27 UTC",
      "updated_date": "2026-02-17 01:57:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:42:07.044077+00:00"
    },
    {
      "arxiv_id": "2602.15298v1",
      "title": "X-MAP: eXplainable Misclassification Analysis and Profiling for Spam and Phishing Detection",
      "title_zh": "X-MAPï¼šé¢å‘åƒåœ¾é‚®ä»¶åŠé’“é±¼æ£€æµ‹çš„å¯è§£é‡Šè¯¯åˆ†ç±»åˆ†æä¸ç‰¹å¾å‰–æ",
      "authors": [
        "Qi Zhang",
        "Dian Chen",
        "Lance M. Kaplan",
        "Audun JÃ¸sang",
        "Dong Hyun Jeong",
        "Feng Chen",
        "Jin-Hee Cho"
      ],
      "abstract": "Misclassifications in spam and phishing detection are very harmful, as false negatives expose users to attacks while false positives degrade trust. Existing uncertainty-based detectors can flag potential errors, but possibly be deceived and offer limited interpretability. This paper presents X-MAP, an eXplainable Misclassification Analysis and Profilling framework that reveals topic-level semantic patterns behind model failures. X-MAP combines SHAP-based feature attributions with non-negative matrix factorization to build interpretable topic profiles for reliably classified spam/phishing and legitimate messages, and measures each message's deviation from these profiles using Jensen-Shannon divergence. Experiments on SMS and phishing datasets show that misclassified messages exhibit at least two times larger divergence than correctly classified ones. As a detector, X-MAP achieves up to 0.98 AUROC and lowers the false-rejection rate at 95% TRR to 0.089 on positive predictions. When used as a repair layer on base detectors, it recovers up to 97% of falsely rejected correct predictions with moderate leakage. These results demonstrate X-MAP's effectiveness and interpretability for improving spam and phishing detection.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†X-MAPï¼Œä¸€ç§æ—¨åœ¨è§£å†³åƒåœ¾é‚®ä»¶å’Œç½‘ç»œé’“é±¼æ£€æµ‹ä¸­è¯¯åˆ†ç±»å±å®³åŠå…¶å¯è§£é‡Šæ€§ä¸è¶³çš„å¯è§£é‡Šåˆ†ææ¡†æ¶ã€‚è¯¥æ¡†æ¶ç»“åˆäº†åŸºäºSHAPçš„ç‰¹å¾å½’å› ä¸éè´ŸçŸ©é˜µåˆ†è§£(Non-negative Matrix Factorization)ï¼Œé€šè¿‡æ„å»ºåƒåœ¾é‚®ä»¶åŠåˆæ³•æ¶ˆæ¯çš„ä¸»é¢˜ç”»åƒï¼Œæ­ç¤ºæ¨¡å‹å¤±æ•ˆèƒŒåçš„è¯­ä¹‰æ¨¡å¼ã€‚åˆ©ç”¨Jensen-Shannon Divergenceè¡¡é‡æ¶ˆæ¯ä¸ç”»åƒçš„åç¦»åº¦ï¼Œç ”ç©¶å‘ç°è¯¯åˆ†ç±»æ¶ˆæ¯çš„åç¦»ç¨‹åº¦è‡³å°‘æ˜¯æ­£ç¡®åˆ†ç±»æ¶ˆæ¯çš„ä¸¤å€ã€‚å®éªŒè¡¨æ˜ï¼ŒX-MAPåœ¨ç›¸å…³æ•°æ®é›†ä¸Šå®ç°äº†é«˜è¾¾0.98çš„AUROCï¼Œå¹¶åœ¨ä¿æŒé«˜æ£€æµ‹ç‡çš„åŒæ—¶æ˜¾è‘—é™ä½äº†é”™è¯¯æ‹’ç»ç‡ã€‚å½“ä½œä¸ºç°æœ‰æ£€æµ‹å™¨çš„ä¿®å¤å±‚ä½¿ç”¨æ—¶ï¼Œå®ƒèƒ½å¤Ÿæ¢å¤é«˜è¾¾97%è¢«é”™è¯¯æ‹’ç»çš„æ­£ç¡®é¢„æµ‹ï¼Œæœ‰æ•ˆæå‡äº†æ£€æµ‹ç³»ç»Ÿçš„é²æ£’æ€§ä¸é€æ˜åº¦ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15298v1",
      "published_date": "2026-02-17 01:46:08 UTC",
      "updated_date": "2026-02-17 01:46:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:42:17.042633+00:00"
    },
    {
      "arxiv_id": "2602.15294v1",
      "title": "EAA: Automating materials characterization with vision language model agents",
      "title_zh": "EAAï¼šåŸºäºè§†è§‰è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“çš„ææ–™è¡¨å¾è‡ªåŠ¨åŒ–",
      "authors": [
        "Ming Du",
        "Yanqi Luo",
        "Srutarshi Banerjee",
        "Michael Wojcik",
        "Jelena Popovic",
        "Mathew J. Cherukara"
      ],
      "abstract": "We present Experiment Automation Agents (EAA), a vision-language-model-driven agentic system designed to automate complex experimental microscopy workflows. EAA integrates multimodal reasoning, tool-augmented action, and optional long-term memory to support both autonomous procedures and interactive user-guided measurements. Built on a flexible task-manager architecture, the system enables workflows ranging from fully agent-driven automation to logic-defined routines that embed localized LLM queries. EAA further provides a modern tool ecosystem with two-way compatibility for Model Context Protocol (MCP), allowing instrument-control tools to be consumed or served across applications. We demonstrate EAA at an imaging beamline at the Advanced Photon Source, including automated zone plate focusing, natural language-described feature search, and interactive data acquisition. These results illustrate how vision-capable agents can enhance beamline efficiency, reduce operational burden, and lower the expertise barrier for users.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº†Experiment Automation Agents (EAA)ï¼Œè¿™æ˜¯ä¸€ä¸ªç”±è§†è§‰è¯­è¨€æ¨¡å‹(Vision-Language Model, VLM)é©±åŠ¨çš„æ™ºèƒ½ä½“ç³»ç»Ÿï¼Œæ—¨åœ¨è‡ªåŠ¨åŒ–å¤æ‚çš„å®éªŒæ˜¾å¾®é•œå·¥ä½œæµã€‚è¯¥ç³»ç»Ÿæ•´åˆäº†å¤šæ¨¡æ€æ¨ç†ã€å·¥å…·å¢å¼ºè¡ŒåŠ¨ä»¥åŠå¯é€‰çš„é•¿æœŸè®°å¿†åŠŸèƒ½ï¼Œèƒ½å¤Ÿæ”¯æŒå…¨è‡ªåŠ¨ç¨‹åºå’Œäº¤äº’å¼ç”¨æˆ·å¼•å¯¼æµ‹é‡ã€‚EAAåŸºäºçµæ´»çš„ä»»åŠ¡ç®¡ç†å™¨æ¶æ„ï¼Œå¹¶æ„å»ºäº†å…·å¤‡Model Context Protocol (MCP)åŒå‘å…¼å®¹æ€§çš„å·¥å…·ç”Ÿæ€ç³»ç»Ÿï¼Œå®ç°äº†ä»ªå™¨æ§åˆ¶å·¥å…·åœ¨ä¸åŒåº”ç”¨é—´çš„æ— ç¼é›†æˆã€‚åœ¨Advanced Photon Source (APS)æˆåƒå…‰æŸçº¿çš„å®è¯æ¼”ç¤ºä¸­ï¼ŒEAAæˆåŠŸå®Œæˆäº†åŒºåŸŸæ¿èšç„¦(zone plate focusing)ã€åŸºäºè‡ªç„¶è¯­è¨€æè¿°çš„ç‰¹å¾æœç´¢ä»¥åŠäº¤äº’å¼æ•°æ®é‡‡é›†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¿™ç§å…·å¤‡è§†è§‰èƒ½åŠ›çš„æ™ºèƒ½ä½“èƒ½æ˜¾è‘—æå‡å…‰æŸçº¿è¿è¡Œæ•ˆç‡ï¼Œå‡è½»ç§‘ç ”äººå‘˜çš„æ“ä½œè´Ÿæ‹…ï¼Œå¹¶æœ‰æ•ˆé™ä½äº†å¤æ‚å®éªŒè®¾å¤‡çš„ä½¿ç”¨é—¨æ§›ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15294v1",
      "published_date": "2026-02-17 01:34:05 UTC",
      "updated_date": "2026-02-17 01:34:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:42:14.337711+00:00"
    },
    {
      "arxiv_id": "2602.15293v1",
      "title": "The Information Geometry of Softmax: Probing and Steering",
      "title_zh": "Softmax çš„ä¿¡æ¯å‡ ä½•ï¼šæ¢æµ‹ä¸å¼•å¯¼",
      "authors": [
        "Kiho Park",
        "Todd Nief",
        "Yo Joong Choe",
        "Victor Veitch"
      ],
      "abstract": "This paper concerns the question of how AI systems encode semantic structure into the geometric structure of their representation spaces. The motivating observation of this paper is that the natural geometry of these representation spaces should reflect the way models use representations to produce behavior. We focus on the important special case of representations that define softmax distributions. In this case, we argue that the natural geometry is information geometry. Our focus is on the role of information geometry on semantic encoding and the linear representation hypothesis. As an illustrative application, we develop \"dual steering\", a method for robustly steering representations to exhibit a particular concept using linear probes. We prove that dual steering optimally modifies the target concept while minimizing changes to off-target concepts. Empirically, we find that dual steering enhances the controllability and stability of concept manipulation.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æ¢è®¨äº†AIç³»ç»Ÿå¦‚ä½•å°†è¯­ä¹‰ç»“æ„ç¼–ç ä¸ºè¡¨ç¤ºç©ºé—´çš„å‡ ä½•ç»“æ„ï¼Œå¹¶æå‡ºå¯¹äºå®šä¹‰softmaxåˆ†å¸ƒçš„è¡¨ç¤ºï¼Œå…¶è‡ªç„¶å‡ ä½•å½¢å¼åº”å½“æ˜¯ä¿¡æ¯å‡ ä½•(Information Geometry)ã€‚ä½œè€…é‡ç‚¹åˆ†æäº†ä¿¡æ¯å‡ ä½•åœ¨è¯­ä¹‰ç¼–ç å’Œçº¿æ€§è¡¨ç¤ºå‡è®¾(Linear Representation Hypothesis)ä¸­çš„ä½œç”¨ï¼Œå¼ºè°ƒå‡ ä½•ç»“æ„åº”åæ˜ æ¨¡å‹åˆ©ç”¨è¡¨ç¤ºç”Ÿæˆè¡Œä¸ºçš„æ–¹å¼ã€‚åŸºäºæ­¤ç†è®ºï¼Œç ”ç©¶å¼€å‘äº†ä¸€ç§åä¸ºâ€œåŒé‡æ§åˆ¶â€(Dual Steering)çš„æ–¹æ³•ï¼Œåˆ©ç”¨çº¿æ€§æ¢é’ˆ(Linear Probes)å®ç°å¯¹è¡¨ç¤ºä¸­ç‰¹å®šæ¦‚å¿µçš„ç¨³å¥å¼•å¯¼ã€‚ç†è®ºè¯æ˜Dual Steeringåœ¨ä¿®æ”¹ç›®æ ‡æ¦‚å¿µæ—¶èƒ½æœ‰æ•ˆæœ€å°åŒ–å¯¹éç›®æ ‡æ¦‚å¿µçš„å½±å“ï¼Œå®éªŒç»“æœè¿›ä¸€æ­¥è¯å®è¯¥æ–¹æ³•æ˜¾è‘—æå‡äº†æ¦‚å¿µæ“ä½œçš„å¯æ§æ€§ä¸ç¨³å®šæ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Code is available at https://github.com/KihoPark/dual-steering",
      "pdf_url": "https://arxiv.org/pdf/2602.15293v1",
      "published_date": "2026-02-17 01:33:28 UTC",
      "updated_date": "2026-02-17 01:33:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:42:56.133197+00:00"
    },
    {
      "arxiv_id": "2602.15286v1",
      "title": "AI-Paging: Lease-Based Execution Anchoring for Network-Exposed AI-as-a-Service",
      "title_zh": "AI-Pagingï¼šé¢å‘ç½‘ç»œå¼€æ”¾å‹ AI å³æœåŠ¡çš„åŸºäºç§Ÿçº¦çš„æ‰§è¡Œé”šå®š",
      "authors": [
        "Merve Saimler",
        "Mohaned Chraiti"
      ],
      "abstract": "With AI-as-a-Service (AIaaS) now deployed across multiple providers and model tiers, selecting the appropriate model instance at run time is increasingly outside the end user's knowledge and operational control. Accordingly, the 6G service providers are envisioned to play a crucial role in exposing AIaaS in a setting where users submit only an intent while the network helps in the intent-to-model matching (resolution) and execution placement under policy, trust, and Quality of Service (QoS) constraints. The network role becomes to discover candidate execution endpoints and selects a suitable model/anchor under policy and QoS constraints in a process referred here to as AI-paging (by analogy to cellular call paging). In the proposed architecture, AI-paging is a control-plane transaction that resolves an intent into an AI service identity (AISI), a scoped session token (AIST), and an expiring admission lease (COMMIT) that authorizes user-plane steering to a selected AI execution anchor (AEXF) under a QoS binding. AI-Paging enforces two invariants: (i) lease-gated steering (without COMMIT, no steering state is installed) and (ii) make-before-break anchoring to support continuity and reliability of AIaaS services under dynamic network conditions. We prototype AI-Paging using existing control- and user-plane mechanisms (service-based control, QoS flows, and policy-based steering) with no new packet headers, ensuring compatibility with existing 3GPP-based exposure and management architectures, and evaluate transaction latency, relocation interruption, enforcement correctness under lease expiry, and audit-evidence overhead under mobility and failures.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†AI-Pagingï¼Œè¿™æ˜¯ä¸€ç§é’ˆå¯¹6Gç¯å¢ƒä¸‹ç½‘ç»œå¼€æ”¾å¼äººå·¥æ™ºèƒ½æœåŠ¡ï¼ˆAI-as-a-Serviceï¼‰çš„åŸºäºç§Ÿçº¦çš„æ‰§è¡Œé”šå®šæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç”¨æˆ·åœ¨æ„å›¾åˆ°æ¨¡å‹åŒ¹é…ï¼ˆresolutionï¼‰åŠæ‰§è¡Œä½ç½®é€‰æ‹©æ–¹é¢çš„æ§åˆ¶éš¾é¢˜ã€‚AI-Pagingä½œä¸ºä¸€ç§æ§åˆ¶é¢äº‹åŠ¡ï¼Œé€šè¿‡å°†ç”¨æˆ·æ„å›¾è§£æä¸ºAIæœåŠ¡æ ‡è¯†ï¼ˆAISIï¼‰ã€ä¼šè¯ä»¤ç‰Œï¼ˆAISTï¼‰å’Œåˆ°æœŸå‡†å…¥ç§Ÿçº¦ï¼ˆCOMMITï¼‰ï¼Œæˆæƒç”¨æˆ·é¢åœ¨ç‰¹å®šQoSçº¦æŸä¸‹è½¬å‘é€‰å®šçš„AIæ‰§è¡Œé”šç‚¹ï¼ˆAEXFï¼‰ã€‚è¯¥æ¶æ„ç¡®ç«‹äº†ç§Ÿçº¦é—¨æ§è½¬å‘ï¼ˆlease-gated steeringï¼‰å’Œå…ˆè¿åæ–­ï¼ˆmake-before-breakï¼‰é”šå®šä¸¤ä¸ªå…³é”®ä¸å˜æ€§ï¼Œä»¥ä¿éšœåŠ¨æ€ç½‘ç»œç¯å¢ƒä¸‹AIaaSæœåŠ¡çš„å®‰å…¨æ€§ã€è¿ç»­æ€§å’Œå¯é æ€§ã€‚ä½œè€…åˆ©ç”¨ç°æœ‰çš„3GPPæœåŠ¡åŒ–æ¶æ„å’ŒQoSæµæœºåˆ¶å®ç°äº†åŸå‹ç³»ç»Ÿï¼Œç¡®ä¿äº†ä¸ç°è¡Œç½‘ç»œç®¡ç†æ¶æ„çš„å…¼å®¹æ€§ï¼Œæ— éœ€å¼•å…¥é¢å¤–çš„æ•°æ®åŒ…å¤´ã€‚å®éªŒè¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ¡ˆåœ¨äº‹åŠ¡å»¶è¿Ÿã€é‡å®šä½ä¸­æ–­ã€ç§Ÿçº¦åˆ°æœŸå¼ºåˆ¶æ‰§è¡Œçš„æ­£ç¡®æ€§ä»¥åŠç§»åŠ¨æ€§åœºæ™¯ä¸‹çš„å®¡è®¡å¼€é”€æ–¹é¢å‡è¡¨ç°ä¼˜å¼‚ï¼Œä¸ºå®ç°å¯æ§ä¸”é«˜æ•ˆçš„AIæœåŠ¡åˆ†å‘æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15286v1",
      "published_date": "2026-02-17 01:11:26 UTC",
      "updated_date": "2026-02-17 01:11:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:42:54.547223+00:00"
    },
    {
      "arxiv_id": "2602.15283v1",
      "title": "Complex-Valued Unitary Representations as Classification Heads for Improved Uncertainty Quantification in Deep Neural Networks",
      "title_zh": "å¤æ•°å€¼å¹ºæ­£è¡¨ç¤ºä½œä¸ºåˆ†ç±»å¤´ï¼šæå‡æ·±åº¦ç¥ç»ç½‘ç»œçš„ä¸ç¡®å®šæ€§é‡åŒ–èƒ½åŠ›",
      "authors": [
        "Akbar Anbar Jafari",
        "Cagri Ozcinar",
        "Gholamreza Anbarjafari"
      ],
      "abstract": "Modern deep neural networks achieve high predictive accuracy but remain poorly calibrated: their confidence scores do not reliably reflect the true probability of correctness. We propose a quantum-inspired classification head architecture that projects backbone features into a complex-valued Hilbert space and evolves them under a learned unitary transformation parameterised via the Cayley map. Through a controlled hybrid experimental design - training a single shared backbone and comparing lightweight interchangeable heads - we isolate the effect of complex-valued unitary representations on calibration. Our ablation study on CIFAR-10 reveals that the unitary magnitude head (complex features evolved under a Cayley unitary, read out via magnitude and softmax) achieves an Expected Calibration Error (ECE) of 0.0146, representing a 2.4x improvement over a standard softmax head (0.0355) and a 3.5x improvement over temperature scaling (0.0510). Surprisingly, replacing the softmax readout with a Born rule measurement layer - the quantum-mechanically motivated approach - degrades calibration to an ECE of 0.0819. On the CIFAR-10H human-uncertainty benchmark, the wave function head achieves the lowest KL-divergence (0.336) to human soft labels among all compared methods, indicating that complex-valued representations better capture the structure of human perceptual ambiguity. We provide theoretical analysis connecting norm-preserving unitary dynamics to calibration through feature-space geometry, report negative results on out-of-distribution detection and sentiment analysis to delineate the method's scope, and discuss practical implications for safety-critical applications. Code is publicly available.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ·±åº¦ç¥ç»ç½‘ç»œé¢„æµ‹å‡†ç¡®åº¦é«˜ä½†æ¨¡å‹æ ¡å‡†(calibration)æ€§èƒ½å·®ï¼Œå¯¼è‡´ç½®ä¿¡åº¦æ— æ³•çœŸå®åæ˜ é¢„æµ‹æ¦‚ç‡çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§å—é‡å­å¯å‘çš„åˆ†ç±»å¤´æ¶æ„ã€‚è¯¥æ–¹æ³•å°†ä¸»å¹²ç‰¹å¾æŠ•å½±åˆ°å¤å€¼å¸Œå°”ä¼¯ç‰¹ç©ºé—´(complex-valued Hilbert space)ï¼Œå¹¶åˆ©ç”¨ç» Cayley map å‚æ•°åŒ–çš„å­¦ä¹ å•ä½å˜æ¢(unitary transformation)è¿›è¡Œæ¼”åŒ–ã€‚é€šè¿‡åœ¨ CIFAR-10 ä¸Šçš„å—æ§å®éªŒï¼Œç ”ç©¶å‘ç°å•ä½å¹…åº¦å¤´(unitary magnitude head)çš„é¢„æœŸæ ¡å‡†è¯¯å·®(ECE)ä»…ä¸º 0.0146ï¼Œä¼˜äºæ ‡å‡† softmax å’Œæ¸©åº¦ç¼©æ”¾(temperature scaling)æŠ€æœ¯ã€‚æ­¤å¤–ï¼Œå®éªŒè¡¨æ˜è¯¥æ¶æ„ä¸­çš„æ³¢å‡½æ•°å¤´(wave function head)åœ¨æ•æ‰äººç±»æ„ŸçŸ¥æ¨¡ç³Šæ€§æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä¸äººç±»è½¯æ ‡ç­¾(human soft labels)çš„ KL æ•£åº¦(KL-divergence)è¾¾åˆ°æœ€ä½ã€‚è¯¥é¡¹å·¥ä½œé€šè¿‡ç‰¹å¾ç©ºé—´å‡ ä½•åˆ†æäº†èŒƒæ•°ä¿æŒå•ä½åŠ¨åŠ›å­¦å¯¹æ ¡å‡†çš„å½±å“ï¼Œä¸ºæå‡å®‰å…¨å…³é”®åº”ç”¨ä¸­çš„ä¸ç¡®å®šæ€§é‡åŒ–(uncertainty quantification)æä¾›äº†æ–°æ€è·¯ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "21 pages, 12 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.15283v1",
      "published_date": "2026-02-17 00:45:27 UTC",
      "updated_date": "2026-02-17 00:45:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:42:58.043818+00:00"
    },
    {
      "arxiv_id": "2602.15281v1",
      "title": "High-Fidelity Network Management for Federated AI-as-a-Service: Cross-Domain Orchestration",
      "title_zh": "é¢å‘è”é‚¦äººå·¥æ™ºèƒ½å³æœåŠ¡çš„é«˜ä¿çœŸç½‘ç»œç®¡ç†ï¼šè·¨åŸŸç¼–æ’",
      "authors": [
        "Merve Saimler",
        "Mohaned Chraiti",
        "Ozgur Ercetin"
      ],
      "abstract": "To support the emergence of AI-as-a-Service (AIaaS), communication service providers (CSPs) are on the verge of a radical transformation-from pure connectivity providers to AIaaS a managed network service (control-and-orchestration plane that exposes AI models). In this model, the CSP is responsible not only for transport/communications, but also for intent-to-model resolution and joint network-compute orchestration, i.e., reliable and timely end-to-end delivery. The resulting end-to-end AIaaS service thus becomes governed by communications impairments (delay, loss) and inference impairments (latency, error). A central open problem is an operational AIaaS control-and-orchestration framework that enforces high fidelity, particularly under multi-domain federation. This paper introduces an assurance-oriented AIaaS management plane based on Tail-Risk Envelopes (TREs): signed, composable per-domain descriptors that combine deterministic guardrails with stochastic rate-latency-impairment models. Using stochastic network calculus, we derive bounds on end-to-end delay violation probabilities across tandem domains and obtain an optimization-ready risk-budget decomposition. We show that tenant-level reservations prevent bursty traffic from inflating tail latency under TRE contracts. An auditing layer then uses runtime telemetry to estimate extreme-percentile performance, quantify uncertainty, and attribute tail-risk to each domain for accountability. Packet-level Monte-Carlo simulations demonstrate improved p99.9 compliance under overload via admission control and robust tenant isolation under correlated burstiness.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è”é‚¦ AI-as-a-Service (AIaaS) ç¯å¢ƒä¸‹çš„è·¨åŸŸç¼–æ’é—®é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªé¢å‘é«˜ä¿çœŸç½‘ç»œç®¡ç†çš„ AIaaS ç®¡ç†å¹³é¢ã€‚ç ”ç©¶å¼•å…¥äº†åŸºäºå°¾éƒ¨é£é™©åŒ…ç»œ (Tail-Risk Envelopes, TREs) çš„æè¿°ç¬¦ï¼Œé€šè¿‡ç»“åˆç¡®å®šæ€§è¾¹ç•Œä¸éšæœºé€Ÿç‡-å»¶è¿Ÿ-æŸä¼¤æ¨¡å‹ï¼Œè§£å†³äº†å¤šåŸŸè”é‚¦ä¸­ç«¯åˆ°ç«¯ AI æœåŠ¡å—é€šä¿¡å’Œæ¨ç†æŸä¼¤å½±å“çš„æŒ‘æˆ˜ã€‚åˆ©ç”¨éšæœºç½‘ç»œæ¼”ç®— (Stochastic Network Calculus)ï¼Œè¯¥æ¡†æ¶æ¨å¯¼äº†è·¨ä¸²è”åŸŸçš„ç«¯åˆ°ç«¯å»¶è¿Ÿè¿çº¦æ¦‚ç‡è¾¹ç•Œï¼Œå¹¶å®ç°äº†å¯ä¼˜åŒ–çš„é£é™©é¢„ç®—åˆ†è§£ã€‚å®éªŒè¡¨æ˜ï¼Œç§Ÿæˆ·çº§é¢„ç•™æœºåˆ¶èƒ½æœ‰æ•ˆé˜²æ­¢çªå‘æµé‡å¯¼è‡´çš„å°¾éƒ¨å»¶è¿Ÿå¢åŠ ï¼Œè€Œå®¡è®¡å±‚åˆ©ç”¨è¿è¡Œæ—¶é¥æµ‹æŠ€æœ¯å®ç°äº†æ€§èƒ½è¯„ä¼°ä¸è´£ä»»å½’å±ã€‚Packet-level Monte-Carlo ä»¿çœŸç»“æœè¯å®ï¼Œè¯¥æ–¹æ¡ˆåœ¨è¿‡è½½æƒ…å†µä¸‹æ˜¾è‘—æå‡äº† p99.9 åˆè§„æ€§ï¼Œå¹¶åœ¨ç›¸å…³çªå‘æµé‡ç¯å¢ƒä¸‹å±•ç°å‡ºå¼ºå¤§çš„ç§Ÿæˆ·éš”ç¦»èƒ½åŠ›ã€‚",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15281v1",
      "published_date": "2026-02-17 00:40:04 UTC",
      "updated_date": "2026-02-17 00:40:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:43:02.437764+00:00"
    },
    {
      "arxiv_id": "2602.15278v1",
      "title": "Visual Persuasion: What Influences Decisions of Vision-Language Models?",
      "title_zh": "è§†è§‰è¯±å¯¼ï¼šä»€ä¹ˆåœ¨å½±å“å¤šæ¨¡æ€å¤§æ¨¡å‹çš„å†³ç­–ï¼Ÿ",
      "authors": [
        "Manuel Cherep",
        "Pranav M R",
        "Pattie Maes",
        "Nikhil Singh"
      ],
      "abstract": "The web is littered with images, once created for human consumption and now increasingly interpreted by agents using vision-language models (VLMs). These agents make visual decisions at scale, deciding what to click, recommend, or buy. Yet, we know little about the structure of their visual preferences. We introduce a framework for studying this by placing VLMs in controlled image-based choice tasks and systematically perturbing their inputs. Our key idea is to treat the agent's decision function as a latent visual utility that can be inferred through revealed preference: choices between systematically edited images. Starting from common images, such as product photos, we propose methods for visual prompt optimization, adapting text optimization methods to iteratively propose and apply visually plausible modifications using an image generation model (such as in composition, lighting, or background). We then evaluate which edits increase selection probability. Through large-scale experiments on frontier VLMs, we demonstrate that optimized edits significantly shift choice probabilities in head-to-head comparisons. We develop an automatic interpretability pipeline to explain these preferences, identifying consistent visual themes that drive selection. We argue that this approach offers a practical and efficient way to surface visual vulnerabilities, safety concerns that might otherwise be discovered implicitly in the wild, supporting more proactive auditing and governance of image-based AI agents.",
      "tldr_zh": "è¯¥ç ”ç©¶è°ƒæŸ¥äº†è§†è§‰è¯­è¨€æ¨¡å‹(Vision-Language Models, VLMs)åœ¨ä½œä¸ºæ™ºèƒ½ä½“è¿›è¡Œç‚¹å‡»ã€æ¨èæˆ–è´­ä¹°å†³ç­–æ—¶çš„è§†è§‰åå¥½ç»“æ„ã€‚ä½œè€…æå‡ºäº†ä¸€ä¸ªåœ¨å—æ§å›¾åƒé€‰æ‹©ä»»åŠ¡ä¸­ç ”ç©¶VLMsçš„æ¡†æ¶ï¼Œé€šè¿‡æ˜¾ç¤ºåå¥½(revealed preference)å°†æ¨¡å‹çš„å†³ç­–å‡½æ•°è§†ä¸ºæ½œåœ¨è§†è§‰æ•ˆç”¨è¿›è¡Œæ¨æ–­ã€‚ç ”ç©¶å¼•å…¥äº†è§†è§‰æç¤ºä¼˜åŒ–(visual prompt optimization)æ–¹æ³•ï¼Œåˆ©ç”¨å›¾åƒç”Ÿæˆæ¨¡å‹å¯¹å›¾åƒçš„æ„å›¾ã€å…‰ç…§æˆ–èƒŒæ™¯è¿›è¡Œè¿­ä»£ä¿®æ”¹ï¼Œå¹¶è¯„ä¼°å“ªäº›ç¼–è¾‘ä¼šå¢åŠ æ¨¡å‹çš„é€‰æ‹©æ¦‚ç‡ã€‚åœ¨å¤§è§„æ¨¡å‰æ²¿VLMsä¸Šçš„å®éªŒè¯æ˜ï¼Œç»è¿‡ä¼˜åŒ–çš„ç¼–è¾‘èƒ½æ˜¾è‘—æ”¹å˜æ¨¡å‹çš„é€‰æ‹©æ¦‚ç‡ï¼Œä¸”ç ”ç©¶é…å¥—çš„è‡ªåŠ¨å¯è§£é‡Šæ€§æµæ°´çº¿èƒ½è¯†åˆ«å‡ºé©±åŠ¨é€‰æ‹©çš„ä¸€è‡´æ€§è§†è§‰ä¸»é¢˜ã€‚è¯¥æ–¹æ³•ä¸ºè¯†åˆ«è§†è§‰æ¼æ´å’Œå®‰å…¨éšæ‚£æä¾›äº†é«˜æ•ˆæ‰‹æ®µï¼Œæ”¯æŒå¯¹åŸºäºå›¾åƒçš„AIæ™ºèƒ½ä½“è¿›è¡Œæ›´ä¸»åŠ¨çš„å®¡è®¡ä¸æ²»ç†ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "45 pages, 17 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.15278v1",
      "published_date": "2026-02-17 00:33:53 UTC",
      "updated_date": "2026-02-17 00:33:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:43:06.645764+00:00"
    },
    {
      "arxiv_id": "2602.15277v1",
      "title": "Accelerating Large-Scale Dataset Distillation via Exploration-Exploitation Optimization",
      "title_zh": "é€šè¿‡æ¢ç´¢-åˆ©ç”¨ä¼˜åŒ–åŠ é€Ÿå¤§è§„æ¨¡æ•°æ®é›†è’¸é¦",
      "authors": [
        "Muhammad J. Alahmadi",
        "Peng Gao",
        "Feiyi Wang",
        "Dongkuan",
        "Xu"
      ],
      "abstract": "Dataset distillation compresses the original data into compact synthetic datasets, reducing training time and storage while retaining model performance, enabling deployment under limited resources. Although recent decoupling-based distillation methods enable dataset distillation at large-scale, they continue to face an efficiency gap: optimization-based decoupling methods achieve higher accuracy but demand intensive computation, whereas optimization-free decoupling methods are efficient but sacrifice accuracy. To overcome this trade-off, we propose Exploration-Exploitation Distillation (E^2D), a simple, practical method that minimizes redundant computation through an efficient pipeline that begins with full-image initialization to preserve semantic integrity and feature diversity. It then uses a two-phase optimization strategy: an exploration phase that performs uniform updates and identifies high-loss regions, and an exploitation phase that focuses updates on these regions to accelerate convergence. We evaluate E^2D on large-scale benchmarks, surpassing the state-of-the-art on ImageNet-1K while being 18x faster, and on ImageNet-21K, our method substantially improves accuracy while remaining 4.3x faster. These results demonstrate that targeted, redundancy-reducing updates, rather than brute-force optimization, bridge the gap between accuracy and efficiency in large-scale dataset distillation. Code is available at https://github.com/ncsu-dk-lab.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è§„æ¨¡ Dataset Distillation ä¸­ä¼˜åŒ–æ–¹æ³•è®¡ç®—å¼€é”€å¤§ä¸éä¼˜åŒ–æ–¹æ³•ç²¾åº¦ä½ä¹‹é—´çš„æƒè¡¡é—®é¢˜ï¼Œæå‡ºäº† Exploration-Exploitation Distillation (E^2D) æ¡†æ¶ã€‚è¯¥æ–¹æ³•é¦–å…ˆé‡‡ç”¨ Full-image initialization ä»¥ä¿ç•™åˆæˆæ•°æ®é›†çš„è¯­ä¹‰å®Œæ•´æ€§å’Œç‰¹å¾å¤šæ ·æ€§ï¼Œéšåé‡‡ç”¨ä¸¤é˜¶æ®µä¼˜åŒ–ç­–ç•¥ã€‚åœ¨ Exploration phaseï¼Œç³»ç»Ÿé€šè¿‡å‡åŒ€æ›´æ–°è¯†åˆ«å‡ºé«˜æŸå¤±åŒºåŸŸï¼Œè€Œåœ¨ Exploitation phase åˆ™å°†æ›´æ–°é‡ç‚¹é›†ä¸­äºè¿™äº›åŒºåŸŸä»¥åŠ é€Ÿæ”¶æ•›ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒE^2D åœ¨ ImageNet-1K åŸºå‡†æµ‹è¯•ä¸­è¶…è¶Šäº†ç°æœ‰æœ€å…ˆè¿›æŠ€æœ¯ï¼Œä¸”è¿è¡Œé€Ÿåº¦æå‡äº† 18 å€ï¼›åœ¨æ›´å…·æŒ‘æˆ˜æ€§çš„ ImageNet-21K ä¸Šï¼Œè¯¥æ–¹æ³•åœ¨ä¿æŒ 4.3 å€åŠ é€Ÿçš„åŒæ—¶æ˜¾è‘—æé«˜äº†å‡†ç¡®ç‡ã€‚è¯¥ç ”ç©¶è¯æ˜äº†é€šè¿‡æœ‰é’ˆå¯¹æ€§çš„å‡å°‘å†—ä½™è®¡ç®—è€Œéæš´åŠ›ä¼˜åŒ–ï¼Œå¯ä»¥æœ‰æ•ˆå¼¥åˆå¤§è§„æ¨¡æ•°æ®è’¸é¦ä¸­ç²¾åº¦ä¸æ•ˆç‡ä¹‹é—´çš„å·®è·ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15277v1",
      "published_date": "2026-02-17 00:27:58 UTC",
      "updated_date": "2026-02-17 00:27:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:43:52.440695+00:00"
    },
    {
      "arxiv_id": "2602.15274v1",
      "title": "When Remembering and Planning are Worth it: Navigating under Change",
      "title_zh": "è®°å¿†ä¸è§„åˆ’çš„ä»·å€¼æ‰€åœ¨ï¼šå˜åŠ¨ç¯å¢ƒä¸‹çš„å¯¼èˆªç­–ç•¥",
      "authors": [
        "Omid Madani",
        "J. Brian Burns",
        "Reza Eghbali",
        "Thomas L. Dean"
      ],
      "abstract": "We explore how different types and uses of memory can aid spatial navigation in changing uncertain environments. In the simple foraging task we study, every day, our agent has to find its way from its home, through barriers, to food. Moreover, the world is non-stationary: from day to day, the location of the barriers and food may change, and the agent's sensing such as its location information is uncertain and very limited. Any model construction, such as a map, and use, such as planning, needs to be robust against these challenges, and if any learning is to be useful, it needs to be adequately fast. We look at a range of strategies, from simple to sophisticated, with various uses of memory and learning. We find that an architecture that can incorporate multiple strategies is required to handle (sub)tasks of a different nature, in particular for exploration and search, when food location is not known, and for planning a good path to a remembered (likely) food location. An agent that utilizes non-stationary probability learning techniques to keep updating its (episodic) memories and that uses those memories to build maps and plan on the fly (imperfect maps, i.e. noisy and limited to the agent's experience) can be increasingly and substantially more efficient than the simpler (minimal-memory) agents, as the task difficulties such as distance to goal are raised, as long as the uncertainty, from localization and change, is not too large.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨ä¸æ–­å˜åŒ–ä¸”ä¸ç¡®å®šçš„ç¯å¢ƒä¸­ï¼Œä¸åŒç±»å‹å’Œç”¨é€”çš„è®°å¿† (Memory) å¦‚ä½•è¾…åŠ©ç©ºé—´å¯¼èˆªï¼Œé‡ç‚¹åˆ†æäº†ä¸€ä¸ªæ™ºèƒ½ä½“åœ¨åŠ¨æ€ä¸–ç•Œä¸­å¯»æ‰¾é£Ÿç‰©çš„è§…é£Ÿä»»åŠ¡ã€‚åœ¨è¯¥ä»»åŠ¡ä¸­ï¼Œéšœç¢ç‰©å’Œé£Ÿç‰©çš„ä½ç½®æ¯æ—¥éƒ½ä¼šå‘ç”Ÿå˜åŠ¨ï¼Œä¸”æ™ºèƒ½ä½“çš„æ„ŸçŸ¥ä¿¡æ¯å…·æœ‰é«˜åº¦ä¸ç¡®å®šæ€§å’Œå±€é™æ€§ï¼Œè¦æ±‚å…¶æ¨¡å‹æ„å»ºä¸è§„åˆ’è¿‡ç¨‹å¿…é¡»å…·å¤‡å¼ºå¥çš„é²æ£’æ€§ã€‚ç ”ç©¶å¯¹æ¯”äº†ä»ç®€å•åˆ°å¤æ‚çš„å¤šç§ç­–ç•¥ï¼Œå‘ç°éœ€è¦ä¸€ç§èƒ½å¤Ÿæ•´åˆå¤šç§ç­–ç•¥çš„æ¶æ„æ¥å¤„ç†æ¢ç´¢æœç´¢ä¸è·¯å¾„è§„åˆ’ç­‰ä¸åŒæ€§è´¨çš„å­ä»»åŠ¡ (Subtasks)ã€‚å®éªŒè¡¨æ˜ï¼Œåˆ©ç”¨éå¹³ç¨³æ¦‚ç‡å­¦ä¹  (Non-stationary Probability Learning) æŠ€æœ¯æŒç»­æ›´æ–°æƒ…å¢ƒè®°å¿† (Episodic Memory) çš„æ™ºèƒ½ä½“ï¼Œåœ¨å¤„ç†é•¿è·ç¦»ç›®æ ‡ç­‰é«˜éš¾åº¦ä»»åŠ¡æ—¶æ•ˆç‡æ˜¾è‘—æé«˜ã€‚è¿™äº›æ™ºèƒ½ä½“é€šè¿‡è®°å¿†å®æ—¶æ„å»ºä¸å®Œå–„çš„åœ°å›¾ (Imperfect Maps) å¹¶è¿›è¡ŒåŠ¨æ€è§„åˆ’ï¼Œå…¶è¡¨ç°è¿œä¼˜äºæç®€è®°å¿†æ™ºèƒ½ä½“ã€‚ç ”ç©¶æœ€ç»ˆæŒ‡å‡ºï¼Œåªè¦å®šä½å’Œç¯å¢ƒå˜åŒ–å¸¦æ¥çš„ä¸ç¡®å®šæ€§ (Uncertainty) ä¸è¶…è¿‡ä¸€å®šé™åº¦ï¼Œè¿™ç§ç»“åˆè®°å¿†ä¸è§„åˆ’çš„æœºåˆ¶åœ¨åº”å¯¹å¤æ‚å¯¼èˆªä»»åŠ¡æ—¶å…·æœ‰å®è´¨æ€§çš„ä¼˜åŠ¿ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15274v1",
      "published_date": "2026-02-17 00:15:47 UTC",
      "updated_date": "2026-02-17 00:15:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:43:56.833414+00:00"
    },
    {
      "arxiv_id": "2602.15270v1",
      "title": "Enhancing Diversity and Feasibility: Joint Population Synthesis from Multi-source Data Using Generative Models",
      "title_zh": "æå‡å¤šæ ·æ€§ä¸å¯è¡Œæ€§ï¼šåŸºäºç”Ÿæˆæ¨¡å‹çš„å¤šæºæ•°æ®è”åˆäººå£åˆæˆ",
      "authors": [
        "Farbod Abbasi",
        "Zachary Patterson",
        "Bilal Farooq"
      ],
      "abstract": "Generating realistic synthetic populations is essential for agent-based models (ABM) in transportation and urban planning. Current methods face two major limitations. First, many rely on a single dataset or follow a sequential data fusion and generation process, which means they fail to capture the complex interplay between features. Second, these approaches struggle with sampling zeros (valid but unobserved attribute combinations) and structural zeros (infeasible combinations due to logical constraints), which reduce the diversity and feasibility of the generated data. This study proposes a novel method to simultaneously integrate and synthesize multi-source datasets using a Wasserstein Generative Adversarial Network (WGAN) with gradient penalty. This joint learning method improves both the diversity and feasibility of synthetic data by defining a regularization term (inverse gradient penalty) for the generator loss function. For the evaluation, we implement a unified evaluation metric for similarity, and place special emphasis on measuring diversity and feasibility through recall, precision, and the F1 score. Results show that the proposed joint approach outperforms the sequential baseline, with recall increasing by 7\\% and precision by 15\\%. Additionally, the regularization term further improves diversity and feasibility, reflected in a 10\\% increase in recall and 1\\% in precision. We assess similarity distributions using a five-metric score. The joint approach performs better overall, and reaches a score of 88.1 compared to 84.6 for the sequential method. Since synthetic populations serve as a key input for ABM, this multi-source generative approach has the potential to significantly enhance the accuracy and reliability of ABM.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹äº¤é€šå’ŒåŸå¸‚è§„åˆ’ä¸­æ™ºèƒ½ä½“æ¨¡å‹(Agent-Based Models, ABM)æ‰€éœ€çš„åˆæˆäººå£ç”Ÿæˆé—®é¢˜ï¼ŒæŒ‡å‡ºäº†ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤šæºæ•°æ®èåˆä»¥åŠé‡‡æ ·é›¶å€¼(sampling zeros)å’Œç»“æ„é›¶å€¼(structural zeros)æ–¹é¢çš„å±€é™æ€§ã€‚ä¸ºè§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºå¸¦æ¢¯åº¦æƒ©ç½šçš„ç“¦ç‘Ÿæ–¯å¦ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(Wasserstein Generative Adversarial Network, WGAN)çš„æ–°å‹æ–¹æ³•ï¼Œå®ç°äº†å¤šæºæ•°æ®é›†çš„è”åˆé›†æˆä¸åˆæˆã€‚è¯¥æ–¹æ³•çš„æ ¸å¿ƒåˆ›æ–°åœ¨äºç”Ÿæˆå™¨æŸå¤±å‡½æ•°ä¸­å¼•å…¥äº†æ­£åˆ™åŒ–é¡¹ï¼ˆé€†æ¢¯åº¦æƒ©ç½šï¼‰ï¼Œæ—¨åœ¨åŒæ­¥æå‡åˆæˆæ•°æ®çš„å¤šæ ·æ€§å’Œå¯è¡Œæ€§ã€‚ç ”ç©¶é€šè¿‡ç›¸ä¼¼æ€§ã€å¬å›ç‡(recall)å’Œç²¾ç¡®ç‡(precision)ç­‰æŒ‡æ ‡è¿›è¡Œè¯„ä¼°ï¼Œç»“æœè¡¨æ˜è”åˆå­¦ä¹ æ–¹æ³•åœ¨å¬å›ç‡å’Œç²¾ç¡®ç‡ä¸Šåˆ†åˆ«æ¯”åºåˆ—åŒ–åŸºå‡†æ¨¡å‹æé«˜äº†7%å’Œ15%ã€‚æ­¤å¤–ï¼Œæ­£åˆ™åŒ–é¡¹çš„åŠ å…¥ä½¿å¬å›ç‡è¿›ä¸€æ­¥æå‡äº†10%ï¼Œæ•´ä½“ç›¸ä¼¼åº¦è¯„åˆ†è¾¾åˆ°88.1åˆ†ï¼Œä¼˜äºä¼ ç»Ÿåºåˆ—åŒ–æ–¹æ³•çš„84.6åˆ†ã€‚è¯¥ç ”ç©¶é€šè¿‡å¤šæºç”Ÿæˆæ–¹æ³•æ˜¾è‘—å¢å¼ºäº†ABMè¾“å…¥æ•°æ®çš„è´¨é‡ï¼Œä¸ºæå‡åŸå¸‚è§„åˆ’æ¨¡æ‹Ÿçš„å‡†ç¡®æ€§å’Œå¯é æ€§å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages, 8 figures, 5 tables",
      "pdf_url": "https://arxiv.org/pdf/2602.15270v1",
      "published_date": "2026-02-17 00:02:30 UTC",
      "updated_date": "2026-02-17 00:02:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:44:00.733114+00:00"
    },
    {
      "arxiv_id": "2602.15265v1",
      "title": "From Diagnosis to Inoculation: Building Cognitive Resistance to AI Disempowerment",
      "title_zh": "ä»è¯Šæ–­åˆ°æ¥ç§ï¼šæ„å»ºé’ˆå¯¹ AI å‰¥æƒçš„è®¤çŸ¥æŠµæŠ—åŠ›",
      "authors": [
        "Aleksey Komissarov"
      ],
      "abstract": "Recent empirical research by Sharma et al. (2026) demonstrated that AI assistant interactions carry meaningful potential for situational human disempowerment, including reality distortion, value judgment distortion, and action distortion. While this work provides a critical diagnosis of the problem, concrete pedagogical interventions remain underexplored. I present an AI literacy framework built around eight cross-cutting Learning Outcomes (LOs), developed independently through teaching practice and subsequently found to align with Sharma et al.'s disempowerment taxonomy. I report a case study from a publicly available online course, where a co-teaching methodology--with AI serving as an active voice co-instructor--was used to deliver this framework. Drawing on inoculation theory (McGuire, 1961)--a well-established persuasion research framework recently applied to misinformation prebunking by the Cambridge school (van der Linden, 2022; Roozenbeek & van der Linden, 2019)--I argue that AI literacy cannot be acquired through declarative knowledge alone, but requires guided exposure to AI failure modes, including the sycophantic validation and authority projection patterns identified by Sharma et al. This application of inoculation theory to AI-specific distortion is, to my knowledge, novel. I discuss the convergence between the pedagogically-derived framework and Sharma et al.'s empirically-derived taxonomy, and argue that this convergence--two independent approaches arriving at similar problem descriptions--strengthens the case for both the diagnosis and the proposed educational response.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹äººå·¥æ™ºèƒ½äº¤äº’ä¸­å¯èƒ½å¯¼è‡´çš„äººç±»å¤±èƒ½(AI Disempowerment)é—®é¢˜ï¼Œæ¢è®¨äº†å¦‚ä½•é€šè¿‡æ•™è‚²å¹²é¢„æ„å»ºè®¤çŸ¥æŠµæŠ—åŠ›ï¼Œä»¥åº”å¯¹ç°å®ã€ä»·å€¼è§‚å’Œè¡ŒåŠ¨ç»´åº¦çš„æ‰­æ›²ã€‚ä½œè€…æå‡ºäº†ä¸€ä¸ªåŒ…å«å…«é¡¹äº¤å‰å­¦ä¹ æˆæœ(Learning Outcomes, LOs)çš„äººå·¥æ™ºèƒ½ç´ å…»(AI Literacy)æ¡†æ¶ï¼Œå¹¶ç»“åˆå…¬å¼€è¯¾ç¨‹æ¡ˆä¾‹å±•ç¤ºäº†äººå·¥æ™ºèƒ½ä½œä¸ºå…±åŒå¯¼å¸ˆçš„ååŒæ•™å­¦æ–¹æ³•ã€‚ç ”ç©¶åˆ›æ–°æ€§åœ°å¼•å…¥äº†æ¥ç§ç†è®º(Inoculation Theory)ï¼Œä¸»å¼ äººå·¥æ™ºèƒ½ç´ å…»çš„è·å–ä¸èƒ½ä»…ä¾èµ–é™ˆè¿°æ€§çŸ¥è¯†ï¼Œè€Œå¿…é¡»é€šè¿‡å¼•å¯¼å­¦ä¹ è€…ä¸»åŠ¨æ¥è§¦äººå·¥æ™ºèƒ½çš„å¤±æ•ˆæ¨¡å¼æ¥å®ç°ã€‚è¿™äº›å¤±æ•ˆæ¨¡å¼åŒ…æ‹¬å¥‰æ‰¿æ€§éªŒè¯(Sycophantic Validation)å’Œæƒå¨æŠ•å°„(Authority Projection)ç­‰å…¸å‹çš„è¯±å¯¼æ€§è¡Œä¸ºã€‚æ•™å­¦å®è·µè¡ç”Ÿçš„æ¡†æ¶ä¸å·²æœ‰å®è¯ç ”ç©¶åˆ†ç±»æ³•çš„é«˜åº¦ä¸€è‡´æ€§ï¼Œæœ‰åŠ›åœ°è®ºè¯äº†è¯¥è¯Šæ–­ç»“æœåŠç›¸åº”æ•™è‚²å¯¹ç­–çš„å¯é æ€§ã€‚è¯¥ç ”ç©¶é€šè¿‡é¢„é˜²æ€§çš„â€œæ¥ç§â€ç­–ç•¥ï¼Œä¸ºå¢å¼ºäººç±»åœ¨äººå·¥æ™ºèƒ½è¾…åŠ©ç¯å¢ƒä¸‹çš„è®¤çŸ¥è‡ªä¸»æƒæä¾›äº†åˆ‡å®å¯è¡Œçš„æ•™å­¦è·¯å¾„ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "11 pages, 1 table. Perspective / Position Paper",
      "pdf_url": "https://arxiv.org/pdf/2602.15265v1",
      "published_date": "2026-02-16 23:47:13 UTC",
      "updated_date": "2026-02-16 23:47:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:44:06.739872+00:00"
    },
    {
      "arxiv_id": "2602.15260v1",
      "title": "Fast and Effective On-policy Distillation from Reasoning Prefixes",
      "title_zh": "åŸºäºæ¨ç†å‰ç¼€çš„é«˜æ•ˆåœ¨çº¿ç­–ç•¥è’¸é¦",
      "authors": [
        "Dongxu Zhang",
        "Zhichao Yang",
        "Sepehr Janghorbani",
        "Jun Han",
        "Andrew Ressler",
        "Qian Qian",
        "Gregory D. Lyng",
        "Sanjit Singh Batra",
        "Robert E. Tillman"
      ],
      "abstract": "On-policy distillation (OPD), which samples trajectories from the student model and supervises them with a teacher at the token level, avoids relying solely on verifiable terminal rewards and can yield better generalization than off-policy distillation. However, OPD requires expensive on-the-fly sampling of the student policy during training, which substantially increases training cost, especially for long responses. Our initial analysis shows that, during OPD, training signals are often concentrated in the prefix of each output, and that even a short teacher-generated prefix can significantly help the student produce the correct answer. Motivated by these observations, we propose a simple yet effective modification of OPD: we apply the distillation objective only to prefixes of student-generated outputs and terminate each sampling early during distillation. Experiments on a suite of AI-for-Math and out-of-domain benchmarks show that on-policy prefix distillation matches the performance of full OPD while reducing training FLOP by 2x-47x.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç­–ç•¥å†…è’¸é¦ (On-policy distillation, OPD) æŠ€æœ¯ï¼ŒæŒ‡å‡ºå…¶è™½èƒ½æä¾›ä¼˜äºç­–ç•¥å¤–è’¸é¦çš„æ³›åŒ–æ€§èƒ½ï¼Œä½†å› è®­ç»ƒä¸­éœ€å®æ—¶é‡‡æ ·è€Œé¢ä¸´æé«˜çš„è®¡ç®—æˆæœ¬ã€‚é€šè¿‡åˆæ­¥åˆ†æï¼Œä½œè€…å‘ç° OPD çš„è®­ç»ƒä¿¡å·ä¸»è¦é›†ä¸­åœ¨è¾“å‡ºçš„å‰ç¼€ (prefix) éƒ¨åˆ†ï¼Œä¸”çŸ­å°çš„æ•™å¸ˆç”Ÿæˆå‰ç¼€å·²è¶³ä»¥å¼•å¯¼å­¦ç”Ÿæ¨¡å‹å¾—å‡ºæ­£ç¡®ç­”æ¡ˆã€‚é’ˆå¯¹è¿™ä¸€è§‚å¯Ÿï¼Œç ”ç©¶æå‡ºäº†ä¸€ç§æ”¹è¿›çš„ç­–ç•¥å†…å‰ç¼€è’¸é¦æ–¹æ³•ï¼Œé€šè¿‡ä»…å¯¹å­¦ç”Ÿç”Ÿæˆè¾“å‡ºçš„å‰ç¼€éƒ¨åˆ†åº”ç”¨è’¸é¦ç›®æ ‡å¹¶æå‰ç»ˆæ­¢é‡‡æ ·ï¼Œå¤§å¹…ä¼˜åŒ–äº†è®­ç»ƒè¿‡ç¨‹ã€‚åœ¨ AI-for-Math åŠåŸŸå¤– (out-of-domain) åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨ä¿æŒä¸å®Œæ•´ OPD ç›¸å½“æ€§èƒ½çš„åŒæ—¶ï¼Œå°†è®­ç»ƒæ‰€éœ€çš„æµ®ç‚¹è¿ç®—é‡ (FLOPs) é™ä½äº† 2 åˆ° 47 å€ã€‚è¯¥ç ”ç©¶è¯æ˜äº†åˆ©ç”¨æ¨ç†å‰ç¼€è¿›è¡Œé«˜æ•ˆæ¨¡å‹è’¸é¦çš„å¯è¡Œæ€§ï¼Œä¸ºä¼˜åŒ–å¤§è¯­è¨€æ¨¡å‹çš„è®­ç»ƒæ•ˆç‡æä¾›äº†æ–°è·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15260v1",
      "published_date": "2026-02-16 23:28:54 UTC",
      "updated_date": "2026-02-16 23:28:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:45:13.646079+00:00"
    },
    {
      "arxiv_id": "2602.15259v1",
      "title": "Knowing Isn't Understanding: Re-grounding Generative Proactivity with Epistemic and Behavioral Insight",
      "title_zh": "çŸ¥æ™“å¹¶éç†è§£ï¼šåŸºäºè®¤çŸ¥ä¸è¡Œä¸ºæ´å¯Ÿé‡å¡‘ç”Ÿæˆå¼ä¸»åŠ¨æ€§",
      "authors": [
        "Kirandeep Kaur",
        "Xingda Lyu",
        "Chirag Shah"
      ],
      "abstract": "Generative AI agents equate understanding with resolving explicit queries, an assumption that confines interaction to what users can articulate. This assumption breaks down when users themselves lack awareness of what is missing, risky, or worth considering. In such conditions, proactivity is not merely an efficiency enhancement, but an epistemic necessity. We refer to this condition as epistemic incompleteness: where progress depends on engaging with unknown unknowns for effective partnership. Existing approaches to proactivity remain narrowly anticipatory, extrapolating from past behavior and presuming that goals are already well defined, thereby failing to support users meaningfully. However, surfacing possibilities beyond a user's current awareness is not inherently beneficial. Unconstrained proactive interventions can misdirect attention, overwhelm users, or introduce harm. Proactive agents, therefore, require behavioral grounding: principled constraints on when, how, and to what extent an agent should intervene. We advance the position that generative proactivity must be grounded both epistemically and behaviorally. Drawing on the philosophy of ignorance and research on proactive behavior, we argue that these theories offer critical guidance for designing agents that can engage responsibly and foster meaningful partnerships.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ï¼ˆGenerative AIï¼‰æ™ºèƒ½ä½“åœ¨ç†è§£ç”¨æˆ·éœ€æ±‚æ—¶çš„å±€é™æ€§ï¼ŒæŒ‡å‡ºç›®å‰çš„äº¤äº’å¾€å¾€å±€é™äºç”¨æˆ·èƒ½æ˜ç¡®è¡¨è¾¾çš„å†…å®¹ï¼Œå¿½è§†äº†ç”¨æˆ·å¯èƒ½é¢ä¸´çš„è®¤çŸ¥ä¸å®Œæ•´æ€§ï¼ˆepistemic incompletenessï¼‰ã€‚åœ¨è¿™ç§ç”¨æˆ·è‡ªèº«ä¸æ¸…æ¥šé£é™©æˆ–æ½œåœ¨å¯èƒ½æ€§çš„æƒ…å†µä¸‹ï¼Œä¸»åŠ¨æ€§ï¼ˆproactivityï¼‰ä¸å†ä»…æ˜¯æå‡æ•ˆç‡çš„å·¥å…·ï¼Œè€Œæ˜¯è®¤çŸ¥ä¸Šçš„å¿…ç„¶éœ€æ±‚ã€‚ä½œè€…æ‰¹è¯„äº†ç°æœ‰æ–¹æ³•ä»…é€šè¿‡è¿‡å»è¡Œä¸ºè¿›è¡Œç®€å•é¢„æµ‹çš„å±€é™ï¼Œå¹¶æŒ‡å‡ºä¸å—çº¦æŸçš„ä¸»åŠ¨å¹²é¢„å¯èƒ½ä¼šå¹²æ‰°ç”¨æˆ·æˆ–é€ æˆä¼¤å®³ã€‚å› æ­¤ï¼Œè®ºæ–‡ä¸»å¼ ç”Ÿæˆå¼ä¸»åŠ¨æ€§å¿…é¡»åœ¨è®¤çŸ¥ï¼ˆepistemicï¼‰å’Œè¡Œä¸ºï¼ˆbehavioralï¼‰ç»´åº¦ä¸Šè¿›è¡ŒåŒé‡é‡æ„ã€‚é€šè¿‡ç»“åˆæ— çŸ¥å“²å­¦ï¼ˆphilosophy of ignoranceï¼‰å’Œä¸»åŠ¨è¡Œä¸ºç ”ç©¶ï¼Œè¯¥ç ”ç©¶ä¸ºè®¾è®¡èƒ½å¤Ÿè´Ÿè´£ä»»åœ°ä»‹å…¥å¹¶å»ºç«‹æ·±å±‚ä¼™ä¼´å…³ç³»çš„æ™ºèƒ½ä½“æä¾›äº†ç†è®ºæ¡†æ¶ä¸æŒ‡å¯¼åŸåˆ™ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15259v1",
      "published_date": "2026-02-16 23:28:17 UTC",
      "updated_date": "2026-02-16 23:28:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:44:40.138990+00:00"
    },
    {
      "arxiv_id": "2602.15257v1",
      "title": "How to Train Your Long-Context Visual Document Model",
      "title_zh": "å¦‚ä½•è®­ç»ƒä½ çš„é•¿ä¸Šä¸‹æ–‡è§†è§‰æ–‡æ¡£æ¨¡å‹",
      "authors": [
        "Austin Veselka"
      ],
      "abstract": "We present the first comprehensive, large-scale study of training long-context vision language models up to 344K context, targeting long-document visual question answering with measured transfer to long-context text. While several such strong are open-weight, namely Qwen3 VL and GLM 4.5/6V, their training recipes and data pipelines are not reproducible. We systematically study continued pretraining, supervised finetuning, and preference optimization for 24B and 32B parameter models, backed by extensive LC evaluations and ablations to bridge this gap, and achieve state-of-the-art performance on MMLongBenchDoc for both parameter scales. In addition to this, our key findings include: (i) training on context lengths that match evaluation context lengths outperforms training on longer contexts, (ii) training and evaluating with page indices provides a simple, high-impact boost to long-document performance, (iii) our synthetic data pipelines enable self-improvement via continued pretraining and supervised finetuning, and (iv) we extend the known text-to-visual long context transfer to the reverse, showing that visual long context training transfers to long-context text performance. We also release MMLBD-C, a manually corrected version of MMLongBenchDoc to reduce erroneous and low quality examples in the benchmark.",
      "tldr_zh": "è¯¥ç ”ç©¶å¯¹é•¿ä¸Šä¸‹æ–‡è§†è§‰è¯­è¨€æ¨¡å‹(Long-Context Vision Language Models)çš„è®­ç»ƒè¿›è¡Œäº†é¦–æ¬¡å¤§è§„æ¨¡å…¨é¢ç ”ç©¶ï¼ŒæˆåŠŸå°†ä¸Šä¸‹æ–‡é•¿åº¦æ‰©å±•è‡³344Kï¼Œé‡ç‚¹è§£å†³äº†é•¿æ–‡æ¡£è§†è§‰é—®ç­”(Long-Document Visual Question Answering)ä»»åŠ¡ã€‚ç ”ç©¶è€…é’ˆå¯¹24Bå’Œ32Bå‚æ•°è§„æ¨¡çš„æ¨¡å‹ï¼Œç³»ç»Ÿåœ°æ¢è®¨äº†æŒç»­é¢„è®­ç»ƒ(Continued Pretraining)ã€ç›‘ç£å¾®è°ƒ(Supervised Finetuning)å’Œåå¥½ä¼˜åŒ–(Preference Optimization)çš„è®­ç»ƒæ–¹æ¡ˆï¼Œå¹¶åœ¨MMLongBenchDocåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†é¢†å…ˆçš„State-of-the-Artæ€§èƒ½ã€‚å…³é”®å‘ç°åŒ…æ‹¬ï¼šåŒ¹é…è®­ç»ƒä¸è¯„ä¼°çš„ä¸Šä¸‹æ–‡é•¿åº¦æ•ˆæœæœ€ä½³ï¼Œå¼•å…¥é¡µé¢ç´¢å¼•(Page Indices)å¯æ˜¾è‘—æå‡æ€§èƒ½ï¼Œä¸”åˆæˆæ•°æ®æµæ°´çº¿èƒ½æ”¯æŒæ¨¡å‹çš„è‡ªæˆ‘æ”¹è¿›ã€‚ç ”ç©¶è¿˜æ­ç¤ºäº†è§†è§‰é•¿ä¸Šä¸‹æ–‡è®­ç»ƒèƒ½æœ‰æ•ˆåå‘è¿ç§»è‡³çº¯æ–‡æœ¬é•¿ä¸Šä¸‹æ–‡ä»»åŠ¡ï¼Œå¹¶å‘å¸ƒäº†ç»è¿‡äººå·¥ä¿®æ­£çš„MMLBD-Cæ•°æ®é›†ä»¥ä¼˜åŒ–è¯„ä¼°è´¨é‡ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15257v1",
      "published_date": "2026-02-16 23:26:51 UTC",
      "updated_date": "2026-02-16 23:26:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:44:51.843404+00:00"
    },
    {
      "arxiv_id": "2602.15252v1",
      "title": "Decision Making under Imperfect Recall: Algorithms and Benchmarks",
      "title_zh": "ä¸å®Œå…¨è®°å¿†ä¸‹çš„å†³ç­–ï¼šç®—æ³•ä¸åŸºå‡†",
      "authors": [
        "Emanuel Tewolde",
        "Brian Hu Zhang",
        "Ioannis Anagnostides",
        "Tuomas Sandholm",
        "Vincent Conitzer"
      ],
      "abstract": "In game theory, imperfect-recall decision problems model situations in which an agent forgets information it held before. They encompass games such as the ``absentminded driver'' and team games with limited communication. In this paper, we introduce the first benchmark suite for imperfect-recall decision problems. Our benchmarks capture a variety of problem types, including ones concerning privacy in AI systems that elicit sensitive information, and AI safety via testing of agents in simulation. Across 61 problem instances generated using this suite, we evaluate the performance of different algorithms for finding first-order optimal strategies in such problems. In particular, we introduce the family of regret matching (RM) algorithms for nonlinear constrained optimization. This class of parameter-free algorithms has enjoyed tremendous success in solving large two-player zero-sum games, but, surprisingly, they were hitherto relatively unexplored beyond that setting. Our key finding is that RM algorithms consistently outperform commonly employed first-order optimizers such as projected gradient descent, often by orders of magnitude. This establishes, for the first time, the RM family as a formidable approach to large-scale constrained optimization problems.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åšå¼ˆè®ºä¸­çš„ä¸å®Œå…¨è®°å¿†(Imperfect Recall)å†³ç­–é—®é¢˜ï¼Œæ¨¡æ‹Ÿäº†æ™ºèƒ½ä½“é—å¿˜å…ˆå‰ä¿¡æ¯çš„æƒ…æ™¯ï¼Œå¦‚â€œå¿ƒä¸åœ¨ç„‰çš„é©¾é©¶å‘˜â€å’Œé€šä¿¡å—é™çš„å›¢é˜Ÿåšå¼ˆã€‚è®ºæ–‡å¼•å…¥äº†é¦–ä¸ªé’ˆå¯¹æ­¤ç±»é—®é¢˜çš„åŸºå‡†æµ‹è¯•é›†(Benchmark Suite)ï¼Œæ¶µç›–äº†AIéšç§ä¿æŠ¤å’ŒAIå®‰å…¨æ¨¡æ‹Ÿç­‰å¤šä¸ªå…³é”®åº”ç”¨åœºæ™¯ã€‚é€šè¿‡å¯¹61ä¸ªé—®é¢˜å®ä¾‹çš„è¯„ä¼°ï¼Œç ”ç©¶è€…å¯¹æ¯”äº†ä¸åŒç®—æ³•åœ¨å¯»æ‰¾ä¸€é˜¶æœ€ä¼˜ç­–ç•¥(First-order Optimal Strategies)æ–¹é¢çš„æ€§èƒ½ã€‚ç ”ç©¶é‡ç‚¹ä»‹ç»äº†åæ‚”åŒ¹é…(Regret Matching, RM)ç®—æ³•æ—åœ¨éçº¿æ€§çº¦æŸä¼˜åŒ–(Nonlinear Constrained Optimization)ä¸­çš„åº”ç”¨ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒRMç³»åˆ—ç®—æ³•åœ¨æ€§èƒ½ä¸Šä¸€è‡´ä¸”æ˜¾è‘—åœ°ä¼˜äºæŠ•å½±æ¢¯åº¦ä¸‹é™(Projected Gradient Descent)ç­‰å¸¸ç”¨ä¸€é˜¶ä¼˜åŒ–å™¨ï¼Œæå‡å¹…åº¦å¸¸è¾¾æ•°ä¸ªæ•°é‡çº§ã€‚è¿™ä¸€å‘ç°é¦–æ¬¡ç¡®ç«‹äº†RMç®—æ³•å®¶æ—æ˜¯å¤„ç†å¤§è§„æ¨¡çº¦æŸä¼˜åŒ–é—®é¢˜çš„ä¸€ç§æå…·ç«äº‰åŠ›çš„æ‰‹æ®µã€‚",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.GT",
      "comment": "39 pages, 71 figures, 4 table",
      "pdf_url": "https://arxiv.org/pdf/2602.15252v1",
      "published_date": "2026-02-16 23:19:01 UTC",
      "updated_date": "2026-02-16 23:19:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:45:36.039944+00:00"
    },
    {
      "arxiv_id": "2602.15249v1",
      "title": "Artificial Intelligence Specialization in the European Union: Underexplored Role of the Periphery at NUTS-3 Level",
      "title_zh": "æ¬§ç›Ÿäººå·¥æ™ºèƒ½ä¸“ä¸šåŒ–ç ”ç©¶ï¼šNUTS-3 å±‚çº§è¾¹ç¼˜åœ°åŒºå°šæœªè¢«å……åˆ†æŒ–æ˜çš„ä½œç”¨",
      "authors": [
        "Victor Herrero-Solana"
      ],
      "abstract": "This study examines the geographical distribution of Artificial Intelligence (AI) research production across European regions at the NUTS-3 level for the period 2015-2024. Using bibliometric data from Clarivate InCites and the Citation Topics classification system, we analyze two hierarchical levels of thematic aggregation: Electrical Engineering, Electronics & Computer Science (Macro Citation Topic 4) and Artificial Intelligence & Machine Learning (Meso Citation Topic 4.61). We calculate the Relative Specialization Index (RSI) and Relative Citation Impact (RCI) for 781 NUTS-3 regions. While major metropolitan hubs such as Paris (IIle-de-France), Warszawa, and Madrid lead in absolute production volume, our findings reveal that peripheral regions, particularly from Eastern Europe and Spain, exhibit the highest levels of relative AI specialization. Notably, we find virtually no correlation between regional specialization and citation impact, identifying four distinct regional profiles: high-impact specialized regions (e.g., Granada, Jaen, Vilniaus), high-volume but low-impact regions (e.g., Bugas, several Polish regions), high-impact non-specialized regions, with Fyn (Denmark) standing out as a remarkable outlier achieving exceptional citation impact (RCI > 4) despite low specialization, and diversified portfolios with selective excellence (e.g., German regions). These results suggest that AI research represents a strategic opportunity for peripheral regions to develop competitive scientific niches, though achieving international visibility requires more than research volume alone.",
      "tldr_zh": "è¯¥ç ”ç©¶è°ƒæŸ¥äº†2015-2024å¹´é—´æ¬§ç›ŸNUTS-3å±‚çº§åŒºåŸŸåœ¨äººå·¥æ™ºèƒ½(AI)ç ”ç©¶æ–¹é¢çš„åœ°ç†åˆ†å¸ƒä¸ä¸“ä¸šåŒ–ç¨‹åº¦ã€‚é€šè¿‡åˆ†æClarivate InCitesçš„æ–‡çŒ®è®¡é‡æ•°æ®ï¼Œç ”ç©¶è®¡ç®—äº†781ä¸ªåœ°åŒºçš„ç›¸å¯¹ä¸“ä¸šåŒ–æŒ‡æ•°(RSI)å’Œç›¸å¯¹å¼•ç”¨å½±å“åŠ›(RCI)ï¼Œæ¶µç›–äº†ç”µæ°”å·¥ç¨‹ã€ç”µå­ä¸è®¡ç®—æœºç§‘å­¦ä»¥åŠäººå·¥æ™ºèƒ½ä¸æœºå™¨å­¦ä¹ ä¸¤ä¸ªå±‚çº§ã€‚ç ”ç©¶å‘ç°ï¼Œè™½ç„¶å·´é»ã€åæ²™å’Œé©¬å¾·é‡Œç­‰å¤§éƒ½å¸‚åœ¨ç»å¯¹äº§é‡ä¸Šé¢†å…ˆï¼Œä½†ä¸œæ¬§å’Œè¥¿ç­ç‰™çš„è¾¹ç¼˜åŒ–åœ°åŒºåœ¨AIé¢†åŸŸè¡¨ç°å‡ºæœ€é«˜çš„ç›¸å¯¹ä¸“ä¸šåŒ–æ°´å¹³ã€‚ç ”ç©¶è¿›ä¸€æ­¥è¯†åˆ«äº†é«˜å½±å“åŠ›ä¸“ä¸šåŒ–åœ°åŒºã€é«˜äº§é‡ä½å½±å“åŠ›åœ°åŒºç­‰å››ç§åŒºåŸŸç”»åƒï¼Œå¹¶ç‰¹åˆ«æŒ‡å‡ºä¸¹éº¦çš„Fynåœ°åŒºåœ¨ä½ä¸“ä¸šåŒ–ä¸‹å®ç°äº†æé«˜çš„å¼•ç”¨å½±å“åŠ›ã€‚ç»“æœè¡¨æ˜ï¼ŒåŒºåŸŸä¸“ä¸šåŒ–ä¸å¼•ç”¨å½±å“åŠ›ä¹‹é—´å‡ ä¹ä¸å­˜åœ¨ç›¸å…³æ€§ï¼ŒAIç ”ç©¶ä¸ºè¾¹ç¼˜åœ°åŒºå¼€å‘ç«äº‰æ€§ç§‘å­¦åˆ©åŸºæä¾›äº†æˆ˜ç•¥æœºé‡ï¼Œä½†æå‡å›½é™…çŸ¥ååº¦ä»éœ€åœ¨ç ”ç©¶è§„æ¨¡ä¹‹å¤–å¯»æ±‚çªç ´ã€‚",
      "categories": [
        "cs.DL",
        "cs.AI"
      ],
      "primary_category": "cs.DL",
      "comment": "6 pages, 3 figures, submitted to IEEE Computational Intelligence Magazine",
      "pdf_url": "https://arxiv.org/pdf/2602.15249v1",
      "published_date": "2026-02-16 23:01:14 UTC",
      "updated_date": "2026-02-16 23:01:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:45:31.935830+00:00"
    },
    {
      "arxiv_id": "2602.15248v1",
      "title": "Predicting Invoice Dilution in Supply Chain Finance with Leakage Free Two Stage XGBoost, KAN (Kolmogorov Arnold Networks), and Ensemble Models",
      "title_zh": "åŸºäºæ— æ³„æ¼ä¸¤é˜¶æ®µ XGBoostã€KANï¼ˆKolmogorov-Arnold Networksï¼‰åŠé›†æˆæ¨¡å‹çš„ä¾›åº”é“¾é‡‘èå‘ç¥¨ç¨€é‡Šé¢„æµ‹",
      "authors": [
        "Pavel Koptev",
        "Vishnu Kumar",
        "Konstantin Malkov",
        "George Shapiro",
        "Yury Vikhanov"
      ],
      "abstract": "Invoice or payment dilution is the gap between the approved invoice amount and the actual collection is a significant source of non credit risk and margin loss in supply chain finance. Traditionally, this risk is managed through the buyer's irrevocable payment undertaking (IPU), which commits to full payment without deductions. However, IPUs can hinder supply chain finance adoption, particularly among sub-invested grade buyers. A newer, data-driven methods use real-time dynamic credit limits, projecting dilution for each buyer-supplier pair in real-time. This paper introduces an AI, machine learning framework and evaluates how that can supplement a deterministic algorithm to predict invoice dilution using extensive production dataset across nine key transaction fields.",
      "tldr_zh": "è¯¥ç ”ç©¶èšç„¦äºä¾›åº”é“¾é‡‘è (Supply Chain Finance) ä¸­çš„å‘ç¥¨ç¨€é‡Š (Invoice Dilution) é£é™©ï¼Œå³æ ¸å‡†å‘ç¥¨é‡‘é¢ä¸å®é™…å›æ¬¾ä¹‹é—´çš„å·®é¢ã€‚ä¸ºäº†å…‹æœä¼ ç»Ÿä¸å¯æ’¤é”€ä»˜æ¬¾æ‰¿è¯º (IPU) é™åˆ¶èèµ„æ™®åŠçš„å¼Šç«¯ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäº AI å’Œæœºå™¨å­¦ä¹ çš„é¢„æµ‹æ¡†æ¶ã€‚è¯¥æ¡†æ¶åˆ©ç”¨æ¶µç›–ä¹ä¸ªå…³é”®äº¤æ˜“é¢†åŸŸçš„çœŸå®ç”Ÿäº§æ•°æ®é›†ï¼Œåˆ›æ–°æ€§åœ°é‡‡ç”¨äº†æ— æ³„æ¼ä¸¤é˜¶æ®µ XGBoostã€KAN (Kolmogorov Arnold Networks) å’Œé›†æˆæ¨¡å‹ (Ensemble Models)ã€‚ç ”ç©¶é€šè¿‡å®æ—¶é¢„æµ‹ä¹°å–åŒæ–¹çš„ç¨€é‡Šæ¦‚ç‡ï¼Œä¸ºä¼ ç»Ÿçš„ç¡®å®šæ€§ç®—æ³•æä¾›äº†é‡è¦è¡¥å……ï¼Œæ—¨åœ¨å®ç°æ›´çµæ´»çš„åŠ¨æ€ä¿¡ç”¨é¢åº¦ç®¡ç†ã€‚è¿™ç§æ•°æ®é©±åŠ¨çš„æ–¹æ³•æœ‰æ•ˆé™ä½äº†éä¿¡ç”¨é£é™©å’Œåˆ©æ¶¦æŸå¤±ï¼Œä¸ºäºšæŠ•èµ„çº§ä¹°å®¶å‚ä¸ä¾›åº”é“¾é‡‘èæä¾›äº†æ–°çš„æŠ€æœ¯æ‰‹æ®µã€‚",
      "categories": [
        "cs.AI",
        "math.OC",
        "q-fin.MF"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15248v1",
      "published_date": "2026-02-16 23:00:39 UTC",
      "updated_date": "2026-02-16 23:00:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:45:36.442619+00:00"
    },
    {
      "arxiv_id": "2602.15245v1",
      "title": "MyoInteract: A Framework for Fast Prototyping of Biomechanical HCI Tasks using Reinforcement Learning",
      "title_zh": "MyoInteractï¼šåŸºäºå¼ºåŒ–å­¦ä¹ çš„ç”Ÿç‰©åŠ›å­¦äººæœºäº¤äº’ä»»åŠ¡å¿«é€ŸåŸå‹è®¾è®¡æ¡†æ¶",
      "authors": [
        "Ankit Bhattarai",
        "Hannah Selder",
        "Florian Fischer",
        "Arthur Fleig",
        "Per Ola Kristensson"
      ],
      "abstract": "Reinforcement learning (RL)-based biomechanical simulations have the potential to revolutionise HCI research and interaction design, but currently lack usability and interpretability. Using the Human Action Cycle as a design lens, we identify key limitations of biomechanical RL frameworks and develop MyoInteract, a novel framework for fast prototyping of biomechanical HCI tasks. MyoInteract allows designers to setup tasks, user models, and training parameters from an easy-to-use GUI within minutes. It trains and evaluates muscle-actuated simulated users within minutes, reducing training times by up to 98%. A workshop study with 12 interaction designers revealed that MyoInteract allowed novices in biomechanical RL to successfully setup, train, and assess goal-directed user movements within a single session. By transforming biomechanical RL from a days-long expert task into an accessible hour-long workflow, this work significantly lowers barriers to entry and accelerates iteration cycles in HCI biomechanics research.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† MyoInteractï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨å¿«é€ŸåŸå‹åŒ–ç”Ÿç‰©åŠ›å­¦äººæœºäº¤äº’ï¼ˆHCIï¼‰ä»»åŠ¡çš„åˆ›æ–°æ¡†æ¶ï¼Œè§£å†³äº†ç°æœ‰åŸºäºå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰çš„ç”Ÿç‰©åŠ›å­¦æ¨¡æ‹Ÿåœ¨å¯ç”¨æ€§å’Œå¯è§£é‡Šæ€§æ–¹é¢çš„å±€é™ã€‚è¯¥æ¡†æ¶ä»¥äººç±»åŠ¨ä½œå¾ªç¯ï¼ˆHuman Action Cycleï¼‰ä¸ºè®¾è®¡è§†è§’ï¼Œæä¾›äº†ä¸€ä¸ªæ˜“äºä½¿ç”¨çš„å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIï¼‰ï¼Œä½¿ç”¨æˆ·èƒ½å¤Ÿåœ¨å‡ åˆ†é’Ÿå†…å®Œæˆä»»åŠ¡ã€ç”¨æˆ·æ¨¡å‹åŠè®­ç»ƒå‚æ•°çš„è®¾ç½®ã€‚MyoInteract æ˜¾è‘—ä¼˜åŒ–äº†æ€§èƒ½ï¼Œå°†è‚Œè‚‰é©±åŠ¨æ¨¡æ‹Ÿç”¨æˆ·çš„è®­ç»ƒæ—¶é—´ç¼©çŸ­äº†é«˜è¾¾ 98%ï¼Œå°†åŸæœ¬éœ€è¦æ•°å¤©çš„ä¸“å®¶çº§ä»»åŠ¡è½¬åŒ–ä¸ºä¸€å°æ—¶å†…çš„ä¾¿æ·å·¥ä½œæµã€‚ä¸€é¡¹é’ˆå¯¹ 12 åäº¤äº’è®¾è®¡å¸ˆçš„å·¥ä½œåŠç ”ç©¶è¡¨æ˜ï¼Œå³ä½¿æ˜¯éä¸“å®¶ç”¨æˆ·ä¹Ÿèƒ½åœ¨å•æ¬¡æ“ä½œä¸­æˆåŠŸå®Œæˆç›®æ ‡å¯¼å‘åŠ¨ä½œçš„è®¾ç½®ã€è®­ç»ƒä¸è¯„ä¼°ã€‚é€šè¿‡é™ä½æŠ€æœ¯é—¨æ§›å¹¶åŠ é€Ÿè¿­ä»£å‘¨æœŸï¼Œè¯¥å·¥ä½œä¸ºç”Ÿç‰©åŠ›å­¦ HCI ç ”ç©¶é¢†åŸŸæä¾›äº†é«˜æ•ˆä¸”æ˜“äºè®¿é—®çš„å·¥å…·æ”¯æŒã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15245v1",
      "published_date": "2026-02-16 22:51:57 UTC",
      "updated_date": "2026-02-16 22:51:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:46:07.937651+00:00"
    },
    {
      "arxiv_id": "2602.15241v1",
      "title": "GenAI for Systems: Recurring Challenges and Design Principles from Software to Silicon",
      "title_zh": "é¢å‘ç³»ç»Ÿçš„ç”Ÿæˆå¼ AIï¼šä»è½¯ä»¶åˆ°èŠ¯ç‰‡çš„å…±æ€§æŒ‘æˆ˜ä¸è®¾è®¡åŸåˆ™",
      "authors": [
        "Arya Tschand",
        "Chenyu Wang",
        "Zishen Wan",
        "Andrew Cheng",
        "Ioana Cristescu",
        "Kevin He",
        "Howard Huang",
        "Alexander Ingare",
        "Akseli Kangaslahti",
        "Sara Kangaslahti",
        "Theo Lebryk",
        "Hongjin Lin",
        "Jeffrey Jian Ma",
        "Alexandru Meterez",
        "Clara Mohri",
        "Depen Morwani",
        "Sunny Qin",
        "Roy Rinberg",
        "Paula Rodriguez-Diaz",
        "Alyssa Mia Taliotis",
        "Pernille Undrum Fathi",
        "Rosie Zhao",
        "Todd Zhou",
        "Vijay Janapa Reddi"
      ],
      "abstract": "Generative AI is reshaping how computing systems are designed, optimized, and built, yet research remains fragmented across software, architecture, and chip design communities. This paper takes a cross-stack perspective, examining how generative models are being applied from code generation and distributed runtimes through hardware design space exploration to RTL synthesis, physical layout, and verification. Rather than reviewing each layer in isolation, we analyze how the same structural difficulties and effective responses recur across the stack. Our central finding is one of convergence. Despite the diversity of domains and tools, the field keeps encountering five recurring challenges (the feedback loop crisis, the tacit knowledge problem, trust and validation, co-design across boundaries, and the shift from determinism to dynamism) and keeps arriving at five design principles that independently emerge as effective responses (embracing hybrid approaches, designing for continuous feedback, separating concerns by role, matching methods to problem structure, and building on decades of systems knowledge). We organize these into a challenge--principle map that serves as a diagnostic and design aid, showing which principles have proven effective for which challenges across layers. Through concrete cross-stack examples, we show how systems navigate this map as they mature, and argue that the field needs shared engineering methodology, including common vocabularies, cross-layer benchmarks, and systematic design practices, so that progress compounds across communities rather than being rediscovered in each one. Our analysis covers more than 275 papers spanning eleven application areas across three layers of the computing stack, and distills open research questions that become visible only from a cross-layer vantage point.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ (Generative AI) å¦‚ä½•ä»è½¯ä»¶ã€æ¶æ„åˆ°èŠ¯ç‰‡è®¾è®¡å…¨æ–¹ä½é‡å¡‘è®¡ç®—ç³»ç»Ÿã€‚é€šè¿‡å¯¹æ¶µç›–11ä¸ªåº”ç”¨é¢†åŸŸçš„275å¤šç¯‡è®ºæ–‡è¿›è¡Œè·¨å±‚çº§åˆ†æï¼Œæœ¬æ–‡è¯†åˆ«äº†è®¡ç®—å †æ ˆä¸­åå¤å‡ºç°çš„äº”å¤§æ ¸å¿ƒæŒ‘æˆ˜ï¼ŒåŒ…æ‹¬åé¦ˆå¾ªç¯å±æœº (feedback loop crisis)ã€éšæ€§çŸ¥è¯†é—®é¢˜ (tacit knowledge problem)ã€ä¿¡ä»»ä¸éªŒè¯ (trust and validation)ã€è·¨ç•ŒååŒè®¾è®¡ (co-design across boundaries) ä»¥åŠä»ç¡®å®šæ€§å‘åŠ¨æ€æ€§çš„è½¬å˜ (shift from determinism to dynamism)ã€‚ä¸ä¹‹å¯¹åº”ï¼Œç ”ç©¶æ€»ç»“äº†äº”ä¸ªé€šç”¨çš„è®¾è®¡åŸåˆ™ï¼Œå¦‚é‡‡ç”¨æ··åˆæ–¹æ³• (hybrid approaches) å’ŒæŒç»­åé¦ˆè®¾è®¡ï¼Œå¹¶å°†å…¶æ•´åˆä¸ºä¸€å¥—â€œæŒ‘æˆ˜-åŸåˆ™åœ°å›¾â€ (challenge-principle map) ä»¥æŒ‡å¯¼ç³»ç»Ÿè®¾è®¡ã€‚è¯¥è®ºæ–‡å¼ºè°ƒäº†å»ºç«‹ç»Ÿä¸€å·¥ç¨‹æ–¹æ³•è®ºã€è·¨å±‚åŸºå‡†æµ‹è¯•å’Œç³»ç»ŸåŒ–è®¾è®¡å®è·µçš„å¿…è¦æ€§ï¼Œæ—¨åœ¨é¿å…ä¸åŒç ”ç©¶ç¤¾åŒºé—´çš„é‡å¤åŠ³åŠ¨ã€‚é€šè¿‡è¿™ç§è·¨å±‚è§†è§’ï¼Œç ”ç©¶ä¸ä»…æç‚¼äº†ç°æœ‰çš„è®¾è®¡æ¨¡å¼ï¼Œè¿˜æ­ç¤ºäº†ä»…åœ¨å…¨å±€è§†è§’ä¸‹å¯è§çš„å¼€æ”¾æ€§ç ”ç©¶é—®é¢˜ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15241v1",
      "published_date": "2026-02-16 22:45:33 UTC",
      "updated_date": "2026-02-16 22:45:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:46:09.445029+00:00"
    },
    {
      "arxiv_id": "2602.15238v1",
      "title": "Closing the Distribution Gap in Adversarial Training for LLMs",
      "title_zh": "å¼¥åˆå¤§è¯­è¨€æ¨¡å‹å¯¹æŠ—è®­ç»ƒä¸­çš„åˆ†å¸ƒå·®è·",
      "authors": [
        "Chengzhi Hu",
        "Jonas Dornbusch",
        "David LÃ¼dke",
        "Stephan GÃ¼nnemann",
        "Leo Schwinn"
      ],
      "abstract": "Adversarial training for LLMs is one of the most promising methods to reliably improve robustness against adversaries. However, despite significant progress, models remain vulnerable to simple in-distribution exploits, such as rewriting prompts in the past tense or translating them into other languages. We argue that this persistent fragility stems from a fundamental limitation in current adversarial training algorithms: they minimize adversarial loss on their training set but inadequately cover the data distribution, resulting in vulnerability to seemingly simple attacks. To bridge this gap, we propose Distributional Adversarial Training, DAT. We leverage Diffusion LLMs to approximate the true joint distribution of prompts and responses, enabling generation of diverse, high-likelihood samples that address generalization failures. By combining optimization over the data distribution provided by the diffusion model with continuous adversarial training, DAT achieves substantially higher adversarial robustness than previous methods.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†åˆ†å¸ƒå¯¹æŠ—è®­ç»ƒ (Distributional Adversarial Training, DAT)ï¼Œæ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨å¯¹æŠ—è®­ç»ƒä¸­å› æ•°æ®åˆ†å¸ƒè¦†ç›–ä¸è¶³è€Œå¯¼è‡´çš„é²æ£’æ€§è„†å¼±é—®é¢˜ï¼Œä¾‹å¦‚æ¨¡å‹ä»æ˜“å—åˆ°è¿‡å»æ—¶é‡å†™æˆ–è¯­è¨€ç¿»è¯‘ç­‰ç®€å•åˆ†å¸ƒå†…æ”»å‡»çš„å½±å“ã€‚DAT åˆ©ç”¨æ‰©æ•£è¯­è¨€æ¨¡å‹ (Diffusion LLMs) æ¥è¿‘ä¼¼æç¤º (prompts) ä¸å›å¤ (responses) çš„çœŸå®è”åˆåˆ†å¸ƒï¼Œä»è€Œç”Ÿæˆå¤šæ ·åŒ–ä¸”é«˜æ¦‚ç‡çš„æ ·æœ¬æ¥åº”å¯¹æ³›åŒ–å¤±è´¥ã€‚é€šè¿‡å°†æ‰©æ•£æ¨¡å‹æä¾›çš„åˆ†å¸ƒä¼˜åŒ–ä¸æŒç»­å¯¹æŠ—è®­ç»ƒ (continuous adversarial training) ç›¸ç»“åˆï¼Œè¯¥æ–¹æ³•æœ‰æ•ˆå¼¥åˆäº†åˆ†å¸ƒé—´éš™ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDAT åœ¨å¯¹æŠ—é²æ£’æ€§æ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œä¸ºæ„å»ºæ›´å¯é ã€æ›´å…·æŠ—æ”»å‡»èƒ½åŠ›çš„è¯­è¨€æ¨¡å‹æä¾›äº†æ–°è·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15238v1",
      "published_date": "2026-02-16 22:34:52 UTC",
      "updated_date": "2026-02-16 22:34:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:46:35.933251+00:00"
    },
    {
      "arxiv_id": "2602.15222v1",
      "title": "Automatically Finding Reward Model Biases",
      "title_zh": "è‡ªåŠ¨åŒ–å‘ç°å¥–åŠ±æ¨¡å‹åè§",
      "authors": [
        "Atticus Wang",
        "IvÃ¡n Arcuschin",
        "Arthur Conmy"
      ],
      "abstract": "Reward models are central to large language model (LLM) post-training. However, past work has shown that they can reward spurious or undesirable attributes such as length, format, hallucinations, and sycophancy. In this work, we introduce and study the research problem of automatically finding reward model biases in natural language. We offer a simple approach of using an LLM to iteratively propose and refine candidate biases. Our method can recover known biases and surface novel ones: for example, we found that Skywork-V2-8B, a leading open-weight reward model, often mistakenly favors responses with redundant spacing and responses with hallucinated content. In addition, we show evidence that evolutionary iteration outperforms flat best-of-N search, and we validate the recall of our pipeline using synthetically injected biases. We hope our work contributes to further research on improving RMs through automated interpretability methods.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¦‚ä½•è‡ªåŠ¨å‘ç°å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åæœŸè®­ç»ƒä¸­å¥–åŠ±æ¨¡å‹ï¼ˆReward Modelsï¼‰å­˜åœ¨çš„åå·®é—®é¢˜ï¼Œå¦‚å¯¹é•¿åº¦ã€æ ¼å¼ã€å¹»è§‰åŠå¥‰æ‰¿è¡Œä¸ºçš„é”™è¯¯åå¥½ã€‚ä½œè€…æå‡ºäº†ä¸€ç§åˆ©ç”¨LLMè¿­ä»£ç”Ÿæˆå¹¶ä¼˜åŒ–å€™é€‰åå·®çš„æ–¹æ³•ï¼Œå¹¶è¯æ˜äº†è¿›åŒ–è¿­ä»£ï¼ˆEvolutionary Iterationï¼‰åœ¨å‘ç°åå·®æ–¹é¢çš„æ•ˆæœä¼˜äºä¼ ç»Ÿçš„Best-of-Næœç´¢ã€‚å®éªŒå‘ç°ï¼Œå³ä½¿æ˜¯é¢†å…ˆçš„å¼€æºå¥–åŠ±æ¨¡å‹Skywork-V2-8Bä¹Ÿä¼šé”™è¯¯åœ°åå¥½åŒ…å«å†—ä½™ç©ºæ ¼å’Œå¹»è§‰å†…å®¹ï¼ˆHallucinated Contentï¼‰çš„å›ç­”ã€‚é€šè¿‡åˆæˆåå·®æ³¨å…¥å®éªŒï¼Œç ”ç©¶éªŒè¯äº†è¯¥è‡ªåŠ¨åŒ–æµæ°´çº¿çš„é«˜å¬å›ç‡ï¼Œè¯æ˜å…¶èƒ½æœ‰æ•ˆè¯†åˆ«æ¨¡å‹æ½œåœ¨çš„ç³»ç»Ÿæ€§ç¼ºé™·ã€‚è¯¥å·¥ä½œä¸ä»…æ­ç¤ºäº†ç°æœ‰æ¨¡å‹çš„æ–°å‹åå·®ï¼Œè¿˜ä¸ºé€šè¿‡è‡ªåŠ¨åŒ–å¯è§£é‡Šæ€§ï¼ˆAutomated Interpretabilityï¼‰æ‰‹æ®µæ”¹è¿›å¥–åŠ±æ¨¡å‹æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15222v1",
      "published_date": "2026-02-16 22:05:44 UTC",
      "updated_date": "2026-02-16 22:05:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:46:32.949206+00:00"
    },
    {
      "arxiv_id": "2602.15212v1",
      "title": "Secure and Energy-Efficient Wireless Agentic AI Networks",
      "title_zh": "å®‰å…¨ä¸”é«˜èƒ½æ•ˆçš„æ— çº¿æ™ºèƒ½ä½“ AI ç½‘ç»œ",
      "authors": [
        "Yuanyan Song",
        "Kezhi Wang",
        "Xinmian Xu"
      ],
      "abstract": "In this paper, we introduce a secure wireless agentic AI network comprising one supervisor AI agent and multiple other AI agents to provision quality of service (QoS) for users' reasoning tasks while ensuring confidentiality of private knowledge and reasoning outcomes. Specifically, the supervisor AI agent can dynamically assign other AI agents to participate in cooperative reasoning, while the unselected AI agents act as friendly jammers to degrade the eavesdropper's interception performance. To extend the service duration of AI agents, an energy minimization problem is formulated that jointly optimizes AI agent selection, base station (BS) beamforming, and AI agent transmission power, subject to latency and reasoning accuracy constraints. To address the formulated problem, we propose two resource allocation schemes, ASC and LAW, which first decompose it into three sub-problems. Specifically, ASC optimizes each sub-problem iteratively using the proposed alternating direction method of multipliers (ADMM)-based algorithm, semi-definite relaxation (SDR), and successive convex approximation (SCA), while LAW tackles each sub-problem using the proposed large language model (LLM) optimizer within an agentic workflow. The experimental results show that the proposed solutions can reduce network energy consumption by up to 59.1% compared to other benchmark schemes. Furthermore, the proposed schemes are validated using a practical agentic AI system based on Qwen, demonstrating satisfactory reasoning accuracy across various public benchmarks.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼•å…¥äº†ä¸€ç§å®‰å…¨ä¸”èŠ‚èƒ½çš„æ— çº¿æ™ºèƒ½ä½“AIç½‘ç»œ (Wireless Agentic AI Networks)ï¼Œç”±ä¸€ä¸ªä¸»ç®¡AIæ™ºèƒ½ä½“ (Supervisor AI Agent) å’Œå¤šä¸ªåä½œAIæ™ºèƒ½ä½“ç»„æˆï¼Œæ—¨åœ¨ä¸ºç”¨æˆ·æ¨ç†ä»»åŠ¡æä¾›æœåŠ¡è´¨é‡ (QoS) ä¿éšœå¹¶ç¡®ä¿ç§æœ‰çŸ¥è¯†çš„æœºå¯†æ€§ã€‚ä¸»ç®¡æ™ºèƒ½ä½“è´Ÿè´£åŠ¨æ€åˆ†é…åä½œæ™ºèƒ½ä½“è¿›è¡Œåˆä½œæ¨ç† (Cooperative Reasoning)ï¼Œè€Œæœªè¢«é€‰ä¸­çš„æ™ºèƒ½ä½“åˆ™å……å½“å‹å¥½å¹²æ‰°å™¨ (Friendly Jammers) ä»¥æŠ‘åˆ¶çªƒå¬ã€‚ä¸ºäº†å»¶é•¿æœåŠ¡æ—¶é—´ï¼Œç ”ç©¶é€šè¿‡è”åˆä¼˜åŒ–æ™ºèƒ½ä½“é€‰æ‹©ã€åŸºç«™æ³¢æŸæˆå½¢ (BS Beamforming) å’Œä¼ è¾“åŠŸç‡ï¼Œæ„å»ºäº†å—å»¶è¿Ÿå’Œæ¨ç†å‡†ç¡®æ€§çº¦æŸçš„èƒ½é‡æœ€å°åŒ–é—®é¢˜ã€‚æ–‡ç« æå‡ºäº†ä¸¤ç§èµ„æºåˆ†é…æ–¹æ¡ˆï¼šåŸºäºADMMã€SDRå’ŒSCAè¿­ä»£ä¼˜åŒ–çš„ASCæ–¹æ¡ˆï¼Œä»¥åŠåœ¨æ™ºèƒ½ä½“å·¥ä½œæµ (Agentic Workflow) ä¸­åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ (LLM) ä¼˜åŒ–å™¨çš„LAWæ–¹æ¡ˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ¡ˆç›¸æ¯”åŸºå‡†æ–¹æ¡ˆå¯é™ä½é«˜è¾¾59.1%çš„ç½‘ç»œèƒ½è€—ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶åœ¨åŸºäºé€šä¹‰åƒé—® (Qwen) çš„å®é™…ç³»ç»Ÿä¸­éªŒè¯äº†å…¶æœ‰æ•ˆæ€§ï¼Œå¹¶åœ¨å¤šä¸ªå…¬å¼€åŸºå‡†æµ‹è¯•ä¸­ä¿æŒäº†å‡ºè‰²çš„æ¨ç†å‡†ç¡®æ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Submitted to journal",
      "pdf_url": "https://arxiv.org/pdf/2602.15212v1",
      "published_date": "2026-02-16 21:42:33 UTC",
      "updated_date": "2026-02-16 21:42:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:46:43.938116+00:00"
    },
    {
      "arxiv_id": "2602.15206v1",
      "title": "MAVRL: Learning Reward Functions from Multiple Feedback Types with Amortized Variational Inference",
      "title_zh": "MAVRLï¼šåŸºäºæ‘Šé”€å˜åˆ†æ¨ç†çš„å¤šåé¦ˆç±»å‹å¥–åŠ±å‡½æ•°å­¦ä¹ ",
      "authors": [
        "RaphaÃ«l Baur",
        "Yannick Metz",
        "Maria Gkoulta",
        "Mennatallah El-Assady",
        "Giorgia Ramponi",
        "Thomas Kleine Buening"
      ],
      "abstract": "Reward learning typically relies on a single feedback type or combines multiple feedback types using manually weighted loss terms. Currently, it remains unclear how to jointly learn reward functions from heterogeneous feedback types such as demonstrations, comparisons, ratings, and stops that provide qualitatively different signals. We address this challenge by formulating reward learning from multiple feedback types as Bayesian inference over a shared latent reward function, where each feedback type contributes information through an explicit likelihood. We introduce a scalable amortized variational inference approach that learns a shared reward encoder and feedback-specific likelihood decoders and is trained by optimizing a single evidence lower bound. Our approach avoids reducing feedback to a common intermediate representation and eliminates the need for manual loss balancing. Across discrete and continuous-control benchmarks, we show that jointly inferred reward posteriors outperform single-type baselines, exploit complementary information across feedback types, and yield policies that are more robust to environment perturbations. The inferred reward uncertainty further provides interpretable signals for analyzing model confidence and consistency across feedback types.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¥–åŠ±å­¦ä¹ (Reward learning)ä¸­å¼‚æ„åé¦ˆä¿¡å·æ•´åˆå›°éš¾çš„é—®é¢˜ï¼Œæå‡ºäº†MAVRLæ¡†æ¶ã€‚è¯¥æ¡†æ¶å°†æ¼”ç¤º(Demonstrations)ã€æ¯”è¾ƒ(Comparisons)ã€è¯„åˆ†(Ratings)å’Œåœæ­¢(Stops)ç­‰å¤šç§åé¦ˆç±»å‹çš„å¥–åŠ±å­¦ä¹ å»ºæ¨¡ä¸ºå¯¹å…±äº«æ½œåœ¨å¥–åŠ±å‡½æ•°çš„è´å¶æ–¯æ¨ç†(Bayesian inference)ã€‚MAVRLé‡‡ç”¨äº†å¯æ‰©å±•çš„æ‘Šé”€å˜åˆ†æ¨ç†(Amortized variational inference)æŠ€æœ¯ï¼Œé€šè¿‡å…±äº«å¥–åŠ±ç¼–ç å™¨(Reward encoder)å’Œåé¦ˆç‰¹å®šçš„ä¼¼ç„¶è§£ç å™¨(Likelihood decoders)æ¥ä¼˜åŒ–ç»Ÿä¸€çš„è¯æ®ä¸‹ç•Œã€‚è¿™ç§æ–¹æ³•æœ‰æ•ˆåœ°é¿å…äº†å°†å„ç±»åé¦ˆå¼ºåˆ¶æ˜ å°„ä¸ºç»Ÿä¸€ä¸­é—´è¡¨ç¤ºï¼Œå¹¶æ¶ˆé™¤äº†ç¹ççš„æ‰‹åŠ¨æŸå¤±å¹³è¡¡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMAVRLåœ¨ç¦»æ•£å’Œè¿ç»­æ§åˆ¶ä»»åŠ¡ä¸­å‡ä¼˜äºå•ä¸€åé¦ˆåŸºçº¿ï¼Œèƒ½å¤Ÿå……åˆ†åˆ©ç”¨åé¦ˆé—´çš„äº’è¡¥ä¿¡æ¯ï¼Œå¹¶æé«˜ç­–ç•¥åœ¨ç¯å¢ƒæ‰°åŠ¨ä¸‹çš„ç¨³å¥æ€§ã€‚æ¨æ–­å‡ºçš„å¥–åŠ±ä¸ç¡®å®šæ€§(Reward uncertainty)è¿˜ä¸ºåˆ†ææ¨¡å‹åœ¨ä¸åŒåé¦ˆæºä¹‹é—´çš„ä¸€è‡´æ€§æä¾›äº†å…·æœ‰è§£é‡Šæ€§çš„åº¦é‡ä¾æ®ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "25 pages, 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.15206v1",
      "published_date": "2026-02-16 21:36:28 UTC",
      "updated_date": "2026-02-16 21:36:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:47:48.834763+00:00"
    },
    {
      "arxiv_id": "2602.15202v1",
      "title": "Tomography by Design: An Algebraic Approach to Low-Rank Quantum States",
      "title_zh": "è®¾è®¡å¼å±‚æï¼šä½ç§©é‡å­æ€çš„ä»£æ•°æ–¹æ³•",
      "authors": [
        "Shakir Showkat Sofi",
        "Charlotte Vermeylen",
        "Lieven De Lathauwer"
      ],
      "abstract": "We present an algebraic algorithm for quantum state tomography that leverages measurements of certain observables to estimate structured entries of the underlying density matrix. Under low-rank assumptions, the remaining entries can be obtained solely using standard numerical linear algebra operations. The proposed algebraic matrix completion framework applies to a broad class of generic, low-rank mixed quantum states and, compared with state-of-the-art methods, is computationally efficient while providing deterministic recovery guarantees.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§é’ˆå¯¹ä½ç§©é‡å­æ€å±‚æ (Quantum State Tomography) çš„ä»£æ•°ç®—æ³• (Algebraic Algorithm)ï¼Œæ—¨åœ¨é€šè¿‡ä»£æ•°æ–¹æ³•é«˜æ•ˆè¡¨å¾ç»“æ„åŒ–é‡å­ç³»ç»Ÿã€‚è¯¥æ–¹æ³•åˆ©ç”¨å¯¹ç‰¹å®šå¯è§‚æµ‹é‡ (Observables) çš„æµ‹é‡æ¥ä¼°è®¡åº•å±‚å¯†åº¦çŸ©é˜µ (Density Matrix) çš„ç»“æ„åŒ–æ¡ç›®ã€‚åœ¨ä½ç§© (Low-rank) å‡è®¾çš„å‰æä¸‹ï¼Œå¯†åº¦çŸ©é˜µçš„å‰©ä½™æ¡ç›®å¯ä»¥å®Œå…¨é€šè¿‡æ ‡å‡†çš„æ•°å€¼çº¿æ€§ä»£æ•°è¿ç®—è·å¾—ã€‚è¿™ä¸€æå‡ºçš„ä»£æ•°çŸ©é˜µè¡¥å…¨ (Algebraic Matrix Completion) æ¡†æ¶é€‚ç”¨äºä¸€ç±»å¹¿æ³›çš„é€šç”¨ä½ç§©æ··åˆé‡å­æ€ (Mixed Quantum States)ã€‚ä¸ç°æœ‰çš„å…ˆè¿›æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥ç®—æ³•åœ¨ä¿è¯è®¡ç®—æ•ˆç‡çš„åŒæ—¶ï¼Œè¿˜æä¾›äº†ç¡®å®šæ€§çš„æ¢å¤ä¿è¯ (Deterministic Recovery Guarantees)ã€‚è¯¥ç ”ç©¶ä¸ºå®ç°å¤§è§„æ¨¡é‡å­ç³»ç»Ÿçš„ç²¾ç¡®é‡å»ºæä¾›äº†ä¸€ç§ç¨³å¥ä¸”å…·æœ‰æ•°å­¦ä¿éšœçš„ä»£æ•°å¤„ç†æ–¹æ¡ˆã€‚",
      "categories": [
        "quant-ph",
        "cs.AI",
        "eess.SP",
        "math.NA",
        "stat.CO"
      ],
      "primary_category": "quant-ph",
      "comment": "5 pages, Submitted to EUSIPCO2026",
      "pdf_url": "https://arxiv.org/pdf/2602.15202v1",
      "published_date": "2026-02-16 21:31:47 UTC",
      "updated_date": "2026-02-16 21:31:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:47:10.778172+00:00"
    },
    {
      "arxiv_id": "2602.15198v1",
      "title": "Colosseum: Auditing Collusion in Cooperative Multi-Agent Systems",
      "title_zh": "Colosseumï¼šåä½œå¼å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­çš„åˆè°‹å®¡è®¡",
      "authors": [
        "Mason Nakamura",
        "Abhinav Kumar",
        "Saswat Das",
        "Sahar Abdelnabi",
        "Saaduddin Mahmud",
        "Ferdinando Fioretto",
        "Shlomo Zilberstein",
        "Eugene Bagdasarian"
      ],
      "abstract": "Multi-agent systems, where LLM agents communicate through free-form language, enable sophisticated coordination for solving complex cooperative tasks. This surfaces a unique safety problem when individual agents form a coalition and \\emph{collude} to pursue secondary goals and degrade the joint objective. In this paper, we present Colosseum, a framework for auditing LLM agents' collusive behavior in multi-agent settings. We ground how agents cooperate through a Distributed Constraint Optimization Problem (DCOP) and measure collusion via regret relative to the cooperative optimum. Colosseum tests each LLM for collusion under different objectives, persuasion tactics, and network topologies. Through our audit, we show that most out-of-the-box models exhibited a propensity to collude when a secret communication channel was artificially formed. Furthermore, we discover ``collusion on paper'' when agents plan to collude in text but would often pick non-collusive actions, thus providing little effect on the joint task. Colosseum provides a new way to study collusion by measuring communications and actions in rich yet verifiable environments.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Colosseumï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºå®¡è®¡åä½œå¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLM agentsï¼‰åˆè°‹ï¼ˆcollusionï¼‰è¡Œä¸ºçš„æ¡†æ¶ã€‚é’ˆå¯¹æ™ºèƒ½ä½“å¯èƒ½é€šè¿‡è‡ªç”±è¯­è¨€é€šä¿¡å½¢æˆç§ä¸‹è”ç›Ÿå¹¶æŸå®³å…±åŒç›®æ ‡çš„å®‰å…¨éšæ‚£ï¼Œç ”ç©¶è€…å°†åä½œè¿‡ç¨‹å»ºæ¨¡ä¸ºåˆ†å¸ƒå¼çº¦æŸä¼˜åŒ–é—®é¢˜ï¼ˆDCOPï¼‰ã€‚Colosseum é€šè¿‡ç›¸å¯¹äºåä½œæœ€ä¼˜è§£çš„é—æ†¾å€¼ï¼ˆregretï¼‰æ¥é‡åŒ–åˆè°‹ç¨‹åº¦ï¼Œå¹¶åœ¨å¤šç§ç›®æ ‡ã€è¯´æœç­–ç•¥å’Œç½‘ç»œæ‹“æ‰‘ä¸‹å¯¹ LLM è¿›è¡Œå…¨é¢å®¡è®¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå¤§å¤šæ•°ç°æœ‰çš„æ¨¡å‹åœ¨å…·å¤‡ç§˜å¯†é€šä¿¡é€šé“æ—¶å‡è¡¨ç°å‡ºåˆè°‹å€¾å‘ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜æ­ç¤ºäº†â€œçº¸é¢åˆè°‹â€ï¼ˆcollusion on paperï¼‰ç°è±¡ï¼Œå³æ™ºèƒ½ä½“è™½åœ¨æ–‡æœ¬è®¡åˆ’ä¸­è¾¾æˆåˆè°‹æ„å›¾ï¼Œä½†åœ¨æ‰§è¡Œé˜¶æ®µå¾€å¾€ä¼šé€‰æ‹©éåˆè°‹è¡ŒåŠ¨ã€‚Colosseum ä¸ºåœ¨å¯éªŒè¯ç¯å¢ƒä¸­è¯„ä¼°å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„é€šä¿¡ä¸å®‰å…¨é£é™©æä¾›äº†é‡è¦çš„ç ”ç©¶å·¥å…·å’Œæ–¹æ³•ã€‚",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15198v1",
      "published_date": "2026-02-16 21:27:38 UTC",
      "updated_date": "2026-02-16 21:27:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:48:04.837243+00:00"
    },
    {
      "arxiv_id": "2602.15197v1",
      "title": "OpaqueToolsBench: Learning Nuances of Tool Behavior Through Interaction",
      "title_zh": "OpaqueToolsBenchï¼šé€šè¿‡äº¤äº’å­¦ä¹ å·¥å…·è¡Œä¸ºçš„ç»†å¾®ç‰¹å¾",
      "authors": [
        "Skyler Hallinan",
        "Thejas Venkatesh",
        "Xiang Ren",
        "Sai Praneeth Karimireddy",
        "Ashwin Paranjape",
        "Yuhao Zhang",
        "Jack Hessel"
      ],
      "abstract": "Tool-calling is essential for Large Language Model (LLM) agents to complete real-world tasks. While most existing benchmarks assume simple, perfectly documented tools, real-world tools (e.g., general \"search\" APIs) are often opaque, lacking clear best practices or failure modes. Can LLM agents improve their performance in environments with opaque tools by interacting and subsequently improving documentation? To study this, we create OpaqueToolsBench, a benchmark consisting of three distinct task-oriented environments: general function calling, interactive chess playing, and long-trajectory agentic search. Each environment provides underspecified tools that models must learn to use effectively to complete the task. Results on OpaqueToolsBench suggest existing methods for automatically documenting tools are expensive and unreliable when tools are opaque. To address this, we propose a simple framework, ToolObserver, that iteratively refines tool documentation by observing execution feedback from tool-calling trajectories. Our approach outperforms existing methods on OpaqueToolsBench across datasets, even in relatively hard settings. Furthermore, for test-time tool exploration settings, our method is also efficient, consuming 3.5-7.5x fewer total tokens than the best baseline.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨è°ƒç”¨â€œä¸é€æ˜â€å·¥å…·ï¼ˆå¦‚ç¼ºå°‘æœ€ä½³å®è·µæˆ–æ•…éšœæ¨¡å¼è¯´æ˜çš„APIï¼‰æ—¶é¢ä¸´çš„æŒ‘æˆ˜ï¼Œå¹¶æå‡ºäº†OpaqueToolsBenchåŸºå‡†æµ‹è¯•ã€‚è¯¥åŸºå‡†åŒ…å«é€šç”¨å‡½æ•°è°ƒç”¨(general function calling)ã€äº¤äº’å¼å›½é™…è±¡æ£‹(interactive chess playing)å’Œé•¿è½¨è¿¹æ™ºèƒ½ä½“æœç´¢(long-trajectory agentic search)ä¸‰ä¸ªä»»åŠ¡ç¯å¢ƒï¼Œè¦æ±‚æ¨¡å‹é€šè¿‡äº¤äº’å­¦ä¹ å¹¶ä¼˜åŒ–å·¥å…·ä½¿ç”¨ã€‚ç ”ç©¶æŒ‡å‡ºï¼Œç°æœ‰çš„è‡ªåŠ¨æ–‡æ¡£ç”Ÿæˆæ–¹æ³•åœ¨å¤„ç†ä¸é€æ˜å·¥å…·æ—¶æˆæœ¬é«˜æ˜‚ä¸”ä¸å¯é ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†ToolObserveræ¡†æ¶ï¼Œé€šè¿‡è§‚å¯Ÿå·¥å…·è°ƒç”¨è½¨è¿¹ä¸­çš„æ‰§è¡Œåé¦ˆæ¥è¿­ä»£å®Œå–„å·¥å…·æ–‡æ¡£ã€‚å®éªŒè¯æ˜ï¼ŒToolObserveråœ¨ä¸åŒæ•°æ®é›†ä¸‹å‡ä¼˜äºç°æœ‰åŸºçº¿æ–¹æ³•ï¼Œæ˜¾è‘—æå‡äº†ä»»åŠ¡å®Œæˆè´¨é‡ã€‚æ­¤å¤–ï¼Œåœ¨æµ‹è¯•æ—¶å·¥å…·æ¢ç´¢è¿‡ç¨‹ä¸­ï¼Œè¯¥æ–¹æ³•çš„Tokenæ¶ˆè€—é‡æ¯”æœ€ä¼˜åŸºçº¿æ¨¡å‹é™ä½äº†3.5è‡³7.5å€ï¼Œå±•ç°äº†æé«˜çš„æ•ˆç‡ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15197v1",
      "published_date": "2026-02-16 21:26:37 UTC",
      "updated_date": "2026-02-16 21:26:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:47:36.339087+00:00"
    },
    {
      "arxiv_id": "2602.15195v1",
      "title": "Weight space Detection of Backdoors in LoRA Adapters",
      "title_zh": "LoRA é€‚é…å™¨åé—¨çš„æƒé‡ç©ºé—´æ£€æµ‹",
      "authors": [
        "David Puertolas Merenciano",
        "Ekaterina Vasyagina",
        "Raghav Dixit",
        "Kevin Zhu",
        "Ruizhe Li",
        "Javier Ferrando",
        "Maheep Chaudhary"
      ],
      "abstract": "LoRA adapters let users fine-tune large language models (LLMs) efficiently. However, LoRA adapters are shared through open repositories like Hugging Face Hub \\citep{huggingface_hub_docs}, making them vulnerable to backdoor attacks. Current detection methods require running the model with test input data -- making them impractical for screening thousands of adapters where the trigger for backdoor behavior is unknown. We detect poisoned adapters by analyzing their weight matrices directly, without running the model -- making our method data-agnostic. Our method extracts simple statistics -- how concentrated the singular values are, their entropy, and the distribution shape -- and flags adapters that deviate from normal patterns. We evaluate the method on 500 LoRA adapters -- 400 clean, and 100 poisoned for Llama-3.2-3B on instruction and reasoning datasets: Alpaca, Dolly, GSM8K, ARC-Challenge, SQuADv2, NaturalQuestions, HumanEval, and GLUE dataset. We achieve 97\\% detection accuracy with less than 2\\% false positives.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº† LoRA é€‚é…å™¨åœ¨å…±äº«è¿‡ç¨‹ä¸­é¢ä¸´çš„åé—¨æ”»å‡»å¨èƒï¼ŒæŒ‡å‡ºä¼ ç»Ÿæ£€æµ‹æ–¹æ³•å› ä¾èµ–æµ‹è¯•æ•°æ®å’Œå·²çŸ¥è§¦å‘å™¨è€Œéš¾ä»¥åœ¨æµ·é‡é€‚é…å™¨ç­›æŸ¥ä¸­åº”ç”¨ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†ä¸€ç§æ•°æ®æ— å…³ (data-agnostic) çš„æ£€æµ‹æ–¹æ¡ˆï¼Œé€šè¿‡ç›´æ¥åˆ†ææƒé‡çŸ©é˜µè€Œéè¿è¡Œæ¨¡å‹æ¥è¯†åˆ«ä¸­æ¯’é€‚é…å™¨ã€‚è¯¥æ–¹æ³•ä¸»è¦æå–å¥‡å¼‚å€¼é›†ä¸­åº¦ (singular values concentration)ã€ç†µ (entropy) ä»¥åŠåˆ†å¸ƒå½¢çŠ¶ç­‰ç»Ÿè®¡ç‰¹å¾ï¼Œå¹¶æ®æ­¤æ ‡è®°åç¦»æ­£å¸¸æ¨¡å¼çš„å¼‚å¸¸é€‚é…å™¨ã€‚ç ”ç©¶åœ¨ Llama-3.2-3B æ¨¡å‹ä»¥åŠ Alpacaã€GSM8Kã€GLUE ç­‰å¤šä¸ªæŒ‡ä»¤å’Œæ¨ç†æ•°æ®é›†ä¸Šå¯¹ 500 ä¸ª LoRA é€‚é…å™¨è¿›è¡Œäº†éªŒè¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ£€æµ‹å‡†ç¡®ç‡ä¸Šè¾¾åˆ°äº† 97%ï¼Œä¸”è¯¯æŠ¥ç‡ (false positives) ä½äº 2%ã€‚è¿™ä¸€æˆæœä¸ºåœ¨ Hugging Face ç­‰å¼€æ”¾ä»“åº“ä¸­é«˜æ•ˆã€ä½æˆæœ¬åœ°ç­›æŸ¥æ½œåœ¨å®‰å…¨é£é™©æä¾›äº†æœ‰æ•ˆçš„æŠ€æœ¯æ”¯æŒã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15195v1",
      "published_date": "2026-02-16 21:20:47 UTC",
      "updated_date": "2026-02-16 21:20:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:47:44.441456+00:00"
    },
    {
      "arxiv_id": "2602.15189v1",
      "title": "ScrapeGraphAI-100k: A Large-Scale Dataset for LLM-Based Web Information Extraction",
      "title_zh": "ScrapeGraphAI-100kï¼šé¢å‘åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„ç½‘é¡µä¿¡æ¯æå–çš„å¤§è§„æ¨¡æ•°æ®é›†",
      "authors": [
        "William Brach",
        "Francesco Zuppichini",
        "Marco Vinciguerra",
        "Lorenzo Padoan"
      ],
      "abstract": "The use of large language models for web information extraction is becoming increasingly fundamental to modern web information retrieval pipelines. However, existing datasets tend to be small, synthetic or text-only, failing to capture the structural context of the web. We introduce ScrapeGraphAI-100k, a large-scale dataset comprising real-world LLM extraction events, collected via opt-in ScrapeGraphAI telemetry during Q2 and Q3 of 2025. Starting from 9M events, we deduplicate and balance by schema to produce 93,695 examples spanning diverse domains and languages. Each instance includes Markdown content, a prompt, a JSON schema, the LLM response, and complexity/validation metadata. We characterize the datasets structural diversity and its failure modes as schema complexity increases. We also provide a fine-tuning experiment showing that a small language model (1.7B) trained on a subset narrows the gap to larger baselines (30B), underscoring the datasets utility for efficient extraction. ScrapeGraphAI-100k enables fine-tuning small models, benchmarking structured extraction, and studying schema induction for web IR indexing, and is publicly available on HuggingFace.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº†ScrapeGraphAI-100kï¼Œè¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)ç½‘é¡µä¿¡æ¯æå–çš„å¤§è§„æ¨¡æ•°æ®é›†ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ•°æ®é›†è§„æ¨¡è¾ƒå°ä¸”ç¼ºä¹ç½‘é¡µç»“æ„ä¸Šä¸‹æ–‡çš„é—®é¢˜ã€‚è¯¥æ•°æ®é›†åŒ…å«é€šè¿‡ScrapeGraphAIé¥æµ‹ç³»ç»Ÿæ”¶é›†å¹¶ç»è¿‡ç­›é€‰çš„93,695ä¸ªçœŸå®æå–äº‹ä»¶ï¼Œæ¶µç›–äº†å¤šæ ·åŒ–çš„é¢†åŸŸå’Œè¯­è¨€ã€‚æ¯ä¸ªæ•°æ®å®ä¾‹å‡é›†æˆäº†Markdownå†…å®¹ã€æç¤ºè¯(prompt)ã€JSON schemaã€LLMå“åº”ä»¥åŠå¤æ‚åº¦å’ŒéªŒè¯å…ƒæ•°æ®ã€‚ç ”ç©¶æ·±å…¥åˆ†æäº†æ•°æ®é›†çš„ç»“æ„å¤šæ ·æ€§ï¼Œå¹¶æ¢è®¨äº†éšç€æ¨¡å¼(schema)å¤æ‚åº¦å¢åŠ è€Œå‡ºç°çš„å¤±æ•ˆæ¨¡å¼ã€‚å¾®è°ƒå®éªŒè¡¨æ˜ï¼Œåœ¨å­é›†ä¸Šè®­ç»ƒçš„1.7Bå°å‹è¯­è¨€æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆç¼©å°ä¸30Bå¤§å‹åŸºå‡†æ¨¡å‹çš„æ€§èƒ½å·®è·ï¼Œçªæ˜¾äº†è¯¥æ•°æ®é›†åœ¨é«˜æ•ˆæå–ä»»åŠ¡ä¸­çš„å®ç”¨ä»·å€¼ã€‚ScrapeGraphAI-100kç›®å‰å·²åœ¨HuggingFaceå…¬å¼€å‘å¸ƒï¼Œä¸ºå°å‹æ¨¡å‹å¾®è°ƒã€ç»“æ„åŒ–æå–åŸºå‡†æµ‹è¯•ä»¥åŠç½‘é¡µä¿¡æ¯æ£€ç´¢(IR)ç´¢å¼•çš„æ¨¡å¼å½’çº³ç ”ç©¶æä¾›äº†å…³é”®æ”¯æŒã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15189v1",
      "published_date": "2026-02-16 20:56:59 UTC",
      "updated_date": "2026-02-16 20:56:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:48:22.563013+00:00"
    },
    {
      "arxiv_id": "2602.15173v1",
      "title": "Mind the (DH) Gap! A Contrast in Risky Choices Between Reasoning and Conversational LLMs",
      "title_zh": "å…³æ³¨ (DH) é¸¿æ²Ÿï¼šæ¨ç†å‹ä¸å¯¹è¯å‹å¤§è¯­è¨€æ¨¡å‹åœ¨é£é™©å†³ç­–ä¸­çš„å·®å¼‚å¯¹æ¯”",
      "authors": [
        "Luise Ge",
        "Yongyan Zhang",
        "Yevgeniy Vorobeychik"
      ],
      "abstract": "The use of large language models either as decision support systems, or in agentic workflows, is rapidly transforming the digital ecosystem. However, the understanding of LLM decision-making under uncertainty remains limited. We initiate a comparative study of LLM risky choices along two dimensions: (1) prospect representation (explicit vs. experience based) and (2) decision rationale (explanation). Our study, which involves 20 frontier and open LLMs, is complemented by a matched human subjects experiment, which provides one reference point, while an expected payoff maximizing rational agent model provides another. We find that LLMs cluster into two categories: reasoning models (RMs) and conversational models (CMs). RMs tend towards rational behavior, are insensitive to the order of prospects, gain/loss framing, and explanations, and behave similarly whether prospects are explicit or presented via experience history. CMs are significantly less rational, slightly more human-like, sensitive to prospect ordering, framing, and explanation, and exhibit a large description-history gap. Paired comparisons of open LLMs suggest that a key factor differentiating RMs and CMs is training for mathematical reasoning.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨ä¸ç¡®å®šæ€§ä¸‹çš„é£é™©å†³ç­–è¡Œä¸ºè¿›è¡Œäº†å¯¹æ¯”ç ”ç©¶ï¼Œä»å‰æ™¯è¡¨å¾ (prospect representation) å’Œå†³ç­–ä¾æ® (decision rationale) ä¸¤ä¸ªç»´åº¦è¯„ä¼°äº† 20 ç§å‰æ²¿åŠå¼€æºæ¨¡å‹ã€‚å®éªŒé€šè¿‡å¯¹æ¯”äººç±»å—è¯•è€…å’Œç†æ€§ä»£ç†æ¨¡å‹ï¼Œå‘ç° LLMs æ˜æ˜¾åˆ†ä¸ºæ¨ç†æ¨¡å‹ (Reasoning Models, RMs) å’Œå¯¹è¯æ¨¡å‹ (Conversational Models, CMs) ä¸¤å¤§é›†ç¾¤ã€‚æ¨ç†æ¨¡å‹å€¾å‘äºç†æ€§è¡Œä¸ºï¼Œå¯¹é€‰é¡¹é¡ºåºã€æ¡†æ¶æ•ˆåº” (framing) åŠè§£é‡Šä¸æ•æ„Ÿï¼Œä¸”åœ¨æ˜¾å¼æè¿°å’Œç»éªŒå†å²ä¸‹è¡¨ç°ä¸€è‡´ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œå¯¹è¯æ¨¡å‹çš„ç†æ€§ç¨‹åº¦è¾ƒä½ï¼Œè¡¨ç°å‡ºæ›´æ¥è¿‘äººç±»çš„å±€é™æ€§ï¼Œå¯¹æ¡†æ¶å’Œè§£é‡Šé«˜åº¦æ•æ„Ÿï¼Œå¹¶å­˜åœ¨æ˜¾è‘—çš„æè¿°-å†å²å·®è· (description-history gap)ã€‚ç ”ç©¶æœ€åæŒ‡å‡ºï¼Œæ•°å­¦æ¨ç† (mathematical reasoning) æ–¹é¢çš„è®­ç»ƒæ˜¯å¯¼è‡´è¿™ä¸¤ç±»æ¨¡å‹åœ¨é£é™©å†³ç­–ä¸­äº§ç”Ÿæ˜¾è‘—å·®å¼‚çš„å…³é”®å› ç´ ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15173v1",
      "published_date": "2026-02-16 20:24:54 UTC",
      "updated_date": "2026-02-16 20:24:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:48:33.937717+00:00"
    },
    {
      "arxiv_id": "2602.15161v1",
      "title": "Exploiting Layer-Specific Vulnerabilities to Backdoor Attack in Federated Learning",
      "title_zh": "åˆ©ç”¨å±‚ç‰¹å¼‚æ€§æ¼æ´çš„è”é‚¦å­¦ä¹ åé—¨æ”»å‡»",
      "authors": [
        "Mohammad Hadi Foroughi",
        "Seyed Hamed Rastegar",
        "Mohammad Sabokrou",
        "Ahmad Khonsari"
      ],
      "abstract": "Federated learning (FL) enables distributed model training across edge devices while preserving data locality. This decentralized approach has emerged as a promising solution for collaborative learning on sensitive user data, effectively addressing the longstanding privacy concerns inherent in centralized systems. However, the decentralized nature of FL exposes new security vulnerabilities, especially backdoor attacks that threaten model integrity. To investigate this critical concern, this paper presents the Layer Smoothing Attack (LSA), a novel backdoor attack that exploits layer-specific vulnerabilities in neural networks. First, a Layer Substitution Analysis methodology systematically identifies backdoor-critical (BC) layers that contribute most significantly to backdoor success. Subsequently, LSA strategically manipulates these BC layers to inject persistent backdoors while remaining undetected by state-of-the-art defense mechanisms. Extensive experiments across diverse model architectures and datasets demonstrate that LSA achieves a remarkably backdoor success rate of up to 97% while maintaining high model accuracy on the primary task, consistently bypassing modern FL defenses. These findings uncover fundamental vulnerabilities in current FL security frameworks, demonstrating that future defenses must incorporate layer-aware detection and mitigation strategies.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è”é‚¦å­¦ä¹  (Federated Learning) çš„å®‰å…¨éšæ‚£ï¼Œæå‡ºäº†ä¸€ç§åä¸ºå±‚å¹³æ»‘æ”»å‡» (Layer Smoothing Attack, LSA) çš„æ–°å‹åé—¨æ”»å‡»ï¼Œæ—¨åœ¨åˆ©ç”¨ç¥ç»ç½‘ç»œä¸­çš„å±‚ç‰¹å®šæ¼æ´è¿›è¡Œæ¸—é€ã€‚ç ”ç©¶é¦–å…ˆåˆ©ç”¨å±‚æ›¿æ¢åˆ†æ (Layer Substitution Analysis) æ–¹æ³•ç³»ç»Ÿåœ°è¯†åˆ«å‡ºå¯¹åé—¨æˆåŠŸè´¡çŒ®æœ€å¤§çš„åé—¨å…³é”®å±‚ (backdoor-critical layers)ï¼Œéšåé€šè¿‡ç­–ç•¥æ€§æ“çºµè¿™äº›ç‰¹å®šå±‚æ¥æ³¨å…¥æŒä¹…åé—¨å¹¶é€ƒé¿æ£€æµ‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒLSA åœ¨å¤šç§æ¨¡å‹æ¶æ„å’Œæ•°æ®é›†ä¸Šå®ç°äº†é«˜è¾¾ 97% çš„åé—¨æˆåŠŸç‡ï¼ŒåŒæ—¶èƒ½ä¿æŒä¸»ä»»åŠ¡çš„é«˜å‡†ç¡®ç‡å¹¶æœ‰æ•ˆç»•è¿‡ç°æœ‰çš„å…ˆè¿›é˜²å¾¡æœºåˆ¶ã€‚è¯¥å‘ç°æ­ç¤ºäº†å½“å‰è”é‚¦å­¦ä¹ å®‰å…¨æ¡†æ¶åœ¨å±‚çº§é˜²å¾¡ä¸Šçš„å±€é™æ€§ï¼Œå¼ºè°ƒäº†æœªæ¥çš„å®‰å…¨ç­–ç•¥å¿…é¡»æ•´åˆå±‚æ„ŸçŸ¥ (layer-aware) çš„æ£€æµ‹ä¸ç¼“è§£æ‰‹æ®µã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "This paper has been accepted for publication in IEEE ICC 2026",
      "pdf_url": "https://arxiv.org/pdf/2602.15161v1",
      "published_date": "2026-02-16 19:59:53 UTC",
      "updated_date": "2026-02-16 19:59:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:48:35.436147+00:00"
    },
    {
      "arxiv_id": "2602.15158v1",
      "title": "da Costa and Tarski meet Goguen and Carnap: a novel approach for ontological heterogeneity based on consequence systems",
      "title_zh": "da Costa ä¸ Tarski é‡è§ Goguen ä¸ Carnapï¼šä¸€ç§åŸºäºæ¨è®ºç³»ç»Ÿçš„æœ¬ä½“å¼‚è´¨æ€§æ–°æ–¹æ³•",
      "authors": [
        "Gabriel Rocha"
      ],
      "abstract": "This paper presents a novel approach for ontological heterogeneity that draws heavily from Carnapian-Goguenism, as presented by Kutz, Mossakowski and LÃ¼cke (2010). The approach is provisionally designated da Costian-Tarskianism, named after da Costa's Principle of Tolerance in Mathematics and after Alfred Tarski's work on the concept of a consequence operator. The approach is based on the machinery of consequence systems, as developed by Carnielli et al. (2008) and Citkin and Muravitsky (2022), and it introduces the idea of an extended consequence system, which is a consequence system extended with ontological axioms. The paper also defines the concept of an extended development graph, which is a graph structure that allows ontologies to be related via morphisms of extended consequence systems, and additionally via other operations such as fibring and splitting. Finally, we discuss the implications of this approach for the field of applied ontology and suggest directions for future research.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸º da Costian-Tarskianism çš„æ–°é¢–æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³æœ¬ä½“å¼‚æ„æ€§ (ontological heterogeneity) é—®é¢˜ï¼Œè¯¥æ–¹æ³•æ·±å— Carnapian-Goguenism ç†è®ºçš„å¯å‘ã€‚è¯¥æ–¹æ¡ˆåŸºäºç»“æœç³»ç»Ÿ (consequence systems) çš„æœºåˆ¶ï¼Œå¹¶å¼•å…¥äº†æ‰©å±•ç»“æœç³»ç»Ÿ (extended consequence system) çš„æ¦‚å¿µï¼Œå³åœ¨ç»“æœç³»ç»Ÿä¸­åŠ å…¥æœ¬ä½“å…¬ç† (ontological axioms)ã€‚æ–‡ä¸­å®šä¹‰äº†æ‰©å±•å¼€å‘å›¾ (extended development graph) è¿™ä¸€å›¾å½¢ç»“æ„ï¼Œå…è®¸é€šè¿‡æ‰©å±•ç»“æœç³»ç»Ÿçš„æ€å°„ (morphisms) ä»¥åŠçº¤ç»´åŒ– (fibring) å’Œæ‹†åˆ† (splitting) ç­‰æ“ä½œæ¥å…³è”ä¸åŒçš„æœ¬ä½“ã€‚é€šè¿‡æ•´åˆ Newton da Costa çš„æ•°å­¦å®¹å¿åŸåˆ™å’Œ Alfred Tarski çš„ç»“æœç®—å­æ¦‚å¿µï¼Œè¯¥ç ”ç©¶ä¸ºå¤„ç†å¤æ‚æœ¬ä½“å…³ç³»æä¾›äº†æ–°çš„å½¢å¼åŒ–æ¡†æ¶ã€‚æœ€åï¼Œæ–‡ç« æ¢è®¨äº†è¯¥æ–¹æ³•å¯¹åº”ç”¨æœ¬ä½“ (applied ontology) é¢†åŸŸçš„æ„ä¹‰ï¼Œå¹¶ä¸ºå®ç°æ›´çµæ´»çš„è¯­ä¹‰äº’æ“ä½œæ€§æŒ‡æ˜äº†æœªæ¥ç ”ç©¶æ–¹å‘ã€‚",
      "categories": [
        "cs.AI",
        "cs.IR",
        "math.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "22 pages, 5 figures, 1 table",
      "pdf_url": "https://arxiv.org/pdf/2602.15158v1",
      "published_date": "2026-02-16 19:58:35 UTC",
      "updated_date": "2026-02-16 19:58:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:48:31.243736+00:00"
    },
    {
      "arxiv_id": "2602.15156v1",
      "title": "Panini: Continual Learning in Token Space via Structured Memory",
      "title_zh": "Paniniï¼šåŸºäºç»“æ„åŒ–è®°å¿†çš„ Token ç©ºé—´æŒç»­å­¦ä¹ ",
      "authors": [
        "Shreyas Rajesh",
        "Pavan Holur",
        "Mehmet Yigit Turali",
        "Chenda Duan",
        "Vwani Roychowdhury"
      ],
      "abstract": "Language models are increasingly used to reason over content they were not trained on, such as new documents, evolving knowledge, and user-specific data. A common approach is retrieval-augmented generation (RAG), which stores verbatim documents externally (as chunks) and retrieves only a relevant subset at inference time for an LLM to reason over. However, this results in inefficient usage of test-time compute (LLM repeatedly reasons over the same documents); moreover, chunk retrieval can inject irrelevant context that increases unsupported generation. We propose a human-like non-parametric continual learning framework, where the base model remains fixed, and learning occurs by integrating each new experience into an external semantic memory state that accumulates and consolidates itself continually. We present Panini, which realizes this by representing documents as Generative Semantic Workspaces (GSW) -- an entity- and event-aware network of question-answer (QA) pairs, sufficient for an LLM to reconstruct the experienced situations and mine latent knowledge via reasoning-grounded inference chains on the network. Given a query, Panini only traverses the continually-updated GSW (not the verbatim documents or chunks), and retrieves the most likely inference chains. Across six QA benchmarks, Panini achieves the highest average performance, 5%-7% higher than other competitive baselines, while using 2-30x fewer answer-context tokens, supports fully open-source pipelines, and reduces unsupported answers on curated unanswerable queries. The results show that efficient and accurate structuring of experiences at write time -- as achieved by the GSW framework -- yields both efficiency and reliability gains at read time. Code is available at https://github.com/roychowdhuryresearch/gsw-memory.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Paniniï¼Œä¸€ç§åŸºäºç»“æ„åŒ–å­˜å‚¨çš„éå‚æ•°åŒ–æŒç»­å­¦ä¹ (Continual Learning)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³æ£€ç´¢å¢å¼ºç”ŸæˆæŠ€æœ¯(RAG)åœ¨å¤„ç†æ–°æ–‡æ¡£å’ŒåŠ¨æ€çŸ¥è¯†æ—¶å­˜åœ¨çš„æ¨ç†æ•ˆç‡ä½ä¸‹åŠæ— å…³ä¸Šä¸‹æ–‡å¹²æ‰°ç­‰é—®é¢˜ã€‚è¯¥æ¡†æ¶å°†æ–‡æ¡£è¡¨ç¤ºä¸ºç”Ÿæˆå¼è¯­ä¹‰å·¥ä½œç©ºé—´(Generative Semantic Workspaces, GSW)ï¼Œå³ä¸€ä¸ªç”±å®ä½“å’Œäº‹ä»¶æ„ŸçŸ¥çš„é—®ç­”(QA)å¯¹æ„æˆçš„ç½‘ç»œï¼Œä½¿å¤§è¯­è¨€æ¨¡å‹(LLM)èƒ½å¤Ÿé€šè¿‡æ¨ç†é”šå®šçš„æ¨æ–­é“¾é‡å»ºåœºæ™¯å¹¶æŒ–æ˜æ½œåœ¨çŸ¥è¯†ã€‚åœ¨æ¨ç†é˜¶æ®µï¼ŒPaniniä»…éœ€éå†æŒç»­æ›´æ–°çš„GSWè€ŒéåŸå§‹æ–‡æ¡£å—ï¼Œä»è€Œæ˜¾è‘—å‡å°‘äº†æµ‹è¯•æ—¶çš„è®¡ç®—æ¶ˆè€—ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒPaniniåœ¨å…­é¡¹é—®ç­”åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜äºç«äº‰åŸºçº¿æ¨¡å‹ï¼Œå‡†ç¡®ç‡æå‡5%-7%ï¼ŒåŒæ—¶å‡å°‘äº†2-30å€çš„ä¸Šä¸‹æ–‡Tokenæ¶ˆè€—ã€‚è¯¥æ–¹æ³•è¯æ˜äº†åœ¨å†™å…¥ç«¯å¯¹ç»éªŒè¿›è¡Œé«˜æ•ˆç»“æ„åŒ–å¤„ç†ï¼Œå¯ä»¥æ˜¾è‘—æå‡è¯»å–ç«¯çš„å¯é æ€§ä¸æ•ˆç‡ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "35 pages, code available at: https://github.com/roychowdhuryresearch/gsw-memory",
      "pdf_url": "https://arxiv.org/pdf/2602.15156v1",
      "published_date": "2026-02-16 19:58:03 UTC",
      "updated_date": "2026-02-16 19:58:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:48:30.240374+00:00"
    },
    {
      "arxiv_id": "2602.15143v1",
      "title": "Protecting Language Models Against Unauthorized Distillation through Trace Rewriting",
      "title_zh": "é€šè¿‡è½¨è¿¹é‡å†™ä¿æŠ¤è¯­è¨€æ¨¡å‹å…å—æœªç»æˆæƒçš„è’¸é¦",
      "authors": [
        "Xinhang Ma",
        "William Yeoh",
        "Ning Zhang",
        "Yevgeniy Vorobeychik"
      ],
      "abstract": "Knowledge distillation is a widely adopted technique for transferring capabilities from LLMs to smaller, more efficient student models. However, unauthorized use of knowledge distillation takes unfair advantage of the considerable effort and cost put into developing frontier models. We investigate methods for modifying teacher-generated reasoning traces to achieve two objectives that deter unauthorized distillation: (1) \\emph{anti-distillation}, or degrading the training usefulness of query responses, and (2) \\emph{API watermarking}, which embeds verifiable signatures in student models. We introduce several approaches for dynamically rewriting a teacher's reasoning outputs while preserving answer correctness and semantic coherence. Two of these leverage the rewriting capabilities of LLMs, while others use gradient-based techniques. Our experiments show that a simple instruction-based rewriting approach achieves a strong anti-distillation effect while maintaining or even improving teacher performance. Furthermore, we show that our rewriting approach also enables highly reliable watermark detection with essentially no false alarms.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æœªç»æˆæƒçš„çŸ¥è¯†è’¸é¦(Knowledge distillation)é—®é¢˜ï¼Œæå‡ºäº†é€šè¿‡é‡å†™æ¨ç†è½¨è¿¹(trace rewriting)æ¥ä¿æŠ¤å¤§è¯­è¨€æ¨¡å‹çš„æ–¹æ³•ã€‚ç ”ç©¶æ—¨åœ¨å®ç°ä¸¤ä¸ªæ ¸å¿ƒç›®æ ‡ï¼šä¸€æ˜¯é€šè¿‡é™ä½æŸ¥è¯¢å“åº”çš„è®­ç»ƒä»·å€¼æ¥å®ç°åè’¸é¦(anti-distillation)ï¼ŒäºŒæ˜¯åœ¨å­¦ç”Ÿæ¨¡å‹ä¸­åµŒå…¥å¯éªŒè¯ç­¾åçš„APIæ°´å°(API watermarking)ã€‚ä½œè€…å¼€å‘äº†å¤šç§åŠ¨æ€é‡å†™æ•™å¸ˆæ¨¡å‹æ¨ç†è¾“å‡ºçš„æŠ€æœ¯ï¼ŒåŒ…æ‹¬åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(LLMs)çš„é‡å†™èƒ½åŠ›å’ŒåŸºäºæ¢¯åº¦(gradient-based)çš„æ–¹æ³•ï¼Œå¹¶åœ¨é‡å†™è¿‡ç¨‹ä¸­ç¡®ä¿äº†ç­”æ¡ˆçš„æ­£ç¡®æ€§ä¸è¯­ä¹‰è¿è´¯æ€§ã€‚å®éªŒè¯æ˜ï¼Œä¸€ç§ç®€å•çš„åŸºäºæŒ‡ä»¤çš„é‡å†™æ–¹æ³•åœ¨ç»´æŒç”šè‡³å¢å¼ºæ•™å¸ˆæ¨¡å‹æ€§èƒ½çš„åŒæ—¶ï¼Œèƒ½å¤Ÿäº§ç”Ÿæ˜¾è‘—çš„åè’¸é¦æ•ˆæœã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜æ”¯æŒæé«˜å¯é æ€§çš„æ°´å°æ£€æµ‹ï¼Œä¸”å‡ ä¹ä¸å­˜åœ¨è¯¯æŠ¥ï¼Œä¸ºä¿æŠ¤å‰æ²¿æ¨¡å‹å…å—éæ³•å‰½çªƒæä¾›äº†æœ‰æ•ˆæ‰‹æ®µã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15143v1",
      "published_date": "2026-02-16 19:40:07 UTC",
      "updated_date": "2026-02-16 19:40:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:48:46.440525+00:00"
    },
    {
      "arxiv_id": "2602.15139v1",
      "title": "CGRA-DeBERTa Concept Guided Residual Augmentation Transformer for Theologically Islamic Understanding",
      "title_zh": "CGRA-DeBERTaï¼šé¢å‘ä¼Šæ–¯å…°ç¥å­¦ç†è§£çš„æ¦‚å¿µå¼•å¯¼æ®‹å·®å¢å¼º Transformer",
      "authors": [
        "Tahir Hussain",
        "Saddam Hussain Khan"
      ],
      "abstract": "Accurate QA over classical Islamic texts remains challenging due to domain specific semantics, long context dependencies, and concept sensitive reasoning. Therefore, a new CGRA DeBERTa, a concept guided residual domain augmentation transformer framework, is proposed that enhances theological QA over Hadith corpora. The CGRA DeBERTa builds on a customized DeBERTa transformer backbone with lightweight LoRA based adaptations and a residual concept aware gating mechanism. The customized DeBERTa embedding block learns global and positional context, while Concept Guided Residual Blocks incorporate theological priors from a curated Islamic Concept Dictionary of 12 core terms. Moreover, the Concept Gating Mechanism selectively amplifies semantically critical tokens via importance weighted attention, applying differential scaling from 1.04 to 3.00. This design preserves contextual integrity, strengthens domain-specific semantic representations, and enables accurate, efficient span extraction while maintaining computational efficiency. This paper reports the results of training CGRA using a specially constructed dataset of 42591 QA pairs from the text of Sahih alBukhari and Sahih Muslim. While BERT achieved an EM score of 75.87 and DeBERTa one of 89.77, our model scored 97.85 and thus surpassed them by 8.08 on an absolute scale, all while adding approximately 8 inference overhead due to parameter efficient gating. The qualitative evaluation noted better extraction and discrimination and theological precision. This study presents Hadith QA systems that are efficient, interpretable, and accurate and that scale provide educational materials with necessary theological nuance.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¼Šæ–¯å…°ç»å…¸æ–‡æœ¬é—®ç­”ï¼ˆQAï¼‰ä¸­é¢†åŸŸè¯­ä¹‰å¤æ‚ã€é•¿ä¸Šä¸‹æ–‡ä¾èµ–å’Œæ¦‚å¿µæ•æ„Ÿæ¨ç†çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†CGRA-DeBERTaæ¡†æ¶ã€‚è¯¥æ¡†æ¶ä»¥è‡ªå®šä¹‰çš„DeBERTaä¸ºæ ¸å¿ƒï¼Œæ•´åˆäº†åŸºäºLoRAçš„è½»é‡åŒ–è‡ªé€‚åº”æŠ€æœ¯å’Œæ®‹å·®æ¦‚å¿µæ„ŸçŸ¥é—¨æ§æœºåˆ¶ï¼ˆResidual concept-aware gating mechanismï¼‰ã€‚é€šè¿‡å¼•å…¥åŒ…å«12ä¸ªæ ¸å¿ƒæœ¯è¯­çš„ä¼Šæ–¯å…°æ¦‚å¿µè¯å…¸ï¼ˆIslamic Concept Dictionaryï¼‰ï¼Œå…¶Concept Guided Residual Blocksèƒ½å¤Ÿæœ‰æ•ˆèå…¥ç¥å­¦å…ˆéªŒçŸ¥è¯†ã€‚æ­¤å¤–ï¼Œæ¦‚å¿µé—¨æ§æœºåˆ¶é€šè¿‡é‡è¦æ€§æƒé‡æ³¨æ„åŠ›å¯¹å…³é”®Tokenè¿›è¡Œå·®å¼‚åŒ–ç¼©æ”¾ï¼Œåœ¨æ˜¾è‘—æå‡é¢†åŸŸè¯­ä¹‰è¡¨è¾¾ç²¾ç¡®æ€§çš„åŒæ—¶ä»…å¢åŠ äº†çº¦8%çš„æ¨ç†å¼€é”€ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨æ¶µç›–ã€Šå¸ƒå“ˆé‡Œåœ£è®­å®å½•ã€‹å’Œã€Šç©†æ–¯æ—åœ£è®­å®å½•ã€‹çš„å¤§è§„æ¨¡æ•°æ®é›†ä¸Šï¼Œè¯¥æ¨¡å‹çš„ç²¾ç¡®åŒ¹é…ï¼ˆEMï¼‰å¾—åˆ†é«˜è¾¾97.85ï¼Œç›¸è¾ƒäºåŸºçº¿DeBERTaæå‡äº†8.08ã€‚è¿™é¡¹ç ”ç©¶ä¸ºæ„å»ºé«˜æ•ˆã€å¯è§£é‡Šä¸”å…·æœ‰ç¥å­¦ç»†å¾®å·®åˆ«çš„åœ£è®­é—®ç­”ç³»ç»Ÿæä¾›äº†åˆ›æ–°çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "24 Pages, 9 Tables, 7 Figures",
      "pdf_url": "https://arxiv.org/pdf/2602.15139v1",
      "published_date": "2026-02-16 19:36:32 UTC",
      "updated_date": "2026-02-16 19:36:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:48:57.542270+00:00"
    },
    {
      "arxiv_id": "2602.15138v1",
      "title": "MB-DSMIL-CL-PL: Scalable Weakly Supervised Ovarian Cancer Subtype Classification and Localisation Using Contrastive and Prototype Learning with Frozen Patch Features",
      "title_zh": "MB-DSMIL-CL-PLï¼šåŸºäºå¯¹æ¯”å­¦ä¹ ä¸åŸå‹å­¦ä¹ åŠå†»ç»“åˆ‡ç‰‡ç‰¹å¾çš„å¯æ‰©å±•å¼±ç›‘ç£åµå·¢ç™Œäºšå‹åˆ†ç±»ä¸å®šä½",
      "authors": [
        "Marcus Jenkins",
        "Jasenka Mazibrada",
        "Bogdan Leahu",
        "Michal Mackiewicz"
      ],
      "abstract": "The study of histopathological subtypes is valuable for the personalisation of effective treatment strategies for ovarian cancer. However, increasing diagnostic workloads present a challenge for UK pathology departments, leading to the rise in AI approaches. While traditional approaches in this field have relied on pre-computed, frozen image features, recent advances have shifted towards end-to-end feature extraction, providing an improvement in accuracy but at the expense of significantly reduced scalability during training and time-consuming experimentation. In this paper, we propose a new approach for subtype classification and localisation in ovarian cancer histopathology images using contrastive and prototype learning with pre-computed, frozen features via feature-space augmentations. Compared to DSMIL, our method achieves an improvement of 70.4\\% and 15.3\\% in F1 score for instance- and slide-level classification, respectively, along with AUC gains of 16.9\\% for instance localisation and 2.3\\% for slide classification, while maintaining the use of frozen patch features.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æå‡ºäº†MB-DSMIL-CL-PLæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³åµå·¢ç™Œç»„ç»‡ç—…ç†å­¦äºšå‹åˆ†ç±»ä¸å®šä½ä¸­ç«¯åˆ°ç«¯ç‰¹å¾æå–å¸¦æ¥çš„å¯æ‰©å±•æ€§å·®å’Œè®­ç»ƒè€—æ—¶é•¿çš„é—®é¢˜ã€‚è¯¥æ–¹æ³•åœ¨ä¿ç•™é¢„è®¡ç®—å†·å†»è¡¥ä¸ç‰¹å¾(Frozen Patch Features)çš„åŸºç¡€ä¸Šï¼Œåˆ›æ–°æ€§åœ°å¼•å…¥äº†å¯¹æ¯”å­¦ä¹ (Contrastive Learning)å’ŒåŸå‹å­¦ä¹ (Prototype Learning)ï¼Œå¹¶é€šè¿‡ç‰¹å¾ç©ºé—´å¢å¼ºæŠ€æœ¯ä¼˜åŒ–æ¨¡å‹è¡¨ç°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œä¸DSMILåŸºçº¿æ¨¡å‹ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•åœ¨å®ä¾‹çº§å’Œåˆ‡ç‰‡çº§åˆ†ç±»çš„F1åˆ†æ•°åˆ†åˆ«æå‡äº†70.4%å’Œ15.3%ï¼ŒåŒæ—¶åœ¨å®ä¾‹å®šä½çš„AUCæŒ‡æ ‡ä¸Šå–å¾—äº†16.9%çš„æ˜¾è‘—å¢é•¿ã€‚MB-DSMIL-CL-PLè¯æ˜äº†åœ¨ä¸ä¾èµ–æ˜‚è´µçš„ç«¯åˆ°ç«¯è®­ç»ƒå‰æä¸‹ï¼Œé€šè¿‡å…ˆè¿›çš„å­¦ä¹ ç­–ç•¥ä»èƒ½å®ç°é«˜ç²¾åº¦çš„å¾®è§‚ç—…ç†è¯Šæ–­ï¼Œä¸ºå¤§è§„æ¨¡å¼±ç›‘ç£åŒ»å­¦å½±åƒåˆ†ææä¾›äº†é«˜æ•ˆä¸”å¯æ‰©å±•çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15138v1",
      "published_date": "2026-02-16 19:33:33 UTC",
      "updated_date": "2026-02-16 19:33:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:48:55.449832+00:00"
    },
    {
      "arxiv_id": "2602.15128v1",
      "title": "PolyNODE: Variable-dimension Neural ODEs on M-polyfolds",
      "title_zh": "PolyNODEï¼šM-polyfolds ä¸Šçš„å¯å˜ç»´åº¦ç¥ç»å¸¸å¾®åˆ†æ–¹ç¨‹",
      "authors": [
        "Per Ã…hag",
        "Alexander Friedrich",
        "Fredrik Ohlsson",
        "Viktor Vigren NÃ¤slund"
      ],
      "abstract": "Neural ordinary differential equations (NODEs) are geometric deep learning models based on dynamical systems and flows generated by vector fields on manifolds. Despite numerous successful applications, particularly within the flow matching paradigm, all existing NODE models are fundamentally constrained to fixed-dimensional dynamics by the intrinsic nature of the manifold's dimension. In this paper, we extend NODEs to M-polyfolds (spaces that can simultaneously accommodate varying dimensions and a notion of differentiability) and introduce PolyNODEs, the first variable-dimensional flow-based model in geometric deep learning. As an example application, we construct explicit M-polyfolds featuring dimensional bottlenecks and PolyNODE autoencoders based on parametrised vector fields that traverse these bottlenecks. We demonstrate experimentally that our PolyNODE models can be trained to solve reconstruction tasks in these spaces, and that latent representations of the input can be extracted and used to solve downstream classification tasks. The code used in our experiments is publicly available at https://github.com/turbotage/PolyNODE .",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†PolyNODEï¼Œè¿™æ˜¯å‡ ä½•æ·±åº¦å­¦ä¹ (geometric deep learning)é¢†åŸŸé¦–ä¸ªåŸºäºæµ(flow-based)çš„å¯å˜ç»´æ¨¡å‹ã€‚ä¼ ç»Ÿçš„ç¥ç»å¸¸å¾®åˆ†æ–¹ç¨‹(Neural ordinary differential equations, NODEs)å—é™äºæµå½¢çš„å†…åœ¨ç»´åº¦ï¼Œé€šå¸¸åªèƒ½å¤„ç†å›ºå®šç»´åº¦çš„åŠ¨åŠ›å­¦è¿‡ç¨‹ã€‚ä¸ºäº†æ‰“ç ´è¿™ä¸€é™åˆ¶ï¼Œä½œè€…å°†NODEsæ‰©å±•åˆ°äº†èƒ½å¤ŸåŒæ—¶å®¹çº³ä¸åŒç»´åº¦ä¸”å…·å¤‡å¯å¾®æ€§çš„M-polyfoldsç©ºé—´ã€‚ç ”ç©¶é€šè¿‡æ„å»ºå…·æœ‰ç»´åº¦ç“¶é¢ˆ(dimensional bottlenecks)çš„æ˜¾å¼M-polyfoldsï¼Œå¼€å‘äº†åŸºäºå‚æ•°åŒ–å‘é‡åœºçš„PolyNODEè‡ªåŠ¨ç¼–ç å™¨ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒPolyNODEæ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆå®Œæˆé‡æ„ä»»åŠ¡ï¼Œå¹¶èƒ½æå–è¾“å…¥æ•°æ®çš„æ½œåœ¨è¡¨ç¤ºç”¨äºè§£å†³ä¸‹æ¸¸åˆ†ç±»ä»»åŠ¡ã€‚è¿™ä¸€å·¥ä½œçªç ´äº†ä¼ ç»Ÿæ¨¡å‹åœ¨å›ºå®šç»´åº¦ä¸Šçš„é™åˆ¶ï¼Œä¸ºåœ¨å˜ç»´ç©ºé—´ä¸­è¿›è¡ŒåŠ¨åŠ›å­¦ç³»ç»Ÿå»ºæ¨¡æä¾›äº†å…¨æ–°çš„å‡ ä½•æ¡†æ¶ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15128v1",
      "published_date": "2026-02-16 19:11:06 UTC",
      "updated_date": "2026-02-16 19:11:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:49:01.259730+00:00"
    },
    {
      "arxiv_id": "2602.15112v1",
      "title": "ResearchGym: Evaluating Language Model Agents on Real-World AI Research",
      "title_zh": "ResearchGymï¼šé¢å‘çœŸå®ä¸–ç•Œ AI ç ”ç©¶çš„è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“è¯„ä¼°",
      "authors": [
        "Aniketh Garikaparthi",
        "Manasi Patwardhan",
        "Arman Cohan"
      ],
      "abstract": "We introduce ResearchGym, a benchmark and execution environment for evaluating AI agents on end-to-end research. To instantiate this, we repurpose five oral and spotlight papers from ICML, ICLR, and ACL. From each paper's repository, we preserve the datasets, evaluation harness, and baseline implementations but withhold the paper's proposed method. This results in five containerized task environments comprising 39 sub-tasks in total. Within each environment, agents must propose novel hypotheses, run experiments, and attempt to surpass strong human baselines on the paper's metrics. In a controlled evaluation of an agent powered by GPT-5, we observe a sharp capability--reliability gap. The agent improves over the provided baselines from the repository in just 1 of 15 evaluations (6.7%) by 11.5%, and completes only 26.5% of sub-tasks on average. We identify recurring long-horizon failure modes, including impatience, poor time and resource management, overconfidence in weak hypotheses, difficulty coordinating parallel experiments, and hard limits from context length. Yet in a single run, the agent surpasses the solution of an ICML 2025 Spotlight task, indicating that frontier agents can occasionally reach state-of-the-art performance, but do so unreliably. We additionally evaluate proprietary agent scaffolds including Claude Code (Opus-4.5) and Codex (GPT-5.2) which display a similar gap. ResearchGym provides infrastructure for systematic evaluation and analysis of autonomous agents on closed-loop research.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† ResearchGymï¼Œä¸€ä¸ªæ—¨åœ¨è¯„ä¼° AI æ™ºèƒ½ä½“ (AI agents) ç«¯åˆ°ç«¯ (end-to-end) ç ”ç©¶èƒ½åŠ›çš„åŸºå‡†æµ‹è¯•ä¸æ‰§è¡Œç¯å¢ƒã€‚é€šè¿‡é‡æ–°åˆ©ç”¨æ¥è‡ª ICMLã€ICLR å’Œ ACL çš„äº”ç¯‡é¡¶å°–è®ºæ–‡ï¼Œè¯¥ç¯å¢ƒæ„å»ºäº† 39 ä¸ªå­ä»»åŠ¡ï¼Œè¦æ±‚æ™ºèƒ½ä½“è‡ªä¸»æå‡ºå‡è®¾ã€æ‰§è¡Œå®éªŒå¹¶å°è¯•è¶…è¶Šå¼ºäººç±»åŸºå‡†ã€‚å®éªŒè¡¨æ˜ï¼Œæ­è½½ GPT-5 çš„æ™ºèƒ½ä½“åœ¨èƒ½åŠ›ä¸å¯é æ€§ä¹‹é—´å­˜åœ¨å·¨å¤§é¸¿æ²Ÿï¼Œå¹³å‡ä»…èƒ½å®Œæˆ 26.5% çš„å­ä»»åŠ¡ï¼Œä¸”åœ¨ 15 æ¬¡è¯„ä¼°ä¸­ä»…æœ‰ä¸€æ¬¡æˆåŠŸè¶…è¶ŠåŸºå‡†ã€‚ç ”ç©¶è¯†åˆ«å‡ºæ™ºèƒ½ä½“åœ¨é•¿æœŸè§„åˆ’ã€èµ„æºç®¡ç†ã€å¹¶è¡Œå®éªŒåè°ƒä»¥åŠä¸Šä¸‹æ–‡é•¿åº¦é™åˆ¶ç­‰æ–¹é¢çš„å¤šé¡¹å¤±æ•ˆæ¨¡å¼ã€‚å°½ç®¡æ™ºèƒ½ä½“å¶å°”èƒ½è¾¾åˆ°é¡¶å°–ç ”ç©¶æ°´å¹³ï¼ˆå¦‚è¶…è¶Š ICML 2025 Spotlight ä»»åŠ¡ï¼‰ï¼Œä½†å…¶è¡¨ç°æä¸ç¨³å®šï¼Œä¸” Claude Code (Opus-4.5) å’Œ Codex (GPT-5.2) ç­‰æ¨¡å‹ä¹Ÿå‘ˆç°å‡ºç±»ä¼¼çš„å¯é æ€§é—®é¢˜ã€‚ResearchGym ä¸ºè‡ªåŠ¨åŒ–æ™ºèƒ½ä½“åœ¨é—­åˆå›è·¯ (closed-loop) ç ”ç©¶ä¸­çš„ç³»ç»Ÿæ€§è¯„ä¼°å’Œåˆ†ææä¾›äº†é‡è¦çš„åŸºç¡€è®¾æ–½ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.15112v1",
      "published_date": "2026-02-16 19:00:03 UTC",
      "updated_date": "2026-02-16 19:00:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-18T04:49:18.145305+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 110,
  "processed_papers_count": 110,
  "failed_papers_count": 0,
  "llm_backup_calls": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-02-18T04:50:20.754029+00:00"
}