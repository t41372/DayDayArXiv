[
  {
    "arxiv_id": "2411.06626v1",
    "title": "Exploring social bots: A feature-based approach to improve bot detection in social networks",
    "authors": [
      "Salvador Lopez-Joya",
      "Jose A. Diaz-Garcia",
      "M. Dolores Ruiz",
      "Maria J. Martin-Bautista"
    ],
    "abstract": "The importance of social media in our daily lives has unfortunately led to an\nincrease in the spread of misinformation, political messages and malicious\nlinks. One of the most popular ways of carrying out those activities is using\nautomated accounts, also known as bots, which makes the detection of such\naccounts a necessity. This paper addresses that problem by investigating\nfeatures based on the user account profile and its content, aiming to\nunderstand the relevance of each feature as a basis for improving future bot\ndetectors. Through an exhaustive process of research, inference and feature\nselection, we are able to surpass the state of the art on several metrics using\nclassical machine learning algorithms and identify the types of features that\nare most important in detecting automated accounts.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06626v1",
    "published_date": "2024-11-10 23:19:08 UTC",
    "updated_date": "2024-11-10 23:19:08 UTC"
  },
  {
    "arxiv_id": "2411.06624v3",
    "title": "A Review of Fairness and A Practical Guide to Selecting Context-Appropriate Fairness Metrics in Machine Learning",
    "authors": [
      "Caleb J. S. Barr",
      "Olivia Erdelyi",
      "Paul D. Docherty",
      "Randolph C. Grace"
    ],
    "abstract": "Recent regulatory proposals for artificial intelligence emphasize fairness\nrequirements for machine learning models. However, precisely defining the\nappropriate measure of fairness is challenging due to philosophical, cultural\nand political contexts. Biases can infiltrate machine learning models in\ncomplex ways depending on the model's context, rendering a single common metric\nof fairness insufficient. This ambiguity highlights the need for criteria to\nguide the selection of context-aware measures, an issue of increasing\nimportance given the proliferation of ever tighter regulatory requirements. To\naddress this, we developed a flowchart to guide the selection of contextually\nappropriate fairness measures. Twelve criteria were used to formulate the\nflowchart. This included consideration of model assessment criteria, model\nselection criteria, and data bias. We also review fairness literature in the\ncontext of machine learning and link it to core regulatory instruments to\nassist policymakers, AI developers, researchers, and other stakeholders in\nappropriately addressing fairness concerns and complying with relevant\nregulatory requirements.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "24 pages, 5 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2411.06624v3",
    "published_date": "2024-11-10 23:13:28 UTC",
    "updated_date": "2025-02-11 00:44:45 UTC"
  },
  {
    "arxiv_id": "2411.06616v1",
    "title": "MEANT: Multimodal Encoder for Antecedent Information",
    "authors": [
      "Benjamin Iyoya Irving",
      "Annika Marie Schoene"
    ],
    "abstract": "The stock market provides a rich well of information that can be split across\nmodalities, making it an ideal candidate for multimodal evaluation. Multimodal\ndata plays an increasingly important role in the development of machine\nlearning and has shown to positively impact performance. But information can do\nmore than exist across modes -- it can exist across time. How should we attend\nto temporal data that consists of multiple information types? This work\nintroduces (i) the MEANT model, a Multimodal Encoder for Antecedent information\nand (ii) a new dataset called TempStock, which consists of price, Tweets, and\ngraphical data with over a million Tweets from all of the companies in the S&P\n500 Index. We find that MEANT improves performance on existing baselines by\nover 15%, and that the textual information affects performance far more than\nthe visual information on our time-dependent task from our ablation study.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06616v1",
    "published_date": "2024-11-10 22:42:36 UTC",
    "updated_date": "2024-11-10 22:42:36 UTC"
  },
  {
    "arxiv_id": "2411.07794v1",
    "title": "Feature Fusion Transferability Aware Transformer for Unsupervised Domain Adaptation",
    "authors": [
      "Xiaowei Yu",
      "Zhe Huang",
      "Zao Zhang"
    ],
    "abstract": "Unsupervised domain adaptation (UDA) aims to leverage the knowledge learned\nfrom labeled source domains to improve performance on the unlabeled target\ndomains. While Convolutional Neural Networks (CNNs) have been dominant in\nprevious UDA methods, recent research has shown promise in applying Vision\nTransformers (ViTs) to this task. In this study, we propose a novel Feature\nFusion Transferability Aware Transformer (FFTAT) to enhance ViT performance in\nUDA tasks. Our method introduces two key innovations: First, we introduce a\npatch discriminator to evaluate the transferability of patches, generating a\ntransferability matrix. We integrate this matrix into self-attention, directing\nthe model to focus on transferable patches. Second, we propose a feature fusion\ntechnique to fuse embeddings in the latent space, enabling each embedding to\nincorporate information from all others, thereby improving generalization.\nThese two components work in synergy to enhance feature representation\nlearning. Extensive experiments on widely used benchmarks demonstrate that our\nmethod significantly improves UDA performance, achieving state-of-the-art\n(SOTA) results.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)\n  2025",
    "pdf_url": "http://arxiv.org/pdf/2411.07794v1",
    "published_date": "2024-11-10 22:23:12 UTC",
    "updated_date": "2024-11-10 22:23:12 UTC"
  },
  {
    "arxiv_id": "2411.06611v2",
    "title": "vTune: Verifiable Fine-Tuning for LLMs Through Backdooring",
    "authors": [
      "Eva Zhang",
      "Arka Pal",
      "Akilesh Potti",
      "Micah Goldblum"
    ],
    "abstract": "As fine-tuning large language models (LLMs) becomes increasingly prevalent,\nusers often rely on third-party services with limited visibility into their\nfine-tuning processes. This lack of transparency raises the question: how do\nconsumers verify that fine-tuning services are performed correctly? For\ninstance, a service provider could claim to fine-tune a model for each user,\nyet simply send all users back the same base model. To address this issue, we\npropose vTune, a simple method that uses a small number of backdoor data points\nadded to the training data to provide a statistical test for verifying that a\nprovider fine-tuned a custom model on a particular user's dataset. Unlike\nexisting works, vTune is able to scale to verification of fine-tuning on\nstate-of-the-art LLMs, and can be used both with open-source and closed-source\nmodels. We test our approach across several model families and sizes as well as\nacross multiple instruction-tuning datasets, and find that the statistical test\nis satisfied with p-values on the order of $\\sim 10^{-40}$, with no negative\nimpact on downstream task performance. Further, we explore several attacks that\nattempt to subvert vTune and demonstrate the method's robustness to these\nattacks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06611v2",
    "published_date": "2024-11-10 22:08:37 UTC",
    "updated_date": "2024-11-12 03:04:07 UTC"
  },
  {
    "arxiv_id": "2411.06606v2",
    "title": "Gen-AI for User Safety: A Survey",
    "authors": [
      "Akshar Prabhu Desai",
      "Tejasvi Ravi",
      "Mohammad Luqman",
      "Mohit Sharma",
      "Nithya Kota",
      "Pranjul Yadav"
    ],
    "abstract": "Machine Learning and data mining techniques (i.e. supervised and unsupervised\ntechniques) are used across domains to detect user safety violations. Examples\ninclude classifiers used to detect whether an email is spam or a web-page is\nrequesting bank login information. However, existing ML/DM classifiers are\nlimited in their ability to understand natural languages w.r.t the context and\nnuances. The aforementioned challenges are overcome with the arrival of Gen-AI\ntechniques, along with their inherent ability w.r.t translation between\nlanguages, fine-tuning between various tasks and domains.\n  In this manuscript, we provide a comprehensive overview of the various work\ndone while using Gen-AI techniques w.r.t user safety. In particular, we first\nprovide the various domains (e.g. phishing, malware, content moderation,\ncounterfeit, physical safety) across which Gen-AI techniques have been applied.\nNext, we provide how Gen-AI techniques can be used in conjunction with various\ndata modalities i.e. text, images, videos, audio, executable binaries to detect\nviolations of user-safety. Further, also provide an overview of how Gen-AI\ntechniques can be used in an adversarial setting. We believe that this work\nrepresents the first summarization of Gen-AI techniques for user-safety.",
    "categories": [
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06606v2",
    "published_date": "2024-11-10 21:49:10 UTC",
    "updated_date": "2024-11-22 20:34:26 UTC"
  },
  {
    "arxiv_id": "2411.06601v3",
    "title": "OffLight: An Offline Multi-Agent Reinforcement Learning Framework for Traffic Signal Control",
    "authors": [
      "Rohit Bokade",
      "Xiaoning Jin"
    ],
    "abstract": "Efficient traffic control (TSC) is essential for urban mobility, but\ntraditional systems struggle to handle the complexity of real-world traffic.\nMulti-agent Reinforcement Learning (MARL) offers adaptive solutions, but online\nMARL requires extensive interactions with the environment, making it costly and\nimpractical. Offline MARL mitigates these challenges by using historical\ntraffic data for training but faces significant difficulties with heterogeneous\nbehavior policies in real-world datasets, where mixed-quality data complicates\nlearning. We introduce OffLight, a novel offline MARL framework designed to\nhandle heterogeneous behavior policies in TSC datasets. To improve learning\nefficiency, OffLight incorporates Importance Sampling (IS) to correct for\ndistributional shifts and Return-Based Prioritized Sampling (RBPS) to focus on\nhigh-quality experiences. OffLight utilizes a Gaussian Mixture Variational\nGraph Autoencoder (GMM-VGAE) to capture the diverse distribution of behavior\npolicies from local observations. Extensive experiments across real-world urban\ntraffic scenarios show that OffLight outperforms existing offline RL methods,\nachieving up to a 7.8% reduction in average travel time and 11.2% decrease in\nqueue length. Ablation studies confirm the effectiveness of OffLight's\ncomponents in handling heterogeneous data and improving policy performance.\nThese results highlight OffLight's scalability and potential to improve urban\ntraffic management without the risks of online learning.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06601v3",
    "published_date": "2024-11-10 21:26:17 UTC",
    "updated_date": "2025-03-18 01:22:42 UTC"
  },
  {
    "arxiv_id": "2411.06590v1",
    "title": "CriticAL: Critic Automation with Language Models",
    "authors": [
      "Michael Y. Li",
      "Vivek Vajipey",
      "Noah D. Goodman",
      "Emily B. Fox"
    ],
    "abstract": "Understanding the world through models is a fundamental goal of scientific\nresearch. While large language model (LLM) based approaches show promise in\nautomating scientific discovery, they often overlook the importance of\ncriticizing scientific models. Criticizing models deepens scientific\nunderstanding and drives the development of more accurate models. Automating\nmodel criticism is difficult because it traditionally requires a human expert\nto define how to compare a model with data and evaluate if the discrepancies\nare significant--both rely heavily on understanding the modeling assumptions\nand domain. Although LLM-based critic approaches are appealing, they introduce\nnew challenges: LLMs might hallucinate the critiques themselves. Motivated by\nthis, we introduce CriticAL (Critic Automation with Language Models). CriticAL\nuses LLMs to generate summary statistics that capture discrepancies between\nmodel predictions and data, and applies hypothesis tests to evaluate their\nsignificance. We can view CriticAL as a verifier that validates models and\ntheir critiques by embedding them in a hypothesis testing framework. In\nexperiments, we evaluate CriticAL across key quantitative and qualitative\ndimensions. In settings where we synthesize discrepancies between models and\ndatasets, CriticAL reliably generates correct critiques without hallucinating\nincorrect ones. We show that both human and LLM judges consistently prefer\nCriticAL's critiques over alternative approaches in terms of transparency and\nactionability. Finally, we show that CriticAL's critiques enable an LLM\nscientist to improve upon human-designed models on real-world datasets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06590v1",
    "published_date": "2024-11-10 20:41:35 UTC",
    "updated_date": "2024-11-10 20:41:35 UTC"
  },
  {
    "arxiv_id": "2411.06583v1",
    "title": "Enhancing frozen histological section images using permanent-section-guided deep learning with nuclei attention",
    "authors": [
      "Elad Yoshai",
      "Gil Goldinger",
      "Miki Haifler",
      "Natan T. Shaked"
    ],
    "abstract": "In histological pathology, frozen sections are often used for rapid diagnosis\nduring surgeries, as they can be produced within minutes. However, they suffer\nfrom artifacts and often lack crucial diagnostic details, particularly within\nthe cell nuclei region. Permanent sections, on the other hand, contain more\ndiagnostic detail but require a time-intensive preparation process. Here, we\npresent a generative deep learning approach to enhance frozen section images by\nleveraging guidance from permanent sections. Our method places a strong\nemphasis on the nuclei region, which contains critical information in both\nfrozen and permanent sections. Importantly, our approach avoids generating\nartificial data in blank regions, ensuring that the network only enhances\nexisting features without introducing potentially unreliable information. We\nachieve this through a segmented attention network, incorporating\nnuclei-segmented images during training and adding an additional loss function\nto refine the nuclei details in the generated permanent images. We validated\nour method across various tissues, including kidney, breast, and colon. This\napproach significantly improves histological efficiency and diagnostic\naccuracy, enhancing frozen section images within seconds, and seamlessly\nintegrating into existing laboratory workflows.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "q-bio.QM"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06583v1",
    "published_date": "2024-11-10 20:16:32 UTC",
    "updated_date": "2024-11-10 20:16:32 UTC"
  },
  {
    "arxiv_id": "2411.06581v2",
    "title": "HAFLQ: Heterogeneous Adaptive Federated LoRA Fine-tuned LLM with Quantization",
    "authors": [
      "Yang Su",
      "Na Yan",
      "Yansha Deng",
      "Mischa Dohler",
      "Robert Schober"
    ],
    "abstract": "Federated fine-tuning of pre-trained Large Language Models (LLMs) enables\ntask-specific adaptation across diverse datasets while preserving privacy.\nHowever, challenges such as high computational and memory demands,\nheterogeneous client resources, bandwidth constraints, and ineffective global\naggregation hinder its efficiency. To address these issues, we propose HAFLQ\n(Heterogeneous Adaptive Federated Low-Rank Adaptation Fine-tuned LLM with\nQuantization), a novel framework for efficient and scalable federated\nfine-tuning of LLMs in heterogeneous environments. To reduce memory and\ncomputation demands, we propose a salience-driven adaptive LLM quantization\nframework that evaluates the importance of transformer blocks using a salience\nmetric and applies adaptive block-wise quantization accordingly. To handle\nheterogeneous computational capabilities, we propose an importance-based\nparameter truncation and freezing scheme. To address communication bottlenecks,\nwe propose an importance-aware bandwidth-adaptive quantization method, which\ndynamically adjusts parameter precision based on importance and bandwidth\nconstraints. To improve global model aggregation, we propose an adaptive rank-1\nmatrix-level aggregation strategy, which prevents information dilution and\naccelerates convergence by aggregating only updated rank-1 matrices from\nclients. Experimental results on the text classification task demonstrate that\nHAFLQ reduces memory usage by 31%, lowers communication cost by 49%, improves\naccuracy by 50%, and achieves faster convergence compared to the baseline\nmethod.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "This is an extended journal version based on our previous conference\n  paper accepted at the 2025 IEEE International Conference on Communications\n  (ICC), with additional sections and new results",
    "pdf_url": "http://arxiv.org/pdf/2411.06581v2",
    "published_date": "2024-11-10 19:59:54 UTC",
    "updated_date": "2025-05-16 11:03:52 UTC"
  },
  {
    "arxiv_id": "2411.06577v1",
    "title": "Discovering emergent connections in quantum physics research via dynamic word embeddings",
    "authors": [
      "Felix Frohnert",
      "Xuemei Gu",
      "Mario Krenn",
      "Evert van Nieuwenburg"
    ],
    "abstract": "As the field of quantum physics evolves, researchers naturally form subgroups\nfocusing on specialized problems. While this encourages in-depth exploration,\nit can limit the exchange of ideas across structurally similar problems in\ndifferent subfields. To encourage cross-talk among these different specialized\nareas, data-driven approaches using machine learning have recently shown\npromise to uncover meaningful connections between research concepts, promoting\ncross-disciplinary innovation. Current state-of-the-art approaches represent\nconcepts using knowledge graphs and frame the task as a link prediction\nproblem, where connections between concepts are explicitly modeled. In this\nwork, we introduce a novel approach based on dynamic word embeddings for\nconcept combination prediction. Unlike knowledge graphs, our method captures\nimplicit relationships between concepts, can be learned in a fully unsupervised\nmanner, and encodes a broader spectrum of information. We demonstrate that this\nrepresentation enables accurate predictions about the co-occurrence of concepts\nwithin research abstracts over time. To validate the effectiveness of our\napproach, we provide a comprehensive benchmark against existing methods and\noffer insights into the interpretability of these embeddings, particularly in\nthe context of quantum physics research. Our findings suggest that this\nrepresentation offers a more flexible and informative way of modeling\nconceptual relationships in scientific literature.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "quant-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "7 pages; 4 figures; 1 table; Appendix: 2 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.06577v1",
    "published_date": "2024-11-10 19:45:59 UTC",
    "updated_date": "2024-11-10 19:45:59 UTC"
  },
  {
    "arxiv_id": "2411.06568v2",
    "title": "Meta-Learning Objectives for Preference Optimization",
    "authors": [
      "Carlo Alfano",
      "Silvia Sapora",
      "Jakob Nicolaus Foerster",
      "Patrick Rebeschini",
      "Yee Whye Teh"
    ],
    "abstract": "Evaluating preference optimization (PO) algorithms on LLM alignment is a\nchallenging task that presents prohibitive costs, noise, and several variables\nlike model size and hyper-parameters. In this work, we show that it is possible\nto gain insights on the efficacy of PO algorithm on much simpler benchmarks. We\ndesign a diagnostic suite of MuJoCo tasks and datasets, which we use to\nsystematically evaluate PO algorithms, establishing a more controlled and\ncheaper benchmark. We then propose a novel family of PO algorithms based on\nmirror descent, which we call Mirror Preference Optimization (MPO). Through\nevolutionary strategies, we search this class to discover algorithms\nspecialized to specific properties of preference datasets, such as\nmixed-quality or noisy data. We demonstrate that our discovered PO algorithms\noutperform all known algorithms in the targeted MuJoCo settings. Finally, based\non the insights gained from our MuJoCo experiments, we design a novel PO\nalgorithm that significantly outperforms existing baselines in an LLM alignment\ntask.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06568v2",
    "published_date": "2024-11-10 19:11:48 UTC",
    "updated_date": "2025-02-04 22:02:01 UTC"
  },
  {
    "arxiv_id": "2411.06565v3",
    "title": "Foundation Model for Composite Microstructures: Reconstruction, Stiffness, and Nonlinear Behavior Prediction",
    "authors": [
      "Ting-Ju Wei",
      "Chuin-Shan Chen"
    ],
    "abstract": "The rapid advancement of machine learning has unlocked numerous opportunities\nfor materials science, particularly in accelerating the design and analysis of\nmaterials. However, a significant challenge lies in the scarcity and high cost\nof obtaining high-quality materials datasets. While foundation models\npre-trained on large datasets have excelled in fields like natural language\nprocessing by leveraging latent features through transfer learning, their\napplication in materials science remains limited. Here, we present a foundation\nmodel specifically designed for composite materials. Pre-trained on a dataset\nof short-fiber composites to learn robust latent features, the model accurately\npredicts homogenized stiffness during transfer learning, even with limited\ntraining data. Additionally, our model effectively predicts the material's\nnonlinear behavior by transferring these learned features to an\nInteraction-based Material Network, which is a constitutive surrogate model.\nThese results demonstrate the potential of our foundation model to capture\ncomplex material behaviors. Our findings validate the feasibility and\neffectiveness of foundation models in composite materials. We anticipate\nextending this approach to more complex three-dimensional composite materials,\npolycrystalline materials, and beyond. Moreover, this framework enables\nhigh-accuracy predictions even when experimental data are scarce, paving the\nway for more efficient and cost-effective materials design and analysis.",
    "categories": [
      "cs.CE",
      "cs.AI"
    ],
    "primary_category": "cs.CE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06565v3",
    "published_date": "2024-11-10 19:06:25 UTC",
    "updated_date": "2025-04-08 19:00:34 UTC"
  },
  {
    "arxiv_id": "2411.06559v2",
    "title": "Is Your LLM Secretly a World Model of the Internet? Model-Based Planning for Web Agents",
    "authors": [
      "Yu Gu",
      "Kai Zhang",
      "Yuting Ning",
      "Boyuan Zheng",
      "Boyu Gou",
      "Tianci Xue",
      "Cheng Chang",
      "Sanjari Srivastava",
      "Yanan Xie",
      "Peng Qi",
      "Huan Sun",
      "Yu Su"
    ],
    "abstract": "Language agents based on large language models (LLMs) have demonstrated great\npromise in automating web-based tasks. Recent work has shown that incorporating\nadvanced planning algorithms, e.g., tree search, is advantageous over reactive\nplanning for web agents. However, unlike simulated sandbox environments,\nreal-world environments such as the web are rife with irreversible actions.\nThis undermines the feasibility of backtracking, a cornerstone of (tree)\nsearch. Overly relying on test-time search also hurts efficiency. We advocate\nmodel-based planning for web agents that employs a world model to simulate and\ndeliberate over the outcome of each candidate action before committing to one.\nWe systematically explore this paradigm by (1) Proposing a model-based planning\nframework, WebDreamer, which employs LLMs to serve as both world models and\nvalue functions; (2) Training specialized LLMs as world models with a scalable\ndata synthesis pipeline. Empirical results demonstrate that WebDreamer achieves\nsubstantial performance improvements over reactive baselines. It is\ncompetitive, while being 4-5 times more efficient, with tree search in sandbox\nenvironments (VisualWebArena) and also works effectively on real-world websites\n(Online-Mind2Web and Mind2Web-Live). Furthermore, our trained world model,\nDreamer-7B, performs comparable to GPT-4o, highlighting the potential of\nspecialized world models for efficient and effective planning in complex web\nenvironments.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "22 pages, 11 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2411.06559v2",
    "published_date": "2024-11-10 18:50:51 UTC",
    "updated_date": "2025-04-01 05:04:47 UTC"
  },
  {
    "arxiv_id": "2411.06549v1",
    "title": "In-Context Learning for Preserving Patient Privacy: A Framework for Synthesizing Realistic Patient Portal Messages",
    "authors": [
      "Joseph Gatto",
      "Parker Seegmiller",
      "Timothy E. Burdick",
      "Sarah Masud Preum"
    ],
    "abstract": "Since the COVID-19 pandemic, clinicians have seen a large and sustained\ninflux in patient portal messages, significantly contributing to clinician\nburnout. To the best of our knowledge, there are no large-scale public patient\nportal messages corpora researchers can use to build tools to optimize\nclinician portal workflows. Informed by our ongoing work with a regional\nhospital, this study introduces an LLM-powered framework for configurable and\nrealistic patient portal message generation. Our approach leverages few-shot\ngrounded text generation, requiring only a small number of de-identified\npatient portal messages to help LLMs better match the true style and tone of\nreal data. Clinical experts in our team deem this framework as HIPAA-friendly,\nunlike existing privacy-preserving approaches to synthetic text generation\nwhich cannot guarantee all sensitive attributes will be protected. Through\nextensive quantitative and human evaluation, we show that our framework\nproduces data of higher quality than comparable generation methods as well as\nall related datasets. We believe this work provides a path forward for (i) the\nrelease of large-scale synthetic patient message datasets that are\nstylistically similar to ground-truth samples and (ii) HIPAA-friendly data\ngeneration which requires minimal human de-identification efforts.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Findings paper presented at Machine Learning for Health (ML4H)\n  symposium 2024, December 15-16, 2024, Vancouver, Canada, 8 pages",
    "pdf_url": "http://arxiv.org/pdf/2411.06549v1",
    "published_date": "2024-11-10 18:06:55 UTC",
    "updated_date": "2024-11-10 18:06:55 UTC"
  },
  {
    "arxiv_id": "2411.06542v4",
    "title": "Is Linear Feedback on Smoothed Dynamics Sufficient for Stabilizing Contact-Rich Plans?",
    "authors": [
      "Yuki Shirai",
      "Tong Zhao",
      "H. J. Terry Suh",
      "Huaijiang Zhu",
      "Xinpei Ni",
      "Jiuguang Wang",
      "Max Simchowitz",
      "Tao Pang"
    ],
    "abstract": "Designing planners and controllers for contact-rich manipulation is extremely\nchallenging as contact violates the smoothness conditions that many\ngradient-based controller synthesis tools assume. Contact smoothing\napproximates a non-smooth system with a smooth one, allowing one to use these\nsynthesis tools more effectively. However, applying classical control synthesis\nmethods to smoothed contact dynamics remains relatively under-explored. This\npaper analyzes the efficacy of linear controller synthesis using differential\nsimulators based on contact smoothing. We introduce natural baselines for\nleveraging contact smoothing to compute (a) open-loop plans robust to uncertain\nconditions and/or dynamics, and (b) feedback gains to stabilize around\nopen-loop plans. Using robotic bimanual whole-body manipulation as a testbed,\nwe perform extensive empirical experiments on over 300 trajectories and analyze\nwhy LQR seems insufficient for stabilizing contact-rich plans. The video\nsummarizing this paper and hardware experiments is found here:\nhttps://youtu.be/HLaKi6qbwQg?si=_zCAmBBD6rGSitm9.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "ICRA2025",
    "pdf_url": "http://arxiv.org/pdf/2411.06542v4",
    "published_date": "2024-11-10 17:48:26 UTC",
    "updated_date": "2025-05-14 11:58:21 UTC"
  },
  {
    "arxiv_id": "2411.06538v1",
    "title": "A Next-Generation Approach to Airline Reservations: Integrating Cloud Microservices with AI and Blockchain for Enhanced Operational Performance",
    "authors": [
      "Biman Barua",
      "M. Shamim Kaiser"
    ],
    "abstract": "This research proposes the development of a next generation airline\nreservation system that incorporates the Cloud microservices, distributed\nartificial intelligence modules and the blockchain technology to improve on the\nefficiency, safety and customer satisfaction. The traditional reservation\nsystems encounter issues related to the expansion of the systems, the integrity\nof the data provided and the level of service offered to the customers, which\nis the main focus of this architecture through the modular and data centric\ndesign approaches. This will allow different operations such as reservations,\npayments, and customer data management among others to be performed separately\nthereby facilitating high availability of the system by 30% and enhancing\nperformance of the system by 40% on its scalability. Such systems contain AI\ndriven modules that utilize the past booking patterns along with the profile of\nthe customer to estimate the demand and make recommendations, which increases\nto 25 % of customer engagement. Moreover, blockchain is effective in engaging\nan incorruptible ledger system for the all transactions therefore mitigating\nfraud incidences and increasing the clarity by 20%. The system was subjected to\nanalysis using a simulator and using machine learning evaluations that rated it\nagainst other conventional systems. The results show that there were clear\nenhancements in the speed of transactions where the rates of secure data\nprocessing rose by 35%, and the system response time by 15 %. The system can\nalso be used for other high transaction industries like logistics and\nhospitality. This structural design is indicative of how the use of advanced\ntechnologies will revolutionize the airline reservation sector. The\nimplications are growing effectiveness, improvement in security and greater\ncustomer contentment.",
    "categories": [
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.AI",
    "comment": "25 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.06538v1",
    "published_date": "2024-11-10 17:38:30 UTC",
    "updated_date": "2024-11-10 17:38:30 UTC"
  },
  {
    "arxiv_id": "2411.06535v1",
    "title": "Probabilistic Consensus through Ensemble Validation: A Framework for LLM Reliability",
    "authors": [
      "Ninad Naik"
    ],
    "abstract": "Large Language Models (LLMs) have shown significant advances in text\ngeneration but often lack the reliability needed for autonomous deployment in\nhigh-stakes domains like healthcare, law, and finance. Existing approaches rely\non external knowledge or human oversight, limiting scalability. We introduce a\nnovel framework that repurposes ensemble methods for content validation through\nmodel consensus. In tests across 78 complex cases requiring factual accuracy\nand causal consistency, our framework improved precision from 73.1% to 93.9%\nwith two models (95% CI: 83.5%-97.9%) and to 95.6% with three models (95% CI:\n85.2%-98.8%). Statistical analysis indicates strong inter-model agreement\n($\\kappa$ > 0.76) while preserving sufficient independence to catch errors\nthrough disagreement. We outline a clear pathway to further enhance precision\nwith additional validators and refinements. Although the current approach is\nconstrained by multiple-choice format requirements and processing latency, it\noffers immediate value for enabling reliable autonomous AI systems in critical\napplications.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2411.06535v1",
    "published_date": "2024-11-10 17:32:16 UTC",
    "updated_date": "2024-11-10 17:32:16 UTC"
  },
  {
    "arxiv_id": "2411.06528v1",
    "title": "Epistemic Integrity in Large Language Models",
    "authors": [
      "Bijean Ghafouri",
      "Shahrad Mohammadzadeh",
      "James Zhou",
      "Pratheeksha Nair",
      "Jacob-Junqi Tian",
      "Mayank Goel",
      "Reihaneh Rabbany",
      "Jean-François Godbout",
      "Kellin Pelrine"
    ],
    "abstract": "Large language models are increasingly relied upon as sources of information,\nbut their propensity for generating false or misleading statements with high\nconfidence poses risks for users and society. In this paper, we confront the\ncritical problem of epistemic miscalibration $\\unicode{x2013}$ where a model's\nlinguistic assertiveness fails to reflect its true internal certainty. We\nintroduce a new human-labeled dataset and a novel method for measuring the\nlinguistic assertiveness of Large Language Models (LLMs) which cuts error rates\nby over 50% relative to previous benchmarks. Validated across multiple\ndatasets, our method reveals a stark misalignment between how confidently\nmodels linguistically present information and their actual accuracy. Further\nhuman evaluations confirm the severity of this miscalibration. This evidence\nunderscores the urgent risk of the overstated certainty LLMs hold which may\nmislead users on a massive scale. Our framework provides a crucial step forward\nin diagnosing this miscalibration, offering a path towards correcting it and\nmore trustworthy AI across domains.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06528v1",
    "published_date": "2024-11-10 17:10:13 UTC",
    "updated_date": "2024-11-10 17:10:13 UTC"
  },
  {
    "arxiv_id": "2411.06525v3",
    "title": "I2VControl-Camera: Precise Video Camera Control with Adjustable Motion Strength",
    "authors": [
      "Wanquan Feng",
      "Jiawei Liu",
      "Pengqi Tu",
      "Tianhao Qi",
      "Mingzhen Sun",
      "Tianxiang Ma",
      "Songtao Zhao",
      "Siyu Zhou",
      "Qian He"
    ],
    "abstract": "Video generation technologies are developing rapidly and have broad potential\napplications. Among these technologies, camera control is crucial for\ngenerating professional-quality videos that accurately meet user expectations.\nHowever, existing camera control methods still suffer from several limitations,\nincluding control precision and the neglect of the control for subject motion\ndynamics. In this work, we propose I2VControl-Camera, a novel camera control\nmethod that significantly enhances controllability while providing\nadjustability over the strength of subject motion. To improve control\nprecision, we employ point trajectory in the camera coordinate system instead\nof only extrinsic matrix information as our control signal. To accurately\ncontrol and adjust the strength of subject motion, we explicitly model the\nhigher-order components of the video trajectory expansion, not merely the\nlinear terms, and design an operator that effectively represents the motion\nstrength. We use an adapter architecture that is independent of the base model\nstructure. Experiments on static and dynamic scenes show that our framework\noutperformances previous methods both quantitatively and qualitatively. The\nproject page is: https://wanquanf.github.io/I2VControlCamera .",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to ICLR 2025, Project page:\n  https://wanquanf.github.io/I2VControlCamera",
    "pdf_url": "http://arxiv.org/pdf/2411.06525v3",
    "published_date": "2024-11-10 16:59:39 UTC",
    "updated_date": "2025-02-28 06:40:38 UTC"
  },
  {
    "arxiv_id": "2411.06524v1",
    "title": "Does This Summary Answer My Question? Modeling Query-Focused Summary Readers with Rational Speech Acts",
    "authors": [
      "Cesare Spinoso-Di Piano",
      "Jackie Chi Kit Cheung"
    ],
    "abstract": "Query-focused summarization (QFS) is the task of generating a summary in\nresponse to a user-written query. Despite its user-oriented nature, there has\nbeen limited work in QFS in explicitly considering a user's understanding of a\ngenerated summary, potentially causing QFS systems to underperform at inference\ntime. In this paper, we adapt the Rational Speech Act (RSA) framework, a model\nof human communication, to explicitly model a reader's understanding of a\nquery-focused summary and integrate it within the generation method of existing\nQFS systems. In particular, we introduce the answer reconstruction objective\nwhich approximates a reader's understanding of a summary by their ability to\nuse it to reconstruct the answer to their initial query. Using this objective,\nwe are able to re-rank candidate summaries generated by existing QFS systems\nand select summaries that better align with their corresponding query and\nreference summary. More generally, our study suggests that a simple and\neffective way of improving a language generation system designed for a\nuser-centered task may be to explicitly incorporate its user requirements into\nthe system's generation procedure.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06524v1",
    "published_date": "2024-11-10 16:48:21 UTC",
    "updated_date": "2024-11-10 16:48:21 UTC"
  },
  {
    "arxiv_id": "2411.07271v2",
    "title": "Multi-hop Upstream Anticipatory Traffic Signal Control with Deep Reinforcement Learning",
    "authors": [
      "Xiaocan Li",
      "Xiaoyu Wang",
      "Ilia Smirnov",
      "Scott Sanner",
      "Baher Abdulhai"
    ],
    "abstract": "Coordination in traffic signal control is crucial for managing congestion in\nurban networks. Existing pressure-based control methods focus only on immediate\nupstream links, leading to suboptimal green time allocation and increased\nnetwork delays. However, effective signal control inherently requires\ncoordination across a broader spatial scope, as the effect of upstream traffic\nshould influence signal control decisions at downstream intersections,\nimpacting a large area in the traffic network. Although agent communication\nusing neural network-based feature extraction can implicitly enhance spatial\nawareness, it significantly increases the learning complexity, adding an\nadditional layer of difficulty to the challenging task of control in deep\nreinforcement learning. To address the issue of learning complexity and myopic\ntraffic pressure definition, our work introduces a novel concept based on\nMarkov chain theory, namely \\textit{multi-hop upstream pressure}, which\ngeneralizes the conventional pressure to account for traffic conditions beyond\nthe immediate upstream links. This farsighted and compact metric informs the\ndeep reinforcement learning agent to preemptively clear the multi-hop upstream\nqueues, guiding the agent to optimize signal timings with a broader spatial\nawareness. Simulations on synthetic and realistic (Toronto) scenarios\ndemonstrate controllers utilizing multi-hop upstream pressure significantly\nreduce overall network delay by prioritizing traffic movements based on a\nbroader understanding of upstream congestion.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY",
      "math.PR"
    ],
    "primary_category": "cs.LG",
    "comment": "5 tables, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.07271v2",
    "published_date": "2024-11-10 16:28:42 UTC",
    "updated_date": "2025-01-16 21:09:57 UTC"
  },
  {
    "arxiv_id": "2411.07795v2",
    "title": "InvisMark: Invisible and Robust Watermarking for AI-generated Image Provenance",
    "authors": [
      "Rui Xu",
      "Mengya Hu",
      "Deren Lei",
      "Yaxi Li",
      "David Lowe",
      "Alex Gorevski",
      "Mingyu Wang",
      "Emily Ching",
      "Alex Deng"
    ],
    "abstract": "The proliferation of AI-generated images has intensified the need for robust\ncontent authentication methods. We present InvisMark, a novel watermarking\ntechnique designed for high-resolution AI-generated images. Our approach\nleverages advanced neural network architectures and training strategies to\nembed imperceptible yet highly robust watermarks. InvisMark achieves\nstate-of-the-art performance in imperceptibility (PSNR$\\sim$51, SSIM $\\sim$\n0.998) while maintaining over 97\\% bit accuracy across various image\nmanipulations. Notably, we demonstrate the successful encoding of 256-bit\nwatermarks, significantly expanding payload capacity while preserving image\nquality. This enables the embedding of UUIDs with error correction codes,\nachieving near-perfect decoding success rates even under challenging image\ndistortions. We also address potential vulnerabilities against advanced attacks\nand propose mitigation strategies. By combining high imperceptibility, extended\npayload capacity, and resilience to manipulations, InvisMark provides a robust\nfoundation for ensuring media provenance in an era of increasingly\nsophisticated AI-generated content. Source code of this paper is available at:\nhttps://github.com/microsoft/InvisMark.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted to WACV 2025",
    "pdf_url": "http://arxiv.org/pdf/2411.07795v2",
    "published_date": "2024-11-10 16:22:22 UTC",
    "updated_date": "2024-11-19 05:19:44 UTC"
  },
  {
    "arxiv_id": "2411.06510v1",
    "title": "Offline Handwritten Signature Verification Using a Stream-Based Approach",
    "authors": [
      "Kecia G. de Moura",
      "Rafael M. O. Cruz",
      "Robert Sabourin"
    ],
    "abstract": "Handwritten Signature Verification (HSV) systems distinguish between genuine\nand forged signatures. Traditional HSV development involves a static batch\nconfiguration, constraining the system's ability to model signatures to the\nlimited data available. Signatures exhibit high intra-class variability and are\nsensitive to various factors, including time and external influences, imparting\nthem a dynamic nature. This paper investigates the signature learning process\nwithin a data stream context. We propose a novel HSV approach with an adaptive\nsystem that receives an infinite sequence of signatures and is updated over\ntime. Experiments were carried out on GPDS Synthetic, CEDAR, and MCYT datasets.\nResults demonstrate the superior performance of the proposed method compared to\nstandard approaches that use a Support Vector Machine as a classifier.\nImplementation of the method is available at\nhttps://github.com/kdMoura/stream_hsv.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted for oral presentation at the International Conference on\n  Pattern Recognition (ICPR) 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.06510v1",
    "published_date": "2024-11-10 16:16:06 UTC",
    "updated_date": "2024-11-10 16:16:06 UTC"
  },
  {
    "arxiv_id": "2411.06508v1",
    "title": "Understanding the Role of Equivariance in Self-supervised Learning",
    "authors": [
      "Yifei Wang",
      "Kaiwen Hu",
      "Sharut Gupta",
      "Ziyu Ye",
      "Yisen Wang",
      "Stefanie Jegelka"
    ],
    "abstract": "Contrastive learning has been a leading paradigm for self-supervised\nlearning, but it is widely observed that it comes at the price of sacrificing\nuseful features (\\eg colors) by being invariant to data augmentations. Given\nthis limitation, there has been a surge of interest in equivariant\nself-supervised learning (E-SSL) that learns features to be augmentation-aware.\nHowever, even for the simplest rotation prediction method, there is a lack of\nrigorous understanding of why, when, and how E-SSL learns useful features for\ndownstream tasks. To bridge this gap between practice and theory, we establish\nan information-theoretic perspective to understand the generalization ability\nof E-SSL. In particular, we identify a critical explaining-away effect in E-SSL\nthat creates a synergy between the equivariant and classification tasks. This\nsynergy effect encourages models to extract class-relevant features to improve\nits equivariant prediction, which, in turn, benefits downstream tasks requiring\nsemantic features. Based on this perspective, we theoretically analyze the\ninfluence of data transformations and reveal several principles for practical\ndesigns of E-SSL. Our theory not only aligns well with existing E-SSL methods\nbut also sheds light on new directions by exploring the benefits of model\nequivariance. We believe that a theoretically grounded understanding on the\nrole of equivariance would inspire more principled and advanced designs in this\nfield. Code is available at https://github.com/kaotty/Understanding-ESSL.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.IT",
      "math.IT",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.06508v1",
    "published_date": "2024-11-10 16:09:47 UTC",
    "updated_date": "2024-11-10 16:09:47 UTC"
  },
  {
    "arxiv_id": "2411.06498v1",
    "title": "Barriers to Complexity-Theoretic Proofs that Achieving AGI Using Machine Learning is Intractable",
    "authors": [
      "Michael Guerzhoy"
    ],
    "abstract": "A recent paper (van Rooij et al. 2024) claims to have proved that achieving\nhuman-like intelligence using learning from data is intractable in a\ncomplexity-theoretic sense. We identify that the proof relies on an unjustified\nassumption about the distribution of (input, output) pairs to the system. We\nbriefly discuss that assumption in the context of two fundamental barriers to\nrepairing the proof: the need to precisely define ``human-like,\" and the need\nto account for the fact that a particular machine learning system will have\nparticular inductive biases that are key to the analysis.",
    "categories": [
      "cs.AI",
      "cs.CC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06498v1",
    "published_date": "2024-11-10 15:47:30 UTC",
    "updated_date": "2024-11-10 15:47:30 UTC"
  },
  {
    "arxiv_id": "2411.06493v2",
    "title": "LProtector: An LLM-driven Vulnerability Detection System",
    "authors": [
      "Ze Sheng",
      "Fenghua Wu",
      "Xiangwu Zuo",
      "Chao Li",
      "Yuxin Qiao",
      "Lei Hang"
    ],
    "abstract": "This paper presents LProtector, an automated vulnerability detection system\nfor C/C++ codebases driven by the large language model (LLM) GPT-4o and\nRetrieval-Augmented Generation (RAG). As software complexity grows, traditional\nmethods face challenges in detecting vulnerabilities effectively. LProtector\nleverages GPT-4o's powerful code comprehension and generation capabilities to\nperform binary classification and identify vulnerabilities within target\ncodebases. We conducted experiments on the Big-Vul dataset, showing that\nLProtector outperforms two state-of-the-art baselines in terms of F1 score,\ndemonstrating the potential of integrating LLMs with vulnerability detection.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "5 pages, 4 figures. This is a preprint version of the article. The\n  final version will be published in the proceedings of the IEEE conference",
    "pdf_url": "http://arxiv.org/pdf/2411.06493v2",
    "published_date": "2024-11-10 15:21:30 UTC",
    "updated_date": "2024-11-14 05:34:13 UTC"
  },
  {
    "arxiv_id": "2411.06490v1",
    "title": "Hermes: A Large Language Model Framework on the Journey to Autonomous Networks",
    "authors": [
      "Fadhel Ayed",
      "Ali Maatouk",
      "Nicola Piovesan",
      "Antonio De Domenico",
      "Merouane Debbah",
      "Zhi-Quan Luo"
    ],
    "abstract": "The drive toward automating cellular network operations has grown with the\nincreasing complexity of these systems. Despite advancements, full autonomy\ncurrently remains out of reach due to reliance on human intervention for\nmodeling network behaviors and defining policies to meet target requirements.\nNetwork Digital Twins (NDTs) have shown promise in enhancing network\nintelligence, but the successful implementation of this technology is\nconstrained by use case-specific architectures, limiting its role in advancing\nnetwork autonomy. A more capable network intelligence, or \"telecommunications\nbrain\", is needed to enable seamless, autonomous management of cellular\nnetwork. Large Language Models (LLMs) have emerged as potential enablers for\nthis vision but face challenges in network modeling, especially in reasoning\nand handling diverse data types. To address these gaps, we introduce Hermes, a\nchain of LLM agents that uses \"blueprints\" for constructing NDT instances\nthrough structured and explainable logical steps. Hermes allows automatic,\nreliable, and accurate network modeling of diverse use cases and\nconfigurations, thus marking progress toward fully autonomous network\noperations.",
    "categories": [
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06490v1",
    "published_date": "2024-11-10 15:12:12 UTC",
    "updated_date": "2024-11-10 15:12:12 UTC"
  },
  {
    "arxiv_id": "2411.06463v1",
    "title": "RL-Pruner: Structured Pruning Using Reinforcement Learning for CNN Compression and Acceleration",
    "authors": [
      "Boyao Wang",
      "Volodymyr Kindratenko"
    ],
    "abstract": "Convolutional Neural Networks (CNNs) have demonstrated exceptional\nperformance in recent years. Compressing these models not only reduces storage\nrequirements, making deployment to edge devices feasible, but also accelerates\ninference, thereby reducing latency and computational costs. Structured\npruning, which removes filters at the layer level, directly modifies the model\narchitecture. This approach achieves a more compact architecture while\nmaintaining target accuracy, ensuring that the compressed model retains good\ncompatibility and hardware efficiency. Our method is based on a key\nobservation: filters in different layers of a neural network have varying\nimportance to the model's performance. When the number of filters to prune is\nfixed, the optimal pruning distribution across different layers is uneven to\nminimize performance loss. Layers that are more sensitive to pruning should\naccount for a smaller proportion of the pruning distribution. To leverage this\ninsight, we propose RL-Pruner, which uses reinforcement learning to learn the\noptimal pruning distribution. RL-Pruner can automatically extract dependencies\nbetween filters in the input model and perform pruning, without requiring\nmodel-specific pruning implementations. We conducted experiments on models such\nas GoogleNet, ResNet, and MobileNet, comparing our approach to other structured\npruning methods to validate its effectiveness. Our code is available at\nhttps://github.com/Beryex/RLPruner-CNN.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06463v1",
    "published_date": "2024-11-10 13:35:10 UTC",
    "updated_date": "2024-11-10 13:35:10 UTC"
  },
  {
    "arxiv_id": "2411.06448v1",
    "title": "Over-parameterized Student Model via Tensor Decomposition Boosted Knowledge Distillation",
    "authors": [
      "Yu-Liang Zhan",
      "Zhong-Yi Lu",
      "Hao Sun",
      "Ze-Feng Gao"
    ],
    "abstract": "Increased training parameters have enabled large pre-trained models to excel\nin various downstream tasks. Nevertheless, the extensive computational\nrequirements associated with these models hinder their widespread adoption\nwithin the community. We focus on Knowledge Distillation (KD), where a compact\nstudent model is trained to mimic a larger teacher model, facilitating the\ntransfer of knowledge of large models. In contrast to much of the previous\nwork, we scale up the parameters of the student model during training, to\nbenefit from overparameterization without increasing the inference latency. In\nparticular, we propose a tensor decomposition strategy that effectively\nover-parameterizes the relatively small student model through an efficient and\nnearly lossless decomposition of its parameter matrices into higher-dimensional\ntensors. To ensure efficiency, we further introduce a tensor constraint loss to\nalign the high-dimensional tensors between the student and teacher models.\nComprehensive experiments validate the significant performance enhancement by\nour approach in various KD tasks, covering computer vision and natural language\nprocessing areas. Our code is available at\nhttps://github.com/intell-sci-comput/OPDF.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "38th Conference on Neural Information Processing Systems (NeurIPS\n  2024)",
    "pdf_url": "http://arxiv.org/pdf/2411.06448v1",
    "published_date": "2024-11-10 12:40:59 UTC",
    "updated_date": "2024-11-10 12:40:59 UTC"
  },
  {
    "arxiv_id": "2411.06445v1",
    "title": "Prompt-Efficient Fine-Tuning for GPT-like Deep Models to Reduce Hallucination and to Improve Reproducibility in Scientific Text Generation Using Stochastic Optimisation Techniques",
    "authors": [
      "Daniil Sulimov"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly adopted for complex scientific\ntext generation tasks, yet they often suffer from limitations in accuracy,\nconsistency, and hallucination control. This thesis introduces a\nParameter-Efficient Fine-Tuning (PEFT) approach tailored for GPT-like models,\naiming to mitigate hallucinations and enhance reproducibility, particularly in\nthe computational domain of mass spectrometry. We implemented Low-Rank\nAdaptation (LoRA) adapters to refine GPT-2, termed MS-GPT, using a specialized\ncorpus of mass spectrometry literature. Through novel evaluation methods\napplied to LLMs, including BLEU, ROUGE, and Perplexity scores, the fine-tuned\nMS-GPT model demonstrated superior text coherence and reproducibility compared\nto the baseline GPT-2, confirmed through statistical analysis with the Wilcoxon\nrank-sum test. Further, we propose a reproducibility metric based on cosine\nsimilarity of model outputs under controlled prompts, showcasing MS-GPT's\nenhanced stability. This research highlights PEFT's potential to optimize LLMs\nfor scientific contexts, reducing computational costs while improving model\nreliability.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T50, 91B82",
      "I.2.7; G.3"
    ],
    "primary_category": "cs.CL",
    "comment": "73 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.06445v1",
    "published_date": "2024-11-10 12:28:09 UTC",
    "updated_date": "2024-11-10 12:28:09 UTC"
  },
  {
    "arxiv_id": "2411.08063v1",
    "title": "MatPilot: an LLM-enabled AI Materials Scientist under the Framework of Human-Machine Collaboration",
    "authors": [
      "Ziqi Ni",
      "Yahao Li",
      "Kaijia Hu",
      "Kunyuan Han",
      "Ming Xu",
      "Xingyu Chen",
      "Fengqi Liu",
      "Yicong Ye",
      "Shuxin Bai"
    ],
    "abstract": "The rapid evolution of artificial intelligence, particularly large language\nmodels, presents unprecedented opportunities for materials science research. We\nproposed and developed an AI materials scientist named MatPilot, which has\nshown encouraging abilities in the discovery of new materials. The core\nstrength of MatPilot is its natural language interactive human-machine\ncollaboration, which augments the research capabilities of human scientist\nteams through a multi-agent system. MatPilot integrates unique cognitive\nabilities, extensive accumulated experience, and ongoing curiosity of\nhuman-beings with the AI agents' capabilities of advanced abstraction, complex\nknowledge storage and high-dimensional information processing. It could\ngenerate scientific hypotheses and experimental schemes, and employ predictive\nmodels and optimization algorithms to drive an automated experimental platform\nfor experiments. It turns out that our system demonstrates capabilities for\nefficient validation, continuous learning, and iterative optimization.",
    "categories": [
      "physics.soc-ph",
      "cond-mat.mtrl-sci",
      "cs.AI"
    ],
    "primary_category": "physics.soc-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.08063v1",
    "published_date": "2024-11-10 12:23:44 UTC",
    "updated_date": "2024-11-10 12:23:44 UTC"
  },
  {
    "arxiv_id": "2411.06442v1",
    "title": "Local Implicit Wavelet Transformer for Arbitrary-Scale Super-Resolution",
    "authors": [
      "Minghong Duan",
      "Linhao Qu",
      "Shaolei Liu",
      "Manning Wang"
    ],
    "abstract": "Implicit neural representations have recently demonstrated promising\npotential in arbitrary-scale Super-Resolution (SR) of images. Most existing\nmethods predict the pixel in the SR image based on the queried coordinate and\nensemble nearby features, overlooking the importance of incorporating\nhigh-frequency prior information in images, which results in limited\nperformance in reconstructing high-frequency texture details in images. To\naddress this issue, we propose the Local Implicit Wavelet Transformer (LIWT) to\nenhance the restoration of high-frequency texture details. Specifically, we\ndecompose the features extracted by an encoder into four sub-bands containing\ndifferent frequency information using Discrete Wavelet Transform (DWT). We then\nintroduce the Wavelet Enhanced Residual Module (WERM) to transform these four\nsub-bands into high-frequency priors, followed by utilizing the Wavelet Mutual\nProjected Fusion (WMPF) and the Wavelet-aware Implicit Attention (WIA) to fully\nexploit the high-frequency prior information for recovering high-frequency\ndetails in images. We conducted extensive experiments on benchmark datasets to\nvalidate the effectiveness of LIWT. Both qualitative and quantitative results\ndemonstrate that LIWT achieves promising performance in arbitrary-scale SR\ntasks, outperforming other state-of-the-art methods. The code is available at\nhttps://github.com/dmhdmhdmh/LIWT.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by BMVC 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.06442v1",
    "published_date": "2024-11-10 12:21:14 UTC",
    "updated_date": "2024-11-10 12:21:14 UTC"
  },
  {
    "arxiv_id": "2411.06438v5",
    "title": "Conditional [MASK] Discrete Diffusion Language Model",
    "authors": [
      "Hyukhun Koh",
      "Minha Jhang",
      "Dohyung Kim",
      "Sangmook Lee",
      "Kyomin Jung"
    ],
    "abstract": "Although auto-regressive models excel in natural language processing, they\noften struggle to generate diverse text and provide limited controllability.\nNon-auto-regressive methods could be an alternative but often produce\ndegenerate outputs and exhibit shortcomings in conditional generation. To\naddress these challenges, we propose Diffusion-EAGS, a novel framework that\nintegrates conditional masked language models into diffusion language models\nthrough the theoretical lens of a conditional Markov Random Field. In doing so,\nwe propose entropy-adaptive Gibbs sampling and entropy-based noise scheduling\nto counterbalance each model's shortcomings. Experimental results show that\nDiffusion-EAGS outperforms baselines and achieves the best quality-diversity\ntradeoff, demonstrating its effectiveness in non-autoregressive text\ngeneration.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06438v5",
    "published_date": "2024-11-10 11:49:36 UTC",
    "updated_date": "2025-02-24 09:11:03 UTC"
  },
  {
    "arxiv_id": "2411.06437v1",
    "title": "CTC-Assisted LLM-Based Contextual ASR",
    "authors": [
      "Guanrou Yang",
      "Ziyang Ma",
      "Zhifu Gao",
      "Shiliang Zhang",
      "Xie Chen"
    ],
    "abstract": "Contextual ASR or hotword customization holds substantial practical value.\nDespite the impressive performance of current end-to-end (E2E) automatic speech\nrecognition (ASR) systems, they often face challenges in accurately recognizing\nrare words. Typical E2E contextual ASR models commonly feature complex\narchitectures and decoding mechanisms, limited in performance and susceptible\nto interference from distractor words. With large language model (LLM)-based\nASR models emerging as the new mainstream, we propose a CTC-Assisted LLM-Based\nContextual ASR model with an efficient filtering algorithm. By using coarse CTC\ndecoding results to filter potential relevant hotwords and incorporating them\ninto LLM prompt input, our model attains WER/B-WER of 1.27%/3.67% and\n2.72%/8.02% on the Librispeech test-clean and test-other sets targeting on\nrecognizing rare long-tail words, demonstrating significant improvements\ncompared to the baseline LLM-based ASR model, and substantially surpassing\nother related work. More remarkably, with the help of the large language model\nand proposed filtering algorithm, our contextual ASR model still performs well\nwith 2000 biasing words.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "eess.AS",
    "comment": "SLT 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.06437v1",
    "published_date": "2024-11-10 11:47:50 UTC",
    "updated_date": "2024-11-10 11:47:50 UTC"
  },
  {
    "arxiv_id": "2411.06429v1",
    "title": "Reinforcement learning for Quantum Tiq-Taq-Toe",
    "authors": [
      "Catalin-Viorel Dinu",
      "Thomas Moerland"
    ],
    "abstract": "Quantum Tiq-Taq-Toe is a well-known benchmark and playground for both quantum\ncomputing and machine learning. Despite its popularity, no reinforcement\nlearning (RL) methods have been applied to Quantum Tiq-Taq-Toe. Although there\nhas been some research on Quantum Chess this game is significantly more complex\nin terms of computation and analysis. Therefore, we study the combination of\nquantum computing and reinforcement learning in Quantum Tiq-Taq-Toe, which may\nserve as an accessible testbed for the integration of both fields.\n  Quantum games are challenging to represent classically due to their inherent\npartial observability and the potential for exponential state complexity. In\nQuantum Tiq-Taq-Toe, states are observed through Measurement (a 3x3 matrix of\nstate probabilities) and Move History (a 9x9 matrix of entanglement relations),\nmaking strategy complex as each move can collapse the quantum state.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06429v1",
    "published_date": "2024-11-10 11:20:36 UTC",
    "updated_date": "2024-11-10 11:20:36 UTC"
  },
  {
    "arxiv_id": "2411.06428v1",
    "title": "Neuro-Symbolic Rule Lists",
    "authors": [
      "Sascha Xu",
      "Nils Philipp Walter",
      "Jilles Vreeken"
    ],
    "abstract": "Machine learning models deployed in sensitive areas such as healthcare must\nbe interpretable to ensure accountability and fairness. Rule lists (if Age < 35\n$\\wedge$ Priors > 0 then Recidivism = True, else if Next Condition . . . )\noffer full transparency, making them well-suited for high-stakes decisions.\nHowever, learning such rule lists presents significant challenges. Existing\nmethods based on combinatorial optimization require feature pre-discretization\nand impose restrictions on rule size. Neuro-symbolic methods use more scalable\ncontinuous optimization yet place similar pre-discretization constraints and\nsuffer from unstable optimization. To address the existing limitations, we\nintroduce NeuRules, an end-to-end trainable model that unifies discretization,\nrule learning, and rule order into a single differentiable framework. We\nformulate a continuous relaxation of the rule list learning problem that\nconverges to a strict rule list through temperature annealing. NeuRules learns\nboth the discretizations of individual features, as well as their combination\ninto conjunctive rules without any pre-processing or restrictions. Extensive\nexperiments demonstrate that NeuRules consistently outperforms both\ncombinatorial and neuro-symbolic methods, effectively learning simple and\ncomplex rules, as well as their order, across a wide range of datasets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06428v1",
    "published_date": "2024-11-10 11:10:36 UTC",
    "updated_date": "2024-11-10 11:10:36 UTC"
  },
  {
    "arxiv_id": "2411.06426v2",
    "title": "SequentialBreak: Large Language Models Can be Fooled by Embedding Jailbreak Prompts into Sequential Prompt Chains",
    "authors": [
      "Bijoy Ahmed Saiem",
      "MD Sadik Hossain Shanto",
      "Rakib Ahsan",
      "Md Rafi ur Rashid"
    ],
    "abstract": "As the integration of the Large Language Models (LLMs) into various\napplications increases, so does their susceptibility to misuse, raising\nsignificant security concerns. Numerous jailbreak attacks have been proposed to\nassess the security defense of LLMs. Current jailbreak attacks mainly rely on\nscenario camouflage, prompt obfuscation, prompt optimization, and prompt\niterative optimization to conceal malicious prompts. In particular, sequential\nprompt chains in a single query can lead LLMs to focus on certain prompts while\nignoring others, facilitating context manipulation. This paper introduces\nSequentialBreak, a novel jailbreak attack that exploits this vulnerability. We\ndiscuss several scenarios, not limited to examples like Question Bank, Dialog\nCompletion, and Game Environment, where the harmful prompt is embedded within\nbenign ones that can fool LLMs into generating harmful responses. The distinct\nnarrative structures of these scenarios show that SequentialBreak is flexible\nenough to adapt to various prompt formats beyond those discussed. Extensive\nexperiments demonstrate that SequentialBreak uses only a single query to\nachieve a substantial gain of attack success rate over existing baselines\nagainst both open-source and closed-source models. Through our research, we\nhighlight the urgent need for more robust and resilient safeguards to enhance\nLLM security and prevent potential misuse. All the result files and website\nassociated with this research are available in this GitHub repository:\nhttps://anonymous.4open.science/r/JailBreakAttack-4F3B/.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06426v2",
    "published_date": "2024-11-10 11:08:28 UTC",
    "updated_date": "2025-02-14 16:32:54 UTC"
  },
  {
    "arxiv_id": "2411.06420v1",
    "title": "Generating Mixcode Popular Songs with Artificial Intelligence: Concepts, Plans, and Speculations",
    "authors": [
      "Abhishek Kaushik",
      "Kayla Rush"
    ],
    "abstract": "Music is a potent form of expression that can communicate, accentuate or even\ncreate the emotions of an individual or a collective. Both historically and in\ncontemporary experiences, musical expression was and is commonly\ninstrumentalized for social, political and/or economic purposes. Generative\nartificial intelligence provides a wealth of both opportunities and challenges\nwith regard to music and its role in society. This paper discusses a proposed\nproject integrating artificial intelligence and popular music, with the\nultimate goal of creating a powerful tool for implementing music for social\ntransformation, education, healthcare, and emotional well-being. Given that it\nis being presented at the outset of a collaboration between a computer\nscientist/data analyst and an ethnomusicologist/social anthropologist. it is\nmainly conceptual and somewhat speculative in nature.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "Link to the paper:https://aimc2024.pubpub.org/pub/rdulfbve/release/1\n  Published in The International Conference on AI and Musical Creativity at the\n  University of Oxford (2024) https://aimc2024.pubpub.org/",
    "pdf_url": "http://arxiv.org/pdf/2411.06420v1",
    "published_date": "2024-11-10 10:49:13 UTC",
    "updated_date": "2024-11-10 10:49:13 UTC"
  },
  {
    "arxiv_id": "2411.06409v1",
    "title": "Automated Strategy Invention for Confluence of Term Rewrite Systems",
    "authors": [
      "Liao Zhang",
      "Fabian Mitterwallner",
      "Jan Jakubuv",
      "Cezary Kaliszyk"
    ],
    "abstract": "Term rewriting plays a crucial role in software verification and compiler\noptimization. With dozens of highly parameterizable techniques developed to\nprove various system properties, automatic term rewriting tools work in an\nextensive parameter space. This complexity exceeds human capacity for parameter\nselection, motivating an investigation into automated strategy invention. In\nthis paper, we focus on confluence, an important property of term rewrite\nsystems, and apply machine learning to develop the first learning-guided\nautomatic confluence prover. Moreover, we randomly generate a large dataset to\nanalyze confluence for term rewrite systems. Our results focus on improving the\nstate-of-the-art automatic confluence prover CSI: When equipped with our\ninvented strategies, it surpasses its human-designed strategies both on the\naugmented dataset and on the original human-created benchmark dataset Cops,\nproving/disproving the confluence of several term rewrite systems for which no\nautomated proofs were known before.",
    "categories": [
      "cs.LO",
      "cs.AI",
      "F.4.2; I.2.8"
    ],
    "primary_category": "cs.LO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06409v1",
    "published_date": "2024-11-10 10:08:43 UTC",
    "updated_date": "2024-11-10 10:08:43 UTC"
  },
  {
    "arxiv_id": "2411.06403v1",
    "title": "Mastering NIM and Impartial Games with Weak Neural Networks: An AlphaZero-inspired Multi-Frame Approach",
    "authors": [
      "Søren Riis"
    ],
    "abstract": "This paper provides a theoretical framework that validates and explains the\nresults in the work with Bei Zhou experimentally finding that AlphaZero-style\nreinforcement learning algorithms struggle to learn optimal play in NIM, a\ncanonical impartial game proposed as an AI challenge by Harvey Friedman in\n2017. Our analysis resolves a controversy around these experimental results,\nwhich revealed unexpected difficulties in learning NIM despite its mathematical\nsimplicity compared to games like chess and Go.\n  Our key contributions are as follows:\n  We prove that by incorporating recent game history, these limited AlphaZero\nmodels can, in principle, achieve optimal play in NIM.\n  We introduce a novel search strategy where roll-outs preserve game-theoretic\nvalues during move selection, guided by a specialised policy network.\n  We provide constructive proofs showing that our approach enables optimal play\nwithin the \\(\\text{AC}^0\\) complexity class despite the theoretical limitations\nof these networks.\n  This research demonstrates how constrained neural networks when properly\ndesigned, can achieve sophisticated decision-making even in domains where their\nbasic computational capabilities appear insufficient.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06403v1",
    "published_date": "2024-11-10 09:34:26 UTC",
    "updated_date": "2024-11-10 09:34:26 UTC"
  },
  {
    "arxiv_id": "2411.06402v1",
    "title": "Fineweb-Edu-Ar: Machine-translated Corpus to Support Arabic Small Language Models",
    "authors": [
      "Sultan Alrashed",
      "Dmitrii Khizbullin",
      "David R. Pugh"
    ],
    "abstract": "As large language models (LLMs) grow and develop, so do their data demands.\nThis is especially true for multilingual LLMs, where the scarcity of\nhigh-quality and readily available data online has led to a multitude of\nsynthetic dataset generation approaches. A key technique in this space is\nmachine translation (MT), where high-quality English text is adapted to a\ntarget, comparatively low-resource language. This report introduces\nFineWeb-Edu-Ar, a machine-translated version of the exceedingly popular\n(deduplicated) FineWeb-Edu dataset from HuggingFace. To the best of our\nknowledge, FineWeb-Edu-Ar is the largest publicly available machine-translated\nArabic dataset out there, with its size of 202B tokens of an Arabic-trained\ntokenizer.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06402v1",
    "published_date": "2024-11-10 09:29:51 UTC",
    "updated_date": "2024-11-10 09:29:51 UTC"
  },
  {
    "arxiv_id": "2411.06396v1",
    "title": "A Variance Minimization Approach to Temporal-Difference Learning",
    "authors": [
      "Xingguo Chen",
      "Yu Gong",
      "Shangdong Yang",
      "Wenhao Wang"
    ],
    "abstract": "Fast-converging algorithms are a contemporary requirement in reinforcement\nlearning. In the context of linear function approximation, the magnitude of the\nsmallest eigenvalue of the key matrix is a major factor reflecting the\nconvergence speed. Traditional value-based RL algorithms focus on minimizing\nerrors. This paper introduces a variance minimization (VM) approach for\nvalue-based RL instead of error minimization. Based on this approach, we\nproposed two objectives, the Variance of Bellman Error (VBE) and the Variance\nof Projected Bellman Error (VPBE), and derived the VMTD, VMTDC, and VMETD\nalgorithms. We provided proofs of their convergence and optimal policy\ninvariance of the variance minimization. Experimental studies validate the\neffectiveness of the proposed algorithms.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06396v1",
    "published_date": "2024-11-10 08:56:16 UTC",
    "updated_date": "2024-11-10 08:56:16 UTC"
  },
  {
    "arxiv_id": "2411.06391v1",
    "title": "CausalStock: Deep End-to-end Causal Discovery for News-driven Stock Movement Prediction",
    "authors": [
      "Shuqi Li",
      "Yuebo Sun",
      "Yuxin Lin",
      "Xin Gao",
      "Shuo Shang",
      "Rui Yan"
    ],
    "abstract": "There are two issues in news-driven multi-stock movement prediction tasks\nthat are not well solved in the existing works. On the one hand, \"relation\ndiscovery\" is a pivotal part when leveraging the price information of other\nstocks to achieve accurate stock movement prediction. Given that stock\nrelations are often unidirectional, such as the \"supplier-consumer\"\nrelationship, causal relations are more appropriate to capture the impact\nbetween stocks. On the other hand, there is substantial noise existing in the\nnews data leading to extracting effective information with difficulty. With\nthese two issues in mind, we propose a novel framework called CausalStock for\nnews-driven multi-stock movement prediction, which discovers the temporal\ncausal relations between stocks. We design a lag-dependent temporal causal\ndiscovery mechanism to model the temporal causal graph distribution. Then a\nFunctional Causal Model is employed to encapsulate the discovered causal\nrelations and predict the stock movements. Additionally, we propose a Denoised\nNews Encoder by taking advantage of the excellent text evaluation ability of\nlarge language models (LLMs) to extract useful information from massive news\ndata. The experiment results show that CausalStock outperforms the strong\nbaselines for both news-driven multi-stock movement prediction and multi-stock\nmovement prediction tasks on six real-world datasets collected from the US,\nChina, Japan, and UK markets. Moreover, getting benefit from the causal\nrelations, CausalStock could offer a clear prediction mechanism with good\nexplainability.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.06391v1",
    "published_date": "2024-11-10 08:24:03 UTC",
    "updated_date": "2024-11-10 08:24:03 UTC"
  },
  {
    "arxiv_id": "2411.06387v4",
    "title": "Self-Training Meets Consistency: Improving LLMs' Reasoning with Consistency-Driven Rationale Evaluation",
    "authors": [
      "Jaehyeok Lee",
      "Keisuke Sakaguchi",
      "JinYeong Bak"
    ],
    "abstract": "Self-training approach for large language models (LLMs) improves reasoning\nabilities by training the models on their self-generated rationales. Previous\napproaches have labeled rationales that produce correct answers for a given\nquestion as appropriate for training. However, a single measure risks\nmisjudging rationale quality, leading the models to learn flawed reasoning\npatterns. To address this issue, we propose CREST (Consistency-driven Rationale\nEvaluation for Self-Training), a self-training framework that further evaluates\neach rationale through follow-up questions and leverages this evaluation to\nguide its training. Specifically, we introduce two methods: (1) filtering out\nrationales that frequently result in incorrect answers on follow-up questions\nand (2) preference learning based on mixed preferences from rationale\nevaluation results of both original and follow-up questions. Experiments on\nthree question-answering datasets using open LLMs show that CREST not only\nimproves the logical robustness and correctness of rationales but also improves\nreasoning abilities compared to previous self-training approaches.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to NAACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2411.06387v4",
    "published_date": "2024-11-10 08:11:05 UTC",
    "updated_date": "2025-02-06 07:07:28 UTC"
  },
  {
    "arxiv_id": "2411.06385v1",
    "title": "Class Granularity: How richly does your knowledge graph represent the real world?",
    "authors": [
      "Sumin Seo",
      "Heeseon Cheon",
      "Hyunho Kim"
    ],
    "abstract": "To effectively manage and utilize knowledge graphs, it is crucial to have\nmetrics that can assess the quality of knowledge graphs from various\nperspectives. While there have been studies on knowledge graph quality metrics,\nthere has been a lack of research on metrics that measure how richly\nontologies, which form the backbone of knowledge graphs, are defined or the\nimpact of richly defined ontologies. In this study, we propose a new metric\ncalled Class Granularity, which measures how well a knowledge graph is\nstructured in terms of how finely classes with unique characteristics are\ndefined. Furthermore, this research presents potential impact of Class\nGranularity in knowledge graph's on downstream tasks. In particular, we explore\nits influence on graph embedding and provide experimental results.\nAdditionally, this research goes beyond traditional Linked Open Data comparison\nstudies, which mainly focus on factors like scale and class distribution, by\nusing Class Granularity to compare four different LOD sources.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2411.06385v1",
    "published_date": "2024-11-10 07:57:39 UTC",
    "updated_date": "2024-11-10 07:57:39 UTC"
  },
  {
    "arxiv_id": "2411.06376v2",
    "title": "Project Tracyn: Generative Artificial Intelligence based Peripherals Trace Synthesizer",
    "authors": [
      "Zhibai Huang",
      "Yihan Shen",
      "Yongchen Xie",
      "Zhixiang Wei",
      "Yun wang",
      "Fangxin Liu",
      "Tao Song",
      "Zhengwei Qi"
    ],
    "abstract": "Peripheral Component Interconnect Express (PCIe) is the de facto interconnect\nstandard for high-speed peripherals and CPUs. Prototyping and optimizing PCIe\ndevices for emerging scenarios is an ongoing challenge. Since Transaction Layer\nPackets (TLPs) capture device-CPU interactions, it is crucial to analyze and\ngenerate realistic TLP traces for effective device design and optimization.\nGenerative AI offers a promising approach for creating intricate, custom TLP\ntraces necessary for PCIe hardware and software development. However, existing\nmodels often generate impractical traces due to the absence of PCIe-specific\nconstraints, such as TLP ordering and causality. This paper presents Phantom,\nthe first framework that treats TLP trace generation as a generative AI problem\nwhile incorporating PCIe-specific constraints. We validate Phantom's\neffectiveness by generating TLP traces for an actual PCIe network interface\ncard. Experimental results show that Phantom produces practical, large-scale\nTLP traces, significantly outperforming existing models, with improvements of\nup to 1000$\\times$ in task-specific metrics and up to 2.19$\\times$ in Frechet\nInception Distance (FID) compared to backbone-only methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06376v2",
    "published_date": "2024-11-10 07:15:03 UTC",
    "updated_date": "2025-01-13 14:39:34 UTC"
  },
  {
    "arxiv_id": "2411.14449v2",
    "title": "Unlearn to Relearn Backdoors: Deferred Backdoor Functionality Attacks on Deep Learning Models",
    "authors": [
      "Jeongjin Shin",
      "Sangdon Park"
    ],
    "abstract": "Deep learning models are vulnerable to backdoor attacks, where adversaries\ninject malicious functionality during training that activates on trigger inputs\nat inference time. Extensive research has focused on developing stealthy\nbackdoor attacks to evade detection and defense mechanisms. However, these\napproaches still have limitations that leave the door open for detection and\nmitigation due to their inherent design to cause malicious behavior in the\npresence of a trigger. To address this limitation, we introduce Deferred\nActivated Backdoor Functionality (DABF), a new paradigm in backdoor attacks.\nUnlike conventional attacks, DABF initially conceals its backdoor, producing\nbenign outputs even when triggered. This stealthy behavior allows DABF to\nbypass multiple detection and defense methods, remaining undetected during\ninitial inspections. The backdoor functionality is strategically activated only\nafter the model undergoes subsequent updates, such as retraining on benign\ndata. DABF attacks exploit the common practice in the life cycle of machine\nlearning models to perform model updates and fine-tuning after initial\ndeployment. To implement DABF attacks, we approach the problem by making the\nunlearning of the backdoor fragile, allowing it to be easily cancelled and\nsubsequently reactivate the backdoor functionality. To achieve this, we propose\na novel two-stage training scheme, called DeferBad. Our extensive experiments\nacross various fine-tuning scenarios, backdoor attack types, datasets, and\nmodel architectures demonstrate the effectiveness and stealthiness of DeferBad.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.14449v2",
    "published_date": "2024-11-10 07:01:53 UTC",
    "updated_date": "2024-11-25 06:51:39 UTC"
  },
  {
    "arxiv_id": "2411.06367v1",
    "title": "BayesNAM: Leveraging Inconsistency for Reliable Explanations",
    "authors": [
      "Hoki Kim",
      "Jinseong Park",
      "Yujin Choi",
      "Seungyun Lee",
      "Jaewook Lee"
    ],
    "abstract": "Neural additive model (NAM) is a recently proposed explainable artificial\nintelligence (XAI) method that utilizes neural network-based architectures.\nGiven the advantages of neural networks, NAMs provide intuitive explanations\nfor their predictions with high model performance. In this paper, we analyze a\ncritical yet overlooked phenomenon: NAMs often produce inconsistent\nexplanations, even when using the same architecture and dataset. Traditionally,\nsuch inconsistencies have been viewed as issues to be resolved. However, we\nargue instead that these inconsistencies can provide valuable explanations\nwithin the given data model. Through a simple theoretical framework, we\ndemonstrate that these inconsistencies are not mere artifacts but emerge\nnaturally in datasets with multiple important features. To effectively leverage\nthis information, we introduce a novel framework, Bayesian Neural Additive\nModel (BayesNAM), which integrates Bayesian neural networks and feature\ndropout, with theoretical proof demonstrating that feature dropout effectively\ncaptures model inconsistencies. Our experiments demonstrate that BayesNAM\neffectively reveals potential problems such as insufficient data or structural\nlimitations of the model, providing more reliable explanations and potential\nremedies.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "Under Review",
    "pdf_url": "http://arxiv.org/pdf/2411.06367v1",
    "published_date": "2024-11-10 05:55:25 UTC",
    "updated_date": "2024-11-10 05:55:25 UTC"
  },
  {
    "arxiv_id": "2411.06363v1",
    "title": "Layer-Wise Feature Metric of Semantic-Pixel Matching for Few-Shot Learning",
    "authors": [
      "Hao Tang",
      "Junhao Lu",
      "Guoheng Huang",
      "Ming Li",
      "Xuhang Chen",
      "Guo Zhong",
      "Zhengguang Tan",
      "Zinuo Li"
    ],
    "abstract": "In Few-Shot Learning (FSL), traditional metric-based approaches often rely on\nglobal metrics to compute similarity. However, in natural scenes, the spatial\narrangement of key instances is often inconsistent across images. This spatial\nmisalignment can result in mismatched semantic pixels, leading to inaccurate\nsimilarity measurements. To address this issue, we propose a novel method\ncalled the Layer-Wise Features Metric of Semantic-Pixel Matching (LWFM-SPM) to\nmake finer comparisons. Our method enhances model performance through two key\nmodules: (1) the Layer-Wise Embedding (LWE) Module, which refines the\ncross-correlation of image pairs to generate well-focused feature maps for each\nlayer; (2)the Semantic-Pixel Matching (SPM) Module, which aligns critical\npixels based on semantic embeddings using an assignment algorithm. We conducted\nextensive experiments to evaluate our method on four widely used few-shot\nclassification benchmarks: miniImageNet, tieredImageNet, CUB-200-2011, and\nCIFAR-FS. The results indicate that LWFM-SPM achieves competitive performance\nacross these benchmarks. Our code will be publicly available on\nhttps://github.com/Halo2Tang/Code-for-LWFM-SPM.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06363v1",
    "published_date": "2024-11-10 05:12:24 UTC",
    "updated_date": "2024-11-10 05:12:24 UTC"
  },
  {
    "arxiv_id": "2411.06353v2",
    "title": "Deep Active Learning in the Open World",
    "authors": [
      "Tian Xie",
      "Jifan Zhang",
      "Haoyue Bai",
      "Robert Nowak"
    ],
    "abstract": "Machine learning models deployed in open-world scenarios often encounter\nunfamiliar conditions and perform poorly in unanticipated situations. As AI\nsystems advance and find application in safety-critical domains, effectively\nhandling out-of-distribution (OOD) data is crucial to building open-world\nlearning systems. In this work, we introduce ALOE, a novel active learning\nalgorithm for open-world environments designed to enhance model adaptation by\nincorporating new OOD classes via a two-stage approach. First, diversity\nsampling selects a representative set of examples, followed by energy-based OOD\ndetection to prioritize likely unknown classes for annotation. This strategy\naccelerates class discovery and learning, even under constrained annotation\nbudgets. Evaluations on three long-tailed image classification benchmarks\ndemonstrate that ALOE outperforms traditional active learning baselines,\neffectively expanding known categories while balancing annotation cost. Our\nfindings reveal a crucial tradeoff between enhancing known-class performance\nand discovering new classes, setting the stage for future advancements in\nopen-world machine learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06353v2",
    "published_date": "2024-11-10 04:04:20 UTC",
    "updated_date": "2025-04-19 00:44:17 UTC"
  },
  {
    "arxiv_id": "2411.06336v1",
    "title": "Balancing Power and Ethics: A Framework for Addressing Human Rights Concerns in Military AI",
    "authors": [
      "Mst Rafia Islam",
      "Azmine Toushik Wasi"
    ],
    "abstract": "AI has made significant strides recently, leading to various applications in\nboth civilian and military sectors. The military sees AI as a solution for\ndeveloping more effective and faster technologies. While AI offers benefits\nlike improved operational efficiency and precision targeting, it also raises\nserious ethical and legal concerns, particularly regarding human rights\nviolations. Autonomous weapons that make decisions without human input can\nthreaten the right to life and violate international humanitarian law. To\naddress these issues, we propose a three-stage framework (Design, In\nDeployment, and During/After Use) for evaluating human rights concerns in the\ndesign, deployment, and use of military AI. Each phase includes multiple\ncomponents that address various concerns specific to that phase, ranging from\nbias and regulatory issues to violations of International Humanitarian Law. By\nthis framework, we aim to balance the advantages of AI in military operations\nwith the need to protect human rights.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CE",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "Accepted for oral (only 3 papers are selected!) Harms and Risks of AI\n  in the Military Workshop (HRAIM 2024) at Mila Quebec\n  (https://www.harms-risks-ai-military.org/accepted-abstracts.html#:~:text=Balancing%20Power%20and%20Ethics)",
    "pdf_url": "http://arxiv.org/pdf/2411.06336v1",
    "published_date": "2024-11-10 02:27:01 UTC",
    "updated_date": "2024-11-10 02:27:01 UTC"
  },
  {
    "arxiv_id": "2411.16694v1",
    "title": "Reaction-conditioned De Novo Enzyme Design with GENzyme",
    "authors": [
      "Chenqing Hua",
      "Jiarui Lu",
      "Yong Liu",
      "Odin Zhang",
      "Jian Tang",
      "Rex Ying",
      "Wengong Jin",
      "Guy Wolf",
      "Doina Precup",
      "Shuangjia Zheng"
    ],
    "abstract": "The introduction of models like RFDiffusionAA, AlphaFold3, AlphaProteo, and\nChai1 has revolutionized protein structure modeling and interaction prediction,\nprimarily from a binding perspective, focusing on creating ideal lock-and-key\nmodels. However, these methods can fall short for enzyme-substrate\ninteractions, where perfect binding models are rare, and induced fit states are\nmore common. To address this, we shift to a functional perspective for enzyme\ndesign, where the enzyme function is defined by the reaction it catalyzes.\nHere, we introduce \\textsc{GENzyme}, a \\textit{de novo} enzyme design model\nthat takes a catalytic reaction as input and generates the catalytic pocket,\nfull enzyme structure, and enzyme-substrate binding complex. \\textsc{GENzyme}\nis an end-to-end, three-staged model that integrates (1) a catalytic pocket\ngeneration and sequence co-design module, (2) a pocket inpainting and enzyme\ninverse folding module, and (3) a binding and screening module to optimize and\npredict enzyme-substrate complexes. The entire design process is driven by the\ncatalytic reaction being targeted. This reaction-first approach allows for more\naccurate and biologically relevant enzyme design, potentially surpassing\nstructure-based and binding-focused models in creating enzymes capable of\ncatalyzing specific reactions. We provide \\textsc{GENzyme} code at\nhttps://github.com/WillHua127/GENzyme.",
    "categories": [
      "q-bio.BM",
      "cs.AI"
    ],
    "primary_category": "q-bio.BM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.16694v1",
    "published_date": "2024-11-10 00:37:26 UTC",
    "updated_date": "2024-11-10 00:37:26 UTC"
  },
  {
    "arxiv_id": "2411.06316v1",
    "title": "Prompts Matter: Comparing ML/GAI Approaches for Generating Inductive Qualitative Coding Results",
    "authors": [
      "John Chen",
      "Alexandros Lotsos",
      "Lexie Zhao",
      "Grace Wang",
      "Uri Wilensky",
      "Bruce Sherin",
      "Michael Horn"
    ],
    "abstract": "Inductive qualitative methods have been a mainstay of education research for\ndecades, yet it takes much time and effort to conduct rigorously. Recent\nadvances in artificial intelligence, particularly with generative AI (GAI),\nhave led to initial success in generating inductive coding results. Like human\ncoders, GAI tools rely on instructions to work, and how to instruct it may\nmatter. To understand how ML/GAI approaches could contribute to qualitative\ncoding processes, this study applied two known and two theory-informed novel\napproaches to an online community dataset and evaluated the resulting coding\nresults. Our findings show significant discrepancies between ML/GAI approaches\nand demonstrate the advantage of our approaches, which introduce human coding\nprocesses into GAI prompts.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by AERA 2025 Annual Meeting",
    "pdf_url": "http://arxiv.org/pdf/2411.06316v1",
    "published_date": "2024-11-10 00:23:55 UTC",
    "updated_date": "2024-11-10 00:23:55 UTC"
  }
]