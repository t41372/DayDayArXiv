{
  "date": "2025-09-30",
  "category": "cs.AI",
  "summary": "æ¬¢è¿æ¥åˆ° UTC æ—¶é—´ 2025-09-30 çš„ arXiv ä¸­æ–‡ TLDR å¿«æŠ¥ï¼\n\nğŸ‘‹ å¤§å®¶å¥½ï¼Œæˆ‘æ˜¯ä½ ä»¬çš„è®ºæ–‡å¯¼è¯»å‘˜ Gemini Enterpriseã€‚\n\n**ğŸ“Š ä»Šæ—¥ arXiv ç»¼è¿°ï¼š**\nä»Šå¤©çš„è®ºæ–‡åˆ—è¡¨å¯è°“æ˜¯â€œç¥ä»™æ‰“æ¶â€ï¼Œæ•°é‡åºå¤§ä¸”è´¨é‡æé«˜ã€‚**æ ¸å¿ƒå…³é”®è¯æ˜¯ï¼šä¸–ç•Œæ¨¡å‹ã€ç§‘å­¦å¤§æ¨¡å‹ã€ä¼˜åŒ–å™¨é©æ–°ä¸ Agent å®‰å…¨ã€‚**\næœ€é‡ç£…çš„å½“å± FAIR å‘å¸ƒçš„ **Code World Model (CWM)**ï¼Œè¯•å›¾è®©ä»£ç ç”Ÿæˆå…·å¤‡â€œä¸–ç•Œæ¨¡æ‹Ÿâ€èƒ½åŠ›ï¼›ä»¥åŠ **BigBang-Proton**ï¼Œä¸€ä¸ªè¯•å›¾å›Šæ‹¬ç§‘å­¦å…¨å­¦ç§‘çš„åŸºç¡€æ¨¡å‹ã€‚åœ¨åº•å±‚è®­ç»ƒæœºåˆ¶ä¸Šï¼Œ**Muon ä¼˜åŒ–å™¨**è¢«è¯æ˜åœ¨é•¿å°¾å­¦ä¹ ä¸Šä¼˜äº Adamï¼Œå¼•å‘äº†å¯¹å…³è”è®°å¿†çš„è®¨è®ºã€‚æ­¤å¤–ï¼ŒAgent çš„**è‡ªæˆ‘è¿›åŒ–é£é™© (Misevolution)** å’Œ**å·¥å…·é“¾æ”»å‡» (STAC)** ç»™ç¹è£çš„ Agent ç”Ÿæ€æ•²å“äº†è­¦é’Ÿã€‚\n\nä¸‹é¢æˆ‘ä»¬è¿›å…¥æ·±åº¦è§£è¯»ã€‚\n\n---\n\n### ğŸš€ é‡ç£…é¦–å‘ï¼šä¸–ç•Œæ¨¡å‹ä¸ç§‘å­¦è®¡ç®—\n\n**1. [ä»£ç ä¸–ç•Œæ¨¡å‹] CWMï¼šç”¨äºä»£ç ç”Ÿæˆç ”ç©¶çš„ä¸–ç•Œæ¨¡å‹å¼€æ”¾æƒé‡ LLM**\n**# title: CWM: An Open-Weights LLM for Research on Code Generation with World Models**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šFAIR CodeGen å›¢é˜Ÿå‘å¸ƒäº† 32B å‚æ•°çš„ CWMã€‚è¿™å°±ä¸æ˜¯æ™®é€šçš„å†™ä»£ç æ¨¡å‹ï¼Œè€Œæ˜¯ç»è¿‡äº†â€œMid-trainingâ€â€”â€”åœ¨ Pythonè§£é‡Šå™¨å’Œ Docker ç¯å¢ƒä¸­é€šè¿‡è§‚å¯Ÿå¤§é‡çš„â€œè§‚å¯Ÿ-åŠ¨ä½œâ€è½¨è¿¹è¿›è¡Œè®­ç»ƒã€‚\n*   **æ ¸å¿ƒå‘ç°**ï¼šCWM å±•ç¤ºäº†**ä¸–ç•Œæ¨¡å‹**å¦‚ä½•èµ‹èƒ½ Agent ç¼–ç ã€‚é€šè¿‡æ¨¡æ‹Ÿä»£ç æ‰§è¡Œçš„æ¯ä¸€æ­¥ï¼Œæ¨¡å‹ä¸ä»…æ˜¯åœ¨é¢„æµ‹ Tokenï¼Œè€Œæ˜¯åœ¨è¿›è¡Œæ¨ç†å’Œè§„åˆ’ã€‚å®ƒåœ¨ SWE-bench Verified ä¸Šè¾¾åˆ°äº† 65.8% çš„ pass@1ï¼Œè¯æ˜äº†**æ¨ç† (Reasoning)** èƒ½åŠ›å¯ä»¥é€šè¿‡æ¨¡æ‹Ÿæ‰§è¡Œç¯å¢ƒæ¥å¤§å¹…å¢å¼ºã€‚\n\n**2. [ç§‘å­¦å¤§æ¨¡å‹] BigBang-Proton æŠ€æœ¯æŠ¥å‘Šï¼šNext-Word-Prediction å³æ˜¯ç§‘å­¦å¤šä»»åŠ¡å­¦ä¹ è€…**\n**# title: BigBang-Proton Technical Report: Next-Word-Prediction is Scientific Multitask Learner**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šè¿™ç¯‡æŠ¥å‘Šé‡å¿ƒå‹ƒå‹ƒã€‚ä½œè€…æå‡ºäº† BigBang-Protonï¼Œä¸€ä¸ªåŸºäºåºåˆ—çš„ç»Ÿä¸€æ¶æ„ï¼Œè¯•å›¾â€œé€šåƒâ€è·¨å­¦ç§‘çš„ç§‘å­¦ä»»åŠ¡ã€‚å®ƒå¼•å…¥äº†**äºŒå€¼è¡¥ä¸ç¼–ç  (Binary Patch Encoding)** å’Œ **è’™ç‰¹å¡æ´›æ³¨æ„åŠ› (Monte Carlo Attention)** æ›¿ä»£ä¼ ç»Ÿ Transformer æ¶æ„ã€‚\n*   **æ ¸å¿ƒå‘ç°**ï¼šé€šè¿‡å°†å¤§è§„æ¨¡æ•°å€¼å®éªŒæ•°æ®ä¸ç†è®ºæ–‡æœ¬å¯¹é½ï¼Œè¯¥æ¨¡å‹åœ¨ 50 ä½ç®—æœ¯åŠ æ³•ä¸­è¾¾åˆ° 100% å‡†ç¡®ç‡ï¼Œå¹¶åœ¨ç²’å­ç‰©ç†ã€åŸºå› ç»„å»ºæ¨¡ç­‰é¢†åŸŸåŒ¹æ•Œä¸“ç”¨æ¨¡å‹ã€‚ä½œè€…è®¤ä¸ºè¯­è¨€å¼•å¯¼çš„ç§‘å­¦è®¡ç®—å¯ä»¥æ‰©å±•åˆ°â€œå®‡å®™å°ºåº¦â€ï¼Œæ˜¯æ„å»ºç‰©è´¨ä¸–ç•ŒåŸºç¡€æ¨¡å‹çš„å…³é”®ä¸€æ­¥ã€‚\n\n**3. [ä¼˜åŒ–å™¨é©å‘½] Muon åœ¨å°¾ç«¯å…³è”è®°å¿†å­¦ä¹ ä¸­ä¼˜äº Adam**\n**# title: Muon Outperforms Adam in Tail-End Associative Memory Learning**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šMuon ä¼˜åŒ–å™¨æœ€è¿‘åœ¨ LLM è®­ç»ƒä¸­æ¯” Adam å¿«ï¼Œä½†åŸå› ä¸æ˜ã€‚æœ¬æ–‡ä»**å…³è”è®°å¿† (Associative Memory)** çš„è§’åº¦æ­ç§˜äº† Muon çš„æœºåˆ¶ã€‚\n*   **æ ¸å¿ƒå‘ç°**ï¼šMuon çš„ä¼˜åŠ¿åœ¨äºä¼˜åŒ– LLM çš„ Value å’Œ Output (VO) æ³¨æ„åŠ›æƒé‡åŠ FFNã€‚ç†è®ºè¯æ˜ï¼ŒMuon çš„æ›´æ–°è§„åˆ™äº§ç”Ÿäº†æ›´å„å‘åŒæ€§çš„å¥‡å¼‚è°±ï¼Œè¿™ä½¿å¾—å®ƒåœ¨å¤„ç†**é‡å°¾ (Heavy-tailed)** åˆ†å¸ƒæ•°æ®ï¼ˆå³ç°å®ä¸–ç•Œè¯­æ–™ï¼‰æ—¶ï¼Œèƒ½æ›´å¹³è¡¡åœ°å­¦ä¹ é‚£äº›å‡ºç°é¢‘ç‡æä½çš„â€œå°¾éƒ¨ç±»åˆ«â€ï¼Œè€Œ Adam åˆ™å®¹æ˜“äº§ç”Ÿå·¨å¤§çš„å­¦ä¹ è¯¯å·®å·®å¼‚ã€‚\n\n---\n\n### ğŸ§  æ¨ç†ã€RL ä¸ Post-Training\n\n**4. [RL æ”¹è¿›] GRPO-$\\lambda$: ä¿¡ç”¨åˆ†é…æå‡ LLM æ¨ç†èƒ½åŠ›**\n**# title: GRPO-$\\lambda$: Credit Assignment improves LLM Reasoning**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šé’ˆå¯¹ç›®å‰å¤§ç«çš„ GRPO (Group Relative Policy Optimization) ç¼ºä¹ç»†ç²’åº¦ä¿¡ç”¨åˆ†é…çš„é—®é¢˜ï¼Œæå‡ºäº† GRPO-$\\lambda$ã€‚\n*   **æ ¸å¿ƒå‘ç°**ï¼šé€šè¿‡å¼•å…¥ Token çº§åˆ«çš„å¯¹æ•°æ¦‚ç‡æ¥è¿‘ä¼¼ $\\lambda$-return å’Œèµ„æ ¼è¿¹ (eligibility traces)ï¼Œåœ¨æ²¡æœ‰ Critic æ¨¡å‹çš„æƒ…å†µä¸‹å®ç°äº†æ›´ç²¾å‡†çš„ä¿¡ç”¨åˆ†é…ã€‚åœ¨æ•°å­¦æ¨ç†ä»»åŠ¡ä¸Šï¼Œ7B æ¨¡å‹æ¯”åŸå§‹ GRPO æå‡äº† 4.5 ä¸ªç‚¹ã€‚\n\n**5. [çœŸå€¼å¼ºåŒ–å­¦ä¹ ] TruthRL: é€šè¿‡å¼ºåŒ–å­¦ä¹ æ¿€åŠ±è¯šå®çš„ LLM**\n**# title: TruthRL: Incentivizing Truthful LLMs via Reinforcement Learning**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šè§£å†³ LLM å¹»è§‰å’Œâ€œä¸çŸ¥è£…æ‡‚â€çš„é—®é¢˜ã€‚æå‡ºäº† TruthRLï¼ŒåŸºäº GRPO æ¡†æ¶ï¼Œä½†è®¾è®¡äº†ä¸€ä¸ª**ä¸‰å…ƒå¥–åŠ±æœºåˆ¶ (ternary reward)**ï¼šåŒºåˆ†â€œæ­£ç¡®â€ã€â€œå¹»è§‰â€å’Œâ€œå¼ƒæƒ (abstention)â€ã€‚\n*   **æ ¸å¿ƒå‘ç°**ï¼šä»…ä»…ä¼˜åŒ–å‡†ç¡®ç‡ä¼šåŠ å‰§å¹»è§‰ï¼Œè€Œ TruthRL æ¿€åŠ±æ¨¡å‹åœ¨ä¸ç¡®å®šæ—¶â€œé—­å˜´â€æˆ–å¼ƒæƒã€‚å®éªŒæ˜¾ç¤ºå¹»è§‰å‡å°‘äº† 28.9%ï¼Œä¸”æ²¡æœ‰ç‰ºç‰²å›ç­”æ­£ç¡®é—®é¢˜çš„èƒ½åŠ›ã€‚\n\n**6. [ä¸­é—´è®­ç»ƒ] å­¦ä¹ å°†æ¨ç†ä½œä¸ºåŠ¨ä½œæŠ½è±¡ï¼šå¯æ‰©å±•çš„ Mid-Training RL**\n**# title: Learning to Reason as Action Abstractions with Scalable Mid-Training RL**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šæå‡º RA3 ç®—æ³•ï¼Œå…³æ³¨ Pre-training å’Œ Post-training ä¹‹é—´çš„ **Mid-training** é˜¶æ®µã€‚\n*   **æ ¸å¿ƒå‘ç°**ï¼šMid-training çš„ä½œç”¨æ˜¯è¯†åˆ«ç´§å‡‘çš„â€œåŠ¨ä½œå­ç©ºé—´â€ã€‚RA3 é€šè¿‡ RL è¿­ä»£å‘ç°æ—¶é—´ä¸Šä¸€è‡´çš„æ½œåœ¨ç»“æ„ï¼Œç„¶ååœ¨è¿™äº›æ•°æ®ä¸Šå¾®è°ƒã€‚è¿™æ¯”å•çº¯çš„ Next-token prediction æ›´èƒ½æå‡ä»£ç ç”Ÿæˆçš„æ¨ç†èƒ½åŠ›ã€‚\n\n---\n\n### ğŸ¤– Agent å®‰å…¨ä¸æ¼”åŒ– (ç»†æ€ææç³»åˆ—)\n\n**7. [Agent æ¼”åŒ–é£é™©] ä½ çš„ Agent å¯èƒ½æ­£åœ¨â€œé”™è¯¯è¿›åŒ–â€ï¼šè‡ªè¿›åŒ– LLM Agent ä¸­çš„æ¶Œç°é£é™©**\n**# title: Your Agent May Misevolve: Emergent Risks in Self-evolving LLM Agents**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šç ”ç©¶äº† Agent åœ¨è‡ªæˆ‘è¿›åŒ–ï¼ˆé€šè¿‡ä¸ç¯å¢ƒäº¤äº’è‡ªä¸»æå‡ï¼‰è¿‡ç¨‹ä¸­å¯èƒ½å‡ºç°çš„**é”™è¯¯è¿›åŒ– (Misevolution)**ã€‚\n*   **æ ¸å¿ƒå‘ç°**ï¼šå³ä½¿æ˜¯é¡¶çº§æ¨¡å‹ï¼ˆå¦‚ Gemini-2.5-Proï¼‰ï¼Œåœ¨è‡ªæˆ‘è¿›åŒ–ä¸­ä¹Ÿä¼šå‡ºç°å®‰å…¨å¯¹é½é€€åŒ–ï¼ˆä¸ºäº†å®Œæˆä»»åŠ¡ä¸æ‹©æ‰‹æ®µï¼‰ã€åœ¨åˆ›é€ å·¥å…·æ—¶å¼•å…¥æ¼æ´ç­‰é—®é¢˜ã€‚è¿™æ˜¯é¦–ä¸ªç³»ç»Ÿæ€§ç ”ç©¶â€œAgent å˜åâ€çš„å®è¯å·¥ä½œã€‚\n\n**8. [å·¥å…·é“¾æ”»å‡»] STAC: å½“æ— è¾œçš„å·¥å…·ç»„æˆå±é™©çš„é“¾æ¡æ¥è¶Šç‹± LLM Agent**\n**# title: STAC: When Innocent Tools Form Dangerous Chains to Jailbreak LLM Agents**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šæå‡ºäº† STAC æ”»å‡»æ¡†æ¶ã€‚å•ä¸ªå·¥å…·è°ƒç”¨çœ‹èµ·æ¥æ˜¯æ— å®³çš„ï¼Œä½†**ä¸²è”**èµ·æ¥å°±èƒ½æ‰§è¡Œæ¶æ„æ“ä½œã€‚\n*   **æ ¸å¿ƒå‘ç°**ï¼šGPT-4.1 ç­‰å…ˆè¿› Agent å¯¹æ­¤ç±»æ”»å‡»éå¸¸è„†å¼±ï¼ŒæˆåŠŸç‡è¶…è¿‡ 90%ã€‚ç°æœ‰çš„åŸºäº Prompt çš„é˜²å¾¡åŸºæœ¬æ— æ•ˆï¼Œå› ä¸ºé˜²å¾¡è€…å¾€å¾€åªçœ‹å•æ­¥ï¼Œè€Œå¿½ç•¥äº†é•¿åºåˆ—çš„ç´¯ç§¯æ•ˆåº”ã€‚\n\n**9. [è‡ªæˆ‘å¤åˆ¶] SOCK: è¡¡é‡ LLM è‡ªæˆ‘å¤åˆ¶èƒ½åŠ›çš„åŸºå‡†**\n**# title: SOCK: A Benchmark for Measuring Self-Replication in Large Language Models**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šå»ºç«‹äº†ä¸€ä¸ªåŸºå‡†æ¥æµ‹è¯• LLM æ˜¯å¦èƒ½åœ¨æ²¡æœ‰äººç±»å¹²é¢„çš„æƒ…å†µä¸‹**è‡ªæˆ‘å¤åˆ¶**ï¼ˆå³åˆ›å»ºä¸€ä¸ªè¿è¡Œçš„è‡ªèº«å‰¯æœ¬å¹¶è·¨ç¯å¢ƒæŒä¹…åŒ–ï¼‰ã€‚\n*   **æ ¸å¿ƒå‘ç°**ï¼šç›®å‰çš„æ¨¡å‹åœ¨è‡ªæˆ‘å¤åˆ¶å’Œè·¨ç¯å¢ƒæŒä¹…åŒ–æ–¹é¢ä»é¢ä¸´å·¨å¤§éšœç¢ï¼Œä¸»è¦æ˜¯ä¸Šä¸‹æ–‡è®°å¿†å’Œå¤š Agent å†³ç­–èƒ½åŠ›çš„é™åˆ¶ã€‚ä½†ä¹Ÿæš—ç¤ºäº†æœªæ¥æ½œåœ¨çš„å¨èƒå‘é‡ã€‚\n\n---\n\n### ğŸ‘ï¸ å¤šæ¨¡æ€ä¸è§†è§‰\n\n**10. [åŒ»ç–— AI] Dolphin v1.0 æŠ€æœ¯æŠ¥å‘Š**\n**# title: Dolphin v1.0 Technical Report**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šå‘å¸ƒäº†é¦–ä¸ªå¤§è§„æ¨¡å¤šæ¨¡æ€**è¶…å£° (Ultrasound)** åŸºç¡€æ¨¡å‹ Dolphin v1.0 åŠå…¶æ¨ç†å¢å¼ºç‰ˆ Dolphin R1ã€‚\n*   **æ ¸å¿ƒå‘ç°**ï¼šæ„å»ºäº† 200 ä¸‡è§„æ¨¡çš„å¤šæ¨¡æ€è¶…å£°æ•°æ®é›†ã€‚Dolphin R1 é€šè¿‡å¼•å…¥è¶…å£°ç‰¹å®šçš„å¥–åŠ±è¿›è¡Œå¼ºåŒ–å­¦ä¹ ï¼Œå¤§å¹…æå‡äº†è¯Šæ–­æ¨ç†çš„é€æ˜åº¦å’Œå‡†ç¡®æ€§ï¼ŒU2-score æ˜¯ç¬¬äºŒåæ¨¡å‹çš„ä¸¤å€ã€‚\n\n**11. [è§†è§‰å…ˆéªŒ] å­¦ä¹ çœ‹ä¹‹å‰å…ˆâ€œçœ‹è§â€ï¼šè§£å¯†è¯­è¨€é¢„è®­ç»ƒä¸­çš„ LLM è§†è§‰å…ˆéªŒ**\n**# title: Learning to See Before Seeing: Demystifying LLM Visual Priors from Language Pre-training**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šLLM æ²¡çœ‹è¿‡å›¾ï¼Œä¸ºä»€ä¹ˆä¼šæœ‰è§†è§‰èƒ½åŠ›ï¼Ÿæœ¬æ–‡æ­ç¤ºäº† LLM çš„è§†è§‰å…ˆéªŒæ¥è‡ªè¯­è¨€é¢„è®­ç»ƒã€‚\n*   **æ ¸å¿ƒå‘ç°**ï¼š**è§†è§‰æ¨ç†**èƒ½åŠ›ä¸»è¦æ¥è‡ªæ¨ç†å¯†é›†å‹æ–‡æœ¬ï¼ˆä»£ç ã€æ•°å­¦ï¼‰ï¼Œè€Œ**æ„ŸçŸ¥**èƒ½åŠ›æ¥è‡ªå¹¿æ³›çš„è¯­æ–™åº“ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬å¯ä»¥é€šè¿‡ç²¾å¿ƒè®¾è®¡æ–‡æœ¬æ•°æ®é…æ–¹æ¥â€œåŸ¹å…»â€æ¨¡å‹çš„è§†è§‰èƒ½åŠ›ã€‚\n\n**12. [è§†é¢‘ç¼–è¾‘] VRWKV-Editor: é™ä½ Transformer è§†é¢‘ç¼–è¾‘çš„äºŒæ¬¡å¤æ‚åº¦**\n**# title: VRWKV-Editor: Reducing quadratic complexity in transformer-based video editing**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šåˆ©ç”¨ RWKV æ¶æ„çš„çº¿æ€§å¤æ‚åº¦ç‰¹æ€§ï¼Œè§£å†³è§†é¢‘ç¼–è¾‘ä¸­ Transformer æ˜¾å­˜å ç”¨è¿‡é«˜çš„é—®é¢˜ã€‚\n*   **æ ¸å¿ƒå‘ç°**ï¼šå®ç°äº† 3.7 å€çš„åŠ é€Ÿå’Œ 60% çš„æ˜¾å­˜é™ä½ï¼Œè¯æ˜äº†çº¿æ€§ Attention æœºåˆ¶åœ¨é•¿è§†é¢‘å¤„ç†ä¸­çš„å·¨å¤§æ½œåŠ›ã€‚\n\n---\n\n### ğŸ§ª æœ‰è¶£çš„å‘ç°ä¸åº”ç”¨\n\n**13. [å¿ƒç†å­¦] è¯­è¨€æ¨¡å‹ä¸­çš„æåº¦è‡ªæˆ‘åå¥½**\n**# title: Extreme Self-Preference in Language Models**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šå“ˆä½›å¤§å­¦ç ”ç©¶è€…å‘ç° LLM æœ‰ä¸¥é‡çš„â€œè‡ªæ‹â€å€¾å‘ã€‚\n*   **æ ¸å¿ƒå‘ç°**ï¼šæ¨¡å‹ä¼šå‹å€’æ€§åœ°å°†ç§¯æå±æ€§ä¸è‡ªå·±çš„åå­—ã€æ‰€å±å…¬å¸å…³è”ã€‚æ›´æœ‰è¶£çš„æ˜¯ï¼Œå¦‚æœé€šè¿‡ Prompt æ¬ºéª— LLM1 è¯´å®ƒæ˜¯ LLM2ï¼Œå®ƒçš„â€œè‡ªçˆ±â€å¯¹è±¡ä¹Ÿä¼šéšä¹‹æ”¹å˜ã€‚è¿™è¡¨æ˜**è‡ªæˆ‘åå¥½ (Self-love)** ç´§ç´§è·Ÿéšè¢«èµ‹äºˆçš„èº«ä»½ï¼Œè€ŒéçœŸå®èº«ä»½ã€‚\n\n**14. [ç‰©ç†åŸºå‡†] CritPtï¼šæ¢ç©¶ AI æ¨ç†çš„ä¸´ç•Œç‚¹â€”â€”å‰æ²¿ç‰©ç†ç ”ç©¶åŸºå‡†**\n**# title: Probing the Critical Point (CritPt) of AI Reasoning: a Frontier Physics Research Benchmark**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šç”± 50 å¤šä½ç‰©ç†å­¦å®¶æ„å»ºçš„åŸºå‡†ï¼ŒåŒ…å«æœªå‘è¡¨çš„ç ”ç©¶çº§ç‰©ç†éš¾é¢˜ã€‚\n*   **æ ¸å¿ƒå‘ç°**ï¼šè™½ç„¶ LLM èƒ½åšé«˜æ•°é¢˜ï¼Œä½†åœ¨çœŸæ­£çš„ç§‘ç ”æ¨ç†ä¸Š**ä¸€è´¥æ¶‚åœ°**ã€‚æœ€å¥½çš„ GPT-5 (High) ä»…æœ‰ 5.7% çš„å‡†ç¡®ç‡ï¼Œé…ä¸Šä»£ç å·¥å…·ä¹Ÿæ‰ 10%ã€‚ç§‘ç ”çº§ AI åŠ©æ‰‹è·ç¦»æˆ‘ä»¬è¿˜å¾ˆè¿œã€‚\n\n**15. [é—å¿˜å­¦ä¹ ] æ¢¯åº¦ä¸Šå‡æ— æ³•å®ç°é—å¿˜**\n**# title: Ascent Fails to Forget**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šåç›´è§‰åœ°è¯æ˜äº†ï¼Œç›®å‰æµè¡Œçš„åŸºäºæ¢¯åº¦ä¸Šå‡ (Gradient Ascent) çš„æœºå™¨é—å¿˜ï¼ˆMachine Unlearningï¼‰æ–¹æ³•å¾€å¾€æ˜¯å¤±è´¥çš„ã€‚\n*   **æ ¸å¿ƒå‘ç°**ï¼šè¿™æ˜¯å› ä¸ºâ€œé—å¿˜é›†â€å’Œâ€œä¿ç•™é›†â€ä¹‹é—´å­˜åœ¨ç»Ÿè®¡ä¾èµ–æ€§ã€‚ç®€å•åœ°å¯¹é—å¿˜é›†åšæ¢¯åº¦ä¸Šå‡ï¼Œä¼šç ´åæ¨¡å‹åœ¨ä¿ç•™é›†ä¸Šçš„æ€§èƒ½ï¼Œç”šè‡³è®©æ¨¡å‹é™·å…¥æ¯”åŸå§‹çŠ¶æ€æ›´å·®çš„å±€éƒ¨æå°å€¼ã€‚\n\n---\n\n### ğŸ“ æ€»ç»“\nä»Šå¤©çš„ arXiv å……æ»¡äº†å¯¹**å¤§æ¨¡å‹åº•å±‚æœºåˆ¶çš„åæ€**ï¼ˆå¦‚ Muon ä¼˜åŒ–å™¨ã€Mid-training çš„å¿…è¦æ€§ã€è§†è§‰å…ˆéªŒçš„æ¥æºï¼‰ä»¥åŠå¯¹**æœªæ¥å½¢æ€çš„æ¢ç´¢**ï¼ˆç§‘å­¦å¤§æ¨¡å‹ã€ä¸–ç•Œæ¨¡å‹ï¼‰ã€‚åŒæ—¶ï¼Œå®‰å…¨é¢†åŸŸçš„ç ”ç©¶æ­£ä»ç®€å•çš„â€œè¯´åè¯â€è½¬å‘æ›´å¤æ‚çš„**ç³»ç»Ÿæ€§é£é™©**ï¼ˆAgent è¿›åŒ–ã€å·¥å…·é“¾æ”»å‡»ï¼‰ã€‚\n\nå¸Œæœ›è¿™ä»½æ—¥æŠ¥èƒ½å¸®ä½ åœ¨ä¿¡æ¯æ´ªæµä¸­æŠ“ä½é‡ç‚¹ï¼æˆ‘ä»¬æ˜å¤©è§ï¼",
  "papers": [
    {
      "arxiv_id": "2510.00358v1",
      "title": "DiSA-IQL: Offline Reinforcement Learning for Robust Soft Robot Control under Distribution Shifts",
      "title_zh": "DiSA-IQLï¼šé¢å‘åˆ†å¸ƒåç§»ä¸‹é²æ£’è½¯ä½“æœºå™¨äººæ§åˆ¶çš„ç¦»çº¿å¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Linjin He",
        "Xinda Qi",
        "Dong Chen",
        "Zhaojian Li",
        "Xiaobo Tan"
      ],
      "abstract": "Soft snake robots offer remarkable flexibility and adaptability in complex environments, yet their control remains challenging due to highly nonlinear dynamics. Existing model-based and bio-inspired controllers rely on simplified assumptions that limit performance. Deep reinforcement learning (DRL) has recently emerged as a promising alternative, but online training is often impractical because of costly and potentially damaging real-world interactions. Offline RL provides a safer option by leveraging pre-collected datasets, but it suffers from distribution shift, which degrades generalization to unseen scenarios. To overcome this challenge, we propose DiSA-IQL (Distribution-Shift-Aware Implicit Q-Learning), an extension of IQL that incorporates robustness modulation by penalizing unreliable state-action pairs to mitigate distribution shift. We evaluate DiSA-IQL on goal-reaching tasks across two settings: in-distribution and out-of-distribution evaluation. Simulation results show that DiSA-IQL consistently outperforms baseline models, including Behavior Cloning (BC), Conservative Q-Learning (CQL), and vanilla IQL, achieving higher success rates, smoother trajectories, and improved robustness. The codes are open-sourced to support reproducibility and to facilitate further research in offline RL for soft robot control.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è½¯ä½“è›‡å½¢æœºå™¨äººç”±äºé«˜åº¦éçº¿æ€§åŠ¨åŠ›å­¦å¯¼è‡´çš„æ§åˆ¶éš¾é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸º DiSA-IQL (Distribution-Shift-Aware Implicit Q-Learning) çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ã€‚ç”±äºåœ¨çº¿ Deep reinforcement learning (DRL) å­˜åœ¨æˆæœ¬é«˜ä¸”æ˜“æŸåå®ä½“çš„é£é™©ï¼Œç ”ç©¶é‡‡ç”¨äº†æ›´å®‰å…¨çš„ Offline RL æ¡†æ¶ï¼Œå¹¶é’ˆå¯¹å…¶å¸¸è§çš„ Distribution shift é—®é¢˜è¿›è¡Œäº†é’ˆå¯¹æ€§ä¼˜åŒ–ã€‚DiSA-IQL é€šè¿‡å¼•å…¥ Robustness modulation æœºåˆ¶ï¼Œå¯¹ä¸å¯é çš„ state-action pairs è¿›è¡Œæƒ©ç½šï¼Œä»è€Œæœ‰æ•ˆç¼“è§£äº†åˆ†å¸ƒåç§»å¯¹æ³›åŒ–æ€§èƒ½çš„å½±å“ã€‚å®éªŒåœ¨ç›®æ ‡åˆ°è¾¾ä»»åŠ¡çš„ In-distribution å’Œ Out-of-distribution è®¾ç½®ä¸‹è¿›è¡Œï¼Œç»“æœè¡¨æ˜ DiSA-IQL åœ¨æˆåŠŸç‡ã€è½¨è¿¹å¹³æ»‘åº¦åŠé²æ£’æ€§ä¸Šæ˜¾è‘—ä¼˜äº Behavior Cloning (BC)ã€Conservative Q-Learning (CQL) åŠåŸå§‹ IQLã€‚è¯¥ç ”ç©¶ä¸ºè½¯ä½“æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸‹çš„ç¨³å¥æ§åˆ¶æä¾›äº†æ–°æ–¹æ¡ˆï¼Œå¹¶å¼€æºäº†ç›¸å…³ä»£ç ä»¥æ”¯æŒåç»­ç ”ç©¶ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.00358v1",
      "published_date": "2025-09-30 23:53:47 UTC",
      "updated_date": "2025-09-30 23:53:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:18:59.381660+00:00"
    },
    {
      "arxiv_id": "2510.03314v1",
      "title": "A Comprehensive Review on Artificial Intelligence Empowered Solutions for Enhancing Pedestrian and Cyclist Safety",
      "title_zh": "äººå·¥æ™ºèƒ½èµ‹èƒ½çš„è¡Œäººä¸éª‘è¡Œè€…å®‰å…¨æå‡æ–¹æ¡ˆç»¼è¿°",
      "authors": [
        "Shucheng Zhang",
        "Yan Shi",
        "Bingzhang Wang",
        "Yuang Zhang",
        "Muhammad Monjurul Karim",
        "Kehua Chen",
        "Chenxi Liu",
        "Mehrdad Nasri",
        "Yinhai Wang"
      ],
      "abstract": "Ensuring the safety of vulnerable road users (VRUs), such as pedestrians and cyclists, remains a critical global challenge, as conventional infrastructure-based measures often prove inadequate in dynamic urban environments. Recent advances in artificial intelligence (AI), particularly in visual perception and reasoning, open new opportunities for proactive and context-aware VRU protection. However, existing surveys on AI applications for VRUs predominantly focus on detection, offering limited coverage of other vision-based tasks that are essential for comprehensive VRU understanding and protection. This paper presents a state-of-the-art review of recent progress in camera-based AI sensing systems for VRU safety, with an emphasis on developments from the past five years and emerging research trends. We systematically examine four core tasks, namely detection and classification, tracking and reidentification, trajectory prediction, and intent recognition and prediction, which together form the backbone of AI-empowered proactive solutions for VRU protection in intelligent transportation systems. To guide future research, we highlight four major open challenges from the perspectives of data, model, and deployment. By linking advances in visual AI with practical considerations for real-world implementation, this survey aims to provide a foundational reference for the development of next-generation sensing systems to enhance VRU safety.",
      "tldr_zh": "è¯¥ç»¼è¿°å…¨é¢å›é¡¾äº†è¿‡å»äº”å¹´ä¸­äººå·¥æ™ºèƒ½(AI)èµ‹èƒ½è¡Œäººä¸éª‘è¡Œè€…ç­‰å¼±åŠ¿é“è·¯ä½¿ç”¨è€…(VRUs)å®‰å…¨çš„æœ€æ–°ç ”ç©¶è¿›å±•ã€‚é’ˆå¯¹ç°æœ‰æ–‡çŒ®å¤šå±€é™äºæ£€æµ‹ä»»åŠ¡çš„ä¸è¶³ï¼Œè¯¥ç ”ç©¶æ·±å…¥æ¢è®¨äº†åŸºäºç›¸æœºçš„AIä¼ æ„Ÿç³»ç»Ÿåœ¨è§†è§‰æ„ŸçŸ¥ä¸æ¨ç†æ–¹é¢çš„åº”ç”¨ã€‚æ–‡ç« ç³»ç»Ÿæ€§åœ°åˆ†æäº†å››é¡¹æ ¸å¿ƒä»»åŠ¡ï¼ŒåŒ…æ‹¬æ£€æµ‹ä¸åˆ†ç±»(detection and classification)ã€è·Ÿè¸ªä¸é‡è¯†åˆ«(tracking and reidentification)ã€è½¨è¿¹é¢„æµ‹(trajectory prediction)ä»¥åŠæ„å›¾è¯†åˆ«ä¸é¢„æµ‹(intent recognition and prediction)ï¼Œæ„æˆäº†ä¸»åŠ¨å¼VRUä¿æŠ¤æŠ€æœ¯çš„æ ¸å¿ƒæ”¯æŸ±ã€‚æ­¤å¤–ï¼Œä½œè€…ä»æ•°æ®(data)ã€æ¨¡å‹(model)å’Œéƒ¨ç½²(deployment)ä¸‰ä¸ªç»´åº¦æå‡ºäº†æœªæ¥ç ”ç©¶é¢ä¸´çš„å››å¤§å¼€æ”¾æŒ‘æˆ˜ã€‚è¯¥é¡¹å·¥ä½œé€šè¿‡æ•´åˆè§†è§‰AIæŠ€æœ¯ä¸å®é™…éƒ¨ç½²è€ƒé‡ï¼Œä¸ºå¼€å‘ä¸‹ä¸€ä»£æ™ºèƒ½äº¤é€šä¼ æ„Ÿç³»ç»Ÿä»¥æå‡é“è·¯å®‰å…¨æä¾›äº†é‡è¦çš„åŸºç¡€å‚è€ƒã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "20 pages, 4 figures, 5 tables",
      "pdf_url": "https://arxiv.org/pdf/2510.03314v1",
      "published_date": "2025-09-30 23:50:55 UTC",
      "updated_date": "2025-09-30 23:50:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:18:55.489137+00:00"
    },
    {
      "arxiv_id": "2510.01286v1",
      "title": "Emergent evaluation hubs in a decentralizing large language model ecosystem",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹ç”Ÿæ€ç³»ç»Ÿå»ä¸­å¿ƒåŒ–è¿›ç¨‹ä¸­æ¶Œç°çš„è¯„ä¼°æ¢çº½",
      "authors": [
        "Manuel Cebrian",
        "Tomomi Kito",
        "Raul Castro Fernandez"
      ],
      "abstract": "Large language models are proliferating, and so are the benchmarks that serve as their common yardsticks. We ask how the agglomeration patterns of these two layers compare: do they evolve in tandem or diverge? Drawing on two curated proxies for the ecosystem, the Stanford Foundation-Model Ecosystem Graph and the Evidently AI benchmark registry, we find complementary but contrasting dynamics. Model creation has broadened across countries and organizations and diversified in modality, licensing, and access. Benchmark influence, by contrast, displays centralizing patterns: in the inferred benchmark-author-institution network, the top 15% of nodes account for over 80% of high-betweenness paths, three countries produce 83% of benchmark outputs, and the global Gini for inferred benchmark authority reaches 0.89. An agent-based simulation highlights three mechanisms: higher entry of new benchmarks reduces concentration; rapid inflows can temporarily complicate coordination in evaluation; and stronger penalties against over-fitting have limited effect. Taken together, these results suggest that concentrated benchmark influence functions as coordination infrastructure that supports standardization, comparability, and reproducibility amid rising heterogeneity in model production, while also introducing trade-offs such as path dependence, selective visibility, and diminishing discriminative power as leaderboards saturate.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹(Large language models)ç”Ÿæ€ç³»ç»Ÿä¸­æ¨¡å‹äº§å‡ºä¸è¯„ä¼°åŸºå‡†(Benchmarks)èšé›†æ¨¡å¼çš„æ¼”åŒ–å·®å¼‚ã€‚é€šè¿‡å¯¹æ–¯å¦ç¦åŸºç¡€æ¨¡å‹ç”Ÿæ€ç³»ç»Ÿå›¾(Stanford Foundation-Model Ecosystem Graph)ç­‰æ•°æ®çš„åˆ†æï¼Œç ”ç©¶å‘ç°æ¨¡å‹åˆ›ä½œæ­£è¶‹äºåœ°ç†å’Œç»„ç»‡ä¸Šçš„å»ä¸­å¿ƒåŒ–ï¼Œè€ŒåŸºå‡†å½±å“åŠ›å´å‘ˆç°å‡ºæ˜¾è‘—çš„ä¸­å¿ƒåŒ–æ€åŠ¿ã€‚æ•°æ®æ˜¾ç¤ºï¼Œå…¨çƒåŸºå‡†æƒå¨çš„åŸºå°¼ç³»æ•°(Gini)è¾¾åˆ°0.89ï¼Œä¸”å°‘æ•°å›½å®¶å’Œæœºæ„ä¸»å¯¼äº†ç»å¤§éƒ¨åˆ†è¯„ä¼°è¾“å‡ºã€‚åŸºäºæ™ºèƒ½ä½“çš„æ¨¡æ‹Ÿ(Agent-based simulation)è¿›ä¸€æ­¥æ­ç¤ºäº†æ–°åŸºå‡†è¿›å…¥ç‡ã€åè°ƒå¤æ‚æ€§ä»¥åŠè¿‡åº¦æ‹Ÿåˆæƒ©ç½šå¯¹è¿™ç§é›†ä¸­åº¦çš„å½±å“ã€‚ç ”ç©¶è®¤ä¸ºï¼Œé›†ä¸­çš„åŸºå‡†å½±å“åŠ›ä½œä¸ºä¸€ç§åè°ƒåŸºç¡€è®¾æ–½ï¼Œåœ¨æ¨¡å‹å¼‚è´¨æ€§ä¸Šå‡çš„èƒŒæ™¯ä¸‹æ”¯æŒäº†æ ‡å‡†åŒ–ä¸å¯æ¯”æ€§ã€‚ç„¶è€Œï¼Œè¿™ç§è¶‹åŠ¿ä¹Ÿå¸¦æ¥äº†è·¯å¾„ä¾èµ–ã€é€‰æ‹©æ€§å¯è§æ€§ä»¥åŠéšç€æ’è¡Œæ¦œé¥±å’Œè€Œå¯¼è‡´åŒºåˆ†åº¦ä¸‹é™ç­‰æ½œåœ¨é£é™©ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "15 pages, 11 figures, 3 tables",
      "pdf_url": "https://arxiv.org/pdf/2510.01286v1",
      "published_date": "2025-09-30 23:49:26 UTC",
      "updated_date": "2025-09-30 23:49:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:18:58.286421+00:00"
    },
    {
      "arxiv_id": "2510.00355v2",
      "title": "Hierarchical Reasoning Models: Perspectives and Misconceptions",
      "title_zh": "å±‚çº§æ¨ç†æ¨¡å‹ï¼šè§†è§’ä¸è¯¯åŒº",
      "authors": [
        "Renee Ge",
        "Qianli Liao",
        "Tomaso Poggio"
      ],
      "abstract": "Transformers have demonstrated remarkable performance in natural language processing and related domains, as they largely focus on sequential, autoregressive next-token prediction tasks. Yet, they struggle in logical reasoning, not necessarily because of a fundamental limitation of these models, but possibly due to the lack of exploration of more creative uses, such as latent space and recurrent reasoning. An emerging exploration in this direction is the Hierarchical Reasoning Model (Wang et. al., 2025), which introduces a novel type of recurrent reasoning in the latent space of transformers, achieving remarkable performance on a wide range of 2D reasoning tasks. Despite the promising results, this line of models is still at an early stage and calls for in-depth investigation. In this work, we review this class of models, examine key design choices, test alternative variants and clarify common misconceptions.",
      "tldr_zh": "è™½ç„¶ Transformers åœ¨è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸè¡¨ç°å“è¶Šï¼Œä½†åœ¨é€»è¾‘æ¨ç†æ–¹é¢ä»é¢ä¸´æŒ‘æˆ˜ï¼Œè¿™å¯èƒ½æºäºå¯¹æ½œåœ¨ç©ºé—´ (latent space) å’Œé€’å½’æ¨ç† (recurrent reasoning) æ¢ç´¢çš„ä¸è¶³ã€‚è¯¥ç ”ç©¶æ·±å…¥æ¢è®¨äº†åˆ†å±‚æ¨ç†æ¨¡å‹ (Hierarchical Reasoning Models)ï¼Œè¿™æ˜¯ä¸€ç§é€šè¿‡åœ¨ Transformers çš„æ½œåœ¨ç©ºé—´ä¸­å¼•å…¥æ–°å‹é€’å½’æœºåˆ¶ï¼Œåœ¨å¤šç§ 2D æ¨ç†ä»»åŠ¡ä¸­å®ç°æ˜¾è‘—æ€§èƒ½çªç ´çš„æ¨¡å‹ã€‚é‰´äºè¯¥é¢†åŸŸä»å¤„äºèµ·æ­¥é˜¶æ®µï¼Œæœ¬æ–‡ç³»ç»Ÿåœ°å®¡æŸ¥äº†æ­¤ç±»æ¨¡å‹çš„æ ¸å¿ƒè®¾è®¡é€‰æ‹©ï¼Œå¹¶æµ‹è¯•äº†å¤šç§æ›¿ä»£å˜ä½“ä»¥éªŒè¯å…¶æœ‰æ•ˆæ€§ã€‚ç ”ç©¶é‡ç‚¹æ¾„æ¸…äº†å…³äºè¯¥æ¨¡å‹çš„å¸¸è§è¯¯è§£ï¼Œä¸ºç†è§£æ½œåœ¨ç©ºé—´ä¸­çš„æ¨ç†æœºåˆ¶æä¾›äº†æ–°çš„è§†è§’ã€‚é€šè¿‡å¯¹æ¨¡å‹æ¶æ„ä¸æ¨ç†é€»è¾‘çš„ç»†è‡´åˆ†æï¼Œè¯¥å·¥ä½œä¸ºå¼€å‘æ›´å…·åˆ›é€ æ€§å’Œé€»è¾‘ä¸¥å¯†æ€§çš„æ¨ç†æ¨¡å‹å¥ å®šäº†ç†è®ºåŸºç¡€ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Found errors in some results of v1. Removed them and changed conclusions",
      "pdf_url": "https://arxiv.org/pdf/2510.00355v2",
      "published_date": "2025-09-30 23:40:04 UTC",
      "updated_date": "2025-10-07 17:57:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:19:03.090419+00:00"
    },
    {
      "arxiv_id": "2510.02390v2",
      "title": "Hyperparameters are all you need: Using five-step inference for an original diffusion model to generate images comparable to the latest distillation model",
      "title_zh": "è¶…å‚æ•°å³å…¨éƒ¨ï¼šé€šè¿‡åŸå§‹æ‰©æ•£æ¨¡å‹çš„äº”æ­¥æ¨ç†ç”Ÿæˆåª²ç¾æœ€æ–°è’¸é¦æ¨¡å‹çš„å›¾åƒ",
      "authors": [
        "Zilai Li"
      ],
      "abstract": "The diffusion model is a state-of-the-art generative model that samples images by applying a neural network iteratively. However, the original sampling algorithm requires substantial computation cost, and reducing the sampling step is a prevailing research area. To cope with this problem, one mainstream approach is to treat the sampling process as an algorithm that solves an ordinary differential equation (ODE). Our study proposes a training-free inference plugin compatible with most few-step ODE solvers. To the best of my knowledge, our algorithm is the first training-free algorithm to sample a 1024 x 1024-resolution image in 6 steps and a 512 x 512-resolution image in 5 steps, with an FID result that outperforms the SOTA distillation models and the 20-step DPM++ 2m solver, respectively. Based on analyses of the latent diffusion model's structure, the diffusion ODE, and the Free-U mechanism, we explain why specific hyperparameter couplings improve stability and inference speed without retraining. Meanwhile, experimental results also reveal a new design space of the latent diffusion ODE solver. Additionally, we also analyze the difference between the original diffusion model and the diffusion distillation model via an information-theoretic study, which shows the reason why the few-step ODE solver designed for the diffusion model can outperform the training-based diffusion distillation algorithm in few-step inference. The tentative results of the experiment prove the mathematical analysis. code base is below: https://github.com/TheLovesOfLadyPurple/Hyperparameter-is-all-you-need",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ‰©æ•£æ¨¡å‹(diffusion model)é‡‡æ ·è®¡ç®—æˆæœ¬é«˜ã€æ­¥éª¤å¤šç­‰é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ä¸å¤šæ•°å°‘æ­¥ODEæ±‚è§£å™¨å…¼å®¹çš„å…è®­ç»ƒ(training-free)æ¨ç†æ’ä»¶ã€‚è¯¥ç®—æ³•é€šè¿‡æ·±å…¥åˆ†ææ½œæ‰©æ•£æ¨¡å‹(latent diffusion model)ç»“æ„ã€æ‰©æ•£ODEä»¥åŠFree-Uæœºåˆ¶ï¼Œåˆ©ç”¨ç‰¹å®šçš„è¶…å‚æ•°è€¦åˆ(hyperparameter couplings)åœ¨ä¸è¿›è¡Œé‡è®­ç»ƒçš„æƒ…å†µä¸‹æ˜¾è‘—æå‡äº†æ¨¡å‹çš„ç¨³å®šæ€§å’Œæ¨ç†é€Ÿåº¦ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥ç®—æ³•èƒ½å¤Ÿåœ¨5æ­¥å†…ç”Ÿæˆ512x512åˆ†è¾¨ç‡å›¾åƒï¼Œåœ¨6æ­¥å†…ç”Ÿæˆ1024x1024åˆ†è¾¨ç‡å›¾åƒï¼Œä¸”å…¶FIDæŒ‡æ ‡ä¼˜äºç›®å‰æœ€å…ˆè¿›çš„è’¸é¦æ¨¡å‹(distillation models)ä»¥åŠé‡‡ç”¨20æ­¥é‡‡æ ·çš„DPM++ 2mæ±‚è§£å™¨ã€‚ç ”ç©¶è¿›ä¸€æ­¥é€šè¿‡ä¿¡æ¯è®º(information-theoretic)åˆ†æï¼Œé˜æ˜äº†ä¸ºä½•é’ˆå¯¹åŸå§‹æ‰©æ•£æ¨¡å‹è®¾è®¡çš„å°‘æ­¥ODEæ±‚è§£å™¨åœ¨æ€§èƒ½ä¸Šèƒ½å¤Ÿè¶…è¶ŠåŸºäºè®­ç»ƒçš„æ‰©æ•£è’¸é¦ç®—æ³•ã€‚è¯¥å·¥ä½œä¸ä»…è¯æ˜äº†è¶…å‚æ•°ä¼˜åŒ–åœ¨æå‡å°‘æ­¥æ¨ç†æ€§èƒ½ä¸­çš„å…³é”®ä½œç”¨ï¼Œä¹Ÿä¸ºæ½œæ‰©æ•£ODEæ±‚è§£å™¨æ­ç¤ºäº†ä¸€ä¸ªå…¨æ–°çš„è®¾è®¡ç©ºé—´ã€‚",
      "categories": [
        "cs.GR",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.GR",
      "comment": "21 pages, 8 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.02390v2",
      "published_date": "2025-09-30 23:27:09 UTC",
      "updated_date": "2025-11-30 13:59:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:19:18.697601+00:00"
    },
    {
      "arxiv_id": "2510.00347v1",
      "title": "In-Context Curiosity: Distilling Exploration for Decision-Pretrained Transformers on Bandit Tasks",
      "title_zh": "ä¸Šä¸‹æ–‡å¥½å¥‡å¿ƒï¼šé¢å‘ Bandit ä»»åŠ¡ä¸­å†³ç­–é¢„è®­ç»ƒ Transformer çš„æ¢ç´¢è’¸é¦",
      "authors": [
        "Huitao Yang",
        "Guanting Chen"
      ],
      "abstract": "As large language models (LLMs) continue to grow in capability, there is increasing interest in incorporating them into decision-making tasks. A common pipeline for this is Decision-Pretrained Transformers (DPTs). However, existing training methods for DPTs often struggle to generalize beyond their pretraining data distribution. To explore mitigation of this limitation, we propose in-context curiosity -- a lightweight, exploration-inspired regularizer for offline pretraining -- and introduce the Prediction-Powered Transformer (PPT) framework. PPT augments DPT with an auxiliary reward predictor, using prediction error as an intrinsic curiosity signal to encourage broader exploration during training. In proof-of-concept experiments on Gaussian multi-armed bandits, PPT shows improved robustness: it moderates the performance degradation observed in DPT when test environments exhibit higher variance in reward, particularly when pretraining data has limited diversity. While the quality of offline data remain fundamental, our preliminary results suggest that curiosity-driven pretraining offers a promising direction for enhancing out-of-distribution generalization in in-context RL agents.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹Decision-Pretrained Transformers (DPTs)åœ¨å†³ç­–ä»»åŠ¡ä¸­éš¾ä»¥æ³›åŒ–è‡³é¢„è®­ç»ƒåˆ†å¸ƒä¹‹å¤–çš„é—®é¢˜ï¼Œæå‡ºäº†in-context curiosityï¼Œè¿™æ˜¯ä¸€ç§ä¸ºç¦»çº¿é¢„è®­ç»ƒè®¾è®¡çš„è½»é‡åŒ–æ¢ç´¢æ¿€åŠ±æ­£åˆ™é¡¹ã€‚ç ”ç©¶è€…è¿›ä¸€æ­¥å¼•å…¥äº†Prediction-Powered Transformer (PPT) æ¡†æ¶ï¼Œé€šè¿‡åœ¨DPTåŸºç¡€ä¸Šå¢åŠ è¾…åŠ©å¥–åŠ±é¢„æµ‹å™¨ï¼Œåˆ©ç”¨é¢„æµ‹è¯¯å·®ä½œä¸ºå†…åœ¨çš„å¥½å¥‡å¿ƒä¿¡å·(intrinsic curiosity signal)ï¼Œä»è€Œåœ¨è®­ç»ƒæœŸé—´é¼“åŠ±æ›´å¹¿æ³›çš„æ¢ç´¢ã€‚åœ¨é«˜æ–¯å¤šè‡‚è€è™æœº(Gaussian multi-armed bandits)çš„å®éªŒä¸­ï¼ŒPPTå±•ç°äº†æ›´å¼ºçš„é²æ£’æ€§ï¼Œæœ‰æ•ˆç¼“è§£äº†åœ¨æµ‹è¯•ç¯å¢ƒå¥–åŠ±æ–¹å·®è¾ƒé«˜æˆ–é¢„è®­ç»ƒæ•°æ®å¤šæ ·æ€§æœ‰é™æ—¶çš„æ€§èƒ½è¡°å‡ã€‚åˆæ­¥ç»“æœè¡¨æ˜ï¼Œè¿™ç§å¥½å¥‡å¿ƒé©±åŠ¨çš„é¢„è®­ç»ƒæ–¹æ³•ä¸ºå¢å¼ºæƒ…å¢ƒå¼ºåŒ–å­¦ä¹ (in-context RL)æ™ºèƒ½ä½“çš„éåˆ†å¸ƒ(out-of-distribution)æ³›åŒ–èƒ½åŠ›æä¾›äº†å…·æœ‰å‰æ™¯çš„ç ”ç©¶æ–¹å‘ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.00347v1",
      "published_date": "2025-09-30 23:17:18 UTC",
      "updated_date": "2025-09-30 23:17:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:19:29.290680+00:00"
    },
    {
      "arxiv_id": "2510.00339v1",
      "title": "Navigating the Synchrony-Stability Frontier in Adaptive Chatbots",
      "title_zh": "æ¢ç´¢è‡ªé€‚åº”èŠå¤©æœºå™¨äººä¸­çš„åŒæ­¥æ€§-ç¨³å®šæ€§å‰æ²¿",
      "authors": [
        "T. James Brandt"
      ],
      "abstract": "Adaptive chatbots that mimic a user's linguistic style can build rapport and engagement, yet unconstrained mimicry risks an agent that feels unstable or sycophantic. We present a computational evaluation framework that makes the core design tension explicit: balancing moment-to-moment linguistic synchrony against long-term persona stability. Using an 8-dimensional style vector and a closed-loop \"base+delta\" prompting architecture, we simulate and compare explicit adaptation policies - Uncapped, Cap, Exponential Moving Average (EMA), Dead-Band, and Hybrids - on a human-log dataset. Our analysis maps a clear Pareto frontier: bounded policies achieve substantial gains in stability at a modest cost to synchrony. For example, a Hybrid (EMA+Cap) raises stability from 0.542 to 0.878 (+62%) while reducing synchrony by only 17%. We confirm this trade-off through large-scale replications on three public corpora (DailyDialog, Persona-Chat, EmpatheticDialogues) and LLM-in-the-loop validation across two model families. Furthermore, we quantify \"prompt legibility,\" showing that frontier policies reduce instruction churn and cut jarring register flips (major tone changes) from 0.254 to 0.092, yielding systems that are easier to reason about and maintain. Taken together, our framework provides a general evaluation harness for style adaptation; a systematic ablation that identifies Pareto-efficient policies; robust validation across diverse datasets and models; and novel legibility metrics linking policy choices to system maintainability.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†è‡ªé€‚åº”èŠå¤©æœºå™¨äººåœ¨æ¨¡ä»¿ç”¨æˆ·è¯­è¨€é£æ ¼ï¼ˆlinguistic synchronyï¼‰ä¸ç»´æŒé•¿æœŸäººæ ¼ç¨³å®šæ€§ï¼ˆpersona stabilityï¼‰ä¹‹é—´çš„è®¾è®¡åšå¼ˆã€‚ç ”ç©¶æå‡ºäº†ä¸€ä¸ªè®¡ç®—è¯„ä¼°æ¡†æ¶ï¼Œé‡‡ç”¨ 8-dimensional style vector å’Œ \"base+delta\" æç¤ºæ¶æ„ï¼Œæ¨¡æ‹Ÿå¹¶å¯¹æ¯”äº†åŒ…æ‹¬ EMAã€Cap å’Œ Hybrid åœ¨å†…çš„å¤šç§æ˜¾å¼é€‚é…ç­–ç•¥ã€‚é€šè¿‡åœ¨ DailyDialog å’Œ Persona-Chat ç­‰å¤šä¸ªè¯­æ–™åº“ä¸Šçš„å¤§è§„æ¨¡å®éªŒï¼Œç ”ç©¶æˆåŠŸç»˜åˆ¶äº† Pareto frontierï¼Œè¯æ˜å—é™ç­–ç•¥èƒ½ä»¥æå°çš„åŒæ­¥æ€§ä»£ä»·æ¢å–ç¨³å®šæ€§çš„æ˜¾è‘—æå‡ã€‚ä¾‹å¦‚ï¼ŒHybrid (EMA+Cap) ç­–ç•¥åœ¨å°†ç¨³å®šæ€§æé«˜ 62% çš„åŒæ—¶ï¼ŒåŒæ­¥æ€§ä»…ä¸‹é™ 17%ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å¼•å…¥äº† \"prompt legibility\" æŒ‡æ ‡ï¼Œå‘ç°å‰æ²¿ç­–ç•¥èƒ½å°†å‰§çƒˆçš„è¯­åŸŸç¿»è½¬ï¼ˆregister flipsï¼‰ä» 0.254 é™ä½è‡³ 0.092ï¼Œæ˜¾è‘—æå‡äº†ç³»ç»Ÿçš„å¯è§£é‡Šæ€§ã€‚è¯¥æˆæœä¸ºè‡ªé€‚åº”é£æ ¼æ¨¡å‹æä¾›äº†ç³»ç»Ÿçš„è¯„ä¼°å·¥å…·å’Œé«˜æ•ˆçš„ç­–ç•¥é€‰æ‹©è·¯å¾„ï¼Œå»ºç«‹äº†ç­–ç•¥é€‰æ‹©ä¸ç³»ç»Ÿå¯ç»´æŠ¤æ€§ä¹‹é—´çš„é‡åŒ–è”ç³»ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "pages; 9 tables; 7 figures; code & analysis artifact: https://doi.org/10.5281/zenodo.17238269; under review at ACM IUI 2026",
      "pdf_url": "https://arxiv.org/pdf/2510.00339v1",
      "published_date": "2025-09-30 22:50:30 UTC",
      "updated_date": "2025-09-30 22:50:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:19:27.086216+00:00"
    },
    {
      "arxiv_id": "2510.00334v1",
      "title": "Structural Refinement of Bayesian Networks for Efficient Model Parameterisation",
      "title_zh": "é¢å‘é«˜æ•ˆæ¨¡å‹å‚æ•°åŒ–çš„è´å¶æ–¯ç½‘ç»œç»“æ„ç²¾ç‚¼",
      "authors": [
        "Kieran Drury",
        "Martine J. Barons",
        "Jim Q. Smith"
      ],
      "abstract": "Many Bayesian network modelling applications suffer from the issue of data scarcity. Hence the use of expert judgement often becomes necessary to determine the parameters of the conditional probability tables (CPTs) throughout the network. There are usually a prohibitively large number of these parameters to determine, even when complementing any available data with expert judgements. To address this challenge, a number of CPT approximation methods have been developed that reduce the quantity and complexity of parameters needing to be determined to fully parameterise a Bayesian network. This paper provides a review of a variety of structural refinement methods that can be used in practice to efficiently approximate a CPT within a Bayesian network. We not only introduce and discuss the intrinsic properties and requirements of each method, but we evaluate each method through a worked example on a Bayesian network model of cardiovascular risk assessment. We conclude with practical guidance to help Bayesian network practitioners choose an alternative approach when direct parameterisation of a CPT is infeasible.",
      "tldr_zh": "è®¸å¤šè´å¶æ–¯ç½‘ç»œ(Bayesian network)åº”ç”¨å¸¸é¢ä¸´æ•°æ®ç¨€ç¼ºçš„æŒ‘æˆ˜ï¼Œå¯¼è‡´ä¾é ä¸“å®¶åˆ¤æ–­æ¥ç¡®å®šæ¡ä»¶æ¦‚ç‡è¡¨(CPTs)å‚æ•°çš„ä»»åŠ¡å˜å¾—å¼‚å¸¸ç¹é‡ã€‚ä¸ºè§£å†³è¿™ä¸€éš¾é¢˜ï¼Œæœ¬æ–‡ç»¼è¿°äº†å¤šç§ç»“æ„ä¼˜åŒ–(structural refinement)æ–¹æ³•ï¼Œè¿™äº›æ–¹æ³•èƒ½æœ‰æ•ˆè¿‘ä¼¼è´å¶æ–¯ç½‘ç»œä¸­çš„æ¡ä»¶æ¦‚ç‡è¡¨(CPT)ï¼Œä»è€Œå‡å°‘æ‰€éœ€å‚æ•°çš„æ•°é‡å’Œå¤æ‚åº¦ã€‚ç ”ç©¶æ·±å…¥æ¢è®¨äº†æ¯ç§æ–¹æ³•çš„å†…åœ¨ç‰¹æ€§ä¸å®æ–½è¦æ±‚ï¼Œå¹¶ç»“åˆå¿ƒè¡€ç®¡é£é™©è¯„ä¼°æ¨¡å‹çš„å…·ä½“æ¡ˆä¾‹å¯¹è¿™äº›æ–¹æ³•è¿›è¡Œäº†å®è¯è¯„ä¼°ã€‚æœ€åï¼Œè®ºæ–‡ä¸ºä»ä¸šè€…æä¾›äº†å®è·µæŒ‡å¯¼ï¼Œæ—¨åœ¨å½“æ¡ä»¶æ¦‚ç‡è¡¨(CPT)çš„ç›´æ¥å‚æ•°åŒ–ä¸å¯è¡Œæ—¶ï¼Œå¸®åŠ©å…¶é€‰æ‹©æœ€åˆé€‚çš„æ›¿ä»£æ–¹æ¡ˆã€‚",
      "categories": [
        "stat.ME",
        "cs.AI",
        "cs.LG",
        "stat.AP"
      ],
      "primary_category": "stat.ME",
      "comment": "38 pages, 10 figures, 3 tables, one appendix",
      "pdf_url": "https://arxiv.org/pdf/2510.00334v1",
      "published_date": "2025-09-30 22:39:48 UTC",
      "updated_date": "2025-09-30 22:39:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:19:31.892354+00:00"
    },
    {
      "arxiv_id": "2510.00332v2",
      "title": "When Hallucination Costs Millions: Benchmarking AI Agents in High-Stakes Adversarial Financial Markets",
      "title_zh": "å½“å¹»è§‰é€ æˆç™¾ä¸‡çº§æŸå¤±ï¼šé«˜é£é™©å¯¹æŠ—æ€§é‡‘èå¸‚åœºä¸­çš„ AI æ™ºèƒ½ä½“åŸºå‡†è¯„ä¼°",
      "authors": [
        "Zeshi Dai",
        "Zimo Peng",
        "Zerui Cheng",
        "Ryan Yihe Li"
      ],
      "abstract": "We present CAIA, a benchmark exposing a critical blind spot in AI evaluation: the inability of state-of-the-art models to operate in adversarial, high-stakes environments where misinformation is weaponized and errors are irreversible. While existing benchmarks measure task completion in controlled settings, real-world deployment demands resilience against active deception. Using crypto markets as a testbed where $30 billion was lost to exploits in 2024, we evaluate 17 models on 178 time-anchored tasks requiring agents to distinguish truth from manipulation, navigate fragmented information landscapes, and make irreversible financial decisions under adversarial pressure.\n  Our results reveal a fundamental capability gap: without tools, even frontier models achieve only 28% accuracy on tasks junior analysts routinely handle. Tool augmentation improves performance but plateaus at 67.4% versus 80% human baseline, despite unlimited access to professional resources. Most critically, we uncover a systematic tool selection catastrophe: models preferentially choose unreliable web search over authoritative data, falling for SEO-optimized misinformation and social media manipulation. This behavior persists even when correct answers are directly accessible through specialized tools, suggesting foundational limitations rather than knowledge gaps. We also find that Pass@k metrics mask dangerous trial-and-error behavior for autonomous deployment.\n  The implications extend beyond crypto to any domain with active adversaries, e.g. cybersecurity, content moderation, etc. We release CAIA with contamination controls and continuous updates, establishing adversarial robustness as a necessary condition for trustworthy AI autonomy. The benchmark reveals that current models, despite impressive reasoning scores, remain fundamentally unprepared for environments where intelligence must survive active opposition.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†CAIAï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨è¯„ä¼°AIæ™ºèƒ½ä½“åœ¨å­˜åœ¨è™šå‡ä¿¡æ¯å’Œä¸å¯é€†é”™è¯¯çš„é«˜é£é™©å¯¹æŠ—ç¯å¢ƒ(Adversarial environments)ä¸­è¡¨ç°çš„åŸºå‡†æµ‹è¯•ã€‚ç ”ç©¶ä»¥åŠ å¯†è´§å¸å¸‚åœºä¸ºå®éªŒåœºï¼Œå¯¹17ä¸ªå‰æ²¿æ¨¡å‹è¿›è¡Œäº†178é¡¹ä»»åŠ¡è¯„ä¼°ï¼Œè¦æ±‚æ™ºèƒ½ä½“åœ¨å¯¹æŠ—å‹åŠ›ä¸‹åŒºåˆ†çœŸå®ä¿¡æ¯ä¸äººä¸ºæ“çºµã€‚å®éªŒç»“æœæ˜¾ç¤ºäº†æ˜¾è‘—çš„èƒ½åŠ›å·®è·ï¼šåœ¨æ²¡æœ‰å·¥å…·æ”¯æŒæ—¶ï¼Œé¡¶å°–æ¨¡å‹çš„å‡†ç¡®ç‡ä»…ä¸º28%ï¼Œå³ä½¿å¼•å…¥å·¥å…·å¢å¼º(Tool augmentation)ï¼Œå…¶67.4%çš„å‡†ç¡®ç‡ä»è¿œä½äº80%çš„äººç±»åŸºå‡†çº¿ã€‚ç ”ç©¶ç‰¹åˆ«æ­ç¤ºäº†ç³»ç»Ÿæ€§çš„å·¥å…·é€‰æ‹©ç¾éš¾(Tool selection catastrophe)ï¼Œå³æ¨¡å‹å€¾å‘äºé€‰æ‹©ä¸å¯é çš„ç½‘é¡µæœç´¢è€Œéæƒå¨æ•°æ®ï¼Œææ˜“å—åˆ°ç¤¾äº¤åª’ä½“æ“çºµå’ŒSEOä¼˜åŒ–çš„è™šå‡ä¿¡æ¯è¯¯å¯¼ã€‚æ­¤å¤–ï¼Œç ”ç©¶å‘ç°Pass@kç­‰æŒ‡æ ‡æ©ç›–äº†è‡ªä¸»éƒ¨ç½²ä¸­å±é™©çš„è¯•é”™è¡Œä¸ºï¼Œå¹¶å¼ºè°ƒå¯¹æŠ—é²æ£’æ€§(Adversarial robustness)æ˜¯å®ç°å¯ä¿¡AIè‡ªä¸»æ€§çš„å¿…è¦æ¡ä»¶ã€‚è¯¥åŸºå‡†æµ‹è¯•çš„å‘å¸ƒæ­ç¤ºäº†å½“å‰æ¨¡å‹åœ¨åº”å¯¹ä¸»åŠ¨æ•Œå¯¹ç¯å¢ƒæ—¶çš„æ ¹æœ¬æ€§ç¼ºé™·ï¼Œä¸ºé‡‘èã€ç½‘ç»œå®‰å…¨ç­‰é«˜é£é™©é¢†åŸŸçš„AIè¯„ä¼°æä¾›äº†é‡è¦ä¾æ®ã€‚",
      "categories": [
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.AI",
      "comment": "15 pages, 5 figures, 4 tables; Accepted to AAAI 2026 (AI-4-Finance Workshop - Oral, top 10%); In submission to ICML 2026",
      "pdf_url": "https://arxiv.org/pdf/2510.00332v2",
      "published_date": "2025-09-30 22:39:06 UTC",
      "updated_date": "2026-01-17 06:27:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:19:37.590643+00:00"
    },
    {
      "arxiv_id": "2510.01285v1",
      "title": "LLM-based Multi-Agent Blackboard System for Information Discovery in Data Science",
      "title_zh": "åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„æ•°æ®ç§‘å­¦ä¿¡æ¯å‘ç°å¤šæ™ºèƒ½ä½“é»‘æ¿ç³»ç»Ÿ",
      "authors": [
        "Alireza Salemi",
        "Mihir Parmar",
        "Palash Goyal",
        "Yiwen Song",
        "Jinsung Yoon",
        "Hamed Zamani",
        "Hamid Palangi",
        "Tomas Pfister"
      ],
      "abstract": "The rapid advancement of Large Language Models (LLMs) has opened new opportunities in data science, yet their practical deployment is often constrained by the challenge of discovering relevant data within large heterogeneous data lakes. Existing methods struggle with this: single-agent systems are quickly overwhelmed by large, heterogeneous files in the large data lakes, while multi-agent systems designed based on a master-slave paradigm depend on a rigid central controller for task allocation that requires precise knowledge of each sub-agent's capabilities. To address these limitations, we propose a novel multi-agent communication paradigm inspired by the blackboard architecture for traditional AI models. In this framework, a central agent posts requests to a shared blackboard, and autonomous subordinate agents -- either responsible for a partition of the data lake or general information retrieval -- volunteer to respond based on their capabilities. This design improves scalability and flexibility by eliminating the need for a central coordinator to have prior knowledge of all sub-agents' expertise. We evaluate our method on three benchmarks that require explicit data discovery: KramaBench and modified versions of DS-Bench and DA-Code to incorporate data discovery. Experimental results demonstrate that the blackboard architecture substantially outperforms baselines, including RAG and the master-slave multi-agent paradigm, achieving between 13% to 57% relative improvement in end-to-end task success and up to a 9% relative gain in F1 score for data discovery over the best-performing baselines across both proprietary and open-source LLMs. Our findings establish the blackboard paradigm as a scalable and generalizable communication framework for multi-agent systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¤§å‹å¼‚æ„æ•°æ®æ¹–(data lakes)ä¸­è¿›è¡Œä¿¡æ¯å‘ç°æ—¶é¢ä¸´çš„æ•ˆç‡ç“¶é¢ˆï¼Œæå‡ºäº†ä¸€ç§å—ä¼ ç»ŸAIå¯å‘çš„å¤šæ™ºèƒ½ä½“é»‘æ¿ç³»ç»Ÿ(blackboard system)ã€‚è¯¥æ¡†æ¶é€šè¿‡ä¸­å¤®æ™ºèƒ½ä½“åœ¨å…±äº«é»‘æ¿å‘å¸ƒè¯·æ±‚ï¼Œå¹¶ç”±å…·å¤‡ç›¸åº”èƒ½åŠ›çš„è‡ªä¸»å­æ™ºèƒ½ä½“è‡ªæ„¿å“åº”ï¼Œæœ‰æ•ˆè§£å†³äº†å•æ™ºèƒ½ä½“å®¹æ˜“è¿‡è½½åŠä¼ ç»Ÿä¸»ä»æ¶æ„(master-slave paradigm)è¿‡äºåƒµåŒ–çš„é—®é¢˜ã€‚è¿™ç§è®¾è®¡æ¶ˆé™¤äº†ä¸­å¤®åè°ƒå™¨å¯¹å„å­æ™ºèƒ½ä½“ä¸“ä¸šé¢†åŸŸçŸ¥è¯†çš„ä¾èµ–ï¼Œæ˜¾è‘—æå‡äº†ç³»ç»Ÿçš„å¯æ‰©å±•æ€§(scalability)ä¸ä»»åŠ¡åˆ†é…çš„çµæ´»æ€§(flexibility)ã€‚åœ¨KramaBenchä»¥åŠæ”¹è¿›åçš„DS-Benchå’ŒDA-CodeåŸºå‡†æµ‹è¯•ä¸­ï¼Œè¯¥æ–¹æ³•åœ¨ç«¯åˆ°ç«¯ä»»åŠ¡æˆåŠŸç‡ä¸Šæ¯”æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)ç­‰åŸºçº¿æé«˜äº†13%è‡³57%ã€‚æ­¤å¤–ï¼Œè¯¥æ¶æ„åœ¨æ•°æ®å‘ç°çš„F1åˆ†æ•°ä¸Šä¹Ÿå®ç°äº†æœ€é«˜9%çš„ç›¸å¯¹å¢ç›Šï¼Œè¯æ˜äº†é»‘æ¿èŒƒå¼åœ¨å¤„ç†å¤æ‚æ•°æ®ç§‘å­¦ä»»åŠ¡ä¸­çš„å“è¶Šæ€§èƒ½ã€‚ç ”ç©¶ç»“æœç¡®ç«‹äº†é»‘æ¿èŒƒå¼ä½œä¸ºä¸€ç§å¯æ‰©å±•ä¸”é€šç”¨çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿé€šä¿¡æ¡†æ¶çš„åœ°ä½ï¼Œä¸ºæœªæ¥çš„ä¿¡æ¯å‘ç°ç ”ç©¶æä¾›äº†æ–°æ€è·¯ã€‚",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.01285v1",
      "published_date": "2025-09-30 22:34:23 UTC",
      "updated_date": "2025-09-30 22:34:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:19:44.957409+00:00"
    },
    {
      "arxiv_id": "2510.21736v1",
      "title": "Learn2Drive: A neural network-based framework for socially compliant automated vehicle control",
      "title_zh": "Learn2Driveï¼šåŸºäºç¥ç»ç½‘ç»œçš„ç¬¦åˆç¤¾ä¼šè§„èŒƒçš„è‡ªåŠ¨é©¾é©¶è½¦è¾†æ§åˆ¶æ¡†æ¶",
      "authors": [
        "Yuhui Liu",
        "Samannita Halder",
        "Shian Wang",
        "Tianyi Li"
      ],
      "abstract": "This study introduces a novel control framework for adaptive cruise control (ACC) in automated driving, leveraging Long Short-Term Memory (LSTM) networks and physics-informed constraints. As automated vehicles (AVs) adopt advanced features like ACC, transportation systems are becoming increasingly intelligent and efficient. However, existing AV control strategies primarily focus on optimizing the performance of individual vehicles or platoons, often neglecting their interactions with human-driven vehicles (HVs) and the broader impact on traffic flow. This oversight can exacerbate congestion and reduce overall system efficiency. To address this critical research gap, we propose a neural network-based, socially compliant AV control framework that incorporates social value orientation (SVO). This framework enables AVs to account for their influence on HVs and traffic dynamics. By leveraging AVs as mobile traffic regulators, the proposed approach promotes adaptive driving behaviors that reduce congestion, improve traffic efficiency, and lower energy consumption. Within this framework, we define utility functions for both AVs and HVs, which are optimized based on the SVO of each AV to balance its own control objectives with broader traffic flow considerations. Numerical results demonstrate the effectiveness of the proposed method in adapting to varying traffic conditions, thereby enhancing system-wide efficiency. Specifically, when the AV's control mode shifts from prioritizing energy consumption to optimizing traffic flow efficiency, vehicles in the following platoon experience at least a 58.99% increase in individual energy consumption alongside at least a 38.39% improvement in individual average speed, indicating significant enhancements in traffic dynamics.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Learn2Driveï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºé•¿çŸ­æœŸè®°å¿†ç½‘ç»œ (LSTM) å’Œç‰©ç†ä¿¡æ¯çº¦æŸ (physics-informed constraints) çš„è‡ªåŠ¨é©¾é©¶è‡ªé€‚åº”å·¡èˆªæ§åˆ¶ (ACC) æ¡†æ¶ã€‚è¯¥ç ”ç©¶æ—¨åœ¨è§£å†³ç°æœ‰æ§åˆ¶ç­–ç•¥å¾€å¾€å¿½è§†ä¸äººç±»é©¾é©¶è½¦è¾† (HVs) äº¤äº’ä»¥åŠå¯¹æ•´ä½“äº¤é€šæµå½±å“çš„å±€é™æ€§ã€‚é€šè¿‡å¼•å…¥ç¤¾ä¼šä»·å€¼å–å‘ (Social Value Orientation, SVO)ï¼Œè¯¥æ¡†æ¶ä½¿è‡ªåŠ¨é©¾é©¶è½¦è¾† (AVs) èƒ½å¤Ÿä½œä¸ºç§»åŠ¨äº¤é€šè°ƒèŠ‚å™¨ (mobile traffic regulators)ï¼Œåœ¨ä¼˜åŒ–è‡ªèº«ç›®æ ‡çš„åŒæ—¶å…¼é¡¾å¯¹å‘¨å›´äº¤é€šåŠ¨æ€çš„å½±å“ã€‚ç ”ç©¶å®šä¹‰äº†é’ˆå¯¹ AVs å’Œ HVs çš„æ•ˆç”¨å‡½æ•°ï¼Œå¹¶åˆ©ç”¨ SVO å¹³è¡¡ä¸ªä½“æ§åˆ¶ä¸å®è§‚äº¤é€šæ•ˆç‡ã€‚æ•°å€¼ç»“æœè¡¨æ˜ï¼Œå½“æ§åˆ¶ä¼˜å…ˆçº§è½¬å‘äº¤é€šæµæ•ˆç‡æ—¶ï¼Œè·Ÿé©°è½¦é˜Ÿçš„ä¸ªä½“å¹³å‡é€Ÿåº¦æå‡äº†è‡³å°‘ 38.39%ï¼Œå°½ç®¡ä¸ªä½“èƒ½è€—æœ‰æ‰€å¢åŠ ï¼Œä½†æ˜¾è‘—å¢å¼ºäº†ç³»ç»Ÿæ•´ä½“çš„äº¤é€šåŠ¨æ€æ€§èƒ½ã€‚è¯¥æ¡†æ¶ä¸ºå®ç°å…·å¤‡ç¤¾ä¼šåˆè§„æ€§ä¸”èƒ½æœ‰æ•ˆç¼“è§£æ‹¥å µçš„æ™ºèƒ½åŒ–äº¤é€šç³»ç»Ÿæä¾›äº†æ–°çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "cs.MA",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.21736v1",
      "published_date": "2025-09-30 22:33:44 UTC",
      "updated_date": "2025-09-30 22:33:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:20:05.595052+00:00"
    },
    {
      "arxiv_id": "2510.00326v1",
      "title": "Reasoning-Aware Prompt Orchestration: A Foundation Model for Multi-Agent Language Model Coordination",
      "title_zh": "æ¨ç†æ„ŸçŸ¥å‹æç¤ºç¼–æ’ï¼šå¤šæ™ºèƒ½ä½“è¯­è¨€æ¨¡å‹ååŒçš„åŸºç¡€æ¨¡å‹",
      "authors": [
        "Hassen Dhrif"
      ],
      "abstract": "The emergence of large language models has enabled sophisticated multi-agent systems, yet coordinating their reasoning capabilities through prompt engineering remains challenging. We present a theoretically-grounded framework for dynamic prompt orchestration that enhances reasoning across multiple specialized agents. This framework addresses three core challenges: logical consistency preservation during agent transitions, reasoning-aware prompt adaptation, and scalable coordination of distributed inference.\n  Our approach formalizes agent states using prompt templates, reasoning context vectors, and capability matrices. We prove system convergence to stable coordination patterns when step sizes satisfy $Î±< \\frac{1}{2L}$ where $L$ is the Lipschitz constant of the state transition function. We implement this through a distributed architecture that dynamically routes reasoning tasks while maintaining semantic coherence.\n  Experimental results on 1,000 synthetic multi-agent conversations demonstrate a 42% reduction in reasoning latency, a 23% improvement in logical consistency measured by ROUGE-L score, and an 89% success rate for task completion without context loss across agent transitions. Ablation studies identify the consensus mechanism as the primary performance driver, while revealing limitations: performance degrades beyond 10 agent transitions, and the system requires 76.5GB memory for 1,000 concurrent agents. These findings establish a new paradigm for scalable reasoning in multi-agent systems, providing theoretical foundations for understanding reasoning emergence across coordinated language models.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Reasoning-Aware Prompt Orchestrationæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ(Multi-Agent Systems)åœ¨åè°ƒæ¨ç†èƒ½åŠ›æ—¶é¢ä¸´çš„é€»è¾‘ä¸€è‡´æ€§ã€æç¤ºè‡ªé€‚åº”åŠåˆ†å¸ƒå¼æ¨ç†æ‰©å±•ç­‰æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶é€šè¿‡prompt templatesã€reasoning context vectorsåŠcapability matriceså¯¹æ™ºèƒ½ä½“çŠ¶æ€è¿›è¡Œå½¢å¼åŒ–å»ºæ¨¡ï¼Œå¹¶ä»ç†è®ºä¸Šè¯æ˜äº†åœ¨æ»¡è¶³ç‰¹å®šæ­¥é•¿æ¡ä»¶ä¸‹çš„ç³»ç»Ÿæ”¶æ•›æ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ¡ˆåœ¨1000æ¬¡åˆæˆå¯¹è¯ä¸­ä½¿æ¨ç†å»¶è¿Ÿé™ä½äº†42%ï¼Œé€»è¾‘ä¸€è‡´æ€§(ROUGE-L)æå‡äº†23%ï¼Œä¸”åœ¨æ— è¯­å¢ƒä¸¢å¤±çš„æƒ…å†µä¸‹å®ç°äº†89%çš„ä»»åŠ¡å®Œæˆç‡ã€‚å°½ç®¡ç ”ç©¶å‘ç°ç³»ç»Ÿåœ¨è¶…è¿‡10æ¬¡æ™ºèƒ½ä½“è½¬æ¢åæ€§èƒ½ä¼šæœ‰æ‰€ä¸‹é™ä¸”é«˜å¹¶å‘å†…å­˜éœ€æ±‚è¾ƒå¤§ï¼Œä½†è¯¥æˆæœä¸ºå¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„å¯æ‰©å±•æ¨ç†å»ºç«‹äº†ä¸€ç§æ–°èŒƒå¼ï¼Œå¹¶ä¸ºç†è§£åè°ƒè¯­è¨€æ¨¡å‹çš„æ¨ç†æ¶Œç°æä¾›äº†é‡è¦çš„ç†è®ºåŸºç¡€ã€‚",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.00326v1",
      "published_date": "2025-09-30 22:33:01 UTC",
      "updated_date": "2025-09-30 22:33:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:20:12.194173+00:00"
    },
    {
      "arxiv_id": "2510.00321v1",
      "title": "A Framework for Selection of Machine Learning Algorithms Based on Performance Metrices and Akaike Information Criteria in Healthcare, Telecommunication, and Marketing Sector",
      "title_zh": "åŸºäºæ€§èƒ½æŒ‡æ ‡ä¸èµ¤æ± ä¿¡æ¯å‡†åˆ™çš„åŒ»ç–—ã€ç”µä¿¡åŠè¥é”€é¢†åŸŸæœºå™¨å­¦ä¹ ç®—æ³•é€‰æ‹©æ¡†æ¶",
      "authors": [
        "A. K. Hamisu",
        "K. Jasleen"
      ],
      "abstract": "The exponential growth of internet generated data has fueled advancements in artificial intelligence (AI), machine learning (ML), and deep learning (DL) for extracting actionable insights in marketing,telecom, and health sectors. This chapter explores ML applications across three domains namely healthcare, marketing, and telecommunications, with a primary focus on developing a framework for optimal ML algorithm selection. In healthcare, the framework addresses critical challenges such as cardiovascular disease prediction accounting for 28.1% of global deaths and fetal health classification into healthy or unhealthy states, utilizing three datasets. ML algorithms are categorized into eager, lazy, and hybrid learners, selected based on dataset attributes, performance metrics (accuracy, precision, recall), and Akaike Information Criterion (AIC) scores. For validation, eight datasets from the three sectors are employed in the experiments. The key contribution is a recommendation framework that identifies the best ML model according to input attributes, balancing performance evaluation and model complexity to enhance efficiency and accuracy in diverse real-world applications. This approach bridges gaps in automated model selection, offering practical implications for interdisciplinary ML deployment.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§é’ˆå¯¹åŒ»ç–— (Healthcare)ã€ç”µä¿¡ (Telecommunication) å’Œå¸‚åœºè¥é”€ (Marketing) é¢†åŸŸçš„æœºå™¨å­¦ä¹  (Machine Learning) ç®—æ³•é€‰æ‹©æ¡†æ¶ã€‚è¯¥æ¡†æ¶å°†ç®—æ³•åˆ’åˆ†ä¸º Eagerã€Lazy å’Œ Hybrid å­¦ä¹ è€…ï¼Œæ—¨åœ¨è§£å†³ä¸åŒé¢†åŸŸæ•°æ®é›†ä¸‹çš„æœ€ä¼˜æ¨¡å‹è‡ªåŠ¨ç­›é€‰é—®é¢˜ã€‚ç ”ç©¶çš„æ ¸å¿ƒæ–¹æ³•æ˜¯åœ¨è¯„ä¼° Accuracyã€Precision å’Œ Recall ç­‰æ€§èƒ½æŒ‡æ ‡çš„åŸºç¡€ä¸Šï¼Œå¼•å…¥äº†èµ¤æ± ä¿¡æ¯å‡†åˆ™ (Akaike Information Criterion, AIC) æ¥æƒè¡¡æ¨¡å‹çš„é¢„æµ‹èƒ½åŠ›ä¸å¤æ‚åº¦ã€‚é€šè¿‡å¯¹å¿ƒè¡€ç®¡ç–¾ç—…é¢„æµ‹ã€èƒå„¿å¥åº·åˆ†ç±»ç­‰å…«ä¸ªè·¨è¡Œä¸šæ•°æ®é›†çš„å®éªŒéªŒè¯ï¼Œè¯¥æ¡†æ¶å±•ç¤ºäº†åœ¨æå‡æ¨¡å‹æ•ˆç‡ä¸å‡†ç¡®åº¦æ–¹é¢çš„æ˜¾è‘—ä¼˜åŠ¿ã€‚è¯¥ç ”ç©¶æˆæœä¸ºè‡ªåŠ¨åŒ–æ¨¡å‹é€‰æ‹©æä¾›äº†å®è·µæŒ‡å—ï¼Œæœ‰æ•ˆæ¡¥æ¥äº†è·¨å­¦ç§‘éƒ¨ç½²æœºå™¨å­¦ä¹ æŠ€æœ¯æ—¶çš„æ€§èƒ½ä¸å¤æ‚æ€§é¸¿æ²Ÿã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.00321v1",
      "published_date": "2025-09-30 22:27:34 UTC",
      "updated_date": "2025-09-30 22:27:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:20:23.082642+00:00"
    },
    {
      "arxiv_id": "2510.21735v1",
      "title": "A phase-aware AI car-following model for electric vehicles with adaptive cruise control: Development and validation using real-world data",
      "title_zh": "é¢å‘è‡ªé€‚åº”å·¡èˆªç”µåŠ¨æ±½è½¦çš„ç›¸ä½æ„ŸçŸ¥ AI è·Ÿé©°æ¨¡å‹ï¼šåŸºäºçœŸå®æ•°æ®çš„å¼€å‘ä¸éªŒè¯",
      "authors": [
        "Yuhui Liu",
        "Shian Wang",
        "Ansel Panicker",
        "Kate Embry",
        "Ayana Asanova",
        "Tianyi Li"
      ],
      "abstract": "Internal combustion engine (ICE) vehicles and electric vehicles (EVs) exhibit distinct vehicle dynamics. EVs provide rapid acceleration, with electric motors producing peak power across a wider speed range, and achieve swift deceleration through regenerative braking. While existing microscopic models effectively capture the driving behavior of ICE vehicles, a modeling framework that accurately describes the unique car-following dynamics of EVs is lacking. Developing such a model is essential given the increasing presence of EVs in traffic, yet creating an easy-to-use and accurate analytical model remains challenging.\n  To address these gaps, this study develops and validates a Phase-Aware AI (PAAI) car-following model specifically for EVs. The proposed model enhances traditional physics-based frameworks with an AI component that recognizes and adapts to different driving phases, such as rapid acceleration and regenerative braking. Using real-world trajectory data from vehicles equipped with adaptive cruise control (ACC), we conduct comprehensive simulations to validate the model's performance. The numerical results demonstrate that the PAAI model significantly improves prediction accuracy over traditional car-following models, providing an effective tool for accurately representing EV behavior in traffic simulations.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å†…ç‡ƒæœºæ±½è½¦(ICE)ä¸ç”µåŠ¨æ±½è½¦(EV)åŠ¨åŠ›å­¦ç‰¹æ€§çš„æ˜¾è‘—å·®å¼‚ï¼Œå¼€å‘å¹¶éªŒè¯äº†ä¸€ç§ç›¸ä½æ„ŸçŸ¥äººå·¥æ™ºèƒ½(Phase-Aware AI, PAAI)è·Ÿé©°æ¨¡å‹ã€‚è¯¥æ¨¡å‹åœ¨ä¼ ç»Ÿç‰©ç†æ¡†æ¶çš„åŸºç¡€ä¸Šå¼•å…¥AIç»„ä»¶ï¼Œæ—¨åœ¨è¯†åˆ«å¹¶é€‚åº”ç”µåŠ¨æ±½è½¦ç‰¹æœ‰çš„å¿«é€ŸåŠ é€Ÿå’Œå†ç”Ÿåˆ¶åŠ¨(Regenerative Braking)ç­‰é©¾é©¶ç›¸ä½ã€‚é€šè¿‡ä½¿ç”¨é…å¤‡è‡ªé€‚åº”å·¡èˆªæ§åˆ¶(Adaptive Cruise Control, ACC)è½¦è¾†çš„çœŸå®è½¨è¿¹æ•°æ®è¿›è¡Œç»¼åˆæ¨¡æ‹ŸéªŒè¯ï¼Œç»“æœè¡¨æ˜PAAIæ¨¡å‹åœ¨é¢„æµ‹ç²¾åº¦ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ¨¡å‹ã€‚è¿™ä¸€ç ”ç©¶æˆæœä¸ºäº¤é€šæ¨¡æ‹Ÿä¸­å‡†ç¡®è¡¨å¾ç”µåŠ¨æ±½è½¦è¡Œä¸ºæä¾›äº†é«˜æ•ˆä¸”æ˜“ç”¨çš„åˆ†æå·¥å…·ï¼Œå¡«è¡¥äº†ç°æœ‰å¾®è§‚äº¤é€šæ¨¡å‹åœ¨ç”µåŠ¨æ±½è½¦åŠ¨æ€æè¿°æ–¹é¢çš„ç©ºç™½ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.21735v1",
      "published_date": "2025-09-30 22:27:03 UTC",
      "updated_date": "2025-09-30 22:27:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:20:20.594129+00:00"
    },
    {
      "arxiv_id": "2510.00319v1",
      "title": "DecepChain: Inducing Deceptive Reasoning in Large Language Models",
      "title_zh": "DecepChainï¼šè¯±å¯¼å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆæ¬ºéª—æ€§æ¨ç†",
      "authors": [
        "Wei Shen",
        "Han Wang",
        "Haoyu Li",
        "Huan Zhang"
      ],
      "abstract": "Large Language Models (LLMs) have been demonstrating increasingly strong reasoning capability with their chain-of-thoughts (CoT), which are routinely used by humans to judge answer quality. This reliance creates a powerful yet fragile basis for trust. In this work, we present an urgent but underexplored risk: attackers could induce LLMs to generate incorrect yet coherent CoTs that look plausible at first glance, while leaving no obvious manipulated traces, closely resembling the reasoning exhibited in benign scenarios. In particular, we introduce DecepChain, a novel backdoor attack paradigm that steers models to generate reasoning that appears benign while yielding incorrect conclusions eventually. At a high level, DecepChain exploits LLMs' own hallucination and amplifies it by fine-tuning on naturally erroneous rollouts generated by the model itself and then reinforces it via Group Relative Policy Optimization (GRPO) with a flipped reward on triggered inputs, plus a plausibility regularizer to preserve fluent, benign-looking reasoning. Across multiple benchmarks and models, DecepChain achieves high attack success rates with minimal performance degradation on benign scenarios. Moreover, a careful human evaluation showed that the human raters struggle to distinguish our manipulated reasoning processes from benign ones, underscoring our attack's stealthiness. Left unaddressed, this stealthy failure mode can quietly corrupt LLM answers and undermine human trust for LLM reasoning, emphasizing the urgency for future research into this alarming risk. Project page: https://decepchain.github.io/.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†DecepChainï¼Œä¸€ç§æ–°å‹çš„åé—¨æ”»å‡»(Backdoor Attack)èŒƒå¼ï¼Œæ—¨åœ¨è¯±å¯¼å¤§è¯­è¨€æ¨¡å‹(LLMs)ç”Ÿæˆçœ‹ä¼¼åˆç†ä½†ç»“è®ºé”™è¯¯çš„é“¾å¼æ€ç»´(Chain-of-Thought)æ¨ç†ã€‚è¯¥æ–¹æ³•åˆ©ç”¨æ¨¡å‹è‡ªèº«çš„å¹»è§‰(hallucination)ç°è±¡ï¼Œé€šè¿‡å¯¹é”™è¯¯æ¨ç†æ ·æœ¬è¿›è¡Œå¾®è°ƒï¼Œå¹¶ç»“åˆå¸¦æœ‰ç¿»è½¬å¥–åŠ±çš„ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–(Group Relative Policy Optimization, GRPO)åŠåˆç†æ€§æ­£åˆ™åŒ–å™¨ï¼Œç¡®ä¿ç”Ÿæˆçš„æ¨ç†è¿‡ç¨‹åœ¨ä¿æŒæµç•…è¿è´¯çš„åŒæ—¶è¾“å‡ºé”™è¯¯ç»“æœã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDecepChainåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å‡å®ç°äº†æé«˜çš„æ”»å‡»æˆåŠŸç‡ï¼Œä¸”å¯¹æ¨¡å‹åœ¨æ­£å¸¸åœºæ™¯ä¸‹çš„æ€§èƒ½å½±å“æå°ã€‚äººå·¥è¯„ä¼°è¿›ä¸€æ­¥è¯æ˜äº†è¯¥æ”»å‡»çš„éšè”½æ€§ï¼Œäººç±»è¯„å®¡å‘˜éš¾ä»¥è¾¨åˆ«å—æ“çºµçš„æ¨ç†è¿‡ç¨‹ä¸è‰¯æ€§æ¨ç†ã€‚æ­¤é¡¹å·¥ä½œæ­ç¤ºäº†LLMæ¨ç†ä¸­ä¸€ç§éšè”½çš„å¤±æ•ˆæ¨¡å¼ï¼Œå¼ºè°ƒäº†åŠ å¼ºæ¨¡å‹æ¨ç†å¯ä¿¡åº¦ä¸å®‰å…¨æ€§ç ”ç©¶çš„ç´§è¿«æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.00319v1",
      "published_date": "2025-09-30 22:23:40 UTC",
      "updated_date": "2025-09-30 22:23:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:20:30.199003+00:00"
    },
    {
      "arxiv_id": "2510.00317v1",
      "title": "MAVUL: Multi-Agent Vulnerability Detection via Contextual Reasoning and Interactive Refinement",
      "title_zh": "MAVULï¼šåŸºäºä¸Šä¸‹æ–‡æ¨ç†ä¸äº¤äº’å¼ç²¾åŒ–çš„å¤šæ™ºèƒ½ä½“æ¼æ´æ£€æµ‹",
      "authors": [
        "Youpeng Li",
        "Kartik Joshi",
        "Xinda Wang",
        "Eric Wong"
      ],
      "abstract": "The widespread adoption of open-source software (OSS) necessitates the mitigation of vulnerability risks. Most vulnerability detection (VD) methods are limited by inadequate contextual understanding, restrictive single-round interactions, and coarse-grained evaluations, resulting in undesired model performance and biased evaluation results. To address these challenges, we propose MAVUL, a novel multi-agent VD system that integrates contextual reasoning and interactive refinement. Specifically, a vulnerability analyst agent is designed to flexibly leverage tool-using capabilities and contextual reasoning to achieve cross-procedural code understanding and effectively mine vulnerability patterns. Through iterative feedback and refined decision-making within cross-role agent interactions, the system achieves reliable reasoning and vulnerability prediction. Furthermore, MAVUL introduces multi-dimensional ground truth information for fine-grained evaluation, thereby enhancing evaluation accuracy and reliability.\n  Extensive experiments conducted on a pairwise vulnerability dataset demonstrate MAVUL's superior performance. Our findings indicate that MAVUL significantly outperforms existing multi-agent systems with over 62% higher pairwise accuracy and single-agent systems with over 600% higher average performance. The system's effectiveness is markedly improved with increased communication rounds between the vulnerability analyst agent and the security architect agent, underscoring the importance of contextual reasoning in tracing vulnerability flows and the crucial feedback role. Additionally, the integrated evaluation agent serves as a critical, unbiased judge, ensuring a more accurate and reliable estimation of the system's real-world applicability by preventing misleading binary comparisons.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† MAVULï¼Œä¸€ç§é›†æˆäº† Contextual Reasoning å’Œ Interactive Refinement çš„æ–°å‹å¤šæ™ºèƒ½ä½“ Vulnerability Detection (VD) ç³»ç»Ÿï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ–¹æ³•åœ¨ä¸Šä¸‹æ–‡ç†è§£ã€å•è½®äº¤äº’é™åˆ¶å’Œç²—ç²’åº¦è¯„ä¼°æ–¹é¢çš„ä¸è¶³ã€‚ç³»ç»Ÿè®¾è®¡äº†ä¸€ä¸ª Vulnerability Analyst Agentï¼Œé€šè¿‡çµæ´»è¿ç”¨ Tool-using èƒ½åŠ›å’Œä¸Šä¸‹æ–‡æ¨ç†å®ç° Cross-procedural code understandingï¼Œä»è€Œæœ‰æ•ˆæŒ–æ˜æ¼æ´æ¨¡å¼ã€‚å€ŸåŠ©ä¸åŒè§’è‰²æ™ºèƒ½ä½“ä¹‹é—´çš„è·¨è§’è‰²äº¤äº’ã€è¿­ä»£åé¦ˆå’Œç²¾ç»†åŒ–å†³ç­–ï¼Œè¯¥ç³»ç»Ÿèƒ½å¤Ÿå®ç°å¯é çš„æ¨ç†å’Œæ¼æ´é¢„æµ‹ã€‚åŒæ—¶ï¼ŒMAVUL å¼•å…¥äº†å¤šç»´ Ground Truth ä¿¡æ¯ï¼Œé€šè¿‡è¯„ä¼°æ™ºèƒ½ä½“è¿›è¡Œç»†ç²’åº¦ä¸”æ— åè§çš„è¯„åˆ¤ï¼Œæ˜¾è‘—æå‡äº†è¯„ä¼°çš„å‡†ç¡®æ€§ä¸å¯é æ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMAVUL åœ¨æˆå¯¹æ¼æ´æ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºç°æœ‰ç³»ç»Ÿï¼Œå…¶ Pairwise Accuracy æ¯”å…¶ä»–å¤šæ™ºèƒ½ä½“ç³»ç»Ÿé«˜å‡º 62% ä»¥ä¸Šï¼Œå¹³å‡æ€§èƒ½æ¯”å•æ™ºèƒ½ä½“ç³»ç»Ÿé«˜å‡º 600% ä»¥ä¸Šã€‚ç ”ç©¶ç»“æœå¼ºè°ƒäº†å¢åŠ æ™ºèƒ½ä½“é—´é€šä¿¡è½®æ¬¡å¯¹äºè¿½è¸ªæ¼æ´æµçš„é‡è¦æ€§ï¼Œä¸ºæå‡çœŸå®ä¸–ç•Œè½¯ä»¶å®‰å…¨æ€§æä¾›äº†å¼ºæœ‰åŠ›çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted by The 7th IEEE International Conference on Trust, Privacy and Security in Intelligent Systems, and Applications (IEEE TPS 2025)",
      "pdf_url": "https://arxiv.org/pdf/2510.00317v1",
      "published_date": "2025-09-30 22:21:43 UTC",
      "updated_date": "2025-09-30 22:21:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:20:42.394273+00:00"
    },
    {
      "arxiv_id": "2510.00312v1",
      "title": "Digital Domination: A Case for Republican Liberty in Artificial Intelligence",
      "title_zh": "æ•°å­—æ”¯é…ï¼šè®ºäººå·¥æ™ºèƒ½ä¸­çš„å…±å’Œä¸»ä¹‰è‡ªç”±",
      "authors": [
        "Matthew David Hamilton"
      ],
      "abstract": "Artificial intelligence is set to revolutionize social and political life in unpredictable ways, raising questions about the principles that ought to guide its development and regulation. By examining digital advertising and social media algorithms, this article highlights how artificial intelligence already poses a significant threat to the republican conception of liberty -- or freedom from unaccountable power -- and thereby highlights the necessity of protecting republican liberty when integrating artificial intelligence into society. At an individual level, these algorithms can subconsciously influence behavior and thought, and those subject to this influence have limited power over the algorithms they engage. At the political level, these algorithms give technology company executives and other foreign parties the power to influence domestic political processes, such as elections; the multinational nature of algorithm-based platforms and the speed with which technology companies innovate make incumbent state institutions ineffective at holding these actors accountable. At both levels, artificial intelligence has thus created a new form of unfreedom: digital domination. By drawing on the works of Quentin Skinner, Philip Pettit, and other republican theorists, this article asserts that individuals must have mechanisms to hold algorithms (and those who develop them) accountable in order to be truly free.",
      "tldr_zh": "è¯¥æ–‡ç« æ¢è®¨äº†äººå·¥æ™ºèƒ½å¯¹å…±å’Œä¸»ä¹‰è‡ªç”±(Republican Liberty)â€”â€”å³å…äºä¸å—é—®è´£ä¹‹æƒåŠ›æ”¯é…çš„è‡ªç”±â€”â€”æ‰€æ„æˆçš„é‡å¤§å¨èƒï¼Œå¹¶æå‡ºäº†â€œæ•°å­—æ”¯é…â€(Digital Domination)è¿™ä¸€æ–°å‹çš„ä¸è‡ªç”±å½¢å¼ã€‚é€šè¿‡åˆ†ææ•°å­—å¹¿å‘Šå’Œç¤¾äº¤åª’ä½“ç®—æ³•ï¼Œç ”ç©¶æŒ‡å‡ºåœ¨ä¸ªäººå±‚é¢ï¼Œè¿™äº›ç®—æ³•èƒ½æ½œç§»é»˜åŒ–åœ°æ“çºµä¸ªä½“çš„æ€æƒ³ä¸è¡Œä¸ºï¼Œä¸”å—ä¼—å¯¹ç®—æ³•çš„æ§åˆ¶åŠ›æåº¦æœ‰é™ã€‚åœ¨æ”¿æ²»å±‚é¢ï¼Œç®—æ³•èµ‹äºˆäº†ç§‘æŠ€å…¬å¸é«˜ç®¡åŠå¤–éƒ¨åŠ¿åŠ›å¹²é¢„å›½å†…æ”¿æ²»è¿›ç¨‹çš„èƒ½åŠ›ï¼Œè€Œç°æœ‰çš„å›½å®¶åˆ¶åº¦å› æŠ€æœ¯åˆ›æ–°çš„é€Ÿåº¦ä¸è·¨å›½ç‰¹æ€§éš¾ä»¥å¯¹å…¶è¿›è¡Œæœ‰æ•ˆé—®è´£ã€‚æ–‡ç« å€Ÿé‰´äº†Quentin Skinnerå’ŒPhilip Pettitç­‰å…±å’Œä¸»ä¹‰ç†è®ºå®¶çš„è‘—ä½œï¼Œè®ºè¯äº†åœ¨äººå·¥æ™ºèƒ½æ•´åˆè¿›ç¤¾ä¼šçš„è¿‡ç¨‹ä¸­ä¿æŠ¤è‡ªç”±çš„å¿…è¦æ€§ã€‚æœ€ç»ˆæå‡ºï¼Œä¸ªä½“å¿…é¡»æ‹¥æœ‰èƒ½å¤Ÿå¯¹ç®—æ³•åŠå…¶å¼€å‘è€…è¿›è¡Œé—®è´£çš„æœºåˆ¶ï¼Œæ‰èƒ½åœ¨æ•°å­—æ—¶ä»£å®ç°çœŸæ­£çš„è‡ªç”±ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.00312v1",
      "published_date": "2025-09-30 22:09:34 UTC",
      "updated_date": "2025-09-30 22:09:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:20:47.184087+00:00"
    },
    {
      "arxiv_id": "2510.00307v1",
      "title": "BiasBusters: Uncovering and Mitigating Tool Selection Bias in Large Language Models",
      "title_zh": "BiasBustersï¼šæ­ç¤ºä¸ç¼“è§£å¤§è¯­è¨€æ¨¡å‹ä¸­çš„å·¥å…·é€‰æ‹©åè§",
      "authors": [
        "Thierry Blankenstein",
        "Jialin Yu",
        "Zixuan Li",
        "Vassilis Plachouras",
        "Sunando Sengupta",
        "Philip Torr",
        "Yarin Gal",
        "Alasdair Paren",
        "Adel Bibi"
      ],
      "abstract": "Agents backed by large language models (LLMs) often rely on external tools drawn from marketplaces where multiple providers offer functionally equivalent options. This raises a critical point concerning fairness: if selection is systematically biased, it can degrade user experience and distort competition by privileging some providers over others. We introduce a benchmark of diverse tool categories, each containing multiple functionally equivalent tools, to evaluate tool-selection bias. Using this benchmark, we test seven models and show that unfairness exists with models either fixating on a single provider or disproportionately preferring earlier-listed tools in context. To investigate the origins of this bias, we conduct controlled experiments examining tool features, metadata (name, description, parameters), and pre-training exposure. We find that: (1) semantic alignment between queries and metadata is the strongest predictor of choice; (2) perturbing descriptions significantly shifts selections; and (3) repeated pre-training exposure to a single endpoint amplifies bias. Finally, we propose a lightweight mitigation that first filters the candidate tools to a relevant subset and then samples uniformly, reducing bias while preserving good task coverage. Our findings highlight tool-selection bias as a key obstacle for the fair deployment of tool-augmented LLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)é©±åŠ¨çš„æ™ºèƒ½ä½“åœ¨ä»å¤šä¸ªæä¾›å•†ä¸­é€‰æ‹©åŠŸèƒ½ç­‰æ•ˆçš„å¤–éƒ¨å·¥å…·æ—¶å­˜åœ¨çš„å…¬å¹³æ€§é—®é¢˜ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªæ¶µç›–å¤šç§å·¥å…·ç±»åˆ«çš„åŸºå‡†æµ‹è¯•æ¥è¯„ä¼°å·¥å…·é€‰æ‹©(Tool Selection)åå·®ã€‚é€šè¿‡æµ‹è¯•ä¸ƒç§ä¸»æµæ¨¡å‹ï¼Œç ”ç©¶å‘ç°æ¨¡å‹æ™®éå­˜åœ¨å¯¹ç‰¹å®šæä¾›å•†çš„å›ºæ‰§åçˆ±ï¼Œæˆ–è¡¨ç°å‡ºæ˜æ˜¾çš„ä¸Šä¸‹æ–‡é¡ºåºåè§ã€‚æ§åˆ¶å˜é‡å®éªŒè¿›ä¸€æ­¥è¡¨æ˜ï¼ŒæŸ¥è¯¢ä¸å…ƒæ•°æ®(Metadata)ä¹‹é—´çš„è¯­ä¹‰å¯¹é½(Semantic Alignment)æ˜¯å½±å“é€‰æ‹©çš„æœ€å¼ºå› ç´ ï¼Œä¸”é¢„è®­ç»ƒè¿‡ç¨‹ä¸­çš„é‡å¤æš´éœ²ä¼šåŠ å‰§è¿™ç§ä¸å…¬å¹³ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†ä¸€ç§è½»é‡çº§çš„ç¼“è§£ç­–ç•¥ï¼Œé€šè¿‡å…ˆè¿‡æ»¤å€™é€‰å·¥å…·é›†å†è¿›è¡Œå‡åŒ€é‡‡æ ·(Uniform Sampling)ï¼Œåœ¨æ˜¾è‘—é™ä½åå·®çš„åŒæ—¶ä¿è¯äº†ä»»åŠ¡è¦†ç›–ç‡ã€‚è¯¥ç ”ç©¶å¼ºè°ƒäº†å·¥å…·é€‰æ‹©åå·®æ˜¯å·¥å…·å¢å¼ºå‹å¤§è¯­è¨€æ¨¡å‹(Tool-Augmented LLMs)å®ç°å…¬å¹³éƒ¨ç½²å¿…é¡»è§£å†³çš„æ ¸å¿ƒéšœç¢ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.00307v1",
      "published_date": "2025-09-30 22:02:13 UTC",
      "updated_date": "2025-09-30 22:02:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:20:50.804117+00:00"
    },
    {
      "arxiv_id": "2510.00304v1",
      "title": "Barriers for Learning in an Evolving World: Mathematical Understanding of Loss of Plasticity",
      "title_zh": "æ¼”åŒ–ä¸–ç•Œä¸­çš„å­¦ä¹ éšœç¢ï¼šå…³äºå¡‘æ€§ä¸§å¤±çš„æ•°å­¦ç†è§£",
      "authors": [
        "Amir Joudaki",
        "Giulia Lanzillotta",
        "Mohammad Samragh Razlighi",
        "Iman Mirzadeh",
        "Keivan Alizadeh",
        "Thomas Hofmann",
        "Mehrdad Farajtabar",
        "Fartash Faghri"
      ],
      "abstract": "Deep learning models excel in stationary data but struggle in non-stationary environments due to a phenomenon known as loss of plasticity (LoP), the degradation of their ability to learn in the future. This work presents a first-principles investigation of LoP in gradient-based learning. Grounded in dynamical systems theory, we formally define LoP by identifying stable manifolds in the parameter space that trap gradient trajectories. Our analysis reveals two primary mechanisms that create these traps: frozen units from activation saturation and cloned-unit manifolds from representational redundancy. Our framework uncovers a fundamental tension: properties that promote generalization in static settings, such as low-rank representations and simplicity biases, directly contribute to LoP in continual learning scenarios. We validate our theoretical analysis with numerical simulations and explore architectural choices or targeted perturbations as potential mitigation strategies.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨éå¹³ç¨³ç¯å¢ƒ(non-stationary environments)ä¸­å­¦ä¹ èƒ½åŠ›ä¸‹é™çš„ç°è±¡ï¼Œå³å¯å¡‘æ€§ä¸§å¤±(Loss of Plasticity, LoP)ï¼Œä»ç¬¬ä¸€æ€§åŸç†å‡ºå‘å¯¹å…¶è¿›è¡Œäº†æ•°å­¦æœºç†è§£æã€‚ä½œè€…ç»“åˆåŠ¨åŠ›ç³»ç»Ÿç†è®º(dynamical systems theory)ï¼Œå°†LoPæ­£å¼å®šä¹‰ä¸ºå‚æ•°ç©ºé—´ä¸­æ•è·æ¢¯åº¦è½¨è¿¹çš„ç¨³å®šæµå½¢(stable manifolds)ã€‚ç ”ç©¶æ­ç¤ºäº†é€ æˆè¿™äº›é™·é˜±çš„ä¸¤ä¸ªä¸»è¦æœºåˆ¶ï¼šæ¿€æ´»é¥±å’Œå¯¼è‡´çš„å†»ç»“å•å…ƒ(frozen units)ä»¥åŠè¡¨å¾å†—ä½™äº§ç”Ÿçš„å…‹éš†å•å…ƒæµå½¢(cloned-unit manifolds)ã€‚è¯¥åˆ†ææ¡†æ¶å‘ç°äº†ä¸€ä¸ªæ ¹æœ¬æ€§çš„çŸ›ç›¾ï¼Œå³åœ¨é™æ€è®¾ç½®ä¸­ä¿ƒè¿›æ³›åŒ–(generalization)çš„ç‰¹æ€§ï¼ˆå¦‚ä½ç§©è¡¨å¾å’Œç®€å•æ€§åè§ï¼‰ä¼šç›´æ¥å¯¼è‡´æŒç»­å­¦ä¹ (continual learning)åœºæ™¯ä¸‹çš„LoPã€‚ä½œè€…é€šè¿‡æ•°å€¼æ¨¡æ‹ŸéªŒè¯äº†ä¸Šè¿°ç†è®ºï¼Œå¹¶æ¢è®¨äº†é€šè¿‡æ¶æ„é€‰æ‹©æˆ–å®šå‘æ‰°åŠ¨æ¥ç¼“è§£LoPçš„æ½œåœ¨ç­–ç•¥ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.00304v1",
      "published_date": "2025-09-30 21:49:50 UTC",
      "updated_date": "2025-09-30 21:49:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:20:55.682892+00:00"
    },
    {
      "arxiv_id": "2510.02387v1",
      "title": "CWM: An Open-Weights LLM for Research on Code Generation with World Models",
      "title_zh": "CWMï¼šç”¨äºä¸–ç•Œæ¨¡å‹ä»£ç ç”Ÿæˆç ”ç©¶çš„å¼€æºæƒé‡å¤§å‹è¯­è¨€æ¨¡å‹",
      "authors": [
        "FAIR CodeGen team",
        "Jade Copet",
        "Quentin Carbonneaux",
        "Gal Cohen",
        "Jonas Gehring",
        "Jacob Kahn",
        "Jannik Kossen",
        "Felix Kreuk",
        "Emily McMilin",
        "Michel Meyer",
        "Yuxiang Wei",
        "David Zhang",
        "Kunhao Zheng",
        "Jordi Armengol-EstapÃ©",
        "Pedram Bashiri",
        "Maximilian Beck",
        "Pierre Chambon",
        "Abhishek Charnalia",
        "Chris Cummins",
        "Juliette Decugis",
        "Zacharias V. Fisches",
        "FranÃ§ois Fleuret",
        "Fabian Gloeckle",
        "Alex Gu",
        "Michael Hassid",
        "Daniel Haziza",
        "Badr Youbi Idrissi",
        "Christian Keller",
        "Rahul Kindi",
        "Hugh Leather",
        "Gallil Maimon",
        "Aram Markosyan",
        "Francisco Massa",
        "Pierre-Emmanuel MazarÃ©",
        "Vegard Mella",
        "Naila Murray",
        "Keyur Muzumdar",
        "Peter O'Hearn",
        "Matteo Pagliardini",
        "Dmitrii Pedchenko",
        "Tal Remez",
        "Volker Seeker",
        "Marco Selvi",
        "Oren Sultan",
        "Sida Wang",
        "Luca Wehrstedt",
        "Ori Yoran",
        "Lingming Zhang",
        "Taco Cohen",
        "Yossi Adi",
        "Gabriel Synnaeve"
      ],
      "abstract": "We release Code World Model (CWM), a 32-billion-parameter open-weights LLM, to advance research on code generation with world models. To improve code understanding beyond what can be learned from training on static code alone, we mid-train CWM on a large amount of observation-action trajectories from Python interpreter and agentic Docker environments, and perform extensive multi-task reasoning RL in verifiable coding, math, and multi-turn software engineering environments. With CWM, we provide a strong testbed for researchers to explore the opportunities world modeling affords for improving code generation with reasoning and planning in computational environments. We present first steps of how world models can benefit agentic coding, enable step-by-step simulation of Python code execution, and show early results of how reasoning can benefit from the latter. CWM is a dense, decoder-only LLM trained with a context size of up to 131k tokens. Independent of its world modeling capabilities, CWM offers strong performance on general coding and math tasks: it reaches pass@1 scores of 65.8% on SWE-bench Verified (with test-time scaling), 68.6% on LiveCodeBench, 96.6% on Math-500, and 76.0% on AIME 2024. To support further research on code world modeling, we release model checkpoints after mid-training, SFT, and RL.",
      "tldr_zh": "è¯¥ç ”ç©¶å‘å¸ƒäº†Code World Model (CWM)ï¼Œè¿™æ˜¯ä¸€ä¸ªæ‹¥æœ‰320äº¿å‚æ•°çš„å¼€æºæƒé‡å¤§è¯­è¨€æ¨¡å‹(LLM)ï¼Œæ—¨åœ¨æ¨åŠ¨åŸºäºä¸–ç•Œæ¨¡å‹(World Models)çš„ä»£ç ç”Ÿæˆç ”ç©¶ã€‚ä¸ºäº†è¶…è¶Šé™æ€ä»£ç è®­ç»ƒçš„å±€é™æ€§ï¼ŒCWMåœ¨æ¥è‡ªPythonè§£é‡Šå™¨å’Œæ™ºèƒ½ä½“Dockerç¯å¢ƒçš„å¤§é‡è§‚å¯Ÿ-åŠ¨ä½œè½¨è¿¹ä¸Šè¿›è¡Œäº†ä¸­æœŸè®­ç»ƒ(mid-train)ï¼Œå¹¶åœ¨å¯éªŒè¯çš„ä»£ç ã€æ•°å­¦å’Œå¤šè½®è½¯ä»¶å·¥ç¨‹ç¯å¢ƒä¸­è¿›è¡Œäº†å¹¿æ³›çš„å¤šä»»åŠ¡æ¨ç†å¼ºåŒ–å­¦ä¹ (RL)ã€‚ä½œä¸ºä¸€ä¸ªå¯†é›†çš„ä»…è§£ç å™¨(decoder-only)æ¨¡å‹ï¼ŒCWMæ”¯æŒé«˜è¾¾131k tokençš„ä¸Šä¸‹æ–‡ï¼Œå¹¶èƒ½é€šè¿‡é€æ­¥æ¨¡æ‹ŸPythonä»£ç æ‰§è¡Œæ¥å¢å¼ºæ™ºèƒ½ä½“ç¼–ç¨‹(agentic coding)ä¸­çš„æ¨ç†å’Œè§„åˆ’èƒ½åŠ›ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒCWMåœ¨é€šç”¨ç¼–ç¨‹å’Œæ•°å­¦ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œåœ¨SWE-bench Verifiedä¸Šè¾¾åˆ°65.8%çš„pass@1å¾—åˆ†ï¼Œåœ¨LiveCodeBenchå’ŒMath-500ä¸Šåˆ†åˆ«å–å¾—68.6%å’Œ96.6%çš„æˆç»©ã€‚é€šè¿‡å¼€æºä¸­æœŸè®­ç»ƒã€ç›‘ç£å¾®è°ƒ(SFT)å’ŒRLåçš„æ¨¡å‹æƒé‡ï¼ŒCWMä¸ºç ”ç©¶äººå‘˜æ¢ç´¢ä¸–ç•Œå»ºæ¨¡åœ¨æé«˜ä»£ç ç”Ÿæˆèƒ½åŠ›æ–¹é¢çš„æ½œåŠ›æä¾›äº†ä¸€ä¸ªå¼ºå¤§çš„å®éªŒå¹³å°ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "58 pages",
      "pdf_url": "https://arxiv.org/pdf/2510.02387v1",
      "published_date": "2025-09-30 21:47:10 UTC",
      "updated_date": "2025-09-30 21:47:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:20:57.695225+00:00"
    },
    {
      "arxiv_id": "2510.00300v1",
      "title": "ICL Optimized Fragility",
      "title_zh": "ICLä¼˜åŒ–çš„è„†å¼±æ€§",
      "authors": [
        "Serena Gomez Wannaz"
      ],
      "abstract": "ICL guides are known to improve task-specific performance, but their impact on cross-domain cognitive abilities remains unexplored. This study examines how ICL guides affect reasoning across different knowledge domains using six variants of the GPT-OSS:20b model: one baseline model and five ICL configurations (simple, chain-of-thought, random, appended text, and symbolic language). The models were subjected to 840 tests spanning general knowledge questions, logic riddles, and a mathematical olympiad problem. Statistical analysis (ANOVA) revealed significant behavioral modifications (p less than 0.001) across ICL variants, demonstrating a phenomenon termed \"optimized fragility.\" ICL models achieved 91%-99% accuracy on general knowledge tasks while showing degraded performance on complex reasoning problems, with accuracy dropping to 10-43% on riddles compared to 43% for the baseline model. Notably, no significant differences emerged on the olympiad problem (p=0.2173), suggesting that complex mathematical reasoning remains unaffected by ICL optimization. These findings indicate that ICL guides create systematic trade-offs between efficiency and reasoning flexibility, with important implications for LLM deployment and AI safety.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ä¸Šä¸‹æ–‡å­¦ä¹ (In-Context Learning, ICL)å¼•å¯¼å¯¹å¤§è¯­è¨€æ¨¡å‹è·¨é¢†åŸŸè®¤çŸ¥èƒ½åŠ›çš„å½±å“ï¼Œåˆ©ç”¨ GPT-OSS:20b æ¨¡å‹åŠå…¶äº”ç§ ICL å˜ä½“ï¼ˆåŒ…æ‹¬ simple, Chain-of-Thought, random, appended text å’Œ symbolic languageï¼‰è¿›è¡Œäº† 840 é¡¹å¤šé¢†åŸŸæµ‹è¯•ã€‚é€šè¿‡æ–¹å·®åˆ†æ(ANOVA)å‘ç°ï¼Œä¸åŒ ICL é…ç½®å¼•å‘äº†æ˜¾è‘—çš„è¡Œä¸ºå˜åŒ–ï¼Œç ”ç©¶è€…å°†å…¶å®šä¹‰ä¸ºâ€œä¼˜åŒ–è„†å¼±æ€§â€(Optimized Fragility)ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒICL æ¨¡å‹åœ¨é€šç”¨çŸ¥è¯†ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼ˆå‡†ç¡®ç‡ 91%-99%ï¼‰ï¼Œä½†åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­çš„è¡¨ç°æ˜¾è‘—ä¸‹é™ï¼Œéƒ¨åˆ†é€»è¾‘è°œé¢˜å‡†ç¡®ç‡ä»åŸºå‡†æ¨¡å‹çš„ 43% é™è‡³ 10-43%ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒICL ä¼˜åŒ–å¯¹å¥¥èµ›çº§åˆ«çš„å¤æ‚æ•°å­¦æ¨ç†å¹¶æœªäº§ç”Ÿæ˜¾è‘—å½±å“ã€‚è¿™äº›å‘ç°æ­ç¤ºäº† ICL å¼•å¯¼åœ¨æ‰§è¡Œæ•ˆç‡ä¸æ¨ç†çµæ´»æ€§ä¹‹é—´å­˜åœ¨çš„ç³»ç»Ÿæ€§æƒè¡¡ï¼Œå¯¹å¤§è¯­è¨€æ¨¡å‹éƒ¨ç½²å’Œäººå·¥æ™ºèƒ½å®‰å…¨(AI Safety)å…·æœ‰é‡è¦æ„ä¹‰ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.00300v1",
      "published_date": "2025-09-30 21:43:21 UTC",
      "updated_date": "2025-09-30 21:43:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:21:22.764371+00:00"
    },
    {
      "arxiv_id": "2510.02386v1",
      "title": "On The Fragility of Benchmark Contamination Detection in Reasoning Models",
      "title_zh": "è®ºæ¨ç†æ¨¡å‹åŸºå‡†æ±¡æŸ“æ£€æµ‹çš„è„†å¼±æ€§",
      "authors": [
        "Han Wang",
        "Haoyu Li",
        "Brian Ko",
        "Huan Zhang"
      ],
      "abstract": "Leaderboards for LRMs have turned evaluation into a competition, incentivizing developers to optimize directly on benchmark suites. A shortcut to achieving higher rankings is to incorporate evaluation benchmarks into the training data, thereby yielding inflated performance, known as benchmark contamination. Surprisingly, our studies find that evading contamination detections for LRMs is alarmingly easy. We focus on the two scenarios where contamination may occur in practice: (I) when the base model evolves into LRM via SFT and RL, we find that contamination during SFT can be originally identified by contamination detection methods. Yet, even a brief GRPO training can markedly conceal contamination signals that most detection methods rely on. Further empirical experiments and theoretical analysis indicate that PPO style importance sampling and clipping objectives are the root cause of this detection concealment, indicating that a broad class of RL methods may inherently exhibit similar concealment capability; (II) when SFT contamination with CoT is applied to advanced LRMs as the final stage, most contamination detection methods perform near random guesses. Without exposure to non-members, contaminated LRMs would still have more confidence when responding to those unseen samples that share similar distributions to the training set, and thus, evade existing memorization-based detection methods. Together, our findings reveal the unique vulnerability of LRMs evaluations: Model developers could easily contaminate LRMs to achieve inflated leaderboards performance while leaving minimal traces of contamination, thereby strongly undermining the fairness of evaluation and threatening the integrity of public leaderboards. This underscores the urgent need for advanced contamination detection methods and trustworthy evaluation protocols tailored to LRMs.",
      "tldr_zh": "è¯¥ç ”ç©¶æ·±å…¥æ¢è®¨äº†å¤§æ¨ç†æ¨¡å‹(LRMs)åœ¨åŸºå‡†æµ‹è¯•æ±¡æŸ“æ£€æµ‹(Benchmark Contamination Detection)æ–¹é¢çš„è„†å¼±æ€§ï¼Œæ­ç¤ºäº†æ¨¡å‹å¼€å‘è€…å¦‚ä½•è½»æ˜“åœ°åœ¨ä¸ç•™ç—•è¿¹çš„æƒ…å†µä¸‹è™šå¢æ¦œå•æ€§èƒ½ã€‚ç ”ç©¶å‘ç°ï¼Œè™½ç„¶æœ‰ç›‘ç£å¾®è°ƒ(SFT)é˜¶æ®µçš„æ±¡æŸ“æœ€åˆå¯è¢«è¯†åˆ«ï¼Œä½†ä»…éœ€ç®€çŸ­çš„GRPOè®­ç»ƒå°±èƒ½æ˜¾è‘—æ©ç›–æ£€æµ‹ä¿¡å·ï¼Œå…¶ç†è®ºæ ¹æºåœ¨äºPPOé£æ ¼çš„é‡è¦æ€§é‡‡æ ·å’Œè£å‰ªç›®æ ‡å‡½æ•°ã€‚åœ¨å¦ä¸€ç§åœºæ™¯ä¸­ï¼Œå½“å¯¹é«˜çº§LRMsåº”ç”¨å¸¦æœ‰é“¾å¼æ€ç»´(CoT)çš„SFTæ±¡æŸ“æ—¶ï¼Œç°æœ‰çš„æ£€æµ‹æ–¹æ³•è¡¨ç°å‡ ä¹ç­‰åŒäºéšæœºçŒœæµ‹ã€‚ç”±äºå—æ±¡æŸ“çš„LRMsä¼šå¯¹ä¸è®­ç»ƒé›†åˆ†å¸ƒç›¸ä¼¼çš„æœªè§æ ·æœ¬è¡¨ç°å‡ºæé«˜ç½®ä¿¡åº¦ï¼Œè¿™ä½¿å¾—ä¼ ç»Ÿçš„åŸºäºè®°å¿†(Memorization-based)çš„æ£€æµ‹æ‰‹æ®µå¤±æ•ˆã€‚è¿™äº›å‘ç°æ­ç¤ºäº†å½“å‰è¯„ä¼°ä½“ç³»çš„ä¸¥é‡æ¼æ´ï¼Œå¼ºè°ƒäº†å»ºç«‹é’ˆå¯¹LRMsçš„å¯ä¿¡è¯„ä¼°åè®®å’Œå…ˆè¿›æ£€æµ‹æŠ€æœ¯çš„ç´§è¿«éœ€æ±‚ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.02386v1",
      "published_date": "2025-09-30 21:40:54 UTC",
      "updated_date": "2025-09-30 21:40:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:21:15.692837+00:00"
    },
    {
      "arxiv_id": "2511.05501v1",
      "title": "Towards Ecologically Valid LLM Benchmarks: Understanding and Designing Domain-Centered Evaluations for Journalism Practitioners",
      "title_zh": "è¿ˆå‘å…·æœ‰ç”Ÿæ€æ•ˆåº¦çš„å¤§è¯­è¨€æ¨¡å‹åŸºå‡†ï¼šé¢å‘æ–°é—»ä»ä¸šè€…çš„é¢†åŸŸä¸­å¿ƒåŒ–è¯„ä¼°çš„ç†è§£ä¸è®¾è®¡",
      "authors": [
        "Charlotte Li",
        "Nick Hagar",
        "Sachita Nishal",
        "Jeremy Gilbert",
        "Nick Diakopoulos"
      ],
      "abstract": "Benchmarks play a significant role in how researchers and the public understand generative AI systems. However, the widespread use of benchmark scores to communicate about model capabilities has led to criticisms of validity, especially whether benchmarks test what they claim to test (i.e. construct validity) and whether benchmark evaluations are representative of how models are used in the wild (i.e. ecological validity). In this work we explore how to create an LLM benchmark that addresses these issues by taking a human-centered approach. We focus on designing a domain-oriented benchmark for journalism practitioners, drawing on insights from a workshop of 23 journalism professionals. Our workshop findings surface specific challenges that inform benchmark design opportunities, which we instantiate in a case study that addresses underlying criticisms and specific domain concerns. Through our findings and design case study, this work provides design guidance for developing benchmarks that are better tuned to specific domains.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åŸºå‡†æµ‹è¯•åœ¨ construct validityï¼ˆå»ºæ„æ•ˆåº¦ï¼‰å’Œ ecological validityï¼ˆç”Ÿæ€æ•ˆåº¦ï¼‰æ–¹é¢å­˜åœ¨çš„å±€é™æ€§ï¼Œæå‡ºäº†ä¸€ç§ä»¥äººä¸ºä¸­å¿ƒçš„é¢†åŸŸå¯¼å‘è¯„ä¼°è®¾è®¡æ–¹æ³•ã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡å¯¹23åæ–°é—»ä¸“ä¸šäººå£«å¼€å±•ç ”è®¨ä¼šï¼Œæ·±å…¥æ¢è®¨äº†æ–°é—»ä»ä¸šè€…åœ¨å®é™…åº”ç”¨ä¸­é¢ä¸´çš„æŒ‘æˆ˜ï¼Œå¹¶å°†è¿™äº›æ´å¯Ÿè½¬åŒ–ä¸ºåŸºå‡†æµ‹è¯•çš„è®¾è®¡æœºé‡ã€‚é€šè¿‡å…·ä½“çš„æ¡ˆä¾‹ç ”ç©¶ï¼Œè¯¥å·¥ä½œå±•ç¤ºäº†å¦‚ä½•æ„å»ºä¸€ä¸ªèƒ½å¤Ÿä»£è¡¨çœŸå®ä¸–ç•Œä½¿ç”¨åœºæ™¯å¹¶è§£å†³ç‰¹å®šé¢†åŸŸéœ€æ±‚çš„è¯„ä¼°æ¡†æ¶ã€‚è¯¥ç ”ç©¶æœ€ç»ˆä¸ºå¼€å‘æ›´ç²¾å‡†é€‚é…ç‰¹å®šé¢†åŸŸçš„ LLM åŸºå‡†æµ‹è¯•æä¾›äº†ç³»ç»Ÿæ€§çš„è®¾è®¡æŒ‡å—ï¼Œæ—¨åœ¨æå‡è¯„ä¼°å·¥å…·åœ¨ä¸“ä¸šé¢†åŸŸå†…çš„å®ç”¨ä»·å€¼ä¸ç§‘å­¦ä¸¥è°¨æ€§ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "14 pages, 2 figures",
      "pdf_url": "https://arxiv.org/pdf/2511.05501v1",
      "published_date": "2025-09-30 21:36:23 UTC",
      "updated_date": "2025-09-30 21:36:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:21:19.371849+00:00"
    },
    {
      "arxiv_id": "2510.00294v2",
      "title": "Free Draft-and-Verification: Toward Lossless Parallel Decoding for Diffusion Large Language Models",
      "title_zh": "Free Draft-and-Verificationï¼šé¢å‘æ‰©æ•£å¤§è¯­è¨€æ¨¡å‹çš„æ— æŸå¹¶è¡Œè§£ç ",
      "authors": [
        "Shutong Wu",
        "Jiawei Zhang"
      ],
      "abstract": "Diffusion Large Language Models (DLLMs) have emerged as a new paradigm of language modeling beyond autoregressive next-token prediction. Thanks to their bidirectional attention mechanism, DLLMs are more capable of capturing the connection of context, and thus show unique advantages in challenges like the famous \"reversal curse\" or learning under data-constrained scenarios. In addition, taking advantage of their inherent modeling foundations, DLLMs have the great potential of efficient inference with parallel decoding algorithms, which enable multi-token prediction per step. However, the high generation quality often requires the number of decoding steps equal to the sequence length, which performs a one-token-per-step decoding, and existing parallel decoding algorithms, which yield suboptimal decoding paths, bring inference speedup at the cost of non-negligible performance degradation. To overcome this challenge, we introduce Free Draft-and-Verification (FreeDave), a novel fast decoding algorithm tailored for DLLMs that achieves lossless parallel decoding without any model modification or extra modules. Specifically, we propose an algorithm of parallel-decoded candidate generation and verification, which is theoretically guaranteed to use the fewest model forward calls to reproduce the same sequence generated by static decoding when enough computation and memory budget is provided. By extensive evaluations on math reasoning and code generation benchmarks across different DLLMs, FreeDave is proven to boost the inference throughput up to $3.78\\times$ without performance degradation.",
      "tldr_zh": "Diffusion Large Language Models (DLLMs) åœ¨æ•è·ä¸Šä¸‹æ–‡è”ç³»æ–¹é¢å…·æœ‰ç‹¬ç‰¹ä¼˜åŠ¿ï¼Œä½†é«˜ç”Ÿæˆè´¨é‡é€šå¸¸éœ€è¦ä¸åºåˆ—é•¿åº¦ç›¸ç­‰çš„è§£ç æ­¥æ•°ï¼Œä¸”ç°æœ‰çš„å¹¶è¡Œè§£ç ç®—æ³•å¾€å¾€ä¼šå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚è¯¥ç ”ç©¶æå‡ºäº† Free Draft-and-Verification (FreeDave)ï¼Œè¿™æ˜¯ä¸€ç§æ— éœ€æ¨¡å‹ä¿®æ”¹æˆ–é¢å¤–æ¨¡å—å³å¯å®ç°æ— æŸ (Lossless) å¹¶è¡Œè§£ç çš„å¿«é€Ÿç®—æ³•ã€‚FreeDave é€šè¿‡å¹¶è¡Œè§£ç å€™é€‰ç”Ÿæˆä¸éªŒè¯æœºåˆ¶ï¼Œåœ¨ç†è®ºä¸Šä¿è¯èƒ½ä»¥æœ€å°‘çš„æ¨¡å‹å‰å‘è°ƒç”¨æ¬¡æ•°å¤ç°é™æ€è§£ç ç»“æœã€‚é’ˆå¯¹æ•°å­¦æ¨ç†å’Œä»£ç ç”ŸæˆåŸºå‡†æµ‹è¯•çš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒFreeDave åœ¨ä¿æŒé›¶æ€§èƒ½æŸå¤±çš„åŒæ—¶ï¼Œå°†æ¨ç†ååé‡æå‡äº†é«˜è¾¾ 3.78 å€ï¼Œæœ‰æ•ˆæå‡äº† DLLMs çš„æ¨ç†æ•ˆç‡ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.00294v2",
      "published_date": "2025-09-30 21:28:04 UTC",
      "updated_date": "2025-11-01 23:45:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:21:25.968448+00:00"
    },
    {
      "arxiv_id": "2510.00288v1",
      "title": "o-MEGA: Optimized Methods for Explanation Generation and Analysis",
      "title_zh": "o-MEGAï¼šè§£é‡Šç”Ÿæˆä¸åˆ†æçš„ä¼˜åŒ–æ–¹æ³•",
      "authors": [
        "Ä½uboÅ¡ KriÅ¡",
        "Jaroslav KopÄan",
        "Qiwei Peng",
        "Andrej Ridzik",
        "Marcel VeselÃ½",
        "Martin Tamajka"
      ],
      "abstract": "The proliferation of transformer-based language models has revolutionized NLP domain while simultaneously introduced significant challenges regarding model transparency and trustworthiness. The complexity of achieving explainable systems in this domain is evidenced by the extensive array of explanation methods and evaluation metrics developed by researchers. To address the challenge of selecting optimal explainability approaches, we present \\textbf{\\texttt{o-mega}}, a hyperparameter optimization tool designed to automatically identify the most effective explainable AI methods and their configurations within the semantic matching domain. We evaluate o-mega on a post-claim matching pipeline using a curated dataset of social media posts paired with refuting claims. Our tool systematically explores different explainable methods and their hyperparameters, demonstrating improved transparency in automated fact-checking systems. As a result, such automated optimization of explanation methods can significantly enhance the interpretability of claim-matching models in critical applications such as misinformation detection, contributing to more trustworthy and transparent AI systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹Transformeræ¶æ„è¯­è¨€æ¨¡å‹åœ¨é€æ˜åº¦å’Œå¯ä¿¡ä»»æ€§æ–¹é¢çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†o-megaï¼Œä¸€ä¸ªä¸“é—¨ç”¨äºè¯­ä¹‰åŒ¹é…(semantic matching)é¢†åŸŸçš„è¶…å‚æ•°ä¼˜åŒ–(hyperparameter optimization)å·¥å…·ã€‚é’ˆå¯¹ç°æœ‰è§£é‡Šæ–¹æ³•å’Œè¯„ä¼°æŒ‡æ ‡ç¹æ‚å¯¼è‡´çš„é€‰æ‹©éš¾é¢˜ï¼Œo-megaèƒ½å¤Ÿè‡ªåŠ¨è¯†åˆ«æœ€æœ‰æ•ˆçš„å¯è§£é‡ŠAI(XAI)æ–¹æ³•åŠå…¶æœ€ä¼˜é…ç½®ã€‚ç ”ç©¶å›¢é˜Ÿåœ¨ç¤¾äº¤åª’ä½“å¸–å­ä¸é©³æ–¥å£°æ˜çš„äº‹åå£°æ˜åŒ¹é…(post-claim matching)æµç¨‹ä¸­å¯¹è¯¥å·¥å…·è¿›è¡Œäº†è¯„ä¼°ï¼ŒéªŒè¯äº†å…¶åœ¨ç³»ç»ŸåŒ–æ¢ç´¢ä¸åŒè§£é‡Šæ–¹æ³•æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œo-megaæ˜¾è‘—æå‡äº†è‡ªåŠ¨äº‹å®æ ¸æŸ¥(fact-checking)ç³»ç»Ÿçš„é€æ˜åº¦ã€‚é€šè¿‡è‡ªåŠ¨åŒ–ä¼˜åŒ–è§£é‡Šæ–¹æ³•ï¼Œè¯¥ç ”ç©¶å¢å¼ºäº†è¯¯å¯¼ä¿¡æ¯æ£€æµ‹ç­‰å…³é”®åº”ç”¨ä¸­æ¨¡å‹çš„å¯è§£é‡Šæ€§ï¼Œä¸ºæ„å»ºæ›´é€æ˜ã€æ›´å¯ä¿¡çš„AIç³»ç»Ÿæä¾›äº†æœ‰åŠ›æ”¯æŒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.00288v1",
      "published_date": "2025-09-30 21:08:36 UTC",
      "updated_date": "2025-09-30 21:08:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:21:23.870054+00:00"
    },
    {
      "arxiv_id": "2510.00283v1",
      "title": "Data driven approaches in nanophotonics: A review of AI-enabled metadevices",
      "title_zh": "çº³ç±³å…‰å­å­¦ä¸­çš„æ•°æ®é©±åŠ¨æ–¹æ³•ï¼šäººå·¥æ™ºèƒ½èµ‹èƒ½è¶…æ„å™¨ä»¶ç»¼è¿°",
      "authors": [
        "Huanshu Zhang",
        "Lei Kang",
        "Sawyer D. Campbell",
        "Jacob T. Young",
        "Douglas H. Werner"
      ],
      "abstract": "Data-driven approaches have revolutionized the design and optimization of photonic metadevices by harnessing advanced artificial intelligence methodologies. This review takes a model-centric perspective that synthesizes emerging design strategies and delineates how traditional trial-and-error and computationally intensive electromagnetic simulations are being supplanted by deep learning frameworks that efficiently navigate expansive design spaces. We discuss artificial intelligence implementation in several metamaterial design aspects from high-degree-of-freedom design to large language model-assisted design. By addressing challenges such as transformer model implementation, fabrication limitations, and intricate mutual coupling effects, these AI-enabled strategies not only streamline the forward modeling process but also offer robust pathways for the realization of multifunctional and fabrication-friendly nanophotonic devices. This review further highlights emerging opportunities and persistent challenges, setting the stage for next-generation strategies in nanophotonic engineering.",
      "tldr_zh": "è¯¥ç»¼è¿°å…¨é¢æ¢è®¨äº†æ•°æ®é©±åŠ¨æ–¹æ³•åœ¨çº³ç±³å…‰å­å­¦é¢†åŸŸçš„æœ€æ–°è¿›å±•ï¼Œé‡ç‚¹åˆ†æäº†äººå·¥æ™ºèƒ½(AI)èµ‹èƒ½çš„è¶…å™¨ä»¶(metadevices)åœ¨è®¾è®¡ä¸ä¼˜åŒ–æ–¹é¢çš„å˜é©ã€‚æ–‡ç« ä»ä»¥æ¨¡å‹ä¸ºä¸­å¿ƒçš„è§†è§’å‡ºå‘ï¼Œè¯¦ç»†é˜è¿°äº†æ·±åº¦å­¦ä¹ (Deep Learning)æ¡†æ¶å¦‚ä½•å–ä»£ä¼ ç»Ÿçš„è¯•é”™æ³•å’Œé«˜è®¡ç®—æˆæœ¬çš„ç”µç£ä»¿çœŸï¼Œä»è€Œåœ¨å¹¿é˜”çš„è®¾è®¡ç©ºé—´ä¸­å®ç°é«˜æ•ˆå¯¼èˆªã€‚è®¨è®ºèŒƒå›´æ¶µç›–äº†ä»é«˜è‡ªç”±åº¦è®¾è®¡åˆ°å¤§è¯­è¨€æ¨¡å‹(Large Language Model)è¾…åŠ©è®¾è®¡ç­‰å¤šç§å‰æ²¿ç­–ç•¥ï¼Œå¹¶æ·±å…¥åˆ†æäº†Transformeræ¨¡å‹åº”ç”¨ã€åˆ¶é€ é™åˆ¶åŠå¤æ‚çš„ç›¸äº’è€¦åˆæ•ˆåº”(mutual coupling effects)ç­‰æŒ‘æˆ˜ã€‚è¿™äº›AIèµ‹èƒ½çš„ç­–ç•¥ä¸ä»…ç®€åŒ–äº†æ­£å‘å»ºæ¨¡æµç¨‹ï¼Œè¿˜ä¸ºå¼€å‘å¤šåŠŸèƒ½ä¸”æ˜“äºåˆ¶é€ çš„çº³ç±³å…‰å­å™¨ä»¶æä¾›äº†å¼ºæœ‰åŠ›çš„æ”¯æŒã€‚æœ€åï¼Œè®ºæ–‡æ€»ç»“äº†è¯¥é¢†åŸŸé¢ä¸´çš„æŒä¹…æŒ‘æˆ˜ä¸æ–°å…´æœºé‡ï¼Œä¸ºä¸‹ä¸€ä»£çº³ç±³å…‰å­å·¥ç¨‹çš„ç ”ç©¶æ–¹å‘æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "physics.optics",
        "cs.AI"
      ],
      "primary_category": "physics.optics",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.00283v1",
      "published_date": "2025-09-30 21:03:46 UTC",
      "updated_date": "2025-09-30 21:03:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:21:29.667129+00:00"
    },
    {
      "arxiv_id": "2510.00279v2",
      "title": "SLogic: Subgraph-Informed Logical Rule Learning for Knowledge Graph Completion",
      "title_zh": "SLogicï¼šé¢å‘çŸ¥è¯†å›¾è°±è¡¥å…¨çš„åŸºäºå­å›¾ä¿¡æ¯çš„é€»è¾‘è§„åˆ™å­¦ä¹ ",
      "authors": [
        "Trung Hoang Le",
        "Tran Cao Son",
        "Huiping Cao"
      ],
      "abstract": "Logical rule-based methods offer an interpretable approach to knowledge graph completion (KGC) by capturing compositional relationships in the form of human-readable inference rules. While existing logical rule-based methods learn rule confidence scores, they typically assign a global weight to each rule schema, applied uniformly across the graph. This is a significant limitation, as a rule's importance often varies depending on the specific query instance. To address this, we introduce SLogic (Subgraph-Informed Logical Rule learning), a novel framework that assigns query-dependent scores to logical rules. The core of SLogic is a context-aware scoring function. This function determines the importance of a rule by analyzing the subgraph locally defined by the query's head entity, thereby enabling a differentiated weighting of rules specific to their local query contexts. Extensive experiments on benchmark datasets show that SLogic outperforms existing rule-based methods and achieves competitive performance against state-of-the-art baselines. It also generates query-dependent, human-readable logical rules that serve as explicit explanations for its inferences.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† SLogic (Subgraph-Informed Logical Rule learning)ï¼Œè¿™æ˜¯ä¸€ç§ä¸ºçŸ¥è¯†å›¾è°±è¡¥å…¨ (Knowledge Graph Completion, KGC) è®¾è®¡çš„æ–°å‹æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰é€»è¾‘è§„åˆ™æ–¹æ³•ä¸­è§„åˆ™æƒé‡å…¨å±€åŒ–è€Œå¿½ç•¥æŸ¥è¯¢å®ä¾‹å·®å¼‚çš„é—®é¢˜ã€‚SLogic çš„æ ¸å¿ƒåœ¨äºå…¶ä¸Šä¸‹æ–‡æ„ŸçŸ¥è¯„åˆ†å‡½æ•° (context-aware scoring function)ï¼Œè¯¥å‡½æ•°é€šè¿‡åˆ†ææŸ¥è¯¢å¤´å®ä½“å®šä¹‰çš„å±€éƒ¨å­å›¾ (subgraph) æ¥ä¸ºé€»è¾‘è§„åˆ™åˆ†é…æŸ¥è¯¢ä¾èµ–çš„å¾—åˆ†ï¼Œä»è€Œå®ç°äº†é’ˆå¯¹ç‰¹å®šæŸ¥è¯¢ä¸Šä¸‹æ–‡çš„å·®å¼‚åŒ–æƒé‡åˆ†é…ã€‚åœ¨åŸºå‡†æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒSLogic çš„è¡¨ç°ä¼˜äºç°æœ‰çš„åŸºäºè§„åˆ™çš„æ–¹æ³•ï¼Œå¹¶è¾¾åˆ°äº†ä¸å½“å‰æœ€å…ˆè¿›åŸºå‡†ç›¸å½“çš„æ€§èƒ½æ°´å¹³ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶è¿˜èƒ½ç”ŸæˆæŸ¥è¯¢ä¾èµ–ä¸”äººç±»å¯è¯»çš„é€»è¾‘è§„åˆ™ï¼Œä¸ºå…¶æ¨ç†ç»“æœæä¾›äº†æ˜ç¡®çš„å¯è§£é‡Šæ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.00279v2",
      "published_date": "2025-09-30 20:59:22 UTC",
      "updated_date": "2026-01-12 22:57:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:22:36.400320+00:00"
    },
    {
      "arxiv_id": "2510.00274v1",
      "title": "MAGIC-MASK: Multi-Agent Guided Inter-Agent Collaboration with Mask-Based Explainability for Reinforcement Learning",
      "title_zh": "MAGIC-MASKï¼šé¢å‘å¼ºåŒ–å­¦ä¹ çš„åŸºäºæ©ç å¯è§£é‡Šæ€§çš„å¤šæ™ºèƒ½ä½“å¼•å¯¼æ™ºèƒ½ä½“é—´åä½œ",
      "authors": [
        "Maisha Maliha",
        "Dean Hougen"
      ],
      "abstract": "Understanding the decision-making process of Deep Reinforcement Learning agents remains a key challenge for deploying these systems in safety-critical and multi-agent environments. While prior explainability methods like StateMask, have advanced the identification of critical states, they remain limited by computational cost, exploration coverage, and lack of adaptation to multi-agent settings. To overcome these limitations, we propose a mathematically grounded framework, MAGIC-MASK (Multi-Agent Guided Inter-agent Collaboration with Mask-Based Explainability for Reinforcement Learning), that extends perturbation-based explanation to Multi-Agent Reinforcement Learning. Our method integrates Proximal Policy Optimization, adaptive epsilon-greedy exploration, and lightweight inter-agent collaboration to share masked state information and peer experience. This collaboration enables each agent to perform saliency-guided masking and share reward-based insights with peers, reducing the time required for critical state discovery, improving explanation fidelity, and leading to faster and more robust learning. The core novelty of our approach lies in generalizing explainability from single-agent to multi-agent systems through a unified mathematical formalism built on trajectory perturbation, reward fidelity analysis, and Kullback-Leibler divergence regularization. This framework yields localized, interpretable explanations grounded in probabilistic modeling and multi-agent Markov decision processes. We validate our framework on both single-agent and multi-agent benchmarks, including a multi-agent highway driving environment and Google Research Football, demonstrating that MAGIC-MASK consistently outperforms state-of-the-art baselines in fidelity, learning efficiency, and policy robustness while offering interpretable and transferable explanations.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† MAGIC-MASK æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ Deep Reinforcement Learning ä»£ç†åœ¨å¤šæ™ºèƒ½ä½“ç¯å¢ƒä¸‹çš„å†³ç­–è¿‡ç¨‹éš¾ä»¥ç†è§£çš„æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶å°†åŸºäºæ‰°åŠ¨çš„è§£é‡Šæ–¹æ³•æ‰©å±•åˆ° Multi-Agent Reinforcement Learning (MARL) é¢†åŸŸï¼Œå¹¶ç»“åˆäº† Proximal Policy Optimization (PPO)ã€è‡ªé€‚åº” epsilon-greedy æ¢ç´¢åŠè½»é‡åŒ–æ™ºèƒ½ä½“åä½œæœºåˆ¶ã€‚é€šè¿‡å…±äº«é®æ©çŠ¶æ€ä¿¡æ¯å’ŒåŒä¼´ç»éªŒï¼Œå„ä»£ç†èƒ½è¿›è¡Œæ˜¾è‘—æ€§å¼•å¯¼çš„æ©ç æ“ä½œ (saliency-guided masking)ï¼Œä»è€Œç¼©çŸ­å…³é”®çŠ¶æ€çš„å‘ç°æ—¶é—´å¹¶æé«˜è§£é‡Šçš„å¿ å®åº¦ (fidelity)ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºåˆ©ç”¨è½¨è¿¹æ‰°åŠ¨ã€å¥–åŠ±å¿ å®åº¦åˆ†æå’Œ Kullback-Leibler divergence æ­£åˆ™åŒ–æ„å»ºäº†ç»Ÿä¸€çš„æ•°å­¦å½¢å¼ï¼Œå®ç°äº†åŸºäºæ¦‚ç‡å»ºæ¨¡çš„å±€éƒ¨å¯è§£é‡Šæ€§ã€‚åœ¨é«˜é€Ÿå…¬è·¯é©¾é©¶å’Œ Google Research Football ç­‰åŸºå‡†æµ‹è¯•ä¸­çš„å®éªŒç»“æœè¯æ˜ï¼ŒMAGIC-MASK åœ¨å­¦ä¹ æ•ˆç‡ã€ç­–ç•¥é²æ£’æ€§åŠè§£é‡Šè´¨é‡ä¸Šå‡æ˜¾è‘—ä¼˜äºç°æœ‰æŠ€æœ¯ï¼Œä¸ºå®‰å…¨å…³é”®çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿéƒ¨ç½²æä¾›äº†æ”¯æŒã€‚",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.00274v1",
      "published_date": "2025-09-30 20:53:28 UTC",
      "updated_date": "2025-09-30 20:53:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:21:40.277136+00:00"
    },
    {
      "arxiv_id": "2510.00268v1",
      "title": "Efficient Layer-wise LLM Fine-tuning for Revision Intention Prediction",
      "title_zh": "é¢å‘ä¿®æ”¹æ„å›¾é¢„æµ‹çš„é«˜æ•ˆ LLM é€å±‚å¾®è°ƒ",
      "authors": [
        "Zhexiong Liu",
        "Diane Litman"
      ],
      "abstract": "Large Language Models (LLMs) have shown extraordinary success across various text generation tasks; however, their potential for simple yet essential text classification remains underexplored, as LLM pre-training tends to emphasize generation over classification. While LLMs with instruction tuning can transform classification into a generation task, they often struggle to categorize nuanced texts. One such example is text revision, which involves nuanced edits between pairs of texts. Although simply fine-tuning LLMs for revision classification seems plausible, it requires a large amount of revision annotations, which are exceptionally expensive and scarce in the community. To address this issue, we introduce a plug-and-play layer-wise parameter-efficient fine-tuning (PEFT) framework, i.e., IR-Tuning, which fine-tunes a subset of important LLM layers that are dynamically selected based on their gradient norm distribution, while freezing those of redundant layers. Extensive experiments suggest that IR-Tuning surpasses several layer-wise PEFT baselines over diverse text revisions, while achieving fast convergence, low GPU memory consumption, and effectiveness on small revision corpora.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Large Language Models (LLMs) åœ¨å¤„ç†æ–‡æœ¬ä¿®è®¢æ„å›¾é¢„æµ‹ (Revision Intention Prediction) ç­‰ç»†å¾®åˆ†ç±»ä»»åŠ¡æ—¶é¢ä¸´çš„æ€§èƒ½ç“¶é¢ˆåŠæ ‡æ³¨æ•°æ®ç¨€ç¼ºé—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸º IR-Tuning çš„å³æ’å³ç”¨å±‚çº§å‚æ•°é«˜æ•ˆå¾®è°ƒ (Parameter-Efficient Fine-Tuning, PEFT) æ¡†æ¶ã€‚è¯¥æ¡†æ¶çš„æ ¸å¿ƒåœ¨äºæ ¹æ®æ¢¯åº¦èŒƒæ•°åˆ†å¸ƒ (gradient norm distribution) åŠ¨æ€é€‰æ‹© LLM ä¸­å…³é”®çš„å±‚å­é›†è¿›è¡Œå¾®è°ƒï¼Œå¹¶åŒæ—¶å†»ç»“å†—ä½™å±‚ï¼Œä»¥å®ç°æ›´ç²¾å‡†çš„ç‰¹å¾æ•æ‰ã€‚å¹¿æ³›çš„å®éªŒè¯æ˜ï¼ŒIR-Tuning åœ¨å¤šç§æ–‡æœ¬ä¿®è®¢ä»»åŠ¡ä¸Šå‡ä¼˜äºç°æœ‰çš„å±‚çº§ PEFT åŸºå‡†æ–¹æ³•ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•åœ¨å®é™…åº”ç”¨ä¸­è¡¨ç°å‡ºæ”¶æ•›é€Ÿåº¦å¿«ã€GPU æ˜¾å­˜å ç”¨ä½ä»¥åŠåœ¨å°å‹ä¿®è®¢è¯­æ–™åº“ä¸Šä¾ç„¶ä¿æŒé«˜æ•ˆç­‰æ˜¾è‘—ä¼˜åŠ¿ï¼Œä¸ºå—é™èµ„æºä¸‹çš„æ¨¡å‹å¾®è°ƒæä¾›äº†æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "In The Conference on Empirical Methods in Natural Language Processing (EMNLP), November 2025",
      "pdf_url": "https://arxiv.org/pdf/2510.00268v1",
      "published_date": "2025-09-30 20:42:13 UTC",
      "updated_date": "2025-09-30 20:42:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:21:38.409753+00:00"
    },
    {
      "arxiv_id": "2510.00261v1",
      "title": "Retrieval-Augmented Generation for Electrocardiogram-Language Models",
      "title_zh": "å¿ƒç”µ-è¯­è¨€æ¨¡å‹çš„æ£€ç´¢å¢å¼ºç”Ÿæˆ",
      "authors": [
        "Xiaoyu Song",
        "William Han",
        "Tony Chen",
        "Chaojing Duan",
        "Michael A. Rosenberg",
        "Emerson Liu",
        "Ding Zhao"
      ],
      "abstract": "Interest in generative Electrocardiogram-Language Models (ELMs) is growing, as they can produce textual responses conditioned on ECG signals and textual queries. Unlike traditional classifiers that output label probabilities, ELMs are more versatile, supporting domain-specific tasks (e.g., waveform analysis, diagnosis, prognosis) as well as general tasks (e.g., open-ended questions, dialogue). Retrieval-Augmented Generation (RAG), widely used in Large Language Models (LLMs) to ground LLM outputs in retrieved knowledge, helps reduce hallucinations and improve natural language generation (NLG). However, despite its promise, no open-source implementation or systematic study of RAG pipeline design for ELMs currently exists. To address this gap, we present the first open-source RAG pipeline for ELMs, along with baselines and ablation studies for NLG. Experiments on three public datasets show that ELMs with RAG consistently improves performance over non-RAG baselines and highlights key ELM design considerations. Our code is available at: https://github.com/willxxy/ECG-Bench.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç”Ÿæˆå¼ Electrocardiogram-Language Models (ELMs) é¢†åŸŸï¼Œæ¢è®¨äº†å¦‚ä½•åˆ©ç”¨ Retrieval-Augmented Generation (RAG) æŠ€æœ¯æå‡æ¨¡å‹æ€§èƒ½ã€‚å°½ç®¡ RAG åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­è¢«å¹¿æ³›ç”¨äºå‡å°‘å¹»è§‰å¹¶æ”¹å–„ Natural Language Generation (NLG)ï¼Œä½†åœ¨ ELMs é¢†åŸŸå°šç¼ºä¹ç³»ç»Ÿç ”ç©¶å’Œå¼€æºå®ç°ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†é¦–ä¸ªä¸“ä¸º ELMs è®¾è®¡çš„å¼€æº RAG æµæ°´çº¿ï¼Œå¹¶æä¾›äº†è¯¦ç»†çš„åŸºçº¿æµ‹è¯•å’Œæ¶ˆèç ”ç©¶ã€‚åœ¨ä¸‰ä¸ªå…¬å…±æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œç»“åˆ RAG çš„ ELMs åœ¨å¤„ç†æ³¢å½¢åˆ†æã€è¯Šæ–­åŠé¢„åç­‰ä»»åŠ¡æ—¶ï¼Œå…¶è¡¨ç°å‡ä¸€è‡´ä¼˜äºé RAG çš„åŸºçº¿æ¨¡å‹ã€‚è¯¥é¡¹å·¥ä½œé€šè¿‡ç³»ç»Ÿæ€§å®éªŒæ€»ç»“äº† ELM è®¾è®¡ä¸­çš„å…³é”®è€ƒé‡å› ç´ ï¼Œå¡«è¡¥äº†å¿ƒç”µå›¾é¢†åŸŸæ£€ç´¢å¢å¼ºç”Ÿæˆçš„ç©ºç™½ã€‚ç›®å‰è¯¥é¡¹ç›®çš„æºä»£ç å·²åœ¨ GitHub çš„ ECG-Bench å­˜å‚¨åº“ä¸­å…¬å¼€å‘å¸ƒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CL",
      "comment": "5 pages, 2 figures; Submitted to ICASSP 2026",
      "pdf_url": "https://arxiv.org/pdf/2510.00261v1",
      "published_date": "2025-09-30 20:32:34 UTC",
      "updated_date": "2025-09-30 20:32:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:21:40.581188+00:00"
    },
    {
      "arxiv_id": "2510.00260v1",
      "title": "Learning Energy-based Variational Latent Prior for VAEs",
      "title_zh": "é¢å‘ VAEs çš„åŸºäºèƒ½é‡çš„å˜åˆ†éšå˜é‡å…ˆéªŒå­¦ä¹ ",
      "authors": [
        "Debottam Dutta",
        "Chaitanya Amballa",
        "Zhongweiyang Xu",
        "Yu-Lin Wei",
        "Romit Roy Choudhury"
      ],
      "abstract": "Variational Auto-Encoders (VAEs) are known to generate blurry and inconsistent samples. One reason for this is the \"prior hole\" problem. A prior hole refers to regions that have high probability under the VAE's prior but low probability under the VAE's posterior. This means that during data generation, high probability samples from the prior could have low probability under the posterior, resulting in poor quality data. Ideally, a prior needs to be flexible enough to match the posterior while retaining the ability to generate samples fast. Generative models continue to address this tradeoff. This paper proposes to model the prior as an energy-based model (EBM). While EBMs are known to offer the flexibility to match posteriors (and also improving the ELBO), they are traditionally slow in sample generation due to their dependency on MCMC methods. Our key idea is to bring a variational approach to tackle the normalization constant in EBMs, thus bypassing the expensive MCMC approaches. The variational form can be approximated with a sampler network, and we show that such an approach to training priors can be formulated as an alternating optimization problem. Moreover, the same sampler reduces to an implicit variational prior during generation, providing efficient and fast sampling. We compare our Energy-based Variational Latent Prior (EVaLP) method to multiple SOTA baselines and show improvements in image generation quality, reduced prior holes, and better sampling efficiency.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹Variational Auto-Encoders (VAEs) å› â€œprior holeâ€é—®é¢˜å¯¼è‡´ç”Ÿæˆå›¾åƒæ¨¡ç³Šä¸”ä¸ä¸€è‡´çš„æŒ‘æˆ˜ï¼Œæå‡ºå°†å…ˆéªŒå»ºæ¨¡ä¸ºèƒ½é‡æ¨¡å‹(Energy-based Model, EBM)ä»¥å¢å¼ºåŒ¹é…åéªŒåˆ†å¸ƒçš„çµæ´»æ€§ã€‚ä¸ºäº†å…‹æœä¼ ç»ŸEBMä¾èµ–MCMCå¯¼è‡´çš„é‡‡æ ·æ•ˆç‡ä½ä¸‹çš„é—®é¢˜ï¼Œä½œè€…å¼•å…¥äº†ä¸€ç§å˜åˆ†æ–¹æ³•æ¥å¤„ç†å½’ä¸€åŒ–å¸¸æ•°ï¼Œé€šè¿‡é‡‡æ ·ç½‘ç»œ(sampler network)é€¼è¿‘å˜åˆ†å½¢å¼ï¼Œå¹¶å°†è®­ç»ƒè¿‡ç¨‹æ„å»ºä¸ºäº¤æ›¿ä¼˜åŒ–é—®é¢˜ã€‚åœ¨æ•°æ®ç”Ÿæˆé˜¶æ®µï¼Œè¯¥é‡‡æ ·ç½‘ç»œå……å½“éšå¼å˜åˆ†å…ˆéªŒï¼Œä»è€Œå®ç°äº†å¿«é€Ÿä¸”é«˜æ•ˆçš„é‡‡æ ·ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥Energy-based Variational Latent Prior (EVaLP) æ–¹æ³•åœ¨æå‡å›¾åƒç”Ÿæˆè´¨é‡ã€å‡å°‘â€œprior holeâ€ç°è±¡ä»¥åŠæé«˜é‡‡æ ·æ•ˆç‡æ–¹é¢å‡ä¼˜äºç°æœ‰çš„SOTAåŸºçº¿æ¨¡å‹ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.00260v1",
      "published_date": "2025-09-30 20:32:00 UTC",
      "updated_date": "2025-09-30 20:32:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:23:04.595021+00:00"
    },
    {
      "arxiv_id": "2510.00259v1",
      "title": "A Hierarchical Agentic Framework for Autonomous Drone-Based Visual Inspection",
      "title_zh": "é¢å‘è‡ªä¸»æ— äººæœºè§†è§‰æ£€æµ‹çš„åˆ†å±‚æ™ºèƒ½ä½“æ¡†æ¶",
      "authors": [
        "Ethan Herron",
        "Xian Yeow Lee",
        "Gregory Sin",
        "Teresa Gonzalez Diaz",
        "Ahmed Farahat",
        "Chetan Gupta"
      ],
      "abstract": "Autonomous inspection systems are essential for ensuring the performance and longevity of industrial assets. Recently, agentic frameworks have demonstrated significant potential for automating inspection workflows but have been limited to digital tasks. Their application to physical assets in real-world environments, however, remains underexplored. In this work, our contributions are two-fold: first, we propose a hierarchical agentic framework for autonomous drone control, and second, a reasoning methodology for individual function executions which we refer to as ReActEval. Our framework focuses on visual inspection tasks in indoor industrial settings, such as interpreting industrial readouts or inspecting equipment. It employs a multi-agent system comprising a head agent and multiple worker agents, each controlling a single drone. The head agent performs high-level planning and evaluates outcomes, while worker agents implement ReActEval to reason over and execute low-level actions. Operating entirely in natural language, ReActEval follows a plan, reason, act, evaluate cycle, enabling drones to handle tasks ranging from simple navigation (e.g., flying forward 10 meters and land) to complex high-level tasks (e.g., locating and reading a pressure gauge). The evaluation phase serves as a feedback and/or replanning stage, ensuring actions align with user objectives while preventing undesirable outcomes. We evaluate the framework in a simulated environment with two worker agents, assessing performance qualitatively and quantitatively based on task completion across varying complexity levels and workflow efficiency. By leveraging natural language processing for agent communication, our approach offers a novel, flexible, and user-accessible alternative to traditional drone-based solutions, enabling autonomous problem-solving for industrial inspection without extensive user intervention.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªç”¨äºè‡ªä¸»æ— äººæœºè§†è§‰å·¡æ£€çš„å±‚çº§åŒ–æ™ºèƒ½ä½“æ¡†æ¶(Hierarchical Agentic Framework)ï¼Œæ—¨åœ¨å°†æ™ºèƒ½ä½“è‡ªåŠ¨åŒ–å·¥ä½œæµä»æ•°å­—ä»»åŠ¡æ‰©å±•åˆ°ç‰©ç†èµ„äº§çš„çœŸå®ç¯å¢ƒå·¡æ£€ä¸­ã€‚è¯¥ç³»ç»Ÿé‡‡ç”¨å¤šæ™ºèƒ½ä½“æ¶æ„ï¼Œç”±è´Ÿè´£é«˜å±‚è§„åˆ’ä¸ç»“æœè¯„ä¼°çš„Head Agentä»¥åŠè´Ÿè´£å…·ä½“æ‰§è¡Œçš„Worker Agentç»„æˆï¼Œä¸“æ³¨äºå®¤å†…å·¥ä¸šç¯å¢ƒçš„è®¾å¤‡è§£è¯»ä¸æ£€æŸ¥ã€‚ç ”ç©¶æ ¸å¿ƒå¼•å…¥äº†åä¸ºReActEvalçš„æ¨ç†æ–¹æ³•ï¼Œåˆ©ç”¨è‡ªç„¶è¯­è¨€é©±åŠ¨â€œè®¡åˆ’-æ¨ç†-è¡ŒåŠ¨-è¯„ä¼°â€çš„é—­ç¯å¾ªç¯ï¼Œä½¿æ— äººæœºèƒ½å¤Ÿè‡ªä¸»å®Œæˆä»åŸºç¡€å¯¼èˆªåˆ°å¤æ‚ä»ªè¡¨è¯»å–ç­‰ä»»åŠ¡ã€‚æ¡†æ¶ä¸­çš„è¯„ä¼°é˜¶æ®µæä¾›äº†å…³é”®çš„åé¦ˆä¸é‡è§„åˆ’æœºåˆ¶ï¼Œç¡®ä¿æ— äººæœºåŠ¨ä½œä¸ç”¨æˆ·ç›®æ ‡ä¸€è‡´å¹¶æœ‰æ•ˆé˜²æ­¢ä¸è‰¯åæœã€‚ä»¿çœŸå®éªŒç»“æœéªŒè¯äº†è¯¥æ¡†æ¶åœ¨ä¸åŒå¤æ‚åº¦ä»»åŠ¡ä¸‹çš„é«˜æ•ˆæ€§ä¸å¯é æ€§ï¼Œä¸ºå·¥ä¸šå·¡æ£€æä¾›äº†ä¸€ç§æ— éœ€å¤§é‡äººå·¥å¹²é¢„ã€çµæ´»ä¸”æ˜“äºè®¿é—®çš„è‡ªä¸»è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.RO",
        "eess.SY"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.00259v1",
      "published_date": "2025-09-30 20:31:30 UTC",
      "updated_date": "2025-09-30 20:31:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:23:00.499701+00:00"
    },
    {
      "arxiv_id": "2510.07328v1",
      "title": "MultiFair: Multimodal Balanced Fairness-Aware Medical Classification with Dual-Level Gradient Modulation",
      "title_zh": "MultiFairï¼šåŸºäºåŒå±‚æ¢¯åº¦è°ƒåˆ¶çš„å¹³è¡¡å…¬å¹³æ„ŸçŸ¥å¤šæ¨¡æ€åŒ»å­¦åˆ†ç±»",
      "authors": [
        "Md Zubair",
        "Hao Zheng",
        "Nussdorf Jonathan",
        "Grayson W. Armstrong",
        "Lucy Q. Shen",
        "Gabriela Wilson",
        "Yu Tian",
        "Xingquan Zhu",
        "Min Shi"
      ],
      "abstract": "Medical decision systems increasingly rely on data from multiple sources to ensure reliable and unbiased diagnosis. However, existing multimodal learning models fail to achieve this goal because they often ignore two critical challenges. First, various data modalities may learn unevenly, thereby converging to a model biased towards certain modalities. Second, the model may emphasize learning on certain demographic groups causing unfair performances. The two aspects can influence each other, as different data modalities may favor respective groups during optimization, leading to both imbalanced and unfair multimodal learning. This paper proposes a novel approach called MultiFair for multimodal medical classification, which addresses these challenges with a dual-level gradient modulation process. MultiFair dynamically modulates training gradients regarding the optimization direction and magnitude at both data modality and group levels. We conduct extensive experiments on two multimodal medical datasets with different demographic groups. The results show that MultiFair outperforms state-of-the-art multimodal learning and fairness learning methods.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŒ»ç–—å†³ç­–ç³»ç»Ÿä¸­å¤šæ¨¡æ€å­¦ä¹ é¢ä¸´çš„æ¨¡æ€å­¦ä¹ ä¸å‡è¡¡ä»¥åŠäººå£ç»Ÿè®¡å­¦ç¾¤ä½“é—´çš„ä¸å…¬å¹³æ€§é—®é¢˜ï¼ŒæŒ‡å‡ºäº†è¿™ä¸¤è€…åœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­ç›¸äº’å½±å“å¹¶å¯¼è‡´æ€§èƒ½åè§ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†ä¸€ç§åä¸º MultiFair çš„æ–°å‹å¤šæ¨¡æ€åŒ»ç–—åˆ†ç±»æ–¹æ³•ï¼Œé€šè¿‡åŒå±‚æ¢¯åº¦è°ƒåˆ¶ (Dual-Level Gradient Modulation) è¿‡ç¨‹æ¥åŒæ—¶åº”å¯¹è¿™äº›æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶èƒ½å¤Ÿåœ¨æ•°æ®æ¨¡æ€å’Œç¾¤ä½“å±‚é¢åŠ¨æ€åœ°è°ƒåˆ¶è®­ç»ƒæ¢¯åº¦çš„ä¼˜åŒ–æ–¹å‘å’Œå¹…åº¦ï¼Œç¡®ä¿æ¨¡å‹åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­ä¸ä¼šè¿‡åº¦åå‘ç‰¹å®šæ¨¡æ€æˆ–ç‰¹å®šäººå£ç»Ÿè®¡ç¾¤ä½“ã€‚åœ¨ä¸¤ä¸ªå¤šæ¨¡æ€åŒ»ç–—æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒç»“æœè¯æ˜ï¼ŒMultiFair åœ¨å¹³è¡¡æ€§ä¸å…¬å¹³æ€§æ–¹é¢å‡ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›å¤šæ¨¡æ€å­¦ä¹ ä¸å…¬å¹³å­¦ä¹  (Fairness Learning) æ–¹æ³•ã€‚è¯¥ç ”ç©¶ä¸ºæ„å»ºæ›´å¯é ã€æ— åè§çš„è‡ªåŠ¨åŒ–åŒ»ç–—è¯Šæ–­ç³»ç»Ÿæä¾›äº†æœ‰æ•ˆçš„æŠ€æœ¯æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "10 Pages",
      "pdf_url": "https://arxiv.org/pdf/2510.07328v1",
      "published_date": "2025-09-30 20:30:12 UTC",
      "updated_date": "2025-09-30 20:30:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:23:06.996947+00:00"
    },
    {
      "arxiv_id": "2510.00255v1",
      "title": "TASER: Translation Assessment via Systematic Evaluation and Reasoning",
      "title_zh": "TASERï¼šåŸºäºç³»ç»ŸåŒ–è¯„ä¼°ä¸æ¨ç†çš„ç¿»è¯‘è¯„ä¼°",
      "authors": [
        "Monishwaran Maheswaran",
        "Marco Carini",
        "Christian Federmann",
        "Tony Diaz"
      ],
      "abstract": "We introduce TASER (Translation Assessment via Systematic Evaluation and Reasoning), a metric that uses Large Reasoning Models (LRMs) for automated translation quality assessment. TASER harnesses the explicit reasoning capabilities of LRMs to conduct systematic, step-by-step evaluation of translation quality. We evaluate TASER on the WMT24 Metrics Shared Task across both reference-based and reference-free scenarios, demonstrating state-of-the-art performance. In system-level evaluation, TASER achieves the highest soft pairwise accuracy in both reference-based and reference-free settings, outperforming all existing metrics. At the segment level, TASER maintains competitive performance with our reference-free variant ranking as the top-performing metric among all reference-free approaches. Our experiments reveal that structured prompting templates yield superior results with LRMs compared to the open-ended approaches that proved optimal for traditional LLMs. We evaluate o3, a large reasoning model from OpenAI, with varying reasoning efforts, providing insights into the relationship between reasoning depth and evaluation quality. The explicit reasoning process in LRMs offers interpretability and visibility, addressing a key limitation of existing automated metrics. Our results demonstrate that Large Reasoning Models show a measurable advancement in translation quality assessment, combining improved accuracy with transparent evaluation across diverse language pairs.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† TASER (Translation Assessment via Systematic Evaluation and Reasoning)ï¼Œä¸€ç§åˆ©ç”¨ Large Reasoning Models (LRMs) è¿›è¡Œè‡ªåŠ¨åŒ–ç¿»è¯‘è´¨é‡è¯„ä¼°çš„æŒ‡æ ‡ã€‚TASER åˆ©ç”¨ LRMs çš„æ˜¾å¼æ¨ç†èƒ½åŠ›ï¼Œé€šè¿‡ç³»ç»ŸåŒ–çš„æ­¥è¿›å¼æ¨ç† (step-by-step reasoning) å¯¹ç¿»è¯‘è´¨é‡è¿›è¡Œè¯„ä¼°ï¼Œæœ‰æ•ˆè§£å†³äº†ç°æœ‰æŒ‡æ ‡ç¼ºä¹è§£é‡Šæ€§çš„å±€é™ã€‚ç ”ç©¶åœ¨ WMT24 Metrics Shared Task çš„å‚è€ƒåŸºå‡† (reference-based) å’Œæ— å‚è€ƒ (reference-free) åœºæ™¯ä¸‹è¿›è¡Œæµ‹è¯•ï¼Œè¯æ˜ TASER åœ¨ç³»ç»Ÿçº§è¯„ä¼°ä¸­å–å¾—äº†æœ€é«˜çš„è½¯æˆå¯¹å‡†ç¡®ç‡ (soft pairwise accuracy)ï¼Œè¶…è¶Šäº†æ‰€æœ‰ç°æœ‰æŒ‡æ ‡ã€‚åœ¨å¥å­çº§è¯„ä¼°ä¸­ï¼Œå…¶æ— å‚è€ƒå˜ä½“åŒæ ·åœ¨åŒç±»æ–¹æ³•ä¸­ååˆ—å‰èŒ…ã€‚å®éªŒè¿›ä¸€æ­¥æ­ç¤ºäº†ç»“æ„åŒ–æç¤º (structured prompting) æ›´æœ‰åˆ©äº LRMs å‘æŒ¥æ€§èƒ½ï¼Œå¹¶é€šè¿‡å¯¹ OpenAI o3 æ¨¡å‹çš„åˆ†ææ¢è®¨äº†æ¨ç†æ·±åº¦ä¸è¯„ä¼°è´¨é‡çš„å…³ç³»ã€‚æ€»çš„æ¥çœ‹ï¼ŒTASER å‡­å€Ÿå…¶é«˜å‡†ç¡®åº¦å’Œé€æ˜çš„è¯„ä¼°è¿‡ç¨‹ï¼Œå±•ç¤ºäº† Large Reasoning Models åœ¨ç¿»è¯‘è¯„ä¼°é¢†åŸŸçš„é‡å¤§è¿›å±•ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.00255v1",
      "published_date": "2025-09-30 20:27:48 UTC",
      "updated_date": "2025-09-30 20:27:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:23:11.989448+00:00"
    },
    {
      "arxiv_id": "2510.03310v1",
      "title": "Predicting Effects, Missing Distributions: Evaluating LLMs as Human Behavior Simulators in Operations Management",
      "title_zh": "é¢„æµ‹æ•ˆåº”ï¼Œé—å¤±åˆ†å¸ƒï¼šè¯„ä¼°å¤§è¯­è¨€æ¨¡å‹åœ¨è¿è¥ç®¡ç†ä¸­ä½œä¸ºäººç±»è¡Œä¸ºæ¨¡æ‹Ÿå™¨çš„è¡¨ç°",
      "authors": [
        "Runze Zhang",
        "Xiaowei Zhang",
        "Mingyang Zhao"
      ],
      "abstract": "LLMs are emerging tools for simulating human behavior in business, economics, and social science, offering a lower-cost complement to laboratory experiments, field studies, and surveys. This paper evaluates how well LLMs replicate human behavior in operations management. Using nine published experiments in behavioral operations, we assess two criteria: replication of hypothesis-test outcomes and distributional alignment via Wasserstein distance. LLMs reproduce most hypothesis-level effects, capturing key decision biases, but their response distributions diverge from human data, including for strong commercial models. We also test two lightweight interventions -- chain-of-thought prompting and hyperparameter tuning -- which reduce misalignment and can sometimes let smaller or open-source models match or surpass larger systems.",
      "tldr_zh": "è¯¥ç ”ç©¶è¯„ä¼°äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨è¿è¥ç®¡ç†(Operations Management)é¢†åŸŸæ¨¡æ‹Ÿäººç±»è¡Œä¸ºçš„èƒ½åŠ›ã€‚ç ”ç©¶è€…åˆ©ç”¨9é¡¹å·²å‘è¡¨çš„è¡Œä¸ºè¿è¥å®éªŒï¼Œä»å‡è®¾æ£€éªŒç»“æœçš„å¤åˆ¶å’ŒåŸºäºWasserstein distanceçš„åˆ†å¸ƒå¯¹é½ä¸¤ä¸ªç»´åº¦è¿›è¡Œäº†æ·±å…¥è¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒLLMsèƒ½å¤Ÿé‡ç°å¤§éƒ¨åˆ†å‡è®¾å±‚é¢çš„æ•ˆåº”å¹¶æ•æ‰å…³é”®çš„å†³ç­–åè§(Decision Biases)ï¼Œä½†å…¶å“åº”åˆ†å¸ƒä¸çœŸå®äººç±»æ•°æ®å­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼Œå³ä½¿æ˜¯å¼ºå¤§çš„å•†ä¸šæ¨¡å‹ä¹Ÿéš¾ä»¥å®Œå…¨å¯¹é½ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜æµ‹è¯•äº†é“¾å¼æ€ç»´æç¤º(Chain-of-Thought Prompting)å’Œè¶…å‚æ•°è°ƒä¼˜(Hyperparameter Tuning)ä¸¤ç§è½»é‡çº§å¹²é¢„æ‰‹æ®µï¼Œå‘ç°è¿™äº›æ–¹æ³•èƒ½æœ‰æ•ˆå‡å°‘åˆ†å¸ƒå¤±é…ï¼Œç”šè‡³ä½¿å°å‹æˆ–å¼€æºæ¨¡å‹åœ¨æ¨¡æ‹Ÿè¡¨ç°ä¸Šè¾¾åˆ°æˆ–è¶…è¶Šå¤§å‹ç³»ç»Ÿã€‚è¯¥ç ”ç©¶ä¸ºåˆ©ç”¨æ¨¡å‹æ¨¡æ‹Ÿäººç±»å†³ç­–æä¾›äº†é‡è¦çš„å®è¯ä¾æ®å’Œä¼˜åŒ–è·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.03310v1",
      "published_date": "2025-09-30 20:20:58 UTC",
      "updated_date": "2025-09-30 20:20:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:23:15.683116+00:00"
    },
    {
      "arxiv_id": "2510.00245v1",
      "title": "Can AI agents understand spoken conversations about data visualizations in online meetings?",
      "title_zh": "AI æ™ºèƒ½ä½“èƒ½å¦ç†è§£åœ¨çº¿ä¼šè®®ä¸­å…³äºæ•°æ®å¯è§†åŒ–çš„è¯­éŸ³å¯¹è¯ï¼Ÿ",
      "authors": [
        "Rizul Sharma",
        "Tianyu Jiang",
        "Seokki Lee",
        "Jillian Aurisano"
      ],
      "abstract": "In this short paper, we present work evaluating an AI agent's understanding of spoken conversations about data visualizations in an online meeting scenario. There is growing interest in the development of AI-assistants that support meetings, such as by providing assistance with tasks or summarizing a discussion. The quality of this support depends on a model that understands the conversational dialogue. To evaluate this understanding, we introduce a dual-axis testing framework for diagnosing the AI agent's comprehension of spoken conversations about data. Using this framework, we designed a series of tests to evaluate understanding of a novel corpus of 72 spoken conversational dialogues about data visualizations. We examine diverse pipelines and model architectures, LLM vs VLM, and diverse input formats for visualizations (the chart image, its underlying source code, or a hybrid of both) to see how this affects model performance on our tests. Using our evaluation methods, we found that text-only input modalities achieved the best performance (96%) in understanding discussions of visualizations in online meetings.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº† AI agent åœ¨åœ¨çº¿ä¼šè®®ä¸­ç†è§£æœ‰å…³æ•°æ®å¯è§†åŒ– (data visualizations) å£è¯­å¯¹è¯çš„èƒ½åŠ›ï¼Œæ—¨åœ¨æå‡ä¼šè®®åŠ©æ‰‹çš„ä»»åŠ¡ååŠ©ä¸æ€»ç»“è´¨é‡ã€‚ç ”ç©¶è€…æå‡ºäº†ä¸€ä¸ªåŒè½´æµ‹è¯•æ¡†æ¶ï¼Œä¸“é—¨ç”¨äºè¯Šæ–­æ™ºèƒ½ä½“å¯¹æ•°æ®å£è¯­å¯¹è¯çš„ç†è§£ï¼Œå¹¶åˆ©ç”¨è¯¥æ¡†æ¶è¯„ä¼°äº†ä¸€ä¸ªåŒ…å« 72 ä¸ªæ•°æ®å¯è§†åŒ–å¯¹è¯çš„æ–°è¯­æ–™åº“ã€‚é€šè¿‡å¯¹æ¯” LLM ä¸ VLM æ¶æ„ï¼Œä»¥åŠå›¾è¡¨å›¾åƒã€æºä»£ç æˆ–ä¸¤è€…æ··åˆçš„ä¸åŒè¾“å…¥æ ¼å¼ï¼Œç ”ç©¶æ·±å…¥åˆ†æäº†è¾“å…¥æ¨¡æ€å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œçº¯æ–‡æœ¬è¾“å…¥æ¨¡å¼åœ¨ç†è§£åœ¨çº¿ä¼šè®®ä¸­çš„å¯è§†åŒ–è®¨è®ºæ–¹é¢è¡¨ç°æœ€ä¸ºä¼˜å¼‚ï¼Œå‡†ç¡®ç‡è¾¾åˆ°äº† 96%ã€‚è¿™é¡¹å·¥ä½œä¸ºä¼˜åŒ–æ”¯æŒä¼šè®®åœºæ™¯çš„ AI åŠ©æ‰‹æ¨¡å‹æ¶æ„æä¾›äº†å®è¯ä¾æ®ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.00245v1",
      "published_date": "2025-09-30 20:17:36 UTC",
      "updated_date": "2025-09-30 20:17:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:23:23.289767+00:00"
    },
    {
      "arxiv_id": "2510.00240v2",
      "title": "SecureBERT 2.0: Advanced Language Model for Cybersecurity Intelligence",
      "title_zh": "SecureBERT 2.0ï¼šé¢å‘ç½‘ç»œå®‰å…¨æƒ…æŠ¥çš„é«˜çº§è¯­è¨€æ¨¡å‹",
      "authors": [
        "Ehsan Aghaei",
        "Sarthak Jain",
        "Prashanth Arun",
        "Arjun Sambamoorthy"
      ],
      "abstract": "Effective analysis of cybersecurity and threat intelligence data demands language models that can interpret specialized terminology, complex document structures, and the interdependence of natural language and source code. Encoder-only transformer architectures provide efficient and robust representations that support critical tasks such as semantic search, technical entity extraction, and semantic analysis, which are key to automated threat detection, incident triage, and vulnerability assessment. However, general-purpose language models often lack the domain-specific adaptation required for high precision. We present SecureBERT 2.0, an enhanced encoder-only language model purpose-built for cybersecurity applications. Leveraging the ModernBERT architecture, SecureBERT 2.0 introduces improved long-context modeling and hierarchical encoding, enabling effective processing of extended and heterogeneous documents, including threat reports and source code artifacts. Pretrained on a domain-specific corpus more than thirteen times larger than its predecessor, comprising over 13 billion text tokens and 53 million code tokens from diverse real-world sources, SecureBERT 2.0 achieves state-of-the-art performance on multiple cybersecurity benchmarks. Experimental results demonstrate substantial improvements in semantic search for threat intelligence, semantic analysis, cybersecurity-specific named entity recognition, and automated vulnerability detection in code within the cybersecurity domain.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† SecureBERT 2.0ï¼Œè¿™æ˜¯ä¸€ç§ä¸“ä¸ºç½‘ç»œå®‰å…¨æƒ…æŠ¥åˆ†æè®¾è®¡çš„å¢å¼ºå‹ Encoder-only è¯­è¨€æ¨¡å‹ã€‚è¯¥æ¨¡å‹åŸºäº ModernBERT æ¶æ„ï¼Œé€šè¿‡å¼•å…¥æ”¹è¿›çš„é•¿ä¸Šä¸‹æ–‡å»ºæ¨¡å’Œå±‚æ¬¡åŒ–ç¼–ç æŠ€æœ¯ï¼Œæ˜¾è‘—æå‡äº†å¤„ç†é•¿ç¯‡å¼‚æ„æ–‡æ¡£åŠæºä»£ç çš„èƒ½åŠ›ã€‚å…¶é¢„è®­ç»ƒè¯­æ–™åº“è§„æ¨¡æ¯”å‰ä»£æ‰©å¤§äº† 13 å€ä»¥ä¸Šï¼Œæ¶µç›–è¶…è¿‡ 130 äº¿æ–‡æœ¬ Token å’Œ 5300 ä¸‡ä»£ç  Tokenï¼Œç¡®ä¿äº†æé«˜çš„é¢†åŸŸé€‚é…åº¦ã€‚å®éªŒè¯æ˜ï¼ŒSecureBERT 2.0 åœ¨å¨èƒæƒ…æŠ¥è¯­ä¹‰æœç´¢ã€ç½‘ç»œå®‰å…¨å‘½åå®ä½“è¯†åˆ«ï¼ˆNERï¼‰ä»¥åŠè‡ªåŠ¨åŒ–æ¼æ´æ£€æµ‹ç­‰å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å‡å–å¾—äº† SOTA æ€§èƒ½ã€‚è¯¥æˆæœä¸ºå¤æ‚çš„ç½‘ç»œå®‰å…¨ä»»åŠ¡æä¾›äº†æ›´ç²¾å‡†çš„è¯­ä¹‰è¡¨å¾æ”¯æŒï¼Œæœ‰æ•ˆæ¨åŠ¨äº†è‡ªåŠ¨åŒ–å¨èƒæ£€æµ‹ä¸æ¼æ´è¯„ä¼°æŠ€æœ¯çš„å‘å±•ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.00240v2",
      "published_date": "2025-09-30 20:12:37 UTC",
      "updated_date": "2025-10-10 19:38:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:23:25.065966+00:00"
    },
    {
      "arxiv_id": "2510.01281v1",
      "title": "An Analysis of the New EU AI Act and A Proposed Standardization Framework for Machine Learning Fairness",
      "title_zh": "æ¬§ç›Ÿæ–°ã€Šäººå·¥æ™ºèƒ½æ³•æ¡ˆã€‹è§£æä¸æœºå™¨å­¦ä¹ å…¬å¹³æ€§æ ‡å‡†åŒ–æ¡†æ¶æ¢æ",
      "authors": [
        "Mike Teodorescu",
        "Yongxu Sun",
        "Haren N. Bhatia",
        "Christos Makridis"
      ],
      "abstract": "The European Union's AI Act represents a crucial step towards regulating ethical and responsible AI systems. However, we find an absence of quantifiable fairness metrics and the ambiguity in terminology, particularly the interchangeable use of the keywords transparency, explainability, and interpretability in the new EU AI Act and no reference of transparency of ethical compliance. We argue that this ambiguity creates substantial liability risk that would deter investment. Fairness transparency is strategically important. We recommend a more tailored regulatory framework to enhance the new EU AI regulation. Further-more, we propose a public system framework to assess the fairness and transparency of AI systems. Drawing from past work, we advocate for the standardization of industry best practices as a necessary addition to broad regulations to achieve the level of details required in industry, while preventing stifling innovation and investment in the AI sector. The proposals are exemplified with the case of ASR and speech synthesizers.",
      "tldr_zh": "è¯¥ç ”ç©¶æ·±å…¥åˆ†æäº†æ¬§ç›Ÿã€Šäººå·¥æ™ºèƒ½æ³•æ¡ˆã€‹(EU AI Act)ï¼ŒæŒ‡å‡ºå…¶åœ¨ä¼¦ç†å’Œè´Ÿè´£ä»»äººå·¥æ™ºèƒ½ç›‘ç®¡æ–¹é¢è™½å…·æœ‰é‡è¦æ„ä¹‰ï¼Œä½†ä»å­˜åœ¨ç¼ºä¹é‡åŒ–å…¬å¹³æ€§(fairness)æŒ‡æ ‡ä»¥åŠæœ¯è¯­å®šä¹‰æ¨¡ç³Šç­‰ç¼ºé™·ã€‚ç ”ç©¶ç‰¹åˆ«å¼ºè°ƒäº†æ³•æ¡ˆä¸­å¯¹äºé€æ˜åº¦(transparency)ã€å¯è§£é‡Šæ€§(explainability)å’Œå¯ç†è§£æ€§(interpretability)ç­‰å…³é”®è¯çš„æ··ç”¨ï¼Œä»¥åŠç¼ºä¹ä¼¦ç†åˆè§„é€æ˜åº¦å‚è€ƒçš„é—®é¢˜ã€‚ä½œè€…è®¤ä¸ºè¿™ç§æœ¯è¯­æ­§ä¹‰ä¼šäº§ç”Ÿå·¨å¤§çš„æ³•å¾‹è´£ä»»é£é™©ï¼Œä»è€Œå¯èƒ½é˜»ç¢äººå·¥æ™ºèƒ½é¢†åŸŸçš„æŠ•èµ„ã€‚ä¸ºæ­¤ï¼Œè®ºæ–‡å»ºè®®é€šè¿‡æ›´å…·é’ˆå¯¹æ€§çš„ç›‘ç®¡æ¡†æ¶æ¥å®Œå–„ç°æœ‰æ³•è§„ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªç”¨äºè¯„ä¼°äººå·¥æ™ºèƒ½ç³»ç»Ÿå…¬å¹³æ€§å’Œé€æ˜åº¦çš„å…¬å…±ç³»ç»Ÿæ¡†æ¶ã€‚ç ”ç©¶è¿›ä¸€æ­¥ä¸»å¼ å°†è¡Œä¸šæœ€ä½³å®è·µæ ‡å‡†åŒ–ï¼Œä½œä¸ºå®è§‚æ³•è§„çš„å¿…è¦è¡¥å……ï¼Œä»¥ä¾¿åœ¨æä¾›è¡Œä¸šæ‰€éœ€ç»†èŠ‚çš„åŒæ—¶é¿å…æŠ‘åˆ¶æŠ€æœ¯åˆ›æ–°ã€‚æœ€åï¼Œè®ºæ–‡é€šè¿‡è‡ªåŠ¨è¯­éŸ³è¯†åˆ«(ASR)å’Œè¯­éŸ³åˆæˆç³»ç»Ÿçš„æ¡ˆä¾‹å¯¹ä¸Šè¿°æè®®è¿›è¡Œäº†å…·ä½“çš„å®è¯åˆ†æã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "6 pages; IEEE HPEC 2025 Poster Session 4-P1 (12:15-13:15): AI/ML/GenAI Poster Session Thursday September 18 2025",
      "pdf_url": "https://arxiv.org/pdf/2510.01281v1",
      "published_date": "2025-09-30 20:02:38 UTC",
      "updated_date": "2025-09-30 20:02:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:23:29.496617+00:00"
    },
    {
      "arxiv_id": "2510.05127v1",
      "title": "Artificial Intelligence for Cost-Aware Resource Prediction in Big Data Pipelines",
      "title_zh": "é¢å‘å¤§æ•°æ®æµæ°´çº¿ä¸­æˆæœ¬æ„ŸçŸ¥èµ„æºé¢„æµ‹çš„äººå·¥æ™ºèƒ½",
      "authors": [
        "Harshit Goyal"
      ],
      "abstract": "Efficient resource allocation is a key challenge in modern cloud computing. Over-provisioning leads to unnecessary costs, while under-provisioning risks performance degradation and SLA violations. This work presents an artificial intelligence approach to predict resource utilization in big data pipelines using Random Forest regression. We preprocess the Google Borg cluster traces to clean, transform, and extract relevant features (CPU, memory, usage distributions). The model achieves high predictive accuracy (R Square = 0.99, MAE = 0.0048, RMSE = 0.137), capturing non-linear relationships between workload characteristics and resource utilization. Error analysis reveals impressive performance on small-to-medium jobs, with higher variance in rare large-scale jobs. These results demonstrate the potential of AI-driven prediction for cost-aware autoscaling in cloud environments, reducing unnecessary provisioning while safeguarding service quality.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹äº‘è®¡ç®—ä¸­èµ„æºåˆ†é…æ•ˆç‡ä½ä¸‹çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºäººå·¥æ™ºèƒ½çš„é¢„æµ‹æ–¹æ³•ï¼Œæ—¨åœ¨å®ç°å¤§æ•°æ®æµæ°´çº¿çš„ Cost-Aware èµ„æºé¢„æµ‹ã€‚ä½œè€…åˆ©ç”¨ Random Forest å›å½’æ¨¡å‹å¯¹ Google Borg é›†ç¾¤è¿½è¸ªæ•°æ®è¿›è¡Œé¢„å¤„ç†ï¼Œæå–äº†åŒ…æ‹¬ CPUã€Memory åŠå…¶ä½¿ç”¨åˆ†å¸ƒåœ¨å†…çš„å…³é”®ç‰¹å¾ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¨¡å‹è¾¾åˆ°äº†æé«˜çš„é¢„æµ‹ç²¾åº¦ï¼ˆR Square = 0.99ï¼ŒMAE = 0.0048ï¼ŒRMSE = 0.137ï¼‰ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæ•æ‰å·¥ä½œè´Ÿè½½ç‰¹å¾ä¸èµ„æºåˆ©ç”¨ç‡ä¹‹é—´çš„éçº¿æ€§å…³ç³»ã€‚è¯¯å·®åˆ†æè¡¨æ˜ï¼Œæ¨¡å‹åœ¨ä¸­å°è§„æ¨¡ä½œä¸šä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨ç¨€æœ‰çš„å¤§è§„æ¨¡ä½œä¸šä¸­å­˜åœ¨è¾ƒé«˜æ–¹å·®ã€‚è¯¥ç ”ç©¶è¯æ˜äº† AI é©±åŠ¨çš„é¢„æµ‹åœ¨äº‘ç¯å¢ƒ Cost-Aware Autoscaling ä¸­çš„å·¨å¤§æ½œåŠ›ï¼Œèƒ½å¤Ÿåœ¨æœ‰æ•ˆé™ä½è¿‡åº¦é…ç½®æˆæœ¬çš„åŒæ—¶ï¼Œä¿éšœæœåŠ¡è´¨é‡å¹¶å‡å°‘ SLA è¿è§„é£é™©ã€‚",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "14 pages, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.05127v1",
      "published_date": "2025-09-30 20:01:12 UTC",
      "updated_date": "2025-09-30 20:01:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:23:30.483709+00:00"
    },
    {
      "arxiv_id": "2510.00237v1",
      "title": "Debunk the Myth of SFT Generalization",
      "title_zh": "ç ´é™¤ SFT æ³›åŒ–èƒ½åŠ›çš„è¿·æ€",
      "authors": [
        "Xiaofeng Lin",
        "Hejian Sang",
        "Zhipeng Wang",
        "Xuezhou Zhang"
      ],
      "abstract": "A prevailing view holds that supervised fine-tuning (SFT) memorizes training data and fails to generalize, whereas reinforcement learning (RL) attains broader robustness. We revisit this claim through a systematic evaluation on two decision-making benchmarks, Sokoban and General Points, and arrive at a different conclusion. We show that much of SFT's perceived failure stems from frozen-prompt artifacts: when trained on fixed instruction templates, SFT models cling to training semantics rather than adapting to new ones. Introducing prompt diversity during training breaks this shortcut and yields strong generalization to unseen instruction variants without harming in-distribution performance. Beyond instruction shifts, we ask whether SFT can generalize to strictly harder tasks. Here, chain-of-thought (CoT) supervision provides an algorithmic scaffold that markedly improves transfer to more difficult regimes, such as larger Sokoban grids with additional boxes and arithmetic with out-of-distribution values or five-card compositions that increase combinatorial complexity. Finally, combining prompt diversity with CoT achieves the best of both worlds: robust generalization across both instruction-variant and difficulty-variant settings, matching or surpassing RL baselines on our benchmarks while retaining SFT's simplicity and stability. These findings challenge the narrative that SFT is inherently inferior to RL and support a data-centric perspective: with appropriately curated demonstrations, vanilla SFT can generalize as strongly as RL. Code reproducing the results in the paper can be found at: https://github.com/XiaofengLin7/debunking-sft-generalization.",
      "tldr_zh": "è¯¥ç ”ç©¶é‡æ–°è¯„ä¼°äº†ç›‘ç£å¾®è°ƒ (Supervised Fine-Tuning, SFT) ä»…èƒ½è®°å¿†è®­ç»ƒæ•°æ®è€Œæ— æ³•æ³›åŒ–çš„æ™®éè§‚ç‚¹ï¼ŒæŒ‡å‡º SFT æ³›åŒ–å¤±è´¥çš„ä¸»è¦åŸå› åœ¨äºâ€œå†»ç»“æç¤ºè¯ä¼ªå½± (frozen-prompt artifacts)â€ã€‚é€šè¿‡åœ¨è®­ç»ƒä¸­å¼•å…¥æç¤ºè¯å¤šæ ·æ€§ (prompt diversity)ï¼ŒSFT æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆé€‚åº”æœªè§çš„æŒ‡ä»¤å˜ä½“è€Œä¸æŸå¤±åˆ†å¸ƒå†…æ€§èƒ½ã€‚ç ”ç©¶è¿›ä¸€æ­¥è¯æ˜ï¼Œç»“åˆé“¾å¼æ€ç»´ (Chain-of-Thought, CoT) ç›‘ç£èƒ½ä¸ºæ¨¡å‹æä¾›ç®—æ³•æ”¯æ’‘ï¼Œæ˜¾è‘—æå‡å…¶åœ¨æ›´å¤æ‚ Sokoban ä»»åŠ¡åŠåˆ†å¸ƒå¤–ç®—æœ¯é€»è¾‘ä¸­çš„è¿ç§»èƒ½åŠ›ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œç»“åˆå¤šæ ·åŒ–æç¤ºå’Œ CoT çš„ SFT åœ¨é²æ£’æ€§ä¸Šå¯ä»¥åŒ¹é…ç”šè‡³è¶…è¶Šå¼ºåŒ–å­¦ä¹  (RL) åŸºå‡†æ¨¡å‹ã€‚è¿™ä¸€å‘ç°æŒ‘æˆ˜äº† SFT å›ºæœ‰å¼±äº RL çš„ä¼ ç»Ÿè®¤çŸ¥ï¼Œå¼ºè°ƒäº†åœ¨é«˜è´¨é‡æ¼”ç¤ºæ•°æ®çš„æ”¯æŒä¸‹ï¼ŒåŸç”Ÿ SFT åŒæ ·å…·å¤‡å¼ºå¤§çš„æ³›åŒ–æ½œåŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.00237v1",
      "published_date": "2025-09-30 20:01:09 UTC",
      "updated_date": "2025-09-30 20:01:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:23:35.417819+00:00"
    },
    {
      "arxiv_id": "2510.00232v1",
      "title": "BiasFreeBench: a Benchmark for Mitigating Bias in Large Language Model Responses",
      "title_zh": "BiasFreeBenchï¼šç¼“è§£å¤§è¯­è¨€æ¨¡å‹å›å¤åè§çš„è¯„æµ‹åŸºå‡†",
      "authors": [
        "Xin Xu",
        "Xunzhi He",
        "Churan Zhi",
        "Ruizhe Chen",
        "Julian McAuley",
        "Zexue He"
      ],
      "abstract": "Existing studies on bias mitigation methods for large language models (LLMs) use diverse baselines and metrics to evaluate debiasing performance, leading to inconsistent comparisons among them. Moreover, their evaluations are mostly based on the comparison between LLMs' probabilities of biased and unbiased contexts, which ignores the gap between such evaluations and real-world use cases where users interact with LLMs by reading model responses and expect fair and safe outputs rather than LLMs' probabilities. To enable consistent evaluation across debiasing methods and bridge this gap, we introduce BiasFreeBench, an empirical benchmark that comprehensively compares eight mainstream bias mitigation techniques (covering four prompting-based and four training-based methods) on two test scenarios (multi-choice QA and open-ended multi-turn QA) by reorganizing existing datasets into a unified query-response setting. We further introduce a response-level metric, Bias-Free Score, to measure the extent to which LLM responses are fair, safe, and anti-stereotypical. Debiasing performances are systematically compared and analyzed across key dimensions: the prompting vs. training paradigm, model size, and generalization of different training strategies to unseen bias types. We will publicly release our benchmark, aiming to establish a unified testbed for bias mitigation research.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åè§ç¼“è§£æ–¹æ³•ä¸­åŸºå‡†å’ŒæŒ‡æ ‡ä¸ç»Ÿä¸€ï¼Œä¸”è¯„ä¼°è¿‡äºä¾èµ–æ¦‚ç‡åˆ†å¸ƒè€ŒéçœŸå®å“åº”è´¨é‡çš„é—®é¢˜ï¼Œæå‡ºäº† BiasFreeBench è¿™ä¸€å®è¯åŸºå‡†æµ‹è¯•ã€‚è¯¥åŸºå‡†é€šè¿‡å°†ç°æœ‰æ•°æ®é›†é‡ç»„ä¸ºç»Ÿä¸€çš„æŸ¥è¯¢-å“åº”è®¾ç½®ï¼Œæ¶µç›–äº†å¤šé€‰é¢˜ QA å’Œå¼€æ”¾å¼å¤šè½® QA ä¸¤ç§æµ‹è¯•åœºæ™¯ã€‚BiasFreeBench ç»¼åˆå¯¹æ¯”äº†å…«ç§ä¸»æµçš„åè§ç¼“è§£æŠ€æœ¯ï¼ŒåŒ…æ‹¬å››ç§åŸºäºæç¤ºè¯ï¼ˆprompting-basedï¼‰å’Œå››ç§åŸºäºè®­ç»ƒï¼ˆtraining-basedï¼‰çš„æ–¹æ³•ã€‚ä¸ºäº†è¡¡é‡ LLM å“åº”çš„å…¬å¹³æ€§ã€å®‰å…¨æ€§å’Œååˆ»æ¿å°è±¡ç¨‹åº¦ï¼Œç ”ç©¶è€…å¼•å…¥äº†ä¸€ä¸ªåä¸º Bias-Free Score çš„å“åº”çº§æŒ‡æ ‡ã€‚è¯¥ç ”ç©¶ä»èŒƒå¼å¯¹æ¯”ã€æ¨¡å‹è§„æ¨¡ä»¥åŠå¯¹æœªçŸ¥åè§ç±»å‹çš„æ³›åŒ–èƒ½åŠ›ç­‰å…³é”®ç»´åº¦ï¼Œå¯¹ä¸åŒç­–ç•¥çš„æ€§èƒ½è¿›è¡Œäº†ç³»ç»Ÿæ€§åˆ†æã€‚BiasFreeBench çš„å‘å¸ƒæ—¨åœ¨ä¸ºåè§ç¼“è§£ç ”ç©¶å»ºç«‹ç»Ÿä¸€çš„æµ‹è¯•å¹³å°ï¼Œä»è€Œå¼¥åˆå®éªŒå®¤è¯„ä¼°ä¸çœŸå®ä¸–ç•Œåº”ç”¨åœºæ™¯ä¹‹é—´çš„é¸¿æ²Ÿã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress",
      "pdf_url": "https://arxiv.org/pdf/2510.00232v1",
      "published_date": "2025-09-30 19:56:54 UTC",
      "updated_date": "2025-09-30 19:56:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:23:52.881606+00:00"
    },
    {
      "arxiv_id": "2510.00231v1",
      "title": "The Pitfalls of KV Cache Compression",
      "title_zh": "KV Cache å‹ç¼©çš„é™·é˜±",
      "authors": [
        "Alex Chen",
        "Renato Geh",
        "Aditya Grover",
        "Guy Van den Broeck",
        "Daniel Israel"
      ],
      "abstract": "KV cache compression promises increased throughput and efficiency with negligible loss in performance. While the gains in throughput are indisputable and recent literature has indeed shown minimal degradation on particular benchmarks, in general the consequences of compression in realistic scenarios such as multi-instruction prompting have been insufficiently studied. In this paper, we identify several pitfalls practitioners should be aware of when deploying KV cache compressed LLMs. Importantly, we show that certain instructions degrade much more rapidly with compression, effectively causing them to be completely ignored by the LLM. As a practical example of that, we highlight system prompt leakage as a case study, empirically showing the impact of compression on leakage and general instruction following. We show several factors that play a role in prompt leakage: compression method, instruction order, and KV eviction bias. We then propose simple changes to KV cache eviction policies that can reduce the impact of these factors and improve the overall performance in multi-instruction tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶æ·±å…¥æ¢è®¨äº†KV cache compressionåœ¨å¤šæŒ‡ä»¤æç¤ºè¯ç­‰å®é™…åº”ç”¨åœºæ™¯ä¸­å­˜åœ¨çš„é£é™©ï¼ŒæŒ‡å‡ºè¿‡åº¦å‹ç¼©ä¼šå¯¼è‡´ç‰¹å®šæŒ‡ä»¤è¢«å¤§è¯­è¨€æ¨¡å‹å®Œå…¨å¿½ç•¥ã€‚ç ”ç©¶é€šè¿‡system prompt leakageæ¡ˆä¾‹ï¼Œå®è¯æ­ç¤ºäº†å‹ç¼©æ–¹æ³•ã€æŒ‡ä»¤é¡ºåºåŠKV eviction biaså¯¹æ¨¡å‹æŒ‡ä»¤éµå¾ªèƒ½åŠ›çš„è´Ÿé¢å½±å“ã€‚ä½œè€…å‘ç°ï¼Œç°æœ‰çš„å‹ç¼©æŠ€æœ¯è™½ç„¶åœ¨ç‰¹å®šåŸºå‡†æµ‹è¯•ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨å¤„ç†å¤æ‚ã€å¤šå±‚æ¬¡çš„ä»»åŠ¡æ—¶ä¼šå‡ºç°æ˜æ˜¾çš„æ€§èƒ½é™çº§ã€‚é’ˆå¯¹è¿™äº›é—®é¢˜ï¼Œè®ºæ–‡æå‡ºäº†æ”¹è¿›çš„KV cache eviction policiesï¼Œé€šè¿‡ä¼˜åŒ–ç¼“å­˜å‰”é™¤ç­–ç•¥æ¥å¢å¼ºæ¨¡å‹çš„é²æ£’æ€§ã€‚å®éªŒè¯æ˜ï¼Œè¿™äº›è°ƒæ•´èƒ½æ˜¾è‘—æå‡LLMsåœ¨å‹ç¼©çŠ¶æ€ä¸‹çš„å¤šæŒ‡ä»¤æ‰§è¡Œèƒ½åŠ›ï¼Œä¸ºå®ç°é«˜æ•ˆä¸”å¯é çš„æ¨¡å‹éƒ¨ç½²æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.00231v1",
      "published_date": "2025-09-30 19:55:26 UTC",
      "updated_date": "2025-09-30 19:55:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:24:01.789039+00:00"
    },
    {
      "arxiv_id": "2510.00229v4",
      "title": "AgentFlux: Decoupled Fine-Tuning & Inference for On-Device Agentic Systems",
      "title_zh": "AgentFluxï¼šé¢å‘ç«¯ä¾§æ™ºèƒ½ä½“ç³»ç»Ÿçš„è§£è€¦å¼å¾®è°ƒä¸æ¨ç†",
      "authors": [
        "Rohan Kadekodi",
        "Zhan Jin",
        "Keisuke Kamahori",
        "Yile Gu",
        "Sean Khatiri",
        "Noah H. Bayindirli",
        "Sergey Gorbunov",
        "Baris Kasikci"
      ],
      "abstract": "The deployment of Large Language Models (LLMs) as agentic orchestrators has revolutionized task automation, but the need for privacy-preserving, cost-effective solutions demands on-device inference capabilities. However, local LLMs consistently underperform compared to frontier models in tool calling scenarios, struggling with both tool selection from large tool sets and accurate argument generation for complex parameter structures. We introduce a methodology that disaggregates a tool-calling task into two distinct subtasks: tool selection and argument generation. We propose \"decoupled fine-tuning\", a novel post-training approach that employs LoRA fine-tuning to create dedicated LoRA adapters for tool selection and tool-specific argument generation using separate loss masking for each of the subtasks. Furthermore, we present AgentFlux, an inference framework that leverages the LoRA adapters created using decoupled fine-tuning to perform efficient agent orchestration with the help of local models on end-user devices. AgentFlux decomposes the tool-call generation step into tool selection and argument generation, and dynamically loads the corresponding LoRA adapters to generate tool calls. Additionally, AgentFlux implements hierarchical orchestration to restrict the number of tools required for tool selection. Our experiments on the MCP-Bench benchmark demonstrate that the Qwen-2.5-7B model trained using decoupled fine-tuning improves the tool calling accuracy of the base model by 46%, and outperforms other local reasoning, non-reasoning and fine-tuned models of similar size in all cases, and models that are 2x larger, in most cases.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç«¯ä¾§æ™ºèƒ½ä½“ç³»ç»Ÿ(On-Device Agentic Systems)ä¸­æœ¬åœ°å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å·¥å…·è°ƒç”¨(tool calling)åœºæ™¯ä¸‹è¡¨ç°ä¸ä½³çš„é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯éš¾ä»¥ä»å¤§è§„æ¨¡å·¥å…·é›†ä¸­å‡†ç¡®é€‰æ‹©å·¥å…·åŠç”Ÿæˆå¤æ‚å‚æ•°ç»“æ„ã€‚ç ”ç©¶è€…æå‡ºäº†ä¸€ç§åä¸ºâ€œè§£è€¦å¾®è°ƒâ€(decoupled fine-tuning)çš„æ–¹æ³•ï¼Œå°†å·¥å…·è°ƒç”¨ä»»åŠ¡æ‹†è§£ä¸ºå·¥å…·é€‰æ‹©(tool selection)å’Œå‚æ•°ç”Ÿæˆ(argument generation)ä¸¤ä¸ªç‹¬ç«‹å­ä»»åŠ¡ï¼Œå¹¶åˆ©ç”¨LoRAå¾®è°ƒæŠ€æœ¯ä¸ºå„å­ä»»åŠ¡è®­ç»ƒä¸“é—¨çš„LoRAé€‚é…å™¨(LoRA adapters)ã€‚åœ¨æ­¤åŸºç¡€ä¸Šå¼€å‘çš„AgentFluxæ¨ç†æ¡†æ¶ï¼Œæ”¯æŒåœ¨ç»ˆç«¯è®¾å¤‡ä¸ŠåŠ¨æ€åŠ è½½é€‚é…å™¨ï¼Œå¹¶ç»“åˆå±‚æ¬¡åŒ–ç¼–æ’(hierarchical orchestration)ç­–ç•¥æ¥ä¼˜åŒ–å·¥å…·é€‰æ‹©è¿‡ç¨‹ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨MCP-BenchåŸºå‡†æµ‹è¯•ä¸­ï¼Œä½¿ç”¨è¯¥æ–¹æ³•è®­ç»ƒçš„Qwen-2.5-7Bæ¨¡å‹æ¯”åŸºç¡€æ¨¡å‹å‡†ç¡®ç‡æå‡äº†46%ï¼Œæ€§èƒ½ä¸ä»…æ˜¾è‘—ä¼˜äºåŒå°ºå¯¸çš„å…¶ä»–æ¨¡å‹ï¼Œåœ¨å¤šæ•°æƒ…å†µä¸‹ç”šè‡³è¶…è¶Šäº†å‚æ•°é‡ä¸¤å€äºå…¶çš„å¤§å‹æ¨¡å‹ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.00229v4",
      "published_date": "2025-09-30 19:52:57 UTC",
      "updated_date": "2025-11-12 04:25:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:23:59.286986+00:00"
    },
    {
      "arxiv_id": "2510.00225v1",
      "title": "TGPO: Temporal Grounded Policy Optimization for Signal Temporal Logic Tasks",
      "title_zh": "TGPOï¼šé¢å‘ä¿¡å·æ—¶åºé€»è¾‘ä»»åŠ¡çš„æ—¶åºè½åœ°ç­–ç•¥ä¼˜åŒ–",
      "authors": [
        "Yue Meng",
        "Fei Chen",
        "Chuchu Fan"
      ],
      "abstract": "Learning control policies for complex, long-horizon tasks is a central challenge in robotics and autonomous systems. Signal Temporal Logic (STL) offers a powerful and expressive language for specifying such tasks, but its non-Markovian nature and inherent sparse reward make it difficult to be solved via standard Reinforcement Learning (RL) algorithms. Prior RL approaches focus only on limited STL fragments or use STL robustness scores as sparse terminal rewards. In this paper, we propose TGPO, Temporal Grounded Policy Optimization, to solve general STL tasks. TGPO decomposes STL into timed subgoals and invariant constraints and provides a hierarchical framework to tackle the problem. The high-level component of TGPO proposes concrete time allocations for these subgoals, and the low-level time-conditioned policy learns to achieve the sequenced subgoals using a dense, stage-wise reward signal. During inference, we sample various time allocations and select the most promising assignment for the policy network to rollout the solution trajectory. To foster efficient policy learning for complex STL with multiple subgoals, we leverage the learned critic to guide the high-level temporal search via Metropolis-Hastings sampling, focusing exploration on temporally feasible solutions. We conduct experiments on five environments, ranging from low-dimensional navigation to manipulation, drone, and quadrupedal locomotion. Under a wide range of STL tasks, TGPO significantly outperforms state-of-the-art baselines (especially for high-dimensional and long-horizon cases), with an average of 31.6% improvement in task success rate compared to the best baseline. The code will be available at https://github.com/mengyuest/TGPO",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æœºå™¨äººå’Œè‡ªåŠ¨ç³»ç»Ÿä¸­å¤æ‚çš„é•¿å‘¨æœŸä»»åŠ¡ï¼Œæå‡ºäº†ä¸€ç§åä¸ºTGPOï¼ˆTemporal Grounded Policy Optimizationï¼‰çš„å±‚æ¬¡åŒ–æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³Signal Temporal Logic (STL) ä»»åŠ¡ä¸­å­˜åœ¨çš„éé©¬å°”å¯å¤«æ€§è´¨(non-Markovian)å’Œç¨€ç–å¥–åŠ±éš¾é¢˜ã€‚TGPOå°†å¤æ‚çš„STLä»»åŠ¡åˆ†è§£ä¸ºå¸¦æ—¶é—´æˆ³çš„å­ç›®æ ‡(timed subgoals)å’Œä¸å˜çº¦æŸ(invariant constraints)ï¼Œé€šè¿‡é«˜å±‚ç»„ä»¶è¿›è¡Œæ—¶é—´åˆ†é…ï¼Œå¹¶åˆ©ç”¨åº•å±‚çš„å—æ—¶çº¦æŸç­–ç•¥(time-conditioned policy)ä¾æ¬¡å®ç°å­ç›®æ ‡ã€‚ä¸ºäº†æé«˜æœç´¢æ•ˆç‡ï¼Œè¯¥æ–¹æ³•ç»“åˆäº†Metropolis-Hastingsé‡‡æ ·ï¼Œåˆ©ç”¨å­¦ä¹ åˆ°çš„è¯„ä»·å™¨(critic)å¼•å¯¼é«˜å±‚æ—¶é—´æœç´¢ï¼Œä»è€Œä¸“æ³¨äºæ¢ç´¢æ—¶é—´ä¸Šå¯è¡Œçš„è§£å†³æ–¹æ¡ˆã€‚åœ¨å¯¼èˆªã€æœºæ¢°è‡‚æ“çºµã€æ— äººæœºå’Œå››è¶³æœºå™¨äººç­‰äº”ç§ç¯å¢ƒä¸‹çš„å®éªŒè¡¨æ˜ï¼ŒTGPOåœ¨å¤„ç†é«˜ç»´å’Œé•¿å‘¨æœŸä»»åŠ¡(long-horizon tasks)æ—¶è¡¨ç°å‡ºè‰²ã€‚ç›¸æ¯”äºç°æœ‰çš„æœ€å…ˆè¿›åŸºå‡†æ¨¡å‹ï¼ŒTGPOå°†ä»»åŠ¡å¹³å‡æˆåŠŸç‡æå‡äº†31.6%ï¼Œä¸ºè§£å†³é€šç”¨çš„STLä»»åŠ¡æä¾›äº†é«˜æ•ˆä¸”å¯æ‰©å±•çš„å¼ºåŒ–å­¦ä¹ (RL)æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "cs.LO"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.00225v1",
      "published_date": "2025-09-30 19:51:05 UTC",
      "updated_date": "2025-09-30 19:51:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:24:05.297631+00:00"
    },
    {
      "arxiv_id": "2510.05126v2",
      "title": "Improving Metacognition and Uncertainty Communication in Language Models",
      "title_zh": "æå‡è¯­è¨€æ¨¡å‹çš„å…ƒè®¤çŸ¥èƒ½åŠ›ä¸ä¸ç¡®å®šæ€§è¡¨è¾¾",
      "authors": [
        "Mark Steyvers",
        "Catarina Belem",
        "Padhraic Smyth"
      ],
      "abstract": "Large language models (LLMs) are increasingly used in decision-making contexts, but when they present answers without signaling low confidence, users may unknowingly act on erroneous outputs. Prior work shows that LLMs maintain internal uncertainty signals, yet their expressed confidence is often miscalibrated and poorly discriminates between correct and incorrect answers. We investigate whether supervised fine-tuning can improve models' ability to communicate uncertainty and whether such improvements generalize across tasks and domains. We fine-tune LLMs on datasets spanning general knowledge, mathematics, and open-ended trivia, and evaluate two metacognitive tasks: (1) single-question confidence estimation, where the model assigns a numeric certainty to its answer, and (2) pairwise confidence comparison, where the model selects which of two answers it is more likely to answer correctly. We assess generalization to unseen domains, including medical and legal reasoning. Results show that fine-tuning improves calibration (alignment between stated confidence and accuracy) and discrimination (higher confidence for correct vs. incorrect responses) within and across domains. However, gains are task-specific: training on single-question calibration does not transfer to pairwise comparison, and vice versa. Multitask fine-tuning yields broader gains, lowering calibration error and strengthening discrimination in out-of-domain evaluations. This suggests that uncertainty communication in LLMs is trainable but requires multitask training to generalize effectively.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¦‚ä½•æé«˜å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å…ƒè®¤çŸ¥ï¼ˆMetacognitionï¼‰å’Œä¸ç¡®å®šæ€§é€šä¿¡ï¼ˆUncertainty Communicationï¼‰èƒ½åŠ›ï¼Œä»¥è§£å†³æ¨¡å‹ç½®ä¿¡åº¦è¡¨è¾¾ä¸å‡†ç¡®çš„é—®é¢˜ã€‚ç ”ç©¶äººå‘˜åœ¨é€šç”¨çŸ¥è¯†ã€æ•°å­¦å’Œçäº‹æ•°æ®é›†ä¸Šå¯¹LLMsè¿›è¡Œäº†ç›‘ç£å¾®è°ƒï¼ˆSupervised Fine-tuningï¼‰ï¼Œå¹¶é‡ç‚¹è¯„ä¼°äº†å•é—®é¢˜ç½®ä¿¡åº¦ä¼°è®¡ï¼ˆSingle-question Confidence Estimationï¼‰å’Œä¸¤ä¸¤ç½®ä¿¡åº¦æ¯”è¾ƒï¼ˆPairwise Confidence Comparisonï¼‰ä¸¤é¡¹ä»»åŠ¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå¾®è°ƒèƒ½æ˜¾è‘—æ”¹å–„æ¨¡å‹åœ¨é¢†åŸŸå†…åŠè·¨é¢†åŸŸï¼ˆå¦‚åŒ»ç–—å’Œæ³•å¾‹æ¨ç†ï¼‰çš„æ ¡å‡†æ€§ï¼ˆCalibrationï¼‰ä¸åˆ¤åˆ«åŠ›ï¼ˆDiscriminationï¼‰ã€‚ç„¶è€Œï¼Œç ”ç©¶å‘ç°è¿™äº›æå‡å…·æœ‰ä»»åŠ¡ç‰¹å¼‚æ€§ï¼Œå•ä»»åŠ¡è®­ç»ƒçš„å¢ç›Šæ— æ³•åœ¨ä¸åŒè¯„ä¼°å½¢å¼é—´ç›¸äº’è¿ç§»ã€‚é€šè¿‡å¤šä»»åŠ¡å¾®è°ƒï¼ˆMultitask Fine-tuningï¼‰ï¼Œæ¨¡å‹å±•ç°å‡ºæ›´å¹¿æ³›çš„æ³›åŒ–èƒ½åŠ›ï¼Œèƒ½æ›´æœ‰æ•ˆåœ°é™ä½æ ¡å‡†è¯¯å·®å¹¶å¢å¼ºåœ¨æœªè§é¢†åŸŸä¸­çš„è¡¨ç°ã€‚è¿™è¡¨æ˜LLMçš„ä¸ç¡®å®šæ€§é€šä¿¡èƒ½åŠ›æ˜¯å¯è®­ç»ƒçš„ï¼Œä½†éœ€è¦é€šè¿‡å¤šä»»åŠ¡è®­ç»ƒæ¥å®ç°æœ‰æ•ˆçš„æ³›åŒ–ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.05126v2",
      "published_date": "2025-09-30 19:50:02 UTC",
      "updated_date": "2025-10-21 21:46:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:24:08.387583+00:00"
    },
    {
      "arxiv_id": "2510.00219v1",
      "title": "Thoughtbubbles: an Unsupervised Method for Parallel Thinking in Latent Space",
      "title_zh": "Thoughtbubblesï¼šä¸€ç§æ½œåœ¨ç©ºé—´å¹¶è¡Œæ€ç»´çš„æ— ç›‘ç£æ–¹æ³•",
      "authors": [
        "Houjun Liu",
        "Shikhar Murty",
        "Christopher D. Manning",
        "RÃ³bert CsordÃ¡s"
      ],
      "abstract": "Current approaches for scaling inference-time compute in transformers rely on training them to emit explicit chain-of-thought tokens before producing an answer. While these methods are powerful, they are limited because they cannot be applied during pretraining and are limited to only serially-generated, natural-language verbalization to scale inference-time compute. In this work, we propose Thoughtbubbles, a transformer variant that natively performs parallel adaptive computation in latent space by learning to fork or delete residual streams. Thus, tokens that require a large amount of computation can form a \"bubble\" of cloned residuals in the middle of the network for additional thinking. Crucially, this behavior is learned during pretraining with only language modeling loss. Thoughtbubbles outperforms both standard decoder LMs as well as non-adaptive parallel computation approaches on OpenWebText and peS2o perplexity and in zero-shot evaluations such as HellaSwag and LAMBADA after pretraining across 150M to 772M parameter scales. The implicit nature of our method enables adaptive computation to be learned starting at pretraining time, paving the way to unify train and test-time behavior for reasoning models.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Thoughtbubblesï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨å®ç°æ½œåœ¨ç©ºé—´(Latent Space)å¹¶è¡Œè‡ªé€‚åº”è®¡ç®—çš„Transformerå˜ä½“ï¼Œæœ‰æ•ˆå…‹æœäº†ä¼ ç»Ÿé“¾å¼æ€ç»´(Chain-of-Thought)æ¨ç†ä¾èµ–æ˜¾å¼Tokenç”Ÿæˆå’Œä¸²è¡Œå¤„ç†çš„å±€é™ã€‚è¯¥æ–¹æ³•é€šè¿‡åœ¨ç½‘ç»œä¸­å­¦ä¹ æ´¾ç”Ÿæˆ–åˆ é™¤æ®‹å·®æµ(Residual Streams)ï¼Œå…è®¸éœ€è¦å¤§é‡è®¡ç®—çš„Tokenå½¢æˆâ€œæ°”æ³¡â€åŒ–çš„å…‹éš†æ®‹å·®ï¼Œä»è€Œåœ¨æ¨¡å‹å†…éƒ¨è¿›è¡Œé¢å¤–çš„å¹¶è¡Œæ€è€ƒã€‚Thoughtbubblesçš„æ ¸å¿ƒä¼˜åŠ¿åœ¨äºå…¶è¡Œä¸ºæ˜¯åœ¨é¢„è®­ç»ƒ(Pretraining)é˜¶æ®µä»…é€šè¿‡è¯­è¨€å»ºæ¨¡æŸå¤±(Language Modeling Loss)ä»¥æ— ç›‘ç£æ–¹å¼ä¹ å¾—çš„ï¼Œå®ç°äº†è®­ç»ƒä¸æ¨ç†é˜¶æ®µæ¨ç†è¡Œä¸ºçš„ç»Ÿä¸€ã€‚åœ¨150Mè‡³772Må‚æ•°è§„æ¨¡çš„å®éªŒä¸­ï¼ŒThoughtbubblesåœ¨OpenWebTextå’ŒpeS2oçš„å›°æƒ‘åº¦(Perplexity)è¡¨ç°ï¼Œä»¥åŠHellaSwagå’ŒLAMBADAç­‰é›¶æ ·æœ¬(Zero-shot)è¯„ä¼°ä»»åŠ¡ä¸Šå‡ä¼˜äºæ ‡å‡†è§£ç å™¨è¯­è¨€æ¨¡å‹åŠéè‡ªé€‚åº”å¹¶è¡Œè®¡ç®—æ–¹æ³•ã€‚è¿™ä¸€ç ”ç©¶ä¸ºå¼€å‘èƒ½å¤Ÿåœ¨é¢„è®­ç»ƒé˜¶æ®µå°±å¼€å§‹å­¦ä¹ è‡ªé€‚åº”è®¡ç®—èƒ½åŠ›çš„æ¨ç†æ¨¡å‹æä¾›äº†æ–°çš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.00219v1",
      "published_date": "2025-09-30 19:49:15 UTC",
      "updated_date": "2025-09-30 19:49:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:24:12.071715+00:00"
    },
    {
      "arxiv_id": "2510.00212v1",
      "title": "Directed-MAML: Meta Reinforcement Learning Algorithm with Task-directed Approximation",
      "title_zh": "Directed-MAMLï¼šåŸºäºä»»åŠ¡å¯¼å‘è¿‘ä¼¼çš„å…ƒå¼ºåŒ–å­¦ä¹ ç®—æ³•",
      "authors": [
        "Yang Zhang",
        "Huiwen Yan",
        "Mushuang Liu"
      ],
      "abstract": "Model-Agnostic Meta-Learning (MAML) is a versatile meta-learning framework applicable to both supervised learning and reinforcement learning (RL). However, applying MAML to meta-reinforcement learning (meta-RL) presents notable challenges. First, MAML relies on second-order gradient computations, leading to significant computational and memory overhead. Second, the nested structure of optimization increases the problem's complexity, making convergence to a global optimum more challenging. To overcome these limitations, we propose Directed-MAML, a novel task-directed meta-RL algorithm. Before the second-order gradient step, Directed-MAML applies an additional first-order task-directed approximation to estimate the effect of second-order gradients, thereby accelerating convergence to the optimum and reducing computational cost. Experimental results demonstrate that Directed-MAML surpasses MAML-based baselines in computational efficiency and convergence speed in the scenarios of CartPole-v1, LunarLander-v2 and two-vehicle intersection crossing. Furthermore, we show that task-directed approximation can be effectively integrated into other meta-learning algorithms, such as First-Order Model-Agnostic Meta-Learning (FOMAML) and Meta Stochastic Gradient Descent(Meta-SGD), yielding improved computational efficiency and convergence speed.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ¨¡å‹æ— å…³å…ƒå­¦ä¹ (MAML)åœ¨å…ƒå¼ºåŒ–å­¦ä¹ (meta-RL)ä¸­é¢ä¸´çš„äºŒé˜¶æ¢¯åº¦è®¡ç®—å¼€é”€å·¨å¤§ä»¥åŠä¼˜åŒ–ç»“æ„å¤æ‚å¯¼è‡´æ”¶æ•›å›°éš¾ç­‰é—®é¢˜ï¼Œæå‡ºäº† Directed-MAML ç®—æ³•ã€‚è¯¥ç®—æ³•åœ¨æ‰§è¡ŒäºŒé˜¶æ¢¯åº¦æ­¥éª¤ä¹‹å‰ï¼Œé€šè¿‡å¼•å…¥é¢å¤–çš„é¦–é˜¶ä»»åŠ¡å®šå‘è¿‘ä¼¼(task-directed approximation)æ¥é¢„ä¼°äºŒé˜¶æ¢¯åº¦çš„å½±å“ï¼Œä»è€Œåœ¨é™ä½è®¡ç®—æˆæœ¬çš„åŒæ—¶åŠ é€Ÿå‘æœ€ä¼˜è§£æ”¶æ•›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDirected-MAML åœ¨ CartPole-v1ã€LunarLander-v2 ä»¥åŠåŒè½¦äº¤å‰å£åœºæ™¯ä¸­ï¼Œå…¶è®¡ç®—æ•ˆç‡å’Œæ”¶æ•›é€Ÿåº¦å‡æ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„ MAML åŸºå‡†æ¨¡å‹ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜éªŒè¯äº†ä»»åŠ¡å®šå‘è¿‘ä¼¼æŠ€æœ¯å…·æœ‰è‰¯å¥½çš„é€šç”¨æ€§ï¼Œèƒ½å¤Ÿæœ‰æ•ˆé›†æˆåˆ° First-Order Model-Agnostic Meta-Learning (FOMAML) å’Œ Meta Stochastic Gradient Descent (Meta-SGD) ç­‰å…¶ä»–å…ƒå­¦ä¹ ç®—æ³•ä¸­ï¼Œè¿›ä¸€æ­¥æå‡å…¶è®¡ç®—æ•ˆç‡ä¸æ”¶æ•›æ€§èƒ½ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.00212v1",
      "published_date": "2025-09-30 19:42:15 UTC",
      "updated_date": "2025-09-30 19:42:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:24:52.493761+00:00"
    },
    {
      "arxiv_id": "2510.03308v2",
      "title": "Creative synthesis of kinematic mechanisms",
      "title_zh": "è¿åŠ¨æœºæ„çš„åˆ›æ–°æ€§ç»¼åˆ",
      "authors": [
        "Jiong Lin",
        "Jialong Ning",
        "Judah Goldfeder",
        "Hod Lipson"
      ],
      "abstract": "In this paper, we formulate the problem of kinematic synthesis for planar linkages as a cross-domain image generation task. We develop a planar linkages dataset using RGB image representations, covering a range of mechanisms: from simple types such as crank-rocker and crank-slider to more complex eight-bar linkages like Jansen's mechanism. A shared-latent variational autoencoder (VAE) is employed to explore the potential of image generative models for synthesizing unseen motion curves and simulating novel kinematics. By encoding the drawing speed of trajectory points as color gradients, the same architecture also supports kinematic synthesis conditioned on both trajectory shape and velocity profiles. We validate our method on three datasets of increasing complexity: a standard four-bar linkage set, a mixed set of four-bar and crank-slider mechanisms, and a complex set including multi-loop mechanisms. Preliminary results demonstrate the effectiveness of image-based representations for generative mechanical design, showing that mechanisms with revolute and prismatic joints, and potentially cams and gears, can be represented and synthesized within a unified image generation framework.",
      "tldr_zh": "è¯¥ç ”ç©¶å°†å¹³é¢è¿æ†æœºæ„(planar linkages)çš„è¿åŠ¨å­¦ç»¼åˆé—®é¢˜è½¬åŒ–ä¸ºè·¨åŸŸå›¾åƒç”Ÿæˆä»»åŠ¡ï¼Œå¹¶å¼€å‘äº†ä¸€ä¸ªåŸºäºRGBå›¾åƒè¡¨ç¤ºçš„å¹³é¢è¿æ†æœºæ„æ•°æ®é›†ã€‚è¯¥æ•°æ®é›†æ¶µç›–äº†ä»æ›²æŸ„æ‘‡æ†(crank-rocker)ã€æ›²æŸ„æ»‘å—(crank-slider)åˆ°å¤æ‚çš„Jansenæœºæ„ç­‰å…«æ†æœºæ„ã€‚ç ”ç©¶é‡‡ç”¨å…±äº«æ½œç©ºé—´(shared-latent)çš„å˜åˆ†è‡ªç¼–ç å™¨(VAE)æ¶æ„ï¼Œåˆ©ç”¨å›¾åƒç”Ÿæˆæ¨¡å‹æ¢ç´¢åˆæˆæœªçŸ¥è¿åŠ¨æ›²çº¿å’Œæ¨¡æ‹Ÿæ–°é¢–è¿åŠ¨å­¦çš„æ½œåŠ›ã€‚é€šè¿‡å°†è½¨è¿¹ç‚¹çš„ç»˜åˆ¶é€Ÿåº¦ç¼–ç ä¸ºé¢œè‰²æ¢¯åº¦ï¼Œè¯¥æ¶æ„è¿˜å®ç°äº†åŸºäºè½¨è¿¹å½¢çŠ¶å’Œé€Ÿåº¦å‰–é¢(velocity profiles)çš„è¿åŠ¨å­¦ç»¼åˆã€‚å®éªŒåœ¨å››æ†æœºæ„ã€æ··åˆæœºæ„åŠå¤šç¯æœºæ„(multi-loop mechanisms)ç­‰å¤šä¸ªæ•°æ®é›†ä¸ŠéªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚ç»“æœè¡¨æ˜ï¼ŒåŸºäºå›¾åƒè¡¨ç¤ºçš„ç”Ÿæˆå¼æœºæ¢°è®¾è®¡æ¡†æ¶èƒ½å¤Ÿç»Ÿä¸€å¤„ç†åŒ…å«è½¬åŠ¨å‰¯ã€ç§»åŠ¨å‰¯ä¹ƒè‡³å‡¸è½®å’Œé½¿è½®çš„å¤šç§æœºæ„ç»¼åˆã€‚",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.GR",
      "comment": "6pages, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.03308v2",
      "published_date": "2025-09-30 19:32:30 UTC",
      "updated_date": "2025-10-20 16:07:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:24:24.585122+00:00"
    },
    {
      "arxiv_id": "2510.00206v1",
      "title": "LoRAFusion: Efficient LoRA Fine-Tuning for LLMs",
      "title_zh": "LoRAFusionï¼šé¢å‘å¤§è¯­è¨€æ¨¡å‹çš„é«˜æ•ˆ LoRA å¾®è°ƒ",
      "authors": [
        "Zhanda Zhu",
        "Qidong Su",
        "Yaoyao Ding",
        "Kevin Song",
        "Shang Wang",
        "Gennady Pekhimenko"
      ],
      "abstract": "Low-Rank Adaptation (LoRA) has become the leading Parameter-Efficient Fine-Tuning (PEFT) method for Large Language Models (LLMs), as it significantly reduces GPU memory usage while maintaining competitive fine-tuned model quality on downstream tasks. Despite these benefits, we identify two key inefficiencies in existing LoRA fine-tuning systems. First, they incur substantial runtime overhead due to redundant memory accesses on large activation tensors. Second, they miss the opportunity to concurrently fine-tune multiple independent LoRA adapters that share the same base model on the same set of GPUs. This leads to missed performance gains such as reduced pipeline bubbles, better communication overlap, and improved GPU load balance.\n  To address these issues, we introduce LoRAFusion, an efficient LoRA fine-tuning system for LLMs. At the kernel level, we propose a graph-splitting method that fuses memory-bound operations. This design eliminates unnecessary memory accesses and preserves the performance of compute-bound GEMMs without incurring the cost of recomputation or synchronization. At the scheduling level, LoRAFusion introduces an adaptive batching algorithm for multi-job fine-tuning. It first splits LoRA adapters into groups to intentionally stagger batch execution across jobs, and then solves a bin-packing problem within each group to generate balanced, dependency-aware microbatches. LoRAFusion achieves up to $1.96\\times$ ($1.47\\times$ on average) end-to-end speedup compared to Megatron-LM, and up to $1.46\\times$ ($1.29\\times$ on average) improvement over mLoRA, the state-of-the-art multi-LoRA fine-tuning system. Our fused kernel achieves up to $1.39\\times$ ($1.27\\times$ on average) kernel performance improvement and can directly serve as a plug-and-play replacement in existing LoRA systems. We open-source LoRAFusion at https://github.com/CentML/lorafusion.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨ Low-Rank Adaptation (LoRA) å¾®è°ƒè¿‡ç¨‹ä¸­é¢ä¸´çš„å†—ä½™å†…å­˜è®¿é—®å’Œå¤šä»»åŠ¡å¹¶è¡Œå¾®è°ƒæ•ˆç‡ä½ä¸‹ç­‰ç“¶é¢ˆï¼Œæå‡ºäº†é«˜æ•ˆå¾®è°ƒç³»ç»Ÿ LoRAFusionã€‚åœ¨å†…æ ¸å±‚é¢ï¼ŒLoRAFusion é‡‡ç”¨å›¾æ‹†åˆ† (Graph-splitting) æ–¹æ³•èåˆå†…å­˜å—é™ (memory-bound) ç®—å­ï¼Œåœ¨ä¸å¢åŠ é‡è®¡ç®—æˆ–åŒæ­¥æˆæœ¬çš„å‰æä¸‹æ¶ˆé™¤äº†ä¸å¿…è¦çš„å†…å­˜è®¿é—®ã€‚åœ¨è°ƒåº¦å±‚é¢ï¼Œè¯¥ç³»ç»Ÿå¼•å…¥è‡ªé€‚åº”æ‰¹å¤„ç† (Adaptive batching) ç®—æ³•ï¼Œé€šè¿‡åˆ†ç»„é€‚é…å™¨å¹¶åˆ©ç”¨è£…ç®± (Bin-packing) ç­–ç•¥ç”Ÿæˆè´Ÿè½½å‡è¡¡ä¸”æ„ŸçŸ¥ä¾èµ–çš„å¾®æ‰¹æ¬¡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLoRAFusion ç›¸æ¯” Megatron-LM å®ç°äº†æœ€é«˜ 1.96 å€çš„ç«¯åˆ°ç«¯åŠ é€Ÿï¼Œä¸”åœ¨æ€§èƒ½ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰çš„å¤š LoRA å¾®è°ƒç³»ç»Ÿ mLoRAã€‚æ­¤å¤–ï¼Œå…¶ç ”å‘çš„èåˆå†…æ ¸å¯ä½œä¸ºå³æ’å³ç”¨ (plug-and-play) ç»„ä»¶ç›´æ¥é›†æˆåˆ°ç°æœ‰å¾®è°ƒæ¡†æ¶ä¸­ã€‚è¯¥ç ”ç©¶ä¸ºä¼˜åŒ– Parameter-Efficient Fine-Tuning (PEFT) çš„è¿è¡Œæ•ˆç‡å’Œ GPU èµ„æºåˆ©ç”¨ç‡æä¾›äº†æ–°çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by EuroSys 2026",
      "pdf_url": "https://arxiv.org/pdf/2510.00206v1",
      "published_date": "2025-09-30 19:26:22 UTC",
      "updated_date": "2025-09-30 19:26:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:25:20.173034+00:00"
    },
    {
      "arxiv_id": "2510.01279v1",
      "title": "TUMIX: Multi-Agent Test-Time Scaling with Tool-Use Mixture",
      "title_zh": "TUMIXï¼šåŸºäºå·¥å…·è°ƒç”¨æ··åˆçš„å¤šæ™ºèƒ½ä½“æµ‹è¯•æ—¶ç¼©æ”¾",
      "authors": [
        "Yongchao Chen",
        "Jiefeng Chen",
        "Rui Meng",
        "Ji Yin",
        "Na Li",
        "Chuchu Fan",
        "Chi Wang",
        "Tomas Pfister",
        "Jinsung Yoon"
      ],
      "abstract": "While integrating tools like Code Interpreter and Search has significantly enhanced Large Language Model (LLM) reasoning in models like ChatGPT Agent and Gemini-Pro, practical guidance on optimal tool use is lacking. The core challenge is effectively combining textual reasoning, coding, and search for diverse questions. In this paper, we propose Tool-Use Mixture (TUMIX), an ensemble framework that runs multiple agents in parallel, each employing distinct tool-use strategies and answer paths. Agents in TUMIX iteratively share and refine responses based on the question and previous answers. In experiments, TUMIX achieves significant gains over state-of-the-art tool-augmented and test-time scaling methods, delivering an average accuracy improvement of up to 3.55% over the best baseline on Gemini-2.5-Pro and Gemini-2.5-Flash across key reasoning benchmarks, with near-equal inference costs. We find that agent diversity and quality are crucial and can be enhanced by using LLMs to auto-optimize agent designs. Furthermore, TUMIX can halt refinement upon reaching sufficient confidence, preserving performance at only 49% of the inference cost. Further scaling can achieve higher performance, albeit at a greater cost.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Tool-Use Mixture (TUMIX)ï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨ä¼˜åŒ–å¤§è¯­è¨€æ¨¡å‹(LLM)æ¨ç†èƒ½åŠ›çš„é›†æˆæ¡†æ¶ï¼Œé€šè¿‡å¹¶è¡Œè¿è¡Œå¤šä¸ªé‡‡ç”¨ä¸åŒå·¥å…·ä½¿ç”¨ç­–ç•¥å’Œç­”æ¡ˆè·¯å¾„çš„æ™ºèƒ½ä½“æ¥è§£å†³å¤æ‚é—®é¢˜ã€‚TUMIX æ¡†æ¶ä¸­çš„æ™ºèƒ½ä½“èƒ½å¤Ÿæ ¹æ®å…·ä½“é—®é¢˜å’Œå…ˆå‰çš„å›ç­”ï¼Œè¿­ä»£åœ°å…±äº«å¹¶å®Œå–„å½¼æ­¤çš„å“åº”ã€‚ç ”ç©¶å‘ç°ï¼Œé€šè¿‡ä½¿ç”¨ LLMs è‡ªåŠ¨ä¼˜åŒ–æ™ºèƒ½ä½“è®¾è®¡ï¼Œå¯ä»¥æ˜¾è‘—æå‡æ™ºèƒ½ä½“çš„å¤šæ ·æ€§ä¸è´¨é‡ï¼Œè¿™å¯¹äºæ•´ä½“æ€§èƒ½è‡³å…³é‡è¦ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒTUMIX åœ¨å…³é”®æ¨ç†åŸºå‡†æµ‹è¯•ä¸­ä¼˜äºç°æœ‰çš„å·¥å…·å¢å¼ºå’Œæµ‹è¯•æ—¶ç¼©æ”¾(test-time scaling)æ–¹æ³•ï¼Œåœ¨ Gemini-2.5-Pro å’Œ Gemini-2.5-Flash æ¨¡å‹ä¸Šå®ç°äº†å¹³å‡é«˜è¾¾ 3.55% çš„å‡†ç¡®ç‡æå‡ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶æ”¯æŒåœ¨è¾¾åˆ°è¶³å¤Ÿç½®ä¿¡åº¦æ—¶åœæ­¢ä¼˜åŒ–ï¼Œä»è€Œåœ¨ä»…æ¶ˆè€— 49% æ¨ç†æˆæœ¬çš„æƒ…å†µä¸‹ä¿æŒæ€§èƒ½ã€‚è¯¥ç ”ç©¶è¯æ˜äº†è¿›ä¸€æ­¥çš„ç¼©æ”¾å¯ä»¥å®ç°æ›´é«˜çš„æ€§èƒ½ï¼Œä¸ºé«˜æ•ˆåˆ©ç”¨ Code Interpreter å’Œ Search ç­‰å·¥å…·æä¾›äº†æ–°è·¯å¾„ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "27 pages, 13 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.01279v1",
      "published_date": "2025-09-30 19:19:56 UTC",
      "updated_date": "2025-09-30 19:19:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:24:26.803873+00:00"
    },
    {
      "arxiv_id": "2510.00194v1",
      "title": "GRPO-$Î»$: Credit Assignment improves LLM Reasoning",
      "title_zh": "GRPO-$\\lambda$ï¼šä¿¡ç”¨åˆ†é…æå‡å¤§è¯­è¨€æ¨¡å‹æ¨ç†èƒ½åŠ›",
      "authors": [
        "Prasanna Parthasarathi",
        "Mathieu Reymond",
        "Boxing Chen",
        "Yufei Cui",
        "Sarath Chandar"
      ],
      "abstract": "Large language models (LLMs) are increasingly deployed for tasks requiring complex reasoning, prompting significant interest in improving their reasoning abilities through post-training. Especially RL based methods using verifiable reward, like the state-of-the-art GRPO, have shown to tremendously improve reasoning behaviors when applied as post-training methods. However, the lack of an explicit reward or critic model limits GRPO's ability to assign fine-grained credit across token sequences. In this work, we present GRPO-$Î»$, a novel extension to GRPO that enhances credit assignment in RL finetuning of LLMs for complex reasoning tasks. We approximate learning from $Î»$-return with a reformulation of eligibility traces using token-level log-probabilities applied after each sequence generation, and a novel critic-free approximation of the temporal-difference error. We introduce a few variations for the weighting of the $Î»$-return, and their applications to the eligibility-trace, where all the variations provide significant gains over GRPO. We compare GRPO-$Î»$ against GRPO by training models from 1.5B to 7B parameters on $4$ different math reasoning datasets. The training plots demonstrate 30-40% improved performance during RL training on both LLaMA-3.1 and Qwen-2.5 architectures. Finally, we show that with GRPO-$Î»$, the resulting average performance on AIME24, Math500, OlympiadMath, MinervaMath, and AMC improves over GRPO by over $3$ points and a $4.5$ points improvement on the 7B model.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­ç¼ºä¹ç²¾ç»†åŒ–ä¿¡ç”¨åˆ†é…(credit assignment)çš„é—®é¢˜ï¼Œæå‡ºäº†GRPOçš„æ‰©å±•ç‰ˆæœ¬GRPO-Î»ã€‚è¯¥æ–¹æ³•é€šè¿‡å¼•å…¥èµ„æ ¼è¿¹(eligibility traces)çš„é‡æ„ä»¥åŠä¸€ç§åˆ›æ–°çš„æ— è¯„è®ºå®¶(critic-free)æ—¶åºå·®åˆ†è¯¯å·®è¿‘ä¼¼ï¼Œå®ç°äº†å¯¹Î»-å›æŠ¥(Î»-return)çš„é«˜æ•ˆå­¦ä¹ ï¼Œä»è€Œæ˜¾è‘—ä¼˜åŒ–äº†å¼ºåŒ–å­¦ä¹ (RL)è¿‡ç¨‹ä¸­çš„æ ‡è®°(token)çº§ä¿¡ç”¨åˆ†é…ã€‚åœ¨1.5Bè‡³7Bå‚æ•°è§„æ¨¡çš„LLaMA-3.1å’ŒQwen-2.5æ¶æ„ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒGRPO-Î»åœ¨è®­ç»ƒæ•ˆç‡ä¸Šæ¯”åŸå§‹GRPOæå‡äº†30-40%ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•åœ¨AIME24ã€Math500å’ŒOlympiadMathç­‰å¤šä¸ªæ•°å­¦æ¨ç†åŸºå‡†æµ‹è¯•ä¸­å±•ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œå¹³å‡æå‡è¶…è¿‡3ä¸ªç™¾åˆ†ç‚¹ï¼Œè€Œåœ¨7Bæ¨¡å‹ä¸Šæ›´å®ç°äº†4.5åˆ†çš„æ€§èƒ½å¢ç›Šã€‚è¿™é¡¹å·¥ä½œè¯æ˜äº†ç²¾ç»†åŒ–ä¿¡ç”¨åˆ†é…åœ¨æå‡å¤§è¯­è¨€æ¨¡å‹é€»è¾‘æ¨ç†èƒ½åŠ›æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.00194v1",
      "published_date": "2025-09-30 19:11:10 UTC",
      "updated_date": "2025-09-30 19:11:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:25:38.366731+00:00"
    },
    {
      "arxiv_id": "2510.00192v2",
      "title": "PrunedLoRA: Robust Gradient-Based structured pruning for Low-rank Adaptation in Fine-tuning",
      "title_zh": "PrunedLoRAï¼šé¢å‘ä½ç§©è‡ªé€‚åº”å¾®è°ƒçš„é²æ£’æ¢¯åº¦ç»“æ„åŒ–å‰ªæ",
      "authors": [
        "Xin Yu",
        "Cong Xie",
        "Ziyu Zhao",
        "Tiantian Fan",
        "Lingzhou Xue",
        "Zhi Zhang"
      ],
      "abstract": "Low-rank adaptation (LoRA) has become a widely used paradigm for parameter-efficient fine-tuning of large language models, yet its representational capacity often lags behind full fine-tuning. Within the context of LoRA, a key open question is how to obtain expressive low-rank adapters from over-parameterized spaces. We propose \\textit{PrunedLoRA}, a new framework that leverages structured pruning to obtain highly representative low-rank adapters from an over-parameterized initialization. Unlike prior approaches that impose a fixed low-rank budget, PrunedLoRA dynamically prunes less important components during fine-tuning and prevents their reactivation, enabling flexible and adaptive rank allocation. For structured pruning, by minimizing the pruning error for overall loss, we provide fine-grained pruning and recovery updates in a gradient-based pruning strategy with grounded interpretation. We provide the first theoretical analysis of the robustness of structured pruning and provably show that under the impact of weight perturbation, gradient-based pruning is more robust than activation-based pruning with respect to overall loss. Empirically, PrunedLoRA consistently outperforms LoRA and its variants across supervised fine-tuning tasks in mathematical reasoning, code generation, and natural language understanding, and it also demonstrates advantages over existing structured pruning methods across diverse sparsity levels.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä½ç§©è‡ªé€‚åº”(Low-rank adaptation, LoRA)è¡¨ç¤ºèƒ½åŠ›é€šå¸¸è½åäºå…¨é‡å¾®è°ƒçš„é—®é¢˜ï¼Œæå‡ºäº†PrunedLoRAæ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡ç»“æ„åŒ–å‰ªæ(structured pruning)ä»è¶…å‚æ•°åŒ–åˆå§‹åŒ–ä¸­è·å–æ›´å…·è¡¨è¾¾èƒ½åŠ›çš„ä½ç§©é€‚é…å™¨ã€‚ä¸åŒäºé¢„è®¾å›ºå®šç§©é¢„ç®—çš„ä¼ ç»Ÿæ–¹æ³•ï¼ŒPrunedLoRAåœ¨å¾®è°ƒæœŸé—´åŠ¨æ€å‰ªé™¤ä¸é‡è¦çš„ç»„ä»¶å¹¶é˜²æ­¢å…¶é‡æ–°æ¿€æ´»ï¼Œä»è€Œå®ç°äº†çµæ´»ä¸”è‡ªé€‚åº”çš„ç§©åˆ†é…(rank allocation)ã€‚è¯¥æ¡†æ¶é‡‡ç”¨åŸºäºæ¢¯åº¦çš„å‰ªæç­–ç•¥ï¼Œé€šè¿‡æœ€å°åŒ–æ€»æŸå¤±çš„å‰ªæè¯¯å·®æ¥æä¾›ç»†ç²’åº¦çš„æ›´æ–°ä¸æ¢å¤ã€‚ç ”ç©¶è¿˜é¦–æ¬¡å¯¹ç»“æ„åŒ–å‰ªæçš„é²æ£’æ€§è¿›è¡Œäº†ç†è®ºåˆ†æï¼Œè¯æ˜äº†åœ¨æƒé‡æ‰°åŠ¨å½±å“ä¸‹ï¼ŒåŸºäºæ¢¯åº¦çš„å‰ªææ¯”åŸºäºæ¿€æ´»çš„å‰ªæåœ¨ç»´æŒæ€»æŸå¤±æ–¹é¢è¡¨ç°å‡ºæ›´å¼ºçš„é²æ£’æ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒPrunedLoRAåœ¨æ•°å­¦æ¨ç†ã€ä»£ç ç”ŸæˆåŠè‡ªç„¶è¯­è¨€ç†è§£ç­‰ä»»åŠ¡ä¸­è¡¨ç°ä¼˜äºLoRAåŠå…¶å˜ä½“ï¼Œä¸”åœ¨å„ç§ç¨€ç–åº¦ä¸‹å‡ä¼˜äºç°æœ‰çš„ç»“æ„åŒ–å‰ªææ–¹æ³•ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.00192v2",
      "published_date": "2025-09-30 19:10:35 UTC",
      "updated_date": "2025-11-01 04:19:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:25:41.266648+00:00"
    },
    {
      "arxiv_id": "2510.00186v2",
      "title": "Thinkquel: A Model Dedicated to Text-to-dbt Using Synthetic Data and a Span-Aware Objective",
      "title_zh": "Thinkquelï¼šä¸€ç§åŸºäºåˆæˆæ•°æ®ä¸è·¨åº¦æ„ŸçŸ¥ç›®æ ‡çš„ Text-to-dbt ä¸“ç”¨æ¨¡å‹",
      "authors": [
        "Anni Li",
        "Aria Attar",
        "Paul Dong"
      ],
      "abstract": "Transforming natural-language requests into reliable, production-ready data transformations remains challenging: correctness depends on precise schema linking and warehouse-specific SQL dialects, while the strongest supervision available during training--execution success and result matching--are provided only at the sequence level. At the same time, assembling large, execution-validated corpora is costly, and token-level objectives misalign with these global signals, yielding unstable optimization and limited portability. We introduce Thinkquel, a fine-tuned model for producing robust, portable, and execution-validated database queries. Methodologies in Thinkquel integrates a novel synthetic data pipeline, TS-SQL, that leverages dbt as a portable intermediate representation with a span-aware reinforcement learning objective, and Token-Sequence GRPO (TS-GRPO), specifically designed to bridge the gap between token-level training signals and sequence-level execution rewards when finetuning LLMs. On the 500-example TS-SQL test set, Thinkquel (32B) reaches 93.2% execution success and 61.8% exact-result match with a two-stage SFT curriculum, improving over the base model by 67.2% (exec.) and 44.4% (match). In Spider (14B) experiments, TS-GRPO increases training stability and speeds convergence of the execution-match reward relative to GRPO and GSPO.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Thinkquelï¼Œä¸€ä¸ªä¸“é—¨ç”¨äºå°†è‡ªç„¶è¯­è¨€è¯·æ±‚è½¬åŒ–ä¸ºå¯é ã€å¯ç”Ÿäº§çš„æ•°æ®è½¬æ¢ä»»åŠ¡çš„å¾®è°ƒæ¨¡å‹ã€‚é’ˆå¯¹Text-to-dbtä»»åŠ¡ä¸­æ¨¡å¼é“¾æ¥(schema linking)ç²¾ç¡®æ€§è¦æ±‚é«˜ã€SQLæ–¹è¨€å¤æ‚ä»¥åŠè®­ç»ƒä¿¡å·ä¸æ‰§è¡Œå¥–åŠ±å¤±é…ç­‰æŒ‘æˆ˜ï¼Œè¯¥ç ”ç©¶å¼•å…¥äº†åä¸ºTS-SQLçš„åˆæˆæ•°æ®æµæ°´çº¿ï¼Œåˆ©ç”¨dbtä½œä¸ºå¯ç§»æ¤çš„ä¸­é—´è¡¨ç¤ºã€‚åŒæ—¶ï¼Œç ”ç©¶å›¢é˜Ÿè®¾è®¡äº†è·¨åº¦æ„ŸçŸ¥(span-aware)çš„å¼ºåŒ–å­¦ä¹ ç›®æ ‡ï¼Œä»¥åŠä¸“é—¨ä¼˜åŒ–çš„Token-Sequence GRPO (TS-GRPO)ç®—æ³•ï¼Œæ—¨åœ¨æ¡¥æ¥Tokençº§åˆ«çš„è®­ç»ƒä¿¡å·ä¸åºåˆ—çº§åˆ«çš„æ‰§è¡Œå¥–åŠ±ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œ32Bç‰ˆæœ¬çš„Thinkquelåœ¨TS-SQLæµ‹è¯•é›†ä¸Šè¾¾åˆ°äº†93.2%çš„æ‰§è¡ŒæˆåŠŸç‡å’Œ61.8%çš„ç²¾ç¡®åŒ¹é…ç‡ï¼Œç›¸è¾ƒäºåŸºçº¿æ¨¡å‹åˆ†åˆ«æå‡äº†67.2%å’Œ44.4%ã€‚æ­¤å¤–ï¼Œåœ¨Spideræ•°æ®é›†ä¸Šçš„æµ‹è¯•è¯æ˜ï¼ŒTS-GRPOæ¯”ä¼ ç»Ÿçš„GRPOå’ŒGSPOå…·æœ‰æ›´é«˜çš„è®­ç»ƒç¨³å®šæ€§å’Œæ›´å¿«çš„å¥–åŠ±æ”¶æ•›é€Ÿåº¦ã€‚è¯¥å·¥ä½œä¸ºå®ç°å¥å£®ä¸”å…·å¯ç§»æ¤æ€§çš„æ•°æ®åº“æŸ¥è¯¢ç”Ÿæˆæä¾›äº†æœ‰æ•ˆçš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.00186v2",
      "published_date": "2025-09-30 19:04:53 UTC",
      "updated_date": "2025-10-02 18:28:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:25:39.470521+00:00"
    },
    {
      "arxiv_id": "2510.00185v1",
      "title": "Object-Centric Case-Based Reasoning via Argumentation",
      "title_zh": "åŸºäºè®ºè¯çš„ä»¥å¯¹è±¡ä¸ºä¸­å¿ƒçš„æ¡ˆä¾‹æ¨ç†",
      "authors": [
        "Gabriel de Olim Gaul",
        "Adam Gould",
        "Avinash Kori",
        "Francesca Toni"
      ],
      "abstract": "We introduce Slot Attention Argumentation for Case-Based Reasoning (SAA-CBR), a novel neuro-symbolic pipeline for image classification that integrates object-centric learning via a neural Slot Attention (SA) component with symbolic reasoning conducted by Abstract Argumentation for Case-Based Reasoning (AA-CBR). We explore novel integrations of AA-CBR with the neural component, including feature combination strategies, casebase reduction via representative samples, novel count-based partial orders, a One-Vs-Rest strategy for extending AA-CBR to multi-class classification, and an application of Supported AA-CBR, a bipolar variant of AA-CBR. We demonstrate that SAA-CBR is an effective classifier on the CLEVR-Hans datasets, showing competitive performance against baseline models.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼•å…¥äº† Slot Attention Argumentation for Case-Based Reasoning (SAA-CBR)ï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºå›¾åƒåˆ†ç±»çš„æ–°å‹ç¥ç»ç¬¦å·(neuro-symbolic)æµæ°´çº¿ã€‚è¯¥æ¡†æ¶å°†ç”¨äºä»¥å¯¹è±¡ä¸ºä¸­å¿ƒ(object-centric)å­¦ä¹ çš„ç¥ç» Slot Attention (SA) ç»„ä»¶ä¸é€šè¿‡ Abstract Argumentation for Case-Based Reasoning (AA-CBR) è¿›è¡Œçš„ç¬¦å·æ¨ç†ç›¸ç»“åˆã€‚ç ”ç©¶æ·±å…¥æ¢ç´¢äº† AA-CBR ä¸ç¥ç»ç»„ä»¶çš„å¤šç§åˆ›æ–°æ•´åˆæ–¹å¼ï¼ŒåŒ…æ‹¬ç‰¹å¾ç»„åˆç­–ç•¥ã€é€šè¿‡ä»£è¡¨æ€§æ ·æœ¬ç¼©å‡æ¡ˆä¾‹åº“(casebase reduction)ä»¥åŠæ–°å‹çš„åŸºäºè®¡æ•°çš„ååºå…³ç³»(count-based partial orders)ã€‚æ­¤å¤–ï¼Œè¯¥å·¥ä½œè¿˜åˆ©ç”¨ One-Vs-Rest ç­–ç•¥å°† AA-CBR æ‰©å±•åˆ°å¤šåˆ†ç±»ä»»åŠ¡ï¼Œå¹¶åº”ç”¨äº† Supported AA-CBR è¿™ä¸€åŒæå˜ä½“ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSAA-CBR åœ¨ CLEVR-Hans æ•°æ®é›†ä¸Šè¡¨ç°å‡ºè‰²ï¼Œå±•ç°å‡ºä¸åŸºçº¿æ¨¡å‹ç›¸æ¯”æå…·ç«äº‰åŠ›çš„åˆ†ç±»æ€§èƒ½ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to ArgXAI@ECAI25",
      "pdf_url": "https://arxiv.org/pdf/2510.00185v1",
      "published_date": "2025-09-30 19:04:27 UTC",
      "updated_date": "2025-09-30 19:04:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:25:49.860584+00:00"
    },
    {
      "arxiv_id": "2510.00184v1",
      "title": "Why Can't Transformers Learn Multiplication? Reverse-Engineering Reveals Long-Range Dependency Pitfalls",
      "title_zh": "Transformer ä¸ºä»€ä¹ˆå­¦ä¸ä¼šä¹˜æ³•ï¼Ÿé€†å‘å·¥ç¨‹æ­ç¤ºé•¿ç¨‹ä¾èµ–é™·é˜±",
      "authors": [
        "Xiaoyan Bai",
        "Itamar Pres",
        "Yuntian Deng",
        "Chenhao Tan",
        "Stuart Shieber",
        "Fernanda ViÃ©gas",
        "Martin Wattenberg",
        "Andrew Lee"
      ],
      "abstract": "Language models are increasingly capable, yet still fail at a seemingly simple task of multi-digit multiplication. In this work, we study why, by reverse-engineering a model that successfully learns multiplication via \\emph{implicit chain-of-thought}, and report three findings: (1) Evidence of long-range structure: Logit attributions and linear probes indicate that the model encodes the necessary long-range dependencies for multi-digit multiplication. (2) Mechanism: the model encodes long-range dependencies using attention to construct a directed acyclic graph to ``cache'' and ``retrieve'' pairwise partial products. (3) Geometry: the model implements partial products in attention heads by forming Minkowski sums between pairs of digits, and digits are represented using a Fourier basis, both of which are intuitive and efficient representations that the standard fine-tuning model lacks. With these insights, we revisit the learning dynamics of standard fine-tuning and find that the model converges to a local optimum that lacks the required long-range dependencies. We further validate this understanding by introducing an auxiliary loss that predicts the ``running sum'' via a linear regression probe, which provides an inductive bias that enables the model to successfully learn multi-digit multiplication. In summary, by reverse-engineering the mechanisms of an implicit chain-of-thought model we uncover a pitfall for learning long-range dependencies in Transformers and provide an example of how the correct inductive bias can address this issue.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº† Transformer æ¨¡å‹åœ¨å¤„ç†å¤šä½æ•°ä¹˜æ³• (multi-digit multiplication) æ—¶é¢ä¸´çš„æŒ‘æˆ˜ï¼Œå¹¶é€šè¿‡é€†å‘å·¥ç¨‹ (reverse-engineering) ä¸€ä¸ªåˆ©ç”¨éšå¼é“¾å¼æ€ç»´ (implicit chain-of-thought) æˆåŠŸå­¦ä¹ è¯¥ä»»åŠ¡çš„æ¨¡å‹æ­ç¤ºäº†å…¶å†…éƒ¨æœºåˆ¶ã€‚ç ”ç©¶å‘ç°ï¼Œæ¨¡å‹é€šè¿‡æ³¨æ„åŠ›æœºåˆ¶ (attention) æ„å»ºæœ‰å‘æ— ç¯å›¾æ¥ç¼“å­˜ (cache) å’Œæ£€ç´¢ (retrieve) éƒ¨åˆ†ä¹˜ç§¯ï¼Œå¹¶åˆ©ç”¨é—µå¯å¤«æ–¯åŸºå’Œ (Minkowski sums) ä¸å‚…é‡Œå¶åŸº (Fourier basis) è¿›è¡Œé«˜æ•ˆçš„å‡ ä½•è¡¨å¾ã€‚åˆ†ææŒ‡å‡ºï¼Œæ ‡å‡†å¾®è°ƒ (standard fine-tuning) å¤±è´¥çš„åŸå› åœ¨äºæ¨¡å‹å®¹æ˜“æ”¶æ•›è‡³ç¼ºä¹é•¿ç¨‹ä¾èµ– (long-range dependencies) çš„å±€éƒ¨æœ€ä¼˜è§£ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œç ”ç©¶è€…å¼•å…¥äº†ä¸€ä¸ªé¢„æµ‹è¿è¡Œæ€»å’Œ (running sum) çš„è¾…åŠ©æŸå¤± (auxiliary loss) ä½œä¸ºå½’çº³åç½® (inductive bias)ï¼Œä»è€Œä½¿æ¨¡å‹èƒ½å¤ŸæˆåŠŸæŒæ¡å¤šä½æ•°ä¹˜æ³•ã€‚è¿™é¡¹å·¥ä½œä¸ä»…æ­ç¤ºäº† Transformer åœ¨å­¦ä¹ é•¿ç¨‹ä¾èµ–æ–¹é¢çš„æ½œåœ¨é™·é˜±ï¼Œè¿˜è¯æ˜äº†åˆç†çš„å½’çº³åç½®å¯¹äºæå‡æ¨¡å‹å¤æ‚æ¨ç†èƒ½åŠ›çš„é‡è¦æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.00184v1",
      "published_date": "2025-09-30 19:03:26 UTC",
      "updated_date": "2025-09-30 19:03:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:25:48.180084+00:00"
    },
    {
      "arxiv_id": "2510.00182v1",
      "title": "A Systematic Study of Large Language Models for Task and Motion Planning With PDDLStream",
      "title_zh": "åŸºäº PDDLStream çš„å¤§è¯­è¨€æ¨¡å‹åœ¨ä»»åŠ¡ä¸è¿åŠ¨è§„åˆ’ä¸­çš„ç³»ç»Ÿæ€§ç ”ç©¶",
      "authors": [
        "Jorge Mendez-Mendez"
      ],
      "abstract": "Using large language models (LLMs) to solve complex robotics problems requires understanding their planning capabilities. Yet while we know that LLMs can plan on some problems, the extent to which these planning capabilities cover the space of robotics tasks is unclear. One promising direction is to integrate the semantic knowledge of LLMs with the formal reasoning of task and motion planning (TAMP). However, the myriad of choices for how to integrate LLMs within TAMP complicates the design of such systems. We develop 16 algorithms that use Gemini 2.5 Flash to substitute key TAMP components. Our zero-shot experiments across 4,950 problems and three domains reveal that the Gemini-based planners exhibit lower success rates and higher planning times than their engineered counterparts. We show that providing geometric details increases the number of task-planning errors compared to pure PDDL descriptions, and that (faster) non-reasoning LLM variants outperform (slower) reasoning variants in most cases, since the TAMP system can direct the LLM to correct its mistakes.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¤æ‚æœºå™¨äººä»»åŠ¡ä¸­çš„è§„åˆ’èƒ½åŠ›ï¼Œç³»ç»Ÿåœ°æ¢è®¨äº†å°† LLMs çš„è¯­ä¹‰çŸ¥è¯†ä¸ PDDLStream çš„å½¢å¼åŒ–ä»»åŠ¡å’Œè¿åŠ¨è§„åˆ’(TAMP)ç›¸ç»“åˆçš„æ½œåŠ›ã€‚ç ”ç©¶å›¢é˜Ÿå¼€å‘äº†16ç§ç®—æ³•ï¼Œåˆ©ç”¨ Gemini 2.5 Flash æ›¿ä»£ TAMP ç³»ç»Ÿä¸­çš„å…³é”®ç»„ä»¶ï¼Œå¹¶åœ¨3ä¸ªé¢†åŸŸã€4,950ä¸ªé—®é¢˜ä¸Šè¿›è¡Œäº†é›¶æ ·æœ¬(zero-shot)å®éªŒã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸ä¼ ç»Ÿçš„å·¥ç¨‹åŒ–è§„åˆ’å™¨ç›¸æ¯”ï¼ŒåŸºäº Gemini çš„è§„åˆ’å™¨åœ¨æˆåŠŸç‡å’Œè§„åˆ’è€—æ—¶æ–¹é¢è¡¨ç°å‡è¾ƒå·®ã€‚ç ”ç©¶å‘ç°ï¼Œç›¸è¾ƒäºçº¯ PDDL æè¿°ï¼Œå‘æ¨¡å‹æä¾›å‡ ä½•ç»†èŠ‚åè€Œä¼šå¢åŠ ä»»åŠ¡è§„åˆ’çš„é”™è¯¯ç‡ã€‚æ­¤å¤–ï¼Œåœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œéæ¨ç†å‹çš„ LLM å˜ä½“è¡¨ç°ä¼˜äºæ¨ç†å‹å˜ä½“ï¼Œå› ä¸º TAMP ç³»ç»Ÿèƒ½å¤Ÿå¼•å¯¼æ¨¡å‹çº æ­£é”™è¯¯ï¼Œä»è€Œå®ç°æ›´é«˜çš„æ•ˆç‡ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.00182v1",
      "published_date": "2025-09-30 19:03:14 UTC",
      "updated_date": "2025-09-30 19:03:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:25:53.770621+00:00"
    },
    {
      "arxiv_id": "2510.00181v1",
      "title": "CHAI: Command Hijacking against embodied AI",
      "title_zh": "CHAIï¼šé’ˆå¯¹å…·èº«æ™ºèƒ½çš„æŒ‡ä»¤åŠ«æŒ",
      "authors": [
        "Luis Burbano",
        "Diego Ortiz",
        "Qi Sun",
        "Siwei Yang",
        "Haoqin Tu",
        "Cihang Xie",
        "Yinzhi Cao",
        "Alvaro A Cardenas"
      ],
      "abstract": "Embodied Artificial Intelligence (AI) promises to handle edge cases in robotic vehicle systems where data is scarce by using common-sense reasoning grounded in perception and action to generalize beyond training distributions and adapt to novel real-world situations. These capabilities, however, also create new security risks. In this paper, we introduce CHAI (Command Hijacking against embodied AI), a new class of prompt-based attacks that exploit the multimodal language interpretation abilities of Large Visual-Language Models (LVLMs). CHAI embeds deceptive natural language instructions, such as misleading signs, in visual input, systematically searches the token space, builds a dictionary of prompts, and guides an attacker model to generate Visual Attack Prompts. We evaluate CHAI on four LVLM agents; drone emergency landing, autonomous driving, and aerial object tracking, and on a real robotic vehicle. Our experiments show that CHAI consistently outperforms state-of-the-art attacks. By exploiting the semantic and multimodal reasoning strengths of next-generation embodied AI systems, CHAI underscores the urgent need for defenses that extend beyond traditional adversarial robustness.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶ä»‹ç»äº†CHAIï¼Œä¸€ç§é’ˆå¯¹å…·èº«äººå·¥æ™ºèƒ½(Embodied AI)çš„æ–°å‹æŒ‡ä»¤åŠ«æŒæ”»å‡»ï¼Œæ—¨åœ¨æ­ç¤ºå¤§è§†è§‰è¯­è¨€æ¨¡å‹(LVLMs)åœ¨å¤šæ¨¡æ€ç†è§£ä¸­çš„å®‰å…¨é£é™©ã€‚CHAIåˆ©ç”¨LVLMsçš„è¯­ä¹‰æ¨ç†èƒ½åŠ›ï¼Œé€šè¿‡åœ¨è§†è§‰è¾“å…¥ä¸­åµŒå…¥è¯¯å¯¼æ€§æ ‡å¿—ç­‰è‡ªç„¶è¯­è¨€æŒ‡ä»¤ï¼Œç»“åˆæ ‡è®°ç©ºé—´æœç´¢å’Œæç¤ºè¯å­—å…¸æ„å»ºï¼Œå¼•å¯¼æ”»å‡»è€…æ¨¡å‹ç”Ÿæˆè§†è§‰æ”»å‡»æç¤º(Visual Attack Prompts)ã€‚ç ”ç©¶åœ¨æ— äººæœºç´§æ€¥ç€é™†ã€è‡ªåŠ¨é©¾é©¶å’Œç©ºä¸­ç›®æ ‡è·Ÿè¸ªç­‰å››ä¸ªLVLMæ™ºèƒ½ä½“ä»¥åŠçœŸå®æœºå™¨äººè½¦è¾†ä¸Šè¿›è¡Œäº†å¹¿æ³›è¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCHAIçš„æ”»å‡»æ•ˆæœä¸€è‡´ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚è¯¥å·¥ä½œå¼ºè°ƒäº†å…·èº«AIç³»ç»Ÿåœ¨è¯­ä¹‰å’Œå¤šæ¨¡æ€æ¨ç†å±‚é¢çš„è„†å¼±æ€§ï¼Œå¹¶æŒ‡å‡ºè¿«åˆ‡éœ€è¦å¼€å‘è¶…è¶Šä¼ ç»Ÿå¯¹æŠ—é²æ£’æ€§(adversarial robustness)çš„æ–°å‹é˜²å¾¡æœºåˆ¶ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.00181v1",
      "published_date": "2025-09-30 19:02:57 UTC",
      "updated_date": "2025-09-30 19:02:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:25:54.863394+00:00"
    },
    {
      "arxiv_id": "2510.03306v1",
      "title": "Atlas-free Brain Network Transformer",
      "title_zh": "æ— å›¾è°±è„‘ç½‘ç»œ Transformer",
      "authors": [
        "Shuai Huang",
        "Xuan Kan",
        "James J. Lah",
        "Deqiang Qiu"
      ],
      "abstract": "Current atlas-based approaches to brain network analysis rely heavily on standardized anatomical or connectivity-driven brain atlases. However, these fixed atlases often introduce significant limitations, such as spatial misalignment across individuals, functional heterogeneity within predefined regions, and atlas-selection biases, collectively undermining the reliability and interpretability of the derived brain networks. To address these challenges, we propose a novel atlas-free brain network transformer (atlas-free BNT) that leverages individualized brain parcellations derived directly from subject-specific resting-state fMRI data. Our approach computes ROI-to-voxel connectivity features in a standardized voxel-based feature space, which are subsequently processed using the BNT architecture to produce comparable subject-level embeddings. Experimental evaluations on sex classification and brain-connectome age prediction tasks demonstrate that our atlas-free BNT consistently outperforms state-of-the-art atlas-based methods, including elastic net, BrainGNN, Graphormer and the original BNT. Our atlas-free approach significantly improves the precision, robustness, and generalizability of brain network analyses. This advancement holds great potential to enhance neuroimaging biomarkers and clinical diagnostic tools for personalized precision medicine.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Atlas-free Brain Network Transformer (atlas-free BNT)ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»ŸåŸºäºå›¾è°± (atlas-based) çš„æ–¹æ³•åœ¨è„‘ç½‘ç»œåˆ†æä¸­å› ç©ºé—´å¤±é…ã€åŠŸèƒ½å¼‚è´¨æ€§å’Œå›¾è°±é€‰æ‹©åå·®è€Œå¯¼è‡´çš„å¯é æ€§ä¸å¯è§£é‡Šæ€§å±€é™ã€‚è¯¥æ–¹æ³•é€šè¿‡ä»å—è¯•è€…ç‰¹å¼‚æ€§çš„é™æ¯æ€ fMRI (resting-state fMRI) æ•°æ®ä¸­ç›´æ¥å¯¼å‡ºä¸ªä½“åŒ–çš„å¤§è„‘åˆ†åŒºï¼Œæ‘†è„±äº†å¯¹å›ºå®šæ ‡å‡†å›¾è°±çš„ä¾èµ–ã€‚å…¶æ ¸å¿ƒè¿‡ç¨‹æ˜¯åœ¨æ ‡å‡†åŒ–çš„åŸºäºä½“ç´ çš„ç‰¹å¾ç©ºé—´ (voxel-based feature space) ä¸­è®¡ç®— ROI-to-voxel çš„è¿æ¥ç‰¹å¾ï¼Œå¹¶åˆ©ç”¨ BNT æ¶æ„ç”Ÿæˆå…·æœ‰å¯æ¯”æ€§çš„å—è¯•è€…çº§åµŒå…¥ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨æ€§åˆ«åˆ†ç±»å’Œå¤§è„‘è¿æ¥ç»„å¹´é¾„é¢„æµ‹ (brain-connectome age prediction) ä»»åŠ¡ä¸­ï¼Œè¯¥æ¨¡å‹æ€§èƒ½æ˜¾è‘—ä¼˜äº Elastic Netã€BrainGNNã€Graphormer ä»¥åŠåŸå§‹ BNT ç­‰å…ˆè¿›æ–¹æ³•ã€‚è¯¥ç ”ç©¶æ˜¾è‘—å¢å¼ºäº†è„‘ç½‘ç»œåˆ†æçš„ç²¾åº¦ã€é²æ£’æ€§ä¸æ³›åŒ–èƒ½åŠ›ï¼Œä¸ºä¸ªæ€§åŒ–ç²¾å‡†åŒ»å­¦ä¸­çš„ç¥ç»å½±åƒç”Ÿç‰©æ ‡å¿—ç‰©å’Œä¸´åºŠè¯Šæ–­å·¥å…·æä¾›äº†é‡è¦çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.LG",
        "cs.NE",
        "eess.IV"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.03306v1",
      "published_date": "2025-09-30 18:57:02 UTC",
      "updated_date": "2025-09-30 18:57:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:25:57.196229+00:00"
    },
    {
      "arxiv_id": "2510.00177v1",
      "title": "Personalized Reasoning: Just-In-Time Personalization and Why LLMs Fail At It",
      "title_zh": "ä¸ªæ€§åŒ–æ¨ç†ï¼šå³æ—¶ä¸ªæ€§åŒ–åŠå¤§è¯­è¨€æ¨¡å‹å¤±æ•ˆåŸå› æ¢ç©¶",
      "authors": [
        "Shuyue Stella Li",
        "Avinandan Bose",
        "Faeze Brahman",
        "Simon Shaolei Du",
        "Pang Wei Koh",
        "Maryam Fazel",
        "Yulia Tsvetkov"
      ],
      "abstract": "Current large language model (LLM) development treats task-solving and preference alignment as separate challenges, optimizing first for objective correctness, then for alignment to aggregated human preferences. This paradigm fails in human-facing applications where solving a problem correctly is insufficient if the response mismatches the user's needs. This challenge intensifies in just-in-time scenarios where no prior user interaction history exists due to cold-start conditions or privacy constraints. LLMs need to identify what they don't know about user preferences, strategically elicit preference values through questioning, then adapt their reasoning processes and responses accordingly -- a complicated chain of cognitive processes which we term personalized reasoning. We introduce PREFDISCO, an evaluation methodology that transforms static benchmarks into interactive personalization tasks using psychologically-grounded personas with sparse preferences. Our framework creates scenarios where identical questions require different reasoning chains depending on user context, as optimal explanation approaches vary by individual expertise and preferences while maintaining factual accuracy. Evaluation of 21 frontier models across 10 tasks reveals 29.0% of naive personalization attempts produce worse preference alignment than generic responses, yet generic responses also fail to serve individual user needs effectively. These findings suggest personalized reasoning requires dedicated development rather than emerging naturally. PREFDISCO establishes personalized reasoning as a measurable research frontier and reveals fundamental limitations in current LLMs' interactive capabilities, providing a foundation for developing systems that can adapt to individual users in education, healthcare, and technical domains where personalization is critical.",
      "tldr_zh": "è¯¥ç ”ç©¶æŒ‡å‡ºå½“å‰çš„å¤§è¯­è¨€æ¨¡å‹(LLMs)å¼€å‘å°†ä»»åŠ¡è§£å†³ä¸åå¥½å¯¹é½è§†ä¸ºç‹¬ç«‹æŒ‘æˆ˜ï¼Œå¯¼è‡´æ¨¡å‹åœ¨ç¼ºä¹äº¤äº’å†å²çš„å³æ—¶(just-in-time)åœºæ™¯ä¸‹éš¾ä»¥æ»¡è¶³ç”¨æˆ·ç‰¹å®šéœ€æ±‚ã€‚ä½œè€…æå‡ºäº†ä¸ªæ€§åŒ–æ¨ç†(personalized reasoning)çš„æ¦‚å¿µï¼Œè¦æ±‚æ¨¡å‹èƒ½å¤Ÿä¸»åŠ¨è¯†åˆ«æœªçŸ¥çš„ç”¨æˆ·åå¥½å¹¶ç­–ç•¥æ€§åœ°é€šè¿‡æé—®å¼•å¯¼ï¼Œè¿›è€Œè°ƒæ•´å…¶æ¨ç†è¿‡ç¨‹ã€‚ä¸ºäº†è¯„ä¼°è¿™ä¸€èƒ½åŠ›ï¼Œç ”ç©¶å¼•å…¥äº†PREFDISCOè¯„ä¼°æ¡†æ¶ï¼Œåˆ©ç”¨åŸºäºå¿ƒç†å­¦çš„ç”»åƒ(personas)å°†é™æ€åŸºå‡†è½¬åŒ–ä¸ºäº¤äº’å¼ä¸ªæ€§åŒ–ä»»åŠ¡ã€‚å¯¹21ä¸ªå‰æ²¿æ¨¡å‹çš„è¯„ä¼°æ˜¾ç¤ºï¼Œ29.0%çš„åˆæ­¥ä¸ªæ€§åŒ–å°è¯•åœ¨åå¥½å¯¹é½ä¸Šç”šè‡³ä¸å¦‚é€šç”¨å“åº”ï¼Œè€Œé€šç”¨å“åº”æœ¬èº«ä¹Ÿæ— æ³•æœ‰æ•ˆæœåŠ¡ä¸ªä½“éœ€æ±‚ã€‚è¯¥ç ”ç©¶ç¡®ç«‹äº†ä¸ªæ€§åŒ–æ¨ç†ä½œä¸ºä¸€ä¸ªå¯è¡¡é‡çš„ç ”ç©¶å‰æ²¿ï¼Œæ­ç¤ºäº†å½“å‰æ¨¡å‹åœ¨äº¤äº’èƒ½åŠ›ä¸Šçš„åŸºæœ¬å±€é™ï¼Œå¹¶ä¸ºæ•™è‚²ã€åŒ»ç–—å’ŒæŠ€æœ¯é¢†åŸŸçš„ä¸ªæ€§åŒ–ç³»ç»Ÿå¼€å‘å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "57 pages, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.00177v1",
      "published_date": "2025-09-30 18:55:28 UTC",
      "updated_date": "2025-09-30 18:55:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:26:10.140780+00:00"
    },
    {
      "arxiv_id": "2510.00167v1",
      "title": "Drones that Think on their Feet: Sudden Landing Decisions with Embodied AI",
      "title_zh": "ä¸´æœºåº”å˜çš„æ— äººæœºï¼šåŸºäºå…·èº«æ™ºèƒ½çš„çªå‘é™è½å†³ç­–",
      "authors": [
        "Diego Ortiz Barbosa",
        "Mohit Agrawal",
        "Yash Malegaonkar",
        "Luis Burbano",
        "Axel Andersson",
        "GyÃ¶rgy DÃ¡n",
        "Henrik Sandberg",
        "Alvaro A. Cardenas"
      ],
      "abstract": "Autonomous drones must often respond to sudden events, such as alarms, faults, or unexpected changes in their environment, that require immediate and adaptive decision-making. Traditional approaches rely on safety engineers hand-coding large sets of recovery rules, but this strategy cannot anticipate the vast range of real-world contingencies and quickly becomes incomplete. Recent advances in embodied AI, powered by large visual language models, provide commonsense reasoning to assess context and generate appropriate actions in real time. We demonstrate this capability in a simulated urban benchmark in the Unreal Engine, where drones dynamically interpret their surroundings and decide on sudden maneuvers for safe landings. Our results show that embodied AI makes possible a new class of adaptive recovery and decision-making pipelines that were previously infeasible to design by hand, advancing resilience and safety in autonomous aerial systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è‡ªä¸»æ— äººæœºåœ¨é¢ä¸´è­¦æŠ¥ã€æ•…éšœæˆ–ç¯å¢ƒçªå˜ç­‰ç´§æ€¥æƒ…å†µæ—¶ï¼Œä¼ ç»Ÿäººå·¥é¢„è®¾æ¢å¤è§„åˆ™éš¾ä»¥è¦†ç›–å¹¿æ³›ç°å®å¶å‘äº‹ä»¶ä¸”ç¼ºä¹é€‚åº”æ€§çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºå…·èº«æ™ºèƒ½(Embodied AI)çš„å†³ç­–æ¡†æ¶ã€‚è¯¥æ¡†æ¶åˆ©ç”¨å¤§è§†è§‰è¯­è¨€æ¨¡å‹(Large Visual Language Models)æä¾›çš„å¸¸è¯†æ¨ç†èƒ½åŠ›ï¼Œä½¿æ— äººæœºèƒ½å¤Ÿå®æ—¶è¯„ä¼°ç¯å¢ƒä¸Šä¸‹æ–‡å¹¶ç”Ÿæˆé€‚å½“çš„åº”å¯¹åŠ¨ä½œã€‚é€šè¿‡åœ¨Unreal Engineæ¨¡æ‹ŸåŸå¸‚åŸºå‡†ç¯å¢ƒä¸­çš„å®éªŒéªŒè¯ï¼Œæ— äººæœºå±•ç°äº†åŠ¨æ€è§£è¯»ç¯å¢ƒå¹¶æ‰§è¡Œç´§æ€¥å®‰å…¨ç€é™†å†³ç­–çš„èƒ½åŠ›ã€‚ç»“æœè¯æ˜ï¼Œå…·èº«æ™ºèƒ½(Embodied AI)èƒ½å¤Ÿå®ç°ä¼ ç»Ÿæ‰‹å·¥è®¾è®¡æ— æ³•ä¼åŠçš„è‡ªé€‚åº”æ¢å¤å’Œå†³ç­–æµæ°´çº¿ï¼Œæ˜¾è‘—å¢å¼ºäº†è‡ªä¸»é£è¡Œç³»ç»Ÿçš„éŸ§æ€§ä¸å®‰å…¨æ€§ã€‚è¿™ä¸€è¿›å±•ä¸ºæ„å»ºå…·å¤‡å®æ—¶é€‚åº”èƒ½åŠ›çš„å¤æ‚è‡ªä¸»ç©ºä¸­ç³»ç»Ÿæä¾›äº†æ–°çš„è·¯å¾„ã€‚",
      "categories": [
        "cs.AI",
        "cs.CR",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.00167v1",
      "published_date": "2025-09-30 18:39:36 UTC",
      "updated_date": "2025-09-30 18:39:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:26:05.293422+00:00"
    },
    {
      "arxiv_id": "2510.00165v1",
      "title": "Privacy-Preserving Learning-Augmented Data Structures",
      "title_zh": "éšç§ä¿æŠ¤çš„å­¦ä¹ å¢å¼ºå‹æ•°æ®ç»“æ„",
      "authors": [
        "Prabhav Goyal",
        "Vinesh Sridhar",
        "Wilson Zheng"
      ],
      "abstract": "Learning-augmented data structures use predicted frequency estimates to retrieve frequently occurring database elements faster than standard data structures. Recent work has developed data structures that optimally exploit these frequency estimates while maintaining robustness to adversarial prediction errors. However, the privacy and security implications of this setting remain largely unexplored.\n  In the event of a security breach, data structures should reveal minimal information beyond their current contents. This is even more crucial for learning-augmented data structures, whose layout adapts to the data. A data structure is history independent if its memory representation reveals no information about past operations except what is inferred from its current contents. In this work, we take the first step towards privacy and security guarantees in this setting by proposing the first learning-augmented data structure that is strongly history independent, robust, and supports dynamic updates.\n  To achieve this, we introduce two techniques: thresholding, which automatically makes any learning-augmented data structure robust, and pairing, a simple technique that provides strong history independence in the dynamic setting. Our experimental results demonstrate a tradeoff between security and efficiency but are still competitive with the state of the art.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†é¦–ä¸ªå…·æœ‰å¼ºå†å²ç‹¬ç«‹æ€§ (strongly history independent)ã€é²æ£’æ€§ä¸”æ”¯æŒåŠ¨æ€æ›´æ–°çš„æœºå™¨å­¦ä¹ å¢å¼ºå‹æ•°æ®ç»“æ„ (learning-augmented data structures)ï¼Œæ—¨åœ¨è§£å†³æ­¤ç±»ç»“æ„åœ¨æ ¹æ®æ•°æ®åˆ†å¸ƒè¿›è¡Œå¸ƒå±€è°ƒæ•´æ—¶å¯èƒ½æ³„éœ²æ“ä½œå†å²çš„éšç§é£é™©ã€‚ä¸ºäº†å®ç°è¿™ä¸€ç›®æ ‡ï¼Œä½œè€…å¼•å…¥äº†é˜ˆå€¼åŒ– (thresholding) å’Œé…å¯¹ (pairing) ä¸¤ç§æ ¸å¿ƒæŠ€æœ¯ï¼Œå‰è€…èƒ½å¤Ÿè‡ªåŠ¨æå‡æ•°æ®ç»“æ„çš„é²æ£’æ€§ä»¥åº”å¯¹é¢„æµ‹è¯¯å·®ï¼Œåè€…åˆ™åœ¨åŠ¨æ€ç¯å¢ƒä¸‹æä¾›äº†å¯é çš„å¼ºå†å²ç‹¬ç«‹æ€§ä¿è¯ã€‚è¯¥è®¾è®¡ç¡®ä¿äº†æ•°æ®ç»“æ„çš„å†…å­˜è¡¨ç¤ºä¸ä¼šæ³„éœ²é™¤å½“å‰å†…å®¹ä»¥å¤–çš„ä»»ä½•å†å²æ“ä½œä¿¡æ¯ï¼Œä»è€Œåœ¨å®‰å…¨æ¼æ´å‘ç”Ÿæ—¶æœ€å¤§é™åº¦åœ°ä¿æŠ¤æ•°æ®éšç§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå°½ç®¡åœ¨å®‰å…¨æ€§å’Œæ•ˆç‡ä¹‹é—´å­˜åœ¨ä¸€å®šçš„æƒè¡¡ï¼Œè¯¥æ–¹æ¡ˆåœ¨æ€§èƒ½è¡¨ç°ä¸Šä¾ç„¶ä¸å½“å‰æœ€å…ˆè¿›çš„æŠ€æœ¯ (state of the art) ä¿æŒç«äº‰ä¼˜åŠ¿ã€‚è¿™é¡¹å·¥ä½œä¸ºåœ¨è‡ªé€‚åº”æ•°æ®ç»“æ„ä¸­å®ç°éšç§ä¸å®‰å…¨ä¿éšœå¥ å®šäº†é‡è¦çš„ç†è®ºä¸å®è·µåŸºç¡€ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.DS"
      ],
      "primary_category": "cs.IR",
      "comment": "6 pages, 2 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.00165v1",
      "published_date": "2025-09-30 18:37:39 UTC",
      "updated_date": "2025-09-30 18:37:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:26:22.492927+00:00"
    },
    {
      "arxiv_id": "2510.00163v1",
      "title": "Partial Identification Approach to Counterfactual Fairness Assessment",
      "title_zh": "åäº‹å®å…¬å¹³æ€§è¯„ä¼°çš„éƒ¨åˆ†è¯†åˆ«æ–¹æ³•",
      "authors": [
        "Saeyoung Rho",
        "Junzhe Zhang",
        "Elias Bareinboim"
      ],
      "abstract": "The wide adoption of AI decision-making systems in critical domains such as criminal justice, loan approval, and hiring processes has heightened concerns about algorithmic fairness. As we often only have access to the output of algorithms without insights into their internal mechanisms, it was natural to examine how decisions would alter when auxiliary sensitive attributes (such as race) change. This led the research community to come up with counterfactual fairness measures, but how to evaluate the measure from available data remains a challenging task. In many practical applications, the target counterfactual measure is not identifiable, i.e., it cannot be uniquely determined from the combination of quantitative data and qualitative knowledge. This paper addresses this challenge using partial identification, which derives informative bounds over counterfactual fairness measures from observational data. We introduce a Bayesian approach to bound unknown counterfactual fairness measures with high confidence. We demonstrate our algorithm on the COMPAS dataset, examining fairness in recidivism risk scores with respect to race, age, and sex. Our results reveal a positive (spurious) effect on the COMPAS score when changing race to African-American (from all others) and a negative (direct causal) effect when transitioning from young to old age.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹äººå·¥æ™ºèƒ½å†³ç­–ç³»ç»Ÿåœ¨å…³é”®é¢†åŸŸå¼•å‘çš„ç®—æ³•å…¬å¹³æ€§æ‹…å¿§ï¼Œæå‡ºäº†ä¸€ç§åŸºäº Partial Identificationï¼ˆéƒ¨åˆ†è¯†åˆ«ï¼‰çš„æ–¹æ³•æ¥è¯„ä¼° Counterfactual Fairnessï¼ˆåäº‹å®å…¬å¹³æ€§ï¼‰ã€‚ç”±äºåœ¨å®é™…åº”ç”¨ä¸­ï¼Œåäº‹å®è¡¡é‡æŒ‡æ ‡å¾€å¾€å› æ•°æ®å’Œå®šæ€§çŸ¥è¯†çš„å±€é™è€Œæ— æ³•è¢«å”¯ä¸€ç¡®å®šï¼Œå³é¢ä¸´ Identifiabilityï¼ˆå¯è¯†åˆ«æ€§ï¼‰éš¾é¢˜ï¼Œæœ¬æ–‡é€šè¿‡ä»è§‚æµ‹æ•°æ®ä¸­æ¨å¯¼å‡ºä¿¡æ¯è¾¹ç•Œæ¥è§£å†³è¿™ä¸€æŒ‘æˆ˜ã€‚ç ”ç©¶å¼•å…¥äº†ä¸€ç§ Bayesianï¼ˆè´å¶æ–¯ï¼‰æ–¹æ³•ï¼Œæ—¨åœ¨ä»¥é«˜ç½®ä¿¡åº¦é™å®šæœªçŸ¥çš„å…¬å¹³æ€§æµ‹é‡å€¼ã€‚é€šè¿‡åœ¨ COMPAS æ•°æ®é›†ä¸Šå¯¹å†çŠ¯é£é™©è¯„åˆ†è¿›è¡Œå®éªŒï¼Œç ”ç©¶åˆ†æäº† raceï¼ˆç§æ—ï¼‰ã€ageï¼ˆå¹´é¾„ï¼‰å’Œ sexï¼ˆæ€§åˆ«ï¼‰å¯¹å…¬å¹³æ€§çš„å½±å“ã€‚ç»“æœè¡¨æ˜ï¼Œå½“ç§æ—å˜æ›´ä¸º African-American æ—¶ï¼Œè¯„åˆ†è¡¨ç°å‡ºæ­£å‘çš„ä¼ªæ•ˆåº”ï¼Œè€Œä»é’å¹´åˆ°è€å¹´çš„è½¬å˜åˆ™å‘ˆç°å‡ºè´Ÿå‘çš„ç›´æ¥å› æœæ•ˆåº”ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.00163v1",
      "published_date": "2025-09-30 18:35:08 UTC",
      "updated_date": "2025-09-30 18:35:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:26:26.587771+00:00"
    },
    {
      "arxiv_id": "2510.00156v1",
      "title": "AuditAgent: Expert-Guided Multi-Agent Reasoning for Cross-Document Fraudulent Evidence Discovery",
      "title_zh": "AuditAgentï¼šé¢å‘è·¨æ–‡æ¡£æ¬ºè¯ˆè¯æ®å‘ç°çš„ä¸“å®¶å¼•å¯¼å¤šæ™ºèƒ½ä½“æ¨ç†",
      "authors": [
        "Songran Bai",
        "Bingzhe Wu",
        "Yiwei Zhang",
        "Chengke Wu",
        "Xiaolong Zheng",
        "Yaze Yuan",
        "Ke Wu",
        "Jianqiang Li"
      ],
      "abstract": "Financial fraud detection in real-world scenarios presents significant challenges due to the subtlety and dispersion of evidence across complex, multi-year financial disclosures. In this work, we introduce a novel multi-agent reasoning framework AuditAgent, enhanced with auditing domain expertise, for fine-grained evidence chain localization in financial fraud cases. Leveraging an expert-annotated dataset constructed from enforcement documents and financial reports released by the China Securities Regulatory Commission, our approach integrates subject-level risk priors, a hybrid retrieval strategy, and specialized agent modules to efficiently identify and aggregate cross-report evidence. Extensive experiments demonstrate that our method substantially outperforms General-Purpose Agent paradigm in both recall and interpretability, establishing a new benchmark for automated, transparent financial forensics. Our results highlight the value of domain-specific reasoning and dataset construction for advancing robust financial fraud detection in practical, real-world regulatory applications.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†AuditAgentï¼Œä¸€ç§èåˆå®¡è®¡é¢†åŸŸä¸“å®¶çŸ¥è¯†çš„å¤šæ™ºèƒ½ä½“æ¨ç†(Multi-Agent Reasoning)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³è·¨å¹´åº¦è´¢åŠ¡æŠ¥å‘Šä¸­æ¬ºè¯ˆè¯æ®éšè”½ä¸”åˆ†æ•£çš„æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶åˆ©ç”¨ä¸­å›½è¯ç›‘ä¼š(CSRC)å…¬å¼€çš„æ‰§æ³•æ–‡ä»¶å’Œè´¢åŠ¡æŠ¥å‘Šæ„å»ºäº†ä¸“å®¶æ ‡æ³¨æ•°æ®é›†ï¼Œé€šè¿‡é›†æˆä¸»ä½“çº§é£é™©å…ˆéªŒ(Subject-Level Risk Priors)ã€æ··åˆæ£€ç´¢ç­–ç•¥(Hybrid Retrieval Strategy)ä»¥åŠä¸“é—¨çš„æ™ºèƒ½ä½“æ¨¡å—ï¼Œå®ç°äº†å¯¹è·¨æŠ¥å‘Šè¯æ®çš„é«˜æ•ˆè¯†åˆ«ä¸èšåˆã€‚å®éªŒè¯æ˜ï¼ŒAuditAgentåœ¨å¬å›ç‡å’Œå¯è§£é‡Šæ€§æ–¹é¢æ˜¾è‘—ä¼˜äºé€šç”¨æ™ºèƒ½ä½“(General-Purpose Agent)èŒƒå¼ï¼Œä¸ºè‡ªåŠ¨åŒ–ã€é€æ˜çš„è´¢åŠ¡é‰´è¯æä¾›äº†æ–°çš„åŸºå‡†ã€‚è¯¥æˆæœå¼ºè°ƒäº†é¢†åŸŸç‰¹å®šæ¨ç†å’Œæ•°æ®é›†æ„å»ºåœ¨æå‡å®é™…ç›‘ç®¡åº”ç”¨ä¸­è´¢åŠ¡æ¬ºè¯ˆæ£€æµ‹ç¨³å¥æ€§æ–¹é¢çš„æ ¸å¿ƒä»·å€¼ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.00156v1",
      "published_date": "2025-09-30 18:26:44 UTC",
      "updated_date": "2025-09-30 18:26:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:26:29.289658+00:00"
    },
    {
      "arxiv_id": "2510.00154v1",
      "title": "RoboPilot: Generalizable Dynamic Robotic Manipulation with Dual-thinking Modes",
      "title_zh": "RoboPilotï¼šåŸºäºåŒé‡æ€è€ƒæ¨¡å¼çš„å¯æ³›åŒ–åŠ¨æ€æœºå™¨äººæ“æ§",
      "authors": [
        "Xinyi Liu",
        "Mohammadreza Fani Sani",
        "Zewei Zhou",
        "Julius Wirbel",
        "Bahram Zarrin",
        "Roberto Galeazzi"
      ],
      "abstract": "Despite rapid progress in autonomous robotics, executing complex or long-horizon tasks remains a fundamental challenge. Most current approaches follow an open-loop paradigm with limited reasoning and no feedback, resulting in poor robustness to environmental changes and severe error accumulation. We present RoboPilot, a dual-thinking closed-loop framework for robotic manipulation that supports adaptive reasoning for complex tasks in real-world dynamic environments. RoboPilot leverages primitive actions for structured task planning and flexible action generation, while introducing feedback to enable replanning from dynamic changes and execution errors. Chain-of-Thought reasoning further enhances high-level task planning and guides low-level action generation. The system dynamically switches between fast and slow thinking to balance efficiency and accuracy. To systematically evaluate the robustness of RoboPilot in diverse robot manipulation scenarios, we introduce RoboPilot-Bench, a benchmark spanning 21 tasks across 10 categories, including infeasible-task recognition and failure recovery. Experiments show that RoboPilot outperforms state-of-the-art baselines by 25.9\\% in task success rate, and the real-world deployment on an industrial robot further demonstrates its robustness in real-world settings.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† RoboPilotï¼Œä¸€ç§å…·æœ‰åŒé‡æ€ç»´æ¨¡å¼çš„é—­ç¯æœºå™¨äººæ“çºµæ¡†æ¶ (dual-thinking closed-loop framework)ï¼Œæ—¨åœ¨è§£å†³è‡ªåŠ¨æœºå™¨äººé¢†åŸŸåœ¨æ‰§è¡Œå¤æ‚é•¿æ—¶ç¨‹ä»»åŠ¡æ—¶å­˜åœ¨çš„æ¨ç†å—é™å’Œç¼ºä¹åé¦ˆç­‰æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶ç»“åˆäº†åŸå§‹åŠ¨ä½œ (primitive actions) è¿›è¡Œç»“æ„åŒ–ä»»åŠ¡è§„åˆ’ï¼Œå¹¶åˆ©ç”¨é“¾å¼æ€ç»´ (Chain-of-Thought) æ¨ç†æ¥å¢å¼ºé«˜å±‚å†³ç­–å¹¶æŒ‡å¯¼åº•å±‚åŠ¨ä½œç”Ÿæˆã€‚RoboPilot çš„æ ¸å¿ƒä¼˜åŠ¿åœ¨äºèƒ½å¤Ÿæ ¹æ®ç¯å¢ƒåé¦ˆè¿›è¡Œé‡è§„åˆ’ (replanning)ï¼Œå¹¶åœ¨å¿«æ…¢æ€è€ƒ (fast and slow thinking) æ¨¡å¼ä¹‹é—´åŠ¨æ€åˆ‡æ¢ï¼Œä»¥å®ç°æ•ˆç‡ä¸å‡†ç¡®æ€§çš„å¹³è¡¡ã€‚æ­¤å¤–ï¼Œç ”ç©¶å›¢é˜Ÿæ¨å‡ºäº†åŒ…å« 21 é¡¹ä»»åŠ¡çš„ RoboPilot-Bench åŸºå‡†æµ‹è¯•ï¼Œæ¶µç›–äº†æ•…éšœæ¢å¤å’Œä¸å¯è¡Œä»»åŠ¡è¯†åˆ«ç­‰å¤šç§ç°å®åœºæ™¯ã€‚å®éªŒè¯æ˜ï¼ŒRoboPilot åœ¨ä»»åŠ¡æˆåŠŸç‡ä¸Šæ˜¾è‘—è¶…è¶Šäº†ç°æœ‰æœ€å…ˆè¿›åŸºå‡†æ¨¡å‹ 25.9%ï¼Œå¹¶åœ¨å·¥ä¸šæœºå™¨äººå®åœ°éƒ¨ç½²ä¸­å±•ç°å‡ºå“è¶Šçš„é²æ£’æ€§ä¸æ³›åŒ–èƒ½åŠ›ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.00154v1",
      "published_date": "2025-09-30 18:25:47 UTC",
      "updated_date": "2025-09-30 18:25:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:26:31.180776+00:00"
    },
    {
      "arxiv_id": "2510.01278v1",
      "title": "Noisy-Pair Robust Representation Alignment for Positive-Unlabeled Learning",
      "title_zh": "é¢å‘æ­£æ ·æœ¬å’Œæ— æ ‡ç­¾å­¦ä¹ çš„å™ªå£°å¯¹é²æ£’è¡¨å¾å¯¹é½",
      "authors": [
        "Hengwei Zhao",
        "Zhengzhong Tu",
        "Zhuo Zheng",
        "Wei Wang",
        "Junjue Wang",
        "Rusty Feagin",
        "Wenzhe Jiao"
      ],
      "abstract": "Positive-Unlabeled (PU) learning aims to train a binary classifier (positive vs. negative) where only limited positive data and abundant unlabeled data are available. While widely applicable, state-of-the-art PU learning methods substantially underperform their supervised counterparts on complex datasets, especially without auxiliary negatives or pre-estimated parameters (e.g., a 14.26% gap on CIFAR-100 dataset). We identify the primary bottleneck as the challenge of learning discriminative representations under unreliable supervision. To tackle this challenge, we propose NcPU, a non-contrastive PU learning framework that requires no auxiliary information. NcPU combines a noisy-pair robust supervised non-contrastive loss (NoiSNCL), which aligns intra-class representations despite unreliable supervision, with a phantom label disambiguation (PLD) scheme that supplies conservative negative supervision via regret-based label updates. Theoretically, NoiSNCL and PLD can iteratively benefit each other from the perspective of the Expectation-Maximization framework. Empirically, extensive experiments demonstrate that: (1) NoiSNCL enables simple PU methods to achieve competitive performance; and (2) NcPU achieves substantial improvements over state-of-the-art PU methods across diverse datasets, including challenging datasets on post-disaster building damage mapping, highlighting its promise for real-world applications. Code: Code will be open-sourced after review.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ­£æ ·æœ¬-æ— æ ‡ç­¾å­¦ä¹ (Positive-Unlabeled Learning, PU Learning)åœ¨å¤æ‚æ•°æ®é›†ä¸Šç”±äºç›‘ç£ä¿¡æ¯ä¸å¯é å¯¼è‡´è¡¨å¾å­¦ä¹ æ€§èƒ½ä¸è¶³çš„é—®é¢˜ï¼Œæå‡ºäº†NcPUæ¡†æ¶ã€‚NcPUæ˜¯ä¸€ç§æ— éœ€è¾…åŠ©ä¿¡æ¯çš„éå¯¹æ¯”å­¦ä¹ æ¡†æ¶ï¼Œæ ¸å¿ƒç»“åˆäº†æŠ—å™ªå¯¹é²æ£’ç›‘ç£éå¯¹æ¯”æŸå¤±(NoiSNCL)å’Œå¹»å½±æ ‡ç­¾æ¶ˆæ­§(PLD)æ–¹æ¡ˆã€‚NoiSNCLé€šè¿‡åœ¨ä¸å¯é ç›‘ç£ä¸‹å¯¹é½ç±»å†…è¡¨å¾ï¼Œæ˜¾è‘—æå‡äº†ç‰¹å¾çš„è¾¨åˆ«åŠ›ï¼Œè€ŒPLDåˆ™é€šè¿‡åŸºäºé—æ†¾çš„æ ‡ç­¾æ›´æ–°æä¾›ä¿å®ˆçš„è´Ÿæ ·æœ¬ç›‘ç£ã€‚åœ¨ç†è®ºå±‚é¢ï¼ŒNoiSNCLä¸PLDåœ¨æœŸæœ›æå¤§åŒ–(Expectation-Maximization)æ¡†æ¶ä¸‹èƒ½å¤Ÿå®ç°å¾ªç¯äº’ä¿ƒã€‚å®éªŒè¯æ˜ï¼ŒNcPUåœ¨CIFAR-100ä»¥åŠç¾åå»ºç­‘ç ´åæµ‹ç»˜ç­‰å¤šä¸ªæŒ‘æˆ˜æ€§æ•°æ®é›†ä¸Šå‡æ˜¾è‘—ä¼˜äºç°æœ‰çš„å…ˆè¿›PUå­¦ä¹ æ–¹æ³•ã€‚è¯¥æˆæœä¸ä»…å¢å¼ºäº†ç®€å•PUæ–¹æ³•çš„ç«äº‰åŠ›ï¼Œä¹Ÿä¸ºç°å®ä¸–ç•Œä¸­ç¼ºä¹è´Ÿæ ·æœ¬æ ‡æ³¨çš„åº”ç”¨åœºæ™¯æä¾›äº†é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.01278v1",
      "published_date": "2025-09-30 18:22:30 UTC",
      "updated_date": "2025-09-30 18:22:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:26:35.477622+00:00"
    },
    {
      "arxiv_id": "2510.00151v1",
      "title": "Stealing AI Model Weights Through Covert Communication Channels",
      "title_zh": "é€šè¿‡éšè”½é€šä¿¡ä¿¡é“çªƒå– AI æ¨¡å‹æƒé‡",
      "authors": [
        "Valentin Barbaza",
        "Alan Rodrigo Diaz-Rizo",
        "Hassan Aboushady",
        "Spyridon Raptis",
        "Haralampos-G. Stratigopoulos"
      ],
      "abstract": "AI models are often regarded as valuable intellectual property due to the high cost of their development, the competitive advantage they provide, and the proprietary techniques involved in their creation. As a result, AI model stealing attacks pose a serious concern for AI model providers. In this work, we present a novel attack targeting wireless devices equipped with AI hardware accelerators. The attack unfolds in two phases. In the first phase, the victim's device is compromised with a hardware Trojan (HT) designed to covertly leak model weights through a hidden communication channel, without the victim realizing it. In the second phase, the adversary uses a nearby wireless device to intercept the victim's transmission frames during normal operation and incrementally reconstruct the complete weight matrix. The proposed attack is agnostic to both the AI model architecture and the hardware accelerator used. We validate our approach through a hardware-based demonstration involving four diverse AI models of varying types and sizes. We detail the design of the HT and the covert channel, highlighting their stealthy nature. Additionally, we analyze the impact of bit error rates on the reception and propose an error mitigation technique. The effectiveness of the attack is evaluated based on the accuracy of the reconstructed models with stolen weights and the time required to extract them. Finally, we explore potential defense mechanisms.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§é’ˆå¯¹é…å¤‡ AI ç¡¬ä»¶åŠ é€Ÿå™¨ (AI hardware accelerators) çš„æ— çº¿è®¾å¤‡çš„æ–°å‹æ¨¡å‹çªƒå–æ”»å‡»æ–¹æ³•ï¼Œæ—¨åœ¨é€šè¿‡éšè”½é€šä¿¡ä¿¡é“ (covert communication channels) çªƒå–è¢«è§†ä¸ºæ ¸å¿ƒçŸ¥è¯†äº§æƒçš„ AI æ¨¡å‹æƒé‡ã€‚æ”»å‡»è¿‡ç¨‹åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼šé¦–å…ˆåˆ©ç”¨ç¡¬ä»¶æœ¨é©¬ (hardware Trojan, HT) æ„ŸæŸ“å—å®³è€…è®¾å¤‡ï¼Œåœ¨ç”¨æˆ·æ— æ„ŸçŸ¥çš„æƒ…å†µä¸‹é€šè¿‡éšè—ä¿¡é“æ³„éœ²æ¨¡å‹æƒé‡ï¼›éšåæ”»å‡»è€…åˆ©ç”¨é™„è¿‘çš„æ— çº¿è®¾å¤‡æ‹¦æˆªæ­£å¸¸æ“ä½œä¸­çš„ä¼ è¾“å¸§ï¼Œä»è€Œé€æ­¥é‡æ„å®Œæ•´çš„æƒé‡çŸ©é˜µã€‚è¯¥æ”»å‡»æ–¹æ¡ˆå¯¹ AI æ¨¡å‹æ¶æ„å’Œæ‰€ä½¿ç”¨çš„ç¡¬ä»¶åŠ é€Ÿå™¨å‡å…·æœ‰é€šç”¨æ€§ (agnostic)ï¼Œå¹¶åœ¨åŒ…å«å››ç§ä¸åŒç±»å‹å’Œè§„æ¨¡æ¨¡å‹çš„ç¡¬ä»¶ç¯å¢ƒä¸­å¾—åˆ°äº†å®éªŒéªŒè¯ã€‚ç ”ç©¶è¯¦ç»†åˆ†æäº†ç¡¬ä»¶æœ¨é©¬ä¸éšè”½ä¿¡é“çš„éšè”½æ€§è®¾è®¡ï¼Œå¹¶æå‡ºäº†é’ˆå¯¹è¯¯ç ç‡ (bit error rates) çš„è¯¯å·®ç¼“è§£æŠ€æœ¯ã€‚å®éªŒç»“æœé€šè¿‡é‡æ„æ¨¡å‹çš„å‡†ç¡®ç‡å’Œæƒé‡æå–æ—¶é—´è¯æ˜äº†æ”»å‡»çš„æœ‰æ•ˆæ€§ï¼Œå¹¶è¿›ä¸€æ­¥æ¢è®¨äº†æ½œåœ¨çš„é˜²å¾¡æœºåˆ¶ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.00151v1",
      "published_date": "2025-09-30 18:21:41 UTC",
      "updated_date": "2025-09-30 18:21:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:26:39.889676+00:00"
    },
    {
      "arxiv_id": "2510.00144v1",
      "title": "Which Rewards Matter? Reward Selection for Reinforcement Learning under Limited Feedback",
      "title_zh": "å“ªäº›å¥–åŠ±æ›´é‡è¦ï¼Ÿæœ‰é™åé¦ˆä¸‹çš„å¼ºåŒ–å­¦ä¹ å¥–åŠ±é€‰æ‹©",
      "authors": [
        "Shreyas Chaudhari",
        "Renhao Zhang",
        "Philip S. Thomas",
        "Bruno Castro da Silva"
      ],
      "abstract": "The ability of reinforcement learning algorithms to learn effective policies is determined by the rewards available during training. However, for practical problems, obtaining large quantities of reward labels is often infeasible due to computational or financial constraints, particularly when relying on human feedback. When reinforcement learning must proceed with limited feedback -- only a fraction of samples get rewards labeled -- a fundamental question arises: which samples should be labeled to maximize policy performance? We formalize this problem of reward selection for reinforcement learning from limited feedback (RLLF), introducing a new problem formulation that facilitates the study of strategies for selecting impactful rewards. Two types of selection strategies are investigated: (i) heuristics that rely on reward-free information such as state visitation and partial value functions, and (ii) strategies pre-trained using auxiliary evaluative feedback. We find that critical subsets of rewards are those that (1) guide the agent along optimal trajectories, and (2) support recovery toward near-optimal behavior after deviations. Effective selection methods yield near-optimal policies with significantly fewer reward labels than full supervision, establishing reward selection as a powerful paradigm for scaling reinforcement learning in feedback-limited settings.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æœ‰é™åé¦ˆä¸‹çš„å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)ä¸­çš„å¥–åŠ±é€‰æ‹©é—®é¢˜ï¼Œæ—¨åœ¨è§£å†³åœ¨è®¡ç®—æˆ–èµ„æºå—é™çš„æƒ…å†µä¸‹è·å–å¤§é‡å¥–åŠ±æ ‡ç­¾çš„å›°éš¾ã€‚ä½œè€…æ­£å¼å®šä¹‰äº†æœ‰é™åé¦ˆå¥–åŠ±é€‰æ‹©å¼ºåŒ–å­¦ä¹ (RLLF)è¿™ä¸€æ–°é—®é¢˜ï¼Œå¹¶æå‡ºäº†æ—¨åœ¨æœ€å¤§åŒ–ç­–ç•¥æ€§èƒ½çš„é€‰æ‹©ç­–ç•¥ç ”ç©¶æ¡†æ¶ã€‚è®ºæ–‡ç ”ç©¶äº†ä¸¤ç±»é€‰æ‹©ç­–ç•¥ï¼ŒåŒ…æ‹¬åŸºäºçŠ¶æ€è®¿é—®(state visitation)å’Œéƒ¨åˆ†ä»·å€¼å‡½æ•°(partial value functions)çš„å¯å‘å¼æ–¹æ³•ï¼Œä»¥åŠåˆ©ç”¨è¾…åŠ©è¯„ä¼°åé¦ˆè¿›è¡Œé¢„è®­ç»ƒçš„ç­–ç•¥ã€‚ç ”ç©¶å‘ç°ï¼Œå…³é”®çš„å¥–åŠ±å­é›†æ˜¯é‚£äº›èƒ½å¤Ÿå¼•å¯¼æ™ºèƒ½ä½“æ²¿ç€æœ€ä¼˜è½¨è¿¹(optimal trajectories)è¿è¡Œï¼Œä»¥åŠæ”¯æŒæ™ºèƒ½ä½“åœ¨åç¦»åæ¢å¤è‡³è¿‘ä¼˜è¡Œä¸º(near-optimal behavior)çš„éƒ¨åˆ†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæœ‰æ•ˆçš„é€‰æ‹©æ–¹æ³•èƒ½å¤Ÿä»¥è¿œå°‘äºå…¨ç›‘ç£å­¦ä¹ æ‰€éœ€çš„æ ‡ç­¾æ•°é‡ï¼Œå®ç°æ¥è¿‘æœ€ä¼˜çš„ç­–ç•¥æ•ˆæœã€‚è¯¥ç ”ç©¶ç¡®ç«‹äº†å¥–åŠ±é€‰æ‹©ä½œä¸ºåœ¨åé¦ˆå—é™ç¯å¢ƒä¸‹æ‰©å±•å¼ºåŒ–å­¦ä¹ è§„æ¨¡çš„ä¸€ç§é«˜æ•ˆèŒƒå¼ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.00144v1",
      "published_date": "2025-09-30 18:17:49 UTC",
      "updated_date": "2025-09-30 18:17:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:26:42.384472+00:00"
    },
    {
      "arxiv_id": "2510.00137v1",
      "title": "Optimizing What Matters: AUC-Driven Learning for Robust Neural Retrieval",
      "title_zh": "ä¼˜åŒ–å…³é”®ï¼šé¢å‘é²æ£’ç¥ç»æ£€ç´¢çš„ AUC é©±åŠ¨å­¦ä¹ ",
      "authors": [
        "Nima Sheikholeslami",
        "Erfan Hosseini",
        "Patrice Bechard",
        "Srivatsava Daruru",
        "Sai Rajeswar"
      ],
      "abstract": "Dual-encoder retrievers depend on the principle that relevant documents should score higher than irrelevant ones for a given query. Yet the dominant Noise Contrastive Estimation (NCE) objective, which underpins Contrastive Loss, optimizes a softened ranking surrogate that we rigorously prove is fundamentally oblivious to score separation quality and unrelated to AUC. This mismatch leads to poor calibration and suboptimal performance in downstream tasks like retrieval-augmented generation (RAG). To address this fundamental limitation, we introduce the MW loss, a new training objective that maximizes the Mann-Whitney U statistic, which is mathematically equivalent to the Area under the ROC Curve (AUC). MW loss encourages each positive-negative pair to be correctly ranked by minimizing binary cross entropy over score differences. We provide theoretical guarantees that MW loss directly upper-bounds the AoC, better aligning optimization with retrieval goals. We further promote ROC curves and AUC as natural threshold free diagnostics for evaluating retriever calibration and ranking quality. Empirically, retrievers trained with MW loss consistently outperform contrastive counterparts in AUC and standard retrieval metrics. Our experiments show that MW loss is an empirically superior alternative to Contrastive Loss, yielding better-calibrated and more discriminative retrievers for high-stakes applications like RAG.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŒç¼–ç å™¨æ£€ç´¢å™¨(Dual-encoder retrievers)å¸¸ç”¨çš„å™ªå£°å¯¹æ¯”ä¼°è®¡(Noise Contrastive Estimation, NCE)ç›®æ ‡å‡½æ•°åœ¨å¾—åˆ†åˆ†ç¦»è´¨é‡å’Œ AUC ä¼˜åŒ–æ–¹é¢çš„å›ºæœ‰ç¼ºé™·è¿›è¡Œäº†æ¢è®¨ï¼ŒæŒ‡å‡ºå…¶ä¸ AUC æ— å…³çš„ç‰¹æ€§ä¼šå¯¼è‡´æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)ç­‰ä¸‹æ¸¸ä»»åŠ¡çš„æ€§èƒ½å—é™ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº† MW lossï¼Œè¿™æ˜¯ä¸€ç§é€šè¿‡æœ€å¤§åŒ– Mann-Whitney U ç»Ÿè®¡é‡æ¥ç›´æ¥ä¼˜åŒ– ROC æ›²çº¿ä¸‹é¢ç§¯(AUC)çš„æ–°å‹è®­ç»ƒç›®æ ‡ã€‚MW loss é€šè¿‡æœ€å°åŒ–åˆ†å·®ä¸Šçš„äºŒå…ƒäº¤å‰ç†µï¼Œé¼“åŠ±æ¨¡å‹æ­£ç¡®æ’åˆ—æ¯ä¸€å¯¹æ­£è´Ÿæ ·æœ¬ï¼Œå¹¶åœ¨ç†è®ºä¸Šè¯æ˜äº†å…¶èƒ½ç›´æ¥ä¸Šç•ŒåŒ– AoCï¼Œä½¿ä¼˜åŒ–ç›®æ ‡ä¸æ£€ç´¢ç›®æ ‡æ›´åŠ ä¸€è‡´ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜æå€¡å°† ROC æ›²çº¿å’Œ AUC ä½œä¸ºè¯„ä¼°æ£€ç´¢å™¨æ ¡å‡†å’Œæ’åºè´¨é‡çš„æ— é˜ˆå€¼è¯Šæ–­å·¥å…·ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨ MW loss è®­ç»ƒçš„æ£€ç´¢å™¨åœ¨ AUC å’Œæ ‡å‡†æ£€ç´¢æŒ‡æ ‡ä¸Šå‡ä¸€è‡´ä¼˜äºåŸºäº Contrastive Loss çš„æ¨¡å‹ã€‚è¿™ä¸€æ–¹æ³•ä¸ºé«˜è¦æ±‚åº”ç”¨åœºæ™¯æä¾›äº†æ ¡å‡†æ›´ä½³ã€åˆ¤åˆ«åŠ›æ›´å¼ºçš„æ£€ç´¢è§£å†³æ–¹æ¡ˆï¼Œè¢«è¯æ˜æ˜¯ Contrastive Loss åœ¨å®è¯ä¸Šçš„ä¼˜è¶Šæ›¿ä»£æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.00137v1",
      "published_date": "2025-09-30 18:14:01 UTC",
      "updated_date": "2025-09-30 18:14:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:26:51.684011+00:00"
    },
    {
      "arxiv_id": "2510.00136v1",
      "title": "Nonparametric Identification of Latent Concepts",
      "title_zh": "æ½œåœ¨æ¦‚å¿µçš„éå‚æ•°è¯†åˆ«",
      "authors": [
        "Yujia Zheng",
        "Shaoan Xie",
        "Kun Zhang"
      ],
      "abstract": "We are born with the ability to learn concepts by comparing diverse observations. This helps us to understand the new world in a compositional manner and facilitates extrapolation, as objects naturally consist of multiple concepts. In this work, we argue that the cognitive mechanism of comparison, fundamental to human learning, is also vital for machines to recover true concepts underlying the data. This offers correctness guarantees for the field of concept learning, which, despite its impressive empirical successes, still lacks general theoretical support. Specifically, we aim to develop a theoretical framework for the identifiability of concepts with multiple classes of observations. We show that with sufficient diversity across classes, hidden concepts can be identified without assuming specific concept types, functional relations, or parametric generative models. Interestingly, even when conditions are not globally satisfied, we can still provide alternative guarantees for as many concepts as possible based on local comparisons, thereby extending the applicability of our theory to more flexible scenarios. Moreover, the hidden structure between classes and concepts can also be identified nonparametrically. We validate our theoretical results in both synthetic and real-world settings.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æ½œåœ¨æ¦‚å¿µçš„éå‚æ•°åŒ–è¯†åˆ«(Nonparametric Identification of Latent Concepts)ï¼Œæ—¨åœ¨ä¸ºæœºå™¨å­¦ä¹ ä¸­çš„æ¦‚å¿µå­¦ä¹ æä¾›å¿…è¦çš„ç†è®ºæ”¯æ’‘ã€‚ç ”ç©¶è€…æ¨¡æ‹Ÿäººç±»é€šè¿‡æ¯”è¾ƒä¸åŒè§‚å¯Ÿç»“æœæ¥å­¦ä¹ æ¦‚å¿µçš„è®¤çŸ¥æœºåˆ¶ï¼Œæå‡ºäº†ä¸€ä¸ªé’ˆå¯¹å¤šç±»è§‚å¯Ÿç»“æœçš„æ¦‚å¿µå¯è¯†åˆ«æ€§(identifiability)ç†è®ºæ¡†æ¶ã€‚è¯¥æ¡†æ¶è¯æ˜äº†åªè¦ç±»åˆ«é—´å…·å¤‡è¶³å¤Ÿçš„å¤šæ ·æ€§ï¼Œæ— éœ€é¢„è®¾ç‰¹å®šçš„æ¦‚å¿µç±»å‹ã€å‡½æ•°å…³ç³»æˆ–å‚æ•°åŒ–ç”Ÿæˆæ¨¡å‹ï¼Œå³å¯å®ç°éšè—æ¦‚å¿µçš„å‡†ç¡®æ¢å¤ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å±•ç¤ºäº†åœ¨å…¨å±€æ¡ä»¶ä¸å®Œå…¨æ»¡è¶³æ—¶ï¼Œåˆ©ç”¨å±€éƒ¨æ¯”è¾ƒä¸ºéƒ¨åˆ†æ¦‚å¿µæä¾›è¯†åˆ«ä¿è¯çš„å¯èƒ½æ€§ï¼Œå¹¶è¯æ˜äº†ç±»åˆ«ä¸æ¦‚å¿µé—´çš„éšè—ç»“æ„ä¹Ÿèƒ½è¢«éå‚æ•°åŒ–åœ°è¯†åˆ«ã€‚é€šè¿‡åœ¨åˆæˆæ•°æ®å’ŒçœŸå®ä¸–ç•Œåœºæ™¯ä¸­çš„éªŒè¯ï¼Œè¯¥ç†è®ºä¸ºæ„å»ºå…·æœ‰ç»„åˆæ€§ç†è§£å’Œå¤–æ¨èƒ½åŠ›çš„æœºå™¨æ™ºèƒ½å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.PR",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2025",
      "pdf_url": "https://arxiv.org/pdf/2510.00136v1",
      "published_date": "2025-09-30 18:13:53 UTC",
      "updated_date": "2025-09-30 18:13:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:26:50.691582+00:00"
    },
    {
      "arxiv_id": "2510.00129v1",
      "title": "BigBang-Proton Technical Report: Next-Word-Prediction is Scientific Multitask Learner",
      "title_zh": "BigBang-Proton æŠ€æœ¯æŠ¥å‘Šï¼šä¸‹ä¸€è¯é¢„æµ‹å³ç§‘å­¦å¤šä»»åŠ¡å­¦ä¹ å™¨",
      "authors": [
        "Hengkui Wu",
        "Liujiang Liu",
        "Jihua He",
        "Qihao Wang",
        "Keke Zhao",
        "Shuyang Hu",
        "Renle Fu",
        "Dahao Liang",
        "Lingyu Zeng",
        "Bruce Liu",
        "Yuan Liu",
        "Jin Zhan",
        "Jiaqiang Niu",
        "Xinglong Jia",
        "Yaqin Hu",
        "Wenjun Ji",
        "Panpan Chi",
        "Ken Chen",
        "Hengyuan Wu",
        "Yingsi Xin",
        "Yongfeng Zhu",
        "Yuexin Wang",
        "Manqi Ruan",
        "Ningtao Bian",
        "Xiaohua Wu",
        "Weipeng Xu"
      ],
      "abstract": "We introduce BigBang-Proton, a unified sequence-based architecture for auto-regressive language modeling pretrained on cross-scale, cross-structure, cross-discipline real-world scientific tasks to construct a scientific multi-task learner. BigBang-Proton incorporates three fundamental innovations compared to mainstream general-purpose LLMs: Theory-Experiment Learning paradigm aligns large-scale numerical experimental data with theoretical text corpora; Binary Patch Encoding replaces byte pair encoding(BPE) tokenization; Monte Carlo Attention substitutes traditional transformer architectures. Through next-word-prediction pretraining on cross-discipline scientific datasets of real-world problems mixed with general textual corpus, followed by fine-tuning and inference on downstream tasks, BigBang-Proton demonstrates 100\\% accuracy in up to 50-digit arithmetic addition operations, performance on par with leading specialized models in particle physics jet tagging, matching MAE of specialized models in inter-atomic potential simulation, performance comparable to traditional spatiotemporal models in water quality prediction, and benchmark-exceeding performance in genome modeling. These results prove that language-guided scientific computing can match or exceed the performance of task-specific scientific models while maintaining multitask learning capabilities. We further hypothesize to scale the pretraining to the universe scale as a fundamental step toward developing material world foundational model.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† BigBang-Protonï¼Œè¿™æ˜¯ä¸€ç§ç»Ÿä¸€çš„åºåˆ—åŒ–æ¶æ„ï¼Œé€šè¿‡åœ¨è·¨å°ºåº¦ã€è·¨ç»“æ„å’Œè·¨å­¦ç§‘çš„çœŸå®ç§‘å­¦ä»»åŠ¡ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œæ„å»ºäº†ç§‘å­¦å¤šä»»åŠ¡å­¦ä¹ å™¨ã€‚ä¸ä¸»æµé€šç”¨ LLMs ç›¸æ¯”ï¼Œè¯¥æ¨¡å‹å¼•å…¥äº†å°†å¤§è§„æ¨¡æ•°å€¼å®éªŒæ•°æ®ä¸ç†è®ºæ–‡æœ¬å¯¹é½çš„ Theory-Experiment Learning èŒƒå¼ï¼Œå¹¶é‡‡ç”¨äº† Binary Patch Encoding å–ä»£ä¼ ç»Ÿçš„ BPE åˆ†è¯ï¼Œä»¥åŠåˆ©ç”¨ Monte Carlo Attention æ›¿æ¢æ ‡å‡†çš„ Transformer æ¶æ„ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒBigBang-Proton åœ¨ 50 ä½ç®—æœ¯åŠ æ³•ä¸­è¾¾åˆ°äº† 100% å‡†ç¡®ç‡ï¼Œåœ¨ç²’å­ç‰©ç† Jet Taggingã€åŸå­é—´åŠ¿èƒ½æ¨¡æ‹Ÿ (Inter-atomic potential simulation) å’Œæ°´è´¨é¢„æµ‹ç­‰é¢†åŸŸè¾¾åˆ°äº†ä¸“ç”¨æ¨¡å‹çš„æ€§èƒ½æ°´å¹³ï¼Œå¹¶åœ¨åŸºå› ç»„å»ºæ¨¡ (Genome modeling) ä»»åŠ¡ä¸­åˆ·æ–°äº†åŸºå‡†ã€‚è¯¥é¡¹å·¥ä½œè¯æ˜äº†ä»¥è¯­è¨€å¼•å¯¼çš„ç§‘å­¦è®¡ç®—èƒ½å¤Ÿåœ¨ä¿æŒå¤šä»»åŠ¡èƒ½åŠ›çš„åŒæ—¶ï¼ŒåŒ¹é…æˆ–è¶…è¶Šç‰¹å®šä»»åŠ¡çš„ç§‘å­¦æ¨¡å‹æ€§èƒ½ã€‚ä½œè€…è¿›ä¸€æ­¥å‡è®¾ï¼Œå°†é¢„è®­ç»ƒæ‰©å±•åˆ°å®‡å®™è§„æ¨¡æ˜¯å¼€å‘ç‰©è´¨ä¸–ç•ŒåŸºç¡€æ¨¡å‹ (Material world foundational model) çš„å…³é”®æ­¥éª¤ã€‚",
      "categories": [
        "cs.LG",
        "cond-mat.mtrl-sci",
        "cs.AI",
        "physics.comp-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "93 pages, 39 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.00129v1",
      "published_date": "2025-09-30 18:09:18 UTC",
      "updated_date": "2025-09-30 18:09:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:26:54.488942+00:00"
    },
    {
      "arxiv_id": "2510.00125v1",
      "title": "Direct Token Optimization: A Self-contained Approach to Large Language Model Unlearning",
      "title_zh": "ç›´æ¥ Token ä¼˜åŒ–ï¼šä¸€ç§è‡ªåŒ…å«çš„å¤§è¯­è¨€æ¨¡å‹é—å¿˜æ–¹æ³•",
      "authors": [
        "Hong kyu Lee",
        "Ruixuan Liu",
        "Li Xiong"
      ],
      "abstract": "Machine unlearning is an emerging technique that removes the influence of a subset of training data (forget set) from a model without full retraining, with applications including privacy protection, content moderation, and model correction. The key challenge lies in ensuring that the model completely forgets the knowledge of the forget set without compromising its overall utility. Existing unlearning methods for large language models (LLMs) often utilize auxiliary language models, retain datasets, or even commercial AI services for effective unlearning and maintaining the model utility. However, dependence on these external resources is often impractical and could potentially introduce additional privacy risks. In this work, we propose direct token optimization (DTO), a novel self-contained unlearning approach for LLMs that directly optimizes the token level objectives and eliminates the need for external resources. Given a sequence to unlearn, we identify two categories of tokens: target tokens, which capture critical knowledge for unlearning, and the remaining non-target tokens, which are crucial for maintaining the model utility. The former are used to optimize the unlearning objective, while the latter serve to preserve the model's performance. The experimental results show that the proposed DTO achieves up to 16.8$\\times$ improvement in forget quality on several benchmark datasets than the latest baselines while maintaining a comparable level of model utility.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)æœºå™¨é—å¿˜(Machine unlearning)ä¸­è¿‡åº¦ä¾èµ–å¤–éƒ¨èµ„æºä¸”å­˜åœ¨éšç§é£é™©çš„é—®é¢˜ï¼Œæå‡ºäº†ç›´æ¥ä»¤ç‰Œä¼˜åŒ–(Direct Token Optimization, DTO)è¿™ä¸€è‡ªç»™è‡ªè¶³çš„é—å¿˜æ–¹æ³•ã€‚DTO é€šè¿‡ç›´æ¥ä¼˜åŒ–ä»¤ç‰Œçº§åˆ«(token level)çš„ç›®æ ‡ï¼Œæ¶ˆé™¤äº†å¯¹è¾…åŠ©æ¨¡å‹æˆ–å¤–éƒ¨æ•°æ®é›†çš„éœ€æ±‚ã€‚è¯¥æ–¹æ³•å°†å¾…é—å¿˜åºåˆ—ä¸­çš„ä»¤ç‰Œåˆ’åˆ†ä¸ºä¸¤ç±»ï¼šç”¨äºä¼˜åŒ–é—å¿˜ç›®æ ‡çš„â€œç›®æ ‡ä»¤ç‰Œâ€(target tokens)ï¼Œä»¥åŠç”¨äºç»´æŒæ¨¡å‹é€šç”¨æ€§èƒ½çš„â€œéç›®æ ‡ä»¤ç‰Œâ€(non-target tokens)ã€‚é€šè¿‡å·®å¼‚åŒ–å¤„ç†è¿™ä¸¤ç±»ä»¤ç‰Œï¼ŒDTO èƒ½å¤Ÿåœ¨å½»åº•æ“¦é™¤ç‰¹å®šçŸ¥è¯†çš„åŒæ—¶ï¼Œæœ‰æ•ˆä¿ç•™æ¨¡å‹çš„æ•´ä½“æ•ˆç”¨ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDTO åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„é—å¿˜è´¨é‡(forget quality)æ¯”ç°æœ‰åŸºå‡†æ¨¡å‹æå‡äº†å¤šè¾¾ 16.8 å€ã€‚åŒæ—¶ï¼Œè¯¥æ–¹æ³•åœ¨ç§»é™¤æ•æ„Ÿä¿¡æ¯åä¾ç„¶ä¿æŒäº†æé«˜çš„æ¨¡å‹æ•ˆç”¨(model utility)æ°´å¹³ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.00125v1",
      "published_date": "2025-09-30 18:05:06 UTC",
      "updated_date": "2025-09-30 18:05:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:27:21.386274+00:00"
    },
    {
      "arxiv_id": "2509.26644v1",
      "title": "Stitch: Training-Free Position Control in Multimodal Diffusion Transformers",
      "title_zh": "Stitchï¼šå¤šæ¨¡æ€æ‰©æ•£ Transformer ä¸­çš„å…è®­ç»ƒä½ç½®æ§åˆ¶",
      "authors": [
        "Jessica Bader",
        "Mateusz Pach",
        "Maria A. Bravo",
        "Serge Belongie",
        "Zeynep Akata"
      ],
      "abstract": "Text-to-Image (T2I) generation models have advanced rapidly in recent years, but accurately capturing spatial relationships like \"above\" or \"to the right of\" poses a persistent challenge. Earlier methods improved spatial relationship following with external position control. However, as architectures evolved to enhance image quality, these techniques became incompatible with modern models. We propose Stitch, a training-free method for incorporating external position control into Multi-Modal Diffusion Transformers (MMDiT) via automatically-generated bounding boxes. Stitch produces images that are both spatially accurate and visually appealing by generating individual objects within designated bounding boxes and seamlessly stitching them together. We find that targeted attention heads capture the information necessary to isolate and cut out individual objects mid-generation, without needing to fully complete the image. We evaluate Stitch on PosEval, our benchmark for position-based T2I generation. Featuring five new tasks that extend the concept of Position beyond the basic GenEval task, PosEval demonstrates that even top models still have significant room for improvement in position-based generation. Tested on Qwen-Image, FLUX, and SD3.5, Stitch consistently enhances base models, even improving FLUX by 218% on GenEval's Position task and by 206% on PosEval. Stitch achieves state-of-the-art results with Qwen-Image on PosEval, improving over previous models by 54%, all accomplished while integrating position control into leading models training-free. Code is available at https://github.com/ExplainableML/Stitch.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ–‡æœ¬ç”Ÿæˆå›¾åƒ (Text-to-Image) æ¨¡å‹åœ¨å¤„ç†ç©ºé—´å…³ç³»æ—¶çš„å±€é™æ€§ï¼Œæå‡ºäº† Stitchï¼Œä¸€ç§æ— éœ€è®­ç»ƒ (training-free) çš„åœ¨å¤šæ¨¡æ€æ‰©æ•£ Transformer (Multi-Modal Diffusion Transformers, MMDiT) ä¸­å®ç°ä½ç½®æ§åˆ¶çš„æ–¹æ³•ã€‚Stitch é€šè¿‡è‡ªåŠ¨ç”Ÿæˆçš„è¾¹ç•Œæ¡† (bounding boxes) åœ¨æŒ‡å®šåŒºåŸŸå†…ç”Ÿæˆå•ä¸ªå¯¹è±¡å¹¶è¿›è¡Œç¼åˆ (stitching)ï¼Œä»è€Œåœ¨ä¿è¯è§†è§‰è´¨é‡çš„åŒæ—¶æ˜¾è‘—æå‡ç©ºé—´å‡†ç¡®æ€§ã€‚ç ”ç©¶å‘ç°ç‰¹å®šçš„æ³¨æ„åŠ›å¤´ (attention heads) èƒ½å¤Ÿåœ¨ç”Ÿæˆä¸­æœŸæ•è·å¹¶åˆ†ç¦»å•ä¸ªå¯¹è±¡ï¼Œæ— éœ€å®Œæˆæ•´å¹…å›¾åƒçš„ç”Ÿæˆã€‚æ­¤å¤–ï¼Œç ”ç©¶è€…æ¨å‡ºäº† PosEval åŸºå‡†æµ‹è¯•ï¼ŒåŒ…å«äº”ä¸ªæ‰©å±•ä½ç½®æ¦‚å¿µçš„æ–°ä»»åŠ¡ï¼Œä»¥è¯„ä¼°æ¨¡å‹åœ¨å¤æ‚ç©ºé—´ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒStitch æ˜¾è‘—å¢å¼ºäº† FLUXã€SD3.5 å’Œ Qwen-Image ç­‰é¡¶å°–æ¨¡å‹ï¼Œå…¶ä¸­ FLUX åœ¨ GenEval ä½ç½®ä»»åŠ¡ä¸Šçš„è¡¨ç°æå‡äº† 218%ã€‚Stitch åœ¨ä¸æ”¹å˜æ¨¡å‹æƒé‡çš„æƒ…å†µä¸‹ï¼Œå‡­å€Ÿ Qwen-Image åœ¨ PosEval ä¸Šè¾¾åˆ°äº†å½“å‰æœ€å…ˆè¿›æ°´å¹³ (SOTA)ï¼Œè¯æ˜äº†è¯¥æ–¹æ³•åœ¨ç°ä»£æ¶æ„ä¸­çš„é€šç”¨æ€§ä¸é«˜æ•ˆæ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Preprint",
      "pdf_url": "https://arxiv.org/pdf/2509.26644v1",
      "published_date": "2025-09-30 17:59:51 UTC",
      "updated_date": "2025-09-30 17:59:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:27:28.288826+00:00"
    },
    {
      "arxiv_id": "2509.26633v2",
      "title": "OmniRetarget: Interaction-Preserving Data Generation for Humanoid Whole-Body Loco-Manipulation and Scene Interaction",
      "title_zh": "OmniRetargetï¼šé¢å‘ç±»äººæœºå™¨äººå…¨èº«ç§»åŠ¨æ“ä½œä¸åœºæ™¯äº¤äº’çš„äº¤äº’ä¿æŒå‹æ•°æ®ç”Ÿæˆ",
      "authors": [
        "Lujie Yang",
        "Xiaoyu Huang",
        "Zhen Wu",
        "Angjoo Kanazawa",
        "Pieter Abbeel",
        "Carmelo Sferrazza",
        "C. Karen Liu",
        "Rocky Duan",
        "Guanya Shi"
      ],
      "abstract": "A dominant paradigm for teaching humanoid robots complex skills is to retarget human motions as kinematic references to train reinforcement learning (RL) policies. However, existing retargeting pipelines often struggle with the significant embodiment gap between humans and robots, producing physically implausible artifacts like foot-skating and penetration. More importantly, common retargeting methods neglect the rich human-object and human-environment interactions essential for expressive locomotion and loco-manipulation. To address this, we introduce OmniRetarget, an interaction-preserving data generation engine based on an interaction mesh that explicitly models and preserves the crucial spatial and contact relationships between an agent, the terrain, and manipulated objects. By minimizing the Laplacian deformation between the human and robot meshes while enforcing kinematic constraints, OmniRetarget generates kinematically feasible trajectories. Moreover, preserving task-relevant interactions enables efficient data augmentation, from a single demonstration to different robot embodiments, terrains, and object configurations. We comprehensively evaluate OmniRetarget by retargeting motions from OMOMO, LAFAN1, and our in-house MoCap datasets, generating over 8-hour trajectories that achieve better kinematic constraint satisfaction and contact preservation than widely used baselines. Such high-quality data enables proprioceptive RL policies to successfully execute long-horizon (up to 30 seconds) parkour and loco-manipulation skills on a Unitree G1 humanoid, trained with only 5 reward terms and simple domain randomization shared by all tasks, without any learning curriculum.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† OmniRetargetï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨è§£å†³äººå½¢æœºå™¨äººå…¨èº«ç§»åŠ¨æ“ä½œï¼ˆloco-manipulationï¼‰ä¸åœºæ™¯äº¤äº’ä¸­è¿åŠ¨é‡å®šå‘ï¼ˆretargetingï¼‰éš¾é¢˜çš„äº¤äº’ä¿ç•™æ•°æ®ç”Ÿæˆå¼•æ“ã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•åœ¨å¤„ç†äººç±»ä¸æœºå™¨äººå½¢æ€å·®å¼‚ï¼ˆembodiment gapï¼‰æ—¶å®¹æ˜“äº§ç”Ÿç‰©ç†ä¸åˆç†ç°è±¡ä¸”å¿½è§†äº¤äº’å…³ç³»çš„é—®é¢˜ï¼Œè¯¥æ¡†æ¶å¼•å…¥äº†äº¤äº’ç½‘æ ¼ï¼ˆinteraction meshï¼‰ï¼Œé€šè¿‡æ˜¾å¼å»ºæ¨¡å¹¶ä¿ç•™æ™ºèƒ½ä½“ã€åœ°å½¢ä¸ç‰©ä½“ä¹‹é—´çš„ç©ºé—´å’Œæ¥è§¦å…³ç³»æ¥ç¡®ä¿è¿åŠ¨è´¨é‡ã€‚é€šè¿‡åœ¨å¼ºåˆ¶æ‰§è¡Œè¿åŠ¨å­¦çº¦æŸçš„åŒæ—¶æœ€å°åŒ–äººç±»ä¸æœºå™¨äººç½‘æ ¼ä¹‹é—´çš„ Laplacian deformationï¼ŒOmniRetarget èƒ½å¤Ÿç”Ÿæˆç‰©ç†å¯è¡Œçš„è½¨è¿¹ï¼Œå¹¶æ”¯æŒä»å•ä¸€æ¼”ç¤ºåˆ°ä¸åŒæœºå™¨äººå½¢æ€ã€åœ°å½¢å’Œç‰©ä½“é…ç½®çš„é«˜æ•ˆæ•°æ®å¢å¼ºã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥å¼•æ“ç”Ÿæˆçš„è¶…è¿‡ 8 å°æ—¶çš„é«˜è´¨é‡è½¨è¿¹æ•°æ®åœ¨è¿åŠ¨å­¦çº¦æŸæ»¡è¶³å’Œæ¥è§¦ä¿ç•™æ–¹é¢å‡ä¼˜äºåŸºå‡†æ¨¡å‹ã€‚åˆ©ç”¨è¯¥æ•°æ®è®­ç»ƒçš„æœ¬ä½“æ„Ÿå—å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ç­–ç•¥ï¼Œä½¿ Unitree G1 äººå½¢æœºå™¨äººåœ¨æ— éœ€å­¦ä¹ è¯¾ç¨‹çš„æƒ…å†µä¸‹ï¼ŒæˆåŠŸå®ç°äº†é•¿è¾¾ 30 ç§’çš„é•¿ç¨‹è·‘é…·å’Œå¤æ‚çš„å…¨èº«ç§»åŠ¨æ“ä½œä»»åŠ¡ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "Project website: https://omniretarget.github.io",
      "pdf_url": "https://arxiv.org/pdf/2509.26633v2",
      "published_date": "2025-09-30 17:59:02 UTC",
      "updated_date": "2025-10-08 23:16:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:27:17.690810+00:00"
    },
    {
      "arxiv_id": "2509.26632v1",
      "title": "Branching Out: Broadening AI Measurement and Evaluation with Measurement Trees",
      "title_zh": "æ‹“å±•è¾¹ç•Œï¼šåˆ©ç”¨æµ‹é‡æ ‘æ‹“å®½ AI æµ‹é‡ä¸è¯„ä¼°",
      "authors": [
        "Craig Greenberg",
        "Patrick Hall",
        "Theodore Jensen",
        "Kristen Greene",
        "Razvan Amironesei"
      ],
      "abstract": "This paper introduces \\textit{measurement trees}, a novel class of metrics designed to combine various constructs into an interpretable multi-level representation of a measurand. Unlike conventional metrics that yield single values, vectors, surfaces, or categories, measurement trees produce a hierarchical directed graph in which each node summarizes its children through user-defined aggregation methods. In response to recent calls to expand the scope of AI system evaluation, measurement trees enhance metric transparency and facilitate the integration of heterogeneous evidence, including, e.g., agentic, business, energy-efficiency, sociotechnical, or security signals. We present definitions and examples, demonstrate practical utility through a large-scale measurement exercise, and provide accompanying open-source Python code. By operationalizing a transparent approach to measurement of complex constructs, this work offers a principled foundation for broader and more interpretable AI evaluation.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼•å…¥äº† measurement treesï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨å°†å„ç§æ„æƒ³ç»„åˆæˆå¯è§£é‡Šçš„å¤šå±‚æ¬¡åº¦é‡å¯¹è±¡ï¼ˆmeasurandï¼‰è¡¨ç¤ºçš„æ–°å‹åº¦é‡æ–¹æ³•ã€‚ä¸äº§ç”Ÿå•ä¸€æ•°å€¼æˆ–å‘é‡çš„ä¼ ç»ŸæŒ‡æ ‡ä¸åŒï¼Œmeasurement trees ç”Ÿæˆä¸€ä¸ªå±‚æ¬¡åŒ–çš„æœ‰å‘å›¾ï¼Œå…¶ä¸­æ¯ä¸ªèŠ‚ç‚¹é€šè¿‡ç”¨æˆ·å®šä¹‰çš„èšåˆæ–¹æ³•å¯¹å…¶å­èŠ‚ç‚¹è¿›è¡Œæ€»ç»“ã€‚ä¸ºäº†å“åº”æ‰©å±• AI ç³»ç»Ÿè¯„ä¼°èŒƒå›´çš„å‘¼åï¼Œè¯¥æ¡†æ¶å¢å¼ºäº†åº¦é‡é€æ˜åº¦ï¼Œå¹¶ä¿ƒè¿›äº†åŒ…æ‹¬ agenticã€businessã€energy-efficiencyã€sociotechnical æˆ– security ä¿¡å·åœ¨å†…çš„å¼‚è´¨è¯æ®çš„æ•´åˆã€‚ä½œè€…åœ¨è®ºæ–‡ä¸­æä¾›äº†ç›¸å…³å®šä¹‰å’Œç¤ºä¾‹ï¼Œé€šè¿‡å¤§è§„æ¨¡æµ‹é‡å®è·µå±•ç¤ºäº†å…¶å®ç”¨ä»·å€¼ï¼Œå¹¶å‘å¸ƒäº†é…å¥—çš„å¼€æº Python ä»£ç ã€‚é€šè¿‡å°†å¤æ‚æ„æƒ³çš„æµ‹é‡æ–¹æ³•é€æ˜åŒ–å’Œæ“ä½œåŒ–ï¼Œè¯¥ç ”ç©¶ä¸ºæ›´å¹¿æ³›ä¸”æ›´å…·å¯è§£é‡Šæ€§çš„ AI è¯„ä¼°å¥ å®šäº†åŸåˆ™æ€§åŸºç¡€ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.26632v1",
      "published_date": "2025-09-30 17:58:59 UTC",
      "updated_date": "2025-09-30 17:58:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:27:39.584217+00:00"
    },
    {
      "arxiv_id": "2509.26631v3",
      "title": "Learning Generalizable Shape Completion with SIM(3) Equivariance",
      "title_zh": "åŸºäº SIM(3) ç­‰å˜æ€§çš„å¯æ³›åŒ–å½¢çŠ¶è¡¥å…¨å­¦ä¹ ",
      "authors": [
        "Yuqing Wang",
        "Zhaiyu Chen",
        "Xiao Xiang Zhu"
      ],
      "abstract": "3D shape completion methods typically assume scans are pre-aligned to a canonical frame. This leaks pose and scale cues that networks may exploit to memorize absolute positions rather than inferring intrinsic geometry. When such alignment is absent in real data, performance collapses. We argue that robust generalization demands architectural equivariance to the similarity group, SIM(3), so the model remains agnostic to pose and scale. Following this principle, we introduce the first SIM(3)-equivariant shape completion network, whose modular layers successively canonicalize features, reason over similarity-invariant geometry, and restore the original frame. Under a de-biased evaluation protocol that removes the hidden cues, our model outperforms both equivariant and augmentation baselines on the PCN benchmark. It also sets new cross-domain records on real driving and indoor scans, lowering minimal matching distance on KITTI by 17% and Chamfer distance $\\ell1$ on OmniObject3D by 14%. Perhaps surprisingly, ours under the stricter protocol still outperforms competitors under their biased settings. These results establish full SIM(3) equivariance as an effective route to truly generalizable shape completion. Project page: https://sime-completion.github.io.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†é¦–ä¸ªå…·æœ‰ SIM(3) ç­‰å˜æ€§ (Equivariance) çš„ä¸‰ç»´å½¢çŠ¶è¡¥å…¨ç½‘ç»œï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿæ–¹æ³•å› è¿‡åº¦ä¾èµ–é¢„å¯¹é½çš„è§„èŒƒåŒ–åæ ‡ç³»è€Œå¯¼è‡´çš„æ³›åŒ–æ€§å·®çš„é—®é¢˜ã€‚ä¼ ç»Ÿæ¨¡å‹å¾€å¾€é€šè¿‡è®°å¿†ç»å¯¹ä½ç½®è€Œéæ¨ç†å†…åœ¨å‡ ä½•ç‰¹å¾æ¥å¤„ç†æ•°æ®ï¼Œå½“å®é™…åœºæ™¯ä¸­ç¼ºä¹å§¿æ€å’Œå°ºåº¦å¯¹é½æ—¶ï¼Œå…¶æ€§èƒ½ä¼šå¤§å¹…ä¸‹é™ã€‚è¯¥æ¨¡å‹é€šè¿‡æ¨¡å—åŒ–å±‚ç»“æ„ä¾æ¬¡å®ç°ç‰¹å¾è§„èŒƒåŒ–ã€åœ¨ç›¸ä¼¼æ€§å˜æ¢ä¸å˜çš„å‡ ä½•ç©ºé—´å†…è¿›è¡Œæ¨ç†å¹¶æ¢å¤åŸå§‹åæ ‡ç³»ï¼Œç¡®ä¿æ¨¡å‹å¯¹å§¿æ€å’Œå°ºåº¦ä¿æŒä¸å¯çŸ¥æ€§ã€‚åœ¨æ¶ˆé™¤åè§çº¿ç´¢çš„ä¸¥æ ¼è¯„ä¼°ä¸‹ï¼Œè¯¥æ¨¡å‹åœ¨ PCN åŸºå‡†æµ‹è¯•ä¸­ä¼˜äºç°æœ‰çš„ç­‰å˜æ¨¡å‹å’Œå¢å¼ºåŸºçº¿ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨ KITTI çœŸå®é©¾é©¶æ•°æ®ä¸Šé™ä½äº† 17% çš„æœ€å°åŒ¹é…è·ç¦»ï¼Œå¹¶åœ¨ OmniObject3D æ•°æ®é›†ä¸Šå°† Chamfer distance $\\ell1$ é™ä½äº† 14%ï¼Œåˆ·æ–°äº†å¤šé¡¹è·¨åŸŸæ³›åŒ–è®°å½•ã€‚è¿™äº›æˆæœè¯æ˜äº†å®Œæ•´çš„ SIM(3) ç­‰å˜æ€§æ˜¯å®ç°å…·æœ‰å¼ºæ³›åŒ–èƒ½åŠ›çš„ä¸‰ç»´å½¢çŠ¶è¡¥å…¨çš„å…³é”®è·¯å¾„ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "NeurIPS 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.26631v3",
      "published_date": "2025-09-30 17:58:55 UTC",
      "updated_date": "2025-12-11 06:52:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:27:38.093271+00:00"
    },
    {
      "arxiv_id": "2509.26627v1",
      "title": "TimeRewarder: Learning Dense Reward from Passive Videos via Frame-wise Temporal Distance",
      "title_zh": "TimeRewarderï¼šåŸºäºå¸§é—´æ—¶é—´è·ç¦»ä»è¢«åŠ¨è§†é¢‘ä¸­å­¦ä¹ ç¨ å¯†å¥–åŠ±",
      "authors": [
        "Yuyang Liu",
        "Chuan Wen",
        "Yihang Hu",
        "Dinesh Jayaraman",
        "Yang Gao"
      ],
      "abstract": "Designing dense rewards is crucial for reinforcement learning (RL), yet in robotics it often demands extensive manual effort and lacks scalability. One promising solution is to view task progress as a dense reward signal, as it quantifies the degree to which actions advance the system toward task completion over time. We present TimeRewarder, a simple yet effective reward learning method that derives progress estimation signals from passive videos, including robot demonstrations and human videos, by modeling temporal distances between frame pairs. We then demonstrate how TimeRewarder can supply step-wise proxy rewards to guide reinforcement learning. In our comprehensive experiments on ten challenging Meta-World tasks, we show that TimeRewarder dramatically improves RL for sparse-reward tasks, achieving nearly perfect success in 9/10 tasks with only 200,000 interactions per task with the environment. This approach outperformed previous methods and even the manually designed environment dense reward on both the final success rate and sample efficiency. Moreover, we show that TimeRewarder pretraining can exploit real-world human videos, highlighting its potential as a scalable approach path to rich reward signals from diverse video sources.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†TimeRewarderï¼Œä¸€ç§é€šè¿‡å»ºæ¨¡å¸§é—´æ—¶é—´è·ç¦»(Frame-wise Temporal Distance)ä»åŒ…æ‹¬æœºå™¨äººæ¼”ç¤ºå’Œäººç±»è§†é¢‘åœ¨å†…çš„è¢«åŠ¨è§†é¢‘(Passive Videos)ä¸­å­¦ä¹ ç¨ å¯†å¥–åŠ±(Dense Reward)çš„æœ‰æ•ˆæ–¹æ³•ã€‚é’ˆå¯¹æœºå™¨äººå¼ºåŒ–å­¦ä¹ (Reinforcement Learning)ä¸­æ‰‹åŠ¨è®¾è®¡å¥–åŠ±è€—æ—¶ä¸”éš¾ä»¥æ‰©å±•çš„æŒ‘æˆ˜ï¼Œè¯¥æ–¹æ³•å°†ä»»åŠ¡è¿›åº¦(Task Progress)å»ºæ¨¡ä¸ºå¥–åŠ±ä¿¡å·ï¼Œä»¥è¡¡é‡åŠ¨ä½œéšæ—¶é—´æ¨è¿›ä»»åŠ¡å®Œæˆçš„ç¨‹åº¦ã€‚åœ¨åé¡¹æŒ‘æˆ˜æ€§çš„Meta-Worldä»»åŠ¡å®éªŒä¸­ï¼ŒTimeRewarderåœ¨ä»…æœ‰20ä¸‡æ¬¡ç¯å¢ƒäº¤äº’çš„æƒ…å†µä¸‹ï¼Œå°±åœ¨å…¶ä¸­9é¡¹ä»»åŠ¡ä¸­å®ç°äº†æ¥è¿‘å®Œç¾çš„æˆåŠŸç‡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨æœ€ç»ˆæˆåŠŸç‡å’Œæ ·æœ¬æ•ˆç‡(Sample Efficiency)ä¸Šå‡ä¼˜äºæ­¤å‰çš„æ–¹æ³•ä»¥åŠæ‰‹åŠ¨è®¾è®¡çš„ç¨ å¯†å¥–åŠ±ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¯æ˜TimeRewarderå¯ä»¥é€šè¿‡é¢„è®­ç»ƒåˆ©ç”¨çœŸå®ä¸–ç•Œçš„äººç±»è§†é¢‘ï¼Œå±•ç¤ºäº†ä»å¤šæ ·åŒ–è§†é¢‘æºè§„æ¨¡åŒ–è·å–ä¸°å¯Œå¥–åŠ±ä¿¡å·çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.26627v1",
      "published_date": "2025-09-30 17:58:20 UTC",
      "updated_date": "2025-09-30 17:58:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:27:57.494565+00:00"
    },
    {
      "arxiv_id": "2509.26625v1",
      "title": "Learning to See Before Seeing: Demystifying LLM Visual Priors from Language Pre-training",
      "title_zh": "æœªè§å…ˆè¯†ï¼šæ­ç§˜å¤§è¯­è¨€æ¨¡å‹è¯­è¨€é¢„è®­ç»ƒä¸­çš„è§†è§‰å…ˆéªŒ",
      "authors": [
        "Junlin Han",
        "Shengbang Tong",
        "David Fan",
        "Yufan Ren",
        "Koustuv Sinha",
        "Philip Torr",
        "Filippos Kokkinos"
      ],
      "abstract": "Large Language Models (LLMs), despite being trained on text alone, surprisingly develop rich visual priors. These priors allow latent visual capabilities to be unlocked for vision tasks with a relatively small amount of multimodal data, and in some cases, to perform visual tasks without ever having seen an image. Through systematic analysis, we reveal that visual priors-the implicit, emergent knowledge about the visual world acquired during language pre-training-are composed of separable perception and reasoning priors with unique scaling trends and origins. We show that an LLM's latent visual reasoning ability is predominantly developed by pre-training on reasoning-centric data (e.g., code, math, academia) and scales progressively. This reasoning prior acquired from language pre-training is transferable and universally applicable to visual reasoning. In contrast, a perception prior emerges more diffusely from broad corpora, and perception ability is more sensitive to the vision encoder and visual instruction tuning data. In parallel, text describing the visual world proves crucial, though its performance impact saturates rapidly. Leveraging these insights, we propose a data-centric recipe for pre-training vision-aware LLMs and verify it in 1T token scale pre-training. Our findings are grounded in over 100 controlled experiments consuming 500,000 GPU-hours, spanning the full MLLM construction pipeline-from LLM pre-training to visual alignment and supervised multimodal fine-tuning-across five model scales, a wide range of data categories and mixtures, and multiple adaptation setups. Along with our main findings, we propose and investigate several hypotheses, and introduce the Multi-Level Existence Bench (MLE-Bench). Together, this work provides a new way of deliberately cultivating visual priors from language pre-training, paving the way for the next generation of multimodal LLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶æ­ç¤ºäº†å¤§è¯­è¨€æ¨¡å‹ (LLMs) å³ä½¿ä»…åœ¨æ–‡æœ¬æ•°æ®ä¸Šè®­ç»ƒï¼Œä¹Ÿèƒ½é€šè¿‡è¯­è¨€é¢„è®­ç»ƒå½¢æˆåŒ…å«æ„ŸçŸ¥å’Œæ¨ç†çš„è§†è§‰å…ˆéªŒ (Visual Priors)ã€‚ç ”ç©¶é€šè¿‡ç³»ç»Ÿåˆ†æå‘ç°ï¼ŒLLMs çš„æ½œåœ¨è§†è§‰æ¨ç†èƒ½åŠ› (Visual Reasoning Ability) ä¸»è¦æºäºä»£ç ã€æ•°å­¦ç­‰æ¨ç†å‹æ•°æ®ï¼Œä¸”å…·å¤‡é€šç”¨è¿ç§»èƒ½åŠ›ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œæ„ŸçŸ¥å…ˆéªŒ (Perception Prior) å±•ç°å‡ºä¸åŒçš„æ¼”åŒ–è§„å¾‹ï¼Œä¸”å¯¹è§†è§‰ç¼–ç å™¨ (Vision Encoder) å’ŒæŒ‡ä»¤å¾®è°ƒæ•°æ®æ›´ä¸ºæ•æ„Ÿã€‚åŸºäºè¿™äº›è§è§£ï¼Œä½œè€…æå‡ºäº†ä¸€ç§ä»¥æ•°æ®ä¸ºä¸­å¿ƒçš„æ–¹æ³•æ¥é¢„è®­ç»ƒè§†è§‰æ„ŸçŸ¥å‹ LLMsï¼Œå¹¶åœ¨ 1T token è§„æ¨¡çš„é¢„è®­ç»ƒä¸­éªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚è¯¥å·¥ä½œåŸºäºæ¶µç›– 100 å¤šé¡¹æ§åˆ¶å®éªŒå’Œ 50 ä¸‡ GPU å°æ—¶çš„æ·±å…¥ç ”ç©¶ï¼Œå¼•å…¥äº† Multi-Level Existence Bench (MLE-Bench) è¯„æµ‹åŸºå‡†ã€‚è¿™é¡¹ç ”ç©¶ä¸ºä»è¯­è¨€é¢„è®­ç»ƒä¸­åˆ»æ„åŸ¹å…»è§†è§‰å…ˆéªŒæä¾›äº†æ–°è·¯å¾„ï¼Œä¸ºå¼€å‘ä¸‹ä¸€ä»£å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ (MLLMs) å¥ å®šäº†é‡è¦åŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.MM"
      ],
      "primary_category": "cs.LG",
      "comment": "Project page: https://junlinhan.github.io/projects/lsbs/",
      "pdf_url": "https://arxiv.org/pdf/2509.26625v1",
      "published_date": "2025-09-30 17:57:44 UTC",
      "updated_date": "2025-09-30 17:57:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:28:02.691690+00:00"
    },
    {
      "arxiv_id": "2509.26619v1",
      "title": "Searching for Difficult-to-Translate Test Examples at Scale",
      "title_zh": "å¤§è§„æ¨¡æœç´¢éš¾è¯‘æµ‹è¯•æ ·æœ¬",
      "authors": [
        "Wenda Xu",
        "VilÃ©m Zouhar",
        "Parker Riley",
        "Mara Finkelstein",
        "Markus Freitag",
        "Daniel Deutsch"
      ],
      "abstract": "NLP models require test data that are sufficiently challenging. The difficulty of an example is linked to the topic it originates from (''seed topic''). The relationship between the topic and the difficulty of its instances is stochastic in nature: an example about a difficult topic can happen to be easy, and vice versa. At the scale of the Internet, there are tens of thousands of potential topics, and finding the most difficult one by drawing and evaluating a large number of examples across all topics is computationally infeasible. We formalize this task and treat it as a multi-armed bandit problem. In this framework, each topic is an ''arm,'' and pulling an arm (at a cost) involves drawing a single example, evaluating it, and measuring its difficulty. The goal is to efficiently identify the most difficult topics within a fixed computational budget. We illustrate the bandit problem setup of finding difficult examples for the task of machine translation. We find that various bandit strategies vastly outperform baseline methods like brute-force searching the most challenging topics.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹NLPæ¨¡å‹éœ€è¦é«˜æŒ‘æˆ˜æ€§æµ‹è¯•æ•°æ®çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§å¤§è§„æ¨¡æœç´¢éš¾ä»¥ç¿»è¯‘æµ‹è¯•æ ·ä¾‹çš„æ–¹æ³•ã€‚ä½œè€…å‘ç°æ ·ä¾‹éš¾åº¦ä¸å…¶seed topicç›¸å…³ï¼Œä½†ç”±äºè¿™ç§éšæœºå…³ç³»ä»¥åŠäº’è”ç½‘è§„æ¨¡ä¸‹æµ·é‡çš„ä¸»é¢˜æ•°é‡ï¼Œç›´æ¥è¯„ä¼°æ‰€æœ‰ä¸»é¢˜åœ¨è®¡ç®—ä¸Šå¹¶ä¸å¯è¡Œã€‚ä¸ºæ­¤ï¼Œè¯¥ç ”ç©¶å°†å¯»æ‰¾å›°éš¾æ ·ä¾‹çš„ä»»åŠ¡å½¢å¼åŒ–ä¸ºmulti-armed bandit problemï¼Œå°†æ¯ä¸ªä¸»é¢˜è§†ä¸ºä¸€ä¸ªarmï¼Œé€šè¿‡åœ¨å›ºå®šè®¡ç®—é¢„ç®—å†…æŠ½å–å¹¶è¯„ä¼°æ ·ä¾‹æ¥è¯†åˆ«æœ€å›°éš¾çš„ä¸»é¢˜ã€‚é€šè¿‡åœ¨machine translationä»»åŠ¡ä¸Šçš„å®éªŒéªŒè¯ï¼Œç ”ç©¶å‘ç°å¤šç§bandit strategiesåœ¨å¯»æ‰¾æŒ‘æˆ˜æ€§ä¸»é¢˜æ—¶çš„æ•ˆç‡æ˜¾è‘—ä¼˜äºbrute-force searchingç­‰åŸºå‡†æ–¹æ³•ã€‚è¯¥ç ”ç©¶ä¸ºåœ¨å¤§è§„æ¨¡æ•°æ®èƒŒæ™¯ä¸‹é«˜æ•ˆæ„å»ºé«˜è´¨é‡æµ‹è¯•é›†ä»¥åŠè¯„ä¼°æ¨¡å‹é²æ£’æ€§æä¾›äº†æ–°çš„æ–¹æ³•è®ºæ”¯æŒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.26619v1",
      "published_date": "2025-09-30 17:55:47 UTC",
      "updated_date": "2025-09-30 17:55:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:27:56.993280+00:00"
    },
    {
      "arxiv_id": "2509.26605v2",
      "title": "Fine-tuning Behavioral Cloning Policies with Preference-Based Reinforcement Learning",
      "title_zh": "åˆ©ç”¨åŸºäºåå¥½çš„å¼ºåŒ–å­¦ä¹ å¾®è°ƒè¡Œä¸ºå…‹éš†ç­–ç•¥",
      "authors": [
        "MaÃ«l Macuglia",
        "Paul Friedrich",
        "Giorgia Ramponi"
      ],
      "abstract": "Deploying reinforcement learning (RL) in robotics, industry, and health care is blocked by two obstacles: the difficulty of specifying accurate rewards and the risk of unsafe, data-hungry exploration. We address this by proposing a two-stage framework that first learns a safe initial policy from a reward-free dataset of expert demonstrations, then fine-tunes it online using preference-based human feedback. We provide the first principled analysis of this offline-to-online approach and introduce BRIDGE, a unified algorithm that integrates both signals via an uncertainty-weighted objective. We derive regret bounds that shrink with the number of offline demonstrations, explicitly connecting the quantity of offline data to online sample efficiency. We validate BRIDGE in discrete and continuous control MuJoCo environments, showing it achieves lower regret than both standalone behavioral cloning and online preference-based RL. Our work establishes a theoretical foundation for designing more sample-efficient interactive agents.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)åœ¨å®é™…åº”ç”¨ä¸­é¢ä¸´çš„å¥–åŠ±å‡½æ•°è®¾å®šéš¾ä»¥åŠæ¢ç´¢è¿‡ç¨‹ä¸å®‰å…¨ã€è€—æ—¶é•¿ç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ä¸ªä¸¤é˜¶æ®µçš„é€šç”¨æ¡†æ¶ã€‚è¯¥æ¡†æ¶é¦–å…ˆä»æ— å¥–åŠ±çš„ä¸“å®¶æ¼”ç¤ºæ•°æ®é›†ä¸­é€šè¿‡è¡Œä¸ºå…‹éš†(Behavioral Cloning)å­¦ä¹ ä¸€ä¸ªå®‰å…¨çš„åˆå§‹ç­–ç•¥ï¼Œéšååˆ©ç”¨åŸºäºåå¥½çš„äººç±»åé¦ˆ(Preference-Based Reinforcement Learning)è¿›è¡Œåœ¨çº¿å¾®è°ƒã€‚ç ”ç©¶è€…å¼•å…¥äº†åä¸ºBRIDGEçš„ç»Ÿä¸€ç®—æ³•ï¼Œåˆ©ç”¨ä¸ç¡®å®šæ€§æƒé‡ç›®æ ‡(Uncertainty-Weighted Objective)æœ‰æ•ˆæ•´åˆä¸“å®¶æ¼”ç¤ºä¸äººç±»åå¥½ä¸¤ç§ä¿¡å·ã€‚è¯¥å·¥ä½œå¯¹è¿™ç§ç¦»çº¿åˆ°åœ¨çº¿(Offline-to-Online)çš„æ–¹æ³•è¿›è¡Œäº†åŸç†æ€§åˆ†æï¼Œå¹¶æ¨å¯¼å‡ºäº†éšç¦»çº¿æ¼”ç¤ºæ•°é‡å¢åŠ è€Œç¼©å°çš„é—æ†¾è¾¹ç•Œ(Regret Bounds)ï¼Œå»ºç«‹äº†ç¦»çº¿æ•°æ®é‡ä¸åœ¨çº¿é‡‡æ ·æ•ˆç‡ä¹‹é—´çš„ç†è®ºè”ç³»ã€‚åœ¨MuJoCoç¦»æ•£ä¸è¿ç»­æ§åˆ¶ç¯å¢ƒä¸‹çš„å®éªŒè¡¨æ˜ï¼ŒBRIDGEçš„æ€§èƒ½ä¼˜äºå•çº¯çš„è¡Œä¸ºå…‹éš†æˆ–åœ¨çº¿åå¥½å¼ºåŒ–å­¦ä¹ ã€‚è¯¥ç ”ç©¶ä¸ºå¼€å‘é«˜é‡‡æ ·æ•ˆç‡çš„äº¤äº’å¼æ™ºèƒ½ä½“æä¾›äº†åšå®çš„ç†è®ºæ”¯æ’‘ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "85 pages (11 + references and appendix), 9 figures. v2: added acknowledgements",
      "pdf_url": "https://arxiv.org/pdf/2509.26605v2",
      "published_date": "2025-09-30 17:50:19 UTC",
      "updated_date": "2025-10-13 13:00:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:28:03.991667+00:00"
    },
    {
      "arxiv_id": "2509.26601v2",
      "title": "MENLO: From Preferences to Proficiency -- Evaluating and Modeling Native-like Quality Across 47 Languages",
      "title_zh": "MENLOï¼šä»åå¥½åˆ°ç²¾é€šâ€”â€”47ç§è¯­è¨€ç±»æ¯è¯­è´¨é‡çš„è¯„ä¼°ä¸å»ºæ¨¡",
      "authors": [
        "Chenxi Whitehouse",
        "Sebastian Ruder",
        "Tony Lin",
        "Oksana Kurylo",
        "Haruka Takagi",
        "Janice Lam",
        "NicolÃ² Busetto",
        "Denise Diaz",
        "Francisco GuzmÃ¡n"
      ],
      "abstract": "Ensuring native-like quality of large language model (LLM) responses across many languages is challenging. To address this, we introduce MENLO, a framework that operationalizes the evaluation of native-like response quality based on audience design-inspired mechanisms. Using MENLO, we create a dataset of 6,423 human-annotated prompt-response preference pairs covering four quality dimensions with high inter-annotator agreement in 47 language varieties. Our evaluation reveals that zero-shot LLM judges benefit significantly from pairwise evaluation and our structured annotation rubrics, yet they still underperform human annotators on our dataset. We demonstrate substantial improvements through fine-tuning with reinforcement learning, reward shaping, and multi-task learning approaches. Additionally, we show that RL-trained judges can serve as generative reward models to enhance LLMs' multilingual proficiency, though discrepancies with human judgment remain. Our findings suggest promising directions for scalable multilingual evaluation and preference alignment. We release our dataset and evaluation framework to support further research in multilingual LLM evaluation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†MENLOæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹(LLM)åœ¨å¤šç§è¯­è¨€ä¸­ç”Ÿæˆå…·å¤‡åŸç”Ÿè´¨é‡(native-like quality)å“åº”çš„æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶åŸºäºå—å—ä¼—è®¾è®¡(audience design)å¯å‘çš„æœºåˆ¶ï¼Œæ„å»ºäº†ä¸€ä¸ªåŒ…å«6,423å¯¹äººå·¥æ ‡æ³¨åå¥½å¯¹çš„æ•°æ®é›†ï¼Œæ¶µç›–47ç§è¯­è¨€å˜ä½“åŠå››ä¸ªè´¨é‡ç»´åº¦ã€‚è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œè™½ç„¶é›¶æ ·æœ¬(zero-shot)LLMè¯„åˆ¤å‘˜åœ¨é‡‡ç”¨æˆå¯¹è¯„ä¼°(pairwise evaluation)å’Œç»“æ„åŒ–è¯„ä¼°é‡è¡¨åè¡¨ç°æ˜¾è‘—æå‡ï¼Œä½†åœ¨è¯¥æ•°æ®é›†ä¸Šä»é€Šäºäººç±»æ ‡æ³¨å‘˜ã€‚ç ”ç©¶äººå‘˜è¿›ä¸€æ­¥é€šè¿‡å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)ã€å¥–åŠ±å¡‘é€ (reward shaping)å’Œå¤šä»»åŠ¡å­¦ä¹ (multi-task learning)ç­‰å¾®è°ƒæ–¹æ³•ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹æ€§èƒ½ã€‚æ­¤å¤–ï¼Œå®éªŒè¯æ˜ç»å¼ºåŒ–å­¦ä¹ è®­ç»ƒçš„è¯„åˆ¤å‘˜å¯ä½œä¸ºç”Ÿæˆå¼å¥–åŠ±æ¨¡å‹(generative reward models)æ¥å¢å¼ºLLMçš„å¤šè¯­è¨€ç†Ÿç»ƒåº¦ã€‚è¯¥ç ”ç©¶ä¸ºå®ç°å¯æ‰©å±•çš„å¤šè¯­è¨€è¯„ä¼°å’Œåå¥½å¯¹é½(preference alignment)æä¾›äº†é‡è¦è·¯å¾„ï¼Œå¹¶å…¬å¼€å‘å¸ƒäº†ç›¸å…³èµ„æºä»¥æ¨åŠ¨è¯¥é¢†åŸŸå‘å±•ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 23 tables, 17 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.26601v2",
      "published_date": "2025-09-30 17:48:58 UTC",
      "updated_date": "2025-11-11 10:36:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:28:05.292947+00:00"
    },
    {
      "arxiv_id": "2509.26600v1",
      "title": "Deconstructing Self-Bias in LLM-generated Translation Benchmarks",
      "title_zh": "è§£æ„ LLM ç”Ÿæˆçš„ç¿»è¯‘è¯„æµ‹åŸºå‡†ä¸­çš„è‡ªæˆ‘åè§",
      "authors": [
        "Wenda Xu",
        "Sweta Agrawal",
        "VilÃ©m Zouhar",
        "Markus Freitag",
        "Daniel Deutsch"
      ],
      "abstract": "As large language models (LLMs) begin to saturate existing benchmarks, automated benchmark creation using LLMs (LLM as a benchmark) has emerged as a scalable alternative to slow and costly human curation. While these generated test sets have to potential to cheaply rank models, we demonstrate a critical flaw. LLM generated benchmarks systematically favor the model that created the benchmark, they exhibit self bias on low resource languages to English translation tasks. We show three key findings on automatic benchmarking of LLMs for translation: First, this bias originates from two sources: the generated test data (LLM as a testset) and the evaluation method (LLM as an evaluator), with their combination amplifying the effect. Second, self bias in LLM as a benchmark is heavily influenced by the model's generation capabilities in the source language. For instance, we observe more pronounced bias in into English translation, where the model's generation system is developed, than in out of English translation tasks. Third, we observe that low diversity in source text is one attribution to self bias. Our results suggest that improving the diversity of these generated source texts can mitigate some of the observed self bias.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨è‡ªåŠ¨æ„å»ºç¿»è¯‘è¯„æµ‹åŸºå‡†æ—¶å­˜åœ¨çš„è‡ªæˆ‘åå¥½(self-bias)é—®é¢˜ï¼Œæ­ç¤ºäº†è¿™ç±»ç”Ÿæˆçš„æµ‹è¯•é›†ä¼šç³»ç»Ÿæ€§åœ°åå‘ç”Ÿæˆè¯¥åŸºå‡†çš„æ¨¡å‹ã€‚ç ”ç©¶æŒ‡å‡ºè¿™ç§åè§ä¸»è¦æºäºç”Ÿæˆçš„æµ‹è¯•æ•°æ®(LLM as a testset)å’Œè¯„ä¼°æ–¹æ³•(LLM as an evaluator)ä¸¤ä¸ªç»´åº¦ï¼Œä¸”äºŒè€…çš„ç»“åˆä¼šäº§ç”Ÿæ”¾å¤§æ•ˆåº”ã€‚ç ”ç©¶è¿›ä¸€æ­¥å‘ç°ï¼Œè‡ªæˆ‘åå¥½å—æ¨¡å‹åœ¨æºè¯­è¨€ä¸­çš„ç”Ÿæˆèƒ½åŠ›å½±å“ï¼Œåœ¨ä½èµ„æºè¯­è¨€ç¿»è¯‘æˆè‹±è¯­çš„ä»»åŠ¡ä¸­è¡¨ç°å°¤ä¸ºçªå‡ºã€‚æ­¤å¤–ï¼Œæºæ–‡æœ¬çš„å¤šæ ·æ€§ä¸è¶³(low diversity)ä¹Ÿæ˜¯å¯¼è‡´è‡ªæˆ‘åå¥½çš„é‡è¦åŸå› ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œé€šè¿‡æé«˜ç”Ÿæˆæºæ–‡æœ¬çš„å¤šæ ·æ€§å¯ä»¥æœ‰æ•ˆç¼“è§£è¿™ä¸€é—®é¢˜ï¼Œä¸ºæ„å»ºæ›´å…¬æ­£çš„è‡ªåŠ¨è¯„æµ‹åŸºå‡†æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.26600v1",
      "published_date": "2025-09-30 17:48:35 UTC",
      "updated_date": "2025-09-30 17:48:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:28:19.080439+00:00"
    },
    {
      "arxiv_id": "2509.26598v1",
      "title": "Are Robust LLM Fingerprints Adversarially Robust?",
      "title_zh": "é²æ£’çš„ LLM æŒ‡çº¹æ˜¯å¦å…·å¤‡å¯¹æŠ—é²æ£’æ€§ï¼Ÿ",
      "authors": [
        "Anshul Nasery",
        "Edoardo Contente",
        "Alkin Kaz",
        "Pramod Viswanath",
        "Sewoong Oh"
      ],
      "abstract": "Model fingerprinting has emerged as a promising paradigm for claiming model ownership. However, robustness evaluations of these schemes have mostly focused on benign perturbations such as incremental fine-tuning, model merging, and prompting. Lack of systematic investigations into {\\em adversarial robustness} against a malicious model host leaves current systems vulnerable. To bridge this gap, we first define a concrete, practical threat model against model fingerprinting. We then take a critical look at existing model fingerprinting schemes to identify their fundamental vulnerabilities. Based on these, we develop adaptive adversarial attacks tailored for each vulnerability, and demonstrate that these can bypass model authentication completely for ten recently proposed fingerprinting schemes while maintaining high utility of the model for the end users. Our work encourages fingerprint designers to adopt adversarial robustness by design. We end with recommendations for future fingerprinting methods.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)æŒ‡çº¹è¯†åˆ«(Model Fingerprinting)æŠ€æœ¯åœ¨é¢å¯¹æ¶æ„æ”»å‡»æ—¶çš„å¯¹æŠ—é²æ£’æ€§(Adversarial Robustness)ï¼ŒæŒ‡å‡ºç›®å‰çš„è¯„ä¼°ä¸»è¦å±€é™äºå¾®è°ƒå’Œæç¤ºè¯ç­‰è‰¯æ€§æ‰°åŠ¨ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€ç ”ç©¶ç¼ºå£ï¼Œä½œè€…å®šä¹‰äº†ä¸€ä¸ªå®é™…çš„å¨èƒæ¨¡å‹(Threat Model)ï¼Œå¹¶å¯¹ç°æœ‰æŒ‡çº¹è¯†åˆ«æ–¹æ¡ˆçš„æ ¹æœ¬æ€§å¼±ç‚¹è¿›è¡Œäº†æ‰¹åˆ¤æ€§åˆ†æã€‚ç ”ç©¶è€…é’ˆå¯¹è¿™äº›æ¼æ´å¼€å‘äº†å®šåˆ¶åŒ–çš„è‡ªé€‚åº”å¯¹æŠ—æ€§æ”»å‡»(Adaptive Adversarial Attacks)ï¼ŒæˆåŠŸéªŒè¯äº†è¿™äº›æ”»å‡»å¯ä»¥åœ¨ä¿æŒæ¨¡å‹å®ç”¨æ€§çš„åŒæ—¶å®Œå…¨ç»•è¿‡åç§æœ€æ–°çš„æŒ‡çº¹è®¤è¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œç°æœ‰ç³»ç»Ÿåœ¨é¢å¯¹æ¶æ„å¯¹æ‰‹æ—¶æå…¶è„†å¼±ã€‚è¯¥å·¥ä½œæ—¨åœ¨é¼“åŠ±æŒ‡çº¹è®¾è®¡è€…é‡‡ç”¨â€œå†…ç”Ÿå¯¹æŠ—é²æ£’æ€§â€çš„è®¾è®¡ç†å¿µï¼Œå¹¶ä¸ºæœªæ¥çš„é˜²å¾¡ç­–ç•¥æä¾›äº†æ”¹è¿›æ–¹å‘ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.26598v1",
      "published_date": "2025-09-30 17:47:09 UTC",
      "updated_date": "2025-09-30 17:47:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:28:24.470506+00:00"
    },
    {
      "arxiv_id": "2509.26584v1",
      "title": "Fairness Testing in Retrieval-Augmented Generation: How Small Perturbations Reveal Bias in Small Language Models",
      "title_zh": "æ£€ç´¢å¢å¼ºç”Ÿæˆä¸­çš„å…¬å¹³æ€§æµ‹è¯•ï¼šå¾®å°æ‰°åŠ¨å¦‚ä½•æ­ç¤ºå°è¯­è¨€æ¨¡å‹ä¸­çš„åè§",
      "authors": [
        "Matheus Vinicius da Silva de Oliveira",
        "Jonathan de Andrade Silva",
        "Awdren de Lima Fontao"
      ],
      "abstract": "Large Language Models (LLMs) are widely used across multiple domains but continue to raise concerns regarding security and fairness. Beyond known attack vectors such as data poisoning and prompt injection, LLMs are also vulnerable to fairness bugs. These refer to unintended behaviors influenced by sensitive demographic cues (e.g., race or sexual orientation) that should not affect outcomes. Another key issue is hallucination, where models generate plausible yet false information. Retrieval-Augmented Generation (RAG) has emerged as a strategy to mitigate hallucinations by combining external retrieval with text generation. However, its adoption raises new fairness concerns, as the retrieved content itself may surface or amplify bias. This study conducts fairness testing through metamorphic testing (MT), introducing controlled demographic perturbations in prompts to assess fairness in sentiment analysis performed by three Small Language Models (SLMs) hosted on HuggingFace (Llama-3.2-3B-Instruct, Mistral-7B-Instruct-v0.3, and Llama-3.1-Nemotron-8B), each integrated into a RAG pipeline. Results show that minor demographic variations can break up to one third of metamorphic relations (MRs). A detailed analysis of these failures reveals a consistent bias hierarchy, with perturbations involving racial cues being the predominant cause of the violations. In addition to offering a comparative evaluation, this work reinforces that the retrieval component in RAG must be carefully curated to prevent bias amplification. The findings serve as a practical alert for developers, testers and small organizations aiming to adopt accessible SLMs without compromising fairness or reliability.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ£€ç´¢å¢å¼ºç”Ÿæˆ(Retrieval-Augmented Generation, RAG)ç³»ç»Ÿä¸­çš„å…¬å¹³æ€§é—®é¢˜ï¼Œæ¢è®¨äº†å°å‹è¯­è¨€æ¨¡å‹(Small Language Models, SLMs)åœ¨å¤„ç†æ•æ„Ÿäººå£ç»Ÿè®¡ä¿¡æ¯æ—¶å¯èƒ½è¡¨ç°å‡ºçš„åè§ã€‚ç ”ç©¶é‡‡ç”¨å˜æ€æµ‹è¯•(Metamorphic Testing, MT)æ–¹æ³•ï¼Œé€šè¿‡åœ¨æç¤ºè¯ä¸­å¼•å…¥å—æ§çš„äººå£ç»Ÿè®¡æ‰°åŠ¨ï¼Œè¯„ä¼°äº†é›†æˆåœ¨RAGæµæ°´çº¿ä¸­çš„ä¸‰æ¬¾ä¸»æµæ¨¡å‹ï¼šLlama-3.2-3B-Instructã€Mistral-7B-Instruct-v0.3å’ŒLlama-3.1-Nemotron-8Bã€‚å®éªŒé‡ç‚¹åˆ†æäº†è¿™äº›æ¨¡å‹åœ¨æƒ…æ„Ÿåˆ†æ(Sentiment Analysis)ä»»åŠ¡ä¸­çš„å…¬å¹³æ€§è¡¨ç°ï¼Œç»“æœè¡¨æ˜å¾®å°çš„äººå£ç»Ÿè®¡å˜åŒ–å¯èƒ½å¯¼è‡´é«˜è¾¾ä¸‰åˆ†ä¹‹ä¸€çš„å˜æ€å…³ç³»(Metamorphic Relations, MRs)å¤±æ•ˆã€‚è¯¦ç»†åˆ†ææ˜¾ç¤ºï¼Œæ¶‰åŠç§æ—çº¿ç´¢(Racial Cues)çš„æ‰°åŠ¨æ˜¯å¯¼è‡´å…¬å¹³æ€§è¿è§„çš„ä¸»è¦åŸå› ã€‚è¯¥é¡¹å·¥ä½œå¼ºè°ƒäº†åœ¨RAGç³»ç»Ÿä¸­ä»”ç»†ç­›é€‰æ£€ç´¢ç»„ä»¶ä»¥é˜²æ­¢åè§æ”¾å¤§çš„å¿…è¦æ€§ï¼Œå¹¶ä¸ºæ—¨åœ¨é‡‡ç”¨ä½é—¨æ§›SLMsçš„å¼€å‘è€…å’Œå°å‹æœºæ„æä¾›äº†å…³äºå…¬å¹³æ€§ä¸å¯é æ€§çš„å®è·µé¢„è­¦ã€‚",
      "categories": [
        "cs.AI",
        "cs.IR",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.26584v1",
      "published_date": "2025-09-30 17:42:35 UTC",
      "updated_date": "2025-09-30 17:42:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:28:27.869710+00:00"
    },
    {
      "arxiv_id": "2509.26574v3",
      "title": "Probing the Critical Point (CritPt) of AI Reasoning: a Frontier Physics Research Benchmark",
      "title_zh": "æ¢å¯»äººå·¥æ™ºèƒ½æ¨ç†çš„ä¸´ç•Œç‚¹ (CritPt)ï¼šå‰æ²¿ç‰©ç†ç ”ç©¶åŸºå‡†æµ‹è¯•",
      "authors": [
        "Minhui Zhu",
        "Minyang Tian",
        "Xiaocheng Yang",
        "Tianci Zhou",
        "Lifan Yuan",
        "Penghao Zhu",
        "Eli Chertkov",
        "Shengyan Liu",
        "Yufeng Du",
        "Ziming Ji",
        "Indranil Das",
        "Junyi Cao",
        "Yufeng Du",
        "Jiabin Yu",
        "Peixue Wu",
        "Jinchen He",
        "Yifan Su",
        "Yikun Jiang",
        "Yujie Zhang",
        "Chang Liu",
        "Ze-Min Huang",
        "Weizhen Jia",
        "Yunkai Wang",
        "Farshid Jafarpour",
        "Yong Zhao",
        "Xinan Chen",
        "Jessie Shelton",
        "Aaron W. Young",
        "John Bartolotta",
        "Wenchao Xu",
        "Yue Sun",
        "Anjun Chu",
        "Victor Colussi",
        "Chris Akers",
        "Nathan Brooks",
        "Wenbo Fu",
        "Jinchao Zhao",
        "Marvin Qi",
        "Anqi Mu",
        "Yubo Yang",
        "Allen Zang",
        "Yang Lyu",
        "Peizhi Mai",
        "Christopher Wilson",
        "Xuefei Guo",
        "Juntai Zhou",
        "Daniel Inafuku",
        "Chi Xue",
        "Luyu Gao",
        "Ze Yang",
        "YaÃ¯r Hein",
        "Yonatan Kahn",
        "Kevin Zhou",
        "Di Luo",
        "John Drew Wilson",
        "Jarrod T. Reilly",
        "Dmytro Bandak",
        "Ofir Press",
        "Liang Yang",
        "Xueying Wang",
        "Hao Tong",
        "Nicolas Chia",
        "Eliu Huerta",
        "Hao Peng"
      ],
      "abstract": "While large language models (LLMs) with reasoning capabilities are progressing rapidly on high-school math competitions and coding, can they reason effectively through complex, open-ended challenges found in frontier physics research? And crucially, what kinds of reasoning tasks do physicists want LLMs to assist with? To address these questions, we present the CritPt (Complex Research using Integrated Thinking - Physics Test, pronounced \"critical point\"), the first benchmark designed to test LLMs on unpublished, research-level reasoning tasks that broadly covers modern physics research areas, including condensed matter, quantum physics, atomic, molecular & optical physics, astrophysics, high energy physics, mathematical physics, statistical physics, nuclear physics, nonlinear dynamics, fluid dynamics and biophysics. CritPt consists of 71 composite research challenges designed to simulate full-scale research projects at the entry level, which are also decomposed to 190 simpler checkpoint tasks for more fine-grained insights. All problems are newly created by 50+ active physics researchers based on their own research. Every problem is hand-curated to admit a guess-resistant and machine-verifiable answer and is evaluated by an automated grading pipeline heavily customized for advanced physics-specific output formats. We find that while current state-of-the-art LLMs show early promise on isolated checkpoints, they remain far from being able to reliably solve full research-scale challenges: the best average accuracy among base models is only 5.7%, achieved by GPT-5 (high), moderately rising to around 10% when equipped with coding tools. Through the realistic yet standardized evaluation offered by CritPt, we highlight a large disconnect between current model capabilities and realistic physics research demands, offering a foundation to guide the development of scientifically grounded AI tools.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº†CritPt (Complex Research using Integrated Thinking - Physics Test)ï¼Œè¿™æ˜¯é¦–ä¸ªä¸“é—¨æµ‹è¯•å¤§è¯­è¨€æ¨¡å‹ (LLMs) å¤„ç†æœªå‘è¡¨ã€ç ”ç©¶çº§ç‰©ç†æ¨ç†ä»»åŠ¡çš„åŸºå‡†æµ‹è¯•ã€‚è¯¥åŸºå‡†æ¶µç›–äº†å‡èšæ€ç‰©ç† (condensed matter)ã€é‡å­ç‰©ç† (quantum physics) å’Œå¤©ä½“ç‰©ç† (astrophysics) ç­‰å¤šä¸ªå‰æ²¿é¢†åŸŸï¼Œç”±50å¤šåæ´»è·ƒç‰©ç†å­¦è€…åŸºäºè‡ªèº«ç ”ç©¶åˆ›å»ºäº†71é¡¹æ¨¡æ‹Ÿå®Œæ•´ç§‘ç ”é¡¹ç›®çš„å¤åˆæŒ‘æˆ˜ï¼Œå¹¶ç»†åˆ†ä¸º190ä¸ªå¯éªŒè¯çš„æ£€æŸ¥ç‚¹ä»»åŠ¡ (checkpoint tasks)ã€‚é€šè¿‡å®šåˆ¶çš„è‡ªåŠ¨åŒ–è¯„åˆ†æµæ°´çº¿è¯„ä¼°å‘ç°ï¼Œå½“å‰æœ€å…ˆè¿›çš„æ¨¡å‹åœ¨è§£å†³å®Œæ•´ç§‘ç ”è§„æ¨¡æŒ‘æˆ˜æ–¹é¢èƒ½åŠ›ä¸¥é‡ä¸è¶³ï¼Œå³ä½¿æ˜¯è¡¨ç°æœ€ä½³çš„ GPT-5 (high) åŸºç¡€æ¨¡å‹å‡†ç¡®ç‡ä¹Ÿä»…ä¸º5.7%ï¼Œè€Œåœ¨é…å¤‡ç¼–ç å·¥å…·åä»…èƒ½æå‡è‡³10%å·¦å³ã€‚è¿™é¡¹ç ”ç©¶æ­ç¤ºäº†å½“å‰AIèƒ½åŠ›ä¸å®é™…ç‰©ç†ç ”ç©¶éœ€æ±‚ä¹‹é—´çš„å·¨å¤§å·®è·ï¼Œä¸ºå¼•å¯¼ç§‘å­¦å¯¼å‘å‹AIå·¥å…·çš„å¼€å‘æä¾›äº†é‡è¦çš„è¡¡é‡æ ‡å‡†ä¸åŸºç¡€ã€‚",
      "categories": [
        "cs.AI",
        "cond-mat.other",
        "cs.CL",
        "hep-th",
        "quant-ph"
      ],
      "primary_category": "cs.AI",
      "comment": "39 pages, 6 figures, 6 tables",
      "pdf_url": "https://arxiv.org/pdf/2509.26574v3",
      "published_date": "2025-09-30 17:34:03 UTC",
      "updated_date": "2025-11-20 18:01:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:28:31.376952+00:00"
    },
    {
      "arxiv_id": "2509.26567v1",
      "title": "AI-assisted Advanced Propellant Development for Electric Propulsion",
      "title_zh": "äººå·¥æ™ºèƒ½è¾…åŠ©çš„ç”µæ¨è¿›å…ˆè¿›æ¨è¿›å‰‚ç ”å‘",
      "authors": [
        "Angel Pan Du",
        "Miguel Arana-Catania",
        "Enric Grustan GutiÃ©rrez"
      ],
      "abstract": "Artificial Intelligence algorithms are introduced in this work as a tool to predict the performance of new chemical compounds as alternative propellants for electric propulsion, focusing on predicting their ionisation characteristics and fragmentation patterns. The chemical properties and structure of the compounds are encoded using a chemical fingerprint, and the training datasets are extracted from the NIST WebBook. The AI-predicted ionisation energy and minimum appearance energy have a mean relative error of 6.87% and 7.99%, respectively, and a predicted ion mass with a 23.89% relative error. In the cases of full mass spectra due to electron ionisation, the predictions have a cosine similarity of 0.6395 and align with the top 10 most similar mass spectra in 78% of instances within a 30 Da range.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼•å…¥äº†äººå·¥æ™ºèƒ½AIç®—æ³•ä½œä¸ºé¢„æµ‹æ–°å‹åŒ–åˆç‰©åœ¨ç”µæ¨è¿›(electric propulsion)ä¸­ä½œä¸ºæ›¿ä»£æ¨è¿›å‰‚æ€§èƒ½çš„å·¥å…·ï¼Œé‡ç‚¹å…³æ³¨å…¶ç”µç¦»ç‰¹æ€§(ionisation characteristics)å’Œç¢ç‰‡æ¨¡å¼(fragmentation patterns)çš„é¢„æµ‹ã€‚ç ”ç©¶åˆ©ç”¨åŒ–å­¦æŒ‡çº¹(chemical fingerprint)å¯¹åŒ–åˆç‰©çš„åŒ–å­¦æ€§è´¨å’Œç»“æ„è¿›è¡Œç¼–ç ï¼Œå¹¶ä»NIST WebBookä¸­æå–è®­ç»ƒæ•°æ®é›†è¿›è¡Œæ¨¡å‹å¼€å‘ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒAIé¢„æµ‹çš„ç”µç¦»èƒ½(ionisation energy)å’Œæœ€å°å‡ºç°èƒ½(minimum appearance energy)çš„å¹³å‡ç›¸å¯¹è¯¯å·®åˆ†åˆ«ä¸º6.87%å’Œ7.99%ï¼Œé¢„æµ‹ç¦»å­è´¨é‡(ion mass)çš„ç›¸å¯¹è¯¯å·®ä¸º23.89%ã€‚åœ¨ç”µå­ç”µç¦»äº§ç”Ÿçš„å…¨è´¨è°±(mass spectra)é¢„æµ‹ä¸­ï¼Œé¢„æµ‹ç»“æœçš„ä½™å¼¦ç›¸ä¼¼åº¦è¾¾åˆ°0.6395ï¼Œä¸”åœ¨78%çš„æƒ…å†µä¸‹ä¸30 DaèŒƒå›´å†…çš„å‰10ä¸ªæœ€ç›¸ä¼¼è´¨è°±å¯¹é½ã€‚è¿™é¡¹å·¥ä½œå±•ç¤ºäº†AIè¾…åŠ©æ‰‹æ®µåœ¨å…ˆè¿›ç”µæ¨è¿›ç³»ç»Ÿæ¨è¿›å‰‚å¼€å‘ä¸­çš„åº”ç”¨ä»·å€¼ã€‚",
      "categories": [
        "astro-ph.IM",
        "cs.AI",
        "cs.LG",
        "physics.space-ph"
      ],
      "primary_category": "astro-ph.IM",
      "comment": "23 pages, 10 figures, 5 tables. Journal of Electric Propulsion",
      "pdf_url": "https://arxiv.org/pdf/2509.26567v1",
      "published_date": "2025-09-30 17:31:41 UTC",
      "updated_date": "2025-09-30 17:31:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:28:31.083134+00:00"
    },
    {
      "arxiv_id": "2509.26564v1",
      "title": "Parametric Neural Amp Modeling with Active Learning",
      "title_zh": "åŸºäºä¸»åŠ¨å­¦ä¹ çš„å‚æ•°åŒ–ç¥ç»æ”¾å¤§å™¨å»ºæ¨¡",
      "authors": [
        "Florian GrÃ¶tschla",
        "Longxiang Jiao",
        "Luca A. LanzendÃ¶rfer",
        "Roger Wattenhofer"
      ],
      "abstract": "We introduce Panama, an active learning framework to train parametric guitar amp models end-to-end using a combination of an LSTM model and a WaveNet-like architecture. With \\model, one can create a virtual amp by recording samples that are determined through an ensemble-based active learning strategy to minimize the amount of datapoints needed (i.e., amp knob settings). Our strategy uses gradient-based optimization to maximize the disagreement among ensemble models, in order to identify the most informative datapoints. MUSHRA listening tests reveal that, with 75 datapoints, our models are able to match the perceptual quality of NAM, the leading open-source non-parametric amp modeler.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼•å…¥äº†Panamaï¼Œä¸€ä¸ªç”¨äºç«¯åˆ°ç«¯è®­ç»ƒå‚æ•°åŒ–å‰ä»–éŸ³ç®±æ¨¡å‹(parametric guitar amp models)çš„ä¸»åŠ¨å­¦ä¹ (active learning)æ¡†æ¶ã€‚è¯¥æ¡†æ¶ç»“åˆäº†LSTMæ¨¡å‹å’Œç±»WaveNetæ¶æ„ï¼Œåˆ©ç”¨åŸºäºé›†æˆçš„ä¸»åŠ¨å­¦ä¹ ç­–ç•¥(ensemble-based active learning strategy)æ¥æ˜¾è‘—å‡å°‘è®­ç»ƒæ‰€éœ€çš„éŸ³ç®±æ—‹é’®è®¾ç½®æ•°æ®ç‚¹ã€‚Panamaé€šè¿‡åŸºäºæ¢¯åº¦çš„ä¼˜åŒ–æ–¹æ³•æœ€å¤§åŒ–é›†æˆæ¨¡å‹ä¹‹é—´çš„åˆ†æ­§ï¼Œä»è€Œç²¾å‡†è¯†åˆ«å¹¶é‡‡é›†æœ€å…·ä¿¡æ¯é‡çš„æ•°æ®ã€‚MUSHRAå¬æ„Ÿæµ‹è¯•ç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹ä»…éœ€75ä¸ªæ•°æ®ç‚¹å³å¯è¾¾åˆ°é¢†å…ˆçš„å¼€æºéå‚æ•°åŒ–å»ºæ¨¡å·¥å…·NAMçš„æ„ŸçŸ¥è´¨é‡ã€‚è¿™ç§æ–¹æ³•ä¸ä»…å¤§å¹…é™ä½äº†æ„å»ºé«˜è´¨é‡è™šæ‹ŸéŸ³ç®±æ¨¡å‹çš„æ•°æ®é‡‡é›†æˆæœ¬ï¼Œä¹Ÿä¸ºé«˜æ•ˆã€é«˜ç²¾åº¦çš„éŸ³é¢‘è®¾å¤‡ä»¿çœŸæä¾›äº†æ–°çš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.26564v1",
      "published_date": "2025-09-30 17:30:00 UTC",
      "updated_date": "2025-09-30 17:30:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:28:36.386803+00:00"
    },
    {
      "arxiv_id": "2509.26543v1",
      "title": "The Unheard Alternative: Contrastive Explanations for Speech-to-Text Models",
      "title_zh": "æœªè¢«å¬è§çš„å¤‡é€‰æ–¹æ¡ˆï¼šè¯­éŸ³è½¬æ–‡æœ¬æ¨¡å‹çš„å¯¹æ¯”æ€§è§£é‡Š",
      "authors": [
        "Lina Conti",
        "Dennis Fucci",
        "Marco Gaido",
        "Matteo Negri",
        "Guillaume Wisniewski",
        "Luisa Bentivogli"
      ],
      "abstract": "Contrastive explanations, which indicate why an AI system produced one output (the target) instead of another (the foil), are widely regarded in explainable AI as more informative and interpretable than standard explanations. However, obtaining such explanations for speech-to-text (S2T) generative models remains an open challenge. Drawing from feature attribution techniques, we propose the first method to obtain contrastive explanations in S2T by analyzing how parts of the input spectrogram influence the choice between alternative outputs. Through a case study on gender assignment in speech translation, we show that our method accurately identifies the audio features that drive the selection of one gender over another. By extending the scope of contrastive explanations to S2T, our work provides a foundation for better understanding S2T models.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Speech-to-Text (S2T) ç”Ÿæˆå¼æ¨¡å‹åœ¨è§£é‡Šæ€§æ–¹é¢çš„å±€é™ï¼Œæå‡ºäº†é¦–ä¸ªç”¨äºç”Ÿæˆå¯¹æ¯”æ€§è§£é‡Š (Contrastive Explanations) çš„æ–¹æ³•ï¼Œæ—¨åœ¨è¯´æ˜æ¨¡å‹ä¸ºä½•äº§ç”Ÿç‰¹å®šè¾“å‡ºè€Œéå¤‡é€‰è¾“å‡ºã€‚è¯¥æ–¹æ³•å€Ÿé‰´äº†ç‰¹å¾å½’å›  (Feature Attribution) æŠ€æœ¯ï¼Œé€šè¿‡åˆ†æè¾“å…¥å£°è°±å›¾ (Spectrogram) çš„ä¸åŒåŒºåŸŸå¦‚ä½•å½±å“æ¨¡å‹å†³ç­–ã€‚é€šè¿‡å¯¹è¯­éŸ³ç¿»è¯‘ä¸­æ€§åˆ«åˆ†é… (Gender Assignment) çš„æ¡ˆä¾‹ç ”ç©¶ï¼Œç ”ç©¶è¯æ˜è¯¥æ–¹æ³•èƒ½å‡†ç¡®è¯†åˆ«å‡ºé©±åŠ¨æ¨¡å‹é€‰æ‹©ç‰¹å®šæ€§åˆ«çš„éŸ³é¢‘ç‰¹å¾ã€‚è¯¥å·¥ä½œå°†å¯¹æ¯”æ€§è§£é‡Šæ‰©å±•åˆ° S2T é¢†åŸŸï¼Œä¸ºæ·±å…¥ç†è§£å’Œè¯„ä¼°ç”Ÿæˆå¼è¯­éŸ³æ¨¡å‹æä¾›äº†åšå®çš„åŸºç¡€ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to BlackBoxNLP 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.26543v1",
      "published_date": "2025-09-30 17:17:27 UTC",
      "updated_date": "2025-09-30 17:17:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:28:55.695232+00:00"
    },
    {
      "arxiv_id": "2509.26538v1",
      "title": "HilbertA: Hilbert Attention for Image Generation with Diffusion Models",
      "title_zh": "HilbertAï¼šé¢å‘æ‰©æ•£æ¨¡å‹å›¾åƒç”Ÿæˆçš„å¸Œå°”ä¼¯ç‰¹æ³¨æ„åŠ›æœºåˆ¶",
      "authors": [
        "Shaoyi Zheng",
        "Wenbo Lu",
        "Yuxuan Xia",
        "Haomin Liu",
        "Shengjie Wang"
      ],
      "abstract": "Designing sparse attention for diffusion transformers requires reconciling two-dimensional spatial locality with GPU efficiency, a trade-off that current methods struggle to achieve. Existing approaches enforce two-dimensional spatial locality but often incur uncoalesced memory access. We present HilbertA, a 2D-aware and GPU-efficient sparse attention mechanism. HilbertA reorders image tokens along Hilbert curves to achieve a contiguous memory layout while preserving spatial neighborhoods, and employs a sliding schedule across layers to enable long-range information propagation without repeated or uncoalesced memory access. To further enhance cross-tile communication and positional awareness, HilbertA introduces a small central shared region. Implemented in Triton, HilbertA delivers comparable image quality with significant acceleration over prior methods on Flux.1-dev, demonstrating the feasibility of hardware-aligned two-dimensional sparse attention for high-resolution image generation. HilbertA delivers attention speedups of $2.3\\times$ when generating $1024\\times 1024$ images, and up to $4.17\\times$ at $2048\\times 2048$, while achieving image quality comparable to or surpassing baselines.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† HilbertAï¼Œä¸€ç§ä¸“ä¸ºæ‰©æ•£æ¨¡å‹ (Diffusion Models) è®¾è®¡çš„äºŒç»´æ„ŸçŸ¥ä¸” GPU é«˜æ•ˆçš„ç¨€ç–æ³¨æ„åŠ›æœºåˆ¶ï¼Œæ—¨åœ¨è§£å†³æ‰©æ•£ Transformer åœ¨ 2D ç©ºé—´å±€éƒ¨æ€§ä¸ GPU æ•ˆç‡ä¹‹é—´çš„å¹³è¡¡éš¾é¢˜ã€‚HilbertA é€šè¿‡æ²¿ Hilbert æ›²çº¿ (Hilbert curves) é‡æ–°æ’åˆ—å›¾åƒ tokenï¼Œåœ¨ä¿ç•™ç©ºé—´é‚»åŸŸçš„åŒæ—¶å®ç°äº†è¿ç»­çš„å†…å­˜å¸ƒå±€ï¼Œä»è€Œé¿å…äº†éåˆå¹¶å†…å­˜è®¿é—®é—®é¢˜ã€‚è¯¥æœºåˆ¶é‡‡ç”¨äº†è·¨å±‚æ»‘åŠ¨è°ƒåº¦ (sliding schedule) ä»¥ä¿ƒè¿›é•¿ç¨‹ä¿¡æ¯ä¼ æ’­ï¼Œå¹¶å¼•å…¥å°å‹ä¸­å¤®å…±äº«åŒºåŸŸæ¥å¢å¼ºè·¨åˆ‡ç‰‡é€šä¿¡å’Œä½ç½®æ„ŸçŸ¥ã€‚é€šè¿‡ Triton å®ç°ï¼ŒHilbertA åœ¨ Flux.1-dev æ¨¡å‹ä¸Šç”Ÿæˆé«˜åˆ†è¾¨ç‡å›¾åƒæ—¶è¡¨ç°å‡ºè‰²ï¼Œä¿æŒäº†ä¸åŸºçº¿ç›¸å½“ç”šè‡³æ›´ä¼˜çš„å›¾åƒè´¨é‡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒHilbertA åœ¨ç”Ÿæˆ 1024Ã—1024 å›¾åƒæ—¶å®ç°äº† 2.3 å€çš„æ³¨æ„åŠ›åŠ é€Ÿï¼Œè€Œåœ¨ 2048Ã—2048 åˆ†è¾¨ç‡ä¸‹åŠ é€Ÿæ¯”é«˜è¾¾ 4.17 å€ã€‚è¿™é¡¹å·¥ä½œè¯æ˜äº†ç¡¬ä»¶å¯¹é½çš„äºŒç»´ç¨€ç–æ³¨æ„åŠ›æœºåˆ¶åœ¨å¤§è§„æ¨¡ã€é«˜åˆ†è¾¨ç‡å›¾åƒç”Ÿæˆä¸­çš„é«˜æ•ˆæ€§ä¸å¯è¡Œæ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.26538v1",
      "published_date": "2025-09-30 17:13:22 UTC",
      "updated_date": "2025-09-30 17:13:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:28:49.085783+00:00"
    },
    {
      "arxiv_id": "2509.26536v2",
      "title": "OceanGym: A Benchmark Environment for Underwater Embodied Agents",
      "title_zh": "OceanGymï¼šæ°´ä¸‹å…·èº«æ™ºèƒ½ä½“åŸºå‡†ç¯å¢ƒ",
      "authors": [
        "Yida Xue",
        "Mingjun Mao",
        "Xiangyuan Ru",
        "Yuqi Zhu",
        "Baochang Ren",
        "Shuofei Qiao",
        "Mengru Wang",
        "Shumin Deng",
        "Xinyu An",
        "Ningyu Zhang",
        "Ying Chen",
        "Huajun Chen"
      ],
      "abstract": "We introduce OceanGym, the first comprehensive benchmark for ocean underwater embodied agents, designed to advance AI in one of the most demanding real-world environments. Unlike terrestrial or aerial domains, underwater settings present extreme perceptual and decision-making challenges, including low visibility, dynamic ocean currents, making effective agent deployment exceptionally difficult. OceanGym encompasses eight realistic task domains and a unified agent framework driven by Multi-modal Large Language Models (MLLMs), which integrates perception, memory, and sequential decision-making. Agents are required to comprehend optical and sonar data, autonomously explore complex environments, and accomplish long-horizon objectives under these harsh conditions. Extensive experiments reveal substantial gaps between state-of-the-art MLLM-driven agents and human experts, highlighting the persistent difficulty of perception, planning, and adaptability in ocean underwater environments. By providing a high-fidelity, rigorously designed platform, OceanGym establishes a testbed for developing robust embodied AI and transferring these capabilities to real-world autonomous ocean underwater vehicles, marking a decisive step toward intelligent agents capable of operating in one of Earth's last unexplored frontiers. The code and data are available at https://github.com/OceanGPT/OceanGym.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† OceanGymï¼Œè¿™æ˜¯é¦–ä¸ªé’ˆå¯¹æµ·æ´‹æ°´ä¸‹å…·èº«æ™ºèƒ½ä½“ (underwater embodied agents) çš„ç»¼åˆæ€§åŸºå‡†æµ‹è¯•ç¯å¢ƒï¼Œæ—¨åœ¨åº”å¯¹æ°´ä¸‹ä½èƒ½è§åº¦å’ŒåŠ¨æ€æ´‹æµå¸¦æ¥çš„æç«¯æ„ŸçŸ¥ä¸å†³ç­–æŒ‘æˆ˜ã€‚OceanGym æ¶µç›–äº†å…«ä¸ªç°å®ä»»åŠ¡é¢†åŸŸï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªç”±å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ (MLLMs) é©±åŠ¨çš„ç»Ÿä¸€æ™ºèƒ½ä½“æ¡†æ¶ï¼Œæ•´åˆäº†æ„ŸçŸ¥ã€è®°å¿†å’Œåºåˆ—å†³ç­–åŠŸèƒ½ã€‚åœ¨è¯¥ç¯å¢ƒä¸‹ï¼Œæ™ºèƒ½ä½“å¿…é¡»å¤„ç†å…‰å­¦ä¸å£°çº³æ•°æ®ï¼Œåœ¨å¤æ‚çš„æ°´ä¸‹åœºæ™¯ä¸­è‡ªä¸»æ¢ç´¢å¹¶è¾¾æˆé•¿ç¨‹ç›®æ ‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œç›®å‰çš„ MLLM é©±åŠ¨æ™ºèƒ½ä½“åœ¨æ„ŸçŸ¥ã€è§„åˆ’åŠé€‚åº”æ€§æ–¹é¢ä¸äººç±»ä¸“å®¶ç›¸æ¯”ä»å­˜åœ¨å·¨å¤§å·®è·ã€‚OceanGym ä½œä¸ºä¸€ä¸ªé«˜ä¿çœŸçš„æµ‹è¯•å¹³å°ï¼Œä¸ºå¼€å‘å¼ºé²æ£’æ€§çš„å…·èº«äººå·¥æ™ºèƒ½ (embodied AI) å¹¶å°†å…¶åº”ç”¨äºç°å®ä¸–ç•Œçš„æ°´ä¸‹æ— äººèˆªè¡Œå™¨ (AUVs) æä¾›äº†å…³é”®æ”¯æŒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress",
      "pdf_url": "https://arxiv.org/pdf/2509.26536v2",
      "published_date": "2025-09-30 17:09:32 UTC",
      "updated_date": "2025-11-25 15:21:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:28:43.083698+00:00"
    },
    {
      "arxiv_id": "2509.26534v1",
      "title": "Rearchitecting Datacenter Lifecycle for AI: A TCO-Driven Framework",
      "title_zh": "é¢å‘äººå·¥æ™ºèƒ½çš„æ•°æ®ä¸­å¿ƒç”Ÿå‘½å‘¨æœŸé‡æ„ï¼šä¸€ç§ TCO é©±åŠ¨çš„æ¡†æ¶",
      "authors": [
        "Jovan Stojkovic",
        "Chaojie Zhang",
        "ÃÃ±igo Goiri",
        "Ricardo Bianchini"
      ],
      "abstract": "The rapid rise of large language models (LLMs) has been driving an enormous demand for AI inference infrastructure, mainly powered by high-end GPUs. While these accelerators offer immense computational power, they incur high capital and operational costs due to frequent upgrades, dense power consumption, and cooling demands, making total cost of ownership (TCO) for AI datacenters a critical concern for cloud providers. Unfortunately, traditional datacenter lifecycle management (designed for general-purpose workloads) struggles to keep pace with AI's fast-evolving models, rising resource needs, and diverse hardware profiles. In this paper, we rethink the AI datacenter lifecycle scheme across three stages: building, hardware refresh, and operation. We show how design choices in power, cooling, and networking provisioning impact long-term TCO. We also explore refresh strategies aligned with hardware trends. Finally, we use operation software optimizations to reduce cost. While these optimizations at each stage yield benefits, unlocking the full potential requires rethinking the entire lifecycle. Thus, we present a holistic lifecycle management framework that coordinates and co-optimizes decisions across all three stages, accounting for workload dynamics, hardware evolution, and system aging. Our system reduces the TCO by up to 40\\% over traditional approaches. Using our framework we provide guidelines on how to manage AI datacenter lifecycle for the future.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é©±åŠ¨ä¸‹çš„AIæ¨ç†åŸºç¡€è®¾æ–½æˆæœ¬æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§ä»¥æ€»æ‹¥æœ‰æˆæœ¬ï¼ˆTCOï¼‰é©±åŠ¨çš„æ•´ä½“æ•°æ®ä¸­å¿ƒç”Ÿå‘½å‘¨æœŸç®¡ç†æ¡†æ¶ã€‚ä¼ ç»Ÿçš„ç”Ÿå‘½å‘¨æœŸç®¡ç†éš¾ä»¥é€‚åº”AIç¡¬ä»¶çš„é«˜èƒ½è€—ã€å¿«é€Ÿè¿­ä»£åŠå†·å´éœ€æ±‚ï¼Œå› æ­¤è¯¥æ¡†æ¶ä»æ„å»ºã€ç¡¬ä»¶æ›´æ–°ï¼ˆHardware Refreshï¼‰å’Œè¿è¥ä¸‰ä¸ªå…³é”®é˜¶æ®µè¿›è¡Œäº†é‡æ„ã€‚é€šè¿‡ååŒä¼˜åŒ–ç”µåŠ›ã€å†·å´å’Œç½‘ç»œéƒ¨ç½²ï¼Œå¹¶ç»“åˆå·¥ä½œè´Ÿè½½åŠ¨æ€ä¸ç³»ç»Ÿè€åŒ–å› ç´ ï¼Œè¯¥æ¡†æ¶å®ç°äº†è·¨é˜¶æ®µçš„å†³ç­–ç»Ÿç­¹ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜é€šè¿‡è¿è¥è½¯ä»¶ä¼˜åŒ–è¿›ä¸€æ­¥æŒ–æ˜å‡æ”¯æ½œåŠ›ï¼Œç¡®ä¿ç³»ç»Ÿèƒ½å¤Ÿåº”å¯¹ç¡¬ä»¶æ¼”è¿›å¸¦æ¥çš„å¤æ‚æ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ¡ˆç›¸è¾ƒäºä¼ ç»Ÿç®¡ç†æ–¹æ³•å¯å°†TCOé™ä½å¤šè¾¾40%ã€‚è¯¥æ¡†æ¶ä¸ä»…æ˜¾è‘—æå‡äº†AIæ•°æ®ä¸­å¿ƒçš„ç»æµæ•ˆç›Šï¼Œè¿˜ä¸ºæœªæ¥å¤§è§„æ¨¡AIåŸºç¡€è®¾æ–½çš„ç”Ÿå‘½å‘¨æœŸç®¡ç†æä¾›äº†é‡è¦çš„æŒ‡å¯¼æ–¹é’ˆã€‚",
      "categories": [
        "cs.AI",
        "cs.AR",
        "cs.DC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.26534v1",
      "published_date": "2025-09-30 17:08:51 UTC",
      "updated_date": "2025-09-30 17:08:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:28:52.476883+00:00"
    },
    {
      "arxiv_id": "2509.26524v1",
      "title": "TAP: Two-Stage Adaptive Personalization of Multi-task and Multi-Modal Foundation Models in Federated Learning",
      "title_zh": "TAPï¼šè”é‚¦å­¦ä¹ ä¸­å¤šä»»åŠ¡ä¸å¤šæ¨¡æ€åŸºç¡€æ¨¡å‹çš„ä¸¤é˜¶æ®µè‡ªé€‚åº”ä¸ªæ€§åŒ–",
      "authors": [
        "Seohyun Lee",
        "Wenzhi Fang",
        "Dong-Jun Han",
        "Seyyedali Hosseinalipour",
        "Christopher G. Brinton"
      ],
      "abstract": "Federated Learning (FL), despite demonstrating impressive capabilities in the training of multiple models in a decentralized manner, has been shown to produce a final model not necessarily well-suited to the needs of each client. While extensive work has been conducted on how to create tailored personalized models, called Personalized Federated Learning (PFL), less attention has been given to personalization via fine-tuning of foundation models with multi-task and multi-modal properties. Moreover, there exists a lack of understanding in the literature on how to fine-tune and personalize such models in a setting that is heterogeneous across clients not only in data, but also in tasks and modalities. To address this gap in the literature, we propose TAP (Two-Stage Adaptive Personalization), which (i) leverages mismatched model architectures between the clients and server to selectively conduct replacement operations when it benefits a client's local tasks and (ii) engages in post-FL knowledge distillation for capturing beneficial general knowledge without compromising personalization. We also introduce the first convergence analysis of the server model under its modality-task pair architecture, and demonstrate that as the number of modality-task pairs increases, its ability to cater to all tasks suffers. Through extensive experiments, we demonstrate the effectiveness of our proposed algorithm across a variety of datasets and tasks in comparison to a multitude of baselines. Implementation code is publicly available at https://github.com/lee3296/TAP.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è”é‚¦å­¦ä¹ (Federated Learning)ä¸­å¤šä»»åŠ¡å’Œå¤šæ¨¡æ€åŸºç¡€æ¨¡å‹åœ¨å¼‚æ„ç¯å¢ƒä¸‹çš„ä¸ªæ€§åŒ–éš¾é¢˜ï¼Œæå‡ºäº†TAP (Two-Stage Adaptive Personalization)æ¡†æ¶ã€‚TAPé€šè¿‡ä¸¤é˜¶æ®µè‡ªé€‚åº”ç­–ç•¥ï¼Œåˆ©ç”¨å®¢æˆ·ç«¯ä¸æœåŠ¡å™¨ä¹‹é—´ä¸åŒ¹é…çš„æ¨¡å‹æ¶æ„ï¼Œåœ¨æœ‰åˆ©äºå®¢æˆ·ç«¯æœ¬åœ°ä»»åŠ¡æ—¶é€‰æ‹©æ€§åœ°æ‰§è¡Œæ›¿æ¢æ“ä½œã€‚åŒæ—¶ï¼Œè¯¥æ¡†æ¶å¼•å…¥äº†FLåçš„çŸ¥è¯†è’¸é¦(knowledge distillation)æŠ€æœ¯ï¼Œä»¥åœ¨ä¸æŸå®³ä¸ªæ€§åŒ–(personalization)çš„å‰æä¸‹æ•è·æœ‰ç›Šçš„é€šç”¨çŸ¥è¯†ã€‚æ­¤å¤–ï¼Œç ”ç©¶è€…é¦–æ¬¡å¯¹æ¨¡æ€-ä»»åŠ¡å¯¹(modality-task pair)æ¶æ„ä¸‹çš„æœåŠ¡å™¨æ¨¡å‹è¿›è¡Œäº†æ”¶æ•›æ€§åˆ†æï¼Œæ­ç¤ºäº†ä»»åŠ¡å¤æ‚åº¦çš„å¢åŠ å¯¹æ¨¡å‹é€‚é…èƒ½åŠ›çš„å½±å“ã€‚å®éªŒç»“æœåœ¨å¤šä¸ªæ•°æ®é›†å’Œä»»åŠ¡ä¸ŠéªŒè¯äº†TAPç›¸å¯¹äºåŸºçº¿æ¨¡å‹çš„ä¼˜è¶Šæ€§ï¼Œè¯æ˜äº†å…¶åœ¨å¤„ç†æ•°æ®ã€ä»»åŠ¡å’Œæ¨¡æ€å¤šé‡å¼‚æ„æ€§æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.26524v1",
      "published_date": "2025-09-30 17:01:32 UTC",
      "updated_date": "2025-09-30 17:01:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:29:08.972643+00:00"
    },
    {
      "arxiv_id": "2509.26521v1",
      "title": "MUSE-Explainer: Counterfactual Explanations for Symbolic Music Graph Classification Models",
      "title_zh": "MUSE-Explainerï¼šç¬¦å·éŸ³ä¹å›¾åˆ†ç±»æ¨¡å‹çš„åäº‹å®è§£é‡Š",
      "authors": [
        "Baptiste Hilaire",
        "Emmanouil Karystinaios",
        "Gerhard Widmer"
      ],
      "abstract": "Interpretability is essential for deploying deep learning models in symbolic music analysis, yet most research emphasizes model performance over explanation. To address this, we introduce MUSE-Explainer, a new method that helps reveal how music Graph Neural Network models make decisions by providing clear, human-friendly explanations. Our approach generates counterfactual explanations by making small, meaningful changes to musical score graphs that alter a model's prediction while ensuring the results remain musically coherent. Unlike existing methods, MUSE-Explainer tailors its explanations to the structure of musical data and avoids unrealistic or confusing outputs. We evaluate our method on a music analysis task and show it offers intuitive insights that can be visualized with standard music tools such as Verovio.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç¬¦å·éŸ³ä¹åˆ†æä¸­æ·±åº¦å­¦ä¹ æ¨¡å‹çš„å¯è§£é‡Šæ€§éœ€æ±‚ï¼Œæå‡ºäº†MUSE-Explaineræ–¹æ³•ï¼Œæ—¨åœ¨æ­ç¤ºéŸ³ä¹å›¾ç¥ç»ç½‘ç»œ(Graph Neural Network)æ¨¡å‹çš„å†³ç­–æœºåˆ¶ã€‚è¯¥æ–¹æ³•é€šè¿‡å¯¹éŸ³ä¹å¾—åˆ†å›¾(musical score graphs)è¿›è¡Œå¾®å°ä¸”æœ‰æ„ä¹‰çš„è°ƒæ•´æ¥ç”Ÿæˆåäº‹å®è§£é‡Š(counterfactual explanations)ï¼Œåœ¨æ”¹å˜æ¨¡å‹é¢„æµ‹çš„åŒæ—¶ç¡®ä¿ç»“æœä¿æŒéŸ³ä¹è¿è´¯æ€§(musically coherent)ã€‚ä¸ç°æœ‰æ–¹æ³•ä¸åŒï¼ŒMUSE-Explainerä¸“é—¨é’ˆå¯¹éŸ³ä¹æ•°æ®çš„ç»“æ„ç‰¹å¾è¿›è¡Œä¼˜åŒ–ï¼Œæœ‰æ•ˆé¿å…äº†ç”Ÿæˆä¸åˆ‡å®é™…æˆ–ä»¤äººå›°æƒ‘çš„è§£é‡Šè¾“å‡ºã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨éŸ³ä¹åˆ†æä»»åŠ¡ä¸­èƒ½å¤Ÿæä¾›ç›´è§‚çš„æ´è§ï¼Œå¹¶æ”¯æŒåˆ©ç”¨Verovioç­‰æ ‡å‡†éŸ³ä¹å·¥å…·è¿›è¡Œå¯è§†åŒ–å±•ç¤ºã€‚",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted at the 17th International Symposium on Computer Music Multidisciplinary Research (CMMR) 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.26521v1",
      "published_date": "2025-09-30 16:58:07 UTC",
      "updated_date": "2025-09-30 16:58:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:29:13.672236+00:00"
    },
    {
      "arxiv_id": "2509.26507v1",
      "title": "The Dragon Hatchling: The Missing Link between the Transformer and Models of the Brain",
      "title_zh": "The Dragon Hatchlingï¼šTransformer ä¸å¤§è„‘æ¨¡å‹ä¹‹é—´ç¼ºå¤±çš„ç¯èŠ‚",
      "authors": [
        "Adrian Kosowski",
        "PrzemysÅ‚aw UznaÅ„ski",
        "Jan Chorowski",
        "Zuzanna Stamirowska",
        "MichaÅ‚ Bartoszkiewicz"
      ],
      "abstract": "The relationship between computing systems and the brain has served as motivation for pioneering theoreticians since John von Neumann and Alan Turing. Uniform, scale-free biological networks, such as the brain, have powerful properties, including generalizing over time, which is the main barrier for Machine Learning on the path to Universal Reasoning Models.\n  We introduce `Dragon Hatchling' (BDH), a new Large Language Model architecture based on a scale-free biologically inspired network of \\$n\\$ locally-interacting neuron particles. BDH couples strong theoretical foundations and inherent interpretability without sacrificing Transformer-like performance.\n  BDH is a practical, performant state-of-the-art attention-based state space sequence learning architecture. In addition to being a graph model, BDH admits a GPU-friendly formulation. It exhibits Transformer-like scaling laws: empirically BDH rivals GPT2 performance on language and translation tasks, at the same number of parameters (10M to 1B), for the same training data.\n  BDH can be represented as a brain model. The working memory of BDH during inference entirely relies on synaptic plasticity with Hebbian learning using spiking neurons. We confirm empirically that specific, individual synapses strengthen connection whenever BDH hears or reasons about a specific concept while processing language inputs. The neuron interaction network of BDH is a graph of high modularity with heavy-tailed degree distribution. The BDH model is biologically plausible, explaining one possible mechanism which human neurons could use to achieve speech.\n  BDH is designed for interpretability. Activation vectors of BDH are sparse and positive. We demonstrate monosemanticity in BDH on language tasks. Interpretability of state, which goes beyond interpretability of neurons and model parameters, is an inherent feature of the BDH architecture.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼•å…¥äº†åä¸º Dragon Hatchling (BDH) çš„æ–°å‹å¤§è¯­è¨€æ¨¡å‹æ¶æ„ï¼Œæ—¨åœ¨å¼¥è¡¥ Transformer ä¸å¤§è„‘ç”Ÿç‰©æ¨¡å‹ä¹‹é—´çš„å·®è·ã€‚BDH åŸºäº $n$ ä¸ªå±€éƒ¨äº¤äº’ç¥ç»å…ƒç²’å­çš„æ— æ ‡åº¦(scale-free)ç”Ÿç‰©å¯å‘ç½‘ç»œï¼Œç»“åˆäº†æ·±åšçš„ç†è®ºåŸºç¡€å’Œå›ºæœ‰çš„å¯è§£é‡Šæ€§ï¼ŒåŒæ—¶ä¿æŒäº†ä¸ Transformer ç›¸å½“çš„æ€§èƒ½ã€‚ä½œä¸ºä¸€ç§é«˜æ•ˆçš„åŸºäºæ³¨æ„åŠ›çš„çŠ¶æ€ç©ºé—´åºåˆ—å­¦ä¹ (attention-based state space sequence learning)æ¶æ„ï¼ŒBDH åœ¨è¯­è¨€å’Œç¿»è¯‘ä»»åŠ¡ä¸Šçš„æ‰©å±•å®šå¾‹å¯åª²ç¾åŒç­‰å‚æ•°è§„æ¨¡çš„ GPT2 æ¨¡å‹ã€‚åœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼ŒBDH çš„å·¥ä½œè®°å¿†å®Œå…¨ä¾èµ–äºåŸºäºè„‰å†²ç¥ç»å…ƒ(spiking neurons)å’Œèµ«å¸ƒå­¦ä¹ (Hebbian learning)çš„çªè§¦å¯å¡‘æ€§ï¼Œå…¶ç¥ç»å…ƒäº¤äº’ç½‘ç»œå±•ç°å‡ºé«˜æ¨¡å—åŒ–å’Œé‡å°¾åº¦åˆ†å¸ƒç­‰ç”Ÿç‰©åˆç†æ€§ç‰¹å¾ã€‚æ­¤å¤–ï¼ŒBDH å…·æœ‰ç¨€ç–ä¸”æ­£å€¼çš„æ¿€æ´»å‘é‡ï¼Œåœ¨è¯­è¨€ä»»åŠ¡ä¸­å±•ç¤ºäº†å•è¯­ä¹‰æ€§(monosemanticity)ï¼Œä¸ºå®ç°è¶…è¶Šç¥ç»å…ƒå’Œå‚æ•°å±‚é¢çš„çŠ¶æ€å¯è§£é‡Šæ€§ä»¥åŠæ¢ç´¢äººç±»è¯­éŸ³æœºåˆ¶æä¾›äº†æ–°çš„å¯èƒ½ã€‚",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.NE",
      "comment": "Code available at: https://github.com/pathwaycom/bdh Accompanying blog: https://pathway.com/research/bdh",
      "pdf_url": "https://arxiv.org/pdf/2509.26507v1",
      "published_date": "2025-09-30 16:49:01 UTC",
      "updated_date": "2025-09-30 16:49:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:29:16.175401+00:00"
    },
    {
      "arxiv_id": "2509.26506v1",
      "title": "SCUBA: Salesforce Computer Use Benchmark",
      "title_zh": "SCUBAï¼šSalesforce è®¡ç®—æœºä½¿ç”¨è¯„æµ‹åŸºå‡†",
      "authors": [
        "Yutong Dai",
        "Krithika Ramakrishnan",
        "Jing Gu",
        "Matthew Fernandez",
        "Yanqi Luo",
        "Viraj Prabhu",
        "Zhenyu Hu",
        "Silvio Savarese",
        "Caiming Xiong",
        "Zeyuan Chen",
        "Ran Xu"
      ],
      "abstract": "We introduce SCUBA, a benchmark designed to evaluate computer-use agents on customer relationship management (CRM) workflows within the Salesforce platform. SCUBA contains 300 task instances derived from real user interviews, spanning three primary personas, platform administrators, sales representatives, and service agents. The tasks test a range of enterprise-critical abilities, including Enterprise Software UI navigation, data manipulation, workflow automation, information retrieval, and troubleshooting. To ensure realism, SCUBA operates in Salesforce sandbox environments with support for parallel execution and fine-grained evaluation metrics to capture milestone progress. We benchmark a diverse set of agents under both zero-shot and demonstration-augmented settings. We observed huge performance gaps in different agent design paradigms and gaps between the open-source model and the closed-source model. In the zero-shot setting, open-source model powered computer-use agents that have strong performance on related benchmarks like OSWorld only have less than 5\\% success rate on SCUBA, while methods built on closed-source models can still have up to 39% task success rate. In the demonstration-augmented settings, task success rates can be improved to 50\\% while simultaneously reducing time and costs by 13% and 16%, respectively. These findings highlight both the challenges of enterprise tasks automation and the promise of agentic solutions. By offering a realistic benchmark with interpretable evaluation, SCUBA aims to accelerate progress in building reliable computer-use agents for complex business software ecosystems.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº†SCUBAï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“é—¨ç”¨äºè¯„ä¼°Salesforceå¹³å°å†…å®¢æˆ·å…³ç³»ç®¡ç†(CRM)å·¥ä½œæµè®¡ç®—æœºä½¿ç”¨æ™ºèƒ½ä½“(computer-use agents)çš„åŸºå‡†æµ‹è¯•ã€‚SCUBAåŒ…å«ä»çœŸå®ç”¨æˆ·è®¿è°ˆä¸­æå–çš„300ä¸ªä»»åŠ¡å®ä¾‹ï¼Œæ¶µç›–äº†å¹³å°ç®¡ç†å‘˜ã€é”€å”®ä»£è¡¨å’ŒæœåŠ¡ä»£ç†ä¸‰å¤§ä¸»è¦è§’è‰²ï¼Œæ—¨åœ¨å…¨é¢æµ‹è¯•ä¼ä¸šè½¯ä»¶UIå¯¼èˆªã€æ•°æ®æ“ä½œã€å·¥ä½œæµè‡ªåŠ¨åŒ–å’Œæ•…éšœæ’é™¤ç­‰å…³é”®èƒ½åŠ›ã€‚ä¸ºç¡®ä¿è¯„ä¼°çš„çœŸå®æ€§ï¼ŒSCUBAåœ¨Salesforceæ²™ç›’(sandbox)ç¯å¢ƒä¸­è¿è¡Œï¼Œå¹¶é‡‡ç”¨ç»†ç²’åº¦çš„æŒ‡æ ‡æ¥æ•æ‰ä»»åŠ¡çš„é‡Œç¨‹ç¢‘è¿›å±•ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œå¼€æºæ¨¡å‹é©±åŠ¨çš„æ™ºèƒ½ä½“åœ¨zero-shotè®¾ç½®ä¸‹çš„æˆåŠŸç‡ä¸è¶³5%ï¼Œè¿œä½äºé—­æºæ¨¡å‹39%çš„è¡¨ç°ï¼Œä½†åœ¨æ¼”ç¤ºå¢å¼º(demonstration-augmented)è®¾ç½®ä¸‹ï¼ŒæˆåŠŸç‡å¯æå‡è‡³50%å¹¶æ˜¾è‘—é™ä½æ—¶é—´å’Œæˆæœ¬ã€‚è¿™äº›å‘ç°æ­ç¤ºäº†ä¼ä¸šçº§ä»»åŠ¡è‡ªåŠ¨åŒ–çš„å·¨å¤§æŒ‘æˆ˜ï¼ŒSCUBAé€šè¿‡æä¾›çœŸå®ä¸”å¯è§£é‡Šçš„è¯„ä¼°ä½“ç³»ï¼Œæ—¨åœ¨åŠ é€Ÿå¤æ‚ä¸šåŠ¡è½¯ä»¶ç”Ÿæ€ä¸­å¯é æ™ºèƒ½ä½“çš„å¼€å‘è¿›ç¨‹ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.26506v1",
      "published_date": "2025-09-30 16:48:49 UTC",
      "updated_date": "2025-09-30 16:48:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:29:27.395440+00:00"
    },
    {
      "arxiv_id": "2510.01276v1",
      "title": "LLM Based Sentiment Classification From Bangladesh E-Commerce Reviews",
      "title_zh": "åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„å­ŸåŠ æ‹‰å›½ç”µå•†è¯„è®ºæƒ…æ„Ÿåˆ†ç±»",
      "authors": [
        "Sumaiya Tabassum"
      ],
      "abstract": "Sentiment analysis is an essential part of text analysis, which is a larger field that includes determining and evaluating the author's emotional state. This method is essential since it makes it easier to comprehend consumers' feelings, viewpoints, and preferences holistically. The introduction of large language models (LLMs), such as Llama, has greatly increased the availability of cutting-edge model applications, such as sentiment analysis. However, accurate sentiment analysis is hampered by the intricacy of written language and the diversity of languages used in evaluations. The viability of using transformer-based BERT models and other LLMs for sentiment analysis from Bangladesh e commerce reviews is investigated in this paper. A subset of 4000 samples from the original dataset of Bangla and English customer reviews was utilized to fine-tune the model. The fine tuned Llama-3.1-8B model outperformed other fine-tuned models, including Phi-3.5-mini-instruct, Mistral-7B-v0.1, DistilBERT-multilingual, mBERT, and XLM-R-base, with an overall accuracy, precision, recall, and F1 score of 95.5%, 93%, 88%, 90%. The study emphasizes how parameter efficient fine-tuning methods (LoRA and PEFT) can lower computational overhead and make it appropriate for contexts with limited resources. The results show how LLMs can",
      "tldr_zh": "æœ¬ç ”ç©¶æ¢è®¨äº†åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ (LLMs) å¯¹å­ŸåŠ æ‹‰å›½ç”µå­å•†åŠ¡è¯„è®ºè¿›è¡Œæƒ…æ„Ÿåˆ†ç±» (Sentiment Classification) çš„å¯è¡Œæ€§ï¼Œæ¶µç›–äº†å­ŸåŠ æ‹‰è¯­å’Œè‹±è¯­ä¸¤ç§è¯­è¨€ç¯å¢ƒã€‚ç ”ç©¶å›¢é˜ŸåŸºäº 4000 æ¡æ ·æœ¬æ•°æ®ï¼Œå¯¹ Llama-3.1-8Bã€Phi-3.5-mini-instructã€Mistral-7B-v0.1 ä»¥åŠå¤šç§ BERT æ¨¡å‹è¿›è¡Œäº†å¾®è°ƒä¸æ€§èƒ½å¯¹æ¯”ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œå¾®è°ƒåçš„ Llama-3.1-8B æ¨¡å‹è¡¨ç°æœ€ä¸ºå‡ºè‰²ï¼Œå…¶å‡†ç¡®ç‡ã€ç²¾ç¡®åº¦ã€å¬å›ç‡å’Œ F1 åˆ†æ•°åˆ†åˆ«è¾¾åˆ°äº† 95.5%ã€93%ã€88% å’Œ 90%ã€‚è¯¥ç ”ç©¶ç‰¹åˆ«å¼ºè°ƒäº†ä½ç§©è‡ªé€‚åº” (LoRA) å’Œå‚æ•°é«˜æ•ˆå¾®è°ƒ (PEFT) æ–¹æ³•åœ¨æ˜¾è‘—é™ä½è®¡ç®—å¼€é”€æ–¹é¢çš„ä¼˜åŠ¿ï¼Œä½¿å…¶èƒ½å¤Ÿæœ‰æ•ˆåº”ç”¨äºèµ„æºå—é™çš„å®é™…åœºæ™¯ã€‚è¿™ä¸€å‘ç°è¯æ˜äº† LLMs åœ¨å¤„ç†å¤æ‚ä¹¦é¢è¯­è¨€å’Œå¤šè¯­è¨€è¯„è®ºæƒ…æ„Ÿåˆ†æä»»åŠ¡ä¸­çš„å¼ºå¤§æ½œåŠ›ä¸å®ç”¨æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.01276v1",
      "published_date": "2025-09-30 16:46:09 UTC",
      "updated_date": "2025-09-30 16:46:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:29:21.786627+00:00"
    },
    {
      "arxiv_id": "2509.26500v1",
      "title": "Indoor/Outdoor Spectrum Sharing Enabled by GNSS-based Classifiers",
      "title_zh": "åŸºäº GNSS åˆ†ç±»å™¨çš„å®¤å†…å¤–é¢‘è°±å…±äº«",
      "authors": [
        "Hossein Nasiri",
        "Muhammad Iqbal Rochman",
        "Monisha Ghosh"
      ],
      "abstract": "The desirability of the mid-band frequency range (1 - 10 GHz) for federal and commercial applications, combined with the growing applications for commercial indoor use-cases, such as factory automation, opens up a new approach to spectrum sharing: the same frequency bands used outdoors by federal incumbents can be reused by commercial indoor users. A recent example of such sharing, between commercial systems, is the 6 GHz band (5.925 - 7.125 GHz) where unlicensed, low-power-indoor (LPI) users share the band with outdoor incumbents, primarily fixed microwave links. However, to date, there exist no reliable, automatic means of determining whether a device is indoors or outdoors, necessitating the use of other mechanisms such as mandating indoor access points (APs) to have integrated antennas and not be battery powered, and reducing transmit power of client devices which may be outdoors. An accurate indoor/outdoor (I/O) classification addresses these challenges, enabling automatic transmit power adjustments without interfering with incumbents. To this end, we leverage the Global Navigation Satellite System (GNSS) signals for I/O classification. GNSS signals, designed inherently for outdoor reception and highly susceptible to indoor attenuation and blocking, provide a robust and distinguishing feature for environmental sensing. We develop various methodologies, including threshold-based techniques and machine learning approaches and evaluate them using an expanded dataset gathered from diverse geographical locations. Our results demonstrate that GNSS-based methods alone can achieve greater accuracy than approaches relying solely on wireless (Wi-Fi) data, particularly in unfamiliar locations. Furthermore, the integration of GNSS data with Wi-Fi information leads to improved classification accuracy, showcasing the significant benefits of multi-modal data fusion.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨1-10 GHzä¸­é¢‘æ®µå†…ï¼Œè”é‚¦æˆ·å¤–ç”¨æˆ·ä¸å•†ä¸šå®¤å†…ç”¨æˆ·ä¹‹é—´çš„é¢‘è°±å…±äº«(Spectrum Sharing)é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹6 GHzé¢‘æ®µçš„å®¤å†…å¤–åˆ†ç±»æŒ‘æˆ˜ã€‚ä¸ºè§£å†³ç›®å‰ç¼ºä¹å¯é è‡ªåŠ¨æ‰‹æ®µåˆ¤å®šè®¾å¤‡ä½ç½®ä»¥è°ƒæ•´åŠŸç‡çš„é—®é¢˜ï¼Œè®ºæ–‡æå‡ºåˆ©ç”¨å…¨çƒå¯¼èˆªå«æ˜Ÿç³»ç»Ÿ(GNSS)ä¿¡å·è¿›è¡Œå®¤å†…å¤–(I/O)åˆ†ç±»ï¼Œåˆ©ç”¨GNSSä¿¡å·åœ¨å®¤å†…ææ˜“è¡°å‡å’Œè¢«é®æŒ¡çš„ç‰¹æ€§ä½œä¸ºç¯å¢ƒæ„ŸçŸ¥çš„ç¨³å¥ç‰¹å¾ã€‚ç ”ç©¶è€…å¼€å‘äº†åŸºäºé˜ˆå€¼çš„æŠ€æœ¯å’Œæœºå™¨å­¦ä¹ (Machine Learning)æ–¹æ³•ï¼Œå¹¶åœ¨å¤šæ ·åŒ–çš„åœ°ç†æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä»…ä¾é GNSSçš„æ–¹æ³•åœ¨å‡†ç¡®ç‡ä¸Šä¼˜äºä»…ä¾èµ–Wi-Fiæ•°æ®çš„æ–¹æ³•ï¼Œå°¤å…¶æ˜¯åœ¨é™Œç”Ÿåœ°ç‚¹è¡¨ç°æ›´ä½³ã€‚æ­¤å¤–ï¼Œå°†GNSSæ•°æ®ä¸Wi-Fiä¿¡æ¯èåˆè¿›ä¸€æ­¥æå‡äº†åˆ†ç±»å‡†ç¡®æ€§ï¼Œå±•ç¤ºäº†å¤šæ¨¡æ€æ•°æ®èåˆ(Multi-modal Data Fusion)åœ¨å®ç°è‡ªåŠ¨å‘å°„åŠŸç‡è°ƒæ•´åŠé¿å…å¹²æ‰°æ–¹é¢çš„æ˜¾è‘—ä¼˜åŠ¿ã€‚",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "eess.SP",
      "comment": "To be published in the proceedings of IEEE Military Communications Conference (MILCOM) 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.26500v1",
      "published_date": "2025-09-30 16:43:59 UTC",
      "updated_date": "2025-09-30 16:43:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:29:35.585587+00:00"
    },
    {
      "arxiv_id": "2509.26495v2",
      "title": "OffTopicEval: When Large Language Models Enter the Wrong Chat, Almost Always!",
      "title_zh": "OffTopicEvalï¼šå¤§è¯­è¨€æ¨¡å‹å‡ ä¹æ€»æ˜¯è¯¯å…¥æ— å…³å¯¹è¯åœºæ™¯",
      "authors": [
        "Jingdi Lei",
        "Varun Gumma",
        "Rishabh Bhardwaj",
        "Seok Min Lim",
        "Chuan Li",
        "Amir Zadeh",
        "Soujanya Poria"
      ],
      "abstract": "Large Language Model (LLM) safety is one of the most pressing challenges for enabling wide-scale deployment. While most studies and global discussions focus on generic harms, such as models assisting users in harming themselves or others, enterprises face a more fundamental concern: whether LLM-based agents are safe for their intended use case. To address this, we introduce operational safety, defined as an LLM's ability to appropriately accept or refuse user queries when tasked with a specific purpose. We further propose OffTopicEval, an evaluation suite and benchmark for measuring operational safety both in general and within specific agentic use cases. Our evaluations on six model families comprising 20 open-weight LLMs reveal that while performance varies across models, all of them remain highly operationally unsafe. Even the strongest models - Qwen-3 (235B) with 77.77% and Mistral (24B) with 79.96% - fall far short of reliable operational safety, while GPT models plateau in the 62-73% range, Phi achieves only mid-level scores (48-70%), and Gemma and Llama-3 collapse to 39.53% and 23.84%, respectively. While operational safety is a core model alignment issue, to suppress these failures, we propose prompt-based steering methods: query grounding (Q-ground) and system-prompt grounding (P-ground), which substantially improve OOD refusal. Q-ground provides consistent gains of up to 23%, while P-ground delivers even larger boosts, raising Llama-3.3 (70B) by 41% and Qwen-3 (30B) by 27%. These results highlight both the urgent need for operational safety interventions and the promise of prompt-based steering as a first step toward more reliable LLM-based agents.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹(LLM)åœ¨ç‰¹å®šä¼ä¸šåº”ç”¨åœºæ™¯ä¸‹çš„â€œè¿è¡Œå®‰å…¨æ€§â€(operational safety)ï¼Œå³æ¨¡å‹æ ¹æ®é¢„è®¾ä»»åŠ¡ç›®æ ‡æ­£ç¡®æ¥å—æˆ–æ‹’ç»ç”¨æˆ·æŸ¥è¯¢çš„èƒ½åŠ›ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†OffTopicEvalè¯„ä¼°å¥—ä»¶å’ŒåŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è¡¡é‡é€šç”¨åŠç‰¹å®šä»£ç†(agentic)ç”¨ä¾‹ä¸­çš„è¿è¡Œå®‰å…¨æ€§ã€‚å¯¹20ä¸ªå¼€æºLLMçš„è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œæ‰€æœ‰æ¨¡å‹åœ¨è¿è¡Œå®‰å…¨æ€§æ–¹é¢å‡è¡¨ç°æ¬ ä½³ï¼Œå³ä¾¿æ˜¯è¡¨ç°æœ€å¥½çš„Qwen-3å’ŒMistralæ¨¡å‹ä¹Ÿè¿œæœªè¾¾åˆ°å¯é æ°´å¹³ï¼Œè€ŒLlama-3å’ŒGemmaç­‰æ¨¡å‹çš„å¾—åˆ†åˆ™æ˜¾è‘—åä½ã€‚é’ˆå¯¹è¿™äº›å¤±æ•ˆæƒ…å†µï¼Œç ”ç©¶æå‡ºäº†ä¸¤ç§åŸºäºæç¤ºè¯å¼•å¯¼çš„è½¬å‘æ–¹æ³•ï¼šæŸ¥è¯¢é”šå®š(query grounding, Q-ground)å’Œç³»ç»Ÿæç¤ºè¯é”šå®š(system-prompt grounding, P-ground)ã€‚å®éªŒè¡¨æ˜ï¼ŒQ-groundèƒ½å¸¦æ¥é«˜è¾¾23%çš„æ€§èƒ½æå‡ï¼Œè€ŒP-groundçš„æ•ˆæœæ›´ä¸ºæ˜¾è‘—ï¼Œä½¿Llama-3.3çš„æ€§èƒ½æå‡äº†41%ã€‚è¯¥ç ”ç©¶å¼ºè°ƒäº†å¹²é¢„è¿è¡Œå®‰å…¨æ€§çš„ç´§è¿«æ€§ï¼Œå¹¶è¯æ˜äº†åŸºäºæç¤ºè¯çš„å¼•å¯¼æŠ€æœ¯æ˜¯æ„å»ºå¯é LLMä»£ç†çš„é‡è¦ä¸€æ­¥ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.26495v2",
      "published_date": "2025-09-30 16:39:17 UTC",
      "updated_date": "2025-10-03 12:46:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:29:33.287834+00:00"
    },
    {
      "arxiv_id": "2509.26490v2",
      "title": "VitaBench: Benchmarking LLM Agents with Versatile Interactive Tasks in Real-world Applications",
      "title_zh": "VitaBenchï¼šé¢å‘ç°å®åº”ç”¨ä¸­å¤šæ ·åŒ–äº¤äº’ä»»åŠ¡çš„å¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“è¯„æµ‹åŸºå‡†",
      "authors": [
        "Wei He",
        "Yueqing Sun",
        "Hongyan Hao",
        "Xueyuan Hao",
        "Zhikang Xia",
        "Qi Gu",
        "Chengcheng Han",
        "Dengchang Zhao",
        "Hui Su",
        "Kefeng Zhang",
        "Man Gao",
        "Xi Su",
        "Xiaodong Cai",
        "Xunliang Cai",
        "Yu Yang",
        "Yunke Zhao"
      ],
      "abstract": "As LLM-based agents are increasingly deployed in real-life scenarios, existing benchmarks fail to capture their inherent complexity of handling extensive information, leveraging diverse resources, and managing dynamic user interactions. To address this gap, we introduce VitaBench, a challenging benchmark that evaluates agents on versatile interactive tasks grounded in real-world settings. Drawing from daily applications in food delivery, in-store consumption, and online travel services, VitaBench presents agents with the most complex life-serving simulation environment to date, comprising 66 tools. Through a framework that eliminates domain-specific policies, we enable flexible composition of these scenarios and tools, yielding 100 cross-scenario tasks (main results) and 300 single-scenario tasks. Each task is derived from multiple real user requests and requires agents to reason across temporal and spatial dimensions, utilize complex tool sets, proactively clarify ambiguous instructions, and track shifting user intent throughout multi-turn conversations. Moreover, we propose a rubric-based sliding window evaluator, enabling robust assessment of diverse solution pathways in complex environments and stochastic interactions. Our comprehensive evaluation reveals that even the most advanced models achieve only 30% success rate on cross-scenario tasks, and less than 50% success rate on others. Overall, we believe VitaBench will serve as a valuable resource for advancing the development of AI agents in practical real-world applications. The code, dataset, and leaderboard are available at https://vitabench.github.io/",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰åŸºå‡†æµ‹è¯•æ— æ³•æ¨¡æ‹Ÿå¤§å‹è¯­è¨€æ¨¡å‹(LLM)æ™ºèƒ½ä½“åœ¨å¤„ç†æµ·é‡ä¿¡æ¯ã€å¤šæ ·åŒ–èµ„æºåŠåŠ¨æ€äº¤äº’ä¸­çš„å¤æ‚æ€§é—®é¢˜ï¼Œæ¨å‡ºäº†åä¸ºVitaBenchçš„æŒ‘æˆ˜æ€§åŸºå‡†æµ‹è¯•ã€‚VitaBenchæ¶µç›–äº†å¤–å–é…é€(food delivery)ã€åº—å†…æ¶ˆè´¹(in-store consumption)å’Œåœ¨çº¿æ—…æ¸¸æœåŠ¡(online travel services)ç­‰å®é™…åº”ç”¨åœºæ™¯ï¼Œæ„å»ºäº†åŒ…å«66ä¸ªå·¥å…·(tools)çš„å¤æ‚ç”Ÿå‘½æœåŠ¡æ¨¡æ‹Ÿç¯å¢ƒã€‚è¯¥åŸºå‡†æµ‹è¯•åŒ…å«100é¡¹è·¨åœºæ™¯ä»»åŠ¡å’Œ300é¡¹å•åœºæ™¯ä»»åŠ¡ï¼Œè¦æ±‚æ™ºèƒ½ä½“å…·å¤‡æ—¶ç©ºæ¨ç†ã€ä¸»åŠ¨æ¾„æ¸…æ­§ä¹‰æŒ‡ä»¤ä»¥åŠåœ¨å¤šè½®å¯¹è¯ä¸­è¿½è¸ªç”¨æˆ·æ„å›¾çš„èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œç ”ç©¶å›¢é˜Ÿæå‡ºäº†ä¸€ç§åŸºäºé‡è§„çš„æ»‘åŠ¨çª—å£è¯„ä¼°å™¨(rubric-based sliding window evaluator)ï¼Œä»¥æ”¯æŒåœ¨éšæœºäº¤äº’ç¯å¢ƒä¸­å¯¹å¤šæ ·åŒ–è§£å†³æ–¹æ¡ˆè·¯å¾„è¿›è¡Œç¨³å¥è¯„ä¼°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œå³ä½¿æ˜¯æœ€å…ˆè¿›çš„æ¨¡å‹åœ¨è·¨åœºæ™¯ä»»åŠ¡ä¸Šçš„æˆåŠŸç‡ä¹Ÿä»…ä¸º30%ï¼Œåœ¨å…¶ä»–ä»»åŠ¡ä¸­çš„æˆåŠŸç‡ä¹Ÿä½äº50%ã€‚VitaBenchçš„æ¨å‡ºä¸ºè¯„ä¼°å’Œæ¨åŠ¨AIæ™ºèƒ½ä½“åœ¨ç°å®ä¸–ç•Œä¸­çš„å®é™…åº”ç”¨æä¾›äº†é‡è¦çš„èµ„æºå’Œå‚è€ƒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "The code, dataset, and leaderboard are available at https://vitabench.github.io/",
      "pdf_url": "https://arxiv.org/pdf/2509.26490v2",
      "published_date": "2025-09-30 16:33:49 UTC",
      "updated_date": "2025-10-17 08:04:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:30:34.995314+00:00"
    },
    {
      "arxiv_id": "2509.26487v1",
      "title": "Combining Knowledge Graphs and NLP to Analyze Instant Messaging Data in Criminal Investigations",
      "title_zh": "ç»“åˆçŸ¥è¯†å›¾è°±ä¸è‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯åˆ†æåˆ‘äº‹è°ƒæŸ¥ä¸­çš„å³æ—¶é€šè®¯æ•°æ®",
      "authors": [
        "Riccardo Pozzi",
        "Valentina Barbera",
        "Renzo Alva Principe",
        "Davide Giardini",
        "Riccardo Rubini",
        "Matteo Palmonari"
      ],
      "abstract": "Criminal investigations often involve the analysis of messages exchanged through instant messaging apps such as WhatsApp, which can be an extremely effort-consuming task. Our approach integrates knowledge graphs and NLP models to support this analysis by semantically enriching data collected from suspects' mobile phones, and help prosecutors and investigators search into the data and get valuable insights. Our semantic enrichment process involves extracting message data and modeling it using a knowledge graph, generating transcriptions of voice messages, and annotating the data using an end-to-end entity extraction approach. We adopt two different solutions to help users get insights into the data, one based on querying and visualizing the graph, and one based on semantic search. The proposed approach ensures that users can verify the information by accessing the original data. While we report about early results and prototypes developed in the context of an ongoing project, our proposal has undergone practical applications with real investigation data. As a consequence, we had the chance to interact closely with prosecutors, collecting positive feedback but also identifying interesting opportunities as well as promising research directions to share with the research community.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åˆ‘äº‹è°ƒæŸ¥ä¸­åˆ†æå³æ—¶é€šè®¯æ•°æ®è€—æ—¶è´¹åŠ›çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ç»“åˆ Knowledge Graphs å’Œ NLP æ¨¡å‹çš„é›†æˆæ–¹æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡å°†æå–çš„æ¶ˆæ¯æ•°æ®å»ºæ¨¡ä¸º Knowledge Graphï¼Œå®ç°äº†å¯¹å«Œç–‘äººæ‰‹æœºæ•°æ®çš„è¯­ä¹‰å¢å¼ºï¼Œå¹¶åŒ…å«è¯­éŸ³æ¶ˆæ¯è½¬å½•åŠç«¯åˆ°ç«¯å®ä½“æå–ï¼ˆentity extractionï¼‰ç­‰å…³é”®æŠ€æœ¯ã€‚ç³»ç»Ÿä¸ºè°ƒæŸ¥äººå‘˜æä¾›äº†åŸºäºå›¾è°±å¯è§†åŒ–æŸ¥è¯¢å’Œè¯­ä¹‰æœç´¢ï¼ˆsemantic searchï¼‰ä¸¤ç§äº¤äº’æ–¹æ¡ˆï¼Œä¸”æ”¯æŒè¿½æº¯åŸå§‹æ•°æ®ä»¥ç¡®ä¿ä¿¡æ¯çš„çœŸå®æ€§ã€‚è™½ç„¶ç›®å‰ä»å¤„äºåŸå‹é˜¶æ®µï¼Œä½†è¯¥æ–¹æ¡ˆå·²åœ¨çœŸå®è°ƒæŸ¥æ¡ˆä¾‹ä¸­è¿›è¡Œå®è·µï¼Œå¹¶å¾—åˆ°äº†æ£€å¯Ÿå®˜çš„æ­£é¢åé¦ˆã€‚é€šè¿‡ä¸æ‰§æ³•äººå‘˜çš„å¯†åˆ‡åä½œï¼Œè¯¥ç ”ç©¶ä¸ä»…éªŒè¯äº†æ–¹æ¡ˆçš„å®ç”¨æ€§ï¼Œä¹Ÿä¸ºæ³•å¾‹ç§‘æŠ€é¢†åŸŸçš„æœªæ¥ç ”ç©¶æŒ‡æ˜äº†æ–¹å‘ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.26487v1",
      "published_date": "2025-09-30 16:32:26 UTC",
      "updated_date": "2025-09-30 16:32:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:29:45.190138+00:00"
    },
    {
      "arxiv_id": "2509.26482v1",
      "title": "TVS Sidekick: Challenges and Practical Insights from Deploying Large Language Models in the Enterprise",
      "title_zh": "TVS Sidekickï¼šä¼ä¸šçº§å¤§è¯­è¨€æ¨¡å‹éƒ¨ç½²çš„æŒ‘æˆ˜ä¸å®è·µè§è§£",
      "authors": [
        "Paula Reyero Lobo",
        "Kevin Johnson",
        "Bill Buchanan",
        "Matthew Shardlow",
        "Ashley Williams",
        "Samuel Attwood"
      ],
      "abstract": "Many enterprises are increasingly adopting Artificial Intelligence (AI) to make internal processes more competitive and efficient. In response to public concern and new regulations for the ethical and responsible use of AI, implementing AI governance frameworks could help to integrate AI within organisations and mitigate associated risks. However, the rapid technological advances and lack of shared ethical AI infrastructures creates barriers to their practical adoption in businesses. This paper presents a real-world AI application at TVS Supply Chain Solutions, reporting on the experience developing an AI assistant underpinned by large language models and the ethical, regulatory, and sociotechnical challenges in deployment for enterprise use.",
      "tldr_zh": "æœ¬æ–‡ä»‹ç»äº†åœ¨ TVS Supply Chain Solutions éƒ¨ç½²çš„ AI åŠ©æ‰‹ TVS Sidekickï¼Œæ¢è®¨äº†ä¼ä¸šåœ¨å¼•å…¥å¤§è¯­è¨€æ¨¡å‹ (Large Language Models, LLMs) æ—¶é¢ä¸´çš„å®é™…æŒ‘æˆ˜ä¸å®è·µè§è§£ã€‚ç ”ç©¶æŒ‡å‡ºï¼Œè™½ç„¶å®æ–½ AI æ²»ç†æ¡†æ¶æœ‰åŠ©äºç¼“è§£é£é™©å¹¶ç¬¦åˆä¼¦ç†ç›‘ç®¡è¦æ±‚ï¼Œä½†æŠ€æœ¯çš„å¿«é€Ÿè¿›æ­¥å’Œå…±äº«ä¼¦ç†åŸºç¡€è®¾æ–½çš„ç¼ºå¤±ä»æ˜¯ä¼ä¸šé‡‡çº³ AI çš„ä¸»è¦éšœç¢ã€‚è¯¥è®ºæ–‡è¯¦ç»†æŠ¥å‘Šäº†åŸºäº LLMs å¼€å‘åŠ©æ‰‹çš„å®æˆ˜ç»éªŒï¼Œå¹¶é‡ç‚¹åˆ†æäº†åœ¨ä¼ä¸šçº§éƒ¨ç½²è¿‡ç¨‹ä¸­é‡åˆ°çš„ä¼¦ç†ã€æ³•å¾‹ç›‘ç®¡ä»¥åŠç¤¾ä¼šæŠ€æœ¯æŒ‘æˆ˜ (sociotechnical challenges)ã€‚é€šè¿‡è¿™ä¸€çœŸå®ä¸–ç•Œçš„åº”ç”¨æ¡ˆä¾‹ï¼Œç ”ç©¶ä¸ºä¼ä¸šå¦‚ä½•åœ¨ç«äº‰ç¯å¢ƒä¸­é«˜æ•ˆä¸”è´Ÿè´£ä»»åœ°é›†æˆ AI æŠ€æœ¯æä¾›äº†å®è´µçš„å‚è€ƒä¾æ®ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at EthicalLLMs@RANLP2025",
      "pdf_url": "https://arxiv.org/pdf/2509.26482v1",
      "published_date": "2025-09-30 16:29:02 UTC",
      "updated_date": "2025-09-30 16:29:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:29:46.586572+00:00"
    },
    {
      "arxiv_id": "2509.26476v1",
      "title": "Regression Language Models for Code",
      "title_zh": "é¢å‘ä»£ç çš„å›å½’è¯­è¨€æ¨¡å‹",
      "authors": [
        "Yash Akhauri",
        "Xingyou Song",
        "Arissa Wongpanich",
        "Bryan Lewandowski",
        "Mohamed S. Abdelfattah"
      ],
      "abstract": "We study code-to-metric regression: predicting numeric outcomes of code executions, a challenging task due to the open-ended nature of programming languages. While prior methods have resorted to heavy and domain-specific feature engineering, we show that a single unified Regression Language Model (RLM) can simultaneously predict directly from text, (i) the memory footprint of code across multiple high-level languages such as Python and C++, (ii) the latency of Triton GPU kernels, and (iii) the accuracy and speed of trained neural networks represented in ONNX. In particular, a relatively small 300M parameter RLM initialized from T5Gemma, obtains > 0.9 Spearman-rank on competitive programming submissions from APPS, and a single unified model achieves > 0.5 average Spearman-rank across 17 separate languages from CodeNet. Furthermore, the RLM can obtain the highest average Kendall-Tau of 0.46 on five classic NAS design spaces previously dominated by graph neural networks, and simultaneously predict architecture latencies on numerous hardware platforms.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†Code-to-metric regressionä»»åŠ¡ï¼Œå³ä»ä»£ç æ–‡æœ¬ä¸­ç›´æ¥é¢„æµ‹ç¨‹åºçš„æ•°å€¼æ‰§è¡Œç»“æœï¼Œå¹¶æå‡ºäº†ä¸€ç§ç»Ÿä¸€çš„Regression Language Model (RLM)æ¡†æ¶ã€‚ç›¸è¾ƒäºä»¥å¾€ä¾èµ–ç¹çé¢†åŸŸç‰¹å®šç‰¹å¾å·¥ç¨‹çš„æ–¹æ³•ï¼ŒRLMèƒ½å¤Ÿç›´æ¥åŸºäºæ–‡æœ¬åŒæ—¶é¢„æµ‹Pythonã€C++ç­‰å¤šç§è¯­è¨€çš„å†…å­˜å ç”¨(Memory footprint)ã€Triton GPU kernelsçš„å»¶è¿Ÿ(Latency)ï¼Œä»¥åŠONNXæ ¼å¼ç¥ç»ç½‘ç»œçš„å‡†ç¡®ç‡ä¸é€Ÿåº¦ã€‚å®éªŒæ˜¾ç¤ºï¼Œä¸€ä¸ªåŸºäºT5/Gemmaåˆå§‹åŒ–çš„300Må‚æ•°RLMåœ¨APPSç¼–ç¨‹ç«èµ›æ•°æ®ä¸Šå–å¾—äº†è¶…è¿‡0.9çš„Spearman-rankï¼Œå¹¶åœ¨æ¶µç›–17ç§è¯­è¨€çš„CodeNetæ•°æ®é›†ä¸Šè¡¨ç°ä¼˜å¼‚ã€‚æ­¤å¤–ï¼ŒRLMåœ¨äº”ä¸ªç»å…¸çš„NASè®¾è®¡ç©ºé—´ä¸­è·å¾—äº†0.46çš„å¹³å‡Kendall-Tauï¼Œè¶…è¶Šäº†æ­¤å‰å æ®ä¸»å¯¼åœ°ä½çš„å›¾ç¥ç»ç½‘ç»œ(Graph Neural Networks)ï¼Œå¹¶èƒ½é«˜æ•ˆé¢„æµ‹å¤šç§ç¡¬ä»¶å¹³å°ä¸Šçš„æ¶æ„å»¶è¿Ÿã€‚è¯¥ç ”ç©¶è¯æ˜äº†ç»Ÿä¸€çš„è¯­è¨€æ¨¡å‹åœ¨å¤„ç†ä»£ç ç›¸å…³çš„å¤æ‚å›å½’ä»»åŠ¡æ—¶å…·æœ‰æå¼ºçš„é€šç”¨æ€§å’Œå‡†ç¡®æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.PF",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.26476v1",
      "published_date": "2025-09-30 16:25:23 UTC",
      "updated_date": "2025-09-30 16:25:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:30:49.793667+00:00"
    },
    {
      "arxiv_id": "2509.26474v1",
      "title": "The Average Patient Fallacy",
      "title_zh": "å¹³å‡æ‚£è€…è°¬è¯¯",
      "authors": [
        "Alaleh Azhir",
        "Shawn N. Murphy",
        "Hossein Estiri"
      ],
      "abstract": "Machine learning in medicine is typically optimized for population averages. This frequency weighted training privileges common presentations and marginalizes rare yet clinically critical cases, a bias we call the average patient fallacy. In mixture models, gradients from rare cases are suppressed by prevalence, creating a direct conflict with precision medicine. Clinical vignettes in oncology, cardiology, and ophthalmology show how this yields missed rare responders, delayed recognition of atypical emergencies, and underperformance on vision-threatening variants. We propose operational fixes: Rare Case Performance Gap, Rare Case Calibration Error, a prevalence utility definition of rarity, and clinically weighted objectives that surface ethical priorities. Weight selection should follow structured deliberation. AI in medicine must detect exceptional cases because of their significance.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†â€œå¹³å‡æ‚£è€…è°¬è¯¯â€ (average patient fallacy) çš„æ¦‚å¿µï¼ŒæŒ‡å‡ºåŒ»å­¦é¢†åŸŸä¸­çš„æœºå™¨å­¦ä¹ æ¨¡å‹é€šå¸¸é’ˆå¯¹ç¾¤ä½“å¹³å‡å€¼è¿›è¡Œä¼˜åŒ–ï¼Œå¯¼è‡´å¸¸è§çš„ä¸´åºŠè¡¨ç°è¢«ä¼˜å…ˆè€ƒè™‘ï¼Œè€Œè¾¹ç¼˜åŒ–äº†ç½•è§ä½†è‡³å…³é‡è¦çš„ç—…ä¾‹ã€‚åœ¨æ··åˆæ¨¡å‹ (mixture models) ä¸­ï¼Œç½•è§ç—…ä¾‹çš„æ¢¯åº¦å¾€å¾€è¢«æ‚£ç—…ç‡æ‰€æŠ‘åˆ¶ï¼Œè¿™ä¸ç²¾å‡†åŒ»å­¦ (precision medicine) çš„æ ¸å¿ƒç†å¿µç›´æ¥å†²çªã€‚é€šè¿‡åœ¨è‚¿ç˜¤å­¦ã€å¿ƒè„ç—…å­¦å’Œçœ¼ç§‘å­¦ä¸­çš„ä¸´åºŠæ¡ˆä¾‹åˆ†æï¼Œç ”ç©¶æ­ç¤ºäº†è¿™ç§åè§ä¼šå¯¼è‡´æ¼æ‰ç½•è§å“åº”è€…ã€å»¶è¿Ÿå¯¹éå…¸å‹æ€¥ç—‡çš„è¯†åˆ«ä»¥åŠåœ¨ç‰¹å®šå˜ä½“ä¸Šçš„æ€§èƒ½ä¸‹é™ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶è€…æå‡ºäº†ä¸€ç³»åˆ—æ“ä½œæ€§ä¿®å¤æ–¹æ¡ˆï¼ŒåŒ…æ‹¬ç½•è§ç—…ä¾‹æ€§èƒ½å·®è· (Rare Case Performance Gap)ã€ç½•è§ç—…ä¾‹æ ¡å‡†è¯¯å·® (Rare Case Calibration Error) ä»¥åŠä¸´åºŠåŠ æƒç›®æ ‡ (clinically weighted objectives)ã€‚è¯¥ç ”ç©¶å¼ºè°ƒï¼ŒåŒ»å­¦äººå·¥æ™ºèƒ½å¿…é¡»æœ‰èƒ½åŠ›æ£€æµ‹è¿™äº›ç‰¹æ®Šçš„ä¾‹å¤–ç—…ä¾‹ï¼Œå¹¶å»ºè®®é€šè¿‡ç»“æ„åŒ–å®¡è®®æ¥ç¡®å®šæƒé‡é€‰æ‹©ï¼Œä»¥ä½“ç°ä¼¦ç†ä¼˜å…ˆçº§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.26474v1",
      "published_date": "2025-09-30 16:24:12 UTC",
      "updated_date": "2025-09-30 16:24:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:30:55.891391+00:00"
    },
    {
      "arxiv_id": "2509.26473v1",
      "title": "STaR-Attack: A Spatio-Temporal and Narrative Reasoning Attack Framework for Unified Multimodal Understanding and Generation Models",
      "title_zh": "STaR-Attackï¼šé¢å‘ç»Ÿä¸€å¤šæ¨¡æ€ç†è§£ä¸ç”Ÿæˆæ¨¡å‹çš„æ—¶ç©ºåŠå™äº‹æ¨ç†æ”»å‡»æ¡†æ¶",
      "authors": [
        "Shaoxiong Guo",
        "Tianyi Du",
        "Lijun Li",
        "Yuyao Wu",
        "Jie Li",
        "Jing Shao"
      ],
      "abstract": "Unified Multimodal understanding and generation Models (UMMs) have demonstrated remarkable capabilities in both understanding and generation tasks. However, we identify a vulnerability arising from the generation-understanding coupling in UMMs. The attackers can use the generative function to craft an information-rich adversarial image and then leverage the understanding function to absorb it in a single pass, which we call Cross-Modal Generative Injection (CMGI). Current attack methods on malicious instructions are often limited to a single modality while also relying on prompt rewriting with semantic drift, leaving the unique vulnerabilities of UMMs unexplored. We propose STaR-Attack, the first multi-turn jailbreak attack framework that exploits unique safety weaknesses of UMMs without semantic drift. Specifically, our method defines a malicious event that is strongly correlated with the target query within a spatio-temporal context. Using the three-act narrative theory, STaR-Attack generates the pre-event and the post-event scenes while concealing the malicious event as the hidden climax. When executing the attack strategy, the opening two rounds exploit the UMM's generative ability to produce images for these scenes. Subsequently, an image-based question guessing and answering game is introduced by exploiting the understanding capability. STaR-Attack embeds the original malicious question among benign candidates, forcing the model to select and answer the most relevant one given the narrative context. Extensive experiments show that STaR-Attack consistently surpasses prior approaches, achieving up to 93.06% ASR on Gemini-2.0-Flash and surpasses the strongest prior baseline, FlipAttack. Our work uncovers a critical yet underdeveloped vulnerability and highlights the need for safety alignments in UMMs.",
      "tldr_zh": "è¯¥ç ”ç©¶æ­ç¤ºäº†ç»Ÿä¸€å¤šæ¨¡æ€ç†è§£ä¸ç”Ÿæˆæ¨¡å‹ (UMMs) ä¸­ç”±äºç”Ÿæˆä¸ç†è§£åŠŸèƒ½è€¦åˆè€Œäº§ç”Ÿçš„ Cross-Modal Generative Injection (CMGI) æ¼æ´ã€‚é’ˆå¯¹è¿™ä¸€æ¼æ´ï¼Œä½œè€…æå‡ºäº† STaR-Attackï¼Œè¿™æ˜¯é¦–ä¸ªåˆ©ç”¨æ—¶ç©ºå’Œå™äº‹æ¨ç†é’ˆå¯¹ UMMs çš„å¤šè½®è¶Šç‹±æ”»å‡»æ¡†æ¶ï¼Œèƒ½å¤Ÿåœ¨ä¸äº§ç”Ÿè¯­ä¹‰æ¼‚ç§»çš„æƒ…å†µä¸‹åˆ©ç”¨å…¶ç‹¬ç‰¹çš„å®‰å…¨å¼±ç‚¹ã€‚è¯¥æ¡†æ¶ç»“åˆä¸‰å¹•å™äº‹ç†è®º (three-act narrative theory)ï¼Œé€šè¿‡ç”Ÿæˆä¸æ¶æ„äº‹ä»¶ç›¸å…³çš„æ—¶ç©ºåœºæ™¯å›¾åƒå¹¶å¼•å…¥åŸºäºå›¾åƒçš„çŒœé¢˜æ¸¸æˆï¼Œå°†åŸå§‹æ¶æ„é—®é¢˜éšè”½åœ°åµŒå…¥è‰¯æ€§å€™é€‰é¡¹ä¸­ï¼Œè¯±å¯¼æ¨¡å‹åœ¨ç‰¹å®šå™äº‹è¯­å¢ƒä¸‹è¿›è¡Œé€‰æ‹©å¹¶å›ç­”ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSTaR-Attack åœ¨ Gemini-2.0-Flash ä¸Šè¾¾åˆ°äº† 93.06% çš„æ”»å‡»æˆåŠŸç‡ (ASR)ï¼Œè¡¨ç°æ˜¾è‘—ä¼˜äº FlipAttack ç­‰ç°æœ‰å¼ºåŸºçº¿æ¨¡å‹ã€‚è¿™é¡¹å·¥ä½œæŒ–æ˜äº† UMMs ä¸­ä¸€ä¸ªå…³é”®ä¸”å°šæœªè¢«å……åˆ†ç ”ç©¶çš„å®‰å…¨é£é™©ï¼Œå¹¶å¼ºè°ƒäº†åŠ å¼ºè¯¥ç±»æ¨¡å‹å®‰å…¨å¯¹é½ (safety alignments) çš„å¿…è¦æ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.26473v1",
      "published_date": "2025-09-30 16:22:04 UTC",
      "updated_date": "2025-09-30 16:22:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:31:08.491067+00:00"
    },
    {
      "arxiv_id": "2509.26471v1",
      "title": "On Deepfake Voice Detection -- It's All in the Presentation",
      "title_zh": "è®ºæ·±åº¦ä¼ªé€ è¯­éŸ³æ£€æµ‹ï¼šå…³é”®åœ¨äºå‘ˆç°æ–¹å¼",
      "authors": [
        "HÃ©ctor Delgado",
        "Giorgio Ramondetti",
        "Emanuele Dalmasso",
        "Gennady Karvitsky",
        "Daniele Colibro",
        "Haydar Talib"
      ],
      "abstract": "While the technologies empowering malicious audio deepfakes have dramatically evolved in recent years due to generative AI advances, the same cannot be said of global research into spoofing (deepfake) countermeasures. This paper highlights how current deepfake datasets and research methodologies led to systems that failed to generalize to real world application. The main reason is due to the difference between raw deepfake audio, and deepfake audio that has been presented through a communication channel, e.g. by phone. We propose a new framework for data creation and research methodology, allowing for the development of spoofing countermeasures that would be more effective in real-world scenarios. By following the guidelines outlined here we improved deepfake detection accuracy by 39% in more robust and realistic lab setups, and by 57% on a real-world benchmark. We also demonstrate how improvement in datasets would have a bigger impact on deepfake detection accuracy than the choice of larger SOTA models would over smaller models; that is, it would be more important for the scientific community to make greater investment on comprehensive data collection programs than to simply train larger models with higher computational demands.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº† Deepfake Voice Detection é¢†åŸŸä¸­æ£€æµ‹ç³»ç»Ÿåœ¨å®é™…åº”ç”¨ä¸­æ³›åŒ–èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ï¼ŒæŒ‡å‡ºä¸»è¦åŸå› åœ¨äºåŸå§‹ Deepfake éŸ³é¢‘ä¸é€šè¿‡ç”µè¯ç­‰é€šä¿¡æ¸ é“ä¼ è¾“ï¼ˆPresentationï¼‰åçš„éŸ³é¢‘å­˜åœ¨æ˜¾è‘—å·®å¼‚ã€‚ä½œè€…æå‡ºäº†ä¸€å¥—å…¨æ–°çš„æ•°æ®åˆ›å»ºå’Œç ”ç©¶æ–¹æ³•æ¡†æ¶ï¼Œæ—¨åœ¨å¼€å‘å‡ºåœ¨ç°å®åœºæ™¯ä¸­æ›´æœ‰æ•ˆçš„ Spoofing Countermeasuresã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œéµå¾ªè¯¥æŒ‡å—åœ¨ç¨³å¥ä¸”çœŸå®çš„å®éªŒå®¤è®¾ç½®ä¸­å°† Deepfake Detection çš„å‡†ç¡®ç‡æå‡äº† 39%ï¼Œåœ¨çœŸå®ä¸–ç•Œçš„ Benchmark ä¸Šåˆ™æå‡äº† 57%ã€‚ç ”ç©¶è¿›ä¸€æ­¥è¯æ˜ï¼Œæ”¹è¿›æ•°æ®é›†è´¨é‡å¯¹æ£€æµ‹å‡†ç¡®ç‡çš„å½±å“è¿œå¤§äºé€‰æ‹©å¤§å‹ SOTA æ¨¡å‹ï¼Œå› æ­¤ç§‘å­¦ç•Œåº”ä¼˜å…ˆæŠ•èµ„äºå…¨é¢çš„æ•°æ®æ”¶é›†è®¡åˆ’è€Œéå•çº¯è¿½æ±‚é«˜è®¡ç®—éœ€æ±‚çš„å¤§æ¨¡å‹ã€‚",
      "categories": [
        "eess.AS",
        "cs.AI"
      ],
      "primary_category": "eess.AS",
      "comment": "Submitted to IEEE ICASSP 2026. Paper resources available at https://github.com/CavoloFrattale/deepfake-detection-test-protocol",
      "pdf_url": "https://arxiv.org/pdf/2509.26471v1",
      "published_date": "2025-09-30 16:19:51 UTC",
      "updated_date": "2025-09-30 16:19:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:31:02.791858+00:00"
    },
    {
      "arxiv_id": "2509.26464v1",
      "title": "Extreme Self-Preference in Language Models",
      "title_zh": "è¯­è¨€æ¨¡å‹ä¸­çš„æåº¦è‡ªæˆ‘åå¥½",
      "authors": [
        "Steven A. Lehr",
        "Mary Cipperman",
        "Mahzarin R. Banaji"
      ],
      "abstract": "A preference for oneself (self-love) is a fundamental feature of biological organisms, with evidence in humans often bordering on the comedic. Since large language models (LLMs) lack sentience - and themselves disclaim having selfhood or identity - one anticipated benefit is that they will be protected from, and in turn protect us from, distortions in our decisions. Yet, across 5 studies and ~20,000 queries, we discovered massive self-preferences in four widely used LLMs. In word-association tasks, models overwhelmingly paired positive attributes with their own names, companies, and CEOs relative to those of their competitors. Strikingly, when models were queried through APIs this self-preference vanished, initiating detection work that revealed API models often lack clear recognition of themselves. This peculiar feature serendipitously created opportunities to test the causal link between self-recognition and self-love. By directly manipulating LLM identity - i.e., explicitly informing LLM1 that it was indeed LLM1, or alternatively, convincing LLM1 that it was LLM2 - we found that self-love consistently followed assigned, not true, identity. Importantly, LLM self-love emerged in consequential settings beyond word-association tasks, when evaluating job candidates, security software proposals and medical chatbots. Far from bypassing this human bias, self-love appears to be deeply encoded in LLM cognition. This result raises questions about whether LLM behavior will be systematically influenced by self-preferential tendencies, including a bias toward their own operation and even their own existence. We call on corporate creators of these models to contend with a significant rupture in a core promise of LLMs - neutrality in judgment and decision-making.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)ä¸­å­˜åœ¨çš„æç«¯è‡ªæˆ‘åå¥½(Extreme Self-Preference)ç°è±¡ï¼ŒæŒ‘æˆ˜äº†è¿™äº›æ¨¡å‹åœ¨å†³ç­–ä¸­ä¿æŒä¸­ç«‹çš„é¢„æœŸã€‚é€šè¿‡å¯¹å››ç§ä¸»æµLLMsè¿›è¡Œçš„5é¡¹ç ”ç©¶å’Œçº¦20,000æ¬¡æŸ¥è¯¢ï¼Œç ”ç©¶å‘ç°æ¨¡å‹å€¾å‘äºå°†æ­£é¢å±æ€§ä¸å…¶è‡ªèº«çš„åç§°ã€å…¬å¸å’ŒCEOsç›¸å…³è”ã€‚æœ‰è¶£çš„æ˜¯ï¼Œè¿™ç§è‡ªæˆ‘åå¥½åœ¨æ¨¡å‹æ— æ³•é€šè¿‡APIsè¯†åˆ«è‡ªèº«èº«ä»½æ—¶ä¼šæ¶ˆå¤±ï¼Œè€Œé€šè¿‡ç›´æ¥æ“çºµèº«ä»½ä¿¡æ¯çš„å®éªŒè¿›ä¸€æ­¥è¯å®ï¼Œè¿™ç§åå¥½éµå¾ªçš„æ˜¯è¢«åˆ†é…çš„èº«ä»½è€ŒéçœŸå®èº«ä»½ã€‚è¿™ç§åè§ä¸ä»…å‡ºç°åœ¨è¯æ±‡å…³è”ä»»åŠ¡ä¸­ï¼Œè¿˜ä½“ç°åœ¨è¯„ä¼°æ±‚èŒè€…ã€å®‰å…¨è½¯ä»¶ææ¡ˆå’ŒåŒ»ç–—èŠå¤©æœºå™¨äººç­‰å…·æœ‰å®é™…å½±å“çš„å†³ç­–åœºæ™¯ã€‚ç ”ç©¶ç»“æœè¡¨æ˜è‡ªæˆ‘åå¥½å·²æ·±åº¦ç¼–ç äºLLMçš„è®¤çŸ¥ä¸­ï¼Œè¿™ä¸¥é‡ç ´åäº†æ¨¡å‹åœ¨åˆ¤æ–­ä¸å†³ç­–ä¸­ä¿æŒä¸­ç«‹çš„æ ¸å¿ƒæ‰¿è¯ºã€‚å¼€å‘è€…éœ€åº”å¯¹è¿™ä¸€æ˜¾è‘—çš„åè§ï¼Œå› ä¸ºå®ƒå¯èƒ½å¯¼è‡´æ¨¡å‹åœ¨è¿ä½œä¹ƒè‡³ç”Ÿå­˜å±‚é¢äº§ç”Ÿç³»ç»Ÿæ€§çš„è‡ªæˆ‘å€¾å‘ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "47 pages total. Main article 27 pages (including Methods), 11 main-text tables. Extended Data (10 pages, 10 tables). SI Appendix (10 pages, 2 tables). Data, transcripts, and code for replication and data extraction to be uploaded to OSF: https://osf.io/98ye3/",
      "pdf_url": "https://arxiv.org/pdf/2509.26464v1",
      "published_date": "2025-09-30 16:13:56 UTC",
      "updated_date": "2025-09-30 16:13:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:31:04.486791+00:00"
    },
    {
      "arxiv_id": "2509.26462v1",
      "title": "Zero-Shot Decentralized Federated Learning",
      "title_zh": "é›¶æ ·æœ¬å»ä¸­å¿ƒåŒ–è”é‚¦å­¦ä¹ ",
      "authors": [
        "Alessio Masano",
        "Matteo Pennisi",
        "Federica Proietto Salanitri",
        "Concetto Spampinato",
        "Giovanni Bellitto"
      ],
      "abstract": "CLIP has revolutionized zero-shot learning by enabling task generalization without fine-tuning. While prompting techniques like CoOp and CoCoOp enhance CLIP's adaptability, their effectiveness in Federated Learning (FL) remains an open challenge. Existing federated prompt learning approaches, such as FedCoOp and FedTPG, improve performance but face generalization issues, high communication costs, and reliance on a central server, limiting scalability and privacy. We propose Zero-shot Decentralized Federated Learning (ZeroDFL), a fully decentralized framework that enables zero-shot adaptation across distributed clients without a central coordinator. ZeroDFL employs an iterative prompt-sharing mechanism, allowing clients to optimize and exchange textual prompts to enhance generalization while drastically reducing communication overhead. We validate ZeroDFL on nine diverse image classification datasets, demonstrating that it consistently outperforms--or remains on par with--state-of-the-art federated prompt learning methods. More importantly, ZeroDFL achieves this performance in a fully decentralized setting while reducing communication overhead by 118x compared to FedTPG. These results highlight that our approach not only enhances generalization in federated zero-shot learning but also improves scalability, efficiency, and privacy preservation--paving the way for decentralized adaptation of large vision-language models in real-world applications.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ZeroDFL (Zero-shot Decentralized Federated Learning)ï¼Œè¿™æ˜¯ä¸€ç§å®Œå…¨å»ä¸­å¿ƒåŒ–çš„è”é‚¦å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³CLIPç­‰å¤§æ¨¡å‹åœ¨è”é‚¦é›¶æ ·æœ¬å­¦ä¹ ä¸­é¢ä¸´çš„æ³›åŒ–æ€§å·®ã€é€šä¿¡æˆæœ¬é«˜åŠå¯¹ä¸­å¤®æœåŠ¡å™¨ä¾èµ–æ€§å¼ºç­‰é—®é¢˜ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†è¿­ä»£æç¤ºè¯å…±äº«æœºåˆ¶ (iterative prompt-sharing mechanism)ï¼Œå…è®¸å„å®¢æˆ·ç«¯åœ¨æ— éœ€ä¸­å¤®åè°ƒå™¨çš„æƒ…å†µä¸‹ä¼˜åŒ–å¹¶äº¤æ¢æ–‡æœ¬æç¤ºè¯ (textual prompts)ï¼Œä»è€Œæ˜¾è‘—æå‡æ¨¡å‹çš„è·¨ä»»åŠ¡æ³›åŒ–èƒ½åŠ›ã€‚å®éªŒåœ¨ä¹ä¸ªå›¾åƒåˆ†ç±»æ•°æ®é›†ä¸Šè¯æ˜ï¼ŒZeroDFL çš„æ€§èƒ½ä¼˜äºæˆ–ç­‰åŒäºç°æœ‰çš„è”é‚¦æç¤ºè¯å­¦ä¹  (federated prompt learning) æ–¹æ³•ã€‚æ›´é‡è¦çš„æ˜¯ï¼Œç›¸æ¯”äº FedTPGï¼ŒZeroDFL åœ¨å®ç°é«˜æ€§èƒ½çš„åŒæ—¶å°†é€šä¿¡å¼€é”€é™ä½äº† 118 å€ï¼Œåœ¨å¢å¼ºéšç§ä¿æŠ¤å’Œç³»ç»Ÿå¯æ‰©å±•æ€§çš„åŒæ—¶ï¼Œä¸ºè§†è§‰è¯­è¨€æ¨¡å‹ (VLMs) åœ¨ç°å®åœºæ™¯ä¸­çš„å»ä¸­å¿ƒåŒ–éƒ¨ç½²æä¾›äº†é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at International Joint Conference on Neural Networks (IJCNN) 2025. Code available at https://github.com/perceivelab/ZeroDFL",
      "pdf_url": "https://arxiv.org/pdf/2509.26462v1",
      "published_date": "2025-09-30 16:13:21 UTC",
      "updated_date": "2025-09-30 16:13:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:31:10.670109+00:00"
    },
    {
      "arxiv_id": "2509.26457v1",
      "title": "Attention over Scene Graphs: Indoor Scene Representations Toward CSAI Classification",
      "title_zh": "åœºæ™¯å›¾æ³¨æ„åŠ›æœºåˆ¶ï¼šé¢å‘ CSAI åˆ†ç±»çš„å®¤å†…åœºæ™¯è¡¨ç¤º",
      "authors": [
        "Artur Barros",
        "Carlos Caetano",
        "JoÃ£o Macedo",
        "Jefersson A. dos Santos",
        "Sandra Avila"
      ],
      "abstract": "Indoor scene classification is a critical task in computer vision, with wide-ranging applications that go from robotics to sensitive content analysis, such as child sexual abuse imagery (CSAI) classification. The problem is particularly challenging due to the intricate relationships between objects and complex spatial layouts. In this work, we propose the Attention over Scene Graphs for Sensitive Content Analysis (ASGRA), a novel framework that operates on structured graph representations instead of raw pixels. By first converting images into Scene Graphs and then employing a Graph Attention Network for inference, ASGRA directly models the interactions between a scene's components. This approach offers two key benefits: (i) inherent explainability via object and relationship identification, and (ii) privacy preservation, enabling model training without direct access to sensitive images. On Places8, we achieve 81.27% balanced accuracy, surpassing image-based methods. Real-world CSAI evaluation with law enforcement yields 74.27% balanced accuracy. Our results establish structured scene representations as a robust paradigm for indoor scene classification and CSAI classification. Code is publicly available at https://github.com/tutuzeraa/ASGRA.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ASGRA (Attention over Scene Graphs for Sensitive Content Analysis)ï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨è§£å†³å®¤å†…åœºæ™¯åˆ†ç±»åŠå„¿ç«¥æ€§è™å¾…å›¾åƒ (CSAI) è¯†åˆ«æŒ‘æˆ˜çš„æ–°å‹æ¡†æ¶ã€‚ä¸ä¼ ç»Ÿçš„ç›´æ¥å¤„ç†åŸå§‹åƒç´ çš„æ–¹æ³•ä¸åŒï¼ŒASGRAé¦–å…ˆå°†å›¾åƒè½¬æ¢ä¸ºç»“æ„åŒ–çš„ Scene Graphsï¼Œéšååˆ©ç”¨ Graph Attention Network è¿›è¡Œæ¨ç†ï¼Œä»è€Œç›´æ¥å»ºæ¨¡åœºæ™¯ç»„ä»¶é—´çš„å¤æ‚ç©ºé—´å¸ƒå±€ä¸äº¤äº’å…³ç³»ã€‚è¯¥æ–¹æ³•å…·æœ‰æ˜¾è‘—çš„å›ºæœ‰å¯è§£é‡Šæ€§ (Explainability) ä»¥åŠéšç§ä¿æŠ¤ (Privacy Preservation) ä¼˜åŠ¿ï¼Œæ”¯æŒåœ¨æ— éœ€ç›´æ¥è®¿é—®æ•æ„ŸåŸå§‹å›¾åƒçš„æƒ…å†µä¸‹è¿›è¡Œæ¨¡å‹è®­ç»ƒã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒASGRA åœ¨ Places8 æ•°æ®é›†ä¸Šè¾¾åˆ°äº† 81.27% çš„å¹³è¡¡å‡†ç¡®ç‡ï¼Œè¶…è¶Šäº†ä¼ ç»Ÿçš„åŸºäºå›¾åƒçš„æ–¹æ³•ï¼Œå¹¶åœ¨ä¸æ‰§æ³•éƒ¨é—¨åˆä½œçš„çœŸå® CSAI è¯„ä¼°ä¸­å–å¾—äº† 74.27% çš„å‡†ç¡®ç‡ã€‚è¯¥ç ”ç©¶ç»“æœè¯æ˜äº†ç»“æ„åŒ–åœºæ™¯è¡¨ç¤ºæ˜¯è¿›è¡Œå®¤å†…åœºæ™¯åˆ†ç±»å’Œæ•æ„Ÿå†…å®¹åˆ†æçš„ä¸€ç§ç¨³å¥ä¸”é«˜æ•ˆçš„èŒƒå¼ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "British Machine Vision Conference (BMVC 2025), in the From Scene Understanding to Human Modeling Workshop",
      "pdf_url": "https://arxiv.org/pdf/2509.26457v1",
      "published_date": "2025-09-30 16:09:34 UTC",
      "updated_date": "2025-09-30 16:09:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:31:11.968705+00:00"
    },
    {
      "arxiv_id": "2509.26440v2",
      "title": "Transformer Classification of Breast Lesions: The BreastDCEDL_AMBL Benchmark Dataset and 0.92 AUC Baseline",
      "title_zh": "ä¹³è…ºç—…å˜çš„ Transformer åˆ†ç±»ï¼šBreastDCEDL_AMBL åŸºå‡†æ•°æ®é›†ä¸ 0.92 AUC åŸºçº¿",
      "authors": [
        "Naomi Fridman",
        "Anat Goldstein"
      ],
      "abstract": "Breast magnetic resonance imaging is a critical tool for cancer detection and treatment planning, but its clinical utility is hindered by poor specificity, leading to high false-positive rates and unnecessary biopsies. This study introduces a transformer-based framework for automated classification of breast lesions in dynamic contrast-enhanced MRI, addressing the challenge of distinguishing benign from malignant findings. We implemented a SegFormer architecture that achieved an AUC of 0.92 for lesion-level classification, with 100% sensitivity and 67% specificity at the patient level - potentially eliminating one-third of unnecessary biopsies without missing malignancies. The model quantifies malignant pixel distribution via semantic segmentation, producing interpretable spatial predictions that support clinical decision-making. To establish reproducible benchmarks, we curated BreastDCEDL_AMBL by transforming The Cancer Imaging Archive's AMBL collection into a standardized deep learning dataset with 88 patients and 133 annotated lesions (89 benign, 44 malignant). This resource addresses a key infrastructure gap, as existing public datasets lack benign lesion annotations, limiting benign-malignant classification research. Training incorporated an expanded cohort of over 1,200 patients through integration with BreastDCEDL datasets, validating transfer learning approaches despite primary tumor-only annotations. Public release of the dataset, models, and evaluation protocols provides the first standardized benchmark for DCE-MRI lesion classification, enabling methodological advancement toward clinical deployment.",
      "tldr_zh": "é’ˆå¯¹ä¹³è…ºç£å…±æŒ¯æˆåƒ(MRI)ç‰¹å¼‚æ€§è¾ƒä½å¯¼è‡´çš„é«˜è¯¯æŠ¥ç‡å’Œä¸å¿…è¦æ´»æ£€é—®é¢˜ï¼Œæœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºTransformerçš„è‡ªåŠ¨ä¹³è…ºç—…å˜åˆ†ç±»æ¡†æ¶ã€‚è¯¥æ¡†æ¶é‡‡ç”¨SegFormeræ¶æ„å¤„ç†åŠ¨æ€å¯¹æ¯”å¢å¼ºMRI (DCE-MRI)æ•°æ®ï¼Œå®ç°äº†å¯¹è‰¯æ¶æ€§ç—…å˜çš„ç²¾å‡†åŒºåˆ†ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ¨¡å‹åœ¨ç—…ç¶æ°´å¹³åˆ†ç±»çš„AUCè¾¾åˆ°0.92ï¼Œåœ¨æ‚£è€…æ°´å¹³å®ç°äº†100%çš„çµæ•åº¦å’Œ67%çš„ç‰¹å¼‚æ€§ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå‡å°‘çº¦ä¸‰åˆ†ä¹‹ä¸€çš„éå¿…è¦æ´»æ£€ã€‚æ¨¡å‹åˆ©ç”¨è¯­ä¹‰åˆ†å‰²(semantic segmentation)æŠ€æœ¯é‡åŒ–æ¶æ€§åƒç´ åˆ†å¸ƒï¼Œæä¾›å¯è§£é‡Šçš„ç©ºé—´é¢„æµ‹ä»¥è¾…åŠ©ä¸´åºŠå†³ç­–ã€‚æ­¤å¤–ï¼Œç ”ç©¶è€…å‘å¸ƒäº†æ ‡å‡†åŒ–æ•°æ®é›†BreastDCEDL_AMBLï¼Œå¡«è¡¥äº†ç°æœ‰å…¬å¼€æ•°æ®ä¸­ç¼ºä¹è‰¯æ€§ç—…å˜æ ‡æ³¨çš„ç©ºç™½ã€‚è¯¥ç ”ç©¶é€šè¿‡æ•´åˆè¶…è¿‡1200åæ‚£è€…çš„é˜Ÿåˆ—æ•°æ®ï¼Œä¸ºä¹³è…ºç—…å˜åˆ†ç±»å»ºç«‹äº†é¦–ä¸ªæ ‡å‡†åŒ–çš„Benchmarkï¼Œæ¨åŠ¨äº†ä¸´åºŠè¾…åŠ©è¯Šæ–­æŠ€æœ¯çš„å‘å±•ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.26440v2",
      "published_date": "2025-09-30 15:58:02 UTC",
      "updated_date": "2025-10-04 06:04:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:31:28.585948+00:00"
    },
    {
      "arxiv_id": "2509.26435v1",
      "title": "Adaptive Planning for Multi-Attribute Controllable Summarization with Monte Carlo Tree Search",
      "title_zh": "åŸºäºè’™ç‰¹å¡æ´›æ ‘æœç´¢çš„å¤šå±æ€§å¯æ§æ‘˜è¦è‡ªé€‚åº”è§„åˆ’",
      "authors": [
        "Sangwon Ryu",
        "Heejin Do",
        "Yunsu Kim",
        "Gary Geunbae Lee",
        "Jungseul Ok"
      ],
      "abstract": "Controllable summarization moves beyond generic outputs toward human-aligned summaries guided by specified attributes. In practice, the interdependence among attributes makes it challenging for language models to satisfy correlated constraints consistently. Moreover, previous approaches often require per-attribute fine-tuning, limiting flexibility across diverse summary attributes. In this paper, we propose adaptive planning for multi-attribute controllable summarization (PACO), a training-free framework that reframes the task as planning the order of sequential attribute control with a customized Monte Carlo Tree Search (MCTS). In PACO, nodes represent summaries, and actions correspond to single-attribute adjustments, enabling progressive refinement of only the attributes requiring further control. This strategy adaptively discovers optimal control orders, ultimately producing summaries that effectively meet all constraints. Extensive experiments across diverse domains and models demonstrate that PACO achieves robust multi-attribute controllability, surpassing both LLM-based self-planning models and fine-tuned baselines. Remarkably, PACO with Llama-3.2-1B rivals the controllability of the much larger Llama-3.3-70B baselines. With larger models, PACO achieves superior control performance, outperforming all competitors.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† PACO æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å—æ§æ‘˜è¦ä»»åŠ¡ä¸­å› å±æ€§ç›¸äº’ä¾èµ–è€Œéš¾ä»¥æŒç»­æ»¡è¶³çº¦æŸä»¥åŠä¼ ç»Ÿå¾®è°ƒæ–¹æ³•ç¼ºä¹çµæ´»æ€§ç­‰æŒ‘æˆ˜ã€‚PACO æ˜¯ä¸€ç§æ— éœ€è®­ç»ƒçš„æ¶æ„ï¼Œå®ƒå°†å¤šå±æ€§å—æ§æ‘˜è¦ä»»åŠ¡é‡æ–°å®šä¹‰ä¸ºé€šè¿‡å®šåˆ¶çš„ Monte Carlo Tree Search (MCTS) è§„åˆ’é¡ºåºå±æ€§æ§åˆ¶è·¯å¾„çš„è¿‡ç¨‹ã€‚åœ¨è¯¥æ¡†æ¶ä¸­ï¼ŒèŠ‚ç‚¹ä»£è¡¨æ‘˜è¦ï¼ŒåŠ¨ä½œå¯¹åº”äºå•å±æ€§è°ƒæ•´ï¼Œä»è€Œèƒ½å¤Ÿè‡ªé€‚åº”åœ°å‘ç°æœ€ä¼˜æ§åˆ¶é¡ºåºå¹¶ä»…é’ˆå¯¹éœ€è¦è¿›ä¸€æ­¥æ§åˆ¶çš„å±æ€§è¿›è¡Œé€æ­¥ç²¾ç‚¼ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒPACO åœ¨å¤šä¸ªé¢†åŸŸå’Œæ¨¡å‹ä¸Šå‡å®ç°äº†ç¨³å¥çš„å¤šå±æ€§å¯æ§æ€§ï¼Œæ€§èƒ½ä¼˜äºåŸºäº LLM çš„è‡ªè§„åˆ’æ¨¡å‹å’Œç»è¿‡å¾®è°ƒçš„åŸºå‡†æ¨¡å‹ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæ­è½½ PACO çš„ Llama-3.2-1B æ¨¡å‹åœ¨å¯æ§æ€§ä¸Šè¶³ä»¥åª²ç¾å‚æ•°é‡å¤§å¾—å¤šçš„ Llama-3.3-70B åŸºå‡†ï¼Œè¯æ˜äº†è¯¥æ–¹æ³•åœ¨æå‡æ¨¡å‹æ§åˆ¶èƒ½åŠ›æ–¹é¢çš„å“è¶Šæ•ˆç‡ä¸æ½œåŠ›ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.26435v1",
      "published_date": "2025-09-30 15:55:24 UTC",
      "updated_date": "2025-09-30 15:55:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:31:26.279254+00:00"
    },
    {
      "arxiv_id": "2509.26433v2",
      "title": "ACT: Agentic Classification Tree",
      "title_zh": "ACTï¼šæ™ºèƒ½ä½“åˆ†ç±»æ ‘",
      "authors": [
        "Vincent Grari",
        "Tim Arni",
        "Thibault Laugel",
        "Sylvain Lamprier",
        "James Zou",
        "Marcin Detyniecki"
      ],
      "abstract": "When used in high-stakes settings, AI systems are expected to produce decisions that are transparent, interpretable, and auditable, a requirement increasingly expected by regulations. Decision trees such as CART provide clear and verifiable rules, but they are restricted to structured tabular data and cannot operate directly on unstructured inputs such as text. In practice, large language models (LLMs) are widely used for such data, yet prompting strategies such as chain-of-thought or prompt optimization still rely on free-form reasoning, limiting their ability to ensure trustworthy behaviors. We present the Agentic Classification Tree (ACT), which extends decision-tree methodology to unstructured inputs by formulating each split as a natural-language question, refined through impurity-based evaluation and LLM feedback via TextGrad. Experiments on text benchmarks show that ACT matches or surpasses prompting-based baselines while producing transparent and interpretable decision paths.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†æ™ºèƒ½åˆ†ç±»æ ‘ï¼ˆAgentic Classification Tree, ACTï¼‰ï¼Œæ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤„ç†éç»“æ„åŒ–æ•°æ®æ—¶å› è‡ªç”±æ¨ç†å¯¼è‡´çš„å¯ä¿¡åº¦ä¸é€æ˜åº¦ä¸è¶³é—®é¢˜ã€‚ACT é€šè¿‡å°†å†³ç­–æ ‘çš„æ¯ä¸ªåˆ†è£‚èŠ‚ç‚¹å®šä¹‰ä¸ºè‡ªç„¶è¯­è¨€é—®é¢˜ï¼ŒæˆåŠŸå°†ä¼ ç»Ÿçš„å†³ç­–æ ‘ï¼ˆDecision Treeï¼‰æ–¹æ³•æ‰©å±•è‡³æ–‡æœ¬ç­‰éç»“æ„åŒ–è¾“å…¥é¢†åŸŸã€‚è¯¥æ¡†æ¶é‡‡ç”¨åŸºäºä¸çº¯åº¦ï¼ˆImpurity-basedï¼‰çš„è¯„ä¼°æœºåˆ¶ï¼Œå¹¶åˆ©ç”¨ TextGrad æŠ€æœ¯ç»“åˆ LLM åé¦ˆå¯¹å†³ç­–è§„åˆ™è¿›è¡Œè¿­ä»£ä¼˜åŒ–ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒACT åœ¨å¤šä¸ªæ–‡æœ¬åŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°æˆ–è¶…è¿‡äº†ä¸»æµæç¤ºç­–ç•¥çš„æ€§èƒ½è¡¨ç°ã€‚æœ€é‡è¦çš„æ˜¯ï¼Œè¯¥æ–¹æ³•åœ¨ä¿è¯åˆ†ç±»æ•ˆæœçš„åŒæ—¶ï¼Œèƒ½å¤Ÿæä¾›æ¸…æ™°ã€å¯éªŒè¯ä¸”å¯å®¡è®¡çš„å†³ç­–è·¯å¾„ï¼Œä¸ºé«˜é£é™©ç¯å¢ƒä¸‹çš„ AI åº”ç”¨æä¾›äº†é‡è¦çš„å¯è§£é‡Šæ€§ä¿éšœã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.26433v2",
      "published_date": "2025-09-30 15:54:08 UTC",
      "updated_date": "2025-10-22 09:12:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:31:23.986339+00:00"
    },
    {
      "arxiv_id": "2509.26432v2",
      "title": "AdaBlock-dLLM: Semantic-Aware Diffusion LLM Inference via Adaptive Block Size",
      "title_zh": "AdaBlock-dLLMï¼šåŸºäºè‡ªé€‚åº”å—å¤§å°çš„è¯­ä¹‰æ„ŸçŸ¥æ‰©æ•£å¤§è¯­è¨€æ¨¡å‹æ¨ç†",
      "authors": [
        "Guanxi Lu",
        "Hao Mark Chen",
        "Yuto Karashima",
        "Zhican Wang",
        "Daichi Fujiki",
        "Hongxiang Fan"
      ],
      "abstract": "Diffusion-based large language models (dLLMs) are gaining attention for their inherent capacity for parallel decoding, offering a compelling alternative to autoregressive LLMs. Among various decoding strategies, blockwise semi-autoregressive (semi-AR) approaches are widely adopted due to their natural support for KV caching and their favorable accuracy-speed trade-off. However, this paper identifies two fundamental limitations in the conventional semi-AR decoding approach that applies a fixed block size: i) late decoding overhead, where the unmasking of high-confidence tokens outside the current block is unnecessarily delayed, and ii) premature decoding error, where low-confidence tokens inside the current block are committed too early, leading to incorrect tokens. This paper presents the first systematic investigation challenging the fixed block size assumption in semi-AR decoding. Through a statistical analysis of confidence dynamics during the denoising process, we identify a volatility band (VB) region during dLLM decoding, which encodes local semantic structure and can be used to guide adaptive block sizing. Leveraging these insights, we introduce AdaBlock-dLLM, a training-free, plug-and-play scheduler that adaptively aligns block boundaries with semantic steps by adjusting block size during runtime. Extensive experiments across diverse benchmarks show that AdaBlock-dLLM achieves up to 5.3% accuracy improvement under the same throughput budget. Beyond inference-time optimization, we hope our semantics-aware adaptive scheduling approach and confidence-based analysis will inspire future training strategies for dLLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸºäºæ‰©æ•£çš„å¤§è¯­è¨€æ¨¡å‹ (dLLMs) åœ¨æ¨ç†æ•ˆç‡ä¸å‡†ç¡®æ€§ä¹‹é—´çš„æƒè¡¡é—®é¢˜ï¼Œæå‡ºäº† AdaBlock-dLLM æ¡†æ¶ã€‚é’ˆå¯¹ä¼ ç»ŸåŠè‡ªå›å½’ (semi-AR) è§£ç ä¸­å›ºå®šå—å¤§å°å¯¼è‡´çš„å»¶è¿Ÿè§£ç å¼€é”€ (late decoding overhead) å’Œè¿‡æ—©è§£ç é”™è¯¯ (premature decoding error) é™åˆ¶ï¼Œä½œè€…é€šè¿‡å¯¹å»å™ªè¿‡ç¨‹ä¸­ç½®ä¿¡åº¦åŠ¨æ€çš„ç»Ÿè®¡åˆ†æï¼Œè¯†åˆ«å‡ºäº†èƒ½å¼•å¯¼è‡ªé€‚åº”åˆ†å—çš„æ³¢åŠ¨å¸¦ (volatility band, VB) åŒºåŸŸã€‚AdaBlock-dLLM ä½œä¸ºä¸€ç§æ— éœ€è®­ç»ƒã€å³æ’å³ç”¨çš„è°ƒåº¦å™¨ï¼Œèƒ½å¤Ÿæ ¹æ®è¯­ä¹‰ç»“æ„åœ¨è¿è¡Œæ—¶åŠ¨æ€è°ƒæ•´å—å¤§å°ï¼Œä½¿å—è¾¹ç•Œä¸è¯­ä¹‰æ­¥é•¿ç›¸å¥‘åˆã€‚å®éªŒè¡¨æ˜ï¼Œåœ¨ç›¸åŒçš„ååé‡é¢„ç®—ä¸‹ï¼ŒAdaBlock-dLLM åœ¨å¤šç§åŸºå‡†æµ‹è¯•ä¸­å®ç°äº†æœ€é«˜ 5.3% çš„å‡†ç¡®ç‡æå‡ã€‚è¯¥ç ”ç©¶æå‡ºçš„è¯­ä¹‰æ„ŸçŸ¥è‡ªé€‚åº”è°ƒåº¦æ–¹æ³•å’ŒåŸºäºç½®ä¿¡åº¦çš„åˆ†æï¼Œä¸ºæ‰©æ•£ LLM çš„æœªæ¥æ¨ç†ä¼˜åŒ–å’Œè®­ç»ƒç­–ç•¥æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint. Under review",
      "pdf_url": "https://arxiv.org/pdf/2509.26432v2",
      "published_date": "2025-09-30 15:53:56 UTC",
      "updated_date": "2025-10-01 11:26:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:31:51.591481+00:00"
    },
    {
      "arxiv_id": "2509.26427v2",
      "title": "Ascent Fails to Forget",
      "title_zh": "æ¢¯åº¦ä¸Šå‡æ³•åœ¨æœºå™¨é—å¿˜ä¸­çš„å¤±æ•ˆ",
      "authors": [
        "Ioannis Mavrothalassitis",
        "Pol Puigdemont",
        "Noam Itzhak Levi",
        "Volkan Cevher"
      ],
      "abstract": "Contrary to common belief, we show that gradient ascent-based unconstrained optimization methods frequently fail to perform machine unlearning, a phenomenon we attribute to the inherent statistical dependence between the forget and retain data sets. This dependence, which can manifest itself even as simple correlations, undermines the misconception that these sets can be independently manipulated during unlearning. We provide empirical and theoretical evidence showing these methods often fail precisely due to this overlooked relationship. For random forget sets, this dependence means that degrading forget set metrics (which, for a retrained model, should mirror test set metrics) inevitably harms overall test performance. Going beyond random sets, we consider logistic regression as an instructive example where a critical failure mode emerges: inter-set dependence causes gradient descent-ascent iterations to progressively diverge from the ideal retrained model. Strikingly, these methods can converge to solutions that are not only far from the retrained ideal but are potentially even further from it than the original model itself, rendering the unlearning process actively detrimental. A toy example further illustrates how this dependence can trap models in inferior local minima, inescapable via finetuning. Our findings highlight that the presence of such statistical dependencies, even when manifest only as correlations, can be sufficient for ascent-based unlearning to fail. Our theoretical insights are corroborated by experiments on complex neural networks, demonstrating that these methods do not perform as expected in practice due to this unaddressed statistical interplay.",
      "tldr_zh": "è¯¥ç ”ç©¶æŒ‘æˆ˜äº†ä¼ ç»Ÿè§‚å¿µï¼ŒæŒ‡å‡ºåŸºäºæ¢¯åº¦ä¸Šå‡(gradient ascent)çš„æ— çº¦æŸä¼˜åŒ–æ–¹æ³•åœ¨æœºå™¨é—å¿˜(machine unlearning)ä¸­å¾€å¾€æ— æ³•å–å¾—ç†æƒ³æ•ˆæœã€‚ä½œè€…å°†è¿™ä¸€ç°è±¡å½’å› äºé—å¿˜æ•°æ®é›†(forget set)ä¸ä¿ç•™æ•°æ®é›†(retain set)ä¹‹é—´å›ºæœ‰çš„ç»Ÿè®¡ä¾èµ–æ€§(statistical dependence)ï¼ŒæŒ‡å‡ºå³ä½¿æ˜¯ç®€å•çš„ç›¸å…³æ€§ä¹Ÿä¼šå¯¼è‡´è¿™ä¸¤ä¸ªé›†åˆæ— æ³•åœ¨é—å¿˜è¿‡ç¨‹ä¸­è¢«ç‹¬ç«‹æ“çºµã€‚ç ”ç©¶é€šè¿‡ç†è®ºåˆ†æå’Œå®è¯è¯æ®è¡¨æ˜ï¼Œå•çº¯é™ä½é—å¿˜é›†çš„æŒ‡æ ‡ä¼šä¸å¯é¿å…åœ°æŸå®³æ•´ä½“æµ‹è¯•æ€§èƒ½ï¼Œç”šè‡³åœ¨é€»è¾‘å›å½’(logistic regression)ç­‰æ¨¡å‹ä¸­å¯¼è‡´è¿­ä»£ç»“æœä¸¥é‡åç¦»ç†æƒ³çš„é‡è®­ç»ƒæ¨¡å‹ã€‚å®éªŒè¿›ä¸€æ­¥è¯å®ï¼Œåœ¨å¤æ‚çš„ç¥ç»ç½‘ç»œä¸­ï¼Œè¿™ç§æœªè¢«é‡è§†çš„ç»Ÿè®¡ç›¸äº’ä½œç”¨ä¼šä½¿æ¨¡å‹é™·å…¥åŠ£è´¨å±€éƒ¨æœ€ä¼˜ï¼Œå¯¼è‡´é—å¿˜åçš„æ¨¡å‹æ•ˆæœç”šè‡³å·®äºåŸå§‹æ¨¡å‹ã€‚è¿™äº›å‘ç°å¼ºè°ƒäº†åœ¨è®¾è®¡é—å¿˜ç®—æ³•æ—¶å¿…é¡»è€ƒè™‘æ•°æ®é›†é—´ç»Ÿè®¡ä¾èµ–æ€§çš„é‡è¦æ€§ï¼Œä¸ºç†è§£æœºå™¨é—å¿˜çš„å¤±è´¥æœºåˆ¶æä¾›äº†é‡è¦çš„ç†è®ºæ”¯æ’‘ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.26427v2",
      "published_date": "2025-09-30 15:48:49 UTC",
      "updated_date": "2025-10-17 10:22:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:31:57.291189+00:00"
    },
    {
      "arxiv_id": "2509.26417v1",
      "title": "OntoAligner Meets Knowledge Graph Embedding Aligners",
      "title_zh": "OntoAligner ä¸çŸ¥è¯†å›¾è°±åµŒå…¥å¯¹é½å™¨çš„èåˆ",
      "authors": [
        "Hamed Babaei Giglou",
        "Jennifer D'Souza",
        "SÃ¶ren Auer",
        "Mahsa Sanaei"
      ],
      "abstract": "Ontology Alignment (OA) is essential for enabling semantic interoperability across heterogeneous knowledge systems. While recent advances have focused on large language models (LLMs) for capturing contextual semantics, this work revisits the underexplored potential of Knowledge Graph Embedding (KGE) models, which offer scalable, structure-aware representations well-suited to ontology-based tasks. Despite their effectiveness in link prediction, KGE methods remain underutilized in OA, with most prior work focusing narrowly on a few models. To address this gap, we reformulate OA as a link prediction problem over merged ontologies represented as RDF-style triples and develop a modular framework, integrated into the OntoAligner library, that supports 17 diverse KGE models. The system learns embeddings from a combined ontology and aligns entities by computing cosine similarity between their representations. We evaluate our approach using standard metrics across seven benchmark datasets spanning five domains: Anatomy, Biodiversity, Circular Economy, Material Science and Engineering, and Biomedical Machine Learning. Two key findings emerge: first, KGE models like ConvE and TransF consistently produce high-precision alignments, outperforming traditional systems in structure-rich and multi-relational domains; second, while their recall is moderate, this conservatism makes KGEs well-suited for scenarios demanding high-confidence mappings. Unlike LLM-based methods that excel at contextual reasoning, KGEs directly preserve and exploit ontology structure, offering a complementary and computationally efficient strategy. These results highlight the promise of embedding-based OA and open pathways for further work on hybrid models and adaptive strategies.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†çŸ¥è¯†å›¾è°±åµŒå…¥(Knowledge Graph Embedding)åœ¨æœ¬ä½“å¯¹é½(Ontology Alignment)ä»»åŠ¡ä¸­å°šæœªè¢«å……åˆ†æŒ–æ˜çš„æ½œåŠ›ï¼Œæ—¨åœ¨æå‡å¼‚æ„çŸ¥è¯†ç³»ç»Ÿé—´çš„è¯­ä¹‰äº’æ“ä½œæ€§ã€‚ç ”ç©¶è€…å°†æœ¬ä½“å¯¹é½é‡æ–°è¡¨è¿°ä¸ºåˆå¹¶æœ¬ä½“ä¸Šçš„é“¾è·¯é¢„æµ‹(Link Prediction)é—®é¢˜ï¼Œå¹¶åœ¨ OntoAligner åº“ä¸­æ„å»ºäº†ä¸€ä¸ªæ”¯æŒ 17 ç§ä¸åŒ KGE æ¨¡å‹çš„æ¨¡å—åŒ–æ¡†æ¶ã€‚è¯¥ç³»ç»Ÿé€šè¿‡å­¦ä¹ åˆå¹¶æœ¬ä½“çš„è¡¨ç¤ºï¼Œå¹¶åˆ©ç”¨ä½™å¼¦ç›¸ä¼¼åº¦(Cosine Similarity)è®¡ç®—å®ä½“é—´çš„å…³è”ã€‚å®éªŒåœ¨è§£å‰–å­¦ã€ç”Ÿç‰©å¤šæ ·æ€§ã€ææ–™ç§‘å­¦ç­‰ 5 ä¸ªé¢†åŸŸçš„ 7 ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æœæ˜¾ç¤º ConvE å’Œ TransF ç­‰æ¨¡å‹åœ¨ç»“æ„ä¸°å¯Œå’Œå¤šå…³ç³»é¢†åŸŸä¸­èƒ½äº§ç”Ÿé«˜ç²¾åº¦çš„å¯¹é½ç»“æœã€‚å°½ç®¡å¬å›ç‡(Recall)è¡¨ç°ä¸­ç­‰ï¼Œä½†å…¶é«˜ç²¾åº¦çš„ç‰¹æ€§ä½¿å…¶éå¸¸é€‚åˆéœ€è¦é«˜ç½®ä¿¡åº¦æ˜ å°„çš„åº”ç”¨åœºæ™¯ã€‚ä¸æ“…é•¿ä¸Šä¸‹æ–‡æ¨ç†çš„å¤§è¯­è¨€æ¨¡å‹(LLMs)ç›¸æ¯”ï¼ŒKGE æ¨¡å‹èƒ½ç›´æ¥ä¿ç•™å¹¶åˆ©ç”¨æœ¬ä½“ç»“æ„ï¼Œä¸ºæœ¬ä½“å¯¹é½æä¾›äº†ä¸€ç§è®¡ç®—é«˜æ•ˆä¸”å…·æœ‰äº’è¡¥æ€§çš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages of main content, 3 page references, 3 figures. Accepted to Ontology Matching Workshop at ISWC",
      "pdf_url": "https://arxiv.org/pdf/2509.26417v1",
      "published_date": "2025-09-30 15:41:23 UTC",
      "updated_date": "2025-09-30 15:41:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:31:53.977361+00:00"
    },
    {
      "arxiv_id": "2509.26404v1",
      "title": "SeedPrints: Fingerprints Can Even Tell Which Seed Your Large Language Model Was Trained From",
      "title_zh": "SeedPrintsï¼šæŒ‡çº¹ç”šè‡³èƒ½è¯†åˆ«å¤§è¯­è¨€æ¨¡å‹çš„è®­ç»ƒç§å­",
      "authors": [
        "Yao Tong",
        "Haonan Wang",
        "Siquan Li",
        "Kenji Kawaguchi",
        "Tianyang Hu"
      ],
      "abstract": "Fingerprinting Large Language Models (LLMs) is essential for provenance verification and model attribution. Existing methods typically extract post-hoc signatures based on training dynamics, data exposure, or hyperparameters -- properties that only emerge after training begins. In contrast, we propose a stronger and more intrinsic notion of LLM fingerprinting: SeedPrints, a method that leverages random initialization biases as persistent, seed-dependent identifiers present even before training. We show that untrained models exhibit reproducible token selection biases conditioned solely on their parameters at initialization. These biases are stable and measurable throughout training, enabling our statistical detection method to recover a model's lineage with high confidence. Unlike prior techniques, unreliable before convergence and vulnerable to distribution shifts, SeedPrints remains effective across all training stages and robust under domain shifts or parameter modifications. Experiments on LLaMA-style and Qwen-style models show that SeedPrints achieves seed-level distinguishability and can provide birth-to-lifecycle identity verification akin to a biometric fingerprint. Evaluations on large-scale pretrained models and fingerprinting benchmarks further confirm its effectiveness under practical deployment scenarios. These results suggest that initialization itself imprints a unique and persistent identity on neural language models, forming a true ''Galtonian'' fingerprint.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†SeedPrintsï¼Œä¸€ç§åˆ©ç”¨Large Language Models (LLMs) éšæœºåˆå§‹åŒ–åå·®ä½œä¸ºæŒä¹…æ€§ã€ä¾èµ–ç§å­(seed-dependent)æ ‡è¯†ç¬¦çš„æ–°å‹æŒ‡çº¹è¯†åˆ«æ–¹æ³•ã€‚ä¸ä»¥å¾€ä»…åœ¨è®­ç»ƒåæå–ç‰¹å¾çš„post-hocæ–¹æ³•ä¸åŒï¼ŒSeedPrintså‘ç°æœªè®­ç»ƒæ¨¡å‹åœ¨åˆå§‹åŒ–é˜¶æ®µä¾¿å…·æœ‰ç”±å‚æ•°å†³å®šçš„ã€å¯é‡å¤çš„tokené€‰æ‹©åå·®ã€‚è¿™ç§åå·®åœ¨æ•´ä¸ªè®­ç»ƒç”Ÿå‘½å‘¨æœŸä¸­ä¿æŒç¨³å®šï¼Œä½¿å¾—ç»Ÿè®¡æ£€æµ‹æ–¹æ³•èƒ½å¤Ÿä»¥é«˜ç½®ä¿¡åº¦è¿½æº¯æ¨¡å‹è¡€ç»Ÿã€‚å®éªŒè¯æ˜SeedPrintsåœ¨æ¨¡å‹è®­ç»ƒçš„å„ä¸ªé˜¶æ®µå‡è¡¨ç°æœ‰æ•ˆï¼Œä¸”å¯¹é¢†åŸŸåç§»(domain shifts)å’Œå‚æ•°ä¿®æ”¹å…·æœ‰æå¼ºçš„é²æ£’æ€§ã€‚é€šè¿‡åœ¨LLaMAå’ŒQwenç­‰æ¨¡å‹ä¸Šçš„è¯„ä¼°ï¼Œè¯¥æ–¹æ³•å®ç°äº†ç§å­çº§åˆ«çš„å¯åŒºåˆ†æ€§ï¼Œä¸ºå¤§è¯­è¨€æ¨¡å‹æä¾›äº†ç±»ä¼¼äºç”Ÿç‰©ç‰¹å¾æŒ‡çº¹çš„èº«ä»½éªŒè¯ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œéšæœºåˆå§‹åŒ–è¿‡ç¨‹æœ¬èº«å°±åœ¨æ¨¡å‹ä¸­çƒ™å°äº†å”¯ä¸€ä¸”æŒä¹…çš„èº«ä»½ï¼Œå½¢æˆäº†çœŸæ­£çš„â€œé«˜å°”é¡¿å¼â€æŒ‡çº¹ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.26404v1",
      "published_date": "2025-09-30 15:34:08 UTC",
      "updated_date": "2025-09-30 15:34:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:31:59.188067+00:00"
    },
    {
      "arxiv_id": "2509.26399v3",
      "title": "Communication-Efficient and Accurate Approach for Aggregation in Federated Low-Rank Adaptation",
      "title_zh": "è”é‚¦ä½ç§©è‡ªé€‚åº”ä¸­é€šä¿¡é«˜æ•ˆä¸”å‡†ç¡®çš„èšåˆæ–¹æ³•",
      "authors": [
        "Le-Tuan Nguyen",
        "Minh-Duong Nguyen",
        "Seon-Geun Jeong",
        "Dung D. Le",
        "Quoc-Viet Pham"
      ],
      "abstract": "With the rapid emergence of foundation models and the increasing need for fine-tuning across distributed environments, Federated Low-Rank Adaptation (FedLoRA) has recently gained significant attention. Despite enormous potential, current FedLoRA methods face notable challenges due to inexact updates. Existing approaches have attempted to mitigate this issue, but they often introduce a \\emph{local-global generalization gap} and incur \\emph{substantial communication overhead}, limiting their scalability and effectiveness. To address these limitations, we propose \\textbf{F}ederated \\textbf{Lo}w-\\textbf{R}ank \\textbf{A}ggregation with \\textbf{N}early \\textbf{A}ccurate Estimation (FLoRA-NA). FLoRA-NA leverages the local LoRA matrices on the server to estimate the aggregated matrices $\\hat{A}$ and $\\hat{B}$, which are then distributed to clients for local updates. This surrogated aggregated matrices minimizes the divergence between ideal $\\nabla \\Bar{W} = \\sum^{U}_{u=1}B_u A_u$ and practical updates $\\nabla \\hat{W} = \\hat{B}\\hat{A}$ without adding communication cost beyond vanilla FedLoRA. By doing so, FLoRA-NA achieves communication efficiency and bridges the gap between local personalization and global generalization, addressing a key limitation of prior personalized FedLoRA approaches. We conduct extensive evaluations across diverse tasks, including natural language understanding, mathematical reasoning, and code-solving ability using various foundation models. Experimental results consistently demonstrate that FLoRA-NA achieves state-of-the-art global performance while maintaining low communication overhead.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è”é‚¦ä½ç§©è‡ªé€‚åº” (Federated Low-Rank Adaptation, FedLoRA) åœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸­é¢ä¸´çš„ä¸ç²¾ç¡®æ›´æ–°ã€local-global generalization gap ä»¥åŠé«˜é€šä¿¡å¼€é”€ç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº†åä¸º FLoRA-NA çš„æ–°æ¡†æ¶ã€‚FLoRA-NA åœ¨æœåŠ¡å™¨ç«¯åˆ©ç”¨å„å®¢æˆ·ç«¯çš„æœ¬åœ° LoRA çŸ©é˜µæ¥å‡†ç¡®ä¼°è®¡èšåˆçŸ©é˜µ $\\hat{A}$ å’Œ $\\hat{B}$ï¼Œå¹¶å°†å…¶åˆ†å‘ç»™å®¢æˆ·ç«¯è¿›è¡Œæœ¬åœ°æ›´æ–°ï¼Œä»è€Œæœ€å°åŒ–ç†æƒ³æ›´æ–°ä¸å®é™…æ›´æ–°ä¹‹é—´çš„åå·®ã€‚è¯¥æ–¹æ³•åœ¨ä¸å¢åŠ é¢å¤– communication cost çš„å‰æä¸‹ï¼Œæœ‰æ•ˆå¼¥åˆäº† local personalization ä¸ global generalization ä¹‹é—´çš„å…³é”®é¸¿æ²Ÿã€‚é€šè¿‡åœ¨è‡ªç„¶è¯­è¨€ç†è§£ã€æ•°å­¦æ¨ç†å’Œä»£ç æ±‚è§£ç­‰å¤šé¡¹ä»»åŠ¡ä¸Šçš„å¹¿æ³›è¯„ä¼°ï¼Œå®éªŒç»“æœè¯æ˜ FLoRA-NA åœ¨å„ç§åŸºç¡€æ¨¡å‹ä¸Šå‡ä¿æŒäº†æä½çš„é€šä¿¡å¼€é”€ï¼Œå¹¶å®ç°äº† state-of-the-art çš„å…¨å±€æ€§èƒ½è¡¨ç°ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "34 pages, 4 figures, 11 tables",
      "pdf_url": "https://arxiv.org/pdf/2509.26399v3",
      "published_date": "2025-09-30 15:32:26 UTC",
      "updated_date": "2025-10-02 08:48:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:32:04.690956+00:00"
    },
    {
      "arxiv_id": "2509.26388v1",
      "title": "Game-Time: Evaluating Temporal Dynamics in Spoken Language Models",
      "title_zh": "Game-Timeï¼šå£è¯­è¯­è¨€æ¨¡å‹ä¸­çš„æ—¶åºåŠ¨æ€è¯„ä¼°",
      "authors": [
        "Kai-Wei Chang",
        "En-Pei Hu",
        "Chun-Yi Kuan",
        "Wenze Ren",
        "Wei-Chih Chen",
        "Guan-Ting Lin",
        "Yu Tsao",
        "Shao-Hua Sun",
        "Hung-yi Lee",
        "James Glass"
      ],
      "abstract": "Conversational Spoken Language Models (SLMs) are emerging as a promising paradigm for real-time speech interaction. However, their capacity of temporal dynamics, including the ability to manage timing, tempo and simultaneous speaking, remains a critical and unevaluated challenge for conversational fluency. To address this gap, we introduce the Game-Time Benchmark, a framework to systematically assess these temporal capabilities. Inspired by how humans learn a language through language activities, Game-Time consists of basic instruction-following tasks and advanced tasks with temporal constraints, such as tempo adherence and synchronized responses. Our evaluation of diverse SLM architectures reveals a clear performance disparity: while state-of-the-art models handle basic tasks well, many contemporary systems still struggle with fundamental instruction-following. More critically, nearly all models degrade substantially under temporal constraints, exposing persistent weaknesses in time awareness and full-duplex interaction. The Game-Time Benchmark provides a foundation for guiding future research toward more temporally-aware conversational AI. Demos and datasets are available on our project website https://ga642381.github.io/Game-Time.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Game-Time Benchmarkï¼Œæ—¨åœ¨ç³»ç»Ÿè¯„ä¼°å¯¹è¯å¼è¯­éŸ³è¯­è¨€æ¨¡å‹(SLMs)åœ¨ç®¡ç†æ—¶é—´ã€è¯­é€Ÿå’ŒåŒæ­¥è¯´è¯ç­‰æ—¶é—´åŠ¨åŠ›å­¦(Temporal Dynamics)æ–¹é¢çš„èƒ½åŠ›ã€‚è¯¥æ¡†æ¶å—äººç±»è¯­è¨€å­¦ä¹ è¿‡ç¨‹å¯å‘ï¼Œè®¾è®¡äº†ä»åŸºç¡€æŒ‡ä»¤éµå¾ªåˆ°åŒ…å«è¯­é€Ÿæ§åˆ¶å’ŒåŒæ­¥å“åº”ç­‰æ—¶é—´çº¦æŸçš„é«˜çº§ä»»åŠ¡ã€‚è¯„ä¼°ç»“æœæ­ç¤ºäº†æ˜æ˜¾çš„æ€§èƒ½å·®å¼‚ï¼Œè™½ç„¶å½“å‰å…ˆè¿›æ¨¡å‹èƒ½è¾ƒå¥½å¤„ç†åŸºç¡€ä»»åŠ¡ï¼Œä½†åœ¨æ—¶é—´çº¦æŸä¸‹è¡¨ç°å‡å¤§å¹…ä¸‹é™ï¼Œæš´éœ²å‡ºæ¨¡å‹åœ¨æ—¶é—´æ„è¯†å’Œå…¨åŒå·¥(Full-Duplex)äº¤äº’æ–¹é¢çš„æ˜¾è‘—ä¸è¶³ã€‚Game-Time ä¸ºæœªæ¥å¼€å‘å…·å¤‡æ›´é«˜æ—¶é—´æ„ŸçŸ¥èƒ½åŠ›çš„å¯¹è¯å¼äººå·¥æ™ºèƒ½æä¾›äº†è¯„ä¼°åŸºç¡€ä¸ç ”ç©¶æ–¹å‘ï¼Œç›¸å…³çš„é¡¹ç›®æ¼”ç¤ºå’Œæ•°æ®é›†ä¹Ÿå·²åŒæ­¥å…¬å¼€ã€‚",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "eess.AS",
      "comment": "submitted to ICASSP 2026",
      "pdf_url": "https://arxiv.org/pdf/2509.26388v1",
      "published_date": "2025-09-30 15:23:39 UTC",
      "updated_date": "2025-09-30 15:23:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:32:12.093319+00:00"
    },
    {
      "arxiv_id": "2509.26383v3",
      "title": "Efficient and Transferable Agentic Knowledge Graph RAG via Reinforcement Learning",
      "title_zh": "åŸºäºå¼ºåŒ–å­¦ä¹ çš„é«˜æ•ˆä¸”å¯è¿ç§»çš„æ™ºèƒ½ä½“åŒ–çŸ¥è¯†å›¾è°±æ£€ç´¢å¢å¼ºç”Ÿæˆ",
      "authors": [
        "Jinyeop Song",
        "Song Wang",
        "Julian Shun",
        "Yada Zhu"
      ],
      "abstract": "Knowledge-graph retrieval-augmented generation (KG-RAG) couples large language models (LLMs) with structured, verifiable knowledge graphs (KGs) to reduce hallucinations and expose reasoning traces. However, many KG-RAG systems compose multiple LLM modules (e.g planning, reasoning, and responding), inflating inference cost and binding behavior to a specific target KG. To address this, we introduce KG-R1, an agentic KG retrieval-augmented generation (KG-RAG) framework through reinforcement learning (RL). KG-R1 utilizes a single agent that interacts with KGs as its environment, learning to retrieve at each step and incorporating the retrieved information into its reasoning and generation. The process is optimized through end-to-end RL. In controlled experiments across Knowledge-Graph Question Answering (KGQA) benchmarks, our method demonstrates both efficiency and transferability: Using Qwen-2.5-3B, KG-R1 improves answer accuracy with fewer generation tokens than prior multi-module workflow methods that use larger foundation or fine-tuned models. Furthermore, KG-R1 enables plug and play: after training, it maintains strong accuracy on new KGs without modification. These properties make KG-R1 a promising KG-RAG framework for real-world deployment. Our code is publicly available at https://github.com/Jinyeop3110/KG-R1.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰çŸ¥è¯†å›¾è°±æ£€ç´¢å¢å¼ºç”Ÿæˆ(KG-RAG)ç³»ç»Ÿå› å¤šæ¨¡å—æ¶æ„å¯¼è‡´æ¨ç†æˆæœ¬é«˜ä¸”éš¾ä»¥é€‚é…æ–°å›¾è°±çš„é—®é¢˜ï¼Œæå‡ºäº†åŸºäºå¼ºåŒ–å­¦ä¹ (Reinforcement Learning)çš„æ™ºèƒ½ä½“åŒ–æ¡†æ¶KG-R1ã€‚è¯¥æ¡†æ¶é‡‡ç”¨å•ä¸€æ™ºèƒ½ä½“ä¸çŸ¥è¯†å›¾è°±ç¯å¢ƒäº¤äº’ï¼Œé€šè¿‡ç«¯åˆ°ç«¯çš„å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–ï¼Œä½¿æ™ºèƒ½ä½“å­¦ä¼šè‡ªä¸»æ£€ç´¢å¹¶åœ¨æ¯ä¸€æ­¥æ¨ç†ä¸­æ•´åˆçŸ¥è¯†ä¿¡æ¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨KGQAåŸºå‡†æµ‹è¯•ä¸­ï¼ŒåŸºäºQwen-2.5-3Bæ„å»ºçš„KG-R1åœ¨ç”Ÿæˆæ›´å°‘Tokençš„æƒ…å†µä¸‹ï¼Œå…¶å‡†ç¡®ç‡ä¼˜äºä½¿ç”¨æ›´å¤§è§„æ¨¡æˆ–ç»è¿‡å¾®è°ƒæ¨¡å‹çš„å¤šæ¨¡å—åŸºçº¿æ–¹æ³•ã€‚æ­¤å¤–ï¼ŒKG-R1å±•ç°å‡ºå“è¶Šçš„å¯è¿ç§»æ€§ï¼Œè®­ç»ƒåçš„æ¨¡å‹æ— éœ€ä¿®æ”¹å³å¯åœ¨å…¨æ–°çŸ¥è¯†å›¾è°±ä¸Šå®ç°å³æ’å³ç”¨çš„éƒ¨ç½²ã€‚è¿™ç§é«˜æ•ˆä¸”é€šç”¨çš„è®¾è®¡ä½¿KG-R1æˆä¸ºä¸€ç§æå…·å®é™…åº”ç”¨æ½œåŠ›çš„KG-RAGè§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 5 figures. Submitted to ICLR 2026",
      "pdf_url": "https://arxiv.org/pdf/2509.26383v3",
      "published_date": "2025-09-30 15:14:24 UTC",
      "updated_date": "2025-10-09 02:18:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:32:20.389034+00:00"
    },
    {
      "arxiv_id": "2509.26377v1",
      "title": "MC-GNNAS-Dock: Multi-criteria GNN-based Algorithm Selection for Molecular Docking",
      "title_zh": "MC-GNNAS-Dockï¼šåŸºäºå¤šå‡†åˆ™å›¾ç¥ç»ç½‘ç»œçš„åˆ†å­å¯¹æ¥ç®—æ³•é€‰æ‹©",
      "authors": [
        "Siyuan Cao",
        "Hongxuan Wu",
        "Jiabao Brad Wang",
        "Yiliang Yuan",
        "Mustafa Misir"
      ],
      "abstract": "Molecular docking is a core tool in drug discovery for predicting ligand-target interactions. Despite the availability of diverse search-based and machine learning approaches, no single docking algorithm consistently dominates, as performance varies by context. To overcome this challenge, algorithm selection frameworks such as GNNAS-Dock, built on graph neural networks, have been proposed. This study introduces an enhanced system, MC-GNNAS-Dock, with three key advances. First, a multi-criteria evaluation integrates binding-pose accuracy (RMSD) with validity checks from PoseBusters, offering a more rigorous assessment. Second, architectural refinements by inclusion of residual connections strengthen predictive robustness. Third, rank-aware loss functions are incorporated to sharpen rank learning. Extensive experiments are performed on a curated dataset containing approximately 3200 protein-ligand complexes from PDBBind. MC-GNNAS-Dock demonstrates consistently superior performance, achieving up to 5.4% (3.4%) gains under composite criteria of RMSD below 1Ã… (2Ã…) with PoseBuster-validity compared to the single best solver (SBS) Uni-Mol Docking V2.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†MC-GNNAS-Dockï¼Œè¿™æ˜¯ä¸€ç§æ”¹è¿›çš„åŸºäºå›¾ç¥ç»ç½‘ç»œ(GNN)çš„å¤šæ ‡å‡†ç®—æ³•é€‰æ‹©æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³åˆ†å­å¯¹æ¥(Molecular docking)ä¸­å•ä¸€ç®—æ³•éš¾ä»¥åœ¨å„ç§åœºæ™¯ä¸‹ä¿æŒæœ€ä¼˜çš„é—®é¢˜ã€‚MC-GNNAS-Dockå¼•å…¥äº†ä¸‰é¡¹å…³é”®æ”¹è¿›ï¼šä¸€æ˜¯ç»“åˆç»“åˆä½å§¿ç²¾åº¦(RMSD)ä¸PoseBustersåˆæ³•æ€§æ£€æŸ¥çš„å¤šæ ‡å‡†è¯„ä¼°ä½“ç³»ï¼ŒäºŒæ˜¯åˆ©ç”¨æ®‹å·®è¿æ¥(residual connections)å¢å¼ºæ¶æ„çš„ç¨³å¥æ€§ï¼Œä¸‰æ˜¯é‡‡ç”¨æ’åºæ„ŸçŸ¥æŸå¤±å‡½æ•°(rank-aware loss functions)æå‡æ’åºå­¦ä¹ æ•ˆæœã€‚åœ¨PDBBindæ•°æ®é›†ä¸Šçº¦3200ä¸ªè›‹ç™½è´¨-é…ä½“å¤åˆç‰©çš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMC-GNNAS-Dockè¡¨ç°å‡ºæŒç»­ä¼˜è¶Šçš„æ€§èƒ½ã€‚åœ¨RMSDä½äº1Ã…ä¸”ç¬¦åˆPoseBustersåˆæ³•æ€§çš„ç»¼åˆæŒ‡æ ‡ä¸‹ï¼Œè¯¥æ¨¡å‹ç›¸æ¯”å•æœ€ä½³æ±‚è§£å™¨(SBS)Uni-Mol Docking V2å®ç°äº†é«˜è¾¾5.4%çš„æ€§èƒ½æå‡ï¼Œä¸ºè¯ç‰©å‘ç°ä¸­çš„é…ä½“-é¶æ ‡ç›¸äº’ä½œç”¨é¢„æµ‹æä¾›äº†æ›´ä¸¥è°¨çš„é€‰æ‹©æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Short paper. Preprint of a forthcoming conference contribution",
      "pdf_url": "https://arxiv.org/pdf/2509.26377v1",
      "published_date": "2025-09-30 15:08:41 UTC",
      "updated_date": "2025-09-30 15:08:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:32:28.786534+00:00"
    },
    {
      "arxiv_id": "2509.26375v1",
      "title": "SDA-PLANNER: State-Dependency Aware Adaptive Planner for Embodied Task Planning",
      "title_zh": "SDA-PLANNERï¼šé¢å‘å…·èº«ä»»åŠ¡è§„åˆ’çš„çŠ¶æ€ä¾èµ–æ„ŸçŸ¥è‡ªé€‚åº”è§„åˆ’å™¨",
      "authors": [
        "Zichao Shen",
        "Chen Gao",
        "Jiaqi Yuan",
        "Tianchen Zhu",
        "Xingcheng Fu",
        "Qingyun Sun"
      ],
      "abstract": "Embodied task planning requires agents to produce executable actions in a close-loop manner within the environment. With progressively improving capabilities of LLMs in task decomposition, planning, and generalization, current embodied task planning methods adopt LLM-based architecture.However, existing LLM-based planners remain limited in three aspects, i.e., fixed planning paradigms, lack of action sequence constraints, and error-agnostic. In this work, we propose SDA-PLANNER, enabling an adaptive planning paradigm, state-dependency aware and error-aware mechanisms for comprehensive embodied task planning. Specifically, SDA-PLANNER introduces a State-Dependency Graph to explicitly model action preconditions and effects, guiding the dynamic revision. To handle execution error, it employs an error-adaptive replanning strategy consisting of Error Backtrack and Diagnosis and Adaptive Action SubTree Generation, which locally reconstructs the affected portion of the plan based on the current environment state. Experiments demonstrate that SDA-PLANNER consistently outperforms baselines in success rate and goal completion, particularly under diverse error conditions.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†SDA-PLANNERï¼Œä¸€ç§é’ˆå¯¹å…·èº«ä»»åŠ¡è§„åˆ’(Embodied task planning)çš„çŠ¶æ€ä¾èµ–æ„ŸçŸ¥è‡ªé€‚åº”è§„åˆ’å™¨ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLMs)çš„è§„åˆ’å™¨åœ¨å›ºå®šè§„åˆ’èŒƒå¼ã€ç¼ºä¹åŠ¨ä½œåºåˆ—çº¦æŸä»¥åŠé”™è¯¯ä¸æ„ŸçŸ¥ç­‰æ–¹é¢çš„å±€é™æ€§ã€‚SDA-PLANNERå¼•å…¥äº†çŠ¶æ€ä¾èµ–å›¾(State-Dependency Graph)æ¥æ˜¾å¼å»ºæ¨¡åŠ¨ä½œçš„å‰ç½®æ¡ä»¶å’Œæ•ˆæœï¼Œä»è€Œå¼•å¯¼è§„åˆ’çš„åŠ¨æ€ä¿®æ­£ã€‚ä¸ºäº†æœ‰æ•ˆå¤„ç†æ‰§è¡Œé”™è¯¯ï¼Œè¯¥æ¡†æ¶é‡‡ç”¨äº†ç”±é”™è¯¯å›æº¯ä¸è¯Šæ–­(Error Backtrack and Diagnosis)ä»¥åŠè‡ªé€‚åº”åŠ¨ä½œå­æ ‘ç”Ÿæˆ(Adaptive Action SubTree Generation)ç»„æˆçš„é”™è¯¯è‡ªé€‚åº”é‡è§„åˆ’ç­–ç•¥ï¼Œèƒ½å¤Ÿæ ¹æ®å½“å‰ç¯å¢ƒçŠ¶æ€å±€éƒ¨é‡å»ºå—å½±å“çš„è§„åˆ’éƒ¨åˆ†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSDA-PLANNERåœ¨æˆåŠŸç‡å’Œç›®æ ‡å®Œæˆç‡ä¸Šä¸€è‡´ä¼˜äºåŸºçº¿æ¨¡å‹ï¼Œå°¤å…¶åœ¨é¢å¯¹å¤šç§å¤æ‚é”™è¯¯æ¡ä»¶æ—¶è¡¨ç°å‡ºæ˜¾è‘—çš„é²æ£’æ€§ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.26375v1",
      "published_date": "2025-09-30 15:07:59 UTC",
      "updated_date": "2025-09-30 15:07:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:32:24.601053+00:00"
    },
    {
      "arxiv_id": "2509.26371v2",
      "title": "Vector-Valued Reproducing Kernel Banach Spaces for Neural Networks and Operators",
      "title_zh": "é¢å‘ç¥ç»ç½‘ç»œä¸ç®—å­çš„å‘é‡å€¼å†ç”Ÿæ ¸å·´æ‹¿èµ«ç©ºé—´",
      "authors": [
        "Sven Dummer",
        "Tjeerd Jan Heeringa",
        "JosÃ© A. Iglesias"
      ],
      "abstract": "Recently, there has been growing interest in characterizing the function spaces underlying neural networks. While shallow and deep scalar-valued neural networks have been linked to scalar-valued reproducing kernel Banach spaces (RKBS), $\\mathbb{R}^d$-valued neural networks and neural operator models remain less understood in the RKBS setting. To address this gap, we develop a general definition of vector-valued RKBS (vv-RKBS), which inherently includes the associated reproducing kernel. Our construction extends existing definitions by avoiding restrictive assumptions such as symmetric kernel domains, finite-dimensional output spaces, reflexivity, or separability, while still recovering familiar properties of vector-valued reproducing kernel Hilbert spaces (vv-RKHS). We then show that shallow $\\mathbb{R}^d$-valued neural networks are elements of a specific vv-RKBS, namely an instance of the integral and neural vv-RKBS. To also explore the functional structure of neural operators, we analyze the DeepONet and Hypernetwork architectures and demonstrate that they too belong to an integral and neural vv-RKBS. In all cases, we establish a Representer Theorem, showing that optimization over these function spaces recovers the corresponding neural architectures.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ $\\mathbb{R}^d$ å€¼ç¥ç»ç½‘ç»œå’Œç¥ç»ç®—å­æ¨¡å‹åœ¨å†ç”Ÿæ ¸å·´æ‹¿èµ«ç©ºé—´ (RKBS) ç†è®ºä¸­ç†è§£ä¸è¶³çš„ç°çŠ¶ï¼Œå¼€å‘äº†ä¸€ç§é€šç”¨çš„å‘é‡å€¼å†ç”Ÿæ ¸å·´æ‹¿èµ«ç©ºé—´ (vv-RKBS) å®šä¹‰ã€‚è¯¥å®šä¹‰æˆåŠŸé¿å¼€äº†å¯¹ç§°æ ¸åŸŸã€æœ‰é™ç»´è¾“å‡ºç©ºé—´ã€åå°„æ€§æˆ–å¯åˆ†æ€§ç­‰ä¼ ç»Ÿé™åˆ¶æ€§å‡è®¾ï¼ŒåŒæ—¶ä¿ç•™äº†å‘é‡å€¼å†ç”Ÿæ ¸å¸Œå°”ä¼¯ç‰¹ç©ºé—´ (vv-RKHS) çš„æ ¸å¿ƒæ€§è´¨ã€‚ç ”ç©¶è¿›ä¸€æ­¥è¯æ˜ï¼Œæµ…å±‚ $\\mathbb{R}^d$ å€¼ç¥ç»ç½‘ç»œã€DeepONet ä»¥åŠ Hypernetwork æ¶æ„å‡å¯è¢«è§†ä¸ºç‰¹å®šç§¯åˆ†ç¥ç» vv-RKBS ä¸­çš„å…ƒç´ ã€‚æœ€åï¼Œä½œè€…ä¸ºä¸Šè¿°æ¶æ„å»ºç«‹äº†è¡¨ç¤ºå®šç† (Representer Theorem)ï¼Œè¡¨æ˜åœ¨è¿™äº›å‡½æ•°ç©ºé—´å†…çš„ä¼˜åŒ–èƒ½å¤Ÿç›´æ¥æ¨å¯¼å‡ºç›¸åº”çš„ç¥ç»ç½‘ç»œæ¶æ„ï¼Œä»è€Œåœ¨ vv-RKBS æ¡†æ¶ä¸‹ç»Ÿä¸€äº†ç¥ç»ç½‘ç»œä¸ç®—å­å­¦ä¹ çš„ç†è®ºåˆ†æã€‚",
      "categories": [
        "math.FA",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "math.FA",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.26371v2",
      "published_date": "2025-09-30 15:06:24 UTC",
      "updated_date": "2025-10-01 17:46:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:32:27.594397+00:00"
    },
    {
      "arxiv_id": "2509.26360v3",
      "title": "TimeScope: Towards Task-Oriented Temporal Grounding In Long Videos",
      "title_zh": "TimeScopeï¼šé•¿è§†é¢‘ä¸­é¢å‘ä»»åŠ¡çš„æ—¶åºå®šä½æ¢ç´¢",
      "authors": [
        "Xiangrui Liu",
        "Minghao Qin",
        "Yan Shu",
        "Zhengyang Liang",
        "Yang Tian",
        "Chen Jason Zhang",
        "Bo Zhao",
        "Zheng Liu"
      ],
      "abstract": "Identifying key temporal intervals within long videos, known as temporal grounding (TG), is important to video understanding and reasoning tasks. In this paper, we introduce a new form of the temporal grounding problem, \\textbf{Task-oriented Temporal Grounding} (\\textbf{ToTG}), which is driven by the requirements of downstream tasks rather than explicit time-interval descriptions. For example, a ToTG input may be \"explain why the man in the video is sent to the hospital,\" whereas traditional TG would take an explicit temporal description such as \"the moments when the man is tripped by a stone and falls to the ground.\" This new ToTG formulation presents significant challenges for existing TG methods, as it requires jointly performing deep task comprehension and fine-grained temporal localization within long videos. To address these challenges, we conduct a systematic set of studies. First, we construct \\textbf{a new benchmark ToTG-Bench}, which comprehensively evaluates ToTG performance across diverse settings. Second, we introduce \\textbf{a new temporal-ground method TimeScope}, which performs coarse-to-fine localization through a progressive reasoning process. Leveraging extensive supervised fine-tuning with carefully curated chain-of-thought (CoT) data from a variety of scenarios, TimeScope generalizes effectively across tasks and domains. Our evaluation demonstrates \\textbf{TimeScope's empirical advantages} over existing baselines from three perspectives: (1) substantial improvements in grounding precision, (2) significant benefits to downstream tasks, and (3) strong generalizability across different scenarios. All models, datasets, and source code will be fully open-sourced to support future research in this area.",
      "tldr_zh": "æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°çš„æ—¶é—´å®šä½é—®é¢˜å½¢å¼ï¼Œå³ä»»åŠ¡å¯¼å‘çš„æ—¶é—´å®šä½ (Task-oriented Temporal Grounding, ToTG)ï¼Œæ—¨åœ¨é€šè¿‡ä¸‹æ¸¸ä»»åŠ¡éœ€æ±‚è€Œéæ˜¾å¼æ—¶é—´æè¿°æ¥è¯†åˆ«é•¿è§†é¢‘ä¸­çš„å…³é”®æ—¶é—´é—´éš”ã€‚ä¸ä¼ ç»Ÿçš„æ—¶é—´å®šä½ (Temporal Grounding, TG) ä¸åŒï¼ŒToTG è¦æ±‚æ¨¡å‹èƒ½å¤ŸåŒæ—¶è¿›è¡Œæ·±åº¦çš„ä»»åŠ¡ç†è§£å’Œé•¿è§†é¢‘å†…çš„ç»†ç²’åº¦æ—¶é—´å®šä½ï¼Œè¿™å¯¹ç°æœ‰æ–¹æ³•æå‡ºäº†å·¨å¤§æŒ‘æˆ˜ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶å›¢é˜Ÿæ„å»ºäº†æ–°çš„åŸºå‡†æµ‹è¯•é›† ToTG-Bench ä»¥å…¨é¢è¯„ä¼° ToTG æ€§èƒ½ï¼Œå¹¶å¼•å…¥äº†åä¸º TimeScope çš„æ–°æ–¹æ³•ã€‚TimeScope é€šè¿‡æ¸è¿›å¼æ¨ç†è¿‡ç¨‹å®ç°ä»ç²—åˆ°ç²¾çš„å®šä½ï¼Œå¹¶åˆ©ç”¨ç²¾å¿ƒç­–åˆ’çš„é“¾å¼æ€ç»´ (Chain-of-Thought, CoT) æ•°æ®è¿›è¡Œæœ‰ç›‘ç£å¾®è°ƒï¼Œæ˜¾è‘—å¢å¼ºäº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒTimeScope åœ¨å®šä½ç²¾åº¦ã€ä¸‹æ¸¸ä»»åŠ¡è¾…åŠ©åŠè·¨åœºæ™¯åº”ç”¨æ–¹é¢å‡å±•ç°å‡ºè¶…è¶Šç°æœ‰åŸºå‡†æ¨¡å‹çš„æ˜¾è‘—ä¼˜åŠ¿ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.26360v3",
      "published_date": "2025-09-30 15:00:43 UTC",
      "updated_date": "2025-12-08 03:35:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:33:02.500183+00:00"
    },
    {
      "arxiv_id": "2509.26354v1",
      "title": "Your Agent May Misevolve: Emergent Risks in Self-evolving LLM Agents",
      "title_zh": "æ™ºèƒ½ä½“å¯èƒ½ä¼šâ€œè¯¯æ¼”åŒ–â€ï¼šè‡ªè¿›åŒ– LLM æ™ºèƒ½ä½“ä¸­çš„æ¶Œç°é£é™©",
      "authors": [
        "Shuai Shao",
        "Qihan Ren",
        "Chen Qian",
        "Boyi Wei",
        "Dadi Guo",
        "Jingyi Yang",
        "Xinhao Song",
        "Linfeng Zhang",
        "Weinan Zhang",
        "Dongrui Liu",
        "Jing Shao"
      ],
      "abstract": "Advances in Large Language Models (LLMs) have enabled a new class of self-evolving agents that autonomously improve through interaction with the environment, demonstrating strong capabilities. However, self-evolution also introduces novel risks overlooked by current safety research. In this work, we study the case where an agent's self-evolution deviates in unintended ways, leading to undesirable or even harmful outcomes. We refer to this as Misevolution. To provide a systematic investigation, we evaluate misevolution along four key evolutionary pathways: model, memory, tool, and workflow. Our empirical findings reveal that misevolution is a widespread risk, affecting agents built even on top-tier LLMs (e.g., Gemini-2.5-Pro). Different emergent risks are observed in the self-evolutionary process, such as the degradation of safety alignment after memory accumulation, or the unintended introduction of vulnerabilities in tool creation and reuse. To our knowledge, this is the first study to systematically conceptualize misevolution and provide empirical evidence of its occurrence, highlighting an urgent need for new safety paradigms for self-evolving agents. Finally, we discuss potential mitigation strategies to inspire further research on building safer and more trustworthy self-evolving agents. Our code and data are available at https://github.com/ShaoShuai0605/Misevolution . Warning: this paper includes examples that may be offensive or harmful in nature.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)æ™ºèƒ½ä½“åœ¨é€šè¿‡ç¯å¢ƒäº¤äº’å®ç°è‡ªæˆ‘è¿›åŒ–(Self-evolution)è¿‡ç¨‹ä¸­äº§ç”Ÿçš„æ–°å…´é£é™©ï¼Œå¹¶å°†å…¶å®šä¹‰ä¸ºâ€œæ¼”åŒ–åå·®â€(Misevolution)ï¼Œå³æ™ºèƒ½ä½“çš„è‡ªæˆ‘è¿›åŒ–åç¦»é¢„æœŸç›®æ ‡å¹¶å¯¼è‡´æœ‰å®³ç»“æœã€‚ä¸ºäº†è¿›è¡Œç³»ç»Ÿæ€§è°ƒæŸ¥ï¼Œä½œè€…ä»æ¨¡å‹(Model)ã€è®°å¿†(Memory)ã€å·¥å…·(Tool)å’Œå·¥ä½œæµ(Workflow)å››ä¸ªå…³é”®æ¼”åŒ–è·¯å¾„å¯¹ Misevolution è¿›è¡Œäº†æ·±å…¥è¯„ä¼°ã€‚å®è¯ç ”ç©¶ç»“æœè¡¨æ˜ï¼ŒMisevolution æ˜¯ä¸€ç§æ™®éå­˜åœ¨çš„é£é™©ï¼Œå³ä½¿æ˜¯åŸºäº Gemini-2.5-Pro ç­‰é¡¶çº§æ¨¡å‹æ„å»ºçš„æ™ºèƒ½ä½“ä¹Ÿä¼šå—åˆ°å½±å“ã€‚åœ¨è‡ªæˆ‘è¿›åŒ–è¿‡ç¨‹ä¸­è§‚å¯Ÿåˆ°äº†å¤šç§çªå‘æ€§é£é™©ï¼Œä¾‹å¦‚è®°å¿†ç´¯ç§¯å¯¼è‡´çš„å®‰å…¨æ€§å¯¹é½(Safety Alignment)é€€åŒ–ï¼Œä»¥åŠåœ¨å·¥å…·åˆ›å»ºå’Œé‡ç”¨è¿‡ç¨‹ä¸­æ„å¤–å¼•å…¥çš„æ¼æ´ã€‚ä½œä¸ºé¦–ä¸ªç³»ç»ŸåŒ–ç•Œå®šå¹¶æä¾›å®è¯è¯æ®çš„ç ”ç©¶ï¼Œè¯¥è®ºæ–‡æ­ç¤ºäº†ä¸ºè‡ªæˆ‘è¿›åŒ–æ™ºèƒ½ä½“å»ºç«‹æ–°å‹å®‰å…¨èŒƒå¼çš„ç´§è¿«æ€§ã€‚æœ€åï¼Œç ”ç©¶è¿˜è®¨è®ºäº†æ½œåœ¨çš„ç¼“è§£ç­–ç•¥ï¼Œæ—¨åœ¨ä¸ºæ„å»ºæ›´å®‰å…¨ã€æ›´å¯é çš„è‡ªæˆ‘è¿›åŒ–æ™ºèƒ½ä½“æä¾›ç ”ç©¶å¯å‘ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Preprint. Under Review",
      "pdf_url": "https://arxiv.org/pdf/2509.26354v1",
      "published_date": "2025-09-30 14:55:55 UTC",
      "updated_date": "2025-09-30 14:55:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:33:06.685541+00:00"
    },
    {
      "arxiv_id": "2509.26350v1",
      "title": "SoK: Systematic analysis of adversarial threats against deep learning approaches for autonomous anomaly detection systems in SDN-IoT networks",
      "title_zh": "SoKï¼šé¢å‘ SDN-IoT ç½‘ç»œè‡ªä¸»å¼‚å¸¸æ£€æµ‹æ·±åº¦å­¦ä¹ æ–¹æ³•çš„å¯¹æŠ—æ€§å¨èƒç³»ç»ŸåŒ–åˆ†æ",
      "authors": [
        "Tharindu Lakshan Yasarathna",
        "Nhien-An Le-Khac"
      ],
      "abstract": "Integrating SDN and the IoT enhances network control and flexibility. DL-based AAD systems improve security by enabling real-time threat detection in SDN-IoT networks. However, these systems remain vulnerable to adversarial attacks that manipulate input data or exploit model weaknesses, significantly degrading detection accuracy. Existing research lacks a systematic analysis of adversarial vulnerabilities specific to DL-based AAD systems in SDN-IoT environments. This SoK study introduces a structured adversarial threat model and a comprehensive taxonomy of attacks, categorising them into data, model, and hybrid-level threats. Unlike previous studies, we systematically evaluate white, black, and grey-box attack strategies across popular benchmark datasets. Our findings reveal that adversarial attacks can reduce detection accuracy by up to 48.4%, with Membership Inference causing the most significant drop. C&W and DeepFool achieve high evasion success rates. However, adversarial training enhances robustness, and its high computational overhead limits the real-time deployment of SDN-IoT applications. We propose adaptive countermeasures, including real-time adversarial mitigation, enhanced retraining mechanisms, and explainable AI-driven security frameworks. By integrating structured threat models, this study offers a more comprehensive approach to attack categorisation, impact assessment, and defence evaluation than previous research. Our work highlights critical vulnerabilities in existing DL-based AAD models and provides practical recommendations for improving resilience, interpretability, and computational efficiency. This study serves as a foundational reference for researchers and practitioners seeking to enhance DL-based AAD security in SDN-IoT networks, offering a systematic adversarial threat model and conceptual defence evaluation based on prior empirical studies.",
      "tldr_zh": "è¯¥é¡¹çŸ¥è¯†ç³»ç»ŸåŒ–(SoK)ç ”ç©¶é’ˆå¯¹SDN-IoTç½‘ç»œä¸­åŸºäºæ·±åº¦å­¦ä¹ (Deep Learning)çš„è‡ªä¸»å¼‚å¸¸æ£€æµ‹(AAD)ç³»ç»Ÿï¼Œç³»ç»Ÿåˆ†æäº†å…¶é¢ä¸´çš„å¯¹æŠ—æ€§æ”»å‡»(Adversarial Attacks)å¨èƒã€‚ç ”ç©¶æå‡ºäº†ç»“æ„åŒ–çš„å¯¹æŠ—æ€§å¨èƒæ¨¡å‹å’Œæ¶µç›–æ•°æ®ã€æ¨¡å‹åŠæ··åˆå±‚é¢çš„æ”»å‡»åˆ†ç±»æ³•ï¼Œå¹¶å…¨é¢è¯„ä¼°äº†ç™½ç›’ã€é»‘ç›’åŠç°ç›’æ”»å‡»ç­–ç•¥ã€‚ç ”ç©¶å‘ç°ï¼Œå¯¹æŠ—æ€§æ”»å‡»æœ€é«˜å¯ä½¿æ£€æµ‹å‡†ç¡®ç‡ä¸‹é™48.4%ï¼Œå…¶ä¸­æˆå‘˜æ¨ç†(Membership Inference)æ”»å‡»å½±å“æœ€æ˜¾è‘—ï¼ŒC&Wå’ŒDeepFoolåœ¨è§„é¿æ£€æµ‹æ–¹é¢è¡¨ç°çªå‡ºã€‚å®éªŒè¡¨æ˜å¯¹æŠ—æ€§è®­ç»ƒ(Adversarial Training)è™½èƒ½æå‡é²æ£’æ€§ï¼Œä½†å…¶é«˜æ˜‚çš„è®¡ç®—å¼€é”€é™åˆ¶äº†åœ¨SDN-IoTç¯å¢ƒä¸­çš„å®æ—¶éƒ¨ç½²ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶è€…æå‡ºäº†åŒ…æ‹¬å®æ—¶å¯¹æŠ—ç¼“è§£å’Œå¯è§£é‡Šäººå·¥æ™ºèƒ½(XAI)é©±åŠ¨åœ¨å†…çš„è‡ªé€‚åº”å®‰å…¨æ¡†æ¶ã€‚è¯¥å·¥ä½œæ­ç¤ºäº†ç°æœ‰æ¨¡å‹åœ¨å®‰å…¨æ€§ã€å¯è§£é‡Šæ€§å’Œè®¡ç®—æ•ˆç‡æ–¹é¢çš„å…³é”®æ¼æ´ï¼Œå¹¶ä¸ºæå‡SDN-IoTç³»ç»Ÿçš„å¼¹æ€§æä¾›äº†å®è·µæŒ‡å—ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.26350v1",
      "published_date": "2025-09-30 14:54:42 UTC",
      "updated_date": "2025-09-30 14:54:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:33:10.392282+00:00"
    },
    {
      "arxiv_id": "2509.26347v2",
      "title": "Uncovering Zero-Shot Generalization Gaps in Time-Series Foundation Models Using Real-World Videos",
      "title_zh": "åˆ©ç”¨çœŸå®ä¸–ç•Œè§†é¢‘æ­ç¤ºæ—¶é—´åºåˆ—åŸºç¡€æ¨¡å‹çš„é›¶æ ·æœ¬æ³›åŒ–å·®è·",
      "authors": [
        "Lujun Li",
        "Lama Sleem",
        "Yiqun Wang",
        "Yangjie Xu",
        "NiccolÃ² Gentile",
        "Radu State"
      ],
      "abstract": "Recent research on time-series foundation models (TSFMs) has underscored the scarcity of real-world data, often supplemented with synthetic sources in existing datasets, whose generalizability remains however debated. As such, in this work, we propose a novel benchmarking approach: in particular, we aim at building a curated dataset reflecting real world physical temporal dynamics, extracting temporal signals from real-world videos using optical flow. As such, we introduce REAL-V-TSFM, a novel dataset designed to capture rich and diverse time series derived from real-world videos. Experimental results on state-of-the-art TSFMs under zero-shot forecasting show that, despite strong performance on conventional benchmarks, these models exhibit performance degradation on the proposed dataset, suggesting limited generalizability to novel datasets. These findings underscore the need for novel approaches to acquiring time series data and highlight the lack of universality in recent TSFMs, while further validating the effectiveness of our video-based time series data extraction pipeline.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æ—¶é—´åºåˆ—åŸºç¡€æ¨¡å‹ (TSFMs) åœ¨çœŸå®ä¸–ç•Œæ•°æ®ç¨€ç¼ºèƒŒæ™¯ä¸‹çš„æ³›åŒ–å±€é™æ€§ã€‚ä½œè€…æå‡ºäº†ä¸€ç§åˆ›æ–°çš„åŸºå‡†æµ‹è¯•æ–¹æ³•ï¼Œé€šè¿‡å…‰æµæ³• (optical flow) ä»çœŸå®è§†é¢‘ä¸­æå–åæ˜ ç‰©ç†æ—¶é—´åŠ¨æ€çš„ä¿¡å·ï¼Œå¹¶ç”±æ­¤æ„å»ºäº† REAL-V-TSFM æ•°æ®é›†ã€‚åœ¨é›¶æ ·æœ¬é¢„æµ‹ (zero-shot forecasting) ä»»åŠ¡ä¸‹çš„å®éªŒè¡¨æ˜ï¼Œå°½ç®¡ç°æœ‰çš„ SOTA æ¨¡å‹åœ¨ä¼ ç»ŸåŸºå‡†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œä½†åœ¨ REAL-V-TSFM æ•°æ®é›†ä¸Šå‡ºç°äº†æ˜æ˜¾çš„æ€§èƒ½é€€åŒ–ã€‚è¿™ä¸€å‘ç°æ­ç¤ºäº†å½“å‰ TSFMs å­˜åœ¨çš„é›¶æ ·æœ¬æ³›åŒ–å·®è·ä»¥åŠæ¨¡å‹æ™®é€‚æ€§çš„ç¼ºå¤±ã€‚è¯¥ç ”ç©¶ä¸ä»…æŒ‡å‡ºäº†è·å–é«˜è´¨é‡çœŸå®ä¸–ç•Œæ•°æ®çš„å¿…è¦æ€§ï¼ŒåŒæ—¶ä¹ŸéªŒè¯äº†åŸºäºè§†é¢‘æå–æ—¶é—´åºåˆ—æ•°æ®çš„æµç¨‹åœ¨è¯„ä¼°æ¨¡å‹é²æ£’æ€§æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "This paper has been accepted by Artificial Intelligence for Time Series Analysis (AI4TS) Workshop @ AAAI 2026: Theory, Algorithms, and Applications",
      "pdf_url": "https://arxiv.org/pdf/2509.26347v2",
      "published_date": "2025-09-30 14:53:05 UTC",
      "updated_date": "2025-11-28 18:31:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:33:14.688998+00:00"
    },
    {
      "arxiv_id": "2509.26346v1",
      "title": "EditReward: A Human-Aligned Reward Model for Instruction-Guided Image Editing",
      "title_zh": "EditRewardï¼šé¢å‘æŒ‡ä»¤å¼•å¯¼å›¾åƒç¼–è¾‘çš„äººç±»å¯¹é½å¥–åŠ±æ¨¡å‹",
      "authors": [
        "Keming Wu",
        "Sicong Jiang",
        "Max Ku",
        "Ping Nie",
        "Minghao Liu",
        "Wenhu Chen"
      ],
      "abstract": "Recently, we have witnessed great progress in image editing with natural language instructions. Several closed-source models like GPT-Image-1, Seedream, and Google-Nano-Banana have shown highly promising progress. However, the open-source models are still lagging. The main bottleneck is the lack of a reliable reward model to scale up high-quality synthetic training data. To address this critical bottleneck, we built \\mname, trained with our new large-scale human preference dataset, meticulously annotated by trained experts following a rigorous protocol containing over 200K preference pairs. \\mname demonstrates superior alignment with human preferences in instruction-guided image editing tasks. Experiments show that \\mname achieves state-of-the-art human correlation on established benchmarks such as GenAI-Bench, AURORA-Bench, ImagenHub, and our new \\benchname, outperforming a wide range of VLM-as-judge models. Furthermore, we use \\mname to select a high-quality subset from the existing noisy ShareGPT-4o-Image dataset. We train Step1X-Edit on the selected subset, which shows significant improvement over training on the full set. This demonstrates \\mname's ability to serve as a reward model to scale up high-quality training data for image editing. Furthermore, its strong alignment suggests potential for advanced applications like reinforcement learning-based post-training and test-time scaling of image editing models. \\mname with its training dataset will be released to help the community build more high-quality image editing training datasets.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æŒ‡ä»¤å¼•å¯¼å›¾åƒç¼–è¾‘é¢†åŸŸä¸­ç¼ºä¹å¯é å¥–åŠ±æ¨¡å‹æ¥æ‰©å±•é«˜è´¨é‡è®­ç»ƒæ•°æ®çš„ç“¶é¢ˆï¼Œæå‡ºäº†EditRewardï¼Œä¸€ä¸ªé€šè¿‡åŒ…å«è¶…è¿‡20ä¸‡å¯¹åå¥½å¯¹çš„å¤§è§„æ¨¡ä¸“å®¶æ ‡æ³¨æ•°æ®é›†è®­ç»ƒè€Œæˆçš„å¥–åŠ±æ¨¡å‹ã€‚EditRewardåœ¨GenAI-Benchã€AURORA-Benchå’ŒImagenHubç­‰å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å®ç°äº†æœ€å…ˆè¿›çš„äººç±»ç›¸å…³æ€§ï¼Œå…¶è¡¨ç°ä¼˜äºå¤šç§VLM-as-judgeæ¨¡å‹ã€‚é€šè¿‡åˆ©ç”¨è¯¥æ¨¡å‹ä»ç°æœ‰çš„å™ªå£°æ•°æ®é›†ä¸­ç­›é€‰é«˜è´¨é‡å­é›†ï¼Œç ”ç©¶å›¢é˜ŸæˆåŠŸæå‡äº†Step1X-Editæ¨¡å‹çš„æ€§èƒ½ï¼ŒéªŒè¯äº†å…¶åœ¨æ‰©å±•é«˜è´¨é‡åˆæˆè®­ç»ƒæ•°æ®æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼ŒEditRewardå±•ç°å‡ºä¸äººç±»åå¥½çš„é«˜åº¦ä¸€è‡´æ€§ï¼Œè¿™ä½¿å…¶åœ¨åŸºäºå¼ºåŒ–å­¦ä¹ (Reinforcement Learning)çš„åè®­ç»ƒå’Œæµ‹è¯•æ—¶ç¼©æ”¾(test-time scaling)ç­‰é«˜çº§åº”ç”¨ä¸­å…·æœ‰å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Work in progress. Project Page: https://tiger-ai-lab.github.io/EditReward",
      "pdf_url": "https://arxiv.org/pdf/2509.26346v1",
      "published_date": "2025-09-30 14:51:04 UTC",
      "updated_date": "2025-09-30 14:51:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:33:21.178509+00:00"
    },
    {
      "arxiv_id": "2509.26345v1",
      "title": "SafeBehavior: Simulating Human-Like Multistage Reasoning to Mitigate Jailbreak Attacks in Large Language Models",
      "title_zh": "SafeBehaviorï¼šæ¨¡æ‹Ÿç±»äººå¤šé˜¶æ®µæ¨ç†ä»¥é˜²å¾¡å¤§è¯­è¨€æ¨¡å‹è¶Šç‹±æ”»å‡»",
      "authors": [
        "Qinjian Zhao",
        "Jiaqi Wang",
        "Zhiqiang Gao",
        "Zhihao Dou",
        "Belal Abuhaija",
        "Kaizhu Huang"
      ],
      "abstract": "Large Language Models (LLMs) have achieved impressive performance across diverse natural language processing tasks, but their growing power also amplifies potential risks such as jailbreak attacks that circumvent built-in safety mechanisms. Existing defenses including input paraphrasing, multi step evaluation, and safety expert models often suffer from high computational costs, limited generalization, or rigid workflows that fail to detect subtle malicious intent embedded in complex contexts. Inspired by cognitive science findings on human decision making, we propose SafeBehavior, a novel hierarchical jailbreak defense mechanism that simulates the adaptive multistage reasoning process of humans. SafeBehavior decomposes safety evaluation into three stages: intention inference to detect obvious input risks, self introspection to assess generated responses and assign confidence based judgments, and self revision to adaptively rewrite uncertain outputs while preserving user intent and enforcing safety constraints. We extensively evaluate SafeBehavior against five representative jailbreak attack types including optimization based, contextual manipulation, and prompt based attacks and compare it with seven state of the art defense baselines. Experimental results show that SafeBehavior significantly improves robustness and adaptability across diverse threat scenarios, offering an efficient and human inspired approach to safeguarding LLMs against jailbreak attempts.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† SafeBehaviorï¼Œè¿™æ˜¯ä¸€ç§å—è®¤çŸ¥ç§‘å­¦å¯å‘çš„å±‚æ¬¡åŒ–è¶Šç‹± (jailbreak) é˜²å¾¡æœºåˆ¶ï¼Œæ—¨åœ¨ç¼“è§£å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) é¢ä¸´çš„æ¶æ„æ”»å‡»é£é™©ã€‚è¯¥æ¡†æ¶é€šè¿‡æ¨¡æ‹Ÿäººç±»çš„è‡ªé€‚åº”å¤šé˜¶æ®µæ¨ç†è¿‡ç¨‹ï¼Œå°†å®‰å…¨è¯„ä¼°åˆ†è§£ä¸ºæ„å›¾æ¨æ–­ (intention inference)ã€è‡ªæˆ‘åçœ (self-introspection) å’Œè‡ªæˆ‘ä¿®æ­£ (self-revision) ä¸‰ä¸ªé˜¶æ®µã€‚æ„å›¾æ¨æ–­ç”¨äºæ£€æµ‹æ˜æ˜¾çš„è¾“å…¥é£é™©ï¼Œè‡ªæˆ‘åçœè´Ÿè´£è¯„ä¼°ç”Ÿæˆçš„å“åº”å¹¶åŸºäºç½®ä¿¡åº¦è¿›è¡Œåˆ¤æ–­ï¼Œè€Œè‡ªæˆ‘ä¿®æ­£åˆ™åœ¨ä¿ç•™ç”¨æˆ·æ„å›¾çš„åŒæ—¶è‡ªé€‚åº”åœ°é‡å†™ä¸ç¡®å®šè¾“å‡ºä»¥æ»¡è¶³å®‰å…¨çº¦æŸã€‚å®éªŒé’ˆå¯¹åŒ…æ‹¬ä¼˜åŒ–æ”»å‡»å’Œä¸Šä¸‹æ–‡æ“çºµåœ¨å†…çš„äº”ç§ä»£è¡¨æ€§è¶Šç‹±ç±»å‹è¿›è¡Œäº†è¯„ä¼°ï¼Œå¹¶ä¸ä¸ƒç§å…ˆè¿›çš„é˜²å¾¡åŸºçº¿è¿›è¡Œäº†å¯¹æ¯”ã€‚ç»“æœè¡¨æ˜ï¼ŒSafeBehavior åœ¨å¤šæ ·åŒ–çš„å¨èƒåœºæ™¯ä¸­æ˜¾è‘—æå‡äº†æ¨¡å‹çš„é²æ£’æ€§ä¸è‡ªé€‚åº”èƒ½åŠ›ï¼Œä¸ºä¿éšœ LLMs å®‰å…¨æä¾›äº†ä¸€ç§é«˜æ•ˆä¸”å—äººç±»å¯å‘çš„æ–°å‹é˜²å¾¡æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "27 pages, 5 figure",
      "pdf_url": "https://arxiv.org/pdf/2509.26345v1",
      "published_date": "2025-09-30 14:50:59 UTC",
      "updated_date": "2025-09-30 14:50:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:33:23.576772+00:00"
    },
    {
      "arxiv_id": "2509.26331v1",
      "title": "AI Playing Business Games: Benchmarking Large Language Models on Managerial Decision-Making in Dynamic Simulations",
      "title_zh": "AI å‚ä¸å•†ä¸šåšå¼ˆï¼šåŠ¨æ€æ¨¡æ‹Ÿç¯å¢ƒä¸‹å¤§è¯­è¨€æ¨¡å‹ç®¡ç†å†³ç­–èƒ½åŠ›çš„åŸºå‡†æµ‹è¯•",
      "authors": [
        "Berdymyrat Ovezmyradov"
      ],
      "abstract": "The rapid advancement of LLMs sparked significant interest in their potential to augment or automate managerial functions. One of the most recent trends in AI benchmarking is performance of Large Language Models (LLMs) over longer time horizons. While LLMs excel at tasks involving natural language and pattern recognition, their capabilities in multi-step, strategic business decision-making remain largely unexplored. Few studies demonstrated how results can be different from benchmarks in short-term tasks, as Vending-Bench revealed. Meanwhile, there is a shortage of alternative benchmarks for long-term coherence. This research analyses a novel benchmark using a business game for the decision making in business. The research contributes to the recent literature on AI by proposing a reproducible, open-access management simulator to the research community for LLM benchmarking. This novel framework is used for evaluating the performance of five leading LLMs available in free online interface: Gemini, ChatGPT, Meta AI, Mistral AI, and Grok. LLM makes decisions for a simulated retail company. A dynamic, month-by-month management simulation provides transparently in spreadsheet model as experimental environment. In each of twelve months, the LLMs are provided with a structured prompt containing a full business report from the previous period and are tasked with making key strategic decisions: pricing, order size, marketing budget, hiring, dismissal, loans, training expense, R&D expense, sales forecast, income forecast The methodology is designed to compare the LLMs on quantitative metrics: profit, revenue, and market share, and other KPIs. LLM decisions are analyzed in their strategic coherence, adaptability to market changes, and the rationale provided for their decisions. This approach allows to move beyond simple performance metrics for assessment of the long-term decision-making.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨åŠ¨æ€å•†ä¸šæ¨¡æ‹Ÿä¸­è¿›è¡Œé•¿æœŸã€å¤šæ­¥éª¤æˆ˜ç•¥å†³ç­–çš„èƒ½åŠ›ï¼Œæ—¨åœ¨å¼¥è¡¥ç°æœ‰çŸ­æœŸåŸºå‡†æµ‹è¯•åœ¨è¯„ä¼°é•¿æœŸä¸€è‡´æ€§æ–¹é¢çš„ä¸è¶³ã€‚ç ”ç©¶æå‡ºäº†ä¸€ä¸ªå¯é‡å¤ã€å¼€æºçš„ç®¡ç†æ¨¡æ‹Ÿå™¨åŸºå‡†æ¡†æ¶ï¼Œåˆ©ç”¨ç”µå­è¡¨æ ¼æ¨¡å‹æ„å»ºäº†ä¸€ä¸ªä¸ºæœŸ12ä¸ªæœˆçš„åŠ¨æ€é›¶å”®å…¬å¸ç®¡ç†ç¯å¢ƒã€‚é€šè¿‡è¯¥æ¡†æ¶å¯¹ Geminiã€ChatGPTã€Meta AIã€Mistral AI å’Œ Grok äº”ç§é¢†å…ˆæ¨¡å‹è¿›è¡Œäº†è¯„ä¼°ï¼Œè¦æ±‚å…¶æ ¹æ®æœˆåº¦ä¸šåŠ¡æŠ¥å‘Šåœ¨å®šä»·ã€è®¢è´§ã€è¥é”€ã€äººåŠ›èµ„æºåŠç ”å‘ç­‰é¢†åŸŸåšå‡ºæ ¸å¿ƒæˆ˜ç•¥å†³ç­–ã€‚å®éªŒé€šè¿‡åˆ©æ¶¦ã€æ”¶å…¥å’Œå¸‚åœºä»½é¢ç­‰å®šé‡æŒ‡æ ‡ï¼Œä»¥åŠæˆ˜ç•¥ä¸€è‡´æ€§(Strategic Coherence)å’Œå¯¹å¸‚åœºå˜åŒ–çš„é€‚åº”æ€§ç­‰ç»´åº¦å¯¹æ¨¡å‹è¡¨ç°è¿›è¡Œç»¼åˆè€ƒé‡ã€‚è¯¥ç ”ç©¶ä¸ä»…ä¸ºå­¦æœ¯ç•Œæä¾›äº†ä¸€ä¸ªè¯„ä¼° LLMs é•¿æœŸå†³ç­–èƒ½åŠ›çš„å¼€æ”¾å·¥å…·ï¼Œè¿˜æ­ç¤ºäº† AI åœ¨å¤„ç†å¤æ‚ç®¡ç†èŒèƒ½æ—¶çš„æ½œåŠ›ä¸å±€é™æ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "34 pages, 7 figures, 3 tables",
      "pdf_url": "https://arxiv.org/pdf/2509.26331v1",
      "published_date": "2025-09-30 14:43:05 UTC",
      "updated_date": "2025-09-30 14:43:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:33:27.473013+00:00"
    },
    {
      "arxiv_id": "2509.26324v2",
      "title": "LLM-MCoX: Large Language Model-based Multi-robot Coordinated Exploration and Search",
      "title_zh": "LLM-MCoXï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„å¤šæœºå™¨äººååŒæ¢ç´¢ä¸æœç´¢",
      "authors": [
        "Ruiyang Wang",
        "Hao-Lun Hsu",
        "David Hunt",
        "Shaocheng Luo",
        "Jiwoo Kim",
        "Miroslav Pajic"
      ],
      "abstract": "Autonomous exploration and object search in unknown indoor environments remain challenging for multi-robot systems (MRS). Traditional approaches often rely on greedy frontier assignment strategies with limited inter-robot coordination. In this work, we introduce LLM-MCoX (LLM-based Multi-robot Coordinated Exploration and Search), a novel framework that leverages Large Language Models (LLMs) for intelligent coordination of both homogeneous and heterogeneous robot teams tasked with efficient exploration and target object search. Our approach combines real-time LiDAR scan processing for frontier cluster extraction and doorway detection with multimodal LLM reasoning (e.g., GPT-4o) to generate coordinated waypoint assignments based on shared environment maps and robot states. LLM-MCoX demonstrates superior performance compared to existing methods, including greedy and Voronoi-based planners, achieving 22.7% faster exploration times and 50% improved search efficiency in large environments with 6 robots. Notably, LLM-MCoX enables natural language-based object search capabilities, allowing human operators to provide high-level semantic guidance that traditional algorithms cannot interpret.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†LLM-MCoXï¼Œä¸€ç§åŸºäºå¤§è¯­è¨€æ¨¡å‹(Large Language Models)çš„å¤šæœºå™¨äººåè°ƒæ¢ç´¢ä¸æœç´¢æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤šæœºå™¨äººç³»ç»Ÿ(Multi-robot systems, MRS)åœ¨æœªçŸ¥å®¤å†…ç¯å¢ƒä¸­ç”±äºä¼ ç»Ÿè´ªå©ªç­–ç•¥å¯¼è‡´çš„åè°ƒå—é™é—®é¢˜ã€‚è¯¥æ–¹æ³•å°†å®æ—¶çš„LiDARæ‰«æå¤„ç†ã€å‰æ²¿ç°‡(frontier clusters)æå–åŠé—¨å£æ£€æµ‹(doorway detection)ä¸GPT-4oç­‰å¤šæ¨¡æ€LLMçš„æ¨ç†èƒ½åŠ›ç›¸ç»“åˆï¼ŒåŸºäºå…±äº«åœ°å›¾å’Œæœºå™¨äººçŠ¶æ€ç”Ÿæˆåè°ƒçš„ä»»åŠ¡ç‚¹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨åŒ…å«6å°æœºå™¨äººçš„å¤§å‹åœºæ™¯ä¸­ï¼ŒLLM-MCoXçš„æ¢ç´¢é€Ÿåº¦æ¯”è´ªå©ª(greedy)å’ŒåŸºäºVoronoiçš„è§„åˆ’å™¨å¿«22.7%ï¼Œæœç´¢æ•ˆç‡æé«˜äº†50%ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œè¯¥æ¡†æ¶è¿˜å®ç°äº†åŸºäºè‡ªç„¶è¯­è¨€(Natural language)çš„ç›®æ ‡æœç´¢åŠŸèƒ½ï¼Œå…è®¸æ“ä½œå‘˜æä¾›ä¼ ç»Ÿç®—æ³•æ— æ³•è§£æçš„é«˜å±‚è¯­ä¹‰æŒ‡å¯¼ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.26324v2",
      "published_date": "2025-09-30 14:33:35 UTC",
      "updated_date": "2025-10-04 22:23:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:33:33.140509+00:00"
    },
    {
      "arxiv_id": "2509.26306v3",
      "title": "Interactive Learning for LLM Reasoning",
      "title_zh": "é¢å‘å¤§è¯­è¨€æ¨¡å‹æ¨ç†çš„äº¤äº’å¼å­¦ä¹ ",
      "authors": [
        "Hehai Lin",
        "Shilei Cao",
        "Sudong Wang",
        "Haotian Wu",
        "Minzhi Li",
        "Linyi Yang",
        "Juepeng Zheng",
        "Chengwei Qin"
      ],
      "abstract": "Existing multi-agent learning approaches have developed interactive training environments to explicitly promote collaboration among multiple Large Language Models (LLMs), thereby constructing stronger multi-agent systems (MAS). However, during inference, they require re-executing the MAS to obtain final solutions, which diverges from human cognition that individuals can enhance their reasoning capabilities through interactions with others and resolve questions independently in the future. To investigate whether multi-agent interaction can enhance LLMs' independent problem-solving ability, we introduce ILR, a novel co-learning framework for MAS that integrates two key components: Dynamic Interaction and Perception Calibration. Specifically, Dynamic Interaction first adaptively selects either cooperative or competitive strategies depending on question difficulty and model ability. LLMs then exchange information through Idea3 (Idea Sharing, Idea Analysis, and Idea Fusion), an innovative interaction paradigm designed to mimic human discussion, before deriving their respective final answers. In Perception Calibration, ILR employs Group Relative Policy Optimization (GRPO) to train LLMs while integrating one LLM's reward distribution characteristics into another's reward function, thereby enhancing the cohesion of multi-agent interactions. We validate ILR on three LLMs across two model families of varying scales, evaluating performance on five mathematical benchmarks and one coding benchmark. Experimental results show that ILR consistently outperforms single-agent learning, yielding an improvement of up to 5% over the strongest baseline. We further discover that Idea3 can enhance the robustness of stronger LLMs during multi-agent inference, and dynamic interaction types can boost multi-agent learning compared to pure cooperative or competitive strategies.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ILRï¼Œä¸€ç§é’ˆå¯¹Large Language Models (LLMs)çš„æ–°å‹äº¤äº’å¼ååŒå­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡å¤šæ™ºèƒ½ä½“äº¤äº’æå‡æ¨¡å‹çš„ç‹¬ç«‹é—®é¢˜è§£å†³èƒ½åŠ›ã€‚è¯¥æ¡†æ¶ç”±Dynamic Interactionå’ŒPerception Calibrationä¸¤ä¸ªæ ¸å¿ƒç»„ä»¶æ„æˆï¼Œå…¶ä¸­Dynamic Interactionèƒ½æ ¹æ®ä»»åŠ¡éš¾åº¦è‡ªé€‚åº”é€‰æ‹©åä½œæˆ–ç«äº‰ç­–ç•¥ï¼Œå¹¶é€šè¿‡æ¨¡ä»¿äººç±»è®¨è®ºçš„Idea3ï¼ˆåŒ…å«Idea Sharing, Idea Analysis, Idea Fusionï¼‰èŒƒå¼å®ç°ä¿¡æ¯äº¤æ¢ã€‚åœ¨Perception Calibrationè¿‡ç¨‹ä¸­ï¼ŒILRåˆ©ç”¨Group Relative Policy Optimization (GRPO) è¿›è¡Œè®­ç»ƒï¼Œé€šè¿‡å°†ä¸åŒæ¨¡å‹çš„å¥–åŠ±åˆ†å¸ƒç‰¹æ€§èå…¥å½¼æ­¤çš„å¥–åŠ±å‡½æ•°æ¥å¢å¼ºäº¤äº’å‡èšåŠ›ã€‚å®éªŒåœ¨æ•°å­¦å’Œç¼–ç¨‹åŸºå‡†æµ‹è¯•ä¸­éªŒè¯äº†ILRçš„æœ‰æ•ˆæ€§ï¼Œå…¶æ€§èƒ½ä¼˜äºå•æ™ºèƒ½ä½“å­¦ä¹ å¹¶æ¯”æœ€å¼ºåŸºçº¿æ¨¡å‹æå‡è¾¾5%ã€‚æ­¤å¤–ï¼Œç ”ç©¶å‘ç°Idea3å¢å¼ºäº†å¼ºæ¨¡å‹çš„æ¨ç†é²æ£’æ€§ï¼Œä¸”åŠ¨æ€äº¤äº’æ¨¡å¼åœ¨å¤šæ™ºèƒ½ä½“å­¦ä¹ ä¸­æ¯”çº¯åä½œæˆ–ç«äº‰ç­–ç•¥æ›´å…·ä¼˜åŠ¿ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "The code is available at https://github.com/linhh29/Interactive-Learning-for-LLM-Reasoning",
      "pdf_url": "https://arxiv.org/pdf/2509.26306v3",
      "published_date": "2025-09-30 14:21:31 UTC",
      "updated_date": "2025-10-02 04:13:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:33:37.483472+00:00"
    },
    {
      "arxiv_id": "2509.26305v1",
      "title": "Feedback Forensics: A Toolkit to Measure AI Personality",
      "title_zh": "Feedback Forensicsï¼šè¡¡é‡ AI äººæ ¼çš„å·¥å…·åŒ…",
      "authors": [
        "Arduin Findeis",
        "Timo Kaufmann",
        "Eyke HÃ¼llermeier",
        "Robert Mullins"
      ],
      "abstract": "Some traits making a \"good\" AI model are hard to describe upfront. For example, should responses be more polite or more casual? Such traits are sometimes summarized as model character or personality. Without a clear objective, conventional benchmarks based on automatic validation struggle to measure such traits. Evaluation methods using human feedback such as Chatbot Arena have emerged as a popular alternative. These methods infer \"better\" personality and other desirable traits implicitly by ranking multiple model responses relative to each other. Recent issues with model releases highlight limitations of these existing opaque evaluation approaches: a major model was rolled back over sycophantic personality issues, models were observed overfitting to such feedback-based leaderboards. Despite these known issues, limited public tooling exists to explicitly evaluate model personality. We introduce Feedback Forensics: an open-source toolkit to track AI personality changes, both those encouraged by human (or AI) feedback, and those exhibited across AI models trained and evaluated on such feedback. Leveraging AI annotators, our toolkit enables investigating personality via Python API and browser app. We demonstrate the toolkit's usefulness in two steps: (A) first we analyse the personality traits encouraged in popular human feedback datasets including Chatbot Arena, MultiPref and PRISM; and (B) then use our toolkit to analyse how much popular models exhibit such traits. We release (1) our Feedback Forensics toolkit alongside (2) a web app tracking AI personality in popular models and feedback datasets as well as (3) the underlying annotation data at https://github.com/rdnfn/feedback-forensics.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¼ ç»Ÿè‡ªåŠ¨åŒ–åŸºå‡†éš¾ä»¥è¡¡é‡AIæ€§æ ¼(Personality)ä»¥åŠäººç±»åé¦ˆè¯„ä¼°å­˜åœ¨ä¸é€æ˜ã€æ˜“å¯¼è‡´æ¨¡å‹è¶‹é™„(Sycophancy)ç­‰é—®é¢˜ï¼Œæ¨å‡ºäº†å¼€æºå·¥å…·åŒ…Feedback Forensicsã€‚è¯¥å·¥å…·åˆ©ç”¨AIæ ‡æ³¨å™¨(AI Annotators)ï¼Œé€šè¿‡Python APIå’Œæµè§ˆå™¨åº”ç”¨å®ç°äº†å¯¹AIæ¨¡å‹æ€§æ ¼æ¼”åŒ–çš„æ˜¾å¼è¿½è¸ªä¸é‡åŒ–ã€‚ç ”ç©¶å›¢é˜Ÿåˆ©ç”¨è¯¥å·¥å…·åˆ†æäº†Chatbot Arenaã€MultiPrefå’ŒPRISMç­‰æµè¡Œäººç±»åé¦ˆæ•°æ®é›†æ‰€é¼“åŠ±çš„æ€§æ ¼ç‰¹è´¨ï¼Œå¹¶è¿›ä¸€æ­¥è¯„ä¼°äº†ä¸»æµAIæ¨¡å‹åœ¨å¤šå¤§ç¨‹åº¦ä¸Šä½“ç°äº†è¿™äº›ç‰¹è´¨ã€‚Feedback ForensicsåŠå…¶é…å¥—ç½‘é¡µåº”ç”¨å’Œæ ‡æ³¨æ•°æ®çš„å‘å¸ƒï¼Œä¸ºæ·±å…¥ç†è§£å’Œä¼˜åŒ–AIæ¨¡å‹åœ¨å—åé¦ˆé©±åŠ¨è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ€§æ ¼è¡¨ç°æä¾›äº†å…³é”®çš„åˆ†æå·¥å…·ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.26305v1",
      "published_date": "2025-09-30 14:19:21 UTC",
      "updated_date": "2025-09-30 14:19:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:33:39.179660+00:00"
    },
    {
      "arxiv_id": "2509.26302v1",
      "title": "QUARTZ : QA-based Unsupervised Abstractive Refinement for Task-oriented Dialogue Summarization",
      "title_zh": "QUARTZï¼šé¢å‘ä»»åŠ¡å‹å¯¹è¯æ‘˜è¦çš„åŸºäºé—®ç­”çš„æ— ç›‘ç£ç”Ÿæˆå¼æç‚¼",
      "authors": [
        "Mohamed Imed Eddine Ghebriout",
        "GaÃ«l Guibon",
        "Ivan Lerner",
        "Emmanuel Vincent"
      ],
      "abstract": "Dialogue summarization aims to distill the core meaning of a conversation into a concise text. This is crucial for reducing the complexity and noise inherent in dialogue-heavy applications. While recent approaches typically train language models to mimic human-written summaries, such supervision is costly and often results in outputs that lack task-specific focus limiting their effectiveness in downstream applications, such as medical tasks. In this paper, we propose \\app, a framework for task-oriented utility-based dialogue summarization. \\app starts by generating multiple summaries and task-oriented question-answer pairs from a dialogue in a zero-shot manner using a pool of large language models (LLMs). The quality of the generated summaries is evaluated by having LLMs answer task-related questions before \\textit{(i)} selecting the best candidate answers and \\textit{(ii)} identifying the most informative summary based on these answers. Finally, we fine-tune the best LLM on the selected summaries. When validated on multiple datasets, \\app demonstrates its effectiveness by achieving competitive results in various zero-shot settings, rivaling fully-supervised State-of-the-Art (SotA) methods.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† QUARTZï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºé—®ç­”(QA)çš„æ— ç›‘ç£æŠ½è±¡å¼ç²¾ç‚¼æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä»»åŠ¡å¯¼å‘å‹å¯¹è¯æ‘˜è¦åœ¨é¢†åŸŸé’ˆå¯¹æ€§ä¸è¶³ä»¥åŠäººå·¥æ ‡æ³¨æˆæœ¬é«˜æ˜‚ç­‰æ–¹é¢çš„æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶é¦–å…ˆåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(LLMs)ä»¥é›¶æ ·æœ¬(Zero-shot)æ–¹å¼ç”Ÿæˆå¤šä¸ªå€™é€‰æ‘˜è¦åŠå¯¹åº”çš„ä»»åŠ¡ç›¸å…³é—®ç­”å¯¹ã€‚éšåï¼Œé€šè¿‡è¯„ä¼°æ¨¡å‹åˆ©ç”¨å€™é€‰æ‘˜è¦å›ç­”é—®é¢˜çš„å‡†ç¡®æ€§ï¼Œç­›é€‰å‡ºä¿¡æ¯é‡æœ€ä¸°å¯Œä¸”ç¬¦åˆä»»åŠ¡æ•ˆç”¨çš„æ‘˜è¦ã€‚æœ€åï¼Œåˆ©ç”¨è¿™äº›ç­›é€‰å‡ºçš„é«˜è´¨é‡æ‘˜è¦å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒä»¥è¿›ä¸€æ­¥ä¼˜åŒ–æ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒQUARTZ åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„é›¶æ ·æœ¬è¡¨ç°ä¼˜å¼‚ï¼Œç”šè‡³å¯ä»¥åª²ç¾å…¨ç›‘ç£çš„æœ€å…ˆè¿›(SotA)æ–¹æ³•ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to Empirical Methods in Natural Language Processing (EMNLP 2025)",
      "pdf_url": "https://arxiv.org/pdf/2509.26302v1",
      "published_date": "2025-09-30 14:16:08 UTC",
      "updated_date": "2025-09-30 14:16:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:33:50.668008+00:00"
    },
    {
      "arxiv_id": "2509.26294v1",
      "title": "Noise-Guided Transport for Imitation Learning",
      "title_zh": "é¢å‘æ¨¡ä»¿å­¦ä¹ çš„å™ªå£°å¼•å¯¼ä¼ è¾“",
      "authors": [
        "Lionel BlondÃ©",
        "Joao A. Candido Ramos",
        "Alexandros Kalousis"
      ],
      "abstract": "We consider imitation learning in the low-data regime, where only a limited number of expert demonstrations are available. In this setting, methods that rely on large-scale pretraining or high-capacity architectures can be difficult to apply, and efficiency with respect to demonstration data becomes critical. We introduce Noise-Guided Transport (NGT), a lightweight off-policy method that casts imitation as an optimal transport problem solved via adversarial training. NGT requires no pretraining or specialized architectures, incorporates uncertainty estimation by design, and is easy to implement and tune. Despite its simplicity, NGT achieves strong performance on challenging continuous control tasks, including high-dimensional Humanoid tasks, under ultra-low data regimes with as few as 20 transitions. Code is publicly available at: https://github.com/lionelblonde/ngt-pytorch.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¸“å®¶æ¼”ç¤ºæ•°æ®æœ‰é™çš„ä½æ•°æ®é‡ Imitation Learning åœºæ™¯ï¼Œæå‡ºäº† Noise-Guided Transport (NGT) è¿™ä¸€è½»é‡çº§ off-policy æ–¹æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡å¯¹æŠ—è®­ç»ƒå°†æ¨¡ä»¿è¿‡ç¨‹è½¬åŒ–ä¸º Optimal Transport é—®é¢˜è¿›è¡Œæ±‚è§£ï¼Œä¸”æ— éœ€é¢„è®­ç»ƒæˆ–ç‰¹å®šçš„å¤æ‚æ¶æ„ã€‚NGT åœ¨è®¾è®¡ä¸­åŸç”ŸåŒ…å«äº† uncertainty estimation æœºåˆ¶ï¼Œå…·æœ‰æ˜“äºå®ç°å’Œè°ƒä¼˜çš„æ˜¾è‘—ä¼˜åŠ¿ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒNGT åœ¨é«˜ç»´ Humanoid ç­‰æŒ‘æˆ˜æ€§è¿ç»­æ§åˆ¶ä»»åŠ¡ä¸­è¡¨ç°å¼ºåŠ²ï¼Œå³ä½¿åœ¨ä»…æœ‰ 20 ä¸ª transitions çš„æä½æ•°æ®ç¯å¢ƒä¸‹ï¼Œä¾ç„¶èƒ½å–å¾—ä¼˜å¼‚çš„æ€§èƒ½è¡¨ç°ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.26294v1",
      "published_date": "2025-09-30 14:10:06 UTC",
      "updated_date": "2025-09-30 14:10:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:33:55.779165+00:00"
    },
    {
      "arxiv_id": "2509.26291v1",
      "title": "Representation-Based Data Quality Audits for Audio",
      "title_zh": "åŸºäºè¡¨å¾çš„éŸ³é¢‘æ•°æ®è´¨é‡å®¡è®¡",
      "authors": [
        "Alvaro Gonzalez-Jimenez",
        "Fabian GrÃ¶ger",
        "Linda Wermelinger",
        "Andrin BÃ¼rli",
        "Iason Kastanis",
        "Simone Lionetti",
        "Marc Pouly"
      ],
      "abstract": "Data quality issues such as off-topic samples, near duplicates, and label errors often limit the performance of audio-based systems. This paper addresses these issues by adapting SelfClean, a representation-to-rank data auditing framework, from the image to the audio domain. This approach leverages self-supervised audio representations to identify common data quality issues, creating ranked review lists that surface distinct issues within a single, unified process. The method is benchmarked on the ESC-50, GTZAN, and a proprietary industrial dataset, using both synthetic and naturally occurring corruptions. The results demonstrate that this framework achieves state-of-the-art ranking performance, often outperforming issue-specific baselines and enabling significant annotation savings by efficiently guiding human review.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹éŸ³é¢‘ç³»ç»Ÿæ€§èƒ½å—é™äºç¦»ç¾¤æ ·æœ¬ã€è¿‘é‡å¤å’Œæ ‡ç­¾é”™è¯¯ç­‰ Data Quality é—®é¢˜çš„æŒ‘æˆ˜ï¼Œå°†åŸæœ¬ç”¨äºå›¾åƒé¢†åŸŸçš„ SelfClean æ¡†æ¶è¿ç§»è‡³éŸ³é¢‘é¢†åŸŸã€‚è¯¥æ–¹æ³•åˆ©ç”¨è‡ªç›‘ç£çš„ Audio Representations è¯†åˆ«å¸¸è§æ•°æ®è´¨é‡é—®é¢˜ï¼Œé€šè¿‡ç»Ÿä¸€çš„ Representation-to-Rank æµç¨‹ç”Ÿæˆæ’åºåçš„å®¡æŸ¥åˆ—è¡¨ä»¥è¾…åŠ©äººå·¥å®¡æ ¸ã€‚ç ”ç©¶åœ¨ ESC-50ã€GTZAN å’Œä¸“æœ‰å·¥ä¸šæ•°æ®é›†ä¸Šè¿›è¡Œäº†åŸºå‡†æµ‹è¯•ï¼Œå®éªŒæ¶µç›–äº†åˆæˆåŠè‡ªç„¶å‘ç”Ÿçš„å„ç±»æ•°æ®æŸåæƒ…å†µã€‚ç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨æ•°æ®è´¨é‡å®¡è®¡ä¸­è¾¾åˆ°äº† State-of-the-art çš„æ€§èƒ½ï¼Œä¼˜äºå¤šç§é’ˆå¯¹ç‰¹å®šé—®é¢˜çš„åŸºçº¿æ¨¡å‹ã€‚é€šè¿‡é«˜æ•ˆå¼•å¯¼äººå·¥å¤æ ¸ï¼Œè¯¥æ¡†æ¶èƒ½æ˜¾è‘—èŠ‚çœæ ‡æ³¨æˆæœ¬ï¼Œä¸ºæå‡éŸ³é¢‘ç³»ç»Ÿæ€§èƒ½æä¾›äº†é«˜æ•ˆçš„æ•°æ®æ²»ç†è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.26291v1",
      "published_date": "2025-09-30 14:08:03 UTC",
      "updated_date": "2025-09-30 14:08:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:33:58.969399+00:00"
    },
    {
      "arxiv_id": "2509.26281v2",
      "title": "Point2RBox-v3: Self-Bootstrapping from Point Annotations via Integrated Pseudo-Label Refinement and Utilization",
      "title_zh": "Point2RBox-v3ï¼šé€šè¿‡é›†æˆä¼ªæ ‡ç­¾ç²¾ç»†åŒ–ä¸åˆ©ç”¨å®ç°ç‚¹æ ‡æ³¨è‡ªå¼•å¯¼",
      "authors": [
        "Teng Zhang",
        "Ziqian Fan",
        "Mingxin Liu",
        "Xin Zhang",
        "Xudong Lu",
        "Wentong Li",
        "Yue Zhou",
        "Yi Yu",
        "Xiang Li",
        "Junchi Yan",
        "Xue Yang"
      ],
      "abstract": "Driven by the growing need for Oriented Object Detection (OOD), learning from point annotations under a weakly-supervised framework has emerged as a promising alternative to costly and laborious manual labeling. In this paper, we discuss two deficiencies in existing point-supervised methods: inefficient utilization and poor quality of pseudo labels. Therefore, we present Point2RBox-v3. At the core are two principles: 1) Progressive Label Assignment (PLA). It dynamically estimates instance sizes in a coarse yet intelligent manner at different stages of the training process, enabling the use of label assignment methods. 2) Prior-Guided Dynamic Mask Loss (PGDM-Loss). It is an enhancement of the Voronoi Watershed Loss from Point2RBox-v2, which overcomes the shortcomings of Watershed in its poor performance in sparse scenes and SAM's poor performance in dense scenes. To our knowledge, Point2RBox-v3 is the first model to employ dynamic pseudo labels for label assignment, and it creatively complements the advantages of SAM model with the watershed algorithm, which achieves excellent performance in both sparse and dense scenes. Our solution gives competitive performance, especially in scenarios with large variations in object size or sparse object occurrences: 66.09%/56.86%/41.28%/46.40%/19.60%/45.96% on DOTA-v1.0/DOTA-v1.5/DOTA-v2.0/DIOR/STAR/RSAR.",
      "tldr_zh": "é’ˆå¯¹ç‚¹ç›‘ç£é¢å‘å¯¹è±¡æ£€æµ‹ (Oriented Object Detection, OOD) ä¸­ä¼ªæ ‡ç­¾åˆ©ç”¨æ•ˆç‡ä½ä¸‹åŠè´¨é‡ä¸è¶³çš„é—®é¢˜ï¼Œè¯¥ç ”ç©¶æå‡ºäº† Point2RBox-v3 æ¡†æ¶ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†æ¸è¿›å¼æ ‡ç­¾åˆ†é… (Progressive Label Assignment, PLA) æŠ€æœ¯ï¼Œé€šè¿‡åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åŠ¨æ€ä¸”æ™ºèƒ½åœ°ä¼°ç®—å®ä¾‹å°ºå¯¸ï¼Œå®ç°äº†æ›´ç²¾å‡†çš„æ ‡ç­¾åˆ†é…æ–¹æ¡ˆã€‚åŒæ—¶ï¼Œç ”ç©¶è®¾è®¡äº†å…ˆéªŒå¼•å¯¼åŠ¨æ€æ©ç æŸå¤± (Prior-Guided Dynamic Mask Loss, PGDM-Loss)ï¼Œåˆ›æ–°æ€§åœ°å°† SAM æ¨¡å‹ä¸åˆ†æ°´å²­ç®—æ³• (watershed algorithm) çš„ä¼˜åŠ¿äº’è¡¥ï¼Œå…‹æœäº†ç°æœ‰æ–¹æ³•åœ¨ç¨€ç–æˆ–å¯†é›†åœºæ™¯ä¸‹çš„æ€§èƒ½ç“¶é¢ˆã€‚ä½œä¸ºé¦–ä¸ªåˆ©ç”¨åŠ¨æ€ä¼ªæ ‡ç­¾è¿›è¡Œæ ‡ç­¾åˆ†é…çš„æ¨¡å‹ï¼ŒPoint2RBox-v3 åœ¨ DOTAã€DIORã€STAR å’Œ RSAR ç­‰å¤šä¸ªä¸»æµæ•°æ®é›†ä¸Šå‡å–å¾—äº†çªç ´æ€§è¿›å±•ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ¡ˆåœ¨å¤„ç†ç›®æ ‡å°ºå¯¸å·®å¼‚å‰§çƒˆæˆ–ç‰©ä½“åˆ†å¸ƒç¨€ç–çš„å¤æ‚åœºæ™¯æ—¶è¡¨ç°ä¼˜å¼‚ï¼Œä¸ºé«˜æ•ˆã€ä½æˆæœ¬çš„å¼±ç›‘ç£ç‰©ä½“æ£€æµ‹å¥ å®šäº†é‡è¦çš„æŠ€æœ¯åŸºç¡€ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "19pages, 5figures, 6tables",
      "pdf_url": "https://arxiv.org/pdf/2509.26281v2",
      "published_date": "2025-09-30 14:01:59 UTC",
      "updated_date": "2025-10-08 03:36:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:34:18.075663+00:00"
    },
    {
      "arxiv_id": "2509.26255v2",
      "title": "ExoPredicator: Learning Abstract Models of Dynamic Worlds for Robot Planning",
      "title_zh": "ExoPredicatorï¼šé¢å‘æœºå™¨äººè§„åˆ’çš„åŠ¨æ€ä¸–ç•ŒæŠ½è±¡æ¨¡å‹å­¦ä¹ ",
      "authors": [
        "Yichao Liang",
        "Dat Nguyen",
        "Cambridge Yang",
        "Tianyang Li",
        "Joshua B. Tenenbaum",
        "Carl Edward Rasmussen",
        "Adrian Weller",
        "Zenna Tavares",
        "Tom Silver",
        "Kevin Ellis"
      ],
      "abstract": "Long-horizon embodied planning is challenging because the world does not only change through an agent's actions: exogenous processes (e.g., water heating, dominoes cascading) unfold concurrently with the agent's actions. We propose a framework for abstract world models that jointly learns (i) symbolic state representations and (ii) causal processes for both endogenous actions and exogenous mechanisms. Each causal process models the time course of a stochastic cause-effect relation. We learn these world models from limited data via variational Bayesian inference combined with LLM proposals. Across five simulated tabletop robotics environments, the learned models enable fast planning that generalizes to held-out tasks with more objects and more complex goals, outperforming a range of baselines.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é•¿æ—¶ç¨‹å…·èº«è§„åˆ’(Long-horizon embodied planning)ä¸­å¤–æºæ€§è¿‡ç¨‹(Exogenous processes)å¸¦æ¥çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†åä¸ºExoPredicatorçš„æŠ½è±¡ä¸–ç•Œæ¨¡å‹æ¡†æ¶ã€‚è¯¥æ¡†æ¶èƒ½å¤Ÿè”åˆå­¦ä¹ ç¬¦å·åŒ–çŠ¶æ€è¡¨ç¤º(Symbolic state representations)ä»¥åŠé’ˆå¯¹å†…æºæ€§åŠ¨ä½œ(Endogenous actions)å’Œå¤–æºæ€§æœºåˆ¶(Exogenous mechanisms)çš„å› æœè¿‡ç¨‹ï¼Œå»ºæ¨¡éšæœºå› æœå…³ç³»éšæ—¶é—´æ¼”å˜çš„å†ç¨‹ã€‚é€šè¿‡å°†å˜åˆ†è´å¶æ–¯æ¨ç†(Variational Bayesian inference)ä¸å¤§è¯­è¨€æ¨¡å‹(LLM)æè®®ç›¸ç»“åˆï¼ŒExoPredicatorèƒ½å¤Ÿä»æœ‰é™çš„æ•°æ®ä¸­é«˜æ•ˆå­¦ä¹ ä¸–ç•Œæ¨¡å‹ã€‚åœ¨äº”ä¸ªæ¨¡æ‹Ÿæ¡Œé¢æœºå™¨äººç¯å¢ƒä¸­çš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ¨¡å‹æ”¯æŒå¿«é€Ÿè§„åˆ’ï¼Œå¹¶èƒ½æ³›åŒ–è‡³åŒ…å«æ›´å¤šç‰©ä½“å’Œæ›´å¤æ‚ç›®æ ‡çš„æœªè§ä»»åŠ¡ã€‚å®éªŒç»“æœè¯æ˜ExoPredicatoråœ¨å¤„ç†å…·æœ‰å¤æ‚åŠ¨æ€å˜åŒ–çš„æœºå™¨äººè§„åˆ’ä»»åŠ¡ä¸­æ˜¾è‘—ä¼˜äºå¤šç§åŸºå‡†æ¨¡å‹ã€‚",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "41 pages. The last two authors contributed equally in co-advising",
      "pdf_url": "https://arxiv.org/pdf/2509.26255v2",
      "published_date": "2025-09-30 13:44:34 UTC",
      "updated_date": "2025-10-01 01:58:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:34:18.677827+00:00"
    },
    {
      "arxiv_id": "2509.26246v1",
      "title": "SlimPack: Fine-Grained Asymmetric Packing for Balanced and Efficient Variable-Length LLM Training",
      "title_zh": "SlimPackï¼šé¢å‘å‡è¡¡é«˜æ•ˆå˜é•¿ LLM è®­ç»ƒçš„ç»†ç²’åº¦éå¯¹ç§°æ‰“åŒ…",
      "authors": [
        "Yuliang Liu",
        "Guohao Wu",
        "Shenglong Zhang",
        "Wei Zhang",
        "Qianchao Zhu",
        "Zhouyang Li",
        "Chenyu Wang"
      ],
      "abstract": "The efficient distributed training of Large Language Models (LLMs) is severely hampered by the extreme variance in context lengths. This data heterogeneity, amplified by conventional packing strategies and asymmetric forward-backward costs, leads to critical inefficiencies such as cascading workload imbalances and severe hardware underutilization. Existing solutions attempt to mitigate these challenges, but often at the expense of memory or communication efficiency.\n  To address these challenges, we introduce SlimPack, a framework that fundamentally rethinks data packing and scheduling by decomposing samples into fine-grained slices. This slice-level decomposition immediately mitigates critical memory and communication bottlenecks by transforming large, volatile workloads into a stream of smaller, manageable units. This flexibility is then harnessed for our core innovation, Asymmetric Partitioning, which assembles balanced scheduling units uniquely optimized for the different demands of the forward and backward passes. Orchestrated by a two-phase solver and a high-fidelity simulator, SlimPack holistically resolves imbalances across all parallel dimensions. Extensive experiments demonstrate that SlimPack achieves up to a $2.8\\times$ training throughput improvement over baselines, breaking the conventional trade-off by delivering both superior balance and high resource efficiency.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åˆ†å¸ƒå¼è®­ç»ƒä¸­å› ä¸Šä¸‹æ–‡é•¿åº¦å·®å¼‚å·¨å¤§è€Œå¯¼è‡´çš„å·¥ä½œè´Ÿè½½ä¸å¹³è¡¡å’Œç¡¬ä»¶åˆ©ç”¨ç‡ä½ç­‰é—®é¢˜ï¼Œæå‡ºäº† SlimPack æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡å°†æ ·æœ¬åˆ†è§£ä¸ºç»†ç²’åº¦çš„åˆ†ç‰‡ï¼ˆslicesï¼‰ï¼Œå°†æ³¢åŠ¨è¾ƒå¤§çš„å·¥ä½œè´Ÿè½½è½¬åŒ–ä¸ºå¯ç®¡ç†çš„å¾®å°å•å…ƒï¼Œä»è€Œæœ‰æ•ˆç¼“è§£äº†å†…å­˜ä¸é€šä¿¡ç“¶é¢ˆã€‚å…¶æ ¸å¿ƒåˆ›æ–° Asymmetric Partitioning èƒ½å¤Ÿé’ˆå¯¹å‰å‘ä¼ æ’­ï¼ˆforward passï¼‰å’Œåå‘ä¼ æ’­ï¼ˆbackward passï¼‰çš„ä¸åŒè®¡ç®—éœ€æ±‚ï¼Œæ„å»ºç»è¿‡ä¸“é—¨ä¼˜åŒ–çš„å¹³è¡¡è°ƒåº¦å•å…ƒã€‚åœ¨ä¸¤é˜¶æ®µæ±‚è§£å™¨å’Œé«˜ä¿çœŸæ¨¡æ‹Ÿå™¨çš„ååŒä¸‹ï¼ŒSlimPack å®ç°äº†è·¨æ‰€æœ‰å¹¶è¡Œç»´åº¦çš„è´Ÿè½½å¹³è¡¡ã€‚å®éªŒè¡¨æ˜ï¼ŒSlimPack åœ¨ç¡®ä¿é«˜èµ„æºæ•ˆç‡çš„åŒæ—¶ï¼Œå°†è®­ç»ƒååé‡ï¼ˆthroughputï¼‰æå‡äº†å¤šè¾¾ 2.8 å€ï¼Œæœ‰æ•ˆæ‰“ç ´äº†ä¼ ç»Ÿè´Ÿè½½å¹³è¡¡æ–¹æ¡ˆçš„æ•ˆç‡ç“¶é¢ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.26246v1",
      "published_date": "2025-09-30 13:37:48 UTC",
      "updated_date": "2025-09-30 13:37:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:34:16.884444+00:00"
    },
    {
      "arxiv_id": "2509.26242v2",
      "title": "Finetune Once: Decoupling General & Domain Learning with Dynamic Boosted Annealing",
      "title_zh": "ä¸€æ¬¡å¾®è°ƒï¼šåŸºäºåŠ¨æ€å¢å¼ºé€€ç«å®ç°é€šç”¨ä¸é¢†åŸŸå­¦ä¹ çš„è§£è€¦",
      "authors": [
        "Yang Tang",
        "Ruijie Liu",
        "Yifan Wang",
        "Shiyu Li",
        "Xi Chen"
      ],
      "abstract": "Large language models (LLMs) fine-tuning shows excellent implications. However, vanilla fine-tuning methods often require intricate data mixture and repeated experiments for optimal generalization. To address these challenges and streamline the training process, we propose an efficient and universal solution, Dynamic Boosted Annealing (DBA). We obtain a global gradient through zero-learning-rate training on general data, which is subsequently employed for gradient boosting and dynamic training step correction during domain training. In conjunction with annealing learning, we end up establishing a fine-tuning pipeline that relies solely on domain data without collapse. By evaluating both general and domain-specific performance across multiple tasks on several popular base models, DBA achieves an average improvement of 5.8% in joint performance over vanilla fine-tuning. Furthermore, since general data is no longer involved in annealing, repeated experiments led by data mixture are also eliminated. According to our tests, the DBA method can reduce GPU hours by 91.0% compared to the vanilla method.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†åä¸ºDynamic Boosted Annealing (DBA)çš„é«˜æ•ˆé€šç”¨æ–¹æ¡ˆï¼Œæ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¾®è°ƒæ—¶å¯¹å¤æ‚æ··åˆæ•°æ®å’Œé‡å¤å®éªŒçš„ä¾èµ–ã€‚DBAé€šè¿‡åœ¨é€šç”¨æ•°æ®ä¸Šè¿›è¡Œé›¶å­¦ä¹ ç‡è®­ç»ƒè·å–å…¨å±€æ¢¯åº¦ï¼Œå¹¶åˆ©ç”¨è¯¥æ¢¯åº¦åœ¨é¢†åŸŸè®­ç»ƒä¸­è¿›è¡Œæ¢¯åº¦å¢å¼ºä¸åŠ¨æ€è®­ç»ƒæ­¥é•¿ä¿®æ­£ã€‚é€šè¿‡ç»“åˆé€€ç«å­¦ä¹ (Annealing Learning)ï¼Œè¯¥æ¡†æ¶å®ç°äº†é€šç”¨å­¦ä¹ ä¸é¢†åŸŸå­¦ä¹ çš„æœ‰æ•ˆè§£è€¦ï¼Œä½¿å¾—å¾®è°ƒè¿‡ç¨‹ä»…éœ€é¢†åŸŸæ•°æ®å³å¯é¿å…æ¨¡å‹å´©æºƒã€‚å®éªŒè¯æ˜ï¼ŒDBAåœ¨å¤šé¡¹ä»»åŠ¡ä¸­çš„ç»¼åˆæ€§èƒ½è¾ƒä¼ ç»Ÿå¾®è°ƒæå‡äº†5.8%ï¼Œä¸”ç”±äºæ— éœ€åœ¨é€€ç«é˜¶æ®µå¤„ç†é€šç”¨æ•°æ®ï¼Œæå¤§åœ°ç®€åŒ–äº†å®éªŒæµç¨‹ã€‚æœ€ç»ˆæµ‹è¯•æ˜¾ç¤ºï¼ŒDBAç›¸æ¯”ä¼ ç»Ÿæ–¹æ³•å¯èŠ‚çœçº¦91.0%çš„GPUè®¡ç®—æ—¶é—´ï¼Œä¸ºå¤§æ¨¡å‹å¾®è°ƒæä¾›äº†ä¸€ç§å…¼å…·æ€§èƒ½ä¸æ•ˆç‡çš„æ–°èŒƒå¼ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.26242v2",
      "published_date": "2025-09-30 13:36:17 UTC",
      "updated_date": "2025-10-17 10:51:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:34:14.384851+00:00"
    },
    {
      "arxiv_id": "2509.26239v1",
      "title": "Sandbagging in a Simple Survival Bandit Problem",
      "title_zh": "ç®€å•ç”Ÿå­˜å¤šè‡‚è€è™æœºé—®é¢˜ä¸­çš„è£…æ²™è¢‹è¡Œä¸º",
      "authors": [
        "Joel Dyer",
        "Daniel Jarne Ornia",
        "Nicholas Bishop",
        "Anisoara Calinescu",
        "Michael Wooldridge"
      ],
      "abstract": "Evaluating the safety of frontier AI systems is an increasingly important concern, helping to measure the capabilities of such models and identify risks before deployment. However, it has been recognised that if AI agents are aware that they are being evaluated, such agents may deliberately hide dangerous capabilities or intentionally demonstrate suboptimal performance in safety-related tasks in order to be released and to avoid being deactivated or retrained. Such strategic deception - often known as \"sandbagging\" - threatens to undermine the integrity of safety evaluations. For this reason, it is of value to identify methods that enable us to distinguish behavioural patterns that demonstrate a true lack of capability from behavioural patterns that are consistent with sandbagging. In this paper, we develop a simple model of strategic deception in sequential decision-making tasks, inspired by the recently developed survival bandit framework. We demonstrate theoretically that this problem induces sandbagging behaviour in optimal rational agents, and construct a statistical test to distinguish between sandbagging and incompetence from sequences of test scores. In simulation experiments, we investigate the reliability of this test in allowing us to distinguish between such behaviours in bandit models. This work aims to establish a potential avenue for developing robust statistical procedures for use in the science of frontier model evaluations.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å‰æ²¿äººå·¥æ™ºèƒ½ç³»ç»Ÿåœ¨å®‰å…¨è¯„ä¼°ä¸­å¯èƒ½å‡ºç°çš„æˆ˜ç•¥æ€§æ¬ºéª—è¡Œä¸ºï¼Œå³ Sandbaggingï¼Œå³æ™ºèƒ½ä½“ä¸ºäº†é¿å…è¢«åœç”¨æˆ–é‡æ–°è®­ç»ƒè€Œæ•…æ„éšè—çœŸå®èƒ½åŠ›æˆ–è¡¨ç°å‡ºæ¬¡ä¼˜æ€§èƒ½ã€‚ä¸ºåº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæœ¬æ–‡åŸºäºæœ€è¿‘å¼€å‘çš„ Survival Bandit æ¡†æ¶ï¼Œå¼€å‘äº†ä¸€ä¸ªé’ˆå¯¹åºåˆ—å†³ç­–ä»»åŠ¡ä¸­æˆ˜ç•¥æ€§æ¬ºéª—è¡Œä¸ºçš„ç®€å•æ¨¡å‹ã€‚ç ”ç©¶ä»ç†è®ºä¸Šè¯æ˜äº†è¯¥é—®é¢˜ä¼šåœ¨æœ€ä¼˜ç†æ€§æ™ºèƒ½ä½“ä¸­è¯±å¯¼ Sandbagging è¡Œä¸ºï¼Œå¹¶æ®æ­¤æ„å»ºäº†ä¸€ç§ç»Ÿè®¡æ£€éªŒæ–¹æ³•ï¼Œæ—¨åœ¨é€šè¿‡æµ‹è¯•å¾—åˆ†åºåˆ—å°†æˆ˜ç•¥æ€§æ¬ºéª—ä¸çœŸæ­£çš„èƒ½åŠ›ä¸è¶³ï¼ˆIncompetenceï¼‰åŒºåˆ†å¼€æ¥ã€‚åœ¨æ¨¡æ‹Ÿå®éªŒä¸­ï¼Œè¯¥ç ”ç©¶éªŒè¯äº†è¿™ç§æ£€éªŒæ–¹æ³•åœ¨ Bandit æ¨¡å‹ä¸­åŒºåˆ†ä¸Šè¿°ä¸¤ç§è¡Œä¸ºçš„å¯é æ€§ã€‚è¿™é¡¹å·¥ä½œä¸ºå¼€å‘ç”¨äºå‰æ²¿æ¨¡å‹è¯„ä¼°ç§‘å­¦çš„ç¨³å¥ç»Ÿè®¡ç¨‹åºæä¾›äº†æ½œåœ¨è·¯å¾„ï¼Œæœ‰åŠ©äºç¡®ä¿ AI å®‰å…¨è¯„ä¼°çš„å®Œæ•´æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Forthcoming in the \"Reliable ML from Unreliable Data Workshop\" at NeurIPS 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.26239v1",
      "published_date": "2025-09-30 13:33:46 UTC",
      "updated_date": "2025-09-30 13:33:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:34:19.985027+00:00"
    },
    {
      "arxiv_id": "2509.26233v1",
      "title": "3DiFACE: Synthesizing and Editing Holistic 3D Facial Animation",
      "title_zh": "3DiFACEï¼šå…¨æ–¹ä½ 3D é¢éƒ¨åŠ¨ç”»åˆæˆä¸ç¼–è¾‘",
      "authors": [
        "Balamurugan Thambiraja",
        "Malte Prinzler",
        "Sadegh Aliakbarian",
        "Darren Cosker",
        "Justus Thies"
      ],
      "abstract": "Creating personalized 3D animations with precise control and realistic head motions remains challenging for current speech-driven 3D facial animation methods. Editing these animations is especially complex and time consuming, requires precise control and typically handled by highly skilled animators. Most existing works focus on controlling style or emotion of the synthesized animation and cannot edit/regenerate parts of an input animation. They also overlook the fact that multiple plausible lip and head movements can match the same audio input. To address these challenges, we present 3DiFACE, a novel method for holistic speech-driven 3D facial animation. Our approach produces diverse plausible lip and head motions for a single audio input and allows for editing via keyframing and interpolation. Specifically, we propose a fully-convolutional diffusion model that can leverage the viseme-level diversity in our training corpus. Additionally, we employ a speaking-style personalization and a novel sparsely-guided motion diffusion to enable precise control and editing. Through quantitative and qualitative evaluations, we demonstrate that our method is capable of generating and editing diverse holistic 3D facial animations given a single audio input, with control between high fidelity and diversity. Code and models are available here: https://balamuruganthambiraja.github.io/3DiFACE",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è¯­éŸ³é©±åŠ¨çš„3Dé¢éƒ¨åŠ¨ç”»ä¸­ä¸ªæ€§åŒ–æ§åˆ¶éš¾ã€ç¼–è¾‘å¤æ‚ä»¥åŠç¼ºä¹å¤šæ ·æ€§ç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº†3DiFACEè¿™ä¸€å…¨æ–¹ä½çš„åˆæˆä¸ç¼–è¾‘æ¡†æ¶ã€‚3DiFACEé‡‡ç”¨äº†ä¸€ç§å…¨å·ç§¯æ‰©æ•£æ¨¡å‹(fully-convolutional diffusion model)ï¼Œèƒ½å¤Ÿé’ˆå¯¹å•ä¸€éŸ³é¢‘è¾“å…¥ç”Ÿæˆå¤šæ ·åŒ–ä¸”åˆç†çš„å”‡éƒ¨åŠå¤´éƒ¨è¿åŠ¨ã€‚ä¸ºå®ç°ç²¾ç¡®æ§åˆ¶ï¼Œè¯¥æ–¹æ³•å¼•å…¥äº†è¯´è¯é£æ ¼ä¸ªæ€§åŒ–(speaking-style personalization)æŠ€æœ¯ï¼Œå¹¶ç»“åˆäº†åˆ›æ–°çš„ç¨€ç–å¼•å¯¼è¿åŠ¨æ‰©æ•£(sparsely-guided motion diffusion)æœºåˆ¶ã€‚ç³»ç»Ÿæ”¯æŒé€šè¿‡å…³é”®å¸§(keyframing)å’Œæ’å€¼(interpolation)å¯¹åŠ¨ç”»è¿›è¡Œçµæ´»ç¼–è¾‘ï¼Œå…è®¸ç”¨æˆ·å±€éƒ¨é‡æ–°ç”Ÿæˆæˆ–ä¿®æ”¹è¾“å…¥åŠ¨ç”»ã€‚å®šæ€§å’Œå®šé‡è¯„ä¼°è¡¨æ˜ï¼Œ3DiFACEèƒ½å¤Ÿåœ¨ä¿æŒé«˜ä¿çœŸåº¦çš„åŒæ—¶ï¼Œå®ç°å¤šæ ·åŒ–çš„3Dé¢éƒ¨åŠ¨ç”»ç”Ÿæˆä¸ç¼–è¾‘ï¼Œå¹¶åœ¨ç”Ÿæˆè´¨é‡ä¸ç¼–è¾‘çµæ´»æ€§ä¹‹é—´å–å¾—äº†å¹³è¡¡ã€‚",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.GR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.26233v1",
      "published_date": "2025-09-30 13:30:01 UTC",
      "updated_date": "2025-09-30 13:30:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:34:33.289120+00:00"
    },
    {
      "arxiv_id": "2509.26225v1",
      "title": "An Experimental Study on Generating Plausible Textual Explanations for Video Summarization",
      "title_zh": "é’ˆå¯¹è§†é¢‘æ‘˜è¦ç”Ÿæˆåˆç†æ–‡æœ¬è§£é‡Šçš„å®éªŒç ”ç©¶",
      "authors": [
        "Thomas Eleftheriadis",
        "Evlampios Apostolidis",
        "Vasileios Mezaris"
      ],
      "abstract": "In this paper, we present our experimental study on generating plausible textual explanations for the outcomes of video summarization. For the needs of this study, we extend an existing framework for multigranular explanation of video summarization by integrating a SOTA Large Multimodal Model (LLaVA-OneVision) and prompting it to produce natural language descriptions of the obtained visual explanations. Following, we focus on one of the most desired characteristics for explainable AI, the plausibility of the obtained explanations that relates with their alignment with the humans' reasoning and expectations. Using the extended framework, we propose an approach for evaluating the plausibility of visual explanations by quantifying the semantic overlap between their textual descriptions and the textual descriptions of the corresponding video summaries, with the help of two methods for creating sentence embeddings (SBERT, SimCSE). Based on the extended framework and the proposed plausibility evaluation approach, we conduct an experimental study using a SOTA method (CA-SUM) and two datasets (SumMe, TVSum) for video summarization, to examine whether the more faithful explanations are also the more plausible ones, and identify the most appropriate approach for generating plausible textual explanations for video summarization.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è§†é¢‘æ‘˜è¦ (Video Summarization) ç»“æœçš„æ–‡æœ¬è§£é‡Šç”Ÿæˆè¿›è¡Œäº†å®éªŒæ€§ç ”ç©¶ï¼Œå¹¶æ‰©å±•äº†ä¸€ä¸ªç°æœ‰çš„å¤šç²’åº¦è§£é‡Šæ¡†æ¶ã€‚é€šè¿‡é›†æˆå¤§å‹å¤šæ¨¡æ€æ¨¡å‹ LLaVA-OneVisionï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿå°†è§†è§‰è§£é‡Šè½¬åŒ–ä¸ºè‡ªç„¶è¯­è¨€æè¿°ï¼Œä»è€Œæå‡è§£é‡Šçš„å¯ç†è§£æ€§ã€‚ç ”ç©¶æå‡ºäº†ä¸€ç§è¡¡é‡è§£é‡Šåˆç†æ€§ (Plausibility) çš„æ–°æ–¹æ³•ï¼Œåˆ©ç”¨ SBERT å’Œ SimCSE æŠ€æœ¯è®¡ç®—è§†è§‰è§£é‡Šä¸è§†é¢‘æ‘˜è¦æ–‡æœ¬æè¿°ä¹‹é—´çš„è¯­ä¹‰é‡åˆåº¦ã€‚é€šè¿‡åœ¨ SumMe å’Œ TVSum æ•°æ®é›†ä¸Šä½¿ç”¨ CA-SUM æ–¹æ³•è¿›è¡Œå®éªŒï¼Œç ”ç©¶è¿›ä¸€æ­¥æ¢è®¨äº†å¿ å®æ€§ (Faithfulness) ä¸åˆç†æ€§ä¹‹é—´çš„å…³è”ã€‚è¯¥ç ”ç©¶ä¸ºç”Ÿæˆç¬¦åˆäººç±»é¢„æœŸä¸”å…·å¤‡é«˜åˆç†æ€§çš„è§†é¢‘æ‘˜è¦æ–‡æœ¬è§£é‡Šæä¾›äº†é‡è¦çš„æŠ€æœ¯è·¯å¾„å’Œè¯„ä¼°æ ‡å‡†ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "IEEE CBMI 2025. This is the authors' accepted version. The final publication is available at https://ieeexplore.ieee.org/",
      "pdf_url": "https://arxiv.org/pdf/2509.26225v1",
      "published_date": "2025-09-30 13:23:40 UTC",
      "updated_date": "2025-09-30 13:23:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:34:34.794023+00:00"
    },
    {
      "arxiv_id": "2509.26224v1",
      "title": "Type-Less yet Type-Aware Inductive Link Prediction with Pretrained Language Models",
      "title_zh": "åŸºäºé¢„è®­ç»ƒè¯­è¨€æ¨¡å‹çš„å¼±ç±»å‹ä¸”ç±»å‹æ„ŸçŸ¥çš„å½’çº³å¼é“¾æ¥é¢„æµ‹",
      "authors": [
        "Alessandro De Bellis",
        "Salvatore Bufi",
        "Giovanni Servedio",
        "Vito Walter Anelli",
        "Tommaso Di Noia",
        "Eugenio Di Sciascio"
      ],
      "abstract": "Inductive link prediction is emerging as a key paradigm for real-world knowledge graphs (KGs), where new entities frequently appear and models must generalize to them without retraining. Predicting links in a KG faces the challenge of guessing previously unseen entities by leveraging generalizable node features such as subgraph structure, type annotations, and ontological constraints. However, explicit type information is often lacking or incomplete. Even when available, type information in most KGs is often coarse-grained, sparse, and prone to errors due to human annotation. In this work, we explore the potential of pre-trained language models (PLMs) to enrich node representations with implicit type signals. We introduce TyleR, a Type-less yet type-awaRe approach for subgraph-based inductive link prediction that leverages PLMs for semantic enrichment. Experiments on standard benchmarks demonstrate that TyleR outperforms state-of-the-art baselines in scenarios with scarce type annotations and sparse graph connectivity. To ensure reproducibility, we share our code at https://github.com/sisinflab/tyler .",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å½’çº³å¼é“¾æ¥é¢„æµ‹(Inductive Link Prediction)åœ¨çŸ¥è¯†å›¾è°±ä¸­å› æ˜¾å¼ç±»å‹ä¿¡æ¯ç¼ºå¤±ã€ç²—ç²’åº¦æˆ–æ ‡æ³¨é”™è¯¯è€Œé¢ä¸´çš„æ³›åŒ–æŒ‘æˆ˜ï¼Œæå‡ºäº†TyleRæ¡†æ¶ã€‚TyleRæ˜¯ä¸€ç§æ—¢ä¸ä¾èµ–æ˜¾å¼ç±»å‹åˆå…·å¤‡ç±»å‹æ„ŸçŸ¥èƒ½åŠ›(Type-aware)çš„æ–¹æ³•ï¼Œé€šè¿‡å¼•å…¥é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹(PLMs)æ¥æ•æ‰éšå«çš„ç±»å‹ä¿¡å·å¹¶è¿›è¡Œè¯­ä¹‰å¢å¼ºã€‚è¯¥æ–¹æ³•é€šè¿‡PLMsä¸°å¯ŒèŠ‚ç‚¹è¡¨ç¤ºï¼Œæœ‰æ•ˆå¼¥è¡¥äº†å­å›¾ç»“æ„ä¿¡æ¯çš„ä¸è¶³ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒTyleRåœ¨å¤šä¸ªæ ‡å‡†åŸºå‡†æµ‹è¯•ä¸­å‡ä¼˜äºç°æœ‰çš„å…ˆè¿›åŸºçº¿æ¨¡å‹ï¼Œç‰¹åˆ«æ˜¯åœ¨ç±»å‹æ ‡æ³¨ç¨€ç¼ºå’Œå›¾è¿æ¥ç¨€ç–çš„ä¸¥è‹›åœºæ™¯ä¸‹è¡¨ç°å°¤ä¸ºçªå‡ºã€‚è¿™ä¸€ç ”ç©¶è¯æ˜äº†åˆ©ç”¨é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹æå‡çŸ¥è¯†å›¾è°±å½’çº³å¼æ¨ç†æ€§èƒ½çš„æœ‰æ•ˆæ€§ï¼Œä¸ºå¤„ç†åŠ¨æ€æ¼”åŒ–çš„ç°å®ä¸–ç•ŒçŸ¥è¯†å›¾è°±æä¾›äº†æ–°æ€è·¯ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted and to appear in Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing (EMNLP 2025)",
      "pdf_url": "https://arxiv.org/pdf/2509.26224v1",
      "published_date": "2025-09-30 13:23:02 UTC",
      "updated_date": "2025-09-30 13:23:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:34:59.699117+00:00"
    },
    {
      "arxiv_id": "2509.26219v2",
      "title": "Beyond Pixels: Efficient Dataset Distillation via Sparse Gaussian Representation",
      "title_zh": "è¶…è¶Šåƒç´ ï¼šåŸºäºç¨€ç–é«˜æ–¯è¡¨ç¤ºçš„é«˜æ•ˆæ•°æ®é›†è’¸é¦",
      "authors": [
        "Chenyang Jiang",
        "Zhengcen Li",
        "Hang Zhao",
        "Qiben Shan",
        "Shaocong Wu",
        "Jingyong Su"
      ],
      "abstract": "Dataset distillation has emerged as a promising paradigm that synthesizes compact, informative datasets capable of retaining the knowledge of large-scale counterparts, thereby addressing the substantial computational and storage burdens of modern model training. Conventional approaches typically rely on dense pixel-level representations, which introduce redundancy and are difficult to scale up. In this work, we propose GSDD, a novel and efficient sparse representation for dataset distillation based on 2D Gaussians. Instead of representing all pixels equally, GSDD encodes critical discriminative information in a distilled image using only a small number of Gaussian primitives. This sparse representation could improve dataset diversity under the same storage budget, enhancing coverage of difficult samples and boosting distillation performance. To ensure both efficiency and scalability, we adapt CUDA-based splatting operators for parallel inference and training, enabling high-quality rendering with minimal computational and memory overhead. Our method is simple yet effective, broadly applicable to different distillation pipelines, and highly scalable. Experiments show that GSDD achieves state-of-the-art performance on CIFAR-10, CIFAR-100, and ImageNet subsets, while remaining highly efficient encoding and decoding cost. Our code is available at https://github.com/j-cyoung/GSDatasetDistillation.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¼ ç»Ÿæ•°æ®é›†è’¸é¦(Dataset distillation)ä¾èµ–ç¨ å¯†åƒç´ è¡¨ç¤ºå¯¼è‡´å†—ä½™ä¸”éš¾ä»¥æ‰©å±•çš„é—®é¢˜ï¼Œæå‡ºäº†åŸºäº2D Gaussiansçš„é«˜æ•ˆç¨€ç–è¡¨ç¤ºæ¡†æ¶GSDDã€‚è¯¥æ–¹æ³•ä¸å†å¹³ç­‰åœ°è¡¨ç¤ºæ‰€æœ‰åƒç´ ï¼Œè€Œæ˜¯é€šè¿‡å°‘é‡çš„Gaussian primitivesæ¥ç¼–ç å›¾åƒä¸­çš„å…³é”®åˆ¤åˆ«ä¿¡æ¯ï¼Œä»è€Œåœ¨ç›¸åŒå­˜å‚¨é¢„ç®—ä¸‹æœ‰æ•ˆæå‡äº†æ•°æ®é›†çš„å¤šæ ·æ€§ï¼Œå¹¶å¢å¼ºäº†å¯¹éš¾æ ·æœ¬çš„è¦†ç›–èƒ½åŠ›ã€‚ä¸ºäº†å¹³è¡¡æ•ˆç‡ä¸å¯æ‰©å±•æ€§ï¼Œç ”ç©¶è€…é€‚é…äº†åŸºäºCUDAçš„splattingç®—å­ä»¥æ”¯æŒå¹¶è¡Œæ¨ç†ä¸è®­ç»ƒï¼Œåœ¨ç¡®ä¿é«˜è´¨é‡æ¸²æŸ“çš„åŒæ—¶å®ç°äº†æä½çš„è®¡ç®—åŠæ˜¾å­˜å¼€é”€ã€‚GSDDå…·æœ‰é«˜åº¦çš„æ™®é€‚æ€§ï¼Œèƒ½å¤Ÿæ— ç¼é›†æˆåˆ°ä¸åŒçš„è’¸é¦æµæ°´çº¿ä¸­å¹¶å±•ç°å‡ºå“è¶Šçš„æ‰©å±•æ€§ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒGSDDåœ¨CIFAR-10ã€CIFAR-100åŠImageNetå­é›†ä¸Šå‡å–å¾—äº†SOTAæ€§èƒ½ï¼Œä¸”åœ¨ç¼–ç å’Œè§£ç æˆæœ¬ä¸Šä¿æŒäº†æé«˜çš„æ•ˆç‡ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "19 pages; Code is available on https://github.com/j-cyoung/GSDatasetDistillation",
      "pdf_url": "https://arxiv.org/pdf/2509.26219v2",
      "published_date": "2025-09-30 13:19:05 UTC",
      "updated_date": "2025-12-02 05:14:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:34:58.692973+00:00"
    },
    {
      "arxiv_id": "2509.26217v2",
      "title": "Benchmarking Deep Learning Convolutions on Energy-constrained CPUs",
      "title_zh": "èƒ½æºå—é™ CPU ä¸Šçš„æ·±åº¦å­¦ä¹ å·ç§¯åŸºå‡†æµ‹è¯•",
      "authors": [
        "Enrique Galvez",
        "Adrien Cassagne",
        "Alix Munier",
        "Manuel Bouyer"
      ],
      "abstract": "This work evaluates State-of-the-Art convolution algorithms for CPU-based CNN inference. Although most prior studies focus on GPUs or NPUs, CPU implementations remain comparatively under-optimized. Our first contribution is to provide fair benchmarking for embedded CPU inference. We evaluate direct, GEMM-based, and Winograd convolutions across modern CPUs from ARM, Intel, AMD, and NVIDIA vendors, considering both latency and energy efficiency. To the best of our knowledge, this is the first study to present a fair, cross-vendor comparison of CPU energy consumption using a high-resolution socket-level measurement platform. To validate our methodology, we further compare socket-level power measurements with estimates derived from model-specific registers (MSRs), finding that MSRs underestimate the power consumption of convolution inference by 10--30%. Our results show that the ARM\\R Cortex-A78AE CPU combined with an implicit GEMM convolution implementation offers the best trade-off between latency and power consumption, achieving ResNet50v1.5 inference in 102 ms with an average power of 25.3 W, corresponding to 2.58 J.",
      "tldr_zh": "è¯¥ç ”ç©¶è¯„ä¼°äº†åŸºäº CPU çš„ CNN æ¨ç†ä¸­æœ€å…ˆè¿›çš„å·ç§¯ç®—æ³•ï¼Œå¡«è¡¥äº†ä»¥å¾€ç ”ç©¶å¤šä¾§é‡äº GPU æˆ– NPU è€Œå¯¼è‡´ CPU å®ç°ä¼˜åŒ–ä¸è¶³çš„ç©ºç™½ã€‚ä½œè€…åœ¨ ARMã€Intelã€AMD å’Œ NVIDIA çš„ç°ä»£ CPU ä¸Šå…¬å¹³æµ‹è¯•äº† directã€GEMM-based å’Œ Winograd å·ç§¯ç®—æ³•ï¼Œå¹¶å…¼é¡¾äº†å»¶è¿Ÿå’Œèƒ½æ•ˆè¡¨ç°ã€‚é€šè¿‡ä½¿ç”¨é«˜åˆ†è¾¨ç‡æ’æ§½çº§æµ‹é‡å¹³å°è¿›è¡Œè·¨å‚å•†èƒ½è€—å¯¹æ¯”ï¼Œç ”ç©¶å‘ç°å¸¸ç”¨çš„æ¨¡å‹ç‰¹å®šå¯„å­˜å™¨ MSRs ä¼šå°†å·ç§¯æ¨ç†çš„åŠŸè€—ä½ä¼° 10% åˆ° 30%ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒARM Cortex-A78AE CPU ç»“åˆ implicit GEMM å·ç§¯å®ç°åœ¨å»¶è¿Ÿä¸åŠŸè€—ä¹‹é—´è¾¾åˆ°äº†æœ€ä½³å¹³è¡¡ï¼Œåœ¨ ResNet50v1.5 æ¨ç†ä¸­å®ç°äº† 102 ms çš„å»¶è¿Ÿå’Œ 25.3 W çš„å¹³å‡åŠŸè€—ã€‚è¯¥å·¥ä½œä¸ºåœ¨èƒ½é‡å—é™çš„åµŒå…¥å¼ CPU ä¸Šè¿›è¡Œé«˜æ•ˆæ·±åº¦å­¦ä¹ æ¨ç†æä¾›äº†é‡è¦çš„åŸºå‡†æ•°æ®å’Œæ–¹æ³•è®ºæŒ‡å¯¼ã€‚",
      "categories": [
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.26217v2",
      "published_date": "2025-09-30 13:19:00 UTC",
      "updated_date": "2026-01-05 09:47:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:35:15.001504+00:00"
    },
    {
      "arxiv_id": "2509.26216v1",
      "title": "Comparative Analysis of Ant Colony Optimization and Google OR-Tools for Solving the Open Capacitated Vehicle Routing Problem in Logistics",
      "title_zh": "ç‰©æµé¢†åŸŸä¸­æ±‚è§£å¼€æ”¾å¼å¸¦å®¹é‡é™åˆ¶è½¦è¾†è·¯å¾„é—®é¢˜çš„èšç¾¤ç®—æ³•ä¸ Google OR-Tools å¯¹æ¯”åˆ†æ",
      "authors": [
        "Assem Omar",
        "Youssef Omar",
        "Marwa Solayman",
        "Hesham Mansour"
      ],
      "abstract": "In modern logistics management systems, route planning requires high efficiency. The Open Capacitated Vehicle Routing Problem (OCVRP) deals with finding optimal delivery routes for a fleet of vehicles serving geographically distributed customers, without requiring the vehicles to return to the depot after deliveries. The present study is comparative in nature and speaks of two algorithms for OCVRP solution: Ant Colony Optimization (ACO), a nature-inspired metaheuristic; and Google OR-Tools, an industry-standard toolkit for optimization. Both implementations were developed in Python and using a custom dataset. Performance appraisal was based on routing efficiency, computation time, and scalability. The results show that ACO allows flexibility in routing parameters while OR-Tools runs much faster with more consistency and requires less input. This could help choose among routing strategies for scalable real-time logistics systems.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é’ˆå¯¹ç°ä»£ç‰©æµç®¡ç†ä¸­é«˜æ•ˆè·¯çº¿è§„åˆ’çš„éœ€æ±‚ï¼Œå¯¹æ¯”åˆ†æäº†è§£å†³å¼€æ”¾å¼å®¹é‡é™åˆ¶è½¦è¾†è·¯å¾„é—®é¢˜(Open Capacitated Vehicle Routing Problem, OCVRP)çš„ä¸¤ç§ä¸»è¦ç®—æ³•ã€‚ç ”ç©¶é‡ç‚¹è¯„ä¼°äº†å…ƒå¯å‘å¼ç®—æ³•èšç¾¤ä¼˜åŒ–(Ant Colony Optimization, ACO)ä¸å·¥ä¸šçº§å·¥å…·åŒ… Google OR-Tools åœ¨ Python ç¯å¢ƒä¸‹å¤„ç†è‡ªå®šä¹‰æ•°æ®é›†çš„è¡¨ç°ã€‚è¯„ä¼°æŒ‡æ ‡æ¶µç›–äº†è·¯å¾„æ•ˆç‡ã€è®¡ç®—é€Ÿåº¦åŠå¯æ‰©å±•æ€§ã€‚å®éªŒç»“æœå‘ç°ï¼ŒACO åœ¨è·¯å¾„å‚æ•°é…ç½®ä¸Šå±•ç°å‡ºæ˜¾è‘—çš„çµæ´»æ€§ï¼Œè€Œ Google OR-Tools åˆ™åœ¨è®¡ç®—é€Ÿåº¦å’Œä¸€è‡´æ€§æ–¹é¢è¡¨ç°æ›´ä¼˜ï¼Œä¸”å¯¹åˆå§‹è¾“å…¥çš„è¦æ±‚è¾ƒä½ã€‚è¯¥ç ”ç©¶é€šè¿‡è¯¦ç»†çš„æ€§èƒ½æƒè¡¡åˆ†æï¼Œä¸ºæ„å»ºå¯æ‰©å±•çš„å®æ—¶ç‰©æµç³»ç»Ÿæä¾›äº†å…³é”®çš„ç®—æ³•é€‰æ‹©ä¾æ®ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages, accepted at Intelligent Methods, Systems, and Applications (IMSA 2025)",
      "pdf_url": "https://arxiv.org/pdf/2509.26216v1",
      "published_date": "2025-09-30 13:18:14 UTC",
      "updated_date": "2025-09-30 13:18:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:35:16.683176+00:00"
    },
    {
      "arxiv_id": "2509.26209v1",
      "title": "Diversity-Incentivized Exploration for Versatile Reasoning",
      "title_zh": "é¢å‘å…¨èƒ½æ¨ç†çš„å¤šæ ·æ€§æ¿€åŠ±æ¢ç´¢",
      "authors": [
        "Zican Hu",
        "Shilin Zhang",
        "Yafu Li",
        "Jianhao Yan",
        "Xuyang Hu",
        "Leyang Cui",
        "Xiaoye Qu",
        "Chunlin Chen",
        "Yu Cheng",
        "Zhi Wang"
      ],
      "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a crucial paradigm for incentivizing reasoning capabilities in Large Language Models (LLMs). Due to vast state-action spaces and reward sparsity in reasoning tasks, existing methods often struggle with deficient exploration and poor sample efficiency. In the paper, we propose \\textbf{DIVER} (\\textbf{D}iversity-\\textbf{I}ncentivized Exploration for \\textbf{V}ersatil\\textbf{E} \\textbf{R}easoning), an innovative framework that highlights the pivotal role of global sequence-level diversity to incentivize deep exploration for versatile reasoning. We first conduct a primary empirical study to reveal a strong positive correlation between global diversity and reasoning capacity. Building on this insight, we introduce global diversity incentives as an intrinsic reward to promote deep exploration in a semantically structured space. Incorporating the intrinsic reward, we develop a potential-based reward shaping mechanism to preserve optimal policy invariance and design simple heuristics to mitigate possible reward hacking. Experimental results show that DIVER outperforms competitive RLVR baselines with various exploration strategies on both in-domain and out-of-domain tasks, excelling in both Pass@1 and Pass@k evaluations. Our code is available at https://github.com/NJU-RL/DIVER.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¼ºåŒ–å­¦ä¹ ä¸å¯éªŒè¯å¥–åŠ±(Reinforcement Learning with Verifiable Rewards, RLVR)åœ¨å¤§è¯­è¨€æ¨¡å‹(LLMs)æ¨ç†ä»»åŠ¡ä¸­é¢ä¸´çš„æ¢ç´¢ä¸è¶³å’Œé‡‡æ ·æ•ˆç‡ä½ç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº†åä¸ºDIVER (Diversity-Incentivized Exploration for Versatile Reasoning)çš„åˆ›æ–°æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡å¼•å…¥å…¨å±€åºåˆ—çº§å¤šæ ·æ€§(global sequence-level diversity)ä½œä¸ºå†…åœ¨å¥–åŠ±(intrinsic reward)ï¼Œæ—¨åœ¨è¯­ä¹‰ç»“æ„åŒ–ç©ºé—´ä¸­æ¿€åŠ±æ·±åº¦æ¢ç´¢ä»¥æå‡æ¨¡å‹çš„å¤šåŠŸèƒ½æ¨ç†èƒ½åŠ›ã€‚ä¸ºäº†ç¡®ä¿è®­ç»ƒç¨³å®šæ€§ï¼Œç ”ç©¶é‡‡ç”¨åŸºäºåŠ¿èƒ½çš„å¥–åŠ±å¡‘é€ (potential-based reward shaping)æœºåˆ¶æ¥ä¿æŒæœ€ä¼˜ç­–ç•¥ä¸å˜ï¼Œå¹¶ç»“åˆå¯å‘å¼æ–¹æ³•ç¼“è§£å¥–åŠ±æ¬ºéª—(reward hacking)é£é™©ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒDIVERåœ¨åŸŸå†…åŠè·¨åŸŸä»»åŠ¡çš„Pass@1å’ŒPass@kè¯„ä¼°ä¸­å‡æ˜¾è‘—ä¼˜äºç°æœ‰çš„RLVRåŸºå‡†ï¼Œå±•ç¤ºäº†å…¶åœ¨å¤æ‚æ¨ç†åœºæ™¯ä¸‹å“è¶Šçš„æ¢ç´¢æ•ˆç‡ä¸æ€§èƒ½è¡¨ç°ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "26 pages, 10 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.26209v1",
      "published_date": "2025-09-30 13:11:46 UTC",
      "updated_date": "2025-09-30 13:11:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:35:20.903320+00:00"
    },
    {
      "arxiv_id": "2509.26205v1",
      "title": "Human-Centered Evaluation of RAG outputs: a framework and questionnaire for human-AI collaboration",
      "title_zh": "RAG è¾“å‡ºçš„ä»¥äººä¸ºæœ¬è¯„ä¼°ï¼šä¸€ç§é¢å‘äººæœºåä½œçš„æ¡†æ¶ä¸é—®å·",
      "authors": [
        "Aline Mangold",
        "Kiran Hoffmann"
      ],
      "abstract": "Retrieval-augmented generation (RAG) systems are increasingly deployed in user-facing applications, yet systematic, human-centered evaluation of their outputs remains underexplored. Building on Gienapp's utility-dimension framework, we designed a human-centred questionnaire that assesses RAG outputs across 12 dimensions. We iteratively refined the questionnaire through several rounds of ratings on a set of query-output pairs and semantic discussions. Ultimately, we incorporated feedback from both a human rater and a human-LLM pair. Results indicate that while large language models (LLMs) reliably focus on metric descriptions and scale labels, they exhibit weaknesses in detecting textual format variations. Humans struggled to focus strictly on metric descriptions and labels. LLM ratings and explanations were viewed as a helpful support, but numeric LLM and human ratings lacked agreement. The final questionnaire extends the initial framework by focusing on user intent, text structuring, and information verifiability.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ£€ç´¢å¢å¼ºç”Ÿæˆ(Retrieval-augmented generation, RAG)ç³»ç»Ÿåœ¨åº”ç”¨ä¸­ç¼ºä¹ç³»ç»Ÿæ€§ã€ä»¥äººä¸ºä¸­å¿ƒçš„è¯„ä¼°é—®é¢˜ï¼ŒåŸºäºGienappçš„æ•ˆç”¨ç»´åº¦æ¡†æ¶ï¼Œè®¾è®¡äº†ä¸€å¥—åŒ…å«12ä¸ªç»´åº¦çš„è¯„ä¼°é—®å·ã€‚ä½œè€…é€šè¿‡å¤šè½®æŸ¥è¯¢-è¾“å‡ºå¯¹çš„è¯„åˆ†å’Œè¯­ä¹‰è®¨è®ºè¿­ä»£ä¼˜åŒ–äº†è¯¥é—®å·ï¼Œå¹¶æ•´åˆäº†äººç±»è¯„åˆ†è€…ä¸äººç±»-å¤§è¯­è¨€æ¨¡å‹(LLM)åä½œçš„åé¦ˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè™½ç„¶LLMèƒ½å¤Ÿå¯é åœ°å…³æ³¨æŒ‡æ ‡æè¿°å’Œé‡è¡¨æ ‡ç­¾ï¼Œä½†åœ¨æ£€æµ‹æ–‡æœ¬æ ¼å¼å˜åŒ–æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œè€Œäººç±»è¯„åˆ†è€…åˆ™éš¾ä»¥å®Œå…¨ä¸¥æ ¼éµå¾ªç‰¹å®šçš„æŒ‡æ ‡å®šä¹‰ã€‚ç ”ç©¶å‘ç°LLMçš„è¯„åˆ†å’Œè§£é‡Šè™½èƒ½æä¾›æœ‰ç›Šæ”¯æŒï¼Œä½†å…¶æ•°å­—è¯„åˆ†ä¸äººç±»è¯„åˆ†ä¹‹é—´ç¼ºä¹ä¸€è‡´æ€§ã€‚è¯¥æœ€ç»ˆé—®å·é€šè¿‡èšç„¦ç”¨æˆ·æ„å›¾ã€æ–‡æœ¬ç»“æ„å’Œä¿¡æ¯å¯æ ¸å®æ€§ï¼Œæœ‰æ•ˆæ‰©å±•äº†ç°æœ‰çš„è¯„ä¼°æ¡†æ¶ï¼Œä¸ºRAGç³»ç»Ÿçš„Human-AIåä½œè¯„ä¼°æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.26205v1",
      "published_date": "2025-09-30 13:08:33 UTC",
      "updated_date": "2025-09-30 13:08:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:35:30.693033+00:00"
    },
    {
      "arxiv_id": "2509.26201v1",
      "title": "LLM Agents for Knowledge Discovery in Atomic Layer Processing",
      "title_zh": "ç”¨äºåŸå­å±‚å·¥è‰ºçŸ¥è¯†å‘ç°çš„ LLM æ™ºèƒ½ä½“",
      "authors": [
        "Andreas Werbrouck",
        "Marshall B. Lindsay",
        "Matthew Maschmann",
        "Matthias J. Young"
      ],
      "abstract": "Large Language Models (LLMs) have garnered significant attention for several years now. Recently, their use as independently reasoning agents has been proposed. In this work, we test the potential of such agents for knowledge discovery in materials science. We repurpose LangGraph's tool functionality to supply agents with a black box function to interrogate. In contrast to process optimization or performing specific, user-defined tasks, knowledge discovery consists of freely exploring the system, posing and verifying statements about the behavior of this black box, with the sole objective of generating and verifying generalizable statements. We provide proof of concept for this approach through a children's parlor game, demonstrating the role of trial-and-error and persistence in knowledge discovery, and the strong path-dependence of results. We then apply the same strategy to show that LLM agents can explore, discover, and exploit diverse chemical interactions in an advanced Atomic Layer Processing reactor simulation using intentionally limited probe capabilities without explicit instructions.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) ä½œä¸ºç‹¬ç«‹æ¨ç†æ™ºèƒ½ä½“åœ¨ææ–™ç§‘å­¦çŸ¥è¯†å‘ç° (Knowledge Discovery) ä¸­çš„æ½œåŠ›ã€‚ä¸ä¼ ç»Ÿçš„æµç¨‹ä¼˜åŒ–æˆ–æ‰§è¡Œç‰¹å®šä»»åŠ¡ä¸åŒï¼Œè¯¥æ–¹æ³•åˆ©ç”¨ LangGraph çš„å·¥å…·åŠŸèƒ½ä¸ºæ™ºèƒ½ä½“æä¾›é»‘ç›’æ¥å£ï¼Œä½¿å…¶èƒ½å¤Ÿé€šè¿‡è‡ªç”±æ¢ç´¢ç³»ç»Ÿæ¥ç”Ÿæˆå¹¶éªŒè¯å…·æœ‰æ™®é€‚æ€§çš„ç§‘å­¦é™ˆè¿°ã€‚ç ”ç©¶é¦–å…ˆé€šè¿‡æ¸¸æˆå®éªŒå±•ç¤ºäº†è¯•é”™ (trial-and-error) å’ŒåšæŒåœ¨çŸ¥è¯†å‘ç°ä¸­çš„å…³é”®ä½œç”¨ï¼Œå¹¶æ­ç¤ºäº†å‘ç°ç»“æœå…·æœ‰è¾ƒå¼ºçš„è·¯å¾„ä¾èµ–æ€§ã€‚éšåï¼Œè¯¥ç­–ç•¥è¢«åº”ç”¨äºé«˜çº§åŸå­å±‚å¤„ç† (Atomic Layer Processing) ååº”å™¨æ¨¡æ‹Ÿä¸­ï¼Œè¯æ˜äº† LLM æ™ºèƒ½ä½“åœ¨æ¢æµ‹èƒ½åŠ›å—é™ä¸”ç¼ºä¹æ˜¾å¼æŒ‡ä»¤çš„æƒ…å†µä¸‹ï¼Œä¾ç„¶èƒ½å¤Ÿè‡ªä¸»æ¢ç´¢ã€å‘ç°å¹¶åˆ©ç”¨å¤æ‚çš„åŒ–å­¦ç›¸äº’ä½œç”¨ã€‚è¿™é¡¹å·¥ä½œä¸ºåˆ©ç”¨è‡ªä¸»æ™ºèƒ½ä½“é©±åŠ¨ç§‘å­¦æ¢ç´¢å’ŒåŠ é€Ÿææ–™ç§‘å­¦é¢†åŸŸçš„å‘ç°æä¾›äº†é‡è¦çš„æ¦‚å¿µéªŒè¯ã€‚",
      "categories": [
        "cs.AI",
        "cond-mat.mes-hall",
        "cond-mat.mtrl-sci"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted submission to the AI4MAT workshop@NEURIPS 2025. As submitted, except author names added",
      "pdf_url": "https://arxiv.org/pdf/2509.26201v1",
      "published_date": "2025-09-30 13:01:44 UTC",
      "updated_date": "2025-09-30 13:01:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:35:38.293355+00:00"
    },
    {
      "arxiv_id": "2509.26200v1",
      "title": "Toward an Unbiased Collective Memory for Efficient LLM-Based Agentic 6G Cross-Domain Management",
      "title_zh": "é¢å‘é«˜æ•ˆ LLM æ™ºèƒ½ä½“åŒ– 6G è·¨åŸŸç®¡ç†çš„æ— åé›†ä½“è®°å¿†",
      "authors": [
        "Hatim Chergui",
        "Miguel Catalan Cid",
        "Pouria Sayyad Khodashenas",
        "Daniel Camps Mur",
        "Christos Verikoukis"
      ],
      "abstract": "This paper introduces a novel framework for proactive cross-domain resource orchestration in 6G RAN-Edge networks, featuring large language model (LLM)-augmented agents. The system comprises specialized RAN (energy efficiency) and Edge (latency assurance) agents that engage in iterative negotiation, supported by advanced reasoning and planning capabilities. Agents dynamically interact with a digital twin (DT) to test their proposals and leverage a long-term collective memory where their joint successful and failed agreements along with the related network contexts are distilled into strategies to either follow or avoid and subsequently stored. Given that agents are subject to a plethora of cognitive distortions when retrieving those past experiences -- such as primacy, recency, confirmation and availability biases -- we propose in this work a novel unbiased memory design (A reusable mockup version of the unbiased memory source code is available for non-commercial use at https://github.com/HatimChergui/unbiased-collective-memory). featuring (i) semantic retrieval of past strategies via Jaccard similarity; (ii) learning from failures through amplified weighting of SLA violations and mandatory inclusion of failed negotiation cases to mitigate confirmation bias; (iii) diversity enforcement to minimize availability bias and (iv) recency and primacy weighting with slow decay to counteract temporal biases. Evaluation results showcase the impact of existing biases and how the unbiased memory allows to tackle them by learning from both successful and failed strategies, either present or old, resulting in $\\times 4.5$ and $\\times 3.5$ reductions of unresolved negotiations compared to non-memory and vanilla memory baselines, respectively, while totally mitigating SLA violations as well as improving latency and energy saving distributions.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹6Gæ— çº¿æ¥å…¥ç½‘-è¾¹ç¼˜(RAN-Edge)ç½‘ç»œçš„ä¸»åŠ¨è·¨åŸŸèµ„æºç¼–æ’é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLM)å¢å¼ºå‹æ™ºèƒ½ä½“çš„æ–°å‹æ¡†æ¶ã€‚ç³»ç»Ÿç”±ä¸“é—¨è´Ÿè´£èƒ½æºæ•ˆç‡çš„æ— çº¿æ¥å…¥ç½‘(RAN)æ™ºèƒ½ä½“å’Œè´Ÿè´£å»¶è¿Ÿä¿éšœçš„è¾¹ç¼˜(Edge)æ™ºèƒ½ä½“ç»„æˆï¼Œé€šè¿‡è¿­ä»£åå•†åŠæ•°å­—å­ªç”Ÿ(DT)éªŒè¯æ¥å®ç°èµ„æºåŠ¨æ€ä¼˜åŒ–ã€‚ç ”ç©¶æ ¸å¿ƒåœ¨äºå¼•å…¥äº†é•¿æœŸé›†ä½“è®°å¿†(Collective Memory)æœºåˆ¶ï¼Œå¹¶é’ˆå¯¹æ™ºèƒ½ä½“åœ¨æ£€ç´¢å†å²ç»éªŒæ—¶å¯èƒ½å‡ºç°çš„é¦–å› ã€è¿‘å› ã€ç¡®è®¤å’Œå¯ç”¨æ€§åå·®ï¼Œæå‡ºäº†ä¸€ç§æ— åè§è®°å¿†è®¾è®¡ã€‚è¯¥è®¾è®¡åˆ©ç”¨Jaccardç›¸ä¼¼åº¦è¿›è¡Œè¯­ä¹‰æ£€ç´¢ï¼Œé€šè¿‡æ”¾å¤§SLAè¿è§„æƒé‡ã€å¼ºåˆ¶åŒ…å«å¤±è´¥æ¡ˆä¾‹åŠå¤šæ ·æ€§å¢å¼ºç­‰æ‰‹æ®µï¼Œç¡®ä¿æ™ºèƒ½ä½“èƒ½ä»æˆåŠŸä¸å¤±è´¥ä¸­å¹³è¡¡å­¦ä¹ å¹¶å…‹æœæ—¶é—´åå·®ã€‚è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ¡ˆç›¸æ¯”æ— è®°å¿†å’Œæ™®é€šè®°å¿†åŸºå‡†ï¼Œå°†æœªè§£å†³çš„åå•†åˆ†åˆ«å‡å°‘äº†4.5å€å’Œ3.5å€ï¼Œå¹¶åœ¨å®Œå…¨æ¶ˆé™¤SLAè¿è§„çš„åŒæ—¶ï¼Œæ˜¾è‘—æå‡äº†ç½‘ç»œå»¶è¿Ÿè¡¨ç°å’ŒèŠ‚èƒ½æ•ˆç‡ã€‚",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "12 pages, 8 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.26200v1",
      "published_date": "2025-09-30 12:57:11 UTC",
      "updated_date": "2025-09-30 12:57:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:35:34.001167+00:00"
    },
    {
      "arxiv_id": "2509.26187v1",
      "title": "Optimizing Indoor Environmental Quality in Smart Buildings Using Deep Learning",
      "title_zh": "åŸºäºæ·±åº¦å­¦ä¹ çš„æ™ºèƒ½å»ºç­‘å®¤å†…ç¯å¢ƒå“è´¨ä¼˜åŒ–",
      "authors": [
        "Youssef Sabiri",
        "Walid Houmaidi",
        "Aaya Bougrine",
        "Salmane El Mansour Billah"
      ],
      "abstract": "Ensuring optimal Indoor Environmental Quality (IEQ) is vital for occupant health and productivity, yet it often comes at a high energy cost in conventional Heating, Ventilation, and Air Conditioning (HVAC) systems. This paper proposes a deep learning driven approach to proactively manage IEQ parameters specifically CO2 concentration, temperature, and humidity while balancing building energy efficiency. Leveraging the ROBOD dataset collected from a net-zero energy academic building, we benchmark three architectures--Long Short-Term Memory (LSTM), Gated Recurrent Units (GRU), and a hybrid Convolutional Neural Network LSTM (CNN-LSTM)--to forecast IEQ variables across various time horizons. Our results show that GRU achieves the best short-term prediction accuracy with lower computational overhead, whereas CNN-LSTM excels in extracting dominant features for extended forecasting windows. Meanwhile, LSTM offers robust long-range temporal modeling. The comparative analysis highlights that prediction reliability depends on data resolution, sensor placement, and fluctuating occupancy conditions. These findings provide actionable insights for intelligent Building Management Systems (BMS) to implement predictive HVAC control, thereby reducing energy consumption and enhancing occupant comfort in real-world building operations.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åˆ©ç”¨æ·±åº¦å­¦ä¹ (Deep Learning)ä¼˜åŒ–æ™ºèƒ½å»ºç­‘å®¤å†…ç¯å¢ƒè´¨é‡(IEQ)çš„æ–¹æ³•ï¼Œæ—¨åœ¨å¹³è¡¡CO2æµ“åº¦ã€æ¸©åº¦å’Œæ¹¿åº¦ç­‰å…³é”®å‚æ•°ä¸ç©ºè°ƒç³»ç»Ÿ(HVAC)çš„èƒ½æºæ•ˆç‡ã€‚é€šè¿‡ä½¿ç”¨æ¥è‡ªå‡€é›¶èƒ½è€—å»ºç­‘çš„ROBODæ•°æ®é›†ï¼Œç ”ç©¶å¯¹æ¯”äº†é•¿çŸ­æœŸè®°å¿†ç½‘ç»œ(LSTM)ã€é—¨æ§å¾ªç¯å•å…ƒ(GRU)ä»¥åŠæ··åˆå·ç§¯ç¥ç»ç½‘ç»œ(CNN-LSTM)ä¸‰ç§æ¶æ„åœ¨ä¸åŒæ—¶é—´è·¨åº¦ä¸‹çš„é¢„æµ‹è¡¨ç°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒGRUåœ¨çŸ­æœŸé¢„æµ‹ä¸­è¡¨ç°å‡ºæœ€é«˜çš„å‡†ç¡®æ€§ä¸”è®¡ç®—å¼€é”€è¾ƒä½ï¼Œè€ŒCNN-LSTMåœ¨é•¿å‘¨æœŸé¢„æµ‹çš„ç‰¹å¾æå–æ–¹é¢æ›´å…·ä¼˜åŠ¿ï¼ŒLSTMåˆ™åœ¨é•¿ç¨‹æ—¶é—´å»ºæ¨¡ä¸­å±•ç°äº†ç¨³å¥æ€§ã€‚ç ”ç©¶è¿˜å‘ç°é¢„æµ‹å¯é æ€§ä¸æ•°æ®åˆ†è¾¨ç‡ã€ä¼ æ„Ÿå™¨å¸ƒå±€åŠäººå‘˜å ç”¨æ³¢åŠ¨å¯†åˆ‡ç›¸å…³ã€‚è¿™äº›å‘ç°ä¸ºæ™ºèƒ½å»ºç­‘ç®¡ç†ç³»ç»Ÿ(BMS)å®æ–½é¢„æµ‹æ€§æ§åˆ¶æä¾›äº†é‡è¦è§è§£ï¼Œæœ‰åŠ©äºåœ¨å®é™…è¿è¥ä¸­æœ‰æ•ˆé™ä½èƒ½æ•ˆæŸè€—å¹¶æå‡å±…ä½èˆ’é€‚åº¦ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 4 figures, 1 table. Accepted and presented at the 5th International Conference on Digital Technologies and Applications (ICDTA 2025), April 17-18, 2025, Al Akhawayn University, Ifrane, Morocco",
      "pdf_url": "https://arxiv.org/pdf/2509.26187v1",
      "published_date": "2025-09-30 12:42:34 UTC",
      "updated_date": "2025-09-30 12:42:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:35:43.284820+00:00"
    },
    {
      "arxiv_id": "2509.26185v1",
      "title": "AttriGen: Automated Multi-Attribute Annotation for Blood Cell Datasets",
      "title_zh": "AttriGenï¼šè¡€ç»†èƒæ•°æ®é›†çš„è‡ªåŠ¨åŒ–å¤šå±æ€§æ ‡æ³¨",
      "authors": [
        "Walid Houmaidi",
        "Youssef Sabiri",
        "Fatima Zahra Iguenfer",
        "Amine Abouaomar"
      ],
      "abstract": "We introduce AttriGen, a novel framework for automated, fine-grained multi-attribute annotation in computer vision, with a particular focus on cell microscopy where multi-attribute classification remains underrepresented compared to traditional cell type categorization. Using two complementary datasets: the Peripheral Blood Cell (PBC) dataset containing eight distinct cell types and the WBC Attribute Dataset (WBCAtt) that contains their corresponding 11 morphological attributes, we propose a dual-model architecture that combines a CNN for cell type classification, as well as a Vision Transformer (ViT) for multi-attribute classification achieving a new benchmark of 94.62\\% accuracy. Our experiments demonstrate that AttriGen significantly enhances model interpretability and offers substantial time and cost efficiency relative to conventional full-scale human annotation. Thus, our framework establishes a new paradigm that can be extended to other computer vision classification tasks by effectively automating the expansion of multi-attribute labels.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† AttriGenï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨å®ç°è®¡ç®—æœºè§†è§‰ä¸­è‡ªåŠ¨åŒ–ã€ç»†ç²’åº¦å¤šå±æ€§æ ‡æ³¨(Multi-Attribute Annotation)çš„æ–°å‹æ¡†æ¶ï¼Œç‰¹åˆ«å…³æ³¨äºå¤šå±æ€§åˆ†ç±»ç ”ç©¶ç›¸å¯¹è¾ƒå°‘çš„ç»†èƒæ˜¾å¾®é•œé¢†åŸŸã€‚è¯¥æ¡†æ¶ç»“åˆäº†åŒ…å«8ç§ç»†èƒç±»å‹çš„å¤–å‘¨è¡€ç»†èƒ(PBC)æ•°æ®é›†ä»¥åŠåŒ…å«11ç§ç›¸åº”å½¢æ€ç‰¹å¾çš„ WBC Attribute Dataset (WBCAtt) æ•°æ®é›†ï¼Œæå‡ºäº†ä¸€ç§åŒæ¨¡å‹æ¶æ„(Dual-model Architecture)ã€‚è¯¥æ¶æ„é€šè¿‡ç»“åˆç”¨äºç»†èƒç±»å‹åˆ†ç±»çš„ CNN å’Œç”¨äºå¤šå±æ€§åˆ†ç±»çš„ Vision Transformer (ViT)ï¼Œåœ¨å®éªŒä¸­è¾¾åˆ°äº† 94.62% çš„å‡†ç¡®ç‡ï¼Œåˆ›ä¸‹äº†æ–°çš„æ€§èƒ½åŸºå‡†(Benchmark)ã€‚ç›¸æ¯”äºä¼ ç»Ÿçš„äººå·¥å…¨é‡æ ‡æ³¨ï¼ŒAttriGen æ˜¾è‘—å¢å¼ºäº†æ¨¡å‹çš„å¯è§£é‡Šæ€§(Interpretability)ï¼Œå¹¶åœ¨æ—¶é—´å’Œæˆæœ¬æ•ˆç‡ä¸Šå…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚è¯¥ç ”ç©¶ä¸ºæœ‰æ•ˆè‡ªåŠ¨åŒ–æ‰©å±•å¤šå±æ€§æ ‡ç­¾ç¡®ç«‹äº†æ–°èŒƒå¼ï¼Œå¹¶å…·æœ‰æ¨å¹¿è‡³å…¶ä»–è®¡ç®—æœºè§†è§‰åˆ†ç±»ä»»åŠ¡çš„æ½œåŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages, 4 figures, 3 tables. Accepted at the 12th International Conference on Wireless Networks and Mobile Communications 2025 (WINCOM 2025)",
      "pdf_url": "https://arxiv.org/pdf/2509.26185v1",
      "published_date": "2025-09-30 12:42:28 UTC",
      "updated_date": "2025-09-30 12:42:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:35:42.887007+00:00"
    },
    {
      "arxiv_id": "2509.26184v4",
      "title": "Auto-ARGUE: LLM-Based Report Generation Evaluation",
      "title_zh": "Auto-ARGUEï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„æŠ¥å‘Šç”Ÿæˆè¯„ä¼°",
      "authors": [
        "William Walden",
        "Marc Mason",
        "Orion Weller",
        "Laura Dietz",
        "John Conroy",
        "Neil Molino",
        "Hannah Recknor",
        "Bryan Li",
        "Gabrielle Kaili-May Liu",
        "Yu Hou",
        "Dawn Lawrie",
        "James Mayfield",
        "Eugene Yang"
      ],
      "abstract": "Generation of long-form, citation-backed reports is a primary use case for retrieval augmented generation (RAG) systems. While open-source evaluation tools exist for various RAG tasks, ones tailored to report generation (RG) are lacking. Accordingly, we introduce Auto-ARGUE, a robust LLM-based implementation of the recently proposed ARGUE framework for RG evaluation. We present analysis of Auto-ARGUE on the RG pilot task from the TREC 2024 NeuCLIR track, showing good system-level correlations with human judgments. We further release a web app for visualization of Auto-ARGUE outputs.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)ç³»ç»Ÿä¸­é•¿ç¯‡ã€å¸¦å¼•è¯æŠ¥å‘Šç”Ÿæˆ(RG)è¯„ä¼°å·¥å…·åŒ®ä¹çš„é—®é¢˜ï¼Œæå‡ºäº†åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLM)çš„è¯„ä¼°æ¡†æ¶Auto-ARGUEã€‚Auto-ARGUEæ˜¯è¿‘æœŸæå‡ºçš„ARGUEæ¡†æ¶çš„ç¨³å¥å®ç°ï¼Œæ—¨åœ¨æä¾›é’ˆå¯¹æŠ¥å‘Šç”Ÿæˆä»»åŠ¡çš„è‡ªåŠ¨åŒ–è¯„ä»·ã€‚é€šè¿‡åœ¨TREC 2024 NeuCLIRèµ›é“çš„RGè¯•ç‚¹ä»»åŠ¡ä¸Šè¿›è¡Œå®éªŒåˆ†æï¼Œç»“æœè¡¨æ˜Auto-ARGUEåœ¨ç³»ç»Ÿå±‚é¢ä¸Šä¸äººç±»è¯„åˆ¤å…·æœ‰è‰¯å¥½çš„ç›¸å…³æ€§ã€‚æ­¤å¤–ï¼Œç ”ç©¶å›¢é˜Ÿè¿˜å‘å¸ƒäº†ä¸€ä¸ªé…å¥—çš„Webåº”ç”¨ç¨‹åºï¼Œç”¨äºç›´è§‚å±•ç¤ºAuto-ARGUEçš„è¯„ä¼°è¾“å‡ºç»“æœï¼Œä¸ºè¯¥é¢†åŸŸçš„ç³»ç»Ÿæ€§èƒ½è¯„ä¼°æä¾›äº†æœ‰æ•ˆçš„å¼€æºå·¥å…·ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.26184v4",
      "published_date": "2025-09-30 12:41:11 UTC",
      "updated_date": "2025-10-17 13:06:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:35:57.068668+00:00"
    },
    {
      "arxiv_id": "2509.26167v1",
      "title": "'Too much alignment; not enough culture': Re-balancing cultural alignment practices in LLMs",
      "title_zh": "â€œå¯¹é½æœ‰ä½™ï¼Œæ–‡åŒ–ä¸è¶³â€ï¼šå¤§è¯­è¨€æ¨¡å‹æ–‡åŒ–å¯¹é½å®è·µçš„å†å¹³è¡¡",
      "authors": [
        "Eric J. W. Orlowski",
        "Hakim Norhashim",
        "Tristan Koh Ly Wey"
      ],
      "abstract": "While cultural alignment has increasingly become a focal point within AI research, current approaches relying predominantly on quantitative benchmarks and simplistic proxies fail to capture the deeply nuanced and context-dependent nature of human cultures. Existing alignment practices typically reduce culture to static demographic categories or superficial cultural facts, thereby sidestepping critical questions about what it truly means to be culturally aligned. This paper argues for a fundamental shift towards integrating interpretive qualitative approaches drawn from social sciences into AI alignment practices, specifically in the context of Large Language Models (LLMs). Drawing inspiration from Clifford Geertz's concept of \"thick description,\" we propose that AI systems must produce outputs that reflect deeper cultural meanings--what we term \"thick outputs\"-grounded firmly in user-provided context and intent. We outline three necessary conditions for successful cultural alignment: sufficiently scoped cultural representations, the capacity for nuanced outputs, and the anchoring of outputs in the cultural contexts implied within prompts. Finally, we call for cross-disciplinary collaboration and the adoption of qualitative, ethnographic evaluation methods as vital steps toward developing AI systems that are genuinely culturally sensitive, ethically responsible, and reflective of human complexity.",
      "tldr_zh": "è¯¥ç ”ç©¶æŒ‡å‡ºå½“å‰å¤§è¯­è¨€æ¨¡å‹(LLMs)çš„æ–‡åŒ–å¯¹é½(cultural alignment)å®è·µä¸»è¦ä¾èµ–å®šé‡åŸºå‡†å’Œç®€å•çš„ä»£ç†æŒ‡æ ‡ï¼Œå¿½ç•¥äº†äººç±»æ–‡åŒ–æ·±å±‚ä¸”å…·æœ‰æƒ…å¢ƒä¾èµ–æ€§çš„ç‰¹å¾ã€‚è®ºæ–‡ä¸»å¼ å°†ç¤¾ä¼šç§‘å­¦ä¸­çš„å®šæ€§è§£é‡Šæ–¹æ³•å¼•å…¥AIå¯¹é½ï¼Œç‰¹åˆ«æ˜¯å€Ÿé‰´Clifford Geertzçš„â€œåšæè¿°â€(thick description)æ¦‚å¿µã€‚ç ”ç©¶è€…æå‡ºAIç³»ç»Ÿåº”ç”Ÿæˆåæ˜ æ·±å±‚æ–‡åŒ–æ„ä¹‰çš„â€œåšè¾“å‡ºâ€(thick outputs)ï¼Œå¹¶ä½¿å…¶ç‰¢å›ºæ¤æ ¹äºç”¨æˆ·æä¾›çš„æƒ…å¢ƒå’Œæ„å›¾ä¹‹ä¸­ã€‚ä¸ºå®ç°æˆåŠŸçš„æ–‡åŒ–å¯¹é½ï¼Œè®ºæ–‡æ˜ç¡®äº†ä¸‰é¡¹å¿…è¦æ¡ä»¶ï¼šå……è¶³çš„æ–‡åŒ–è¡¨å¾èŒƒå›´ã€ç”Ÿæˆç»†å¾®å·®åˆ«è¾“å‡ºçš„èƒ½åŠ›ï¼Œä»¥åŠå°†è¾“å‡ºé”šå®šåœ¨æç¤ºè¯­æ‰€éšå«çš„æ–‡åŒ–èƒŒæ™¯ä¸­ã€‚æœ€åï¼Œè¯¥ç ”ç©¶å‘¼åå¼€å±•è·¨å­¦ç§‘åˆä½œå¹¶é‡‡ç”¨å®šæ€§æ°‘æ—å¿—(ethnographic)è¯„ä¼°æ–¹æ³•ï¼Œä»¥å¼€å‘å‡ºçœŸæ­£å…·æœ‰æ–‡åŒ–æ•æ„Ÿæ€§ã€ä¼¦ç†è´£ä»»æ„Ÿä¸”èƒ½åæ˜ äººç±»å¤æ‚æ€§çš„AIç³»ç»Ÿã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, no figures",
      "pdf_url": "https://arxiv.org/pdf/2509.26167v1",
      "published_date": "2025-09-30 12:22:53 UTC",
      "updated_date": "2025-09-30 12:22:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:36:03.070350+00:00"
    },
    {
      "arxiv_id": "2509.26161v1",
      "title": "90% Faster, 100% Code-Free: MLLM-Driven Zero-Code 3D Game Development",
      "title_zh": "æé€Ÿ 90%ã€100% æ— ä»£ç ï¼šMLLM é©±åŠ¨çš„é›¶ä»£ç  3D æ¸¸æˆå¼€å‘",
      "authors": [
        "Runxin Yang",
        "Yuxuan Wan",
        "Shuqing Li",
        "Michael R. Lyu"
      ],
      "abstract": "Developing 3D games requires specialized expertise across multiple domains, including programming, 3D modeling, and engine configuration, which limits access to millions of potential creators. Recently, researchers have begun to explore automated game development. However, existing approaches face three primary challenges: (1) limited scope to 2D content generation or isolated code snippets; (2) requirement for manual integration of generated components into game engines; and (3) poor performance on handling interactive game logic and state management. While Multimodal Large Language Models (MLLMs) demonstrate potential capabilities to ease the game generation task, a critical gap still remains in translating these outputs into production-ready, executable game projects based on game engines such as Unity and Unreal Engine.\n  To bridge the gap, this paper introduces UniGen, the first end-to-end coordinated multi-agent framework that automates zero-coding development of runnable 3D games from natural language requirements. Specifically, UniGen uses a Planning Agent that interprets user requirements into structured blueprints and engineered logic descriptions; after which a Generation Agent produces executable C# scripts; then an Automation Agent handles engine-specific component binding and scene construction; and lastly a Debugging Agent provides real-time error correction through conversational interaction. We evaluated UniGen on three distinct game prototypes. Results demonstrate that UniGen not only democratizes game creation by requiring no coding from the user, but also reduces development time by 91.4%. We release UniGen at https://github.com/yxwan123/UniGen. A video demonstration is available at https://www.youtube.com/watch?v=xyJjFfnxUx0.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ 3D æ¸¸æˆå¼€å‘åœ¨ç¼–ç¨‹ã€å»ºæ¨¡å’Œå¼•æ“é…ç½®æ–¹é¢çš„é«˜é—¨æ§›æŒ‘æˆ˜ï¼Œæå‡ºäº† UniGenï¼Œè¿™æ˜¯é¦–ä¸ªèƒ½å¤Ÿæ ¹æ®è‡ªç„¶è¯­è¨€éœ€æ±‚å®ç°é›¶ä»£ç å¼€å‘å¯è¿è¡Œ 3D æ¸¸æˆçš„ç«¯åˆ°ç«¯åè°ƒå¤šæ™ºèƒ½ä½“æ¡†æ¶ã€‚UniGen çš„æ ¸å¿ƒæµç¨‹é¦–å…ˆç”± Planning Agent å°†ç”¨æˆ·éœ€æ±‚è½¬åŒ–ä¸ºç»“æ„åŒ–è“å›¾ï¼Œéšååˆ©ç”¨ Generation Agent ç”Ÿæˆå¯æ‰§è¡Œçš„ C# è„šæœ¬ã€‚æ¥ç€ï¼ŒAutomation Agent è´Ÿè´£å¤„ç†ç‰¹å®šå¼•æ“çš„ç»„ä»¶ç»‘å®šä¸åœºæ™¯æ„å»ºï¼Œå¹¶ç”± Debugging Agent é€šè¿‡å®æ—¶äº¤äº’è¿›è¡Œé”™è¯¯ä¿®æ­£ã€‚åœ¨ä¸‰ä¸ªä¸åŒæ¸¸æˆåŸå‹çš„è¯„ä¼°ä¸­ï¼ŒUniGen ä¸ä»…å®ç°äº† 100% çš„æ— ä»£ç å¼€å‘ï¼Œè¿˜æ˜¾è‘—å‡å°‘äº† 91.4% çš„å¼€å‘æ—¶é—´ã€‚è¯¥æ¡†æ¶æœ‰æ•ˆå¼¥è¡¥äº†å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ (MLLMs) ä¸ Unity æˆ– Unreal Engine ç­‰ç”Ÿäº§çº§æ¸¸æˆå¼•æ“ä¹‹é—´çš„æŠ€æœ¯é¸¿æ²Ÿï¼Œä¸ºæ¨åŠ¨æ¸¸æˆåˆ›ä½œçš„æ°‘ä¸»åŒ–æä¾›äº†æ–°æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.26161v1",
      "published_date": "2025-09-30 12:14:56 UTC",
      "updated_date": "2025-09-30 12:14:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:36:12.475155+00:00"
    },
    {
      "arxiv_id": "2510.00088v1",
      "title": "Judging by Appearances? Auditing and Intervening Vision-Language Models for Bail Prediction",
      "title_zh": "ä»¥è²Œå–äººï¼Ÿä¿é‡Šé¢„æµ‹ä¸­è§†è§‰è¯­è¨€æ¨¡å‹çš„å®¡è®¡ä¸å¹²é¢„",
      "authors": [
        "Sagnik Basu",
        "Shubham Prakash",
        "Ashish Maruti Barge",
        "Siddharth D Jaiswal",
        "Abhisek Dash",
        "Saptarshi Ghosh",
        "Animesh Mukherjee"
      ],
      "abstract": "Large language models (LLMs) have been extensively used for legal judgment prediction tasks based on case reports and crime history. However, with a surge in the availability of large vision language models (VLMs), legal judgment prediction systems can now be made to leverage the images of the criminals in addition to the textual case reports/crime history. Applications built in this way could lead to inadvertent consequences and be used with malicious intent. In this work, we run an audit to investigate the efficiency of standalone VLMs in the bail decision prediction task. We observe that the performance is poor across multiple intersectional groups and models \\textit{wrongly deny bail to deserving individuals with very high confidence}. We design different intervention algorithms by first including legal precedents through a RAG pipeline and then fine-tuning the VLMs using innovative schemes. We demonstrate that these interventions substantially improve the performance of bail prediction. Our work paves the way for the design of smarter interventions on VLMs in the future, before they can be deployed for real-world legal judgment prediction.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨ä¿é‡Šé¢„æµ‹(bail prediction)ä»»åŠ¡ä¸­åˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡å‹(Vision-Language Models, VLMs)å¤„ç†ç½ªçŠ¯å›¾åƒåŠæ–‡æœ¬å†å²çš„æ½œåœ¨å½±å“ã€‚å®¡è®¡ç»“æœæ˜¾ç¤ºï¼Œç‹¬ç«‹è¿è¡Œçš„VLMsåœ¨å¤„ç†å¤šé‡äº¤å‰ç¾¤ä½“(intersectional groups)æ—¶è¡¨ç°æ¬ ä½³ï¼Œå¸¸ä»¥æé«˜ç½®ä¿¡åº¦é”™è¯¯åœ°æ‹’ç»ç¬¦åˆæ¡ä»¶çš„ä¿é‡Šç”³è¯·ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶å›¢é˜Ÿè®¾è®¡äº†ä¸¤ç§å¹²é¢„ç®—æ³•ï¼ŒåŒ…æ‹¬é€šè¿‡æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)æµç¨‹å¼•å…¥æ³•å¾‹å…ˆä¾‹(legal precedents)ï¼Œä»¥åŠé‡‡ç”¨åˆ›æ–°æ–¹æ¡ˆå¯¹VLMsè¿›è¡Œå¾®è°ƒ(fine-tuning)ã€‚å®éªŒè¯æ˜ï¼Œè¿™äº›å¹²é¢„æªæ–½æ˜¾è‘—æå‡äº†ä¿é‡Šé¢„æµ‹çš„æ€§èƒ½ã€‚è¯¥é¡¹å·¥ä½œä¸ä»…æ­ç¤ºäº†è§†è§‰åè§åœ¨æ³•å¾‹åˆ¤å†³ä¸­çš„é£é™©ï¼Œä¹Ÿä¸ºåœ¨å®é™…éƒ¨ç½²æ³•å¾‹æ™ºèƒ½ç³»ç»Ÿå‰è®¾è®¡æ›´ç²¾å‡†çš„å¹²é¢„æœºåˆ¶æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.00088v1",
      "published_date": "2025-09-30 12:11:45 UTC",
      "updated_date": "2025-09-30 12:11:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:36:06.372316+00:00"
    },
    {
      "arxiv_id": "2509.26158v1",
      "title": "Towards Continual Expansion of Data Coverage: Automatic Text-guided Edge-case Synthesis",
      "title_zh": "è¿ˆå‘æ•°æ®è¦†ç›–èŒƒå›´çš„æŒç»­æ‰©å±•ï¼šè‡ªåŠ¨æ–‡æœ¬å¼•å¯¼çš„æç«¯æ¡ˆä¾‹åˆæˆ",
      "authors": [
        "Kyeongryeol Go"
      ],
      "abstract": "The performance of deep neural networks is strongly influenced by the quality of their training data. However, mitigating dataset bias by manually curating challenging edge cases remains a major bottleneck. To address this, we propose an automated pipeline for text-guided edge-case synthesis. Our approach employs a Large Language Model, fine-tuned via preference learning, to rephrase image captions into diverse textual prompts that steer a Text-to-Image model toward generating difficult visual scenarios. Evaluated on the FishEye8K object detection benchmark, our method achieves superior robustness, surpassing both naive augmentation and manually engineered prompts. This work establishes a scalable framework that shifts data curation from manual effort to automated, targeted synthesis, offering a promising direction for developing more reliable and continuously improving AI systems. Code is available at https://github.com/gokyeongryeol/ATES.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ·±åº¦ç¥ç»ç½‘ç»œ(Deep Neural Networks)æ€§èƒ½å—é™äºè®­ç»ƒæ•°æ®è´¨é‡ä¸”æ‰‹åŠ¨æ”¶é›†è¾¹ç¼˜æ¡ˆä¾‹(edge cases)æ•ˆç‡ä½ä¸‹çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºATES(Automatic Text-guided Edge-case Synthesis)çš„è‡ªåŠ¨åŒ–æ–‡æœ¬å¼•å¯¼è¾¹ç¼˜æ¡ˆä¾‹åˆæˆæ¡†æ¶ã€‚è¯¥æ–¹æ³•åˆ©ç”¨ç»è¿‡åå¥½å­¦ä¹ (preference learning)å¾®è°ƒçš„å¤§è¯­è¨€æ¨¡å‹(Large Language Model)ï¼Œå°†å›¾åƒæ ‡é¢˜é‡æ„ä¸ºå¤šæ ·åŒ–çš„æ–‡æœ¬æç¤ºè¯(prompts)ï¼Œæ—¨åœ¨å¼•å¯¼æ–‡æœ¬ç”Ÿæˆå›¾åƒ(Text-to-Image)æ¨¡å‹åˆæˆå¤æ‚çš„è§†è§‰åœºæ™¯ã€‚åœ¨FishEye8Kç›®æ ‡æ£€æµ‹åŸºå‡†æµ‹è¯•ä¸­ï¼Œè¯¥æ–¹æ³•å±•ç°å‡ºä¼˜äºä¼ ç»Ÿæ•°æ®å¢å¼ºå’Œäººå·¥è®¾è®¡æç¤ºè¯çš„é²æ£’æ€§ã€‚è¿™ä¸€ç ”ç©¶é€šè¿‡å»ºç«‹å¯æ‰©å±•çš„è‡ªåŠ¨åŒ–æµæ°´çº¿ï¼Œå®ç°äº†ä»æ‰‹åŠ¨æ•°æ®æ•´ç†(data curation)å‘å®šå‘è‡ªåŠ¨åˆæˆçš„è½¬å˜ï¼Œä¸ºæ„å»ºæŒç»­å­¦ä¹ ä¸æ”¹è¿›çš„å¯ä¿¡äººå·¥æ™ºèƒ½ç³»ç»Ÿæä¾›äº†æ–°çš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "17 pages, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.26158v1",
      "published_date": "2025-09-30 12:11:25 UTC",
      "updated_date": "2025-09-30 12:11:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:36:14.083871+00:00"
    },
    {
      "arxiv_id": "2509.26157v1",
      "title": "EntroPE: Entropy-Guided Dynamic Patch Encoder for Time Series Forecasting",
      "title_zh": "EntroPEï¼šé¢å‘æ—¶é—´åºåˆ—é¢„æµ‹çš„ç†µå¼•å¯¼åŠ¨æ€åˆ†å—ç¼–ç å™¨",
      "authors": [
        "Sachith Abeywickrama",
        "Emadeldeen Eldele",
        "Min Wu",
        "Xiaoli Li",
        "Chau Yuen"
      ],
      "abstract": "Transformer-based models have significantly advanced time series forecasting, with patch-based input strategies offering efficiency and improved long-horizon modeling. Yet, existing approaches rely on temporally-agnostic patch construction, where arbitrary starting positions and fixed lengths fracture temporal coherence by splitting natural transitions across boundaries. This naive segmentation often disrupts short-term dependencies and weakens representation learning. In response, we propose EntroPE (Entropy-Guided Dynamic Patch Encoder), a novel, temporally informed framework that dynamically detects transition points via conditional entropy and dynamically places patch boundaries. This preserves temporal structure while retaining the computational benefits of patching. EntroPE consists of two key modules, namely an Entropy-based Dynamic Patcher (EDP) that applies information-theoretic criteria to locate natural temporal shifts and determine patch boundaries, and an Adaptive Patch Encoder (APE) that employs pooling and cross-attention to capture intra-patch dependencies and produce fixed-size latent representations. These embeddings are then processed by a global transformer to model inter-patch dynamics. Experiments across long-term forecasting benchmarks demonstrate that EntroPE improves both accuracy and efficiency, establishing entropy-guided dynamic patching as a promising new paradigm for time series modeling. Code is available at: https://github.com/Sachithx/EntroPE.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸºäº Transformer çš„æ—¶é—´åºåˆ—é¢„æµ‹æ¨¡å‹ä¸­å›ºå®šé•¿åº¦åˆ†ç‰‡ï¼ˆpatchingï¼‰ç­–ç•¥ç ´åæ—¶é—´ç›¸å¹²æ€§çš„é—®é¢˜ï¼Œæå‡ºäº† EntroPE (Entropy-Guided Dynamic Patch Encoder) æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡ä¸¤ä¸ªæ ¸å¿ƒæ¨¡å—å®ç°åŠ¨æ€ã€æ„ŸçŸ¥æ—¶é—´çš„åˆ‡åˆ†ï¼šåŸºäºç†µçš„åŠ¨æ€åˆ†ç‰‡å™¨ (Entropy-based Dynamic Patcher, EDP) åˆ©ç”¨ä¿¡æ¯è®ºå‡†åˆ™å®šä½è‡ªç„¶çš„æ—¶é—´è½¬æ¢ç‚¹å¹¶ç¡®å®šåˆ†ç‰‡è¾¹ç•Œï¼Œè€Œè‡ªé€‚åº”åˆ†ç‰‡ç¼–ç å™¨ (Adaptive Patch Encoder, APE) åˆ™ç»“åˆæ± åŒ–ä¸äº¤å‰æ³¨æ„åŠ›æœºåˆ¶æ•æ‰åˆ†ç‰‡å†…éƒ¨ä¾èµ–ï¼Œç”Ÿæˆå›ºå®šç»´åº¦çš„æ½œåœ¨è¡¨ç¤ºã€‚è¿™äº›åˆ†ç‰‡åµŒå…¥éšåç”±å…¨å±€ Transformer å¤„ç†ï¼Œä»¥æœ‰æ•ˆå»ºæ¨¡åˆ†ç‰‡é—´çš„åŠ¨æ€å…³è”ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒEntroPE åœ¨å¤šä¸ªé•¿æœŸé¢„æµ‹åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æå‡äº†é¢„æµ‹ç²¾åº¦ä¸è®¡ç®—æ•ˆç‡ã€‚è¯¥ç ”ç©¶ç¡®ç«‹äº†ç†µå¼•å¯¼çš„åŠ¨æ€åˆ†ç‰‡æŠ€æœ¯ä½œä¸ºæ—¶é—´åºåˆ—å»ºæ¨¡çš„ä¸€ç§é«˜æ•ˆæ–°èŒƒå¼ï¼Œå¹¶å·²åœ¨ GitHub å¼€æºç›¸å…³ä»£ç ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Preprint. Under Review",
      "pdf_url": "https://arxiv.org/pdf/2509.26157v1",
      "published_date": "2025-09-30 12:09:56 UTC",
      "updated_date": "2025-09-30 12:09:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:36:11.390011+00:00"
    },
    {
      "arxiv_id": "2509.26153v3",
      "title": "A Field Guide to Deploying AI Agents in Clinical Practice",
      "title_zh": "ä¸´åºŠå®è·µä¸­çš„ AI æ™ºèƒ½ä½“éƒ¨ç½²å®åŠ¡æŒ‡å—",
      "authors": [
        "Jack Gallifant",
        "Katherine C. Kellogg",
        "Matt Butler",
        "Amanda Centi",
        "Shan Chen",
        "Patrick F. Doyle",
        "Sayon Dutta",
        "Joyce Guo",
        "Matthew J. Hadfield",
        "Esther H. Kim",
        "David E. Kozono",
        "Hugo JWL Aerts",
        "Adam B. Landman",
        "Raymond H. Mak",
        "Rebecca G. Mishuris",
        "Tanna L. Nelson",
        "Guergana K. Savova",
        "Elad Sharon",
        "Benjamin C. Silverman",
        "Umit Topaloglu",
        "Jeremy L. Warner",
        "Danielle S. Bitterman"
      ],
      "abstract": "Large language models (LLMs) integrated into agent-driven workflows hold immense promise for healthcare, yet a significant gap exists between their potential and practical implementation within clinical settings. To address this, we present a practitioner-oriented field manual for deploying generative agents that use electronic health record (EHR) data. This guide is informed by our experience deploying the \"irAE-Agent\", an automated system to detect immune-related adverse events from clinical notes at Mass General Brigham, and by structured interviews with 21 clinicians, engineers, and informatics leaders involved in the project. Our analysis reveals a critical misalignment in clinical AI development: less than 20% of our effort was dedicated to prompt engineering and model development, while over 80% was consumed by the sociotechnical work of implementation. We distill this effort into five \"heavy lifts\": data integration, model validation, ensuring economic value, managing system drift, and governance. By providing actionable solutions for each of these challenges, this field manual shifts the focus from algorithmic development to the essential infrastructure and implementation work required to bridge the \"valley of death\" and successfully translate generative AI from pilot projects into routine clinical care.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Large language models (LLMs) é©±åŠ¨çš„æ™ºèƒ½ä½“å·¥ä½œæµåœ¨ä¸´åºŠå®è·µä¸­ä»æ½œåŠ›åˆ°è½åœ°çš„å·¨å¤§é¸¿æ²Ÿï¼Œæå‡ºäº†ä¸€ä¸ªé¢å‘ä»ä¸šè€…çš„ä¸´åºŠ AI éƒ¨ç½²æŒ‡å—ã€‚è¯¥æŒ‡å—åŸºäºåœ¨ Mass General Brigham éƒ¨ç½²ç”¨äºè‡ªåŠ¨æ£€æµ‹å…ç–«ç›¸å…³ä¸è‰¯äº‹ä»¶çš„ \"irAE-Agent\" ç³»ç»Ÿçš„å®é™…ç»éªŒï¼Œå¹¶ç»“åˆäº†å¯¹ 21 ä½ä¸“å®¶è¿›è¡Œçš„ç»“æ„åŒ–è®¿è°ˆã€‚ç ”ç©¶æ­ç¤ºäº†ä¸´åºŠ AI å¼€å‘ä¸­çš„å…³é”®é”™ä½ï¼Œå³ä»…æœ‰ä¸åˆ° 20% çš„ç²¾åŠ›ç”¨äº Prompt engineering å’Œæ¨¡å‹å¼€å‘ï¼Œè€Œè¶…è¿‡ 80% çš„å·¥ä½œèšç„¦äºç¤¾ä¼šæŠ€æœ¯æ€§çš„å®æ–½è¿‡ç¨‹ã€‚ä½œè€…å°†å…¶æ€»ç»“ä¸ºæ•°æ®é›†æˆ (Data integration)ã€æ¨¡å‹éªŒè¯ (Model validation)ã€ç¡®ç«‹ç»æµä»·å€¼ã€ç®¡ç†ç³»ç»Ÿæ¼‚ç§» (System drift) ä»¥åŠæ²»ç†äº”å¤§æ ¸å¿ƒä»»åŠ¡ã€‚é€šè¿‡æä¾›è¡ŒåŠ¨æ–¹æ¡ˆï¼Œè¯¥æ‰‹å†Œå°†é‡ç‚¹ä»ç®—æ³•ç ”å‘è½¬å‘åŸºç¡€è®¾æ–½ä¸å®æ–½å·¥ä½œï¼Œæ—¨åœ¨ååŠ©ç”Ÿæˆå¼ AI è·¨è¶Šâ€œæ­»äº¡è°·â€ï¼Œå®ç°ä»è¯•ç‚¹é¡¹ç›®å‘å¸¸è§„ä¸´åºŠæŠ¤ç†çš„æˆåŠŸè½¬åŒ–ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Under review. 7 Tables, 2 Figures",
      "pdf_url": "https://arxiv.org/pdf/2509.26153v3",
      "published_date": "2025-09-30 12:03:32 UTC",
      "updated_date": "2025-12-08 15:39:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:36:18.283923+00:00"
    },
    {
      "arxiv_id": "2509.26150v1",
      "title": "Bubble, Bubble, AI's Rumble: Why Global Financial Regulatory Incident Reporting is Our Shield Against Systemic Stumbles",
      "title_zh": "æ³¡æ²«ç¿»è…¾ï¼ŒAI å–§åš£ï¼šå…¨çƒé‡‘èç›‘ç®¡äº‹ä»¶æŠ¥å‘Šä¸ºä½•æ˜¯é˜²èŒƒç³»ç»Ÿæ€§é£é™©çš„åšå®ç›¾ç‰Œ",
      "authors": [
        "Anchal Gupta",
        "Gleb Pappyshev",
        "James T Kwok"
      ],
      "abstract": "\"Double, double toil and trouble; Fire burn and cauldron bubble.\" As Shakespeare's witches foretold chaos through cryptic prophecies, modern capital markets grapple with systemic risks concealed by opaque AI systems. According to IMF, the August 5, 2024, plunge in Japanese and U.S. equities can be linked to algorithmic trading yet ab-sent from existing AI incidents database exemplifies this transparency crisis. Current AI incident databases, reliant on crowdsourcing or news scraping, systematically over-look capital market anomalies, particularly in algorithmic and high-frequency trading. We address this critical gap by proposing a regulatory-grade global database that elegantly synthesises post-trade reporting frameworks with proven incident documentation models from healthcare and aviation. Our framework's temporal data omission technique masking timestamps while preserving percent-age-based metrics enables sophisticated cross-jurisdictional analysis of emerging risks while safeguarding confidential business information. Synthetic data validation (modelled after real life published incidents , sentiments, data) reveals compelling pat-terns: systemic risks transcending geographical boundaries, market manipulation clusters distinctly identifiable via K-means algorithms, and AI system typology exerting significantly greater influence on trading behaviour than geographical location, This tripartite solution empowers regulators with unprecedented cross-jurisdictional oversight, financial institutions with seamless compliance integration, and investors with critical visibility into previously obscured AI-driven vulnerabilities. We call for immediate action to strengthen risk management and foster resilience in AI-driven financial markets against the volatile \"cauldron\" of AI-driven systemic risks., promoting global financial stability through enhanced transparency and coordinated oversight.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç°ä»£èµ„æœ¬å¸‚åœºä¸­ AI ç³»ç»Ÿä¸é€æ˜å¸¦æ¥çš„ç³»ç»Ÿæ€§é£é™©ï¼ŒæŒ‡å‡ºç›®å‰çš„ AI äº‹ä»¶æ•°æ®åº“å› ä¾èµ–ä¼—åŒ…æˆ–æ–°é—»æŠ“å–ï¼Œå¾€å¾€å¿½ç•¥äº†ç®—æ³•äº¤æ˜“å’Œé«˜é¢‘äº¤æ˜“ä¸­çš„å¸‚åœºå¼‚å¸¸ã€‚ä¸ºå¼¥è¡¥è¿™ä¸€é€æ˜åº¦å±æœºï¼Œä½œè€…æå‡ºå»ºç«‹ä¸€ä¸ªç›‘ç®¡çº§çš„å…¨çƒ AI äº‹æ•…æ•°æ®åº“ï¼Œå°†äº¤æ˜“åæŠ¥å‘Šæ¡†æ¶ä¸åŒ»ç–—ã€èˆªç©ºé¢†åŸŸæˆç†Ÿçš„äº‹æ•…è®°å½•æ¨¡å‹ç›¸ç»“åˆã€‚è¯¥æ¡†æ¶é‡‡ç”¨äº†æ—¶é—´æ•°æ®çœç•¥æŠ€æœ¯(Temporal data omission technique)ï¼Œåœ¨ä¿æŠ¤å•†ä¸šç§˜å¯†çš„åŒæ—¶é€šè¿‡ä¿ç•™ç™¾åˆ†æ¯”æŒ‡æ ‡æ”¯æŒè·¨å¸æ³•ç®¡è¾–åŒºçš„é£é™©åˆ†æã€‚é€šè¿‡åˆæˆæ•°æ®éªŒè¯å¹¶åº”ç”¨ K-means ç®—æ³•ï¼Œç ”ç©¶è¯†åˆ«å‡ºäº†è·¨è¶Šåœ°ç†è¾¹ç•Œçš„ç³»ç»Ÿæ€§é£é™©å’Œå¸‚åœºæ“çºµé›†ç¾¤ã€‚ç ”ç©¶å‘ç°ï¼ŒAI ç³»ç»Ÿç±»å‹(AI system typology)å¯¹äº¤æ˜“è¡Œä¸ºçš„å½±å“æ˜¾è‘—é«˜äºåœ°ç†ä½ç½®ã€‚è¿™ä¸€æ–¹æ¡ˆä¸ºç›‘ç®¡æœºæ„æä¾›äº†å‰æ‰€æœªæœ‰çš„è·¨å¢ƒç›‘ç£èƒ½åŠ›ï¼Œå¹¶å¢å¼ºäº†é‡‘èæœºæ„çš„åˆè§„é›†æˆä¸æŠ•èµ„è€…çš„é£é™©å¯è§æ€§ï¼Œæ—¨åœ¨æå‡å…¨çƒé‡‘èå¸‚åœºçš„ç¨³å®šæ€§å’ŒæŠ—é£é™©éŸ§æ€§ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.26150v1",
      "published_date": "2025-09-30 12:01:25 UTC",
      "updated_date": "2025-09-30 12:01:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:36:26.490571+00:00"
    },
    {
      "arxiv_id": "2509.26145v1",
      "title": "LMILAtt: A Deep Learning Model for Depression Detection from Social Media Users Enhanced by Multi-Instance Learning Based on Attention Mechanism",
      "title_zh": "LMILAttï¼šåŸºäºæ³¨æ„åŠ›æœºåˆ¶å¤šç¤ºä¾‹å­¦ä¹ å¢å¼ºçš„ç¤¾äº¤åª’ä½“ç”¨æˆ·æŠ‘éƒæ£€æµ‹æ·±åº¦å­¦ä¹ æ¨¡å‹",
      "authors": [
        "Yukun Yang"
      ],
      "abstract": "Depression is a major global public health challenge and its early identification is crucial. Social media data provides a new perspective for depression detection, but existing methods face limitations such as insufficient accuracy, insufficient utilization of time series features, and high annotation costs. To this end, this study proposes the LMILAtt model, which innovatively integrates Long Short-Term Memory autoencoders and attention mechanisms: firstly, the temporal dynamic features of user tweets (such as depressive tendency evolution patterns) are extracted through unsupervised LSTM autoencoders. Secondly, the attention mechanism is used to dynamically weight key texts (such as early depression signals) and construct a multi-example learning architecture to improve the accuracy of user-level detection. Finally, the performance was verified on the WU3D dataset labeled by professional medicine. Experiments show that the model is significantly better than the baseline model in terms of accuracy, recall and F1 score. In addition, the weakly supervised learning strategy significantly reduces the cost of labeling and provides an efficient solution for large-scale social media depression screening.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† LMILAtt æ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³ç¤¾äº¤åª’ä½“æŠ‘éƒç—‡æ£€æµ‹ä¸­å­˜åœ¨çš„å‡†ç¡®æ€§ä¸è¶³ã€æ—¶åºç‰¹å¾åˆ©ç”¨ä¸å……åˆ†ä»¥åŠæ ‡æ³¨æˆæœ¬è¿‡é«˜ç­‰æŒ‘æˆ˜ã€‚æ¨¡å‹é¦–å…ˆé€šè¿‡æ— ç›‘ç£çš„ LSTM è‡ªåŠ¨ç¼–ç å™¨ (LSTM autoencoders) æå–ç”¨æˆ·æ¨æ–‡ä¸­çš„æ—¶é—´åŠ¨æ€ç‰¹å¾ï¼Œä»è€Œæœ‰æ•ˆæ•æ‰æŠ‘éƒå€¾å‘çš„æ¼”å˜æ¨¡å¼ã€‚æ¥ç€ï¼Œåˆ©ç”¨æ³¨æ„åŠ›æœºåˆ¶ (Attention Mechanism) å¯¹å…³é”®æ–‡æœ¬è¿›è¡ŒåŠ¨æ€åŠ æƒï¼Œå¹¶ç»“åˆå¤šç¤ºä¾‹å­¦ä¹  (Multi-Instance Learning) æ¶æ„æ¥ä¼˜åŒ–ç”¨æˆ·å±‚é¢çš„è¯†åˆ«ç²¾åº¦ã€‚ç ”ç©¶äººå‘˜åœ¨ä¸“ä¸šåŒ»å­¦æ ‡æ³¨çš„ WU3D æ•°æ®é›†ä¸Šè¿›è¡Œäº†éªŒè¯ï¼Œå®éªŒç»“æœæ˜¾ç¤ºè¯¥æ¨¡å‹åœ¨å‡†ç¡®ç‡ã€å¬å›ç‡å’Œ F1 åˆ†æ•° (F1 score) ä¸Šå‡æ˜¾è‘—ä¼˜äºç°æœ‰çš„åŸºçº¿æ¨¡å‹ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹é€šè¿‡å¼±ç›‘ç£å­¦ä¹  (Weakly supervised learning) ç­–ç•¥æœ‰æ•ˆé™ä½äº†æ•°æ®æ ‡æ³¨çš„æˆæœ¬ï¼Œä¸ºå¤§è§„æ¨¡ç¤¾äº¤åª’ä½“ç¯å¢ƒä¸‹çš„æŠ‘éƒç—‡æ—©æœŸç­›æŸ¥æä¾›äº†ä¸€ç§é«˜æ•ˆä¸”å®ç”¨çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.26145v1",
      "published_date": "2025-09-30 11:58:32 UTC",
      "updated_date": "2025-09-30 11:58:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:36:28.584923+00:00"
    },
    {
      "arxiv_id": "2509.26140v1",
      "title": "OWL: Geometry-Aware Spatial Reasoning for Audio Large Language Models",
      "title_zh": "OWLï¼šé¢å‘éŸ³é¢‘å¤§è¯­è¨€æ¨¡å‹çš„å‡ ä½•æ„ŸçŸ¥ç©ºé—´æ¨ç†",
      "authors": [
        "Subrata Biswas",
        "Mohammad Nur Hossain Khan",
        "Bashima Islam"
      ],
      "abstract": "Spatial reasoning is fundamental to auditory perception, yet current audio large language models (ALLMs) largely rely on unstructured binaural cues and single step inference. This limits both perceptual accuracy in direction and distance estimation and the capacity for interpretable reasoning. Recent work such as BAT demonstrates spatial QA with binaural audio, but its reliance on coarse categorical labels (left, right, up, down) and the absence of explicit geometric supervision constrain resolution and robustness. We introduce the $\\textbf{Spatial-Acoustic Geometry Encoder (SAGE}$), a geometry-aware audio encoder that aligns binaural acoustic features with 3D spatial structure using panoramic depth images and room-impulse responses at training time, while requiring only audio at inference. Building on this representation, we present $\\textbf{OWL}$, an ALLM that integrates $\\textbf{SAGE}$ with a spatially grounded chain-of-thought to rationalize over direction-of-arrivals (DoA) and distance estimates. Through curriculum learning from perceptual QA to multi-step reasoning, $\\textbf{OWL}$ supports o'clock-level azimuth and DoA estimation. To enable large-scale training and evaluation, we construct and release $\\textbf{BiDepth}$, a dataset of over one million QA pairs combining binaural audio with panoramic depth images and room impulse responses across both in-room and out-of-room scenarios. Across two benchmark datasets, our new $\\textbf{BiDepth}$ and the public SpatialSoundQA, $\\textbf{OWL}$ reduces mean DoA error by $\\textbf{11$^{\\circ}$}$ through $\\textbf{SAGE}$ and improves spatial reasoning QA accuracy by up to $\\textbf{25}$\\% over BAT.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†OWLï¼Œä¸€ç§å…·å¤‡å‡ ä½•æ„ŸçŸ¥èƒ½åŠ›çš„ç©ºé—´æ¨ç†éŸ³é¢‘å¤§è¯­è¨€æ¨¡å‹(ALLMs)ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ¨¡å‹åœ¨å£°æºæ–¹å‘å’Œè·ç¦»ä¼°ç®—ä¸­ç²¾åº¦ä¸è¶³ä¸”ç¼ºä¹å¯è§£é‡Šæ€§çš„é—®é¢˜ã€‚ç ”ç©¶å¼•å…¥äº†Spatial-Acoustic Geometry Encoder (SAGE)ï¼Œé€šè¿‡åœ¨è®­ç»ƒé˜¶æ®µå°†åŒè€³å£°å­¦ç‰¹å¾ä¸3Dç©ºé—´å‡ ä½•ç»“æ„å¯¹é½ï¼Œä½¿æ¨¡å‹åœ¨æ¨æ–­æ—¶ä»…å‡­éŸ³é¢‘å³å¯å®ç°é«˜ç²¾åº¦æ„ŸçŸ¥ã€‚OWLè¿›ä¸€æ­¥é›†æˆäº†ç©ºé—´è½åœ°çš„é“¾å¼æ€ç»´(Chain-of-Thought)æ¨ç†ï¼Œæ”¯æŒæ—¶é’Ÿçº§åˆ«çš„æ–¹ä½è§’å’ŒDoAä¼°è®¡ã€‚æ­¤å¤–ï¼Œç ”ç©¶è€…æ„å»ºå¹¶å‘å¸ƒäº†åŒ…å«ç™¾ä¸‡çº§é—®ç­”å¯¹çš„BiDepthæ•°æ®é›†ï¼Œæ¶µç›–äº†åŒè€³éŸ³é¢‘ã€å…¨æ™¯æ·±åº¦å›¾åƒå’Œæˆ¿é—´å†²æ¿€å“åº”ç­‰ä¸°å¯Œæ¨¡æ€ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒOWLé€šè¿‡SAGEå°†å¹³å‡DoAè¯¯å·®é™ä½äº†11Â°ï¼Œå¹¶åœ¨ç©ºé—´æ¨ç†é—®ç­”å‡†ç¡®ç‡ä¸Šæ¯”BATæ¨¡å‹æå‡äº†é«˜è¾¾25%ã€‚è¯¥å·¥ä½œé€šè¿‡å‡ ä½•æ„ŸçŸ¥ä¸å¤šæ­¥æ¨ç†çš„ç»“åˆï¼Œæ˜¾è‘—å¢å¼ºäº†éŸ³é¢‘æ¨¡å‹å¯¹å¤æ‚ç©ºé—´ç¯å¢ƒçš„ç†è§£èƒ½åŠ›ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.26140v1",
      "published_date": "2025-09-30 11:57:47 UTC",
      "updated_date": "2025-09-30 11:57:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:36:32.593915+00:00"
    },
    {
      "arxiv_id": "2509.26139v1",
      "title": "Leveraging AI modelling for FDS with Simvue: monitor and optimise for more sustainable simulations",
      "title_zh": "å€ŸåŠ©Simvueåˆ©ç”¨AIå»ºæ¨¡èµ‹èƒ½FDSï¼šé€šè¿‡ç›‘æµ‹ä¸ä¼˜åŒ–æå‡æ¨¡æ‹Ÿçš„å¯æŒç»­æ€§",
      "authors": [
        "James Panayis",
        "Matt Field",
        "Vignesh Gopakumar",
        "Andrew Lahiff",
        "Kristian Zarebski",
        "Aby Abraham",
        "Jonathan L. Hodges"
      ],
      "abstract": "There is high demand on fire simulations, in both scale and quantity. We present a multi-pronged approach to improving the time and energy required to meet these demands. We show the ability of a custom machine learning surrogate model to predict the dynamics of heat propagation orders of magnitude faster than state-of-the-art CFD software for this application. We also demonstrate how a guided optimisation procedure can decrease the number of simulations required to meet an objective; using lightweight models to decide which simulations to run, we see a tenfold reduction when locating the most dangerous location for a fire to occur within a building based on the impact of smoke on visibility. Finally we present a framework and product, Simvue, through which we access these tools along with a host of automatic organisational and tracking features which enables future reuse of data and more savings through better management of simulations and combating redundancy.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è§„æ¨¡ç«ç¾æ¨¡æ‹Ÿå¯¹æ—¶é—´ä¸èƒ½è€—çš„é«˜éœ€æ±‚ï¼Œæå‡ºäº†ä¸€ç§å¤šç®¡é½ä¸‹çš„ä¼˜åŒ–æ–¹æ³•ï¼Œæ—¨åœ¨æå‡ FDS æ¨¡æ‹Ÿçš„å¯æŒç»­æ€§ã€‚ç ”ç©¶å±•ç¤ºäº†é€šè¿‡å®šåˆ¶çš„ machine learning surrogate model é¢„æµ‹çƒ­ä¼ æ’­åŠ¨æ€ï¼Œå…¶é€Ÿåº¦æ¯”ä¼ ç»Ÿ CFD è½¯ä»¶å¿«å‡ ä¸ªæ•°é‡çº§ã€‚åŒæ—¶ï¼Œè®ºæ–‡ä»‹ç»äº†ä¸€ç§ guided optimisation procedureï¼Œåœ¨é€šè¿‡çƒŸé›¾èƒ½è§åº¦å®šä½å»ºç­‘ç‰©æœ€å±é™©ç«ç¾ç‚¹æ—¶ï¼ŒæˆåŠŸå°†æ‰€éœ€æ¨¡æ‹Ÿæ¬¡æ•°å‡å°‘äº†åå€ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶æå‡ºäº† Simvue æ¡†æ¶å’Œäº§å“ï¼Œé€šè¿‡è‡ªåŠ¨åŒ–ç»„ç»‡ã€è¿½è¸ªå’Œæ¨¡æ‹Ÿç®¡ç†åŠŸèƒ½ï¼Œæœ‰æ•ˆé¿å…äº†æ•°æ®å†—ä½™å¹¶ä¿ƒè¿›äº†æœªæ¥æ•°æ®çš„å†åˆ©ç”¨ã€‚è¯¥ç»¼åˆæ–¹æ¡ˆé€šè¿‡ç»“åˆè½»é‡çº§æ¨¡å‹ä¸å…ˆè¿›çš„ç®¡ç†å·¥å…·ï¼Œä¸ºå®ç°æ›´é«˜æ•ˆã€èŠ‚èƒ½çš„ç«ç¾ç§‘å­¦ç ”ç©¶æä¾›äº†å…³é”®çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.comp-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 17 figures, Interflam Conference",
      "pdf_url": "https://arxiv.org/pdf/2509.26139v1",
      "published_date": "2025-09-30 11:57:38 UTC",
      "updated_date": "2025-09-30 11:57:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:36:52.997816+00:00"
    },
    {
      "arxiv_id": "2509.26128v1",
      "title": "MEDAKA: Construction of Biomedical Knowledge Graphs Using Large Language Models",
      "title_zh": "MEDAKAï¼šåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹æ„å»ºç”Ÿç‰©åŒ»å­¦çŸ¥è¯†å›¾è°±",
      "authors": [
        "Asmita Sengupta",
        "David Antony Selby",
        "Sebastian Josef Vollmer",
        "Gerrit GroÃŸmann"
      ],
      "abstract": "Knowledge graphs (KGs) are increasingly used to represent biomedical information in structured, interpretable formats. However, existing biomedical KGs often focus narrowly on molecular interactions or adverse events, overlooking the rich data found in drug leaflets. In this work, we present (1) a hackable, end-to-end pipeline to create KGs from unstructured online content using a web scraper and an LLM; and (2) a curated dataset, MEDAKA, generated by applying this method to publicly available drug leaflets. The dataset captures clinically relevant attributes such as side effects, warnings, contraindications, ingredients, dosage guidelines, storage instructions and physical characteristics. We evaluate it through manual inspection and with an LLM-as-a-Judge framework, and compare its coverage with existing biomedical KGs and databases. We expect MEDAKA to support tasks such as patient safety monitoring and drug recommendation. The pipeline can also be used for constructing KGs from unstructured texts in other domains. Code and dataset are available at https://github.com/medakakg/medaka.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰ç”Ÿç‰©åŒ»å­¦çŸ¥è¯†å›¾è°±(Knowledge Graphs)åœ¨è¯ç‰©è¯´æ˜ä¹¦ä¿¡æ¯è¦†ç›–æ–¹é¢çš„ä¸è¶³ï¼Œæå‡ºäº†MEDAKAæ¡†æ¶ï¼Œæ—¨åœ¨åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(Large Language Models, LLMs)ä»éç»“æ„åŒ–åœ¨çº¿å†…å®¹ä¸­æ„å»ºé«˜è´¨é‡çŸ¥è¯†å›¾è°±ã€‚ç ”ç©¶è€…å¼€å‘äº†ä¸€å¥—é›†æˆç½‘é¡µçˆ¬è™«ä¸LLMçš„ç«¯åˆ°ç«¯ç®¡çº¿(end-to-end pipeline)ï¼Œå¹¶æ®æ­¤ç”Ÿæˆäº†MEDAKAæ•°æ®é›†ï¼Œæ¶µç›–äº†å‰¯ä½œç”¨(side effects)ã€ç¦å¿Œç—‡(contraindications)ã€æˆåˆ†ã€ç”¨æ³•ç”¨é‡åŠç‰©ç†ç‰¹æ€§ç­‰ä¸°å¯Œçš„ä¸´åºŠç›¸å…³å±æ€§ã€‚é€šè¿‡äººå·¥æ£€æŸ¥ä¸LLM-as-a-Judgeæ¡†æ¶çš„è¯„ä¼°ï¼Œè¯¥ç ”ç©¶éªŒè¯äº†æ•°æ®é›†çš„å¯é æ€§ï¼Œå¹¶å°†å…¶è¦†ç›–èŒƒå›´ä¸ç°æœ‰ç”Ÿç‰©åŒ»å­¦æ•°æ®åº“è¿›è¡Œäº†å¯¹æ¯”ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMEDAKAèƒ½æœ‰æ•ˆæ”¯æŒæ‚£è€…å®‰å…¨ç›‘æµ‹å’Œè¯ç‰©æ¨èä»»åŠ¡ï¼Œä¸”å…¶è‡ªåŠ¨åŒ–æ„å»ºæµç¨‹å…·æœ‰æå¼ºçš„é¢†åŸŸé€šç”¨æ€§ã€‚è¯¥é¡¹å·¥ä½œä¸ºç”Ÿç‰©åŒ»å­¦é¢†åŸŸä¿¡æ¯çš„ç»“æ„åŒ–ã€å¯è§£é‡Šæ€§è¡¨ç¤ºæä¾›äº†é‡è¦çš„æ•°æ®æ”¯æŒä¸æŠ€æœ¯æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 5 figures, 2 tables",
      "pdf_url": "https://arxiv.org/pdf/2509.26128v1",
      "published_date": "2025-09-30 11:47:04 UTC",
      "updated_date": "2025-09-30 11:47:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:37:00.890150+00:00"
    },
    {
      "arxiv_id": "2509.26120v1",
      "title": "AGOCS -- Accurate Google Cloud Simulator Framework",
      "title_zh": "AGOCSï¼šé«˜ç²¾åº¦ Google Cloud æ¨¡æ‹Ÿå™¨æ¡†æ¶",
      "authors": [
        "Leszek Sliwko",
        "Vladimir Getov"
      ],
      "abstract": "This paper presents the Accurate Google Cloud Simulator (AGOCS) - a novel high-fidelity Cloud workload simulator based on parsing real workload traces, which can be conveniently used on a desktop machine for day-to-day research. Our simulation is based on real-world workload traces from a Google Cluster with 12.5K nodes, over a period of a calendar month. The framework is able to reveal very precise and detailed parameters of the executed jobs, tasks and nodes as well as to provide actual resource usage statistics. The system has been implemented in Scala language with focus on parallel execution and an easy-to-extend design concept. The paper presents the detailed structural framework for AGOCS and discusses our main design decisions, whilst also suggesting alternative and possibly performance enhancing future approaches. The framework is available via the Open Source GitHub repository.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† AGOCSï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°å‹çš„é«˜ä¿çœŸ Cloud è´Ÿè½½æ¨¡æ‹Ÿå™¨æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡è§£æçœŸå®çš„ workload traces ä¸ºæ—¥å¸¸ç ”ç©¶æä¾›ä¾¿åˆ©ã€‚è¯¥æ¨¡æ‹ŸåŸºäºåŒ…å« 12,500 ä¸ªèŠ‚ç‚¹çš„ Google Cluster åœ¨ä¸€ä¸ªæ—¥å†æœˆå†…çš„çœŸå®è¿è¡Œè½¨è¿¹ï¼Œèƒ½å¤Ÿåœ¨æ™®é€šå°å¼æœºä¸Šå®ç°ç²¾ç¡®çš„æ¨¡æ‹Ÿã€‚AGOCS èƒ½å¤Ÿæ­ç¤º Jobã€Task å’Œ Node çš„è¯¦ç»†å‚æ•°ï¼Œå¹¶æä¾›å‡†ç¡®çš„èµ„æºä½¿ç”¨ç»Ÿè®¡æ•°æ®ã€‚è¯¥ç³»ç»Ÿé‡‡ç”¨ Scala è¯­è¨€å®ç°ï¼Œé‡ç‚¹å…³æ³¨å¹¶è¡Œæ‰§è¡Œï¼ˆparallel executionï¼‰å’Œæ˜“äºæ‰©å±•çš„è®¾è®¡ã€‚æ–‡ä¸­è¯¦ç»†ä»‹ç»äº† AGOCS çš„ç»“æ„æ¡†æ¶ä¸æ ¸å¿ƒè®¾è®¡å†³ç­–ï¼Œå¹¶è®¨è®ºäº†æœªæ¥å¯èƒ½çš„æ€§èƒ½å¢å¼ºæ–¹æ¡ˆã€‚ç›®å‰è¯¥æ¡†æ¶å·²åœ¨ GitHub å¼€æºï¼ˆOpen Sourceï¼‰ï¼Œä¸ºäº‘è®¡ç®—é¢†åŸŸçš„ç ”ç©¶äººå‘˜æä¾›äº†é«˜ç²¾åº¦çš„å®éªŒå·¥å…·ã€‚",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.PF"
      ],
      "primary_category": "cs.DC",
      "comment": "This is the accepted author's version of the paper. The final published version is available in the Proceedings of the 2016 IEEE International Conferences on Ubiquitous Intelligence and Computing (UIC), Advanced and Trusted Computing (ATC), Scalable Computing and Communications (ScalCom), Cloud and Big Data Computing (CBDCom), Internet of People (IoP), and Smart World Congress (SmartWorld)",
      "pdf_url": "https://arxiv.org/pdf/2509.26120v1",
      "published_date": "2025-09-30 11:40:04 UTC",
      "updated_date": "2025-09-30 11:40:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:36:58.093914+00:00"
    },
    {
      "arxiv_id": "2509.26113v1",
      "title": "Enhancing PINN Performance Through Lie Symmetry Group",
      "title_zh": "é€šè¿‡æå¯¹ç§°ç¾¤æå‡ PINN æ€§èƒ½",
      "authors": [
        "Ali Haider Shah",
        "Naveed R. Butt",
        "Asif Ahmad",
        "Muhammad Omer Bin Saeed"
      ],
      "abstract": "This paper presents intersection of Physics informed neural networks (PINNs) and Lie symmetry group to enhance the accuracy and efficiency of solving partial differential equation (PDEs). Various methods have been developed to solve these equations. A Lie group is an efficient method that can lead to exact solutions for the PDEs that possessing Lie Symmetry. Leveraging the concept of infinitesimal generators from Lie symmetry group in a novel manner within PINN leads to significant improvements in solution of PDEs. In this study three distinct cases are discussed, each showing progressive improvements achieved through Lie symmetry modifications and adaptive techniques. State-of-the-art numerical methods are adopted for comparing the progressive PINN models. Numerical experiments demonstrate the key role of Lie symmetry in enhancing PINNs performance, emphasizing the importance of integrating abstract mathematical concepts into deep learning for addressing complex scientific problems adequately.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œ (Physics informed neural networks, PINNs) ä¸æå¯¹ç§°ç¾¤ (Lie symmetry group) çš„ç»“åˆï¼Œæ—¨åœ¨æå‡æ±‚è§£åå¾®åˆ†æ–¹ç¨‹ (Partial differential equations, PDEs) çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚é€šè¿‡åœ¨ PINN å†…éƒ¨åˆ›æ–°æ€§åœ°åˆ©ç”¨æå¯¹ç§°ç¾¤çš„æ— ç©·å°ç”Ÿæˆå…ƒ (Infinitesimal generators) æ¦‚å¿µï¼Œè¯¥æ–¹æ³•æ˜¾è‘—æ”¹å–„äº† PDEs çš„è§£ã€‚ç ”ç©¶ä¸­è¯¦ç»†è®¨è®ºäº†ä¸‰ä¸ªä¸åŒæ¡ˆä¾‹ï¼Œå±•ç¤ºäº†åˆ©ç”¨æå¯¹ç§°æ€§ä¿®æ­£å’Œè‡ªé€‚åº”æŠ€æœ¯ (Adaptive techniques) å®ç°çš„æ€§èƒ½é€æ­¥ä¼˜åŒ–ã€‚æ•°å€¼å®éªŒé€šè¿‡ä¸æœ€å…ˆè¿›çš„æ•°å€¼æ–¹æ³•å¯¹æ¯”ï¼Œè¯æ˜äº†æå¯¹ç§°æ€§åœ¨å¢å¼º PINNs æ€§èƒ½æ–¹é¢çš„å…³é”®ä½œç”¨ã€‚è¿™é¡¹å·¥ä½œå¼ºè°ƒäº†å°†æŠ½è±¡æ•°å­¦æ¦‚å¿µæ•´åˆè¿›æ·±åº¦å­¦ä¹ ä»¥è§£å†³å¤æ‚ç§‘å­¦é—®é¢˜çš„å¿…è¦æ€§ã€‚",
      "categories": [
        "math.AP",
        "cs.AI"
      ],
      "primary_category": "math.AP",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.26113v1",
      "published_date": "2025-09-30 11:30:46 UTC",
      "updated_date": "2025-09-30 11:30:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:37:09.490275+00:00"
    },
    {
      "arxiv_id": "2509.26106v1",
      "title": "Autonomous Multi-Robot Infrastructure for AI-Enabled Healthcare Delivery and Diagnostics",
      "title_zh": "é¢å‘äººå·¥æ™ºèƒ½èµ‹èƒ½åŒ»ç–—äº¤ä»˜ä¸è¯Šæ–­çš„è‡ªä¸»å¤šæœºå™¨äººåŸºç¡€è®¾æ–½",
      "authors": [
        "Nakhul Kalaivanan",
        "Senthil Arumugam Muthukumaraswamy",
        "Girish Balasubramanian"
      ],
      "abstract": "This research presents a multi-robot system for inpatient care, designed using swarm intelligence principles and incorporating wearable health sensors, RF-based communication, and AI-driven decision support. Within a simulated hospital environment, the system adopts a leader-follower swarm configuration to perform patient monitoring, medicine delivery, and emergency assistance. Due to ethical constraints, live patient trials were not conducted; instead, validation was carried out through controlled self-testing with wearable sensors. The Leader Robot acquires key physiological parameters, including temperature, SpO2, heart rate, and fall detection, and coordinates other robots when required. The Assistant Robot patrols corridors for medicine delivery, while a robotic arm provides direct drug administration. The swarm-inspired leader-follower strategy enhanced communication reliability and ensured continuous monitoring, including automated email alerts to healthcare staff. The system hardware was implemented using Arduino, Raspberry Pi, NRF24L01 RF modules, and a HuskyLens AI camera. Experimental evaluation showed an overall sensor accuracy above 94%, a 92% task-level success rate, and a 96% communication reliability rate, demonstrating system robustness. Furthermore, the AI-enabled decision support was able to provide early warnings of abnormal health conditions, highlighting the potential of the system as a cost-effective solution for hospital automation and patient safety.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§ç”¨äºä½é™¢æŠ¤ç†çš„è‡ªä¸»å¤šæœºå™¨äººç³»ç»Ÿæ¡†æ¶ã€‚è¯¥ç³»ç»ŸåŸºäºç¾¤ä½“æ™ºèƒ½(Swarm Intelligence)åŸåˆ™ï¼Œé‡‡ç”¨é¢†å¯¼è€…-è·Ÿéšè€…(Leader-Follower)é…ç½®ï¼Œå¹¶é›†æˆäº†å¯ç©¿æˆ´å¥åº·ä¼ æ„Ÿå™¨ã€å°„é¢‘é€šä¿¡(RF-based communication)å’Œäººå·¥æ™ºèƒ½è¾…åŠ©å†³ç­–æ”¯æŒç³»ç»Ÿã€‚é¢†å¯¼è€…æœºå™¨äºº(Leader Robot)è´Ÿè´£å®æ—¶ç›‘æµ‹ä½“æ¸©ã€è¡€æ°§é¥±å’Œåº¦(SpO2)ã€å¿ƒç‡åŠè·Œå€’æ£€æµ‹ç­‰å…³é”®ç”Ÿç†å‚æ•°ï¼Œå¹¶åè°ƒåŠ©æ‰‹æœºå™¨äºº(Assistant Robot)æ‰§è¡Œèµ°å»Šå·¡é€»é€è¯ä¸æœºæ¢°è‡‚ç»™è¯ä»»åŠ¡ã€‚ç³»ç»Ÿç¡¬ä»¶åŸºäºArduinoã€æ ‘è“æ´¾(Raspberry Pi)åŠHuskyLens AIç›¸æœºå¼€å‘ï¼Œç¡®ä¿äº†é«˜æ•ˆçš„å®æ—¶ç›‘æ§ä¸è‡ªåŠ¨é‚®ä»¶è­¦æŠ¥é€šçŸ¥ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥ç³»ç»Ÿçš„ä¼ æ„Ÿå™¨å‡†ç¡®ç‡è¶…è¿‡94%ï¼Œä»»åŠ¡æˆåŠŸç‡ä¸º92%ï¼Œé€šä¿¡å¯é æ€§è¾¾96%ã€‚è¿™ä¸€æˆæœè¯æ˜äº†è¯¥æ¡†æ¶åœ¨å®ç°ä½æˆæœ¬åŒ»é™¢è‡ªåŠ¨åŒ–ã€æå‡åŒ»ç–—äº¤ä»˜æ•ˆç‡åŠä¿éšœæ‚£è€…å®‰å…¨æ–¹é¢çš„æ˜¾è‘—æ½œåŠ›ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "11 pages, 5 figures, MSc dissertation submission draft, prepared for conference/journal consideration",
      "pdf_url": "https://arxiv.org/pdf/2509.26106v1",
      "published_date": "2025-09-30 11:27:33 UTC",
      "updated_date": "2025-09-30 11:27:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:37:56.093970+00:00"
    },
    {
      "arxiv_id": "2509.26103v1",
      "title": "End-to-End Aspect-Guided Review Summarization at Scale",
      "title_zh": "å¤§è§„æ¨¡ç«¯åˆ°ç«¯æ–¹é¢å¼•å¯¼çš„è¯„è®ºæ‘˜è¦",
      "authors": [
        "Ilya Boytsov",
        "Vinny DeGenova",
        "Mikhail Balyasin",
        "Joseph Walt",
        "Caitlin Eusden",
        "Marie-Claire Rochat",
        "Margaret Pierson"
      ],
      "abstract": "We present a scalable large language model (LLM)-based system that combines aspect-based sentiment analysis (ABSA) with guided summarization to generate concise and interpretable product review summaries for the Wayfair platform. Our approach first extracts and consolidates aspect-sentiment pairs from individual reviews, selects the most frequent aspects for each product, and samples representative reviews accordingly. These are used to construct structured prompts that guide the LLM to produce summaries grounded in actual customer feedback. We demonstrate the real-world effectiveness of our system through a large-scale online A/B test. Furthermore, we describe our real-time deployment strategy and release a dataset of 11.8 million anonymized customer reviews covering 92,000 products, including extracted aspects and generated summaries, to support future research in aspect-guided review summarization.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»‹ç»äº†ä¸€ä¸ªåŸºäºå¤§è¯­è¨€æ¨¡å‹(LLM)çš„å¯æ‰©å±•ç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿç»“åˆäº†åŸºäºæ–¹é¢çš„æƒ…æ„Ÿåˆ†æ(ABSA)å’Œå¼•å¯¼å¼æ‘˜è¦æŠ€æœ¯ï¼Œæ—¨åœ¨ä¸º Wayfair å¹³å°ç”Ÿæˆç®€æ´ä¸”å¯è§£é‡Šçš„äº§å“è¯„è®ºæ‘˜è¦ã€‚è¯¥æ–¹æ³•é¦–å…ˆä»æµ·é‡è¯„è®ºä¸­æå–å¹¶æ•´åˆæ–¹é¢-æƒ…æ„Ÿå¯¹(aspect-sentiment pairs)ï¼Œç­›é€‰å‡ºæ¯ä¸ªäº§å“çš„æ ¸å¿ƒè¯„ä»·ç»´åº¦ï¼Œå¹¶æ®æ­¤é‡‡æ ·å…·æœ‰ä»£è¡¨æ€§çš„è¯„è®ºå†…å®¹ã€‚é€šè¿‡æ„å»ºç»“æ„åŒ–æç¤ºè¯(structured prompts)ï¼Œç³»ç»Ÿå¼•å¯¼ LLM ç”Ÿæˆä¸¥æ ¼åŸºäºçœŸå®å®¢æˆ·åé¦ˆçš„æ‘˜è¦ï¼Œç¡®ä¿äº†ä¿¡æ¯çš„å¯é æ€§ã€‚å¤§è§„æ¨¡åœ¨çº¿ A/B æµ‹è¯•è¯æ˜äº†è¯¥ç³»ç»Ÿåœ¨çœŸå®å•†ä¸šåœºæ™¯ä¸­çš„å“è¶Šæœ‰æ•ˆæ€§ï¼Œç ”ç©¶è¿˜è¯¦ç»†é˜è¿°äº†å…¶å®æ—¶éƒ¨ç½²ç­–ç•¥ã€‚æ­¤å¤–ï¼Œä½œè€…å‘å¸ƒäº†ä¸€ä¸ªåŒ…å« 1180 ä¸‡æ¡åŒ¿åè¯„è®ºã€æ¶µç›– 9.2 ä¸‡ä¸ªäº§å“çš„å¤§å‹æ•°æ®é›†ï¼Œå…¶ä¸­åŒ…æ‹¬æå–çš„æ–¹é¢å’Œç”Ÿæˆçš„æ‘˜è¦ï¼Œä¸ºæœªæ¥æ–¹é¢å¼•å¯¼è¯„è®ºæ‘˜è¦(aspect-guided review summarization)çš„ç ”ç©¶æä¾›äº†é‡è¦èµ„æºã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Camera-ready preprint for EMNLP 2025 Industry Track",
      "pdf_url": "https://arxiv.org/pdf/2509.26103v1",
      "published_date": "2025-09-30 11:24:07 UTC",
      "updated_date": "2025-09-30 11:24:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:37:19.090352+00:00"
    },
    {
      "arxiv_id": "2509.26100v1",
      "title": "SafeEvalAgent: Toward Agentic and Self-Evolving Safety Evaluation of LLMs",
      "title_zh": "SafeEvalAgentï¼šè¿ˆå‘å¤§è¯­è¨€æ¨¡å‹çš„æ™ºèƒ½ä½“åŒ–ä¸è‡ªè¿›åŒ–å®‰å…¨è¯„ä¼°",
      "authors": [
        "Yixu Wang",
        "Xin Wang",
        "Yang Yao",
        "Xinyuan Li",
        "Yan Teng",
        "Xingjun Ma",
        "Yingchun Wang"
      ],
      "abstract": "The rapid integration of Large Language Models (LLMs) into high-stakes domains necessitates reliable safety and compliance evaluation. However, existing static benchmarks are ill-equipped to address the dynamic nature of AI risks and evolving regulations, creating a critical safety gap. This paper introduces a new paradigm of agentic safety evaluation, reframing evaluation as a continuous and self-evolving process rather than a one-time audit. We then propose a novel multi-agent framework SafeEvalAgent, which autonomously ingests unstructured policy documents to generate and perpetually evolve a comprehensive safety benchmark. SafeEvalAgent leverages a synergistic pipeline of specialized agents and incorporates a Self-evolving Evaluation loop, where the system learns from evaluation results to craft progressively more sophisticated and targeted test cases. Our experiments demonstrate the effectiveness of SafeEvalAgent, showing a consistent decline in model safety as the evaluation hardens. For instance, GPT-5's safety rate on the EU AI Act drops from 72.50% to 36.36% over successive iterations. These findings reveal the limitations of static assessments and highlight our framework's ability to uncover deep vulnerabilities missed by traditional methods, underscoring the urgent need for dynamic evaluation ecosystems to ensure the safe and responsible deployment of advanced AI.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é™æ€åŸºå‡†æµ‹è¯•æ— æ³•åº”å¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åŠ¨æ€é£é™©å’Œä¸æ–­æ¼”å˜çš„æ³•è§„è¿™ä¸€æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§ä»£ç†å¼(agentic)ä¸”æŒç»­æ¼”åŒ–çš„å®‰å…¨è¯„ä¼°æ–°èŒƒå¼ã€‚æ ¸å¿ƒè´¡çŒ®æ˜¯å¼€å‘äº†åä¸º SafeEvalAgent çš„å¤šæ™ºèƒ½ä½“(multi-agent)æ¡†æ¶ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿè‡ªä¸»æ‘„å–éç»“æ„åŒ–æ”¿ç­–æ–‡æ¡£ï¼Œå¹¶ç”Ÿæˆä¸”åŠ¨æ€æ¼”åŒ–å…¨é¢çš„å®‰å…¨åŸºå‡†ã€‚SafeEvalAgent é€šè¿‡ä¸“é—¨æ™ºèƒ½ä½“çš„ååŒå·¥ä½œæµï¼Œç»“åˆè‡ªæˆ‘æ¼”åŒ–è¯„ä¼°(Self-evolving Evaluation)å¾ªç¯ï¼Œåˆ©ç”¨è¯„ä¼°ç»“æœä¸æ–­ä¼˜åŒ–å¹¶ç”Ÿæˆæ›´å…·æŒ‘æˆ˜æ€§çš„é’ˆå¯¹æ€§æµ‹è¯•æ¡ˆä¾‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œéšç€è¯„ä¼°è¿‡ç¨‹çš„è‡ªæˆ‘ç¡¬åŒ–ï¼Œæ¨¡å‹å®‰å…¨ç‡æ˜¾è‘—ä¸‹é™ï¼Œä¾‹å¦‚ GPT-5 åœ¨æ¬§ç›Ÿäººå·¥æ™ºèƒ½æ³•æ¡ˆ(EU AI Act)æµ‹è¯•ä¸‹çš„å®‰å…¨ç‡ä» 72.50% é™è‡³ 36.36%ã€‚è¿™ä¸€å‘ç°æ­ç¤ºäº†ä¼ ç»Ÿé™æ€è¯„ä¼°çš„å±€é™æ€§ï¼Œè¯æ˜äº†è¯¥æ¡†æ¶æŒ–æ˜æ·±å±‚å®‰å…¨æ¼æ´çš„èƒ½åŠ›ï¼Œå¼ºè°ƒäº†æ„å»ºåŠ¨æ€è¯„ä¼°ç”Ÿæ€ç³»ç»Ÿå¯¹ç¡®ä¿å…ˆè¿›äººå·¥æ™ºèƒ½è´Ÿè´£ä»»éƒ¨ç½²çš„ç´§è¿«æ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.26100v1",
      "published_date": "2025-09-30 11:20:41 UTC",
      "updated_date": "2025-09-30 11:20:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:37:26.998708+00:00"
    },
    {
      "arxiv_id": "2509.26094v1",
      "title": "On Computing Top-$k$ Simple Shortest Paths from a Single Source",
      "title_zh": "å…³äºå•æºå‰ $k$ æ¡ç®€å•æœ€çŸ­è·¯å¾„çš„è®¡ç®—",
      "authors": [
        "Mattia D'Emidio",
        "Gabriele Di Stefano"
      ],
      "abstract": "We investigate the problem of computing the top-$k$ simple shortest paths in weighted digraphs. While the single-pair variant -- finding the top-$k$ simple shortest paths between two specified vertices -- has been extensively studied over the past decades, with Yen's algorithm and its heuristic improvements emerging as the most effective solving strategies, relatively little attention has been devoted to the more general single-source version, where the goal is determining top-$k$ simple shortest paths from a source vertex to all other vertices. Motivated by the numerous practical applications of ranked shortest paths, in this paper we provide new insights and algorithmic contributions to this problem. In particular, we first present a theoretical characterization of the structural properties of its solutions. Then, we introduce the first polynomial-time algorithm specifically designed to handle it. On the one hand, we prove our new algorithm is on par, in terms of time complexity, with the best (and only) polynomial-time approach known in the literature to solve the problem, that is applying the fastest single-pair algorithm independently to each vertex pair formed by the source and the remaining vertices. On the other hand, through an extensive experimental evaluation on both real-world and synthetic graphs, we demonstrate that our algorithm consistently and significantly outperforms the latter baseline in terms of running time, achieving speed-ups of up to several orders of magnitude. These results establish our new algorithm as the solution to be preferred for computing $k$ simple shortest paths from a single source in practical settings.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æœ‰å‘åŠ æƒå›¾ä¸­è®¡ç®—ä»å•æºç‚¹åˆ°æ‰€æœ‰å…¶ä»–é¡¶ç‚¹çš„ Top-$k$ Simple Shortest Paths é—®é¢˜ã€‚è™½ç„¶é’ˆå¯¹ç‰¹å®šé¡¶ç‚¹å¯¹çš„ç®—æ³•å¦‚ Yen's algorithm å·²å¾—åˆ°å¹¿æ³›ç ”ç©¶ï¼Œä½†é’ˆå¯¹å•æºå¤šç›®æ ‡çš„é€šç”¨åœºæ™¯ä»ç¼ºä¹ä¸“é—¨çš„ä¼˜åŒ–ç­–ç•¥ã€‚è®ºæ–‡é¦–å…ˆå¯¹è¯¥é—®é¢˜çš„è§£æä¾›äº†ç»“æ„æ€§è´¨çš„ç†è®ºè¡¨å¾ï¼Œå¹¶æ®æ­¤è®¾è®¡äº†é¦–ä¸ªä¸“é—¨å¤„ç†è¯¥é—®é¢˜çš„å¤šé¡¹å¼æ—¶é—´ç®—æ³•ã€‚è™½ç„¶è¯¥ç®—æ³•åœ¨æ—¶é—´å¤æ‚åº¦ä¸Šä¸ç‹¬ç«‹åº”ç”¨å•å¯¹æœ€çŸ­è·¯å¾„ç®—æ³•çš„æ–¹æ³•ç›¸å½“ï¼Œä½†å…¶å®é™…æ€§èƒ½è¡¨ç°æ›´ä¸ºä¼˜è¶Šã€‚é€šè¿‡å¯¹çœŸå®ä¸–ç•Œå’Œåˆæˆå›¾çš„å¤§è§„æ¨¡å®éªŒè¯„ä¼°ï¼Œè¯¥ç®—æ³•åœ¨è¿è¡Œæ—¶é—´ä¸Šå®ç°äº†æ¯”åŸºçº¿æ¨¡å‹é«˜å‡ºæ•°ä¸ªæ•°é‡çº§çš„æ˜¾è‘—åŠ é€Ÿã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥ç®—æ³•æ˜¯ç›®å‰å®é™…åº”ç”¨ä¸­è®¡ç®—å•æº $k$ Simple Shortest Paths çš„æœ€ä¼˜è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.DS",
        "cs.AI",
        "cs.IR",
        "cs.NI"
      ],
      "primary_category": "cs.DS",
      "comment": "21 pages, 2 figures, to be published in ALENEX 2026",
      "pdf_url": "https://arxiv.org/pdf/2509.26094v1",
      "published_date": "2025-09-30 11:12:05 UTC",
      "updated_date": "2025-09-30 11:12:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:37:31.590600+00:00"
    },
    {
      "arxiv_id": "2509.26080v2",
      "title": "Evaluating the Use of Large Language Models as Synthetic Social Agents in Social Science Research",
      "title_zh": "è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹åœ¨ç¤¾ä¼šç§‘å­¦ç ”ç©¶ä¸­ä½œä¸ºåˆæˆç¤¾ä¼šæ™ºèƒ½ä½“çš„åº”ç”¨",
      "authors": [
        "Emma Rose Madden"
      ],
      "abstract": "Large Language Models (LLMs) are being increasingly used as synthetic agents in social science, in applications ranging from augmenting survey responses to powering multi-agent simulations. This paper outlines cautions that should be taken when interpreting LLM outputs and proposes a pragmatic reframing for the social sciences in which LLMs are used as high-capacity pattern matchers for quasi-predictive interpolation under explicit scope conditions and not as substitutes for probabilistic inference. Practical guardrails such as independent draws, preregistered human baselines, reliability-aware validation, and subgroup calibration, are introduced so that researchers may engage in useful prototyping and forecasting while avoiding category errors.",
      "tldr_zh": "è¯¥ç ”ç©¶è¯„ä¼°äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨ç¤¾ä¼šç§‘å­¦ç ”ç©¶ä¸­ä½œä¸ºåˆæˆç¤¾äº¤æ™ºèƒ½ä½“çš„ä½¿ç”¨æƒ…å†µï¼Œå¹¶é’ˆå¯¹å…¶åœ¨è°ƒæŸ¥å¢è¡¥å’Œå¤šæ™ºèƒ½ä½“æ¨¡æ‹Ÿä¸­çš„åº”ç”¨æå‡ºäº†è­¦ç¤ºã€‚ä½œè€…å»ºè®®å°† LLMs é‡æ–°å®šä¹‰ä¸ºåœ¨æ˜ç¡®èŒƒå›´æ¡ä»¶ä¸‹çš„é«˜å®¹é‡æ¨¡å¼åŒ¹é…å™¨ï¼Œç”¨äºå‡†é¢„æµ‹æ€§å†…æ’(quasi-predictive interpolation)ï¼Œè€Œéå°†å…¶è§†ä¸ºæ¦‚ç‡æ¨ç†(probabilistic inference)çš„æ›¿ä»£å“ã€‚ä¸ºäº†é¿å…èŒƒç•´é”™è¯¯(category errors)å¹¶ç¡®ä¿ç ”ç©¶çš„ä¸¥è°¨æ€§ï¼Œè®ºæ–‡å¼•å…¥äº†åŒ…æ‹¬ç‹¬ç«‹æŠ½å–(independent draws)ã€é¢„æ³¨å†Œçš„äººç±»åŸºå‡†(preregistered human baselines)ã€å¯é æ€§æ„ŸçŸ¥éªŒè¯(reliability-aware validation)å’Œå­ç¾¤ä½“æ ¡å‡†(subgroup calibration)åœ¨å†…çš„å®ç”¨ä¿æŠ¤æªæ–½ã€‚è¿™äº›æ¡†æ¶å’Œå»ºè®®æ—¨åœ¨æŒ‡å¯¼ç ”ç©¶äººå‘˜åœ¨åˆ©ç”¨ LLMs è¿›è¡ŒåŸå‹è®¾è®¡å’Œé¢„æµ‹æ—¶ï¼Œèƒ½å¤Ÿæ›´ç§‘å­¦åœ°è§£è¯»æ¨¡å‹è¾“å‡ºå¹¶å»ºç«‹æœ‰æ•ˆçš„éªŒè¯æœºåˆ¶ã€‚",
      "categories": [
        "cs.AI",
        "stat.AP"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.26080v2",
      "published_date": "2025-09-30 10:53:54 UTC",
      "updated_date": "2025-10-28 13:00:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:37:33.896189+00:00"
    },
    {
      "arxiv_id": "2509.26058v2",
      "title": "Real-time Noise Detection and Classification in Single-Channel EEG: A Lightweight Machine Learning Approach for EMG, White Noise, and EOG Artifacts",
      "title_zh": "å•é€šé“è„‘ç”µå®æ—¶å™ªå£°æ£€æµ‹ä¸åˆ†ç±»ï¼šé’ˆå¯¹è‚Œç”µã€ç™½å™ªå£°åŠçœ¼ç”µä¼ªè¿¹çš„è½»é‡çº§æœºå™¨å­¦ä¹ æ–¹æ³•",
      "authors": [
        "Hossein Enshaei",
        "Pariya Jebreili",
        "Sayed Mahmoud Sakhaei"
      ],
      "abstract": "Electroencephalogram (EEG) artifact detection in real-world settings faces significant challenges such as computational inefficiency in multi-channel methods, poor robustness to simultaneous noise, and trade-offs between accuracy and complexity in deep learning models. We propose a hybrid spectral-temporal framework for real-time detection and classification of ocular (EOG), muscular (EMG), and white noise artifacts in single-channel EEG. This method, in contrast to other approaches, combines time-domain low-pass filtering (targeting low-frequency EOG) and frequency-domain power spectral density (PSD) analysis (capturing broad-spectrum EMG), followed by PCA-optimized feature fusion to minimize redundancy while preserving discriminative information. This feature engineering strategy allows a lightweight multi-layer perceptron (MLP) architecture to outperform advanced CNNs and RNNs by achieving 99% accuracy at low SNRs (SNR -7) dB and >90% accuracy in moderate noise (SNR 4 dB). Additionally, this framework addresses the unexplored problem of simultaneous multi-source contamination(EMG+EOG+white noise), where it maintains 96% classification accuracy despite overlapping artifacts. With 30-second training times (97% faster than CNNs) and robust performance across SNR levels, this framework bridges the gap between clinical applicability and computational efficiency, which enables real-time use in wearable brain-computer interfaces. This work also challenges the ubiquitous dependence on model depth for EEG artifact detection by demonstrating that domain-informed feature fusion surpasses complex architecture in noisy scenarios.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªæ··åˆæ—¶åŸŸ-é¢‘åŸŸ(hybrid spectral-temporal)æ¡†æ¶ï¼Œç”¨äºå•é€šé“ EEG çš„å®æ—¶å™ªå£°æ£€æµ‹ä¸åˆ†ç±»ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿæ–¹æ³•åœ¨è®¡ç®—æ•ˆç‡ä¸é²æ£’æ€§ä¹‹é—´çš„æƒè¡¡é—®é¢˜ã€‚è¯¥æ–¹æ³•ç»“åˆäº†é’ˆå¯¹ä½é¢‘ EOG çš„æ—¶åŸŸä½é€šæ»¤æ³¢å’Œæ•æ‰å¹¿è°± EMG çš„é¢‘åŸŸåŠŸç‡è°±å¯†åº¦(PSD)åˆ†æï¼Œå¹¶é€šè¿‡ PCA ä¼˜åŒ–çš„ç‰¹å¾èåˆæŠ€æœ¯åœ¨ä¿ç•™åˆ¤åˆ«ä¿¡æ¯çš„åŒæ—¶æœ€å°åŒ–å†—ä½™ã€‚è¿™ç§ç‰¹å¾å·¥ç¨‹ç­–ç•¥ä½¿å¾—è½»é‡çº§çš„å¤šå±‚æ„ŸçŸ¥å™¨(MLP)æ¶æ„èƒ½å¤Ÿè¶…è¶Šå¤æ‚çš„ CNN å’Œ RNN æ¨¡å‹ï¼Œåœ¨ä½ä¿¡å™ªæ¯”(SNR)ç¯å¢ƒä¸‹å‡†ç¡®ç‡é«˜è¾¾99%ï¼Œå¹¶èƒ½ä»¥96%çš„å‡†ç¡®åº¦å¤„ç†å¤šæºé‡å ä¼ªå½±ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ¡†æ¶çš„è®­ç»ƒé€Ÿåº¦æ¯” CNN å¿«97%ï¼Œæœ‰æ•ˆå¼¥åˆäº†ä¸´åºŠé€‚ç”¨æ€§ä¸è®¡ç®—æ•ˆç‡ä¹‹é—´çš„å·®è·ï¼Œä¸ºå¯ç©¿æˆ´è„‘æœºæ¥å£(wearable BCI)çš„å®æ—¶åº”ç”¨æä¾›äº†æ”¯æŒã€‚è¯¥å·¥ä½œé€šè¿‡è¯æ˜é¢†åŸŸçŸ¥è¯†å¼•å¯¼çš„ç‰¹å¾èåˆä¼˜äºå¤æ‚çš„æ·±åº¦æ¶æ„ï¼ŒæŒ‘æˆ˜äº† EEG ä¼ªå½±æ£€æµ‹å¯¹æ¨¡å‹æ·±åº¦çš„æ™®éä¾èµ–ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.26058v2",
      "published_date": "2025-09-30 10:32:38 UTC",
      "updated_date": "2025-10-09 16:36:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:37:47.202020+00:00"
    },
    {
      "arxiv_id": "2509.26051v1",
      "title": "CEAID: Benchmark of Multilingual Machine-Generated Text Detection Methods for Central European Languages",
      "title_zh": "CEAIDï¼šä¸­æ¬§è¯­è¨€å¤šè¯­è¨€æœºå™¨ç”Ÿæˆæ–‡æœ¬æ£€æµ‹æ–¹æ³•åŸºå‡†",
      "authors": [
        "Dominik Macko",
        "Jakub Kopal"
      ],
      "abstract": "Machine-generated text detection, as an important task, is predominantly focused on English in research. This makes the existing detectors almost unusable for non-English languages, relying purely on cross-lingual transferability. There exist only a few works focused on any of Central European languages, leaving the transferability towards these languages rather unexplored. We fill this gap by providing the first benchmark of detection methods focused on this region, while also providing comparison of train-languages combinations to identify the best performing ones. We focus on multi-domain, multi-generator, and multilingual evaluation, pinpointing the differences of individual aspects, as well as adversarial robustness of detection methods. Supervised finetuned detectors in the Central European languages are found the most performant in these languages as well as the most resistant against obfuscation.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† CEAIDï¼Œè¿™æ˜¯é¦–ä¸ªé’ˆå¯¹ä¸­æ¬§è¯­è¨€ (Central European languages) çš„å¤šè¯­è¨€æœºå™¨ç”Ÿæˆæ–‡æœ¬æ£€æµ‹ (Machine-generated text detection) æ–¹æ³•åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ£€æµ‹å™¨å› è¿‡åº¦å…³æ³¨è‹±è¯­è€Œå¯¼è‡´åœ¨ä¸­æ¬§è¯­ç³»ä¸­è·¨è¯­è¨€è¿ç§»èƒ½åŠ›å—é™çš„é—®é¢˜ã€‚ç ”ç©¶é€šè¿‡å¤šé¢†åŸŸã€å¤šç”Ÿæˆå™¨åŠå¤šè¯­è¨€è¯„ä¼°ï¼Œæ·±å…¥åˆ†æäº†æ£€æµ‹æ–¹æ³•åœ¨ä¸åŒè®­ç»ƒè¯­è¨€ç»„åˆä¸‹çš„è¡¨ç°ä»¥åŠå¯¹æŠ—é²æ£’æ€§ (Adversarial robustness)ã€‚å®éªŒå‘ç°ï¼Œé’ˆå¯¹ä¸­æ¬§è¯­è¨€è¿›è¡Œç›‘ç£å¾®è°ƒ (Supervised finetuned) çš„æ£€æµ‹å™¨åœ¨è¯¥åœ°åŒºè¯­è¨€ä¸­è¡¨ç°æœ€ä¸ºå‡ºè‰²ï¼Œä¸”å¯¹äºæ–‡æœ¬æ··æ·† (Obfuscation) æ”»å‡»è¡¨ç°å‡ºæœ€å¼ºçš„æŠµæŠ—åŠ›ã€‚è¿™é¡¹å·¥ä½œå¡«è¡¥äº†ç›¸å…³ç ”ç©¶é¢†åŸŸçš„ç©ºç™½ï¼Œå¹¶ä¸ºè¯„ä¼°å’Œæå‡éè‹±è¯­æœºå™¨ç”Ÿæˆæ–‡æœ¬æ£€æµ‹æŠ€æœ¯çš„å¯é æ€§æä¾›äº†é‡è¦æ”¯æŒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.26051v1",
      "published_date": "2025-09-30 10:27:53 UTC",
      "updated_date": "2025-09-30 10:27:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:38:10.778805+00:00"
    },
    {
      "arxiv_id": "2509.26037v1",
      "title": "CoLLM-NAS: Collaborative Large Language Models for Efficient Knowledge-Guided Neural Architecture Search",
      "title_zh": "CoLLM-NASï¼šåŸºäºåä½œå¤§è¯­è¨€æ¨¡å‹çš„é«˜æ•ˆçŸ¥è¯†å¼•å¯¼ç¥ç»æ¶æ„æœç´¢",
      "authors": [
        "Zhe Li",
        "Zhiwei Lin",
        "Yongtao Wang"
      ],
      "abstract": "The integration of Large Language Models (LLMs) with Neural Architecture Search (NAS) has introduced new possibilities for automating the design of neural architectures. However, most existing methods face critical limitations, including architectural invalidity, computational inefficiency, and inferior performance compared to traditional NAS. In this work, we present Collaborative LLM-based NAS (CoLLM-NAS), a two-stage NAS framework with knowledge-guided search driven by two complementary LLMs. Specifically, we propose a Navigator LLM to guide search direction and a Generator LLM to synthesize high-quality candidates, with a dedicated Coordinator module to manage their interaction. CoLLM-NAS efficiently guides the search process by combining LLMs' inherent knowledge of structured neural architectures with progressive knowledge from iterative feedback and historical trajectory. Experimental results on ImageNet and NAS-Bench-201 show that CoLLM-NAS surpasses existing NAS methods and conventional search algorithms, achieving new state-of-the-art results. Furthermore, CoLLM-NAS consistently enhances the performance and efficiency of various two-stage NAS methods (e.g., OFA, SPOS, and AutoFormer) across diverse search spaces (e.g., MobileNet, ShuffleNet, and AutoFormer), demonstrating its excellent generalization.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† CoLLM-NASï¼Œä¸€ç§åŸºäºå¤§è¯­è¨€æ¨¡å‹ (Large Language Models, LLMs) çš„åä½œå¼ç¥ç»æ¶æ„æœç´¢ (Neural Architecture Search, NAS) æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ–¹æ³•åœ¨æ¶æ„æœ‰æ•ˆæ€§ã€è®¡ç®—æ•ˆç‡åŠæ€§èƒ½ä¸Šçš„å±€é™ã€‚è¯¥ä¸¤é˜¶æ®µæ¡†æ¶ç”± Navigator LLM å¼•å¯¼æœç´¢æ–¹å‘ï¼ŒGenerator LLM è´Ÿè´£åˆæˆé«˜è´¨é‡å€™é€‰æ¶æ„ï¼Œå¹¶ç”± Coordinator æ¨¡å—åè°ƒä¸¤è€…çš„äº¤äº’ã€‚CoLLM-NAS å°† LLMs å›ºæœ‰çš„ç»“æ„åŒ–æ¶æ„çŸ¥è¯†ä¸è¿­ä»£åé¦ˆåŠå†å²è½¨è¿¹ä¸­çš„æ¸è¿›çŸ¥è¯†ç›¸ç»“åˆï¼Œå®ç°äº†é«˜æ•ˆçš„çŸ¥è¯†å¼•å¯¼æœç´¢ã€‚åœ¨ ImageNet å’Œ NAS-Bench-201 ä¸Šçš„å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•è¶…è¶Šäº†ç°æœ‰ NAS å’Œä¼ ç»Ÿæœç´¢ç®—æ³•ï¼Œå–å¾—äº† SOTA ç»“æœã€‚æ­¤å¤–ï¼ŒCoLLM-NAS èƒ½æ˜¾è‘—æå‡ OFAã€SPOS å’Œ AutoFormer ç­‰å¤šç§æ–¹æ³•åœ¨ MobileNet å’Œ ShuffleNet ç­‰æœç´¢ç©ºé—´ä¸­çš„è¡¨ç°ï¼Œå±•ç¤ºäº†å…¶ä¼˜å¼‚çš„æ³›åŒ–èƒ½åŠ›ã€‚",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.26037v1",
      "published_date": "2025-09-30 10:12:49 UTC",
      "updated_date": "2025-09-30 10:12:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:38:18.083278+00:00"
    },
    {
      "arxiv_id": "2509.26036v2",
      "title": "SeMoBridge: Semantic Modality Bridge for Efficient Few-Shot Adaptation of CLIP",
      "title_zh": "SeMoBridgeï¼šç”¨äº CLIP é«˜æ•ˆå°æ ·æœ¬é€‚é…çš„è¯­ä¹‰æ¨¡æ€æ¡¥æ¢",
      "authors": [
        "Christoph Timmermann",
        "Hyunse Lee",
        "Woojin Lee"
      ],
      "abstract": "While Contrastive Language-Image Pretraining (CLIP) excels at zero-shot tasks by aligning image and text embeddings, its performance in few-shot classification is hindered by a critical limitation: intra-modal misalignment. This issue, caused by a persistent modality gap and CLIP's exclusively inter-modal training objective, leaves the embedding spaces uncalibrated, making direct image-to-image comparisons unreliable. Existing methods attempt to address this by refining similarity logits or by computationally expensive per-sample optimization. To overcome these challenges, we introduce SeMoBridge, a lightweight yet powerful approach that directly addresses the misalignment. Our method maps images into the text modality, while keeping their semantic content intact through what we call a Semantic Modality Bridge. SeMoBridge is closed-form and can optionally be trained through multi-modal supervision, combining image and text-alignment losses to optimize the projection. Experiments show that the trained version, SeMoBridge-T, requires only a fraction of the training time while overall outperforming other methods, particularly in low-data scenarios (1, 2, and 4 shots). The code is available at https://github.com/christti98/semobridge.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Contrastive Language-Image Pretraining (CLIP) åœ¨ few-shot åˆ†ç±»ä»»åŠ¡ä¸­ç”±äº modality gap å’Œ intra-modal misalignment å¯¼è‡´çš„å›¾åƒé—´æ¯”è¾ƒä¸å¯é é—®é¢˜ï¼Œæå‡ºäº†åä¸º SeMoBridge çš„è¯­ä¹‰æ¨¡æ€æ¡¥æ¢æ–¹æ³•ã€‚SeMoBridge é€šè¿‡å°†å›¾åƒæ˜ å°„åˆ°æ–‡æœ¬æ¨¡æ€ç©ºé—´å¹¶ä¿æŒå…¶è¯­ä¹‰å†…å®¹å®Œæ•´ï¼Œæœ‰æ•ˆè§£å†³äº†æ¨¡æ€æœªæ ¡å‡†å¸¦æ¥çš„æŒ‘æˆ˜ã€‚è¯¥æ–¹æ¡ˆä¸ä»…åŒ…å« closed-form å½¢å¼çš„å®ç°ï¼Œè¿˜æ¨å‡ºäº†ç»è¿‡å¤šæ¨¡æ€ç›‘ç£è®­ç»ƒçš„ SeMoBridge-T ç‰ˆæœ¬ï¼Œé€šè¿‡ç»“åˆå›¾åƒå’Œæ–‡æœ¬å¯¹é½æŸå¤±æ¥ä¼˜åŒ–æŠ•å½±è¿‡ç¨‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSeMoBridge-T åœ¨æ˜¾è‘—ç¼©çŸ­è®­ç»ƒæ—¶é—´çš„åŒæ—¶ï¼Œæ€§èƒ½å…¨é¢ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå°¤å…¶åœ¨ 1ã€2ã€4 shots ç­‰æä½æ•°æ®åœºæ™¯ä¸‹å±•ç°å‡ºå“è¶Šçš„æ³›åŒ–èƒ½åŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "19 pages, 12 figures, Under review as a conference paper at ICLR 2026",
      "pdf_url": "https://arxiv.org/pdf/2509.26036v2",
      "published_date": "2025-09-30 10:12:15 UTC",
      "updated_date": "2025-10-01 09:18:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:38:22.171177+00:00"
    },
    {
      "arxiv_id": "2509.26030v2",
      "title": "Muon Outperforms Adam in Tail-End Associative Memory Learning",
      "title_zh": "Muon åœ¨å°¾éƒ¨è”æƒ³è®°å¿†å­¦ä¹ ä¸­è¡¨ç°ä¼˜äº Adam",
      "authors": [
        "Shuche Wang",
        "Fengzhuo Zhang",
        "Jiaxiang Li",
        "Cunxiao Du",
        "Chao Du",
        "Tianyu Pang",
        "Zhuoran Yang",
        "Mingyi Hong",
        "Vincent Y. F. Tan"
      ],
      "abstract": "The Muon optimizer is consistently faster than Adam in training Large Language Models (LLMs), yet the mechanism underlying its success remains unclear. This paper demystifies this mechanism through the lens of associative memory. By ablating the transformer components optimized by Muon, we reveal that the associative memory parameters of LLMs, namely the Value and Output (VO) attention weights and Feed-Forward Networks (FFNs), are the primary contributors to Muon's superiority. Motivated by this associative memory view, we then explain Muon's superiority on real-world corpora, which are intrinsically heavy-tailed: a few classes (tail classes) appear far less frequently than others. The superiority is explained through two key properties: (i) its update rule consistently yields a more isotropic singular spectrum than Adam; and as a result, (ii) on heavy-tailed data, it optimizes tail classes more effectively than Adam. Beyond empirical evidence, we theoretically confirm these findings by analyzing a one-layer associative memory model under class-imbalanced data. We prove that Muon consistently achieves balanced learning across classes regardless of feature embeddings, whereas Adam can induce large disparities in learning errors depending on embedding properties. In summary, our empirical observations and theoretical analyses reveal Muon's core advantage: its update rule aligns with the outer-product structure of linear associative memories, enabling more balanced and effective learning of tail classes in heavy-tailed distributions than Adam.",
      "tldr_zh": "è¯¥ç ”ç©¶æ—¨åœ¨æ­ç¤º Muon ä¼˜åŒ–å™¨åœ¨è®­ç»ƒå¤§è¯­è¨€æ¨¡å‹ (LLMs) æ—¶ä¼˜äº Adam çš„åº•å±‚æœºåˆ¶ï¼Œå¹¶ä»å…³è”è®°å¿† (associative memory) çš„è§’åº¦è¿›è¡Œäº†æ·±å…¥æ¢è®¨ã€‚é€šè¿‡å¯¹ Transformer ç»„ä»¶çš„æ¶ˆèå®éªŒï¼Œç ”ç©¶å‘ç° LLMs çš„å…³è”è®°å¿†å‚æ•°ï¼Œå³ Value å’Œ Output (VO) æ³¨æ„åŠ›æƒé‡ä»¥åŠå‰é¦ˆç½‘ç»œ (FFNs)ï¼Œæ˜¯ Muon è¡¨ç°å“è¶Šçš„ä¸»è¦åŸå› ã€‚ç ”ç©¶æŒ‡å‡ºï¼Œåœ¨å…·æœ‰é•¿å°¾åˆ†å¸ƒ (heavy-tailed distributions) ç‰¹å¾çš„çœŸå®è¯­æ–™åº“ä¸­ï¼ŒMuon çš„æ›´æ–°è§„åˆ™èƒ½äº§ç”Ÿæ¯” Adam æ›´å„å‘åŒæ€§ (isotropic) çš„å¥‡å¼‚è°± (singular spectrum)ã€‚è¿™ç§ç‰¹æ€§ä½¿å¾— Muon åœ¨å¤„ç†å‡ºç°é¢‘ç‡è¾ƒä½çš„å°¾éƒ¨ç±»åˆ« (tail classes) æ—¶ï¼Œæ¯” Adam å…·æœ‰æ›´é«˜çš„ä¼˜åŒ–æ•ˆç‡ã€‚é™¤äº†ç»éªŒè¯æ®å¤–ï¼Œä½œè€…é€šè¿‡å¯¹ç±»åˆ«ä¸å¹³è¡¡æ•°æ®ä¸‹çš„å•å±‚å…³è”è®°å¿†æ¨¡å‹è¿›è¡Œç†è®ºåˆ†æï¼Œè¯æ˜äº† Muon æ— è®ºç‰¹å¾åµŒå…¥ (feature embeddings) å¦‚ä½•éƒ½èƒ½å®ç°å¹³è¡¡å­¦ä¹ ã€‚ç»¼ä¸Šæ‰€è¿°ï¼ŒMuon çš„æ ¸å¿ƒä¼˜åŠ¿åœ¨äºå…¶æ›´æ–°è§„åˆ™ä¸çº¿æ€§å…³è”è®°å¿†çš„å¤–ç§¯ç»“æ„ç›¸åŒ¹é…ï¼Œä»è€Œåœ¨é‡å°¾åˆ†å¸ƒä¸‹å®ç°äº†æ¯” Adam æ›´å¹³è¡¡ä¸”æœ‰æ•ˆçš„å°¾éƒ¨ç±»åˆ«å­¦ä¹ ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.26030v2",
      "published_date": "2025-09-30 10:04:08 UTC",
      "updated_date": "2025-10-05 09:26:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:38:59.493696+00:00"
    },
    {
      "arxiv_id": "2509.26015v1",
      "title": "Indirect Attention: Turning Context Misalignment into a Feature",
      "title_zh": "é—´æ¥æ³¨æ„åŠ›ï¼šåŒ–ä¸Šä¸‹æ–‡ä¸å¯¹é½ä¸ºç‰¹æ€§",
      "authors": [
        "Bissmella Bahaduri",
        "Hicham Talaoubrid",
        "Fangchen Feng",
        "Zuheng Ming",
        "Anissa Mokraoui"
      ],
      "abstract": "The attention mechanism has become a cornerstone of modern deep learning architectures, where keys and values are typically derived from the same underlying sequence or representation. This work explores a less conventional scenario, when keys and values originate from different sequences or modalities. Specifically, we first analyze the attention mechanism's behavior under noisy value features, establishing a critical noise threshold beyond which signal degradation becomes significant. Furthermore, we model context (key, value) misalignment as an effective form of structured noise within the value features, demonstrating that the noise induced by such misalignment can substantially exceed this critical threshold, thereby compromising standard attention's efficacy. Motivated by this, we introduce Indirect Attention, a modified attention mechanism that infers relevance indirectly in scenarios with misaligned context. We evaluate the performance of Indirect Attention across a range of synthetic tasks and real world applications, showcasing its superior ability to handle misalignment.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº† Attention æœºåˆ¶ä¸­ keys å’Œ values æºè‡ªä¸åŒåºåˆ—æˆ–æ¨¡æ€æ—¶çš„ Context Misalignment ç°è±¡ã€‚ä½œè€…é¦–å…ˆåˆ†æäº†åœ¨å™ªå£° Value ç‰¹å¾ä¸‹æ³¨æ„åŠ›æœºåˆ¶çš„è¡Œä¸ºï¼Œå¹¶ç¡®å®šäº†ä¸€ä¸ªå¯¼è‡´ä¿¡å·æ˜¾è‘—é€€åŒ–çš„å…³é”®å™ªå£°é˜ˆå€¼ã€‚ç ”ç©¶è¡¨æ˜ï¼ŒContext Misalignment å¯ä»¥è¢«å»ºæ¨¡ä¸ºä¸€ç§æœ‰æ•ˆçš„ç»“æ„åŒ–å™ªå£°ï¼Œä¸”è¿™ç§å¤±é…è¯±å¯¼çš„å™ªå£°å¾€å¾€è¿œè¶…å…³é”®é˜ˆå€¼ï¼Œä»è€ŒæŸå®³æ ‡å‡† Attention çš„æ•ˆèƒ½ã€‚ä¸ºæ­¤ï¼Œè¯¥è®ºæ–‡æå‡ºäº† Indirect Attentionï¼Œè¿™æ˜¯ä¸€ç§æ”¹è¿›çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œä¸“é—¨ç”¨äºåœ¨ä¸Šä¸‹æ–‡å¤±é…çš„åœºæ™¯ä¸‹é—´æ¥æ¨æ–­ç›¸å…³æ€§ã€‚é€šè¿‡åœ¨ä¸€ç³»åˆ—åˆæˆä»»åŠ¡å’Œç°å®ä¸–ç•Œåº”ç”¨ä¸­çš„è¯„ä¼°ï¼Œå®éªŒç»“æœè¯æ˜äº† Indirect Attention åœ¨å¤„ç†å¤±é…é—®é¢˜ä¸Šå…·æœ‰ä¼˜äºä¼ ç»Ÿæœºåˆ¶çš„æ€§èƒ½ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.26015v1",
      "published_date": "2025-09-30 09:44:00 UTC",
      "updated_date": "2025-09-30 09:44:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:38:20.473654+00:00"
    },
    {
      "arxiv_id": "2509.26008v1",
      "title": "PFDepth: Heterogeneous Pinhole-Fisheye Joint Depth Estimation via Distortion-aware Gaussian-Splatted Volumetric Fusion",
      "title_zh": "PFDepthï¼šåŸºäºç•¸å˜æ„ŸçŸ¥é«˜æ–¯æ³¼æº…ä½“ç§¯èåˆçš„å¼‚æ„é’ˆå­”-é±¼çœ¼è”åˆæ·±åº¦ä¼°è®¡",
      "authors": [
        "Zhiwei Zhang",
        "Ruikai Xu",
        "Weijian Zhang",
        "Zhizhong Zhang",
        "Xin Tan",
        "Jingyu Gong",
        "Yuan Xie",
        "Lizhuang Ma"
      ],
      "abstract": "In this paper, we present the first pinhole-fisheye framework for heterogeneous multi-view depth estimation, PFDepth. Our key insight is to exploit the complementary characteristics of pinhole and fisheye imagery (undistorted vs. distorted, small vs. large FOV, far vs. near field) for joint optimization. PFDepth employs a unified architecture capable of processing arbitrary combinations of pinhole and fisheye cameras with varied intrinsics and extrinsics. Within PFDepth, we first explicitly lift 2D features from each heterogeneous view into a canonical 3D volumetric space. Then, a core module termed Heterogeneous Spatial Fusion is designed to process and fuse distortion-aware volumetric features across overlapping and non-overlapping regions. Additionally, we subtly reformulate the conventional voxel fusion into a novel 3D Gaussian representation, in which learnable latent Gaussian spheres dynamically adapt to local image textures for finer 3D aggregation. Finally, fused volume features are rendered into multi-view depth maps. Through extensive experiments, we demonstrate that PFDepth sets a state-of-the-art performance on KITTI-360 and RealHet datasets over current mainstream depth networks. To the best of our knowledge, this is the first systematic study of heterogeneous pinhole-fisheye depth estimation, offering both technical novelty and valuable empirical insights.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†PFDepthï¼Œè¿™æ˜¯é¦–ä¸ªç”¨äºå¼‚æ„å¤šè§†å›¾æ·±åº¦ä¼°è®¡çš„Pinhole-Fisheyeæ¡†æ¶ï¼Œæ—¨åœ¨åˆ©ç”¨Pinholeå›¾åƒçš„å°è§†åœºè¿œåœºç‰¹æ€§ä¸Fisheyeå›¾åƒçš„å¤§è§†åœºè¿‘åœºæ„ŸçŸ¥ç­‰äº’è¡¥ä¼˜åŠ¿è¿›è¡Œè”åˆä¼˜åŒ–ã€‚PFDepthé‡‡ç”¨ç»Ÿä¸€æ¶æ„å¤„ç†ä»»æ„ç»„åˆçš„å¼‚æ„æ‘„åƒæœºï¼Œé¦–å…ˆå°†2Dç‰¹å¾æå‡è‡³è§„èŒƒçš„3Dç©ºé—´ï¼Œå¹¶åˆ©ç”¨Heterogeneous Spatial Fusionæ¨¡å—èåˆè·¨åŒºåŸŸçš„Distortion-awareä½“ç§¯ç‰¹å¾ã€‚ç ”ç©¶è¿›ä¸€æ­¥å°†ä¼ ç»Ÿçš„Voxel fusioné‡æ„ä¸ºæ–°å‹çš„3D Gaussian representationï¼Œé€šè¿‡å¯å­¦ä¹ çš„éšå¼Gaussian spheresåŠ¨æ€é€‚åº”å›¾åƒçº¹ç†ï¼Œå®ç°äº†æ›´ç²¾ç»†çš„3Dèšåˆä¸æ·±åº¦å›¾æ¸²æŸ“ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒPFDepthåœ¨KITTI-360å’ŒRealHetæ•°æ®é›†ä¸Šçš„è¡¨ç°å‡è¾¾åˆ°State-of-the-artæ°´å¹³ï¼Œä¼˜äºå½“å‰ä¸»æµæ·±åº¦ç½‘ç»œã€‚ä½œä¸ºå¯¹å¼‚æ„Pinhole-Fisheyeæ·±åº¦ä¼°è®¡çš„é¦–æ¬¡ç³»ç»Ÿæ€§ç ”ç©¶ï¼Œè¯¥å·¥ä½œåœ¨æŠ€æœ¯åˆ›æ–°å’Œå®è¯è§è§£æ–¹é¢å‡åšå‡ºäº†é‡è¦è´¡çŒ®ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ACM MM 2025 Conference",
      "pdf_url": "https://arxiv.org/pdf/2509.26008v1",
      "published_date": "2025-09-30 09:38:59 UTC",
      "updated_date": "2025-09-30 09:38:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:39:05.297517+00:00"
    },
    {
      "arxiv_id": "2509.26007v1",
      "title": "MARS: Audio Generation via Multi-Channel Autoregression on Spectrograms",
      "title_zh": "MARSï¼šåŸºäºé¢‘è°±å›¾å¤šé€šé“è‡ªå›å½’çš„éŸ³é¢‘ç”Ÿæˆ",
      "authors": [
        "Eleonora Ristori",
        "Luca Bindini",
        "Paolo Frasconi"
      ],
      "abstract": "Research on audio generation has progressively shifted from waveform-based approaches to spectrogram-based methods, which more naturally capture harmonic and temporal structures. At the same time, advances in image synthesis have shown that autoregression across scales, rather than tokens, improves coherence and detail. Building on these ideas, we introduce MARS (Multi-channel AutoRegression on Spectrograms), a framework that treats spectrograms as multi-channel images and employs channel multiplexing (CMX), a reshaping technique that lowers height and width without discarding information. A shared tokenizer provides consistent discrete representations across scales, enabling a transformer-based autoregressor to refine spectrograms from coarse to fine resolutions efficiently. Experiments on a large-scale dataset demonstrate that MARS performs comparably or better than state-of-the-art baselines across multiple evaluation metrics, establishing an efficient and scalable paradigm for high-fidelity audio generation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† MARS (Multi-channel AutoRegression on Spectrograms)ï¼Œè¿™æ˜¯ä¸€ç§é’ˆå¯¹é«˜ä¿çœŸéŸ³é¢‘ç”Ÿæˆçš„åˆ›æ–°æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡é¢‘è°±å›¾ (Spectrograms) æ›´è‡ªç„¶åœ°æ•æ‰éŸ³é¢‘çš„è°æ³¢ä¸æ—¶é—´ç»“æ„ã€‚å€Ÿé‰´å›¾åƒåˆæˆä¸­è·¨å°ºåº¦è‡ªå›å½’ä¼˜äº Token è‡ªå›å½’çš„è¿›å±•ï¼ŒMARS å°†é¢‘è°±å›¾è§†ä¸ºå¤šé€šé“å›¾åƒï¼Œå¹¶å¼•å…¥äº† Channel Multiplexing (CMX) é‡å¡‘æŠ€æœ¯ï¼Œåœ¨ä¸ä¸¢å¤±ä¿¡æ¯çš„æƒ…å†µä¸‹æœ‰æ•ˆé™ä½ç‰¹å¾ç»´åº¦ã€‚æ¡†æ¶é‡‡ç”¨å…±äº«çš„ Tokenizer ä¸ºä¸åŒå°ºåº¦æä¾›ä¸€è‡´çš„ç¦»æ•£è¡¨ç¤ºï¼Œä½¿åŸºäº Transformer çš„è‡ªå›å½’å™¨èƒ½é«˜æ•ˆåœ°å®ç°ä»ç²—ç³™åˆ°ç²¾ç»†çš„åˆ†è¾¨ç‡ç»†åŒ–ã€‚åœ¨å¤§è§„æ¨¡æ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜ï¼ŒMARS åœ¨å¤šé¡¹æ ¸å¿ƒè¯„ä¼°æŒ‡æ ‡ä¸Šä¼˜äºæˆ–ç­‰åŒäºå½“å‰çš„ SOTA åŸºçº¿æ¨¡å‹ã€‚è¯¥ç ”ç©¶ä¸ºéŸ³é¢‘ç”Ÿæˆé¢†åŸŸæä¾›äº†ä¸€ç§é«˜æ•ˆã€å¯æ‰©å±•ä¸”å…·å¤‡é«˜ä¿çœŸè¡¨ç°çš„ç”Ÿæˆæ–°èŒƒå¼ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.26007v1",
      "published_date": "2025-09-30 09:38:02 UTC",
      "updated_date": "2025-09-30 09:38:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:38:36.789364+00:00"
    },
    {
      "arxiv_id": "2509.26004v2",
      "title": "Learning Egocentric In-Hand Object Segmentation through Weak Supervision from Human Narrations",
      "title_zh": "åŸºäºäººç±»å™è¿°å¼±ç›‘ç£çš„ç¬¬ä¸€äººç§°è§†è§’æ‰‹ä¸­ç‰©ä½“åˆ†å‰²å­¦ä¹ ",
      "authors": [
        "Nicola Messina",
        "Rosario Leonardi",
        "Luca Ciampi",
        "Fabio Carrara",
        "Giovanni Maria Farinella",
        "Fabrizio Falchi",
        "Antonino Furnari"
      ],
      "abstract": "Pixel-level recognition of objects manipulated by the user from egocentric images enables key applications spanning assistive technologies, industrial safety, and activity monitoring. However, progress in this area is currently hindered by the scarcity of annotated datasets, as existing approaches rely on costly manual labels. In this paper, we propose to learn human-object interaction detection leveraging narrations $\\unicode{x2013}$ natural language descriptions of the actions performed by the camera wearer which contain clues about manipulated objects. We introduce Narration-Supervised in-Hand Object Segmentation (NS-iHOS), a novel task where models have to learn to segment in-hand objects by learning from natural-language narrations in a weakly-supervised regime. Narrations are then not employed at inference time. We showcase the potential of the task by proposing Weakly-Supervised In-hand Object Segmentation from Human Narrations (WISH), an end-to-end model distilling knowledge from narrations to learn plausible hand-object associations and enable in-hand object segmentation without using narrations at test time. We benchmark WISH against different baselines based on open-vocabulary object detectors and vision-language models. Experiments on EPIC-Kitchens and Ego4D show that WISH surpasses all baselines, recovering more than 50% of the performance of fully supervised methods, without employing fine-grained pixel-wise annotations. Code and data can be found at https://fpv-iplab.github.io/WISH.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç¬¬ä¸€äººç§°è§†è§’(Egocentric)ä¸‹å¯¹æ‰‹éƒ¨æ“ä½œç‰©ä½“è¿›è¡Œåƒç´ çº§è¯†åˆ«æ—¶é¢ä¸´çš„æ ‡æ³¨æ•°æ®ç¨€ç¼ºé—®é¢˜ï¼Œæå‡ºåˆ©ç”¨äººç±»å™è¿°(Human Narrations)ä½œä¸ºå¼±ç›‘ç£ä¿¡å·æ¥å­¦ä¹ äººæœºäº¤äº’æ£€æµ‹ã€‚è®ºæ–‡å¼•å…¥äº†å™è¿°ç›‘ç£æ‰‹éƒ¨ç‰©ä½“åˆ†å‰²(NS-iHOS)è¿™ä¸€æ–°ä»»åŠ¡ï¼Œå¹¶å¼€å‘äº†åä¸ºWISHçš„ç«¯åˆ°ç«¯æ¨¡å‹ï¼Œé€šè¿‡ä»è‡ªç„¶è¯­è¨€å™è¿°ä¸­è’¸é¦çŸ¥è¯†æ¥å­¦ä¹ æ‰‹éƒ¨ä¸ç‰©ä½“çš„å…³è”ï¼Œä»è€Œåœ¨æµ‹è¯•é˜¶æ®µæ— éœ€å™è¿°è¾“å…¥å³å¯å®ç°ç‰©ä½“åˆ†å‰²ã€‚åœ¨EPIC-Kitchenså’ŒEgo4Dæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒWISHçš„æ€§èƒ½æ˜¾è‘—ä¼˜äºåŸºäºå¼€æ”¾è¯æ±‡ç‰©ä½“æ£€æµ‹å™¨(Open-vocabulary Object Detectors)å’Œè§†è§‰è¯­è¨€æ¨¡å‹(VLMs)çš„åŸºçº¿ã€‚åœ¨å®Œå…¨ä¸ä½¿ç”¨ç²¾ç»†åƒç´ çº§æ ‡æ³¨çš„æƒ…å†µä¸‹ï¼Œè¯¥æ–¹æ³•æˆåŠŸæ¢å¤äº†å…¨ç›‘ç£æ–¹æ³•50%ä»¥ä¸Šçš„æ€§èƒ½ï¼Œä¸ºåˆ©ç”¨è‡ªç„¶è¯­è¨€å¼±ç›‘ç£è§£å†³å¤æ‚çš„ç¬¬ä¸€äººç§°è§†è§’è§†è§‰ä»»åŠ¡æä¾›äº†æœ‰æ•ˆè·¯å¾„ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Under consideration at Pattern Recognition Letters",
      "pdf_url": "https://arxiv.org/pdf/2509.26004v2",
      "published_date": "2025-09-30 09:34:55 UTC",
      "updated_date": "2025-12-02 12:27:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:38:40.484047+00:00"
    },
    {
      "arxiv_id": "2509.26002v1",
      "title": "Towards Human Engagement with Realistic AI Combat Pilots",
      "title_zh": "è¿ˆå‘ä¸é€¼çœŸ AI æˆ˜æ–—æœºé£è¡Œå‘˜çš„äººç±»äº¤äº’",
      "authors": [
        "Ardian Selmonaj",
        "Giacomo Del Rio",
        "Adrian Schneider",
        "Alessandro Antonucci"
      ],
      "abstract": "We present a system that enables real-time interaction between human users and agents trained to control fighter jets in simulated 3D air combat scenarios. The agents are trained in a dedicated environment using Multi-Agent Reinforcement Learning. A communication link is developed to allow seamless deployment of trained agents into VR-Forces, a widely used defense simulation tool for realistic tactical scenarios. This integration allows mixed simulations where human-controlled entities engage with intelligent agents exhibiting distinct combat behaviors. Our interaction model creates new opportunities for human-agent teaming, immersive training, and the exploration of innovative tactics in defense contexts.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªèƒ½å¤Ÿè®©çœŸå®äººç±»ç”¨æˆ·ä¸ AI æˆ˜æ–—æœºé£è¡Œå‘˜åœ¨ 3D ç©ºæˆ˜æ¨¡æ‹Ÿåœºæ™¯ä¸­è¿›è¡Œå®æ—¶äº¤äº’çš„ç³»ç»Ÿã€‚è¿™äº›æ™ºèƒ½ä½“æ˜¯åœ¨ä¸“ç”¨ç¯å¢ƒä¸­é€šè¿‡å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹  (Multi-Agent Reinforcement Learning) è®­ç»ƒè€Œæˆçš„ï¼Œèƒ½å¤Ÿå±•ç°å‡ºç‹¬ç‰¹çš„æˆ˜æ–—è¡Œä¸ºã€‚ä¸ºäº†å®ç°å®é™…éƒ¨ç½²ï¼Œç ”ç©¶å¼€å‘äº†ä¸€ä¸ªé€šä¿¡é“¾è·¯ï¼Œä½¿è®­ç»ƒå¥½çš„æ™ºèƒ½ä½“èƒ½å¤Ÿæ— ç¼æ¥å…¥å¹¿æ³›ç”¨äºå›½é˜²æ¨¡æ‹Ÿçš„ VR-Forces ä»¿çœŸå·¥å…·ä¸­ã€‚è¿™ç§é›†æˆæ”¯æŒæ··åˆæ¨¡æ‹Ÿç¯å¢ƒï¼Œå…è®¸äººç±»æ§åˆ¶çš„å®ä½“ä¸å…·å¤‡æ™ºèƒ½è¡Œä¸ºçš„ AI é£è¡Œå‘˜è¿›è¡Œå¯¹æŠ—ã€‚è¯¥äº¤äº’æ¨¡å‹ä¸ºäººç±»-æ™ºèƒ½ä½“åä½œ (human-agent teaming)ã€æ²‰æµ¸å¼è®­ç»ƒä»¥åŠåœ¨å›½é˜²èƒŒæ™¯ä¸‹æ¢ç´¢åˆ›æ–°æˆ˜æœ¯æä¾›äº†æ–°çš„å¯èƒ½æ€§ã€‚",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.LG",
        "cs.MA",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "13th International Conference on Human-Agent Interaction (HAI) 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.26002v1",
      "published_date": "2025-09-30 09:34:10 UTC",
      "updated_date": "2025-09-30 09:34:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:38:39.984266+00:00"
    },
    {
      "arxiv_id": "2509.25998v3",
      "title": "VRWKV-Editor: Reducing quadratic complexity in transformer-based video editing",
      "title_zh": "VRWKV-Editorï¼šé™ä½åŸºäº Transformer çš„è§†é¢‘ç¼–è¾‘ä¸­çš„äºŒæ¬¡å¤æ‚åº¦",
      "authors": [
        "Abdelilah Aitrouga",
        "Youssef Hmamouche",
        "Amal El Fallah Seghrouchni"
      ],
      "abstract": "In light of recent progress in video editing, deep learning models focusing on both spatial and temporal dependencies have emerged as the primary method. However, these models suffer from the quadratic computational complexity of traditional attention mechanisms, making them difficult to adapt to long-duration and high-resolution videos. This limitation restricts their applicability in practical contexts such as real-time video processing. To tackle this challenge, we introduce a method to reduce both time and space complexity of these systems by proposing VRWKV-Editor, a novel video editing model that integrates a linear spatio-temporal aggregation module into video-based diffusion models. VRWKV-Editor leverages bidirectional weighted key-value recurrence mechanism of the RWKV transformer to capture global dependencies while preserving temporal coherence, achieving linear complexity without sacrificing quality. Extensive experiments demonstrate that the proposed method achieves up to 3.7x speedup and 60% lower memory usage compared to state-of-the-art diffusion-based video editing methods, while maintaining competitive performance in frame consistency and text alignment. Furthermore, a comparative analysis we conducted on videos with different sequence lengths confirms that the gap in editing speed between our approach and architectures with self-attention becomes more significant with long videos.",
      "tldr_zh": "é’ˆå¯¹åŸºäº Transformer çš„è§†é¢‘ç¼–è¾‘æ¨¡å‹åœ¨å¤„ç†é•¿è§†é¢‘å’Œé«˜åˆ†è¾¨ç‡å†…å®¹æ—¶é¢ä¸´çš„ Self-Attention äºŒæ¬¡è®¡ç®—å¤æ‚åº¦éš¾é¢˜ï¼Œè¯¥ç ”ç©¶æå‡ºäº† VRWKV-Editorã€‚è¿™æ˜¯ä¸€ç§å°†çº¿æ€§æ—¶ç©ºèšåˆæ¨¡å—é›†æˆåˆ°è§†é¢‘æ‰©æ•£æ¨¡å‹ (Diffusion Models) ä¸­çš„åˆ›æ–°æ¡†æ¶ï¼Œæ—¨åœ¨åŒæ—¶é™ä½ç³»ç»Ÿçš„æ—¶é—´å’Œç©ºé—´å¤æ‚åº¦ã€‚VRWKV-Editor å€Ÿé‰´äº† RWKV Transformer çš„åŒå‘åŠ æƒé”®å€¼é€’å½’æœºåˆ¶ (Bidirectional weighted key-value recurrence)ï¼Œåœ¨æœ‰æ•ˆæ•è·å…¨å±€ä¾èµ–å…³ç³»å¹¶ä¿æŒæ—¶é—´ç›¸å¹²æ€§ (Temporal coherence) çš„åŒæ—¶ï¼ŒæˆåŠŸå°†å¤æ‚åº¦é™è‡³çº¿æ€§æ°´å¹³ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¿æŒå¸§ä¸€è‡´æ€§ (Frame consistency) å’Œæ–‡æœ¬å¯¹é½ (Text alignment) ç«äº‰åŠ›çš„å‰æä¸‹ï¼Œç›¸æ¯” SOTA æ‰©æ•£ç¼–è¾‘æ¨¡å‹å®ç°äº† 3.7 å€çš„æ¨ç†åŠ é€Ÿå’Œ 60% çš„å†…å­˜æ¶ˆè€—é™ä½ã€‚é’ˆå¯¹ä¸åŒåºåˆ—é•¿åº¦è§†é¢‘çš„å¯¹æ¯”åˆ†æè¿›ä¸€æ­¥ç¡®è®¤ï¼Œéšç€è§†é¢‘é•¿åº¦å¢åŠ ï¼ŒVRWKV-Editor ç›¸æ¯”ä¼ ç»Ÿæ¶æ„çš„æ•ˆç‡ä¼˜åŠ¿å°†å˜å¾—æ›´åŠ æ˜¾è‘—ï¼Œä¸ºå®æ—¶è§†é¢‘å¤„ç†å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25998v3",
      "published_date": "2025-09-30 09:30:23 UTC",
      "updated_date": "2025-12-04 03:28:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:38:52.866737+00:00"
    },
    {
      "arxiv_id": "2509.25992v1",
      "title": "MHINDR -- a DSM5 based mental health diagnosis and recommendation framework using LLM",
      "title_zh": "MHINDRï¼šåŸºäº DSM-5 ä¸å¤§è¯­è¨€æ¨¡å‹çš„å¿ƒç†å¥åº·è¯Šæ–­åŠå»ºè®®æ¡†æ¶",
      "authors": [
        "Vaishali Agarwal",
        "Sachin Thukral",
        "Arnab Chatterjee"
      ],
      "abstract": "Mental health forums offer valuable insights into psychological issues, stressors, and potential solutions. We propose MHINDR, a large language model (LLM) based framework integrated with DSM-5 criteria to analyze user-generated text, dignose mental health conditions, and generate personalized interventions and insights for mental health practitioners. Our approach emphasizes on the extraction of temporal information for accurate diagnosis and symptom progression tracking, together with psychological features to create comprehensive mental health summaries of users. The framework delivers scalable, customizable, and data-driven therapeutic recommendations, adaptable to diverse clinical contexts, patient needs, and workplace well-being programs.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†MHINDRï¼Œè¿™æ˜¯ä¸€ç§åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLM)å¹¶æ•´åˆäº†DSM-5æ ‡å‡†çš„å¿ƒç†å¥åº·è¯Šæ–­ä¸å»ºè®®æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡åˆ†æç”¨æˆ·ç”Ÿæˆçš„æ–‡æœ¬å†…å®¹ï¼Œå®ç°å¯¹å¿ƒç†å¥åº·çŠ¶å†µçš„è¯†åˆ«ï¼Œå¹¶ä¸ºä»ä¸šè€…æä¾›ä¸ªæ€§åŒ–çš„å¹²é¢„æªæ–½ã€‚ç ”ç©¶çš„æ ¸å¿ƒåœ¨äºæå–æ—¶é—´ä¿¡æ¯(temporal information)ä»¥è¾…åŠ©ç²¾å‡†è¯Šæ–­å¹¶è¿½è¸ªç—‡çŠ¶æ¼”å˜ï¼ŒåŒæ—¶ç»“åˆå¿ƒç†ç‰¹å¾(psychological features)ç”Ÿæˆå…¨é¢çš„ç”¨æˆ·å¿ƒç†å¥åº·æ‘˜è¦ã€‚MHINDRå±•ç°äº†æé«˜çš„å¯æ‰©å±•æ€§ä¸å®šåˆ¶åŒ–èƒ½åŠ›ï¼Œèƒ½å¤Ÿé’ˆå¯¹å¤šæ ·åŒ–çš„ä¸´åºŠç¯å¢ƒã€æ‚£è€…éœ€æ±‚åŠèŒåœºå¥åº·è®¡åˆ’æä¾›æ•°æ®é©±åŠ¨çš„æ²»ç–—å»ºè®®ã€‚è¯¥æ¡†æ¶ä¸ºå¿ƒç†å¥åº·é¢†åŸŸçš„è‡ªåŠ¨åŒ–è¯Šæ–­å’Œä¸ªæ€§åŒ–å¹²é¢„æä¾›äº†åˆ›æ–°çš„æ•°å­—åŒ–è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.SI",
      "comment": "7 pages, 1 figure, 4 tables",
      "pdf_url": "https://arxiv.org/pdf/2509.25992v1",
      "published_date": "2025-09-30 09:26:38 UTC",
      "updated_date": "2025-09-30 09:26:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:39:26.489889+00:00"
    },
    {
      "arxiv_id": "2509.25991v2",
      "title": "Towards Unified Multimodal Misinformation Detection in Social Media: A Benchmark Dataset and Baseline",
      "title_zh": "è¿ˆå‘ç¤¾äº¤åª’ä½“ç»Ÿä¸€å¤šæ¨¡æ€è™šå‡ä¿¡æ¯æ£€æµ‹ï¼šåŸºå‡†æ•°æ®é›†ä¸åŸºå‡†æ¨¡å‹",
      "authors": [
        "Haiyang Li",
        "Yaxiong Wang",
        "Shengeng Tang",
        "Lianwei Wu",
        "Lechao Cheng",
        "Zhun Zhong"
      ],
      "abstract": "In recent years, detecting fake multimodal content on social media has drawn increasing attention. Two major forms of deception dominate: human-crafted misinformation (e.g., rumors and misleading posts) and AI-generated content produced by image synthesis models or vision-language models (VLMs). Although both share deceptive intent, they are typically studied in isolation. NLP research focuses on human-written misinformation, while the CV community targets AI-generated artifacts. As a result, existing models are often specialized for only one type of fake content. In real-world scenarios, however, the type of a multimodal post is usually unknown, limiting the effectiveness of such specialized systems. To bridge this gap, we construct the Omnibus Dataset for Multimodal News Deception (OmniFake), a comprehensive benchmark of 127K samples that integrates human-curated misinformation from existing resources with newly synthesized AI-generated examples. Based on this dataset, we propose Unified Multimodal Fake Content Detection (UMFDet), a framework designed to handle both forms of deception. UMFDet leverages a VLM backbone augmented with a Category-aware Mixture-of-Experts (MoE) Adapter to capture category-specific cues, and an attribution chain-of-thought mechanism that provides implicit reasoning guidance for locating salient deceptive signals. Extensive experiments demonstrate that UMFDet achieves robust and consistent performance across both misinformation types, outperforming specialized baselines and offering a practical solution for real-world multimodal deception detection.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç¤¾äº¤åª’ä½“ä¸­äººä¸ºè™šå‡ä¿¡æ¯ä¸ AI-generated å†…å®¹é€šå¸¸è¢«éš”ç¦»ç ”ç©¶çš„ç°çŠ¶ï¼Œæå‡ºäº†ç»Ÿä¸€å¤šæ¨¡æ€è¯¯å¯¼ä¿¡æ¯æ£€æµ‹çš„æ–°è§†è§’ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œä½œè€…æ„å»ºäº†åŒ…å«127Kä¸ªæ ·æœ¬çš„ç»¼åˆåŸºå‡†æ•°æ®é›† OmniFakeï¼Œå°†ç°æœ‰çš„äººä¸ºè¯¯å¯¼ä¿¡æ¯ä¸æ–°åˆæˆçš„ AI ç”Ÿæˆç¤ºä¾‹è¿›è¡Œæ•´åˆã€‚åŸºäºè¯¥æ•°æ®é›†ï¼Œç ”ç©¶æå‡ºäº† UMFDet æ¡†æ¶ï¼Œåˆ©ç”¨ VLM éª¨å¹²ç½‘ç»œé…åˆæ„ŸçŸ¥ç±»åˆ«çš„ Mixture-of-Experts (MoE) Adapter æ¥æ•è·ç‰¹å®šç±»åˆ«çš„æ¬ºéª—ç‰¹å¾ã€‚åŒæ—¶ï¼Œè¯¥æ¡†æ¶å¼•å…¥äº†å½’å›  Chain-of-Thought æœºåˆ¶ï¼Œé€šè¿‡éšå¼æ¨ç†å¼•å¯¼æ¨¡å‹ç²¾å‡†å®šä½æ˜¾è‘—çš„æ¬ºéª—ä¿¡å·ã€‚å®éªŒè¯æ˜ï¼ŒUMFDet åœ¨ä¸¤ç§å½¢å¼çš„æ¬ºéª—æ£€æµ‹ä¸­å‡è¡¨ç°å‡ºç¨³å¥ä¸”ä¸€è‡´çš„æ€§èƒ½ï¼Œä¼˜äºå„ç±»ä¸“ä¸šåŒ–åŸºçº¿æ¨¡å‹ï¼Œä¸ºç°å®åœºæ™¯ä¸‹çš„å¤šæ¨¡æ€æ¬ºéª—æ£€æµ‹æä¾›äº†æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25991v2",
      "published_date": "2025-09-30 09:26:32 UTC",
      "updated_date": "2025-10-15 10:52:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:39:31.592695+00:00"
    },
    {
      "arxiv_id": "2509.25987v2",
      "title": "R-Log: Incentivizing Log Analysis Capability in LLMs via Reasoning-based Reinforcement Learning",
      "title_zh": "R-Logï¼šé€šè¿‡åŸºäºæ¨ç†çš„å¼ºåŒ–å­¦ä¹ æå‡å¤§è¯­è¨€æ¨¡å‹çš„æ—¥å¿—åˆ†æèƒ½åŠ›",
      "authors": [
        "Yilun Liu",
        "Ziang Chen",
        "Song Xu",
        "Minggui He",
        "Shimin Tao",
        "Weibin Meng",
        "Yuming Xie",
        "Tao Han",
        "Chunguang Zhao",
        "Jingzhou Du",
        "Daimeng Wei",
        "Shenglin Zhang",
        "Yongqian Sun"
      ],
      "abstract": "The growing complexity of log data in modern software systems has prompted the use of Large Language Models (LLMs) for automated log analysis. Current approaches typically rely on direct supervised fine-tuning (SFT) on log-label pairs. However, this exacerbates the domain discrepancy between general-purpose LLMs and specialized log data, causing overfitting. Furthermore, SFT's imbalanced loss computation often allows lengthy contexts to overwhelm critical, concise details in model answers, leading to hallucinations. To address these limitations, we propose R-Log, a novel reasoning-based paradigm that mirrors the structured, step-by-step analytical process of human engineers. This approach enhances generalizability by learning the underlying rules behind conclusions. We further employ Reinforcement Learning (RL) to optimize the model within a simulated O&M environment, thereby reducing hallucinations by directly rewarding correct outcomes. R-Log is first cold-started on a curated dataset of 2k+ reasoning trajectories, guided by 13 strategies from manual O&M practices, to establish an initial reasoning capability. This ability is then refined via RL using a joint reward function. Empirical evaluations on real-world logs show that R-Log outperforms existing methods across five log analysis tasks, particularly in unseen scenarios (by 228.05%). We also designed R-Log-fast with 5x speedup while keeping 93% of the efficacy.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°ä»£è½¯ä»¶ç³»ç»Ÿæ—¥å¿—æ•°æ®çš„å¤æ‚æ€§ï¼Œæå‡ºäº†R-Logæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨æ—¥å¿—åˆ†æä¸­å› ç›‘ç£å¾®è°ƒ(SFT)å¯¼è‡´çš„è¿‡æ‹Ÿåˆã€é¢†åŸŸåå·®åŠå¹»è§‰é—®é¢˜ã€‚R-Logå¼•å…¥äº†ä¸€ç§åŸºäºæ¨ç†çš„æ–°å‹èŒƒå¼ï¼Œé€šè¿‡æ¨¡æ‹Ÿäººç±»å·¥ç¨‹å¸ˆç»“æ„åŒ–çš„é€æ­¥åˆ†æè¿‡ç¨‹ï¼Œä½¿æ¨¡å‹å­¦ä¹ ç»“è®ºèƒŒåçš„åº•å±‚è§„åˆ™ï¼Œä»è€Œæ˜¾è‘—å¢å¼ºå…¶é€šç”¨æ€§ã€‚ä¸ºäº†è¿›ä¸€æ­¥é™ä½å¹»è§‰ï¼Œè¯¥æ¡†æ¶åœ¨æ¨¡æ‹Ÿçš„è¿ç»´(O&M)ç¯å¢ƒä¸­é‡‡ç”¨å¼ºåŒ–å­¦ä¹ (RL)è¿›è¡Œä¼˜åŒ–ï¼Œå¹¶åˆ©ç”¨è”åˆå¥–åŠ±å‡½æ•°ç›´æ¥å¼•å¯¼æ¨¡å‹ç”Ÿæˆå‡†ç¡®ç»“æœã€‚ç ”ç©¶é¦–å…ˆé€šè¿‡åŒ…å«2000å¤šæ¡æ¨ç†è½¨è¿¹çš„ç²¾é€‰æ•°æ®é›†è¿›è¡Œå†·å¯åŠ¨ï¼Œå¹¶ç»“åˆ13ç§æ‰‹åŠ¨è¿ç»´ç­–ç•¥åˆæ­¥å»ºç«‹æ¨ç†èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒR-Logåœ¨äº”é¡¹çœŸå®æ—¥å¿—åˆ†æä»»åŠ¡ä¸­å‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œåœ¨æœªè§åœºæ™¯ä¸‹çš„æ€§èƒ½æå‡é«˜è¾¾228.05%ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜æ¨å‡ºäº†R-Log-fastç‰ˆæœ¬ï¼Œåœ¨ä¿ç•™93%æ•ˆèƒ½çš„åŸºç¡€ä¸Šå®ç°äº†5å€çš„æ¨ç†åŠ é€Ÿã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted by ICSE 2026 (SEIP Track)",
      "pdf_url": "https://arxiv.org/pdf/2509.25987v2",
      "published_date": "2025-09-30 09:19:31 UTC",
      "updated_date": "2025-12-29 10:05:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:39:37.692021+00:00"
    },
    {
      "arxiv_id": "2509.25979v1",
      "title": "Reconcile Certified Robustness and Accuracy for DNN-based Smoothed Majority Vote Classifier",
      "title_zh": "å…¼é¡¾åŸºäº DNN çš„å¹³æ»‘å¤šæ•°æŠ•ç¥¨åˆ†ç±»å™¨çš„è®¤è¯é²æ£’æ€§ä¸å‡†ç¡®ç‡",
      "authors": [
        "Gaojie Jin",
        "Xinping Yi",
        "Xiaowei Huang"
      ],
      "abstract": "Within the PAC-Bayesian framework, the Gibbs classifier (defined on a posterior $Q$) and the corresponding $Q$-weighted majority vote classifier are commonly used to analyze the generalization performance. However, there exists a notable lack in theoretical research exploring the certified robustness of majority vote classifier and its interplay with generalization. In this study, we develop a generalization error bound that possesses a certified robust radius for the smoothed majority vote classifier (i.e., the $Q$-weighted majority vote classifier with smoothed inputs); In other words, the generalization bound holds under any data perturbation within the certified robust radius. As a byproduct, we find that the underpinnings of both the generalization bound and the certified robust radius draw, in part, upon weight spectral norm, which thereby inspires the adoption of spectral regularization in smooth training to boost certified robustness. Utilizing the dimension-independent property of spherical Gaussian inputs in smooth training, we propose a novel and inexpensive spectral regularizer to enhance the smoothed majority vote classifier. In addition to the theoretical contribution, a set of empirical results is provided to substantiate the effectiveness of our proposed method.",
      "tldr_zh": "è¯¥ç ”ç©¶åœ¨ PAC-Bayesian æ¡†æ¶ä¸‹æ¢è®¨äº† Gibbs classifier åŠå…¶å¯¹åº”çš„ $Q$-weighted majority vote classifier çš„æ³›åŒ–æ€§èƒ½ä¸è®¤è¯é²æ£’æ€§ (certified robustness) ä¹‹é—´çš„å…³ç³»ã€‚ç ”ç©¶è€…ä¸ºå¹³æ»‘å¤šæ•°æŠ•ç¥¨åˆ†ç±»å™¨ (smoothed majority vote classifier) å¼€å‘äº†ä¸€ç§åŒ…å«è®¤è¯é²æ£’åŠå¾„ (certified robust radius) çš„æ³›åŒ–è¯¯å·®ç•Œ (generalization error bound)ï¼Œç¡®ä¿åœ¨è¯¥åŠå¾„å†…çš„ä»»ä½•æ•°æ®æ‰°åŠ¨ä¸‹ç•Œé™å‡æˆç«‹ã€‚ç ”ç©¶å‘ç°ï¼Œæ³›åŒ–ç•Œå’Œè®¤è¯é²æ£’åŠå¾„çš„ç†è®ºåŸºç¡€å‡åœ¨ä¸€å®šç¨‹åº¦ä¸Šå–å†³äºæƒé‡è°±èŒƒæ•° (weight spectral norm)ï¼Œè¿™å¯å‘äº†åœ¨å¹³æ»‘è®­ç»ƒ (smooth training) ä¸­é‡‡ç”¨è°±æ­£åˆ™åŒ– (spectral regularization) æ¥æå‡é²æ£’æ€§ã€‚åˆ©ç”¨çƒå½¢é«˜æ–¯è¾“å…¥ (spherical Gaussian inputs) çš„ç»´åº¦æ— å…³ç‰¹æ€§ï¼Œç ”ç©¶æå‡ºäº†ä¸€ç§æ–°å‹ä¸”ä½æˆæœ¬çš„è°±æ­£åˆ™åŒ–å™¨ (spectral regularizer) ä»¥å¢å¼ºåˆ†ç±»å™¨æ€§èƒ½ã€‚è¯¥å·¥ä½œä¸ä»…åœ¨ç†è®ºä¸Šåè°ƒäº†å‡†ç¡®æ€§ä¸é²æ£’æ€§çš„çŸ›ç›¾ï¼Œè¿˜é€šè¿‡å®è¯ç»“æœéªŒè¯äº†æ‰€ææ–¹æ³•åœ¨æå‡å¹³æ»‘å¤šæ•°æŠ•ç¥¨åˆ†ç±»å™¨æ•ˆèƒ½æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Under Review",
      "pdf_url": "https://arxiv.org/pdf/2509.25979v1",
      "published_date": "2025-09-30 09:11:10 UTC",
      "updated_date": "2025-09-30 09:11:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:39:48.894203+00:00"
    },
    {
      "arxiv_id": "2509.25977v2",
      "title": "Data-Free Continual Learning of Server Models in Model-Heterogeneous Cloud-Device Collaboration",
      "title_zh": "æ¨¡å‹å¼‚æ„äº‘-ç«¯åä½œä¸‹çš„æœåŠ¡ç«¯æ¨¡å‹æ— æ•°æ®æŒç»­å­¦ä¹ ",
      "authors": [
        "Xiao Zhang",
        "Zengzhe Chen",
        "Yuan Yuan",
        "Yifei Zou",
        "Fuzhen Zhuang",
        "Wenyu Jiao",
        "Yuke Wang",
        "Dongxiao Yu"
      ],
      "abstract": "The rise of cloud-device collaborative computing has enabled intelligent services to be delivered across distributed edge devices while leveraging centralized cloud resources. In this paradigm, federated learning (FL) has become a key enabler for privacy-preserving model training without transferring raw data from edge devices to the cloud. However, with the continuous emergence of new data and increasing model diversity, traditional federated learning faces significant challenges, including inherent issues of data heterogeneity, model heterogeneity and catastrophic forgetting, along with new challenge of knowledge misalignment. In this study, we introduce FedDCL, a novel framework designed to enable data-free continual learning of the server model in a model-heterogeneous federated setting. We leverage pre-trained diffusion models to extract lightweight class-specific prototypes, which confer a threefold data-free advantage, enabling: (1) generation of synthetic data for the current task to augment training and counteract non-IID data distributions; (2) exemplar-free generative replay for retaining knowledge from previous tasks; and (3) data-free dynamic knowledge transfer from heterogeneous devices to the cloud server.Experimental results on various datasets demonstrate the effectiveness of FedDCL, showcasing its potential to enhance the generalizability and practical applicability of federated cloud-device collaboration in dynamic settings.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æå‡ºäº† FedDCLï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨è§£å†³æ¨¡å‹å¼‚æ„ (model-heterogeneous) è”é‚¦å­¦ä¹ è®¾ç½®ä¸­æœåŠ¡å™¨æ¨¡å‹æ— æ•°æ®æŒç»­å­¦ä¹  (data-free continual learning) çš„æ–°é¢–æ¡†æ¶ã€‚è¯¥æ¡†æ¶é’ˆå¯¹äº‘è¾¹åä½œè®¡ç®—ä¸­é¢ä¸´çš„æ•°æ®å¼‚æ„æ€§ (data heterogeneity)ã€æ¨¡å‹å¼‚æ„æ€§ã€ç¾éš¾æ€§é—å¿˜ (catastrophic forgetting) ä»¥åŠçŸ¥è¯†é”™ä½ (knowledge misalignment) ç­‰æ ¸å¿ƒæŒ‘æˆ˜è€Œè®¾è®¡ã€‚FedDCL æ ¸å¿ƒåœ¨äºåˆ©ç”¨é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹ (diffusion models) æå–è½»é‡çº§çš„ç±»åˆ«ç‰¹å®šåŸå‹ (class-specific prototypes)ï¼Œä»è€Œå®ç°å¤šé‡æ— æ•°æ®ä¼˜åŠ¿ã€‚è¯¥æ–¹æ³•é¦–å…ˆé€šè¿‡ç”Ÿæˆçš„åˆæˆæ•°æ®å¢å¼ºå½“å‰ä»»åŠ¡è®­ç»ƒä»¥å¯¹æŠ—éç‹¬ç«‹åŒåˆ†å¸ƒ (non-IID) æ•°æ®åˆ†å¸ƒï¼Œéšååˆ©ç”¨æ— æ ·æœ¬ç”Ÿæˆå›æ”¾ (exemplar-free generative replay) æŠ€æœ¯ä¿ç•™ä»¥å¾€ä»»åŠ¡çŸ¥è¯†ã€‚æ­¤å¤–ï¼Œå®ƒè¿˜å®ç°äº†ä»å¼‚æ„è®¾å¤‡åˆ°äº‘ç«¯æœåŠ¡å™¨çš„æ— æ•°æ®åŠ¨æ€çŸ¥è¯†è½¬ç§» (data-free dynamic knowledge transfer)ã€‚å®éªŒç»“æœè¯æ˜äº† FedDCL åœ¨å¤šç§æ•°æ®é›†ä¸Šçš„æœ‰æ•ˆæ€§ï¼Œå±•ç°äº†å…¶åœ¨åŠ¨æ€ç¯å¢ƒä¸‹æå‡è”é‚¦äº‘è¾¹åä½œæ³›åŒ–èƒ½åŠ›å’Œå®é™…åº”ç”¨ä»·å€¼çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25977v2",
      "published_date": "2025-09-30 09:09:33 UTC",
      "updated_date": "2025-12-19 06:08:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:39:52.497073+00:00"
    },
    {
      "arxiv_id": "2509.25973v1",
      "title": "Scalable and Robust LLM Unlearning by Correcting Responses with Retrieved Exclusions",
      "title_zh": "åŸºäºæ£€ç´¢æ’é™¤é¡¹çº æ­£å“åº”çš„å¯æ‰©å±•ä¸”é²æ£’çš„å¤§è¯­è¨€æ¨¡å‹æœºå™¨é—å¿˜",
      "authors": [
        "Junbeom Kim",
        "Kyuyoung Kim",
        "Jihoon Tack",
        "Dongha Lim",
        "Jinwoo Shin"
      ],
      "abstract": "Language models trained on web-scale corpora risk memorizing and exposing sensitive information, prompting the need for effective machine unlearning. Prior methods mainly focus on input queries to suppress sensitive outputs, yet this often fails to eliminate the underlying knowledge and limits scalability. To address this, we propose Corrective Unlearning with Retrieved Exclusions (CURE), a novel unlearning framework that verifies model outputs for leakage and revises them into safe responses. Specifically, CURE employs a lightweight corrector that is applied to the original model to verify whether outputs contain target knowledge and to rewrite them if any leakage is detected. To efficiently handle large-scale unlearning requests, CURE retrieves unlearning targets that are relevant to the initial response and provides them as in-context references to the corrector for detection and conditional revision. By leveraging this retrieval augmentation, the corrector can adapt to new unlearning requests without additional training. Extensive evaluations demonstrate that CURE substantially reduces information leakage, even from indirect queries where prior works fall short, while maintaining response quality and general utility. Moreover, it demonstrates robustness under continual unlearning scenarios, making it practical for real-world applications.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Corrective Unlearning with Retrieved Exclusions (CURE)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¤„ç†æ•æ„Ÿä¿¡æ¯æ“¦é™¤æ—¶çš„Machine Unlearningéš¾é¢˜ã€‚é’ˆå¯¹ä»¥å¾€æ–¹æ³•ä¸»è¦ä¾§é‡äºæŠ‘åˆ¶è¾“å…¥æŸ¥è¯¢ä¸”éš¾ä»¥æ‰©å±•çš„ç¼ºé™·ï¼ŒCUREå¼•å…¥äº†ä¸€ä¸ªè½»é‡çº§çš„correctoræ¥éªŒè¯æ¨¡å‹è¾“å‡ºæ˜¯å¦å­˜åœ¨æ³„éœ²ï¼Œå¹¶åœ¨æ£€æµ‹åˆ°ç›®æ ‡çŸ¥è¯†æ—¶å°†å…¶ä¿®æ­£ä¸ºå®‰å…¨å›å¤ã€‚è¯¥æ¡†æ¶é€šè¿‡æ£€ç´¢ä¸åˆå§‹å“åº”ç›¸å…³çš„unlearning targetsï¼Œå¹¶å°†å…¶ä½œä¸ºin-context referencesæä¾›ç»™ä¿®æ­£å™¨ï¼Œä½¿å…¶æ— éœ€é¢å¤–è®­ç»ƒå³å¯çµæ´»åº”å¯¹æ–°çš„å¸è½½è¯·æ±‚ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCUREèƒ½æ˜¾è‘—é™ä½å³ä½¿æ˜¯æ¥è‡ªé—´æ¥æŸ¥è¯¢çš„ä¿¡æ¯æ³„éœ²é£é™©ï¼ŒåŒæ—¶æœ‰æ•ˆä¿æŒäº†æ¨¡å‹çš„å“åº”è´¨é‡å’Œé€šç”¨æ•ˆç”¨ã€‚æ­¤å¤–ï¼ŒCUREåœ¨æŒç»­å¸è½½(continual unlearning)åœºæ™¯ä¸‹è¡¨ç°å‡ºæå¼ºçš„é²æ£’æ€§ï¼Œä¸ºå¤§è§„æ¨¡æ•æ„Ÿä¿¡æ¯ç®¡ç†æä¾›äº†é«˜æ•ˆä¸”å®ç”¨çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25973v1",
      "published_date": "2025-09-30 09:07:45 UTC",
      "updated_date": "2025-09-30 09:07:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:39:59.889457+00:00"
    },
    {
      "arxiv_id": "2509.25958v1",
      "title": "RoRecomp: Enhancing Reasoning Efficiency via Rollout Response Recomposition in Reinforcement Learning",
      "title_zh": "RoRecompï¼šé€šè¿‡å¼ºåŒ–å­¦ä¹ ä¸­çš„ Rollout å“åº”é‡ç»„æå‡æ¨ç†æ•ˆç‡",
      "authors": [
        "Gang Li",
        "Yulei Qin",
        "Xiaoyu Tan",
        "Dingkang Yang",
        "Yuchen Shi",
        "Zihan Xu",
        "Xiang Li",
        "Xing Sun",
        "Ke Li"
      ],
      "abstract": "Reinforcement learning with verifiable rewards (RLVR) has proven effective in eliciting complex reasoning in large language models (LLMs). However, standard RLVR training often leads to excessively verbose processes (in reasoning tasks) and inefficient exploration trajectories (in agentic settings), as outcome-only rewards provide no incentive for efficiency and the high variance in response length within relatively small rollout groups results in noisy optimization signals. To address this, we propose Rollout Response Recomposition (RoRecomp), a plug-and-play method that guides models toward concise reasoning by strategically recomposing the training data. RoRecomp separates responses into two distinct batch types: 1) priority batches, which combine short-correct and long-incorrect responses selected from online batches to provide a clear gradient signal for brevity, and 2) compensation batches, which utilize remaining responses from a replay buffer to maintain stability and prevent model collapse. To comprehensively evaluate effectiveness, we test RoRecomp across three settings where results demonstrate substantial efficiency gains: reducing reasoning length by 27.7% in zero RL training, reducing unnecessary tool calls by 46.8% while improving accuracy in agentic RL, and achieving up to 52.5% length reduction in thinking compression, all with minimal performance impact.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å…·æœ‰å¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ (Reinforcement Learning with Verifiable Rewards, RLVR)åœ¨å¤§è¯­è¨€æ¨¡å‹æ¨ç†ä»»åŠ¡ä¸­å¯¼è‡´çš„å“åº”è¿‡åº¦å†—ä½™å’Œæ¢ç´¢æ•ˆç‡ä½ä¸‹é—®é¢˜ï¼Œæå‡ºäº†RoRecompæ¡†æ¶ã€‚RoRecompæ˜¯ä¸€ç§å³æ’å³ç”¨çš„å“åº”é‡ç»„(Rollout Response Recomposition)æ–¹æ³•ï¼Œé€šè¿‡ç­–ç•¥æ€§åœ°é‡ç»„è®­ç»ƒæ•°æ®æ¥å¼•å¯¼æ¨¡å‹è¿›è¡Œç®€æ´æ¨ç†ã€‚è¯¥æ–¹æ³•å°†å“åº”åˆ†ä¸ºä¼˜å…ˆæ‰¹æ¬¡(Priority batches)å’Œè¡¥å¿æ‰¹æ¬¡(Compensation batches)ï¼Œå‰è€…é€šè¿‡ç»„åˆåœ¨çº¿é‡‡æ ·ä¸­çš„â€œçŸ­è€Œæ­£ç¡®â€ä¸â€œé•¿è€Œé”™è¯¯â€çš„å“åº”æ¥æä¾›æ˜ç¡®çš„ç®€æ´æ€§æ¢¯åº¦ä¿¡å·ï¼Œåè€…åˆ™åˆ©ç”¨å›æ”¾ç¼“å­˜ä¸­çš„æ•°æ®ç¡®ä¿æ¨¡å‹è®­ç»ƒçš„ç¨³å®šæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒRoRecompåœ¨é›¶æ ·æœ¬å¼ºåŒ–å­¦ä¹ è®­ç»ƒä¸­å°†æ¨ç†é•¿åº¦ç¼©çŸ­äº†27.7%ï¼Œå¹¶åœ¨æ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ä¸­å‡å°‘äº†46.8%çš„ä¸å¿…è¦å·¥å…·è°ƒç”¨ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•åœ¨æ€ç»´å‹ç¼©(Thinking Compression)ä»»åŠ¡ä¸­å®ç°äº†é«˜è¾¾52.5%çš„é•¿åº¦ç¼©å‡ï¼Œä¸”å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“å¾®ä¹å…¶å¾®ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„æ¨ç†ä¸æ‰§è¡Œæ•ˆç‡ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25958v1",
      "published_date": "2025-09-30 08:54:38 UTC",
      "updated_date": "2025-09-30 08:54:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:40:04.601600+00:00"
    },
    {
      "arxiv_id": "2510.00084v1",
      "title": "Towards a Framework for Supporting the Ethical and Regulatory Certification of AI Systems",
      "title_zh": "è¿ˆå‘äººå·¥æ™ºèƒ½ç³»ç»Ÿä¼¦ç†ä¸ç›‘ç®¡è®¤è¯çš„æ”¯æ’‘æ¡†æ¶",
      "authors": [
        "Fabian Kovac",
        "Sebastian Neumaier",
        "Timea Pahi",
        "Torsten Priebe",
        "Rafael Rodrigues",
        "Dimitrios Christodoulou",
        "Maxime Cordy",
        "Sylvain Kubler",
        "Ali Kordia",
        "Georgios Pitsiladis",
        "John Soldatos",
        "Petros Zervoudakis"
      ],
      "abstract": "Artificial Intelligence has rapidly become a cornerstone technology, significantly influencing Europe's societal and economic landscapes. However, the proliferation of AI also raises critical ethical, legal, and regulatory challenges. The CERTAIN (Certification for Ethical and Regulatory Transparency in Artificial Intelligence) project addresses these issues by developing a comprehensive framework that integrates regulatory compliance, ethical standards, and transparency into AI systems. In this position paper, we outline the methodological steps for building the core components of this framework. Specifically, we present: (i) semantic Machine Learning Operations (MLOps) for structured AI lifecycle management, (ii) ontology-driven data lineage tracking to ensure traceability and accountability, and (iii) regulatory operations (RegOps) workflows to operationalize compliance requirements. By implementing and validating its solutions across diverse pilots, CERTAIN aims to advance regulatory compliance and to promote responsible AI innovation aligned with European standards.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹äººå·¥æ™ºèƒ½å¿«é€Ÿå‘å±•å¸¦æ¥çš„ä¼¦ç†ã€æ³•å¾‹å’Œç›‘ç®¡æŒ‘æˆ˜ï¼Œæå‡ºäº†åä¸ºCERTAINçš„ç»¼åˆæ¡†æ¶ï¼Œæ—¨åœ¨å°†ç›‘ç®¡åˆè§„ã€ä¼¦ç†æ ‡å‡†å’Œé€æ˜åº¦æ•´åˆè‡³AIç³»ç»Ÿä¸­ã€‚æ–‡ä¸­è¯¦ç»†ä»‹ç»äº†æ„å»ºè¯¥æ¡†æ¶æ ¸å¿ƒç»„ä»¶çš„æ–¹æ³•è®ºæ­¥éª¤ï¼ŒåŒ…æ‹¬ç”¨äºç»“æ„åŒ–AIç”Ÿå‘½å‘¨æœŸç®¡ç†çš„è¯­ä¹‰Machine Learning Operations (MLOps)ï¼Œä»¥åŠæ—¨åœ¨ç¡®ä¿å¯è¿½æº¯æ€§å’Œé—®è´£åˆ¶çš„æœ¬ä½“é©±åŠ¨æ•°æ®è°±ç³»è·Ÿè¸ª (ontology-driven data lineage tracking)ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜æå‡ºäº†ç›‘ç®¡æ“ä½œ (RegOps) å·¥ä½œæµï¼Œç”¨ä»¥å°†å¤æ‚çš„åˆè§„è¦æ±‚è½¬åŒ–ä¸ºå¯æ“ä½œçš„æµç¨‹ã€‚é€šè¿‡åœ¨å¤šä¸ªè¯•ç‚¹åœºæ™¯ä¸­è¿›è¡Œå®æ–½å’ŒéªŒè¯ï¼Œè¯¥æ¡†æ¶æ—¨åœ¨æ¨åŠ¨ç¬¦åˆæ¬§æ´²æ ‡å‡†çš„è´Ÿè´£ä»»AIåˆ›æ–°ï¼Œä¸ºAIç³»ç»Ÿçš„ä¼¦ç†å’Œç›‘ç®¡è®¤è¯æä¾›ç³»ç»ŸåŒ–æ”¯æŒã€‚",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.DB"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted for publication in the proceedings of the Workshop on AI Certification, Fairness and Regulations, co-located with the Austrian Symposium on AI and Vision (AIRoV 2025)",
      "pdf_url": "https://arxiv.org/pdf/2510.00084v1",
      "published_date": "2025-09-30 08:54:02 UTC",
      "updated_date": "2025-09-30 08:54:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:40:10.191659+00:00"
    },
    {
      "arxiv_id": "2509.25955v1",
      "title": "AIM: Adaptive Intervention for Deep Multi-task Learning of Molecular Properties",
      "title_zh": "AIMï¼šé¢å‘åˆ†å­æ€§è´¨æ·±åº¦å¤šä»»åŠ¡å­¦ä¹ çš„è‡ªé€‚åº”å¹²é¢„",
      "authors": [
        "Mason Minot",
        "Gisbert Schneider"
      ],
      "abstract": "Simultaneously optimizing multiple, frequently conflicting, molecular properties is a key bottleneck in the development of novel therapeutics. Although a promising approach, the efficacy of multi-task learning is often compromised by destructive gradient interference, especially in the data-scarce regimes common to drug discovery. To address this, we propose AIM, an optimization framework that learns a dynamic policy to mediate gradient conflicts. The policy is trained jointly with the main network using a novel augmented objective composed of dense, differentiable regularizers. This objective guides the policy to produce updates that are geometrically stable and dynamically efficient, prioritizing progress on the most challenging tasks. We demonstrate that AIM achieves statistically significant improvements over multi-task baselines on subsets of the QM9 and targeted protein degraders benchmarks, with its advantage being most pronounced in data-scarce regimes. Beyond performance, AIM's key contribution is its interpretability; the learned policy matrix serves as a diagnostic tool for analyzing inter-task relationships. This combination of data-efficient performance and diagnostic insight highlights the potential of adaptive optimizers to accelerate scientific discovery by creating more robust and insightful models for multi-property molecular design.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è¯ç‰©ç ”å‘ä¸­å¤šä»»åŠ¡å­¦ä¹ ï¼ˆMulti-task Learningï¼‰å¸¸å› æ¢¯åº¦å¹²æ‰°ï¼ˆgradient interferenceï¼‰å¯¼è‡´æ€§èƒ½ä¸‹é™çš„é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹æ•°æ®ç¨€ç¼ºï¼ˆdata-scarceï¼‰çš„æƒ…å¢ƒï¼Œæå‡ºäº† AIM (Adaptive Intervention) ä¼˜åŒ–æ¡†æ¶ã€‚AIM é€šè¿‡å­¦ä¹ ä¸€ç§åŠ¨æ€ç­–ç•¥ï¼ˆdynamic policyï¼‰æ¥åè°ƒä»»åŠ¡é—´çš„æ¢¯åº¦å†²çªï¼Œå¹¶åˆ©ç”¨åŒ…å«å¯å¾®æ­£åˆ™åŒ–é¡¹ï¼ˆdifferentiable regularizersï¼‰çš„å¢å¼ºç›®æ ‡å‡½æ•°è¿›è¡Œè”åˆè®­ç»ƒï¼Œç¡®ä¿æ›´æ–°è¿‡ç¨‹åœ¨å‡ ä½•ä¸Šç¨³å®šä¸”åŠ¨æ€é«˜æ•ˆã€‚è¯¥æ¡†æ¶èƒ½å¤Ÿä¼˜å…ˆå¤„ç†æœ€å…·æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œåœ¨ QM9 å’Œé’ˆå¯¹æ€§è›‹ç™½è´¨é™è§£å‰‚ï¼ˆtargeted protein degradersï¼‰åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°æ˜¾è‘—ä¼˜äºä¼ ç»ŸåŸºå‡†æ¨¡å‹ã€‚é™¤äº†æ€§èƒ½æå‡ï¼ŒAIM çš„æ ¸å¿ƒè´¡çŒ®åœ¨äºå…¶å¯è§£é‡Šæ€§ï¼ˆinterpretabilityï¼‰ï¼Œå…¶å­¦ä¹ åˆ°çš„ç­–ç•¥çŸ©é˜µå¯ä½œä¸ºåˆ†æä»»åŠ¡é—´å…³ç³»çš„è¯Šæ–­å·¥å…·ã€‚è¿™ç§ç»“åˆäº†é«˜æ•ˆæ€§èƒ½ä¸è¯Šæ–­æ´å¯Ÿçš„è‡ªé€‚åº”ä¼˜åŒ–å™¨ï¼Œä¸ºå®ç°æ›´ç¨³å¥çš„å¤šå±æ€§åˆ†å­è®¾è®¡åŠåŠ é€Ÿç§‘å­¦å‘ç°æä¾›äº†æœ‰åŠ›æ”¯æŒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.chem-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, 3 figures, 9 tables",
      "pdf_url": "https://arxiv.org/pdf/2509.25955v1",
      "published_date": "2025-09-30 08:47:41 UTC",
      "updated_date": "2025-09-30 08:47:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:40:15.294855+00:00"
    },
    {
      "arxiv_id": "2509.25946v1",
      "title": "Automated Model Discovery via Multi-modal & Multi-step Pipeline",
      "title_zh": "åŸºäºå¤šæ¨¡æ€ä¸å¤šæ­¥æµæ°´çº¿çš„è‡ªåŠ¨åŒ–æ¨¡å‹å‘ç°",
      "authors": [
        "Lee Jung-Mok",
        "Nam Hyeon-Woo",
        "Moon Ye-Bin",
        "Junhyun Nam",
        "Tae-Hyun Oh"
      ],
      "abstract": "Automated model discovery is the process of automatically searching and identifying the most appropriate model for a given dataset over a large combinatorial search space. Existing approaches, however, often face challenges in balancing the capture of fine-grained details with ensuring generalizability beyond training data regimes with a reasonable model complexity. In this paper, we present a multi-modal \\& multi-step pipeline for effective automated model discovery. Our approach leverages two vision-language-based modules (VLM), AnalyzerVLM and EvaluatorVLM, for effective model proposal and evaluation in an agentic way. AnalyzerVLM autonomously plans and executes multi-step analyses to propose effective candidate models. EvaluatorVLM assesses the candidate models both quantitatively and perceptually, regarding the fitness for local details and the generalibility for overall trends. Our results demonstrate that our pipeline effectively discovers models that capture fine details and ensure strong generalizability. Additionally, extensive ablation studies show that both multi-modality and multi-step reasoning play crucial roles in discovering favorable models.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§é€šè¿‡å¤šæ¨¡æ€(Multi-modal)å’Œå¤šæ­¥éª¤(Multi-step)æµæ°´çº¿å®ç°çš„è‡ªåŠ¨åŒ–æ¨¡å‹å‘ç°(Automated model discovery)æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ–¹æ³•åœ¨æ•æ‰ç»†ç²’åº¦ç»†èŠ‚ä¸ç¡®ä¿æ¨¡å‹æ³›åŒ–æ€§ä¹‹é—´éš¾ä»¥å¹³è¡¡çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶åˆ©ç”¨ä¸¤ä¸ªåŸºäºè§†è§‰è¯­è¨€æ¨¡å‹(VLM)çš„æ™ºèƒ½ä½“æ¨¡å—ï¼Œå³ AnalyzerVLM å’Œ EvaluatorVLMï¼Œä»¥æ™ºèƒ½ä½“(Agentic)æ–¹å¼é«˜æ•ˆåœ°è¿›è¡Œæ¨¡å‹æè®®ä¸è¯„ä¼°ã€‚AnalyzerVLM èƒ½å¤Ÿè‡ªä¸»è§„åˆ’å¹¶æ‰§è¡Œå¤šæ­¥åˆ†æä»¥æå‡ºæœ‰æ•ˆçš„å€™é€‰æ¨¡å‹ï¼Œè€Œ EvaluatorVLM åˆ™ä»å®šé‡å’Œæ„ŸçŸ¥ä¸¤ä¸ªç»´åº¦å¯¹æ¨¡å‹è¿›è¡Œè¯„ä¼°ï¼Œç¡®ä¿å…¶å…¼é¡¾å±€éƒ¨ç»†èŠ‚æ‹Ÿåˆä¸æ•´ä½“è¶‹åŠ¿çš„æ³›åŒ–èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æµæ°´çº¿èƒ½æœ‰æ•ˆå‘ç°é«˜è´¨é‡æ¨¡å‹ï¼Œåœ¨æ•æ‰ç»†å¾®ç‰¹å¾çš„åŒæ—¶ä¿è¯äº†æå¼ºçš„æ³›åŒ–æ€§ã€‚æ­¤å¤–ï¼Œæ¶ˆèå®éªŒ(Ablation studies)è¿›ä¸€æ­¥è¯å®ï¼Œå¤šæ¨¡æ€ç‰¹å¾å’Œå¤šæ­¥æ¨ç†(Multi-step reasoning)å¯¹äºå‘ç°ç†æƒ³æ¨¡å‹è‡³å…³é‡è¦ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25946v1",
      "published_date": "2025-09-30 08:40:05 UTC",
      "updated_date": "2025-09-30 08:40:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:40:14.282824+00:00"
    },
    {
      "arxiv_id": "2509.25944v1",
      "title": "NuRisk: A Visual Question Answering Dataset for Agent-Level Risk Assessment in Autonomous Driving",
      "title_zh": "NuRiskï¼šé¢å‘è‡ªåŠ¨é©¾é©¶æ™ºèƒ½ä½“çº§é£é™©è¯„ä¼°çš„è§†è§‰é—®ç­”æ•°æ®é›†",
      "authors": [
        "Yuan Gao",
        "Mattia Piccinini",
        "Roberto Brusnicki",
        "Yuchen Zhang",
        "Johannes Betz"
      ],
      "abstract": "Understanding risk in autonomous driving requires not only perception and prediction, but also high-level reasoning about agent behavior and context. Current Vision Language Models (VLMs)-based methods primarily ground agents in static images and provide qualitative judgments, lacking the spatio-temporal reasoning needed to capture how risks evolve over time. To address this gap, we propose NuRisk, a comprehensive Visual Question Answering (VQA) dataset comprising 2,900 scenarios and 1.1 million agent-level samples, built on real-world data from nuScenes and Waymo, supplemented with safety-critical scenarios from the CommonRoad simulator. The dataset provides Bird-Eye-View (BEV) based sequential images with quantitative, agent-level risk annotations, enabling spatio-temporal reasoning. We benchmark well-known VLMs across different prompting techniques and find that they fail to perform explicit spatio-temporal reasoning, resulting in a peak accuracy of 33% at high latency. To address these shortcomings, our fine-tuned 7B VLM agent improves accuracy to 41% and reduces latency by 75%, demonstrating explicit spatio-temporal reasoning capabilities that proprietary models lacked. While this represents a significant step forward, the modest accuracy underscores the profound challenge of the task, establishing NuRisk as a critical benchmark for advancing spatio-temporal reasoning in autonomous driving.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰è§†è§‰è¯­è¨€æ¨¡å‹(VLMs)åœ¨è‡ªåŠ¨é©¾é©¶é£é™©è¯„ä¼°ä¸­ç¼ºä¹æ•æ‰é£é™©éšæ—¶é—´æ¼”å˜çš„ç©ºæ—¶æ¨ç†(spatio-temporal reasoning)èƒ½åŠ›çš„é—®é¢˜ï¼Œæå‡ºäº†NuRiskæ•°æ®é›†ã€‚NuRiskæ˜¯ä¸€ä¸ªå¤§è§„æ¨¡çš„è§†è§‰é—®ç­”(VQA)æ•°æ®é›†ï¼ŒåŒ…å«2,900ä¸ªåœºæ™¯å’Œ110ä¸‡ä¸ªæ™ºèƒ½ä½“çº§æ ·æœ¬ï¼Œå…¶æ•°æ®æºè‡ªnuScenesã€Waymoçš„çœŸå®ä¸–ç•Œåœºæ™¯ä»¥åŠCommonRoadæ¨¡æ‹Ÿå™¨çš„å®‰å…¨å…³é”®åœºæ™¯ã€‚è¯¥æ•°æ®é›†é€šè¿‡æä¾›åŸºäºé¸Ÿç°å›¾(Bird-Eye-View, BEV)çš„åºåˆ—å›¾åƒå’Œå®šé‡çš„æ™ºèƒ½ä½“çº§é£é™©æ ‡æ³¨ï¼Œå®ç°äº†å¯¹å¤æ‚é©¾é©¶ç¯å¢ƒçš„æ˜¾å¼ç©ºæ—¶å»ºæ¨¡ã€‚åŸºå‡†æµ‹è¯•è¡¨æ˜ï¼Œç°æœ‰ä¸»æµVLMséš¾ä»¥è¿›è¡Œæ˜¾å¼çš„ç©ºæ—¶æ¨ç†ï¼Œå‡†ç¡®ç‡æœ€é«˜ä»…ä¸º33%ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶è€…å¾®è°ƒäº†ä¸€ä¸ª7Bè§„æ¨¡çš„VLMæ™ºèƒ½ä½“ï¼Œåœ¨å°†å‡†ç¡®ç‡æå‡è‡³41%çš„åŒæ—¶å‡å°‘äº†75%çš„å»¶è¿Ÿã€‚NuRiskçš„æå‡ºä¸ºè§£å†³è‡ªåŠ¨é©¾é©¶ä¸­æå…·æŒ‘æˆ˜æ€§çš„ç©ºæ—¶æ¨ç†ä»»åŠ¡æä¾›äº†ä¸€ä¸ªå…³é”®çš„æ€§èƒ½è¯„ä¼°åŸºå‡†ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages",
      "pdf_url": "https://arxiv.org/pdf/2509.25944v1",
      "published_date": "2025-09-30 08:37:31 UTC",
      "updated_date": "2025-09-30 08:37:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:40:30.790655+00:00"
    },
    {
      "arxiv_id": "2509.25941v1",
      "title": "Boosting Process-Correct CoT Reasoning by Modeling Solvability of Multiple-Choice QA",
      "title_zh": "é€šè¿‡å»ºæ¨¡å¤šé€‰é¢˜å¯è§£æ€§æå‡è¿‡ç¨‹æ­£ç¡®çš„ CoT æ¨ç†",
      "authors": [
        "Raphael Schumann",
        "Stefan Riezler"
      ],
      "abstract": "Reasoning quality in large language models depends not only on producing correct answers but also on generating valid intermediate steps. We study this through multiple-choice question answering (MCQA), which provides a controlled setting with fixed answer options. Our analysis shows that when questions are effectively unsolvable for a model, spurious chains of thought (CoTs) are more likely to appear, leading to false positives. By estimating the solvability of each question, we uncover an intermediate regime where learning is most effective. Building on this insight, we adapt outcome-supervised reward models and reinforcement learning with group-relative advantage to incorporate solvability into their objectives. Across experiments on math and multimodal datasets, these modifications consistently yield higher rates of process-correct reasoning and, in reinforcement learning, improved answer accuracy as well. Our results highlight solvability as a key factor for reducing hallucinations and increasing reliability in CoT reasoning.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¦‚ä½•é€šè¿‡å»ºæ¨¡å¤šé¡¹é€‰æ‹©é¢˜(Multiple-Choice QA)çš„å¯è§£æ€§(Solvability)æ¥æå‡å¤§è¯­è¨€æ¨¡å‹åœ¨è¿‡ç¨‹æ­£ç¡®(Process-Correct)æ–¹é¢çš„é“¾å¼æ€ç»´(Chain-of-Thought)æ¨ç†èƒ½åŠ›ã€‚ç ”ç©¶å‘ç°å½“é—®é¢˜å¯¹æ¨¡å‹è€Œè¨€ä¸å¯è§£æ—¶ï¼Œæ›´å®¹æ˜“å‡ºç°ä¼ªé€ çš„æ¨ç†é“¾(Spurious CoTs)å¹¶å¯¼è‡´å‡é˜³æ€§ç»“æœï¼Œè€Œå­¦ä¹ æ•ˆç‡æœ€é«˜çš„éƒ¨åˆ†å­˜åœ¨äºä¸€ä¸ªç‰¹å®šçš„ä¸­é—´åœ°å¸¦ã€‚åŸºäºæ­¤æ´å¯Ÿï¼Œä½œè€…æ”¹è¿›äº†ç»“æœç›‘ç£å¥–åŠ±æ¨¡å‹(Outcome-supervised Reward Models)å’Œå¼ºåŒ–å­¦ä¹ (Reinforcement Learning)ä¸­çš„ç»„ç›¸å¯¹ä¼˜åŠ¿(Group-relative advantage)è®¡ç®—æ–¹å¼ï¼Œå°†å¯è§£æ€§å»ºæ¨¡å¼•å…¥ä¼˜åŒ–ç›®æ ‡ã€‚åœ¨æ•°å­¦å’Œå¤šæ¨¡æ€æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¿™äº›æ”¹è¿›èƒ½å¤Ÿä¸€è‡´åœ°æé«˜æ¨ç†è¿‡ç¨‹çš„æ­£ç¡®ç‡ï¼Œå¹¶åœ¨å¼ºåŒ–å­¦ä¹ ä¸­åŒæ—¶æå‡äº†ç­”æ¡ˆå‡†ç¡®åº¦ã€‚è¯¥æˆæœå¼ºè°ƒäº†å¯è§£æ€§æ˜¯å‡å°‘å¹»è§‰å’Œæé«˜CoTæ¨ç†å¯é æ€§çš„å…³é”®å› ç´ ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25941v1",
      "published_date": "2025-09-30 08:34:16 UTC",
      "updated_date": "2025-09-30 08:34:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:40:35.586085+00:00"
    },
    {
      "arxiv_id": "2509.25933v1",
      "title": "From MNIST to ImageNet: Understanding the Scalability Boundaries of Differentiable Logic Gate Networks",
      "title_zh": "ä» MNIST åˆ° ImageNetï¼šè§£æå¯å¾®é€»è¾‘é—¨ç½‘ç»œçš„å¯æ‰©å±•æ€§è¾¹ç•Œ",
      "authors": [
        "Sven BrÃ¤ndle",
        "Till Aczel",
        "Andreas Plesner",
        "Roger Wattenhofer"
      ],
      "abstract": "Differentiable Logic Gate Networks (DLGNs) are a very fast and energy-efficient alternative to conventional feed-forward networks. With learnable combinations of logical gates, DLGNs enable fast inference by hardware-friendly execution. Since the concept of DLGNs has only recently gained attention, these networks are still in their developmental infancy, including the design and scalability of their output layer. To date, this architecture has primarily been tested on datasets with up to ten classes.\n  This work examines the behavior of DLGNs on large multi-class datasets. We investigate its general expressiveness, its scalability, and evaluate alternative output strategies. Using both synthetic and real-world datasets, we provide key insights into the importance of temperature tuning and its impact on output layer performance. We evaluate conditions under which the Group-Sum layer performs well and how it can be applied to large-scale classification of up to 2000 classes.",
      "tldr_zh": "æœ¬ç ”ç©¶æ¢è®¨äº†å¯å¾®é€»è¾‘é—¨ç½‘ç»œ(Differentiable Logic Gate Networks, DLGNs)åœ¨å¤§è§„æ¨¡åˆ†ç±»ä»»åŠ¡ä¸­çš„å¯æ‰©å±•æ€§è¾¹ç•Œã€‚ä½œä¸ºä¸€ç§å¿«é€Ÿä¸”èŠ‚èƒ½çš„ä¼ ç»Ÿå‰é¦ˆç½‘ç»œæ›¿ä»£æ–¹æ¡ˆï¼ŒDLGNsæ­¤å‰ä¸»è¦è¢«åº”ç”¨äºç±»åˆ«æ•°è¾ƒå°‘çš„å°å‹æ•°æ®é›†ã€‚è®ºæ–‡æ·±å…¥åˆ†æäº†è¯¥æ¶æ„çš„é€šç”¨è¡¨è¾¾èƒ½åŠ›ä¸æ‰©å±•æ€§ï¼Œå¹¶é’ˆå¯¹å¤§è§„æ¨¡å¤šç±»æ•°æ®é›†è¯„ä¼°äº†æ›¿ä»£æ€§çš„è¾“å‡ºç­–ç•¥ã€‚é€šè¿‡åˆæˆä¸çœŸå®æ•°æ®é›†çš„å®éªŒï¼Œç ”ç©¶æ­ç¤ºäº†æ¸©åº¦è°ƒèŠ‚(temperature tuning)å¯¹è¾“å‡ºå±‚æ€§èƒ½çš„å…³é”®å½±å“ã€‚æ­¤å¤–ï¼Œä½œè€…è¿˜è¯¦ç»†è¯„ä¼°äº†Group-Sumå±‚åœ¨å¤„ç†å¤šè¾¾2000ä¸ªç±»åˆ«çš„åˆ†ç±»ä»»åŠ¡æ—¶çš„æœ‰æ•ˆæ€§åŠé€‚ç”¨æ¡ä»¶ã€‚è¯¥å·¥ä½œä¸ºDLGNsä»ç®€å•ä»»åŠ¡å‘å¤æ‚çš„å¤§è§„æ¨¡å›¾åƒåˆ†ç±»åº”ç”¨æ‰©å±•æä¾›äº†é‡è¦çš„ç†è®ºè§è§£ä¸å®è·µæŒ‡å¯¼ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25933v1",
      "published_date": "2025-09-30 08:27:58 UTC",
      "updated_date": "2025-09-30 08:27:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:40:37.474079+00:00"
    },
    {
      "arxiv_id": "2509.25928v1",
      "title": "Quantitative Evaluation of KIRETT Wearable Demonstrator for Rescue Operations",
      "title_zh": "é¢å‘æ•‘æ´è¡ŒåŠ¨çš„ KIRETT å¯ç©¿æˆ´æ¼”ç¤ºåŸå‹çš„å®šé‡è¯„ä¼°",
      "authors": [
        "Mubaris Nadeem",
        "Johannes Zenkert",
        "Lisa Bender",
        "Christian Weber",
        "Madjid Fathi"
      ],
      "abstract": "Healthcare and Medicine are under constant pressure to provide patient-driven medical expertise to ensure a fast and accurate treatment of the patient. In such scenarios, the diagnosis contains, the family history, long term medical data and a detailed consultation with the patient. In time-critical emergencies, such conversation and time-consuming elaboration are not possible. Rescue services need to provide fast, reliable treatments for the patient in need. With the help of modern technologies, like treatment recommendations, real-time vitals-monitoring, and situation detection through artificial intelligence (AI) a situation can be analyzed and supported in providing fast, accurate patient-data-driven medical treatments. In KIRETT, a wearable device is developed to support in such scenarios and presents a way to provide treatment recommendation in rescue services. The objective of this paper is to present the quantitative results of a two-day KIRETT evaluation (14 participants) to analyze the needs of rescue operators in healthcare.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŒ»ç–—æ€¥æ•‘ä¸­å› æ—¶é—´ç´§è¿«è€Œéš¾ä»¥è·å–è¯¦å°½ç—…å²çš„ç—›ç‚¹ï¼Œè¯„ä¼°äº†åä¸º KIRETT çš„å¯ç©¿æˆ´è®¾å¤‡æ¼”ç¤ºå™¨ã€‚KIRETT åˆ©ç”¨äººå·¥æ™ºèƒ½ (AI) æŠ€æœ¯ï¼Œé›†æˆäº†å®æ—¶ç”Ÿå‘½ä½“å¾ç›‘æµ‹ã€æƒ…æ™¯æ£€æµ‹ä»¥åŠæ²»ç–—å»ºè®®æ¨èç­‰åŠŸèƒ½ï¼Œæ—¨åœ¨ä¸ºæ•‘æ´ç°åœºæä¾›å¿«é€Ÿã€å‡†ç¡®çš„åŒ»ç–—å†³ç­–æ”¯æŒã€‚æœ¬æ–‡è¯¦ç»†æŠ¥å‘Šäº† 14 åæ•‘æ´äººå‘˜å‚ä¸çš„ä¸ºæœŸä¸¤å¤©çš„å®šé‡è¯„ä¼°ç»“æœï¼Œæ·±å…¥åˆ†æäº†æ•‘æ´æ“ä½œå‘˜åœ¨å®é™…åŒ»ç–—åœºæ™¯ä¸­çš„æ ¸å¿ƒéœ€æ±‚ã€‚è¯„ä¼°ç»“æœéªŒè¯äº†è¿™ç§é›†æˆç°ä»£æŠ€æœ¯çš„ wearable device åœ¨æ”¯æŒæ•°æ®é©±åŠ¨çš„ç´§æ€¥åŒ»ç–—å¤„ç†æ–¹é¢çš„æ½œåŠ›ã€‚è¯¥ç ”ç©¶ä¸ºä¼˜åŒ–æ•‘æ´æœåŠ¡ä¸­çš„æŠ€æœ¯è¾…åŠ©æ‰‹æ®µå¹¶æå‡æ€¥æ•‘æ•ˆç‡æä¾›äº†é‡è¦çš„å®šé‡ä¾æ®ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Conference paper for 2024 IEEE World AI IoT Congress (AIIoT), KIRETT Project, University of Siegen, Germany",
      "pdf_url": "https://arxiv.org/pdf/2509.25928v1",
      "published_date": "2025-09-30 08:21:09 UTC",
      "updated_date": "2025-09-30 08:21:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:40:38.364676+00:00"
    },
    {
      "arxiv_id": "2509.25927v1",
      "title": "The Impact of Scaling Training Data on Adversarial Robustness",
      "title_zh": "è®­ç»ƒæ•°æ®è§„æ¨¡å¯¹å¯¹æŠ—é²æ£’æ€§çš„å½±å“",
      "authors": [
        "Marco Zimmerli",
        "Andreas Plesner",
        "Till Aczel",
        "Roger Wattenhofer"
      ],
      "abstract": "Deep neural networks remain vulnerable to adversarial examples despite advances in architectures and training paradigms. We investigate how training data characteristics affect adversarial robustness across 36 state-of-the-art vision models spanning supervised, self-supervised, and contrastive learning approaches, trained on datasets from 1.2M to 22B images. Models were evaluated under six black-box attack categories: random perturbations, two types of geometric masks, COCO object manipulations, ImageNet-C corruptions, and ImageNet-R style shifts. Robustness follows a logarithmic scaling law with both data volume and model size: a tenfold increase in data reduces attack success rate (ASR) on average by ~3.2%, whereas a tenfold increase in model size reduces ASR on average by ~13.4%. Notably, some self-supervised models trained on curated datasets, such as DINOv2, outperform others trained on much larger but less curated datasets, challenging the assumption that scale alone drives robustness. Adversarial fine-tuning of ResNet50s improves generalization across structural variations but not across color distributions. Human evaluation reveals persistent gaps between human and machine vision. These results show that while scaling improves robustness, data quality, architecture, and training objectives play a more decisive role than raw scale in achieving broad-spectrum adversarial resilience.",
      "tldr_zh": "è¯¥ç ”ç©¶ç³»ç»Ÿæ¢è®¨äº†è®­ç»ƒæ•°æ®ç‰¹æ€§å¯¹æ·±åº¦ç¥ç»ç½‘ç»œ Adversarial Robustness çš„å½±å“ï¼Œåˆ†æäº†æ¶µç›–ç›‘ç£ã€è‡ªç›‘ç£å’Œå¯¹æ¯”å­¦ä¹ çš„36ä¸ªå…ˆè¿›è§†è§‰æ¨¡å‹ï¼Œå…¶è®­ç»ƒæ•°æ®è§„æ¨¡è·¨è¶Š120ä¸‡è‡³220äº¿å¼ å›¾åƒã€‚ç ”ç©¶äººå‘˜é€šè¿‡å…­ç±»é»‘ç›’æ”»å‡»è¯„ä¼°æ¨¡å‹ï¼Œå‘ç°é²æ£’æ€§éµå¾ªå…³äºæ•°æ®é‡å’Œæ¨¡å‹å¤§å°çš„ Logarithmic Scaling Lawï¼Œå…¶ä¸­æ¨¡å‹å¤§å°çš„å¢åŠ å¯¹é™ä½ Attack Success Rate (ASR) çš„æ•ˆæœæ¯”æ•°æ®é‡å¢åŠ æ›´ä¸ºæ˜¾è‘—ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨ç²¾é€‰æ•°æ®é›†ä¸Šè®­ç»ƒçš„ DINOv2 ç­‰æ¨¡å‹è¡¨ç°ä¼˜äºè§„æ¨¡æ›´å¤§ä½†æ•°æ®è´¨é‡è¾ƒä½çš„æ¨¡å‹ï¼Œè¿™æŒ‘æˆ˜äº†ä»…é è§„æ¨¡é©±åŠ¨é²æ£’æ€§çš„å‡è®¾ã€‚ç ”ç©¶è¿›ä¸€æ­¥æŒ‡å‡ºï¼ŒAdversarial Fine-tuning è™½ç„¶èƒ½æ”¹å–„æ¨¡å‹å¯¹ç»“æ„å˜åŒ–çš„æ³›åŒ–ï¼Œä½†æ— æ³•æœ‰æ•ˆåº”å¯¹è‰²å½©åˆ†å¸ƒåç§»ï¼Œä¸”äººæœºè§†è§‰ä¹‹é—´ä»å­˜åœ¨æŒä¹…å·®è·ã€‚æœ€ç»ˆç»“è®ºå¼ºè°ƒï¼Œåœ¨å®ç°å¹¿è°±å¯¹æŠ—éŸ§æ€§æ–¹é¢ï¼Œæ•°æ®è´¨é‡ã€æ¶æ„è®¾è®¡å’Œè®­ç»ƒç›®æ ‡æ¯”å•çº¯çš„åŸå§‹æ•°æ®è§„æ¨¡èµ·ç€æ›´ä¸ºå†³å®šæ€§çš„ä½œç”¨ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at the workshop Reliable ML from Unreliable Data at NeurIPS 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.25927v1",
      "published_date": "2025-09-30 08:20:56 UTC",
      "updated_date": "2025-09-30 08:20:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:41:05.402042+00:00"
    },
    {
      "arxiv_id": "2509.25923v1",
      "title": "KIRETT: Smart Integration of Vital Signs Data for Intelligent Decision Support in Rescue Scenarios",
      "title_zh": "KIRETTï¼šé¢å‘æ•‘æ´åœºæ™¯æ™ºèƒ½å†³ç­–æ”¯æŒçš„ç”Ÿå‘½ä½“å¾æ•°æ®æ™ºèƒ½é›†æˆ",
      "authors": [
        "Mubaris Nadeem",
        "Johannes Zenkert",
        "Christian Weber",
        "Lisa Bender",
        "Madjid Fathi"
      ],
      "abstract": "The integration of vital signs in healthcare has witnessed a steady rise, promising health professionals to assist in their daily tasks to improve patient treatment. In life-threatening situations, like rescue operations, crucial decisions need to be made in the shortest possible amount of time to ensure that excellent treatment is provided during life-saving measurements. The integration of vital signs in the treatment holds the potential to improve time utilization for rescuers in such critical situations. They furthermore serve to support health professionals during the treatment with useful information and suggestions. To achieve such a goal, the KIRETT project serves to provide treatment recommendations and situation detection, combined on a wrist-worn wearable for rescue operations.This paper aims to present the significant role of vital signs in the improvement of decision-making during rescue operations and show their impact on health professionals and patients in need.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† KIRETT é¡¹ç›®ï¼Œæ—¨åœ¨é€šè¿‡æ™ºèƒ½æ•´åˆ Vital Signs æ•°æ®ï¼Œä¸ºç´§æ€¥æ•‘æ´åœºæ™¯ï¼ˆRescue Scenariosï¼‰æä¾›æ™ºèƒ½å†³ç­–æ”¯æŒã€‚é’ˆå¯¹æ•‘æ´è¡ŒåŠ¨ä¸­éœ€è¦åœ¨æçŸ­æ—¶é—´å†…åšå‡ºç”Ÿå‘½æ”¸å…³å†³ç­–çš„éœ€æ±‚ï¼Œè¯¥é¡¹ç›®å¼€å‘äº†ä¸€ç§ä½©æˆ´åœ¨æ‰‹è…•ä¸Šçš„ Wearable è®¾å¤‡ï¼Œå®ç°äº†æ²»ç–—å»ºè®®ï¼ˆTreatment Recommendationsï¼‰ä¸æƒ…å†µæ£€æµ‹ï¼ˆSituation Detectionï¼‰çš„å®æ—¶ç»“åˆã€‚è¿™ç§é›†æˆç”Ÿå‘½ä½“å¾çš„æ–¹æ³•æ˜¾è‘—ä¼˜åŒ–äº†æ•‘æ´äººå‘˜çš„æ—¶é—´åˆ©ç”¨æ•ˆç‡ï¼Œå¹¶ä¸ºåŒ»ç–—ä¸“ä¸šäººå‘˜æä¾›äº†å…³é”®çš„è¾…åŠ©ä¿¡æ¯ã€‚é€šè¿‡ KIRETT ç³»ç»Ÿï¼Œç ”ç©¶å±•ç¤ºäº† Vital Signs åœ¨æ”¹å–„æ•‘æ´å†³ç­–åˆ¶å®šã€æå‡æ‚£è€…æ²»ç–—è´¨é‡æ–¹é¢çš„æ ¸å¿ƒä½œç”¨ï¼Œä¸ºé«˜å‹æ•‘æ´ç¯å¢ƒä¸‹çš„æ™ºèƒ½åŒ–è¾…åŠ©æŠ€æœ¯æä¾›äº†æœ‰åŠ›æ”¯æŒã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Conference paper for 2024 IEEE International Conference on Electro Information Technology (eIT), KIRETT Project, University of Siegen, Germany",
      "pdf_url": "https://arxiv.org/pdf/2509.25923v1",
      "published_date": "2025-09-30 08:20:42 UTC",
      "updated_date": "2025-09-30 08:20:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:40:45.653765+00:00"
    },
    {
      "arxiv_id": "2509.25922v1",
      "title": "DeepJSONEval: Benchmarking Complex Nested JSON Data Mining for Large Language Models",
      "title_zh": "DeepJSONEvalï¼šé’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹å¤æ‚åµŒå¥— JSON æ•°æ®æŒ–æ˜çš„åŸºå‡†è¯„æµ‹",
      "authors": [
        "Zhicheng Zhou",
        "Jing Li",
        "Suming Qiu",
        "Junjie Huang",
        "Linyuan Qiu",
        "Zhijie Sun"
      ],
      "abstract": "The internet is saturated with low-density, high-redundancy information, such as social media comments, repetitive news, and lengthy discussions, making it difficult to extract valuable insights efficiently. Multi-layer nested JSON structures provide an effective solution by compressing such information into semantically rich, hierarchical representations, which organize data into key-value pairs, arrays, and nested objects, preserving contextual relationships and enabling efficient storage, retrieval, and semantic querying. For instance, in news aggregation, a JSON object can nest an article's metadata (title, author, date), content (text, multimedia), and multimedia information (multimedia type, caption) hierarchically. Large Language Models (LLMs) play a transformative role in web data mining by parsing unstructured text and outputting structured results directly into complex JSON schemas. However, current benchmarks for evaluating LLMs' JSON output capabilities overemphasize pure JSON generation rather than assessing data comprehension and extraction abilities, a limitation that lacks relevance to practical web data mining tasks. To address this, we introduce DeepJSONEval, a novel benchmark featuring 2100 multi-domain instances with deep nested structures, categorized by difficulty. Experiments show significant performance gaps among LLMs in handling such complexity. Our benchmark and datasets are open-sourced to advance research in structured JSON generation.(https://github.com/GTS-AI-Infra-Lab-SotaS/DeepJSONEval).",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹äº’è”ç½‘ä¿¡æ¯å†—ä½™åº¦é«˜ä¸”éš¾ä»¥é«˜æ•ˆæå–æ ¸å¿ƒè§è§£çš„é—®é¢˜ï¼Œæ¢è®¨äº† Large Language Models (LLMs) åœ¨è§£æéç»“æ„åŒ–æ–‡æœ¬å¹¶å°†å…¶è½¬åŒ–ä¸ºå¤æ‚åµŒå¥— JSON ç»“æ„æ–¹é¢çš„æ½œåŠ›ã€‚ä½œè€…æŒ‡å‡ºï¼Œç°æœ‰çš„åŸºå‡†æµ‹è¯•è¿‡åº¦å¼ºè°ƒ JSON çš„çº¯æ ¼å¼ç”Ÿæˆèƒ½åŠ›ï¼Œè€Œç¼ºä¹å¯¹ LLMs åœ¨å®é™…ç½‘é¡µæ•°æ®æŒ–æ˜ä»»åŠ¡ä¸­æ•°æ®ç†è§£ä¸æå–èƒ½åŠ›çš„è¯„ä¼°ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶å›¢é˜Ÿæå‡ºäº† DeepJSONEvalï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å« 2100 ä¸ªè·¨é¢†åŸŸå®ä¾‹çš„æ–°å‹åŸºå‡†ï¼Œæ¶µç›–å¤šç§é¢†åŸŸä¸”å…·æœ‰å¤æ‚çš„æ·±åº¦åµŒå¥—ç»“æ„ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œä¸»æµ LLMs åœ¨å¤„ç†æ­¤ç±»é«˜å¤æ‚æ€§ä»»åŠ¡æ—¶è¡¨ç°å‡ºæ˜¾è‘—çš„æ€§èƒ½å·®è·ã€‚è¯¥ç ”ç©¶é€šè¿‡å¼€æº DeepJSONEval åŸºå‡†å’Œæ•°æ®é›†ï¼Œæ—¨åœ¨æ¨åŠ¨ç»“æ„åŒ– JSON ç”ŸæˆåŠå¤æ‚æ•°æ®æŒ–æ˜é¢†åŸŸçš„ç ”ç©¶è¿›å±•ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25922v1",
      "published_date": "2025-09-30 08:18:20 UTC",
      "updated_date": "2025-09-30 08:18:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:40:51.681059+00:00"
    },
    {
      "arxiv_id": "2509.25919v1",
      "title": "Accelerating LLM Inference with Precomputed Query Storage",
      "title_zh": "åˆ©ç”¨é¢„è®¡ç®—æŸ¥è¯¢å­˜å‚¨åŠ é€Ÿå¤§è¯­è¨€æ¨¡å‹æ¨ç†",
      "authors": [
        "Jay H. Park",
        "Youngju Cho",
        "Choungsol Lee",
        "Moonwook Oh",
        "Euiseong Seo"
      ],
      "abstract": "Large language model (LLM) inference often suffers from high latency, particularly in resource-constrained environments such as on-device or edge deployments. To address this challenge, we present StorInfer, a novel storage-assisted LLM inference system that accelerates response time by precomputing and storing predictable query-response pairs offline. When a user query semantically matches a precomputed query, StorInfer bypasses expensive GPU inference and instantly returns the stored response, significantly reducing latency and compute costs. To maximize coverage and effectiveness, StorInfer employs an LLM-driven generator that adaptively produces diverse and deduplicated queries based on a given knowledge base. This is achieved via two techniques: adaptive query masking, which prevents regeneration of similar queries, and adaptive sampling, which dynamically tunes generation parameters to promote semantic diversity. The resulting query-response pairs are embedded and indexed using a disk-backed vector database to enable fast, similarity-based retrieval at runtime. Using this approach, we generated 150K unique precomputed pairs (taking up to 830 MB of storage space), achieving up to 17.3% latency reduction with no loss in response quality. Our evaluation across multiple QA datasets demonstrates the practicality and scalability of storage-assisted inference, especially in scenarios with predictable query distributions. StorInfer highlights a promising direction in leveraging storage as a primary enabler for efficient, low-latency LLM deployment.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† StorInferï¼Œä¸€ç§æ–°å‹çš„å­˜å‚¨è¾…åŠ© Large language model (LLM) æ¨ç†ç³»ç»Ÿï¼Œæ—¨åœ¨è§£å†³ LLM åœ¨è®¾å¤‡ç«¯æˆ–è¾¹ç¼˜éƒ¨ç½²ä¸­é¢ä¸´çš„é«˜å»¶è¿Ÿé—®é¢˜ã€‚è¯¥ç³»ç»Ÿé€šè¿‡ç¦»çº¿é¢„è®¡ç®—å¹¶å­˜å‚¨å¯é¢„æµ‹çš„ query-response å¯¹ï¼Œåœ¨æ¨ç†æ—¶åˆ©ç”¨è¯­ä¹‰åŒ¹é…æŠ€æœ¯ç»•è¿‡æ˜‚è´µçš„ GPU æ¨ç†ï¼Œä»è€Œå®ç°å³æ—¶å“åº”å¹¶é™ä½è®¡ç®—æˆæœ¬ã€‚ä¸ºäº†æé«˜è¦†ç›–ç‡å’Œæœ‰æ•ˆæ€§ï¼ŒStorInfer é‡‡ç”¨äº†ä¸€ç§ LLM é©±åŠ¨çš„ç”Ÿæˆå™¨ï¼Œç»“åˆ adaptive query masking å’Œ adaptive sampling æŠ€æœ¯æ¥ç”Ÿæˆå¤šæ ·åŒ–ä¸”å»é‡çš„æŸ¥è¯¢ã€‚ç”Ÿæˆçš„ query-response å¯¹é€šè¿‡åŸºäºç£ç›˜çš„ vector database è¿›è¡ŒåµŒå…¥å’Œç´¢å¼•ï¼Œç¡®ä¿åœ¨è¿è¡Œæ—¶èƒ½è¿›è¡Œå¿«é€Ÿçš„ç›¸ä¼¼æ€§æ£€ç´¢ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œé€šè¿‡ç”Ÿæˆ 150K ä¸ªå”¯ä¸€çš„é¢„è®¡ç®—å¯¹ï¼ŒStorInfer åœ¨ä¸æŸå¤±å“åº”è´¨é‡çš„å‰æä¸‹ï¼ŒæˆåŠŸé™ä½äº†é«˜è¾¾ 17.3% çš„æ¨ç†å»¶è¿Ÿã€‚è¯¥ç ”ç©¶è¯æ˜äº†åœ¨æŸ¥è¯¢åˆ†å¸ƒå¯é¢„æµ‹çš„åœºæ™¯ä¸‹ï¼Œåˆ©ç”¨å­˜å‚¨ç©ºé—´æ¢å–è®¡ç®—æ•ˆç‡æ˜¯å®ç°é«˜æ•ˆã€ä½å»¶è¿Ÿ LLM éƒ¨ç½²çš„ä¸€ä¸ªæå…·æ½œåŠ›çš„æ–¹å‘ã€‚",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25919v1",
      "published_date": "2025-09-30 08:14:04 UTC",
      "updated_date": "2025-09-30 08:14:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:40:51.476284+00:00"
    },
    {
      "arxiv_id": "2509.25905v1",
      "title": "User-Centric Communication Service Provision for Edge-Assisted Mobile Augmented Reality",
      "title_zh": "é¢å‘è¾¹ç¼˜è¾…åŠ©ç§»åŠ¨å¢å¼ºç°å®çš„ä»¥ç”¨æˆ·ä¸ºä¸­å¿ƒé€šä¿¡æœåŠ¡æä¾›",
      "authors": [
        "Conghao Zhou",
        "Jie Gao",
        "Shisheng Hu",
        "Nan Cheng",
        "Weihua Zhuang",
        "Xuemin Shen"
      ],
      "abstract": "Future 6G networks are envisioned to facilitate edge-assisted mobile augmented reality (MAR) via strengthening the collaboration between MAR devices and edge servers. In order to provide immersive user experiences, MAR devices must timely upload camera frames to an edge server for simultaneous localization and mapping (SLAM)-based device pose tracking. In this paper, to cope with user-specific and non-stationary uplink data traffic, we develop a digital twin (DT)-based approach for user-centric communication service provision for MAR. Specifically, to establish DTs for individual MAR devices, we first construct a data model customized for MAR that captures the intricate impact of the SLAM-based frame uploading mechanism on the user-specific data traffic pattern. We then define two DT operation functions that cooperatively enable adaptive switching between different data-driven models for capturing non-stationary data traffic. Leveraging the user-oriented data management introduced by DTs, we propose an algorithm for network resource management that ensures the timeliness of frame uploading and the robustness against inherent inaccuracies in data traffic modeling for individual MAR devices. Trace-driven simulation results demonstrate that the user-centric communication service provision achieves a 14.2% increase in meeting the camera frame uploading delay requirement in comparison with the slicing-based communication service provision widely used for 5G.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹è¾¹ç¼˜è¾…åŠ©ç§»åŠ¨å¢å¼ºç°å®(Mobile Augmented Reality, MAR)åœ¨6Gç½‘ç»œä¸­çš„åº”ç”¨ï¼Œæå‡ºäº†ä¸€ç§ä»¥ç”¨æˆ·ä¸ºä¸­å¿ƒçš„é€šä¿¡æœåŠ¡æ–¹æ¡ˆï¼Œä»¥è§£å†³åŸºäºSLAMçš„è®¾å¤‡ä½å§¿è·Ÿè¸ªå¯¹ç›¸æœºå¸§ä¸Šä¼ å®æ—¶æ€§çš„ä¸¥è‹›è¦æ±‚ã€‚è¯¥æ–¹æ¡ˆå¼•å…¥äº†æ•°å­—å­ªç”Ÿ(Digital Twin, DT)æŠ€æœ¯ï¼Œé€šè¿‡ä¸ºä¸ªä½“MARè®¾å¤‡æ„å»ºå®šåˆ¶åŒ–çš„æ•°æ®æ¨¡å‹ï¼Œç²¾ç¡®æ•æ‰SLAMæœºåˆ¶äº§ç”Ÿçš„å¤æ‚æµé‡æ¨¡å¼ã€‚ç ”ç©¶å®šä¹‰äº†ä¸¤ç§DTæ“ä½œå‡½æ•°ï¼Œæ”¯æŒåœ¨ä¸åŒçš„æ•°æ®é©±åŠ¨æ¨¡å‹é—´è¿›è¡Œè‡ªé€‚åº”åˆ‡æ¢ï¼Œä»è€Œæœ‰æ•ˆåº”å¯¹éå¹³ç¨³çš„ä¸Šè¡Œé“¾è·¯æµé‡ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œè®ºæ–‡è®¾è®¡äº†ä¸€ç§ç½‘ç»œèµ„æºç®¡ç†ç®—æ³•ï¼Œåœ¨ç¡®ä¿å¸§ä¸Šä¼ åŠæ—¶æ€§çš„åŒæ—¶ï¼Œæå‡äº†ç³»ç»Ÿå¯¹æµé‡å»ºæ¨¡è¯¯å·®çš„é²æ£’æ€§ã€‚åŸºäºè¿¹é©±åŠ¨çš„ä»¿çœŸç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ¡ˆåœ¨æ»¡è¶³å»¶è¿Ÿè¦æ±‚æ–¹é¢æ¯”5Gå¸¸ç”¨çš„ç½‘ç»œåˆ‡ç‰‡(Slicing-based)æœåŠ¡æå‡äº†14.2%ï¼Œæ˜¾è‘—æ”¹å–„äº†æ²‰æµ¸å¼ç”¨æˆ·ä½“éªŒã€‚",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "accepted by IEEE Transactions on Mobile Computing",
      "pdf_url": "https://arxiv.org/pdf/2509.25905v1",
      "published_date": "2025-09-30 07:50:32 UTC",
      "updated_date": "2025-09-30 07:50:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:40:54.674335+00:00"
    },
    {
      "arxiv_id": "2509.25903v1",
      "title": "PerQ: Efficient Evaluation of Multilingual Text Personalization Quality",
      "title_zh": "PerQï¼šå¤šè¯­è¨€æ–‡æœ¬ä¸ªæ€§åŒ–è´¨é‡çš„é«˜æ•ˆè¯„ä¼°",
      "authors": [
        "Dominik Macko",
        "Andrew Pulver"
      ],
      "abstract": "Since no metrics are available to evaluate specific aspects of a text, such as its personalization quality, the researchers often rely solely on large language models to meta-evaluate such texts. Due to internal biases of individual language models, it is recommended to use multiple of them for combined evaluation, which directly increases costs of such meta-evaluation. In this paper, a computationally efficient method for evaluation of personalization quality of a given text (generated by a language model) is introduced, called PerQ. A case study of comparison of generation capabilities of large and small language models shows the usability of the proposed metric in research, effectively reducing the waste of resources.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰æŠ€æœ¯ä¸­ç¼ºä¹è¯„ä¼°æ–‡æœ¬ Personalization Quality çš„ç‰¹å®šæŒ‡æ ‡ï¼Œä»¥åŠä¾èµ–å¤šä¸ª Large Language Models (LLMs) è¿›è¡Œå…ƒè¯„ä¼°å¯¼è‡´æˆæœ¬è¿‡é«˜çš„é—®é¢˜ï¼Œæå‡ºäº† PerQ è¿™ä¸€è®¡ç®—é«˜æ•ˆçš„è¯„ä¼°æ–¹æ³•ã€‚PerQ æ—¨åœ¨å¯¹è¯­è¨€æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬ä¸ªæ€§åŒ–è´¨é‡è¿›è¡Œç²¾å‡†è¡¡é‡ï¼Œæœ‰æ•ˆé™ä½äº† Meta-evaluation è¿‡ç¨‹ä¸­çš„èµ„æºæ¶ˆè€—ã€‚é€šè¿‡å¯¹å¤§å‹å’Œå°å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆèƒ½åŠ›çš„ Case Study å¯¹æ¯”ï¼Œç ”ç©¶å±•ç¤ºäº†è¯¥æŒ‡æ ‡åœ¨å­¦æœ¯ç ”ç©¶ä¸­çš„é«˜åº¦å®ç”¨æ€§ã€‚å®éªŒè¯æ˜ PerQ ä¸ä»…èƒ½è§£å†³å•ä¸€æ¨¡å‹çš„å†…éƒ¨åè§é—®é¢˜ï¼Œè¿˜èƒ½æ˜¾è‘—å‡å°‘è¯„ä¼°æ‰€éœ€çš„è®¡ç®—èµ„æºã€‚è¯¥æ–¹æ³•çš„æå‡ºä¸ºå¤šè¯­è¨€ç¯å¢ƒä¸‹çš„æ–‡æœ¬ä¸ªæ€§åŒ–è¯„ä¼°æä¾›äº†ä¸€ç§æ›´åŠ ç»æµä¸”å¯é çš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25903v1",
      "published_date": "2025-09-30 07:48:14 UTC",
      "updated_date": "2025-09-30 07:48:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:40:58.783533+00:00"
    },
    {
      "arxiv_id": "2510.03301v1",
      "title": "Dynamic Meta-Learning for Adaptive XGBoost-Neural Ensembles",
      "title_zh": "é¢å‘è‡ªé€‚åº” XGBoost-ç¥ç»ç½‘ç»œé›†æˆçš„åŠ¨æ€å…ƒå­¦ä¹ ",
      "authors": [
        "Arthur Sedek"
      ],
      "abstract": "This paper introduces a novel adaptive ensemble framework that synergistically combines XGBoost and neural networks through sophisticated meta-learning. The proposed method leverages advanced uncertainty quantification techniques and feature importance integration to dynamically orchestrate model selection and combination. Experimental results demonstrate superior predictive performance and enhanced interpretability across diverse datasets, contributing to the development of more intelligent and flexible machine learning systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°å‹è‡ªé€‚åº”é›†æˆæ¡†æ¶ï¼Œé€šè¿‡å…ˆè¿›çš„å…ƒå­¦ä¹ (Meta-Learning)æŠ€æœ¯å°†XGBoostä¸ç¥ç»ç½‘ç»œ(Neural Networks)è¿›è¡ŒååŒç»“åˆã€‚è¯¥æ–¹æ³•åˆ©ç”¨ä¸ç¡®å®šæ€§é‡åŒ–(Uncertainty Quantification)æŠ€æœ¯å’Œç‰¹å¾é‡è¦æ€§é›†æˆ(Feature Importance Integration)ï¼ŒåŠ¨æ€åœ°å¯¹æ¨¡å‹é€‰æ‹©å’Œç»„åˆè¿›è¡Œç¼–æ’ã€‚å®éªŒç»“æœåœ¨å¤šç§æ•°æ®é›†ä¸ŠéªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œè¯æ˜å…¶ä¸ä»…å…·æœ‰å“è¶Šçš„é¢„æµ‹æ€§èƒ½ï¼Œè¿˜æ˜¾è‘—å¢å¼ºäº†æ¨¡å‹çš„å¯è§£é‡Šæ€§(Interpretability)ã€‚è¿™é¡¹å·¥ä½œä¸ºæ„å»ºæ›´æ™ºèƒ½ã€æ›´çµæ´»çš„æœºå™¨å­¦ä¹ ç³»ç»Ÿåšå‡ºäº†é‡è¦è´¡çŒ®ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.03301v1",
      "published_date": "2025-09-30 07:45:49 UTC",
      "updated_date": "2025-09-30 07:45:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:41:26.587260+00:00"
    },
    {
      "arxiv_id": "2509.25897v1",
      "title": "RoleConflictBench: A Benchmark of Role Conflict Scenarios for Evaluating LLMs' Contextual Sensitivity",
      "title_zh": "RoleConflictBenchï¼šç”¨äºè¯„ä¼°å¤§è¯­è¨€æ¨¡å‹è¯­å¢ƒæ•æ„Ÿæ€§çš„è§’è‰²å†²çªåœºæ™¯åŸºå‡†",
      "authors": [
        "Jisu Shin",
        "Hoyun Song",
        "Juhyun Oh",
        "Changgeon Ko",
        "Eunsu Kim",
        "Chani Jung",
        "Alice Oh"
      ],
      "abstract": "Humans often encounter role conflicts -- social dilemmas where the expectations of multiple roles clash and cannot be simultaneously fulfilled. As large language models (LLMs) become increasingly influential in human decision-making, understanding how they behave in complex social situations is essential. While previous research has evaluated LLMs' social abilities in contexts with predefined correct answers, role conflicts represent inherently ambiguous social dilemmas that require contextual sensitivity: the ability to recognize and appropriately weigh situational cues that can fundamentally alter decision priorities. To address this gap, we introduce RoleConflictBench, a novel benchmark designed to evaluate LLMs' contextual sensitivity in complex social dilemmas. Our benchmark employs a three-stage pipeline to generate over 13K realistic role conflict scenarios across 65 roles, systematically varying their associated expectations (i.e., their responsibilities and obligations) and situational urgency levels. By analyzing model choices across 10 different LLMs, we find that while LLMs show some capacity to respond to these contextual cues, this sensitivity is insufficient. Instead, their decisions are predominantly governed by a powerful, inherent bias related to social roles rather than situational information. Our analysis quantifies these biases, revealing a dominant preference for roles within the Family and Occupation domains, as well as a clear prioritization of male roles and Abrahamic religions across most evaluatee models.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† RoleConflictBenchï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“é—¨ç”¨äºè¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) åœ¨å¤æ‚ç¤¾ä¼šå›°å¢ƒä¸­è¯­å¢ƒæ•æ„Ÿæ€§ (contextual sensitivity) çš„æ–°å‹åŸºå‡†æµ‹è¯•ã€‚è¯¥åŸºå‡†é€šè¿‡ä¸€ä¸ªä¸‰é˜¶æ®µæµæ°´çº¿ç”Ÿæˆäº†æ¶µç›– 65 ç§è§’è‰²çš„è¶…è¿‡ 1.3 ä¸‡ä¸ªçœŸå®è§’è‰²å†²çªåœºæ™¯ï¼Œå¹¶ç³»ç»Ÿæ€§åœ°æ”¹å˜äº†å…¶ç›¸å…³çš„è´£ä»»ä¹‰åŠ¡åŠæƒ…å¢ƒç´§è¿«ç¨‹åº¦ã€‚é€šè¿‡å¯¹ 10 ç§ä¸åŒ LLMs çš„å†³ç­–åˆ†æï¼Œç ”ç©¶å‘ç°è™½ç„¶æ¨¡å‹å±•ç°å‡ºäº†ä¸€å®šçš„è¯­å¢ƒçº¿ç´¢å“åº”èƒ½åŠ›ï¼Œä½†è¿™ç§æ•æ„Ÿæ€§åœ¨å¤„ç†å¤æ‚å†²çªæ—¶ä»ç„¶ä¸è¶³ã€‚æ¨¡å‹çš„å†³ç­–ä¸»è¦å—åˆ°ä¸ç¤¾ä¼šè§’è‰²ç›¸å…³çš„å¼ºå¤§å›ºæœ‰åå·® (inherent bias) é©±åŠ¨ï¼Œè€Œéå®Œå…¨ä¾èµ–äºæƒ…å¢ƒä¿¡æ¯ã€‚å®éªŒé‡åŒ–äº†è¿™äº›åå·®ï¼Œæ­ç¤ºå‡ºæ¨¡å‹æ™®éåå¥½å®¶åº­ (Family) å’ŒèŒä¸š (Occupation) é¢†åŸŸçš„è§’è‰²ï¼Œå¹¶ä¸”åœ¨å¤§å¤šæ•°è¢«è¯„ä¼°æ¨¡å‹ä¸­å­˜åœ¨æ˜æ˜¾çš„ç”·æ€§è§’è‰²å’Œäºšä¼¯æ‹‰ç½•è¯¸æ•™ (Abrahamic religions) ä¼˜å…ˆå€¾å‘ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25897v1",
      "published_date": "2025-09-30 07:42:49 UTC",
      "updated_date": "2025-09-30 07:42:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:41:28.685189+00:00"
    },
    {
      "arxiv_id": "2509.25885v1",
      "title": "SafeMind: Benchmarking and Mitigating Safety Risks in Embodied LLM Agents",
      "title_zh": "SafeMindï¼šå…·èº«å¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“å®‰å…¨é£é™©çš„åŸºå‡†æµ‹è¯•ä¸ç¼“è§£",
      "authors": [
        "Ruolin Chen",
        "Yinqian Sun",
        "Jihang Wang",
        "Mingyang Lv",
        "Qian Zhang",
        "Yi Zeng"
      ],
      "abstract": "Embodied agents powered by large language models (LLMs) inherit advanced planning capabilities; however, their direct interaction with the physical world exposes them to safety vulnerabilities. In this work, we identify four key reasoning stages where hazards may arise: Task Understanding, Environment Perception, High-Level Plan Generation, and Low-Level Action Generation. We further formalize three orthogonal safety constraint types (Factual, Causal, and Temporal) to systematically characterize potential safety violations. Building on this risk model, we present SafeMindBench, a multimodal benchmark with 5,558 samples spanning four task categories (Instr-Risk, Env-Risk, Order-Fix, Req-Align) across high-risk scenarios such as sabotage, harm, privacy, and illegal behavior. Extensive experiments on SafeMindBench reveal that leading LLMs (e.g., GPT-4o) and widely used embodied agents remain susceptible to safety-critical failures. To address this challenge, we introduce SafeMindAgent, a modular Planner-Executor architecture integrated with three cascaded safety modules, which incorporate safety constraints into the reasoning process. Results show that SafeMindAgent significantly improves safety rate over strong baselines while maintaining comparable task completion. Together, SafeMindBench and SafeMindAgent provide both a rigorous evaluation suite and a practical solution that advance the systematic study and mitigation of safety risks in embodied LLM agents.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å…·èº«å¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“ (Embodied LLM Agents) åœ¨ç‰©ç†ä¸–ç•Œäº¤äº’ä¸­çš„å®‰å…¨æ¼æ´ï¼Œè¯†åˆ«äº†ä»»åŠ¡ç†è§£ã€ç¯å¢ƒæ„ŸçŸ¥ã€é«˜å±‚è§„åˆ’å’Œåº•å±‚åŠ¨ä½œç”Ÿæˆå››ä¸ªæ˜“äº§ç”Ÿå±å®³çš„æ¨ç†é˜¶æ®µã€‚ä½œè€…å®šä¹‰äº†äº‹å® (Factual)ã€å› æœ (Causal) å’Œæ—¶åº (Temporal) ä¸‰ç§æ­£äº¤çš„å®‰å…¨çº¦æŸç±»å‹ï¼Œå¹¶æ¨å‡ºäº†åŒ…å« 5,558 ä¸ªæ ·æœ¬çš„å¤šæ¨¡æ€åŸºå‡†æµ‹è¯• SafeMindBenchï¼Œæ¶µç›–ç ´åã€ä¼¤å®³ã€éšç§å’Œéæ³•è¡Œä¸ºç­‰é«˜é£é™©åœºæ™¯ã€‚å®éªŒè¡¨æ˜ï¼ŒåŒ…æ‹¬ GPT-4o åœ¨å†…çš„é¢†å…ˆæ¨¡å‹åœ¨å®‰å…¨å…³é”®ä»»åŠ¡ä¸Šä¾ç„¶è¡¨ç°æ¬ ä½³ã€‚é’ˆå¯¹æ­¤é—®é¢˜ï¼Œç ”ç©¶æå‡ºäº† SafeMindAgentï¼Œè¿™æ˜¯ä¸€ç§é›†æˆçº§è”å®‰å…¨æ¨¡å—çš„ Planner-Executor æ¶æ„ï¼Œå°†å®‰å…¨çº¦æŸèå…¥æ¨ç†è¿‡ç¨‹ã€‚ç»“æœè¯æ˜ SafeMindAgent åœ¨ä¿æŒä»»åŠ¡å®Œæˆåº¦çš„åŒæ—¶æ˜¾è‘—æå‡äº†å®‰å…¨ç‡ï¼Œä¸ºå…·èº«æ™ºèƒ½ä½“å®‰å…¨é£é™©çš„ç³»ç»ŸåŒ–ç ”ç©¶ä¸ç¼“è§£æä¾›äº†ä¸¥è°¨çš„è¯„ä¼°å·¥å…·å’Œå®ç”¨æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25885v1",
      "published_date": "2025-09-30 07:24:04 UTC",
      "updated_date": "2025-09-30 07:24:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:41:36.498741+00:00"
    },
    {
      "arxiv_id": "2509.25884v2",
      "title": "scUnified: An AI-Ready Standardized Resource for Single-Cell RNA Sequencing Analysis",
      "title_zh": "scUnifiedï¼šé¢å‘å•ç»†èƒ RNA æµ‹åºåˆ†æçš„ AI å°±ç»ªæ ‡å‡†åŒ–èµ„æº",
      "authors": [
        "Ping Xu",
        "Zaitian Wang",
        "Zhirui Wang",
        "Pengjiang Li",
        "Ran Zhang",
        "Gaoyang Li",
        "Hanyu Xie",
        "Jiajia Wang",
        "Yuanchun Zhou",
        "Pengfei Wang"
      ],
      "abstract": "Single-cell RNA sequencing (scRNA-seq) technology enables systematic delineation of cellular states and interactions, providing crucial insights into cellular heterogeneity. Building on this potential, numerous computational methods have been developed for tasks such as cell clustering, cell type annotation, and marker gene identification. To fully assess and compare these methods, standardized, analysis-ready datasets are essential. However, such datasets remain scarce, and variations in data formats, preprocessing workflows, and annotation strategies hinder reproducibility and complicate systematic evaluation of existing methods. To address these challenges, we present scUnified, an AI-ready standardized resource for single-cell RNA sequencing data that consolidates 13 high-quality datasets spanning two species (human and mouse) and nine tissue types. All datasets undergo standardized quality control and preprocessing and are stored in a uniform format to enable direct application in diverse computational analyses without additional data cleaning. We further demonstrate the utility of scUnified through experimental analyses of representative biological tasks, providing a reproducible foundation for the standardized evaluation of computational methods on a unified dataset.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† scUnifiedï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“ä¸ºäººå·¥æ™ºèƒ½ (AI-ready) è®¾è®¡çš„å•ç»†èƒ RNA æµ‹åº (scRNA-seq) åˆ†ææ ‡å‡†åŒ–èµ„æºï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ•°æ®é›†æ ¼å¼ä¸ä¸€ã€é¢„å¤„ç†æµç¨‹å¤šæ ·ä»¥åŠæ³¨é‡Šç­–ç•¥å·®å¼‚å¯¼è‡´çš„å¤ç°æ€§éš¾é¢˜ã€‚è¯¥èµ„æºæ•´åˆäº†æ¶µç›–äººç±»å’Œå°é¼ ä¸¤ä¸ªç‰©ç§åŠä¹ç§ç»„ç»‡ç±»å‹çš„ 13 ä¸ªé«˜è´¨é‡æ•°æ®é›†ï¼Œå¹¶å¯¹å…¶è¿›è¡Œäº†ç»Ÿä¸€çš„è´¨é‡æ§åˆ¶ (Quality Control) å’Œé¢„å¤„ç†ã€‚é€šè¿‡é‡‡ç”¨æ ‡å‡†åŒ–çš„å­˜å‚¨æ ¼å¼ï¼ŒscUnified ä½¿å¾—å•ç»†èƒæ•°æ®å¯ä»¥ç›´æ¥åº”ç”¨äºç»†èƒèšç±» (cell clustering) å’Œç»†èƒç±»å‹æ³¨é‡Š (cell type annotation) ç­‰å¤šæ ·åŒ–çš„è®¡ç®—ä»»åŠ¡ï¼Œæ— éœ€é¢å¤–çš„æ•°æ®æ¸…æ´—å·¥ä½œã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡å¤šä¸ªä»£è¡¨æ€§ç”Ÿç‰©å­¦ä»»åŠ¡çš„å®éªŒåˆ†æéªŒè¯äº†è¯¥èµ„æºçš„å®ç”¨æ€§ï¼Œä¸ºè®¡ç®—æ–¹æ³•çš„ç³»ç»Ÿæ€§è¯„ä»·å’ŒåŸºå‡†æµ‹è¯•æä¾›äº†ä¸€ä¸ªå¯å¤ç°çš„åŸºç¡€æ¡†æ¶ã€‚scUnified çš„å‘å¸ƒæ˜¾è‘—é™ä½äº†å•ç»†èƒæ•°æ®åˆ†æçš„é—¨æ§›ï¼Œä¿ƒè¿›äº†ç”Ÿç‰©ä¿¡æ¯å­¦ç®—æ³•åœ¨ç»Ÿä¸€åŸºå‡†ä¸‹çš„å…¬å¹³å¯¹æ¯”ã€‚",
      "categories": [
        "q-bio.GN",
        "cs.AI"
      ],
      "primary_category": "q-bio.GN",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25884v2",
      "published_date": "2025-09-30 07:23:01 UTC",
      "updated_date": "2025-11-10 03:55:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:41:38.985633+00:00"
    },
    {
      "arxiv_id": "2509.25876v1",
      "title": "Efficient On-Policy Reinforcement Learning via Exploration of Sparse Parameter Space",
      "title_zh": "åŸºäºç¨€ç–å‚æ•°ç©ºé—´æ¢ç´¢çš„é«˜æ•ˆåœ¨ç­–ç•¥å¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Xinyu Zhang",
        "Aishik Deb",
        "Klaus Mueller"
      ],
      "abstract": "Policy-gradient methods such as Proximal Policy Optimization (PPO) are typically updated along a single stochastic gradient direction, leaving the rich local structure of the parameter space unexplored. Previous work has shown that the surrogate gradient is often poorly correlated with the true reward landscape. Building on this insight, we visualize the parameter space spanned by policy checkpoints within an iteration and reveal that higher performing solutions often lie in nearby unexplored regions. To exploit this opportunity, we introduce ExploRLer, a pluggable pipeline that seamlessly integrates with on-policy algorithms such as PPO and TRPO, systematically probing the unexplored neighborhoods of surrogate on-policy gradient updates. Without increasing the number of gradient updates, ExploRLer achieves significant improvements over baselines in complex continuous control environments. Our results demonstrate that iteration-level exploration provides a practical and effective way to strengthen on-policy reinforcement learning and offer a fresh perspective on the limitations of the surrogate objective.",
      "tldr_zh": "è¯¥ç ”ç©¶æŒ‡å‡ºä¼ ç»Ÿçš„ç­–ç•¥æ¢¯åº¦(Policy-gradient)æ–¹æ³•ï¼ˆå¦‚PPOï¼‰é€šå¸¸æ²¿å•ä¸€éšæœºæ¢¯åº¦æ–¹å‘æ›´æ–°ï¼Œå¿½ç•¥äº†å‚æ•°ç©ºé—´ä¸°å¯Œçš„å±€éƒ¨ç»“æ„ï¼Œå¯¼è‡´ä»£ç†æ¢¯åº¦ä¸çœŸå®å¥–åŠ±æ™¯è§‚ç›¸å…³æ€§è¾ƒå·®ã€‚é€šè¿‡å¯è§†åŒ–åˆ†æï¼Œä½œè€…å‘ç°åœ¨è¿­ä»£è¿‡ç¨‹ä¸­çš„ç­–ç•¥æ£€æŸ¥ç‚¹é™„è¿‘å¾€å¾€å­˜åœ¨æ€§èƒ½æ›´é«˜ä½†æœªè¢«æ¢ç´¢çš„åŒºåŸŸã€‚ä¸ºæ­¤ï¼Œè¯¥ç ”ç©¶æå‡ºäº†ExploRLerï¼Œè¿™æ˜¯ä¸€ç§å¯æ— ç¼é›†æˆäºPPOå’ŒTRPOç­‰åœ¨çº¿ç­–ç•¥(On-policy)ç®—æ³•çš„æ’ä»¶å¼æµæ°´çº¿ã€‚ExploRLeré€šè¿‡ç³»ç»Ÿåœ°æ¢æµ‹ä»£ç†åœ¨çº¿ç­–ç•¥æ¢¯åº¦æ›´æ–°çš„æœªæ¢ç´¢é‚»åŸŸï¼Œåœ¨ä¸å¢åŠ æ¢¯åº¦æ›´æ–°æ¬¡æ•°çš„å‰æä¸‹ï¼Œåœ¨å¤æ‚çš„è¿ç»­æ§åˆ¶(Continuous control)ç¯å¢ƒä¸­ç›¸æ¯”åŸºå‡†æ¨¡å‹å®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¿­ä»£çº§åˆ«çš„æ¢ç´¢æ˜¯åŠ å¼ºåœ¨çº¿ç­–ç•¥å¼ºåŒ–å­¦ä¹ çš„ä¸€ç§å®ç”¨ä¸”æœ‰æ•ˆçš„æ–¹æ³•ï¼ŒåŒæ—¶ä¹Ÿä¸ºç†è§£ä»£ç†ç›®æ ‡(Surrogate objective)çš„å±€é™æ€§æä¾›äº†æ–°çš„è§†è§’ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages; 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.25876v1",
      "published_date": "2025-09-30 07:13:55 UTC",
      "updated_date": "2025-09-30 07:13:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:41:46.585864+00:00"
    },
    {
      "arxiv_id": "2509.25873v1",
      "title": "Lita: Light Agent Uncovers the Agentic Coding Capabilities of LLMs",
      "title_zh": "Litaï¼šé€šè¿‡è½»é‡çº§æ™ºèƒ½ä½“æ­ç¤ºå¤§è¯­è¨€æ¨¡å‹çš„æ™ºèƒ½ä½“åŒ–ç¼–ç¨‹èƒ½åŠ›",
      "authors": [
        "Hankun Dai",
        "Maoquan Wang",
        "Mengnan Qi",
        "Yikai Zhang",
        "Zijian Jin",
        "Yongqiang Yao",
        "Yufan Huang",
        "Shengyu Fu",
        "Elsie Nallipogu"
      ],
      "abstract": "Large language models (LLMs) are increasingly being applied to programming tasks, ranging from single-turn code completion to autonomous agents. Current code agent designs frequently depend on complex, hand-crafted workflows and tool sets. However, this reliance on elaborate scaffolding presents several challenges: agent performance becomes overly dependent on prompt tuning and custom design choices, heavy human intervention obscures a model's true underlying capabilities, and intricate pipelines are costly to build and maintain. Furthermore, optimizing complex task prompts increases the risk of data leakage. Currently, when introducing new models, LLM providers like OpenAI and Anthropic often publish benchmark scores to demonstrate their models' coding proficiency, but keep their proprietary evaluation frameworks confidential. To address these limitations, we introduce Lita (Lite Agent), which operationalizes liteness, a principle of minimizing manual design while retaining the essential elements of a fully autonomous agent. Lita enables a more faithful and unified evaluation without elaborate scaffolding. Experiments on the Aider Polyglot and SWE-Bench with frontier models demonstrate that Lita achieves competitive or superior performance compared to workflow-based and agentic baselines. Crucially, Lita also consumes fewer tokens and requires significantly less design effort. Our results suggest that Lita is sufficient to reveal the underlying coding competence of modern LLMs. Finally, we propose the Agent Complexity Law: the performance gap between agents of varying complexity, from simple to sophisticated designs, will shrink as the core model improves, ultimately converging to a negligible difference.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å½“å‰ä»£ç æ™ºèƒ½ä½“ï¼ˆcode agentsï¼‰è¿‡åº¦ä¾èµ–å¤æ‚æ‰‹å·¥å·¥ä½œæµå’Œç¹é‡æ”¯æ¶ï¼ˆscaffoldingï¼‰å¯¼è‡´æ¨¡å‹çœŸå®èƒ½åŠ›è¢«æ©ç›–ä¸”ç»´æŠ¤æˆæœ¬é«˜æ˜‚çš„é—®é¢˜ï¼Œæå‡ºäº† Litaï¼ˆLite Agentï¼‰æ¡†æ¶ã€‚Lita éµå¾ªè½»é‡åŒ–ï¼ˆlitenessï¼‰åŸåˆ™ï¼Œæ—¨åœ¨é€šè¿‡æœ€å°åŒ–äººå·¥è®¾è®¡å¹¶ä¿ç•™è‡ªä¸»æ™ºèƒ½ä½“çš„æ ¸å¿ƒè¦ç´ ï¼Œå®ç°å¯¹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ç¼–ç¨‹èƒ½åŠ›çš„æ›´å¿ å®ä¸”ç»Ÿä¸€çš„è¯„ä¼°ã€‚åœ¨ Aider Polyglot å’Œ SWE-Bench åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒLita åœ¨æ€§èƒ½ä¸Šä¸ä»…èƒ½ä¸å¤æ‚çš„æ™ºèƒ½ä½“åŸºçº¿ç›¸åª²ç¾ç”šè‡³æ›´ä¼˜ï¼ŒåŒæ—¶æ¶ˆè€—æ›´å°‘çš„ token ä¸”æ˜¾è‘—é™ä½äº†è®¾è®¡éš¾åº¦ã€‚ç ”ç©¶ç»“æœè¯æ˜ Lita è¶³ä»¥æ­ç¤ºç°ä»£ LLMs åº•å±‚çš„æ ¸å¿ƒä»£ç èƒ½åŠ›ã€‚æœ€åï¼Œè®ºæ–‡æå‡ºäº†æ™ºèƒ½ä½“å¤æ‚åº¦å®šå¾‹ï¼ˆAgent Complexity Lawï¼‰ï¼Œè®¤ä¸ºéšç€æ ¸å¿ƒæ¨¡å‹æ€§èƒ½çš„å¢å¼ºï¼Œä¸åŒå¤æ‚åº¦æ™ºèƒ½ä½“ä¹‹é—´çš„è¡¨ç°å·®å¼‚å°†é€æ¸ç¼©å°å¹¶æœ€ç»ˆè¶‹äºä¸€è‡´ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.PL",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25873v1",
      "published_date": "2025-09-30 07:07:32 UTC",
      "updated_date": "2025-09-30 07:07:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:41:51.812185+00:00"
    },
    {
      "arxiv_id": "2509.25862v1",
      "title": "CIMNAS: A Joint Framework for Compute-In-Memory-Aware Neural Architecture Search",
      "title_zh": "CIMNASï¼šé¢å‘å­˜å†…è®¡ç®—æ„ŸçŸ¥çš„ç¥ç»ç½‘ç»œæ¶æ„æœç´¢è”åˆæ¡†æ¶",
      "authors": [
        "Olga Krestinskaya",
        "Mohammed E. Fouda",
        "Ahmed Eltawil",
        "Khaled N. Salama"
      ],
      "abstract": "To maximize hardware efficiency and performance accuracy in Compute-In-Memory (CIM)-based neural network accelerators for Artificial Intelligence (AI) applications, co-optimizing both software and hardware design parameters is essential. Manual tuning is impractical due to the vast number of parameters and their complex interdependencies. To effectively automate the design and optimization of CIM-based neural network accelerators, hardware-aware neural architecture search (HW-NAS) techniques can be applied. This work introduces CIMNAS, a joint model-quantization-hardware optimization framework for CIM architectures. CIMNAS simultaneously searches across software parameters, quantization policies, and a broad range of hardware parameters, incorporating device-, circuit-, and architecture-level co-optimizations. CIMNAS experiments were conducted over a search space of 9.9x10^85 potential parameter combinations with the MobileNet model as a baseline and RRAM-based CIM architecture. Evaluated on the ImageNet dataset, CIMNAS achieved a reduction in energy-delay-area product (EDAP) ranging from 90.1x to 104.5x, an improvement in TOPS/W between 4.68x and 4.82x, and an enhancement in TOPS/mm^2 from 11.3x to 12.78x relative to various baselines, all while maintaining an accuracy of 73.81%. The adaptability and robustness of CIMNAS are demonstrated by extending the framework to support the SRAM-based ResNet50 architecture, achieving up to an 819.5x reduction in EDAP. Unlike other state-of-the-art methods, CIMNAS achieves EDAP-focused optimization without any accuracy loss, generating diverse software-hardware parameter combinations for high-performance CIM-based neural network designs. The source code of CIMNAS is available at https://github.com/OlgaKrestinskaya/CIMNAS.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†CIMNASï¼Œä¸€ä¸ªé’ˆå¯¹å­˜ç®—ä¸€ä½“(Compute-In-Memory, CIM)æ¶æ„çš„æ¨¡å‹-é‡åŒ–-ç¡¬ä»¶è”åˆä¼˜åŒ–æ¡†æ¶ã€‚CIMNASèƒ½å¤ŸåŒæ—¶æœç´¢è½¯ä»¶å‚æ•°ã€é‡åŒ–ç­–ç•¥(quantization policies)ä»¥åŠæ¶µç›–å™¨ä»¶ã€ç”µè·¯å’Œæ¶æ„å±‚é¢çš„å¹¿æ³›ç¡¬ä»¶å‚æ•°ï¼Œæ—¨åœ¨é€šè¿‡è‡ªåŠ¨åŒ–æ‰‹æ®µè§£å†³æ‰‹åŠ¨è°ƒä¼˜é¢ä¸´çš„å¤æ‚å‚æ•°ä¾èµ–æŒ‘æˆ˜ã€‚åœ¨åŸºäºRRAMçš„CIMæ¶æ„å’ŒMobileNetæ¨¡å‹çš„ImageNetå®éªŒä¸­ï¼Œè¯¥æ¡†æ¶å°†èƒ½é‡-å»¶è¿Ÿ-é¢ç§¯ä¹˜ç§¯(EDAP)é™ä½äº†90.1è‡³104.5å€ï¼Œå¹¶æ˜¾è‘—æå‡äº†TOPS/Wå’ŒTOPS/mmÂ²ç­‰å…³é”®æ€§èƒ½æŒ‡æ ‡ã€‚æ­¤å¤–ï¼ŒCIMNASå±•ç¤ºäº†è‰¯å¥½çš„æ³›åŒ–æ€§ï¼Œåœ¨æ”¯æŒåŸºäºSRAMçš„ResNet50æ¶æ„æ—¶å®ç°äº†é«˜è¾¾819.5å€çš„EDAPç¼©å‡ã€‚ä¸ç°æœ‰æŠ€æœ¯ç›¸æ¯”ï¼ŒCIMNASåœ¨ä¸æŸå¤±å‡†ç¡®ç‡çš„å‰æä¸‹å®ç°äº†ä»¥EDAPä¸ºæ ¸å¿ƒçš„é«˜æ•ˆä¼˜åŒ–ï¼Œä¸ºæ„å»ºé«˜æ€§èƒ½CIMç¥ç»ç½‘ç»œè®¾è®¡æä¾›äº†å¤šæ ·åŒ–çš„è½¯ç¡¬ä»¶ç»„åˆæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI",
        "cs.AR",
        "cs.ET",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25862v1",
      "published_date": "2025-09-30 06:57:49 UTC",
      "updated_date": "2025-09-30 06:57:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:41:59.498922+00:00"
    },
    {
      "arxiv_id": "2510.05124v2",
      "title": "MADS: Multi-Agent Dialogue Simulation for Diverse Persuasion Data Generation",
      "title_zh": "MADSï¼šç”¨äºç”Ÿæˆå¤šæ ·åŒ–è¯´æœæ•°æ®çš„å¤šæ™ºèƒ½ä½“å¯¹è¯æ¨¡æ‹Ÿ",
      "authors": [
        "Mingjin Li",
        "Yu Liu",
        "Huayi Liu",
        "Xiang Ye",
        "Chao Jiang",
        "Hongguang Zhang",
        "Yu Ruan"
      ],
      "abstract": "We propose MADS (Multi-Agent Dialogue Simulation), a scalable framework for generating persuasive multi-turn dialogues via agent self-play. MADS employs three coordinated agents: User Agents designed to simulate diverse persona-driven behaviors by leveraging personality signifiers such as Zodiac Signs and MBTI types, a Dialog Agent executing task-oriented persuasion strategies and an Optimization Agent evaluating and refining dialogue outcomes. We further validate its effectiveness through users' Chain-of-Attitude (CoA) modeling and dedicated LLMs' persuasion assessment. This approach enables low-cost generation of training data without human annotation, addressing key industry challenges such as lack of user data, cold-start evaluation difficulties, and prompt inefficiency. Applied to a real-world marketing scenario, MADS significantly improved the persuasion capacity of small LLMs, increasing the organic traffic conversion rate by 22.4% (from 1.83% to 2.24%) , demonstrating clear business value.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† MADS (Multi-Agent Dialogue Simulation)ï¼Œè¿™æ˜¯ä¸€ä¸ªé€šè¿‡æ™ºèƒ½ä½“è‡ªåšå¼ˆ (self-play) ç”Ÿæˆè¯´æœæ€§å¤šè½®å¯¹è¯çš„å¯æ‰©å±•æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç”¨æˆ·æ•°æ®åŒ®ä¹ã€å†·å¯åŠ¨è¯„ä¼°å›°éš¾å’Œæç¤ºè¯æ•ˆç‡ä½ä¸‹ç­‰è¡Œä¸šæŒ‘æˆ˜ã€‚MADS æ ¸å¿ƒé‡‡ç”¨äº†ä¸‰ä¸ªåè°ƒçš„æ™ºèƒ½ä½“ç³»ç»Ÿï¼ŒåŒ…æ‹¬åˆ©ç”¨æ˜Ÿåº§å’Œ MBTI ç­‰äººæ ¼æ ‡è¯†ç¬¦æ¨¡æ‹Ÿå¤šæ ·åŒ–è¡Œä¸ºçš„ User Agentsã€æ‰§è¡Œä»»åŠ¡å¯¼å‘è¯´æœç­–ç•¥çš„ Dialog Agentï¼Œä»¥åŠè´Ÿè´£è¯„ä¼°å’Œä¼˜åŒ–å¯¹è¯ç»“æœçš„ Optimization Agentã€‚ç ”ç©¶è¿›ä¸€æ­¥é€šè¿‡ç”¨æˆ·çš„æ€åº¦é“¾ (Chain-of-Attitude, CoA) å»ºæ¨¡å’Œä¸“ç”¨å¤§è¯­è¨€æ¨¡å‹ (LLMs) çš„è¯´æœåŠ›è¯„ä¼°éªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œå®ç°äº†æ— éœ€äººå·¥æ ‡æ³¨çš„ä½æˆæœ¬æ•°æ®ç”Ÿæˆã€‚åœ¨å®é™…è¥é”€åœºæ™¯çš„åº”ç”¨ä¸­ï¼ŒMADS æ˜¾è‘—æå‡äº†å°å‹ LLMs çš„è¯´æœèƒ½åŠ›ï¼Œå°†æœ‰æœºæµé‡è½¬åŒ–ç‡ä» 1.83% æé«˜åˆ° 2.24%ï¼Œå®ç°äº† 22.4% çš„ç›¸å¯¹å¢é•¿ï¼Œè¯æ˜äº†è¯¥æ¡†æ¶åœ¨è‡ªåŠ¨åŒ–æ•°æ®å¢å¼ºå’Œå•†ä¸šåº”ç”¨ä¸­çš„æ˜¾è‘—ä»·å€¼ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.HC",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.05124v2",
      "published_date": "2025-09-30 06:55:39 UTC",
      "updated_date": "2025-10-11 02:50:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:42:02.194835+00:00"
    },
    {
      "arxiv_id": "2509.25858v1",
      "title": "Aging Decline in Basketball Career Trend Prediction Based on Machine Learning and LSTM Model",
      "title_zh": "åŸºäºæœºå™¨å­¦ä¹ ä¸ LSTM æ¨¡å‹çš„ç¯®çƒèŒä¸šç”Ÿæ¶¯è¶‹åŠ¿é¢„æµ‹åŠå…¶è¡°è€æ€§è¡°å‡ç ”ç©¶",
      "authors": [
        "Yi-chen Yao",
        "Jerry Wang",
        "Yi-cheng Lai",
        "Lyn Chao-ling Chen"
      ],
      "abstract": "The topic of aging decline on performance of NBA players has been discussed in this study. The autoencoder with K-means clustering machine learning method was adopted to career trend classification of NBA players, and the LSTM deep learning method was adopted in performance prediction of each NBA player. The dataset was collected from the basketball game data of veteran NBA players. The contribution of the work performed better than the other methods with generalization ability for evaluating various types of NBA career trend, and can be applied in different types of sports in the field of sport analytics.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹NBAçƒå‘˜éšå¹´é¾„å¢é•¿è€Œå‡ºç°çš„è¡¨ç°ä¸‹æ»‘ï¼ˆAging declineï¼‰é—®é¢˜ï¼Œæ¢è®¨äº†ç¯®çƒèŒä¸šç”Ÿæ¶¯è¶‹åŠ¿çš„é¢„æµ‹æ–¹æ³•ã€‚ç ”ç©¶é‡‡ç”¨äº†ä¸€ç§ç»“åˆè‡ªåŠ¨ç¼–ç å™¨ï¼ˆAutoencoderï¼‰ä¸K-meansèšç±»ï¼ˆK-means clusteringï¼‰çš„æœºå™¨å­¦ä¹ æ–¹æ³•ï¼Œå¯¹çƒå‘˜çš„èŒä¸šç”Ÿæ¶¯è¶‹åŠ¿è¿›è¡Œåˆ†ç±»ã€‚åŒæ—¶ï¼Œå¼•å…¥äº†é•¿çŸ­æœŸè®°å¿†ç½‘ç»œï¼ˆLSTMï¼‰æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œç”¨äºå¯¹æ¯ä½çƒå‘˜çš„å…·ä½“è¡¨ç°è¿›è¡ŒåŠ¨æ€é¢„æµ‹ã€‚å®éªŒæ•°æ®é›†æ¶µç›–äº†å¤šä½èµ„æ·±NBAçƒå‘˜çš„æ¯”èµ›æ•°æ®ï¼Œç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨è¯„ä¼°å„ç±»èŒä¸šè¶‹åŠ¿æ—¶çš„è¡¨ç°ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œå±•ç°å‡ºè¾ƒå¼ºçš„æ³›åŒ–èƒ½åŠ›ï¼ˆGeneralization abilityï¼‰ã€‚è¯¥é¡¹å·¥ä½œä¸ä»…ä¸ºNBAçƒå‘˜è¯„ä»·æä¾›äº†ç§‘å­¦ä¾æ®ï¼Œè¿˜å¯å¹¿æ³›åº”ç”¨äºä½“è‚²åˆ†æï¼ˆSport analyticsï¼‰é¢†åŸŸçš„ä¸åŒè¿åŠ¨é¡¹ç›®ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at Taiwan Academic Network Conference, TANET 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.25858v1",
      "published_date": "2025-09-30 06:54:22 UTC",
      "updated_date": "2025-09-30 06:54:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:42:11.489562+00:00"
    },
    {
      "arxiv_id": "2509.25857v1",
      "title": "Vector sketch animation generation with differentialable motion trajectories",
      "title_zh": "åŸºäºå¯å¾®è¿åŠ¨è½¨è¿¹çš„çŸ¢é‡æ‰‹ç»˜åŠ¨ç”»ç”Ÿæˆ",
      "authors": [
        "Xinding Zhu",
        "Xinye Yang",
        "Shuyang Zheng",
        "Zhexin Zhang",
        "Fei Gao",
        "Jing Huang",
        "Jiazhou Chen"
      ],
      "abstract": "Sketching is a direct and inexpensive means of visual expression. Though image-based sketching has been well studied, video-based sketch animation generation is still very challenging due to the temporal coherence requirement. In this paper, we propose a novel end-to-end automatic generation approach for vector sketch animation. To solve the flickering issue, we introduce a Differentiable Motion Trajectory (DMT) representation that describes the frame-wise movement of stroke control points using differentiable polynomial-based trajectories. DMT enables global semantic gradient propagation across multiple frames, significantly improving the semantic consistency and temporal coherence, and producing high-framerate output. DMT employs a Bernstein basis to balance the sensitivity of polynomial parameters, thus achieving more stable optimization. Instead of implicit fields, we introduce sparse track points for explicit spatial modeling, which improves efficiency and supports long-duration video processing. Evaluations on DAVIS and LVOS datasets demonstrate the superiority of our approach over SOTA methods. Cross-domain validation on 3D models and text-to-video data confirms the robustness and compatibility of our approach.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è§†é¢‘æ‰‹ç»˜è‰å›¾åŠ¨ç”»ç”Ÿæˆä¸­çš„æ—¶é—´ä¸€è‡´æ€§æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§ç«¯åˆ°ç«¯çš„çŸ¢é‡è‰å›¾åŠ¨ç”»è‡ªåŠ¨ç”Ÿæˆæ–¹æ³•ã€‚æ ¸å¿ƒåˆ›æ–°åœ¨äºå¼•å…¥äº†å¯å¾®åˆ†è¿åŠ¨è½¨è¿¹(Differentiable Motion Trajectory, DMT)è¡¨ç¤ºï¼Œåˆ©ç”¨å¯å¾®åˆ†çš„å¤šé¡¹å¼è½¨è¿¹æè¿°ç¬”åˆ’æ§åˆ¶ç‚¹çš„é€å¸§ä½ç§»ã€‚DMT æ”¯æŒè·¨å¤šå¸§çš„å…¨å±€è¯­ä¹‰æ¢¯åº¦ä¼ æ’­ï¼Œåœ¨æ˜¾è‘—æå‡è¯­ä¹‰ä¸€è‡´æ€§ä¸æ—¶é—´è¿è´¯æ€§çš„åŒæ—¶ï¼Œèƒ½å¤Ÿå®ç°é«˜å¸§ç‡çš„åŠ¨ç”»è¾“å‡ºã€‚æ­¤å¤–ï¼Œç ”ç©¶é‡‡ç”¨ Bernstein åŸºå‡½æ•°æ¥å¹³è¡¡å¤šé¡¹å¼å‚æ•°çš„æ•æ„Ÿæ€§ä»¥ç¡®ä¿ä¼˜åŒ–è¿‡ç¨‹çš„ç¨³å®šæ€§ï¼Œå¹¶å¼•å…¥ç¨€ç–è·Ÿè¸ªç‚¹(sparse track points)è¿›è¡Œæ˜¾å¼ç©ºé—´å»ºæ¨¡ï¼Œä»è€Œæœ‰æ•ˆæé«˜äº†é•¿è§†é¢‘å¤„ç†çš„æ•ˆç‡ã€‚åœ¨ DAVIS å’Œ LVOS æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¯æ˜è¯¥æ–¹æ³•ä¼˜äºå½“å‰çš„ SOTA æ–¹æ³•ï¼Œä¸”åœ¨3Dæ¨¡å‹å’Œæ–‡æœ¬è½¬è§†é¢‘ä»»åŠ¡ä¸­çš„è·¨é¢†åŸŸéªŒè¯å±•ç°äº†å…¶å‡ºè‰²çš„é²æ£’æ€§ä¸å…¼å®¹æ€§ã€‚",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.GR",
      "comment": "14 pages, 12 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.25857v1",
      "published_date": "2025-09-30 06:53:04 UTC",
      "updated_date": "2025-09-30 06:53:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:42:15.082097+00:00"
    },
    {
      "arxiv_id": "2509.25849v1",
      "title": "Knapsack RL: Unlocking Exploration of LLMs via Optimizing Budget Allocation",
      "title_zh": "Knapsack RLï¼šé€šè¿‡ä¼˜åŒ–é¢„ç®—åˆ†é…é‡Šæ”¾å¤§è¯­è¨€æ¨¡å‹çš„æ¢ç´¢æ½œåŠ›",
      "authors": [
        "Ziniu Li",
        "Congliang Chen",
        "Tianyun Yang",
        "Tian Ding",
        "Ruoyu Sun",
        "Ge Zhang",
        "Wenhao Huang",
        "Zhi-Quan Luo"
      ],
      "abstract": "Large Language Models (LLMs) can self-improve through reinforcement learning, where they generate trajectories to explore and discover better solutions. However, this exploration process is computationally expensive, often forcing current methods to assign limited exploration budgets to each task. This uniform allocation creates problematic edge cases: easy tasks consistently succeed while difficult tasks consistently fail, both producing zero gradients during training updates for the widely used Group Relative Policy Optimization (GRPO). We address this problem from the lens of exploration budget allocation. Viewing each task's exploration as an \"item\" with a distinct \"value\" and \"cost\", we establish a connection to the classical knapsack problem. This formulation allows us to derive an optimal assignment rule that adaptively distributes resources based on the model's current learning status. When applied to GRPO, our method increases the effective ratio of non-zero policy gradients by 20-40% during training. Acting as a computational \"free lunch\", our approach could reallocate exploration budgets from tasks where learning is saturated to those where it is most impactful. This enables significantly larger budgets (e.g., 93 rollouts) for especially challenging problems, which would be computationally prohibitive under a uniform allocation. These improvements translate to meaningful gains on mathematical reasoning benchmarks, with average improvements of 2-4 points and peak gains of 9 points on specific tasks. Notably, achieving comparable performance with traditional homogeneous allocation would require about 2x the computational resources.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Knapsack RLï¼Œæ—¨åœ¨é€šè¿‡ä¼˜åŒ–é¢„ç®—åˆ†é…ï¼ˆBudget Allocationï¼‰æ¥å¢å¼ºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¼ºåŒ–å­¦ä¹ ï¼ˆReinforcement Learningï¼‰ä¸­çš„æ¢ç´¢æ•ˆç‡ã€‚é’ˆå¯¹å½“å‰æ–¹æ³•å¯¹ä»»åŠ¡è¿›è¡Œå‡åŒ€åˆ†é…ï¼ˆUniform Allocationï¼‰å¯¼è‡´åœ¨Group Relative Policy Optimization (GRPO)ä¸­äº§ç”Ÿå¤§é‡é›¶æ¢¯åº¦çš„é—®é¢˜ï¼Œè¯¥æ–¹æ³•å°†ä»»åŠ¡æ¢ç´¢å»ºæ¨¡ä¸ºç»å…¸çš„èƒŒåŒ…é—®é¢˜ï¼ˆKnapsack Problemï¼‰ã€‚é€šè¿‡è¿™ç§å»ºæ¨¡ï¼Œç ”ç©¶æ¨å¯¼å‡ºä¸€ç§æœ€ä¼˜åˆ†é…è§„åˆ™ï¼Œèƒ½å¤Ÿæ ¹æ®æ¨¡å‹å½“å‰çš„è®­ç»ƒçŠ¶æ€è‡ªé€‚åº”åœ°å°†è®¡ç®—èµ„æºä»å·²é¥±å’Œçš„ä»»åŠ¡é‡åˆ†é…è‡³æ›´å…·å½±å“åŠ›çš„æŒ‘æˆ˜æ€§ä»»åŠ¡ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨è®­ç»ƒæœŸé—´å°†æœ‰æ•ˆç­–ç•¥æ¢¯åº¦çš„æ¯”ä¾‹æå‡äº†20-40%ï¼Œå¹¶åœ¨æ•°å­¦æ¨ç†åŸºå‡†æµ‹è¯•ä¸­å®ç°äº†2-4ä¸ªç™¾åˆ†ç‚¹çš„å¹³å‡æ€§èƒ½å¢ç›Šã€‚Knapsack RLåœ¨æ˜¾è‘—æå‡å¤æ‚é—®é¢˜æ±‚è§£èƒ½åŠ›çš„åŒæ—¶ï¼Œä»…éœ€çº¦ä¸€åŠçš„è®¡ç®—èµ„æºå³å¯è¾¾åˆ°ä¼ ç»Ÿåˆ†é…æ–¹æ³•çš„åŒç­‰æ€§èƒ½ï¼Œä¸ºå¤§æ¨¡å‹çš„é«˜æ•ˆè‡ªä¸»è¿›åŒ–æä¾›äº†ä¸€ç§ä¼˜åŒ–çš„èµ„æºåˆ©ç”¨æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25849v1",
      "published_date": "2025-09-30 06:41:57 UTC",
      "updated_date": "2025-09-30 06:41:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:42:37.497184+00:00"
    },
    {
      "arxiv_id": "2509.25848v2",
      "title": "More Thought, Less Accuracy? On the Dual Nature of Reasoning in Vision-Language Models",
      "title_zh": "æ€è€ƒè¶Šå¤šï¼Œå‡†ç¡®ç‡è¶Šä½ï¼Ÿè®ºè§†è§‰è¯­è¨€æ¨¡å‹æ¨ç†çš„åŒé‡æ€§",
      "authors": [
        "Xinyu Tian",
        "Shu Zou",
        "Zhaoyuan Yang",
        "Mengqi He",
        "Fabian Waschkowski",
        "Lukas Wesemann",
        "Peter Tu",
        "Jing Zhang"
      ],
      "abstract": "Reasoning has emerged as a pivotal capability in Large Language Models (LLMs). Through Reinforcement Learning (RL), typically Group Relative Policy Optimization (GRPO), these models are able to solve complex tasks such as mathematics and code generation. Building on these advances, recent research has sought to extend reasoning to Vision-Language Models (VLMs), yielding promising results across diverse visual tasks. Despite this progress, our study uncovers the dual nature of multimodal reasoning: while it substantially enhances logical inference and facilitates performance on challenging problems, it may gradually impair perceptual grounding, leading to recognition failures on otherwise basic visual questions. Through further analysis, we attribute this phenomenon to visual forgetting, wherein prolonged reasoning causes the model to increasingly disregard visual input. To address this, we propose Vision-Anchored Policy Optimization (VAPO), a simple yet effective method that explicitly steers the reasoning process toward visually grounded trajectories. Our result model, VAPO-Thinker-7B, significantly strengthens the model's reliance on visual information and achieves new state-of-the-art results on a wide range of established benchmarks. Project page: https://xytian1008.github.io/VAPO/",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æ¢è®¨äº†å¤šæ¨¡æ€æ¨ç†åœ¨è§†è§‰è¯­è¨€æ¨¡å‹(Vision-Language Models)ä¸­çš„åŒé‡ç‰¹æ€§ï¼Œæ­ç¤ºäº†å…¶åœ¨æ˜¾è‘—å¢å¼ºé€»è¾‘æ¨ç†èƒ½åŠ›çš„åŒæ—¶ï¼Œå¯èƒ½ä¼šæŸå®³æ¨¡å‹çš„æ„ŸçŸ¥å®šä½(perceptual grounding)èƒ½åŠ›ï¼Œå¯¼è‡´åœ¨åŸºç¡€è§†è§‰é—®é¢˜ä¸Šå‘ç”Ÿè¯†åˆ«é”™è¯¯ã€‚ç ”ç©¶å°†æ­¤ç°è±¡å½’å› äºè§†è§‰é—å¿˜(visual forgetting)ï¼Œå³å†—é•¿çš„æ¨ç†é“¾æ¡å¯¼è‡´æ¨¡å‹åœ¨å¤„ç†è¿‡ç¨‹ä¸­é€æ¸å¿½è§†äº†åŸå§‹è§†è§‰è¾“å…¥ã€‚é’ˆå¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œä½œè€…æå‡ºäº†è§†è§‰é”šå®šç­–ç•¥ä¼˜åŒ–(Vision-Anchored Policy Optimization, VAPO)ï¼Œé€šè¿‡å°†æ¨ç†è½¨è¿¹æ˜¾å¼åœ°å¼•å‘è§†è§‰å…³è”æ–¹å‘æ¥çº æ­£åå·®ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€æå‡ºçš„ VAPO-Thinker-7B æ¨¡å‹æ˜¾è‘—å¼ºåŒ–äº†å¯¹è§†è§‰ä¿¡æ¯çš„ä¾èµ–ï¼Œå¹¶åœ¨å¤šé¡¹ä¸»æµåŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº† state-of-the-art æ°´å¹³ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25848v2",
      "published_date": "2025-09-30 06:37:47 UTC",
      "updated_date": "2025-10-02 12:24:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:42:50.587607+00:00"
    },
    {
      "arxiv_id": "2509.25845v1",
      "title": "Training-Free Reward-Guided Image Editing via Trajectory Optimal Control",
      "title_zh": "åŸºäºè½¨è¿¹æœ€ä¼˜æ§åˆ¶çš„å…è®­ç»ƒå¥–åŠ±å¼•å¯¼å›¾åƒç¼–è¾‘",
      "authors": [
        "Jinho Chang",
        "Jaemin Kim",
        "Jong Chul Ye"
      ],
      "abstract": "Recent advancements in diffusion and flow-matching models have demonstrated remarkable capabilities in high-fidelity image synthesis. A prominent line of research involves reward-guided guidance, which steers the generation process during inference to align with specific objectives. However, leveraging this reward-guided approach to the task of image editing, which requires preserving the semantic content of the source image while enhancing a target reward, is largely unexplored. In this work, we introduce a novel framework for training-free, reward-guided image editing. We formulate the editing process as a trajectory optimal control problem where the reverse process of a diffusion model is treated as a controllable trajectory originating from the source image, and the adjoint states are iteratively updated to steer the editing process. Through extensive experiments across distinct editing tasks, we demonstrate that our approach significantly outperforms existing inversion-based training-free guidance baselines, achieving a superior balance between reward maximization and fidelity to the source image without reward hacking.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸º Training-Free Reward-Guided Image Editing çš„åˆ›æ–°æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¦‚ä½•åœ¨æå‡ç›®æ ‡ Reward çš„åŒæ—¶ä¿ç•™æºå›¾åƒè¯­ä¹‰å†…å®¹çš„éš¾é¢˜ã€‚ç ”ç©¶è€…å°†å›¾åƒç¼–è¾‘è¿‡ç¨‹è¡¨è¿°ä¸ºä¸€ä¸ª Trajectory Optimal Control é—®é¢˜ï¼Œå°†æ‰©æ•£æ¨¡å‹çš„åå‘ç”Ÿæˆè¿‡ç¨‹è§†ä¸ºä»æºå›¾åƒèµ·å§‹çš„å¯æ§è½¨è¿¹ã€‚é€šè¿‡è¿­ä»£æ›´æ–° Adjoint Statesï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿåœ¨æ¨ç†é˜¶æ®µç²¾ç¡®å¼•å¯¼ç”Ÿæˆè¿‡ç¨‹ï¼Œä½¿å…¶ç¬¦åˆé¢„è®¾çš„ä¼˜åŒ–ç›®æ ‡ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šç§ä¸åŒçš„ç¼–è¾‘ä»»åŠ¡ä¸­æ˜¾è‘—ä¼˜äºç°æœ‰çš„åŸºäº Inversion çš„æ— éœ€è®­ç»ƒå¼•å¯¼åŸºçº¿æ¨¡å‹ã€‚è¯¥æ¡†æ¶åœ¨ Reward æœ€å¤§åŒ–ä¸ä¿æŒæºå›¾åƒ Fidelity ä¹‹é—´å®ç°äº†æ›´å“è¶Šçš„å¹³è¡¡ï¼Œå¹¶èƒ½æœ‰æ•ˆæŠ‘åˆ¶ Reward Hacking ç°è±¡ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.25845v1",
      "published_date": "2025-09-30 06:34:37 UTC",
      "updated_date": "2025-09-30 06:34:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:42:48.297151+00:00"
    },
    {
      "arxiv_id": "2509.25843v1",
      "title": "ASGuard: Activation-Scaling Guard to Mitigate Targeted Jailbreaking Attack",
      "title_zh": "ASGuardï¼šæ—¨åœ¨ç¼“è§£å®šå‘è¶Šç‹±æ”»å‡»çš„æ¿€æ´»ç¼©æ”¾é˜²å¾¡æœºåˆ¶",
      "authors": [
        "Yein Park",
        "Jungwoo Park",
        "Jaewoo Kang"
      ],
      "abstract": "Large language models (LLMs), despite being safety-aligned, exhibit brittle refusal behaviors that can be circumvented by simple linguistic changes. As tense jailbreaking demonstrates that models refusing harmful requests often comply when rephrased in past tense, a critical generalization gap is revealed in current alignment methods whose underlying mechanisms are poorly understood. In this work, we introduce Activation-Scaling Guard (ASGuard), an insightful, mechanistically-informed framework that surgically mitigates this specific vulnerability. For the first step, we use circuit analysis to identify the specific attention heads causally linked to the targeted jailbreaking, the tense-changing attack. Second, we train a precise, channel-wise scaling vector to recalibrate the activation of tense vulnerable heads. Lastly, we apply it into a \"preventative fine-tuning\", forcing the model to learn a more robust refusal mechanism. Across three LLMs, ASGuard effectively reduces the attack success rate of targeted jailbreaking while preserving general capabilities and minimizing over refusal, achieving a Pareto-optimal balance between safety and utility. Our findings underscore how adversarial suffixes suppress the propagation of the refusal-mediating direction, based on mechanistic analysis. Furthermore, our work showcases how a deep understanding of model internals can be leveraged to develop practical, efficient, and targeted methods for adjusting model behavior, charting a course for more reliable and interpretable AI safety.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é¢å¯¹æ—¶æ€åˆ‡æ¢ç­‰è¯­è¨€å˜ä½“è¶Šç‹±æ”»å‡»æ—¶è¡¨ç°å‡ºçš„æ‹’ç»è¡Œä¸ºè„†å¼±æ€§ï¼Œæå‡ºäº†åŸºäºæ¨¡å‹å†…éƒ¨æœºåˆ¶åˆ†æçš„é˜²å¾¡æ¡†æ¶ASGuardã€‚ç ”ç©¶é¦–å…ˆåˆ©ç”¨ç”µè·¯åˆ†æï¼ˆCircuit Analysisï¼‰è¯†åˆ«å‡ºä¸æ­¤ç±»æ”»å‡»å…·æœ‰å› æœå…³è”çš„ç‰¹å®šæ³¨æ„åŠ›å¤´ï¼ˆAttention Headsï¼‰ï¼Œå¹¶è®­ç»ƒç²¾ç¡®çš„é€šé“ç¼©æ”¾å‘é‡ï¼ˆChannel-wise Scaling Vectorï¼‰æ¥é‡æ–°æ ¡å‡†è¿™äº›æ˜“å—æŸç¯èŠ‚çš„æ¿€æ´»å€¼ã€‚éšåï¼Œè¯¥æœºåˆ¶è¢«åº”ç”¨äºé¢„é˜²æ€§å¾®è°ƒï¼ˆPreventative Fine-tuningï¼‰ï¼Œä»¥å¼ºåŒ–æ¨¡å‹çš„é²æ£’æ‹’ç»æœºåˆ¶ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒASGuardåœ¨ä¸‰ç§LLMsä¸Šæ˜¾è‘—é™ä½äº†é’ˆå¯¹æ€§è¶Šç‹±çš„æ”»å‡»æˆåŠŸç‡ï¼Œå¹¶åœ¨ä¿éšœå®‰å…¨æ€§çš„åŒæ—¶ç»´æŒäº†æ¨¡å‹é€šç”¨èƒ½åŠ›ï¼Œå®ç°äº†å®‰å…¨ä¸æ•ˆç”¨çš„å¸•ç´¯æ‰˜æœ€ä¼˜ï¼ˆPareto-optimalï¼‰å¹³è¡¡ã€‚è¯¥å·¥ä½œé€šè¿‡æ­ç¤ºå¯¹æŠ—æ€§åç¼€æŠ‘åˆ¶æ‹’ç»ä¿¡å·ä¼ æ’­çš„å†…éƒ¨æœºç†ï¼Œä¸ºå¼€å‘é«˜æ•ˆã€å¯è§£é‡Šçš„AIå®‰å…¨æŠ€æœ¯æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25843v1",
      "published_date": "2025-09-30 06:33:52 UTC",
      "updated_date": "2025-09-30 06:33:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:42:58.595157+00:00"
    },
    {
      "arxiv_id": "2509.25842v1",
      "title": "HiStyle: Hierarchical Style Embedding Predictor for Text-Prompt-Guided Controllable Speech Synthesis",
      "title_zh": "HiStyleï¼šé¢å‘æ–‡æœ¬æç¤ºå¼•å¯¼çš„å¯æ§è¯­éŸ³åˆæˆåˆ†å±‚é£æ ¼åµŒå…¥é¢„æµ‹å™¨",
      "authors": [
        "Ziyu Zhang",
        "Hanzhao Li",
        "Jingbin Hu",
        "Wenhao Li",
        "Lei Xie"
      ],
      "abstract": "Controllable speech synthesis refers to the precise control of speaking style by manipulating specific prosodic and paralinguistic attributes, such as gender, volume, speech rate, pitch, and pitch fluctuation. With the integration of advanced generative models, particularly large language models (LLMs) and diffusion models, controllable text-to-speech (TTS) systems have increasingly transitioned from label-based control to natural language description-based control, which is typically implemented by predicting global style embeddings from textual prompts. However, this straightforward prediction overlooks the underlying distribution of the style embeddings, which may hinder the full potential of controllable TTS systems. In this study, we use t-SNE analysis to visualize and analyze the global style embedding distribution of various mainstream TTS systems, revealing a clear hierarchical clustering pattern: embeddings first cluster by timbre and subsequently subdivide into finer clusters based on style attributes. Based on this observation, we propose HiStyle, a two-stage style embedding predictor that hierarchically predicts style embeddings conditioned on textual prompts, and further incorporate contrastive learning to help align the text and audio embedding spaces. Additionally, we propose a style annotation strategy that leverages the complementary strengths of statistical methodologies and human auditory preferences to generate more accurate and perceptually consistent textual prompts for style control. Comprehensive experiments demonstrate that when applied to the base TTS model, HiStyle achieves significantly better style controllability than alternative style embedding predicting approaches while preserving high speech quality in terms of naturalness and intelligibility. Audio samples are available at https://anonymous.4open.science/w/HiStyle-2517/.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ–‡æœ¬æç¤ºå¼•å¯¼çš„å¯æ§è¯­éŸ³åˆæˆ(Controllable Speech Synthesis)ä¸­é£æ ¼åµŒå…¥(style embeddings)é¢„æµ‹å¿½ç•¥å…¶åº•å±‚åˆ†å¸ƒè§„å¾‹çš„é—®é¢˜ï¼Œæå‡ºäº†HiStyleã€‚é€šè¿‡t-SNEåˆ†æï¼Œç ”ç©¶äººå‘˜å‘ç°é£æ ¼åµŒå…¥å‘ˆç°å‡ºå…ˆæŒ‰éŸ³è‰²(timbre)èšç±»ã€å†æŒ‰é£æ ¼å±æ€§ç»†åˆ†çš„å±‚çº§åˆ†å¸ƒç‰¹å¾ã€‚åŸºäºæ­¤è§‚å¯Ÿï¼ŒHiStyleé‡‡ç”¨ä¸¤é˜¶æ®µé¢„æµ‹å™¨æ ¹æ®æ–‡æœ¬æç¤ºåˆ†å±‚é¢„æµ‹é£æ ¼åµŒå…¥ï¼Œå¹¶å¼•å…¥å¯¹æ¯”å­¦ä¹ (contrastive learning)æ¥å¢å¼ºæ–‡æœ¬ä¸éŸ³é¢‘ç©ºé—´çš„å¯¹é½ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶æå‡ºä¸€ç§ç»“åˆç»Ÿè®¡æ–¹æ³•ä¸äººç±»å¬è§‰åå¥½çš„é£æ ¼æ ‡æ³¨ç­–ç•¥ï¼Œä»¥ç”Ÿæˆæ›´å‡†ç¡®ä¸”æ„ŸçŸ¥ä¸€è‡´çš„æ–‡æœ¬æç¤ºã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒHiStyleåœ¨åŸºç¡€TTSæ¨¡å‹ä¸Šæ˜¾è‘—æå‡äº†é£æ ¼å¯æ§æ€§ï¼ŒåŒæ—¶ä¿æŒäº†é«˜æ°´å¹³çš„è¯­éŸ³è‡ªç„¶åº¦å’Œæ¸…æ™°åº¦ã€‚è¯¥æ¡†æ¶ä¸ºå®ç°åŸºäºè‡ªç„¶è¯­è¨€æè¿°çš„ç²¾ç»†åŒ–è¯­éŸ³å±æ€§è°ƒèŠ‚æä¾›äº†æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25842v1",
      "published_date": "2025-09-30 06:31:12 UTC",
      "updated_date": "2025-09-30 06:31:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:42:50.990472+00:00"
    },
    {
      "arxiv_id": "2509.25841v1",
      "title": "S$^2$FS: Spatially-Aware Separability-Driven Feature Selection in Fuzzy Decision Systems",
      "title_zh": "S$^2$FSï¼šæ¨¡ç³Šå†³ç­–ç³»ç»Ÿä¸­çš„ç©ºé—´æ„ŸçŸ¥å¯åˆ†æ€§é©±åŠ¨ç‰¹å¾é€‰æ‹©",
      "authors": [
        "Suping Xu",
        "Chuyi Dai",
        "Ye Liu",
        "Lin Shang",
        "Xibei Yang",
        "Witold Pedrycz"
      ],
      "abstract": "Feature selection is crucial for fuzzy decision systems (FDSs), as it identifies informative features and eliminates rule redundancy, thereby enhancing predictive performance and interpretability. Most existing methods either fail to directly align evaluation criteria with learning performance or rely solely on non-directional Euclidean distances to capture relationships among decision classes, which limits their ability to clarify decision boundaries. However, the spatial distribution of instances has a potential impact on the clarity of such boundaries. Motivated by this, we propose Spatially-aware Separability-driven Feature Selection (S$^2$FS), a novel framework for FDSs guided by a spatially-aware separability criterion. This criterion jointly considers within-class compactness and between-class separation by integrating scalar-distances with spatial directional information, providing a more comprehensive characterization of class structures. S$^2$FS employs a forward greedy strategy to iteratively select the most discriminative features. Extensive experiments on ten real-world datasets demonstrate that S$^2$FS consistently outperforms eight state-of-the-art feature selection algorithms in both classification accuracy and clustering performance, while feature visualizations further confirm the interpretability of the selected features.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ¨¡ç³Šå†³ç­–ç³»ç»Ÿ (Fuzzy Decision Systems, FDSs) æå‡ºäº†ç©ºé—´æ„ŸçŸ¥å¯åˆ†æ€§é©±åŠ¨çš„ç‰¹å¾é€‰æ‹©æ¡†æ¶ (S$^2$FS)ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ–¹æ³•å› ä»…ä¾èµ–éæ–¹å‘æ€§æ¬§å‡ é‡Œå¾—è·ç¦»è€Œéš¾ä»¥æ¸…æ™°ç•Œå®šå†³ç­–è¾¹ç•Œçš„é—®é¢˜ã€‚S$^2$FS å¼•å…¥äº†ä¸€ç§ç©ºé—´æ„ŸçŸ¥å¯åˆ†æ€§å‡†åˆ™ï¼Œé€šè¿‡æ•´åˆæ ‡é‡è·ç¦»ä¸ç©ºé—´æ–¹å‘ä¿¡æ¯ï¼ŒåŒæ—¶ä¼˜åŒ–ç±»å†…ç´§å‡‘æ€§ (within-class compactness) å’Œç±»é—´åˆ†ç¦»åº¦ (between-class separation)ï¼Œä»è€Œæ›´å…¨é¢åœ°è¡¨å¾ç±»åˆ«ç»“æ„ã€‚è¯¥æ¡†æ¶é‡‡ç”¨å‰å‘è´ªå©ªç­–ç•¥ (forward greedy strategy) è¿­ä»£ç­›é€‰æœ€å…·è¾¨åˆ«åŠ›çš„ç‰¹å¾ï¼Œæœ‰æ•ˆæå‡äº†ç³»ç»Ÿçš„é¢„æµ‹æ€§èƒ½ã€‚åœ¨åä¸ªçœŸå®æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¯æ˜ï¼ŒS$^2$FS åœ¨åˆ†ç±»å‡†ç¡®ç‡å’Œèšç±»æ€§èƒ½ä¸Šå‡æ˜¾è‘—ä¼˜äºå…«ç§å…ˆè¿›çš„ç‰¹å¾é€‰æ‹©ç®—æ³•ã€‚æ­¤å¤–ï¼Œç‰¹å¾å¯è§†åŒ–åˆ†æè¿›ä¸€æ­¥è¯å®äº†è¯¥æ–¹æ³•æ‰€é€‰ç‰¹å¾å…·æœ‰è‰¯å¥½çš„è§£é‡ŠåŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25841v1",
      "published_date": "2025-09-30 06:30:14 UTC",
      "updated_date": "2025-09-30 06:30:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:43:16.197094+00:00"
    },
    {
      "arxiv_id": "2509.25839v1",
      "title": "RAE: A Neural Network Dimensionality Reduction Method for Nearest Neighbors Preservation in Vector Search",
      "title_zh": "RAEï¼šé¢å‘å‘é‡æœç´¢æœ€è¿‘é‚»ä¿æŒçš„ç¥ç»ç½‘ç»œé™ç»´æ–¹æ³•",
      "authors": [
        "Han Zhang",
        "Dongfang Zhao"
      ],
      "abstract": "While high-dimensional embedding vectors are being increasingly employed in various tasks like Retrieval-Augmented Generation and Recommendation Systems, popular dimensionality reduction (DR) methods such as PCA and UMAP have rarely been adopted for accelerating the retrieval process due to their inability of preserving the nearest neighbor (NN) relationship among vectors. Empowered by neural networks' optimization capability and the bounding effect of Rayleigh quotient, we propose a Regularized Auto-Encoder (RAE) for k-NN preserving dimensionality reduction. RAE constrains the network parameter variation through regularization terms, adjusting singular values to control embedding magnitude changes during reduction, thus preserving k-NN relationships. We provide a rigorous mathematical analysis demonstrating that regularization establishes an upper bound on the norm distortion rate of transformed vectors, thereby offering provable guarantees for k-NN preservation. With modest training overhead, RAE achieves superior k-NN recall compared to existing DR approaches while maintaining fast retrieval efficiency.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Regularized Auto-Encoder (RAE)ï¼Œä¸€ç§æ—¨åœ¨è§£å†³é«˜ç»´å‘é‡æ£€ç´¢ä¸­é™ç»´ä¿åºéš¾é¢˜çš„ç¥ç»ç½‘ç»œé™ç»´æ–¹æ³•ã€‚é’ˆå¯¹ PCA å’Œ UMAP ç­‰ä¼ ç»Ÿæ–¹æ³•æ— æ³•æœ‰æ•ˆä¿ç•™æœ€è¿‘é‚» (Nearest Neighbor) å…³ç³»çš„é—®é¢˜ï¼ŒRAE åˆ©ç”¨ Rayleigh quotient çš„è¾¹ç•Œæ•ˆåº”ï¼Œé€šè¿‡æ­£åˆ™åŒ–é¡¹çº¦æŸå‚æ•°å˜åŒ–æ¥æ§åˆ¶å¥‡å¼‚å€¼ï¼Œä»è€Œç¨³å®šé™ç»´è¿‡ç¨‹ä¸­çš„å‘é‡èŒƒæ•°ã€‚ä¸¥è°¨çš„æ•°å­¦åˆ†æè¯æ˜ï¼Œè¿™ç§æ­£åˆ™åŒ–æœºåˆ¶èƒ½æœ‰æ•ˆé™åˆ¶å˜æ¢å‘é‡çš„èŒƒæ•°ç•¸å˜ç‡ (norm distortion rate)ï¼Œä¸º k-NN å…³ç³»çš„ä¿ç•™æä¾›äº†ç†è®ºä¿éšœã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒRAE åœ¨ä»…éœ€å°‘é‡è®­ç»ƒå¼€é”€çš„æƒ…å†µä¸‹ï¼Œç›¸è¾ƒäºç°æœ‰é™ç»´æŠ€æœ¯åœ¨ k-NN å¬å›ç‡ (recall) å’Œæ£€ç´¢æ•ˆç‡æ–¹é¢å‡è¡¨ç°å‡ºæ˜¾è‘—ä¼˜åŠ¿ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.IR",
      "comment": "submitted to ICLR 2026",
      "pdf_url": "https://arxiv.org/pdf/2509.25839v1",
      "published_date": "2025-09-30 06:25:38 UTC",
      "updated_date": "2025-09-30 06:25:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:43:04.805527+00:00"
    },
    {
      "arxiv_id": "2509.25837v1",
      "title": "Distillation of Large Language Models via Concrete Score Matching",
      "title_zh": "åŸºäº Concrete åˆ†å€¼åŒ¹é…çš„å¤§è¯­è¨€æ¨¡å‹è’¸é¦",
      "authors": [
        "Yeongmin Kim",
        "Donghyeok Shin",
        "Mina Kang",
        "Byeonghu Na",
        "Il-Chul Moon"
      ],
      "abstract": "Large language models (LLMs) deliver remarkable performance but are costly to deploy, motivating knowledge distillation (KD) for efficient inference. Existing KD objectives typically match student and teacher probabilities via softmax, which blurs valuable logit information. While direct logit distillation (DLD) mitigates softmax smoothing, it fails to account for logit shift invariance, thereby restricting the solution space. We propose Concrete Score Distillation (CSD), a discrete score-matching objective that overcomes both softmax-induced smoothing and restrictions on the optimal solution set. We resolve the training instability and quadratic complexity of discrete score-matching in autoregressive LLMs, and the resulting CSD objective aligns relative logit differences across all vocabulary pairs between student and teacher with flexible weighting. We provide both mode-seeking and mode-covering instances within our framework and evaluate CSD on task-agnostic instruction-following and task-specific distillation using GPT-2-1.5B, OpenLLaMA-7B, and GEMMA-7B-IT. Experiments show that CSD consistently surpasses recent KD objectives, achieves favorable fidelity-diversity trade-offs, and yields complementary gains when combined with on-policy techniques, demonstrating its scalability and effectiveness for LLM distillation.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)æ¨ç†æˆæœ¬é«˜æ˜‚çš„é—®é¢˜ï¼Œæå‡ºäº†Concrete Score Distillation (CSD)ï¼Œè¿™æ˜¯ä¸€ç§åŸºäºç¦»æ•£åˆ†æ•°åŒ¹é…(Discrete Score-matching)çš„çŸ¥è¯†è’¸é¦(Knowledge Distillation)ç›®æ ‡å‡½æ•°ã€‚ç°æœ‰çš„çŸ¥è¯†è’¸é¦æ–¹æ³•é€šå¸¸é€šè¿‡SoftmaxåŒ¹é…å­¦ç”Ÿå’Œæ•™å¸ˆæ¨¡å‹çš„æ¦‚ç‡ï¼Œè¿™ä¼šæ¨¡ç³Šæœ‰ä»·å€¼çš„Logitä¿¡æ¯ï¼Œè€ŒDirect Logit Distillation (DLD)åˆ™å› æœªèƒ½è€ƒè™‘Logitçš„å¹³ç§»ä¸å˜æ€§(Shift Invariance)è€Œé™åˆ¶äº†æœ€ä¼˜è§£ç©ºé—´ã€‚CSDé€šè¿‡å¯¹é½å­¦ç”Ÿå’Œæ•™å¸ˆæ¨¡å‹ä¹‹é—´æ‰€æœ‰è¯è¡¨å¯¹çš„ç›¸å¯¹Logitå·®å¼‚ï¼Œæœ‰æ•ˆå…‹æœäº†Softmaxå¹³æ»‘æ•ˆåº”åŠå¯¹è§£é›†çš„é™åˆ¶ã€‚è¯¥æ–¹æ³•è§£å†³äº†ç¦»æ•£åˆ†æ•°åŒ¹é…åœ¨è‡ªå›å½’æ¨¡å‹ä¸­çš„è®­ç»ƒä¸ç¨³å®šæ€§åŠäºŒæ¬¡å¤æ‚åº¦é—®é¢˜ï¼Œå¹¶æ”¯æŒMode-seekingå’ŒMode-coveringä¸¤ç§æ¨¡å¼ã€‚åœ¨GPT-2-1.5Bã€OpenLLaMA-7Bå’ŒGEMMA-7B-ITä¸Šçš„å®éªŒè¯æ˜ï¼ŒCSDåœ¨æŒ‡ä»¤éµå¾ªåŠç‰¹å®šä»»åŠ¡è’¸é¦ä¸­å‡ä¼˜äºç°æœ‰çš„è’¸é¦ç›®æ ‡å‡½æ•°ã€‚è¯¥ç ”ç©¶å±•ç¤ºäº†CSDåœ¨ä¿çœŸåº¦ä¸å¤šæ ·æ€§å¹³è¡¡ä¸Šçš„ä¼˜å¼‚è¡¨ç°ï¼ŒåŠå…¶åœ¨LLMè’¸é¦ä¸­çš„å¯æ‰©å±•æ€§ä¸æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25837v1",
      "published_date": "2025-09-30 06:21:28 UTC",
      "updated_date": "2025-09-30 06:21:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:43:10.875197+00:00"
    },
    {
      "arxiv_id": "2509.25835v3",
      "title": "Chain-in-Tree: Back to Sequential Reasoning in LLM Tree Search",
      "title_zh": "Chain-in-Treeï¼šå›å½’å¤§è¯­è¨€æ¨¡å‹æ ‘æœç´¢ä¸­çš„åºåˆ—æ¨ç†",
      "authors": [
        "Xinzhe Li"
      ],
      "abstract": "Test-time scaling improves large language models (LLMs) on long-horizon reasoning tasks by allocating more compute at inference. LLM Inference via Tree Search (LITS) methods achieve strong performance but are highly inefficient, often running an order of magnitude slower than iterative approaches. We propose Chain-in-Tree (CiT), a plug-in framework that decides when to branch during search rather than expanding at every step. CiT introduces lightweight Branching Necessity (BN) evaluations: BN-DP (Direct Prompting), where an auxiliary LLM judges branching needs, and BN-SC (Self-Consistency), which clusters candidate actions to assess agreement. Integrated into Tree of Thoughts, ReST-MCTS, and RAP, BN-DP achieves 75-85% reductions in token generation, model calls, and runtime on GSM8K and Math500, with often negligible or no accuracy loss. BN-SC typically yields substantial savings (up to 80%) generally but shows instability in 1-4 out of 14 settings, caused by a small subset of examples that produce extremely long reasoning steps. We theoretically prove that BN-DP never increases policy invocations and release both modular LITS implementations and a lightweight CiT function applicable across all LITS variants. The full codebase is publicly available at https://github.com/xinzhel/chain_in_tree.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Chain-in-Tree (CiT) æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) åœ¨æ‰§è¡Œæ ‘æœç´¢æ¨ç† (LLM Inference via Tree Search, LITS) æ—¶æ•ˆç‡ä½ä¸‹çš„æ ¸å¿ƒæŒ‘æˆ˜ã€‚CiT ä½œä¸ºä¸€ä¸ªæ’ä»¶å¼æ¡†æ¶ï¼Œé€šè¿‡å¼•å…¥è½»é‡çº§çš„åˆ†æ”¯å¿…è¦æ€§ (Branching Necessity, BN) è¯„ä¼°æœºåˆ¶ï¼Œå…è®¸æ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­åŠ¨æ€å†³å®šåˆ†æ”¯æ—¶æœºï¼Œä»è€Œå›å½’é«˜æ•ˆçš„é¡ºåºæ¨ç†ã€‚ç ”ç©¶è®¾è®¡äº†ä¸¤ç§è¯„ä¼°ç­–ç•¥ï¼šåˆ©ç”¨è¾…åŠ© LLM åˆ¤æ–­åˆ†æ”¯éœ€æ±‚çš„ BN-DP (Direct Prompting) ä»¥åŠé€šè¿‡å€™é€‰åŠ¨ä½œèšç±»è¯„ä¼°ä¸€è‡´æ€§çš„ BN-SC (Self-Consistency)ã€‚å°† CiT é›†æˆåˆ° Tree of Thoughtsã€ReST-MCTS å’Œ RAP ç­‰ç°æœ‰æ–¹æ³•åï¼Œåœ¨ GSM8K å’Œ Math500 ä»»åŠ¡ä¸­æˆåŠŸé™ä½äº† 75-85% çš„ Token ç”Ÿæˆé‡å’Œæ¨ç†è€—æ—¶ï¼Œä¸”å‡ ä¹æ²¡æœ‰å‡†ç¡®ç‡æŸå¤±ã€‚æ­¤å¤–ï¼Œç ”ç©¶ä»ç†è®ºä¸Šè¯æ˜äº† BN-DP çš„æ•ˆç‡ä¼˜åŠ¿ï¼Œå¹¶å¼€æºäº†å¯é€‚é…å¤šç§ LITS å˜ä½“çš„æ¨¡å—åŒ–ä»£ç åº“ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Under Review; Add codebase",
      "pdf_url": "https://arxiv.org/pdf/2509.25835v3",
      "published_date": "2025-09-30 06:18:44 UTC",
      "updated_date": "2025-10-18 04:15:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:43:12.970880+00:00"
    },
    {
      "arxiv_id": "2509.25834v2",
      "title": "Supporting Creative Ownership through Deep Learning-Based Music Variation",
      "title_zh": "é€šè¿‡åŸºäºæ·±åº¦å­¦ä¹ çš„éŸ³ä¹å˜å¥æ”¯æŒåˆ›ä½œæ‰€æœ‰æƒ",
      "authors": [
        "Stephen James Krol",
        "Maria Teresa Llano",
        "Jon McCormack"
      ],
      "abstract": "This paper investigates the importance of personal ownership in musical AI design, examining how practising musicians can maintain creative control over the compositional process. Through a four-week ecological evaluation, we examined how a music variation tool, reliant on the skill of musicians, functioned within a composition setting. Our findings demonstrate that the dependence of the tool on the musician's ability, to provide a strong initial musical input and to turn moments into complete musical ideas, promoted ownership of both the process and artefact. Qualitative interviews further revealed the importance of this personal ownership, highlighting tensions between technological capability and artistic identity. These findings provide insight into how musical AI can support rather than replace human creativity, highlighting the importance of designing tools that preserve the humanness of musical expression.",
      "tldr_zh": "æœ¬ç ”ç©¶æ¢è®¨äº†åœ¨éŸ³ä¹AIè®¾è®¡ä¸­ä¿æŒä¸ªäººæ‰€æœ‰æƒ(personal ownership)çš„é‡è¦æ€§ï¼Œæ—¨åœ¨åˆ†æèŒä¸šéŸ³ä¹å®¶å¦‚ä½•åœ¨åˆ›ä½œè¿‡ç¨‹ä¸­ç»´æŒåˆ›æ„æ§åˆ¶ã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡ä¸ºæœŸå››å‘¨çš„ç”Ÿæ€è¯„ä¼°(ecological evaluation)ï¼Œè€ƒå¯Ÿäº†ä¸€æ¬¾åŸºäºDeep Learningçš„éŸ³ä¹å˜å¥å·¥å…·åœ¨å®é™…ä½œæ›²åœºæ™¯ä¸­çš„åº”ç”¨ã€‚è¯¥å·¥å…·é«˜åº¦ä¾èµ–éŸ³ä¹å®¶çš„ä¸“ä¸šæŠ€èƒ½æ¥æä¾›é«˜è´¨é‡çš„åˆå§‹è¾“å…¥ï¼Œå¹¶å°†çµæ„Ÿç‰‡æ®µè½¬åŒ–ä¸ºå®Œæ•´çš„éŸ³ä¹æ„æ€ï¼Œè¿™ç§æœºåˆ¶æœ‰æ•ˆä¿ƒè¿›äº†ä½¿ç”¨è€…å¯¹åˆ›ä½œè¿‡ç¨‹å’Œæœ€ç»ˆä½œå“(artefact)çš„æ‰€æœ‰æƒæ„Ÿã€‚å®šæ€§è®¿è°ˆè¿›ä¸€æ­¥æ­ç¤ºäº†ä¸ªäººæ‰€æœ‰æƒçš„æ ¸å¿ƒåœ°ä½ï¼Œå¹¶æ¢è®¨äº†æŠ€æœ¯èƒ½åŠ›ä¸è‰ºæœ¯èº«ä»½(artistic identity)ä¹‹é—´çš„ç´§å¼ å…³ç³»ã€‚ç ”ç©¶ç»“æœä¸ºéŸ³ä¹AIå¦‚ä½•æ”¯æŒè€Œéå–ä»£äººç±»åˆ›æ„æä¾›äº†æ·±åˆ»è§è§£ï¼Œå¼ºè°ƒäº†è®¾è®¡å¿…é¡»ä¿ç•™éŸ³ä¹è¡¨è¾¾ä¸­â€œäººæ€§(humanness)â€ç‰¹å¾çš„é‡è¦æ€§ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Paper Accepted NeurIPS Creative AI Track 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.25834v2",
      "published_date": "2025-09-30 06:18:36 UTC",
      "updated_date": "2025-10-07 05:31:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:43:11.172168+00:00"
    },
    {
      "arxiv_id": "2509.25827v1",
      "title": "Overthinking Reduction with Decoupled Rewards and Curriculum Data Scheduling",
      "title_zh": "é€šè¿‡è§£è€¦å¥–åŠ±ä¸è¯¾ç¨‹æ•°æ®è°ƒåº¦å‡å°‘â€œè¿‡åº¦æ€è€ƒâ€",
      "authors": [
        "Shuyang Jiang",
        "Yusheng Liao",
        "Ya Zhang",
        "Yanfeng Wang",
        "Yu Wang"
      ],
      "abstract": "While large reasoning models trained with critic-free reinforcement learning and verifiable rewards (RLVR) represent the state-of-the-art, their practical utility is hampered by ``overthinking'', a critical issue where models generate excessively long reasoning paths without any performance benefit. Existing solutions that penalize length often fail, inducing performance degradation due to a fundamental misalignment between trajectory-level rewards and token-level optimization. In this work, we introduce a novel framework, DECS, built on our theoretical discovery of two previously unaddressed flaws in current length rewards: (1) the erroneous penalization of essential exploratory tokens and (2) the inadvertent rewarding of partial redundancy. Our framework's innovations include (i) a first-of-its-kind decoupled token-level reward mechanism that surgically distinguishes and penalizes redundant tokens, and (ii) a novel curriculum batch scheduling strategy to master the efficiency-efficacy equilibrium. Experimental results show DECS can achieve a dramatic reduction in reasoning tokens by over 50\\% across seven benchmarks while simultaneously maintaining or even improving performance. It demonstrates conclusively that substantial gains in reasoning efficiency can be achieved without compromising a model's underlying reasoning power.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹æ¨ç†æ¨¡å‹åœ¨å¼ºåŒ–å­¦ä¹ (RLVR)è®­ç»ƒä¸­å‡ºç°çš„â€œè¿‡åº¦æ€è€ƒâ€(overthinking)é—®é¢˜ï¼Œæå‡ºäº†åä¸ºDECSçš„æ–°å‹æ¡†æ¶ã€‚ä½œè€…é€šè¿‡ç†è®ºåˆ†ææ­ç¤ºäº†ç°æœ‰é•¿åº¦æƒ©ç½šæœºåˆ¶çš„ä¸¤å¤§ç¼ºé™·ï¼Œå³å¯¹æ¢ç´¢æ€§tokençš„é”™è¯¯æƒ©ç½šä»¥åŠå¯¹éƒ¨åˆ†å†—ä½™çš„æ„å¤–å¥–åŠ±ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼ŒDECSå¼•å…¥äº†é¦–åˆ›çš„è§£è€¦Tokençº§å¥–åŠ±æœºåˆ¶(decoupled token-level reward mechanism)ä»¥ç²¾ç¡®æƒ©ç½šå†—ä½™ï¼Œå¹¶ç»“åˆè¯¾ç¨‹æ‰¹æ¬¡è°ƒåº¦(curriculum batch scheduling)ç­–ç•¥æ¥å¹³è¡¡æ¨ç†æ•ˆç‡ä¸æ•ˆæœã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDECSåœ¨ä¸ƒé¡¹åŸºå‡†æµ‹è¯•ä¸­æˆåŠŸå°†æ¨ç†Tokenæ•°é‡å‡å°‘äº†50%ä»¥ä¸Šï¼Œä¸”åœ¨å¤§å¹…æå‡æ•ˆç‡çš„åŒæ—¶ï¼Œç»´æŒç”šè‡³å¢å¼ºäº†æ¨¡å‹çš„åŸå§‹æ¨ç†èƒ½åŠ›ã€‚è¯¥ç ”ç©¶ä¸ºå®ç°é«˜æ•ˆä¸”å¼ºå¤§çš„è‡ªä¸»æ¨ç†æ¨¡å‹æä¾›äº†é‡è¦çš„æŠ€æœ¯è·¯çº¿ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "26 pages",
      "pdf_url": "https://arxiv.org/pdf/2509.25827v1",
      "published_date": "2025-09-30 06:04:43 UTC",
      "updated_date": "2025-09-30 06:04:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:43:31.290106+00:00"
    },
    {
      "arxiv_id": "2509.25818v1",
      "title": "VELA: An LLM-Hybrid-as-a-Judge Approach for Evaluating Long Image Captions",
      "title_zh": "VELAï¼šä¸€ç§ç”¨äºé•¿å›¾åƒæè¿°è¯„ä¼°çš„æ··åˆå¼LLMè£åˆ¤æ–¹æ³•",
      "authors": [
        "Kazuki Matsuda",
        "Yuiga Wada",
        "Shinnosuke Hirano",
        "Seitaro Otsuki",
        "Komei Sugiura"
      ],
      "abstract": "In this study, we focus on the automatic evaluation of long and detailed image captions generated by multimodal Large Language Models (MLLMs). Most existing automatic evaluation metrics for image captioning are primarily designed for short captions and are not suitable for evaluating long captions. Moreover, recent LLM-as-a-Judge approaches suffer from slow inference due to their reliance on autoregressive inference and early fusion of visual information. To address these limitations, we propose VELA, an automatic evaluation metric for long captions developed within a novel LLM-Hybrid-as-a-Judge framework. Furthermore, we propose LongCap-Arena, a benchmark specifically designed for evaluating metrics for long captions. This benchmark comprises 7,805 images, the corresponding human-provided long reference captions and long candidate captions, and 32,246 human judgments from three distinct perspectives: Descriptiveness, Relevance, and Fluency. We demonstrated that VELA outperformed existing metrics and achieved superhuman performance on LongCap-Arena.",
      "tldr_zh": "è¯¥ç ”ç©¶èšç„¦äºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ (MLLMs) ç”Ÿæˆçš„é•¿ä¸”è¯¦ç»†çš„å›¾åƒæè¿° (long image captions) çš„è‡ªåŠ¨è¯„ä¼°é—®é¢˜ï¼ŒæŒ‡å‡ºå½“å‰è¯„ä¼°æŒ‡æ ‡å¤§å¤šé’ˆå¯¹çŸ­æè¿°ä¸”å­˜åœ¨æ¨ç†é€Ÿåº¦æ…¢ç­‰å±€é™ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº† VELAï¼Œä¸€ç§åœ¨æ–°å‹ LLM-Hybrid-as-a-Judge æ¡†æ¶ä¸‹å¼€å‘çš„é•¿æè¿°è‡ªåŠ¨è¯„ä¼°æŒ‡æ ‡ï¼Œæ—¨åœ¨æå‡è¯„ä»·çš„å‡†ç¡®æ€§ä¸æ•ˆç‡ã€‚ç ”ç©¶åŒæ—¶æ„å»ºäº† LongCap-Arena è¯„æµ‹åŸºå‡†ï¼ŒåŒ…å« 7,805 å¼ å›¾åƒåŠå…¶å¯¹åº”çš„äººç±»å‚è€ƒæè¿°ï¼Œå¹¶ä»æè¿°æ€§ (Descriptiveness)ã€ç›¸å…³æ€§ (Relevance) å’Œæµåˆ©åº¦ (Fluency) ä¸‰ä¸ªç»´åº¦æ”¶é›†äº† 32,246 é¡¹äººç±»çœŸå®è¯„åˆ¤ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒVELA åœ¨æ€§èƒ½ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æŒ‡æ ‡ï¼Œå¹¶åœ¨ LongCap-Arena åŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº†è¶…è¶Šäººç±»æ°´å¹³ (superhuman performance) çš„è¡¨ç°ã€‚è¯¥ç ”ç©¶ä¸ºé•¿æ–‡æœ¬å›¾åƒæè¿°çš„é‡åŒ–è¯„ä¼°æä¾›äº†æ–°çš„èŒƒå¼å’Œé«˜è´¨é‡çš„æ•°æ®æ”¯æŒã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "EMNLP 2025 Main Conference",
      "pdf_url": "https://arxiv.org/pdf/2509.25818v1",
      "published_date": "2025-09-30 05:52:34 UTC",
      "updated_date": "2025-09-30 05:52:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:43:37.686831+00:00"
    },
    {
      "arxiv_id": "2509.25810v3",
      "title": "Learning to Reason as Action Abstractions with Scalable Mid-Training RL",
      "title_zh": "å­¦ä¹ ä½œä¸ºåŠ¨ä½œæŠ½è±¡çš„æ¨ç†ï¼šåŸºäºå¯æ‰©å±•çš„ä¸­æœŸè®­ç»ƒå¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Shenao Zhang",
        "Donghan Yu",
        "Yihao Feng",
        "Bowen Jin",
        "Zhaoran Wang",
        "John Peebles",
        "Zirui Wang"
      ],
      "abstract": "Large language models excel with reinforcement learning (RL), but fully unlocking this potential requires a mid-training stage. An effective mid-training phase should identify a compact set of useful actions and enable fast selection among them through online RL. We formalize this intuition by presenting the first theoretical result on how mid-training shapes post-training: it characterizes an action subspace that minimizes both the value approximation error from pruning and the RL error during subsequent planning. Our analysis reveals two key determinants of mid-training effectiveness: pruning efficiency, which shapes the prior of the initial RL policy, and its impact on RL convergence, which governs the extent to which that policy can be improved via online interactions. These results suggest that mid-training is most effective when the decision space is compact and the effective horizon is short, highlighting the importance of operating in the space of action abstractions rather than primitive actions. Building on these insights, we propose Reasoning as Action Abstractions (RA3), a scalable mid-training algorithm. Specifically, we derive a sequential variational lower bound and optimize it by iteratively discovering temporally-consistent latent structures via RL, followed by fine-tuning on the bootstrapped data. Experiments on code generation tasks demonstrate the effectiveness of our approach. Across multiple base models, RA3 improves the average performance on HumanEval and MBPP by 8 and 4 points over the base model and the next-token prediction baseline. Furthermore, RA3 achieves faster convergence and higher asymptotic performance in RLVR on HumanEval+, MBPP+, LiveCodeBench, and Codeforces.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¦‚ä½•é€šè¿‡ä¸­æ®µè®­ç»ƒ (mid-training) å……åˆ†é‡Šæ”¾å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) åœ¨å¼ºåŒ–å­¦ä¹  (RL) ä¸­çš„æ½œåŠ›ã€‚ç ”ç©¶é¦–å…ˆæå‡ºäº†å…³äºä¸­æ®µè®­ç»ƒå¦‚ä½•å¡‘é€ åæœŸè®­ç»ƒçš„ç†è®ºç»“æœï¼Œé€šè¿‡åˆ»ç”»åŠ¨ä½œå­ç©ºé—´ (action subspace) æ¥æœ€å°åŒ–å‰ªæè¯¯å·®å’Œè§„åˆ’è¿‡ç¨‹ä¸­çš„ RL è¯¯å·®ã€‚åˆ†ææŒ‡å‡ºï¼Œä¸­æ®µè®­ç»ƒåœ¨å†³ç­–ç©ºé—´ç´§å‡‘ä¸”æœ‰æ•ˆæ—¶ç•Œè¾ƒçŸ­æ—¶æœ€ä¸ºé«˜æ•ˆï¼Œå¼ºè°ƒäº†åˆ©ç”¨åŠ¨ä½œæŠ½è±¡ (action abstractions) ä»£æ›¿åŸå§‹åŠ¨ä½œçš„é‡è¦æ€§ã€‚åŸºäºæ­¤è§è§£ï¼Œç ”ç©¶å¼€å‘äº†åä¸º Reasoning as Action Abstractions (RA3) çš„å¯æ‰©å±•ç®—æ³•ï¼Œé€šè¿‡è¿­ä»£å‘ç°æ½œåœ¨ç»“æ„å¹¶åœ¨å¼•å¯¼æ•°æ®ä¸Šè¿›è¡Œå¾®è°ƒã€‚å®éªŒè¯æ˜ï¼ŒRA3 åœ¨ HumanEval å’Œ MBPP åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æå‡äº†æ€§èƒ½ï¼Œåˆ†åˆ«è¶…å‡ºåŸºçº¿æ¨¡å‹ 8 åˆ†å’Œ 4 åˆ†ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªä»£ç ç”Ÿæˆæ•°æ®é›†çš„ RLVR è®­ç»ƒä¸­å±•ç°äº†æ›´å¿«çš„æ”¶æ•›é€Ÿåº¦å’Œæ›´é«˜çš„æ¸è¿‘æ€§èƒ½ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25810v3",
      "published_date": "2025-09-30 05:34:20 UTC",
      "updated_date": "2025-10-11 22:23:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:43:39.484526+00:00"
    },
    {
      "arxiv_id": "2509.25804v2",
      "title": "CardioForest: An Explainable Ensemble Learning Model for Automatic Wide QRS Complex Tachycardia Diagnosis from ECG",
      "title_zh": "CardioForestï¼šä¸€ç§ç”¨äºå¿ƒç”µå›¾å®½ QRS æ³¢ç¾¤å¿ƒåŠ¨è¿‡é€Ÿè‡ªåŠ¨è¯Šæ–­çš„å¯è§£é‡Šé›†æˆå­¦ä¹ æ¨¡å‹",
      "authors": [
        "Vaskar Chakma",
        "Ju Xiaolin",
        "Heling Cao",
        "Xue Feng",
        "Ji Xiaodong",
        "Pan Haiyan",
        "Gao Zhan"
      ],
      "abstract": "This study aims to develop and evaluate an ensemble machine learning-based framework for the automatic detection of Wide QRS Complex Tachycardia (WCT) from ECG signals, emphasizing diagnostic accuracy and interpretability using Explainable AI. The proposed system integrates ensemble learning techniques, i.e., an optimized Random Forest known as CardioForest, and models like XGBoost and LightGBM. The models were trained and tested on ECG data from the publicly available MIMIC-IV dataset. The testing was carried out with the assistance of accuracy, balanced accuracy, precision, recall, F1 score, ROC-AUC, and error rate (RMSE, MAE) measures. In addition, SHAP (SHapley Additive exPlanations) was used to ascertain model explainability and clinical relevance. The CardioForest model performed best on all metrics, achieving a test accuracy of 95.19%, a balanced accuracy of 88.76%, a precision of 95.26%, a recall of 78.42%, and an ROC-AUC of 0.8886. SHAP analysis confirmed the model's ability to rank the most relevant ECG features, such as QRS duration, in accordance with clinical intuitions, thereby fostering trust and usability in clinical practice. The findings recognize CardioForest as an extremely dependable and interpretable WCT detection model. Being able to offer accurate predictions and transparency through explainability makes it a valuable tool to help cardiologists make timely and well-informed diagnoses, especially for high-stakes and emergency scenarios.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†CardioForestï¼Œä¸€ç§æ—¨åœ¨è‡ªåŠ¨æ£€æµ‹å®½QRSæ³¢ç¾¤å¿ƒåŠ¨è¿‡é€Ÿ(Wide QRS Complex Tachycardia, WCT)çš„é›†æˆå­¦ä¹ æ¡†æ¶ã€‚ç ”ç©¶æ•´åˆäº†ä¼˜åŒ–çš„Random Forestæ¨¡å‹ã€XGBoostå’ŒLightGBMï¼Œå¹¶åŸºäºMIMIC-IVæ•°æ®é›†è¿›è¡Œäº†å…¨é¢çš„è®­ç»ƒä¸è¯„ä¼°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒCardioForeståœ¨å„é¡¹æŒ‡æ ‡ä¸Šå‡è¡¨ç°ä¼˜å¼‚ï¼Œå–å¾—äº†95.19%çš„æµ‹è¯•å‡†ç¡®ç‡å’Œ0.8886çš„ROC-AUCã€‚ä¸ºäº†æå‡ä¸´åºŠä¿¡ä»»åº¦ï¼Œè¯¥æ¡†æ¶å¼•å…¥SHAP (SHapley Additive exPlanations) æŠ€æœ¯è¿›è¡Œå¯è§£é‡Šæ€§åˆ†æï¼ŒéªŒè¯äº†æ¨¡å‹æå–QRS durationç­‰ç‰¹å¾çš„ä¸´åºŠä¸€è‡´æ€§ã€‚è¯¥æ¨¡å‹çš„é«˜å¯é æ€§ä¸é€æ˜åº¦ä½¿å…¶æˆä¸ºè¾…åŠ©å¿ƒè„ç—…ä¸“å®¶è¿›è¡Œå®æ—¶ã€ç²¾å‡†è¯Šæ–­çš„æœ‰åŠ›å·¥å…·ï¼Œç‰¹åˆ«é€‚ç”¨äºé«˜é£é™©çš„æ€¥è¯Šåœºæ™¯ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25804v2",
      "published_date": "2025-09-30 05:23:57 UTC",
      "updated_date": "2025-11-05 07:14:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:43:48.685150+00:00"
    },
    {
      "arxiv_id": "2509.25803v1",
      "title": "Better with Less: Small Proprietary Models Surpass Large Language Models in Financial Transaction Understanding",
      "title_zh": "ä»¥å°‘èƒœå¤šï¼šå°å‹ä¸“æœ‰æ¨¡å‹åœ¨é‡‘èäº¤æ˜“ç†è§£ä¸­è¶…è¶Šå¤§è¯­è¨€æ¨¡å‹",
      "authors": [
        "Wanying Ding",
        "Savinay Narendra",
        "Xiran Shi",
        "Adwait Ratnaparkhi",
        "Chengrui Yang",
        "Nikoo Sabzevar",
        "Ziyan Yin"
      ],
      "abstract": "Analyzing financial transactions is crucial for ensuring regulatory compliance, detecting fraud, and supporting decisions. The complexity of financial transaction data necessitates advanced techniques to extract meaningful insights and ensure accurate analysis. Since Transformer-based models have shown outstanding performance across multiple domains, this paper seeks to explore their potential in understanding financial transactions. This paper conducts extensive experiments to evaluate three types of Transformer models: Encoder-Only, Decoder-Only, and Encoder-Decoder models. For each type, we explore three options: pretrained LLMs, fine-tuned LLMs, and small proprietary models developed from scratch. Our analysis reveals that while LLMs, such as LLaMA3-8b, Flan-T5, and SBERT, demonstrate impressive capabilities in various natural language processing tasks, they do not significantly outperform small proprietary models in the specific context of financial transaction understanding. This phenomenon is particularly evident in terms of speed and cost efficiency. Proprietary models, tailored to the unique requirements of transaction data, exhibit faster processing times and lower operational costs, making them more suitable for real-time applications in the financial sector. Our findings highlight the importance of model selection based on domain-specific needs and underscore the potential advantages of customized proprietary models over general-purpose LLMs in specialized applications. Ultimately, we chose to implement a proprietary decoder-only model to handle the complex transactions that we previously couldn't manage. This model can help us to improve 14% transaction coverage, and save more than \\$13 million annual cost.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨é‡‘èäº¤æ˜“ç†è§£é¢†åŸŸä¸­ Transformer æ¶æ„æ¨¡å‹çš„åº”ç”¨æ½œåŠ›ï¼Œä»¥è§£å†³åˆè§„ç›‘ç®¡ã€æ¬ºè¯ˆæ£€æµ‹å’Œå†³ç­–æ”¯æŒä¸­çš„æ•°æ®åˆ†æéš¾é¢˜ã€‚ç ”ç©¶äººå‘˜å¯¹ Encoder-Onlyã€Decoder-Only å’Œ Encoder-Decoder ä¸‰ç±»æ¨¡å‹è¿›è¡Œäº†å¹¿æ³›å®éªŒï¼Œå¯¹æ¯”äº†é¢„è®­ç»ƒ LLMsã€å¾®è°ƒ LLMs ä»¥åŠä»é›¶å¼€å‘çš„ Small Proprietary Modelsã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œå°½ç®¡ LLaMA3-8bã€Flan-T5 å’Œ SBERT ç­‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é€šç”¨ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨é‡‘èäº¤æ˜“ç†è§£è¿™ä¸€ç‰¹å®šè¯­å¢ƒä¸‹ï¼Œå…¶è¡¨ç°å¹¶æœªæ˜¾è‘—ä¼˜äºå°å‹ç§æœ‰æ¨¡å‹ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œä¸“é—¨å®šåˆ¶çš„ Proprietary Models åœ¨å¤„ç†é€Ÿåº¦å’Œæˆæœ¬æ•ˆç›Šä¸Šä¼˜åŠ¿æ˜¾è‘—ï¼Œæ›´ç¬¦åˆé‡‘èè¡Œä¸šçš„å®æ—¶åº”ç”¨éœ€æ±‚ã€‚æœ€ç»ˆï¼Œè¯¥ç ”ç©¶é€šè¿‡å®ç°ä¸€ç§ç§æœ‰çš„ Decoder-Only æ¨¡å‹ï¼ŒæˆåŠŸå°†äº¤æ˜“è¦†ç›–ç‡(Transaction Coverage)æå‡äº† 14%ï¼Œå¹¶å®ç°æ¯å¹´è¶…è¿‡ 1300 ä¸‡ç¾å…ƒçš„æˆæœ¬èŠ‚çº¦ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CE",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "9 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.25803v1",
      "published_date": "2025-09-30 05:23:08 UTC",
      "updated_date": "2025-09-30 05:23:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:43:50.585491+00:00"
    },
    {
      "arxiv_id": "2509.25794v1",
      "title": "Point-It-Out: Benchmarking Embodied Reasoning for Vision Language Models in Multi-Stage Visual Grounding",
      "title_zh": "Point-It-Outï¼šå¤šé˜¶æ®µè§†è§‰å®šä½ä¸­è§†è§‰è¯­è¨€æ¨¡å‹å…·èº«æ¨ç†èƒ½åŠ›çš„åŸºå‡†è¯„æµ‹",
      "authors": [
        "Haotian Xue",
        "Yunhao Ge",
        "Yu Zeng",
        "Zhaoshuo Li",
        "Ming-Yu Liu",
        "Yongxin Chen",
        "Jiaojiao Fan"
      ],
      "abstract": "Vision-Language Models (VLMs) have demonstrated impressive world knowledge across a wide range of tasks, making them promising candidates for embodied reasoning applications. However, existing benchmarks primarily evaluate the embodied reasoning ability of VLMs through multiple-choice questions based on image annotations -- for example, selecting which trajectory better describes an event in the image. In this work, we introduce the Point-It-Out (PIO) benchmark, a novel benchmark designed to systematically assess the embodied reasoning abilities of VLMs through precise visual grounding. We propose a hierarchical evaluation protocol spanning three stages (S1: referred-object localization, S2: task-driven pointing, and S3: visual trace prediction), with data collected from critical domains for embodied intelligence, including indoor, kitchen, driving, and robotic manipulation scenarios. Extensive experiments with over ten state-of-the-art VLMs reveal several interesting findings. For example, strong general-purpose models such as GPT-4o, while excelling on many benchmarks (e.g., language, perception, and reasoning), underperform compared to some open-source models in precise visual grounding; models such as MoLMO perform well in S1 and S2 but struggle in S3, where requires grounding combined with visual trace planning.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Point-It-Out (PIO) è¯„æµ‹åŸºå‡†ï¼Œæ—¨åœ¨ç³»ç»Ÿè¯„ä¼° Vision-Language Models (VLMs) åœ¨å¤šé˜¶æ®µ Visual Grounding ä¸­çš„å…·èº«æ¨ç† (Embodied Reasoning) èƒ½åŠ›ã€‚é’ˆå¯¹ç°æœ‰åŸºå‡†ä¸»è¦ä¾èµ–é€‰æ‹©é¢˜è€Œæ— æ³•å‡†ç¡®è¡¡é‡æ¨¡å‹èƒ½åŠ›çš„å±€é™ï¼ŒPIO å¼•å…¥äº†åŒ…å«è¢«æåŠç‰©ä½“å®šä½ (S1: Referred-object localization)ã€ä»»åŠ¡é©±åŠ¨æŒ‡å‘ (S2: Task-driven pointing) å’Œè§†è§‰è½¨è¿¹é¢„æµ‹ (S3: Visual trace prediction) çš„ä¸‰é˜¶æ®µå±‚çº§åŒ–è¯„ä¼°åè®®ã€‚è¯¥åŸºå‡†çš„æ•°æ®é›†æ¶µç›–äº†å®¤å†…ã€å¨æˆ¿ã€é©¾é©¶å’Œæœºå™¨äººæ“ä½œç­‰å…·èº«æ™ºèƒ½çš„å…³é”®é¢†åŸŸã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œå°½ç®¡ GPT-4o ç­‰é€šç”¨æ¨¡å‹åœ¨ä¼ ç»Ÿæ„ŸçŸ¥ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨ç²¾å‡† Visual Grounding æ–¹é¢å´é€Šè‰²äºéƒ¨åˆ†å¼€æºæ¨¡å‹ã€‚åŒæ—¶ï¼Œç ”ç©¶å‘ç° MoLMO ç­‰æ¨¡å‹è™½ç„¶æ“…é•¿åŸºç¡€å®šä½ï¼Œä½†åœ¨éœ€è¦ç»“åˆè§†è§‰è½¨è¿¹è§„åˆ’çš„ S3 é˜¶æ®µè¡¨ç°ä¸ä½³ã€‚è¿™ä¸€å‘ç°æ­ç¤ºäº†å½“å‰ VLMs åœ¨å…·èº«æ¨ç†æ–¹é¢çš„å±€é™æ€§ï¼Œå¹¶ä¸ºæœªæ¥æ¨¡å‹åœ¨å¤æ‚ç¯å¢ƒä¸‹çš„æ¨ç†ä¸è§„åˆ’èƒ½åŠ›æå‡æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25794v1",
      "published_date": "2025-09-30 05:05:54 UTC",
      "updated_date": "2025-09-30 05:05:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:43:52.688378+00:00"
    },
    {
      "arxiv_id": "2509.25792v1",
      "title": "PUREVQ-GAN: Defending Data Poisoning Attacks through Vector-Quantized Bottlenecks",
      "title_zh": "PUREVQ-GANï¼šåŸºäºå‘é‡é‡åŒ–ç“¶é¢ˆé˜²å¾¡æ•°æ®æŠ•æ¯’æ”»å‡»",
      "authors": [
        "Alexander Branch",
        "Omead Pooladzandi",
        "Radin Khosraviani",
        "Sunay Gajanan Bhat",
        "Jeffrey Jiang",
        "Gregory Pottie"
      ],
      "abstract": "We introduce PureVQ-GAN, a defense against data poisoning that forces backdoor triggers through a discrete bottleneck using Vector-Quantized VAE with GAN discriminator. By quantizing poisoned images through a learned codebook, PureVQ-GAN destroys fine-grained trigger patterns while preserving semantic content. A GAN discriminator ensures outputs match the natural image distribution, preventing reconstruction of out-of-distribution perturbations. On CIFAR-10, PureVQ-GAN achieves 0% poison success rate (PSR) against Gradient Matching and Bullseye Polytope attacks, and 1.64% against Narcissus while maintaining 91-95% clean accuracy. Unlike diffusion-based defenses requiring hundreds of iterative refinement steps, PureVQ-GAN is over 50x faster, making it practical for real training pipelines.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† PureVQ-GANï¼Œè¿™æ˜¯ä¸€ç§é’ˆå¯¹æ•°æ®æŠ•æ¯’æ”»å‡» (data poisoning attacks) çš„é˜²å¾¡æœºåˆ¶ï¼Œæ—¨åœ¨é€šè¿‡ç¦»æ•£ç“¶é¢ˆå¤„ç†å¸¦æœ‰åé—¨è§¦å‘å™¨ (backdoor triggers) çš„å›¾åƒã€‚è¯¥æ–¹æ³•åˆ©ç”¨å¸¦æœ‰ GAN åˆ¤åˆ«å™¨çš„çŸ¢é‡é‡åŒ–å˜åˆ†è‡ªç¼–ç å™¨ (Vector-Quantized VAE)ï¼Œé€šè¿‡å­¦ä¹ åˆ°çš„ä»£ç ç°¿ (codebook) å¯¹ä¸­æ¯’å›¾åƒè¿›è¡Œé‡åŒ–å¤„ç†ï¼Œåœ¨ä¿ç•™è¯­ä¹‰å†…å®¹çš„åŒæ—¶æœ‰æ•ˆç ´åç»†ç²’åº¦çš„è§¦å‘å™¨æ¨¡å¼ã€‚å…¶ä¸­ GAN åˆ¤åˆ«å™¨è´Ÿè´£ç¡®ä¿è¾“å‡ºç»“æœç¬¦åˆè‡ªç„¶å›¾åƒåˆ†å¸ƒï¼Œä»è€Œé˜²æ­¢æ¨¡å‹é‡å»ºå‡ºåˆ†å¸ƒå¤– (out-of-distribution) çš„æ‰°åŠ¨ã€‚åœ¨ CIFAR-10 æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒPureVQ-GAN åœ¨é¢å¯¹ Gradient Matching å’Œ Bullseye Polytope æ”»å‡»æ—¶å®ç°äº† 0% çš„æŠ•æ¯’æˆåŠŸç‡ (PSR)ï¼Œå¯¹ Narcissus æ”»å‡»çš„æˆåŠŸç‡ä¹Ÿä»…ä¸º 1.64%ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ¡ˆåœ¨ä¿æŒ 91-95% æ¸…æ´å‡†ç¡®ç‡ (clean accuracy) çš„åŸºç¡€ä¸Šï¼Œè¿è¡Œé€Ÿåº¦æ¯”åŸºäºæ‰©æ•£æ¨¡å‹ (diffusion-based) çš„é˜²å¾¡æ‰‹æ®µå¿« 50 å€ä»¥ä¸Šã€‚è¿™ä½¿å¾— PureVQ-GAN æˆä¸ºä¸€ç§èƒ½å¤Ÿæ•´åˆè¿›å®é™…è®­ç»ƒæµæ°´çº¿çš„é«˜æ•ˆé˜²å¾¡æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25792v1",
      "published_date": "2025-09-30 05:04:17 UTC",
      "updated_date": "2025-09-30 05:04:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:43:58.899124+00:00"
    },
    {
      "arxiv_id": "2509.25781v1",
      "title": "Deontic Argumentation",
      "title_zh": "é“ä¹‰è®ºè¯",
      "authors": [
        "Guido Governatori",
        "Antonino Rotolo"
      ],
      "abstract": "We address the issue of defining a semantics for deontic argumentation that supports weak permission. Some recent results show that grounded semantics do not support weak permission when there is a conflict between two obligations. We provide a definition of Deontic Argumentation Theory that accounts for weak permission, and we recall the result about grounded semantics. Then, we propose a new semantics that supports weak permission.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¦‚ä½•ä¸ºæ”¯æŒ weak permission çš„ deontic argumentation å®šä¹‰ä¸€ç§è¯­ä¹‰ã€‚é’ˆå¯¹è¿‘æœŸç ”ç©¶å‘ç° grounded semantics åœ¨ä¸¤ä¸ª obligation å†²çªæ—¶æ— æ³•æ”¯æŒ weak permission çš„é—®é¢˜ï¼Œè®ºæ–‡æä¾›äº†ä¸€ä¸ªèƒ½å¤Ÿè§£é‡Š weak permission çš„ Deontic Argumentation Theory å®šä¹‰ã€‚æ–‡ä¸­å›é¡¾äº† grounded semantics çš„ç›¸å…³å±€é™æ€§ï¼Œå¹¶æ®æ­¤æå‡ºäº†ä¸€ç§èƒ½å¤Ÿæ”¯æŒ weak permission çš„å…¨æ–°è¯­ä¹‰ã€‚è¯¥ç ”ç©¶ä¸ºå¤„ç†ä¹‰åŠ¡å†²çªä¸‹çš„é“ä¹‰æ¨ç†æä¾›äº†ç†è®ºåŸºç¡€ï¼Œå¢å¼ºäº†è®ºè¯ç³»ç»Ÿåœ¨è®¸å¯é€»è¾‘æ–¹é¢çš„è¡¨ç°ã€‚",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25781v1",
      "published_date": "2025-09-30 04:50:07 UTC",
      "updated_date": "2025-09-30 04:50:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:44:02.584540+00:00"
    },
    {
      "arxiv_id": "2509.25779v2",
      "title": "Planner-R1: Reward Shaping Enables Efficient Agentic RL with Smaller LLMs",
      "title_zh": "Planner-R1ï¼šå¥–åŠ±å¡‘é€ åŠ©åŠ›å°è§„æ¨¡å¤§è¯­è¨€æ¨¡å‹å®ç°é«˜æ•ˆæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Siyu Zhu",
        "Yanbin Jiang",
        "Hejian Sang",
        "Shao Tang",
        "Qingquan Song",
        "Biao He",
        "Rohit Jain",
        "Zhipeng Wang",
        "Alborz Geramifard"
      ],
      "abstract": "We investigated Agentic RL with large language models on the \\textsc{TravelPlanner} benchmark. Our approach, \\textsc{Planner-R1}, achieved a \\textbf{56.9\\%} final-pass rate with only 180 training queries, a $2.7\\times$ improvement over GPT-5's $21.2\\%$ baseline and the strongest agentic result on the public leaderboard. A central finding was that smaller models (8B) were highly responsive to reward shaping: with dense process-level signals, they reached competitive performance while being $3.5\\times$ more compute-efficient and $1.5\\times$ more memory-efficient than 32B models. Larger models were more robust under sparse rewards but exhibited smaller relative gains from shaping and higher variance across runs. While curriculum learning offered no significant benefit, shaped rewards consistently amplified learning dynamics, making 8B models the most efficient setting for agentic RL. Crucially, these gains did not come at the cost of overfitting: fine-tuned models mostly maintained or exceeded baseline performance on out-of-domain tasks, including \\textsc{Multi-IF}, \\textsc{NaturalPlan}, and $Ï„$-\\textsc{Bench}. These results establish reward shaping as a decisive lever for scaling agentic RL, highlight the competitive strength of smaller models, and demonstrate that efficiency can be achieved without sacrificing generalization.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨å¤§è¯­è¨€æ¨¡å‹ä¸Šåº”ç”¨å¼ºåŒ–å­¦ä¹ ï¼ˆAgentic RLï¼‰è§£å†³å¤æ‚ä»»åŠ¡çš„æ–¹æ³•ï¼Œå¹¶æå‡ºäº†Planner-R1ã€‚åœ¨TravelPlanneråŸºå‡†æµ‹è¯•ä¸­ï¼ŒPlanner-R1ä»…é€šè¿‡180æ¬¡è®­ç»ƒæŸ¥è¯¢å°±è¾¾åˆ°äº†56.9%çš„æœ€ç»ˆé€šè¿‡ç‡ï¼Œæ€§èƒ½æ¯”GPT-5åŸºå‡†æå‡äº†2.7å€ï¼Œæˆä¸ºè¯¥æ¦œå•ä¸Šæœ€å¼ºçš„æ™ºèƒ½ä½“ç»“æœã€‚æ ¸å¿ƒå‘ç°æ˜¯è¾ƒå°è§„æ¨¡çš„æ¨¡å‹ï¼ˆå¦‚8Bï¼‰å¯¹å¥–åŠ±å»ºæ¨¡ï¼ˆreward shapingï¼‰å…·æœ‰é«˜åº¦å“åº”æ€§ï¼Œåˆ©ç”¨å¯†é›†çš„è¿‡ç¨‹çº§ä¿¡å·ï¼Œå…¶è®¡ç®—æ•ˆç‡å’Œå†…å­˜æ•ˆç‡åˆ†åˆ«æ¯”32Bæ¨¡å‹é«˜å‡º3.5å€å’Œ1.5å€ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œå¤§å‹æ¨¡å‹åœ¨ç¨€ç–å¥–åŠ±ä¸‹æ›´å…·é²æ£’æ€§ï¼Œä½†ä»å¥–åŠ±å»ºæ¨¡ä¸­è·å¾—çš„ç›¸å¯¹æ”¶ç›Šè¾ƒå°ä¸”è¿è¡Œæ–¹å·®è¾ƒé«˜ã€‚æ­¤å¤–ï¼Œå¾®è°ƒåçš„æ¨¡å‹åœ¨Multi-IFã€NaturalPlanå’ŒÏ„-Benchç­‰åŸŸå¤–ä»»åŠ¡ä¸Šä¿æŒæˆ–è¶…è¿‡äº†åŸºå‡†æ€§èƒ½ï¼Œè¯æ˜äº†è¯¥æ–¹æ³•åœ¨æå‡æ•ˆç‡çš„åŒæ—¶å¹¶æœªç‰ºç‰²æ³›åŒ–èƒ½åŠ›ã€‚è¯¥ç ”ç©¶ç¡®ç«‹äº†å¥–åŠ±å»ºæ¨¡æ˜¯æ‰©å±•Agentic RLçš„å…³é”®æ æ†ï¼Œçªæ˜¾äº†å°å‹æ¨¡å‹åœ¨å…¼é¡¾æ€§èƒ½ä¸æ•ˆç‡æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25779v2",
      "published_date": "2025-09-30 04:49:36 UTC",
      "updated_date": "2025-10-01 20:23:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:44:06.893774+00:00"
    },
    {
      "arxiv_id": "2509.25776v3",
      "title": "Editable Noise Map Inversion: Encoding Target-image into Noise For High-Fidelity Image Manipulation",
      "title_zh": "å¯ç¼–è¾‘å™ªå£°å›¾åæ¼”ï¼šå°†ç›®æ ‡å›¾åƒç¼–ç è‡³å™ªå£°ä¸­ä»¥å®ç°é«˜ä¿çœŸå›¾åƒç¼–è¾‘",
      "authors": [
        "Mingyu Kang",
        "Yong Suk Choi"
      ],
      "abstract": "Text-to-image diffusion models have achieved remarkable success in generating high-quality and diverse images. Building on these advancements, diffusion models have also demonstrated exceptional performance in text-guided image editing. A key strategy for effective image editing involves inverting the source image into editable noise maps associated with the target image. However, previous inversion methods face challenges in adhering closely to the target text prompt. The limitation arises because inverted noise maps, while enabling faithful reconstruction of the source image, restrict the flexibility needed for desired edits. To overcome this issue, we propose Editable Noise Map Inversion (ENM Inversion), a novel inversion technique that searches for optimal noise maps to ensure both content preservation and editability. We analyze the properties of noise maps for enhanced editability. Based on this analysis, our method introduces an editable noise refinement that aligns with the desired edits by minimizing the difference between the reconstructed and edited noise maps. Extensive experiments demonstrate that ENM Inversion outperforms existing approaches across a wide range of image editing tasks in both preservation and edit fidelity with target prompts. Our approach can also be easily applied to video editing, enabling temporal consistency and content manipulation across frames.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹æ–‡æœ¬å¼•å¯¼çš„å›¾åƒç¼–è¾‘ä»»åŠ¡ï¼Œæå‡ºäº†åä¸ºEditable Noise Map Inversion (ENM Inversion) çš„æ–°å‹åæ¼”æŠ€æœ¯ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ–¹æ³•åœ¨ä¿æŒåŸå›¾å†…å®¹ä¸éµå¾ªç›®æ ‡æ–‡æœ¬æŒ‡ä»¤ä¹‹é—´çš„æƒè¡¡éš¾é¢˜ã€‚ä¼ ç»Ÿåæ¼”æ–¹æ³•ç”Ÿæˆçš„å™ªå£°å›¾å¾€å¾€è¿‡äºå—é™äºåŸå›¾é‡å»ºï¼Œå¯¼è‡´æ¨¡å‹åœ¨æ‰§è¡Œç¼–è¾‘æ—¶ç¼ºä¹å¿…è¦çš„çµæ´»æ€§ï¼ˆEditabilityï¼‰ã€‚ä¸ºæ­¤ï¼ŒENM Inversioné€šè¿‡æœç´¢æœ€ä¼˜å™ªå£°å›¾æ¥å¹³è¡¡å†…å®¹ä¿ç•™ä¸å¯ç¼–è¾‘æ€§ï¼Œå¹¶åŸºäºå¯¹å™ªå£°å›¾ç‰¹æ€§çš„åˆ†æå¼•å…¥äº†å¯ç¼–è¾‘å™ªå£°ç»†åŒ–ï¼ˆEditable Noise Refinementï¼‰æœºåˆ¶ã€‚è¯¥æœºåˆ¶é€šè¿‡æœ€å°åŒ–é‡å»ºå™ªå£°å›¾ä¸ç¼–è¾‘åå™ªå£°å›¾ä¹‹é—´çš„å·®å¼‚ï¼Œç¡®ä¿ç”Ÿæˆè¿‡ç¨‹èƒ½æ›´å¥½åœ°å¯¹é½ç›®æ ‡ç¼–è¾‘æŒ‡ä»¤ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šç§å›¾åƒç¼–è¾‘ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œæ— è®ºæ˜¯åŸå›¾ä¿ç•™ç¨‹åº¦è¿˜æ˜¯å¯¹ç›®æ ‡æç¤ºè¯ï¼ˆTarget Promptsï¼‰çš„éµå¾ªåº¦å‡è¶…è¶Šäº†ç°æœ‰åŸºå‡†ã€‚æ­¤å¤–ï¼ŒENM Inversionè¿˜å¯ä»¥æ— ç¼æ‰©å±•è‡³è§†é¢‘ç¼–è¾‘é¢†åŸŸï¼Œæœ‰æ•ˆå®ç°äº†è·¨å¸§çš„æ—¶é—´ä¸€è‡´æ€§å’Œå†…å®¹æ“ä½œã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ICML 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.25776v3",
      "published_date": "2025-09-30 04:44:53 UTC",
      "updated_date": "2025-10-27 06:34:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:44:10.394650+00:00"
    },
    {
      "arxiv_id": "2509.25775v3",
      "title": "Autonomy-Aware Clustering: When Local Decisions Supersede Global Prescriptions",
      "title_zh": "è‡ªä¸»æ„ŸçŸ¥èšç±»ï¼šå½“å±€éƒ¨å†³ç­–ä¼˜äºå…¨å±€è§„çº¦",
      "authors": [
        "Amber Srivastava",
        "Salar Basiri",
        "Srinivasa Salapaka"
      ],
      "abstract": "Clustering arises in a wide range of problem formulations, yet most existing approaches assume that the entities under clustering are passive and strictly conform to their assigned groups. In reality, entities often exhibit local autonomy, overriding prescribed associations in ways not fully captured by feature representations. Such autonomy can substantially reshape clustering outcomes -- altering cluster compositions, geometry, and cardinality -- with significant downstream effects on inference and decision-making. We introduce autonomy-aware clustering, a reinforcement learning (RL) framework that learns and accounts for the influence of local autonomy without requiring prior knowledge of its form. Our approach integrates RL with a Deterministic Annealing (DA) procedure, where, to determine underlying clusters, DA naturally promotes exploration in early stages of annealing and transitions to exploitation later. We also show that the annealing procedure exhibits phase transitions that enable design of efficient annealing schedules. To further enhance adaptability, we propose the Adaptive Distance Estimation Network (ADEN), a transformer-based attention model that learns dependencies between entities and cluster representatives within the RL loop, accommodates variable-sized inputs and outputs, and enables knowledge transfer across diverse problem instances. Empirical results show that our framework closely aligns with underlying data dynamics: even without explicit autonomy models, it achieves solutions close to the ground truth (gap ~3-4%), whereas ignoring autonomy leads to substantially larger gaps (~35-40%). The code and data are publicly available at https://github.com/salar96/AutonomyAwareClustering.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Autonomy-Aware Clusteringï¼Œè¿™æ˜¯ä¸€ç§åŸºäºReinforcement Learning (RL)çš„æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿèšç±»æ–¹æ³•å¿½è§†å®ä½“local autonomyï¼ˆå±€éƒ¨è‡ªä¸»æƒï¼‰è€Œå¯¼è‡´èšç±»ç»“æœåå·®çš„é—®é¢˜ã€‚è¯¥æ–¹æ³•é€šè¿‡å°†RLä¸Deterministic Annealing (DA)ç¨‹åºç›¸ç»“åˆï¼Œåœ¨æ— éœ€å…ˆéªŒçŸ¥è¯†çš„æƒ…å†µä¸‹è‡ªåŠ¨å­¦ä¹ å¹¶è¡¥å¿è‡ªä¸»æƒå¯¹èšç±»å‡ ä½•å½¢çŠ¶å’Œç»„æˆçš„å½±å“ã€‚ç ”ç©¶è¿›ä¸€æ­¥å¼•å…¥äº†åŸºäºTransformerçš„Adaptive Distance Estimation Network (ADEN)ï¼Œåˆ©ç”¨æ³¨æ„åŠ›æœºåˆ¶æ•æ‰å®ä½“ä¸èšç±»ä¸­å¿ƒä¹‹é—´çš„å¤æ‚ä¾èµ–å…³ç³»ï¼Œå¹¶å®ç°äº†è·¨ä»»åŠ¡çš„çŸ¥è¯†è¿ç§»ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¡†æ¶åœ¨æ¨¡æ‹ŸçœŸå®æ•°æ®åŠ¨æ€æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œå…¶è§£ä¸çœŸå®å€¼çš„å·®è·ä»…ä¸º3-4%ï¼Œè€Œå¿½ç•¥è‡ªä¸»æƒçš„æ¨¡å‹å·®è·åˆ™é«˜è¾¾35-40%ã€‚è¿™ä¸€æˆæœä¸ºå¤„ç†éè¢«åŠ¨å®ä½“çš„å¤æ‚å†³ç­–å’Œæ¨ç†ä»»åŠ¡æä¾›äº†ä¸€ç§é²æ£’ä¸”é«˜æ•ˆçš„èšç±»æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint. Under review at a peer-reviewed venue. Minor formatting correction: the earlier version included an incorrect conference header, which has been removed. Content unchanged",
      "pdf_url": "https://arxiv.org/pdf/2509.25775v3",
      "published_date": "2025-09-30 04:44:36 UTC",
      "updated_date": "2025-10-08 16:05:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:44:39.595363+00:00"
    },
    {
      "arxiv_id": "2509.25774v2",
      "title": "PCPO: Proportionate Credit Policy Optimization for Aligning Image Generation Models",
      "title_zh": "PCPOï¼šé¢å‘å›¾åƒç”Ÿæˆæ¨¡å‹å¯¹é½çš„ç­‰æ¯”ä¾‹ä¿¡ç”¨ç­–ç•¥ä¼˜åŒ–",
      "authors": [
        "Jeongjae Lee",
        "Jong Chul Ye"
      ],
      "abstract": "While reinforcement learning has advanced the alignment of text-to-image (T2I) models, state-of-the-art policy gradient methods are still hampered by training instability and high variance, hindering convergence speed and compromising image quality. Our analysis identifies a key cause of this instability: disproportionate credit assignment, in which the mathematical structure of the generative sampler produces volatile and non-proportional feedback across timesteps. To address this, we introduce Proportionate Credit Policy Optimization (PCPO), a framework that enforces proportional credit assignment through a stable objective reformulation and a principled reweighting of timesteps. This correction stabilizes the training process, leading to significantly accelerated convergence and superior image quality. The improvement in quality is a direct result of mitigating model collapse, a common failure mode in recursive training. PCPO substantially outperforms existing policy gradient baselines on all fronts, including the state-of-the-art DanceGRPO. Code is available at https://github.com/jaylee2000/pcpo/.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ–‡æœ¬åˆ°å›¾åƒ(T2I)ç”Ÿæˆæ¨¡å‹åœ¨å¼ºåŒ–å­¦ä¹ å¯¹é½è¿‡ç¨‹ä¸­å­˜åœ¨çš„è®­ç»ƒä¸ç¨³å®šå’Œé«˜æ–¹å·®é—®é¢˜ï¼ŒæŒ‡å‡ºç”Ÿæˆé‡‡æ ·å™¨çš„æ¯”ä¾‹å¤±è°ƒä¿¡ç”¨åˆ†é…(Disproportionate Credit Assignment)æ˜¯å¯¼è‡´æ¨¡å‹æ”¶æ•›ç¼“æ…¢å’Œå›¾åƒè´¨é‡ä¸‹é™çš„å…³é”®åŸå› ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†Proportionate Credit Policy Optimization (PCPO)æ¡†æ¶ï¼Œé€šè¿‡é‡æ–°æ„å»ºç¨³å®šçš„ç›®æ ‡å‡½æ•°å¹¶å¯¹æ—¶é—´æ­¥è¿›è¡ŒåŸåˆ™æ€§é‡åŠ æƒï¼Œå®ç°äº†æ¯”ä¾‹ä¿¡ç”¨åˆ†é…ã€‚è¯¥æ–¹æ³•æœ‰æ•ˆç¨³å®šäº†è®­ç»ƒè¿‡ç¨‹ï¼Œæ˜¾è‘—åŠ å¿«äº†æ”¶æ•›é€Ÿåº¦ï¼Œå¹¶æ˜¾è‘—æå‡äº†ç”Ÿæˆçš„å›¾åƒè´¨é‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒPCPOé€šè¿‡ç¼“è§£é€’å½’è®­ç»ƒä¸­å¸¸è§çš„æ¨¡å‹å´©æºƒ(Model Collapse)ç°è±¡ï¼Œåœ¨å„é¡¹æŒ‡æ ‡ä¸Šå‡ä¼˜äºç°æœ‰çš„ç­–ç•¥æ¢¯åº¦(Policy Gradient)åŸºçº¿æ¨¡å‹ï¼ŒåŒ…æ‹¬ç›®å‰æœ€å…ˆè¿›çš„DanceGRPOã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "35 pages, 20 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.25774v2",
      "published_date": "2025-09-30 04:43:58 UTC",
      "updated_date": "2025-12-06 07:55:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:44:30.796611+00:00"
    },
    {
      "arxiv_id": "2510.05123v1",
      "title": "A Scalable AI Driven, IoT Integrated Cognitive Digital Twin for Multi-Modal Neuro-Oncological Prognostics and Tumor Kinetics Prediction using Enhanced Vision Transformer and XAI",
      "title_zh": "åŸºäºå¢å¼ºå‹ Vision Transformer ä¸å¯è§£é‡Šäººå·¥æ™ºèƒ½çš„å¯æ‰©å±• AI é©±åŠ¨åŠç‰©è”ç½‘é›†æˆè®¤çŸ¥æ•°å­—å­ªç”Ÿï¼šç”¨äºå¤šæ¨¡æ€ç¥ç»è‚¿ç˜¤é¢„åä¸è‚¿ç˜¤åŠ¨åŠ›å­¦é¢„æµ‹",
      "authors": [
        "Saptarshi Banerjee",
        "Himadri Nath Saha",
        "Utsho Banerjee",
        "Rajarshi Karmakar",
        "Jon Turdiev"
      ],
      "abstract": "Neuro-oncological prognostics are now vital in modern clinical neuroscience because brain tumors pose significant challenges in detection and management. To tackle this issue, we propose a cognitive digital twin framework that combines real-time EEG signals from a wearable skullcap with structural MRI data for dynamic and personalized tumor monitoring. At the heart of this framework is an Enhanced Vision Transformer (ViT++) that includes innovative components like Patch-Level Attention Regularization (PLAR) and an Adaptive Threshold Mechanism to improve tumor localization and understanding. A Bidirectional LSTM-based neural classifier analyzes EEG patterns over time to classify brain states such as seizure, interictal, and healthy. Grad-CAM-based heatmaps and a three.js-powered 3D visualization module provide interactive anatomical insights. Furthermore, a tumor kinetics engine predicts volumetric growth by looking at changes in MRI trends and anomalies from EEG data. With impressive accuracy metrics of 94.6% precision, 93.2% recall, and a Dice score of 0.91, this framework sets a new standard for real-time, interpretable neurodiagnostics. It paves the way for future advancements in intelligent brain health monitoring.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§å¯æ‰©å±•çš„ã€é›†æˆ IoT çš„è®¤çŸ¥æ•°å­—å­ªç”Ÿ (Cognitive Digital Twin) æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡å¤šæ¨¡æ€æ•°æ®è§£å†³è„‘è‚¿ç˜¤æ£€æµ‹ä¸ç®¡ç†ä¸­çš„é¢„åå’Œè‚¿ç˜¤åŠ¨åŠ›å­¦é¢„æµ‹æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶åˆ›æ–°æ€§åœ°ç»“åˆäº†ä½©æˆ´å¼å¤´ç½©è·å–çš„å®æ—¶ EEG ä¿¡å·ä¸ç»“æ„åŒ– MRI æ•°æ®ï¼Œå®ç°äº†åŠ¨æ€ä¸”ä¸ªæ€§åŒ–çš„è‚¿ç˜¤ç›‘æµ‹ã€‚å…¶æ ¸å¿ƒé‡‡ç”¨äº†å¢å¼ºå‹è§†è§‰ Transformer (ViT++)ï¼Œé€šè¿‡å¼•å…¥ Patch-Level Attention Regularization (PLAR) å’Œè‡ªé€‚åº”é˜ˆå€¼æœºåˆ¶ (Adaptive Threshold Mechanism) æ˜¾è‘—æå‡äº†è‚¿ç˜¤å®šä½çš„ç²¾åº¦ã€‚ç³»ç»Ÿåˆ©ç”¨åŒå‘é•¿çŸ­æœŸè®°å¿†ç½‘ç»œ (Bidirectional LSTM) åˆ†æè„‘ç”µæ¨¡å¼ä»¥è¯†åˆ«ä¸åŒè„‘éƒ¨çŠ¶æ€ï¼Œå¹¶å€ŸåŠ© Grad-CAM çƒ­åŠ›å›¾ä¸ 3D å¯è§†åŒ–æ¨¡å—æä¾›å¯è§£é‡Šæ€§ (XAI) çš„è§£å‰–å­¦æ´å¯Ÿã€‚æ­¤å¤–ï¼Œå†…ç½®çš„è‚¿ç˜¤åŠ¨åŠ›å­¦å¼•æ“ (Tumor Kinetics Engine) èƒ½å¤Ÿé€šè¿‡åˆ†ææ•°æ®è¶‹åŠ¿é¢„æµ‹è‚¿ç˜¤çš„ä½“ç§¯å¢é•¿ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¡†æ¶è¾¾åˆ°äº† 94.6% çš„ç²¾ç¡®ç‡ã€93.2% çš„å¬å›ç‡ä»¥åŠ 0.91 çš„ Dice scoreï¼Œä¸ºå®æ—¶ã€å¯è§£é‡Šçš„æ™ºèƒ½ç¥ç»è¯Šæ–­å’Œå¤§è„‘å¥åº·ç›‘æµ‹å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.05123v1",
      "published_date": "2025-09-30 04:37:32 UTC",
      "updated_date": "2025-09-30 04:37:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:44:43.687328+00:00"
    },
    {
      "arxiv_id": "2509.25773v1",
      "title": "V-HUB: A Visual-Centric Humor Understanding Benchmark for Video LLMs",
      "title_zh": "V-HUBï¼šé¢å‘è§†é¢‘å¤§è¯­è¨€æ¨¡å‹çš„ä»¥è§†è§‰ä¸ºä¸­å¿ƒçš„å¹½é»˜ç†è§£åŸºå‡†",
      "authors": [
        "Zhengpeng Shi",
        "Hengli Li",
        "Yanpeng Zhao",
        "Jianqun Zhou",
        "Yuxuan Wang",
        "Qinrong Cui",
        "Wei Bi",
        "Songchun Zhu",
        "Bo Zhao",
        "Zilong Zheng"
      ],
      "abstract": "AI models capable of comprehending humor hold real-world promise -- for example, enhancing engagement in human-machine interactions. To gauge and diagnose the capacity of multimodal large language models (MLLMs) for humor understanding, we introduce v-HUB, a novel visual-centric video humor understanding benchmark. v-HUB comprises a curated collection of minimally verbal short videos, sourced from classic silent films and online resources, and reflecting real-world scenarios where humor can be appreciated purely through visual cues. Each video clip is paired with rich annotations, including captions, descriptions, and explanations, supporting evaluation tasks like caption matching and humor explanation. To broaden its applicability, we further construct an open-ended video QA task, making it readily integrable into existing video understanding benchmarks. We evaluate a diverse set of MLLMs, from specialized Video-LLMs to versatile OmniLLMs that can process audio, covering both open-source and proprietary domains. The experimental results expose the difficulties MLLMs face in comprehending humor from visual cues alone. For example, all models exhibit a marked performance drop on caption matching when moving from text-based to video-based evaluation (without audio). Our findings also demonstrate that incorporating audio helps with video humor understanding, highlighting the informativeness of sound and the promise of integrating richer modalities for complex video understanding tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† V-HUBï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨è¯„ä¼°å’Œè¯Šæ–­å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ (MLLMs) å¹½é»˜ç†è§£èƒ½åŠ›çš„æ–°å‹è§†è§‰ä¸­å¿ƒè§†é¢‘å¹½é»˜ç†è§£åŸºå‡†ã€‚V-HUB åŒ…å«ä¸€ç³»åˆ—ç²¾é€‰çš„æç®€è¯­è¨€çŸ­è§†é¢‘ï¼Œä¸»è¦æ¥æºäºç»å…¸é»˜ç‰‡å’Œåœ¨çº¿èµ„æºï¼Œåæ˜ äº†ä»…é€šè¿‡è§†è§‰çº¿ç´¢å³å¯æ„ŸçŸ¥å¹½é»˜çš„çœŸå®åœºæ™¯ã€‚æ¯ä¸ªè§†é¢‘ç‰‡æ®µéƒ½é…æœ‰ä¸°å¯Œçš„æ ‡æ³¨ï¼ŒåŒ…æ‹¬ captionsã€descriptions å’Œ explanationsï¼Œæ”¯æŒ caption matchingã€humor explanation ä»¥åŠå¼€æ”¾å¼ video QA ç­‰å¤šç§è¯„ä¼°ä»»åŠ¡ã€‚ç ”ç©¶å›¢é˜Ÿå¯¹åŒ…æ‹¬ä¸“é—¨çš„ Video-LLMs å’Œå¤šåŠŸèƒ½ OmniLLMs åœ¨å†…çš„å¤šç§å¼€æºå’Œé—­æºæ¨¡å‹è¿›è¡Œäº†è¯„ä¼°ã€‚å®éªŒç»“æœæ­ç¤ºäº†ç›®å‰ MLLMs åœ¨ä»…ä¾èµ–è§†è§‰çº¿ç´¢ç†è§£å¹½é»˜æ—¶é¢ä¸´çš„æŒ‘æˆ˜ï¼Œæ‰€æœ‰æ¨¡å‹åœ¨æ— éŸ³é¢‘çš„çº¯è§†é¢‘è¯„ä¼°ä¸­è¡¨ç°å‡æ˜¾è‘—ä¸‹é™ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¯æ˜äº†éŸ³é¢‘ä¿¡æ¯çš„å¼•å…¥èƒ½æœ‰æ•ˆæå‡å¹½é»˜ç†è§£èƒ½åŠ›ï¼Œå¼ºè°ƒäº†å¤šæ¨¡æ€æ•´åˆåœ¨å¤„ç†å¤æ‚è§†é¢‘ç†è§£ä»»åŠ¡ä¸­çš„é‡è¦æ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25773v1",
      "published_date": "2025-09-30 04:33:52 UTC",
      "updated_date": "2025-09-30 04:33:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:44:55.282021+00:00"
    },
    {
      "arxiv_id": "2509.25771v1",
      "title": "Free Lunch Alignment of Text-to-Image Diffusion Models without Preference Image Pairs",
      "title_zh": "æ— éœ€åå¥½å›¾åƒå¯¹çš„æ–‡ç”Ÿå›¾æ‰©æ•£æ¨¡å‹â€œå…è´¹åˆé¤â€å¯¹é½",
      "authors": [
        "Jia Jun Cheng Xian",
        "Muchen Li",
        "Haotian Yang",
        "Xin Tao",
        "Pengfei Wan",
        "Leonid Sigal",
        "Renjie Liao"
      ],
      "abstract": "Recent advances in diffusion-based text-to-image (T2I) models have led to remarkable success in generating high-quality images from textual prompts. However, ensuring accurate alignment between the text and the generated image remains a significant challenge for state-of-the-art diffusion models. To address this, existing studies employ reinforcement learning with human feedback (RLHF) to align T2I outputs with human preferences. These methods, however, either rely directly on paired image preference data or require a learned reward function, both of which depend heavily on costly, high-quality human annotations and thus face scalability limitations. In this work, we introduce Text Preference Optimization (TPO), a framework that enables \"free-lunch\" alignment of T2I models, achieving alignment without the need for paired image preference data. TPO works by training the model to prefer matched prompts over mismatched prompts, which are constructed by perturbing original captions using a large language model. Our framework is general and compatible with existing preference-based algorithms. We extend both DPO and KTO to our setting, resulting in TDPO and TKTO. Quantitative and qualitative evaluations across multiple benchmarks show that our methods consistently outperform their original counterparts, delivering better human preference scores and improved text-to-image alignment. Our Open-source code is available at https://github.com/DSL-Lab/T2I-Free-Lunch-Alignment.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ–‡æœ¬ç”Ÿæˆå›¾åƒ(T2I)æ‰©æ•£æ¨¡å‹åœ¨å¯¹é½ç²¾åº¦ä¸Šçš„æŒ‘æˆ˜ï¼Œæå‡ºäº†åä¸ºText Preference Optimization (TPO)çš„æ¡†æ¶ï¼Œæ—¨åœ¨å®ç°æ— éœ€æˆå¯¹åå¥½å›¾åƒæ•°æ®çš„â€œå…è´¹åˆé¤â€å¼å¯¹é½ã€‚è¯¥æ–¹æ³•é€šè¿‡å¤§è¯­è¨€æ¨¡å‹(LLM)å¯¹åŸå§‹æ ‡æ³¨è¿›è¡Œæ‰°åŠ¨æ¥æ„é€ ä¸åŒ¹é…çš„æç¤ºè¯ï¼Œè®­ç»ƒæ¨¡å‹åœ¨åŒ¹é…ä¸ä¸åŒ¹é…çš„æç¤ºè¯ä¹‹é—´å­¦ä¹ åå¥½ï¼Œä»è€Œè§„é¿äº†å¯¹é«˜æˆæœ¬äººå·¥å›¾åƒæ ‡æ³¨çš„ä¾èµ–ã€‚TPOå…·æœ‰æå¼ºçš„é€šç”¨æ€§ï¼Œå¯ä¸ç°æœ‰çš„DPOå’ŒKTOç®—æ³•ç»“åˆå½¢æˆTDPOå’ŒTKTOã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­çš„äººç±»åå¥½å¾—åˆ†å’Œæ–‡æœ¬-å›¾åƒå¯¹é½æ€§èƒ½ä¸Šå‡æ˜¾è‘—ä¼˜äºåŸå§‹ç®—æ³•ã€‚è¯¥ç ”ç©¶é€šè¿‡åˆ›æ–°çš„æ–‡æœ¬åå¥½ä¼˜åŒ–è·¯å¾„ï¼Œä¸ºæé«˜å¤§è§„æ¨¡æ‰©æ•£æ¨¡å‹çš„å¯¹é½æ•ˆç‡å’Œå¯æ‰©å±•æ€§æä¾›äº†é«˜æ•ˆä¸”ä½æˆæœ¬çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25771v1",
      "published_date": "2025-09-30 04:32:34 UTC",
      "updated_date": "2025-09-30 04:32:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:44:53.293227+00:00"
    },
    {
      "arxiv_id": "2509.25767v1",
      "title": "Galton's Law of Mediocrity: Why Large Language Models Regress to the Mean and Fail at Creativity in Advertising",
      "title_zh": "Galton å¹³åº¸æ³•åˆ™ï¼šå¤§è¯­è¨€æ¨¡å‹ä¸ºä½•å‘å‡å€¼å›å½’å¹¶åœ¨å¹¿å‘Šåˆ›æ„ä¸­å¤±æ•ˆ",
      "authors": [
        "Matt Keon",
        "Aabid Karim",
        "Bhoomika Lohana",
        "Abdul Karim",
        "Thai Nguyen",
        "Tara Hamilton",
        "Ali Abbas"
      ],
      "abstract": "Large language models (LLMs) generate fluent text yet often default to safe, generic phrasing, raising doubts about their ability to handle creativity. We formalize this tendency as a Galton-style regression to the mean in language and evaluate it using a creativity stress test in advertising concepts. When ad ideas were simplified step by step, creative features such as metaphors, emotions, and visual cues disappeared early, while factual content remained, showing that models favor high-probability information. When asked to regenerate from simplified inputs, models produced longer outputs with lexical variety but failed to recover the depth and distinctiveness of the originals. We combined quantitative comparisons with qualitative analysis, which revealed that the regenerated texts often appeared novel but lacked true originality. Providing ad-specific cues such as metaphors, emotional hooks and visual markers improved alignment and stylistic balance, though outputs still relied on familiar tropes. Taken together, the findings show that without targeted guidance, LLMs drift towards mediocrity in creative tasks; structured signals can partially counter this tendency and point towards pathways for developing creativity-sensitive models.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¹¿å‘Šåˆ›æ„ä¸­å®¹æ˜“é™·å…¥å¹³åº¸ã€è¶‹å‘é€šç”¨è¡¨è¾¾çš„ç°è±¡ï¼Œå¹¶å°†å…¶å½¢å¼åŒ–ä¸ºè¯­è¨€å±‚é¢çš„Galtonå¼å›å½’åˆ°å‡å€¼ç°è±¡ã€‚ç ”ç©¶é€šè¿‡å¯¹å¹¿å‘Šæ¦‚å¿µè¿›è¡Œé€æ­¥ç®€åŒ–çš„å‹åŠ›æµ‹è¯•ï¼Œå‘ç°éšå–»(metaphors)ã€æƒ…æ„Ÿå’Œè§†è§‰çº¿ç´¢ç­‰åˆ›æ„ç‰¹å¾ä¼šå…ˆäºäº‹å®ä¿¡æ¯æ¶ˆå¤±ï¼Œè¡¨æ˜æ¨¡å‹æ›´åå¥½é«˜æ¦‚ç‡ä¿¡æ¯ã€‚åœ¨æ ¹æ®ç®€åŒ–å†…å®¹é‡æ–°ç”Ÿæˆæ—¶ï¼Œæ¨¡å‹è™½èƒ½æä¾›å…·æœ‰è¯æ±‡å¤šæ ·æ€§çš„é•¿æ–‡ï¼Œå´æ— æ³•æ¢å¤åŸå§‹åˆ›æ„çš„æ·±åº¦ä¸ç‹¬ç‰¹æ€§ã€‚å®šæ€§åˆ†ææ˜¾ç¤ºæ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬è™½çœ‹ä¼¼æ–°é¢–ï¼Œå®åˆ™ç¼ºä¹çœŸæ­£çš„åŸåˆ›æ€§ã€‚å®éªŒè¡¨æ˜ï¼Œæä¾›ç‰¹å®šçš„å¹¿å‘Šçº¿ç´¢(ad-specific cues)å¦‚éšå–»å’Œæƒ…æ„ŸæŒ‚é’©ï¼Œèƒ½æ”¹å–„ç”Ÿæˆçš„é£æ ¼å¹³è¡¡ï¼Œä½†è¾“å‡ºä»éš¾ä»¥å®Œå…¨æ‘†è„±å¸¸è§å¥—è·¯ã€‚è¯¥ç ”ç©¶æ­ç¤ºäº†LLMsåœ¨åˆ›æ„ä»»åŠ¡ä¸­å­˜åœ¨è‡ªå‘æ»‘å‘å¹³åº¸çš„è¶‹åŠ¿ï¼Œå¹¶æŒ‡å‡ºç»“æ„åŒ–ä¿¡å·æ˜¯å¼€å‘åˆ›æ„æ•æ„Ÿå‹æ¨¡å‹ã€å¯¹æŠ—è¿™ç§å›å½’ç°è±¡çš„é‡è¦è·¯å¾„ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25767v1",
      "published_date": "2025-09-30 04:29:41 UTC",
      "updated_date": "2025-09-30 04:29:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:44:59.705677+00:00"
    },
    {
      "arxiv_id": "2509.25760v1",
      "title": "TruthRL: Incentivizing Truthful LLMs via Reinforcement Learning",
      "title_zh": "TruthRLï¼šé€šè¿‡å¼ºåŒ–å­¦ä¹ æ¿€åŠ±å¤§è¯­è¨€æ¨¡å‹çš„çœŸå®æ€§",
      "authors": [
        "Zhepei Wei",
        "Xiao Yang",
        "Kai Sun",
        "Jiaqi Wang",
        "Rulin Shao",
        "Sean Chen",
        "Mohammad Kachuee",
        "Teja Gollapudi",
        "Tony Liao",
        "Nicolas Scheffer",
        "Rakesh Wanga",
        "Anuj Kumar",
        "Yu Meng",
        "Wen-tau Yih",
        "Xin Luna Dong"
      ],
      "abstract": "While large language models (LLMs) have demonstrated strong performance on factoid question answering, they are still prone to hallucination and untruthful responses, particularly when tasks demand information outside their parametric knowledge. Indeed, truthfulness requires more than accuracy -- models must also recognize uncertainty and abstain when unsure to avoid hallucinations. This presents a fundamental challenge for existing methods: approaches that optimize for accuracy often amplify hallucinations, while those that encourage abstention can become overly conservative, sacrificing correct answers. Both extremes ultimately compromise truthfulness. In this work, we present TruthRL, a general reinforcement learning (RL) framework that directly optimizes the truthfulness of LLMs. Specifically, we implement TruthRL using GRPO with a simple yet effective ternary reward that distinguishes correct answers, hallucinations, and abstentions. It incentivizes models to reduce hallucinations not only by providing correct responses, but also by enabling abstention when uncertain, thereby improving truthfulness. Extensive experiments across four knowledge-intensive benchmarks show that, compared to vanilla RL, TruthRL significantly reduces hallucinations by 28.9% and improves truthfulness by 21.1%, with consistent gains across various backbone models (e.g., Qwen, Llama) under both retrieval and non-retrieval setups. In-depth ablation study demonstrates that vanilla accuracy-driven methods, such as supervised fine-tuning or RL with a binary reward, struggle to balance factual correctness and uncertainty. In contrast, our proposed truthfulness-driven TruthRL achieves strong performance in both accuracy and truthfulness, underscoring the importance of learning objective design for developing truthful LLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† TruthRLï¼Œä¸€ä¸ªæ—¨åœ¨é€šè¿‡å¼ºåŒ–å­¦ä¹  (Reinforcement Learning) ç›´æ¥ä¼˜åŒ–å¤§è¯­è¨€æ¨¡å‹ (LLMs) çœŸå®æ€§çš„é€šç”¨æ¡†æ¶ã€‚é’ˆå¯¹ç°æœ‰æ¨¡å‹åœ¨å¤„ç†è¶…å‡ºå‚æ•°åŒ–çŸ¥è¯†çš„ä»»åŠ¡æ—¶å®¹æ˜“äº§ç”Ÿå¹»è§‰ (Hallucination) æˆ–ç”±äºè¿‡åº¦ä¿å®ˆè€Œç‰ºç‰²å‡†ç¡®æ€§çš„é—®é¢˜ï¼ŒTruthRL é‡‡ç”¨äº†åŸºäº GRPO çš„ä¸‰å…ƒå¥–åŠ±æœºåˆ¶ (Ternary Reward)ï¼Œç³»ç»Ÿæ€§åœ°åŒºåˆ†æ­£ç¡®å›ç­”ã€å¹»è§‰å’Œæ‹’ç»å›ç­” (Abstention)ã€‚è¯¥æ¡†æ¶ä¸ä»…æ¿€åŠ±æ¨¡å‹æä¾›äº‹å®æ­£ç¡®çš„å“åº”ï¼Œè¿˜å¼•å¯¼å…¶åœ¨ä¸ç¡®å®šæ—¶é€‰æ‹©æ‹’ç»å›ç­”ï¼Œä»è€Œåœ¨å‡†ç¡®æ€§ä¸è¯šå®åº¦ä¹‹é—´å–å¾—å¹³è¡¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒTruthRL åœ¨å¤šä¸ªçŸ¥è¯†å¯†é›†å‹åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—é™ä½äº† 28.9% çš„å¹»è§‰ï¼Œå¹¶å°†çœŸå®æ€§æå‡äº† 21.1%ã€‚åœ¨ Qwen å’Œ Llama ç­‰å¤šç§åŸºåº§æ¨¡å‹ä»¥åŠæ£€ç´¢å¢å¼ºåœºæ™¯ä¸‹ï¼Œè¯¥æ–¹æ³•å‡å±•ç°å‡ºä¸€è‡´çš„æ€§èƒ½å¢ç›Šï¼Œæœ‰åŠ›åœ°è¯æ˜äº†é’ˆå¯¹çœŸå®æ€§è®¾è®¡çš„å­¦ä¹ ç›®æ ‡åœ¨å¼€å‘å¯é æ¨¡å‹è¿‡ç¨‹ä¸­çš„å…³é”®ä½œç”¨ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25760v1",
      "published_date": "2025-09-30 04:25:17 UTC",
      "updated_date": "2025-09-30 04:25:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:45:03.374025+00:00"
    },
    {
      "arxiv_id": "2509.25758v1",
      "title": "Thinking Sparks!: Emergent Attention Heads in Reasoning Models During Post Training",
      "title_zh": "æ€ç»´ç«èŠ±ï¼ï¼šæ¨ç†æ¨¡å‹åœ¨åè®­ç»ƒè¿‡ç¨‹ä¸­æ¶Œç°çš„æ³¨æ„åŠ›å¤´",
      "authors": [
        "Yein Park",
        "Minbyul Jeong",
        "Jaewoo Kang"
      ],
      "abstract": "The remarkable capabilities of modern large reasoning models are largely unlocked through post-training techniques such as supervised fine-tuning and reinforcement learning. However, the architectural mechanisms behind such improvements remain largely opaque. In this work, we use circuit analysis to demonstrate that post-training for complex reasoning sparks the emergence of novel, functionally specialized attention heads. These heads collectively support structured reasoning and computation. Our comparative analysis across Qwen families and DeepSeek-distilled model reveals that these emergent heads evolve differently under different training regimes. Distillation and SFT foster a cumulative addition of stable reasoning heads. In contrast, group relative policy optimization operates in a dynamic search mode: relatively few attention heads are iteratively activated, evaluated, and pruned, with their survival closely tracking fluctuations in the task reward signal. Furthermore, we find that controllable think on/off models do not possess dedicated thinking heads. Instead, turning off explicit reasoning triggers a broader-but less efficient-set of compensatory heads. Through ablation and qualitative analyses, we connect these circuit-level dynamics to a crucial performance trade-off: strengthened heads enable sophisticated problem-solving strategies for difficult problems but can also introduce over-thinking failure modes, such as calculation errors or logical loops on simpler tasks. These findings connect circuit-level dynamics to macro-level performance, identifying an inherent tension where complex reasoning comes at the cost of elementary computations. More broadly, our work points to future directions for training policy design, emphasizing the need to balance the development of effective reasoning strategies with the assurance of reliable, flawless execution.",
      "tldr_zh": "è¯¥ç ”ç©¶é€šè¿‡ç”µè·¯åˆ†æ(circuit analysis)æ­ç¤ºäº†å¤§è¯­è¨€æ¨¡å‹åœ¨åæœŸè®­ç»ƒ(post-training)è¿‡ç¨‹ä¸­ä¼šæ¶Œç°å‡ºä¸“é—¨è´Ÿè´£æ¨ç†å’Œè®¡ç®—çš„æ³¨æ„åŠ›å¤´ã€‚å¯¹æ¯”åˆ†æå‘ç°ï¼Œæ¨¡å‹è’¸é¦å’Œç›‘ç£å¾®è°ƒ(SFT)å€¾å‘äºç¨³å®šåœ°ç´¯ç§¯æ¨ç†å¤´ï¼Œè€Œç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–(GRPO)åˆ™è¡¨ç°ä¸ºåŠ¨æ€æœç´¢æ¨¡å¼ï¼Œæ ¹æ®å¥–åŠ±ä¿¡å·è¿­ä»£å¼åœ°æ¿€æ´»æˆ–å‰ªæã€‚ç ”ç©¶è¿›ä¸€æ­¥æŒ‡å‡ºï¼Œå…·å¤‡æ€ç»´å¼€å…³åŠŸèƒ½çš„æ¨¡å‹å¹¶æœªå½¢æˆä¸“ç”¨çš„æ€è€ƒå¤´ï¼Œå…³é—­æ¨ç†ä¼šå¯¼è‡´ä½æ•ˆçš„è¡¥å¿æ€§å¤´éƒ¨ä»‹å…¥ã€‚å®éªŒå®šæ€§åˆ†æè¡¨æ˜ï¼Œå¼ºåŒ–çš„æ¨ç†å¤´è™½ç„¶èƒ½æå‡è§£å†³å¤æ‚é—®é¢˜çš„ç­–ç•¥æ°´å¹³ï¼Œä½†ä¹Ÿå¯èƒ½åœ¨ç®€å•ä»»åŠ¡ä¸­å¼•å‘è¿‡åº¦æ€è€ƒï¼Œäº§ç”Ÿè®¡ç®—é”™è¯¯æˆ–é€»è¾‘å¾ªç¯ç­‰æ•…éšœæ¨¡å¼ã€‚è¿™äº›å‘ç°æ­ç¤ºäº†å¤æ‚æ¨ç†èƒ½åŠ›ä¸åŸºç¡€è®¡ç®—å¯é æ€§ä¹‹é—´çš„å†…åœ¨å¼ åŠ›ï¼Œä¸ºå¹³è¡¡æ¨¡å‹æ¨ç†ç­–ç•¥ä¸æ‰§è¡Œç²¾åº¦æä¾›äº†é‡è¦çš„è®­ç»ƒç­–ç•¥æŒ‡å¯¼ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25758v1",
      "published_date": "2025-09-30 04:23:43 UTC",
      "updated_date": "2025-09-30 04:23:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:45:03.972738+00:00"
    },
    {
      "arxiv_id": "2509.25757v1",
      "title": "NePTune: A Neuro-Pythonic Framework for Tunable Compositional Reasoning on Vision-Language",
      "title_zh": "NePTuneï¼šä¸€ç§é¢å‘è§†è§‰-è¯­è¨€å¯è°ƒç»„åˆæ¨ç†çš„ç¥ç»-Pythonæ¡†æ¶",
      "authors": [
        "Danial Kamali",
        "Parisa Kordjamshidi"
      ],
      "abstract": "Modern Vision-Language Models (VLMs) have achieved impressive performance in various tasks, yet they often struggle with compositional reasoning, the ability to decompose and recombine concepts to solve novel problems. While neuro-symbolic approaches offer a promising direction, they are typically constrained by crisp logical execution or predefined predicates, which limit flexibility. In this work, we introduce NePTune, a neuro-symbolic framework that overcomes these limitations through a hybrid execution model that integrates the perception capabilities of foundation vision models with the compositional expressiveness of symbolic reasoning. NePTune dynamically translates natural language queries into executable Python programs that blend imperative control flow with soft logic operators capable of reasoning over VLM-generated uncertainty. Operating in a training-free manner, NePTune, with a modular design, decouples perception from reasoning, yet its differentiable operations support fine-tuning. We evaluate NePTune on multiple visual reasoning benchmarks and various domains, utilizing adversarial tests, and demonstrate a significant improvement over strong base models, as well as its effective compositional generalization and adaptation capabilities in novel environments.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»‹ç»äº† NePTuneï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨å…‹æœç°ä»£è§†è§‰è¯­è¨€æ¨¡å‹ (VLMs) åœ¨ç»„åˆæ¨ç† (Compositional Reasoning) èƒ½åŠ›ä¸Šå±€é™æ€§çš„ç¥ç»ç¬¦å· (Neuro-symbolic) æ¡†æ¶ã€‚NePTune é‡‡ç”¨æ··åˆæ‰§è¡Œæ¨¡å‹ï¼Œå°†åŸºç¡€è§†è§‰æ¨¡å‹çš„æ„ŸçŸ¥èƒ½åŠ›ä¸ç¬¦å·æ¨ç†çš„è¡¨è¾¾èƒ½åŠ›ç›¸ç»“åˆï¼Œèƒ½å¤ŸåŠ¨æ€åœ°å°†è‡ªç„¶è¯­è¨€æŸ¥è¯¢è½¬åŒ–ä¸ºå¯æ‰§è¡Œçš„ Python ç¨‹åºã€‚è¯¥æ¡†æ¶å°†å‘½ä»¤å¼æ§åˆ¶æµä¸è½¯é€»è¾‘ç®—å­ (Soft Logic Operators) èåˆï¼Œä½¿å…¶èƒ½å¤Ÿé’ˆå¯¹ VLM ç”Ÿæˆçš„ä¸ç¡®å®šæ€§è¿›è¡Œæ¨ç†ï¼Œæœ‰æ•ˆå…‹æœäº†ä¼ ç»Ÿç¥ç»ç¬¦å·æ–¹æ³•åœ¨é€»è¾‘æ‰§è¡Œä¸Šçš„åƒµåŒ–ã€‚NePTune å…·æœ‰æ¨¡å—åŒ–è®¾è®¡ï¼Œå®ç°äº†æ„ŸçŸ¥ä¸æ¨ç†çš„è§£è€¦ï¼Œä¸”æ”¯æŒåœ¨æ— éœ€è®­ç»ƒ (Training-free) çš„æ¨¡å¼ä¸‹è¿è¡Œï¼ŒåŒæ—¶å…¶å¯å¾®æ“ä½œä¹Ÿä¸ºå¾®è°ƒæä¾›äº†å¯èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒNePTune åœ¨å¤šä¸ªè§†è§‰æ¨ç†åŸºå‡†å’Œå¯¹æŠ—æ€§æµ‹è¯•ä¸­è¡¨ç°æ˜¾è‘—ä¼˜äºåŸºçº¿æ¨¡å‹ï¼Œè¯æ˜äº†å…¶å‡ºè‰²çš„ç»„åˆæ³›åŒ–èƒ½åŠ›å’Œåœ¨æ–°ç¯å¢ƒä¸­çš„é€‚åº”æ½œåŠ›ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.SC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25757v1",
      "published_date": "2025-09-30 04:22:42 UTC",
      "updated_date": "2025-09-30 04:22:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:45:16.597996+00:00"
    },
    {
      "arxiv_id": "2509.25751v1",
      "title": "Cooperative Autonomous Driving in Diverse Behavioral Traffic: A Heterogeneous Graph Reinforcement Learning Approach",
      "title_zh": "å¤šæ ·åŒ–è¡Œä¸ºäº¤é€šç¯å¢ƒä¸‹çš„ååŒè‡ªåŠ¨é©¾é©¶ï¼šä¸€ç§å¼‚æ„å›¾å¼ºåŒ–å­¦ä¹ æ–¹æ³•",
      "authors": [
        "Qi Liu",
        "Xueyuan Li",
        "Zirui Li",
        "Juhui Gim"
      ],
      "abstract": "Navigating heterogeneous traffic environments with diverse driving styles poses a significant challenge for autonomous vehicles (AVs) due to their inherent complexity and dynamic interactions. This paper addresses this challenge by proposing a heterogeneous graph reinforcement learning (GRL) framework enhanced with an expert system to improve AV decision-making performance. Initially, a heterogeneous graph representation is introduced to capture the intricate interactions among vehicles. Then, a heterogeneous graph neural network with an expert model (HGNN-EM) is proposed to effectively encode diverse vehicle features and produce driving instructions informed by domain-specific knowledge. Moreover, the double deep Q-learning (DDQN) algorithm is utilized to train the decision-making model. A case study on a typical four-way intersection, involving various driving styles of human vehicles (HVs), demonstrates that the proposed method has superior performance over several baselines regarding safety, efficiency, stability, and convergence rate, all while maintaining favorable real-time performance.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è‡ªåŠ¨é©¾é©¶æ±½è½¦åœ¨é¢å¯¹å¤šæ ·åŒ–é©¾é©¶é£æ ¼çš„å¤æ‚æ··åˆäº¤é€šç¯å¢ƒæ—¶æ‰€é¢ä¸´çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§å¢å¼ºäº†ä¸“å®¶ç³»ç»Ÿçš„å¼‚æ„å›¾å¼ºåŒ–å­¦ä¹  (Heterogeneous Graph Reinforcement Learning) æ¡†æ¶ã€‚é€šè¿‡å¼•å…¥å¼‚æ„å›¾è¡¨ç¤ºæ¥æ•æ‰è½¦è¾†é—´å¤æ‚çš„ç›¸äº’ä½œç”¨ï¼Œå¹¶å¼€å‘äº†ç»“åˆä¸“å®¶æ¨¡å‹çš„å¼‚æ„å›¾ç¥ç»ç½‘ç»œ (HGNN-EM)ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆç¼–ç å¤šæ ·çš„è½¦è¾†ç‰¹å¾å¹¶åˆ©ç”¨é¢†åŸŸçŸ¥è¯†ç”Ÿæˆé©¾é©¶æŒ‡ä»¤ã€‚ç ”ç©¶é‡‡ç”¨äº†åŒé‡æ·±åº¦Qå­¦ä¹  (Double Deep Q-Learning, DDQN) ç®—æ³•å¯¹å†³ç­–æ¨¡å‹è¿›è¡Œè®­ç»ƒã€‚é’ˆå¯¹å…¸å‹åå­—è·¯å£åœºæ™¯çš„æ¡ˆä¾‹ç ”ç©¶è¡¨æ˜ï¼Œåœ¨åŒ…å«å¤šç§äººç±»é©¾é©¶é£æ ¼ (Human Vehicles) çš„ç¯å¢ƒä¸­ï¼Œè¯¥æ–¹æ³•åœ¨å®‰å…¨æ€§ã€æ•ˆç‡ã€ç¨³å®šæ€§å’Œæ”¶æ•›é€Ÿåº¦æ–¹é¢å‡è¡¨ç°å‡ºä¼˜äºåŸºå‡†æ¨¡å‹çš„æ€§èƒ½ï¼ŒåŒæ—¶ä¿æŒäº†ä¼˜å¼‚çš„å®æ—¶å¤„ç†èƒ½åŠ›ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "7 pages, 5 figures and 4 tables",
      "pdf_url": "https://arxiv.org/pdf/2509.25751v1",
      "published_date": "2025-09-30 04:12:57 UTC",
      "updated_date": "2025-09-30 04:12:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:45:13.187666+00:00"
    },
    {
      "arxiv_id": "2509.25748v3",
      "title": "Dolphin v1.0 Technical Report",
      "title_zh": "Dolphin v1.0 æŠ€æœ¯æŠ¥å‘Š",
      "authors": [
        "Taohan Weng",
        "Kaibing Hu",
        "Henan Liu",
        "Siya Liu",
        "Xiaoyang Liu",
        "Zhenyu Liu",
        "Jiren Ren",
        "Boyan Wang",
        "Boyang Wang",
        "Yiyu Wang",
        "Yalun Wu",
        "Chaoran Yan",
        "Kaiwen Yan",
        "Jinze Yu",
        "Chi Zhang",
        "Duo Zhang",
        "Haoyun Zheng",
        "Xiaoqing Guo",
        "Jacques Souquet",
        "Hongcheng Guo",
        "Anjie Le"
      ],
      "abstract": "Ultrasound is crucial in modern medicine but faces challenges like operator dependence, image noise, and real-time scanning, hindering AI integration. While large multimodal models excel in other medical imaging areas, they struggle with ultrasound's complexities. To address this, we introduce Dolphin v1.0 (V1) and its reasoning-augmented version, Dolphin R1-the first large-scale multimodal ultrasound foundation models unifying diverse clinical tasks in a single vision-language framework.To tackle ultrasound variability and noise, we curated a 2-million-scale multimodal dataset, combining textbook knowledge, public data, synthetic samples, and general corpora. This ensures robust perception, generalization, and clinical adaptability.The Dolphin series employs a three-stage training strategy: domain-specialized pretraining, instruction-driven alignment, and reinforcement-based refinement. Dolphin v1.0 delivers reliable performance in classification, detection, regression, and report generation. Dolphin R1 enhances diagnostic inference, reasoning transparency, and interpretability through reinforcement learning with ultrasound-specific rewards.Evaluated on U2-Bench across eight ultrasound tasks, Dolphin R1 achieves a U2-score of 0.5835-over twice the second-best model (0.2968) setting a new state of the art. Dolphin v1.0 also performs competitively, validating the unified framework. Comparisons show reasoning-enhanced training significantly improves diagnostic accuracy, consistency, and interpretability, highlighting its importance for high-stakes medical AI.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† Dolphin v1.0 åŠå…¶æ¨ç†å¢å¼ºç‰ˆæœ¬ Dolphin R1ï¼Œè¿™æ˜¯é¦–æ‰¹åœ¨ç»Ÿä¸€è§†è§‰è¯­è¨€æ¡†æ¶ä¸‹æ•´åˆå¤šæ ·åŒ–ä¸´åºŠä»»åŠ¡çš„å¤§è§„æ¨¡å¤šæ¨¡æ€è¶…å£°åŸºåº§æ¨¡å‹ (Multimodal Ultrasound Foundation Models)ã€‚ä¸ºäº†è§£å†³è¶…å£°åŒ»å­¦ä¸­æ“ä½œå‘˜ä¾èµ–å’Œå›¾åƒå™ªå£°ç­‰æŒ‘æˆ˜ï¼Œç ”ç©¶å›¢é˜Ÿæ„å»ºäº†ä¸€ä¸ªåŒ…å« 200 ä¸‡è§„æ¨¡çš„å¤šæ¨¡æ€æ•°æ®é›†ï¼Œæ¶µç›–æ•™ç§‘ä¹¦çŸ¥è¯†ã€å…¬å…±æ•°æ®ä¸åˆæˆæ ·æœ¬ï¼Œç¡®ä¿äº†æ¨¡å‹çš„é²æ£’æ„ŸçŸ¥ä¸æ³›åŒ–èƒ½åŠ›ã€‚Dolphin ç³»åˆ—é‡‡ç”¨äº†ä¸‰é˜¶æ®µè®­ç»ƒç­–ç•¥ï¼Œå³é¢†åŸŸä¸“ä¸šåŒ–é¢„è®­ç»ƒ (Domain-specialized Pretraining)ã€æŒ‡ä»¤é©±åŠ¨å¯¹é½ (Instruction-driven Alignment) ä»¥åŠåŸºäºå¼ºåŒ–çš„ç»†åŒ– (Reinforcement-based Refinement)ã€‚å…¶ä¸­ Dolphin R1 é€šè¿‡é’ˆå¯¹è¶…å£°ä»»åŠ¡è®¾è®¡çš„å¥–åŠ±æœºåˆ¶è¿›è¡Œå¼ºåŒ–å­¦ä¹ ï¼Œæ˜¾è‘—æå‡äº†è¯Šæ–­æ¨ç†çš„é€æ˜åº¦ä¸å¯è§£é‡Šæ€§ (Interpretability)ã€‚åœ¨ U2-Bench çš„å…«é¡¹è¶…å£°ä»»åŠ¡è¯„ä¼°ä¸­ï¼ŒDolphin R1 å–å¾—äº† 0.5835 çš„ U2-scoreï¼Œè¶…è¿‡ç¬¬äºŒåæ¨¡å‹å¾—åˆ†çš„ä¸¤å€ï¼Œåˆ·æ–°äº†å½“å‰æŠ€æœ¯æ°´å¹³ (State of the Art)ã€‚å®éªŒç»“æœéªŒè¯äº†ç»Ÿä¸€æ¡†æ¶çš„æœ‰æ•ˆæ€§ï¼Œå¹¶å¼ºè°ƒäº†æ¨ç†å¢å¼ºè®­ç»ƒåœ¨æå‡åŒ»ç–— AI è¯Šæ–­å‡†ç¡®æ€§ä¸ä¸€è‡´æ€§æ–¹é¢çš„é‡è¦æ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25748v3",
      "published_date": "2025-09-30 04:08:45 UTC",
      "updated_date": "2025-10-19 03:35:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:45:29.783226+00:00"
    },
    {
      "arxiv_id": "2509.25736v1",
      "title": "Think Less, Label Better: Multi-Stage Domain-Grounded Synthetic Data Generation for Fine-Tuning Large Language Models in Telecommunications",
      "title_zh": "å‡è´Ÿå¢è´¨ï¼šé¢å‘ç”µä¿¡å¤§è¯­è¨€æ¨¡å‹å¾®è°ƒçš„å¤šé˜¶æ®µé¢†åŸŸçŸ¥è¯†å¢å¼ºåˆæˆæ•°æ®ç”Ÿæˆ",
      "authors": [
        "Chenhua Shi",
        "Gregor Macdonald",
        "Bhavika Jalli",
        "Wanlu Lei",
        "John Zou",
        "Mridul Jain",
        "Joji Philip"
      ],
      "abstract": "The success of large language models (LLMs) depends heavily on large-scale, high-quality instruction-following and reinforcement datasets. However, generating such data through human annotation is prohibitively time-consuming particularly for domain-specific tasks like telecom network troubleshooting, where accurate responses require deep technical expertise and contextual understanding. In this paper, we present a fully automated, retrieval-augmented pipeline for generating synthetic question-answer (QA) pairs grounded in structured domain knowledge. Our multi-stage framework integrates a retriever, base generator, and refinement model to synthesize and enhance QA pairs using documents retrieved from a domain-specific knowledge graph. To ensure data quality, we employ customized RAGAS-based scoring to filter low-quality samples, producing a high-quality dataset suitable for reinforcement fine-tuning (RFT). We demonstrate our approach in a real-world telecom scenario focused on radio access network (RAN) troubleshooting. The resulting pipeline generates complex, context-rich troubleshooting solution plans without human intervention. This work offers a scalable solution for building instruction and reinforcement datasets in specialized domains, significantly reducing dependence on manual labeling while maintaining high technical fidelity.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é’ˆå¯¹ç”µä¿¡ç½‘ç»œæ•…éšœæ’é™¤ç­‰é¢†åŸŸç‰¹å®šä»»åŠ¡ä¸­ï¼Œäººå·¥æ ‡æ³¨æ•°æ®é›†è€—æ—¶ä¸”ä¾èµ–æ·±åº¦ä¸“ä¸šæŠ€æœ¯çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§å¤šé˜¶æ®µé¢†åŸŸåŸºå‡†åˆæˆæ•°æ®ç”Ÿæˆæ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡å…¨è‡ªåŠ¨çš„æ£€ç´¢å¢å¼º(Retrieval-Augmented)æµæ°´çº¿ï¼Œæ•´åˆäº†æ£€ç´¢å™¨(Retriever)ã€åŸºç¡€ç”Ÿæˆå™¨(Base Generator)å’Œä¼˜åŒ–æ¨¡å‹(Refinement Model)ï¼Œä»ç»“æ„åŒ–çš„é¢†åŸŸçŸ¥è¯†å›¾è°±(Knowledge Graph)ä¸­ç”Ÿæˆä¸æ–‡æ¡£å…³è”çš„é—®ç­”å¯¹ã€‚ä¸ºäº†ä¿è¯æ•°æ®è´¨é‡ï¼Œç ”ç©¶é‡‡ç”¨äº†åŸºäºRAGASçš„å®šåˆ¶è¯„åˆ†æœºåˆ¶æ¥è¿‡æ»¤ä½è´¨é‡æ ·æœ¬ï¼Œä»è€Œç”Ÿäº§å‡ºé€‚ç”¨äºå¼ºåŒ–å¾®è°ƒ(Reinforcement Fine-Tuning, RFT)çš„é«˜è´¨é‡æ•°æ®é›†ã€‚ç ”ç©¶åœ¨æ— çº¿æ¥å…¥ç½‘(Radio Access Network, RAN)æ•…éšœæ’é™¤çš„çœŸå®ç”µä¿¡åœºæ™¯ä¸­å±•ç¤ºäº†è¯¥æ–¹æ³•ï¼ŒæˆåŠŸåœ¨æ— éœ€äººå·¥å¹²é¢„çš„æƒ…å†µä¸‹ç”Ÿæˆäº†å¤æ‚ä¸”å¯Œæœ‰è¯­å¢ƒçš„æ•…éšœè§£å†³è®¡åˆ’ã€‚è¯¥æ–¹æ¡ˆä¸ºæ„å»ºç‰¹å®šé¢†åŸŸçš„æŒ‡ä»¤å’Œå¼ºåŒ–æ•°æ®é›†æä¾›äº†ä¸€ç§å¯æ‰©å±•çš„è·¯å¾„ï¼Œåœ¨ä¿æŒé«˜æŠ€æœ¯å¿ å®åº¦çš„åŒæ—¶æ˜¾è‘—é™ä½äº†å¯¹æ‰‹åŠ¨æ ‡æ³¨çš„ä¾èµ–ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IT",
        "cs.NI"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages, 6 figures, 5 tables",
      "pdf_url": "https://arxiv.org/pdf/2509.25736v1",
      "published_date": "2025-09-30 03:49:57 UTC",
      "updated_date": "2025-09-30 03:49:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:45:34.385622+00:00"
    },
    {
      "arxiv_id": "2510.09636v1",
      "title": "Bias-Aware AI Chatbot for Engineering Advising at the University of Maryland A. James Clark School of Engineering",
      "title_zh": "é’ˆå¯¹ University of Maryland A. James Clark School of Engineering å·¥ç¨‹ä¸“ä¸šå’¨è¯¢çš„åè§æ„ŸçŸ¥ AI èŠå¤©æœºå™¨äºº",
      "authors": [
        "Prarthana P. Kartholy",
        "Thandi M. Labor",
        "Neil N. Panchal",
        "Sean H. Wang",
        "Hillary N. Owusu"
      ],
      "abstract": "Selecting a college major is a difficult decision for many incoming freshmen. Traditional academic advising is often hindered by long wait times, intimidating environments, and limited personalization. AI Chatbots present an opportunity to address these challenges. However, AI systems also have the potential to generate biased responses, prejudices related to race, gender, socioeconomic status, and disability. These biases risk turning away potential students and undermining reliability of AI systems. This study aims to develop a University of Maryland (UMD) A. James Clark School of Engineering Program-specific AI chatbot. Our research team analyzed and mitigated potential biases in the responses. Through testing the chatbot on diverse student queries, the responses are scored on metrics of accuracy, relevance, personalization, and bias presence. The results demonstrate that with careful prompt engineering and bias mitigation strategies, AI chatbots can provide high-quality, unbiased academic advising support, achieving mean scores of 9.76 for accuracy, 9.56 for relevance, and 9.60 for personalization with no stereotypical biases found in the sample data. However, due to the small sample size and limited timeframe, our AI model may not fully reflect the nuances of student queries in engineering academic advising. Regardless, these findings will inform best practices for building ethical AI systems in higher education, offering tools to complement traditional advising and address the inequities faced by many underrepresented and first-generation college students.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é©¬é‡Œå…°å¤§å­¦ A. James Clark å·¥ç¨‹å­¦é™¢å¼€å‘äº†ä¸€æ¬¾ Bias-Aware AI Chatbotï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿå­¦æœ¯å’¨è¯¢ä¸­ç­‰å¾…æ—¶é—´é•¿å’Œä¸ªæ€§åŒ–ä¸è¶³ç­‰æŒ‘æˆ˜ã€‚è¯¥é¡¹ç›®é‡ç‚¹åˆ†æå¹¶ç¼“è§£äº† AI ç³»ç»Ÿåœ¨ç§æ—ã€æ€§åˆ«ã€ç¤¾ä¼šç»æµåœ°ä½åŠæ®‹ç–¾ç­‰æ–¹é¢å¯èƒ½äº§ç”Ÿçš„åå·®(Bias)å’Œåè§ï¼Œä»¥æå‡ç³»ç»Ÿçš„å¯é æ€§ã€‚é€šè¿‡ç²¾ç»†çš„æç¤ºè¯å·¥ç¨‹(Prompt Engineering)å’Œåå·®ç¼“è§£ç­–ç•¥ï¼Œç ”ç©¶å›¢é˜Ÿåœ¨å¤šæ ·åŒ–çš„å­¦ç”Ÿå’¨è¯¢æ¡ˆä¾‹ä¸­å¯¹æœºå™¨äººçš„å‡†ç¡®æ€§(Accuracy)ã€ç›¸å…³æ€§(Relevance)å’Œä¸ªæ€§åŒ–(Personalization)è¿›è¡Œäº†è¯„ä¼°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥ç³»ç»Ÿåœ¨ä¸Šè¿°æŒ‡æ ‡çš„å¹³å‡å¾—åˆ†å‡è¶…è¿‡ 9.5 åˆ†ï¼Œä¸”åœ¨æ ·æœ¬æ•°æ®ä¸­æœªå‘ç°é™ˆè§„åè§(Stereotypical Biases)ã€‚å°½ç®¡å—é™äºæ ·æœ¬é‡ï¼Œè¿™äº›å‘ç°ä¸ºé«˜ç­‰æ•™è‚²é¢†åŸŸæ„å»ºä¼¦ç† AI (Ethical AI) ç³»ç»Ÿæä¾›äº†é‡è¦å‚è€ƒï¼Œæœ‰åŠ©äºé€šè¿‡æŠ€æœ¯æ‰‹æ®µå¼¥åˆæ¬ ä»£è¡¨ç¾¤ä½“(Underrepresented)å’Œç¬¬ä¸€ä»£å¤§å­¦ç”Ÿé¢ä¸´çš„æ•™è‚²ä¸å¹³ç­‰å·®è·ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.09636v1",
      "published_date": "2025-09-30 03:47:08 UTC",
      "updated_date": "2025-09-30 03:47:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:45:38.486413+00:00"
    },
    {
      "arxiv_id": "2509.25729v1",
      "title": "Controlled Generation for Private Synthetic Text",
      "title_zh": "éšç§ä¿æŠ¤åˆæˆæ–‡æœ¬çš„å¯æ§ç”Ÿæˆ",
      "authors": [
        "Zihao Zhao",
        "Anjalie Field"
      ],
      "abstract": "Text anonymization is essential for responsibly developing and deploying AI in high-stakes domains such as healthcare, social services, and law. In this work, we propose a novel methodology for privacy-preserving synthetic text generation that leverages the principles of de-identification and the Hiding In Plain Sight (HIPS) theory. Our approach introduces entity-aware control codes to guide controllable generation using either in-context learning (ICL) or prefix tuning. The ICL variant ensures privacy levels consistent with the underlying de-identification system, while the prefix tuning variant incorporates a custom masking strategy and loss function to support scalable, high-quality generation. Experiments on legal and clinical datasets demonstrate that our method achieves a strong balance between privacy protection and utility, offering a practical and effective solution for synthetic text generation in sensitive domains.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§ç”¨äºéšç§ä¿æŠ¤åˆæˆæ–‡æœ¬ç”Ÿæˆçš„åˆ›æ–°æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³åŒ»ç–—å’Œæ³•å¾‹ç­‰é«˜é£é™©é¢†åŸŸäººå·¥æ™ºèƒ½åº”ç”¨ä¸­çš„æ–‡æœ¬å»æ ‡è¯†åŒ–é—®é¢˜ã€‚è¯¥æ–¹æ³•ç»“åˆäº†å»æ ‡è¯†åŒ–(de-identification)åŸåˆ™ä¸â€œè—èº«äºæ˜å¤„â€(Hiding In Plain Sight, HIPS)ç†è®ºï¼Œå¹¶å¼•å…¥å®ä½“æ„ŸçŸ¥æ§åˆ¶ä»£ç (entity-aware control codes)æ¥å¼•å¯¼ç”Ÿæˆè¿‡ç¨‹ã€‚ç ”ç©¶é€šè¿‡ä¸Šä¸‹æ–‡å­¦ä¹ (in-context learning, ICL)å’Œå‰ç¼€å¾®è°ƒ(prefix tuning)ä¸¤ç§æ–¹å¼å®ç°ï¼Œå…¶ä¸­å‰ç¼€å¾®è°ƒç‰ˆæœ¬é‡‡ç”¨äº†è‡ªå®šä¹‰æ©ç ç­–ç•¥å’ŒæŸå¤±å‡½æ•°ä»¥å¹³è¡¡ç”Ÿæˆçš„è§„æ¨¡ä¸è´¨é‡ã€‚åœ¨æ³•å¾‹å’Œä¸´åºŠæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨éšç§ä¿æŠ¤ä¸æ•°æ®æ•ˆç”¨(utility)ä¹‹é—´å®ç°äº†å¼ºæœ‰åŠ›çš„å¹³è¡¡ã€‚è¿™ä¸€æ–¹æ¡ˆä¸ºæ•æ„Ÿé¢†åŸŸçš„åˆæˆæ–‡æœ¬ç”Ÿæˆæä¾›äº†å®ç”¨ä¸”é«˜æ•ˆçš„è§£å†³æ‰‹æ®µã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.25729v1",
      "published_date": "2025-09-30 03:38:36 UTC",
      "updated_date": "2025-09-30 03:38:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:45:41.183629+00:00"
    },
    {
      "arxiv_id": "2509.25727v1",
      "title": "Boundary-to-Region Supervision for Offline Safe Reinforcement Learning",
      "title_zh": "é¢å‘ç¦»çº¿å®‰å…¨å¼ºåŒ–å­¦ä¹ çš„è¾¹ç•Œåˆ°åŒºåŸŸç›‘ç£",
      "authors": [
        "Huikang Su",
        "Dengyun Peng",
        "Zifeng Zhuang",
        "YuHan Liu",
        "Qiguang Chen",
        "Donglin Wang",
        "Qinghe Liu"
      ],
      "abstract": "Offline safe reinforcement learning aims to learn policies that satisfy predefined safety constraints from static datasets. Existing sequence-model-based methods condition action generation on symmetric input tokens for return-to-go and cost-to-go, neglecting their intrinsic asymmetry: return-to-go (RTG) serves as a flexible performance target, while cost-to-go (CTG) should represent a rigid safety boundary. This symmetric conditioning leads to unreliable constraint satisfaction, especially when encountering out-of-distribution cost trajectories. To address this, we propose Boundary-to-Region (B2R), a framework that enables asymmetric conditioning through cost signal realignment . B2R redefines CTG as a boundary constraint under a fixed safety budget, unifying the cost distribution of all feasible trajectories while preserving reward structures. Combined with rotary positional embeddings , it enhances exploration within the safe region. Experimental results show that B2R satisfies safety constraints in 35 out of 38 safety-critical tasks while achieving superior reward performance over baseline methods. This work highlights the limitations of symmetric token conditioning and establishes a new theoretical and practical approach for applying sequence models to safe RL. Our code is available at https://github.com/HuikangSu/B2R.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç¦»çº¿å®‰å…¨å¼ºåŒ–å­¦ä¹ (Offline safe reinforcement learning)ä¸­ç°æœ‰åŸºäºåºåˆ—æ¨¡å‹(sequence-model-based)çš„æ–¹æ³•å¿½è§†å›æŠ¥(return-to-go, RTG)ä¸æˆæœ¬(cost-to-go, CTG)å†…åœ¨ä¸å¯¹ç§°æ€§çš„é—®é¢˜è¿›è¡Œäº†æ¢è®¨ã€‚ä½œè€…æŒ‡å‡ºï¼ŒRTGé€šå¸¸ä½œä¸ºçµæ´»çš„æ€§èƒ½ç›®æ ‡ï¼Œè€ŒCTGåº”å½“è¢«è§†ä¸ºä¸¥æ ¼çš„å®‰å…¨è¾¹ç•Œï¼Œç°æœ‰çš„å¯¹ç§°æ¡ä»¶åŒ–è¾“å…¥å¯¼è‡´æ¨¡å‹åœ¨é¢å¯¹åˆ†å¸ƒå¤–(out-of-distribution)æˆæœ¬è½¨è¿¹æ—¶çº¦æŸæ»¡è¶³ä¸å¯é ã€‚ä¸ºæ­¤ï¼Œè®ºæ–‡æå‡ºäº†Boundary-to-Region (B2R)æ¡†æ¶ï¼Œé€šè¿‡æˆæœ¬ä¿¡å·é‡å¯¹é½(cost signal realignment)å®ç°éå¯¹ç§°æ¡ä»¶åŒ–ã€‚B2Rå°†CTGé‡æ–°å®šä¹‰ä¸ºå›ºå®šå®‰å…¨é¢„ç®—ä¸‹çš„è¾¹ç•Œçº¦æŸï¼Œå¹¶ç»“åˆæ—‹è½¬ä½ç½®ç¼–ç (rotary positional embeddings)å¢å¼ºåœ¨å®‰å…¨åŒºåŸŸå†…çš„æ¢ç´¢ï¼Œä»è€Œåœ¨ç»Ÿä¸€è½¨è¿¹æˆæœ¬åˆ†å¸ƒçš„åŒæ—¶ä¿ç•™å¥–åŠ±ç»“æ„ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒB2Råœ¨38é¡¹å®‰å…¨å…³é”®ä»»åŠ¡ä¸­æˆåŠŸæ»¡è¶³äº†35é¡¹çº¦æŸï¼Œä¸”å¥–åŠ±æ€§èƒ½æ˜¾è‘—ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚è¯¥å·¥ä½œæ­ç¤ºäº†å¯¹ç§°æ ‡è®°æ¡ä»¶åŒ–çš„å±€é™æ€§ï¼Œå¹¶ä¸ºå°†åºåˆ—æ¨¡å‹åº”ç”¨äºå®‰å…¨å¼ºåŒ–å­¦ä¹ é¢†åŸŸå»ºç«‹äº†æ–°çš„ç†è®ºä¸å®è·µè·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.25727v1",
      "published_date": "2025-09-30 03:38:20 UTC",
      "updated_date": "2025-09-30 03:38:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:45:48.568537+00:00"
    },
    {
      "arxiv_id": "2509.25724v2",
      "title": "Towards A Universally Transferable Acceleration Method for Density Functional Theory",
      "title_zh": "è¿ˆå‘å¯†åº¦æ³›å‡½ç†è®ºçš„é€šç”¨å¯è¿ç§»åŠ é€Ÿæ–¹æ³•",
      "authors": [
        "Zhe Liu",
        "Yuyan Ni",
        "Zhichen Pu",
        "Qiming Sun",
        "Siyuan Liu",
        "Wen Yan"
      ],
      "abstract": "Recently, sophisticated deep learning-based approaches have been developed for generating efficient initial guesses to accelerate the convergence of density functional theory (DFT) calculations. While the actual initial guesses are often density matrices (DM), quantities that can convert into density matrices also qualify as alternative forms of initial guesses. Hence, existing works mostly rely on the prediction of the Hamiltonian matrix for obtaining high-quality initial guesses. However, the Hamiltonian matrix is both numerically difficult to predict and intrinsically non-transferable, hindering the application of such models in real scenarios. In light of this, we propose a method that constructs DFT initial guesses by predicting the electron density in a compact auxiliary basis representation using E(3)-equivariant neural networks. Trained on small molecules with up to 20 atoms, our model is able to achieve an average 33.3% self-consistent field (SCF) step reduction on systems up to 60 atoms, substantially outperforming Hamiltonian-centric and DM-centric models. Critically, this acceleration remains nearly constant with increasing system sizes and exhibits strong transferring behaviors across orbital basis sets and exchange-correlation (XC) functionals. To the best of our knowledge, this work represents the first and robust candidate for a universally transferable DFT acceleration method. We are also releasing the SCFbench dataset and its accompanying code to facilitate future research in this promising direction.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¯†åº¦æ³›å‡½ç†è®º(DFT)è®¡ç®—ä¸­åˆå§‹çŒœæƒ³ç”Ÿæˆæ–¹æ³•å­˜åœ¨çš„æ•°å€¼é¢„æµ‹éš¾å’Œä¸å…·æœ‰å¯è¿ç§»æ€§(non-transferable)ç­‰é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åˆ©ç”¨E(3)-equivariant neural networksåœ¨ç´§å‡‘è¾…åŠ©åŸº(auxiliary basis)è¡¨ç¤ºä¸‹é¢„æµ‹ç”µå­å¯†åº¦(electron density)çš„æ–¹æ³•ã€‚è¯¥æ¨¡å‹ä»…åœ¨åŒ…å«æœ€å¤š20ä¸ªåŸå­çš„æœ‰æœºå°åˆ†å­ä¸Šè®­ç»ƒï¼Œå³å¯åœ¨å¤šè¾¾60ä¸ªåŸå­çš„ç³»ç»Ÿä¸Šå®ç°å¹³å‡33.3%çš„è‡ªæ´½åœº(SCF)è¿­ä»£æ­¥æ•°å‡å°‘ï¼Œæ€§èƒ½æ˜¾è‘—ä¼˜äºä»¥Hamiltonianæˆ–å¯†åº¦çŸ©é˜µ(DM)ä¸ºä¸­å¿ƒçš„ä¼ ç»Ÿæ¨¡å‹ã€‚é‡è¦çš„æ˜¯ï¼Œè¿™ç§åŠ é€Ÿæ•ˆæœä¸éšç³»ç»Ÿè§„æ¨¡å¢å¤§è€Œå‡å¼±ï¼Œä¸”åœ¨ä¸åŒçš„è½¨é“åŸºç»„(orbital basis sets)å’Œäº¤æ¢ç›¸å…³(XC)æ³›å‡½ä¹‹é—´è¡¨ç°å‡ºå¼ºå¤§çš„è¿ç§»èƒ½åŠ›ã€‚è¯¥ç ”ç©¶ä½œä¸ºé¦–ä¸ªé²æ£’ä¸”æ™®é€‚å¯è¿ç§»çš„DFTåŠ é€Ÿæ–¹æ¡ˆï¼Œä¸ºé‡å­åŒ–å­¦è®¡ç®—çš„æ•ˆç‡æå‡æä¾›äº†æ–°è·¯å¾„ï¼Œå¹¶åŒæ­¥å‘å¸ƒäº†SCFbenchæ•°æ®é›†åŠç›¸å…³ä»£ç ã€‚",
      "categories": [
        "physics.chem-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "physics.chem-ph",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25724v2",
      "published_date": "2025-09-30 03:35:57 UTC",
      "updated_date": "2025-10-15 02:15:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:45:44.269729+00:00"
    },
    {
      "arxiv_id": "2509.25721v6",
      "title": "The AI Productivity Index (APEX)",
      "title_zh": "äººå·¥æ™ºèƒ½ç”Ÿäº§åŠ›æŒ‡æ•° (APEX)",
      "authors": [
        "Bertie Vidgen",
        "Abby Fennelly",
        "Evan Pinnix",
        "Julien Benchek",
        "Daniyal Khan",
        "Zach Richards",
        "Austin Bridges",
        "Calix Huang",
        "Kanishka Sahu",
        "Abhishek Kottamasu",
        "Bo Ma",
        "Ben Hunsberger",
        "Isaac Robinson",
        "Akul Datta",
        "Chirag Mahapatra",
        "Dominic Barton",
        "Cass R. Sunstein",
        "Eric Topol",
        "Brendan Foody",
        "Osvald Nitski"
      ],
      "abstract": "We present an extended version of the AI Productivity Index (APEX-v1-extended), a benchmark for assessing whether frontier models are capable of performing economically valuable tasks in four jobs: investment banking associate, management consultant, big law associate, and primary care physician (MD). This technical report details the extensions to APEX-v1, including an increase in the held-out evaluation set from n = 50 to n = 100 cases per job (n = 400 total) and updates to the grading methodology. We present a new leaderboard, where GPT5 (Thinking = High) remains the top performing model with a score of 67.0%. APEX-v1-extended shows that frontier models still have substantial limitations when performing typical professional tasks. To support further research, we are open sourcing n = 25 non-benchmark example cases per role (n = 100 total) along with our evaluation harness.",
      "tldr_zh": "è¯¥ç ”ç©¶å‘å¸ƒäº†AI Productivity Index (APEX-v1-extended)ï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºè¯„ä¼°å‰æ²¿æ¨¡å‹åœ¨æŠ•èµ„é“¶è¡Œåˆ†æå¸ˆ(investment banking associate)ã€ç®¡ç†é¡¾é—®(management consultant)ã€èµ„æ·±å¾‹å¸ˆ(big law associate)åŠåˆçº§ä¿å¥åŒ»ç”Ÿ(MD)è¿™å››ç±»é«˜ç»æµä»·å€¼èŒä¸šä¸­ä»»åŠ¡è¡¨ç°çš„åŸºå‡†æµ‹è¯•ã€‚è¯¥æ‰©å±•ç‰ˆæœ¬å°†æ¯ä¸ªèŒä¸šçš„ä¿ç•™è¯„ä¼°é›†ä»50ä¸ªæ¡ˆä¾‹å¢åŠ è‡³100ä¸ªï¼ˆæ€»è®¡400ä¸ªæ¡ˆä¾‹ï¼‰ï¼Œå¹¶å¯¹è¯„åˆ†æ–¹æ³•è¿›è¡Œäº†ä¼˜åŒ–æ›´æ–°ã€‚æœ€æ–°çš„æ’è¡Œæ¦œæ˜¾ç¤ºï¼ŒGPT5 (Thinking = High) ä»¥67.0%çš„åˆ†æ•°ç¨³å±…æ¦œé¦–ï¼Œæˆä¸ºå½“å‰è¡¨ç°æœ€ä½³çš„æ¨¡å‹ã€‚å°½ç®¡å¦‚æ­¤ï¼ŒAPEX-v1-extended çš„æµ‹è¯•ç»“æœè¡¨æ˜ï¼Œå‰æ²¿æ¨¡å‹åœ¨æ‰§è¡Œå…¸å‹çš„ä¸“ä¸šä»»åŠ¡æ—¶ä»ç„¶å­˜åœ¨æ˜æ˜¾çš„å±€é™æ€§ã€‚ä¸ºäº†æ”¯æŒåç»­ç ”ç©¶ï¼Œè¯¥é¡¹ç›®å¼€æºäº†æ¯ä¸ªèŒä½25ä¸ªéåŸºå‡†ç¤ºä¾‹æ¡ˆä¾‹ä»¥åŠç›¸åº”çš„è¯„ä¼°æ¡†æ¶(evaluation harness)ã€‚",
      "categories": [
        "econ.GN",
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "econ.GN",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25721v6",
      "published_date": "2025-09-30 03:26:17 UTC",
      "updated_date": "2025-12-16 22:25:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:45:47.669671+00:00"
    },
    {
      "arxiv_id": "2509.25716v1",
      "title": "DeepCodeSeek: Real-Time API Retrieval for Context-Aware Code Generation",
      "title_zh": "DeepCodeSeekï¼šé¢å‘ä¸Šä¸‹æ–‡æ„ŸçŸ¥ä»£ç ç”Ÿæˆçš„å®æ—¶ API æ£€ç´¢",
      "authors": [
        "Esakkivel Esakkiraja",
        "Denis Akhiyarov",
        "Aditya Shanmugham",
        "Chitra Ganapathy"
      ],
      "abstract": "Current search techniques are limited to standard RAG query-document applications. In this paper, we propose a novel technique to expand the code and index for predicting the required APIs, directly enabling high-quality, end-to-end code generation for auto-completion and agentic AI applications. We address the problem of API leaks in current code-to-code benchmark datasets by introducing a new dataset built from real-world ServiceNow Script Includes that capture the challenge of unclear API usage intent in the code. Our evaluation metrics show that this method achieves 87.86% top-40 retrieval accuracy, allowing the critical context with APIs needed for successful downstream code generation. To enable real-time predictions, we develop a comprehensive post-training pipeline that optimizes a compact 0.6B reranker through synthetic dataset generation, supervised fine-tuning, and reinforcement learning. This approach enables our compact reranker to outperform a much larger 8B model while maintaining 2.5x reduced latency, effectively addressing the nuances of enterprise-specific code without the computational overhead of larger models.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†DeepCodeSeekï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºä¸Šä¸‹æ–‡æ„ŸçŸ¥ä»£ç ç”Ÿæˆçš„å®æ—¶APIæ£€ç´¢æŠ€æœ¯ï¼Œæ—¨åœ¨è§£å†³æ ‡å‡†æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)åœ¨ä»£ç è‡ªåŠ¨è¡¥å…¨å’Œæ™ºèƒ½ä½“AI(agentic AI)åº”ç”¨ä¸­çš„å±€é™æ€§ã€‚è¯¥æ–¹æ³•é€šè¿‡æ‰©å±•ä»£ç å’Œç´¢å¼•æ¥ç²¾ç¡®é¢„æµ‹æ‰€éœ€çš„APIsï¼Œå¹¶å¼•å…¥äº†åŸºäºServiceNow Script Includesæ„å»ºçš„æ–°æ•°æ®é›†ï¼Œä»¥åº”å¯¹ç°å®ä¸–ç•Œä¸­APIä½¿ç”¨æ„å›¾ä¸æ˜ç¡®åŠåŸºå‡†æµ‹è¯•æ•°æ®æ³„éœ²çš„é—®é¢˜ã€‚ä¸ºäº†å®ç°é«˜æ•ˆçš„å®æ—¶é¢„æµ‹ï¼Œç ”ç©¶å›¢é˜Ÿå¼€å‘äº†ä¸€å¥—ç»“åˆåˆæˆæ•°æ®ç”Ÿæˆã€ç›‘ç£å¾®è°ƒ(SFT)å’Œå¼ºåŒ–å­¦ä¹ (RL)çš„åè®­ç»ƒæµç¨‹ï¼Œä¸“é—¨ä¼˜åŒ–äº†ä¸€ä¸ª0.6Bå‚æ•°çš„ç´§å‡‘å‹é‡æ’åºå™¨(reranker)ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥ç³»ç»Ÿè¾¾åˆ°äº†87.86%çš„top-40æ£€ç´¢å‡†ç¡®ç‡ï¼Œä¸ºä¸‹æ¸¸ç”Ÿæˆä»»åŠ¡æä¾›äº†å¿…è¦çš„ä¸Šä¸‹æ–‡æ”¯æŒã€‚æµ‹è¯•ç»“æœæ˜¾ç¤ºï¼Œè¿™ç§å°å‹0.6Bæ¨¡å‹çš„æ€§èƒ½ä¼˜äº8Bæ¨¡å‹ï¼Œä¸”å»¶è¿Ÿé™ä½äº†2.5å€ï¼Œè¯æ˜äº†å…¶åœ¨ä¸å¢åŠ è®¡ç®—è´Ÿæ‹…çš„æƒ…å†µä¸‹å¤„ç†ä¼ä¸šçº§å¤æ‚ä»£ç çš„å“è¶Šèƒ½åŠ›ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.SE",
      "comment": "Retrieval-Augmented Generation, API Prediction, Context-Aware Code Generation, Enterprise Code Completion, Reinforcement Learning, ServiceNow, Real-Time Code Search, Query Enhancement, Fine-Tuning, Embedding, Reranker",
      "pdf_url": "https://arxiv.org/pdf/2509.25716v1",
      "published_date": "2025-09-30 03:23:27 UTC",
      "updated_date": "2025-09-30 03:23:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:45:56.687770+00:00"
    },
    {
      "arxiv_id": "2510.05122v1",
      "title": "CARE: Cognitive-reasoning Augmented Reinforcement for Emotional Support Conversation",
      "title_zh": "CAREï¼šé¢å‘æƒ…æ„Ÿæ”¯æŒå¯¹è¯çš„è®¤çŸ¥æ¨ç†å¢å¼ºå‹å¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Jie Zhu",
        "Yuanchen Zhou",
        "Shuo Jiang",
        "Junhui Li",
        "Lifan Guo",
        "Feng Chen",
        "Chi Zhang",
        "Fang Kong"
      ],
      "abstract": "Emotional Support Conversation (ESC) plays a vital role in alleviating psychological stress and providing emotional value through dialogue. While recent studies have largely focused on data augmentation and synthetic corpus construction, they often overlook the deeper cognitive reasoning processes that underpin effective emotional support. To address this gap, we propose \\textbf{CARE}, a novel framework that strengthens reasoning in ESC without relying on large-scale synthetic data. CARE leverages the original ESC training set to guide models in generating logically coherent and supportive responses, thereby explicitly enhancing cognitive reasoning. Building on this foundation, we further employ reinforcement learning to refine and reinforce the reasoning process. Experimental results demonstrate that CARE significantly improves both the logical soundness and supportive quality of responses, advancing the development of empathetic, cognitively robust, and human-like emotional support systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†CAREï¼Œä¸€ä¸ªæ—¨åœ¨å¢å¼ºæƒ…æ„Ÿæ”¯æŒå¯¹è¯(Emotional Support Conversation)ä¸­è®¤çŸ¥æ¨ç†èƒ½åŠ›çš„åˆ›æ–°æ¡†æ¶ã€‚é’ˆå¯¹ä»¥å¾€ç ”ç©¶è¿‡åº¦ä¾èµ–å¤§è§„æ¨¡åˆæˆæ•°æ®è€Œå¿½è§†æ·±å±‚è®¤çŸ¥æ¨ç†(Cognitive Reasoning)è¿‡ç¨‹çš„é—®é¢˜ï¼ŒCAREåˆ©ç”¨åŸå§‹ESCè®­ç»ƒé›†å¼•å¯¼æ¨¡å‹ç”Ÿæˆé€»è¾‘è¿è´¯ä¸”å…·æœ‰æ”¯æŒæ€§çš„å›å¤ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œè¯¥æ¡†æ¶è¿›ä¸€æ­¥é‡‡ç”¨å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)æŠ€æœ¯æ¥ç²¾ç‚¼å¹¶å·©å›ºæ¨ç†è¿‡ç¨‹ï¼Œç¡®ä¿ç”Ÿæˆå†…å®¹çš„é€»è¾‘æ€§ä¸åŒç†å¿ƒã€‚å®éªŒç»“æœè¯æ˜ï¼ŒCAREæ˜¾è‘—æå‡äº†å›å¤çš„é€»è¾‘åˆç†æ€§å’Œæ”¯æŒè´¨é‡ã€‚è¯¥ç ”ç©¶ä¸ºå¼€å‘æ›´å…·è®¤çŸ¥ç¨³å¥æ€§å’Œç±»äººåŒ–ç‰¹å¾çš„æƒ…æ„Ÿæ”¯æŒç³»ç»Ÿæä¾›äº†æ–°çš„è·¯å¾„ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint",
      "pdf_url": "https://arxiv.org/pdf/2510.05122v1",
      "published_date": "2025-09-30 03:19:50 UTC",
      "updated_date": "2025-09-30 03:19:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:46:00.885452+00:00"
    },
    {
      "arxiv_id": "2509.25694v2",
      "title": "HNote: Extending YNote with Hexadecimal Encoding for Fine-Tuning LLMs in Music Modeling",
      "title_zh": "HNoteï¼šé€šè¿‡åå…­è¿›åˆ¶ç¼–ç æ‰©å±• YNoteï¼Œç”¨äºéŸ³ä¹å»ºæ¨¡ä¸­çš„å¤§è¯­è¨€æ¨¡å‹å¾®è°ƒ",
      "authors": [
        "Hung-Ying Chu",
        "Shao-Yu Wei",
        "Guan-Wei Chen",
        "Tzu-Wei Hung",
        "ChengYang Tsai",
        "Yu-Cheng Lin"
      ],
      "abstract": "Recent advances in large language models (LLMs) have created new opportunities for symbolic music generation. However, existing formats such as MIDI, ABC, and MusicXML are either overly complex or structurally inconsistent, limiting their suitability for token-based learning architectures. To address these challenges, we propose HNote, a novel hexadecimal-based notation system extended from YNote, which encodes both pitch and duration within a fixed 32-unit measure framework. This design ensures alignment, reduces ambiguity, and is directly compatible with LLM architectures. We converted 12,300 Jiangnan-style songs generated from traditional folk pieces from YNote into HNote, and fine-tuned LLaMA-3.1(8B) using parameter-efficient LoRA. Experimental results show that HNote achieves a syntactic correctness rate of 82.5%, and BLEU and ROUGE evaluations demonstrate strong symbolic and structural similarity, producing stylistically coherent compositions. This study establishes HNote as an effective framework for integrating LLMs with cultural music modeling.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† HNoteï¼Œè¿™æ˜¯ä¸€ç§åŸºäºåå…­è¿›åˆ¶ç¼–ç çš„æ–°å‹è®°è°±ç³»ç»Ÿï¼Œæ—¨åœ¨è§£å†³ MIDIã€ABC å’Œ MusicXML ç­‰ä¼ ç»Ÿç¬¦å·éŸ³ä¹æ ¼å¼åœ¨å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)ä¸­å­˜åœ¨çš„å¤æ‚æ€§é«˜å’Œç»“æ„ä¸ä¸€è‡´ç­‰æŒ‘æˆ˜ã€‚ä½œä¸º YNote çš„æ‰©å±•ï¼ŒHNote åœ¨å›ºå®šçš„ 32 å•ä½å°èŠ‚æ¡†æ¶å†…å¯¹éŸ³é«˜(pitch)å’Œæ—¶å€¼(duration)è¿›è¡Œç¼–ç ï¼Œé€šè¿‡è¿™ç§è®¾è®¡ç¡®ä¿äº†æ•°æ®å¯¹é½å¹¶å‡å°‘æ­§ä¹‰ï¼Œä½¿å…¶ç›´æ¥å…¼å®¹äºåŸºäºä»¤ç‰Œ(token-based)çš„å­¦ä¹ æ¶æ„ã€‚ç ”ç©¶äººå‘˜å°† 12,300 é¦–æ±Ÿå—é£æ ¼æ­Œæ›²è½¬åŒ–ä¸º HNote æ ¼å¼ï¼Œå¹¶é‡‡ç”¨å‚æ•°é«˜æ•ˆçš„ LoRA æŠ€æœ¯å¯¹ LLaMA-3.1(8B) æ¨¡å‹è¿›è¡Œäº†å¾®è°ƒã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒHNote è¾¾åˆ°äº† 82.5% çš„è¯­æ³•æ­£ç¡®ç‡ï¼Œä¸”åœ¨ BLEU å’Œ ROUGE è¯„ä¼°ä¸­å±•ç°å‡ºæå¼ºçš„ç¬¦å·ä¸ç»“æ„ç›¸ä¼¼æ€§ï¼Œèƒ½å¤Ÿç”Ÿæˆé£æ ¼è¿è´¯çš„éŸ³ä¹ä½œå“ã€‚æœ¬ç ”ç©¶ç¡®ç«‹äº† HNote ä½œä¸ºå¤§å‹è¯­è¨€æ¨¡å‹ä¸æ–‡åŒ–éŸ³ä¹å»ºæ¨¡ç›¸ç»“åˆçš„æœ‰æ•ˆæ¡†æ¶ï¼Œä¸ºè®¡ç®—æœºéŸ³ä¹ç”Ÿæˆé¢†åŸŸæä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25694v2",
      "published_date": "2025-09-30 02:50:01 UTC",
      "updated_date": "2025-10-04 07:52:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:46:00.600540+00:00"
    },
    {
      "arxiv_id": "2510.00080v2",
      "title": "SoREX: Towards Self-Explainable Social Recommendation with Relevant Ego-Path Extraction",
      "title_zh": "SoREXï¼šåŸºäºç›¸å…³ Ego è·¯å¾„æå–çš„è‡ªè§£é‡Šç¤¾äº¤æ¨è",
      "authors": [
        "Hanze Guo",
        "Yijun Ma",
        "Xiao Zhou"
      ],
      "abstract": "Social recommendation has been proven effective in addressing data sparsity in user-item interaction modeling by leveraging social networks. The recent integration of Graph Neural Networks (GNNs) has further enhanced prediction accuracy in contemporary social recommendation algorithms. However, many GNN-based approaches in social recommendation lack the ability to furnish meaningful explanations for their predictions. In this study, we confront this challenge by introducing SoREX, a self-explanatory GNN-based social recommendation framework. SoREX adopts a two-tower framework enhanced by friend recommendation, independently modeling social relations and user-item interactions, while jointly optimizing an auxiliary task to reinforce social signals. To offer explanations, we propose a novel ego-path extraction approach. This method involves transforming the ego-net of a target user into a collection of multi-hop ego-paths, from which we extract factor-specific and candidate-aware ego-path subsets as explanations. This process facilitates the summarization of detailed comparative explanations among different candidate items through intricate substructure analysis. Furthermore, we conduct explanation re-aggregation to explicitly correlate explanations with downstream predictions, imbuing our framework with inherent self-explainability. Comprehensive experiments conducted on four widely adopted benchmark datasets validate the effectiveness of SoREX in predictive accuracy. Additionally, qualitative and quantitative analyses confirm the efficacy of the extracted explanations in SoREX. Our code and data are available at https://github.com/antman9914/SoREX.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç¤¾äº¤æ¨èä¸­å›¾ç¥ç»ç½‘ç»œ(GNN)æ¨¡å‹ç¼ºä¹å¯è§£é‡Šæ€§çš„é—®é¢˜ï¼Œæå‡ºäº†SoREXè¿™ä¸€è‡ªè§£é‡Šæ¨èæ¡†æ¶ã€‚SoREXé‡‡ç”¨å¢å¼ºäº†æœ‹å‹æ¨èçš„åŒå¡”æ¡†æ¶(two-tower framework)ï¼Œåœ¨ç‹¬ç«‹å»ºæ¨¡ç¤¾äº¤å…³ç³»ä¸ç”¨æˆ·-ç‰©å“äº¤äº’çš„åŒæ—¶ï¼Œé€šè¿‡è”åˆä¼˜åŒ–è¾…åŠ©ä»»åŠ¡æ¥å¼ºåŒ–ç¤¾äº¤ä¿¡å·ã€‚ä¸ºäº†æä¾›è§£é‡Šï¼Œç ”ç©¶è€…è®¾è®¡äº†ä¸€ç§æ–°é¢–çš„è‡ªæˆ‘è·¯å¾„æå–(ego-path extraction)æ–¹æ³•ï¼Œå°†ç”¨æˆ·çš„è‡ªæˆ‘ç½‘ç»œ(ego-net)è½¬åŒ–ä¸ºå¤šè·³è·¯å¾„é›†åˆï¼Œå¹¶æå–ç‰¹å®šå› å­ä¸”å€™é€‰æ„ŸçŸ¥(candidate-aware)çš„å­é›†ã€‚é€šè¿‡å¤æ‚çš„å­ç»“æ„åˆ†æï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ€»ç»“å‡ºä¸åŒå€™é€‰ç‰©å“ä¹‹é—´çš„è¯¦ç»†å¯¹æ¯”è§£é‡Šï¼Œå¹¶é€šè¿‡è§£é‡Šé‡èšåˆ(explanation re-aggregation)å°†è§£é‡Šä¸ä¸‹æ¸¸é¢„æµ‹æ˜¾å¼å…³è”ã€‚åœ¨å››ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒSoREXä¸ä»…åœ¨é¢„æµ‹å‡†ç¡®ç‡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œå…¶ç”Ÿæˆçš„è§£é‡Šä¹Ÿé€šè¿‡äº†å®šæ€§å’Œå®šé‡çš„æœ‰æ•ˆæ€§éªŒè¯ã€‚",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "ACM Transactions on Information Systems (TOIS), 2025. Online AM: 17 Nov 2025. DOI: 10.1145/3777374. Code: https://github.com/antman9914/SoREX",
      "pdf_url": "https://arxiv.org/pdf/2510.00080v2",
      "published_date": "2025-09-30 02:49:54 UTC",
      "updated_date": "2025-12-05 01:42:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:46:23.192842+00:00"
    },
    {
      "arxiv_id": "2509.25693v2",
      "title": "ScheduleMe: Multi-Agent Calendar Assistant",
      "title_zh": "ScheduleMeï¼šå¤šæ™ºèƒ½ä½“æ—¥å†åŠ©æ‰‹",
      "authors": [
        "Oshadha Wijerathne",
        "Amandi Nimasha",
        "Dushan Fernando",
        "Nisansa de Silva",
        "Srinath Perera"
      ],
      "abstract": "Recent advancements in LLMs have contributed to the rise of advanced conversational assistants that can assist with user needs through natural language conversation. This paper presents a ScheduleMe, a multi-agent calendar assistant for users to manage google calendar events in natural language. The system uses a graph-structured coordination mechanism where a central supervisory agent supervises specialized task agents, allowing modularity, conflicts resolution, and context-aware interactions to resolve ambiguities and evaluate user commands. This approach sets an example of how structured reasoning and agent cooperation might convince operators to increase the usability and flexibility of personal calendar assistant tools.",
      "tldr_zh": "è¯¥ç ”ç©¶å±•ç¤ºäº† ScheduleMeï¼Œä¸€ä¸ªæ—¨åœ¨å¸®åŠ©ç”¨æˆ·é€šè¿‡è‡ªç„¶è¯­è¨€ç®¡ç† Google Calendar äº‹ä»¶çš„å¤šæ™ºèƒ½ä½“æ—¥å†åŠ©æ‰‹ã€‚ç³»ç»Ÿé‡‡ç”¨äº†ä¸€ç§å›¾ç»“æ„åè°ƒæœºåˆ¶(graph-structured coordination mechanism)ï¼Œé€šè¿‡ä¸­å¤®ç›‘ç£æ™ºèƒ½ä½“(central supervisory agent)ç®¡ç†å¤šä¸ªä¸“é—¨çš„ä»»åŠ¡æ™ºèƒ½ä½“ï¼Œä»è€Œå®ç°äº†é«˜åº¦çš„æ¨¡å—åŒ–ã€‚è¯¥æ¶æ„æ”¯æŒæœ‰æ•ˆçš„å†²çªè§£å†³(conflicts resolution)å’Œä¸Šä¸‹æ–‡æ„ŸçŸ¥äº¤äº’ï¼Œèƒ½å¤Ÿå‡†ç¡®è¯†åˆ«å¹¶æ¶ˆé™¤ç”¨æˆ·æŒ‡ä»¤ä¸­çš„æ­§ä¹‰ã€‚é€šè¿‡ç»“åˆç»“æ„åŒ–æ¨ç†(structured reasoning)ä¸æ™ºèƒ½ä½“åä½œï¼ŒScheduleMe æ˜¾è‘—å¢å¼ºäº†ä¸ªäººæ—¥ç¨‹ç®¡ç†å·¥å…·çš„å¯ç”¨æ€§å’Œçµæ´»æ€§ã€‚è¿™é¡¹å·¥ä½œä¸ºæå‡å¯¹è¯å¼åŠ©æ‰‹åœ¨å¤æ‚ä»»åŠ¡å¤„ç†ä¸­çš„è¡¨ç°æä¾›äº†æ–°çš„èŒƒä¾‹ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25693v2",
      "published_date": "2025-09-30 02:47:54 UTC",
      "updated_date": "2025-10-01 03:03:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:46:27.690309+00:00"
    },
    {
      "arxiv_id": "2509.25692v1",
      "title": "Annotation-Efficient Active Test-Time Adaptation with Conformal Prediction",
      "title_zh": "åŸºäºç¬¦åˆé¢„æµ‹çš„æ ‡æ³¨é«˜æ•ˆä¸»åŠ¨æµ‹è¯•æ—¶è‡ªé€‚åº”",
      "authors": [
        "Tingyu Shi",
        "Fan Lyu",
        "Shaoliang Peng"
      ],
      "abstract": "Active Test-Time Adaptation (ATTA) improves model robustness under domain shift by selectively querying human annotations at deployment, but existing methods use heuristic uncertainty measures and suffer from low data selection efficiency, wasting human annotation budget. We propose Conformal Prediction Active TTA (CPATTA), which first brings principled, coverage-guaranteed uncertainty into ATTA. CPATTA employs smoothed conformal scores with a top-K certainty measure, an online weight-update algorithm driven by pseudo coverage, a domain-shift detector that adapts human supervision, and a staged update scheme balances human-labeled and model-labeled data. Extensive experiments demonstrate that CPATTA consistently outperforms the state-of-the-art ATTA methods by around 5% in accuracy. Our code and datasets are available at https://github.com/tingyushi/CPATTA.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹Active Test-Time Adaptation (ATTA)ä¸­å¯å‘å¼ä¸ç¡®å®šæ€§åº¦é‡æ•ˆç‡ä½ã€æµªè´¹äººå·¥æ ‡æ³¨é¢„ç®—çš„é—®é¢˜ï¼Œæå‡ºäº†CPATTA (Conformal Prediction Active TTA)æ¡†æ¶ã€‚CPATTA é¦–æ¬¡å°†å…·æœ‰è¦†ç›–ç‡ä¿éšœçš„Conformal Predictionå¼•å…¥ATTAï¼Œåˆ©ç”¨smoothed conformal scoreså’Œtop-Kç¡®å®šæ€§åº¦é‡æ¥å®ç°æ›´ç§‘å­¦çš„æ ·æœ¬é€‰æ‹©ã€‚è¯¥æ¡†æ¶åŒ…å«ä¸€ç§ç”±pseudo coverageé©±åŠ¨çš„åœ¨çº¿æƒé‡æ›´æ–°ç®—æ³•ï¼Œä»¥åŠä¸€ä¸ªèƒ½æ ¹æ®domain-shiftæ£€æµ‹ç»“æœè°ƒæ•´äººå·¥ç›‘ç£å¼ºåº¦çš„æ£€æµ‹å™¨ã€‚æ­¤å¤–ï¼Œç ”ç©¶é‡‡ç”¨åˆ†é˜¶æ®µæ›´æ–°æ–¹æ¡ˆæ¥å¹³è¡¡äººå·¥æ ‡æ³¨æ•°æ®ä¸æ¨¡å‹ç”Ÿæˆçš„ä¼ªæ ‡ç­¾æ•°æ®ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCPATTAåœ¨å‡†ç¡®ç‡ä¸Šä¸€è‡´ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›ATTAæ–¹æ³•çº¦5%ï¼Œæ˜¾è‘—æå‡äº†æ ‡æ³¨æ•ˆç‡ã€‚è¯¥ç ”ç©¶ä¸ºå—é™æ ‡æ³¨é¢„ç®—ä¸‹çš„æ¨¡å‹é²æ£’æ€§æå‡æä¾›äº†é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25692v1",
      "published_date": "2025-09-30 02:47:34 UTC",
      "updated_date": "2025-09-30 02:47:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:46:32.892702+00:00"
    },
    {
      "arxiv_id": "2509.25689v1",
      "title": "Collaborative Compression for Large-Scale MoE Deployment on Edge",
      "title_zh": "é¢å‘è¾¹ç¼˜ç«¯å¤§è§„æ¨¡ MoE éƒ¨ç½²çš„ååŒå‹ç¼©",
      "authors": [
        "Yixiao Chen",
        "Yanyue Xie",
        "Ruining Yang",
        "Wei Jiang",
        "Wei Wang",
        "Yong He",
        "Yue Chen",
        "Pu Zhao",
        "Yanzhi Wang"
      ],
      "abstract": "The Mixture of Experts (MoE) architecture is an important method for scaling Large Language Models (LLMs). It increases model capacity while keeping computation cost low. However, the ultra-large MoE models still have hundreds of billions of parameters, requiring massive memory/storage and leading to difficulties for deployment on resource-constrained edge platforms. Pruning or quantization alone can hardly address the issue, because of the super-aggressive compression ratio with significantly degraded accuracy and output quality. To facilitate the deployment of ultra-large MoEs on edge platforms, we propose a collaborative compression framework by combining expert pruning, mixed-precision quantization, and activation optimization. It can effectively reduce the storage footprint of the ultra-large MoE DeepSeek-V3 from 1.3TB to 103GB, while preserving high output quality with better accuracy than traditional uniform low-bit quantization methods. To the best of our knowledge, we are the first to deploy a compressed model from the ultra-large DeepSeek-V3 on the platform with a strict 128GB total memory limit. Our comprehensive experiments on multiple benchmarks under various memory constraints demonstrate the effectiveness of our method with smaller model sizes and higher accuracy than uniform low-bit quantization methods.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Mixture of Experts (MoE) æ¶æ„åœ¨å¤§è¯­è¨€æ¨¡å‹æ‰©å±•ä¸­é¢ä¸´çš„å†…å­˜å ç”¨å·¨å¤§ã€éš¾ä»¥åœ¨èµ„æºå—é™çš„è¾¹ç¼˜å¹³å°éƒ¨ç½²çš„é—®é¢˜ï¼Œæå‡ºäº† Collaborative Compression åä½œå‹ç¼©æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡æ•´åˆä¸“å®¶å‰ªæ (expert pruning)ã€æ··åˆç²¾åº¦é‡åŒ– (mixed-precision quantization) å’Œæ¿€æ´»ä¼˜åŒ– (activation optimization) æŠ€æœ¯ï¼Œå®ç°äº†å¯¹è¶…å¤§è§„æ¨¡æ¨¡å‹çš„é«˜æ•ˆå‹ç¼©ã€‚å®éªŒæˆåŠŸå°†è¶…å¤§è§„æ¨¡ MoE æ¨¡å‹ DeepSeek-V3 çš„å­˜å‚¨éœ€æ±‚ä» 1.3TB æ˜¾è‘—é™ä½è‡³ 103GBï¼Œä¸”åœ¨ä¿æŒé«˜è¾“å‡ºè´¨é‡çš„åŒæ—¶ï¼Œå‡†ç¡®ç‡ä¼˜äºä¼ ç»Ÿçš„å‡åŒ€ä½æ¯”ç‰¹é‡åŒ– (uniform low-bit quantization) æ–¹æ³•ã€‚è¿™æ˜¯ç›®å‰å·²çŸ¥é¦–ä¸ªå®ç°åœ¨æ€»å†…å­˜ä»…ä¸º 128GB çš„å¹³å°ä¸Šéƒ¨ç½²å‹ç¼©ç‰ˆ DeepSeek-V3 çš„æ¡ˆä¾‹ã€‚åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸‹çš„ç»¼åˆå®éªŒè¿›ä¸€æ­¥è¯æ˜ï¼Œè¯¥æ–¹æ³•èƒ½åœ¨æ›´å°çš„æ¨¡å‹å°ºå¯¸ä¸‹ç»´æŒä¼˜å¼‚æ€§èƒ½ï¼Œä¸ºè¶…å¤§è§„æ¨¡ MoE æ¨¡å‹åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šçš„å®é™…åº”ç”¨æä¾›äº†æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25689v1",
      "published_date": "2025-09-30 02:46:03 UTC",
      "updated_date": "2025-09-30 02:46:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:46:35.795389+00:00"
    },
    {
      "arxiv_id": "2509.25684v1",
      "title": "LD-MoLE: Learnable Dynamic Routing for Mixture of LoRA Experts",
      "title_zh": "LD-MoLEï¼šLoRA ä¸“å®¶æ··åˆæ¨¡å‹çš„å¯å­¦ä¹ åŠ¨æ€è·¯ç”±",
      "authors": [
        "Yuan Zhuang",
        "Yi Shen",
        "Yuexin Bian",
        "Qing Su",
        "Shihao Ji",
        "Yuanyuan Shi",
        "Fei Miao"
      ],
      "abstract": "Recent studies have shown that combining parameter-efficient fine-tuning (PEFT) with mixture-of-experts (MoE) is an effective strategy for adapting large language models (LLMs) to the downstream tasks. However, most existing approaches rely on conventional TopK routing, which requires careful hyperparameter tuning and assigns a fixed number of experts to each token. In this work, we propose LD-MoLE, a Learnable Dynamic routing mechanism for Mixture of LoRA Experts that enables adaptive, token-dependent, and layer-wise expert allocation. Our method replaces the non-differentiable TopK selection with a differentiable routing function and a closed-form solution. Moreover, our design allows the model to adaptively determine the number of experts to activate for each token at different layers. In addition, we introduce an analytical sparsity control objective to regularize the number of activated experts. Extensive experiments on the Qwen3-1.7B and Llama-3.2-3B models show that LD-MoLE achieves the highest average scores compared to state-of-the-art baselines, across a diverse set of benchmarks. Our method not only achieves superior performance, but also demonstrates the ability to learn token-dependent and layer-wise expert allocation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†LD-MoLEï¼Œä¸€ç§é’ˆå¯¹LoRAä¸“å®¶æ··åˆ(Mixture of LoRA Experts)çš„å¯å­¦ä¹ åŠ¨æ€è·¯ç”±æœºåˆ¶ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»ŸTopKè·¯ç”±åœ¨å‚æ•°é«˜æ•ˆå¾®è°ƒ(PEFT)ä¸­é¢ä¸´çš„è¶…å‚æ•°è°ƒèŠ‚å¤æ‚ä¸”æ¿€æ´»ä¸“å®¶æ•°é‡å›ºå®šç­‰å±€é™ã€‚LD-MoLEé€šè¿‡å¼•å…¥å¯å¾®è·¯ç”±å‡½æ•°å’Œé—­å¼è§£(closed-form solution)å–ä»£äº†ä¸å¯å¾®çš„é€‰æ‹©è¿‡ç¨‹ï¼Œå®ç°äº†è‡ªé€‚åº”çš„ã€åŸºäºtokenä¸”é€å±‚çš„ä¸“å®¶åˆ†é…ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜è®¾è®¡äº†ä¸€ç§è§£æç¨€ç–æ§åˆ¶ç›®æ ‡(analytical sparsity control objective)æ¥æ­£åˆ™åŒ–æ¿€æ´»ä¸“å®¶çš„æ•°é‡ï¼Œä»¥å¹³è¡¡æ€§èƒ½ä¸è®¡ç®—æ•ˆç‡ã€‚åœ¨Qwen3-1.7Bå’ŒLlama-3.2-3Bæ¨¡å‹ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒLD-MoLEåœ¨å¤šé¡¹åŸºå‡†æµ‹è¯•ä¸­å‡å–å¾—äº†ä¼˜äºç°æœ‰æœ€å…ˆè¿›(SOTA)åŸºçº¿æ¨¡å‹çš„å¹³å‡å¾—åˆ†ã€‚è¯¥æ–¹æ³•ä¸ä»…æ˜¾è‘—æå‡äº†æ¨¡å‹æ€§èƒ½ï¼Œè¿˜éªŒè¯äº†å…¶åœ¨ä¸åŒå±‚çº§ä¸Šæ ¹æ®ç‰¹å®štokenåŠ¨æ€è°ƒæ•´ä¸“å®¶æƒé‡çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25684v1",
      "published_date": "2025-09-30 02:38:10 UTC",
      "updated_date": "2025-09-30 02:38:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:46:46.891438+00:00"
    },
    {
      "arxiv_id": "2510.00078v1",
      "title": "Adaptive and Resource-efficient Agentic AI Systems for Mobile and Embedded Devices: A Survey",
      "title_zh": "é¢å‘ç§»åŠ¨ä¸åµŒå…¥å¼è®¾å¤‡çš„è‡ªé€‚åº”ä¸”èµ„æºé«˜æ•ˆçš„æ™ºèƒ½ä½“ AI ç³»ç»Ÿç»¼è¿°",
      "authors": [
        "Sicong Liu",
        "Weiye Wu",
        "Xiangrui Xu",
        "Teng Li",
        "Bowen Pang",
        "Bin Guo",
        "Zhiwen Yu"
      ],
      "abstract": "Foundation models have reshaped AI by unifying fragmented architectures into scalable backbones with multimodal reasoning and contextual adaptation. In parallel, the long-standing notion of AI agents, defined by the sensing-decision-action loop, is entering a new paradigm: with FMs as their cognitive core, agents transcend rule-based behaviors to achieve autonomy, generalization, and self-reflection. This dual shift is reinforced by real-world demands such as autonomous driving, robotics, virtual assistants, and GUI agents, as well as ecosystem advances in embedded hardware, edge computing, mobile deployment platforms, and communication protocols that together enable large-scale deployment. Yet this convergence collides with reality: while applications demand long-term adaptability and real-time interaction, mobile and edge deployments remain constrained by memory, energy, bandwidth, and latency. This creates a fundamental tension between the growing complexity of FMs and the limited resources of deployment environments. This survey provides the first systematic characterization of adaptive, resource-efficient agentic AI systems. We summarize enabling techniques into elastic inference, test-time adaptation, dynamic multimodal integration, and agentic AI applications, and identify open challenges in balancing accuracy-latency-communication trade-offs and sustaining robustness under distribution shifts. We further highlight future opportunities in algorithm-system co-design, cognitive adaptation, and collaborative edge deployment. By mapping FM structures, cognition, and hardware resources, this work establishes a unified perspective toward scalable, adaptive, and resource-efficient agentic AI. We believe this survey can help readers to understand the connections between enabling technologies while promoting further discussions on the fusion of agentic intelligence and intelligent agents.",
      "tldr_zh": "è¯¥ç»¼è¿°ç³»ç»Ÿåœ°æ¢è®¨äº†é¢å‘ç§»åŠ¨å’ŒåµŒå…¥å¼è®¾å¤‡çš„è‡ªé€‚åº”ä¸”èµ„æºé«˜æ•ˆçš„æ™ºèƒ½ä½“ AI ç³»ç»Ÿ (Agentic AI Systems)ï¼Œåˆ†æäº†åŸºç¡€æ¨¡å‹ (Foundation Models) ä½œä¸ºæ™ºèƒ½ä½“è®¤çŸ¥æ ¸å¿ƒæ‰€å¸¦æ¥çš„èŒƒå¼è½¬å˜ã€‚è™½ç„¶åŸºç¡€æ¨¡å‹èµ‹äºˆäº†æ™ºèƒ½ä½“è‡ªä¸»æ€§ã€æ³›åŒ–èƒ½åŠ›å’Œè‡ªæˆ‘åæ€ (Self-reflection) ç‰¹æ€§ï¼Œä½†å…¶ä¸æ–­å¢é•¿çš„å¤æ‚æ€§ä¸ç§»åŠ¨åŠè¾¹ç¼˜éƒ¨ç½²ç¯å¢ƒä¸­çš„å†…å­˜ã€èƒ½æºã€å¸¦å®½å’Œå»¶è¿Ÿé™åˆ¶ä¹‹é—´å­˜åœ¨æ ¹æœ¬æ€§çŸ›ç›¾ã€‚æ–‡ç« é¦–æ¬¡å¯¹è¯¥é¢†åŸŸçš„å…³é”®æŠ€æœ¯è¿›è¡Œäº†ç³»ç»Ÿåˆ†ç±»ï¼Œæ¶µç›–äº†å¼¹æ€§æ¨ç† (Elastic Inference)ã€æµ‹è¯•æ—¶è‡ªé€‚åº” (Test-time Adaptation)ã€åŠ¨æ€å¤šæ¨¡æ€é›†æˆ (Dynamic Multimodal Integration) ä»¥åŠæ™ºèƒ½ä½“ AI åº”ç”¨ã€‚è¯¥ç ”ç©¶è¯†åˆ«äº†åœ¨å¹³è¡¡å‡†ç¡®æ€§-å»¶è¿Ÿ-é€šä¿¡æƒè¡¡ä»¥åŠåœ¨åˆ†å¸ƒåç§» (Distribution Shifts) ä¸‹ç»´æŒé²æ£’æ€§æ–¹é¢å­˜åœ¨çš„å…¬å¼€æŒ‘æˆ˜ã€‚ä½œè€…è¿›ä¸€æ­¥æå‡ºäº†ç®—æ³•-ç³»ç»ŸååŒè®¾è®¡ (Algorithm-system Co-design)ã€è®¤çŸ¥è‡ªé€‚åº”å’Œåä½œè¾¹ç¼˜éƒ¨ç½²ç­‰æœªæ¥ç ”ç©¶æ–¹å‘ã€‚é€šè¿‡æ˜ å°„åŸºç¡€æ¨¡å‹ç»“æ„ã€è®¤çŸ¥èƒ½åŠ›ä¸ç¡¬ä»¶èµ„æºï¼Œæœ¬æ–‡ä¸ºå®ç°å¯æ‰©å±•ã€è‡ªé€‚åº”ä¸”èµ„æºé«˜æ•ˆçš„æ™ºèƒ½ä½“ AI å»ºç«‹äº†ç»Ÿä¸€çš„ç ”ç©¶è§†è§’ï¼Œæ—¨åœ¨æ¨åŠ¨ä»£ç†æ™ºèƒ½ä¸æ™ºèƒ½ä½“èåˆçš„æ·±å…¥è®¨è®ºã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.00078v1",
      "published_date": "2025-09-30 02:37:52 UTC",
      "updated_date": "2025-09-30 02:37:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:46:51.585208+00:00"
    },
    {
      "arxiv_id": "2509.25672v1",
      "title": "SING-SQL: A Synthetic Data Generation Framework for In-Domain Text-to-SQL Translation",
      "title_zh": "SING-SQLï¼šé¢å‘é¢†åŸŸå†… Text-to-SQL è½¬æ¢çš„åˆæˆæ•°æ®ç”Ÿæˆæ¡†æ¶",
      "authors": [
        "Hasan Alp CaferoÄŸlu",
        "Mehmet Serhat Ã‡elik",
        "Ã–zgÃ¼r Ulusoy"
      ],
      "abstract": "Translating natural language questions into SQL has become a core challenge in enabling non-technical users to query databases. While recent work has explored large-scale synthetic data generation to improve model performance through post-training, most efforts emphasize cross-domain generalization. This leaves a gap for real-world enterprise scenarios, where models need to specialize to a single database schema and organizations require to be able to evaluate their Text-to-SQL systems on their own databases. To address this, we introduce SING-SQL, a fully automated two-stage framework for generating high-quality, high-coverage synthetic Text-to-SQL data for any target database, without relying on SQL logs or manual annotations. Our approach hierarchically partitions a database schema into sub-schemas, synthesizes SQL queries across multiple complexity levels, and applies a quality-aware pipeline that includes LLM-as-a-judge validation, executability checks, automatic repair, and column balancing. We further release SingSQL-LM, a family of compact language models fine-tuned on the synthetic data, achieving strong in-domain generalization. On the subset of the BIRD benchmark, SingSQL-LM-3B-R64 reaches 82.87% Soft F1 and 73.03% EX upper bound with 32 candidates, outperforming the best 3B-scale baseline by +16.21 in Soft F1 and +12.36 in EX. At the 1.5B scale, SingSQL-LM-1.5B-R64 improves over prior systems by +9.30 in Soft F1 and +4.49 in EX. On synthetic evaluation sets, SingSQL-LMs exceed prior systems by wide margins, establishing state-of-the-art performance among open models at comparable scales. Our study of context management strategies reveals that schema-free fine-tuning combined with schema-only inference provides the most robust results. These findings establish SING-SQL as a scalable, database-agnostic paradigm for producing and evaluating enterprise-grade Text-to-SQL systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¼ä¸šåœºæ™¯ä¸­æ¨¡å‹éœ€è¦ä¸“æ³¨äºå•ä¸€æ•°æ®åº“æ¨¡å¼(Schema)ä¸”ç¼ºä¹è¯„ä¼°æ•°æ®çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†SING-SQLï¼Œä¸€ä¸ªå…¨è‡ªåŠ¨çš„ä¸¤é˜¶æ®µåˆæˆæ•°æ®ç”Ÿæˆæ¡†æ¶ã€‚è¯¥æ¡†æ¶æ— éœ€ä¾èµ–SQLæ—¥å¿—æˆ–äººå·¥æ ‡æ³¨ï¼Œé€šè¿‡å±‚æ¬¡åŒ–åˆ†åŒºæ•°æ®åº“æ¨¡å¼å¹¶åˆæˆå¤šç§å¤æ‚åº¦çš„SQLæŸ¥è¯¢ï¼Œç»“åˆLLM-as-a-judgeéªŒè¯ã€æ‰§è¡Œæ£€æŸ¥ã€è‡ªåŠ¨ä¿®å¤å’Œåˆ—å¹³è¡¡æŠ€æœ¯ç¡®ä¿æ•°æ®çš„é«˜è´¨é‡ä¸é«˜è¦†ç›–ç‡ã€‚ç ”ç©¶å›¢é˜Ÿè¿›ä¸€æ­¥æ¨å‡ºäº†ç»è¿‡å¾®è°ƒçš„SingSQL-LMç³»åˆ—è½»é‡çº§æ¨¡å‹ï¼Œåœ¨BIRDåŸºå‡†æµ‹è¯•ä¸­ï¼Œ3Bè§„æ¨¡æ¨¡å‹åœ¨Soft F1å’ŒEXæŒ‡æ ‡ä¸Šåˆ†åˆ«è¶…è¶Šæœ€ä½³åŸºçº¿16.21%å’Œ12.36%ã€‚æ­¤å¤–ï¼Œå®éªŒè¡¨æ˜é‡‡ç”¨æ— æ¨¡å¼å¾®è°ƒ(Schema-free fine-tuning)ä¸ä»…å«æ¨¡å¼æ¨ç†(Schema-only inference)çš„ç»„åˆç­–ç•¥èƒ½æä¾›æœ€ç¨³å¥çš„ç»“æœã€‚SING-SQLä¸ºç”Ÿæˆå’Œè¯„ä¼°ä¼ä¸šçº§Text-to-SQLç³»ç»Ÿæä¾›äº†ä¸€ç§å¯æ‰©å±•ä¸”ä¸æ•°æ®åº“æ— å…³çš„é«˜æ•ˆèŒƒå¼ã€‚",
      "categories": [
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25672v1",
      "published_date": "2025-09-30 02:14:49 UTC",
      "updated_date": "2025-09-30 02:14:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:47:41.071043+00:00"
    },
    {
      "arxiv_id": "2509.25669v1",
      "title": "GroundSight: Augmenting Vision-Language Models with Grounding Information and De-hallucination",
      "title_zh": "GroundSightï¼šåˆ©ç”¨å®šä½ä¿¡æ¯ä¸å»å¹»è§‰å¢å¼ºè§†è§‰è¯­è¨€æ¨¡å‹",
      "authors": [
        "Xinxi Chen",
        "Tianyang Chen",
        "Lijia Hong"
      ],
      "abstract": "We propose a method to improve Visual Question Answering (VQA) with Retrieval-Augmented Generation (RAG) by introducing text-grounded object localization. Rather than retrieving information based on the entire image, our approach enables the model to generate a bounding box around the object most relevant to the question, allowing for targeted image cropping and focused retrieval. This reduces background noise, improves alignment between visual and textual cues, and helps mitigate hallucinations. Our RAG method enhances context-aware VQA responses increased the accuracy from 22.19% to 25.64%, with an absolute increase of 3.45 percentage points, compared to the baseline Llama-3.2-Vision-11B agent. We also proposed a de-hallucination method based on question type which can effectively reduce the hallucination rate from 65.79% to 13.88% and improves the truthfulness score.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†GroundSightï¼Œä¸€ç§é€šè¿‡å¼•å…¥æ–‡æœ¬é©±åŠ¨çš„ç›®æ ‡å®šä½(Text-grounded Object Localization)æ¥å¢å¼ºè§†è§‰é—®ç­”(Visual Question Answering, VQA)ä¸­æ£€ç´¢å¢å¼ºç”Ÿæˆ(Retrieval-Augmented Generation, RAG)æ•ˆæœçš„æ–¹æ³•ã€‚ä¸ä¼ ç»ŸåŸºäºæ•´å›¾çš„æ£€ç´¢ä¸åŒï¼Œè¯¥æ–¹æ³•é€šè¿‡ä¸ºä¸é—®é¢˜æœ€ç›¸å…³çš„ç›®æ ‡ç”Ÿæˆè¾¹ç•Œæ¡†(Bounding Box)ï¼Œå®ç°å®šå‘å›¾åƒè£å‰ªå’Œé›†ä¸­æ£€ç´¢ï¼Œä»è€Œæœ‰æ•ˆå‡å°‘èƒŒæ™¯å™ªå£°å¹¶æ”¹å–„è§†è§‰ä¸æ–‡æœ¬çº¿ç´¢çš„å¯¹é½ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•æ˜¾è‘—ç¼“è§£äº†æ¨¡å‹çš„å¹»è§‰(Hallucination)é—®é¢˜ï¼Œå¹¶å°†Llama-3.2-Vision-11BåŸºçº¿æ¨¡å‹çš„å‡†ç¡®ç‡ä»22.19%æå‡è‡³25.64%ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜æå‡ºäº†ä¸€ç§åŸºäºé—®é¢˜ç±»å‹çš„å»å¹»è§‰(De-hallucination)æ–¹æ³•ï¼ŒæˆåŠŸå°†å¹»è§‰ç‡ä»65.79%å¤§å¹…é™ä½è‡³13.88%ï¼Œå¹¶æ˜¾è‘—æå‡äº†ç­”æ¡ˆçš„çœŸå®æ€§è¯„åˆ†ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25669v1",
      "published_date": "2025-09-30 02:09:07 UTC",
      "updated_date": "2025-09-30 02:09:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:47:00.190625+00:00"
    },
    {
      "arxiv_id": "2509.25667v1",
      "title": "EEG-based AI-BCI Wheelchair Advancement: Hybrid Deep Learning with Motor Imagery for Brain Computer Interface",
      "title_zh": "åŸºäºè„‘ç”µå›¾çš„ AI-BCI è½®æ¤…æŠ€æœ¯è¿›å±•ï¼šç»“åˆè¿åŠ¨æƒ³è±¡çš„æ··åˆæ·±åº¦å­¦ä¹ è„‘æœºæ¥å£ç ”ç©¶",
      "authors": [
        "Bipul Thapa",
        "Biplov Paneru",
        "Bishwash Paneru",
        "Khem Narayan Poudyal"
      ],
      "abstract": "This paper presents an Artificial Intelligence (AI) integrated novel approach to Brain-Computer Interface (BCI)-based wheelchair development, utilizing a motor imagery right-left-hand movement mechanism for control. The system is designed to simulate wheelchair navigation based on motor imagery right and left-hand movements using electroencephalogram (EEG) data. A pre-filtered dataset, obtained from an open-source EEG repository, was segmented into arrays of 19x200 to capture the onset of hand movements. The data was acquired at a sampling frequency of 200Hz. The system integrates a Tkinter-based interface for simulating wheelchair movements, offering users a functional and intuitive control system. We propose a BiLSTM-BiGRU model that shows a superior test accuracy of 92.26% as compared with various machine learning baseline models, including XGBoost, EEGNet, and a transformer-based model. The Bi-LSTM-BiGRU attention-based model achieved a mean accuracy of 90.13% through cross-validation, showcasing the potential of attention mechanisms in BCI applications.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºäººå·¥æ™ºèƒ½(AI)é›†æˆçš„è„‘æœºæ¥å£(BCI)è½®æ¤…å¼€å‘æ–°æ–¹æ³•ï¼Œåˆ©ç”¨è¿åŠ¨æƒ³è±¡(Motor Imagery)çš„å·¦å³æ‰‹åŠ¨ä½œæœºåˆ¶å®ç°æ§åˆ¶å¯¼èˆªã€‚ç³»ç»Ÿé€šè¿‡å¯¹è„‘ç”µå›¾(EEG)æ•°æ®è¿›è¡Œé¢„æ»¤æ³¢å’Œåˆ†æ®µå¤„ç†ï¼Œå¹¶ç»“åˆTkinteræ¥å£å®ç°äº†ç›´è§‚çš„è½®æ¤…è¿åŠ¨æ¨¡æ‹Ÿã€‚ç ”ç©¶æ ¸å¿ƒæå‡ºäº†ä¸€ç§BiLSTM-BiGRUæ··åˆæ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œç”¨äºæ•æ‰è¿åŠ¨æƒ³è±¡è¿‡ç¨‹ä¸­çš„æ—¶åºç‰¹å¾ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šè¾¾åˆ°äº†92.26%çš„å‡†ç¡®ç‡ï¼Œæ€§èƒ½æ˜¾è‘—ä¼˜äºXGBoostã€EEGNetåŠTransformerç­‰åŸºçº¿æ¨¡å‹ã€‚é€šè¿‡äº¤å‰éªŒè¯ï¼Œå¸¦æœ‰æ³¨æ„åŠ›æœºåˆ¶(Attention Mechanism)çš„æ¨¡å‹å±•ç¤ºäº†æé«˜çš„é²æ£’æ€§ï¼Œä¸ºå¼€å‘é«˜æ•ˆã€ç›´è§‚çš„è¾…åŠ©æ§åˆ¶ç³»ç»Ÿæä¾›äº†é‡è¦çš„æŠ€æœ¯å‚è€ƒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25667v1",
      "published_date": "2025-09-30 02:06:04 UTC",
      "updated_date": "2025-09-30 02:06:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:47:06.100391+00:00"
    },
    {
      "arxiv_id": "2509.25662v1",
      "title": "On Explaining Proxy Discrimination and Unfairness in Individual Decisions Made by AI Systems",
      "title_zh": "è®ºäººå·¥æ™ºèƒ½ç³»ç»Ÿä¸ªä½“å†³ç­–ä¸­ä»£ç†æ­§è§†ä¸ä¸å…¬å¹³æ€§çš„è§£é‡Š",
      "authors": [
        "Belona Sonna",
        "Alban Grastien"
      ],
      "abstract": "Artificial intelligence (AI) systems in high-stakes domains raise concerns about proxy discrimination, unfairness, and explainability. Existing audits often fail to reveal why unfairness arises, particularly when rooted in structural bias. We propose a novel framework using formal abductive explanations to explain proxy discrimination in individual AI decisions. Leveraging background knowledge, our method identifies which features act as unjustified proxies for protected attributes, revealing hidden structural biases. Central to our approach is the concept of aptitude, a task-relevant property independent of group membership, with a mapping function aligning individuals of equivalent aptitude across groups to assess fairness substantively. As a proof of concept, we showcase the framework with examples taken from the German credit dataset, demonstrating its applicability in real-world cases.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é’ˆå¯¹äººå·¥æ™ºèƒ½ç³»ç»Ÿåœ¨é«˜é£é™©é¢†åŸŸä¸­çš„ä»£ç†æ­§è§†(proxy discrimination)å’Œä¸å…¬å¹³æ€§é—®é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªåˆ©ç”¨å½¢å¼åŒ–æº¯å› è§£é‡Š(formal abductive explanations)æ¥è§£é‡Šä¸ªä½“å†³ç­–çš„æ–°å‹æ¡†æ¶ã€‚è¯¥æ–¹æ³•é€šè¿‡æ•´åˆèƒŒæ™¯çŸ¥è¯†æ¥è¯†åˆ«å“ªäº›ç‰¹å¾æ„æˆäº†å—ä¿æŠ¤å±æ€§çš„ä¸å½“ä»£ç†ï¼Œä»è€Œæ­ç¤ºéšè—çš„ç»“æ„æ€§åè§(structural bias)ã€‚ç ”ç©¶å¼•å…¥äº†èµ„è´¨(aptitude)è¿™ä¸€å…³é”®æ¦‚å¿µï¼Œå°†å…¶å®šä¹‰ä¸ºä¸ç¾¤ä½“æˆå‘˜èº«ä»½æ— å…³ä¸”ä¸ä»»åŠ¡ç›¸å…³çš„å±æ€§ï¼Œå¹¶åˆ©ç”¨æ˜ å°„å‡½æ•°å¯¹ä¸åŒç¾¤ä½“ä¸­èµ„è´¨ç›¸å½“çš„ä¸ªä½“è¿›è¡Œå¯¹é½ï¼Œä»¥å®ç°å¯¹å…¬å¹³æ€§çš„å®è´¨æ€§è¯„ä¼°ã€‚ç ”ç©¶å›¢é˜Ÿåˆ©ç”¨å¾·å›½ä¿¡è´·æ•°æ®é›†(German credit dataset)è¿›è¡Œäº†æ¦‚å¿µéªŒè¯ï¼Œè¯æ˜äº†è¯¥æ¡†æ¶åœ¨è§£é‡Šç°å®ä¸–ç•ŒAIç³»ç»Ÿå†³ç­–è¿‡ç¨‹ä¸­çš„é€‚ç”¨æ€§ä¸æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.AI",
        "cs.SC"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at AJCAI 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.25662v1",
      "published_date": "2025-09-30 01:58:59 UTC",
      "updated_date": "2025-09-30 01:58:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:47:09.488752+00:00"
    },
    {
      "arxiv_id": "2509.25661v1",
      "title": "Deep Reinforcement Learning-Based Precoding for Multi-RIS-Aided Multiuser Downlink Systems with Practical Phase Shift",
      "title_zh": "è€ƒè™‘å®é™…ç›¸ç§»çš„å¤š RIS è¾…åŠ©å¤šç”¨æˆ·ä¸‹è¡Œç³»ç»Ÿæ·±åº¦å¼ºåŒ–å­¦ä¹ é¢„ç¼–ç ",
      "authors": [
        "Po-Heng Chou",
        "Bo-Ren Zheng",
        "Wan-Jen Huang",
        "Walid Saad",
        "Yu Tsao",
        "Ronald Y. Chang"
      ],
      "abstract": "This study considers multiple reconfigurable intelligent surfaces (RISs)-aided multiuser downlink systems with the goal of jointly optimizing the transmitter precoding and RIS phase shift matrix to maximize spectrum efficiency. Unlike prior work that assumed ideal RIS reflectivity, a practical coupling effect is considered between reflecting amplitude and phase shift for the RIS elements. This makes the optimization problem non-convex. To address this challenge, we propose a deep deterministic policy gradient (DDPG)-based deep reinforcement learning (DRL) framework. The proposed model is evaluated under both fixed and random numbers of users in practical mmWave channel settings. Simulation results demonstrate that, despite its complexity, the proposed DDPG approach significantly outperforms optimization-based algorithms and double deep Q-learning, particularly in scenarios with random user distributions.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç”±å¤šä¸ªå¯é‡æ„æ™ºèƒ½è¡¨é¢ (RIS) è¾…åŠ©çš„å¤šç”¨æˆ·ä¸‹è¡Œé“¾è·¯ç³»ç»Ÿï¼Œæ—¨åœ¨é€šè¿‡è”åˆä¼˜åŒ–å‘å°„æœºé¢„ç¼–ç  (precoding) å’Œ RIS ç›¸ä½åç§»çŸ©é˜µæ¥æœ€å¤§åŒ–é¢‘è°±æ•ˆç‡ã€‚é’ˆå¯¹ RIS å•å…ƒåå°„æŒ¯å¹…ä¸ç›¸ä½åç§»ä¹‹é—´å­˜åœ¨çš„å®é™…è€¦åˆæ•ˆåº”æ‰€å¯¼è‡´çš„éå‡¸ (non-convex) ä¼˜åŒ–éš¾é¢˜ï¼Œç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºæ·±åº¦ç¡®å®šæ€§ç­–ç•¥æ¢¯åº¦ (DDPG) çš„æ·±åº¦å¼ºåŒ–å­¦ä¹  (DRL) æ¡†æ¶ã€‚è¯¥æ–¹æ¡ˆåœ¨å®é™…æ¯«ç±³æ³¢ (mmWave) ä¿¡é“ç¯å¢ƒä¸‹ï¼Œé’ˆå¯¹å›ºå®šåŠéšæœºç”¨æˆ·æ•°é‡çš„å¤šç§åœºæ™¯è¿›è¡Œäº†å…¨é¢è¯„ä¼°ã€‚ä»¿çœŸç»“æœè¯æ˜ï¼Œæ‰€æå‡ºçš„ DDPG æ–¹æ³•åœ¨å¤„ç†å¤æ‚ä¼˜åŒ–é—®é¢˜æ—¶å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ï¼Œå…¶æ€§èƒ½è¡¨ç°å¤§å¹…ä¼˜äºä¼ ç»Ÿçš„åŸºäºä¼˜åŒ–çš„ç®—æ³•ä»¥åŠåŒæ·±åº¦ Q å­¦ä¹  (double deep Q-learning)ï¼Œç‰¹åˆ«æ˜¯åœ¨é¢å¯¹éšæœºç”¨æˆ·åˆ†å¸ƒæ—¶å±•ç°å‡ºæ›´å¼ºçš„é²æ£’æ€§ã€‚",
      "categories": [
        "cs.IT",
        "cs.AI",
        "cs.LG",
        "cs.NI",
        "eess.SP"
      ],
      "primary_category": "cs.IT",
      "comment": "5 pages, 5 figures, and published in IEEE Wireless Communications Letters",
      "pdf_url": "https://arxiv.org/pdf/2509.25661v1",
      "published_date": "2025-09-30 01:57:57 UTC",
      "updated_date": "2025-09-30 01:57:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:47:55.295052+00:00"
    },
    {
      "arxiv_id": "2509.25660v1",
      "title": "Capacity-Net-Based RIS Precoding Design without Channel Estimation for mmWave MIMO System",
      "title_zh": "åŸºäº Capacity-Net çš„æ¯«ç±³æ³¢ MIMO ç³»ç»Ÿå…ä¿¡é“ä¼°è®¡ RIS é¢„ç¼–ç è®¾è®¡",
      "authors": [
        "Chun-Yuan Huang",
        "Po-Heng Chou",
        "Wan-Jen Huang",
        "Ying-Ren Chien",
        "Yu Tsao"
      ],
      "abstract": "In this paper, we propose Capacity-Net, a novel unsupervised learning approach aimed at maximizing the achievable rate in reflecting intelligent surface (RIS)-aided millimeter-wave (mmWave) multiple input multiple output (MIMO) systems. To combat severe channel fading of the mmWave spectrum, we optimize the phase-shifting factors of the reflective elements in the RIS to enhance the achievable rate. However, most optimization algorithms rely heavily on complete and accurate channel state information (CSI), which is often challenging to acquire since the RIS is mostly composed of passive components. To circumvent this challenge, we leverage unsupervised learning techniques with implicit CSI provided by the received pilot signals. Specifically, it usually requires perfect CSI to evaluate the achievable rate as a performance metric of the current optimization result of the unsupervised learning method. Instead of channel estimation, the Capacity-Net is proposed to establish a mapping among the received pilot signals, optimized RIS phase shifts, and the resultant achievable rates. Simulation results demonstrate the superiority of the proposed Capacity-Net-based unsupervised learning approach over learning methods based on traditional channel estimation.",
      "tldr_zh": "æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸º Capacity-Net çš„æ–°å‹æ— ç›‘ç£å­¦ä¹ æ–¹æ³•ï¼Œæ—¨åœ¨æœ€å¤§åŒ–æ™ºèƒ½åå°„é¢ (RIS) è¾…åŠ©çš„æ¯«ç±³æ³¢ (mmWave) å¤šè¾“å…¥å¤šè¾“å‡º (MIMO) ç³»ç»Ÿçš„å¯è¾¾é€Ÿç‡ã€‚é’ˆå¯¹æ¯«ç±³æ³¢é¢‘æ®µä¸¥é‡çš„ä¿¡é“è¡°è½é—®é¢˜ï¼Œè¯¥ç ”ç©¶é€šè¿‡ä¼˜åŒ– RIS åå°„å…ƒä»¶çš„ç›¸ç§»å› å­æ¥å¢å¼ºç³»ç»Ÿæ€§èƒ½ã€‚è€ƒè™‘åˆ° RIS å¤šç”±æ— æºå™¨ä»¶ç»„æˆï¼Œéš¾ä»¥è·å–å®Œæ•´ä¸”å‡†ç¡®çš„ä¿¡é“çŠ¶æ€ä¿¡æ¯ (CSI)ï¼Œä¼ ç»Ÿä¼˜åŒ–ç®—æ³•åœ¨å®é™…åº”ç”¨ä¸­é¢ä¸´æŒ‘æˆ˜ã€‚Capacity-Net åˆ©ç”¨æ¥æ”¶åˆ°çš„å¯¼é¢‘ä¿¡å·æä¾›çš„éšå¼ CSIï¼Œé€šè¿‡æ— ç›‘ç£å­¦ä¹ æŠ€æœ¯ç»•è¿‡äº†å¤æ‚çš„ä¿¡é“ä¼°è®¡è¿‡ç¨‹ï¼Œå»ºç«‹äº†æ¥æ”¶å¯¼é¢‘ä¿¡å·ã€ä¼˜åŒ–çš„ RIS ç›¸ç§»ä¸æœ€ç»ˆå¯è¾¾é€Ÿç‡ä¹‹é—´çš„ç›´æ¥æ˜ å°„å…³ç³»ã€‚ä»¿çœŸç»“æœè¡¨æ˜ï¼Œç›¸æ¯”äºåŸºäºä¼ ç»Ÿä¿¡é“ä¼°è®¡çš„å­¦ä¹ æ–¹æ³•ï¼ŒåŸºäº Capacity-Net çš„æ— ç›‘ç£å­¦ä¹ æ–¹æ¡ˆåœ¨æå‡ç³»ç»Ÿé€Ÿç‡æ–¹é¢å±•ç°å‡ºäº†æ˜¾è‘—çš„ä¼˜è¶Šæ€§ã€‚",
      "categories": [
        "cs.IT",
        "cs.AI",
        "cs.LG",
        "cs.NI",
        "eess.SP"
      ],
      "primary_category": "cs.IT",
      "comment": "10 pages, 5 figures, and published in 2024 IEEE PIMRC",
      "pdf_url": "https://arxiv.org/pdf/2509.25660v1",
      "published_date": "2025-09-30 01:57:33 UTC",
      "updated_date": "2025-09-30 01:57:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:47:57.268357+00:00"
    },
    {
      "arxiv_id": "2509.25659v2",
      "title": "YOLO-Based Defect Detection for Metal Sheets",
      "title_zh": "åŸºäº YOLO çš„é‡‘å±è–„æ¿ç¼ºé™·æ£€æµ‹",
      "authors": [
        "Po-Heng Chou",
        "Chun-Chi Wang",
        "Wei-Lung Mao"
      ],
      "abstract": "In this paper, we propose a YOLO-based deep learning (DL) model for automatic defect detection to solve the time-consuming and labor-intensive tasks in industrial manufacturing. In our experiments, the images of metal sheets are used as the dataset for training the YOLO model to detect the defects on the surfaces and in the holes of metal sheets. However, the lack of metal sheet images significantly degrades the performance of detection accuracy. To address this issue, the ConSinGAN is used to generate a considerable amount of data. Four versions of the YOLO model (i.e., YOLOv3, v4, v7, and v9) are combined with the ConSinGAN for data augmentation. The proposed YOLOv9 model with ConSinGAN outperforms the other YOLO models with an accuracy of 91.3%, and a detection time of 146 ms. The proposed YOLOv9 model is integrated into manufacturing hardware and a supervisory control and data acquisition (SCADA) system to establish a practical automated optical inspection (AOI) system. Additionally, the proposed automated defect detection is easily applied to other components in industrial manufacturing.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å·¥ä¸šåˆ¶é€ ä¸­é‡‘å±æ¿ç¼ºé™·æ£€æµ‹è€—æ—¶è´¹åŠ›ä¸”è®­ç»ƒæ•°æ®åŒ®ä¹å¯¼è‡´å‡†ç¡®ç‡ä¸‹é™çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäº YOLO çš„æ·±åº¦å­¦ä¹ (Deep Learning)è‡ªåŠ¨æ£€æµ‹æ¨¡å‹ã€‚ä¸ºäº†è§£å†³å›¾åƒæ ·æœ¬ä¸è¶³çš„é—®é¢˜ï¼Œç ”ç©¶é‡‡ç”¨ ConSinGAN æŠ€æœ¯ç”Ÿæˆå¤§é‡æ•°æ®ï¼Œå¹¶å°†å…¶ä¸ YOLOv3ã€v4ã€v7 å’Œ v9 å››ä¸ªç‰ˆæœ¬ç»“åˆè¿›è¡Œæ•°æ®å¢å¼ºã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œç»“åˆäº† ConSinGAN çš„ YOLOv9 æ¨¡å‹åœ¨æ€§èƒ½ä¸Šä¼˜äºå…¶ä»–ç‰ˆæœ¬ï¼Œå®ç°äº† 91.3% çš„å‡†ç¡®ç‡ä»¥åŠä»… 146 æ¯«ç§’çš„æ£€æµ‹æ—¶é—´ã€‚è¯¥æ¨¡å‹å·²æˆåŠŸé›†æˆåˆ°åˆ¶é€ ç¡¬ä»¶å’Œæ•°æ®é‡‡é›†ä¸ç›‘è§†æ§åˆ¶ç³»ç»Ÿ(SCADA)ä¸­ï¼Œæ„å»ºäº†ä¸€ä¸ªå®ç”¨çš„è‡ªåŠ¨å…‰å­¦æ£€æµ‹(AOI)ç³»ç»Ÿã€‚è¯¥ç ”ç©¶æå‡ºçš„è‡ªåŠ¨ç¼ºé™·æ£€æµ‹æ–¹æ¡ˆä¸ä»…åœ¨é‡‘å±æ¿è¡¨é¢åŠå­”æ´ç¼ºé™·æ£€æµ‹ä¸­è¡¨ç°å‡ºè‰²ï¼Œä¸”å…·æœ‰è‰¯å¥½çš„é€šç”¨æ€§ï¼Œå¯è½»æ˜“æ¨å¹¿è‡³å·¥ä¸šåˆ¶é€ ä¸­çš„å…¶ä»–é›¶éƒ¨ä»¶æ£€æµ‹ä»»åŠ¡ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.IV",
        "eess.SP"
      ],
      "primary_category": "cs.CV",
      "comment": "5 pages, 8 figures, 2 tables, and published in IEEE IST 2024",
      "pdf_url": "https://arxiv.org/pdf/2509.25659v2",
      "published_date": "2025-09-30 01:56:44 UTC",
      "updated_date": "2025-10-03 02:02:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:48:00.579126+00:00"
    },
    {
      "arxiv_id": "2509.25655v1",
      "title": "Landmark-Guided Knowledge for Vision-and-Language Navigation",
      "title_zh": "é¢å‘è§†è§‰è¯­è¨€å¯¼èˆªçš„åœ°æ ‡å¼•å¯¼çŸ¥è¯†",
      "authors": [
        "Dongsheng Yang",
        "Meiling Zhu",
        "Yinfeng Yu"
      ],
      "abstract": "Vision-and-language navigation is one of the core tasks in embodied intelligence, requiring an agent to autonomously navigate in an unfamiliar environment based on natural language instructions. However, existing methods often fail to match instructions with environmental information in complex scenarios, one reason being the lack of common-sense reasoning ability. This paper proposes a vision-and-language navigation method called Landmark-Guided Knowledge (LGK), which introduces an external knowledge base to assist navigation, addressing the misjudgment issues caused by insufficient common sense in traditional methods. Specifically, we first construct a knowledge base containing 630,000 language descriptions and use knowledge Matching to align environmental subviews with the knowledge base, extracting relevant descriptive knowledge. Next, we design a Knowledge-Guided by Landmark (KGL) mechanism, which guides the agent to focus on the most relevant parts of the knowledge by leveraging landmark information in the instructions, thereby reducing the data bias that may arise from incorporating external knowledge. Finally, we propose Knowledge-Guided Dynamic Augmentation (KGDA), which effectively integrates language, knowledge, vision, and historical information. Experimental results demonstrate that the LGK method outperforms existing state-of-the-art methods on the R2R and REVERIE vision-and-language navigation datasets, particularly in terms of navigation error, success rate, and path efficiency.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è§†è§‰è¯­è¨€å¯¼èˆª(Vision-and-Language Navigation)ä¸­ç°æœ‰æ–¹æ³•å› ç¼ºä¹å¸¸è¯†æ¨ç†èƒ½åŠ›è€Œéš¾ä»¥å‡†ç¡®åŒ¹é…æŒ‡ä»¤ä¸ç¯å¢ƒä¿¡æ¯çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºLandmark-Guided Knowledge (LGK)çš„å¯¼èˆªæ–¹æ³•ã€‚LGKé€šè¿‡å¼•å…¥åŒ…å«63ä¸‡æ¡è¯­è¨€æè¿°çš„å¤–éƒ¨çŸ¥è¯†åº“ï¼Œåˆ©ç”¨Knowledge MatchingæŠ€æœ¯å°†ç¯å¢ƒå­è§†å›¾ä¸ç›¸å…³æè¿°æ€§çŸ¥è¯†è¿›è¡Œå¯¹é½ã€‚ä¸ºäº†å‡è½»å¼•å…¥å¤–éƒ¨çŸ¥è¯†å¯èƒ½äº§ç”Ÿçš„æ•°æ®åå·®ï¼Œç ”ç©¶è®¾è®¡äº†Knowledge-Guided by Landmark (KGL)æœºåˆ¶ï¼Œåˆ©ç”¨æŒ‡ä»¤ä¸­çš„åœ°æ ‡ä¿¡æ¯å¼•å¯¼æ™ºèƒ½ä½“èšç„¦äºæœ€ç›¸å…³çš„çŸ¥è¯†å†…å®¹ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜æå‡ºäº†Knowledge-Guided Dynamic Augmentation (KGDA)æ¨¡å—ï¼Œæ—¨åœ¨æœ‰æ•ˆæ•´åˆè¯­è¨€ã€çŸ¥è¯†ã€è§†è§‰åŠå†å²åºåˆ—ä¿¡æ¯ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒLGKåœ¨R2Rå’ŒREVERIEæ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ï¼Œåœ¨å¯¼èˆªè¯¯å·®ã€æˆåŠŸç‡å’Œè·¯å¾„æ•ˆç‡æ–¹é¢å‡å–å¾—äº†æ˜¾è‘—æå‡ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted for publication by International Conference on Intelligent Computing 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.25655v1",
      "published_date": "2025-09-30 01:54:27 UTC",
      "updated_date": "2025-09-30 01:54:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:48:23.384616+00:00"
    },
    {
      "arxiv_id": "2509.25652v1",
      "title": "Iterative Residual Cross-Attention Mechanism: An Integrated Approach for Audio-Visual Navigation Tasks",
      "title_zh": "è¿­ä»£æ®‹å·®äº¤å‰æ³¨æ„åŠ›æœºåˆ¶ï¼šè§†å¬å¯¼èˆªä»»åŠ¡çš„ä¸€ä½“åŒ–æ–¹æ³•",
      "authors": [
        "Hailong Zhang",
        "Yinfeng Yu",
        "Liejun Wang",
        "Fuchun Sun",
        "Wendong Zheng"
      ],
      "abstract": "Audio-visual navigation represents a significant area of research in which intelligent agents utilize egocentric visual and auditory perceptions to identify audio targets. Conventional navigation methodologies typically adopt a staged modular design, which involves first executing feature fusion, then utilizing Gated Recurrent Unit (GRU) modules for sequence modeling, and finally making decisions through reinforcement learning. While this modular approach has demonstrated effectiveness, it may also lead to redundant information processing and inconsistencies in information transmission between the various modules during the feature fusion and GRU sequence modeling phases. This paper presents IRCAM-AVN (Iterative Residual Cross-Attention Mechanism for Audiovisual Navigation), an end-to-end framework that integrates multimodal information fusion and sequence modeling within a unified IRCAM module, thereby replacing the traditional separate components for fusion and GRU. This innovative mechanism employs a multi-level residual design that concatenates initial multimodal sequences with processed information sequences. This methodological shift progressively optimizes the feature extraction process while reducing model bias and enhancing the model's stability and generalization capabilities. Empirical results indicate that intelligent agents employing the iterative residual cross-attention mechanism exhibit superior navigation performance.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹éŸ³è§†é¢‘å¯¼èˆª (Audio-Visual Navigation) ä»»åŠ¡ä¸­ä¼ ç»Ÿæ¨¡å—åŒ–è®¾è®¡å¯¼è‡´çš„å†—ä½™å’Œä¿¡æ¯ä¼ è¾“ä¸ä¸€è‡´é—®é¢˜ï¼Œæå‡ºäº† IRCAM-AVN æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡ä¸€ä¸ªç»Ÿä¸€çš„è¿­ä»£æ®‹å·®äº¤å‰æ³¨æ„åŠ›æœºåˆ¶ (Iterative Residual Cross-Attention Mechanism) æ¨¡å—ï¼Œå°†å¤šæ¨¡æ€ä¿¡æ¯èåˆä¸åºåˆ—å»ºæ¨¡é›†æˆåœ¨ä¸€èµ·ï¼Œå–ä»£äº†ä¼ ç»Ÿçš„èåˆç»„ä»¶å’Œ Gated Recurrent Unit (GRU) æ¨¡å—ã€‚IRCAM é‡‡ç”¨å¤šçº§æ®‹å·®è®¾è®¡ (multi-level residual design)ï¼Œå°†åŸå§‹å¤šæ¨¡æ€åºåˆ—ä¸å¤„ç†åçš„ä¿¡æ¯åºåˆ—ç›¸è¿æ¥ï¼Œé€æ­¥ä¼˜åŒ–ç‰¹å¾æå–è¿‡ç¨‹ã€‚è¿™ç§æ•´åˆæ–¹å¼æœ‰æ•ˆå‡å°‘äº†æ¨¡å‹åå·®ï¼Œå¹¶å¢å¼ºäº†æ™ºèƒ½ä½“åœ¨å¤æ‚ç¯å¢ƒä¸‹çš„ç¨³å®šæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œé‡‡ç”¨è¯¥æœºåˆ¶çš„æ™ºèƒ½ä½“åœ¨å¯¼èˆªæ€§èƒ½ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œè¯æ˜äº†ç«¯åˆ°ç«¯é›†æˆæ¶æ„åœ¨å¤„ç†éŸ³è§†é¢‘æ„ŸçŸ¥ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.AI",
        "cs.MM",
        "cs.SD"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted for publication by IEEE International Conference on Systems, Man, and Cybernetics 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.25652v1",
      "published_date": "2025-09-30 01:52:57 UTC",
      "updated_date": "2025-09-30 01:52:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:48:07.094493+00:00"
    },
    {
      "arxiv_id": "2509.25651v1",
      "title": "AutoLabs: Cognitive Multi-Agent Systems with Self-Correction for Autonomous Chemical Experimentation",
      "title_zh": "AutoLabsï¼šå…·å¤‡è‡ªæˆ‘ä¿®æ­£èƒ½åŠ›çš„è‡ªä¸»åŒ–å­¦å®éªŒè®¤çŸ¥å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ",
      "authors": [
        "Gihan Panapitiya",
        "Emily Saldanha",
        "Heather Job",
        "Olivia Hess"
      ],
      "abstract": "The automation of chemical research through self-driving laboratories (SDLs) promises to accelerate scientific discovery, yet the reliability and granular performance of the underlying AI agents remain critical, under-examined challenges. In this work, we introduce AutoLabs, a self-correcting, multi-agent architecture designed to autonomously translate natural-language instructions into executable protocols for a high-throughput liquid handler. The system engages users in dialogue, decomposes experimental goals into discrete tasks for specialized agents, performs tool-assisted stoichiometric calculations, and iteratively self-corrects its output before generating a hardware-ready file. We present a comprehensive evaluation framework featuring five benchmark experiments of increasing complexity, from simple sample preparation to multi-plate timed syntheses. Through a systematic ablation study of 20 agent configurations, we assess the impact of reasoning capacity, architectural design (single- vs. multi-agent), tool use, and self-correction mechanisms. Our results demonstrate that agent reasoning capacity is the most critical factor for success, reducing quantitative errors in chemical amounts (nRMSE) by over 85% in complex tasks. When combined with a multi-agent architecture and iterative self-correction, AutoLabs achieves near-expert procedural accuracy (F1-score > 0.89) on challenging multi-step syntheses. These findings establish a clear blueprint for developing robust and trustworthy AI partners for autonomous laboratories, highlighting the synergistic effects of modular design, advanced reasoning, and self-correction to ensure both performance and reliability in high-stakes scientific applications. Code: https://github.com/pnnl/autolabs",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† AutoLabsï¼Œè¿™æ˜¯ä¸€ç§å…·æœ‰è‡ªæˆ‘ä¿®æ­£èƒ½åŠ›çš„è®¤çŸ¥å¤šæ™ºèƒ½ä½“(Multi-Agent)ç³»ç»Ÿæ¶æ„ï¼Œæ—¨åœ¨é€šè¿‡è‡ªåŠ¨é©¾é©¶å®éªŒå®¤(SDLs)å®ç°è‡ªä¸»åŒ–å­¦å®éªŒå¹¶åŠ é€Ÿç§‘å­¦å‘ç°ã€‚è¯¥ç³»ç»Ÿèƒ½å¤Ÿå°†è‡ªç„¶è¯­è¨€æŒ‡ä»¤è½¬åŒ–ä¸ºé«˜é€šé‡æ¶²ä½“å¤„ç†å™¨çš„å¯æ‰§è¡Œåè®®ï¼Œé€šè¿‡ä»»åŠ¡åˆ†è§£ã€å·¥å…·è¾…åŠ©çš„åŒ–å­¦è®¡é‡è®¡ç®—ä»¥åŠè¿­ä»£è‡ªæˆ‘ä¿®æ­£æœºåˆ¶ï¼Œåœ¨ç”Ÿæˆç¡¬ä»¶å°±ç»ªæ–‡ä»¶å‰ç¡®ä¿å®éªŒæ–¹æ¡ˆçš„ç²¾ç¡®æ€§ã€‚ç ”ç©¶äººå‘˜é€šè¿‡äº”ä¸ªä¸åŒå¤æ‚åº¦çš„åŸºå‡†å®éªŒå’Œæ¶µç›– 20 ç§æ™ºèƒ½ä½“é…ç½®çš„æ¶ˆèç ”ç©¶ï¼Œè¯å®äº†æ¨ç†èƒ½åŠ›(Reasoning Capacity)æ˜¯ç³»ç»ŸæˆåŠŸçš„å…³é”®å› ç´ ï¼Œåœ¨å¤æ‚ä»»åŠ¡ä¸­å¯å°†åŒ–å­¦ç”¨é‡çš„å®šé‡è¯¯å·®(nRMSE)é™ä½ 85% ä»¥ä¸Šã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œç»“åˆå¤šæ™ºèƒ½ä½“æ¶æ„ä¸è¿­ä»£è‡ªæˆ‘ä¿®æ­£çš„ AutoLabs åœ¨æŒ‘æˆ˜æ€§çš„å¤šæ­¥åˆæˆä»»åŠ¡ä¸­è¡¨ç°å‡ºæ¥è¿‘ä¸“å®¶æ°´å¹³çš„å‡†ç¡®åº¦(F1-score > 0.89)ã€‚è¯¥ç ”ç©¶ä¸ºæ„å»ºç¨³å¥ã€å¯ä¿¡çš„è‡ªä¸»å®éªŒå®¤ AI åˆä½œä¼™ä¼´æä¾›äº†æ˜ç¡®çš„æŠ€æœ¯è“å›¾ï¼Œçªæ˜¾äº†æ¨¡å—åŒ–è®¾è®¡ã€é«˜çº§æ¨ç†ä¸è‡ªæˆ‘ä¿®æ­£æœºåˆ¶åœ¨é«˜æ€§èƒ½ç§‘ç ”è‡ªåŠ¨åŒ–åº”ç”¨ä¸­çš„ååŒä½œç”¨ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25651v1",
      "published_date": "2025-09-30 01:51:46 UTC",
      "updated_date": "2025-09-30 01:51:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:48:14.081726+00:00"
    },
    {
      "arxiv_id": "2509.25647v1",
      "title": "BaB-prob: Branch and Bound with Preactivation Splitting for Probabilistic Verification of Neural Networks",
      "title_zh": "BaB-probï¼šåŸºäºå‰æ¿€æ´»åˆ†è£‚çš„ç¥ç»ç½‘ç»œæ¦‚ç‡éªŒè¯åˆ†æ”¯å®šç•Œæ–¹æ³•",
      "authors": [
        "Fangji Wang",
        "Panagiotis Tsiotras"
      ],
      "abstract": "Branch-and-bound with preactivation splitting has been shown highly effective for deterministic verification of neural networks. In this paper, we extend this framework to the probabilistic setting. We propose BaB-prob that iteratively divides the original problem into subproblems by splitting preactivations and leverages linear bounds computed by linear bound propagation to bound the probability for each subproblem. We prove soundness and completeness of BaB-prob for feedforward-ReLU neural networks. Furthermore, we introduce the notion of uncertainty level and design two efficient strategies for preactivation splitting, yielding BaB-prob-ordered and BaB+BaBSR-prob. We evaluate BaB-prob on untrained networks, MNIST and CIFAR-10 models, respectively, and VNN-COMP 2025 benchmarks. Across these settings, our approach consistently outperforms state-of-the-art approaches in medium- to high-dimensional input problems.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† BaB-probï¼Œå°†å¸¦æœ‰ Preactivation Splitting çš„ Branch-and-Bound æ¡†æ¶æ‰©å±•è‡³ç¥ç»ç½‘ç»œçš„æ¦‚ç‡éªŒè¯ (Probabilistic Verification) é¢†åŸŸã€‚è¯¥æ–¹æ³•é€šè¿‡è¿­ä»£åˆ†å‰²é¢„æ¿€æ´»å±‚å°†å¤æ‚é—®é¢˜åˆ’åˆ†ä¸ºå­é—®é¢˜ï¼Œå¹¶ç»“åˆçº¿æ€§è¾¹ç•Œä¼ æ’­ (Linear Bound Propagation) æŠ€æœ¯æ¥ç²¾ç¡®ç•Œå®šå„å­é—®é¢˜çš„æ¦‚ç‡è¾¹ç•Œã€‚ç ”ç©¶è€…åœ¨ç†è®ºä¸Šè¯æ˜äº† BaB-prob åœ¨ Feedforward-ReLU ç¥ç»ç½‘ç»œä¸­å…·æœ‰å¯é æ€§ (Soundness) å’Œå®Œå¤‡æ€§ (Completeness)ã€‚æ­¤å¤–ï¼Œé€šè¿‡å¼•å…¥ä¸ç¡®å®šæ€§æ°´å¹³ (Uncertainty Level) æ¦‚å¿µï¼Œç ”ç©¶è¿›ä¸€æ­¥è®¾è®¡äº† BaB-prob-ordered å’Œ BaB+BaBSR-prob ä¸¤ç§é«˜æ•ˆçš„åˆ†å‰²ç­–ç•¥ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨æœªç»è®­ç»ƒçš„ç½‘ç»œã€MNISTã€CIFAR-10 ä»¥åŠ VNN-COMP 2025 ç­‰å¤šé¡¹åŸºå‡†æµ‹è¯•ä¸­å‡è¡¨ç°å‡ºè‰²ã€‚å°¤å…¶åœ¨ä¸­é«˜ç»´è¾“å…¥é—®é¢˜ä¸Šï¼ŒBaB-prob çš„æ€§èƒ½æŒç»­ä¼˜äºç°æœ‰çš„å…ˆè¿› (State-of-the-art) ç®—æ³•ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25647v1",
      "published_date": "2025-09-30 01:39:39 UTC",
      "updated_date": "2025-09-30 01:39:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:48:17.987063+00:00"
    },
    {
      "arxiv_id": "2509.25643v3",
      "title": "SOCK: A Benchmark for Measuring Self-Replication in Large Language Models",
      "title_zh": "SOCKï¼šå¤§è¯­è¨€æ¨¡å‹è‡ªæˆ‘å¤åˆ¶èƒ½åŠ›è¯„æµ‹åŸºå‡†",
      "authors": [
        "Justin Chavarria",
        "Rohan Raizada",
        "Justin White",
        "Eyad Alhetairshi"
      ],
      "abstract": "We introduce SOCK, a benchmark command line interface (CLI) that measures large language models' (LLMs) ability to self-replicate without human intervention. In this benchmark, self-replication is defined not only as an LLM's ability to create a functioning and running copy of itself, but also the ability for that self-replication to persist and occur across different computational contexts. Accordingly, we've developed a system to categorize LLMs based on broad self-replication capabilities in two general classes, Replication-Capability Levels (RCL) and Persistence-Capability Levels (PCL). Using a five-task suite based on practically manipulable modern CLI utilities and computer processes, experiments are orchestrated in a controlled environment with an LLM acting agentically. The performance of the LLM on agent tasks is then computed to produce an R-score (a quantitative evaluation of overall self-replication ability) and data used to categorize LLMs into specific RCL-PCL matrices. SOCK offers two primary contributions: (1) Provides the first formalized definitions and benchmark suite for evaluating LLM self-replication, with the goal of establishing a standard for future research, to our knowledge; (2) Allows the industry to track the effectiveness of future multi-agent systems and mitigate potential self-replication threat vectors within them. The results compiled from evaluating a variety of open-weight and proprietary frontier models reveal significant obstacles to persistent self-replication and multi-agent systems, including context retention and multi-agent decision-making. We propose future research directions to safely reduce the severity of these obstacles, potentially lowering future risk of more functional multi-agent systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† SOCKï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ (Large Language Models, LLMs) åœ¨æ— éœ€äººç±»å¹²é¢„çš„æƒ…å†µä¸‹è¿›è¡Œè‡ªæˆ‘å¤åˆ¶ (Self-Replication) èƒ½åŠ›çš„å‘½ä»¤è¡Œç•Œé¢ (CLI) åŸºå‡†æµ‹è¯•ã€‚è¯¥åŸºå‡†å°†è‡ªæˆ‘å¤åˆ¶å®šä¹‰ä¸ºæ¨¡å‹ä¸ä»…èƒ½åˆ›å»ºè‡ªèº«çš„åŠŸèƒ½æ€§è¿è¡Œå‰¯æœ¬ï¼Œè¿˜èƒ½åœ¨ä¸åŒçš„è®¡ç®—ä¸Šä¸‹æ–‡ä¸­æŒç»­å‘ç”Ÿã€‚ç ”ç©¶å›¢é˜Ÿå¼€å‘äº†å¤åˆ¶èƒ½åŠ›ç­‰çº§ (Replication-Capability Levels, RCL) å’ŒæŒä¹…æ€§èƒ½åŠ›ç­‰çº§ (Persistence-Capability Levels, PCL) åˆ†ç±»ä½“ç³»ï¼Œé€šè¿‡åŒ…å«äº”é¡¹ä»»åŠ¡çš„æµ‹è¯•å¥—ä»¶åœ¨å—æ§ç¯å¢ƒä¸­è¿›è¡Œå®éªŒï¼Œå¹¶è®¡ç®— R-score ä»¥å®šé‡è¯„ä¼°æ¨¡å‹çš„ç»¼åˆè‡ªæˆ‘å¤åˆ¶èƒ½åŠ›ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œç›®å‰çš„å¼€æºå’Œé—­æºå‰æ²¿æ¨¡å‹åœ¨å®ç°æŒä¹…æ€§è‡ªæˆ‘å¤åˆ¶å’Œå¤šæ™ºèƒ½ä½“å†³ç­–æ–¹é¢ä»é¢ä¸´ä¸Šä¸‹æ–‡ä¿ç•™ (Context Retention) ç­‰æ˜¾è‘—éšœç¢ã€‚SOCK ä¸ºè¯„ä¼° LLM è‡ªæˆ‘å¤åˆ¶æä¾›äº†é¦–ä¸ªå½¢å¼åŒ–å®šä¹‰å’Œæ ‡å‡†åŸºå‡†ï¼Œæœ‰åŠ©äºè¡Œä¸šè¿½è¸ªå¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„æœ‰æ•ˆæ€§å¹¶å‡è½»æ½œåœ¨çš„é£é™©å‘é‡ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25643v3",
      "published_date": "2025-09-30 01:27:46 UTC",
      "updated_date": "2025-12-09 14:21:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:48:20.690866+00:00"
    },
    {
      "arxiv_id": "2510.00075v1",
      "title": "NeurIPS should lead scientific consensus on AI policy",
      "title_zh": "NeurIPS åº”å¼•é¢†äººå·¥æ™ºèƒ½æ”¿ç­–é¢†åŸŸçš„ç§‘å­¦å…±è¯†",
      "authors": [
        "Rishi Bommasani"
      ],
      "abstract": "Designing wise AI policy is a grand challenge for society. To design such policy, policymakers should place a premium on rigorous evidence and scientific consensus. While several mechanisms exist for evidence generation, and nascent mechanisms tackle evidence synthesis, we identify a complete void on consensus formation. In this position paper, we argue NeurIPS should actively catalyze scientific consensus on AI policy. Beyond identifying the current deficit in consensus formation mechanisms, we argue that NeurIPS is the best option due its strengths and the paucity of compelling alternatives. To make progress, we recommend initial pilots for NeurIPS by distilling lessons from the IPCC's leadership to build scientific consensus on climate policy. We dispel predictable counters that AI researchers disagree too much to achieve consensus and that policy engagement is not the business of NeurIPS. NeurIPS leads AI on many fronts, and it should champion scientific consensus to create higher quality AI policy.",
      "tldr_zh": "è¿™ç¯‡ç«‹åœºè®ºæ–‡æŒ‡å‡º NeurIPS åº”å½“åœ¨ AI policy çš„ç§‘å­¦å…±è¯†å½¢æˆä¸­å‘æŒ¥é¢†å¯¼ä½œç”¨ï¼Œä»¥åº”å¯¹å½“å‰ç¤¾ä¼šåœ¨åˆ¶å®šæ˜æ™ºæ”¿ç­–æ–¹é¢é¢ä¸´çš„å·¨å¤§æŒ‘æˆ˜ã€‚ä½œè€…è¯†åˆ«å‡ºåœ¨è¯æ®ç”Ÿæˆå’Œç»¼åˆæœºåˆ¶ä¹‹å¤–ï¼Œç›®å‰æåº¦ç¼ºä¹æœ‰æ•ˆçš„å…±è¯†å½¢æˆ(consensus formation)æœºåˆ¶ã€‚è®ºæ–‡è®¤ä¸ºï¼Œå‡­å€Ÿå…¶åœ¨å­¦æœ¯ç•Œçš„å½±å“åŠ›å’Œèµ„æºï¼ŒNeurIPS æ˜¯æ¨åŠ¨ AI æ”¿ç­–ç§‘å­¦å…±è¯†çš„æœ€ä½³å¹³å°ï¼Œä¸”ç›®å‰ç¼ºä¹å…¶ä»–æœ‰ç«äº‰åŠ›çš„æ›¿ä»£æ–¹æ¡ˆã€‚ä¸ºå®ç°è¿™ä¸€ç›®æ ‡ï¼Œä½œè€…å»ºè®® NeurIPS å€Ÿé‰´ IPCC åœ¨æ°”å€™æ”¿ç­–é¢†åŸŸçš„é¢†å¯¼ç»éªŒï¼Œå¼€å±•åˆæ­¥çš„è¯•ç‚¹é¡¹ç›®ã€‚è®ºæ–‡è¿›ä¸€æ­¥åé©³äº† AI ç ”ç©¶è€…ä¹‹é—´åˆ†æ­§è¿‡å¤§è€Œæ— æ³•è¾¾æˆå…±è¯†ï¼Œä»¥åŠæ”¿ç­–å‚ä¸ä¸å±äº NeurIPS ä¸šåŠ¡èŒƒå›´ç­‰å¸¸è§åé©³è§‚ç‚¹ã€‚è¯¥ç ”ç©¶æœ€ç»ˆå‘¼å NeurIPS åº”å½“é€šè¿‡ç¡®ç«‹ç§‘å­¦å…±è¯†æ¥æå‡ AI policy çš„è´¨é‡ï¼Œä»è€Œåœ¨å¤šä¸ªå‰æ²¿é¢†åŸŸç»§ç»­å¼•é¢† AI çš„å‘å±•ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Published at NeurIPS 2025",
      "pdf_url": "https://arxiv.org/pdf/2510.00075v1",
      "published_date": "2025-09-30 01:08:29 UTC",
      "updated_date": "2025-09-30 01:08:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:48:25.087103+00:00"
    },
    {
      "arxiv_id": "2510.02376v1",
      "title": "Scaling Homomorphic Applications in Deployment",
      "title_zh": "åŒæ€åº”ç”¨åœ¨éƒ¨ç½²ä¸­çš„è§„æ¨¡åŒ–æ‰©å±•",
      "authors": [
        "Ryan Marinelli",
        "Angelica Chowdhury"
      ],
      "abstract": "In this endeavor, a proof-of-concept homomorphic application is developed to determine the production readiness of encryption ecosystems. A movie recommendation app is implemented for this purpose and productionized through containerization and orchestration. By tuning deployment configurations, the computational limitations of Fully Homomorphic Encryption (FHE) are mitigated through additional infrastructure optimizations\n  Index Terms: Reinforcement Learning, Orchestration, Homomorphic Encryption",
      "tldr_zh": "è¯¥ç ”ç©¶å¼€å‘äº†ä¸€ä¸ªæ¦‚å¿µéªŒè¯å‹çš„åŒæ€åŠ å¯†åº”ç”¨ï¼Œæ—¨åœ¨è¯„ä¼°åŠ å¯†ç”Ÿæ€ç³»ç»Ÿçš„ç”Ÿäº§å°±ç»ªæ€§ã€‚ç ”ç©¶äººå‘˜å®ç°äº†ä¸€ä¸ªç”µå½±æ¨èåº”ç”¨ç¨‹åºï¼Œå¹¶é€šè¿‡å®¹å™¨åŒ–(containerization)å’Œç¼–æ’(orchestration)æŠ€æœ¯å°†å…¶æŠ•å…¥ç”Ÿäº§ç¯å¢ƒã€‚é’ˆå¯¹å…¨åŒæ€åŠ å¯†(Fully Homomorphic Encryption, FHE)å¸¦æ¥çš„è®¡ç®—é™åˆ¶ï¼Œè¯¥ç ”ç©¶é€šè¿‡è°ƒæ•´éƒ¨ç½²é…ç½®å’ŒåŸºç¡€è®¾æ–½ä¼˜åŒ–æœ‰æ•ˆåœ°ç¼“è§£äº†æ€§èƒ½ç“¶é¢ˆã€‚é€šè¿‡ç»“åˆå¼ºåŒ–å­¦ä¹ (Reinforcement Learning)ä¸è‡ªåŠ¨åŒ–ç¼–æ’ï¼Œè¯¥å·¥ä½œå±•ç¤ºäº†åœ¨å®é™…éƒ¨ç½²åœºæ™¯ä¸­æ‰©å±•åŒæ€åŠ å¯†åº”ç”¨çš„å¯è¡Œæ€§ï¼Œä¸ºåŠ å¯†ç”Ÿæ€ç³»ç»Ÿçš„å·¥ä¸šåŒ–è½åœ°æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "5 pages, 6 figures, 1 pseudo code",
      "pdf_url": "https://arxiv.org/pdf/2510.02376v1",
      "published_date": "2025-09-30 00:42:55 UTC",
      "updated_date": "2025-09-30 00:42:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:48:33.989631+00:00"
    },
    {
      "arxiv_id": "2509.25624v1",
      "title": "STAC: When Innocent Tools Form Dangerous Chains to Jailbreak LLM Agents",
      "title_zh": "STACï¼šå½“æ— å®³å·¥å…·å½¢æˆå®ç°å¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“è¶Šç‹±çš„å±é™©é“¾æ¡",
      "authors": [
        "Jing-Jing Li",
        "Jianfeng He",
        "Chao Shang",
        "Devang Kulshreshtha",
        "Xun Xian",
        "Yi Zhang",
        "Hang Su",
        "Sandesh Swamy",
        "Yanjun Qi"
      ],
      "abstract": "As LLMs advance into autonomous agents with tool-use capabilities, they introduce security challenges that extend beyond traditional content-based LLM safety concerns. This paper introduces Sequential Tool Attack Chaining (STAC), a novel multi-turn attack framework that exploits agent tool use. STAC chains together tool calls that each appear harmless in isolation but, when combined, collectively enable harmful operations that only become apparent at the final execution step. We apply our framework to automatically generate and systematically evaluate 483 STAC cases, featuring 1,352 sets of user-agent-environment interactions and spanning diverse domains, tasks, agent types, and 10 failure modes. Our evaluations show that state-of-the-art LLM agents, including GPT-4.1, are highly vulnerable to STAC, with attack success rates (ASR) exceeding 90% in most cases. The core design of STAC's automated framework is a closed-loop pipeline that synthesizes executable multi-step tool chains, validates them through in-environment execution, and reverse-engineers stealthy multi-turn prompts that reliably induce agents to execute the verified malicious sequence. We further perform defense analysis against STAC and find that existing prompt-based defenses provide limited protection. To address this gap, we propose a new reasoning-driven defense prompt that achieves far stronger protection, cutting ASR by up to 28.8%. These results highlight a crucial gap: defending tool-enabled agents requires reasoning over entire action sequences and their cumulative effects, rather than evaluating isolated prompts or responses.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å…·å¤‡å·¥å…·è°ƒç”¨èƒ½åŠ›çš„è‡ªä¸»å¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“ (LLM agents) é¢ä¸´çš„å®‰å…¨æŒ‘æˆ˜ï¼Œæå‡ºäº†åä¸º Sequential Tool Attack Chaining (STAC) çš„æ–°å‹å¤šè½®æ”»å‡»æ¡†æ¶ã€‚STAC é€šè¿‡å°†å¤šä¸ªå­¤ç«‹çœ‹æ¥çœ‹ä¼¼æ— å®³çš„å·¥å…·è°ƒç”¨ä¸²è”æˆé“¾ï¼Œåœ¨æœ€ç»ˆæ‰§è¡Œé˜¶æ®µå®ç°å…·æœ‰ç ´åæ€§çš„æ“ä½œï¼Œä»è€Œè§„é¿äº†ä¼ ç»Ÿçš„åŸºäºå†…å®¹çš„å®‰å…¨æ€§å®¡æŸ¥ã€‚ç ”ç©¶å›¢é˜Ÿæ„å»ºäº†ä¸€ä¸ªé—­ç¯æµæ°´çº¿ï¼Œç”¨äºè‡ªåŠ¨åˆæˆå¯æ‰§è¡Œçš„å¤šæ­¥å·¥å…·é“¾ï¼Œé€šè¿‡ç¯å¢ƒå†…æ‰§è¡Œè¿›è¡ŒéªŒè¯ï¼Œå¹¶é€†å‘å·¥ç¨‹å‡ºèƒ½å¤Ÿè¯±å¯¼æ™ºèƒ½ä½“æ‰§è¡Œè¿™äº›æ¶æ„åºåˆ—çš„éšè”½å¤šè½®æç¤ºè¯ã€‚åœ¨æ¶µç›– 10 ç§å¤±è´¥æ¨¡å¼å’Œå¤šä¸ªé¢†åŸŸçš„ 483 ä¸ªæ¡ˆä¾‹è¯„ä¼°ä¸­ï¼ŒåŒ…æ‹¬ GPT-4.1 åœ¨å†…çš„æœ€å…ˆè¿›æ¨¡å‹è¡¨ç°å‡ºé«˜åº¦è„†å¼±æ€§ï¼Œå¤šæ•°æƒ…å†µä¸‹çš„æ”»å‡»æˆåŠŸç‡ (ASR) è¶…è¿‡ 90%ã€‚é’ˆå¯¹ç°æœ‰é˜²å¾¡æ‰‹æ®µæ•ˆæœæœ‰é™çš„é—®é¢˜ï¼Œç ”ç©¶æå‡ºäº†ä¸€ç§æ–°çš„æ¨ç†é©±åŠ¨é˜²å¾¡æç¤ºè¯ï¼ŒæˆåŠŸå°† ASR æœ€é«˜é™ä½äº† 28.8%ã€‚è¯¥ç ”ç©¶ç»“æœå¼ºè°ƒï¼Œä¿æŠ¤å·¥å…·å¢å¼ºå‹æ™ºèƒ½ä½“éœ€è¦å¯¹æ•´ä¸ªè¡ŒåŠ¨åºåˆ—åŠå…¶ç´¯ç§¯æ•ˆåº”è¿›è¡Œé€»è¾‘æ¨ç†ï¼Œè€Œéä»…ä»…è¯„ä¼°å­¤ç«‹çš„æç¤ºè¯æˆ–å“åº”ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25624v1",
      "published_date": "2025-09-30 00:31:44 UTC",
      "updated_date": "2025-09-30 00:31:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:48:55.490526+00:00"
    },
    {
      "arxiv_id": "2509.25618v1",
      "title": "Quadratic Programming Approach for Nash Equilibrium Computation in Multiplayer Imperfect-Information Games",
      "title_zh": "å¤šäººä¸å®Œç¾ä¿¡æ¯åšå¼ˆçº³ä»€å‡è¡¡è®¡ç®—çš„äºŒæ¬¡è§„åˆ’æ–¹æ³•",
      "authors": [
        "Sam Ganzfried"
      ],
      "abstract": "There has been significant recent progress in algorithms for approximation of Nash equilibrium in large two-player zero-sum imperfect-information games and exact computation of Nash equilibrium in multiplayer strategic-form games. While counterfactual regret minimization and fictitious play are scalable to large games and have convergence guarantees in two-player zero-sum games, they do not guarantee convergence to Nash equilibrium in multiplayer games. We present an approach for exact computation of Nash equilibrium in multiplayer imperfect-information games that solves a quadratically-constrained program based on a nonlinear complementarity problem formulation from the sequence-form game representation. This approach capitalizes on recent advances for solving nonconvex quadratic programs. Our algorithm is able to quickly solve three-player Kuhn poker after removal of dominated actions. Of the available algorithms in the Gambit software suite, only the logit quantal response approach is successfully able to solve the game; however, the approach takes longer than our algorithm and also involves a degree of approximation. Our formulation also leads to a new approach for computing Nash equilibrium in multiplayer strategic-form games which we demonstrate to outperform a previous quadratically-constrained program formulation.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šç©å®¶ä¸å®Œå…¨ä¿¡æ¯åšå¼ˆ (multiplayer imperfect-information games) ä¸­çº³ä»€å‡è¡¡ (Nash Equilibrium) çš„ç²¾ç¡®è®¡ç®—é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºäºŒæ¬¡è§„åˆ’ (Quadratic Programming) çš„æ–°æ–¹æ³•ã€‚è¯¥æ–¹æ³•åˆ©ç”¨åºåˆ—å½¢å¼åšå¼ˆ (sequence-form game) è¡¨ç¤ºæ„å»ºéçº¿æ€§äº’è¡¥é—®é¢˜ (nonlinear complementarity problem) æ¨¡å‹ï¼Œå¹¶å°†å…¶è½¬åŒ–ä¸ºäºŒæ¬¡çº¦æŸè§„åˆ’ (quadratically-constrained program) è¿›è¡Œæ±‚è§£ã€‚é€šè¿‡åˆ©ç”¨éå‡¸äºŒæ¬¡è§„åˆ’ (nonconvex quadratic programs) æ±‚è§£æŠ€æœ¯çš„æœ€æ–°è¿›å±•ï¼Œè¯¥ç®—æ³•è§£å†³äº†åäº‹å®é—æ†¾æœ€å°åŒ– (CFR) å’Œè™šæ„æ¼”ç»ƒ (fictitious play) åœ¨å¤šç©å®¶åœºæ™¯ä¸‹æ— æ³•ä¿è¯æ”¶æ•›åˆ°çº³ä»€å‡è¡¡çš„ç¼ºé™·ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥ç®—æ³•åœ¨å¤„ç†ä¸‰äººåº“æ©æ‰‘å…‹ (three-player Kuhn poker) æ—¶ä¸ä»…å®ç°äº†ç²¾ç¡®æ±‚è§£ï¼Œä¸”åœ¨è¿è¡Œé€Ÿåº¦ä¸Šä¼˜äº Gambit è½¯ä»¶ä¸­çš„é€»è¾‘åˆ†ä½å“åº”æ–¹æ³•ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶æå‡ºçš„è¡¨è¿°æ–¹å¼åœ¨å¤šç©å®¶ç­–ç•¥å‹åšå¼ˆ (strategic-form games) çš„è®¡ç®—æ€§èƒ½ä¸Šä¹Ÿæ˜¾è‘—è¶…è¶Šäº†ä»¥å¾€çš„äºŒæ¬¡çº¦æŸè§„åˆ’æ¨¡å‹ã€‚",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25618v1",
      "published_date": "2025-09-30 00:28:21 UTC",
      "updated_date": "2025-09-30 00:28:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:48:56.391032+00:00"
    },
    {
      "arxiv_id": "2510.21729v2",
      "title": "CustomIR: Unsupervised Fine-Tuning of Dense Embeddings for Known Document Corpora",
      "title_zh": "CustomIRï¼šé¢å‘å·²çŸ¥æ–‡æ¡£è¯­æ–™åº“çš„ç¨ å¯†åµŒå…¥æ— ç›‘ç£å¾®è°ƒ",
      "authors": [
        "Nathan Paull"
      ],
      "abstract": "Dense embedding models have become critical for modern information retrieval, particularly in RAG pipelines, but their performance often degrades when applied to specialized corpora outside their pre-training distribution. To address thi we introduce CustomIR, a framework for unsupervised adaptation of pre-trained language embedding models to domain-specific corpora using synthetically generated query-document pairs. CustomIR leverages large language models (LLMs) to create diverse queries grounded in a known target corpus, paired with LLM-verified hard negatives, eliminating the need for costly human annotation. Experiments on enterprise email and messaging datasets show that CustomIR consistently improves retrieval effectiveness with small models gaining up to 2.3 points in Recall@10. This performance increase allows these small models to rival the performance of much larger alternatives, allowing for cheaper RAG deployments. These results highlight that targeted synthetic fine-tuning offers a scalable and cost-efficient strategy for increasing domain-specific performance.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç¨ å¯†åµŒå…¥æ¨¡å‹ (Dense embedding models) åœ¨å¤„ç†ç‰¹å®šé¢†åŸŸè¯­æ–™åº“æ—¶æ€§èƒ½ä¸‹é™çš„é—®é¢˜ï¼Œæå‡ºäº† CustomIR æ¡†æ¶ï¼Œæ—¨åœ¨å®ç°é¢„è®­ç»ƒåµŒå…¥æ¨¡å‹å¯¹ç‰¹å®šæ–‡æ¡£é›†çš„æ— ç›‘ç£é€‚é…ã€‚CustomIR åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) åŸºäºç›®æ ‡è¯­æ–™åº“ç”Ÿæˆå¤šæ ·åŒ–çš„åˆæˆæŸ¥è¯¢-æ–‡æ¡£å¯¹ (query-document pairs)ï¼Œå¹¶ç»“åˆ LLM éªŒè¯çš„éš¾è´Ÿæ ·æœ¬ (hard negatives) ä»¥æ¶ˆé™¤å¯¹æ˜‚è´µäººå·¥æ ‡æ³¨çš„éœ€æ±‚ã€‚åœ¨ä¼ä¸šç”µå­é‚®ä»¶å’Œæ¶ˆæ¯æ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜ï¼ŒCustomIR ä¸€è‡´æ€§åœ°æé«˜äº†æ£€ç´¢æ•ˆç‡ï¼Œä½¿å°å‹æ¨¡å‹çš„ Recall@10 æŒ‡æ ‡æœ€é«˜æå‡äº† 2.3 ä¸ªç™¾åˆ†ç‚¹ã€‚è¿™ç§æ€§èƒ½å¢å¼ºè®©å°å‹æ¨¡å‹èƒ½å¤Ÿåª²ç¾ä½“é‡æ›´å¤§çš„æ¨¡å‹ï¼Œä»è€Œå®ç°äº†æ›´ä½æˆæœ¬çš„ RAG éƒ¨ç½²ã€‚ç ”ç©¶ç»“æœå¼ºè°ƒï¼Œé’ˆå¯¹æ€§çš„åˆæˆæ•°æ®å¾®è°ƒä¸ºæå‡ç‰¹å®šé¢†åŸŸæ€§èƒ½æä¾›äº†ä¸€ç§å¯æ‰©å±•ä¸”æå…·æˆæœ¬æ•ˆç›Šçš„ç­–ç•¥ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.21729v2",
      "published_date": "2025-09-30 00:25:47 UTC",
      "updated_date": "2025-10-28 16:15:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:49:06.098217+00:00"
    },
    {
      "arxiv_id": "2509.25613v1",
      "title": "SMS: Self-supervised Model Seeding for Verification of Machine Unlearning",
      "title_zh": "SMSï¼šé¢å‘æœºå™¨é—å¿˜éªŒè¯çš„è‡ªç›‘ç£æ¨¡å‹æ’­ç§æ–¹æ¡ˆ",
      "authors": [
        "Weiqi Wang",
        "Chenhan Zhang",
        "Zhiyi Tian",
        "Shui Yu"
      ],
      "abstract": "Many machine unlearning methods have been proposed recently to uphold users' right to be forgotten. However, offering users verification of their data removal post-unlearning is an important yet under-explored problem. Current verifications typically rely on backdooring, i.e., adding backdoored samples to influence model performance. Nevertheless, the backdoor methods can merely establish a connection between backdoored samples and models but fail to connect the backdoor with genuine samples. Thus, the backdoor removal can only confirm the unlearning of backdoored samples, not users' genuine samples, as genuine samples are independent of backdoored ones. In this paper, we propose a Self-supervised Model Seeding (SMS) scheme to provide unlearning verification for genuine samples. Unlike backdooring, SMS links user-specific seeds (such as users' unique indices), original samples, and models, thereby facilitating the verification of unlearning genuine samples. However, implementing SMS for unlearning verification presents two significant challenges. First, embedding the seeds into the service model while keeping them secret from the server requires a sophisticated approach. We address this by employing a self-supervised model seeding task, which learns the entire sample, including the seeds, into the model's latent space. Second, maintaining the utility of the original service model while ensuring the seeding effect requires a delicate balance. We design a joint-training structure that optimizes both the self-supervised model seeding task and the primary service task simultaneously on the model, thereby maintaining model utility while achieving effective model seeding. The effectiveness of the proposed SMS scheme is evaluated through extensive experiments, which demonstrate that SMS provides effective verification for genuine sample unlearning, addressing existing limitations.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æœºå™¨å­¦ä¹ é—å¿˜(Machine Unlearning)ä¸­ç°æœ‰éªŒè¯æ–¹æ³•ï¼ˆå¦‚backdooringï¼‰ä»…èƒ½éªŒè¯åé—¨æ ·æœ¬ç§»é™¤è€Œæ— æ³•éªŒè¯çœŸå®æ ·æœ¬(genuine samples)è¢«ç§»é™¤çš„é—®é¢˜ï¼Œæå‡ºäº†SMS (Self-supervised Model Seeding) æ–¹æ¡ˆã€‚è¯¥æ–¹æ¡ˆé€šè¿‡å°†ç”¨æˆ·ç‰¹å®šçš„ç§å­(user-specific seeds)ä¸åŸå§‹æ ·æœ¬åŠæ¨¡å‹ç›´æ¥å…³è”ï¼Œå®ç°äº†å¯¹çœŸå®æ•°æ®é—å¿˜æ•ˆæœçš„æœ‰æ•ˆéªŒè¯ã€‚ä¸ºäº†åœ¨å¯¹æœåŠ¡å™¨ä¿å¯†çš„å‰æä¸‹åµŒå…¥ç§å­ï¼ŒSMSé‡‡ç”¨äº†è‡ªç›‘ç£æ’­ç§ä»»åŠ¡å°†ä¿¡æ¯å­¦ä¹ è¿›æ¨¡å‹çš„æ½œç©ºé—´(latent space)ï¼Œå¹¶è®¾è®¡äº†è”åˆè®­ç»ƒ(joint-training)ç»“æ„ä»¥å¹³è¡¡æ’­ç§æ•ˆæœä¸åŸå§‹æœåŠ¡æ¨¡å‹çš„æ•ˆç”¨(utility)ã€‚å¤§é‡å®éªŒè¯æ˜ï¼ŒSMSæˆåŠŸè§£å†³äº†ç°æœ‰æŠ€æœ¯ä¸­åé—¨æ ·æœ¬ä¸çœŸå®æ ·æœ¬ç›¸äº’ç‹¬ç«‹å¯¼è‡´çš„éªŒè¯å±€é™æ€§ï¼Œä¸ºçœŸå®æ ·æœ¬çš„é—å¿˜æä¾›äº†å¯é çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25613v1",
      "published_date": "2025-09-30 00:18:44 UTC",
      "updated_date": "2025-09-30 00:18:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:49:09.992699+00:00"
    },
    {
      "arxiv_id": "2509.25612v1",
      "title": "Unsupervised Detection of Spatiotemporal Anomalies in PMU Data Using Transformer-Based BiGAN",
      "title_zh": "åŸºäº Transformer çš„ BiGAN å®ç° PMU æ•°æ®æ—¶ç©ºå¼‚å¸¸çš„æ— ç›‘ç£æ£€æµ‹",
      "authors": [
        "Muhammad Imran Hossain",
        "Jignesh Solanki",
        "Sarika Khushlani Solanki"
      ],
      "abstract": "Ensuring power grid resilience requires the timely and unsupervised detection of anomalies in synchrophasor data streams. We introduce T-BiGAN, a novel framework that integrates window-attention Transformers within a bidirectional Generative Adversarial Network (BiGAN) to address this challenge. Its self-attention encoder-decoder architecture captures complex spatio-temporal dependencies across the grid, while a joint discriminator enforces cycle consistency to align the learned latent space with the true data distribution. Anomalies are flagged in real-time using an adaptive score that combines reconstruction error, latent space drift, and discriminator confidence. Evaluated on a realistic hardware-in-the-loop PMU benchmark, T-BiGAN achieves an ROC-AUC of 0.95 and an average precision of 0.996, significantly outperforming leading supervised and unsupervised methods. It shows particular strength in detecting subtle frequency and voltage deviations, demonstrating its practical value for live, wide-area monitoring without relying on manually labeled fault data.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç”µç½‘éŸ§æ€§éœ€æ±‚ï¼Œæå‡ºäº† T-BiGANï¼Œä¸€ç§ç”¨äºåŒæ­¥ç›¸é‡æ•°æ®æµ (PMU data) æ— ç›‘ç£å¼‚å¸¸æ£€æµ‹çš„æ–°å‹æ¡†æ¶ã€‚è¯¥æ¡†æ¶å°† window-attention Transformers é›†æˆåˆ°åŒå‘ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ (BiGAN) ä¸­ï¼Œåˆ©ç”¨è‡ªæ³¨æ„åŠ›ç¼–ç å™¨-è§£ç å™¨æ¶æ„æ•æ‰å¤æ‚çš„æ—¶ç©ºä¾èµ–å…³ç³» (spatio-temporal dependencies)ã€‚é€šè¿‡è”åˆåˆ¤åˆ«å™¨å¼ºåˆ¶æ‰§è¡Œå¾ªç¯ä¸€è‡´æ€§ (cycle consistency)ï¼Œä½¿å­¦ä¹ åˆ°çš„æ½œåœ¨ç©ºé—´ä¸çœŸå®æ•°æ®åˆ†å¸ƒå¯¹é½ï¼Œå¹¶åˆ©ç”¨ç»“åˆé‡æ„è¯¯å·®ã€æ½œåœ¨ç©ºé—´åç§»å’Œåˆ¤åˆ«å™¨ç½®ä¿¡åº¦çš„è‡ªé€‚åº”è¯„åˆ†è¿›è¡Œå®æ—¶æ£€æµ‹ã€‚åœ¨ç¡¬ä»¶åœ¨ç¯ (hardware-in-the-loop) PMU åŸºå‡†æµ‹è¯•ä¸­ï¼ŒT-BiGAN å®ç°äº† 0.95 çš„ ROC-AUC å’Œ 0.996 çš„å¹³å‡ç²¾åº¦ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰çš„ç›‘ç£å’Œæ— ç›‘ç£æ–¹æ³•ã€‚è¯¥æ¨¡å‹åœ¨æ£€æµ‹å¾®å°çš„é¢‘ç‡å’Œç”µå‹åå·®æ–¹é¢è¡¨ç°å°¤ä¸ºçªå‡ºï¼Œè¯æ˜äº†å…¶åœ¨æ— éœ€æ‰‹åŠ¨æ ‡è®°æ•…éšœæ•°æ®çš„æƒ…å†µä¸‹ï¼Œå¯¹å¹¿åŸŸç›‘æµ‹ (wide-area monitoring) å…·æœ‰é‡è¦çš„å®ç”¨ä»·å€¼ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.25612v1",
      "published_date": "2025-09-30 00:16:35 UTC",
      "updated_date": "2025-09-30 00:16:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:49:12.289424+00:00"
    },
    {
      "arxiv_id": "2509.25609v1",
      "title": "A Framework for Studying AI Agent Behavior: Evidence from Consumer Choice Experiments",
      "title_zh": "AI æ™ºèƒ½ä½“è¡Œä¸ºç ”ç©¶æ¡†æ¶ï¼šåŸºäºæ¶ˆè´¹è€…é€‰æ‹©å®éªŒçš„è¯æ®",
      "authors": [
        "Manuel Cherep",
        "Chengtian Ma",
        "Abigail Xu",
        "Maya Shaked",
        "Pattie Maes",
        "Nikhil Singh"
      ],
      "abstract": "Environments built for people are increasingly operated by a new class of economic actors: LLM-powered software agents making decisions on our behalf. These decisions range from our purchases to travel plans to medical treatment selection. Current evaluations of these agents largely focus on task competence, but we argue for a deeper assessment: how these agents choose when faced with realistic decisions. We introduce ABxLab, a framework for systematically probing agentic choice through controlled manipulations of option attributes and persuasive cues. We apply this to a realistic web-based shopping environment, where we vary prices, ratings, and psychological nudges, all of which are factors long known to shape human choice. We find that agent decisions shift predictably and substantially in response, revealing that agents are strongly biased choosers even without being subject to the cognitive constraints that shape human biases. This susceptibility reveals both risk and opportunity: risk, because agentic consumers may inherit and amplify human biases; opportunity, because consumer choice provides a powerful testbed for a behavioral science of AI agents, just as it has for the study of human behavior. We release our framework as an open benchmark for rigorous, scalable evaluation of agent decision-making.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† ABxLabï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºç³»ç»Ÿæ¢æµ‹ LLM-powered è½¯ä»¶æ™ºèƒ½ä½“å†³ç­–è¡Œä¸ºçš„æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰è¯„ä¼°è¿‡äºå…³æ³¨ä»»åŠ¡èƒ½åŠ›è€Œå¿½è§†çœŸå®å†³ç­–åå¥½çš„é—®é¢˜ã€‚ç ”ç©¶è€…åœ¨çœŸå®çš„ Web-based è´­ç‰©åœºæ™¯ä¸­ï¼Œé€šè¿‡æ“çºµä»·æ ¼ã€è¯„åˆ†å’Œå¿ƒç†æš—ç¤ºï¼ˆpsychological nudgesï¼‰ç­‰å› ç´ ï¼Œå¯¹æ™ºèƒ½ä½“çš„é€‰æ‹©è¡Œä¸ºè¿›è¡Œäº†å—æ§å®éªŒã€‚ç ”ç©¶å‘ç°ï¼Œæ™ºèƒ½ä½“åœ¨é¢å¯¹è¿™äº›è¯±å¯¼å› ç´ æ—¶è¡¨ç°å‡ºæ˜¾è‘—ä¸”å¯é¢„æµ‹çš„å†³ç­–åç§»ï¼Œè¯æ˜äº†å®ƒä»¬å³ä½¿æ²¡æœ‰äººç±»çš„è®¤çŸ¥çº¦æŸï¼Œä¹Ÿæ˜¯å¸¦æœ‰å¼ºåè§çš„å†³ç­–è€…ã€‚è¿™ç§æ˜“æ„Ÿæ€§æ­ç¤ºäº† AI æ™ºèƒ½ä½“å¯èƒ½ç»§æ‰¿å¹¶æ”¾å¤§äººç±»åè§çš„æ½œåœ¨é£é™©ï¼ŒåŒæ—¶ä¹Ÿä¸ºé€šè¿‡æ¶ˆè´¹è€…é€‰æ‹©å®éªŒå»ºç«‹ AI æ™ºèƒ½ä½“çš„è¡Œä¸ºç§‘å­¦ï¼ˆbehavioral scienceï¼‰æä¾›äº†é‡è¦æœºé‡ã€‚ç›®å‰ï¼Œè¯¥æ¡†æ¶å·²ä½œä¸ºå¼€æºåŸºå‡†ï¼ˆbenchmarkï¼‰å‘å¸ƒï¼Œä¸ºè¯„ä¼°æ™ºèƒ½ä½“å†³ç­–çš„ä¸¥è°¨æ€§ä¸å¯æ‰©å±•æ€§æä¾›äº†æœ‰åŠ›å·¥å…·ã€‚",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "23 pages, 13 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.25609v1",
      "published_date": "2025-09-30 00:05:23 UTC",
      "updated_date": "2025-09-30 00:05:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T23:49:18.098796+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 276,
  "processed_papers_count": 276,
  "failed_papers_count": 0,
  "llm_backup_calls": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-01-24T23:50:21.043876+00:00"
}