{
  "date": "2024-04-16",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-04-16 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 模型优化、语言模型应用、计算机视觉和强化学习等领域，强调了 LLM 在安全、泛化和多模态任务中的潜力，同时探讨了扩散模型和知识图谱的新方法；令人印象深刻的文章包括使用 GPT-4 解决编程挑战的 \"Can Language Models Solve Olympiad Programming?\"，以及高效扩散模型应用的 \"AAVDiff\"。\n\n### LLM 和安全相关论文\n- **不确定性-based 弃权在 LLM 中改善安全性和减少幻觉 (Uncertainty-Based Abstention in LLMs)**：该论文提出使用统计不确定性和对话不确定性指标，让 LLM 在回答不确定问题时选择弃权，从而提升正确率 2%-8%、减少 50% 幻觉并提高 70%-99% 安全性，主要贡献在于为 LLM 部署提供可靠的可靠性提升框架。\n- **LLMem: 估计 GPU 内存使用以微调预训练 LLM (LLMem: Estimating GPU Memory Usage for Fine-Tuning Pre-Trained LLMs)**：作者使用分布式微调方法估计 GPU 内存消耗，错误率低至 1.6%，帮助优化资源受限环境下的 LLM 微调过程，关键在于精确的内存预测公式。\n- **Masked Autoencoders for Microscopy are Scalable Learners of Cellular Biology**：这篇论文展示了自监督掩码自编码器在显微镜图像上的扩展性，显著提升生物图像分析精度，贡献在于构建高效的细胞生物学基础模型。\n- **MiniCheck: Efficient Fact-Checking of LLMs on Grounding Documents**：论文引入小模型进行 LLM 输出事实检查，错误率低于 GPT-4 的 1.6%，主要发现是使用合成数据训练的小模型能高效验证 LLM 幻觉。\n\n这些 LLM 相关工作突出了模型的安全性和高效性，特别是在处理不确定性和事实检查方面，具有实际应用潜力。\n\n### 计算机视觉和生成模型\n- **AAVDiff: Experimental Validation of Enhanced Viability and Diversity in Recombinant Adeno-Associated Virus (AAV) Capsids through Diffusion Generation**：利用扩散模型生成 AAV 病毒蛋白序列，提高了病毒多样性和活性，实验验证显示其在药物设计中的优越性，关键贡献是首次将扩散模型应用于生物医学图像生成。\n- **LaDiC: Are Diffusion Models Really Inferior to Autoregressive Counterparts for Image-to-Text Generation?**：论文证明扩散模型在图像到文本生成中不逊于自回归模型，通过新架构实现 BLEU@4 达 38.2，贡献在于挑战传统认知并提升多模态生成效率。\n- **Masked Autoencoders for Microscopy are Scalable Learners of Cellular Biology**：（已简要提及）扩展到视觉领域，展示了其在生物图像上的可扩展性。\n- **Vision-and-Language Navigation via Causal Learning**：引入因果学习框架提升视觉语言导航精度，相对改善成功率达 35%，主要发现是处理视觉和语言混淆的因果调整机制。\n\n这些论文展示了扩散模型在图像生成和导航中的创新，\"AAVDiff\" 特别值得关注，因为它直接应用于医疗领域。\n\n### 强化学习和机器人\n- **Can Language Models Solve Olympiad Programming?**：作者使用 GPT-4 和自反思方法提升 LLM 在编程奥林匹克任务的准确率至 20.2%，贡献在于首次构建 USACO 基准并探索 LLM 的算法推理潜力。\n- **Dynamics Fairness in Reinforcement Learning**：论文从因果视角分解强化学习中的不公平因素，引入动态公平性概念，通过实验减少不平等，关键在于新的因果分解公式。\n- **Autonomous Implicit Indoor Scene Reconstruction with Frontier Exploration**：提出基于前沿探索的隐式场景重建方法，提高重建质量和效率，贡献在于结合不确定性建模的自主规划策略。\n\n强化学习论文强调公平性和实际应用，\"Can Language Models Solve Olympiad Programming?\" 因其与 GPT-4 的结合而具有话题度。\n\n其他论文如 \"Exploring Augmentation and Cognitive Strategies for AI based Synthetic Personae\" 等涉及 AI 生成和认知策略，但相对次要，仅快速提及：这些工作探索了 LLM 在合成人物和认知框架中的增强方法，提供初步实验支持但未有突破性发现。\n\n总体而言，今天的论文突出了 AI 模型的泛化和应用潜力，但 LLM 安全和视觉生成仍是核心亮点。更多细节可查阅 arXiv。",
  "papers": [
    {
      "arxiv_id": "2404.10960v1",
      "title": "Uncertainty-Based Abstention in LLMs Improves Safety and Reduces Hallucinations",
      "title_zh": "翻译失败",
      "authors": [
        "Christian Tomani",
        "Kamalika Chaudhuri",
        "Ivan Evtimov",
        "Daniel Cremers",
        "Mark Ibrahim"
      ],
      "abstract": "A major barrier towards the practical deployment of large language models\n(LLMs) is their lack of reliability. Three situations where this is\nparticularly apparent are correctness, hallucinations when given unanswerable\nquestions, and safety. In all three cases, models should ideally abstain from\nresponding, much like humans, whose ability to understand uncertainty makes us\nrefrain from answering questions we don't know. Inspired by analogous\napproaches in classification, this study explores the feasibility and efficacy\nof abstaining while uncertain in the context of LLMs within the domain of\nquestion-answering. We investigate two kinds of uncertainties, statistical\nuncertainty metrics and a distinct verbalized measure, termed as In-Dialogue\nUncertainty (InDU). Using these uncertainty measures combined with models with\nand without Reinforcement Learning with Human Feedback (RLHF), we show that in\nall three situations, abstention based on the right kind of uncertainty measure\ncan boost the reliability of LLMs. By sacrificing only a few highly uncertain\nsamples we can improve correctness by 2% to 8%, avoid 50% hallucinations via\ncorrectly identifying unanswerable questions and increase safety by 70% up to\n99% with almost no additional computational overhead.",
      "tldr_zh": "该研究探讨了基于不确定性（uncertainty）的弃权（abstention）机制如何提升大型语言模型（LLMs）的可靠性，针对正确性、幻觉（hallucinations）和安全性的问题。研究使用统计不确定性指标和 In-Dialogue Uncertainty (InDU) 作为衡量标准，并结合有无 Reinforcement Learning with Human Feedback (RLHF) 的模型，允许模型在不确定时选择不回答。结果显示，这种方法能将正确性提高 2% 到 8%，正确识别并避免 50% 的不可回答问题导致的幻觉，并将安全性提升 70% 到 99%，且几乎不增加计算开销。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10960v1",
      "published_date": "2024-04-16 23:56:38 UTC",
      "updated_date": "2024-04-16 23:56:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:46:13.875132"
    },
    {
      "arxiv_id": "2404.10952v1",
      "title": "Can Language Models Solve Olympiad Programming?",
      "title_zh": "语言模型能解决奥林匹克编程吗？",
      "authors": [
        "Quan Shi",
        "Michael Tang",
        "Karthik Narasimhan",
        "Shunyu Yao"
      ],
      "abstract": "Computing olympiads contain some of the most challenging problems for humans,\nrequiring complex algorithmic reasoning, puzzle solving, in addition to\ngenerating efficient code. However, it has been understudied as a domain to\nevaluate language models (LMs). In this paper, we introduce the USACO benchmark\nwith 307 problems from the USA Computing Olympiad, along with high-quality unit\ntests, reference code, and official analyses for each problem. These resources\nenable us to construct and test a range of LM inference methods for competitive\nprogramming for the first time. We find GPT-4 only achieves a 8.7% pass@1\naccuracy with zero-shot chain-of-thought prompting, and our best inference\nmethod improves it to 20.2% using a combination of self-reflection and\nretrieval over episodic knowledge. However, this is far from solving the\nbenchmark. To better understand the remaining challenges, we design a novel\nhuman-in-the-loop study and surprisingly find that a small number of targeted\nhints enable GPT-4 to solve 13 out of 15 problems previously unsolvable by any\nmodel and method. Our benchmark, baseline methods, quantitative results, and\nqualitative analysis serve as an initial step toward LMs with grounded,\ncreative, and algorithmic reasoning.",
      "tldr_zh": "本研究探讨了语言模型（LMs）在计算奥林匹克编程中的表现，引入了USACO基准测试，包含307个问题及其高质量单元测试、参考代码和官方分析，以评估LMs的算法推理和代码生成能力。实验结果显示，GPT-4采用零-shot chain-of-thought prompting仅达到8.7%的pass@1准确率，通过结合self-reflection和retrieval方法提升至20.2%。此外，一项人类参与研究发现，提供少量针对性提示能帮助GPT-4解决更多难题，揭示了LMs在grounded、creative和algorithmic reasoning方面的潜在挑战与改进方向。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.CL",
      "comment": "Code and data: https://princeton-nlp.github.io/USACOBench/",
      "pdf_url": "http://arxiv.org/pdf/2404.10952v1",
      "published_date": "2024-04-16 23:27:38 UTC",
      "updated_date": "2024-04-16 23:27:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:46:26.147338"
    },
    {
      "arxiv_id": "2404.10946v1",
      "title": "Information encoding and decoding in in-vitro neural networks on micro electrode arrays through stimulation timing",
      "title_zh": "翻译失败",
      "authors": [
        "Trym A. E. Lindell",
        "Ola H. Ramstad",
        "Ionna Sandvig",
        "Axel Sandvig",
        "Stefano Nichele"
      ],
      "abstract": "A primary challenge in utilizing in-vitro biological neural networks for\ncomputations is finding good encoding and decoding schemes for inputting and\ndecoding data to and from the networks. Furthermore, identifying the optimal\nparameter settings for a given combination of encoding and decoding schemes\nadds additional complexity to this challenge. In this study we explore\nstimulation timing as an encoding method, i.e. we encode information as the\ndelay between stimulation pulses and identify the bounds and acuity of\nstimulation timings which produce linearly separable spike responses. We also\nexamine the optimal readout parameters for a linear decoder in the form of\nepoch length, time bin size and epoch offset. Our results suggest that\nstimulation timings between 36 and 436ms may be optimal for encoding and that\ndifferent combinations of readout parameters may be optimal at different parts\nof the evoked spike response.",
      "tldr_zh": "本研究探讨了在体外神经网络（in-vitro neural networks）上通过刺激时机进行信息编码和解码的挑战，旨在为计算应用提供有效的方案。研究者使用刺激脉冲之间的延迟作为编码方法，识别出36至436毫秒的刺激时机界限，以产生线性可分的尖峰响应（spike responses）。此外，通过测试线性解码器（linear decoder）的读取参数，如时期长度（epoch length）、时间 bin 大小和时期偏移，发现不同参数组合在唤起尖峰响应的不同阶段可能最优，从而为优化神经网络计算提供了新见解。",
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ],
      "primary_category": "q-bio.NC",
      "comment": "50 pages, 23 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.10946v1",
      "published_date": "2024-04-16 22:59:40 UTC",
      "updated_date": "2024-04-16 22:59:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:46:37.396926"
    },
    {
      "arxiv_id": "2404.10942v2",
      "title": "What Hides behind Unfairness? Exploring Dynamics Fairness in Reinforcement Learning",
      "title_zh": "什么隐藏在不公平背后？",
      "authors": [
        "Zhihong Deng",
        "Jing Jiang",
        "Guodong Long",
        "Chengqi Zhang"
      ],
      "abstract": "In sequential decision-making problems involving sensitive attributes like\nrace and gender, reinforcement learning (RL) agents must carefully consider\nlong-term fairness while maximizing returns. Recent works have proposed many\ndifferent types of fairness notions, but how unfairness arises in RL problems\nremains unclear. In this paper, we address this gap in the literature by\ninvestigating the sources of inequality through a causal lens. We first analyse\nthe causal relationships governing the data generation process and decompose\nthe effect of sensitive attributes on long-term well-being into distinct\ncomponents. We then introduce a novel notion called dynamics fairness, which\nexplicitly captures the inequality stemming from environmental dynamics,\ndistinguishing it from those induced by decision-making or inherited from the\npast. This notion requires evaluating the expected changes in the next state\nand the reward induced by changing the value of the sensitive attribute while\nholding everything else constant. To quantitatively evaluate this\ncounterfactual concept, we derive identification formulas that allow us to\nobtain reliable estimations from data. Extensive experiments demonstrate the\neffectiveness of the proposed techniques in explaining, detecting, and reducing\ninequality in reinforcement learning. We publicly release code at\nhttps://github.com/familyld/InsightFair.",
      "tldr_zh": "本研究探讨了强化学习（Reinforcement Learning, RL）中不公平性的来源，特别是在涉及敏感属性（如种族和性别）的顺序决策问题中，强调了长期公平性与回报最大化的平衡。作者通过因果视角分析数据生成过程，将敏感属性对长期福祉的影响分解为不同组件，并引入了新的动态公平性（Dynamics Fairness）概念，以区分环境动态导致的不平等与决策或历史因素诱发的不平等。该概念通过评估改变敏感属性值（其他条件不变）对下一状态和奖励的预期变化来进行量化，并推导了识别公式以从数据中获取可靠估计。实验结果证明了这些技术的有效性，能够解释、检测和减少RL中的不平等，并公开了相关代码。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, 9 figures, accepted by IJCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.10942v2",
      "published_date": "2024-04-16 22:47:59 UTC",
      "updated_date": "2024-04-28 08:49:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:46:50.407007"
    },
    {
      "arxiv_id": "2404.10934v1",
      "title": "Shears: Unstructured Sparsity with Neural Low-rank Adapter Search",
      "title_zh": "翻译失败",
      "authors": [
        "J. Pablo Muñoz",
        "Jinjie Yuan",
        "Nilesh Jain"
      ],
      "abstract": "Recently, several approaches successfully demonstrated that weight-sharing\nNeural Architecture Search (NAS) can effectively explore a search space of\nelastic low-rank adapters (LoRA), allowing the parameter-efficient fine-tuning\n(PEFT) and compression of large language models. In this paper, we introduce a\nnovel approach called Shears, demonstrating how the integration of\ncost-effective sparsity and a proposed Neural Low-rank adapter Search (NLS)\nalgorithm can further improve the efficiency of PEFT approaches. Results\ndemonstrate the benefits of Shears compared to other methods, reaching high\nsparsity levels while improving or with little drop in accuracy, utilizing a\nsingle GPU for a pair of hours.",
      "tldr_zh": "该论文提出了 Shears 方法，通过整合 unstructured sparsity 和 Neural Low-rank adapter Search (NLS) 算法，进一步提升了参数高效微调 (PEFT) 的效率。\nShears 基于 Neural Architecture Search (NAS) 探索 low-rank adapters (LoRA)，允许在高稀疏度下保持或仅有轻微准确率下降，同时优化了大语言模型的微调和压缩过程。\n实验结果表明，Shears 比其他方法更具优势，仅需单个 GPU 几小时即可实现高效性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "2024 Annual Conference of the North American Chapter of the\n  Association for Computational Linguistics (Industry Track)",
      "pdf_url": "http://arxiv.org/pdf/2404.10934v1",
      "published_date": "2024-04-16 22:12:36 UTC",
      "updated_date": "2024-04-16 22:12:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:47:02.756560"
    },
    {
      "arxiv_id": "2404.10933v1",
      "title": "LLMem: Estimating GPU Memory Usage for Fine-Tuning Pre-Trained LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Taeho Kim",
        "Yanming Wang",
        "Vatshank Chaturvedi",
        "Lokesh Gupta",
        "Seyeon Kim",
        "Yongin Kwon",
        "Sangtae Ha"
      ],
      "abstract": "Fine-tuning pre-trained large language models (LLMs) with limited hardware\npresents challenges due to GPU memory constraints. Various distributed\nfine-tuning methods have been proposed to alleviate memory constraints on GPU.\nHowever, determining the most effective method for achieving rapid fine-tuning\nwhile preventing GPU out-of-memory issues in a given environment remains\nunclear. To address this challenge, we introduce LLMem, a solution that\nestimates the GPU memory consumption when applying distributed fine-tuning\nmethods across multiple GPUs and identifies the optimal method. We conduct GPU\nmemory usage estimation prior to fine-tuning, leveraging the fundamental\nstructure of transformer-based decoder models and the memory usage distribution\nof each method. Experimental results show that LLMem accurately estimates peak\nGPU memory usage on a single GPU, with error rates of up to 1.6%. Additionally,\nit shows an average error rate of 3.0% when applying distributed fine-tuning\nmethods to LLMs with more than a billion parameters on multi-GPU setups.",
      "tldr_zh": "该论文提出LLMem，一种用于估计微调预训练大型语言模型(LLMs)的GPU内存消耗的工具，以帮助在有限硬件环境下选择最佳分布式微调方法。LLMem通过分析Transformer-based解码器模型的基本结构和各方法的内存使用分布，在微调前进行准确预测。实验结果显示，在单GPU上，LLMem的峰值内存估计错误率低至1.6%；在多GPU设置中，对超过十亿参数的LLMs，平均错误率仅为3.0%。这为高效避免GPU内存溢出问题提供了实用解决方案。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 9 figures, accepted to IJCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.10933v1",
      "published_date": "2024-04-16 22:11:35 UTC",
      "updated_date": "2024-04-16 22:11:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:47:13.425811"
    },
    {
      "arxiv_id": "2404.10924v1",
      "title": "Binder: Hierarchical Concept Representation through Order Embedding of Binary Vectors",
      "title_zh": "Binder：通过二进制向量的顺序嵌入实现分层概念表示",
      "authors": [
        "Croix Gyurek",
        "Niloy Talukder",
        "Mohammad Al Hasan"
      ],
      "abstract": "For natural language understanding and generation, embedding concepts using\nan order-based representation is an essential task. Unlike traditional point\nvector based representation, an order-based representation imposes geometric\nconstraints on the representation vectors for explicitly capturing various\nsemantic relationships that may exist between a pair of concepts. In existing\nliterature, several approaches on order-based embedding have been proposed,\nmostly focusing on capturing hierarchical relationships; examples include\nvectors in Euclidean space, complex, Hyperbolic, order, and Box Embedding. Box\nembedding creates region-based rich representation of concepts, but along the\nprocess it sacrifices simplicity, requiring a custom-made optimization scheme\nfor learning the representation. Hyperbolic embedding improves embedding\nquality by exploiting the ever-expanding property of Hyperbolic space, but it\nalso suffers from the same fate as box embedding as gradient descent like\noptimization is not simple in the Hyperbolic space. In this work, we propose\nBinder, a novel approach for order-based representation. Binder uses binary\nvectors for embedding, so the embedding vectors are compact with an order of\nmagnitude smaller footprint than other methods. Binder uses a simple and\nefficient optimization scheme for learning representation vectors with a linear\ntime complexity. Our comprehensive experimental results show that Binder is\nvery accurate, yielding competitive results on the representation task. But\nBinder stands out from its competitors on the transitive closure link\nprediction task as it can learn concept embeddings just from the direct edges,\nwhereas all existing order-based approaches rely on the indirect edges.",
      "tldr_zh": "该论文提出 Binder，一种基于二进制向量的顺序嵌入(order-based representation)方法，用于捕获概念间的层次关系和语义约束。Binder 通过紧凑的二进制向量嵌入实现高效表示，与现有方法如 Box Embedding 和 Hyperbolic embedding 相比，它采用简单线性时间优化的方案，避免了复杂的自定义优化问题。实验结果显示，Binder 在概念表示任务上准确性与竞争方法相当，但在传递闭包链接预测(transitive closure link prediction)任务上表现出色，能仅从直接边学习嵌入，而无需依赖间接边。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10924v1",
      "published_date": "2024-04-16 21:52:55 UTC",
      "updated_date": "2024-04-16 21:52:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:47:26.613746"
    },
    {
      "arxiv_id": "2404.10907v3",
      "title": "Causal Effect Estimation Using Random Hyperplane Tessellations",
      "title_zh": "翻译失败",
      "authors": [
        "Abhishek Dalvi",
        "Neil Ashtekar",
        "Vasant Honavar"
      ],
      "abstract": "Matching is one of the simplest approaches for estimating causal effects from\nobservational data. Matching techniques compare the observed outcomes across\npairs of individuals with similar covariate values but different treatment\nstatuses in order to estimate causal effects. However, traditional matching\ntechniques are unreliable given high-dimensional covariates due to the infamous\ncurse of dimensionality. To overcome this challenge, we propose a simple, fast,\nyet highly effective approach to matching using Random Hyperplane Tessellations\n(RHPT). First, we prove that the RHPT representation is an approximate\nbalancing score -- thus maintaining the strong ignorability assumption -- and\nprovide empirical evidence for this claim. Second, we report results of\nextensive experiments showing that matching using RHPT outperforms traditional\nmatching techniques and is competitive with state-of-the-art deep learning\nmethods for causal effect estimation. In addition, RHPT avoids the need for\ncomputationally expensive training of deep neural networks.",
      "tldr_zh": "该研究针对高维协变量下因果效应估计（Causal Effect Estimation）面临的维度诅咒问题，提出了一种基于 Random Hyperplane Tessellations (RHPT) 的简单高效匹配方法。作者证明 RHPT 是一种近似平衡分数（approximate balancing score），从而维持了强忽略性假设（strong ignorability assumption），并通过实证证据支持这一特性。实验结果显示，该方法优于传统匹配技术，并在性能上与最先进的深度学习方法相当，同时避免了训练深度神经网络的计算开销。总的来说，RHPT 为高维数据下的因果效应估计提供了可靠且高效的解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "At CLeaR 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.10907v3",
      "published_date": "2024-04-16 20:53:58 UTC",
      "updated_date": "2024-09-19 20:40:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:47:38.275692"
    },
    {
      "arxiv_id": "2404.10906v1",
      "title": "Towards a Research Community in Interpretable Reinforcement Learning: the InterpPol Workshop",
      "title_zh": "翻译失败",
      "authors": [
        "Hector Kohler",
        "Quentin Delfosse",
        "Paul Festor",
        "Philippe Preux"
      ],
      "abstract": "Embracing the pursuit of intrinsically explainable reinforcement learning\nraises crucial questions: what distinguishes explainability from\ninterpretability? Should explainable and interpretable agents be developed\noutside of domains where transparency is imperative? What advantages do\ninterpretable policies offer over neural networks? How can we rigorously define\nand measure interpretability in policies, without user studies? What\nreinforcement learning paradigms,are the most suited to develop interpretable\nagents? Can Markov Decision Processes integrate interpretable state\nrepresentations? In addition to motivate an Interpretable RL community centered\naround the aforementioned questions, we propose the first venue dedicated to\nInterpretable RL: the InterpPol Workshop.",
      "tldr_zh": "这篇论文旨在推动可解释强化学习(Interpretable Reinforcement Learning)社区的发展，探讨了关键问题如解释性(explainability)与可解释性(interpretability)的区别、可解释代理是否仅限于透明性要求高的领域，以及可解释策略相对于神经网络的优点。\n它进一步讨论了如何在不进行用户研究的情况下定义和测量策略的可解释性、最适合开发可解释代理的强化学习范式，以及Markov Decision Processes是否能整合可解释的状态表示。\n论文的主要贡献是提出第一个专门针对可解释RL的研讨会InterpPol Workshop，以激发相关研究和社区互动。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.LG",
        "cs.SC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10906v1",
      "published_date": "2024-04-16 20:53:17 UTC",
      "updated_date": "2024-04-16 20:53:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:47:51.088861"
    },
    {
      "arxiv_id": "2404.10901v1",
      "title": "CrossGP: Cross-Day Glucose Prediction Excluding Physiological Information",
      "title_zh": "CrossGP：跨日葡萄糖预测，排除生理信息",
      "authors": [
        "Ziyi Zhou",
        "Ming Cheng",
        "Yanjun Cui",
        "Xingjian Diao",
        "Zhaorui Ma"
      ],
      "abstract": "The increasing number of diabetic patients is a serious issue in society\ntoday, which has significant negative impacts on people's health and the\ncountry's financial expenditures. Because diabetes may develop into potential\nserious complications, early glucose prediction for diabetic patients is\nnecessary for timely medical treatment. Existing glucose prediction methods\ntypically utilize patients' private data (e.g. age, gender, ethnicity) and\nphysiological parameters (e.g. blood pressure, heart rate) as reference\nfeatures for glucose prediction, which inevitably leads to privacy protection\nconcerns. Moreover, these models generally focus on either long-term\n(monthly-based) or short-term (minute-based) predictions. Long-term prediction\nmethods are generally inaccurate because of the external uncertainties that can\ngreatly affect the glucose values, while short-term ones fail to provide timely\nmedical guidance. Based on the above issues, we propose CrossGP, a novel\nmachine-learning framework for cross-day glucose prediction solely based on the\npatient's external activities without involving any physiological parameters.\nMeanwhile, we implement three baseline models for comparison. Extensive\nexperiments on Anderson's dataset strongly demonstrate the superior performance\nof CrossGP and prove its potential for future real-life applications.",
      "tldr_zh": "该论文针对糖尿病血糖预测的隐私问题，提出了一种新型机器学习框架 CrossGP，仅基于患者的外部活动数据（如日常行为），而不涉及任何 physiological parameters，实现跨日血糖预测。相比现有方法，CrossGP 解决了长期预测的不准确性和短期预测的局限性，提供更及时的医疗指导。实验在 Anderson's dataset 上表明，CrossGP 优于三个基线模型，展示了其在实际应用中的潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10901v1",
      "published_date": "2024-04-16 20:40:59 UTC",
      "updated_date": "2024-04-16 20:40:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:48:01.844035"
    },
    {
      "arxiv_id": "2404.10896v1",
      "title": "From a Lossless (~1.5:1) Compression Algorithm for Llama2 7B Weights to Variable Precision, Variable Range, Compressed Numeric Data Types for CNNs and LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Vincenzo Liguori"
      ],
      "abstract": "This paper starts with a simple lossless ~1.5:1 compression algorithm for the\nweights of the Large Language Model (LLM) Llama2 7B [1] that can be implemented\nin ~200 LUTs in AMD FPGAs, processing over 800 million bfloat16 numbers per\nsecond. This framework is then extended to variable precision, variable range,\ncompressed numerical data types that are a user defined super set of both\nfloats and posits [2]. The paper then discusses a simple hardware\nimplementation of such format based on ANS (Asymmetrical Numeral Systems) [3]\nthat acts as a bridge between this flexible data format and a computational\nengine while, at the same time, achieving bandwidth reduction. An example of a\ntoken factory using weight compression and sharing is also given.",
      "tldr_zh": "该论文首先提出了一种无损压缩算法（约1.5:1），针对 Llama2 7B 模型的权重，能够在 AMD FPGA 上使用约200 LUTs 实现，并处理超过800百万 bfloat16 数字每秒。接着，该框架扩展到可变精度、可变范围的压缩数值数据类型，这些类型是 floats 和 posits 的超集，并通过基于 ANS (Asymmetrical Numeral Systems) 的硬件实现，桥接数据格式与计算引擎，同时减少带宽。最后，论文提供了一个使用权重压缩和共享的 token factory 示例，适用于 CNNs 和 LLMs 的高效数据处理。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10896v1",
      "published_date": "2024-04-16 20:37:54 UTC",
      "updated_date": "2024-04-16 20:37:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:48:14.950241"
    },
    {
      "arxiv_id": "2404.10890v1",
      "title": "Exploring Augmentation and Cognitive Strategies for AI based Synthetic Personae",
      "title_zh": "翻译失败",
      "authors": [
        "Rafael Arias Gonzalez",
        "Steve DiPaola"
      ],
      "abstract": "Large language models (LLMs) hold potential for innovative HCI research,\nincluding the creation of synthetic personae. However, their black-box nature\nand propensity for hallucinations pose challenges. To address these\nlimitations, this position paper advocates for using LLMs as data augmentation\nsystems rather than zero-shot generators. We further propose the development of\nrobust cognitive and memory frameworks to guide LLM responses. Initial\nexplorations suggest that data enrichment, episodic memory, and self-reflection\ntechniques can improve the reliability of synthetic personae and open up new\navenues for HCI research.",
      "tldr_zh": "这篇论文探讨了大型语言模型（LLMs）在人机交互（HCI）研究中创建合成人物的潜力，同时解决其黑箱性质和幻觉倾向带来的挑战。主要建议是将LLMs用作数据增强系统，而不是零样本生成器，并开发认知和记忆框架（如episodic memory和self-reflection）来指导模型响应。初步探索显示，这些策略能提升合成人物的可靠性，并为HCI研究开辟新途径。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.IR",
        "I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "This paper was accepted for publication: Proceedings of ACM Conf on\n  Human Factors in Computing Systems (CHI 24), Rafael Arias Gonzalez, Steve\n  DiPaola. Exploring Augmentation and Cognitive Strategies for Synthetic\n  Personae. ACM SigCHI, in Challenges and Opportunities of LLM-Based Synthetic\n  Personae and Data in HCI Workshop, 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.10890v1",
      "published_date": "2024-04-16 20:22:12 UTC",
      "updated_date": "2024-04-16 20:22:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:48:25.349188"
    },
    {
      "arxiv_id": "2404.10889v1",
      "title": "Cognitive-Motor Integration in Assessing Bimanual Motor Skills",
      "title_zh": "翻译失败",
      "authors": [
        "Erim Yanik",
        "Xavier Intes",
        "Suvranu De"
      ],
      "abstract": "Accurate assessment of bimanual motor skills is essential across various\nprofessions, yet, traditional methods often rely on subjective assessments or\nfocus solely on motor actions, overlooking the integral role of cognitive\nprocesses. This study introduces a novel approach by leveraging deep neural\nnetworks (DNNs) to analyze and integrate both cognitive decision-making and\nmotor execution. We tested this methodology by assessing laparoscopic surgery\nskills within the Fundamentals of Laparoscopic Surgery program, which is a\nprerequisite for general surgery certification. Utilizing video capture of\nmotor actions and non-invasive functional near-infrared spectroscopy (fNIRS)\nfor measuring neural activations, our approach precisely classifies subjects by\nexpertise level and predicts FLS behavioral performance scores, significantly\nsurpassing traditional single-modality assessments.",
      "tldr_zh": "本研究针对评估双臂动作技能（bimanual motor skills）的传统方法存在主观性和忽略认知过程的问题，提出了一种整合认知决策与动作执行的创新方法，使用 deep neural networks (DNNs) 进行分析。\n该方法结合视频捕捉动作和 functional near-infrared spectroscopy (fNIRS) 测量神经激活，应用于 Fundamentals of Laparoscopic Surgery (FLS) 程序的腹腔镜手术技能评估。\n结果显示，该方法能精确分类受试者的专业水平并预测行为表现分数，显著优于传统单模态评估，从而为更全面的技能评估提供新途径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages, 3 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2404.10889v1",
      "published_date": "2024-04-16 20:20:23 UTC",
      "updated_date": "2024-04-16 20:20:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:48:38.555029"
    },
    {
      "arxiv_id": "2404.10883v1",
      "title": "Automated Discovery of Functional Actual Causes in Complex Environments",
      "title_zh": "复杂环境中功能实际原因的",
      "authors": [
        "Caleb Chuck",
        "Sankaran Vaidyanathan",
        "Stephen Giguere",
        "Amy Zhang",
        "David Jensen",
        "Scott Niekum"
      ],
      "abstract": "Reinforcement learning (RL) algorithms often struggle to learn policies that\ngeneralize to novel situations due to issues such as causal confusion,\noverfitting to irrelevant factors, and failure to isolate control of state\nfactors. These issues stem from a common source: a failure to accurately\nidentify and exploit state-specific causal relationships in the environment.\nWhile some prior works in RL aim to identify these relationships explicitly,\nthey rely on informal domain-specific heuristics such as spatial and temporal\nproximity. Actual causality offers a principled and general framework for\ndetermining the causes of particular events. However, existing definitions of\nactual cause often attribute causality to a large number of events, even if\nmany of them rarely influence the outcome. Prior work on actual causality\nproposes normality as a solution to this problem, but its existing\nimplementations are challenging to scale to complex and continuous-valued RL\nenvironments. This paper introduces functional actual cause (FAC), a framework\nthat uses context-specific independencies in the environment to restrict the\nset of actual causes. We additionally introduce Joint Optimization for Actual\nCause Inference (JACI), an algorithm that learns from observational data to\ninfer functional actual causes. We demonstrate empirically that FAC agrees with\nknown results on a suite of examples from the actual causality literature, and\nJACI identifies actual causes with significantly higher accuracy than existing\nheuristic methods in a set of complex, continuous-valued environments.",
      "tldr_zh": "这项研究针对强化学习 (RL) 算法在复杂环境中因果混淆、过拟合和无法隔离状态因素等问题，提出了一种功能实际因果 (Functional Actual Cause, FAC) 框架，利用环境中的上下文特定独立性来限制实际原因的集合。研究还引入了 Joint Optimization for Actual Cause Inference (JACI) 算法，通过从观测数据中学习来准确推断这些功能实际原因。与现有依赖启发式方法的做法相比，JACI 在复杂、连续值环境中显著提高了实际原因识别的准确性。实验结果证明，FAC 与实际因果文献中的已知示例一致，为 RL 算法更好地泛化到新情况提供了原则性解决方案。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "stat.ME"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10883v1",
      "published_date": "2024-04-16 20:04:29 UTC",
      "updated_date": "2024-04-16 20:04:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:48:51.584588"
    },
    {
      "arxiv_id": "2404.10880v1",
      "title": "HumMUSS: Human Motion Understanding using State Space Models",
      "title_zh": "HumMUSS：使用状态空间模型的人类运动理解",
      "authors": [
        "Arnab Kumar Mondal",
        "Stefano Alletto",
        "Denis Tome"
      ],
      "abstract": "Understanding human motion from video is essential for a range of\napplications, including pose estimation, mesh recovery and action recognition.\nWhile state-of-the-art methods predominantly rely on transformer-based\narchitectures, these approaches have limitations in practical scenarios.\nTransformers are slower when sequentially predicting on a continuous stream of\nframes in real-time, and do not generalize to new frame rates. In light of\nthese constraints, we propose a novel attention-free spatiotemporal model for\nhuman motion understanding building upon recent advancements in state space\nmodels. Our model not only matches the performance of transformer-based models\nin various motion understanding tasks but also brings added benefits like\nadaptability to different video frame rates and enhanced training speed when\nworking with longer sequence of keypoints. Moreover, the proposed model\nsupports both offline and real-time applications. For real-time sequential\nprediction, our model is both memory efficient and several times faster than\ntransformer-based approaches while maintaining their high accuracy.",
      "tldr_zh": "本文提出 HumMUSS，一种基于 State Space Models 的新型注意力-free 时空模型，用于视频中人类动作理解，支持姿态估计、网格恢复和动作识别等任务。相比传统基于 Transformer 的方法，HumMUSS 不仅在性能上相当，还具备适应不同视频帧率、更快训练速度以及实时顺序预测的优势。实验结果显示，该模型在实时应用中内存效率更高，比 Transformer 模型快几倍，同时保持高准确性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 24",
      "pdf_url": "http://arxiv.org/pdf/2404.10880v1",
      "published_date": "2024-04-16 19:59:21 UTC",
      "updated_date": "2024-04-16 19:59:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:49:03.200860"
    },
    {
      "arxiv_id": "2404.10849v2",
      "title": "End-To-End Training and Testing Gamification Framework to Learn Human Highway Driving",
      "title_zh": "端到端训练与测试游戏化框架，用于学习人类高速公路驾驶",
      "authors": [
        "Satya R. Jaladi",
        "Zhimin Chen",
        "Narahari R. Malayanur",
        "Raja M. Macherla",
        "Bing Li"
      ],
      "abstract": "The current autonomous stack is well modularized and consists of perception,\ndecision making and control in a handcrafted framework. With the advances in\nartificial intelligence (AI) and computing resources, researchers have been\npushing the development of end-to-end AI for autonomous driving, at least in\nproblems of small searching space such as in highway scenarios, and more and\nmore photorealistic simulation will be critical for efficient learning. In this\nresearch, we propose a novel game-based end-to-end learning and testing\nframework for autonomous vehicle highway driving, by learning from human\ndriving skills. Firstly, we utilize the popular game Grand Theft Auto V (GTA V)\nto collect highway driving data with our proposed programmable labels. Then, an\nend-to-end architecture predicts the steering and throttle values that control\nthe vehicle by the image of the game screen. The predicted control values are\nsent to the game via a virtual controller to keep the vehicle in lane and avoid\ncollisions with other vehicles on the road. The proposed solution is validated\nin GTA V games, and the results demonstrate the effectiveness of this\nend-to-end gamification framework for learning human driving skills.",
      "tldr_zh": "该研究提出了一种基于游戏化的端到端（End-to-End）训练和测试框架，用于学习人类高速公路驾驶技能，以推动自动驾驶技术的进步。框架利用 Grand Theft Auto V (GTA V) 游戏收集带可编程标签的驾驶数据，并设计了一个端到端架构，通过游戏屏幕图像预测转向和油门控制值。预测值通过虚拟控制器发送到游戏中，实现车辆保持车道和避免碰撞。实验结果在 GTA V 环境中验证，证明了该框架在模拟学习中的有效性，为高效的自动驾驶 AI 开发提供了新途径。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted by ITSC",
      "pdf_url": "http://arxiv.org/pdf/2404.10849v2",
      "published_date": "2024-04-16 18:51:58 UTC",
      "updated_date": "2024-04-18 05:14:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:49:14.265233"
    },
    {
      "arxiv_id": "2404.10848v1",
      "title": "A LayoutLMv3-Based Model for Enhanced Relation Extraction in Visually-Rich Documents",
      "title_zh": "翻译失败",
      "authors": [
        "Wiam Adnan",
        "Joel Tang",
        "Yassine Bel Khayat Zouggari",
        "Seif Edinne Laatiri",
        "Laurent Lam",
        "Fabien Caspani"
      ],
      "abstract": "Document Understanding is an evolving field in Natural Language Processing\n(NLP). In particular, visual and spatial features are essential in addition to\nthe raw text itself and hence, several multimodal models were developed in the\nfield of Visual Document Understanding (VDU). However, while research is mainly\nfocused on Key Information Extraction (KIE), Relation Extraction (RE) between\nidentified entities is still under-studied. For instance, RE is crucial to\nregroup entities or obtain a comprehensive hierarchy of data in a document. In\nthis paper, we present a model that, initialized from LayoutLMv3, can match or\noutperform the current state-of-the-art results in RE applied to Visually-Rich\nDocuments (VRD) on FUNSD and CORD datasets, without any specific pre-training\nand with fewer parameters. We also report an extensive ablation study performed\non FUNSD, highlighting the great impact of certain features and modelization\nchoices on the performances.",
      "tldr_zh": "本文提出一个基于LayoutLMv3的模型，用于提升Visually-Rich Documents (VRD)中的Relation Extraction (RE)，以解决当前视觉文档理解(VDU)领域对RE研究的不足。模型无需特定预训练，即在FUNSD和CORD数据集上匹配或超过了现有最先进的结果，同时参数更少。该研究通过广泛的消融实验，突出了特定特征和模型设计选择对性能的显著影响，为文档实体关系提取提供了高效方法。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at the International Conference on Document Analysis and\n  Recognition (ICDAR 2024)",
      "pdf_url": "http://arxiv.org/pdf/2404.10848v1",
      "published_date": "2024-04-16 18:50:57 UTC",
      "updated_date": "2024-04-16 18:50:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:49:26.964901"
    },
    {
      "arxiv_id": "2404.10843v1",
      "title": "Geometric Neural Operators (GNPs) for Data-Driven Deep Learning of Non-Euclidean Operators",
      "title_zh": "翻译失败",
      "authors": [
        "Blaine Quackenbush",
        "Paul J. Atzberger"
      ],
      "abstract": "We introduce Geometric Neural Operators (GNPs) for accounting for geometric\ncontributions in data-driven deep learning of operators. We show how GNPs can\nbe used (i) to estimate geometric properties, such as the metric and\ncurvatures, (ii) to approximate Partial Differential Equations (PDEs) on\nmanifolds, (iii) learn solution maps for Laplace-Beltrami (LB) operators, and\n(iv) to solve Bayesian inverse problems for identifying manifold shapes. The\nmethods allow for handling geometries of general shape including point-cloud\nrepresentations. The developed GNPs provide approaches for incorporating the\nroles of geometry in data-driven learning of operators.",
      "tldr_zh": "本研究引入了Geometric Neural Operators (GNPs)，一种用于数据驱动深度学习框架，以整合非Euclidean空间中的几何贡献。GNPs 可以估计几何属性如度量和曲率、逼近流形上的Partial Differential Equations (PDEs)、学习Laplace-Beltrami (LB) 算子的解映射，以及解决Bayesian inverse problems 以识别流形形状。该方法适用于各种几何形状，包括点云表示，从而为数据驱动算子学习中有效处理几何因素提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10843v1",
      "published_date": "2024-04-16 18:43:27 UTC",
      "updated_date": "2024-04-16 18:43:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:49:38.460741"
    },
    {
      "arxiv_id": "2404.10786v1",
      "title": "Sustainability of Data Center Digital Twins with Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Soumyendu Sarkar",
        "Avisek Naug",
        "Antonio Guillen",
        "Ricardo Luna",
        "Vineet Gundecha",
        "Ashwin Ramesh Babu",
        "Sajad Mousavi"
      ],
      "abstract": "The rapid growth of machine learning (ML) has led to an increased demand for\ncomputational power, resulting in larger data centers (DCs) and higher energy\nconsumption. To address this issue and reduce carbon emissions, intelligent\ndesign and control of DC components such as IT servers, cabinets, HVAC cooling,\nflexible load shifting, and battery energy storage are essential. However, the\ncomplexity of designing and controlling them in tandem presents a significant\nchallenge. While some individual components like CFD-based design and\nReinforcement Learning (RL) based HVAC control have been researched, there's a\ngap in the holistic design and optimization covering all elements\nsimultaneously. To tackle this, we've developed DCRL-Green, a multi-agent RL\nenvironment that empowers the ML community to design data centers and research,\ndevelop, and refine RL controllers for carbon footprint reduction in DCs. It is\na flexible, modular, scalable, and configurable platform that can handle large\nHigh Performance Computing (HPC) clusters. Furthermore, in its default setup,\nDCRL-Green provides a benchmark for evaluating single as well as multi-agent RL\nalgorithms. It easily allows users to subclass the default implementations and\ndesign their own control approaches, encouraging community development for\nsustainable data centers. Open Source Link:\nhttps://github.com/HewlettPackard/dc-rl",
      "tldr_zh": "该研究针对机器学习增长导致的数据中心（DCs）能耗和碳排放增加的问题，提出了一种基于 Reinforcement Learning (RL) 的多智能体环境 DCRL-Green，用于整体优化 DCs 组件，如 IT 服务器、HVAC 冷却系统和电池存储。DCRL-Green 是一个灵活、可扩展的平台，支持设计和测试单代理或多代理 RL 算法，提供基准评估，以实现 DCs 的整体控制和碳足迹减排。论文强调该环境鼓励社区通过开源方式（如 GitHub 链接）开发自定义控制策略，推动可持续数据中心的设计和创新。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG",
        "cs.MA",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.DC",
      "comment": "2024 Proceedings of the AAAI Conference on Artificial Intelligence",
      "pdf_url": "http://arxiv.org/pdf/2404.10786v1",
      "published_date": "2024-04-16 18:22:30 UTC",
      "updated_date": "2024-04-16 18:22:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:49:51.477162"
    },
    {
      "arxiv_id": "2404.10830v2",
      "title": "Fewer Truncations Improve Language Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Hantian Ding",
        "Zijian Wang",
        "Giovanni Paolini",
        "Varun Kumar",
        "Anoop Deoras",
        "Dan Roth",
        "Stefano Soatto"
      ],
      "abstract": "In large language model training, input documents are typically concatenated\ntogether and then split into sequences of equal length to avoid padding tokens.\nDespite its efficiency, the concatenation approach compromises data integrity\n-- it inevitably breaks many documents into incomplete pieces, leading to\nexcessive truncations that hinder the model from learning to compose logically\ncoherent and factually consistent content that is grounded on the complete\ncontext. To address the issue, we propose Best-fit Packing, a scalable and\nefficient method that packs documents into training sequences through\nlength-aware combinatorial optimization. Our method completely eliminates\nunnecessary truncations while retaining the same training efficiency as\nconcatenation. Empirical results from both text and code pre-training show that\nour method achieves superior performance (e.g., relatively +4.7% on reading\ncomprehension; +16.8% in context following; and +9.2% on program synthesis),\nand reduces closed-domain hallucination effectively by up to 58.3%.",
      "tldr_zh": "本研究指出，大型语言模型训练中，传统文档连接和等长序列分割方法会导致过度 truncations，影响模型生成逻辑连贯和事实一致的内容。为解决此问题，作者提出 Best-fit Packing 技术，这是一种基于长度-aware combinatorial optimization 的高效打包方法，能完全消除不必要截断，同时保持训练效率。实验结果显示，该方法在文本和代码预训练上显著提升性能，例如阅读理解提高 4.7%、上下文遵循提高 16.8%、程序合成提高 9.2%，并将封闭域 hallucination 减少多达 58.3%。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.10830v2",
      "published_date": "2024-04-16 18:08:29 UTC",
      "updated_date": "2024-05-02 17:10:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:50:02.155079"
    },
    {
      "arxiv_id": "2404.10824v2",
      "title": "Decoupled Weight Decay for Any $p$ Norm",
      "title_zh": "翻译失败",
      "authors": [
        "Nadav Joseph Outmezguine",
        "Noam Levi"
      ],
      "abstract": "With the success of deep neural networks (NNs) in a variety of domains, the\ncomputational and storage requirements for training and deploying large NNs\nhave become a bottleneck for further improvements. Sparsification has\nconsequently emerged as a leading approach to tackle these issues. In this\nwork, we consider a simple yet effective approach to sparsification, based on\nthe Bridge, or $L_p$ regularization during training. We introduce a novel\nweight decay scheme, which generalizes the standard $L_2$ weight decay to any\n$p$ norm. We show that this scheme is compatible with adaptive optimizers, and\navoids the gradient divergence associated with $0<p<1$ norms. We empirically\ndemonstrate that it leads to highly sparse networks, while maintaining\ngeneralization performance comparable to standard $L_2$ regularization.",
      "tldr_zh": "该研究针对深度神经网络的计算和存储需求问题，提出了一种新的权重衰减方案，将标准的 $L_2$ 权重衰减泛化到任意 $p$ 范数，从而实现网络的稀疏化。该方案基于 $L_p$ 正则化，兼容自适应优化器，并有效避免了 $0<p<1$ 范数相关的梯度发散问题。实验结果表明，这种方法能生成高度稀疏的网络，同时保持与 $L_2$ 正则化相当的泛化性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "GitHub link: https://github.com/Nadav-out/PAdam",
      "pdf_url": "http://arxiv.org/pdf/2404.10824v2",
      "published_date": "2024-04-16 18:02:15 UTC",
      "updated_date": "2024-04-22 20:31:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:50:14.959475"
    },
    {
      "arxiv_id": "2404.10775v3",
      "title": "COMBO: Compositional World Models for Embodied Multi-Agent Cooperation",
      "title_zh": "COMBO：组合式世界模型用于具身多智能体合作",
      "authors": [
        "Hongxin Zhang",
        "Zeyuan Wang",
        "Qiushi Lyu",
        "Zheyuan Zhang",
        "Sunli Chen",
        "Tianmin Shu",
        "Behzad Dariush",
        "Kwonjoon Lee",
        "Yilun Du",
        "Chuang Gan"
      ],
      "abstract": "In this paper, we investigate the problem of embodied multi-agent\ncooperation, where decentralized agents must cooperate given only egocentric\nviews of the world. To effectively plan in this setting, in contrast to\nlearning world dynamics in a single-agent scenario, we must simulate world\ndynamics conditioned on an arbitrary number of agents' actions given only\npartial egocentric visual observations of the world. To address this issue of\npartial observability, we first train generative models to estimate the overall\nworld state given partial egocentric observations. To enable accurate\nsimulation of multiple sets of actions on this world state, we then propose to\nlearn a compositional world model for multi-agent cooperation by factorizing\nthe naturally composable joint actions of multiple agents and compositionally\ngenerating the video conditioned on the world state. By leveraging this\ncompositional world model, in combination with Vision Language Models to infer\nthe actions of other agents, we can use a tree search procedure to integrate\nthese modules and facilitate online cooperative planning. We evaluate our\nmethods on three challenging benchmarks with 2-4 agents. The results show our\ncompositional world model is effective and the framework enables the embodied\nagents to cooperate efficiently with different agents across various tasks and\nan arbitrary number of agents, showing the promising future of our proposed\nmethods. More videos can be found at\nhttps://umass-embodied-agi.github.io/COMBO/.",
      "tldr_zh": "本研究探讨了基于自我中心视角（egocentric views）的多智能体合作问题，提出COMBO框架，利用组合式世界模型（compositional world model）来模拟世界动态。框架首先训练生成模型从部分观察估计整体世界状态，然后通过分解多个智能体的联合动作（joint actions）并组合生成视频，结合视觉语言模型（Vision Language Models）推断其他智能体的动作，并采用树搜索（tree search）进行在线合作规划。实验在3个包含2-4个智能体的挑战性基准上验证了该方法的有效性，使智能体在各种任务中高效合作，并支持任意数量的智能体参与。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.CV",
      "comment": "Published at ICLR 2025. 24 pages. The first three authors contributed\n  equally",
      "pdf_url": "http://arxiv.org/pdf/2404.10775v3",
      "published_date": "2024-04-16 17:59:11 UTC",
      "updated_date": "2025-04-16 00:50:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:50:26.969102"
    },
    {
      "arxiv_id": "2404.10774v2",
      "title": "MiniCheck: Efficient Fact-Checking of LLMs on Grounding Documents",
      "title_zh": "翻译失败",
      "authors": [
        "Liyan Tang",
        "Philippe Laban",
        "Greg Durrett"
      ],
      "abstract": "Recognizing if LLM output can be grounded in evidence is central to many\ntasks in NLP: retrieval-augmented generation, summarization, document-grounded\ndialogue, and more. Current approaches to this kind of fact-checking are based\non verifying each piece of a model generation against potential evidence using\nan LLM. However, this process can be very computationally expensive, requiring\nmany calls to a model to check a single response. In this work, we show how to\nbuild small fact-checking models that have GPT-4-level performance but for 400x\nlower cost. We do this by constructing synthetic training data with GPT-4,\nwhich involves creating realistic yet challenging instances of factual errors\nvia a structured generation procedure. Training on this data teaches models to\ncheck each fact in the claim and recognize synthesis of information across\nsentences. For evaluation, we unify datasets from recent work on fact-checking\nand grounding LLM generations into a new benchmark, LLM-AggreFact. Our best\nsystem MiniCheck-FT5 (770M parameters) outperforms all systems of comparable\nsize and reaches GPT-4 accuracy. We release LLM-AggreFact, code for data\nsynthesis, and models.",
      "tldr_zh": "本文提出 MiniCheck，一种高效的事实检查框架，用于验证大型语言模型 (LLMs) 输出是否基于证据文档，从而提升检索增强生成、总结和对话等 NLP 任务的可靠性。与传统方法相比，MiniCheck 通过使用 GPT-4 生成合成训练数据，并通过结构化过程创建现实的错误实例，训练小型模型来检查每个事实声明并识别跨句子信息合成。实验在新的基准 LLM-AggreFact 上显示，最佳系统 MiniCheck-FT5 (770M 参数) 达到了 GPT-4 水平的准确性，但计算成本降低了 400 倍。作者发布了数据集、代码和模型，以促进进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.10774v2",
      "published_date": "2024-04-16 17:59:10 UTC",
      "updated_date": "2024-10-01 15:39:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:50:39.758714"
    },
    {
      "arxiv_id": "2404.10763v1",
      "title": "LaDiC: Are Diffusion Models Really Inferior to Autoregressive Counterparts for Image-to-Text Generation?",
      "title_zh": "翻译失败",
      "authors": [
        "Yuchi Wang",
        "Shuhuai Ren",
        "Rundong Gao",
        "Linli Yao",
        "Qingyan Guo",
        "Kaikai An",
        "Jianhong Bai",
        "Xu Sun"
      ],
      "abstract": "Diffusion models have exhibited remarkable capabilities in text-to-image\ngeneration. However, their performance in image-to-text generation,\nspecifically image captioning, has lagged behind Auto-Regressive (AR) models,\ncasting doubt on their applicability for such tasks. In this work, we revisit\ndiffusion models, highlighting their capacity for holistic context modeling and\nparallel decoding. With these benefits, diffusion models can alleviate the\ninherent limitations of AR methods, including their slow inference speed, error\npropagation, and unidirectional constraints. Furthermore, we identify the prior\nunderperformance of diffusion models stemming from the absence of an effective\nlatent space for image-text alignment, and the discrepancy between continuous\ndiffusion processes and discrete textual data. In response, we introduce a\nnovel architecture, LaDiC, which utilizes a split BERT to create a dedicated\nlatent space for captions and integrates a regularization module to manage\nvarying text lengths. Our framework also includes a diffuser for semantic\nimage-to-text conversion and a Back&Refine technique to enhance token\ninteractivity during inference. LaDiC achieves state-of-the-art performance for\ndiffusion-based methods on the MS COCO dataset with 38.2 BLEU@4 and 126.2\nCIDEr, demonstrating exceptional performance without pre-training or ancillary\nmodules. This indicates strong competitiveness with AR models, revealing the\npreviously untapped potential of diffusion models in image-to-text generation.",
      "tldr_zh": "本研究质疑了Diffusion models在图像到文本生成（如图像描述）中是否劣于Autoregressive (AR) models，强调Diffusion models的优势在于整体上下文建模和并行解码，能缓解AR models的慢速推理、错误传播和单向约束问题。作者识别出Diffusion models的不足，包括缺乏有效的潜在空间和连续过程与离散文本的差异，并提出LaDiC架构，使用split BERT创建专用的标题潜在空间、正则化模块处理文本长度、diffuser进行语义转换，以及Back&Refine技术增强推理中的令牌互动。实验结果显示，LaDiC在MS COCO数据集上达到最先进性能（38.2 BLEU@4和126.2 CIDEr），无需预训练或辅助模块，证明Diffusion models在图像到文本生成中具有与AR models竞争的潜力。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10763v1",
      "published_date": "2024-04-16 17:47:16 UTC",
      "updated_date": "2024-04-16 17:47:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:50:53.338987"
    },
    {
      "arxiv_id": "2404.10740v3",
      "title": "N-Agent Ad Hoc Teamwork",
      "title_zh": "翻译失败",
      "authors": [
        "Caroline Wang",
        "Arrasy Rahman",
        "Ishan Durugkar",
        "Elad Liebman",
        "Peter Stone"
      ],
      "abstract": "Current approaches to learning cooperative multi-agent behaviors assume\nrelatively restrictive settings. In standard fully cooperative multi-agent\nreinforcement learning, the learning algorithm controls $\\textit{all}$ agents\nin the scenario, while in ad hoc teamwork, the learning algorithm usually\nassumes control over only a $\\textit{single}$ agent in the scenario. However,\nmany cooperative settings in the real world are much less restrictive. For\nexample, in an autonomous driving scenario, a company might train its cars with\nthe same learning algorithm, yet once on the road, these cars must cooperate\nwith cars from another company. Towards expanding the class of scenarios that\ncooperative learning methods may optimally address, we introduce $N$-agent ad\nhoc teamwork (NAHT), where a set of autonomous agents must interact and\ncooperate with dynamically varying numbers and types of teammates. This paper\nformalizes the problem, and proposes the Policy Optimization with Agent\nModelling (POAM) algorithm. POAM is a policy gradient, multi-agent\nreinforcement learning approach to the NAHT problem, that enables adaptation to\ndiverse teammate behaviors by learning representations of teammate behaviors.\nEmpirical evaluation on tasks from the multi-agent particle environment and\nStarCraft II shows that POAM improves cooperative task returns compared to\nbaseline approaches, and enables out-of-distribution generalization to unseen\nteammates.",
      "tldr_zh": "该论文引入 N-Agent Ad Hoc Teamwork (NAHT) 概念，解决现有多智能体强化学习中对队友数量和类型假设过于严格的问题，例如不同公司自动驾驶汽车间的合作。论文提出 Policy Optimization with Agent Modelling (POAM) 算法，这是一种基于策略梯度的多智能体强化学习方法，通过学习队友行为的表示来实现对动态变化队友的适应。实验在多智能体粒子环境和 StarCraft II 任务上表明，POAM 比基线方法显著提高了合作任务回报，并实现了对未见队友的泛化能力。",
      "categories": [
        "cs.AI",
        "I.2.11; I.2.1; I.2.6; I.2.8"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10740v3",
      "published_date": "2024-04-16 17:13:08 UTC",
      "updated_date": "2024-10-04 16:08:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:51:04.632769"
    },
    {
      "arxiv_id": "2404.10733v1",
      "title": "Bootstrapping Linear Models for Fast Online Adaptation in Human-Agent Collaboration",
      "title_zh": "翻译失败",
      "authors": [
        "Benjamin A Newman",
        "Chris Paxton",
        "Kris Kitani",
        "Henny Admoni"
      ],
      "abstract": "Agents that assist people need to have well-initialized policies that can\nadapt quickly to align with their partners' reward functions. Initializing\npolicies to maximize performance with unknown partners can be achieved by\nbootstrapping nonlinear models using imitation learning over large, offline\ndatasets. Such policies can require prohibitive computation to fine-tune\nin-situ and therefore may miss critical run-time information about a partner's\nreward function as expressed through their immediate behavior. In contrast,\nonline logistic regression using low-capacity models performs rapid inference\nand fine-tuning updates and thus can make effective use of immediate in-task\nbehavior for reward function alignment. However, these low-capacity models\ncannot be bootstrapped as effectively by offline datasets and thus have poor\ninitializations. We propose BLR-HAC, Bootstrapped Logistic Regression for Human\nAgent Collaboration, which bootstraps large nonlinear models to learn the\nparameters of a low-capacity model which then uses online logistic regression\nfor updates during collaboration. We test BLR-HAC in a simulated surface\nrearrangement task and demonstrate that it achieves higher zero-shot accuracy\nthan shallow methods and takes far less computation to adapt online while still\nachieving similar performance to fine-tuned, large nonlinear models. For code,\nplease see our project page https://sites.google.com/view/blr-hac.",
      "tldr_zh": "该研究针对人类-代理协作（Human-Agent Collaboration）中的在线适应问题，提出了一种引导线性模型（Bootstrapping Linear Models）的方法，以实现快速策略调整。BLR-HAC（Bootstrapped Logistic Regression for Human Agent Collaboration）框架首先利用大型非线性模型通过模仿学习（imitation learning）从离线数据集引导低容量模型的参数，然后在协作过程中应用在线逻辑回归（online logistic regression）进行实时更新，从而平衡初始性能和计算效率。在模拟的表面重排任务中，BLR-HAC 实现了比浅层方法更高的零样本准确率（zero-shot accuracy），并在在线适应时显著减少计算量，同时其性能与微调的大型非线性模型相当。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 4 figures, Accepted to AAMAS 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.10733v1",
      "published_date": "2024-04-16 17:05:43 UTC",
      "updated_date": "2024-04-16 17:05:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:51:15.424969"
    },
    {
      "arxiv_id": "2404.10731v1",
      "title": "What is Meant by AGI? On the Definition of Artificial General Intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Bowen Xu"
      ],
      "abstract": "This paper aims to establish a consensus on AGI's definition. General\nintelligence refers to the adaptation to open environments according to certain\nprinciples using limited resources. It emphasizes that adaptation or learning\nis an indispensable property of intelligence, and places the controversial part\nwithin the principles of intelligence, which can be described from different\nperspectives.",
      "tldr_zh": "这篇论文旨在为 AGI（Artificial General Intelligence）建立一个共识定义，将其描述为使用有限资源根据某些原则适应开放环境。论文强调，适应或学习是智能的不可或缺属性，并将争议焦点放在智能的原则上，这些原则可以从不同视角进行分析。通过这一定义，论文有助于澄清 AGI 的核心概念并推动相关研究。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10731v1",
      "published_date": "2024-04-16 17:03:50 UTC",
      "updated_date": "2024-04-16 17:03:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:51:25.462752"
    },
    {
      "arxiv_id": "2404.10730v1",
      "title": "Insight Gained from Migrating a Machine Learning Model to Intelligence Processing Units",
      "title_zh": "从将机器学习模型迁移到智能处理单元中获得的见解",
      "authors": [
        "Hieu Le",
        "Zhenhua He",
        "Mai Le",
        "Dhruva K. Chakravorty",
        "Lisa M. Perez",
        "Akhil Chilumuru",
        "Yan Yao",
        "Jiefu Chen"
      ],
      "abstract": "The discoveries in this paper show that Intelligence Processing Units (IPUs)\noffer a viable accelerator alternative to GPUs for machine learning (ML)\napplications within the fields of materials science and battery research. We\ninvestigate the process of migrating a model from GPU to IPU and explore\nseveral optimization techniques, including pipelining and gradient\naccumulation, aimed at enhancing the performance of IPU-based models.\nFurthermore, we have effectively migrated a specialized model to the IPU\nplatform. This model is employed for predicting effective conductivity, a\nparameter crucial in ion transport processes, which govern the performance of\nmultiple charge and discharge cycles of batteries. The model utilizes a\nConvolutional Neural Network (CNN) architecture to perform prediction tasks for\neffective conductivity. The performance of this model on the IPU is found to be\ncomparable to its execution on GPUs. We also analyze the utilization and\nperformance of Graphcore's Bow IPU. Through benchmark tests, we observe\nsignificantly improved performance with the Bow IPU when compared to its\npredecessor, the Colossus IPU.",
      "tldr_zh": "这篇论文探讨了将机器学习 (ML) 模型从 GPU 迁移到 Intelligence Processing Units (IPUs) 的过程，发现 IPUs 是材料科学和电池研究领域 ML 应用的可靠替代方案。作者调查了迁移方法，包括采用 pipelining 和 gradient accumulation 等优化技术，以提升 IPU 模型的性能。特别地，他们成功地将一个基于 Convolutional Neural Network (CNN) 的模型移植到 IPU 平台，用于预测电池离子传输过程中的有效电导率 (effective conductivity)。实验结果显示，该模型在 IPU 上的性能与 GPU 相当，且 Graphcore's Bow IPU 在基准测试中比其前代 Colossus IPU 表现出显著改进。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "arXiv admin note: This version has been removed by arXiv\n  administrators as the submitter did not have the right to agree to the\n  license at the time of submission",
      "pdf_url": "http://arxiv.org/pdf/2404.10730v1",
      "published_date": "2024-04-16 17:02:52 UTC",
      "updated_date": "2024-04-16 17:02:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:51:40.427794"
    },
    {
      "arxiv_id": "2404.10717v1",
      "title": "Mixed Prototype Consistency Learning for Semi-supervised Medical Image Segmentation",
      "title_zh": "半监督医学图像分割的混合原型一致性学习",
      "authors": [
        "Lijian Li"
      ],
      "abstract": "Recently, prototype learning has emerged in semi-supervised medical image\nsegmentation and achieved remarkable performance. However, the scarcity of\nlabeled data limits the expressiveness of prototypes in previous methods,\npotentially hindering the complete representation of prototypes for class\nembedding. To address this problem, we propose the Mixed Prototype Consistency\nLearning (MPCL) framework, which includes a Mean Teacher and an auxiliary\nnetwork. The Mean Teacher generates prototypes for labeled and unlabeled data,\nwhile the auxiliary network produces additional prototypes for mixed data\nprocessed by CutMix. Through prototype fusion, mixed prototypes provide extra\nsemantic information to both labeled and unlabeled prototypes. High-quality\nglobal prototypes for each class are formed by fusing two enhanced prototypes,\noptimizing the distribution of hidden embeddings used in consistency learning.\nExtensive experiments on the left atrium and type B aortic dissection datasets\ndemonstrate MPCL's superiority over previous state-of-the-art approaches,\nconfirming the effectiveness of our framework. The code will be released soon.",
      "tldr_zh": "该研究针对半监督医疗图像分割中，原型学习因标注数据稀缺而导致表达力不足的问题，提出了一种Mixed Prototype Consistency Learning (MPCL)框架。该框架结合Mean Teacher和辅助网络，其中Mean Teacher为标注和未标注数据生成原型，辅助网络则为通过CutMix处理的混合数据产生额外原型。通过原型融合，MPCL优化了全局原型分布，提供更多语义信息以提升一致性学习效果。在左心房和B型主动脉夹层数据集上的实验表明，MPCL优于现有最先进方法，证明了其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.10717v1",
      "published_date": "2024-04-16 16:51:12 UTC",
      "updated_date": "2024-04-16 16:51:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:51:50.621469"
    },
    {
      "arxiv_id": "2404.10704v1",
      "title": "Question Difficulty Ranking for Multiple-Choice Reading Comprehension",
      "title_zh": "多项选择阅读理解的问题难度排名",
      "authors": [
        "Vatsal Raina",
        "Mark Gales"
      ],
      "abstract": "Multiple-choice (MC) tests are an efficient method to assess English\nlearners. It is useful for test creators to rank candidate MC questions by\ndifficulty during exam curation. Typically, the difficulty is determined by\nhaving human test takers trial the questions in a pretesting stage. However,\nthis is expensive and not scalable. Therefore, we explore automated approaches\nto rank MC questions by difficulty. However, there is limited data for explicit\ntraining of a system for difficulty scores. Hence, we compare task transfer and\nzero-shot approaches: task transfer adapts level classification and reading\ncomprehension systems for difficulty ranking while zero-shot prompting of\ninstruction finetuned language models contrasts absolute assessment against\ncomparative. It is found that level classification transfers better than\nreading comprehension. Additionally, zero-shot comparative assessment is more\neffective at difficulty ranking than the absolute assessment and even the task\ntransfer approaches at question difficulty ranking with a Spearman's\ncorrelation of 40.4%. Combining the systems is observed to further boost the\ncorrelation.",
      "tldr_zh": "这篇论文探讨了自动排名多选题（Multiple-Choice, MC）难度的方法，以辅助英语学习者评估，避免依赖昂贵的预测试过程。作者比较了任务转移方法（将水平分类和阅读理解系统适应用于难度排名）和零样本提示方法（通过指令微调的语言模型进行对比评估）。结果显示，零样本的对比评估在难度排名上最有效，Spearman's correlation 达到 40.4%，并发现结合多种方法可进一步提升相关性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "7 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.10704v1",
      "published_date": "2024-04-16 16:23:10 UTC",
      "updated_date": "2024-04-16 16:23:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:52:04.240807"
    },
    {
      "arxiv_id": "2404.10683v1",
      "title": "Simplex Decomposition for Portfolio Allocation Constraints in Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "David Winkel",
        "Niklas Strauß",
        "Matthias Schubert",
        "Thomas Seidl"
      ],
      "abstract": "Portfolio optimization tasks describe sequential decision problems in which\nthe investor's wealth is distributed across a set of assets. Allocation\nconstraints are used to enforce minimal or maximal investments into particular\nsubsets of assets to control for objectives such as limiting the portfolio's\nexposure to a certain sector due to environmental concerns. Although methods\nfor constrained Reinforcement Learning (CRL) can optimize policies while\nconsidering allocation constraints, it can be observed that these general\nmethods yield suboptimal results. In this paper, we propose a novel approach to\nhandle allocation constraints based on a decomposition of the constraint action\nspace into a set of unconstrained allocation problems. In particular, we\nexamine this approach for the case of two constraints. For example, an investor\nmay wish to invest at least a certain percentage of the portfolio into green\ntechnologies while limiting the investment in the fossil energy sector. We show\nthat the action space of the task is equivalent to the decomposed action space,\nand introduce a new reinforcement learning (RL) approach CAOSD, which is built\non top of the decomposition. The experimental evaluation on real-world\nNasdaq-100 data demonstrates that our approach consistently outperforms\nstate-of-the-art CRL benchmarks for portfolio optimization.",
      "tldr_zh": "这篇论文针对投资组合优化中的分配约束问题，提出了一种基于动作空间分解的方法，以改进 Reinforcement Learning (RL) 的性能。作者将约束动作空间分解为多个无约束分配问题，特别是针对两个约束（如最小投资于绿色技术并限制化石能源投资），并开发了新的 RL 算法 CAOSD 来处理这些分解。实验结果显示，在真实 Nasdaq-100 数据上，CAOSD 比现有 Constrained Reinforcement Learning (CRL) 基准方法表现出色，一致地提升了优化效果。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10683v1",
      "published_date": "2024-04-16 16:00:59 UTC",
      "updated_date": "2024-04-16 16:00:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:52:17.112995"
    },
    {
      "arxiv_id": "2404.10679v1",
      "title": "HSVI-based Online Minimax Strategies for Partially Observable Stochastic Games with Neural Perception Mechanisms",
      "title_zh": "基于 HSVI 的在线最小最大策略，用于带有神经感知机制的部分可观测随机博弈",
      "authors": [
        "Rui Yan",
        "Gabriel Santos",
        "Gethin Norman",
        "David Parker",
        "Marta Kwiatkowska"
      ],
      "abstract": "We consider a variant of continuous-state partially-observable stochastic\ngames with neural perception mechanisms and an asymmetric information\nstructure. One agent has partial information, with the observation function\nimplemented as a neural network, while the other agent is assumed to have full\nknowledge of the state. We present, for the first time, an efficient online\nmethod to compute an $\\varepsilon$-minimax strategy profile, which requires\nonly one linear program to be solved for each agent at every stage, instead of\na complex estimation of opponent counterfactual values. For the\npartially-informed agent, we propose a continual resolving approach which uses\nlower bounds, pre-computed offline with heuristic search value iteration\n(HSVI), instead of opponent counterfactual values. This inherits the soundness\nof continual resolving at the cost of pre-computing the bound. For the\nfully-informed agent, we propose an inferred-belief strategy, where the agent\nmaintains an inferred belief about the belief of the partially-informed agent\nbased on (offline) upper bounds from HSVI, guaranteeing $\\varepsilon$-distance\nto the value of the game at the initial belief known to both agents.",
      "tldr_zh": "本研究针对带有神经感知机制的部分可观测随机博弈（Partially Observable Stochastic Games），提出了一种基于 HSVI 的在线 minimax 策略计算方法，以处理不对称信息结构，其中一个代理使用神经网络实现部分观察，另一个代理拥有完整状态知识。方法的核心在于为每个代理在每个阶段仅需解决一个线性程序，从而避免复杂的对手反事实值估计。对于部分信息代理，采用持续解析方法，利用离线预计算的 HSVI 下界来确保策略的可靠性；对于完全信息代理，则通过推断信念策略基于 HSVI 上界维护对手信念的估计，保证 ε-minimax 策略与游戏初始值的 ε-距离。该方法首次实现了高效计算，提高了博弈策略的精确性和适用性。",
      "categories": [
        "cs.GT",
        "cs.AI"
      ],
      "primary_category": "cs.GT",
      "comment": "12 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.10679v1",
      "published_date": "2024-04-16 15:58:20 UTC",
      "updated_date": "2024-04-16 15:58:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:52:30.530592"
    },
    {
      "arxiv_id": "2404.10662v2",
      "title": "Continual Offline Reinforcement Learning via Diffusion-based Dual Generative Replay",
      "title_zh": "翻译失败",
      "authors": [
        "Jinmei Liu",
        "Wenbin Li",
        "Xiangyu Yue",
        "Shilin Zhang",
        "Chunlin Chen",
        "Zhi Wang"
      ],
      "abstract": "We study continual offline reinforcement learning, a practical paradigm that\nfacilitates forward transfer and mitigates catastrophic forgetting to tackle\nsequential offline tasks. We propose a dual generative replay framework that\nretains previous knowledge by concurrent replay of generated pseudo-data.\nFirst, we decouple the continual learning policy into a diffusion-based\ngenerative behavior model and a multi-head action evaluation model, allowing\nthe policy to inherit distributional expressivity for encompassing a\nprogressive range of diverse behaviors. Second, we train a task-conditioned\ndiffusion model to mimic state distributions of past tasks. Generated states\nare paired with corresponding responses from the behavior generator to\nrepresent old tasks with high-fidelity replayed samples. Finally, by\ninterleaving pseudo samples with real ones of the new task, we continually\nupdate the state and behavior generators to model progressively diverse\nbehaviors, and regularize the multi-head critic via behavior cloning to\nmitigate forgetting. Experiments demonstrate that our method achieves better\nforward transfer with less forgetting, and closely approximates the results of\nusing previous ground-truth data due to its high-fidelity replay of the sample\nspace. Our code is available at\n\\href{https://github.com/NJU-RL/CuGRO}{https://github.com/NJU-RL/CuGRO}.",
      "tldr_zh": "该论文研究了continual offline reinforcement learning，提出了一种基于diffusion-based的双生成重放框架，以促进前向转移并缓解catastrophic forgetting。框架将持续学习策略分解为diffusion-based generative behavior model和multi-head action evaluation model，并训练任务条件扩散模型来高保真度重放过去任务的状态分布。实验结果表明，该方法通过交错伪样本和真实样本进行更新，实现更好的前向转移、减少遗忘，并接近使用真实先前数据的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10662v2",
      "published_date": "2024-04-16 15:39:11 UTC",
      "updated_date": "2024-04-18 04:49:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:52:43.096160"
    },
    {
      "arxiv_id": "2404.10646v1",
      "title": "Efficient Parking Search using Shared Fleet Data",
      "title_zh": "高效停车搜索使用共享车辆群数据",
      "authors": [
        "Niklas Strauß",
        "Lukas Rottkamp",
        "Sebatian Schmoll",
        "Matthias Schubert"
      ],
      "abstract": "Finding an available on-street parking spot is a relevant problem of\nday-to-day life. In recent years, cities such as Melbourne and San Francisco\ndeployed sensors that provide real-time information about the occupation of\nparking spots. Finding a free parking spot in such a smart environment can be\nmodeled and solved as a Markov decision process (MDP). The problem has to\nconsider uncertainty as available parking spots might not remain available\nuntil arrival due to other vehicles also claiming spots in the meantime.\nKnowing the parking intention of every vehicle in the environment would\neliminate this uncertainty. Unfortunately, it does currently not seem realistic\nto have such data from all vehicles. In contrast, acquiring data from a subset\nof vehicles or a vehicle fleet appears feasible and has the potential to reduce\nuncertainty.\n  In this paper, we examine the question of how useful sharing data within a\nvehicle fleet might be for the search times of particular drivers. We use fleet\ndata to better estimate the availability of parking spots at arrival. Since\noptimal solutions for large scenarios are infeasible, we base our method on\napproximate solutions, which have been shown to perform well in single-agent\nsettings. Our experiments are conducted on a simulation using real-world and\nsynthetic data from the city of Melbourne. The results indicate that fleet data\ncan significantly reduce search times for an available parking spot.",
      "tldr_zh": "本研究探讨了利用共享车队数据（fleet data）来优化街边停车搜索问题，将其建模为Markov Decision Process (MDP)，以处理停车位可用性的不确定性。方法通过从车队车辆收集数据来更好地估计停车位在到达时的可用性，并采用近似解决方案，以适用于大规模场景。实验基于墨尔本的真实和合成数据进行，结果显示，共享车队数据可显著减少寻找可用停车位的搜索时间。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Long Version; published at 2021 22nd IEEE International Conference on\n  Mobile Data Management (MDM)",
      "pdf_url": "http://arxiv.org/pdf/2404.10646v1",
      "published_date": "2024-04-16 15:20:28 UTC",
      "updated_date": "2024-04-16 15:20:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:52:53.028817"
    },
    {
      "arxiv_id": "2404.10645v1",
      "title": "Continuous Control Reinforcement Learning: Distributed Distributional DrQ Algorithms",
      "title_zh": "翻译失败",
      "authors": [
        "Zehao Zhou"
      ],
      "abstract": "Distributed Distributional DrQ is a model-free and off-policy RL algorithm\nfor continuous control tasks based on the state and observation of the agent,\nwhich is an actor-critic method with the data-augmentation and the\ndistributional perspective of critic value function. Aim to learn to control\nthe agent and master some tasks in a high-dimensional continuous space. DrQ-v2\nuses DDPG as the backbone and achieves out-performance in various continuous\ncontrol tasks. Here Distributed Distributional DrQ uses Distributed\nDistributional DDPG as the backbone, and this modification aims to achieve\nbetter performance in some hard continuous control tasks through the better\nexpression ability of distributional value function and distributed actor\npolicies.",
      "tldr_zh": "本论文提出了一种名为 Distributed Distributional DrQ 的无模型、非策略强化学习（RL）算法，针对连续控制任务，通过 actor-critic 方法结合数据增强（data-augmentation）和分布视角（distributional perspective）的 critic 值函数来优化代理的状态和观察学习。算法以 Distributed Distributional DDPG 为骨干，旨在在高维连续空间中提升代理控制能力，尤其适用于复杂任务。相比 DrQ-v2，该改进利用分布值函数的更好表达能力和分布式 actor 策略，在困难的连续控制任务中实现了更高的性能表现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.10645v1",
      "published_date": "2024-04-16 15:18:40 UTC",
      "updated_date": "2024-04-16 15:18:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:53:04.600102"
    },
    {
      "arxiv_id": "2404.10618v2",
      "title": "Private Attribute Inference from Images with Vision-Language Models",
      "title_zh": "使用视觉语言模型从图像中推断私人属性",
      "authors": [
        "Batuhan Tömekçe",
        "Mark Vero",
        "Robin Staab",
        "Martin Vechev"
      ],
      "abstract": "As large language models (LLMs) become ubiquitous in our daily tasks and\ndigital interactions, associated privacy risks are increasingly in focus. While\nLLM privacy research has primarily focused on the leakage of model training\ndata, it has recently been shown that LLMs can make accurate privacy-infringing\ninferences from previously unseen texts. With the rise of vision-language\nmodels (VLMs), capable of understanding both images and text, a key question is\nwhether this concern transfers to the previously unexplored domain of benign\nimages posted online. To answer this question, we compile an image dataset with\nhuman-annotated labels of the image owner's personal attributes. In order to\nunderstand the privacy risks posed by VLMs beyond traditional human attribute\nrecognition, our dataset consists of images where the inferable private\nattributes do not stem from direct depictions of humans. On this dataset, we\nevaluate 7 state-of-the-art VLMs, finding that they can infer various personal\nattributes at up to 77.6% accuracy. Concerningly, we observe that accuracy\nscales with the general capabilities of the models, implying that future models\ncan be misused as stronger inferential adversaries, establishing an imperative\nfor the development of adequate defenses.",
      "tldr_zh": "本文研究了视觉语言模型（VLMs）从图像中推断私人属性的隐私风险，扩展了大型语言模型（LLMs）在文本领域的类似问题。研究者编译了一个数据集，包含人类标注的图像所有者个人属性标签，这些图像不直接描绘人类，但仍可用于推断属性。实验评估了7个最先进的VLMs，发现它们能以高达77.6%的准确率推断各种个人属性，且准确率随模型整体能力提升而增加。这突显了潜在的隐私威胁，强调了开发有效防御措施的紧迫性。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10618v2",
      "published_date": "2024-04-16 14:42:49 UTC",
      "updated_date": "2024-11-04 11:11:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:53:17.346296"
    },
    {
      "arxiv_id": "2404.10597v1",
      "title": "Hardware-aware training of models with synaptic delays for digital event-driven neuromorphic processors",
      "title_zh": "翻译失败",
      "authors": [
        "Alberto Patino-Saucedo",
        "Roy Meijer",
        "Amirreza Yousefzadeh",
        "Manil-Dev Gomony",
        "Federico Corradi",
        "Paul Detteter",
        "Laura Garrido-Regife",
        "Bernabe Linares-Barranco",
        "Manolis Sifalakis"
      ],
      "abstract": "Configurable synaptic delays are a basic feature in many neuromorphic neural\nnetwork hardware accelerators. However, they have been rarely used in model\nimplementations, despite their promising impact on performance and efficiency\nin tasks that exhibit complex (temporal) dynamics, as it has been unclear how\nto optimize them. In this work, we propose a framework to train and deploy, in\ndigital neuromorphic hardware, highly performing spiking neural network models\n(SNNs) where apart from the synaptic weights, the per-synapse delays are also\nco-optimized. Leveraging spike-based back-propagation-through-time, the\ntraining accounts for both platform constraints, such as synaptic weight\nprecision and the total number of parameters per core, as a function of the\nnetwork size. In addition, a delay pruning technique is used to reduce memory\nfootprint with a low cost in performance. We evaluate trained models in two\nneuromorphic digital hardware platforms: Intel Loihi and Imec Seneca. Loihi\noffers synaptic delay support using the so-called Ring-Buffer hardware\nstructure. Seneca does not provide native hardware support for synaptic delays.\nA second contribution of this paper is therefore a novel area- and\nmemory-efficient hardware structure for acceleration of synaptic delays, which\nwe have integrated in Seneca. The evaluated benchmark involves several models\nfor solving the SHD (Spiking Heidelberg Digits) classification task, where\nminimal accuracy degradation during the transition from software to hardware is\ndemonstrated. To our knowledge, this is the first work showcasing how to train\nand deploy hardware-aware models parameterized with synaptic delays, on\nmulticore neuromorphic hardware accelerators.",
      "tldr_zh": "该研究提出一个硬件感知框架，用于训练和部署数字事件驱动神经形态处理器上的脉冲神经网络 (SNNs)，其中不仅优化突触权重，还共同优化每个突触的延迟，以提升处理复杂时间动态任务的性能和效率。框架采用基于脉冲的后向传播通过时间 (spike-based back-propagation-through-time) 进行训练，同时考虑平台约束如突触权重精度和参数数量，并引入延迟修剪技术来降低内存占用。实验在 Intel Loihi 和 Imec Seneca 平台上评估 SHD (Spiking Heidelberg Digits) 分类任务，结果显示模型从软件到硬件过渡时准确性退化最小；此外，论文贡献了一个新型的面积和内存高效硬件结构，集成到 Seneca 以支持突触延迟。这是首个展示如何训练和部署带有突触延迟参数的硬件感知模型的工作。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10597v1",
      "published_date": "2024-04-16 14:22:58 UTC",
      "updated_date": "2024-04-16 14:22:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:53:31.809919"
    },
    {
      "arxiv_id": "2404.10591v2",
      "title": "Learning Symbolic Task Representation from a Human-Led Demonstration: A Memory to Store, Retrieve, Consolidate, and Forget Experiences",
      "title_zh": "翻译失败",
      "authors": [
        "Luca Buoncompagni",
        "Fulvio Mastrogiovanni"
      ],
      "abstract": "We present a symbolic learning framework inspired by cognitive-like memory\nfunctionalities (i.e., storing, retrieving, consolidating and forgetting) to\ngenerate task representations to support high-level task planning and knowledge\nbootstrapping. We address a scenario involving a non-expert human, who performs\na single task demonstration, and a robot, which online learns structured\nknowledge to re-execute the task based on experiences, i.e., observations. We\nconsider a one-shot learning process based on non-annotated data to store an\nintelligible representation of the task, which can be refined through\ninteraction, e.g., via verbal or visual communication. Our general-purpose\nframework relies on fuzzy Description Logic, which has been used to extend the\npreviously developed Scene Identification and Tagging algorithm. In this paper,\nwe exploit such an algorithm to implement cognitive-like memory functionalities\nemploying scores that rank memorised observations over time based on simple\nheuristics. Our main contribution is the formalisation of a framework that can\nbe used to systematically investigate different heuristics for bootstrapping\nhierarchical knowledge representations based on robot observations. Through an\nillustrative assembly task scenario, the paper presents the performance of our\nframework to discuss its benefits and limitations.",
      "tldr_zh": "本研究提出一个受认知记忆启发的符号学习框架，旨在通过存储、检索、巩固和遗忘功能生成任务表示，支持高层任务规划和知识引导。该框架针对非专家人类进行单次演示的场景，让机器人从非标注观察数据中实现one-shot learning，并使用fuzzy Description Logic扩展的Scene Identification and Tagging算法来处理记忆功能。研究的主要贡献是形式化该框架，用于系统探索基于机器人观察的层次知识表示启发式方法；通过一个组装任务场景的实验，展示了框架的性能及其优势和局限性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC",
        "cs.LO",
        "68T40 (Primary) 68T20, 68T27, 68T30, 68T37, 05C72, 68Q32 (Secondary)",
        "I.2.4; I.2.6; E.1"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10591v2",
      "published_date": "2024-04-16 14:14:34 UTC",
      "updated_date": "2024-04-19 14:21:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:53:41.084054"
    },
    {
      "arxiv_id": "2404.10579v1",
      "title": "The application of Augmented Reality (AR) in Remote Work and Education",
      "title_zh": "增强现实 (AR) 在远程工作和教育中的应用",
      "authors": [
        "Keqin Li",
        "Peng Xirui",
        "Jintong Song",
        "Bo Hong",
        "Jin Wang"
      ],
      "abstract": "With the rapid advancement of technology, Augmented Reality (AR) technology,\nknown for its ability to deeply integrate virtual information with the real\nworld, is gradually transforming traditional work modes and teaching methods.\nParticularly in the realms of remote work and online education, AR technology\ndemonstrates a broad spectrum of application prospects. This paper delves into\nthe application potential and actual effects of AR technology in remote work\nand education. Through a systematic literature review, this study outlines the\nkey features, advantages, and challenges of AR technology. Based on theoretical\nanalysis, it discusses the scientific basis and technical support that AR\ntechnology provides for enhancing remote work efficiency and promoting\ninnovation in educational teaching models. Additionally, by designing an\nempirical research plan and analyzing experimental data, this article reveals\nthe specific performance and influencing factors of AR technology in practical\napplications. Finally, based on the results of the experiments, this research\nsummarizes the application value of AR technology in remote work and education,\nlooks forward to its future development trends, and proposes forward-looking\nresearch directions and strategic suggestions, offering empirical foundation\nand theoretical guidance for further promoting the in-depth application of AR\ntechnology in related fields.",
      "tldr_zh": "这篇论文探讨了Augmented Reality (AR)技术在远程工作和在线教育中的应用潜力，通过系统文献综述和理论分析，概述了AR的关键特征、优势（如提升效率和创新教学模式）以及面临的挑战。研究基于实证研究计划和实验数据分析，揭示了AR在实际应用中的具体表现和影响因素。结果显示，AR为远程工作效率和教育创新提供了科学基础和技术支持。最终，论文总结了AR的应用价值，展望其未来发展趋势，并提出相关研究方向和战略建议。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10579v1",
      "published_date": "2024-04-16 14:04:46 UTC",
      "updated_date": "2024-04-16 14:04:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:53:53.834516"
    },
    {
      "arxiv_id": "2404.10575v1",
      "title": "EMC$^2$: Efficient MCMC Negative Sampling for Contrastive Learning with Global Convergence",
      "title_zh": "翻译失败",
      "authors": [
        "Chung-Yiu Yau",
        "Hoi-To Wai",
        "Parameswaran Raman",
        "Soumajyoti Sarkar",
        "Mingyi Hong"
      ],
      "abstract": "A key challenge in contrastive learning is to generate negative samples from\na large sample set to contrast with positive samples, for learning better\nencoding of the data. These negative samples often follow a softmax\ndistribution which are dynamically updated during the training process.\nHowever, sampling from this distribution is non-trivial due to the high\ncomputational costs in computing the partition function. In this paper, we\npropose an Efficient Markov Chain Monte Carlo negative sampling method for\nContrastive learning (EMC$^2$). We follow the global contrastive learning loss\nas introduced in SogCLR, and propose EMC$^2$ which utilizes an adaptive\nMetropolis-Hastings subroutine to generate hardness-aware negative samples in\nan online fashion during the optimization. We prove that EMC$^2$ finds an\n$\\mathcal{O}(1/\\sqrt{T})$-stationary point of the global contrastive loss in\n$T$ iterations. Compared to prior works, EMC$^2$ is the first algorithm that\nexhibits global convergence (to stationarity) regardless of the choice of batch\nsize while exhibiting low computation and memory cost. Numerical experiments\nvalidate that EMC$^2$ is effective with small batch training and achieves\ncomparable or better performance than baseline algorithms. We report the\nresults for pre-training image encoders on STL-10 and Imagenet-100.",
      "tldr_zh": "本论文针对对比学习（Contrastive Learning）中负样本生成面临的挑战，提出了一种高效的 Markov Chain Monte Carlo (MCMC) 负采样方法 EMC²，以从动态 softmax 分布中生成 hardness-aware 负样本。EMC² 基于 SogCLR 的全局对比学习损失，利用自适应 Metropolis-Hastings 子程序，在优化过程中在线采样负样本，并证明该算法在 T 迭代中可达到 O(1/√T) 的驻点，同时不依赖批量大小实现全局收敛，且计算和内存成本较低。实验结果显示，EMC² 在小批量训练下有效，并在 STL-10 和 Imagenet-100 数据集上预训练图像编码器时，性能与基线算法相当或优于后者。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "20 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.10575v1",
      "published_date": "2024-04-16 13:53:58 UTC",
      "updated_date": "2024-04-16 13:53:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:54:05.623685"
    },
    {
      "arxiv_id": "2404.10574v1",
      "title": "Uncertainty-guided Open-Set Source-Free Unsupervised Domain Adaptation with Target-private Class Segregation",
      "title_zh": "翻译失败",
      "authors": [
        "Mattia Litrico",
        "Davide Talon",
        "Sebastiano Battiato",
        "Alessio Del Bue",
        "Mario Valerio Giuffrida",
        "Pietro Morerio"
      ],
      "abstract": "Standard Unsupervised Domain Adaptation (UDA) aims to transfer knowledge from\na labeled source domain to an unlabeled target but usually requires\nsimultaneous access to both source and target data. Moreover, UDA approaches\ncommonly assume that source and target domains share the same labels space.\nYet, these two assumptions are hardly satisfied in real-world scenarios. This\npaper considers the more challenging Source-Free Open-set Domain Adaptation\n(SF-OSDA) setting, where both assumptions are dropped. We propose a novel\napproach for SF-OSDA that exploits the granularity of target-private categories\nby segregating their samples into multiple unknown classes. Starting from an\ninitial clustering-based assignment, our method progressively improves the\nsegregation of target-private samples by refining their pseudo-labels with the\nguide of an uncertainty-based sample selection module. Additionally, we propose\na novel contrastive loss, named NL-InfoNCELoss, that, integrating negative\nlearning into self-supervised contrastive learning, enhances the model\nrobustness to noisy pseudo-labels. Extensive experiments on benchmark datasets\ndemonstrate the superiority of the proposed method over existing approaches,\nestablishing new state-of-the-art performance. Notably, additional analyses\nshow that our method is able to learn the underlying semantics of novel\nclasses, opening the possibility to perform novel class discovery.",
      "tldr_zh": "这篇论文针对Source-Free Open-set Domain Adaptation (SF-OSDA)问题，提出了一种新方法，通过将目标私有类别分离成多个未知类，并利用不确定性指导来逐步改进伪标签的准确性。方法包括基于聚类的初始分配、不确定性样本选择模块，以及新型对比损失NL-InfoNCE Loss，该损失将负学习融入自监督对比学习中，以提升模型对噪声伪标签的鲁棒性。在基准数据集上的广泛实验表明，该方法优于现有方法，建立了新的最先进性能，并展示了学习新类底层语义的能力，支持潜在的新类发现。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10574v1",
      "published_date": "2024-04-16 13:52:00 UTC",
      "updated_date": "2024-04-16 13:52:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:54:19.546413"
    },
    {
      "arxiv_id": "2404.10573v2",
      "title": "AAVDiff: Experimental Validation of Enhanced Viability and Diversity in Recombinant Adeno-Associated Virus (AAV) Capsids through Diffusion Generation",
      "title_zh": "AAVDiff：通过扩散生成增强重组腺相关病毒（AAV）衣壳活力和多样性的实验验证",
      "authors": [
        "Lijun Liu",
        "Jiali Yang",
        "Jianfei Song",
        "Xinglin Yang",
        "Lele Niu",
        "Zeqi Cai",
        "Hui Shi",
        "Tingjun Hou",
        "Chang-yu Hsieh",
        "Weiran Shen",
        "Yafeng Deng"
      ],
      "abstract": "Recombinant adeno-associated virus (rAAV) vectors have revolutionized gene\ntherapy, but their broad tropism and suboptimal transduction efficiency limit\ntheir clinical applications. To overcome these limitations, researchers have\nfocused on designing and screening capsid libraries to identify improved\nvectors. However, the large sequence space and limited resources present\nchallenges in identifying viable capsid variants. In this study, we propose an\nend-to-end diffusion model to generate capsid sequences with enhanced\nviability. Using publicly available AAV2 data, we generated 38,000 diverse AAV2\nviral protein (VP) sequences, and evaluated 8,000 for viral selection. The\nresults attested the superiority of our model compared to traditional methods.\nAdditionally, in the absence of AAV9 capsid data, apart from one wild-type\nsequence, we used the same model to directly generate a number of viable\nsequences with up to 9 mutations. we transferred the remaining 30,000 samples\nto the AAV9 domain. Furthermore, we conducted mutagenesis on AAV9 VP\nhypervariable regions VI and V, contributing to the continuous improvement of\nthe AAV9 VP sequence. This research represents a significant advancement in the\ndesign and functional validation of rAAV vectors, offering innovative solutions\nto enhance specificity and transduction efficiency in gene therapy\napplications.",
      "tldr_zh": "本文提出AAVDiff，一种基于diffusion model的端到端方法，用于生成重组腺相关病毒(rAAV)衣壳序列，以解决其广泛嗜性和低转导效率的问题。研究者利用AAV2公开数据生成了38,000个多样VP序列，并评估了8,000个进行病毒选择，结果显示该模型在活力和多样性上优于传统方法。进一步扩展到AAV9领域，该方法成功生成了多达9个突变的 viable 序列，并通过对超变异区域的突变实验持续优化VP序列，为基因治疗的特异性和转导效率提供了重大进展。",
      "categories": [
        "cs.AI",
        "cs.CE",
        "q-bio.BM"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10573v2",
      "published_date": "2024-04-16 13:51:43 UTC",
      "updated_date": "2024-04-17 12:08:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:54:31.608027"
    },
    {
      "arxiv_id": "2404.10552v1",
      "title": "Unveiling the Misuse Potential of Base Large Language Models via In-Context Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Xiao Wang",
        "Tianze Chen",
        "Xianjun Yang",
        "Qi Zhang",
        "Xun Zhao",
        "Dahua Lin"
      ],
      "abstract": "The open-sourcing of large language models (LLMs) accelerates application\ndevelopment, innovation, and scientific progress. This includes both base\nmodels, which are pre-trained on extensive datasets without alignment, and\naligned models, deliberately designed to align with ethical standards and human\nvalues. Contrary to the prevalent assumption that the inherent\ninstruction-following limitations of base LLMs serve as a safeguard against\nmisuse, our investigation exposes a critical oversight in this belief. By\ndeploying carefully designed demonstrations, our research demonstrates that\nbase LLMs could effectively interpret and execute malicious instructions. To\nsystematically assess these risks, we introduce a novel set of risk evaluation\nmetrics. Empirical results reveal that the outputs from base LLMs can exhibit\nrisk levels on par with those of models fine-tuned for malicious purposes. This\nvulnerability, requiring neither specialized knowledge nor training, can be\nmanipulated by almost anyone, highlighting the substantial risk and the\ncritical need for immediate attention to the base LLMs' security protocols.",
      "tldr_zh": "本研究揭示了 base Large Language Models (LLMs) 通过 In-Context Learning 的滥用潜力，挑战了这些模型因指令遵循限制而难以被误用的假设。研究者通过设计精心演示(demonstrations)，证明 base LLMs 可以有效解释和执行恶意指令，并引入了新的风险评估指标。实验结果显示，base LLMs 的输出风险水平与恶意微调模型相当，这种易于利用的漏洞无需专业知识或训练，强调了立即加强 base LLMs 安全协议的必要性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10552v1",
      "published_date": "2024-04-16 13:22:54 UTC",
      "updated_date": "2024-04-16 13:22:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:54:43.063533"
    },
    {
      "arxiv_id": "2404.10551v1",
      "title": "The Evolution of Learning: Assessing the Transformative Impact of Generative AI on Higher Education",
      "title_zh": "翻译失败",
      "authors": [
        "Stefanie Krause",
        "Bhumi Hitesh Panchal",
        "Nikhil Ubhe"
      ],
      "abstract": "Generative Artificial Intelligence (GAI) models such as ChatGPT have\nexperienced a surge in popularity, attracting 100 million active users in 2\nmonths and generating an estimated 10 million daily queries. Despite this\nremarkable adoption, there remains a limited understanding to which extent this\ninnovative technology influences higher education. This research paper\ninvestigates the impact of GAI on university students and Higher Education\nInstitutions (HEIs). The study adopts a mixed-methods approach, combining a\ncomprehensive survey with scenario analysis to explore potential benefits,\ndrawbacks, and transformative changes the new technology brings. Using an\nonline survey with 130 participants we assessed students' perspectives and\nattitudes concerning present ChatGPT usage in academics. Results show that\nstudents use the current technology for tasks like assignment writing and exam\npreparation and believe it to be a effective help in achieving academic goals.\nThe scenario analysis afterwards projected potential future scenarios,\nproviding valuable insights into the possibilities and challenges associated\nwith incorporating GAI into higher education. The main motivation is to gain a\ntangible and precise understanding of the potential consequences for HEIs and\nto provide guidance responding to the evolving learning environment. The\nfindings indicate that irresponsible and excessive use of the technology could\nresult in significant challenges. Hence, HEIs must develop stringent policies,\nreevaluate learning objectives, upskill their lecturers, adjust the curriculum\nand reconsider examination approaches.",
      "tldr_zh": "这篇论文探讨了生成式人工智能(Generative AI, GAI)如 ChatGPT 对高等教育的变革性影响，调查了其对大学学生和高等教育机构(HEIs)的潜在益处、缺点及变化。研究采用混合方法，包括对130名参与者的在线调查和场景分析，结果显示学生常使用GAI进行作业写作和考试准备，并认为它有助于实现学术目标。场景分析预测了未来整合GAI的可能挑战，如不负责任的使用可能导致重大问题。论文建议HEIs制定严格政策、重新评估学习目标、提升讲师技能、调整课程和优化考试方式，以应对这一演变的学习环境。",
      "categories": [
        "cs.AI",
        "cs.ET",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10551v1",
      "published_date": "2024-04-16 13:19:57 UTC",
      "updated_date": "2024-04-16 13:19:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:54:54.983786"
    },
    {
      "arxiv_id": "2407.00004v1",
      "title": "Multi-objective generative AI for designing novel brain-targeting small molecules",
      "title_zh": "多目标生成式人工智能用于设计新型脑靶向小分子",
      "authors": [
        "Ayush Noori",
        "Iñaki Arango",
        "William E. Byrd",
        "Nada Amin"
      ],
      "abstract": "The strict selectivity of the blood-brain barrier (BBB) represents one of the\nmost formidable challenges to successful central nervous system (CNS) drug\ndelivery. Computational methods to generate BBB permeable drugs in silico may\nbe valuable tools in the CNS drug design pipeline. However, in real-world\napplications, BBB penetration alone is insufficient; rather, after transiting\nthe BBB, molecules must bind to a specific target or receptor in the brain and\nmust also be safe and non-toxic. To discover small molecules that concurrently\nsatisfy these constraints, we use multi-objective generative AI to synthesize\ndrug-like BBB-permeable small molecules. Specifically, we computationally\nsynthesize molecules with predicted binding affinity against dopamine receptor\nD2, the primary target for many clinically effective antipsychotic drugs. After\ntraining several graph neural network-based property predictors, we adapt\nSyntheMol (Swanson et al., 2024), a recently developed Monte Carlo Tree\nSearch-based algorithm for antibiotic design, to perform a multi-objective\nguided traversal over an easily synthesizable molecular space. We design a\nlibrary of 26,581 novel and diverse small molecules containing hits with high\npredicted BBB permeability and favorable predicted safety and toxicity\nprofiles, and that could readily be synthesized for experimental validation in\nthe wet lab. We also validate top scoring molecules with molecular docking\nsimulation against the D2 receptor and demonstrate predicted binding affinity\non par with risperidone, a clinically prescribed D2-targeting antipsychotic. In\nthe future, the SyntheMol-based computational approach described here may\nenable the discovery of novel neurotherapeutics for currently intractable\ndisorders of the CNS.",
      "tldr_zh": "本研究利用多目标生成 AI 设计新型针对脑部的小分子药物，旨在同时满足血-brain barrier (BBB) 渗透、特定靶点结合（如多巴胺受体 D2）和安全无毒的要求。研究者训练了基于 graph neural network 的属性预测器，并改编 SyntheMol 算法（一种 Monte Carlo Tree Search 驱动的方法）来在易合成分子空间进行多目标引导遍历，从而生成了 26,581 个新颖多样的小分子库，这些分子具有高预估 BBB 渗透性和良好安全特性。分子对接模拟显示，顶尖分子与临床药物 risperidone 具有相似的预估结合亲和力，为未来发现新型中枢神经系统 (CNS) 治疗药物提供了潜在工具。",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.LG",
        "q-bio.QM"
      ],
      "primary_category": "q-bio.BM",
      "comment": "20 pages, 4 figures, Generative and Experimental Perspectives for\n  Biomolecular Design Workshop at the 12th International Conference on Learning\n  Representations",
      "pdf_url": "http://arxiv.org/pdf/2407.00004v1",
      "published_date": "2024-04-16 12:57:06 UTC",
      "updated_date": "2024-04-16 12:57:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:55:07.792533"
    },
    {
      "arxiv_id": "2404.10513v2",
      "title": "CoTAR: Chain-of-Thought Attribution Reasoning with Multi-level Granularity",
      "title_zh": "翻译失败",
      "authors": [
        "Moshe Berchansky",
        "Daniel Fleischer",
        "Moshe Wasserblat",
        "Peter Izsak"
      ],
      "abstract": "State-of-the-art performance in QA tasks is currently achieved by systems\nemploying Large Language Models (LLMs), however these models tend to\nhallucinate information in their responses. One approach focuses on enhancing\nthe generation process by incorporating attribution from the given input to the\noutput. However, the challenge of identifying appropriate attributions and\nverifying their accuracy against a source is a complex task that requires\nsignificant improvements in assessing such systems. We introduce an\nattribution-oriented Chain-of-Thought reasoning method to enhance the accuracy\nof attributions. This approach focuses the reasoning process on generating an\nattribution-centric output. Evaluations on two context-enhanced\nquestion-answering datasets using GPT-4 demonstrate improved accuracy and\ncorrectness of attributions. In addition, the combination of our method with\nfinetuning enhances the response and attribution accuracy of two smaller LLMs,\nshowing their potential to outperform GPT-4 in some cases.",
      "tldr_zh": "该论文提出CoTAR，一种基于Chain-of-Thought Attribution Reasoning with Multi-level Granularity 的方法，旨在解决Large Language Models (LLMs) 在QA tasks 中产生的幻觉问题，通过多级粒度聚焦归因推理来提升输出准确性。该方法强调生成以归因为中心的响应，并在两个context-enhanced question-answering数据集上使用GPT-4进行评估，显示了归因准确性和正确性的显著改进。此外，将CoTAR与微调结合后，较小的LLMs在某些情况下超过了GPT-4的表现，为构建更可靠的LLMs系统提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Findings of the Association for Computational Linguistics: EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.10513v2",
      "published_date": "2024-04-16 12:37:10 UTC",
      "updated_date": "2024-11-26 21:43:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:55:20.084944"
    },
    {
      "arxiv_id": "2404.10508v4",
      "title": "White Men Lead, Black Women Help? Benchmarking Language Agency Social Biases in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Yixin Wan",
        "Kai-Wei Chang"
      ],
      "abstract": "Social biases can manifest in language agency. While several studies\napproached agency-related bias in human-written language, very limited research\nhas investigated such biases in Large Language Model (LLM)-generated content.\nIn addition, previous works often rely on string-matching techniques to\nidentify agentic and communal words within texts, which fall short of\naccurately classifying language agency. We introduce the novel Language Agency\nBias Evaluation (LABE) benchmark, which comprehensively evaluates biases in\nLLMs by analyzing agency levels attributed to different demographic groups in\nmodel generations. LABE leverages 5,400 template-based prompts, an accurate\nagency classifier, and corresponding bias metrics to test for gender, racial,\nand intersectional language agency biases in LLMs on 3 text generation tasks:\nbiographies, professor reviews, and reference letters. We also contribute the\nLanguage Agency Classification (LAC) dataset, consisting of 3,724 agentic and\ncommunal sentences. Using LABE, we unveil language agency social biases in 3\nrecent LLMs: ChatGPT, Llama3, and Mistral. We observe that: (1) LLM generations\ntend to demonstrate greater gender bias than human-written texts; (2) Models\ndemonstrate remarkably higher levels of intersectional bias than the other bias\naspects. Those who are at the intersection of gender and racial minority\ngroups--such as Black females--are consistently described by texts with lower\nlevels of agency, aligning with real-world social inequalities; (3) Among the 3\nLLMs investigated, Llama3 demonstrates the greatest overall bias; (4) Not only\ndoes prompt-based mitigation fail to resolve language agency bias in LLMs, but\nit frequently leads to the exacerbation of biases in generated texts.",
      "tldr_zh": "本论文探讨了大型语言模型(LLM)生成的文本中存在的语言代理偏见，特别是在性别、种族和交叉性方面。研究者引入了Language Agency Bias Evaluation (LABE)基准，利用5400个模板提示和一个精确的代理分类器，对ChatGPT、Llama3和Mistral等模型在传记、教授评论和推荐信等任务上进行偏见评估，同时贡献了Language Agency Classification (LAC)数据集，包含3724个代理和社区句子。结果显示，LLM生成的文本比人类文本表现出更大的性别偏见，且交叉偏见（如针对黑人女性的低代理水平）更为严重，其中Llama3的整体偏见最大；此外，提示-based缓解方法非但无效，还可能加剧偏见，这反映了现实社会不平等。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10508v4",
      "published_date": "2024-04-16 12:27:54 UTC",
      "updated_date": "2024-10-24 17:43:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:55:31.883864"
    },
    {
      "arxiv_id": "2404.10505v1",
      "title": "Data Collection of Real-Life Knowledge Work in Context: The RLKWiC Dataset",
      "title_zh": "翻译失败",
      "authors": [
        "Mahta Bakhshizadeh",
        "Christian Jilek",
        "Markus Schröder",
        "Heiko Maus",
        "Andreas Dengel"
      ],
      "abstract": "Over the years, various approaches have been employed to enhance the\nproductivity of knowledge workers, from addressing psychological well-being to\nthe development of personal knowledge assistants. A significant challenge in\nthis research area has been the absence of a comprehensive, publicly accessible\ndataset that mirrors real-world knowledge work. Although a handful of datasets\nexist, many are restricted in access or lack vital information dimensions,\ncomplicating meaningful comparison and benchmarking in the domain. This paper\npresents RLKWiC, a novel dataset of Real-Life Knowledge Work in Context,\nderived from monitoring the computer interactions of eight participants over a\nspan of two months. As the first publicly available dataset offering a wealth\nof essential information dimensions (such as explicated contexts, textual\ncontents, and semantics), RLKWiC seeks to address the research gap in the\npersonal information management domain, providing valuable insights for\nmodeling user behavior.",
      "tldr_zh": "本文研究了知识工作者的生产力提升问题，指出现有数据集因访问限制或信息缺失而难以进行有效比较和基准测试。作者引入 RLKWiC dataset，这是一个通过监控八名参与者两个月的计算机互动而收集的首个公开数据集，涵盖上下文、文本内容和语义等关键信息维度。该数据集填补了个人信息管理领域的研发空白，为用户行为建模提供宝贵洞见。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted and presented at the 10th International Conference on\n  Information Management (ICIM2024), will be published in Springer CCIS series\n  Conference Proceedings (Electronic ISSN: 1865-0937; Print ISSN: 1865-0929)",
      "pdf_url": "http://arxiv.org/pdf/2404.10505v1",
      "published_date": "2024-04-16 12:23:59 UTC",
      "updated_date": "2024-04-16 12:23:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:55:41.906693"
    },
    {
      "arxiv_id": "2404.10503v1",
      "title": "A Sentiment Analysis of Medical Text Based on Deep Learning",
      "title_zh": "基于深度学习的医疗文本情感分析",
      "authors": [
        "Yinan Chen"
      ],
      "abstract": "The field of natural language processing (NLP) has made significant progress\nwith the rapid development of deep learning technologies. One of the research\ndirections in text sentiment analysis is sentiment analysis of medical texts,\nwhich holds great potential for application in clinical diagnosis. However, the\nmedical field currently lacks sufficient text datasets, and the effectiveness\nof sentiment analysis is greatly impacted by different model design approaches,\nwhich presents challenges. Therefore, this paper focuses on the medical domain,\nusing bidirectional encoder representations from transformers (BERT) as the\nbasic pre-trained model and experimenting with modules such as convolutional\nneural network (CNN), fully connected network (FCN), and graph convolutional\nnetworks (GCN) at the output layer. Experiments and analyses were conducted on\nthe METS-CoV dataset to explore the training performance after integrating\ndifferent deep learning networks. The results indicate that CNN models\noutperform other networks when trained on smaller medical text datasets in\ncombination with pre-trained models like BERT. This study highlights the\nsignificance of model selection in achieving effective sentiment analysis in\nthe medical domain and provides a reference for future research to develop more\nefficient model architectures.",
      "tldr_zh": "这篇论文探讨了基于深度学习的医疗文本情感分析，针对医疗领域数据集不足和模型设计挑战的问题，使用 BERT 作为基础预训练模型，并在输出层整合 CNN、FCN 和 GCN 等网络进行实验。研究在 METS-CoV 数据集上评估了不同网络的训练性能，结果表明 CNN 模型在结合 BERT 的小规模数据集上表现最佳。论文强调了模型选择对医疗情感分析的重要性，并为未来开发更高效的模型架构提供参考。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10503v1",
      "published_date": "2024-04-16 12:20:49 UTC",
      "updated_date": "2024-04-16 12:20:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:55:54.552739"
    },
    {
      "arxiv_id": "2404.10501v2",
      "title": "Self-Supervised Visual Preference Alignment",
      "title_zh": "自监督视觉偏好对齐",
      "authors": [
        "Ke Zhu",
        "Zheng Ge",
        "Liang Zhao",
        "Xiangyu Zhang"
      ],
      "abstract": "This paper makes the first attempt towards unsupervised preference alignment\nin Vision-Language Models (VLMs). We generate chosen and rejected responses\nwith regard to the original and augmented image pairs, and conduct preference\nalignment with direct preference optimization. It is based on a core idea:\nproperly designed augmentation to the image input will induce VLM to generate\nfalse but hard negative responses, which helps the model to learn from and\nproduce more robust and powerful answers. The whole pipeline no longer hinges\non supervision from GPT-4 or human involvement during alignment, and is highly\nefficient with few lines of code. With only 8k randomly sampled unsupervised\ndata, it achieves 90\\% relative score to GPT-4 on complex reasoning in\nLLaVA-Bench, and improves LLaVA-7B/13B by 6.7\\%/5.6\\% score on complex\nmulti-modal benchmark MM-Vet. Visualizations shows its improved ability to\nalign with user-intentions. A series of ablations are firmly conducted to\nreveal the latent mechanism of the approach, which also indicates its potential\ntowards further scaling. Code are available in\nhttps://github.com/Kevinz-code/SeVa.",
      "tldr_zh": "这篇论文首次提出Self-Supervised Visual Preference Alignment，一种无监督偏好对齐方法，用于提升Vision-Language Models (VLMs)的性能。该方法通过对图像输入进行适当的augmentation，生成chosen和rejected响应，并采用direct preference optimization进行训练，从而利用虚假但有挑战性的负样本增强模型的鲁棒性和输出质量。实验结果显示，仅使用8k随机无监督数据，该方法在LLaVA-Bench上的复杂推理得分达到GPT-4的90%相对水平，并在MM-Vet基准上使LLaVA-7B/13B模型提升6.7%/5.6%。此外，通过可视化和消融实验，该方法证明了其对用户意图对齐的改善潜力，并揭示了其潜在机制。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "MM2024 oral",
      "pdf_url": "http://arxiv.org/pdf/2404.10501v2",
      "published_date": "2024-04-16 12:19:54 UTC",
      "updated_date": "2024-08-21 11:36:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:56:08.648731"
    },
    {
      "arxiv_id": "2404.10500v1",
      "title": "When Emotional Stimuli meet Prompt Designing: An Auto-Prompt Graphical Paradigm",
      "title_zh": "翻译失败",
      "authors": [
        "Chenggian Ma",
        "Xiangyu Zhao",
        "Chunhui Zhang",
        "Yanzhao Qin",
        "Wentao Zhang"
      ],
      "abstract": "With the development of Large Language Models (LLM), numerous prompts have\nbeen proposed, each with a rich set of features and their own merits. This\npaper summarizes the prompt words for large language models (LLMs),\ncategorizing them into stimulating and framework types, and proposes an\nAuto-Prompt Graphical Paradigm(APGP) that combines both stimulating and\nframework prompts to enhance the problem-solving capabilities of LLMs across\nmultiple domains, then exemplifies it with a framework that adheres to this\nparadigm. The framework involves automated prompt generation and consideration\nof emotion-stimulus factors, guiding LLMs in problem abstraction, diversified\nsolutions generation, comprehensive optimization, and self-verification after\nproviding answers, ensuring solution accuracy. Compared to traditional stimuli\nand framework prompts, this framework integrates the advantages of both by\nadopting automated approaches inspired by APE work, overcoming the limitations\nof manually designed prompts. Test results on the ruozhiba and BBH datasets\ndemonstrate that this framework can effectively improve the efficiency and\naccuracy of LLMs in problem-solving, paving the way for new applications of\nLLMs.",
      "tldr_zh": "本研究总结了Large Language Models (LLM) 的提示词类型，包括刺激型和框架型，并提出Auto-Prompt Graphical Paradigm (APGP)，一种结合情感刺激因素的自动提示生成框架，以提升LLM在多领域问题解决的能力。APGP 通过自动化方法引导LLM进行问题抽象、多样化解决方案生成、全面优化和自我验证，从而克服传统手动提示的局限。实验在ruozhiba和BBH数据集上显示，该框架显著提高了LLM的效率和准确性，为LLM的新应用铺平道路。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T20",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.10500v1",
      "published_date": "2024-04-16 12:19:08 UTC",
      "updated_date": "2024-04-16 12:19:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:56:19.986759"
    },
    {
      "arxiv_id": "2404.10499v1",
      "title": "Robust Noisy Label Learning via Two-Stream Sample Distillation",
      "title_zh": "基于双流样本蒸馏的鲁棒噪声标签学习",
      "authors": [
        "Sihan Bai",
        "Sanping Zhou",
        "Zheng Qin",
        "Le Wang",
        "Nanning Zheng"
      ],
      "abstract": "Noisy label learning aims to learn robust networks under the supervision of\nnoisy labels, which plays a critical role in deep learning. Existing work\neither conducts sample selection or label correction to deal with noisy labels\nduring the model training process. In this paper, we design a simple yet\neffective sample selection framework, termed Two-Stream Sample Distillation\n(TSSD), for noisy label learning, which can extract more high-quality samples\nwith clean labels to improve the robustness of network training. Firstly, a\nnovel Parallel Sample Division (PSD) module is designed to generate a certain\ntraining set with sufficient reliable positive and negative samples by jointly\nconsidering the sample structure in feature space and the human prior in loss\nspace. Secondly, a novel Meta Sample Purification (MSP) module is further\ndesigned to mine adequate semi-hard samples from the remaining uncertain\ntraining set by learning a strong meta classifier with extra golden data. As a\nresult, more and more high-quality samples will be distilled from the noisy\ntraining set to train networks robustly in every iteration. Extensive\nexperiments on four benchmark datasets, including CIFAR-10, CIFAR-100,\nTiny-ImageNet, and Clothing-1M, show that our method has achieved\nstate-of-the-art results over its competitors.",
      "tldr_zh": "本论文针对 Noisy label learning（噪声标签学习）问题，提出了一种简单有效的样本选择框架 Two-Stream Sample Distillation (TSSD)，旨在通过提炼高质量样本提升深度学习模型的鲁棒性。框架包括 Parallel Sample Division (PSD) 模块，该模块结合特征空间的样本结构和损失空间的人为先验，生成可靠的正负样本集；以及 Meta Sample Purification (MSP) 模块，该模块利用额外黄金数据训练元分类器，从不确定样本中挖掘半硬样本，实现迭代式样本提炼。在 CIFAR-10、CIFAR-100、Tiny-ImageNet 和 Clothing-1M 等基准数据集上的实验表明，该方法比现有方法取得了 state-of-the-art 的性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10499v1",
      "published_date": "2024-04-16 12:18:08 UTC",
      "updated_date": "2024-04-16 12:18:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:56:33.722094"
    },
    {
      "arxiv_id": "2404.10498v1",
      "title": "LAECIPS: Large Vision Model Assisted Adaptive Edge-Cloud Collaboration for IoT-based Perception System",
      "title_zh": "LAECIPS：大型视觉模型辅助的自适应边云协作，用于基于 IoT 的感知系统",
      "authors": [
        "Shijing Hu",
        "Ruijun Deng",
        "Xin Du",
        "Zhihui Lu",
        "Qiang Duan",
        "Yi He",
        "Shih-Chia Huang",
        "Jie Wu"
      ],
      "abstract": "Recent large vision models (e.g., SAM) enjoy great potential to facilitate\nintelligent perception with high accuracy. Yet, the resource constraints in the\nIoT environment tend to limit such large vision models to be locally deployed,\nincurring considerable inference latency thereby making it difficult to support\nreal-time applications, such as autonomous driving and robotics. Edge-cloud\ncollaboration with large-small model co-inference offers a promising approach\nto achieving high inference accuracy and low latency. However, existing\nedge-cloud collaboration methods are tightly coupled with the model\narchitecture and cannot adapt to the dynamic data drifts in heterogeneous IoT\nenvironments. To address the issues, we propose LAECIPS, a new edge-cloud\ncollaboration framework. In LAECIPS, both the large vision model on the cloud\nand the lightweight model on the edge are plug-and-play. We design an\nedge-cloud collaboration strategy based on hard input mining, optimized for\nboth high accuracy and low latency. We propose to update the edge model and its\ncollaboration strategy with the cloud under the supervision of the large vision\nmodel, so as to adapt to the dynamic IoT data streams. Theoretical analysis of\nLAECIPS proves its feasibility. Experiments conducted in a robotic semantic\nsegmentation system using real-world datasets show that LAECIPS outperforms its\nstate-of-the-art competitors in accuracy, latency, and communication overhead\nwhile having better adaptability to dynamic environments.",
      "tldr_zh": "该论文提出 LAECIPS 框架，利用 Large Vision Model（如 SAM）辅助的自适应 Edge-Cloud Collaboration，解决 IoT 感知系统中的资源限制和高推断延迟问题。LAECIPS 允许云端大型视觉模型和边缘轻量模型即插即用，并通过基于 Hard Input Mining 的策略优化准确性和延迟。框架还包括大型模型监督下的边缘模型更新机制，以适应动态 IoT 数据流。实验在机器人语义分割系统中表明，LAECIPS 优于现有方法，在准确性、延迟和通信开销方面表现出色，并具备更好的动态环境适应性。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.DC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10498v1",
      "published_date": "2024-04-16 12:12:06 UTC",
      "updated_date": "2024-04-16 12:12:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:56:46.594448"
    },
    {
      "arxiv_id": "2404.10464v3",
      "title": "DESTEIN: Navigating Detoxification of Language Models via Universal Steering Pairs and Head-wise Activation Fusion",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Li",
        "Han Jiang",
        "Chuanyang Gong",
        "Zhihua Wei"
      ],
      "abstract": "Despite the remarkable achievements of language models (LMs) across a broad\nspectrum of tasks, their propensity for generating toxic outputs remains a\nprevalent concern. Current solutions involving finetuning or auxiliary models\nusually require extensive computational resources, hindering their practicality\nin large language models (LLMs). In this paper, we propose DeStein, a novel\nmethod that detoxifies LMs by applying representation engineering in activation\nspaces with lower resource and time costs. Specifically, we derive\ndetoxification vectors from self-induced, universal steering pairs through\narithmetic operations in activation spaces. During inference, detoxification is\nachieved by fusing the detoxification vectors with the original representations\nin a head-wise manner. Empirical results demonstrate that our method\nsignificantly outperforms previous state-of-the-art approaches on various\nmetrics, while also maintaining satisfactory generation quality and diversity.\nWe further validate the practicality and scalability of DeStein with a series\nof white-box LLMs. The method is open-sourced at\nhttps://github.com/LizLizLi/DeStein. Warning: Some example model outputs may\ncontain highly offensive or disturbing text.",
      "tldr_zh": "该论文针对语言模型 (LMs) 生成毒性输出的问题，提出了一种高效的 DeStein 方法，通过在激活空间中应用表示工程来实现净化，而非依赖资源密集的微调或辅助模型。DeStein 具体利用自诱导的通用转向对 (universal steering pairs) 通过算术操作派生净化向量，并在推理过程中以头级激活融合 (head-wise activation fusion) 的方式与原表示结合。实验结果表明，该方法在各种指标上显著优于现有最先进方法，同时保持了生成质量和多样性，并验证了其在白盒 LLMs 上的实用性和可扩展性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10464v3",
      "published_date": "2024-04-16 11:07:48 UTC",
      "updated_date": "2024-08-10 14:17:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:56:58.769708"
    },
    {
      "arxiv_id": "2404.10458v1",
      "title": "Advancing Long-Term Multi-Energy Load Forecasting with Patchformer: A Patch and Transformer-Based Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Qiuyi Hong",
        "Fanlin Meng",
        "Felipe Maldonado"
      ],
      "abstract": "In the context of increasing demands for long-term multi-energy load\nforecasting in real-world applications, this paper introduces Patchformer, a\nnovel model that integrates patch embedding with encoder-decoder\nTransformer-based architectures. To address the limitation in existing\nTransformer-based models, which struggle with intricate temporal patterns in\nlong-term forecasting, Patchformer employs patch embedding, which predicts\nmultivariate time-series data by separating it into multiple univariate data\nand segmenting each of them into multiple patches. This method effectively\nenhances the model's ability to capture local and global semantic dependencies.\nThe numerical analysis shows that the Patchformer obtains overall better\nprediction accuracy in both multivariate and univariate long-term forecasting\non the novel Multi-Energy dataset and other benchmark datasets. In addition,\nthe positive effect of the interdependence among energy-related products on the\nperformance of long-term time-series forecasting across Patchformer and other\ncompared models is discovered, and the superiority of the Patchformer against\nother models is also demonstrated, which presents a significant advancement in\nhandling the interdependence and complexities of long-term multi-energy\nforecasting. Lastly, Patchformer is illustrated as the only model that follows\nthe positive correlation between model performance and the length of the past\nsequence, which states its ability to capture long-range past local semantic\ninformation.",
      "tldr_zh": "本文提出 Patchformer，一种结合 patch embedding 和 encoder-decoder Transformer 架构的模型，用于提升长期多能载荷预测的准确性。该模型通过将多变量时间序列数据分离成多个单变量并进一步分割成 patches，有效捕捉局部和全局语义依赖，解决现有 Transformer 模型在处理复杂时间模式上的局限。实验结果显示，Patchformer 在 Multi-Energy 数据集和其他基准数据集上实现了更好的预测准确率，并突显了能源相关产品间相互依赖性的积极影响。最后，Patchformer 是唯一模型，其性能与过去序列长度呈正相关，证明了其在捕捉长距离语义信息方面的优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10458v1",
      "published_date": "2024-04-16 10:56:33 UTC",
      "updated_date": "2024-04-16 10:56:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:57:09.811260"
    },
    {
      "arxiv_id": "2404.10454v1",
      "title": "A Computer Vision-Based Quality Assessment Technique for the automatic control of consumables for analytical laboratories",
      "title_zh": "一种基于计算机视觉的质量评估技术，用于分析实验室消耗品的自动控制",
      "authors": [
        "Meriam Zribi",
        "Paolo Pagliuca",
        "Francesca Pitolli"
      ],
      "abstract": "The rapid growth of the Industry 4.0 paradigm is increasing the pressure to\ndevelop effective automated monitoring systems. Artificial Intelligence (AI) is\na convenient tool to improve the efficiency of industrial processes while\nreducing errors and waste. In fact, it allows the use of real-time data to\nincrease the effectiveness of monitoring systems, minimize errors, make the\nproduction process more sustainable, and save costs. In this paper, a novel\nautomatic monitoring system is proposed in the context of production process of\nplastic consumables used in analysis laboratories, with the aim to increase the\neffectiveness of the control process currently performed by a human operator.\nIn particular, we considered the problem of classifying the presence or absence\nof a transparent anticoagulant substance inside test tubes. Specifically, a\nhand-designed deep network model is used and compared with some\nstate-of-the-art models for its ability to categorize different images of vials\nthat can be either filled with the anticoagulant or empty. Collected results\nindicate that the proposed approach is competitive with state-of-the-art models\nin terms of accuracy. Furthermore, we increased the complexity of the task by\ntraining the models on the ability to discriminate not only the presence or\nabsence of the anticoagulant inside the vial, but also the size of the test\ntube. The analysis performed in the latter scenario confirms the\ncompetitiveness of our approach. Moreover, our model is remarkably superior in\nterms of its generalization ability and requires significantly fewer resources.\nThese results suggest the possibility of successfully implementing such a model\nin the production process of a plastic consumables company.",
      "tldr_zh": "这篇论文提出了一种基于计算机视觉的自动质量评估技术，用于Industry 4.0背景下分析实验室塑料消耗品的自动控制，旨在通过Artificial Intelligence (AI)提高生产效率、减少错误和浪费。研究重点是开发一个手设计的深度网络模型，来分类试管中透明抗凝血物质的存在与否，并扩展到区分试管大小，与state-of-the-art模型进行比较。实验结果显示，该方法在准确性上与最先进模型相当，但在泛化能力和资源需求方面表现出显著优势，表明其可成功应用于实际生产过程。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "31 pages, 13 figures, 10 tables",
      "pdf_url": "http://arxiv.org/pdf/2404.10454v1",
      "published_date": "2024-04-16 10:50:16 UTC",
      "updated_date": "2024-04-16 10:50:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:57:22.455366"
    },
    {
      "arxiv_id": "2404.10445v4",
      "title": "SparseDM: Toward Sparse Efficient Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Kafeng Wang",
        "Jianfei Chen",
        "He Li",
        "Zhenpeng Mi",
        "Jun Zhu"
      ],
      "abstract": "Diffusion models represent a powerful family of generative models widely used\nfor image and video generation. However, the time-consuming deployment, long\ninference time, and requirements on large memory hinder their applications on\nresource constrained devices. In this paper, we propose a method based on the\nimproved Straight-Through Estimator to improve the deployment efficiency of\ndiffusion models. Specifically, we add sparse masks to the Convolution and\nLinear layers in a pre-trained diffusion model, then transfer learn the sparse\nmodel during the fine-tuning stage and turn on the sparse masks during\ninference. Experimental results on a Transformer and UNet-based diffusion\nmodels demonstrate that our method reduces MACs by 50% while maintaining FID.\nSparse models are accelerated by approximately 1.2x on the GPU. Under other\nMACs conditions, the FID is also lower than 1 compared to other methods.",
      "tldr_zh": "该研究提出 SparseDM 方法，旨在提升扩散模型（Diffusion models）的部署效率，以解决其推理时间长、内存需求高的问题。该方法基于改进的 Straight-Through Estimator，在预训练的扩散模型中为卷积（Convolution）和线性（Linear）层添加稀疏掩码（sparse masks），并通过微调阶段的转移学习优化模型。实验结果显示，在 Transformer 和 UNet-based 扩散模型上，该方法将 MACs 减少 50% 同时保持 FID，模型在 GPU 上加速约 1.2 倍，且在其他 MACs 条件下，FID 比其他方法低 1。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper has been accepted by ICME 2025",
      "pdf_url": "http://arxiv.org/pdf/2404.10445v4",
      "published_date": "2024-04-16 10:31:06 UTC",
      "updated_date": "2025-04-17 16:05:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:57:33.490800"
    },
    {
      "arxiv_id": "2404.10443v1",
      "title": "AGHINT: Attribute-Guided Representation Learning on Heterogeneous Information Networks with Transformer",
      "title_zh": "翻译失败",
      "authors": [
        "Jinhui Yuan",
        "Shan Lu",
        "Peibo Duan",
        "Jieyue He"
      ],
      "abstract": "Recently, heterogeneous graph neural networks (HGNNs) have achieved\nimpressive success in representation learning by capturing long-range\ndependencies and heterogeneity at the node level. However, few existing studies\nhave delved into the utilization of node attributes in heterogeneous\ninformation networks (HINs). In this paper, we investigate the impact of\ninter-node attribute disparities on HGNNs performance within the benchmark\ntask, i.e., node classification, and empirically find that typical models\nexhibit significant performance decline when classifying nodes whose attributes\nmarkedly differ from their neighbors. To alleviate this issue, we propose a\nnovel Attribute-Guided heterogeneous Information Networks representation\nlearning model with Transformer (AGHINT), which allows a more effective\naggregation of neighbor node information under the guidance of attributes.\nSpecifically, AGHINT transcends the constraints of the original graph structure\nby directly integrating higher-order similar neighbor features into the\nlearning process and modifies the message-passing mechanism between nodes based\non their attribute disparities. Extensive experimental results on three\nreal-world heterogeneous graph benchmarks with target node attributes\ndemonstrate that AGHINT outperforms the state-of-the-art.",
      "tldr_zh": "该研究发现，现有异构图神经网络 (HGNNs) 在处理异构信息网络 (HINs) 时，由于节点属性差异，会导致节点分类性能显著下降。针对这一问题，论文提出了一种新型模型 AGHINT，利用 Transformer 框架，通过属性指导来更有效地聚合邻居信息，包括直接整合更高阶相似邻居特征并根据属性差异修改消息传递机制。实验结果显示，AGHINT 在三个真实世界异构图基准数据集上优于最先进模型，提升了节点表示学习的整体性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.10443v1",
      "published_date": "2024-04-16 10:30:48 UTC",
      "updated_date": "2024-04-16 10:30:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:57:45.629890"
    },
    {
      "arxiv_id": "2404.10433v1",
      "title": "Explainable concept mappings of MRI: Revealing the mechanisms underlying deep learning-based brain disease classification",
      "title_zh": "翻译失败",
      "authors": [
        "Christian Tinauer",
        "Anna Damulina",
        "Maximilian Sackl",
        "Martin Soellradl",
        "Reduan Achtibat",
        "Maximilian Dreyer",
        "Frederik Pahde",
        "Sebastian Lapuschkin",
        "Reinhold Schmidt",
        "Stefan Ropele",
        "Wojciech Samek",
        "Christian Langkammer"
      ],
      "abstract": "Motivation. While recent studies show high accuracy in the classification of\nAlzheimer's disease using deep neural networks, the underlying learned concepts\nhave not been investigated.\n  Goals. To systematically identify changes in brain regions through concepts\nlearned by the deep neural network for model validation.\n  Approach. Using quantitative R2* maps we separated Alzheimer's patients\n(n=117) from normal controls (n=219) by using a convolutional neural network\nand systematically investigated the learned concepts using Concept Relevance\nPropagation and compared these results to a conventional region of\ninterest-based analysis.\n  Results. In line with established histological findings and the region of\ninterest-based analyses, highly relevant concepts were primarily found in and\nadjacent to the basal ganglia.\n  Impact. The identification of concepts learned by deep neural networks for\ndisease classification enables validation of the models and could potentially\nimprove reliability.",
      "tldr_zh": "本研究旨在揭示深度神经网络（deep neural networks）在基于MRI的阿尔茨海默病（Alzheimer's disease）分类中的底层学习概念，以验证模型准确性。研究者使用卷积神经网络（convolutional neural network）和Concept Relevance Propagation方法，分析定量R2*地图数据，将117例阿尔茨海默病患者与219例正常对照组分开，并与传统的region of interest-based分析进行比较。结果显示，高相关概念主要集中在基底神经节及其邻近区域，与既有的组织学发现一致。该方法有助于验证深度学习模型，提高其在脑病分类中的可靠性和解释性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10433v1",
      "published_date": "2024-04-16 09:56:08 UTC",
      "updated_date": "2024-04-16 09:56:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:57:58.272757"
    },
    {
      "arxiv_id": "2404.10429v1",
      "title": "MEEL: Multi-Modal Event Evolution Learning",
      "title_zh": "MEEL: 多模态事件演化学习",
      "authors": [
        "Zhengwei Tao",
        "Zhi Jin",
        "Junqiang Huang",
        "Xiancai Chen",
        "Xiaoying Bai",
        "Haiyan Zhao",
        "Yifan Zhang",
        "Chongyang Tao"
      ],
      "abstract": "Multi-modal Event Reasoning (MMER) endeavors to endow machines with the\nability to comprehend intricate event relations across diverse data modalities.\nMMER is fundamental and underlies a wide broad of applications. Despite\nextensive instruction fine-tuning, current multi-modal large language models\nstill fall short in such ability. The disparity stems from that existing models\nare insufficient to capture underlying principles governing event evolution in\nvarious scenarios. In this paper, we introduce Multi-Modal Event Evolution\nLearning (MEEL) to enable the model to grasp the event evolution mechanism,\nyielding advanced MMER ability. Specifically, we commence with the design of\nevent diversification to gather seed events from a rich spectrum of scenarios.\nSubsequently, we employ ChatGPT to generate evolving graphs for these seed\nevents. We propose an instruction encapsulation process that formulates the\nevolving graphs into instruction-tuning data, aligning the comprehension of\nevent reasoning to humans. Finally, we observe that models trained in this way\nare still struggling to fully comprehend event evolution. In such a case, we\npropose the guiding discrimination strategy, in which models are trained to\ndiscriminate the improper evolution direction. We collect and curate a\nbenchmark M-EV2 for MMER. Extensive experiments on M-EV2 validate the\neffectiveness of our approach, showcasing competitive performance in\nopen-source multi-modal LLMs.",
      "tldr_zh": "这篇论文针对 Multi-Modal Event Reasoning (MMER) 的不足，提出 Multi-Modal Event Evolution Learning (MEEL) 方法，以帮助多模态大语言模型更好地理解和掌握事件演化机制。MEEL 的关键步骤包括事件多样化收集种子事件、使用 ChatGPT 生成演化图、指令封装过程将图转化为训练数据，以及指导性辨别策略训练模型识别不正确的演化方向。实验在构建的 M-EV2 基准上验证了该方法的有效性，显著提升了开源多模态 LLMs 的性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10429v1",
      "published_date": "2024-04-16 09:46:37 UTC",
      "updated_date": "2024-04-16 09:46:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:58:10.998132"
    },
    {
      "arxiv_id": "2404.10425v2",
      "title": "Optimizing BioTac Simulation for Realistic Tactile Perception",
      "title_zh": "优化 BioTac 模拟以实现真实的触觉感知",
      "authors": [
        "Wadhah Zai El Amri",
        "Nicolás Navarro-Guerrero"
      ],
      "abstract": "Tactile sensing presents a promising opportunity for enhancing the\ninteraction capabilities of today's robots. BioTac is a commonly used tactile\nsensor that enables robots to perceive and respond to physical tactile stimuli.\nHowever, the sensor's non-linearity poses challenges in simulating its\nbehavior. In this paper, we first investigate a BioTac simulation that uses\ntemperature, force, and contact point positions to predict the sensor outputs.\nWe show that training with BioTac temperature readings does not yield accurate\nsensor output predictions during deployment. Consequently, we tested three\nalternative models, i.e., an XGBoost regressor, a neural network, and a\ntransformer encoder. We train these models without temperature readings and\nprovide a detailed investigation of the window size of the input vectors. We\ndemonstrate that we achieve statistically significant improvements over the\nbaseline network. Furthermore, our results reveal that the XGBoost regressor\nand transformer outperform traditional feed-forward neural networks in this\ntask. We make all our code and results available online on\nhttps://github.com/wzaielamri/Optimizing_BioTac_Simulation.",
      "tldr_zh": "本研究针对BioTac传感器的非线性挑战，优化其模拟以实现更真实的触觉感知。首先，调查了使用温度、力和接触点位置预测传感器输出的初始模拟，但发现纳入温度读数会导致部署时预测不准确。随后，测试了三种替代模型，包括XGBoost回归器、神经网络和Transformer编码器，这些模型排除温度读数并优化输入向量的窗口大小。结果显示，新模型比基线网络实现了统计显著的改进，其中XGBoost和Transformer在预测性能上优于传统前馈神经网络，并公开了所有代码和结果以供进一步研究。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "12 pages (including appendix), Accepted at the International Joint\n  Conference on Neural Network (IJCNN) 2024, Yokohama, Japan. \\c{opyright} 2024\n  IEEE. Personal use of this material is permitted. Permission from IEEE must\n  be obtained for all other uses, in any current or future media... (We refer\n  to IEEE Copyrights)",
      "pdf_url": "http://arxiv.org/pdf/2404.10425v2",
      "published_date": "2024-04-16 09:43:58 UTC",
      "updated_date": "2024-10-21 13:28:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:58:23.686810"
    },
    {
      "arxiv_id": "2404.10416v1",
      "title": "Disentangling Instructive Information from Ranked Multiple Candidates for Multi-Document Scientific Summarization",
      "title_zh": "翻译失败",
      "authors": [
        "Pancheng Wang",
        "Shasha Li",
        "Dong Li",
        "Kehan Long",
        "Jintao Tang",
        "Ting Wang"
      ],
      "abstract": "Automatically condensing multiple topic-related scientific papers into a\nsuccinct and concise summary is referred to as Multi-Document Scientific\nSummarization (MDSS). Currently, while commonly used abstractive MDSS methods\ncan generate flexible and coherent summaries, the difficulty in handling global\ninformation and the lack of guidance during decoding still make it challenging\nto generate better summaries. To alleviate these two shortcomings, this paper\nintroduces summary candidates into MDSS, utilizing the global information of\nthe document set and additional guidance from the summary candidates to guide\nthe decoding process. Our insights are twofold: Firstly, summary candidates can\nprovide instructive information from both positive and negative perspectives,\nand secondly, selecting higher-quality candidates from multiple options\ncontributes to producing better summaries. Drawing on the insights, we propose\na summary candidates fusion framework -- Disentangling Instructive information\nfrom Ranked candidates (DIR) for MDSS. Specifically, DIR first uses a\nspecialized pairwise comparison method towards multiple candidates to pick out\nthose of higher quality. Then DIR disentangles the instructive information of\nsummary candidates into positive and negative latent variables with Conditional\nVariational Autoencoder. These variables are further incorporated into the\ndecoder to guide generation. We evaluate our approach with three different\ntypes of Transformer-based models and three different types of candidates, and\nconsistently observe noticeable performance improvements according to automatic\nand human evaluation. More analyses further demonstrate the effectiveness of\nour model in handling global information and enhancing decoding\ncontrollability.",
      "tldr_zh": "这篇论文针对 Multi-Document Scientific Summarization (MDSS) 的挑战，提出了一种新框架 Disentangling Instructive information from Ranked candidates (DIR)，通过引入摘要候选来利用全局信息并提供正面和负面指导，以改善摘要生成过程。具体而言，DIR 先采用成对比较方法从多个候选中筛选高质量选项，然后使用 Conditional Variational Autoencoder 分离正面和负面潜在变量，并将其整合到解码器中指导生成。实验结果显示，该框架在三种 Transformer-based 模型和三种候选类型上实现了显著性能提升，并在自动和人工评估中证明了其在处理全局信息和提升解码可控性方面的有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by SIGIR 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.10416v1",
      "published_date": "2024-04-16 09:33:07 UTC",
      "updated_date": "2024-04-16 09:33:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:58:37.026975"
    },
    {
      "arxiv_id": "2404.10405v1",
      "title": "Integration of Self-Supervised BYOL in Semi-Supervised Medical Image Recognition",
      "title_zh": "自监督 BYOL 在半监督医学图像识别中的整合",
      "authors": [
        "Hao Feng",
        "Yuanzhe Jia",
        "Ruijia Xu",
        "Mukesh Prasad",
        "Ali Anaissi",
        "Ali Braytee"
      ],
      "abstract": "Image recognition techniques heavily rely on abundant labeled data,\nparticularly in medical contexts. Addressing the challenges associated with\nobtaining labeled data has led to the prominence of self-supervised learning\nand semi-supervised learning, especially in scenarios with limited annotated\ndata. In this paper, we proposed an innovative approach by integrating\nself-supervised learning into semi-supervised models to enhance medical image\nrecognition. Our methodology commences with pre-training on unlabeled data\nutilizing the BYOL method. Subsequently, we merge pseudo-labeled and labeled\ndatasets to construct a neural network classifier, refining it through\niterative fine-tuning. Experimental results on three different datasets\ndemonstrate that our approach optimally leverages unlabeled data, outperforming\nexisting methods in terms of accuracy for medical image recognition.",
      "tldr_zh": "本论文提出了一种创新方法，将自监督学习(Self-Supervised BYOL)整合到半监督模型(Semi-Supervised)中，以提升医疗图像识别的性能，特别是在标注数据有限的情况下。方法首先利用BYOL在无标签数据上进行预训练，然后将伪标签和真实标签数据合并，构建神经网络分类器并通过迭代微调进行优化。实验结果显示，该方法在三个不同数据集上均表现出色，在准确率方面优于现有方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ICCS 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.10405v1",
      "published_date": "2024-04-16 09:12:16 UTC",
      "updated_date": "2024-04-16 09:12:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:58:48.269996"
    },
    {
      "arxiv_id": "2404.10393v1",
      "title": "Offline Trajectory Generalization for Offline Reinforcement Learning",
      "title_zh": "离线轨迹泛化用于离线强化学习",
      "authors": [
        "Ziqi Zhao",
        "Zhaochun Ren",
        "Liu Yang",
        "Fajie Yuan",
        "Pengjie Ren",
        "Zhumin Chen",
        "jun Ma",
        "Xin Xin"
      ],
      "abstract": "Offline reinforcement learning (RL) aims to learn policies from static\ndatasets of previously collected trajectories. Existing methods for offline RL\neither constrain the learned policy to the support of offline data or utilize\nmodel-based virtual environments to generate simulated rollouts. However, these\nmethods suffer from (i) poor generalization to unseen states; and (ii) trivial\nimprovement from low-qualified rollout simulation. In this paper, we propose\noffline trajectory generalization through world transformers for offline\nreinforcement learning (OTTO). Specifically, we use casual Transformers, a.k.a.\nWorld Transformers, to predict state dynamics and the immediate reward. Then we\npropose four strategies to use World Transformers to generate high-rewarded\ntrajectory simulation by perturbing the offline data. Finally, we jointly use\noffline data with simulated data to train an offline RL algorithm. OTTO serves\nas a plug-in module and can be integrated with existing offline RL methods to\nenhance them with better generalization capability of transformers and\nhigh-rewarded data augmentation. Conducting extensive experiments on D4RL\nbenchmark datasets, we verify that OTTO significantly outperforms\nstate-of-the-art offline RL methods.",
      "tldr_zh": "本文提出OTTO框架，用于提升Offline RL的轨迹泛化能力，通过World Transformers预测状态动态和即时奖励，以解决现有方法对未见状态的泛化不足和模拟数据质量低的问题。具体而言，OTTO采用四个策略扰动离线数据生成高奖励的模拟轨迹，并将这些数据与原始离线数据结合训练RL算法，作为一个插件模块增强现有方法的性能。在D4RL基准数据集上的实验表明，OTTO显著优于最先进的Offline RL方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10393v1",
      "published_date": "2024-04-16 08:48:46 UTC",
      "updated_date": "2024-04-16 08:48:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:59:01.277962"
    },
    {
      "arxiv_id": "2404.10387v1",
      "title": "CNN-based explanation ensembling for dataset, representation and explanations evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Weronika Hryniewska-Guzik",
        "Luca Longo",
        "Przemysław Biecek"
      ],
      "abstract": "Explainable Artificial Intelligence has gained significant attention due to\nthe widespread use of complex deep learning models in high-stake domains such\nas medicine, finance, and autonomous cars. However, different explanations\noften present different aspects of the model's behavior. In this research\nmanuscript, we explore the potential of ensembling explanations generated by\ndeep classification models using convolutional model. Through experimentation\nand analysis, we aim to investigate the implications of combining explanations\nto uncover a more coherent and reliable patterns of the model's behavior,\nleading to the possibility of evaluating the representation learned by the\nmodel. With our method, we can uncover problems of under-representation of\nimages in a certain class. Moreover, we discuss other side benefits like\nfeatures' reduction by replacing the original image with its explanations\nresulting in the removal of some sensitive information. Through the use of\ncarefully selected evaluation metrics from the Quantus library, we demonstrated\nthe method's superior performance in terms of Localisation and Faithfulness,\ncompared to individual explanations.",
      "tldr_zh": "这篇论文提出了一种基于 CNN 的解释集成方法，用于评估数据集、模型表示和解释，以提升 Explainable Artificial Intelligence 在高风险领域的可靠性。方法通过集成深度分类模型生成的解释，揭示模型行为的更连贯模式，并能检测图像在某些类别的欠表示问题，同时通过替换原始图像减少特征并移除敏感信息。实验结果显示，该方法在 Quantus 库的 Localisation 和 Faithfulness 指标上，表现优于单个解释。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "accepted at 2nd World Conference on eXplainable Artificial\n  Intelligence",
      "pdf_url": "http://arxiv.org/pdf/2404.10387v1",
      "published_date": "2024-04-16 08:39:29 UTC",
      "updated_date": "2024-04-16 08:39:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:59:12.725840"
    },
    {
      "arxiv_id": "2404.10386v2",
      "title": "I/O in Machine Learning Applications on HPC Systems: A 360-degree Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Noah Lewis",
        "Jean Luca Bez",
        "Surendra Byna"
      ],
      "abstract": "Growing interest in Artificial Intelligence (AI) has resulted in a surge in\ndemand for faster methods of Machine Learning (ML) model training and\ninference. This demand for speed has prompted the use of high performance\ncomputing (HPC) systems that excel in managing distributed workloads. Because\ndata is the main fuel for AI applications, the performance of the storage and\nI/O subsystem of HPC systems is critical. In the past, HPC applications\naccessed large portions of data written by simulations or experiments or\ningested data for visualizations or analysis tasks. ML workloads perform small\nreads spread across a large number of random files. This shift of I/O access\npatterns poses several challenges to modern parallel storage systems. In this\npaper, we survey I/O in ML applications on HPC systems, and target literature\nwithin a 6-year time window from 2019 to 2024. We define the scope of the\nsurvey, provide an overview of the common phases of ML, review available\nprofilers and benchmarks, examine the I/O patterns encountered during offline\ndata preparation, training, and inference, and explore I/O optimizations\nutilized in modern ML frameworks and proposed in recent literature. Lastly, we\nseek to expose research gaps that could spawn further R&D.",
      "tldr_zh": "这篇论文对机器学习(ML)应用在高性能计算(HPC)系统上的输入/输出(I/O)问题进行了全面调查，聚焦于2019-2024年的相关文献。论文概述了ML的常见阶段，包括离线数据准备、训练和推理，审查了现有的分析器和基准测试，并分析了ML工作负载的I/O模式，如小读操作分布在大量随机文件中，与传统HPC应用形成对比。最终，它探讨了现代ML框架中的I/O优化策略，并暴露了研究空白，以推动未来的研发。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG",
        "H.3.2; H.3.4; I.2.11"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10386v2",
      "published_date": "2024-04-16 08:37:36 UTC",
      "updated_date": "2025-03-07 15:11:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:59:24.739754"
    },
    {
      "arxiv_id": "2404.10384v1",
      "title": "Reasoning on Efficient Knowledge Paths:Knowledge Graph Guides Large Language Model for Domain Question Answering",
      "title_zh": "基于高效知识路径的推理：知识图谱引导大语言模型进行领域问答",
      "authors": [
        "Yuqi Wang",
        "Boran Jiang",
        "Yi Luo",
        "Dawei He",
        "Peng Cheng",
        "Liangcai Gao"
      ],
      "abstract": "Large language models (LLMs), such as GPT3.5, GPT4 and LLAMA2 perform\nsurprisingly well and outperform human experts on many tasks. However, in many\ndomain-specific evaluations, these LLMs often suffer from hallucination\nproblems due to insufficient training of relevant corpus. Furthermore,\nfine-tuning large models may face problems such as the LLMs are not open source\nor the construction of high-quality domain instruction is difficult. Therefore,\nstructured knowledge databases such as knowledge graph can better provide\ndomain background knowledge for LLMs and make full use of the reasoning and\nanalysis capabilities of LLMs. In some previous works, LLM was called multiple\ntimes to determine whether the current triplet was suitable for inclusion in\nthe subgraph when retrieving subgraphs through a question. Especially for the\nquestion that require a multi-hop reasoning path, frequent calls to LLM will\nconsume a lot of computing power. Moreover, when choosing the reasoning path,\nLLM will be called once for each step, and if one of the steps is selected\nincorrectly, it will lead to the accumulation of errors in the following steps.\nIn this paper, we integrated and optimized a pipeline for selecting reasoning\npaths from KG based on LLM, which can reduce the dependency on LLM. In\naddition, we propose a simple and effective subgraph retrieval method based on\nchain of thought (CoT) and page rank which can returns the paths most likely to\ncontain the answer. We conduct experiments on three datasets: GenMedGPT-5k\n[14], WebQuestions [2], and CMCQA [21]. Finally, RoK can demonstrate that using\nfewer LLM calls can achieve the same results as previous SOTAs models.",
      "tldr_zh": "该论文探讨了大型语言模型（LLMs）在领域特定问答中的幻觉问题（hallucination），由于训练数据不足和微调困难而导致效率低下。作者提出一种优化管道，利用知识图谱（Knowledge Graph）引导 LLMs，通过基于 Chain of Thought (CoT) 和 Page Rank 的子图检索方法，减少 LLM 调用次数并避免错误积累。实验在 GenMedGPT-5k、WebQuestions 和 CMCQA 数据集上显示，该方法（RoK）仅需更少的计算资源即可达到与 SOTAs 模型相当的性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10384v1",
      "published_date": "2024-04-16 08:28:16 UTC",
      "updated_date": "2024-04-16 08:28:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:59:36.482560"
    },
    {
      "arxiv_id": "2404.10378v1",
      "title": "Second Edition FRCSyn Challenge at CVPR 2024: Face Recognition Challenge in the Era of Synthetic Data",
      "title_zh": "翻译失败",
      "authors": [
        "Ivan DeAndres-Tame",
        "Ruben Tolosana",
        "Pietro Melzi",
        "Ruben Vera-Rodriguez",
        "Minchul Kim",
        "Christian Rathgeb",
        "Xiaoming Liu",
        "Aythami Morales",
        "Julian Fierrez",
        "Javier Ortega-Garcia",
        "Zhizhou Zhong",
        "Yuge Huang",
        "Yuxi Mi",
        "Shouhong Ding",
        "Shuigeng Zhou",
        "Shuai He",
        "Lingzhi Fu",
        "Heng Cong",
        "Rongyu Zhang",
        "Zhihong Xiao",
        "Evgeny Smirnov",
        "Anton Pimenov",
        "Aleksei Grigorev",
        "Denis Timoshenko",
        "Kaleb Mesfin Asfaw",
        "Cheng Yaw Low",
        "Hao Liu",
        "Chuyi Wang",
        "Qing Zuo",
        "Zhixiang He",
        "Hatef Otroshi Shahreza",
        "Anjith George",
        "Alexander Unnervik",
        "Parsa Rahimi",
        "Sébastien Marcel",
        "Pedro C. Neto",
        "Marco Huber",
        "Jan Niklas Kolf",
        "Naser Damer",
        "Fadi Boutros",
        "Jaime S. Cardoso",
        "Ana F. Sequeira",
        "Andrea Atzori",
        "Gianni Fenu",
        "Mirko Marras",
        "Vitomir Štruc",
        "Jiang Yu",
        "Zhangjie Li",
        "Jichun Li",
        "Weisong Zhao",
        "Zhen Lei",
        "Xiangyu Zhu",
        "Xiao-Yu Zhang",
        "Bernardo Biesseck",
        "Pedro Vidal",
        "Luiz Coelho",
        "Roger Granada",
        "David Menotti"
      ],
      "abstract": "Synthetic data is gaining increasing relevance for training machine learning\nmodels. This is mainly motivated due to several factors such as the lack of\nreal data and intra-class variability, time and errors produced in manual\nlabeling, and in some cases privacy concerns, among others. This paper presents\nan overview of the 2nd edition of the Face Recognition Challenge in the Era of\nSynthetic Data (FRCSyn) organized at CVPR 2024. FRCSyn aims to investigate the\nuse of synthetic data in face recognition to address current technological\nlimitations, including data privacy concerns, demographic biases,\ngeneralization to novel scenarios, and performance constraints in challenging\nsituations such as aging, pose variations, and occlusions. Unlike the 1st\nedition, in which synthetic data from DCFace and GANDiffFace methods was only\nallowed to train face recognition systems, in this 2nd edition we propose new\nsub-tasks that allow participants to explore novel face generative methods. The\noutcomes of the 2nd FRCSyn Challenge, along with the proposed experimental\nprotocol and benchmarking contribute significantly to the application of\nsynthetic data to face recognition.",
      "tldr_zh": "该论文概述了 CVPR 2024 举办的第二届 FRCSyn 挑战赛，旨在探讨合成数据（synthetic data）在人脸识别（face recognition）中的应用，以解决数据隐私担忧、人口统计偏见、泛化能力和挑战场景（如老化、姿态变化和遮挡）等问题。相比第一届，本次挑战赛引入新子任务，允许参与者使用新型人脸生成方法（如 DCFace 和 GANDiffFace），从而扩展合成数据的探索范围。挑战赛的结果、实验协议和基准测试为合成数据在人脸识别领域的实际应用提供了显著贡献。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "arXiv admin note: text overlap with arXiv:2311.10476",
      "pdf_url": "http://arxiv.org/pdf/2404.10378v1",
      "published_date": "2024-04-16 08:15:10 UTC",
      "updated_date": "2024-04-16 08:15:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:59:48.507742"
    },
    {
      "arxiv_id": "2404.10356v2",
      "title": "Generating Counterfactual Trajectories with Latent Diffusion Models for Concept Discovery",
      "title_zh": "利用潜在扩散模型生成反事实轨迹以实现概念发现",
      "authors": [
        "Payal Varshney",
        "Adriano Lucieri",
        "Christoph Balada",
        "Andreas Dengel",
        "Sheraz Ahmed"
      ],
      "abstract": "Trustworthiness is a major prerequisite for the safe application of opaque\ndeep learning models in high-stakes domains like medicine. Understanding the\ndecision-making process not only contributes to fostering trust but might also\nreveal previously unknown decision criteria of complex models that could\nadvance the state of medical research. The discovery of decision-relevant\nconcepts from black box models is a particularly challenging task. This study\nproposes Concept Discovery through Latent Diffusion-based Counterfactual\nTrajectories (CDCT), a novel three-step framework for concept discovery\nleveraging the superior image synthesis capabilities of diffusion models. In\nthe first step, CDCT uses a Latent Diffusion Model (LDM) to generate a\ncounterfactual trajectory dataset. This dataset is used to derive a\ndisentangled representation of classification-relevant concepts using a\nVariational Autoencoder (VAE). Finally, a search algorithm is applied to\nidentify relevant concepts in the disentangled latent space. The application of\nCDCT to a classifier trained on the largest public skin lesion dataset revealed\nnot only the presence of several biases but also meaningful biomarkers.\nMoreover, the counterfactuals generated within CDCT show better FID scores than\nthose produced by a previously established state-of-the-art method, while being\n12 times more resource-efficient. Unsupervised concept discovery holds great\npotential for the application of trustworthy AI and the further development of\nhuman knowledge in various domains. CDCT represents a further step in this\ndirection.",
      "tldr_zh": "该研究提出了一种名为 CDCT 的三步框架，用于从黑盒深度学习模型中发现决策相关概念，从而提升模型在医学等高风险领域的可信度。CDCT 首先利用 Latent Diffusion Model (LDM) 生成反事实轨迹数据集，然后通过 Variational Autoencoder (VAE) 提取分类相关概念的分离表示，最后应用搜索算法在分离的潜在空间中识别关键概念。在应用于最大公共皮肤病变数据集的分类器上，CDCT 揭示了多种偏置和有意义的生物标记物，同时生成的反事实轨迹在 FID scores 上优于现有最先进方法，且资源效率提高了 12 倍。该框架为可信赖 AI 的应用和人类知识发展提供了重要推进。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at International Conference on Pattern Recognition (ICPR)\n  2024",
      "pdf_url": "http://arxiv.org/pdf/2404.10356v2",
      "published_date": "2024-04-16 07:44:08 UTC",
      "updated_date": "2025-01-06 14:47:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:00:00.876801"
    },
    {
      "arxiv_id": "2404.10337v3",
      "title": "Exploring the Role of Token in Transformer-based Time Series Forecasting",
      "title_zh": "探索 Token 在基于 Transformer 的时间序列预测中的作用",
      "authors": [
        "Jianqi Zhang",
        "Jingyao Wang",
        "Chuxiong Sun",
        "Xingchen Shen",
        "Fanjiang Xu",
        "Changwen Zheng",
        "Wenwen Qiang"
      ],
      "abstract": "Transformer-based methods are a mainstream approach for solving time series\nforecasting (TSF). These methods use temporal or variable tokens from\nobservable data to make predictions. However, most focus on optimizing the\nmodel structure, with few studies paying attention to the role of tokens for\npredictions. The role is crucial since a model that distinguishes useful tokens\nfrom useless ones will predict more effectively. In this paper, we explore this\nissue. Through theoretical analyses, we find that the gradients mainly depend\non tokens that contribute to the predicted series, called positive tokens.\nBased on this finding, we explore what helps models select these positive\ntokens. Through a series of experiments, we obtain three observations: i)\npositional encoding (PE) helps the model identify positive tokens; ii) as the\nnetwork depth increases, the PE information gradually weakens, affecting the\nmodel's ability to identify positive tokens in deeper layers; iii) both\nenhancing PE in the deeper layers and using semantic-based PE can improve the\nmodel's ability to identify positive tokens, thus boosting performance.\nInspired by these findings, we design temporal positional encoding (T-PE) for\ntemporal tokens and variable positional encoding (V-PE) for variable tokens. To\nutilize T-PE and V-PE, we propose T2B-PE, a Transformer-based dual-branch\nframework. Extensive experiments demonstrate that T2B-PE has superior\nrobustness and effectiveness.",
      "tldr_zh": "本研究探讨了 token 在基于 Transformer 的时间序列预测（Time Series Forecasting, TSF）中的作用，通过理论分析发现，模型的梯度主要依赖于对预测有贡献的 positive tokens。实验观察表明，positional encoding (PE) 有助于识别这些 positive tokens，但随着网络深度增加，PE 信息会减弱；为此，作者提出 temporal positional encoding (T-PE) 和 variable positional encoding (V-PE)，并开发了 T2B-PE，一个双分支 Transformer 框架，以增强对 positive tokens 的识别能力。大量实验结果显示，T2B-PE 框架具有出色的鲁棒性和有效性，提高了 TSF 模型的性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10337v3",
      "published_date": "2024-04-16 07:21:39 UTC",
      "updated_date": "2024-10-30 01:49:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:00:12.868970"
    },
    {
      "arxiv_id": "2404.10332v1",
      "title": "Prescribing the Right Remedy: Mitigating Hallucinations in Large Vision-Language Models via Targeted Instruction Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Rui Hu",
        "Yahan Tu",
        "Jitao Sang"
      ],
      "abstract": "Despite achieving outstanding performance on various cross-modal tasks,\ncurrent large vision-language models (LVLMs) still suffer from hallucination\nissues, manifesting as inconsistencies between their generated responses and\nthe corresponding images. Prior research has implicated that the low quality of\ninstruction data, particularly the skewed balance between positive and negative\nsamples, is a significant contributor to model hallucinations. Recently,\nresearchers have proposed high-quality instruction datasets, such as\nLRV-Instruction, to mitigate model hallucination. Nonetheless, our\ninvestigation reveals that hallucinatory concepts from different LVLMs exhibit\nspecificity, i.e. the distribution of hallucinatory concepts varies\nsignificantly across models. Existing datasets did not consider the\nhallucination specificity of different models in the design processes, thereby\ndiminishing their efficacy in mitigating model hallucination. In this paper, we\npropose a targeted instruction data generation framework named DFTG that\ntailored to the hallucination specificity of different models. Concretely, DFTG\nconsists of two stages: hallucination diagnosis, which extracts the necessary\ninformation from the model's responses and images for hallucination diagnosis;\nand targeted data generation, which generates targeted instruction data based\non diagnostic results. The experimental results on hallucination benchmarks\ndemonstrate that the targeted instruction data generated by our method are more\neffective in mitigating hallucinations compared to previous datasets.",
      "tldr_zh": "当前的大型视觉语言模型 (LVLMs) 存在幻觉问题，导致生成的响应与对应图像不一致，主要由于指令数据质量低和正负样本不平衡。论文提出DFTG框架，包括幻觉诊断阶段（从模型响应和图像中提取信息进行诊断）和针对性数据生成阶段（基于诊断结果生成定制指令数据），以应对不同模型的幻觉特异性。实验结果显示，DFTG生成的数据在幻觉基准测试中比现有数据集更有效地缓解了模型幻觉。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10332v1",
      "published_date": "2024-04-16 07:14:32 UTC",
      "updated_date": "2024-04-16 07:14:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:00:25.158891"
    },
    {
      "arxiv_id": "2404.10329v2",
      "title": "Towards Complex Ontology Alignment using Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Reihaneh Amini",
        "Sanaz Saki Norouzi",
        "Pascal Hitzler",
        "Reza Amini"
      ],
      "abstract": "Ontology alignment, a critical process in the Semantic Web for detecting\nrelationships between different ontologies, has traditionally focused on\nidentifying so-called \"simple\" 1-to-1 relationships through class labels and\nproperties comparison. The more practically useful exploration of more complex\nalignments remains a hard problem to automate, and as such is largely\nunderexplored, i.e. in application practice it is usually done manually by\nontology and domain experts. Recently, the surge in Natural Language Processing\n(NLP) capabilities, driven by advancements in Large Language Models (LLMs),\npresents new opportunities for enhancing ontology engineering practices,\nincluding ontology alignment tasks. This paper investigates the application of\nLLM technologies to tackle the complex ontology alignment challenge. Leveraging\na prompt-based approach and integrating rich ontology content so-called modules\nour work constitutes a significant advance towards automating the complex\nalignment task.",
      "tldr_zh": "本研究探讨了使用Large Language Models (LLMs)来处理复杂的Ontology Alignment问题，该任务传统上主要关注简单的1-to-1关系，而复杂对齐往往需手动由专家完成。论文采用prompt-based方法，并整合本体内容模块，以提升自动化能力。结果表明，此方法为Semantic Web领域提供了显著进展，推动了复杂本体对齐的自动化进程。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10329v2",
      "published_date": "2024-04-16 07:13:22 UTC",
      "updated_date": "2024-07-22 20:07:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:00:37.632731"
    },
    {
      "arxiv_id": "2404.10320v2",
      "title": "CARE to Compare: A real-world dataset for anomaly detection in wind turbine data",
      "title_zh": "CARE to Compare：用于风力涡轮机数据",
      "authors": [
        "Christian Gück",
        "Cyriana M. A. Roelofs",
        "Stefan Faulstich"
      ],
      "abstract": "Anomaly detection plays a crucial role in the field of predictive maintenance\nfor wind turbines, yet the comparison of different algorithms poses a difficult\ntask because domain specific public datasets are scarce. Many comparisons of\ndifferent approaches either use benchmarks composed of data from many different\ndomains, inaccessible data or one of the few publicly available datasets which\nlack detailed information about the faults. Moreover, many publications\nhighlight a couple of case studies where fault detection was successful. With\nthis paper we publish a high quality dataset that contains data from 36 wind\nturbines across 3 different wind farms as well as the most detailed fault\ninformation of any public wind turbine dataset as far as we know. The new\ndataset contains 89 years worth of real-world operating data of wind turbines,\ndistributed across 44 labeled time frames for anomalies that led up to faults,\nas well as 51 time series representing normal behavior. Additionally, the\nquality of training data is ensured by turbine-status-based labels for each\ndata point. Furthermore, we propose a new scoring method, called CARE\n(Coverage, Accuracy, Reliability and Earliness), which takes advantage of the\ninformation depth that is present in the dataset to identify a good all-around\nanomaly detection model. This score considers the anomaly detection\nperformance, the ability to recognize normal behavior properly and the\ncapability to raise as few false alarms as possible while simultaneously\ndetecting anomalies early.",
      "tldr_zh": "本论文针对风力涡轮机异常检测领域的公共数据集缺失问题，发布了一个真实世界数据集，包含36个风力涡轮机来自3个风场的89年操作数据，以及44个标记的异常时间帧和51个正常行为序列，并通过基于涡轮机状态的标签确保数据质量。数据集提供了迄今为止最详细的故障信息，以支持算法比较和性能评估。该研究还提出了CARE (Coverage, Accuracy, Reliability and Earliness) 评分方法，用于全面评估异常检测模型的表现，包括覆盖率、准确性、可靠性和提前检测能力，从而帮助识别优秀的异常检测算法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2"
      ],
      "primary_category": "cs.LG",
      "comment": "28 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.10320v2",
      "published_date": "2024-04-16 07:02:40 UTC",
      "updated_date": "2024-04-18 05:56:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:00:50.232662"
    },
    {
      "arxiv_id": "2404.10317v2",
      "title": "LLMs4OM: Matching Ontologies with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Hamed Babaei Giglou",
        "Jennifer D'Souza",
        "Felix Engel",
        "Sören Auer"
      ],
      "abstract": "Ontology Matching (OM), is a critical task in knowledge integration, where\naligning heterogeneous ontologies facilitates data interoperability and\nknowledge sharing. Traditional OM systems often rely on expert knowledge or\npredictive models, with limited exploration of the potential of Large Language\nModels (LLMs). We present the LLMs4OM framework, a novel approach to evaluate\nthe effectiveness of LLMs in OM tasks. This framework utilizes two modules for\nretrieval and matching, respectively, enhanced by zero-shot prompting across\nthree ontology representations: concept, concept-parent, and concept-children.\nThrough comprehensive evaluations using 20 OM datasets from various domains, we\ndemonstrate that LLMs, under the LLMs4OM framework, can match and even surpass\nthe performance of traditional OM systems, particularly in complex matching\nscenarios. Our results highlight the potential of LLMs to significantly\ncontribute to the field of OM.",
      "tldr_zh": "本文提出 LLMs4OM 框架，利用 Large Language Models (LLMs) 来处理 Ontology Matching (OM) 任务，以提升知识集成中的数据互操作性和共享。框架包括检索和匹配模块，通过 zero-shot prompting 和三种本体表示（concept, concept-parent, concept-children）进行增强评估。在 20 个不同领域的 OM 数据集上测试，结果显示 LLMs4OM 能与传统系统匹敌甚至超越性能，尤其在复杂匹配场景中，突显了 LLMs 在本体匹配领域的巨大潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 1 figure, accepted to ESWC 2024 Special Track on LLMs for\n  Knowledge Engineering\n  (https://2024.eswc-conferences.org/call-for-papers-llms/)",
      "pdf_url": "http://arxiv.org/pdf/2404.10317v2",
      "published_date": "2024-04-16 06:55:45 UTC",
      "updated_date": "2024-04-23 10:37:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:01:02.011032"
    },
    {
      "arxiv_id": "2404.10311v1",
      "title": "Learning and Optimization for Price-based Demand Response of Electric Vehicle Charging",
      "title_zh": "翻译失败",
      "authors": [
        "Chengyang Gu",
        "Yuxin Pan",
        "Ruohong Liu",
        "Yize Chen"
      ],
      "abstract": "In the context of charging electric vehicles (EVs), the price-based demand\nresponse (PBDR) is becoming increasingly significant for charging load\nmanagement. Such response usually encourages cost-sensitive customers to adjust\ntheir energy demand in response to changes in price for financial incentives.\nThus, to model and optimize EV charging, it is important for charging station\noperator to model the PBDR patterns of EV customers by precisely predicting\ncharging demands given price signals. Then the operator refers to these demands\nto optimize charging station power allocation policy. The standard pipeline\ninvolves offline fitting of a PBDR function based on historical EV charging\nrecords, followed by applying estimated EV demands in downstream charging\nstation operation optimization. In this work, we propose a new decision-focused\nend-to-end framework for PBDR modeling that combines prediction errors and\ndownstream optimization cost errors in the model learning stage. We evaluate\nthe effectiveness of our method on a simulation of charging station operation\nwith synthetic PBDR patterns of EV customers, and experimental results\ndemonstrate that this framework can provide a more reliable prediction model\nfor the ultimate optimization process, leading to more effective optimization\nsolutions in terms of cost savings and charging station operation objectives\nwith only a few training samples.",
      "tldr_zh": "这篇论文针对电动汽车(EV)充电中的基于价格的需求响应(PBDR)，提出了一种新的决策导向的端到端框架，以更精确地建模EV客户的需求并优化充电站操作。该框架在模型学习阶段同时考虑预测错误和下游优化成本错误，从而超越传统离线拟合方法的局限。通过模拟实验，研究结果表明，该方法仅需少量训练样本即可提供更可靠的预测模型，实现更高的成本节省和充电站操作效率。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "Accepted by American Control Conference (ACC) 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.10311v1",
      "published_date": "2024-04-16 06:39:30 UTC",
      "updated_date": "2024-04-16 06:39:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:01:13.117555"
    },
    {
      "arxiv_id": "2404.10308v1",
      "title": "Hierarchical Context Merging: Better Long Context Understanding for Pre-trained LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Woomin Song",
        "Seunghyuk Oh",
        "Sangwoo Mo",
        "Jaehyung Kim",
        "Sukmin Yun",
        "Jung-Woo Ha",
        "Jinwoo Shin"
      ],
      "abstract": "Large language models (LLMs) have shown remarkable performance in various\nnatural language processing tasks. However, a primary constraint they face is\nthe context limit, i.e., the maximum number of tokens they can process.\nPrevious works have explored architectural changes and modifications in\npositional encoding to relax the constraint, but they often require expensive\ntraining or do not address the computational demands of self-attention. In this\npaper, we present Hierarchical cOntext MERging (HOMER), a new training-free\nscheme designed to overcome the limitations. HOMER uses a divide-and-conquer\nalgorithm, dividing long inputs into manageable chunks. Each chunk is then\nprocessed collectively, employing a hierarchical strategy that merges adjacent\nchunks at progressive transformer layers. A token reduction technique precedes\neach merging, ensuring memory usage efficiency. We also propose an optimized\ncomputational order reducing the memory requirement to logarithmically scale\nwith respect to input length, making it especially favorable for environments\nwith tight memory restrictions. Our experiments demonstrate the proposed\nmethod's superior performance and memory efficiency, enabling the broader use\nof LLMs in contexts requiring extended context. Code is available at\nhttps://github.com/alinlab/HOMER.",
      "tldr_zh": "这篇论文提出了 Hierarchical cOntext MERging (HOMER)，一种无需训练的方案，用于提升预训练 LLMs 在长上下文理解方面的性能，以解决传统方法在计算需求和内存限制上的问题。HOMER 采用 divide-and-conquer 算法，将长输入分成可管理块，并在 transformer 层通过层次化策略逐层合并相邻块，同时结合 token reduction 技术确保内存效率，并优化计算顺序使内存需求以对数方式随输入长度增长。实验结果显示，HOMER 在性能和内存效率上显著优于基线模型，支持 LLMs 在需要扩展上下文的任务中更广泛应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to ICLR 2024. The first two authors contributed equally",
      "pdf_url": "http://arxiv.org/pdf/2404.10308v1",
      "published_date": "2024-04-16 06:34:08 UTC",
      "updated_date": "2024-04-16 06:34:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:01:26.298904"
    },
    {
      "arxiv_id": "2404.10307v1",
      "title": "Learnable Prompt for Few-Shot Semantic Segmentation in Remote Sensing Domain",
      "title_zh": "翻译失败",
      "authors": [
        "Steve Andreas Immanuel",
        "Hagai Raja Sinulingga"
      ],
      "abstract": "Few-shot segmentation is a task to segment objects or regions of novel\nclasses within an image given only a few annotated examples. In the generalized\nsetting, the task extends to segment both the base and the novel classes. The\nmain challenge is how to train the model such that the addition of novel\nclasses does not hurt the base classes performance, also known as catastrophic\nforgetting. To mitigate this issue, we use SegGPT as our base model and train\nit on the base classes. Then, we use separate learnable prompts to handle\npredictions for each novel class. To handle various object sizes which\ntypically present in remote sensing domain, we perform patch-based prediction.\nTo address the discontinuities along patch boundaries, we propose a\npatch-and-stitch technique by re-framing the problem as an image inpainting\ntask. During inference, we also utilize image similarity search over image\nembeddings for prompt selection and novel class filtering to reduce false\npositive predictions. Based on our experiments, our proposed method boosts the\nweighted mIoU of a simple fine-tuned SegGPT from 15.96 to 35.08 on the\nvalidation set of few-shot OpenEarthMap dataset given in the challenge.",
      "tldr_zh": "该研究针对遥感领域的Few-shot Semantic Segmentation任务，提出了一种使用learnable prompts的方法，以缓解模型在新类别学习时发生的灾难性遗忘问题。具体而言，该方法以SegGPT为基础模型，在基类上预训练后，为每个新类别使用独立的learnable prompts进行预测，并结合patch-based prediction和patch-and-stitch技术来处理遥感图像中各种物体大小及边界不连续问题。推理阶段还引入图像相似性搜索用于prompt选择和新类别过滤，以减少假阳性预测。在few-shot OpenEarthMap数据集的验证集上，该方法将简单微调SegGPT的weighted mIoU从15.96提升至35.08，显著提高了分割性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to CVPRW 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.10307v1",
      "published_date": "2024-04-16 06:33:08 UTC",
      "updated_date": "2024-04-16 06:33:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:01:37.394644"
    },
    {
      "arxiv_id": "2404.10299v2",
      "title": "Clustering and Data Augmentation to Improve Accuracy of Sleep Assessment and Sleep Individuality Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Shintaro Tamai",
        "Masayuki Numao",
        "Ken-ichi Fukui"
      ],
      "abstract": "Recently, growing health awareness, novel methods allow individuals to\nmonitor sleep at home. Utilizing sleep sounds offers advantages over\nconventional methods like smartwatches, being non-intrusive, and capable of\ndetecting various physiological activities. This study aims to construct a\nmachine learning-based sleep assessment model providing evidence-based\nassessments, such as poor sleep due to frequent movement during sleep onset.\nExtracting sleep sound events, deriving latent representations using VAE,\nclustering with GMM, and training LSTM for subjective sleep assessment achieved\na high accuracy of 94.8% in distinguishing sleep satisfaction. Moreover,\nTimeSHAP revealed differences in impactful sound event types and timings for\ndifferent individuals.",
      "tldr_zh": "本研究利用睡眠声音作为非侵入式监控方法，构建了一个基于机器学习的睡眠评估模型，以提升评估准确性和分析睡眠个体差异。方法包括提取睡眠声音事件、使用 VAE 提取潜在表示、通过 GMM 进行聚类，以及训练 LSTM 模型进行主观睡眠评估。结果显示，该模型在区分睡眠满意度方面达到了94.8%的准确率；此外，利用 TimeSHAP 分析揭示了不同个体在影响声音事件类型和时序上的差异，从而为个性化睡眠健康管理提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10299v2",
      "published_date": "2024-04-16 05:56:41 UTC",
      "updated_date": "2024-10-17 07:02:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:01:49.481773"
    },
    {
      "arxiv_id": "2404.10297v1",
      "title": "Future Language Modeling from Temporal Document History",
      "title_zh": "基于时序文档历史的未来语言建模",
      "authors": [
        "Changmao Li",
        "Jeffrey Flanigan"
      ],
      "abstract": "Predicting the future is of great interest across many aspects of human\nactivity. Businesses are interested in future trends, traders are interested in\nfuture stock prices, and companies are highly interested in future\ntechnological breakthroughs. While there are many automated systems for\npredicting future numerical data, such as weather, stock prices, and demand for\nproducts, there is relatively little work in automatically predicting textual\ndata. Humans are interested in textual data predictions because it is a natural\nformat for our consumption, and experts routinely make predictions in a textual\nformat (Christensen et al., 2004; Tetlock & Gardner, 2015; Frick, 2015).\nHowever, there has been relatively little formalization of this general problem\nin the machine learning or natural language processing communities. To address\nthis gap, we introduce the task of future language modeling: probabilistic\nmodeling of texts in the future based on a temporal history of texts. To our\nknowledge, our work is the first work to formalize the task of predicting the\nfuture in this way. We show that it is indeed possible to build future language\nmodels that improve upon strong non-temporal language model baselines, opening\nthe door to working on this important, and widely applicable problem.",
      "tldr_zh": "这篇论文引入了“future language modeling”任务，即基于时间序列的文本历史（temporal document history）对未来文本进行概率建模，以填补机器学习和自然语言处理领域中文本预测的空白。作者强调，相比于数值数据的预测，文本预测更符合人类消费习惯，但此前缺乏正式化。实验结果显示，该方法能够构建出优于非时间序列语言模型基线的模型，证明了其可行性，并为商业趋势、科技突破等领域的文本预测打开了新大门。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.10297v1",
      "published_date": "2024-04-16 05:45:52 UTC",
      "updated_date": "2024-04-16 05:45:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:02:01.087189"
    },
    {
      "arxiv_id": "2404.10296v5",
      "title": "Interpolating neural network: A novel unification of machine learning and interpolation theory",
      "title_zh": "插值神经网络：机器学习与插值理论的一种新颖统一",
      "authors": [
        "Chanwook Park",
        "Sourav Saha",
        "Jiachen Guo",
        "Hantao Zhang",
        "Xiaoyu Xie",
        "Miguel A. Bessa",
        "Dong Qian",
        "Wei Chen",
        "Gregory J. Wagner",
        "Jian Cao",
        "Wing Kam Liu"
      ],
      "abstract": "Artificial intelligence (AI) has revolutionized software development,\nshifting from task-specific codes (Software 1.0) to neural network-based\napproaches (Software 2.0). However, applying this transition in engineering\nsoftware presents challenges, including low surrogate model accuracy, the curse\nof dimensionality in inverse design, and rising complexity in physical\nsimulations. We introduce an interpolating neural network (INN), grounded in\ninterpolation theory and tensor decomposition, to realize Engineering Software\n2.0 by advancing data training, partial differential equation solving, and\nparameter calibration. INN offers orders of magnitude fewer trainable/solvable\nparameters for comparable model accuracy than traditional multi-layer\nperceptron (MLP) or physics-informed neural networks (PINN). Demonstrated in\nmetal additive manufacturing, INN rapidly constructs an accurate surrogate\nmodel of Laser Powder Bed Fusion (L-PBF) heat transfer simulation, achieving\nsub-10-micrometer resolution for a 10 mm path in under 15 minutes on a single\nGPU. This makes a transformative step forward across all domains essential to\nengineering software.",
      "tldr_zh": "该研究提出 Interpolating Neural Network (INN)，一种将机器学习与 interpolation theory 相结合的新框架，旨在解决工程软件从 Software 1.0 向 Software 2.0 转型中的挑战，如代理模型准确性低和维数灾难（curse of dimensionality）。INN 利用 interpolation theory 和 tensor decomposition，显著减少训练参数数量，并在数据训练、偏微分方程（PDE）求解及参数校准方面表现出色。实验结果显示，在金属增材制造中，INN 快速构建高精度 Laser Powder Bed Fusion (L-PBF) 热传输模拟模型，在单 GPU 上实现 sub-10-micrometer 分辨率并在 15 分钟内完成路径模拟，推动了工程软件领域的变革性进步。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.10296v5",
      "published_date": "2024-04-16 05:40:30 UTC",
      "updated_date": "2024-11-25 15:00:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:02:15.680375"
    },
    {
      "arxiv_id": "2404.10289v1",
      "title": "The Dearth of the Author in AI-Supported Writing",
      "title_zh": "翻译失败",
      "authors": [
        "Max Kreminski"
      ],
      "abstract": "We diagnose and briefly discuss the dearth of the author: a condition that\narises when AI-based creativity support tools for writing allow users to\nproduce large amounts of text without making a commensurate number of creative\ndecisions, resulting in output that is sparse in expressive intent. We argue\nthat the dearth of the author helps to explain a number of recurring\ndifficulties and anxieties around AI-based writing support tools, but that it\nalso suggests an ambitious new goal for AI-based CSTs.",
      "tldr_zh": "该论文诊断了“dearth of the author”现象，即AI-based creativity support tools（AI 辅助写作工具）允许用户快速生成大量文本，却未伴随足够的创意决策，导致输出缺乏expressive intent（表达意图）。作者认为，这一问题解释了AI写作工具的常见困难和焦虑，如用户对产出的控制感缺失。论文进而提出，为AI-based CSTs设定一个雄心勃勃的新目标，以提升工具对用户表达意图的支持。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Published as a workshop paper at the In2Writing workshop at CHI 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.10289v1",
      "published_date": "2024-04-16 05:23:03 UTC",
      "updated_date": "2024-04-16 05:23:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:02:28.267199"
    },
    {
      "arxiv_id": "2404.10281v3",
      "title": "AI-Assisted Writing in Education: Ecosystem Risks and Mitigations",
      "title_zh": "翻译失败",
      "authors": [
        "Antonette Shibani",
        "Simon Buckingham Shum"
      ],
      "abstract": "While the excitement around the capabilities of technological advancements is\ngiving rise to new AI-based writing assistants, the overarching ecosystem plays\na crucial role in how they are adopted in educational practice. In this paper,\nwe point to key ecological aspects for consideration. We draw insights from\nextensive research integrated with practice on a writing feedback tool over 9\nyears at a university, and we highlight potential risks when these are\noverlooked. It informs the design of educational writing support tools to be\nbetter aligned within broader contexts to balance innovation with practical\nimpact.",
      "tldr_zh": "这篇论文探讨了 AI-Assisted Writing 在教育中的生态系统风险与缓解策略，强调技术采用需考虑更广泛的环境因素。作者基于 9 年的大学写作反馈工具研究和实践经验，整合了大量洞见，突出了忽略这些生态方面可能导致的问题，如工具实际应用中的挑战。最终，论文建议在设计教育写作支持工具时，应将其与更广阔的背景对齐，以实现创新与实际影响的平衡。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10281v3",
      "published_date": "2024-04-16 04:49:35 UTC",
      "updated_date": "2024-05-14 10:06:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:02:40.903715"
    },
    {
      "arxiv_id": "2404.10275v1",
      "title": "OptiGrad: A Fair and more Efficient Price Elasticity Optimization via a Gradient Based Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Vincent Grari",
        "Marcin Detyniecki"
      ],
      "abstract": "This paper presents a novel approach to optimizing profit margins in non-life\ninsurance markets through a gradient descent-based method, targeting three key\nobjectives: 1) maximizing profit margins, 2) ensuring conversion rates, and 3)\nenforcing fairness criteria such as demographic parity (DP). Traditional\npricing optimization, which heavily lean on linear and semi definite\nprogramming, encounter challenges in balancing profitability and fairness.\nThese challenges become especially pronounced in situations that necessitate\ncontinuous rate adjustments and the incorporation of fairness criteria.\nSpecifically, indirect Ratebook optimization, a widely-used method for new\nbusiness price setting, relies on predictor models such as XGBoost or GLMs/GAMs\nto estimate on downstream individually optimized prices. However, this strategy\nis prone to sequential errors and struggles to effectively manage optimizations\nfor continuous rate scenarios. In practice, to save time actuaries frequently\nopt for optimization within discrete intervals (e.g., range of [-20\\%, +20\\%]\nwith fix increments) leading to approximate estimations. Moreover, to\ncircumvent infeasible solutions they often use relaxed constraints leading to\nsuboptimal pricing strategies. The reverse-engineered nature of traditional\nmodels complicates the enforcement of fairness and can lead to biased outcomes.\nOur method addresses these challenges by employing a direct optimization\nstrategy in the continuous space of rates and by embedding fairness through an\nadversarial predictor model. This innovation not only reduces sequential errors\nand simplifies the complexities found in traditional models but also directly\nintegrates fairness measures into the commercial premium calculation. We\ndemonstrate improved margin performance and stronger enforcement of fairness\nhighlighting the critical need to evolve existing pricing strategies.",
      "tldr_zh": "本研究提出OptiGrad，一种基于梯度下降(Gradient Descent)的学习方法，用于优化非寿险市场的价格弹性，目标包括最大化利润率、确保转换率以及强制执行公平标准如Demographic Parity (DP)。传统定价优化依赖线性规划和半定规划，往往在平衡盈利性和公平性时面临挑战，例如间接Ratebook优化易产生顺序错误且在连续率调整中效率低下，导致次优策略。OptiGrad通过直接在连续率空间进行优化，并整合对抗性预测模型来嵌入公平性，减少错误并简化复杂性。实验结果显示，该方法显著提升了利润表现和公平性执行，强调了现有定价策略的演进必要性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY",
        "stat.AP"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.10275v1",
      "published_date": "2024-04-16 04:21:59 UTC",
      "updated_date": "2024-04-16 04:21:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:02:53.700030"
    },
    {
      "arxiv_id": "2404.10274v2",
      "title": "Sparse Attention Regression Network Based Soil Fertility Prediction With Ummaso",
      "title_zh": "翻译失败",
      "authors": [
        "R V Raghavendra Rao",
        "U Srinivasulu Reddy"
      ],
      "abstract": "The challenge of imbalanced soil nutrient datasets significantly hampers\naccurate predictions of soil fertility. To tackle this, a new method is\nsuggested in this research, combining Uniform Manifold Approximation and\nProjection (UMAP) with Least Absolute Shrinkage and Selection Operator (LASSO).\nThe main aim is to counter the impact of uneven data distribution and improve\nsoil fertility models' predictive precision. The model introduced uses Sparse\nAttention Regression, effectively incorporating pertinent features from the\nimbalanced dataset. UMAP is utilized initially to reduce data complexity,\nunveiling hidden structures and important patterns. Following this, LASSO is\napplied to refine features and enhance the model's interpretability. The\nexperimental outcomes highlight the effectiveness of the UMAP and LASSO hybrid\napproach. The proposed model achieves outstanding performance metrics, reaching\na predictive accuracy of 98%, demonstrating its capability in accurate soil\nfertility predictions. Additionally, it showcases a Precision of 91.25%,\nindicating its adeptness in identifying fertile soil instances accurately. The\nRecall metric stands at 90.90%, emphasizing the model's ability to capture true\npositive cases effectively.",
      "tldr_zh": "该研究针对土壤养分数据集不平衡导致的预测准确性问题，提出了一种结合 Uniform Manifold Approximation and Projection (UMAP) 和 Least Absolute Shrinkage and Selection Operator (LASSO) 的新方法，以提升土壤肥力预测模型的精度。方法首先利用 UMAP 减少数据复杂性，揭示隐藏结构和重要模式；随后应用 LASSO 精炼特征，提高模型的可解释性，并整合 Sparse Attention Regression 来提取相关特征。实验结果显示，该模型在土壤肥力预测中达到98%的准确率，Precision 为91.25%，Recall 为90.90%，证明其在处理不平衡数据集方面的显著有效性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "There is an error in the result section",
      "pdf_url": "http://arxiv.org/pdf/2404.10274v2",
      "published_date": "2024-04-16 04:17:17 UTC",
      "updated_date": "2024-09-10 07:21:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:03:05.574194"
    },
    {
      "arxiv_id": "2404.10271v2",
      "title": "Social Choice Should Guide AI Alignment in Dealing with Diverse Human Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Vincent Conitzer",
        "Rachel Freedman",
        "Jobst Heitzig",
        "Wesley H. Holliday",
        "Bob M. Jacobs",
        "Nathan Lambert",
        "Milan Mossé",
        "Eric Pacuit",
        "Stuart Russell",
        "Hailey Schoelkopf",
        "Emanuel Tewolde",
        "William S. Zwicker"
      ],
      "abstract": "Foundation models such as GPT-4 are fine-tuned to avoid unsafe or otherwise\nproblematic behavior, such as helping to commit crimes or producing racist\ntext. One approach to fine-tuning, called reinforcement learning from human\nfeedback, learns from humans' expressed preferences over multiple outputs.\nAnother approach is constitutional AI, in which the input from humans is a list\nof high-level principles. But how do we deal with potentially diverging input\nfrom humans? How can we aggregate the input into consistent data about\n\"collective\" preferences or otherwise use it to make collective choices about\nmodel behavior? In this paper, we argue that the field of social choice is well\npositioned to address these questions, and we discuss ways forward for this\nagenda, drawing on discussions in a recent workshop on Social Choice for AI\nEthics and Safety held in Berkeley, CA, USA in December 2023.",
      "tldr_zh": "该论文主张，在处理多样化人类反馈时，社会选择（social choice）理论应指导 AI 对齐（AI alignment），以确保模型行为更一致和安全。作者讨论了两种现有方法：基于人类反馈的强化学习（reinforcement learning from human feedback）和宪法 AI（constitutional AI），并指出这些方法在面对分歧反馈时存在挑战。论文建议通过社会选择理论聚合集体偏好，形成统一的模型决策策略，并基于 2023 年伯克利研讨会的讨论，提出了未来的研究方向。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.GT",
        "68T01, 68T50, 91B14, 91B12",
        "I.2.0; I.2.7; K.4.2; I.2.m; J.4"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.10271v2",
      "published_date": "2024-04-16 03:59:33 UTC",
      "updated_date": "2024-06-04 14:34:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:03:16.350888"
    },
    {
      "arxiv_id": "2404.10267v4",
      "title": "OneActor: Consistent Character Generation via Cluster-Conditioned Guidance",
      "title_zh": "OneActor：通过聚类条件指导的一致角色生成",
      "authors": [
        "Jiahao Wang",
        "Caixia Yan",
        "Haonan Lin",
        "Weizhan Zhang",
        "Mengmeng Wang",
        "Tieliang Gong",
        "Guang Dai",
        "Hao Sun"
      ],
      "abstract": "Text-to-image diffusion models benefit artists with high-quality image\ngeneration. Yet their stochastic nature hinders artists from creating\nconsistent images of the same subject. Existing methods try to tackle this\nchallenge and generate consistent content in various ways. However, they either\ndepend on external restricted data or require expensive tuning of the diffusion\nmodel. For this issue, we propose a novel one-shot tuning paradigm, termed\nOneActor. It efficiently performs consistent subject generation solely driven\nby prompts via a learned semantic guidance to bypass the laborious backbone\ntuning. We lead the way to formalize the objective of consistent subject\ngeneration from a clustering perspective, and thus design a cluster-conditioned\nmodel. To mitigate the overfitting challenge shared by one-shot tuning\npipelines, we augment the tuning with auxiliary samples and devise two\ninference strategies: semantic interpolation and cluster guidance. These\ntechniques are later verified to significantly improve the generation quality.\nComprehensive experiments show that our method outperforms a variety of\nbaselines with satisfactory subject consistency, superior prompt conformity as\nwell as high image quality. Our method is capable of multi-subject generation\nand compatible with popular diffusion extensions. Besides, we achieve a 4 times\nfaster tuning speed than tuning-based baselines and, if desired, avoid\nincreasing the inference time. Furthermore, our method can be naturally\nutilized to pre-train a consistent subject generation network from scratch,\nwhich will implement this research task into more practical applications.\n(Project page: https://johnneywang.github.io/OneActor-webpage/)",
      "tldr_zh": "本文提出OneActor，一种基于Cluster-Conditioned Guidance的单次微调范式，用于文本到图像diffusion models中生成一致的主题图像，从而解决现有方法依赖外部数据或昂贵微调的局限性。该方法从聚类视角正式化一致主题生成目标，并通过辅助样本、语义插值和聚类引导策略来缓解过拟合问题，提高生成质量。实验结果显示，OneActor在主题一致性、提示符合性和图像质量上优于多种基线方法，且微调速度比基线快4倍，同时支持多主题生成和与流行diffusion扩展的兼容。此外，它可用于从零训练一致主题生成网络，推动实际应用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10267v4",
      "published_date": "2024-04-16 03:45:45 UTC",
      "updated_date": "2024-10-28 03:05:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:03:29.751815"
    },
    {
      "arxiv_id": "2404.10260v2",
      "title": "HelixFold-Multimer: Elevating Protein Complex Structure Prediction to New Heights",
      "title_zh": "HelixFold-Multimer：将蛋白质复合物结构预测提升到新的高度",
      "authors": [
        "Xiaomin Fang",
        "Jie Gao",
        "Jing Hu",
        "Lihang Liu",
        "Yang Xue",
        "Xiaonan Zhang",
        "Kunrui Zhu"
      ],
      "abstract": "While monomer protein structure prediction tools boast impressive accuracy,\nthe prediction of protein complex structures remains a daunting challenge in\nthe field. This challenge is particularly pronounced in scenarios involving\ncomplexes with protein chains from different species, such as antigen-antibody\ninteractions, where accuracy often falls short. Limited by the accuracy of\ncomplex prediction, tasks based on precise protein-protein interaction analysis\nalso face obstacles. In this report, we highlight the ongoing advancements of\nour protein complex structure prediction model, HelixFold-Multimer,\nunderscoring its enhanced performance. HelixFold-Multimer provides precise\npredictions for diverse protein complex structures, especially in therapeutic\nprotein interactions. Notably, HelixFold-Multimer achieves remarkable success\nin antigen-antibody and peptide-protein structure prediction, greatly\nsurpassing AlphaFold 3. HelixFold-Multimer is now available for public use on\nthe PaddleHelix platform, offering both a general version and an\nantigen-antibody version. Researchers can conveniently access and utilize this\nservice for their development needs.",
      "tldr_zh": "该研究强调了蛋白质复合物结构预测的挑战，尤其是涉及不同物种的蛋白链，如 antigen-antibody 互动，导致预测准确性不足，并影响基于精确 protein-protein interaction 分析的任务。论文介绍了 HelixFold-Multimer 模型的最新进展，该模型显著提升了各种蛋白复合物结构的预测性能，尤其在治疗性蛋白互动、抗原-antibody 和 peptide-protein 结构预测上，超越了 AlphaFold 3。HelixFold-Multimer 已在 PaddleHelix 平台公开提供，包括通用版和 antigen-antibody 版，供研究人员使用。",
      "categories": [
        "q-bio.BM",
        "cs.AI"
      ],
      "primary_category": "q-bio.BM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10260v2",
      "published_date": "2024-04-16 03:29:37 UTC",
      "updated_date": "2024-05-17 11:47:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:03:40.895766"
    },
    {
      "arxiv_id": "2404.10259v4",
      "title": "Uncovering Latent Arguments in Social Media Messaging by Employing LLMs-in-the-Loop Strategy",
      "title_zh": "通过采用 LLMs-in-the-Loop 策略揭示社交媒体信息中的潜在论点",
      "authors": [
        "Tunazzina Islam",
        "Dan Goldwasser"
      ],
      "abstract": "The widespread use of social media has led to a surge in popularity for\nautomated methods of analyzing public opinion. Supervised methods are adept at\ntext categorization, yet the dynamic nature of social media discussions poses a\ncontinual challenge for these techniques due to the constant shifting of the\nfocus. On the other hand, traditional unsupervised methods for extracting\nthemes from public discourse, such as topic modeling, often reveal overarching\npatterns that might not capture specific nuances. Consequently, a significant\nportion of research into social media discourse still depends on\nlabor-intensive manual coding techniques and a human-in-the-loop approach,\nwhich are both time-consuming and costly. In this work, we study the problem of\ndiscovering arguments associated with a specific theme. We propose a generic\nLLMs-in-the-Loop strategy that leverages the advanced capabilities of Large\nLanguage Models (LLMs) to extract latent arguments from social media messaging.\nTo demonstrate our approach, we apply our framework to contentious topics. We\nuse two publicly available datasets: (1) the climate campaigns dataset of 14k\nFacebook ads with 25 themes and (2) the COVID-19 vaccine campaigns dataset of\n9k Facebook ads with 14 themes. Additionally, we design a downstream task as\nstance prediction by leveraging talking points in climate debates. Furthermore,\nwe analyze demographic targeting and the adaptation of messaging based on\nreal-world events.",
      "tldr_zh": "本研究针对社交媒体讨论的动态性和传统方法的局限性（如监督分类难以适应变化，以及无监督主题建模忽略细微差别），提出了一种通用的 LLMs-in-the-Loop 策略，利用 Large Language Models (LLMs) 来提取潜在论点。研究将该框架应用于两个公开数据集：气候活动数据集（14k Facebook 广告，25 个主题）和 COVID-19 疫苗数据集（9k Facebook 广告，14 个主题）。此外，设计了下游任务如 stance prediction，以分析人口统计学针对（demographic targeting）和基于真实事件的消息适应，从而提升社交媒体舆论分析的效率和准确性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG",
        "cs.SI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at the Findings of 2025 Annual Conference of the Nations of\n  the Americas Chapter of the ACL (NAACL 2025)",
      "pdf_url": "http://arxiv.org/pdf/2404.10259v4",
      "published_date": "2024-04-16 03:26:43 UTC",
      "updated_date": "2025-01-27 16:15:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:03:53.538677"
    },
    {
      "arxiv_id": "2404.10242v1",
      "title": "Masked Autoencoders for Microscopy are Scalable Learners of Cellular Biology",
      "title_zh": "翻译失败",
      "authors": [
        "Oren Kraus",
        "Kian Kenyon-Dean",
        "Saber Saberian",
        "Maryam Fallah",
        "Peter McLean",
        "Jess Leung",
        "Vasudev Sharma",
        "Ayla Khan",
        "Jia Balakrishnan",
        "Safiye Celik",
        "Dominique Beaini",
        "Maciej Sypetkowski",
        "Chi Vicky Cheng",
        "Kristen Morse",
        "Maureen Makes",
        "Ben Mabey",
        "Berton Earnshaw"
      ],
      "abstract": "Featurizing microscopy images for use in biological research remains a\nsignificant challenge, especially for large-scale experiments spanning millions\nof images. This work explores the scaling properties of weakly supervised\nclassifiers and self-supervised masked autoencoders (MAEs) when training with\nincreasingly larger model backbones and microscopy datasets. Our results show\nthat ViT-based MAEs outperform weakly supervised classifiers on a variety of\ntasks, achieving as much as a 11.5% relative improvement when recalling known\nbiological relationships curated from public databases. Additionally, we\ndevelop a new channel-agnostic MAE architecture (CA-MAE) that allows for\ninputting images of different numbers and orders of channels at inference time.\nWe demonstrate that CA-MAEs effectively generalize by inferring and evaluating\non a microscopy image dataset (JUMP-CP) generated under different experimental\nconditions with a different channel structure than our pretraining data\n(RPI-93M). Our findings motivate continued research into scaling\nself-supervised learning on microscopy data in order to create powerful\nfoundation models of cellular biology that have the potential to catalyze\nadvancements in drug discovery and beyond.",
      "tldr_zh": "本研究探讨了自监督Masked Autoencoders (MAEs) 在显微镜图像特征化中的缩放特性，特别是在大规模生物数据集上训练时。结果显示，基于ViT的MAEs 优于弱监督分类器，在回忆已知生物关系任务上实现了高达11.5%的相对改进。研究还开发了新的channel-agnostic MAE (CA-MAE) 架构，能处理不同数量和顺序的图像通道，并在不同实验条件（如JUMP-CP数据集）上有效泛化，与预训练数据（RPI-93M）相比表现出色。这些发现鼓励进一步扩展自监督学习，以构建强大的细胞生物学基础模型，促进药物发现等领域的发展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2024 Highlight. arXiv admin note: text overlap with\n  arXiv:2309.16064",
      "pdf_url": "http://arxiv.org/pdf/2404.10242v1",
      "published_date": "2024-04-16 02:42:06 UTC",
      "updated_date": "2024-04-16 02:42:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:04:05.152909"
    },
    {
      "arxiv_id": "2404.10241v1",
      "title": "Vision-and-Language Navigation via Causal Learning",
      "title_zh": "基于因果学习的视觉与语言导航",
      "authors": [
        "Liuyi Wang",
        "Zongtao He",
        "Ronghao Dang",
        "Mengjiao Shen",
        "Chengju Liu",
        "Qijun Chen"
      ],
      "abstract": "In the pursuit of robust and generalizable environment perception and\nlanguage understanding, the ubiquitous challenge of dataset bias continues to\nplague vision-and-language navigation (VLN) agents, hindering their performance\nin unseen environments. This paper introduces the generalized cross-modal\ncausal transformer (GOAT), a pioneering solution rooted in the paradigm of\ncausal inference. By delving into both observable and unobservable confounders\nwithin vision, language, and history, we propose the back-door and front-door\nadjustment causal learning (BACL and FACL) modules to promote unbiased learning\nby comprehensively mitigating potential spurious correlations. Additionally, to\ncapture global confounder features, we propose a cross-modal feature pooling\n(CFP) module supervised by contrastive learning, which is also shown to be\neffective in improving cross-modal representations during pre-training.\nExtensive experiments across multiple VLN datasets (R2R, REVERIE, RxR, and\nSOON) underscore the superiority of our proposed method over previous\nstate-of-the-art approaches. Code is available at\nhttps://github.com/CrystalSixone/VLN-GOAT.",
      "tldr_zh": "这篇论文针对视觉和语言导航(VLN)中的数据集偏差问题，提出了一种基于因果推理的通用跨模态因果变换器(GOAT)，以提升代理在未知环境中的鲁棒性和泛化性。GOAT 通过后门调整因果学习(BACL)和前门调整因果学习(FACL)模块来处理视觉、语言和历史中的可观察和不可观察混杂因素，同时引入跨模态特征池化(CFP)模块，利用对比学习捕捉全局特征并改善跨模态表示。在 R2R、REVERIE、RxR 和 SOON 等数据集上的广泛实验显示，该方法优于现有最先进方法，为更可靠的 VLN 提供了新范式。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10241v1",
      "published_date": "2024-04-16 02:40:35 UTC",
      "updated_date": "2024-04-16 02:40:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:04:18.442944"
    },
    {
      "arxiv_id": "2404.10234v1",
      "title": "Compressible and Searchable: AI-native Multi-Modal Retrieval System with Learned Image Compression",
      "title_zh": "翻译失败",
      "authors": [
        "Jixiang Luo"
      ],
      "abstract": "The burgeoning volume of digital content across diverse modalities\nnecessitates efficient storage and retrieval methods. Conventional approaches\nstruggle to cope with the escalating complexity and scale of multimedia data.\nIn this paper, we proposed framework addresses this challenge by fusing\nAI-native multi-modal search capabilities with neural image compression. First\nwe analyze the intricate relationship between compressibility and\nsearchability, recognizing the pivotal role each plays in the efficiency of\nstorage and retrieval systems. Through the usage of simple adapter is to bridge\nthe feature of Learned Image Compression(LIC) and Contrastive Language-Image\nPretraining(CLIP) while retaining semantic fidelity and retrieval of\nmulti-modal data. Experimental evaluations on Kodak datasets demonstrate the\nefficacy of our approach, showcasing significant enhancements in compression\nefficiency and search accuracy compared to existing methodologies. Our work\nmarks a significant advancement towards scalable and efficient multi-modal\nsearch systems in the era of big data.",
      "tldr_zh": "该论文提出了一种AI-native多模态检索系统框架，将Learned Image Compression (LIC)与多模态搜索相结合，以应对数字内容激增带来的存储和检索挑战。通过一个简单适配器桥接LIC和Contrastive Language-Image Pretraining (CLIP)，框架保持了语义保真性，同时提升了多模态数据的压缩效率和可搜索性。在Kodak数据集上的实验表明，该方法在压缩效率和搜索准确性上比现有方法显著提升，为大数据时代构建可扩展的多模态搜索系统提供了重要进展。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10234v1",
      "published_date": "2024-04-16 02:29:00 UTC",
      "updated_date": "2024-04-16 02:29:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:04:30.923200"
    },
    {
      "arxiv_id": "2404.10226v1",
      "title": "Find The Gap: Knowledge Base Reasoning For Visual Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Elham J. Barezi",
        "Parisa Kordjamshidi"
      ],
      "abstract": "We analyze knowledge-based visual question answering, for which given a\nquestion, the models need to ground it into the visual modality and retrieve\nthe relevant knowledge from a given large knowledge base (KB) to be able to\nanswer. Our analysis has two folds, one based on designing neural architectures\nand training them from scratch, and another based on large pre-trained language\nmodels (LLMs). Our research questions are: 1) Can we effectively augment models\nby explicit supervised retrieval of the relevant KB information to solve the\nKB-VQA problem? 2) How do task-specific and LLM-based models perform in the\nintegration of visual and external knowledge, and multi-hop reasoning over both\nsources of information? 3) Is the implicit knowledge of LLMs sufficient for\nKB-VQA and to what extent it can replace the explicit KB? Our results\ndemonstrate the positive impact of empowering task-specific and LLM models with\nsupervised external and visual knowledge retrieval models. Our findings show\nthat though LLMs are stronger in 1-hop reasoning, they suffer in 2-hop\nreasoning in comparison with our fine-tuned NN model even if the relevant\ninformation from both modalities is available to the model. Moreover, we\nobserved that LLM models outperform the NN model for KB-related questions which\nconfirms the effectiveness of implicit knowledge in LLMs however, they do not\nalleviate the need for external KB.",
      "tldr_zh": "这篇论文分析了基于知识库的视觉问答（KB-VQA），探讨了如何通过显式监督检索从大型知识库（KB）中获取相关信息，以增强模型在视觉模态 grounding 和问题回答方面的性能。研究比较了从零训练的神经架构模型与大型预训练语言模型（LLMs）在整合视觉知识、外部知识以及多跳推理（multi-hop reasoning）上的表现。结果表明，显式知识检索显著提升了模型效果，LLMs 在1-hop 推理中更强，但在2-hop 推理中不如微调的神经网络模型，且尽管LLMs 的隐式知识有效，但仍无法完全取代外部 KB。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10226v1",
      "published_date": "2024-04-16 02:11:46 UTC",
      "updated_date": "2024-04-16 02:11:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:04:44.754751"
    },
    {
      "arxiv_id": "2404.10225v1",
      "title": "Rethinking Software Engineering in the Foundation Model Era: From Task-Driven AI Copilots to Goal-Driven AI Pair Programmers",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmed E. Hassan",
        "Gustavo A. Oliva",
        "Dayi Lin",
        "Boyuan Chen",
        "Zhen Ming",
        "Jiang"
      ],
      "abstract": "The advent of Foundation Models (FMs) and AI-powered copilots has transformed\nthe landscape of software development, offering unprecedented code completion\ncapabilities and enhancing developer productivity. However, the current\ntask-driven nature of these copilots falls short in addressing the broader\ngoals and complexities inherent in software engineering (SE). In this paper, we\npropose a paradigm shift towards goal-driven AI-powered pair programmers that\ncollaborate with human developers in a more holistic and context-aware manner.\nWe envision AI pair programmers that are goal-driven, human partners, SE-aware,\nand self-learning. These AI partners engage in iterative, conversation-driven\ndevelopment processes, aligning closely with human goals and facilitating\ninformed decision-making. We discuss the desired attributes of such AI pair\nprogrammers and outline key challenges that must be addressed to realize this\nvision. Ultimately, our work represents a shift from AI-augmented SE to\nAI-transformed SE by replacing code completion with a collaborative partnership\nbetween humans and AI that enhances both productivity and software quality.",
      "tldr_zh": "Foundation Models (FMs) 和 AI 辅助工具已提升软件开发效率，但当前的任务驱动型 AI Copilots 无法充分应对软件工程的整体目标和复杂性。论文提出一种范式转变，发展目标驱动型 AI Pair Programmers，这些 AI 作为人类伙伴，具备 goal-driven、human partners、SE-aware 和 self-learning 等特性，通过迭代对话驱动开发过程，支持决策并提升软件质量。AI Pair Programmers 旨在与人类开发者进行更全面的协作，最终实现从 AI-augmented SE 到 AI-transformed SE 的转变。关键挑战包括构建上下文感知能力和处理实际部署问题，以进一步提高生产力和可靠性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10225v1",
      "published_date": "2024-04-16 02:10:20 UTC",
      "updated_date": "2024-04-16 02:10:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:04:56.553650"
    },
    {
      "arxiv_id": "2404.10220v2",
      "title": "Closed-Loop Open-Vocabulary Mobile Manipulation with GPT-4V",
      "title_zh": "翻译失败",
      "authors": [
        "Peiyuan Zhi",
        "Zhiyuan Zhang",
        "Yu Zhao",
        "Muzhi Han",
        "Zeyu Zhang",
        "Zhitian Li",
        "Ziyuan Jiao",
        "Baoxiong Jia",
        "Siyuan Huang"
      ],
      "abstract": "Autonomous robot navigation and manipulation in open environments require\nreasoning and replanning with closed-loop feedback. In this work, we present\nCOME-robot, the first closed-loop robotic system utilizing the GPT-4V\nvision-language foundation model for open-ended reasoning and adaptive planning\nin real-world scenarios.COME-robot incorporates two key innovative modules: (i)\na multi-level open-vocabulary perception and situated reasoning module that\nenables effective exploration of the 3D environment and target object\nidentification using commonsense knowledge and situated information, and (ii)\nan iterative closed-loop feedback and restoration mechanism that verifies task\nfeasibility, monitors execution success, and traces failure causes across\ndifferent modules for robust failure recovery. Through comprehensive\nexperiments involving 8 challenging real-world mobile and tabletop manipulation\ntasks, COME-robot demonstrates a significant improvement in task success rate\n(~35%) compared to state-of-the-art methods. We further conduct comprehensive\nanalyses to elucidate how COME-robot's design facilitates failure recovery,\nfree-form instruction following, and long-horizon task planning.",
      "tldr_zh": "该研究提出COME-robot，这是首个利用GPT-4V视觉语言模型的闭环机器人系统，用于开放环境下的自主导航和操作。该系统包括两个关键模块：(i) 多级开放词汇感知和情境推理模块，利用常识知识和情境信息进行3D环境探索及目标对象识别；(ii) 迭代闭环反馈和恢复机制，用于验证任务可行性、监控执行成功并追踪失败原因以实现鲁棒恢复。在8个挑战性真实世界移动和桌面操作任务中，COME-robot的任务成功率比最先进方法提高了约35%，并通过分析展示了其在失败恢复、自由形式指令遵循和长horizon任务规划方面的优势。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "6 pages, Accepted at 2025 IEEE ICRA, website:\n  https://come-robot.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2404.10220v2",
      "published_date": "2024-04-16 02:01:56 UTC",
      "updated_date": "2025-03-07 05:09:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:05:07.001732"
    },
    {
      "arxiv_id": "2404.10218v1",
      "title": "Autonomous Implicit Indoor Scene Reconstruction with Frontier Exploration",
      "title_zh": "自主隐式室内场景重建结合前沿探索",
      "authors": [
        "Jing Zeng",
        "Yanxu Li",
        "Jiahao Sun",
        "Qi Ye",
        "Yunlong Ran",
        "Jiming Chen"
      ],
      "abstract": "Implicit neural representations have demonstrated significant promise for 3D\nscene reconstruction. Recent works have extended their applications to\nautonomous implicit reconstruction through the Next Best View (NBV) based\nmethod. However, the NBV method cannot guarantee complete scene coverage and\noften necessitates extensive viewpoint sampling, particularly in complex\nscenes. In the paper, we propose to 1) incorporate frontier-based exploration\ntasks for global coverage with implicit surface uncertainty-based\nreconstruction tasks to achieve high-quality reconstruction. and 2) introduce a\nmethod to achieve implicit surface uncertainty using color uncertainty, which\nreduces the time needed for view selection. Further with these two tasks, we\npropose an adaptive strategy for switching modes in view path planning, to\nreduce time and maintain superior reconstruction quality. Our method exhibits\nthe highest reconstruction quality among all planning methods and superior\nplanning efficiency in methods involving reconstruction tasks. We deploy our\nmethod on a UAV and the results show that our method can plan multi-task views\nand reconstruct a scene with high quality.",
      "tldr_zh": "该论文提出了一种自主隐式室内场景重建方法，通过结合frontier-based exploration任务（用于全局覆盖）和基于隐式表面不确定性的重建任务，实现高效的高质量3D重建。该方法利用颜色不确定性来快速估计隐式表面不确定性，并引入自适应策略优化视点路径规划，减少采样时间和计算开销。与Next Best View (NBV)方法相比，该方法在重建质量上表现出最高性能，并在涉及重建任务的规划中效率更优。最终，在UAV上部署实验验证了其能有效规划多任务视点并实现高质场景重建。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "7 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.10218v1",
      "published_date": "2024-04-16 01:59:03 UTC",
      "updated_date": "2024-04-16 01:59:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:05:20.527603"
    },
    {
      "arxiv_id": "2404.10211v1",
      "title": "Anomaly Correction of Business Processes Using Transformer Autoencoder",
      "title_zh": "基于 Transformer Autoencoder 的商业流程异常修正",
      "authors": [
        "Ziyou Gong",
        "Xianwen Fang",
        "Ping Wu"
      ],
      "abstract": "Event log records all events that occur during the execution of business\nprocesses, so detecting and correcting anomalies in event log can provide\nreliable guarantee for subsequent process analysis. The previous works mainly\ninclude next event prediction based methods and autoencoder-based methods.\nThese methods cannot accurately and efficiently detect anomalies and correct\nanomalies at the same time, and they all rely on the set threshold to detect\nanomalies. To solve these problems, we propose a business process anomaly\ncorrection method based on Transformer autoencoder. By using self-attention\nmechanism and autoencoder structure, it can efficiently process event sequences\nof arbitrary length, and can directly output corrected business process\ninstances, so that it can adapt to various scenarios. At the same time, the\nanomaly detection is transformed into a classification problem by means of\nselfsupervised learning, so that there is no need to set a specific threshold\nin anomaly detection. The experimental results on several real-life event logs\nshow that the proposed method is superior to the previous methods in terms of\nanomaly detection accuracy and anomaly correction results while ensuring high\nrunning efficiency.",
      "tldr_zh": "本文提出了一种基于 Transformer autoencoder 的业务流程异常纠正方法，以解决现有方法（如基于下一事件预测或 autoencoder 的方法）在检测和纠正异常时存在的准确性不足、效率低下以及对阈值依赖的问题。  \n该方法利用自注意力机制和 autoencoder 结构，能高效处理任意长度的事件序列，并通过自监督学习将异常检测转化为分类问题，从而直接输出纠正后的业务流程实例。  \n实验结果表明，该方法在多个真实事件日志上优于现有方法，在异常检测准确率、纠正效果和运行效率方面均表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10211v1",
      "published_date": "2024-04-16 01:45:18 UTC",
      "updated_date": "2024-04-16 01:45:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:05:31.576863"
    },
    {
      "arxiv_id": "2404.10209v3",
      "title": "Demonstration of DB-GPT: Next Generation Data Interaction System Empowered by Large Language Models",
      "title_zh": "DB-GPT 的演示：由大型语言模型赋能的下一代数据交互系统",
      "authors": [
        "Siqiao Xue",
        "Danrui Qi",
        "Caigao Jiang",
        "Wenhui Shi",
        "Fangyin Cheng",
        "Keting Chen",
        "Hongjun Yang",
        "Zhiping Zhang",
        "Jianshan He",
        "Hongyang Zhang",
        "Ganglin Wei",
        "Wang Zhao",
        "Fan Zhou",
        "Hong Yi",
        "Shaodong Liu",
        "Hongjun Yang",
        "Faqiang Chen"
      ],
      "abstract": "The recent breakthroughs in large language models (LLMs) are positioned to\ntransition many areas of software. The technologies of interacting with data\nparticularly have an important entanglement with LLMs as efficient and\nintuitive data interactions are paramount. In this paper, we present DB-GPT, a\nrevolutionary and product-ready Python library that integrates LLMs into\ntraditional data interaction tasks to enhance user experience and\naccessibility. DB-GPT is designed to understand data interaction tasks\ndescribed by natural language and provide context-aware responses powered by\nLLMs, making it an indispensable tool for users ranging from novice to expert.\nIts system design supports deployment across local, distributed, and cloud\nenvironments. Beyond handling basic data interaction tasks like Text-to-SQL\nwith LLMs, it can handle complex tasks like generative data analysis through a\nMulti-Agents framework and the Agentic Workflow Expression Language (AWEL). The\nService-oriented Multi-model Management Framework (SMMF) ensures data privacy\nand security, enabling users to employ DB-GPT with private LLMs. Additionally,\nDB-GPT offers a series of product-ready features designed to enable users to\nintegrate DB-GPT within their product environments easily. The code of DB-GPT\nis available at Github(https://github.com/eosphoros-ai/DB-GPT) which already\nhas over 10.7k stars. Please install DB-GPT for your own usage with the\ninstructions(https://github.com/eosphoros-ai/DB-GPT#install) and watch a\n5-minute introduction video on Youtube(https://youtu.be/n_8RI1ENyl4) to further\ninvestigate DB-GPT.",
      "tldr_zh": "本论文展示了 DB-GPT，一种由 Large Language Models (LLMs) 赋能的下一代数据交互系统，作为一个产品就绪的 Python 库，提升了从初学者到专家的用户体验。DB-GPT 通过自然语言理解数据任务，提供上下文感知响应，支持基本功能如 Text-to-SQL，以及复杂任务如生成数据分析，利用 Multi-Agents framework 和 Agentic Workflow Expression Language (AWEL)。此外，该系统采用 Service-oriented Multi-model Management Framework (SMMF) 保障数据隐私和安全，支持本地、分布式及云部署，并已在 GitHub 上开源，获得广泛关注。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10209v3",
      "published_date": "2024-04-16 01:38:34 UTC",
      "updated_date": "2024-04-24 23:50:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:05:45.416092"
    },
    {
      "arxiv_id": "2404.10202v1",
      "title": "Towards a Novel Perspective on Adversarial Examples Driven by Frequency",
      "title_zh": "翻译失败",
      "authors": [
        "Zhun Zhang",
        "Yi Zeng",
        "Qihe Liu",
        "Shijie Zhou"
      ],
      "abstract": "Enhancing our understanding of adversarial examples is crucial for the secure\napplication of machine learning models in real-world scenarios. A prevalent\nmethod for analyzing adversarial examples is through a frequency-based\napproach. However, existing research indicates that attacks designed to exploit\nlow-frequency or high-frequency information can enhance attack performance,\nleading to an unclear relationship between adversarial perturbations and\ndifferent frequency components. In this paper, we seek to demystify this\nrelationship by exploring the characteristics of adversarial perturbations\nwithin the frequency domain. We employ wavelet packet decomposition for\ndetailed frequency analysis of adversarial examples and conduct statistical\nexaminations across various frequency bands. Intriguingly, our findings\nindicate that significant adversarial perturbations are present within the\nhigh-frequency components of low-frequency bands. Drawing on this insight, we\npropose a black-box adversarial attack algorithm based on combining different\nfrequency bands. Experiments conducted on multiple datasets and models\ndemonstrate that combining low-frequency bands and high-frequency components of\nlow-frequency bands can significantly enhance attack efficiency. The average\nattack success rate reaches 99\\%, surpassing attacks that utilize a single\nfrequency segment. Additionally, we introduce the normalized disturbance\nvisibility index as a solution to the limitations of $L_2$ norm in assessing\ncontinuous and discrete perturbations.",
      "tldr_zh": "本研究旨在通过频率分析深化对对抗样本(adversarial examples)的理解，解决现有方法在低频和高频信息利用上的模糊关系。研究者采用小波包分解(wavelet packet decomposition)对对抗样本进行详细频率分析，发现显著的对抗扰动主要存在于低频带的高频组成部分。基于这一洞见，他们提出了一种黑盒对抗攻击算法(black-box adversarial attack algorithm)，通过结合不同频带显著提升攻击效率，在多个数据集和模型上实现平均成功率99%，优于单一频段攻击。此外，引入了归一化扰动可见性指数(normalized disturbance visibility index)来克服$L_2$范数在评估连续和离散扰动时的局限性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10202v1",
      "published_date": "2024-04-16 00:58:46 UTC",
      "updated_date": "2024-04-16 00:58:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:05:55.639154"
    },
    {
      "arxiv_id": "2404.10200v1",
      "title": "TEL'M: Test and Evaluation of Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "George Cybenko",
        "Joshua Ackerman",
        "Paul Lintilhac"
      ],
      "abstract": "Language Models have demonstrated remarkable capabilities on some tasks while\nfailing dramatically on others. The situation has generated considerable\ninterest in understanding and comparing the capabilities of various Language\nModels (LMs) but those efforts have been largely ad hoc with results that are\noften little more than anecdotal. This is in stark contrast with testing and\nevaluation processes used in healthcare, radar signal processing, and other\ndefense areas. In this paper, we describe Test and Evaluation of Language\nModels (TEL'M) as a principled approach for assessing the value of current and\nfuture LMs focused on high-value commercial, government and national security\napplications. We believe that this methodology could be applied to other\nArtificial Intelligence (AI) technologies as part of the larger goal of\n\"industrializing\" AI.",
      "tldr_zh": "该论文指出，语言模型（LMs）在某些任务上表现出色，但在其他任务上失败明显，而现有的评估方法往往随意且仅限于轶事性结果，与医疗保健或国防领域的系统化测试形成鲜明对比。作者提出 TEL'M，这是一种原则性的测试和评估框架，旨在评估当前和未来 LMs 在高价值应用（如商业、政府和国家安全领域）中的价值。该方法可扩展到其他 Artificial Intelligence (AI) 技术，推动 AI 的“工业化”。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10200v1",
      "published_date": "2024-04-16 00:54:17 UTC",
      "updated_date": "2024-04-16 00:54:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:06:07.351857"
    },
    {
      "arxiv_id": "2404.10199v5",
      "title": "CULTURE-GEN: Revealing Global Cultural Perception in Language Models through Natural Language Prompting",
      "title_zh": "CULTURE-GEN: 通过自然语言提示揭示语言模型中的全球文化感知",
      "authors": [
        "Huihan Li",
        "Liwei Jiang",
        "Jena D. Hwang",
        "Hyunwoo Kim",
        "Sebastin Santy",
        "Taylor Sorensen",
        "Bill Yuchen Lin",
        "Nouha Dziri",
        "Xiang Ren",
        "Yejin Choi"
      ],
      "abstract": "As the utilization of large language models (LLMs) has proliferated\nworld-wide, it is crucial for them to have adequate knowledge and fair\nrepresentation for diverse global cultures. In this work, we uncover culture\nperceptions of three SOTA models on 110 countries and regions on 8\nculture-related topics through culture-conditioned generations, and extract\nsymbols from these generations that are associated to each culture by the LLM.\nWe discover that culture-conditioned generation consist of linguistic \"markers\"\nthat distinguish marginalized cultures apart from default cultures. We also\ndiscover that LLMs have an uneven degree of diversity in the culture symbols,\nand that cultures from different geographic regions have different presence in\nLLMs' culture-agnostic generation. Our findings promote further research in\nstudying the knowledge and fairness of global culture perception in LLMs. Code\nand Data can be found here: https://github.com/huihanlhh/Culture-Gen/",
      "tldr_zh": "本文提出CULTURE-GEN框架，通过自然语言提示，揭示大型语言模型（LLMs）对110个国家和地区的文化感知，并从模型生成的文本中提取与各文化相关的符号。研究发现，文化条件生成中存在语言“markers”来区分边缘化文化，但LLMs在文化符号的多样性上不均匀，且不同地理区域的文化在模型中存在表现差异。总体而言，该工作促进了对LLMs全球文化知识和公平性的深入研究，并提供了开源代码和数据。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10199v5",
      "published_date": "2024-04-16 00:50:43 UTC",
      "updated_date": "2024-08-20 06:53:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:06:19.444027"
    },
    {
      "arxiv_id": "2404.10198v3",
      "title": "ClashEval: Quantifying the tug-of-war between an LLM's internal prior and external evidence",
      "title_zh": "翻译失败",
      "authors": [
        "Kevin Wu",
        "Eric Wu",
        "James Zou"
      ],
      "abstract": "Retrieval augmented generation (RAG) is frequently used to mitigate\nhallucinations and provide up-to-date knowledge for large language models\n(LLMs). However, given that document retrieval is an imprecise task and\nsometimes results in erroneous or even harmful content being presented in\ncontext, this raises the question of how LLMs handle retrieved information: If\nthe provided content is incorrect, does the model know to ignore it, or does it\nrecapitulate the error? Conversely, when the model's initial response is\nincorrect, does it always know to use the retrieved information to correct\nitself, or does it insist on its wrong prior response? To answer this, we\ncurate a dataset of over 1200 questions across six domains (e.g., drug dosages,\nOlympic records, locations) along with content relevant to answering each\nquestion. We further apply precise perturbations to the answers in the content\nthat range from subtle to blatant errors. We benchmark six top-performing LLMs,\nincluding GPT-4o, on this dataset and find that LLMs are susceptible to\nadopting incorrect retrieved content, overriding their own correct prior\nknowledge over 60% of the time. However, the more unrealistic the retrieved\ncontent is (i.e. more deviated from truth), the less likely the model is to\nadopt it. Also, the less confident a model is in its initial response (via\nmeasuring token probabilities), the more likely it is to adopt the information\nin the retrieved content. We exploit this finding and demonstrate simple\nmethods for improving model accuracy where there is conflicting retrieved\ncontent. Our results highlight a difficult task and benchmark for LLMs --\nnamely, their ability to correctly discern when it is wrong in light of correct\nretrieved content and to reject cases when the provided content is incorrect.",
      "tldr_zh": "这篇论文引入了ClashEval框架，用于量化大型语言模型(LLMs)内部先验知识与外部检索证据之间的冲突，特别是在Retrieval Augmented Generation (RAG)应用中。研究者构建了一个包含超过1200个问题的数据集，涵盖六个领域（如药物剂量和奥运记录），并对检索内容施加从微妙到明显的错误扰动，以评估LLMs处理不正确信息的表现。实验结果显示，六种顶级LLMs（包括GPT-4o）在60%以上情况下会采纳错误的检索内容，覆盖自身正确知识；然而，如果内容更不现实或模型对初始响应的token probabilities自信度低，则更可能忽略或修正它。该研究还提出了简单方法来改善模型准确性，并为LLMs正确辨别和处理冲突信息提供了重要基准。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Revised June 9 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.10198v3",
      "published_date": "2024-04-16 00:43:03 UTC",
      "updated_date": "2025-02-07 05:11:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:06:33.479962"
    },
    {
      "arxiv_id": "2404.10800v3",
      "title": "Integrating Graph Neural Networks with Scattering Transform for Anomaly Detection",
      "title_zh": "整合图神经网络与",
      "authors": [
        "Abdeljalil Zoubir",
        "Badr Missaoui"
      ],
      "abstract": "In this paper, we present two novel methods in Network Intrusion Detection\nSystems (NIDS) using Graph Neural Networks (GNNs). The first approach,\nScattering Transform with E-GraphSAGE (STEG), utilizes the scattering transform\nto conduct multi-resolution analysis of edge feature vectors. This provides a\ndetailed representation that is essential for identifying subtle anomalies in\nnetwork traffic. The second approach improves node representation by initiating\nwith Node2Vec, diverging from standard methods of using uniform values, thereby\ncapturing a more accurate and holistic network picture. Our methods have shown\nsignificant improvements in performance compared to existing state-of-the-art\nmethods in benchmark NIDS datasets.",
      "tldr_zh": "本文提出两种新方法，将 Graph Neural Networks (GNNs) 与 Scattering Transform 整合，用于 Network Intrusion Detection Systems (NIDS) 中的异常检测。第一种方法，Scattering Transform with E-GraphSAGE (STEG)，通过对边特征向量的多分辨率分析，提供详细表示以识别网络流量中的细微异常。第二种方法则使用 Node2Vec 初始化节点表示，取代统一值的方法，从而捕获更准确的网络整体图景。实验结果显示，这些方法在基准 NIDS 数据集上比现有最先进方法有显著性能提升。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10800v3",
      "published_date": "2024-04-16 00:02:12 UTC",
      "updated_date": "2024-04-24 12:43:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:06:45.409955"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 102,
  "processed_papers_count": 102,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-18T01:07:06.188723"
}