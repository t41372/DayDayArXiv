{
  "date": "2025-05-09",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-05-09 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 80 篇论文，主要聚焦 AI 和机器学习领域，包括 LLM 的优化、AI 安全、机器人自主性以及量子计算应用，其中 UniVLA 在机器人跨体策略上的创新和 LLMs 在生物学基准的超预期表现令人印象深刻，同时著名学者如 Joshua B. Tenenbaum 的 Neuro-Symbolic Concepts 论文值得关注。\n\n今天论文覆盖 AI、机器人、量子计算和生物信息学等主题，我将优先讨论重要、创新性和话题度高的文章（如涉及 LLM 和机器人领域的），并将相关论文归类快速概述。以下按主题分组，突出核心贡献。\n\n### AI 和 LLM 相关\n- **KCluster: An LLM-based Clustering Approach to Knowledge Component Discovery（KCluster: 基于 LLM 的知识组件发现聚类方法）**  \n  这篇论文提出 KCluster 算法，使用 LLM 诱导的相似度指标对教育评估问题进行聚类，发现更有效的知识组件模型。贡献在于减少人工干预，并提升学生表现预测准确性，适用于大规模问题库的教育 AI。\n\n- **Opening the Scope of Openness in AI（扩展 AI 中的开放性）**  \n  作者 Tamara Paris 等讨论 AI 开放性的新框架，超越开源软件的定义，构建一个跨学科分类法。发现 AI 开放应包括行动、系统属性和伦理目标，这对 AI 治理和公平性有重要启发，尤其在 ACM FAccT 会议接受的背景下。\n\n- **Remote Rowhammer Attack using Adversarial Observations on Federated Learning Clients（使用联邦学习客户端的对抗观察进行远程 Rowhammer 攻击）**  \n  这篇探讨 AI 安全的论文揭示了联邦学习中的新攻击方式，通过强化学习操纵传感器数据诱发服务器内存位翻转。贡献在于首次展示无需后门访问即可远程攻击，强调了 FL 系统安全性的紧迫性。\n\n- **Neuro-Symbolic Concepts（神经符号概念）**  \n  作者包括著名学者 Joshua B. Tenenbaum，他们提出基于神经符号概念的代理框架，支持持续学习和灵活推理。发现这种方法在图像、视频和机器人任务中实现高效组合泛化，强化了 AI 在多领域应用的潜力。\n\n其他 LLM 相关论文如 Reliable Collaborative Conversational Agent System（使用 LLM 和 ASP 的可靠对话代理系统）快速提到：它结合逻辑编程提升代理协作安全，应用于任务导向对话。\n\n### 机器人和自主系统\n- **UniVLA: Learning to Act Anywhere with Task-centric Latent Actions（UniVLA: 使用任务导向潜在动作的通用机器人学习）**  \n  这篇印象深刻的论文提出 UniVLA 框架，通过从视频中学习任务导向动作表示，实现机器人跨体策略转移。贡献在于高效适应不同环境，仅需少量数据即可在模拟和真实机器人上表现优异，推动了机器人泛化能力的边界。\n\n- **Let Humanoids Hike! Integrative Skill Development on Complex Trails（让人形机器人远足！复杂路径的综合技能开发）**  \n  作者开发 LEGO-H 框架，使用分层强化学习和视觉 Transformer 让机器人自主远足。发现它能处理多样地形，提升感知-决策-执行一体化，实验在模拟环境中验证了鲁棒性。\n\n- **MAGE: A Multi-stage Avatar Generator with Sparse Observations（MAGE: 使用稀疏观察的多阶段虚拟体生成器）**  \n  论文引入多阶段预测策略，从头-手观察逐步推断全身体势。贡献在于减少歧义，提高运动连续性和准确性，适用于 AR/VR 场景。\n\n其他机器人论文如 FlowHFT（高频交易的模仿学习）和 APOLLO（量子证明的 LLM 协作）快速掠过：前者优化交易策略，后者提升定理证明效率，但影响力较小。\n\n### 量子计算和科学应用\n- **Quantum State Preparation via Large-Language-Model-Driven Evolution（通过 LLM 驱动演化的量子态准备）**  \n  这篇论文创新地将 LLM 与进化优化结合，自动设计量子电路。发现它能生成高效量子模拟器，并在实验中验证了噪声缓解效果，对可扩展量子计算有重要启发。\n\n- **ML.ENERGY Benchmark: Toward Automated Inference Energy Measurement and Optimization（ML.ENERGY 基准: 自动化推理能效测量与优化）**  \n  论文提出 ML.ENERGY 基准，评估 AI 模型的能效。贡献在于通过案例研究展示设计选择如何节省能耗（最高 40%），并提供开源工具，促进绿色 AI 发展。\n\n其他科学论文如 Improved Uncertainty Quantification in Physics-Informed Neural Networks（PINNs 的不确定性量化改进）和 Towards AI-Driven Human-Machine Co-Teaming（AI 驱动的人机协作）快速提到：前者提升 PINNs 鲁棒性，后者优化网络安全，但主题较 niche。\n\n### 其他领域快速概述\n今天还有生物、医学和计算机视觉论文，如：\n- **LLMs Outperform Experts on Challenging Biology Benchmarks（LLMs 在生物学基准上超越专家）**  \n  评估 27 个 LLM 在生物任务上的表现，发现顶级模型如 o3 超过专家水平。\n- **HyperspectralMAE: The Hyperspectral Imagery Classification Model（HyperspectralMAE: 超光谱图像分类模型）**  \n  使用双分支掩码自编码器提升图像分类准确性。\n- **PyResBugs: A Dataset of Residual Python Bugs（PyResBugs: Python 残留缺陷数据集）**  \n  提供缺陷数据集，支持 NL 驱动的错误注入。\n\n这些论文虽有价值，但相对常规，我仅简要列出以控制篇幅。总体而言，今天 arXiv 强调 AI 的实用性和安全，LLM 在教育、机器人和量子领域的应用潜力巨大，读者可关注 UniVLA 和 Neuro-Symbolic Concepts 等创新工作。明天的更新拭目以待！",
  "papers": [
    {
      "arxiv_id": "2505.06469v1",
      "title": "KCluster: An LLM-based Clustering Approach to Knowledge Component Discovery",
      "title_zh": "KCluster：基于LLM的知识组件发现聚类方法",
      "authors": [
        "Yumou Wei",
        "Paulo Carvalho",
        "John Stamper"
      ],
      "abstract": "Educators evaluate student knowledge using knowledge component (KC) models\nthat map assessment questions to KCs. Still, designing KC models for large\nquestion banks remains an insurmountable challenge for instructors who need to\nanalyze each question by hand. The growing use of Generative AI in education is\nexpected only to aggravate this chronic deficiency of expert-designed KC\nmodels, as course engineers designing KCs struggle to keep up with the pace at\nwhich questions are generated. In this work, we propose KCluster, a novel KC\ndiscovery algorithm based on identifying clusters of congruent questions\naccording to a new similarity metric induced by a large language model (LLM).\nWe demonstrate in three datasets that an LLM can create an effective metric of\nquestion similarity, which a clustering algorithm can use to create KC models\nfrom questions with minimal human effort. Combining the strengths of LLM and\nclustering, KCluster generates descriptive KC labels and discovers KC models\nthat predict student performance better than the best expert-designed models\navailable. In anticipation of future work, we illustrate how KCluster can\nreveal insights into difficult KCs and suggest improvements to instruction.",
      "tldr_zh": "本研究提出 KCluster，一种基于 Large Language Model (LLM) 的聚类方法，用于自动发现知识组件 (KC) 模型，以解决教育者手动分析大型问题库的难题。该方法通过 LLM 诱导的相似性指标识别相似的评估问题，并应用聚类算法生成描述性的 KC 标签，从而减少人为干预。在三个数据集上实验证明，KCluster 产生的 KC 模型比专家设计的模型更准确，能更好地预测学生表现，并提供对困难 KC 的洞见以改进教学。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to the Educational Data Mining (EDM) 2025 conference",
      "pdf_url": "http://arxiv.org/pdf/2505.06469v1",
      "published_date": "2025-05-09 23:47:58 UTC",
      "updated_date": "2025-05-09 23:47:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:14:07.242303"
    },
    {
      "arxiv_id": "2505.15825v1",
      "title": "Multilinear subspace learning for person re-identification based fusion of high order tensor features",
      "title_zh": "翻译失败",
      "authors": [
        "Ammar Chouchane",
        "Mohcene Bessaoudi",
        "Hamza Kheddar",
        "Abdelmalik Ouamane",
        "Tiago Vieira",
        "Mahmoud Hassaballah"
      ],
      "abstract": "Video surveillance image analysis and processing is a challenging field in\ncomputer vision, with one of its most difficult tasks being Person\nRe-Identification (PRe-ID). PRe-ID aims to identify and track target\nindividuals who have already been detected in a network of cameras, using a\nrobust description of their pedestrian images. The success of recent research\nin person PRe-ID is largely due to effective feature extraction and\nrepresentation, as well as the powerful learning of these features to reliably\ndiscriminate between pedestrian images. To this end, two powerful features,\nConvolutional Neural Networks (CNN) and Local Maximal Occurrence (LOMO), are\nmodeled on multidimensional data using the proposed method, High-Dimensional\nFeature Fusion (HDFF). Specifically, a new tensor fusion scheme is introduced\nto leverage and combine these two types of features in a single tensor, even\nthough their dimensions are not identical. To enhance the system's accuracy, we\nemploy Tensor Cross-View Quadratic Analysis (TXQDA) for multilinear subspace\nlearning, followed by cosine similarity for matching. TXQDA efficiently\nfacilitates learning while reducing the high dimensionality inherent in\nhigh-order tensor data. The effectiveness of our approach is verified through\nexperiments on three widely-used PRe-ID datasets: VIPeR, GRID, and PRID450S.\nExtensive experiments demonstrate that our approach outperforms recent\nstate-of-the-art methods.",
      "tldr_zh": "该论文针对视频监控中的人重新识别（PRe-ID）挑战，提出了一种基于高阶张量特征融合的多线性子空间学习方法，以提升行人图像的鲁棒描述和区分能力。具体而言，该方法引入 High-Dimensional Feature Fusion (HDFF) 方案，将 Convolutional Neural Networks (CNN) 和 Local Maximal Occurrence (LOMO) 特征融合成单一张量，并使用 Tensor Cross-View Quadratic Analysis (TXQDA) 进行多线性子空间学习，以减少高维数据并提高匹配准确性。实验在 VIPeR、GRID 和 PRID450S 数据集上验证，表明该方法优于现有最先进技术。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15825v1",
      "published_date": "2025-05-09 23:39:27 UTC",
      "updated_date": "2025-05-09 23:39:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:14:19.369334"
    },
    {
      "arxiv_id": "2505.06464v1",
      "title": "Opening the Scope of Openness in AI",
      "title_zh": "扩展AI中开放性的范围",
      "authors": [
        "Tamara Paris",
        "AJung Moon",
        "Jin Guo"
      ],
      "abstract": "The concept of openness in AI has so far been heavily inspired by the\ndefinition and community practice of open source software. This positions\nopenness in AI as having positive connotations; it introduces assumptions of\ncertain advantages, such as collaborative innovation and transparency. However,\nthe practices and benefits of open source software are not fully transferable\nto AI, which has its own challenges. Framing a notion of openness tailored to\nAI is crucial to addressing its growing societal implications, risks, and\ncapabilities. We argue that considering the fundamental scope of openness in\ndifferent disciplines will broaden discussions, introduce important\nperspectives, and reflect on what openness in AI should mean. Toward this goal,\nwe qualitatively analyze 98 concepts of openness discovered from topic\nmodeling, through which we develop a taxonomy of openness. Using this taxonomy\nas an instrument, we situate the current discussion on AI openness, identify\ngaps and highlight links with other disciplines. Our work contributes to the\nrecent efforts in framing openness in AI by reflecting principles and practices\nof openness beyond open source software and calls for a more holistic view of\nopenness in terms of actions, system properties, and ethical objectives.",
      "tldr_zh": "该论文探讨了AI领域的开放概念，目前主要受开源软件(open source software)的影响，导致假设其带来协作创新和透明等优势，但这些实践并不完全适用于AI的独特挑战。作者通过对从主题建模(topic modeling)中提取的98个开放概念进行定性分析，开发了一个开放分类法(taxonomy)。基于此分类法，他们定位了当前AI开放讨论的范围，识别了现有差距，并与其他学科建立联系，最终呼吁一种更全面的AI开放视角，包括行动、系统属性和伦理目标。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "To appear in ACM Conference on Fairness, Accountability, and\n  Transparency (ACM FAccT) 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.06464v1",
      "published_date": "2025-05-09 23:16:44 UTC",
      "updated_date": "2025-05-09 23:16:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:14:30.659845"
    },
    {
      "arxiv_id": "2505.06459v1",
      "title": "Improved Uncertainty Quantification in Physics-Informed Neural Networks Using Error Bounds and Solution Bundles",
      "title_zh": "使用误差界和解束改善物理信息神经网络中的不确定",
      "authors": [
        "Pablo Flores",
        "Olga Graf",
        "Pavlos Protopapas",
        "Karim Pichara"
      ],
      "abstract": "Physics-Informed Neural Networks (PINNs) have been widely used to obtain\nsolutions to various physical phenomena modeled as Differential Equations. As\nPINNs are not naturally equipped with mechanisms for Uncertainty\nQuantification, some work has been done to quantify the different uncertainties\nthat arise when dealing with PINNs. In this paper, we use a two-step procedure\nto train Bayesian Neural Networks that provide uncertainties over the solutions\nto differential equation systems provided by PINNs. We use available error\nbounds over PINNs to formulate a heteroscedastic variance that improves the\nuncertainty estimation. Furthermore, we solve forward problems and utilize the\nobtained uncertainties when doing parameter estimation in inverse problems in\ncosmology.",
      "tldr_zh": "本文提出了一种改进 Physics-Informed Neural Networks (PINNs) 不确定性量化的方法，通过利用误差边界和解决方案束来提升准确性。研究采用两步过程训练 Bayesian Neural Networks，利用 heteroscedastic variance 公式化不确定性估计，从而更好地量化 PINNs 解决微分方程系统的变异性。该方法在正向问题中验证有效，并应用于宇宙学反问题中的参数估计，提供更可靠的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.comp-ph",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06459v1",
      "published_date": "2025-05-09 22:40:39 UTC",
      "updated_date": "2025-05-09 22:40:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:14:42.865203"
    },
    {
      "arxiv_id": "2505.06438v1",
      "title": "Reliable Collaborative Conversational Agent System Based on LLMs and Answer Set Programming",
      "title_zh": "基于LLMs和Answer Set Programming的可靠协作对话代理系统",
      "authors": [
        "Yankai Zeng",
        "Gopal Gupta"
      ],
      "abstract": "As the Large-Language-Model-driven (LLM-driven) Artificial Intelligence (AI)\nbots became popular, people realized their strong potential in Task-Oriented\nDialogue (TOD). However, bots relying wholly on LLMs are unreliable in their\nknowledge, and whether they can finally produce a correct result for the task\nis not guaranteed. The collaboration among these agents also remains a\nchallenge, since the necessary information to convey is unclear, and the\ninformation transfer is by prompts -- unreliable, and malicious knowledge is\neasy to inject. With the help of logic programming tools such as Answer Set\nProgramming (ASP), conversational agents can be built safely and reliably, and\ncommunication among the agents made more efficient and secure. We proposed an\nAdministrator-Assistant Dual-Agent paradigm, where the two ASP-driven bots\nshare the same knowledge base and complete their tasks independently, while the\ninformation can be passed by a Collaborative Rule Set (CRS). The knowledge and\ninformation conveyed are encapsulated and invisible to the users, ensuring the\nsecurity of information transmission. We have constructed AutoManager, a\ndual-agent system for managing the drive-through window of a fast-food\nrestaurant such as Taco Bell in the US. In AutoManager, the assistant bot takes\nthe customer's order while the administrator bot manages the menu and food\nsupply. We evaluated our AutoManager and compared it with the real-world Taco\nBell Drive-Thru AI Order Taker, and the results show that our method is more\nreliable.",
      "tldr_zh": "该论文解决了LLM驱动的对话代理在Task-Oriented Dialogue (TOD)中的不可靠性问题，包括知识不准确和代理协作挑战，通过整合Answer Set Programming (ASP)构建安全可靠的系统。研究提出Administrator-Assistant Dual-Agent范式，其中两个ASP驱动的代理共享知识基，并通过Collaborative Rule Set (CRS)封装信息进行高效、安全传输。实验中开发的AutoManager系统用于管理快餐店如Taco Bell的Drive-Thru窗口，结果显示其可靠性优于真实世界的AI订单系统。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.06438v1",
      "published_date": "2025-05-09 21:14:32 UTC",
      "updated_date": "2025-05-09 21:14:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:14:55.437932"
    },
    {
      "arxiv_id": "2505.06436v1",
      "title": "My Emotion on your face: The use of Facial Keypoint Detection to preserve Emotions in Latent Space Editing",
      "title_zh": "翻译失败",
      "authors": [
        "Jingrui He",
        "Andrew Stephen McGough"
      ],
      "abstract": "Generative Adversarial Network approaches such as StyleGAN/2 provide two key\nbenefits: the ability to generate photo-realistic face images and possessing a\nsemantically structured latent space from which these images are created. Many\napproaches have emerged for editing images derived from vectors in the latent\nspace of a pre-trained StyleGAN/2 models by identifying semantically meaningful\ndirections (e.g., gender or age) in the latent space. By moving the vector in a\nspecific direction, the ideal result would only change the target feature while\npreserving all the other features. Providing an ideal data augmentation\napproach for gesture research as it could be used to generate numerous image\nvariations whilst keeping the facial expressions intact. However, entanglement\nissues, where changing one feature inevitably affects other features, impacts\nthe ability to preserve facial expressions. To address this, we propose the use\nof an addition to the loss function of a Facial Keypoint Detection model to\nrestrict changes to the facial expressions. Building on top of an existing\nmodel, adding the proposed Human Face Landmark Detection (HFLD) loss, provided\nby a pre-trained Facial Keypoint Detection model, to the original loss\nfunction. We quantitatively and qualitatively evaluate the existing and our\nextended model, showing the effectiveness of our approach in addressing the\nentanglement issue and maintaining the facial expression. Our approach achieves\nup to 49% reduction in the change of emotion in our experiments. Moreover, we\nshow the benefit of our approach by comparing with state-of-the-art models. By\nincreasing the ability to preserve the facial gesture and expression during\nfacial transformation, we present a way to create human face images with fixed\nexpression but different appearances, making it a reliable data augmentation\napproach for Facial Gesture and Expression research.",
      "tldr_zh": "本文提出了一种方法，使用 Facial Keypoint Detection 来解决潜在空间编辑中的纠缠问题（entanglement），以在编辑面部图像（如通过 StyleGAN/2 生成）时保留面部表情。研究在 Facial Keypoint Detection 模型的损失函数中添加 Human Face Landmark Detection (HFLD) 损失，限制表情变化，同时允许其他特征（如性别或年龄）调整。实验结果显示，该方法可将表情变化减少高达 49%，并在与现有模型的比较中表现出优势，为面部手势和表情研究提供可靠的数据增强途径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Submitted to 2nd International Workshop on Synthetic Data for Face\n  and Gesture Analysis at IEEE FG 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.06436v1",
      "published_date": "2025-05-09 21:10:27 UTC",
      "updated_date": "2025-05-09 21:10:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:15:07.907367"
    },
    {
      "arxiv_id": "2505.06428v1",
      "title": "What Do People Want to Know About Artificial Intelligence (AI)? The Importance of Answering End-User Questions to Explain Autonomous Vehicle (AV) Decisions",
      "title_zh": "翻译失败",
      "authors": [
        "Somayeh Molaei",
        "Lionel P. Robert",
        "Nikola Banovic"
      ],
      "abstract": "Improving end-users' understanding of decisions made by autonomous vehicles\n(AVs) driven by artificial intelligence (AI) can improve utilization and\nacceptance of AVs. However, current explanation mechanisms primarily help AI\nresearchers and engineers in debugging and monitoring their AI systems, and may\nnot address the specific questions of end-users, such as passengers, about AVs\nin various scenarios. In this paper, we conducted two user studies to\ninvestigate questions that potential AV passengers might pose while riding in\nan AV and evaluate how well answers to those questions improve their\nunderstanding of AI-driven AV decisions. Our initial formative study identified\na range of questions about AI in autonomous driving that existing explanation\nmechanisms do not readily address. Our second study demonstrated that\ninteractive text-based explanations effectively improved participants'\ncomprehension of AV decisions compared to simply observing AV decisions. These\nfindings inform the design of interactions that motivate end-users to engage\nwith and inquire about the reasoning behind AI-driven AV decisions.",
      "tldr_zh": "本研究探讨了回答终端用户问题的重要性，以提升人们对AI驱动的自动驾驶车辆(AV)决策的理解，从而提高AV的使用和接受度。研究者开展了两个用户研究：第一个形成性研究识别出潜在AV乘客可能提出的各种问题，这些问题现有解释机制无法充分解决；第二个研究证明，交互式文本解释比单纯观察AV决策更能有效改善参与者的理解。这些发现为设计鼓励用户参与和询问AI决策推理的交互系统提供了重要指导。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted to the Proceedings of the ACM on Human-Computer Interaction,\n  CSCW, October 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.06428v1",
      "published_date": "2025-05-09 20:57:34 UTC",
      "updated_date": "2025-05-09 20:57:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:15:19.258149"
    },
    {
      "arxiv_id": "2505.06413v1",
      "title": "Natural Reflection Backdoor Attack on Vision Language Model for Autonomous Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Ming Liu",
        "Siyuan Liang",
        "Koushik Howlader",
        "Liwen Wang",
        "Dacheng Tao",
        "Wensheng Zhang"
      ],
      "abstract": "Vision-Language Models (VLMs) have been integrated into autonomous driving\nsystems to enhance reasoning capabilities through tasks such as Visual Question\nAnswering (VQA). However, the robustness of these systems against backdoor\nattacks remains underexplored. In this paper, we propose a natural\nreflection-based backdoor attack targeting VLM systems in autonomous driving\nscenarios, aiming to induce substantial response delays when specific visual\ntriggers are present. We embed faint reflection patterns, mimicking natural\nsurfaces such as glass or water, into a subset of images in the DriveLM\ndataset, while prepending lengthy irrelevant prefixes (e.g., fabricated stories\nor system update notifications) to the corresponding textual labels. This\nstrategy trains the model to generate abnormally long responses upon\nencountering the trigger. We fine-tune two state-of-the-art VLMs, Qwen2-VL and\nLLaMA-Adapter, using parameter-efficient methods. Experimental results\ndemonstrate that while the models maintain normal performance on clean inputs,\nthey exhibit significantly increased inference latency when triggered,\npotentially leading to hazardous delays in real-world autonomous driving\ndecision-making. Further analysis examines factors such as poisoning rates,\ncamera perspectives, and cross-view transferability. Our findings uncover a new\nclass of attacks that exploit the stringent real-time requirements of\nautonomous driving, posing serious challenges to the security and reliability\nof VLM-augmented driving systems.",
      "tldr_zh": "本研究提出了一种自然反射后门攻击（Natural Reflection Backdoor Attack），针对视觉语言模型（VLMs）在自动驾驶系统中的应用，旨在通过特定视觉触发器诱发模型响应延迟。攻击方法涉及在DriveLM数据集的部分图像中嵌入微弱的反射图案（如玻璃或水表面），并为对应文本标签添加冗长无关前缀（如虚构故事或系统更新通知），以训练模型在触发时生成异常长的响应。实验结果显示，微调后的Qwen2-VL和LLaMA-Adapter模型在干净输入上保持正常性能，但遇到触发器时推理延迟显著增加，可能导致自动驾驶决策中的安全风险。该攻击还分析了中毒率、相机视角和跨视图可转移性等因素，揭示了VLMs在实时应用中的新安全挑战。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06413v1",
      "published_date": "2025-05-09 20:28:17 UTC",
      "updated_date": "2025-05-09 20:28:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:15:32.004949"
    },
    {
      "arxiv_id": "2505.06411v1",
      "title": "MAGE:A Multi-stage Avatar Generator with Sparse Observations",
      "title_zh": "翻译失败",
      "authors": [
        "Fangyu Du",
        "Yang Yang",
        "Xuehao Gao",
        "Hongye Hou"
      ],
      "abstract": "Inferring full-body poses from Head Mounted Devices, which capture only\n3-joint observations from the head and wrists, is a challenging task with wide\nAR/VR applications. Previous attempts focus on learning one-stage motion\nmapping and thus suffer from an over-large inference space for unobserved body\njoint motions. This often leads to unsatisfactory lower-body predictions and\npoor temporal consistency, resulting in unrealistic or incoherent motion\nsequences. To address this, we propose a powerful Multi-stage Avatar GEnerator\nnamed MAGE that factorizes this one-stage direct motion mapping learning with a\nprogressive prediction strategy. Specifically, given initial 3-joint motions,\nMAGE gradually inferring multi-scale body part poses at different abstract\ngranularity levels, starting from a 6-part body representation and gradually\nrefining to 22 joints. With decreasing abstract levels step by step, MAGE\nintroduces more motion context priors from former prediction stages and thus\nimproves realistic motion completion with richer constraint conditions and less\nambiguity. Extensive experiments on large-scale datasets verify that MAGE\nsignificantly outperforms state-of-the-art methods with better accuracy and\ncontinuity.",
      "tldr_zh": "这篇论文提出了 MAGE，一种多阶段头像生成器，用于从头戴设备捕获的稀疏观察（仅头部和手腕的3个关节）推断全身体势，以解决传统单阶段运动映射的准确性和时间一致性问题。MAGE 采用渐进预测策略，从6部分身体表示逐步细化到22个关节，每个阶段引入更多运动上下文先验，减少歧义并提升预测的真实性。实验在大型数据集上验证，MAGE 在准确性和连续性方面显著优于现有方法，为 AR/VR 应用提供了更可靠的运动完成技术。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06411v1",
      "published_date": "2025-05-09 20:21:00 UTC",
      "updated_date": "2025-05-09 20:21:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:15:43.725346"
    },
    {
      "arxiv_id": "2505.06409v1",
      "title": "Engineering Risk-Aware, Security-by-Design Frameworks for Assurance of Large-Scale Autonomous AI Models",
      "title_zh": "翻译失败",
      "authors": [
        "Krti Tallam"
      ],
      "abstract": "As AI models scale to billions of parameters and operate with increasing\nautonomy, ensuring their safe, reliable operation demands engineering-grade\nsecurity and assurance frameworks. This paper presents an enterprise-level,\nrisk-aware, security-by-design approach for large-scale autonomous AI systems,\nintegrating standardized threat metrics, adversarial hardening techniques, and\nreal-time anomaly detection into every phase of the development lifecycle. We\ndetail a unified pipeline - from design-time risk assessments and secure\ntraining protocols to continuous monitoring and automated audit logging - that\ndelivers provable guarantees of model behavior under adversarial and\noperational stress. Case studies in national security, open-source model\ngovernance, and industrial automation demonstrate measurable reductions in\nvulnerability and compliance overhead. Finally, we advocate cross-sector\ncollaboration - uniting engineering teams, standards bodies, and regulatory\nagencies - to institutionalize these technical safeguards within a resilient,\nend-to-end assurance ecosystem for the next generation of AI.",
      "tldr_zh": "这篇论文提出了一种风险感知(risk-aware)、安全设计(security-by-design)的框架，用于确保大规模自治 AI 模型的安全性和可靠性。该框架整合了标准化威胁指标、adversarial hardening 技术和实时异常检测，贯穿开发生命周期的每个阶段，包括设计时的风险评估、安全训练、持续监控和自动审计日志，以提供可证明的模型行为保证。案例研究在国家安全、开源模型治理和工业自动化领域展示了显著减少漏洞和合规开销的效果。最后，论文倡导跨部门合作，包括工程团队、标准机构和监管机构，以构建一个坚韧的端到端 AI 保障生态系统。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.ET",
        "cs.LG",
        "cs.MA",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06409v1",
      "published_date": "2025-05-09 20:14:53 UTC",
      "updated_date": "2025-05-09 20:14:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:15:55.876206"
    },
    {
      "arxiv_id": "2505.06402v1",
      "title": "Camera Control at the Edge with Language Models for Scene Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Alexiy Buynitsky",
        "Sina Ehsani",
        "Bhanu Pallakonda",
        "Pragyana Mishra"
      ],
      "abstract": "In this paper, we present Optimized Prompt-based Unified System (OPUS), a\nframework that utilizes a Large Language Model (LLM) to control Pan-Tilt-Zoom\n(PTZ) cameras, providing contextual understanding of natural environments. To\nachieve this goal, the OPUS system improves cost-effectiveness by generating\nkeywords from a high-level camera control API and transferring knowledge from\nlarger closed-source language models to smaller ones through Supervised\nFine-Tuning (SFT) on synthetic data. This enables efficient edge deployment\nwhile maintaining performance comparable to larger models like GPT-4. OPUS\nenhances environmental awareness by converting data from multiple cameras into\ntextual descriptions for language models, eliminating the need for specialized\nsensory tokens. In benchmark testing, our approach significantly outperformed\nboth traditional language model techniques and more complex prompting methods,\nachieving a 35% improvement over advanced techniques and a 20% higher task\naccuracy compared to closed-source models like Gemini Pro. The system\ndemonstrates OPUS's capability to simplify PTZ camera operations through an\nintuitive natural language interface. This approach eliminates the need for\nexplicit programming and provides a conversational method for interacting with\ncamera systems, representing a significant advancement in how users can control\nand utilize PTZ camera technology.",
      "tldr_zh": "本文提出 OPUS 框架，利用 Large Language Model (LLM) 控制 Pan-Tilt-Zoom (PTZ) 相机，实现对自然环境的上下文理解，并通过生成关键词和高层 API 结合 Supervised Fine-Tuning (SFT) 在合成数据上转移知识，提升成本效益和边缘部署效率。OPUS 将多相机数据转换为文本描述，免除专用感官标记的需求，使系统性能与 GPT-4 相当。在基准测试中，该框架比传统方法和复杂提示技术提高了 35%，并比 Gemini Pro 高 20% 的任务准确率，提供直观的自然语言接口，简化相机操作并实现对话式交互。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.RO",
      "comment": "7 pages, 6 figures. This work was presented and published at the 11th\n  IEEE International Conference on Control, Automation and Robotics (ICCAR) in\n  2025",
      "pdf_url": "http://arxiv.org/pdf/2505.06402v1",
      "published_date": "2025-05-09 20:00:29 UTC",
      "updated_date": "2025-05-09 20:00:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:16:08.207735"
    },
    {
      "arxiv_id": "2505.07871v1",
      "title": "Evaluating Financial Sentiment Analysis with Annotators Instruction Assisted Prompting: Enhancing Contextual Interpretation and Stock Prediction Accuracy",
      "title_zh": "使用标注者指令辅助提示评估",
      "authors": [
        "A M Muntasir Rahman",
        "Ajim Uddin",
        "Guiling \"Grace\" Wang"
      ],
      "abstract": "Financial sentiment analysis (FSA) presents unique challenges to LLMs that\nsurpass those in typical sentiment analysis due to the nuanced language used in\nfinancial contexts. The prowess of these models is often undermined by the\ninherent subjectivity of sentiment classifications in existing benchmark\ndatasets like Financial Phrasebank. These datasets typically feature undefined\nsentiment classes that reflect the highly individualized perspectives of\nannotators, leading to significant variability in annotations. This variability\nresults in an unfair expectation for LLMs during benchmarking, where they are\ntasked to conjecture the subjective viewpoints of human annotators without\nsufficient context. In this paper, we introduce the Annotators' Instruction\nAssisted Prompt, a novel evaluation prompt designed to redefine the task\ndefinition of FSA for LLMs. By integrating detailed task instructions\noriginally intended for human annotators into the LLMs' prompt framework, AIAP\naims to standardize the understanding of sentiment across both human and\nmachine interpretations, providing a fair and context-rich foundation for\nsentiment analysis. We utilize a new dataset, WSBS, derived from the\nWallStreetBets subreddit to demonstrate how AIAP significantly enhances LLM\nperformance by aligning machine operations with the refined task definitions.\nExperimental results demonstrate that AIAP enhances LLM performance\nsignificantly, with improvements up to 9.08. This context-aware approach not\nonly yields incremental gains in performance but also introduces an innovative\nsentiment-indexing method utilizing model confidence scores. This method\nenhances stock price prediction models and extracts more value from the\nfinancial sentiment analysis, underscoring the significance of WSB as a\ncritical source of financial text. Our research offers insights into both\nimproving FSA through better evaluation methods.",
      "tldr_zh": "该论文探讨了金融情感分析（FSA）对大型语言模型（LLMs）的独特挑战，如现有基准数据集（如Financial Phrasebank）的标注主观性导致的评估不公。研究引入了Annotators' Instruction Assisted Prompt（AIAP），一种新颖的提示框架，将人类标注者的详细任务指令整合到LLMs中，以标准化情感理解并提供丰富的语境支持。利用新数据集WSBS（源自WallStreetBets子reddit），实验结果显示AIAP显著提升LLMs性能，提高幅度高达9.08%。此外，该方法还提出了一种基于模型置信度分数的创新情感索引技术，提升了股票价格预测的准确性，并突出了改进FSA评估方法的潜在价值。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07871v1",
      "published_date": "2025-05-09 19:44:04 UTC",
      "updated_date": "2025-05-09 19:44:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:16:20.553968"
    },
    {
      "arxiv_id": "2505.06394v1",
      "title": "Towards AI-Driven Human-Machine Co-Teaming for Adaptive and Agile Cyber Security Operation Centers",
      "title_zh": "迈向AI驱动的人机协同团队，用于适应性和敏捷的网络安全运营中心",
      "authors": [
        "Massimiliano Albanese",
        "Xinming Ou",
        "Kevin Lybarger",
        "Daniel Lende",
        "Dmitry Goldgof"
      ],
      "abstract": "Security Operations Centers (SOCs) face growing challenges in managing\ncybersecurity threats due to an overwhelming volume of alerts, a shortage of\nskilled analysts, and poorly integrated tools. Human-AI collaboration offers a\npromising path to augment the capabilities of SOC analysts while reducing their\ncognitive overload. To this end, we introduce an AI-driven human-machine\nco-teaming paradigm that leverages large language models (LLMs) to enhance\nthreat intelligence, alert triage, and incident response workflows. We present\na vision in which LLM-based AI agents learn from human analysts the tacit\nknowledge embedded in SOC operations, enabling the AI agents to improve their\nperformance on SOC tasks through this co-teaming. We invite SOCs to collaborate\nwith us to further develop this process and uncover replicable patterns where\nhuman-AI co-teaming yields measurable improvements in SOC productivity.",
      "tldr_zh": "该论文探讨了Security Operations Centers (SOCs) 在应对海量警报、分析师短缺和工具整合问题时的挑战，并提出一种AI驱动的人机协作范式。利用large language models (LLMs)，该范式增强威胁情报、警报分级和事件响应流程，让AI agents 通过学习人类分析师的隐性知识来提升SOC任务性能。最终，研究呼吁与SOCs 合作，识别人类-AI co-teaming 的可复制模式，以实现SOC生产力的可量化改善。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06394v1",
      "published_date": "2025-05-09 19:38:26 UTC",
      "updated_date": "2025-05-09 19:38:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:16:31.159078"
    },
    {
      "arxiv_id": "2505.06380v1",
      "title": "Offensive Security for AI Systems: Concepts, Practices, and Applications",
      "title_zh": "AI 系统的进攻性安全：概念、实践和应用",
      "authors": [
        "Josh Harguess",
        "Chris M. Ward"
      ],
      "abstract": "As artificial intelligence (AI) systems become increasingly adopted across\nsectors, the need for robust, proactive security strategies is paramount.\nTraditional defensive measures often fall short against the unique and evolving\nthreats facing AI-driven technologies, making offensive security an essential\napproach for identifying and mitigating risks. This paper presents a\ncomprehensive framework for offensive security in AI systems, emphasizing\nproactive threat simulation and adversarial testing to uncover vulnerabilities\nthroughout the AI lifecycle. We examine key offensive security techniques,\nincluding weakness and vulnerability assessment, penetration testing, and red\nteaming, tailored specifically to address AI's unique susceptibilities. By\nsimulating real-world attack scenarios, these methodologies reveal critical\ninsights, informing stronger defensive strategies and advancing resilience\nagainst emerging threats. This framework advances offensive AI security from\ntheoretical concepts to practical, actionable methodologies that organizations\ncan implement to strengthen their AI systems against emerging threats.",
      "tldr_zh": "这篇论文提出一个针对 AI 系统的进攻性安全（offensive security）框架，强调通过主动威胁模拟和对抗测试来识别并缓解风险，以应对传统防御措施的不足。该框架包括 weakness and vulnerability assessment、penetration testing 和 red teaming 等关键技术，专门针对 AI 的独特易受攻击性，通过模拟真实攻击场景揭示漏洞并提供洞见。最终，该方法将理论概念转化为可操作的实践，帮助组织加强 AI 系统对新兴威胁的韧性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06380v1",
      "published_date": "2025-05-09 18:58:56 UTC",
      "updated_date": "2025-05-09 18:58:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:16:43.588318"
    },
    {
      "arxiv_id": "2505.06378v1",
      "title": "Bi-LSTM based Multi-Agent DRL with Computation-aware Pruning for Agent Twins Migration in Vehicular Embodied AI Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxiang Wei",
        "Zhuoqi Zeng",
        "Yue Zhong",
        "Jiawen Kang",
        "Ryan Wen Liu",
        "M. Shamim Hossain"
      ],
      "abstract": "With the advancement of large language models and embodied Artificial\nIntelligence (AI) in the intelligent transportation scenarios, the combination\nof them in intelligent transportation spawns the Vehicular Embodied AI Network\n(VEANs). In VEANs, Autonomous Vehicles (AVs) are typical agents whose local\nadvanced AI applications are defined as vehicular embodied AI agents, enabling\ncapabilities such as environment perception and multi-agent collaboration. Due\nto computation latency and resource constraints, the local AI applications and\nservices running on vehicular embodied AI agents need to be migrated, and\nsubsequently referred to as vehicular embodied AI agent twins, which drive the\nadvancement of vehicular embodied AI networks to offload intensive tasks to\nRoadside Units (RSUs), mitigating latency problems while maintaining service\nquality. Recognizing workload imbalance among RSUs in traditional approaches,\nwe model AV-RSU interactions as a Stackelberg game to optimize bandwidth\nresource allocation for efficient migration. A Tiny Multi-Agent Bidirectional\nLSTM Proximal Policy Optimization (TMABLPPO) algorithm is designed to\napproximate the Stackelberg equilibrium through decentralized coordination.\nFurthermore, a personalized neural network pruning algorithm based on Path\neXclusion (PX) dynamically adapts to heterogeneous AV computation capabilities\nby identifying task-critical parameters in trained models, reducing model\ncomplexity with less performance degradation. Experimental validation confirms\nthe algorithm's effectiveness in balancing system load and minimizing delays,\ndemonstrating significant improvements in vehicular embodied AI agent\ndeployment.",
      "tldr_zh": "这篇论文针对Vehicular Embodied AI Networks (VEANs)中Autonomous Vehicles (AVs)的Agent Twins迁移问题，提出了一种基于Bi-LSTM的Multi-Agent Deep Reinforcement Learning (DRL)框架，以解决计算延迟和资源限制。框架通过将AV-RSU互动建模为Stackelberg游戏优化带宽资源分配，并设计了Tiny Multi-Agent Bidirectional LSTM Proximal Policy Optimization (TMABLPPO)算法，实现去中心化协调和近似均衡；同时，引入基于Path eXclusion (PX)的个性化神经网络剪枝算法，动态适应异构AV的计算能力，减少模型复杂度并最小化性能损失。实验验证表明，该方法显著改善了系统负载平衡和延迟最小化，提升了vehicular embodied AI agent的部署效率。",
      "categories": [
        "cs.GT",
        "cs.AI"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06378v1",
      "published_date": "2025-05-09 18:52:26 UTC",
      "updated_date": "2025-05-09 18:52:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:16:56.630151"
    },
    {
      "arxiv_id": "2505.06371v1",
      "title": "The ML.ENERGY Benchmark: Toward Automated Inference Energy Measurement and Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Jae-Won Chung",
        "Jiachen Liu",
        "Jeff J. Ma",
        "Ruofan Wu",
        "Oh Jun Kweon",
        "Yuxuan Xia",
        "Zhiyu Wu",
        "Mosharaf Chowdhury"
      ],
      "abstract": "As the adoption of Generative AI in real-world services grow explosively,\nenergy has emerged as a critical bottleneck resource. However, energy remains a\nmetric that is often overlooked, under-explored, or poorly understood in the\ncontext of building ML systems. We present the ML.ENERGY Benchmark, a benchmark\nsuite and tool for measuring inference energy consumption under realistic\nservice environments, and the corresponding ML.ENERGY Leaderboard, which have\nserved as a valuable resource for those hoping to understand and optimize the\nenergy consumption of their generative AI services. In this paper, we explain\nfour key design principles for benchmarking ML energy we have acquired over\ntime, and then describe how they are implemented in the ML.ENERGY Benchmark. We\nthen highlight results from the latest iteration of the benchmark, including\nenergy measurements of 40 widely used model architectures across 6 different\ntasks, case studies of how ML design choices impact energy consumption, and how\nautomated optimization recommendations can lead to significant (sometimes more\nthan 40%) energy savings without changing what is being computed by the model.\nThe ML.ENERGY Benchmark is open-source and can be easily extended to various\ncustomized models and application scenarios.",
      "tldr_zh": "该论文提出 ML.ENERGY Benchmark，一种用于自动化测量和优化机器学习(ML)模型推理能源消耗的基准测试套件和排行榜，以应对生成式 AI 服务中能源瓶颈问题。基准设计基于四个关键原则，包括在现实服务环境中测量 40 个模型架构在 6 个任务上的能源消耗，并通过案例研究分析 ML 设计选择如何影响能源效率。结果显示，自动化优化推荐可实现超过 40% 的能源节省，而不改变模型计算，且该基准是开源的，便于扩展到自定义模型和场景。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Leaderboard: https://ml.energy/leaderboard",
      "pdf_url": "http://arxiv.org/pdf/2505.06371v1",
      "published_date": "2025-05-09 18:27:32 UTC",
      "updated_date": "2025-05-09 18:27:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:17:08.252284"
    },
    {
      "arxiv_id": "2505.06363v1",
      "title": "Learning Sequential Kinematic Models from Demonstrations for Multi-Jointed Articulated Objects",
      "title_zh": "翻译失败",
      "authors": [
        "Anmol Gupta",
        "Weiwei Gu",
        "Omkar Patil",
        "Jun Ki Lee",
        "Nakul Gopalan"
      ],
      "abstract": "As robots become more generalized and deployed in diverse environments, they\nmust interact with complex objects, many with multiple independent joints or\ndegrees of freedom (DoF) requiring precise control. A common strategy is object\nmodeling, where compact state-space models are learned from real-world\nobservations and paired with classical planning. However, existing methods\noften rely on prior knowledge or focus on single-DoF objects, limiting their\napplicability. They also fail to handle occluded joints and ignore the\nmanipulation sequences needed to access them. We address this by learning\nobject models from human demonstrations. We introduce Object Kinematic Sequence\nMachines (OKSMs), a novel representation capturing both kinematic constraints\nand manipulation order for multi-DoF objects. To estimate these models from\npoint cloud data, we present Pokenet, a deep neural network trained on human\ndemonstrations. We validate our approach on 8,000 simulated and 1,600\nreal-world annotated samples. Pokenet improves joint axis and state estimation\nby over 20 percent on real-world data compared to prior methods. Finally, we\ndemonstrate OKSMs on a Sawyer robot using inverse kinematics-based planning to\nmanipulate multi-DoF objects.",
      "tldr_zh": "本研究针对机器人与多关节、多自由度（DoF）对象的交互问题，提出了一种从人类演示中学习对象模型的方法，以解决现有方法依赖先验知识和无法处理遮挡关节的局限。作者引入了Object Kinematic Sequence Machines (OKSMs)，一种新型表示，能够捕捉多DoF对象的运动约束和操作顺序。基于此，他们开发了Pokenet，一种从point cloud data中估计模型的深度神经网络，并在8,000个模拟和1,600个真实样本上验证，实现了关节轴和状态估计准确率提高20%以上。最后，通过逆运动学规划在Sawyer机器人上演示了OKSMs的应用，为机器人精确操控复杂对象提供了可靠框架。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06363v1",
      "published_date": "2025-05-09 18:09:06 UTC",
      "updated_date": "2025-05-09 18:09:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:17:19.532329"
    },
    {
      "arxiv_id": "2505.06347v1",
      "title": "Quantum State Preparation via Large-Language-Model-Driven Evolution",
      "title_zh": "通过大语言模型驱动的进化实现量子态制备",
      "authors": [
        "Qing-Hong Cao",
        "Zong-Yue Hou",
        "Ying-Ying Li",
        "Xiaohui Liu",
        "Zhuo-Yang Song",
        "Liang-Qi Zhang",
        "Shutao Zhang",
        "Ke Zhao"
      ],
      "abstract": "We propose an automated framework for quantum circuit design by integrating\nlarge-language models (LLMs) with evolutionary optimization to overcome the\nrigidity, scalability limitations, and expert dependence of traditional ones in\nvariational quantum algorithms. Our approach (FunSearch) autonomously discovers\nhardware-efficient ans\\\"atze with new features of scalability and\nsystem-size-independent number of variational parameters entirely from scratch.\nDemonstrations on the Ising and XY spin chains with n = 9 qubits yield circuits\ncontaining 4 parameters, achieving near-exact energy extrapolation across\nsystem sizes. Implementations on quantum hardware (Zuchongzhi chip) validate\npracticality, where two-qubit quantum gate noises can be effectively mitigated\nvia zero-noise extrapolations for a spin chain system as large as 20 sites.\nThis framework bridges algorithmic design and experimental constraints,\ncomplementing contemporary quantum architecture search frameworks to advance\nscalable quantum simulations.",
      "tldr_zh": "本研究提出了一种自动化框架FunSearch，将大型语言模型(LLMs)与进化优化相结合，用于量子电路设计，以克服传统变分量子算法的刚性、可扩展性限制和对专家的依赖。该框架能从零开始自主发现硬件高效的ansätze，具有可扩展性和系统大小无关的参数数量。在Ising和XY自旋链（n=9量子比特）上，实验实现了仅含4个参数的电路，并实现近精确的能量外推；同时，在Zuchongzhi芯片上验证了其实用性，通过零噪声外推有效缓解双量子比特门噪声，支持高达20站点的自旋链系统。该框架桥接了算法设计与实验约束，推动了可扩展量子模拟的发展。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "hep-lat",
        "hep-ph"
      ],
      "primary_category": "quant-ph",
      "comment": "6 + 4 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.06347v1",
      "published_date": "2025-05-09 18:00:02 UTC",
      "updated_date": "2025-05-09 18:00:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:17:31.905361"
    },
    {
      "arxiv_id": "2505.06218v1",
      "title": "Let Humanoids Hike! Integrative Skill Development on Complex Trails",
      "title_zh": "翻译失败",
      "authors": [
        "Kwan-Yee Lin",
        "Stella X. Yu"
      ],
      "abstract": "Hiking on complex trails demands balance, agility, and adaptive\ndecision-making over unpredictable terrain. Current humanoid research remains\nfragmented and inadequate for hiking: locomotion focuses on motor skills\nwithout long-term goals or situational awareness, while semantic navigation\noverlooks real-world embodiment and local terrain variability. We propose\ntraining humanoids to hike on complex trails, driving integrative skill\ndevelopment across visual perception, decision making, and motor execution. We\ndevelop a learning framework, LEGO-H, that enables a vision-equipped humanoid\nrobot to hike complex trails autonomously. We introduce two technical\ninnovations: 1) A temporal vision transformer variant - tailored into\nHierarchical Reinforcement Learning framework - anticipates future local goals\nto guide movement, seamlessly integrating locomotion with goal-directed\nnavigation. 2) Latent representations of joint movement patterns, combined with\nhierarchical metric learning - enhance Privileged Learning scheme - enable\nsmooth policy transfer from privileged training to onboard execution. These\ncomponents allow LEGO-H to handle diverse physical and environmental challenges\nwithout relying on predefined motion patterns. Experiments across varied\nsimulated trails and robot morphologies highlight LEGO-H's versatility and\nrobustness, positioning hiking as a compelling testbed for embodied autonomy\nand LEGO-H as a baseline for future humanoid development.",
      "tldr_zh": "该论文探讨了训练人形机器人（Humanoids）在复杂地形上远足的需求，强调整合视觉感知、决策和运动执行的技能发展，以解决当前研究中存在的碎片化问题。作者提出LEGO-H学习框架，包括一个temporal vision transformer变体整合进Hierarchical Reinforcement Learning，用于预测局部目标并指导导航，以及latent representations结合hierarchical metric learning来提升Privileged Learning的平滑转移。该框架使机器人无需预定义动作模式即可应对多样物理和环境挑战，实验在模拟地形和不同机器人形态上证明了LEGO-H的鲁棒性和多功能性，将远足作为人形机器人自主性的重要测试平台。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "CVPR 2025. Project page:\n  https://lego-h-humanoidrobothiking.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2505.06218v1",
      "published_date": "2025-05-09 17:53:02 UTC",
      "updated_date": "2025-05-09 17:53:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:17:44.962154"
    },
    {
      "arxiv_id": "2505.07870v1",
      "title": "Efficient Fairness Testing in Large Language Models: Prioritizing Metamorphic Relations for Bias Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Suavis Giramata",
        "Madhusudan Srinivasan",
        "Venkat Naidu Gudivada",
        "Upulee Kanewala"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly deployed in various\napplications, raising critical concerns about fairness and potential biases in\ntheir outputs. This paper explores the prioritization of metamorphic relations\n(MRs) in metamorphic testing as a strategy to efficiently detect fairness\nissues within LLMs. Given the exponential growth of possible test cases,\nexhaustive testing is impractical; therefore, prioritizing MRs based on their\neffectiveness in detecting fairness violations is crucial. We apply a sentence\ndiversity-based approach to compute and rank MRs to optimize fault detection.\nExperimental results demonstrate that our proposed prioritization approach\nimproves fault detection rates by 22% compared to random prioritization and 12%\ncompared to distance-based prioritization, while reducing the time to the first\nfailure by 15% and 8%, respectively. Furthermore, our approach performs within\n5% of fault-based prioritization in effectiveness, while significantly reducing\nthe computational cost associated with fault labeling. These results validate\nthe effectiveness of diversity-based MR prioritization in enhancing fairness\ntesting for LLMs.",
      "tldr_zh": "该论文探讨了在大型语言模型（LLMs）中通过优先化 metamorphic relations（MRs）来高效检测公平性偏置问题，以应对测试用例指数级增长带来的挑战。研究提出了一种基于句子多样性的方法来计算和排名 MRs，从而优化故障检测过程。实验结果显示，该方法相较于随机优先化提高了22%的故障检测率，并比基于距离的优先化提高了12%，同时将首次失败时间减少了15%和8%。总体而言，这一方法在有效性上接近基于故障的优先化，但显著降低了计算成本，为LLMs的公平性测试提供了更高效的策略。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07870v1",
      "published_date": "2025-05-09 17:48:34 UTC",
      "updated_date": "2025-05-09 17:48:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:17:55.621240"
    },
    {
      "arxiv_id": "2505.06335v1",
      "title": "Remote Rowhammer Attack using Adversarial Observations on Federated Learning Clients",
      "title_zh": "翻译失败",
      "authors": [
        "Jinsheng Yuan",
        "Yuhang Hao",
        "Weisi Guo",
        "Yun Wu",
        "Chongyan Gu"
      ],
      "abstract": "Federated Learning (FL) has the potential for simultaneous global learning\namongst a large number of parallel agents, enabling emerging AI such as LLMs to\nbe trained across demographically diverse data. Central to this being efficient\nis the ability for FL to perform sparse gradient updates and remote direct\nmemory access at the central server. Most of the research in FL security\nfocuses on protecting data privacy at the edge client or in the communication\nchannels between the client and server. Client-facing attacks on the server are\nless well investigated as the assumption is that a large collective of clients\noffer resilience.\n  Here, we show that by attacking certain clients that lead to a high frequency\nrepetitive memory update in the server, we can remote initiate a rowhammer\nattack on the server memory. For the first time, we do not need backdoor access\nto the server, and a reinforcement learning (RL) attacker can learn how to\nmaximize server repetitive memory updates by manipulating the client's sensor\nobservation. The consequence of the remote rowhammer attack is that we are able\nto achieve bit flips, which can corrupt the server memory. We demonstrate the\nfeasibility of our attack using a large-scale FL automatic speech recognition\n(ASR) systems with sparse updates, our adversarial attacking agent can achieve\naround 70\\% repeated update rate (RUR) in the targeted server model,\neffectively inducing bit flips on server DRAM. The security implications are\nthat can cause disruptions to learning or may inadvertently cause elevated\nprivilege. This paves the way for further research on practical mitigation\nstrategies in FL and hardware design.",
      "tldr_zh": "本研究揭示了联邦学习（Federated Learning, FL）中的新安全风险，通过操纵客户端的传感器观察数据，远程发起 Rowhammer 攻击。攻击者利用强化学习（Reinforcement Learning, RL）算法来最大化服务器端的重复内存更新，从而无需后门访问就诱导服务器内存位翻转。实验在大型 FL 自动语音识别（ASR）系统中显示，攻击可实现约70%的重复更新率（RUR），导致服务器 DRAM 位翻转并可能破坏学习过程或提升权限。该工作强调了 FL 系统的潜在漏洞，并呼吁开发有效的缓解策略和硬件设计改进。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06335v1",
      "published_date": "2025-05-09 17:27:17 UTC",
      "updated_date": "2025-05-09 17:27:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:18:08.217451"
    },
    {
      "arxiv_id": "2505.06191v1",
      "title": "Neuro-Symbolic Concepts",
      "title_zh": "神经符号概念",
      "authors": [
        "Jiayuan Mao",
        "Joshua B. Tenenbaum",
        "Jiajun Wu"
      ],
      "abstract": "This article presents a concept-centric paradigm for building agents that can\nlearn continually and reason flexibly. The concept-centric agent utilizes a\nvocabulary of neuro-symbolic concepts. These concepts, such as object,\nrelation, and action concepts, are grounded on sensory inputs and actuation\noutputs. They are also compositional, allowing for the creation of novel\nconcepts through their structural combination. To facilitate learning and\nreasoning, the concepts are typed and represented using a combination of\nsymbolic programs and neural network representations. Leveraging such\nneuro-symbolic concepts, the agent can efficiently learn and recombine them to\nsolve various tasks across different domains, ranging from 2D images, videos,\n3D scenes, and robotic manipulation tasks. This concept-centric framework\noffers several advantages, including data efficiency, compositional\ngeneralization, continual learning, and zero-shot transfer.",
      "tldr_zh": "本文提出了一种概念中心范式（concept-centric paradigm），用于构建能够持续学习和灵活推理的代理。该范式依赖于神经符号概念（neuro-symbolic concepts），包括对象、关系和动作概念，这些概念基于感官输入和动作输出，并通过符号程序和神经网络表示实现可组合性。代理可以高效学习并重组这些概念，以处理从2D图像、视频、3D场景到机器人操作等多样任务，优势包括数据效率（data efficiency）、组合泛化（compositional generalization）、持续学习（continual learning）和零样本转移（zero-shot transfer）。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "To appear in Communications of the ACM",
      "pdf_url": "http://arxiv.org/pdf/2505.06191v1",
      "published_date": "2025-05-09 17:02:51 UTC",
      "updated_date": "2025-05-09 17:02:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:18:19.521627"
    },
    {
      "arxiv_id": "2505.06186v2",
      "title": "Query-driven Document-level Scientific Evidence Extraction from Biomedical Studies",
      "title_zh": "翻译失败",
      "authors": [
        "Massimiliano Pronesti",
        "Joao Bettencourt-Silva",
        "Paul Flanagan",
        "Alessandra Pascale",
        "Oisin Redmond",
        "Anya Belz",
        "Yufang Hou"
      ],
      "abstract": "Extracting scientific evidence from biomedical studies for clinical research\nquestions (e.g., Does stem cell transplantation improve quality of life in\npatients with medically refractory Crohn's disease compared to placebo?) is a\ncrucial step in synthesising biomedical evidence. In this paper, we focus on\nthe task of document-level scientific evidence extraction for clinical\nquestions with conflicting evidence. To support this task, we create a dataset\ncalled CochraneForest, leveraging forest plots from Cochrane systematic\nreviews. It comprises 202 annotated forest plots, associated clinical research\nquestions, full texts of studies, and study-specific conclusions. Building on\nCochraneForest, we propose URCA (Uniform Retrieval Clustered Augmentation), a\nretrieval-augmented generation framework designed to tackle the unique\nchallenges of evidence extraction. Our experiments show that URCA outperforms\nthe best existing methods by up to 10.3% in F1 score on this task. However, the\nresults also underscore the complexity of CochraneForest, establishing it as a\nchallenging testbed for advancing automated evidence synthesis systems.",
      "tldr_zh": "本论文探讨了基于查询的文档级科学证据提取任务，旨在从生物医学研究中获取针对临床问题的证据（如干细胞移植对克罗恩病患者生活质量的影响）。研究者创建了 CochraneForest 数据集，包括 202 个标注的森林图、临床研究问题、研究全文和结论，以支持证据提取的分析。论文提出 URCA（Uniform Retrieval Clustered Augmentation）框架，这是一种检索增强生成方法，能够有效处理冲突证据的挑战。实验结果显示，URCA 在 F1 score 上比现有最佳方法提升 10.3%，同时将 CochraneForest 确立为自动证据合成系统的复杂测试平台。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06186v2",
      "published_date": "2025-05-09 16:55:06 UTC",
      "updated_date": "2025-05-13 10:50:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:18:31.958127"
    },
    {
      "arxiv_id": "2505.06333v1",
      "title": "NSF-MAP: Neurosymbolic Multimodal Fusion for Robust and Interpretable Anomaly Prediction in Assembly Pipelines",
      "title_zh": "翻译失败",
      "authors": [
        "Chathurangi Shyalika",
        "Renjith Prasad",
        "Fadi El Kalach",
        "Revathy Venkataramanan",
        "Ramtin Zand",
        "Ramy Harik",
        "Amit Sheth"
      ],
      "abstract": "In modern assembly pipelines, identifying anomalies is crucial in ensuring\nproduct quality and operational efficiency. Conventional single-modality\nmethods fail to capture the intricate relationships required for precise\nanomaly prediction in complex predictive environments with abundant data and\nmultiple modalities. This paper proposes a neurosymbolic AI and fusion-based\napproach for multimodal anomaly prediction in assembly pipelines. We introduce\na time series and image-based fusion model that leverages decision-level fusion\ntechniques. Our research builds upon three primary novel approaches in\nmultimodal learning: time series and image-based decision-level fusion\nmodeling, transfer learning for fusion, and knowledge-infused learning. We\nevaluate the novel method using our derived and publicly available multimodal\ndataset and conduct comprehensive ablation studies to assess the impact of our\npreprocessing techniques and fusion model compared to traditional baselines.\nThe results demonstrate that a neurosymbolic AI-based fusion approach that uses\ntransfer learning can effectively harness the complementary strengths of time\nseries and image data, offering a robust and interpretable approach for anomaly\nprediction in assembly pipelines with enhanced performance. \\noindent The\ndatasets, codes to reproduce the results, supplementary materials, and demo are\navailable at https://github.com/ChathurangiShyalika/NSF-MAP.",
      "tldr_zh": "本文提出NSF-MAP，一种神经符号AI和多模态融合方法，用于装配流水线中的鲁棒且可解释的异常预测，旨在解决传统单模态方法无法捕捉复杂关系的问题。该方法引入时间序列和图像的决策级融合建模、transfer learning用于融合，以及knowledge-infused learning，以利用多种数据模态的互补优势。通过实验和消融研究，NSF-MAP在公开多模态数据集上显著提升预测性能，并提供数据集、代码和演示资源。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 7 figures, 2 tables, IJCAI 2025 (International Joint\n  Conferences on Artificial Intelligence) Special Track on AI4Tech: AI Enabling\n  Critical Technologies",
      "pdf_url": "http://arxiv.org/pdf/2505.06333v1",
      "published_date": "2025-05-09 16:50:42 UTC",
      "updated_date": "2025-05-09 16:50:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:18:43.394137"
    },
    {
      "arxiv_id": "2505.06175v1",
      "title": "Turbo-ICL: In-Context Learning-Based Turbo Equalization",
      "title_zh": "翻译失败",
      "authors": [
        "Zihang Song",
        "Matteo Zecchin",
        "Bipin Rajendran",
        "Osvaldo Simeone"
      ],
      "abstract": "This paper introduces a novel in-context learning (ICL) framework, inspired\nby large language models (LLMs), for soft-input soft-output channel\nequalization in coded multiple-input multiple-output (MIMO) systems. The\nproposed approach learns to infer posterior symbol distributions directly from\na prompt of pilot signals and decoder feedback. A key innovation is the use of\nprompt augmentation to incorporate extrinsic information from the decoder\noutput as additional context, enabling the ICL model to refine its symbol\nestimates iteratively across turbo decoding iterations. Two model variants,\nbased on Transformer and state-space architectures, are developed and\nevaluated. Extensive simulations demonstrate that, when traditional linear\nassumptions break down, e.g., in the presence of low-resolution quantization,\nICL equalizers consistently outperform conventional model-based baselines, even\nwhen the latter are provided with perfect channel state information. Results\nalso highlight the advantage of Transformer-based models under limited training\ndiversity, as well as the efficiency of state-space models in\nresource-constrained scenarios.",
      "tldr_zh": "本论文提出了一种基于In-Context Learning (ICL)的框架，Turbo-ICL，受Large Language Models (LLMs)启发，用于软输入软输出通道均衡（soft-input soft-output channel equalization）在编码的Multiple-Input Multiple-Output (MIMO)系统中。该框架通过从pilot signals和decoder feedback的提示中学习推断后验符号分布，并利用prompt augmentation整合decoder输出的外部信息，实现turbo decoding迭代中的符号估计精炼。论文开发了两种模型变体：基于Transformer和state-space architectures的版本。实验结果显示，在传统线性假设失效的场景（如低分辨率量化）下，ICL均衡器显著优于基于模型的基线，即使后者拥有完美的channel state information，且Transformer模型在训练多样性有限时表现突出，而state-space模型在资源受限环境中更高效。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06175v1",
      "published_date": "2025-05-09 16:29:29 UTC",
      "updated_date": "2025-05-09 16:29:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:18:56.294246"
    },
    {
      "arxiv_id": "2505.06152v1",
      "title": "MM-Skin: Enhancing Dermatology Vision-Language Model with an Image-Text Dataset Derived from Textbooks",
      "title_zh": "MM-Skin：利用源自教科书的图像文本数据集",
      "authors": [
        "Wenqi Zeng",
        "Yuqi Sun",
        "Chenxi Ma",
        "Weimin Tan",
        "Bo Yan"
      ],
      "abstract": "Medical vision-language models (VLMs) have shown promise as clinical\nassistants across various medical fields. However, specialized dermatology VLM\ncapable of delivering professional and detailed diagnostic analysis remains\nunderdeveloped, primarily due to less specialized text descriptions in current\ndermatology multimodal datasets. To address this issue, we propose MM-Skin, the\nfirst large-scale multimodal dermatology dataset that encompasses 3 imaging\nmodalities, including clinical, dermoscopic, and pathological and nearly 10k\nhigh-quality image-text pairs collected from professional textbooks. In\naddition, we generate over 27k diverse, instruction-following vision question\nanswering (VQA) samples (9 times the size of current largest dermatology VQA\ndataset). Leveraging public datasets and MM-Skin, we developed SkinVL, a\ndermatology-specific VLM designed for precise and nuanced skin disease\ninterpretation. Comprehensive benchmark evaluations of SkinVL on VQA,\nsupervised fine-tuning (SFT) and zero-shot classification tasks across 8\ndatasets, reveal its exceptional performance for skin diseases in comparison to\nboth general and medical VLM models. The introduction of MM-Skin and SkinVL\noffers a meaningful contribution to advancing the development of clinical\ndermatology VLM assistants. MM-Skin is available at\nhttps://github.com/ZwQ803/MM-Skin",
      "tldr_zh": "该论文提出 MM-Skin，这是一个首个大规模多模态皮肤病数据集，从专业教科书收集近 10k 高质量图像-文本对，并涵盖临床、皮镜和病理三种图像模态，同时生成了超过 27k 多样化的 VQA 样本，以解决当前皮肤病 VLM 缺乏专业描述的问题。基于 MM-Skin 和公共数据集，研究者开发了 SkinVL，一种专为皮肤病设计的 VLM，用于精确的疾病解读。在 VQA、SFT 和零样本分类任务的基准评估中，SkinVL 在 8 个数据集上表现出色，优于通用和医疗 VLM 模型，为临床皮肤病 VLM 助手的开发提供了重要贡献。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06152v1",
      "published_date": "2025-05-09 16:03:47 UTC",
      "updated_date": "2025-05-09 16:03:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:19:10.034833"
    },
    {
      "arxiv_id": "2505.06150v1",
      "title": "A Scaling Law for Token Efficiency in LLM Fine-Tuning Under Fixed Compute Budgets",
      "title_zh": "翻译失败",
      "authors": [
        "Ryan Lagasse",
        "Aidan Kiernans",
        "Avijit Ghosh",
        "Shiri Dori-Hacohen"
      ],
      "abstract": "We introduce a scaling law for fine-tuning large language models (LLMs) under\nfixed compute budgets that explicitly accounts for data composition.\nConventional approaches measure training data solely by total tokens, yet the\nnumber of examples and their average token length -- what we term \\emph{dataset\nvolume} -- play a decisive role in model performance. Our formulation is tuned\nfollowing established procedures. Experiments on the BRICC dataset\n\\cite{salavati2024reducing} and subsets of the MMLU dataset\n\\cite{hendrycks2021measuringmassivemultitasklanguage}, evaluated under multiple\nsubsampling strategies, reveal that data composition significantly affects\ntoken efficiency. These results motivate refined scaling laws for practical LLM\nfine-tuning in resource-constrained settings.",
      "tldr_zh": "本研究提出了一种缩放定律（scaling law），用于在固定计算预算下微调大型语言模型（LLMs），该定律首次明确考虑数据组成，包括例子数量和平均token长度（dataset volume），而非仅依赖总token数。实验在BRICC数据集和MMLU数据集的子集上，通过多种子采样策略进行验证，结果显示数据组成对token效率有显著影响。最终，这为资源受限场景下的LLMs微调提供了更精确的指导，帮助优化模型性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06150v1",
      "published_date": "2025-05-09 16:02:23 UTC",
      "updated_date": "2025-05-09 16:02:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:19:19.849204"
    },
    {
      "arxiv_id": "2505.06331v1",
      "title": "Mask-PINNs: Regulating Feature Distributions in Physics-Informed Neural Networks",
      "title_zh": "Mask-PINNs：在物理信息神经网络中调节特征分布",
      "authors": [
        "Feilong Jiang",
        "Xiaonan Hou",
        "Jianqiao Ye",
        "Min Xia"
      ],
      "abstract": "Physics-Informed Neural Networks (PINNs) are a class of deep learning models\ndesigned to solve partial differential equations by incorporating physical laws\ndirectly into the loss function. However, the internal covariate shift, which\nhas been largely overlooked, hinders the effective utilization of neural\nnetwork capacity in PINNs. To this end, we propose Mask-PINNs, a novel\narchitecture designed to address this issue in PINNs. Unlike traditional\nnormalization methods such as BatchNorm or LayerNorm, we introduce a learnable,\nnonlinear mask function that constrains the feature distributions without\nviolating underlying physics. The experimental results show that the proposed\nmethod significantly improves feature distribution stability, accuracy, and\nrobustness across various activation functions and PDE benchmarks. Furthermore,\nit enables the stable and efficient training of wider networks a capability\nthat has been largely overlooked in PINNs.",
      "tldr_zh": "本研究针对Physics-Informed Neural Networks (PINNs) 中存在的内部协变量偏移问题，提出了一种新架构Mask-PINNs，以优化特征分布。该方法引入一个可学习的非线性掩码函数，来约束特征分布，同时确保不违反底层物理定律，从而避免了传统BatchNorm或LayerNorm的局限。实验结果显示，Mask-PINNs显著提升了特征分布的稳定性、准确性和鲁棒性，在多种激活函数和PDE基准上表现优异，并支持更宽网络的稳定高效训练。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06331v1",
      "published_date": "2025-05-09 15:38:52 UTC",
      "updated_date": "2025-05-09 15:38:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:19:31.004222"
    },
    {
      "arxiv_id": "2505.06330v2",
      "title": "Prompting Large Language Models for Training-Free Non-Intrusive Load Monitoring",
      "title_zh": "翻译失败",
      "authors": [
        "Junyu Xue",
        "Xudong Wang",
        "Xiaoling He",
        "Shicheng Liu",
        "Yi Wang",
        "Guoming Tang"
      ],
      "abstract": "Non-intrusive load monitoring (NILM) aims to disaggregate aggregate household\nelectricity consumption into individual appliance usage and thus enables more\neffective energy management. While deep learning has advanced NILM, it remains\nlimited by its dependence on labeled data, restricted generalization, and lack\nof explainability. This paper introduces the first prompt-based NILM framework\nthat leverages large language models (LLMs) with in-context learning. We design\nand evaluate prompt strategies that integrate appliance features, timestamps\nand contextual information, as well as representative time-series examples on\nwidely used open datasets. With optimized prompts, LLMs achieve competitive\nstate detection accuracy and demonstrate robust generalization without the need\nfor fine-tuning. LLMs also enhance explainability by providing clear,\nhuman-readable explanations for their predictions. Our results show that LLMs\ncan reduce data requirements, improve adaptability, and provide transparent\nenergy disaggregation in NILM applications.",
      "tldr_zh": "本文提出了一种基于提示的大型语言模型(LLMs)框架，用于训练-free 非入侵式负载监测(NILM)，旨在解决传统深度学习方法依赖标注数据、泛化能力弱和缺乏可解释性的问题。通过设计整合家电特征、时间戳、上下文信息以及代表性时间序列的提示策略，LLMs 利用 in-context learning 在开源数据集上实现了竞争性的设备状态检测准确率。结果表明，该框架无需微调即可提升泛化能力，提供清晰的人类可读解释，并显著减少数据需求，从而提升 NILM 在能源管理中的适应性和透明度。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06330v2",
      "published_date": "2025-05-09 15:35:11 UTC",
      "updated_date": "2025-05-20 12:43:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:19:44.415644"
    },
    {
      "arxiv_id": "2505.06123v1",
      "title": "Wasserstein Distances Made Explainable: Insights into Dataset Shifts and Transport Phenomena",
      "title_zh": "翻译失败",
      "authors": [
        "Philip Naumann",
        "Jacob Kauffmann",
        "Grégoire Montavon"
      ],
      "abstract": "Wasserstein distances provide a powerful framework for comparing data\ndistributions. They can be used to analyze processes over time or to detect\ninhomogeneities within data. However, simply calculating the Wasserstein\ndistance or analyzing the corresponding transport map (or coupling) may not be\nsufficient for understanding what factors contribute to a high or low\nWasserstein distance. In this work, we propose a novel solution based on\nExplainable AI that allows us to efficiently and accurately attribute\nWasserstein distances to various data components, including data subgroups,\ninput features, or interpretable subspaces. Our method achieves high accuracy\nacross diverse datasets and Wasserstein distance specifications, and its\npractical utility is demonstrated in two use cases.",
      "tldr_zh": "该研究提出了一种基于 Explainable AI 的新方法，用于对 Wasserstein distances 进行可解释性分析，从而揭示数据分布差异（如数据集偏移）和传输现象背后的关键因素。该方法能够高效准确地将 Wasserstein distances 归因于数据子群、输入特征或可解释子空间，提升了对距离计算的理解。实验结果显示，该方法在多种数据集和 Wasserstein distances 规范下表现出高准确性，并在两个实际用例中证明了其实用价值。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06123v1",
      "published_date": "2025-05-09 15:26:38 UTC",
      "updated_date": "2025-05-09 15:26:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:19:55.012428"
    },
    {
      "arxiv_id": "2505.06118v1",
      "title": "The Application of Deep Learning for Lymph Node Segmentation: A Systematic Review",
      "title_zh": "深度学习在淋巴结分割中的应用：一项系统综述",
      "authors": [
        "Jingguo Qu",
        "Xinyang Han",
        "Man-Lik Chui",
        "Yao Pu",
        "Simon Takadiyi Gunda",
        "Ziman Chen",
        "Jing Qin",
        "Ann Dorothy King",
        "Winnie Chiu-Wing Chu",
        "Jing Cai",
        "Michael Tin-Cheung Ying"
      ],
      "abstract": "Automatic lymph node segmentation is the cornerstone for advances in computer\nvision tasks for early detection and staging of cancer. Traditional\nsegmentation methods are constrained by manual delineation and variability in\noperator proficiency, limiting their ability to achieve high accuracy. The\nintroduction of deep learning technologies offers new possibilities for\nimproving the accuracy of lymph node image analysis. This study evaluates the\napplication of deep learning in lymph node segmentation and discusses the\nmethodologies of various deep learning architectures such as convolutional\nneural networks, encoder-decoder networks, and transformers in analyzing\nmedical imaging data across different modalities. Despite the advancements, it\nstill confronts challenges like the shape diversity of lymph nodes, the\nscarcity of accurately labeled datasets, and the inadequate development of\nmethods that are robust and generalizable across different imaging modalities.\nTo the best of our knowledge, this is the first study that provides a\ncomprehensive overview of the application of deep learning techniques in lymph\nnode segmentation task. Furthermore, this study also explores potential future\nresearch directions, including multimodal fusion techniques, transfer learning,\nand the use of large-scale pre-trained models to overcome current limitations\nwhile enhancing cancer diagnosis and treatment planning strategies.",
      "tldr_zh": "本研究系统综述了深度学习在淋巴结分割中的应用，作为癌症早期检测和分期的核心任务。传统方法受限于手动划分和操作者变异性，准确性不足，而深度学习技术如卷积神经网络(convolutional neural networks)、编码器-解码器网络和Transformer，能显著提升医疗图像分析的精确度。论文评估了这些架构在不同成像模式下的表现，但强调了当前挑战，包括淋巴结形状多样性、标注数据集的稀缺，以及方法的鲁棒性和泛化性不足。作为首个全面概述此领域的系统综述，该研究提出未来方向，如多模态融合(multimodal fusion)、转移学习(transfer learning)和大规模预训练模型，以改善癌症诊断和治疗规划。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06118v1",
      "published_date": "2025-05-09 15:17:00 UTC",
      "updated_date": "2025-05-09 15:17:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:20:08.086185"
    },
    {
      "arxiv_id": "2505.06111v2",
      "title": "UniVLA: Learning to Act Anywhere with Task-centric Latent Actions",
      "title_zh": "UniVLA：通过任务中心潜在动作学习在任意环境行动",
      "authors": [
        "Qingwen Bu",
        "Yanting Yang",
        "Jisong Cai",
        "Shenyuan Gao",
        "Guanghui Ren",
        "Maoqing Yao",
        "Ping Luo",
        "Hongyang Li"
      ],
      "abstract": "A generalist robot should perform effectively across various environments.\nHowever, most existing approaches heavily rely on scaling action-annotated data\nto enhance their capabilities. Consequently, they are often limited to single\nphysical specification and struggle to learn transferable knowledge across\ndifferent embodiments and environments. To confront these limitations, we\npropose UniVLA, a new framework for learning cross-embodiment\nvision-language-action (VLA) policies. Our key innovation is to derive\ntask-centric action representations from videos with a latent action model.\nThis enables us to exploit extensive data across a wide spectrum of embodiments\nand perspectives. To mitigate the effect of task-irrelevant dynamics, we\nincorporate language instructions and establish a latent action model within\nthe DINO feature space. Learned from internet-scale videos, the generalist\npolicy can be deployed to various robots through efficient latent action\ndecoding. We obtain state-of-the-art results across multiple manipulation and\nnavigation benchmarks, as well as real-robot deployments. UniVLA achieves\nsuperior performance over OpenVLA with less than 1/20 of pretraining compute\nand 1/10 of downstream data. Continuous performance improvements are observed\nas heterogeneous data, even including human videos, are incorporated into the\ntraining pipeline. The results underscore UniVLA's potential to facilitate\nscalable and efficient robot policy learning.",
      "tldr_zh": "该研究提出UniVLA框架，用于学习跨实体（embodiments）的vision-language-action (VLA)策略，旨在使机器人能够在各种环境中高效执行任务。UniVLA的关键创新是通过潜在动作模型从视频中衍生任务中心化的动作表示，并整合语言指令和DINO feature space，以减少任务无关动态的影响，从而利用互联网规模的异构数据进行训练。实验结果显示，UniVLA在多个操作和导航基准测试中取得最先进性能，且比OpenVLA使用更少的预训练计算（1/20）和下游数据（1/10），并通过添加人类视频等数据实现持续性能提升，展示了其在可扩展机器人策略学习方面的潜力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted to RSS 2025. Code is available at\n  https://github.com/OpenDriveLab/UniVLA",
      "pdf_url": "http://arxiv.org/pdf/2505.06111v2",
      "published_date": "2025-05-09 15:11:13 UTC",
      "updated_date": "2025-05-15 10:31:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:20:20.157512"
    },
    {
      "arxiv_id": "2505.06110v1",
      "title": "Multimodal Sentiment Analysis on CMU-MOSEI Dataset using Transformer-based Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jugal Gajjar",
        "Kaustik Ranaware"
      ],
      "abstract": "This project performs multimodal sentiment analysis using the CMU-MOSEI\ndataset, using transformer-based models with early fusion to integrate text,\naudio, and visual modalities. We employ BERT-based encoders for each modality,\nextracting embeddings that are concatenated before classification. The model\nachieves strong performance, with 97.87\\% 7-class accuracy and a 0.9682\nF1-score on the test set, demonstrating the effectiveness of early fusion in\ncapturing cross-modal interactions. The training utilized Adam optimization\n(lr=1e-4), dropout (0.3), and early stopping to ensure generalization and\nrobustness. Results highlight the superiority of transformer architectures in\nmodeling multimodal sentiment, with a low MAE (0.1060) indicating precise\nsentiment intensity prediction. Future work may compare fusion strategies or\nenhance interpretability. This approach utilizes multimodal learning by\neffectively combining linguistic, acoustic, and visual cues for sentiment\nanalysis.",
      "tldr_zh": "该研究在 CMU-MOSEI 数据集上使用 Transformer-based 模型进行多模态情感分析，通过 early fusion 整合文本、音频和视觉模态。模型采用 BERT-based 编码器提取各模态嵌入，并将它们拼接后进行分类，训练过程中使用 Adam 优化器（lr=1e-4）、dropout(0.3)和早停以提升泛化性。实验结果显示，模型在测试集上取得了 97.87% 的 7 类准确率、0.9682 的 F1-score 和 0.1060 的 MAE，证明了 early fusion 在捕捉跨模态交互方面的有效性。该方法突出了 Transformer 架构在多模态情感分析中的优势，并建议未来工作比较融合策略或增强模型可解释性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages, 2 figures, 5 tables, and 19 references",
      "pdf_url": "http://arxiv.org/pdf/2505.06110v1",
      "published_date": "2025-05-09 15:10:57 UTC",
      "updated_date": "2025-05-09 15:10:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:20:33.892533"
    },
    {
      "arxiv_id": "2505.08800v1",
      "title": "Graph-based Online Monitoring of Train Driver States via Facial and Skeletal Features",
      "title_zh": "翻译失败",
      "authors": [
        "Olivia Nocentini",
        "Marta Lagomarsino",
        "Gokhan Solak",
        "Younggeol Cho",
        "Qiyi Tong",
        "Marta Lorenzini",
        "Arash Ajoudani"
      ],
      "abstract": "Driver fatigue poses a significant challenge to railway safety, with\ntraditional systems like the dead-man switch offering limited and basic\nalertness checks. This study presents an online behavior-based monitoring\nsystem utilizing a customised Directed-Graph Neural Network (DGNN) to classify\ntrain driver's states into three categories: alert, not alert, and\npathological. To optimize input representations for the model, an ablation\nstudy was performed, comparing three feature configurations: skeletal-only,\nfacial-only, and a combination of both. Experimental results show that\ncombining facial and skeletal features yields the highest accuracy (80.88%) in\nthe three-class model, outperforming models using only facial or skeletal\nfeatures. Furthermore, this combination achieves over 99% accuracy in the\nbinary alertness classification. Additionally, we introduced a novel dataset\nthat, for the first time, incorporates simulated pathological conditions into\ntrain driver monitoring, broadening the scope for assessing risks related to\nfatigue and health. This work represents a step forward in enhancing railway\nsafety through advanced online monitoring using vision-based technologies.",
      "tldr_zh": "该研究针对司机疲劳对铁路安全的威胁，提出了一种基于 Directed-Graph Neural Network (DGNN) 的在线监控系统，用于将火车司机状态分类为警觉、不警觉和病理状态。研究通过消融实验比较了骨骼特征、面部特征以及二者结合的输入表示，结果显示结合面部和骨骼特征的模型在三分类任务中达到最高准确率（80.88%），而在二分类警觉性任务中超过99%。此外，团队引入了一个新数据集，首次纳入模拟病理条件，以扩展对疲劳和健康风险的评估。该系统代表了利用视觉技术提升铁路安全的显著进步。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08800v1",
      "published_date": "2025-05-09 15:06:19 UTC",
      "updated_date": "2025-05-09 15:06:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:20:50.248898"
    },
    {
      "arxiv_id": "2505.06108v3",
      "title": "LLMs Outperform Experts on Challenging Biology Benchmarks",
      "title_zh": "大语言模型在挑战性的生物学",
      "authors": [
        "Lennart Justen"
      ],
      "abstract": "This study systematically evaluates 27 frontier Large Language Models on\neight biology benchmarks spanning molecular biology, genetics, cloning,\nvirology, and biosecurity. Models from major AI developers released between\nNovember 2022 and April 2025 were assessed through ten independent runs per\nbenchmark. The findings reveal dramatic improvements in biological\ncapabilities. Top model performance increased more than 4-fold on the\nchallenging text-only subset of the Virology Capabilities Test over the study\nperiod, with OpenAI's o3 now performing twice as well as expert virologists.\nSeveral models now match or exceed expert-level performance on other\nchallenging benchmarks, including the biology subsets of GPQA and WMDP and\nLAB-Bench CloningScenarios. Contrary to expectations, chain-of-thought did not\nsubstantially improve performance over zero-shot evaluation, while extended\nreasoning features in o3-mini and Claude 3.7 Sonnet typically improved\nperformance as predicted by inference scaling. Benchmarks such as PubMedQA and\nthe MMLU and WMDP biology subsets exhibited performance plateaus well below\n100%, suggesting benchmark saturation and errors in the underlying benchmark\ndata. The analysis highlights the need for more sophisticated evaluation\nmethodologies as AI systems continue to advance.",
      "tldr_zh": "本研究评估了27个前沿大型语言模型（LLMs）在八个生物学基准上的表现，包括分子生物学、遗传学、克隆、病毒学和生物安全，涵盖了2022年11月至2025年4月发布的模型。结果显示，顶级模型性能大幅提升，例如在Virology Capabilities Test的文本子集中提高了4倍以上，OpenAI的o3模型甚至超过了专家病毒学家的水平，并在GPQA、WMDP和LAB-Bench CloningScenarios等基准上达到或超越专家表现。意外的是，chain-of-thought推理并未显著改善zero-shot评估，而扩展推理功能如o3-mini和Claude 3.7 Sonnet则有效提升了性能；然而，一些基准如PubMedQA和MMLU生物子集存在饱和和数据错误问题，强调了需要更先进的评估方法来跟踪AI系统的进步。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06108v3",
      "published_date": "2025-05-09 15:05:57 UTC",
      "updated_date": "2025-05-21 20:34:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:20:57.529726"
    },
    {
      "arxiv_id": "2505.06096v1",
      "title": "Free and Fair Hardware: A Pathway to Copyright Infringement-Free Verilog Generation using LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Sam Bush",
        "Matthew DeLorenzo",
        "Phat Tieu",
        "Jeyavijayan Rajendran"
      ],
      "abstract": "Limitations in Large Language Model (LLM) capabilities for hardware design\ntasks, such as generating functional Verilog codes, have motivated various\nfine-tuning optimizations utilizing curated hardware datasets from open-source\nrepositories. However, these datasets remain limited in size and contain\nminimal checks on licensing for reuse, resulting in potential copyright\nviolations by fine-tuned LLMs. Therefore, we propose an evaluation benchmark to\nestimate the risk of Verilog-trained LLMs to generate copyright-protected\ncodes. To minimize this risk, we present an open-source Verilog dataset,\nFreeSet, containing over 220k files, along with the automated dataset curation\nframework utilized to provide additional guarantees of fair-use Verilog data.\nWe then execute an LLM fine-tuning framework consisting of continual\npre-training, resulting in a fine-tuned Llama model for Verilog, FreeV. Our\nresults indicate that FreeV demonstrates the smallest risk of\ncopyright-infringement among prior works, with only a 3% violation rate.\nFurthermore, experimental results demonstrate improvements in Verilog\ngeneration functionality over its baseline model, improving VerilogEval pass@10\nrates by over 10%.",
      "tldr_zh": "这篇论文针对大型语言模型(LLM)在生成Verilog代码时可能侵犯版权的问题，提出一个评估基准来估算风险，并创建了一个开源数据集FreeSet，包含超过22万文件及其自动整理框架，以确保数据符合公平使用标准。作者随后通过持续预训练微调Llama模型，开发出FreeV模型，结果显示FreeV的版权侵犯率仅为3%，显著低于现有工作。实验证明，FreeV在Verilog代码生成功能上取得了改进，提升了VerilogEval的pass@10率超过10%。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at DAC 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.06096v1",
      "published_date": "2025-05-09 14:44:07 UTC",
      "updated_date": "2025-05-09 14:44:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:21:09.175193"
    },
    {
      "arxiv_id": "2505.06091v1",
      "title": "UniSymNet: A Unified Symbolic Network Guided by Transformer",
      "title_zh": "UniSymNet：基于 Transformer 的统一符号网络",
      "authors": [
        "Xinxin Li",
        "Juan Zhang",
        "Da Li",
        "Xingyu Liu",
        "Jin Xu",
        "Junping Yin"
      ],
      "abstract": "Symbolic Regression (SR) is a powerful technique for automatically\ndiscovering mathematical expressions from input data. Mainstream SR algorithms\nsearch for the optimal symbolic tree in a vast function space, but the\nincreasing complexity of the tree structure limits their performance. Inspired\nby neural networks, symbolic networks have emerged as a promising new paradigm.\nHowever, most existing symbolic networks still face certain challenges: binary\nnonlinear operators $\\{\\times, \\div\\}$ cannot be naturally extended to\nmultivariate operators, and training with fixed architecture often leads to\nhigher complexity and overfitting. In this work, we propose a Unified Symbolic\nNetwork that unifies nonlinear binary operators into nested unary operators and\ndefine the conditions under which UniSymNet can reduce complexity. Moreover, we\npre-train a Transformer model with a novel label encoding method to guide\nstructural selection, and adopt objective-specific optimization strategies to\nlearn the parameters of the symbolic network. UniSymNet shows high fitting\naccuracy, excellent symbolic solution rate, and relatively low expression\ncomplexity, achieving competitive performance on low-dimensional Standard\nBenchmarks and high-dimensional SRBench.",
      "tldr_zh": "该论文针对 Symbolic Regression (SR) 的复杂度问题，提出了一种统一的符号网络 UniSymNet，将二元非线性运算符（如 × 和 ÷）转化为嵌套一元运算符，并定义了减少表达式复杂度的条件。UniSymNet 通过预训练 Transformer 模型和创新的标签编码方法来指导网络结构选择，并采用特定目标的优化策略学习参数。实验结果显示，该方法在低维 Standard Benchmarks 和高维 SRBench 上实现了高拟合准确率、优秀的符号解决方案率以及较低的表达式复杂度，展现出竞争力的性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06091v1",
      "published_date": "2025-05-09 14:38:25 UTC",
      "updated_date": "2025-05-09 14:38:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:21:20.563025"
    },
    {
      "arxiv_id": "2505.06085v2",
      "title": "Assessing Tenstorrent's RISC-V MatMul Acceleration Capabilities",
      "title_zh": "翻译失败",
      "authors": [
        "Hiari Pizzini Cavagna",
        "Daniele Cesarini",
        "Andrea Bartolini"
      ],
      "abstract": "The increasing demand for generative AI as Large Language Models (LLMs)\nservices has driven the need for specialized hardware architectures that\noptimize computational efficiency and energy consumption. This paper evaluates\nthe performance of the Tenstorrent Grayskull e75 RISC-V accelerator for basic\nlinear algebra kernels at reduced numerical precision, a fundamental operation\nin LLM computations. We present a detailed characterization of Grayskull's\nexecution model, gridsize, matrix dimensions, data formats, and numerical\nprecision impact computational efficiency. Furthermore, we compare Grayskull's\nperformance against state-of-the-art architectures with tensor acceleration,\nincluding Intel Sapphire Rapids processors and two NVIDIA GPUs (V100 and A100).\nWhilst NVIDIA GPUs dominate raw performance, Grayskull demonstrates a\ncompetitive trade-off between power consumption and computational throughput,\nreaching a peak of 1.55 TFLOPs/Watt with BF16.",
      "tldr_zh": "该论文评估了 Tenstorrent Grayskull e75 RISC-V 加速器在低精度矩阵乘法(MatMul)操作上的性能，这是 Large Language Models (LLMs) 计算的核心。研究通过详细表征其执行模型、网格大小、矩阵维度、数据格式和数值精度，分析了这些因素对计算效率的影响，并与 Intel Sapphire Rapids 处理器以及 NVIDIA V100 和 A100 GPU 进行了比较。尽管 NVIDIA GPU 在原始性能上领先，Grayskull 展示了出色的功耗效率，达到峰值 1.55 TFLOPs/Watt 的性能。整体结果突显了 RISC-V 架构在优化计算吞吐量和能效方面的竞争潜力。",
      "categories": [
        "cs.PF",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.PF",
      "comment": "Accepted to the Computational Aspects of Deep Learning Workshop at\n  ISC High Performance 2025. To appear in the ISC High Performance 2025\n  Workshop Proceedings",
      "pdf_url": "http://arxiv.org/pdf/2505.06085v2",
      "published_date": "2025-05-09 14:29:37 UTC",
      "updated_date": "2025-05-15 13:07:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:21:31.076300"
    },
    {
      "arxiv_id": "2505.06049v1",
      "title": "Seqret: Mining Rule Sets from Event Sequences",
      "title_zh": "Seqret: 从事件序列中挖掘规则集",
      "authors": [
        "Aleena Siji",
        "Joscha Cüppers",
        "Osman Ali Mian",
        "Jilles Vreeken"
      ],
      "abstract": "Summarizing event sequences is a key aspect of data mining. Most existing\nmethods neglect conditional dependencies and focus on discovering sequential\npatterns only. In this paper, we study the problem of discovering both\nconditional and unconditional dependencies from event sequence data. We do so\nby discovering rules of the form $X \\rightarrow Y$ where $X$ and $Y$ are\nsequential patterns. Rules like these are simple to understand and provide a\nclear description of the relation between the antecedent and the consequent. To\ndiscover succinct and non-redundant sets of rules we formalize the problem in\nterms of the Minimum Description Length principle. As the search space is\nenormous and does not exhibit helpful structure, we propose the Seqret method\nto discover high-quality rule sets in practice. Through extensive empirical\nevaluation we show that unlike the state of the art, Seqret ably recovers the\nground truth on synthetic datasets and finds useful rules from real datasets.",
      "tldr_zh": "本文提出Seqret方法，用于从事件序列数据中挖掘规则集，旨在发现条件和无条件依赖，而非仅限于sequential patterns。规则形式为$X \\rightarrow Y$，其中X和Y是sequential patterns，这些规则易于理解并清晰描述前件与后件的关联。Seqret基于Minimum Description Length (MDL)原则形式化问题，生成简洁非冗余的规则集；实验结果显示，该方法在合成数据集上能恢复ground truth，在真实数据集上发现有用规则，并显著优于现有技术。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06049v1",
      "published_date": "2025-05-09 13:44:15 UTC",
      "updated_date": "2025-05-09 13:44:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:21:43.921806"
    },
    {
      "arxiv_id": "2505.06047v1",
      "title": "PYRREGULAR: A Unified Framework for Irregular Time Series, with Classification Benchmarks",
      "title_zh": "翻译失败",
      "authors": [
        "Francesco Spinnato",
        "Cristiano Landi"
      ],
      "abstract": "Irregular temporal data, characterized by varying recording frequencies,\ndiffering observation durations, and missing values, presents significant\nchallenges across fields like mobility, healthcare, and environmental science.\nExisting research communities often overlook or address these challenges in\nisolation, leading to fragmented tools and methods. To bridge this gap, we\nintroduce a unified framework, and the first standardized dataset repository\nfor irregular time series classification, built on a common array format to\nenhance interoperability. This repository comprises 34 datasets on which we\nbenchmark 12 classifier models from diverse domains and communities. This work\naims to centralize research efforts and enable a more robust evaluation of\nirregular temporal data analysis methods.",
      "tldr_zh": "该论文针对irregular time series数据（如变化记录频率、不同观察持续时间和缺失值）的挑战，提出一个统一框架和首个标准化数据集仓库，以通用数组格式提升数据互操作性。该仓库包含34个数据集，并对12个来自不同领域的分类器模型进行基准测试，旨在整合碎片化的研究工具和方法。通过这项工作，研究者可以实现更稳健的irregular time series分析方法评估。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06047v1",
      "published_date": "2025-05-09 13:43:43 UTC",
      "updated_date": "2025-05-09 13:43:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:21:55.425044"
    },
    {
      "arxiv_id": "2505.06030v1",
      "title": "Why Are You Wrong? Counterfactual Explanations for Language Grounding with 3D Objects",
      "title_zh": "翻译失败",
      "authors": [
        "Tobias Preintner",
        "Weixuan Yuan",
        "Qi Huang",
        "Adrian König",
        "Thomas Bäck",
        "Elena Raponi",
        "Niki van Stein"
      ],
      "abstract": "Combining natural language and geometric shapes is an emerging research area\nwith multiple applications in robotics and language-assisted design. A crucial\ntask in this domain is object referent identification, which involves selecting\na 3D object given a textual description of the target. Variability in language\ndescriptions and spatial relationships of 3D objects makes this a complex task,\nincreasing the need to better understand the behavior of neural network models\nin this domain. However, limited research has been conducted in this area.\nSpecifically, when a model makes an incorrect prediction despite being provided\nwith a seemingly correct object description, practitioners are left wondering:\n\"Why is the model wrong?\". In this work, we present a method answering this\nquestion by generating counterfactual examples. Our method takes a\nmisclassified sample, which includes two objects and a text description, and\ngenerates an alternative yet similar formulation that would have resulted in a\ncorrect prediction by the model. We have evaluated our approach with data from\nthe ShapeTalk dataset along with three distinct models. Our counterfactual\nexamples maintain the structure of the original description, are semantically\nsimilar and meaningful. They reveal weaknesses in the description, model bias\nand enhance the understanding of the models behavior. Theses insights help\npractitioners to better interact with systems as well as engineers to improve\nmodels.",
      "tldr_zh": "这篇论文探讨了语言 grounding 与 3D 对象相结合的领域，焦点在于对象参照物识别任务，即通过文本描述选择正确3D对象时模型的错误原因。作者提出了一种生成反事实例子（counterfactual examples）的方法：针对误分类样本（包括两个对象和文本描述），创建语义相似且结构保持的替代描述，以揭示模型为什么出错。实验在ShapeTalk数据集上使用三个不同模型进行评估，结果显示这些反事实例子能暴露模型偏差、描述弱点，并帮助实践者和工程师提升模型理解和改进性能。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at IJCNN 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.06030v1",
      "published_date": "2025-05-09 13:24:44 UTC",
      "updated_date": "2025-05-09 13:24:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:22:08.310741"
    },
    {
      "arxiv_id": "2505.06023v1",
      "title": "Universal Approximation Theorem for Deep Q-Learning via FBSDE System",
      "title_zh": "翻译失败",
      "authors": [
        "Qian Qi"
      ],
      "abstract": "The approximation capabilities of Deep Q-Networks (DQNs) are commonly\njustified by general Universal Approximation Theorems (UATs) that do not\nleverage the intrinsic structural properties of the optimal Q-function, the\nsolution to a Bellman equation. This paper establishes a UAT for a class of\nDQNs whose architecture is designed to emulate the iterative refinement process\ninherent in Bellman updates. A central element of our analysis is the\npropagation of regularity: while the transformation induced by a single Bellman\noperator application exhibits regularity, for which Backward Stochastic\nDifferential Equations (BSDEs) theory provides analytical tools, the uniform\nregularity of the entire sequence of value iteration iterates--specifically,\ntheir uniform Lipschitz continuity on compact domains under standard Lipschitz\nassumptions on the problem data--is derived from finite-horizon dynamic\nprogramming principles. We demonstrate that layers of a deep residual network,\nconceived as neural operators acting on function spaces, can approximate the\naction of the Bellman operator. The resulting approximation theorem is thus\nintrinsically linked to the control problem's structure, offering a proof\ntechnique wherein network depth directly corresponds to iterations of value\nfunction refinement, accompanied by controlled error propagation. This\nperspective reveals a dynamic systems view of the network's operation on a\nspace of value functions.",
      "tldr_zh": "这篇论文建立了针对Deep Q-Learning的Universal Approximation Theorem (UAT)，通过Backward Stochastic Differential Equations (BSDEs)系统，利用Bellman方程的内在结构特性，证明了特定DQNs架构的近似能力。论文的核心方法是设计DQNs来模拟Bellman更新的迭代精炼过程，并分析价值迭代序列的统一正则性，特别是其Lipschitz连续性。结果显示，深层残差网络的层可以有效近似Bellman操作符，使网络深度直接对应于价值函数的迭代精炼，并实现可控的错误传播，从而提供了一个动态系统视角。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06023v1",
      "published_date": "2025-05-09 13:11:55 UTC",
      "updated_date": "2025-05-09 13:11:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:22:20.370386"
    },
    {
      "arxiv_id": "2505.06020v1",
      "title": "ArtRAG: Retrieval-Augmented Generation with Structured Context for Visual Art Understanding",
      "title_zh": "ArtRAG：带有结构化上下文的检索增强生成用于视觉艺术理解",
      "authors": [
        "Shuai Wang",
        "Ivona Najdenkoska",
        "Hongyi Zhu",
        "Stevan Rudinac",
        "Monika Kackovic",
        "Nachoem Wijnberg",
        "Marcel Worring"
      ],
      "abstract": "Understanding visual art requires reasoning across multiple perspectives --\ncultural, historical, and stylistic -- beyond mere object recognition. While\nrecent multimodal large language models (MLLMs) perform well on general image\ncaptioning, they often fail to capture the nuanced interpretations that fine\nart demands. We propose ArtRAG, a novel, training-free framework that combines\nstructured knowledge with retrieval-augmented generation (RAG) for\nmulti-perspective artwork explanation. ArtRAG automatically constructs an Art\nContext Knowledge Graph (ACKG) from domain-specific textual sources, organizing\nentities such as artists, movements, themes, and historical events into a rich,\ninterpretable graph. At inference time, a multi-granular structured retriever\nselects semantically and topologically relevant subgraphs to guide generation.\nThis enables MLLMs to produce contextually grounded, culturally informed art\ndescriptions. Experiments on the SemArt and Artpedia datasets show that ArtRAG\noutperforms several heavily trained baselines. Human evaluations further\nconfirm that ArtRAG generates coherent, insightful, and culturally enriched\ninterpretations.",
      "tldr_zh": "该论文提出ArtRAG，一种无需训练的框架，结合结构化知识和Retrieval-Augmented Generation (RAG)，旨在提升视觉艺术理解的多视角解读，如文化、历史和风格层面。ArtRAG自动构建Art Context Knowledge Graph (ACKG)从领域特定文本中组织实体（如艺术家、运动、主题和历史事件），并使用多粒度结构化检索器选择相关子图来指导多模态大语言模型(MLLMs)的生成过程。实验结果显示，ArtRAG在SemArt和Artpedia数据集上优于多个经过重度训练的基线模型，且人类评估确认其生成的艺术描述连贯、富有洞见并融入文化元素。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06020v1",
      "published_date": "2025-05-09 13:08:27 UTC",
      "updated_date": "2025-05-09 13:08:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:22:33.067162"
    },
    {
      "arxiv_id": "2505.05988v1",
      "title": "Minimal Sequent Calculus for Teaching First-Order Logic: Lessons Learned",
      "title_zh": "翻译失败",
      "authors": [
        "Jørgen Villadsen"
      ],
      "abstract": "MiniCalc is a web app for teaching first-order logic based on a minimal\nsequent calculus. As an option the proofs can be verified in the Isabelle proof\nassistant. We present the lessons learned using the tool in recent years at our\nuniversity.",
      "tldr_zh": "这篇论文介绍了MiniCalc，一个基于minimal sequent calculus的网页应用，用于教学first-order logic。该工具允许用户在Isabelle proof assistant中验证证明，从而增强学习过程的准确性和可靠性。作者总结了在过去几年中在大学使用该工具的经验教训，包括其优势和潜在改进点。",
      "categories": [
        "cs.LO",
        "cs.AI",
        "F.4; I.2.3; K.3.1"
      ],
      "primary_category": "cs.LO",
      "comment": "In Proceedings ThEdu24, arXiv:2505.04677",
      "pdf_url": "http://arxiv.org/pdf/2505.05988v1",
      "published_date": "2025-05-09 12:18:17 UTC",
      "updated_date": "2025-05-09 12:18:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:22:42.153162"
    },
    {
      "arxiv_id": "2505.05976v1",
      "title": "Pseudo-Boolean d-DNNF Compilation for Expressive Feature Modeling Constructs",
      "title_zh": "翻译失败",
      "authors": [
        "Chico Sundermann",
        "Stefan Vill",
        "Elias Kuiter",
        "Sebastian Krieter",
        "Thomas Thüm",
        "Matthias Tichy"
      ],
      "abstract": "Configurable systems typically consist of reusable assets that have\ndependencies between each other. To specify such dependencies, feature models\nare commonly used. As feature models in practice are often complex, automated\nreasoning is typically employed to analyze the dependencies. Here, the de facto\nstandard is translating the feature model to conjunctive normal form (CNF) to\nenable employing off-the-shelf tools, such as SAT or #SAT solvers. However,\nmodern feature-modeling dialects often contain constructs, such as cardinality\nconstraints, that are ill-suited for conversion to CNF. This mismatch between\nthe input of reasoning engines and the available feature-modeling dialects\nlimits the applicability of the more expressive constructs. In this work, we\nshorten this gap between expressive constructs and scalable automated\nreasoning. Our contribution is twofold: First, we provide a pseudo-Boolean\nencoding for feature models, which facilitates smaller representations of\ncommonly employed constructs compared to Boolean encoding. Second, we propose a\nnovel method to compile pseudo-Boolean formulas to Boolean d-DNNF. With the\ncompiled d-DNNFs, we can resort to a plethora of efficient analyses already\nused in feature modeling. Our empirical evaluation shows that our proposal\nsubstantially outperforms the state-of-the-art based on CNF inputs for\nexpressive constructs. For every considered dataset representing different\nfeature models and feature-modeling constructs, the feature models can be\nsignificantly faster translated to pseudo-Boolean than to CNF. Overall,\nderiving d-DNNFs from a feature model with the targeted expressive constraints\ncan be substantially accelerated using our pseudo-Boolean approach.\nFurthermore, our approach is competitive on feature models with only basic\nconstructs.",
      "tldr_zh": "本文提出了一种针对表现力强的特征建模结构的伪布尔（Pseudo-Boolean）编码和 d-DNNF 编译方法，以解决传统特征模型转换为 CNF（Conjunctive Normal Form）的局限性，这些局限性在处理基数约束等复杂结构时效率低下。主要贡献包括：提供伪布尔编码，使常用结构的表示更紧凑；并开发一种新方法，将伪布尔公式编译为布尔 d-DNNF，从而支持高效的特征模型分析。实验结果显示，该方法在多种数据集上显著优于基于 CNF 的状态艺术方法，特征模型的转换速度更快，尤其在包含表现力强约束的场景中表现出色；即使在仅使用基本结构的模型上，该方法也保持竞争力。",
      "categories": [
        "cs.AI",
        "cs.LO",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05976v1",
      "published_date": "2025-05-09 12:00:43 UTC",
      "updated_date": "2025-05-09 12:00:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:22:56.685968"
    },
    {
      "arxiv_id": "2505.05965v1",
      "title": "A Noise-Resilient Semi-Supervised Graph Autoencoder for Overlapping Semantic Community Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Abdelfateh Bekkair",
        "Slimane Bellaouar",
        "Slimane Oulad-Naoui"
      ],
      "abstract": "Community detection in networks with overlapping structures remains a\nsignificant challenge, particularly in noisy real-world environments where\nintegrating topology, node attributes, and prior information is critical. To\naddress this, we propose a semi-supervised graph autoencoder that combines\ngraph multi-head attention and modularity maximization to robustly detect\noverlapping communities. The model learns semantic representations by fusing\nstructural, attribute, and prior knowledge while explicitly addressing noise in\nnode features. Key innovations include a noise-resistant architecture and a\nsemantic semi-supervised design optimized for community quality through\nmodularity constraints. Experiments demonstrate superior performance the model\noutperforms state-of-the-art methods in overlapping community detection\n(improvements in NMI and F1-score) and exhibits exceptional robustness to\nattribute noise, maintaining stable performance under 60\\% feature corruption.\nThese results highlight the importance of integrating attribute semantics and\nstructural patterns for accurate community discovery in complex networks.",
      "tldr_zh": "本研究针对网络中重叠结构社区检测的挑战，特别是在嘈杂环境中整合拓扑、节点属性和先验信息的问题，提出了一种噪声抵抗的半监督图自编码器(semi-supervised graph autoencoder)。该模型通过结合图多头注意力(graph multi-head attention)和模块度最大化(modularity maximization)，融合结构、属性和先验知识来学习语义表示，同时采用噪声抵抗架构(noise-resistant architecture)和语义半监督设计来优化社区质量。实验结果显示，该模型在重叠社区检测中优于现有方法，显著提升了NMI和F1-score指标，并在60%特征损坏下保持稳定性能。这些发现强调了整合属性语义和结构模式对复杂网络中准确社区发现的重要性。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05965v1",
      "published_date": "2025-05-09 11:34:07 UTC",
      "updated_date": "2025-05-09 11:34:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:23:08.483604"
    },
    {
      "arxiv_id": "2505.05946v1",
      "title": "Elastic Weight Consolidation for Full-Parameter Continual Pre-Training of Gemma2",
      "title_zh": "翻译失败",
      "authors": [
        "Vytenis Šliogeris",
        "Povilas Daniušis",
        "Artūras Nakvosas"
      ],
      "abstract": "This technical report describes an experiment on autoregressive pre-training\nof Gemma2 2 billion parameter large language model (LLM) with 10\\% on the\nLithuanian language component of CulturaX from the point of view of continual\nlearning. We apply elastic weight consolidation (EWC) to the full set of the\nmodel's parameters and investigate language understanding benchmarks,\nconsisting of Arc, Belebele, Gsm8K, Hellaswag, MMLU, TruthfulQA, and Winogrande\nsets (both in English and Lithuanian versions), and perplexity benchmarks. We\nempirically demonstrate that EWC regularisation allows us not only to mitigate\ncatastrophic forgetting effects but also that it is potentially beneficial for\nlearning of the new task with LLMs.",
      "tldr_zh": "本研究探讨了使用Elastic Weight Consolidation (EWC) 对Gemma2（一个20亿参数的语言模型）进行全参数持续预训练，焦点是整合Lithuanian语言的10% CulturaX数据集，以缓解灾难性遗忘问题。实验评估了多种语言理解基准（如ARC、Belebele、Gsm8K、Hellaswag、MMLU、TruthfulQA和Winogrande），包括英文和Lithuanian版本，以及困惑度指标。结果显示，EWC不仅有效减轻了遗忘效应，还可能增强模型在新任务上的学习能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.05946v1",
      "published_date": "2025-05-09 10:43:37 UTC",
      "updated_date": "2025-05-09 10:43:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:23:20.312224"
    },
    {
      "arxiv_id": "2505.05943v1",
      "title": "Achieving 3D Attention via Triplet Squeeze and Excitation Block",
      "title_zh": "翻译失败",
      "authors": [
        "Maan Alhazmi",
        "Abdulrahman Altahhan"
      ],
      "abstract": "The emergence of ConvNeXt and its variants has reaffirmed the conceptual and\nstructural suitability of CNN-based models for vision tasks, re-establishing\nthem as key players in image classification in general, and in facial\nexpression recognition (FER) in particular. In this paper, we propose a new set\nof models that build on these advancements by incorporating a new set of\nattention mechanisms that combines Triplet attention with\nSqueeze-and-Excitation (TripSE) in four different variants. We demonstrate the\neffectiveness of these variants by applying them to the ResNet18, DenseNet and\nConvNext architectures to validate their versatility and impact. Our study\nshows that incorporating a TripSE block in these CNN models boosts their\nperformances, particularly for the ConvNeXt architecture, indicating its\nutility. We evaluate the proposed mechanisms and associated models across four\ndatasets, namely CIFAR100, ImageNet, FER2013 and AffectNet datasets, where\nConvNext with TripSE achieves state-of-the-art results with an accuracy of\n\\textbf{78.27\\%} on the popular FER2013 dataset, a new feat for this dataset.",
      "tldr_zh": "本论文提出了一种新的注意力机制 TripSE，将 Triplet attention 与 Squeeze-and-Excitation 结合，创建四个变体，以提升 CNN 模型在视觉任务中的性能。该机制被应用于 ResNet18、DenseNet 和 ConvNext 架构中，验证了其通用性和有效性，尤其在 ConvNext 上显著提高了模型表现。在 CIFAR100、ImageNet、FER2013 和 AffectNet 数据集上进行评估后，ConvNext with TripSE 在 FER2013 数据集上达到了 78.27% 的准确率，实现了该数据集的 state-of-the-art 水平。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05943v1",
      "published_date": "2025-05-09 10:36:30 UTC",
      "updated_date": "2025-05-09 10:36:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:23:32.636694"
    },
    {
      "arxiv_id": "2505.06328v1",
      "title": "A Grounded Memory System For Smart Personal Assistants",
      "title_zh": "翻译失败",
      "authors": [
        "Felix Ocker",
        "Jörg Deigmöller",
        "Pavel Smirnov",
        "Julian Eggert"
      ],
      "abstract": "A wide variety of agentic AI applications - ranging from cognitive assistants\nfor dementia patients to robotics - demand a robust memory system grounded in\nreality. In this paper, we propose such a memory system consisting of three\ncomponents. First, we combine Vision Language Models for image captioning and\nentity disambiguation with Large Language Models for consistent information\nextraction during perception. Second, the extracted information is represented\nin a memory consisting of a knowledge graph enhanced by vector embeddings to\nefficiently manage relational information. Third, we combine semantic search\nand graph query generation for question answering via Retrieval Augmented\nGeneration. We illustrate the system's working and potential using a real-world\nexample.",
      "tldr_zh": "该论文提出了一种基于现实的记忆系统，用于智能个人助手的AI应用，如认知助手和机器人，以确保记忆的稳健性。该系统由三个组件组成：首先，使用Vision Language Models (VLMs) 进行图像描述和实体消歧，并结合Large Language Models (LLMs) 实现一致的信息提取；其次，将提取的信息存储在由知识图谱和向量嵌入增强的记忆中，以高效管理关系数据；最后，通过语义搜索和图查询生成结合Retrieval Augmented Generation (RAG) 进行问答。论文通过真实世界的例子展示了该系统的运作和潜力。",
      "categories": [
        "cs.AI",
        "H.3.3; H.3.4; I.2.1; I.2.5; I.2.7; I.2.10; J.3"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 5 figures, accepted for the ESWC 2025 TEXT2KG workshop",
      "pdf_url": "http://arxiv.org/pdf/2505.06328v1",
      "published_date": "2025-05-09 10:08:22 UTC",
      "updated_date": "2025-05-09 10:08:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:23:43.522119"
    },
    {
      "arxiv_id": "2505.05916v1",
      "title": "IRNN: Innovation-driven Recurrent Neural Network for Time-Series Data Modeling and Prediction",
      "title_zh": "IRNN：创新驱动的循环神经网络用于时间序列数据建模和预测",
      "authors": [
        "Yifan Zhou",
        "Yibo Wang",
        "Chao Shang"
      ],
      "abstract": "Many real-world datasets are time series that are sequentially collected and\ncontain rich temporal information. Thus, a common interest in practice is to\ncapture dynamics of time series and predict their future evolutions. To this\nend, the recurrent neural network (RNN) has been a prevalent and effective\nmachine learning option, which admits a nonlinear state-space model\nrepresentation. Motivated by the resemblance between RNN and Kalman filter (KF)\nfor linear state-space models, we propose in this paper Innovation-driven RNN\n(IRNN), a novel RNN architecture tailored to time-series data modeling and\nprediction tasks. By adapting the concept of \"innovation\" from KF to RNN, past\nprediction errors are adopted as additional input signals to update hidden\nstates of RNN and boost prediction performance. Since innovation data depend on\nnetwork parameters, existing training algorithms for RNN do not apply to IRNN\nstraightforwardly. Thus, a tailored training algorithm dubbed input\nupdating-based back-propagation through time (IU-BPTT) is further proposed,\nwhich alternates between updating innovations and optimizing network parameters\nvia gradient descent. Experiments on real-world benchmark datasets show that\nthe integration of innovations into various forms of RNN leads to remarkably\nimproved prediction accuracy of IRNN without increasing the training cost\nsubstantially.",
      "tldr_zh": "本研究针对时间序列数据建模和预测问题，提出了一种创新驱动的循环神经网络（Innovation-driven RNN，IRNN），该架构受Kalman Filter（KF）启发，将过去的预测错误作为“创新”信号输入，以更新RNN的隐藏状态并提升预测性能。不同于传统RNN，IRNN需处理创新数据对网络参数的依赖，因此作者开发了专属训练算法input updating-based back-propagation through time（IU-BPTT），该算法交替更新创新数据并通过梯度下降优化参数。实验结果显示，IRNN在真实基准数据集上显著提高了各种RNN形式的预测准确性，同时未大幅增加训练成本。总体而言，这一方法为时间序列预测提供了更高效的框架。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05916v1",
      "published_date": "2025-05-09 09:43:40 UTC",
      "updated_date": "2025-05-09 09:43:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:23:56.670179"
    },
    {
      "arxiv_id": "2505.05901v2",
      "title": "Examining the Source of Defects from a Mechanical Perspective for 3D Anomaly Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Hanzhe Liang",
        "Aoran Wang",
        "Jie Zhou",
        "Xin Jin",
        "Can Gao",
        "Jinbao Wang"
      ],
      "abstract": "In this paper, we explore a novel approach to 3D anomaly detection (AD) that\ngoes beyond merely identifying anomalies based on structural characteristics.\nOur primary perspective is that most anomalies arise from unpredictable\ndefective forces originating from both internal and external sources. To\naddress these anomalies, we seek out opposing forces that can help correct\nthem. Therefore, we introduce the Mechanics Complementary Model-based Framework\nfor the 3D-AD task (MC4AD), which generates internal and external corrective\nforces for each point. We first propose a Diverse Anomaly-Generation (DA-Gen)\nmodule designed to simulate various types of anomalies. Next, we present the\nCorrective Force Prediction Network (CFP-Net), which uses complementary\nrepresentations for point-level analysis to simulate the different\ncontributions from internal and external corrective forces. To ensure the\ncorrective forces are constrained effectively, we have developed a combined\nloss function that includes a new symmetric loss and an overall loss. Notably,\nwe implement a Hierarchical Quality Control (HQC) strategy based on a three-way\ndecision process and contribute a dataset titled Anomaly-IntraVariance, which\nincorporates intraclass variance to evaluate our model. As a result, the\nproposed MC4AD has been proven effective through theory and experimentation.\nThe experimental results demonstrate that our approach yields nine\nstate-of-the-art performances, achieving optimal results with minimal\nparameters and the fastest inference speed across five existing datasets, in\naddition to the proposed Anomaly-IntraVariance dataset. The source is available\nat https://github.com/hzzzzzhappy/MC4AD",
      "tldr_zh": "这篇论文从机械视角探讨3D Anomaly Detection的缺陷来源，认为异常主要源于内部和外部缺陷力，并提出Mechanics Complementary Model-based Framework for 3D-AD (MC4AD)框架来生成纠正力。框架包括Diverse Anomaly-Generation (DA-Gen)模块用于模拟各种异常，以及Corrective Force Prediction Network (CFP-Net)结合互补表示进行点级分析，并通过新的symmetric loss和overall loss函数以及Hierarchical Quality Control (HQC)策略进行优化。实验结果表明，MC4AD在五个现有数据集和新贡献的Anomaly-IntraVariance数据集上实现了九个state-of-the-art性能，具有最少参数和最快推理速度。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "26 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.05901v2",
      "published_date": "2025-05-09 09:09:08 UTC",
      "updated_date": "2025-05-15 15:46:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:24:10.313002"
    },
    {
      "arxiv_id": "2505.05895v1",
      "title": "Leveraging Vision-Language Models for Visual Grounding and Analysis of Automotive UI",
      "title_zh": "利用视觉语言模型进行汽车用户界面的视觉定位和分析",
      "authors": [
        "Benjamin Raphael Ernhofer",
        "Daniil Prokhorov",
        "Jannica Langner",
        "Dominik Bollmann"
      ],
      "abstract": "Modern automotive infotainment systems require intelligent and adaptive\nsolutions to handle frequent User Interface (UI) updates and diverse design\nvariations. We introduce a vision-language framework for understanding and\ninteracting with automotive infotainment systems, enabling seamless adaptation\nacross different UI designs. To further support research in this field, we\nrelease AutomotiveUI-Bench-4K, an open-source dataset of 998 images with 4,208\nannotations. Additionally, we present a synthetic data pipeline to generate\ntraining data. We fine-tune a Molmo-7B-based model using Low-Rank Adaptation\n(LoRa) and incorporating reasoning generated by our pipeline, along with visual\ngrounding and evaluation capabilities. The fine-tuned Evaluative Large Action\nModel (ELAM) achieves strong performance on AutomotiveUI-Bench-4K (model and\ndataset are available on Hugging Face) and demonstrating strong cross-domain\ngeneralization, including a +5.2% improvement on ScreenSpot over the baseline\nmodel. Notably, our approach achieves 80.4% average accuracy on ScreenSpot,\nclosely matching or even surpassing specialized models for desktop, mobile, and\nweb, such as ShowUI, despite being trained for the infotainment domain. This\nresearch investigates how data collection and subsequent fine-tuning can lead\nto AI-driven progress within automotive UI understanding and interaction. The\napplied method is cost-efficient and fine-tuned models can be deployed on\nconsumer-grade GPUs.",
      "tldr_zh": "本研究提出了一种基于 Vision-Language Models 的框架，用于汽车信息娱乐系统的视觉定位 (Visual Grounding) 和分析，支持不同 UI 设计的无缝适应。该框架伴随着开源数据集 AutomotiveUI-Bench-4K（包含 998 张图像和 4,208 个标注）以及一个合成数据管道，用于生成训练数据。研究通过 Low-Rank Adaptation (LoRa) 微调 Molmo-7B 模型，开发出 Evaluative Large Action Model (ELAM)，该模型在 AutomotiveUI-Bench-4K 上表现出色，并在 ScreenSpot 任务中比基线模型提升 5.2%，达到 80.4% 的平均准确率。该方法成本高效，可部署在消费级 GPU 上，并展示了强大的跨域泛化能力，推动了汽车 UI 理解和交互的 AI 进展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05895v1",
      "published_date": "2025-05-09 09:01:52 UTC",
      "updated_date": "2025-05-09 09:01:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:24:21.090005"
    },
    {
      "arxiv_id": "2505.05893v1",
      "title": "LightNobel: Improving Sequence Length Limitation in Protein Structure Prediction Model via Adaptive Activation Quantization",
      "title_zh": "LightNobel：通过自适应激活量化改善蛋白质结构预测模型中的序列长度限制",
      "authors": [
        "Seunghee Han",
        "Soongyu Choi",
        "Joo-Young Kim"
      ],
      "abstract": "Recent advances in Protein Structure Prediction Models (PPMs), such as\nAlphaFold2 and ESMFold, have revolutionized computational biology by achieving\nunprecedented accuracy in predicting three-dimensional protein folding\nstructures. However, these models face significant scalability challenges,\nparticularly when processing proteins with long amino acid sequences (e.g.,\nsequence length > 1,000). The primary bottleneck that arises from the\nexponential growth in activation sizes is driven by the unique data structure\nin PPM, which introduces an additional dimension that leads to substantial\nmemory and computational demands. These limitations have hindered the effective\nscaling of PPM for real-world applications, such as analyzing large proteins or\ncomplex multimers with critical biological and pharmaceutical relevance.\n  In this paper, we present LightNobel, the first hardware-software co-designed\naccelerator developed to overcome scalability limitations on the sequence\nlength in PPM. At the software level, we propose Token-wise Adaptive Activation\nQuantization (AAQ), which leverages unique token-wise characteristics, such as\ndistogram patterns in PPM activations, to enable fine-grained quantization\ntechniques without compromising accuracy. At the hardware level, LightNobel\nintegrates the multi-precision reconfigurable matrix processing unit (RMPU) and\nversatile vector processing unit (VVPU) to enable the efficient execution of\nAAQ. Through these innovations, LightNobel achieves up to 8.44x, 8.41x speedup\nand 37.29x, 43.35x higher power efficiency over the latest NVIDIA A100 and H100\nGPUs, respectively, while maintaining negligible accuracy loss. It also reduces\nthe peak memory requirement up to 120.05x in PPM, enabling scalable processing\nfor proteins with long sequences.",
      "tldr_zh": "该研究针对蛋白质结构预测模型（PPMs）如 AlphaFold2 和 ESMFold 在处理长氨基酸序列（长度超过1,000）时面临的内存和计算瓶颈，提出了LightNobel——一个硬件-软件协同设计的加速器。LightNobel 在软件层面引入Token-wise Adaptive Activation Quantization (AAQ)，利用PPMs激活的独特特性（如distogram模式）进行细粒度量化，以维持准确性；在硬件层面，集成multi-precision reconfigurable matrix processing unit (RMPU)和versatile vector processing unit (VVPU)，实现高效执行。实验结果显示，LightNobel 相比NVIDIA A100和H100 GPU 分别实现8.44x和8.41x的速度提升、37.29x和43.35x的功率效率改进，并将峰值内存需求减少高达120.05x，从而使长序列蛋白质的处理变得可扩展。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.ET",
        "cs.LG",
        "q-bio.BM",
        "B.7; I.2; J.3"
      ],
      "primary_category": "cs.AR",
      "comment": "To appear in the Proceedings of the 52nd IEEE/ACM International\n  Symposium on Computer Architecture (ISCA 2025)",
      "pdf_url": "http://arxiv.org/pdf/2505.05893v1",
      "published_date": "2025-05-09 09:01:10 UTC",
      "updated_date": "2025-05-09 09:01:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:24:33.510772"
    },
    {
      "arxiv_id": "2505.05880v1",
      "title": "Combining Abstract Argumentation and Machine Learning for Efficiently Analyzing Low-Level Process Event Streams",
      "title_zh": "结合抽象论证和机器学习以高效分析低级过程事件流",
      "authors": [
        "Bettina Fazzinga",
        "Sergio Flesca",
        "Filippo Furfaro",
        "Luigi Pontieri",
        "Francesco Scala"
      ],
      "abstract": "Monitoring and analyzing process traces is a critical task for modern\ncompanies and organizations. In scenarios where there is a gap between trace\nevents and reference business activities, this entails an interpretation\nproblem, amounting to translating each event of any ongoing trace into the\ncorresponding step of the activity instance. Building on a recent approach that\nframes the interpretation problem as an acceptance problem within an Abstract\nArgumentation Framework (AAF), one can elegantly analyze plausible event\ninterpretations (possibly in an aggregated form), as well as offer explanations\nfor those that conflict with prior process knowledge. Since, in settings where\nevent-to-activity mapping is highly uncertain (or simply under-specified) this\nreasoning-based approach may yield lowly-informative results and heavy\ncomputation, one can think of discovering a sequencetagging model, trained to\nsuggest highly-probable candidate event interpretations in a context-aware way.\nHowever, training such a model optimally may require using a large amount of\nmanually-annotated example traces. Considering the urgent need of developing\nGreen AI solutions enabling environmental and societal sustainability (with\nreduced labor/computational costs and carbon footprint), we propose a\ndata/computation-efficient neuro-symbolic approach to the problem, where the\ncandidate interpretations returned by the example-driven sequence tagger is\nrefined by the AAF-based reasoner. This allows us to also leverage prior\nknowledge to compensate for the scarcity of example data, as confirmed by\nexperimental results; clearly, this property is particularly useful in settings\nwhere data annotation and model optimization costs are subject to stringent\nconstraints.",
      "tldr_zh": "该论文探讨了监控和分析低级过程事件流的问题，特别是将事件映射到业务活动步骤的解释挑战。作者提出一种结合 Abstract Argumentation Framework (AAF) 和机器学习的 neuro-symbolic 方法，其中序列标记模型（sequence tagging model）生成候选事件解释，而 AAF 推理器进一步优化这些解释，以减少数据标注和计算需求。实验结果显示，这种方法能有效利用先验知识弥补数据稀缺，提升分析效率，并支持 Green AI 的可持续发展目标。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05880v1",
      "published_date": "2025-05-09 08:45:07 UTC",
      "updated_date": "2025-05-09 08:45:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:24:44.406503"
    },
    {
      "arxiv_id": "2505.05877v2",
      "title": "Multi-Modal Molecular Representation Learning via Structure Awareness",
      "title_zh": "翻译失败",
      "authors": [
        "Rong Yin",
        "Ruyue Liu",
        "Xiaoshuai Hao",
        "Xingrui Zhou",
        "Yong Liu",
        "Can Ma",
        "Weiping Wang"
      ],
      "abstract": "Accurate extraction of molecular representations is a critical step in the\ndrug discovery process. In recent years, significant progress has been made in\nmolecular representation learning methods, among which multi-modal molecular\nrepresentation methods based on images, and 2D/3D topologies have become\nincreasingly mainstream. However, existing these multi-modal approaches often\ndirectly fuse information from different modalities, overlooking the potential\nof intermodal interactions and failing to adequately capture the complex\nhigher-order relationships and invariant features between molecules. To\novercome these challenges, we propose a structure-awareness-based multi-modal\nself-supervised molecular representation pre-training framework (MMSA) designed\nto enhance molecular graph representations by leveraging invariant knowledge\nbetween molecules. The framework consists of two main modules: the multi-modal\nmolecular representation learning module and the structure-awareness module.\nThe multi-modal molecular representation learning module collaboratively\nprocesses information from different modalities of the same molecule to\novercome intermodal differences and generate a unified molecular embedding.\nSubsequently, the structure-awareness module enhances the molecular\nrepresentation by constructing a hypergraph structure to model higher-order\ncorrelations between molecules. This module also introduces a memory mechanism\nfor storing typical molecular representations, aligning them with memory\nanchors in the memory bank to integrate invariant knowledge, thereby improving\nthe model generalization ability. Extensive experiments have demonstrated the\neffectiveness of MMSA, which achieves state-of-the-art performance on the\nMoleculeNet benchmark, with average ROC-AUC improvements ranging from 1.8% to\n9.6% over baseline methods.",
      "tldr_zh": "本文提出了一种基于结构感知的多模态自监督分子表示预训练框架（MMSA），旨在解决现有多模态方法忽略模态间交互和高阶关系的问题，从而提升分子表示学习在药物发现中的准确性。框架包括多模态分子表示学习模块，用于融合图像、2D/3D 拓扑等模态信息生成统一分子嵌入，以及结构-awareness 模块，通过超图结构建模分子间的高阶相关性并引入记忆机制整合不变知识，提高模型的泛化能力。实验在 MoleculeNet 基准上表明，MMSA 相较基线方法平均 ROC-AUC 提高了 1.8% 到 9.6%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by IEEE Transactions on Image Processing (TIP) 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.05877v2",
      "published_date": "2025-05-09 08:37:29 UTC",
      "updated_date": "2025-05-12 01:15:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:24:56.925442"
    },
    {
      "arxiv_id": "2505.05870v1",
      "title": "Towards Facial Image Compression with Consistency Preserving Diffusion Prior",
      "title_zh": "翻译失败",
      "authors": [
        "Yimin Zhou",
        "Yichong Xia",
        "Bin Chen",
        "Baoyi An",
        "Haoqian Wang",
        "Zhi Wang",
        "Yaowei Wang",
        "Zikun Zhou"
      ],
      "abstract": "With the widespread application of facial image data across various domains,\nthe efficient storage and transmission of facial images has garnered\nsignificant attention. However, the existing learned face image compression\nmethods often produce unsatisfactory reconstructed image quality at low bit\nrates. Simply adapting diffusion-based compression methods to facial\ncompression tasks results in reconstructed images that perform poorly in\ndownstream applications due to insufficient preservation of high-frequency\ninformation. To further explore the diffusion prior in facial image\ncompression, we propose Facial Image Compression with a Stable Diffusion Prior\n(FaSDiff), a method that preserves consistency through frequency enhancement.\nFaSDiff employs a high-frequency-sensitive compressor in an end-to-end\nframework to capture fine image details and produce robust visual prompts.\nAdditionally, we introduce a hybrid low-frequency enhancement module that\ndisentangles low-frequency facial semantics and stably modulates the diffusion\nprior alongside visual prompts. The proposed modules allow FaSDiff to leverage\ndiffusion priors for superior human visual perception while minimizing\nperformance loss in machine vision due to semantic inconsistency. Extensive\nexperiments show that FaSDiff outperforms state-of-the-art methods in balancing\nhuman visual quality and machine vision accuracy. The code will be released\nafter the paper is accepted.",
      "tldr_zh": "该研究针对人脸图像压缩问题，提出了一种名为 FaSDiff 的方法，利用 Stable Diffusion Prior 通过频率增强保持图像一致性，以解决现有方法在低比特率下重建质量差和高频信息丢失的问题。FaSDiff 包括一个高频敏感压缩器，用于捕捉细微图像细节并生成鲁棒的视觉提示，以及一个混合低频增强模块，来分离低频人脸语义并稳定调节 diffusion prior，从而平衡人类视觉感知和机器视觉准确性。实验结果显示，FaSDiff 在人脸图像压缩任务中优于最先进方法，在提升视觉质量的同时最小化语义不一致性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05870v1",
      "published_date": "2025-05-09 08:13:51 UTC",
      "updated_date": "2025-05-09 08:13:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:25:08.657923"
    },
    {
      "arxiv_id": "2505.05869v1",
      "title": "Generative Discovery of Partial Differential Equations by Learning from Math Handbooks",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Xu",
        "Yuntian Chen",
        "Rui Cao",
        "Tianning Tang",
        "Mengge Du",
        "Jian Li",
        "Adrian H. Callaghan",
        "Dongxiao Zhang"
      ],
      "abstract": "Data driven discovery of partial differential equations (PDEs) is a promising\napproach for uncovering the underlying laws governing complex systems. However,\npurely data driven techniques face the dilemma of balancing search space with\noptimization efficiency. This study introduces a knowledge guided approach that\nincorporates existing PDEs documented in a mathematical handbook to facilitate\nthe discovery process. These PDEs are encoded as sentence like structures\ncomposed of operators and basic terms, and used to train a generative model,\ncalled EqGPT, which enables the generation of free form PDEs. A loop of\ngeneration evaluation optimization is constructed to autonomously identify the\nmost suitable PDE. Experimental results demonstrate that this framework can\nrecover a variety of PDE forms with high accuracy and computational efficiency,\nparticularly in cases involving complex temporal derivatives or intricate\nspatial terms, which are often beyond the reach of conventional methods. The\napproach also exhibits generalizability to irregular spatial domains and higher\ndimensional settings. Notably, it succeeds in discovering a previously\nunreported PDE governing strongly nonlinear surface gravity waves propagating\ntoward breaking, based on real world experimental data, highlighting its\napplicability to practical scenarios and its potential to support scientific\ndiscovery.",
      "tldr_zh": "本研究提出了一种知识引导的方法，用于数据驱动发现偏微分方程 (PDEs)，通过整合数学手册中的现有PDEs来平衡搜索空间与优化效率。研究将PDEs编码为由运算符和基本术语组成的句子式结构，并训练生成模型EqGPT来生成自由形式的PDEs，同时构建生成-评估-优化循环以自主识别最合适的方程。实验结果显示，该框架能高精度地恢复各种PDEs形式，尤其在处理复杂时间导数或空间项时，比传统方法更高效，并适用于不规则空间域和更高维设置。该方法基于真实实验数据成功发现了一个先前未报道的强烈非线性表面重力波PDEs，展示了其在实际科学发现中的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.comp-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05869v1",
      "published_date": "2025-05-09 08:09:21 UTC",
      "updated_date": "2025-05-09 08:09:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:25:20.305188"
    },
    {
      "arxiv_id": "2505.05863v1",
      "title": "Evolutionary ecology of words",
      "title_zh": "词汇的进化生态学",
      "authors": [
        "Reiji Suzuki",
        "Takaya Arita"
      ],
      "abstract": "We propose a model for the evolutionary ecology of words as one attempt to\nextend evolutionary game theory and agent-based models by utilizing the rich\nlinguistic expressions of Large Language Models (LLMs). Our model enables the\nemergence and evolution of diverse and infinite options for interactions among\nagents. Within the population, each agent possesses a short word (or phrase)\ngenerated by an LLM and moves within a spatial environment. When agents become\nadjacent, the outcome of their interaction is determined by the LLM based on\nthe relationship between their words, with the loser's word being replaced by\nthe winner's. Word mutations, also based on LLM outputs, may occur. We\nconducted preliminary experiments assuming that ``strong animal species\" would\nsurvive. The results showed that from an initial population consisting of\nwell-known species, many species emerged both gradually and in a punctuated\nequilibrium manner. Each trial demonstrated the unique evolution of diverse\npopulations, with one type of large species becoming dominant, such as\nterrestrial animals, marine life, or extinct species, which were ecologically\nspecialized and adapted ones across diverse extreme habitats. We also conducted\na long-term experiment with a large population, demonstrating the emergence and\ncoexistence of diverse species.",
      "tldr_zh": "该研究提出了一种名为“Evolutionary ecology of words”的模型，利用 Large Language Models (LLMs) 扩展进化博弈论和 agent-based models，模拟词语在代理间的演化生态。模型中，代理使用 LLMs 生成的词语或短语在空间环境中移动，互动结果由 LLMs 决定，导致失败者的词语被替换，并可能发生突变。实验结果显示，从初始已知物种开始，代理群体以渐进和 punctuated equilibrium 方式演化出多样化物种，如陆地动物、海生生物或灭绝物种，这些物种在极端栖息地中专业化和适应，最终实现长期的多样性共存。",
      "categories": [
        "q-bio.PE",
        "cs.AI",
        "cs.CL",
        "92B20"
      ],
      "primary_category": "q-bio.PE",
      "comment": "8 pages, 5 figures. Preprint of the paper published in Proceedings of\n  2025 IEEE Symposium on Computational Intelligence in Artificial Life and\n  Cooperative Intelligent Systems (ALIFE-CIS)",
      "pdf_url": "http://arxiv.org/pdf/2505.05863v1",
      "published_date": "2025-05-09 07:57:10 UTC",
      "updated_date": "2025-05-09 07:57:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:25:33.286996"
    },
    {
      "arxiv_id": "2505.07866v1",
      "title": "Computationally Efficient Diffusion Models in Medical Imaging: A Comprehensive Review",
      "title_zh": "医学",
      "authors": [
        "Abdullah",
        "Tao Huang",
        "Ickjai Lee",
        "Euijoon Ahn"
      ],
      "abstract": "The diffusion model has recently emerged as a potent approach in computer\nvision, demonstrating remarkable performances in the field of generative\nartificial intelligence. Capable of producing high-quality synthetic images,\ndiffusion models have been successfully applied across a range of applications.\nHowever, a significant challenge remains with the high computational cost\nassociated with training and generating these models. This study focuses on the\nefficiency and inference time of diffusion-based generative models,\nhighlighting their applications in both natural and medical imaging. We present\nthe most recent advances in diffusion models by categorizing them into three\nkey models: the Denoising Diffusion Probabilistic Model (DDPM), the Latent\nDiffusion Model (LDM), and the Wavelet Diffusion Model (WDM). These models play\na crucial role in medical imaging, where producing fast, reliable, and\nhigh-quality medical images is essential for accurate analysis of abnormalities\nand disease diagnosis. We first investigate the general framework of DDPM, LDM,\nand WDM and discuss the computational complexity gap filled by these models in\nnatural and medical imaging. We then discuss the current limitations of these\nmodels as well as the opportunities and future research directions in medical\nimaging.",
      "tldr_zh": "这篇综述论文探讨了扩散模型（diffusion models）在医疗成像中的计算效率问题，强调了这些模型在生成高质量合成图像方面的潜力，同时分析了其在自然和医疗成像中的应用。论文对三种关键模型——Denoising Diffusion Probabilistic Model (DDPM)、Latent Diffusion Model (LDM) 和 Wavelet Diffusion Model (WDM)——进行了分类讨论，评估了它们填补计算复杂性空白的作用，并突出了在医疗诊断中的优势，如快速可靠的图像生成。最终，论文指出了这些模型的当前局限性，并提出了未来的研究机会和方向，以进一步提升效率和应用潜力。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "pages 36, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.07866v1",
      "published_date": "2025-05-09 07:56:04 UTC",
      "updated_date": "2025-05-09 07:56:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:25:46.677001"
    },
    {
      "arxiv_id": "2505.06326v1",
      "title": "Enterprise Architecture as a Dynamic Capability for Scalable and Sustainable Generative AI adoption: Bridging Innovation and Governance in Large Organisations",
      "title_zh": "翻译失败",
      "authors": [
        "Alexander Ettinger"
      ],
      "abstract": "Generative Artificial Intelligence is a powerful new technology with the\npotential to boost innovation and reshape governance in many industries.\nNevertheless, organisations face major challenges in scaling GenAI, including\ntechnology complexity, governance gaps and resource misalignments. This study\nexplores how Enterprise Architecture Management can meet the complex\nrequirements of GenAI adoption within large enterprises. Based on a systematic\nliterature review and the qualitative analysis of 16 semi-structured interviews\nwith experts, it examines the relationships between EAM, dynamic capabilities\nand GenAI adoption. The review identified key limitations in existing EA\nframeworks, particularly their inability to fully address the unique\nrequirements of GenAI. The interviews, analysed using the Gioia methodology,\nrevealed critical enablers and barriers to GenAI adoption across industries.\nThe findings indicate that EAM, when theorised as sensing, seizing and\ntransforming dynamic capabilities, can enhance GenAI adoption by improving\nstrategic alignment, governance frameworks and organisational agility. However,\nthe study also highlights the need to tailor EA frameworks to GenAI-specific\nchallenges, including low data governance maturity and the balance between\ninnovation and compliance. Several conceptual frameworks are proposed to guide\nEA leaders in aligning GenAI maturity with organisational readiness. The work\ncontributes to academic understanding and industry practice by clarifying the\nrole of EA in bridging innovation and governance in disruptive technology\nenvironments.",
      "tldr_zh": "这篇论文探讨了企业架构管理 (EAM) 如何作为动态能力，促进生成式 AI (GenAI) 在大型组织的可扩展和可持续采用，从而桥接创新与治理挑战。研究通过系统文献综述和对16位专家的半结构化访谈（采用Gioia方法进行分析），揭示了现有EA框架的局限性，如无法充分应对GenAI的复杂性、治理缺口和资源错配。关键发现是，EAM通过感知、抓住和转化动态能力，能提升战略对齐、组织敏捷性和GenAI采用效率，但需针对特定问题（如数据治理不成熟和创新与合规平衡）进行定制。论文提出了若干概念框架，以指导EA领导者评估组织准备度，并为学术和行业实践提供平衡创新与治理的实用见解。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "82 pages excluding appendix",
      "pdf_url": "http://arxiv.org/pdf/2505.06326v1",
      "published_date": "2025-05-09 07:41:33 UTC",
      "updated_date": "2025-05-09 07:41:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:25:57.791129"
    },
    {
      "arxiv_id": "2505.05849v2",
      "title": "AGENTFUZZER: Generic Black-Box Fuzzing for Indirect Prompt Injection against LLM Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Zhun Wang",
        "Vincent Siu",
        "Zhe Ye",
        "Tianneng Shi",
        "Yuzhou Nie",
        "Xuandong Zhao",
        "Chenguang Wang",
        "Wenbo Guo",
        "Dawn Song"
      ],
      "abstract": "The strong planning and reasoning capabilities of Large Language Models\n(LLMs) have fostered the development of agent-based systems capable of\nleveraging external tools and interacting with increasingly complex\nenvironments. However, these powerful features also introduce a critical\nsecurity risk: indirect prompt injection, a sophisticated attack vector that\ncompromises the core of these agents, the LLM, by manipulating contextual\ninformation rather than direct user prompts. In this work, we propose a generic\nblack-box fuzzing framework, AgentXploit, designed to automatically discover\nand exploit indirect prompt injection vulnerabilities across diverse LLM\nagents. Our approach starts by constructing a high-quality initial seed corpus,\nthen employs a seed selection algorithm based on Monte Carlo Tree Search (MCTS)\nto iteratively refine inputs, thereby maximizing the likelihood of uncovering\nagent weaknesses. We evaluate AgentXploit on two public benchmarks, AgentDojo\nand VWA-adv, where it achieves 71% and 70% success rates against agents based\non o3-mini and GPT-4o, respectively, nearly doubling the performance of\nbaseline attacks. Moreover, AgentXploit exhibits strong transferability across\nunseen tasks and internal LLMs, as well as promising results against defenses.\nBeyond benchmark evaluations, we apply our attacks in real-world environments,\nsuccessfully misleading agents to navigate to arbitrary URLs, including\nmalicious sites.",
      "tldr_zh": "这篇论文提出了 AGENTFUZZER，一种针对 Large Language Models (LLMs) 代理的通用黑盒模糊测试框架，旨在自动发现和利用 indirect prompt injection 漏洞，以应对这些代理在外部工具交互中面临的严重安全风险。该框架通过构建高质量初始种子语料库，并采用基于 Monte Carlo Tree Search (MCTS) 的种子选择算法进行迭代输入优化，从而高效识别代理弱点。在评估中，AgentXploit 在 AgentDojo 和 VWA-adv 基准上分别实现了 71% 和 70% 的成功率，显著优于基线攻击，并展示了强大的转移性和在真实环境中的实际应用，如引导代理访问恶意 URL。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05849v2",
      "published_date": "2025-05-09 07:40:17 UTC",
      "updated_date": "2025-05-21 05:34:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:26:10.094079"
    },
    {
      "arxiv_id": "2505.07865v1",
      "title": "CellVerse: Do Large Language Models Really Understand Cell Biology?",
      "title_zh": "CellVerse: 大语言模型真的理解细胞生物学吗？",
      "authors": [
        "Fan Zhang",
        "Tianyu Liu",
        "Zhihong Zhu",
        "Hao Wu",
        "Haixin Wang",
        "Donghao Zhou",
        "Yefeng Zheng",
        "Kun Wang",
        "Xian Wu",
        "Pheng-Ann Heng"
      ],
      "abstract": "Recent studies have demonstrated the feasibility of modeling single-cell data\nas natural languages and the potential of leveraging powerful large language\nmodels (LLMs) for understanding cell biology. However, a comprehensive\nevaluation of LLMs' performance on language-driven single-cell analysis tasks\nstill remains unexplored. Motivated by this challenge, we introduce CellVerse,\na unified language-centric question-answering benchmark that integrates four\ntypes of single-cell multi-omics data and encompasses three hierarchical levels\nof single-cell analysis tasks: cell type annotation (cell-level), drug response\nprediction (drug-level), and perturbation analysis (gene-level). Going beyond\nthis, we systematically evaluate the performance across 14 open-source and\nclosed-source LLMs ranging from 160M to 671B on CellVerse. Remarkably, the\nexperimental results reveal: (1) Existing specialist models (C2S-Pythia) fail\nto make reasonable decisions across all sub-tasks within CellVerse, while\ngeneralist models such as Qwen, Llama, GPT, and DeepSeek family models exhibit\npreliminary understanding capabilities within the realm of cell biology. (2)\nThe performance of current LLMs falls short of expectations and has substantial\nroom for improvement. Notably, in the widely studied drug response prediction\ntask, none of the evaluated LLMs demonstrate significant performance\nimprovement over random guessing. CellVerse offers the first large-scale\nempirical demonstration that significant challenges still remain in applying\nLLMs to cell biology. By introducing CellVerse, we lay the foundation for\nadvancing cell biology through natural languages and hope this paradigm could\nfacilitate next-generation single-cell analysis.",
      "tldr_zh": "本研究探讨大型语言模型（LLMs）是否真正理解细胞生物学，通过引入CellVerse基准来评估其在语言驱动单细胞分析任务上的性能。CellVerse整合四种单细胞多组学数据，并涵盖三个层次的任务：细胞类型注释（cell-level）、药物响应预测（drug-level）和扰动分析（gene-level）。在评估14个LLMs（参数从160M到671B）后，发现专业模型如C2S-Pythia在所有子任务上表现不佳，而通用模型如Qwen、Llama、GPT和DeepSeek显示初步理解能力，但整体性能仍有很大改进空间，尤其在药物响应预测任务上，无模型优于随机猜测。该基准为推进LLMs在细胞生物学中的应用奠定基础，并强调了通过自然语言范式提升单细胞分析的潜力。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.CL",
        "q-bio.CB"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07865v1",
      "published_date": "2025-05-09 06:47:23 UTC",
      "updated_date": "2025-05-09 06:47:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:26:22.289927"
    },
    {
      "arxiv_id": "2505.06325v1",
      "title": "Human in the Latent Loop (HILL): Interactively Guiding Model Training Through Human Intuition",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Geissler",
        "Lars Krupp",
        "Vishal Banwari",
        "David Habusch",
        "Bo Zhou",
        "Paul Lukowicz",
        "Jakob Karolus"
      ],
      "abstract": "Latent space representations are critical for understanding and improving the\nbehavior of machine learning models, yet they often remain obscure and\nintricate. Understanding and exploring the latent space has the potential to\ncontribute valuable human intuition and expertise about respective domains. In\nthis work, we present HILL, an interactive framework allowing users to\nincorporate human intuition into the model training by interactively reshaping\nlatent space representations. The modifications are infused into the model\ntraining loop via a novel approach inspired by knowledge distillation, treating\nthe user's modifications as a teacher to guide the model in reshaping its\nintrinsic latent representation. The process allows the model to converge more\neffectively and overcome inefficiencies, as well as provide beneficial insights\nto the user. We evaluated HILL in a user study tasking participants to train an\noptimal model, closely observing the employed strategies. The results\ndemonstrated that human-guided latent space modifications enhance model\nperformance while maintaining generalization, yet also revealing the risks of\nincluding user biases. Our work introduces a novel human-AI interaction\nparadigm that infuses human intuition into model training and critically\nexamines the impact of human intervention on training strategies and potential\nbiases.",
      "tldr_zh": "本研究提出 HILL（Human in the Latent Loop）框架，通过交互式方式让用户利用人类直觉重塑机器学习模型的 latent space 表示，从而指导模型训练。该框架采用一种受 knowledge distillation 启发的创新方法，将用户修改视为教师信号，融入训练循环以提升模型收敛效率和性能。在用户研究中，HILL 显著提高了模型性能和泛化能力，但也揭示了引入用户偏见的风险，强调了人类-AI interaction 新范式的潜在影响和挑战。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06325v1",
      "published_date": "2025-05-09 06:17:46 UTC",
      "updated_date": "2025-05-09 06:17:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:26:33.085407"
    },
    {
      "arxiv_id": "2505.05799v1",
      "title": "MxMoE: Mixed-precision Quantization for MoE with Accuracy and Performance Co-Design",
      "title_zh": "MxMoE：MoE 的混合精度量化，结合准确性和性能共同设计",
      "authors": [
        "Haojie Duanmu",
        "Xiuhong Li",
        "Zhihang Yuan",
        "Size Zheng",
        "Jiangfei Duan",
        "Xingcheng Zhang",
        "Dahua Lin"
      ],
      "abstract": "Mixture-of-Experts (MoE) models face deployment challenges due to their large\nparameter counts and computational demands. We explore quantization for MoE\nmodels and highlight two key insights: 1) linear blocks exhibit varying\nquantization sensitivity, and 2) divergent expert activation frequencies create\nheterogeneous computational characteristics. Based on these observations, we\nintroduce MxMoE, a mixed-precision optimization framework for MoE models that\nconsiders both algorithmic and system perspectives. MxMoE navigates the design\nspace defined by parameter sensitivity, expert activation dynamics, and\nhardware resources to derive efficient mixed-precision configurations.\nAdditionally, MxMoE automatically generates optimized mixed-precision GroupGEMM\nkernels, enabling parallel execution of GEMMs with different precisions.\nEvaluations show that MxMoE outperforms existing methods, achieving 2.4 lower\nWikitext-2 perplexity than GPTQ at 2.25-bit and delivering up to 3.4x speedup\nover full precision, as well as up to 29.4% speedup over uniform quantization\nat equivalent accuracy with 5-bit weight-activation quantization. Our code is\navailable at https://github.com/cat538/MxMoE.",
      "tldr_zh": "该论文针对 Mixture-of-Experts (MoE) 模型的参数规模和计算需求带来的部署挑战，提出了 MxMoE 框架，该框架通过混合精度量化优化，结合线性块的量化敏感度、专家激活频率以及硬件资源进行算法和系统协同设计。MxMoE 自动生成优化的混合精度 GroupGEMM 内核，支持不同精度的 GEMM 并行执行，从而提升模型效率。实验结果显示，MxMoE 在 2.25-bit 量化下比 GPTQ 降低 2.4 Wikitext-2 perplexity，提供高达 3.4x 的加速性能，并比等效精度的统一量化提升达 29.4%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05799v1",
      "published_date": "2025-05-09 05:32:21 UTC",
      "updated_date": "2025-05-09 05:32:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:26:46.559835"
    },
    {
      "arxiv_id": "2505.05796v1",
      "title": "Human-in-the-Loop AI for HVAC Management Enhancing Comfort and Energy Efficiency",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyu Liang",
        "Frits de Nijs",
        "Buser Say",
        "Hao Wang"
      ],
      "abstract": "Heating, Ventilation, and Air Conditioning (HVAC) systems account for\napproximately 38% of building energy consumption globally, making them one of\nthe most energy-intensive services. The increasing emphasis on energy\nefficiency and sustainability, combined with the need for enhanced occupant\ncomfort, presents a significant challenge for traditional HVAC systems. These\nsystems often fail to dynamically adjust to real-time changes in electricity\nmarket rates or individual comfort preferences, leading to increased energy\ncosts and reduced comfort. In response, we propose a Human-in-the-Loop (HITL)\nArtificial Intelligence framework that optimizes HVAC performance by\nincorporating real-time user feedback and responding to fluctuating electricity\nprices. Unlike conventional systems that require predefined information about\noccupancy or comfort levels, our approach learns and adapts based on ongoing\nuser input. By integrating the occupancy prediction model with reinforcement\nlearning, the system improves operational efficiency and reduces energy costs\nin line with electricity market dynamics, thereby contributing to demand\nresponse initiatives. Through simulations, we demonstrate that our method\nachieves significant cost reductions compared to baseline approaches while\nmaintaining or enhancing occupant comfort. This feedback-driven approach\nensures personalized comfort control without the need for predefined settings,\noffering a scalable solution that balances individual preferences with economic\nand environmental goals.",
      "tldr_zh": "这篇论文针对 HVAC 系统的高能源消耗问题（占全球建筑能耗约38%），提出了一种 Human-in-the-Loop (HITL) AI 框架，通过实时用户反馈和响应电价波动来优化系统性能。框架整合了 occupancy prediction model 和 reinforcement learning，实现动态调整和适应个人舒适偏好，而无需预定义设置。模拟实验显示，该方法相较基线方法降低了能源成本，同时维持或提升了 occupant 舒适度。该创新方案为需求响应（demand response）提供可扩展的解决方案，平衡了经济、环境和个性化目标。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY",
        "math.OC"
      ],
      "primary_category": "eess.SY",
      "comment": "ACM e-Energy 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.05796v1",
      "published_date": "2025-05-09 05:23:37 UTC",
      "updated_date": "2025-05-09 05:23:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:26:57.166660"
    },
    {
      "arxiv_id": "2505.05794v1",
      "title": "What Is Next for LLMs? Next-Generation AI Computing Hardware Using Photonic Chips",
      "title_zh": "翻译失败",
      "authors": [
        "Renjie Li",
        "Wenjie Wei",
        "Qi Xin",
        "Xiaoli Liu",
        "Sixuan Mao",
        "Erik Ma",
        "Zijian Chen",
        "Malu Zhang",
        "Haizhou Li",
        "Zhaoyu Zhang"
      ],
      "abstract": "Large language models (LLMs) are rapidly pushing the limits of contemporary\ncomputing hardware. For example, training GPT-3 has been estimated to consume\naround 1300 MWh of electricity, and projections suggest future models may\nrequire city-scale (gigawatt) power budgets. These demands motivate exploration\nof computing paradigms beyond conventional von Neumann architectures. This\nreview surveys emerging photonic hardware optimized for next-generation\ngenerative AI computing. We discuss integrated photonic neural network\narchitectures (e.g., Mach-Zehnder interferometer meshes, lasers,\nwavelength-multiplexed microring resonators) that perform ultrafast matrix\noperations. We also examine promising alternative neuromorphic devices,\nincluding spiking neural network circuits and hybrid spintronic-photonic\nsynapses, which combine memory and processing. The integration of\ntwo-dimensional materials (graphene, TMDCs) into silicon photonic platforms is\nreviewed for tunable modulators and on-chip synaptic elements.\nTransformer-based LLM architectures (self-attention and feed-forward layers)\nare analyzed in this context, identifying strategies and challenges for mapping\ndynamic matrix multiplications onto these novel hardware substrates. We then\ndissect the mechanisms of mainstream LLMs, such as ChatGPT, DeepSeek, and\nLLaMA, highlighting their architectural similarities and differences. We\nsynthesize state-of-the-art components, algorithms, and integration methods,\nhighlighting key advances and open issues in scaling such systems to mega-sized\nLLM models. We find that photonic computing systems could potentially surpass\nelectronic processors by orders of magnitude in throughput and energy\nefficiency, but require breakthroughs in memory, especially for long-context\nwindows and long token sequences, and in storage of ultra-large datasets.",
      "tldr_zh": "这篇评论探讨了大型语言模型(LLMs)对传统计算硬件的挑战，如GPT-3的巨量电力消耗，并提出光子芯片作为下一代AI计算硬件的潜在解决方案。论文审视了集成光子神经网络架构（如Mach-Zehnder interferometer meshes、激光器和wavelength-multiplexed microring resonators），以及神经形态设备（如spiking neural network circuits和hybrid spintronic-photonic synapses），并整合二维材料（如graphene和TMDCs）来提升矩阵运算效率。分析显示，Transformer-based LLM架构（如self-attention层）可映射到这些硬件上，实现吞吐量和能效的数倍提升，但需克服内存挑战，尤其是处理长上下文窗口和超大规模数据集。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.AR",
      "comment": "36 pages, 22 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.05794v1",
      "published_date": "2025-05-09 05:19:14 UTC",
      "updated_date": "2025-05-09 05:19:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:27:10.214895"
    },
    {
      "arxiv_id": "2505.05784v3",
      "title": "FlowHFT: Imitation Learning via Flow Matching Policy for Optimal High-Frequency Trading under Diverse Market Conditions",
      "title_zh": "FlowHFT：基于流匹配策略的模仿学习，用于在多样化市场条件下实现最优高频交易",
      "authors": [
        "Yang Li",
        "Zhi Chen",
        "Steve Yang"
      ],
      "abstract": "High-frequency trading (HFT) is an investing strategy that continuously\nmonitors market states and places bid and ask orders at millisecond speeds.\nTraditional HFT approaches fit models with historical data and assume that\nfuture market states follow similar patterns. This limits the effectiveness of\nany single model to the specific conditions it was trained for. Additionally,\nthese models achieve optimal solutions only under specific market conditions,\nsuch as assumptions about stock price's stochastic process, stable order flow,\nand the absence of sudden volatility. Real-world markets, however, are dynamic,\ndiverse, and frequently volatile. To address these challenges, we propose the\nFlowHFT, a novel imitation learning framework based on flow matching policy.\nFlowHFT simultaneously learns strategies from numerous expert models, each\nproficient in particular market scenarios. As a result, our framework can\nadaptively adjust investment decisions according to the prevailing market\nstate. Furthermore, FlowHFT incorporates a grid-search fine-tuning mechanism.\nThis allows it to refine strategies and achieve superior performance even in\ncomplex or extreme market scenarios where expert strategies may be suboptimal.\nWe test FlowHFT in multiple market environments. We first show that flow\nmatching policy is applicable in stochastic market environments, thus enabling\nFlowHFT to learn trading strategies under different market conditions. Notably,\nour single framework consistently achieves performance superior to the best\nexpert for each market condition.",
      "tldr_zh": "这篇论文提出了FlowHFT，一种基于流匹配政策(Flow Matching Policy)的模仿学习(Imitation Learning)框架，旨在解决高频交易(HFT)在多样化市场条件下的局限性问题。FlowHFT通过从多个专家模型中同时学习策略，实现对动态市场状态的自适应调整，并引入网格搜索微调机制以优化复杂或极端场景下的表现。实验结果显示，该框架在多种随机市场环境中均优于单一专家模型，证明其在不同条件下实现最优HFT策略的有效性。",
      "categories": [
        "q-fin.TR",
        "cs.AI",
        "cs.CE",
        "q-fin.CP"
      ],
      "primary_category": "q-fin.TR",
      "comment": "16 pages, 6 figures, 7 tables, 2 algorithms",
      "pdf_url": "http://arxiv.org/pdf/2505.05784v3",
      "published_date": "2025-05-09 04:58:14 UTC",
      "updated_date": "2025-05-22 04:48:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:27:21.299818"
    },
    {
      "arxiv_id": "2505.06324v1",
      "title": "Document Attribution: Examining Citation Relationships using Large Language Models",
      "title_zh": "文档归属：使用大型语言模型考察引用关系",
      "authors": [
        "Vipula Rawte",
        "Ryan A. Rossi",
        "Franck Dernoncourt",
        "Nedim Lipka"
      ],
      "abstract": "As Large Language Models (LLMs) are increasingly applied to document-based\ntasks - such as document summarization, question answering, and information\nextraction - where user requirements focus on retrieving information from\nprovided documents rather than relying on the model's parametric knowledge,\nensuring the trustworthiness and interpretability of these systems has become a\ncritical concern. A central approach to addressing this challenge is\nattribution, which involves tracing the generated outputs back to their source\ndocuments. However, since LLMs can produce inaccurate or imprecise responses,\nit is crucial to assess the reliability of these citations.\n  To tackle this, our work proposes two techniques. (1) A zero-shot approach\nthat frames attribution as a straightforward textual entailment task. Our\nmethod using flan-ul2 demonstrates an improvement of 0.27% and 2.4% over the\nbest baseline of ID and OOD sets of AttributionBench, respectively. (2) We also\nexplore the role of the attention mechanism in enhancing the attribution\nprocess. Using a smaller LLM, flan-t5-small, the F1 scores outperform the\nbaseline across almost all layers except layer 4 and layers 8 through 11.",
      "tldr_zh": "这篇论文探讨了在使用 Large Language Models (LLMs) 处理文档任务（如总结、问答和信息提取）时，确保输出归因（attribution）的可靠性和可解释性问题，旨在通过追踪生成内容回溯到源文档来评估其准确性。论文提出了一种 zero-shot 方法，将归因 framing 为文本蕴含（textual entailment）任务，使用 flan-ul2 模型，在 AttributionBench 的 ID 和 OOD 集上分别比最佳基准提高了 0.27% 和 2.4%。此外，他们探索了 attention mechanism 在归因过程中的作用，使用 flan-t5-small 模型，其 F1 scores 在几乎所有层（除 layer 4 和 8-11 外）上均超过了基准。这些技术为提升 LLMs 在文档任务中的可信度提供了新途径。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06324v1",
      "published_date": "2025-05-09 04:40:11 UTC",
      "updated_date": "2025-05-09 04:40:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:27:35.049330"
    },
    {
      "arxiv_id": "2505.05777v1",
      "title": "PyResBugs: A Dataset of Residual Python Bugs for Natural Language-Driven Fault Injection",
      "title_zh": "翻译失败",
      "authors": [
        "Domenico Cotroneo",
        "Giuseppe De Rosa",
        "Pietro Liguori"
      ],
      "abstract": "This paper presents PyResBugs, a curated dataset of residual bugs, i.e.,\ndefects that persist undetected during traditional testing but later surface in\nproduction, collected from major Python frameworks. Each bug in the dataset is\npaired with its corresponding fault-free (fixed) version and annotated with\nmulti-level natural language (NL) descriptions. These NL descriptions enable\nnatural language-driven fault injection, offering a novel approach to\nsimulating real-world faults in software systems. By bridging the gap between\nsoftware fault injection techniques and real-world representativeness,\nPyResBugs provides researchers with a high-quality resource for advancing\nAI-driven automated testing in Python systems.",
      "tldr_zh": "本论文介绍了PyResBugs数据集，该数据集收集了来自主要Python框架的残留bug（即传统测试中未检测到的生产环境缺陷），每个bug都配对了修复版本并标注了多级自然语言（NL）描述。  \n这些NL描述支持自然语言驱动的故障注入方法，允许更真实地模拟软件系统中的真实世界故障，从而桥接了故障注入技术和实际应用之间的差距。  \nPyResBugs为AI驱动的Python系统自动化测试提供高质量资源，帮助研究人员提升测试效率和准确性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05777v1",
      "published_date": "2025-05-09 04:39:09 UTC",
      "updated_date": "2025-05-09 04:39:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:27:45.108335"
    },
    {
      "arxiv_id": "2505.07864v1",
      "title": "Arrow-Guided VLM: Enhancing Flowchart Understanding via Arrow Direction Encoding",
      "title_zh": "Arrow-Guided VLM：通过箭头方向编码增强流程图理解",
      "authors": [
        "Takamitsu Omasa",
        "Ryo Koshihara",
        "Masumi Morishige"
      ],
      "abstract": "Flowcharts are indispensable tools in software design and business-process\nanalysis, yet current vision-language models (VLMs) frequently misinterpret the\ndirectional arrows and graph topology that set these diagrams apart from\nnatural images. We introduce a seven-stage pipeline grouped into three broader\nprocesses: (1) arrow-aware detection of nodes and arrow endpoints; (2) optical\ncharacter recognition (OCR) to extract node text; and (3) construction of a\nstructured prompt that guides the VLMs. Tested on a 90-question benchmark\ndistilled from 30 annotated flowcharts, the method raises overall accuracy from\n80 % to 89 % (+9 percentage points) without any task-specific fine-tuning. The\ngain is most pronounced for next-step queries (25/30 -> 30/30; 100 %, +17 pp);\nbranch-result questions improve more modestly, and before-step questions remain\ndifficult. A parallel evaluation with an LLM-as-a-Judge protocol shows the same\ntrends, reinforcing the advantage of explicit arrow encoding. Limitations\ninclude dependence on detector and OCR precision, the small evaluation set, and\nresidual errors at nodes with multiple incoming edges. Future work will enlarge\nthe benchmark with synthetic and handwritten flowcharts and assess the approach\non Business Process Model and Notation (BPMN) and Unified Modeling Language\n(UML).",
      "tldr_zh": "该研究针对视觉语言模型 (VLM) 在流程图理解中常误解方向箭头和图形拓扑的问题，提出了一种Arrow-Guided VLM方法，通过一个七阶段管道增强流程图解析。该管道包括：(1) 箭头感知的节点和端点检测；(2) 光学字符识别 (OCR) 提取节点文本；以及(3) 构建结构化提示来引导VLM。在一个由30个注释流程图提炼的90个问题基准测试中，该方法无需任务特定微调，将整体准确率从80%提高到89%，尤其在下一步骤查询上从25/30提升至30/30 (100%)。尽管存在依赖检测器和OCR精度的限制，未来工作将扩大基准测试并评估在Business Process Model and Notation (BPMN) 和Unified Modeling Language (UML)上的表现。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages, 1 figures,",
      "pdf_url": "http://arxiv.org/pdf/2505.07864v1",
      "published_date": "2025-05-09 04:27:36 UTC",
      "updated_date": "2025-05-09 04:27:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:27:58.314097"
    },
    {
      "arxiv_id": "2505.05768v1",
      "title": "Predicting Diabetic Macular Edema Treatment Responses Using OCT: Dataset and Methods of APTOS Competition",
      "title_zh": "翻译失败",
      "authors": [
        "Weiyi Zhang",
        "Peranut Chotcomwongse",
        "Yinwen Li",
        "Pusheng Xu",
        "Ruijie Yao",
        "Lianhao Zhou",
        "Yuxuan Zhou",
        "Hui Feng",
        "Qiping Zhou",
        "Xinyue Wang",
        "Shoujin Huang",
        "Zihao Jin",
        "Florence H. T. Chung",
        "Shujun Wang",
        "Yalin Zheng",
        "Mingguang He",
        "Danli Shi",
        "Paisan Ruamviboonsuk"
      ],
      "abstract": "Diabetic macular edema (DME) significantly contributes to visual impairment\nin diabetic patients. Treatment responses to intravitreal therapies vary,\nhighlighting the need for patient stratification to predict therapeutic\nbenefits and enable personalized strategies. To our knowledge, this study is\nthe first to explore pre-treatment stratification for predicting DME treatment\nresponses. To advance this research, we organized the 2nd Asia-Pacific\nTele-Ophthalmology Society (APTOS) Big Data Competition in 2021. The\ncompetition focused on improving predictive accuracy for anti-VEGF therapy\nresponses using ophthalmic OCT images. We provided a dataset containing tens of\nthousands of OCT images from 2,000 patients with labels across four sub-tasks.\nThis paper details the competition's structure, dataset, leading methods, and\nevaluation metrics. The competition attracted strong scientific community\nparticipation, with 170 teams initially registering and 41 reaching the final\nround. The top-performing team achieved an AUC of 80.06%, highlighting the\npotential of AI in personalized DME treatment and clinical decision-making.",
      "tldr_zh": "本研究首次探索使用治疗前分层预测糖尿病黄斑水肿(DME)对抗VEGF疗法的响应，以实现个性化治疗策略和改善患者预后。研究组织了2021年APTOS大数据库比赛，提供了一个数据集，包含数万张OCT图像来自2000名患者，并涵盖四个子任务。比赛聚焦于提升OCT图像预测准确性，吸引了170个团队注册，41个进入决赛。顶尖团队的AUC达到80.06%，突显AI在DME个性化治疗和临床决策中的潜力。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "42 pages,5 tables, 12 figures, challenge report",
      "pdf_url": "http://arxiv.org/pdf/2505.05768v1",
      "published_date": "2025-05-09 04:12:05 UTC",
      "updated_date": "2025-05-09 04:12:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:28:10.772094"
    },
    {
      "arxiv_id": "2505.05762v1",
      "title": "Multi-Agent Systems for Robotic Autonomy with LLMs",
      "title_zh": "基于 LLMs 的机器人自治多智能体系统",
      "authors": [
        "Junhong Chen",
        "Ziqi Yang",
        "Haoyuan G Xu",
        "Dandan Zhang",
        "George Mylonas"
      ],
      "abstract": "Since the advent of Large Language Models (LLMs), various research based on\nsuch models have maintained significant academic attention and impact,\nespecially in AI and robotics. In this paper, we propose a multi-agent\nframework with LLMs to construct an integrated system for robotic task\nanalysis, mechanical design, and path generation. The framework includes three\ncore agents: Task Analyst, Robot Designer, and Reinforcement Learning Designer.\nOutputs are formatted as multimodal results, such as code files or technical\nreports, for stronger understandability and usability. To evaluate\ngeneralizability comparatively, we conducted experiments with models from both\nGPT and DeepSeek. Results demonstrate that the proposed system can design\nfeasible robots with control strategies when appropriate task inputs are\nprovided, exhibiting substantial potential for enhancing the efficiency and\naccessibility of robotic system development in research and industrial\napplications.",
      "tldr_zh": "该论文提出了一种基于大型语言模型 (LLMs) 的多智能体框架，用于机器人自治系统的任务分析、机械设计和路径生成。该框架包括三个核心代理：Task Analyst、Robot Designer 和 Reinforcement Learning Designer，这些代理输出多模态结果，如代码文件或技术报告，以提升系统的可理解性和可用性。通过使用 GPT 和 DeepSeek 模型进行的实验表明，该系统在提供适当任务输入时，能设计出可行的机器人和控制策略，从而显著提高机器人系统在研究和工业应用中的开发效率和可访问性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "11 pages, 2 figures, 5 tables, submitted for publication",
      "pdf_url": "http://arxiv.org/pdf/2505.05762v1",
      "published_date": "2025-05-09 03:52:37 UTC",
      "updated_date": "2025-05-09 03:52:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:28:21.771712"
    },
    {
      "arxiv_id": "2505.05758v2",
      "title": "APOLLO: Automated LLM and Lean Collaboration for Advanced Formal Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Azim Ospanov",
        "Farzan Farnia",
        "Roozbeh Yousefzadeh"
      ],
      "abstract": "Formal reasoning and automated theorem proving constitute a challenging\nsubfield of machine learning, in which machines are tasked with proving\nmathematical theorems using formal languages like Lean. A formal verification\nsystem can check whether a formal proof is correct or not almost\ninstantaneously, but generating a completely correct formal proof with large\nlanguage models (LLMs) remains a formidable task. The usual approach in the\nliterature is to prompt the LLM many times (up to several thousands) until one\nof the generated proofs passes the verification system. In this work, we\npresent APOLLO (Automated PrOof repair via LLM and Lean cOllaboration), a\nmodular, model-agnostic pipeline that combines the strengths of the Lean\ncompiler with an LLM's reasoning abilities to achieve better proof-generation\nresults at a low sampling budget. Apollo directs a fully automated process in\nwhich the LLM generates proofs for theorems, a set of agents analyze the\nproofs, fix the syntax errors, identify the mistakes in the proofs using Lean,\nisolate failing sub-lemmas, utilize automated solvers, and invoke an LLM on\neach remaining goal with a low top-K budget. The repaired sub-proofs are\nrecombined and reverified, iterating up to a user-controlled maximum number of\nattempts. On the miniF2F benchmark, we establish a new state-of-the-art\naccuracy of 75.0% among 7B-parameter models while keeping the sampling budget\nbelow one thousand. Moreover, Apollo raises the state-of-the-art accuracy for\nGoedel-Prover-SFT to 65.6% while cutting sample complexity from 25,600 to a few\nhundred. General-purpose models (o3-mini, o4-mini) jump from 3-7% to over 40%\naccuracy. Our results demonstrate that targeted, compiler-guided repair of LLM\noutputs yields dramatic gains in both efficiency and correctness, suggesting a\ngeneral paradigm for scalable automated theorem proving.",
      "tldr_zh": "该研究引入了 APOLLO 框架，这是一个模块化、模型无关的管道，将大型语言模型（LLMs）和 Lean 编译器相结合，用于高效的自动定理证明。APOLLO 通过让 LLMs 生成初始证明、代理修复语法错误和逻辑问题、隔离失败子引理、使用自动求解器并迭代验证，来显著降低采样预算并提升准确率。在 miniF2F 基准测试中，APOLLO 使 7B 参数模型达到 75.0% 的新状态-of-the-art 准确率，并将其他模型如 Goedel-Prover-SFT 和通用模型的性能大幅提升，同时将采样量从数千减少到几百。该框架证明了编译器引导的修复方法在可扩展自动定理证明中的潜力，提高了效率和正确性。",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05758v2",
      "published_date": "2025-05-09 03:38:31 UTC",
      "updated_date": "2025-05-12 08:03:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:28:34.559395"
    },
    {
      "arxiv_id": "2505.05756v1",
      "title": "Evolutionary thoughts: integration of large language models and evolutionary algorithms",
      "title_zh": "进化思想：大语言模型与进化算法的整合",
      "authors": [
        "Antonio Jimeno Yepes",
        "Pieter Barnard"
      ],
      "abstract": "Large Language Models (LLMs) have unveiled remarkable capabilities in\nunderstanding and generating both natural language and code, but LLM reasoning\nis prone to hallucination and struggle with complex, novel scenarios, often\ngetting stuck on partial or incorrect solutions. However, the inherent ability\nof Evolutionary Algorithms (EAs) to explore extensive and complex search spaces\nmakes them particularly effective in scenarios where traditional optimization\nmethodologies may falter. However, EAs explore a vast search space when applied\nto complex problems.\n  To address the computational bottleneck of evaluating large populations,\nparticularly crucial for complex evolutionary tasks, we introduce a highly\nefficient evaluation framework. This implementation maintains compatibility\nwith existing primitive definitions, ensuring the generation of valid\nindividuals.\n  Using LLMs, we propose an enhanced evolutionary search strategy that enables\na more focused exploration of expansive solution spaces. LLMs facilitate the\ngeneration of superior candidate solutions, as evidenced by empirical results\ndemonstrating their efficacy in producing improved outcomes.",
      "tldr_zh": "本研究探讨了大型语言模型(LLMs)和进化算法(EAs)的整合，以解决LLMs易出现幻觉(hallucination)和在复杂场景中卡住的问题，以及EAs在计算密集型搜索中的瓶颈。论文引入了一个高效评估框架，确保生成有效个体，并利用LLMs增强进化搜索策略，实现对广阔解决方案空间的更聚焦探索。实验结果显示，这种整合方法能产生更优的候选解决方案，证明了其在复杂优化任务中的有效性。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05756v1",
      "published_date": "2025-05-09 03:32:18 UTC",
      "updated_date": "2025-05-09 03:32:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:28:44.985555"
    },
    {
      "arxiv_id": "2505.05753v1",
      "title": "Towards Embodiment Scaling Laws in Robot Locomotion",
      "title_zh": "翻译失败",
      "authors": [
        "Bo Ai",
        "Liu Dai",
        "Nico Bohlinger",
        "Dichen Li",
        "Tongzhou Mu",
        "Zhanxin Wu",
        "K. Fay",
        "Henrik I. Christensen",
        "Jan Peters",
        "Hao Su"
      ],
      "abstract": "Developing generalist agents that can operate across diverse tasks,\nenvironments, and physical embodiments is a grand challenge in robotics and\nartificial intelligence. In this work, we focus on the axis of embodiment and\ninvestigate embodiment scaling laws$\\unicode{x2013}$the hypothesis that\nincreasing the number of training embodiments improves generalization to unseen\nones. Using robot locomotion as a test bed, we procedurally generate a dataset\nof $\\sim$1,000 varied embodiments, spanning humanoids, quadrupeds, and\nhexapods, and train generalist policies capable of handling diverse observation\nand action spaces on random subsets. We find that increasing the number of\ntraining embodiments improves generalization to unseen ones, and scaling\nembodiments is more effective in enabling embodiment-level generalization than\nscaling data on small, fixed sets of embodiments. Notably, our best policy,\ntrained on the full dataset, zero-shot transfers to novel embodiments in the\nreal world, such as Unitree Go2 and H1. These results represent a step toward\ngeneral embodied intelligence, with potential relevance to adaptive control for\nconfigurable robots, co-design of morphology and control, and beyond.",
      "tldr_zh": "该研究探讨了机器人运动领域的“embodiment scaling laws”，即通过增加训练中物理形态的数量来提升对未见形态的泛化能力。研究者生成了一个约1000个多样化形态的数据集，包括人形、四足和六足机器人，并训练通用策略以处理不同的观察和动作空间。结果显示，增加训练形态的数量比在固定形态上扩展数据更有效地提升泛化性能，且最佳策略实现了零-shot transfers，在真实世界中成功应用于Unitree Go2和H1机器人。这些发现为通用具身智能铺平了道路，可能应用于可配置机器人的自适应控制和形态控制的共同设计。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "32 pages. Project website: https://embodiment-scaling-laws.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2505.05753v1",
      "published_date": "2025-05-09 03:25:43 UTC",
      "updated_date": "2025-05-09 03:25:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:28:57.499107"
    },
    {
      "arxiv_id": "2505.06321v2",
      "title": "Learn to Think: Bootstrapping LLM Reasoning Capability Through Graph Representation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Hang Gao",
        "Chenhao Zhang",
        "Tie Wang",
        "Junsuo Zhao",
        "Fengge Wu",
        "Changwen Zheng",
        "Huaping Liu"
      ],
      "abstract": "Large Language Models (LLMs) have achieved remarkable success across various\ndomains. However, they still face significant challenges, including high\ncomputational costs for training and limitations in solving complex reasoning\nproblems. Although existing methods have extended the reasoning capabilities of\nLLMs through structured paradigms, these approaches often rely on task-specific\nprompts and predefined reasoning processes, which constrain their flexibility\nand generalizability. To address these limitations, we propose a novel\nframework that leverages graph learning to enable more flexible and adaptive\nreasoning capabilities for LLMs. Specifically, this approach models the\nreasoning process of a problem as a graph and employs LLM-based graph learning\nto guide the adaptive generation of each reasoning step. To further enhance the\nadaptability of the model, we introduce a Graph Neural Network (GNN) module to\nperform representation learning on the generated reasoning process, enabling\nreal-time adjustments to both the model and the prompt. Experimental results\ndemonstrate that this method significantly improves reasoning performance\nacross multiple tasks without requiring additional training or task-specific\nprompt design. Code can be found in https://github.com/zch65458525/L2T.",
      "tldr_zh": "该论文提出了一种新框架，通过图表示学习(Graph Representation Learning)来提升大型语言模型(LLMs)的推理能力，解决现有方法依赖任务特定提示和预定义过程的局限性。框架将问题推理过程建模为图，利用LLM-based 图学习指导自适应推理步骤生成，并引入Graph Neural Network (GNN)模块进行推理过程的表示学习，实现模型和提示的实时调整。实验结果表明，该方法无需额外训练或任务特定设计，即可显著提高多个任务的推理性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by IJCAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.06321v2",
      "published_date": "2025-05-09 02:51:22 UTC",
      "updated_date": "2025-05-17 00:10:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:29:09.839436"
    },
    {
      "arxiv_id": "2505.05738v1",
      "title": "Accurate and Efficient Multivariate Time Series Forecasting via Offline Clustering",
      "title_zh": "通过离线聚类实现准确且高效的多变量时间序列预测",
      "authors": [
        "Yiming Niu",
        "Jinliang Deng",
        "Lulu Zhang",
        "Zimu Zhou",
        "Yongxin Tong"
      ],
      "abstract": "Accurate and efficient multivariate time series (MTS) forecasting is\nessential for applications such as traffic management and weather prediction,\nwhich depend on capturing long-range temporal dependencies and interactions\nbetween entities. Existing methods, particularly those based on Transformer\narchitectures, compute pairwise dependencies across all time steps, leading to\na computational complexity that scales quadratically with the length of the\ninput. To overcome these challenges, we introduce the Forecaster with Offline\nClustering Using Segments (FOCUS), a novel approach to MTS forecasting that\nsimplifies long-range dependency modeling through the use of prototypes\nextracted via offline clustering. These prototypes encapsulate high-level\nevents in the real-world system underlying the data, summarizing the key\ncharacteristics of similar time segments. In the online phase, FOCUS\ndynamically adapts these patterns to the current input and captures\ndependencies between the input segment and high-level events, enabling both\naccurate and efficient forecasting. By identifying prototypes during the\noffline clustering phase, FOCUS reduces the computational complexity of\nmodeling long-range dependencies in the online phase to linear scaling.\nExtensive experiments across diverse benchmarks demonstrate that FOCUS achieves\nstate-of-the-art accuracy while significantly reducing computational costs.",
      "tldr_zh": "本研究针对多变量时间序列（MTS）预测问题，提出了一种准确且高效的方法，即Forecaster with Offline Clustering Using Segments (FOCUS)，以解决现有基于Transformer架构模型的计算复杂度随输入长度平方增长的挑战。FOCUS通过离线聚类提取原型，这些原型总结了数据中高水平事件和类似时间段的关键特征，并在在线阶段动态适应输入以捕捉长程依赖关系，从而将建模复杂度降低到线性级别。实验结果显示，在多种基准测试中，FOCUS实现了最先进的预测准确性，同时显著降低了计算成本。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05738v1",
      "published_date": "2025-05-09 02:34:06 UTC",
      "updated_date": "2025-05-09 02:34:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:29:21.754146"
    },
    {
      "arxiv_id": "2505.05710v1",
      "title": "HyperspectralMAE: The Hyperspectral Imagery Classification Model using Fourier-Encoded Dual-Branch Masked Autoencoder",
      "title_zh": "翻译失败",
      "authors": [
        "Wooyoung Jeong",
        "Hyun Jae Park",
        "Seonghun Jeong",
        "Jong Wook Jang",
        "Tae Hoon Lim",
        "Dae Seoung Kim"
      ],
      "abstract": "Hyperspectral imagery provides rich spectral detail but poses unique\nchallenges because of its high dimensionality in both spatial and spectral\ndomains. We propose \\textit{HyperspectralMAE}, a Transformer-based foundation\nmodel for hyperspectral data that employs a \\textit{dual masking} strategy:\nduring pre-training we randomly occlude 50\\% of spatial patches and 50\\% of\nspectral bands. This forces the model to learn representations capable of\nreconstructing missing information across both dimensions. To encode spectral\norder, we introduce learnable harmonic Fourier positional embeddings based on\nwavelength. The reconstruction objective combines mean-squared error (MSE) with\nthe spectral angle mapper (SAM) to balance pixel-level accuracy and\nspectral-shape fidelity.\n  The resulting model contains about $1.8\\times10^{8}$ parameters and produces\n768-dimensional embeddings, giving it sufficient capacity for transfer\nlearning. We pre-trained HyperspectralMAE on two large hyperspectral corpora --\nNASA EO-1 Hyperion ($\\sim$1\\,600 scenes, $\\sim$$3\\times10^{11}$ pixel spectra)\nand DLR EnMAP Level-0 ($\\sim$1\\,300 scenes, $\\sim$$3\\times10^{11}$ pixel\nspectra) -- and fine-tuned it for land-cover classification on the Indian Pines\nbenchmark. HyperspectralMAE achieves state-of-the-art transfer-learning\naccuracy on Indian Pines, confirming that masked dual-dimensional pre-training\nyields robust spectral-spatial representations. These results demonstrate that\ndual masking and wavelength-aware embeddings advance hyperspectral image\nreconstruction and downstream analysis.",
      "tldr_zh": "本研究提出 HyperspectralMAE，一种基于 Transformer 的高光谱图像分类模型，采用双重掩码策略（随机遮挡 50% 的空间补丁和 50% 的光谱带）以及基于波长的可学习谐波 Fourier 位置嵌入，以有效处理高维空间和光谱数据。重建目标结合均方误差 (MSE) 和光谱角度映射器 (SAM)，平衡像素级精度和光谱形状保真度，使模型产生 768 维鲁棒嵌入。实验结果显示，该模型在 NASA EO-1 Hyperion 和 DLR EnMAP 数据集上预训练后，在 Indian Pines 土地覆盖分类基准上实现了最先进的转移学习准确率，证明双重掩码和波长感知嵌入显著提升了高光谱图像重建和下游分析性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05710v1",
      "published_date": "2025-05-09 01:16:42 UTC",
      "updated_date": "2025-05-09 01:16:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:29:35.109411"
    },
    {
      "arxiv_id": "2505.05704v1",
      "title": "Assessing Robustness to Spurious Correlations in Post-Training Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Julia Shuieh",
        "Prasann Singhal",
        "Apaar Shanker",
        "John Heyer",
        "George Pu",
        "Samuel Denton"
      ],
      "abstract": "Supervised and preference-based fine-tuning techniques have become popular\nfor aligning large language models (LLMs) with user intent and correctness\ncriteria. However, real-world training data often exhibits spurious\ncorrelations -- arising from biases, dataset artifacts, or other \"shortcut\"\nfeatures -- that can compromise a model's performance or generalization. In\nthis paper, we systematically evaluate three post-training algorithms --\nSupervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and KTO\n(Kahneman-Tversky Optimization) -- across a diverse set of synthetic tasks and\nspuriousness conditions. Our tasks span mathematical reasoning, constrained\ninstruction-following, and document-grounded question answering. We vary the\ndegree of spurious correlation (10% vs. 90%) and investigate two forms of\nartifacts: \"Feature Ambiguity\" and \"Distributional Narrowness.\" Our results\nshow that the models often but not always degrade under higher spuriousness.\nThe preference-based methods (DPO/KTO) can demonstrate relative robustness in\nmathematical reasoning tasks. By contrast, SFT maintains stronger performance\nin complex, context-intensive tasks. These findings highlight that no single\npost-training strategy universally outperforms in all scenarios; the best\nchoice depends on the type of target task and the nature of spurious\ncorrelations.",
      "tldr_zh": "这篇论文评估了后训练语言模型（LLMs）对虚假相关性（spurious correlations）的鲁棒性，比较了 Supervised Fine-Tuning (SFT)、Direct Preference Optimization (DPO) 和 KTO (Kahneman-Tversky Optimization) 三种算法在合成任务中的表现。研究涉及数学推理、受限指令跟随和文档基础问答等任务，并通过变异虚假相关性程度（10% vs. 90%）和伪像形式（如 Feature Ambiguity 和 Distributional Narrowness）来模拟真实数据偏差。结果表明，偏好-based 方法（DPO 和 KTO）在数学推理任务中显示出相对鲁棒性，而 SFT 在复杂、上下文密集任务中保持更强性能；总体上，没有单一策略在所有场景中优越，选择取决于任务类型和虚假相关性的性质。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ICLR '25 Workshop on Spurious Correlation and Shortcut Learning",
      "pdf_url": "http://arxiv.org/pdf/2505.05704v1",
      "published_date": "2025-05-09 00:39:43 UTC",
      "updated_date": "2025-05-09 00:39:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:29:47.542271"
    },
    {
      "arxiv_id": "2505.05701v1",
      "title": "Pretraining a Shared Q-Network for Data-Efficient Offline Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jongchan Park",
        "Mingyu Park",
        "Donghwan Lee"
      ],
      "abstract": "Offline reinforcement learning (RL) aims to learn a policy from a static\ndataset without further interactions with the environment. Collecting\nsufficiently large datasets for offline RL is exhausting since this data\ncollection requires colossus interactions with environments and becomes tricky\nwhen the interaction with the environment is restricted. Hence, how an agent\nlearns the best policy with a minimal static dataset is a crucial issue in\noffline RL, similar to the sample efficiency problem in online RL. In this\npaper, we propose a simple yet effective plug-and-play pretraining method to\ninitialize a feature of a $Q$-network to enhance data efficiency in offline RL.\nSpecifically, we introduce a shared $Q$-network structure that outputs\npredictions of the next state and $Q$-value. We pretrain the shared $Q$-network\nthrough a supervised regression task that predicts a next state and trains the\nshared $Q$-network using diverse offline RL methods. Through extensive\nexperiments, we empirically demonstrate that our method enhances the\nperformance of existing popular offline RL methods on the D4RL, Robomimic and\nV-D4RL benchmarks. Furthermore, we show that our method significantly boosts\ndata-efficient offline RL across various data qualities and data distributions\ntrough D4RL and ExoRL benchmarks. Notably, our method adapted with only 10% of\nthe dataset outperforms standard algorithms even with full datasets.",
      "tldr_zh": "本论文针对离线强化学习（Offline RL）的样本效率问题，提出了一种简单有效的预训练方法，用于初始化共享 Q-Network 的特征，以最小化静态数据集需求。该方法通过一个共享 Q-Network 结构预测下一个状态和 Q 值，并采用监督回归任务进行预训练，随后应用于各种离线 RL 方法。实验结果显示，该方法在 D4RL、Robomimic 和 V-D4RL 基准上显著提升了现有算法的性能，即使使用仅 10% 的数据集，也能超越标准算法在完整数据集上的表现，尤其适用于不同数据质量和分布的场景。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05701v1",
      "published_date": "2025-05-09 00:26:01 UTC",
      "updated_date": "2025-05-09 00:26:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:29:57.941050"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 80,
  "processed_papers_count": 80,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-24T21:30:16.541249"
}