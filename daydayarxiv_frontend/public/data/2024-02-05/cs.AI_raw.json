[
  {
    "arxiv_id": "2402.03590v1",
    "title": "Assessing the Impact of Distribution Shift on Reinforcement Learning Performance",
    "authors": [
      "Ted Fujimoto",
      "Joshua Suetterlein",
      "Samrat Chatterjee",
      "Auroop Ganguly"
    ],
    "abstract": "Research in machine learning is making progress in fixing its own\nreproducibility crisis. Reinforcement learning (RL), in particular, faces its\nown set of unique challenges. Comparison of point estimates, and plots that\nshow successful convergence to the optimal policy during training, may\nobfuscate overfitting or dependence on the experimental setup. Although\nresearchers in RL have proposed reliability metrics that account for\nuncertainty to better understand each algorithm's strengths and weaknesses, the\nrecommendations of past work do not assume the presence of out-of-distribution\nobservations. We propose a set of evaluation methods that measure the\nrobustness of RL algorithms under distribution shifts. The tools presented here\nargue for the need to account for performance over time while the agent is\nacting in its environment. In particular, we recommend time series analysis as\na method of observational RL evaluation. We also show that the unique\nproperties of RL and simulated dynamic environments allow us to make stronger\nassumptions to justify the measurement of causal impact in our evaluations. We\nthen apply these tools to single-agent and multi-agent environments to show the\nimpact of introducing distribution shifts during test time. We present this\nmethodology as a first step toward rigorous RL evaluation in the presence of\ndistribution shifts.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "Poster at the Workshop on Regulatable Machine Learning at the 37th\n  Conference on Neural Information Processing Systems (RegML @ NeurIPS 2023)",
    "pdf_url": "http://arxiv.org/pdf/2402.03590v1",
    "published_date": "2024-02-05 23:50:55 UTC",
    "updated_date": "2024-02-05 23:50:55 UTC"
  },
  {
    "arxiv_id": "2402.03588v1",
    "title": "Continual Domain Adversarial Adaptation via Double-Head Discriminators",
    "authors": [
      "Yan Shen",
      "Zhanghexuan Ji",
      "Chunwei Ma",
      "Mingchen Gao"
    ],
    "abstract": "Domain adversarial adaptation in a continual setting poses a significant\nchallenge due to the limitations on accessing previous source domain data.\nDespite extensive research in continual learning, the task of adversarial\nadaptation cannot be effectively accomplished using only a small number of\nstored source domain data, which is a standard setting in memory replay\napproaches. This limitation arises from the erroneous empirical estimation of\n$\\gH$-divergence with few source domain samples. To tackle this problem, we\npropose a double-head discriminator algorithm, by introducing an addition\nsource-only domain discriminator that are trained solely on source learning\nphase. We prove that with the introduction of a pre-trained source-only domain\ndiscriminator, the empirical estimation error of $\\gH$-divergence related\nadversarial loss is reduced from the source domain side. Further experiments on\nexisting domain adaptation benchmark show that our proposed algorithm achieves\nmore than 2$\\%$ improvement on all categories of target domain adaptation task\nwhile significantly mitigating the forgetting on source domain.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "AISTATS 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.03588v1",
    "published_date": "2024-02-05 23:46:03 UTC",
    "updated_date": "2024-02-05 23:46:03 UTC"
  },
  {
    "arxiv_id": "2402.03583v3",
    "title": "MQuinE: a cure for \"Z-paradox\" in knowledge graph embedding models",
    "authors": [
      "Yang Liu",
      "Huang Fang",
      "Yunfeng Cai",
      "Mingming Sun"
    ],
    "abstract": "Knowledge graph embedding (KGE) models achieved state-of-the-art results on\nmany knowledge graph tasks including link prediction and information retrieval.\nDespite the superior performance of KGE models in practice, we discover a\ndeficiency in the expressiveness of some popular existing KGE models called\n\\emph{Z-paradox}. Motivated by the existence of Z-paradox, we propose a new KGE\nmodel called \\emph{MQuinE} that does not suffer from Z-paradox while preserves\nstrong expressiveness to model various relation patterns including\nsymmetric/asymmetric, inverse, 1-N/N-1/N-N, and composition relations with\ntheoretical justification. Experiments on real-world knowledge bases indicate\nthat Z-paradox indeed degrades the performance of existing KGE models, and can\ncause more than 20\\% accuracy drop on some challenging test samples. Our\nexperiments further demonstrate that MQuinE can mitigate the negative impact of\nZ-paradox and outperform existing KGE models by a visible margin on link\nprediction tasks.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SI",
    "comment": "18pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2402.03583v3",
    "published_date": "2024-02-05 23:20:05 UTC",
    "updated_date": "2024-09-20 05:31:57 UTC"
  },
  {
    "arxiv_id": "2402.03578v2",
    "title": "LLM Multi-Agent Systems: Challenges and Open Problems",
    "authors": [
      "Shanshan Han",
      "Qifan Zhang",
      "Yuhang Yao",
      "Weizhao Jin",
      "Zhaozhuo Xu"
    ],
    "abstract": "This paper explores multi-agent systems and identify challenges that remain\ninadequately addressed. By leveraging the diverse capabilities and roles of\nindividual agents, multi-agent systems can tackle complex tasks through agent\ncollaboration. We discuss optimizing task allocation, fostering robust\nreasoning through iterative debates, managing complex and layered context\ninformation, and enhancing memory management to support the intricate\ninteractions within multi-agent systems. We also explore potential applications\nof multi-agent systems in blockchain systems to shed light on their future\ndevelopment and application in real-world distributed systems.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03578v2",
    "published_date": "2024-02-05 23:06:42 UTC",
    "updated_date": "2025-05-12 18:42:44 UTC"
  },
  {
    "arxiv_id": "2402.03575v2",
    "title": "Toward Human-AI Alignment in Large-Scale Multi-Player Games",
    "authors": [
      "Sugandha Sharma",
      "Guy Davidson",
      "Khimya Khetarpal",
      "Anssi Kanervisto",
      "Udit Arora",
      "Katja Hofmann",
      "Ida Momennejad"
    ],
    "abstract": "Achieving human-AI alignment in complex multi-agent games is crucial for\ncreating trustworthy AI agents that enhance gameplay. We propose a method to\nevaluate this alignment using an interpretable task-sets framework, focusing on\nhigh-level behavioral tasks instead of low-level policies. Our approach has\nthree components. First, we analyze extensive human gameplay data from Xbox's\nBleeding Edge (100K+ games), uncovering behavioral patterns in a complex task\nspace. This task space serves as a basis set for a behavior manifold capturing\ninterpretable axes: fight-flight, explore-exploit, and solo-multi-agent.\nSecond, we train an AI agent to play Bleeding Edge using a Generative\nPretrained Causal Transformer and measure its behavior. Third, we project human\nand AI gameplay to the proposed behavior manifold to compare and contrast. This\nallows us to interpret differences in policy as higher-level behavioral\nconcepts, e.g., we find that while human players exhibit variability in\nfight-flight and explore-exploit behavior, AI players tend towards uniformity.\nFurthermore, AI agents predominantly engage in solo play, while humans often\nengage in cooperative and competitive multi-agent patterns. These stark\ndifferences underscore the need for interpretable evaluation, design, and\nintegration of AI in human-aligned applications. Our study advances the\nalignment discussion in AI and especially generative AI research, offering a\nmeasurable framework for interpretable human-agent alignment in multiplayer\ngaming.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03575v2",
    "published_date": "2024-02-05 22:55:33 UTC",
    "updated_date": "2024-06-18 20:23:37 UTC"
  },
  {
    "arxiv_id": "2402.03570v4",
    "title": "Diffusion World Model: Future Modeling Beyond Step-by-Step Rollout for Offline Reinforcement Learning",
    "authors": [
      "Zihan Ding",
      "Amy Zhang",
      "Yuandong Tian",
      "Qinqing Zheng"
    ],
    "abstract": "We introduce Diffusion World Model (DWM), a conditional diffusion model\ncapable of predicting multistep future states and rewards concurrently. As\nopposed to traditional one-step dynamics models, DWM offers long-horizon\npredictions in a single forward pass, eliminating the need for recursive\nqueries. We integrate DWM into model-based value estimation, where the\nshort-term return is simulated by future trajectories sampled from DWM. In the\ncontext of offline reinforcement learning, DWM can be viewed as a conservative\nvalue regularization through generative modeling. Alternatively, it can be seen\nas a data source that enables offline Q-learning with synthetic data. Our\nexperiments on the D4RL dataset confirm the robustness of DWM to long-horizon\nsimulation. In terms of absolute performance, DWM significantly surpasses\none-step dynamics models with a $44\\%$ performance gain, and is comparable to\nor slightly surpassing their model-free counterparts.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03570v4",
    "published_date": "2024-02-05 22:43:57 UTC",
    "updated_date": "2024-10-15 20:56:47 UTC"
  },
  {
    "arxiv_id": "2402.03563v2",
    "title": "Distinguishing the Knowable from the Unknowable with Language Models",
    "authors": [
      "Gustaf Ahdritz",
      "Tian Qin",
      "Nikhil Vyas",
      "Boaz Barak",
      "Benjamin L. Edelman"
    ],
    "abstract": "We study the feasibility of identifying epistemic uncertainty (reflecting a\nlack of knowledge), as opposed to aleatoric uncertainty (reflecting entropy in\nthe underlying distribution), in the outputs of large language models (LLMs)\nover free-form text. In the absence of ground-truth probabilities, we explore a\nsetting where, in order to (approximately) disentangle a given LLM's\nuncertainty, a significantly larger model stands in as a proxy for the ground\ntruth. We show that small linear probes trained on the embeddings of frozen,\npretrained models accurately predict when larger models will be more confident\nat the token level and that probes trained on one text domain generalize to\nothers. Going further, we propose a fully unsupervised method that achieves\nnon-trivial accuracy on the same task. Taken together, we interpret these\nresults as evidence that LLMs naturally contain internal representations of\ndifferent types of uncertainty that could potentially be leveraged to devise\nmore informative indicators of model confidence in diverse practical settings.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03563v2",
    "published_date": "2024-02-05 22:22:49 UTC",
    "updated_date": "2024-02-27 07:37:08 UTC"
  },
  {
    "arxiv_id": "2402.03561v2",
    "title": "VLN-Video: Utilizing Driving Videos for Outdoor Vision-and-Language Navigation",
    "authors": [
      "Jialu Li",
      "Aishwarya Padmakumar",
      "Gaurav Sukhatme",
      "Mohit Bansal"
    ],
    "abstract": "Outdoor Vision-and-Language Navigation (VLN) requires an agent to navigate\nthrough realistic 3D outdoor environments based on natural language\ninstructions. The performance of existing VLN methods is limited by\ninsufficient diversity in navigation environments and limited training data. To\naddress these issues, we propose VLN-Video, which utilizes the diverse outdoor\nenvironments present in driving videos in multiple cities in the U.S. augmented\nwith automatically generated navigation instructions and actions to improve\noutdoor VLN performance. VLN-Video combines the best of intuitive classical\napproaches and modern deep learning techniques, using template infilling to\ngenerate grounded navigation instructions, combined with an image rotation\nsimilarity-based navigation action predictor to obtain VLN style data from\ndriving videos for pretraining deep learning VLN models. We pre-train the model\non the Touchdown dataset and our video-augmented dataset created from driving\nvideos with three proxy tasks: Masked Language Modeling, Instruction and\nTrajectory Matching, and Next Action Prediction, so as to learn\ntemporally-aware and visually-aligned instruction representations. The learned\ninstruction representation is adapted to the state-of-the-art navigator when\nfine-tuning on the Touchdown dataset. Empirical results demonstrate that\nVLN-Video significantly outperforms previous state-of-the-art models by 2.1% in\ntask completion rate, achieving a new state-of-the-art on the Touchdown\ndataset.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "AAAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.03561v2",
    "published_date": "2024-02-05 22:20:19 UTC",
    "updated_date": "2024-02-07 18:02:51 UTC"
  },
  {
    "arxiv_id": "2402.03559v3",
    "title": "Constrained Synthesis with Projected Diffusion Models",
    "authors": [
      "Jacob K Christopher",
      "Stephen Baek",
      "Ferdinando Fioretto"
    ],
    "abstract": "This paper introduces an approach to endow generative diffusion processes the\nability to satisfy and certify compliance with constraints and physical\nprinciples. The proposed method recast the traditional sampling process of\ngenerative diffusion models as a constrained optimization problem, steering the\ngenerated data distribution to remain within a specified region to ensure\nadherence to the given constraints. These capabilities are validated on\napplications featuring both convex and challenging, non-convex, constraints as\nwell as ordinary differential equations, in domains spanning from synthesizing\nnew materials with precise morphometric properties, generating physics-informed\nmotion, optimizing paths in planning scenarios, and human motion synthesis.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Published at the 38th Conference on Neural Information Processing\n  Systems (NeurIPS 2024)",
    "pdf_url": "http://arxiv.org/pdf/2402.03559v3",
    "published_date": "2024-02-05 22:18:16 UTC",
    "updated_date": "2024-11-01 20:15:18 UTC"
  },
  {
    "arxiv_id": "2402.03539v1",
    "title": "Extended Version of: On the Structural Hardness of Answer Set Programming: Can Structure Efficiently Confine the Power of Disjunctions?",
    "authors": [
      "Markus Hecher",
      "Rafael Kiesel"
    ],
    "abstract": "Answer Set Programming (ASP) is a generic problem modeling and solving\nframework with a strong focus on knowledge representation and a rapid growth of\nindustrial applications. So far, the study of complexity resulted in\ncharacterizing hardness and determining their sources, fine-grained insights in\nthe form of dichotomy-style results, as well as detailed parameterized\ncomplexity landscapes. Unfortunately, for the well-known parameter treewidth\ndisjunctive programs require double-exponential runtime under reasonable\ncomplexity assumptions. This quickly becomes out of reach. We deal with the\nclassification of structural parameters for disjunctive ASP on the program's\nrule structure (incidence graph).\n  First, we provide a polynomial kernel to obtain single-exponential runtime in\nterms of vertex cover size, despite subset-minimization being not represented\nin the program's structure. Then we turn our attention to strictly better\nstructural parameters between vertex cover size and treewidth. Here, we provide\ndouble-exponential lower bounds for the most prominent parameters in that\nrange: treedepth, feedback vertex size, and cliquewidth. Based on this, we\nargue that unfortunately our options beyond vertex cover size are limited. Our\nresults provide an in-depth hardness study, relying on a novel reduction from\nnormal to disjunctive programs, trading the increase of complexity for an\nexponential parameter compression.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03539v1",
    "published_date": "2024-02-05 21:51:36 UTC",
    "updated_date": "2024-02-05 21:51:36 UTC"
  },
  {
    "arxiv_id": "2402.03535v1",
    "title": "Preliminary Report on Mantis Shrimp: a Multi-Survey Computer Vision Photometric Redshift Model",
    "authors": [
      "Andrew Engel",
      "Gautham Narayan",
      "Nell Byler"
    ],
    "abstract": "The availability of large, public, multi-modal astronomical datasets presents\nan opportunity to execute novel research that straddles the line between\nscience of AI and science of astronomy. Photometric redshift estimation is a\nwell-established subfield of astronomy. Prior works show that computer vision\nmodels typically outperform catalog-based models, but these models face\nadditional complexities when incorporating images from more than one instrument\nor sensor. In this report, we detail our progress creating Mantis Shrimp, a\nmulti-survey computer vision model for photometric redshift estimation that\nfuses ultra-violet (GALEX), optical (PanSTARRS), and infrared (UnWISE) imagery.\nWe use deep learning interpretability diagnostics to measure how the model\nleverages information from the different inputs. We reason about the behavior\nof the CNNs from the interpretability metrics, specifically framing the result\nin terms of physically-grounded knowledge of galaxy properties.",
    "categories": [
      "astro-ph.IM",
      "cs.AI"
    ],
    "primary_category": "astro-ph.IM",
    "comment": "4 pages, 1 figure, 1 table. Submitted to AI4Differential Equations in\n  Science Workshop at ICLR24. Public repository unavailable while under\n  institutional review",
    "pdf_url": "http://arxiv.org/pdf/2402.03535v1",
    "published_date": "2024-02-05 21:44:19 UTC",
    "updated_date": "2024-02-05 21:44:19 UTC"
  },
  {
    "arxiv_id": "2402.06660v3",
    "title": "A philosophical and ontological perspective on Artificial General Intelligence and the Metaverse",
    "authors": [
      "Martin Schmalzried"
    ],
    "abstract": "This paper leverages various philosophical and ontological frameworks to\nexplore the concept of embodied artificial general intelligence (AGI), its\nrelationship to human consciousness, and the key role of the metaverse in\nfacilitating this relationship. Several theoretical frameworks underpin this\nexploration, such as embodied cognition, Michael Levin's computational boundary\nof a \"Self,\" Donald D. Hoffman's Interface Theory of Perception, and Bernardo\nKastrup's analytical idealism, which lead to considering our perceived outer\nreality as a symbolic representation of alternate inner states of being, and\nwhere AGI could embody a different form of consciousness with a larger\ncomputational boundary. The paper further discusses the developmental stages of\nAGI, the requirements for the emergence of an embodied AGI, the importance of a\ncalibrated symbolic interface for AGI, and the key role played by the\nmetaverse, decentralized systems, open-source blockchain technology, as well as\nopen-source AI research. It also explores the idea of a feedback loop between\nAGI and human users in metaverse spaces as a tool for AGI calibration, as well\nas the role of local homeostasis and decentralized governance as preconditions\nfor achieving a stable embodied AGI. The paper concludes by emphasizing the\nimportance of achieving a certain degree of harmony in human relations and\nrecognizing the interconnectedness of humanity at a global level, as key\nprerequisites for the emergence of a stable embodied AGI.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "Presented at the conference second international conference on\n  human-centred AI ethics: seeing the human in the artificial (HCAIE 2023):\n  https://ethics-ai.eu/hcaie2023/",
    "pdf_url": "http://arxiv.org/pdf/2402.06660v3",
    "published_date": "2024-02-05 21:43:11 UTC",
    "updated_date": "2024-12-09 12:40:08 UTC"
  },
  {
    "arxiv_id": "2402.03525v1",
    "title": "Deep Reinforcement Learning for Picker Routing Problem in Warehousing",
    "authors": [
      "George Dunn",
      "Hadi Charkhgard",
      "Ali Eshragh",
      "Sasan Mahmoudinazlou",
      "Elizabeth Stojanovski"
    ],
    "abstract": "Order Picker Routing is a critical issue in Warehouse Operations Management.\nDue to the complexity of the problem and the need for quick solutions,\nsuboptimal algorithms are frequently employed in practice. However,\nReinforcement Learning offers an appealing alternative to traditional\nheuristics, potentially outperforming existing methods in terms of speed and\naccuracy. We introduce an attention based neural network for modeling picker\ntours, which is trained using Reinforcement Learning. Our method is evaluated\nagainst existing heuristics across a range of problem parameters to demonstrate\nits efficacy. A key advantage of our proposed method is its ability to offer an\noption to reduce the perceived complexity of routes.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03525v1",
    "published_date": "2024-02-05 21:25:45 UTC",
    "updated_date": "2024-02-05 21:25:45 UTC"
  },
  {
    "arxiv_id": "2402.07928v1",
    "title": "Abstracted Trajectory Visualization for Explainability in Reinforcement Learning",
    "authors": [
      "Yoshiki Takagi",
      "Roderick Tabalba",
      "Nurit Kirshenbaum",
      "Jason Leigh"
    ],
    "abstract": "Explainable AI (XAI) has demonstrated the potential to help reinforcement\nlearning (RL) practitioners to understand how RL models work. However, XAI for\nusers who do not have RL expertise (non-RL experts), has not been studied\nsufficiently. This results in a difficulty for the non-RL experts to\nparticipate in the fundamental discussion of how RL models should be designed\nfor an incoming society where humans and AI coexist. Solving such a problem\nwould enable RL experts to communicate with the non-RL experts in producing\nmachine learning solutions that better fit our society. We argue that\nabstracted trajectories, that depicts transitions between the major states of\nthe RL model, will be useful for non-RL experts to build a mental model of the\nagents. Our early results suggest that by leveraging a visualization of the\nabstracted trajectories, users without RL expertise are able to infer the\nbehavior patterns of RL.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "14pages, 11figures",
    "pdf_url": "http://arxiv.org/pdf/2402.07928v1",
    "published_date": "2024-02-05 21:17:44 UTC",
    "updated_date": "2024-02-05 21:17:44 UTC"
  },
  {
    "arxiv_id": "2402.03519v1",
    "title": "Resolving Transcription Ambiguity in Spanish: A Hybrid Acoustic-Lexical System for Punctuation Restoration",
    "authors": [
      "Xiliang Zhu",
      "Chia-Tien Chang",
      "Shayna Gardiner",
      "David Rossouw",
      "Jonas Robertson"
    ],
    "abstract": "Punctuation restoration is a crucial step after Automatic Speech Recognition\n(ASR) systems to enhance transcript readability and facilitate subsequent NLP\ntasks. Nevertheless, conventional lexical-based approaches are inadequate for\nsolving the punctuation restoration task in Spanish, where ambiguity can be\noften found between unpunctuated declaratives and questions. In this study, we\npropose a novel hybrid acoustic-lexical punctuation restoration system for\nSpanish transcription, which consolidates acoustic and lexical signals through\na modular process. Our experiment results show that the proposed system can\neffectively improve F1 score of question marks and overall punctuation\nrestoration on both public and internal Spanish conversational datasets.\nAdditionally, benchmark comparison against LLMs (Large Language Model)\nindicates the superiority of our approach in accuracy, reliability and latency.\nFurthermore, we demonstrate that the Word Error Rate (WER) of the ASR module\nalso benefits from our proposed system.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to UnImplicit workshop at EACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.03519v1",
    "published_date": "2024-02-05 21:05:35 UTC",
    "updated_date": "2024-02-05 21:05:35 UTC"
  },
  {
    "arxiv_id": "2402.03509v1",
    "title": "Evaluating the Factuality of Zero-shot Summarizers Across Varied Domains",
    "authors": [
      "Sanjana Ramprasad",
      "Kundan Krishna",
      "Zachary C Lipton",
      "Byron C Wallace"
    ],
    "abstract": "Recent work has shown that large language models (LLMs) are capable of\ngenerating summaries zero-shot (i.e., without explicit supervision) that, under\nhuman assessment, are often comparable or even preferred to manually composed\nreference summaries. However, this prior work has focussed almost exclusively\non evaluating news article summarization. How do zero-shot summarizers perform\nin other (potentially more specialized) domains? In this work we evaluate\nzero-shot generated summaries across specialized domains including biomedical\narticles, and legal bills (in addition to standard news benchmarks for\nreference). We focus especially on the factuality of outputs. We acquire\nannotations from domain experts to identify inconsistencies in summaries and\nsystematically categorize these errors. We analyze whether the prevalence of a\ngiven domain in the pretraining corpus affects extractiveness and faithfulness\nof generated summaries of articles in this domain. We release all collected\nannotations to facilitate additional research toward measuring and realizing\nfactually accurate summarization, beyond news articles. The dataset can be\ndownloaded from https://github.com/sanjanaramprasad/zero_shot_faceval_domains",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03509v1",
    "published_date": "2024-02-05 20:51:11 UTC",
    "updated_date": "2024-02-05 20:51:11 UTC"
  },
  {
    "arxiv_id": "2402.03507v1",
    "title": "Neural networks for abstraction and reasoning: Towards broad generalization in machines",
    "authors": [
      "Mikel Bober-Irizar",
      "Soumya Banerjee"
    ],
    "abstract": "For half a century, artificial intelligence research has attempted to\nreproduce the human qualities of abstraction and reasoning - creating computer\nsystems that can learn new concepts from a minimal set of examples, in settings\nwhere humans find this easy. While specific neural networks are able to solve\nan impressive range of problems, broad generalisation to situations outside\ntheir training data has proved elusive.In this work, we look at several novel\napproaches for solving the Abstraction & Reasoning Corpus (ARC), a dataset of\nabstract visual reasoning tasks introduced to test algorithms on broad\ngeneralization. Despite three international competitions with $100,000 in\nprizes, the best algorithms still fail to solve a majority of ARC tasks and\nrely on complex hand-crafted rules, without using machine learning at all. We\nrevisit whether recent advances in neural networks allow progress on this task.\n  First, we adapt the DreamCoder neurosymbolic reasoning solver to ARC.\nDreamCoder automatically writes programs in a bespoke domain-specific language\nto perform reasoning, using a neural network to mimic human intuition. We\npresent the Perceptual Abstraction and Reasoning Language (PeARL) language,\nwhich allows DreamCoder to solve ARC tasks, and propose a new recognition model\nthat allows us to significantly improve on the previous best implementation.We\nalso propose a new encoding and augmentation scheme that allows large language\nmodels (LLMs) to solve ARC tasks, and find that the largest models can solve\nsome ARC tasks. LLMs are able to solve a different group of problems to\nstate-of-the-art solvers, and provide an interesting way to complement other\napproaches. We perform an ensemble analysis, combining models to achieve better\nresults than any system alone. Finally, we publish the arckit Python library to\nmake future research on ARC easier.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "32 pages main text, 17 pages",
    "pdf_url": "http://arxiv.org/pdf/2402.03507v1",
    "published_date": "2024-02-05 20:48:57 UTC",
    "updated_date": "2024-02-05 20:48:57 UTC"
  },
  {
    "arxiv_id": "2402.03501v1",
    "title": "An Inpainting-Infused Pipeline for Attire and Background Replacement",
    "authors": [
      "Felipe Rodrigues Perche-Mahlow",
      "André Felipe-Zanella",
      "William Alberto Cruz-Castañeda",
      "Marcellus Amadeus"
    ],
    "abstract": "In recent years, groundbreaking advancements in Generative Artificial\nIntelligence (GenAI) have triggered a transformative paradigm shift,\nsignificantly influencing various domains. In this work, we specifically\nexplore an integrated approach, leveraging advanced techniques in GenAI and\ncomputer vision emphasizing image manipulation. The methodology unfolds through\nseveral stages, including depth estimation, the creation of inpaint masks based\non depth information, the generation and replacement of backgrounds utilizing\nStable Diffusion in conjunction with Latent Consistency Models (LCMs), and the\nsubsequent replacement of clothes and application of aesthetic changes through\nan inpainting pipeline. Experiments conducted in this study underscore the\nmethodology's efficacy, highlighting its potential to produce visually\ncaptivating content. The convergence of these advanced techniques allows users\nto input photographs of individuals and manipulate them to modify clothing and\nbackground based on specific prompts without manually input inpainting masks,\neffectively placing the subjects within the vast landscape of creative\nimagination.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03501v1",
    "published_date": "2024-02-05 20:34:32 UTC",
    "updated_date": "2024-02-05 20:34:32 UTC"
  },
  {
    "arxiv_id": "2402.03500v1",
    "title": "Curriculum reinforcement learning for quantum architecture search under hardware errors",
    "authors": [
      "Yash J. Patel",
      "Akash Kundu",
      "Mateusz Ostaszewski",
      "Xavier Bonet-Monroig",
      "Vedran Dunjko",
      "Onur Danaci"
    ],
    "abstract": "The key challenge in the noisy intermediate-scale quantum era is finding\nuseful circuits compatible with current device limitations. Variational quantum\nalgorithms (VQAs) offer a potential solution by fixing the circuit architecture\nand optimizing individual gate parameters in an external loop. However,\nparameter optimization can become intractable, and the overall performance of\nthe algorithm depends heavily on the initially chosen circuit architecture.\nSeveral quantum architecture search (QAS) algorithms have been developed to\ndesign useful circuit architectures automatically. In the case of parameter\noptimization alone, noise effects have been observed to dramatically influence\nthe performance of the optimizer and final outcomes, which is a key line of\nstudy. However, the effects of noise on the architecture search, which could be\njust as critical, are poorly understood. This work addresses this gap by\nintroducing a curriculum-based reinforcement learning QAS (CRLQAS) algorithm\ndesigned to tackle challenges in realistic VQA deployment. The algorithm\nincorporates (i) a 3D architecture encoding and restrictions on environment\ndynamics to explore the search space of possible circuits efficiently, (ii) an\nepisode halting scheme to steer the agent to find shorter circuits, and (iii) a\nnovel variant of simultaneous perturbation stochastic approximation as an\noptimizer for faster convergence. To facilitate studies, we developed an\noptimized simulator for our algorithm, significantly improving computational\nefficiency in simulating noisy quantum circuits by employing the Pauli-transfer\nmatrix formalism in the Pauli-Liouville basis. Numerical experiments focusing\non quantum chemistry tasks demonstrate that CRLQAS outperforms existing QAS\nalgorithms across several metrics in both noiseless and noisy environments.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "quant-ph",
    "comment": "32 pages, 11 figures, 6 tables. Accepted at ICLR 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.03500v1",
    "published_date": "2024-02-05 20:33:00 UTC",
    "updated_date": "2024-02-05 20:33:00 UTC"
  },
  {
    "arxiv_id": "2402.03494v3",
    "title": "Beyond Text: Utilizing Vocal Cues to Improve Decision Making in LLMs for Robot Navigation Tasks",
    "authors": [
      "Xingpeng Sun",
      "Haoming Meng",
      "Souradip Chakraborty",
      "Amrit Singh Bedi",
      "Aniket Bera"
    ],
    "abstract": "While LLMs excel in processing text in these human conversations, they\nstruggle with the nuances of verbal instructions in scenarios like social\nnavigation, where ambiguity and uncertainty can erode trust in robotic and\nother AI systems. We can address this shortcoming by moving beyond text and\nadditionally focusing on the paralinguistic features of these audio responses.\nThese features are the aspects of spoken communication that do not involve the\nliteral wording (lexical content) but convey meaning and nuance through how\nsomething is said. We present Beyond Text: an approach that improves LLM\ndecision-making by integrating audio transcription along with a subsection of\nthese features, which focus on the affect and more relevant in human-robot\nconversations.This approach not only achieves a 70.26% winning rate,\noutperforming existing LLMs by 22.16% to 48.30% (gemini-1.5-pro and gpt-3.5\nrespectively), but also enhances robustness against token manipulation\nadversarial attacks, highlighted by a 22.44% less decrease ratio than the\ntext-only language model in winning rate. Beyond Text' marks an advancement in\nsocial robot navigation and broader Human-Robot interactions, seamlessly\nintegrating text-based guidance with human-audio-informed language models.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "30 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.03494v3",
    "published_date": "2024-02-05 20:11:56 UTC",
    "updated_date": "2024-11-11 04:03:28 UTC"
  },
  {
    "arxiv_id": "2402.03486v1",
    "title": "Early prediction of onset of sepsis in Clinical Setting",
    "authors": [
      "Fahim Mohammad",
      "Lakshmi Arunachalam",
      "Samanway Sadhu",
      "Boudewijn Aasman",
      "Shweta Garg",
      "Adil Ahmed",
      "Silvie Colman",
      "Meena Arunachalam",
      "Sudhir Kulkarni",
      "Parsa Mirhaji"
    ],
    "abstract": "This study proposes the use of Machine Learning models to predict the early\nonset of sepsis using deidentified clinical data from Montefiore Medical Center\nin Bronx, NY, USA. A supervised learning approach was adopted, wherein an\nXGBoost model was trained utilizing 80\\% of the train dataset, encompassing 107\nfeatures (including the original and derived features). Subsequently, the model\nwas evaluated on the remaining 20\\% of the test data. The model was validated\non prospective data that was entirely unseen during the training phase. To\nassess the model's performance at the individual patient level and timeliness\nof the prediction, a normalized utility score was employed, a widely recognized\nscoring methodology for sepsis detection, as outlined in the PhysioNet Sepsis\nChallenge paper. Metrics such as F1 Score, Sensitivity, Specificity, and Flag\nRate were also devised. The model achieved a normalized utility score of 0.494\non test data and 0.378 on prospective data at threshold 0.3. The F1 scores were\n80.8\\% and 67.1\\% respectively for the test data and the prospective data for\nthe same threshold, highlighting its potential to be integrated into clinical\ndecision-making processes effectively. These results bear testament to the\nmodel's robust predictive capabilities and its potential to substantially\nimpact clinical decision-making processes.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.LG",
    "comment": "16 pages, 6 figures and 7 tables",
    "pdf_url": "http://arxiv.org/pdf/2402.03486v1",
    "published_date": "2024-02-05 19:58:40 UTC",
    "updated_date": "2024-02-05 19:58:40 UTC"
  },
  {
    "arxiv_id": "2402.03483v2",
    "title": "SWAG: Storytelling With Action Guidance",
    "authors": [
      "Zeeshan Patel",
      "Karim El-Refai",
      "Jonathan Pei",
      "Tianle Li"
    ],
    "abstract": "Automated long-form story generation typically employs long-context large\nlanguage models (LLMs) for one-shot creation, which can produce cohesive but\nnot necessarily engaging content. We introduce Storytelling With Action\nGuidance (SWAG), a novel approach to storytelling with LLMs. Our approach\nframes story writing as a search problem through a two-model feedback loop: one\nLLM generates story content, and another auxiliary LLM is used to choose the\nnext best \"action\" to steer the story's future direction. Our results show that\nSWAG can substantially outperform previous end-to-end story generation\ntechniques when evaluated by GPT-4 and through human evaluation. Our SWAG\npipeline using only small open-source models surpasses GPT-3.5-Turbo.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP Findings 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.03483v2",
    "published_date": "2024-02-05 19:55:06 UTC",
    "updated_date": "2024-10-07 22:36:38 UTC"
  },
  {
    "arxiv_id": "2402.05968v1",
    "title": "Federated Learning Priorities Under the European Union Artificial Intelligence Act",
    "authors": [
      "Herbert Woisetschläger",
      "Alexander Erben",
      "Bill Marino",
      "Shiqiang Wang",
      "Nicholas D. Lane",
      "Ruben Mayer",
      "Hans-Arno Jacobsen"
    ],
    "abstract": "The age of AI regulation is upon us, with the European Union Artificial\nIntelligence Act (AI Act) leading the way. Our key inquiry is how this will\naffect Federated Learning (FL), whose starting point of prioritizing data\nprivacy while performing ML fundamentally differs from that of centralized\nlearning. We believe the AI Act and future regulations could be the missing\ncatalyst that pushes FL toward mainstream adoption. However, this can only\noccur if the FL community reprioritizes its research focus. In our position\npaper, we perform a first-of-its-kind interdisciplinary analysis (legal and ML)\nof the impact the AI Act may have on FL and make a series of observations\nsupporting our primary position through quantitative and qualitative analysis.\nWe explore data governance issues and the concern for privacy. We establish new\nchallenges regarding performance and energy efficiency within lifecycle\nmonitoring. Taken together, our analysis suggests there is a sizable\nopportunity for FL to become a crucial component of AI Act-compliant ML systems\nand for the new regulation to drive the adoption of FL techniques in general.\nMost noteworthy are the opportunities to defend against data bias and enhance\nprivate and secure computation",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "cs.DC",
      "I.2; I.2.11; K.5"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05968v1",
    "published_date": "2024-02-05 19:52:19 UTC",
    "updated_date": "2024-02-05 19:52:19 UTC"
  },
  {
    "arxiv_id": "2402.07927v2",
    "title": "A Systematic Survey of Prompt Engineering in Large Language Models: Techniques and Applications",
    "authors": [
      "Pranab Sahoo",
      "Ayush Kumar Singh",
      "Sriparna Saha",
      "Vinija Jain",
      "Samrat Mondal",
      "Aman Chadha"
    ],
    "abstract": "Prompt engineering has emerged as an indispensable technique for extending\nthe capabilities of large language models (LLMs) and vision-language models\n(VLMs). This approach leverages task-specific instructions, known as prompts,\nto enhance model efficacy without modifying the core model parameters. Rather\nthan updating the model parameters, prompts allow seamless integration of\npre-trained models into downstream tasks by eliciting desired model behaviors\nsolely based on the given prompt. Prompts can be natural language instructions\nthat provide context to guide the model or learned vector representations that\nactivate relevant knowledge. This burgeoning field has enabled success across\nvarious applications, from question-answering to commonsense reasoning.\nHowever, there remains a lack of systematic organization and understanding of\nthe diverse prompt engineering methods and techniques. This survey paper\naddresses the gap by providing a structured overview of recent advancements in\nprompt engineering, categorized by application area. For each prompting\napproach, we provide a summary detailing the prompting methodology, its\napplications, the models involved, and the datasets utilized. We also delve\ninto the strengths and limitations of each approach and include a taxonomy\ndiagram and table summarizing datasets, models, and critical points of each\nprompting technique. This systematic analysis enables a better understanding of\nthis rapidly developing field and facilitates future research by illuminating\nopen challenges and opportunities for prompt engineering.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "12 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.07927v2",
    "published_date": "2024-02-05 19:49:13 UTC",
    "updated_date": "2025-03-16 06:23:34 UTC"
  },
  {
    "arxiv_id": "2402.03480v1",
    "title": "Trillion Parameter AI Serving Infrastructure for Scientific Discovery: A Survey and Vision",
    "authors": [
      "Nathaniel Hudson",
      "J. Gregory Pauloski",
      "Matt Baughman",
      "Alok Kamatar",
      "Mansi Sakarvadia",
      "Logan Ward",
      "Ryan Chard",
      "André Bauer",
      "Maksim Levental",
      "Wenyi Wang",
      "Will Engler",
      "Owen Price Skelly",
      "Ben Blaiszik",
      "Rick Stevens",
      "Kyle Chard",
      "Ian Foster"
    ],
    "abstract": "Deep learning methods are transforming research, enabling new techniques, and\nultimately leading to new discoveries. As the demand for more capable AI models\ncontinues to grow, we are now entering an era of Trillion Parameter Models\n(TPM), or models with more than a trillion parameters -- such as Huawei's\nPanGu-$\\Sigma$. We describe a vision for the ecosystem of TPM users and\nproviders that caters to the specific needs of the scientific community. We\nthen outline the significant technical challenges and open problems in system\ndesign for serving TPMs to enable scientific research and discovery.\nSpecifically, we describe the requirements of a comprehensive software stack\nand interfaces to support the diverse and flexible requirements of researchers.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 3 figures, accepted for publication in the proceedings of\n  the 10th IEEE/ACM International Conference on Big Data Computing,\n  Applications and Technologies (BDCAT2023)",
    "pdf_url": "http://arxiv.org/pdf/2402.03480v1",
    "published_date": "2024-02-05 19:48:31 UTC",
    "updated_date": "2024-02-05 19:48:31 UTC"
  },
  {
    "arxiv_id": "2402.03479v4",
    "title": "DRED: Zero-Shot Transfer in Reinforcement Learning via Data-Regularised Environment Design",
    "authors": [
      "Samuel Garcin",
      "James Doran",
      "Shangmin Guo",
      "Christopher G. Lucas",
      "Stefano V. Albrecht"
    ],
    "abstract": "Autonomous agents trained using deep reinforcement learning (RL) often lack\nthe ability to successfully generalise to new environments, even when these\nenvironments share characteristics with the ones they have encountered during\ntraining. In this work, we investigate how the sampling of individual\nenvironment instances, or levels, affects the zero-shot generalisation (ZSG)\nability of RL agents. We discover that, for deep actor-critic architectures\nsharing their base layers, prioritising levels according to their value loss\nminimises the mutual information between the agent's internal representation\nand the set of training levels in the generated training data. This provides a\nnovel theoretical justification for the regularisation achieved by certain\nadaptive sampling strategies. We then turn our attention to unsupervised\nenvironment design (UED) methods, which assume control over level generation.\nWe find that existing UED methods can significantly shift the training\ndistribution, which translates to low ZSG performance. To prevent both\noverfitting and distributional shift, we introduce data-regularised environment\ndesign (DRED). DRED generates levels using a generative model trained to\napproximate the ground truth distribution of an initial set of level\nparameters. Through its grounding, DRED achieves significant improvements in\nZSG over adaptive level sampling strategies and UED methods. Our code and\nexperimental data are available at https://github.com/uoe-agents/dred.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "To appear in ICML 2024. A preliminary version of this work\n  (arXiv:2310.03494) was presented at the ALOE workshop, NeurIPS 2023. arXiv\n  admin note: text overlap with arXiv:2310.03494",
    "pdf_url": "http://arxiv.org/pdf/2402.03479v4",
    "published_date": "2024-02-05 19:47:45 UTC",
    "updated_date": "2024-06-11 21:25:23 UTC"
  },
  {
    "arxiv_id": "2402.03457v1",
    "title": "Efficient and Interpretable Traffic Destination Prediction using Explainable Boosting Machines",
    "authors": [
      "Yasin Yousif",
      "Jörg Müller"
    ],
    "abstract": "Developing accurate models for traffic trajectory predictions is crucial for\nachieving fully autonomous driving. Various deep neural network models have\nbeen employed to address this challenge, but their black-box nature hinders\ntransparency and debugging capabilities in a deployed system. Glass-box models\noffer a solution by providing full interpretability through methods like\n\\ac{GAM}. In this study, we evaluate an efficient additive model called\n\\ac{EBM} for traffic prediction on three popular mixed traffic datasets:\n\\ac{SDD}, \\ac{InD}, and Argoverse. Our results show that the \\ac{EBM} models\nperform competitively in predicting pedestrian destinations within \\ac{SDD} and\n\\ac{InD} while providing modest predictions for vehicle-dominant Argoverse\ndataset. Additionally, our transparent trained models allow us to analyse\nfeature importance and interactions, as well as provide qualitative examples of\npredictions explanation. The full training code will be made public upon\npublication.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03457v1",
    "published_date": "2024-02-05 19:09:42 UTC",
    "updated_date": "2024-02-05 19:09:42 UTC"
  },
  {
    "arxiv_id": "2402.03435v1",
    "title": "Psychological Assessments with Large Language Models: A Privacy-Focused and Cost-Effective Approach",
    "authors": [
      "Sergi Blanco-Cuaresma"
    ],
    "abstract": "This study explores the use of Large Language Models (LLMs) to analyze text\ncomments from Reddit users, aiming to achieve two primary objectives: firstly,\nto pinpoint critical excerpts that support a predefined psychological\nassessment of suicidal risk; and secondly, to summarize the material to\nsubstantiate the preassigned suicidal risk level. The work is circumscribed to\nthe use of \"open-source\" LLMs that can be run locally, thereby enhancing data\nprivacy. Furthermore, it prioritizes models with low computational\nrequirements, making it accessible to both individuals and institutions\noperating on limited computing budgets. The implemented strategy only relies on\na carefully crafted prompt and a grammar to guide the LLM's text completion.\nDespite its simplicity, the evaluation metrics show outstanding results, making\nit a valuable privacy-focused and cost-effective approach. This work is part of\nthe Computational Linguistics and Clinical Psychology (CLPsych) 2024 shared\ntask.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to the Workshop on Computational Linguistics and Clinical\n  Psychology (CLPsych) at EACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.03435v1",
    "published_date": "2024-02-05 19:00:02 UTC",
    "updated_date": "2024-02-05 19:00:02 UTC"
  },
  {
    "arxiv_id": "2402.03311v1",
    "title": "HASSOD: Hierarchical Adaptive Self-Supervised Object Detection",
    "authors": [
      "Shengcao Cao",
      "Dhiraj Joshi",
      "Liang-Yan Gui",
      "Yu-Xiong Wang"
    ],
    "abstract": "The human visual perception system demonstrates exceptional capabilities in\nlearning without explicit supervision and understanding the part-to-whole\ncomposition of objects. Drawing inspiration from these two abilities, we\npropose Hierarchical Adaptive Self-Supervised Object Detection (HASSOD), a\nnovel approach that learns to detect objects and understand their compositions\nwithout human supervision. HASSOD employs a hierarchical adaptive clustering\nstrategy to group regions into object masks based on self-supervised visual\nrepresentations, adaptively determining the number of objects per image.\nFurthermore, HASSOD identifies the hierarchical levels of objects in terms of\ncomposition, by analyzing coverage relations between masks and constructing\ntree structures. This additional self-supervised learning task leads to\nimproved detection performance and enhanced interpretability. Lastly, we\nabandon the inefficient multi-round self-training process utilized in prior\nmethods and instead adapt the Mean Teacher framework from semi-supervised\nlearning, which leads to a smoother and more efficient training process.\nThrough extensive experiments on prevalent image datasets, we demonstrate the\nsuperiority of HASSOD over existing methods, thereby advancing the state of the\nart in self-supervised object detection. Notably, we improve Mask AR from 20.2\nto 22.5 on LVIS, and from 17.0 to 26.0 on SA-1B. Project page:\nhttps://HASSOD-NeurIPS23.github.io.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "NeurIPS 2023",
    "pdf_url": "http://arxiv.org/pdf/2402.03311v1",
    "published_date": "2024-02-05 18:59:41 UTC",
    "updated_date": "2024-02-05 18:59:41 UTC"
  },
  {
    "arxiv_id": "2402.03310v3",
    "title": "V-IRL: Grounding Virtual Intelligence in Real Life",
    "authors": [
      "Jihan Yang",
      "Runyu Ding",
      "Ellis Brown",
      "Xiaojuan Qi",
      "Saining Xie"
    ],
    "abstract": "There is a sensory gulf between the Earth that humans inhabit and the digital\nrealms in which modern AI agents are created. To develop AI agents that can\nsense, think, and act as flexibly as humans in real-world settings, it is\nimperative to bridge the realism gap between the digital and physical worlds.\nHow can we embody agents in an environment as rich and diverse as the one we\ninhabit, without the constraints imposed by real hardware and control? Towards\nthis end, we introduce V-IRL: a platform that enables agents to scalably\ninteract with the real world in a virtual yet realistic environment. Our\nplatform serves as a playground for developing agents that can accomplish\nvarious practical tasks and as a vast testbed for measuring progress in\ncapabilities spanning perception, decision-making, and interaction with\nreal-world data across the entire globe.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "Project page: https://virl-platform.github.io",
    "pdf_url": "http://arxiv.org/pdf/2402.03310v3",
    "published_date": "2024-02-05 18:59:36 UTC",
    "updated_date": "2024-07-18 08:08:29 UTC"
  },
  {
    "arxiv_id": "2402.03305v2",
    "title": "Do Diffusion Models Learn Semantically Meaningful and Efficient Representations?",
    "authors": [
      "Qiyao Liang",
      "Ziming Liu",
      "Ila Fiete"
    ],
    "abstract": "Diffusion models are capable of impressive feats of image generation with\nuncommon juxtapositions such as astronauts riding horses on the moon with\nproperly placed shadows. These outputs indicate the ability to perform\ncompositional generalization, but how do the models do so? We perform\ncontrolled experiments on conditional DDPMs learning to generate 2D spherical\nGaussian bumps centered at specified $x$- and $y$-positions. Our results show\nthat the emergence of semantically meaningful latent representations is key to\nachieving high performance. En route to successful performance over learning,\nthe model traverses three distinct phases of latent representations: (phase A)\nno latent structure, (phase B) a 2D manifold of disordered states, and (phase\nC) a 2D ordered manifold. Corresponding to each of these phases, we identify\nqualitatively different generation behaviors: 1) multiple bumps are generated,\n2) one bump is generated but at inaccurate $x$ and $y$ locations, 3) a bump is\ngenerated at the correct $x$ and y location. Furthermore, we show that even\nunder imbalanced datasets where features ($x$- versus $y$-positions) are\nrepresented with skewed frequencies, the learning process for $x$ and $y$ is\ncoupled rather than factorized, demonstrating that simple vanilla-flavored\ndiffusion models cannot learn efficient representations in which localization\nin $x$ and $y$ are factorized into separate 1D tasks. These findings suggest\nthe need for future work to find inductive biases that will push generative\nmodels to discover and exploit factorizable independent structures in their\ninputs, which will be required to vault these models into more data-efficient\nregimes.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.03305v2",
    "published_date": "2024-02-05 18:58:38 UTC",
    "updated_date": "2024-04-30 14:32:31 UTC"
  },
  {
    "arxiv_id": "2402.03303v1",
    "title": "Nevermind: Instruction Override and Moderation in Large Language Models",
    "authors": [
      "Edward Kim"
    ],
    "abstract": "Given the impressive capabilities of recent Large Language Models (LLMs), we\ninvestigate and benchmark the most popular proprietary and different sized open\nsource models on the task of explicit instruction following in conflicting\nsituations, e.g. overrides. These include the ability of the model to override\nthe knowledge within the weights of the model, the ability to override (or\nmoderate) extracted knowledge in the prompt, and lastly the ability to perform\na full jailbreak. Experimentation performed suggest several key findings to\nimprove instruction following - larger models perform the best in following\ninstructions that override internal and contextual instructions, and are\nobedient, even to a fault. When scaling to longer contexts via rope scaling, a\nsignificant buffer needs to be maintained from the edge of the perplexity cliff\nin order to maintain instruction following capabilities. Finally, we observe\nimproving instruction following, and subsequently instruction\noverrides/jailbreaks, is fundamentally at odds with the ability of a language\nmodel to follow given safety filters or guidelines. Thus, we postulate the most\neffective approach for safe, trustworthy AI should be dealt external to the LLM\nitself.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "11 pages",
    "pdf_url": "http://arxiv.org/pdf/2402.03303v1",
    "published_date": "2024-02-05 18:58:19 UTC",
    "updated_date": "2024-02-05 18:58:19 UTC"
  },
  {
    "arxiv_id": "2402.06659v2",
    "title": "Shadowcast: Stealthy Data Poisoning Attacks Against Vision-Language Models",
    "authors": [
      "Yuancheng Xu",
      "Jiarui Yao",
      "Manli Shu",
      "Yanchao Sun",
      "Zichu Wu",
      "Ning Yu",
      "Tom Goldstein",
      "Furong Huang"
    ],
    "abstract": "Vision-Language Models (VLMs) excel in generating textual responses from\nvisual inputs, but their versatility raises security concerns. This study takes\nthe first step in exposing VLMs' susceptibility to data poisoning attacks that\ncan manipulate responses to innocuous, everyday prompts. We introduce\nShadowcast, a stealthy data poisoning attack where poison samples are visually\nindistinguishable from benign images with matching texts. Shadowcast\ndemonstrates effectiveness in two attack types. The first is a traditional\nLabel Attack, tricking VLMs into misidentifying class labels, such as confusing\nDonald Trump for Joe Biden. The second is a novel Persuasion Attack, leveraging\nVLMs' text generation capabilities to craft persuasive and seemingly rational\nnarratives for misinformation, such as portraying junk food as healthy. We show\nthat Shadowcast effectively achieves the attacker's intentions using as few as\n50 poison samples. Crucially, the poisoned samples demonstrate transferability\nacross different VLM architectures, posing a significant concern in black-box\nsettings. Moreover, Shadowcast remains potent under realistic conditions\ninvolving various text prompts, training data augmentation, and image\ncompression techniques. This work reveals how poisoned VLMs can disseminate\nconvincing yet deceptive misinformation to everyday, benign users, emphasizing\nthe importance of data integrity for responsible VLM deployments. Our code is\navailable at: https://github.com/umd-huang-lab/VLM-Poisoning.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted by Thirty-Eighth Annual Conference on Neural Information\n  Processing Systems (Neurips 2024)",
    "pdf_url": "http://arxiv.org/pdf/2402.06659v2",
    "published_date": "2024-02-05 18:55:53 UTC",
    "updated_date": "2024-10-14 16:17:34 UTC"
  },
  {
    "arxiv_id": "2402.03300v3",
    "title": "DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models",
    "authors": [
      "Zhihong Shao",
      "Peiyi Wang",
      "Qihao Zhu",
      "Runxin Xu",
      "Junxiao Song",
      "Xiao Bi",
      "Haowei Zhang",
      "Mingchuan Zhang",
      "Y. K. Li",
      "Y. Wu",
      "Daya Guo"
    ],
    "abstract": "Mathematical reasoning poses a significant challenge for language models due\nto its complex and structured nature. In this paper, we introduce DeepSeekMath\n7B, which continues pre-training DeepSeek-Coder-Base-v1.5 7B with 120B\nmath-related tokens sourced from Common Crawl, together with natural language\nand code data. DeepSeekMath 7B has achieved an impressive score of 51.7% on the\ncompetition-level MATH benchmark without relying on external toolkits and\nvoting techniques, approaching the performance level of Gemini-Ultra and GPT-4.\nSelf-consistency over 64 samples from DeepSeekMath 7B achieves 60.9% on MATH.\nThe mathematical reasoning capability of DeepSeekMath is attributed to two key\nfactors: First, we harness the significant potential of publicly available web\ndata through a meticulously engineered data selection pipeline. Second, we\nintroduce Group Relative Policy Optimization (GRPO), a variant of Proximal\nPolicy Optimization (PPO), that enhances mathematical reasoning abilities while\nconcurrently optimizing the memory usage of PPO.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03300v3",
    "published_date": "2024-02-05 18:55:32 UTC",
    "updated_date": "2024-04-27 15:25:53 UTC"
  },
  {
    "arxiv_id": "2402.03295v1",
    "title": "Ginger: An Efficient Curvature Approximation with Linear Complexity for General Neural Networks",
    "authors": [
      "Yongchang Hao",
      "Yanshuai Cao",
      "Lili Mou"
    ],
    "abstract": "Second-order optimization approaches like the generalized Gauss-Newton method\nare considered more powerful as they utilize the curvature information of the\nobjective function with preconditioning matrices. Albeit offering tempting\ntheoretical benefits, they are not easily applicable to modern deep learning.\nThe major reason is due to the quadratic memory and cubic time complexity to\ncompute the inverse of the matrix. These requirements are infeasible even with\nstate-of-the-art hardware. In this work, we propose Ginger, an\neigendecomposition for the inverse of the generalized Gauss-Newton matrix. Our\nmethod enjoys efficient linear memory and time complexity for each iteration.\nInstead of approximating the conditioning matrix, we directly maintain its\ninverse to make the approximation more accurate. We provide the convergence\nresult of Ginger for non-convex objectives. Our experiments on different tasks\nwith different model architectures verify the effectiveness of our method. Our\ncode is publicly available.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03295v1",
    "published_date": "2024-02-05 18:51:17 UTC",
    "updated_date": "2024-02-05 18:51:17 UTC"
  },
  {
    "arxiv_id": "2402.03293v2",
    "title": "Flora: Low-Rank Adapters Are Secretly Gradient Compressors",
    "authors": [
      "Yongchang Hao",
      "Yanshuai Cao",
      "Lili Mou"
    ],
    "abstract": "Despite large neural networks demonstrating remarkable abilities to complete\ndifferent tasks, they require excessive memory usage to store the optimization\nstates for training. To alleviate this, the low-rank adaptation (LoRA) is\nproposed to reduce the optimization states by training fewer parameters.\nHowever, LoRA restricts overall weight update matrices to be low-rank, limiting\nthe model performance. In this work, we investigate the dynamics of LoRA and\nidentify that it can be approximated by a random projection. Based on this\nobservation, we propose Flora, which is able to achieve high-rank updates by\nresampling the projection matrices while enjoying the sublinear space\ncomplexity of optimization states. We conduct experiments across different\ntasks and model architectures to verify the effectiveness of our approach.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted @ ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.03293v2",
    "published_date": "2024-02-05 18:50:39 UTC",
    "updated_date": "2024-06-12 22:17:37 UTC"
  },
  {
    "arxiv_id": "2402.03290v1",
    "title": "InstanceDiffusion: Instance-level Control for Image Generation",
    "authors": [
      "Xudong Wang",
      "Trevor Darrell",
      "Sai Saketh Rambhatla",
      "Rohit Girdhar",
      "Ishan Misra"
    ],
    "abstract": "Text-to-image diffusion models produce high quality images but do not offer\ncontrol over individual instances in the image. We introduce InstanceDiffusion\nthat adds precise instance-level control to text-to-image diffusion models.\nInstanceDiffusion supports free-form language conditions per instance and\nallows flexible ways to specify instance locations such as simple single\npoints, scribbles, bounding boxes or intricate instance segmentation masks, and\ncombinations thereof. We propose three major changes to text-to-image models\nthat enable precise instance-level control. Our UniFusion block enables\ninstance-level conditions for text-to-image models, the ScaleU block improves\nimage fidelity, and our Multi-instance Sampler improves generations for\nmultiple instances. InstanceDiffusion significantly surpasses specialized\nstate-of-the-art models for each location condition. Notably, on the COCO\ndataset, we outperform previous state-of-the-art by 20.4% AP$_{50}^\\text{box}$\nfor box inputs, and 25.4% IoU for mask inputs.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Preprint; Project page:\n  https://people.eecs.berkeley.edu/~xdwang/projects/InstDiff/",
    "pdf_url": "http://arxiv.org/pdf/2402.03290v1",
    "published_date": "2024-02-05 18:49:17 UTC",
    "updated_date": "2024-02-05 18:49:17 UTC"
  },
  {
    "arxiv_id": "2402.03289v1",
    "title": "Make Every Move Count: LLM-based High-Quality RTL Code Generation Using MCTS",
    "authors": [
      "Matthew DeLorenzo",
      "Animesh Basak Chowdhury",
      "Vasudev Gohil",
      "Shailja Thakur",
      "Ramesh Karri",
      "Siddharth Garg",
      "Jeyavijayan Rajendran"
    ],
    "abstract": "Existing large language models (LLMs) for register transfer level code\ngeneration face challenges like compilation failures and suboptimal power,\nperformance, and area (PPA) efficiency. This is due to the lack of PPA\nawareness in conventional transformer decoding algorithms. In response, we\npresent an automated transformer decoding algorithm that integrates Monte Carlo\ntree-search for lookahead, guiding the transformer to produce compilable,\nfunctionally correct, and PPA-optimized code. Empirical evaluation with a\nfine-tuned language model on RTL codesets shows that our proposed technique\nconsistently generates functionally correct code compared to prompting-only\nmethods and effectively addresses the PPA-unawareness drawback of naive large\nlanguage models. For the largest design generated by the state-of-the-art LLM\n(16-bit adder), our technique can achieve a 31.8% improvement in the area-delay\nproduct.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03289v1",
    "published_date": "2024-02-05 18:47:04 UTC",
    "updated_date": "2024-02-05 18:47:04 UTC"
  },
  {
    "arxiv_id": "2402.03286v3",
    "title": "Training-Free Consistent Text-to-Image Generation",
    "authors": [
      "Yoad Tewel",
      "Omri Kaduri",
      "Rinon Gal",
      "Yoni Kasten",
      "Lior Wolf",
      "Gal Chechik",
      "Yuval Atzmon"
    ],
    "abstract": "Text-to-image models offer a new level of creative flexibility by allowing\nusers to guide the image generation process through natural language. However,\nusing these models to consistently portray the same subject across diverse\nprompts remains challenging. Existing approaches fine-tune the model to teach\nit new words that describe specific user-provided subjects or add image\nconditioning to the model. These methods require lengthy per-subject\noptimization or large-scale pre-training. Moreover, they struggle to align\ngenerated images with text prompts and face difficulties in portraying multiple\nsubjects. Here, we present ConsiStory, a training-free approach that enables\nconsistent subject generation by sharing the internal activations of the\npretrained model. We introduce a subject-driven shared attention block and\ncorrespondence-based feature injection to promote subject consistency between\nimages. Additionally, we develop strategies to encourage layout diversity while\nmaintaining subject consistency. We compare ConsiStory to a range of baselines,\nand demonstrate state-of-the-art performance on subject consistency and text\nalignment, without requiring a single optimization step. Finally, ConsiStory\ncan naturally extend to multi-subject scenarios, and even enable training-free\npersonalization for common objects.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to journal track of SIGGRAPH 2024 (TOG). Project page is at\n  https://consistory-paper.github.io",
    "pdf_url": "http://arxiv.org/pdf/2402.03286v3",
    "published_date": "2024-02-05 18:42:34 UTC",
    "updated_date": "2024-05-30 11:42:15 UTC"
  },
  {
    "arxiv_id": "2402.03284v1",
    "title": "Deal, or no deal (or who knows)? Forecasting Uncertainty in Conversations using Large Language Models",
    "authors": [
      "Anthony Sicilia",
      "Hyunwoo Kim",
      "Khyathi Raghavi Chandu",
      "Malihe Alikhani",
      "Jack Hessel"
    ],
    "abstract": "Effective interlocutors account for the uncertain goals, beliefs, and\nemotions of others. But even the best human conversationalist cannot perfectly\nanticipate the trajectory of a dialogue. How well can language models represent\ninherent uncertainty in conversations? We propose FortUne Dial, an expansion of\nthe long-standing \"conversation forecasting\" task: instead of just accuracy,\nevaluation is conducted with uncertainty-aware metrics, effectively enabling\nabstention on individual instances. We study two ways in which language models\npotentially represent outcome uncertainty (internally, using scores and\ndirectly, using tokens) and propose fine-tuning strategies to improve\ncalibration of both representations. Experiments on eight difficult negotiation\ncorpora demonstrate that our proposed fine-tuning strategies (a traditional\nsupervision strategy and an off-policy reinforcement learning strategy) can\ncalibrate smaller open-source models to compete with pre-trained models 10x\ntheir size.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "2 Figures; 7 Tables; 27 pages",
    "pdf_url": "http://arxiv.org/pdf/2402.03284v1",
    "published_date": "2024-02-05 18:39:47 UTC",
    "updated_date": "2024-02-05 18:39:47 UTC"
  },
  {
    "arxiv_id": "2402.03282v3",
    "title": "A Theoretical Framework for Partially Observed Reward-States in RLHF",
    "authors": [
      "Chinmaya Kausik",
      "Mirco Mutti",
      "Aldo Pacchiano",
      "Ambuj Tewari"
    ],
    "abstract": "The growing deployment of reinforcement learning from human feedback (RLHF)\ncalls for a deeper theoretical investigation of its underlying models. The\nprevalent models of RLHF do not account for neuroscience-backed,\npartially-observed \"internal states\" that can affect human feedback, nor do\nthey accommodate intermediate feedback during an interaction. Both of these can\nbe instrumental in speeding up learning and improving alignment. To address\nthese limitations, we model RLHF as reinforcement learning with partially\nobserved reward-states (PORRL). We accommodate two kinds of feedback $-$\ncardinal and dueling feedback. We first demonstrate that PORRL subsumes a wide\nclass of RL problems, including traditional RL, RLHF, and reward machines. For\ncardinal feedback, we present two model-based methods (POR-UCRL, POR-UCBVI). We\ngive both cardinal regret and sample complexity guarantees for the methods,\nshowing that they improve over naive history-summarization. We then discuss the\nbenefits of a model-free method like GOLF with naive history-summarization in\nsettings with recursive internal states and dense intermediate feedback. For\nthis purpose, we define a new history aware version of the Bellman-eluder\ndimension and give a new guarantee for GOLF in our setting, which can be\nexponentially sharper in illustrative examples. For dueling feedback, we show\nthat a naive reduction to cardinal feedback fails to achieve sublinear dueling\nregret. We then present the first explicit reduction that converts guarantees\nfor cardinal regret to dueling regret. In both feedback settings, we show that\nour models and guarantees generalize and extend existing ones.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "64 pages. 14 pages for main paper, 50 pages for references + appendix",
    "pdf_url": "http://arxiv.org/pdf/2402.03282v3",
    "published_date": "2024-02-05 18:38:55 UTC",
    "updated_date": "2024-11-09 07:09:00 UTC"
  },
  {
    "arxiv_id": "2402.03271v3",
    "title": "Uncertainty of Thoughts: Uncertainty-Aware Planning Enhances Information Seeking in Large Language Models",
    "authors": [
      "Zhiyuan Hu",
      "Chumin Liu",
      "Xidong Feng",
      "Yilun Zhao",
      "See-Kiong Ng",
      "Anh Tuan Luu",
      "Junxian He",
      "Pang Wei Koh",
      "Bryan Hooi"
    ],
    "abstract": "In the face of uncertainty, the ability to *seek information* is of\nfundamental importance. In many practical applications, such as medical\ndiagnosis and troubleshooting, the information needed to solve the task is not\ninitially given and has to be actively sought by asking follow-up questions\n(for example, a doctor asking a patient for more details about their symptoms).\nIn this work, we introduce Uncertainty of Thoughts (UoT), an algorithm to\naugment large language models with the ability to actively seek information by\nasking effective questions. UoT combines 1) an *uncertainty-aware simulation\napproach* which enables the model to simulate possible future scenarios and how\nlikely they are to occur, 2) *uncertainty-based rewards* motivated by\ninformation gain which incentivizes the model to seek information, and 3) a\n*reward propagation scheme* to select the optimal question to ask in a way that\nmaximizes the expected reward. In experiments on medical diagnosis,\ntroubleshooting, and the `20 Questions` game, UoT achieves an average\nperformance improvement of 38.1% in the rate of successful task completion\nacross multiple LLMs compared with direct prompting and also improves\nefficiency (i.e., the number of questions needed to complete the task). Our\ncode has been released [here](https://github.com/zhiyuanhubj/UoT)",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.03271v3",
    "published_date": "2024-02-05 18:28:44 UTC",
    "updated_date": "2024-11-13 17:10:20 UTC"
  },
  {
    "arxiv_id": "2402.03268v3",
    "title": "Understanding Reasoning Ability of Language Models From the Perspective of Reasoning Paths Aggregation",
    "authors": [
      "Xinyi Wang",
      "Alfonso Amayuelas",
      "Kexun Zhang",
      "Liangming Pan",
      "Wenhu Chen",
      "William Yang Wang"
    ],
    "abstract": "Pre-trained language models (LMs) are able to perform complex reasoning\nwithout explicit fine-tuning. To understand how pre-training with a next-token\nprediction objective contributes to the emergence of such reasoning capability,\nwe propose that we can view an LM as deriving new conclusions by aggregating\nindirect reasoning paths seen at pre-training time. We found this perspective\neffective in two important cases of reasoning: logic reasoning with knowledge\ngraphs (KGs) and chain-of-thought (CoT) reasoning. More specifically, we\nformalize the reasoning paths as random walk paths on the knowledge/reasoning\ngraphs. Analyses of learned LM distributions suggest that a weighted sum of\nrelevant random walk path probabilities is a reasonable way to explain how LMs\nreason. Experiments and analysis on multiple KG and CoT datasets reveal the\neffect of training on random walk paths and suggest that augmenting unlabeled\nrandom walk reasoning paths can improve real-world multi-step reasoning\nperformance. code: https://github.com/WANGXinyiLinda/LM_random_walk",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.03268v3",
    "published_date": "2024-02-05 18:25:51 UTC",
    "updated_date": "2024-06-20 18:46:06 UTC"
  },
  {
    "arxiv_id": "2402.03251v1",
    "title": "CLIP Can Understand Depth",
    "authors": [
      "Dunam Kim",
      "Seokju Lee"
    ],
    "abstract": "Recent studies on generalizing CLIP for monocular depth estimation reveal\nthat CLIP pre-trained on web-crawled data is inefficient for deriving proper\nsimilarities between image patches and depth-related prompts. In this paper, we\nadapt CLIP for meaningful quality of monocular depth estimation with dense\nprediction, without fine-tuning its original vision-language alignment. By\njointly training a compact deconvolutional decoder with a tiny learnable\nembedding matrix named mirror, as a static prompt for its text encoder, CLIP is\nenabled to understand depth. With this approach, our model exhibits impressive\nperformance matching several previous state-of-the-art vision-only models on\nthe NYU Depth v2 and KITTI datasets, outperforming every CLIP-based depth\nestimation model with a large margin. Experiments on temporal depth consistency\nand spatial continuity demonstrate that the prior knowledge of CLIP can be\neffectively refined by our proposed framework. Furthermore, an ablation study\non mirror proves that the resulting model estimates depth utilizing knowledge\nnot only from the image encoder but also text encoder despite not being given\nany prompt written in a human way. This research demonstrates that through\nminimal adjustments, the prior knowledge of vision-language foundation models,\nsuch as CLIP, can be generalized even to domains where learning during\npretraining is challenging. We facilitate future works focused on methods to\nadjust suboptimal prior knowledge of vision-language models using non-human\nlanguage prompts, achieving performance on par with task-specific\nstate-of-the-art methodologies.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03251v1",
    "published_date": "2024-02-05 18:09:33 UTC",
    "updated_date": "2024-02-05 18:09:33 UTC"
  },
  {
    "arxiv_id": "2402.03247v3",
    "title": "HEANA: A Hybrid Time-Amplitude Analog Optical Accelerator with Flexible Dataflows for Energy-Efficient CNN Inference",
    "authors": [
      "Sairam Sri Vatsavai",
      "Venkata Sai Praneeth Karempudi",
      "Ishan Thakkar"
    ],
    "abstract": "Several photonic microring resonators (MRRs) based analog accelerators have\nbeen proposed to accelerate the inference of integer-quantized CNNs with\nremarkably higher throughput and energy efficiency compared to their electronic\ncounterparts. However, the existing analog photonic accelerators suffer from\nthree shortcomings: (i) severe hampering of wavelength parallelism due to\nvarious crosstalk effects, (ii) inflexibility of supporting various dataflows\nother than the weight-stationary dataflow, and (iii) failure in fully\nleveraging the ability of photodetectors to perform in-situ accumulations.\nThese shortcomings collectively hamper the performance and energy efficiency of\nprior accelerators. To tackle these shortcomings, we present a novel Hybrid\ntimE Amplitude aNalog optical Accelerator, called HEANA. HEANA employs hybrid\ntime-amplitude analog optical multipliers (TAOMs) that increase the flexibility\nof HEANA to support multiple dataflows. A spectrally hitless arrangement of\nTAOMs significantly reduces the crosstalk effects, thereby increasing the\nwavelength parallelism in HEANA. Moreover, HEANA employs our invented balanced\nphoto-charge accumulators (BPCAs) that enable buffer-less, in-situ, temporal\naccumulations to eliminate the need to use reduction networks in HEANA,\nrelieving it from related latency and energy overheads. Our evaluation for the\ninference of four modern CNNs indicates that HEANA provides improvements of\natleast 66x and 84x in frames-per-second (FPS) and FPS/W (energy-efficiency),\nrespectively, for equal-area comparisons, on gmean over two MRR-based analog\nCNN accelerators from prior work.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.AR",
    "comment": "The paper is accepted at ACM TODAES",
    "pdf_url": "http://arxiv.org/pdf/2402.03247v3",
    "published_date": "2024-02-05 18:05:34 UTC",
    "updated_date": "2024-12-15 19:36:10 UTC"
  },
  {
    "arxiv_id": "2402.03246v6",
    "title": "SGS-SLAM: Semantic Gaussian Splatting For Neural Dense SLAM",
    "authors": [
      "Mingrui Li",
      "Shuhong Liu",
      "Heng Zhou",
      "Guohao Zhu",
      "Na Cheng",
      "Tianchen Deng",
      "Hongyu Wang"
    ],
    "abstract": "We present SGS-SLAM, the first semantic visual SLAM system based on Gaussian\nSplatting. It incorporates appearance, geometry, and semantic features through\nmulti-channel optimization, addressing the oversmoothing limitations of neural\nimplicit SLAM systems in high-quality rendering, scene understanding, and\nobject-level geometry. We introduce a unique semantic feature loss that\neffectively compensates for the shortcomings of traditional depth and color\nlosses in object optimization. Through a semantic-guided keyframe selection\nstrategy, we prevent erroneous reconstructions caused by cumulative errors.\nExtensive experiments demonstrate that SGS-SLAM delivers state-of-the-art\nperformance in camera pose estimation, map reconstruction, precise semantic\nsegmentation, and object-level geometric accuracy, while ensuring real-time\nrendering capabilities.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03246v6",
    "published_date": "2024-02-05 18:03:53 UTC",
    "updated_date": "2024-11-24 09:56:50 UTC"
  },
  {
    "arxiv_id": "2402.05967v7",
    "title": "The last Dance : Robust backdoor attack via diffusion models and bayesian approach",
    "authors": [
      "Orson Mengara"
    ],
    "abstract": "Diffusion models are state-of-the-art deep learning generative models that\nare trained on the principle of learning forward and backward diffusion\nprocesses via the progressive addition of noise and denoising. In this paper,\nwe aim to fool audio-based DNN models, such as those from the Hugging Face\nframework, primarily those that focus on audio, in particular transformer-based\nartificial intelligence models, which are powerful machine learning models that\nsave time and achieve results faster and more efficiently. We demonstrate the\nfeasibility of backdoor attacks (called `BacKBayDiffMod`) on audio transformers\nderived from Hugging Face, a popular framework in the world of artificial\nintelligence research. The backdoor attack developed in this paper is based on\npoisoning model training data uniquely by incorporating backdoor diffusion\nsampling and a Bayesian approach to the distribution of poisoned data.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "Preprint (Last update, will never be modified again( correction of a\n  sketch)): audio backdoor attack on Hugging Face's Transformer pre-trained\n  models. This attack incorporates state-of-the-art Bayesian techniques, a\n  modified Fokker-Planck equation (via Yang-Mills), and a diffusion model\n  approach",
    "pdf_url": "http://arxiv.org/pdf/2402.05967v7",
    "published_date": "2024-02-05 18:00:07 UTC",
    "updated_date": "2025-04-20 19:42:23 UTC"
  },
  {
    "arxiv_id": "2402.03227v4",
    "title": "IGUANe: a 3D generalizable CycleGAN for multicenter harmonization of brain MR images",
    "authors": [
      "Vincent Roca",
      "Grégory Kuchcinski",
      "Jean-Pierre Pruvo",
      "Dorian Manouvriez",
      "Renaud Lopes"
    ],
    "abstract": "In MRI studies, the aggregation of imaging data from multiple acquisition\nsites enhances sample size but may introduce site-related variabilities that\nhinder consistency in subsequent analyses. Deep learning methods for image\ntranslation have emerged as a solution for harmonizing MR images across sites.\nIn this study, we introduce IGUANe (Image Generation with Unified Adversarial\nNetworks), an original 3D model that leverages the strengths of domain\ntranslation and straightforward application of style transfer methods for\nmulticenter brain MR image harmonization. IGUANe extends CycleGAN by\nintegrating an arbitrary number of domains for training through a many-to-one\narchitecture. The framework based on domain pairs enables the implementation of\nsampling strategies that prevent confusion between site-related and biological\nvariabilities. During inference, the model can be applied to any image, even\nfrom an unknown acquisition site, making it a universal generator for\nharmonization. Trained on a dataset comprising T1-weighted images from 11\ndifferent scanners, IGUANe was evaluated on data from unseen sites. The\nassessments included the transformation of MR images with traveling subjects,\nthe preservation of pairwise distances between MR images within domains, the\nevolution of volumetric patterns related to age and Alzheimer$'$s disease (AD),\nand the performance in age regression and patient classification tasks.\nComparisons with other harmonization and normalization methods suggest that\nIGUANe better preserves individual information in MR images and is more\nsuitable for maintaining and reinforcing variabilities related to age and AD.\nFuture studies may further assess IGUANe in other multicenter contexts, either\nusing the same model or retraining it for applications to different image\nmodalities. IGUANe is available at\nhttps://github.com/RocaVincent/iguane_harmonization.git.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "29 pages, 14 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.03227v4",
    "published_date": "2024-02-05 17:38:49 UTC",
    "updated_date": "2024-11-14 14:11:57 UTC"
  },
  {
    "arxiv_id": "2402.03216v4",
    "title": "BGE M3-Embedding: Multi-Lingual, Multi-Functionality, Multi-Granularity Text Embeddings Through Self-Knowledge Distillation",
    "authors": [
      "Jianlv Chen",
      "Shitao Xiao",
      "Peitian Zhang",
      "Kun Luo",
      "Defu Lian",
      "Zheng Liu"
    ],
    "abstract": "In this paper, we present a new embedding model, called M3-Embedding, which\nis distinguished for its versatility in Multi-Linguality, Multi-Functionality,\nand Multi-Granularity. It can support more than 100 working languages, leading\nto new state-of-the-art performances on multi-lingual and cross-lingual\nretrieval tasks. It can simultaneously perform the three common retrieval\nfunctionalities of embedding model: dense retrieval, multi-vector retrieval,\nand sparse retrieval, which provides a unified model foundation for real-world\nIR applications. It is able to process inputs of different granularities,\nspanning from short sentences to long documents of up to 8192 tokens. The\neffective training of M3-Embedding involves the following technical\ncontributions. We propose a novel self-knowledge distillation approach, where\nthe relevance scores from different retrieval functionalities can be integrated\nas the teacher signal to enhance the training quality. We also optimize the\nbatching strategy, enabling a large batch size and high training throughput to\nensure the discriminativeness of embeddings. To the best of our knowledge,\nM3-Embedding is the first embedding model which realizes such a strong\nversatility. The model and code will be publicly available at\nhttps://github.com/FlagOpen/FlagEmbedding.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03216v4",
    "published_date": "2024-02-05 17:26:49 UTC",
    "updated_date": "2024-06-28 09:55:49 UTC"
  },
  {
    "arxiv_id": "2402.03214v3",
    "title": "Organic or Diffused: Can We Distinguish Human Art from AI-generated Images?",
    "authors": [
      "Anna Yoo Jeong Ha",
      "Josephine Passananti",
      "Ronik Bhaskar",
      "Shawn Shan",
      "Reid Southen",
      "Haitao Zheng",
      "Ben Y. Zhao"
    ],
    "abstract": "The advent of generative AI images has completely disrupted the art world.\nDistinguishing AI generated images from human art is a challenging problem\nwhose impact is growing over time. A failure to address this problem allows bad\nactors to defraud individuals paying a premium for human art and companies\nwhose stated policies forbid AI imagery. It is also critical for content owners\nto establish copyright, and for model trainers interested in curating training\ndata in order to avoid potential model collapse.\n  There are several different approaches to distinguishing human art from AI\nimages, including classifiers trained by supervised learning, research tools\ntargeting diffusion models, and identification by professional artists using\ntheir knowledge of artistic techniques. In this paper, we seek to understand\nhow well these approaches can perform against today's modern generative models\nin both benign and adversarial settings. We curate real human art across 7\nstyles, generate matching images from 5 generative models, and apply 8\ndetectors (5 automated detectors and 3 different human groups including 180\ncrowdworkers, 4000+ professional artists, and 13 expert artists experienced at\ndetecting AI). Both Hive and expert artists do very well, but make mistakes in\ndifferent ways (Hive is weaker against adversarial perturbations while Expert\nartists produce higher false positives). We believe these weaknesses will\nremain as models continue to evolve, and use our data to demonstrate why a\ncombined team of human and automated detectors provides the best combination of\naccuracy and robustness.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03214v3",
    "published_date": "2024-02-05 17:25:04 UTC",
    "updated_date": "2024-07-02 20:22:14 UTC"
  },
  {
    "arxiv_id": "2402.03204v1",
    "title": "Multi-agent Reinforcement Learning for Energy Saving in Multi-Cell Massive MIMO Systems",
    "authors": [
      "Tianzhang Cai",
      "Qichen Wang",
      "Shuai Zhang",
      "Özlem Tuğfe Demir",
      "Cicek Cavdar"
    ],
    "abstract": "We develop a multi-agent reinforcement learning (MARL) algorithm to minimize\nthe total energy consumption of multiple massive MIMO (multiple-input\nmultiple-output) base stations (BSs) in a multi-cell network while preserving\nthe overall quality-of-service (QoS) by making decisions on the multi-level\nadvanced sleep modes (ASMs) and antenna switching of these BSs. The problem is\nmodeled as a decentralized partially observable Markov decision process\n(DEC-POMDP) to enable collaboration between individual BSs, which is necessary\nto tackle inter-cell interference. A multi-agent proximal policy optimization\n(MAPPO) algorithm is designed to learn a collaborative BS control policy. To\nenhance its scalability, a modified version called MAPPO-neighbor policy is\nfurther proposed. Simulation results demonstrate that the trained MAPPO agent\nachieves better performance compared to baseline policies. Specifically,\ncompared to the auto sleep mode 1 (symbol-level sleeping) algorithm, the\nMAPPO-neighbor policy reduces power consumption by approximately 8.7% during\nlow-traffic hours and improves energy efficiency by approximately 19% during\nhigh-traffic hours, respectively.",
    "categories": [
      "cs.IT",
      "cs.AI",
      "cs.LG",
      "math.IT"
    ],
    "primary_category": "cs.IT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03204v1",
    "published_date": "2024-02-05 17:15:00 UTC",
    "updated_date": "2024-02-05 17:15:00 UTC"
  },
  {
    "arxiv_id": "2402.05966v4",
    "title": "Vanishing Feature: Diagnosing Model Merging and Beyond",
    "authors": [
      "Xingyu Qu",
      "Samuel Horvath"
    ],
    "abstract": "Model merging offers an efficient way to combine pre-trained neural networks\nbut often suffers from inconsistent performance, especially when merging models\nwith different initializations. We identify the ``vanishing feature''\nphenomenon, where input-induced features diminish during propagation through\nthe merged model, degrading performance. Through theoretical and empirical\nanalysis, we reveal that this phenomenon underpins challenges like variance\ncollapse and explains techniques like permutation-based merging, post-merging\nnormalization, etc. We show that existing normalization strategies can be\nenhanced by precisely targeting the vanishing feature issue. Leveraging these\ninsights, we propose the ``Preserve-First Merging'' (PFM) strategy, which\nfocuses on preserving early-layer features, enabling the merged models, for the\nfirst time, to outperform the original models in advanced settings without\npost-training. Furthermore, we demonstrate that the vanishing feature\nphenomenon extends to other contexts, such as model pruning. Applying\npost-pruning normalization to mitigate the issue significantly improves\none-shot pruning performance at high sparsity, offering a simple and effective\npost-pruning solution. The code is available at https://github.com/XingyuQu/VF.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "36 pages, published as a conference paper (Oral) at the Second\n  Conference on Parsimony and Learning (CPAL 2025)",
    "pdf_url": "http://arxiv.org/pdf/2402.05966v4",
    "published_date": "2024-02-05 17:06:26 UTC",
    "updated_date": "2025-02-26 20:48:00 UTC"
  },
  {
    "arxiv_id": "2402.03190v4",
    "title": "Unified Hallucination Detection for Multimodal Large Language Models",
    "authors": [
      "Xiang Chen",
      "Chenxi Wang",
      "Yida Xue",
      "Ningyu Zhang",
      "Xiaoyan Yang",
      "Qiang Li",
      "Yue Shen",
      "Lei Liang",
      "Jinjie Gu",
      "Huajun Chen"
    ],
    "abstract": "Despite significant strides in multimodal tasks, Multimodal Large Language\nModels (MLLMs) are plagued by the critical issue of hallucination. The reliable\ndetection of such hallucinations in MLLMs has, therefore, become a vital aspect\nof model evaluation and the safeguarding of practical application deployment.\nPrior research in this domain has been constrained by a narrow focus on\nsingular tasks, an inadequate range of hallucination categories addressed, and\na lack of detailed granularity. In response to these challenges, our work\nexpands the investigative horizons of hallucination detection. We present a\nnovel meta-evaluation benchmark, MHaluBench, meticulously crafted to facilitate\nthe evaluation of advancements in hallucination detection methods.\nAdditionally, we unveil a novel unified multimodal hallucination detection\nframework, UNIHD, which leverages a suite of auxiliary tools to validate the\noccurrence of hallucinations robustly. We demonstrate the effectiveness of\nUNIHD through meticulous evaluation and comprehensive analysis. We also provide\nstrategic insights on the application of specific tools for addressing various\ncategories of hallucinations.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by ACL 2024 (main conference)",
    "pdf_url": "http://arxiv.org/pdf/2402.03190v4",
    "published_date": "2024-02-05 16:56:11 UTC",
    "updated_date": "2024-05-27 11:52:56 UTC"
  },
  {
    "arxiv_id": "2402.05130v2",
    "title": "LB-KBQA: Large-language-model and BERT based Knowledge-Based Question and Answering System",
    "authors": [
      "Yan Zhao",
      "Zhongyun Li",
      "Yushan Pan",
      "Jiaxing Wang",
      "Yihong Wang"
    ],
    "abstract": "Generative Artificial Intelligence (AI), because of its emergent abilities,\nhas empowered various fields, one typical of which is large language models\n(LLMs). One of the typical application fields of Generative AI is large\nlanguage models (LLMs), and the natural language understanding capability of\nLLM is dramatically improved when compared with conventional AI-based methods.\nThe natural language understanding capability has always been a barrier to the\nintent recognition performance of the Knowledge-Based-Question-and-Answer\n(KBQA) system, which arises from linguistic diversity and the newly appeared\nintent. Conventional AI-based methods for intent recognition can be divided\ninto semantic parsing-based and model-based approaches. However, both of the\nmethods suffer from limited resources in intent recognition. To address this\nissue, we propose a novel KBQA system based on a Large Language Model(LLM) and\nBERT (LB-KBQA). With the help of generative AI, our proposed method could\ndetect newly appeared intent and acquire new knowledge. In experiments on\nfinancial domain question answering, our model has demonstrated superior\neffectiveness.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05130v2",
    "published_date": "2024-02-05 16:47:17 UTC",
    "updated_date": "2024-02-09 02:45:51 UTC"
  },
  {
    "arxiv_id": "2402.03183v1",
    "title": "Predicting Configuration Performance in Multiple Environments with Sequential Meta-learning",
    "authors": [
      "Jingzhi Gong",
      "Tao Chen"
    ],
    "abstract": "Learning and predicting the performance of given software configurations are\nof high importance to many software engineering activities. While configurable\nsoftware systems will almost certainly face diverse running environments (e.g.,\nversion, hardware, and workload), current work often either builds performance\nmodels under a single environment or fails to properly handle data from diverse\nsettings, hence restricting their accuracy for new environments. In this paper,\nwe target configuration performance learning under multiple environments. We do\nso by designing SeMPL - a meta-learning framework that learns the common\nunderstanding from configurations measured in distinct (meta) environments and\ngeneralizes them to the unforeseen, target environment. What makes it unique is\nthat unlike common meta-learning frameworks (e.g., MAML and MetaSGD) that train\nthe meta environments in parallel, we train them sequentially, one at a time.\nThe order of training naturally allows discriminating the contributions among\nmeta environments in the meta-model built, which fits better with the\ncharacteristic of configuration data that is known to dramatically differ\nbetween different environments. Through comparing with 15 state-of-the-art\nmodels under nine systems, our extensive experimental results demonstrate that\nSeMPL performs considerably better on 89% of the systems with up to 99%\naccuracy improvement, while being data-efficient, leading to a maximum of 3.86x\nspeedup. All code and data can be found at our repository:\nhttps://github.com/ideas-labo/SeMPL.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG",
      "cs.PF"
    ],
    "primary_category": "cs.SE",
    "comment": "This paper has been accepted by FSE'24",
    "pdf_url": "http://arxiv.org/pdf/2402.03183v1",
    "published_date": "2024-02-05 16:47:13 UTC",
    "updated_date": "2024-02-05 16:47:13 UTC"
  },
  {
    "arxiv_id": "2402.03181v5",
    "title": "C-RAG: Certified Generation Risks for Retrieval-Augmented Language Models",
    "authors": [
      "Mintong Kang",
      "Nezihe Merve Gürel",
      "Ning Yu",
      "Dawn Song",
      "Bo Li"
    ],
    "abstract": "Despite the impressive capabilities of large language models (LLMs) across\ndiverse applications, they still suffer from trustworthiness issues, such as\nhallucinations and misalignments. Retrieval-augmented language models (RAG)\nhave been proposed to enhance the credibility of generations by grounding\nexternal knowledge, but the theoretical understandings of their generation\nrisks remains unexplored. In this paper, we answer: 1) whether RAG can indeed\nlead to low generation risks, 2) how to provide provable guarantees on the\ngeneration risks of RAG and vanilla LLMs, and 3) what sufficient conditions\nenable RAG models to reduce generation risks. We propose C-RAG, the first\nframework to certify generation risks for RAG models. Specifically, we provide\nconformal risk analysis for RAG models and certify an upper confidence bound of\ngeneration risks, which we refer to as conformal generation risk. We also\nprovide theoretical guarantees on conformal generation risks for general\nbounded risk functions under test distribution shifts. We prove that RAG\nachieves a lower conformal generation risk than that of a single LLM when the\nquality of the retrieval model and transformer is non-trivial. Our intensive\nempirical results demonstrate the soundness and tightness of our conformal\ngeneration risk guarantees across four widely-used NLP datasets on four\nstate-of-the-art retrieval models.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.03181v5",
    "published_date": "2024-02-05 16:46:16 UTC",
    "updated_date": "2024-07-30 02:47:47 UTC"
  },
  {
    "arxiv_id": "2402.03176v1",
    "title": "Comparison of Topic Modelling Approaches in the Banking Context",
    "authors": [
      "Bayode Ogunleye",
      "Tonderai Maswera",
      "Laurence Hirsch",
      "Jotham Gaudoin",
      "Teresa Brunsdon"
    ],
    "abstract": "Topic modelling is a prominent task for automatic topic extraction in many\napplications such as sentiment analysis and recommendation systems. The\napproach is vital for service industries to monitor their customer discussions.\nThe use of traditional approaches such as Latent Dirichlet Allocation (LDA) for\ntopic discovery has shown great performances, however, they are not consistent\nin their results as these approaches suffer from data sparseness and inability\nto model the word order in a document. Thus, this study presents the use of\nKernel Principal Component Analysis (KernelPCA) and K-means Clustering in the\nBERTopic architecture. We have prepared a new dataset using tweets from\ncustomers of Nigerian banks and we use this to compare the topic modelling\napproaches. Our findings showed KernelPCA and K-means in the BERTopic\narchitecture-produced coherent topics with a coherence score of 0.8463.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG",
      "stat.CO",
      "H.3.3"
    ],
    "primary_category": "cs.IR",
    "comment": "14 pages, Journal of Applied Science",
    "pdf_url": "http://arxiv.org/pdf/2402.03176v1",
    "published_date": "2024-02-05 16:43:53 UTC",
    "updated_date": "2024-02-05 16:43:53 UTC"
  },
  {
    "arxiv_id": "2402.03175v2",
    "title": "Beyond the Black Box: A Statistical Model for LLM Reasoning and Inference",
    "authors": [
      "Siddhartha Dalal",
      "Vishal Misra"
    ],
    "abstract": "This paper introduces a novel Bayesian learning model to explain the behavior\nof Large Language Models (LLMs), focusing on their core optimization metric of\nnext token prediction. We develop a theoretical framework based on an ideal\ngenerative text model represented by a multinomial transition probability\nmatrix with a prior, and examine how LLMs approximate this matrix. Key\ncontributions include: (i) a continuity theorem relating embeddings to\nmultinomial distributions, (ii) a demonstration that LLM text generation aligns\nwith Bayesian learning principles, (iii) an explanation for the emergence of\nin-context learning in larger models, (iv) empirical validation using\nvisualizations of next token probabilities from an instrumented Llama model Our\nfindings provide new insights into LLM functioning, offering a statistical\nfoundation for understanding their capabilities and limitations. This framework\nhas implications for LLM design, training, and application, potentially guiding\nfuture developments in the field.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03175v2",
    "published_date": "2024-02-05 16:42:10 UTC",
    "updated_date": "2024-09-24 13:30:25 UTC"
  },
  {
    "arxiv_id": "2402.03173v3",
    "title": "MULTI: Multimodal Understanding Leaderboard with Text and Images",
    "authors": [
      "Zichen Zhu",
      "Yang Xu",
      "Lu Chen",
      "Jingkai Yang",
      "Yichuan Ma",
      "Yiming Sun",
      "Hailin Wen",
      "Jiaqi Liu",
      "Jinyu Cai",
      "Yingzi Ma",
      "Situo Zhang",
      "Zihan Zhao",
      "Liangtai Sun",
      "Kai Yu"
    ],
    "abstract": "The rapid development of multimodal large language models (MLLMs) raises the\nquestion of how they compare to human performance. While existing datasets\noften feature synthetic or overly simplistic tasks, some models have already\nsurpassed human expert baselines. In this paper, we present MULTI, a Chinese\nmultimodal dataset derived from authentic examination questions. Comprising\nover 18,000 carefully selected and refined questions, MULTI evaluates models\nusing real-world examination standards, encompassing image-text comprehension,\ncomplex reasoning, and knowledge recall. Additionally, We also introduce\nMULTI-Elite, a 500-question selected hard subset, and MULTI-Extend with more\nthan 4,500 external knowledge context pieces for testing in-context learning\ncapabilities. Our evaluation highlights substantial room for MLLM advancement,\nwith Qwen2-VL-72B achieving a 76.9% accuracy on MULTI and 53.1% on MULTI-Elite\nleading 25 evaluated models, compared to human expert baselines of 86.1% and\n73.1%. MULTI serves not only as a robust evaluation platform but also paves the\nway for the development of expert-level AI.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "24 pages, 19 figures, 10 tables. Details and access are available at:\n  https://OpenDFM.github.io/MULTI-Benchmark/",
    "pdf_url": "http://arxiv.org/pdf/2402.03173v3",
    "published_date": "2024-02-05 16:41:02 UTC",
    "updated_date": "2025-01-07 07:05:05 UTC"
  },
  {
    "arxiv_id": "2402.03172v1",
    "title": "Accurate and Well-Calibrated ICD Code Assignment Through Attention Over Diverse Label Embeddings",
    "authors": [
      "Gonçalo Gomes",
      "Isabel Coutinho",
      "Bruno Martins"
    ],
    "abstract": "Although the International Classification of Diseases (ICD) has been adopted\nworldwide, manually assigning ICD codes to clinical text is time-consuming,\nerror-prone, and expensive, motivating the development of automated approaches.\nThis paper describes a novel approach for automated ICD coding, combining\nseveral ideas from previous related work. We specifically employ a strong\nTransformer-based model as a text encoder and, to handle lengthy clinical\nnarratives, we explored either (a) adapting the base encoder model into a\nLongformer, or (b) dividing the text into chunks and processing each chunk\nindependently. The representations produced by the encoder are combined with a\nlabel embedding mechanism that explores diverse ICD code synonyms. Experiments\nwith different splits of the MIMIC-III dataset show that the proposed approach\noutperforms the current state-of-the-art models in ICD coding, with the label\nembeddings significantly contributing to the good performance. Our approach\nalso leads to properly calibrated classification results, which can effectively\ninform downstream tasks such as quantification.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to EACL2024",
    "pdf_url": "http://arxiv.org/pdf/2402.03172v1",
    "published_date": "2024-02-05 16:40:23 UTC",
    "updated_date": "2024-02-05 16:40:23 UTC"
  },
  {
    "arxiv_id": "2402.03164v1",
    "title": "Decidable Reasoning About Time in Finite-Domain Situation Calculus Theories",
    "authors": [
      "Till Hofmann",
      "Stefan Schupp",
      "Gerhard Lakemeyer"
    ],
    "abstract": "Representing time is crucial for cyber-physical systems and has been studied\nextensively in the Situation Calculus. The most commonly used approach\nrepresents time by adding a real-valued fluent $\\mathit{time}(a)$ that attaches\na time point to each action and consequently to each situation. We show that in\nthis approach, checking whether there is a reachable situation that satisfies a\ngiven formula is undecidable, even if the domain of discourse is restricted to\na finite set of objects. We present an alternative approach based on\nwell-established results from timed automata theory by introducing clocks as\nreal-valued fluents with restricted successor state axioms and comparison\noperators. %that only allow comparisons against fixed rationals. With this\nrestriction, we can show that the reachability problem for finite-domain basic\naction theories is decidable. Finally, we apply our results on Golog program\nrealization by presenting a decidable procedure for determining an action\nsequence that is a successful execution of a given program.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03164v1",
    "published_date": "2024-02-05 16:32:12 UTC",
    "updated_date": "2024-02-05 16:32:12 UTC"
  },
  {
    "arxiv_id": "2402.07925v1",
    "title": "Point and Instruct: Enabling Precise Image Editing by Unifying Direct Manipulation and Text Instructions",
    "authors": [
      "Alec Helbling",
      "Seongmin Lee",
      "Polo Chau"
    ],
    "abstract": "Machine learning has enabled the development of powerful systems capable of\nediting images from natural language instructions. However, in many common\nscenarios it is difficult for users to specify precise image transformations\nwith text alone. For example, in an image with several dogs, it is difficult to\nselect a particular dog and move it to a precise location. Doing this with text\nalone would require a complex prompt that disambiguates the target dog and\ndescribes the destination. However, direct manipulation is well suited to\nvisual tasks like selecting objects and specifying locations. We introduce\nPoint and Instruct, a system for seamlessly combining familiar direct\nmanipulation and textual instructions to enable precise image manipulation.\nWith our system, a user can visually mark objects and locations, and reference\nthem in textual instructions. This allows users to benefit from both the visual\ndescriptiveness of natural language and the spatial precision of direct\nmanipulation.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.07925v1",
    "published_date": "2024-02-05 16:23:07 UTC",
    "updated_date": "2024-02-05 16:23:07 UTC"
  },
  {
    "arxiv_id": "2403.05544v1",
    "title": "From Algorithm Worship to the Art of Human Learning: Insights from 50-year journey of AI in Education",
    "authors": [
      "Kaska Porayska-Pomsta"
    ],
    "abstract": "Current discourse surrounding Artificial Intelligence (AI) oscillates between\nhope and apprehension, painting a future where AI reshapes every facet of human\nlife, including Education. This paper delves into the complexities of AI's role\nin Education, addressing the mixed messages that have both enthused and alarmed\neducators, policymakers, and the public. It explores the promises that AI holds\nfor enhancing learning through personalisation at scale, against the backdrop\nof concerns about ethical implications, the devaluation of non-STEM subjects,\nand the potential transformative impact on our neurocognitive and\nsocio-emotional functioning. Drawing on recent research and global discourse,\nthe paper seeks to unpack the reasons behind the vagueness of current\ndiscussions on AI in Education (AIED) and the implications of this ambiguity\nfor future educational practices and policies. By highlighting insights from\neducational research and synthesising evidence-based best practices in AIED,\nthe aim is to provide a clearer understanding of how AI technologies can be\naligned with the fundamental principles of learning and teaching, and explore\nwhat concrete actions may need to be prioritised now to truly enhance learning\nexperiences and outcomes for all in the future.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "12 pages; opinion piece",
    "pdf_url": "http://arxiv.org/pdf/2403.05544v1",
    "published_date": "2024-02-05 16:12:14 UTC",
    "updated_date": "2024-02-05 16:12:14 UTC"
  },
  {
    "arxiv_id": "2402.03141v2",
    "title": "Boosting Reinforcement Learning with Strongly Delayed Feedback Through Auxiliary Short Delays",
    "authors": [
      "Qingyuan Wu",
      "Simon Sinong Zhan",
      "Yixuan Wang",
      "Yuhui Wang",
      "Chung-Wei Lin",
      "Chen Lv",
      "Qi Zhu",
      "Jürgen Schmidhuber",
      "Chao Huang"
    ],
    "abstract": "Reinforcement learning (RL) is challenging in the common case of delays\nbetween events and their sensory perceptions. State-of-the-art (SOTA) state\naugmentation techniques either suffer from state space explosion or performance\ndegeneration in stochastic environments. To address these challenges, we\npresent a novel Auxiliary-Delayed Reinforcement Learning (AD-RL) method that\nleverages auxiliary tasks involving short delays to accelerate RL with long\ndelays, without compromising performance in stochastic environments.\nSpecifically, AD-RL learns a value function for short delays and uses\nbootstrapping and policy improvement techniques to adjust it for long delays.\nWe theoretically show that this can greatly reduce the sample complexity. On\ndeterministic and stochastic benchmarks, our method significantly outperforms\nthe SOTAs in both sample efficiency and policy performance. Code is available\nat https://github.com/QingyuanWuNothing/AD-RL.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.03141v2",
    "published_date": "2024-02-05 16:11:03 UTC",
    "updated_date": "2024-06-05 19:12:37 UTC"
  },
  {
    "arxiv_id": "2402.03138v2",
    "title": "Just Cluster It: An Approach for Exploration in High-Dimensions using Clustering and Pre-Trained Representations",
    "authors": [
      "Stefan Sylvius Wagner",
      "Stefan Harmeling"
    ],
    "abstract": "In this paper we adopt a representation-centric perspective on exploration in\nreinforcement learning, viewing exploration fundamentally as a density\nestimation problem. We investigate the effectiveness of clustering\nrepresentations for exploration in 3-D environments, based on the observation\nthat the importance of pixel changes between transitions is less pronounced in\n3-D environments compared to 2-D environments, where pixel changes between\ntransitions are typically distinct and significant. We propose a method that\nperforms episodic and global clustering on random representations and on\npre-trained DINO representations to count states, i.e, estimate pseudo-counts.\nSurprisingly, even random features can be clustered effectively to count states\nin 3-D environments, however when these become visually more complex,\npre-trained DINO representations are more effective thanks to the pre-trained\ninductive biases in the representations. Overall, this presents a pathway for\nintegrating pre-trained biases into exploration. We evaluate our approach on\nthe VizDoom and Habitat environments, demonstrating that our method surpasses\nother well-known exploration methods in these settings.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at the International Conference On Machine Learning (ICML)\n  2024",
    "pdf_url": "http://arxiv.org/pdf/2402.03138v2",
    "published_date": "2024-02-05 16:08:58 UTC",
    "updated_date": "2024-08-14 19:08:48 UTC"
  },
  {
    "arxiv_id": "2402.03136v2",
    "title": "Mastering Zero-Shot Interactions in Cooperative and Competitive Simultaneous Games",
    "authors": [
      "Yannik Mahlau",
      "Frederik Schubert",
      "Bodo Rosenhahn"
    ],
    "abstract": "The combination of self-play and planning has achieved great successes in\nsequential games, for instance in Chess and Go. However, adapting algorithms\nsuch as AlphaZero to simultaneous games poses a new challenge. In these games,\nmissing information about concurrent actions of other agents is a limiting\nfactor as they may select different Nash equilibria or do not play optimally at\nall. Thus, it is vital to model the behavior of the other agents when\ninteracting with them in simultaneous games. To this end, we propose Albatross:\nAlphaZero for Learning Bounded-rational Agents and Temperature-based Response\nOptimization using Simulated Self-play. Albatross learns to play the novel\nequilibrium concept of a Smooth Best Response Logit Equilibrium (SBRLE), which\nenables cooperation and competition with agents of any playing strength. We\nperform an extensive evaluation of Albatross on a set of cooperative and\ncompetitive simultaneous perfect-information games. In contrast to AlphaZero,\nAlbatross is able to exploit weak agents in the competitive game of\nBattlesnake. Additionally, it yields an improvement of 37.6% compared to\nprevious state of the art in the cooperative Overcooked benchmark.",
    "categories": [
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03136v2",
    "published_date": "2024-02-05 16:03:44 UTC",
    "updated_date": "2024-06-11 12:26:30 UTC"
  },
  {
    "arxiv_id": "2402.03130v3",
    "title": "User Centric Evaluation of Code Generation Tools",
    "authors": [
      "Tanha Miah",
      "Hong Zhu"
    ],
    "abstract": "With the rapid advance of machine learning (ML) technology, large language\nmodels (LLMs) are increasingly explored as an intelligent tool to generate\nprogram code from natural language specifications. However, existing\nevaluations of LLMs have focused on their capabilities in comparison with\nhumans. It is desirable to evaluate their usability when deciding on whether to\nuse a LLM in software production. This paper proposes a user centric method for\nthis purpose. It includes metadata in the test cases of a benchmark to describe\ntheir usages, conducts testing in a multi-attempt process that mimics the uses\nof LLMs, measures LLM generated solutions on a set of quality attributes that\nreflect usability, and evaluates the performance based on user experiences in\nthe uses of LLMs as a tool.\n  The paper also reports a case study with the method in the evaluation of\nChatGPT's usability as a code generation tool for the R programming language.\nOur experiments demonstrated that ChatGPT is highly useful for generating R\nprogram code although it may fail on hard programming tasks. The user\nexperiences are good with overall average number of attempts being 1.61 and the\naverage time of completion being 47.02 seconds. Our experiments also found that\nthe weakest aspect of usability is conciseness, which has a score of 3.80 out\nof 5.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "The paper is accepted by IEEE AITest 2024 at IEEE CISOSE 2024\n  Congress as an invited paper, and will appear in the AITest 2024 Conference\n  Proceedings",
    "pdf_url": "http://arxiv.org/pdf/2402.03130v3",
    "published_date": "2024-02-05 15:56:19 UTC",
    "updated_date": "2024-06-18 13:45:05 UTC"
  },
  {
    "arxiv_id": "2402.03119v2",
    "title": "Good Teachers Explain: Explanation-Enhanced Knowledge Distillation",
    "authors": [
      "Amin Parchami-Araghi",
      "Moritz Böhle",
      "Sukrut Rao",
      "Bernt Schiele"
    ],
    "abstract": "Knowledge Distillation (KD) has proven effective for compressing large\nteacher models into smaller student models. While it is well known that student\nmodels can achieve similar accuracies as the teachers, it has also been shown\nthat they nonetheless often do not learn the same function. It is, however,\noften highly desirable that the student's and teacher's functions share similar\nproperties such as basing the prediction on the same input features, as this\nensures that students learn the 'right features' from the teachers. In this\nwork, we explore whether this can be achieved by not only optimizing the\nclassic KD loss but also the similarity of the explanations generated by the\nteacher and the student. Despite the idea being simple and intuitive, we find\nthat our proposed 'explanation-enhanced' KD (e$^2$KD) (1) consistently provides\nlarge gains in terms of accuracy and student-teacher agreement, (2) ensures\nthat the student learns from the teacher to be right for the right reasons and\nto give similar explanations, and (3) is robust with respect to the model\narchitectures, the amount of training data, and even works with 'approximate',\npre-computed explanations.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "32 pages, 11 figures, European Conference on Computer Vision (ECCV)\n  2024",
    "pdf_url": "http://arxiv.org/pdf/2402.03119v2",
    "published_date": "2024-02-05 15:47:54 UTC",
    "updated_date": "2024-07-21 16:37:25 UTC"
  },
  {
    "arxiv_id": "2402.03112v1",
    "title": "Infrared Spectra Prediction for Diazo Groups Utilizing a Machine Learning Approach with Structural Attention Mechanism",
    "authors": [
      "Chengchun Liu",
      "Fanyang Mo"
    ],
    "abstract": "Infrared (IR) spectroscopy is a pivotal technique in chemical research for\nelucidating molecular structures and dynamics through vibrational and\nrotational transitions. However, the intricate molecular fingerprints\ncharacterized by unique vibrational and rotational patterns present substantial\nanalytical challenges. Here, we present a machine learning approach employing a\nStructural Attention Mechanism tailored to enhance the prediction and\ninterpretation of infrared spectra, particularly for diazo compounds. Our model\ndistinguishes itself by honing in on chemical information proximal to\nfunctional groups, thereby significantly bolstering the accuracy, robustness,\nand interpretability of spectral predictions. This method not only demystifies\nthe correlations between infrared spectral features and molecular structures\nbut also offers a scalable and efficient paradigm for dissecting complex\nmolecular interactions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.chem-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "21 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.03112v1",
    "published_date": "2024-02-05 15:44:43 UTC",
    "updated_date": "2024-02-05 15:44:43 UTC"
  },
  {
    "arxiv_id": "2402.03110v3",
    "title": "Non-Stationary Latent Auto-Regressive Bandits",
    "authors": [
      "Anna L. Trella",
      "Walter Dempsey",
      "Asim H. Gazi",
      "Ziping Xu",
      "Finale Doshi-Velez",
      "Susan A. Murphy"
    ],
    "abstract": "For the non-stationary multi-armed bandit (MAB) problem, many existing\nmethods allow a general mechanism for the non-stationarity, but rely on a\nbudget for the non-stationarity that is sub-linear to the total number of time\nsteps $T$. In many real-world settings, however, the mechanism for the\nnon-stationarity can be modeled, but there is no budget for the\nnon-stationarity. We instead consider the non-stationary bandit problem where\nthe reward means change due to a latent, auto-regressive (AR) state. We develop\nLatent AR LinUCB (LARL), an online linear contextual bandit algorithm that does\nnot rely on the non-stationary budget, but instead forms good predictions of\nreward means by implicitly predicting the latent state. The key idea is to\nreduce the problem to a linear dynamical system which can be solved as a linear\ncontextual bandit. In fact, LARL approximates a steady-state Kalman filter and\nefficiently learns system parameters online. We provide an interpretable regret\nbound for LARL with respect to the level of non-stationarity in the\nenvironment. LARL achieves sub-linear regret in this setting if the noise\nvariance of the latent state process is sufficiently small with respect to $T$.\nEmpirically, LARL outperforms various baseline methods in this non-stationary\nbandit problem.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03110v3",
    "published_date": "2024-02-05 15:38:01 UTC",
    "updated_date": "2025-02-28 02:29:21 UTC"
  },
  {
    "arxiv_id": "2402.03099v1",
    "title": "Intent-based Prompt Calibration: Enhancing prompt optimization with synthetic boundary cases",
    "authors": [
      "Elad Levi",
      "Eli Brosh",
      "Matan Friedmann"
    ],
    "abstract": "Prompt engineering is a challenging and important task due to the high\nsensitivity of Large Language Models (LLMs) to the given prompt and the\ninherent ambiguity of a textual task instruction. Automatic prompt engineering\nis essential to achieve optimized performance from LLMs. Recent studies have\ndemonstrated the capabilities of LLMs to automatically conduct prompt\nengineering by employing a meta-prompt that incorporates the outcomes of the\nlast trials and proposes an improved prompt. However, this requires a\nhigh-quality benchmark to compare different prompts, which is difficult and\nexpensive to acquire in many real-world use cases. In this work, we introduce a\nnew method for automatic prompt engineering, using a calibration process that\niteratively refines the prompt to the user intent. During the optimization\nprocess, the system jointly generates synthetic data of boundary use cases and\noptimizes the prompt according to the generated dataset. We demonstrate the\neffectiveness of our method with respect to strong proprietary models on\nreal-world tasks such as moderation and generation. Our method outperforms\nstate-of-the-art methods with a limited number of annotated samples.\nFurthermore, we validate the advantages of each one of the system's key\ncomponents. Our system is built in a modular way, facilitating easy adaptation\nto other tasks. The code is available\n$\\href{https://github.com/Eladlev/AutoPrompt}{here}$.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03099v1",
    "published_date": "2024-02-05 15:28:43 UTC",
    "updated_date": "2024-02-05 15:28:43 UTC"
  },
  {
    "arxiv_id": "2402.03081v1",
    "title": "Preference-Conditioned Language-Guided Abstraction",
    "authors": [
      "Andi Peng",
      "Andreea Bobu",
      "Belinda Z. Li",
      "Theodore R. Sumers",
      "Ilia Sucholutsky",
      "Nishanth Kumar",
      "Thomas L. Griffiths",
      "Julie A. Shah"
    ],
    "abstract": "Learning from demonstrations is a common way for users to teach robots, but\nit is prone to spurious feature correlations. Recent work constructs state\nabstractions, i.e. visual representations containing task-relevant features,\nfrom language as a way to perform more generalizable learning. However, these\nabstractions also depend on a user's preference for what matters in a task,\nwhich may be hard to describe or infeasible to exhaustively specify using\nlanguage alone. How do we construct abstractions to capture these latent\npreferences? We observe that how humans behave reveals how they see the world.\nOur key insight is that changes in human behavior inform us that there are\ndifferences in preferences for how humans see the world, i.e. their state\nabstractions. In this work, we propose using language models (LMs) to query for\nthose preferences directly given knowledge that a change in behavior has\noccurred. In our framework, we use the LM in two ways: first, given a text\ndescription of the task and knowledge of behavioral change between states, we\nquery the LM for possible hidden preferences; second, given the most likely\npreference, we query the LM to construct the state abstraction. In this\nframework, the LM is also able to ask the human directly when uncertain about\nits own estimate. We demonstrate our framework's ability to construct effective\npreference-conditioned abstractions in simulated experiments, a user study, as\nwell as on a real Spot robot performing mobile manipulation tasks.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "HRI 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.03081v1",
    "published_date": "2024-02-05 15:12:15 UTC",
    "updated_date": "2024-02-05 15:12:15 UTC"
  },
  {
    "arxiv_id": "2402.03072v1",
    "title": "Learning to Abstract Visuomotor Mappings using Meta-Reinforcement Learning",
    "authors": [
      "Carlos A. Velazquez-Vargas",
      "Isaac Ray Christian",
      "Jordan A. Taylor",
      "Sreejan Kumar"
    ],
    "abstract": "We investigated the human capacity to acquire multiple visuomotor mappings\nfor de novo skills. Using a grid navigation paradigm, we tested whether\ncontextual cues implemented as different \"grid worlds\", allow participants to\nlearn two distinct key-mappings more efficiently. Our results indicate that\nwhen contextual information is provided, task performance is significantly\nbetter. The same held true for meta-reinforcement learning agents that differed\nin whether or not they receive contextual information when performing the task.\nWe evaluated their accuracy in predicting human performance in the task and\nanalyzed their internal representations. The results indicate that contextual\ncues allow the formation of separate representations in space and time when\nusing different visuomotor mappings, whereas the absence of them favors sharing\none representation. While both strategies can allow learning of multiple\nvisuomotor mappings, we showed contextual cues provide a computational\nadvantage in terms of how many mappings can be learned.",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.NC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03072v1",
    "published_date": "2024-02-05 15:02:35 UTC",
    "updated_date": "2024-02-05 15:02:35 UTC"
  },
  {
    "arxiv_id": "2402.03067v1",
    "title": "Multilingual transformer and BERTopic for short text topic modeling: The case of Serbian",
    "authors": [
      "Darija Medvecki",
      "Bojana Bašaragin",
      "Adela Ljajić",
      "Nikola Milošević"
    ],
    "abstract": "This paper presents the results of the first application of BERTopic, a\nstate-of-the-art topic modeling technique, to short text written in a\nmorphologi-cally rich language. We applied BERTopic with three multilingual\nembed-ding models on two levels of text preprocessing (partial and full) to\nevalu-ate its performance on partially preprocessed short text in Serbian. We\nalso compared it to LDA and NMF on fully preprocessed text. The experiments\nwere conducted on a dataset of tweets expressing hesitancy toward COVID-19\nvaccination. Our results show that with adequate parameter setting, BERTopic\ncan yield informative topics even when applied to partially pre-processed short\ntext. When the same parameters are applied in both prepro-cessing scenarios,\nthe performance drop on partially preprocessed text is minimal. Compared to LDA\nand NMF, judging by the keywords, BERTopic offers more informative topics and\ngives novel insights when the number of topics is not limited. The findings of\nthis paper can be significant for re-searchers working with other\nmorphologically rich low-resource languages and short text.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03067v1",
    "published_date": "2024-02-05 14:59:29 UTC",
    "updated_date": "2024-02-05 14:59:29 UTC"
  },
  {
    "arxiv_id": "2402.03049v4",
    "title": "EasyInstruct: An Easy-to-use Instruction Processing Framework for Large Language Models",
    "authors": [
      "Yixin Ou",
      "Ningyu Zhang",
      "Honghao Gui",
      "Ziwen Xu",
      "Shuofei Qiao",
      "Yida Xue",
      "Runnan Fang",
      "Kangwei Liu",
      "Lei Li",
      "Zhen Bi",
      "Guozhou Zheng",
      "Huajun Chen"
    ],
    "abstract": "In recent years, instruction tuning has gained increasing attention and\nemerged as a crucial technique to enhance the capabilities of Large Language\nModels (LLMs). To construct high-quality instruction datasets, many instruction\nprocessing approaches have been proposed, aiming to achieve a delicate balance\nbetween data quantity and data quality. Nevertheless, due to inconsistencies\nthat persist among various instruction processing methods, there is no standard\nopen-source instruction processing implementation framework available for the\ncommunity, which hinders practitioners from further developing and advancing.\nTo facilitate instruction processing research and development, we present\nEasyInstruct, an easy-to-use instruction processing framework for LLMs, which\nmodularizes instruction generation, selection, and prompting, while also\nconsidering their combination and interaction. EasyInstruct is publicly\nreleased and actively maintained at https://github.com/zjunlp/EasyInstruct,\nalong with an online demo app and a demo video for quick-start, calling for\nbroader research centered on instruction data and synthetic data.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL 2024 System Demonstrations; Project website:\n  https://zjunlp.github.io/project/EasyInstruct Code:\n  https://github.com/zjunlp/EasyInstruct Video: https://youtu.be/rfQOWYfziFo\n  Demo: https://huggingface.co/spaces/zjunlp/EasyInstruct",
    "pdf_url": "http://arxiv.org/pdf/2402.03049v4",
    "published_date": "2024-02-05 14:33:56 UTC",
    "updated_date": "2024-06-24 02:10:23 UTC"
  },
  {
    "arxiv_id": "2402.03040v1",
    "title": "InteractiveVideo: User-Centric Controllable Video Generation with Synergistic Multimodal Instructions",
    "authors": [
      "Yiyuan Zhang",
      "Yuhao Kang",
      "Zhixin Zhang",
      "Xiaohan Ding",
      "Sanyuan Zhao",
      "Xiangyu Yue"
    ],
    "abstract": "We introduce $\\textit{InteractiveVideo}$, a user-centric framework for video\ngeneration. Different from traditional generative approaches that operate based\non user-provided images or text, our framework is designed for dynamic\ninteraction, allowing users to instruct the generative model through various\nintuitive mechanisms during the whole generation process, e.g. text and image\nprompts, painting, drag-and-drop, etc. We propose a Synergistic Multimodal\nInstruction mechanism, designed to seamlessly integrate users' multimodal\ninstructions into generative models, thus facilitating a cooperative and\nresponsive interaction between user inputs and the generative process. This\napproach enables iterative and fine-grained refinement of the generation result\nthrough precise and effective user instructions. With\n$\\textit{InteractiveVideo}$, users are given the flexibility to meticulously\ntailor key aspects of a video. They can paint the reference image, edit\nsemantics, and adjust video motions until their requirements are fully met.\nCode, models, and demo are available at\nhttps://github.com/invictus717/InteractiveVideo",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "Code, models, and demo are available at\n  https://github.com/invictus717/InteractiveVideo",
    "pdf_url": "http://arxiv.org/pdf/2402.03040v1",
    "published_date": "2024-02-05 14:24:46 UTC",
    "updated_date": "2024-02-05 14:24:46 UTC"
  },
  {
    "arxiv_id": "2402.03038v1",
    "title": "Automatic Combination of Sample Selection Strategies for Few-Shot Learning",
    "authors": [
      "Branislav Pecher",
      "Ivan Srba",
      "Maria Bielikova",
      "Joaquin Vanschoren"
    ],
    "abstract": "In few-shot learning, such as meta-learning, few-shot fine-tuning or\nin-context learning, the limited number of samples used to train a model have a\nsignificant impact on the overall success. Although a large number of sample\nselection strategies exist, their impact on the performance of few-shot\nlearning is not extensively known, as most of them have been so far evaluated\nin typical supervised settings only. In this paper, we thoroughly investigate\nthe impact of 20 sample selection strategies on the performance of 5 few-shot\nlearning approaches over 8 image and 6 text datasets. In addition, we propose a\nnew method for automatic combination of sample selection strategies (ACSESS)\nthat leverages the strengths and complementary information of the individual\nstrategies. The experimental results show that our method consistently\noutperforms the individual selection strategies, as well as the recently\nproposed method for selecting support examples for in-context learning. We also\nshow a strong modality, dataset and approach dependence for the majority of\nstrategies as well as their dependence on the number of shots - demonstrating\nthat the sample selection strategies play a significant role for lower number\nof shots, but regresses to random selection at higher number of shots.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03038v1",
    "published_date": "2024-02-05 14:23:43 UTC",
    "updated_date": "2024-02-05 14:23:43 UTC"
  },
  {
    "arxiv_id": "2403.08802v3",
    "title": "Governance of Generative Artificial Intelligence for Companies",
    "authors": [
      "Johannes Schneider",
      "Pauline Kuss",
      "Rene Abraham",
      "Christian Meske"
    ],
    "abstract": "Generative Artificial Intelligence (GenAI), specifically large language\nmodels like ChatGPT, has swiftly entered organizations without adequate\ngovernance, posing both opportunities and risks. Despite extensive debates on\nGenAI's transformative nature and regulatory measures, limited research\naddresses organizational governance, encompassing technical and business\nperspectives. Although numerous frameworks for governance of AI exist, it is\nnot clear to what extent they apply to GenAI. Our review paper fills this gap\nby surveying recent works with the purpose of better understanding fundamental\ncharacteristics of GenAI and adjusting prior frameworks specifically towards\nGenAI governance within companies. To do so, it extends Nickerson's framework\ndevelopment processes to include prior conceptualizations. Our framework\noutlines the scope, objectives, and governance mechanisms tailored to harness\nbusiness opportunities as well as mitigate risks associated with GenAI\nintegration. Our research contributes a focused approach to GenAI governance,\noffering practical insights for companies navigating the challenges of GenAI\nadoption and highlighting research gaps.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08802v3",
    "published_date": "2024-02-05 14:20:19 UTC",
    "updated_date": "2024-12-03 09:39:57 UTC"
  },
  {
    "arxiv_id": "2402.03017v3",
    "title": "A Complete Survey on Contemporary Methods, Emerging Paradigms and Hybrid Approaches for Few-Shot Learning",
    "authors": [
      "Georgios Tsoumplekas",
      "Vladislav Li",
      "Panagiotis Sarigiannidis",
      "Vasileios Argyriou"
    ],
    "abstract": "Despite the widespread success of deep learning, its intense requirements for\nvast amounts of data and extensive training make it impractical for various\nreal-world applications where data is scarce. In recent years, Few-Shot\nLearning (FSL) has emerged as a learning paradigm that aims to address these\nlimitations by leveraging prior knowledge to enable rapid adaptation to novel\nlearning tasks. Due to its properties that highly complement deep learning's\ndata-intensive needs, FSL has seen significant growth in the past few years.\nThis survey provides a comprehensive overview of both well-established methods\nas well as recent advancements in the FSL field. The presented taxonomy extends\npreviously proposed ones by incorporating emerging FSL paradigms, such as\nin-context learning, along with novel categories within the meta-learning\nparadigm for FSL, including neural processes and probabilistic meta-learning.\nFurthermore, a holistic overview of FSL is provided by discussing hybrid FSL\napproaches that extend FSL beyond the typically examined supervised learning\nsetting. The survey also explores FSL's diverse applications across various\ndomains. Finally, recent trends shaping the field, outstanding challenges, and\npromising future research directions are discussed.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "63 pages, 16 figures. Under review",
    "pdf_url": "http://arxiv.org/pdf/2402.03017v3",
    "published_date": "2024-02-05 13:55:54 UTC",
    "updated_date": "2025-01-24 13:36:52 UTC"
  },
  {
    "arxiv_id": "2402.03014v1",
    "title": "Whom to Trust? Elective Learning for Distributed Gaussian Process Regression",
    "authors": [
      "Zewen Yang",
      "Xiaobing Dai",
      "Akshat Dubey",
      "Sandra Hirche",
      "Georges Hattab"
    ],
    "abstract": "This paper introduces an innovative approach to enhance distributed\ncooperative learning using Gaussian process (GP) regression in multi-agent\nsystems (MASs). The key contribution of this work is the development of an\nelective learning algorithm, namely prior-aware elective distributed GP\n(Pri-GP), which empowers agents with the capability to selectively request\npredictions from neighboring agents based on their trustworthiness. The\nproposed Pri-GP effectively improves individual prediction accuracy, especially\nin cases where the prior knowledge of an agent is incorrect. Moreover, it\neliminates the need for computationally intensive variance calculations for\ndetermining aggregation weights in distributed GP. Furthermore, we establish a\nprediction error bound within the Pri-GP framework, ensuring the reliability of\npredictions, which is regarded as a crucial property in safety-critical MAS\napplications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, conference preprint",
    "pdf_url": "http://arxiv.org/pdf/2402.03014v1",
    "published_date": "2024-02-05 13:52:56 UTC",
    "updated_date": "2024-02-05 13:52:56 UTC"
  },
  {
    "arxiv_id": "2402.03009v2",
    "title": "UniMem: Towards a Unified View of Long-Context Large Language Models",
    "authors": [
      "Junjie Fang",
      "Likai Tang",
      "Hongzhe Bi",
      "Yujia Qin",
      "Si Sun",
      "Zhenyu Li",
      "Haolun Li",
      "Yongjian Li",
      "Xin Cong",
      "Yankai Lin",
      "Yukun Yan",
      "Xiaodong Shi",
      "Sen Song",
      "Zhiyuan Liu",
      "Maosong Sun"
    ],
    "abstract": "Long-context processing is a critical ability that constrains the\napplicability of large language models (LLMs). Although there exist various\nmethods devoted to enhancing the long-context processing ability of LLMs, they\nare developed in an isolated manner and lack systematic analysis and\nintegration of their strengths, hindering further developments. In this paper,\nwe introduce UniMem, a Unified framework that reformulates existing\nlong-context methods from the view of Memory augmentation of LLMs.\nDistinguished by its four core dimensions-Memory Management, Memory Writing,\nMemory Reading, and Memory Injection, UniMem empowers researchers to conduct\nsystematic exploration of long-context methods. We re-formulate 16 existing\nmethods based on UniMem and analyze four representative methods:\nTransformer-XL, Memorizing Transformer, RMT, and Longformer into equivalent\nUniMem forms to reveal their design principles and strengths. Based on these\nanalyses, we propose UniMix, an innovative approach that integrates the\nstrengths of these algorithms. Experimental results show that UniMix achieves\nsuperior performance in handling long contexts with significantly lower\nperplexity than baselines.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "COLM 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.03009v2",
    "published_date": "2024-02-05 13:47:53 UTC",
    "updated_date": "2024-08-19 14:47:15 UTC"
  },
  {
    "arxiv_id": "2402.02992v2",
    "title": "Decoding-time Realignment of Language Models",
    "authors": [
      "Tianlin Liu",
      "Shangmin Guo",
      "Leonardo Bianco",
      "Daniele Calandriello",
      "Quentin Berthet",
      "Felipe Llinares",
      "Jessica Hoffmann",
      "Lucas Dixon",
      "Michal Valko",
      "Mathieu Blondel"
    ],
    "abstract": "Aligning language models with human preferences is crucial for reducing\nerrors and biases in these models. Alignment techniques, such as reinforcement\nlearning from human feedback (RLHF), are typically cast as optimizing a\ntradeoff between human preference rewards and a proximity regularization term\nthat encourages staying close to the unaligned model. Selecting an appropriate\nlevel of regularization is critical: insufficient regularization can lead to\nreduced model capabilities due to reward hacking, whereas excessive\nregularization hinders alignment. Traditional methods for finding the optimal\nregularization level require retraining multiple models with varying\nregularization strengths. This process, however, is resource-intensive,\nespecially for large models. To address this challenge, we propose\ndecoding-time realignment (DeRa), a simple method to explore and evaluate\ndifferent regularization strengths in aligned models without retraining. DeRa\nenables control over the degree of alignment, allowing users to smoothly\ntransition between unaligned and aligned models. It also enhances the\nefficiency of hyperparameter tuning by enabling the identification of effective\nregularization strengths using a validation dataset.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "In Proceedings of the 41st International Conference on Machine\n  Learning (ICML 2024)",
    "pdf_url": "http://arxiv.org/pdf/2402.02992v2",
    "published_date": "2024-02-05 13:31:28 UTC",
    "updated_date": "2024-05-24 08:39:07 UTC"
  },
  {
    "arxiv_id": "2402.02987v2",
    "title": "Reconstruct Your Previous Conversations! Comprehensively Investigating Privacy Leakage Risks in Conversations with GPT Models",
    "authors": [
      "Junjie Chu",
      "Zeyang Sha",
      "Michael Backes",
      "Yang Zhang"
    ],
    "abstract": "Significant advancements have recently been made in large language models\nrepresented by GPT models. Users frequently have multi-round private\nconversations with cloud-hosted GPT models for task optimization. Yet, this\noperational paradigm introduces additional attack surfaces, particularly in\ncustom GPTs and hijacked chat sessions. In this paper, we introduce a\nstraightforward yet potent Conversation Reconstruction Attack. This attack\ntargets the contents of previous conversations between GPT models and benign\nusers, i.e., the benign users' input contents during their interaction with GPT\nmodels. The adversary could induce GPT models to leak such contents by querying\nthem with designed malicious prompts. Our comprehensive examination of privacy\nrisks during the interactions with GPT models under this attack reveals GPT-4's\nconsiderable resilience. We present two advanced attacks targeting improved\nreconstruction of past conversations, demonstrating significant privacy leakage\nacross all models under these advanced techniques. Evaluating various defense\nmechanisms, we find them ineffective against these attacks. Our findings\nhighlight the ease with which privacy can be compromised in interactions with\nGPT models, urging the community to safeguard against potential abuses of these\nmodels' capabilities.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted in EMNLP 2024. 14 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.02987v2",
    "published_date": "2024-02-05 13:18:42 UTC",
    "updated_date": "2024-10-07 12:11:58 UTC"
  },
  {
    "arxiv_id": "2402.02978v1",
    "title": "Evaluating Datalog Tools for Meta-reasoning over OWL 2 QL",
    "authors": [
      "Haya Majid Qureshi",
      "Wolfgang Faber"
    ],
    "abstract": "Metamodeling is a general approach to expressing knowledge about classes and\nproperties in an ontology. It is a desirable modeling feature in multiple\napplications that simplifies the extension and reuse of ontologies.\nNevertheless, allowing metamodeling without restrictions is problematic for\nseveral reasons, mainly due to undecidability issues. Practical languages,\ntherefore, forbid classes to occur as instances of other classes or treat such\noccurrences as semantically different objects. Specifically, meta-querying in\nSPARQL under the Direct Semantic Entailment Regime (DSER) uses the latter\napproach, thereby effectively not supporting meta-queries. However, several\nextensions enabling different metamodeling features have been proposed over the\nlast decade. This paper deals with the Metamodeling Semantics (MS) over OWL 2\nQL and the Metamodeling Semantic Entailment Regime (MSER), as proposed in\nLenzerini et al. (2015) and Lenzerini et al. (2020); Cima et al. (2017). A\nreduction from OWL 2 QL to Datalog for meta-querying was proposed in Cima et\nal. (2017). In this paper, we experiment with various logic programming tools\nthat support Datalog querying to determine their suitability as back-ends to\nMSER query answering. These tools stem from different logic programming\nparadigms (Prolog, pure Datalog, Answer Set Programming, Hybrid Knowledge\nBases). Our work shows that the Datalog approach to MSER querying is practical\nalso for sizeable ontologies with limited resources (time and memory). This\npaper significantly extends Qureshi & Faber (2021) by a more detailed\nexperimental analysis and more background. Under consideration in Theory and\nPractice of Logic Programming (TPLP).",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)",
    "pdf_url": "http://arxiv.org/pdf/2402.02978v1",
    "published_date": "2024-02-05 13:06:35 UTC",
    "updated_date": "2024-02-05 13:06:35 UTC"
  },
  {
    "arxiv_id": "2402.02977v4",
    "title": "Variational Flow Models: Flowing in Your Style",
    "authors": [
      "Kien Do",
      "Duc Kieu",
      "Toan Nguyen",
      "Dang Nguyen",
      "Hung Le",
      "Dung Nguyen",
      "Thin Nguyen"
    ],
    "abstract": "We propose a systematic training-free method to transform the probability\nflow of a \"linear\" stochastic process characterized by the equation\nX_{t}=a_{t}X_{0}+\\sigma_{t}X_{1} into a straight constant-speed (SC) flow,\nreminiscent of Rectified Flow. This transformation facilitates fast sampling\nalong the original probability flow via the Euler method without training a new\nmodel of the SC flow. The flexibility of our approach allows us to extend our\ntransformation to inter-convert two posterior flows of two distinct linear\nstochastic processes. Moreover, we can easily integrate high-order numerical\nsolvers into the transformed SC flow, further enhancing the sampling accuracy\nand efficiency. Rigorous theoretical analysis and extensive experimental\nresults substantiate the advantages of our framework. Our code is available at\nthis [https://github.com/clarken92/VFM||link].",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Our code is available at: https://github.com/clarken92/VFM",
    "pdf_url": "http://arxiv.org/pdf/2402.02977v4",
    "published_date": "2024-02-05 12:58:29 UTC",
    "updated_date": "2024-08-05 01:24:52 UTC"
  },
  {
    "arxiv_id": "2405.00679v2",
    "title": "Exploring Biologically Inspired Mechanisms of Adversarial Robustness",
    "authors": [
      "Konstantin Holzhausen",
      "Mia Merlid",
      "Håkon Olav Torvik",
      "Anders Malthe-Sørenssen",
      "Mikkel Elle Lepperød"
    ],
    "abstract": "Backpropagation-optimized artificial neural networks, while precise, lack\nrobustness, leading to unforeseen behaviors that affect their safety.\nBiological neural systems do solve some of these issues already. Unlike\nartificial models, biological neurons adjust connectivity based on neighboring\ncell activity. Understanding the biological mechanisms of robustness can pave\nthe way towards building trust worthy and safe systems. Robustness in neural\nrepresentations is hypothesized to correlate with the smoothness of the\nencoding manifold. Recent work suggests power law covariance spectra, which\nwere observed studying the primary visual cortex of mice, to be indicative of a\nbalanced trade-off between accuracy and robustness in representations. Here, we\nshow that unsupervised local learning models with winner takes all dynamics\nlearn such power law representations, providing upcoming studies a mechanistic\nmodel with that characteristic. Our research aims to understand the interplay\nbetween geometry, spectral properties, robustness, and expressivity in neural\nrepresentations. Hence, we study the link between representation smoothness and\nspectrum by using weight, Jacobian and spectral regularization while assessing\nperformance and adversarial robustness. Our work serves as a foundation for\nfuture research into the mechanisms underlying power law spectra and optimally\nsmooth encodings in both biological and artificial systems. The insights gained\nmay elucidate the mechanisms that realize robust neural networks in mammalian\nbrains and inform the development of more stable and reliable artificial\nsystems.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.00679v2",
    "published_date": "2024-02-05 12:06:00 UTC",
    "updated_date": "2025-01-29 09:10:33 UTC"
  },
  {
    "arxiv_id": "2402.05128v3",
    "title": "Enhancing textual textbook question answering with large language models and retrieval augmented generation",
    "authors": [
      "Hessa Abdulrahman Alawwad",
      "Areej Alhothali",
      "Usman Naseem",
      "Ali Alkhathlan",
      "Amani Jamal"
    ],
    "abstract": "Textbook question answering (TQA) is a challenging task in artificial\nintelligence due to the complex nature of context needed to answer complex\nquestions. Although previous research has improved the task, there are still\nsome limitations in textual TQA, including weak reasoning and inability to\ncapture contextual information in the lengthy context. We propose a framework\n(PLRTQA) that incorporates the retrieval augmented generation (RAG) technique\nto handle the out-of-domain scenario where concepts are spread across different\nlessons, and utilize transfer learning to handle the long context and enhance\nreasoning abilities. Our architecture outperforms the baseline, achieving an\naccuracy improvement of 4. 12% in the validation set and 9. 84% in the test set\nfor textual multiple-choice questions. While this paper focuses on solving\nchallenges in the textual TQA, It provides a foundation for future work in\nmultimodal TQA where the visual components are integrated to address more\ncomplex educational scenarios. Code: https://github.com/hessaAlawwad/PLR-TQA",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05128v3",
    "published_date": "2024-02-05 11:58:56 UTC",
    "updated_date": "2025-01-22 07:14:27 UTC"
  },
  {
    "arxiv_id": "2402.02921v1",
    "title": "Mining a Minimal Set of Behavioral Patterns using Incremental Evaluation",
    "authors": [
      "Mehdi Acheli",
      "Daniela Grigori",
      "Matthias Weidlich"
    ],
    "abstract": "Process mining provides methods to analyse event logs generated by\ninformation systems during the execution of processes. It thereby supports the\ndesign, validation, and execution of processes in domains ranging from\nhealthcare, through manufacturing, to e-commerce. To explore the regularities\nof flexible processes that show a large behavioral variability, it was\nsuggested to mine recurrent behavioral patterns that jointly describe the\nunderlying process. Existing approaches to behavioral pattern mining, however,\nsuffer from two limitations. First, they show limited scalability as\nincremental computation is incorporated only in the generation of pattern\ncandidates, but not in the evaluation of their quality. Second, process\nanalysis based on mined patterns shows limited effectiveness due to an\noverwhelmingly large number of patterns obtained in practical application\nscenarios, many of which are redundant. In this paper, we address these\nlimitations to facilitate the analysis of complex, flexible processes based on\nbehavioral patterns. Specifically, we improve COBPAM, our initial behavioral\npattern mining algorithm, by an incremental procedure to evaluate the quality\nof pattern candidates, optimizing thereby its efficiency. Targeting a more\neffective use of the resulting patterns, we further propose pruning strategies\nfor redundant patterns and show how relations between the remaining patterns\nare extracted and visualized to provide process insights. Our experiments with\ndiverse real-world datasets indicate a considerable reduction of the runtime\nneeded for pattern mining, while a qualitative assessment highlights how\nrelations between patterns guide the analysis of the underlying process.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02921v1",
    "published_date": "2024-02-05 11:41:37 UTC",
    "updated_date": "2024-02-05 11:41:37 UTC"
  },
  {
    "arxiv_id": "2402.02910v2",
    "title": "DS-MS-TCN: Otago Exercises Recognition with a Dual-Scale Multi-Stage Temporal Convolutional Network",
    "authors": [
      "Meng Shang",
      "Lenore Dedeyne",
      "Jolan Dupont",
      "Laura Vercauteren",
      "Nadjia Amini",
      "Laurence Lapauw",
      "Evelien Gielen",
      "Sabine Verschueren",
      "Carolina Varon",
      "Walter De Raedt",
      "Bart Vanrumste"
    ],
    "abstract": "The Otago Exercise Program (OEP) represents a crucial rehabilitation\ninitiative tailored for older adults, aimed at enhancing balance and strength.\nDespite previous efforts utilizing wearable sensors for OEP recognition,\nexisting studies have exhibited limitations in terms of accuracy and\nrobustness. This study addresses these limitations by employing a single\nwaist-mounted Inertial Measurement Unit (IMU) to recognize OEP exercises among\ncommunity-dwelling older adults in their daily lives. A cohort of 36 older\nadults participated in laboratory settings, supplemented by an additional 7\nolder adults recruited for at-home assessments. The study proposes a Dual-Scale\nMulti-Stage Temporal Convolutional Network (DS-MS-TCN) designed for two-level\nsequence-to-sequence classification, incorporating them in one loss function.\nIn the first stage, the model focuses on recognizing each repetition of the\nexercises (micro labels). Subsequent stages extend the recognition to encompass\nthe complete range of exercises (macro labels). The DS-MS-TCN model surpasses\nexisting state-of-the-art deep learning models, achieving f1-scores exceeding\n80% and Intersection over Union (IoU) f1-scores surpassing 60% for all four\nexercises evaluated. Notably, the model outperforms the prior study utilizing\nthe sliding window technique, eliminating the need for post-processing stages\nand window size tuning. To our knowledge, we are the first to present a novel\nperspective on enhancing Human Activity Recognition (HAR) systems through the\nrecognition of each repetition of activities.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02910v2",
    "published_date": "2024-02-05 11:25:45 UTC",
    "updated_date": "2024-02-07 14:21:37 UTC"
  },
  {
    "arxiv_id": "2402.02904v1",
    "title": "Replication of Impedance Identification Experiments on a Reinforcement-Learning-Controlled Digital Twin of Human Elbows",
    "authors": [
      "Hao Yu",
      "Zebin Huang",
      "Qingbo Liu",
      "Ignacio Carlucho",
      "Mustafa Suphi Erden"
    ],
    "abstract": "This study presents a pioneering effort to replicate human neuromechanical\nexperiments within a virtual environment utilising a digital human model. By\nemploying MyoSuite, a state-of-the-art human motion simulation platform\nenhanced by Reinforcement Learning (RL), multiple types of impedance\nidentification experiments of human elbow were replicated on a musculoskeletal\nmodel. We compared the elbow movement controlled by an RL agent with the motion\nof an actual human elbow in terms of the impedance identified in\ntorque-perturbation experiments. The findings reveal that the RL agent exhibits\nhigher elbow impedance to stabilise the target elbow motion under perturbation\nthan a human does, likely due to its shorter reaction time and superior sensory\ncapabilities. This study serves as a preliminary exploration into the potential\nof virtual environment simulations for neuromechanical research, offering an\ninitial yet promising alternative to conventional experimental approaches. An\nRL-controlled digital twin with complete musculoskeletal models of the human\nbody is expected to be useful in designing experiments and validating\nrehabilitation theory before experiments on real human subjects.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "8 pages, 5 figures; Submitted to WCCI-2024",
    "pdf_url": "http://arxiv.org/pdf/2402.02904v1",
    "published_date": "2024-02-05 11:16:32 UTC",
    "updated_date": "2024-02-05 11:16:32 UTC"
  },
  {
    "arxiv_id": "2402.02896v1",
    "title": "LLM Agents in Interaction: Measuring Personality Consistency and Linguistic Alignment in Interacting Populations of Large Language Models",
    "authors": [
      "Ivar Frisch",
      "Mario Giulianelli"
    ],
    "abstract": "While both agent interaction and personalisation are vibrant topics in\nresearch on large language models (LLMs), there has been limited focus on the\neffect of language interaction on the behaviour of persona-conditioned LLM\nagents. Such an endeavour is important to ensure that agents remain consistent\nto their assigned traits yet are able to engage in open, naturalistic\ndialogues. In our experiments, we condition GPT-3.5 on personality profiles\nthrough prompting and create a two-group population of LLM agents using a\nsimple variability-inducing sampling algorithm. We then administer personality\ntests and submit the agents to a collaborative writing task, finding that\ndifferent profiles exhibit different degrees of personality consistency and\nlinguistic alignment to their conversational partners. Our study seeks to lay\nthe groundwork for better understanding of dialogue-based interaction between\nLLMs and highlights the need for new approaches to crafting robust, more\nhuman-like LLM personas for interactive environments.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.MA"
    ],
    "primary_category": "cs.CL",
    "comment": "To appear in Proceedings of the 1st Personalization of Generative AI\n  Workshop, EACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.02896v1",
    "published_date": "2024-02-05 11:05:20 UTC",
    "updated_date": "2024-02-05 11:05:20 UTC"
  },
  {
    "arxiv_id": "2402.02885v1",
    "title": "A Review on Building Blocks of Decentralized Artificial Intelligence",
    "authors": [
      "Vid Kersic",
      "Muhamed Turkanovic"
    ],
    "abstract": "Artificial intelligence is transforming our lives, and technological progress\nand transfer from the academic and theoretical sphere to the real world are\naccelerating yearly. But during that progress and transition, several open\nproblems and questions need to be addressed for the field to develop ethically,\nsuch as digital privacy, ownership, and control. These are some of the reasons\nwhy the currently most popular approaches of artificial intelligence, i.e.,\ncentralized AI (CEAI), are questionable, with other directions also being\nwidely explored, such as decentralized artificial intelligence (DEAI), to solve\nsome of the most reaching problems. This paper provides a systematic literature\nreview (SLR) of existing work in the field of DEAI, presenting the findings of\n71 identified studies. The paper's primary focus is identifying the building\nblocks of DEAI solutions and networks, tackling the DEAI analysis from a\nbottom-up approach. In the end, future directions of research and open problems\nare proposed.",
    "categories": [
      "cs.AI",
      "cs.CR",
      "cs.DC"
    ],
    "primary_category": "cs.AI",
    "comment": "This work has been submitted to the IEEE for possible publication",
    "pdf_url": "http://arxiv.org/pdf/2402.02885v1",
    "published_date": "2024-02-05 10:54:14 UTC",
    "updated_date": "2024-02-05 10:54:14 UTC"
  },
  {
    "arxiv_id": "2402.05963v1",
    "title": "Frugal Actor-Critic: Sample Efficient Off-Policy Deep Reinforcement Learning Using Unique Experiences",
    "authors": [
      "Nikhil Kumar Singh",
      "Indranil Saha"
    ],
    "abstract": "Efficient utilization of the replay buffer plays a significant role in the\noff-policy actor-critic reinforcement learning (RL) algorithms used for\nmodel-free control policy synthesis for complex dynamical systems. We propose a\nmethod for achieving sample efficiency, which focuses on selecting unique\nsamples and adding them to the replay buffer during the exploration with the\ngoal of reducing the buffer size and maintaining the independent and\nidentically distributed (IID) nature of the samples. Our method is based on\nselecting an important subset of the set of state variables from the\nexperiences encountered during the initial phase of random exploration,\npartitioning the state space into a set of abstract states based on the\nselected important state variables, and finally selecting the experiences with\nunique state-reward combination by using a kernel density estimator. We\nformally prove that the off-policy actor-critic algorithm incorporating the\nproposed method for unique experience accumulation converges faster than the\nvanilla off-policy actor-critic algorithm. Furthermore, we evaluate our method\nby comparing it with two state-of-the-art actor-critic RL algorithms on several\ncontinuous control benchmarks available in the Gym environment. Experimental\nresults demonstrate that our method achieves a significant reduction in the\nsize of the replay buffer for all the benchmarks while achieving either faster\nconvergent or better reward accumulation compared to the baseline algorithms.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05963v1",
    "published_date": "2024-02-05 10:04:00 UTC",
    "updated_date": "2024-02-05 10:04:00 UTC"
  },
  {
    "arxiv_id": "2402.04012v2",
    "title": "Quantized Approximately Orthogonal Recurrent Neural Networks",
    "authors": [
      "Armand Foucault",
      "Franck Mamalet",
      "François Malgouyres"
    ],
    "abstract": "In recent years, Orthogonal Recurrent Neural Networks (ORNNs) have gained\npopularity due to their ability to manage tasks involving long-term\ndependencies, such as the copy-task, and their linear complexity. However,\nexisting ORNNs utilize full precision weights and activations, which prevents\ntheir deployment on compact devices.In this paper, we explore the quantization\nof the weight matrices in ORNNs, leading to Quantized approximately Orthogonal\nRNNs (QORNNs). The construction of such networks remained an open problem,\nacknowledged for its inherent instability. We propose and investigate two\nstrategies to learn QORNN by combining quantization-aware training (QAT) and\northogonal projections. We also study post-training quantization of the\nactivations for pure integer computation of the recurrent loop. The most\nefficient models achieve results similar to state-of-the-art full-precision\nORNN, LSTM and FastRNN on a variety of standard benchmarks, even with 4-bits\nquantization.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG",
      "eess.SP",
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.04012v2",
    "published_date": "2024-02-05 09:59:57 UTC",
    "updated_date": "2024-06-10 11:40:40 UTC"
  },
  {
    "arxiv_id": "2402.02844v1",
    "title": "Comparing Knowledge Sources for Open-Domain Scientific Claim Verification",
    "authors": [
      "Juraj Vladika",
      "Florian Matthes"
    ],
    "abstract": "The increasing rate at which scientific knowledge is discovered and health\nclaims shared online has highlighted the importance of developing efficient\nfact-checking systems for scientific claims. The usual setting for this task in\nthe literature assumes that the documents containing the evidence for claims\nare already provided and annotated or contained in a limited corpus. This\nrenders the systems unrealistic for real-world settings where knowledge sources\nwith potentially millions of documents need to be queried to find relevant\nevidence. In this paper, we perform an array of experiments to test the\nperformance of open-domain claim verification systems. We test the final\nverdict prediction of systems on four datasets of biomedical and health claims\nin different settings. While keeping the pipeline's evidence selection and\nverdict prediction parts constant, document retrieval is performed over three\ncommon knowledge sources (PubMed, Wikipedia, Google) and using two different\ninformation retrieval techniques. We show that PubMed works better with\nspecialized biomedical claims, while Wikipedia is more suited for everyday\nhealth concerns. Likewise, BM25 excels in retrieval precision, while semantic\nsearch in recall of relevant evidence. We discuss the results, outline frequent\nretrieval patterns and challenges, and provide promising future directions.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to EACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.02844v1",
    "published_date": "2024-02-05 09:57:15 UTC",
    "updated_date": "2024-02-05 09:57:15 UTC"
  },
  {
    "arxiv_id": "2402.02826v1",
    "title": "SynthVision -- Harnessing Minimal Input for Maximal Output in Computer Vision Models using Synthetic Image data",
    "authors": [
      "Yudara Kularathne",
      "Prathapa Janitha",
      "Sithira Ambepitiya",
      "Thanveer Ahamed",
      "Dinuka Wijesundara",
      "Prarththanan Sothyrajah"
    ],
    "abstract": "Rapid development of disease detection computer vision models is vital in\nresponse to urgent medical crises like epidemics or events of bioterrorism.\nHowever, traditional data gathering methods are too slow for these scenarios\nnecessitating innovative approaches to generate reliable models quickly from\nminimal data. We demonstrate our new approach by building a comprehensive\ncomputer vision model for detecting Human Papilloma Virus Genital warts using\nonly synthetic data. In our study, we employed a two phase experimental design\nusing diffusion models. In the first phase diffusion models were utilized to\ngenerate a large number of diverse synthetic images from 10 HPV guide images\nexplicitly focusing on accurately depicting genital warts. The second phase\ninvolved the training and testing vision model using this synthetic dataset.\nThis method aimed to assess the effectiveness of diffusion models in rapidly\ngenerating high quality training data and the subsequent impact on the vision\nmodel performance in medical image recognition. The study findings revealed\nsignificant insights into the performance of the vision model trained on\nsynthetic images generated through diffusion models. The vision model showed\nexceptional performance in accurately identifying cases of genital warts. It\nachieved an accuracy rate of 96% underscoring its effectiveness in medical\nimage classification. For HPV cases the model demonstrated a high precision of\n99% and a recall of 94%. In normal cases the precision was 95% with an\nimpressive recall of 99%. These metrics indicate the model capability to\ncorrectly identify true positive cases and minimize false positives. The model\nachieved an F1 Score of 96% for HPV cases and 97% for normal cases. The high F1\nScore across both categories highlights the balanced nature of the model\nprecision and recall ensuring reliability and robustness in its predictions.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "12 pages 5 figures 1 table",
    "pdf_url": "http://arxiv.org/pdf/2402.02826v1",
    "published_date": "2024-02-05 09:18:49 UTC",
    "updated_date": "2024-02-05 09:18:49 UTC"
  },
  {
    "arxiv_id": "2402.02823v2",
    "title": "Evading Data Contamination Detection for Language Models is (too) Easy",
    "authors": [
      "Jasper Dekoninck",
      "Mark Niklas Müller",
      "Maximilian Baader",
      "Marc Fischer",
      "Martin Vechev"
    ],
    "abstract": "Large language models are widespread, with their performance on benchmarks\nfrequently guiding user preferences for one model over another. However, the\nvast amount of data these models are trained on can inadvertently lead to\ncontamination with public benchmarks, thus compromising performance\nmeasurements. While recently developed contamination detection methods try to\naddress this issue, they overlook the possibility of deliberate contamination\nby malicious model providers aiming to evade detection. We argue that this\nsetting is of crucial importance as it casts doubt on the reliability of public\nbenchmarks. To more rigorously study this issue, we propose a categorization of\nboth model providers and contamination detection methods. This reveals\nvulnerabilities in existing methods that we exploit with EAL, a simple yet\neffective contamination technique that significantly inflates benchmark\nperformance while completely evading current detection methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02823v2",
    "published_date": "2024-02-05 09:10:32 UTC",
    "updated_date": "2024-02-12 17:50:07 UTC"
  },
  {
    "arxiv_id": "2402.02805v2",
    "title": "Graph-enhanced Large Language Models in Asynchronous Plan Reasoning",
    "authors": [
      "Fangru Lin",
      "Emanuele La Malfa",
      "Valentin Hofmann",
      "Elle Michelle Yang",
      "Anthony Cohn",
      "Janet B. Pierrehumbert"
    ],
    "abstract": "Planning is a fundamental property of human intelligence. Reasoning about\nasynchronous plans is challenging since it requires sequential and parallel\nplanning to optimize time costs. Can large language models (LLMs) succeed at\nthis task? Here, we present the first large-scale study investigating this\nquestion. We find that a representative set of closed and open-source LLMs,\nincluding GPT-4 and LLaMA-2, behave poorly when not supplied with illustrations\nabout the task-solving process in our benchmark AsyncHow. We propose a novel\ntechnique called Plan Like a Graph (PLaG) that combines graphs with natural\nlanguage prompts and achieves state-of-the-art results. We show that although\nPLaG can boost model performance, LLMs still suffer from drastic degradation\nwhen task complexity increases, highlighting the limits of utilizing LLMs for\nsimulating digital devices. We see our study as an exciting step towards using\nLLMs as efficient autonomous agents. Our code and data are available at\nhttps://github.com/fangru-lin/graph-llm-asynchow-plan.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at ICML-2024",
    "pdf_url": "http://arxiv.org/pdf/2402.02805v2",
    "published_date": "2024-02-05 08:26:33 UTC",
    "updated_date": "2024-06-03 13:07:06 UTC"
  },
  {
    "arxiv_id": "2402.02803v2",
    "title": "Large Language Model Distilling Medication Recommendation Model",
    "authors": [
      "Qidong Liu",
      "Xian Wu",
      "Xiangyu Zhao",
      "Yuanshao Zhu",
      "Zijian Zhang",
      "Feng Tian",
      "Yefeng Zheng"
    ],
    "abstract": "The recommendation of medication is a vital aspect of intelligent healthcare\nsystems, as it involves prescribing the most suitable drugs based on a\npatient's specific health needs. Unfortunately, many sophisticated models\ncurrently in use tend to overlook the nuanced semantics of medical data, while\nonly relying heavily on identities. Furthermore, these models face significant\nchallenges in handling cases involving patients who are visiting the hospital\nfor the first time, as they lack prior prescription histories to draw upon. To\ntackle these issues, we harness the powerful semantic comprehension and\ninput-agnostic characteristics of Large Language Models (LLMs). Our research\naims to transform existing medication recommendation methodologies using LLMs.\nIn this paper, we introduce a novel approach called Large Language Model\nDistilling Medication Recommendation (LEADER). We begin by creating appropriate\nprompt templates that enable LLMs to suggest medications effectively. However,\nthe straightforward integration of LLMs into recommender systems leads to an\nout-of-corpus issue specific to drugs. We handle it by adapting the LLMs with a\nnovel output layer and a refined tuning loss function. Although LLM-based\nmodels exhibit remarkable capabilities, they are plagued by high computational\ncosts during inference, which is impractical for the healthcare sector. To\nmitigate this, we have developed a feature-level knowledge distillation\ntechnique, which transfers the LLM's proficiency to a more compact model.\nExtensive experiments conducted on two real-world datasets, MIMIC-III and\nMIMIC-IV, demonstrate that our proposed model not only delivers effective\nresults but also is efficient. To ease the reproducibility of our experiments,\nwe release the implementation code online.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02803v2",
    "published_date": "2024-02-05 08:25:22 UTC",
    "updated_date": "2025-01-27 04:30:43 UTC"
  },
  {
    "arxiv_id": "2402.02801v2",
    "title": "KS-Lottery: Finding Certified Lottery Tickets for Multilingual Language Models",
    "authors": [
      "Fei Yuan",
      "Chang Ma",
      "Shuai Yuan",
      "Qiushi Sun",
      "Lei Li"
    ],
    "abstract": "The lottery ticket hypothesis posits the existence of ``winning tickets''\nwithin a randomly initialized neural network. Do winning tickets exist for LLMs\nin fine-tuning scenarios? How can we find such winning tickets? In this paper,\nwe propose KS-Lottery, a method to identify a small subset of LLM parameters\nhighly effective in multilingual fine-tuning. Our key idea is to use\nKolmogorov-Smirnov Test to analyze the distribution shift of parameters before\nand after fine-tuning. We further theoretically prove that KS-Lottery can find\nthe certified winning tickets in the embedding layer, fine-tuning on the found\nparameters is guaranteed to perform as well as full fine-tuning. Comparing\nKS-Lottery with other parameter-efficient tuning algorithms on translation\ntasks, the experimental results show that KS-Lottery finds a much smaller set\nof parameters for fine-tuning while achieving the comparable performance as\nfull fine-tuning LLM. Surprisingly, we find that fine-tuning 18 tokens'\nembedding of LLaMA suffices to reach the fine-tuning translation\nperformance~\\footnote{https://github.com/CONE-MT/KS-Lottery.}.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02801v2",
    "published_date": "2024-02-05 08:19:56 UTC",
    "updated_date": "2024-06-03 07:35:25 UTC"
  },
  {
    "arxiv_id": "2402.02791v4",
    "title": "PanGu-$π$ Pro:Rethinking Optimization and Architecture for Tiny Language Models",
    "authors": [
      "Yehui Tang",
      "Kai Han",
      "Fangcheng Liu",
      "Yunsheng Ni",
      "Yuchuan Tian",
      "Zheyuan Bai",
      "Yi-Qi Hu",
      "Sichao Liu",
      "Shangling Jui",
      "Yunhe Wang"
    ],
    "abstract": "The power of large language models (LLMs) has been demonstrated through\nnumerous data and computing resources. However, the application of language\nmodels on mobile devices is facing huge challenge on the computation and memory\ncosts, that is, tiny language models with high performance are urgently\nrequired. Limited by the highly complex training process, there are many\ndetails for optimizing language models that are seldom studied carefully. In\nthis study, based on a tiny language model with 1B parameters, we carefully\ndesign a series of empirical study to analyze the effect of each component.\nThree perspectives are mainly discussed, \\ie, neural architecture, parameter\ninitialization, and optimization strategy. Several design formulas are\nempirically proved especially effective for tiny language models, including\ntokenizer compression, architecture tweaking, parameter inheritance and\nmultiple-round training. Then we train PanGu-$\\pi$-1B Pro and PanGu-$\\pi$-1.5B\nPro on 1.6T multilingual corpora, following the established formulas.\nExperimental results demonstrate the improved optimization and architecture\nyield a notable average improvement of 8.87 on benchmark evaluation sets for\nPanGu-$\\pi$-1B Pro. Besides, PanGu-$\\pi$-1.5B Pro surpasses a range of SOTA\nmodels with larger model sizes, validating its superior performance. The code\nis available at https://github.com/YuchuanTian/RethinkTinyLM.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02791v4",
    "published_date": "2024-02-05 07:59:38 UTC",
    "updated_date": "2025-04-03 02:13:53 UTC"
  },
  {
    "arxiv_id": "2402.02781v1",
    "title": "Dual Knowledge Distillation for Efficient Sound Event Detection",
    "authors": [
      "Yang Xiao",
      "Rohan Kumar Das"
    ],
    "abstract": "Sound event detection (SED) is essential for recognizing specific sounds and\ntheir temporal locations within acoustic signals. This becomes challenging\nparticularly for on-device applications, where computational resources are\nlimited. To address this issue, we introduce a novel framework referred to as\ndual knowledge distillation for developing efficient SED systems in this work.\nOur proposed dual knowledge distillation commences with temporal-averaging\nknowledge distillation (TAKD), utilizing a mean student model derived from the\ntemporal averaging of the student model's parameters. This allows the student\nmodel to indirectly learn from a pre-trained teacher model, ensuring a stable\nknowledge distillation. Subsequently, we introduce embedding-enhanced feature\ndistillation (EEFD), which involves incorporating an embedding distillation\nlayer within the student model to bolster contextual learning. On DCASE 2023\nTask 4A public evaluation dataset, our proposed SED system with dual knowledge\ndistillation having merely one-third of the baseline model's parameters,\ndemonstrates superior performance in terms of PSDS1 and PSDS2. This highlights\nthe importance of proposed dual knowledge distillation for compact SED systems,\nwhich can be ideal for edge devices.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted to ICASSP 2024 (Deep Neural Network Model Compression\n  Workshop)",
    "pdf_url": "http://arxiv.org/pdf/2402.02781v1",
    "published_date": "2024-02-05 07:30:32 UTC",
    "updated_date": "2024-02-05 07:30:32 UTC"
  },
  {
    "arxiv_id": "2402.10228v5",
    "title": "Q-Star Meets Scalable Posterior Sampling: Bridging Theory and Practice via HyperAgent",
    "authors": [
      "Yingru Li",
      "Jiawei Xu",
      "Lei Han",
      "Zhi-Quan Luo"
    ],
    "abstract": "We propose HyperAgent, a reinforcement learning (RL) algorithm based on the\nhypermodel framework for exploration in RL. HyperAgent allows for the efficient\nincremental approximation of posteriors associated with an optimal action-value\nfunction ($Q^\\star$) without the need for conjugacy and follows the greedy\npolicies w.r.t. these approximate posterior samples. We demonstrate that\nHyperAgent offers robust performance in large-scale deep RL benchmarks. It can\nsolve Deep Sea hard exploration problems with episodes that optimally scale\nwith problem size and exhibits significant efficiency gains in the Atari suite.\nImplementing HyperAgent requires minimal code addition to well-established deep\nRL frameworks like DQN. We theoretically prove that, under tabular assumptions,\nHyperAgent achieves logarithmic per-step computational complexity while\nattaining sublinear regret, matching the best known randomized tabular RL\nalgorithm.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Proceedings of the $\\mathit{41}^{st}$ International Conference on\n  Machine Learning, Vienna, Austria. PMLR 235, 2024. Copyright 2024 by the\n  author(s). Invited talk in Informs Optimization Conference 2024 and\n  International Symposium on Mathematical Programming 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.10228v5",
    "published_date": "2024-02-05 07:07:30 UTC",
    "updated_date": "2024-06-14 04:51:07 UTC"
  },
  {
    "arxiv_id": "2402.02769v3",
    "title": "Learning from Teaching Regularization: Generalizable Correlations Should be Easy to Imitate",
    "authors": [
      "Can Jin",
      "Tong Che",
      "Hongwu Peng",
      "Yiyuan Li",
      "Dimitris N. Metaxas",
      "Marco Pavone"
    ],
    "abstract": "Generalization remains a central challenge in machine learning. In this work,\nwe propose Learning from Teaching (LoT), a novel regularization technique for\ndeep neural networks to enhance generalization. Inspired by the human ability\nto capture concise and abstract patterns, we hypothesize that generalizable\ncorrelations are expected to be easier to imitate. LoT operationalizes this\nconcept to improve the generalization of the main model with auxiliary student\nlearners. The student learners are trained by the main model and, in turn,\nprovide feedback to help the main model capture more generalizable and imitable\ncorrelations. Our experimental results across several domains, including\nComputer Vision, Natural Language Processing, and methodologies like\nReinforcement Learning, demonstrate that the introduction of LoT brings\nsignificant benefits compared to training models on the original dataset. The\nresults suggest the effectiveness and efficiency of LoT in identifying\ngeneralizable information at the right scales while discarding spurious data\ncorrelations, thus making LoT a valuable addition to current machine learning.\nCode is available at https://github.com/jincan333/LoT.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02769v3",
    "published_date": "2024-02-05 07:05:17 UTC",
    "updated_date": "2024-10-31 06:17:08 UTC"
  },
  {
    "arxiv_id": "2402.02768v1",
    "title": "Intent Profiling and Translation Through Emergent Communication",
    "authors": [
      "Salwa Mostafa",
      "Mohammed S. Elbamby",
      "Mohamed K. Abdel-Aziz",
      "Mehdi Bennis"
    ],
    "abstract": "To effectively express and satisfy network application requirements,\nintent-based network management has emerged as a promising solution. In\nintent-based methods, users and applications express their intent in a\nhigh-level abstract language to the network. Although this abstraction\nsimplifies network operation, it induces many challenges to efficiently express\napplications' intents and map them to different network capabilities.\nTherefore, in this work, we propose an AI-based framework for intent profiling\nand translation. We consider a scenario where applications interacting with the\nnetwork express their needs for network services in their domain language. The\nmachine-to-machine communication (i.e., between applications and the network)\nis complex since it requires networks to learn how to understand the domain\nlanguages of each application, which is neither practical nor scalable.\nInstead, a framework based on emergent communication is proposed for intent\nprofiling, in which applications express their abstract quality-of-experience\n(QoE) intents to the network through emergent communication messages.\nSubsequently, the network learns how to interpret these communication messages\nand map them to network capabilities (i.e., slices) to guarantee the requested\nQuality-of-Service (QoS). Simulation results show that the proposed method\noutperforms self-learning slicing and other baselines, and achieves a\nperformance close to the perfect knowledge baseline.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02768v1",
    "published_date": "2024-02-05 07:02:43 UTC",
    "updated_date": "2024-02-05 07:02:43 UTC"
  },
  {
    "arxiv_id": "2402.02764v1",
    "title": "List-aware Reranking-Truncation Joint Model for Search and Retrieval-augmented Generation",
    "authors": [
      "Shicheng Xu",
      "Liang Pang",
      "Jun Xu",
      "Huawei Shen",
      "Xueqi Cheng"
    ],
    "abstract": "The results of information retrieval (IR) are usually presented in the form\nof a ranked list of candidate documents, such as web search for humans and\nretrieval-augmented generation for large language models (LLMs). List-aware\nretrieval aims to capture the list-level contextual features to return a better\nlist, mainly including reranking and truncation. Reranking finely re-scores the\ndocuments in the list. Truncation dynamically determines the cut-off point of\nthe ranked list to achieve the trade-off between overall relevance and avoiding\nmisinformation from irrelevant documents. Previous studies treat them as two\nseparate tasks and model them separately. However, the separation is not\noptimal. First, it is hard to share the contextual information of the ranking\nlist between the two tasks. Second, the separate pipeline usually meets the\nerror accumulation problem, where the small error from the reranking stage can\nlargely affect the truncation stage. To solve these problems, we propose a\nReranking-Truncation joint model (GenRT) that can perform the two tasks\nconcurrently. GenRT integrates reranking and truncation via generative paradigm\nbased on encoder-decoder architecture. We also design the novel loss functions\nfor joint optimization to make the model learn both tasks. Sharing parameters\nby the joint model is conducive to making full use of the common modeling\ninformation of the two tasks. Besides, the two tasks are performed concurrently\nand co-optimized to solve the error accumulation problem between separate\nstages. Experiments on public learning-to-rank benchmarks and open-domain Q\\&A\ntasks show that our method achieves SOTA performance on both reranking and\ntruncation tasks for web search and retrieval-augmented LLMs.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted by WWW 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.02764v1",
    "published_date": "2024-02-05 06:52:53 UTC",
    "updated_date": "2024-02-05 06:52:53 UTC"
  },
  {
    "arxiv_id": "2402.06147v2",
    "title": "DeAL: Decoding-time Alignment for Large Language Models",
    "authors": [
      "James Y. Huang",
      "Sailik Sengupta",
      "Daniele Bonadiman",
      "Yi-an Lai",
      "Arshit Gupta",
      "Nikolaos Pappas",
      "Saab Mansour",
      "Katrin Kirchhoff",
      "Dan Roth"
    ],
    "abstract": "Large Language Models (LLMs) are nowadays expected to generate content\naligned with human preferences. Current work focuses on alignment at model\ntraining time, through techniques such as Reinforcement Learning with Human\nFeedback (RLHF). However, it is unclear if such methods are an effective choice\nto teach alignment objectives to the model. First, the inability to incorporate\nmultiple, custom rewards and reliance on a model developer's view of universal\nand static principles are key limitations. Second, the residual gaps in model\ntraining and the reliability of such approaches are also questionable (e.g.\nsusceptibility to jail-breaking even after safety training). To address these,\nwe propose DeAL, a framework that allows the user to customize reward functions\nand enables Decoding-time Alignment of LLMs (DeAL). At its core, we view\ndecoding as a heuristic-guided search process and facilitate the use of a wide\nvariety of alignment objectives. Our experiments with programmatic constraints\nsuch as keyword and length constraints (studied widely in the pre-LLM era) and\nabstract objectives such as harmlessness and helpfulness (proposed in the\npost-LLM era) show that we can DeAL with fine-grained trade-offs, improve\nadherence to alignment objectives, and address residual gaps in LLMs. Lastly,\nwhile DeAL can be effectively paired with RLHF and prompting techniques, its\ngenerality makes decoding slower, an optimization we leave for future work.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "The appendix contains data that is offensive / disturbing in nature",
    "pdf_url": "http://arxiv.org/pdf/2402.06147v2",
    "published_date": "2024-02-05 06:12:29 UTC",
    "updated_date": "2024-02-21 02:25:32 UTC"
  },
  {
    "arxiv_id": "2402.05127v1",
    "title": "Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering",
    "authors": [
      "Aryan Agrawal"
    ],
    "abstract": "This paper introduces a novel paradigm for depression detection and treatment\nusing advanced Large Language Models (LLMs): Generative Pre-trained Transformer\n4 (GPT-4), Llama 2 chat, and Gemini. These LLMs are fine-tuned with specialized\nprompts to diagnose, explain, and suggest therapeutic interventions for\ndepression. A unique few-shot prompting method enhances the models' ability to\nanalyze and explain depressive symptoms based on the DSM-5 criteria. In the\ninteraction phase, the models engage in empathetic dialogue management, drawing\nfrom resources like PsychDB and a Cognitive Behavioral Therapy (CBT) Guide,\nfostering supportive interactions with individuals experiencing major\ndepressive disorders. Additionally, the research introduces the Illuminate\nDatabase, enriched with various CBT modules, aiding in personalized therapy\nrecommendations. The study evaluates LLM performance using metrics such as F1\nscores, Precision, Recall, Cosine similarity, and Recall-Oriented Understudy\nfor Gisting Evaluation (ROUGE) across different test sets, demonstrating their\neffectiveness. This comprehensive approach blends cutting-edge AI with\nestablished psychological methods, offering new possibilities in mental health\ncare and showcasing the potential of LLMs in revolutionizing depression\ndiagnosis and treatment strategies.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 9 figures, 9 tables",
    "pdf_url": "http://arxiv.org/pdf/2402.05127v1",
    "published_date": "2024-02-05 06:08:06 UTC",
    "updated_date": "2024-02-05 06:08:06 UTC"
  },
  {
    "arxiv_id": "2402.02733v4",
    "title": "ToonAging: Face Re-Aging upon Artistic Portrait Style Transfer",
    "authors": [
      "Bumsoo Kim",
      "Abdul Muqeet",
      "Kyuchul Lee",
      "Sanghyun Seo"
    ],
    "abstract": "Face re-aging is a prominent field in computer vision and graphics, with\nsignificant applications in photorealistic domains such as movies, advertising,\nand live streaming. Recently, the need to apply face re-aging to\nnon-photorealistic images, like comics, illustrations, and animations, has\nemerged as an extension in various entertainment sectors. However, the lack of\na network that can seamlessly edit the apparent age in NPR images has limited\nthese tasks to a naive, sequential approach. This often results in unpleasant\nartifacts and a loss of facial attributes due to domain discrepancies. In this\npaper, we introduce a novel one-stage method for face re-aging combined with\nportrait style transfer, executed in a single generative step. We leverage\nexisting face re-aging and style transfer networks, both trained within the\nsame PR domain. Our method uniquely fuses distinct latent vectors, each\nresponsible for managing aging-related attributes and NPR appearance. By\nadopting an exemplar-based approach, our method offers greater flexibility\ncompared to domain-level fine-tuning approaches, which typically require\nseparate training or fine-tuning for each domain. This effectively addresses\nthe limitation of requiring paired datasets for re-aging and domain-level,\ndata-driven approaches for stylization. Our experiments show that our model can\neffortlessly generate re-aged images while simultaneously transferring the\nstyle of examples, maintaining both natural appearance and controllability.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at CVPR 2024 AI4CC Workshop, Project Page:\n  https://gh-bumsookim.github.io/ToonAging/",
    "pdf_url": "http://arxiv.org/pdf/2402.02733v4",
    "published_date": "2024-02-05 05:25:33 UTC",
    "updated_date": "2024-05-28 05:00:41 UTC"
  },
  {
    "arxiv_id": "2402.02732v1",
    "title": "A Generative Approach to Surrogate-based Black-box Attacks",
    "authors": [
      "Raha Moraffah",
      "Huan Liu"
    ],
    "abstract": "Surrogate-based black-box attacks have exposed the heightened vulnerability\nof DNNs. These attacks are designed to craft adversarial examples for any\nsamples with black-box target feedback for only a given set of samples.\nState-of-the-art surrogate-based attacks involve training a discriminative\nsurrogate that mimics the target's outputs. The goal is to learn the decision\nboundaries of the target. The surrogate is then attacked by white-box attacks\nto craft adversarial examples similar to the original samples but belong to\nother classes. With limited samples, the discriminative surrogate fails to\naccurately learn the target's decision boundaries, and these surrogate-based\nattacks suffer from low success rates. Different from the discriminative\napproach, we propose a generative surrogate that learns the distribution of\nsamples residing on or close to the target's decision boundaries. The\ndistribution learned by the generative surrogate can be used to craft\nadversarial examples that have imperceptible differences from the original\nsamples but belong to other classes. The proposed generative approach results\nin attacks with remarkably high attack success rates on various targets and\ndatasets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02732v1",
    "published_date": "2024-02-05 05:22:58 UTC",
    "updated_date": "2024-02-05 05:22:58 UTC"
  },
  {
    "arxiv_id": "2402.02718v1",
    "title": "Denoising Time Cycle Modeling for Recommendation",
    "authors": [
      "Sicong Xie",
      "Qunwei Li",
      "Weidi Xu",
      "Kaiming Shen",
      "Shaohu Chen",
      "Wenliang Zhong"
    ],
    "abstract": "Recently, modeling temporal patterns of user-item interactions have attracted\nmuch attention in recommender systems. We argue that existing methods ignore\nthe variety of temporal patterns of user behaviors. We define the subset of\nuser behaviors that are irrelevant to the target item as noises, which limits\nthe performance of target-related time cycle modeling and affect the\nrecommendation performance. In this paper, we propose Denoising Time Cycle\nModeling (DiCycle), a novel approach to denoise user behaviors and select the\nsubset of user behaviors that are highly related to the target item. DiCycle is\nable to explicitly model diverse time cycle patterns for recommendation.\nExtensive experiments are conducted on both public benchmarks and a real-world\ndataset, demonstrating the superior performance of DiCycle over the\nstate-of-the-art recommendation methods.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02718v1",
    "published_date": "2024-02-05 04:28:08 UTC",
    "updated_date": "2024-02-05 04:28:08 UTC"
  },
  {
    "arxiv_id": "2402.02716v1",
    "title": "Understanding the planning of LLM agents: A survey",
    "authors": [
      "Xu Huang",
      "Weiwen Liu",
      "Xiaolong Chen",
      "Xingmei Wang",
      "Hao Wang",
      "Defu Lian",
      "Yasheng Wang",
      "Ruiming Tang",
      "Enhong Chen"
    ],
    "abstract": "As Large Language Models (LLMs) have shown significant intelligence, the\nprogress to leverage LLMs as planning modules of autonomous agents has\nattracted more attention. This survey provides the first systematic view of\nLLM-based agents planning, covering recent works aiming to improve planning\nability. We provide a taxonomy of existing works on LLM-Agent planning, which\ncan be categorized into Task Decomposition, Plan Selection, External Module,\nReflection and Memory. Comprehensive analyses are conducted for each direction,\nand further challenges for the field of research are discussed.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages, 2 tables, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.02716v1",
    "published_date": "2024-02-05 04:25:24 UTC",
    "updated_date": "2024-02-05 04:25:24 UTC"
  },
  {
    "arxiv_id": "2402.02713v2",
    "title": "Position: What Can Large Language Models Tell Us about Time Series Analysis",
    "authors": [
      "Ming Jin",
      "Yifan Zhang",
      "Wei Chen",
      "Kexin Zhang",
      "Yuxuan Liang",
      "Bin Yang",
      "Jindong Wang",
      "Shirui Pan",
      "Qingsong Wen"
    ],
    "abstract": "Time series analysis is essential for comprehending the complexities inherent\nin various realworld systems and applications. Although large language models\n(LLMs) have recently made significant strides, the development of artificial\ngeneral intelligence (AGI) equipped with time series analysis capabilities\nremains in its nascent phase. Most existing time series models heavily rely on\ndomain knowledge and extensive model tuning, predominantly focusing on\nprediction tasks. In this paper, we argue that current LLMs have the potential\nto revolutionize time series analysis, thereby promoting efficient\ndecision-making and advancing towards a more universal form of time series\nanalytical intelligence. Such advancement could unlock a wide range of\npossibilities, including time series modality switching and question answering.\nWe encourage researchers and practitioners to recognize the potential of LLMs\nin advancing time series analysis and emphasize the need for trust in these\nrelated efforts. Furthermore, we detail the seamless integration of time series\nanalysis with existing LLM technologies and outline promising avenues for\nfuture research.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by the 41st International Conference on Machine Learning\n  (ICML 2024)",
    "pdf_url": "http://arxiv.org/pdf/2402.02713v2",
    "published_date": "2024-02-05 04:17:49 UTC",
    "updated_date": "2024-06-01 06:42:09 UTC"
  },
  {
    "arxiv_id": "2402.09453v1",
    "title": "Improving EEG Signal Classification Accuracy Using Wasserstein Generative Adversarial Networks",
    "authors": [
      "Joshua Park",
      "Priyanshu Mahey",
      "Ore Adeniyi"
    ],
    "abstract": "Electroencephalography (EEG) plays a vital role in recording brain activities\nand is integral to the development of brain-computer interface (BCI)\ntechnologies. However, the limited availability and high variability of EEG\nsignals present substantial challenges in creating reliable BCIs. To address\nthis issue, we propose a practical solution drawing on the latest developments\nin deep learning and Wasserstein Generative Adversarial Network (WGAN). The\nWGAN was trained on the BCI2000 dataset, consisting of around 1500 EEG\nrecordings and 64 channels from 45 individuals. The generated EEG signals were\nevaluated via three classifiers yielding improved average accuracies. The\nquality of generated signals measured using Frechet Inception Distance (FID)\nyielded scores of 1.345 and 11.565 for eyes-open and closed respectively. Even\nwithout a spectral or spatial loss term, our WGAN model was able to emulate the\nspectral and spatial properties of the EEG training data. The WGAN-generated\ndata mirrored the dominant alpha activity during closed-eye resting and high\ndelta waves in the training data in its topographic map and power spectral\ndensity (PSD) plot. Our research testifies to the potential of WGANs in\naddressing the limited EEG data issue for BCI development by enhancing a small\ndataset to improve classifier generalizability.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "11 pages, 2 tables, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.09453v1",
    "published_date": "2024-02-05 03:57:30 UTC",
    "updated_date": "2024-02-05 03:57:30 UTC"
  },
  {
    "arxiv_id": "2402.06656v1",
    "title": "DiffsFormer: A Diffusion Transformer on Stock Factor Augmentation",
    "authors": [
      "Yuan Gao",
      "Haokun Chen",
      "Xiang Wang",
      "Zhicai Wang",
      "Xue Wang",
      "Jinyang Gao",
      "Bolin Ding"
    ],
    "abstract": "Machine learning models have demonstrated remarkable efficacy and efficiency\nin a wide range of stock forecasting tasks. However, the inherent challenges of\ndata scarcity, including low signal-to-noise ratio (SNR) and data homogeneity,\npose significant obstacles to accurate forecasting. To address this issue, we\npropose a novel approach that utilizes artificial intelligence-generated\nsamples (AIGS) to enhance the training procedures. In our work, we introduce\nthe Diffusion Model to generate stock factors with Transformer architecture\n(DiffsFormer). DiffsFormer is initially trained on a large-scale source domain,\nincorporating conditional guidance so as to capture global joint distribution.\nWhen presented with a specific downstream task, we employ DiffsFormer to\naugment the training procedure by editing existing samples. This editing step\nallows us to control the strength of the editing process, determining the\nextent to which the generated data deviates from the target domain. To evaluate\nthe effectiveness of DiffsFormer augmented training, we conduct experiments on\nthe CSI300 and CSI800 datasets, employing eight commonly used machine learning\nmodels. The proposed method achieves relative improvements of 7.2% and 27.8% in\nannualized return ratio for the respective datasets. Furthermore, we perform\nextensive experiments to gain insights into the functionality of DiffsFormer\nand its constituent components, elucidating how they address the challenges of\ndata scarcity and enhance the overall model performance. Our research\ndemonstrates the efficacy of leveraging AIGS and the DiffsFormer architecture\nto mitigate data scarcity in stock forecasting tasks.",
    "categories": [
      "q-fin.ST",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-fin.ST",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.06656v1",
    "published_date": "2024-02-05 03:54:36 UTC",
    "updated_date": "2024-02-05 03:54:36 UTC"
  },
  {
    "arxiv_id": "2402.02705v2",
    "title": "Representation Surgery for Multi-Task Model Merging",
    "authors": [
      "Enneng Yang",
      "Li Shen",
      "Zhenyi Wang",
      "Guibing Guo",
      "Xiaojun Chen",
      "Xingwei Wang",
      "Dacheng Tao"
    ],
    "abstract": "Multi-task learning (MTL) compresses the information from multiple tasks into\na unified backbone to improve computational efficiency and generalization.\nRecent work directly merges multiple independently trained models to perform\nMTL instead of collecting their raw data for joint training, greatly expanding\nthe application scenarios of MTL. However, by visualizing the representation\ndistribution of existing model merging schemes, we find that the merged model\noften suffers from the dilemma of representation bias. That is, there is a\nsignificant discrepancy in the representation distribution between the merged\nand individual models, resulting in poor performance of merged MTL. In this\npaper, we propose a representation surgery solution called \"Surgery\" to reduce\nrepresentation bias in the merged model. Specifically, Surgery is a lightweight\ntask-specific module that takes the representation of the merged model as input\nand attempts to output the biases contained in the representation from the\nmerged model. We then designed an unsupervised optimization objective that\nupdates the Surgery module by minimizing the distance between the merged\nmodel's representation and the individual model's representation. Extensive\nexperiments demonstrate significant MTL performance improvements when our\nSurgery module is applied to state-of-the-art (SOTA) model merging schemes.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Forty-first International Conference on Machine Learning (ICML 2024)",
    "pdf_url": "http://arxiv.org/pdf/2402.02705v2",
    "published_date": "2024-02-05 03:39:39 UTC",
    "updated_date": "2024-05-28 09:35:17 UTC"
  },
  {
    "arxiv_id": "2402.02701v2",
    "title": "Understanding What Affects the Generalization Gap in Visual Reinforcement Learning: Theory and Empirical Evidence",
    "authors": [
      "Jiafei Lyu",
      "Le Wan",
      "Xiu Li",
      "Zongqing Lu"
    ],
    "abstract": "Recently, there are many efforts attempting to learn useful policies for\ncontinuous control in visual reinforcement learning (RL). In this scenario, it\nis important to learn a generalizable policy, as the testing environment may\ndiffer from the training environment, e.g., there exist distractors during\ndeployment. Many practical algorithms are proposed to handle this problem.\nHowever, to the best of our knowledge, none of them provide a theoretical\nunderstanding of what affects the generalization gap and why their proposed\nmethods work. In this paper, we bridge this issue by theoretically answering\nthe key factors that contribute to the generalization gap when the testing\nenvironment has distractors. Our theories indicate that minimizing the\nrepresentation distance between training and testing environments, which aligns\nwith human intuition, is the most critical for the benefit of reducing the\ngeneralization gap. Our theoretical results are supported by the empirical\nevidence in the DMControl Generalization Benchmark (DMC-GB).",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by Journal of Artificial Intelligence Research (JAIR)",
    "pdf_url": "http://arxiv.org/pdf/2402.02701v2",
    "published_date": "2024-02-05 03:27:52 UTC",
    "updated_date": "2024-10-16 08:12:42 UTC"
  },
  {
    "arxiv_id": "2402.02698v1",
    "title": "Beyond Expectations: Learning with Stochastic Dominance Made Practical",
    "authors": [
      "Shicong Cen",
      "Jincheng Mei",
      "Hanjun Dai",
      "Dale Schuurmans",
      "Yuejie Chi",
      "Bo Dai"
    ],
    "abstract": "Stochastic dominance models risk-averse preferences for decision making with\nuncertain outcomes, which naturally captures the intrinsic structure of the\nunderlying uncertainty, in contrast to simply resorting to the expectations.\nDespite theoretically appealing, the application of stochastic dominance in\nmachine learning has been scarce, due to the following challenges:\n$\\textbf{i)}$, the original concept of stochastic dominance only provides a\n$\\textit{partial order}$, therefore, is not amenable to serve as an optimality\ncriterion; and $\\textbf{ii)}$, an efficient computational recipe remains\nlacking due to the continuum nature of evaluating stochastic dominance.%, which\nbarriers its application for machine learning.\n  In this work, we make the first attempt towards establishing a general\nframework of learning with stochastic dominance. We first generalize the\nstochastic dominance concept to enable feasible comparisons between any\narbitrary pair of random variables. We next develop a simple and\ncomputationally efficient approach for finding the optimal solution in terms of\nstochastic dominance, which can be seamlessly plugged into many learning tasks.\nNumerical experiments demonstrate that the proposed method achieves comparable\nperformance as standard risk-neutral strategies and obtains better trade-offs\nagainst risk across a variety of applications including supervised learning,\nreinforcement learning, and portfolio optimization.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02698v1",
    "published_date": "2024-02-05 03:21:23 UTC",
    "updated_date": "2024-02-05 03:21:23 UTC"
  },
  {
    "arxiv_id": "2402.02696v1",
    "title": "Causal Feature Selection for Responsible Machine Learning",
    "authors": [
      "Raha Moraffah",
      "Paras Sheth",
      "Saketh Vishnubhatla",
      "Huan Liu"
    ],
    "abstract": "Machine Learning (ML) has become an integral aspect of many real-world\napplications. As a result, the need for responsible machine learning has\nemerged, focusing on aligning ML models to ethical and social values, while\nenhancing their reliability and trustworthiness. Responsible ML involves many\nissues. This survey addresses four main issues: interpretability, fairness,\nadversarial robustness, and domain generalization. Feature selection plays a\npivotal role in the responsible ML tasks. However, building upon statistical\ncorrelations between variables can lead to spurious patterns with biases and\ncompromised performance. This survey focuses on the current study of causal\nfeature selection: what it is and how it can reinforce the four aspects of\nresponsible ML. By identifying features with causal impacts on outcomes and\ndistinguishing causality from correlation, causal feature selection is posited\nas a unique approach to ensuring ML models to be ethically and socially\nresponsible in high-stakes applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02696v1",
    "published_date": "2024-02-05 03:20:28 UTC",
    "updated_date": "2024-02-05 03:20:28 UTC"
  },
  {
    "arxiv_id": "2402.02695v2",
    "title": "Exploiting Class Probabilities for Black-box Sentence-level Attacks",
    "authors": [
      "Raha Moraffah",
      "Huan Liu"
    ],
    "abstract": "Sentence-level attacks craft adversarial sentences that are synonymous with\ncorrectly-classified sentences but are misclassified by the text classifiers.\nUnder the black-box setting, classifiers are only accessible through their\nfeedback to queried inputs, which is predominately available in the form of\nclass probabilities. Even though utilizing class probabilities results in\nstronger attacks, due to the challenges of using them for sentence-level\nattacks, existing attacks use either no feedback or only the class labels.\nOvercoming the challenges, we develop a novel algorithm that uses class\nprobabilities for black-box sentence-level attacks, investigate the\neffectiveness of using class probabilities on the attack's success, and examine\nthe question if it is worthy or practical to use class probabilities by\nblack-box sentence-level attacks. We conduct extensive evaluations of our\nattack comparing with the baselines across various classifiers and benchmark\ndatasets.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "EACL 2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2402.02695v2",
    "published_date": "2024-02-05 03:15:26 UTC",
    "updated_date": "2024-02-21 00:09:00 UTC"
  },
  {
    "arxiv_id": "2402.02687v1",
    "title": "Poisson Process for Bayesian Optimization",
    "authors": [
      "Xiaoxing Wang",
      "Jiaxing Li",
      "Chao Xue",
      "Wei Liu",
      "Weifeng Liu",
      "Xiaokang Yang",
      "Junchi Yan",
      "Dacheng Tao"
    ],
    "abstract": "BayesianOptimization(BO) is a sample-efficient black-box optimizer, and\nextensive methods have been proposed to build the absolute function response of\nthe black-box function through a probabilistic surrogate model, including\nTree-structured Parzen Estimator (TPE), random forest (SMAC), and Gaussian\nprocess (GP). However, few methods have been explored to estimate the relative\nrankings of candidates, which can be more robust to noise and have better\npracticality than absolute function responses, especially when the function\nresponses are intractable but preferences can be acquired. To this end, we\npropose a novel ranking-based surrogate model based on the Poisson process and\nintroduce an efficient BO framework, namely Poisson Process Bayesian\nOptimization (PoPBO). Two tailored acquisition functions are further derived\nfrom classic LCB and EI to accommodate it. Compared to the classic GP-BO\nmethod, our PoPBO has lower computation costs and better robustness to noise,\nwhich is verified by abundant experiments. The results on both simulated and\nreal-world benchmarks, including hyperparameter optimization (HPO) and neural\narchitecture search (NAS), show the effectiveness of PoPBO.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02687v1",
    "published_date": "2024-02-05 02:54:50 UTC",
    "updated_date": "2024-02-05 02:54:50 UTC"
  },
  {
    "arxiv_id": "2402.06655v1",
    "title": "Adversarial Text Purification: A Large Language Model Approach for Defense",
    "authors": [
      "Raha Moraffah",
      "Shubh Khandelwal",
      "Amrita Bhattacharjee",
      "Huan Liu"
    ],
    "abstract": "Adversarial purification is a defense mechanism for safeguarding classifiers\nagainst adversarial attacks without knowing the type of attacks or training of\nthe classifier. These techniques characterize and eliminate adversarial\nperturbations from the attacked inputs, aiming to restore purified samples that\nretain similarity to the initially attacked ones and are correctly classified\nby the classifier. Due to the inherent challenges associated with\ncharacterizing noise perturbations for discrete inputs, adversarial text\npurification has been relatively unexplored. In this paper, we investigate the\neffectiveness of adversarial purification methods in defending text\nclassifiers. We propose a novel adversarial text purification that harnesses\nthe generative capabilities of Large Language Models (LLMs) to purify\nadversarial text without the need to explicitly characterize the discrete noise\nperturbations. We utilize prompt engineering to exploit LLMs for recovering the\npurified examples for given adversarial examples such that they are\nsemantically similar and correctly classified. Our proposed method demonstrates\nremarkable performance over various classifiers, improving their accuracy under\nthe attack by over 65% on average.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "PAKDD 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.06655v1",
    "published_date": "2024-02-05 02:36:41 UTC",
    "updated_date": "2024-02-05 02:36:41 UTC"
  },
  {
    "arxiv_id": "2402.02681v3",
    "title": "Equivariant Symmetry Breaking Sets",
    "authors": [
      "YuQing Xie",
      "Tess Smidt"
    ],
    "abstract": "Equivariant neural networks (ENNs) have been shown to be extremely effective\nin applications involving underlying symmetries. By construction ENNs cannot\nproduce lower symmetry outputs given a higher symmetry input. However, symmetry\nbreaking occurs in many physical systems and we may obtain a less symmetric\nstable state from an initial highly symmetric one. Hence, it is imperative that\nwe understand how to systematically break symmetry in ENNs. In this work, we\npropose a novel symmetry breaking framework that is fully equivariant and is\nthe first which fully addresses spontaneous symmetry breaking. We emphasize\nthat our approach is general and applicable to equivariance under any group. To\nachieve this, we introduce the idea of symmetry breaking sets (SBS). Rather\nthan redesign existing networks, we design sets of symmetry breaking objects\nwhich we feed into our network based on the symmetry of our inputs and outputs.\nWe show there is a natural way to define equivariance on these sets, which\ngives an additional constraint. Minimizing the size of these sets equates to\ndata efficiency. We prove that minimizing these sets translates to a well\nstudied group theory problem, and tabulate solutions to this problem for the\npoint groups. Finally, we provide some examples of symmetry breaking to\ndemonstrate how our approach works in practice. The code for these examples is\navailable at \\url{https://github.com/atomicarchitects/equivariant-SBS}.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "50 pages, 19 figures Published in Transactions on Machine Learning\n  Research, October 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.02681v3",
    "published_date": "2024-02-05 02:35:11 UTC",
    "updated_date": "2024-11-14 16:30:13 UTC"
  },
  {
    "arxiv_id": "2402.02680v2",
    "title": "Large Language Models are Geographically Biased",
    "authors": [
      "Rohin Manvi",
      "Samar Khanna",
      "Marshall Burke",
      "David Lobell",
      "Stefano Ermon"
    ],
    "abstract": "Large Language Models (LLMs) inherently carry the biases contained in their\ntraining corpora, which can lead to the perpetuation of societal harm. As the\nimpact of these foundation models grows, understanding and evaluating their\nbiases becomes crucial to achieving fairness and accuracy. We propose to study\nwhat LLMs know about the world we live in through the lens of geography. This\napproach is particularly powerful as there is ground truth for the numerous\naspects of human life that are meaningfully projected onto geographic space\nsuch as culture, race, language, politics, and religion. We show various\nproblematic geographic biases, which we define as systemic errors in geospatial\npredictions. Initially, we demonstrate that LLMs are capable of making accurate\nzero-shot geospatial predictions in the form of ratings that show strong\nmonotonic correlation with ground truth (Spearman's $\\rho$ of up to 0.89). We\nthen show that LLMs exhibit common biases across a range of objective and\nsubjective topics. In particular, LLMs are clearly biased against locations\nwith lower socioeconomic conditions (e.g. most of Africa) on a variety of\nsensitive subjective topics such as attractiveness, morality, and intelligence\n(Spearman's $\\rho$ of up to 0.70). Finally, we introduce a bias score to\nquantify this and find that there is significant variation in the magnitude of\nbias across existing LLMs. Code is available on the project website:\nhttps://rohinmanvi.github.io/GeoLLM",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02680v2",
    "published_date": "2024-02-05 02:32:09 UTC",
    "updated_date": "2024-10-05 18:20:58 UTC"
  },
  {
    "arxiv_id": "2402.02675v2",
    "title": "Verifiable evaluations of machine learning models using zkSNARKs",
    "authors": [
      "Tobin South",
      "Alexander Camuto",
      "Shrey Jain",
      "Shayla Nguyen",
      "Robert Mahari",
      "Christian Paquin",
      "Jason Morton",
      "Alex 'Sandy' Pentland"
    ],
    "abstract": "In a world of increasing closed-source commercial machine learning models,\nmodel evaluations from developers must be taken at face value. These benchmark\nresults-whether over task accuracy, bias evaluations, or safety checks-are\ntraditionally impossible to verify by a model end-user without the costly or\nimpossible process of re-performing the benchmark on black-box model outputs.\nThis work presents a method of verifiable model evaluation using model\ninference through zkSNARKs. The resulting zero-knowledge computational proofs\nof model outputs over datasets can be packaged into verifiable evaluation\nattestations showing that models with fixed private weights achieve stated\nperformance or fairness metrics over public inputs. We present a flexible\nproving system that enables verifiable attestations to be performed on any\nstandard neural network model with varying compute requirements. For the first\ntime, we demonstrate this across a sample of real-world models and highlight\nkey challenges and design solutions. This presents a new transparency paradigm\nin the verifiable evaluation of private models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "68T01"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02675v2",
    "published_date": "2024-02-05 02:21:11 UTC",
    "updated_date": "2024-05-22 17:36:47 UTC"
  },
  {
    "arxiv_id": "2402.02658v2",
    "title": "Multi-step Problem Solving Through a Verifier: An Empirical Analysis on Model-induced Process Supervision",
    "authors": [
      "Zihan Wang",
      "Yunxuan Li",
      "Yuexin Wu",
      "Liangchen Luo",
      "Le Hou",
      "Hongkun Yu",
      "Jingbo Shang"
    ],
    "abstract": "Process supervision, using a trained verifier to evaluate the intermediate\nsteps generated by a reasoner, has demonstrated significant improvements in\nmulti-step problem solving. In this paper, to avoid the expensive effort of\nhuman annotation on the verifier training data, we introduce Model-induced\nProcess Supervision (MiPS), a novel method for automating data curation. MiPS\nannotates an intermediate step by sampling completions of this solution through\nthe reasoning model, and obtaining an accuracy defined as the proportion of\ncorrect completions. Inaccuracies of the reasoner would cause MiPS\nunderestimating the accuracy of intermediate steps, therefore, we suggest and\nempirically show that verification focusing on high predicted scores of the\nverifier shall be preferred over that of low predicted scores, contrary to\nprior observations on human curated data. Our approach significantly improves\nthe performance of PaLM 2 on math and coding tasks (accuracy +0.67% on GSM8K,\n+4.16% on MATH, +0.92% on MBPP compared with an output supervision trained\nverifier). Additionally, our study demonstrates that the verifier exhibits\nstrong generalization ability across different reasoning models.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02658v2",
    "published_date": "2024-02-05 00:57:51 UTC",
    "updated_date": "2024-10-14 19:33:00 UTC"
  },
  {
    "arxiv_id": "2402.02651v3",
    "title": "Vision-Language Models Provide Promptable Representations for Reinforcement Learning",
    "authors": [
      "William Chen",
      "Oier Mees",
      "Aviral Kumar",
      "Sergey Levine"
    ],
    "abstract": "Humans can quickly learn new behaviors by leveraging background world\nknowledge. In contrast, agents trained with reinforcement learning (RL)\ntypically learn behaviors from scratch. We thus propose a novel approach that\nuses the vast amounts of general and indexable world knowledge encoded in\nvision-language models (VLMs) pre-trained on Internet-scale data for embodied\nRL. We initialize policies with VLMs by using them as promptable\nrepresentations: embeddings that encode semantic features of visual\nobservations based on the VLM's internal knowledge and reasoning capabilities,\nas elicited through prompts that provide task context and auxiliary\ninformation. We evaluate our approach on visually-complex, long horizon RL\ntasks in Minecraft and robot navigation in Habitat. We find that our policies\ntrained on embeddings from off-the-shelf, general-purpose VLMs outperform\nequivalent policies trained on generic, non-promptable image embeddings. We\nalso find our approach outperforms instruction-following methods and performs\ncomparably to domain-specific embeddings. Finally, we show that our approach\ncan use chain-of-thought prompting to produce representations of common-sense\nsemantic reasoning, improving policy performance in novel scenes by 1.5 times.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02651v3",
    "published_date": "2024-02-05 00:48:56 UTC",
    "updated_date": "2024-05-23 01:04:11 UTC"
  },
  {
    "arxiv_id": "2402.02648v2",
    "title": "Recursive Chain-of-Feedback Prevents Performance Degradation from Redundant Prompting",
    "authors": [
      "Jinwoo Ahn",
      "Kyuseung Shin"
    ],
    "abstract": "Large Language Models (LLMs) frequently struggle with complex reasoning\ntasks, failing to construct logically sound steps towards the solution. In\nresponse to this behavior, users often try prompting the LLMs repeatedly in\nhopes of reaching a better response. This paper studies such repetitive\nbehavior and its effect by defining a novel setting, Chain-of-Feedback (CoF).\nThe setting takes questions that require multi-step reasoning as an input. Upon\nresponse, we repetitively prompt meaningless feedback (e.g. 'make another\nattempt') requesting additional trials. Surprisingly, our preliminary results\nshow that repeated meaningless feedback gradually decreases the quality of the\nresponses, eventually leading to a larger deviation from the intended outcome.\nTo alleviate these troubles, we propose a novel method, Recursive\nChain-of-Feedback (R-CoF). Following the logic of recursion in computer\nscience, R-CoF recursively revises the initially incorrect response by breaking\ndown each incorrect reasoning step into smaller individual problems. Our\npreliminary results show that majority of questions that LLMs fail to respond\ncorrectly can be answered using R-CoF without any sample data outlining the\nlogical process.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Still Ongoing Work; 8 Pages; 2 Figures",
    "pdf_url": "http://arxiv.org/pdf/2402.02648v2",
    "published_date": "2024-02-05 00:44:28 UTC",
    "updated_date": "2024-03-01 10:46:01 UTC"
  },
  {
    "arxiv_id": "2402.05125v3",
    "title": "Zero-Shot Clinical Trial Patient Matching with LLMs",
    "authors": [
      "Michael Wornow",
      "Alejandro Lozano",
      "Dev Dash",
      "Jenelle Jindal",
      "Kenneth W. Mahaffey",
      "Nigam H. Shah"
    ],
    "abstract": "Matching patients to clinical trials is a key unsolved challenge in bringing\nnew drugs to market. Today, identifying patients who meet a trial's eligibility\ncriteria is highly manual, taking up to 1 hour per patient. Automated screening\nis challenging, however, as it requires understanding unstructured clinical\ntext. Large language models (LLMs) offer a promising solution. In this work, we\nexplore their application to trial matching. First, we design an LLM-based\nsystem which, given a patient's medical history as unstructured clinical text,\nevaluates whether that patient meets a set of inclusion criteria (also\nspecified as free text). Our zero-shot system achieves state-of-the-art scores\non the n2c2 2018 cohort selection benchmark. Second, we improve the data and\ncost efficiency of our method by identifying a prompting strategy which matches\npatients an order of magnitude faster and more cheaply than the status quo, and\ndevelop a two-stage retrieval pipeline that reduces the number of tokens\nprocessed by up to a third while retaining high performance. Third, we evaluate\nthe interpretability of our system by having clinicians evaluate the natural\nlanguage justifications generated by the LLM for each eligibility decision, and\nshow that it can output coherent explanations for 97% of its correct decisions\nand 75% of its incorrect ones. Our results establish the feasibility of using\nLLMs to accelerate clinical trial operations.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05125v3",
    "published_date": "2024-02-05 00:06:08 UTC",
    "updated_date": "2024-04-10 05:37:26 UTC"
  }
]