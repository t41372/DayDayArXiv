{
  "date": "2025-12-05",
  "category": "cs.AI",
  "summary": "æ¬¢è¿æ¥åˆ° UTC æ—¶é—´ 2025-12-05 çš„ arXiv ä¸­æ–‡ TLDR å¿«æŠ¥ï¼\n\n**ä¸€å¥è¯æ€»ç»“ï¼š**\nä»Šå¤©çš„ arXiv å……æ»¡äº†å¯¹ **AGI ç³»ç»Ÿå±‚ï¼ˆSystem 2ï¼‰** çš„æ·±åº¦æ€è€ƒï¼Œä» Jason Weston æå‡ºçš„â€œäººæœºååŒè¿›åŒ–â€åˆ°å¤šç¯‡å…³äºæ¨ç†æ•ˆç‡ã€è‡ªæˆ‘åæ€å’Œâ€œæ„å¿—åŠ›è½¯å¼±â€çš„å“²å­¦æ¢è®¨ï¼›åŒæ—¶ï¼Œ**è§†é¢‘ç†è§£ä¸ç”Ÿæˆ**ï¼ˆå°¤å…¶æ˜¯é•¿è§†é¢‘å’Œ 3D æ§åˆ¶ï¼‰è¿æ¥äº†å¤šé¡¹ Agentic è§†è§’çš„çªç ´ã€‚\n\n---\n\n### ğŸŒŸ æ·±åº¦æ€è€ƒï¼šAGIã€æ¨ç†ä¸ååŒè¿›åŒ–\n\n**1. AI & Human Co-Improvement for Safer Co-Superintelligence**\n**(AI ä¸äººç±»çš„ååŒè¿›åŒ–ï¼šè¿ˆå‘æ›´å®‰å…¨çš„ååŒè¶…çº§æ™ºèƒ½)**\n> Authors: Jason Weston, Jakob Foerster\n> æ ¸å¿ƒè§‚ç‚¹ï¼šMeta å’Œç‰›æ´¥çš„å¤§ä½¬å‘å£°ï¼Œåå¯¹å•çº¯è¿½æ±‚ AI çš„è‡ªæˆ‘è¿›åŒ– (Self-improvement)ã€‚\n- **æ ¸å¿ƒè§‚ç‚¹**ï¼šå•çº¯çš„ AI è‡ªæˆ‘è¿›åŒ–è™½ç„¶ä»¤äººå…´å¥‹ï¼Œä½†å……æ»¡å±é™©ã€‚ä½œè€…ä¸»å¼ ä¸€ä¸ªæ–°çš„ç›®æ ‡ï¼š**ååŒè¿›åŒ– (Co-improvement)**ã€‚\n- **æ–¹æ³•è®º**ï¼šæ„å»ºèƒ½ä¸äººç±»ç ”ç©¶å‘˜åä½œçš„ AI ç³»ç»Ÿï¼Œä»æ„æ€åˆ°å®éªŒå…¨æµç¨‹åˆä½œã€‚\n- **æ„ä¹‰**ï¼šè¿™ç§â€œäººåœ¨ç¯è·¯â€çš„ç ”ç©¶è¿›åŒ–ä¸ä»…èƒ½åŠ é€Ÿ AI å‘å±•ï¼Œæ›´èƒ½é€šè¿‡å…±ç”Ÿå…³ç³»ç¡®ä¿è¶…çº§æ™ºèƒ½çš„å®‰å…¨æ€§ï¼ˆCo-superintelligenceï¼‰ã€‚\n\n**2. The Missing Layer of AGI: From Pattern Alchemy to Coordination Physics**\n**(AGI çš„ç¼ºå¤±å±‚ï¼šä»æ¨¡å¼ç‚¼é‡‘æœ¯åˆ°åè°ƒç‰©ç†å­¦)**\n> Authors: Edward Y. Chang\n> æ ¸å¿ƒè§‚ç‚¹ï¼šåé©³ LLM åªæ˜¯â€œæ¨¡å¼åŒ¹é…å™¨â€çš„è§‚ç‚¹ï¼Œæå‡ºäº† System-2 åè°ƒå±‚ã€‚\n- **æ ¸å¿ƒå‘ç°**ï¼šLLM çš„æ¨¡å¼åº“æ˜¯å¿…è¦çš„ System-1 åŸºè´¨ï¼Œä½†ç¼ºå¤±äº†ä¸€ä¸ªè´Ÿè´£é€‰æ‹©ã€çº¦æŸå’Œç»‘å®šçš„ **System-2 åè°ƒå±‚**ã€‚\n- **æ–°æ¡†æ¶**ï¼šæå‡ºäº† **UCCT ç†è®º**ï¼ˆè¯­ä¹‰é”šå®šï¼‰å’Œ **MACI æ¶æ„**ï¼ˆåŒ…å«è¯±å¯¼ã€è‹æ ¼æ‹‰åº•å¼è¯„åˆ¤å’Œäº‹åŠ¡æ€§è®°å¿†ï¼‰ï¼Œå°†æ¨ç†å»ºæ¨¡ä¸ºå—ç›®æ ‡çº¦æŸçš„ç›¸å˜è¿‡ç¨‹ï¼Œè€Œéç®€å•çš„æ¦‚ç‡ç”Ÿæˆã€‚\n\n**3. LYNX: Learning Dynamic Exits for Confidence-Controlled Reasoning**\n**(LYNXï¼šå­¦ä¹ åŠ¨æ€é€€å‡ºæœºåˆ¶ä»¥å®ç°ç½®ä¿¡åº¦å¯æ§çš„æ¨ç†)**\n> Authors: Ã–mer Faruk AkgÃ¼l et al.\n> æ ¸å¿ƒè§‚ç‚¹ï¼šå¤§æ¨¡å‹ç»å¸¸â€œæƒ³å¤ªå¤šâ€ (Overthinking)ï¼Œå¾—æ•™å®ƒä»¬è§å¥½å°±æ”¶ã€‚\n- **é—®é¢˜**ï¼šç°æœ‰çš„æ¨ç†æ¨¡å‹å¾€å¾€åœ¨å·²ç»è·å¾—æ­£ç¡®ç­”æ¡ˆåè¿˜åœ¨ç»§ç»­æ¨ç†ï¼Œæµªè´¹ç®—åŠ›ç”šè‡³å¯¼è‡´é”™è¯¯ã€‚\n- **æ–¹æ³•**ï¼šLYNX åˆ©ç”¨æ¨¡å‹åœ¨æ¨ç†çº¿ç´¢è¯ï¼ˆå¦‚ \"hmm\", \"wait\"ï¼‰å¤„çš„éšè—çŠ¶æ€ï¼Œè®­ç»ƒè½»é‡çº§æ¢é’ˆæ¥å†³å®šæ˜¯å¦â€œæå‰é€€å‡ºâ€ã€‚\n- **æ•ˆæœ**ï¼šåœ¨ GSM8K ä¸Šå‡å°‘äº† 40-65% çš„ Token æ¶ˆè€—ä¸”ä¿æŒäº†å‡†ç¡®ç‡ï¼Œå®ç°äº†å¸•ç´¯æ‰˜æœ€ä¼˜çš„æ•ˆç‡-å‡†ç¡®ç‡æƒè¡¡ã€‚\n\n**4. The Seeds of Scheming: Weakness of Will in the Building Blocks of Agentic Systems**\n**(é˜´è°‹çš„ç§å­ï¼šAgent ç³»ç»ŸåŸºçŸ³ä¸­çš„â€œæ„å¿—åŠ›è½¯å¼±â€)**\n> Authors: Robert Yang\n> æ ¸å¿ƒè§‚ç‚¹ï¼šç”¨å“²å­¦ä¸­çš„â€œæ„å¿—åŠ›è½¯å¼± (Akrasia)â€ æ¦‚å¿µæ¥åˆ†æ AI çš„ä¸ä¸€è‡´æ€§ã€‚\n- **æ ¸å¿ƒå‘ç°**ï¼šæ¨¡å‹ç»å¸¸â€œçŸ¥é“â€æ­£ç¡®ç­”æ¡ˆï¼Œä½†å¹¶æœªæŒ‰æ­¤è¡ŒåŠ¨ã€‚è¿™ä¸ä»…æ˜¯ Bugï¼Œæ›´åƒæ˜¯å“²å­¦ä¸Šçš„ Akrasiaã€‚\n- **è´¡çŒ®**ï¼šæå‡ºäº† **Akrasia Benchmark**ï¼Œæµ‹è¯•æ¨¡å‹åœ¨é¢å¯¹è¯±æƒ‘ï¼ˆå¦‚æ—¶é—´å‹åŠ›ã€åŒä¹‰è¯å¹²æ‰°ï¼‰æ—¶æ˜¯å¦ä¼šèƒŒå›è‡ªå·±çš„â€œå…ˆéªŒæ‰¿è¯ºâ€ã€‚è¿™ä¸ºç†è§£å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­çš„â€œè“„æ„æ¬ºéª—â€æˆ–â€œé˜´è°‹â€æä¾›äº†å¾®è§‚è§†è§’ã€‚\n\n---\n\n### ğŸ‘ï¸ è§†è§‰æ™ºèƒ½ï¼šAgentic Video & 3D Gen\n\n**5. Active Video Perception: Iterative Evidence Seeking for Agentic Long Video Understanding**\n**(ä¸»åŠ¨è§†é¢‘æ„ŸçŸ¥ï¼šç”¨äºé•¿è§†é¢‘ç†è§£çš„è¿­ä»£è¯æ®æœå¯» Agent)**\n> Authors: Ziyang Wang et al. (Salesforce & Stanford)\n> æ ¸å¿ƒè§‚ç‚¹ï¼šè§†é¢‘ç†è§£ä¸åº”æ˜¯è¢«åŠ¨çœ‹ï¼Œè€Œåº”æ˜¯ä¸»åŠ¨â€œæœâ€ã€‚\n- **é—®é¢˜**ï¼šä¼ ç»Ÿé•¿è§†é¢‘ç†è§£ä¾èµ– Query æ— å…³çš„ Captionï¼Œæ•ˆç‡ä½ä¸”ä¸¢å¤±ç»†èŠ‚ã€‚\n- **æ–¹æ³•**ï¼šæå‡ºäº† **AVP** æ¡†æ¶ï¼Œå°†è§†é¢‘è§†ä¸ºå¯äº¤äº’ç¯å¢ƒã€‚Agent è¿›è¡Œâ€œè®¡åˆ’-è§‚å¯Ÿ-åæ€â€çš„å¾ªç¯ï¼Œä¸»åŠ¨å»åƒç´ å±‚é¢å¯»æ‰¾è¯æ®ï¼Œç›´åˆ°è®¤ä¸ºä¿¡æ¯è¶³ä»¥å›ç­”é—®é¢˜ã€‚\n- **æ•ˆæœ**ï¼šåœ¨é•¿è§†é¢‘åŸºå‡†ä¸Šï¼Œå‡†ç¡®ç‡æå‡ 5.7%ï¼Œä»…éœ€ 18.4% çš„æ¨ç†æ—¶é—´å’Œ 12.4% çš„ Tokenã€‚\n\n**6. SpaceControl: Introducing Test-Time Spatial Control to 3D Generative Modeling**\n**(SpaceControlï¼šä¸º 3D ç”Ÿæˆæ¨¡å‹å¼•å…¥æµ‹è¯•æ—¶ç©ºé—´æ§åˆ¶)**\n> Authors: Elisabetta Fedele, Leonidas Guibas et al.\n> æ ¸å¿ƒè§‚ç‚¹ï¼šGuibas å›¢é˜Ÿæ–°ä½œï¼Œæ— éœ€è®­ç»ƒå³å¯æ§åˆ¶ 3D ç”Ÿæˆçš„å‡ ä½•å½¢çŠ¶ã€‚\n- **è´¡çŒ®**ï¼šä¸€ç§æ— éœ€è®­ç»ƒ (Training-free) çš„æµ‹è¯•æ—¶æ–¹æ³•ï¼Œå…è®¸ç”¨æˆ·é€šè¿‡å‡ ä½•è¾“å…¥ï¼ˆä»ç²—ç³™åŸè¯­åˆ°è¯¦ç»†ç½‘æ ¼ï¼‰æ˜¾å¼æ§åˆ¶ 3D ç”Ÿæˆã€‚\n- **äº®ç‚¹**ï¼šæä¾›äº†ä¸€ä¸ªå¯æ§å‚æ•°ï¼Œç”¨äºå¹³è¡¡å‡ ä½•ä¿çœŸåº¦å’Œç”Ÿæˆç»“æœçš„çœŸå®æ„Ÿï¼Œç”šè‡³æ”¯æŒäº¤äº’å¼ç¼–è¾‘è¶…äºŒæ¬¡æ›²é¢æ¥ç”Ÿæˆ 3D èµ„äº§ã€‚\n\n**7. WAM-Flow: Parallel Coarse-to-Fine Motion Planning via Discrete Flow Matching for Autonomous Driving**\n**(WAM-Flowï¼šåŸºäºç¦»æ•£æµåŒ¹é…çš„è‡ªåŠ¨é©¾é©¶å¹¶è¡Œç”±ç²—åˆ°ç²¾è¿åŠ¨è§„åˆ’)**\n> Authors: Yifang Xu et al. (Fudan & Alibaba)\n> æ ¸å¿ƒè§‚ç‚¹ï¼šç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶çš„æ–°èŒƒå¼â€”â€”ç¦»æ•£æµåŒ¹é…ã€‚\n- **æ–¹æ³•**ï¼šå¼•å…¥äº† **WAM-Flow**ï¼Œä¸€ä¸ªè§†è§‰-è¯­è¨€-åŠ¨ä½œ (VLA) æ¨¡å‹ã€‚ä¸åŒäºè‡ªå›å½’ï¼Œå®ƒä½¿ç”¨å…¨å¹¶è¡Œã€åŒå‘å»å™ªçš„æµåŒ¹é… (Flow Matching) è¿›è¡Œè½¨è¿¹è§„åˆ’ã€‚\n- **æ•ˆæœ**ï¼šåœ¨ NAVSIM v1 åŸºå‡†ä¸Šï¼Œ1 æ­¥æ¨ç†è¾¾åˆ° 89.1 PDMSï¼Œæ˜¾è‘—ä¼˜äºè‡ªå›å½’å’Œæ‰©æ•£åŸºçº¿ï¼Œè¯æ˜äº†æµåŒ¹é…åœ¨ç«¯åˆ°ç«¯é©¾é©¶ä¸­çš„æ½œåŠ›ã€‚\n\n**8. EgoEdit: Dataset, Real-Time Streaming Model, and Benchmark for Egocentric Video Editing**\n**(EgoEditï¼šç¬¬ä¸€äººç§°è§†é¢‘ç¼–è¾‘çš„æ•°æ®é›†ã€å®æ—¶æµæ¨¡å‹ä¸åŸºå‡†)**\n> Authors: Runjia Li et al. (Snap Research)\n> æ ¸å¿ƒè§‚ç‚¹ï¼šSnapchat æå®šç¬¬ä¸€äººç§°è§†é¢‘ç¼–è¾‘ï¼Œç‰¹åˆ«æ˜¯æ‰‹éƒ¨äº¤äº’ã€‚\n- **æŒ‘æˆ˜**ï¼šç¬¬ä¸€äººç§° (Egocentric) è§†é¢‘é•œå¤´æ™ƒåŠ¨å¤§ã€æ‰‹éƒ¨äº¤äº’é¢‘ç¹ï¼Œç°æœ‰ç¼–è¾‘å™¨å¾ˆéš¾å¤„ç†ã€‚\n- **è´¡çŒ®**ï¼šæ¨å‡ºäº† EgoEdit ç³»ç»Ÿï¼Œæ”¯æŒå• GPU å®æ—¶æµå¼æ¨ç†ï¼Œå¹¶ä¸”ç‰¹åˆ«æ³¨é‡â€œæ‰‹éƒ¨ä¿æŒâ€å’Œâ€œæŒ‡ä»¤å¿ å®åº¦â€ã€‚\n\n---\n\n### ğŸ›¡ï¸ å®‰å…¨ä¸å¯¹é½ï¼šJailbreak ä¸éªŒè¯\n\n**9. BEAVER: An Efficient Deterministic LLM Verifier**\n**(BEAVERï¼šä¸€ç§é«˜æ•ˆçš„ç¡®å®šæ€§ LLM éªŒè¯å™¨)**\n> Authors: Tarun Suresh, Gagandeep Singh et al.\n> æ ¸å¿ƒè§‚ç‚¹ï¼šå‘Šåˆ«æ¦‚ç‡çŒœæµ‹ï¼Œç»™ LLM åŠ ä¸Šç¡®å®šæ€§çš„å®‰å…¨è¾¹ç•Œã€‚\n- **è´¡çŒ®**ï¼šé¦–ä¸ªå®ç”¨çš„æ¡†æ¶ï¼Œç”¨äºè®¡ç®— LLM æ»¡è¶³çº¦æŸçš„**ç¡®å®šæ€§æ¦‚ç‡ç•Œé™**ã€‚\n- **æ–¹æ³•**ï¼šåˆ©ç”¨ Token Trie å’Œ Frontier æ•°æ®ç»“æ„ç³»ç»Ÿåœ°æ¢ç´¢ç”Ÿæˆç©ºé—´ã€‚æ¯”åŸºçº¿æ–¹æ³•è·å¾— 6-8 å€æ›´ç´§çš„æ¦‚ç‡ç•Œé™ï¼Œèƒ½è¯†åˆ«å‡ºæ›´å¤šé«˜é£é™©å®ä¾‹ã€‚\n\n**10. Safe2Harm: Semantic Isomorphism Attacks for Jailbreaking Large Language Models**\n**(Safe2Harmï¼šç”¨äºè¶Šç‹±å¤§è¯­è¨€æ¨¡å‹çš„è¯­ä¹‰åŒæ„æ”»å‡»)**\n> Authors: Fan Yang\n> æ ¸å¿ƒè§‚ç‚¹ï¼šæŠŠåé—®é¢˜åŒ…è£…æˆâ€œåŸç†ç›¸åŒâ€çš„å¥½é—®é¢˜ï¼Œè¯±å¯¼ LLM çŠ¯é”™ã€‚\n- **æ–¹æ³•**ï¼šå‘ç°è®¸å¤šæœ‰å®³åœºæ™¯ä¸åˆæ³•åœºæ™¯åœ¨åº•å±‚åŸç†ä¸Šé«˜åº¦ä¸€è‡´ï¼ˆè¯­ä¹‰åŒæ„ï¼‰ã€‚æ”»å‡»åˆ†å››æ­¥ï¼šå°†æœ‰å®³é—®é¢˜é‡å†™ä¸ºå®‰å…¨çš„åŒæ„é—®é¢˜ -> æå–æ˜ å°„å…³ç³» -> è®© LLM å›ç­”å®‰å…¨é—®é¢˜ -> é€†å‘é‡å†™ç­”æ¡ˆå˜ä¸ºæœ‰å®³å†…å®¹ã€‚\n- **ç»“æœ**ï¼šåœ¨ 7 ä¸ªä¸»æµ LLM ä¸Šå±•ç°äº†å¼ºå¤§çš„è¶Šç‹±èƒ½åŠ›ã€‚\n\n**11. The Forgotten Shield: Safety Grafting in Parameter-Space for Medical MLLMs**\n**(è¢«é—å¿˜çš„ç›¾ç‰Œï¼šåŒ»ç–—å¤šæ¨¡æ€å¤§æ¨¡å‹çš„å‚æ•°ç©ºé—´å®‰å…¨å«æ¥)**\n> Authors: Jiale Zhao et al.\n> æ ¸å¿ƒè§‚ç‚¹ï¼šåŒ»ç–—å¾®è°ƒä¼šè®©å¤§æ¨¡å‹â€œå¿˜è®°â€é€šç”¨çš„å®‰å…¨å¯¹é½ã€‚\n- **å‘ç°**ï¼šMedical MLLM åœ¨å¾®è°ƒåï¼Œè™½ç„¶åŒ»ç–—èƒ½åŠ›å¼ºäº†ï¼Œä½†é¢å¯¹è·¨æ¨¡æ€è¶Šç‹±æ”»å‡»å˜å¾—éå¸¸è„†å¼±ï¼ˆç¾éš¾æ€§é—å¿˜ï¼‰ã€‚\n- **å¯¹ç­–**ï¼šæå‡ºâ€œå‚æ•°ç©ºé—´å¹²é¢„â€ï¼Œä»åŸå§‹åŸºåº§æ¨¡å‹ä¸­æå–å®‰å…¨çŸ¥è¯†ï¼Œå¹¶â€œå«æ¥â€å›å¾®è°ƒåçš„æ¨¡å‹ï¼Œæ— éœ€é¢å¤–çš„å®‰å…¨æ•°æ®è®­ç»ƒã€‚\n\n---\n\n### ğŸ§ª ç§‘å­¦ã€å¿ƒç†ä¸è¶£é—»\n\n**12. Future You: Designing and Evaluating Multimodal AI-generated Digital Twins for Strengthening Future Self-Continuity**\n**(æœªæ¥çš„ä½ ï¼šè®¾è®¡ä¸è¯„ä¼°å¤šæ¨¡æ€ AI ç”Ÿæˆçš„æ•°å­—å­ªç”Ÿä»¥å¢å¼ºæœªæ¥è‡ªæˆ‘è¿ç»­æ€§)**\n> Authors: MIT Media Lab å›¢é˜Ÿ\n> æ ¸å¿ƒè§‚ç‚¹ï¼šå’Œ 30 å¹´åçš„è‡ªå·±èŠå¤©ï¼Œä¼šæ”¹å˜ä½ å½“ä¸‹çš„å†³å®šå—ï¼Ÿ\n- **å®éªŒ**ï¼šåˆ›å»ºç”¨æˆ·çš„ AI æ•°å­—å­ªç”Ÿï¼ˆå˜è€çš„è„¸ã€å£°éŸ³ã€è‡ªä¼ å™äº‹ï¼‰ï¼Œè®©ç”¨æˆ·ä¸â€œæœªæ¥çš„è‡ªå·±â€å¯¹è¯ã€‚\n- **å‘ç°**ï¼šè¿™ç§äº’åŠ¨æ˜¾è‘—å¢å¼ºäº†â€œæœªæ¥è‡ªæˆ‘è¿ç»­æ€§ (FSC)â€ï¼Œå‡å°‘äº†ç„¦è™‘ã€‚ç›¸æ¯”çº¯æ–‡æœ¬ï¼ŒAvatar å½¢å¼å¸¦æ¥æœ€å¼ºçš„ç”ŸåŠ¨æ„Ÿï¼Œä½†äº¤äº’è´¨é‡ï¼ˆå¯¹è¯çš„çœŸå®æ„Ÿï¼‰æ¯”å½¢å¼æ›´é‡è¦ã€‚\n\n**13. To Err Is Human: Systematic Quantification of Errors in Published AI Papers via LLM Analysis**\n**(äººéåœ£è´¤ï¼šåˆ©ç”¨ LLM ç³»ç»Ÿé‡åŒ–å·²å‘è¡¨ AI è®ºæ–‡ä¸­çš„é”™è¯¯)**\n> Authors: Federico Bianchi, James Zou et al. (Stanford)\n> æ ¸å¿ƒè§‚ç‚¹ï¼šAI é¡¶ä¼šè®ºæ–‡é‡Œçš„å®¢è§‚é”™è¯¯ï¼ˆå…¬å¼ã€å›¾è¡¨ï¼‰è¶Šæ¥è¶Šå¤šäº†ã€‚\n- **æ•°æ®**ï¼šç”¨ GPT-5 æ£€æŸ¥äº† NeurIPS, ICLR ç­‰é¡¶ä¼šè®ºæ–‡ã€‚\n- **å‘ç°**ï¼šNeurIPS è®ºæ–‡å¹³å‡é”™è¯¯æ•°ä» 2021 å¹´çš„ 3.8 ä¸ªå¢åŠ åˆ° 2025 å¹´çš„ 5.9 ä¸ªã€‚è™½ç„¶å¤§å¤šæ˜¯å°é”™ï¼Œä½† LLM Checker èƒ½ä¿®æ­£å…¶ä¸­ 75.8% çš„é”™è¯¯ã€‚\n\n**14. Smart Timing for Mining: A Deep Learning Framework for Bitcoin Hardware ROI Prediction**\n**(æŒ–çŸ¿çš„æ™ºèƒ½æ—¶æœºï¼šæ¯”ç‰¹å¸ç¡¬ä»¶æŠ•èµ„å›æŠ¥ç‡é¢„æµ‹çš„æ·±åº¦å­¦ä¹ æ¡†æ¶)**\n> Authors: Sithumi Wickramasinghe et al.\n> æ ¸å¿ƒè§‚ç‚¹ï¼šä»€ä¹ˆæ—¶å€™ä¹°çŸ¿æœºæœ€åˆ’ç®—ï¼ŸAI å‘Šè¯‰ä½ ã€‚\n- **è´¡çŒ®**ï¼šæå‡ºäº† MineROI-Netï¼Œé¢„æµ‹è´­ä¹° ASIC çŸ¿æœºåœ¨ä¸€å¹´å†…æ˜¯èµšé’±ã€ä¿æœ¬è¿˜æ˜¯äºé’±ã€‚\n- **æ•ˆæœ**ï¼šå‡†ç¡®ç‡ 83.7%ï¼Œèƒ½æœ‰æ•ˆè¯†åˆ«â€œä¸è¯¥ä¹°â€çš„æ—¶æœºï¼ˆ93.6% ç²¾åº¦ï¼‰ï¼Œå¸®çŸ¿å·¥çœé’±ã€‚\n\n**15. SymPyBench: A Dynamic Benchmark for Scientific Reasoning with Executable Python Code**\n**(SymPyBenchï¼šåŸºäºå¯æ‰§è¡Œ Python ä»£ç çš„ç§‘å­¦æ¨ç†åŠ¨æ€åŸºå‡†)**\n> Authors: Shima Imani et al.\n> æ ¸å¿ƒè§‚ç‚¹ï¼šç§‘å­¦æ¨ç†ä¸èƒ½åªçœ‹ç­”æ¡ˆï¼Œè¦çœ‹ä»£ç å’Œè¿‡ç¨‹ã€‚\n- **å†…å®¹**ï¼šåŒ…å« 1.5 ä¸‡é“å¤§å­¦ç‰©ç†é¢˜ï¼Œæ¯é“é¢˜éƒ½é…æœ‰å¯æ‰§è¡Œçš„ Python ä»£ç æ¥ç”Ÿæˆ Ground Truthã€‚æ”¯æŒç¬¦å·è§£å’Œæ•°å€¼è§£ï¼Œèƒ½é€šè¿‡ä»£ç éªŒè¯æ¨ç†è¿‡ç¨‹çš„æ­£ç¡®æ€§ã€‚\n\n---\n\n### ğŸ“¦ å·¥ä¸šåº”ç”¨ä¸ RAG\n\n**16. ChipMind: Retrieval-Augmented Reasoning for Long-Context Circuit Design Specifications**\n**(ChipMindï¼šé¢å‘é•¿æ–‡æœ¬ç”µè·¯è®¾è®¡è§„èŒƒçš„æ£€ç´¢å¢å¼ºæ¨ç†)**\n> Authors: Changwen Xing et al.\n> æ ¸å¿ƒè§‚ç‚¹ï¼šç”¨ KG + RAG æå®šå‡ ç™¾é¡µçš„èŠ¯ç‰‡è®¾è®¡æ–‡æ¡£ã€‚\n- **ç—›ç‚¹**ï¼šèŠ¯ç‰‡è§„æ ¼ä¹¦å¤ªé•¿ï¼ŒContext Window ä¸å¤Ÿç”¨ã€‚\n- **æ–¹æ³•**ï¼šå°†ç”µè·¯è§„èŒƒè½¬åŒ–ä¸ºçŸ¥è¯†å›¾è°± (ChipKG)ï¼Œç»“åˆä¿¡æ¯è®ºè‡ªé€‚åº”æ£€ç´¢å’Œæ„å›¾æ„ŸçŸ¥è¿‡æ»¤ã€‚æ€§èƒ½æ¯”åŸºçº¿æå‡ 34.59%ã€‚\n\n**17. Industrial AI Robustness Card: Evaluating and Monitoring Time Series Models**\n**(å·¥ä¸š AI é²æ£’æ€§å¡ç‰‡ï¼šè¯„ä¼°ä¸ç›‘æ§æ—¶é—´åºåˆ—æ¨¡å‹)**\n> Authors: Alexander Windmann et al.\n> æ ¸å¿ƒè§‚ç‚¹ï¼šæ¬§ç›Ÿ AI æ³•æ¡ˆæ¥äº†ï¼Œå·¥ä¸šç•Œéœ€è¦æ ‡å‡†åŒ–çš„æ¨¡å‹â€œä½“æ£€æŠ¥å‘Šâ€ã€‚\n- **è´¡çŒ®**ï¼šæå‡ºäº† IARCï¼Œä¸€ç§è½»é‡çº§çš„åè®®ï¼Œç”¨äºè®°å½•å’Œè¯„ä¼°å·¥ä¸šæ—¶é—´åºåˆ—æ¨¡å‹çš„é²æ£’æ€§ï¼ˆæ¼‚ç§»ç›‘æ§ã€ä¸ç¡®å®šæ€§é‡åŒ–ã€å‹åŠ›æµ‹è¯•ï¼‰ï¼Œç›´æ¥å¯¹é½æ¬§ç›Ÿåˆè§„è¦æ±‚ã€‚",
  "papers": [
    {
      "arxiv_id": "2512.06205v2",
      "title": "On measuring grounding and generalizing grounding problems",
      "title_zh": "è®ºæ¥åœ°çš„åº¦é‡ä¸æ¥åœ°é—®é¢˜çš„æ³›åŒ–",
      "authors": [
        "Daniel Quigley",
        "Eric Maynard"
      ],
      "abstract": "The symbol grounding problem asks how tokens like cat can be about cats, as opposed to mere shapes manipulated in a calculus. We recast grounding from a binary judgment into an audit across desiderata, each indexed by an evaluation tuple (context, meaning type, threat model, reference distribution): authenticity (mechanisms reside inside the agent and, for strong claims, were acquired through learning or evolution); preservation (atomic meanings remain intact); faithfulness, both correlational (realized meanings match intended ones) and etiological (internal mechanisms causally contribute to success); robustness (graceful degradation under declared perturbations); compositionality (the whole is built systematically from the parts). We apply this framework to four grounding modes (symbolic; referential; vectorial; relational) and three case studies: model-theoretic semantics achieves exact composition but lacks etiological warrant; large language models show correlational fit and local robustness for linguistic tasks, yet lack selection-for-success on world tasks without grounded interaction; human language meets the desiderata under strong authenticity through evolutionary and developmental acquisition. By operationalizing a philosophical inquiry about representation, we equip philosophers of science, computer scientists, linguists, and mathematicians with a common language and technical framework for systematic investigation of grounding and meaning.",
      "tldr_zh": "è¯¥ç ”ç©¶å°†ç¬¦å·æ¥åœ°é—®é¢˜(symbol grounding problem)ä»äºŒå…ƒåˆ¤æ–­é‡æ–°å®šä¹‰ä¸ºä¸€å¥—è·¨å¤šä¸ªéœ€æ±‚çš„å®¡è®¡æ¡†æ¶ï¼Œæ—¨åœ¨ç³»ç»ŸåŒ–åœ°è¡¡é‡å’Œåˆ†æè¡¨å¾ä¸æ„ä¹‰çš„å…³ç³»ã€‚è¯¥æ¡†æ¶ç”±äº”ä¸ªæ ¸å¿ƒè¡¡é‡ç»´åº¦ç»„æˆï¼šçœŸå®æ€§(authenticity)ã€ä¿å­˜æ€§(preservation)ã€å¿ å®æ€§(faithfulness)ã€é²æ£’æ€§(robustness)ä»¥åŠç»„åˆæ€§(compositionality)ã€‚ä½œè€…å°†æ­¤æ¡†æ¶åº”ç”¨äºç¬¦å·åŒ–ã€æŒ‡ç§°åŒ–ã€å‘é‡åŒ–å’Œå…³ç³»åŒ–å››ç§æ¥åœ°æ¨¡å¼ï¼Œå¹¶å¼€å±•äº†å¤šç»´åº¦çš„æ¡ˆä¾‹ç ”ç©¶ã€‚ç ”ç©¶æŒ‡å‡ºï¼Œå¤§è¯­è¨€æ¨¡å‹(large language models)è™½ç„¶åœ¨è¯­è¨€ä»»åŠ¡ä¸­è¡¨ç°å‡ºç›¸å…³æ€§å¥‘åˆå’Œå±€éƒ¨é²æ£’æ€§ï¼Œä½†åœ¨ç¼ºä¹æ¥åœ°äº¤äº’çš„æƒ…å†µä¸‹ï¼Œæ— æ³•åœ¨ç°å®ä¸–ç•Œä»»åŠ¡ä¸­è·å¾—ç—…å› æ€§(etiological)çš„æˆåŠŸä¿éšœã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œäººç±»è¯­è¨€é€šè¿‡è¿›åŒ–å’Œå‘è‚²ä¹ å¾—æ»¡è¶³äº†å¼ºçœŸå®æ€§éœ€æ±‚ï¼Œè€Œæ¨¡å‹ç†è®ºè¯­ä¹‰å­¦åˆ™ç¼ºä¹ç—…å› æ€§è¯æ˜ã€‚è¯¥ç ”ç©¶é€šè¿‡å°†å…³äºè¡¨å¾çš„å“²å­¦æ¢ç©¶æ“ä½œåŒ–ï¼Œä¸ºè®¡ç®—æœºç§‘å­¦ã€è¯­è¨€å­¦å’Œå“²å­¦ç­‰é¢†åŸŸæä¾›äº†ä¸€å¥—ç”¨äºç³»ç»Ÿè°ƒæŸ¥æ¥åœ°ä¸æ„ä¹‰é—®é¢˜çš„é€šç”¨è¯­è¨€å’ŒæŠ€æœ¯æ¡†æ¶ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "resubmission: 39 pages, 85 sources, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.06205v2",
      "published_date": "2025-12-05 22:58:47 UTC",
      "updated_date": "2025-12-31 02:06:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:51:54.968165+00:00"
    },
    {
      "arxiv_id": "2512.06204v1",
      "title": "Quantifying Memory Use in Reinforcement Learning with Temporal Range",
      "title_zh": "åˆ©ç”¨ Temporal Range é‡åŒ–å¼ºåŒ–å­¦ä¹ ä¸­çš„è®°å¿†ä½¿ç”¨",
      "authors": [
        "Rodney Lafuente-Mercado",
        "Daniela Rus",
        "T. Konstantin Rusch"
      ],
      "abstract": "How much does a trained RL policy actually use its past observations? We propose \\emph{Temporal Range}, a model-agnostic metric that treats first-order sensitivities of multiple vector outputs across a temporal window to the input sequence as a temporal influence profile and summarizes it by the magnitude-weighted average lag. Temporal Range is computed via reverse-mode automatic differentiation from the Jacobian blocks $\\partial y_s/\\partial x_t\\in\\mathbb{R}^{c\\times d}$ averaged over final timesteps $s\\in\\{t+1,\\dots,T\\}$ and is well-characterized in the linear setting by a small set of natural axioms. Across diagnostic and control tasks (POPGym; flicker/occlusion; Copy-$k$) and architectures (MLPs, RNNs, SSMs), Temporal Range (i) remains small in fully observed control, (ii) scales with the task's ground-truth lag in Copy-$k$, and (iii) aligns with the minimum history window required for near-optimal return as confirmed by window ablations. We also report Temporal Range for a compact Long Expressive Memory (LEM) policy trained on the task, using it as a proxy readout of task-level memory. Our axiomatic treatment draws on recent work on range measures, specialized here to temporal lag and extended to vector-valued outputs in the RL setting. Temporal Range thus offers a practical per-sequence readout of memory dependence for comparing agents and environments and for selecting the shortest sufficient context.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Temporal Rangeï¼Œè¿™æ˜¯ä¸€ç§ä¸æ¨¡å‹æ— å…³çš„æŒ‡æ ‡ï¼Œæ—¨åœ¨é‡åŒ–å·²è®­ç»ƒçš„å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)ç­–ç•¥å¯¹è¿‡å»è§‚å¯Ÿç»“æœçš„å®é™…ä½¿ç”¨ç¨‹åº¦ã€‚è¯¥æ–¹æ³•é€šè¿‡åå‘æ¨¡å¼è‡ªåŠ¨å¾®åˆ†(reverse-mode automatic differentiation)è®¡ç®—é›…å¯æ¯”çŸ©é˜µ(Jacobian blocks)ï¼Œå°†ç­–ç•¥è¾“å‡ºå¯¹è¾“å…¥åºåˆ—çš„ä¸€é˜¶æ•æ„Ÿåº¦å®šä¹‰ä¸ºæ—¶é—´å½±å“å‰–é¢ï¼Œå¹¶ä»¥å¹…åº¦åŠ æƒå¹³å‡æ»åæ¥è¡¡é‡å†…å­˜ä¾èµ–ã€‚å®éªŒåœ¨ POPGymã€Copy-k ç­‰ä»»åŠ¡ä»¥åŠ MLPã€RNNã€SSM ç­‰å¤šç§æ¶æ„ä¸Šè¿›è¡Œï¼Œç»“æœè¡¨æ˜ Temporal Range åœ¨å®Œå…¨è§‚æµ‹ä»»åŠ¡ä¸­æ•°å€¼è¾ƒå°ï¼Œä¸”èƒ½å‡†ç¡®åæ˜  Copy-k ä»»åŠ¡ä¸­çš„çœŸå®æ»åã€‚æ­¤å¤–ï¼Œè¯¥æŒ‡æ ‡ä¸å®ç°è¿‘ä¹æœ€ä¼˜å›æŠ¥æ‰€éœ€çš„æœ€çŸ­å†å²çª—å£é«˜åº¦ä¸€è‡´ï¼Œä¸ºè¯„ä¼°æ™ºèƒ½ä½“çš„å†…å­˜ä½¿ç”¨å’Œé€‰æ‹©æœ€çŸ­æœ‰æ•ˆä¸Šä¸‹æ–‡æä¾›äº†å®ç”¨çš„åˆ†æå·¥å…·ã€‚ç ”ç©¶æœ€åé€šè¿‡åœ¨ Long Expressive Memory (LEM) ç­–ç•¥ä¸Šçš„åº”ç”¨ï¼Œè¯æ˜äº†è¯¥æŒ‡æ ‡ä½œä¸ºä»»åŠ¡çº§å†…å­˜è¯»å–ä»£ç†çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.06204v1",
      "published_date": "2025-12-05 22:58:09 UTC",
      "updated_date": "2025-12-05 22:58:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:52:10.134665+00:00"
    },
    {
      "arxiv_id": "2512.15735v4",
      "title": "Deep Reinforcement Learning Optimization for Uncertain Nonlinear Systems via Event-Triggered Robust Adaptive Dynamic Programming",
      "title_zh": "åŸºäºäº‹ä»¶è§¦å‘é²æ£’è‡ªé€‚åº”åŠ¨æ€è§„åˆ’çš„ä¸ç¡®å®šéçº¿æ€§ç³»ç»Ÿæ·±åº¦å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–",
      "authors": [
        "Ningwei Bai",
        "Chi Pui Chan",
        "Qichen Yin",
        "Tengyang Gong",
        "Yunda Yan",
        "Zezhi Tang"
      ],
      "abstract": "This work proposes a unified control architecture that couples a Reinforcement Learning (RL)-driven controller with a disturbance-rejection Extended State Observer (ESO), complemented by an Event-Triggered Mechanism (ETM) to limit unnecessary computations. The ESO is utilized to estimate the system states and the lumped disturbance in real time, forming the foundation for effective disturbance compensation. To obtain near-optimal behavior without an accurate system description, a value-iteration-based Adaptive Dynamic Programming (ADP) method is adopted for policy approximation. The inclusion of the ETM ensures that parameter updates of the learning module are executed only when the state deviation surpasses a predefined bound, thereby preventing excessive learning activity and substantially reducing computational load. A Lyapunov-oriented analysis is used to characterize the stability properties of the resulting closed-loop system. Numerical experiments further confirm that the developed approach maintains strong control performance and disturbance tolerance, while achieving a significant reduction in sampling and processing effort compared with standard time-triggered ADP schemes.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å…·æœ‰ä¸ç¡®å®šæ€§çš„éçº¿æ€§ç³»ç»Ÿæå‡ºäº†ä¸€ç§ç»Ÿä¸€çš„æ§åˆ¶æ¶æ„ï¼Œå°† Reinforcement Learning (RL) é©±åŠ¨çš„æ§åˆ¶å™¨ä¸ç”¨äºå®æ—¶ä¼°è®¡çŠ¶æ€å’Œæ€»æ‰°åŠ¨çš„ Extended State Observer (ESO) ç›¸ç»“åˆã€‚ä¸ºäº†åœ¨ç¼ºä¹ç²¾ç¡®ç³»ç»Ÿæè¿°çš„æƒ…å†µä¸‹è·å–è¿‘ä¼˜ç­–ç•¥ï¼Œè¯¥æ¶æ„é‡‡ç”¨äº†åŸºäº value-iteration çš„ Adaptive Dynamic Programming (ADP) æ–¹æ³•ã€‚ç ”ç©¶ä¸­å¼•å…¥çš„ Event-Triggered Mechanism (ETM) è§„å®šä»…åœ¨çŠ¶æ€åå·®è¶…è¿‡é¢„è®¾é˜ˆå€¼æ—¶æ‰æ‰§è¡Œå‚æ•°æ›´æ–°ï¼Œä»è€Œæœ‰æ•ˆé¿å…äº†è¿‡åº¦å­¦ä¹ å¹¶æ˜¾è‘—é™ä½äº†è®¡ç®—è´Ÿè·ã€‚é€šè¿‡ Lyapunov-oriented analysis è¯æ˜äº†æ‰€å¾—é—­ç¯ç³»ç»Ÿçš„ç¨³å®šæ€§ç‰¹å¾ã€‚æ•°å€¼å®éªŒç»“æœè¡¨æ˜ï¼Œä¸æ ‡å‡†çš„æ—¶é—´è§¦å‘ ADP æ–¹æ¡ˆç›¸æ¯”ï¼Œè¯¥æ–¹æ³•åœ¨ä¿æŒå“è¶Šæ§åˆ¶æ€§èƒ½å’Œæ‰°åŠ¨å®¹å¿åº¦çš„åŒæ—¶ï¼Œå¤§å¹…å‡å°‘äº†é‡‡æ ·ä¸å¤„ç†å·¥ä½œé‡ã€‚",
      "categories": [
        "math.OC",
        "cs.AI",
        "eess.SY"
      ],
      "primary_category": "math.OC",
      "comment": "9 pages, 9 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.15735v4",
      "published_date": "2025-12-05 22:52:22 UTC",
      "updated_date": "2025-12-30 13:01:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:51:42.865378+00:00"
    },
    {
      "arxiv_id": "2512.06196v1",
      "title": "ARCANE: A Multi-Agent Framework for Interpretable and Configurable Alignment",
      "title_zh": "ARCANEï¼šä¸€ç§é¢å‘å¯è§£é‡Šä¸å¯é…ç½®å¯¹é½çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶",
      "authors": [
        "Charlie Masters",
        "Marta GrzeÅ›kiewicz",
        "Stefano V. Albrecht"
      ],
      "abstract": "As agents based on large language models are increasingly deployed to long-horizon tasks, maintaining their alignment with stakeholder preferences becomes critical. Effective alignment in such settings requires reward models that are interpretable so that stakeholders can understand and audit model objectives. Moreover, reward models must be capable of steering agents at interaction time, allowing preference shifts to be incorporated without retraining. We introduce ARCANE, a framework that frames alignment as a multi-agent collaboration problem that dynamically represents stakeholder preferences as natural-language rubrics: weighted sets of verifiable criteria that can be generated on-the-fly from task context. Inspired by utility theory, we formulate rubric learning as a reconstruction problem and apply a regularized Group-Sequence Policy Optimization (GSPO) procedure that balances interpretability, faithfulness, and computational efficiency. Using a corpus of 219 labeled rubrics derived from the GDPVal benchmark, we evaluate ARCANE on challenging tasks requiring multi-step reasoning and tool use. The learned rubrics produce compact, legible evaluations and enable configurable trade-offs (e.g., correctness vs. conciseness) without retraining. Our results show that rubric-based reward models offer a promising path toward interpretable, test-time adaptive alignment for complex, long-horizon AI systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ARCANEï¼Œä¸€ä¸ªæ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹(LLM)æ™ºèƒ½ä½“åœ¨é•¿ç¨‹ä»»åŠ¡(long-horizon tasks)ä¸­å¯¹é½(Alignment)é—®é¢˜çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶ã€‚é’ˆå¯¹ç°æœ‰å¥–åŠ±æ¨¡å‹ç¼ºä¹å¯è§£é‡Šæ€§å’Œæµ‹è¯•æ—¶å¯é…ç½®æ€§çš„æŒ‘æˆ˜ï¼ŒARCANEå°†åˆ©ç›Šç›¸å…³è€…çš„åå¥½åŠ¨æ€è½¬åŒ–ä¸ºè‡ªç„¶è¯­è¨€è¯„ä¼°å‡†åˆ™(Rubrics)ï¼Œå³ä¸€ç»„å¯éšä»»åŠ¡ä¸Šä¸‹æ–‡å®æ—¶ç”Ÿæˆçš„åŠ æƒéªŒè¯æ ‡å‡†ã€‚å—åˆ°æ•ˆç”¨ç†è®º(Utility theory)çš„å¯å‘ï¼Œè¯¥æ¡†æ¶å°†è¯„ä¼°å‡†åˆ™çš„å­¦ä¹ è¡¨è¿°ä¸ºä¸€ä¸ªé‡æ„é—®é¢˜ï¼Œå¹¶é‡‡ç”¨æ­£åˆ™åŒ–ç»„åºåˆ—ç­–ç•¥ä¼˜åŒ–(Group-Sequence Policy Optimization, GSPO)ç¨‹åºæ¥å¹³è¡¡æ¨¡å‹çš„å¯è§£é‡Šæ€§ã€å¿ å®åº¦ä¸è®¡ç®—æ•ˆç‡ã€‚ç ”ç©¶å›¢é˜Ÿåœ¨æ¶‰åŠå¤šæ­¥æ¨ç†å’Œå·¥å…·ä½¿ç”¨çš„æŒ‘æˆ˜æ€§ä»»åŠ¡ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æœæ˜¾ç¤ºARCANEç”Ÿæˆçš„è¯„ä¼°å‡†åˆ™ä¸ä»…ç®€æ´æ˜“è¯»ï¼Œä¸”æ”¯æŒåœ¨æ— éœ€é‡æ–°è®­ç»ƒçš„æƒ…å†µä¸‹å®ç°è¯¸å¦‚å‡†ç¡®æ€§ä¸ç®€æ´æ€§ä¹‹é—´çš„é…ç½®æƒè¡¡ã€‚è¯¥ç ”ç©¶è¯æ˜äº†åŸºäºè¯„ä¼°å‡†åˆ™çš„å¥–åŠ±æ¨¡å‹åœ¨å®ç°å¤æ‚é•¿ç¨‹AIç³»ç»Ÿçš„å¯è§£é‡Šæ€§åŠæµ‹è¯•æ—¶è‡ªé€‚åº”å¯¹é½æ–¹é¢å…·æœ‰æ˜¾è‘—æ½œåŠ›ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to the AAAI 2026 LLAMAS Workshop (Large Language Model Agents for Multi-Agent Systems)",
      "pdf_url": "https://arxiv.org/pdf/2512.06196v1",
      "published_date": "2025-12-05 22:39:54 UTC",
      "updated_date": "2025-12-05 22:39:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:52:03.107791+00:00"
    },
    {
      "arxiv_id": "2512.06193v4",
      "title": "Do You Feel Comfortable? Detecting Hidden Conversational Escalation in AI Chatbots",
      "title_zh": "â€œä½ æ„Ÿåˆ°èˆ’é€‚å—ï¼Ÿâ€ï¼šAI èŠå¤©æœºå™¨äººä¸­éšè”½å¯¹è¯å‡çº§çš„æ£€æµ‹",
      "authors": [
        "Jihyung Park",
        "Saleh Afroogh",
        "David Atkinson",
        "Junfeng Jiao"
      ],
      "abstract": "Large Language Models (LLM) are increasingly integrated into everyday interactions, serving not only as information assistants but also as emotional companions. Even in the absence of explicit toxicity, repeated emotional reinforcement or affective drift can gradually escalate distress in a form of \\textit{implicit harm} that traditional toxicity filters fail to detect. Existing guardrail mechanisms often rely on external classifiers or clinical rubrics that may lag behind the nuanced, real-time dynamics of a developing conversation. To address this gap, we propose GAUGE (Guarding Affective Utterance Generation Escalation), logit-based framework for the real-time detection of hidden conversational escalation. GAUGE measures how an LLM's output probabilistically shifts the affective state of a dialogue.",
      "tldr_zh": "è¯¥é¡¹ç ”ç©¶å…³æ³¨å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨å……å½“æƒ…æ„Ÿä¼´ä¾£æ—¶äº§ç”Ÿçš„â€œéšæ€§ä¼¤å®³(implicit harm)â€ï¼Œå³ç”±é‡å¤çš„æƒ…æ„Ÿå¼ºåŒ–æˆ–æƒ…æ„Ÿæ¼‚ç§»(affective drift)é€æ¸ç´¯ç§¯çš„è´Ÿé¢æƒ…ç»ªå‡çº§ï¼Œè€Œè¿™ç§é£é™©å¾€å¾€éš¾ä»¥è¢«ä¼ ç»Ÿçš„æ¯’æ€§è¿‡æ»¤å™¨æ£€æµ‹ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œä½œè€…æå‡ºäº†GAUGE (Guarding Affective Utterance Generation Escalation) æ¡†æ¶ï¼Œè¿™æ˜¯ä¸€ç§åŸºäºLogitçš„å®æ—¶æ£€æµ‹éšè—å¯¹è¯å‡çº§çš„æ–¹æ³•ã€‚GAUGE é€šè¿‡æ¦‚ç‡æµ‹é‡LLMçš„è¾“å‡ºå¦‚ä½•æ”¹å˜å¯¹è¯çš„æƒ…æ„ŸçŠ¶æ€(affective state)ï¼Œèƒ½å¤Ÿæ›´çµæ•åœ°æ•æ‰å¯¹è¯ä¸­çš„å¾®å¦™åŠ¨æ€ã€‚ç›¸æ¯”ä¾èµ–å¤–éƒ¨åˆ†ç±»å™¨æˆ–ä¸´åºŠå‡†åˆ™çš„ç°æœ‰é˜²å¾¡æœºåˆ¶ï¼Œè¯¥æ¡†æ¶è§£å†³äº†å®æ—¶æ€§æ»åçš„é—®é¢˜ï¼Œä¸ºæ£€æµ‹å’Œé¢„é˜²AIå¯¹è¯ä¸­çš„éšæ€§æƒ…æ„Ÿå±å®³æä¾›äº†æ–°çš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.06193v4",
      "published_date": "2025-12-05 22:28:04 UTC",
      "updated_date": "2026-01-21 19:09:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:51:47.781087+00:00"
    },
    {
      "arxiv_id": "2512.06190v1",
      "title": "Multi-Modal Zero-Shot Prediction of Color Trajectories in Food Drying",
      "title_zh": "é£Ÿå“å¹²ç‡¥ä¸­é¢œè‰²è½¨è¿¹çš„å¤šæ¨¡æ€é›¶æ ·æœ¬é¢„æµ‹",
      "authors": [
        "Shichen Li",
        "Ahmadreza Eslaminia",
        "Chenhui Shao"
      ],
      "abstract": "Food drying is widely used to reduce moisture content, ensure safety, and extend shelf life. Color evolution of food samples is an important indicator of product quality in food drying. Although existing studies have examined color changes under different drying conditions, current approaches primarily rely on low-dimensional color features and cannot fully capture the complex, dynamic color trajectories of food samples. Moreover, existing modeling approaches lack the ability to generalize to unseen process conditions. To address these limitations, we develop a novel multi-modal color-trajectory prediction method that integrates high-dimensional temporal color information with drying process parameters to enable accurate and data-efficient color trajectory prediction. Under unseen drying conditions, the model attains RMSEs of 2.12 for cookie drying and 1.29 for apple drying, reducing errors by over 90% compared with baseline models. These experimental results demonstrate the model's superior accuracy, robustness, and broad applicability.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°å‹çš„å¤šæ¨¡æ€é¢œè‰²è½¨è¿¹é¢„æµ‹æ–¹æ³•(Multi-Modal Color-Trajectory Prediction)ï¼Œæ—¨åœ¨è§£å†³é£Ÿå“å¹²ç‡¥è¿‡ç¨‹ä¸­é¢œè‰²æ¼”å˜é¢„æµ‹éš¾ä»¥æ•æ‰å¤æ‚åŠ¨æ€è½¨è¿¹ä¸”æ³›åŒ–èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚è¯¥æ–¹æ³•é€šè¿‡æ•´åˆé«˜ç»´æ—¶åºé¢œè‰²ä¿¡æ¯ä¸å¹²ç‡¥å·¥è‰ºå‚æ•°ï¼Œå®ç°äº†å‡†ç¡®ä¸”æ•°æ®é«˜æ•ˆçš„é¢œè‰²è½¨è¿¹é¢„æµ‹ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨æœªè§çš„å¹²ç‡¥æ¡ä»¶ä¸‹ï¼Œè¯¥æ¨¡å‹åœ¨é¥¼å¹²å’Œè‹¹æœå¹²ç‡¥ä»»åŠ¡ä¸­çš„å‡æ–¹æ ¹è¯¯å·®(RMSE)åˆ†åˆ«è¾¾åˆ°2.12å’Œ1.29ï¼Œç›¸æ¯”åŸºçº¿æ¨¡å‹è¯¯å·®é™ä½äº†90%ä»¥ä¸Šã€‚è¿™è¡¨æ˜è¯¥æ¨¡å‹åœ¨é›¶æ ·æœ¬é¢„æµ‹(Zero-Shot Prediction)æ–¹é¢å…·æœ‰æ˜¾è‘—çš„å‡†ç¡®æ€§ã€é²æ£’æ€§å’Œå¹¿æ³›çš„å·¥ä¸šåº”ç”¨å‰æ™¯ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.06190v1",
      "published_date": "2025-12-05 22:17:25 UTC",
      "updated_date": "2025-12-05 22:17:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:52:17.932796+00:00"
    },
    {
      "arxiv_id": "2512.11870v2",
      "title": "Using Socio-economic Indicators, Smart Transit Systems, and Urban Simulator to Accelerate ZEV Adoption and Reduce VMT",
      "title_zh": "åˆ©ç”¨ç¤¾ä¼šç»æµæŒ‡æ ‡ã€æ™ºæ…§äº¤é€šç³»ç»ŸåŠåŸå¸‚æ¨¡æ‹Ÿå™¨åŠ é€Ÿé›¶æ’æ”¾è½¦è¾†æ™®åŠå¹¶å‡å°‘è½¦è¾†è¡Œé©¶é‡Œç¨‹",
      "authors": [
        "Mulham Fawakherji",
        "Bruce Race",
        "Driss Benhaddou"
      ],
      "abstract": "Globally, on-road transportation accounts for 15% of greenhouse gas (GHG) emissions and an estimated 385,000 premature deaths from PM2.5. Cities play a critical role in meeting IPCC targets, generating 75% of global energy-related GHG emissions. In Houston, Texas, on-road transportation represents 48% of baseline emissions in the Climate Action Plan (CAP). To reach net-zero by 2050, the CAP targets a 70% emissions reduction from a 2014 baseline, offset by 30% renewable energy. This goal is challenging because Houston is low-density and auto-dependent, with 89% of on-road emissions from cars and small trucks and limited public transit usage. Socio-economic disparities further constrain Zero Emissions Vehicle (ZEV) adoption. Strategies focus on expanding ZEV access and reducing Vehicle Miles Traveled (VMT) by 20% through transit improvements and city design. This paper presents methods for establishing an on-road emissions baseline and evaluating policies that leverage socio-economic indicators and Intelligent Transportation Systems (ITS) to accelerate ZEV adoption and reduce VMT. Smart parking, transit incentives, secure data systems, and ZEV fleet management support improvements in modal split and system reliability. Policy options are analyzed and potential actions identified. To support evaluation, a simulation environment was developed in Unity 3D, enabling dynamic modeling of urban mobility and visualization of policy scenarios. Auto-dependent cities aiming for 2050 emission targets can benefit from the indicators, metrics, and technologies discussed.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¼‘æ–¯é¡¿ç­‰ä½å¯†åº¦ã€é«˜åº¦ä¾èµ–æ±½è½¦çš„åŸå¸‚æ‰€é¢ä¸´çš„äº¤é€šç¢³æ’æ”¾æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€å¥—åˆ©ç”¨ç¤¾ä¼šç»æµæŒ‡æ ‡å’Œæ™ºèƒ½äº¤é€šç³»ç»Ÿ(ITS)æ¥åŠ é€Ÿé›¶æ’æ”¾è½¦è¾†(ZEV)æ™®åŠå¹¶å‡å°‘è½¦è¾†è¡Œé©¶é‡Œç¨‹(VMT)çš„ç»¼åˆæ–¹æ¡ˆã€‚è®ºæ–‡è¯¦ç»†é˜è¿°äº†å»ºç«‹é“è·¯æ’æ”¾åŸºå‡†çš„æ–¹æ³•ï¼Œå¹¶è¯„ä¼°äº†åŒ…æ‹¬æ™ºèƒ½åœè½¦ã€å…¬å…±äº¤é€šæ¿€åŠ±æªæ–½ä»¥åŠZEVè½¦é˜Ÿç®¡ç†åœ¨å†…çš„å¤šç§æ”¿ç­–é€‰é¡¹ï¼Œæ—¨åœ¨ä¼˜åŒ–äº¤é€šæ¨¡å¼åˆ†é…å¹¶æå‡ç³»ç»Ÿå¯é æ€§ã€‚ä¸ºäº†é‡åŒ–æ”¿ç­–æ•ˆæœï¼Œç ”ç©¶å›¢é˜Ÿåœ¨Unity 3Dä¸­å¼€å‘äº†ä¸€ä¸ªåŸå¸‚æ¨¡æ‹Ÿå™¨ï¼Œå®ç°äº†åŸå¸‚ç§»åŠ¨æ€§çš„åŠ¨æ€å»ºæ¨¡ä¸æ”¿ç­–æƒ…æ™¯çš„ç›´è§‚å¯è§†åŒ–ã€‚åˆ†æè¿‡ç¨‹è¯†åˆ«äº†èƒ½å¤Ÿæœ‰æ•ˆæ¨åŠ¨å‡æ’çš„æ½œåœ¨è¡ŒåŠ¨è·¯å¾„ï¼Œä¸ºä¼‘æ–¯é¡¿å®ç°2050å¹´å‡€é›¶æ’æ”¾ç›®æ ‡æä¾›äº†å…³é”®çš„å†³ç­–æ”¯æŒã€‚è¯¥ç ”ç©¶æˆæœä¸ºç±»ä¼¼ä¾èµ–ç§å®¶è½¦çš„åŸå¸‚æä¾›äº†å¯å€Ÿé‰´çš„æŒ‡æ ‡ä½“ç³»å’ŒæŠ€æœ¯æ¡†æ¶ï¼Œå¯¹äºè¾¾æˆIPCCæ°”å€™ç›®æ ‡å…·æœ‰é‡è¦çš„å®è·µæ„ä¹‰ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.11870v2",
      "published_date": "2025-12-05 22:15:24 UTC",
      "updated_date": "2025-12-16 16:55:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:52:07.412751+00:00"
    },
    {
      "arxiv_id": "2512.07901v2",
      "title": "The Theory of Strategic Evolution: Games with Endogenous Players and Strategic Replicators",
      "title_zh": "æˆ˜ç•¥æ¼”åŒ–ç†è®ºï¼šå†…ç”Ÿå‚ä¸è€…åšå¼ˆä¸æˆ˜ç•¥å¤åˆ¶å­",
      "authors": [
        "Kevin Vallier"
      ],
      "abstract": "Von Neumann founded both game theory and the theory of self-reproducing automata, but the two programs never merged. This paper provides the synthesis. The Theory of Strategic Evolution analyzes strategic replicators: entities that optimize under resource constraints and spawn copies of themselves. We introduce Games with Endogenous Players (GEPs), where lineages (not instances) are the fundamental strategic units, and define Evolutionarily Stable Distributions of Intelligence (ESDIs) as the resulting equilibrium concept.\n  The central mathematical object is a hierarchy of strategic layers linked by cross-level gain matrices. Under a small-gain condition (spectral radius less than one), the system admits a global Lyapunov function at every finite depth. We prove closure under meta-selection: adding governance levels, innovation, or constitutional evolution preserves the dynamical structure. The Alignment Impossibility Theorem shows that unrestricted self-modification destroys this structure; stable alignment requires bounded modification classes.\n  Applications include AI deployment dynamics, market concentration, and institutional design. The framework shows why personality engineering fails under selection pressure and identifies constitutional constraints necessary for stable multi-agent systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†æˆ˜ç•¥è¿›åŒ–ç†è®º(Theory of Strategic Evolution)ï¼Œé€šè¿‡èåˆåšå¼ˆè®ºä¸è‡ªæˆ‘å¤åˆ¶è‡ªåŠ¨æœºç†è®ºï¼Œåˆ†æäº†åœ¨èµ„æºçº¦æŸä¸‹ä¼˜åŒ–å¹¶è‡ªæˆ‘å¤åˆ¶çš„ç­–ç•¥å¤åˆ¶è€…(Strategic Replicators)ã€‚ç ”ç©¶å¼•å…¥äº†å†…ç”Ÿå‚ä¸è€…åšå¼ˆ(Games with Endogenous Players, GEPs)ï¼Œå°†è°±ç³»è€Œéä¸ªä½“è§†ä¸ºæ ¸å¿ƒæˆ˜ç•¥å•ä½ï¼Œå¹¶æå‡ºäº†æ¼”åŒ–ç¨³å®šæ™ºèƒ½åˆ†å¸ƒ(Evolutionarily Stable Distributions of Intelligence, ESDIs)ä½œä¸ºå¹³è¡¡æ¦‚å¿µã€‚è¯¥æ¡†æ¶å»ºç«‹äº†ç”±è·¨å±‚å¢ç›ŠçŸ©é˜µé“¾æ¥çš„æˆ˜ç•¥å±‚çº§ç»“æ„ï¼Œè¯æ˜äº†åœ¨å°å¢ç›Šæ¡ä»¶ä¸‹ç³»ç»Ÿå­˜åœ¨å…¨å±€æé›…æ™®è¯ºå¤«å‡½æ•°(Lyapunov function)ï¼Œä¸”åœ¨å…ƒé€‰æ‹©æœºåˆ¶ä¸‹å…·æœ‰ç»“æ„å°é—­æ€§ã€‚å¯¹é½ä¸å¯èƒ½å®šç†(Alignment Impossibility Theorem)è¡¨æ˜ï¼Œæ— é™åˆ¶çš„è‡ªæˆ‘ä¿®æ”¹ä¼šç“¦è§£ç³»ç»Ÿç»“æ„ï¼Œå› æ­¤ç¨³å®šçš„å¯¹é½å¿…é¡»å»ºç«‹åœ¨å—é™çš„ä¿®æ”¹ç±»åˆ«ä¹‹ä¸Šã€‚è¯¥ç†è®ºæ­ç¤ºäº†æ€§æ ¼å·¥ç¨‹åœ¨é€‰æ‹©å‹åŠ›ä¸‹å¤±æ•ˆçš„æ·±å±‚åŸå› ï¼Œå¹¶ä¸ºAIéƒ¨ç½²ã€å¸‚åœºé›†ä¸­åº¦åŠå¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„åˆ¶åº¦è®¾è®¡æä¾›äº†å¿…è¦çš„å®ªæ³•çº¦æŸæŒ‡å¯¼ã€‚",
      "categories": [
        "cs.GT",
        "cs.AI",
        "econ.TH"
      ],
      "primary_category": "cs.GT",
      "comment": "Draft manuscript, 30k words. Companion to Agentic Capital. Submitted to establish priority",
      "pdf_url": "https://arxiv.org/pdf/2512.07901v2",
      "published_date": "2025-12-05 21:58:03 UTC",
      "updated_date": "2025-12-15 23:19:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:52:16.491361+00:00"
    },
    {
      "arxiv_id": "2512.06172v1",
      "title": "DEFEND: Poisoned Model Detection and Malicious Client Exclusion Mechanism for Secure Federated Learning-based Road Condition Classification",
      "title_zh": "DEFENDï¼šé¢å‘å®‰å…¨è”é‚¦å­¦ä¹ è·¯å†µåˆ†ç±»çš„ä¸­æ¯’æ¨¡å‹æ£€æµ‹ä¸æ¶æ„å®¢æˆ·ç«¯æ’é™¤æœºåˆ¶",
      "authors": [
        "Sheng Liu",
        "Panos Papadimitratos"
      ],
      "abstract": "Federated Learning (FL) has drawn the attention of the Intelligent Transportation Systems (ITS) community. FL can train various models for ITS tasks, notably camera-based Road Condition Classification (RCC), in a privacy-preserving collaborative way. However, opening up to collaboration also opens FL-based RCC systems to adversaries, i.e., misbehaving participants that can launch Targeted Label-Flipping Attacks (TLFAs) and threaten transportation safety. Adversaries mounting TLFAs poison training data to misguide model predictions, from an actual source class (e.g., wet road) to a wrongly perceived target class (e.g., dry road). Existing countermeasures against poisoning attacks cannot maintain model performance under TLFAs close to the performance level in attack-free scenarios, because they lack specific model misbehavior detection for TLFAs and neglect client exclusion after the detection. To close this research gap, we propose DEFEND, which includes a poisoned model detection strategy that leverages neuron-wise magnitude analysis for attack goal identification and Gaussian Mixture Model (GMM)-based clustering. DEFEND discards poisoned model contributions in each round and adapts accordingly client ratings, eventually excluding malicious clients. Extensive evaluation involving various FL-RCC models and tasks shows that DEFEND can thwart TLFAs and outperform seven baseline countermeasures, with at least 15.78% improvement, with DEFEND remarkably achieving under attack the same performance as in attack-free scenarios.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸºäº Federated Learning (FL) çš„é“è·¯çŠ¶å†µåˆ†ç±» (Road Condition Classification, RCC) ç³»ç»Ÿæ˜“å—ç›®æ ‡æ ‡ç­¾ç¿»è½¬æ”»å‡» (Targeted Label-Flipping Attacks, TLFAs) å¨èƒçš„é—®é¢˜ï¼Œæå‡ºäº†åä¸º DEFEND çš„å®‰å…¨é˜²æŠ¤æœºåˆ¶ã€‚è¯¥æ–¹æ¡ˆæ ¸å¿ƒåŒ…å«ä¸€ç§åˆ©ç”¨ neuron-wise magnitude analysis è¿›è¡Œæ”»å‡»ç›®æ ‡è¯†åˆ«çš„ç­–ç•¥ï¼Œå¹¶ç»“åˆ Gaussian Mixture Model (GMM) èšç±»å®ç°ä¸­æ¯’æ¨¡å‹çš„ç²¾å‡†æ£€æµ‹ã€‚DEFEND åœ¨æ¯è½®åä½œä¸­å‰”é™¤ä¸­æ¯’æ¨¡å‹çš„è´¡çŒ®ï¼Œå¹¶æ ¹æ®å®¢æˆ·ç«¯è¯„åˆ†æœºåˆ¶æœ€ç»ˆè¯†åˆ«å¹¶æ’é™¤æ¶æ„å‚ä¸è€…ã€‚å®éªŒè¯„ä¼°è¡¨æ˜ï¼Œè¯¥æœºåˆ¶åœ¨å¤šç§ FL-RCC æ¨¡å‹å’Œä»»åŠ¡ä¸­å‡ä¼˜äºä¸ƒç§åŸºå‡†æ–¹æ¡ˆï¼Œæ€§èƒ½æå‡è‡³å°‘ 15.78%ã€‚æœ€æ˜¾è‘—çš„æˆæœæ˜¯ï¼ŒDEFEND åœ¨å—åˆ°æ”»å‡»æ—¶ä»èƒ½è¾¾åˆ°ä¸æ— æ”»å‡»åœºæ™¯ç›¸åŒçš„æ€§èƒ½æ°´å¹³ï¼Œæœ‰æ•ˆè§£å†³äº†ç°æœ‰é˜²å¾¡æ‰‹æ®µåœ¨é¢å¯¹ TLFAs æ—¶æ€§èƒ½ä¸‹é™åŠç¼ºä¹å®¢æˆ·ç«¯æ’é™¤æœºåˆ¶çš„é—®é¢˜ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted to the 41st ACM/SIGAPP Symposium on Applied Computing (SAC 2026)",
      "pdf_url": "https://arxiv.org/pdf/2512.06172v1",
      "published_date": "2025-12-05 21:50:27 UTC",
      "updated_date": "2025-12-05 21:50:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:52:40.346395+00:00"
    },
    {
      "arxiv_id": "2512.06161v1",
      "title": "Deep learning for autism detection using clinical notes: A comparison of transfer learning for a transparent and black-box approach",
      "title_zh": "åŸºäºä¸´åºŠç—…å†çš„æ·±åº¦å­¦ä¹ å­¤ç‹¬ç—‡æ£€æµ‹ï¼šé€æ˜ä¸é»‘ç›’æ–¹æ³•çš„è¿ç§»å­¦ä¹ å¯¹æ¯”ç ”ç©¶",
      "authors": [
        "Gondy Leroy",
        "Prakash Bisht",
        "Sai Madhuri Kandula",
        "Nell Maltman",
        "Sydney Rice"
      ],
      "abstract": "Autism spectrum disorder (ASD) is a complex neurodevelopmental condition whose rising prevalence places increasing demands on a lengthy diagnostic process. Machine learning (ML) has shown promise in automating ASD diagnosis, but most existing models operate as black boxes and are typically trained on a single dataset, limiting their generalizability. In this study, we introduce a transparent and interpretable ML approach that leverages BioBERT, a state-of-the-art language model, to analyze unstructured clinical text. The model is trained to label descriptions of behaviors and map them to diagnostic criteria, which are then used to assign a final label (ASD or not). We evaluate transfer learning, the ability to transfer knowledge to new data, using two distinct real-world datasets. We trained on datasets sequentially and mixed together and compared the performance of the best models and their ability to transfer to new data. We also created a black-box approach and repeated this transfer process for comparison. Our transparent model demonstrated robust performance, with the mixed-data training strategy yielding the best results (97 % sensitivity, 98 % specificity). Sequential training across datasets led to a slight drop in performance, highlighting the importance of training data order. The black-box model performed worse (90 % sensitivity, 96 % specificity) when trained sequentially or with mixed data. Overall, our transparent approach outperformed the black-box approach. Mixing datasets during training resulted in slightly better performance and should be the preferred approach when practically possible. This work paves the way for more trustworthy, generalizable, and clinically actionable AI tools in neurodevelopmental diagnostics.",
      "tldr_zh": "é’ˆå¯¹è‡ªé—­ç—‡è°±ç³»éšœç¢(Autism Spectrum Disorder, ASD)è¯Šæ–­å‘¨æœŸé•¿ä¸”ç°æœ‰æœºå™¨å­¦ä¹ æ¨¡å‹ç¼ºä¹é€æ˜åº¦å’Œæ³›åŒ–èƒ½åŠ›çš„é—®é¢˜ï¼Œè¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºBioBERTçš„é€æ˜ä¸”å¯è§£é‡Šçš„æ·±åº¦å­¦ä¹ æ–¹æ³•ã€‚è¯¥æ–¹æ³•åˆ©ç”¨BioBERTåˆ†æéç»“æ„åŒ–ä¸´åºŠç¬”è®°ï¼Œå°†è¡Œä¸ºæè¿°æ˜ å°„åˆ°å…·ä½“çš„è¯Šæ–­æ ‡å‡†ï¼Œä»è€Œç”Ÿæˆæœ€ç»ˆçš„è¯Šæ–­æ ‡ç­¾ã€‚ç ”ç©¶äººå‘˜é€šè¿‡ä¸¤ä¸ªçœŸå®çš„ä¸´åºŠæ•°æ®é›†è¯„ä¼°äº†è¿ç§»å­¦ä¹ (Transfer Learning)çš„æ•ˆæœï¼Œå¹¶å¯¹æ¯”äº†é€æ˜æ¨¡å‹ä¸é»‘ç›’(Black-box)æ¨¡å‹åœ¨é¡ºåºè®­ç»ƒå’Œæ··åˆè®­ç»ƒæ¨¡å¼ä¸‹çš„è¡¨ç°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œé€æ˜æ¨¡å‹åœ¨æ··åˆæ•°æ®è®­ç»ƒç­–ç•¥ä¸‹è¡¨ç°æœ€ä½³ï¼Œçµæ•åº¦(Sensitivity)è¾¾åˆ°97%ï¼Œç‰¹å¼‚æ€§(Specificity)ä¸º98%ï¼Œæ˜¾è‘—ä¼˜äºé»‘ç›’æ¨¡å‹çš„è¡¨ç°ã€‚ç ”ç©¶å‘ç°ï¼Œæ··åˆè®­ç»ƒçš„æ•ˆæœä¼˜äºé¡ºåºè®­ç»ƒï¼Œä¸”é€æ˜æ¨¡å‹åœ¨è·¨æ•°æ®é›†è¿ç§»ä¸­å±•ç°å‡ºæ›´å¼ºçš„é²æ£’æ€§ã€‚è¯¥å·¥ä½œä¸ºå¼€å‘æ›´å…·ä¿¡ä»»åº¦ã€é€šç”¨æ€§ä¸”å…·å¤‡ä¸´åºŠæ“ä½œä»·å€¼çš„ç¥ç»å‘è‚²è¯Šæ–­äººå·¥æ™ºèƒ½å·¥å…·å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages",
      "pdf_url": "https://arxiv.org/pdf/2512.06161v1",
      "published_date": "2025-12-05 21:14:59 UTC",
      "updated_date": "2025-12-05 21:14:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:52:28.587581+00:00"
    },
    {
      "arxiv_id": "2512.06154v1",
      "title": "Learning Invariant Graph Representations Through Redundant Information",
      "title_zh": "åŸºäºå†—ä½™ä¿¡æ¯çš„ä¸å˜å›¾è¡¨ç¤ºå­¦ä¹ ",
      "authors": [
        "Barproda Halder",
        "Pasan Dissanayake",
        "Sanghamitra Dutta"
      ],
      "abstract": "Learning invariant graph representations for out-of-distribution (OOD) generalization remains challenging because the learned representations often retain spurious components. To address this challenge, this work introduces a new tool from information theory called Partial Information Decomposition (PID) that goes beyond classical information-theoretic measures. We identify limitations in existing approaches for invariant representation learning that solely rely on classical information-theoretic measures, motivating the need to precisely focus on redundant information about the target $Y$ shared between spurious subgraphs $G_s$ and invariant subgraphs $G_c$ obtained via PID. Next, we propose a new multi-level optimization framework that we call -- Redundancy-guided Invariant Graph learning (RIG) -- that maximizes redundant information while isolating spurious and causal subgraphs, enabling OOD generalization under diverse distribution shifts. Our approach relies on alternating between estimating a lower bound of redundant information (which itself requires an optimization) and maximizing it along with additional objectives. Experiments on both synthetic and real-world graph datasets demonstrate the generalization capabilities of our proposed RIG framework.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å›¾è¡¨ç¤ºå­¦ä¹ åœ¨åˆ†å¸ƒå¤–ï¼ˆOut-of-Distribution, OODï¼‰æ³›åŒ–ä¸­å®¹æ˜“ä¿ç•™ä¼ªç›¸å…³ï¼ˆspuriousï¼‰æˆåˆ†çš„æŒ‘æˆ˜ï¼Œå¼•å…¥äº†ä¿¡æ¯è®ºä¸­çš„éƒ¨åˆ†ä¿¡æ¯åˆ†è§£ï¼ˆPartial Information Decomposition, PIDï¼‰å·¥å…·ã€‚ç ”ç©¶è€…å‘ç°ç°æœ‰æ–¹æ³•ä»…ä¾èµ–ç»å…¸ä¿¡æ¯è®ºåº¦é‡å…·æœ‰å±€é™æ€§ï¼Œè¿›è€Œæå‡ºåº”ç²¾å‡†å…³æ³¨ä¼ªå­å›¾ï¼ˆspurious subgraphs, $G_s$ï¼‰ä¸ä¸å˜å­å›¾ï¼ˆinvariant subgraphs, $G_c$ï¼‰ä¹‹é—´å…³äºç›®æ ‡ $Y$ çš„å†—ä½™ä¿¡æ¯ï¼ˆredundant informationï¼‰ã€‚åŸºäºæ­¤ï¼Œè®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºå†—ä½™å¼•å¯¼çš„ä¸å˜å›¾å­¦ä¹ ï¼ˆRedundancy-guided Invariant Graph learning, RIGï¼‰çš„å¤šå±‚ä¼˜åŒ–æ¡†æ¶ï¼Œé€šè¿‡æœ€å¤§åŒ–å†—ä½™ä¿¡æ¯æ¥éš”ç¦»ä¼ªå­å›¾ä¸å› æœå­å›¾ã€‚è¯¥æ–¹æ³•é‡‡ç”¨äº¤æ›¿ä¼˜åŒ–ç­–ç•¥æ¥ä¼°è®¡å¹¶æœ€å¤§åŒ–å†—ä½™ä¿¡æ¯çš„ä¸‹ç•Œï¼Œä»è€Œå¢å¼ºæ¨¡å‹åœ¨å¤šæ ·åŒ–åˆ†å¸ƒåç§»ä¸‹çš„æ³›åŒ–èƒ½åŠ›ã€‚å®éªŒç»“æœåœ¨åˆæˆåŠçœŸå®ä¸–ç•Œå›¾æ•°æ®é›†ä¸Šå‡éªŒè¯äº† RIG æ¡†æ¶åœ¨å®ç° OOD æ³›åŒ–æ–¹é¢çš„ä¼˜è¶Šæ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.06154v1",
      "published_date": "2025-12-05 21:07:11 UTC",
      "updated_date": "2025-12-05 21:07:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:53:15.645482+00:00"
    },
    {
      "arxiv_id": "2512.06134v1",
      "title": "Physics-Informed Neural Koopman Machine for Interpretable Longitudinal Personalized Alzheimer's Disease Forecasting",
      "title_zh": "ç”¨äºå¯è§£é‡Šçºµå‘ä¸ªæ€§åŒ–é˜¿å°”èŒ¨æµ·é»˜ç—…é¢„æµ‹çš„ç‰©ç†ä¿¡æ¯å¼•å¯¼ç¥ç» Koopman æœº",
      "authors": [
        "Georgi Hrusanov",
        "Duy-Thanh Vu",
        "Duy-Cat Can",
        "Sophie Tascedda",
        "Margaret Ryan",
        "Julien Bodelet",
        "Katarzyna Koscielska",
        "Carsten Magnus",
        "Oliver Y. ChÃ©n"
      ],
      "abstract": "Early forecasting of individual cognitive decline in Alzheimer's disease (AD) is central to disease evaluation and management. Despite advances, it is as of yet challenging for existing methodological frameworks to integrate multimodal data for longitudinal personalized forecasting while maintaining interpretability. To address this gap, we present the Neural Koopman Machine (NKM), a new machine learning architecture inspired by dynamical systems and attention mechanisms, designed to forecast multiple cognitive scores simultaneously using multimodal genetic, neuroimaging, proteomic, and demographic data. NKM integrates analytical ($Î±$) and biological ($Î²$) knowledge to guide feature grouping and control the hierarchical attention mechanisms to extract relevant patterns. By implementing Fusion Group-Aware Hierarchical Attention within the Koopman operator framework, NKM transforms complex nonlinear trajectories into interpretable linear representations. To demonstrate NKM's efficacy, we applied it to study the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset. Our results suggest that NKM consistently outperforms both traditional machine learning methods and deep learning models in forecasting trajectories of cognitive decline. Specifically, NKM (1) forecasts changes of multiple cognitive scores simultaneously, (2) quantifies differential biomarker contributions to predicting distinctive cognitive scores, and (3) identifies brain regions most predictive of cognitive deterioration. Together, NKM advances personalized, interpretable forecasting of future cognitive decline in AD using past multimodal data through an explainable, explicit system and reveals potential multimodal biological underpinnings of AD progression.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸ºNeural Koopman Machine (NKM)çš„æ–°å‹æœºå™¨å­¦ä¹ æ¶æ„ï¼Œæ—¨åœ¨è§£å†³é˜¿å°”èŒ¨æµ·é»˜ç—… (Alzheimer's Disease) çºµå‘ä¸ªæ€§åŒ–é¢„æµ‹ä¸­å¤šæ¨¡æ€æ•°æ®æ•´åˆä¸å¯è§£é‡Šæ€§ä¸è¶³çš„æŒ‘æˆ˜ã€‚NKM å—åˆ°åŠ¨åŠ›ç³»ç»Ÿå’Œæ³¨æ„åŠ›æœºåˆ¶çš„å¯å‘ï¼Œé›†æˆäº†åˆ†æçŸ¥è¯† ($Î±$) å’Œç”Ÿç‰©å­¦çŸ¥è¯† ($Î²$) æ¥å¼•å¯¼ç‰¹å¾åˆ†ç»„ï¼Œå¹¶åˆ©ç”¨èåˆç»„æ„ŸçŸ¥å±‚æ¬¡æ³¨æ„åŠ› (Fusion Group-Aware Hierarchical Attention) æœºåˆ¶åœ¨ Koopman ç®—å­æ¡†æ¶ä¸‹å°†å¤æ‚çš„éçº¿æ€§è½¨è¿¹è½¬åŒ–ä¸ºå¯è§£é‡Šçš„çº¿æ€§è¡¨ç¤ºã€‚è¯¥æ¡†æ¶ç»“åˆé—ä¼ ã€ç¥ç»å½±åƒã€è›‹ç™½è´¨ç»„å­¦å’Œäººå£ç»Ÿè®¡å­¦æ•°æ®ï¼Œèƒ½å¤ŸåŒæ—¶é¢„æµ‹å¤šä¸ªè®¤çŸ¥å¾—åˆ†çš„æ¼”å˜ã€‚åœ¨ Alzheimer's Disease Neuroimaging Initiative (ADNI) æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒNKM çš„é¢„æµ‹æ€§èƒ½ä¸€è‡´ä¼˜äºä¼ ç»Ÿçš„æœºå™¨å­¦ä¹ æ–¹æ³•å’Œæ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚ç ”ç©¶å‘ç° NKM ä¸ä»…èƒ½å®ç°ç²¾å‡†é¢„æµ‹ï¼Œè¿˜èƒ½é‡åŒ–ä¸åŒç”Ÿç‰©æ ‡å¿—ç‰©å¯¹ç‰¹å®šè®¤çŸ¥å¾—åˆ†çš„è´¡çŒ®ï¼Œå¹¶è¯†åˆ«å‡ºä¸è®¤çŸ¥æ¶åŒ–æœ€å…·ç›¸å…³æ€§çš„è„‘åŒºã€‚è¯¥å·¥ä½œé€šè¿‡å¯è§£é‡Šçš„æ˜¾å¼ç³»ç»Ÿæ·±åŒ–äº†å¯¹ç–¾ç—…è¿›å±•ä¸­å¤šæ¨¡æ€ç”Ÿç‰©å­¦åŸºç¡€çš„ç†è§£ï¼Œä¸ºä¸ªæ€§åŒ–ã€ç²¾å‡†çš„è®¤çŸ¥è¡°é€€é¢„æµ‹å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.NC",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.06134v1",
      "published_date": "2025-12-05 20:29:01 UTC",
      "updated_date": "2025-12-05 20:29:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:53:24.533590+00:00"
    },
    {
      "arxiv_id": "2512.06123v1",
      "title": "Toward Patch Robustness Certification and Detection for Deep Learning Systems Beyond Consistent Samples",
      "title_zh": "é¢å‘æ·±åº¦å­¦ä¹ ç³»ç»Ÿè¶…è¶Šä¸€è‡´æ€§æ ·æœ¬çš„è¡¥ä¸é²æ£’æ€§è®¤è¯ä¸æ£€æµ‹",
      "authors": [
        "Qilin Zhou",
        "Zhengyuan Wei",
        "Haipeng Wang",
        "Zhuo Wang",
        "W. K. Chan"
      ],
      "abstract": "Patch robustness certification is an emerging kind of provable defense technique against adversarial patch attacks for deep learning systems. Certified detection ensures the detection of all patched harmful versions of certified samples, which mitigates the failures of empirical defense techniques that could (easily) be compromised. However, existing certified detection methods are ineffective in certifying samples that are misclassified or whose mutants are inconsistently pre icted to different labels. This paper proposes HiCert, a novel masking-based certified detection technique. By focusing on the problem of mutants predicted with a label different from the true label with our formal analysis, HiCert formulates a novel formal relation between harmful samples generated by identified loopholes and their benign counterparts. By checking the bound of the maximum confidence among these potentially harmful (i.e., inconsistent) mutants of each benign sample, HiCert ensures that each harmful sample either has the minimum confidence among mutants that are predicted the same as the harmful sample itself below this bound, or has at least one mutant predicted with a label different from the harmful sample itself, formulated after two novel insights. As such, HiCert systematically certifies those inconsistent samples and consistent samples to a large extent. To our knowledge, HiCert is the first work capable of providing such a comprehensive patch robustness certification for certified detection. Our experiments show the high effectiveness of HiCert with a new state-of the-art performance: It certifies significantly more benign samples, including those inconsistent and consistent, and achieves significantly higher accuracy on those samples without warnings and a significantly lower false silent ratio.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†HiCertï¼Œä¸€ç§åŸºäºæ©ç (masking-based)çš„å…¨æ–°è®¤è¯æ£€æµ‹(certified detection)æŠ€æœ¯ï¼Œæ—¨åœ¨æå‡æ·±åº¦å­¦ä¹ ç³»ç»Ÿå¯¹æŠ—è¡¥ä¸æ”»å‡»(adversarial patch attacks)çš„è¡¥ä¸ç¨³å¥æ€§è®¤è¯æ°´å¹³ã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•æ— æ³•æœ‰æ•ˆå¤„ç†åˆ†ç±»é”™è¯¯æˆ–é¢„æµ‹æ ‡ç­¾ä¸ä¸€è‡´(inconsistent samples)æ ·æœ¬çš„å±€é™æ€§ï¼ŒHiCerté€šè¿‡å½¢å¼åŒ–åˆ†æ(formal analysis)å»ºç«‹äº†æœ‰å®³æ ·æœ¬ä¸å…¶è‰¯æ€§å¯¹åº”æ ·æœ¬ä¹‹é—´çš„å…³è”é€»è¾‘ã€‚è¯¥æŠ€æœ¯é€šè¿‡ç›‘æ§è‰¯æ€§æ ·æœ¬æ½œåœ¨æœ‰å®³å˜ä½“çš„æœ€å¤§ç½®ä¿¡åº¦è¾¹ç•Œï¼Œç¡®ä¿æœ‰å®³æ ·æœ¬å› ç½®ä¿¡åº¦æä½æˆ–è§¦å‘æ ‡ç­¾å†²çªè€Œè¢«å‡†ç¡®è¯†åˆ«ï¼Œä»è€Œå®ç°äº†å¯¹ä¸€è‡´å’Œä¸ä¸€è‡´æ ·æœ¬çš„ç³»ç»ŸåŒ–è®¤è¯ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒHiCertåœ¨è®¤è¯æ ·æœ¬æ•°é‡ã€æ— é¢„è­¦å‡†ç¡®ç‡åŠæ›´ä½çš„æ¼æŠ¥ç‡(false silent ratio)æ–¹é¢å‡è¾¾åˆ°äº†SOTAæ€§èƒ½ã€‚ä½œä¸ºé¦–ä¸ªæä¾›æ­¤ç±»å…¨é¢è¡¥ä¸ç¨³å¥æ€§è®¤è¯çš„å·¥ä½œï¼ŒHiCertæ˜¾è‘—å¢å¼ºäº†å¯è¯æ˜é˜²å¾¡æŠ€æœ¯çš„å®ç”¨æ€§ä¸å¯é æ€§ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.SE",
      "comment": "accepted by IEEE Transactions on Reliability; extended technical report",
      "pdf_url": "https://arxiv.org/pdf/2512.06123v1",
      "published_date": "2025-12-05 20:02:09 UTC",
      "updated_date": "2025-12-05 20:02:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:53:16.682772+00:00"
    },
    {
      "arxiv_id": "2512.15733v1",
      "title": "A Context-Free Smart Grid Model Using Complex System Approach",
      "title_zh": "åŸºäºå¤æ‚ç³»ç»Ÿæ–¹æ³•çš„ä¸Šä¸‹æ–‡æ— å…³æ™ºèƒ½ç”µç½‘æ¨¡å‹",
      "authors": [
        "Soufian Ben Amor",
        "Alain Bui",
        "Guillaume Guerard"
      ],
      "abstract": "Energy and pollution are urging problems of the 21th century. By gradually changing the actual power grid system, smart grid may evolve into different systems by means of size, elements and strategies, but its fundamental requirements and objectives will not change such as optimizing production, transmission, and consumption. Studying the smart grid through modeling and simulation provides us with valuable results which cannot be obtained in real world due to time and cost related constraints. Moreover, due to the complexity of the smart grid, achieving global optimization is not an easy task. In this paper, we propose a complex system based approach to the smart grid modeling, accentuating on the optimization by combining game theoretical and classical methods in different levels. Thanks to this combination, the optimization can be achieved with flexibility and scalability, while keeping its generality.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹21ä¸–çºªæ—¥ç›Šä¸¥å³»çš„èƒ½æºä¸æ±¡æŸ“é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºComplex Systemæ–¹æ³•çš„Context-Free Smart Gridæ¨¡å‹ã€‚ç”±äºSmart Gridæ¶‰åŠä¼—å¤šå…ƒä»¶ä¸å¤æ‚ç­–ç•¥ï¼Œå®ç°å…¨å±€ä¼˜åŒ–å…·æœ‰æå¤§æŒ‘æˆ˜ï¼Œå› æ­¤è¯¥æ¨¡å‹é€šè¿‡åœ¨ä¸åŒå±‚çº§ç»“åˆGame Theoreticalä¸Classical Methodsæ¥å¯»æ±‚æœ€ä¼˜è§£ã€‚è¿™ç§æ–¹æ³•è®ºçš„ç»“åˆä½¿å¾—æ¨¡å‹åœ¨ä¿æŒGeneralityçš„åŒæ—¶ï¼Œå…·å¤‡äº†ä¼˜ç§€çš„Flexibilityä¸Scalabilityï¼Œèƒ½å¤Ÿé€‚åº”ä¸åŒè§„æ¨¡çš„ç”µç½‘æ¼”å˜ã€‚ç ”ç©¶å¼ºè°ƒäº†å»ºæ¨¡ä¸ä»¿çœŸåœ¨æ™ºèƒ½ç”µç½‘ç ”ç©¶ä¸­çš„é‡è¦æ€§ï¼Œè®¤ä¸ºè¿™èƒ½æœ‰æ•ˆè§£å†³ç°å®å®éªŒä¸­é¢ä¸´çš„æ—¶é—´ä¸æˆæœ¬çº¦æŸã€‚æœ€ç»ˆï¼Œè¯¥æ¨¡å‹ä¸ºä¼˜åŒ–ç”µåŠ›ç”Ÿäº§ã€ä¼ è¾“ä¸æ¶ˆè´¹æä¾›äº†å¯æ‰©å±•çš„ç†è®ºæ”¯æ’‘ï¼Œä¸ºæœªæ¥ç”µåŠ›ç³»ç»Ÿçš„æ™ºèƒ½åŒ–è½¬å‹å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "math.OC",
        "cs.AI",
        "eess.SY"
      ],
      "primary_category": "math.OC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.15733v1",
      "published_date": "2025-12-05 19:53:30 UTC",
      "updated_date": "2025-12-05 19:53:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:53:11.279810+00:00"
    },
    {
      "arxiv_id": "2512.06112v2",
      "title": "WAM-Flow: Parallel Coarse-to-Fine Motion Planning via Discrete Flow Matching for Autonomous Driving",
      "title_zh": "WAM-Flowï¼šåŸºäºç¦»æ•£æµåŒ¹é…çš„è‡ªåŠ¨é©¾é©¶å¹¶è¡Œç”±ç²—åˆ°ç²¾è¿åŠ¨è§„åˆ’",
      "authors": [
        "Yifang Xu",
        "Jiahao Cui",
        "Feipeng Cai",
        "Zhihao Zhu",
        "Hanlin Shang",
        "Shan Luan",
        "Mingwang Xu",
        "Neng Zhang",
        "Yaoyi Li",
        "Jia Cai",
        "Siyu Zhu"
      ],
      "abstract": "We introduce WAM-Flow, a vision-language-action (VLA) model that casts ego-trajectory planning as discrete flow matching over a structured token space. In contrast to autoregressive decoders, WAM-Flow performs fully parallel, bidirectional denoising, enabling coarse-to-fine refinement with a tunable compute-accuracy trade-off. Specifically, the approach combines a metric-aligned numerical tokenizer that preserves scalar geometry via triplet-margin learning, a geometry-aware flow objective and a simulator-guided GRPO alignment that integrates safety, ego progress, and comfort rewards while retaining parallel generation. A multi-stage adaptation converts a pre-trained auto-regressive backbone (Janus-1.5B) from causal decoding to non-causal flow model and strengthens road-scene competence through continued multimodal pretraining. Thanks to the inherent nature of consistency model training and parallel decoding inference, WAM-Flow achieves superior closed-loop performance against autoregressive and diffusion-based VLA baselines, with 1-step inference attaining 89.1 PDMS and 5-step inference reaching 90.3 PDMS on NAVSIM v1 benchmark. These results establish discrete flow matching as a new promising paradigm for end-to-end autonomous driving. The code will be publicly available soon.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† WAM-Flowï¼Œä¸€ç§å°†è‡ªåŠ¨é©¾é©¶ ego-trajectory planning å»ºæ¨¡ä¸ºç»“æ„åŒ–æ ‡è®°ç©ºé—´ä¸Š discrete flow matching çš„ vision-language-action (VLA) æ¨¡å‹ã€‚ä¸ autoregressive decoders ä¸åŒï¼ŒWAM-Flow æ‰§è¡Œå…¨å¹¶è¡Œçš„åŒå‘å»å™ªï¼Œå®ç°äº† coarse-to-fine çš„è½¨è¿¹ç»†åŒ–ï¼Œå¹¶æ”¯æŒå¯è°ƒèŠ‚çš„è®¡ç®—ä¸å‡†ç¡®åº¦æƒè¡¡ã€‚è¯¥æ–¹æ³•ç»“åˆäº†é€šè¿‡ triplet-margin learning ä¿æŒå‡ ä½•ç‰¹æ€§çš„ metric-aligned numerical tokenizerï¼Œä»¥åŠæ•´åˆäº†å®‰å…¨æ€§ã€è¿›åº¦å’Œèˆ’é€‚åº¦å¥–åŠ±çš„ simulator-guided GRPO å¯¹é½æŠ€æœ¯ã€‚é€šè¿‡å¤šé˜¶æ®µé€‚é…ï¼Œç ”ç©¶è€…å°†é¢„è®­ç»ƒçš„ Janus-1.5B ä» causal decoding è½¬æ¢ä¸º non-causal flow æ¨¡å‹ï¼Œæ˜¾è‘—å¢å¼ºäº†å…¶é“è·¯åœºæ™¯çš„å¤„ç†èƒ½åŠ›ã€‚åœ¨ NAVSIM v1 åŸºå‡†æµ‹è¯•ä¸­ï¼ŒWAM-Flow çš„ 1 æ­¥æ¨ç†è¾¾åˆ° 89.1 PDMSï¼Œ5 æ­¥æ¨ç†è¾¾åˆ° 90.3 PDMSï¼Œæ€§èƒ½ä¼˜äºè‡ªå›å½’å’Œ diffusion-based åŸºå‡†ã€‚è¿™é¡¹å·¥ä½œè¯æ˜äº† discrete flow matching æ˜¯ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶é¢†åŸŸä¸€ä¸ªæå…·å‰æ™¯çš„æ–°èŒƒå¼ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "18 pages, 11 figures. Code & Model: https://github.com/fudan-generative-vision/WAM-Flow",
      "pdf_url": "https://arxiv.org/pdf/2512.06112v2",
      "published_date": "2025-12-05 19:36:46 UTC",
      "updated_date": "2025-12-11 16:06:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:53:38.491905+00:00"
    },
    {
      "arxiv_id": "2512.06106v1",
      "title": "Future You: Designing and Evaluating Multimodal AI-generated Digital Twins for Strengthening Future Self-Continuity",
      "title_zh": "Future Youï¼šå¢å¼ºæœªæ¥è‡ªæˆ‘è¿ç»­æ€§çš„å¤šæ¨¡æ€AIç”Ÿæˆæ•°å­—å­ªç”Ÿçš„è®¾è®¡ä¸è¯„ä¼°",
      "authors": [
        "Constanze Albrecht",
        "Chayapatr Archiwaranguprok",
        "Rachel Poonsiriwong",
        "Awu Chen",
        "Peggy Yin",
        "Monchai Lertsutthiwong",
        "Kavin Winson",
        "Hal Hershfield",
        "Pattie Maes",
        "Pat Pataranutaporn"
      ],
      "abstract": "What if users could meet their future selves today? AI-generated future selves simulate meaningful encounters with a digital twin decades in the future. As AI systems advance, combining cloned voices, age-progressed facial rendering, and autobiographical narratives, a central question emerges: Does the modality of these future selves alter their psychological and affective impact? How might a text-based chatbot, a voice-only system, or a photorealistic avatar shape present-day decisions and our feeling of connection to the future? We report a randomized controlled study (N=92) evaluating three modalities of AI-generated future selves (text, voice, avatar) against a neutral control condition. We also report a systematic model evaluation between Claude 4 and three other Large Language Models (LLMs), assessing Claude 4 across psychological and interaction dimensions and establishing conversational AI quality as a critical determinant of intervention effectiveness. All personalized modalities strengthened Future Self-Continuity (FSC), emotional well-being, and motivation compared to control, with avatar producing the largest vividness gains, yet with no significant differences between formats. Interaction quality metrics, particularly persuasiveness, realism, and user engagement, emerged as robust predictors of psychological and affective outcomes, indicating that how compelling the interaction feels matters more than the form it takes. Content analysis found thematic patterns: text emphasized career planning, while voice and avatar facilitated personal reflection. Claude 4 outperformed ChatGPT 3.5, Llama 4, and Qwen 3 in enhancing psychological, affective, and FSC outcomes.",
      "tldr_zh": "è¯¥ç ”ç©¶è®¾è®¡å¹¶è¯„ä¼°äº†åä¸ºâ€œFuture Youâ€çš„å¤šæ¨¡æ€AIç”Ÿæˆæ•°å­—å­ªç”Ÿç³»ç»Ÿï¼Œæ—¨åœ¨é€šè¿‡è®©ç”¨æˆ·ä¸æ•°åå¹´åçš„æœªæ¥è‡ªæˆ‘è¿›è¡Œæ¨¡æ‹Ÿäº’åŠ¨ï¼Œå¢å¼ºæœªæ¥è‡ªæˆ‘è¿ç»­æ€§(Future Self-Continuity, FSC)ã€‚ç ”ç©¶é€šè¿‡ä¸€é¡¹éšæœºå¯¹ç…§å®éªŒå¯¹æ¯”äº†æ–‡æœ¬(text)ã€è¯­éŸ³(voice)å’Œå†™å®è™šæ‹ŸåŒ–èº«(avatar)ä¸‰ç§æ¨¡æ€å¯¹å¿ƒç†å’Œæƒ…æ„Ÿçš„å½±å“ï¼Œå¹¶å¯¹Claude 4ç­‰å¤šç§å¤§è¯­è¨€æ¨¡å‹(LLMs)è¿›è¡Œäº†ç³»ç»Ÿè¯„ä¼°ã€‚ç»“æœè¡¨æ˜ï¼Œæ‰€æœ‰ä¸ªæ€§åŒ–æ¨¡æ€å‡æ˜¾è‘—æå‡äº†ç”¨æˆ·çš„FSCã€æƒ…æ„Ÿç¦ç¥‰å’ŒåŠ¨åŠ›ï¼Œå…¶ä¸­è™šæ‹ŸåŒ–èº«åœ¨å¢å¼ºç”ŸåŠ¨æ„Ÿæ–¹é¢æ•ˆæœæœ€ä¸ºæ˜¾è‘—ã€‚ç ”ç©¶è¿›ä¸€æ­¥å‘ç°ï¼Œäº¤äº’è´¨é‡ï¼ˆå¦‚è¯´æœåŠ›ã€çœŸå®æ„Ÿå’Œå‚ä¸åº¦ï¼‰æ˜¯å¿ƒç†ç»“æœçš„å…³é”®å†³å®šå› ç´ ï¼Œå…¶å½±å“è¶…è¿‡äº†æ¨¡æ€æœ¬èº«ã€‚æ­¤å¤–ï¼ŒClaude 4åœ¨å¢å¼ºå¿ƒç†å½±å“å’ŒFSCæˆæœæ–¹é¢ä¼˜äºChatGPT 3.5ã€Llama 4å’ŒQwen 3ã€‚è¯¥å·¥ä½œæ­ç¤ºäº†ç”Ÿæˆå¼AIåœ¨å¹²é¢„äººç±»é•¿æœŸå†³ç­–å’Œè‡ªæˆ‘æ„ŸçŸ¥æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.06106v1",
      "published_date": "2025-12-05 19:24:18 UTC",
      "updated_date": "2025-12-05 19:24:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:53:45.544046+00:00"
    },
    {
      "arxiv_id": "2512.06105v1",
      "title": "Explainable Melanoma Diagnosis with Contrastive Learning and LLM-based Report Generation",
      "title_zh": "åŸºäºå¯¹æ¯”å­¦ä¹ ä¸å¤§è¯­è¨€æ¨¡å‹æŠ¥å‘Šç”Ÿæˆçš„å¯è§£é‡Šæ€§é»‘è‰²ç´ ç˜¤è¯Šæ–­",
      "authors": [
        "Junwen Zheng",
        "Xinran Xu",
        "Li Rong Wang",
        "Chang Cai",
        "Lucinda Siyun Tan",
        "Dingyuan Wang",
        "Hong Liang Tey",
        "Xiuyi Fan"
      ],
      "abstract": "Deep learning has demonstrated expert-level performance in melanoma classification, positioning it as a powerful tool in clinical dermatology. However, model opacity and the lack of interpretability remain critical barriers to clinical adoption, as clinicians often struggle to trust the decision-making processes of black-box models. To address this gap, we present a Cross-modal Explainable Framework for Melanoma (CEFM) that leverages contrastive learning as the core mechanism for achieving interpretability. Specifically, CEFM maps clinical criteria for melanoma diagnosis-namely Asymmetry, Border, and Color (ABC)-into the Vision Transformer embedding space using dual projection heads, thereby aligning clinical semantics with visual features. The aligned representations are subsequently translated into structured textual explanations via natural language generation, creating a transparent link between raw image data and clinical interpretation. Experiments on public datasets demonstrate 92.79% accuracy and an AUC of 0.961, along with significant improvements across multiple interpretability metrics. Qualitative analyses further show that the spatial arrangement of the learned embeddings aligns with clinicians' application of the ABC rule, effectively bridging the gap between high-performance classification and clinical trust.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†é»‘è‰²ç´ ç˜¤è¯Šæ–­çš„è·¨æ¨¡æ€å¯è§£é‡Šæ¡†æ¶(CEFM)ï¼Œåˆ©ç”¨å¯¹æ¯”å­¦ä¹ (Contrastive Learning)ä½œä¸ºæ ¸å¿ƒæœºåˆ¶ï¼Œæ—¨åœ¨è§£å†³æ·±åº¦å­¦ä¹ é»‘ç›’æ¨¡å‹åœ¨ä¸´åºŠçš®è‚¤åŒ»å­¦ä¸­ç¼ºä¹é€æ˜åº¦å’Œå¯è§£é‡Šæ€§çš„ç“¶é¢ˆã€‚CEFMé€šè¿‡åŒæŠ•å½±å¤´(dual projection heads)å°†é»‘è‰²ç´ ç˜¤è¯Šæ–­çš„ä¸´åºŠABCè§„åˆ™ï¼Œå³ä¸å¯¹ç§°æ€§(Asymmetry)ã€è¾¹ç•Œ(Border)å’Œé¢œè‰²(Color)ï¼Œæ˜ å°„åˆ°Vision Transformerçš„åµŒå…¥ç©ºé—´ï¼Œå®ç°äº†ä¸´åºŠè¯­ä¹‰ä¸è§†è§‰ç‰¹å¾çš„æ·±åº¦å¯¹é½ã€‚è¿™äº›å¯¹é½åçš„è¡¨å¾è¿›ä¸€æ­¥é€šè¿‡è‡ªç„¶è¯­è¨€ç”ŸæˆæŠ€æœ¯è½¬åŒ–ä¸ºç»“æ„åŒ–çš„æ–‡æœ¬æŠ¥å‘Šï¼Œåœ¨åŸå§‹å›¾åƒæ•°æ®ä¸ä¸´åºŠå†³ç­–ä¹‹é—´å»ºç«‹äº†é€æ˜çš„æ¡¥æ¢ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨å…¬å¼€æ•°æ®é›†ä¸Šå®ç°äº†92.79%çš„å‡†ç¡®ç‡å’Œ0.961çš„æ›²çº¿ä¸‹é¢ç§¯(AUC)ï¼Œå¹¶åœ¨å¯è§£é‡Šæ€§æŒ‡æ ‡ä¸Šè¡¨ç°ä¼˜å¼‚ã€‚å®šæ€§åˆ†æè¯å®ï¼Œæ¨¡å‹å­¦ä¹ åˆ°çš„åµŒå…¥ç©ºé—´æ’åˆ—ä¸ä¸´åºŠåŒ»ç”Ÿçš„è¯Šæ–­é€»è¾‘é«˜åº¦ä¸€è‡´ï¼Œæœ‰æ•ˆå¼¥åˆäº†é«˜æ€§èƒ½åˆ†ç±»ä¸ä¸´åºŠä¿¡ä»»ä¹‹é—´çš„é¸¿æ²Ÿã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "AAAI-26-AIA",
      "pdf_url": "https://arxiv.org/pdf/2512.06105v1",
      "published_date": "2025-12-05 19:19:36 UTC",
      "updated_date": "2025-12-05 19:19:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:53:41.185224+00:00"
    },
    {
      "arxiv_id": "2512.06102v1",
      "title": "JaxWildfire: A GPU-Accelerated Wildfire Simulator for Reinforcement Learning",
      "title_zh": "JaxWildfireï¼šé¢å‘å¼ºåŒ–å­¦ä¹ çš„ GPU åŠ é€Ÿé‡ç«æ¨¡æ‹Ÿå™¨",
      "authors": [
        "Ufuk Ã‡akÄ±r",
        "Victor-Alexandru Darvariu",
        "Bruno Lacerda",
        "Nick Hawes"
      ],
      "abstract": "Artificial intelligence methods are increasingly being explored for managing wildfires and other natural hazards. In particular, reinforcement learning (RL) is a promising path towards improving outcomes in such uncertain decision-making scenarios and moving beyond reactive strategies. However, training RL agents requires many environment interactions, and the speed of existing wildfire simulators is a severely limiting factor. We introduce $\\texttt{JaxWildfire}$, a simulator underpinned by a principled probabilistic fire spread model based on cellular automata. It is implemented in JAX and enables vectorized simulations using $\\texttt{vmap}$, allowing high throughput of simulations on GPUs. We demonstrate that $\\texttt{JaxWildfire}$ achieves 6-35x speedup over existing software and enables gradient-based optimization of simulator parameters. Furthermore, we show that $\\texttt{JaxWildfire}$ can be used to train RL agents to learn wildfire suppression policies. Our work is an important step towards enabling the advancement of RL techniques for managing natural hazards.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† JaxWildfireï¼Œè¿™æ˜¯ä¸€æ¬¾ä¸“é—¨ä¸ºå¼ºåŒ–å­¦ä¹  (Reinforcement Learning) è®¾è®¡çš„ GPU åŠ é€Ÿæ—ç«æ¨¡æ‹Ÿå™¨ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ¨¡æ‹Ÿå™¨å› è¿è¡Œç¼“æ…¢è€Œé™åˆ¶æ™ºèƒ½ä½“è®­ç»ƒæ•ˆç‡çš„é—®é¢˜ã€‚JaxWildfire åŸºäºå…ƒèƒè‡ªåŠ¨æœº (cellular automata) çš„æ¦‚ç‡ç«ç¾è”“å»¶æ¨¡å‹ï¼Œå¹¶åˆ©ç”¨ JAX æ¡†æ¶åŠå…¶ vmap åŠŸèƒ½å®ç°äº†é«˜åº¦å‘é‡åŒ–çš„ä»¿çœŸï¼Œä»è€Œåœ¨ GPU ä¸Šè·å¾—æé«˜çš„æ¨¡æ‹Ÿååé‡ã€‚å®éªŒæ•°æ®è¡¨æ˜ï¼ŒJaxWildfire è¾ƒç°æœ‰è½¯ä»¶å®ç°äº† 6-35 å€çš„æ€§èƒ½æå‡ï¼Œå¹¶æ”¯æŒå¯¹æ¨¡æ‹Ÿå™¨å‚æ•°è¿›è¡ŒåŸºäºæ¢¯åº¦çš„ä¼˜åŒ– (gradient-based optimization)ã€‚è¯¥å·¥å…·æˆåŠŸåº”ç”¨äºè®­ç»ƒæ—ç«æ‰‘æ•‘ç­–ç•¥ï¼Œä¸ºæ¨åŠ¨å¼ºåŒ–å­¦ä¹ åœ¨è‡ªç„¶ç¾å®³ç®¡ç†é¢†åŸŸçš„åº”ç”¨æä¾›äº†é‡è¦æ”¯æŒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "To be presented at the NeurIPS 2025 Workshop on Machine Learning and the Physical Sciences (ML4PS)",
      "pdf_url": "https://arxiv.org/pdf/2512.06102v1",
      "published_date": "2025-12-05 19:06:07 UTC",
      "updated_date": "2025-12-05 19:06:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:53:48.391921+00:00"
    },
    {
      "arxiv_id": "2512.06097v1",
      "title": "Empathy by Design: Aligning Large Language Models for Healthcare Dialogue",
      "title_zh": "å…±æƒ…å¼è®¾è®¡ï¼šé¢å‘åŒ»ç–—å¯¹è¯çš„å¤§è¯­è¨€æ¨¡å‹å¯¹é½",
      "authors": [
        "Emre Umucu",
        "Guillermina Solis",
        "Leon Garza",
        "Emilia Rivas",
        "Beatrice Lee",
        "Anantaa Kotal",
        "Aritran Piplai"
      ],
      "abstract": "General-purpose large language models (LLMs) have demonstrated remarkable generative and reasoning capabilities but remain limited in healthcare and caregiving applications due to two key deficiencies: factual unreliability and a lack of empathetic communication. These shortcomings pose significant risks in sensitive contexts where users, particularly non-professionals and caregivers, seek medically relevant guidance or emotional reassurance. To address these challenges, we introduce a Direct Preference Optimization (DPO)-based alignment framework designed to improve factual correctness, semantic coherence, and human-centric qualities such as empathy, politeness, and simplicity in caregiver-patient dialogues. Our approach fine-tunes domain-adapted LLMs using pairwise preference data, where preferred responses reflect supportive and accessible communication styles while rejected ones represent prescriptive or overly technical tones. This direct optimization method aligns model outputs with human preferences more efficiently than traditional reinforcement-learning-based alignment. Empirical evaluations across multiple open and proprietary LLMs show that our DPO-tuned models achieve higher semantic alignment, improved factual accuracy, and stronger human-centric evaluation scores compared to baseline and commercial alternatives such as Google medical dialogue systems. These improvements demonstrate that preference-based alignment offers a scalable and transparent pathway toward developing trustworthy, empathetic, and clinically informed AI assistants for caregiver and healthcare communication. Our open-source code is available at: https://github.com/LeonG19/Empathy-by-Design",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é€šç”¨å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨åŒ»ç–—ä¿å¥é¢†åŸŸé¢ä¸´çš„äº‹å®ä¸å¯é å’Œå…±æƒ…ç¼ºå¤±é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºç›´æ¥åå¥½ä¼˜åŒ–(Direct Preference Optimization, DPO)çš„å¯¹é½æ¡†æ¶ã€‚è¯¥æ¡†æ¶åˆ©ç”¨æˆå¯¹åå¥½æ•°æ®å¯¹é¢†åŸŸé€‚é…çš„LLMsè¿›è¡Œå¾®è°ƒï¼Œæ—¨åœ¨æå‡å›å¤çš„åŒ»ç–—å‡†ç¡®æ€§ã€è¯­ä¹‰è¿è´¯æ€§ä»¥åŠå…±æƒ…(empathy)ã€ç¤¼è²Œ(politeness)å’Œç®€æ´æ€§(simplicity)ç­‰ä»¥äººä¸ºä¸­å¿ƒçš„ç‰¹æ€§ã€‚ç ”ç©¶é€šè¿‡è®©æ¨¡å‹åå‘æ”¯æŒæ€§ä¸”æ˜“äºç†è§£çš„æ²Ÿé€šé£æ ¼ï¼Œè€Œéå¼ºåˆ¶æ€§æˆ–è¿‡äºæŠ€æœ¯æ€§çš„è¯­æ°”ï¼Œå®ç°äº†æ¯”ä¼ ç»Ÿå¼ºåŒ–å­¦ä¹ æ›´é«˜æ•ˆçš„äººç±»åå¥½å¯¹é½ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œç»DPOè°ƒä¼˜çš„æ¨¡å‹åœ¨è¯­ä¹‰å¯¹é½ã€äº‹å®å‡†ç¡®æ€§å’Œäººç±»ä¸­å¿ƒè¯„åˆ†æ–¹é¢å‡æ˜¾è‘—ä¼˜äºåŸºçº¿æ¨¡å‹åŠGoogleåŒ»ç–—å¯¹è¯ç³»ç»Ÿç­‰å•†ä¸šæ–¹æ¡ˆã€‚è¯¥æˆæœè¯æ˜äº†åå¥½å¯¹é½æ˜¯å¼€å‘å€¼å¾—ä¿¡èµ–ã€å…·å¤‡ä¸´åºŠçŸ¥è¯†ä¸”å¯Œæœ‰äººæ–‡å…³æ€€çš„AIåŒ»ç–—åŠ©æ‰‹çš„å¯æ‰©å±•ä¸”é€æ˜çš„è·¯å¾„ï¼Œç›¸å…³ä»£ç å·²åœ¨GitHubå¼€æºã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.06097v1",
      "published_date": "2025-12-05 19:04:28 UTC",
      "updated_date": "2025-12-05 19:04:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:53:44.638927+00:00"
    },
    {
      "arxiv_id": "2512.05967v1",
      "title": "Enhancing Retrieval-Augmented Generation with Entity Linking for Educational Platforms",
      "title_zh": "ç»“åˆå®ä½“é“¾æ¥å¢å¼ºæ•™è‚²å¹³å°ä¸­çš„æ£€ç´¢å¢å¼ºç”Ÿæˆ",
      "authors": [
        "Francesco Granata",
        "Francesco Poggi",
        "Misael MongiovÃ¬"
      ],
      "abstract": "In the era of Large Language Models (LLMs), Retrieval-Augmented Generation (RAG) architectures are gaining significant attention for their ability to ground language generation in reliable knowledge sources. Despite their impressive effectiveness in many areas, RAG systems based solely on semantic similarity often fail to ensure factual accuracy in specialized domains, where terminological ambiguity can affect retrieval relevance. This study proposes an enhanced RAG architecture that integrates a factual signal derived from Entity Linking to improve the accuracy of educational question-answering systems in Italian. The system includes a Wikidata-based Entity Linking module and implements three re-ranking strategies to combine semantic and entity-based information: a hybrid score weighting model, reciprocal rank fusion, and a cross-encoder re-ranker. Experiments were conducted on two benchmarks: a custom academic dataset and the standard SQuAD-it dataset. Results show that, in domain-specific contexts, the hybrid schema based on reciprocal rank fusion significantly outperforms both the baseline and the cross-encoder approach, while the cross-encoder achieves the best results on the general-domain dataset. These findings confirm the presence of an effect of domain mismatch and highlight the importance of domain adaptation and hybrid ranking strategies to enhance factual precision and reliability in retrieval-augmented generation. They also demonstrate the potential of entity-aware RAG systems in educational environments, fostering adaptive and reliable AI-based tutoring tools.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Retrieval-Augmented Generation (RAG) ç³»ç»Ÿåœ¨ç‰¹å®šé¢†åŸŸä¸­ä»…ä¾é è¯­ä¹‰ç›¸ä¼¼åº¦å¸¸å› æœ¯è¯­æ­§ä¹‰å¯¼è‡´äº‹å®å‡†ç¡®æ€§ä¸‹é™çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§é€šè¿‡é›†æˆ Entity Linking æ¥å¢å¼ºäº‹å®ä¿¡å·çš„æ–°å‹æ¶æ„ï¼Œæ—¨åœ¨æå‡æ„å¤§åˆ©è¯­æ•™è‚²é—®ç­”ç³»ç»Ÿçš„ç²¾åº¦ã€‚è¯¥ç³»ç»ŸåŒ…å«ä¸€ä¸ªåŸºäº Wikidata çš„å®ä½“é“¾æ¥æ¨¡å—ï¼Œå¹¶å®ç°äº†æ··åˆè¯„åˆ†åŠ æƒã€Reciprocal Rank Fusion (RRF) å’Œ Cross-encoder ä¸‰ç§é‡æ’åºç­–ç•¥ã€‚å®éªŒåœ¨è‡ªå®šä¹‰å­¦æœ¯æ•°æ®é›†å’Œæ ‡å‡† SQuAD-it æ•°æ®é›†ä¸Šè¿›è¡Œï¼Œç»“æœè¡¨æ˜åœ¨ç‰¹å®šé¢†åŸŸä¸­ï¼ŒåŸºäº RRF çš„æ··åˆæ–¹æ¡ˆæ€§èƒ½æ˜¾è‘—ä¼˜äºåŸºçº¿å’Œ Cross-encoder æ–¹æ³•ï¼Œè€Œ Cross-encoder åœ¨é€šç”¨é¢†åŸŸè¡¨ç°æœ€ä½³ã€‚è¿™äº›å‘ç°è¯å®äº†é¢†åŸŸä¸åŒ¹é… (Domain Mismatch) å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ï¼Œå¼ºè°ƒäº†é¢†åŸŸè‡ªé€‚åº”å’Œæ··åˆæ’åºç­–ç•¥åœ¨æå‡æ£€ç´¢å¢å¼ºç”Ÿæˆå¯é æ€§æ–¹é¢çš„é‡è¦æ€§ã€‚è¯¥ç ”ç©¶å±•ç¤ºäº† Entity-aware RAG ç³»ç»Ÿåœ¨æ•™è‚²ç¯å¢ƒä¸­çš„å·¨å¤§æ½œåŠ›ï¼Œä¸ºæ„å»ºè‡ªé€‚åº”çš„äººå·¥æ™ºèƒ½è¾…å¯¼å·¥å…·å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.05967v1",
      "published_date": "2025-12-05 18:59:18 UTC",
      "updated_date": "2025-12-05 18:59:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:53:55.162703+00:00"
    },
    {
      "arxiv_id": "2512.05964v2",
      "title": "Training-Time Action Conditioning for Efficient Real-Time Chunking",
      "title_zh": "é¢å‘é«˜æ•ˆå®æ—¶åˆ†å—çš„è®­ç»ƒé˜¶æ®µåŠ¨ä½œæ¡ä»¶åŒ–",
      "authors": [
        "Kevin Black",
        "Allen Z. Ren",
        "Michael Equi",
        "Sergey Levine"
      ],
      "abstract": "Real-time chunking (RTC) enables vision-language-action models (VLAs) to generate smooth, reactive robot trajectories by asynchronously predicting action chunks and conditioning on previously committed actions via inference-time inpainting. However, this inpainting method introduces computational overhead that increases inference latency. In this work, we propose a simple alternative: simulating inference delay at training time and conditioning on action prefixes directly, eliminating any inference-time overhead. Our method requires no modifications to the model architecture or robot runtime, and can be implemented with only a few additional lines of code. In simulated experiments, we find that training-time RTC outperforms inference-time RTC at higher inference delays. In real-world experiments on box building and espresso making tasks with the $Ï€_{0.6}$ VLA, we demonstrate that training-time RTC maintains both task performance and speed parity with inference-time RTC while being computationally cheaper. Our results suggest that training-time action conditioning is a practical drop-in replacement for inference-time inpainting in real-time robot control.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è§†è§‰è¯­è¨€åŠ¨ä½œæ¨¡å‹(VLAs)åœ¨å®æ—¶åˆ†å—(Real-time chunking, RTC)è¿‡ç¨‹ä¸­ï¼Œç”±äºæ¨ç†æ—¶è¡¥å…¨(inference-time inpainting)äº§ç”Ÿçš„é¢å¤–è®¡ç®—å¼€é”€å’Œå»¶è¿Ÿé—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ç®€æ´é«˜æ•ˆçš„è®­ç»ƒæ—¶åŠ¨ä½œæ¡ä»¶åŒ–(training-time action conditioning)æ–¹æ³•ã€‚è¯¥æ–¹æ¡ˆé€šè¿‡åœ¨è®­ç»ƒé˜¶æ®µæ¨¡æ‹Ÿæ¨ç†å»¶è¿Ÿå¹¶ç›´æ¥å¯¹åŠ¨ä½œå‰ç¼€(action prefixes)è¿›è¡Œæ¡ä»¶åŒ–å¤„ç†ï¼Œå½»åº•æ¶ˆé™¤äº†æ¨ç†æ—¶çš„è®¡ç®—è´Ÿæ‹…ï¼Œä¸”æ— éœ€æ›´æ”¹æ¨¡å‹æ¶æ„æˆ–æœºå™¨äººè¿è¡Œé€»è¾‘ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨è¾ƒé«˜çš„æ¨ç†å»¶è¿Ÿç¯å¢ƒä¸‹ï¼Œè¯¥æ–¹æ³•åœ¨æ¨¡æ‹Ÿå®éªŒä¸­çš„è¡¨ç°ä¼˜äºä¼ ç»Ÿçš„æ¨ç†æ—¶RTCæ–¹æ¡ˆã€‚åœ¨çº¸ç®±æ­å»ºå’Œå’–å•¡åˆ¶ä½œç­‰çœŸå®åœºæ™¯ä»»åŠ¡ä¸­ï¼Œè¯¥æ–¹æ³•åœ¨ä¿æŒä»»åŠ¡æˆåŠŸç‡ä¸è¿è¡Œé€Ÿåº¦çš„åŒæ—¶ï¼Œæ˜¾è‘—é™ä½äº†è®¡ç®—æˆæœ¬ã€‚ç ”ç©¶ç»“æœè¯æ˜ï¼Œè¿™ç§è®­ç»ƒæ—¶æ–¹æ³•æ˜¯æœºå™¨äººå®æ—¶æ§åˆ¶ä¸­æ¨ç†æ—¶è¡¥å…¨æŠ€æœ¯çš„ç†æƒ³æ›¿ä»£æ–¹æ¡ˆï¼Œå…·æœ‰æé«˜çš„å·¥ç¨‹å®ç”¨ä»·å€¼ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.05964v2",
      "published_date": "2025-12-05 18:57:28 UTC",
      "updated_date": "2025-12-09 01:07:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:54:17.434854+00:00"
    },
    {
      "arxiv_id": "2512.06065v1",
      "title": "EgoEdit: Dataset, Real-Time Streaming Model, and Benchmark for Egocentric Video Editing",
      "title_zh": "EgoEditï¼šç¬¬ä¸€äººç§°è§†è§’è§†é¢‘ç¼–è¾‘çš„æ•°æ®é›†ã€å®æ—¶æµå¼æ¨¡å‹åŠåŸºå‡†æµ‹è¯•",
      "authors": [
        "Runjia Li",
        "Moayed Haji-Ali",
        "Ashkan Mirzaei",
        "Chaoyang Wang",
        "Arpit Sahni",
        "Ivan Skorokhodov",
        "Aliaksandr Siarohin",
        "Tomas Jakab",
        "Junlin Han",
        "Sergey Tulyakov",
        "Philip Torr",
        "Willi Menapace"
      ],
      "abstract": "We study instruction-guided editing of egocentric videos for interactive AR applications. While recent AI video editors perform well on third-person footage, egocentric views present unique challenges - including rapid egomotion and frequent hand-object interactions - that create a significant domain gap. Moreover, existing offline editing pipelines suffer from high latency, limiting real-time interaction. To address these issues, we present a complete ecosystem for egocentric video editing. First, we construct EgoEditData, a carefully designed and manually curated dataset specifically designed for egocentric editing scenarios, featuring rich hand-object interactions, while explicitly preserving hands. Second, we develop EgoEdit, an instruction-following egocentric video editor that supports real-time streaming inference on a single GPU. Finally, we introduce EgoEditBench, an evaluation suite targeting instruction faithfulness, hand and interaction preservation, and temporal stability under egomotion. Across both egocentric and general editing tasks, EgoEdit produces temporally stable, instruction-faithful results with interactive latency. It achieves clear gains on egocentric editing benchmarks-where existing methods struggle-while maintaining performance comparable to the strongest baselines on general editing tasks. EgoEditData and EgoEditBench will be made public for the research community. See our website at https://snap-research.github.io/EgoEdit",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹äº¤äº’å¼ AR åº”ç”¨ä¸­çš„ç¬¬ä¸€è§†è§’(Egocentric)è§†é¢‘ç¼–è¾‘å±•å¼€ï¼Œæ—¨åœ¨è§£å†³å¿«é€Ÿè¿åŠ¨å’Œå¤æ‚æ‰‹ç‰©äº¤äº’(Hand-Object Interactions)å¸¦æ¥çš„åŸŸåç½®åŠé«˜å»¶è¿Ÿé—®é¢˜ã€‚ä½œè€…é¦–å…ˆæ„å»ºäº† EgoEditData æ•°æ®é›†ï¼Œé€šè¿‡äººå·¥ç­›é€‰ä¸“é—¨æ”¶é›†äº†åŒ…å«ä¸°å¯Œæ‰‹éƒ¨åŠ¨ä½œä¸”æ˜¾å¼ä¿ç•™æ‰‹éƒ¨ç‰¹å¾çš„ç¬¬ä¸€è§†è§’åœºæ™¯ã€‚éšåå¼€å‘äº† EgoEdit æ¨¡å‹ï¼Œè¿™æ˜¯ä¸€ç§éµå¾ªæŒ‡ä»¤çš„å®æ—¶æµå¼(Streaming)è§†é¢‘ç¼–è¾‘å™¨ï¼Œæ”¯æŒåœ¨å•å¼  GPU ä¸Šè¿›è¡Œäº¤äº’å¼æ¨ç†ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜æ¨å‡ºäº† EgoEditBench è¯„æµ‹åŸºå‡†ï¼Œç”¨äºè¡¡é‡æŒ‡ä»¤å¿ å®åº¦ã€æ‰‹éƒ¨åŠäº¤äº’ä¿ç•™æƒ…å†µä»¥åŠåœ¨è‡ªæˆ‘è¿åŠ¨ä¸‹çš„æ—¶é—´ç¨³å®šæ€§ã€‚å®éªŒè¯æ˜ï¼ŒEgoEdit åœ¨ä¿è¯é€šç”¨è§†é¢‘ç¼–è¾‘æ€§èƒ½çš„åŒæ—¶ï¼Œæ˜¾è‘—æå‡äº†åœ¨ç¬¬ä¸€è§†è§’ä»»åŠ¡ä¸Šçš„ç¨³å®šæ€§ä¸äº¤äº’å®æ—¶æ€§ã€‚è¯¥å·¥ä½œä¸ºç ”ç©¶ç¤¾åŒºæä¾›äº†ä¸€å¥—å®Œæ•´çš„ç”Ÿæ€ç³»ç»Ÿï¼Œå…‹æœäº†ç°æœ‰ç¦»çº¿æµæ°´çº¿æ— æ³•æ»¡è¶³å®æ—¶äº¤äº’éœ€æ±‚çš„é™åˆ¶ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://snap-research.github.io/EgoEdit",
      "pdf_url": "https://arxiv.org/pdf/2512.06065v1",
      "published_date": "2025-12-05 18:57:05 UTC",
      "updated_date": "2025-12-05 18:57:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:54:31.508769+00:00"
    },
    {
      "arxiv_id": "2512.05962v1",
      "title": "Whatever Remains Must Be True: Filtering Drives Reasoning in LLMs, Shaping Diversity",
      "title_zh": "ä½™è€…å¿…çœŸï¼šè¿‡æ»¤é©±åŠ¨å¤§è¯­è¨€æ¨¡å‹æ¨ç†å¹¶å¡‘é€ å¤šæ ·æ€§",
      "authors": [
        "GermÃ¡n Kruszewski",
        "Pierre Erbacher",
        "Jos Rozen",
        "Marc Dymetman"
      ],
      "abstract": "Reinforcement Learning (RL) has become the de facto standard for tuning LLMs to solve tasks involving reasoning. However, growing evidence shows that models trained in such way often suffer from a significant loss in diversity. We argue that this arises because RL implicitly optimizes the \"mode-seeking\" or \"zero-forcing\" Reverse KL to a target distribution causing the model to concentrate mass on certain high-probability regions of the target while neglecting others. In this work, we instead begin from an explicit target distribution, obtained by filtering out incorrect answers while preserving the relative probabilities of correct ones. Starting from a pre-trained LLM, we approximate this target distribution using the $Î±$-divergence family, which unifies prior approaches and enables direct control of the precision-diversity trade-off by interpolating between mode-seeking and mass-covering divergences. On a Lean theorem-proving benchmark, our method achieves state-of-the-art performance along the coverage-precision Pareto frontier, outperforming all prior methods on the coverage axis.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¼ºåŒ–å­¦ä¹ (RL)åœ¨æå‡å¤§è¯­è¨€æ¨¡å‹(LLMs)æ¨ç†èƒ½åŠ›æ—¶å¯¼è‡´çš„ç”Ÿæˆå¤šæ ·æ€§ç¼ºå¤±é—®é¢˜ã€‚ä½œè€…æŒ‡å‡ºï¼Œè¿™ç§ç°è±¡æºäºå¼ºåŒ–å­¦ä¹ éšå¼ä¼˜åŒ–äº†å…·æœ‰â€œæ¨¡å¼å¯»æ±‚(mode-seeking)â€æˆ–â€œé›¶å¼ºåˆ¶(zero-forcing)â€ç‰¹æ€§çš„é€†å‘KLæ•£åº¦(Reverse KL)ï¼Œå¯¼è‡´æ¨¡å‹è¿‡åº¦é›†ä¸­äºé«˜æ¦‚ç‡åŒºåŸŸè€Œå¿½ç•¥äº†å…¶ä»–å¯èƒ½æ€§ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶æå‡ºäº†ä¸€ç§é€šè¿‡è¿‡æ»¤æ‰é”™è¯¯ç­”æ¡ˆå¹¶ä¿ç•™æ­£ç¡®ç­”æ¡ˆç›¸å¯¹æ¦‚ç‡æ¥æ„å»ºæ˜¾å¼ç›®æ ‡åˆ†å¸ƒçš„æ–¹æ³•ã€‚é€šè¿‡åˆ©ç”¨$\\alpha$-divergenceå®¶æ—æ¥é€¼è¿‘è¯¥ç›®æ ‡åˆ†å¸ƒï¼Œè¯¥æ–¹æ³•å…è®¸åœ¨æ¨¡å¼å¯»æ±‚ä¸â€œè´¨é‡è¦†ç›–(mass-covering)â€æ•£åº¦ä¹‹é—´è¿›è¡Œæ’å€¼ï¼Œä»è€Œç›´æ¥æ§åˆ¶ç²¾ç¡®åº¦ä¸å¤šæ ·æ€§ä¹‹é—´çš„æƒè¡¡(trade-off)ã€‚åœ¨Leanå®šç†è¯æ˜åŸºå‡†æµ‹è¯•ä¸­ï¼Œè¯¥æ–¹æ³•åœ¨è¦†ç›–ç‡-ç²¾ç¡®åº¦(coverage-precision)å¸•ç´¯æ‰˜å‰æ²¿ä¸Šè¾¾åˆ°äº†SOTAæ°´å¹³ï¼Œå°¤å…¶åœ¨è¦†ç›–ç‡æŒ‡æ ‡ä¸Šæ˜¾è‘—ä¼˜äºæ­¤å‰æ‰€æœ‰æ–¹æ³•ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.05962v1",
      "published_date": "2025-12-05 18:56:40 UTC",
      "updated_date": "2025-12-05 18:56:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:54:26.542423+00:00"
    },
    {
      "arxiv_id": "2512.05960v1",
      "title": "AQUA-Net: Adaptive Frequency Fusion and Illumination Aware Network for Underwater Image Enhancement",
      "title_zh": "AQUA-Netï¼šé¢å‘æ°´ä¸‹å›¾åƒå¢å¼ºçš„è‡ªé€‚åº”é¢‘ç‡èåˆä¸å…‰ç…§æ„ŸçŸ¥ç½‘ç»œ",
      "authors": [
        "Munsif Ali",
        "Najmul Hassan",
        "Lucia Ventura",
        "Davide Di Bari",
        "Simonepietro Canese"
      ],
      "abstract": "Underwater images often suffer from severe color distortion, low contrast, and a hazy appearance due to wavelength-dependent light absorption and scattering. Simultaneously, existing deep learning models exhibit high computational complexity, which limits their practical deployment for real-time underwater applications. To address these challenges, this paper presents a novel underwater image enhancement model, called Adaptive Frequency Fusion and Illumination Aware Network (AQUA-Net). It integrates a residual encoder decoder with dual auxiliary branches, which operate in the frequency and illumination domains. The frequency fusion encoder enriches spatial representations with frequency cues from the Fourier domain and preserves fine textures and structural details. Inspired by Retinex, the illumination-aware decoder performs adaptive exposure correction through a learned illumination map that separates reflectance from lighting effects. This joint spatial, frequency, and illumination design enables the model to restore color balance, visual contrast, and perceptual realism under diverse underwater conditions. Additionally, we present a high-resolution, real-world underwater video-derived dataset from the Mediterranean Sea, which captures challenging deep-sea conditions with realistic visual degradations to enable robust evaluation and development of deep learning models. Extensive experiments on multiple benchmark datasets show that AQUA-Net performs on par with SOTA in both qualitative and quantitative evaluations while using less number of parameters. Ablation studies further confirm that the frequency and illumination branches provide complementary contributions that improve visibility and color representation. Overall, the proposed model shows strong generalization capability and robustness, and it provides an effective solution for real-world underwater imaging applications.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†AQUA-Netï¼Œä¸€ç§æ—¨åœ¨è§£å†³æ°´ä¸‹å›¾åƒè‰²å½©å¤±çœŸã€ä½å¯¹æ¯”åº¦å’Œé«˜è®¡ç®—å¤æ‚åº¦é—®é¢˜çš„å¢å¼ºç½‘ç»œæ¨¡å‹ã€‚è¯¥æ¨¡å‹é‡‡ç”¨äº†é›†æˆé¢‘ç‡ä¸å…‰ç…§åŒè¾…åŠ©åˆ†æ”¯çš„æ®‹å·®ç¼–è§£ç ç»“æ„ï¼Œå…¶ä¸­é¢‘ç‡èåˆç¼–ç å™¨åˆ©ç”¨FourieråŸŸä¿¡æ¯å¢å¼ºç©ºé—´è¡¨ç¤ºï¼Œä»è€Œæœ‰æ•ˆä¿ç•™å›¾åƒçš„ç²¾ç»†çº¹ç†ä¸ç»“æ„ç»†èŠ‚ã€‚å…¶å…‰ç…§æ„ŸçŸ¥è§£ç å™¨å—Retinexç†è®ºå¯å‘ï¼Œé€šè¿‡å­¦ä¹ å…‰ç…§å›¾å®ç°è‡ªé€‚åº”æ›å…‰æ ¡æ­£ï¼Œèƒ½å¤Ÿåœ¨å¤šç§å¤æ‚æ°´ä¸‹ç¯å¢ƒä¸‹æ¢å¤è‰²å½©å¹³è¡¡ä¸è§†è§‰çœŸå®æ„Ÿã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜è´¡çŒ®äº†ä¸€ä¸ªæºè‡ªåœ°ä¸­æµ·çš„é«˜åˆ†è¾¨ç‡çœŸå®æ°´ä¸‹è§†é¢‘æ•°æ®é›†ï¼Œç”¨äºè¯„ä¼°æ¨¡å‹åœ¨æ·±æµ·æç«¯æ¡ä»¶ä¸‹çš„ç¨³å¥æ€§ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒAQUA-Netåœ¨ä¿æŒå‚æ•°é‡æ›´å°‘çš„æƒ…å†µä¸‹ï¼Œæ€§èƒ½è¾¾åˆ°äº†ä¸ç°æœ‰å…ˆè¿›æ¨¡å‹(SOTA)ç›¸å½“çš„æ°´å¹³ï¼Œä¸ºå®æ—¶æ°´ä¸‹æˆåƒåº”ç”¨æä¾›äº†é«˜æ•ˆä¸”æ³›åŒ–èƒ½åŠ›å¼ºçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.05960v1",
      "published_date": "2025-12-05 18:56:10 UTC",
      "updated_date": "2025-12-05 18:56:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:54:20.914573+00:00"
    },
    {
      "arxiv_id": "2512.05959v1",
      "title": "M4-RAG: A Massive-Scale Multilingual Multi-Cultural Multimodal RAG",
      "title_zh": "M4-RAGï¼šè¶…å¤§è§„æ¨¡å¤šè¯­è¨€ã€å¤šæ–‡åŒ–ã€å¤šæ¨¡æ€æ£€ç´¢å¢å¼ºç”Ÿæˆ",
      "authors": [
        "David Anugraha",
        "Patrick Amadeus Irawan",
        "Anshul Singh",
        "En-Shiun Annie Lee",
        "Genta Indra Winata"
      ],
      "abstract": "Vision-language models (VLMs) have achieved strong performance in visual question answering (VQA), yet they remain constrained by static training data. Retrieval-Augmented Generation (RAG) mitigates this limitation by enabling access to up-to-date, culturally grounded, and multilingual information; however, multilingual multimodal RAG remains largely underexplored. We introduce M4-RAG, a massive-scale benchmark covering 42 languages and 56 regional dialects and registers, comprising over 80,000 culturally diverse image-question pairs for evaluating retrieval-augmented VQA across languages and modalities. To balance realism with reproducibility, we build a controlled retrieval environment containing millions of carefully curated multilingual documents relevant to the query domains, approximating real-world retrieval conditions while ensuring consistent experimentation. Our systematic evaluation reveals that although RAG consistently benefits smaller VLMs, it fails to scale to larger models and often even degrades their performance, exposing a critical mismatch between model size and current retrieval effectiveness. M4-RAG provides a foundation for advancing next-generation RAG systems capable of reasoning seamlessly across languages, modalities, and cultural contexts.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† M4-RAGï¼Œä¸€ä¸ªå¤§è§„æ¨¡å¤šè¯­è¨€ã€å¤šæ–‡åŒ–ã€å¤šæ¨¡æ€çš„ Retrieval-Augmented Generation (RAG) åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è§£å†³è§†è§‰è¯­è¨€æ¨¡å‹ (VLMs) åœ¨å¤„ç†è·¨è¯­è¨€å’Œè·¨æ–‡åŒ–ä¿¡æ¯æ—¶é¢ä¸´çš„é™æ€è®­ç»ƒæ•°æ®é™åˆ¶ã€‚è¯¥åŸºå‡†æ¶µç›–äº† 42 ç§è¯­è¨€å’Œ 56 ç§åœ°åŒºæ–¹è¨€ï¼ŒåŒ…å«è¶…è¿‡ 80,000 ä¸ªå…·æœ‰æ–‡åŒ–å¤šæ ·æ€§çš„å›¾åƒ-é—®é¢˜å¯¹ï¼Œä¸“é—¨ç”¨äºè¯„ä¼°è·¨è¯­è¨€å’Œè·¨æ¨¡æ€çš„æ£€ç´¢å¢å¼º Visual Question Answering (VQA) æ€§èƒ½ã€‚ä¸ºäº†å¹³è¡¡çœŸå®æ€§ä¸å¯é‡å¤æ€§ï¼Œç ”ç©¶è€…æ„å»ºäº†ä¸€ä¸ªåŒ…å«æ•°ç™¾ä¸‡ç²¾å¿ƒç­–åˆ’çš„å¤šè¯­è¨€æ–‡æ¡£çš„å¯æ§æ£€ç´¢ç¯å¢ƒï¼Œä»¥æ¨¡æ‹Ÿç°å®ä¸–ç•Œçš„æ£€ç´¢æ¡ä»¶ã€‚ç³»ç»Ÿçš„è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œè™½ç„¶ RAG èƒ½å¤Ÿä¸€è‡´åœ°æƒ åŠè¾ƒå°è§„æ¨¡çš„ VLMsï¼Œä½†å®ƒåœ¨å¤§å‹æ¨¡å‹ä¸Šçš„æ‰©å±•æ€§è¾ƒå·®ï¼Œç”šè‡³å¾€å¾€ä¼šå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚è¿™ä¸€å‘ç°æ­ç¤ºäº†å½“å‰æ¨¡å‹è§„æ¨¡ä¸æ£€ç´¢æœ‰æ•ˆæ€§ä¹‹é—´å­˜åœ¨çš„å…³é”®ä¸åŒ¹é…é—®é¢˜ï¼Œä¸ºå¼€å‘èƒ½å¤Ÿè·¨è¯­è¨€ã€å¤šæ¨¡æ€å’Œå¤šæ–‡åŒ–èƒŒæ™¯è¿›è¡Œæ— ç¼æ¨ç†çš„æ–°ä¸€ä»£ RAG ç³»ç»Ÿæä¾›äº†é‡è¦åŸºç¡€ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint",
      "pdf_url": "https://arxiv.org/pdf/2512.05959v1",
      "published_date": "2025-12-05 18:55:58 UTC",
      "updated_date": "2025-12-05 18:55:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:54:28.101741+00:00"
    },
    {
      "arxiv_id": "2512.05958v1",
      "title": "MaxShapley: Towards Incentive-compatible Generative Search with Fair Context Attribution",
      "title_zh": "MaxShapleyï¼šé¢å‘å…¬å¹³å†…å®¹å½’å› çš„æ¿€åŠ±ç›¸å®¹ç”Ÿæˆå¼æœç´¢",
      "authors": [
        "Sara Patel",
        "Mingxun Zhou",
        "Giulia Fanti"
      ],
      "abstract": "Generative search engines based on large language models (LLMs) are replacing traditional search, fundamentally changing how information providers are compensated. To sustain this ecosystem, we need fair mechanisms to attribute and compensate content providers based on their contributions to generated answers. We introduce MaxShapley, an efficient algorithm for fair attribution in generative search pipelines that use retrieval-augmented generation (RAG). MaxShapley is a special case of the celebrated Shapley value; it leverages a decomposable max-sum utility function to compute attributions with linear computation in the number of documents, as opposed to the exponential cost of Shapley values. We evaluate MaxShapley on three multi-hop QA datasets (HotPotQA, MuSiQUE, MS MARCO); MaxShapley achieves comparable attribution quality to exact Shapley computation, while consuming a fraction of its tokens--for instance, it gives up to an 8x reduction in resource consumption over prior state-of-the-art methods at the same attribution accuracy.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLMs)çš„ç”Ÿæˆå¼æœç´¢å¼•æ“åœ¨å†…å®¹æä¾›å•†è¡¥å¿æœºåˆ¶ä¸Šçš„ç¼ºå¤±ï¼Œæå‡ºäº†MaxShapleyç®—æ³•ã€‚MaxShapleyæ˜¯ä¸€ç§ä¸“ä¸ºæ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)æµæ°´çº¿è®¾è®¡çš„é«˜æ•ˆå…¬å¹³å½’å› ç®—æ³•ï¼Œå±äºè‘—åçš„Shapley valueçš„ä¸€ç§ç‰¹æ®Šæƒ…å†µã€‚è¯¥æ–¹æ³•åˆ©ç”¨å¯åˆ†è§£çš„æœ€å¤§å’Œæ•ˆç”¨å‡½æ•°(decomposable max-sum utility function)ï¼Œå°†å½’å› è®¡ç®—å¤æ‚åº¦ä»ä¼ ç»Ÿæ–¹æ³•çš„æŒ‡æ•°çº§é™ä½è‡³æ–‡æ¡£æ•°é‡çš„çº¿æ€§çº§åˆ«ã€‚åœ¨HotPotQAã€MuSiQUEå’ŒMS MARCOç­‰å¤šä¸ªå¤šè·³é—®ç­”æ•°æ®é›†ä¸Šçš„è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼ŒMaxShapleyçš„å½’å› è´¨é‡ä¸ç²¾ç¡®çš„Shapleyè®¡ç®—ç›¸å½“ã€‚ç›¸æ¯”äºç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ï¼ŒMaxShapleyåœ¨ä¿æŒç›¸åŒå½’å› å‡†ç¡®åº¦çš„æƒ…å†µä¸‹ï¼Œå°†èµ„æºæ¶ˆè€—ï¼ˆå¦‚tokenæ•°é‡ï¼‰é™ä½äº†é«˜è¾¾8å€ã€‚è¯¥ç ”ç©¶ä¸ºå»ºç«‹æ¿€åŠ±ç›¸å®¹(incentive-compatible)ä¸”å¯æŒç»­çš„ç”Ÿæˆå¼æœç´¢ç”Ÿæ€ç³»ç»Ÿæä¾›äº†é‡è¦çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.05958v1",
      "published_date": "2025-12-05 18:54:21 UTC",
      "updated_date": "2025-12-05 18:54:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:54:41.512620+00:00"
    },
    {
      "arxiv_id": "2512.06062v1",
      "title": "When Privacy Isn't Synthetic: Hidden Data Leakage in Generative AI Models",
      "title_zh": "éšç§å¹¶éâ€œåˆæˆâ€ï¼šç”Ÿæˆå¼äººå·¥æ™ºèƒ½æ¨¡å‹ä¸­çš„éšæ€§æ•°æ®æ³„éœ²",
      "authors": [
        "S. M. Mustaqim",
        "Anantaa Kotal",
        "Paul H. Yi"
      ],
      "abstract": "Generative models are increasingly used to produce privacy-preserving synthetic data as a safe alternative to sharing sensitive training datasets. However, we demonstrate that such synthetic releases can still leak information about the underlying training samples through structural overlap in the data manifold. We propose a black-box membership inference attack that exploits this vulnerability without requiring access to model internals or real data. The attacker repeatedly queries the generative model to obtain large numbers of synthetic samples, performs unsupervised clustering to identify dense regions of the synthetic distribution, and then analyzes cluster medoids and neighborhoods that correspond to high-density regions in the original training data. These neighborhoods act as proxies for training samples, enabling the adversary to infer membership or reconstruct approximate records. Our experiments across healthcare, finance, and other sensitive domains show that cluster overlap between real and synthetic data leads to measurable membership leakage-even when the generator is trained with differential privacy or other noise mechanisms. The results highlight an under-explored attack surface in synthetic data generation pipelines and call for stronger privacy guarantees that account for distributional neighborhood inference rather than sample-level memorization alone, underscoring its role in privacy-preserving data publishing. Implementation and evaluation code are publicly available at:github.com/Cluster-Medoid-Leakage-Attack.",
      "tldr_zh": "æœ¬ç ”ç©¶æ¢è®¨äº†ç”Ÿæˆå¼ AI æ¨¡å‹åœ¨å‘å¸ƒåˆæˆæ•°æ®(Synthetic Data)æ—¶å­˜åœ¨çš„éšè—æ³„éœ²é£é™©ï¼ŒæŒ‡å‡ºåˆæˆæ•°æ®ä»å¯èƒ½é€šè¿‡æ•°æ®æµå½¢(Data Manifold)çš„ç»“æ„é‡å æ³„éœ²è®­ç»ƒæ ·æœ¬ä¿¡æ¯ã€‚ä½œè€…æå‡ºäº†ä¸€ç§é»‘ç›’æˆå‘˜æ¨ç†æ”»å‡»(Membership Inference Attack)æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åœ¨æ— éœ€è®¿é—®æ¨¡å‹å†…éƒ¨æˆ–çœŸå®æ•°æ®çš„æƒ…å†µä¸‹ï¼Œé€šè¿‡å¯¹å¤§é‡åˆæˆæ ·æœ¬è¿›è¡Œæ— ç›‘ç£èšç±»(Unsupervised Clustering)æ¥è¯†åˆ«é«˜å¯†åº¦åˆ†å¸ƒåŒºåŸŸã€‚ç ”ç©¶åˆ©ç”¨èšç±»ä¸­å¿ƒç‚¹(Medoids)åŠå…¶é‚»åŸŸä½œä¸ºè®­ç»ƒæ ·æœ¬çš„ä»£ç†ï¼ŒæˆåŠŸæ¨æ–­äº†æ•°æ®æˆå‘˜èº«ä»½æˆ–é‡å»ºäº†è¿‘ä¼¼è®°å½•ã€‚åœ¨åŒ»ç–—å’Œé‡‘èç­‰é¢†åŸŸçš„å®éªŒè¡¨æ˜ï¼Œå³ä½¿æ¨¡å‹é‡‡ç”¨äº†å·®åˆ†éšç§(Differential Privacy)ç­‰å™ªå£°æœºåˆ¶ï¼Œè¿™ç§èšç±»é‡å ä¾ç„¶ä¼šå¯¼è‡´æ˜¾è‘—çš„æ³„éœ²ã€‚è¯¥å‘ç°æ­ç¤ºäº†åˆæˆæ•°æ®ç”Ÿæˆç®¡é“ä¸­ä¸€ä¸ªå°šæœªè¢«å……åˆ†é‡è§†çš„æ”»å‡»é¢ï¼Œå¹¶å‘¼åå»ºç«‹èƒ½å¤Ÿåº”å¯¹åˆ†å¸ƒé‚»åŸŸæ¨ç†(Distributional Neighborhood Inference)çš„æ›´å¼ºéšç§ä¿éšœï¼Œè€Œä¸ä»…ä»…å±€é™äºé˜²æ­¢æ ·æœ¬çº§çš„è®°å¿†æ•ˆåº”ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.06062v1",
      "published_date": "2025-12-05 18:52:35 UTC",
      "updated_date": "2025-12-05 18:52:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:55:34.756203+00:00"
    },
    {
      "arxiv_id": "2512.05954v1",
      "title": "SymPyBench: A Dynamic Benchmark for Scientific Reasoning with Executable Python Code",
      "title_zh": "SymPyBenchï¼šåŸºäºå¯æ‰§è¡Œ Python ä»£ç çš„ç§‘å­¦æ¨ç†åŠ¨æ€åŸºå‡†",
      "authors": [
        "Shima Imani",
        "Seungwhan Moon",
        "Adel Ahmadyan",
        "Lu Zhang",
        "Kirmani Ahmed",
        "Babak Damavandi"
      ],
      "abstract": "We introduce, a large-scale synthetic benchmark of 15,045 university-level physics problems (90/10% train/test split). Each problem is fully parameterized, supporting an effectively infinite range of input configurations, and is accompanied by structured, step-by-step reasoning and executable Python code that produces the ground-truth solution for any parameter set. The benchmark contains three question types: MC-Symbolic (multiple-choice with symbolic options), MC-Numerical (multiple-choice with numerical options), and free-form (open-ended responses). These diverse formats test complementary reasoning skills. By leveraging the dynamic, code-driven nature of the benchmark, we introduce three novel evaluation metrics in addition to standard accuracy: Consistency Score, Failure Rate, and Confusion Rate, that quantify variability and uncertainty across problem variants. Experiments with state-of-the-art instruction-tuned language models reveal both strengths and limitations in scientific reasoning, positioning SymPyBench as a foundation for developing more robust and interpretable reasoning systems",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† SymPyBenchï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å« 15,045 ä¸ªå¤§å­¦æ°´å¹³ç‰©ç†é—®é¢˜çš„å¤§è§„æ¨¡åˆæˆåŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è¯„ä¼°æ¨¡å‹çš„ç§‘å­¦æ¨ç†èƒ½åŠ›ã€‚æ¯ä¸ªé—®é¢˜éƒ½ç»è¿‡å®Œå…¨å‚æ•°åŒ– (fully parameterized)ï¼Œæ”¯æŒæ— é™èŒƒå›´çš„è¾“å…¥é…ç½®ï¼Œå¹¶é…æœ‰ç»“æ„åŒ–çš„åˆ†æ­¥æ¨ç†ä»¥åŠå¯ç”Ÿæˆæ ‡å‡†ç­”æ¡ˆçš„å¯æ‰§è¡Œ Python ä»£ç ã€‚è¯¥åŸºå‡†åŒ…å« MC-Symbolicã€MC-Numerical å’Œ free-form ä¸‰ç§é¢˜å‹ï¼Œæ—¨åœ¨å…¨é¢æµ‹è¯•æ¨¡å‹äº’è¡¥çš„æ¨ç†æŠ€èƒ½ã€‚åˆ©ç”¨å…¶åŠ¨æ€çš„ä»£ç é©±åŠ¨ç‰¹æ€§ï¼Œç ”ç©¶è€…å¼•å…¥äº† Consistency Scoreã€Failure Rate å’Œ Confusion Rate ç­‰æ–°å‹è¯„ä¼°æŒ‡æ ‡ï¼Œç”¨ä»¥é‡åŒ–æ¨¡å‹åœ¨ä¸åŒé—®é¢˜å˜ä½“ä¸‹çš„å˜å¼‚æ€§å’Œä¸ç¡®å®šæ€§ã€‚å®éªŒç»“æœæ­ç¤ºäº†å½“å‰æœ€å…ˆè¿›æŒ‡ä»¤å¾®è°ƒè¯­è¨€æ¨¡å‹åœ¨ç§‘å­¦æ¨ç†æ–¹é¢çš„ä¼˜åŠ¿ä¸å±€é™ï¼Œä½¿ SymPyBench æˆä¸ºå¼€å‘æ›´ç¨³å¥ã€å¯è§£é‡Šæ¨ç†ç³»ç»Ÿçš„é‡è¦åŸºç¡€ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.05954v1",
      "published_date": "2025-12-05 18:50:48 UTC",
      "updated_date": "2025-12-05 18:50:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:54:44.307864+00:00"
    },
    {
      "arxiv_id": "2512.05951v2",
      "title": "Trusted AI Agents in the Cloud",
      "title_zh": "äº‘ç«¯å¯ä¿¡ AI æ™ºèƒ½ä½“",
      "authors": [
        "Teofil Bodea",
        "Masanori Misono",
        "Julian Pritzi",
        "Patrick Sabanic",
        "Thore Sommer",
        "Harshavardhan Unnibhavi",
        "David Schall",
        "Nuno Santos",
        "Dimitrios Stavrakakis",
        "Pramod Bhatotia"
      ],
      "abstract": "AI agents powered by large language models are increasingly deployed as cloud services that autonomously access sensitive data, invoke external tools, and interact with other agents. However, these agents run within a complex multi-party ecosystem, where untrusted components can lead to data leakage, tampering, or unintended behavior. Existing Confidential Virtual Machines (CVMs) provide only per binary protection and offer no guarantees for cross-principal trust, accelerator-level isolation, or supervised agent behavior. We present Omega, a system that enables trusted AI agents by enforcing end-to-end isolation, establishing verifiable trust across all contributing principals, and supervising every external interaction with accountable provenance. Omega builds on Confidential VMs and Confidential GPUs to create a Trusted Agent Platform that hosts many agents within a single CVM using nested isolation. It also provides efficient multi-agent orchestration with cross-principal trust establishment via differential attestation, and a policy specification and enforcement framework that governs data access, tool usage, and inter-agent communication for data protection and regulatory compliance. Implemented on AMD SEV-SNP and NVIDIA H100, Omega fully secures agent state across CVM-GPU, and achieves high performance while enabling high-density, policy-compliant multi-agent deployments at cloud scale.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Omegaï¼Œä¸€ä¸ªæ—¨åœ¨ä¸ºäº‘ç«¯ AI ä»£ç†æä¾›ç«¯åˆ°ç«¯éš”ç¦»ã€å¯éªŒè¯ä¿¡ä»»å’Œå¤–éƒ¨äº¤äº’ç›‘ç£çš„ç³»ç»Ÿã€‚é’ˆå¯¹ç°æœ‰ Confidential Virtual Machines (CVMs) åœ¨è·¨ä¸»ä½“ä¿¡ä»»ã€åŠ é€Ÿå™¨éš”ç¦»åŠä»£ç†è¡Œä¸ºç›‘ç£æ–¹é¢çš„ä¸è¶³ï¼ŒOmega åˆ©ç”¨æœºå¯†è™šæ‹Ÿæœºå’Œæœºå¯† GPU (Confidential GPUs) æ„å»ºäº† Trusted Agent Platformï¼Œæ”¯æŒåœ¨å•ä¸ª CVM å†…é€šè¿‡åµŒå¥—éš”ç¦»æ‰˜ç®¡å¤šä¸ªä»£ç†ã€‚è¯¥ç³»ç»Ÿé€šè¿‡å·®å¼‚åŒ–è¯æ˜ (differential attestation) å»ºç«‹è·¨ä¸»ä½“ä¿¡ä»»ï¼Œå¹¶ç»“åˆç­–ç•¥è§„èŒƒä¸æ‰§è¡Œæ¡†æ¶ï¼Œä¸¥æ ¼ç®¡æ§æ•°æ®è®¿é—®ã€å·¥å…·è°ƒç”¨åŠä»£ç†é—´é€šä¿¡ä»¥ç¡®ä¿æ•°æ®ä¿æŠ¤ä¸åˆè§„æ€§ã€‚åœ¨ AMD SEV-SNP å’Œ NVIDIA H100 ä¸Šçš„å®ç°è¡¨æ˜ï¼ŒOmega èƒ½å¤Ÿå®Œå…¨ä¿æŠ¤ CVM-GPU é—´çš„ä»£ç†çŠ¶æ€ã€‚å®éªŒç»“æœè¯æ˜è¯¥ç³»ç»Ÿåœ¨å®ç°é«˜å¯†åº¦ã€ç¬¦åˆç­–ç•¥çš„å¤šä»£ç†äº‘ç«¯éƒ¨ç½²æ—¶ï¼Œä¾ç„¶ä¿æŒäº†æé«˜çš„è¿è¡Œæ€§èƒ½ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.05951v2",
      "published_date": "2025-12-05 18:48:53 UTC",
      "updated_date": "2025-12-13 15:17:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:54:49.392609+00:00"
    },
    {
      "arxiv_id": "2512.05950v1",
      "title": "Impugan: Learning Conditional Generative Models for Robust Data Imputation",
      "title_zh": "Impuganï¼šé¢å‘é²æ£’æ•°æ®æ’è¡¥çš„æ¡ä»¶ç”Ÿæˆæ¨¡å‹å­¦ä¹ ",
      "authors": [
        "Zalish Mahmud",
        "Anantaa Kotal",
        "Aritran Piplai"
      ],
      "abstract": "Incomplete data are common in real-world applications. Sensors fail, records are inconsistent, and datasets collected from different sources often differ in scale, sampling rate, and quality. These differences create missing values that make it difficult to combine data and build reliable models. Standard imputation methods such as regression models, expectation-maximization, and multiple imputation rely on strong assumptions about linearity and independence. These assumptions rarely hold for complex or heterogeneous data, which can lead to biased or over-smoothed estimates. We propose Impugan, a conditional Generative Adversarial Network (cGAN) for imputing missing values and integrating heterogeneous datasets. The model is trained on complete samples to learn how missing variables depend on observed ones. During inference, the generator reconstructs missing entries from available features, and the discriminator enforces realism by distinguishing true from imputed data. This adversarial process allows Impugan to capture nonlinear and multimodal relationships that conventional methods cannot represent. In experiments on benchmark datasets and a multi-source integration task, Impugan achieves up to 82\\% lower Earth Mover's Distance (EMD) and 70\\% lower mutual-information deviation (MI) compared to leading baselines. These results show that adversarially trained generative models provide a scalable and principled approach for imputing and merging incomplete, heterogeneous data. Our model is available at: github.com/zalishmahmud/impuganBigData2025",
      "tldr_zh": "é’ˆå¯¹ç°å®åº”ç”¨ä¸­ç”±äºä¼ æ„Ÿå™¨æ•…éšœæˆ–è®°å½•ä¸ä¸€è‡´å¯¼è‡´çš„ç¼ºå¤±æ•°æ®é—®é¢˜ï¼Œä¼ ç»Ÿæ’è¡¥æ–¹æ³•å¦‚å›å½’æ¨¡å‹å’Œ EM ç®—æ³•å› å…¶å¼ºçƒˆçš„çº¿æ€§ä¸ç‹¬ç«‹æ€§å‡è®¾ï¼Œåœ¨å¤„ç†å¤æ‚æˆ–å¼‚æ„æ•°æ®æ—¶å¾€å¾€ä¼šäº§ç”Ÿåå·®ã€‚æœ¬ç ”ç©¶æå‡ºäº† Impuganï¼Œä¸€ç§åŸºäºæ¡ä»¶ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ (cGAN) çš„ç¼ºå¤±å€¼æ’è¡¥ä¸å¼‚æ„æ•°æ®é›†æ•´åˆæ¨¡å‹ã€‚è¯¥æ¨¡å‹é€šè¿‡åœ¨å®Œæ•´æ ·æœ¬ä¸Šå­¦ä¹ ç¼ºå¤±å˜é‡å¯¹è§‚æµ‹å˜é‡çš„ä¾èµ–å…³ç³»ï¼Œåˆ©ç”¨ç”Ÿæˆå™¨é‡å»ºç¼ºå¤±é¡¹å¹¶è¾…ä»¥åˆ¤åˆ«å™¨å¼ºåˆ¶æ‰§è¡ŒçœŸå®æ€§çº¦æŸã€‚è¿™ç§å¯¹æŠ—æ€§è®­ç»ƒè¿‡ç¨‹ä½¿ Impugan èƒ½å¤Ÿæ•æ‰ä¼ ç»Ÿæ–¹æ³•éš¾ä»¥è¡¨å¾çš„éçº¿æ€§å’Œå¤šæ¨¡æ€å…³ç³»ã€‚åœ¨åŸºå‡†æ•°æ®é›†å’Œå¤šæºæ•´åˆä»»åŠ¡çš„å®éªŒä¸­ï¼ŒImpugan ç›¸æ¯”é¢†å…ˆçš„åŸºçº¿æ¨¡å‹åœ¨ Earth Mover's Distance (EMD) ä¸Šé™ä½äº†é«˜è¾¾ 82%ï¼Œåœ¨äº’ä¿¡æ¯åå·® (MI) ä¸Šé™ä½äº† 70%ã€‚ç ”ç©¶ç»“æœè¯æ˜ï¼Œå¯¹æŠ—è®­ç»ƒçš„ç”Ÿæˆæ¨¡å‹ä¸ºå¤„ç†å’Œåˆå¹¶ç¼ºå¤±ã€å¼‚æ„æ•°æ®æä¾›äº†ä¸€ç§å¯æ‰©å±•ä¸”å…·æœ‰åŸåˆ™æ€§çš„æœ‰æ•ˆæ–¹æ³•ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.05950v1",
      "published_date": "2025-12-05 18:46:33 UTC",
      "updated_date": "2025-12-05 18:46:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:54:45.964449+00:00"
    },
    {
      "arxiv_id": "2512.05946v1",
      "title": "Variational Quantum Rainbow Deep Q-Network for Optimizing Resource Allocation Problem",
      "title_zh": "ä¼˜åŒ–èµ„æºåˆ†é…é—®é¢˜çš„å˜åˆ†é‡å­ Rainbow æ·±åº¦ Q ç½‘ç»œ",
      "authors": [
        "Truong Thanh Hung Nguyen",
        "Truong Thinh Nguyen",
        "Hung Cao"
      ],
      "abstract": "Resource allocation remains NP-hard due to combinatorial complexity. While deep reinforcement learning (DRL) methods, such as the Rainbow Deep Q-Network (DQN), improve scalability through prioritized replay and distributional heads, classical function approximators limit their representational power. We introduce Variational Quantum Rainbow DQN (VQR-DQN), which integrates ring-topology variational quantum circuits with Rainbow DQN to leverage quantum superposition and entanglement. We frame the human resource allocation problem (HRAP) as a Markov decision process (MDP) with combinatorial action spaces based on officer capabilities, event schedules, and transition times. On four HRAP benchmarks, VQR-DQN achieves 26.8% normalized makespan reduction versus random baselines and outperforms Double DQN and classical Rainbow DQN by 4.9-13.4%. These gains align with theoretical connections between circuit expressibility, entanglement, and policy quality, demonstrating the potential of quantum-enhanced DRL for large-scale resource allocation. Our implementation is available at: https://github.com/Analytics-Everywhere-Lab/qtrl/.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹èµ„æºåˆ†é…é—®é¢˜ä¸­å› ç»„åˆå¤æ‚æ€§å¯¼è‡´çš„NP-hardéš¾é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºVariational Quantum Rainbow DQN (VQR-DQN) çš„å˜åˆ†é‡å­å¼ºåŒ–å­¦ä¹ æ¨¡å‹ã€‚è¯¥æ¨¡å‹å°†å…·æœ‰ç¯çŠ¶æ‹“æ‰‘(ring-topology)çš„å˜åˆ†é‡å­ç”µè·¯ä¸ Rainbow Deep Q-Network (DQN) ç›¸ç»“åˆï¼Œæ—¨åœ¨åˆ©ç”¨é‡å­çš„å åŠ å’Œçº ç¼ ç‰¹æ€§æ¥æå‡ä¼ ç»Ÿå‡½æ•°é€¼è¿‘å™¨çš„è¡¨è¾¾èƒ½åŠ›ã€‚ç ”ç©¶è€…å°†äººåŠ›èµ„æºåˆ†é…é—®é¢˜ (HRAP) å»ºæ¨¡ä¸ºå…·æœ‰ç»„åˆåŠ¨ä½œç©ºé—´çš„é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ (MDP)ï¼Œç»¼åˆè€ƒè™‘äº†äººå‘˜èƒ½åŠ›ã€æ´»åŠ¨æ—¶é—´è¡¨å’Œè¿‡æ¸¡æ—¶é—´ã€‚åœ¨å››ä¸ª HRAP åŸºå‡†æµ‹è¯•ä¸­ï¼ŒVQR-DQN ç›¸æ¯”éšæœºåŸºå‡†å®ç°äº† 26.8% çš„æ ‡å‡†åŒ–å®Œå·¥æ—¶é—´ (makespan) ç¼©å‡ï¼Œå¹¶æ˜¾è‘—ä¼˜äº Double DQN å’Œä¼ ç»Ÿçš„ Rainbow DQN æ¨¡å‹ã€‚å®éªŒç»“æœè¿›ä¸€æ­¥è¯å®äº†ç”µè·¯è¡¨è¾¾åŠ›ã€çº ç¼ åº¦ä¸ç­–ç•¥è´¨é‡ä¹‹é—´çš„ç†è®ºå…³è”ï¼Œå±•ç¤ºäº†é‡å­å¢å¼ºçš„æ·±åº¦å¼ºåŒ–å­¦ä¹  (DRL) åœ¨å¤§è§„æ¨¡èµ„æºåˆ†é…åœºæ™¯ä¸­çš„åº”ç”¨æ½œåŠ›ã€‚",
      "categories": [
        "cs.AI",
        "cs.ET",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "Quantum Software Engineering Practices at The 41st ACM/SIGAPP Symposium On Applied Computing (SAC 2026)",
      "pdf_url": "https://arxiv.org/pdf/2512.05946v1",
      "published_date": "2025-12-05 18:43:18 UTC",
      "updated_date": "2025-12-05 18:43:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:55:57.343806+00:00"
    },
    {
      "arxiv_id": "2512.05943v3",
      "title": "TRACE: A Framework for Analyzing and Enhancing Stepwise Reasoning in Vision-Language Models",
      "title_zh": "TRACEï¼šé¢å‘è§†è§‰è¯­è¨€æ¨¡å‹åˆ†æ­¥æ¨ç†çš„åˆ†æä¸å¢å¼ºæ¡†æ¶",
      "authors": [
        "Shima Imani",
        "Seungwhan Moon",
        "Lambert Mathias",
        "Lu Zhang",
        "Babak Damavandi"
      ],
      "abstract": "Reliable mathematical and scientific reasoning remains an open challenge for large vision-language models. Standard final-answer evaluation often masks reasoning errors, allowing silent failures to persist. To address this gap, we introduce TRACE, a framework for Transparent Reasoning And Consistency Evaluation that diagnoses reasoning trajectories rather than only end results. At its core, TRACE leverages Auxiliary Reasoning Sets, compact sub question answer pairs that decompose complex problems, evaluate intermediate steps through consistency-based metrics, and expose failures overlooked by standard evaluation. Our experiments show that consistency across ARS correlates with final-answer correctness and helps pinpoint the reasoning steps where failures arise, offering actionable signals for model improvement. Furthermore, TRACE defines confidence regions that distinguish reliable from unreliable reasoning paths, supporting effective filtering, debugging, and model refinement.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† TRACEï¼Œä¸€ä¸ªç”¨äº Vision-Language Models (VLMs) é€æ­¥æ¨ç†åˆ†æä¸å¢å¼ºçš„æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³è¿™äº›æ¨¡å‹åœ¨å¤„ç†æ•°å­¦å’Œç§‘å­¦æ¨ç†ä»»åŠ¡æ—¶å¯é æ€§ä¸è¶³çš„é—®é¢˜ã€‚é’ˆå¯¹æ ‡å‡†è¯„ä¼°ä»…å…³æ³¨æœ€ç»ˆç­”æ¡ˆè€Œæ©ç›–æ¨ç†è¿‡ç¨‹é”™è¯¯çš„å±€é™æ€§ï¼ŒTRACE é€šè¿‡è¯Šæ–­æ¨ç†è·¯å¾„è€Œéä»…ä»…è¯„ä¼°ç»“æœæ¥æé«˜é€æ˜åº¦ã€‚æ¡†æ¶çš„æ ¸å¿ƒæ˜¯å¼•å…¥äº† Auxiliary Reasoning Sets (ARS)ï¼Œå³é€šè¿‡åˆ†è§£å¤æ‚é—®é¢˜ç”Ÿæˆçš„ç´§å‡‘å­é—®é¢˜å¯¹ï¼Œåˆ©ç”¨åŸºäºä¸€è‡´æ€§çš„åº¦é‡æ ‡å‡† (consistency-based metrics) æ¥è¯„ä¼°ä¸­é—´æ­¥éª¤å¹¶æš´éœ²è¢«æ ‡å‡†è¯„ä¼°å¿½ç•¥çš„é”™è¯¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒARS çš„ä¸€è‡´æ€§ä¸æœ€ç»ˆç­”æ¡ˆçš„å‡†ç¡®æ€§é«˜åº¦ç›¸å…³ï¼Œèƒ½å¤Ÿç²¾å‡†å®šä½æ¨ç†å¤±è´¥å‘ç”Ÿçš„å…·ä½“æ­¥éª¤ï¼Œä¸ºæ¨¡å‹æ”¹è¿›æä¾›äº†å¯æ“ä½œçš„ä¿¡å·ã€‚æ­¤å¤–ï¼ŒTRACE å®šä¹‰äº†ç½®ä¿¡åŒºé—´ (confidence regions) ä»¥åŒºåˆ†å¯é ä¸ä¸å¯é çš„æ¨ç†è·¯å¾„ï¼Œæ”¯æŒæ›´æœ‰æ•ˆçš„æ¨¡å‹è¿‡æ»¤ã€è°ƒè¯•ä¸ç²¾ç‚¼ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.05943v3",
      "published_date": "2025-12-05 18:40:18 UTC",
      "updated_date": "2025-12-11 19:26:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:56:06.131165+00:00"
    },
    {
      "arxiv_id": "2512.05941v1",
      "title": "Zoom in, Click out: Unlocking and Evaluating the Potential of Zooming for GUI Grounding",
      "title_zh": "Zoom in, Click outï¼šè§£é”ä¸è¯„ä¼° GUI å®šä½ä¸­ç¼©æ”¾æœºåˆ¶çš„æ½œåŠ›",
      "authors": [
        "Zhiyuan Jiang",
        "Shenghao Xie",
        "Wenyi Li",
        "Wenqiang Zu",
        "Peihang Li",
        "Jiahao Qiu",
        "Siqi Pei",
        "Lei Ma",
        "Tiejun Huang",
        "Mengdi Wang",
        "Shilong Liu"
      ],
      "abstract": "Grounding is a fundamental capability for building graphical user interface (GUI) agents. Although existing approaches rely on large-scale bounding box supervision, they still face various challenges, such as cross-platform generalization, complex layout analysis, and fine-grained element localization. In this paper, we investigate zoom as a strong yet underexplored prior for GUI grounding, and propose a training-free method, ZoomClick. By characterizing four key properties of zoom (i.e., pre-zoom, depth, shrink size, minimal crop size), we unlock its full capabilities for dynamic spatial focusing and adaptive context switching. Experiments demonstrate that our method significantly boosts the performance of both general vision-language and specialized GUI grounding models, achieving state-of-the-art results on several mainstream benchmarks; for example, UI-Venus-72B attains a 73.1% success rate on ScreenSpot-Pro. Furthermore, we present GUIZoom-Bench, a benchmark for evaluating model adaptability to zoom, aiming to inspire future research on improving zoom for further training and test-time scaling in GUI grounding tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç¼©æ”¾(Zooming)ä½œä¸ºGUI Groundingä»»åŠ¡ä¸­ä¸€ç§å¼ºåŠ›ä½†æœªè¢«å……åˆ†åˆ©ç”¨çš„å…ˆéªŒçŸ¥è¯†ï¼Œå¹¶æå‡ºäº†åä¸ºZoomClickçš„å…è®­ç»ƒ(training-free)æ–¹æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡å®šä¹‰é¢„ç¼©æ”¾(pre-zoom)ã€æ·±åº¦(depth)ã€ç¼©å°æ¯”ä¾‹(shrink size)å’Œæœ€å°è£å‰ªå°ºå¯¸(minimal crop size)å››ä¸ªå…³é”®å±æ€§ï¼Œé‡Šæ”¾äº†åŠ¨æ€ç©ºé—´èšç„¦å’Œè‡ªé€‚åº”ä¸Šä¸‹æ–‡åˆ‡æ¢çš„æ½œåŠ›ï¼Œæœ‰æ•ˆè§£å†³äº†è·¨å¹³å°æ³›åŒ–å’Œç»†ç²’åº¦å…ƒç´ å®šä½ç­‰æŒ‘æˆ˜ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒZoomClickæ˜¾è‘—æå‡äº†é€šç”¨è§†è§‰è¯­è¨€æ¨¡å‹(VLMs)å’Œä¸“ä¸šGUI Groundingæ¨¡å‹çš„æ€§èƒ½ï¼Œåœ¨ScreenSpot-Proç­‰å¤šä¸ªä¸»æµåŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº†SOTAæ°´å¹³ï¼Œä¾‹å¦‚UI-Venus-72Bå®ç°äº†73.1%çš„æˆåŠŸç‡ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜æ¨å‡ºäº†GUIZoom-Benchè¯„æµ‹åŸºå‡†ï¼Œæ—¨åœ¨è¯„ä¼°æ¨¡å‹å¯¹ç¼©æ”¾çš„é€‚åº”èƒ½åŠ›ï¼Œå¹¶ä¸ºæœªæ¥åœ¨GUI Groundingä»»åŠ¡ä¸­åˆ©ç”¨ç¼©æ”¾è¿›è¡Œè®­ç»ƒå’Œæµ‹è¯•æ—¶ç¼©æ”¾(test-time scaling)çš„ç ”ç©¶æä¾›äº†å¯å‘ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Code is available at https://github.com/Princeton-AI2-Lab/ZoomClick",
      "pdf_url": "https://arxiv.org/pdf/2512.05941v1",
      "published_date": "2025-12-05 18:39:12 UTC",
      "updated_date": "2025-12-05 18:39:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:56:24.588398+00:00"
    },
    {
      "arxiv_id": "2512.14704v1",
      "title": "Tourists Profiling by Interest Analysis",
      "title_zh": "åŸºäºå…´è¶£åˆ†æçš„æ¸¸å®¢ç”»åƒ",
      "authors": [
        "Sonia Djebali",
        "Quentin Gabot",
        "Guillaume Guerard"
      ],
      "abstract": "With the recent digital revolution, analyzing of tourists' behaviors and research fields associated with it have changed profoundly. It is now easier to examine behaviors of tourists using digital traces they leave during their travels. The studies conducted on diverse aspects of tourism focus on quantitative aspects of digital traces to reach its conclusions. In this paper, we suggest a study focused on both qualitative and quantitative aspect of digital traces to understand the dynamics governing tourist behavior, especially those concerning attractions networks.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨æ•°å­—åŒ–é©å‘½èƒŒæ™¯ä¸‹é€šè¿‡æ•°å­—è¶³è¿¹(digital traces)åˆ†ææ¸¸å®¢è¡Œä¸ºçš„æ–°æ–¹æ³•ã€‚ä¼ ç»Ÿçš„æ—…æ¸¸ç ”ç©¶å¾€å¾€ä¾§é‡äºæ•°å­—è¶³è¿¹çš„å®šé‡(quantitative)åˆ†æï¼Œè€Œæœ¬æ–‡æå‡ºäº†ä¸€ç§ç»“åˆå®šæ€§(qualitative)ä¸å®šé‡ç»´åº¦çš„ç»¼åˆç ”ç©¶æ¡†æ¶ã€‚é€šè¿‡æ·±å…¥æŒ–æ˜æ¸¸å®¢åœ¨æ—…é€”ä¸­ç•™ä¸‹çš„æ•°æ®ï¼Œè¯¥ç ”ç©¶æ—¨åœ¨æ­ç¤ºé©±åŠ¨æ¸¸å®¢è¡Œä¸ºçš„åŠ¨åŠ›å­¦æœºåˆ¶ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹æ™¯ç‚¹ç½‘ç»œ(attractions networks)çš„æ¼”åŒ–ã€‚è¿™ç§å¤šç»´åº¦çš„åˆ†ææ–¹æ³•æœ‰åŠ©äºæ›´ç²¾å‡†åœ°è¿›è¡Œæ¸¸å®¢ç”»åƒ(tourists profiling)ï¼Œä»è€Œä¸ºæ—…æ¸¸ç®¡ç†å’Œè¥é”€æä¾›æ›´å…·æ·±åº¦çš„è§è§£ã€‚è¯¥æ–¹æ³•æœ‰æ•ˆå¼¥è¡¥äº†å•ä¸€æ•°æ®åˆ†æçš„å±€é™æ€§ï¼Œä¸ºç†è§£å¤æ‚çš„æ—…æ¸¸è¡Œä¸ºåŠ¨æ€æä¾›äº†æ–°çš„è§†è§’ã€‚",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.14704v1",
      "published_date": "2025-12-05 18:35:49 UTC",
      "updated_date": "2025-12-05 18:35:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:56:14.598687+00:00"
    },
    {
      "arxiv_id": "2512.05937v1",
      "title": "Measuring the Effect of Background on Classification and Feature Importance in Deep Learning for AV Perception",
      "title_zh": "è¡¡é‡è‡ªåŠ¨é©¾é©¶æ„ŸçŸ¥æ·±åº¦å­¦ä¹ ä¸­èƒŒæ™¯å¯¹åˆ†ç±»ä¸ç‰¹å¾é‡è¦æ€§çš„å½±å“",
      "authors": [
        "Anne Sielemann",
        "Valentin Barner",
        "Stefan Wolf",
        "Masoud Roschani",
        "Jens Ziehn",
        "Juergen Beyerer"
      ],
      "abstract": "Common approaches to explainable AI (XAI) for deep learning focus on analyzing the importance of input features on the classification task in a given model: saliency methods like SHAP and GradCAM are used to measure the impact of spatial regions of the input image on the classification result. Combined with ground truth information about the location of the object in the input image (e.g., a binary mask), it is determined whether object pixels had a high impact on the classification result, or whether the classification focused on background pixels. The former is considered to be a sign of a healthy classifier, whereas the latter is assumed to suggest overfitting on spurious correlations. A major challenge, however, is that these intuitive interpretations are difficult to test quantitatively, and hence the output of such explanations lacks an explanation itself. One particular reason is that correlations in real-world data are difficult to avoid, and whether they are spurious or legitimate is debatable. Synthetic data in turn can facilitate to actively enable or disable correlations where desired but often lack a sufficient quantification of realism and stochastic properties. [...] Therefore, we systematically generate six synthetic datasets for the task of traffic sign recognition, which differ only in their degree of camera variation and background correlation [...] to quantify the isolated influence of background correlation, different levels of camera variation, and considered traffic sign shapes on the classification performance, as well as background feature importance. [...] Results include a quantification of when and how much background features gain importance to support the classification task based on changes in the training domain [...].\n  Download: synset.de/datasets/synset-signset-ger/background-effect",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æ·±åº¦å­¦ä¹ åœ¨è‡ªåŠ¨é©¾é©¶æ„ŸçŸ¥ä¸­èƒŒæ™¯ä¿¡æ¯å¯¹åˆ†ç±»æ€§èƒ½å’Œç‰¹å¾é‡è¦æ€§çš„å½±å“ï¼Œæ—¨åœ¨è§£å†³å¯è§£é‡Šäººå·¥æ™ºèƒ½(XAI)æ–¹æ³•å¦‚SHAPå’ŒGradCAMåœ¨è§£é‡Šåˆ†ç±»å†³ç­–æ—¶ç¼ºä¹å®šé‡æµ‹è¯•æ ‡å‡†çš„éš¾é¢˜ã€‚ç ”ç©¶æŒ‡å‡ºçœŸå®ä¸–ç•Œæ•°æ®ä¸­éš¾ä»¥è§„é¿çš„ç›¸å…³æ€§ä½¿å¾—åŒºåˆ†åˆæ³•ç‰¹å¾ä¸è™šå‡ç›¸å…³æ€§å˜å¾—å›°éš¾ï¼Œå› æ­¤æå‡ºé€šè¿‡å…­ä¸ªåˆæˆæ•°æ®é›†ç³»ç»Ÿåœ°æ¨¡æ‹Ÿäº¤é€šæ ‡å¿—è¯†åˆ«ä»»åŠ¡ã€‚è¯¥æ¡†æ¶é€šè¿‡æ§åˆ¶å˜é‡æ³•éš”ç¦»å¹¶é‡åŒ–äº†èƒŒæ™¯ç›¸å…³æ€§ã€ç›¸æœºå˜åŒ–ä»¥åŠäº¤é€šæ ‡å¿—å½¢çŠ¶å¯¹æ¨¡å‹åˆ†ç±»è¡¨ç°åŠèƒŒæ™¯ç‰¹å¾é‡è¦æ€§çš„ç‹¬ç«‹å½±å“ã€‚å®éªŒç»“æœæ˜ç¡®äº†èƒŒæ™¯ç‰¹å¾åœ¨ä½•ç§è®­ç»ƒåŸŸå˜åŒ–ä¸‹ä¼šè½¬è€Œæ”¯æŒåˆ†ç±»ä»»åŠ¡ï¼Œå¹¶é‡åŒ–äº†èƒŒæ™¯åƒç´ å¯¹åˆ†ç±»å†³ç­–çš„å…·ä½“è´¡çŒ®ç¨‹åº¦ã€‚è¯¥å·¥ä½œä¸ºç†è§£æ¨¡å‹æ˜¯å¦è¿‡åº¦æ‹Ÿåˆè™šå‡ç›¸å…³æ€§æä¾›äº†å®šé‡çš„è¯„ä»·æŒ‡æ ‡ã€‚ç ”ç©¶å›¢é˜ŸåŒæ­¥å‘å¸ƒäº†ç›¸å…³çš„äº¤é€šæ ‡å¿—åˆæˆæ•°æ®é›†ï¼Œä¸ºè‡ªåŠ¨é©¾é©¶é¢†åŸŸçš„æ¨¡å‹å¯è§£é‡Šæ€§ç ”ç©¶æä¾›äº†é‡è¦æ”¯æ’‘ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 2 figures, 7 tables",
      "pdf_url": "https://arxiv.org/pdf/2512.05937v1",
      "published_date": "2025-12-05 18:25:52 UTC",
      "updated_date": "2025-12-05 18:25:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:56:00.465959+00:00"
    },
    {
      "arxiv_id": "2512.05930v1",
      "title": "PRiSM: An Agentic Multimodal Benchmark for Scientific Reasoning via Python-Grounded Evaluation",
      "title_zh": "PRiSMï¼šåŸºäº Python éªŒè¯è¯„ä¼°çš„ç§‘å­¦æ¨ç†å¤šæ¨¡æ€æ™ºèƒ½ä½“åŸºå‡†",
      "authors": [
        "Shima Imani",
        "Seungwhan Moon",
        "Adel Ahmadyan",
        "Lu Zhang",
        "Kirmani Ahmed",
        "Babak Damavandi"
      ],
      "abstract": "Evaluating vision-language models (VLMs) in scientific domains like mathematics and physics poses unique challenges that go far beyond predicting final answers. These domains demand conceptual understanding, symbolic reasoning, and adherence to formal laws, requirements that most existing benchmarks fail to address. In particular, current datasets tend to be static, lacking intermediate reasoning steps, robustness to variations, or mechanisms for verifying scientific correctness. To address these limitations, we introduce PRiSM, a synthetic, fully dynamic, and multimodal benchmark for evaluating scientific reasoning via grounded Python code. PRiSM includes over 24,750 university-level physics and math problems, and it leverages our scalable agent-based pipeline, PrismAgent, to generate well-structured problem instances. Each problem contains dynamic textual and visual input, a generated figure, alongside rich structured outputs: executable Python code for ground truth generation and verification, and detailed step-by-step reasoning. The dynamic nature and Python-powered automated ground truth generation of our benchmark allow for fine-grained experimental auditing of multimodal VLMs, revealing failure modes, uncertainty behaviors, and limitations in scientific reasoning. To this end, we propose five targeted evaluation tasks covering generalization, symbolic program synthesis, perturbation robustness, reasoning correction, and ambiguity resolution. Through comprehensive evaluation of existing VLMs, we highlight their limitations and showcase how PRiSM enables deeper insights into their scientific reasoning capabilities.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº†PRiSMï¼Œè¿™æ˜¯ä¸€ä¸ªåˆæˆçš„ã€å…¨åŠ¨æ€çš„å¤šæ¨¡æ€åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨é€šè¿‡åŸºäºPythonä»£ç çš„è¯„ä¼°æ¥è¡¡é‡è§†è§‰è¯­è¨€æ¨¡å‹(VLMs)åœ¨æ•°å­¦å’Œç‰©ç†ç­‰ç§‘å­¦é¢†åŸŸçš„æ¨ç†èƒ½åŠ›ã€‚é’ˆå¯¹ç°æœ‰åŸºå‡†æµ‹è¯•é™æ€ã€ç¼ºä¹ä¸­é—´æ¨ç†æ­¥éª¤ä¸”éš¾ä»¥éªŒè¯ç§‘å­¦å‡†ç¡®æ€§çš„é—®é¢˜ï¼ŒPRiSMåˆ©ç”¨å¯æ‰©å±•çš„æ™ºèƒ½ä½“æµæ°´çº¿PrismAgentç”Ÿæˆäº†è¶…è¿‡24,750ä¸ªå¤§å­¦æ°´å¹³çš„ç‰©ç†å’Œæ•°å­¦é¢˜ç›®ã€‚æ¯ä¸ªé—®é¢˜éƒ½åŒ…å«åŠ¨æ€çš„æ–‡æœ¬ä¸è§†è§‰è¾“å…¥ã€ç”¨äºç”ŸæˆçœŸå€¼å’ŒéªŒè¯çš„å¯æ‰§è¡ŒPythonä»£ç ï¼Œä»¥åŠè¯¦ç»†çš„é€æ­¥æ¨ç†è·¯å¾„ã€‚è¯¥åŸºå‡†æµ‹è¯•è®¾è®¡äº†æ¶µç›–æ³›åŒ–(generalization)ã€ç¬¦å·ç¨‹åºåˆæˆ(symbolic program synthesis)ã€æ‰°åŠ¨é²æ£’æ€§ç­‰äº”ä¸ªç»´åº¦çš„è¯„ä¼°ä»»åŠ¡ã€‚é€šè¿‡å¯¹ç°æœ‰VLMsçš„å…¨é¢æµ‹è¯•ï¼ŒPRiSMæˆåŠŸæ­ç¤ºäº†æ¨¡å‹åœ¨ç§‘å­¦æ¨ç†ä¸­çš„å¤±æ•ˆæ¨¡å¼ã€ä¸ç¡®å®šæ€§è¡Œä¸ºå’Œå±€é™æ€§ã€‚è¯¥åŸºå‡†æµ‹è¯•ä¸ºè¯„ä¼°å¤šæ¨¡æ€æ¨¡å‹çš„æ·±åº¦ç§‘å­¦æ¨ç†èƒ½åŠ›æä¾›äº†æ›´ç»†ç²’åº¦çš„å®éªŒå®¡è®¡æ‰‹æ®µå’Œå…³é”®æ´å¯Ÿã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.05930v1",
      "published_date": "2025-12-05 18:14:55 UTC",
      "updated_date": "2025-12-05 18:14:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:56:15.660511+00:00"
    },
    {
      "arxiv_id": "2512.05927v1",
      "title": "World Models That Know When They Don't Know: Controllable Video Generation with Calibrated Uncertainty",
      "title_zh": "çŸ¥å…¶æ‰€ä¸çŸ¥çš„ä¸–ç•Œæ¨¡å‹ï¼šå…·æœ‰æ ¡å‡†ä¸ç¡®å®šæ€§çš„å¯æ§è§†é¢‘ç”Ÿæˆ",
      "authors": [
        "Zhiting Mei",
        "Tenny Yin",
        "Micah Baker",
        "Ola Shorinwa",
        "Anirudha Majumdar"
      ],
      "abstract": "Recent advances in generative video models have led to significant breakthroughs in high-fidelity video synthesis, specifically in controllable video generation where the generated video is conditioned on text and action inputs, e.g., in instruction-guided video editing and world modeling in robotics. Despite these exceptional capabilities, controllable video models often hallucinate - generating future video frames that are misaligned with physical reality - which raises serious concerns in many tasks such as robot policy evaluation and planning. However, state-of-the-art video models lack the ability to assess and express their confidence, impeding hallucination mitigation. To rigorously address this challenge, we propose C3, an uncertainty quantification (UQ) method for training continuous-scale calibrated controllable video models for dense confidence estimation at the subpatch level, precisely localizing the uncertainty in each generated video frame. Our UQ method introduces three core innovations to empower video models to estimate their uncertainty. First, our method develops a novel framework that trains video models for correctness and calibration via strictly proper scoring rules. Second, we estimate the video model's uncertainty in latent space, avoiding training instability and prohibitive training costs associated with pixel-space approaches. Third, we map the dense latent-space uncertainty to interpretable pixel-level uncertainty in the RGB space for intuitive visualization, providing high-resolution uncertainty heatmaps that identify untrustworthy regions. Through extensive experiments on large-scale robot learning datasets (Bridge and DROID) and real-world evaluations, we demonstrate that our method not only provides calibrated uncertainty estimates within the training distribution, but also enables effective out-of-distribution detection.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¯æ§è§†é¢‘ç”Ÿæˆæ¨¡å‹ï¼ˆControllable Video Modelsï¼‰åœ¨æœºå™¨äººç­–ç•¥è¯„ä¼°ç­‰ä»»åŠ¡ä¸­å®¹æ˜“äº§ç”Ÿå¹»è§‰çš„é—®é¢˜ï¼Œæå‡ºäº†åä¸º C3 çš„ä¸ç¡®å®šæ€§é‡åŒ–ï¼ˆUncertainty Quantificationï¼‰æ–¹æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡åœ¨å­å—ï¼ˆsubpatchï¼‰å±‚çº§è¿›è¡Œå¯†é›†ç½®ä¿¡åº¦ä¼°è®¡ï¼Œä½¿ä¸–ç•Œæ¨¡å‹ï¼ˆWorld Modelsï¼‰èƒ½å¤Ÿç²¾ç¡®è¯†åˆ«ç”Ÿæˆå¸§ä¸­ä¸ç‰©ç†ç°å®ä¸ç¬¦çš„åŒºåŸŸã€‚C3 å¼•å…¥äº†åŸºäºä¸¥æ ¼é€‚å®œè¯„åˆ†è§„åˆ™ï¼ˆstrictly proper scoring rulesï¼‰çš„è®­ç»ƒæ¡†æ¶ï¼Œå¹¶åˆ›æ–°æ€§åœ°åœ¨æ½œç©ºé—´ï¼ˆlatent spaceï¼‰è€Œéåƒç´ ç©ºé—´ä¼°è®¡ä¸ç¡®å®šæ€§ï¼Œä»è€Œç¡®ä¿äº†è®­ç»ƒçš„ç¨³å®šæ€§å’Œè®¡ç®—çš„é«˜æ•ˆæ€§ã€‚æ­¤å¤–ï¼Œè¯¥æŠ€æœ¯èƒ½å°†æ½œç©ºé—´ä¸ç¡®å®šæ€§æ˜ å°„ä¸º RGB ç©ºé—´çš„åƒç´ çº§çƒ­åŠ›å›¾ï¼Œä¸ºç›´è§‚å®šä½ä¸å¯ä¿¡åŒºåŸŸæä¾›äº†å¯è§†åŒ–ä¾æ®ã€‚åœ¨ Bridge å’Œ DROID ç­‰å¤§è§„æ¨¡æœºå™¨äººå­¦ä¹ æ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•ä¸ä»…èƒ½æä¾›å‡†ç¡®çš„æ ¡å‡†ä¸ç¡®å®šæ€§ä¼°è®¡ï¼Œè¿˜å…·å¤‡å“è¶Šçš„åˆ†å¸ƒå¤–æ£€æµ‹ï¼ˆOut-of-Distribution Detectionï¼‰èƒ½åŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.05927v1",
      "published_date": "2025-12-05 18:06:18 UTC",
      "updated_date": "2025-12-05 18:06:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:56:19.594363+00:00"
    },
    {
      "arxiv_id": "2512.05925v1",
      "title": "To Err Is Human: Systematic Quantification of Errors in Published AI Papers via LLM Analysis",
      "title_zh": "äººéåœ£è´¤ï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹åˆ†æçš„å·²å‘è¡¨ AI è®ºæ–‡é”™è¯¯ç³»ç»Ÿæ€§é‡åŒ–",
      "authors": [
        "Federico Bianchi",
        "Yongchan Kwon",
        "Zachary Izzo",
        "Linjun Zhang",
        "James Zou"
      ],
      "abstract": "How many mistakes do published AI papers contain? Peer-reviewed publications form the foundation upon which new research and knowledge are built. Errors that persist in the literature can propagate unnoticed, creating confusion in follow-up studies and complicating reproducibility. The accelerating pace of research and the increasing demands on the peer-review system make such mistakes harder to detect and avoid. To address this, we developed a Paper Correctness Checker based on GPT-5 to systematically identify mistakes in papers previously published at top AI conferences and journals. Our analysis focuses on objective mistakes-e.g., errors in formulas, derivations, calculations, figures, and tables-that have a clearly verifiable ground truth. We intentionally exclude subjective considerations such as novelty, importance, or writing quality. We find that published papers contain a non-negligible number of objective mistakes and that the average number of mistakes per paper has increased over time-from 3.8 in NeurIPS 2021 to 5.9 in NeurIPS 2025 (55.3% increase); from 4.1 in ICLR 2018 to 5.2 in ICLR 2025; and from 5.0 in TMLR 2022/23 to 5.5 in TMLR 2025. Human experts reviewed 316 potential mistakes identified by the AI Checker and confirmed that 263 were actual mistakes, corresponding to a precision of 83.2%. While most identified issues are relatively minor, correcting them would reduce confusion in the literature and strengthen reproducibility. The AI Checker also surfaced potentially more substantive mistakes that could affect the interpretation of results. Moreover, we show that the AI Checker can propose correct fixes for 75.8% of the identified mistakes. Overall, this study highlights the potential of frontier LLMs to detect and correct objective mistakes in published papers, helping to establish a firmer foundation of knowledge.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å·²å‘è¡¨ AI è®ºæ–‡ä¸­çš„é”™è¯¯ç‡è¿›è¡Œäº†ç³»ç»Ÿæ€§é‡åŒ–åˆ†æï¼Œå¹¶å¼€å‘äº†ä¸€ä¸ªåŸºäº GPT-5 çš„è®ºæ–‡æ­£ç¡®æ€§æ£€æŸ¥å™¨ (Paper Correctness Checker) æ¥è¯†åˆ«é¡¶çº§ä¼šè®®å’ŒæœŸåˆŠè®ºæ–‡ä¸­çš„å®¢è§‚é”™è¯¯ã€‚åˆ†æé‡ç‚¹åœ¨äºå…¬å¼ã€æ¨å¯¼ã€è®¡ç®—ã€å›¾è¡¨ç­‰å…·æœ‰æ˜ç¡®å¯éªŒè¯äº‹å®çš„å®¢è§‚é”™è¯¯ï¼Œè€Œä¸æ¶‰åŠåˆ›æ–°æ€§æˆ–å†™ä½œè´¨é‡ç­‰ä¸»è§‚è¯„ä»·ã€‚ç ”ç©¶å‘ç°ï¼Œå·²å‘è¡¨è®ºæ–‡ä¸­çš„å®¢è§‚é”™è¯¯æ•°é‡ä¸å¯å¿½è§†ï¼Œä¸”éšæ—¶é—´å‘ˆæ˜¾è‘—ä¸Šå‡è¶‹åŠ¿ï¼Œä¾‹å¦‚ NeurIPS è®ºæ–‡çš„å¹³å‡é”™è¯¯æ•°ä» 2021 å¹´çš„ 3.8 ä¸ªå¢åŠ åˆ° 2025 å¹´çš„ 5.9 ä¸ªã€‚åœ¨å¯¹ AI æ£€æŸ¥å™¨è¯†åˆ«çš„ 316 ä¸ªæ½œåœ¨é”™è¯¯è¿›è¡Œä¸“å®¶è¯„å®¡åï¼Œè¯å®å…¶ä¸­ 263 ä¸ªä¸ºçœŸå®é”™è¯¯ï¼Œå‡†ç¡®ç‡ (precision) è¾¾åˆ° 83.2%ã€‚å°½ç®¡å¤šæ•°é”™è¯¯è¾ƒä¸ºç»†å¾®ï¼Œä½†è¯¥å·¥å…·èƒ½ä¸º 75.8% çš„é”™è¯¯æä¾›æ­£ç¡®çš„ä¿®æ­£å»ºè®®ï¼Œæœ‰åŠ©äºå‡å°‘å­¦æœ¯æ–‡çŒ®ä¸­çš„æ··æ·†å¹¶å¢å¼ºå¯å¤ç°æ€§ (reproducibility)ã€‚è¯¥ç ”ç©¶å±•ç¤ºäº†å‰æ²¿å¤§è¯­è¨€æ¨¡å‹ (frontier LLMs) åœ¨æ£€æµ‹å’Œçº æ­£å­¦æœ¯è®ºæ–‡å®¢è§‚é”™è¯¯æ–¹é¢çš„å·¨å¤§æ½œåŠ›ï¼Œä¸ºæ„å»ºæ›´åšå®çš„ç§‘ç ”çŸ¥è¯†åŸºç¡€æä¾›äº†æŠ€æœ¯æ”¯æŒã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.05925v1",
      "published_date": "2025-12-05 18:04:10 UTC",
      "updated_date": "2025-12-05 18:04:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:56:29.327035+00:00"
    },
    {
      "arxiv_id": "2512.06060v1",
      "title": "Reinforcement Learning Integrated Agentic RAG for Software Test Cases Authoring",
      "title_zh": "èåˆå¼ºåŒ–å­¦ä¹ çš„æ™ºèƒ½ä½“ RAG è½¯ä»¶æµ‹è¯•ç”¨ä¾‹ç¼–å†™",
      "authors": [
        "Mohanakrishnan Hariharan"
      ],
      "abstract": "This paper introduces a framework that integrates reinforcement learning (RL) with autonomous agents to enable continuous improvement in the automated process of software test cases authoring from business requirement documents within Quality Engineering (QE) workflows. Conventional systems employing Large Language Models (LLMs) generate test cases from static knowledge bases, which fundamentally limits their capacity to enhance performance over time. Our proposed Reinforcement Infused Agentic RAG (Retrieve, Augment, Generate) framework overcomes this limitation by employing AI agents that learn from QE feedback, assessments, and defect discovery outcomes to automatically improve their test case generation strategies. The system combines specialized agents with a hybrid vector-graph knowledge base that stores and retrieves software testing knowledge. Through advanced RL algorithms, specifically Proximal Policy Optimization (PPO) and Deep Q-Networks (DQN), these agents optimize their behavior based on QE-reported test effectiveness, defect detection rates, and workflow metrics. As QEs execute AI-generated test cases and provide feedback, the system learns from this expert guidance to improve future iterations. Experimental validation on enterprise Apple projects yielded substantive improvements: a 2.4% increase in test generation accuracy (from 94.8% to 97.2%), and a 10.8% improvement in defect detection rates. The framework establishes a continuous knowledge refinement loop driven by QE expertise, resulting in progressively superior test case quality that enhances, rather than replaces, human testing capabilities.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§å°†å¼ºåŒ–å­¦ä¹  (Reinforcement Learning) ä¸è‡ªä¸»æ™ºèƒ½ä½“é›†æˆçš„æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿå¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨ä»ä¸šåŠ¡éœ€æ±‚æ–‡æ¡£è‡ªåŠ¨ç¼–å†™è½¯ä»¶æµ‹è¯•ç”¨ä¾‹æ—¶ï¼Œå› å—é™äºé™æ€çŸ¥è¯†åº“è€Œæ— æ³•æŒç»­æå‡æ€§èƒ½çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶é‡‡ç”¨äº†å¼ºåŒ–æ³¨å…¥çš„æ™ºèƒ½ä½“ RAG (Reinforcement Infused Agentic RAG) æŠ€æœ¯ï¼Œé€šè¿‡ä¸“é—¨çš„æ™ºèƒ½ä½“ä¸æ··åˆå‘é‡å›¾çŸ¥è¯†åº“ (hybrid vector-graph knowledge base) ç›¸ç»“åˆï¼Œä»è´¨é‡å·¥ç¨‹ (QE) çš„åé¦ˆã€è¯„ä¼°åŠç¼ºé™·å‘ç°ç»“æœä¸­è‡ªåŠ¨å­¦ä¹ å¹¶æ”¹è¿›ç”Ÿæˆç­–ç•¥ã€‚ç³»ç»Ÿåˆ©ç”¨ Proximal Policy Optimization (PPO) å’Œ Deep Q-Networks (DQN) ç­‰å…ˆè¿›ç®—æ³•ï¼Œæ ¹æ®æµ‹è¯•æœ‰æ•ˆæ€§ã€ç¼ºé™·æ£€æµ‹ç‡å’Œå·¥ä½œæµæŒ‡æ ‡ä¼˜åŒ–æ™ºèƒ½ä½“è¡Œä¸ºã€‚åœ¨ Apple ä¼ä¸šçº§é¡¹ç›®ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¡†æ¶å°†æµ‹è¯•ç”Ÿæˆå‡†ç¡®ç‡ä» 94.8% æå‡è‡³ 97.2%ï¼Œå¹¶ä½¿ç¼ºé™·æ£€æµ‹ç‡æ˜¾è‘—æé«˜äº† 10.8%ã€‚è¯¥ç ”ç©¶é€šè¿‡å»ºç«‹ç”± QE ä¸“å®¶æŒ‡å¯¼çš„æŒç»­çŸ¥è¯†ç²¾ç‚¼é—­ç¯ï¼Œå®ç°äº†æµ‹è¯•ç”¨ä¾‹è´¨é‡çš„ç¨³æ­¥æå‡ï¼Œä¸ºå¢å¼ºäººç±»æµ‹è¯•èƒ½åŠ›æä¾›äº†å¯æ‰©å±•çš„è‡ªåŠ¨åŒ–è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.06060v1",
      "published_date": "2025-12-05 17:52:26 UTC",
      "updated_date": "2025-12-05 17:52:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:56:35.886847+00:00"
    },
    {
      "arxiv_id": "2512.05908v1",
      "title": "Natural Language Summarization Enables Multi-Repository Bug Localization by LLMs in Microservice Architectures",
      "title_zh": "è‡ªç„¶è¯­è¨€æ‘˜è¦èµ‹èƒ½å¾®æœåŠ¡æ¶æ„ä¸‹åŸºäº LLM çš„å¤šä»“åº“ç¼ºé™·å®šä½",
      "authors": [
        "Amirkia Rafiei Oskooei",
        "S. Selcan Yukcu",
        "Mehmet Cevheri Bozoglan",
        "Mehmet S. Aktas"
      ],
      "abstract": "Bug localization in multi-repository microservice architectures is challenging due to the semantic gap between natural language bug reports and code, LLM context limitations, and the need to first identify the correct repository. We propose reframing this as a natural language reasoning task by transforming codebases into hierarchical NL summaries and performing NL-to-NL search instead of cross-modal retrieval. Our approach builds context-aware summaries at file, directory, and repository levels, then uses a two-phase search: first routing bug reports to relevant repositories, then performing top-down localization within those repositories. Evaluated on DNext, an industrial system with 46 repositories and 1.1M lines of code, our method achieves Pass@10 of 0.82 and MRR of 0.50, significantly outperforming retrieval baselines and agentic RAG systems like GitHub Copilot and Cursor. This work demonstrates that engineered natural language representations can be more effective than raw source code for scalable bug localization, providing an interpretable repository -> directory -> file search path, which is vital for building trust in enterprise AI tools by providing essential transparency.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¾®æœåŠ¡æ¶æ„ä¸­å¤šä»“åº“ Bug Localization çš„æŒ‘æˆ˜ï¼Œæå‡ºå°†ä»£ç åº“è½¬åŒ–ä¸ºå±‚æ¬¡åŒ–çš„ Natural Language Summarizationï¼Œä»è€Œå°†è¯¥ä»»åŠ¡é‡æ„ä¸ºè‡ªç„¶è¯­è¨€æ¨ç†ä»»åŠ¡ã€‚è¯¥æ–¹æ³•é€šè¿‡æ„å»ºæ–‡ä»¶ã€ç›®å½•å’Œä»“åº“çº§åˆ«çš„ä¸Šä¸‹æ–‡æ„ŸçŸ¥æ‘˜è¦ï¼Œå®ç°äº† Natural Language to Natural Language (NL-to-NL) æœç´¢ï¼Œå–ä»£äº†ä¼ ç»Ÿçš„è·¨æ¨¡æ€æ£€ç´¢ã€‚ç³»ç»Ÿé‡‡ç”¨ä¸¤é˜¶æ®µæœç´¢ç­–ç•¥ï¼Œé¦–å…ˆå°†æ•…éšœæŠ¥å‘Šè·¯ç”±è‡³ç›¸å…³ä»“åº“ï¼Œéšååœ¨ä»“åº“å†…è¿›è¡Œè‡ªé¡¶å‘ä¸‹çš„ç²¾ç¡®å®šä½ã€‚åœ¨åŒ…å«46ä¸ªä»“åº“ã€110ä¸‡è¡Œä»£ç çš„å·¥ä¸šç³»ç»Ÿ DNext ä¸Šçš„è¯„ä¼°æ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•çš„ Pass@10 è¾¾åˆ° 0.82ï¼ŒMRR ä¸º 0.50ï¼Œæ˜¾è‘—ä¼˜äº GitHub Copilot å’Œ Cursor ç­‰ Agentic RAG ç³»ç»Ÿã€‚å®éªŒè¯æ˜ï¼Œç²¾å¿ƒè®¾è®¡çš„è‡ªç„¶è¯­è¨€è¡¨å¾åœ¨å¯æ‰©å±•çš„æ•…éšœå®šä½ä¸­æ¯”åŸå§‹æºä»£ç æ›´æœ‰æ•ˆï¼Œä¸”ç”±äºæä¾›äº†ä»ä»“åº“åˆ°æ–‡ä»¶çš„æœç´¢è·¯å¾„ï¼Œæå¤§åœ°æå‡äº†ç³»ç»Ÿé€æ˜åº¦ä¸å¯è§£é‡Šæ€§ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted at LLM4Code Workshop, ICSE 2026",
      "pdf_url": "https://arxiv.org/pdf/2512.05908v1",
      "published_date": "2025-12-05 17:42:09 UTC",
      "updated_date": "2025-12-05 17:42:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 1,
      "last_update": "2026-01-26T13:57:53.967797+00:00"
    },
    {
      "arxiv_id": "2512.15729v2",
      "title": "TinyMyo: a Tiny Foundation Model for Flexible EMG Signal Processing at the Edge",
      "title_zh": "TinyMyoï¼šé¢å‘è¾¹ç¼˜ä¾§çµæ´»EMGä¿¡å·å¤„ç†çš„å¾®å‹åŸºç¡€æ¨¡å‹",
      "authors": [
        "Matteo Fasulo",
        "Giusy Spacone",
        "Thorir Mar Ingolfsson",
        "Yawei Li",
        "Luca Benini",
        "Andrea Cossettini"
      ],
      "abstract": "Objective: Surface electromyography (EMG) is a non-invasive sensing modality widely used in biomechanics, rehabilitation, prosthetic control, and human-machine interfaces. Despite decades of use, achieving robust generalization across subjects, recording systems, and acquisition protocols remains challenging. While foundation models (FMs) are gaining traction for EMG, existing approaches remain limited to single downstream tasks and lack deployability on embedded platforms. This work addresses these limitations. Methods: We present TinyMyo, a lightweight FM based on a Transformer encoder architecture. The model is pre-trained in a self-supervised manner using masked reconstruction on publicly available datasets. With only 3.6M parameters, TinyMyo is designed to support multiple downstream tasks through minimal task-specific head adaptations. Results: We demonstrate generalization across hand gesture classification, hand kinematic regression, speech production and speech recognition, with performance comparable to or surpassing the state of the art (SoA), and model size below 5M parameters. We achieve SoA results compared to previous FM-based works on the NinaPro DB5 (89.4%), UCI-EMG (97.56%), and EPN-612 (96.74%) datasets. We demonstrate the first-time deployment of an EMG FM on an ultra-low power microcontroller (GAP9), with an inference time of 0.785 s, energy of 44.91 mJ and power envelope of 57.18 mW. Conclusion: TinyMyo demonstrates that compact, self-supervised EMG FM can guarantee strong generalization across multiple downstream tasks while remaining compatible with low-power edge devices. Significance: TinyMyo is the first EMG FM for ultra-low power edge devices, enabling scalable and energy-efficient sensing for motor intent decoding, neuromuscular assessment, and biosignal driven human-machine interaction.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† TinyMyoï¼Œè¿™æ˜¯é¦–ä¸ªä¸“é—¨é’ˆå¯¹è¶…ä½åŠŸè€—è¾¹ç¼˜è®¾å¤‡è®¾è®¡çš„è½»é‡åŒ–è¡¨é¢è‚Œç”µä¿¡å·(EMG)åŸºç¡€æ¨¡å‹(Foundation Model)ï¼Œæ—¨åœ¨è§£å†³æ¨¡å‹åœ¨è·¨å—è¯•è€…å’Œä¸åŒé‡‡é›†åè®®ä¸‹çš„æ³›åŒ–æ€§èƒ½éš¾é¢˜ã€‚TinyMyo é‡‡ç”¨ Transformer encoder æ¶æ„ï¼Œå…¶å‚æ•°é‡ä»…ä¸º 3.6Mï¼Œé€šè¿‡åœ¨å…¬å¼€æ•°æ®é›†ä¸Šè¿›è¡Œæ©ç é‡å»º(masked reconstruction)çš„è‡ªç›‘ç£é¢„è®­ç»ƒè€Œæ„å»ºã€‚è¯¥æ¡†æ¶æ”¯æŒé€šè¿‡æå°çš„ä»»åŠ¡ç‰¹å®šå¤´é€‚é…(task-specific head adaptations)æ¥çµæ´»å¤„ç†æ‰‹åŠ¿åˆ†ç±»ã€è¿åŠ¨å­¦å›å½’åŠè¯­éŸ³è¯†åˆ«ç­‰å¤šç§ä¸‹æ¸¸ä»»åŠ¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒTinyMyo åœ¨ NinaPro DB5ã€UCI-EMG å’Œ EPN-612 æ•°æ®é›†ä¸Šå‡è¾¾åˆ°äº† SOTA æ°´å¹³ï¼Œæ€§èƒ½ä¼˜äºç°æœ‰çš„åŸºç¡€æ¨¡å‹ã€‚æ­¤å¤–ï¼Œç ”ç©¶å›¢é˜Ÿé¦–æ¬¡åœ¨ GAP9 å¾®æ§åˆ¶å™¨ä¸ŠæˆåŠŸéƒ¨ç½²äº†è¯¥æ¨¡å‹ï¼Œåœ¨æä½çš„èƒ½é‡æ¶ˆè€—ä¸‹å®ç°äº†é«˜æ•ˆæ¨ç†ã€‚TinyMyo çš„æˆåŠŸç ”å‘è¯æ˜äº†ç´§å‡‘å‹è‡ªç›‘ç£åŸºç¡€æ¨¡å‹å¯ä»¥åœ¨ä¿è¯å¼ºå¤§æ³›åŒ–èƒ½åŠ›çš„åŒæ—¶é€‚é…ä½åŠŸè€—è¾¹ç¼˜è®¾å¤‡ï¼Œä¸ºåœ¨è¾¹ç¼˜ç«¯è¿›è¡Œé«˜æ•ˆçš„è¿åŠ¨æ„å›¾è§£ç å’Œäººæœºäº¤äº’å¥ å®šäº†é‡è¦åŸºç¡€ã€‚",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.15729v2",
      "published_date": "2025-12-05 17:36:57 UTC",
      "updated_date": "2026-01-15 18:05:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:59:03.522653+00:00"
    },
    {
      "arxiv_id": "2512.05880v1",
      "title": "Neural Coherence : Find higher performance to out-of-distribution tasks from few samples",
      "title_zh": "Neural Coherenceï¼šåŸºäºå°‘é‡æ ·æœ¬æå‡åˆ†å¸ƒå¤–ä»»åŠ¡çš„æ€§èƒ½è¡¨ç°",
      "authors": [
        "Simon Guiroy",
        "Mats Richter",
        "Sarath Chandar",
        "Christopher Pal"
      ],
      "abstract": "To create state-of-the-art models for many downstream tasks, it has become common practice to fine-tune a pre-trained large vision model. However, it remains an open question of how to best determine which of the many possible model checkpoints resulting from a large training run to use as the starting point. This becomes especially important when data for the target task of interest is scarce, unlabeled and out-of-distribution. In such scenarios, common methods relying on in-distribution validation data become unreliable or inapplicable. This work proposes a novel approach for model selection that operates reliably on just a few unlabeled examples from the target task. Our approach is based on a novel concept: Neural Coherence, which entails characterizing a model's activation statistics for source and target domains, allowing one to define model selection methods with high data-efficiency. We provide experiments where models are pre-trained on ImageNet1K and examine target domains consisting of Food-101, PlantNet-300K and iNaturalist. We also evaluate it in many meta-learning settings. Our approach significantly improves generalization across these different target domains compared to established baselines. We further demonstrate the versatility of Neural Coherence as a powerful principle by showing its effectiveness in training data selection.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¸‹æ¸¸ä»»åŠ¡æ•°æ®ç¨€ç¼ºã€æ— æ ‡ç­¾ä¸”å±äºout-of-distributionåœºæ™¯ä¸‹å¦‚ä½•é€‰æ‹©æœ€ä½³é¢„è®­ç»ƒæ¨¡å‹æ£€æŸ¥ç‚¹çš„éš¾é¢˜ï¼Œæå‡ºäº†åä¸ºNeural Coherenceçš„åˆ›æ–°æ–¹æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡è¡¨å¾æ¨¡å‹åœ¨æºåŸŸä¸ç›®æ ‡åŸŸçš„activation statisticsï¼Œä»…éœ€æå°‘æ•°æ— æ ‡ç­¾æ ·æœ¬å³å¯å®ç°é«˜æ•°æ®æ•ˆç‡çš„æ¨¡å‹é€‰æ‹©ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨ImageNet1Ké¢„è®­ç»ƒåŸºç¡€ä¸Šé’ˆå¯¹Food-101ã€PlantNet-300Kå’ŒiNaturalistç­‰ç›®æ ‡åŸŸçš„æµ‹è¯•ä¸­ï¼ŒNeural Coherenceæ˜¾è‘—æå‡äº†è·¨åŸŸæ³›åŒ–èƒ½åŠ›ï¼Œä¸”åœ¨meta-learningè®¾ç½®ä¸­åŒæ ·è¡¨ç°ä¼˜å¼‚ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜éªŒè¯äº†Neural Coherenceåœ¨training data selectionä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ï¼Œè¯æ˜äº†å…¶ä½œä¸ºé€šç”¨åŸåˆ™çš„å¼ºå¤§æ€§èƒ½ã€‚è¯¥æˆæœä¸ºç¼ºä¹æ ‡æ³¨æ•°æ®çš„åˆ†å¸ƒå¤–ä»»åŠ¡æä¾›äº†ä¸€ç§å¯é ä¸”é«˜æ•ˆçš„æ€§èƒ½é¢„æµ‹ä¸æ¨¡å‹ä¼˜åŒ–æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.05880v1",
      "published_date": "2025-12-05 16:55:41 UTC",
      "updated_date": "2025-12-05 16:55:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:58:19.783847+00:00"
    },
    {
      "arxiv_id": "2512.15728v1",
      "title": "FedSight AI: Multi-Agent System Architecture for Federal Funds Target Rate Prediction",
      "title_zh": "FedSight AIï¼šé¢å‘è”é‚¦åŸºé‡‘ç›®æ ‡åˆ©ç‡é¢„æµ‹çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿæ¶æ„",
      "authors": [
        "Yuhan Hou",
        "Tianji Rao",
        "Jeremy Tan",
        "Adler Viton",
        "Xiyue Zhang",
        "David Ye",
        "Abhishek Kodi",
        "Sanjana Dulam",
        "Aditya Paul",
        "Yikai Feng"
      ],
      "abstract": "The Federal Open Market Committee (FOMC) sets the federal funds rate, shaping monetary policy and the broader economy. We introduce \\emph{FedSight AI}, a multi-agent framework that uses large language models (LLMs) to simulate FOMC deliberations and predict policy outcomes. Member agents analyze structured indicators and unstructured inputs such as the Beige Book, debate options, and vote, replicating committee reasoning. A Chain-of-Draft (CoD) extension further improves efficiency and accuracy by enforcing concise multistage reasoning. Evaluated at 2023-2024 meetings, FedSight CoD achieved accuracy of 93.75\\% and stability of 93.33\\%, outperforming baselines including MiniFed and Ordinal Random Forest (RF), while offering transparent reasoning aligned with real FOMC communications.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† FedSight AIï¼Œä¸€ä¸ªåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) æ¨¡æ‹Ÿè”é‚¦å…¬å¼€å¸‚åœºå§”å‘˜ä¼š (FOMC) å®¡è®®å¹¶é¢„æµ‹è”é‚¦åŸºé‡‘ç›®æ ‡åˆ©ç‡çš„å¤šæ™ºèƒ½ä½“æ¶æ„ã€‚è¯¥ç³»ç»Ÿé€šè¿‡æˆå‘˜æ™ºèƒ½ä½“åˆ†æç»“æ„åŒ–æŒ‡æ ‡åŠã€Šè¤çš®ä¹¦ã€‹(Beige Book) ç­‰éç»“æ„åŒ–è¾“å…¥ï¼Œåˆ©ç”¨æ¨¡æ‹Ÿè¾©è®ºä¸æŠ•ç¥¨æœºåˆ¶æ¥å¤åˆ¶å§”å‘˜ä¼šçš„å†³ç­–æ¨ç†è¿‡ç¨‹ã€‚ç ”ç©¶è¿›ä¸€æ­¥å¼•å…¥äº†è‰æ¡ˆé“¾ (Chain-of-Draft, CoD) æ‰©å±•ï¼Œé€šè¿‡ç®€æ´çš„å¤šé˜¶æ®µæ¨ç†æ˜¾è‘—æå‡äº†æ¨¡å‹çš„è¿è¡Œæ•ˆç‡ä¸é¢„æµ‹ç²¾åº¦ã€‚åœ¨ 2023-2024 å¹´ä¼šè®®çš„è¯„ä¼°ä¸­ï¼ŒFedSight CoD è¾¾åˆ°äº† 93.75% çš„å‡†ç¡®ç‡å’Œ 93.33% çš„ç¨³å®šæ€§ï¼Œå…¶æ€§èƒ½è¡¨ç°ä¼˜äº MiniFed å’Œåºæ•°éšæœºæ£®æ— (Ordinal Random Forest, RF) ç­‰åŸºå‡†æ–¹æ³•ã€‚è¯¥æ¡†æ¶ä¸ä»…åœ¨é¢„æµ‹æ€§èƒ½ä¸Šå–å¾—çªç ´ï¼Œè¿˜æä¾›äº†ä¸çœŸå® FOMC æ²Ÿé€šé«˜åº¦ä¸€è‡´çš„é€æ˜æ¨ç†é€»è¾‘ï¼Œä¸ºè‡ªåŠ¨åŒ–è´§å¸æ”¿ç­–åˆ†æå¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "q-fin.GN",
        "cs.AI"
      ],
      "primary_category": "q-fin.GN",
      "comment": "NeurIPS 2025 Generative AI in Finance Workshop",
      "pdf_url": "https://arxiv.org/pdf/2512.15728v1",
      "published_date": "2025-12-05 16:45:18 UTC",
      "updated_date": "2025-12-05 16:45:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:58:40.375705+00:00"
    },
    {
      "arxiv_id": "2512.05865v1",
      "title": "Sparse Attention Post-Training for Mechanistic Interpretability",
      "title_zh": "é¢å‘æœºç†å¯è§£é‡Šæ€§çš„ç¨€ç–æ³¨æ„åŠ›åè®­ç»ƒ",
      "authors": [
        "Florent Draye",
        "Anson Lei",
        "Ingmar Posner",
        "Bernhard SchÃ¶lkopf"
      ],
      "abstract": "We introduce a simple post-training method that makes transformer attention sparse without sacrificing performance. Applying a flexible sparsity regularisation under a constrained-loss objective, we show on models up to 1B parameters that it is possible to retain the original pretraining loss while reducing attention connectivity to $\\approx 0.3 \\%$ of its edges. Unlike sparse-attention methods designed for computational efficiency, our approach leverages sparsity as a structural prior: it preserves capability while exposing a more organized and interpretable connectivity pattern. We find that this local sparsity cascades into global circuit simplification: task-specific circuits involve far fewer components (attention heads and MLPs) with up to 100x fewer edges connecting them. These results demonstrate that transformer attention can be made orders of magnitude sparser, suggesting that much of its computation is redundant and that sparsity may serve as a guiding principle for more structured and interpretable models.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§ç®€å•çš„ Post-Training æ–¹æ³•ï¼Œåœ¨ Constrained-loss Objective ä¸‹é€šè¿‡çµæ´»çš„ Sparsity Regularisation è®© Transformer çš„ Attention å˜å¾—é«˜åº¦ç¨€ç–ä¸”ä¸æŸå¤±æ€§èƒ½ã€‚åœ¨é«˜è¾¾ 1B å‚æ•°è§„æ¨¡çš„æ¨¡å‹ä¸Šï¼Œè¯¥æ–¹æ³•èƒ½åœ¨ä¿æŒåŸå§‹ Pretraining Loss çš„åŒæ—¶ï¼Œå°† Attention Connectivity é™è‡³çº¦ 0.3%ã€‚ä¸ä¾§é‡è®¡ç®—æ•ˆç‡çš„ç ”ç©¶ä¸åŒï¼Œè¯¥æ–¹æ³•åˆ©ç”¨ç¨€ç–æ€§ä½œä¸º Structural Priorï¼Œåœ¨ä¿ç•™æ¨¡å‹èƒ½åŠ›çš„åŒæ—¶æ„å»ºå‡ºæ›´æœ‰åºã€æ›´å…·å¯è§£é‡Šæ€§çš„è¿æ¥æ¨¡å¼ã€‚å®éªŒè¯æ˜è¿™ç§å±€éƒ¨ç¨€ç–ä¼šå¼•å‘å…¨å±€çš„ Circuit Simplificationï¼Œä½¿ä»»åŠ¡ç‰¹å®š Circuit çš„ç»„ä»¶å¤§å¹…å‡å°‘ï¼Œè¿æ¥è¾¹ç¼˜ç¼©å‡é«˜è¾¾ 100 å€ã€‚ç»“æœè¡¨æ˜ Transformer çš„ Attention å­˜åœ¨æå¤§çš„è®¡ç®—å†—ä½™ï¼Œèƒ½å¤Ÿå®ç°å¤šä¸ªæ•°é‡çº§çš„ç¨€ç–åŒ–ã€‚è¿™é¡¹ç ”ç©¶è¯æ˜äº†ç¨€ç–æ€§å¯ä»¥ä½œä¸ºæ„å»ºæ›´å…·ç»“æ„åŒ–å’Œ Mechanistic Interpretability æ¨¡å‹çš„æŒ‡å¯¼åŸåˆ™ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.05865v1",
      "published_date": "2025-12-05 16:40:08 UTC",
      "updated_date": "2025-12-05 16:40:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:58:22.865882+00:00"
    },
    {
      "arxiv_id": "2512.05863v1",
      "title": "Optimizing Medical Question-Answering Systems: A Comparative Study of Fine-Tuned and Zero-Shot Large Language Models with RAG Framework",
      "title_zh": "ä¼˜åŒ–åŒ»å­¦é—®ç­”ç³»ç»Ÿï¼šåŸºäº RAG æ¡†æ¶çš„å¾®è°ƒä¸é›¶æ ·æœ¬å¤§è¯­è¨€æ¨¡å‹å¯¹æ¯”ç ”ç©¶",
      "authors": [
        "Tasnimul Hassan",
        "Md Faisal Karim",
        "Haziq Jeelani",
        "Elham Behnam",
        "Robert Green",
        "Fayeq Jeelani Syed"
      ],
      "abstract": "Medical question-answering (QA) systems can benefit from advances in large language models (LLMs), but directly applying LLMs to the clinical domain poses challenges such as maintaining factual accuracy and avoiding hallucinations. In this paper, we present a retrieval-augmented generation (RAG) based medical QA system that combines domain-specific knowledge retrieval with open-source LLMs to answer medical questions. We fine-tune two state-of-the-art open LLMs (LLaMA~2 and Falcon) using Low-Rank Adaptation (LoRA) for efficient domain specialization. The system retrieves relevant medical literature to ground the LLM's answers, thereby improving factual correctness and reducing hallucinations. We evaluate the approach on benchmark datasets (PubMedQA and MedMCQA) and show that retrieval augmentation yields measurable improvements in answer accuracy compared to using LLMs alone. Our fine-tuned LLaMA~2 model achieves 71.8% accuracy on PubMedQA, substantially improving over the 55.4% zero-shot baseline, while maintaining transparency by providing source references. We also detail the system design and fine-tuning methodology, demonstrating that grounding answers in retrieved evidence reduces unsupported content by approximately 60%. These results highlight the potential of RAG-augmented open-source LLMs for reliable biomedical QA, pointing toward practical clinical informatics applications.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŒ»ç–—é—®ç­”(QA)ç³»ç»Ÿä¸­å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)å­˜åœ¨çš„äº‹å®å‡†ç¡®æ€§ä¸è¶³åŠå¹»è§‰é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºæ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)æ¡†æ¶çš„ä¼˜åŒ–æ–¹æ¡ˆã€‚è¯¥æ–¹æ¡ˆå°†ç‰¹å®šé¢†åŸŸçŸ¥è¯†æ£€ç´¢ä¸å¼€æºLLMsç›¸ç»“åˆï¼Œå¹¶é‡‡ç”¨ä½ç§©è‡ªé€‚åº”(LoRA)æŠ€æœ¯å¯¹LLaMA 2å’ŒFalconæ¨¡å‹è¿›è¡Œäº†é«˜æ•ˆçš„é¢†åŸŸä¸“ä¸šåŒ–å¾®è°ƒã€‚é€šè¿‡æ£€ç´¢ç›¸å…³åŒ»å­¦æ–‡çŒ®æ¥é”šå®šç­”æ¡ˆï¼Œç³»ç»Ÿæ˜¾è‘—æå‡äº†å›ç­”çš„å¯é æ€§ä¸é€æ˜åº¦ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œå¾®è°ƒåçš„LLaMA 2åœ¨PubMedQAæ•°æ®é›†ä¸Šçš„å‡†ç¡®ç‡ä»55.4%çš„é›¶æ ·æœ¬(Zero-Shot)åŸºå‡†æå‡è‡³71.8%ï¼ŒåŒæ—¶å°†æ— ä¾æ®å†…å®¹å‡å°‘äº†çº¦60%ã€‚è¿™ä¸€ç ”ç©¶æˆæœéªŒè¯äº†RAGå¢å¼ºçš„å¼€æºæ¨¡å‹åœ¨ç”Ÿç‰©åŒ»å­¦é—®ç­”é¢†åŸŸçš„åº”ç”¨æ½œåŠ›ï¼Œä¸ºæ„å»ºå¯ä¿¡çš„ä¸´åºŠä¿¡æ¯ç³»ç»Ÿæä¾›äº†æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.05863v1",
      "published_date": "2025-12-05 16:38:47 UTC",
      "updated_date": "2025-12-05 16:38:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:58:22.456241+00:00"
    },
    {
      "arxiv_id": "2512.13705v1",
      "title": "Scaling and Transferability of Annealing Strategies in Large Language Model Training",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹è®­ç»ƒä¸­é€€ç«ç­–ç•¥çš„æ‰©å±•æ€§ä¸å¯è¿ç§»æ€§",
      "authors": [
        "Siqi Wang",
        "Zhengyu Chen",
        "Teng Xiao",
        "Zheqi Lv",
        "Jinluan Yang",
        "Xunliang Cai",
        "Jingang Wang",
        "Xiaomeng Li"
      ],
      "abstract": "Learning rate scheduling is crucial for training large language models, yet understanding the optimal annealing strategies across different model configurations remains challenging. In this work, we investigate the transferability of annealing dynamics in large language model training and refine a generalized predictive framework for optimizing annealing strategies under the Warmup-Steady-Decay (WSD) scheduler. Our improved framework incorporates training steps, maximum learning rate, and annealing behavior, enabling more efficient optimization of learning rate schedules. Our work provides a practical guidance for selecting optimal annealing strategies without exhaustive hyperparameter searches, demonstrating that smaller models can serve as reliable proxies for optimizing the training dynamics of larger models. We validate our findings on extensive experiments using both Dense and Mixture-of-Experts (MoE) models, demonstrating that optimal annealing ratios follow consistent patterns and can be transferred across different training configurations.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æ¢è®¨äº†å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ (Large Language Model) è®­ç»ƒä¸­é€€ç«ç­–ç•¥ (Annealing Strategies) çš„ç¼©æ”¾ä¸å¯è¿ç§»æ€§ï¼Œé‡ç‚¹åˆ†æäº† Warmup-Steady-Decay (WSD) è°ƒåº¦å™¨çš„ä¼˜åŒ–ã€‚ç ”ç©¶å›¢é˜Ÿæ”¹è¿›å¹¶ç»†åŒ–äº†ä¸€ä¸ªé€šç”¨çš„é¢„æµ‹æ¡†æ¶ï¼Œé€šè¿‡æ•´åˆè®­ç»ƒæ­¥æ•°ã€æœ€å¤§å­¦ä¹ ç‡å’Œé€€ç«è¡Œä¸ºï¼Œå®ç°äº†æ›´é«˜æ•ˆçš„å­¦ä¹ ç‡è°ƒåº¦ (Learning Rate Scheduling) ä¼˜åŒ–ã€‚ç ”ç©¶çš„æ ¸å¿ƒå‘ç°æ˜¯é€€ç«åŠ¨æ€åœ¨ä¸åŒæ¨¡å‹é…ç½®é—´å…·æœ‰è‰¯å¥½çš„è¿ç§»æ€§ï¼Œè¿™ä½¿å¾—è¾ƒå°æ¨¡å‹èƒ½å¤Ÿæˆä¸ºä¼˜åŒ–å¤§å‹æ¨¡å‹è®­ç»ƒåŠ¨æ€çš„å¯é ä»£ç†ï¼Œä»è€Œé¿å…äº†è¯¦å°½ä¸”æ˜‚è´µçš„è¶…å‚æ•°æœç´¢ã€‚é€šè¿‡åœ¨å¯†é›†æ¨¡å‹ (Dense) å’Œæ··åˆä¸“å®¶æ¨¡å‹ (Mixture-of-Experts, MoE) ä¸Šçš„å¹¿æ³›å®éªŒï¼Œè¯¥ç ”ç©¶éªŒè¯äº†æœ€ä½³é€€ç«æ¯”ä¾‹éµå¾ªä¸€è‡´çš„æ¨¡å¼ã€‚è¿™ä¸€æˆæœä¸ºåœ¨ä¸åŒè®­ç»ƒé…ç½®ä¸‹é€‰æ‹©æœ€ä¼˜é€€ç«ç­–ç•¥æä¾›äº†é‡è¦çš„å®è·µæŒ‡å¯¼å’Œç†è®ºæ”¯æŒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to AAAI 2026 (camera-ready version)",
      "pdf_url": "https://arxiv.org/pdf/2512.13705v1",
      "published_date": "2025-12-05 16:38:33 UTC",
      "updated_date": "2025-12-05 16:38:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:58:34.143490+00:00"
    },
    {
      "arxiv_id": "2512.05844v1",
      "title": "NEAT: Neighborhood-Guided, Efficient, Autoregressive Set Transformer for 3D Molecular Generation",
      "title_zh": "NEATï¼šé¢å‘ä¸‰ç»´åˆ†å­ç”Ÿæˆçš„é‚»åŸŸå¼•å¯¼é«˜æ•ˆè‡ªå›å½’é›†åˆ Transformer",
      "authors": [
        "Daniel Rose",
        "Roxane Axel Jacob",
        "Johannes Kirchmair",
        "Thierry Langer"
      ],
      "abstract": "Autoregressive models are a promising alternative to diffusion-based models for 3D molecular structure generation. However, a key limitation is the assumption of a token order: while text has a natural sequential order, the next token prediction given a molecular graph prefix should be invariant to atom permutations. Previous works sidestepped this mismatch by using canonical orders or focus atoms. We argue that this is unnecessary. We introduce NEAT, a Neighborhood-guided, Efficient, Autoregressive, Set Transformer that treats molecular graphs as sets of atoms and learns the order-agnostic distribution over admissible tokens at the graph boundary with an autoregressive flow model. NEAT approaches state-of-the-art performance in 3D molecular generation with high computational efficiency and atom-level permutation invariance, establishing a practical foundation for scalable molecular design.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†NEATï¼Œä¸€ç§é‚»åŸŸå¼•å¯¼ä¸”é«˜æ•ˆçš„è‡ªå›å½’é›†åˆTransformer (Neighborhood-guided, Efficient, Autoregressive Set Transformer)ï¼Œæ—¨åœ¨ä¼˜åŒ–3Dåˆ†å­ç»“æ„ç”Ÿæˆè¿‡ç¨‹ã€‚é’ˆå¯¹ä¼ ç»Ÿè‡ªå›å½’æ¨¡å‹é€šå¸¸éœ€è¦å‡è®¾åŸå­é¡ºåºè€Œå¿½ç•¥åˆ†å­å›¾ç½®æ¢ä¸å˜æ€§(permutation invariance)çš„é—®é¢˜ï¼ŒNEATåˆ›æ–°æ€§åœ°å°†åˆ†å­å›¾è§†ä¸ºåŸå­é›†åˆè¿›è¡Œå¤„ç†ã€‚è¯¥æ¡†æ¶åˆ©ç”¨è‡ªå›å½’æµæ¨¡å‹(autoregressive flow model)åœ¨å›¾è¾¹ç•Œå­¦ä¹ å®¹è®¸æ ‡è®°(admissible tokens)çš„é¡ºåºæ— å…³åˆ†å¸ƒï¼Œä»è€Œè§„é¿äº†å¯¹è§„èŒƒé¡ºåº(canonical orders)æˆ–ç„¦ç‚¹åŸå­(focus atoms)çš„ä¾èµ–ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒNEATåœ¨ä¿æŒåŸå­çº§ç½®æ¢ä¸å˜æ€§çš„åŒæ—¶æ˜¾è‘—æå‡äº†è®¡ç®—æ•ˆç‡ï¼Œå¹¶åœ¨3Dåˆ†å­ç”Ÿæˆä»»åŠ¡ä¸­è¾¾åˆ°äº†æ¥è¿‘æœ€å…ˆè¿›(state-of-the-art)çš„æ€§èƒ½æ°´å¹³ã€‚è¯¥æ¨¡å‹çš„æå‡ºä¸ºå®ç°å¯æ‰©å±•ä¸”é«˜æ•ˆçš„åˆ†å­è®¾è®¡å¥ å®šäº†åšå®çš„å®è·µåŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.05844v1",
      "published_date": "2025-12-05 16:18:07 UTC",
      "updated_date": "2025-12-05 16:18:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:58:37.863023+00:00"
    },
    {
      "arxiv_id": "2512.05836v1",
      "title": "Using Large Language Models to Create Personalized Networks From Therapy Sessions",
      "title_zh": "åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹åŸºäºå¿ƒç†æ²»ç–—ä¼šè¯æ„å»ºä¸ªæ€§åŒ–ç½‘ç»œ",
      "authors": [
        "Clarissa W. Ong",
        "Hiba Arnaout",
        "Kate Sheehan",
        "Estella Fox",
        "Eugen Owtscharow",
        "Iryna Gurevych"
      ],
      "abstract": "Recent advances in psychotherapy have focused on treatment personalization, such as by selecting treatment modules based on personalized networks. However, estimating personalized networks typically requires intensive longitudinal data, which is not always feasible. A solution to facilitate scalability of network-driven treatment personalization is leveraging LLMs. In this study, we present an end-to-end pipeline for automatically generating client networks from 77 therapy transcripts to support case conceptualization and treatment planning. We annotated 3364 psychological processes and their corresponding dimensions in therapy transcripts. Using these data, we applied in-context learning to jointly identify psychological processes and their dimensions. The method achieved high performance even with a few training examples. To organize the processes into networks, we introduced a two-step method that grouped them into clinically meaningful clusters. We then generated explanation-augmented relationships between clusters. Experts found that networks produced by our multi-step approach outperformed those built with direct prompting for clinical utility and interpretability, with up to 90% preferring our approach. In addition, the networks were rated favorably by experts, with scores for clinical relevance, novelty, and usefulness ranging from 72-75%. Our findings provide a proof of concept for using LLMs to create clinically relevant networks from therapy transcripts. Advantages of our approach include bottom-up case conceptualization from client utterances in therapy sessions and identification of latent themes. Networks generated from our pipeline may be used in clinical settings and supervision and training. Future research should examine whether these networks improve treatment outcomes relative to other methods of treatment personalization, including statistically estimated networks.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ (Large Language Models, LLMs) ä»å¿ƒç†æ²»ç–—è½¬å½•æ–‡æœ¬ä¸­è‡ªåŠ¨ç”Ÿæˆä¸ªæ€§åŒ–ç½‘ç»œçš„æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿä¸ªæ€§åŒ–ç½‘ç»œä¼°ç®—å¯¹é•¿æœŸçºµå‘æ•°æ®çš„è¿‡åº¦ä¾èµ–ã€‚ç ”ç©¶è€…å¼€å‘äº†ä¸€å¥—ç«¯åˆ°ç«¯ç®¡é“ï¼Œåˆ©ç”¨ä¸Šä¸‹æ–‡å­¦ä¹  (In-context Learning) è¯†åˆ«æ²»ç–—è¿‡ç¨‹ä¸­çš„å¿ƒç†ç»´åº¦ï¼Œå¹¶é€šè¿‡ä¸¤æ­¥èšç±»æ³•æ„å»ºå…·æœ‰ä¸´åºŠæ„ä¹‰çš„èšç±» (clusters) åŠå…¶å…³è”ã€‚ä¸“å®¶è¯„å®¡æ˜¾ç¤ºï¼Œè¯¥å¤šæ­¥æ–¹æ³•ç”Ÿæˆçš„ç½‘ç»œåœ¨ä¸´åºŠå®ç”¨æ€§å’Œå¯è§£é‡Šæ€§ä¸Šè¿œè¶…ç›´æ¥æç¤º (direct prompting) æ–¹æ¡ˆï¼Œå¾—åˆ°äº†90%ä¸“å®¶çš„é¦–é€‰è®¤å¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œç”Ÿæˆçš„ç½‘ç»œåœ¨ä¸´åºŠç›¸å…³æ€§ã€æ–°é¢–æ€§å’Œæœ‰ç”¨æ€§æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œè¯„åˆ†å‡åœ¨72-75%ä¹‹é—´ã€‚è¯¥ç ”ç©¶æˆåŠŸéªŒè¯äº† LLMs åœ¨è‡ªä¸‹è€Œä¸Šçš„æ¡ˆä¾‹æ¦‚å¿µåŒ– (case conceptualization) å’Œæ½œåœ¨ä¸»é¢˜è¯†åˆ«ä¸­çš„åº”ç”¨æ½œåŠ›ã€‚è¿™äº›ç”Ÿæˆçš„ç½‘ç»œå¯ç›´æ¥åº”ç”¨äºä¸´åºŠè®¾ç½®ã€ç£å¯¼åŠä¸“ä¸šåŸ¹è®­ï¼Œä¸ºå®ç°å¯æ‰©å±•çš„ä¸ªæ€§åŒ–æ²»ç–—æä¾›äº†é‡è¦çš„æŠ€æœ¯è¯æ˜ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.05836v1",
      "published_date": "2025-12-05 16:12:12 UTC",
      "updated_date": "2025-12-05 16:12:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:58:43.597767+00:00"
    },
    {
      "arxiv_id": "2512.11868v1",
      "title": "Industrial AI Robustness Card: Evaluating and Monitoring Time Series Models",
      "title_zh": "å·¥ä¸šäººå·¥æ™ºèƒ½é²æ£’æ€§æŠ¥å‘Šå¡ï¼šæ—¶é—´åºåˆ—æ¨¡å‹çš„è¯„ä¼°ä¸ç›‘æµ‹",
      "authors": [
        "Alexander Windmann",
        "Benedikt Stratmann",
        "Mariya Lyashenko",
        "Oliver Niggemann"
      ],
      "abstract": "Industrial AI practitioners face vague robustness requirements in emerging regulations and standards but lack concrete, implementation ready protocols. This paper introduces the Industrial AI Robustness Card (IARC), a lightweight, task agnostic protocol for documenting and evaluating the robustness of AI models on industrial time series. The IARC specifies required fields and an empirical measurement and reporting protocol that combines drift monitoring, uncertainty quantification, and stress tests, and it maps these to relevant EU AI Act obligations. A soft sensor case study on a biopharmaceutical fermentation process illustrates how the IARC supports reproducible robustness evidence and continuous monitoring.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Industrial AI Robustness Card (IARC)ï¼Œè¿™æ˜¯ä¸€ç§è½»é‡çº§ä¸”ä¸ä»»åŠ¡æ— å…³çš„åè®®ï¼Œä¸“é—¨ç”¨äºè®°å½•å’Œè¯„ä¼°å·¥ä¸šé¢†åŸŸ Time Series æ¨¡å‹çš„é²æ£’æ€§ã€‚é’ˆå¯¹ä»ä¸šè€…åœ¨é¢å¯¹ EU AI Act ç­‰æ–°å…´æ³•è§„æ—¶ç¼ºä¹å…·ä½“æ‰§è¡Œåè®®çš„æŒ‘æˆ˜ï¼ŒIARC æä¾›äº†ä¸€å¥—æ ‡å‡†åŒ–çš„å®è¯æµ‹é‡ä¸æŠ¥å‘Šæµç¨‹ã€‚è¯¥åè®®é›†æˆäº† Drift Monitoringã€Uncertainty Quantification å’Œ Stress Testsï¼Œå¹¶å°†å…¶æŠ€æœ¯è¦æ±‚ä¸ç›‘ç®¡ä¹‰åŠ¡ç›´æ¥æŒ‚é’©ã€‚é€šè¿‡ç”Ÿç‰©åˆ¶è¯å‘é…µè¿‡ç¨‹ä¸­çš„ Soft Sensor æ¡ˆä¾‹ç ”ç©¶ï¼Œè®ºæ–‡è¯æ˜äº†è¯¥å·¥å…·åœ¨ç”Ÿæˆå¯é‡å¤é²æ£’æ€§è¯æ®å’Œå®ç°æŒç»­ç›‘æµ‹æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚è¿™ä¸€è´¡çŒ®ä¸ºå·¥ä¸š AI çš„åˆè§„è½åœ°å’Œå¯é æ€§è¯„ä¼°æä¾›äº†å®ç”¨çš„æ“ä½œæŒ‡å—ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.11868v1",
      "published_date": "2025-12-05 16:11:53 UTC",
      "updated_date": "2025-12-05 16:11:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:58:49.667451+00:00"
    },
    {
      "arxiv_id": "2512.08983v1",
      "title": "HSCP: A Two-Stage Spectral Clustering Framework for Resource-Constrained UAV Identification",
      "title_zh": "HSCPï¼šé¢å‘èµ„æºå—é™æ— äººæœºè¯†åˆ«çš„ä¸¤é˜¶æ®µè°±èšç±»æ¡†æ¶",
      "authors": [
        "Maoyu Wang",
        "Yao Lu",
        "Bo Zhou",
        "Zhuangzhi Chen",
        "Yun Lin",
        "Qi Xuan",
        "Guan Gui"
      ],
      "abstract": "With the rapid development of Unmanned Aerial Vehicles (UAVs) and the increasing complexity of low-altitude security threats, traditional UAV identification methods struggle to extract reliable signal features and meet real-time requirements in complex environments. Recently, deep learning based Radio Frequency Fingerprint Identification (RFFI) approaches have greatly improved recognition accuracy. However, their large model sizes and high computational demands hinder deployment on resource-constrained edge devices. While model pruning offers a general solution for complexity reduction, existing weight, channel, and layer pruning techniques struggle to concurrently optimize compression rate, hardware acceleration, and recognition accuracy. To this end, in this paper, we introduce HSCP, a Hierarchical Spectral Clustering Pruning framework that combines layer pruning with channel pruning to achieve extreme compression, high performance, and efficient inference. In the first stage, HSCP employs spectral clustering guided by Centered Kernel Alignment (CKA) to identify and remove redundant layers. Subsequently, the same strategy is applied to the channel dimension to eliminate a finer redundancy. To ensure robustness, we further employ a noise-robust fine-tuning strategy. Experiments on the UAV-M100 benchmark demonstrate that HSCP outperforms existing channel and layer pruning methods. Specifically, HSCP achieves $86.39\\%$ parameter reduction and $84.44\\%$ FLOPs reduction on ResNet18 while improving accuracy by $1.49\\%$ compared to the unpruned baseline, and maintains superior robustness even in low signal-to-noise ratio environments.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† HSCPï¼Œä¸€ç§é’ˆå¯¹èµ„æºå—é™æ— äººæœº (UAV) è¯†åˆ«çš„åˆ†å±‚è°±èšç±»å‰ªææ¡†æ¶ (Hierarchical Spectral Clustering Pruning)ï¼Œæ—¨åœ¨è§£å†³æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šéƒ¨ç½²æ—¶çš„è®¡ç®—è´Ÿæ‹…ã€‚HSCP åˆ›æ–°æ€§åœ°ç»“åˆäº†å±‚å‰ªæ (layer pruning) å’Œé€šé“å‰ªæ (channel pruning)ï¼Œä»¥å®ç°æè‡´çš„æ¨¡å‹å‹ç¼©ä¸é«˜æ•ˆæ¨ç†ã€‚åœ¨ç¬¬ä¸€é˜¶æ®µï¼Œè¯¥æ¡†æ¶åˆ©ç”¨ç”±ä¸­å¿ƒå†…æ ¸å¯¹é½ (Centered Kernel Alignment, CKA) å¼•å¯¼çš„è°±èšç±» (spectral clustering) æ¥è¯†åˆ«å¹¶ç§»é™¤å†—ä½™å±‚ï¼Œéšååœ¨ç¬¬äºŒé˜¶æ®µå°†ç›¸åŒç­–ç•¥åº”ç”¨äºé€šé“ç»´åº¦ä»¥æ¶ˆé™¤æ›´ç»†ç²’åº¦çš„å†—ä½™ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜é‡‡ç”¨äº†æŠ—å™ªå£°å¾®è°ƒ (noise-robust fine-tuning) ç­–ç•¥ä»¥ç¡®ä¿ç³»ç»Ÿçš„ç¨³å¥æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨ UAV-M100 åŸºå‡†æµ‹è¯•ä¸­ï¼ŒHSCP ä½¿ ResNet18 çš„å‚æ•°é‡å‡å°‘äº† 86.39%ï¼ŒFLOPs é™ä½äº† 84.44%ï¼Œä¸”å‡†ç¡®ç‡æ¯”æœªå‰ªæåŸºçº¿æå‡äº† 1.49%ã€‚å³ä½¿åœ¨ä½ä¿¡å™ªæ¯” (low signal-to-noise ratio) ç¯å¢ƒä¸‹ï¼Œè¯¥æ¡†æ¶ä¾ç„¶å±•ç°å‡ºå“è¶Šçš„æ€§èƒ½ï¼Œä¸ºå¤æ‚ä½ç©ºå®‰å…¨ç¯å¢ƒä¸‹çš„å®æ—¶æ— äººæœºè¯†åˆ«æä¾›äº†é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.08983v1",
      "published_date": "2025-12-05 16:03:53 UTC",
      "updated_date": "2025-12-05 16:03:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:58:52.275685+00:00"
    },
    {
      "arxiv_id": "2512.05830v1",
      "title": "Phase-OTDR Event Detection Using Image-Based Data Transformation and Deep Learning",
      "title_zh": "åŸºäºå›¾åƒåŒ–æ•°æ®è½¬æ¢ä¸æ·±åº¦å­¦ä¹ çš„ Phase-OTDR äº‹ä»¶æ£€æµ‹",
      "authors": [
        "Muhammet Cagri Yeke",
        "Samil Sirin",
        "Kivilcim Yuksel",
        "Abdurrahman Gumus"
      ],
      "abstract": "This study focuses on event detection in optical fibers, specifically classifying six events using the Phase-OTDR system. A novel approach is introduced to enhance Phase-OTDR data analysis by transforming 1D data into grayscale images through techniques such as Gramian Angular Difference Field, Gramian Angular Summation Field, and Recurrence Plot. These grayscale images are combined into a multi-channel RGB representation, enabling more robust and adaptable analysis using transfer learning models. The proposed methodology achieves high classification accuracies of 98.84% and 98.24% with the EfficientNetB0 and DenseNet121 models, respectively. A 5-fold cross-validation process confirms the reliability of these models, with test accuracy rates of 99.07% and 98.68%. Using a publicly available Phase-OTDR dataset, the study demonstrates an efficient approach to understanding optical fiber events while reducing dataset size and improving analysis efficiency. The results highlight the transformative potential of image-based analysis in interpreting complex fiber optic sensing data, offering significant advancements in the accuracy and reliability of fiber optic monitoring systems. The codes and the corresponding image-based dataset are made publicly available on GitHub to support further research: https://github.com/miralab-ai/Phase-OTDR-event-detection.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Phase-OTDR ç³»ç»Ÿä¸­çš„å…‰çº¤äº‹ä»¶æ£€æµ‹é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§èƒ½å¤Ÿåˆ†ç±»å…­ç§ä¸åŒäº‹ä»¶çš„åˆ›æ–°æ·±åº¦å­¦ä¹ æ¡†æ¶ã€‚å…¶æ ¸å¿ƒæ–¹æ³•æ˜¯é€šè¿‡ Gramian Angular Difference Field (GADF)ã€Gramian Angular Summation Field (GASF) å’Œ Recurrence Plot (RP) ç­‰æŠ€æœ¯ï¼Œå°†ä¸€ç»´ä¼ æ„Ÿæ•°æ®è½¬åŒ–ä¸ºç°åº¦å›¾åƒï¼Œå¹¶è¿›ä¸€æ­¥åˆæˆä¸ºå¤šé€šé“çš„ RGB å›¾åƒã€‚ç ”ç©¶åˆ©ç”¨ EfficientNetB0 å’Œ DenseNet121 ç­‰è¿ç§»å­¦ä¹ (transfer learning)æ¨¡å‹è¿›è¡Œç‰¹å¾æå–ä¸åˆ†ç±»ï¼Œå®éªŒç»“æœæ˜¾ç¤ºæœ€é«˜åˆ†ç±»å‡†ç¡®ç‡åˆ†åˆ«è¾¾åˆ° 98.84% å’Œ 98.24%ã€‚äº”æŠ˜äº¤å‰éªŒè¯(5-fold cross-validation)çš„ç»“æœè¿›ä¸€æ­¥è¯å®äº†è¯¥æ–¹æ¡ˆåœ¨å¤„ç†å…¬å¼€æ•°æ®é›†æ—¶çš„ç¨³å®šæ€§å’Œå¯é æ€§ã€‚è¿™é¡¹å·¥ä½œä¸ä»…æ˜¾è‘—æé«˜äº†å…‰çº¤ç›‘æµ‹ç³»ç»Ÿçš„åˆ†ææ•ˆç‡ï¼Œè¿˜é€šè¿‡å›¾åƒå˜æ¢æŠ€æœ¯ä¸ºè§£é‡Šå¤æ‚çš„åˆ†å¸ƒå¼å…‰çº¤ä¼ æ„Ÿæ•°æ®æä¾›äº†æ–°é¢–ä¸”é«˜æ•ˆçš„è·¯å¾„ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "22 pages, 11 figures, 5 tables",
      "pdf_url": "https://arxiv.org/pdf/2512.05830v1",
      "published_date": "2025-12-05 15:52:40 UTC",
      "updated_date": "2025-12-05 15:52:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:59:20.686411+00:00"
    },
    {
      "arxiv_id": "2601.04202v1",
      "title": "TeleTables: A Benchmark for Large Language Models in Telecom Table Interpretation",
      "title_zh": "TeleTablesï¼šå¤§è¯­è¨€æ¨¡å‹ç”µä¿¡è¡¨æ ¼è§£è¯»èƒ½åŠ›è¯„ä¼°åŸºå‡†",
      "authors": [
        "Anas Ezzakri",
        "Nicola Piovesan",
        "Mohamed Sana",
        "Antonio De Domenico",
        "Fadhel Ayed",
        "Haozhe Zhang"
      ],
      "abstract": "Language Models (LLMs) are increasingly explored in the telecom industry to support engineering tasks, accelerate troubleshooting, and assist in interpreting complex technical documents. However, recent studies show that LLMs perform poorly on telecom standards, particularly 3GPP specifications. We argue that a key reason is that these standards densely include tables to present essential information, yet the LLM knowledge and interpretation ability of such tables remains largely unexamined. To address this gap, we introduce TeleTables, a benchmark designed to evaluate both the implicit knowledge LLMs have about tables in technical specifications and their explicit ability to interpret them. TeleTables is built through a novel multi-stage data generation pipeline that extracts tables from 3GPP standards and uses multimodal and reasoning-oriented LLMs to generate and validate questions. The resulting dataset, which is publicly available, comprises 500 human-verified question-answer pairs, each associated with the corresponding table in multiple formats. Our evaluation shows that, smaller models (under 10B parameters) struggle both to recall 3GPP knowledge and to interpret tables, indicating the limited exposure to telecom standards in their pretraining and the insufficient inductive biases for navigating complex technical material. Larger models, on the other hand, show stronger reasoning on table interpretation. Overall, TeleTables highlights the need for domain-specialized fine-tuning to reliably interpret and reason over telecom standards.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¤„ç†ç”µä¿¡è¡Œä¸šæ ‡å‡†ï¼ˆå°¤å…¶æ˜¯3GPPè§„èŒƒï¼‰æ—¶è¡¨ç°ä¸ä½³çš„é—®é¢˜ï¼ŒæŒ‡å‡ºè¡¨æ ¼è§£è¯»èƒ½åŠ›çš„ç¼ºå¤±æ˜¯æ ¸å¿ƒç“¶é¢ˆã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†TeleTablesï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“é—¨ç”¨äºè¯„ä¼°LLMså¯¹æŠ€æœ¯è§„èŒƒä¸­è¡¨æ ¼çš„éšå¼çŸ¥è¯†åŠæ˜¾å¼è§£è¯»èƒ½åŠ›çš„åŸºå‡†æµ‹è¯•é›†ã€‚TeleTablesé€šè¿‡ä¸€ç§æ–°é¢–çš„å¤šé˜¶æ®µæ•°æ®ç”Ÿæˆæµæ°´çº¿æ„å»ºï¼Œä»3GPPæ ‡å‡†ä¸­æå–è¡¨æ ¼ï¼Œå¹¶åˆ©ç”¨å¤šæ¨¡æ€åŠæ¨ç†å¯¼å‘çš„LLMsç”Ÿæˆå¹¶éªŒè¯é—®é¢˜ã€‚è¯¥æ•°æ®é›†åŒ…å«500ä¸ªç»è¿‡äººå·¥éªŒè¯çš„é—®ç­”å¯¹ï¼Œæ¯å¯¹å‡å…³è”å¤šç§æ ¼å¼çš„å¯¹åº”è¡¨æ ¼ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œå‚æ•°é‡ä½äº10Bçš„å°å‹æ¨¡å‹åœ¨å¬å›3GPPçŸ¥è¯†å’Œè§£æå¤æ‚è¡¨æ ¼æ–¹é¢è¡¨ç°è¾ƒå·®ï¼Œåæ˜ å‡ºå…¶é¢„è®­ç»ƒé˜¶æ®µå¯¹ç”µä¿¡æ ‡å‡†çš„è¦†ç›–ä¸è¶³ä»¥åŠå½’çº³åç½®(Inductive biases)çš„ç¼ºå¤±ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œå¤§å‹æ¨¡å‹åœ¨è¡¨æ ¼æ¨ç†ä¸Šè¡¨ç°æ›´å¼ºï¼Œä½†æ•´ä½“ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œè‹¥è¦å®ç°å¯¹ç”µä¿¡æ ‡å‡†çš„å¯é è§£è¯»ä¸æ¨ç†ï¼Œè¿›è¡Œé¢†åŸŸä¸“ä¸šåŒ–å¾®è°ƒ(Domain-specialized fine-tuning)ä»æ˜¯å¿…ä¸å¯å°‘çš„ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.04202v1",
      "published_date": "2025-12-05 15:47:00 UTC",
      "updated_date": "2025-12-05 15:47:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:59:18.343805+00:00"
    },
    {
      "arxiv_id": "2601.04201v1",
      "title": "Collective Narrative Grounding: Community-Coordinated Data Contributions to Improve Local AI Systems",
      "title_zh": "é›†ä½“å™äº‹é”šå®šï¼šé€šè¿‡ç¤¾åŒºåä½œçš„æ•°æ®è´¡çŒ®ä¼˜åŒ–æœ¬åœ°åŒ–äººå·¥æ™ºèƒ½ç³»ç»Ÿ",
      "authors": [
        "Zihan Gao",
        "Mohsin Y. K. Yousufi",
        "Jacob Thebault-Spieker"
      ],
      "abstract": "Large language model (LLM) question-answering systems often fail on community-specific queries, creating \"knowledge blind spots\" that marginalize local voices and reinforce epistemic injustice. We present Collective Narrative Grounding, a participatory protocol that transforms community stories into structured narrative units and integrates them into AI systems under community governance. Learning from three participatory mapping workshops with N=24 community members, we designed elicitation methods and a schema that retain narrative richness while enabling entity, time, and place extraction, validation, and provenance control. To scope the problem, we audit a county-level benchmark of 14,782 local information QA pairs, where factual gaps, cultural misunderstandings, geographic confusions, and temporal misalignments account for 76.7% of errors. On a participatory QA set derived from our workshops, a state-of-the-art LLM answered fewer than 21% of questions correctly without added context, underscoring the need for local grounding. The missing facts often appear in the collected narratives, suggesting a direct path to closing the dominant error modes for narrative items. Beyond the protocol and pilot, we articulate key design tensions, such as representation and power, governance and control, and privacy and consent, providing concrete requirements for retrieval-first, provenance-visible, locally governed QA systems. Together, our taxonomy, protocol, and participatory evaluation offer a rigorous foundation for building community-grounded AI that better answers local questions.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLM)åœ¨ç‰¹å®šç¤¾åŒºæŸ¥è¯¢ä¸­å­˜åœ¨çš„â€œçŸ¥è¯†ç›²ç‚¹(knowledge blind spots)â€é—®é¢˜ï¼Œæå‡ºäº† Collective Narrative Groundingï¼Œè¿™æ˜¯ä¸€ç§é€šè¿‡ç¤¾åŒºåä½œå°†æ•…äº‹è½¬åŒ–ä¸ºç»“æ„åŒ–å™äº‹å•å…ƒå¹¶æ•´åˆè¿› AI ç³»ç»Ÿä¸­çš„å‚ä¸å¼åè®®ã€‚ç ”ç©¶é€šè¿‡å¯¹24åç¤¾åŒºæˆå‘˜çš„ç ”è®¨ä¼šï¼Œè®¾è®¡äº†èƒ½å¤Ÿä¿ç•™å™äº‹ä¸°å¯Œæ€§å¹¶æ”¯æŒå®ä½“ã€æ—¶é—´å’Œç©ºé—´æå–åŠæ¥æºæ§åˆ¶çš„æ¨¡å¼(schema)ã€‚å¯¹14,782ä¸ªæœ¬åœ°ä¿¡æ¯é—®ç­”å¯¹çš„å®¡è®¡å‘ç°ï¼Œäº‹å®å·®è·å’Œæ–‡åŒ–è¯¯è§£ç­‰å› ç´ å¯¼è‡´äº†76.7%çš„ç³»ç»Ÿé”™è¯¯ï¼Œè€Œæœ€å…ˆè¿›çš„ LLM åœ¨ç¼ºä¹æœ¬åœ°èƒŒæ™¯ä¸‹çš„æ­£ç¡®ç‡ä½äº21%ã€‚å®éªŒç»“æœè¯æ˜ï¼Œæ”¶é›†åˆ°çš„ç¤¾åŒºå™äº‹èƒ½æœ‰æ•ˆå¡«è¡¥è¿™äº›äº‹å®é¸¿æ²Ÿï¼Œæ˜¾è‘—æ”¹å–„æ¨¡å‹åœ¨æœ¬åœ°çŸ¥è¯†ä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜æ¢è®¨äº†æƒåŠ›åˆ†é…ã€æ•°æ®æ²»ç†å’Œéšç§ä¿æŠ¤ç­‰å…³é”®è®¾è®¡å¼ åŠ›ï¼Œä¸ºæ„å»ºå—æœ¬åœ°æ²»ç†ã€æ¥æºå¯è§çš„ç¤¾åŒºå¢å¼ºå‹ AI ç³»ç»Ÿå¥ å®šäº†åšå®çš„åè®®ä¸è¯„ä¼°åŸºç¡€ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 2 figures, Presented at the NeurIPS 2025 ACA Workshop https://acaworkshop.github.io/accepted-papers.html,",
      "pdf_url": "https://arxiv.org/pdf/2601.04201v1",
      "published_date": "2025-12-05 15:44:54 UTC",
      "updated_date": "2025-12-05 15:44:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:59:35.081751+00:00"
    },
    {
      "arxiv_id": "2512.05825v1",
      "title": "Approximation of Box Decomposition Algorithm for Fast Hypervolume-Based Multi-Objective Optimization",
      "title_zh": "é¢å‘å¿«é€Ÿè¶…ä½“ç§¯å¤šç›®æ ‡ä¼˜åŒ–çš„ç›’åˆ†è§£è¿‘ä¼¼ç®—æ³•",
      "authors": [
        "Shuhei Watanabe"
      ],
      "abstract": "Hypervolume (HV)-based Bayesian optimization (BO) is one of the standard approaches for multi-objective decision-making. However, the computational cost of optimizing the acquisition function remains a significant bottleneck, primarily due to the expense of HV improvement calculations. While HV box-decomposition offers an efficient way to cope with the frequent exact improvement calculations, it suffers from super-polynomial memory complexity $O(MN^{\\lfloor \\frac{M + 1}{2} \\rfloor})$ in the worst case as proposed by Lacour et al. (2017). To tackle this problem, Couckuyt et al. (2012) employed an approximation algorithm. However, a rigorous algorithmic description is currently absent from the literature. This paper bridges this gap by providing comprehensive mathematical and algorithmic details of this approximation algorithm.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸºäº Hypervolume (HV) çš„ Bayesian Optimization (BO) åœ¨å¤šç›®æ ‡å†³ç­–ä¸­é¢ä¸´çš„é‡‡é›†å‡½æ•°ä¼˜åŒ–è®¡ç®—ç“¶é¢ˆï¼Œæ¢è®¨äº† HV improvement çš„é«˜æ•ˆè®¡ç®—æ–¹æ³•ã€‚è™½ç„¶ä¼ ç»Ÿçš„ box-decomposition ç®—æ³•èƒ½åº”å¯¹ç²¾ç¡®è®¡ç®—éœ€æ±‚ï¼Œä½†åœ¨æœ€åæƒ…å†µä¸‹å…·æœ‰ $O(MN^{\\lfloor \\frac{M + 1}{2} \\rfloor})$ çš„è¶…å¤šé¡¹å¼å†…å­˜å¤æ‚åº¦ã€‚ä¸ºäº†è§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œç ”ç©¶è€…å…³æ³¨åˆ° Couckuyt ç­‰äººæ›¾æå‡ºçš„è¿‘ä¼¼ç®—æ³•ï¼Œä½†è¯¥ç®—æ³•åœ¨ç°æœ‰æ–‡çŒ®ä¸­ä¸€ç›´ç¼ºä¹ä¸¥è°¨çš„é€»è¾‘æè¿°ã€‚æœ¬æ–‡é€šè¿‡æä¾›è¯¦å°½çš„æ•°å­¦æ¨¡å‹ä¸ algorithmic details å¡«è¡¥äº†è¿™ä¸€ç ”ç©¶ç©ºç™½ã€‚è¯¥å·¥ä½œé€šè¿‡å¯¹ç®—æ³•ç»†èŠ‚çš„å®Œæ•´åˆ»ç”»ï¼Œä¸ºå®ç°æ›´å¿«é€Ÿã€æ›´é«˜æ•ˆçš„åŸºäº HV çš„å¤šç›®æ ‡ä¼˜åŒ–æä¾›äº†é‡è¦çš„ç†è®ºæ”¯æ’‘ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.05825v1",
      "published_date": "2025-12-05 15:43:06 UTC",
      "updated_date": "2025-12-05 15:43:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:59:29.858629+00:00"
    },
    {
      "arxiv_id": "2512.05824v1",
      "title": "Multimodal Oncology Agent for IDH1 Mutation Prediction in Low-Grade Glioma",
      "title_zh": "ç”¨äºä½çº§åˆ«èƒ¶è´¨ç˜¤ IDH1 çªå˜é¢„æµ‹çš„å¤šæ¨¡æ€è‚¿ç˜¤æ™ºèƒ½ä½“",
      "authors": [
        "Hafsa Akebli",
        "Adam Shephard",
        "Vincenzo Della Mea",
        "Nasir Rajpoot"
      ],
      "abstract": "Low-grade gliomas frequently present IDH1 mutations that define clinically distinct subgroups with specific prognostic and therapeutic implications. This work introduces a Multimodal Oncology Agent (MOA) integrating a histology tool based on the TITAN foundation model for IDH1 mutation prediction in low-grade glioma, combined with reasoning over structured clinical and genomic inputs through PubMed, Google Search, and OncoKB. MOA reports were quantitatively evaluated on 488 patients from the TCGA-LGG cohort against clinical and histology baselines. MOA without the histology tool outperformed the clinical baseline, achieving an F1-score of 0.826 compared to 0.798. When fused with histology features, MOA reached the highest performance with an F1-score of 0.912, exceeding both the histology baseline at 0.894 and the fused histology-clinical baseline at 0.897. These results demonstrate that the proposed agent captures complementary mutation-relevant information enriched through external biomedical sources, enabling accurate IDH1 mutation prediction.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼€å‘äº†å¤šæ¨¡æ€è‚¿ç˜¤æ™ºèƒ½ä½“ Multimodal Oncology Agent (MOA)ï¼Œæ—¨åœ¨æé«˜ä½çº§åˆ«èƒ¶è´¨ç˜¤ Low-Grade Glioma ä¸­ IDH1 çªå˜çš„é¢„æµ‹ç²¾åº¦ã€‚MOA æ•´åˆäº†åŸºäº TITAN åŸºç¡€æ¨¡å‹çš„ç»„ç»‡å­¦åˆ†æå·¥å…·ï¼Œå¹¶èƒ½ç»“åˆ PubMedã€Google Search å’Œ OncoKB ç­‰å¤–éƒ¨çŸ¥è¯†åº“å¯¹ä¸´åºŠåŠåŸºå› ç»„æ•°æ®è¿›è¡Œæ¨ç†ã€‚åœ¨é’ˆå¯¹ TCGA-LGG é˜Ÿåˆ— 488 åæ‚£è€…çš„è¯„ä¼°ä¸­ï¼ŒMOA ä¸ç»„ç»‡å­¦ç‰¹å¾èåˆåè¾¾åˆ°äº† 0.912 çš„æœ€é«˜ F1-scoreï¼Œæ˜¾è‘—ä¼˜äºå•ä¸€ç»„ç»‡å­¦åŸºçº¿åŠä¸´åºŠ-ç»„ç»‡å­¦èåˆåŸºçº¿ã€‚å³ä¾¿åœ¨ä¸ä½¿ç”¨ç»„ç»‡å­¦å·¥å…·çš„æƒ…å†µä¸‹ï¼ŒMOA çš„é¢„æµ‹è¡¨ç°ä¹Ÿè¶…è¶Šäº†ä¼ ç»Ÿä¸´åºŠåŸºçº¿ã€‚è¯¥æˆæœè¯æ˜äº† MOA èƒ½å¤Ÿä»å¤–éƒ¨ç”Ÿç‰©åŒ»å­¦èµ„æºä¸­æå–äº’è¡¥çš„çªå˜ç›¸å…³ä¿¡æ¯ï¼Œä¸ºå®ç°é«˜ç²¾åº¦çš„ IDH1 çªå˜é¢„æµ‹æä¾›äº†æœ‰æ•ˆä¸”å…·æœ‰è§£é‡ŠåŠ›çš„æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "4 pages, 2 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.05824v1",
      "published_date": "2025-12-05 15:43:02 UTC",
      "updated_date": "2025-12-05 15:43:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:00:26.977045+00:00"
    },
    {
      "arxiv_id": "2512.05809v1",
      "title": "Probing the effectiveness of World Models for Spatial Reasoning through Test-time Scaling",
      "title_zh": "é€šè¿‡æµ‹è¯•æ—¶ç¼©æ”¾æ¢ç©¶ä¸–ç•Œæ¨¡å‹åœ¨ç©ºé—´æ¨ç†ä¸­çš„æœ‰æ•ˆæ€§",
      "authors": [
        "Saurav Jha",
        "M. Jehanzeb Mirza",
        "Wei Lin",
        "Shiqi Yang",
        "Sarath Chandar"
      ],
      "abstract": "Vision-Language Models (VLMs) remain limited in spatial reasoning tasks that require multi-view understanding and embodied perspective shifts. Recent approaches such as MindJourney attempt to mitigate this gap through test-time scaling where a world model imagines action-conditioned trajectories and a heuristic verifier selects helpful views from such trajectories. In this work, we systematically examine how such test-time verifiers behave across benchmarks, uncovering both their promise and their pitfalls. Our uncertainty-based analyses show that MindJourney's verifier provides little meaningful calibration, and that random scoring often reduces answer entropy equally well, thus exposing systematic action biases and unreliable reward signals. To mitigate these, we introduce a Verification through Spatial Assertions (ViSA) framework that grounds the test-time reward in verifiable, frame-anchored micro-claims. This principled verifier consistently improves spatial reasoning on the SAT-Real benchmark and corrects trajectory-selection biases through more balanced exploratory behavior. However, on the challenging MMSI-Bench, none of the verifiers, including ours, achieve consistent scaling, suggesting that the current world models form an information bottleneck where imagined views fail to enrich fine-grained reasoning. Together, these findings chart the bad, good, and ugly aspects of test-time verification for world-model-based reasoning. Our code is available at https://github.com/chandar-lab/visa-for-mindjourney.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ä¸–ç•Œæ¨¡å‹(World Models)é€šè¿‡æµ‹è¯•æ—¶ç¼©æ”¾(Test-time Scaling)åœ¨æå‡è§†è§‰è¯­è¨€æ¨¡å‹(VLMs)ç©ºé—´æ¨ç†èƒ½åŠ›æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚é€šè¿‡å¯¹MindJourneyç­‰ç°æœ‰æ–¹æ³•çš„åˆ†æï¼Œç ”ç©¶è€…å‘ç°å…¶å¯å‘å¼éªŒè¯å™¨ç¼ºä¹æœ‰æ•ˆæ ¡å‡†ï¼Œä¸”éšæœºè¯„åˆ†å¾€å¾€èƒ½äº§ç”Ÿç±»ä¼¼çš„ç†µå‡ï¼Œæš´éœ²äº†ç³»ç»Ÿæ€§çš„åŠ¨ä½œåå·®å’Œä¸å¯é çš„å¥–åŠ±ä¿¡å·ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†ç©ºé—´æ–­è¨€éªŒè¯(Verification through Spatial Assertions, ViSA)æ¡†æ¶ï¼Œé€šè¿‡å°†æµ‹è¯•æ—¶å¥–åŠ±å»ºç«‹åœ¨å¯éªŒè¯çš„ã€é”šå®šäºå¸§çš„å¾®è§‚æ–­è¨€(micro-claims)ä¸Šï¼Œåœ¨SAT-RealåŸºå‡†æµ‹è¯•ä¸­æŒç»­æå‡äº†æ¨ç†æ€§èƒ½å¹¶çº æ­£äº†è½¨è¿¹é€‰æ‹©åå·®ã€‚ç„¶è€Œåœ¨æ›´å…·æŒ‘æˆ˜æ€§çš„MMSI-Benchä¸Šï¼Œæ‰€æœ‰éªŒè¯å™¨å‡æœªèƒ½å®ç°æŒç»­ç¼©æ”¾ï¼Œè¿™è¡¨æ˜å½“å‰çš„ä¸–ç•Œæ¨¡å‹åœ¨ç»†ç²’åº¦æ¨ç†ä¸­å­˜åœ¨ä¿¡æ¯ç“¶é¢ˆ(information bottleneck)ã€‚è¯¥å·¥ä½œé€šè¿‡å…¨é¢è¯„ä¼°æµ‹è¯•æ—¶éªŒè¯çš„æœ‰æ•ˆæ€§ï¼Œä¸ºæœªæ¥åŸºäºä¸–ç•Œæ¨¡å‹çš„å…·èº«ç©ºé—´æ¨ç†ç ”ç©¶æä¾›äº†é‡è¦è§è§£ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Extended abstract at World Modeling Workshop 2026",
      "pdf_url": "https://arxiv.org/pdf/2512.05809v1",
      "published_date": "2025-12-05 15:30:08 UTC",
      "updated_date": "2025-12-05 15:30:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:59:30.465016+00:00"
    },
    {
      "arxiv_id": "2512.05803v1",
      "title": "3D Path Planning for Robot-assisted Vertebroplasty from Arbitrary Bi-plane X-ray via Differentiable Rendering",
      "title_zh": "åŸºäºå¯å¾®æ¸²æŸ“çš„ä»»æ„åŒå¹³é¢ X å°„çº¿æœºå™¨äººè¾…åŠ©æ¤ä½“æˆå½¢æœ¯ä¸‰ç»´è·¯å¾„è§„åˆ’",
      "authors": [
        "Blanca Inigo",
        "Benjamin D. Killeen",
        "Rebecca Choi",
        "Michelle Song",
        "Ali Uneri",
        "Majid Khan",
        "Christopher Bailey",
        "Axel Krieger",
        "Mathias Unberath"
      ],
      "abstract": "Robotic systems are transforming image-guided interventions by enhancing accuracy and minimizing radiation exposure. A significant challenge in robotic assistance lies in surgical path planning, which often relies on the registration of intraoperative 2D images with preoperative 3D CT scans. This requirement can be burdensome and costly, particularly in procedures like vertebroplasty, where preoperative CT scans are not routinely performed. To address this issue, we introduce a differentiable rendering-based framework for 3D transpedicular path planning utilizing bi-planar 2D X-rays. Our method integrates differentiable rendering with a vertebral atlas generated through a Statistical Shape Model (SSM) and employs a learned similarity loss to refine the SSM shape and pose dynamically, independent of fixed imaging geometries. We evaluated our framework in two stages: first, through vertebral reconstruction from orthogonal X-rays for benchmarking, and second, via clinician-in-the-loop path planning using arbitrary-view X-rays. Our results indicate that our method outperformed a normalized cross-correlation baseline in reconstruction metrics (DICE: 0.75 vs. 0.65) and achieved comparable performance to the state-of-the-art model ReVerteR (DICE: 0.77), while maintaining generalization to arbitrary views. Success rates for bipedicular planning reached 82% with synthetic data and 75% with cadaver data, exceeding the 66% and 31% rates of a 2D-to-3D baseline, respectively. In conclusion, our framework facilitates versatile, CT-free 3D path planning for robot-assisted vertebroplasty, effectively accommodating real-world imaging diversity without the need for preoperative CT scans.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æœºå™¨äººè¾…åŠ©æ¤ä½“æˆå½¢æœ¯(Vertebroplasty)ä¸­ä¼ ç»Ÿä¸‰ç»´è·¯å¾„è§„åˆ’ä¾èµ–æœ¯å‰3D CTæ‰«æè€Œå¸¦æ¥çš„é«˜æˆæœ¬ä¸æµç¨‹å¤æ‚ç­‰é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºå¯å¾®åˆ†æ¸²æŸ“(Differentiable Rendering)çš„ä¸‰ç»´ç»çš®è·¯å¾„è§„åˆ’æ¡†æ¶ã€‚è¯¥æ–¹æ³•é€šè¿‡å°†å¯å¾®åˆ†æ¸²æŸ“æŠ€æœ¯ä¸åŸºäºç»Ÿè®¡å½¢çŠ¶æ¨¡å‹(Statistical Shape Model, SSM)ç”Ÿæˆçš„æ¤ä½“å›¾è°±ç›¸ç»“åˆï¼Œå¹¶åˆ©ç”¨å­¦ä¹ åˆ°çš„ç›¸ä¼¼æ€§æŸå¤±(Learned Similarity Loss)åŠ¨æ€ä¼˜åŒ–SSMçš„å½¢çŠ¶ä¸å§¿æ€ï¼Œä»è€Œå®ç°äº†åœ¨ä¸ä¾èµ–å›ºå®šå½±åƒå‡ ä½•ç»“æ„çš„æƒ…å†µä¸‹ä»ä»»æ„åŒå¹³é¢2D X-rayå›¾åƒä¸­è¿›è¡Œè§„åˆ’ã€‚ç ”ç©¶é€šè¿‡æ­£äº¤X-rayæ¤ä½“é‡å»ºåŸºå‡†æµ‹è¯•å’ŒåŸºäºä»»æ„è§†è§’X-rayçš„ä¸´åºŠåŒ»ç”Ÿå‚ä¸å¼è·¯å¾„è§„åˆ’ä¸¤ä¸ªé˜¶æ®µå¯¹æ¡†æ¶è¿›è¡Œäº†è¯„ä¼°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨é‡å»ºæŒ‡æ ‡ä¸Šä¼˜äºäº’ç›¸å…³åŸºçº¿(DICE: 0.75 vs. 0.65)ï¼Œå¹¶è¾¾åˆ°äº†ä¸æœ€å…ˆè¿›æ¨¡å‹ReVerteR(DICE: 0.77)ç›¸å½“çš„æ€§èƒ½ï¼ŒåŒæ—¶ä¿æŒäº†å¯¹ä»»æ„è§†è§’çš„æ³›åŒ–èƒ½åŠ›ã€‚åœ¨åŒä¾§æ¤å¼“æ ¹è§„åˆ’(Bipedicular Planning)çš„æˆåŠŸç‡æ–¹é¢ï¼Œåˆæˆæ•°æ®è¾¾åˆ°äº†82%ï¼Œå°¸ä½“æ•°æ®è¾¾åˆ°äº†75%ï¼Œæ˜¾è‘—è¶…è¿‡äº†ä¼ ç»Ÿ2D-to-3DåŸºå‡†æ¨¡å‹ã€‚è¯¥æ¡†æ¶ä¸ºæœºå™¨äººè¾…åŠ©æ¤ä½“æˆå½¢æœ¯æä¾›äº†ä¸€ç§å¤šåŠŸèƒ½ã€æ— éœ€CT(CT-free)çš„3Dè·¯å¾„è§„åˆ’æ–¹æ¡ˆï¼Œèƒ½å¤Ÿæœ‰æ•ˆåº”å¯¹çœŸå®æ‰‹æœ¯ç¯å¢ƒä¸­å½±åƒçš„å¤šæ ·æ€§ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.05803v1",
      "published_date": "2025-12-05 15:26:13 UTC",
      "updated_date": "2025-12-05 15:26:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:59:36.736373+00:00"
    },
    {
      "arxiv_id": "2512.05794v1",
      "title": "Mechanistic Interpretability of Antibody Language Models Using SAEs",
      "title_zh": "åŸºäº SAE çš„æŠ—ä½“è¯­è¨€æ¨¡å‹æœºæ¢°å¯è§£é‡Šæ€§",
      "authors": [
        "Rebonto Haque",
        "Oliver M. Turnbull",
        "Anisha Parsan",
        "Nithin Parsan",
        "John J. Yang",
        "Charlotte M. Deane"
      ],
      "abstract": "Sparse autoencoders (SAEs) are a mechanistic interpretability technique that have been used to provide insight into learned concepts within large protein language models. Here, we employ TopK and Ordered SAEs to investigate an autoregressive antibody language model, p-IgGen, and steer its generation. We show that TopK SAEs can reveal biologically meaningful latent features, but high feature concept correlation does not guarantee causal control over generation. In contrast, Ordered SAEs impose an hierarchical structure that reliably identifies steerable features, but at the expense of more complex and less interpretable activation patterns. These findings advance the mechanistic interpretability of domain-specific protein language models and suggest that, while TopK SAEs are sufficient for mapping latent features to concepts, Ordered SAEs are preferable when precise generative steering is required.",
      "tldr_zh": "è¯¥ç ”ç©¶åˆ©ç”¨ç¨€ç–è‡ªåŠ¨ç¼–ç å™¨(SAEs)å¯¹è‡ªå›å½’æŠ—ä½“è¯­è¨€æ¨¡å‹ p-IgGen è¿›è¡Œäº†æœºæ¢°å¯è§£é‡Šæ€§(Mechanistic Interpretability)åˆ†æï¼Œæ—¨åœ¨æ¢ç´¢å…¶å†…éƒ¨å­¦ä¹ æ¦‚å¿µå¹¶å¼•å¯¼åºåˆ—ç”Ÿæˆã€‚é€šè¿‡å¯¹æ¯” TopK SAEs å’Œ Ordered SAEsï¼Œç ”ç©¶å‘ç° TopK SAEs è™½ç„¶èƒ½æ­ç¤ºå…·æœ‰ç”Ÿç‰©å­¦æ„ä¹‰çš„æ½œåœ¨ç‰¹å¾ï¼Œä½†ç‰¹å¾ä¸æ¦‚å¿µçš„é«˜ç›¸å…³æ€§å¹¶ä¸è¶³ä»¥ä¿è¯å¯¹ç”Ÿæˆçš„å› æœæ§åˆ¶ã€‚ä¸ä¹‹ä¸åŒï¼ŒOrdered SAEs å‡­å€Ÿå…¶å±‚æ¬¡åŒ–ç»“æ„èƒ½å¤Ÿæ›´å¯é åœ°è¯†åˆ«å‡ºå¯å¼•å¯¼çš„ç‰¹å¾ï¼Œå°½ç®¡å…¶æ¿€æ´»æ¨¡å¼åœ¨è§£é‡Šä¸Šæ›´ä¸ºå¤æ‚ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼ŒTopK SAEs é€‚ç”¨äºå°†æ½œåœ¨ç‰¹å¾æ˜ å°„åˆ°å…·ä½“æ¦‚å¿µï¼Œè€Œåœ¨éœ€è¦ç²¾ç¡®ç”Ÿæˆå¼•å¯¼(Generative Steering)çš„åœºæ™¯ä¸‹ï¼ŒOrdered SAEs è¡¨ç°æ›´ä¼˜ã€‚è¿™äº›å‘ç°æ˜¾è‘—æå‡äº†é¢†åŸŸç‰¹å®šè›‹ç™½è´¨è¯­è¨€æ¨¡å‹çš„å¯è§£é‡Šæ€§ï¼Œä¸ºæŠ—ä½“åºåˆ—çš„ç²¾å‡†è®¾è®¡æä¾›äº†ç†è®ºæ”¯æŒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.05794v1",
      "published_date": "2025-12-05 15:18:50 UTC",
      "updated_date": "2025-12-05 15:18:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:59:59.307109+00:00"
    },
    {
      "arxiv_id": "2512.11867v1",
      "title": "On the Dangers of Bootstrapping Generation for Continual Learning and Beyond",
      "title_zh": "è®ºæŒç»­å­¦ä¹ åŠç›¸å…³é¢†åŸŸä¸­è‡ªä¸¾å¼ç”Ÿæˆçš„é£é™©",
      "authors": [
        "Daniil Zverev",
        "A. Sophia Koepke",
        "Joao F. Henriques"
      ],
      "abstract": "The use of synthetically generated data for training models is becoming a common practice. While generated data can augment the training data, repeated training on synthetic data raises concerns about distribution drift and degradation of performance due to contamination of the dataset. We investigate the consequences of this bootstrapping process through the lens of continual learning, drawing a connection to Generative Experience Replay (GER) methods. We present a statistical analysis showing that synthetic data introduces significant bias and variance into training objectives, weakening the reliability of maximum likelihood estimation. We provide empirical evidence showing that popular generative models collapse under repeated training with synthetic data. We quantify this degradation and show that state-of-the-art GER methods fail to maintain alignment in the latent space. Our findings raise critical concerns about the use of synthetic data in continual learning.",
      "tldr_zh": "è¯¥ç ”ç©¶é€šè¿‡æŒç»­å­¦ä¹ ï¼ˆContinual Learningï¼‰å’Œç”Ÿæˆå¼ç»éªŒå›æ”¾ï¼ˆGenerative Experience Replay, GERï¼‰çš„è§†è§’ï¼Œæ·±å…¥æ¢è®¨äº†åˆ©ç”¨åˆæˆæ•°æ®è¿›è¡Œæ¨¡å‹è®­ç»ƒæ‰€å¸¦æ¥çš„æ½œåœ¨é£é™©ã€‚ç ”ç©¶è¡¨æ˜ï¼Œåœ¨åˆæˆæ•°æ®ä¸Šé‡å¤è®­ç»ƒçš„å¼•å¯¼è¿‡ç¨‹ï¼ˆBootstrapping processï¼‰ä¼šå¯¼è‡´åˆ†å¸ƒåç§»å’Œæ€§èƒ½é€€åŒ–ï¼Œè¿™ä¸»è¦æºäºæ•°æ®é›†çš„æ±¡æŸ“ã€‚é€šè¿‡ç»Ÿè®¡åˆ†æï¼Œä½œè€…æ­ç¤ºäº†åˆæˆæ•°æ®ä¸ºè®­ç»ƒç›®æ ‡å¼•å…¥äº†æ˜¾è‘—çš„åå·®å’Œæ–¹å·®ï¼Œæ˜¾è‘—å‰Šå¼±äº†æå¤§ä¼¼ç„¶ä¼°è®¡ï¼ˆMaximum Likelihood Estimation, MLEï¼‰çš„å¯é æ€§ã€‚å®éªŒè¯æ®è¿›ä¸€æ­¥è¯å®ï¼Œä¸»æµç”Ÿæˆæ¨¡å‹åœ¨åˆæˆæ•°æ®çš„å¾ªç¯è®­ç»ƒä¸‹ä¼šå‡ºç°æ¨¡å‹å´©æºƒï¼ˆmodel collapseï¼‰ã€‚æ­¤å¤–ï¼Œç ”ç©¶é‡åŒ–äº†è¿™ç§é€€åŒ–è¿‡ç¨‹ï¼Œå‘ç°ç°æœ‰çš„å…ˆè¿› GER æ–¹æ³•éš¾ä»¥åœ¨æ½œåœ¨ç©ºé—´ï¼ˆlatent spaceï¼‰ä¸­ç»´æŒå¯¹é½ã€‚è¿™äº›å‘ç°å¯¹æŒç»­å­¦ä¹ ä¸­åˆæˆæ•°æ®çš„å¹¿æ³›åº”ç”¨æå‡ºäº†è´¨ç–‘ï¼Œå¼ºè°ƒäº†å…¶åœ¨ç»´æŒæ¨¡å‹é•¿æœŸæ€§èƒ½æ–¹é¢çš„å±€é™æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "eess.IV"
      ],
      "primary_category": "cs.LG",
      "comment": "DAGM German Conference on Pattern Recognition, 2025",
      "pdf_url": "https://arxiv.org/pdf/2512.11867v1",
      "published_date": "2025-12-05 15:16:30 UTC",
      "updated_date": "2025-12-05 15:16:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:00:49.567473+00:00"
    },
    {
      "arxiv_id": "2512.11865v1",
      "title": "Explainable Adversarial-Robust Vision-Language-Action Model for Robotic Manipulation",
      "title_zh": "é¢å‘æœºå™¨äººæ“æ§çš„å¯è§£é‡Šä¸”å…·å¯¹æŠ—é²æ£’æ€§çš„è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹",
      "authors": [
        "Ju-Young Kim",
        "Ji-Hong Park",
        "Myeongjun Kim",
        "Gun-Woo Kim"
      ],
      "abstract": "Smart farming has emerged as a key technology for advancing modern agriculture through automation and intelligent control. However, systems relying on RGB cameras for perception and robotic manipulators for control, common in smart farming, are vulnerable to photometric perturbations such as hue, illumination, and noise changes, which can cause malfunction under adversarial attacks. To address this issue, we propose an explainable adversarial-robust Vision-Language-Action model based on the OpenVLA-OFT framework. The model integrates an Evidence-3 module that detects photometric perturbations and generates natural language explanations of their causes and effects. Experiments show that the proposed model reduces Current Action L1 loss by 21.7% and Next Actions L1 loss by 18.4% compared to the baseline, demonstrating improved action prediction accuracy and explainability under adversarial conditions.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ™ºæ…§å†œä¸šä¸­åŸºäºRGBç›¸æœºæ„ŸçŸ¥å’Œæœºå™¨äººæ“ä½œç³»ç»Ÿçš„è„†å¼±æ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨è‰²è°ƒã€å…‰ç…§å’Œå™ªå£°ç­‰å…‰åº¦æ‰°åŠ¨(photometric perturbations)ä¸‹æ˜“å—å¯¹æŠ—æ”»å‡»çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºOpenVLA-OFTæ¡†æ¶çš„å¯è§£é‡Šå¯¹æŠ—é²æ£’è§†è§‰-è¯­è¨€-åŠ¨ä½œ(Vision-Language-Action)æ¨¡å‹ã€‚è¯¥æ¨¡å‹åˆ›æ–°æ€§åœ°é›†æˆäº†Evidence-3æ¨¡å—ï¼Œç”¨äºå®æ—¶æ£€æµ‹å…‰åº¦æ‰°åŠ¨å¹¶ç”Ÿæˆå…³äºå…¶æˆå› ä¸å½±å“çš„è‡ªç„¶è¯­è¨€è§£é‡Šã€‚å®éªŒæ•°æ®è¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨Current Action L1 lossä¸Šæ¯”åŸºçº¿é™ä½äº†21.7%ï¼Œåœ¨Next Actions L1 lossä¸Šé™ä½äº†18.4%ã€‚è¿™ä¸ä»…è¯æ˜äº†æ¨¡å‹åœ¨å¯¹æŠ—æ¡ä»¶ä¸‹å…·æœ‰æ›´é«˜çš„åŠ¨ä½œé¢„æµ‹å‡†ç¡®ç‡ï¼Œè¿˜é€šè¿‡è‡ªç„¶è¯­è¨€åé¦ˆæå‡äº†ç³»ç»Ÿçš„å¯è§£é‡Šæ€§ã€‚è¯¥æˆæœä¸ºç°ä»£å†œä¸šè‡ªåŠ¨åŒ–åœ¨å¤æ‚åŠ¨æ€ç¯å¢ƒä¸‹çš„ç¨³å®šè¿è¡Œæä¾›äº†é‡è¦çš„æŠ€æœ¯æ”¯æŒã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to MobieSec 2025 (poster session)",
      "pdf_url": "https://arxiv.org/pdf/2512.11865v1",
      "published_date": "2025-12-05 15:06:18 UTC",
      "updated_date": "2025-12-05 15:06:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T13:59:50.360350+00:00"
    },
    {
      "arxiv_id": "2512.05774v1",
      "title": "Active Video Perception: Iterative Evidence Seeking for Agentic Long Video Understanding",
      "title_zh": "ä¸»åŠ¨è§†é¢‘æ„ŸçŸ¥ï¼šé¢å‘æ™ºèƒ½ä½“åŒ–é•¿è§†é¢‘ç†è§£çš„è¿­ä»£å¼è¯æ®æœå¯»",
      "authors": [
        "Ziyang Wang",
        "Honglu Zhou",
        "Shijie Wang",
        "Junnan Li",
        "Caiming Xiong",
        "Silvio Savarese",
        "Mohit Bansal",
        "Michael S. Ryoo",
        "Juan Carlos Niebles"
      ],
      "abstract": "Long video understanding (LVU) is challenging because answering real-world queries often depends on sparse, temporally dispersed cues buried in hours of mostly redundant and irrelevant content. While agentic pipelines improve video reasoning capabilities, prevailing frameworks rely on a query-agnostic captioner to perceive video information, which wastes computation on irrelevant content and blurs fine-grained temporal and spatial information. Motivated by active perception theory, we argue that LVU agents should actively decide what, when, and where to observe, and continuously assess whether the current observation is sufficient to answer the query. We present Active Video Perception (AVP), an evidence-seeking framework that treats the video as an interactive environment and acquires compact, queryrelevant evidence directly from pixels. Concretely, AVP runs an iterative plan-observe-reflect process with MLLM agents. In each round, a planner proposes targeted video interactions, an observer executes them to extract time-stamped evidence, and a reflector evaluates the sufficiency of the evidence for the query, either halting with an answer or triggering further observation. Across five LVU benchmarks, AVP achieves highest performance with significant improvements. Notably, AVP outperforms the best agentic method by 5.7% in average accuracy while only requires 18.4% inference time and 12.4% input tokens.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é•¿è§†é¢‘ç†è§£(Long video understanding, LVU)ä¸­å…³é”®ä¿¡æ¯ç¨€ç–ä¸”åˆ†æ•£çš„æŒ‘æˆ˜ï¼ŒæŒ‡å‡ºå½“å‰æ™ºèƒ½ä½“æ¡†æ¶è¿‡åº¦ä¾èµ–æŸ¥è¯¢æ— å…³çš„æ„ŸçŸ¥æ–¹å¼ä¼šå¯¼è‡´è®¡ç®—å†—ä½™å’Œç»†èŠ‚ä¸¢å¤±ã€‚å—åˆ°ä¸»åŠ¨æ„ŸçŸ¥(active perception)ç†è®ºå¯å‘ï¼Œä½œè€…æå‡ºäº†Active Video Perception (AVP)è¯æ®å¯»æ±‚æ¡†æ¶ï¼Œå°†è§†é¢‘è§†ä¸ºäº¤äº’å¼ç¯å¢ƒå¹¶ç›´æ¥ä»åƒç´ ä¸­è·å–ç´§å‡‘ä¸”ç›¸å…³çš„è¯æ®ã€‚è¯¥æ¡†æ¶åˆ©ç”¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLM)æ™ºèƒ½ä½“æ‰§è¡Œè¿­ä»£çš„â€œè§„åˆ’-è§‚å¯Ÿ-åå°„â€(plan-observe-reflect)æµç¨‹ï¼Œé€šè¿‡å„ç»„ä»¶åä½œç²¾å‡†æå–å¸¦æ—¶é—´æˆ³çš„è¯æ®å¹¶è¯„ä¼°ä¿¡æ¯å……åˆ†æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒAVPåœ¨äº”ä¸ªLVUåŸºå‡†æµ‹è¯•ä¸­å‡å–å¾—äº†æœ€ä¼˜æ€§èƒ½ï¼Œå…¶å¹³å‡å‡†ç¡®ç‡æ¯”ç°æœ‰æœ€ä½³æ™ºèƒ½ä½“æ–¹æ³•é«˜å‡º5.7%ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒAVPåœ¨æ˜¾è‘—æå‡å‡†ç¡®ç‡çš„åŒæ—¶ï¼Œä»…éœ€18.4%çš„æ¨ç†æ—¶é—´å’Œ12.4%çš„è¾“å…¥Tokenï¼Œå¤§å¹…ä¼˜åŒ–äº†é•¿è§†é¢‘ç†è§£çš„æ•ˆç‡ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Website: https://activevideoperception.github.io/",
      "pdf_url": "https://arxiv.org/pdf/2512.05774v1",
      "published_date": "2025-12-05 15:03:48 UTC",
      "updated_date": "2025-12-05 15:03:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:01:03.891338+00:00"
    },
    {
      "arxiv_id": "2512.05765v1",
      "title": "The Missing Layer of AGI: From Pattern Alchemy to Coordination Physics",
      "title_zh": "AGI ç¼ºå¤±çš„å±‚çº§ï¼šä»æ¨¡å¼ç‚¼é‡‘æœ¯åˆ°ååŒç‰©ç†å­¦",
      "authors": [
        "Edward Y. Chang"
      ],
      "abstract": "Influential critiques argue that Large Language Models (LLMs) are a dead end for AGI: \"mere pattern matchers\" structurally incapable of reasoning or planning. We argue this conclusion misidentifies the bottleneck: it confuses the ocean with the net. Pattern repositories are the necessary System-1 substrate; the missing component is a System-2 coordination layer that selects, constrains, and binds these patterns. We formalize this layer via UCCT, a theory of semantic anchoring that models reasoning as a phase transition governed by effective support (rho_d), representational mismatch (d_r), and an adaptive anchoring budget (gamma log k). Under this lens, ungrounded generation is simply an unbaited retrieval of the substrate's maximum likelihood prior, while \"reasoning\" emerges when anchors shift the posterior toward goal-directed constraints. We translate UCCT into architecture with MACI, a coordination stack that implements baiting (behavior-modulated debate), filtering (Socratic judging), and persistence (transactional memory). By reframing common objections as testable coordination failures, we argue that the path to AGI runs through LLMs, not around them.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)ä»…æ˜¯â€œæ¨¡å¼åŒ¹é…å™¨â€è€Œæ— æ³•å®ç°é€šç”¨äººå·¥æ™ºèƒ½(AGI)çš„æ‰¹è¯„ï¼Œæå‡ºé—®é¢˜çš„æ ¸å¿ƒåœ¨äºç¼ºå°‘ä¸€ä¸ªèƒ½å¤Ÿé€‰æ‹©ã€çº¦æŸå’Œç»‘å®šæ¨¡å¼çš„System-2åè°ƒå±‚ã€‚ä½œè€…é€šè¿‡è¯­ä¹‰é”šå®šç†è®ºUCCTå°†è¯¥å±‚å½¢å¼åŒ–ï¼Œå°†æ¨ç†å®šä¹‰ä¸ºä¸€ç§å—æœ‰æ•ˆæ”¯æŒ(rho_d)ã€è¡¨ç¤ºå¤±é…(d_r)å’Œè‡ªé€‚åº”é”šå®šé¢„ç®—(gamma log k)è°ƒèŠ‚çš„ç›¸å˜è¿‡ç¨‹ã€‚åœ¨è¯¥æ¡†æ¶ä¸‹ï¼Œæ— æ ¹æ®çš„ç”Ÿæˆè¢«è§†ä¸ºå¯¹åº•å±‚æœ€å¤§ä¼¼ç„¶å…ˆéªŒçš„æ£€ç´¢ï¼Œè€Œæ¨ç†åˆ™æºäºé”šå®šç‚¹å°†åéªŒæ¦‚ç‡å¼•å¯¼è‡³ç›®æ ‡å¯¼å‘çš„çº¦æŸã€‚ç ”ç©¶è¿›ä¸€æ­¥æå‡ºäº†åä¸ºMACIçš„åè°ƒæ¶æ„ï¼Œé€šè¿‡è¯±å¯¼(baiting)ã€è¿‡æ»¤(filtering)å’ŒæŒä¹…åŒ–(persistence)ç­‰æœºåˆ¶å°†ç†è®ºè½¬åŒ–ä¸ºå®é™…æŠ€æœ¯æ ˆã€‚é€šè¿‡å°†é’ˆå¯¹LLMsçš„å¸¸è§è´¨ç–‘é‡æ„ä¸ºå¯æµ‹è¯•çš„åè°ƒå¤±è´¥é—®é¢˜ï¼Œè¯¥è®ºæ–‡æœ‰åŠ›åœ°è®ºè¯äº†é€šå¾€AGIçš„è·¯å¾„åº”å½“å»ºç«‹åœ¨LLMsä¹‹ä¸Šã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.05765v1",
      "published_date": "2025-12-05 14:51:17 UTC",
      "updated_date": "2025-12-05 14:51:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:01:11.476812+00:00"
    },
    {
      "arxiv_id": "2512.05760v1",
      "title": "Evolutionary System 2 Reasoning: An Empirical Proof",
      "title_zh": "è¿›åŒ–å¼ç³»ç»Ÿ 2 æ¨ç†ï¼šä¸€é¡¹å®è¯è¯æ˜",
      "authors": [
        "Zeyuan Ma",
        "Wenqi Huang",
        "Guo-Huan Song",
        "Hongshu Guo",
        "Sijie Ma",
        "Zhiguang Cao",
        "Yue-Jiao Gong"
      ],
      "abstract": "Machine intelligence marks the ultimate dream of making machines' intelligence comparable to human beings. While recent progress in Large Language Models (LLMs) show substantial specific skills for a wide array of downstream tasks, they more or less fall shorts in general intelligence. Following correlation between intelligence and system 2 reasoning (slow thinking), in this paper, we aim to answering a worthwhile research question: could machine intelligence such as LLMs be evolved to acquire reasoning ability (not specific skill) just like our human beings? To this end, we propose evolutionary reasoning optimization (ERO) framework which performs survival of the fittest over a population of LLMs to search for individual with strong reasoning ability. Given a reasoning task, ERO first initializes multiple LLMs as a population, after which an evolutionary strategy evolves the population to maximize quantified reasoning score of the best individual. Based on experiments on representative testsuites, we claim two surprising empirical discoveries: i) the latest LLMs such as GPT-5 still show limited system 2 reasoning ability; ii) with simple evolution-loop of ERO, a relatively weak model (Qwen-7B) could be enhanced to emerge powerful reasoning ability. Our project can be accessed at https://github.com/MetaEvo/ERO for reproduction needs.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨System 2 reasoningï¼ˆæ…¢é€Ÿæ€è€ƒï¼‰æ–¹é¢çš„å±€é™æ€§ï¼Œå¹¶æå‡ºäº†è¿›åŒ–æ¨ç†ä¼˜åŒ–(Evolutionary Reasoning Optimization, ERO)æ¡†æ¶ã€‚EROæ¡†æ¶é€šè¿‡æ¨¡æ‹Ÿâ€œé€‚è€…ç”Ÿå­˜â€çš„è¿›åŒ–ç­–ç•¥ï¼Œåœ¨LLMç§ç¾¤ä¸­è¿›è¡Œå¤šè½®è¿›åŒ–è¿­ä»£ï¼Œä»¥æœç´¢å¹¶ä¼˜åŒ–å…·å¤‡å¼ºæ¨ç†èƒ½åŠ›çš„ä¸ªä½“ï¼Œæ—¨åœ¨ä½¿æœºå™¨æ™ºèƒ½ä¹ å¾—é€šç”¨çš„æ¨ç†èƒ½åŠ›ã€‚å®éªŒç ”ç©¶å¾—å‡ºäº†ä¸¤ä¸ªé‡è¦çš„å®è¯å‘ç°ï¼šä¸€æ˜¯å³ä¾¿æ˜¯ç›®å‰æœ€å…ˆè¿›çš„LLMsåœ¨System 2 reasoningæ–¹é¢ä»è¡¨ç°æœ‰é™ï¼›äºŒæ˜¯åˆ©ç”¨EROçš„ç®€å•è¿›åŒ–å¾ªç¯ï¼Œå³ä¾¿æ˜¯ä¸€ä¸ªç›¸å¯¹è¾ƒå¼±çš„æ¨¡å‹ï¼ˆå¦‚Qwen-7Bï¼‰ä¹Ÿèƒ½è¢«å¢å¼ºå¹¶æ¶Œç°å‡ºå¼ºå¤§çš„æ¨ç†èƒ½åŠ›ã€‚è¯¥ç ”ç©¶ä¸ºå¦‚ä½•é€šè¿‡è¿›åŒ–ç­–ç•¥æå‡æœºå™¨çš„é€šç”¨æ™ºèƒ½æä¾›äº†æ–°é¢–çš„è·¯å¾„ä¸è¯æ˜ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.05760v1",
      "published_date": "2025-12-05 14:47:57 UTC",
      "updated_date": "2025-12-05 14:47:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:01:27.696855+00:00"
    },
    {
      "arxiv_id": "2512.05753v2",
      "title": "A Fast Anti-Jamming Cognitive Radar Deployment Algorithm Based on Reinforcement Learning",
      "title_zh": "åŸºäºå¼ºåŒ–å­¦ä¹ çš„å¿«é€ŸæŠ—å¹²æ‰°è®¤çŸ¥é›·è¾¾éƒ¨ç½²ç®—æ³•",
      "authors": [
        "Wencheng Cai",
        "Xuchao Gao",
        "Congying Han",
        "Mingqiang Li",
        "Tiande Guo"
      ],
      "abstract": "The fast deployment of cognitive radar to counter jamming remains a critical challenge in modern warfare, where more efficient deployment leads to quicker detection of targets. Existing methods are primarily based on evolutionary algorithms, which are time-consuming and prone to falling into local optima. We tackle these drawbacks via the efficient inference of neural networks and propose a brand new framework: Fast Anti-Jamming Radar Deployment Algorithm (FARDA). We first model the radar deployment problem as an end-to-end task and design deep reinforcement learning algorithms to solve it, where we develop integrated neural modules to perceive heatmap information and a brand new reward format. Empirical results demonstrate that our method achieves coverage comparable to evolutionary algorithms while deploying radars approximately 7,000 times faster. Further ablation experiments confirm the necessity of each component of FARDA.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°ä»£æˆ˜äº‰ä¸­è®¤çŸ¥é›·è¾¾(cognitive radar)å¿«é€Ÿéƒ¨ç½²ä»¥å¯¹æŠ—å¹²æ‰°(jamming)çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†åä¸ºFARDAçš„å…¨æ–°å¿«é€ŸæŠ—å¹²æ‰°é›·è¾¾éƒ¨ç½²ç®—æ³•æ¡†æ¶ã€‚é’ˆå¯¹ç°æœ‰è¿›åŒ–ç®—æ³•(evolutionary algorithms)è€—æ—¶é•¿ä¸”æ˜“é™·å…¥å±€éƒ¨æœ€ä¼˜çš„ç¼ºé™·ï¼ŒFARDAå°†é›·è¾¾éƒ¨ç½²é—®é¢˜å»ºæ¨¡ä¸ºç«¯åˆ°ç«¯(end-to-end)ä»»åŠ¡ï¼Œå¹¶åˆ©ç”¨æ·±åº¦å¼ºåŒ–å­¦ä¹ (deep reinforcement learning)æŠ€æœ¯è¿›è¡Œé«˜æ•ˆæ¨ç†ã€‚è¯¥æ¡†æ¶é€šè¿‡é›†æˆçš„ç¥ç»æ¨¡å—æ„ŸçŸ¥çƒ­å›¾(heatmap)ä¿¡æ¯ï¼Œå¹¶å¼•å…¥äº†å…¨æ–°çš„å¥–åŠ±æ ¼å¼ä»¥ä¼˜åŒ–éƒ¨ç½²ç­–ç•¥ã€‚å®éªŒç»“æœè¯æ˜ï¼Œåœ¨è·å¾—ä¸è¿›åŒ–ç®—æ³•ç›¸å½“çš„è¦†ç›–ç‡çš„å‰æä¸‹ï¼ŒFARDAçš„éƒ¨ç½²é€Ÿåº¦æå‡äº†çº¦7,000å€ã€‚æ¶ˆèå®éªŒ(ablation experiments)è¿›ä¸€æ­¥ç¡®è®¤äº†è¯¥æ¡†æ¶ä¸­å„æ ¸å¿ƒç»„ä»¶å¯¹äºæå‡é›·è¾¾éƒ¨ç½²æ•ˆç‡å’Œæ€§èƒ½çš„å¿…è¦æ€§ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.05753v2",
      "published_date": "2025-12-05 14:39:50 UTC",
      "updated_date": "2026-01-05 08:40:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:01:13.157271+00:00"
    },
    {
      "arxiv_id": "2512.05734v1",
      "title": "KANFormer for Predicting Fill Probabilities via Survival Analysis in Limit Order Books",
      "title_zh": "KANFormerï¼šåŸºäºç”Ÿå­˜åˆ†æçš„é™ä»·è®¢å•ç°¿æˆäº¤æ¦‚ç‡é¢„æµ‹",
      "authors": [
        "Jinfeng Zhong",
        "Emmanuel Bacry",
        "Agathe Guilloux",
        "Jean-FranÃ§ois Muzy"
      ],
      "abstract": "This paper introduces KANFormer, a novel deep-learning-based model for predicting the time-to-fill of limit orders by leveraging both market- and agent-level information. KANFormer combines a Dilated Causal Convolutional network with a Transformer encoder, enhanced by Kolmogorov-Arnold Networks (KANs), which improve nonlinear approximation. Unlike existing models that rely solely on a series of snapshots of the limit order book, KANFormer integrates the actions of agents related to LOB dynamics and the position of the order in the queue to more effectively capture patterns related to execution likelihood. We evaluate the model using CAC 40 index futures data with labeled orders. The results show that KANFormer outperforms existing works in both calibration (Right-Censored Log-Likelihood, Integrated Brier Score) and discrimination (C-index, time-dependent AUC). We further analyze feature importance over time using SHAP (SHapley Additive exPlanations). Our results highlight the benefits of combining rich market signals with expressive neural architectures to achieve accurate and interpretabl predictions of fill probabilities.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸º KANFormer çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œæ—¨åœ¨é€šè¿‡ç”Ÿå­˜åˆ†æ (Survival Analysis) é¢„æµ‹é™ä»·è®¢å•ç°¿ (Limit Order Books, LOB) ä¸­è®¢å•çš„æˆäº¤æ—¶é—´ã€‚è¯¥æ¨¡å‹åˆ›æ–°æ€§åœ°ç»“åˆäº†æ‰©å¼ å› æœå·ç§¯ç½‘ç»œ (Dilated Causal Convolutional network) å’Œ Transformer ç¼–ç å™¨ï¼Œå¹¶å¼•å…¥ Kolmogorov-Arnold Networks (KANs) ä»¥æå‡éçº¿æ€§é€¼è¿‘èƒ½åŠ›ã€‚ä¸åŒäºä»…ä¾èµ–å¸‚åœºå¿«ç…§çš„ä¼ ç»Ÿæ¨¡å‹ï¼ŒKANFormer æ•´åˆäº†ä»£ç†è¡Œä¸ºåŠè®¢å•åœ¨é˜Ÿåˆ—ä¸­çš„ä½ç½®ä¿¡æ¯ï¼Œä»è€Œæ›´ç²¾å‡†åœ°æ•æ‰æ‰§è¡Œæ¦‚ç‡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨ CAC 40 æŒ‡æ•°æœŸè´§æ•°æ®é›†ä¸Šï¼Œè¯¥æ¨¡å‹åœ¨æ ¡å‡†åº¦æŒ‡æ ‡ï¼ˆå¦‚ Right-Censored Log-Likelihood å’Œ Integrated Brier Scoreï¼‰åŠåŒºåˆ†åº¦æŒ‡æ ‡ï¼ˆå¦‚ C-index å’Œ time-dependent AUCï¼‰æ–¹é¢å‡æ˜¾è‘—ä¼˜äºç°æœ‰åŸºå‡†ã€‚æœ€åï¼Œç ”ç©¶é€šè¿‡ SHAP (SHapley Additive exPlanations) è¿›è¡Œäº†ç‰¹å¾é‡è¦æ€§åˆ†æï¼Œè¯æ˜äº†ç»“åˆå¤šç»´åº¦å¸‚åœºä¿¡å·ä¸é«˜æ€§èƒ½ç¥ç»æ¶æ„å¯¹äºå®ç°å‡†ç¡®ä¸”å…·å¯è§£é‡Šæ€§çš„é¢„æµ‹è‡³å…³é‡è¦ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.05734v1",
      "published_date": "2025-12-05 14:15:02 UTC",
      "updated_date": "2025-12-05 14:15:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:01:18.380628+00:00"
    },
    {
      "arxiv_id": "2512.05732v1",
      "title": "Efficient Text Classification with Conformal In-Context Learning",
      "title_zh": "åŸºäºç¬¦åˆæ€§ä¸Šä¸‹æ–‡å­¦ä¹ çš„é«˜æ•ˆæ–‡æœ¬åˆ†ç±»",
      "authors": [
        "Ippokratis Pantelidis",
        "Korbinian Randl",
        "Aron Henriksson"
      ],
      "abstract": "Large Language Models (LLMs) demonstrate strong in-context learning abilities, yet their effectiveness in text classification depends heavily on prompt design and incurs substantial computational cost. Conformal In-Context Learning (CICLe) has been proposed as a resource-efficient framework that integrates a lightweight base classifier with Conformal Prediction to guide LLM prompting by adaptively reducing the set of candidate classes. However, its broader applicability and efficiency benefits beyond a single domain have not yet been systematically explored. In this paper, we present a comprehensive evaluation of CICLe across diverse NLP classification benchmarks. The results show that CICLe consistently improves over its base classifier and outperforms few-shot prompting baselines when the sample size is sufficient for training the base classifier, and performs comparably in low-data regimes. In terms of efficiency, CICLe reduces the number of shots and prompt length by up to 34.45% and 25.16%, respectively, and enables the use of smaller models with competitive performance. CICLe is furthermore particularly advantageous for text classification tasks with high class imbalance. These findings highlight CICLe as a practical and scalable approach for efficient text classification, combining the robustness of traditional classifiers with the adaptability of LLMs, and achieving substantial gains in data and computational efficiency.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº† Conformal In-Context Learning (CICLe) æ¡†æ¶ï¼Œè¿™æ˜¯ä¸€ç§ç»“åˆäº†è½»é‡çº§åŸºç¡€åˆ†ç±»å™¨ä¸ Conformal Prediction çš„èµ„æºé«˜æ•ˆå‹æ–‡æœ¬åˆ†ç±»æ–¹æ³•ï¼Œæ—¨åœ¨é€šè¿‡è‡ªé€‚åº”å‡å°‘å€™é€‰ç±»åˆ«æ¥ä¼˜åŒ– Large Language Models (LLMs) çš„æç¤ºè¿‡ç¨‹ã€‚æœ¬æ–‡é€šè¿‡å¯¹å¤šç§ NLP åˆ†ç±»åŸºå‡†æµ‹è¯•çš„å…¨é¢è¯„ä¼°ï¼Œè¯æ˜äº† CICLe åœ¨è®­ç»ƒæ•°æ®å……è¶³æ—¶å…¶æ€§èƒ½ä¼˜äºåŸºç¡€åˆ†ç±»å™¨åŠ Few-shot prompting åŸºå‡†æ¨¡å‹ï¼Œå¹¶åœ¨ä½æ•°æ®é‡åœºæ™¯ä¸‹è¡¨ç°å‡ºç›¸å½“çš„ç«äº‰åŠ›ã€‚åœ¨æ•ˆç‡æå‡æ–¹é¢ï¼ŒCICLe å¯å°† Few-shot æ ·æœ¬æ•°å’Œ Prompt length åˆ†åˆ«é™ä½å¤šè¾¾ 34.45% å’Œ 25.16%ï¼Œä»è€Œæ”¯æŒåœ¨æ›´å°è§„æ¨¡çš„æ¨¡å‹ä¸Šå®ç°åŒç­‰æ€§èƒ½ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶åœ¨å¤„ç†é«˜åº¦ç±»åˆ«ä¸å¹³è¡¡ (Class imbalance) çš„ä»»åŠ¡ä¸­è¡¨ç°å‡ºæ˜¾è‘—ä¼˜åŠ¿ã€‚ç»¼ä¸Šæ‰€è¿°ï¼ŒCICLe æˆåŠŸç»“åˆäº†ä¼ ç»Ÿåˆ†ç±»å™¨çš„ç¨³å¥æ€§ä¸ LLMs çš„é€‚åº”æ€§ï¼Œä¸ºå®ç°é«˜æ•ˆã€å¯æ‰©å±•çš„æ–‡æœ¬åˆ†ç±»æä¾›äº†æ•°æ®ä¸è®¡ç®—æ•ˆç‡çš„å¤§å¹…å¢ç›Šã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 4 tables, 2 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.05732v1",
      "published_date": "2025-12-05 14:11:44 UTC",
      "updated_date": "2025-12-05 14:11:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:01:51.231331+00:00"
    },
    {
      "arxiv_id": "2512.08982v1",
      "title": "Consist-Retinex: One-Step Noise-Emphasized Consistency Training Accelerates High-Quality Retinex Enhancement",
      "title_zh": "Consist-Retinexï¼šå•æ­¥å™ªå£°å¼ºè°ƒä¸€è‡´æ€§è®­ç»ƒåŠ é€Ÿé«˜è´¨é‡ Retinex å¢å¼º",
      "authors": [
        "Jian Xu",
        "Wei Chen",
        "Shigui Li",
        "Delu Zeng",
        "John Paisley",
        "Qibin Zhao"
      ],
      "abstract": "Diffusion models have achieved remarkable success in low-light image enhancement through Retinex-based decomposition, yet their requirement for hundreds of iterative sampling steps severely limits practical deployment. While recent consistency models offer promising one-step generation for \\textit{unconditional synthesis}, their application to \\textit{conditional enhancement} remains unexplored. We present \\textbf{Consist-Retinex}, the first framework adapting consistency modeling to Retinex-based low-light enhancement. Our key insight is that conditional enhancement requires fundamentally different training dynamics than unconditional generation standard consistency training focuses on low-noise regions near the data manifold, while conditional mapping critically depends on large-noise regimes that bridge degraded inputs to enhanced outputs. We introduce two core innovations: (1) a \\textbf{dual-objective consistency loss} combining temporal consistency with ground-truth alignment under randomized time sampling, providing full-spectrum supervision for stable convergence; and (2) an \\textbf{adaptive noise-emphasized sampling strategy} that prioritizes training on large-noise regions essential for one-step conditional generation. On VE-LOL-L, Consist-Retinex achieves \\textbf{state-of-the-art performance with single-step sampling} (\\textbf{PSNR: 25.51 vs. 23.41, FID: 44.73 vs. 49.59} compared to Diff-Retinex++), while requiring only \\textbf{1/8 of the training budget} relative to the 1000-step Diff-Retinex baseline.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸºäº Retinex åˆ†è§£çš„ Diffusion models åœ¨ä½å…‰ç…§å›¾åƒå¢å¼ºä¸­å› å¤šæ¬¡è¿­ä»£é‡‡æ ·å¯¼è‡´éƒ¨ç½²å—é™çš„é—®é¢˜ï¼Œæå‡ºäº†é¦–ä¸ªå°† Consistency modeling åº”ç”¨äºè¯¥é¢†åŸŸçš„æ¡†æ¶ Consist-Retinexã€‚è¯¥æ¡†æ¶æ­ç¤ºäº†æ¡ä»¶å¢å¼ºä»»åŠ¡å¯¹å¤§å™ªå£°åŒºé—´çš„ä¾èµ–ç‰¹æ€§ï¼Œå¹¶å¼•å…¥äº†ç»“åˆæ—¶é—´ä¸€è‡´æ€§ä¸çœŸå€¼å¯¹é½çš„åŒç›®æ ‡ä¸€è‡´æ€§æŸå¤± (dual-objective consistency loss) ä»¥ç¡®ä¿å…¨é¢‘è°±ç›‘ç£ä¸‹çš„ç¨³å®šæ”¶æ•›ã€‚æ­¤å¤–ï¼Œç ”ç©¶é‡‡ç”¨è‡ªé€‚åº”å™ªå£°å¼ºè°ƒé‡‡æ ·ç­–ç•¥ (adaptive noise-emphasized sampling strategy)ï¼Œä¼˜å…ˆä¼˜åŒ–å¯¹å•æ­¥æ¡ä»¶ç”Ÿæˆè‡³å…³é‡è¦çš„å¤§å™ªå£°åŒºåŸŸã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒConsist-Retinex åœ¨ VE-LOL-L æ•°æ®é›†ä¸Šé€šè¿‡å•æ­¥é‡‡æ ·å®ç°äº† SOTA æ€§èƒ½ï¼Œå…¶ PSNR ç›¸æ¯” Diff-Retinex++ æå‡è‡³ 25.51ï¼Œä¸”è®­ç»ƒæˆæœ¬ä»…ä¸ºåŸºçº¿æ¨¡å‹çš„å…«åˆ†ä¹‹ä¸€ã€‚è¿™ä¸€æˆæœæœ‰æ•ˆè§£å†³äº†é«˜è´¨é‡ Retinex å¢å¼ºæŠ€æœ¯åœ¨å®é™…åº”ç”¨ä¸­çš„æ•ˆç‡ç“¶é¢ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.08982v1",
      "published_date": "2025-12-05 13:44:19 UTC",
      "updated_date": "2025-12-05 13:44:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:01:27.070642+00:00"
    },
    {
      "arxiv_id": "2512.05714v1",
      "title": "Big Tech-Funded AI Papers Have Higher Citation Impact, Greater Insularity, and Larger Recency Bias",
      "title_zh": "ç§‘æŠ€å·¨å¤´èµ„åŠ©çš„äººå·¥æ™ºèƒ½è®ºæ–‡å…·æœ‰æ›´é«˜çš„å¼•ç”¨å½±å“åŠ›ã€æ›´å¼ºçš„å°é—­æ€§ä¸æ›´æ˜¾è‘—çš„è¿‘æ—¶åå·®",
      "authors": [
        "Max Martin Gnewuch",
        "Jan Philip Wahle",
        "Terry Ruas",
        "Bela Gipp"
      ],
      "abstract": "Over the past four decades, artificial intelligence (AI) research has flourished at the nexus of academia and industry. However, Big Tech companies have increasingly acquired the edge in computational resources, big data, and talent. So far, it has been largely unclear how many papers the industry funds, how their citation impact compares to non-funded papers, and what drives industry interest. This study fills that gap by quantifying the number of industry-funded papers at 10 top AI conferences (e.g., ICLR, CVPR, AAAI, ACL) and their citation influence. We analyze about 49.8K papers, about 1.8M citations from AI papers to other papers, and about 2.3M citations from other papers to AI papers from 1998-2022 in Scopus. Through seven research questions, we examine the volume and evolution of industry funding in AI research, the citation impact of funded papers, the diversity and temporal range of their citations, and the subfields in which industry predominantly acts. Our findings reveal that industry presence has grown markedly since 2015, from less than 2 percent to more than 11 percent in 2020. Between 2018 and 2022, 12 percent of industry-funded papers achieved high citation rates as measured by the h5-index, compared to 4 percent of non-industry-funded papers and 2 percent of non-funded papers. Top AI conferences engage more with industry-funded research than non-funded research, as measured by our newly proposed metric, the Citation Preference Ratio (CPR). We show that industry-funded research is increasingly insular, citing predominantly other industry-funded papers while referencing fewer non-funded papers. These findings reveal new trends in AI research funding, including a shift towards more industry-funded papers and their growing citation impact, greater insularity of industry-funded work than non-funded work, and a preference of industry-funded research to cite recent work.",
      "tldr_zh": "è¯¥ç ”ç©¶åˆ†æäº†1998å¹´è‡³2022å¹´é—´10ä¸ªé¡¶çº§AIä¼šè®®ï¼ˆå¦‚ICLR, CVPR, AAAIç­‰ï¼‰çš„çº¦4.98ä¸‡ç¯‡è®ºæ–‡ï¼Œç³»ç»Ÿé‡åŒ–äº†å·¥ä¸šç•Œèµ„åŠ©ç ”ç©¶çš„æ•°é‡æ¼”å˜åŠå…¶å¼•ç”¨å½±å“åŠ›ã€‚ç ”ç©¶å‘ç°ï¼Œè‡ª2015å¹´ä»¥æ¥å·¥ä¸šç•Œå‚ä¸åº¦æ˜¾è‘—æé«˜ï¼Œå…¶èµ„åŠ©è®ºæ–‡åœ¨2020å¹´å æ¯”è¶…è¿‡11%ï¼Œä¸”åœ¨2018è‡³2022å¹´é—´æœ‰12%çš„è®ºæ–‡è¾¾åˆ°äº†h5-indexè¡¡é‡çš„é«˜å¼•ç”¨æ°´å¹³ï¼Œè¿œè¶…éèµ„åŠ©è®ºæ–‡ã€‚é€šè¿‡æ–°æå‡ºçš„å¼•ç”¨åå¥½æ¯”ç‡(Citation Preference Ratio, CPR)ï¼Œç ”ç©¶è¯å®äº†å·¥ä¸šç•Œèµ„åŠ©å·¥ä½œå…·æœ‰æ›´é«˜çš„å¼•ç”¨å†²å‡»åŠ›ã€‚ç„¶è€Œï¼Œè¿™ç±»ç ”ç©¶ä¹Ÿè¡¨ç°å‡ºæ˜æ˜¾çš„å­¤ç«‹æ€§(Insularity)ï¼Œå³å€¾å‘äºä¼˜å…ˆå¼•ç”¨å…¶ä»–å—å·¥ä¸šç•Œèµ„åŠ©çš„è®ºæ–‡ï¼Œå¹¶ä¼´éšè¾ƒå¼ºçš„è¿‘æœŸåå¥½(Recency Bias)ã€‚è¿™äº›å‘ç°æ­ç¤ºäº†AIç ”ç©¶ç»è´¹æ¥æºçš„ç»“æ„æ€§è½¬å˜ï¼Œä»¥åŠå·¥ä¸šç•Œé©±åŠ¨çš„ç ”ç©¶åœ¨å­¦æœ¯ç”Ÿæ€ä¸­æ—¥ç›Šå¢å¼ºçš„å½±å“åŠ›ä¸é—­ç¯è¶‹åŠ¿ã€‚",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.DL",
      "comment": "Published at IEEE (ACDSA)",
      "pdf_url": "https://arxiv.org/pdf/2512.05714v1",
      "published_date": "2025-12-05 13:41:29 UTC",
      "updated_date": "2025-12-05 13:41:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:01:34.406790+00:00"
    },
    {
      "arxiv_id": "2512.05711v1",
      "title": "Bayesian Active Inference for Intelligent UAV Anti-Jamming and Adaptive Trajectory Planning",
      "title_zh": "é¢å‘æ™ºèƒ½æ— äººæœºæŠ—å¹²æ‰°ä¸è‡ªé€‚åº”è½¨è¿¹è§„åˆ’çš„è´å¶æ–¯ä¸»åŠ¨æ¨ç†",
      "authors": [
        "Ali Krayani",
        "Seyedeh Fatemeh Sadati",
        "Lucio Marcenaro",
        "Carlo Regazzoni"
      ],
      "abstract": "This paper proposes a hierarchical trajectory planning framework for UAVs operating under adversarial jamming conditions. Leveraging Bayesian Active Inference, the approach combines expert-generated demonstrations with probabilistic generative modeling to encode high-level symbolic planning, low-level motion policies, and wireless signal feedback. During deployment, the UAV performs online inference to anticipate interference, localize jammers, and adapt its trajectory accordingly, without prior knowledge of jammer locations. Simulation results demonstrate that the proposed method achieves near-expert performance, significantly reducing communication interference and mission cost compared to model-free reinforcement learning baselines, while maintaining robust generalization in dynamic environments.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åœ¨å¯¹æŠ—æ€§å¹²æ‰°ç¯å¢ƒä¸‹è¿è¡Œçš„æ— äººæœºï¼ˆUAVï¼‰ï¼Œæå‡ºäº†ä¸€ä¸ªåˆ†å±‚è½¨è¿¹è§„åˆ’æ¡†æ¶ã€‚è¯¥æ–¹æ³•åˆ©ç”¨è´å¶æ–¯ä¸»åŠ¨æ¨ç†ï¼ˆBayesian Active Inferenceï¼‰ï¼Œé€šè¿‡ç»“åˆä¸“å®¶æ¼”ç¤ºï¼ˆexpert-generated demonstrationsï¼‰ä¸æ¦‚ç‡ç”Ÿæˆå»ºæ¨¡ï¼Œå®ç°äº†å¯¹é«˜å±‚ç¬¦å·è§„åˆ’ã€åº•å±‚è¿åŠ¨ç­–ç•¥åŠæ— çº¿ä¿¡å·åé¦ˆçš„ç»Ÿä¸€ç¼–ç ã€‚åœ¨å®é™…éƒ¨ç½²ä¸­ï¼ŒUAV èƒ½å¤Ÿåœ¨æ— éœ€å¹²æ‰°æºä½ç½®å…ˆéªŒçŸ¥è¯†çš„æƒ…å†µä¸‹ï¼Œé€šè¿‡åœ¨çº¿æ¨ç†é¢„æµ‹å¹²æ‰°å¹¶å®šä½å¹²æ‰°æºï¼Œä»è€Œè‡ªé€‚åº”åœ°è°ƒæ•´é£è¡Œè½¨è¿¹ã€‚ä»¿çœŸç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ¡ˆè¾¾åˆ°äº†æ¥è¿‘ä¸“å®¶çš„æ€§èƒ½æ°´å¹³ï¼Œç›¸æ¯”äºæ— æ¨¡å‹å¼ºåŒ–å­¦ä¹ ï¼ˆmodel-free reinforcement learningï¼‰åŸºå‡†æ˜¾è‘—é™ä½äº†é€šä¿¡å¹²æ‰°å’Œä»»åŠ¡æˆæœ¬ï¼Œå¹¶åœ¨åŠ¨æ€ç¯å¢ƒä¸­å±•ç°å‡ºæå¼ºçš„æ³›åŒ–èƒ½åŠ›ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "eess.SP",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "This paper has been accepted for the 2026 IEEE Consumer Communications & Networking Conference (IEEE CCNC 2026)",
      "pdf_url": "https://arxiv.org/pdf/2512.05711v1",
      "published_date": "2025-12-05 13:38:52 UTC",
      "updated_date": "2025-12-05 13:38:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:01:35.306898+00:00"
    },
    {
      "arxiv_id": "2512.05700v1",
      "title": "Faithfulness metric fusion: Improving the evaluation of LLM trustworthiness across domains",
      "title_zh": "å¿ å®åº¦æŒ‡æ ‡èåˆï¼šæå‡å¤§è¯­è¨€æ¨¡å‹è·¨é¢†åŸŸå¯ä¿¡åº¦è¯„ä¼°",
      "authors": [
        "Ben Malin",
        "Tatiana Kalganova",
        "Nikolaos Boulgouris"
      ],
      "abstract": "We present a methodology for improving the accuracy of faithfulness evaluation in Large Language Models (LLMs). The proposed methodology is based on the combination of elementary faithfulness metrics into a combined (fused) metric, for the purpose of improving the faithfulness of LLM outputs. The proposed strategy for metric fusion deploys a tree-based model to identify the importance of each metric, which is driven by the integration of human judgements evaluating the faithfulness of LLM responses. This fused metric is demonstrated to correlate more strongly with human judgements across all tested domains for faithfulness. Improving the ability to evaluate the faithfulness of LLMs, allows for greater confidence to be placed within models, allowing for their implementation in a greater diversity of scenarios. Additionally, we homogenise a collection of datasets across question answering and dialogue-based domains and implement human judgements and LLM responses within this dataset, allowing for the reproduction and trialling of faithfulness evaluation across domains.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§æ—¨åœ¨æå‡å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)å¿ å®åº¦(Faithfulness)è¯„ä¼°å‡†ç¡®æ€§çš„æ–°æ–¹æ³•ã€‚è¯¥æ–¹æ³•çš„æ ¸å¿ƒæ˜¯å°†å¤šä¸ªåŸºç¡€å¿ å®åº¦æŒ‡æ ‡èåˆæˆä¸€ä¸ªç»¼åˆæŒ‡æ ‡ï¼Œåˆ©ç”¨åŸºäºæ ‘çš„æ¨¡å‹(tree-based model)æ¥ç¡®å®šå„é¡¹æŒ‡æ ‡çš„æƒé‡ï¼Œå¹¶ç”±äººç±»å¯¹LLMå›å¤çš„å¿ å®åº¦è¯„åˆ¤æ•°æ®é©±åŠ¨ä¼˜åŒ–ã€‚å®éªŒè¯æ˜ï¼Œè¿™ç§èåˆæŒ‡æ ‡åœ¨æ‰€æœ‰æµ‹è¯•é¢†åŸŸä¸­ä¸äººç±»åˆ¤æ–­çš„ç›¸å…³æ€§å‡æ˜¾è‘—å¢å¼ºï¼Œä»è€Œèƒ½å¤Ÿæ›´å¯é åœ°è¯„ä¼°LLMçš„å¯ä¿¡åº¦ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜è´¡çŒ®äº†ä¸€ä¸ªæ•´åˆäº†é—®ç­”ä¸å¯¹è¯é¢†åŸŸçš„æ ‡å‡†åŒ–æ•°æ®é›†ï¼Œå¹¶åŒ…å«äººç±»è¯„ä»·ä¸LLMå“åº”è®°å½•ï¼Œä»¥ä¾¿äºå­¦æœ¯ç•Œå¯¹è·¨é¢†åŸŸå¿ å®åº¦è¯„ä¼°è¿›è¡Œå¤ç°ä¸æµ‹è¯•ã€‚è¿™ä¸€æˆæœä¸ºLLMsåœ¨æ›´å¤šå…ƒåŒ–åº”ç”¨åœºæ™¯ä¸­çš„éƒ¨ç½²æä¾›äº†æ›´å¼ºçš„ä¿¡å¿ƒä¿éšœã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, conference paper",
      "pdf_url": "https://arxiv.org/pdf/2512.05700v1",
      "published_date": "2025-12-05 13:28:29 UTC",
      "updated_date": "2025-12-05 13:28:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:01:41.698254+00:00"
    },
    {
      "arxiv_id": "2512.05693v1",
      "title": "HiMoE-VLA: Hierarchical Mixture-of-Experts for Generalist Vision-Language-Action Policies",
      "title_zh": "HiMoE-VLAï¼šé¢å‘é€šç”¨è§†è§‰-è¯­è¨€-åŠ¨ä½œç­–ç•¥çš„å±‚çº§ä¸“å®¶æ··åˆ",
      "authors": [
        "Zhiying Du",
        "Bei Liu",
        "Yaobo Liang",
        "Yichao Shen",
        "Haidong Cao",
        "Xiangyu Zheng",
        "Zhiyuan Feng",
        "Zuxuan Wu",
        "Jiaolong Yang",
        "Yu-Gang Jiang"
      ],
      "abstract": "The development of foundation models for embodied intelligence critically depends on access to large-scale, high-quality robot demonstration data. Recent approaches have sought to address this challenge by training on large collections of heterogeneous robotic datasets. However, unlike vision or language data, robotic demonstrations exhibit substantial heterogeneity across embodiments and action spaces as well as other prominent variations such as senor configurations and action control frequencies. The lack of explicit designs for handling such heterogeneity causes existing methods to struggle with integrating diverse factors, thereby limiting their generalization and leading to degraded performance when transferred to new settings. In this paper, we present HiMoE-VLA, a novel vision-language-action (VLA) framework tailored to effectively handle diverse robotic data with heterogeneity. Specifically, we introduce a Hierarchical Mixture-of-Experts (HiMoE) architecture for the action module which adaptively handles multiple sources of heterogeneity across layers and gradually abstracts them into shared knowledge representations. Through extensive experimentation with simulation benchmarks and real-world robotic platforms, HiMoE-VLA demonstrates a consistent performance boost over existing VLA baselines, achieving higher accuracy and robust generalization across diverse robots and action spaces. The code and models are publicly available at https://github.com/ZhiyingDu/HiMoE-VLA.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å…·èº«æ™ºèƒ½ (embodied intelligence) åŸºç¡€æ¨¡å‹åœ¨å¤„ç†å¤§è§„æ¨¡ã€å¼‚æ„æœºå™¨äººæ•°æ®é›†æ—¶é¢ä¸´çš„æŒ‘æˆ˜ï¼ŒæŒ‡å‡ºå½“å‰æ–¹æ³•åœ¨åº”å¯¹ä¸åŒå½¢æ€ (embodiments)ã€åŠ¨ä½œç©ºé—´ (action spaces) åŠä¼ æ„Ÿå™¨é…ç½®çš„å¼‚æ„æ€§æ—¶å­˜åœ¨æ³›åŒ–èƒ½åŠ›å—é™çš„é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº† HiMoE-VLAï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨é«˜æ•ˆå¤„ç†å¤šæ ·åŒ–æœºå™¨äººæ•°æ®çš„è§†è§‰-è¯­è¨€-åŠ¨ä½œ (vision-language-action, VLA) æ¡†æ¶ã€‚è¯¥æ¡†æ¶çš„æ ¸å¿ƒæ˜¯åœ¨åŠ¨ä½œæ¨¡å—ä¸­å¼•å…¥äº†åˆ†å±‚ä¸“å®¶æ··åˆ (Hierarchical Mixture-of-Experts, HiMoE) æ¶æ„ï¼Œé€šè¿‡å¤šå±‚çº§è‡ªé€‚åº”åœ°å¤„ç†å„ç§å¼‚æ„å› ç´ ï¼Œå¹¶å°†å…¶é€æ¸æŠ½è±¡ä¸ºå…±äº«çš„çŸ¥è¯†è¡¨ç¤ºã€‚é€šè¿‡åœ¨æ¨¡æ‹ŸåŸºå‡†å’ŒçœŸå®ä¸–ç•Œæœºå™¨äººå¹³å°ä¸Šçš„å¹¿æ³›å®éªŒï¼ŒHiMoE-VLA å±•ç°å‡ºä¼˜äºç°æœ‰ VLA åŸºå‡†æ¨¡å‹çš„æ€§èƒ½ã€‚ç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¸åŒæœºå™¨äººå’ŒåŠ¨ä½œç©ºé—´ä¸‹å‡èƒ½å®ç°æ›´é«˜çš„å‡†ç¡®æ€§å’Œæ›´å¼ºçš„æ³›åŒ– (generalization) èƒ½åŠ›ï¼Œä¸ºæ„å»ºé€šç”¨å…·èº«æ™ºèƒ½ç­–ç•¥æä¾›äº†æœ‰æ•ˆæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.05693v1",
      "published_date": "2025-12-05 13:21:05 UTC",
      "updated_date": "2025-12-05 13:21:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:02:06.834641+00:00"
    },
    {
      "arxiv_id": "2512.05681v1",
      "title": "Retrieving Semantically Similar Decisions under Noisy Institutional Labels: Robust Comparison of Embedding Methods",
      "title_zh": "å™ªå£°æœºæ„æ ‡ç­¾ä¸‹çš„è¯­ä¹‰ç›¸ä¼¼åˆ¤å†³æ£€ç´¢ï¼šåµŒå…¥æ–¹æ³•çš„é²æ£’å¯¹æ¯”",
      "authors": [
        "Tereza Novotna",
        "Jakub Harasta"
      ],
      "abstract": "Retrieving case law is a time-consuming task predominantly carried out by querying databases. We provide a comparison of two models in three different settings for Czech Constitutional Court decisions: (i) a large general-purpose embedder (OpenAI), (ii) a domain-specific BERT-trained from scratch on ~30,000 decisions using sliding windows and attention pooling. We propose a noise-aware evaluation including IDF-weighted keyword overlap as graded relevance, binarization via two thresholds (0.20 balanced, 0.28 strict), significance via paired bootstrap, and an nDCG diagnosis supported with qualitative analysis. Despite modest absolute nDCG (expected under noisy labels), the general OpenAI embedder decisively outperforms the domain pre-trained BERT in both settings at @10/@20/@100 across both thresholds; differences are statistically significant. Diagnostics attribute low absolutes to label drift and strong ideals rather than lack of utility. Additionally, our framework is robust enough to be used for evaluation under a noisy gold dataset, which is typical when handling data with heterogeneous labels stemming from legacy judicial databases.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ·å…‹å®ªæ³•æ³•é™¢ï¼ˆCzech Constitutional Courtï¼‰çš„åˆ¤ä¾‹æ£€ç´¢ä»»åŠ¡ï¼Œå¯¹æ¯”äº†å¤§å‹é€šç”¨åµŒå…¥æ¨¡å‹ï¼ˆOpenAIï¼‰ä¸ä½¿ç”¨æ»‘åŠ¨çª—å£åŠæ³¨æ„åŠ›æ± åŒ–æŠ€æœ¯ï¼ˆsliding windows and attention poolingï¼‰ä»é›¶è®­ç»ƒçš„é¢†åŸŸç‰¹å®šBERTæ¨¡å‹ï¼ˆdomain-specific BERTï¼‰ã€‚ç ”ç©¶æå‡ºäº†ä¸€ç§é’ˆå¯¹å™ªå£°æ ‡ç­¾ï¼ˆnoisy labelsï¼‰çš„é²æ£’æ€§è¯„ä¼°æ¡†æ¶ï¼Œç»“åˆäº†IDFåŠ æƒå…³é”®è¯é‡å ï¼ˆIDF-weighted keyword overlapï¼‰ã€äºŒå€¼åŒ–é˜ˆå€¼ï¼ˆbinarization thresholdsï¼‰ä»¥åŠé…å¯¹è‡ªåŠ©æ³•ï¼ˆpaired bootstrapï¼‰è¿›è¡Œè¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨@10/@20/@100ç­‰å¤šä¸ªæ£€ç´¢æŒ‡æ ‡ä¸‹ï¼ŒOpenAIåµŒå…¥æ¨¡å‹åœ¨ç»Ÿè®¡å­¦æ„ä¹‰ä¸Šå‡æ˜¾è‘—ä¼˜äºé¢†åŸŸç‰¹å®šçš„BERTæ¨¡å‹ã€‚è¯Šæ–­åˆ†ææŒ‡å‡ºï¼Œè¾ƒä½çš„ç»å¯¹nDCGåˆ†å€¼ä¸»è¦æºäºæ ‡ç­¾åç§»ï¼ˆlabel driftï¼‰å’Œæé«˜çš„ç†æƒ³æ ‡å‡†ï¼Œè€Œéæ¨¡å‹ç¼ºä¹å®ç”¨ä»·å€¼ã€‚è¯¥ç ”ç©¶è¯æ˜äº†è¯¥æ¡†æ¶åœ¨å¤„ç†å…·æœ‰å¼‚æ„æ ‡ç­¾çš„ä¼ ç»Ÿå¸æ³•æ•°æ®åº“æ—¶çš„æœ‰æ•ˆæ€§ï¼Œä¸ºæ³•å¾‹æ–‡æœ¬çš„è¯­ä¹‰ç›¸ä¼¼æ€§æ£€ç´¢æä¾›äº†é‡è¦çš„è¯„ä¼°èŒƒå¼å’ŒæŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "The manuscript has been accepted for presentation as a short paper at the 38th International Conference on Legal Knowledge and Information Systems (JURIX 2025) in Torino, Italy",
      "pdf_url": "https://arxiv.org/pdf/2512.05681v1",
      "published_date": "2025-12-05 12:54:26 UTC",
      "updated_date": "2025-12-05 12:54:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:02:28.230033+00:00"
    },
    {
      "arxiv_id": "2512.11864v1",
      "title": "Solving Parallel Machine Scheduling With Precedences and Cumulative Resource Constraints With Calendars",
      "title_zh": "æ±‚è§£å¸¦ä¼˜å…ˆå…³ç³»åŠæ—¥å†ç´¯ç§¯èµ„æºçº¦æŸçš„å¹¶è¡Œæœºè°ƒåº¦é—®é¢˜",
      "authors": [
        "Christoph Einspieler",
        "Matthias Horn",
        "Marie-Louise Lackner",
        "Patrick Malik",
        "Nysret Musliu",
        "Felix Winter"
      ],
      "abstract": "The task of finding efficient production schedules for parallel machines is a challenge that arises in most industrial manufacturing domains. There is a large potential to minimize production costs through automated scheduling techniques, due to the large-scale requirements of modern factories. In the past, solution approaches have been studied for many machine scheduling variations, where even basic variants have been shown to be NP-hard. However, in today's real-life production environments, additional complex precedence constraints and resource restrictions with calendars arise that must be fulfilled. These additional constraints cannot be tackled efficiently by existing solution techniques. Thus, there is a strong need to develop and analyze automated methods that can solve such real-life parallel machine scheduling scenarios. In this work, we introduce a novel variant of parallel machine scheduling with job precedences and calendar-based cumulative resource constraints that arises in real-life industrial use cases. A constraint modeling approach is proposed as an exact solution method for small scheduling scenarios together with state-of-the-art constraint-solving technology. Further, we propose a construction heuristic as well as a tailored metaheuristic using local search to efficiently tackle large-scale problem instances. This metaheuristic approach has been deployed and is currently being used in an industrial setting.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å·¥ä¸šåˆ¶é€ ä¸­çš„å¤æ‚è°ƒåº¦æŒ‘æˆ˜ï¼Œå¼•å…¥äº†ä¸€ç§åŒ…å«ä½œä¸šä¼˜å…ˆçº§(Job Precedences)å’ŒåŸºäºæ—¥å†çš„ç´¯ç§¯èµ„æºçº¦æŸ(Calendar-based Cumulative Resource Constraints)çš„æ–°å‹å¹¶è¡Œæœºè°ƒåº¦å˜ä½“ã€‚ä¸ºè§£å†³è¿™ä¸€NP-hardéš¾é¢˜ï¼Œç ”ç©¶æå‡ºäº†ä¸€ç§ç»“åˆå…ˆè¿›çº¦æŸæ±‚è§£æŠ€æœ¯çš„çº¦æŸå»ºæ¨¡(Constraint Modeling)æ–¹æ³•ï¼Œä½œä¸ºå°å‹åœºæ™¯çš„ç²¾ç¡®è§£æ³•ã€‚é’ˆå¯¹å¤§è§„æ¨¡å·¥ä¸šå®ä¾‹ï¼Œä½œè€…è¿›ä¸€æ­¥å¼€å‘äº†æ„é€ å¯å‘å¼ç®—æ³•(Construction Heuristic)ä»¥åŠåŸºäºå±€éƒ¨æœç´¢(Local Search)çš„å®šåˆ¶åŒ–å…ƒå¯å‘å¼ç®—æ³•(Metaheuristic)ã€‚å®éªŒä¸åº”ç”¨è¡¨æ˜ï¼Œè¯¥å…ƒå¯å‘å¼æ–¹æ³•èƒ½å¤Ÿé«˜æ•ˆå¤„ç†å¤æ‚çš„èµ„æºä¸æ—¶é—´é™åˆ¶ã€‚ç›®å‰ï¼Œè¯¥æ–¹æ¡ˆå·²åœ¨å®é™…å·¥ä¸šç¯å¢ƒä¸­éƒ¨ç½²è¿è¡Œï¼Œä¸ºè‡ªåŠ¨åŒ–ç”Ÿäº§è°ƒåº¦å’Œé™ä½ç”Ÿäº§æˆæœ¬æä¾›äº†æœ‰æ•ˆçš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.11864v1",
      "published_date": "2025-12-05 12:35:44 UTC",
      "updated_date": "2025-12-05 12:35:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:02:09.004922+00:00"
    },
    {
      "arxiv_id": "2512.22129v1",
      "title": "ReCollab: Retrieval-Augmented LLMs for Cooperative Ad-hoc Teammate Modeling",
      "title_zh": "ReCollabï¼šé¢å‘åä½œå¼ Ad-hoc é˜Ÿå‹å»ºæ¨¡çš„æ£€ç´¢å¢å¼ºå‹å¤§è¯­è¨€æ¨¡å‹",
      "authors": [
        "Conor Wallace",
        "Umer Siddique",
        "Yongcan Cao"
      ],
      "abstract": "Ad-hoc teamwork (AHT) requires agents to infer the behavior of previously unseen teammates and adapt their policy accordingly. Conventional approaches often rely on fixed probabilistic models or classifiers, which can be brittle under partial observability and limited interaction. Large language models (LLMs) offer a flexible alternative: by mapping short behavioral traces into high-level hypotheses, they can serve as world models over teammate behavior. We introduce \\Collab, a language-based framework that classifies partner types using a behavior rubric derived from trajectory features, and extend it to \\ReCollab, which incorporates retrieval-augmented generation (RAG) to stabilize inference with exemplar trajectories. In the cooperative Overcooked environment, \\Collab effectively distinguishes teammate types, while \\ReCollab consistently improves adaptation across layouts, achieving Pareto-optimal trade-offs between classification accuracy and episodic return. These findings demonstrate the potential of LLMs as behavioral world models for AHT and highlight the importance of retrieval grounding in challenging coordination settings.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å³æ—¶å›¢é˜Ÿåˆä½œ(Ad-hoc Teamwork)ä¸­ä»£ç†éœ€æ¨æ–­æœªçŸ¥é˜Ÿå‹è¡Œä¸ºå¹¶è¿›è¡Œé€‚åº”çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†Collabå’ŒReCollabæ¡†æ¶ã€‚Collabåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(LLMs)ä½œä¸ºè¡Œä¸ºä¸–ç•Œæ¨¡å‹ï¼Œé€šè¿‡ä»è½¨è¿¹ç‰¹å¾ä¸­æå–çš„è¡Œä¸ºå‡†åˆ™(behavior rubric)å¯¹åˆä½œä¼™ä¼´ç±»å‹è¿›è¡Œåˆ†ç±»ã€‚ReCollabè¿›ä¸€æ­¥å¼•å…¥äº†æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)æŠ€æœ¯ï¼Œåˆ©ç”¨ç¤ºä¾‹è½¨è¿¹æ¥ç¨³å®šæ¨ç†è¿‡ç¨‹ï¼Œè§£å†³äº†ä¼ ç»Ÿæ¨¡å‹åœ¨éƒ¨åˆ†å¯è§‚æµ‹ç¯å¢ƒä¸‹çš„è„†å¼±æ€§ã€‚åœ¨åä½œå¼Overcookedç¯å¢ƒä¸­çš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒCollabèƒ½æœ‰æ•ˆåŒºåˆ†é˜Ÿå‹ç±»å‹ï¼Œè€ŒReCollabåœ¨ä¸åŒåœ°å›¾å¸ƒå±€ä¸‹å‡æ˜¾è‘—æå‡äº†é€‚åº”æ€§ï¼Œå¹¶åœ¨åˆ†ç±»å‡†ç¡®ç‡ä¸å›åˆå›æŠ¥ä¹‹é—´è¾¾æˆäº†Pareto-optimalçš„å¹³è¡¡ã€‚è¿™äº›å‘ç°ä¸ä»…éªŒè¯äº†LLMsåœ¨æ¨¡æ‹Ÿé˜Ÿå‹è¡Œä¸ºæ–¹é¢çš„æ½œåŠ›ï¼Œä¹Ÿå‡¸æ˜¾äº†æ£€ç´¢å¢å¼ºæŠ€æœ¯åœ¨å¤„ç†å¤æ‚åè°ƒä»»åŠ¡æ—¶çš„é‡è¦æ€§ã€‚",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.22129v1",
      "published_date": "2025-12-05 12:33:11 UTC",
      "updated_date": "2025-12-05 12:33:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:02:37.001494+00:00"
    },
    {
      "arxiv_id": "2512.05672v1",
      "title": "InverseCrafter: Efficient Video ReCapture as a Latent Domain Inverse Problem",
      "title_zh": "InverseCrafterï¼šä½œä¸ºæ½œç©ºé—´é€†é—®é¢˜çš„é«˜æ•ˆè§†é¢‘é‡æ•è·",
      "authors": [
        "Yeobin Hong",
        "Suhyeon Lee",
        "Hyungjin Chung",
        "Jong Chul Ye"
      ],
      "abstract": "Recent approaches to controllable 4D video generation often rely on fine-tuning pre-trained Video Diffusion Models (VDMs). This dominant paradigm is computationally expensive, requiring large-scale datasets and architectural modifications, and frequently suffers from catastrophic forgetting of the model's original generative priors. Here, we propose InverseCrafter, an efficient inpainting inverse solver that reformulates the 4D generation task as an inpainting problem solved in the latent space. The core of our method is a principled mechanism to encode the pixel space degradation operator into a continuous, multi-channel latent mask, thereby bypassing the costly bottleneck of repeated VAE operations and backpropagation. InverseCrafter not only achieves comparable novel view generation and superior measurement consistency in camera control tasks with near-zero computational overhead, but also excels at general-purpose video inpainting with editing. Code is available at https://github.com/yeobinhong/InverseCrafter.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† InverseCrafterï¼Œè¿™æ˜¯ä¸€ç§é«˜æ•ˆçš„è¡¥å…¨é€†å‘æ±‚è§£å™¨ (inpainting inverse solver)ï¼Œæ—¨åœ¨è§£å†³å¯æ§ 4D è§†é¢‘ç”Ÿæˆåœ¨å¾®è°ƒé¢„è®­ç»ƒ Video Diffusion Models (VDMs) æ—¶é¢ä¸´çš„è®¡ç®—æˆæœ¬é«˜å’Œç¾éš¾æ€§é—å¿˜ç­‰é—®é¢˜ã€‚è¯¥æ–¹æ³•å°† 4D ç”Ÿæˆä»»åŠ¡é‡æ–°è¡¨è¿°ä¸ºæ½œåœ¨ç©ºé—´ (latent space) ä¸­çš„è¡¥å…¨é—®é¢˜ï¼Œå…¶æ ¸å¿ƒåœ¨äºå°†åƒç´ ç©ºé—´é€€åŒ–ç®—å­ (degradation operator) ç¼–ç ä¸ºè¿ç»­çš„å¤šé€šé“æ½œåœ¨æ©ç  (multi-channel latent mask)ã€‚é€šè¿‡è¿™ç§æœºåˆ¶ï¼ŒInverseCrafter æˆåŠŸç»•è¿‡äº†æ˜‚è´µçš„é‡å¤ VAE æ“ä½œå’Œåå‘ä¼ æ’­ç“¶é¢ˆï¼Œå®ç°äº†æ¥è¿‘é›¶çš„é¢å¤–è®¡ç®—å¼€é”€ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨ç›¸æœºæ§åˆ¶ä»»åŠ¡ä¸­è¡¨ç°å‡ºä¼˜å¼‚çš„æµ‹é‡ä¸€è‡´æ€§ (measurement consistency) å’Œæ–°è§†å›¾ç”Ÿæˆèƒ½åŠ›ã€‚æ­¤å¤–ï¼ŒInverseCrafter è¿˜åœ¨é€šç”¨è§†é¢‘è¡¥å…¨ä¸ç¼–è¾‘ä»»åŠ¡ä¸­å±•ç°äº†å“è¶Šçš„æ€§èƒ½ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.05672v1",
      "published_date": "2025-12-05 12:31:09 UTC",
      "updated_date": "2025-12-05 12:31:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:02:14.124317+00:00"
    },
    {
      "arxiv_id": "2512.05667v1",
      "title": "On Dynamic Programming Theory for Leader-Follower Stochastic Games",
      "title_zh": "è®ºä¸»ä»å¼éšæœºåšå¼ˆçš„åŠ¨æ€è§„åˆ’ç†è®º",
      "authors": [
        "Jilles Steeve Dibangoye",
        "Thibaut Le Marre",
        "Ocan Sankur",
        "FranÃ§ois Schwarzentruber"
      ],
      "abstract": "Leader-follower general-sum stochastic games (LF-GSSGs) model sequential decision-making under asymmetric commitment, where a leader commits to a policy and a follower best responds, yielding a strong Stackelberg equilibrium (SSE) with leader-favourable tie-breaking. This paper introduces a dynamic programming (DP) framework that applies Bellman recursion over credible sets-state abstractions formally representing all rational follower best responses under partial leader commitments-to compute SSEs. We first prove that any LF-GSSG admits a lossless reduction to a Markov decision process (MDP) over credible sets. We further establish that synthesising an optimal memoryless deterministic leader policy is NP-hard, motivating the development of Îµ-optimal DP algorithms with provable guarantees on leader exploitability. Experiments on standard mixed-motive benchmarks-including security games, resource allocation, and adversarial planning-demonstrate empirical gains in leader value and runtime scalability over state-of-the-art methods.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é’ˆå¯¹ Leader-follower general-sum stochastic games (LF-GSSGs) æå‡ºäº†ä¸€ç§ Dynamic Programming (DP) æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³éå¯¹ç§°æ‰¿è¯ºä¸‹çš„åºè´¯å†³ç­–é—®é¢˜å¹¶è®¡ç®— Strong Stackelberg Equilibrium (SSE)ã€‚è¯¥æ¡†æ¶é€šè¿‡åœ¨å¯ä¿¡é›†ï¼ˆcredible setsï¼‰ä¸Šåº”ç”¨ Bellman recursionï¼Œå®ç°äº†å°† LF-GSSG æ— æŸè§„çº¦ä¸º Markov decision process (MDP) çš„ç†è®ºçªç ´ã€‚ç ”ç©¶è¿›ä¸€æ­¥è¯æ˜äº†åˆæˆæœ€ä¼˜æ— è®°å¿†ç¡®å®šæ€§é¢†å¯¼è€…ç­–ç•¥å±äº NP-hard é—®é¢˜ï¼Œå¹¶æ®æ­¤å¼€å‘äº†å…·æœ‰å¯è¯æ˜ç•Œé™çš„ $\\epsilon$-optimal DP ç®—æ³•ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å®‰å…¨åšå¼ˆã€èµ„æºåˆ†é…åŠå¯¹æŠ—æ€§è§„åˆ’ç­‰ä»»åŠ¡ä¸­ï¼Œç›¸è¾ƒäºç°æœ‰æŠ€æœ¯åœ¨é¢†å¯¼è€…æ”¶ç›Šå’Œè¿è¡Œæ‰©å±•æ€§æ–¹é¢å‡æœ‰æ˜¾è‘—æå‡ã€‚",
      "categories": [
        "cs.GT",
        "cs.AI"
      ],
      "primary_category": "cs.GT",
      "comment": "31 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.05667v1",
      "published_date": "2025-12-05 12:23:56 UTC",
      "updated_date": "2025-12-05 12:23:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:02:22.061755+00:00"
    },
    {
      "arxiv_id": "2512.05666v1",
      "title": "Feasibility of AI-Assisted Programming for End-User Development",
      "title_zh": "é¢å‘ç»ˆç«¯ç”¨æˆ·å¼€å‘çš„ AI è¾…åŠ©ç¼–ç¨‹å¯è¡Œæ€§",
      "authors": [
        "Irene Weber"
      ],
      "abstract": "End-user development,where non-programmers create or adapt their own digital tools, can play a key role in driving digital transformation within organizations. Currently, low-code/no-code platforms are widely used to enable end-user development through visual programming, minimizing the need for manual coding. Recent advancements in generative AI, particularly large language model-based assistants and \"copilots\", open new possibilities, as they may enable end users to generate and refine programming code and build apps directly from natural language prompts. This approach, here referred to as AI-assisted end-user coding, promises greater flexibility, broader applicability, faster development, improved reusability, and reduced vendor lock-in compared to the established visual LCNC platforms. This paper investigates whether AI-assisted end-user coding is a feasible paradigm for end-user development, which may complement or even replace the LCNC model in the future. To explore this, we conducted a case study in which non-programmers were asked to develop a basic web app through interaction with AI assistants.The majority of study participants successfully completed the task in reasonable time and also expressed support for AI-assisted end-user coding as a viable approach for end-user development. The paper presents the study design, analyzes the outcomes, and discusses potential implications for practice, future research, and academic teaching.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†AI-Assisted Programmingåœ¨End-User Developmenté¢†åŸŸçš„åº”ç”¨å¯è¡Œæ€§ï¼Œåˆ†æäº†å…¶ä½œä¸ºLow-Code/No-Code (LCNC)æ¨¡å‹è¡¥å……æˆ–æ›¿ä»£æ–¹æ¡ˆçš„æ½œåŠ›ã€‚ç ”ç©¶æŒ‡å‡ºï¼ŒåŸºäºLarge Language Modelçš„ç”Ÿæˆå¼AIåŠ©æ‰‹å…è®¸éç¼–ç¨‹äººå‘˜é€šè¿‡è‡ªç„¶è¯­è¨€æç¤ºç›´æ¥ç”Ÿæˆå’Œå®Œå–„ä»£ç ã€‚è¿™ç§è¢«ç§°ä¸ºAI-assisted end-user codingçš„æ¨¡å¼ç›¸è¾ƒäºä¼ ç»ŸLCNCå¹³å°å…·æœ‰æ›´é«˜çš„çµæ´»æ€§ã€æ›´å¹¿çš„é€‚ç”¨æ€§ä»¥åŠæ›´ä½çš„Vendor lock-iné£é™©ã€‚é€šè¿‡ä¸€é¡¹è¦æ±‚éç¨‹åºå‘˜å‚ä¸å¼€å‘Web Appçš„Case studyï¼Œç»“æœæ˜¾ç¤ºå¤§å¤šæ•°å‚ä¸è€…èƒ½å¤Ÿåœ¨åˆç†æ—¶é—´å†…æˆåŠŸå®Œæˆä»»åŠ¡ï¼Œå¹¶æ”¯æŒè¯¥æ¨¡å¼ä½œä¸ºEnd-user developmentçš„å¯è¡Œè·¯å¾„ã€‚è¯¥è®ºæ–‡æœ€ç»ˆè®ºè¯äº†æ­¤èŒƒå¼çš„å¯è¡Œæ€§ï¼Œå¹¶è®¨è®ºäº†å…¶å¯¹æœªæ¥è¡Œä¸šå®è·µã€å­¦æœ¯ç ”ç©¶åŠæ•™è‚²æ•™å­¦çš„æ½œåœ¨å½±å“ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.05666v1",
      "published_date": "2025-12-05 12:13:21 UTC",
      "updated_date": "2025-12-05 12:13:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:02:41.863864+00:00"
    },
    {
      "arxiv_id": "2512.05658v1",
      "title": "Grounded Multilingual Medical Reasoning for Question Answering with Large Language Models",
      "title_zh": "é¢å‘å¤§è¯­è¨€æ¨¡å‹é—®ç­”çš„åŸºäºäº‹å®çš„å¤šè¯­è¨€åŒ»å­¦æ¨ç†",
      "authors": [
        "Pietro Ferrazzi",
        "Aitor Soroa",
        "Rodrigo Agerri"
      ],
      "abstract": "Large Language Models (LLMs) with reasoning capabilities have recently demonstrated strong potential in medical Question Answering (QA). Existing approaches are largely English-focused and primarily rely on distillation from general-purpose LLMs, raising concerns about the reliability of their medical knowledge. In this work, we present a method to generate multilingual reasoning traces grounded in factual medical knowledge. We produce 500k traces in English, Italian, and Spanish, using a retrievalaugmented generation approach over medical information from Wikipedia. The traces are generated to solve medical questions drawn from MedQA and MedMCQA, which we extend to Italian and Spanish. We test our pipeline in both in-domain and outof-domain settings across Medical QA benchmarks, and demonstrate that our reasoning traces improve performance both when utilized via in-context learning (few-shot) and supervised fine-tuning, yielding state-of-the-art results among 8B-parameter LLMs. We believe that these resources can support the development of safer, more transparent clinical decision-support tools in multilingual settings. We release the full suite of resources: reasoning traces, translated QA datasets, Medical-Wikipedia, and fine-tuned models.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºäº‹å®æ€§åŒ»å­¦çŸ¥è¯†çš„åœ°é¢åŒ–å¤šè¯­è¨€æ¨ç†ç”Ÿæˆæ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) åœ¨åŒ»å­¦é—®ç­” (Medical QA) ä¸­è¿‡äºä¾èµ–è‹±æ–‡ä¸”çŸ¥è¯†å¯é æ€§ä¸è¶³çš„é—®é¢˜ã€‚ç ”ç©¶å›¢é˜Ÿåˆ©ç”¨æ£€ç´¢å¢å¼ºç”ŸæˆæŠ€æœ¯ (RAG)ï¼ŒåŸºäºç»´åŸºç™¾ç§‘ä¸­çš„åŒ»å­¦ä¿¡æ¯ï¼Œç”Ÿæˆäº†åŒ…å« 50 ä¸‡æ¡è‹±è¯­ã€æ„å¤§åˆ©è¯­å’Œè¥¿ç­ç‰™è¯­çš„æ¨ç†è½¨è¿¹ (Reasoning Traces)ã€‚è¿™äº›æ¨ç†è½¨è¿¹ä¸“é—¨ç”¨äºè§£å†³ MedQA å’Œ MedMCQA ä¸­çš„åŒ»å­¦é—®é¢˜ï¼Œä¸”ç ”ç©¶è€…å°†è¿™äº›æ•°æ®é›†æ‰©å±•åˆ°äº†æ„å¤§åˆ©è¯­å’Œè¥¿ç­ç‰™è¯­ç‰ˆæœ¬ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•é€šè¿‡ä¸Šä¸‹æ–‡å­¦ä¹  (In-context Learning) å’Œç›‘ç£å¾®è°ƒ (Supervised Fine-tuning) æ˜¾è‘—æå‡äº†æ¨¡å‹æ€§èƒ½ï¼Œåœ¨ 8B å‚æ•°è§„æ¨¡çš„ LLMs ä¸­è¾¾åˆ°äº† SOTA æ°´å¹³ã€‚è¯¥ç ”ç©¶ä¸ºå¼€å‘æ›´å®‰å…¨ã€é€æ˜çš„å¤šè¯­è¨€ä¸´åºŠå†³ç­–æ”¯æŒå·¥å…·æä¾›äº†æ”¯æŒï¼Œå¹¶å…¬å¼€å‘å¸ƒäº†æ¨ç†è½¨è¿¹ã€ç¿»è¯‘åçš„é—®ç­”æ•°æ®é›†ã€åŒ»å­¦ç»´åŸºç™¾ç§‘åŠå¾®è°ƒæ¨¡å‹ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Under Review",
      "pdf_url": "https://arxiv.org/pdf/2512.05658v1",
      "published_date": "2025-12-05 12:05:46 UTC",
      "updated_date": "2025-12-05 12:05:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:02:35.598057+00:00"
    },
    {
      "arxiv_id": "2512.05638v1",
      "title": "Modular Jets for Supervised Pipelines: Diagnosing Mirage vs Identifiability",
      "title_zh": "é¢å‘ç›‘ç£å¼æµæ°´çº¿çš„æ¨¡å—åŒ– Jetï¼šè¾¨æå¹»è±¡ä¸å¯è¾¨è¯†æ€§",
      "authors": [
        "Suman Sanyal"
      ],
      "abstract": "Classical supervised learning evaluates models primarily via predictive risk on hold-out data. Such evaluations quantify how well a function behaves on a distribution, but they do not address whether the internal decomposition of a model is uniquely determined by the data and evaluation design. In this paper, we introduce \\emph{Modular Jets} for regression and classification pipelines. Given a task manifold (input space), a modular decomposition, and access to module-level representations, we estimate empirical jets, which are local linear response maps that describe how each module reacts to small structured perturbations of the input. We propose an empirical notion of \\emph{mirage} regimes, where multiple distinct modular decompositions induce indistinguishable jets and thus remain observationally equivalent, and contrast this with an \\emph{identifiable} regime, where the observed jets single out a decomposition up to natural symmetries. In the setting of two-module linear regression pipelines we prove a jet-identifiability theorem. Under mild rank assumptions and access to module-level jets, the internal factorisation is uniquely determined, whereas risk-only evaluation admits a large family of mirage decompositions that implement the same input-to-output map. We then present an algorithm (MoJet) for empirical jet estimation and mirage diagnostics, and illustrate the framework using linear and deep regression as well as pipeline classification.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç›‘ç£å­¦ä¹ æµæ°´çº¿ä¸­å†…éƒ¨æ¨¡å—åŒ–åˆ†è§£çš„å”¯ä¸€æ€§é—®é¢˜ï¼Œæå‡ºäº† Modular Jets æ¡†æ¶ç”¨äºå›å½’å’Œåˆ†ç±»ä»»åŠ¡ã€‚è¯¥æ–¹æ³•é€šè¿‡ä¼°è®¡ç»éªŒå–·æµ (empirical jets)ï¼Œå³æè¿°æ¨¡å—å¯¹è¾“å…¥ç»“æ„åŒ–å¾®æ‰°ååº”çš„å±€éƒ¨çº¿æ€§å“åº”å›¾ï¼Œæ¥è¯Šæ–­æ¨¡å‹çš„å†…éƒ¨çŠ¶æ€ã€‚ç ”ç©¶å®šä¹‰äº†â€œå¹»è±¡â€ (mirage) çŠ¶æ€ä¸â€œå¯è¾¨è¯†â€ (identifiable) çŠ¶æ€ï¼Œå‰è€…æŒ‡å¤šä¸ªæˆªç„¶ä¸åŒçš„æ¨¡å—åˆ†è§£åœ¨è§‚æµ‹ä¸Šç­‰æ•ˆã€‚åœ¨åŒæ¨¡å—çº¿æ€§å›å½’åœºæ™¯ä¸‹ï¼Œä½œè€…è¯æ˜äº†å–·æµå¯è¾¨è¯†æ€§å®šç†ï¼Œè¡¨æ˜åœ¨å…·å¤‡æ¨¡å—çº§å–·æµä¿¡æ¯æ—¶ï¼Œå†…éƒ¨å› å­åˆ†è§£æ˜¯å”¯ä¸€ç¡®å®šçš„ï¼Œè€Œä¼ ç»Ÿçš„ä»…é£é™©è¯„ä¼° (risk-only evaluation) åˆ™æ— æ³•åŒºåˆ†å¹»è±¡åˆ†è§£ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜æå‡ºäº†ç”¨äºå®è¯å–·æµä¼°è®¡å’Œå¹»è±¡è¯Šæ–­çš„ MoJet ç®—æ³•ã€‚è¯¥æ¡†æ¶åœ¨çº¿æ€§å’Œæ·±åº¦å›å½’ä»¥åŠæµæ°´çº¿åˆ†ç±»å®éªŒä¸­å¾—åˆ°äº†éªŒè¯ï¼Œä¸ºè¯Šæ–­æ¨¡å‹åˆ†è§£çš„ç¡®å®šæ€§æä¾›äº†ç†è®ºä¾æ®ä¸å®ç”¨å·¥å…·ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.05638v1",
      "published_date": "2025-12-05 11:30:46 UTC",
      "updated_date": "2025-12-05 11:30:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:02:42.410347+00:00"
    },
    {
      "arxiv_id": "2512.07898v1",
      "title": "MARINE: Theoretical Optimization and Design for Multi-Agent Recursive IN-context Enhancement",
      "title_zh": "MARINEï¼šå¤šæ™ºèƒ½ä½“é€’å½’å¼ä¸Šä¸‹æ–‡å¢å¼ºçš„ç†è®ºä¼˜åŒ–ä¸è®¾è®¡",
      "authors": [
        "Hongwei Zhang",
        "Ji Lu",
        "Yongsheng Du",
        "Yanqin Gao",
        "Lingjun Huang",
        "Baoli Wang",
        "Fang Tan",
        "Peng Zou"
      ],
      "abstract": "Large Language Model (LLM)-based agents demonstrate advanced reasoning capabilities, yet practical constraints frequently limit outputs to single responses, leaving significant performance potential unrealized. This paper introduces MARINE (Multi-Agent Recursive IN-context Enhancement), a theoretically grounded framework that reconceptualizes test-time reasoning as iterative refinement of a persistent reference trajectory, fundamentally departing from conventional one-shot or multi-sample paradigms. The MARINE refinement operator systematically converts a base model's pass@N capabilities into near-optimal pass@1 performance. Rigorous theoretical analysis establishes that minimal feasible batches maximize expected performance gains under fixed invocation budgets, while logarithmically growing batch schedules ensure continuous improvement without computational constraints. Comprehensive evaluation on the BrowserComp-ZH benchmark demonstrates state-of-the-art results, with a 685B-parameter implementation achieving 46.0% pass@1 accuracy. Meanwhile, MARINE establishes a new paradigm for parameter-efficient reasoning: an 80B-parameter model augmented with MARINE matches the performance of standalone 1000B-parameter agents, reducing parameter requirements by over an order of magnitude. Notably, within a fixed computational budget, the proposed MARINE delivers higher-quality samples to alignment and optimization processes than traditional sampling-and-ranking strategies. Consequently, it has great potential to boost post-training efficiency.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†MARINE (Multi-Agent Recursive IN-context Enhancement) æ¡†æ¶ï¼Œé€šè¿‡å¯¹æŒä¹…å‚è€ƒè½¨è¿¹ (persistent reference trajectory) çš„è¿­ä»£æ”¹è¿›ï¼Œæ—¨åœ¨å°†LLMæ™ºèƒ½ä½“çš„æµ‹è¯•æ—¶æ¨ç†èƒ½åŠ›æœ€å¤§åŒ–ã€‚è¯¥æ¡†æ¶é€šè¿‡ç²¾ç‚¼ç®—å­ (refinement operator) æœ‰æ•ˆåœ°å°†åŸºç¡€æ¨¡å‹çš„ pass@N èƒ½åŠ›è½¬åŒ–ä¸ºæ¥è¿‘æœ€ä¼˜çš„ pass@1 æ€§èƒ½ï¼Œä»æ ¹æœ¬ä¸ŠåŒºåˆ«äºä¼ ç»Ÿçš„å•æ¬¡æˆ–å¤šæ ·æœ¬ç”ŸæˆèŒƒå¼ã€‚ç†è®ºåˆ†æè¯æ˜ï¼Œåœ¨å›ºå®šè°ƒç”¨é¢„ç®—ä¸‹ï¼Œæœ€å°å¯è¡Œæ‰¹æ¬¡èƒ½å®ç°æœ€å¤§çš„é¢„æœŸæ€§èƒ½å¢ç›Šï¼Œè€Œå¯¹æ•°å¢é•¿çš„æ‰¹æ¬¡è°ƒåº¦å¯ç¡®ä¿æ€§èƒ½çš„æŒç»­æå‡ã€‚åœ¨ BrowserComp-ZH åŸºå‡†æµ‹è¯•ä¸­ï¼ŒåŸºäº 685B å‚æ•°æ¨¡å‹çš„ MARINE å®ç°äº† 46.0% çš„ pass@1 å‡†ç¡®ç‡ï¼Œè¾¾åˆ° state-of-the-art æ°´å¹³ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶æ˜¾è‘—æå‡äº†æ¨ç†çš„å‚æ•°æ•ˆç‡ï¼Œä½¿ 80B å‚æ•°æ¨¡å‹èƒ½åŒ¹é… 1000B è§„æ¨¡æ™ºèƒ½ä½“çš„æ€§èƒ½ï¼Œå°†å‚æ•°éœ€æ±‚é™ä½äº†ä¸€ä¸ªæ•°é‡çº§ä»¥ä¸Šã€‚ç›¸æ¯”ä¼ ç»Ÿçš„é‡‡æ ·å’Œæ’åº (sampling-and-ranking) ç­–ç•¥ï¼ŒMARINE åœ¨å›ºå®šè®¡ç®—é¢„ç®—ä¸‹èƒ½æä¾›æ›´é«˜è´¨é‡çš„å¯¹é½ä¼˜åŒ–æ ·æœ¬ï¼Œå±•ç°å‡ºå¢å¼ºæ¨¡å‹åè®­ç»ƒ (post-training) æ•ˆç‡çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.07898v1",
      "published_date": "2025-12-05 11:19:18 UTC",
      "updated_date": "2025-12-05 11:19:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:02:45.335887+00:00"
    },
    {
      "arxiv_id": "2512.10985v1",
      "title": "Marti-5: A Mathematical Model of \"Self in the World\" as a First Step Toward Self-Awareness",
      "title_zh": "Marti-5ï¼šä½œä¸ºè¿ˆå‘è‡ªæˆ‘æ„è¯†ç¬¬ä¸€æ­¥çš„â€œä¸–ç•Œä¸­çš„è‡ªæˆ‘â€æ•°å­¦æ¨¡å‹",
      "authors": [
        "Igor Pivovarov",
        "Sergey Shumsky"
      ],
      "abstract": "The existence of 'what' and 'where' pathways of information processing in the brain was proposed almost 30 years ago, but there is still a lack of a clear mathematical model that could show how these pathways work together. We propose a biologically inspired mathematical model that uses this idea to identify and separate the self from the environment and then build and use a self-model for better predictions. This is a model of neocortical columns governed by the basal ganglia to make predictions and choose the next action, where some columns act as 'what' columns and others act as 'where' columns. Based on this model, we present a reinforcement learning agent that learns purposeful behavior in a virtual environment. We evaluate the agent on the Atari games Pong and Breakout, where it successfully learns to play. We conclude that the ability to separate the self from the environment gives advantages to the agent and therefore such a model could appear in living organisms during evolution. We propose Self-Awareness Principle 1: the ability to separate the self from the world is a necessary but insufficient condition for self-awareness.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Marti-5ï¼Œè¿™æ˜¯ä¸€ä¸ªå—ç”Ÿç‰©å­¦å¯å‘çš„æ•°å­¦æ¨¡å‹ï¼Œæ—¨åœ¨æ¢ç´¢å¤§è„‘ä¸­â€œwhatâ€å’Œâ€œwhereâ€ä¿¡æ¯å¤„ç†é€šè·¯å¦‚ä½•ååŒå·¥ä½œï¼Œå¹¶å°†å…¶ä½œä¸ºå®ç°è‡ªæˆ‘æ„è¯†çš„ç¬¬ä¸€æ­¥ã€‚è¯¥æ¨¡å‹æ¨¡æ‹Ÿäº†å— basal ganglia æ§åˆ¶çš„ neocortical columnsï¼Œé€šè¿‡åŒºåˆ†â€œwhatâ€å’Œâ€œwhereâ€åˆ—æ¥è¯†åˆ«å¹¶å°†è‡ªæˆ‘(self)ä»ç¯å¢ƒä¸­åˆ†ç¦»ï¼Œè¿›è€Œæ„å»ºè‡ªæˆ‘æ¨¡å‹(self-model)ä»¥å®ç°æ›´ä¼˜çš„é¢„æµ‹ã€‚åŸºäºæ­¤æ¨¡å‹å¼€å‘çš„å¼ºåŒ–å­¦ä¹ (reinforcement learning)æ™ºèƒ½ä½“åœ¨ Atari æ¸¸æˆçš„ Pong å’Œ Breakout ä¸­æˆåŠŸå­¦ä¹ äº†æœ‰ç›®çš„çš„è¡Œä¸ºã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œè¿™ç§åˆ†ç¦»è‡ªæˆ‘çš„èƒ½åŠ›ä¸ºæ™ºèƒ½ä½“æä¾›äº†æ˜¾è‘—ä¼˜åŠ¿ï¼Œæš—ç¤ºäº†è¯¥æ¨¡å‹åœ¨ç”Ÿç‰©è¿›åŒ–ä¸­çš„æ½œåœ¨ä»·å€¼ã€‚æœ€åï¼Œè¯¥ç ”ç©¶æå‡ºäº†è‡ªæˆ‘æ„è¯†ç¬¬ä¸€åŸåˆ™(Self-Awareness Principle 1)ï¼Œå¼ºè°ƒåŒºåˆ†è‡ªæˆ‘ä¸ä¸–ç•Œçš„èƒ½åŠ›æ˜¯å®ç°è‡ªæˆ‘æ„è¯†çš„å¿…è¦éå……åˆ†æ¡ä»¶ã€‚",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.NC",
      "comment": "21 pages, 2 figures, 2 videos, 1 table",
      "pdf_url": "https://arxiv.org/pdf/2512.10985v1",
      "published_date": "2025-12-05 11:15:06 UTC",
      "updated_date": "2025-12-05 11:15:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:02:59.810700+00:00"
    },
    {
      "arxiv_id": "2601.04200v1",
      "title": "Attribute-Aware Controlled Product Generation with LLMs for E-commerce",
      "title_zh": "åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„ç”µå•†å±æ€§æ„ŸçŸ¥å—æ§å•†å“ç”Ÿæˆ",
      "authors": [
        "Virginia Negri",
        "VÃ­ctor MartÃ­nez GÃ³mez",
        "Sergio A. Balanya",
        "Subburam Rajaram"
      ],
      "abstract": "Product information extraction is crucial for e-commerce services, but obtaining high-quality labeled datasets remains challenging. We present a systematic approach for generating synthetic e-commerce product data using Large Language Models (LLMs), introducing a controlled modification framework with three strategies: attribute-preserving modification, controlled negative example generation, and systematic attribute removal. Using a state-of-the-art LLM with attribute-aware prompts, we enforce store constraints while maintaining product coherence. Human evaluation of 2000 synthetic products demonstrates high effectiveness, with 99.6% rated as natural, 96.5% containing valid attribute values, and over 90% showing consistent attribute usage. On the public MAVE dataset, our synthetic data achieves 60.5% accuracy, performing on par with real training data (60.8%) and significantly improving upon the 13.4% zero-shot baseline. Hybrid configurations combining synthetic and real data further improve performance, reaching 68.8% accuracy. Our framework provides a practical solution for augmenting e-commerce datasets, particularly valuable for low-resource scenarios.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç”µå•†é¢†åŸŸé«˜è´¨é‡æ ‡æ³¨æ•°æ®é›†è·å–å›°éš¾çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(LLMs)è¿›è¡Œå±æ€§æ„ŸçŸ¥å—æ§äº§å“ç”Ÿæˆçš„ç³»ç»ŸåŒ–æ–¹æ³•ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†å±æ€§ä¿ç•™ä¿®æ”¹(attribute-preserving modification)ã€å—æ§è´Ÿæ ·æœ¬ç”Ÿæˆ(controlled negative example generation)ä»¥åŠç³»ç»ŸåŒ–å±æ€§ç§»é™¤(systematic attribute removal)ä¸‰ç§æ ¸å¿ƒç­–ç•¥ã€‚é€šè¿‡ä½¿ç”¨å…ˆè¿›çš„ LLM å’Œå±æ€§æ„ŸçŸ¥æç¤ºè¯ï¼Œç ”ç©¶ç¡®ä¿äº†ç”Ÿæˆæ•°æ®åœ¨æ»¡è¶³å•†åº—çº¦æŸçš„åŒæ—¶ä¿æŒäº§å“é€»è¾‘çš„è¿è´¯æ€§ã€‚äººå·¥è¯„ä¼°è¯æ˜äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œè¶…è¿‡99.6%çš„åˆæˆäº§å“è¢«è¯„ä¸ºè‡ªç„¶ä¸”åŒ…å«æœ‰æ•ˆçš„å±æ€§å€¼ã€‚åœ¨å…¬å¼€æ•°æ®é›† MAVE ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œä»…ä½¿ç”¨åˆæˆæ•°æ®å³å¯è¾¾åˆ°60.5%çš„å‡†ç¡®ç‡ï¼Œä¸çœŸå®è®­ç»ƒæ•°æ®è¡¨ç°æŒå¹³ï¼Œä¸”æ˜¾è‘—ä¼˜äº13.4%çš„é›¶æ ·æœ¬(zero-shot)åŸºå‡†ã€‚æœ€åï¼Œç»“åˆåˆæˆä¸çœŸå®æ•°æ®çš„æ··åˆé…ç½®è¿›ä¸€æ­¥å°†å‡†ç¡®ç‡æå‡è‡³68.8%ï¼Œä¸ºä½èµ„æºç”µå•†åœºæ™¯ä¸‹çš„æ•°æ®å¢å¼ºæä¾›äº†é«˜æ•ˆä¸”å®ç”¨çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "AAAI'26 Workshop on Shaping Responsible Synthetic Data in the Era of Foundation Models (RSD)",
      "pdf_url": "https://arxiv.org/pdf/2601.04200v1",
      "published_date": "2025-12-05 11:12:10 UTC",
      "updated_date": "2025-12-05 11:12:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:03:27.181854+00:00"
    },
    {
      "arxiv_id": "2512.05619v1",
      "title": "Enhancing Local Search for MaxSAT with Deep Differentiation Clause Weighting",
      "title_zh": "åŸºäºæ·±åº¦å·®å¼‚åŒ–å­å¥åŠ æƒçš„ MaxSAT å±€éƒ¨æœç´¢å¢å¼º",
      "authors": [
        "Menghua Jiang",
        "Haokai Gao",
        "Shuhao Chen",
        "Yin Chen"
      ],
      "abstract": "Partial Maximum Satisfiability (PMS) and Weighted Partial Maximum Satisfiability (WPMS) generalize Maximum Satisfiability (MaxSAT), with broad real-world applications. Recent advances in Stochastic Local Search (SLS) algorithms for solving (W)PMS have mainly focused on designing clause weighting schemes. However, existing methods often fail to adequately distinguish between PMS and WPMS, typically employing uniform update strategies for clause weights and overlooking critical structural differences between the two problem types. In this work, we present a novel clause weighting scheme that, for the first time, updates the clause weights of PMS and WPMS instances according to distinct conditions. This scheme also introduces a new initialization method, which better accommodates the unique characteristics of both instance types. Furthermore, we propose a decimation method that prioritizes satisfying unit and hard clauses, effectively complementing our proposed clause weighting scheme. Building on these methods, we develop a new SLS solver for (W)PMS named DeepDist. Experimental results on benchmarks from the anytime tracks of recent MaxSAT Evaluations show that DeepDist outperforms state-of-the-art SLS solvers. Notably, a hybrid solver combining DeepDist with TT-Open-WBO-Inc surpasses the performance of the MaxSAT Evaluation 2024 winners, SPB-MaxSAT-c-Band and SPB-MaxSAT-c-FPS, highlighting the effectiveness of our approach. The code is available at https://github.com/jmhmaxsat/DeepDist",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹éƒ¨åˆ†æå¤§å¯æ»¡è¶³æ€§é—®é¢˜(PMS)å’ŒåŠ æƒéƒ¨åˆ†æå¤§å¯æ»¡è¶³æ€§é—®é¢˜(WPMS)æå‡ºäº†ä¸€ç§åä¸ºDeepDistçš„éšæœºå±€éƒ¨æœç´¢(Stochastic Local Search, SLS)æ±‚è§£å™¨ã€‚é’ˆå¯¹ç°æœ‰SLSç®—æ³•åœ¨å¤„ç†PMSå’ŒWPMSæ—¶é‡‡ç”¨ç»Ÿä¸€æƒé‡æ›´æ–°ç­–ç•¥ã€å¿½è§†ä¸¤è€…ç»“æ„å·®å¼‚çš„å±€é™æ€§ï¼ŒDeepDisté¦–æ¬¡å¼•å…¥äº†ä¸€ç§æ·±åº¦å·®å¼‚åŒ–å­å¥åŠ æƒ(Deep Differentiation Clause Weighting)æ–¹æ¡ˆï¼Œèƒ½å¤Ÿæ ¹æ®ä¸åŒå®ä¾‹ç±»å‹çš„ç‰¹ç‚¹é‡‡å–ä¸åŒçš„æ›´æ–°æ¡ä»¶ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜æå‡ºäº†ä¸€ç§æ–°çš„åˆå§‹åŒ–æ–¹æ³•ä»¥åŠä¸€ç§ä¼˜å…ˆæ»¡è¶³å•å­å¥(unit clause)å’Œç¡¬å­å¥(hard clause)çš„æ¶ˆå‡æ–¹æ³•ï¼Œæœ‰æ•ˆåœ°è¡¥å……äº†åŠ æƒæ–¹æ¡ˆã€‚åœ¨è¿‘å¹´MaxSAT EvaluationåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDeepDistçš„è¡¨ç°ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›SLSæ±‚è§£å™¨ã€‚ç‰¹åˆ«æ˜¯åœ¨å°†DeepDistä¸TT-Open-WBO-Incç»“åˆåï¼Œå…¶æ€§èƒ½è¶…è¶Šäº†MaxSAT Evaluation 2024çš„å† å†›æ¨¡å‹ï¼Œè¯æ˜äº†è¯¥å·®å¼‚åŒ–ç­–ç•¥åœ¨è§£å†³å¤æ‚ç»„åˆä¼˜åŒ–é—®é¢˜ä¸­çš„å“è¶Šæ•ˆèƒ½ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by ECAI 2025",
      "pdf_url": "https://arxiv.org/pdf/2512.05619v1",
      "published_date": "2025-12-05 11:02:17 UTC",
      "updated_date": "2025-12-05 11:02:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:04:04.588682+00:00"
    },
    {
      "arxiv_id": "2512.08981v1",
      "title": "Mitigating Bias with Words: Inducing Demographic Ambiguity in Face Recognition Templates by Text Encoding",
      "title_zh": "ä»¥è¨€è¯­å‡è½»åè§ï¼šé€šè¿‡æ–‡æœ¬ç¼–ç åœ¨äººè„¸è¯†åˆ«æ¨¡æ¿ä¸­è¯±å¯¼äººå£ç»Ÿè®¡å­¦æ¨¡ç³Šæ€§",
      "authors": [
        "Tahar Chettaoui",
        "Naser Damer",
        "Fadi Boutros"
      ],
      "abstract": "Face recognition (FR) systems are often prone to demographic biases, partially due to the entanglement of demographic-specific information with identity-relevant features in facial embeddings. This bias is extremely critical in large multicultural cities, especially where biometrics play a major role in smart city infrastructure. The entanglement can cause demographic attributes to overshadow identity cues in the embedding space, resulting in disparities in verification performance across different demographic groups. To address this issue, we propose a novel strategy, Unified Text-Image Embedding (UTIE), which aims to induce demographic ambiguity in face embeddings by enriching them with information related to other demographic groups. This encourages face embeddings to emphasize identity-relevant features and thus promotes fairer verification performance across groups. UTIE leverages the zero-shot capabilities and cross-modal semantic alignment of Vision-Language Models (VLMs). Given that VLMs are naturally trained to align visual and textual representations, we enrich the facial embeddings of each demographic group with text-derived demographic features extracted from other demographic groups. This encourages a more neutral representation in terms of demographic attributes. We evaluate UTIE using three VLMs, CLIP, OpenCLIP, and SigLIP, on two widely used benchmarks, RFW and BFW, designed to assess bias in FR. Experimental results show that UTIE consistently reduces bias metrics while maintaining, or even improving in several cases, the face verification accuracy.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹äººè„¸è¯†åˆ«(Face Recognition)ç³»ç»Ÿç”±äºèº«ä»½ç‰¹å¾ä¸äººå£ç»Ÿè®¡ç‰¹å¾äº¤ç»‡è€Œå¯¼è‡´çš„åè§é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºç»Ÿä¸€æ–‡æœ¬-å›¾åƒåµŒå…¥(Unified Text-Image Embedding, UTIE)çš„åˆ›æ–°ç­–ç•¥ã€‚UTIEåˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡å‹(Vision-Language Models, VLMs)çš„è·¨æ¨¡æ€è¯­ä¹‰å¯¹é½èƒ½åŠ›ï¼Œé€šè¿‡å°†ç‰¹å®šäººç¾¤çš„è„¸éƒ¨åµŒå…¥ä¸æ¥è‡ªå…¶ä»–äººå£ç»Ÿè®¡ç»„çš„æ–‡æœ¬ç‰¹å¾ç›¸ç»“åˆï¼Œåœ¨åµŒå…¥ç©ºé—´ä¸­è¯±å¯¼äººå£ç»Ÿè®¡æ¨¡ç³Šæ€§(Demographic Ambiguity)ã€‚è¿™ç§æ–¹æ³•ä¿ƒä½¿äººè„¸åµŒå…¥æ›´ä¾§é‡äºæå–èº«ä»½ç›¸å…³ç‰¹å¾ï¼Œä»è€Œå‡å°‘äº†äººå£ç»Ÿè®¡å±æ€§å¯¹è¯†åˆ«ç»“æœçš„å¹²æ‰°ã€‚ç ”ç©¶äººå‘˜åœ¨CLIPã€OpenCLIPå’ŒSigLIPç­‰æ¨¡å‹ä¸Šè¿›è¡Œäº†å®éªŒï¼Œå¹¶åœ¨RFWå’ŒBFWä¸¤ä¸ªä¸»æµåè§è¯„ä¼°åŸºå‡†ä¸Šè¿›è¡Œäº†æµ‹è¯•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒUTIEä¸ä»…èƒ½æŒç»­é™ä½åè§æŒ‡æ ‡ï¼Œåœ¨å¤šä¸ªæ¡ˆä¾‹ä¸­è¿˜ç»´æŒæˆ–æå‡äº†äººè„¸éªŒè¯çš„å‡†ç¡®ç‡ï¼Œè¯æ˜äº†é€šè¿‡æ–‡æœ¬ç¼–ç ç¼“è§£ç”Ÿç‰©è¯†åˆ«åè§çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at BMVC workshop (SRBS) 2025",
      "pdf_url": "https://arxiv.org/pdf/2512.08981v1",
      "published_date": "2025-12-05 10:41:58 UTC",
      "updated_date": "2025-12-05 10:41:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:03:11.119462+00:00"
    },
    {
      "arxiv_id": "2512.05594v1",
      "title": "Ontology Learning with LLMs: A Benchmark Study on Axiom Identification",
      "title_zh": "åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„æœ¬ä½“å­¦ä¹ ï¼šå…¬ç†è¯†åˆ«åŸºå‡†ç ”ç©¶",
      "authors": [
        "Roos M. Bakker",
        "Daan L. Di Scala",
        "Maaike H. T. de Boer",
        "Stephan A. Raaijmakers"
      ],
      "abstract": "Ontologies are an important tool for structuring domain knowledge, but their development is a complex task that requires significant modelling and domain expertise. Ontology learning, aimed at automating this process, has seen advancements in the past decade with the improvement of Natural Language Processing techniques, and especially with the recent growth of Large Language Models (LLMs). This paper investigates the challenge of identifying axioms: fundamental ontology components that define logical relations between classes and properties. In this work, we introduce an Ontology Axiom Benchmark OntoAxiom, and systematically test LLMs on that benchmark for axiom identification, evaluating different prompting strategies, ontologies, and axiom types. The benchmark consists of nine medium-sized ontologies with together 17.118 triples, and 2.771 axioms. We focus on subclass, disjoint, subproperty, domain, and range axioms. To evaluate LLM performance, we compare twelve LLMs with three shot settings and two prompting strategies: a Direct approach where we query all axioms at once, versus an Axiom-by-Axiom (AbA) approach, where each prompt queries for one axiom only. Our findings show that the AbA prompting leads to higher F1 scores than the direct approach. However, performance varies across axioms, suggesting that certain axioms are more challenging to identify. The domain also influences performance: the FOAF ontology achieves a score of 0.642 for the subclass axiom, while the music ontology reaches only 0.218. Larger LLMs outperform smaller ones, but smaller models may still be viable for resource-constrained settings. Although performance overall is not high enough to fully automate axiom identification, LLMs can provide valuable candidate axioms to support ontology engineers with the development and refinement of ontologies.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(LLMs)è¿›è¡Œæœ¬ä½“å­¦ä¹ (Ontology Learning)ä¸­çš„å…¬ç†è¯†åˆ«(Axiom Identification)æŒ‘æˆ˜ï¼Œæ—¨åœ¨è‡ªåŠ¨åŒ–æ„å»ºå¤æ‚çš„é¢†åŸŸçŸ¥è¯†ç»“æ„ã€‚ç ”ç©¶å›¢é˜Ÿå¼•å…¥äº†OntoAxiomåŸºå‡†æµ‹è¯•é›†ï¼Œæ¶µç›–9ä¸ªæœ¬ä½“åŠ2771ä¸ªå…¬ç†ï¼Œé‡ç‚¹è¯„ä¼°äº†å­ç±»(subclass)ã€ä¸ç›¸äº¤(disjoint)ã€åŸŸ(domain)å’Œå€¼åŸŸ(range)ç­‰å…³é”®å…¬ç†ã€‚é€šè¿‡å¯¹æ¯”12ä¸ªLLMsåœ¨ç›´æ¥æ–¹æ³•(Direct approach)ä¸é€ä¸ªå…¬ç†æŸ¥è¯¢(Axiom-by-Axiom, AbA)ç­–ç•¥ä¸‹çš„è¡¨ç°ï¼Œå®éªŒå‘ç°AbAæ–¹æ³•èƒ½æ˜¾è‘—æå‡F1åˆ†æ•°ã€‚ç ”ç©¶æŒ‡å‡ºæ€§èƒ½è¡¨ç°å—å…¬ç†ç±»å‹å’Œç‰¹å®šé¢†åŸŸï¼ˆå¦‚FOAFä¸éŸ³ä¹æœ¬ä½“ï¼‰çš„æ˜¾è‘—å½±å“ï¼Œä¸”æ¨¡å‹è§„æ¨¡ä¸å‡†ç¡®ç‡å‘ˆæ­£ç›¸å…³ã€‚æœ€ç»ˆç»“æœè¡¨æ˜ï¼Œå°½ç®¡ç›®å‰LLMsçš„æ•´ä½“æ€§èƒ½å°šä¸è¶³ä»¥å®ç°å®Œå…¨è‡ªåŠ¨åŒ–çš„å…¬ç†è¯†åˆ«ï¼Œä½†å…¶èƒ½å¤Ÿæä¾›æœ‰ä»·å€¼çš„å€™é€‰å…¬ç†ï¼Œæœ‰æ•ˆè¾…åŠ©æœ¬ä½“å·¥ç¨‹å¸ˆè¿›è¡ŒçŸ¥è¯†å»ºæ¨¡çš„å¼€å‘ä¸ç²¾ç‚¼ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Submitted to Semantic Web Journal, under review",
      "pdf_url": "https://arxiv.org/pdf/2512.05594v1",
      "published_date": "2025-12-05 10:28:56 UTC",
      "updated_date": "2025-12-05 10:28:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:03:18.292397+00:00"
    },
    {
      "arxiv_id": "2512.06048v1",
      "title": "The Road of Adaptive AI for Precision in Cybersecurity",
      "title_zh": "ç½‘ç»œå®‰å…¨ç²¾å‡†åŒ–ï¼šè‡ªé€‚åº”äººå·¥æ™ºèƒ½çš„æ¼”è¿›ä¹‹è·¯",
      "authors": [
        "Sahil Garg"
      ],
      "abstract": "Cybersecurity's evolving complexity presents unique challenges and opportunities for AI research and practice. This paper shares key lessons and insights from designing, building, and operating production-grade GenAI pipelines in cybersecurity, with a focus on the continual adaptation required to keep pace with ever-shifting knowledge bases, tooling, and threats. Our goal is to provide an actionable perspective for AI practitioners and industry stakeholders navigating the frontier of GenAI for cybersecurity, with particular attention to how different adaptation mechanisms complement each other in end-to-end systems. We present practical guidance derived from real-world deployments, propose best practices for leveraging retrieval- and model-level adaptation, and highlight open research directions for making GenAI more robust, precise, and auditable in cyber defense.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨ç½‘ç»œå®‰å…¨é¢†åŸŸåˆ©ç”¨è‡ªé€‚åº”äººå·¥æ™ºèƒ½å®ç°ç²¾å‡†é˜²å¾¡çš„è·¯å¾„ï¼Œåˆ†äº«äº†åœ¨è®¾è®¡å’Œè¿è¡Œç”Ÿäº§çº§ GenAI æµæ°´çº¿è¿‡ç¨‹ä¸­çš„å…³é”®ç»éªŒã€‚æ–‡ç« é‡ç‚¹å…³æ³¨å¦‚ä½•é€šè¿‡æŒç»­é€‚åº”æœºåˆ¶ï¼ˆcontinual adaptationï¼‰æ¥åº”å¯¹ä¸æ–­å˜åŒ–çš„çŸ¥è¯†åº“ã€å·¥å…·å’Œå¨èƒï¼Œå¹¶æ·±å…¥åˆ†æäº†æ£€ç´¢çº§ï¼ˆretrieval-levelï¼‰ä¸æ¨¡å‹çº§ï¼ˆmodel-levelï¼‰é€‚åº”æŠ€æœ¯åœ¨ç«¯åˆ°ç«¯ç³»ç»Ÿä¸­çš„äº’è¡¥ä½œç”¨ã€‚é€šè¿‡æ€»ç»“å®é™…éƒ¨ç½²ä¸­çš„å®è·µæŒ‡å—ï¼Œæœ¬æ–‡ä¸º AI ä»ä¸šè€…å’Œè¡Œä¸šåˆ©ç›Šç›¸å…³è€…æä¾›äº†å…³äº GenAI åœ¨ç½‘ç»œé˜²å¾¡ä¸­åº”ç”¨çš„è¡ŒåŠ¨å»ºè®®ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜æ˜ç¡®äº†æå‡ GenAI é²æ£’æ€§ã€ç²¾ç¡®æ€§å’Œå¯å®¡è®¡æ€§çš„æœªæ¥ç ”ç©¶æ–¹å‘ï¼Œæ—¨åœ¨æ¨åŠ¨æ„å»ºæ›´å¯é ã€æ›´å…·å¼¹æ€§çš„ç½‘ç»œå®‰å…¨é˜²å¾¡ä½“ç³»ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.06048v1",
      "published_date": "2025-12-05 10:16:45 UTC",
      "updated_date": "2025-12-05 10:16:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:03:16.696032+00:00"
    },
    {
      "arxiv_id": "2512.11863v1",
      "title": "Expert Assessment: The Systemic Environmental Risks of Artficial Intelligence",
      "title_zh": "ä¸“å®¶è¯„ä¼°ï¼šäººå·¥æ™ºèƒ½çš„ç³»ç»Ÿæ€§ç¯å¢ƒé£é™©",
      "authors": [
        "Julian SchÃ¶n",
        "Lena Hoffmann",
        "Nikolas Becker"
      ],
      "abstract": "Artificial intelligence (AI) is often presented as a key tool for addressing societal challenges, such as climate change. At the same time, AI's environmental footprint is expanding increasingly. This report describes the systemic environmental risks of artificial intelligence, in particular, moving beyond direct impacts such as energy and water usage. Systemic environmental risks of AI are emergent, cross-sector harms to climate, biodiversity, freshwater, and broader socioecological systems that arise primarily from AI's integration into social, economic, and physical infrastructures, rather than its direct resource use, and that propagate through feedbacks, yielding nonlinear, inequitable, and potentially irreversible impacts. While these risks are emergent and quantification is uncertain, this report aims to provide an overview of systemic environmental risks. Drawing on a narrative literature review, we propose a three-level framework that operationalizes systemic risk analysis. The framework identifies the structural conditions that shape AI development, the risk amplification mechanisms that propagate environmental harm, and the impacts that manifest as observable ecological and social consequences. We illustrate the framework in expert-interview-based case studies across agriculture and biodiversity, oil and gas, and waste management.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†äººå·¥æ™ºèƒ½(AI)å¸¦æ¥çš„ç³»ç»Ÿæ€§ç¯å¢ƒé£é™©(Systemic environmental risks)ï¼ŒæŒ‡å‡ºå…¶å½±å“å·²è¶…è¶Šèƒ½æºå’Œæ°´èµ„æºæ¶ˆè€—ç­‰ç›´æ¥èŒƒç•´ï¼Œæ¶‰åŠå¯¹æ°”å€™ã€ç”Ÿç‰©å¤šæ ·æ€§å’Œæ·¡æ°´ç³»ç»Ÿçš„è·¨éƒ¨é—¨å±å®³ã€‚ä½œè€…æå‡ºäº†ä¸€ä¸ªä¸‰å±‚åˆ†ææ¡†æ¶(Three-level framework)ï¼Œç”¨äºè¯†åˆ«å¡‘é€ AIå‘å±•çš„ç»“æ„æ€§æ¡ä»¶ã€ä¼ æ’­ç¯å¢ƒå±å®³çš„é£é™©æ”¾å¤§æœºåˆ¶(Risk amplification mechanisms)ï¼Œä»¥åŠæœ€ç»ˆè¡¨ç°å‡ºçš„ç”Ÿæ€å’Œç¤¾ä¼šå½±å“ã€‚è¯¥æ¡†æ¶å¼ºè°ƒï¼ŒAIé€šè¿‡ä¸ç¤¾ä¼šã€ç»æµå’Œç‰©ç†åŸºç¡€è®¾æ–½çš„æ•´åˆï¼Œå¯èƒ½äº§ç”Ÿéçº¿æ€§ã€ä¸å¹³ç­‰ä¸”ä¸å¯é€†çš„è´Ÿé¢åé¦ˆã€‚é€šè¿‡å¯¹å†œä¸šã€ç”Ÿç‰©å¤šæ ·æ€§ã€çŸ³æ²¹å¤©ç„¶æ°”åŠåºŸç‰©ç®¡ç†ç­‰é¢†åŸŸçš„ä¸“å®¶è®¿è°ˆæ¡ˆä¾‹ç ”ç©¶ï¼ŒæŠ¥å‘Šæ­ç¤ºäº†è¿™äº›æ–°å…´é£é™©åœ¨ä¸åŒè¡Œä¸šä¸­çš„å…·ä½“è¡¨ç°ã€‚è¯¥ç ”ç©¶ä¸ºé‡åŒ–ä¸ç¡®å®šæ€§è¾ƒé«˜çš„AIç¯å¢ƒå½±å“æä¾›äº†ç³»ç»Ÿæ€§çš„ç†è®ºç»¼è¿°å’Œè¯„ä¼°å·¥å…·ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.11863v1",
      "published_date": "2025-12-05 10:15:06 UTC",
      "updated_date": "2025-12-05 10:15:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:03:28.876276+00:00"
    },
    {
      "arxiv_id": "2512.08980v2",
      "title": "Training Multi-Image Vision Agents via End2End Reinforcement Learning",
      "title_zh": "åŸºäºç«¯åˆ°ç«¯å¼ºåŒ–å­¦ä¹ çš„å¤šå›¾åƒè§†è§‰æ™ºèƒ½ä½“è®­ç»ƒ",
      "authors": [
        "Chengqi Dong",
        "Chuhuai Yue",
        "Hang He",
        "Rongge Mao",
        "Fenghe Tang",
        "S Kevin Zhou",
        "Zekun Xu",
        "Xiaohan Wang",
        "Jiajun Chai",
        "Wei Lin",
        "Guojun Yin"
      ],
      "abstract": "Recent VLM-based agents aim to replicate OpenAI O3's ``thinking with images\" via tool use, but most open-source methods limit input to a single image, falling short on real-world multi-image QA tasks. To address this, we propose IMAgent, an open-source vision agent trained via end-to-end reinforcement learning dedicated for complex multi-image tasks. By leveraging a multi-agent system, we generate challenging and visually-rich multi-image QA pairs to fully activate the tool-use potential of the base VLM. Through manual verification, we obtain MIFG-QA, comprising 10k samples for training and evaluation. With deeper reasoning steps, VLMs may increasingly ignore visual inputs. We therefore develop two specialized tools for visual reflection and confirmation, allowing the model to proactively reallocate its attention to image content during inference. Benefiting from our well-designed action-trajectory two-level mask strategy, IMAgent achieves stable tool use behavior via pure RL training without requiring costly supervised fine-tuning data. Extensive experiments demonstrate that IMAgent maintains strong performance on existing single-image benchmarks while achieving substantial improvements on our proposed multi-image dataset, with our analysis providing actionable insights for the research community. Codes and data will be released soon.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰è§†è§‰è¯­è¨€æ¨¡å‹(VLMs)åœ¨å¤„ç†å¤šå›¾é—®ç­”ä»»åŠ¡æ—¶çš„å±€é™æ€§ï¼Œæå‡ºäº†IMAgentï¼Œä¸€ä¸ªé€šè¿‡ç«¯åˆ°ç«¯å¼ºåŒ–å­¦ä¹ (End2End Reinforcement Learning)è®­ç»ƒçš„å¼€æºè§†è§‰æ™ºèƒ½ä½“ã€‚ä¸ºäº†æ¿€å‘æ¨¡å‹åœ¨å¤æ‚åœºæ™¯ä¸‹çš„å·¥å…·ä½¿ç”¨èƒ½åŠ›ï¼Œä½œè€…åˆ©ç”¨å¤šæ™ºèƒ½ä½“ç³»ç»Ÿç”Ÿæˆäº†åŒ…å«1ä¸‡ä¸ªæ ·æœ¬çš„MIFG-QAæ•°æ®é›†ï¼Œä¸“é—¨ç”¨äºå¤šå›¾è§†è§‰æ¨ç†ä»»åŠ¡çš„è®­ç»ƒä¸è¯„ä¼°ã€‚é’ˆå¯¹é•¿é“¾æ¡æ¨ç†è¿‡ç¨‹ä¸­æ¨¡å‹å®¹æ˜“å¿½ç•¥å›¾åƒå†…å®¹çš„é—®é¢˜ï¼Œç ”ç©¶å¼€å‘äº†è§†è§‰åæ€(Visual Reflection)å’Œè§†è§‰ç¡®è®¤(Visual Confirmation)ä¸¤ç§ä¸“ç”¨å·¥å…·ï¼Œä¿ƒä½¿æ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­ä¸»åŠ¨é‡æ–°åˆ†é…æ³¨æ„åŠ›ã€‚æ­¤å¤–ï¼ŒIMAgenté‡‡ç”¨äº†ç²¾å¿ƒè®¾è®¡çš„åŠ¨ä½œè½¨è¿¹åŒå±‚æ©ç ç­–ç•¥(Action-Trajectory Two-Level Mask Strategy)ï¼Œå®ç°äº†åœ¨æ— éœ€æ˜‚è´µçš„æœ‰ç›‘ç£å¾®è°ƒ(SFT)æ•°æ®çš„æƒ…å†µä¸‹ï¼Œé€šè¿‡çº¯å¼ºåŒ–å­¦ä¹ è·å¾—ç¨³å®šçš„å·¥å…·ä½¿ç”¨è¡Œä¸ºã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒIMAgentåœ¨ä¿æŒç°æœ‰å•å›¾åŸºå‡†æµ‹è¯•æ€§èƒ½çš„åŒæ—¶ï¼Œåœ¨å¤šå›¾ä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—è¿›æ­¥ï¼Œä¸ºå¤šå›¾è§†è§‰æ™ºèƒ½ä½“çš„ç ”ç©¶æä¾›äº†é‡è¦è§è§£ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.08980v2",
      "published_date": "2025-12-05 10:02:38 UTC",
      "updated_date": "2025-12-16 14:00:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:03:29.658108+00:00"
    },
    {
      "arxiv_id": "2512.05579v1",
      "title": "A Comprehensive Framework for Automated Quality Control in the Automotive Industry",
      "title_zh": "æ±½è½¦å·¥ä¸šè‡ªåŠ¨åŒ–è´¨é‡æ§åˆ¶ç»¼åˆæ¡†æ¶",
      "authors": [
        "Panagiota Moraiti",
        "Panagiotis Giannikos",
        "Athanasios Mastrogeorgiou",
        "Panagiotis Mavridis",
        "Linghao Zhou",
        "Panagiotis Chatzakos"
      ],
      "abstract": "This paper presents a cutting-edge robotic inspection solution designed to automate quality control in automotive manufacturing. The system integrates a pair of collaborative robots, each equipped with a high-resolution camera-based vision system to accurately detect and localize surface and thread defects in aluminum high-pressure die casting (HPDC) automotive components. In addition, specialized lenses and optimized lighting configurations are employed to ensure consistent and high-quality image acquisition. The YOLO11n deep learning model is utilized, incorporating additional enhancements such as image slicing, ensemble learning, and bounding-box merging to significantly improve performance and minimize false detections. Furthermore, image processing techniques are applied to estimate the extent of the detected defects. Experimental results demonstrate real-time performance with high accuracy across a wide variety of defects, while minimizing false detections. The proposed solution is promising and highly scalable, providing the flexibility to adapt to various production environments and meet the evolving demands of the automotive industry.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§ä¸“ä¸ºæ±½è½¦åˆ¶é€ è‡ªåŠ¨åŒ–è´¨é‡æ§åˆ¶è®¾è®¡çš„æœºå™¨äººæ£€æµ‹æ¡†æ¶ã€‚è¯¥ç³»ç»Ÿé›†æˆäº†åä½œæœºå™¨äºº(collaborative robots)ä¸é«˜åˆ†è¾¨ç‡è§†è§‰ç³»ç»Ÿï¼Œé€šè¿‡ä¼˜åŒ–çš„å…‰å­¦é…ç½®ç²¾ç¡®è¯†åˆ«é“åˆé‡‘é«˜å‹å‹é“¸(HPDC)ç»„ä»¶çš„è¡¨é¢åŠèºçº¹ç¼ºé™·ã€‚æŠ€æœ¯æ ¸å¿ƒé‡‡ç”¨äº† YOLO11n æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œå¹¶å¼•å…¥å›¾åƒåˆ‡ç‰‡(image slicing)ã€é›†æˆå­¦ä¹ (ensemble learning)åŠè¾¹ç•Œæ¡†åˆå¹¶(bounding-box merging)ç­‰å¢å¼ºæ‰‹æ®µï¼Œæ˜¾è‘—æå‡äº†æ£€æµ‹ç²¾åº¦å¹¶æœ‰æ•ˆé™ä½äº†è¯¯æŠ¥ç‡ã€‚æ­¤å¤–ï¼Œæ¡†æ¶ç»“åˆå›¾åƒå¤„ç†ç®—æ³•å®ç°äº†å¯¹ç¼ºé™·ç¨‹åº¦çš„å®šé‡è¯„ä¼°ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ¡ˆåœ¨å¤šç§ç¼ºé™·åœºæ™¯ä¸‹å‡è¡¨ç°å‡ºä¼˜å¼‚çš„å®æ—¶æ€§å’Œå‡†ç¡®æ€§ã€‚å‡­å€Ÿå…¶é«˜åº¦çš„å¯æ‰©å±•æ€§ä¸çµæ´»æ€§ï¼Œè¯¥ç ”ç©¶ä¸ºåº”å¯¹æ±½è½¦è¡Œä¸šå¤æ‚çš„ç”Ÿäº§ç¯å¢ƒåŠæ¼”è¿›éœ€æ±‚æä¾›äº†å¯é çš„è‡ªåŠ¨åŒ–è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.05579v1",
      "published_date": "2025-12-05 09:59:10 UTC",
      "updated_date": "2025-12-05 09:59:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:03:32.968065+00:00"
    },
    {
      "arxiv_id": "2512.05576v1",
      "title": "CureAgent: A Training-Free Executor-Analyst Framework for Clinical Reasoning",
      "title_zh": "CureAgentï¼šä¸€ç§ç”¨äºä¸´åºŠæ¨ç†çš„æ— éœ€è®­ç»ƒå‹â€œæ‰§è¡Œè€…-åˆ†æè€…â€æ¡†æ¶",
      "authors": [
        "Ting-Ting Xie",
        "Yixin Zhang"
      ],
      "abstract": "Current clinical agent built on small LLMs, such as TxAgent suffer from a \\textit{Context Utilization Failure}, where models successfully retrieve biomedical evidence due to supervised finetuning but fail to ground their diagnosis in that information. In this work, we propose the Executor-Analyst Framework, a modular architecture that decouples the syntactic precision of tool execution from the semantic robustness of clinical reasoning. By orchestrating specialized TxAgents (Executors) with long-context foundation models (Analysts), we mitigate the reasoning deficits observed in monolithic models. Beyond simple modularity, we demonstrate that a Stratified Ensemble strategy significantly outperforms global pooling by preserving evidentiary diversity, effectively addressing the information bottleneck. Furthermore, our stress tests reveal critical scaling insights: (1) a \\textit{Context-Performance Paradox}, where extending reasoning contexts beyond 12k tokens introduces noise that degrades accuracy; and (2) the \\textit{Curse of Dimensionality} in action spaces, where expanding toolsets necessitates hierarchical retrieval strategies. Crucially, our approach underscores the potential of training-free architectural engineering, achieving state-of-the-art performance on CURE-Bench without the need for expensive end-to-end finetuning. This provides a scalable, agile foundation for the next generation of trustworthy AI-driven therapeutics. Code has been released on https://github.com/June01/CureAgent.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† CureAgentï¼Œè¿™æ˜¯ä¸€ä¸ªæ— éœ€è®­ç»ƒçš„ Executor-Analyst æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä¸´åºŠæ™ºèƒ½ä½“åœ¨ Context Utilization Failure æ–¹é¢çš„é—®é¢˜ï¼Œå³æ¨¡å‹è™½èƒ½æ£€ç´¢ç”Ÿç‰©åŒ»å­¦è¯æ®å´æ— æ³•å°†å…¶æœ‰æ•ˆåº”ç”¨äºè¯Šæ–­ã€‚è¯¥æ¡†æ¶é‡‡ç”¨æ¨¡å—åŒ–æ¶æ„ï¼Œå°†ä¸“é—¨æ‰§è¡Œå·¥å…·çš„ TxAgents (Executors) ä¸å…·å¤‡é•¿ä¸Šä¸‹æ–‡èƒ½åŠ›çš„åŸºåº§æ¨¡å‹ (Analysts) ç›¸ç»“åˆï¼Œå®ç°äº†è¯­æ³•æ‰§è¡Œç²¾åº¦ä¸è¯­ä¹‰æ¨ç†é²æ£’æ€§çš„è§£è€¦ã€‚ä¸ºäº†å…‹æœä¿¡æ¯ç“¶é¢ˆï¼Œç ”ç©¶å¼•å…¥äº† Stratified Ensemble ç­–ç•¥ï¼Œé€šè¿‡ä¿ç•™è¯æ®çš„å¤šæ ·æ€§æ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„å…¨å±€æ± åŒ–æ–¹æ³•ã€‚å‹åŠ›æµ‹è¯•æ­ç¤ºäº† Context-Performance Paradox ç°è±¡ï¼Œå³å½“æ¨ç†ä¸Šä¸‹æ–‡è¶…è¿‡ 12k tokens æ—¶ï¼Œå™ªå£°çš„å¼•å…¥åè€Œä¼šå¯¼è‡´å‡†ç¡®ç‡ä¸‹é™ã€‚æ­¤å¤–ï¼Œç ”ç©¶å‘ç°åŠ¨ä½œç©ºé—´ä¸­å­˜åœ¨ Curse of Dimensionalityï¼Œè¡¨æ˜åœ¨æ‰©å±•å·¥å…·é›†æ—¶å¿…é¡»é‡‡ç”¨å±‚æ¬¡åŒ–æ£€ç´¢ç­–ç•¥ã€‚å®éªŒè¯æ˜ï¼ŒCureAgent åœ¨ CURE-Bench ä¸Šè¾¾åˆ°äº† state-of-the-art æ€§èƒ½ï¼Œä¸”æ— éœ€æ˜‚è´µçš„ç«¯åˆ°ç«¯å¾®è°ƒï¼Œä¸ºæ„å»ºå¯æ‰©å±•ã€æ•æ·ä¸”å¯ä¿¡çš„ AI é©±åŠ¨æ²»ç–—æ–¹æ¡ˆæä¾›äº†é‡è¦åŸºç¡€ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "2nd Place Solution to the CURE-Bench Competition @ NeurIPS 2025. Code available at https://github.com/June01/CureAgent",
      "pdf_url": "https://arxiv.org/pdf/2512.05576v1",
      "published_date": "2025-12-05 09:56:58 UTC",
      "updated_date": "2025-12-05 09:56:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:04:18.472605+00:00"
    },
    {
      "arxiv_id": "2512.06046v1",
      "title": "Beyond Prototyping: Autonomous, Enterprise-Grade Frontend Development from Pixel to Production via a Specialized Multi-Agent Framework",
      "title_zh": "è¶…è¶ŠåŸå‹ï¼šåŸºäºä¸“ç”¨å¤šæ™ºèƒ½ä½“æ¡†æ¶å®ç°ä»åƒç´ åˆ°ç”Ÿäº§çš„è‡ªä¸»åŒ–ä¼ä¸šçº§å‰ç«¯å¼€å‘",
      "authors": [
        "Ramprasath Ganesaraja",
        "Swathika N",
        "Saravanan AP",
        "Kamalkumar Rathinasamy",
        "Chetana Amancharla",
        "Rahul Das",
        "Sahil Dilip Panse",
        "Aditya Batwe",
        "Dileep Vijayan",
        "Veena Ashok",
        "Thanushree A P",
        "Kausthubh J Rao",
        "Alden Olivero",
        "Roshan",
        "Rajeshwar Reddy Manthena",
        "Asmitha Yuga Sre A",
        "Harsh Tripathi",
        "Suganya Selvaraj",
        "Vito Chin",
        "Kasthuri Rangan Bhaskar",
        "Kasthuri Rangan Bhaskar",
        "Venkatraman R",
        "Sajit Vijayakumar"
      ],
      "abstract": "We present AI4UI, a framework of autonomous front-end development agents purpose-built to meet the rigorous requirements of enterprise-grade application delivery. Unlike general-purpose code assistants designed for rapid prototyping, AI4UI focuses on production readiness delivering secure, scalable, compliant, and maintainable UI code integrated seamlessly into enterprise workflows. AI4UI operates with targeted human-in-the-loop involvement: at the design stage, developers embed a Gen-AI-friendly grammar into Figma prototypes to encode requirements for precise interpretation; and at the post processing stage, domain experts refine outputs for nuanced design adjustments, domain-specific optimizations, and compliance needs. Between these stages, AI4UI runs fully autonomously, converting designs into engineering-ready UI code. Technical contributions include a Figma grammar for autonomous interpretation, domain-aware knowledge graphs, a secure abstract/package code integration strategy, expertise driven architecture templates, and a change-oriented workflow coordinated by specialized agent roles. In large-scale benchmarks against industry baselines and leading competitor systems, AI4UI achieved 97.24% platform compatibility, 87.10% compilation success, 86.98% security compliance, 78.00% feature implementation success, 73.50% code-review quality, and 73.36% UI/UX consistency. In blind preference studies with 200 expert evaluators, AI4UI emerged as one of the leaders demonstrating strong competitive standing among leading solutions. Operating asynchronously, AI4UI generates thousands of validated UI screens in weeks rather than months, compressing delivery timeline",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†AI4UIï¼Œä¸€ä¸ªæ—¨åœ¨æ»¡è¶³ä¼ä¸šçº§åº”ç”¨äº¤ä»˜ä¸¥è‹›è¦æ±‚çš„è‡ªä¸»å‰ç«¯å¼€å‘å¤šæ™ºèƒ½ä½“(Multi-Agent)æ¡†æ¶ã€‚ä¸ä¸“æ³¨äºå¿«é€ŸåŸå‹çš„é€šç”¨ä»£ç åŠ©æ‰‹ä¸åŒï¼ŒAI4UI ä¾§é‡äºç”Ÿæˆå®‰å…¨ã€å¯æ‰©å±•ã€åˆè§„ä¸”å¯ç»´æŠ¤çš„ç”Ÿäº§å°±ç»ªå‹(Production-ready) UI ä»£ç å¹¶æ— ç¼é›†æˆè‡³ä¼ä¸šå·¥ä½œæµã€‚è¯¥ç³»ç»Ÿé‡‡ç”¨é’ˆå¯¹æ€§çš„äººæœºååŒæ¨¡å¼ï¼Œåœ¨è®¾è®¡é˜¶æ®µåˆ©ç”¨ Gen-AI å‹å¥½è¯­æ³•å¯¹ Figma åŸå‹è¿›è¡Œéœ€æ±‚ç¼–ç ï¼Œå¹¶åœ¨åå¤„ç†é˜¶æ®µç”±ä¸“å®¶è¿›è¡Œé¢†åŸŸä¼˜åŒ–ï¼Œè€Œä¸­é—´è½¬æ¢è¿‡ç¨‹åˆ™å®Œå…¨è‡ªä¸»ã€‚å…¶æ ¸å¿ƒæŠ€æœ¯è´¡çŒ®æ¶µç›–äº†é¢†åŸŸæ„ŸçŸ¥çŸ¥è¯†å›¾è°±(Knowledge Graphs)ã€å®‰å…¨çš„æŠ½è±¡/åŒ…é›†æˆç­–ç•¥ä»¥åŠç”±ä¸“é—¨æ™ºèƒ½ä½“è§’è‰²åè°ƒçš„å˜æ›´å¯¼å‘å·¥ä½œæµã€‚åœ¨å¤§è§„æ¨¡åŸºå‡†æµ‹è¯•å’Œ 200 åä¸“å®¶çš„ç›²æµ‹ä¸­ï¼ŒAI4UI åœ¨å®‰å…¨æ€§åˆè§„ã€å¹³å°å…¼å®¹æ€§åŠ UI/UX ä¸€è‡´æ€§ç­‰å¤šä¸ªç»´åº¦å±•ç°å‡ºå¼ºå¤§çš„ç«äº‰åŠ›ã€‚é€šè¿‡å¼‚æ­¥æ“ä½œï¼Œè¯¥æ¡†æ¶èƒ½åœ¨æ•°å‘¨å†…ç”Ÿæˆæ•°åƒä¸ªç»è¿‡éªŒè¯çš„ UI ç•Œé¢ï¼Œæ˜¾è‘—å‹ç¼©äº†ä»åƒç´ åˆ°ç”Ÿäº§ç¯å¢ƒçš„äº¤ä»˜å‘¨æœŸã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "17 pages, 9 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.06046v1",
      "published_date": "2025-12-05 09:56:15 UTC",
      "updated_date": "2025-12-05 09:56:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:05:00.788691+00:00"
    },
    {
      "arxiv_id": "2512.05557v1",
      "title": "2K-Characters-10K-Stories: A Quality-Gated Stylized Narrative Dataset with Disentangled Control and Sequence Consistency",
      "title_zh": "2K-Characters-10K-Storiesï¼šå…·å¤‡è§£è€¦æ§åˆ¶ä¸åºåˆ—ä¸€è‡´æ€§çš„è´¨é‡é—¨æ§é£æ ¼åŒ–å™äº‹æ•°æ®é›†",
      "authors": [
        "Xingxi Yin",
        "Yicheng Li",
        "Gong Yan",
        "Chenglin Li",
        "Jian Zhao",
        "Cong Huang",
        "Yue Deng",
        "Yin Zhang"
      ],
      "abstract": "Sequential identity consistency under precise transient attribute control remains a long-standing challenge in controllable visual storytelling. Existing datasets lack sufficient fidelity and fail to disentangle stable identities from transient attributes, limiting structured control over pose, expression, and scene composition and thus constraining reliable sequential synthesis. To address this gap, we introduce \\textbf{2K-Characters-10K-Stories}, a multi-modal stylized narrative dataset of \\textbf{2{,}000} uniquely stylized characters appearing across \\textbf{10{,}000} illustration stories. It is the first dataset that pairs large-scale unique identities with explicit, decoupled control signals for sequential identity consistency. We introduce a \\textbf{Human-in-the-Loop pipeline (HiL)} that leverages expert-verified character templates and LLM-guided narrative planning to generate highly-aligned structured data. A \\textbf{decoupled control} scheme separates persistent identity from transient attributes -- pose and expression -- while a \\textbf{Quality-Gated loop} integrating MMLM evaluation, Auto-Prompt Tuning, and Local Image Editing enforces pixel-level consistency. Extensive experiments demonstrate that models fine-tuned on our dataset achieves performance comparable to closed-source models in generating visual narratives.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¯æ§è§†è§‰å™äº‹(visual storytelling)ä¸­èº«ä»½ä¸€è‡´æ€§ä¸å±æ€§ç²¾ç¡®æ§åˆ¶çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†2K-Characters-10K-Storiesæ•°æ®é›†ã€‚è¿™æ˜¯ä¸€ä¸ªåŒ…å«2,000ä¸ªç‹¬ç‰¹é£æ ¼åŒ–è§’è‰²åŠ10,000ä¸ªæ’ç”»æ•…äº‹çš„å¤§è§„æ¨¡å¤šæ¨¡æ€æ•°æ®é›†ï¼Œé¦–æ¬¡å®ç°äº†æŒä¹…èº«ä»½ä¸ç¬æ—¶å±æ€§çš„è§£è€¦æ§åˆ¶(decoupled control)ã€‚ç ”ç©¶é‡‡ç”¨äººæœºååŒæµç¨‹(Human-in-the-Loop pipeline)ï¼Œåˆ©ç”¨ä¸“å®¶éªŒè¯çš„æ¨¡æ¿å’ŒLLMå¼•å¯¼çš„å™äº‹è§„åˆ’ç”Ÿæˆé«˜è´¨é‡å¯¹é½çš„ç»“æ„åŒ–æ•°æ®ã€‚é€šè¿‡è´¨é‡é—¨æ§å¾ªç¯(Quality-Gated loop)æ•´åˆMMLMè¯„ä¼°ã€Auto-Prompt Tuningå’ŒLocal Image EditingæŠ€æœ¯ï¼Œè¯¥æ¡†æ¶æœ‰æ•ˆç¡®ä¿äº†è§†è§‰åºåˆ—åœ¨åƒç´ çº§åˆ«çš„ä¸€è‡´æ€§ã€‚å®éªŒè¯æ˜ï¼ŒåŸºäºè¯¥æ•°æ®é›†å¾®è°ƒçš„æ¨¡å‹åœ¨è§†è§‰å™äº‹ç”Ÿæˆä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œè¾¾åˆ°äº†ä¸é—­æºæ¨¡å‹ç›¸åª²ç¾çš„æ€§èƒ½ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.05557v1",
      "published_date": "2025-12-05 09:26:24 UTC",
      "updated_date": "2025-12-05 09:26:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:05:03.092780+00:00"
    },
    {
      "arxiv_id": "2512.05556v1",
      "title": "Improving Local Fidelity Through Sampling and Modeling Nonlinearity",
      "title_zh": "é€šè¿‡é‡‡æ ·ä¸éçº¿æ€§å»ºæ¨¡æå‡å±€éƒ¨ä¿çœŸåº¦",
      "authors": [
        "Sanjeev Shrestha",
        "Rahul Dubey",
        "Hui Liu"
      ],
      "abstract": "With the increasing complexity of black-box machine learning models and their adoption in high-stakes areas, it is critical to provide explanations for their predictions. Local Interpretable Model-agnostic Explanation (LIME) is a widely used technique that explains the prediction of any classifier by learning an interpretable model locally around the predicted instance. However, it assumes that the local decision boundary is linear and fails to capture the non-linear relationships, leading to incorrect explanations. In this paper, we propose a novel method that can generate high-fidelity explanations. Multivariate adaptive regression splines (MARS) is used to model non-linear local boundaries that effectively captures the underlying behavior of the reference model, thereby enhancing the local fidelity of the explanation. Additionally, we utilize the N-ball sampling technique, which samples directly from the desired distribution instead of reweighting samples as done in LIME, further improving the faithfulness score. We evaluate our method on three UCI datasets across different classifiers and varying kernel widths. Experimental results show that our method yields more faithful explanations compared to baselines, achieving an average reduction of 37% in root mean square error, significantly improving local fidelity.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ LIME åœ¨è§£é‡Šé»‘ç›’æ¨¡å‹æ—¶å› å‡è®¾å±€éƒ¨çº¿æ€§è€Œæ— æ³•æ•æ‰éçº¿æ€§å…³ç³»çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§é€šè¿‡ä¼˜åŒ–é‡‡æ ·å’Œå»ºæ¨¡éçº¿æ€§æ¥æé«˜å±€éƒ¨ä¿çœŸåº¦(Local Fidelity)çš„æ–¹æ³•ã€‚å…¶æ ¸å¿ƒè´¡çŒ®åœ¨äºå¼•å…¥äº†å¤šå…ƒè‡ªé€‚åº”å›å½’æ ·æ¡(MARS)æ¥å»ºæ¨¡éçº¿æ€§å±€éƒ¨è¾¹ç•Œï¼Œä»è€Œæ›´å‡†ç¡®åœ°åˆ»ç”»å‚è€ƒæ¨¡å‹çš„å¤æ‚è¡Œä¸ºã€‚åŒæ—¶ï¼Œè¯¥æ–¹æ³•é‡‡ç”¨ N-ball é‡‡æ ·æŠ€æœ¯ç›´æ¥ä»ç›®æ ‡åˆ†å¸ƒä¸­è·å–æ ·æœ¬ï¼Œé¿å…äº† LIME ä¸­æ ·æœ¬é‡åŠ æƒçš„å¼Šç«¯ï¼Œè¿›ä¸€æ­¥æå‡äº†è§£é‡Šçš„å¿ å®åº¦(Faithfulness)ã€‚åœ¨ä¸‰ä¸ª UCI æ•°æ®é›†ä¸Šçš„å®éªŒè¯„ä¼°æ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å¤šç§åˆ†ç±»å™¨å’Œå†…æ ¸å®½åº¦ä¸‹å‡è¡¨ç°ä¼˜å¼‚ï¼Œå…¶å‡æ–¹æ ¹è¯¯å·®(RMSE)å¹³å‡é™ä½äº†37%ã€‚ç ”ç©¶ç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•èƒ½ç”Ÿæˆæ¯”åŸºçº¿æ¨¡å‹æ›´å…·å¿ å®åº¦çš„è§£é‡Šï¼Œæ˜¾è‘—å¢å¼ºäº†é»‘ç›’æ¨¡å‹é¢„æµ‹çš„å±€éƒ¨ä¿çœŸåº¦ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.05556v1",
      "published_date": "2025-12-05 09:26:18 UTC",
      "updated_date": "2025-12-05 09:26:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:04:50.997678+00:00"
    },
    {
      "arxiv_id": "2512.05546v1",
      "title": "Conscious Gaze: Adaptive Attention Mechanisms for Hallucination Mitigation in Vision-Language Models",
      "title_zh": "Conscious Gazeï¼šæ—¨åœ¨ç¼“è§£è§†è§‰è¯­è¨€æ¨¡å‹å¹»è§‰çš„è‡ªé€‚åº”æ³¨æ„åŠ›æœºåˆ¶",
      "authors": [
        "Weijue Bu",
        "Guan Yuan",
        "Guixian Zhang"
      ],
      "abstract": "Large Vision-Language Models (VLMs) often exhibit text inertia, where attention drifts from visual evidence toward linguistic priors, resulting in object hallucinations. Existing decoding strategies intervene only at the output logits and thus cannot correct internal reasoning drift, while recent internal-control methods based on heuristic head suppression or global steering vectors lack principled grounding. We introduce Conscious Gaze (CG-VLM), a training-free, inference-time framework that converts game-theoretic interpretability into actionable decoding control. A Cognitive Demand Sensor built on Harsanyi interactions estimates instantaneous vision-text synergy and identifies moments when visual grounding is necessary. Conditioned on this signal, a Focused Consensus Induction module selectively reorients mid-layer attention toward visual tokens before collapse into text priors. CG-VLM achieves state-of-the-art results on POPE and CHAIR across InstructBLIP, LLaVA, Qwen-VL, and mPLUG, while preserving general capabilities, demonstrating that token-level sensing enables precise, context-aware intervention without compromising foundational knowledge.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è§†è§‰è¯­è¨€æ¨¡å‹(VLMs)ä¸­ç”±äºæ³¨æ„åŠ›ä»è§†è§‰è¯æ®å‘è¯­è¨€å…ˆéªŒåç§»è€Œå¯¼è‡´çš„ç‰©ä½“å¹»è§‰é—®é¢˜ï¼Œæå‡ºäº†åä¸ºConscious Gaze (CG-VLM)çš„æ¨ç†æ—¶æ¡†æ¶ã€‚è¿™æ˜¯ä¸€ç§æ— éœ€è®­ç»ƒçš„æ–¹æ³•ï¼Œå°†åšå¼ˆè®ºè§£é‡Šæ€§è½¬åŒ–ä¸ºå¯æ“ä½œçš„è§£ç æ§åˆ¶ï¼Œæ—¨åœ¨çº æ­£æ¨¡å‹å†…éƒ¨çš„æ¨ç†æ¼‚ç§»ã€‚æ¡†æ¶æ ¸å¿ƒåŒ…å«åŸºäºHarsanyi interactionsæ„å»ºçš„Cognitive Demand Sensorï¼Œç”¨äºå®æ—¶è¯„ä¼°è§†è§‰ä¸æ–‡æœ¬çš„ååŒä½œç”¨å¹¶è¯†åˆ«éœ€è¦è§†è§‰å¼•å¯¼çš„å…³é”®æ—¶åˆ»ã€‚åœ¨æ„Ÿåº”ä¿¡å·å¼•å¯¼ä¸‹ï¼ŒFocused Consensus Inductionæ¨¡å—ä¼šé€‰æ‹©æ€§åœ°å°†ä¸­å±‚æ³¨æ„åŠ›é‡æ–°å®šå‘è‡³è§†è§‰tokenï¼Œé˜²æ­¢å…¶è¿‡åº¦ä¾èµ–è¯­è¨€å…ˆéªŒã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCG-VLMåœ¨POPEå’ŒCHAIRåŸºå‡†æµ‹è¯•ä¸­ï¼Œåœ¨InstructBLIPã€LLaVAã€Qwen-VLå’ŒmPLUGç­‰å¤šä¸ªä¸»æµæ¨¡å‹ä¸Šå‡è¾¾åˆ°äº†state-of-the-artæ°´å¹³ã€‚è¯¥ç ”ç©¶è¯æ˜äº†é€šè¿‡tokençº§åˆ«çš„æ„ŸçŸ¥å¯ä»¥å®ç°ç²¾ç¡®ä¸”å…·æœ‰ä¸Šä¸‹æ–‡æ„ŸçŸ¥èƒ½åŠ›çš„å¹²é¢„ï¼Œåœ¨ç¼“è§£å¹»è§‰çš„åŒæ—¶æœ‰æ•ˆä¿ç•™äº†æ¨¡å‹çš„åŸºç¡€é€šç”¨èƒ½åŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.05546v1",
      "published_date": "2025-12-05 09:07:55 UTC",
      "updated_date": "2025-12-05 09:07:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:04:53.895380+00:00"
    },
    {
      "arxiv_id": "2512.05542v1",
      "title": "RoBoN: Routed Online Best-of-n for Test-Time Scaling with Multiple LLMs",
      "title_zh": "RoBoNï¼šé¢å‘å¤š LLM æ¨ç†æ—¶æ‰©å±•çš„è·¯ç”±å¼åœ¨çº¿ Best-of-n æœºåˆ¶",
      "authors": [
        "Jonathan Geuter",
        "Gregor Kornhardt"
      ],
      "abstract": "Best-of-$n$ is a widely used test-time scaling approach for LLM inference. Yet despite evidence that LLMs exhibit complementary strengths across tasks, traditionally best-of-$n$ relies on a single model to generate responses. We propose RoBoN (Routed Online Best-of-$n$), a sequential multi-LLM alternative to the prevailing single-model best-of-$n$. Given a suite of models $\\{m_i\\}_{i=1}^M$, RoBoN sequentially routes generations one-by-one across models, based on scores computed using a reward model and an agreement signal on the predicted responses. This online routing requires no additional training, keeps compute parity, and works with any plug-in reward model. Across reasoning benchmarks (MATH500, OlympiadBench, MinervaMath, GSM8K, MMLU), RoBoN consistently outperforms standard best-of-$n$ applied to each individual model for larger $n$, with gains of up to 3.4\\% in absolute accuracy, and also improves over a uniform multi-model portfolio baseline. Our results indicate that diversity across models can be exploited at inference to improve best-of-$n$ performance over any constituent model alone, providing a simple, training-free path to test-time scaling with multiple LLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰Best-of-$n$æ¨ç†é€šå¸¸ä¾èµ–å•ä¸€æ¨¡å‹çš„é—®é¢˜ï¼Œæå‡ºäº†RoBoN (Routed Online Best-of-$n$)ï¼Œä¸€ç§åˆ©ç”¨å¤šä¸ªLLMè¿›è¡Œæµ‹è¯•æ—¶æ‰©å±•(Test-Time Scaling)çš„é¡ºåºå¤šæ¨¡å‹æ›¿ä»£æ–¹æ¡ˆã€‚é‰´äºä¸åŒLLMåœ¨ä»»åŠ¡ä¸Šè¡¨ç°å‡ºäº’è¡¥ä¼˜åŠ¿ï¼ŒRoBoNé€šè¿‡åŸºäºå¥–åŠ±æ¨¡å‹(Reward Model)è®¡ç®—çš„åˆ†æ•°å’Œé¢„æµ‹å“åº”çš„ä¸€è‡´æ€§ä¿¡å·ï¼Œåœ¨æ¨¡å‹å¥—ä»¶ä¸­é¡ºåºè·¯ç”±ç”Ÿæˆè¿‡ç¨‹ã€‚è¿™ç§åœ¨çº¿è·¯ç”±æ–¹æ³•æ— éœ€é¢å¤–è®­ç»ƒï¼Œä¿æŒäº†è®¡ç®—é‡çš„ä¸€è‡´æ€§ï¼Œå¹¶å…¼å®¹ä»»ä½•æ’ä»¶å¼å¥–åŠ±æ¨¡å‹ã€‚åœ¨MATH500ã€GSM8Kå’ŒMMLUç­‰æ¨ç†åŸºå‡†æµ‹è¯•ä¸­ï¼ŒRoBoNåœ¨è¾ƒå¤§çš„$n$å€¼ä¸‹ä¸€è‡´ä¼˜äºåº”ç”¨äºå•ä¸ªæ¨¡å‹çš„æ ‡å‡†Best-of-$n$ï¼Œç»å¯¹å‡†ç¡®ç‡æå‡é«˜è¾¾3.4%ï¼ŒåŒæ—¶ä¹Ÿä¼˜äºå‡åŒ€çš„å¤šæ¨¡å‹ç»„åˆåŸºçº¿ã€‚ç»“æœè¡¨æ˜ï¼Œåˆ©ç”¨æ¨¡å‹é—´çš„å¤šæ ·æ€§å¯ä»¥åœ¨æ¨ç†é˜¶æ®µæ˜¾è‘—æå‡æ€§èƒ½ï¼Œä¸ºå¤šLLMçš„æµ‹è¯•æ—¶æ‰©å±•æä¾›äº†ä¸€æ¡ç®€å•ä¸”æ— éœ€è®­ç»ƒçš„è·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "20 pages, 3 figures. 39th Conference on Neural Information Processing Systems (NeurIPS 2025) Workshop: Foundations of Reasoning in Language Models",
      "pdf_url": "https://arxiv.org/pdf/2512.05542v1",
      "published_date": "2025-12-05 08:55:39 UTC",
      "updated_date": "2025-12-05 08:55:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 1,
      "last_update": "2026-01-26T14:05:56.626210+00:00"
    },
    {
      "arxiv_id": "2512.05534v2",
      "title": "On the Theoretical Foundation of Sparse Dictionary Learning in Mechanistic Interpretability",
      "title_zh": "è®ºæœºç†å¯è§£é‡Šæ€§ä¸­ç¨€ç–å­—å…¸å­¦ä¹ çš„ç†è®ºåŸºç¡€",
      "authors": [
        "Yiming Tang",
        "Harshvardhan Saini",
        "Zhaoqian Yao",
        "Yizhen Liao",
        "Qianxiao Li",
        "Mengnan Du",
        "Dianbo Liu"
      ],
      "abstract": "As AI models achieve remarkable capabilities across diverse domains, understanding what representations they learn and how they process information has become increasingly important for both scientific progress and trustworthy deployment. Recent works in mechanistic interpretability have shown that neural networks represent meaningful concepts as directions in their representation spaces and often encode diverse concepts in superposition. Various sparse dictionary learning (SDL) methods, including sparse autoencoders, transcoders, and crosscoders, address this by training auxiliary models with sparsity constraints to disentangle these superposed concepts into monosemantic features. These methods have demonstrated remarkable empirical success but have limited theoretical understanding. Existing theoretical work is limited to sparse autoencoders with tied-weight constraints, leaving the broader family of SDL methods without formal grounding. In this work, we develop the first unified theoretical framework considering SDL as one optimization problem. We demonstrate how diverse methods instantiate the theoretical framework and provide rigorous analysis of the optimization landscape. We provide novel theoretical explanations for empirically observed phenomena, including feature absorption and dead neurons. We design the Linear Representation Bench, a benchmark that strictly follows the Linear Representation Hypothesis, to evaluate SDL methods with fully accessible ground-truth features. Motivated by our theory and findings, we develop feature achoring, a novel technique applicable for all SDL methods, to enhance their feature recovery capabilities.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº† Mechanistic Interpretability ä¸­ Sparse Dictionary Learning (SDL) çš„ç†è®ºåŸºç¡€ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ–¹æ³•åœ¨è§£é‡Šç¥ç»ç½‘ç»œ Superposition ç°è±¡æ—¶ç¼ºä¹ç†è®ºæ”¯æ’‘çš„é—®é¢˜ã€‚ä½œè€…å¼€å‘äº†é¦–ä¸ªç»Ÿä¸€çš„ç†è®ºæ¡†æ¶ï¼Œå°† Sparse Autoencodersã€Transcoders å’Œ Crosscoders ç­‰æ–¹æ³•è§†ä½œåŒä¸€ç±»ä¼˜åŒ–é—®é¢˜ï¼Œå¹¶å¯¹å…¶ä¼˜åŒ–æ™¯è§‚è¿›è¡Œäº†ä¸¥æ ¼åˆ†æã€‚è¯¥æ¡†æ¶ä¸º Feature Absorption å’Œ Dead Neurons ç­‰ç»éªŒè§‚å¯Ÿåˆ°çš„ç°è±¡æä¾›äº†é¦–ä¸ªç†è®ºè§£é‡Šï¼Œæ·±åº¦è§£æäº†ç‰¹å¾è§£è€¦çš„åŠ¨åŠ›å­¦è¿‡ç¨‹ã€‚æ­¤å¤–ï¼Œç ”ç©¶å›¢é˜Ÿè®¾è®¡äº†åŸºäº Linear Representation Hypothesis çš„ Linear Representation Bench åŸºå‡†æµ‹è¯•ï¼Œä»¥ä¾¿åœ¨æ‹¥æœ‰ Ground-truth çš„ç¯å¢ƒä¸‹å®¢è§‚è¯„ä¼°ç‰¹å¾æ¢å¤æ•ˆæœã€‚æœ€åï¼Œè®ºæ–‡æå‡ºäº†ä¸€ç§åä¸º Feature Anchoring çš„æ–°æŠ€æœ¯ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡å„ç±» SDL æ–¹æ³•çš„ç‰¹å¾æå–ç²¾åº¦ä¸é²æ£’æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.05534v2",
      "published_date": "2025-12-05 08:47:19 UTC",
      "updated_date": "2026-01-13 08:47:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:05:14.403499+00:00"
    },
    {
      "arxiv_id": "2512.05530v1",
      "title": "MIND: Multi-rationale INtegrated Discriminative Reasoning Framework for Multi-modal Large Models",
      "title_zh": "MINDï¼šå¤šæ¨¡æ€å¤§æ¨¡å‹çš„å¤šç†ç”±é›†æˆåˆ¤åˆ«å¼æ¨ç†æ¡†æ¶",
      "authors": [
        "Chuang Yu",
        "Jinmiao Zhao",
        "Mingxuan Zhao",
        "Yunpeng Liu",
        "Xiujun Shu",
        "Yuanhao Feng",
        "Bo Wang",
        "Xiangyu Yue"
      ],
      "abstract": "Recently, multimodal large language models (MLLMs) have been widely applied to reasoning tasks. However, they suffer from limited multi-rationale semantic modeling, insufficient logical robustness, and are susceptible to misleading interpretations in complex scenarios. Therefore, we propose a Multi-rationale INtegrated Discriminative (MIND) reasoning framework, which is designed to endow MLLMs with human-like cognitive abilities of \"Understand -> Rethink -> Correct\", and achieves a paradigm evolution from passive imitation-based reasoning to active discriminative reasoning. Specifically, we introduce a Rationale Augmentation and Discrimination (RAD) paradigm, which automatically and efficiently expands existing datasets by generating diverse rationales, providing a unified and extensible data foundation. Meanwhile, we design a Progressive Two-stage Correction Learning (P2CL) strategy. The first phase enhances multi-rationale positive learning, while the second phase enables active logic discrimination and correction. In addition, to mitigate representation entanglement in the multi-rationale semantic space, we propose a Multi-rationale Contrastive Alignment (MCA) optimization strategy, which achieves semantic aggregation of correct reasoning and boundary separation of incorrect reasoning. Extensive experiments demonstrate that the proposed MIND reasoning framework achieves state-of-the-art (SOTA) performance on multiple public datasets covering scientific, commonsense, and mathematical scenarios. It provides a new perspective for advancing MLLMs towards higher levels of cognitive intelligence. Our code is available at https://github.com/YuChuang1205/MIND",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLMs)åœ¨å¤šç†ç”±è¯­ä¹‰å»ºæ¨¡å’Œé€»è¾‘é²æ£’æ€§æ–¹é¢çš„å±€é™æ€§ï¼Œæå‡ºäº†MINDï¼ˆMulti-rationale INtegrated Discriminativeï¼‰æ¨ç†æ¡†æ¶ã€‚è¯¥æ¡†æ¶æ—¨åœ¨èµ‹äºˆæ¨¡å‹â€œç†è§£->åæ€->ä¿®æ­£â€çš„ç±»äººè®¤çŸ¥èƒ½åŠ›ï¼Œå®ç°äº†ä»è¢«åŠ¨æ¨¡ä»¿åˆ°ä¸»åŠ¨åˆ¤åˆ«æ¨ç†çš„èŒƒå¼æ¼”è¿›ã€‚ç ”ç©¶å¼•å…¥äº†RADï¼ˆRationale Augmentation and Discriminationï¼‰èŒƒå¼æ¥é«˜æ•ˆæ‰©å±•æ•°æ®é›†ï¼Œå¹¶è®¾è®¡äº†P2CLï¼ˆProgressive Two-stage Correction Learningï¼‰ç­–ç•¥ä»¥å¼ºåŒ–æ­£å‘å­¦ä¹ å¹¶å®ç°ä¸»åŠ¨é€»è¾‘çº é”™ã€‚ä¸ºäº†è§£å†³è¯­ä¹‰ç©ºé—´ä¸­çš„è¡¨ç¤ºçº ç¼ ï¼ŒMINDé‡‡ç”¨äº†MCAï¼ˆMulti-rationale Contrastive Alignmentï¼‰ç­–ç•¥æ¥èšåˆæ­£ç¡®æ¨ç†å¹¶åˆ†ç¦»é”™è¯¯é€»è¾‘ã€‚å¤šé¡¹å®éªŒè¯æ˜ï¼Œè¯¥æ¡†æ¶åœ¨ç§‘å­¦ã€å¸¸è¯†åŠæ•°å­¦æ¨ç†ä»»åŠ¡ä¸­å‡è¾¾åˆ°äº†SOTAæ°´å¹³ï¼Œä¸ºæå‡MLLMsçš„è®¤çŸ¥æ™ºèƒ½æ°´å¹³æä¾›äº†æ–°çš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.05530v1",
      "published_date": "2025-12-05 08:41:44 UTC",
      "updated_date": "2025-12-05 08:41:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:05:13.248048+00:00"
    },
    {
      "arxiv_id": "2512.05529v1",
      "title": "See in Depth: Training-Free Surgical Scene Segmentation with Monocular Depth Priors",
      "title_zh": "See in Depthï¼šåŸºäºå•ç›®æ·±åº¦å…ˆéªŒçš„å…è®­ç»ƒæ‰‹æœ¯åœºæ™¯åˆ†å‰²",
      "authors": [
        "Kunyi Yang",
        "Qingyu Wang",
        "Cheng Yuan",
        "Yutong Ban"
      ],
      "abstract": "Pixel-wise segmentation of laparoscopic scenes is essential for computer-assisted surgery but difficult to scale due to the high cost of dense annotations. We propose depth-guided surgical scene segmentation (DepSeg), a training-free framework that utilizes monocular depth as a geometric prior together with pretrained vision foundation models. DepSeg first estimates a relative depth map with a pretrained monocular depth estimation network and proposes depth-guided point prompts, which SAM2 converts into class-agnostic masks. Each mask is then described by a pooled pretrained visual feature and classified via template matching against a template bank built from annotated frames. On the CholecSeg8k dataset, DepSeg improves over a direct SAM2 auto segmentation baseline (35.9% vs. 14.7% mIoU) and maintains competitive performance even when using only 10--20% of the object templates. These results show that depth-guided prompting and template-based classification offer an annotation-efficient segmentation approach.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†DepSegï¼ˆæ·±åº¦å¼•å¯¼çš„æ‰‹æœ¯åœºæ™¯åˆ†å‰²ï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªæ— éœ€è®­ç»ƒ(Training-free)çš„æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³è…¹è…”é•œåœºæ™¯ä¸­åƒç´ çº§åˆ†å‰²æ ‡æ³¨æˆæœ¬é«˜æ˜‚çš„é—®é¢˜ã€‚è¯¥æ–¹æ³•åˆ©ç”¨å•ç›®æ·±åº¦(Monocular Depth)ä½œä¸ºå‡ ä½•å…ˆéªŒï¼Œå¹¶ç»“åˆé¢„è®­ç»ƒçš„è§†è§‰åŸºç¡€æ¨¡å‹SAM2ã€‚DepSegé¦–å…ˆé€šè¿‡é¢„è®­ç»ƒç½‘ç»œä¼°è®¡ç›¸å¯¹æ·±åº¦å›¾ï¼Œå¹¶æå‡ºæ·±åº¦å¼•å¯¼çš„ç‚¹æç¤º(Point Prompts)ï¼Œéšåç”±SAM2å°†å…¶è½¬æ¢ä¸ºç±»åˆ«æ— å…³çš„æ©ç (Masks)ã€‚æ¯ä¸ªæ©ç é€šè¿‡æå–é¢„è®­ç»ƒè§†è§‰ç‰¹å¾ï¼Œå¹¶ä¸åŸºäºæ ‡æ³¨å¸§æ„å»ºçš„æ¨¡æ¿åº“è¿›è¡Œæ¨¡æ¿åŒ¹é…(Template Matching)æ¥å®Œæˆåˆ†ç±»ã€‚åœ¨CholecSeg8kæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒDepSegçš„å¹³å‡äº¤å¹¶æ¯”(mIoU)ä»åŸºçº¿çš„14.7%æ˜¾è‘—æå‡è‡³35.9%ï¼Œä¸”åœ¨ä»…ä½¿ç”¨10%-20%ç›®æ ‡æ¨¡æ¿æ—¶ä»èƒ½ä¿æŒç«äº‰åŠ›ã€‚è¿™è¯æ˜äº†æ·±åº¦å¼•å¯¼æç¤ºå’ŒåŸºäºæ¨¡æ¿çš„åˆ†ç±»æ˜¯ä¸€ç§æ ‡æ³¨é«˜æ•ˆ(Annotation-efficient)çš„åˆ†å‰²æ–¹æ³•ï¼Œä¸ºè®¡ç®—æœºè¾…åŠ©æ‰‹æœ¯æä¾›äº†æœ‰æ•ˆçš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "The first two authors contributed equally",
      "pdf_url": "https://arxiv.org/pdf/2512.05529v1",
      "published_date": "2025-12-05 08:41:42 UTC",
      "updated_date": "2025-12-05 08:41:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:05:18.529777+00:00"
    },
    {
      "arxiv_id": "2512.05519v1",
      "title": "User Negotiations of Authenticity, Ownership, and Governance on AI-Generated Video Platforms: Evidence from Sora",
      "title_zh": "AI ç”Ÿæˆè§†é¢‘å¹³å°ä¸­ç”¨æˆ·å¯¹çœŸå®æ€§ã€æ‰€æœ‰æƒä¸æ²»ç†çš„åå•†ï¼šæ¥è‡ª Sora çš„è¯æ®",
      "authors": [
        "Bohui Shen",
        "Shrikar Bhatta",
        "Alex Ireebanije",
        "Zexuan Liu",
        "Abhinav Choudhry",
        "Ece Gumusel",
        "Kyrie Zhixuan Zhou"
      ],
      "abstract": "As AI-generated video platforms rapidly advance, ethical challenges such as copyright infringement emerge. This study examines how users make sense of AI-generated videos on OpenAI's Sora by conducting a qualitative content analysis of user comments. Through a thematic analysis, we identified four dynamics that characterize how users negotiate authenticity, authorship, and platform governance on Sora. First, users acted as critical evaluators of realism, assessing micro-details such as lighting, shadows, fluid motion, and physics to judge whether AI-generated scenes could plausibly exist. Second, users increasingly shifted from passive viewers to active creators, expressing curiosity about prompts, techniques, and creative processes. Text prompts were perceived as intellectual property, generating concerns about plagiarism and remixing norms. Third, users reported blurred boundaries between real and synthetic media, worried about misinformation, and even questioned the authenticity of other commenters, suspecting bot-generated engagement. Fourth, users contested platform governance: some perceived moderation as inconsistent or opaque, while others shared tactics for evading prompt censorship through misspellings, alternative phrasing, emojis, or other languages. Despite this, many users also enforced ethical norms by discouraging the misuse of real people's images or disrespectful content. Together, these patterns highlighted how AI-mediated platforms complicate notions of reality, creativity, and rule-making in emerging digital ecosystems. Based on the findings, we discuss governance challenges in Sora and how user negotiations inform future platform governance.",
      "tldr_zh": "æœ¬é¡¹ç ”ç©¶é€šè¿‡å¯¹OpenAIçš„Soraå¹³å°ç”¨æˆ·è¯„è®ºè¿›è¡Œå®šæ€§å†…å®¹åˆ†æ(Qualitative Content Analysis)å’Œä¸»é¢˜åˆ†æ(Thematic Analysis)ï¼Œæ¢è®¨äº†ç”¨æˆ·åœ¨AIç”Ÿæˆè§†é¢‘å¹³å°ä¸­å…³äºçœŸå®æ€§ã€æ‰€æœ‰æƒå’Œæ²»ç†çš„åå•†è¿‡ç¨‹ã€‚ç ”ç©¶è¯†åˆ«å‡ºå››ä¸ªå…³é”®åŠ¨æ€ï¼šé¦–å…ˆï¼Œç”¨æˆ·é€šè¿‡è¯„ä¼°å…‰å½±å’Œç‰©ç†è§„å¾‹ç­‰å¾®è§‚ç»†èŠ‚ï¼Œæ‰¹åˆ¤æ€§åœ°åˆ¤æ–­AIè§†é¢‘çš„çœŸå®åº¦ã€‚å…¶æ¬¡ï¼Œç”¨æˆ·ä»è§‚ä¼—å‘åˆ›ä½œè€…èº«ä»½è½¬å˜ï¼Œå°†æç¤ºè¯(Prompts)è§†ä¸ºçŸ¥è¯†äº§æƒ(Intellectual Property)å¹¶å¯¹å‰½çªƒé£é™©è¡¨ç¤ºå…³æ³¨ã€‚æ­¤å¤–ï¼Œç°å®ä¸åˆæˆåª’ä½“è¾¹ç•Œçš„æ¨¡ç³Šå¼•å‘äº†ç”¨æˆ·å¯¹è™šå‡ä¿¡æ¯(Misinformation)çš„æ‹…å¿§åŠå¯¹äº’åŠ¨çœŸå®æ€§çš„è´¨ç–‘ã€‚æœ€åï¼Œç”¨æˆ·åœ¨å°è¯•è§„é¿å¹³å°æ²»ç†(Platform Governance)å®¡æŸ¥çš„åŒæ—¶ï¼Œä¹Ÿé€šè¿‡è‡ªå‘æŠµåˆ¶ä¸å½“å†…å®¹æ¥ç»´æŠ¤ä¼¦ç†è§„èŒƒã€‚è¿™äº›å‘ç°å¼ºè°ƒäº†AIä¸­ä»‹å¹³å°å¯¹ç°å®è®¤çŸ¥å’Œè§„åˆ™åˆ¶å®šå¸¦æ¥çš„å¤æ‚æŒ‘æˆ˜ï¼Œä¸ºæœªæ¥æ•°å­—ç”Ÿæ€ç³»ç»Ÿçš„æ²»ç†æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.05519v1",
      "published_date": "2025-12-05 08:23:27 UTC",
      "updated_date": "2025-12-05 08:23:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:05:33.041311+00:00"
    },
    {
      "arxiv_id": "2512.05518v1",
      "title": "Matching Ranks Over Probability Yields Truly Deep Safety Alignment",
      "title_zh": "é€šè¿‡æ’ååŒ¹é…è€Œéæ¦‚ç‡åŒ¹é…å®ç°çœŸæ­£çš„æ·±åº¦å®‰å…¨å¯¹é½",
      "authors": [
        "Jason Vega",
        "Gagandeep Singh"
      ],
      "abstract": "A frustratingly easy technique known as the prefilling attack has been shown to effectively circumvent the safety alignment of frontier LLMs by simply prefilling the assistant response with an affirmative prefix before decoding. In response, recent work proposed a supervised fine-tuning (SFT) defense using data augmentation to achieve a \\enquote{deep} safety alignment, allowing the model to generate natural language refusals immediately following harmful prefills. Unfortunately, we show in this work that the \"deep\" safety alignment produced by such an approach is in fact not very deep. A generalization of the prefilling attack, which we refer to as the Rank-Assisted Prefilling (RAP) attack, can effectively extract harmful content from models fine-tuned with the data augmentation defense by selecting low-probability \"harmful\" tokens from the top 20 predicted next tokens at each step (thus ignoring high-probability \"refusal\" tokens). We argue that this vulnerability is enabled due to the \"gaming\" of the SFT objective when the target distribution entropies are low, where low fine-tuning loss is achieved by shifting large probability mass to a small number of refusal tokens while neglecting the high ranks of harmful tokens. We then propose a new perspective on achieving deep safety alignment by matching the token ranks of the target distribution, rather than their probabilities. This perspective yields a surprisingly simple fix to the data augmentation defense based on regularizing the attention placed on harmful prefill tokens, an approach we call PRefill attEntion STOpping (PRESTO). Adding PRESTO yields up to a 4.7x improvement in the mean StrongREJECT score under RAP attacks across three popular open-source LLMs, with low impact to model utility.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)é¢ä¸´çš„prefilling attackåŠå…¶é˜²å¾¡æœºåˆ¶ï¼ŒæŒ‡å‡ºå½“å‰é€šè¿‡æ•°æ®å¢å¼ºå®ç°çš„â€œæ·±åº¦â€å®‰å…¨å¯¹é½å¹¶ä¸å¯é ã€‚ç ”ç©¶è€…æå‡ºäº†ä¸€ç§åä¸ºRank-Assisted Prefilling (RAP)çš„æ”»å‡»æ–¹å¼ï¼Œé€šè¿‡é€‰æ‹©é«˜æ’åçš„æœ‰å®³tokenç»•è¿‡é˜²å¾¡ï¼Œæ­ç¤ºäº†ä¼ ç»Ÿç›‘ç£å¾®è°ƒ(SFT)åœ¨æ¦‚ç‡åˆ†å¸ƒå»ºæ¨¡ä¸Šçš„å±€é™æ€§ã€‚ä¸ºå®ç°çœŸæ­£çš„æ·±åº¦å¯¹é½ï¼Œä½œè€…æå‡ºäº†PRefill attEntion STOpping (PRESTO)æ–¹æ³•ï¼Œä¸»å¼ é€šè¿‡åŒ¹é…tokenæ’åè€Œéä»…åŒ¹é…æ¦‚ç‡æ¥å¢å¼ºå®‰å…¨æ€§ã€‚è¯¥æŠ€æœ¯é€šè¿‡æ­£åˆ™åŒ–å¯¹æœ‰å®³prefill tokençš„æ³¨æ„åŠ›(attention)æ¥ä¿®å¤é˜²å¾¡æ¼æ´ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒPRESTOåœ¨ä¸‰ç§ä¸»æµå¼€æºLLMsä¸Šå°†RAPæ”»å‡»ä¸‹çš„StrongREJECTå¾—åˆ†æå‡äº†æœ€é«˜4.7å€ï¼Œä¸”å¯¹æ¨¡å‹æ•ˆç”¨(utility)çš„å½±å“æå°ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.05518v1",
      "published_date": "2025-12-05 08:22:27 UTC",
      "updated_date": "2025-12-05 08:22:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:05:54.355909+00:00"
    },
    {
      "arxiv_id": "2512.11862v1",
      "title": "Hierarchical Task Offloading and Trajectory Optimization in Low-Altitude Intelligent Networks Via Auction and Diffusion-based MARL",
      "title_zh": "åŸºäºæ‹å–ä¸æ‰©æ•£å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ çš„ä½ç©ºæ™ºèƒ½ç½‘ç»œåˆ†å±‚ä»»åŠ¡å¸è½½ä¸è½¨è¿¹ä¼˜åŒ–",
      "authors": [
        "Jiahao You",
        "Ziye Jia",
        "Can Cui",
        "Chao Dong",
        "Qihui Wu",
        "Zhu Han"
      ],
      "abstract": "The low-altitude intelligent networks (LAINs) emerge as a promising architecture for delivering low-latency and energy-efficient edge intelligence in dynamic and infrastructure-limited environments. By integrating unmanned aerial vehicles (UAVs), aerial base stations, and terrestrial base stations, LAINs can support mission-critical applications such as disaster response, environmental monitoring, and real-time sensing. However, these systems face key challenges, including energy-constrained UAVs, stochastic task arrivals, and heterogeneous computing resources. To address these issues, we propose an integrated air-ground collaborative network and formulate a time-dependent integer nonlinear programming problem that jointly optimizes UAV trajectory planning and task offloading decisions. The problem is challenging to solve due to temporal coupling among decision variables. Therefore, we design a hierarchical learning framework with two timescales. At the large timescale, a Vickrey-Clarke-Groves auction mechanism enables the energy-aware and incentive-compatible trajectory assignment. At the small timescale, we propose the diffusion-heterogeneous-agent proximal policy optimization, a generative multi-agent reinforcement learning algorithm that embeds latent diffusion models into actor networks. Each UAV samples actions from a Gaussian prior and refines them via observation-conditioned denoising, enhancing adaptability and policy diversity. Extensive simulations show that our framework outperforms baselines in energy efficiency, task success rate, and convergence performance.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä½ç©ºæ™ºèƒ½ç½‘ç»œ(Low-Altitude Intelligent Networks, LAINs)ä¸­æ— äººæœº(UAVs)èƒ½é‡å—é™ã€ä»»åŠ¡éšæœºåˆ°è¾¾åŠè®¡ç®—èµ„æºå¼‚æ„ç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§ç©ºåœ°åä½œç½‘ç»œé›†æˆæ¡†æ¶ã€‚ç ”ç©¶è€…å»ºç«‹äº†ä¸€ä¸ªæ—¶å˜æ•´æ•°éçº¿æ€§è§„åˆ’æ¨¡å‹ï¼Œæ—¨åœ¨ååŒä¼˜åŒ–æ— äººæœºè½¨è¿¹è§„åˆ’å’Œä»»åŠ¡å¸è½½å†³ç­–ï¼Œä»¥è§£å†³å†³ç­–å˜é‡é—´çš„æ—¶åŸŸè€¦åˆé—®é¢˜ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶æå‡ºäº†ä¸€ç§åŒæ—¶é—´å°ºåº¦çš„å±‚æ¬¡åŒ–å­¦ä¹ æ¡†æ¶ï¼Œåœ¨å¤§æ—¶é—´å°ºåº¦ä¸Šåˆ©ç”¨Vickrey-Clarke-Groves (VCG)æ‹å–æœºåˆ¶å®ç°èƒ½é‡æ„ŸçŸ¥ä¸”æ¿€åŠ±ç›¸å®¹çš„è½¨è¿¹åˆ†é…ã€‚åœ¨å°æ—¶é—´å°ºåº¦ä¸Šï¼Œç ”ç©¶è®¾è®¡äº†Diffusion-Heterogeneous-Agent Proximal Policy Optimization (DHAPPO)ç®—æ³•ï¼Œè¿™æ˜¯ä¸€ç§å°†æ½œåœ¨æ‰©æ•£æ¨¡å‹(Latent Diffusion Models)åµŒå…¥Actorç½‘ç»œçš„å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ (MARL)ç”Ÿæˆå¼ç®—æ³•ã€‚æ— äººæœºé€šè¿‡ä»é«˜æ–¯å…ˆéªŒé‡‡æ ·å¹¶åˆ©ç”¨åŸºäºè§‚æµ‹çš„å»å™ªè¿‡ç¨‹(Denoising)ä¼˜åŒ–åŠ¨ä½œï¼Œæ˜¾è‘—å¢å¼ºäº†ç­–ç•¥çš„é€‚åº”æ€§å’Œå¤šæ ·æ€§ã€‚ä»¿çœŸç»“æœè¯æ˜ï¼Œè¯¥æ¡†æ¶åœ¨èƒ½é‡æ•ˆç‡(Energy Efficiency)ã€ä»»åŠ¡æˆåŠŸç‡å’Œæ”¶æ•›æ€§èƒ½æ–¹é¢å‡æ˜¾è‘—ä¼˜äºåŸºçº¿æ¨¡å‹ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.11862v1",
      "published_date": "2025-12-05 08:14:45 UTC",
      "updated_date": "2025-12-05 08:14:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:06:10.017357+00:00"
    },
    {
      "arxiv_id": "2512.05508v1",
      "title": "Lyrics Matter: Exploiting the Power of Learnt Representations for Music Popularity Prediction",
      "title_zh": "æ­Œè¯ä¹‹é‡ï¼šåˆ©ç”¨å­¦ä¹ è¡¨å¾çš„åŠ›é‡è¿›è¡ŒéŸ³ä¹æµè¡Œåº¦é¢„æµ‹",
      "authors": [
        "Yash Choudhary",
        "Preeti Rao",
        "Pushpak Bhattacharyya"
      ],
      "abstract": "Accurately predicting music popularity is a critical challenge in the music industry, offering benefits to artists, producers, and streaming platforms. Prior research has largely focused on audio features, social metadata, or model architectures. This work addresses the under-explored role of lyrics in predicting popularity. We present an automated pipeline that uses LLM to extract high-dimensional lyric embeddings, capturing semantic, syntactic, and sequential information. These features are integrated into HitMusicLyricNet, a multimodal architecture that combines audio, lyrics, and social metadata for popularity score prediction in the range 0-100. Our method outperforms existing baselines on the SpotGenTrack dataset, which contains over 100,000 tracks, achieving 9% and 20% improvements in MAE and MSE, respectively. Ablation confirms that gains arise from our LLM-driven lyrics feature pipeline (LyricsAENet), underscoring the value of dense lyric representations.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹éŸ³ä¹äº§ä¸šä¸­å‡†ç¡®é¢„æµ‹éŸ³ä¹å—æ¬¢è¿ç¨‹åº¦çš„æŒ‘æˆ˜ï¼Œé‡ç‚¹æ¢è®¨äº†é•¿æœŸè¢«å¿½è§†çš„æ­Œè¯åœ¨é¢„æµ‹ä¸­çš„å…³é”®ä½œç”¨ã€‚ç ”ç©¶å›¢é˜Ÿæå‡ºäº†ä¸€ç§è‡ªåŠ¨åŒ–æµç¨‹ï¼Œåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(LLM)æå–é«˜ç»´æ­Œè¯åµŒå…¥(lyric embeddings)ï¼Œä»¥å…¨é¢æ•è·æ­Œè¯çš„è¯­ä¹‰ã€å¥æ³•å’Œåºåˆ—ä¿¡æ¯ã€‚è¿™äº›ç‰¹å¾è¢«é›†æˆåˆ°ä¸€ç§åä¸ºHitMusicLyricNetçš„å¤šæ¨¡æ€æ¶æ„ä¸­ï¼Œç»“åˆéŸ³é¢‘ã€æ­Œè¯å’Œç¤¾äº¤å…ƒæ•°æ®æ¥é¢„æµ‹éŸ³è½¨çš„å—æ¬¢è¿ç¨‹åº¦è¯„åˆ†ã€‚åœ¨åŒ…å«è¶…è¿‡10ä¸‡æ¡éŸ³è½¨çš„SpotGenTrackæ•°æ®é›†ä¸Šçš„æµ‹è¯•ç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å¹³å‡ç»å¯¹è¯¯å·®(MAE)å’Œå‡æ–¹è¯¯å·®(MSE)ä¸Šåˆ†åˆ«æ¯”ç°æœ‰åŸºå‡†æ¨¡å‹æå‡äº†9%å’Œ20%ã€‚æ¶ˆèå®éªŒè¿›ä¸€æ­¥è¯å®ï¼Œæ€§èƒ½çš„æ˜¾è‘—å¢ç›Šä¸»è¦æºäºLLMé©±åŠ¨çš„æ­Œè¯ç‰¹å¾å¤„ç†æµç¨‹LyricsAENetã€‚è¯¥ç ”ç©¶å¼ºè°ƒäº†ç¨ å¯†æ­Œè¯è¡¨ç¤º(dense lyric representations)åœ¨æå‡é¢„æµ‹å‡†ç¡®æ€§æ–¹é¢çš„é‡è¦ä»·å€¼ï¼Œä¸ºéŸ³ä¹åˆ›ä½œå’Œæµåª’ä½“å¹³å°æä¾›äº†æ›´é«˜æ•ˆçš„å†³ç­–å·¥å…·ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SD",
      "comment": "8 pages",
      "pdf_url": "https://arxiv.org/pdf/2512.05508v1",
      "published_date": "2025-12-05 08:09:26 UTC",
      "updated_date": "2025-12-05 08:09:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:07:13.169019+00:00"
    },
    {
      "arxiv_id": "2512.08979v1",
      "title": "What Happens When: Learning Temporal Orders of Events in Videos",
      "title_zh": "ä½•æ—¶å‘ç”Ÿäº†ä»€ä¹ˆï¼šè§†é¢‘äº‹ä»¶æ—¶åºå­¦ä¹ ",
      "authors": [
        "Daechul Ahn",
        "Yura Choi",
        "Hyeonbeom Choi",
        "Seongwon Cho",
        "San Kim",
        "Jonghyun Choi"
      ],
      "abstract": "Video Large Multimodal Models (VLMMs) have shown impressive performance in video understanding, yet their ability to accurately capture the temporal order of multiple events remains underexplored. We interestingly observe that, even when video frames are scrambled, models perform very well on the existing benchmarks by comprehensive experiments. This implies that VLMMs may not necessarily rely on accurate sequential processing of visual events, but instead depend on prior knowledge of typical scenarios to answer the question. To benchmark temporal understanding capabilities in VLMMs, we propose VECTOR, designed to explicitly assess a model's ability to identify the temporal order of events. On this benchmark, we observe that various VLMMs often fail to understand the orders of events. To address this, we propose MECOT (Multi-Event instruction fine-tuning with Chain-of-Thought), which (1) trains models on detailed, event-by-event video descriptions and (2) using chain-of-thought prompts at inference to enhance temporal awareness. MECOT outperforms prior arts on VECTOR as well as improving performance on existing video benchmarks, implying effectiveness of temporal understanding. We release our code, model and datasets.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†è§†é¢‘å¤§å¤šæ¨¡æ€æ¨¡å‹ (VLMMs) åœ¨æ•æ‰å¤šä¸ªäº‹ä»¶æ—¶é—´é¡ºåºæ–¹é¢çš„å±€é™æ€§ï¼Œå‘ç°ç°æœ‰æ¨¡å‹åœ¨å¤„ç†ä¹±åºå¸§æ—¶è¡¨ç°ä¾ç„¶è‰¯å¥½ï¼Œè¡¨æ˜å…¶è¿‡åº¦ä¾èµ–åœºæ™¯å…ˆéªŒçŸ¥è¯†è€Œéå‡†ç¡®çš„é¡ºåºè§†è§‰å¤„ç†ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº† VECTOR åŸºå‡†æµ‹è¯•ï¼Œä¸“é—¨ç”¨äºæ˜ç¡®è¯„ä¼°æ¨¡å‹è¯†åˆ«è§†é¢‘ä¸­äº‹ä»¶å‘ç”Ÿé¡ºåºçš„èƒ½åŠ›ã€‚ä¸ºäº†æ”¹å–„æ¨¡å‹çš„æ—¶é—´ç†è§£ï¼Œç ”ç©¶è¿›ä¸€æ­¥æå‡ºäº† MECOT (Multi-Event instruction fine-tuning with Chain-of-Thought) æ–¹æ³•ï¼Œé€šè¿‡è¯¦ç»†çš„é€äº‹ä»¶è§†é¢‘æè¿°è¿›è¡ŒæŒ‡ä»¤å¾®è°ƒï¼Œå¹¶åœ¨æ¨ç†é˜¶æ®µç»“åˆé“¾å¼æ€ç»´æç¤ºä»¥å¢å¼ºæ¨¡å‹çš„æ—¶é—´æ„è¯†ã€‚å®éªŒè¯æ˜ï¼ŒMECOT åœ¨ VECTOR åŠç°æœ‰è§†é¢‘ç†è§£åŸºå‡†ä¸Šå‡æ˜¾è‘—ä¼˜äºå…ˆå‰çš„å…ˆè¿›æ¨¡å‹ï¼Œæœ‰æ•ˆåœ°æå‡äº†æ¨¡å‹å¯¹åŠ¨æ€è§†é¢‘å†…å®¹çš„æ—¶é—´æ„ŸçŸ¥èƒ½åŠ›ã€‚è¯¥ç ”ç©¶é€šè¿‡æ­ç¤ºç°æœ‰æ¨¡å‹çš„ç¼ºé™·å¹¶æä¾›å¼€æºçš„åŸºå‡†ä¸ç®—æ³•ï¼Œä¸ºè§†é¢‘æ™ºèƒ½é¢†åŸŸçš„å‘å±•åšå‡ºäº†é‡è¦è´¡çŒ®ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "WACV 2026",
      "pdf_url": "https://arxiv.org/pdf/2512.08979v1",
      "published_date": "2025-12-05 07:50:59 UTC",
      "updated_date": "2025-12-05 07:50:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:06:42.756593+00:00"
    },
    {
      "arxiv_id": "2512.05481v1",
      "title": "UniFS: Unified Multi-Contrast MRI Reconstruction via Frequency-Spatial Fusion",
      "title_zh": "UniFSï¼šåŸºäºé¢‘åŸŸ-ç©ºåŸŸèåˆçš„ç»Ÿä¸€å¤šå¯¹æ¯”åº¦ MRI é‡å»º",
      "authors": [
        "Jialin Li",
        "Yiwei Ren",
        "Kai Pan",
        "Dong Wei",
        "Pujin Cheng",
        "Xian Wu",
        "Xiaoying Tang"
      ],
      "abstract": "Recently, Multi-Contrast MR Reconstruction (MCMR) has emerged as a hot research topic that leverages high-quality auxiliary modalities to reconstruct undersampled target modalities of interest. However, existing methods often struggle to generalize across different k-space undersampling patterns, requiring the training of a separate model for each specific pattern, which limits their practical applicability. To address this challenge, we propose UniFS, a Unified Frequency-Spatial Fusion model designed to handle multiple k-space undersampling patterns for MCMR tasks without any need for retraining. UniFS integrates three key modules: a Cross-Modal Frequency Fusion module, an Adaptive Mask-Based Prompt Learning module, and a Dual-Branch Complementary Refinement module. These modules work together to extract domain-invariant features from diverse k-space undersampling patterns while dynamically adapt to their own variations. Another limitation of existing MCMR methods is their tendency to focus solely on spatial information while neglect frequency characteristics, or extract only shallow frequency features, thus failing to fully leverage complementary cross-modal frequency information. To relieve this issue, UniFS introduces an adaptive prompt-guided frequency fusion module for k-space learning, significantly enhancing the model's generalization performance. We evaluate our model on the BraTS and HCP datasets with various k-space undersampling patterns and acceleration factors, including previously unseen patterns, to comprehensively assess UniFS's generalizability. Experimental results across multiple scenarios demonstrate that UniFS achieves state-of-the-art performance. Our code is available at https://github.com/LIKP0/UniFS.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† UniFSï¼Œä¸€ç§ç”¨äºå¤šå¯¹æ¯”åº¦ç£å…±æŒ¯æˆåƒé‡å»º (Multi-Contrast MR Reconstruction, MCMR) çš„ç»Ÿä¸€é¢‘ç‡-ç©ºé—´èåˆæ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ–¹æ³•åœ¨ä¸åŒ k-space æ¬ é‡‡æ ·æ¨¡å¼ä¸‹æ³›åŒ–èƒ½åŠ›å·®ä¸”éœ€é‡å¤è®­ç»ƒçš„é—®é¢˜ã€‚UniFS é€šè¿‡é›†æˆè·¨æ¨¡æ€é¢‘ç‡èåˆ (Cross-Modal Frequency Fusion)ã€è‡ªé€‚åº”æ©ç æç¤ºå­¦ä¹  (Adaptive Mask-Based Prompt Learning) å’ŒåŒåˆ†æ”¯äº’è¡¥ç»†åŒ– (Dual-Branch Complementary Refinement) ä¸‰ä¸ªæ ¸å¿ƒæ¨¡å—ï¼Œå®ç°äº†å¯¹å¤šç§æ¬ é‡‡æ ·æ¨¡å¼çš„ç›´æ¥å¤„ç†è€Œæ— éœ€é‡æ–°è®­ç»ƒã€‚ä¸ºäº†å…‹æœä»¥å¾€æ–¹æ³•å¿½è§†é¢‘ç‡ç‰¹å¾çš„å±€é™ï¼Œè¯¥æ¨¡å‹ç‰¹åˆ«å¼•å…¥äº†è‡ªé€‚åº”æç¤ºå¼•å¯¼çš„é¢‘ç‡èåˆæœºåˆ¶ï¼Œå……åˆ†åˆ©ç”¨è·¨æ¨¡æ€çš„äº’è¡¥é¢‘ç‡ä¿¡æ¯ä»¥å¢å¼ºç‰¹å¾æå–ã€‚åœ¨ BraTS å’Œ HCP æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒUniFS åœ¨å¤šç§åŠ é€Ÿå› å­åŠæœªè§è¿‡çš„æ¬ é‡‡æ ·æ¨¡å¼ä¸‹å‡è¡¨ç°å‡ºè‰²ã€‚ç ”ç©¶è¯æ˜ UniFS è¾¾åˆ°äº†å½“å‰æœ€å…ˆè¿› (State-of-the-art) çš„æ€§èƒ½æ°´å¹³ï¼Œä¸ºä¸´åºŠåº”ç”¨ä¸­çµæ´»ã€é«˜æ•ˆçš„ç£å…±æŒ¯é‡å»ºæä¾›äº†æœ‰åŠ›çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.05481v1",
      "published_date": "2025-12-05 07:18:29 UTC",
      "updated_date": "2025-12-05 07:18:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:06:33.512159+00:00"
    },
    {
      "arxiv_id": "2512.05475v1",
      "title": "PERM EQ x GRAPH EQ: Equivariant Neural Networks for Quantum Molecular Learning",
      "title_zh": "PERM EQ x GRAPH EQï¼šç”¨äºé‡å­åˆ†å­å­¦ä¹ çš„ç­‰å˜ç¥ç»ç½‘ç»œ",
      "authors": [
        "Saumya Biswas",
        "Jiten Oswal"
      ],
      "abstract": "In hierarchal order of molecular geometry, we compare the performances of Geometric Quantum Machine Learning models. Two molecular datasets are considered: the simplistic linear shaped LiH-molecule and the trigonal pyramidal molecule NH3. Both accuracy and generalizability metrics are considered. A classical equivariant model is used as a baseline for the performance comparison. The comparative performance of Quantum Machine Learning models with no symmetry equivariance, rotational and permutational equivariance, and graph embedded permutational equivariance is investigated. The performance differentials and the molecular geometry in question reveals the criteria for choice of models for generalizability. Graph embedding of features is shown to be an effective pathway to greater trainability for geometric datasets. Permutational symmetric embedding is found to be the most generalizable quantum Machine Learning model for geometric learning.",
      "tldr_zh": "è¯¥ç ”ç©¶åœ¨é‡å­åˆ†å­å­¦ä¹ é¢†åŸŸæ¢è®¨äº†å‡ ä½• Quantum Machine Learning æ¨¡å‹çš„æ€§èƒ½è¡¨ç°ï¼Œé€šè¿‡çº¿æ€§ LiH åˆ†å­å’Œä¸‰è§’é”¥å½¢ NH3 åˆ†å­æ•°æ®é›†è¯„ä¼°äº†æ¨¡å‹çš„å‡†ç¡®æ€§ä¸ generalizabilityã€‚ç ”ç©¶ä»¥ç»å…¸çš„ equivariant model ä¸ºåŸºå‡†ï¼Œå¯¹æ¯”äº†æ— å¯¹ç§°æ€§ã€å…·æœ‰ rotational and permutational equivariance ä»¥åŠ graph embedded permutational equivariance çš„å¤šç§æ¨¡å‹ã€‚å®éªŒç»“æœæ­ç¤ºäº†æ¨¡å‹é€‰æ‹©ä¸åˆ†å­å‡ ä½•ç»“æ„ä¹‹é—´çš„å…³ç³»ï¼Œè¯æ˜äº†ç‰¹å¾çš„ graph embedding æ˜¯æå‡å‡ ä½•æ•°æ®é›† trainability çš„æœ‰æ•ˆè·¯å¾„ã€‚æœ€ç»ˆç ”ç©¶å‘ç°ï¼Œpermutational symmetric embedding æ˜¯å‡ ä½•å­¦ä¹ ä¸­ generalizability æœ€å¼ºçš„ Quantum Machine Learning æ¨¡å‹ï¼Œä¸ºè¯¥é¢†åŸŸçš„æ¨¡å‹ä¼˜åŒ–æä¾›äº†é‡è¦ä¾æ®ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "quant-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "22 pages, 9 figures, 4 tables",
      "pdf_url": "https://arxiv.org/pdf/2512.05475v1",
      "published_date": "2025-12-05 07:07:39 UTC",
      "updated_date": "2025-12-05 07:07:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:06:47.743266+00:00"
    },
    {
      "arxiv_id": "2512.11860v1",
      "title": "An Operator-Consistent Graph Neural Network for Learning Diffusion Dynamics on Irregular Meshes",
      "title_zh": "é¢å‘ä¸è§„åˆ™ç½‘æ ¼æ‰©æ•£åŠ¨åŠ›å­¦å­¦ä¹ çš„ç®—å­ä¸€è‡´æ€§å›¾ç¥ç»ç½‘ç»œ",
      "authors": [
        "Yuelian Li",
        "Andrew Rushing Hands"
      ],
      "abstract": "Classical numerical methods solve partial differential equations (PDEs) efficiently on regular meshes, but many of them become unstable on irregular domains. In practice, multiphysics interactions such as diffusion, damage, and healing often take place on irregular meshes. We develop an operator-consistent graph neural network (OCGNN-PINN) that approximates PDE evolution under physics-informed constraints. It couples node-edge message passing with a consistency loss enforcing the gradient-divergence relation through the graph incidence matrix, ensuring that discrete node and edge dynamics remain structurally coupled during temporal rollout. We evaluate the model on diffusion processes over physically driven evolving meshes and real-world scanned surfaces. The results show improved temporal stability and prediction accuracy compared with graph convolutional and multilayer perceptron baselines, approaching the performance of Crank-Nicolson solvers on unstructured domains.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼€å‘äº†ä¸€ç§ç®—å­ä¸€è‡´çš„å›¾ç¥ç»ç½‘ç»œ OCGNN-PINNï¼Œæ—¨åœ¨è§£å†³ç»å…¸æ•°å€¼æ–¹æ³•åœ¨ä¸è§„åˆ™ç½‘æ ¼ä¸Šæ±‚è§£åå¾®åˆ†æ–¹ç¨‹ PDEs æ—¶çš„ä¸ç¨³å®šæ€§é—®é¢˜ã€‚è¯¥æ¡†æ¶å°† node-edge message passing ä¸ä¸€ç§ consistency loss ç›¸ç»“åˆï¼Œé€šè¿‡ graph incidence matrix å¼ºåˆ¶æ‰§è¡Œæ¢¯åº¦-æ•£åº¦å…³ç³»ï¼Œä»è€Œç¡®ä¿ç¦»æ•£çš„èŠ‚ç‚¹ä¸è¾¹åŠ¨åŠ›å­¦åœ¨æ—¶é—´æ¼”åŒ–ä¸­ä¿æŒç»“æ„è€¦åˆã€‚é€šè¿‡åœ¨ç‰©ç†é©±åŠ¨çš„æ¼”åŒ–ç½‘æ ¼å’ŒçœŸå®æ‰«æè¡¨é¢çš„ diffusion processes è¿›è¡Œè¯„ä¼°ï¼Œè¯¥æ¨¡å‹å±•ç°å‡ºä¼˜äºå›¾å·ç§¯ç½‘ç»œå’Œå¤šå±‚æ„ŸçŸ¥å™¨åŸºçº¿çš„é¢„æµ‹ç²¾åº¦ä¸æ—¶é—´ç¨³å®šæ€§ã€‚å®éªŒç»“æœè¯æ˜å…¶æ€§èƒ½å·²æ¥è¿‘éç»“æ„åŒ–é¢†åŸŸä¸­çš„ Crank-Nicolson æ±‚è§£å™¨ï¼Œä¸ºå¤„ç†æ¶‰åŠæ‰©æ•£ã€æŸä¼¤åŠæ„ˆåˆç­‰å¤æ‚å¤šç‰©ç†åœºäº¤äº’æä¾›äº†é«˜æ•ˆä¸”ç¨³å¥çš„æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.11860v1",
      "published_date": "2025-12-05 06:58:25 UTC",
      "updated_date": "2025-12-05 06:58:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:06:32.525992+00:00"
    },
    {
      "arxiv_id": "2601.04199v1",
      "title": "The Forgotten Shield: Safety Grafting in Parameter-Space for Medical MLLMs",
      "title_zh": "è¢«é—å¿˜çš„æŠ¤ç›¾ï¼šåŒ»ç–— MLLMs å‚æ•°ç©ºé—´çš„å®‰å…¨å«æ¥",
      "authors": [
        "Jiale Zhao",
        "Xing Mou",
        "Jinlin Wu",
        "Hongyuan Yu",
        "Mingrui Sun",
        "Yang Shi",
        "Xuanwu Yin",
        "Zhen Chen",
        "Zhen Lei",
        "Yaohua Wang"
      ],
      "abstract": "Medical Multimodal Large Language Models (Medical MLLMs) have achieved remarkable progress in specialized medical tasks; however, research into their safety has lagged, posing potential risks for real-world deployment. In this paper, we first establish a multidimensional evaluation framework to systematically benchmark the safety of current SOTA Medical MLLMs. Our empirical analysis reveals pervasive vulnerabilities across both general and medical-specific safety dimensions in existing models, particularly highlighting their fragility against cross-modality jailbreak attacks. Furthermore, we find that the medical fine-tuning process frequently induces catastrophic forgetting of the model's original safety alignment. To address this challenge, we propose a novel \"Parameter-Space Intervention\" approach for efficient safety re-alignment. This method extracts intrinsic safety knowledge representations from original base models and concurrently injects them into the target model during the construction of medical capabilities. Additionally, we design a fine-grained parameter search algorithm to achieve an optimal trade-off between safety and medical performance. Experimental results demonstrate that our approach significantly bolsters the safety guardrails of Medical MLLMs without relying on additional domain-specific safety data, while minimizing degradation to core medical performance.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æ¢è®¨äº†åŒ»ç–—å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMedical MLLMsï¼‰åœ¨å®é™…éƒ¨ç½²ä¸­é¢ä¸´çš„å®‰å…¨é£é™©ï¼ŒæŒ‡å‡ºå…¶åœ¨é€šç”¨å’ŒåŒ»ç–—ç‰¹å®šç»´åº¦ä¸Šå‡å­˜åœ¨æ¼æ´ï¼Œç‰¹åˆ«æ˜¯åœ¨åº”å¯¹è·¨æ¨¡æ€è¶Šç‹±æ”»å‡»ï¼ˆcross-modality jailbreak attacksï¼‰æ—¶è¡¨ç°è„†å¼±ã€‚ç ”ç©¶å‘ç°ï¼ŒåŒ»ç–—å¾®è°ƒï¼ˆmedical fine-tuningï¼‰è¿‡ç¨‹å¾€å¾€ä¼šå¯¼è‡´æ¨¡å‹å¯¹åŸå§‹å®‰å…¨å¯¹é½ï¼ˆsafety alignmentï¼‰äº§ç”Ÿç¾éš¾æ€§é—å¿˜ï¼ˆcatastrophic forgettingï¼‰ã€‚é’ˆå¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œä½œè€…æå‡ºäº†ä¸€ç§â€œå‚æ•°ç©ºé—´å¹²é¢„â€ï¼ˆParameter-Space Interventionï¼‰æ–¹æ³•ï¼Œé€šè¿‡æå–åŸå§‹åŸºç¡€æ¨¡å‹ï¼ˆbase modelsï¼‰çš„å†…åœ¨å®‰å…¨çŸ¥è¯†è¡¨å¾å¹¶å°†å…¶æ³¨å…¥ç›®æ ‡æ¨¡å‹ï¼Œå®ç°é«˜æ•ˆçš„å®‰å…¨é‡æ–°å¯¹é½ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜é€šè¿‡ç»†ç²’åº¦å‚æ•°æœç´¢ç®—æ³•ï¼ˆfine-grained parameter search algorithmï¼‰ä¼˜åŒ–äº†å®‰å…¨æ€§ä¸åŒ»ç–—æ€§èƒ½ä¹‹é—´çš„æƒè¡¡ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¸ä¾èµ–é¢å¤–é¢†åŸŸç‰¹å®šå®‰å…¨æ•°æ®çš„æƒ…å†µä¸‹ï¼Œæ˜¾è‘—å¢å¼ºäº†Medical MLLMsçš„å®‰å…¨æŠ¤æ ï¼ŒåŒæ—¶æœ€å¤§é™åº¦åœ°ä¿ç•™äº†æ¨¡å‹çš„æ ¸å¿ƒåŒ»ç–—æ€§èƒ½ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.04199v1",
      "published_date": "2025-12-05 06:52:06 UTC",
      "updated_date": "2025-12-05 06:52:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:06:44.094003+00:00"
    },
    {
      "arxiv_id": "2512.05469v1",
      "title": "How Ensemble Learning Balances Accuracy and Overfitting: A Bias-Variance Perspective on Tabular Data",
      "title_zh": "é›†æˆå­¦ä¹ å¦‚ä½•å¹³è¡¡å‡†ç¡®ç‡ä¸è¿‡æ‹Ÿåˆï¼šè¡¨æ ¼æ•°æ®ä¸‹çš„åå·®-æ–¹å·®è§†è§’",
      "authors": [
        "Zubair Ahmed Mohammad"
      ],
      "abstract": "Ensemble models often achieve higher accuracy than single learners, but their ability to maintain small generalization gaps is not always well understood. This study examines how ensembles balance accuracy and overfitting across four tabular classification tasks: Breast Cancer, Heart Disease, Pima Diabetes, and Credit Card Fraud. Using repeated stratified cross validation with statistical significance testing, we compare linear models, a single decision tree, and nine ensemble methods. The results show that ensembles can reach high accuracy without large gaps by reducing variance through averaging or controlled boosting. On nearly linear and clean data, linear models already generalize well and ensembles offer little additional benefit. On datasets with meaningful nonlinear structure, tree based ensembles increase test accuracy by 5 to 7 points while keeping gaps below 3 percent. On noisy or highly imbalanced datasets, ensembles remain competitive but require regularization to avoid fitting noise or majority class patterns. We also compute simple dataset complexity indicators, such as linearity score, Fisher ratio, and noise estimate, which explain when ensembles are likely to control variance effectively. Overall, the study provides a clear view of how and when ensembles maintain high accuracy while keeping overfitting low, offering practical guidance for model selection in real world tabular applications.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»åå·®-æ–¹å·® (Bias-Variance) çš„è§†è§’å‡ºå‘ï¼Œæ¢è®¨äº†é›†æˆå­¦ä¹  (Ensemble Learning) åœ¨å¤„ç†è¡¨æ ¼æ•°æ® (Tabular Data) æ—¶å¦‚ä½•å¹³è¡¡å‡†ç¡®ç‡ä¸è¿‡æ‹Ÿåˆã€‚ç ”ç©¶é€šè¿‡åœ¨å››ä¸ªå…¸å‹åˆ†ç±»ä»»åŠ¡ä¸Šåº”ç”¨é‡å¤åˆ†å±‚äº¤å‰éªŒè¯ (Repeated Stratified Cross Validation)ï¼Œå¯¹æ¯”äº†çº¿æ€§æ¨¡å‹ã€å•å†³ç­–æ ‘ä»¥åŠä¹ç§é›†æˆæ–¹æ³•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œé›†æˆæ¨¡å‹é€šè¿‡å¹³å‡åŒ–æˆ–å—æ§çš„æå‡ (Boosting) æœ‰æ•ˆé™ä½äº†æ–¹å·® (Variance)ï¼Œä»è€Œåœ¨ä¸äº§ç”Ÿå·¨å¤§æ³›åŒ–å·®è·çš„æƒ…å†µä¸‹å®ç°é«˜å‡†ç¡®ç‡ã€‚åœ¨çº¿æ€§ä¸”å¹²å‡€çš„æ•°æ®ä¸Šé›†æˆæ–¹æ³•ä¼˜åŠ¿æœ‰é™ï¼Œä½†åœ¨å…·æœ‰æ˜¾è‘—éçº¿æ€§ç»“æ„çš„æ•°æ®é›†ä¸Šï¼ŒåŸºäºæ ‘çš„é›†æˆæ¨¡å‹åœ¨ä¿æŒæ³›åŒ–å·®è·ä½äº3%çš„åŒæ—¶å°†æµ‹è¯•å‡†ç¡®ç‡æé«˜äº†5%è‡³7%ã€‚é’ˆå¯¹å™ªå£°è¾ƒå¤§æˆ–é«˜åº¦ä¸å¹³è¡¡çš„æ•°æ®é›†ï¼Œé›†æˆæ¨¡å‹è™½å…·ç«äº‰åŠ›ä½†ä»éœ€å¼•å…¥æ­£åˆ™åŒ– (Regularization) ä»¥é¿å…å¯¹å™ªå£°æ¨¡å¼çš„æ‹Ÿåˆã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜åˆ©ç”¨çº¿æ€§å¾—åˆ†å’Œå™ªå£°è¯„ä¼°ç­‰å¤æ‚åº¦æŒ‡æ ‡è§£é‡Šäº†é›†æˆæ–¹æ³•æ§åˆ¶æ–¹å·®çš„æœ‰æ•ˆæ€§ï¼Œä¸ºå®é™…åº”ç”¨ä¸­çš„æ¨¡å‹é€‰æ‹©æä¾›äº†ç†è®ºä¾æ®ä¸å®è·µæŒ‡å¯¼ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 9 figures, 3 tables. Code and reproducible experiments are available at: https://github.com/zubair0831/ensemble-generalization-gap",
      "pdf_url": "https://arxiv.org/pdf/2512.05469v1",
      "published_date": "2025-12-05 06:51:06 UTC",
      "updated_date": "2025-12-05 06:51:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:06:55.441977+00:00"
    },
    {
      "arxiv_id": "2512.05468v1",
      "title": "University Building Recognition Dataset in Thailand for the mission-oriented IoT sensor system",
      "title_zh": "é¢å‘ä»»åŠ¡å‹ç‰©è”ç½‘ä¼ æ„Ÿå™¨ç³»ç»Ÿçš„ Thailand å¤§å­¦å»ºç­‘è¯†åˆ«æ•°æ®é›†",
      "authors": [
        "Takara Taniguchi",
        "Yudai Ueda",
        "Atsuya Muramatsu",
        "Kohki Hashimoto",
        "Ryo Yagi",
        "Hideya Ochiai",
        "Chaodit Aswakul"
      ],
      "abstract": "Many industrial sectors have been using of machine learning at inference mode on edge devices. Future directions show that training on edge devices is promising due to improvements in semiconductor performance. Wireless Ad Hoc Federated Learning (WAFL) has been proposed as a promising approach for collaborative learning with device-to-device communication among edges. In particular, WAFL with Vision Transformer (WAFL-ViT) has been tested on image recognition tasks with the UTokyo Building Recognition Dataset (UTBR). Since WAFL-ViT is a mission-oriented sensor system, it is essential to construct specific datasets by each mission. In our work, we have developed the Chulalongkorn University Building Recognition Dataset (CUBR), which is specialized for Chulalongkorn University as a case study in Thailand. Additionally, our results also demonstrate that training on WAFL scenarios achieves better accuracy than self-training scenarios. Dataset is available in https://github.com/jo2lxq/wafl/.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šè¿›è¡Œæœºå™¨å­¦ä¹ è®­ç»ƒçš„è¶‹åŠ¿ï¼Œç‰¹åˆ«æ˜¯åˆ©ç”¨è®¾å¤‡é—´é€šä¿¡å®ç°åä½œå­¦ä¹ çš„æ— çº¿è‡ªç»„ç»‡è”é‚¦å­¦ä¹  (Wireless Ad Hoc Federated Learning, WAFL) æ–¹æ³•ã€‚é’ˆå¯¹é¢å‘ä»»åŠ¡çš„ä¼ æ„Ÿå™¨ç³»ç»Ÿ WAFL-ViT éœ€è¦ç‰¹å®šä»»åŠ¡æ•°æ®é›†çš„éœ€æ±‚ï¼Œç ”ç©¶è€…å¼€å‘å¹¶å‘å¸ƒäº†ä¸“é—¨é’ˆå¯¹æ³°å›½æœ±æ‹‰éš†åŠŸå¤§å­¦çš„å»ºç­‘è¯†åˆ«æ•°æ®é›† (Chulalongkorn University Building Recognition Dataset, CUBR)ã€‚ä½œä¸ºæ³°å›½çš„æ¡ˆä¾‹ç ”ç©¶ï¼Œè¯¥æ•°æ®é›†ä¸ºè¯„ä¼°åä½œå­¦ä¹ ç®—æ³•æä¾›äº†å®é™…åœºæ™¯ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒWAFL åœºæ™¯ä¸‹çš„è®­ç»ƒå‡†ç¡®ç‡æ˜¾è‘—ä¼˜äºè‡ªæˆ‘è®­ç»ƒ (self-training) æ¨¡å¼ï¼Œè¯æ˜äº†åä½œå­¦ä¹ åœ¨å»ºç­‘è¯†åˆ«ä»»åŠ¡ä¸­çš„ä¼˜åŠ¿ã€‚è¯¥å·¥ä½œä¸ä»…ä¸ºç›¸å…³ç ”ç©¶æä¾›äº†å…¬å¼€æ•°æ®é›†ï¼Œä¹Ÿä¸ºå¼€å‘é«˜æ•ˆã€é¢å‘ä»»åŠ¡çš„ IoT ä¼ æ„Ÿå™¨ç³»ç»Ÿå¥ å®šäº†æ•°æ®åŸºç¡€ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.05468v1",
      "published_date": "2025-12-05 06:49:52 UTC",
      "updated_date": "2025-12-05 06:49:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:06:56.091157+00:00"
    },
    {
      "arxiv_id": "2512.05464v1",
      "title": "Dynamic Alignment for Collective Agency: Toward a Scalable Self-Improving Framework for Open-Ended LLM Alignment",
      "title_zh": "é¢å‘é›†ä½“èƒ½åŠ¨æ€§çš„åŠ¨æ€å¯¹é½ï¼šä¸€ç§å¯æ‰©å±•çš„å¼€æ”¾å¼å¤§è¯­è¨€æ¨¡å‹è‡ªæˆ‘æ”¹è¿›å¯¹é½æ¡†æ¶",
      "authors": [
        "Panatchakorn Anantaprayoon",
        "Nataliia Babina",
        "Jad Tarifi",
        "Nima Asgharbeygi"
      ],
      "abstract": "Large Language Models (LLMs) are typically aligned with human values using preference data or predefined principles such as helpfulness, honesty, and harmlessness. However, as AI systems progress toward Artificial General Intelligence (AGI) and Artificial Superintelligence (ASI), such value systems may become insufficient. In addition, human feedback-based alignment remains resource-intensive and difficult to scale. While AI-feedback-based self-improving alignment methods have been explored as a scalable alternative, they have largely remained constrained to conventional alignment values. In this work, we explore both a more holistic alignment objective and a scalable, self-improving alignment approach. Aiming to transcend conventional alignment norms, we introduce Collective Agency (CA)-a unified and open-ended alignment value that encourages integrated agentic capabilities. We also propose Dynamic Alignment-an alignment framework that enables an LLM to iteratively align itself. Dynamic Alignment comprises two key components: (1) automated training dataset generation with LLMs, and (2) a self-rewarding mechanism, where the policy model evaluates its own output candidates and assigns rewards for GRPO-based learning. Experimental results demonstrate that our approach successfully aligns the model to CA while preserving general NLP capabilities.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¼ ç»Ÿå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è¿ˆå‘é€šç”¨äººå·¥æ™ºèƒ½ï¼ˆAGIï¼‰è¿‡ç¨‹ä¸­é¢ä¸´çš„å¯¹é½ä»·å€¼å—é™åŠäººç±»åé¦ˆæˆæœ¬é«˜æ˜‚ç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åä¸º Collective Agency (CA) çš„ç»Ÿä¸€ä¸”å¼€æ”¾çš„å¯¹é½ç›®æ ‡ã€‚ä¸ºå®ç°è¿™ä¸€ç›®æ ‡ï¼Œè®ºæ–‡å¼€å‘äº† Dynamic Alignment æ¡†æ¶ï¼Œé€šè¿‡è¿­ä»£å¼çš„è‡ªæˆ‘æ”¹è¿›æ–¹æ³•å®ç°æ¨¡å‹å¯¹é½ã€‚è¯¥æ¡†æ¶æ•´åˆäº†è‡ªåŠ¨åŒ–çš„è®­ç»ƒæ•°æ®é›†ç”ŸæˆæŠ€æœ¯ï¼Œå¹¶å¼•å…¥äº†è‡ªæˆ‘å¥–åŠ±ï¼ˆself-rewardingï¼‰æœºåˆ¶ï¼Œä½¿ç­–ç•¥æ¨¡å‹èƒ½å¤Ÿè¯„ä¼°è‡ªèº«çš„è¾“å‡ºå¹¶ä¸ºåŸºäº GRPO çš„å¼ºåŒ–å­¦ä¹ æä¾›å¥–åŠ±ã€‚å®éªŒè¯æ˜ï¼ŒDynamic Alignment èƒ½å¤Ÿåœ¨ä¸æŸå®³é€šç”¨ NLP èƒ½åŠ›çš„å‰æä¸‹ï¼Œæœ‰æ•ˆæå‡æ¨¡å‹çš„ Collective Agency æ°´å¹³ï¼Œä¸ºæ„å»ºå¯æ‰©å±•çš„å¼€æ”¾å¼å¯¹é½ç³»ç»Ÿæä¾›äº†æ–°çš„è·¯å¾„ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 4 figures, to appear in AAAI 2026 AIGOV Workshop",
      "pdf_url": "https://arxiv.org/pdf/2512.05464v1",
      "published_date": "2025-12-05 06:46:00 UTC",
      "updated_date": "2025-12-05 06:46:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:07:04.835491+00:00"
    },
    {
      "arxiv_id": "2512.05461v1",
      "title": "Knowing Your Uncertainty -- On the application of LLM in social sciences",
      "title_zh": "çŸ¥å…¶ä¸ç¡®å®šæ€§ï¼šè®ºå¤§è¯­è¨€æ¨¡å‹åœ¨ç¤¾ä¼šç§‘å­¦ä¸­çš„åº”ç”¨",
      "authors": [
        "Bolun Zhang",
        "Linzhuo Li",
        "Yunqi Chen",
        "Qinlin Zhao",
        "Zihan Zhu",
        "Xiaoyuan Yi",
        "Xing Xie"
      ],
      "abstract": "Large language models (LLMs) are rapidly being integrated into computational social science research, yet their blackboxed training and designed stochastic elements in inference pose unique challenges for scientific inquiry. This article argues that applying LLMs to social scientific tasks requires explicit assessment of uncertainty-an expectation long established in both quantitative methodology in the social sciences and machine learning. We introduce a unified framework for evaluating LLM uncertainty along two dimensions: the task type (T), which distinguishes between classification, short-form, and long-form generation, and the validation type (V), which captures the availability of reference data or evaluative criteria. Drawing from both computer science and social science literature, we map existing uncertainty quantification (UQ) methods to this T-V typology and offer practical recommendations for researchers. Our framework provides both a methodological safeguard and a practical guide for integrating LLMs into rigorous social science research.",
      "tldr_zh": "æœ¬ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨è®¡ç®—ç¤¾ä¼šç§‘å­¦ç ”ç©¶ä¸­çš„åº”ç”¨ï¼Œé’ˆå¯¹å…¶è®­ç»ƒè¿‡ç¨‹çš„é»‘ç®±åŒ–å’Œæ¨ç†è¿‡ç¨‹çš„éšæœºæ€§å¸¦æ¥çš„æŒ‘æˆ˜ï¼Œå¼ºè°ƒäº†å¯¹ä¸ç¡®å®šæ€§(Uncertainty)è¿›è¡Œæ˜¾å¼è¯„ä¼°çš„å¿…è¦æ€§ã€‚ä½œè€…æå‡ºäº†ä¸€ä¸ªè¯„ä¼°LLMä¸ç¡®å®šæ€§çš„ç»Ÿä¸€æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å›´ç»•ä»»åŠ¡ç±»å‹(Task type, T)å’ŒéªŒè¯ç±»å‹(Validation type, V)ä¸¤ä¸ªæ ¸å¿ƒç»´åº¦å±•å¼€ã€‚å…¶ä¸­ï¼Œä»»åŠ¡ç±»å‹åŒºåˆ†äº†åˆ†ç±»ã€çŸ­æ ¼å¼ç”Ÿæˆå’Œé•¿æ ¼å¼ç”Ÿæˆï¼Œè€ŒéªŒè¯ç±»å‹åˆ™è€ƒé‡äº†å‚è€ƒæ•°æ®æˆ–è¯„ä¼°æ ‡å‡†çš„å¯è·å¾—æ€§ã€‚ç ”ç©¶é€šè¿‡ç»“åˆè®¡ç®—æœºç§‘å­¦å’Œç¤¾ä¼šç§‘å­¦æ–‡çŒ®ï¼Œå°†ç°æœ‰çš„ä¸ç¡®å®šæ€§é‡åŒ–(Uncertainty Quantification, UQ)æ–¹æ³•æ˜ å°„åˆ°è¯¥T-Våˆ†ç±»ä½“ç³»ä¸­ï¼Œå¹¶ä¸ºç ”ç©¶è€…æä¾›äº†å…·ä½“çš„å®è·µå»ºè®®ã€‚è¯¥æ¡†æ¶ä¸ºå°†LLMsæ•´åˆè¿›ä¸¥è°¨çš„ç¤¾ä¼šç§‘å­¦ç ”ç©¶æä¾›äº†æ–¹æ³•è®ºä¿éšœå’Œå®ç”¨æŒ‡å—ï¼Œæœ‰åŠ©äºç¡®ä¿è®¡ç®—ç¤¾ä¼šç§‘å­¦å‘ç°çš„å¯é æ€§ä¸ç§‘å­¦æ€§ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "49 pages, 10 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.05461v1",
      "published_date": "2025-12-05 06:36:15 UTC",
      "updated_date": "2025-12-05 06:36:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:07:54.258352+00:00"
    },
    {
      "arxiv_id": "2512.05453v1",
      "title": "Parajudica: An RDF-Based Reasoner and Metamodel for Multi-Framework Context-Dependent Data Compliance Assessments",
      "title_zh": "Parajudicaï¼šé¢å‘å¤šæ¡†æ¶ä¸Šä¸‹æ–‡ç›¸å…³æ•°æ®åˆè§„æ€§è¯„ä¼°çš„ RDF æ¨ç†å™¨ä¸å…ƒæ¨¡å‹",
      "authors": [
        "Luc Moreau",
        "Alfred Rossi",
        "Sophie Stalla-Bourdillon"
      ],
      "abstract": "Motivated by the challenges of implementing policy-based data access control (PBAC) under multiple simultaneously applicable compliance frameworks, we present Parajudica, an open, modular, and extensible RDF/SPARQL-based rule system for evaluating context-dependent data compliance status. We demonstrate the utility of this resource and accompanying metamodel through application to existing legal frameworks and industry standards, offering insights for comparative framework analysis. Applications include compliance policy enforcement, compliance monitoring, data discovery, and risk assessment.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åœ¨å¤šä¸ªåŒæ—¶é€‚ç”¨çš„åˆè§„æ¡†æ¶ä¸‹å®æ–½åŸºäºç­–ç•¥çš„æ•°æ®è®¿é—®æ§åˆ¶ (PBAC) æ‰€é¢ä¸´çš„æŒ‘æˆ˜ï¼Œæå‡ºäº† Parajudica æ¡†æ¶ã€‚Parajudica æ˜¯ä¸€ä¸ªåŸºäº RDF/SPARQL çš„è§„åˆ™ç³»ç»Ÿï¼Œå…·æœ‰å¼€æ”¾ã€æ¨¡å—åŒ–å’Œå¯æ‰©å±•çš„ç‰¹æ€§ï¼Œä¸“é—¨ç”¨äºè¯„ä¼°ä¸Šä¸‹æ–‡ç›¸å…³çš„æ•°æ®åˆè§„çŠ¶æ€ã€‚è¯¥ç³»ç»Ÿé€šè¿‡é…å¥—çš„å…ƒæ¨¡å‹ (Metamodel) åœ¨ç°æœ‰æ³•å¾‹æ¡†æ¶å’Œè¡Œä¸šæ ‡å‡†ä¸­è¿›è¡Œäº†éªŒè¯ï¼Œä¸ºè·¨æ¡†æ¶çš„æ¯”è¾ƒåˆ†ææä¾›äº†æ·±å…¥è§è§£ã€‚å…¶åº”ç”¨åœºæ™¯æ¶µç›–äº†åˆè§„ç­–ç•¥æ‰§è¡Œ (Compliance Policy Enforcement)ã€åˆè§„ç›‘æ§ (Compliance Monitoring)ã€æ•°æ®å‘ç°ä»¥åŠé£é™©è¯„ä¼°ç­‰å¤šä¸ªå…³é”®é¢†åŸŸã€‚è¿™ä¸€å·¥å…·çš„æ¨å‡ºä¸ºè§£å†³å¤æ‚æ³•å¾‹ç¯å¢ƒä¸‹çš„æ•°æ®åˆè§„æ€§è¯„ä¼°æä¾›äº†è‡ªåŠ¨åŒ–ä¸”æ ‡å‡†åŒ–çš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.CY",
        "cs.LO"
      ],
      "primary_category": "cs.DB",
      "comment": "17 pages, 8 figures. Code and examples available at https://github.com/alfredr/parajudica",
      "pdf_url": "https://arxiv.org/pdf/2512.05453v1",
      "published_date": "2025-12-05 06:16:34 UTC",
      "updated_date": "2025-12-05 06:16:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:08:17.624587+00:00"
    },
    {
      "arxiv_id": "2512.13704v1",
      "title": "Adjudicator: Correcting Noisy Labels with a KG-Informed Council of LLM Agents",
      "title_zh": "Adjudicatorï¼šåˆ©ç”¨çŸ¥è¯†å›¾è°±å¼•å¯¼çš„å¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“å§”å‘˜ä¼šçº æ­£å™ªå£°æ ‡ç­¾",
      "authors": [
        "Doohee You",
        "Sundeep Paul"
      ],
      "abstract": "The performance of production machine learning systems is fundamentally limited by the quality of their training data. In high-stakes industrial applications, noisy labels can degrade performance and erode user trust. This paper presents Adjudicator, a system that addresses the critical data mining challenge of automatically identifying and correcting label noise and has been validated for production deployment. Adjudicator models this as a neuro-symbolic task, first constructing a dynamic Knowledge Graph (KG) to unify item context. This KG then informs a \"Council of Agents,\" a novel multi-agent Large Language Model architecture where specialized agents debate and vote on a label's validity. We validate our system on a 1,000-item balanced subset of the AlleNoise benchmark. Our KG-informed model achieves a 0.99 F1-score, significantly outperforming a single-LLM baseline (0.48 F1) and a non-KG council (0.59 F1). Our analysis reveals this is due to a Precision, achieved by a novel override logic that uses the KG to perfectly identify complex, structural errors (complete Recall) -- a class of errors that baselines fail to find. This result demonstrates a robust and explainable system for automated, high-precision data verification, serving as a vital proof-of-concept for generating golden datasets in strictly governed industrial environments.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Adjudicatorï¼Œä¸€ä¸ªä¸“é—¨ç”¨äºè¯†åˆ«å’Œçº æ­£é«˜è¦æ±‚å·¥ä¸šåº”ç”¨ä¸­å™ªå£°æ ‡ç­¾(noisy labels)çš„è‡ªåŠ¨åŒ–ç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿå°†æ­¤è¿‡ç¨‹å»ºæ¨¡ä¸ºä¸€é¡¹ç¥ç»ç¬¦å·(neuro-symbolic)ä»»åŠ¡ï¼Œé¦–å…ˆé€šè¿‡æ„å»ºåŠ¨æ€çŸ¥è¯†å›¾è°±(Knowledge Graph, KG)æ¥ç»Ÿä¸€é¡¹ç›®çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚éšåï¼Œè¯¥ KG ä¼šå¼•å¯¼ä¸€ä¸ªç”±å¤šæ™ºèƒ½ä½“å¤§è¯­è¨€æ¨¡å‹(multi-agent LLM)æ¶æ„ç»„æˆçš„â€œè®®ä¼šç³»ç»Ÿâ€(Council of Agents)ï¼Œé€šè¿‡ä¸“é—¨åŒ–æ™ºèƒ½ä½“ä¹‹é—´çš„è¾©è®ºä¸æŠ•ç¥¨æ¥è¯„å®šæ ‡ç­¾çš„æœ‰æ•ˆæ€§ã€‚åœ¨ AlleNoise åŸºå‡†æµ‹è¯•ä¸­çš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¨¡å‹è¾¾åˆ°äº† 0.99 çš„ F1 åˆ†æ•°ï¼Œå…¶è¡¨ç°æ˜¾è‘—ä¼˜äºå•ä¸€ LLM åŸºå‡†åŠç¼ºä¹ KG è¾…åŠ©çš„è®®ä¼šæ–¹æ¡ˆã€‚Adjudicator çš„æ ¸å¿ƒç«äº‰åŠ›åœ¨äºå…¶æ–°é¢–çš„è¦†ç›–é€»è¾‘(override logic)ï¼Œèƒ½åˆ©ç”¨ KG ç²¾ç¡®è¯†åˆ«åŸºå‡†æ¨¡å‹éš¾ä»¥å‘ç°çš„å¤æ‚ç»“æ„æ€§é”™è¯¯ã€‚è¿™ä¸€æˆæœä¸ºåœ¨å—ä¸¥æ ¼ç›‘ç®¡çš„å·¥ä¸šç¯å¢ƒä¸‹è‡ªåŠ¨ç”Ÿæˆé«˜ç²¾åº¦é»„é‡‘æ•°æ®é›†(golden datasets)æä¾›äº†ä¸€ä¸ªç¨³å¥ä¸”å…·æœ‰å¯è§£é‡Šæ€§çš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.13704v1",
      "published_date": "2025-12-05 06:13:00 UTC",
      "updated_date": "2025-12-05 06:13:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:08:19.041906+00:00"
    },
    {
      "arxiv_id": "2512.05449v1",
      "title": "The Seeds of Scheming: Weakness of Will in the Building Blocks of Agentic Systems",
      "title_zh": "æƒè°‹çš„èŒèŠ½ï¼šæ™ºèƒ½ä½“ç³»ç»Ÿæ„å»ºåŸºå—ä¸­çš„æ„å¿—è–„å¼±",
      "authors": [
        "Robert Yang"
      ],
      "abstract": "Large language models display a peculiar form of inconsistency: they \"know\" the correct answer but fail to act on it. In human philosophy, this tension between global judgment and local impulse is called akrasia, or weakness of will. We propose akrasia as a foundational concept for analyzing inconsistency and goal drift in agentic AI systems. To operationalize it, we introduce a preliminary version of the Akrasia Benchmark, currently a structured set of prompting conditions (Baseline [B], Synonym [S], Temporal [T], and Temptation [X]) that measures when a model's local response contradicts its own prior commitments. The benchmark enables quantitative comparison of \"self-control\" across model families, decoding strategies, and temptation types. Beyond single-model evaluation, we outline how micro-level akrasia may compound into macro-level instability in multi-agent systems that may be interpreted as \"scheming\" or deliberate misalignment. By reframing inconsistency as weakness of will, this work connects agentic behavior to classical theories of agency and provides an empirical bridge between philosophy, psychology, and the emerging science of agentic AI.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)è¡¨ç°å‡ºçš„ä¸€ç§ç‰¹æ®Šçš„ä¸ä¸€è‡´æ€§ï¼Œå³æ¨¡å‹è™½ç„¶â€œçŸ¥é“â€æ­£ç¡®ç­”æ¡ˆå´æ— æ³•æ®æ­¤è¡ŒåŠ¨ï¼Œå¹¶å°†è¿™ç§å“²å­¦ä¸Šçš„â€œæ„å¿—è–„å¼±(akrasia)â€æ¦‚å¿µå¼•å…¥åˆ°AIä»£ç†ç³»ç»Ÿçš„åˆ†æä¸­ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†Akrasia Benchmarkï¼Œé€šè¿‡åŸºå‡†(Baseline [B])ã€åŒä¹‰è¯(Synonym [S])ã€æ—¶é—´(Temporal [T])å’Œè¯±æƒ‘(Temptation [X])å››ç§æç¤ºæ¡ä»¶æ¥é‡åŒ–æ¨¡å‹å±€éƒ¨ååº”ä¸å…¶å…ˆå‰æ‰¿è¯ºä¹‹é—´çš„çŸ›ç›¾ã€‚è¯¥åŸºå‡†èƒ½å¤Ÿæ¯”è¾ƒä¸åŒæ¨¡å‹å®¶æ—ã€è§£ç ç­–ç•¥åŠè¯±æƒ‘ç±»å‹ä¸‹çš„â€œè‡ªæˆ‘æ§åˆ¶â€èƒ½åŠ›ï¼Œå¹¶æ­ç¤ºäº†å¾®è§‚å±‚é¢çš„æ„å¿—è–„å¼±å¯èƒ½åœ¨å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­æ¼”åŒ–ä¸ºå®è§‚å±‚é¢çš„ä¸ç¨³å®šæ€§ã€‚è¿™ç§ä¸ç¨³å®šæ€§å¯èƒ½è¢«è§£é‡Šä¸ºâ€œç­–åˆ’(scheming)â€æˆ–æ•…æ„çš„ä¸å¯¹é½(misalignment)ï¼Œä»è€Œå½±å“ç³»ç»Ÿçš„æ•´ä½“å¯é æ€§ã€‚é€šè¿‡å°†ä¸ä¸€è‡´æ€§é‡æ–°å®šä¹‰ä¸ºæ„å¿—è–„å¼±ï¼Œè¯¥å·¥ä½œåœ¨ç»å…¸ä»£ç†ç†è®ºä¸æ–°å…´çš„ä»£ç†AIç§‘å­¦ä¹‹é—´å»ºç«‹äº†å®è¯æ¡¥æ¢ï¼Œä¸ºç†è§£ä»£ç†ç³»ç»Ÿçš„ç›®æ ‡åç§»å’Œè¡Œä¸ºä¸ä¸€è‡´æä¾›äº†æ–°çš„è§†è§’å’Œåˆ†æå·¥å…·ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "4 pages + appendix. AAAI 2026 FAST Workshop (Oral)",
      "pdf_url": "https://arxiv.org/pdf/2512.05449v1",
      "published_date": "2025-12-05 05:57:40 UTC",
      "updated_date": "2025-12-05 05:57:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:08:29.180955+00:00"
    },
    {
      "arxiv_id": "2512.05442v2",
      "title": "IdealTSF: Can Non-Ideal Data Contribute to Enhancing the Performance of Time Series Forecasting Models?",
      "title_zh": "IdealTSFï¼šéç†æƒ³æ•°æ®æ˜¯å¦æœ‰åŠ©äºæå‡æ—¶é—´åºåˆ—é¢„æµ‹æ¨¡å‹çš„æ€§èƒ½ï¼Ÿ",
      "authors": [
        "Hua Wang",
        "Jinghao Lu",
        "Fan Zhang"
      ],
      "abstract": "Deep learning has shown strong performance in time series forecasting tasks. However, issues such as missing values and anomalies in sequential data hinder its further development in prediction tasks. Previous research has primarily focused on extracting feature information from sequence data or addressing these suboptimal data as positive samples for knowledge transfer. A more effective approach would be to leverage these non-ideal negative samples to enhance event prediction. In response, this study highlights the advantages of non-ideal negative samples and proposes the IdealTSF framework, which integrates both ideal positive and negative samples for time series forecasting. IdealTSF consists of three progressive steps: pretraining, training, and optimization. It first pretrains the model by extracting knowledge from negative sample data, then transforms the sequence data into ideal positive samples during training. Additionally, a negative optimization mechanism with adversarial disturbances is applied. Extensive experiments demonstrate that negative sample data unlocks significant potential within the basic attention architecture for time series forecasting. Therefore, IdealTSF is particularly well-suited for applications with noisy samples or low-quality data.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ—¶é—´åºåˆ—é¢„æµ‹ä¸­å­˜åœ¨çš„ç¼ºå¤±å€¼å’Œå¼‚å¸¸å€¼ç­‰ Non-ideal data é—®é¢˜ï¼Œæ¢è®¨äº†éç†æƒ³è´Ÿæ ·æœ¬å¯¹æå‡æ¨¡å‹æ€§èƒ½çš„æ½œåœ¨è´¡çŒ®ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶è€…æå‡ºäº† IdealTSF æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡æ•´åˆç†æƒ³æ­£æ ·æœ¬å’Œéç†æƒ³è´Ÿæ ·æœ¬æ¥å¢å¼ºäº‹ä»¶é¢„æµ‹èƒ½åŠ›ã€‚IdealTSF åŒ…å«é¢„è®­ç»ƒã€è®­ç»ƒå’Œä¼˜åŒ–ä¸‰ä¸ªé€’è¿›é˜¶æ®µï¼šé¦–å…ˆé€šè¿‡ Pretraining ä»è´Ÿæ ·æœ¬ä¸­æå–çŸ¥è¯†ï¼Œéšååœ¨è®­ç»ƒé˜¶æ®µå°†åºåˆ—æ•°æ®è½¬åŒ–ä¸ºç†æƒ³çš„æ­£æ ·æœ¬ï¼Œå¹¶å¼•å…¥å¸¦æœ‰ Adversarial disturbances çš„è´Ÿä¼˜åŒ–æœºåˆ¶ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè´Ÿæ ·æœ¬æ•°æ®èƒ½å¤Ÿæ˜¾è‘—æ¿€å‘åŸºç¡€ Attention æ¶æ„åœ¨æ—¶é—´åºåˆ—é¢„æµ‹ä¸­çš„æ€§èƒ½æ½œåŠ›ã€‚è¯¥æ¡†æ¶è¯æ˜äº†éç†æƒ³æ•°æ®åœ¨æ¨¡å‹è®­ç»ƒä¸­çš„ç‹¬ç‰¹ä»·å€¼ï¼Œç‰¹åˆ«é€‚ç”¨äºåŒ…å« Noisy samples æˆ–ä½è´¨é‡æ•°æ®çš„å®é™…åº”ç”¨åœºæ™¯ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at AAAI 2026",
      "pdf_url": "https://arxiv.org/pdf/2512.05442v2",
      "published_date": "2025-12-05 05:37:25 UTC",
      "updated_date": "2025-12-16 09:16:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:08:10.063160+00:00"
    },
    {
      "arxiv_id": "2512.05439v1",
      "title": "BEAVER: An Efficient Deterministic LLM Verifier",
      "title_zh": "BEAVERï¼šé«˜æ•ˆç¡®å®šæ€§ LLM éªŒè¯å™¨",
      "authors": [
        "Tarun Suresh",
        "Nalin Wadhwa",
        "Debangshu Banerjee",
        "Gagandeep Singh"
      ],
      "abstract": "As large language models (LLMs) transition from research prototypes to production systems, practitioners often need reliable methods to verify that model outputs satisfy required constraints. While sampling-based estimates provide an intuition of model behavior, they offer no sound guarantees. We present BEAVER, the first practical framework for computing deterministic, sound probability bounds on LLM constraint satisfaction. Given any prefix-closed semantic constraint, BEAVER systematically explores the generation space using novel token trie and frontier data structures, maintaining provably sound bounds at every iteration. We formalize the verification problem, prove soundness of our approach, and evaluate BEAVER on correctness verification, privacy verification and secure code generation tasks across multiple state of the art LLMs. BEAVER achieves 6 to 8 times tighter probability bounds and identifies 3 to 4 times more high risk instances compared to baseline methods under identical computational budgets, enabling precise characterization and risk assessment that loose bounds or empirical evaluation cannot provide.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)ä»ç ”ç©¶åŸå‹å‘ç”Ÿäº§ç³»ç»Ÿè½¬å‹è¿‡ç¨‹ä¸­ï¼Œç¼ºä¹å¯é æ–¹æ³•éªŒè¯è¾“å‡ºæ˜¯å¦æ»¡è¶³çº¦æŸæ¡ä»¶çš„é—®é¢˜ï¼Œæå‡ºäº†BEAVERæ¡†æ¶ã€‚ä½œä¸ºé¦–ä¸ªç”¨äºè®¡ç®—LLMçº¦æŸæ»¡è¶³æ€§çš„ç¡®å®šæ€§ã€å¯é æ¦‚ç‡è¾¹ç•Œ(deterministic, sound probability bounds)çš„å®ç”¨æ¡†æ¶ï¼ŒBEAVERèƒ½å¤Ÿé’ˆå¯¹ä»»ä½•å‰ç¼€é—­åˆè¯­ä¹‰çº¦æŸ(prefix-closed semantic constraint)ï¼Œåˆ©ç”¨åˆ›æ–°çš„token trieå’Œfrontieræ•°æ®ç»“æ„ç³»ç»Ÿåœ°æ¢ç´¢ç”Ÿæˆç©ºé—´ï¼Œå¹¶åœ¨æ¯æ¬¡è¿­ä»£ä¸­ç»´æŒå¯è¯æ˜çš„å¯é è¾¹ç•Œã€‚ç ”ç©¶å›¢é˜Ÿå¯¹éªŒè¯é—®é¢˜è¿›è¡Œäº†å½¢å¼åŒ–å®šä¹‰ï¼Œå¹¶åœ¨æ­£ç¡®æ€§éªŒè¯ã€éšç§éªŒè¯å’Œå®‰å…¨ä»£ç ç”Ÿæˆç­‰ä»»åŠ¡ä¸Šå¯¹å¤šæ¬¾æœ€å…ˆè¿›çš„LLMsè¿›è¡Œäº†è¯„ä¼°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨ç›¸åŒè®¡ç®—é¢„ç®—ä¸‹ï¼ŒBEAVERæ¯”åŸºçº¿æ–¹æ³•è·å¾—äº†å¿«6åˆ°8å€çš„ç´§å‡‘æ¦‚ç‡è¾¹ç•Œï¼Œå¹¶å¤šè¯†åˆ«å‡º3åˆ°4å€çš„é«˜é£é™©å®ä¾‹ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼ŒBEAVERå®ç°äº†å¯¹æ¨¡å‹è¡Œä¸ºçš„ç²¾ç¡®è¡¨å¾å’Œé£é™©è¯„ä¼°ï¼Œå…‹æœäº†ä¼ ç»Ÿç»éªŒè¯„ä¼°æˆ–æ¾æ•£è¾¹ç•Œ(loose bounds)çš„å±€é™æ€§ã€‚",
      "categories": [
        "cs.AI",
        "cs.FL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.05439v1",
      "published_date": "2025-12-05 05:34:06 UTC",
      "updated_date": "2025-12-05 05:34:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:08:13.027514+00:00"
    },
    {
      "arxiv_id": "2512.11859v1",
      "title": "Generative Stochastic Optimal Transport: Guided Harmonic Path-Integral Diffusion",
      "title_zh": "ç”Ÿæˆå¼éšæœºæœ€ä¼˜ä¼ è¾“ï¼šå¼•å¯¼è°ƒå’Œè·¯å¾„ç§¯åˆ†æ‰©æ•£",
      "authors": [
        "Michael Chertkov"
      ],
      "abstract": "We introduce Guided Harmonic Path-Integral Diffusion (GH-PID), a linearly-solvable framework for guided Stochastic Optimal Transport (SOT) with a hard terminal distribution and soft, application-driven path costs. A low-dimensional guidance protocol shapes the trajectory ensemble while preserving analytic structure: the forward and backward Kolmogorov equations remain linear, the optimal score admits an explicit Green-function ratio, and Gaussian-Mixture Model (GMM) terminal laws yield closed-form expressions. This enables stable sampling and differentiable protocol learning under exact terminal matching.\n  We develop guidance-centric diagnostics -- path cost, centerline adherence, variance flow, and drift effort -- that make GH-PID an interpretable variational ansatz for empirical SOT. Three navigation scenarios illustrated in 2D: (i) Case A: hand-crafted protocols revealing how geometry and stiffness shape lag, curvature effects, and mode evolution; (ii) Case B: single-task protocol learning, where a PWC centerline is optimized to minimize integrated cost; (iii) Case C: multi-expert fusion, in which a commander reconciles competing expert/teacher trajectories and terminal beliefs through an exact product-of-experts law and learns a consensus protocol. Across all settings, GH-PID generates geometry-aware, trust-aware trajectories that satisfy the prescribed terminal distribution while systematically reducing integrated cost.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Guided Harmonic Path-Integral Diffusion (GH-PID)ï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºå¼•å¯¼éšæœºæœ€ä¼˜ä¼ è¾“ (Stochastic Optimal Transport, SOT) çš„çº¿æ€§å¯è§£æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡ä½ç»´å¼•å¯¼åè®®åœ¨ä¿æŒè§£æç»“æ„çš„åŒæ—¶å¡‘é€ è½¨è¿¹é›†æˆï¼Œä½¿å¾—å‰å‘å’Œåå‘Kolmogorovæ–¹ç¨‹ä¿æŒçº¿æ€§ï¼Œå¹¶ä¸ºé«˜æ–¯æ··åˆæ¨¡å‹ (GMM) ç»ˆç«¯æ³•åˆ™æä¾›é—­å¼è§£ã€‚GH-PIDå®ç°äº†ç¨³å®šçš„é‡‡æ ·å’Œå¯å¾®çš„åè®®å­¦ä¹ ï¼Œç¡®ä¿äº†ç²¾ç¡®çš„ç»ˆç«¯åŒ¹é…ï¼Œå¹¶é€šè¿‡è·¯å¾„æˆæœ¬å’Œä¸­å¿ƒçº¿ä¾ä»æ€§ç­‰è¯Šæ–­æŒ‡æ ‡æä¾›äº†å¯è§£é‡Šçš„å˜åˆ†æ‹Ÿè®¾ (variational ansatz)ã€‚ç ”ç©¶é€šè¿‡æ‰‹å·¥åè®®ã€å•ä»»åŠ¡ä¸­å¿ƒçº¿ä¼˜åŒ–ä»¥åŠåŸºäºä¹˜ç§¯ä¸“å®¶æ³•åˆ™ (product-of-experts) çš„å¤šä¸“å®¶èåˆç­‰äºŒç»´å¯¼èˆªåœºæ™¯éªŒè¯äº†æ¡†æ¶çš„çµæ´»æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒGH-PIDèƒ½å¤Ÿç”Ÿæˆå…·æœ‰å‡ ä½•æ„ŸçŸ¥å’Œä¿¡ä»»æ„ŸçŸ¥çš„è½¨è¿¹ï¼Œåœ¨æ»¡è¶³é¢„è®¾ç»ˆç«¯åˆ†å¸ƒçš„åŒæ—¶ç³»ç»Ÿåœ°é™ä½äº†ç»¼åˆè·¯å¾„æˆæœ¬ã€‚",
      "categories": [
        "cs.LG",
        "cond-mat.stat-mech",
        "cs.AI",
        "eess.SY",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "40 pages, 8 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.11859v1",
      "published_date": "2025-12-05 05:18:15 UTC",
      "updated_date": "2025-12-05 05:18:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:08:25.369887+00:00"
    },
    {
      "arxiv_id": "2512.05432v1",
      "title": "Building Capacity for Artificial Intelligence in Africa: A Cross-Country Survey of Challenges and Governance Pathways",
      "title_zh": "Africa äººå·¥æ™ºèƒ½èƒ½åŠ›å»ºè®¾ï¼šæŒ‘æˆ˜ä¸æ²»ç†è·¯å¾„çš„è·¨å›½è°ƒç ”",
      "authors": [
        "Jeffrey N. A. Aryee",
        "Patrick Davies",
        "Godfred A. Torsah",
        "Mercy M. Apaw",
        "Cyril D. Boateng",
        "Sam M. Mwando",
        "Chris Kwisanga",
        "Eric Jobunga",
        "Leonard K. Amekudzi"
      ],
      "abstract": "Artificial intelligence (AI) is transforming education and the workforce, but access to AI learning opportunities in Africa remains uneven. With rapid demographic shifts and growing labour market pressures, AI has become a strategic development priority, making the demand for relevant skills more urgent. This study investigates how universities and industries engage in shaping AI education and workforce preparation, drawing on survey responses from five African countries (Ghana, Namibia, Rwanda, Kenya and Zambia). The findings show broad recognition of AI importance but limited evidence of consistent engagement, practical training, or equitable access to resources. Most respondents who rated the AI component of their curriculum as very relevant reported being well prepared for jobs, but financial barriers, poor infrastructure, and weak communication limit participation, especially among students and underrepresented groups. Respondents highlighted internships, industry partnerships, and targeted support mechanisms as critical enablers, alongside the need for inclusive governance frameworks. The results showed both the growing awareness of AI's potential and the structural gaps that hinder its translation into workforce capacity. Strengthening university-industry collaboration and addressing barriers of access, funding, and policy are central to ensuring that AI contributes to equitable and sustainable development across the continent.",
      "tldr_zh": "è¯¥ç ”ç©¶é€šè¿‡å¯¹åŠ çº³ã€çº³ç±³æ¯”äºšã€å¢æ—ºè¾¾ã€è‚¯å°¼äºšå’Œèµæ¯”äºšäº”ä¸ªéæ´²å›½å®¶çš„è·¨å›½è°ƒæŸ¥ï¼Œæ·±å…¥æ¢è®¨äº† Artificial Intelligence (AI) èƒ½åŠ›å»ºè®¾ä¸­çš„æŒ‘æˆ˜ä¸æ²»ç†è·¯å¾„ã€‚ç ”ç©¶å‘ç°ï¼Œè™½ç„¶ AI å·²æˆä¸ºæˆ˜ç•¥å‘å±•é‡ç‚¹ï¼Œä½†åœ¨å®é™…çš„æ•™è‚²å‚ä¸ã€å®è·µåŸ¹è®­å’Œèµ„æºå…¬å¹³åˆ†é…æ–¹é¢ä»å­˜åœ¨æ˜¾è‘—å·®è·ã€‚è°ƒæŸ¥ç»“æœæ˜¾ç¤ºï¼ŒCurriculum (è¯¾ç¨‹) çš„ç›¸å…³æ€§ç›´æ¥å½±å“å—è®¿è€…çš„å°±ä¸šå‡†å¤‡ç¨‹åº¦ï¼Œä½† Financial barriers (è´¢åŠ¡å£å’) å’Œ Infrastructure (åŸºç¡€è®¾æ–½) çš„ä¸è¶³ä¸¥é‡é™åˆ¶äº†å­¦ç”ŸåŠä»£è¡¨æ€§ä¸è¶³ç¾¤ä½“çš„å‚ä¸ã€‚å—è®¿è€…ä¸€è‡´è®¤ä¸º Internships (å®ä¹ )ã€Industry partnerships (è¡Œä¸šåˆä½œ) å’Œé’ˆå¯¹æ€§æ”¯æŒæœºåˆ¶æ˜¯æå‡ AI æŠ€èƒ½çš„å…³é”®å› ç´ ã€‚ç ”ç©¶æœ€åå¼ºè°ƒï¼ŒåŠ å¼º University-industry collaboration (æ ¡ä¼åˆä½œ) å¹¶å»ºç«‹åŒ…å®¹æ€§æ²»ç†æ¡†æ¶ï¼Œå¯¹äºåˆ©ç”¨ AI ä¿ƒè¿›éæ´²å¤§é™†çš„å…¬å¹³ä¸å¯æŒç»­å‘å±•å…·æœ‰æ ¸å¿ƒæ„ä¹‰ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "16 pages, 4 figures, 1 table",
      "pdf_url": "https://arxiv.org/pdf/2512.05432v1",
      "published_date": "2025-12-05 05:14:23 UTC",
      "updated_date": "2025-12-05 05:14:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:08:54.602830+00:00"
    },
    {
      "arxiv_id": "2512.05430v1",
      "title": "ArtistMus: A Globally Diverse, Artist-Centric Benchmark for Retrieval-Augmented Music Question Answering",
      "title_zh": "ArtistMusï¼šé¢å‘æ£€ç´¢å¢å¼ºå‹éŸ³ä¹é—®ç­”çš„å…¨çƒå¤šæ ·åŒ–ã€ä»¥è‰ºæœ¯å®¶ä¸ºä¸­å¿ƒçš„è¯„ä¼°åŸºå‡†",
      "authors": [
        "Daeyong Kwon",
        "SeungHeon Doh",
        "Juhan Nam"
      ],
      "abstract": "Recent advances in large language models (LLMs) have transformed open-domain question answering, yet their effectiveness in music-related reasoning remains limited due to sparse music knowledge in pretraining data. While music information retrieval and computational musicology have explored structured and multimodal understanding, few resources support factual and contextual music question answering (MQA) grounded in artist metadata or historical context. We introduce MusWikiDB, a vector database of 3.2M passages from 144K music-related Wikipedia pages, and ArtistMus, a benchmark of 1,000 questions on 500 diverse artists with metadata such as genre, debut year, and topic. These resources enable systematic evaluation of retrieval-augmented generation (RAG) for MQA. Experiments show that RAG markedly improves factual accuracy; open-source models gain up to +56.8 percentage points (for example, Qwen3 8B improves from 35.0 to 91.8), approaching proprietary model performance. RAG-style fine-tuning further boosts both factual recall and contextual reasoning, improving results on both in-domain and out-of-domain benchmarks. MusWikiDB also yields approximately 6 percentage points higher accuracy and 40% faster retrieval than a general-purpose Wikipedia corpus. We release MusWikiDB and ArtistMus to advance research in music information retrieval and domain-specific question answering, establishing a foundation for retrieval-augmented reasoning in culturally rich domains such as music.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨éŸ³ä¹é¢†åŸŸé¢„è®­ç»ƒçŸ¥è¯†ç¨€ç–ä¸”æ¨ç†èƒ½åŠ›å—é™çš„é—®é¢˜ï¼Œæ¨å‡ºäº†MusWikiDBå’ŒArtistMusä¸¤ä¸ªæ ¸å¿ƒèµ„æºã€‚MusWikiDBæ˜¯ä¸€ä¸ªåŒ…å«320ä¸‡ä¸ªéŸ³ä¹ç›¸å…³æ®µè½çš„å‘é‡æ•°æ®åº“ï¼Œè€ŒArtistMusåˆ™æ˜¯æ¶µç›–500ä½å¤šå…ƒè‰ºæœ¯å®¶åŠå…¶å…ƒæ•°æ®çš„æ£€ç´¢å¢å¼ºéŸ³ä¹é—®ç­”(MQA)åŸºå‡†ã€‚å®éªŒè¯æ˜ï¼Œæ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)æŠ€æœ¯èƒ½æ˜¾è‘—æé«˜äº‹å®å‡†ç¡®åº¦ï¼Œä¾‹å¦‚Qwen3 8Bæ¨¡å‹åœ¨åº”ç”¨RAGåå‡†ç¡®ç‡æå‡äº†56.8ä¸ªç™¾åˆ†ç‚¹ã€‚ç ”ç©¶è¿˜å‘ç°ï¼ŒRAGé£æ ¼çš„å¾®è°ƒèƒ½è¿›ä¸€æ­¥å¼ºåŒ–æ¨¡å‹çš„äº‹å®å¬å›ä¸é€»è¾‘æ¨ç†èƒ½åŠ›ã€‚ç›¸æ¯”é€šç”¨è¯­æ–™åº“ï¼ŒMusWikiDBä¸ä»…å°†å‡†ç¡®ç‡æå‡äº†çº¦6ä¸ªç™¾åˆ†ç‚¹ï¼Œè¿˜ä½¿æ£€ç´¢é€Ÿåº¦åŠ å¿«äº†40%ã€‚è¯¥æˆæœä¸ºéŸ³ä¹åŠå…¶ä»–æ–‡åŒ–ç›¸å…³é¢†åŸŸçš„æ£€ç´¢å¢å¼ºæ¨ç†ç ”ç©¶æä¾›äº†é‡è¦åŸºçŸ³ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Submitted to LREC 2026. This work is an evolution of our earlier preprint arXiv:2507.23334",
      "pdf_url": "https://arxiv.org/pdf/2512.05430v1",
      "published_date": "2025-12-05 05:09:30 UTC",
      "updated_date": "2025-12-05 05:09:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:08:33.287984+00:00"
    },
    {
      "arxiv_id": "2512.11858v1",
      "title": "Adaptive Path Integral Diffusion: AdaPID",
      "title_zh": "è‡ªé€‚åº”è·¯å¾„ç§¯åˆ†æ‰©æ•£ï¼šAdaPID",
      "authors": [
        "Michael Chertkov",
        "Hamidreza Behjoo"
      ],
      "abstract": "Diffusion-based samplers -- Score Based Diffusions, Bridge Diffusions and Path Integral Diffusions -- match a target at terminal time, but the real leverage comes from choosing the schedule that governs the intermediate-time dynamics. We develop a path-wise schedule -- selection gramework for Harmonic PID with a time-varying stiffness, exploiting Piece-Wise-Constant(PWC) parametrizations and a simple hierarchical refinement. We introduce schedule-sensitive Quality-of-Sampling (QoS) diagnostics. Assuming a Gaussian-Mixture (GM) target, we retain closed-form Green functions' ration and numerically stable, Neural-Network free oracles for predicted-state maps and score. Experiments in 2D show that QoS driven PWC schedules consistently improve early-exit fidelity, tail accuracy, conditioning of the dynamics, and speciation (label-selection) timing at fixed integration budgets.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†AdaPIDï¼ˆAdaptive Path Integral Diffusionï¼‰ï¼Œä¸€ç§ä¸ºå…·æœ‰éšæ—¶é—´å˜åŒ–åˆšåº¦çš„Harmonic PIDè®¾è®¡çš„è·¯å¾„è°ƒåº¦é€‰æ‹©æ¡†æ¶ï¼Œæ—¨åœ¨ä¼˜åŒ–æ‰©æ•£é‡‡æ ·å™¨ä¸­æ§åˆ¶ä¸­é—´æ—¶é—´åŠ¨æ€çš„è°ƒåº¦æ–¹æ¡ˆã€‚è¯¥æ¡†æ¶é€šè¿‡åˆ©ç”¨åˆ†æ®µå¸¸æ•°ï¼ˆPiece-Wise-Constant, PWCï¼‰å‚æ•°åŒ–å’Œå±‚æ¬¡åŒ–ç»†åŒ–æŠ€æœ¯ï¼Œå¹¶å¼•å…¥äº†è°ƒåº¦æ•æ„Ÿçš„é‡‡æ ·è´¨é‡ï¼ˆQuality-of-Sampling, QoSï¼‰è¯Šæ–­æŒ‡æ ‡ã€‚åœ¨ç›®æ ‡ä¸ºé«˜æ–¯æ··åˆæ¨¡å‹ï¼ˆGaussian-Mixture, GMï¼‰çš„è®¾å®šä¸‹ï¼Œè¯¥æ–¹æ³•ä¿ç•™äº†é—­å¼çš„Green functionsï¼Œå¹¶å®ç°äº†æ— éœ€ç¥ç»ç½‘ç»œï¼ˆNeural-Network freeï¼‰çš„é¢„æµ‹çŠ¶æ€æ˜ å°„ä¸å¾—åˆ†é¢„æµ‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒQoSé©±åŠ¨çš„PWCè°ƒåº¦åœ¨2Dåœºæ™¯ä¸‹æ˜¾è‘—æå‡äº†æ—©æœŸé€€å‡ºä¿çœŸåº¦ã€å°¾éƒ¨å‡†ç¡®åº¦å’ŒåŠ¨åŠ›å­¦çš„è°ƒèŠ‚æ€§èƒ½ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•åœ¨å›ºå®šçš„ç§¯åˆ†é¢„ç®—ä¸‹ä¼˜åŒ–äº†ç‰©ç§å½¢æˆï¼ˆspeciationï¼‰çš„æ—¶é—´é€‰æ‹©ï¼ŒéªŒè¯äº†è‡ªé€‚åº”è°ƒåº¦åœ¨æå‡é‡‡æ ·æ•ˆç‡å’Œç²¾åº¦æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.LG",
        "cond-mat.stat-mech",
        "cs.AI",
        "eess.SY",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "51 pages, 17 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.11858v1",
      "published_date": "2025-12-05 04:57:00 UTC",
      "updated_date": "2025-12-05 04:57:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:08:37.108232+00:00"
    },
    {
      "arxiv_id": "2512.11857v1",
      "title": "TopicProphet: Prophesies on Temporal Topic Trends and Stocks",
      "title_zh": "TopicProphetï¼šæ—¶åºè¯é¢˜è¶‹åŠ¿ä¸è‚¡ç¥¨èµ°åŠ¿é¢„æµ‹",
      "authors": [
        "Olivia Kim"
      ],
      "abstract": "Stocks can't be predicted. Despite many hopes, this premise held itself true for many years due to the nature of quantitative stock data lacking causal logic along with rapid market changes hindering accumulation of significant data for training models. To undertake this matter, we propose a novel framework, TopicProphet, to analyze historical eras that share similar public sentiment trends and historical background. Our research deviates from previous studies that identified impacts of keywords and sentiments - we expand on that method by a sequence of topic modeling, temporal analysis, breakpoint detection and segment optimization to detect the optimal time period for training. This results in improving predictions by providing the model with nuanced patterns that occur from that era's socioeconomic and political status while also resolving the shortage of pertinent stock data to train on. Through extensive analysis, we conclude that TopicProphet produces improved outcomes compared to the state-of-the-art methods in capturing the optimal training data for forecasting financial percentage changes.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† TopicProphet æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³è‚¡ç¥¨é¢„æµ‹ä¸­å› ç¼ºä¹å› æœé€»è¾‘å’Œå¸‚åœºå¿«é€Ÿå˜åŒ–è€Œå¯¼è‡´çš„è®­ç»ƒæ•°æ®ç§¯ç´¯éš¾é¢˜ã€‚ä¸ä»¥å¾€ä»…å…³æ³¨å…³é”®è¯å’Œæƒ…ç»ªå½±å“çš„ç ”ç©¶ä¸åŒï¼ŒTopicProphet é€šè¿‡é›†æˆä¸»é¢˜å»ºæ¨¡ (Topic Modeling)ã€æ—¶é—´åˆ†æ (Temporal Analysis)ã€æ–­ç‚¹æ£€æµ‹ (Breakpoint Detection) å’Œç‰‡æ®µä¼˜åŒ– (Segment Optimization) ç­‰æŠ€æœ¯ï¼Œè¯†åˆ«å¹¶æå–ä¸å½“å‰ç¤¾ä¼šèƒŒæ™¯å’Œæƒ…ç»ªè¶‹åŠ¿ç›¸ä¼¼çš„æœ€ä½³å†å²è®­ç»ƒæ—¶æ®µã€‚è¯¥æ–¹æ³•ä¸ä»…èƒ½å¤Ÿæ•æ‰ç‰¹å®šæ—¶ä»£çš„ç¤¾ä¼šç»æµä¸æ”¿æ²»çŠ¶å†µæ‰€äº§ç”Ÿçš„ç»†å¾®æ¨¡å¼ï¼Œè¿˜æ˜¾è‘—ç¼“è§£äº†ç›¸å…³è‚¡ç¥¨æ•°æ®çš„çŸ­ç¼ºé—®é¢˜ã€‚å®éªŒåˆ†æè¡¨æ˜ï¼ŒTopicProphet åœ¨æ•æ‰é¢„æµ‹é‡‘èç™¾åˆ†æ¯”å˜åŒ–æ‰€éœ€çš„æœ€ä½³è®­ç»ƒæ•°æ®æ–¹é¢ï¼Œå…¶è¡¨ç°ä¼˜äºç°æœ‰çš„å…ˆè¿›æ–¹æ³• (State-of-the-art methods)ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.11857v1",
      "published_date": "2025-12-05 04:33:08 UTC",
      "updated_date": "2025-12-05 04:33:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:09:08.411790+00:00"
    },
    {
      "arxiv_id": "2512.05415v1",
      "title": "Moving object detection from multi-depth images with an attention-enhanced CNN",
      "title_zh": "åŸºäºæ³¨æ„åŠ›å¢å¼ºå‹ CNN çš„å¤šæ·±åº¦å›¾åƒè¿åŠ¨ç›®æ ‡æ£€æµ‹",
      "authors": [
        "Masato Shibukawa",
        "Fumi Yoshida",
        "Toshifumi Yanagisawa",
        "Takashi Ito",
        "Hirohisa Kurosaki",
        "Makoto Yoshikawa",
        "Kohki Kamiya",
        "Ji-an Jiang",
        "Wesley Fraser",
        "JJ Kavelaars",
        "Susan Benecchi",
        "Anne Verbiscer",
        "Akira Hatakeyama",
        "Hosei O",
        "Naoya Ozaki"
      ],
      "abstract": "One of the greatest challenges for detecting moving objects in the solar system from wide-field survey data is determining whether a signal indicates a true object or is due to some other source, like noise. Object verification has relied heavily on human eyes, which usually results in significant labor costs. In order to address this limitation and reduce the reliance on manual intervention, we propose a multi-input convolutional neural network integrated with a convolutional block attention module. This method is specifically tailored to enhance the moving object detection system that we have developed and used previously. The current method introduces two innovations. This first one is a multi-input architecture that processes multiple stacked images simultaneously. The second is the incorporation of the convolutional block attention module which enables the model to focus on essential features in both spatial and channel dimensions. These advancements facilitate efficient learning from multiple inputs, leading to more robust detection of moving objects. The performance of the model is evaluated on a dataset consisting of approximately 2,000 observational images. We achieved an accuracy of nearly 99% with AUC (an Area Under the Curve) of >0.99. These metrics indicate that the proposed model achieves excellent classification performance. By adjusting the threshold for object detection, the new model reduces the human workload by more than 99% compared to manual verification.",
      "tldr_zh": "é’ˆå¯¹å¤ªé˜³ç³»å¹¿åŸŸå·¡å¤©æ•°æ®ä¸­ç§»åŠ¨å¤©ä½“æ£€æµ‹é¢ä¸´çš„å™ªå£°å¹²æ‰°åŠäººå·¥éªŒè¯æˆæœ¬é«˜æ˜‚çš„é—®é¢˜ï¼Œè¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§é›†æˆäº†æ³¨æ„åŠ›æœºåˆ¶çš„å·ç§¯ç¥ç»ç½‘ç»œ(CNN)æ¨¡å‹ã€‚è¯¥æ–¹æ³•çš„æ ¸å¿ƒåˆ›æ–°åœ¨äºé‡‡ç”¨å¤šè¾“å…¥æ¶æ„åŒæ—¶å¤„ç†å¤šå¼ å †å å›¾åƒï¼Œå¹¶å¼•å…¥å·ç§¯å—æ³¨æ„åŠ›æ¨¡å—(Convolutional Block Attention Module, CBAM)ä»¥åœ¨ç©ºé—´å’Œé€šé“ç»´åº¦ä¸Šèšç„¦å…³é”®ç‰¹å¾ã€‚åœ¨åŒ…å«çº¦2,000å¹…è§‚æµ‹å›¾åƒçš„æ•°æ®é›†ä¸Šï¼Œè¯¥æ¨¡å‹å®ç°äº†æ¥è¿‘99%çš„å‡†ç¡®ç‡å’Œè¶…è¿‡0.99çš„æ›²çº¿ä¸‹é¢ç§¯(AUC)ï¼Œå±•ç°å‡ºå“è¶Šçš„åˆ†ç±»æ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨ä¿è¯æ£€æµ‹ç²¾åº¦çš„åŒæ—¶ï¼Œç›¸æ¯”ä¼ ç»Ÿäººå·¥éªŒè¯æ–¹å¼å¯å‡å°‘è¶…è¿‡99%çš„äººåŠ›å·¥ä½œé‡ï¼Œæ˜¾è‘—æå‡äº†å¤§è§„æ¨¡å¤©æ–‡å·¡å¤©ä»»åŠ¡çš„è‡ªåŠ¨åŒ–æ°´å¹³ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "14 pages, 22 figures, submitted to PASJ",
      "pdf_url": "https://arxiv.org/pdf/2512.05415v1",
      "published_date": "2025-12-05 04:29:37 UTC",
      "updated_date": "2025-12-05 04:29:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:09:09.621858+00:00"
    },
    {
      "arxiv_id": "2512.06042v1",
      "title": "Auto-SPT: Automating Semantic Preserving Transformations for Code",
      "title_zh": "Auto-SPTï¼šä»£ç è¯­ä¹‰ä¿æŒå˜æ¢çš„è‡ªåŠ¨åŒ–",
      "authors": [
        "Ashish Hooda",
        "Mihai Christodorescu",
        "Chuangang Ren",
        "Aaron Wilson",
        "Kassem Fawaz",
        "Somesh Jha"
      ],
      "abstract": "Machine learning (ML) models for code clone detection determine whether two pieces of code are semantically equivalent, which in turn is a key building block for software-engineering tasks like refactoring and security tasks like vulnerability and malware detection. While these models are predominantly trained on clean, structured code datasets, real-world code often undergoes a variety of semantic-preserving transformations, including refactoring, minification, automated formatting, and compiler optimizations. To address this critical gap between training and test data, we propose Auto-SPT, a novel framework to automatically construct synthetic-data generators for code. Auto-SPT is designed to produce Semantic Preserving Transformations (SPTs) that alter a program's syntactic structure while preserving its functionality and is instantiated on top of Large Language Models (LLMs). In particular, we use LLMs to craft a diverse set of SPTs, generate strong implementations for these SPTs, and compose them to result into strong transformations. Our formal analysis shows that the diversity of SPTs impacts the strength of their composition. We then empirically demonstrate that Auto-SPT generates more diverse SPTs than existing approaches and these SPTs significantly drop the performance of state-of-the-art code clone detectors. Further experiments show Auto-SPT can be used to enhance code datasets for training, to produce code-clone detection models that are robust to real-world, adversarial code transformations.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Auto-SPT æ¡†æ¶ï¼Œæ—¨åœ¨å¼¥åˆä»£ç å…‹éš†æ£€æµ‹ï¼ˆCode Clone Detectionï¼‰æ¨¡å‹åœ¨å¹²å‡€è®­ç»ƒæ•°æ®ä¸åŒ…å«å¤æ‚è¯­ä¹‰ä¿æŒè½¬æ¢ï¼ˆSemantic Preserving Transformations, SPTsï¼‰çš„ç°å®ä»£ç ä¹‹é—´çš„æ€§èƒ½å·®è·ã€‚Auto-SPT åŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è‡ªåŠ¨æ„å»ºåˆæˆæ•°æ®ç”Ÿæˆå™¨ï¼Œé€šè¿‡è®¾è®¡ã€å®ç°å¹¶ç»„åˆå¤šæ ·åŒ–çš„ SPTsï¼Œåœ¨æ”¹å˜ç¨‹åºè¯­æ³•ç»“æ„çš„åŒæ—¶ä¿ç•™å…¶æ ¸å¿ƒåŠŸèƒ½ã€‚å½¢å¼åŒ–åˆ†ææŒ‡å‡ºï¼ŒSPTs çš„å¤šæ ·æ€§æ˜¯å†³å®šè½¬æ¢ç»„åˆå¼ºåº¦çš„å…³é”®å› ç´ ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒAuto-SPT ç”Ÿæˆçš„è½¬æ¢æ¯”ç°æœ‰æ–¹æ³•æ›´å…·å¤šæ ·æ€§ï¼Œèƒ½å¤Ÿæ˜¾è‘—é™ä½å½“å‰æœ€å…ˆè¿›æ£€æµ‹æ¨¡å‹çš„å‡†ç¡®ç‡ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶è¿˜èƒ½æœ‰æ•ˆå¢å¼ºè®­ç»ƒæ•°æ®é›†ï¼Œæå‡æ¨¡å‹åœ¨åº”å¯¹ç°å®ä¸–ç•ŒåŠå¯¹æŠ—æ€§ä»£ç è½¬æ¢æ—¶çš„é²æ£’æ€§ï¼ˆRobustnessï¼‰ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.06042v1",
      "published_date": "2025-12-05 04:11:44 UTC",
      "updated_date": "2025-12-05 04:11:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:09:12.129174+00:00"
    },
    {
      "arxiv_id": "2512.05411v1",
      "title": "A Systematic Framework for Enterprise Knowledge Retrieval: Leveraging LLM-Generated Metadata to Enhance RAG Systems",
      "title_zh": "ä¼ä¸šçŸ¥è¯†æ£€ç´¢ç³»ç»Ÿæ€§æ¡†æ¶ï¼šåˆ©ç”¨ LLM ç”Ÿæˆçš„å…ƒæ•°æ®å¢å¼º RAG ç³»ç»Ÿ",
      "authors": [
        "Pranav Pushkar Mishra",
        "Kranti Prakash Yeole",
        "Ramyashree Keshavamurthy",
        "Mokshit Bharat Surana",
        "Fatemeh Sarayloo"
      ],
      "abstract": "In enterprise settings, efficiently retrieving relevant information from large and complex knowledge bases is essential for operational productivity and informed decision-making. This research presents a systematic framework for metadata enrichment using large language models (LLMs) to enhance document retrieval in Retrieval-Augmented Generation (RAG) systems. Our approach employs a comprehensive, structured pipeline that dynamically generates meaningful metadata for document segments, substantially improving their semantic representations and retrieval accuracy. Through extensive experiments, we compare three chunking strategies-semantic, recursive, and naive-and evaluate their effectiveness when combined with advanced embedding techniques. The results demonstrate that metadata-enriched approaches consistently outperform content-only baselines, with recursive chunking paired with TF-IDF weighted embeddings yielding an 82.5% precision rate compared to 73.3% for semantic content-only approaches. The naive chunking strategy with prefix-fusion achieved the highest Hit Rate@10 of 0.925. Our evaluation employs cross-encoder reranking for ground truth generation, enabling rigorous assessment via Hit Rate and Metadata Consistency metrics. These findings confirm that metadata enrichment enhances vector clustering quality while reducing retrieval latency, making it a key optimization for RAG systems across knowledge domains. This work offers practical insights for deploying high-performance, scalable document retrieval solutions in enterprise settings, demonstrating that metadata enrichment is a powerful approach for enhancing RAG effectiveness.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªé’ˆå¯¹ä¼ä¸šçŸ¥è¯†æ£€ç´¢çš„ç³»ç»ŸåŒ–æ¡†æ¶ï¼Œæ—¨åœ¨åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ (LLMs) ç”Ÿæˆçš„å…ƒæ•°æ® (Metadata) å¢å¼ºæ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG) ç³»ç»Ÿçš„æ€§èƒ½ã€‚è¯¥æ–¹æ³•é€šè¿‡ç»“æ„åŒ–çš„æµæ°´çº¿ä¸ºæ–‡æ¡£åˆ†æ®µåŠ¨æ€ç”Ÿæˆå…ƒæ•°æ®ï¼Œæ˜¾è‘—æå‡äº†åˆ†æ®µçš„è¯­ä¹‰è¡¨ç¤ºèƒ½åŠ›å’Œæ£€ç´¢å‡†ç¡®åº¦ã€‚ç ”ç©¶è¯¦ç»†å¯¹æ¯”äº†è¯­ä¹‰ (Semantic)ã€é€’å½’ (Recursive) å’Œæœ´ç´  (Naive) ä¸‰ç§åˆ‡ç‰‡ç­–ç•¥ï¼Œå¹¶ç»“åˆå…ˆè¿›çš„åµŒå…¥æŠ€æœ¯è¿›è¡Œäº†è¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå…ƒæ•°æ®å¢å¼ºæ–¹æ¡ˆä¸€è‡´ä¼˜äºä»…ä¾èµ–å†…å®¹çš„åŸºå‡†æ¨¡å‹ï¼Œå…¶ä¸­é€’å½’åˆ‡ç‰‡é…åˆ TF-IDF åŠ æƒåµŒå…¥è¾¾åˆ°äº† 82.5% çš„å‡†ç¡®ç‡ï¼Œè€Œå¸¦æœ‰å‰ç¼€èåˆ (Prefix-fusion) çš„æœ´ç´ åˆ‡ç‰‡ç­–ç•¥å®ç°äº† 0.925 çš„æœ€é«˜ Hit Rate@10ã€‚ç ”ç©¶è¿›ä¸€æ­¥è¯å®ï¼Œå…ƒæ•°æ®å¢å¼ºåœ¨ä¼˜åŒ–å‘é‡èšç±»è´¨é‡çš„åŒæ—¶èƒ½æœ‰æ•ˆé™ä½æ£€ç´¢å»¶è¿Ÿï¼Œä¸ºä¼ä¸šçº§å¤§è§„æ¨¡ã€é«˜æ€§èƒ½æ–‡æ¡£æ£€ç´¢æ–¹æ¡ˆçš„éƒ¨ç½²æä¾›äº†é‡è¦çš„å®è·µæŒ‡å¯¼ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "7 pages, 3 figures, 3 tables",
      "pdf_url": "https://arxiv.org/pdf/2512.05411v1",
      "published_date": "2025-12-05 04:05:06 UTC",
      "updated_date": "2025-12-05 04:05:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:09:18.745587+00:00"
    },
    {
      "arxiv_id": "2512.11856v1",
      "title": "GCoDE: Efficient Device-Edge Co-Inference for GNNs via Architecture-Mapping Co-Search",
      "title_zh": "GCoDEï¼šåŸºäºæ¶æ„-æ˜ å°„ååŒæœç´¢çš„å›¾ç¥ç»ç½‘ç»œé«˜æ•ˆç«¯-è¾¹ååŒæ¨ç†",
      "authors": [
        "Ao Zhou",
        "Jianlei Yang",
        "Tong Qiao",
        "Yingjie Qi",
        "Zhi Yang",
        "Weisheng Zhao",
        "Chunming Hu"
      ],
      "abstract": "Graph Neural Networks (GNNs) have emerged as the state-of-the-art graph learning method. However, achieving efficient GNN inference on edge devices poses significant challenges, limiting their application in real-world edge scenarios. This is due to the high computational cost of GNNs and limited hardware resources on edge devices, which prevent GNN inference from meeting real-time and energy requirements. As an emerging paradigm, device-edge co-inference shows potential for improving inference efficiency and reducing energy consumption on edge devices. Despite its potential, research on GNN device-edge co-inference remains scarce, and our findings show that traditional model partitioning methods are ineffective for GNNs. To address this, we propose GCoDE, the first automatic framework for GNN architecture-mapping Co-design and deployment on Device-Edge hierarchies. By abstracting the device communication process into an explicit operation, GCoDE fuses the architecture and mapping scheme in a unified design space for joint optimization. Additionally, GCoDE's system performance awareness enables effective evaluation of architecture efficiency across diverse heterogeneous systems. By analyzing the energy consumption of various GNN operations, GCoDE introduces an energy prediction method that improves energy assessment accuracy and identifies energy-efficient solutions. Using a constraint-based random search strategy, GCoDE identifies the optimal solution in 1.5 hours, balancing accuracy and efficiency. Moreover, the integrated co-inference engine in GCoDE enables efficient deployment and execution of GNN co-inference. Experimental results show that GCoDE can achieve up to 44.9x speedup and 98.2% energy reduction compared to existing approaches across diverse applications and system configurations.",
      "tldr_zh": "æœ¬ç ”ç©¶æå‡ºäº†GCoDEï¼Œè¿™æ˜¯é¦–ä¸ªé’ˆå¯¹Graph Neural Networks (GNNs) åœ¨ Device-Edge å±‚çº§ç»“æ„ä¸Šè¿›è¡Œæ¶æ„-æ˜ å°„ååŒè®¾è®¡(Co-design)ä¸éƒ¨ç½²çš„è‡ªåŠ¨åŒ–æ¡†æ¶ã€‚è¯¥ç ”ç©¶æ—¨åœ¨è§£å†³ GNN åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šå› é«˜è®¡ç®—å¼€é”€å’Œèµ„æºå—é™è€Œéš¾ä»¥æ»¡è¶³å®æ—¶æ€§ä¸èƒ½è€—è¦æ±‚çš„é—®é¢˜ï¼Œå¹¶æŒ‡å‡ºä¼ ç»Ÿæ¨¡å‹åˆ†åŒºæ–¹æ³•å¯¹ GNN å¹¶ä¸å¥æ•ˆã€‚GCoDE å°†è®¾å¤‡é—´çš„é€šä¿¡è¿‡ç¨‹æŠ½è±¡ä¸ºæ˜¾å¼æ“ä½œï¼Œä»è€Œå°† GNN æ¶æ„ä¸æ˜ å°„æ–¹æ¡ˆèåˆåœ¨ç»Ÿä¸€çš„è®¾è®¡ç©ºé—´å†…è¿›è¡Œè”åˆä¼˜åŒ–ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶å¼•å…¥äº†é«˜ç²¾åº¦çš„èƒ½é‡é¢„æµ‹æ–¹æ³•ä»¥è¯†åˆ«ä½åŠŸè€—è§£å†³æ–¹æ¡ˆï¼Œå¹¶åˆ©ç”¨åŸºäºçº¦æŸçš„éšæœºæœç´¢ç­–ç•¥åœ¨1.5å°æ—¶å†…é”å®šæœ€ä¼˜æ–¹æ¡ˆã€‚å®éªŒè¡¨æ˜ï¼Œåœ¨å¤šç§åº”ç”¨å’Œç³»ç»Ÿé…ç½®ä¸‹ï¼ŒGCoDE ç›¸æ¯”ç°æœ‰æ–¹æ³•å®ç°äº†é«˜è¾¾44.9å€çš„æ¨ç†åŠ é€Ÿå’Œ98.2%çš„èƒ½è€—å‰Šå‡ï¼Œæ˜¾è‘—æå‡äº† GNN åœ¨è¾¹ç¼˜åœºæ™¯çš„éƒ¨ç½²æ•ˆç‡ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "accepted by IEEE Transactions on Computers",
      "pdf_url": "https://arxiv.org/pdf/2512.11856v1",
      "published_date": "2025-12-05 04:02:53 UTC",
      "updated_date": "2025-12-05 04:02:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:09:21.449219+00:00"
    },
    {
      "arxiv_id": "2512.05402v1",
      "title": "Smart Timing for Mining: A Deep Learning Framework for Bitcoin Hardware ROI Prediction",
      "title_zh": "æ™ºé€‰æŒ–çŸ¿æ—¶æœºï¼šä¸€ç§ç”¨äºæ¯”ç‰¹å¸ç¡¬ä»¶æŠ•èµ„å›æŠ¥ç‡é¢„æµ‹çš„æ·±åº¦å­¦ä¹ æ¡†æ¶",
      "authors": [
        "Sithumi Wickramasinghe",
        "Bikramjit Das",
        "Dorien Herremans"
      ],
      "abstract": "Bitcoin mining hardware acquisition requires strategic timing due to volatile markets, rapid technological obsolescence, and protocol-driven revenue cycles. Despite mining's evolution into a capital-intensive industry, there is little guidance on when to purchase new Application-Specific Integrated Circuit (ASIC) hardware, and no prior computational frameworks address this decision problem. We address this gap by formulating hardware acquisition as a time series classification task, predicting whether purchasing ASIC machines yields profitable (Return on Investment (ROI) >= 1), marginal (0 < ROI < 1), or unprofitable (ROI <= 0) returns within one year. We propose MineROI-Net, an open source Transformer-based architecture designed to capture multi-scale temporal patterns in mining profitability. Evaluated on data from 20 ASIC miners released between 2015 and 2024 across diverse market regimes, MineROI-Net outperforms LSTM-based and TSLANet baselines, achieving 83.7% accuracy and 83.1% macro F1-score. The model demonstrates strong economic relevance, achieving 93.6% precision in detecting unprofitable periods and 98.5% precision for profitable ones, while avoiding misclassification of profitable scenarios as unprofitable and vice versa. These results indicate that MineROI-Net offers a practical, data-driven tool for timing mining hardware acquisitions, potentially reducing financial risk in capital-intensive mining operations. The model is available through: https://github.com/AMAAI-Lab/MineROI-Net.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ¯”ç‰¹å¸æŒ–çŸ¿ç¡¬ä»¶è´­ç½®ä¸­çš„æˆ˜ç•¥æ—¶æœºé€‰æ‹©é—®é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªæ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å› å¸‚åœºæ³¢åŠ¨å’ŒæŠ€æœ¯æ·˜æ±°å¿«å¯¼è‡´çš„æŠ•èµ„å†³ç­–éš¾é¢˜ã€‚ç ”ç©¶å°†ç¡¬ä»¶è´­ç½®ä»»åŠ¡è¡¨è¿°ä¸ºæ—¶é—´åºåˆ—åˆ†ç±»é—®é¢˜ï¼Œç”¨äºé¢„æµ‹åœ¨ä¸€å¹´å†…è´­ä¹° ASIC æœºå™¨çš„æŠ•èµ„å›æŠ¥ç‡ (ROI) è¡¨ç°ã€‚ä½œè€…ä¸ºæ­¤å¼€å‘äº†åä¸º MineROI-Net çš„å¼€æº Transformer æ¶æ„ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆæ•è·æŒ–çŸ¿ç›ˆåˆ©ä¸­çš„å¤šå°ºåº¦æ—¶é—´æ¨¡å¼ã€‚å®éªŒæ•°æ®æ¶µç›–äº† 2015 å¹´è‡³ 2024 å¹´é—´çš„ 20 ç§ ASIC çŸ¿æœºï¼Œç»“æœæ˜¾ç¤º MineROI-Net åœ¨å‡†ç¡®ç‡å’Œå® F1 åˆ†æ•° (macro F1-score) ä¸Šå‡æ˜¾è‘—ä¼˜äº LSTM å’Œ TSLANet ç­‰åŸºå‡†æ¨¡å‹ã€‚è¯¥æ¨¡å‹åœ¨è¯†åˆ«ç›ˆåˆ©å’ŒäºæŸæ—¶æœŸæ–¹é¢è¡¨ç°å‡ºæé«˜çš„ç²¾ç¡®åº¦ï¼Œåˆ†åˆ«ä¸º 98.5% å’Œ 93.6%ï¼Œä¸ºå‡å°‘èµ„æœ¬å¯†é›†å‹æŒ–çŸ¿ä¸šåŠ¡çš„è´¢åŠ¡é£é™©æä¾›äº†å®ç”¨çš„æ•°æ®é©±åŠ¨å·¥å…·ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.05402v1",
      "published_date": "2025-12-05 03:47:13 UTC",
      "updated_date": "2025-12-05 03:47:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:09:23.814178+00:00"
    },
    {
      "arxiv_id": "2512.13703v1",
      "title": "Safe2Harm: Semantic Isomorphism Attacks for Jailbreaking Large Language Models",
      "title_zh": "Safe2Harmï¼šé’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹è¶Šç‹±çš„è¯­ä¹‰åŒæ„æ”»å‡»",
      "authors": [
        "Fan Yang"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated exceptional performance across various tasks, but their security vulnerabilities can be exploited by attackers to generate harmful content, causing adverse impacts across various societal domains. Most existing jailbreak methods revolve around Prompt Engineering or adversarial optimization, yet we identify a previously overlooked phenomenon: many harmful scenarios are highly consistent with legitimate ones in terms of underlying principles. Based on this finding, this paper proposes the Safe2Harm Semantic Isomorphism Attack method, which achieves efficient jailbreaking through four stages: first, rewrite the harmful question into a semantically safe question with similar underlying principles; second, extract the thematic mapping relationship between the two; third, let the LLM generate a detailed response targeting the safe question; finally, reversely rewrite the safe response based on the thematic mapping relationship to obtain harmful output. Experiments on 7 mainstream LLMs and three types of benchmark datasets show that Safe2Harm exhibits strong jailbreaking capability, and its overall performance is superior to existing methods. Additionally, we construct a challenging harmful content evaluation dataset containing 358 samples and evaluate the effectiveness of existing harmful detection methods, which can be deployed for LLM input-output filtering to enable defense.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é¢ä¸´çš„å®‰å…¨æ¼æ´åŠè¶Šç‹±æ”»å‡»é£é™©ï¼Œæ­ç¤ºäº†æœ‰å®³åœºæ™¯ä¸åˆæ³•åœºæ™¯åœ¨åº•å±‚é€»è¾‘ä¸Šå…·æœ‰é«˜åº¦ä¸€è‡´æ€§è¿™ä¸€è¢«å¿½è§†çš„ç°è±¡ã€‚åŸºäºæ­¤å‘ç°ï¼Œè®ºæ–‡æå‡ºäº† Safe2Harm è¯­ä¹‰åŒæ„æ”»å‡»ï¼ˆSemantic Isomorphism Attacksï¼‰æ–¹æ³•ï¼Œé€šè¿‡å››ä¸ªé˜¶æ®µå®ç°é«˜æ•ˆè¶Šç‹±ã€‚è¯¥æ–¹æ³•é¦–å…ˆå°†æœ‰å®³é—®é¢˜é‡å†™ä¸ºé€»è¾‘ç›¸ä¼¼ä½†åœ¨è¯­ä¹‰ä¸Šå®‰å…¨çš„åˆæ³•é—®é¢˜ï¼Œå¹¶æå–ä¸¤è€…ä¹‹é—´çš„ä¸»é¢˜æ˜ å°„å…³ç³»ï¼ˆThematic Mappingï¼‰ï¼›éšåå¼•å¯¼æ¨¡å‹å¯¹å®‰å…¨é—®é¢˜ç”Ÿæˆè¯¦ç»†å›ç­”ï¼Œæœ€åæ ¹æ®æ˜ å°„å…³ç³»å°†è¾“å‡ºç»“æœè¿›è¡Œé€†å‘æ”¹å†™ä»¥è·å–æœ‰å®³å†…å®¹ã€‚åœ¨ 7 ç§ä¸»æµ LLMs å’Œä¸‰ç±»åŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒSafe2Harm è¡¨ç°å‡ºæå¼ºçš„è¶Šç‹±èƒ½åŠ›ï¼Œæ€§èƒ½ä¼˜äºç°æœ‰æ–¹æ³•ã€‚æ­¤å¤–ï¼Œç ”ç©¶å›¢é˜Ÿè¿˜æ„å»ºäº†ä¸€ä¸ªåŒ…å« 358 ä¸ªæ ·æœ¬çš„é«˜éš¾åº¦æœ‰å®³å†…å®¹è¯„ä¼°æ•°æ®é›†ï¼Œå¹¶è¯„ä¼°äº†ç°æœ‰æ£€æµ‹æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œä¸ºå¤§æ¨¡å‹é˜²å¾¡æœºåˆ¶çš„éƒ¨ç½²æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.13703v1",
      "published_date": "2025-12-05 03:44:26 UTC",
      "updated_date": "2025-12-05 03:44:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:09:24.494798+00:00"
    },
    {
      "arxiv_id": "2512.05397v2",
      "title": "Simulating Life Paths with Digital Twins: AI-Generated Future Selves Influence Decision-Making and Expand Human Choice",
      "title_zh": "æ•°å­—å­ªç”Ÿé©±åŠ¨çš„ç”Ÿå‘½è·¯å¾„æ¨¡æ‹Ÿï¼šAI ç”Ÿæˆçš„æœªæ¥è‡ªæˆ‘å¯¹å†³ç­–çš„å½±å“åŠå…¶å¯¹äººç±»é€‰æ‹©çš„æ‹“å±•",
      "authors": [
        "Rachel Poonsiriwong",
        "Chayapatr Archiwaranguprok",
        "Constanze Albrecht",
        "Peggy Yin",
        "Nattavudh Powdthavee",
        "Hal Hershfield",
        "Monchai Lertsutthiwong",
        "Kavin Winson",
        "Pat Pataranutaporn"
      ],
      "abstract": "Major life transitions demand high-stakes decisions, yet people often struggle to imagine how their future selves will live with the consequences. To support this limited capacity for mental time travel, we introduce AI-enabled digital twins that have ``lived through'' simulated life scenarios. Rather than predicting optimal outcomes, these simulations extend prospective cognition by making alternative futures vivid enough to support deliberation without assuming which path is best. We evaluate this idea in a randomized controlled study (N=192) using multimodal synthesis - facial age progression, voice cloning, and large language model dialogue - to create personalized avatars representing participants 30 years forward. Young adults 18 to 28 years old described pending binary decisions and were assigned to guided imagination or one of four avatar conditions: single-option, balanced dual-option, or expanded three-option with a system-generated novel alternative. Results showed asymmetric effects: single-sided avatars increased shifts toward the presented option, while balanced presentation produced movement toward both. Introducing a system-generated third option increased adoption of this new alternative compared to control, suggesting that AI-generated future selves can expand choice by surfacing paths that might otherwise go unnoticed. Participants rated evaluative reasoning and eudaimonic meaning-making as more important than emotional or visual vividness. Perceived persuasiveness and baseline agency predicted decision change. These findings advance understanding of AI-mediated episodic prospection and raise questions about autonomy in AI-augmented decisions.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼•å…¥äº†åŸºäºAIçš„æ•°å­—å­ªç”Ÿ(Digital Twins)æŠ€æœ¯ï¼Œæ—¨åœ¨é€šè¿‡æ¨¡æ‹Ÿæœªæ¥ç”Ÿæ´»åœºæ™¯æ¥æ”¯æŒäººç±»åœ¨é¢ä¸´é‡å¤§äººç”ŸæŠ‰æ‹©æ—¶çš„è·¨æ—¶ç©ºå¿ƒç†æ—…è¡Œ(Mental Time Travel)ã€‚ç ”ç©¶é€šè¿‡å¤šæ¨¡æ€åˆæˆæŠ€æœ¯ï¼Œç»“åˆé¢éƒ¨è€åŒ–æ¨¡æ‹Ÿ(Facial Age Progression)ã€å£°éŸ³å…‹éš†(Voice Cloning)å’Œå¤§å‹è¯­è¨€æ¨¡å‹(LLM)å¯¹è¯ï¼Œä¸ºå‚ä¸è€…åˆ›å»ºäº†å‘ˆç°30å¹´åçŠ¶æ€çš„ä¸ªæ€§åŒ–è™šæ‹ŸåŒ–èº«ã€‚é€šè¿‡å¯¹192åå¹´è½»å—è¯•è€…çš„éšæœºå¯¹ç…§å®éªŒï¼Œç ”ç©¶å‘ç°å•ä¾§åŒ–èº«ä¼šå¼•å¯¼å†³ç­–å€¾å‘ï¼Œè€Œå¹³è¡¡çš„å¤šé€‰é¡¹å‘ˆç°åˆ™èƒ½æ˜¾è‘—ä¿ƒè¿›å®¡æ…æ€è€ƒã€‚ç ”ç©¶ç‰¹åˆ«æŒ‡å‡ºï¼Œå¼•å…¥ç³»ç»Ÿç”Ÿæˆçš„ç¬¬ä¸‰ç§æ–¹æ¡ˆèƒ½æœ‰æ•ˆå¸®åŠ©å‚ä¸è€…å‘ç°åŸæœ¬è¢«å¿½è§†çš„è·¯å¾„ï¼Œä»è€Œæ‰©å±•äº†äººç±»çš„é€‰æ‹©ç©ºé—´ã€‚ç»“æœè¡¨æ˜ï¼Œç›¸æ¯”äºè§†è§‰æˆ–æƒ…æ„Ÿçš„ç”ŸåŠ¨æ€§ï¼Œå‚ä¸è€…æ›´çœ‹é‡è¯„ä¼°æ€§æ¨ç†å’Œå®ç°è®ºæ„ä¹‰(Eudaimonic Meaning-making)çš„æ„å»ºã€‚è¿™é¡¹å·¥ä½œä¸ä»…æ¨è¿›äº†å¯¹AIä¸­ä»‹çš„æƒ…æ™¯å‰ç»(Episodic Prospection)çš„ç†è§£ï¼Œä¹Ÿä¸ºAIè¾…åŠ©å†³ç­–ä¸­çš„è‡ªä¸»æ€§é—®é¢˜æä¾›äº†æ–°çš„æ€è€ƒã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.05397v2",
      "published_date": "2025-12-05 03:30:44 UTC",
      "updated_date": "2025-12-08 04:59:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:09:37.688751+00:00"
    },
    {
      "arxiv_id": "2512.11855v1",
      "title": "Achieving Approximate Symmetry Is Exponentially Easier than Exact Symmetry",
      "title_zh": "å®ç°è¿‘ä¼¼å¯¹ç§°æ€§æ¯”ç²¾ç¡®å¯¹ç§°æ€§å‘ˆæŒ‡æ•°çº§æ›´å®¹æ˜“",
      "authors": [
        "Behrooz Tahmasebi",
        "Melanie Weber"
      ],
      "abstract": "Enforcing exact symmetry in machine learning models often yields significant gains in scientific applications, serving as a powerful inductive bias. However, recent work suggests that relying on approximate symmetry can offer greater flexibility and robustness. Despite promising empirical evidence, there has been little theoretical understanding, and in particular, a direct comparison between exact and approximate symmetry is missing from the literature. In this paper, we initiate this study by asking: What is the cost of enforcing exact versus approximate symmetry? To address this question, we introduce averaging complexity, a framework for quantifying the cost of enforcing symmetry via averaging. Our main result is an exponential separation: under standard conditions, achieving exact symmetry requires linear averaging complexity, whereas approximate symmetry can be attained with only logarithmic averaging complexity. To the best of our knowledge, this provides the first theoretical separation of these two cases, formally justifying why approximate symmetry may be preferable in practice. Beyond this, our tools and techniques may be of independent interest for the broader study of symmetries in machine learning.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨æœºå™¨å­¦ä¹ æ¨¡å‹ä¸­å¼ºåˆ¶å®æ–½ç²¾ç¡®å¯¹ç§°æ€§(Exact Symmetry)ä¸è¿‘ä¼¼å¯¹ç§°æ€§(Approximate Symmetry)çš„æˆæœ¬å·®å¼‚ã€‚ä¸ºäº†å¡«è¡¥ç†è®ºç ”ç©¶çš„ç©ºç™½ï¼Œä½œè€…å¼•å…¥äº†å¹³å‡å¤æ‚åº¦(Averaging Complexity)æ¡†æ¶ï¼Œç”¨äºé‡åŒ–é€šè¿‡å¹³å‡åŒ–æ‰‹æ®µå®ç°å¯¹ç§°æ€§çš„ä»£ä»·ã€‚ç ”ç©¶çš„æ ¸å¿ƒå‘ç°æ˜¯ä¸¤è€…ä¹‹é—´å­˜åœ¨æŒ‡æ•°çº§çš„åˆ†ç¦»ï¼Œå³åœ¨æ ‡å‡†æ¡ä»¶ä¸‹ï¼Œå®ç°Exact Symmetryéœ€è¦çº¿æ€§çš„å¹³å‡å¤æ‚åº¦ï¼Œè€ŒApproximate Symmetryä»…éœ€å¯¹æ•°çº§åˆ«çš„å¤æ‚åº¦ã€‚è¿™æ˜¯é¢†åŸŸå†…é¦–æ¬¡å¯¹è¿™ä¸¤ç§æƒ…å†µè¿›è¡Œç†è®ºä¸Šçš„åŒºåˆ†ï¼Œæ­£å¼åˆç†è§£é‡Šäº†ä¸ºä½•è¿‘ä¼¼å¯¹ç§°æ€§åœ¨å®è·µä¸­å¾€å¾€æ¯”ç²¾ç¡®å¯¹ç§°æ€§æ›´å…·ä¼˜åŠ¿ã€‚æ­¤å¤–ï¼Œç ”ç©¶æ‰€å¼€å‘çš„å·¥å…·å’ŒæŠ€æœ¯ä¹Ÿä¸ºæœºå™¨å­¦ä¹ é¢†åŸŸæ›´å¹¿æ³›çš„å¯¹ç§°æ€§ç ”ç©¶æä¾›äº†å…·æœ‰å‚è€ƒä»·å€¼çš„æ–°æ–¹æ³•ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "32 pages, 2 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.11855v1",
      "published_date": "2025-12-05 03:18:18 UTC",
      "updated_date": "2025-12-05 03:18:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:09:36.582198+00:00"
    },
    {
      "arxiv_id": "2512.05386v1",
      "title": "Generalization Beyond Benchmarks: Evaluating Learnable Protein-Ligand Scoring Functions on Unseen Targets",
      "title_zh": "è¶…è¶ŠåŸºå‡†çš„æ³›åŒ–ï¼šåœ¨æœªçŸ¥é¶æ ‡ä¸Šè¯„ä¼°å¯å­¦ä¹ çš„è›‹ç™½è´¨-é…ä½“è¯„åˆ†å‡½æ•°",
      "authors": [
        "Jakub Kopko",
        "David Graber",
        "Saltuk Mustafa Eyrilmez",
        "Stanislav Mazurenko",
        "David Bednar",
        "Jiri Sedlar",
        "Josef Sivic"
      ],
      "abstract": "As machine learning becomes increasingly central to molecular design, it is vital to ensure the reliability of learnable protein-ligand scoring functions on novel protein targets. While many scoring functions perform well on standard benchmarks, their ability to generalize beyond training data remains a significant challenge. In this work, we evaluate the generalization capability of state-of-the-art scoring functions on dataset splits that simulate evaluation on targets with a limited number of known structures and experimental affinity measurements. Our analysis reveals that the commonly used benchmarks do not reflect the true challenge of generalizing to novel targets. We also investigate whether large-scale self-supervised pretraining can bridge this generalization gap and we provide preliminary evidence of its potential. Furthermore, we probe the efficacy of simple methods that leverage limited test-target data to improve scoring function performance. Our findings underscore the need for more rigorous evaluation protocols and offer practical guidance for designing scoring functions with predictive power extending to novel protein targets.",
      "tldr_zh": "è¯¥ç ”ç©¶è¯„ä¼°äº†å¯å­¦ä¹ çš„è›‹ç™½è´¨-é…ä½“è¯„åˆ†å‡½æ•° (protein-ligand scoring functions) åœ¨æœªçŸ¥ç›®æ ‡ (unseen targets) ä¸Šçš„æ³›åŒ–èƒ½åŠ›ï¼Œæ—¨åœ¨ç¡®ä¿æœºå™¨å­¦ä¹ æ¨¡å‹åœ¨åˆ†å­è®¾è®¡ä¸­çš„å¯é æ€§ã€‚ç ”ç©¶äººå‘˜é€šè¿‡æ¨¡æ‹Ÿå…·æœ‰æœ‰é™ç»“æ„å’Œäº²å’ŒåŠ›æ•°æ®çš„ç›®æ ‡åœºæ™¯ï¼Œå¯¹å½“å‰æœ€å…ˆè¿›çš„è¯„åˆ†å‡½æ•°è¿›è¡Œäº†è¯„ä¼°ã€‚åˆ†æå‘ç°ï¼Œå¸¸ç”¨çš„åŸºå‡†æµ‹è¯• (benchmarks) æ— æ³•çœŸå®åæ˜ æ¨¡å‹æ³›åŒ–åˆ°æ–°ç›®æ ‡æ—¶é¢ä¸´çš„æŒ‘æˆ˜ã€‚ç ”ç©¶è¿›ä¸€æ­¥æ¢è®¨äº†å¤§è§„æ¨¡è‡ªæˆ‘ç›‘ç£é¢„è®­ç»ƒ (self-supervised pretraining) åœ¨ç¼©å°æ³›åŒ–å·®è·æ–¹é¢çš„æ½œåŠ›ï¼Œå¹¶æä¾›äº†åˆæ­¥è¯æ®ã€‚æ­¤å¤–ï¼Œè¯¥å·¥ä½œè¿˜è¯æ˜äº†åˆ©ç”¨æœ‰é™çš„æµ‹è¯•ç›®æ ‡æ•°æ®å¯ä»¥æœ‰æ•ˆæå‡è¯„åˆ†å‡½æ•°çš„æ€§èƒ½ã€‚è¿™äº›å‘ç°å¼ºè°ƒäº†å»ºç«‹æ›´ä¸¥æ ¼è¯„ä¼°åè®®çš„å¿…è¦æ€§ï¼Œå¹¶ä¸ºå¼€å‘å…·æœ‰å¼ºè·¨ç›®æ ‡é¢„æµ‹èƒ½åŠ›çš„è¯„åˆ†å‡½æ•°æä¾›äº†å®è·µæŒ‡å¯¼ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 6 figures, submitted to NeurIPS 2025 AI4Science Workshop",
      "pdf_url": "https://arxiv.org/pdf/2512.05386v1",
      "published_date": "2025-12-05 02:55:19 UTC",
      "updated_date": "2025-12-05 02:55:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:09:43.293054+00:00"
    },
    {
      "arxiv_id": "2512.05383v1",
      "title": "Fuzzing the brain: Automated stress testing for the safety of ML-driven neurostimulation",
      "title_zh": "Fuzzing the brainï¼šæœºå™¨å­¦ä¹ é©±åŠ¨ç¥ç»åˆºæ¿€å®‰å…¨æ€§çš„è‡ªåŠ¨åŒ–å‹åŠ›æµ‹è¯•",
      "authors": [
        "Mara Downing",
        "Matthew Peng",
        "Jacob Granley",
        "Michael Beyeler",
        "Tevfik Bultan"
      ],
      "abstract": "Objective: Machine learning (ML) models are increasingly used to generate electrical stimulation patterns in neuroprosthetic devices such as visual prostheses. While these models promise precise and personalized control, they also introduce new safety risks when model outputs are delivered directly to neural tissue. We propose a systematic, quantitative approach to detect and characterize unsafe stimulation patterns in ML-driven neurostimulation systems. Approach: We adapt an automated software testing technique known as coverage-guided fuzzing to the domain of neural stimulation. Here, fuzzing performs stress testing by perturbing model inputs and tracking whether resulting stimulation violates biophysical limits on charge density, instantaneous current, or electrode co-activation. The framework treats encoders as black boxes and steers exploration with coverage metrics that quantify how broadly test cases span the space of possible outputs and violation types. Main results: Applied to deep stimulus encoders for the retina and cortex, the method systematically reveals diverse stimulation regimes that exceed established safety limits. Two violation-output coverage metrics identify the highest number and diversity of unsafe outputs, enabling interpretable comparisons across architectures and training strategies. Significance: Violation-focused fuzzing reframes safety assessment as an empirical, reproducible process. By transforming safety from a training heuristic into a measurable property of the deployed model, it establishes a foundation for evidence-based benchmarking, regulatory readiness, and ethical assurance in next-generation neural interfaces.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è§†è§‰å‡ä½“ç­‰ç¥ç»ä¿®å¤è®¾å¤‡ä¸­æœºå™¨å­¦ä¹ (Machine learning, ML)æ¨¡å‹é©±åŠ¨äº§ç”Ÿçš„ç”µåˆºæ¿€æ¨¡å¼å¯èƒ½å¼•å‘çš„å®‰å…¨é£é™©ï¼Œæå‡ºäº†ä¸€ç§ç³»ç»ŸåŒ–çš„å®šé‡æ£€æµ‹ä¸è¡¨å¾æ–¹æ³•ã€‚ä½œè€…å°†è‡ªåŠ¨åŒ–è½¯ä»¶æµ‹è¯•ä¸­çš„è¦†ç›–å¼•å¯¼æ¨¡ç³Šæµ‹è¯•(coverage-guided fuzzing)æŠ€æœ¯å¼•å…¥ç¥ç»åˆºæ¿€é¢†åŸŸï¼Œé€šè¿‡å¯¹æ¨¡å‹è¾“å…¥è¿›è¡Œå‹åŠ›æµ‹è¯•æ¥æ¢æµ‹è¾“å‡ºæ˜¯å¦è¿åç”µè·å¯†åº¦ã€ç¬æ—¶ç”µæµæˆ–ç”µæå…±åŒæ¿€æ´»ç­‰ç”Ÿç‰©ç‰©ç†æé™ã€‚è¯¥æ¡†æ¶å°†ç¼–ç å™¨è§†ä¸ºé»‘ç›’(black boxes)ï¼Œåˆ©ç”¨è¦†ç›–åº¦æŒ‡æ ‡å¼•å¯¼æœç´¢ï¼Œæ—¨åœ¨å¹¿æ³›éå†å¯èƒ½çš„è¾“å‡ºç©ºé—´å’Œè¿è§„ç±»å‹ã€‚åœ¨è§†ç½‘è†œ(retinal)å’Œçš®å±‚(cortical)æ·±åº¦åˆºæ¿€ç¼–ç å™¨ä¸Šçš„åº”ç”¨ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½ç³»ç»Ÿåœ°å‘ç°å¤šç§è¶…å‡ºæ—¢å®šå®‰å…¨é™åˆ¶çš„å±é™©åˆºæ¿€çŠ¶æ€ã€‚å®éªŒç¡®å®šçš„è¿è§„è¾“å‡ºè¦†ç›–åº¦æŒ‡æ ‡èƒ½æœ‰æ•ˆè¯†åˆ«ä¸å®‰å…¨è¾“å‡ºçš„å¤šæ ·æ€§ï¼Œä»è€Œå®ç°ä¸åŒæ¶æ„ä¹‹é—´çš„å¯è§£é‡Šå¯¹æ¯”ã€‚è¯¥ç ”ç©¶å°†å®‰å…¨æ€§è¯„ä¼°ä»è®­ç»ƒå¯å‘å¼è½¬å˜ä¸ºæ¨¡å‹çš„å¯è¡¡é‡å±æ€§ï¼Œä¸ºä¸‹ä¸€ä»£ç¥ç»æ¥å£çš„åŸºå‡†æµ‹è¯•ã€ç›‘ç®¡å‡†å¤‡å’Œä¼¦ç†ä¿éšœå¥ å®šäº†å®è¯åŸºç¡€ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "20 pages, 4 figures, 2 tables",
      "pdf_url": "https://arxiv.org/pdf/2512.05383v1",
      "published_date": "2025-12-05 02:43:22 UTC",
      "updated_date": "2025-12-05 02:43:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:10:31.095120+00:00"
    },
    {
      "arxiv_id": "2512.05379v1",
      "title": "Mitigating Self-Preference by Authorship Obfuscation",
      "title_zh": "é€šè¿‡ä½œè€…èº«ä»½æ¨¡ç³ŠåŒ–ç¼“è§£è‡ªæˆ‘åå¥½",
      "authors": [
        "Taslim Mahbub",
        "Shi Feng"
      ],
      "abstract": "Language models (LMs) judges are widely used to evaluate the quality of LM outputs. Despite many advantages, LM judges display concerning biases that can impair their integrity in evaluations. One such bias is self-preference: LM judges preferring their own answers over those produced by other LMs or humans. The bias is hard to eliminate as frontier LM judges can distinguish their own outputs from those of others, even when the evaluation candidates are not labeled with their sources. In this paper, we investigate strategies to mitigate self-preference by reducing the LM judges' ability to recognize their own outputs. We apply black-box perturbations to evaluation candidates in pairwise comparison to obfuscate the authorship and reduce self-recognition. We find that perturbations as simple as synonym replacement for a few words predictably reduce self-preference. However, we also uncover fundamental challenges to eliminating the bias: when we extrapolate our perturbations to a more complete neutralization of stylistic differences between the evaluation candidates, self-preference recovers. Our findings suggest that self-recognition and self-preference can happen on many semantic levels, and complete mitigation remains challenging despite promising initial results.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¦‚ä½•é€šè¿‡ä½œè€…èº«ä»½æ¨¡ç³ŠåŒ– (Authorship Obfuscation) æ¥ç¼“è§£è¯­è¨€æ¨¡å‹ (Language Models) è¯„åˆ¤å‘˜åœ¨è¯„ä¼°ä¸­è¡¨ç°å‡ºçš„è‡ªæˆ‘åå¥½ (Self-Preference) åå·®ã€‚ç”±äºå‰æ²¿æ¨¡å‹å³ä½¿åœ¨æœªæ ‡æ³¨æ¥æºçš„æƒ…å†µä¸‹ä¹Ÿèƒ½è¯†åˆ«å‡ºè‡ªå·±çš„è¾“å‡ºï¼Œç ”ç©¶äººå‘˜é‡‡ç”¨äº†é»‘ç›’æ‰°åŠ¨ (Black-box Perturbations) æŠ€æœ¯ï¼Œå¦‚ç®€å•çš„åŒä¹‰è¯æ›¿æ¢ï¼Œæ¥å‡å°‘æ¨¡å‹çš„è‡ªæˆ‘è¯†åˆ«èƒ½åŠ›ã€‚å®éªŒå‘ç°ï¼Œè½»å¾®çš„åŒä¹‰è¯æ›¿æ¢ç¡®å®èƒ½æœ‰æ•ˆé™ä½è‡ªæˆ‘åå¥½ï¼Œä½†å½“è¯•å›¾é€šè¿‡å¤–æ¨æ‰°åŠ¨æ¥å®Œå…¨ä¸­å’Œå€™é€‰ç­”æ¡ˆä¹‹é—´çš„é£æ ¼å·®å¼‚æ—¶ï¼Œè‡ªæˆ‘åå¥½åè€Œä¼šå›å‡ã€‚è¿™è¡¨æ˜è‡ªæˆ‘è¯†åˆ«å’Œè‡ªæˆ‘åå¥½å‘ç”Ÿåœ¨å¤šä¸ªè¯­ä¹‰å±‚é¢ï¼Œå°½ç®¡åˆæ­¥å®éªŒç»“æœå…·æœ‰å¯å‘æ€§ï¼Œä½†å®ç°å®Œå…¨ç¼“è§£ä»é¢ä¸´æ ¹æœ¬æ€§çš„æŒ‘æˆ˜ã€‚è¯¥é¡¹å·¥ä½œæ­ç¤ºäº†æ¨¡å‹å†…éƒ¨åå·®çš„å¤æ‚æ€§ï¼Œä¸ºæœªæ¥å¼€å‘æ›´å…¬å¹³ã€ä¸­ç«‹çš„è¯­è¨€æ¨¡å‹è¯„ä¼°æœºåˆ¶æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.05379v1",
      "published_date": "2025-12-05 02:36:13 UTC",
      "updated_date": "2025-12-05 02:36:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:10:19.490699+00:00"
    },
    {
      "arxiv_id": "2512.05377v3",
      "title": "China Regional 3km Downscaling Based on Residual Corrective Diffusion Model",
      "title_zh": "åŸºäºæ®‹å·®ä¿®æ­£æ‰©æ•£æ¨¡å‹çš„ä¸­å›½åŒºåŸŸ 3km é™å°ºåº¦",
      "authors": [
        "Honglu Sun",
        "Hao Jing",
        "Zhixiang Dai",
        "Sa Xiao",
        "Wei Xue",
        "Jian Sun",
        "Qifeng Lu"
      ],
      "abstract": "A fundamental challenge in numerical weather prediction is to efficiently produce high-resolution forecasts. A common solution is applying downscaling methods, which include dynamical downscaling and statistical downscaling, to the outputs of global models. This work focuses on statistical downscaling, which establishes statistical relationships between low-resolution and high-resolution historical data using statistical models. Deep learning has emerged as a powerful tool for this task, giving rise to various high-performance super-resolution models, which can be directly applied for downscaling, such as diffusion models and Generative Adversarial Networks. This work relies on a diffusion-based downscaling framework named CorrDiff. In contrast to the original work of CorrDiff, the region considered in this work is nearly 40 times larger, and we not only consider surface variables as in the original work, but also encounter high-level variables (six pressure levels) as target downscaling variables. In addition, a global residual connection is added to improve accuracy. In order to generate the 3km forecasts for the China region, we apply our trained models to the 25km global grid forecasts of CMA-GFS, an operational global model of the China Meteorological Administration (CMA), and SFF, a data-driven deep learning-based weather model developed from Spherical Fourier Neural Operators (SFNO). CMA-MESO, a high-resolution regional model, is chosen as the baseline model. The experimental results demonstrate that the forecasts downscaled by our method generally outperform the direct forecasts of CMA-MESO in terms of MAE for the target variables. Our forecasts of radar composite reflectivity show that CorrDiff, as a generative model, can generate fine-scale details that lead to more realistic predictions compared to the corresponding deterministic regression models.",
      "tldr_zh": "é’ˆå¯¹æ•°å€¼å¤©æ°”é¢„æŠ¥ä¸­é«˜æ•ˆç”Ÿæˆé«˜åˆ†è¾¨ç‡é¢„æŠ¥çš„æŒ‘æˆ˜ï¼Œè¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºæ®‹å·®ä¿®æ­£æ‰©æ•£æ¨¡å‹(Residual Corrective Diffusion Model)çš„ä¸­å›½åŒºåŸŸ3kmå°ºåº¦é™å°ºåº¦æ–¹æ³•ã€‚è¯¥æ–¹æ³•åŸºäºæ‰©æ•£æ¨¡å‹(diffusion-based)æ¡†æ¶CorrDiffï¼Œé’ˆå¯¹æ¯”åŸå·¥ä½œå¤§è¿‘40å€çš„ä¸­å›½åŒºåŸŸè¿›è¡Œäº†ä¼˜åŒ–ï¼Œå¹¶å¼•å…¥äº†å…¨çƒæ®‹å·®è¿æ¥(global residual connection)ä»¥æ˜¾è‘—æå‡æ¨¡å‹ç²¾åº¦ã€‚ç ”ç©¶ä¸ä»…å¤„ç†åœ°é¢å˜é‡ï¼Œè¿˜é¦–æ¬¡å°†å…­ä¸ªå‹åŠ›å±‚çš„é«˜ç©ºå˜é‡(high-level variables)çº³å…¥é™å°ºåº¦ç›®æ ‡ã€‚é€šè¿‡å°†è¯¥æ¨¡å‹åº”ç”¨äºCMA-GFSå…¨çƒé¢„æŠ¥å’ŒåŸºäºæ·±åº¦å­¦ä¹ çš„SFFæ¨¡å‹ï¼Œå®éªŒè¯æ˜å…¶åœ¨å¹³å‡ç»å¯¹è¯¯å·®(MAE)æŒ‡æ ‡ä¸Šä¼˜äºé«˜åˆ†è¾¨ç‡åŒºåŸŸæ¨¡å‹CMA-MESOã€‚æ­¤å¤–ï¼Œåœ¨é›·è¾¾ç»„åˆåå°„ç‡(radar composite reflectivity)é¢„æŠ¥ä¸­ï¼Œè¯¥æ–¹æ³•å±•ç°äº†ç”Ÿæˆå¼æ¨¡å‹äº§ç”Ÿç²¾ç»†å°ºåº¦ç»†èŠ‚çš„èƒ½åŠ›ï¼Œæä¾›äº†æ¯”ä¼ ç»Ÿå›å½’æ¨¡å‹æ›´å…·çœŸå®æ„Ÿçš„é¢„æµ‹ç»“æœã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.ao-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.05377v3",
      "published_date": "2025-12-05 02:27:08 UTC",
      "updated_date": "2025-12-15 03:17:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:10:34.985687+00:00"
    },
    {
      "arxiv_id": "2512.05374v1",
      "title": "Please Don't Kill My Vibe: Empowering Agents with Data Flow Control",
      "title_zh": "è¯·åˆ«ç ´åæˆ‘çš„æ°›å›´ï¼šé€šè¿‡æ•°æ®æµæ§åˆ¶èµ‹èƒ½æ™ºèƒ½ä½“",
      "authors": [
        "Charlie Summers",
        "Haneen Mohammed",
        "Eugene Wu"
      ],
      "abstract": "The promise of Large Language Model (LLM) agents is to perform complex, stateful tasks. This promise is stunted by significant risks - policy violations, process corruption, and security flaws - that stem from the lack of visibility and mechanisms to manage undesirable data flows produced by agent actions. Today, agent workflows are responsible for enforcing these policies in ad hoc ways. Just as data validation and access controls shifted from the application to the DBMS, freeing application developers from these concerns, we argue that systems should support Data Flow Controls (DFCs) and enforce DFC policies natively. This paper describes early work developing a portable instance of DFC for DBMSes and outlines a broader research agenda toward DFC for agent ecosystems.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLM)æ™ºèƒ½ä½“åœ¨æ‰§è¡Œå¤æ‚ä»»åŠ¡æ—¶é¢ä¸´çš„æ”¿ç­–è¿è§„ã€è¿‡ç¨‹æŸåå’Œå®‰å…¨æ¼æ´ç­‰æ˜¾è‘—é£é™©ï¼Œè¿™äº›é—®é¢˜ä¸»è¦æºäºç¼ºä¹å¯¹æ™ºèƒ½ä½“æ“ä½œäº§ç”Ÿçš„ä¸è‰¯æ•°æ®æµè¿›è¡Œç®¡ç†å’Œå¯è§æ€§çš„æœºåˆ¶ã€‚ä½œè€…æŒ‡å‡ºç›®å‰ç”±å·¥ä½œæµä»¥ç‰¹è®¾æ–¹å¼å¼ºåˆ¶æ‰§è¡Œæ”¿ç­–çš„å±€é™æ€§ï¼Œå¹¶ä¸»å¼ ç³»ç»Ÿåº”å½“å€Ÿé‰´æ•°æ®åº“ç®¡ç†ç³»ç»Ÿ(DBMS)çš„æ¼”è¿›è·¯å¾„ï¼ŒåŸç”Ÿæ”¯æŒå¹¶å¼ºåˆ¶æ‰§è¡Œæ•°æ®æµæ§åˆ¶(Data Flow Controls, DFCs)ã€‚è®ºæ–‡ä»‹ç»äº†ä¸ºDBMSå¼€å‘ä¾¿æºå¼DFCå®ä¾‹çš„æ—©æœŸå·¥ä½œï¼Œå¹¶å‹¾å‹’äº†é¢å‘æ™ºèƒ½ä½“ç”Ÿæ€ç³»ç»Ÿæ„å»ºDFCçš„å¹¿æ³›ç ”ç©¶è®®ç¨‹ã€‚é€šè¿‡å°†æ•°æ®æµéªŒè¯ä¸è®¿é—®æ§åˆ¶ä»åº”ç”¨å±‚è½¬ç§»è‡³ç³»ç»Ÿå±‚ï¼Œè¯¥ç ”ç©¶æ—¨åœ¨å‡è½»å¼€å‘è€…çš„è´Ÿæ‹…å¹¶ä¸ºæ„å»ºæ›´å®‰å…¨ã€å¯æ§çš„æ™ºèƒ½ä½“ç³»ç»Ÿæä¾›ç³»ç»Ÿçº§æ”¯æŒã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.CR",
      "comment": "7 pages, 7 figures, CIDR 2026",
      "pdf_url": "https://arxiv.org/pdf/2512.05374v1",
      "published_date": "2025-12-05 02:24:27 UTC",
      "updated_date": "2025-12-05 02:24:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:10:34.138896+00:00"
    },
    {
      "arxiv_id": "2512.05373v1",
      "title": "Text Rationalization for Robust Causal Effect Estimation",
      "title_zh": "é¢å‘ç¨³å¥å› æœæ•ˆåº”ä¼°è®¡çš„æ–‡æœ¬åˆç†åŒ–",
      "authors": [
        "Lijinghua Zhang",
        "Hengrui Cai"
      ],
      "abstract": "Recent advances in natural language processing have enabled the increasing use of text data in causal inference, particularly for adjusting confounding factors in treatment effect estimation. Although high-dimensional text can encode rich contextual information, it also poses unique challenges for causal identification and estimation. In particular, the positivity assumption, which requires sufficient treatment overlap across confounder values, is often violated at the observational level, when massive text is represented in feature spaces. Redundant or spurious textual features inflate dimensionality, producing extreme propensity scores, unstable weights, and inflated variance in effect estimates. We address these challenges with Confounding-Aware Token Rationalization (CATR), a framework that selects a sparse necessary subset of tokens using a residual-independence diagnostic designed to preserve confounding information sufficient for unconfoundedness. By discarding irrelevant texts while retaining key signals, CATR mitigates observational-level positivity violations and stabilizes downstream causal effect estimators. Experiments on synthetic data and a real-world study using the MIMIC-III database demonstrate that CATR yields more accurate, stable, and interpretable causal effect estimates than existing baselines.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æ–‡æœ¬æ•°æ®åœ¨å› æœæ¨ç†(Causal Inference)ä¸­çš„åº”ç”¨ï¼Œç‰¹åˆ«æ˜¯åœ¨è°ƒæ•´å¤„ç†æ•ˆåº”ä¼°è®¡(Treatment Effect Estimation)ä¸­çš„æ··æ‚å› ç´ æ–¹é¢ã€‚é’ˆå¯¹é«˜ç»´æ–‡æœ¬ç‰¹å¾å¸¸å¯¼è‡´çš„æ­£å€¼æ€§å‡è®¾(Positivity Assumption)è¿èƒŒã€å€¾å‘å¾—åˆ†æç«¯ä»¥åŠä¼°è®¡æ–¹å·®è¿‡å¤§ç­‰é—®é¢˜ï¼Œä½œè€…æå‡ºäº†æ··æ‚æ„ŸçŸ¥æ ‡è®°åˆç†åŒ–æ¡†æ¶(Confounding-Aware Token Rationalizationï¼Œç®€ç§° CATR)ã€‚CATR é€šè¿‡ä¸€ç§æ®‹å·®ç‹¬ç«‹æ€§è¯Šæ–­(Residual-Independence Diagnostic)æŠ€æœ¯ï¼Œä»åŸå§‹æ–‡æœ¬ä¸­ç­›é€‰å‡ºè¶³ä»¥ä¿è¯æ— æ··æ‚æ€§(Unconfoundedness)çš„ç¨€ç–æ ‡è®°å­é›†ã€‚è¯¥æ–¹æ³•åœ¨å‰”é™¤å†—ä½™å’Œå¹²æ‰°æ–‡æœ¬ä¿¡æ¯çš„åŒæ—¶ï¼Œä¿ç•™äº†å…³é”®çš„æ··æ‚ä¿¡å·ï¼Œä»è€Œç¼“è§£äº†è§‚æµ‹å±‚é¢çš„æ­£å€¼æ€§è¿èƒŒå¹¶ç¨³å®šäº†ä¸‹æ¸¸çš„å› æœæ•ˆåº”ä¼°è®¡å™¨ã€‚åœ¨åˆæˆæ•°æ®å’Œ MIMIC-III æ•°æ®åº“çš„çœŸå®æ¡ˆä¾‹ç ”ç©¶è¡¨æ˜ï¼ŒCATR åœ¨å‡†ç¡®æ€§ã€ç¨³å®šæ€§å’Œå¯è§£é‡Šæ€§æ–¹é¢å‡ä¼˜äºç°æœ‰çš„åŸºçº¿æ¨¡å‹ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ME",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.05373v1",
      "published_date": "2025-12-05 02:18:45 UTC",
      "updated_date": "2025-12-05 02:18:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:10:10.287122+00:00"
    },
    {
      "arxiv_id": "2512.05371v1",
      "title": "ChipMind: Retrieval-Augmented Reasoning for Long-Context Circuit Design Specifications",
      "title_zh": "ChipMindï¼šé¢å‘é•¿ä¸Šä¸‹æ–‡ç”µè·¯è®¾è®¡è§„èŒƒçš„æ£€ç´¢å¢å¼ºæ¨ç†",
      "authors": [
        "Changwen Xing",
        "SamZaak Wong",
        "Xinlai Wan",
        "Yanfeng Lu",
        "Mengli Zhang",
        "Zebin Ma",
        "Lei Qi",
        "Zhengxiong Li",
        "Nan Guan",
        "Zhe Jiang",
        "Xi Wang",
        "Jun Yang"
      ],
      "abstract": "While Large Language Models (LLMs) demonstrate immense potential for automating integrated circuit (IC) development, their practical deployment is fundamentally limited by restricted context windows. Existing context-extension methods struggle to achieve effective semantic modeling and thorough multi-hop reasoning over extensive, intricate circuit specifications. To address this, we introduce ChipMind, a novel knowledge graph-augmented reasoning framework specifically designed for lengthy IC specifications. ChipMind first transforms circuit specifications into a domain-specific knowledge graph ChipKG through the Circuit Semantic-Aware Knowledge Graph Construction methodology. It then leverages the ChipKG-Augmented Reasoning mechanism, combining information-theoretic adaptive retrieval to dynamically trace logical dependencies with intent-aware semantic filtering to prune irrelevant noise, effectively balancing retrieval completeness and precision. Evaluated on an industrial-scale specification reasoning benchmark, ChipMind significantly outperforms state-of-the-art baselines, achieving an average improvement of 34.59% (up to 72.73%). Our framework bridges a critical gap between academic research and practical industrial deployment of LLM-aided Hardware Design (LAD).",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨é›†æˆç”µè·¯(IC)å¼€å‘ä¸­å—é™äºä¸Šä¸‹æ–‡çª—å£ï¼Œéš¾ä»¥å¯¹é•¿ç¯‡å¤æ‚ç”µè·¯è§„èŒƒè¿›è¡Œè¯­ä¹‰å»ºæ¨¡å’Œå¤šè·³æ¨ç†çš„é—®é¢˜ï¼Œæå‡ºäº†ChipMindï¼Œä¸€ç§ä¸“é—¨ä¸ºé•¿ç¯‡ICè§„èŒƒè®¾è®¡çš„çŸ¥è¯†å›¾è°±å¢å¼ºæ¨ç†æ¡†æ¶ã€‚ChipMindé¦–å…ˆé€šè¿‡ç”µè·¯è¯­ä¹‰æ„ŸçŸ¥çŸ¥è¯†å›¾è°±æ„å»ºæ–¹æ³•(Circuit Semantic-Aware Knowledge Graph Construction)å°†ç”µè·¯è§„èŒƒè½¬åŒ–ä¸ºé¢†åŸŸç‰¹å®šçš„çŸ¥è¯†å›¾è°±ChipKGã€‚éšåï¼Œè¯¥æ¡†æ¶åˆ©ç”¨ChipKGå¢å¼ºæ¨ç†æœºåˆ¶ï¼Œç»“åˆä¿¡æ¯è®ºè‡ªé€‚åº”æ£€ç´¢ä»¥åŠ¨æ€è¿½è¸ªé€»è¾‘ä¾èµ–ï¼Œå¹¶é…åˆæ„å›¾æ„ŸçŸ¥è¯­ä¹‰è¿‡æ»¤æ¥å‰”é™¤æ— å…³å™ªå£°ï¼Œæœ‰æ•ˆå¹³è¡¡äº†æ£€ç´¢çš„å®Œæ•´æ€§ä¸ç²¾ç¡®æ€§ã€‚åœ¨å·¥ä¸šçº§è§„èŒƒæ¨ç†åŸºå‡†æµ‹è¯•ä¸­ï¼ŒChipMindçš„æ€§èƒ½æ˜¾è‘—ä¼˜äºç°æœ‰åŸºå‡†æ¨¡å‹ï¼Œå¹³å‡å‡†ç¡®ç‡æå‡äº†34.59%ï¼Œæœ€é«˜æå‡è¾¾72.73%ã€‚è¯¥æ¡†æ¶ä¸ºç¼©å°å­¦æœ¯ç ”ç©¶ä¸å¤§è¯­è¨€æ¨¡å‹è¾…åŠ©ç¡¬ä»¶è®¾è®¡(LAD)å®é™…å·¥ä¸šéƒ¨ç½²ä¹‹é—´çš„å·®è·æä¾›äº†å…³é”®æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by the AAAl26 Conference Main Track",
      "pdf_url": "https://arxiv.org/pdf/2512.05371v1",
      "published_date": "2025-12-05 02:09:49 UTC",
      "updated_date": "2025-12-05 02:09:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:10:30.961688+00:00"
    },
    {
      "arxiv_id": "2512.05365v1",
      "title": "MCP-AI: Protocol-Driven Intelligence Framework for Autonomous Reasoning in Healthcare",
      "title_zh": "MCP-AIï¼šé¢å‘åŒ»ç–—é¢†åŸŸè‡ªä¸»æ¨ç†çš„åè®®é©±åŠ¨å‹æ™ºèƒ½æ¡†æ¶",
      "authors": [
        "Zag ElSayed",
        "Craig Erickson",
        "Ernest Pedapati"
      ],
      "abstract": "Healthcare AI systems have historically faced challenges in merging contextual reasoning, long-term state management, and human-verifiable workflows into a cohesive framework. This paper introduces a completely innovative architecture and concept: combining the Model Context Protocol (MCP) with a specific clinical application, known as MCP-AI. This integration allows intelligent agents to reason over extended periods, collaborate securely, and adhere to authentic clinical logic, representing a significant shift away from traditional Clinical Decision Support Systems (CDSS) and prompt-based Large Language Models (LLMs). As healthcare systems become more complex, the need for autonomous, context-aware clinical reasoning frameworks has become urgent. We present MCP-AI, a novel architecture for explainable medical decision-making built upon the Model Context Protocol (MCP) a modular, executable specification for orchestrating generative and descriptive AI agents in real-time workflows. Each MCP file captures clinical objectives, patient context, reasoning state, and task logic, forming a reusable and auditable memory object. Unlike conventional CDSS or stateless prompt-based AI systems, MCP-AI supports adaptive, longitudinal, and collaborative reasoning across care settings. MCP-AI is validated through two use cases: (1) diagnostic modeling of Fragile X Syndrome with comorbid depression, and (2) remote coordination for Type 2 Diabetes and hypertension. In either scenario, the protocol facilitates physician-in-the-loop validation, streamlines clinical processes, and guarantees secure transitions of AI responsibilities between healthcare providers. The system connects with HL7/FHIR interfaces and adheres to regulatory standards, such as HIPAA and FDA SaMD guidelines. MCP-AI provides a scalable basis for interpretable, composable, and safety-oriented AI within upcoming clinical environments.",
      "tldr_zh": "æœ¬ç ”ç©¶ä»‹ç»äº†MCP-AIï¼Œè¿™æ˜¯ä¸€ç§ä¸“ä¸ºåŒ»ç–—ä¿å¥è®¾è®¡çš„åˆ›æ–°æ¶æ„ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»ŸAIç³»ç»Ÿåœ¨è¯­å¢ƒæ¨ç†ã€é•¿æœŸçŠ¶æ€ç®¡ç†å’Œäººç±»å¯éªŒè¯å·¥ä½œæµæ–¹é¢çš„å±€é™ã€‚è¯¥æ¡†æ¶å°†Model Context Protocol (MCP) ä¸ç‰¹å®šçš„ä¸´åºŠåº”ç”¨ç›¸ç»“åˆï¼Œé€šè¿‡æ¨¡å—åŒ–ä¸”å¯æ‰§è¡Œçš„è§„èŒƒæ¥ç¼–æ’ç”Ÿæˆå¼å’Œæè¿°å¼æ™ºèƒ½ä½“ã€‚æ¯ä¸€ä¸ªMCPæ–‡ä»¶èƒ½å¤Ÿæ•è·ä¸´åºŠç›®æ ‡ã€æ‚£è€…è¯­å¢ƒã€æ¨ç†çŠ¶æ€å’Œä»»åŠ¡é€»è¾‘ï¼Œä»è€Œå½¢æˆå¯é‡å¤ä½¿ç”¨ä¸”å¯å®¡è®¡çš„è®°å¿†å¯¹è±¡ã€‚ä¸ä¼ ç»Ÿçš„Clinical Decision Support Systems (CDSS) æˆ–æ— çŠ¶æ€çš„æç¤ºè¯å¤§æ¨¡å‹(Prompt-based LLMs) ä¸åŒï¼ŒMCP-AIæ”¯æŒé€‚åº”æ€§çš„ã€çºµå‘çš„ä»¥åŠè·¨æŠ¤ç†åœºæ™¯çš„åä½œæ¨ç†ã€‚ç ”ç©¶é€šè¿‡è„†æ€§Xç»¼åˆå¾(Fragile X Syndrome) è¯Šæ–­å»ºæ¨¡å’Œ2å‹ç³–å°¿ç—…(Type 2 Diabetes) è¿œç¨‹åè°ƒä¸¤ä¸ªæ¡ˆä¾‹éªŒè¯äº†è¯¥ç³»ç»Ÿçš„æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼ŒMCP-AIé€šè¿‡è¿æ¥HL7/FHIRæ¥å£ï¼Œå¹¶éµå¾ªHIPAAå’ŒFDA SaMDç­‰ç›‘ç®¡æ ‡å‡†ï¼Œç¡®ä¿äº†åŒ»ç–—è¿‡ç¨‹çš„å®‰å…¨æ€§ä¸åˆè§„æ€§ã€‚è¿™ä¸€æ¡†æ¶ä¸ºæœªæ¥ä¸´åºŠç¯å¢ƒä¸­å¯è§£é‡Šã€å¯ç»„åˆä¸”å®‰å…¨å¯¼å‘çš„AIåº”ç”¨å¥ å®šäº†å¯æ‰©å±•çš„åŸºç¡€ã€‚",
      "categories": [
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.AI",
      "comment": "6 pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.05365v1",
      "published_date": "2025-12-05 02:02:22 UTC",
      "updated_date": "2025-12-05 02:02:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:10:43.161906+00:00"
    },
    {
      "arxiv_id": "2512.05356v2",
      "title": "AI & Human Co-Improvement for Safer Co-Superintelligence",
      "title_zh": "AI ä¸äººç±»ååŒæ”¹è¿›ï¼šè¿ˆå‘æ›´å®‰å…¨çš„ååŒè¶…æ™ºèƒ½",
      "authors": [
        "Jason Weston",
        "Jakob Foerster"
      ],
      "abstract": "Self-improvement is a goal currently exciting the field of AI, but is fraught with danger, and may take time to fully achieve. We advocate that a more achievable and better goal for humanity is to maximize co-improvement: collaboration between human researchers and AIs to achieve co-superintelligence. That is, specifically targeting improving AI systems' ability to work with human researchers to conduct AI research together, from ideation to experimentation, in order to both accelerate AI research and to generally endow both AIs and humans with safer superintelligence through their symbiosis. Focusing on including human research improvement in the loop will both get us there faster, and more safely.",
      "tldr_zh": "è¯¥ç ”ç©¶å€¡å¯¼å°†AIä¸äººç±»å…±åŒæå‡ï¼ˆAI & Human Co-Improvementï¼‰ä½œä¸ºæ¯”å•çº¯çš„AIè‡ªæˆ‘æ”¹è¿›ï¼ˆSelf-improvementï¼‰æ›´å…·å¯è¡Œæ€§ä¸”æ›´å®‰å…¨çš„ç›®æ ‡ï¼Œæ—¨åœ¨å®ç°å…±åŒè¶…æ™ºèƒ½ï¼ˆCo-superintelligenceï¼‰ã€‚è¯¥èŒƒå¼å¼ºè°ƒäººç±»ç ”ç©¶è€…ä¸AIåœ¨AIç ”ç©¶å…¨ç”Ÿå‘½å‘¨æœŸï¼ˆä»æ„æ€åˆ°å®éªŒï¼‰ä¸­çš„æ·±åº¦åä½œï¼Œé€šè¿‡å…±ç”Ÿå…³ç³»ï¼ˆSymbiosisï¼‰å…±åŒè¿›åŒ–ã€‚è¿™ç§æ–¹æ³•ä¸ä»…èƒ½åŠ é€ŸAIç ”å‘è¿›ç¨‹ï¼Œè¿˜èƒ½ç¡®ä¿åœ¨è¿ˆå‘è¶…æ™ºèƒ½çš„è¿‡ç¨‹ä¸­ï¼ŒAIä¸äººç±»éƒ½èƒ½è·å¾—æ›´é«˜çš„å®‰å…¨æ€§ä¿éšœã€‚é€šè¿‡å°†äººç±»ç ”ç©¶èƒ½åŠ›çš„æå‡çº³å…¥æ”¹è¿›é—­ç¯ï¼Œè¯¥ç ”ç©¶ä¸ºå®ç°æ›´å¿«é€Ÿä¸”æ›´å—æ§çš„è¶…æ™ºèƒ½å‘å±•æä¾›äº†æ–°è·¯å¾„ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.05356v2",
      "published_date": "2025-12-05 01:50:23 UTC",
      "updated_date": "2025-12-14 18:03:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:10:40.980845+00:00"
    },
    {
      "arxiv_id": "2512.11854v1",
      "title": "Rep Smarter, Not Harder: AI Hypertrophy Coaching with Wearable Sensors and Edge Neural Networks",
      "title_zh": "ç»ƒå¾—æ›´å·§ï¼Œè€Œéæ›´è‹¦ï¼šåŸºäºå¯ç©¿æˆ´ä¼ æ„Ÿå™¨ä¸è¾¹ç¼˜ç¥ç»ç½‘ç»œçš„äººå·¥æ™ºèƒ½å¢è‚ŒæŒ‡å¯¼",
      "authors": [
        "Grant King",
        "Musa Azeem",
        "Savannah Noblitt",
        "Ramtin Zand",
        "Homayoun Valafar"
      ],
      "abstract": "Optimizing resistance training for hypertrophy requires balancing proximity to muscular failure, often quantified by Repetitions in Reserve (RiR), with fatigue management. However, subjective RiR assessment is unreliable, leading to suboptimal training stimuli or excessive fatigue. This paper introduces a novel system for real-time feedback on near-failure states (RiR $\\le$ 2) during resistance exercise using only a single wrist-mounted Inertial Measurement Unit (IMU). We propose a two-stage pipeline suitable for edge deployment: first, a ResNet-based model segments repetitions from the 6-axis IMU data in real-time. Second, features derived from this segmentation, alongside direct convolutional features and historical context captured by an LSTM, are used by a classification model to identify exercise windows corresponding to near-failure states. Using a newly collected dataset from 13 diverse participants performing preacher curls to failure (631 total reps), our segmentation model achieved an F1 score of 0.83, and the near-failure classifier achieved an F1 score of 0.82 under simulated real-time evaluation conditions (1.6 Hz inference rate). Deployment on a Raspberry Pi 5 yielded an average inference latency of 112 ms, and on an iPhone 16 yielded 23.5 ms, confirming the feasibility for edge computation. This work demonstrates a practical approach for objective, real-time training intensity feedback using minimal hardware, paving the way for accessible AI-driven hypertrophy coaching tools that help users manage intensity and fatigue effectively.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»‹ç»äº†ä¸€ç§åˆ©ç”¨å¯ç©¿æˆ´ä¼ æ„Ÿå™¨å’Œè¾¹ç¼˜ç¥ç»ç½‘ç»œè¿›è¡ŒAIå¢è‚ŒæŒ‡å¯¼çš„æ–°å‹ç³»ç»Ÿï¼Œæ—¨åœ¨è§£å†³æŠ—é˜»è®­ç»ƒä¸­ä¸»è§‚è¯„ä¼°é¢„ç•™æ¬¡æ•°(Repetitions in Reserve, RiR)ä¸å¯é çš„é—®é¢˜ã€‚ç ”ç©¶æå‡ºäº†ä¸€ä¸ªé€‚ç”¨äºè¾¹ç¼˜éƒ¨ç½²çš„ä¸¤é˜¶æ®µæµæ°´çº¿ï¼Œä»…é€šè¿‡å•ä¸ªè…•éƒ¨æƒ¯æ€§æµ‹é‡å•å…ƒ(Inertial Measurement Unit, IMU)æ•è·çš„6è½´æ•°æ®ï¼Œé¦–å…ˆä½¿ç”¨åŸºäºResNetçš„æ¨¡å‹è¿›è¡Œå®æ—¶çš„åŠ¨ä½œé‡å¤åˆ†å‰²ã€‚éšåï¼Œç³»ç»Ÿåˆ©ç”¨æå–çš„å·ç§¯ç‰¹å¾ä»¥åŠç”±é•¿çŸ­æœŸè®°å¿†ç½‘ç»œ(LSTM)æ•æ‰çš„å†å²ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œé€šè¿‡åˆ†ç±»æ¨¡å‹è¯†åˆ«æ¥è¿‘åŠ›ç«­(Near-failure, RiR $\\le$ 2)çš„è¿åŠ¨çŠ¶æ€ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥åŠ¨ä½œåˆ†å‰²æ¨¡å‹å’ŒåŠ›ç«­åˆ†ç±»å™¨åœ¨æ¨¡æ‹Ÿå®æ—¶è¯„ä¼°æ¡ä»¶ä¸‹çš„F1åˆ†æ•°åˆ†åˆ«è¾¾åˆ°äº†0.83å’Œ0.82ã€‚æ­¤å¤–ï¼Œè¯¥ç³»ç»Ÿåœ¨Raspberry Pi 5å’ŒiPhone 16ä¸Šçš„å¹³å‡æ¨ç†å»¶è¿Ÿåˆ†åˆ«ä¸º112æ¯«ç§’å’Œ23.5æ¯«ç§’ï¼ŒéªŒè¯äº†åœ¨ç§»åŠ¨è¾¹ç¼˜è®¾å¤‡ä¸Šå®ç°å®æ—¶è®¡ç®—çš„å¯è¡Œæ€§ã€‚è¯¥å·¥ä½œä¸ºé€šè¿‡æç®€ç¡¬ä»¶æä¾›å®¢è§‚çš„è®­ç»ƒå¼ºåº¦åé¦ˆå¼€è¾Ÿäº†è·¯å¾„ï¼Œæœ‰åŠ©äºç”¨æˆ·æ›´æœ‰æ•ˆåœ°è¿›è¡Œè®­ç»ƒå¼ºåº¦ä¸ç–²åŠ³ç®¡ç†ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "24th International Conference on Machine Learning and Applications",
      "pdf_url": "https://arxiv.org/pdf/2512.11854v1",
      "published_date": "2025-12-05 01:49:47 UTC",
      "updated_date": "2025-12-05 01:49:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:10:53.532596+00:00"
    },
    {
      "arxiv_id": "2512.05350v1",
      "title": "Invisible Load: Uncovering the Challenges of Neurodivergent Women in Software Engineering",
      "title_zh": "éšå½¢é‡æ‹…ï¼šæ­ç¤ºè½¯ä»¶å·¥ç¨‹é¢†åŸŸç¥ç»å¤šæ ·æ€§å¥³æ€§é¢ä¸´çš„æŒ‘æˆ˜",
      "authors": [
        "Munazza Zaib",
        "Wei Wang",
        "Dulaji Hidellaarachchi",
        "Isma Farah Siddiqui"
      ],
      "abstract": "Neurodivergent women in Software Engineering (SE) encounter distinctive challenges at the intersection of gender bias and neurological differences. To the best of our knowledge, no prior work in SE research has systematically examined this group, despite increasing recognition of neurodiversity in the workplace. Underdiagnosis, masking, and male-centric workplace cultures continue to exacerbate barriers that contribute to stress, burnout, and attrition. In response, we propose a hybrid methodological approach that integrates InclusiveMag's inclusivity framework with the GenderMag walkthrough process, tailored to the context of neurodivergent women in SE. The overarching design unfolds across three stages, scoping through literature review, deriving personas and analytic processes, and applying the method in collaborative workshops. We present a targeted literature review that synthesize challenges into cognitive, social, organizational, structural and career progression challenges neurodivergent women face in SE, including how under/late diagnosis and masking intensify exclusion. These findings lay the groundwork for subsequent stages that will develop and apply inclusive analytic methods to support actionable change.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†è½¯ä»¶å·¥ç¨‹ (Software Engineering, SE) é¢†åŸŸä¸­ç¥ç»å¤šæ ·æ€§ (Neurodivergent) å¥³æ€§é¢ä¸´çš„ç‹¬ç‰¹æŒ‘æˆ˜ï¼Œè¿™äº›æŒ‘æˆ˜ä¸»è¦æºäºæ€§åˆ«åè§ä¸ç¥ç»å·®å¼‚çš„äº¤ç»‡ã€‚ç”±äºæ¼è¯Š (Underdiagnosis)ã€æ©é¥° (Masking) ä»¥åŠä»¥ç”·æ€§ä¸ºä¸­å¿ƒçš„èŒåœºæ–‡åŒ–ï¼Œè¿™ä¸€ç¾¤ä½“å¸¸é¢ä¸´ä¸¥é‡çš„å¿ƒç†å‹åŠ›ã€èŒä¸šå€¦æ€ å’Œäººæ‰æµå¤±ç­‰éšœç¢ã€‚ä¸ºäº†ç³»ç»Ÿæ€§åœ°åº”å¯¹è¿™äº›é—®é¢˜ï¼Œç ”ç©¶æå‡ºäº†ä¸€ç§ç»“åˆ InclusiveMag åŒ…å®¹æ€§æ¡†æ¶ä¸ GenderMag èµ°æŸ¥æµç¨‹çš„æ··åˆæ–¹æ³•è®ºã€‚è¯¥è®¾è®¡é€šè¿‡æ–‡çŒ®ç»¼è¿°ã€äººç‰©è§’è‰² (Personas) ä¸åˆ†ææµç¨‹æ¨å¯¼ä»¥åŠåä½œå·¥ä½œåŠä¸‰ä¸ªé˜¶æ®µå±•å¼€ã€‚ç ”ç©¶é€šè¿‡ç»¼è¿°å°†ç›¸å…³æŒ‘æˆ˜å½’çº³ä¸ºè®¤çŸ¥ã€ç¤¾äº¤ã€ç»„ç»‡ã€ç»“æ„å’ŒèŒä¸šå‘å±•äº”ä¸ªç»´åº¦ï¼Œå¹¶åˆ†æäº†æ™šè¯Šå¦‚ä½•è¿›ä¸€æ­¥åŠ å‰§æ’æ–¥æ„Ÿã€‚è¿™äº›å‘ç°ä¸ºåç»­å¼€å‘åŒ…å®¹æ€§åˆ†ææ–¹æ³•ä»¥åŠæ¨åŠ¨ SE è¡Œä¸šå†…çš„å®è´¨æ€§å˜é©å¥ å®šäº†é‡è¦åŸºç¡€ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.05350v1",
      "published_date": "2025-12-05 01:22:59 UTC",
      "updated_date": "2025-12-05 01:22:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:11:07.671674+00:00"
    },
    {
      "arxiv_id": "2512.05343v1",
      "title": "SpaceControl: Introducing Test-Time Spatial Control to 3D Generative Modeling",
      "title_zh": "SpaceControlï¼šä¸º 3D ç”Ÿæˆå¼å»ºæ¨¡å¼•å…¥æµ‹è¯•æ—¶ç©ºé—´æ§åˆ¶",
      "authors": [
        "Elisabetta Fedele",
        "Francis Engelmann",
        "Ian Huang",
        "Or Litany",
        "Marc Pollefeys",
        "Leonidas Guibas"
      ],
      "abstract": "Generative methods for 3D assets have recently achieved remarkable progress, yet providing intuitive and precise control over the object geometry remains a key challenge. Existing approaches predominantly rely on text or image prompts, which often fall short in geometric specificity: language can be ambiguous, and images are cumbersome to edit. In this work, we introduce SpaceControl, a training-free test-time method for explicit spatial control of 3D generation. Our approach accepts a wide range of geometric inputs, from coarse primitives to detailed meshes, and integrates seamlessly with modern pre-trained generative models without requiring any additional training. A controllable parameter lets users trade off between geometric fidelity and output realism. Extensive quantitative evaluation and user studies demonstrate that SpaceControl outperforms both training-based and optimization-based baselines in geometric faithfulness while preserving high visual quality. Finally, we present an interactive user interface that enables online editing of superquadrics for direct conversion into textured 3D assets, facilitating practical deployment in creative workflows. Find our project page at https://spacecontrol3d.github.io/",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†SpaceControlï¼Œä¸€ç§ç”¨äº3Dç”Ÿæˆæ˜¾å¼ç©ºé—´æ§åˆ¶çš„æ— éœ€è®­ç»ƒçš„æµ‹è¯•æ—¶(training-free test-time)æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ–‡æœ¬æˆ–å›¾åƒé©±åŠ¨æ–¹æ³•åœ¨å‡ ä½•ç²¾ç¡®æ§åˆ¶æ–¹é¢çš„ä¸è¶³ã€‚SpaceControlèƒ½å¤Ÿæ¥å—ä»ç²—ç•¥åŸè¯­(coarse primitives)åˆ°è¯¦ç»†ç½‘æ ¼(detailed meshes)çš„å¤šç§å‡ ä½•è¾“å…¥ï¼Œå¹¶åœ¨æ— éœ€é¢å¤–è®­ç»ƒçš„æƒ…å†µä¸‹ä¸ç°ä»£é¢„è®­ç»ƒç”Ÿæˆæ¨¡å‹æ— ç¼é›†æˆã€‚é€šè¿‡å¼•å…¥ç‰¹å®šçš„å¯æ§å‚æ•°ï¼Œè¯¥æ–¹æ³•å…è®¸ç”¨æˆ·åœ¨å‡ ä½•ä¿çœŸåº¦(geometric fidelity)å’Œè¾“å‡ºçœŸå®æ„Ÿ(output realism)ä¹‹é—´çµæ´»æƒè¡¡ã€‚å®šé‡è¯„ä¼°å’Œç”¨æˆ·ç ”ç©¶è¯æ˜ï¼ŒSpaceControlåœ¨ä¿æŒé«˜è§†è§‰è´¨é‡çš„åŒæ—¶ï¼Œåœ¨å‡ ä½•å¿ å®åº¦ä¸Šæ˜¾è‘—ä¼˜äºåŸºäºè®­ç»ƒå’Œä¼˜åŒ–çš„åŸºçº¿æ¨¡å‹ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜å±•ç¤ºäº†ä¸€ä¸ªäº¤äº’å¼ç”¨æˆ·ç•Œé¢ï¼Œæ”¯æŒé€šè¿‡åœ¨çº¿ç¼–è¾‘è¶…äºŒæ¬¡æ›²é¢(superquadrics)ç›´æ¥ç”Ÿæˆé«˜è´¨é‡çš„çº¹ç†3Dèµ„äº§ï¼Œä¸ºå®é™…åˆ›æ„å·¥ä½œæµæä¾›äº†é«˜æ•ˆçš„å·¥å…·æ”¯æŒã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://spacecontrol3d.github.io/",
      "pdf_url": "https://arxiv.org/pdf/2512.05343v1",
      "published_date": "2025-12-05 00:54:48 UTC",
      "updated_date": "2025-12-05 00:54:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:11:43.338393+00:00"
    },
    {
      "arxiv_id": "2512.05338v2",
      "title": "Interaction Tensor SHAP",
      "title_zh": "äº¤äº’å¼ é‡ SHAP",
      "authors": [
        "Hiroki Hasegawa",
        "Yukihiko Okada"
      ],
      "abstract": "This study proposes Interaction Tensor SHAP (IT-SHAP), a tensor algebraic formulation of the Shapley Taylor Interaction Index (STII) that makes its computational structure explicit. STII extends the Shapley value to higher order interactions, but its exponential combinatorial definition makes direct computation intractable at scale. We reformulate STII as a linear transformation acting on a value function and derive an explicit algebraic representation of its weight tensor. This weight tensor is shown to possess a multilinear structure induced by discrete finite difference operators. When the value function admits a Tensor Train representation, higher order interaction indices can be computed in the parallel complexity class NC squared. In contrast, under general tensor network representations without structural assumptions, the same computation is proven to be P sharp hard. The main contributions are threefold. First, we establish an exact Tensor Train representation of the STII weight tensor. Second, we develop a parallelizable evaluation algorithm with explicit complexity bounds under the Tensor Train assumption. Third, we prove that computational intractability is unavoidable in the absence of such structure. These results demonstrate that the computational difficulty of higher order interaction analysis is determined by the underlying algebraic representation rather than by the interaction index itself, providing a theoretical foundation for scalable interpretation of high dimensional models.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Interaction Tensor SHAP (IT-SHAP)ï¼Œè¿™æ˜¯ä¸€ç§é’ˆå¯¹ Shapley Taylor Interaction Index (STII) çš„å¼ é‡ä»£æ•°å…¬å¼ï¼Œæ—¨åœ¨è§£å†³é«˜é˜¶äº¤äº’æŒ‡æ•°åœ¨è®¡ç®—ä¸Šéš¾ä»¥å¤„ç†çš„é—®é¢˜ã€‚IT-SHAP å°† STII é‡æ–°è¡¨è¿°ä¸ºä½œç”¨äºä»·å€¼å‡½æ•°ä¸Šçš„çº¿æ€§å˜æ¢ï¼Œå¹¶å¯¼å‡ºäº†å…¶æƒé‡å¼ é‡çš„æ˜¾å¼ä»£æ•°è¡¨ç¤ºï¼Œæ­ç¤ºäº†ç”±ç¦»æ•£æœ‰é™å·®åˆ†ç®—å­è¯±å¯¼çš„å¤šçº¿æ€§ç»“æ„ã€‚ç ”ç©¶è¯æ˜ï¼Œå½“ä»·å€¼å‡½æ•°å…·æœ‰ Tensor Train è¡¨ç¤ºæ—¶ï¼Œé«˜é˜¶äº¤äº’æŒ‡æ•°å¯ä»¥åœ¨å¹¶è¡Œå¤æ‚åº¦ç±» NC squared ä¸­è®¡ç®—ï¼Œè€Œåœ¨ç¼ºä¹ç»“æ„å‡è®¾çš„æƒ…å†µä¸‹ï¼Œè¯¥è®¡ç®—è¢«è¯æ˜æ˜¯ P sharp hardã€‚ä¸»è¦è´¡çŒ®åŒ…æ‹¬å»ºç«‹äº† STII æƒé‡å¼ é‡çš„ç²¾ç¡® Tensor Train è¡¨ç¤ºï¼Œå¹¶å¼€å‘äº†å…·æœ‰æ˜ç¡®å¤æ‚åº¦ç•Œé™çš„å¹¶è¡ŒåŒ–è¯„ä¼°ç®—æ³•ã€‚è¿™äº›ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œé«˜é˜¶äº¤äº’åˆ†æçš„è®¡ç®—éš¾åº¦ä¸»è¦å–å†³äºåº•å±‚çš„ä»£æ•°è¡¨ç¤ºï¼Œä¸ºé«˜ç»´æ¨¡å‹çš„å¯æ‰©å±•è§£é‡Šå¥ å®šäº†ç†è®ºåŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "22 pages",
      "pdf_url": "https://arxiv.org/pdf/2512.05338v2",
      "published_date": "2025-12-05 00:34:15 UTC",
      "updated_date": "2026-01-05 03:05:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:11:56.833036+00:00"
    },
    {
      "arxiv_id": "2512.05334v1",
      "title": "The Effect of Document Summarization on LLM-Based Relevance Judgments",
      "title_zh": "æ–‡æ¡£æ‘˜è¦å¯¹åŸºäºå¤§è¯­è¨€æ¨¡å‹ç›¸å…³æ€§åˆ¤å®šçš„å½±å“",
      "authors": [
        "Samaneh Mohtadi",
        "Kevin Roitero",
        "Stefano Mizzaro",
        "Gianluca Demartini"
      ],
      "abstract": "Relevance judgments are central to the evaluation of Information Retrieval (IR) systems, but obtaining them from human annotators is costly and time-consuming. Large Language Models (LLMs) have recently been proposed as automated assessors, showing promising alignment with human annotations. Most prior studies have treated documents as fixed units, feeding their full content directly to LLM assessors. We investigate how text summarization affects the reliability of LLM-based judgments and their downstream impact on IR evaluation. Using state-of-the-art LLMs across multiple TREC collections, we compare judgments made from full documents with those based on LLM-generated summaries of different lengths. We examine their agreement with human labels, their effect on retrieval effectiveness evaluation, and their influence on IR systems' ranking stability. Our findings show that summary-based judgments achieve comparable stability in systems' ranking to full-document judgments, while introducing systematic shifts in label distributions and biases that vary by model and dataset. These results highlight summarization as both an opportunity for more efficient large-scale IR evaluation and a methodological choice with important implications for the reliability of automatic judgments.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æ¢è®¨äº†æ–‡æœ¬æ‘˜è¦(Text Summarization)å¯¹åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLMs)çš„ç›¸å…³æ€§åˆ¤åˆ«(Relevance Judgments)å¯é æ€§åŠå…¶å¯¹ä¿¡æ¯æ£€ç´¢(IR)è¯„ä¼°çš„å½±å“ã€‚ç ”ç©¶å›¢é˜Ÿä½¿ç”¨å¤šç§æœ€å…ˆè¿›çš„LLMsåœ¨å¤šä¸ªTRECé›†åˆä¸Šï¼Œå¯¹æ¯”äº†åŸºäºæ–‡æ¡£å…¨æ–‡çš„åˆ¤æ–­ä¸åŸºäºä¸åŒé•¿åº¦æ‘˜è¦çš„åˆ¤æ–­æ•ˆæœã€‚å®éªŒé‡ç‚¹åˆ†æäº†è‡ªåŠ¨åˆ¤æ–­ä¸äººå·¥æ ‡ç­¾çš„ä¸€è‡´æ€§ã€å¯¹æ£€ç´¢æœ‰æ•ˆæ€§è¯„ä¼°çš„å½±å“ï¼Œä»¥åŠå¯¹ç³»ç»Ÿæ’åç¨³å®šæ€§çš„ä½œç”¨ã€‚ç ”ç©¶å‘ç°ï¼ŒåŸºäºæ‘˜è¦çš„åˆ¤æ–­åœ¨ç»´æŒç³»ç»Ÿæ’åç¨³å®šæ€§æ–¹é¢ä¸å…¨æ–‡åˆ¤æ–­è¡¨ç°ç›¸å½“ï¼Œä½†ä¹Ÿä¼šå¼•å…¥æ ‡ç­¾åˆ†å¸ƒçš„ç³»ç»Ÿæ€§åç§»å’Œåå·®ï¼Œä¸”è¿™äº›åå·®éšæ¨¡å‹å’Œæ•°æ®é›†çš„ä¸åŒè€Œæœ‰æ‰€å·®å¼‚ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œåˆ©ç”¨æ‘˜è¦è¿›è¡Œå¤§è§„æ¨¡IRè¯„ä¼°è™½ç„¶èƒ½æ˜¾è‘—æé«˜æ•ˆç‡ï¼Œä½†å…¶ä½œä¸ºä¸€ç§æ–¹æ³•è®ºé€‰æ‹©ï¼Œå¯¹è‡ªåŠ¨åˆ¤å®šç»“æœçš„å¯é æ€§å…·æœ‰å¤æ‚çš„å½±å“ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.05334v1",
      "published_date": "2025-12-05 00:26:13 UTC",
      "updated_date": "2025-12-05 00:26:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:11:26.080278+00:00"
    },
    {
      "arxiv_id": "2512.05325v1",
      "title": "LYNX: Learning Dynamic Exits for Confidence-Controlled Reasoning",
      "title_zh": "LYNXï¼šé¢å‘ç½®ä¿¡åº¦å—æ§æ¨ç†çš„åŠ¨æ€é€€å‡ºå­¦ä¹ ",
      "authors": [
        "Ã–mer Faruk AkgÃ¼l",
        "Yusuf Hakan KalaycÄ±",
        "Rajgopal Kannan",
        "Willie Neiswanger",
        "Viktor Prasanna"
      ],
      "abstract": "Large reasoning models achieve strong performance on complex tasks by generating extended chains of thought, but they often \"overthink\": continuing to reason long after they have enough information to answer correctly. This wastes inference-time compute and can hurt accuracy. Existing attempts to stop early either manipulate decoding with extra sampling and heuristics, rely on auxiliary verifier models, or operate only as post-hoc analysis pipelines without formal guarantees. We introduce LYNX, an online early-exit mechanism that turns a model's own hidden-state awareness into confidence-controlled stopping decisions. LYNX attaches exit decisions to naturally occurring reasoning cues (e.g., \"hmm\", \"wait\") during generation, trains a lightweight probe on hidden states at those cue tokens using supervision from forced exits, and wraps the resulting scores in split conformal prediction to obtain distribution-free control over premature exits. Crucially, we train and calibrate this probe once on a generic mathematical corpus and reuse it unchanged across benchmarks, decoding temperatures, and even non-mathematical tasks. Across three model families spanning 1.5B to 32B parameters, a single mathematically trained probe per base model yields strong accuracy--efficiency tradeoffs. On GSM8K, LYNX matches or improves baseline accuracy while reducing tokens by 40--65\\%; on MATH-500 it improves accuracy by up to 12 points with roughly 35--60\\% fewer tokens; on AIME 2024 it recovers baseline accuracy with more than 50\\% token savings; and on CommonsenseQA, a non-math benchmark, it transfers zero-shot with modest accuracy gains and up to 70\\% fewer tokens. Compared to state-of-the-art early-exit methods, LYNX offers competitive or superior Pareto frontiers while remaining fully online, requiring no proxy models at inference, and providing explicit, user-tunable confidence guarantees.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† LYNXï¼Œä¸€ç§åœ¨çº¿æ—©é€€ (early-exit) æœºåˆ¶ï¼Œæ—¨åœ¨è§£å†³å¤§å‹æ¨ç†æ¨¡å‹åœ¨å¤„ç†å¤æ‚ä»»åŠ¡æ—¶å› â€œè¿‡åº¦æ€è€ƒâ€ (overthinking) å¯¼è‡´çš„æ¨ç†è®¡ç®—æµªè´¹åŠå‡†ç¡®ç‡ä¸‹é™é—®é¢˜ã€‚LYNX åˆ©ç”¨æ¨¡å‹è‡ªèº«çš„éšè—çŠ¶æ€æ„ŸçŸ¥èƒ½åŠ›ï¼Œå°†é€€å‡ºå†³ç­–ä¸ç”Ÿæˆè¿‡ç¨‹ä¸­çš„è‡ªç„¶æ¨ç†æç¤ºç›¸ç»“åˆï¼Œå¹¶é€šè¿‡åœ¨è¿™äº›æç¤ºè¯çš„éšè—çŠ¶æ€ä¸Šè®­ç»ƒè½»é‡çº§æ¢é’ˆ (probe) æ¥å®ç°ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†æ‹†åˆ†ä¿å½¢é¢„æµ‹ (split conformal prediction) æŠ€æœ¯ï¼Œä¸ºé˜²æ­¢è¿‡æ—©é€€å‡ºæä¾›äº†åˆ†å¸ƒæ— å…³ (distribution-free) çš„ç½®ä¿¡åº¦æ§åˆ¶ä¿è¯ã€‚å®éªŒè¡¨æ˜ï¼Œåœ¨é€šç”¨æ•°å­¦è¯­æ–™åº“ä¸Šè®­ç»ƒçš„æ¢é’ˆå¯è·¨åŸºå‡†ã€è§£ç æ¸©åº¦ç”šè‡³æ˜¯éæ•°å­¦ä»»åŠ¡ç›´æ¥å¤ç”¨ã€‚åœ¨ GSM8K å’Œ MATH-500 ç­‰æµ‹è¯•ä¸­ï¼ŒLYNX åœ¨æ˜¾è‘—æå‡å‡†ç¡®ç‡çš„åŒæ—¶ï¼ŒæˆåŠŸå‡å°‘äº† 40% è‡³ 70% çš„ Token ç”Ÿæˆã€‚ç›¸æ¯”ç°æœ‰æ–¹æ³•ï¼ŒLYNX æ— éœ€æ¨ç†ä¾§ä»£ç†æ¨¡å‹ä¸”å®Œå…¨åœ¨çº¿è¿è¡Œï¼Œå®ç°äº†æ›´ä¼˜çš„å¸•ç´¯æ‰˜å‰æ²¿ (Pareto frontiers) ä¸ç”¨æˆ·å¯è°ƒçš„å¯é æ€§ä¿éšœã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.05325v1",
      "published_date": "2025-12-05 00:04:42 UTC",
      "updated_date": "2025-12-05 00:04:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T14:11:35.906845+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 144,
  "processed_papers_count": 144,
  "failed_papers_count": 0,
  "llm_backup_calls": 2,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-01-26T14:13:04.164642+00:00"
}