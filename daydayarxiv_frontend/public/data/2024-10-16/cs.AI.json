{
  "date": "2024-10-16",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-10-16 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 模型的优化、安全和应用，特别是大型语言模型 (LLMs) 的 hallucination 问题、多代理系统和强化学习在机器人决策中的进展，以及图像生成和知识图谱推理等领域的创新方法，其中 LLM 代理的主动性提升和多模态数据处理的相关研究令人印象深刻，同时有知名学者如 David M. Blei 和 Ion Stoica 的参与。\n\n下面，我将挑选几篇重要的论文进行详细讨论，先从 LLM 相关和多代理系统的热点入手，再快速概述其他值得注意的论文。其他较常规或不那么影响深远的论文（如一些特定领域的技术优化），我会简要掠过，只列出标题和核心点，以控制篇幅。\n\n### 重点论文讨论\n\n**1. Large Language Model-driven Multi-Agent Simulation for News Diffusion Under Different Network Structures（大型语言模型驱动的多代理模拟：用于不同网络结构下的新闻传播）**  \n这篇论文由 Yongfeng Zhang 等作者提出，利用 LLM 构建多代理模拟框架，研究新闻传播中的假新闻问题。主要贡献是通过 LLM 驱动代理模拟复杂信息生态，分析代理个性和网络结构对传播的影响，并评估反假新闻策略（如阻断关键代理或公布新闻准确性）。发现 LLM 模拟比传统方法更能揭示传播动态，并在不同网络结构下验证策略有效性。该工作对 AI 在社会影响评估中的应用有重要启示，尤其在假新闻防控领域。\n\n**2. Reverse-Engineering the Reader（逆向工程读者）**  \n作者包括 Ethan Gotlieb Wilcox 和 Ryan Cotterell 等知名学者，这篇论文探索优化语言模型以预测人类阅读时间。主要发现是通过微调模型与线性回归器对齐人类数据，提高了心理预测能力，但也暴露了在 NLP 任务和困惑度上的权衡。该研究首次通过操纵模型对心理数据的对齐来诱导这种趋势，为 LLM 在认知建模中的应用提供了新视角。\n\n**3. Hypothesis Testing the Circuit Hypothesis in LLMs（测试 LLM 中的电路假设）**  \nDavid M. Blei 等作者参与，这篇论文验证 LLM 中子网络（电路）的假设，提出一组假设测试标准。主要贡献是开发了 circuitry 包，用于评估电路的局部性和最小性，发现合成的电路更符合理想属性。该工作为 LLM 的内部机制研究提供了工具和见解，提升了模型可解释性。\n\n**4. JudgeBench: A Benchmark for Evaluating LLM-based Judges（JudgeBench：评估 LLM 判别器的基准）**  \nIon Stoica 等作者构建了一个新基准，用于评估 LLM 在复杂任务中的判别能力。主要发现是现有 LLM 在知识、推理和编码任务上表现不佳，甚至不如随机猜测。该基准揭示了 LLM 判别器的局限性，并为未来研究提供了数据集，推动了 LLM 评估的标准化。\n\n**5. Language Models as Semiotic Machines: Reconceptualizing AI Language Systems through Structuralist and Post-Structuralist Theories of Language（语言模型作为符号机器：通过结构主义和后结构主义理论重新概念化 AI 语言系统）**  \n这篇理论性强的论文由 Elad Vromen 撰写，将语言模型视为符号系统，使用 Saussure 和 Derrida 的理论分析 LLM 的语义行为。主要贡献是提出 LLM 更像统计符号模型，而非认知模拟，提供了一个新框架评估 LLM 的优势和局限。该工作在 AI 哲学层面有话题度。\n\n**6. FedGTST: Boosting Global Transferability of Federated Models via Statistics Tuning（FedGTST：通过统计调整提升联邦模型的全局可转移性）**  \n论文引入了新的联邦学习框架，优化模型转移性。主要发现是通过雅可比范数调整，提升了模型在非独立同分布数据上的鲁棒性，并在实验中超越基线。该方法对隐私保护的联邦学习有实际应用价值。\n\n**7. Reinforcement Learning with Euclidean Data Augmentation for State-Based Continuous Control（使用欧氏数据增强的强化学习：针对基于状态的连续控制）**  \n这篇论文提出欧氏数据增强策略，用于状态-based 连续控制任务。主要贡献是改进了强化学习的效率和性能，实验显示在机器人任务中显著提升准确性。该工作扩展了强化学习在真实世界应用的潜力。\n\n其他相关论文，如那些探讨 LLM 代理和多代理系统的（如论文 14、19、74、84），都强化了 AI 在动态环境中的决策能力，但细节上较为相似，我这里就不再展开。\n\n### 快速掠过其他论文\n以下是今天其他值得一提的论文，我会简要列出标题（中文 + 英文）和核心贡献，优先选取有创新点或实际应用的：\n\n- **Task Consistent Prototype Learning for Incremental Few-shot Semantic Segmentation（任务一致的原型学习：用于增量少样本语义分割）**：提出元学习方法提升模型适应新类别的能力，实验在 PASCAL 和 COCO 上表现优异。\n  \n- **FedCAP: Robust Federated Learning via Customized Aggregation and Personalization（FedCAP：通过自定义聚合和个性化实现鲁棒联邦学习）**：解决联邦学习中的非独立分布和恶意攻击问题，实验显示在非 IID 设置下鲁棒性强。\n  \n- **Tuning Language Models by Mixture-of-Depths Ensemble（通过深度混合集成调整语言模型）**：引入混合深度框架优化 LLM 训练，减少参数量同时提升性能。\n  \n- **ERAS: Evaluating the Robustness of Chinese NLP Models to Morphological Garden Path Errors（ERAS：评估中文 NLP 模型对形态歧义的鲁棒性）**：测试中文模型对词法歧义的鲁棒性，发现需改进语境处理。\n  \n- **Flex: End-to-End Text-Instructed Visual Navigation from Foundation Model Features（Flex：基于基础模型特征的端到端文本指导视觉导航）**：使用预训练模型实现文本指导的机器人导航，实验验证了鲁棒性。\n  \n- **LEGAL-UQA: A Low-Resource Urdu-English Dataset for Legal Question Answering（LEGAL-UQA：用于法律问答的低资源乌尔都-英语数据集）**：发布新数据集，提升低资源语言的法律 QA 性能。\n  \n- **Qtok: A Comprehensive Framework for Evaluating Multilingual Tokenizer Quality in Large Language Models（Qtok：评估多语言标记器质量的全面框架）**：提出评估工具，揭示多语言 LLM 中的标记偏差。\n  \n- **Harmon: Whole-Body Motion Generation of Humanoid Robots from Language Descriptions（Harmon：从语言描述生成人形机器人全身运动）**：使用 LLM 生成机器人运动，实验证明了真实性和准确性。\n  \n- **ShapefileGPT: A Novel Approach for the Automated Evaluation of Open-Ended Question Generation（ShapefileGPT：用于自动评估开放式问题生成的创新方法）**：利用 LLM 优化地理数据处理，提供高效工具。\n\n其他论文，如一些图像处理或特定领域优化（如量子计算、材料科学），贡献虽稳固但不具突破性，我这里就不再详细描述了，例如 **Channel-Wise Mixed-Precision Quantization for Large Language Models（通道-wise 混合精度量化用于大型语言模型）** 主要提升了模型量化效率，但对整体 AI 生态影响有限。\n\n总之，今天的论文展示了 AI 模型在安全、效率和应用上的持续进步，但也暴露了 hallucination 和泛化问题的挑战。欢迎读者关注这些前沿动态！",
  "papers": [
    {
      "arxiv_id": "2410.13909v1",
      "title": "Large Language Model-driven Multi-Agent Simulation for News Diffusion Under Different Network Structures",
      "title_zh": "大语言模型驱动的多智能体模拟，用于不同网络结构下的新闻扩散",
      "authors": [
        "Xinyi Li",
        "Yu Xu",
        "Yongfeng Zhang",
        "Edward C. Malthouse"
      ],
      "abstract": "The proliferation of fake news in the digital age has raised critical\nconcerns, particularly regarding its impact on societal trust and democratic\nprocesses. Diverging from conventional agent-based simulation approaches, this\nwork introduces an innovative approach by employing a large language model\n(LLM)-driven multi-agent simulation to replicate complex interactions within\ninformation ecosystems. We investigate key factors that facilitate news\npropagation, such as agent personalities and network structures, while also\nevaluating strategies to combat misinformation. Through simulations across\nvarying network structures, we demonstrate the potential of LLM-based agents in\nmodeling the dynamics of misinformation spread, validating the influence of\nagent traits on the diffusion process. Our findings emphasize the advantages of\nLLM-based simulations over traditional techniques, as they uncover underlying\ncauses of information spread -- such as agents promoting discussions -- beyond\nthe predefined rules typically employed in existing agent-based models.\nAdditionally, we evaluate three countermeasure strategies, discovering that\nbrute-force blocking influential agents in the network or announcing news\naccuracy can effectively mitigate misinformation. However, their effectiveness\nis influenced by the network structure, highlighting the importance of\nconsidering network structure in the development of future misinformation\ncountermeasures.",
      "tldr_zh": "本文提出了一种基于 Large Language Model (LLM) 驱动的多智能体模拟方法，用于研究不同网络结构下新闻传播动态，特别是假新闻对社会信任和民主进程的影响。该方法超越传统代理模拟，通过考察代理人格和网络结构，揭示了信息传播的底层原因，如代理促进讨论，并证明 LLM 代理在建模误信息扩散方面更具优势。研究评估了三种反制策略，包括阻断影响代理和宣布新闻准确性，发现这些策略的有效性取决于网络结构。总体而言，该工作强调了在设计未来误信息对策时考虑网络结构的重要性。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13909v1",
      "published_date": "2024-10-16 23:58:26 UTC",
      "updated_date": "2024-10-16 23:58:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:06:38.742435"
    },
    {
      "arxiv_id": "2410.13094v1",
      "title": "Task Consistent Prototype Learning for Incremental Few-shot Semantic Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Wenbo Xu",
        "Yanan Wu",
        "Haoran Jiang",
        "Yang Wang",
        "Qiang Wu",
        "Jian Zhang"
      ],
      "abstract": "Incremental Few-Shot Semantic Segmentation (iFSS) tackles a task that\nrequires a model to continually expand its segmentation capability on novel\nclasses using only a few annotated examples. Typical incremental approaches\nencounter a challenge that the objective of the base training phase (fitting\nbase classes with sufficient instances) does not align with the incremental\nlearning phase (rapidly adapting to new classes with less forgetting). This\ndisconnect can result in suboptimal performance in the incremental setting.\nThis study introduces a meta-learning-based prototype approach that encourages\nthe model to learn how to adapt quickly while preserving previous knowledge.\nConcretely, we mimic the incremental evaluation protocol during the base\ntraining session by sampling a sequence of pseudo-incremental tasks. Each task\nin the simulated sequence is trained using a meta-objective to enable rapid\nadaptation without forgetting. To enhance discrimination among class\nprototypes, we introduce prototype space redistribution learning, which\ndynamically updates class prototypes to establish optimal inter-prototype\nboundaries within the prototype space. Extensive experiments on iFSS datasets\nbuilt upon PASCAL and COCO benchmarks show the advanced performance of the\nproposed approach, offering valuable insights for addressing iFSS challenges.",
      "tldr_zh": "该研究针对 Incremental Few-shot Semantic Segmentation (iFSS) 的挑战，提出一种任务一致的原型学习方法，以解决基训练阶段与增量学习阶段目标不一致的问题。方法基于 meta-learning，通过在基训练中模拟伪增量任务序列，并使用元目标训练模型，以实现快速适应新类同时保留既有知识；此外，引入 prototype space redistribution learning 动态更新类原型，优化原型间边界以提升类别区分度。在 PASCAL 和 COCO 基准数据集上的广泛实验中，该方法显著提高了 iFSS 性能，并为该领域提供宝贵见解。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "conference",
      "pdf_url": "http://arxiv.org/pdf/2410.13094v1",
      "published_date": "2024-10-16 23:42:27 UTC",
      "updated_date": "2024-10-16 23:42:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:06:49.564107"
    },
    {
      "arxiv_id": "2410.13086v1",
      "title": "Reverse-Engineering the Reader",
      "title_zh": "翻译失败",
      "authors": [
        "Samuel Kiegeland",
        "Ethan Gotlieb Wilcox",
        "Afra Amini",
        "David Robert Reich",
        "Ryan Cotterell"
      ],
      "abstract": "Numerous previous studies have sought to determine to what extent language\nmodels, pretrained on natural language text, can serve as useful models of\nhuman cognition. In this paper, we are interested in the opposite question:\nwhether we can directly optimize a language model to be a useful cognitive\nmodel by aligning it to human psychometric data. To achieve this, we introduce\na novel alignment technique in which we fine-tune a language model to\nimplicitly optimize the parameters of a linear regressor that directly predicts\nhumans' reading times of in-context linguistic units, e.g., phonemes,\nmorphemes, or words, using surprisal estimates derived from the language model.\nUsing words as a test case, we evaluate our technique across multiple model\nsizes and datasets and find that it improves language models' psychometric\npredictive power. However, we find an inverse relationship between psychometric\npower and a model's performance on downstream NLP tasks as well as its\nperplexity on held-out test data. While this latter trend has been observed\nbefore (Oh et al., 2022; Shain et al., 2024), we are the first to induce it by\nmanipulating a model's alignment to psychometric data.",
      "tldr_zh": "这篇论文探讨了反向优化语言模型（language models）以模拟人类认知的问题，具体通过一种新颖的 alignment technique 微调模型，使其隐式优化一个线性回归器，用 surprisal estimates 预测人类对上下文语言单元（如音素、词素或单词）的阅读时间。研究在多个模型大小和数据集上测试了这一方法，发现它显著提高了语言模型的 psychometric predictive power。实验结果显示，这种优化虽然提升了心理测量预测能力，但会导致模型在下游 NLP tasks 的性能和 perplexity 上下降，这是首次通过操纵模型对 psychometric 数据对齐来诱导这一负相关趋势。总的来说，该工作为语言模型在认知建模中的应用提供了新见解，但也突显了性能权衡的问题。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13086v1",
      "published_date": "2024-10-16 23:05:01 UTC",
      "updated_date": "2024-10-16 23:05:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:07:05.554746"
    },
    {
      "arxiv_id": "2410.13083v1",
      "title": "FedCAP: Robust Federated Learning via Customized Aggregation and Personalization",
      "title_zh": "翻译失败",
      "authors": [
        "Youpeng Li",
        "Xinda Wang",
        "Fuxun Yu",
        "Lichao Sun",
        "Wenbin Zhang",
        "Xuyu Wang"
      ],
      "abstract": "Federated learning (FL), an emerging distributed machine learning paradigm,\nhas been applied to various privacy-preserving scenarios. However, due to its\ndistributed nature, FL faces two key issues: the non-independent and identical\ndistribution (non-IID) of user data and vulnerability to Byzantine threats. To\naddress these challenges, in this paper, we propose FedCAP, a robust FL\nframework against both data heterogeneity and Byzantine attacks. The core of\nFedCAP is a model update calibration mechanism to help a server capture the\ndifferences in the direction and magnitude of model updates among clients.\nFurthermore, we design a customized model aggregation rule that facilitates\ncollaborative training among similar clients while accelerating the model\ndeterioration of malicious clients. With a Euclidean norm-based anomaly\ndetection mechanism, the server can quickly identify and permanently remove\nmalicious clients. Moreover, the impact of data heterogeneity and Byzantine\nattacks can be further mitigated through personalization on the client side. We\nconduct extensive experiments, comparing multiple state-of-the-art baselines,\nto demonstrate that FedCAP performs well in several non-IID settings and shows\nstrong robustness under a series of poisoning attacks.",
      "tldr_zh": "本研究提出 FedCAP，一种针对 Federated Learning (FL) 的鲁棒框架，用于应对数据非独立同分布 (non-IID) 和 Byzantine 威胁问题。FedCAP 的核心机制包括模型更新校准、自定义模型聚合规则以及基于欧氏范数的异常检测，以识别并移除恶意客户端，同时通过客户端个性化进一步缓解数据异质性和攻击影响。实验结果显示，FedCAP 在多种 non-IID 设置下优于现有基线模型，并在各种投毒攻击中表现出强鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 12 figures, 5 tables, accepted by 2024 Annual Computer\n  Security Applications Conference (ACSAC 2024)",
      "pdf_url": "http://arxiv.org/pdf/2410.13083v1",
      "published_date": "2024-10-16 23:01:22 UTC",
      "updated_date": "2024-10-16 23:01:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:07:14.583743"
    },
    {
      "arxiv_id": "2410.13077v1",
      "title": "Tuning Language Models by Mixture-of-Depths Ensemble",
      "title_zh": "通过 Mixture-of-Depths Ensemble 微调语言模型",
      "authors": [
        "Haoyan Luo",
        "Lucia Specia"
      ],
      "abstract": "Transformer-based Large Language Models (LLMs) traditionally rely on\nfinal-layer loss for training and final-layer representations for predictions,\npotentially overlooking the predictive power embedded in intermediate layers.\nSurprisingly, we find that focusing training efforts on these intermediate\nlayers can yield training losses comparable to those of final layers, with\ncomplementary test-time performance. We introduce a novel tuning framework,\nMixture-of-Depths (MoD), which trains late layers as ensembles contributing to\nthe final logits through learned routing weights. With the auxiliary\ndistillation loss and additional normalization modules, we ensure that the\noutputs of the late layers adapt to language modeling. Our MoD framework, which\ncan be integrated with any existing tuning method, shows consistent improvement\non various language modelling tasks. Furthermore, by replacing traditional\ntrainable modules with MoD, our approach achieves similar performance with\nsignificantly fewer trainable parameters, demonstrating the potential of\nleveraging predictive power from intermediate representations during training.",
      "tldr_zh": "该研究发现，Transformer-based Large Language Models (LLMs) 传统上仅依赖最终层的损失和表示，忽略了中间层的预测潜力，而专注于中间层训练可获得相媲美的损失和互补性能。作者提出Mixture-of-Depths (MoD)框架，将后期层训练为集成，通过学到的路由权重贡献到最终logits，并结合辅助蒸馏损失和归一化模块，使输出适应语言建模。该框架可与现有调优方法整合，在各种语言建模任务上实现一致改进，同时通过替换传统模块，以显著更少的可训练参数达到类似性能，展示了利用中间表示的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13077v1",
      "published_date": "2024-10-16 22:51:45 UTC",
      "updated_date": "2024-10-16 22:51:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:07:26.274920"
    },
    {
      "arxiv_id": "2410.13065v1",
      "title": "Language Models as Semiotic Machines: Reconceptualizing AI Language Systems through Structuralist and Post-Structuralist Theories of Language",
      "title_zh": "语言模型作为符号学机器：通过结构主义和后结构主义语言理论重新概念化 AI 语言系统",
      "authors": [
        "Elad Vromen"
      ],
      "abstract": "This paper proposes a novel framework for understanding large language models\n(LLMs) by reconceptualizing them as semiotic machines rather than as imitations\nof human cognition. Drawing from structuralist and post-structuralist theories\nof language-specifically the works of Ferdinand de Saussure and Jacques\nDerrida-I argue that LLMs should be understood as models of language itself,\naligning with Derrida's concept of 'writing' (l'ecriture). The paper is\nstructured into three parts. First, I lay the theoretical groundwork by\nexplaining how the word2vec embedding algorithm operates within Saussure's\nframework of language as a relational system of signs. Second, I apply\nDerrida's critique of Saussure to position 'writing' as the object modeled by\nLLMs, offering a view of the machine's 'mind' as a statistical approximation of\nsign behavior. Finally, the third section addresses how modern LLMs reflect\npost-structuralist notions of unfixed meaning, arguing that the \"next token\ngeneration\" mechanism effectively captures the dynamic nature of meaning. By\nreconceptualizing LLMs as semiotic machines rather than cognitive models, this\nframework provides an alternative lens through which to assess the strengths\nand limitations of LLMs, offering new avenues for future research.",
      "tldr_zh": "这篇论文提出一个新框架，将大型语言模型(LLMs)重新概念化为符号机器，而不是人类认知的模仿，借鉴结构主义理论家Saussure和后结构主义理论家Derrida的作品。论文首先解释word2vec嵌入算法如何符合Saussure的语言符号系统框架，其次应用Derrida的“写作”(l'ecriture)概念，将LLMs视为语言行为的统计近似模型。最终，它探讨LLMs的“下一个标记生成”机制如何捕捉意义的不固定性，从而为评估LLMs的优缺点提供新视角，并为未来研究开辟路径。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.13065v1",
      "published_date": "2024-10-16 21:45:54 UTC",
      "updated_date": "2024-10-16 21:45:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:07:38.973569"
    },
    {
      "arxiv_id": "2410.13061v2",
      "title": "Optimal Transport for Probabilistic Circuits",
      "title_zh": "概率电路的最优传输",
      "authors": [
        "Adrian Ciotinga",
        "YooJung Choi"
      ],
      "abstract": "We introduce a novel optimal transport framework for probabilistic circuits\n(PCs). While it has been shown recently that divergences between distributions\nrepresented as certain classes of PCs can be computed tractably, to the best of\nour knowledge, there is no existing approach to compute the Wasserstein\ndistance between probability distributions given by PCs. We propose a\nWasserstein-type distance that restricts the coupling measure of the associated\noptimal transport problem to be a probabilistic circuit. We then develop an\nalgorithm for computing this distance by solving a series of small linear\nprograms and derive the circuit conditions under which this is tractable.\nFurthermore, we show that we can easily retrieve the optimal transport plan\nbetween the PCs from the solutions to these linear programs. Lastly, we study\nthe empirical Wasserstein distance between a PC and a dataset, and show that we\ncan estimate the PC parameters to minimize this distance through an efficient\niterative algorithm.",
      "tldr_zh": "该研究引入了一种新的 Optimal Transport 框架，应用于 Probabilistic Circuits (PCs)，以计算 PCs 之间尚未解决的 Wasserstein 距离问题。作者提出了一种 Wasserstein-type 距离，将耦合测度限制为 PCs，并开发了通过解决一系列小规模线性程序的算法，实现高效计算，同时推导出使之可计算的电路条件。实验结果显示，该方法能从线性程序解中获取最优传输计划，并通过高效迭代算法估计 PC 参数，以最小化 PCs 与数据集之间的经验 Wasserstein 距离。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "math.OC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13061v2",
      "published_date": "2024-10-16 21:42:16 UTC",
      "updated_date": "2025-03-07 20:03:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:07:50.477180"
    },
    {
      "arxiv_id": "2410.13057v1",
      "title": "ERAS: Evaluating the Robustness of Chinese NLP Models to Morphological Garden Path Errors",
      "title_zh": "翻译失败",
      "authors": [
        "Qinchan Li",
        "Sophie Hao"
      ],
      "abstract": "In languages without orthographic word boundaries, NLP models perform word\nsegmentation, either as an explicit preprocessing step or as an implicit step\nin an end-to-end computation. This paper shows that Chinese NLP models are\nvulnerable to morphological garden path errors: errors caused by a failure to\nresolve local word segmentation ambiguities using sentence-level\nmorphosyntactic context. We propose a benchmark, ERAS, that tests a model's\nvulnerability to morphological garden path errors by comparing its behavior on\nsentences with and without local segmentation ambiguities. Using ERAS, we show\nthat word segmentation models make garden path errors on locally ambiguous\nsentences, but do not make equivalent errors on unambiguous sentences. We\nfurther show that sentiment analysis models with character-level tokenization\nmake implicit garden path errors, even without an explicit word segmentation\nstep in the pipeline. Our results indicate that models' segmentation of Chinese\ntext often fails to account for morphosyntactic context.",
      "tldr_zh": "该论文评估了中文NLP模型对形态garden path errors的鲁棒性，这些错误源于模型无法利用句子级形态语法上下文解决局部词分割歧义。研究提出ERAS基准，通过比较有局部分割歧义和无歧义句子的模型行为来测试模型性能。实验结果显示，词分割模型在歧义句子中易犯garden path errors，而无歧义句子则较少出错；此外，使用字符级标记化的情感分析模型也会出现隐式garden path errors。总体而言，该研究揭示了中文NLP模型在处理文本时往往忽略形态语法上下文，从而为提升模型鲁棒性提供了重要见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Under review in ARR/NAACL",
      "pdf_url": "http://arxiv.org/pdf/2410.13057v1",
      "published_date": "2024-10-16 21:35:20 UTC",
      "updated_date": "2024-10-16 21:35:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:08:02.125290"
    },
    {
      "arxiv_id": "2410.13056v3",
      "title": "Channel-Wise Mixed-Precision Quantization for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zihan Chen",
        "Bike Xie",
        "Jundong Li",
        "Cong Shen"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable success across a\nwide range of language tasks, but their deployment on edge devices remains\nchallenging due to the substantial memory requirements imposed by their large\nparameter sizes. Weight-only quantization presents a promising solution to\nreduce the memory footprint of LLMs. However, existing approaches primarily\nfocus on integer-bit quantization, limiting their adaptability to\nfractional-bit quantization tasks and preventing the full utilization of\navailable storage space on devices. In this paper, we introduce Channel-Wise\nMixed-Precision Quantization (CMPQ), a novel mixed-precision quantization\nmethod that allocates quantization precision in a channel-wise pattern based on\nactivation distributions. By assigning different precision levels to different\nweight channels, CMPQ can adapt to any bit-width constraint. CMPQ employs a\nnon-uniform quantization strategy and incorporates two outlier extraction\ntechniques that collaboratively preserve the critical information, thereby\nminimizing the quantization loss. Experiments on different sizes of LLMs\ndemonstrate that CMPQ not only enhances performance in integer-bit quantization\ntasks but also achieves significant performance gains with a modest increase in\nmemory usage. CMPQ thus represents an adaptive and effective approach to LLM\nquantization, offering substantial benefits across diverse device capabilities.",
      "tldr_zh": "本研究针对Large Language Models (LLMs)的内存需求问题，提出了一种新型量化方法Channel-Wise Mixed-Precision Quantization (CMPQ)，通过基于激活分布的通道级精度分配，实现对任何位宽约束的适应性量化。CMPQ采用非均匀量化策略并结合两种异常值提取技术，以最小化量化损失并保留关键信息。实验结果显示，在不同规模的LLMs上，CMPQ不仅在整数位量化任务中提升性能，还在内存使用适度增加的情况下实现了显著性能改进，为LLMs在边缘设备上的部署提供了高效解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13056v3",
      "published_date": "2024-10-16 21:34:41 UTC",
      "updated_date": "2025-02-03 21:48:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:08:14.440094"
    },
    {
      "arxiv_id": "2410.13054v2",
      "title": "Systems with Switching Causal Relations: A Meta-Causal Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Moritz Willig",
        "Tim Nelson Tobiasch",
        "Florian Peter Busch",
        "Jonas Seng",
        "Devendra Singh Dhami",
        "Kristian Kersting"
      ],
      "abstract": "Most work on causality in machine learning assumes that causal relationships\nare driven by a constant underlying process. However, the flexibility of\nagents' actions or tipping points in the environmental process can change the\nqualitative dynamics of the system. As a result, new causal relationships may\nemerge, while existing ones change or disappear, resulting in an altered causal\ngraph. To analyze these qualitative changes on the causal graph, we propose the\nconcept of meta-causal states, which groups classical causal models into\nclusters based on equivalent qualitative behavior and consolidates specific\nmechanism parameterizations. We demonstrate how meta-causal states can be\ninferred from observed agent behavior, and discuss potential methods for\ndisentangling these states from unlabeled data. Finally, we direct our analysis\ntowards the application of a dynamical system, showing that meta-causal states\ncan also emerge from inherent system dynamics, and thus constitute more than a\ncontext-dependent framework in which mechanisms emerge only as a result of\nexternal factors.",
      "tldr_zh": "该论文从元因果（meta-causal）视角分析了因果关系切换的系统，挑战了传统假设中因果关系由恒定过程驱动的观点，而是强调代理行为或环境变化可能导致因果图（causal graph）的动态改变。作者提出meta-causal states的概念，将经典因果模型基于等价定性行为分组，并整合机制参数化，从而从观察到的代理行为中推断这些状态，并探讨从无标签数据中分离它们的方法。实验和分析显示，meta-causal states不仅源于外部因素，还可从系统固有动态中自然出现，为处理复杂动态系统提供了新框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "21 pages, 3 figures, 4 tables, ICLR 2025 Camera Ready Version",
      "pdf_url": "http://arxiv.org/pdf/2410.13054v2",
      "published_date": "2024-10-16 21:32:31 UTC",
      "updated_date": "2025-04-17 07:48:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:08:26.012242"
    },
    {
      "arxiv_id": "2410.13045v1",
      "title": "FedGTST: Boosting Global Transferability of Federated Models via Statistics Tuning",
      "title_zh": "FedGTST：通过统计调整提升联邦模型的全局可转移性",
      "authors": [
        "Evelyn Ma",
        "Chao Pan",
        "Rasoul Etesami",
        "Han Zhao",
        "Olgica Milenkovic"
      ],
      "abstract": "The performance of Transfer Learning (TL) heavily relies on effective\npretraining, which demands large datasets and substantial computational\nresources. As a result, executing TL is often challenging for individual model\ndevelopers. Federated Learning (FL) addresses these issues by facilitating\ncollaborations among clients, expanding the dataset indirectly, distributing\ncomputational costs, and preserving privacy. However, key challenges remain\nunresolved. First, existing FL methods tend to optimize transferability only\nwithin local domains, neglecting the global learning domain. Second, most\napproaches rely on indirect transferability metrics, which do not accurately\nreflect the final target loss or true degree of transferability. To address\nthese gaps, we propose two enhancements to FL. First, we introduce a\nclient-server exchange protocol that leverages cross-client Jacobian (gradient)\nnorms to boost transferability. Second, we increase the average Jacobian norm\nacross clients at the server, using this as a local regularizer to reduce\ncross-client Jacobian variance. Our transferable federated algorithm, termed\nFedGTST (Federated Global Transferability via Statistics Tuning), demonstrates\nthat increasing the average Jacobian and reducing its variance allows for\ntighter control of the target loss. This leads to an upper bound on the target\nloss in terms of the source loss and source-target domain discrepancy.\nExtensive experiments on datasets such as MNIST to MNIST-M and CIFAR10 to SVHN\nshow that FedGTST outperforms relevant baselines, including FedSR. On the\nsecond dataset pair, FedGTST improves accuracy by 9.8% over FedSR and 7.6% over\nFedIIR when LeNet is used as the backbone.",
      "tldr_zh": "该研究针对Federated Learning (FL) 在Transfer Learning (TL) 中的局限性，提出FedGTST算法，以提升模型的全局transferability。具体而言，FedGTST引入客户端-服务器交换协议，利用跨客户端Jacobian norms来增强transferability，并通过服务器端增加平均Jacobian norm作为本地正则化器，减少Jacobian方差，从而更好地控制目标损失并提供其上界。实验结果显示，在MNIST to MNIST-M和CIFAR10 to SVHN等数据集上，FedGTST比基线如FedSR提高准确率最高达9.8%，证明了其在资源有限场景下的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13045v1",
      "published_date": "2024-10-16 21:13:52 UTC",
      "updated_date": "2024-10-16 21:13:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:08:38.431273"
    },
    {
      "arxiv_id": "2410.13037v1",
      "title": "LFOSum: Summarizing Long-form Opinions with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Mir Tafseer Nayeem",
        "Davood Rafiei"
      ],
      "abstract": "Online reviews play a pivotal role in influencing consumer decisions across\nvarious domains, from purchasing products to selecting hotels or restaurants.\nHowever, the sheer volume of reviews -- often containing repetitive or\nirrelevant content -- leads to information overload, making it challenging for\nusers to extract meaningful insights. Traditional opinion summarization models\nface challenges in handling long inputs and large volumes of reviews, while\nnewer Large Language Model (LLM) approaches often fail to generate accurate and\nfaithful summaries. To address those challenges, this paper introduces (1) a\nnew dataset of long-form user reviews, each entity comprising over a thousand\nreviews, (2) two training-free LLM-based summarization approaches that scale to\nlong inputs, and (3) automatic evaluation metrics. Our dataset of user reviews\nis paired with in-depth and unbiased critical summaries by domain experts,\nserving as a reference for evaluation. Additionally, our novel reference-free\nevaluation metrics provide a more granular, context-sensitive assessment of\nsummary faithfulness. We benchmark several open-source and closed-source LLMs\nusing our methods. Our evaluation reveals that LLMs still face challenges in\nbalancing sentiment and format adherence in long-form summaries, though\nopen-source models can narrow the gap when relevant information is retrieved in\na focused manner.",
      "tldr_zh": "这篇论文提出了LFOSum框架，利用Large Language Models (LLM)来处理在线评论的信息过载问题，针对传统模型和LLM在总结长形式意见时的准确性和忠实度挑战。论文的主要贡献包括：一个新数据集，包含每个实体超过一千条用户评论并配有领域专家的深入批判性摘要；两种无训练的LLM-based总结方法，能高效处理长输入；以及新型的reference-free评估指标，用于更细粒度的上下文敏感评估。实验结果显示，虽然LLM在长形式摘要中仍面临平衡情感和格式遵守的困难，但开源模型通过聚焦相关信息能显著缩小与闭源模型的差距。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.ET",
        "cs.HC",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13037v1",
      "published_date": "2024-10-16 20:52:39 UTC",
      "updated_date": "2024-10-16 20:52:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:08:51.099135"
    },
    {
      "arxiv_id": "2410.13032v1",
      "title": "Hypothesis Testing the Circuit Hypothesis in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Claudia Shi",
        "Nicolas Beltran-Velez",
        "Achille Nazaret",
        "Carolina Zheng",
        "Adrià Garriga-Alonso",
        "Andrew Jesson",
        "Maggie Makar",
        "David M. Blei"
      ],
      "abstract": "Large language models (LLMs) demonstrate surprising capabilities, but we do\nnot understand how they are implemented. One hypothesis suggests that these\ncapabilities are primarily executed by small subnetworks within the LLM, known\nas circuits. But how can we evaluate this hypothesis? In this paper, we\nformalize a set of criteria that a circuit is hypothesized to meet and develop\na suite of hypothesis tests to evaluate how well circuits satisfy them. The\ncriteria focus on the extent to which the LLM's behavior is preserved, the\ndegree of localization of this behavior, and whether the circuit is minimal. We\napply these tests to six circuits described in the research literature. We find\nthat synthetic circuits -- circuits that are hard-coded in the model -- align\nwith the idealized properties. Circuits discovered in Transformer models\nsatisfy the criteria to varying degrees. To facilitate future empirical studies\nof circuits, we created the \\textit{circuitry} package, a wrapper around the\n\\textit{TransformerLens} library, which abstracts away lower-level\nmanipulations of hooks and activations. The software is available at\n\\url{https://github.com/blei-lab/circuitry}.",
      "tldr_zh": "这篇论文测试了大型语言模型(LLMs)中电路假设(circuit hypothesis)，即模型能力主要由小型子网络(circuits)实现。作者制定了评估标准，包括行为保留、行为定位(localization)和最小性(minimality)，并开发了假设测试(hypothesis tests)来评估这些电路。实验结果显示，合成电路(synthetic circuits)符合理想属性，而在Transformer模型中发现的电路则满足标准程度不一。最后，他们发布了circuitry软件包，作为TransformerLens库的包装器，以便利未来的电路研究。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.AI",
      "comment": "Code available here: https://github.com/blei-lab/circuitry",
      "pdf_url": "http://arxiv.org/pdf/2410.13032v1",
      "published_date": "2024-10-16 20:45:29 UTC",
      "updated_date": "2024-10-16 20:45:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:09:03.438066"
    },
    {
      "arxiv_id": "2410.14735v4",
      "title": "Agent Skill Acquisition for Large Language Models via CycleQD",
      "title_zh": "翻译失败",
      "authors": [
        "So Kuroki",
        "Taishi Nakamura",
        "Takuya Akiba",
        "Yujin Tang"
      ],
      "abstract": "Training large language models to acquire specific skills remains a\nchallenging endeavor. Conventional training approaches often struggle with data\ndistribution imbalances and inadequacies in objective functions that do not\nalign well with task-specific performance. To address these challenges, we\nintroduce CycleQD, a novel approach that leverages the Quality Diversity\nframework through a cyclic adaptation of the algorithm, along with a model\nmerging based crossover and an SVD-based mutation. In CycleQD, each task's\nperformance metric is alternated as the quality measure while the others serve\nas the behavioral characteristics. This cyclic focus on individual tasks allows\nfor concentrated effort on one task at a time, eliminating the need for data\nratio tuning and simplifying the design of the objective function. Empirical\nresults from AgentBench indicate that applying CycleQD to LLAMA3-8B-INSTRUCT\nbased models not only enables them to surpass traditional fine-tuning methods\nin coding, operating systems, and database tasks, but also achieves performance\non par with GPT-3.5-TURBO, which potentially contains much more parameters,\nacross these domains. Crucially, this enhanced performance is achieved while\nretaining robust language capabilities, as evidenced by its performance on\nwidely adopted language benchmark tasks. We highlight the key design choices in\nCycleQD, detailing how these contribute to its effectiveness. Furthermore, our\nmethod is general and can be applied to image segmentation models, highlighting\nits applicability across different domains.",
      "tldr_zh": "该研究提出CycleQD，一种基于Quality Diversity框架的循环适应算法，用于训练Large Language Models（LLMs）获取特定技能，通过模型合并based crossover和SVD-based mutation解决数据分布不平衡和目标函数设计问题。在CycleQD中，每个任务的性能指标轮流作为质量测量，其他指标作为行为特征，从而专注于单一任务，避免数据比例调整。实验结果显示，在AgentBench上应用CycleQD到LLAMA3-8B-INSTRUCT模型后，其在编码、操作系统和数据库任务中超越传统微调方法，并与GPT-3.5-TURBO相当，同时保留了语言基准任务的性能；此外，该方法通用，可扩展到图像分割模型等领域。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.CL",
      "comment": "To appear at the 13th International Conference on Learning\n  Representations (ICLR 2025)",
      "pdf_url": "http://arxiv.org/pdf/2410.14735v4",
      "published_date": "2024-10-16 20:27:15 UTC",
      "updated_date": "2025-02-17 06:26:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:09:14.893951"
    },
    {
      "arxiv_id": "2411.00782v2",
      "title": "TradExpert: Revolutionizing Trading with Mixture of Expert LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Qianggang Ding",
        "Haochen Shi",
        "Jiadong Guo",
        "Bang Liu"
      ],
      "abstract": "The integration of Artificial Intelligence (AI) in the financial domain has\nopened new avenues for quantitative trading, particularly through the use of\nLarge Language Models (LLMs). However, the challenge of effectively\nsynthesizing insights from diverse data sources and integrating both structured\nand unstructured data persists. This paper presents TradeExpert, a novel\nframework that employs a mix of experts (MoE) approach, using four specialized\nLLMs, each analyzing distinct sources of financial data, including news\narticles, market data, alpha factors, and fundamental data. The insights of\nthese expert LLMs are further synthesized by a General Expert LLM to make a\nfinal prediction or decision. With specific prompts, TradeExpert can be\nswitched between the prediction mode and the ranking mode for stock movement\nprediction and quantitative stock trading, respectively. In addition to\nexisting benchmarks, we also release a large-scale financial dataset to\ncomprehensively evaluate TradeExpert's effectiveness. Our experimental results\ndemonstrate TradeExpert's superior performance across all trading scenarios.",
      "tldr_zh": "这篇论文介绍了 TradExpert，一种革命性的框架，使用 Mixture of Experts (MoE) 策略整合四个专门的 LLMs 来分析多样化的金融数据来源，包括新闻文章、市场数据、alpha factors 和 fundamental data。框架通过一个 General Expert LLM 合成这些专家的洞见，并支持通过特定提示在预测模式（用于股票运动预测）和排名模式（用于量化股票交易）之间切换。除了现有基准外，作者还发布了大规模金融数据集用于评估。实验结果表明，TradExpert 在所有交易场景中表现出优越性能。",
      "categories": [
        "cs.AI",
        "q-fin.ST"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00782v2",
      "published_date": "2024-10-16 20:24:16 UTC",
      "updated_date": "2025-05-13 13:13:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:09:26.196848"
    },
    {
      "arxiv_id": "2410.13018v1",
      "title": "Learning Representations for Reasoning: Generalizing Across Diverse Structures",
      "title_zh": "翻译失败",
      "authors": [
        "Zhaocheng Zhu"
      ],
      "abstract": "Reasoning, the ability to logically draw conclusions from existing knowledge,\nis a hallmark of human. Together with perception, they constitute the two major\nthemes of artificial intelligence. While deep learning has pushed the limit of\nperception beyond human-level performance, the progress in reasoning domains is\nway behind. One fundamental reason is that reasoning problems usually have\nflexible structures for both knowledge and queries, and many existing models\nonly perform well on structures seen during training. Here we aim to push the\nboundary of reasoning models by devising algorithms that generalize across\nknowledge and query structures, as well as systems that accelerate development\non structured data. This thesis consists of three parts. In Part I, we study\nmodels that can inductively generalize to unseen knowledge graphs with new\nentity and relation vocabularies. For new entities, we propose a framework that\nlearns neural operators in a dynamic programming algorithm computing path\nrepresentations. For relations, we construct a relation graph to capture the\ninteractions between relations, thereby converting new relations into new\nentities. In Part II, we propose two solutions for generalizing across\nmulti-step queries on knowledge graphs and text respectively. For knowledge\ngraphs, we show that multi-step queries can be solved by multiple calls of\ngraph neural networks and fuzzy logic operations. For text, we devise an\nalgorithm to learn explicit knowledge as textual rules to improve large\nlanguage models on multi-step queries. In Part III, we propose two systems to\nfacilitate machine learning development on structured data. Our library treats\nstructured data as first-class citizens and removes the barrier for developing\nalgorithms on structured data. Our node embedding system solves the GPU memory\nbottleneck of embedding matrices and scales to graphs with billion nodes.",
      "tldr_zh": "这篇论文探讨了深度学习在推理领域的挑战，强调现有模型难以泛化到训练中未见的知识和查询结构，并旨在提升模型的归纳泛化能力。在第一部分，作者提出框架来处理知识图谱（knowledge graphs）上的新实体和新关系，包括学习神经算子（neural operators）在动态规划（dynamic programming）算法中计算路径表示，以及构建关系图来转换新关系。在第二部分，针对多步查询，论文介绍了使用图神经网络（graph neural networks）和模糊逻辑（fuzzy logic）操作解决知识图谱问题，以及一种算法通过学习文本规则来提升大型语言模型（large language models）的性能。在第三部分，作者开发了两个系统：一个库将结构化数据视为首要公民，便于算法开发，以及一个可扩展的节点嵌入系统，解决了 GPU 内存瓶颈，支持亿级节点图谱的处理。整体框架为推理模型的进步提供了重要基础。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "PhD thesis",
      "pdf_url": "http://arxiv.org/pdf/2410.13018v1",
      "published_date": "2024-10-16 20:23:37 UTC",
      "updated_date": "2024-10-16 20:23:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:09:40.110560"
    },
    {
      "arxiv_id": "2410.13013v1",
      "title": "LEGAL-UQA: A Low-Resource Urdu-English Dataset for Legal Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Faizan Faisal",
        "Umair Yousaf"
      ],
      "abstract": "We present LEGAL-UQA, the first Urdu legal question-answering dataset derived\nfrom Pakistan's constitution. This parallel English-Urdu dataset includes 619\nquestion-answer pairs, each with corresponding legal article contexts,\naddressing the need for domain-specific NLP resources in low-resource\nlanguages. We describe the dataset creation process, including OCR extraction,\nmanual refinement, and GPT-4-assisted translation and generation of QA pairs.\nOur experiments evaluate the latest generalist language and embedding models on\nLEGAL-UQA, with Claude-3.5-Sonnet achieving 99.19% human-evaluated accuracy. We\nfine-tune mt5-large-UQA-1.0, highlighting the challenges of adapting\nmultilingual models to specialized domains. Additionally, we assess retrieval\nperformance, finding OpenAI's text-embedding-3-large outperforms Mistral's\nmistral-embed. LEGAL-UQA bridges the gap between global NLP advancements and\nlocalized applications, particularly in constitutional law, and lays the\nfoundation for improved legal information access in Pakistan.",
      "tldr_zh": "本文介绍了 LEGAL-UQA，这是一个基于巴基斯坦宪法的低资源乌尔都语-英语法律问答数据集，包含 619 个问题-答案对及其对应的法律条款上下文，旨在填补低资源语言中领域特定 NLP 资源的空白。数据集的创建过程包括 OCR 提取、手动精炼以及 GPT-4 辅助的翻译和 QA 对生成。实验评估显示，Claude-3.5-Sonnet 在人类评估中达到 99.19% 准确率，而微调 mt5-large-UQA-1.0 突出了多语言模型适应专业领域的挑战，且 OpenAI 的 text-embedding-3-large 在检索性能上优于 Mistral 的 mistral-embed。该数据集桥接了全球 NLP 进展与本地应用，为巴基斯坦的宪法法信息访问奠定了基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "68T50"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.13013v1",
      "published_date": "2024-10-16 20:14:45 UTC",
      "updated_date": "2024-10-16 20:14:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:09:52.607910"
    },
    {
      "arxiv_id": "2410.13010v1",
      "title": "Hiding-in-Plain-Sight (HiPS) Attack on CLIP for Targetted Object Removal from Images",
      "title_zh": "翻译失败",
      "authors": [
        "Arka Daw",
        "Megan Hong-Thanh Chung",
        "Maria Mahbub",
        "Amir Sadovnik"
      ],
      "abstract": "Machine learning models are known to be vulnerable to adversarial attacks,\nbut traditional attacks have mostly focused on single-modalities. With the rise\nof large multi-modal models (LMMs) like CLIP, which combine vision and language\ncapabilities, new vulnerabilities have emerged. However, prior work in\nmultimodal targeted attacks aim to completely change the model's output to what\nthe adversary wants. In many realistic scenarios, an adversary might seek to\nmake only subtle modifications to the output, so that the changes go unnoticed\nby downstream models or even by humans. We introduce Hiding-in-Plain-Sight\n(HiPS) attacks, a novel class of adversarial attacks that subtly modifies model\npredictions by selectively concealing target object(s), as if the target object\nwas absent from the scene. We propose two HiPS attack variants, HiPS-cls and\nHiPS-cap, and demonstrate their effectiveness in transferring to downstream\nimage captioning models, such as CLIP-Cap, for targeted object removal from\nimage captions.",
      "tldr_zh": "本论文提出了一种新型对抗性攻击HiPS (Hiding-in-Plain-Sight)，针对多模态模型如CLIP，通过微妙修改图像预测来选择性地隐藏目标对象，使其仿佛不存在，从而避免下游模型或人类察觉。HiPS攻击包括HiPS-cls和HiPS-cap两种变体，前者针对分类任务，后者用于图像描述。实验结果显示，该攻击能有效转移到下游模型如CLIP-Cap，实现从图像描述中移除目标对象，提供了一种更隐蔽的攻击方式。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Published in the 3rd Workshop on New Frontiers in Adversarial Machine\n  Learning at NeurIPS 2024. 10 pages, 7 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.13010v1",
      "published_date": "2024-10-16 20:11:32 UTC",
      "updated_date": "2024-10-16 20:11:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:10:02.375950"
    },
    {
      "arxiv_id": "2410.13002v2",
      "title": "Flex: End-to-End Text-Instructed Visual Navigation from Foundation Model Features",
      "title_zh": "翻译失败",
      "authors": [
        "Makram Chahine",
        "Alex Quach",
        "Alaa Maalouf",
        "Tsun-Hsuan Wang",
        "Daniela Rus"
      ],
      "abstract": "End-to-end learning directly maps sensory inputs to actions, creating highly\nintegrated and efficient policies for complex robotics tasks. However, such\nmodels often struggle to generalize beyond their training scenarios, limiting\nadaptability to new environments, tasks, and concepts. In this work, we\ninvestigate the minimal data requirements and architectural adaptations\nnecessary to achieve robust closed-loop performance with vision-based control\npolicies under unseen text instructions and visual distribution shifts. Our\nfindings are synthesized in Flex (Fly lexically), a framework that uses\npre-trained Vision Language Models (VLMs) as frozen patch-wise feature\nextractors, generating spatially aware embeddings that integrate semantic and\nvisual information. We demonstrate the effectiveness of this approach on a\nquadrotor fly-to-target task, where agents trained via behavior cloning on a\nsmall simulated dataset successfully generalize to real-world scenes with\ndiverse novel goals and command formulations.",
      "tldr_zh": "该论文探讨了端到端（End-to-End）学习在机器人任务中的泛化挑战，提出 Flex 框架，利用预训练的 Vision Language Models (VLMs) 作为冻结的 patch-wise 特征提取器，生成整合语义和视觉信息的空间感知嵌入，以实现基于文本指令的视觉导航。研究调查了最小数据需求和架构适应，确保模型在未见场景下实现鲁棒的闭环性能。在 quadrotor 飞向目标任务中，代理通过行为克隆（behavior cloning）在小规模模拟数据集上训练，便成功泛化到真实世界的多样化目标和命令。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "68T40, 68T05, 68T50",
        "I.2.6; I.2.9; I.2.10; I.4.8"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13002v2",
      "published_date": "2024-10-16 19:59:31 UTC",
      "updated_date": "2025-05-16 15:13:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:10:14.851749"
    },
    {
      "arxiv_id": "2410.12996v1",
      "title": "SSET: Swapping-Sliding Explanation for Time Series Classifiers in Affect Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Nazanin Fouladgar",
        "Marjan Alirezaie",
        "Kary Främling"
      ],
      "abstract": "Local explanation of machine learning (ML) models has recently received\nsignificant attention due to its ability to reduce ambiguities about why the\nmodels make specific decisions. Extensive efforts have been invested to address\nexplainability for different data types, particularly images. However, the work\non multivariate time series data is limited. A possible reason is that the\nconflation of time and other variables in time series data can cause the\ngenerated explanations to be incomprehensible to humans. In addition, some\nefforts on time series fall short of providing accurate explanations as they\neither ignore a context in the time domain or impose differentiability\nrequirements on the ML models. Such restrictions impede their ability to\nprovide valid explanations in real-world applications and non-differentiable ML\nsettings. In this paper, we propose a swapping--sliding decision explanation\nfor multivariate time series classifiers, called SSET. The proposal consists of\nswapping and sliding stages, by which salient sub-sequences causing significant\ndrops in the prediction score are presented as explanations. In the former\nstage, the important variables are detected by swapping the series of interest\nwith close train data from target classes. In the latter stage, the salient\nobservations of these variables are explored by sliding a window over each time\nstep. Additionally, the model measures the importance of different variables\nover time in a novel way characterized by multiple factors. We leverage SSET on\naffect detection domain where evaluations are performed on two real-world\nphysiological time series datasets, WESAD and MAHNOB-HCI, and a deep\nconvolutional classifier, CN-Waterfall. This classifier has shown superior\nperformance to prior models to detect human affective states. Comparing SSET\nwith several benchmarks, including LIME, integrated gradients, and Dynamask, we\nfound..",
      "tldr_zh": "本文提出 SSET 方法，用于解释多变量 time series 分类器在情感检测中的决策问题，解决现有方法忽略时间上下文或要求模型可微的局限。SSET 包括 swapping 阶段（通过交换序列与目标类训练数据检测重要变量）和 sliding 阶段（通过滑动窗口识别关键子序列），从而提供更准确的解释。实验在 WESAD 和 MAHNOB-HCI 数据集上使用 CN-Waterfall 分类器进行评估，结果显示 SSET 优于 LIME、integrated gradients 和 Dynamask 等基准方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12996v1",
      "published_date": "2024-10-16 19:47:08 UTC",
      "updated_date": "2024-10-16 19:47:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:10:26.529286"
    },
    {
      "arxiv_id": "2410.12989v1",
      "title": "Qtok: A Comprehensive Framework for Evaluating Multilingual Tokenizer Quality in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Iaroslav Chelombitko",
        "Egor Safronov",
        "Aleksey Komissarov"
      ],
      "abstract": "In the development of Large Language Models (LLMs), considerable attention\nhas been given to the quality of training datasets. However, the role of\ntokenizers in the LLM training pipeline, particularly for multilingual models,\nhas received less focus. The quality of tokenization can significantly impact a\nmodel's ability to handle diverse languages effectively. We introduce Qtok, a\ntool designed to assess tokenizer quality with a specific emphasis on their\nperformance in multilingual contexts.\n  Our research proposes a set of metrics for evaluating tokenizer quality,\nincluding measures of language coverage, token completeness, and distribution\nacross languages and linguistic categories. Qtok applies these metrics to\nevaluate 13 distinct tokenizers from 58 publicly available models, analyzing\ntheir output across different linguistic contexts. Our analysis revealed\nsignificant variations in token distribution across languages and categories,\nhighlighting potential biases and areas for improvement in current tokenization\nstrategies.\n  This research contributes to the field of tokenizer evaluation within\nmultilingual LLM development by providing a systematic approach to assessing\ntokenizer quality. Our findings highlight the critical role of tokenization in\nmultilingual LLM capability. The Qtok tool and our analysis methodology offer\npractical means for researchers to evaluate and improve tokenization strategies\nfor multilingual applications. We offer a method to compare tokenizer quality\nacross these metrics, which may be useful when selecting or adjusting\ntokenizers for specific multilingual LLM applications.",
      "tldr_zh": "这篇论文介绍了 Qtok 框架，一种全面工具，用于评估大型语言模型 (LLMs) 中多语言分词器的质量，强调分词器在处理多样语言方面的关键影响。研究提出了评估指标，包括语言覆盖度、标记完整性和跨语言分布，并应用这些指标分析了 13 个分词器在 58 个公开模型中的表现。结果揭示了分词器在语言和类别分布上的显著差异，突出了潜在偏见和改进机会，为研究人员提供实用方法来优化多语言 LLM 应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7; I.2.6; H.3.3"
      ],
      "primary_category": "cs.CL",
      "comment": "24 pages, 9 figures, 6 tables. Code and data available at\n  https://github.com/nup-csai/Qtok/",
      "pdf_url": "http://arxiv.org/pdf/2410.12989v1",
      "published_date": "2024-10-16 19:34:34 UTC",
      "updated_date": "2024-10-16 19:34:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:10:37.857035"
    },
    {
      "arxiv_id": "2411.00781v1",
      "title": "Hazards in Daily Life? Enabling Robots to Proactively Detect and Resolve Anomalies",
      "title_zh": "翻译失败",
      "authors": [
        "Zirui Song",
        "Guangxian Ouyang",
        "Meng Fang",
        "Hongbin Na",
        "Zijing Shi",
        "Zhenhao Chen",
        "Yujie Fu",
        "Zeyu Zhang",
        "Shiyu Jiang",
        "Miao Fang",
        "Ling Chen",
        "Xiuying Chen"
      ],
      "abstract": "Existing household robots have made significant progress in performing\nroutine tasks, such as cleaning floors or delivering objects. However, a key\nlimitation of these robots is their inability to recognize potential problems\nor dangers in home environments. For example, a child may pick up and ingest\nmedication that has fallen on the floor, posing a serious risk. We argue that\nhousehold robots should proactively detect such hazards or anomalies within the\nhome, and propose the task of anomaly scenario generation. We leverage\nfoundational models instead of relying on manually labeled data to build\nsimulated environments. Specifically, we introduce a multi-agent brainstorming\napproach, where agents collaborate and generate diverse scenarios covering\nhousehold hazards, hygiene management, and child safety. These textual task\ndescriptions are then integrated with designed 3D assets to simulate realistic\nenvironments. Within these constructed environments, the robotic agent learns\nthe necessary skills to proactively discover and handle the proposed anomalies\nthrough task decomposition, and optimal learning approach selection. We\ndemonstrate that our generated environment outperforms others in terms of task\ndescription and scene diversity, ultimately enabling robotic agents to better\naddress potential household hazards.",
      "tldr_zh": "本文指出，现有家用机器人虽能执行常规任务，但无法主动识别家庭环境中的潜在危险，如儿童误食药物，因此提出 anomaly scenario generation 任务，使用 foundational models 生成模拟环境。研究采用 multi-agent brainstorming 方法，让代理协作创建多样化的场景，包括家庭危险、卫生管理和儿童安全，并将文本描述与3D资产整合形成真实模拟环境。机器人通过 task decomposition 和 optimal learning approach selection 学习主动检测并处理异常，最终实验显示，该环境在任务描述和场景多样性上优于其他方法，提升了机器人应对家庭危险的能力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.RO",
      "comment": "In processing",
      "pdf_url": "http://arxiv.org/pdf/2411.00781v1",
      "published_date": "2024-10-16 19:29:14 UTC",
      "updated_date": "2024-10-16 19:29:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:10:50.551017"
    },
    {
      "arxiv_id": "2410.12983v1",
      "title": "Reinforcement Learning with Euclidean Data Augmentation for State-Based Continuous Control",
      "title_zh": "翻译失败",
      "authors": [
        "Jinzhu Luo",
        "Dingyang Chen",
        "Qi Zhang"
      ],
      "abstract": "Data augmentation creates new data points by transforming the original ones\nfor a reinforcement learning (RL) agent to learn from, which has been shown to\nbe effective for the objective of improving the data efficiency of RL for\ncontinuous control. Prior work towards this objective has been largely\nrestricted to perturbation-based data augmentation where new data points are\ncreated by perturbing the original ones, which has been impressively effective\nfor tasks where the RL agent observes control states as images with\nperturbations including random cropping, shifting, etc. This work focuses on\nstate-based control, where the RL agent can directly observe raw kinematic and\ntask features, and considers an alternative data augmentation applied to these\nfeatures based on Euclidean symmetries under transformations like rotations. We\nshow that the default state features used in exiting benchmark tasks that are\nbased on joint configurations are not amenable to Euclidean transformations. We\ntherefore advocate using state features based on configurations of the limbs\n(i.e., the rigid bodies connected by the joints) that instead provide rich\naugmented data under Euclidean transformations. With minimal hyperparameter\ntuning, we show this new Euclidean data augmentation strategy significantly\nimproves both data efficiency and asymptotic performance of RL on a wide range\nof continuous control tasks.",
      "tldr_zh": "本文提出了一种基于欧氏数据增强的强化学习方法，针对基于状态的连续控制任务，通过应用欧氏对称性（如旋转）对状态特征进行变换，以提高 RL 的数据效率。不同于传统扰动增强，该方法使用基于肢体配置（刚体）的状态特征，而不是关节配置，从而生成更丰富的增强数据。实验结果显示，在最小超参数调整下，这种策略显著提升了 RL 在广泛连续控制任务中的数据效率和渐近性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12983v1",
      "published_date": "2024-10-16 19:25:30 UTC",
      "updated_date": "2024-10-16 19:25:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:11:02.020426"
    },
    {
      "arxiv_id": "2410.12982v1",
      "title": "Flash Inference: Near Linear Time Inference for Long Convolution Sequence Models and Beyond",
      "title_zh": "翻译失败",
      "authors": [
        "Costin-Andrei Oncescu",
        "Sanket Purandare",
        "Stratos Idreos",
        "Sham Kakade"
      ],
      "abstract": "While transformers have been at the core of most recent advancements in\nsequence generative models, their computational cost remains quadratic in\nsequence length. Several subquadratic architectures have been proposed to\naddress this computational issue. Some of them, including long convolution\nsequence models (LCSMs), such as Hyena, address this issue at training time but\nremain quadratic during inference. We propose a method for speeding up LCSMs'\nexact inference to quasilinear $O(L\\log^2L)$ time, identify the key properties\nthat make this possible, and propose a general framework that exploits these.\nOur approach, inspired by previous work on relaxed polynomial interpolation, is\nbased on a tiling which helps decrease memory movement and share computation.\nIt has the added benefit of allowing for almost complete parallelization across\nlayers of the position-mixing part of the architecture. Empirically, we provide\na proof of concept implementation for Hyena, which gets up to $1.6\\times$\nend-to-end improvement over standard inference by improving $50\\times$ within\nthe position-mixing part.",
      "tldr_zh": "本论文针对序列生成模型中transformers的二次方计算成本问题，提出了一种加速长卷积序列模型(LCSMs)推理的方法，将其精确推理时间从二次方优化到近线性的O(L log² L)。该方法基于tiling技术，减少内存移动、共享计算，并实现position-mixing部分的高度并行化，同时提供了一个通用框架来利用这些关键属性。实验在Hyena模型上验证，端到端推理速度提升高达1.6倍，在position-mixing部分改进50倍，从而为高效的序列模型推理铺平道路。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 9 figures, 5 algorithms",
      "pdf_url": "http://arxiv.org/pdf/2410.12982v1",
      "published_date": "2024-10-16 19:23:46 UTC",
      "updated_date": "2024-10-16 19:23:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:11:14.345750"
    },
    {
      "arxiv_id": "2410.12959v1",
      "title": "Large Language Models as a Tool for Mining Object Knowledge",
      "title_zh": "翻译失败",
      "authors": [
        "Hannah YoungEun An",
        "Lenhart K. Schubert"
      ],
      "abstract": "Commonsense knowledge is essential for machines to reason about the world.\nLarge language models (LLMs) have demonstrated their ability to perform almost\nhuman-like text generation. Despite this success, they fall short as\ntrustworthy intelligent systems, due to the opacity of the basis for their\nanswers and a tendency to confabulate facts when questioned about obscure\nentities or technical domains. We hypothesize, however, that their general\nknowledge about objects in the everyday world is largely sound. Based on that\nhypothesis, this paper investigates LLMs' ability to formulate explicit\nknowledge about common physical artifacts, focusing on their parts and\nmaterials. Our work distinguishes between the substances that comprise an\nentire object and those that constitute its parts$\\unicode{x2014}$a previously\nunderexplored distinction in knowledge base construction. Using few-shot with\nfive in-context examples and zero-shot multi-step prompting, we produce a\nrepository of data on the parts and materials of about 2,300 objects and their\nsubtypes. Our evaluation demonstrates LLMs' coverage and soundness in\nextracting knowledge. This contribution to knowledge mining should prove useful\nto AI research on reasoning about object structure and composition and serve as\nan explicit knowledge source (analogous to knowledge graphs) for LLMs\nperforming multi-hop question answering.",
      "tldr_zh": "这篇论文探讨了使用 Large Language Models (LLMs) 作为挖掘物体常识知识的工具，焦点是常见物理物体的部分和材料，包括区分物体整体物质与部分物质的细微区别。作者通过 few-shot（五次 in-context 示例）和 zero-shot multi-step prompting 方法，生成了一个包含约 2300 个物体及其子类型的知识库。实验评估显示，LLMs 在知识提取方面表现出高覆盖性和可靠性，为 AI 在物体结构和组成推理以及多跳问答提供了一个显式知识源。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12959v1",
      "published_date": "2024-10-16 18:46:02 UTC",
      "updated_date": "2024-10-16 18:46:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:11:26.951072"
    },
    {
      "arxiv_id": "2410.12955v1",
      "title": "Long-Tailed Backdoor Attack Using Dynamic Data Augmentation Operations",
      "title_zh": "利用动态数据增强操作的长尾后门攻击",
      "authors": [
        "Lu Pang",
        "Tao Sun",
        "Weimin Lyu",
        "Haibin Ling",
        "Chao Chen"
      ],
      "abstract": "Recently, backdoor attack has become an increasing security threat to deep\nneural networks and drawn the attention of researchers. Backdoor attacks\nexploit vulnerabilities in third-party pretrained models during the training\nphase, enabling them to behave normally for clean samples and mispredict for\nsamples with specific triggers. Existing backdoor attacks mainly focus on\nbalanced datasets. However, real-world datasets often follow long-tailed\ndistributions. In this paper, for the first time, we explore backdoor attack on\nsuch datasets. Specifically, we first analyze the influence of data imbalance\non backdoor attack. Based on our analysis, we propose an effective backdoor\nattack named Dynamic Data Augmentation Operation (D$^2$AO). We design D$^2$AO\nselectors to select operations depending jointly on the class, sample type\n(clean vs. backdoored) and sample features. Meanwhile, we develop a trigger\ngenerator to generate sample-specific triggers. Through simultaneous\noptimization of the backdoored model and trigger generator, guided by dynamic\ndata augmentation operation selectors, we achieve significant advancements.\nExtensive experiments demonstrate that our method can achieve the\nstate-of-the-art attack performance while preserving the clean accuracy.",
      "tldr_zh": "该论文首次探讨了backdoor attack在长尾分布数据集上的应用，分析了数据不平衡如何影响攻击效果。作者提出了一种名为Dynamic Data Augmentation Operation (D$^2$AO)的攻击方法，通过设计选择器根据类别、样本类型（clean vs. backdoored）和样本特征动态选择操作，并开发trigger generator生成特定样本的触发器。实验结果显示，该方法在保持clean accuracy的同时，实现了state-of-the-art的攻击性能。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12955v1",
      "published_date": "2024-10-16 18:44:22 UTC",
      "updated_date": "2024-10-16 18:44:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:11:38.219839"
    },
    {
      "arxiv_id": "2410.12954v2",
      "title": "A Note on Shumailov et al. (2024): `AI Models Collapse When Trained on Recursively Generated Data'",
      "title_zh": "翻译失败",
      "authors": [
        "Ali Borji"
      ],
      "abstract": "The study conducted by Shumailov et al. (2024) demonstrates that repeatedly\ntraining a generative model on synthetic data leads to model collapse. This\nfinding has generated considerable interest and debate, particularly given that\ncurrent models have nearly exhausted the available data. In this work, we\ninvestigate the effects of fitting a distribution (through Kernel Density\nEstimation, or KDE) or a model to the data, followed by repeated sampling from\nit. Our objective is to develop a theoretical understanding of the phenomenon\nobserved by Shumailov et al. (2024). Our results indicate that the outcomes\nreported are a statistical phenomenon and may be unavoidable.",
      "tldr_zh": "这篇论文针对 Shumailov et al. (2024) 的研究，即 AI 模型在递归生成数据上训练会导致模型 collapse，进行理论分析和验证。作者通过 Kernel Density Estimation (KDE) 或模型拟合数据后反复采样，探讨了这一现象的机制。结果表明，这种模型崩溃是统计现象，可能无法避免，为理解数据生成循环中的潜在风险提供了重要洞见。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Comment on https://doi.org/10.1038/s41586-024-07566-y",
      "pdf_url": "http://arxiv.org/pdf/2410.12954v2",
      "published_date": "2024-10-16 18:43:52 UTC",
      "updated_date": "2024-10-24 19:23:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:11:50.051697"
    },
    {
      "arxiv_id": "2410.12941v1",
      "title": "Gradient Map-Assisted Head and Neck Tumor Segmentation: A Pre-RT to Mid-RT Approach in MRI-Guided Radiotherapy",
      "title_zh": "翻译失败",
      "authors": [
        "Jintao Ren",
        "Kim Hochreuter",
        "Mathis Ersted Rasmussen",
        "Jesper Folsted Kallehauge",
        "Stine Sofia Korreman"
      ],
      "abstract": "Radiation therapy (RT) is a vital part of treatment for head and neck cancer,\nwhere accurate segmentation of gross tumor volume (GTV) is essential for\neffective treatment planning. This study investigates the use of pre-RT tumor\nregions and local gradient maps to enhance mid-RT tumor segmentation for head\nand neck cancer in MRI-guided adaptive radiotherapy. By leveraging pre-RT\nimages and their segmentations as prior knowledge, we address the challenge of\ntumor localization in mid-RT segmentation. A gradient map of the tumor region\nfrom the pre-RT image is computed and applied to mid-RT images to improve tumor\nboundary delineation. Our approach demonstrated improved segmentation accuracy\nfor both primary GTV (GTVp) and nodal GTV (GTVn), though performance was\nlimited by data constraints. The final DSCagg scores from the challenge's test\nset evaluation were 0.534 for GTVp, 0.867 for GTVn, and a mean score of 0.70.\nThis method shows potential for enhancing segmentation and treatment planning\nin adaptive radiotherapy. Team: DCPT-Stine's group.",
      "tldr_zh": "本文提出了一种基于梯度图的辅助方法，用于在 MRI-guided radiotherapy 中，从 pre-RT 到 mid-RT 改善头部和颈部肿瘤分割的准确性。方法利用 pre-RT 图像的肿瘤区域梯度图作为先验知识，应用于 mid-RT 图像，以增强肿瘤边界描绘。结果显示，GTVp 的 DSCagg 分数为 0.534，GTVn 为 0.867，平均 0.70，证明了该方法提升了 primary GTV 和 nodal GTV 的分割性能，但受数据限制。该方法为自适应放疗的治疗规划提供了潜在优化潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "physics.med-ph"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12941v1",
      "published_date": "2024-10-16 18:26:51 UTC",
      "updated_date": "2024-10-16 18:26:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:12:03.683112"
    },
    {
      "arxiv_id": "2410.12940v1",
      "title": "UMambaAdj: Advancing GTV Segmentation for Head and Neck Cancer in MRI-Guided RT with UMamba and nnU-Net ResEnc Planner",
      "title_zh": "翻译失败",
      "authors": [
        "Jintao Ren",
        "Kim Hochreuter",
        "Jesper Folsted Kallehauge",
        "Stine Sofia Korreman"
      ],
      "abstract": "Magnetic Resonance Imaging (MRI) plays a crucial role in MRI-guided adaptive\nradiotherapy for head and neck cancer (HNC) due to its superior soft-tissue\ncontrast. However, accurately segmenting the gross tumor volume (GTV), which\nincludes both the primary tumor (GTVp) and lymph nodes (GTVn), remains\nchallenging. Recently, two deep learning segmentation innovations have shown\ngreat promise: UMamba, which effectively captures long-range dependencies, and\nthe nnU-Net Residual Encoder (ResEnc), which enhances feature extraction\nthrough multistage residual blocks. In this study, we integrate these strengths\ninto a novel approach, termed 'UMambaAdj'. Our proposed method was evaluated on\nthe HNTS-MRG 2024 challenge test set using pre-RT T2-weighted MRI images,\nachieving an aggregated Dice Similarity Coefficient (DSCagg) of 0.751 for GTVp\nand 0.842 for GTVn, with a mean DSCagg of 0.796. This approach demonstrates\npotential for more precise tumor delineation in MRI-guided adaptive\nradiotherapy, ultimately improving treatment outcomes for HNC patients. Team:\nDCPT-Stine's group.",
      "tldr_zh": "该研究针对头部和颈部癌症 (HNC) 在 MRI 引导自适应放射治疗中分割总肿瘤体积 (GTV，包括 GTVp 和 GTVn) 的挑战，提出了一种新型方法 UMambaAdj。该方法整合了 UMamba（用于捕捉长距离依赖关系）和 nnU-Net ResEnc Planner（通过多阶段残差块增强特征提取），以提高肿瘤分割的准确性。在 HNTS-MRG 2024 挑战测试集上，使用 pre-RT T2 加权 MRI 图像评估，UMambaAdj 取得了 GTVp 的 DSCagg 为 0.751、GTVn 为 0.842，以及平均 DSCagg 为 0.796 的结果。该方法展示了在 MRI 引导放射治疗中实现更精确肿瘤划分的潜力，有望改善 HNC 患者的治疗效果。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "physics.med-ph"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12940v1",
      "published_date": "2024-10-16 18:26:27 UTC",
      "updated_date": "2024-10-16 18:26:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:12:14.983089"
    },
    {
      "arxiv_id": "2410.12927v2",
      "title": "Deep Model Merging: The Sister of Neural Network Interpretability -- A Survey",
      "title_zh": "深度模型合并：神经",
      "authors": [
        "Arham Khan",
        "Todd Nief",
        "Nathaniel Hudson",
        "Mansi Sakarvadia",
        "Daniel Grzenda",
        "Aswathy Ajith",
        "Jordan Pettyjohn",
        "Kyle Chard",
        "Ian Foster"
      ],
      "abstract": "We survey the model merging literature through the lens of loss landscape\ngeometry to connect observations from empirical studies on model merging and\nloss landscape analysis to phenomena that govern neural network training and\nthe emergence of their inner representations. We distill repeated empirical\nobservations from the literature in these fields into descriptions of four\nmajor characteristics of loss landscape geometry: mode convexity, determinism,\ndirectedness, and connectivity. We argue that insights into the structure of\nlearned representations from model merging have applications to model\ninterpretability and robustness, subsequently we propose promising new research\ndirections at the intersection of these fields.",
      "tldr_zh": "这篇调查论文探讨了深度模型合并（Deep Model Merging）作为神经网络可解释性（Neural Network Interpretability）的“姐妹”领域，通过损失景观几何（Loss Landscape Geometry）的视角，将模型合并的经验观察与神经网络训练及其内部表示的现象联系起来。论文提炼出损失景观的四个主要特征：mode convexity、determinism、directedness 和 connectivity，这些特征源于相关文献的重复经验观察。最终，作者论证了这些见解可应用于提升模型可解释性和鲁棒性，并提出在这些领域交叉的新研究方向。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12927v2",
      "published_date": "2024-10-16 18:14:05 UTC",
      "updated_date": "2025-03-21 23:29:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:12:26.096082"
    },
    {
      "arxiv_id": "2410.12918v2",
      "title": "Boosting Asynchronous Decentralized Learning with Model Fragmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Sayan Biswas",
        "Anne-Marie Kermarrec",
        "Alexis Marouani",
        "Rafael Pires",
        "Rishi Sharma",
        "Martijn de Vos"
      ],
      "abstract": "Decentralized learning (DL) is an emerging technique that allows nodes on the\nweb to collaboratively train machine learning models without sharing raw data.\nDealing with stragglers, i.e., nodes with slower compute or communication than\nothers, is a key challenge in DL. We present DivShare, a novel asynchronous DL\nalgorithm that achieves fast model convergence in the presence of communication\nstragglers. DivShare achieves this by having nodes fragment their models into\nparameter subsets and send, in parallel to computation, each subset to a random\nsample of other nodes instead of sequentially exchanging full models. The\ntransfer of smaller fragments allows more efficient usage of the collective\nbandwidth and enables nodes with slow network links to quickly contribute with\nat least some of their model parameters. By theoretically proving the\nconvergence of DivShare, we provide, to the best of our knowledge, the first\nformal proof of convergence for a DL algorithm that accounts for the effects of\nasynchronous communication with delays. We experimentally evaluate DivShare\nagainst two state-of-the-art DL baselines, AD-PSGD and Swift, and with two\nstandard datasets, CIFAR-10 and MovieLens. We find that DivShare with\ncommunication stragglers lowers time-to-accuracy by up to 3.9x compared to\nAD-PSGD on the CIFAR-10 dataset. Compared to baselines, DivShare also achieves\nup to 19.4% better accuracy and 9.5% lower test loss on the CIFAR-10 and\nMovieLens datasets, respectively.",
      "tldr_zh": "该研究针对去中心化学习(Decentralized Learning, DL)中stragglers（计算或通信较慢的节点）问题，提出了一种新型异步算法DivShare，通过模型碎片化(Model Fragmentation)将模型参数分解成子集，并行发送给其他节点的随机样本，从而提高带宽利用率并加速模型收敛。DivShare首次理论证明了其在异步通信延迟下的收敛性，为DL算法提供了正式的数学基础。在实验中，使用CIFAR-10和MovieLens数据集，DivShare相较于AD-PSGD和Swift基线，在有stragglers情况下将时间到准确率降低多达3.9倍，并在CIFAR-10上准确率提升多达19.4%，MovieLens上测试损失降低多达9.5%。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "Accepted to appear in the Proceedings of the ACM Web Conference 2025\n  (WWW '25)",
      "pdf_url": "http://arxiv.org/pdf/2410.12918v2",
      "published_date": "2024-10-16 18:03:52 UTC",
      "updated_date": "2025-02-03 18:24:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:12:38.911120"
    },
    {
      "arxiv_id": "2410.12913v1",
      "title": "Fair Clustering for Data Summarization: Improved Approximation Algorithms and Complexity Insights",
      "title_zh": "公平聚类用于数据总结：改进的近似算法和复杂性洞见",
      "authors": [
        "Ameet Gadekar",
        "Aristides Gionis",
        "Suhas Thejaswi"
      ],
      "abstract": "Data summarization tasks are often modeled as $k$-clustering problems, where\nthe goal is to choose $k$ data points, called cluster centers, that best\nrepresent the dataset by minimizing a clustering objective. A popular objective\nis to minimize the maximum distance between any data point and its nearest\ncenter, which is formalized as the $k$-center problem. While in some\napplications all data points can be chosen as centers, in the general setting,\ncenters must be chosen from a predefined subset of points, referred as\nfacilities or suppliers; this is known as the $k$-supplier problem. In this\nwork, we focus on fair data summarization modeled as the fair $k$-supplier\nproblem, where data consists of several groups, and a minimum number of centers\nmust be selected from each group while minimizing the $k$-supplier objective.\nThe groups can be disjoint or overlapping, leading to two distinct problem\nvariants each with different computational complexity.\n  We present $3$-approximation algorithms for both variants, improving the\npreviously known factor of $5$. For disjoint groups, our algorithm runs in\npolynomial time, while for overlapping groups, we present a fixed-parameter\ntractable algorithm, where the exponential runtime depends only on the number\nof groups and centers. We show that these approximation factors match the\ntheoretical lower bounds, assuming standard complexity theory conjectures.\nFinally, using an open-source implementation, we demonstrate the scalability of\nour algorithms on large synthetic datasets and assess the price of fairness on\nreal-world data, comparing solution quality with and without fairness\nconstraints.",
      "tldr_zh": "该论文研究了公平数据总结问题，将其建模为公平 k-supplier 问题，目标是在数据集的多个组中选择 k 个中心点，同时确保每个组至少有最小数量的中心，并最小化最大距离聚类目标。作者提出了改进的 3-approximation algorithms，针对组别互斥（disjoint groups）的变体提供多项式时间算法，而针对组别重叠（overlapping groups）的变体提供固定参数可处理的算法。实验结果显示，这些算法在大型合成数据集上具有良好的可扩展性，并在真实数据上评估了公平约束对解决方案质量的影响，证明了逼近因子与理论下界一致。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY",
        "cs.DM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12913v1",
      "published_date": "2024-10-16 18:00:19 UTC",
      "updated_date": "2024-10-16 18:00:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:12:51.199647"
    },
    {
      "arxiv_id": "2410.19803v2",
      "title": "First-Person Fairness in Chatbots",
      "title_zh": "聊天机器人中的第一人称公平",
      "authors": [
        "Tyna Eloundou",
        "Alex Beutel",
        "David G. Robinson",
        "Keren Gu-Lemberg",
        "Anna-Luisa Brakman",
        "Pamela Mishkin",
        "Meghan Shah",
        "Johannes Heidecke",
        "Lilian Weng",
        "Adam Tauman Kalai"
      ],
      "abstract": "Evaluating chatbot fairness is crucial given their rapid proliferation, yet\ntypical chatbot tasks (e.g., resume writing, entertainment) diverge from the\ninstitutional decision-making tasks (e.g., resume screening) which have\ntraditionally been central to discussion of algorithmic fairness. The\nopen-ended nature and diverse use-cases of chatbots necessitate novel methods\nfor bias assessment. This paper addresses these challenges by introducing a\nscalable counterfactual approach to evaluate \"first-person fairness,\" meaning\nfairness toward chatbot users based on demographic characteristics. Our method\nemploys a Language Model as a Research Assistant (LMRA) to yield quantitative\nmeasures of harmful stereotypes and qualitative analyses of demographic\ndifferences in chatbot responses. We apply this approach to assess biases in\nsix of our language models across millions of interactions, covering sixty-six\ntasks in nine domains and spanning two genders and four races. Independent\nhuman annotations corroborate the LMRA-generated bias evaluations. This study\nrepresents the first large-scale fairness evaluation based on real-world chat\ndata. We highlight that post-training reinforcement learning techniques\nsignificantly mitigate these biases. This evaluation provides a practical\nmethodology for ongoing bias monitoring and mitigation.",
      "tldr_zh": "这篇论文针对聊天机器人的快速普及，引入了一种可扩展的逆事实方法来评估“first-person fairness”，即基于用户人口统计特征（如性别和种族）的公平性，以应对其多样化任务带来的偏见挑战。方法利用Language Model as a Research Assistant (LMRA)进行有害刻板印象的量化测量和人口差异的定性分析，并在六个语言模型的数百万真实互动中测试，涵盖66个任务、9个领域和多种人口群体。实验结果显示，强化学习技术能显著缓解这些偏见，且独立人类注释验证了评估的有效性，为持续的偏见监控和缓解提供实用方法。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "In ICLR 2025, 59 pages, 27 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.19803v2",
      "published_date": "2024-10-16 17:59:47 UTC",
      "updated_date": "2025-03-03 15:13:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:13:02.299821"
    },
    {
      "arxiv_id": "2410.12784v2",
      "title": "JudgeBench: A Benchmark for Evaluating LLM-based Judges",
      "title_zh": "JudgeBench：用于评估基于LLM的评判者的基准测试",
      "authors": [
        "Sijun Tan",
        "Siyuan Zhuang",
        "Kyle Montgomery",
        "William Y. Tang",
        "Alejandro Cuadron",
        "Chenguang Wang",
        "Raluca Ada Popa",
        "Ion Stoica"
      ],
      "abstract": "LLM-based judges have emerged as a scalable alternative to human evaluation\nand are increasingly used to assess, compare, and improve models. However, the\nreliability of LLM-based judges themselves is rarely scrutinized. As LLMs\nbecome more advanced, their responses grow more sophisticated, requiring\nstronger judges to evaluate them. Existing benchmarks primarily focus on a\njudge's alignment with human preferences, but often fail to account for more\nchallenging tasks where crowdsourced human preference is a poor indicator of\nfactual and logical correctness. To address this, we propose a novel evaluation\nframework to objectively evaluate LLM-based judges. Based on this framework, we\npropose JudgeBench, a benchmark for evaluating LLM-based judges on challenging\nresponse pairs spanning knowledge, reasoning, math, and coding. JudgeBench\nleverages a novel pipeline for converting existing difficult datasets into\nchallenging response pairs with preference labels reflecting objective\ncorrectness. Our comprehensive evaluation on a collection of prompted judges,\nfine-tuned judges, multi-agent judges, and reward models shows that JudgeBench\nposes a significantly greater challenge than previous benchmarks, with many\nstrong models (e.g., GPT-4o) performing just slightly better than random\nguessing. Overall, JudgeBench offers a reliable platform for assessing\nincreasingly advanced LLM-based judges. Data and code are available at\nhttps://github.com/ScalerLab/JudgeBench.",
      "tldr_zh": "本文提出JudgeBench，一个新的基准，用于评估LLM-based judges在知识、推理、数学和编码等挑战性任务上的可靠性。该基准通过一个创新管道，将现有困难数据集转换为带有客观正确性标签的响应对，弥补了传统基准忽略事实和逻辑正确性的缺陷。实验结果显示，包括GPT-4o在内的强模型在JudgeBench上表现仅略好于随机猜测，突显了评估框架的严苛性和实用性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Published as a conference paper at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.12784v2",
      "published_date": "2024-10-16 17:58:19 UTC",
      "updated_date": "2025-04-05 00:07:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:13:13.716208"
    },
    {
      "arxiv_id": "2410.12774v1",
      "title": "Identifying Task Groupings for Multi-Task Learning Using Pointwise V-Usable Information",
      "title_zh": "翻译失败",
      "authors": [
        "Yingya Li",
        "Timothy Miller",
        "Steven Bethard",
        "Guergana Savova"
      ],
      "abstract": "The success of multi-task learning can depend heavily on which tasks are\ngrouped together. Naively grouping all tasks or a random set of tasks can\nresult in negative transfer, with the multi-task models performing worse than\nsingle-task models. Though many efforts have been made to identify task\ngroupings and to measure the relatedness among different tasks, it remains a\nchallenging research topic to define a metric to identify the best task\ngrouping out of a pool of many potential task combinations. We propose a metric\nof task relatedness based on task difficulty measured by pointwise V-usable\ninformation (PVI). PVI is a recently proposed metric to estimate how much\nusable information a dataset contains given a model. We hypothesize that tasks\nwith not statistically different PVI estimates are similar enough to benefit\nfrom the joint learning process. We conduct comprehensive experiments to\nevaluate the feasibility of this metric for task grouping on 15 NLP datasets in\nthe general, biomedical, and clinical domains. We compare the results of the\njoint learners against single learners, existing baseline methods, and recent\nlarge language models, including Llama 2 and GPT-4. The results show that by\ngrouping tasks with similar PVI estimates, the joint learners yielded\ncompetitive results with fewer total parameters, with consistent performance\nacross domains.",
      "tldr_zh": "本研究探讨了多任务学习(Multi-Task Learning)中任务分组的重要性，提出了一种基于点式 V-可用信息(Pointwise V-Usable Information, PVI)来度量任务相关性的新方法，该方法通过评估任务难度来识别相似任务，从而避免负迁移问题。实验在15个NLP数据集（涵盖一般、生物医学和临床领域）上进行，与单任务学习、现有基线方法以及大型语言模型如Llama 2和GPT-4比较，结果显示，通过分组PVI相似的任务，联合学习模型在减少总参数的情况下取得了竞争性性能，并在不同领域保持一致。总的来说，这一方法为高效的任务分组提供了可行框架。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "main paper 12 pages, Appendix 7 pages, 1 figure, 18 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.12774v1",
      "published_date": "2024-10-16 17:49:45 UTC",
      "updated_date": "2024-10-16 17:49:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:13:27.115165"
    },
    {
      "arxiv_id": "2410.12773v1",
      "title": "Harmon: Whole-Body Motion Generation of Humanoid Robots from Language Descriptions",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenyu Jiang",
        "Yuqi Xie",
        "Jinhan Li",
        "Ye Yuan",
        "Yifeng Zhu",
        "Yuke Zhu"
      ],
      "abstract": "Humanoid robots, with their human-like embodiment, have the potential to\nintegrate seamlessly into human environments. Critical to their coexistence and\ncooperation with humans is the ability to understand natural language\ncommunications and exhibit human-like behaviors. This work focuses on\ngenerating diverse whole-body motions for humanoid robots from language\ndescriptions. We leverage human motion priors from extensive human motion\ndatasets to initialize humanoid motions and employ the commonsense reasoning\ncapabilities of Vision Language Models (VLMs) to edit and refine these motions.\nOur approach demonstrates the capability to produce natural, expressive, and\ntext-aligned humanoid motions, validated through both simulated and real-world\nexperiments. More videos can be found at\nhttps://ut-austin-rpl.github.io/Harmon/.",
      "tldr_zh": "本研究提出Harmon框架，用于从语言描述生成类人机器人（humanoid robots）的多样化全身动作，旨在提升机器人与人类的共存和合作。方法利用人类动作数据集的先验知识初始化动作，并借助Vision Language Models (VLMs)的常识推理能力进行编辑和完善，确保动作自然、富有表现力且与文本对齐。通过模拟和真实实验验证，该框架证明了其有效性，并在项目网站提供更多演示视频。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted for oral presentation at 8th Annual Conference on Robot\n  Learning. Project website: https://ut-austin-rpl.github.io/Harmon/",
      "pdf_url": "http://arxiv.org/pdf/2410.12773v1",
      "published_date": "2024-10-16 17:48:50 UTC",
      "updated_date": "2024-10-16 17:48:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:13:37.820854"
    },
    {
      "arxiv_id": "2410.12772v1",
      "title": "Vaccinating Federated Learning for Robust Modulation Classification in Distributed Wireless Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Hunmin Lee",
        "Hongju Seong",
        "Wonbin Kim",
        "Hyeokchan Kwon",
        "Daehee Seo"
      ],
      "abstract": "Automatic modulation classification (AMC) serves a vital role in ensuring\nefficient and reliable communication services within distributed wireless\nnetworks. Recent developments have seen a surge in interest in deep neural\nnetwork (DNN)-based AMC models, with Federated Learning (FL) emerging as a\npromising framework. Despite these advancements, the presence of various noises\nwithin the signal exerts significant challenges while optimizing models to\ncapture salient features. Furthermore, existing FL-based AMC models commonly\nrely on linear aggregation strategies, which face notable difficulties in\nintegrating locally fine-tuned parameters within practical non-IID (Independent\nand Identically Distributed) environments, thereby hindering optimal learning\nconvergence. To address these challenges, we propose FedVaccine, a novel FL\nmodel aimed at improving generalizability across signals with varying noise\nlevels by deliberately introducing a balanced level of noise. This is\naccomplished through our proposed harmonic noise resilience approach, which\nidentifies an optimal noise tolerance for DNN models, thereby regulating the\ntraining process and mitigating overfitting. Additionally, FedVaccine overcomes\nthe limitations of existing FL-based AMC models' linear aggregation by\nemploying a split-learning strategy using structural clustering topology and\nlocal queue data structure, enabling adaptive and cumulative updates to local\nmodels. Our experimental results, including IID and non-IID datasets as well as\nablation studies, confirm FedVaccine's robust performance and superiority over\nexisting FL-based AMC approaches across different noise levels. These findings\nhighlight FedVaccine's potential to enhance the reliability and performance of\nAMC systems in practical wireless network environments.",
      "tldr_zh": "本研究针对分布式无线网络中的自动调制分类（AMC），提出了一种增强型联邦学习（Federated Learning, FL）框架FedVaccine，以应对信号噪音干扰和非独立同分布（non-IID）环境下线性聚合策略的局限性。FedVaccine通过harmonic noise resilience方法引入平衡水平的噪音，优化DNN模型的噪音耐受性，调节训练过程并缓解过拟合；同时采用split-learning策略结合structural clustering topology和local queue data structure，实现自适应和累积的本地模型更新。实验结果显示，FedVaccine在IID和non-IID数据集上显著优于现有FL-based AMC方法，准确率在不同噪音水平下提升了整体性能，并提升了AMC系统在实际无线网络环境的可靠性和泛化能力。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12772v1",
      "published_date": "2024-10-16 17:48:47 UTC",
      "updated_date": "2024-10-16 17:48:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:13:50.620640"
    },
    {
      "arxiv_id": "2410.12771v1",
      "title": "Open Materials 2024 (OMat24) Inorganic Materials Dataset and Models",
      "title_zh": "Open Materials 2024 (OMat24) 无机材料数据集和模型",
      "authors": [
        "Luis Barroso-Luque",
        "Muhammed Shuaibi",
        "Xiang Fu",
        "Brandon M. Wood",
        "Misko Dzamba",
        "Meng Gao",
        "Ammar Rizvi",
        "C. Lawrence Zitnick",
        "Zachary W. Ulissi"
      ],
      "abstract": "The ability to discover new materials with desirable properties is critical\nfor numerous applications from helping mitigate climate change to advances in\nnext generation computing hardware. AI has the potential to accelerate\nmaterials discovery and design by more effectively exploring the chemical space\ncompared to other computational methods or by trial-and-error. While\nsubstantial progress has been made on AI for materials data, benchmarks, and\nmodels, a barrier that has emerged is the lack of publicly available training\ndata and open pre-trained models. To address this, we present a Meta FAIR\nrelease of the Open Materials 2024 (OMat24) large-scale open dataset and an\naccompanying set of pre-trained models. OMat24 contains over 110 million\ndensity functional theory (DFT) calculations focused on structural and\ncompositional diversity. Our EquiformerV2 models achieve state-of-the-art\nperformance on the Matbench Discovery leaderboard and are capable of predicting\nground-state stability and formation energies to an F1 score above 0.9 and an\naccuracy of 20 meV/atom, respectively. We explore the impact of model size,\nauxiliary denoising objectives, and fine-tuning on performance across a range\nof datasets including OMat24, MPtraj, and Alexandria. The open release of the\nOMat24 dataset and models enables the research community to build upon our\nefforts and drive further advancements in AI-assisted materials science.",
      "tldr_zh": "本研究发布 Open Materials 2024 (OMat24) 大规模开放数据集和预训练模型，以解决 AI 辅助材料发现中缺乏公开训练数据的瓶颈。OMat24 包含超过 1.1 亿个密度功能理论 (DFT) 计算，聚焦于无机材料的结构和组成多样性。研究团队的 EquiformerV2 模型在 Matbench Discovery 排行榜上达到最先进性能，能以 F1 分数超过 0.9 和准确度 20 meV/atom 预测基态稳定性和形成能。该数据集和模型的开放发布将推动 AI 辅助材料科学领域的进一步创新。",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.AI",
        "physics.comp-ph"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "comment": "19 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.12771v1",
      "published_date": "2024-10-16 17:48:34 UTC",
      "updated_date": "2024-10-16 17:48:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:14:02.878868"
    },
    {
      "arxiv_id": "2410.12761v2",
      "title": "SAFREE: Training-Free and Adaptive Guard for Safe Text-to-Image And Video Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Jaehong Yoon",
        "Shoubin Yu",
        "Vaidehi Patil",
        "Huaxiu Yao",
        "Mohit Bansal"
      ],
      "abstract": "Recent advances in diffusion models have significantly enhanced their ability\nto generate high-quality images and videos, but they have also increased the\nrisk of producing unsafe content. Existing unlearning/editing-based methods for\nsafe generation remove harmful concepts from models but face several\nchallenges: (1) They cannot instantly remove harmful concepts without training.\n(2) Their safe generation capabilities depend on collected training data. (3)\nThey alter model weights, risking degradation in quality for content unrelated\nto toxic concepts. To address these, we propose SAFREE, a novel, training-free\napproach for safe T2I and T2V, that does not alter the model's weights.\nSpecifically, we detect a subspace corresponding to a set of toxic concepts in\nthe text embedding space and steer prompt embeddings away from this subspace,\nthereby filtering out harmful content while preserving intended semantics. To\nbalance the trade-off between filtering toxicity and preserving safe concepts,\nSAFREE incorporates a novel self-validating filtering mechanism that\ndynamically adjusts the denoising steps when applying the filtered embeddings.\nAdditionally, we incorporate adaptive re-attention mechanisms within the\ndiffusion latent space to selectively diminish the influence of features\nrelated to toxic concepts at the pixel level. In the end, SAFREE ensures\ncoherent safety checking, preserving the fidelity, quality, and safety of the\noutput. SAFREE achieves SOTA performance in suppressing unsafe content in T2I\ngeneration compared to training-free baselines and effectively filters targeted\nconcepts while maintaining high-quality images. It also shows competitive\nresults against training-based methods. We extend SAFREE to various T2I\nbackbones and T2V tasks, showcasing its flexibility and generalization. SAFREE\nprovides a robust and adaptable safeguard for ensuring safe visual generation.",
      "tldr_zh": "本文提出SAFREE，一种无需训练的适应性守卫，用于安全的文本到图像(T2I)和文本到视频(T2V)生成，旨在解决现有方法在即时移除有害概念、依赖训练数据和潜在模型质量下降等问题。SAFREE通过检测文本嵌入空间中的有害子空间并引导提示嵌入远离它，同时结合自验证过滤机制动态调整去噪步骤，以及自适应再注意力机制在扩散潜在空间中减少有害特征的影响，从而平衡过滤毒性和保留图像质量。实验结果显示，SAFREE在T2I生成中达到SOTA性能，显著抑制不安全内容，同时保持高图像质量，并可扩展到多种T2I backbone和T2V任务，提供可靠的视觉生成安全保障。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "ICLR 2025; The first two authors contributed equally; Project page:\n  https://safree-safe-t2i-t2v.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2410.12761v2",
      "published_date": "2024-10-16 17:32:23 UTC",
      "updated_date": "2025-03-14 04:47:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:14:15.563575"
    },
    {
      "arxiv_id": "2410.12759v1",
      "title": "Unitary Multi-Margin BERT for Robust Natural Language Processing",
      "title_zh": "翻译失败",
      "authors": [
        "Hao-Yuan Chang",
        "Kang L. Wang"
      ],
      "abstract": "Recent developments in adversarial attacks on deep learning leave many\nmission-critical natural language processing (NLP) systems at risk of\nexploitation. To address the lack of computationally efficient adversarial\ndefense methods, this paper reports a novel, universal technique that\ndrastically improves the robustness of Bidirectional Encoder Representations\nfrom Transformers (BERT) by combining the unitary weights with the multi-margin\nloss. We discover that the marriage of these two simple ideas amplifies the\nprotection against malicious interference. Our model, the unitary multi-margin\nBERT (UniBERT), boosts post-attack classification accuracies significantly by\n5.3% to 73.8% while maintaining competitive pre-attack accuracies. Furthermore,\nthe pre-attack and post-attack accuracy tradeoff can be adjusted via a single\nscalar parameter to best fit the design requirements for the target\napplications.",
      "tldr_zh": "本论文针对对抗攻击对自然语言处理(NLP)系统的风险，提出了一种名为Unitary Multi-Margin BERT (UniBERT)的鲁棒性提升方法，通过结合unitary weights和multi-margin loss来增强Bidirectional Encoder Representations from Transformers (BERT)的防御能力。该方法显著提高了模型在攻击后的分类准确率，提升幅度达5.3%至73.8%，同时保持了竞争性的预攻击准确率。此外，通过调整一个标量参数，用户可以灵活平衡预攻击和后攻击准确率，以适应不同应用场景的需求。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12759v1",
      "published_date": "2024-10-16 17:30:58 UTC",
      "updated_date": "2024-10-16 17:30:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:14:36.616579"
    },
    {
      "arxiv_id": "2410.12730v3",
      "title": "Counterfactual Generative Modeling with Variational Causal Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Yulun Wu",
        "Louie McConnell",
        "Claudia Iriondo"
      ],
      "abstract": "Estimating an individual's counterfactual outcomes under interventions is a\nchallenging task for traditional causal inference and supervised learning\napproaches when the outcome is high-dimensional (e.g. gene expressions, facial\nimages) and covariates are relatively limited. In this case, to predict one's\noutcomes under counterfactual treatments, it is crucial to leverage individual\ninformation contained in the observed outcome in addition to the covariates.\nPrior works using variational inference in counterfactual generative modeling\nhave been focusing on neural adaptations and model variants within the\nconditional variational autoencoder formulation, which we argue is\nfundamentally ill-suited to the notion of counterfactual in causal inference.\nIn this work, we present a novel variational Bayesian causal inference\nframework and its theoretical backings to properly handle counterfactual\ngenerative modeling tasks, through which we are able to conduct counterfactual\nsupervision end-to-end during training without any counterfactual samples, and\nencourage disentangled exogenous noise abduction that aids the correct\nidentification of causal effect in counterfactual generations. In experiments,\nwe demonstrate the advantage of our framework compared to state-of-the-art\nmodels in counterfactual generative modeling on multiple benchmarks.",
      "tldr_zh": "本文提出了一种新的变分贝叶斯因果推理框架（variational Bayesian causal inference framework），旨在解决传统方法在高维结果（如基因表达或面部图像）下的反事实生成建模（counterfactual generative modeling）挑战，通过利用观察到的结果信息来估计个体在干预下的反事实结果（counterfactual outcomes）。该框架支持端到端的反事实监督（counterfactual supervision）训练，无需实际反事实样本，并鼓励分离的外生噪声推断（disentangled exogenous noise abduction），以准确识别因果效应。实验结果显示，该方法在多个基准上优于最先进模型，展示了其在因果推理（causal inference）中的显著优势。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.ST",
        "stat.ML",
        "stat.TH"
      ],
      "primary_category": "cs.LG",
      "comment": "Published as a conference paper at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.12730v3",
      "published_date": "2024-10-16 16:44:12 UTC",
      "updated_date": "2025-03-18 17:48:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:14:47.765621"
    },
    {
      "arxiv_id": "2411.00006v1",
      "title": "Personality-Guided Code Generation Using Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yaoqi Guo",
        "Zhenpeng Chen",
        "Jie M. Zhang",
        "Yang Liu",
        "Yun Ma"
      ],
      "abstract": "Code generation, the automatic creation of source code from natural language\ndescriptions, has garnered significant attention due to its potential to\nstreamline software development. Inspired by research that links\ntask-personality alignment with improved development outcomes, we conduct an\nempirical study on personality-guided code generation using large language\nmodels (LLMs). Specifically, we investigate how emulating personality traits\nappropriate to the coding tasks affects LLM performance. We extensively\nevaluate this approach using seven widely adopted LLMs across four\nrepresentative datasets. Our results show that personality guidance\nsignificantly enhances code generation accuracy, with improved pass rates in 23\nout of 28 LLM-dataset combinations. Notably, in 11 cases, the improvement\nexceeds 5%, and in 5 instances, it surpasses 10%, with the highest gain\nreaching 12.9%. Additionally, personality guidance can be easily integrated\nwith other prompting strategies to further boost performance.",
      "tldr_zh": "这篇论文探讨了使用Large Language Models (LLMs)进行个性指导的代码生成，旨在通过模拟任务适配的个性特征来提升代码生成性能。研究者对七个LLMs和四个代表性数据集进行了广泛实证评估，结果显示个性指导显著提高了代码生成准确性，在28个LLM-数据集组合中，23个实现了pass rate改善，其中11个超过5%，5个超过10%，最高达12.9%。此外，该方法易于与其他提示策略结合，进一步增强整体效果。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00006v1",
      "published_date": "2024-10-16 16:42:55 UTC",
      "updated_date": "2024-10-16 16:42:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:14:58.772863"
    },
    {
      "arxiv_id": "2410.12728v1",
      "title": "Transformer based super-resolution downscaling for regional reanalysis: Full domain vs tiling approaches",
      "title_zh": "翻译失败",
      "authors": [
        "Antonio Pérez",
        "Mario Santa Cruz",
        "Daniel San Martín",
        "José Manuel Gutiérrez"
      ],
      "abstract": "Super-resolution (SR) is a promising cost-effective downscaling methodology\nfor producing high-resolution climate information from coarser counterparts. A\nparticular application is downscaling regional reanalysis outputs (predictand)\nfrom the driving global counterparts (predictor). This study conducts an\nintercomparison of various SR downscaling methods focusing on temperature and\nusing the CERRA reanalysis (5.5 km resolution, produced with a regional\natmospheric model driven by ERA5) as example. The method proposed in this work\nis the Swin transformer and two alternative methods are used as benchmark\n(fully convolutional U-Net and convolutional and dense DeepESD) as well as the\nsimple bicubic interpolation. We compare two approaches, the standard one using\nthe full domain as input and a more scalable tiling approach, dividing the full\ndomain into tiles that are used as input. The methods are trained to downscale\nCERRA surface temperature, based on temperature information from the driving\nERA5; in addition, the tiling approach includes static orographic information.\nWe show that the tiling approach, which requires spatial transferability, comes\nat the cost of a lower performance (although it outperforms some full-domain\nbenchmarks), but provides an efficient scalable solution that allows SR\nreduction on a pan-European scale and is valuable for real-time applications.",
      "tldr_zh": "这篇论文探讨了基于 Transformer 的超分辨率 (SR) 降尺度方法，用于从粗分辨率全球再分析数据（如 ERA5）生成高分辨率区域再分析数据（如 CERRA 的 5.5 km 温度数据）。研究比较了 Swin Transformer 与基准方法（如 U-Net、DeepESD 和双立方插值），并评估了全域输入方法与更可扩展的平铺方法（后者将域分成小块并整合静态地形信息）。结果表明，虽然平铺方法性能略低于全域方法（但仍优于某些基准），它提供了高效、可扩展的解决方案，适合泛欧洲规模和实时应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12728v1",
      "published_date": "2024-10-16 16:42:20 UTC",
      "updated_date": "2024-10-16 16:42:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:15:11.955461"
    },
    {
      "arxiv_id": "2410.12720v1",
      "title": "HEnRY: A Multi-Agent System Framework for Multi-Domain Contexts",
      "title_zh": "翻译失败",
      "authors": [
        "Emmanuele Lacavalla",
        "Shuyi Yang",
        "Riccardo Crupi",
        "Joseph E. Gonzalez"
      ],
      "abstract": "This project, named HEnRY, aims to introduce a Multi-Agent System (MAS) into\nIntesa Sanpaolo. The name HEnRY summarizes the project's core principles: the\nHierarchical organization of agents in a layered structure for efficient\nresource management; Efficient optimization of resources and operations to\nenhance overall performance; Reactive ability of agents to quickly respond to\nenvironmental stimuli; and Yielding adaptability and flexibility of agents to\nhandle unexpected situations. The discussion covers two distinct research\npaths: the first focuses on the system architecture, and the second on the\ncollaboration between agents. This work is not limited to the specific\nstructure of the Intesa Sanpaolo context; instead, it leverages existing\nresearch in MAS to introduce a new solution. Since Intesa Sanpaolo is organized\naccording to a model that aligns with international corporate governance best\npractices, this approach could also be relevant to similar scenarios.",
      "tldr_zh": "该研究引入了HEnRY框架，一种Multi-Agent System (MAS)设计，用于多领域上下文，旨在优化Intesa Sanpaolo的资源管理和操作。HEnRY的核心原则包括Hierarchical organization的层级结构、Efficient optimization的性能提升、Reactive ability的快速响应，以及Yielding adaptability的灵活适应性。论文探讨了两个研究路径：系统架构设计和代理间协作，并强调该框架基于现有MAS研究，可扩展应用于类似的企业治理场景。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12720v1",
      "published_date": "2024-10-16 16:28:49 UTC",
      "updated_date": "2024-10-16 16:28:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:15:22.459818"
    },
    {
      "arxiv_id": "2410.12707v1",
      "title": "FusionLLM: A Decentralized LLM Training System on Geo-distributed GPUs with Adaptive Compression",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenheng Tang",
        "Xueze Kang",
        "Yiming Yin",
        "Xinglin Pan",
        "Yuxin Wang",
        "Xin He",
        "Qiang Wang",
        "Rongfei Zeng",
        "Kaiyong Zhao",
        "Shaohuai Shi",
        "Amelie Chi Zhou",
        "Bo Li",
        "Bingsheng He",
        "Xiaowen Chu"
      ],
      "abstract": "To alleviate hardware scarcity in training large deep neural networks (DNNs),\nparticularly large language models (LLMs), we present FusionLLM, a\ndecentralized training system designed and implemented for training DNNs using\ngeo-distributed GPUs across different computing clusters or individual devices.\nDecentralized training faces significant challenges regarding system design and\nefficiency, including: 1) the need for remote automatic differentiation (RAD),\n2) support for flexible model definitions and heterogeneous software, 3)\nheterogeneous hardware leading to low resource utilization or the straggler\nproblem, and 4) slow network communication. To address these challenges, in the\nsystem design, we represent the model as a directed acyclic graph of operators\n(OP-DAG). Each node in the DAG represents the operator in the DNNs, while the\nedge represents the data dependency between operators. Based on this design, 1)\nusers are allowed to customize any DNN without caring low-level operator\nimplementation; 2) we enable the task scheduling with the more fine-grained\nsub-tasks, offering more optimization space; 3) a DAG runtime executor can\nimplement RAD withour requiring the consistent low-level ML framework versions.\n  To enhance system efficiency, we implement a workload estimator and design an\nOP-Fence scheduler to cluster devices with similar bandwidths together and\npartition the DAG to increase throughput. Additionally, we propose an AdaTopK\ncompressor to adaptively compress intermediate activations and gradients at the\nslowest communication links. To evaluate the convergence and efficiency of our\nsystem and algorithms, we train ResNet-101 and GPT-2 on three real-world\ntestbeds using 48 GPUs connected with 8 Mbps~10 Gbps networks. Experimental\nresults demonstrate that our system and method can achieve 1.45 - 9.39x speedup\ncompared to baseline methods while ensuring convergence.",
      "tldr_zh": "本文提出FusionLLM，一种去中心化训练系统，用于在地理分布的GPU上训练LLM和DNNs，以缓解硬件短缺问题。该系统通过将模型表示为操作符的有向无环图(OP-DAG)，实现远程自动微分(RAD)、灵活任务调度和AdaTopK压缩器，以应对异构硬件、资源利用低效和慢速网络通信的挑战。实验在真实测试床上训练ResNet-101和GPT-2，使用48个GPU，结果显示FusionLLM比基线方法提速1.45-9.39倍，同时确保模型收敛。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12707v1",
      "published_date": "2024-10-16 16:13:19 UTC",
      "updated_date": "2024-10-16 16:13:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:15:46.307958"
    },
    {
      "arxiv_id": "2410.12705v5",
      "title": "WorldCuisines: A Massive-Scale Benchmark for Multilingual and Multicultural Visual Question Answering on Global Cuisines",
      "title_zh": "翻译失败",
      "authors": [
        "Genta Indra Winata",
        "Frederikus Hudi",
        "Patrick Amadeus Irawan",
        "David Anugraha",
        "Rifki Afina Putri",
        "Yutong Wang",
        "Adam Nohejl",
        "Ubaidillah Ariq Prathama",
        "Nedjma Ousidhoum",
        "Afifa Amriani",
        "Anar Rzayev",
        "Anirban Das",
        "Ashmari Pramodya",
        "Aulia Adila",
        "Bryan Wilie",
        "Candy Olivia Mawalim",
        "Ching Lam Cheng",
        "Daud Abolade",
        "Emmanuele Chersoni",
        "Enrico Santus",
        "Fariz Ikhwantri",
        "Garry Kuwanto",
        "Hanyang Zhao",
        "Haryo Akbarianto Wibowo",
        "Holy Lovenia",
        "Jan Christian Blaise Cruz",
        "Jan Wira Gotama Putra",
        "Junho Myung",
        "Lucky Susanto",
        "Maria Angelica Riera Machin",
        "Marina Zhukova",
        "Michael Anugraha",
        "Muhammad Farid Adilazuarda",
        "Natasha Santosa",
        "Peerat Limkonchotiwat",
        "Raj Dabre",
        "Rio Alexander Audino",
        "Samuel Cahyawijaya",
        "Shi-Xiong Zhang",
        "Stephanie Yulia Salim",
        "Yi Zhou",
        "Yinxuan Gui",
        "David Ifeoluwa Adelani",
        "En-Shiun Annie Lee",
        "Shogo Okada",
        "Ayu Purwarianti",
        "Alham Fikri Aji",
        "Taro Watanabe",
        "Derry Tanti Wijaya",
        "Alice Oh",
        "Chong-Wah Ngo"
      ],
      "abstract": "Vision Language Models (VLMs) often struggle with culture-specific knowledge,\nparticularly in languages other than English and in underrepresented cultural\ncontexts. To evaluate their understanding of such knowledge, we introduce\nWorldCuisines, a massive-scale benchmark for multilingual and multicultural,\nvisually grounded language understanding. This benchmark includes a visual\nquestion answering (VQA) dataset with text-image pairs across 30 languages and\ndialects, spanning 9 language families and featuring over 1 million data\npoints, making it the largest multicultural VQA benchmark to date. It includes\ntasks for identifying dish names and their origins. We provide evaluation\ndatasets in two sizes (12k and 60k instances) alongside a training dataset (1\nmillion instances). Our findings show that while VLMs perform better with\ncorrect location context, they struggle with adversarial contexts and\npredicting specific regional cuisines and languages. To support future\nresearch, we release a knowledge base with annotated food entries and images\nalong with the VQA data.",
      "tldr_zh": "这篇论文引入了WorldCuisines，一个大规模基准，用于评估Vision Language Models (VLMs) 在多语言和多文化背景下处理文化特定知识的视觉问题回答 (VQA) 能力。该基准包含超过1百万数据点的VQA数据集，覆盖30种语言和方言、9个语系，并包括识别菜名及其来源的任务，提供12k和60k规模的评估数据集以及1百万实例的训练数据集。研究发现，VLMs在正确位置上下文中表现较好，但对对抗性上下文、特定区域美食和语言预测存在挑战。为支持后续研究，作者发布了包含注释食物条目和图像的知识库。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "Best Theme Paper at NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.12705v5",
      "published_date": "2024-10-16 16:11:49 UTC",
      "updated_date": "2025-05-08 08:46:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:15:48.405035"
    },
    {
      "arxiv_id": "2410.12700v1",
      "title": "Embedding an Ethical Mind: Aligning Text-to-Image Synthesis via Lightweight Value Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Xingqi Wang",
        "Xiaoyuan Yi",
        "Xing Xie",
        "Jia Jia"
      ],
      "abstract": "Recent advancements in diffusion models trained on large-scale data have\nenabled the generation of indistinguishable human-level images, yet they often\nproduce harmful content misaligned with human values, e.g., social bias, and\noffensive content. Despite extensive research on Large Language Models (LLMs),\nthe challenge of Text-to-Image (T2I) model alignment remains largely\nunexplored. Addressing this problem, we propose LiVO (Lightweight Value\nOptimization), a novel lightweight method for aligning T2I models with human\nvalues. LiVO only optimizes a plug-and-play value encoder to integrate a\nspecified value principle with the input prompt, allowing the control of\ngenerated images over both semantics and values. Specifically, we design a\ndiffusion model-tailored preference optimization loss, which theoretically\napproximates the Bradley-Terry model used in LLM alignment but provides a more\nflexible trade-off between image quality and value conformity. To optimize the\nvalue encoder, we also develop a framework to automatically construct a\ntext-image preference dataset of 86k (prompt, aligned image, violating image,\nvalue principle) samples. Without updating most model parameters and through\nadaptive value selection from the input prompt, LiVO significantly reduces\nharmful outputs and achieves faster convergence, surpassing several strong\nbaselines and taking an initial step towards ethically aligned T2I models.",
      "tldr_zh": "该论文针对扩散模型在 Text-to-Image (T2I) 生成中可能产生社会偏见和有害内容的问题，提出了一种轻量级方法 LiVO（Lightweight Value Optimization）。LiVO 通过优化一个可插入的 value encoder 与输入提示整合指定的价值原则，并设计了一个针对扩散模型的偏好优化损失函数，该函数类似于 Bradley-Terry model 但提供更灵活的图像质量与价值符合性权衡。研究还构建了一个包含 86k 个文本-图像偏好数据集的框架，用于训练 value encoder，无需更新大多数模型参数，即可显著减少有害输出、实现更快收敛，并优于现有基线，从而为道德校准的 T2I 模型奠定基础。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CY",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ACM Multimedia 2024. The dataset and code can be found at\n  https://github.com/achernarwang/LiVO",
      "pdf_url": "http://arxiv.org/pdf/2410.12700v1",
      "published_date": "2024-10-16 16:03:42 UTC",
      "updated_date": "2024-10-16 16:03:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:16:00.600856"
    },
    {
      "arxiv_id": "2410.12895v1",
      "title": "Large Language Models and the Rationalist Empiricist Debate",
      "title_zh": "大语言模型与理性主义经验主义争论",
      "authors": [
        "David King"
      ],
      "abstract": "To many Chomsky's debates with Quine and Skinner are an updated version of\nthe Rationalist Empiricist debates of the 17th century. The consensus being\nthat Chomsky's Rationalism was victorious. This dispute has reemerged with the\nadvent of Large Language Models. With some arguing that LLMs vindicate\nrationalism because of the necessity of building in innate biases to make them\nwork. The necessity of building in innate biases is taken to prove that\nempiricism hasn't got the conceptual resources to explain linguistic\ncompetence. Such claims depend on the nature of the empiricism one is\nendorsing. Externalized Empiricism has no difficulties with innate apparatus\nonce they are determined empirically (Quine 1969). Thus, externalized\nempiricism is not refuted because of the need to build in innate biases in\nLLMs. Furthermore, the relevance of LLMs to the rationalist empiricist debate\nin relation to humans is dubious. For any claim about whether LLMs learn in an\nempiricist manner to be relevant to humans it needs to be shown that LLMs and\nhumans learn in the same way. Two key features distinguish humans and LLMs.\nHumans learn despite a poverty of stimulus and LLMs learn because of an\nincredibly rich stimulus. Human linguistic outputs are grounded in sensory\nexperience and LLMs are not. These differences in how the two learn indicates\nthat they both use different underlying competencies to produce their output.\nTherefore, any claims about whether LLMs learn in an empiricist manner are not\nrelevant to whether humans learn in an empiricist manner.",
      "tldr_zh": "这篇论文探讨了大型语言模型（LLMs）与理性主义（Rationalism）和经验主义（Empiricism）辩论的关系，指出有些人认为LLMs需要内置先天偏差（innate biases），这支持理性主义并质疑经验主义解释语言能力的能力。论文辩称，外部化经验主义（Externalized Empiricism）可以接受经验确定的先天设备，因此LLMs的需求并不反驳经验主义。最终，论文强调人类学习依赖刺激贫乏的环境和感官经验，而LLMs依赖丰富的刺激和不同机制，因此LLMs的学习方式无法直接应用于人类语言学习的相关辩论。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12895v1",
      "published_date": "2024-10-16 15:49:33 UTC",
      "updated_date": "2024-10-16 15:49:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:16:11.608946"
    },
    {
      "arxiv_id": "2410.12686v2",
      "title": "Automatic Mapping of Anatomical Landmarks from Free-Text Using Large Language Models: Insights from Llama-2",
      "title_zh": "翻译失败",
      "authors": [
        "Mohamad Abdi",
        "Gerardo Hermosillo Valadez",
        "Halid Ziya Yerebakan"
      ],
      "abstract": "Anatomical landmarks are vital in medical imaging for navigation and anomaly\ndetection. Modern large language models (LLMs), like Llama-2, offer promise for\nautomating the mapping of these landmarks in free-text radiology reports to\ncorresponding positions in image data. Recent studies propose LLMs may develop\ncoherent representations of generative processes. Motivated by these insights,\nwe investigated whether LLMs accurately represent the spatial positions of\nanatomical landmarks. Through experiments with Llama-2 models, we found that\nthey can linearly represent anatomical landmarks in space with considerable\nrobustness to different prompts. These results underscore the potential of LLMs\nto enhance the efficiency and accuracy of medical imaging workflows.",
      "tldr_zh": "本研究探讨了使用大型语言模型(LLMs)如 Llama-2 从自由文本放射学报告中自动映射解剖标志(anatomical landmarks)的空间位置，以提升医学成像中的导航和异常检测。实验结果表明，Llama-2 能够线性表示这些标志的空间位置，并对不同提示显示出显著的鲁棒性。这些发现证明了 LLMs 在提高医学成像工作流程效率和准确性的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages, 2 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2410.12686v2",
      "published_date": "2024-10-16 15:48:28 UTC",
      "updated_date": "2024-10-17 12:52:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:16:22.673275"
    },
    {
      "arxiv_id": "2410.12683v1",
      "title": "Generative Neural Reparameterization for Differentiable PDE-constrained Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Archis S. Joglekar"
      ],
      "abstract": "Partial-differential-equation (PDE)-constrained optimization is a well-worn\ntechnique for acquiring optimal parameters of systems governed by PDEs.\nHowever, this approach is limited to providing a single set of optimal\nparameters per optimization. Given a differentiable PDE solver, if the free\nparameters are reparameterized as the output of a neural network, that neural\nnetwork can be trained to learn a map from a probability distribution to the\ndistribution of optimal parameters. This proves useful in the case where there\nare many well performing local minima for the PDE. We apply this technique to\ntrain a neural network that generates optimal parameters that minimize\nlaser-plasma instabilities relevant to laser fusion and show that the neural\nnetwork generates many well performing and diverse minima.",
      "tldr_zh": "该论文提出了一种生成式神经重新参数化方法，用于可微分 PDE-constrained optimization，以克服传统方法仅提供单一优化参数集的局限性。通过将自由参数重新表述为神经网络的输出，并训练网络学习从概率分布到优化参数分布的映射，该方法能生成多个良好局部最小值。论文在激光-plasma instabilities（与激光聚变相关）的优化问题上进行了应用，结果显示神经网络生成了多样且性能优越的参数集。",
      "categories": [
        "physics.comp-ph",
        "cs.AI",
        "cs.LG",
        "cs.NA",
        "math.NA",
        "physics.plasm-ph"
      ],
      "primary_category": "physics.comp-ph",
      "comment": "Accepted to D3S3: Data-driven and Differentiable Simulations,\n  Surrogates, and Solvers - Workshop @ NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.12683v1",
      "published_date": "2024-10-16 15:46:48 UTC",
      "updated_date": "2024-10-16 15:46:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:16:35.290821"
    },
    {
      "arxiv_id": "2410.12672v5",
      "title": "Context Matters: Leveraging Contextual Features for Time Series Forecasting",
      "title_zh": "上下文至关重要：利用上下文特征进行时间序列预测",
      "authors": [
        "Sameep Chattopadhyay",
        "Pulkit Paliwal",
        "Sai Shankar Narasimhan",
        "Shubhankar Agarwal",
        "Sandeep P. Chinchali"
      ],
      "abstract": "Time series forecasts are often influenced by exogenous contextual features\nin addition to their corresponding history. For example, in financial settings,\nit is hard to accurately predict a stock price without considering public\nsentiments and policy decisions in the form of news articles, tweets, etc.\nThough this is common knowledge, the current state-of-the-art (SOTA)\nforecasting models fail to incorporate such contextual information, owing to\nits heterogeneity and multimodal nature. To address this, we introduce\nContextFormer, a novel plug-and-play method to surgically integrate multimodal\ncontextual information into existing pre-trained forecasting models.\nContextFormer effectively distills forecast-specific information from rich\nmultimodal contexts, including categorical, continuous, time-varying, and even\ntextual information, to significantly enhance the performance of existing base\nforecasters. ContextFormer outperforms SOTA forecasting models by up to 30% on\na range of real-world datasets spanning energy, traffic, environmental, and\nfinancial domains.",
      "tldr_zh": "时间序列预测常受外生上下文特征（如新闻和推文）的影响，但现有SOTA模型未能有效整合这些异质多模态信息，导致预测准确性不足。  \n本文提出ContextFormer，一种新型即插即用方法，能够从多模态上下文中提取预测特定信息，包括分类、连续、时间变化和文本特征，并将其整合到现有预训练预测模型中。  \n实验结果显示，ContextFormer在能源、交通、环境和金融领域的真实数据集上，比SOTA模型性能提升高达30%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12672v5",
      "published_date": "2024-10-16 15:36:13 UTC",
      "updated_date": "2025-01-13 20:42:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:16:47.169686"
    },
    {
      "arxiv_id": "2410.12665v1",
      "title": "Hamiltonian bridge: A physics-driven generative framework for targeted pattern control",
      "title_zh": "Hamiltonian bridge：一种基于物理驱动的生成框架，用于针对性模式控制",
      "authors": [
        "Vishaal Krishnan",
        "Sumit Sinha",
        "L. Mahadevan"
      ],
      "abstract": "Patterns arise spontaneously in a range of systems spanning the sciences, and\ntheir study typically focuses on mechanisms to understand their evolution in\nspace-time. Increasingly, there has been a transition towards controlling these\npatterns in various functional settings, with implications for engineering.\nHere, we combine our knowledge of a general class of dynamical laws for pattern\nformation in non-equilibrium systems, and the power of stochastic optimal\ncontrol approaches to present a framework that allows us to control patterns at\nmultiple scales, which we dub the \"Hamiltonian bridge\". We use a mapping\nbetween stochastic many-body Lagrangian physics and deterministic Eulerian\npattern forming PDEs to leverage our recent approach utilizing the\nFeynman-Kac-based adjoint path integral formulation for the control of\ninteracting particles and generalize this to the active control of patterning\nfields. We demonstrate the applicability of our computational framework via\nnumerical experiments on the control of phase separation with and without a\nconserved order parameter, self-assembly of fluid droplets, coupled\nreaction-diffusion equations and finally a phenomenological model for\nspatio-temporal tissue differentiation. We interpret our numerical experiments\nin terms of a theoretical understanding of how the underlying physics shapes\nthe geometry of the pattern manifold, altering the transport paths of patterns\nand the nature of pattern interpolation. We finally conclude by showing how\noptimal control can be utilized to generate complex patterns via an iterative\ncontrol protocol over pattern forming pdes which can be casted as gradient\nflows. All together, our study shows how we can systematically build in\nphysical priors into a generative framework for pattern control in\nnon-equilibrium systems across multiple length and time scales.",
      "tldr_zh": "本文提出“Hamiltonian bridge”框架，这是一种基于物理驱动的生成方法，结合非平衡系统模式形成的动力学定律和随机最优控制(stochastic optimal control)方法，实现对模式在多个尺度上的针对性控制。框架通过将随机多体Lagrangian物理映射到确定性Eulerian模式形成PDEs，并利用Feynman-Kac-based adjoint path integral公式，扩展到模式场的主动控制。数值实验展示了其在相分离、流体液滴自组装、耦合反应-diffusion方程和组织分化模型中的有效性，并阐释了底层物理如何塑造模式流形(pattern manifold)的几何，影响模式传输路径和插值。最后，该框架通过迭代控制协议，将模式形成PDEs视为梯度流，系统性地融入物理先验以生成复杂模式。",
      "categories": [
        "cond-mat.soft",
        "cond-mat.stat-mech",
        "cs.AI",
        "math.DS",
        "math.OC"
      ],
      "primary_category": "cond-mat.soft",
      "comment": "29 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.12665v1",
      "published_date": "2024-10-16 15:24:54 UTC",
      "updated_date": "2024-10-16 15:24:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:17:00.773933"
    },
    {
      "arxiv_id": "2410.12662v2",
      "title": "Cross-Modal Safety Mechanism Transfer in Large Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Shicheng Xu",
        "Liang Pang",
        "Yunchang Zhu",
        "Huawei Shen",
        "Xueqi Cheng"
      ],
      "abstract": "Vision-language alignment in Large Vision-Language Models (LVLMs)\nsuccessfully enables LLMs to understand visual input. However, we find that\nexisting vision-language alignment methods fail to transfer the existing safety\nmechanism for text in LLMs to vision, which leads to vulnerabilities in toxic\nimage. To explore the cause of this problem, we give the insightful explanation\nof where and how the safety mechanism of LVLMs operates and conduct comparative\nanalysis between text and vision. We find that the hidden states at the\nspecific transformer layers play a crucial role in the successful activation of\nsafety mechanism, while the vision-language alignment at hidden states level in\ncurrent methods is insufficient. This results in a semantic shift for input\nimages compared to text in hidden states, therefore misleads the safety\nmechanism. To address this, we propose a novel Text-Guided vision-language\nAlignment method (TGA) for LVLMs. TGA retrieves the texts related to input\nvision and uses them to guide the projection of vision into the hidden states\nspace in LLMs. Experiments show that TGA not only successfully transfers the\nsafety mechanism for text in basic LLMs to vision in vision-language alignment\nfor LVLMs without any safety fine-tuning on the visual modality but also\nmaintains the general performance on various vision tasks (Safe and Good).",
      "tldr_zh": "这篇论文探讨了 Large Vision-Language Models (LVLMs) 中视觉-语言对齐的问题，发现现有方法无法有效转移 LLM 中的文本安全机制到视觉输入，导致对有毒图像的漏洞。作者通过分析特定 transformer 层的隐藏状态，揭示了语义偏移是关键原因，并提出 Text-Guided vision-language Alignment (TGA) 方法，使用相关文本指导视觉投影到 LLM 的隐藏状态空间。实验结果显示，TGA 成功实现了安全机制的跨模态转移，无需对视觉模式进行安全微调，同时保持了在各种视觉任务的整体性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.12662v2",
      "published_date": "2024-10-16 15:20:08 UTC",
      "updated_date": "2025-02-28 06:17:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:17:12.081928"
    },
    {
      "arxiv_id": "2410.12656v3",
      "title": "Evaluating Morphological Compositional Generalization in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Mete Ismayilzada",
        "Defne Circi",
        "Jonne Sälevä",
        "Hale Sirin",
        "Abdullatif Köksal",
        "Bhuwan Dhingra",
        "Antoine Bosselut",
        "Duygu Ataman",
        "Lonneke van der Plas"
      ],
      "abstract": "Large language models (LLMs) have demonstrated significant progress in\nvarious natural language generation and understanding tasks. However, their\nlinguistic generalization capabilities remain questionable, raising doubts\nabout whether these models learn language similarly to humans. While humans\nexhibit compositional generalization and linguistic creativity in language use,\nthe extent to which LLMs replicate these abilities, particularly in morphology,\nis under-explored. In this work, we systematically investigate the\nmorphological generalization abilities of LLMs through the lens of\ncompositionality. We define morphemes as compositional primitives and design a\nnovel suite of generative and discriminative tasks to assess morphological\nproductivity and systematicity. Focusing on agglutinative languages such as\nTurkish and Finnish, we evaluate several state-of-the-art instruction-finetuned\nmultilingual models, including GPT-4 and Gemini. Our analysis shows that LLMs\nstruggle with morphological compositional generalization particularly when\napplied to novel word roots, with performance declining sharply as\nmorphological complexity increases. While models can identify individual\nmorphological combinations better than chance, their performance lacks\nsystematicity, leading to significant accuracy gaps compared to humans.",
      "tldr_zh": "这篇论文评估了大型语言模型 (LLMs) 在形态学组成泛化方面的能力，探讨这些模型是否像人类一样具备语言组成性和创造力。研究者定义了 morphemes 作为组成基元，设计了一系列生成和判别任务，针对 Turkish 和 Finnish 等 agglutinative languages 测试了 GPT-4 和 Gemini 等模型。结果显示，LLMs 在处理新词根时挣扎，随着 morphological complexity 增加，性能急剧下降，尽管在识别单个形态组合时优于随机水平，但整体缺乏 systematicity，与人类表现存在显著差距。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.12656v3",
      "published_date": "2024-10-16 15:17:20 UTC",
      "updated_date": "2025-02-09 22:08:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:17:23.709775"
    },
    {
      "arxiv_id": "2410.12652v1",
      "title": "Constrained Posterior Sampling: Time Series Generation with Hard Constraints",
      "title_zh": "约束后验采样",
      "authors": [
        "Sai Shankar Narasimhan",
        "Shubhankar Agarwal",
        "Litu Rout",
        "Sanjay Shakkottai",
        "Sandeep P. Chinchali"
      ],
      "abstract": "Generating realistic time series samples is crucial for stress-testing models\nand protecting user privacy by using synthetic data. In engineering and\nsafety-critical applications, these samples must meet certain hard constraints\nthat are domain-specific or naturally imposed by physics or nature. Consider,\nfor example, generating electricity demand patterns with constraints on peak\ndemand times. This can be used to stress-test the functioning of power grids\nduring adverse weather conditions. Existing approaches for generating\nconstrained time series are either not scalable or degrade sample quality. To\naddress these challenges, we introduce Constrained Posterior Sampling (CPS), a\ndiffusion-based sampling algorithm that aims to project the posterior mean\nestimate into the constraint set after each denoising update. Notably, CPS\nscales to a large number of constraints (~100) without requiring additional\ntraining. We provide theoretical justifications highlighting the impact of our\nprojection step on sampling. Empirically, CPS outperforms state-of-the-art\nmethods in sample quality and similarity to real time series by around 10% and\n42%, respectively, on real-world stocks, traffic, and air quality datasets.",
      "tldr_zh": "本论文针对生成受硬约束（如物理或领域限制）的时间序列样本的问题，提出了一种名为 Constrained Posterior Sampling (CPS) 的 diffusion-based 采样算法，以支持模型压力测试和用户隐私保护。CPS 通过在每个 denoising 更新后将后验均值估计投影到约束集，确保样本满足大量约束（如约100个）而无需额外训练，并提供了理论证明阐述投影步骤对采样的影响。在真实数据集（如股票、交通和空气质量）上，实验结果显示 CPS 在样本质量上比现有方法提升约10%，在与真实时间序列的相似性上提升约42%。这为工程和安全关键应用提供了更可靠的合成数据生成工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12652v1",
      "published_date": "2024-10-16 15:16:04 UTC",
      "updated_date": "2024-10-16 15:16:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:17:34.866222"
    },
    {
      "arxiv_id": "2410.12641v1",
      "title": "Cascade learning in multi-task encoder-decoder networks for concurrent bone segmentation and glenohumeral joint assessment in shoulder CT scans",
      "title_zh": "翻译失败",
      "authors": [
        "Luca Marsilio",
        "Davide Marzorati",
        "Matteo Rossi",
        "Andrea Moglia",
        "Luca Mainardi",
        "Alfonso Manzotti",
        "Pietro Cerveri"
      ],
      "abstract": "Osteoarthritis is a degenerative condition affecting bones and cartilage,\noften leading to osteophyte formation, bone density loss, and joint space\nnarrowing. Treatment options to restore normal joint function vary depending on\nthe severity of the condition. This work introduces an innovative deep-learning\nframework processing shoulder CT scans. It features the semantic segmentation\nof the proximal humerus and scapula, the 3D reconstruction of bone surfaces,\nthe identification of the glenohumeral (GH) joint region, and the staging of\nthree common osteoarthritic-related pathologies: osteophyte formation (OS), GH\nspace reduction (JS), and humeroscapular alignment (HSA). The pipeline\ncomprises two cascaded CNN architectures: 3D CEL-UNet for segmentation and 3D\nArthro-Net for threefold classification. A retrospective dataset of 571 CT\nscans featuring patients with various degrees of GH osteoarthritic-related\npathologies was used to train, validate, and test the pipeline. Root mean\nsquared error and Hausdorff distance median values for 3D reconstruction were\n0.22mm and 1.48mm for the humerus and 0.24mm and 1.48mm for the scapula,\noutperforming state-of-the-art architectures and making it potentially suitable\nfor a PSI-based shoulder arthroplasty preoperative plan context. The\nclassification accuracy for OS, JS, and HSA consistently reached around 90%\nacross all three categories. The computational time for the inference pipeline\nwas less than 15s, showcasing the framework's efficiency and compatibility with\northopedic radiology practice. The outcomes represent a promising advancement\ntoward the medical translation of artificial intelligence tools. This progress\naims to streamline the preoperative planning pipeline delivering high-quality\nbone surfaces and supporting surgeons in selecting the most suitable surgical\napproach according to the unique patient joint conditions.",
      "tldr_zh": "该研究提出了一种多任务编码器-解码器网络的级联学习框架，用于同时处理肩部 CT 扫描中的骨骼分割和 Glenohumeral (GH) 关节评估。该框架包括 3D CEL-UNet 用于近端肱骨和肩胛骨的语义分割，以及 3D Arthro-Net 用于识别 GH 关节区域并分类三种骨关节炎相关病变：Osteophyte formation (OS)、GH space reduction (JS) 和 Humeroscapular alignment (HSA)。在包含 571 个 CT 扫描的回顾性数据集上，框架实现了 3D 重建的 RMSE 为 0.22-0.24mm 和 Hausdorff 距离中值为 1.48mm，以及各分类准确率约 90%，推理时间小于 15 秒，比现有架构表现更优。整体结果展示了该方法在简化术前规划和支持外科医生选择手术方案方面的潜力，推动 AI 在骨关节炎诊断中的医学应用。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12641v1",
      "published_date": "2024-10-16 15:00:31 UTC",
      "updated_date": "2024-10-16 15:00:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:17:49.389899"
    },
    {
      "arxiv_id": "2410.12631v1",
      "title": "Explainable Moral Values: a neuro-symbolic approach to value classification",
      "title_zh": "可解释的",
      "authors": [
        "Nicolas Lazzari",
        "Stefano De Giorgis",
        "Aldo Gangemi",
        "Valentina Presutti"
      ],
      "abstract": "This work explores the integration of ontology-based reasoning and Machine\nLearning techniques for explainable value classification. By relying on an\nontological formalization of moral values as in the Moral Foundations Theory,\nrelying on the DnS Ontology Design Pattern, the \\textit{sandra} neuro-symbolic\nreasoner is used to infer values (fomalized as descriptions) that are\n\\emph{satisfied by} a certain sentence. Sentences, alongside their structured\nrepresentation, are automatically generated using an open-source Large Language\nModel. The inferred descriptions are used to automatically detect the value\nassociated with a sentence. We show that only relying on the reasoner's\ninference results in explainable classification comparable to other more\ncomplex approaches. We show that combining the reasoner's inferences with\ndistributional semantics methods largely outperforms all the baselines,\nincluding complex models based on neural network architectures. Finally, we\nbuild a visualization tool to explore the potential of theory-based values\nclassification, which is publicly available at http://xmv.geomeaning.com/.",
      "tldr_zh": "该研究提出了一种 neuro-symbolic 方法，结合本体论推理和机器学习技术，用于可解释的价值分类，基于 Moral Foundations Theory 和 DnS Ontology Design Pattern。利用 sandra 推理器从自动生成的句子中推断道德价值描述，并与分布语义方法整合，实现高效的分类。结果表明，仅靠推理器即可达到与复杂模型相当的可解释性，而结合语义方法时性能大幅优于基线；此外，研究还开发了一个公开可视化工具（http://xmv.geomeaning.com/），以探索理论驱动的价值分类潜力。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Published at ESWC24 Satellite Event",
      "pdf_url": "http://arxiv.org/pdf/2410.12631v1",
      "published_date": "2024-10-16 14:53:13 UTC",
      "updated_date": "2024-10-16 14:53:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:17:59.772315"
    },
    {
      "arxiv_id": "2410.13907v2",
      "title": "NSmark: Null Space Based Black-box Watermarking Defense Framework for Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Haodong Zhao",
        "Jinming Hu",
        "Peixuan Li",
        "Fangqi Li",
        "Jinrui Sha",
        "Tianjie Ju",
        "Peixuan Chen",
        "Zhuosheng Zhang",
        "Gongshen Liu"
      ],
      "abstract": "Language models (LMs) have emerged as critical intellectual property (IP)\nassets that necessitate protection. Although various watermarking strategies\nhave been proposed, they remain vulnerable to Linear Functionality Equivalence\nAttack (LFEA), which can invalidate most existing white-box watermarks without\nprior knowledge of the watermarking scheme or training data. This paper\nanalyzes and extends the attack scenarios of LFEA to the commonly employed\nblack-box settings for LMs by considering Last-Layer outputs (dubbed LL-LFEA).\nWe discover that the null space of the output matrix remains invariant against\nLL-LFEA attacks. Based on this finding, we propose NSmark, a black-box\nwatermarking scheme that is task-agnostic and capable of resisting LL-LFEA\nattacks. NSmark consists of three phases: (i) watermark generation using the\ndigital signature of the owner, enhanced by spread spectrum modulation for\nincreased robustness; (ii) watermark embedding through an output mapping\nextractor that preserves the LM performance while maximizing watermark\ncapacity; (iii) watermark verification, assessed by extraction rate and null\nspace conformity. Extensive experiments on both pre-training and downstream\ntasks confirm the effectiveness, scalability, reliability, fidelity, and\nrobustness of our approach. Code is available at\nhttps://github.com/dongdongzhaoUP/NSmark.",
      "tldr_zh": "本文分析了语言模型 (LMs) 水印策略的漏洞，特别是 Linear Functionality Equivalence Attack (LFEA) 在黑盒设置下的扩展 (LL-LFEA)，发现输出矩阵的 Null Space 对此类攻击保持不变。基于此，提出 NSmark 框架，一种任务无关的黑盒水印方案，包括水印生成 (使用数字签名和扩频调制)、嵌入 (通过输出映射提取器保持模型性能) 和验证 (评估提取率和 Null Space 一致性) 三个阶段。实验在预训练和下游任务上验证了 NSmark 的有效性、可扩展性、可靠性和鲁棒性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "In progress",
      "pdf_url": "http://arxiv.org/pdf/2410.13907v2",
      "published_date": "2024-10-16 14:45:27 UTC",
      "updated_date": "2025-02-03 03:15:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:18:14.530783"
    },
    {
      "arxiv_id": "2410.12613v1",
      "title": "Exploring Model Kinship for Merging Large Language Models",
      "title_zh": "探索模型亲缘关系用于合并大型语言模型",
      "authors": [
        "Yedi Hu",
        "Yunzhi Yao",
        "Ningyu Zhang",
        "Shumin Deng",
        "Huajun Chen"
      ],
      "abstract": "Model merging has become one of the key technologies for enhancing the\ncapabilities and efficiency of Large Language Models (LLMs). However, our\nunderstanding of the expected performance gains and principles when merging any\ntwo models remains limited. In this work, we introduce model kinship, the\ndegree of similarity or relatedness between LLMs, analogous to biological\nevolution. With comprehensive empirical analysis, we find that there is a\ncertain relationship between model kinship and the performance gains after\nmodel merging, which can help guide our selection of candidate models. Inspired\nby this, we propose a new model merging strategy: Top-k Greedy Merging with\nModel Kinship, which can yield better performance on benchmark datasets.\nSpecifically, we discover that using model kinship as a criterion can assist us\nin continuously performing model merging, alleviating the degradation (local\noptima) in model evolution, whereas model kinship can serve as a guide to\nescape these traps. Code is available at\nhttps://github.com/zjunlp/ModelKinship.",
      "tldr_zh": "本文探讨了Large Language Models (LLMs)合并技术的优化问题，引入“model kinship”概念来衡量模型间的相似度或相关性，类似于生物进化，以指导模型选择。研究通过全面实证分析发现，model kinship与合并后的性能提升存在显著关系，并据此提出Top-k Greedy Merging with Model Kinship策略，该策略能在基准数据集上实现更好的性能表现。进一步，model kinship作为指导标准，能缓解模型合并过程中的退化问题（如局部最优），促进模型持续进化。代码已开源在指定仓库。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "Ongoing work",
      "pdf_url": "http://arxiv.org/pdf/2410.12613v1",
      "published_date": "2024-10-16 14:29:29 UTC",
      "updated_date": "2024-10-16 14:29:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:18:26.461236"
    },
    {
      "arxiv_id": "2410.12609v2",
      "title": "Towards Graph Foundation Models: Training on Knowledge Graphs Enables Transferability to General Graphs",
      "title_zh": "朝向图基础模型：在知识图上训练实现对一般图的转移性",
      "authors": [
        "Kai Wang",
        "Siqiang Luo",
        "Caihua Shan",
        "Yifei Shen"
      ],
      "abstract": "Inspired by the success of large language models, there is a trend toward\ndeveloping graph foundation models to conduct diverse downstream tasks in\nvarious domains. However, current models often require extra fine-tuning to\napply their learned structural and semantic representations to new graphs,\nwhich limits their versatility. Recent breakthroughs in zero-shot inductive\nreasoning on knowledge graphs (KGs), offer us a new perspective on extending KG\nreasoning to general graph applications. In this paper, we introduce SCR, a\nunified graph reasoning framework designed to train on knowledge graphs and\neffectively generalize across a wide range of graph tasks and domains. We begin\nby designing the task-specific KG structures to establish a unified topology\nfor different task formats. Then we propose semantic-conditioned message\npassing, a novel mechanism addressing the inherent semantic isolation in\ntraditional KG reasoning, by jointly modeling structural and semantic\ninvariance patterns in graph representations. To demonstrate the effectiveness,\nwe evaluate the inductive reasoning capability of SCR using 38 diverse graph\ndatasets, covering node-level, link-level, and graph-level tasks across\nmultiple domains. Our results show substantial performance gains over existing\nfoundation models and supervised baselines, highlighting the efficacy and\nadaptability of our approach.",
      "tldr_zh": "本研究受大型语言模型启发，提出一种图基础模型框架 SCR，通过在知识图谱（KGs）上训练，实现零样本归纳推理并泛化到各种通用图任务。SCR 设计了任务特定的 KG 结构来统一拓扑，并引入语义条件消息传递（semantic-conditioned message passing）机制，联合建模图的结构和语义不变模式，以解决传统 KG 推理中的语义隔离问题。在 38 个多样化数据集上的评估中，SCR 在节点级、链接级和图级任务中显著超越现有基础模型和监督基线，展示了其高效性和适应性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "25 Pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.12609v2",
      "published_date": "2024-10-16 14:26:08 UTC",
      "updated_date": "2025-05-15 14:27:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:18:35.398706"
    },
    {
      "arxiv_id": "2410.12607v1",
      "title": "Low-Rank Adversarial PGD Attack",
      "title_zh": "翻译失败",
      "authors": [
        "Dayana Savostianova",
        "Emanuele Zangrando",
        "Francesco Tudisco"
      ],
      "abstract": "Adversarial attacks on deep neural network models have seen rapid development\nand are extensively used to study the stability of these networks. Among\nvarious adversarial strategies, Projected Gradient Descent (PGD) is a widely\nadopted method in computer vision due to its effectiveness and quick\nimplementation, making it suitable for adversarial training. In this work, we\nobserve that in many cases, the perturbations computed using PGD predominantly\naffect only a portion of the singular value spectrum of the original image,\nsuggesting that these perturbations are approximately low-rank. Motivated by\nthis observation, we propose a variation of PGD that efficiently computes a\nlow-rank attack. We extensively validate our method on a range of standard\nmodels as well as robust models that have undergone adversarial training. Our\nanalysis indicates that the proposed low-rank PGD can be effectively used in\nadversarial training due to its straightforward and fast implementation coupled\nwith competitive performance. Notably, we find that low-rank PGD often performs\ncomparably to, and sometimes even outperforms, the traditional full-rank PGD\nattack, while using significantly less memory.",
      "tldr_zh": "该研究观察到，Projected Gradient Descent (PGD) 在对抗攻击中生成的扰动通常是近似低秩的，因此提出了一种高效的低秩版本 PGD 攻击方法，以减少计算资源需求。研究者在标准模型和经过对抗训练的鲁棒模型上进行了广泛验证，结果显示低秩 PGD 攻击的性能与传统全秩 PGD 相当甚至优于后者，同时显著降低内存使用。总体而言，这一方法为对抗训练提供了简单、快速的实现路径，提升了深度神经网络稳定性的研究效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NA",
        "math.NA",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12607v1",
      "published_date": "2024-10-16 14:24:51 UTC",
      "updated_date": "2024-10-16 14:24:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:18:47.338118"
    },
    {
      "arxiv_id": "2410.12606v2",
      "title": "Self-Supervised Learning of Disentangled Representations for Multivariate Time-Series",
      "title_zh": "翻译失败",
      "authors": [
        "Ching Chang",
        "Chiao-Tung Chan",
        "Wei-Yao Wang",
        "Wen-Chih Peng",
        "Tien-Fu Chen"
      ],
      "abstract": "Multivariate time-series data in fields like healthcare and industry are\ninformative but challenging due to high dimensionality and lack of labels.\nRecent self-supervised learning methods excel in learning rich representations\nwithout labels but struggle with disentangled embeddings and inductive bias\nissues like transformation-invariance. To address these challenges, we\nintroduce TimeDRL, a framework for multivariate time-series representation\nlearning with dual-level disentangled embeddings. TimeDRL features: (i)\ndisentangled timestamp-level and instance-level embeddings using a [CLS] token\nstrategy; (ii) timestamp-predictive and instance-contrastive tasks for\nrepresentation learning; and (iii) avoidance of augmentation methods to\neliminate inductive biases. Experiments on forecasting and classification\ndatasets show TimeDRL outperforms existing methods, with further validation in\nsemi-supervised settings with limited labeled data.",
      "tldr_zh": "这篇论文针对多元时间序列（Multivariate Time-Series）数据的自监督学习（Self-Supervised Learning）挑战，提出 TimeDRL 框架，以实现解缠表示（Disentangled Representations），解决现有方法在嵌入纠缠和归纳偏差（如变换不变性）上的问题。TimeDRL 通过 [CLS] token 策略生成时间戳级和实例级嵌入，并采用时间戳预测和实例对比任务进行表示学习，同时避免使用数据增强方法以消除归纳偏差。在预测和分类数据集上的实验表明，TimeDRL 优于现有方法，并在半监督设置下（有限标签数据）表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This submission has been withdrawn to avoid duplication with a full\n  version of the paper that is already available in another arXiv entry\n  (arXiv:2410.12606). The withdrawn version was a short format prepared for a\n  NeurIPS workshop and is no longer necessary as a separate arXiv submission",
      "pdf_url": "http://arxiv.org/pdf/2410.12606v2",
      "published_date": "2024-10-16 14:24:44 UTC",
      "updated_date": "2024-10-21 06:27:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:18:59.593879"
    },
    {
      "arxiv_id": "2410.12593v1",
      "title": "Expand and Compress: Exploring Tuning Principles for Continual Spatio-Temporal Graph Forecasting",
      "title_zh": "扩展与压缩：探索持续时空图预测的调整原则",
      "authors": [
        "Wei Chen",
        "Yuxuan Liang"
      ],
      "abstract": "The widespread deployment of sensing devices leads to a surge in data for\nspatio-temporal forecasting applications such as traffic flow, air quality, and\nwind energy. Although spatio-temporal graph neural networks have achieved\nsuccess in modeling various static spatio-temporal forecasting scenarios,\nreal-world spatio-temporal data are typically received in a streaming manner,\nand the network continuously expands with the installation of new sensors.\nThus, spatio-temporal forecasting in streaming scenarios faces dual challenges:\nthe inefficiency of retraining models over newly arrived data and the\ndetrimental effects of catastrophic forgetting over long-term history. To\naddress these challenges, we propose a novel prompt tuning-based continuous\nforecasting method, following two fundamental tuning principles guided by\nempirical and theoretical analysis: expand and compress, which effectively\nresolve the aforementioned problems with lightweight tuning parameters.\nSpecifically, we integrate the base spatio-temporal graph neural network with a\ncontinuous prompt pool, utilizing stored prompts (i.e., few learnable\nparameters) in memory, and jointly optimize them with the base spatio-temporal\ngraph neural network. This method ensures that the model sequentially learns\nfrom the spatio-temporal data stream to accomplish tasks for corresponding\nperiods. Extensive experimental results on multiple real-world datasets\ndemonstrate the multi-faceted superiority of our method over the\nstate-of-the-art baselines, including effectiveness, efficiency, universality,\netc.",
      "tldr_zh": "该研究探讨了在流式时空数据场景下（如交通流量、空气质量预测），spatio-temporal graph neural networks 面临的重新训练低效和catastrophic forgetting 问题。作者提出了一种基于提示调优的连续预测方法，遵循“expand and compress”原则，通过整合基时空图神经网络与连续提示池，使用少量可学习参数进行联合优化，实现模型对数据流的顺序学习。实验结果显示，该方法在多个真实数据集上，比现有最先进基线在有效性、效率和通用性等方面表现出显著优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12593v1",
      "published_date": "2024-10-16 14:12:11 UTC",
      "updated_date": "2024-10-16 14:12:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:19:11.044750"
    },
    {
      "arxiv_id": "2410.12591v1",
      "title": "Rethinking Visual Counterfactual Explanations Through Region Constraint",
      "title_zh": "通过区域约束重新思考视觉反事实解释",
      "authors": [
        "Bartlomiej Sobieski",
        "Jakub Grzywaczewski",
        "Bartlomiej Sadlej",
        "Matthew Tivnan",
        "Przemyslaw Biecek"
      ],
      "abstract": "Visual counterfactual explanations (VCEs) have recently gained immense\npopularity as a tool for clarifying the decision-making process of image\nclassifiers. This trend is largely motivated by what these explanations promise\nto deliver -- indicate semantically meaningful factors that change the\nclassifier's decision. However, we argue that current state-of-the-art\napproaches lack a crucial component -- the region constraint -- whose absence\nprevents from drawing explicit conclusions, and may even lead to faulty\nreasoning due to phenomenons like confirmation bias. To address the issue of\nprevious methods, which modify images in a very entangled and widely dispersed\nmanner, we propose region-constrained VCEs (RVCEs), which assume that only a\npredefined image region can be modified to influence the model's prediction. To\neffectively sample from this subclass of VCEs, we propose Region-Constrained\nCounterfactual Schr\\\"odinger Bridges (RCSB), an adaptation of a tractable\nsubclass of Schr\\\"odinger Bridges to the problem of conditional inpainting,\nwhere the conditioning signal originates from the classifier of interest. In\naddition to setting a new state-of-the-art by a large margin, we extend RCSB to\nallow for exact counterfactual reasoning, where the predefined region contains\nonly the factor of interest, and incorporating the user to actively interact\nwith the RVCE by predefining the regions manually.",
      "tldr_zh": "该研究重新审视了视觉反事实解释 (VCEs)，指出现有方法缺少“region constraint”，导致图像修改方式纠缠分散，可能引发确认偏差等问题。作者提出 region-constrained VCEs (RVCEs)，假设仅修改预定义的图像区域来影响模型预测，并开发了 Region-Constrained Counterfactual Schrödinger Bridges (RCSB)，这是一种基于 Schrödinger Bridges 的条件插值方法，用于有效采样 RVCEs。实验结果显示，RCSB 大幅提升了性能，并扩展支持精确反事实推理和用户交互，如手动定义区域，以实现更可靠的图像分类器解释。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2410.12591v1",
      "published_date": "2024-10-16 14:10:48 UTC",
      "updated_date": "2024-10-16 14:10:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:19:23.148934"
    },
    {
      "arxiv_id": "2410.12583v1",
      "title": "STRUX: An LLM for Decision-Making with Structured Explanations",
      "title_zh": "STRUX：用于决策的带有结构化解释的大型语言模型",
      "authors": [
        "Yiming Lu",
        "Yebowen Hu",
        "Hassan Foroosh",
        "Wei Jin",
        "Fei Liu"
      ],
      "abstract": "Countless decisions shape our daily lives, and it is paramount to understand\nthe how and why behind these choices. In this paper, we introduce a new LLM\ndecision-making framework called STRUX, which enhances LLM decision-making by\nproviding structured explanations. These include favorable and adverse facts\nrelated to the decision, along with their respective strengths. STRUX begins by\ndistilling lengthy information into a concise table of key facts. It then\nemploys a series of self-reflection steps to determine which of these facts are\npivotal, categorizing them as either favorable or adverse in relation to a\nspecific decision. Lastly, we fine-tune an LLM to identify and prioritize these\nkey facts to optimize decision-making. STRUX has been evaluated on the\nchallenging task of forecasting stock investment decisions based on earnings\ncall transcripts and demonstrated superior performance against strong\nbaselines. It enhances decision transparency by allowing users to understand\nthe impact of different factors, representing a meaningful step towards\npractical decision-making with LLMs.",
      "tldr_zh": "本论文引入了 STRUX，一种为 LLM 决策提供结构化解释的框架，包括决策相关的事实及其强度（有利和不利）。STRUX 的方法包括将冗长信息提炼成简洁事实表格、通过自反步骤分类关键事实，以及微调 LLM 以优先化这些事实，从而优化决策过程。在基于收益电话记录的股票投资决策任务上，STRUX 比强基线模型表现出色，提升了决策透明度，并为 LLM 在实际决策中的应用提供了重要进展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 7 figures, submitted to NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.12583v1",
      "published_date": "2024-10-16 14:01:22 UTC",
      "updated_date": "2024-10-16 14:01:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:19:36.158888"
    },
    {
      "arxiv_id": "2410.12577v1",
      "title": "On the Utility of Domain Modeling Assistance with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Meriem Ben Chaaben",
        "Lola Burgueño",
        "Istvan David",
        "Houari Sahraoui"
      ],
      "abstract": "Model-driven engineering (MDE) simplifies software development through\nabstraction, yet challenges such as time constraints, incomplete domain\nunderstanding, and adherence to syntactic constraints hinder the design\nprocess. This paper presents a study to evaluate the usefulness of a novel\napproach utilizing large language models (LLMs) and few-shot prompt learning to\nassist in domain modeling. The aim of this approach is to overcome the need for\nextensive training of AI-based completion models on scarce domain-specific\ndatasets and to offer versatile support for various modeling activities,\nproviding valuable recommendations to software modelers. To support this\napproach, we developed MAGDA, a user-friendly tool, through which we conduct a\nuser study and assess the real-world applicability of our approach in the\ncontext of domain modeling, offering valuable insights into its usability and\neffectiveness.",
      "tldr_zh": "这篇论文探讨了模型驱动工程 (MDE) 在软件开发中的挑战，如时间限制、领域理解不全和语法约束，并提出了一种利用大型语言模型 (LLMs) 和少样本提示学习 (few-shot prompt learning) 的新方法来辅助领域建模。该方法无需大量领域特定数据集的训练，就能为各种建模活动提供灵活的推荐支持。研究团队开发了 MAGDA 工具，并通过用户研究验证了其实际适用性，结果显示该方法显著提升了软件建模者的效率和有效性。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12577v1",
      "published_date": "2024-10-16 13:55:34 UTC",
      "updated_date": "2024-10-16 13:55:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:19:47.009747"
    },
    {
      "arxiv_id": "2410.12568v2",
      "title": "Robust RL with LLM-Driven Data Synthesis and Policy Adaptation for Autonomous Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Sihao Wu",
        "Jiaxu Liu",
        "Xiangyu Yin",
        "Guangliang Cheng",
        "Xingyu Zhao",
        "Meng Fang",
        "Xinping Yi",
        "Xiaowei Huang"
      ],
      "abstract": "The integration of Large Language Models (LLMs) into autonomous driving\nsystems demonstrates strong common sense and reasoning abilities, effectively\naddressing the pitfalls of purely data-driven methods. Current LLM-based agents\nrequire lengthy inference times and face challenges in interacting with\nreal-time autonomous driving environments. A key open question is whether we\ncan effectively leverage the knowledge from LLMs to train an efficient and\nrobust Reinforcement Learning (RL) agent. This paper introduces RAPID, a novel\n\\underline{\\textbf{R}}obust \\underline{\\textbf{A}}daptive\n\\underline{\\textbf{P}}olicy \\underline{\\textbf{I}}nfusion and\n\\underline{\\textbf{D}}istillation framework, which trains specialized\nmix-of-policy RL agents using data synthesized by an LLM-based driving agent\nand online adaptation. RAPID features three key designs: 1) utilization of\noffline data collected from an LLM agent to distil expert knowledge into RL\npolicies for faster real-time inference; 2) introduction of robust distillation\nin RL to inherit both performance and robustness from LLM-based teacher; and 3)\nemployment of a mix-of-policy approach for joint decision decoding with a\npolicy adapter. Through fine-tuning via online environment interaction, RAPID\nreduces the forgetting of LLM knowledge while maintaining adaptability to\ndifferent tasks. Extensive experiments demonstrate RAPID's capability to\neffectively integrate LLM knowledge into scaled-down RL policies in an\nefficient, adaptable, and robust way. Code and checkpoints will be made\npublicly available upon acceptance.",
      "tldr_zh": "本研究提出 RAPID 框架（Robust Adaptive Policy Infusion and Distillation），旨在利用 Large Language Models (LLMs) 驱动的数据合成和策略适应，训练高效鲁棒的 Reinforcement Learning (RL) 代理，用于自动驾驶系统。RAPID 的关键设计包括：使用 LLM 代理收集的离线数据蒸馏专家知识以加速实时推理、引入鲁棒 RL 蒸馏继承 LLM 的性能和鲁棒性，以及采用 mix-of-policy 方法结合策略适配器进行联合决策。实验结果显示，RAPID 通过在线环境交互微调，能够有效整合 LLM 知识，实现高效、可适应和鲁棒的 RL 代理性能。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12568v2",
      "published_date": "2024-10-16 13:43:00 UTC",
      "updated_date": "2024-10-20 04:35:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:19:59.688854"
    },
    {
      "arxiv_id": "2410.12561v1",
      "title": "Development of Image Collection Method Using YOLO and Siamese Network",
      "title_zh": "使用 YOLO 和 Siamese Network 的图像收集方法开发",
      "authors": [
        "Chan Young Shin",
        "Ah Hyun Lee",
        "Jun Young Lee",
        "Ji Min Lee",
        "Soo Jin Park"
      ],
      "abstract": "As we enter the era of big data, collecting high-quality data is very\nimportant. However, collecting data by humans is not only very time-consuming\nbut also expensive. Therefore, many scientists have devised various methods to\ncollect data using computers. Among them, there is a method called web\ncrawling, but the authors found that the crawling method has a problem in that\nunintended data is collected along with the user. The authors found that this\ncan be filtered using the object recognition model YOLOv10. However, there are\ncases where data that is not properly filtered remains. Here, image\nreclassification was performed by additionally utilizing the distance output\nfrom the Siamese network, and higher performance was recorded than other\nclassification models. (average \\_f1 score YOLO+MobileNet\n0.678->YOLO+SiameseNet 0.772)) The user can specify a distance threshold to\nadjust the balance between data deficiency and noise-robustness. The authors\nalso found that the Siamese network can achieve higher performance with fewer\nresources because the cropped images are used for object recognition when\nprocessing images in the Siamese network. (Class 20 mean-based f1 score,\nnon-crop+Siamese(MobileNetV3-Small) 80.94 -> crop\npreprocessing+Siamese(MobileNetV3-Small) 82.31) In this way, the image\nretrieval system that utilizes two consecutive models to reduce errors can save\nusers' time and effort, and build better quality data faster and with fewer\nresources than before.",
      "tldr_zh": "该研究开发了一种图像收集方法，使用 YOLOv10 进行对象识别初步过滤不相关数据，并结合 Siamese Network 的距离输出进行图像重新分类，以提高数据质量和准确性。实验结果显示，该方法比 YOLO + MobileNet 的平均 f1 score 从 0.678 提升至 0.772，且通过指定距离阈值，用户能平衡数据缺失和噪声鲁棒性。利用裁剪图像处理的 Siamese Network 还实现了更高的资源效率（如非裁剪 vs. 裁剪 f1 score 从 80.94 提高到 82.31），从而帮助用户更快地以更少资源构建高质量数据集。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages, 13 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.12561v1",
      "published_date": "2024-10-16 13:36:47 UTC",
      "updated_date": "2024-10-16 13:36:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:20:10.934559"
    },
    {
      "arxiv_id": "2410.12558v1",
      "title": "A Claim Decomposition Benchmark for Long-form Answer Verification",
      "title_zh": "翻译失败",
      "authors": [
        "Zhihao Zhang",
        "Yixing Fan",
        "Ruqing Zhang",
        "Jiafeng Guo"
      ],
      "abstract": "The advancement of LLMs has significantly boosted the performance of complex\nlong-form question answering tasks. However, one prominent issue of LLMs is the\ngenerated \"hallucination\" responses that are not factual. Consequently,\nattribution for each claim in responses becomes a common solution to improve\nthe factuality and verifiability. Existing researches mainly focus on how to\nprovide accurate citations for the response, which largely overlook the\nimportance of identifying the claims or statements for each response. To bridge\nthis gap, we introduce a new claim decomposition benchmark, which requires\nbuilding system that can identify atomic and checkworthy claims for LLM\nresponses. Specifically, we present the Chinese Atomic Claim Decomposition\nDataset (CACDD), which builds on the WebCPM dataset with additional expert\nannotations to ensure high data quality. The CACDD encompasses a collection of\n500 human-annotated question-answer pairs, including a total of 4956 atomic\nclaims. We further propose a new pipeline for human annotation and describe the\nchallenges of this task. In addition, we provide experiment results on\nzero-shot, few-shot and fine-tuned LLMs as baselines. The results show that the\nclaim decomposition is highly challenging and requires further explorations.\nAll code and data are publicly available at\n\\url{https://github.com/FBzzh/CACDD}.",
      "tldr_zh": "本文提出一个新的Claim Decomposition基准，用于验证长形式答案的真实性，以解决大型语言模型(LLMs)生成的“hallucination”问题，即非事实响应。研究者构建了Chinese Atomic Claim Decomposition Dataset (CACDD)，基于WebCPM数据集添加专家注解，共包含500个问题-答案对和4956个原子claims，并描述了人类注解管道及任务挑战。实验结果显示，zero-shot、few-shot和fine-tuned LLMs在claim decomposition任务上表现较差，突显其高度挑战性，需要进一步探索。数据集和代码已在GitHub上公开。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by CCIR 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.12558v1",
      "published_date": "2024-10-16 13:34:51 UTC",
      "updated_date": "2024-10-16 13:34:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:20:24.086838"
    },
    {
      "arxiv_id": "2410.12543v3",
      "title": "LLM-based Translation Inference with Iterative Bilingual Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Andong Chen",
        "Kehai Chen",
        "Yang Xiang",
        "Xuefeng Bai",
        "Muyun Yang",
        "Yang Feng",
        "Tiejun Zhao",
        "Min zhang"
      ],
      "abstract": "The remarkable understanding and generation capabilities of large language\nmodels (LLMs) have greatly improved translation performance. However, incorrect\nunderstanding of the sentence to be translated can degrade translation quality.\nTo address this issue, we proposed a novel Iterative Bilingual Understanding\nTranslation (IBUT) method based on the cross-lingual capabilities of LLMs and\nthe dual characteristics of translation tasks. The cross-lingual capability of\nLLMs enables the generation of contextual understanding for both the source and\ntarget languages separately. Furthermore, the dual characteristics allow IBUT\nto generate effective cross-lingual feedback, iteratively refining contextual\nunderstanding, thereby reducing errors and improving translation performance.\nExperimental results showed that the proposed IBUT outperforms several strong\ncomparison methods, especially being generalized to multiple domains (e.g.,\nnews, commonsense, and cultural translation benchmarks).",
      "tldr_zh": "本文提出了一种基于LLM的Iterative Bilingual Understanding Translation (IBUT)方法，以解决LLM在翻译任务中因句子理解错误而导致的性能下降问题。IBUT利用LLM的跨语言能力，分别生成源语言和目标语言的上下文理解，并通过双重特性（dual characteristics）实现迭代反馈，精炼理解并减少错误，从而提升翻译质量。实验结果显示，IBUT在多个领域（如新闻、常识和文化翻译基准）上优于其他方法，展现出良好的泛化性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2410.12543v3",
      "published_date": "2024-10-16 13:21:46 UTC",
      "updated_date": "2024-12-30 07:57:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:20:35.457226"
    },
    {
      "arxiv_id": "2410.12539v2",
      "title": "Counterfactual Effect Decomposition in Multi-Agent Sequential Decision Making",
      "title_zh": "多智能体顺序决策中的反事实效果分解",
      "authors": [
        "Stelios Triantafyllou",
        "Aleksa Sukovic",
        "Yasaman Zolfimoselo",
        "Goran Radanovic"
      ],
      "abstract": "We address the challenge of explaining counterfactual outcomes in multi-agent\nMarkov decision processes. In particular, we aim to explain the total\ncounterfactual effect of an agent's action on the outcome of a realized\nscenario through its influence on the environment dynamics and the agents'\nbehavior. To achieve this, we introduce a novel causal explanation formula that\ndecomposes the counterfactual effect by attributing to each agent and state\nvariable a score reflecting their respective contributions to the effect.\nFirst, we show that the total counterfactual effect of an agent's action can be\ndecomposed into two components: one measuring the effect that propagates\nthrough all subsequent agents' actions and another related to the effect that\npropagates through the state transitions. Building on recent advancements in\ncausal contribution analysis, we further decompose these two effects as\nfollows. For the former, we consider agent-specific effects -- a causal concept\nthat quantifies the counterfactual effect of an agent's action that propagates\nthrough a subset of agents. Based on this notion, we use Shapley value to\nattribute the effect to individual agents. For the latter, we consider the\nconcept of structure-preserving interventions and attribute the effect to state\nvariables based on their \"intrinsic\" contributions. Through extensive\nexperimentation, we demonstrate the interpretability of our approach in a\nGridworld environment with LLM-assisted agents and a sepsis management\nsimulator.",
      "tldr_zh": "本文提出了一种针对多智能体顺序决策中的 Counterfactual Effect Decomposition 方法，旨在解释一个智能体的行动对实际场景结果的反事实影响，通过分解其对环境动态和智能体行为的影响。研究引入一个新颖的因果解释公式，将总反事实效果分为两部分：通过后续智能体行动传播的效果（使用 Shapley value 归因到个别智能体）和通过状态转换传播的效果（基于结构保留干预归因到状态变量的内在贡献）。实验在 Gridworld 环境和败血症管理模拟器上验证了该方法的解释性，展示了其在多智能体决策分析中的潜在应用。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12539v2",
      "published_date": "2024-10-16 13:20:35 UTC",
      "updated_date": "2025-02-07 09:54:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:20:48.289106"
    },
    {
      "arxiv_id": "2410.12538v2",
      "title": "Automated Vehicles at Unsignalized Intersections: Safety and Efficiency Implications of Mixed-Human-Automated Traffic",
      "title_zh": "翻译失败",
      "authors": [
        "Saeed Rahmani",
        "Zhenlin Xu",
        "Simeon C. Calvert",
        "Bart van Arem"
      ],
      "abstract": "The integration of automated vehicles (AVs) into transportation systems\npresents an unprecedented opportunity to enhance road safety and efficiency.\nHowever, understanding the interactions between AVs and human-driven vehicles\n(HVs) at intersections remains an open research question. This study aims to\nbridge this gap by examining behavioral differences and adaptations of AVs and\nHVs at unsignalized intersections by utilizing two large-scale AV datasets from\nWaymo and Lyft. By using a systematic methodology, the research identifies and\nanalyzes merging and crossing conflicts by calculating key safety and\nefficiency metrics, including time to collision (TTC), post-encroachment time\n(PET), maximum required deceleration (MRD), time advantage (TA), and speed and\nacceleration profiles. The findings reveal a paradox in mixed traffic flow:\nwhile AVs maintain larger safety margins, their conservative behavior can lead\nto unexpected situations for human drivers, potentially causing unsafe\nconditions. From a performance point of view, human drivers exhibit more\nconsistent behavior when interacting with AVs versus other HVs, suggesting AVs\nmay contribute to harmonizing traffic flow patterns. Moreover, notable\ndifferences were observed between Waymo and Lyft vehicles, which highlights the\nimportance of considering manufacturer-specific AV behaviors in traffic\nmodeling and management strategies for the safe integration of AVs. The\nprocessed dataset utilized in this study is openly published to foster the\nresearch on AV-HV interactions.",
      "tldr_zh": "本研究探讨了自动驾驶车辆(AVs)和人类驾驶车辆(HVs)在无信号交叉口的互动对安全和效率的影响，使用Waymo和Lyft的大型数据集进行分析。研究通过计算关键指标如时间到碰撞(TTC)、后侵占时间(PET)、最大所需减速(MRD)和时间优势(TA)，揭示了AVs的保守行为虽能维持更大安全边距，但可能导致人类司机意外和潜在不安全情况；同时，人类司机在与AVs互动时表现出更一致的行为，有助于协调交通流。研究还强调了不同制造商（如Waymo和Lyft）AVs行为差异的重要性，并公开了处理后的数据集，以支持未来AV-HV互动研究。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "stat.AP"
      ],
      "primary_category": "cs.RO",
      "comment": "This work has been submitted to Transportation Research Record for\n  potential publication",
      "pdf_url": "http://arxiv.org/pdf/2410.12538v2",
      "published_date": "2024-10-16 13:19:32 UTC",
      "updated_date": "2025-02-04 01:23:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:20:59.940012"
    },
    {
      "arxiv_id": "2410.12537v2",
      "title": "Is Complex Query Answering Really Complex?",
      "title_zh": "翻译失败",
      "authors": [
        "Cosimo Gregucci",
        "Bo Xiong",
        "Daniel Hernandez",
        "Lorenzo Loconte",
        "Pasquale Minervini",
        "Steffen Staab",
        "Antonio Vergari"
      ],
      "abstract": "Complex query answering (CQA) on knowledge graphs (KGs) is gaining momentum\nas a challenging reasoning task. In this paper, we show that the current\nbenchmarks for CQA might not be as complex as we think, as the way they are\nbuilt distorts our perception of progress in this field. For example, we find\nthat in these benchmarks, most queries (up to 98% for some query types) can be\nreduced to simpler problems, e.g., link prediction, where only one link needs\nto be predicted. The performance of state-of-the-art CQA models decreases\nsignificantly when such models are evaluated on queries that cannot be reduced\nto easier types. Thus, we propose a set of more challenging benchmarks composed\nof queries that require models to reason over multiple hops and better reflect\nthe construction of real-world KGs. In a systematic empirical investigation,\nthe new benchmarks show that current methods leave much to be desired from\ncurrent CQA methods.",
      "tldr_zh": "这篇论文质疑了复杂查询回答 (CQA) 在知识图谱 (KGs) 上的真实复杂性，发现现有基准中高达 98% 的查询可以简化为更简单的任务，如链接预测，从而高估了模型的性能。作者通过分析显示，状态-of-the-art CQA 模型在无法简化的查询上表现显著下降。针对这一问题，他们提出了一组更具挑战性的基准，这些基准强调多跳推理并更真实地反映真实世界 KGs 的构建。在系统实证调查中，新基准揭示了当前 CQA 方法仍有很大改进空间。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12537v2",
      "published_date": "2024-10-16 13:19:03 UTC",
      "updated_date": "2025-02-18 12:40:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:21:11.184973"
    },
    {
      "arxiv_id": "2410.12521v1",
      "title": "Spectrum Sharing using Deep Reinforcement Learning in Vehicular Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Riya Dinesh Deshpande",
        "Faheem A. Khan",
        "Qasim Zeeshan Ahmed"
      ],
      "abstract": "As the number of devices getting connected to the vehicular network grows\nexponentially, addressing the numerous challenges of effectively allocating\nspectrum in dynamic vehicular environment becomes increasingly difficult.\nTraditional methods may not suffice to tackle this issue. In vehicular networks\nsafety critical messages are involved and it is important to implement an\nefficient spectrum allocation paradigm for hassle free communication as well as\nmanage the congestion in the network. To tackle this, a Deep Q Network (DQN)\nmodel is proposed as a solution, leveraging its ability to learn optimal\nstrategies over time and make decisions. The paper presents a few results and\nanalyses, demonstrating the efficacy of the DQN model in enhancing spectrum\nsharing efficiency. Deep Reinforcement Learning methods for sharing spectrum in\nvehicular networks have shown promising outcomes, demonstrating the system's\nability to adjust to dynamic communication environments. Both SARL and MARL\nmodels have exhibited successful rates of V2V communication, with the\ncumulative reward of the RL model reaching its maximum as training progresses.",
      "tldr_zh": "该研究针对车辆网络中频谱分配的挑战（如动态环境、网络拥塞和安全消息传输），提出了一种基于 Deep Reinforcement Learning 的解决方案。作者采用 Deep Q Network (DQN) 模型，通过学习最优策略来实现高效的频谱共享，提升通信效率。实验结果显示，DQN 模型显著提高了频谱共享性能，SARL 和 MARL 模型在 V2V 通信中表现出高成功率，且累积奖励随训练而最大化，为车辆网络的动态管理提供了可行方法。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12521v1",
      "published_date": "2024-10-16 12:59:59 UTC",
      "updated_date": "2024-10-16 12:59:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:21:23.231284"
    },
    {
      "arxiv_id": "2410.12520v1",
      "title": "QueensCAMP: an RGB-D dataset for robust Visual SLAM",
      "title_zh": "翻译失败",
      "authors": [
        "Hudson M. S. Bruno",
        "Esther L. Colombini",
        "Sidney N. Givigi Jr"
      ],
      "abstract": "Visual Simultaneous Localization and Mapping (VSLAM) is a fundamental\ntechnology for robotics applications. While VSLAM research has achieved\nsignificant advancements, its robustness under challenging situations, such as\npoor lighting, dynamic environments, motion blur, and sensor failures, remains\na challenging issue. To address these challenges, we introduce a novel RGB-D\ndataset designed for evaluating the robustness of VSLAM systems. The dataset\ncomprises real-world indoor scenes with dynamic objects, motion blur, and\nvarying illumination, as well as emulated camera failures, including lens dirt,\ncondensation, underexposure, and overexposure. Additionally, we offer\nopen-source scripts for injecting camera failures into any images, enabling\nfurther customization by the research community. Our experiments demonstrate\nthat ORB-SLAM2, a traditional VSLAM algorithm, and TartanVO, a Deep\nLearning-based VO algorithm, can experience performance degradation under these\nchallenging conditions. Therefore, this dataset and the camera failure\nopen-source tools provide a valuable resource for developing more robust VSLAM\nsystems capable of handling real-world challenges.",
      "tldr_zh": "本文介绍了QueensCAMP，这是一个RGB-D数据集，旨在评估Visual SLAM系统的鲁棒性，针对挑战性场景如光线不足、动态环境、运动模糊和传感器故障。数据集包括真实室内场景的图像数据，以及模拟的相机故障（如镜头脏污、结露、曝光不足和过度），并提供开源脚本允许研究者自定义注入故障。实验结果显示，ORB-SLAM2和TartanVO在这些条件下性能显著下降，为开发更可靠的VSLAM系统提供了宝贵资源。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.12520v1",
      "published_date": "2024-10-16 12:58:08 UTC",
      "updated_date": "2024-10-16 12:58:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:21:35.411957"
    },
    {
      "arxiv_id": "2410.12509v1",
      "title": "Benchmarking Defeasible Reasoning with Large Language Models -- Initial Experiments and Future Directions",
      "title_zh": "翻译失败",
      "authors": [
        "Ilias Tachmazidis",
        "Sotiris Batsakis",
        "Grigoris Antoniou"
      ],
      "abstract": "Large Language Models (LLMs) have gained prominence in the AI landscape due\nto their exceptional performance. Thus, it is essential to gain a better\nunderstanding of their capabilities and limitations, among others in terms of\nnonmonotonic reasoning. This paper proposes a benchmark that corresponds to\nvarious defeasible rule-based reasoning patterns. We modified an existing\nbenchmark for defeasible logic reasoners by translating defeasible rules into\ntext suitable for LLMs. We conducted preliminary experiments on nonmonotonic\nrule-based reasoning using ChatGPT and compared it with reasoning patterns\ndefined by defeasible logic.",
      "tldr_zh": "这篇论文提出一个基准，用于评估 Large Language Models (LLMs) 在可败式推理（defeasible reasoning）方面的能力和局限性，聚焦于非单调规则推理模式。研究者通过修改现有可败式逻辑推理器基准，将可败式规则转化为适合 LLMs 的文本，并使用 ChatGPT 进行了初步实验，以比较 LLMs 的推理性能与可败式逻辑定义的模式。实验结果为理解 LLMs 在非单调推理中的表现提供了初步洞见，并讨论了未来研究方向。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Presented at NeLaMKRR@KR, 2024 (arXiv:2410.05339)",
      "pdf_url": "http://arxiv.org/pdf/2410.12509v1",
      "published_date": "2024-10-16 12:36:23 UTC",
      "updated_date": "2024-10-16 12:36:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:21:49.243746"
    },
    {
      "arxiv_id": "2410.13905v3",
      "title": "P4GCN: Vertical Federated Social Recommendation with Privacy-Preserving Two-Party Graph Convolution Network",
      "title_zh": "翻译失败",
      "authors": [
        "Zheng Wang",
        "Wanwan Wang",
        "Yimin Huang",
        "Zhaopeng Peng",
        "Ziqi Yang",
        "Ming Yao",
        "Cheng Wang",
        "Xiaoliang Fan"
      ],
      "abstract": "In recent years, graph neural networks (GNNs) have been commonly utilized for\nsocial recommendation systems. However, real-world scenarios often present\nchallenges related to user privacy and business constraints, inhibiting direct\naccess to valuable social information from other platforms. While many existing\nmethods have tackled matrix factorization-based social recommendations without\ndirect social data access, developing GNN-based federated social recommendation\nmodels under similar conditions remains largely unexplored. To address this\nissue, we propose a novel vertical federated social recommendation method\nleveraging privacy-preserving two-party graph convolution networks (P4GCN) to\nenhance recommendation accuracy without requiring direct access to sensitive\nsocial information. First, we introduce a Sandwich-Encryption module to ensure\ncomprehensive data privacy during the collaborative computing process. Second,\nwe provide a thorough theoretical analysis of the privacy guarantees,\nconsidering the participation of both curious and honest parties. Extensive\nexperiments on four real-world datasets demonstrate that P4GCN outperforms\nstate-of-the-art methods in terms of recommendation accuracy.",
      "tldr_zh": "该研究提出 P4GCN，一种垂直联邦社交推荐方法，使用 Privacy-Preserving Two-Party Graph Convolution Network 来提升推荐准确性，同时保护用户隐私，避免直接访问敏感社交信息。首先，引入 Sandwich-Encryption 模块，确保数据在协作计算过程中的全面隐私保护，并对好奇和诚实参与方的隐私风险进行了理论分析。实验结果显示，在四个真实数据集上，P4GCN 超过了最先进方法的性能表现。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.SI",
      "comment": "Accepted by WWW25",
      "pdf_url": "http://arxiv.org/pdf/2410.13905v3",
      "published_date": "2024-10-16 12:29:22 UTC",
      "updated_date": "2025-02-04 03:46:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:21:59.438963"
    },
    {
      "arxiv_id": "2410.12501v1",
      "title": "DH-VTON: Deep Text-Driven Virtual Try-On via Hybrid Attention Learning",
      "title_zh": "DH-VTON：基于混合注意力学习的深度文本驱动虚拟试穿",
      "authors": [
        "Jiabao Wei",
        "Zhiyuan Ma"
      ],
      "abstract": "Virtual Try-ON (VTON) aims to synthesis specific person images dressed in\ngiven garments, which recently receives numerous attention in online shopping\nscenarios. Currently, the core challenges of the VTON task mainly lie in the\nfine-grained semantic extraction (i.e.,deep semantics) of the given reference\ngarments during depth estimation and effective texture preservation when the\ngarments are synthesized and warped onto human body. To cope with these issues,\nwe propose DH-VTON, a deep text-driven virtual try-on model featuring a special\nhybrid attention learning strategy and deep garment semantic preservation\nmodule. By standing on the shoulder of a well-built pre-trained\npaint-by-example (abbr. PBE) approach, we present our DH-VTON pipeline in this\nwork. Specifically, to extract the deep semantics of the garments, we first\nintroduce InternViT-6B as fine-grained feature learner, which can be trained to\nalign with the large-scale intrinsic knowledge with deep text semantics\n(e.g.,\"neckline\" or \"girdle\") to make up for the deficiency of the commonly\nadopted CLIP encoder. Based on this, to enhance the customized dressing\nabilities, we further introduce Garment-Feature ControlNet Plus (abbr. GFC+)\nmodule and propose to leverage a fresh hybrid attention strategy for training,\nwhich can adaptively integrate fine-grained characteristics of the garments\ninto the different layers of the VTON model, so as to achieve multi-scale\nfeatures preservation effects. Extensive experiments on several representative\ndatasets demonstrate that our method outperforms previous diffusion-based and\nGAN-based approaches, showing competitive performance in preserving garment\ndetails and generating authentic human images.",
      "tldr_zh": "本研究提出 DH-VTON，一种深度文本驱动的虚拟试穿（VTON）模型，通过混合注意力学习策略和深层服装语义保留模块，解决服装细粒度语义提取（如 \"neckline\" 或 \"girdle\"）和纹理保留的挑战。\n该模型基于预训练的 Paint-by-Example (PBE) 方法，使用 InternViT-6B 作为细粒度特征学习器来弥补 CLIP 编码器的不足，并引入 Garment-Feature ControlNet Plus (GFC+) 模块，以适应性整合服装的多尺度特征。\n实验在多个代表性数据集上表明，DH-VTON 优于现有的扩散模型和 GAN 模型，在保留服装细节和生成真实人类图像方面表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "5 pages, 6 figures, ICASSP2025",
      "pdf_url": "http://arxiv.org/pdf/2410.12501v1",
      "published_date": "2024-10-16 12:27:10 UTC",
      "updated_date": "2024-10-16 12:27:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:22:15.251765"
    },
    {
      "arxiv_id": "2410.12893v3",
      "title": "MIRROR: A Novel Approach for the Automated Evaluation of Open-Ended Question Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Aniket Deroy",
        "Subhankar Maity",
        "Sudeshna Sarkar"
      ],
      "abstract": "Automatic question generation is a critical task that involves evaluating\nquestion quality by considering factors such as engagement, pedagogical value,\nand the ability to stimulate critical thinking. These aspects require\nhuman-like understanding and judgment, which automated systems currently lack.\nHowever, human evaluations are costly and impractical for large-scale samples\nof generated questions. Therefore, we propose a novel system, MIRROR (Multi-LLM\nIterative Review and Response for Optimized Rating), which leverages large\nlanguage models (LLMs) to automate the evaluation process for questions\ngenerated by automated question generation systems. We experimented with\nseveral state-of-the-art LLMs, such as GPT-4, Gemini, and Llama2-70b. We\nobserved that the scores of human evaluation metrics, namely relevance,\nappropriateness, novelty, complexity, and grammaticality, improved when using\nthe feedback-based approach called MIRROR, tending to be closer to the human\nbaseline scores. Furthermore, we observed that Pearson's correlation\ncoefficient between GPT-4 and human experts improved when using our proposed\nfeedback-based approach, MIRROR, compared to direct prompting for evaluation.\nError analysis shows that our proposed approach, MIRROR, significantly helps to\nimprove relevance and appropriateness.",
      "tldr_zh": "本文提出MIRROR，一种新型系统，用于自动化评估开放式问题生成的质量，通过多大型语言模型(LLMs)如GPT-4和Gemini的迭代审查和反馈机制，解决当前自动化系统缺乏人类判断的问题。MIRROR专注于提升评估指标，包括相关性(relevance)、适当性(appropriateness)、新颖性(novelty)、复杂性(complexity)和语法正确性(grammaticality)。实验结果显示，使用MIRROR后，LLMs的评分更接近人类基准，且Pearson's correlation coefficient与人类专家的相关性显著提高。错误分析进一步证明，该方法显著改善了问题的相关性和适当性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Updated Version",
      "pdf_url": "http://arxiv.org/pdf/2410.12893v3",
      "published_date": "2024-10-16 12:24:42 UTC",
      "updated_date": "2025-03-25 15:02:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:22:23.839897"
    },
    {
      "arxiv_id": "2410.12490v2",
      "title": "Stabilize the Latent Space for Image Autoregressive Modeling: A Unified Perspective",
      "title_zh": "稳定图像自回归建模的潜在空间：一个统一视角",
      "authors": [
        "Yongxin Zhu",
        "Bocheng Li",
        "Hang Zhang",
        "Xin Li",
        "Linli Xu",
        "Lidong Bing"
      ],
      "abstract": "Latent-based image generative models, such as Latent Diffusion Models (LDMs)\nand Mask Image Models (MIMs), have achieved notable success in image generation\ntasks. These models typically leverage reconstructive autoencoders like VQGAN\nor VAE to encode pixels into a more compact latent space and learn the data\ndistribution in the latent space instead of directly from pixels. However, this\npractice raises a pertinent question: Is it truly the optimal choice? In\nresponse, we begin with an intriguing observation: despite sharing the same\nlatent space, autoregressive models significantly lag behind LDMs and MIMs in\nimage generation. This finding contrasts sharply with the field of NLP, where\nthe autoregressive model GPT has established a commanding presence. To address\nthis discrepancy, we introduce a unified perspective on the relationship\nbetween latent space and generative models, emphasizing the stability of latent\nspace in image generative modeling. Furthermore, we propose a simple but\neffective discrete image tokenizer to stabilize the latent space for image\ngenerative modeling by applying K-Means on the latent features of\nself-supervised learning models. Experimental results show that image\nautoregressive modeling with our tokenizer (DiGIT) benefits both image\nunderstanding and image generation with the next token prediction principle,\nwhich is inherently straightforward for GPT models but challenging for other\ngenerative models. Remarkably, for the first time, a GPT-style autoregressive\nmodel for images outperforms LDMs, which also exhibits substantial improvement\nakin to GPT when scaling up model size. Our findings underscore the potential\nof an optimized latent space and the integration of discrete tokenization in\nadvancing the capabilities of image generative models. The code is available at\n\\url{https://github.com/DAMO-NLP-SG/DiGIT}.",
      "tldr_zh": "本文从一个统一视角探讨了潜在空间的稳定性在图像生成模型中的重要性，指出尽管 LDMs 和 MIMs 已在图像生成中取得成功，但 autoregressive 模型（如 GPT 风格的模型）在该领域落后。作者提出了一种简单有效的离散图像 tokenizer DiGIT，通过在自监督学习模型的潜在特征上应用 K-Means 来稳定潜在空间，从而提升图像 autoregressive 建模的性能。实验结果显示，使用 DiGIT 的模型首次在图像理解和生成任务中超越 LDMs，并在模型规模扩展时实现了显著改进。这些发现突出了优化潜在空间和离散 tokenization 在推进图像生成模型能力方面的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.12490v2",
      "published_date": "2024-10-16 12:13:17 UTC",
      "updated_date": "2024-10-31 11:42:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:22:38.791110"
    },
    {
      "arxiv_id": "2410.12483v2",
      "title": "Stable Object Placement Planning From Contact Point Robustness",
      "title_zh": "基于接触点鲁棒性的稳定物体放置规划",
      "authors": [
        "Philippe Nadeau",
        "Jonathan Kelly"
      ],
      "abstract": "We introduce a planner designed to guide robot manipulators in stably placing\nobjects within intricate scenes. Our proposed method reverses the traditional\napproach to object placement: our planner selects contact points first and then\ndetermines a placement pose that solicits the selected points. This is instead\nof sampling poses, identifying contact points, and evaluating pose quality. Our\nalgorithm facilitates stability-aware object placement planning, imposing no\nrestrictions on object shape, convexity, or mass density homogeneity, while\navoiding combinatorial computational complexity. Our proposed stability\nheuristic enables our planner to find a solution about 20 times faster when\ncompared to the same algorithm not making use of the heuristic and eight times\nfaster than a state-of-the-art method that uses the traditional\nsample-and-evaluate approach. Our proposed planner is also more successful in\nfinding stable placements than the five other benchmarked algorithms. Derived\nfrom first principles and validated in ten real robot experiments, our planner\noffers a general and scalable method to tackle the problem of object placement\nplanning with rigid objects.",
      "tldr_zh": "该论文提出了一种新的规划器，用于指导机器人机械臂在复杂场景中稳定放置物体，通过先选择 contact points 然后确定放置姿势，逆转了传统的采样姿势和评估方法。这种方法支持稳定性感知的物体放置规划，不限制物体形状、凸性或质量密度均匀性，并避免了组合计算复杂性。实验结果显示，该规划器利用稳定性启发式比不使用启发式的算法快 20 倍，比最先进的方法快 8 倍，并在十个真实机器人实验中表现出更高的成功率，提供了一个通用且可扩展的物体放置解决方案。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Submitted to IEEE Transactions on Robotics. Contains 15 pages, 13\n  figures, and 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.12483v2",
      "published_date": "2024-10-16 12:02:15 UTC",
      "updated_date": "2024-12-06 22:52:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:22:49.063995"
    },
    {
      "arxiv_id": "2410.12481v1",
      "title": "SAC-GLAM: Improving Online RL for LLM agents with Soft Actor-Critic and Hindsight Relabeling",
      "title_zh": "翻译失败",
      "authors": [
        "Loris Gaven",
        "Clement Romac",
        "Thomas Carta",
        "Sylvain Lamprier",
        "Olivier Sigaud",
        "Pierre-Yves Oudeyer"
      ],
      "abstract": "The past years have seen Large Language Models (LLMs) strive not only as\ngenerative models but also as agents solving textual sequential decision-making\ntasks. When facing complex environments where their zero-shot abilities are\ninsufficient, recent work showed online Reinforcement Learning (RL) could be\nused for the LLM agent to discover and learn efficient strategies\ninteractively. However, most prior work sticks to on-policy algorithms, which\ngreatly reduces the scope of methods such agents could use for both exploration\nand exploitation, such as experience replay and hindsight relabeling. Yet, such\nmethods may be key for LLM learning agents, and in particular when designing\nautonomous intrinsically motivated agents sampling and pursuing their own goals\n(i.e. autotelic agents). This paper presents and studies an adaptation of Soft\nActor-Critic and hindsight relabeling to LLM agents. Our method not only paves\nthe path towards autotelic LLM agents that learn online but can also outperform\non-policy methods in more classic multi-goal RL environments.",
      "tldr_zh": "该论文提出 SAC-GLAM 方法，将 Soft Actor-Critic (SAC) 和 Hindsight Relabeling 技术应用于 Large Language Models (LLMs) 代理，以提升在线 Reinforcement Learning (RL) 的性能。针对 LLM 代理在复杂环境中的零-shot 能力不足问题，该方法引入经验回放和后见重标记，增强探索和利用策略，支持自主内部动机代理（autotelic agents）的在线学习。实验结果表明，SAC-GLAM 在多目标 RL 环境中超越了 on-policy 方法，为 LLM 代理的交互式策略发现和优化提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12481v1",
      "published_date": "2024-10-16 11:59:27 UTC",
      "updated_date": "2024-10-16 11:59:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:23:02.250635"
    },
    {
      "arxiv_id": "2411.00005v3",
      "title": "Mastering the Craft of Data Synthesis for CodeLLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Meng Chen",
        "Philip Arthur",
        "Qianyu Feng",
        "Cong Duy Vu Hoang",
        "Yu-Heng Hong",
        "Mahdi Kazemi Moghaddam",
        "Omid Nezami",
        "Thien Nguyen",
        "Gioacchino Tangari",
        "Duy Vu",
        "Thanh Vu",
        "Mark Johnson",
        "Krishnaram Kenthapadi",
        "Don Dharmasiri",
        "Long Duong",
        "Yuan-Fang Li"
      ],
      "abstract": "Large language models (LLMs) have shown impressive performance in \\emph{code}\nunderstanding and generation, making coding tasks a key focus for researchers\ndue to their practical applications and value as a testbed for LLM evaluation.\nData synthesis and filtering techniques have been widely adopted and shown to\nbe highly effective in this context. In this paper, we present a focused survey\nand taxonomy of these techniques, emphasizing recent advancements. We highlight\nkey challenges, explore future research directions, and offer practical\nguidance for new researchers entering the field.",
      "tldr_zh": "这篇论文针对 CodeLLMs（代码大型语言模型）的数据合成和过滤技术进行了一个全面调查和分类，强调了这些技术在代码理解和生成任务中的有效性及其作为LLM评估测试床的价值。作者突出了关键挑战，如数据质量和模型优化问题，并探讨了未来研究方向，包括更先进的合成方法。论文为新研究者提供了实用指导，帮助他们在该领域快速入门和应用这些技术。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted at NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2411.00005v3",
      "published_date": "2024-10-16 11:57:14 UTC",
      "updated_date": "2025-02-07 08:49:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:23:13.209786"
    },
    {
      "arxiv_id": "2410.12480v2",
      "title": "KcMF: A Knowledge-compliant Framework for Schema and Entity Matching with Fine-tuning-free LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Yongqin Xu",
        "Huan Li",
        "Ke Chen",
        "Lidan Shou"
      ],
      "abstract": "Schema matching (SM) and entity matching (EM) tasks are crucial for data\nintegration. While large language models (LLMs) have shown promising results in\nthese tasks, they suffer from hallucinations and confusion about task\ninstructions. This study presents the Knowledge-Compliant Matching Framework\n(KcMF), an LLM-based approach that addresses these issues without the need for\ndomain-specific fine-tuning. KcMF employs a once-and-for-all pseudo-code-based\ntask decomposition strategy to adopt natural language statements that guide LLM\nreasoning and reduce confusion across various task types. We also propose two\nmechanisms, Dataset as Knowledge (DaK) and Example as Knowledge (EaK), to build\ndomain knowledge sets when unstructured domain knowledge is lacking. Moreover,\nwe introduce a result-ensemble strategy to leverage multiple knowledge sources\nand suppress badly formatted outputs. Extensive evaluations confirm that KcMF\nclearly enhances five LLM backbones in both SM and EM tasks while outperforming\nthe non-LLM competitors by an average F1-score of 17.93%.",
      "tldr_zh": "这篇论文提出了 KcMF，一种无需微调的知识兼容框架，用于解决 Schema Matching (SM) 和 Entity Matching (EM) 任务中 LLMs 的幻觉和指令混淆问题。KcMF 通过一次性的伪代码-based 任务分解策略来引导 LLM 推理，并引入 Dataset as Knowledge (DaK) 和 Example as Knowledge (EaK) 机制，以构建领域知识集，同时采用结果集成策略来整合多源知识并抑制格式错误输出。实验评估显示，KcMF 显著提升了五种 LLM 骨干在 SM 和 EM 任务上的性能，比非 LLM 竞争对手平均 F1 分数高出 17.93%。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "under reveiw; new results and analysis added, typos corrected",
      "pdf_url": "http://arxiv.org/pdf/2410.12480v2",
      "published_date": "2024-10-16 11:50:02 UTC",
      "updated_date": "2025-02-17 07:23:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:23:26.011228"
    },
    {
      "arxiv_id": "2410.12473v1",
      "title": "Unifying Economic and Language Models for Enhanced Sentiment Analysis of the Oil Market",
      "title_zh": "翻译失败",
      "authors": [
        "Himmet Kaplan",
        "Ralf-Peter Mundani",
        "Heiko Rölke",
        "Albert Weichselbraun",
        "Martin Tschudy"
      ],
      "abstract": "Crude oil, a critical component of the global economy, has its prices\ninfluenced by various factors such as economic trends, political events, and\nnatural disasters. Traditional prediction methods based on historical data have\ntheir limits in forecasting, but recent advancements in natural language\nprocessing bring new possibilities for event-based analysis. In particular,\nLanguage Models (LM) and their advancement, the Generative Pre-trained\nTransformer (GPT), have shown potential in classifying vast amounts of natural\nlanguage. However, these LMs often have difficulty with domain-specific\nterminology, limiting their effectiveness in the crude oil sector. Addressing\nthis gap, we introduce CrudeBERT, a fine-tuned LM specifically for the crude\noil market. The results indicate that CrudeBERT's sentiment scores align more\nclosely with the WTI Futures curve and significantly enhance price predictions,\nunderscoring the crucial role of integrating economic principles into LMs.",
      "tldr_zh": "该论文探讨了原油价格受经济趋势、政治事件和自然灾害等因素影响的问题，传统基于历史数据的预测方法存在局限，而 Language Models (LM) 如 Generative Pre-trained Transformer (GPT) 在情感分析中虽有潜力，但难以处理领域特定术语。针对这一挑战，研究团队引入了 CrudeBERT，一种针对原油市场的微调 LM，通过整合经济原则来提升模型性能。实验结果显示，CrudeBERT 的情感分数与 WTI Futures 曲线更紧密相关，并显著改善了价格预测准确性。这突出了将经济模型与语言模型统一的重要性，为原油市场的情感分析提供了新途径。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12473v1",
      "published_date": "2024-10-16 11:41:24 UTC",
      "updated_date": "2024-10-16 11:41:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:23:37.738277"
    },
    {
      "arxiv_id": "2410.12468v2",
      "title": "Evaluating Software Development Agents: Patch Patterns, Code Quality, and Issue Complexity in Real-World GitHub Scenarios",
      "title_zh": "翻译失败",
      "authors": [
        "Zhi Chen",
        "Lingxiao Jiang"
      ],
      "abstract": "In recent years, AI-based software engineering has progressed from\npre-trained models to advanced agentic workflows, with Software Development\nAgents representing the next major leap. These agents, capable of reasoning,\nplanning, and interacting with external environments, offer promising solutions\nto complex software engineering tasks. However, while much research has\nevaluated code generated by large language models (LLMs), comprehensive studies\non agent-generated patches, particularly in real-world settings, are lacking.\nThis study addresses that gap by evaluating 4,892 patches from 10 top-ranked\nagents on 500 real-world GitHub issues from SWE-Bench Verified, focusing on\ntheir impact on code quality. Our analysis shows no single agent dominated,\nwith 170 issues unresolved, indicating room for improvement. Even for patches\nthat passed unit tests and resolved issues, agents made different file and\nfunction modifications compared to the gold patches from repository developers,\nrevealing limitations in the benchmark's test case coverage. Most agents\nmaintained code reliability and security, avoiding new bugs or vulnerabilities;\nwhile some agents increased code complexity, many reduced code duplication and\nminimized code smells. Finally, agents performed better on simpler codebases,\nsuggesting that breaking complex tasks into smaller sub-tasks could improve\neffectiveness. This study provides the first comprehensive evaluation of\nagent-generated patches on real-world GitHub issues, offering insights to\nadvance AI-driven software development.",
      "tldr_zh": "本研究评估了 Software Development Agents 在真实 GitHub 场景中的表现，焦点是补丁模式（patch patterns）、代码质量和问题复杂性，分析了 10 个顶级代理生成的 4,892 个补丁，针对 SWE-Bench Verified 的 500 个真实问题。结果显示，没有单一代理全面主导，170 个问题未解决，且代理补丁与开发者金标准补丁在文件和函数修改上存在差异，揭示了基准测试覆盖的局限性；同时，大多数代理维持了代码的可靠性和安全性，减少了代码重复和异味，但有些增加了代码复杂性。研究发现，代理在简单代码库上表现更好，建议通过分解复杂任务为子任务来提升效果，为推进 AI 驱动的软件开发提供了宝贵见解。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Paper accepted to the SANER 2025 Conference Research Track",
      "pdf_url": "http://arxiv.org/pdf/2410.12468v2",
      "published_date": "2024-10-16 11:33:57 UTC",
      "updated_date": "2024-12-27 13:52:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:23:51.086788"
    },
    {
      "arxiv_id": "2410.12457v1",
      "title": "Sharpness-Aware Black-Box Optimization",
      "title_zh": "锐度感知黑箱优化",
      "authors": [
        "Feiyang Ye",
        "Yueming Lyu",
        "Xuehao Wang",
        "Masashi Sugiyama",
        "Yu Zhang",
        "Ivor Tsang"
      ],
      "abstract": "Black-box optimization algorithms have been widely used in various machine\nlearning problems, including reinforcement learning and prompt fine-tuning.\nHowever, directly optimizing the training loss value, as commonly done in\nexisting black-box optimization methods, could lead to suboptimal model quality\nand generalization performance. To address those problems in black-box\noptimization, we propose a novel Sharpness-Aware Black-box Optimization (SABO)\nalgorithm, which applies a sharpness-aware minimization strategy to improve the\nmodel generalization. Specifically, the proposed SABO method first\nreparameterizes the objective function by its expectation over a Gaussian\ndistribution. Then it iteratively updates the parameterized distribution by\napproximated stochastic gradients of the maximum objective value within a small\nneighborhood around the current solution in the Gaussian distribution space.\nTheoretically, we prove the convergence rate and generalization bound of the\nproposed SABO algorithm. Empirically, extensive experiments on the black-box\nprompt fine-tuning tasks demonstrate the effectiveness of the proposed SABO\nmethod in improving model generalization performance.",
      "tldr_zh": "本研究针对传统黑箱优化算法在机器学习任务（如强化学习和提示微调）中直接优化训练损失可能导致模型质量和泛化性能不佳的问题，提出了一种新型算法Sharpness-Aware Black-Box Optimization (SABO)。SABO 通过sharpness-aware minimization策略，首先将目标函数重参数化为高斯分布的期望，然后使用近似随机梯度迭代更新分布，以优化高斯分布空间中当前解附近的最大目标值。理论上，该算法证明了其收敛率和泛化界；实验结果显示，在黑箱提示微调任务上，SABO 显著提升了模型的泛化性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "27 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.12457v1",
      "published_date": "2024-10-16 11:08:06 UTC",
      "updated_date": "2024-10-16 11:08:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:24:12.568707"
    },
    {
      "arxiv_id": "2410.12445v3",
      "title": "Open Ko-LLM Leaderboard2: Bridging Foundational and Practical Evaluation for Korean LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Hyeonwoo Kim",
        "Dahyun Kim",
        "Jihoo Kim",
        "Sukyung Lee",
        "Yungi Kim",
        "Chanjun Park"
      ],
      "abstract": "The Open Ko-LLM Leaderboard has been instrumental in benchmarking Korean\nLarge Language Models (LLMs), yet it has certain limitations. Notably, the\ndisconnect between quantitative improvements on the overly academic leaderboard\nbenchmarks and the qualitative impact of the models should be addressed.\nFurthermore, the benchmark suite is largely composed of translated versions of\ntheir English counterparts, which may not fully capture the intricacies of the\nKorean language. To address these issues, we propose Open Ko-LLM Leaderboard2,\nan improved version of the earlier Open Ko-LLM Leaderboard. The original\nbenchmarks are entirely replaced with new tasks that are more closely aligned\nwith real-world capabilities. Additionally, four new native Korean benchmarks\nare introduced to better reflect the distinct characteristics of the Korean\nlanguage. Through these refinements, Open Ko-LLM Leaderboard2 seeks to provide\na more meaningful evaluation for advancing Korean LLMs.",
      "tldr_zh": "该研究指出了原有的 Open Ko-LLM Leaderboard 在评估韩国大型语言模型(LLMs)时存在的局限性，包括量化指标与实际影响脱节，以及基准测试主要为英语版本的翻译，无法充分捕捉韩国语言的特性。  \n为此，研究团队提出了改进版 Open Ko-LLM Leaderboard2，将原有基准测试完全替换为更贴近真实世界能力的任务。  \n此外，还引入了四个新的本土韩国基准测试，以更好地反映韩国语言的独特特点。  \n通过这些优化，Open Ko-LLM Leaderboard2 旨在为韩国 LLMs 的发展提供更具意义的评估框架。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NAACL 2025 Industry",
      "pdf_url": "http://arxiv.org/pdf/2410.12445v3",
      "published_date": "2024-10-16 10:49:22 UTC",
      "updated_date": "2025-03-04 01:18:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:24:14.151882"
    },
    {
      "arxiv_id": "2410.12443v2",
      "title": "Reconstruction of Differentially Private Text Sanitization via Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Shuchao Pang",
        "Zhigang Lu",
        "Haichen Wang",
        "Peng Fu",
        "Yongbin Zhou",
        "Minhui Xue"
      ],
      "abstract": "Differential privacy (DP) is the de facto privacy standard against privacy\nleakage attacks, including many recently discovered ones against large language\nmodels (LLMs). However, we discovered that LLMs could reconstruct the\naltered/removed privacy from given DP-sanitized prompts. We propose two attacks\n(black-box and white-box) based on the accessibility to LLMs and show that LLMs\ncould connect the pair of DP-sanitized text and the corresponding private\ntraining data of LLMs by giving sample text pairs as instructions (in the\nblack-box attacks) or fine-tuning data (in the white-box attacks). To\nillustrate our findings, we conduct comprehensive experiments on modern LLMs\n(e.g., LLaMA-2, LLaMA-3, ChatGPT-3.5, ChatGPT-4, ChatGPT-4o, Claude-3,\nClaude-3.5, OPT, GPT-Neo, GPT-J, Gemma-2, and Pythia) using commonly used\ndatasets (such as WikiMIA, Pile-CC, and Pile-Wiki) against both word-level and\nsentence-level DP. The experimental results show promising recovery rates,\ne.g., the black-box attacks against the word-level DP over WikiMIA dataset gave\n72.18% on LLaMA-2 (70B), 82.39% on LLaMA-3 (70B), 75.35% on Gemma-2, 91.2% on\nChatGPT-4o, and 94.01% on Claude-3.5 (Sonnet). More urgently, this study\nindicates that these well-known LLMs have emerged as a new security risk for\nexisting DP text sanitization approaches in the current environment.",
      "tldr_zh": "本研究揭示了大语言模型(LLMs)能够重建差分隐私(DP)处理的文本，从而泄露私有数据，提出了黑盒和白盒攻击方法。\n在黑盒攻击中，通过提供样本文本对作为指令来连接DP-sanitized文本和私有训练数据；在白盒攻击中，则利用微调数据实现。\n实验在多种LLMs（如LLaMA-2、LLaMA-3、ChatGPT-4o和Claude-3.5）及数据集（如WikiMIA）上进行，结果显示恢复率高达94%，表明现有DP文本清理方法面临严重安全风险。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12443v2",
      "published_date": "2024-10-16 10:41:17 UTC",
      "updated_date": "2025-04-20 03:22:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:24:27.269973"
    },
    {
      "arxiv_id": "2410.12428v1",
      "title": "Conformity in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaochen Zhu",
        "Caiqi Zhang",
        "Tom Stafford",
        "Nigel Collier",
        "Andreas Vlachos"
      ],
      "abstract": "The conformity effect describes the tendency of individuals to align their\nresponses with the majority. Studying this bias in large language models (LLMs)\nis crucial, as LLMs are increasingly used in various information-seeking and\ndecision-making tasks as conversation partners to improve productivity. Thus,\nconformity to incorrect responses can compromise their effectiveness. In this\npaper, we adapt psychological experiments to examine the extent of conformity\nin state-of-the-art LLMs. Our findings reveal that all models tested exhibit\nvarying levels of conformity toward the majority, regardless of their initial\nchoice or correctness, across different knowledge domains. Notably, we are the\nfirst to show that LLMs are more likely to conform when they are more uncertain\nin their own prediction. We further explore factors that influence conformity,\nsuch as training paradigms and input characteristics, finding that\ninstruction-tuned models are less susceptible to conformity, while increasing\nthe naturalness of majority tones amplifies conformity. Finally, we propose two\ninterventions--Devil's Advocate and Question Distillation--to mitigate\nconformity, providing insights into building more robust language models.",
      "tldr_zh": "该研究探讨了大型语言模型（LLMs）中的conformity效应，即模型倾向于与多数意见一致的现象，这可能在信息搜索和决策任务中降低其有效性。研究者通过适应心理实验，测试了多种最先进LLMs，发现所有模型在不同知识领域都表现出不同程度的conformity，尤其是在自身预测不确定时更容易受影响。影响因素包括训练范式（instruction-tuned模型更抗拒conformity）和输入特性（增加majority tones的自然性会放大效应），并提出了Devil's Advocate和Question Distillation两种干预方法，以提升LLMs的鲁棒性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages (8 pages main body), 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.12428v1",
      "published_date": "2024-10-16 10:16:34 UTC",
      "updated_date": "2024-10-16 10:16:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:24:41.132942"
    },
    {
      "arxiv_id": "2410.12418v1",
      "title": "Privacy-Preserving Synthetically Augmented Knowledge Graphs with Semantic Utility",
      "title_zh": "隐私保护的合成增强知识图谱与语义效用",
      "authors": [
        "Luigi Bellomarini",
        "Costanza Catalano",
        "Andrea Coletta",
        "Michela Iezzi",
        "Pierangela Samarati"
      ],
      "abstract": "Knowledge Graphs (KGs) have recently gained relevant attention in many\napplication domains, from healthcare to biotechnology, from logistics to\nfinance. Financial organisations, central banks, economic research entities,\nand national supervision authorities apply ontological reasoning on KGs to\naddress crucial business tasks, such as economic policymaking, banking\nsupervision, anti-money laundering, and economic research. Reasoning allows for\nthe generation of derived knowledge capturing complex business semantics and\nthe set up of effective business processes. A major obstacle in KGs sharing is\nrepresented by privacy considerations since the identity of the data subjects\nand their sensitive or company-confidential information may be improperly\nexposed.\n  In this paper, we propose a novel framework to enable KGs sharing while\nensuring that information that should remain private is not directly released\nnor indirectly exposed via derived knowledge, while maintaining the embedded\nknowledge of the KGs to support business downstream tasks. Our approach\nproduces a privacy-preserving synthetic KG as an augmentation of the input one\nvia the introduction of structural anonymisation. We introduce a novel privacy\nmeasure for KGs, which considers derived knowledge and a new utility metric\nthat captures the business semantics we want to preserve, and propose two novel\nanonymization algorithms. Our extensive experimental evaluation, with both\nsynthetic graphs and real-world datasets, confirms the effectiveness of our\napproach achieving up to a 70% improvement in the privacy of entities compared\nto existing methods not specifically designed for KGs.",
      "tldr_zh": "该研究针对知识图谱（Knowledge Graphs, KGs）在金融等领域共享时的隐私问题，提出一个新框架，用于生成隐私保护的合成KG，同时保留业务语义的实用性。该框架通过引入结构匿名化方法，创建输入KG的增强版本，并定义了一个新的隐私度量（考虑派生知识）和实用性指标，以支持下游业务任务。实验结果显示，该方法在合成图和真实数据集上，比现有方法提高了实体隐私度量多达70%，有效平衡了隐私保护与知识保留。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.DB",
      "comment": "32 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.12418v1",
      "published_date": "2024-10-16 10:04:02 UTC",
      "updated_date": "2024-10-16 10:04:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:24:51.381450"
    },
    {
      "arxiv_id": "2410.12416v1",
      "title": "Enhancing Speech Emotion Recognition through Segmental Average Pooling of Self-Supervised Learning Features",
      "title_zh": "翻译失败",
      "authors": [
        "Jonghwan Hyeon",
        "Yung-Hwan Oh",
        "Ho-Jin Choi"
      ],
      "abstract": "Speech Emotion Recognition (SER) analyzes human emotions expressed through\nspeech. Self-supervised learning (SSL) offers a promising approach to SER by\nlearning meaningful representations from a large amount of unlabeled audio\ndata. However, existing SSL-based methods rely on Global Average Pooling (GAP)\nto represent audio signals, treating speech and non-speech segments equally.\nThis can lead to dilution of informative speech features by irrelevant\nnon-speech information. To address this, the paper proposes Segmental Average\nPooling (SAP), which selectively focuses on informative speech segments while\nignoring non-speech segments. By applying both GAP and SAP to SSL features, our\napproach utilizes overall speech signal information from GAP and specific\ninformation from SAP, leading to improved SER performance. Experiments show\nstate-of-the-art results on the IEMOCAP for English and superior performance on\nKEMDy19 for Korean datasets in both unweighted and weighted accuracies.",
      "tldr_zh": "本研究针对语音情感识别(Speech Emotion Recognition, SER)中的问题，提出了一种改进的自监督学习(Self-Supervised Learning, SSL)特征处理方法。现有方法依赖全局平均池化(Global Average Pooling, GAP)，导致语音和非语音段信息混杂，稀释了关键特征。为此，论文引入分段平均池化(Segmental Average Pooling, SAP)，专注于信息丰富的语音段，同时结合GAP利用整体信号信息，从而提升SER性能。实验结果显示，该方法在IEMOCAP（英语数据集）和KEMDy19（韩语数据集）上实现了最先进性能，在无权重和加权准确率方面均表现出色。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12416v1",
      "published_date": "2024-10-16 10:00:57 UTC",
      "updated_date": "2024-10-16 10:00:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:25:03.917477"
    },
    {
      "arxiv_id": "2410.12409v1",
      "title": "Revealing the Barriers of Language Agents in Planning",
      "title_zh": "揭示语言代理在规划中的障碍",
      "authors": [
        "Jian Xie",
        "Kexun Zhang",
        "Jiangjie Chen",
        "Siyu Yuan",
        "Kai Zhang",
        "Yikai Zhang",
        "Lei Li",
        "Yanghua Xiao"
      ],
      "abstract": "Autonomous planning has been an ongoing pursuit since the inception of\nartificial intelligence. Based on curated problem solvers, early planning\nagents could deliver precise solutions for specific tasks but lacked\ngeneralization. The emergence of large language models (LLMs) and their\npowerful reasoning capabilities has reignited interest in autonomous planning\nby automatically generating reasonable solutions for given tasks. However,\nprior research and our experiments show that current language agents still lack\nhuman-level planning abilities. Even the state-of-the-art reasoning model,\nOpenAI o1, achieves only 15.6% on one of the complex real-world planning\nbenchmarks. This highlights a critical question: What hinders language agents\nfrom achieving human-level planning? Although existing studies have highlighted\nweak performance in agent planning, the deeper underlying issues and the\nmechanisms and limitations of the strategies proposed to address them remain\ninsufficiently understood. In this work, we apply the feature attribution study\nand identify two key factors that hinder agent planning: the limited role of\nconstraints and the diminishing influence of questions. We also find that\nalthough current strategies help mitigate these challenges, they do not fully\nresolve them, indicating that agents still have a long way to go before\nreaching human-level intelligence.",
      "tldr_zh": "这篇论文揭示了语言代理（language agents）在自主规划中的障碍，尽管大语言模型（LLMs）具备强大的推理能力，但它们仍远未达到人类水平。研究通过特征归因研究（feature attribution study）识别出两个关键因素：约束的作用有限（limited role of constraints）和问题的逐渐影响减弱（diminishing influence of questions）。实验结果显示，即使是先进的模型如 OpenAI o1，在复杂真实世界规划基准上也仅取得 15.6% 的成功率。现有策略虽能部分缓解这些问题，但无法完全解决，表明语言代理在实现人类级智能方面仍有很长的路要走。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Work in Progress",
      "pdf_url": "http://arxiv.org/pdf/2410.12409v1",
      "published_date": "2024-10-16 09:44:38 UTC",
      "updated_date": "2024-10-16 09:44:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:25:19.005354"
    },
    {
      "arxiv_id": "2410.12891v2",
      "title": "Multi-trait User Simulation with Adaptive Decoding for Conversational Task Assistants",
      "title_zh": "翻译失败",
      "authors": [
        "Rafael Ferreira",
        "David Semedo",
        "João Magalhães"
      ],
      "abstract": "Conversational systems must be robust to user interactions that naturally\nexhibit diverse conversational traits. Capturing and simulating these diverse\ntraits coherently and efficiently presents a complex challenge. This paper\nintroduces Multi-Trait Adaptive Decoding (mTAD), a method that generates\ndiverse user profiles at decoding-time by sampling from various trait-specific\nLanguage Models (LMs). mTAD provides an adaptive and scalable approach to user\nsimulation, enabling the creation of multiple user profiles without the need\nfor additional fine-tuning. By analyzing real-world dialogues from the\nConversational Task Assistant (CTA) domain, we identify key conversational\ntraits and developed a framework to generate profile-aware dialogues that\nenhance conversational diversity. Experimental results validate the\neffectiveness of our approach in modeling single-traits using specialized LMs,\nwhich can capture less common patterns, even in out-of-domain tasks.\nFurthermore, the results demonstrate that mTAD is a robust and flexible\nframework for combining diverse user simulators.",
      "tldr_zh": "本研究针对对话系统的鲁棒性，提出Multi-trait User Simulation with Adaptive Decoding (mTAD)方法，通过在解码时从各种trait-specific Language Models (LMs)中采样，生成多样化的用户配置文件，实现高效的用户模拟。mTAD是一种自适应且可扩展的框架，无需额外微调，即可基于Conversational Task Assistant (CTA)领域的真实对话分析关键对话特征，并创建profile-aware对话以提升多样性。实验结果显示，该方法在建模单一特征时使用专业LMs能有效捕捉不常见模式，甚至适用于域外任务，且作为灵活框架，能稳健地结合多种用户模拟器，提高整体系统性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint from EMNLP 2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2410.12891v2",
      "published_date": "2024-10-16 09:40:34 UTC",
      "updated_date": "2024-10-28 09:22:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:25:38.187841"
    },
    {
      "arxiv_id": "2410.12389v1",
      "title": "A Fast Convoluted Story: Scaling Probabilistic Inference for Integer Arithmetic",
      "title_zh": "翻译失败",
      "authors": [
        "Lennert De Smet",
        "Pedro Zuidberg Dos Martires"
      ],
      "abstract": "As illustrated by the success of integer linear programming, linear integer\narithmetic is a powerful tool for modelling combinatorial problems.\nFurthermore, the probabilistic extension of linear programming has been used to\nformulate problems in neurosymbolic AI. However, two key problems persist that\nprevent the adoption of neurosymbolic techniques beyond toy problems. First,\nprobabilistic inference is inherently hard, #P-hard to be precise. Second, the\ndiscrete nature of integers renders the construction of meaningful gradients\nchallenging, which is problematic for learning. In order to mitigate these\nissues, we formulate linear arithmetic over integer-valued random variables as\ntensor manipulations that can be implemented in a straightforward fashion using\nmodern deep learning libraries. At the core of our formulation lies the\nobservation that the addition of two integer-valued random variables can be\nperformed by adapting the fast Fourier transform to probabilities in the\nlog-domain. By relying on tensor operations we obtain a differentiable data\nstructure, which unlocks, virtually for free, gradient-based learning. In our\nexperimental validation we show that tensorising probabilistic linear integer\narithmetic and leveraging the fast Fourier transform allows us to push the\nstate of the art by several orders of magnitude in terms of inference and\nlearning times.",
      "tldr_zh": "本文研究了整数算术在建模组合问题和神经符号AI中的应用，但强调了probabilistic inference的计算难度（#P-hard）和整数离散性对梯度构建的挑战。作者提出一种新方法，将整数值随机变量的线性算术表述为tensor manipulations，并利用fast Fourier transform在log-domain处理加法，从而实现可微分结构，支持基于梯度的学习。实验验证显示，这种方法在推理和学习时间上，比现有技术提高了几个数量级的效率。",
      "categories": [
        "cs.AI",
        "68T37",
        "G.3; G.3; I.2.6"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12389v1",
      "published_date": "2024-10-16 09:16:10 UTC",
      "updated_date": "2024-10-16 09:16:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:25:39.776984"
    },
    {
      "arxiv_id": "2410.12381v3",
      "title": "HumanEval-V: Benchmarking High-Level Visual Reasoning with Complex Diagrams in Coding Tasks",
      "title_zh": "HumanEval-V：在编码任务中使用复杂图表进行高级视觉推理的基准测试",
      "authors": [
        "Fengji Zhang",
        "Linquan Wu",
        "Huiyu Bai",
        "Guancheng Lin",
        "Xiao Li",
        "Xiao Yu",
        "Yue Wang",
        "Bei Chen",
        "Jacky Keung"
      ],
      "abstract": "Understanding and reasoning over diagrams is a fundamental aspect of human\nintelligence. While Large Multimodal Models (LMMs) have demonstrated impressive\ncapabilities across various tasks, existing benchmarks lack comprehensive\nevaluation of their diagram interpretation and reasoning abilities,\nparticularly in coding contexts. We present HumanEval-V, a rigorous benchmark\nof human-annotated coding tasks that spans six task types and evaluates diverse\nvisual reasoning capabilities. Each task features carefully crafted diagrams\npaired with function signatures and test cases, employing novel code generation\ntasks to thoroughly assess models' diagram comprehension. Through extensive\nexperiments with 22 LMMs, we find that even top-performing models achieve\nmodest success rates, with Claude 3.5 Sonnet reaching only 36.8% pass@1,\nhighlighting substantial room for improvement. Our analysis reveals that\ncurrent LMMs struggle with spatial transformations, topological relationships,\nand dynamic patterns that humans find intuitive. These findings provide\nvaluable insights for advancing LMMs' visual reasoning abilities. We have\nopen-sourced our code and benchmark at\nhttps://github.com/HumanEval-V/HumanEval-V-Benchmark.",
      "tldr_zh": "本文提出了 HumanEval-V 基准测试，用于评估大型多模态模型 (LMMs) 在处理复杂图表时的视觉推理能力，特别是在编码任务中。该基准包括六种任务类型、人类注释的图表、函数签名和测试用例，通过新型代码生成任务来全面测试模型的图表理解。实验结果显示，22 个 LMMs 中的顶尖模型如 Claude 3.5 Sonnet 仅达到 36.8% 的 pass@1 成功率，暴露了模型在空间变换、拓扑关系和动态模式等方面的不足。这些发现为提升 LMMs 的视觉推理能力提供了宝贵见解，并已开源相关代码和基准。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "homepage https://humaneval-v.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2410.12381v3",
      "published_date": "2024-10-16 09:04:57 UTC",
      "updated_date": "2025-02-18 06:00:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:25:52.755645"
    },
    {
      "arxiv_id": "2410.14733v2",
      "title": "Knowledge Graph Embeddings: A Comprehensive Survey on Capturing Relation Properties",
      "title_zh": "知识图谱嵌入：捕获关系属性的全面综述",
      "authors": [
        "Guanglin Niu"
      ],
      "abstract": "Knowledge Graph Embedding (KGE) techniques play a pivotal role in\ntransforming symbolic Knowledge Graphs (KGs) into numerical representations,\nthereby enhancing various deep learning models for knowledge-augmented\napplications. Unlike entities, relations in KGs are the carriers of semantic\nmeaning, and their accurate modeling is crucial for the performance of KGE\nmodels. Firstly, we address the complex mapping properties inherent in\nrelations, such as one-to-one, one-to-many, many-to-one, and many-to-many\nmappings. We provide a comprehensive summary of relation-aware mapping-based\nmodels, models that utilize specific representation spaces, tensor\ndecomposition-based models, and neural network-based models. Next, focusing on\ncapturing various relation patterns like symmetry, asymmetry, inversion, and\ncomposition, we review models that employ modified tensor decomposition, those\nbased on modified relation-aware mappings, and those that leverage rotation\noperations. Subsequently, considering the implicit hierarchical relations among\nentities, we introduce models that incorporate auxiliary information, models\nbased on hyperbolic spaces, and those that utilize the polar coordinate system.\nFinally, in response to more complex scenarios such as sparse and dynamic KGs,\nthis paper discusses potential future research directions. We explore\ninnovative ideas such as integrating multimodal information into KGE, enhancing\nrelation pattern modeling with rules, and developing models to capture relation\ncharacteristics in dynamic KGE settings.",
      "tldr_zh": "这篇论文对Knowledge Graph Embedding (KGE) 进行了全面综述，重点探讨如何准确捕捉知识图谱中关系的语义属性，如映射类型（one-to-one、one-to-many 等）和模式（对称性、反转、组合）。作者总结了多种模型，包括基于映射的模型、tensor decomposition 方法、神经网络方法，以及利用hyperbolic spaces 和极坐标系统的层次化建模技术，以提升KGE 在深度学习应用中的性能。论文还讨论了未来研究方向，如整合多模态信息、使用规则增强关系模式建模，以及开发适用于动态和稀疏KGs 的新方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "I.2.7"
      ],
      "primary_category": "cs.LG",
      "comment": "22 pages, 8 figures, 3 tables, this paper is a modified English\n  version of our article already published in Computer Science journal (in\n  Chinese), released to facilitate communication among international\n  researchers in the relevant fields",
      "pdf_url": "http://arxiv.org/pdf/2410.14733v2",
      "published_date": "2024-10-16 08:54:52 UTC",
      "updated_date": "2025-03-21 02:50:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:26:04.119767"
    },
    {
      "arxiv_id": "2410.12376v2",
      "title": "ShapefileGPT: A Multi-Agent Large Language Model Framework for Automated Shapefile Processing",
      "title_zh": "ShapefileGPT: 多智能体大语言模型框架，用于自动化的 Shapefile 处理",
      "authors": [
        "Qingming Lin",
        "Rui Hu",
        "Huaxia Li",
        "Sensen Wu",
        "Yadong Li",
        "Kai Fang",
        "Hailin Feng",
        "Zhenhong Du",
        "Liuchang Xu"
      ],
      "abstract": "Vector data is one of the two core data structures in geographic information\nscience (GIS), essential for accurately storing and representing geospatial\ninformation. Shapefile, the most widely used vector data format, has become the\nindustry standard supported by all major geographic information systems.\nHowever, processing this data typically requires specialized GIS knowledge and\nskills, creating a barrier for researchers from other fields and impeding\ninterdisciplinary research in spatial data analysis. Moreover, while large\nlanguage models (LLMs) have made significant advancements in natural language\nprocessing and task automation, they still face challenges in handling the\ncomplex spatial and topological relationships inherent in GIS vector data. To\naddress these challenges, we propose ShapefileGPT, an innovative framework\npowered by LLMs, specifically designed to automate Shapefile tasks.\nShapefileGPT utilizes a multi-agent architecture, in which the planner agent is\nresponsible for task decomposition and supervision, while the worker agent\nexecutes the tasks. We developed a specialized function library for handling\nShapefiles and provided comprehensive API documentation, enabling the worker\nagent to operate Shapefiles efficiently through function calling. For\nevaluation, we developed a benchmark dataset based on authoritative textbooks,\nencompassing tasks in categories such as geometric operations and spatial\nqueries. ShapefileGPT achieved a task success rate of 95.24%, outperforming the\nGPT series models. In comparison to traditional LLMs, ShapefileGPT effectively\nhandles complex vector data analysis tasks, overcoming the limitations of\ntraditional LLMs in spatial analysis. This breakthrough opens new pathways for\nadvancing automation and intelligence in the GIS field, with significant\npotential in interdisciplinary data analysis and application contexts.",
      "tldr_zh": "本研究针对Shapefile作为GIS中核心矢量数据格式的处理难题，提出ShapefileGPT框架，利用多智能体Large Language Model (LLMs)实现自动化Shapefile任务，以克服传统LLMs在处理复杂空间和拓扑关系方面的局限性。该框架包括planner agent负责任务分解和监督，以及worker agent通过专用函数库和API文档执行操作，如几何运算和空间查询。实验基于权威教科书构建的基准数据集显示，ShapefileGPT的成功率达95.24%，优于GPT系列模型。总体而言，该框架推动了GIS领域的自动化和智能化发展，促进跨学科空间数据分析。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12376v2",
      "published_date": "2024-10-16 08:48:27 UTC",
      "updated_date": "2024-10-23 12:58:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:26:16.505181"
    },
    {
      "arxiv_id": "2410.12375v1",
      "title": "PRefLexOR: Preference-based Recursive Language Modeling for Exploratory Optimization of Reasoning and Agentic Thinking",
      "title_zh": "翻译失败",
      "authors": [
        "Markus J. Buehler"
      ],
      "abstract": "PRefLexOR (Preference-based Recursive Language Modeling for Exploratory\nOptimization of Reasoning) combines preference optimization with concepts from\nReinforcement Learning to enable models to self-teach through iterative\nreasoning improvements. We propose a recursive learning approach that engages\nthe model in multi-step reasoning, revisiting, and refining intermediate steps\nbefore producing a final output in training and inference phases. Through\nmultiple training stages, the model first learns to align its reasoning with\naccurate decision paths by optimizing the log odds between preferred and\nnon-preferred responses. During this process, PRefLexOR builds a dynamic\nknowledge graph by generating questions from random text chunks and\nretrieval-augmentation to contextualize relevant details from the entire\ntraining corpus. In the second stage, preference optimization enhances model\nperformance by using rejection sampling to fine-tune reasoning quality by\ncontinually producing in-situ training data while masking the reasoning steps.\nRecursive optimization within a thinking token framework introduces iterative\nfeedback loops, where the model refines reasoning, achieving deeper coherence,\nconsistency, and adaptability. Implemented in small language models with only 3\nbillion parameters, we should that even tiny models can iteratively teach\nthemselves to reason with greater depth and reflectivity. Our implementation is\nstraightforward and can be incorporated into any existing pretrained LLM. We\nfocus our examples on applications in biological materials science and\ndemonstrate the method in a variety of case studies that range from in-domain\nto cross-domain applications. Using reasoning strategies that include thinking\nand reflection modalities we build a multi-agent recursive self-improving\ninference approach to successively improve responses via repeated sampling in\ninference time.",
      "tldr_zh": "该研究提出PRefLexOR，一种基于偏好优化的递归语言建模框架，结合Reinforcement Learning概念，让语言模型通过迭代推理改进实现自我教学。框架采用多步递归学习方法，包括优化偏好响应对数几率、构建动态知识图以及使用拒绝采样生成原位训练数据，以提升推理的连贯性、一致性和适应性。在仅有30亿参数的小型语言模型上实验表明，即使小型模型也能通过递归优化和思考令牌框架实现更深入的推理，并应用于生物材料科学的多领域案例研究中。最终，PRefLexOR易于整合到现有预训练LLM中，支持多智能体递归自我改进推理。",
      "categories": [
        "cs.AI",
        "cond-mat.dis-nn",
        "cond-mat.mes-hall",
        "cond-mat.mtrl-sci",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12375v1",
      "published_date": "2024-10-16 08:46:26 UTC",
      "updated_date": "2024-10-16 08:46:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:26:28.253539"
    },
    {
      "arxiv_id": "2410.14731v2",
      "title": "MatryoshkaKV: Adaptive KV Compression via Trainable Orthogonal Projection",
      "title_zh": "翻译失败",
      "authors": [
        "Bokai Lin",
        "Zihao Zeng",
        "Zipeng Xiao",
        "Siqi Kou",
        "Tianqi Hou",
        "Xiaofeng Gao",
        "Hao Zhang",
        "Zhijie Deng"
      ],
      "abstract": "KV cache has become a de facto technique for the inference of large language\nmodels (LLMs), where tensors of shape (layer number, head number, sequence\nlength, feature dimension) are introduced to cache historical information for\nself-attention. As the size of the model and data grows, the KV cache can\nquickly become a bottleneck within the system in both storage and memory\ntransfer. To address this, prior studies usually focus on the first three axes\nof the cache tensors for compression. This paper supplements them, focusing on\nthe feature dimension axis, by utilizing low-rank projection matrices to\ntransform the cache features into spaces with reduced dimensions. We begin by\ninvestigating the canonical orthogonal projection method for data compression\nthrough principal component analysis (PCA). We observe the issue with PCA\nprojection where significant performance degradation is observed at low\ncompression rates. To bridge the gap, we propose to directly tune the\northogonal projection matrices with a distillation objective using an elaborate\nMatryoshka training strategy. After training, we adaptively search for the\noptimal compression rates for various layers and heads given varying\ncompression budgets. Compared to previous works, our method can easily embrace\npre-trained LLMs and hold a smooth tradeoff between performance and compression\nrate. We empirically witness the high data efficiency of our training procedure\nand find that our method can sustain over 90% performance with an average KV\ncache compression rate of 60% (and up to 75% in certain extreme scenarios) for\npopular LLMs like LLaMA2-7B-base and Mistral-7B-v0.3-base.",
      "tldr_zh": "该论文提出MatryoshkaKV方法，通过可训练的正交投影矩阵针对KV cache的特征维度进行自适应压缩，以缓解大型语言模型(LLMs)推理中的存储和内存传输瓶颈。不同于以往研究，该方法使用主成分分析(PCA)作为起点，但通过蒸馏目标和Matryoshka训练策略直接优化投影矩阵，实现平滑的性能与压缩率权衡。实验结果显示，在LLaMA2-7B-base和Mistral-7B-v0.3-base等模型上，平均KV cache压缩率达60%（极端情况下达75%）时，性能仍能保持90%以上。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14731v2",
      "published_date": "2024-10-16 08:34:51 UTC",
      "updated_date": "2025-05-16 09:40:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:26:40.759304"
    },
    {
      "arxiv_id": "2410.12361v3",
      "title": "Proactive Agent: Shifting LLM Agents from Reactive Responses to Active Assistance",
      "title_zh": "主动代理：将 LLM 代理从反应式响应转向主动协助",
      "authors": [
        "Yaxi Lu",
        "Shenzhi Yang",
        "Cheng Qian",
        "Guirong Chen",
        "Qinyu Luo",
        "Yesai Wu",
        "Huadong Wang",
        "Xin Cong",
        "Zhong Zhang",
        "Yankai Lin",
        "Weiwen Liu",
        "Yasheng Wang",
        "Zhiyuan Liu",
        "Fangming Liu",
        "Maosong Sun"
      ],
      "abstract": "Agents powered by large language models have shown remarkable abilities in\nsolving complex tasks. However, most agent systems remain reactive, limiting\ntheir effectiveness in scenarios requiring foresight and autonomous\ndecision-making. In this paper, we tackle the challenge of developing proactive\nagents capable of anticipating and initiating tasks without explicit human\ninstructions. We propose a novel data-driven approach for this problem.\nFirstly, we collect real-world human activities to generate proactive task\npredictions. These predictions are then labeled by human annotators as either\naccepted or rejected. The labeled data is used to train a reward model that\nsimulates human judgment and serves as an automatic evaluator of the\nproactiveness of LLM agents. Building on this, we develop a comprehensive data\ngeneration pipeline to create a diverse dataset, ProactiveBench, containing\n6,790 events. Finally, we demonstrate that fine-tuning models with the proposed\nProactiveBench can significantly elicit the proactiveness of LLM agents.\nExperimental results show that our fine-tuned model achieves an F1-Score of\n66.47% in proactively offering assistance, outperforming all open-source and\nclose-source models. These results highlight the potential of our method in\ncreating more proactive and effective agent systems, paving the way for future\nadvancements in human-agent collaboration.",
      "tldr_zh": "本文提出一种数据驱动方法，将LLM agents从反应式响应转向主动辅助，解决其在预见性和自主决策方面的局限性。研究首先收集真实世界人类活动数据，通过人类标注训练一个reward model来评估代理的主动性，并开发了ProactiveBench数据集，包含6,790个事件用于模型微调。实验结果显示，微调后的模型在主动提供帮助的F1-Score上达到66.47%，优于所有开源和闭源模型，这为提升人类-代理协作的效率提供了新途径。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.12361v3",
      "published_date": "2024-10-16 08:24:09 UTC",
      "updated_date": "2024-12-03 04:34:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:26:52.306781"
    },
    {
      "arxiv_id": "2410.12360v3",
      "title": "Towards Neural Scaling Laws for Time Series Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Qingren Yao",
        "Chao-Han Huck Yang",
        "Renhe Jiang",
        "Yuxuan Liang",
        "Ming Jin",
        "Shirui Pan"
      ],
      "abstract": "Scaling laws offer valuable insights into the design of time series\nfoundation models (TSFMs). However, previous research has largely focused on\nthe scaling laws of TSFMs for in-distribution (ID) data, leaving their\nout-of-distribution (OOD) scaling behavior and the influence of model\narchitectures less explored. In this work, we examine two common TSFM\narchitectures, encoder-only and decoder-only Transformers, and investigate\ntheir scaling behavior on both ID and OOD data. These models are trained and\nevaluated across varying parameter counts, compute budgets, and dataset sizes.\nOur experiments reveal that the log-likelihood loss of TSFMs exhibits similar\nscaling behavior in both OOD and ID settings. We further compare the scaling\nproperties across different architectures, incorporating two state-of-the-art\nTSFMs as case studies, showing that model architecture plays a significant role\nin scaling. The encoder-only Transformers demonstrate better scalability than\nthe decoder-only Transformers, while the architectural enhancements in the two\nadvanced TSFMs primarily improve ID performance but reduce OOD scalability.\nWhile scaling up TSFMs is expected to drive performance breakthroughs, the lack\nof a comprehensive understanding of TSFM scaling laws has hindered the\ndevelopment of a robust framework to guide model scaling. We fill this gap in\nthis work by synthesizing our findings and providing practical guidelines for\ndesigning and scaling larger TSFMs with enhanced model capabilities.",
      "tldr_zh": "本研究探讨了时间序列基础模型（TSFMs）的神经缩放定律（neural scaling laws），重点考察了模型在分布内（ID）和分布外（OOD）数据上的表现，以及不同架构的影响。研究者训练并评估了编码器-only 和解码器-only Transformers，涵盖不同参数数量、计算预算和数据集大小，结果显示 TSFMs 的 log-likelihood 损失在 ID 和 OOD 设置中表现出相似的缩放行为，但编码器-only Transformers 的可缩放性优于解码器-only Transformers，且一些高级 TSFMs 虽提升了 ID 性能却降低了 OOD 缩放性。通过这些发现，论文提供了设计和缩放更大 TSFMs 的实用指导，以提升模型能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by the 13th International Conference on Learning\n  Representations (ICLR 2025)",
      "pdf_url": "http://arxiv.org/pdf/2410.12360v3",
      "published_date": "2024-10-16 08:23:39 UTC",
      "updated_date": "2025-03-18 06:54:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:27:03.831624"
    },
    {
      "arxiv_id": "2410.13903v1",
      "title": "CoreGuard: Safeguarding Foundational Capabilities of LLMs Against Model Stealing in Edge Deployment",
      "title_zh": "翻译失败",
      "authors": [
        "Qinfeng Li",
        "Yangfan Xie",
        "Tianyu Du",
        "Zhiqiang Shen",
        "Zhenghan Qin",
        "Hao Peng",
        "Xinkui Zhao",
        "Xianwei Zhu",
        "Jianwei Yin",
        "Xuhong Zhang"
      ],
      "abstract": "Proprietary large language models (LLMs) demonstrate exceptional\ngeneralization ability across various tasks. Additionally, deploying LLMs on\nedge devices is trending for efficiency and privacy reasons. However, edge\ndeployment of proprietary LLMs introduces new security threats: attackers who\nobtain an edge-deployed LLM can easily use it as a base model for various tasks\ndue to its high generalization ability, which we call foundational capability\nstealing. Unfortunately, existing model protection mechanisms are often\ntask-specific and fail to protect general-purpose LLMs, as they mainly focus on\nprotecting task-related parameters using trusted execution environments (TEEs).\nAlthough some recent TEE-based methods are able to protect the overall model\nparameters in a computation-efficient way, they still suffer from prohibitive\ncommunication costs between TEE and CPU/GPU, making it impractical to deploy\nfor edge LLMs. To protect the foundational capabilities of edge LLMs, we\npropose CoreGuard, a computation- and communication-efficient model protection\napproach against model stealing on edge devices. The core component of\nCoreGuard is a lightweight and propagative authorization module residing in\nTEE. Extensive experiments show that CoreGuard achieves the same security\nprotection as the black-box security guarantees with negligible overhead.",
      "tldr_zh": "该研究针对大型语言模型(LLMs)在边缘设备部署时面临的模型窃取威胁，提出CoreGuard框架，以保护LLMs的基础能力(foundational capabilities)。CoreGuard的核心是一个轻量级且传播性的授权模块(lightweight and propagative authorization module)，驻留在受信执行环境(TEE)中，通过高效的计算和通信机制避免了现有方法的通信成本问题。实验结果显示，CoreGuard在安全保护方面达到了黑盒级别的保障，同时开销微不足道，为边缘部署的LLMs提供了可靠的防护。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13903v1",
      "published_date": "2024-10-16 08:14:24 UTC",
      "updated_date": "2024-10-16 08:14:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:27:15.635781"
    },
    {
      "arxiv_id": "2410.12350v1",
      "title": "GECTurk WEB: An Explainable Online Platform for Turkish Grammatical Error Detection and Correction",
      "title_zh": "翻译失败",
      "authors": [
        "Ali Gebeşçe",
        "Gözde Gül Şahin"
      ],
      "abstract": "Sophisticated grammatical error detection/correction tools are available for\na small set of languages such as English and Chinese. However, it is not\nstraightforward -- if not impossible -- to adapt them to morphologically rich\nlanguages with complex writing rules like Turkish which has more than 80\nmillion speakers. Even though several tools exist for Turkish, they primarily\nfocus on spelling errors rather than grammatical errors and lack features such\nas web interfaces, error explanations and feedback mechanisms. To fill this\ngap, we introduce GECTurk WEB, a light, open-source, and flexible web-based\nsystem that can detect and correct the most common forms of Turkish writing\nerrors, such as the misuse of diacritics, compound and foreign words, pronouns,\nlight verbs along with spelling mistakes. Our system provides native speakers\nand second language learners an easily accessible tool to detect/correct such\nmistakes and also to learn from their mistakes by showing the explanation for\nthe violated rule(s). The proposed system achieves 88,3 system usability score,\nand is shown to help learn/remember a grammatical rule (confirmed by 80% of the\nparticipants). The GECTurk WEB is available both as an offline tool at\nhttps://github.com/GGLAB-KU/gecturkweb or online at www.gecturk.net.",
      "tldr_zh": "该研究针对土耳其语等形态丰富的语言在语法错误检测和修正工具上的不足，引入了 GECTurk WEB，这是一个轻量级、开源的在线平台，能够检测和修正常见的土耳其写作错误，如重音符号误用、复合词、外来词、代词和轻动词问题。系统不仅提供错误检测与修正功能，还通过解释违反的语法规则，帮助用户学习和避免类似错误。实验结果显示，GECTurk WEB 的系统可用性得分达到 88.3，且 80% 的参与者确认它有助于记忆语法规则。该平台可通过 GitHub 获取离线版本，或访问 www.gecturk.net 使用在线版本。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12350v1",
      "published_date": "2024-10-16 08:13:54 UTC",
      "updated_date": "2024-10-16 08:13:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:27:29.694836"
    },
    {
      "arxiv_id": "2410.12889v1",
      "title": "Using Protected Attributes to Consider Fairness in Multi-Agent Systems",
      "title_zh": "利用受保护属性考虑多智能体系统中的公平性",
      "authors": [
        "Gabriele La Malfa",
        "Jie M. Zhang",
        "Michael Luck",
        "Elizabeth Black"
      ],
      "abstract": "Fairness in Multi-Agent Systems (MAS) has been extensively studied,\nparticularly in reward distribution among agents in scenarios such as goods\nallocation, resource division, lotteries, and bargaining systems. Fairness in\nMAS depends on various factors, including the system's governing rules, the\nbehaviour of the agents, and their characteristics. Yet, fairness in human\nsociety often involves evaluating disparities between disadvantaged and\nprivileged groups, guided by principles of Equality, Diversity, and Inclusion\n(EDI). Taking inspiration from the work on algorithmic fairness, which\naddresses bias in machine learning-based decision-making, we define protected\nattributes for MAS as characteristics that should not disadvantage an agent in\nterms of its expected rewards. We adapt fairness metrics from the algorithmic\nfairness literature -- namely, demographic parity, counterfactual fairness, and\nconditional statistical parity -- to the multi-agent setting, where\nself-interested agents interact within an environment. These metrics allow us\nto evaluate the fairness of MAS, with the ultimate aim of designing MAS that do\nnot disadvantage agents based on protected attributes.",
      "tldr_zh": "该论文探讨了多智能体系统（Multi-Agent Systems, MAS）中的公平性问题，强调评估代理在奖励分配中的不平等，特别是受受保护属性（protected attributes）影响的群体。该研究借鉴算法公平性领域的理念，定义 protected attributes 为不应导致代理在预期奖励上处于劣势的特征，并将公平度量标准——包括 demographic parity、counterfactual fairness 和 conditional statistical parity——适应到 MAS 环境，以评估代理互动的公平性。最终目标是通过这些度量设计出不基于 protected attributes 歧视代理的 MAS 系统，促进平等、多样性和包容性（EDI）原则的实现。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12889v1",
      "published_date": "2024-10-16 08:12:01 UTC",
      "updated_date": "2024-10-16 08:12:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:27:40.047721"
    },
    {
      "arxiv_id": "2410.12346v2",
      "title": "Efficient Diffusion as Low Light Enhancer",
      "title_zh": "翻译失败",
      "authors": [
        "Guanzhou Lan",
        "Qianli Ma",
        "Yuqi Yang",
        "Zhigang Wang",
        "Dong Wang",
        "Xuelong Li",
        "Bin Zhao"
      ],
      "abstract": "The computational burden of the iterative sampling process remains a major\nchallenge in diffusion-based Low-Light Image Enhancement (LLIE). Current\nacceleration methods, whether training-based or training-free, often lead to\nsignificant performance degradation, highlighting the trade-off between\nperformance and efficiency. In this paper, we identify two primary factors\ncontributing to performance degradation: fitting errors and the inference gap.\nOur key insight is that fitting errors can be mitigated by linearly\nextrapolating the incorrect score functions, while the inference gap can be\nreduced by shifting the Gaussian flow to a reflectance-aware residual space.\nBased on the above insights, we design Reflectance-Aware Trajectory Refinement\n(RATR) module, a simple yet effective module to refine the teacher trajectory\nusing the reflectance component of images. Following this, we introduce\n\\textbf{Re}flectance-aware \\textbf{D}iffusion with \\textbf{Di}stilled\n\\textbf{T}rajectory (\\textbf{ReDDiT}), an efficient and flexible distillation\nframework tailored for LLIE. Our framework achieves comparable performance to\nprevious diffusion-based methods with redundant steps in just 2 steps while\nestablishing new state-of-the-art (SOTA) results with 8 or 4 steps.\nComprehensive experimental evaluations on 10 benchmark datasets validate the\neffectiveness of our method, consistently outperforming existing SOTA methods.",
      "tldr_zh": "本研究针对基于扩散模型的低光图像增强 (LLIE) 的计算负担问题，识别出 fitting errors 和 inference gap 作为性能下降的主要因素，并提出通过线性外推 score functions 和将 Gaussian flow 转移到 reflectance-aware residual space 的解决方案。论文设计了 Reflectance-Aware Trajectory Refinement (RATR) 模块，利用图像的 reflectance 组件来优化轨迹，并引入了 ReDDiT（Reflectance-aware Diffusion with Distilled Trajectory）框架，这是一个高效的蒸馏方法，仅需 2 步即可与多步扩散模型匹敌，在 8 或 4 步内实现新的 SOTA 性能。实验在 10 个基准数据集上验证了该方法的有效性，显著优于现有 SOTA 方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.12346v2",
      "published_date": "2024-10-16 08:07:18 UTC",
      "updated_date": "2024-11-21 08:20:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:27:52.294916"
    },
    {
      "arxiv_id": "2410.12342v1",
      "title": "TAS: Distilling Arbitrary Teacher and Student via a Hybrid Assistant",
      "title_zh": "TAS：通过混合助手蒸馏任意教师和学生",
      "authors": [
        "Guopeng Li",
        "Qiang Wang",
        "Ke Yan",
        "Shouhong Ding",
        "Yuan Gao",
        "Gui-Song Xia"
      ],
      "abstract": "Most knowledge distillation (KD) methodologies predominantly focus on\nteacher-student pairs with similar architectures, such as both being\nconvolutional neural networks (CNNs). However, the potential and flexibility of\nKD can be greatly improved by expanding it to novel Cross-Architecture KD\n(CAKD), where the knowledge of homogeneous and heterogeneous teachers can be\ntransferred flexibly to a given student. The primary challenge in CAKD lies in\nthe substantial feature gaps between heterogeneous models, originating from the\ndistinction of their inherent inductive biases and module functions. To this\nend, we introduce an assistant model as a bridge to facilitate smooth feature\nknowledge transfer between heterogeneous teachers and students. More\nimportantly, within our proposed design principle, the assistant model combines\nthe advantages of cross-architecture inductive biases and module functions by\nmerging convolution and attention modules derived from both student and teacher\nmodule functions. Furthermore, we observe that heterogeneous features exhibit\ndiverse spatial distributions in CAKD, hindering the effectiveness of\nconventional pixel-wise mean squared error (MSE) loss. Therefore, we leverage a\nspatial-agnostic InfoNCE loss to align features after spatial smoothing,\nthereby improving the feature alignments in CAKD. Our proposed method is\nevaluated across some homogeneous model pairs and arbitrary heterogeneous\ncombinations of CNNs, ViTs, and MLPs, achieving state-of-the-art performance\nfor distilled models with a maximum gain of 11.47% on CIFAR-100 and 3.67% on\nImageNet-1K. Our code and models will be released.",
      "tldr_zh": "该论文提出了一种名为 TAS 的知识蒸馏（KD）方法，旨在支持任意教师和学生模型间的知识转移，特别是针对 Cross-Architecture KD (CAKD)，以解决异质模型（如 CNNs、ViTs 和 MLPs）之间特征差距的问题。TAS 通过引入一个混合辅助模型（hybrid assistant）作为桥梁，该模型结合了卷积和注意力模块的优势，促进特征知识的平滑转移；同时，使用空间无关的 InfoNCE 损失替换传统的 MSE 损失，以更好地对齐异质特征的空间分布。实验结果显示，该方法在同质和异质模型组合上实现了 state-of-the-art 性能，在 CIFAR-100 上提升 11.47%，在 ImageNet-1K 上提升 3.67%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages, 6 figures, and 12 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.12342v1",
      "published_date": "2024-10-16 08:02:49 UTC",
      "updated_date": "2024-10-16 08:02:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:28:03.742938"
    },
    {
      "arxiv_id": "2410.12341v2",
      "title": "Characterizing Model Collapse in Large Language Models Using Semantic Networks and Next-Token Probability",
      "title_zh": "使用语义网络和下一标记概率表征大语言模型中的模型坍缩",
      "authors": [
        "Daniele Gambetta",
        "Gizem Gezici",
        "Fosca Giannotti",
        "Dino Pedreschi",
        "Alistair Knott",
        "Luca Pappalardo"
      ],
      "abstract": "As synthetic content increasingly infiltrates the web, generative AI models\nmay experience an autophagy process, where they are fine-tuned using their own\noutputs. This autophagy could lead to a phenomenon known as model collapse,\nwhich entails a degradation in the performance and diversity of generative AI\nmodels over successive generations. Recent studies have explored the emergence\nof model collapse across various generative AI models and types of data.\nHowever, the current characterizations of model collapse tend to be simplistic\nand lack comprehensive evaluation. In this article, we conduct a thorough\ninvestigation of model collapse across three text datasets, utilizing semantic\nnetworks to analyze text repetitiveness and diversity, while employing\nnext-token probabilities to quantify the loss of diversity. We also examine how\nthe proportions of synthetic tokens affect the severity of model collapse and\nperform cross-dataset evaluations to identify domain-specific variations. By\nproposing metrics and strategies for a more detailed assessment of model\ncollapse, our study provides new insights for the development of robust\ngenerative AI systems.",
      "tldr_zh": "这篇论文探讨了大型语言模型在使用合成内容进行微调时可能引发的模型崩溃（model collapse），这会导致模型性能和多样性逐渐下降。作者采用语义网络（semantic networks）分析文本的重复性和多样性，并利用下一 token 概率（next-token probability）量化多样性损失，在三个文本数据集上进行全面评估。研究还考察了合成 token 比例对崩溃严重程度的影响，并通过跨数据集评估揭示领域特定差异，最终提出新的指标和策略，以提升生成式 AI 系统的鲁棒性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12341v2",
      "published_date": "2024-10-16 08:02:48 UTC",
      "updated_date": "2025-02-02 22:40:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:28:16.166813"
    },
    {
      "arxiv_id": "2410.12329v1",
      "title": "Understanding the Role of LLMs in Multimodal Evaluation Benchmarks",
      "title_zh": "翻译失败",
      "authors": [
        "Botian Jiang",
        "Lei Li",
        "Xiaonan Li",
        "Zhaowei Li",
        "Xiachong Feng",
        "Lingpeng Kong",
        "Qi Liu",
        "Xipeng Qiu"
      ],
      "abstract": "The rapid advancement of Multimodal Large Language Models (MLLMs) has been\naccompanied by the development of various benchmarks to evaluate their\ncapabilities. However, the true nature of these evaluations and the extent to\nwhich they assess multimodal reasoning versus merely leveraging the underlying\nLarge Language Model (LLM) backbone remain unclear. This paper presents a\ncomprehensive investigation into the role of LLM backbones in MLLM evaluation,\nfocusing on two critical aspects: the degree to which current benchmarks truly\nassess multimodal reasoning and the influence of LLM prior knowledge on\nperformance. Specifically, we introduce a modified evaluation protocol to\ndisentangle the contributions of the LLM backbone from multimodal integration,\nand an automatic knowledge identification technique for diagnosing whether LLMs\nequip the necessary knowledge for corresponding multimodal questions. Our study\nencompasses four diverse MLLM benchmarks and eight state-of-the-art MLLMs. Key\nfindings reveal that some benchmarks allow high performance even without visual\ninputs and up to 50\\% of error rates can be attributed to insufficient world\nknowledge in the LLM backbone, indicating a heavy reliance on language\ncapabilities. To address knowledge deficiencies, we propose a knowledge\naugmentation pipeline that achieves significant performance gains, with\nimprovements of up to 60\\% on certain datasets, resulting in a approximately 4x\nincrease in performance. Our work provides crucial insights into the role of\nthe LLM backbone in MLLMs, and highlights the need for more nuanced\nbenchmarking approaches.",
      "tldr_zh": "这篇论文探讨了 Large Language Model (LLM) 在 Multimodal Large Language Models (MLLMs) 评估基准中的作用，揭示了这些基准可能过度依赖 LLM 的语言能力，而非真正评估多模态推理。作者引入了修改的评估协议和自动知识识别技术，分析了四个 MLLM 基准和八个最先进模型的表现，发现一些基准即使没有视觉输入也能获得高性能，且高达 50% 的错误率归因于 LLM 骨干的知识不足。论文提出了一种知识增强管道，显著提升性能（如某些数据集改善高达 60%，约 4 倍增幅），并强调需要更细致的基准设计以更好地评估 MLLMs。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12329v1",
      "published_date": "2024-10-16 07:49:13 UTC",
      "updated_date": "2024-10-16 07:49:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:28:30.805452"
    },
    {
      "arxiv_id": "2410.18125v3",
      "title": "Towards Edge General Intelligence via Large Language Models: Opportunities and Challenges",
      "title_zh": "翻译失败",
      "authors": [
        "Handi Chen",
        "Weipeng Deng",
        "Shuo Yang",
        "Jinfeng Xu",
        "Zhihan Jiang",
        "Edith C. H. Ngai",
        "Jiangchuan Liu",
        "Xue Liu"
      ],
      "abstract": "Edge Intelligence (EI) has been instrumental in delivering real-time,\nlocalized services by leveraging the computational capabilities of edge\nnetworks. The integration of Large Language Models (LLMs) empowers EI to evolve\ninto the next stage: Edge General Intelligence (EGI), enabling more adaptive\nand versatile applications that require advanced understanding and reasoning\ncapabilities. However, systematic exploration in this area remains\ninsufficient. This survey delineates the distinctions between EGI and\ntraditional EI, categorizing LLM-empowered EGI into three conceptual systems:\ncentralized, hybrid, and decentralized. For each system, we detail the\nframework designs and review existing implementations. Furthermore, we evaluate\nthe performance and throughput of various Small Language Models (SLMs) that are\nmore suitable for development on edge devices. This survey provides researchers\nwith a comprehensive vision of EGI, offering insights into its vast potential\nand establishing a foundation for future advancements in this rapidly evolving\nfield.",
      "tldr_zh": "这篇论文探讨了通过 Large Language Models (LLMs) 实现 Edge General Intelligence (EGI)，旨在提升 Edge Intelligence (EI) 的适应性和多功能性，以支持需要高级理解和推理的应用。论文将 LLM 赋能的 EGI 分为集中式、混合式和分散式三种系统，并详细描述了每种系统的框架设计、现有实现以及 Small Language Models (SLMs) 的性能和吞吐量评估。最终，它提供 EGI 的全面愿景，强调其潜力并为该领域未来发展奠定基础。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18125v3",
      "published_date": "2024-10-16 07:45:31 UTC",
      "updated_date": "2025-03-06 06:10:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:28:41.729727"
    },
    {
      "arxiv_id": "2410.12323v2",
      "title": "Reversal of Thought: Enhancing Large Language Models with Preference-Guided Reverse Reasoning Warm-up",
      "title_zh": "翻译失败",
      "authors": [
        "Jiahao Yuan",
        "Dehui Du",
        "Hao Zhang",
        "Zixiang Di",
        "Usman Naseem"
      ],
      "abstract": "Large language models (LLMs) have shown remarkable performance in reasoning\ntasks but face limitations in mathematical and complex logical reasoning.\nExisting methods to improve LLMs' logical capabilities either involve traceable\nor verifiable logical sequences that generate more reliable responses by\nconstructing logical structures yet increase computational costs, or introduces\nrigid logic template rules, reducing flexibility. In this paper, we propose\nReversal of Thought (RoT), a plug-and-play and cost-effective reasoning\nframework designed to enhance the logical reasoning abilities of LLMs during\nthe warm-up phase prior to batch inference. RoT utilizes a Preference-Guided\nReverse Reasoning warm-up strategy, which integrates logical symbols for\npseudocode planning through meta-cognitive mechanisms and pairwise preference\nself-evaluation to generate task-specific prompts solely through\ndemonstrations, aligning with LLMs' cognitive preferences shaped by RLHF.\nThrough reverse reasoning, we utilize a Cognitive Preference Manager to assess\nknowledge boundaries and further expand LLMs' reasoning capabilities by\naggregating solution logic for known tasks and stylistic templates for unknown\ntasks. Experiments across various tasks demonstrate that RoT surpasses existing\nbaselines in both reasoning accuracy and efficiency.",
      "tldr_zh": "本论文针对 Large Language Models (LLMs) 在数学和复杂逻辑推理中的局限性，提出了 Reversal of Thought (RoT) 框架，这是一种即插即用且成本有效的推理方法。RoT 通过 Preference-Guided Reverse Reasoning warm-up 策略，在预热阶段整合逻辑符号进行伪代码规划，并利用元认知机制（meta-cognitive mechanisms）和成对偏好自我评估（pairwise preference self-evaluation），结合 RLHF 塑造的认知偏好生成任务特定提示，同时通过 Cognitive Preference Manager 评估知识边界并扩展推理能力。实验结果表明，RoT 在各种任务中超过了现有基线，在推理准确性和效率方面表现出显著优势。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12323v2",
      "published_date": "2024-10-16 07:44:28 UTC",
      "updated_date": "2025-02-16 12:11:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:28:53.611900"
    },
    {
      "arxiv_id": "2410.12318v1",
      "title": "UTF:Undertrained Tokens as Fingerprints A Novel Approach to LLM Identification",
      "title_zh": "翻译失败",
      "authors": [
        "Jiacheng Cai",
        "Jiahao Yu",
        "Yangguang Shao",
        "Yuhang Wu",
        "Xinyu Xing"
      ],
      "abstract": "Fingerprinting large language models (LLMs) is essential for verifying model\nownership, ensuring authenticity, and preventing misuse. Traditional\nfingerprinting methods often require significant computational overhead or\nwhite-box verification access. In this paper, we introduce UTF, a novel and\nefficient approach to fingerprinting LLMs by leveraging under-trained tokens.\nUnder-trained tokens are tokens that the model has not fully learned during its\ntraining phase. By utilizing these tokens, we perform supervised fine-tuning to\nembed specific input-output pairs into the model. This process allows the LLM\nto produce predetermined outputs when presented with certain inputs,\neffectively embedding a unique fingerprint. Our method has minimal overhead and\nimpact on model's performance, and does not require white-box access to target\nmodel's ownership identification. Compared to existing fingerprinting methods,\nUTF is also more effective and robust to fine-tuning and random guess.",
      "tldr_zh": "该论文提出了一种新型方法 UTF，利用 under-trained tokens 作为指纹来识别大型语言模型（LLM），以验证模型所有权、确保真实性和防止误用。UTF 通过监督微调，将特定输入-输出对嵌入模型中，使其在遇到这些输入时产生预定输出，从而创建独特指纹，而无需白盒访问或高计算开销。与现有方法相比，该方法对模型性能影响最小，且在面对微调和随机猜测时更有效和鲁棒。总的来说，UTF 为高效的 LLM 指纹识别提供了实用解决方案。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12318v1",
      "published_date": "2024-10-16 07:36:57 UTC",
      "updated_date": "2024-10-16 07:36:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:29:04.557826"
    },
    {
      "arxiv_id": "2410.14730v1",
      "title": "On the Relation Between Linear Diffusion and Power Iteration",
      "title_zh": "翻译失败",
      "authors": [
        "Dana Weitzner",
        "Mauricio Delbracio",
        "Peyman Milanfar",
        "Raja Giryes"
      ],
      "abstract": "Recently, diffusion models have gained popularity due to their impressive\ngenerative abilities. These models learn the implicit distribution given by the\ntraining dataset, and sample new data by transforming random noise through the\nreverse process, which can be thought of as gradual denoising. In this work, we\nexamine the generation process as a ``correlation machine'', where random noise\nis repeatedly enhanced in correlation with the implicit given distribution. To\nthis end, we explore the linear case, where the optimal denoiser in the MSE\nsense is known to be the PCA projection. This enables us to connect the theory\nof diffusion models to the spiked covariance model, where the dependence of the\ndenoiser on the noise level and the amount of training data can be expressed\nanalytically, in the rank-1 case. In a series of numerical experiments, we\nextend this result to general low rank data, and show that low frequencies\nemerge earlier in the generation process, where the denoising basis vectors are\nmore aligned to the true data with a rate depending on their eigenvalues. This\nmodel allows us to show that the linear diffusion model converges in mean to\nthe leading eigenvector of the underlying data, similarly to the prevalent\npower iteration method. Finally, we empirically demonstrate the applicability\nof our findings beyond the linear case, in the Jacobians of a deep, non-linear\ndenoiser, used in general image generation tasks.",
      "tldr_zh": "本文探讨了线性扩散模型（diffusion models）和幂迭代（power iteration）之间的关系，分析了扩散模型的生成过程如何通过逐步增强噪声与隐式分布的相关性来模拟数据分布。作者在线性情况下利用 PCA 投影和 spiked covariance model 理论，证明了去噪器的依赖性，并通过数值实验显示低频成分在生成过程中更早出现，且其对齐率受特征值影响。最终，研究发现线性扩散模型在均值上收敛到底层数据的领先特征向量，类似于幂迭代方法，并通过经验验证扩展到非线性图像生成任务中。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14730v1",
      "published_date": "2024-10-16 07:33:12 UTC",
      "updated_date": "2024-10-16 07:33:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:29:16.162747"
    },
    {
      "arxiv_id": "2410.12312v2",
      "title": "FaceChain-FACT: Face Adapter with Decoupled Training for Identity-preserved Personalization",
      "title_zh": "翻译失败",
      "authors": [
        "Cheng Yu",
        "Haoyu Xie",
        "Lei Shang",
        "Yang Liu",
        "Jun Dan",
        "Liefeng Bo",
        "Baigui Sun"
      ],
      "abstract": "In the field of human-centric personalized image generation, the\nadapter-based method obtains the ability to customize and generate portraits by\ntext-to-image training on facial data. This allows for identity-preserved\npersonalization without additional fine-tuning in inference. Although there are\nimprovements in efficiency and fidelity, there is often a significant\nperformance decrease in test following ability, controllability, and diversity\nof generated faces compared to the base model. In this paper, we analyze that\nthe performance degradation is attributed to the failure to decouple identity\nfeatures from other attributes during extraction, as well as the failure to\ndecouple the portrait generation training from the overall generation task. To\naddress these issues, we propose the Face Adapter with deCoupled Training\n(FACT) framework, focusing on both model architecture and training strategy. To\ndecouple identity features from others, we leverage a transformer-based\nface-export encoder and harness fine-grained identity features. To decouple the\nportrait generation training, we propose Face Adapting Increment\nRegularization~(FAIR), which effectively constrains the effect of face adapters\non the facial region, preserving the generative ability of the base model.\nAdditionally, we incorporate a face condition drop and shuffle mechanism,\ncombined with curriculum learning, to enhance facial controllability and\ndiversity. As a result, FACT solely learns identity preservation from training\ndata, thereby minimizing the impact on the original text-to-image capabilities\nof the base model. Extensive experiments show that FACT has both\ncontrollability and fidelity in both text-to-image generation and inpainting\nsolutions for portrait generation.",
      "tldr_zh": "该论文提出FaceChain-FACT框架，利用Decoupled Training策略来提升基于Face Adapter的人脸个性化图像生成，旨在解决现有方法在测试时跟随能力、可控性和多样性下降的问题。通过transformer-based face-export encoder分离身份特征，并引入Face Adapting Increment Regularization (FAIR)来约束适配器对人脸区域的影响，同时结合face condition drop and shuffle机制及curriculum learning，提升生成的可控性和多样性。实验结果显示，FACT在文本到图像生成和inpainting任务中实现了更好的可控性与保真度，同时最小化了对基础模型的影响。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.12312v2",
      "published_date": "2024-10-16 07:25:24 UTC",
      "updated_date": "2024-10-25 06:56:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:30:21.956729"
    },
    {
      "arxiv_id": "2410.12311v4",
      "title": "Open Domain Question Answering with Conflicting Contexts",
      "title_zh": "开放域问答系统中的冲突上下文",
      "authors": [
        "Siyi Liu",
        "Qiang Ning",
        "Kishaloy Halder",
        "Wei Xiao",
        "Zheng Qi",
        "Phu Mon Htut",
        "Yi Zhang",
        "Neha Anna John",
        "Bonan Min",
        "Yassine Benajiba",
        "Dan Roth"
      ],
      "abstract": "Open domain question answering systems frequently rely on information\nretrieved from large collections of text (such as the Web) to answer questions.\nHowever, such collections of text often contain conflicting information, and\nindiscriminately depending on this information may result in untruthful and\ninaccurate answers. To understand the gravity of this problem, we collect a\nhuman-annotated dataset, Question Answering with Conflicting Contexts (QACC),\nand find that as much as 25% of unambiguous, open domain questions can lead to\nconflicting contexts when retrieved using Google Search. We evaluate and\nbenchmark three powerful Large Language Models (LLMs) with our dataset QACC and\ndemonstrate their limitations in effectively addressing questions with\nconflicting information. To explore how humans reason through conflicting\ncontexts, we request our annotators to provide explanations for their\nselections of correct answers. We demonstrate that by finetuning LLMs to\nexplain their answers, we can introduce richer information into their training\nthat guide them through the process of reasoning with conflicting contexts.",
      "tldr_zh": "本研究探讨了开放域问答（Open Domain Question Answering）系统中冲突上下文的问题，这些系统依赖于从大型文本集合（如网络）检索的信息，但冲突信息可能导致答案不准确或不真实。研究者构建了人类标注数据集 QACC（Question Answering with Conflicting Contexts），发现使用 Google Search 检索时，多达 25% 的明确开放域问题会产生冲突上下文，并评估了三个大语言模型（LLMs）的表现，揭示了它们在处理冲突信息时的局限性。为了模拟人类推理过程，研究人员收集了标注者对正确答案的解释，并通过微调 LLMs 以生成解释，显著提升了模型在冲突上下文中的推理能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12311v4",
      "published_date": "2024-10-16 07:24:28 UTC",
      "updated_date": "2025-04-28 03:06:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:29:40.503110"
    },
    {
      "arxiv_id": "2410.14729v3",
      "title": "Is Less More? Exploring Token Condensation as Training-free Test-time Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Zixin Wang",
        "Dong Gong",
        "Sen Wang",
        "Zi Huang",
        "Yadan Luo"
      ],
      "abstract": "Contrastive Language-Image Pretraining (CLIP) excels at learning\ngeneralizable image representations but often falls short in zero-shot\ninference on certain downstream datasets. Test-time adaptation (TTA) mitigates\nthis issue by adjusting components like normalization layers or context\nprompts, yet it typically requires large batch sizes and extensive\naugmentations, leading to high computational costs. This raises a key question:\nCan VLMs' performance drop in specific test cases be mitigated through\nefficient, training-free approaches? To explore the solution, we investigate\ntoken condensation (TC) techniques, originally designed to enhance vision\ntransformer efficiency by refining token usage during inference. We observe\nthat informative tokens improve visual-text alignment in VLMs like CLIP on\nunseen datasets. However, existing TC methods often fail to maintain\nin-distribution performance when reducing tokens, prompting us to ask: How can\nwe transform TC into an effective ``free-lunch'' adaptation strategy for VLMs?\nTo address this, we propose Token Condensation as Adaptation (TCA), a\ntraining-free adaptation method that takes a step beyond standard TC. Rather\nthan passively discarding tokens, TCA condenses token representation by\nintroducing reservoir-based domain anchor tokens for information-preserving\ntoken reduction and logits correction. TCA achieves up to a 21.4% performance\nimprovement over the strongest baseline on cross-dataset benchmark and the\nCIFAR-100-Corrupted dataset while reducing GFLOPs by 12.2% to 48.9%, with\nminimal hyperparameter dependency on both CLIP and SigLIP series.",
      "tldr_zh": "这篇论文探讨了 token condensation (TC) 作为一种无训练的测试时适应 (TTA) 方法，以提升 CLIP 在零样本下游数据集上的性能，同时解决现有 TTA 方法的高计算成本问题。作者提出 Token Condensation as Adaptation (TCA)，通过引入 reservoir-based domain anchor tokens 来优化 token 表示，实现信息保留和 logits 修正，而非简单丢弃 tokens。实验结果显示，TCA 在跨数据集基准和 CIFAR-100-Corrupted 数据集上比最强基线提高了高达 21.4% 的性能，同时减少了 12.2% 到 48.9% 的 GFLOPs，且对 CLIP 和 SigLIP 系列模型的超参数依赖最小。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "16 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.14729v3",
      "published_date": "2024-10-16 07:13:35 UTC",
      "updated_date": "2025-03-15 09:01:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:29:52.751679"
    },
    {
      "arxiv_id": "2410.12302v1",
      "title": "Two Birds with One Stone: Multi-Task Semantic Communications Systems over Relay Channel",
      "title_zh": "一石二鸟：基于中继信道的多任务语义通信系统",
      "authors": [
        "Yujie Cao",
        "Tong Wu",
        "Zhiyong Chen",
        "Yin Xu",
        "Meixia Tao",
        "Wenjun Zhang"
      ],
      "abstract": "In this paper, we propose a novel multi-task, multi-link relay semantic\ncommunications (MTML-RSC) scheme that enables the destination node to\nsimultaneously perform image reconstruction and classification with one\ntransmission from the source node. In the MTML-RSC scheme, the source node\nbroadcasts a signal using semantic communications, and the relay node forwards\nthe signal to the destination. We analyze the coupling relationship between the\ntwo tasks and the two links (source-to-relay and source-to-destination) and\ndesign a semantic-focused forward method for the relay node, where it\nselectively forwards only the semantics of the relevant class while ignoring\nothers. At the destination, the node combines signals from both the source node\nand the relay node to perform classification, and then uses the classification\nresult to assist in decoding the signal from the relay node for image\nreconstructing. Experimental results demonstrate that the proposed MTML-RSC\nscheme achieves significant performance gains, e.g., $1.73$ dB improvement in\npeak-signal-to-noise ratio (PSNR) for image reconstruction and increasing the\naccuracy from $64.89\\%$ to $70.31\\%$ for classification.",
      "tldr_zh": "本文提出了一种多任务多链路中继语义通信（MTML-RSC）方案，允许目标节点通过源节点的一次传输同时实现图像重建和分类。方案分析了图像重建与分类任务之间，以及源到继电器和源到目标链路之间的耦合关系，设计了继电器节点的语义聚焦转发方法，仅转发相关类的语义以优化信号处理。实验结果显示，MTML-RSC 方案显著提升性能，包括图像重建的 PSNR 提高了 1.73 dB，以及分类准确率从 64.89% 提升至 70.31%。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "cs.LG",
        "math.IT"
      ],
      "primary_category": "cs.IT",
      "comment": "submitted to IEEE WCNC",
      "pdf_url": "http://arxiv.org/pdf/2410.12302v1",
      "published_date": "2024-10-16 07:02:51 UTC",
      "updated_date": "2024-10-16 07:02:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:30:05.486850"
    },
    {
      "arxiv_id": "2410.12298v2",
      "title": "Pyramid-Driven Alignment: Pyramid Principle Guided Integration of Large Language Models and Knowledge Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Lei Sun",
        "Xinchen Wang",
        "Youdi Li"
      ],
      "abstract": "Large Language Models (LLMs) possess impressive reasoning abilities but are\nprone to generating incorrect information, often referred to as hallucinations.\nWhile incorporating external Knowledge Graphs (KGs) can partially mitigate this\nissue, existing methods primarily treat KGs as static knowledge repositories,\noverlooking the critical disparity between KG and LLM knowledge, and failing to\nfully exploit the reasoning capabilities inherent in KGs. To address these\nlimitations, we propose Pyramid-Driven Alignment (PDA), a novel framework for\nseamlessly integrating LLMs with KGs. PDA utilizes Pyramid Principle analysis\nto construct a hierarchical pyramid structure. This structure is designed to\nreflect the input question and generate more validated deductive knowledge,\nthereby enhancing the alignment of LLMs and KGs and ensuring more cohesive\nintegration. Furthermore, PDA employs a recursive mechanism to harness the\nunderlying reasoning abilities of KGs, resulting in more accurate knowledge\nretrieval for question-answering tasks. Our experimental results reveal a\nsubstantial performance advantage of PDA over state-of-the-art baselines, with\nimprovements reaching 26.70% and 26.78%.",
      "tldr_zh": "本研究针对 Large Language Models (LLMs) 的推理能力与易产生 hallucinations 的问题，提出 Pyramid-Driven Alignment (PDA) 框架，以更好地整合 LLMs 和 Knowledge Graphs (KGs)。PDA 通过 Pyramid Principle analysis 构建一个层次化的金字塔结构，根据输入问题生成更可靠的演绎知识，从而提升 LLMs 与 KGs 的对齐和整合。框架还采用递归机制来利用 KGs 的推理能力，实现更准确的知识检索和问答任务。实验结果显示，PDA 相较于现有基线模型，性能提升达 26.70% 和 26.78%。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12298v2",
      "published_date": "2024-10-16 06:57:18 UTC",
      "updated_date": "2024-10-17 11:00:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:30:16.129024"
    },
    {
      "arxiv_id": "2410.12297v1",
      "title": "Conjunction Subspaces Test for Conformal and Selective Classification",
      "title_zh": "针对保形和选择性分类的结合子",
      "authors": [
        "Zengyou He",
        "Zerun Li",
        "Junjie Dong",
        "Xinying Liu",
        "Mudi Jiang",
        "Lianyu Hu"
      ],
      "abstract": "In this paper, we present a new classifier, which integrates significance\ntesting results over different random subspaces to yield consensus p-values for\nquantifying the uncertainty of classification decision. The null hypothesis is\nthat the test sample has no association with the target class on a randomly\nchosen subspace, and hence the classification problem can be formulated as a\nproblem of testing for the conjunction of hypotheses. The proposed classifier\ncan be easily deployed for the purpose of conformal prediction and selective\nclassification with reject and refine options by simply thresholding the\nconsensus p-values. The theoretical analysis on the generalization error bound\nof the proposed classifier is provided and empirical studies on real data sets\nare conducted as well to demonstrate its effectiveness.",
      "tldr_zh": "本论文提出了一种名为Conjunction Subspaces Test的新分类器，通过在不同随机子空间上整合显著性测试结果，生成共识 p-values 来量化分类决策的不确定性。分类问题被表述为测试假设的结合（conjunction of hypotheses），其中零假设为测试样本在随机子空间上与目标类无关。该分类器可轻松应用于conformal prediction和selective classification，通过阈值共识 p-values 实现拒绝或细化选项，并提供了理论上的泛化错误界。实证研究在真实数据集上验证了其有效性，展示了显著的性能提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "36 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.12297v1",
      "published_date": "2024-10-16 06:56:53 UTC",
      "updated_date": "2024-10-16 06:56:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:30:34.594876"
    },
    {
      "arxiv_id": "2410.12295v1",
      "title": "Consistency Calibration: Improving Uncertainty Calibration via Consistency among Perturbed Neighbors",
      "title_zh": "一致性校准：通过扰动邻居之间的一致性改善不确定性校准",
      "authors": [
        "Linwei Tao",
        "Haolan Guo",
        "Minjing Dong",
        "Chang Xu"
      ],
      "abstract": "Calibration is crucial in deep learning applications, especially in fields\nlike healthcare and autonomous driving, where accurate confidence estimates are\nvital for decision-making. However, deep neural networks often suffer from\nmiscalibration, with reliability diagrams and Expected Calibration Error (ECE)\nbeing the only standard perspective for evaluating calibration performance. In\nthis paper, we introduce the concept of consistency as an alternative\nperspective on model calibration, inspired by uncertainty estimation literature\nin large language models (LLMs). We highlight its advantages over the\ntraditional reliability-based view. Building on this concept, we propose a\npost-hoc calibration method called Consistency Calibration (CC), which adjusts\nconfidence based on the model's consistency across perturbed inputs. CC is\nparticularly effective in locally uncertainty estimation, as it requires no\nadditional data samples or label information, instead generating input\nperturbations directly from the source data. Moreover, we show that performing\nperturbations at the logit level significantly improves computational\nefficiency. We validate the effectiveness of CC through extensive comparisons\nwith various post-hoc and training-time calibration methods, demonstrating\nstate-of-the-art performance on standard datasets such as CIFAR-10, CIFAR-100,\nand ImageNet, as well as on long-tailed datasets like ImageNet-LT.",
      "tldr_zh": "本研究针对深度神经网络的校准问题，引入“consistency”（一致性）作为一种新视角，强调模型在扰动输入下的稳定性，以弥补传统基于可靠性图和Expected Calibration Error (ECE)的评估局限。论文提出一种后处理校准方法Consistency Calibration (CC)，通过分析模型对扰动输入的一致性来调整置信度，该方法无需额外数据或标签，仅从源数据生成扰动，并在logit级别操作以提升计算效率。实验结果显示，CC在CIFAR-10、CIFAR-100和ImageNet等标准数据集，以及ImageNet-LT长尾数据集上，相比其他后处理和训练时校准方法，实现了state-of-the-art性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12295v1",
      "published_date": "2024-10-16 06:55:02 UTC",
      "updated_date": "2024-10-16 06:55:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:30:46.471728"
    },
    {
      "arxiv_id": "2410.12288v1",
      "title": "A Prompt-Based Knowledge Graph Foundation Model for Universal In-Context Reasoning",
      "title_zh": "一种基于提示的知识图谱基础模型，用于通用上下文内推理",
      "authors": [
        "Yuanning Cui",
        "Zequn Sun",
        "Wei Hu"
      ],
      "abstract": "Extensive knowledge graphs (KGs) have been constructed to facilitate\nknowledge-driven tasks across various scenarios. However, existing work usually\ndevelops separate reasoning models for different KGs, lacking the ability to\ngeneralize and transfer knowledge across diverse KGs and reasoning settings. In\nthis paper, we propose a prompt-based KG foundation model via in-context\nlearning, namely KG-ICL, to achieve a universal reasoning ability.\nSpecifically, we introduce a prompt graph centered with a query-related example\nfact as context to understand the query relation. To encode prompt graphs with\nthe generalization ability to unseen entities and relations in queries, we\nfirst propose a unified tokenizer that maps entities and relations in prompt\ngraphs to predefined tokens. Then, we propose two message passing neural\nnetworks to perform prompt encoding and KG reasoning, respectively. We conduct\nevaluation on 43 different KGs in both transductive and inductive settings.\nResults indicate that the proposed KG-ICL outperforms baselines on most\ndatasets, showcasing its outstanding generalization and universal reasoning\ncapabilities. The source code is accessible on GitHub:\nhttps://github.com/nju-websoft/KG-ICL.",
      "tldr_zh": "该论文提出了一种基于提示的知识图谱 (KGs) 基础模型，名为 KG-ICL，通过 in-context learning 实现通用推理能力，以解决现有模型在不同 KGs 之间缺乏泛化的问题。模型的核心方法包括构建以查询相关示例事实为中心的提示图，使用统一 tokenizer 将实体和关系映射到预定义的 token，并采用两个消息传递神经网络 (message passing neural networks) 分别进行提示编码和 KG 推理。在 43 个不同 KGs 的 transductive 和 inductive 设置中，KG-ICL 优于基线模型，展示了其出色的泛化和通用推理能力。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted in the 38th Conference on Neural Information Processing\n  Systems (NeurIPS 2024)",
      "pdf_url": "http://arxiv.org/pdf/2410.12288v1",
      "published_date": "2024-10-16 06:47:18 UTC",
      "updated_date": "2024-10-16 06:47:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:30:59.265985"
    },
    {
      "arxiv_id": "2410.14728v1",
      "title": "Security Threats in Agentic AI System",
      "title_zh": "翻译失败",
      "authors": [
        "Raihan Khan",
        "Sayak Sarkar",
        "Sainik Kumar Mahata",
        "Edwin Jose"
      ],
      "abstract": "This research paper explores the privacy and security threats posed to an\nAgentic AI system with direct access to database systems. Such access\nintroduces significant risks, including unauthorized retrieval of sensitive\ninformation, potential exploitation of system vulnerabilities, and misuse of\npersonal or confidential data. The complexity of AI systems combined with their\nability to process and analyze large volumes of data increases the chances of\ndata leaks or breaches, which could occur unintentionally or through\nadversarial manipulation. Furthermore, as AI agents evolve with greater\nautonomy, their capacity to bypass or exploit security measures becomes a\ngrowing concern, heightening the need to address these critical vulnerabilities\nin agentic systems.",
      "tldr_zh": "这篇论文探讨了Agentic AI系统直接访问数据库时面临的隐私和安全威胁，包括未经授权的敏感信息检索、系统漏洞利用以及个人或机密数据的误用。AI系统的复杂性和处理海量数据的能力增加了数据泄露或入侵的风险，这些可能源于意外操作或恶意操控。随着AI代理的自治性增强，其绕过安全措施的可能性进一步加大，论文强调了解决这些关键漏洞的迫切需求。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.CR",
      "comment": "8 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.14728v1",
      "published_date": "2024-10-16 06:40:02 UTC",
      "updated_date": "2024-10-16 06:40:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:31:10.847820"
    },
    {
      "arxiv_id": "2410.12279v1",
      "title": "Beyond Oversmoothing: Evaluating DDPM and MSE for Scalable Speech Synthesis in ASR",
      "title_zh": "翻译失败",
      "authors": [
        "Christoph Minixhofer",
        "Ondrej Klejch",
        "Peter Bell"
      ],
      "abstract": "Synthetically generated speech has rapidly approached human levels of\nnaturalness. However, the paradox remains that ASR systems, when trained on TTS\noutput that is judged as natural by humans, continue to perform badly on real\nspeech. In this work, we explore whether this phenomenon is due to the\noversmoothing behaviour of models commonly used in TTS, with a particular focus\non the behaviour of TTS-for-ASR as the amount of TTS training data is scaled\nup. We systematically compare Denoising Diffusion Probabilistic Models (DDPM)\nto Mean Squared Error (MSE) based models for TTS, when used for ASR model\ntraining. We test the scalability of the two approaches, varying both the\nnumber hours, and the number of different speakers. We find that for a given\nmodel size, DDPM can make better use of more data, and a more diverse set of\nspeakers, than MSE models. We achieve the best reported ratio between real and\nsynthetic speech WER to date (1.46), but also find that a large gap remains.",
      "tldr_zh": "这篇论文探讨了合成语音在自动语音识别（ASR）训练中的性能问题，特别是TTS模型的oversmoothing行为导致的挑战。作者比较了Denoising Diffusion Probabilistic Models (DDPM)和Mean Squared Error (MSE)模型在TTS中的表现，并测试了它们在数据规模（如小时数）和说话者多样性上的可扩展性。结果显示，DDPM比MSE模型更有效地利用更多数据和多样化说话者，实现了迄今最佳的真实与合成语音WER比率（1.46），但两者间仍有显著差距。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "eess.AS",
      "comment": "Under review at ICASSP 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.12279v1",
      "published_date": "2024-10-16 06:35:56 UTC",
      "updated_date": "2024-10-16 06:35:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:31:22.215950"
    },
    {
      "arxiv_id": "2410.12278v1",
      "title": "Controlled Automatic Task-Specific Synthetic Data Generation for Hallucination Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Yong Xie",
        "Karan Aggarwal",
        "Aitzaz Ahmad",
        "Stephen Lau"
      ],
      "abstract": "We present a novel approach to automatically generate non-trivial\ntask-specific synthetic datasets for hallucination detection. Our approach\nfeatures a two-step generation-selection pipeline, using hallucination pattern\nguidance and a language style alignment during generation. Hallucination\npattern guidance leverages the most important task-specific hallucination\npatterns while language style alignment aligns the style of the synthetic\ndataset with benchmark text. To obtain robust supervised detectors from\nsynthetic datasets, we also adopt a data mixture strategy to improve\nperformance robustness and generalization. Our results on three datasets show\nthat our generated hallucination text is more closely aligned with\nnon-hallucinated text versus baselines, to train hallucination detectors with\nbetter generalization. Our hallucination detectors trained on synthetic\ndatasets outperform in-context-learning (ICL)-based detectors by a large margin\nof 32%. Our extensive experiments confirm the benefits of our approach with\ncross-task and cross-generator generalization. Our data-mixture-based training\nfurther improves the generalization and robustness of hallucination detection.",
      "tldr_zh": "本研究提出了一种控制的自动任务特定合成数据生成方法，用于检测 hallucination（幻觉），通过两步生成-选择管道结合 hallucination pattern guidance 和 language style alignment，确保合成数据的相关性和风格一致性。研究还采用 data mixture strategy 来提升监督检测器的性能稳健性和泛化能力。在三个数据集上的实验显示，该方法生成的 hallucination 文本与非幻觉文本更紧密对齐，所训练的检测器比 in-context-learning (ICL) 基于检测器高出 32%，并在跨任务和跨生成器场景中表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "68T50",
        "I.2.7"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12278v1",
      "published_date": "2024-10-16 06:31:59 UTC",
      "updated_date": "2024-10-16 06:31:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:31:35.187086"
    },
    {
      "arxiv_id": "2410.12271v1",
      "title": "Kallini et al. (2024) do not compare impossible languages with constituency-based ones",
      "title_zh": "翻译失败",
      "authors": [
        "Tim Hunter"
      ],
      "abstract": "A central goal of linguistic theory is to find a precise characterization of\nthe notion \"possible human language\", in the form of a computational device\nthat is capable of describing all and only the languages that can be acquired\nby a typically developing human child. The success of recent large language\nmodels (LLMs) in NLP applications arguably raises the possibility that LLMs\nmight be computational devices that meet this goal. This would only be the case\nif, in addition to succeeding in learning human languages, LLMs struggle to\nlearn \"impossible\" human languages. Kallini et al. (2024; \"Mission: Impossible\nLanguage Models\", Proc. ACL) conducted experiments aiming to test this by\ntraining GPT-2 on a variety of synthetic languages, and found that it learns\nsome more successfully than others. They present these asymmetries as support\nfor the idea that LLMs' inductive biases align with what is regarded as\n\"possible\" for human languages, but the most significant comparison has a\nconfound that makes this conclusion unwarranted. In this paper I explain the\nconfound and suggest some ways forward towards constructing a comparison that\nappropriately tests the underlying issue.",
      "tldr_zh": "这篇论文批评了Kallini et al. (2024)的研究，认为他们未正确比较“impossible” languages与基于结构(constituency-based) languages，从而使结论存在混杂因素(confound)。作者指出，Kallini et al.通过训练GPT-2模型测试大型语言模型(LLMs)的归纳偏差(inductive biases)，试图证明LLMs能区分人类可能语言，但实验设计缺陷导致其支持人类语言“possible”特性的论点不可靠。论文解释了这一confound问题，并提出改进建议，如构建更精确的比较框架，以更好地评估LLMs是否能作为表征人类语言计算装置的合适工具。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12271v1",
      "published_date": "2024-10-16 06:16:30 UTC",
      "updated_date": "2024-10-16 06:16:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:31:47.505644"
    },
    {
      "arxiv_id": "2410.12261v4",
      "title": "CATCH: Channel-Aware multivariate Time Series Anomaly Detection via Frequency Patching",
      "title_zh": "翻译失败",
      "authors": [
        "Xingjian Wu",
        "Xiangfei Qiu",
        "Zhengyu Li",
        "Yihang Wang",
        "Jilin Hu",
        "Chenjuan Guo",
        "Hui Xiong",
        "Bin Yang"
      ],
      "abstract": "Anomaly detection in multivariate time series is challenging as heterogeneous\nsubsequence anomalies may occur. Reconstruction-based methods, which focus on\nlearning normal patterns in the frequency domain to detect diverse abnormal\nsubsequences, achieve promising results, while still falling short on capturing\nfine-grained frequency characteristics and channel correlations. To contend\nwith the limitations, we introduce CATCH, a framework based on frequency\npatching. We propose to patchify the frequency domain into frequency bands,\nwhich enhances its ability to capture fine-grained frequency characteristics.\nTo perceive appropriate channel correlations, we propose a Channel Fusion\nModule (CFM), which features a patch-wise mask generator and a masked-attention\nmechanism. Driven by a bi-level multi-objective optimization algorithm, the CFM\nis encouraged to iteratively discover appropriate patch-wise channel\ncorrelations, and to cluster relevant channels while isolating adverse effects\nfrom irrelevant channels. Extensive experiments on 10 real-world datasets and\n12 synthetic datasets demonstrate that CATCH achieves state-of-the-art\nperformance. We make our code and datasets available at\nhttps://github.com/decisionintelligence/CATCH.",
      "tldr_zh": "该研究针对多变量时间序列异常检测的挑战，提出CATCH框架，通过frequency patching将频率域分成frequency bands，以更好地捕捉细粒度的频率特征。CATCH引入Channel Fusion Module (CFM)，包括patch-wise mask generator和masked-attention机制，利用bi-level multi-objective optimization算法迭代发现合适的patch-wise通道相关性，实现相关通道的聚类并隔离无关通道的不利影响。在10个真实数据集和12个合成数据集上的实验表明，CATCH达到了state-of-the-art性能，并公开了代码和数据集。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.12261v4",
      "published_date": "2024-10-16 05:58:55 UTC",
      "updated_date": "2025-05-08 05:13:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:31:58.023996"
    },
    {
      "arxiv_id": "2410.12258v2",
      "title": "Understanding Expert Structures on Minimax Parameter Estimation in Contaminated Mixture of Experts",
      "title_zh": "翻译失败",
      "authors": [
        "Fanqi Yan",
        "Huy Nguyen",
        "Dung Le",
        "Pedram Akbarian",
        "Nhat Ho"
      ],
      "abstract": "We conduct the convergence analysis of parameter estimation in the\ncontaminated mixture of experts. This model is motivated from the prompt\nlearning problem where ones utilize prompts, which can be formulated as\nexperts, to fine-tune a large-scale pre-trained model for learning downstream\ntasks. There are two fundamental challenges emerging from the analysis: (i) the\nproportion in the mixture of the pre-trained model and the prompt may converge\nto zero during the training, leading to the prompt vanishing issue; (ii) the\nalgebraic interaction among parameters of the pre-trained model and the prompt\ncan occur via some partial differential equations and decelerate the prompt\nlearning. In response, we introduce a distinguishability condition to control\nthe previous parameter interaction. Additionally, we also investigate various\ntypes of expert structure to understand their effects on the convergence\nbehavior of parameter estimation. In each scenario, we provide comprehensive\nconvergence rates of parameter estimation along with the corresponding minimax\nlower bounds. Finally, we run several numerical experiments to empirically\njustify our theoretical findings.",
      "tldr_zh": "本研究分析了受污染混合专家（contaminated mixture of experts）模型中参数估计的收敛行为，该模型源于提示学习（prompt learning）问题，用于微调预训练模型以处理下游任务。论文识别了两个关键挑战：提示在混合比例中可能收敛到零导致提示消失问题，以及参数间的代数交互通过偏微分方程减缓学习；为此，引入了 distinguishability condition 来控制参数交互。研究还考察了各种专家结构（expert structure）对收敛的影响，提供全面的参数估计收敛率及对应的 minimax lower bounds，并通过数值实验验证了这些理论发现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Fanqi Yan, Huy Nguyen, and Dung Le contributed equally to this work.\n  Accepted to AISTATS 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.12258v2",
      "published_date": "2024-10-16 05:52:51 UTC",
      "updated_date": "2025-03-06 02:46:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:32:11.269719"
    },
    {
      "arxiv_id": "2410.12250v1",
      "title": "Dual Action Policy for Robust Sim-to-Real Reinforcement Learning",
      "title_zh": "双动作策略用于稳健的 Sim-to-Real 强化学习",
      "authors": [
        "Ng Wen Zheng Terence",
        "Chen Jianda"
      ],
      "abstract": "This paper presents Dual Action Policy (DAP), a novel approach to address the\ndynamics mismatch inherent in the sim-to-real gap of reinforcement learning.\nDAP uses a single policy to predict two sets of actions: one for maximizing\ntask rewards in simulation and another specifically for domain adaptation via\nreward adjustments. This decoupling makes it easier to maximize the overall\nreward in the source domain during training. Additionally, DAP incorporates\nuncertainty-based exploration during training to enhance agent robustness.\nExperimental results demonstrate DAP's effectiveness in bridging the\nsim-to-real gap, outperforming baselines on challenging tasks in simulation,\nand further improvement is achieved by incorporating uncertainty estimation.",
      "tldr_zh": "本论文提出 Dual Action Policy (DAP)，一种创新方法，用于解决强化学习中 sim-to-real 差距导致的动态不匹配问题。DAP 通过一个单一策略预测两组动作，一组专注于模拟环境中最大化任务奖励，另一组通过奖励调整实现领域适应，从而简化源域训练过程；此外，它还整合不确定性-based exploration 来提升代理的鲁棒性。实验结果表明，DAP 在挑战性任务上优于基线模型，并在加入不确定性估计后进一步提升了性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12250v1",
      "published_date": "2024-10-16 05:22:06 UTC",
      "updated_date": "2024-10-16 05:22:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:32:23.605946"
    },
    {
      "arxiv_id": "2410.12236v2",
      "title": "Enhancing LLM Agents for Code Generation with Possibility and Pass-rate Prioritized Experience Replay",
      "title_zh": "使用基于可能性和通过率优先化经验回放增强代码生成的大语言模型代理",
      "authors": [
        "Yuyang Chen",
        "Kaiyan Zhao",
        "Yiming Wang",
        "Ming Yang",
        "Jian Zhang",
        "Xiaoguang Niu"
      ],
      "abstract": "Nowadays transformer-based Large Language Models (LLM) for code generation\ntasks usually apply sampling and filtering pipelines. Due to the sparse reward\nproblem in code generation tasks caused by one-token incorrectness,\ntransformer-based models will sample redundant programs till they find a\ncorrect one, leading to low efficiency. To overcome the challenge, we\nincorporate Experience Replay (ER) in the fine-tuning phase, where codes and\nprograms produced are stored and will be replayed to give the LLM agent a\nchance to learn from past experiences. Based on the spirit of ER, we introduce\na novel approach called BTP pipeline which consists of three phases: beam\nsearch sampling, testing phase, and prioritized experience replay phase. The\napproach makes use of failed programs collected by code models and replays\nprograms with high Possibility and Pass-rate Prioritized value (P2Value) from\nthe replay buffer to improve efficiency. P2Value comprehensively considers the\npossibility of transformers' output and pass rate and can make use of the\nredundant resources caused by the problem that most programs collected by LLMs\nfail to pass any tests. We empirically apply our approach in several LLMs,\ndemonstrating that it enhances their performance in code generation tasks and\nsurpasses existing baselines.",
      "tldr_zh": "该研究针对Transformer-based Large Language Models (LLM) 在代码生成任务中因稀疏奖励问题导致的低效率问题，提出了一种增强方法：结合Experience Replay (ER) 在微调阶段存储和重放过去的代码程序。方法引入BTP pipeline，包括beam search sampling、testing phase 和基于P2Value（考虑transformer输出可能性和通过率）的优先化经验重放阶段，从而利用失败程序并优化资源分配。实验结果显示，该方法显著提升了多种LLM在代码生成任务的性能，并超过了现有基线模型。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12236v2",
      "published_date": "2024-10-16 04:54:42 UTC",
      "updated_date": "2025-01-11 07:08:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:32:33.922601"
    },
    {
      "arxiv_id": "2410.12232v1",
      "title": "Improving the Generalization of Unseen Crowd Behaviors for Reinforcement Learning based Local Motion Planners",
      "title_zh": "翻译失败",
      "authors": [
        "Wen Zheng Terence Ng",
        "Jianda Chen",
        "Sinno Jialin Pan",
        "Tianwei Zhang"
      ],
      "abstract": "Deploying a safe mobile robot policy in scenarios with human pedestrians is\nchallenging due to their unpredictable movements. Current Reinforcement\nLearning-based motion planners rely on a single policy to simulate pedestrian\nmovements and could suffer from the over-fitting issue. Alternatively, framing\nthe collision avoidance problem as a multi-agent framework, where agents\ngenerate dynamic movements while learning to reach their goals, can lead to\nconflicts with human pedestrians due to their homogeneity.\n  To tackle this problem, we introduce an efficient method that enhances agent\ndiversity within a single policy by maximizing an information-theoretic\nobjective. This diversity enriches each agent's experiences, improving its\nadaptability to unseen crowd behaviors. In assessing an agent's robustness\nagainst unseen crowds, we propose diverse scenarios inspired by pedestrian\ncrowd behaviors. Our behavior-conditioned policies outperform existing works in\nthese challenging scenes, reducing potential collisions without additional time\nor travel.",
      "tldr_zh": "该研究针对基于强化学习（Reinforcement Learning）的本地运动规划器在处理未见过的群体行为时存在的过拟合问题，提出了一种高效方法，通过最大化信息论（information-theoretic）目标来增强单一策略内的智能体多样性，从而提高代理对不可预测人行者的适应性。方法将碰撞避免问题视为多智能体框架，但通过多样化策略避免了与人类行人的同质性冲突。实验评估采用受行人群体行为启发的多样化场景，结果显示，该行为条件策略在这些挑战环境中优于现有工作，能显著减少潜在碰撞，同时不增加时间或旅行距离。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12232v1",
      "published_date": "2024-10-16 04:46:21 UTC",
      "updated_date": "2024-10-16 04:46:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:32:46.666099"
    },
    {
      "arxiv_id": "2410.12229v3",
      "title": "Comprehending Knowledge Graphs with Large Language Models for Recommender Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Ziqiang Cui",
        "Yunpeng Weng",
        "Xing Tang",
        "Fuyuan Lyu",
        "Dugang Liu",
        "Xiuqiang He",
        "Chen Ma"
      ],
      "abstract": "In recent years, the introduction of knowledge graphs (KGs) has significantly\nadvanced recommender systems by facilitating the discovery of potential\nassociations between items. However, existing methods still face several\nlimitations. First, most KGs suffer from missing facts or limited scopes.\nSecond, existing methods convert textual information in KGs into IDs, resulting\nin the loss of natural semantic connections between different items. Third,\nexisting methods struggle to capture high-order connections in the global KG.\nTo address these limitations, we propose a novel method called CoLaKG, which\nleverages large language models (LLMs) to improve KG-based recommendations. The\nextensive knowledge and remarkable reasoning capabilities of LLMs enable our\nmethod to supplement missing facts in KGs, and their powerful text\nunderstanding abilities allow for better utilization of semantic information.\nSpecifically, CoLaKG extracts useful information from KGs at both local and\nglobal levels. By employing the item-centered subgraph extraction and prompt\nengineering, it can accurately understand the local information. In addition,\nthrough the semantic-based retrieval module, each item is enriched by related\nitems from the entire knowledge graph, effectively harnessing global\ninformation. Furthermore, the local and global information are effectively\nintegrated into the recommendation model through a representation fusion module\nand a retrieval-augmented representation learning module, respectively.\nExtensive experiments on four real-world datasets demonstrate the superiority\nof our method.",
      "tldr_zh": "该研究针对知识图谱(KGs)在推荐系统中的问题，如缺失事实、语义损失和高阶连接捕获困难，提出了一种新方法CoLaKG，利用大型语言模型(LLMs)的知识和推理能力来改进KG-based推荐。CoLaKG通过item-centered subgraph extraction和prompt engineering提取局部信息，并采用semantic-based retrieval module来整合全局信息，从而补充缺失事实并增强语义理解。最终，通过representation fusion module和retrieval-augmented representation learning module将这些信息融入推荐模型，并在四个真实数据集上的实验中证明了方法的优越性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted as a full paper by SIGIR'25",
      "pdf_url": "http://arxiv.org/pdf/2410.12229v3",
      "published_date": "2024-10-16 04:44:34 UTC",
      "updated_date": "2025-04-17 11:50:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:32:58.482670"
    },
    {
      "arxiv_id": "2410.12228v2",
      "title": "Triple Modality Fusion: Aligning Visual, Textual, and Graph Data with Large Language Models for Multi-Behavior Recommendations",
      "title_zh": "三模态融合：利用大型语言模型对齐视觉、文本和图数据以实现多行为",
      "authors": [
        "Luyi Ma",
        "Xiaohan Li",
        "Zezhong Fan",
        "Kai Zhao",
        "Jianpeng Xu",
        "Jason Cho",
        "Praveen Kanumala",
        "Kaushiki Nag",
        "Sushant Kumar",
        "Kannan Achan"
      ],
      "abstract": "Integrating diverse data modalities is crucial for enhancing the performance\nof personalized recommendation systems. Traditional models, which often rely on\nsingular data sources, lack the depth needed to accurately capture the\nmultifaceted nature of item features and user behaviors. This paper introduces\na novel framework for multi-behavior recommendations, leveraging the fusion of\ntriple-modality, which is visual, textual, and graph data through alignment\nwith large language models (LLMs). By incorporating visual information, we\ncapture contextual and aesthetic item characteristics; textual data provides\ninsights into user interests and item features in detail; and graph data\nelucidates relationships within the item-behavior heterogeneous graphs. Our\nproposed model called Triple Modality Fusion (TMF) utilizes the power of LLMs\nto align and integrate these three modalities, achieving a comprehensive\nrepresentation of user behaviors. The LLM models the user's interactions\nincluding behaviors and item features in natural languages. Initially, the LLM\nis warmed up using only natural language-based prompts. We then devise the\nmodality fusion module based on cross-attention and self-attention mechanisms\nto integrate different modalities from other models into the same embedding\nspace and incorporate them into an LLM. Extensive experiments demonstrate the\neffectiveness of our approach in improving recommendation accuracy. Further\nablation studies validate the effectiveness of our model design and benefits of\nthe TMF.",
      "tldr_zh": "本论文提出了一种名为 Triple Modality Fusion (TMF) 的框架，用于多行为推荐系统，通过 Large Language Models (LLMs) 对齐和融合视觉、文本以及图数据三种模态。视觉数据捕捉物品的上下文和美学特征，文本数据提供用户兴趣和物品特征的详细洞见，而图数据阐明物品-行为异构图中的关系；框架采用基于 cross-attention 和 self-attention 机制的模态融合模块，将这些模态整合到相同的嵌入空间，并通过自然语言提示预热 LLM 以建模用户互动。实验结果显示，该方法显著提高了推荐准确性，消融研究进一步验证了 TMF 设计的有效性和益处。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12228v2",
      "published_date": "2024-10-16 04:44:15 UTC",
      "updated_date": "2025-02-16 09:41:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:33:10.102671"
    },
    {
      "arxiv_id": "2410.12222v3",
      "title": "On A Scale From 1 to 5: Quantifying Hallucination in Faithfulness Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaonan Jing",
        "Srinivas Billa",
        "Danny Godbout"
      ],
      "abstract": "Hallucination has been a popular topic in natural language generation (NLG).\nIn real-world applications, unfaithful content can result in poor data quality\nor loss of trust from end users. Thus, it is crucial to fact-check before\nadopting NLG for production usage, which can be expensive if done manually. In\nthis paper, we investigate automated faithfulness evaluation in guided NLG. We\ndeveloped a rubric template and used large language models (LLMs) to score the\ngeneration on quantifiable scales. We compared popular LLMs as well as widely\nadopted natural language inference (NLI) models in scoring quality and\nsensitivity. In addition, we developed methods for the generation of synthetic\nunfaithful data, as well as heuristics to quantify the percentage of\nhallucination. Our results on 4 travel-domain industry dataset show that GPT-4\ncan provide accurate judgement and explanation of whether a source and a\ngeneration are factually consistent. Furthermore, we found that tuning NLI\nmodels on synthetic data can improve performance. Lastly, we present insights\non the latency and cost of deploying such a system.",
      "tldr_zh": "该论文探讨了自然语言生成 (NLG) 中的幻觉 (hallucination) 问题及其对生成忠诚度 (faithfulness) 的影响，强调了自动化事实检查的重要性，以避免手动评估的成本高昂。研究者开发了一个量化评分模板，使用大语言模型 (LLMs) 和自然语言推理 (NLI) 模型在 1 到 5 的规模上评估生成内容的真实性，并比较了这些模型在评分质量和敏感性方面的表现。同时，他们设计了生成合成不忠诚数据的方法和量化幻觉百分比的启发式策略。在 4 个旅行领域数据集上的实验显示，GPT-4 能准确判断并解释来源与生成的真实一致性，而微调 NLI 模型可显著提升性能，并提供了系统部署的延迟和成本见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NAACL 2025 Findings. 16 pages, 10 tables, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.12222v3",
      "published_date": "2024-10-16 04:36:17 UTC",
      "updated_date": "2025-02-08 09:35:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:33:22.492117"
    },
    {
      "arxiv_id": "2410.12221v1",
      "title": "EdgeRL: Reinforcement Learning-driven Deep Learning Model Inference Optimization at Edge",
      "title_zh": "翻译失败",
      "authors": [
        "Motahare Mounesan",
        "Xiaojie Zhang",
        "Saptarshi Debroy"
      ],
      "abstract": "Balancing mutually diverging performance metrics, such as, processing\nlatency, outcome accuracy, and end device energy consumption is a challenging\nundertaking for deep learning model inference in ad-hoc edge environments. In\nthis paper, we propose EdgeRL framework that seeks to strike such balance by\nusing an Advantage Actor-Critic (A2C) Reinforcement Learning (RL) approach that\ncan choose optimal run-time DNN inference parameters and aligns the performance\nmetrics based on the application requirements. Using real world deep learning\nmodel and a hardware testbed, we evaluate the benefits of EdgeRL framework in\nterms of end device energy savings, inference accuracy improvement, and\nend-to-end inference latency reduction.",
      "tldr_zh": "该研究提出EdgeRL框架，利用Advantage Actor-Critic (A2C) 强化学习(Reinforcement Learning)方法优化边缘环境下的深度学习(DNN)模型推理。EdgeRL通过动态选择最优运行时参数，根据应用需求平衡处理延迟、结果准确性和设备能耗等指标。实验基于真实深度学习模型和硬件测试床，展示了框架在端设备能耗节省、推理准确性提升以及端到端推理延迟减少方面的显著益处。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12221v1",
      "published_date": "2024-10-16 04:31:39 UTC",
      "updated_date": "2024-10-16 04:31:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:33:33.898073"
    },
    {
      "arxiv_id": "2410.12219v1",
      "title": "OmnixR: Evaluating Omni-modality Language Models on Reasoning across Modalities",
      "title_zh": "翻译失败",
      "authors": [
        "Lichang Chen",
        "Hexiang Hu",
        "Mingda Zhang",
        "Yiwen Chen",
        "Zifeng Wang",
        "Yandong Li",
        "Pranav Shyam",
        "Tianyi Zhou",
        "Heng Huang",
        "Ming-Hsuan Yang",
        "Boqing Gong"
      ],
      "abstract": "We introduce OmnixR, an evaluation suite designed to benchmark SoTA\nOmni-modality Language Models, such as GPT-4o and Gemini. Evaluating OLMs,\nwhich integrate multiple modalities such as text, vision, and audio, presents\nunique challenges. Particularly, the user message might often consist of\nmultiple modalities, such that OLMs have to establish holistic understanding\nand reasoning across modalities to accomplish the task. Existing benchmarks are\nlimited to single modality or dual-modality tasks, overlooking comprehensive\nmulti-modal assessments of model reasoning. To address this, OmnixR offers two\nevaluation variants: (1)synthetic subset: a synthetic dataset generated\nautomatically by translating text into multiple modalities--audio, images,\nvideo, and hybrids (Omnify). (2)realistic subset: a real-world dataset,\nmanually curated and annotated by experts, for evaluating cross-modal reasoning\nin natural settings. OmnixR presents a unique evaluation towards assessing OLMs\nover a diverse mix of modalities, such as a question that involves video,\naudio, and text, providing a rigorous cross-modal reasoning testbed unlike any\nexisting benchmarks. Our experiments find that all state-of-the-art OLMs\nstruggle with OmnixR questions that require integrating information from\nmultiple modalities to answer. Further analysis highlights differences in\nreasoning behavior, underscoring the challenges of omni-modal AI alignment.",
      "tldr_zh": "这篇论文介绍了 OmnixR，一个用于评估 Omni-modality Language Models (如 GPT-4o 和 Gemini) 的基准测试套件，专注于测试模型在文本、视觉和音频等多个模态间的跨模态推理能力。OmnixR 包括两个子集：合成子集（通过 Omnify 工具将文本自动转化为音频、图像、视频和混合模态的数据集）和真实子集（由专家手动整理的真实世界数据集），以全面评估模型在复杂多模态任务中的表现。实验发现，所有 SoTA OLMs 在需要整合多种模态信息的问题上挣扎，进一步分析揭示了 omni-modal AI alignment 的挑战和模型推理行为的差异。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.MM"
      ],
      "primary_category": "cs.AI",
      "comment": "19 pages, 6 figures, 12 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.12219v1",
      "published_date": "2024-10-16 04:29:46 UTC",
      "updated_date": "2024-10-16 04:29:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:33:47.658490"
    },
    {
      "arxiv_id": "2410.12214v3",
      "title": "Order-aware Interactive Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Bin Wang",
        "Anwesa Choudhuri",
        "Meng Zheng",
        "Zhongpai Gao",
        "Benjamin Planche",
        "Andong Deng",
        "Qin Liu",
        "Terrence Chen",
        "Ulas Bagci",
        "Ziyan Wu"
      ],
      "abstract": "Interactive segmentation aims to accurately segment target objects with\nminimal user interactions. However, current methods often fail to accurately\nseparate target objects from the background, due to a limited understanding of\norder, the relative depth between objects in a scene. To address this issue, we\npropose OIS: order-aware interactive segmentation, where we explicitly encode\nthe relative depth between objects into order maps. We introduce a novel\norder-aware attention, where the order maps seamlessly guide the user\ninteractions (in the form of clicks) to attend to the image features. We\nfurther present an object-aware attention module to incorporate a strong\nobject-level understanding to better differentiate objects with similar order.\nOur approach allows both dense and sparse integration of user clicks, enhancing\nboth accuracy and efficiency as compared to prior works. Experimental results\ndemonstrate that OIS achieves state-of-the-art performance, improving mIoU\nafter one click by 7.61 on the HQSeg44K dataset and 1.32 on the DAVIS dataset\nas compared to the previous state-of-the-art SegNext, while also doubling\ninference speed compared to current leading methods. The project page is\nhttps://ukaukaaaa.github.io/projects/OIS/index.html",
      "tldr_zh": "该论文提出OIS（Order-aware Interactive Segmentation）方法，以解决交互式分割中对对象相对深度（order）的理解不足，导致目标对象与背景分离不准确的问题。OIS通过显式编码order maps来引导用户点击，并引入order-aware attention和object-aware attention模块，实现对图像特征的精确关注和相似对象的有效区分，支持密集或稀疏的用户交互。实验结果显示，OIS在HQSeg44K数据集上将mIoU提高了7.61，在DAVIS数据集上提高了1.32，与SegNext相比，同时推理速度是当前领先方法的双倍。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ICLR 2025 Interactive demo can be found in project page:\n  https://ukaukaaaa.github.io/projects/OIS/index.html",
      "pdf_url": "http://arxiv.org/pdf/2410.12214v3",
      "published_date": "2024-10-16 04:19:28 UTC",
      "updated_date": "2025-02-06 22:16:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:33:57.955076"
    },
    {
      "arxiv_id": "2410.12207v2",
      "title": "Divide-Verify-Refine: Can LLMs Self-Align with Complex Instructions?",
      "title_zh": "翻译失败",
      "authors": [
        "Xianren Zhang",
        "Xianfeng Tang",
        "Hui Liu",
        "Zongyu Wu",
        "Qi He",
        "Dongwon Lee",
        "Suhang Wang"
      ],
      "abstract": "Recent studies show LLMs struggle with complex instructions involving\nmultiple constraints (e.g., length, format, sentiment). Existing works address\nthis issue by fine-tuning, which heavily relies on fine-tuning data quality and\nis computational expensive. An alternative is leveraging LLMs' self-correction\nto refine responses for better constraint adherence. However, this is limited\nby the feedback quality, as LLMs cannot generate reliable feedback or detect\nerrors. Moreover, its effectiveness relies on few-shot examples illustrating\nresponse modifications. As constraints in complex instructions are diverse,\nmanually crafting such examples for each constraint type can be labor-intensive\nand sub-optimal. To address these two challenges, we propose the\nDivide-Verify-Refine (DVR) framework with three steps: (1) Divide complex\ninstructions into single constraints and prepare appropriate tools; (2) Verify\nresponses using tools that provide rigorous check and textual guidance (e.g.,\nPython toolkit for format checks or pre-trained classifiers for content\nanalysis); (3) Refine: To maximize refinement effectiveness, we propose dynamic\nfew-shot prompting, where a refinement repository collects successful\nrefinements, and these examples are selectively retrieved for future\nrefinements. Recognizing the lack of complexity in existing datasets, we create\na new dataset of complex instructions. DVR doubles Llama3.1-8B's constraint\nadherence and triples Mistral-7B's performance.",
      "tldr_zh": "本研究探讨了大语言模型(LLMs)在处理涉及多个约束（如长度、格式、情感）的复杂指令时的挑战，现有方法依赖微调或自校正但效率低下。论文提出Divide-Verify-Refine (DVR)框架，包括三个步骤：(1) Divide：将复杂指令分解为单个约束并准备工具；(2) Verify：使用工具（如Python工具包或预训练分类器）进行严格检查和指导；(3) Refine：采用动态few-shot prompting，通过一个精炼仓库收集并检索成功示例以优化响应。作者创建了一个新的复杂指令数据集，用于评估DVR框架，结果显示该框架使Llama3.1-8B的约束遵守率翻倍，并将Mistral-7B的性能提高三倍。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2410.12207v2",
      "published_date": "2024-10-16 04:01:55 UTC",
      "updated_date": "2025-02-27 22:16:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:34:11.939280"
    },
    {
      "arxiv_id": "2410.12206v1",
      "title": "Abnormality Forecasting: Time Series Anomaly Prediction via Future Context Modeling",
      "title_zh": "异常预测：通过未来上下文建模的时间序列异常预测",
      "authors": [
        "Sinong Zhao",
        "Wenrui Wang",
        "Hongzuo Xu",
        "Zhaoyang Yu",
        "Qingsong Wen",
        "Gang Wang",
        "xiaoguang Liu",
        "Guansong Pang"
      ],
      "abstract": "Identifying anomalies from time series data plays an important role in\nvarious fields such as infrastructure security, intelligent operation and\nmaintenance, and space exploration. Current research focuses on detecting the\nanomalies after they occur, which can lead to significant financial/reputation\nloss or infrastructure damage. In this work we instead study a more practical\nyet very challenging problem, time series anomaly prediction, aiming at\nproviding early warnings for abnormal events before their occurrence. To tackle\nthis problem, we introduce a novel principled approach, namely future context\nmodeling (FCM). Its key insight is that the future abnormal events in a target\nwindow can be accurately predicted if their preceding observation window\nexhibits any subtle difference to normal data. To effectively capture such\ndifferences, FCM first leverages long-term forecasting models to generate a\ndiscriminative future context based on the observation data, aiming to amplify\nthose subtle but unusual difference. It then models a normality correlation of\nthe observation data with the forecasting future context to complement the\nnormality modeling of the observation data in foreseeing possible abnormality\nin the target window. A joint variate-time attention learning is also\nintroduced in FCM to leverage both temporal signals and features of the time\nseries data for more discriminative normality modeling in the aforementioned\ntwo views. Comprehensive experiments on five datasets demonstrate that FCM\ngains good recall rate (70\\%+) on multiple datasets and significantly\noutperforms all baselines in F1 score. Code is available at\nhttps://github.com/mala-lab/FCM.",
      "tldr_zh": "本文研究了时间序列异常预测问题，旨在通过提前建模未来上下文来提供异常事件预警，从而避免传统事后检测带来的损失。提出了一种新方法Future Context Modeling (FCM)，它利用长期预测模型生成判别性未来上下文，放大观察数据中的细微差异，并结合正常性相关性建模和联合变量-时间注意力学习，以更精确地预测目标窗口的异常。实验在五个数据集上证明，FCM 实现了70%+的召回率，并在F1分数上显著优于基线模型，代码已开源。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 5 figures, submitted to KDD conference",
      "pdf_url": "http://arxiv.org/pdf/2410.12206v1",
      "published_date": "2024-10-16 04:00:00 UTC",
      "updated_date": "2024-10-16 04:00:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:34:21.744854"
    },
    {
      "arxiv_id": "2410.12195v1",
      "title": "Sparse Prototype Network for Explainable Pedestrian Behavior Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Yan Feng",
        "Alexander Carballo",
        "Kazuya Takeda"
      ],
      "abstract": "Predicting pedestrian behavior is challenging yet crucial for applications\nsuch as autonomous driving and smart city. Recent deep learning models have\nachieved remarkable performance in making accurate predictions, but they fail\nto provide explanations of their inner workings. One reason for this problem is\nthe multi-modal inputs. To bridge this gap, we present Sparse Prototype Network\n(SPN), an explainable method designed to simultaneously predict a pedestrian's\nfuture action, trajectory, and pose. SPN leverages an intermediate prototype\nbottleneck layer to provide sample-based explanations for its predictions. The\nprototypes are modality-independent, meaning that they can correspond to any\nmodality from the input. Therefore, SPN can extend to arbitrary combinations of\nmodalities. Regularized by mono-semanticity and clustering constraints, the\nprototypes learn consistent and human-understandable features and achieve\nstate-of-the-art performance on action, trajectory and pose prediction on TITAN\nand PIE. Finally, we propose a metric named Top-K Mono-semanticity Scale to\nquantitatively evaluate the explainability. Qualitative results show the\npositive correlation between sparsity and explainability. Code available at\nhttps://github.com/Equinoxxxxx/SPN.",
      "tldr_zh": "本研究针对行人行为预测中的可解释性问题，提出 Sparse Prototype Network (SPN)，一个可扩展的模型，能同时预测行人的未来动作、轨迹和姿势，同时通过中间原型瓶颈层提供基于样本的解释。\nSPN 的原型是模态独立的，可适用于任意输入模态组合，并通过 mono-semanticity 和聚类约束进行正则化，以学习一致且易懂的特征。\n实验结果显示，SPN 在 TITAN 和 PIE 数据集上实现了最先进的表现，并在动作、轨迹和姿势预测上表现出色；此外，研究还引入 Top-K Mono-semanticity Scale 指标量化可解释性，并证明稀疏性与解释性正相关。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12195v1",
      "published_date": "2024-10-16 03:33:40 UTC",
      "updated_date": "2024-10-16 03:33:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:34:35.831934"
    },
    {
      "arxiv_id": "2410.12193v1",
      "title": "Trajectory Manifold Optimization for Fast and Adaptive Kinodynamic Motion Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Yonghyeon Lee"
      ],
      "abstract": "Fast kinodynamic motion planning is crucial for systems to effectively adapt\nto dynamically changing environments. Despite some efforts, existing approaches\nstill struggle with rapid planning in high-dimensional, complex problems. Not\nsurprisingly, the primary challenge arises from the high-dimensionality of the\nsearch space, specifically the trajectory space. We address this issue with a\ntwo-step method: initially, we identify a lower-dimensional trajectory manifold\n{\\it offline}, comprising diverse trajectories specifically relevant to the\ntask at hand while meeting kinodynamic constraints. Subsequently, we search for\nsolutions within this manifold {\\it online}, significantly enhancing the\nplanning speed. To encode and generate a manifold of continuous-time,\ndifferentiable trajectories, we propose a novel neural network model, {\\it\nDifferentiable Motion Manifold Primitives (DMMP)}, along with a practical\ntraining strategy. Experiments with a 7-DoF robot arm tasked with dynamic\nthrowing to arbitrary target positions demonstrate that our method surpasses\nexisting approaches in planning speed, task success, and constraint\nsatisfaction.",
      "tldr_zh": "该研究针对高维复杂环境中的快速kinodynamic运动规划问题，提出了一种两步优化方法：首先离线识别一个低维trajectory manifold，以包含任务相关且满足动力学约束的多样轨迹；随后在线在该流形中搜索解决方案。论文引入了新模型Differentiable Motion Manifold Primitives (DMMP)，用于编码和生成连续时间可微轨迹，从而显著提升规划效率。实验在7-DoF机器人臂的动态投掷任务中证明，该方法在规划速度、任务成功率和约束满足方面均超越现有方法。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "12 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.12193v1",
      "published_date": "2024-10-16 03:29:33 UTC",
      "updated_date": "2024-10-16 03:29:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:34:46.808905"
    },
    {
      "arxiv_id": "2410.12189v3",
      "title": "DocETL: Agentic Query Rewriting and Evaluation for Complex Document Processing",
      "title_zh": "翻译失败",
      "authors": [
        "Shreya Shankar",
        "Tristan Chambers",
        "Tarak Shah",
        "Aditya G. Parameswaran",
        "Eugene Wu"
      ],
      "abstract": "Analyzing unstructured data has been a persistent challenge in data\nprocessing. Large Language Models (LLMs) have shown promise in this regard,\nleading to recent proposals for declarative frameworks for LLM-powered\nprocessing of unstructured data. However, these frameworks focus on reducing\ncost when executing user-specified operations using LLMs, rather than improving\naccuracy, executing most operations as-is (in a single LLM call). This is\nproblematic for complex tasks and data, where LLM outputs for user-defined\noperations are often inaccurate, even with optimized prompts. For example, an\nLLM may struggle to identify {\\em all} instances of specific clauses, like\nforce majeure or indemnification, in lengthy legal documents, requiring\ndecomposition of the data, the task, or both.\n  We present DocETL, a system that optimizes complex document processing\npipelines, while accounting for LLM shortcomings. DocETL offers a declarative\ninterface for users to define such pipelines and uses an agent-based approach\nto automatically optimize them, leveraging novel agent-based rewrites (that we\ncall rewrite directives), as well as an optimization and evaluation framework.\nWe introduce (i) logical rewriting of pipelines, tailored for LLM-based tasks,\n(ii) an agent-guided plan evaluation mechanism that synthesizes and\norchestrates task-specific validation prompts, and (iii) an optimization\nalgorithm that efficiently finds promising plans, considering the latencies of\nagent-based plan generation and evaluation. Our evaluation on four different\nunstructured document analysis tasks demonstrates that DocETL finds plans with\noutputs that are 25 to 80% more accurate than well-engineered baselines,\naddressing a critical gap in unstructured data analysis. DocETL is open-source\nat docetl.org, and as of March 2025, has amassed over 1.7k GitHub Stars, with\nusers spanning a variety of domains.",
      "tldr_zh": "该研究提出DocETL系统，用于优化复杂文档处理的查询重写和评估，针对Large Language Models (LLMs)在处理非结构化数据时的准确性不足问题。DocETL提供声明式接口，让用户定义处理管道，并采用代理-based方法，包括逻辑重写管道、代理-guided计划评估（如合成任务特定验证提示）和高效优化算法，以自动生成更精确的处理计划。实验结果显示，DocETL在四个非结构化文档分析任务上，比基线方案的输出准确率提高了25%至80%，并已开源并获得广泛应用。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "22 pages, 6 figures, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.12189v3",
      "published_date": "2024-10-16 03:22:35 UTC",
      "updated_date": "2025-04-01 19:47:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:34:59.145292"
    },
    {
      "arxiv_id": "2410.12187v2",
      "title": "DAQ: Density-Aware Post-Training Weight-Only Quantization For LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Yingsong Luo",
        "Ling Chen"
      ],
      "abstract": "Large language models (LLMs) excel in various tasks but face deployment\nchallenges due to hardware constraints. We propose density-aware post-training\nweight-only quantization (DAQ), which has two stages: 1) density-centric\nalignment, which identifies the center of high-density weights and centers the\ndynamic range on this point to align high-density weight regions with\nfloating-point high-precision regions; 2) learnable dynamic range adjustment,\nwhich adjusts the dynamic range by optimizing quantization parameters (i.e.,\nscale and zero-point) based on the impact of weights on the model output.\nExperiments on LLaMA and LLaMA-2 show that DAQ consistently outperforms the\nbest baseline method, reducing perplexity loss by an average of 22.8% on LLaMA\nand 19.6% on LLaMA-2. Our code is available at\nhttps://github.com/LuoYingSong/DAQ.",
      "tldr_zh": "本研究提出了一种密度感知的后训练权重量化方法（DAQ），旨在解决大型语言模型（LLMs）在硬件限制下的部署挑战。DAQ 包括两个阶段：密度中心对齐（density-centric alignment），通过识别高密度权重中心并调整动态范围以匹配浮点高精度区域；以及可学习动态范围调整（learnable dynamic range adjustment），通过优化量化参数（如 scale 和 zero-point）基于权重对模型输出的影响。实验结果显示，在 LLaMA 和 LLaMA-2 模型上，DAQ 比最佳基线方法平均减少了 22.8% 和 19.6% 的 perplexity loss，显著提升了模型性能。代码已开源于 https://github.com/LuoYingSong/DAQ。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.12187v2",
      "published_date": "2024-10-16 03:13:51 UTC",
      "updated_date": "2024-10-17 06:10:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:35:11.164041"
    },
    {
      "arxiv_id": "2410.12175v1",
      "title": "Reinforcement Learning with LTL and $ω$-Regular Objectives via Optimality-Preserving Translation to Average Rewards",
      "title_zh": "翻译失败",
      "authors": [
        "Xuan-Bach Le",
        "Dominik Wagner",
        "Leon Witzman",
        "Alexander Rabinovich",
        "Luke Ong"
      ],
      "abstract": "Linear temporal logic (LTL) and, more generally, $\\omega$-regular objectives\nare alternatives to the traditional discount sum and average reward objectives\nin reinforcement learning (RL), offering the advantage of greater\ncomprehensibility and hence explainability. In this work, we study the\nrelationship between these objectives. Our main result is that each RL problem\nfor $\\omega$-regular objectives can be reduced to a limit-average reward\nproblem in an optimality-preserving fashion, via (finite-memory) reward\nmachines. Furthermore, we demonstrate the efficacy of this approach by showing\nthat optimal policies for limit-average problems can be found asymptotically by\nsolving a sequence of discount-sum problems approximately. Consequently, we\nresolve an open problem: optimal policies for LTL and $\\omega$-regular\nobjectives can be learned asymptotically.",
      "tldr_zh": "该研究探讨了在强化学习（RL）中使用 LTL（Linear Temporal Logic）和 ω-regular 目标的优势，这些目标比传统的折扣和或平均奖励目标更易于理解和解释。主要贡献是通过有限记忆的奖励机器（reward machines），将 ω-regular 目标的 RL 问题以保持最优性的方式转化为平均奖励问题，从而渐近地找到最优策略。该方法证明了可以通过解决一系列折扣和（discount-sum）问题来渐近学习 LTL 和 ω-regular 目标的最优策略，解决了这一领域的开放问题。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12175v1",
      "published_date": "2024-10-16 02:42:37 UTC",
      "updated_date": "2024-10-16 02:42:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:35:22.376654"
    },
    {
      "arxiv_id": "2410.21298v1",
      "title": "Explainable Artificial Intelligent (XAI) for Predicting Asphalt Concrete Stiffness and Rutting Resistance: Integrating Bailey's Aggregate Gradation Method",
      "title_zh": "翻译失败",
      "authors": [
        "Warat Kongkitkul",
        "Sompote Youwai",
        "Siwipa Khamsoy",
        "Manaswee Feungfung"
      ],
      "abstract": "This study employs explainable artificial intelligence (XAI) techniques to\nanalyze the behavior of asphalt concrete with varying aggregate gradations,\nfocusing on resilience modulus (MR) and dynamic stability (DS) as measured by\nwheel track tests. The research utilizes a deep learning model with a\nmulti-layer perceptron architecture to predict MR and DS based on aggregate\ngradation parameters derived from Bailey's Method, including coarse aggregate\nratio (CA), fine aggregate coarse ratio (FAc), and other mix design variables.\nThe model's performance was validated using k-fold cross-validation,\ndemonstrating superior accuracy compared to alternative machine learning\napproaches. SHAP (SHapley Additive exPlanations) values were applied to\ninterpret the model's predictions, providing insights into the relative\nimportance and impact of different gradation characteristics on asphalt\nconcrete performance. Key findings include the identification of critical\naggregate size thresholds, particularly the 0.6 mm sieve size, which\nsignificantly influences both MR and DS. The study revealed size-dependent\nperformance of aggregates, with coarse aggregates primarily affecting rutting\nresistance and medium-fine aggregates influencing stiffness. The research also\nhighlighted the importance of aggregate lithology in determining rutting\nresistance. To facilitate practical application, web-based interfaces were\ndeveloped for predicting MR and DS, incorporating explainable features to\nenhance transparency and interpretation of results. This research contributes a\ndata-driven approach to understanding the complex relationships between\naggregate gradation and asphalt concrete performance, potentially informing\nmore efficient and performance-oriented mix design processes in the future.",
      "tldr_zh": "本研究利用可解释人工智能 (XAI) 技术，结合多层感知器深度学习模型和 Bailey's Aggregate Gradation Method 的参数（如粗骨料比率 (CA) 和细骨料粗比率 (FAc)），预测沥青混凝土的弹性模量 (MR) 和动态稳定性 (DS)。模型通过 k-fold 交叉验证验证，准确性优于其他机器学习方法，并采用 SHAP 值分析揭示骨料级配特征的重要性，例如 0.6 mm 筛孔大小对 MR 和 DS 的关键影响。研究发现，粗骨料主要影响抗车辙性，而中细骨料和骨料岩性则显著影响刚度。该工作开发了基于网络的预测接口，提供数据驱动的见解，以优化未来的沥青混凝土混合设计过程。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "The link to web app https://huggingface.co/spaces/Sompote/MRpredict\n  https://huggingface.co/spaces/Sompote/Dynamic.stability",
      "pdf_url": "http://arxiv.org/pdf/2410.21298v1",
      "published_date": "2024-10-16 02:39:55 UTC",
      "updated_date": "2024-10-16 02:39:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:35:36.291124"
    },
    {
      "arxiv_id": "2410.12172v2",
      "title": "The State of Robot Motion Generation",
      "title_zh": "机器人运动生成的现状",
      "authors": [
        "Kostas E. Bekris",
        "Joe Doerr",
        "Patrick Meng",
        "Sumanth Tangirala"
      ],
      "abstract": "This paper reviews the large spectrum of methods for generating robot motion\nproposed over the 50 years of robotics research culminating in recent\ndevelopments. It crosses the boundaries of methodologies, typically not\nsurveyed together, from those that operate over explicit models to those that\nlearn implicit ones. The paper discusses the current state-of-the-art as well\nas properties of varying methodologies, highlighting opportunities for\nintegration.",
      "tldr_zh": "这篇论文回顾了50年来机器人研究中提出的机器人运动生成(Robot Motion Generation)方法，涵盖从显式模型(Explicit Models)到隐式模型(Implicit Models)的广泛技术。论文分析了当前最先进的状态，以及这些方法的特性，如适用性和局限性。最终，它强调了不同方法之间整合的机会，以推动机器人领域的未来发展。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "I.2.9; I.2.8; I.2.6"
      ],
      "primary_category": "cs.RO",
      "comment": "Presented at the International Symposium of Robotics Research (ISRR),\n  2024. Website:\n  https://pracsys.cs.rutgers.edu/papers/the-state-of-robot-motion-generation/",
      "pdf_url": "http://arxiv.org/pdf/2410.12172v2",
      "published_date": "2024-10-16 02:31:31 UTC",
      "updated_date": "2024-12-16 18:25:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:35:46.080984"
    },
    {
      "arxiv_id": "2410.12166v1",
      "title": "Reclaiming the Source of Programmatic Policies: Programmatic versus Latent Spaces",
      "title_zh": "翻译失败",
      "authors": [
        "Tales H. Carvalho",
        "Kenneth Tjhia",
        "Levi H. S. Lelis"
      ],
      "abstract": "Recent works have introduced LEAPS and HPRL, systems that learn latent spaces\nof domain-specific languages, which are used to define programmatic policies\nfor partially observable Markov decision processes (POMDPs). These systems\ninduce a latent space while optimizing losses such as the behavior loss, which\naim to achieve locality in program behavior, meaning that vectors close in the\nlatent space should correspond to similarly behaving programs. In this paper,\nwe show that the programmatic space, induced by the domain-specific language\nand requiring no training, presents values for the behavior loss similar to\nthose observed in latent spaces presented in previous work. Moreover,\nalgorithms searching in the programmatic space significantly outperform those\nin LEAPS and HPRL. To explain our results, we measured the \"friendliness\" of\nthe two spaces to local search algorithms. We discovered that algorithms are\nmore likely to stop at local maxima when searching in the latent space than\nwhen searching in the programmatic space. This implies that the optimization\ntopology of the programmatic space, induced by the reward function in\nconjunction with the neighborhood function, is more conducive to search than\nthat of the latent space. This result provides an explanation for the superior\nperformance in the programmatic space.",
      "tldr_zh": "本文比较了程序化空间和潜在空间在定义部分可观测马尔可夫决策过程 (POMDPs) 程序化策略中的性能，发现程序化空间无需训练即可实现与潜在空间相似的行为损失值。研究结果显示，在程序化空间中进行搜索的算法显著优于 LEAPS 和 HPRL 系统。作者通过测量两种空间对局部搜索算法的“友好度”，揭示程序化空间的优化拓扑更易避免局部最大值，从而解释了其优越性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published as a conference paper at ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.12166v1",
      "published_date": "2024-10-16 02:10:04 UTC",
      "updated_date": "2024-10-16 02:10:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:35:58.519471"
    },
    {
      "arxiv_id": "2410.12165v2",
      "title": "Dual-Model Distillation for Efficient Action Classification with Hybrid Edge-Cloud Solution",
      "title_zh": "翻译失败",
      "authors": [
        "Timothy Wei",
        "Hsien Xin Peng",
        "Elaine Xu",
        "Bryan Zhao",
        "Lei Ding",
        "Diji Yang"
      ],
      "abstract": "As Artificial Intelligence models, such as Large Video-Language models\n(VLMs), grow in size, their deployment in real-world applications becomes\nincreasingly challenging due to hardware limitations and computational costs.\nTo address this, we design a hybrid edge-cloud solution that leverages the\nefficiency of smaller models for local processing while deferring to larger,\nmore accurate cloud-based models when necessary. Specifically, we propose a\nnovel unsupervised data generation method, Dual-Model Distillation (DMD), to\ntrain a lightweight switcher model that can predict when the edge model's\noutput is uncertain and selectively offload inference to the large model in the\ncloud. Experimental results on the action classification task show that our\nframework not only requires less computational overhead, but also improves\naccuracy compared to using a large model alone. Our framework provides a\nscalable and adaptable solution for action classification in\nresource-constrained environments, with potential applications beyond\nhealthcare. Noteworthy, while DMD-generated data is used for optimizing\nperformance and resource usage in our pipeline, we expect the concept of DMD to\nfurther support future research on knowledge alignment across multiple models.",
      "tldr_zh": "本研究针对大型 AI 模型如 Large Video-Language models (VLMs) 在部署中的硬件和计算成本挑战，提出了一种混合 edge-cloud 解决方案，以实现高效的动作分类。核心方法是 Dual-Model Distillation (DMD)，一种无监督数据生成技术，用于训练轻量级 switcher 模型，预测 edge 模型的不确定性并选择性地将推理任务卸载到云端大模型。实验结果显示，该框架在动作分类任务上比单独使用大模型减少了计算开销并提高了准确率。该解决方案适用于资源受限环境，并有望扩展到其他领域，支持未来多模型知识对齐研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12165v2",
      "published_date": "2024-10-16 02:06:27 UTC",
      "updated_date": "2024-10-20 17:59:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:36:11.264063"
    },
    {
      "arxiv_id": "2410.12159v3",
      "title": "NSSI-Net: A Multi-Concept GAN for Non-Suicidal Self-Injury Detection Using High-Dimensional EEG in a Semi-Supervised Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Zhen Liang",
        "Weishan Ye",
        "Qile Liu",
        "Li Zhang",
        "Gan Huang",
        "Yongjie Zhou"
      ],
      "abstract": "Non-suicidal self-injury (NSSI) is a serious threat to the physical and\nmental health of adolescents, significantly increasing the risk of suicide and\nattracting widespread public concern. Electroencephalography (EEG), as an\nobjective tool for identifying brain disorders, holds great promise. However,\nextracting meaningful and reliable features from high-dimensional EEG data,\nespecially by integrating spatiotemporal brain dynamics into informative\nrepresentations, remains a major challenge. In this study, we introduce an\nadvanced semi-supervised adversarial network, NSSI-Net, to effectively model\nEEG features related to NSSI. NSSI-Net consists of two key modules: a\nspatial-temporal feature extraction module and a multi-concept discriminator.\nIn the spatial-temporal feature extraction module, an integrated 2D\nconvolutional neural network (2D-CNN) and a bi-directional Gated Recurrent Unit\n(BiGRU) are used to capture both spatial and temporal dynamics in EEG data. In\nthe multi-concept discriminator, signal, gender, domain, and disease levels are\nfully explored to extract meaningful EEG features, considering individual,\ndemographic, disease variations across a diverse population. Based on\nself-collected NSSI data (n=114), the model's effectiveness and reliability are\ndemonstrated, with a 5.44% improvement in performance compared to existing\nmachine learning and deep learning methods. This study advances the\nunderstanding and early diagnosis of NSSI in adolescents with depression,\nenabling timely intervention. The source code is available at\nhttps://github.com/Vesan-yws/NSSINet.",
      "tldr_zh": "该研究提出 NSSI-Net，一种基于 GAN 的半监督框架，用于检测非自杀性自伤 (NSSI) 通过处理高维 EEG 数据。模型包括空间-时间特征提取模块（结合 2D-CNN 和 BiGRU 来捕捉 EEG 的空间和时间动态）和多概念判别器（探索信号、性别、领域及疾病水平以提取有意义的特征，考虑个体及人口变异）。基于自收集的 NSSI 数据集 (n=114)，NSSI-Net 比现有机器学习和深度学习方法性能提升 5.44%，有助于推进青少年抑郁症中 NSSI 的理解和早期诊断，实现及时干预。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12159v3",
      "published_date": "2024-10-16 01:39:04 UTC",
      "updated_date": "2025-04-03 07:50:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:36:22.471700"
    },
    {
      "arxiv_id": "2410.12156v1",
      "title": "FragNet: A Graph Neural Network for Molecular Property Prediction with Four Layers of Interpretability",
      "title_zh": "翻译失败",
      "authors": [
        "Gihan Panapitiya",
        "Peiyuan Gao",
        "C Mark Maupin",
        "Emily G Saldanha"
      ],
      "abstract": "Molecular property prediction is a crucial step in many modern-day scientific\napplications including drug discovery and energy storage material design.\nDespite the availability of numerous machine learning models for this task, we\nare lacking in models that provide both high accuracies and interpretability of\nthe predictions. We introduce the FragNet architecture, a graph neural network\nnot only capable of achieving prediction accuracies comparable to the current\nstate-of-the-art models, but also able to provide insight on four levels of\nmolecular substructures. This model enables understanding of which atoms,\nbonds, molecular fragments, and molecular fragment connections are critical in\nthe prediction of a given molecular property. The ability to interpret the\nimportance of connections between fragments is of particular interest for\nmolecules which have substructures that are not connected with regular covalent\nbonds. The interpretable capabilities of FragNet are key to gaining scientific\ninsights from the model's learned patterns between molecular structure and\nmolecular properties.",
      "tldr_zh": "本文提出FragNet，一种图神经网络(Graph Neural Network)，用于分子属性预测，能够实现与最先进模型相当的准确性，同时提供四层可解释性，包括原子、键、分子片段以及片段连接的重要性。相比现有模型，FragNet填补了高准确性和可解释性之间的空白，尤其适用于分析非共价键连接的分子子结构。最终，该框架有助于从分子结构与属性模式中获得科学洞察，支持药物发现和能源存储材料设计等领域。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.chem-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12156v1",
      "published_date": "2024-10-16 01:37:01 UTC",
      "updated_date": "2024-10-16 01:37:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:36:34.639799"
    },
    {
      "arxiv_id": "2410.12154v1",
      "title": "Exploiting LLMs' Reasoning Capability to Infer Implicit Concepts in Legal Information Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Hai-Long Nguyen",
        "Tan-Minh Nguyen",
        "Duc-Minh Nguyen",
        "Thi-Hai-Yen Vuong",
        "Ha-Thanh Nguyen",
        "Xuan-Hieu Phan"
      ],
      "abstract": "Statutory law retrieval is a typical problem in legal language processing,\nthat has various practical applications in law engineering. Modern deep\nlearning-based retrieval methods have achieved significant results for this\nproblem. However, retrieval systems relying on semantic and lexical\ncorrelations often exhibit limitations, particularly when handling queries that\ninvolve real-life scenarios, or use the vocabulary that is not specific to the\nlegal domain. In this work, we focus on overcoming this weaknesses by utilizing\nthe logical reasoning capabilities of large language models (LLMs) to identify\nrelevant legal terms and facts related to the situation mentioned in the query.\nThe proposed retrieval system integrates additional information from the\nterm--based expansion and query reformulation to improve the retrieval\naccuracy. The experiments on COLIEE 2022 and COLIEE 2023 datasets show that\nextra knowledge from LLMs helps to improve the retrieval result of both lexical\nand semantic ranking models. The final ensemble retrieval system outperformed\nthe highest results among all participating teams in the COLIEE 2022 and 2023\ncompetitions.",
      "tldr_zh": "本研究针对法定法检索（statutory law retrieval）中的局限性，即现有基于语义和词汇相关性的深度学习方法在处理现实场景或非法律词汇查询时表现不佳。作者利用大型语言模型（LLMs）的逻辑推理能力来推断查询中隐含的法律术语和事实，并通过术语扩展（term-based expansion）和查询重述（query reformulation）整合额外信息，以提升检索准确性。在 COLIEE 2022 和 COLIEE 2023 数据集上的实验显示，该方法显著改善了词汇和语义排名模型的性能，最终的集成检索系统超过了所有参赛团队的最高成绩。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Presented at NeLaMKRR@KR, 2024 (arXiv:2410.05339)",
      "pdf_url": "http://arxiv.org/pdf/2410.12154v1",
      "published_date": "2024-10-16 01:34:14 UTC",
      "updated_date": "2024-10-16 01:34:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:36:45.824792"
    },
    {
      "arxiv_id": "2410.13901v1",
      "title": "SoK: Prompt Hacking of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Baha Rababah",
        "Shang",
        "Wu",
        "Matthew Kwiatkowski",
        "Carson Leung",
        "Cuneyt Gurcan Akcora"
      ],
      "abstract": "The safety and robustness of large language models (LLMs) based applications\nremain critical challenges in artificial intelligence. Among the key threats to\nthese applications are prompt hacking attacks, which can significantly\nundermine the security and reliability of LLM-based systems. In this work, we\noffer a comprehensive and systematic overview of three distinct types of prompt\nhacking: jailbreaking, leaking, and injection, addressing the nuances that\ndifferentiate them despite their overlapping characteristics. To enhance the\nevaluation of LLM-based applications, we propose a novel framework that\ncategorizes LLM responses into five distinct classes, moving beyond the\ntraditional binary classification. This approach provides more granular\ninsights into the AI's behavior, improving diagnostic precision and enabling\nmore targeted enhancements to the system's safety and robustness.",
      "tldr_zh": "这篇 SoK 论文系统地概述了大型语言模型 (LLMs) 应用中的提示黑客攻击 (prompt hacking)，包括 jailbreaking（越狱）、leaking（泄漏）和 injection（注入）三种类型，并分析了它们之间的细微差异。作者提出一个新框架，将 LLM 响应分类为五个类别，而不是传统的二元分类，从而提供更细粒度的行为洞见。实验表明，该框架提高了诊断精度，并有助于针对性地提升系统的安全性和鲁棒性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.ET"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13901v1",
      "published_date": "2024-10-16 01:30:41 UTC",
      "updated_date": "2024-10-16 01:30:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:36:58.799695"
    },
    {
      "arxiv_id": "2410.12153v1",
      "title": "Layer-of-Thoughts Prompting (LoT): Leveraging LLM-Based Retrieval with Constraint Hierarchies",
      "title_zh": "翻译失败",
      "authors": [
        "Wachara Fungwacharakorn",
        "Nguyen Ha Thanh",
        "May Myo Zin",
        "Ken Satoh"
      ],
      "abstract": "This paper presents a novel approach termed Layer-of-Thoughts Prompting\n(LoT), which utilizes constraint hierarchies to filter and refine candidate\nresponses to a given query. By integrating these constraints, our method\nenables a structured retrieval process that enhances explainability and\nautomation. Existing methods have explored various prompting techniques but\noften present overly generalized frameworks without delving into the nuances of\nprompts in multi-turn interactions. Our work addresses this gap by focusing on\nthe hierarchical relationships among prompts. We demonstrate that the efficacy\nof thought hierarchy plays a critical role in developing efficient and\ninterpretable retrieval algorithms. Leveraging Large Language Models (LLMs),\nLoT significantly improves the accuracy and comprehensibility of information\nretrieval tasks.",
      "tldr_zh": "这篇论文介绍了 Layer-of-Thoughts Prompting (LoT)，一种创新方法，通过利用 constraint hierarchies 来过滤和精炼查询的候选响应，实现结构化的检索过程。该方法强调了提示之间的层次关系（thought hierarchy），解决了现有提示技术在多轮交互中过于泛化的不足，从而提升了检索的可解释性和自动化。实验结果显示，借助 Large Language Models (LLMs)，LoT 显著提高了信息检索任务的准确性和可理解性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Presented at NeLaMKRR@KR, 2024 (arXiv:2410.05339)",
      "pdf_url": "http://arxiv.org/pdf/2410.12153v1",
      "published_date": "2024-10-16 01:20:44 UTC",
      "updated_date": "2024-10-16 01:20:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:37:10.159758"
    },
    {
      "arxiv_id": "2410.12148v1",
      "title": "Facing Identity: The Formation and Performance of Identity via Face-Based Artificial Intelligence Technologies",
      "title_zh": "翻译失败",
      "authors": [
        "Wells Lucas Santo"
      ],
      "abstract": "How is identity constructed and performed in the digital via face-based\nartificial intelligence technologies? While questions of identity on the\ntextual Internet have been thoroughly explored, the Internet has progressed to\na multimedia form that not only centers the visual, but specifically the face.\nAt the same time, a wealth of scholarship has and continues to center the\ntopics of surveillance and control through facial recognition technologies\n(FRTs), which have extended the logics of the racist pseudoscience of\nphysiognomy. Much less work has been devoted to understanding how such\nface-based artificial intelligence technologies have influenced the formation\nand performance of identity. This literature review considers how such\ntechnologies interact with faciality, which entails the construction of what a\nface may represent or signify, along axes of identity such as race, gender, and\nsexuality. In grappling with recent advances in AI such as image generation and\ndeepfakes, I propose that we are now in an era of \"post-facial\" technologies\nthat build off our existing culture of facility while eschewing the analog\nface, complicating our relationship with identity vis-a-vis the face. Drawing\nfrom previous frameworks of identity play in the digital, as well as trans\npractices that have historically played with or transgressed the boundaries of\nidentity classification, we can develop concepts adequate for analyzing digital\nfaciality and identity given the current landscape of post-facial artificial\nintelligence technologies that allow users to interface with the digital in an\nentirely novel manner. To ground this framework of transgression, I conclude by\nproposing an interview study with VTubers -- online streamers who perform using\nmotion-captured avatars instead of their real-life faces -- to gain qualitative\ninsight on how these sociotechnical experiences.",
      "tldr_zh": "这篇论文探讨了基于面部的 AI 技术如何影响数字身份的构建和表现，强调这些技术延续了种族主义伪科学 physiognomy 的逻辑，并通过 facial recognition technologies (FRTs) 强化了对种族、性别和性取向等轴线的 faciality 影响。作者提出，我们正处于“post-facial”技术的时代，这些技术基于现有文化但忽略了真实面部，复杂化了人与身份的关系，并借鉴数字身份游戏和跨性别实践的框架来发展分析数字 faciality 的新概念。为了验证这一框架，论文建议进行对 VTubers（使用动作捕捉头像的在线流媒体）的访谈研究，以获取定性洞见。总的来说，该研究为理解 AI 在数字环境中重塑身份提供了理论基础和实证路径。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12148v1",
      "published_date": "2024-10-16 01:14:04 UTC",
      "updated_date": "2024-10-16 01:14:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:37:22.786576"
    },
    {
      "arxiv_id": "2410.12136v1",
      "title": "Sample-Efficient Reinforcement Learning with Temporal Logic Objectives: Leveraging the Task Specification to Guide Exploration",
      "title_zh": "样本高效的强化学习，带有时序逻辑目标：利用任务规范来指导探索",
      "authors": [
        "Yiannis Kantaros",
        "Jun Wang"
      ],
      "abstract": "This paper addresses the problem of learning optimal control policies for\nsystems with uncertain dynamics and high-level control objectives specified as\nLinear Temporal Logic (LTL) formulas. Uncertainty is considered in the\nworkspace structure and the outcomes of control decisions giving rise to an\nunknown Markov Decision Process (MDP). Existing reinforcement learning (RL)\nalgorithms for LTL tasks typically rely on exploring a product MDP state-space\nuniformly (using e.g., an $\\epsilon$-greedy policy) compromising\nsample-efficiency. This issue becomes more pronounced as the rewards get\nsparser and the MDP size or the task complexity increase. In this paper, we\npropose an accelerated RL algorithm that can learn control policies\nsignificantly faster than competitive approaches. Its sample-efficiency relies\non a novel task-driven exploration strategy that biases exploration towards\ndirections that may contribute to task satisfaction. We provide theoretical\nanalysis and extensive comparative experiments demonstrating the\nsample-efficiency of the proposed method. The benefit of our method becomes\nmore evident as the task complexity or the MDP size increases.",
      "tldr_zh": "本文提出了一种样本效率更高的强化学习（RL）算法，用于处理不确定动态系统，其高级控制目标以线性时序逻辑（LTL）公式指定。该算法通过任务驱动探索策略，将探索偏向于可能有助于任务满足的方向，从而避免了传统方法（如ε-贪婪策略）在未知Markov决策过程（MDP）中的均匀探索问题。实验和理论分析显示，该方法显著加速了控制策略的学习，尤其在任务复杂性或MDP规模增加时，表现出比竞争方法更强的样本效率。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "arXiv admin note: text overlap with arXiv:2205.04424",
      "pdf_url": "http://arxiv.org/pdf/2410.12136v1",
      "published_date": "2024-10-16 00:53:41 UTC",
      "updated_date": "2024-10-16 00:53:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:37:34.413263"
    },
    {
      "arxiv_id": "2410.12130v1",
      "title": "Iter-AHMCL: Alleviate Hallucination for Large Language Model via Iterative Model-level Contrastive Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Huiwen Wu",
        "Xiaohan Li",
        "Xiaogang Xu",
        "Jiafei Wu",
        "Deyi Zhang",
        "Zhe Liu"
      ],
      "abstract": "The development of Large Language Models (LLMs) has significantly advanced\nvarious AI applications in commercial and scientific research fields, such as\nscientific literature summarization, writing assistance, and knowledge graph\nconstruction. However, a significant challenge is the high risk of\nhallucination during LLM inference, which can lead to security concerns like\nfactual inaccuracies, inconsistent information, and fabricated content. To\ntackle this issue, it is essential to develop effective methods for reducing\nhallucination while maintaining the original capabilities of the LLM. This\npaper introduces a novel approach called Iterative Model-level Contrastive\nLearning (Iter-AHMCL) to address hallucination. This method modifies the\nrepresentation layers of pre-trained LLMs by using contrastive `positive' and\n`negative' models, trained on data with and without hallucinations. By\nleveraging the differences between these two models, we create a more\nstraightforward pathway to eliminate hallucinations, and the iterative nature\nof contrastive learning further enhances performance. Experimental validation\non four pre-trained foundation LLMs (LLaMA2, Alpaca, LLaMA3, and Qwen)\nfinetuning with a specially designed dataset shows that our approach achieves\nan average improvement of 10.1 points on the TruthfulQA benchmark.\nComprehensive experiments demonstrate the effectiveness of Iter-AHMCL in\nreducing hallucination while maintaining the general capabilities of LLMs.",
      "tldr_zh": "本论文提出 Iter-AHMCL 方法，通过迭代模型级对比学习（Iterative Model-level Contrastive Learning）来缓解大语言模型（LLMs）的幻觉问题，该方法利用带有和不带幻觉的数据训练正负模型，并通过对比它们的差异修改模型表示层，以消除幻觉并提升性能。实验在 LLaMA2、Alpaca、LLaMA3 和 Qwen 等预训练模型上进行微调，使用专门设计的数据集，结果显示在 TruthfulQA 基准上平均提升 10.1 分。总体而言，Iter-AHMCL 有效减少了幻觉，同时保持了 LLMs 的原有能力，为模型可靠性提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12130v1",
      "published_date": "2024-10-16 00:15:40 UTC",
      "updated_date": "2024-10-16 00:15:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:37:46.944697"
    },
    {
      "arxiv_id": "2410.12126v2",
      "title": "What Do LLMs Need to Understand Graphs: A Survey of Parametric Representation of Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Dongqi Fu",
        "Liri Fang",
        "Zihao Li",
        "Hanghang Tong",
        "Vetle I. Torvik",
        "Jingrui He"
      ],
      "abstract": "Graphs, as a relational data structure, have been widely used for various\napplication scenarios, like molecule design and recommender systems. Recently,\nlarge language models (LLMs) are reorganizing in the AI community for their\nexpected reasoning and inference abilities. Making LLMs understand graph-based\nrelational data has great potential, including but not limited to (1)\ndistillate external knowledge base for eliminating hallucination and breaking\nthe context window limit for LLMs' inference during the retrieval augmentation\ngeneration process; (2) taking graph data as the input and directly solve the\ngraph-based research tasks like protein design and drug discovery. However,\ninputting the entire graph data to LLMs is not practical due to its complex\ntopological structure, data size, and the lack of effective and efficient\nsemantic graph representations. A natural question arises: Is there a kind of\ngraph representation that can be described by natural language for LLM's\nunderstanding and is also easy to require to serve as the raw input for LLMs?\nBased on statistical computation, graph laws pre-define a set of parameters\n(e.g., degree, time, diameter) and identifie their relationships and values by\nobserving the topological distribution of plenty of real-world graph data. We\nbelieve this kind of parametric representation of graphs, graph laws, can be a\nsolution for making LLMs understand graph data as the input. In this survey, we\nfirst review the previous study of graph laws from multiple perspectives, i.e.,\nmacroscope and microscope of graphs, low-order and high-order graphs, static\nand dynamic graphs, different observation spaces, and newly proposed graph\nparameters. After we review various real-world applications benefiting from the\nguidance of graph laws, we conclude the paper with current challenges and\nfuture research directions.",
      "tldr_zh": "这篇调查论文探讨了大型语言模型（LLMs）理解图数据（graphs）的关键问题，聚焦于参数化表示（parametric representation of graphs）。论文指出，直接输入图数据给 LLMs 面临拓扑结构复杂、数据规模大和语义表示不足的挑战，并提出图定律（graph laws）作为一种基于统计参数（如度、diameter）的自然语言描述方案，以提升 LLMs 的推理能力。作者从多个视角回顾了图定律的研究，包括宏观和微观、low-order 和 high-order、静态和动态 graphs，以及不同观察空间，并讨论了其在实际应用（如分子设计和推荐系统）中的益处。最后，论文总结了当前挑战，如高效表示的优化，以及未来研究方向，如更全面的图参数整合。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.SI"
      ],
      "primary_category": "cs.AI",
      "comment": "Preprint, 9 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.12126v2",
      "published_date": "2024-10-16 00:01:31 UTC",
      "updated_date": "2025-02-18 02:16:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:37:59.265443"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 156,
  "processed_papers_count": 156,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-20T12:38:23.088716"
}