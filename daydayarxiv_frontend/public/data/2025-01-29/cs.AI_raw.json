[
  {
    "arxiv_id": "2501.18059v1",
    "title": "Learning the Optimal Stopping for Early Classification within Finite Horizons via Sequential Probability Ratio Test",
    "authors": [
      "Akinori F. Ebihara",
      "Taiki Miyagawa",
      "Kazuyuki Sakurai",
      "Hitoshi Imaoka"
    ],
    "abstract": "Time-sensitive machine learning benefits from Sequential Probability Ratio\nTest (SPRT), which provides an optimal stopping time for early classification\nof time series. However, in finite horizon scenarios, where input lengths are\nfinite, determining the optimal stopping rule becomes computationally intensive\ndue to the need for backward induction, limiting practical applicability. We\nthus introduce FIRMBOUND, an SPRT-based framework that efficiently estimates\nthe solution to backward induction from training data, bridging the gap between\noptimal stopping theory and real-world deployment. It employs density ratio\nestimation and convex function learning to provide statistically consistent\nestimators for sufficient statistic and conditional expectation, both essential\nfor solving backward induction; consequently, FIRMBOUND minimizes Bayes risk to\nreach optimality. Additionally, we present a faster alternative using Gaussian\nprocess regression, which significantly reduces training time while retaining\nlow deployment overhead, albeit with potential compromise in statistical\nconsistency. Experiments across independent and identically distributed\n(i.i.d.), non-i.i.d., binary, multiclass, synthetic, and real-world datasets\nshow that FIRMBOUND achieves optimalities in the sense of Bayes risk and\nspeed-accuracy tradeoff. Furthermore, it advances the tradeoff boundary toward\noptimality when possible and reduces decision-time variance, ensuring reliable\ndecision-making. Code is publicly available at\nhttps://github.com/Akinori-F-Ebihara/FIRMBOUND",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to International Conference on Learning Representations\n  (ICLR) 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.18059v1",
    "published_date": "2025-01-29 23:54:46 UTC",
    "updated_date": "2025-01-29 23:54:46 UTC"
  },
  {
    "arxiv_id": "2501.18055v2",
    "title": "Current Pathology Foundation Models are unrobust to Medical Center Differences",
    "authors": [
      "Edwin D. de Jong",
      "Eric Marcus",
      "Jonas Teuwen"
    ],
    "abstract": "Pathology Foundation Models (FMs) hold great promise for healthcare. Before\nthey can be used in clinical practice, it is essential to ensure they are\nrobust to variations between medical centers. We measure whether pathology FMs\nfocus on biological features like tissue and cancer type, or on the well known\nconfounding medical center signatures introduced by staining procedure and\nother differences. We introduce the Robustness Index. This novel robustness\nmetric reflects to what degree biological features dominate confounding\nfeatures. Ten current publicly available pathology FMs are evaluated. We find\nthat all current pathology foundation models evaluated represent the medical\ncenter to a strong degree. Significant differences in the robustness index are\nobserved. Only one model so far has a robustness index greater than one,\nmeaning biological features dominate confounding features, but only slightly. A\nquantitative approach to measure the influence of medical center differences on\nFM-based prediction performance is described. We analyze the impact of\nunrobustness on classification performance of downstream models, and find that\ncancer-type classification errors are not random, but specifically attributable\nto same-center confounders: images of other classes from the same medical\ncenter. We visualize FM embedding spaces, and find these are more strongly\norganized by medical centers than by biological factors. As a consequence, the\nmedical center of origin is predicted more accurately than the tissue source\nand cancer type. The robustness index introduced here is provided with the aim\nof advancing progress towards clinical adoption of robust and reliable\npathology FMs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18055v2",
    "published_date": "2025-01-29 23:38:14 UTC",
    "updated_date": "2025-02-01 09:33:48 UTC"
  },
  {
    "arxiv_id": "2501.18052v2",
    "title": "SAeUron: Interpretable Concept Unlearning in Diffusion Models with Sparse Autoencoders",
    "authors": [
      "Bartosz Cywi≈Ñski",
      "Kamil Deja"
    ],
    "abstract": "Diffusion models, while powerful, can inadvertently generate harmful or\nundesirable content, raising significant ethical and safety concerns. Recent\nmachine unlearning approaches offer potential solutions but often lack\ntransparency, making it difficult to understand the changes they introduce to\nthe base model. In this work, we introduce SAeUron, a novel method leveraging\nfeatures learned by sparse autoencoders (SAEs) to remove unwanted concepts in\ntext-to-image diffusion models. First, we demonstrate that SAEs, trained in an\nunsupervised manner on activations from multiple denoising timesteps of the\ndiffusion model, capture sparse and interpretable features corresponding to\nspecific concepts. Building on this, we propose a feature selection method that\nenables precise interventions on model activations to block targeted content\nwhile preserving overall performance. Evaluation with the competitive\nUnlearnCanvas benchmark on object and style unlearning highlights SAeUron's\nstate-of-the-art performance. Moreover, we show that with a single SAE, we can\nremove multiple concepts simultaneously and that in contrast to other methods,\nSAeUron mitigates the possibility of generating unwanted content, even under\nadversarial attack. Code and checkpoints are available at:\nhttps://github.com/cywinski/SAeUron.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18052v2",
    "published_date": "2025-01-29 23:29:47 UTC",
    "updated_date": "2025-01-31 18:39:23 UTC"
  },
  {
    "arxiv_id": "2501.18045v2",
    "title": "From tools to thieves: Measuring and understanding public perceptions of AI through crowdsourced metaphors",
    "authors": [
      "Myra Cheng",
      "Angela Y. Lee",
      "Kristina Rapuano",
      "Kate Niederhoffer",
      "Alex Liebscher",
      "Jeffrey Hancock"
    ],
    "abstract": "How has the public responded to the increasing prevalence of artificial\nintelligence (AI)-based technologies? We investigate public perceptions of AI\nby collecting over 12,000 responses over 12 months from a nationally\nrepresentative U.S. sample. Participants provided open-ended metaphors\nreflecting their mental models of AI, a methodology that overcomes the\nlimitations of traditional self-reported measures by capturing more nuance.\nUsing a mixed-methods approach combining quantitative clustering and\nqualitative coding, we identify 20 dominant metaphors shaping public\nunderstanding of AI. To analyze these metaphors systematically, we present a\nscalable framework integrating language modeling (LM)-based techniques to\nmeasure key dimensions of public perception: anthropomorphism (attribution of\nhuman-like qualities), warmth, and competence. We find that Americans generally\nview AI as warm and competent, and that over the past year, perceptions of AI's\nhuman-likeness and warmth have significantly increased ($+34\\%, r = 0.80, p <\n0.01; +41\\%, r = 0.62, p < 0.05$). These implicit perceptions, along with the\nidentified dominant metaphors, strongly predict trust in and willingness to\nadopt AI ($r^2 = 0.21, 0.18, p < 0.001$). Moreover, we uncover systematic\ndemographic differences in metaphors and implicit perceptions, such as the\nhigher propensity of women, older individuals, and people of color to\nanthropomorphize AI, which shed light on demographic disparities in trust and\nadoption. In addition to our dataset and framework for tracking evolving public\nattitudes, we provide actionable insights on using metaphors for inclusive and\nresponsible AI development.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "To appear at the ACM Conference on Fairness, Accountability, and\n  Transparency 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.18045v2",
    "published_date": "2025-01-29 23:17:43 UTC",
    "updated_date": "2025-04-29 05:20:41 UTC"
  },
  {
    "arxiv_id": "2501.18016v1",
    "title": "Digital Twin-Enabled Real-Time Control in Robotic Additive Manufacturing via Soft Actor-Critic Reinforcement Learning",
    "authors": [
      "Matsive Ali",
      "Sandesh Giri",
      "Sen Liu",
      "Qin Yang"
    ],
    "abstract": "Smart manufacturing systems increasingly rely on adaptive control mechanisms\nto optimize complex processes. This research presents a novel approach\nintegrating Soft Actor-Critic (SAC) reinforcement learning with digital twin\ntechnology to enable real-time process control in robotic additive\nmanufacturing. We demonstrate our methodology using a Viper X300s robot arm,\nimplementing two distinct control scenarios: static target acquisition and\ndynamic trajectory following. The system architecture combines Unity's\nsimulation environment with ROS2 for seamless digital twin synchronization,\nwhile leveraging transfer learning to efficiently adapt trained models across\ntasks. Our hierarchical reward structure addresses common reinforcement\nlearning challenges including local minima avoidance, convergence acceleration,\nand training stability. Experimental results show rapid policy convergence and\nrobust task execution in both simulated and physical environments, with\nperformance metrics including cumulative reward, value prediction accuracy,\npolicy loss, and discrete entropy coefficient demonstrating the effectiveness\nof our approach. This work advances the integration of reinforcement learning\nwith digital twins for industrial robotics applications, providing a framework\nfor enhanced adaptive real-time control for smart additive manufacturing\nprocess.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18016v1",
    "published_date": "2025-01-29 22:06:53 UTC",
    "updated_date": "2025-01-29 22:06:53 UTC"
  },
  {
    "arxiv_id": "2501.18011v2",
    "title": "Anatomy Might Be All You Need: Forecasting What to Do During Surgery",
    "authors": [
      "Gary Sarwin",
      "Alessandro Carretta",
      "Victor Staartjes",
      "Matteo Zoli",
      "Diego Mazzatenta",
      "Luca Regli",
      "Carlo Serra",
      "Ender Konukoglu"
    ],
    "abstract": "Surgical guidance can be delivered in various ways. In neurosurgery, spatial\nguidance and orientation are predominantly achieved through neuronavigation\nsystems that reference pre-operative MRI scans. Recently, there has been\ngrowing interest in providing live guidance by analyzing video feeds from tools\nsuch as endoscopes. Existing approaches, including anatomy detection,\norientation feedback, phase recognition, and visual question-answering,\nprimarily focus on aiding surgeons in assessing the current surgical scene.\nThis work aims to provide guidance on a finer scale, aiming to provide guidance\nby forecasting the trajectory of the surgical instrument, essentially\naddressing the question of what to do next. To address this task, we propose a\nmodel that not only leverages the historical locations of surgical instruments\nbut also integrates anatomical features. Importantly, our work does not rely on\nexplicit ground truth labels for instrument trajectories. Instead, the ground\ntruth is generated by a detection model trained to detect both anatomical\nstructures and instruments within surgical videos of a comprehensive dataset\ncontaining pituitary surgery videos. By analyzing the interaction between\nanatomy and instrument movements in these videos and forecasting future\ninstrument movements, we show that anatomical features are a valuable asset in\naddressing this challenging task. To the best of our knowledge, this work is\nthe first attempt to address this task for manually operated surgeries.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18011v2",
    "published_date": "2025-01-29 21:54:31 UTC",
    "updated_date": "2025-01-31 17:07:52 UTC"
  },
  {
    "arxiv_id": "2501.18009v2",
    "title": "Large Language Models Think Too Fast To Explore Effectively",
    "authors": [
      "Lan Pan",
      "Hanbo Xie",
      "Robert C. Wilson"
    ],
    "abstract": "Large Language Models (LLMs) have emerged with many intellectual capacities.\nWhile numerous benchmarks assess their intelligence, limited attention has been\ngiven to their ability to explore--an essential capacity for discovering new\ninformation and adapting to novel environments in both natural and artificial\nsystems. The extent to which LLMs can effectively explore, particularly in\nopen-ended tasks, remains unclear. This study investigates whether LLMs can\nsurpass humans in exploration during an open-ended task, using Little Alchemy 2\nas a paradigm, where agents combine elements to discover new ones. Results show\nmost LLMs underperform compared to humans, except for the o1 model, with\ntraditional LLMs relying primarily on uncertainty-driven strategies, unlike\nhumans who balance uncertainty and empowerment. Results indicate that\ntraditional reasoning-focused LLMs, such as GPT-4o, exhibit a significantly\nfaster and less detailed reasoning process, limiting their exploratory\nperformance. In contrast, the DeepSeek reasoning model demonstrates prolonged,\niterative thought processes marked by repetitive analysis of combinations and\npast trials, reflecting a more thorough and human-like exploration strategy.\nRepresentational analysis of the models with Sparse Autoencoders (SAE) revealed\nthat uncertainty and choices are represented at earlier transformer blocks,\nwhile empowerment values are processed later, causing LLMs to think too fast\nand make premature decisions, hindering effective exploration. These findings\nshed light on the limitations of LLM exploration and suggest directions for\nimproving their adaptability.",
    "categories": [
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "cs.AI",
    "comment": "21 pages, 16 figures, under review",
    "pdf_url": "http://arxiv.org/pdf/2501.18009v2",
    "published_date": "2025-01-29 21:51:17 UTC",
    "updated_date": "2025-05-12 16:02:08 UTC"
  },
  {
    "arxiv_id": "2501.18006v1",
    "title": "Topological Signatures of Adversaries in Multimodal Alignments",
    "authors": [
      "Minh Vu",
      "Geigh Zollicoffer",
      "Huy Mai",
      "Ben Nebgen",
      "Boian Alexandrov",
      "Manish Bhattarai"
    ],
    "abstract": "Multimodal Machine Learning systems, particularly those aligning text and\nimage data like CLIP/BLIP models, have become increasingly prevalent, yet\nremain susceptible to adversarial attacks. While substantial research has\naddressed adversarial robustness in unimodal contexts, defense strategies for\nmultimodal systems are underexplored. This work investigates the topological\nsignatures that arise between image and text embeddings and shows how\nadversarial attacks disrupt their alignment, introducing distinctive\nsignatures. We specifically leverage persistent homology and introduce two\nnovel Topological-Contrastive losses based on Total Persistence and Multi-scale\nkernel methods to analyze the topological signatures introduced by adversarial\nperturbations. We observe a pattern of monotonic changes in the proposed\ntopological losses emerging in a wide range of attacks on image-text\nalignments, as more adversarial samples are introduced in the data. By\ndesigning an algorithm to back-propagate these signatures to input samples, we\nare able to integrate these signatures into Maximum Mean Discrepancy tests,\ncreating a novel class of tests that leverage topological signatures for better\nadversarial detection.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18006v1",
    "published_date": "2025-01-29 21:45:10 UTC",
    "updated_date": "2025-01-29 21:45:10 UTC"
  },
  {
    "arxiv_id": "2501.17991v1",
    "title": "Investigating the Monte-Carlo Tree Search Approach for the Job Shop Scheduling Problem",
    "authors": [
      "Laurie Boveroux",
      "Damien Ernst",
      "Quentin Louveaux"
    ],
    "abstract": "The Job Shop Scheduling Problem (JSSP) is a well-known optimization problem\nin manufacturing, where the goal is to determine the optimal sequence of jobs\nacross different machines to minimize a given objective. In this work, we focus\non minimising the weighted sum of job completion times. We explore the\npotential of Monte Carlo Tree Search (MCTS), a heuristic-based reinforcement\nlearning technique, to solve large-scale JSSPs, especially those with\nrecirculation. We propose several Markov Decision Process (MDP) formulations to\nmodel the JSSP for the MCTS algorithm. In addition, we introduce a new\nsynthetic benchmark derived from real manufacturing data, which captures the\ncomplexity of large, non-rectangular instances often encountered in practice.\nOur experimental results show that MCTS effectively produces good-quality\nsolutions for large-scale JSSP instances, outperforming our constraint\nprogramming approach.",
    "categories": [
      "cs.AI",
      "math.OC",
      "F.2.2"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17991v1",
    "published_date": "2025-01-29 20:55:53 UTC",
    "updated_date": "2025-01-29 20:55:53 UTC"
  },
  {
    "arxiv_id": "2501.17982v2",
    "title": "Belief Roadmaps with Uncertain Landmark Evanescence",
    "authors": [
      "Erick Fuentes",
      "Jared Strader",
      "Ethan Fahnestock",
      "Nicholas Roy"
    ],
    "abstract": "We would like a robot to navigate to a goal location while minimizing state\nuncertainty. To aid the robot in this endeavor, maps provide a prior belief\nover the location of objects and regions of interest. To localize itself within\nthe map, a robot identifies mapped landmarks using its sensors. However, as the\ntime between map creation and robot deployment increases, portions of the map\ncan become stale, and landmarks, once believed to be permanent, may disappear.\nWe refer to the propensity of a landmark to disappear as landmark evanescence.\nReasoning about landmark evanescence during path planning, and the associated\nimpact on localization accuracy, requires analyzing the presence or absence of\neach landmark, leading to an exponential number of possible outcomes of a given\nmotion plan. To address this complexity, we develop BRULE, an extension of the\nBelief Roadmap. During planning, we replace the belief over future robot poses\nwith a Gaussian mixture which is able to capture the effects of landmark\nevanescence. Furthermore, we show that belief updates can be made efficient,\nand that maintaining a random subset of mixture components is sufficient to\nfind high quality solutions. We demonstrate performance in simulated and\nreal-world experiments. Software is available at https://bit.ly/BRULE.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17982v2",
    "published_date": "2025-01-29 20:37:01 UTC",
    "updated_date": "2025-05-01 15:03:04 UTC"
  },
  {
    "arxiv_id": "2501.17980v2",
    "title": "Limits to AI Growth: The Ecological and Social Consequences of Scaling",
    "authors": [
      "Eshta Bhardwaj",
      "Rohan Alexander",
      "Christoph Becker"
    ],
    "abstract": "The accelerating development and deployment of AI technologies depend on the\ncontinued ability to scale their infrastructure. This has implied increasing\namounts of monetary investment and natural resources. Frontier AI applications\nhave thus resulted in rising financial, environmental, and social costs. While\nthe factors that AI scaling depends on reach its limits, the push for its\naccelerated advancement and entrenchment continues. In this paper, we provide a\nholistic review of AI scaling using four lenses (technical, economic,\necological, and social) and review the relationships between these lenses to\nexplore the dynamics of AI growth. We do so by drawing on system dynamics\nconcepts including archetypes such as \"limits to growth\" to model the dynamic\ncomplexity of AI scaling and synthesize several perspectives. Our work maps out\nthe entangled relationships between the technical, economic, ecological and\nsocial perspectives and the apparent limits to growth. The analysis explains\nhow industry's responses to external limits enables continued (but temporary)\nscaling and how this benefits Big Tech while externalizing social and\nenvironmental damages. To avoid an \"overshoot and collapse\" trajectory, we\nadvocate for realigning priorities and norms around scaling to prioritize\nsustainable and mindful advancements.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "14 pages",
    "pdf_url": "http://arxiv.org/pdf/2501.17980v2",
    "published_date": "2025-01-29 20:25:42 UTC",
    "updated_date": "2025-01-31 23:41:52 UTC"
  },
  {
    "arxiv_id": "2501.17974v2",
    "title": "Think Smarter not Harder: Adaptive Reasoning with Inference Aware Optimization",
    "authors": [
      "Zishun Yu",
      "Tengyu Xu",
      "Di Jin",
      "Karthik Abinav Sankararaman",
      "Yun He",
      "Wenxuan Zhou",
      "Zhouhao Zeng",
      "Eryk Helenowski",
      "Chen Zhu",
      "Sinong Wang",
      "Hao Ma",
      "Han Fang"
    ],
    "abstract": "Solving mathematics problems has been an intriguing capability of large\nlanguage models, and many efforts have been made to improve reasoning by\nextending reasoning length, such as through self-correction and extensive long\nchain-of-thoughts. While promising in problem-solving, advanced long reasoning\nchain models exhibit an undesired single-modal behavior, where trivial\nquestions require unnecessarily tedious long chains of thought. In this work,\nwe propose a way to allow models to be aware of inference budgets by\nformulating it as utility maximization with respect to an inference budget\nconstraint, hence naming our algorithm Inference Budget-Constrained Policy\nOptimization (IBPO). In a nutshell, models fine-tuned through IBPO learn to\n``understand'' the difficulty of queries and allocate inference budgets to\nharder ones. With different inference budgets, our best models are able to have\na $4.14$\\% and $5.74$\\% absolute improvement ($8.08$\\% and $11.2$\\% relative\nimprovement) on MATH500 using $2.16$x and $4.32$x inference budgets\nrespectively, relative to LLaMA3.1 8B Instruct. These improvements are\napproximately $2$x those of self-consistency under the same budgets.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17974v2",
    "published_date": "2025-01-29 20:20:48 UTC",
    "updated_date": "2025-01-31 16:06:26 UTC"
  },
  {
    "arxiv_id": "2501.17917v1",
    "title": "Deep Ensembles Secretly Perform Empirical Bayes",
    "authors": [
      "Gabriel Loaiza-Ganem",
      "Valentin Villecroze",
      "Yixin Wang"
    ],
    "abstract": "Quantifying uncertainty in neural networks is a highly relevant problem which\nis essential to many applications. The two predominant paradigms to tackle this\ntask are Bayesian neural networks (BNNs) and deep ensembles. Despite some\nsimilarities between these two approaches, they are typically surmised to lack\na formal connection and are thus understood as fundamentally different. BNNs\nare often touted as more principled due to their reliance on the Bayesian\nparadigm, whereas ensembles are perceived as more ad-hoc; yet, deep ensembles\ntend to empirically outperform BNNs, with no satisfying explanation as to why\nthis is the case. In this work we bridge this gap by showing that deep\nensembles perform exact Bayesian averaging with a posterior obtained with an\nimplicitly learned data-dependent prior. In other words deep ensembles are\nBayesian, or more specifically, they implement an empirical Bayes procedure\nwherein the prior is learned from the data. This perspective offers two main\nbenefits: (i) it theoretically justifies deep ensembles and thus provides an\nexplanation for their strong empirical performance; and (ii) inspection of the\nlearned prior reveals it is given by a mixture of point masses -- the use of\nsuch a strong prior helps elucidate observed phenomena about ensembles.\nOverall, our work delivers a newfound understanding of deep ensembles which is\nnot only of interest in it of itself, but which is also likely to generate\nfuture insights that drive empirical improvements for these models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17917v1",
    "published_date": "2025-01-29 19:00:01 UTC",
    "updated_date": "2025-01-29 19:00:01 UTC"
  },
  {
    "arxiv_id": "2501.17860v1",
    "title": "Dialogue is Better Than Monologue: Instructing Medical LLMs via Strategical Conversations",
    "authors": [
      "Zijie Liu",
      "Xinyu Zhao",
      "Jie Peng",
      "Zhuangdi Zhu",
      "Qingyu Chen",
      "Xia Hu",
      "Tianlong Chen"
    ],
    "abstract": "Current medical AI systems often fail to replicate real-world clinical\nreasoning, as they are predominantly trained and evaluated on static text and\nquestion-answer tasks. These tuning methods and benchmarks overlook critical\naspects like evidence-based reasoning and handling distracting information. To\nbridge this gap, we introduce a novel benchmark that simulates real-world\ndiagnostic scenarios, integrating noise and difficulty levels aligned with\nUSMLE standards. Moreover, we explore dialogue-based fine-tuning, which\ntransforms static datasets into conversational formats to better capture\niterative reasoning processes. Experiments show that dialogue-tuned models\noutperform traditional methods, with improvements of $9.64\\%$ in multi-round\nreasoning scenarios and $6.18\\%$ in accuracy in a noisy environment. Our\nfindings highlight dialogue tuning as a promising approach for advancing\nclinically aligned and robust medical AI systems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17860v1",
    "published_date": "2025-01-29 18:58:48 UTC",
    "updated_date": "2025-01-29 18:58:48 UTC"
  },
  {
    "arxiv_id": "2501.17858v1",
    "title": "Improving Your Model Ranking on Chatbot Arena by Vote Rigging",
    "authors": [
      "Rui Min",
      "Tianyu Pang",
      "Chao Du",
      "Qian Liu",
      "Minhao Cheng",
      "Min Lin"
    ],
    "abstract": "Chatbot Arena is a popular platform for evaluating LLMs by pairwise battles,\nwhere users vote for their preferred response from two randomly sampled\nanonymous models. While Chatbot Arena is widely regarded as a reliable LLM\nranking leaderboard, we show that crowdsourced voting can be rigged to improve\n(or decrease) the ranking of a target model $m_{t}$. We first introduce a\nstraightforward target-only rigging strategy that focuses on new battles\ninvolving $m_{t}$, identifying it via watermarking or a binary classifier, and\nexclusively voting for $m_{t}$ wins. However, this strategy is practically\ninefficient because there are over $190$ models on Chatbot Arena and on average\nonly about $1\\%$ of new battles will involve $m_{t}$. To overcome this, we\npropose omnipresent rigging strategies, exploiting the Elo rating mechanism of\nChatbot Arena that any new vote on a battle can influence the ranking of the\ntarget model $m_{t}$, even if $m_{t}$ is not directly involved in the battle.\nWe conduct experiments on around $1.7$ million historical votes from the\nChatbot Arena Notebook, showing that omnipresent rigging strategies can improve\nmodel rankings by rigging only hundreds of new votes. While we have evaluated\nseveral defense mechanisms, our findings highlight the importance of continued\nefforts to prevent vote rigging. Our code is available at\nhttps://github.com/sail-sg/Rigging-ChatbotArena.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17858v1",
    "published_date": "2025-01-29 18:57:29 UTC",
    "updated_date": "2025-01-29 18:57:29 UTC"
  },
  {
    "arxiv_id": "2501.17855v1",
    "title": "GRACE: Generalizing Robot-Assisted Caregiving with User Functionality Embeddings",
    "authors": [
      "Ziang Liu",
      "Yuanchen Ju",
      "Yu Da",
      "Tom Silver",
      "Pranav N. Thakkar",
      "Jenna Li",
      "Justin Guo",
      "Katherine Dimitropoulou",
      "Tapomayukh Bhattacharjee"
    ],
    "abstract": "Robot caregiving should be personalized to meet the diverse needs of care\nrecipients -- assisting with tasks as needed, while taking user agency in\naction into account. In physical tasks such as handover, bathing, dressing, and\nrehabilitation, a key aspect of this diversity is the functional range of\nmotion (fROM), which can vary significantly between individuals. In this work,\nwe learn to predict personalized fROM as a way to generalize robot\ndecision-making in a wide range of caregiving tasks. We propose a novel\ndata-driven method for predicting personalized fROM using functional assessment\nscores from occupational therapy. We develop a neural model that learns to\nembed functional assessment scores into a latent representation of the user's\nphysical function. The model is trained using motion capture data collected\nfrom users with emulated mobility limitations. After training, the model\npredicts personalized fROM for new users without motion capture. Through\nsimulated experiments and a real-robot user study, we show that the\npersonalized fROM predictions from our model enable the robot to provide\npersonalized and effective assistance while improving the user's agency in\naction. See our website for more visualizations:\nhttps://emprise.cs.cornell.edu/grace/.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.RO",
    "comment": "10 pages, 5 figures, Accepted to IEEE/ACM International Conference on\n  Human-Robot Interaction (HRI), 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.17855v1",
    "published_date": "2025-01-29 18:55:07 UTC",
    "updated_date": "2025-01-29 18:55:07 UTC"
  },
  {
    "arxiv_id": "2501.17842v1",
    "title": "From Sparse to Dense: Toddler-inspired Reward Transition in Goal-Oriented Reinforcement Learning",
    "authors": [
      "Junseok Park",
      "Hyeonseo Yang",
      "Min Whoo Lee",
      "Won-Seok Choi",
      "Minsu Lee",
      "Byoung-Tak Zhang"
    ],
    "abstract": "Reinforcement learning (RL) agents often face challenges in balancing\nexploration and exploitation, particularly in environments where sparse or\ndense rewards bias learning. Biological systems, such as human toddlers,\nnaturally navigate this balance by transitioning from free exploration with\nsparse rewards to goal-directed behavior guided by increasingly dense rewards.\nInspired by this natural progression, we investigate the Toddler-Inspired\nReward Transition in goal-oriented RL tasks. Our study focuses on transitioning\nfrom sparse to potential-based dense (S2D) rewards while preserving optimal\nstrategies. Through experiments on dynamic robotic arm manipulation and\negocentric 3D navigation tasks, we demonstrate that effective S2D reward\ntransitions significantly enhance learning performance and sample efficiency.\nAdditionally, using a Cross-Density Visualizer, we show that S2D transitions\nsmooth the policy loss landscape, resulting in wider minima that improve\ngeneralization in RL models. In addition, we reinterpret Tolman's maze\nexperiments, underscoring the critical role of early free exploratory learning\nin the context of S2D rewards.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO",
      "68T05, 68T20, 91E40"
    ],
    "primary_category": "cs.LG",
    "comment": "Extended version of AAAI 2024 paper: Unveiling the Significance of\n  Toddler-Inspired Reward Transition in Goal-Oriented Reinforcement Learning.\n  This manuscript is currently being prepared for journal submission",
    "pdf_url": "http://arxiv.org/pdf/2501.17842v1",
    "published_date": "2025-01-29 18:46:35 UTC",
    "updated_date": "2025-01-29 18:46:35 UTC"
  },
  {
    "arxiv_id": "2501.17823v2",
    "title": "Robust Multimodal Learning via Cross-Modal Proxy Tokens",
    "authors": [
      "Md Kaykobad Reza",
      "Ameya Patil",
      "Mashhour Solh",
      "M. Salman Asif"
    ],
    "abstract": "Multimodal models often experience a significant performance drop when one or\nmore modalities are missing during inference. To address this challenge, we\npropose a simple yet effective approach that enhances robustness to missing\nmodalities while maintaining strong performance when all modalities are\navailable. Our method introduces cross-modal proxy tokens (CMPTs), which\napproximate the class token of a missing modality by attending only to the\ntokens of the available modality. To efficiently learn the approximation for\nthe missing modality via CMPTs with minimal computational overhead, we employ\nlow-rank adapters in frozen unimodal encoders and jointly optimize an alignment\nloss with a task-specific loss. Extensive experiments on five multimodal\ndatasets show that our method outperforms state-of-the-art baselines across\nvarious missing rates while achieving competitive results in complete-modality\nsettings. Overall, our method offers a flexible and efficient solution for\nrobust multimodal learning. The code and pretrained models will be released on\nGitHub.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "17 Pages, 10 Figures, 6 Tables",
    "pdf_url": "http://arxiv.org/pdf/2501.17823v2",
    "published_date": "2025-01-29 18:15:49 UTC",
    "updated_date": "2025-03-10 01:34:24 UTC"
  },
  {
    "arxiv_id": "2501.17822v2",
    "title": "Aggregation Schemes for Single-Vector WSI Representation Learning in Digital Pathology",
    "authors": [
      "Sobhan Hemati",
      "Ghazal Alabtah",
      "Saghir Alfasly",
      "H. R. Tizhoosh"
    ],
    "abstract": "A crucial step to efficiently integrate Whole Slide Images (WSIs) in\ncomputational pathology is assigning a single high-quality feature vector,\ni.e., one embedding, to each WSI. With the existence of many pre-trained deep\nneural networks and the emergence of foundation models, extracting embeddings\nfor sub-images (i.e., tiles or patches) is straightforward. However, for WSIs,\ngiven their high resolution and gigapixel nature, inputting them into existing\nGPUs as a single image is not feasible. As a result, WSIs are usually split\ninto many patches. Feeding each patch to a pre-trained model, each WSI can then\nbe represented by a set of patches, hence, a set of embeddings. Hence, in such\na setup, WSI representation learning reduces to set representation learning\nwhere for each WSI we have access to a set of patch embeddings. To obtain a\nsingle embedding from a set of patch embeddings for each WSI, multiple\nset-based learning schemes have been proposed in the literature. In this paper,\nwe evaluate the WSI search performance of multiple recently developed\naggregation techniques (mainly set representation learning techniques)\nincluding simple average or max pooling operations, Deep Sets, Memory networks,\nFocal attention, Gaussian Mixture Model (GMM) Fisher Vector, and deep sparse\nand binary Fisher Vector on four different primary sites including bladder,\nbreast, kidney, and Colon from TCGA. Further, we benchmark the search\nperformance of these methods against the median of minimum distances of patch\nembeddings, a non-aggregating approach used for WSI retrieval.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.IR",
      "q-bio.QM"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17822v2",
    "published_date": "2025-01-29 18:14:51 UTC",
    "updated_date": "2025-05-21 15:05:27 UTC"
  },
  {
    "arxiv_id": "2501.17813v1",
    "title": "P-TAME: Explain Any Image Classifier with Trained Perturbations",
    "authors": [
      "Mariano V. Ntrougkas",
      "Vasileios Mezaris",
      "Ioannis Patras"
    ],
    "abstract": "The adoption of Deep Neural Networks (DNNs) in critical fields where\npredictions need to be accompanied by justifications is hindered by their\ninherent black-box nature. In this paper, we introduce P-TAME\n(Perturbation-based Trainable Attention Mechanism for Explanations), a\nmodel-agnostic method for explaining DNN-based image classifiers. P-TAME\nemploys an auxiliary image classifier to extract features from the input image,\nbypassing the need to tailor the explanation method to the internal\narchitecture of the backbone classifier being explained. Unlike traditional\nperturbation-based methods, which have high computational requirements, P-TAME\noffers an efficient alternative by generating high-resolution explanations in a\nsingle forward pass during inference. We apply P-TAME to explain the decisions\nof VGG-16, ResNet-50, and ViT-B-16, three distinct and widely used image\nclassifiers. Quantitative and qualitative results show that our method matches\nor outperforms previous explainability methods, including model-specific\napproaches. Code and trained models will be released upon acceptance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Submitted for publication",
    "pdf_url": "http://arxiv.org/pdf/2501.17813v1",
    "published_date": "2025-01-29 18:06:08 UTC",
    "updated_date": "2025-01-29 18:06:08 UTC"
  },
  {
    "arxiv_id": "2501.17811v1",
    "title": "Janus-Pro: Unified Multimodal Understanding and Generation with Data and Model Scaling",
    "authors": [
      "Xiaokang Chen",
      "Zhiyu Wu",
      "Xingchao Liu",
      "Zizheng Pan",
      "Wen Liu",
      "Zhenda Xie",
      "Xingkai Yu",
      "Chong Ruan"
    ],
    "abstract": "In this work, we introduce Janus-Pro, an advanced version of the previous\nwork Janus. Specifically, Janus-Pro incorporates (1) an optimized training\nstrategy, (2) expanded training data, and (3) scaling to larger model size.\nWith these improvements, Janus-Pro achieves significant advancements in both\nmultimodal understanding and text-to-image instruction-following capabilities,\nwhile also enhancing the stability of text-to-image generation. We hope this\nwork will inspire further exploration in the field. Code and models are\npublicly available.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "Research paper. arXiv admin note: text overlap with arXiv:2410.13848",
    "pdf_url": "http://arxiv.org/pdf/2501.17811v1",
    "published_date": "2025-01-29 18:00:19 UTC",
    "updated_date": "2025-01-29 18:00:19 UTC"
  },
  {
    "arxiv_id": "2501.18649v1",
    "title": "Fake News Detection After LLM Laundering: Measurement and Explanation",
    "authors": [
      "Rupak Kumar Das",
      "Jonathan Dodge"
    ],
    "abstract": "With their advanced capabilities, Large Language Models (LLMs) can generate\nhighly convincing and contextually relevant fake news, which can contribute to\ndisseminating misinformation. Though there is much research on fake news\ndetection for human-written text, the field of detecting LLM-generated fake\nnews is still under-explored. This research measures the efficacy of detectors\nin identifying LLM-paraphrased fake news, in particular, determining whether\nadding a paraphrase step in the detection pipeline helps or impedes detection.\nThis study contributes: (1) Detectors struggle to detect LLM-paraphrased fake\nnews more than human-written text, (2) We find which models excel at which\ntasks (evading detection, paraphrasing to evade detection, and paraphrasing for\nsemantic similarity). (3) Via LIME explanations, we discovered a possible\nreason for detection failures: sentiment shift. (4) We discover a worrisome\ntrend for paraphrase quality measurement: samples that exhibit sentiment shift\ndespite a high BERTSCORE. (5) We provide a pair of datasets augmenting existing\ndatasets with paraphrase outputs and scores. The dataset is available on GitHub",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18649v1",
    "published_date": "2025-01-29 17:58:07 UTC",
    "updated_date": "2025-01-29 17:58:07 UTC"
  },
  {
    "arxiv_id": "2501.17805v1",
    "title": "International AI Safety Report",
    "authors": [
      "Yoshua Bengio",
      "S√∂ren Mindermann",
      "Daniel Privitera",
      "Tamay Besiroglu",
      "Rishi Bommasani",
      "Stephen Casper",
      "Yejin Choi",
      "Philip Fox",
      "Ben Garfinkel",
      "Danielle Goldfarb",
      "Hoda Heidari",
      "Anson Ho",
      "Sayash Kapoor",
      "Leila Khalatbari",
      "Shayne Longpre",
      "Sam Manning",
      "Vasilios Mavroudis",
      "Mantas Mazeika",
      "Julian Michael",
      "Jessica Newman",
      "Kwan Yee Ng",
      "Chinasa T. Okolo",
      "Deborah Raji",
      "Girish Sastry",
      "Elizabeth Seger",
      "Theodora Skeadas",
      "Tobin South",
      "Emma Strubell",
      "Florian Tram√®r",
      "Lucia Velasco",
      "Nicole Wheeler",
      "Daron Acemoglu",
      "Olubayo Adekanmbi",
      "David Dalrymple",
      "Thomas G. Dietterich",
      "Edward W. Felten",
      "Pascale Fung",
      "Pierre-Olivier Gourinchas",
      "Fredrik Heintz",
      "Geoffrey Hinton",
      "Nick Jennings",
      "Andreas Krause",
      "Susan Leavy",
      "Percy Liang",
      "Teresa Ludermir",
      "Vidushi Marda",
      "Helen Margetts",
      "John McDermid",
      "Jane Munga",
      "Arvind Narayanan",
      "Alondra Nelson",
      "Clara Neppel",
      "Alice Oh",
      "Gopal Ramchurn",
      "Stuart Russell",
      "Marietje Schaake",
      "Bernhard Sch√∂lkopf",
      "Dawn Song",
      "Alvaro Soto",
      "Lee Tiedrich",
      "Ga√´l Varoquaux",
      "Andrew Yao",
      "Ya-Qin Zhang",
      "Fahad Albalawi",
      "Marwan Alserkal",
      "Olubunmi Ajala",
      "Guillaume Avrin",
      "Christian Busch",
      "Andr√© Carlos Ponce de Leon Ferreira de Carvalho",
      "Bronwyn Fox",
      "Amandeep Singh Gill",
      "Ahmet Halit Hatip",
      "Juha Heikkil√§",
      "Gill Jolly",
      "Ziv Katzir",
      "Hiroaki Kitano",
      "Antonio Kr√ºger",
      "Chris Johnson",
      "Saif M. Khan",
      "Kyoung Mu Lee",
      "Dominic Vincent Ligot",
      "Oleksii Molchanovskyi",
      "Andrea Monti",
      "Nusu Mwamanzi",
      "Mona Nemer",
      "Nuria Oliver",
      "Jos√© Ram√≥n L√≥pez Portillo",
      "Balaraman Ravindran",
      "Raquel Pezoa Rivera",
      "Hammam Riza",
      "Crystal Rugege",
      "Ciar√°n Seoighe",
      "Jerry Sheehan",
      "Haroon Sheikh",
      "Denise Wong",
      "Yi Zeng"
    ],
    "abstract": "The first International AI Safety Report comprehensively synthesizes the\ncurrent evidence on the capabilities, risks, and safety of advanced AI systems.\nThe report was mandated by the nations attending the AI Safety Summit in\nBletchley, UK. Thirty nations, the UN, the OECD, and the EU each nominated a\nrepresentative to the report's Expert Advisory Panel. A total of 100 AI experts\ncontributed, representing diverse perspectives and disciplines. Led by the\nreport's Chair, these independent experts collectively had full discretion over\nthe report's content.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17805v1",
    "published_date": "2025-01-29 17:47:36 UTC",
    "updated_date": "2025-01-29 17:47:36 UTC"
  },
  {
    "arxiv_id": "2501.17790v1",
    "title": "BreezyVoice: Adapting TTS for Taiwanese Mandarin with Enhanced Polyphone Disambiguation -- Challenges and Insights",
    "authors": [
      "Chan-Jan Hsu",
      "Yi-Cheng Lin",
      "Chia-Chun Lin",
      "Wei-Chih Chen",
      "Ho Lam Chung",
      "Chen-An Li",
      "Yi-Chang Chen",
      "Chien-Yu Yu",
      "Ming-Ji Lee",
      "Chien-Cheng Chen",
      "Ru-Heng Huang",
      "Hung-yi Lee",
      "Da-Shan Shiu"
    ],
    "abstract": "We present BreezyVoice, a Text-to-Speech (TTS) system specifically adapted\nfor Taiwanese Mandarin, highlighting phonetic control abilities to address the\nunique challenges of polyphone disambiguation in the language. Building upon\nCosyVoice, we incorporate a $S^{3}$ tokenizer, a large language model (LLM), an\noptimal-transport conditional flow matching model (OT-CFM), and a grapheme to\nphoneme prediction model, to generate realistic speech that closely mimics\nhuman utterances. Our evaluation demonstrates BreezyVoice's superior\nperformance in both general and code-switching contexts, highlighting its\nrobustness and effectiveness in generating high-fidelity speech. Additionally,\nwe address the challenges of generalizability in modeling long-tail speakers\nand polyphone disambiguation. Our approach significantly enhances performance\nand offers valuable insights into the workings of neural codec TTS systems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17790v1",
    "published_date": "2025-01-29 17:31:26 UTC",
    "updated_date": "2025-01-29 17:31:26 UTC"
  },
  {
    "arxiv_id": "2501.17771v1",
    "title": "2SSP: A Two-Stage Framework for Structured Pruning of LLMs",
    "authors": [
      "Fabrizio Sandri",
      "Elia Cunegatti",
      "Giovanni Iacca"
    ],
    "abstract": "We propose a novel Two-Stage framework for Structured Pruning (2SSP) for\npruning Large Language Models (LLMs), which combines two different strategies\nof pruning, namely Width and Depth Pruning. The first stage (Width Pruning)\nremoves entire neurons, hence their corresponding rows and columns, aiming to\npreserve the connectivity among the pruned structures in the intermediate state\nof the Feed-Forward Networks in each Transformer block. This is done based on\nan importance score measuring the impact of each neuron over the output\nmagnitude. The second stage (Depth Pruning), instead, removes entire Attention\nsubmodules. This is done by applying an iterative process that removes the\nAttention submodules with the minimum impact on a given metric of interest (in\nour case, perplexity). We also propose a novel mechanism to balance the\nsparsity rate of the two stages w.r.t. to the desired global sparsity. We test\n2SSP on four LLM families and three sparsity rates (25\\%, 37.5\\%, and 50\\%),\nmeasuring the resulting perplexity over three language modeling datasets as\nwell as the performance over six downstream tasks. Our method consistently\noutperforms five state-of-the-art competitors over three language modeling and\nsix downstream tasks, with an up to two-order-of-magnitude gain in terms of\npruning time. The code is available at available at\n\\url{https://github.com/FabrizioSandri/2SSP}.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17771v1",
    "published_date": "2025-01-29 17:05:33 UTC",
    "updated_date": "2025-01-29 17:05:33 UTC"
  },
  {
    "arxiv_id": "2501.17767v1",
    "title": "Hybrid Graphs for Table-and-Text based Question Answering using LLMs",
    "authors": [
      "Ankush Agarwal",
      "Ganesh S",
      "Chaitanya Devaguptapu"
    ],
    "abstract": "Answering questions that require reasoning and aggregation across both\nstructured (tables) and unstructured (raw text) data sources presents\nsignificant challenges. Current methods rely on fine-tuning and high-quality,\nhuman-curated data, which is difficult to obtain. Recent advances in Large\nLanguage Models (LLMs) have shown promising results for multi-hop question\nanswering (QA) over single-source text data in a zero-shot setting, yet\nexploration into multi-source Table-Text QA remains limited. In this paper, we\npresent a novel Hybrid Graph-based approach for Table-Text QA that leverages\nLLMs without fine-tuning. Our method constructs a unified Hybrid Graph from\ntextual and tabular data, pruning information based on the input question to\nprovide the LLM with relevant context concisely. We evaluate our approach on\nthe challenging Hybrid-QA and OTT-QA datasets using state-of-the-art LLMs,\nincluding GPT-3.5, GPT-4, and LLaMA-3. Our method achieves the best zero-shot\nperformance on both datasets, improving Exact Match scores by up to 10% on\nHybrid-QA and 5.4% on OTT-QA. Moreover, our approach reduces token usage by up\nto 53% compared to the original context.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at NAACL 2025 Main Track",
    "pdf_url": "http://arxiv.org/pdf/2501.17767v1",
    "published_date": "2025-01-29 16:58:18 UTC",
    "updated_date": "2025-01-29 16:58:18 UTC"
  },
  {
    "arxiv_id": "2501.17759v1",
    "title": "Yin-Yang: Developing Motifs With Long-Term Structure And Controllability",
    "authors": [
      "Keshav Bhandari",
      "Geraint A. Wiggins",
      "Simon Colton"
    ],
    "abstract": "Transformer models have made great strides in generating symbolically\nrepresented music with local coherence. However, controlling the development of\nmotifs in a structured way with global form remains an open research area. One\nof the reasons for this challenge is due to the note-by-note autoregressive\ngeneration of such models, which lack the ability to correct themselves after\ndeviations from the motif. In addition, their structural performance on\ndatasets with shorter durations has not been studied in the literature. In this\nstudy, we propose Yin-Yang, a framework consisting of a phrase generator,\nphrase refiner, and phrase selector models for the development of motifs into\nmelodies with long-term structure and controllability. The phrase refiner is\ntrained on a novel corruption-refinement strategy which allows it to produce\nmelodic and rhythmic variations of an original motif at generation time,\nthereby rectifying deviations of the phrase generator. We also introduce a new\nobjective evaluation metric for quantifying how smoothly the motif manifests\nitself within the piece. Evaluation results show that our model achieves better\nperformance compared to state-of-the-art transformer models while having the\nadvantage of being controllable and making the generated musical structure\nsemi-interpretable, paving the way for musical analysis. Our code and demo page\ncan be found at https://github.com/keshavbhandari/yinyang.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.SC"
    ],
    "primary_category": "cs.SD",
    "comment": "16 Pages, 4 Figures, Accepted at Artificial Intelligence in Music,\n  Sound, Art and Design: 14th International Conference, EvoMUSART 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.17759v1",
    "published_date": "2025-01-29 16:50:09 UTC",
    "updated_date": "2025-01-29 16:50:09 UTC"
  },
  {
    "arxiv_id": "2501.17755v2",
    "title": "AI Governance through Markets",
    "authors": [
      "Philip Moreira Tomei",
      "Rupal Jain",
      "Matija Franklin"
    ],
    "abstract": "This paper argues that market governance mechanisms should be considered a\nkey approach in the governance of artificial intelligence (AI), alongside\ntraditional regulatory frameworks. While current governance approaches have\npredominantly focused on regulation, we contend that market-based mechanisms\noffer effective incentives for responsible AI development. We examine four\nemerging vectors of market governance: insurance, auditing, procurement, and\ndue diligence, demonstrating how these mechanisms can affirm the relationship\nbetween AI risk and financial risk while addressing capital allocation\ninefficiencies. While we do not claim that market forces alone can adequately\nprotect societal interests, we maintain that standardised AI disclosures and\nmarket mechanisms can create powerful incentives for safe and responsible AI\ndevelopment. This paper urges regulators, economists, and machine learning\nresearchers to investigate and implement market-based approaches to AI\ngovernance.",
    "categories": [
      "econ.GN",
      "cs.AI",
      "q-fin.EC"
    ],
    "primary_category": "econ.GN",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17755v2",
    "published_date": "2025-01-29 16:48:13 UTC",
    "updated_date": "2025-03-05 16:20:03 UTC"
  },
  {
    "arxiv_id": "2501.17749v1",
    "title": "Early External Safety Testing of OpenAI's o3-mini: Insights from the Pre-Deployment Evaluation",
    "authors": [
      "Aitor Arrieta",
      "Miriam Ugarte",
      "Pablo Valle",
      "Jos√© Antonio Parejo",
      "Sergio Segura"
    ],
    "abstract": "Large Language Models (LLMs) have become an integral part of our daily lives.\nHowever, they impose certain risks, including those that can harm individuals'\nprivacy, perpetuate biases and spread misinformation. These risks highlight the\nneed for robust safety mechanisms, ethical guidelines, and thorough testing to\nensure their responsible deployment. Safety of LLMs is a key property that\nneeds to be thoroughly tested prior the model to be deployed and accessible to\nthe general users. This paper reports the external safety testing experience\nconducted by researchers from Mondragon University and University of Seville on\nOpenAI's new o3-mini LLM as part of OpenAI's early access for safety testing\nprogram. In particular, we apply our tool, ASTRAL, to automatically and\nsystematically generate up to date unsafe test inputs (i.e., prompts) that\nhelps us test and assess different safety categories of LLMs. We automatically\ngenerate and execute a total of 10,080 unsafe test input on a early o3-mini\nbeta version. After manually verifying the test cases classified as unsafe by\nASTRAL, we identify a total of 87 actual instances of unsafe LLM behavior. We\nhighlight key insights and findings uncovered during the pre-deployment\nexternal testing phase of OpenAI's latest LLM.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "arXiv admin note: text overlap with arXiv:2501.17132",
    "pdf_url": "http://arxiv.org/pdf/2501.17749v1",
    "published_date": "2025-01-29 16:36:53 UTC",
    "updated_date": "2025-01-29 16:36:53 UTC"
  },
  {
    "arxiv_id": "2501.17731v1",
    "title": "Exact characterization of Œµ-Safe Decision Regions for exponential family distributions and Multi Cost SVM approximation",
    "authors": [
      "Alberto Carlevaro",
      "Teodoro Alamo",
      "Fabrizio Dabbene",
      "Maurizio Mongelli"
    ],
    "abstract": "Probabilistic guarantees on the prediction of data-driven classifiers are\nnecessary to define models that can be considered reliable. This is a key\nrequirement for modern machine learning in which the goodness of a system is\nmeasured in terms of trustworthiness, clearly dividing what is safe from what\nis unsafe. The spirit of this paper is exactly in this direction. First, we\nintroduce a formal definition of {\\epsilon}-Safe Decision Region, a subset of\nthe input space in which the prediction of a target (safe) class is\nprobabilistically guaranteed. Second, we prove that, when data come from\nexponential family distributions, the form of such a region is analytically\ndetermined and controllable by design parameters, i.e. the probability of\nsampling the target class and the confidence on the prediction. However, the\nrequest of having exponential data is not always possible. Inspired by this\nlimitation, we developed Multi Cost SVM, an SVM based algorithm that\napproximates the safe region and is also able to handle unbalanced data. The\nresearch is complemented by experiments and code available for reproducibility.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17731v1",
    "published_date": "2025-01-29 16:14:35 UTC",
    "updated_date": "2025-01-29 16:14:35 UTC"
  },
  {
    "arxiv_id": "2501.17725v1",
    "title": "Using Code Generation to Solve Open Instances of Combinatorial Design Problems",
    "authors": [
      "Christopher D. Rosin"
    ],
    "abstract": "The Handbook of Combinatorial Designs catalogs many types of combinatorial\ndesigns, together with lists of open instances for which existence has not yet\nbeen determined. We develop a constructive protocol CPro1, which uses Large\nLanguage Models (LLMs) to generate code that constructs combinatorial designs\nand resolves some of these open instances. The protocol starts from a\ndefinition of a particular type of design, and a verifier that reliably\nconfirms whether a proposed design is valid. The LLM selects strategies and\nimplements them in code, and scaffolding provides automated hyperparameter\ntuning and execution feedback using the verifier. Most generated code fails,\nbut by generating many candidates, the protocol automates exploration of a\nvariety of standard methods (e.g. simulated annealing, genetic algorithms) and\nexperimentation with variations (e.g. cost functions) to find successful\napproaches. Testing on 16 different types of designs, CPro1 constructs\nsolutions to open instances for 6 of them: Symmetric and Skew Weighing\nMatrices, Equidistant Permutation Arrays, Packing Arrays, Balanced Ternary\nDesigns, and Florentine Rectangles.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.DM",
      "math.CO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17725v1",
    "published_date": "2025-01-29 15:57:43 UTC",
    "updated_date": "2025-01-29 15:57:43 UTC"
  },
  {
    "arxiv_id": "2501.17704v1",
    "title": "Inferring Implicit Goals Across Differing Task Models",
    "authors": [
      "Silvia Tulli",
      "Stylianos Loukas Vasileiou",
      "Mohamed Chetouani",
      "Sarath Sreedharan"
    ],
    "abstract": "One of the significant challenges to generating value-aligned behavior is to\nnot only account for the specified user objectives but also any implicit or\nunspecified user requirements. The existence of such implicit requirements\ncould be particularly common in settings where the user's understanding of the\ntask model may differ from the agent's estimate of the model. Under this\nscenario, the user may incorrectly expect some agent behavior to be inevitable\nor guaranteed. This paper addresses such expectation mismatch in the presence\nof differing models by capturing the possibility of unspecified user subgoal in\nthe context of a task captured as a Markov Decision Process (MDP) and querying\nfor it as required. Our method identifies bottleneck states and uses them as\ncandidates for potential implicit subgoals. We then introduce a querying\nstrategy that will generate the minimal number of queries required to identify\na policy guaranteed to achieve the underlying goal. Our empirical evaluations\ndemonstrate the effectiveness of our approach in inferring and achieving\nunstated goals across various tasks.",
    "categories": [
      "cs.AI",
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17704v1",
    "published_date": "2025-01-29 15:20:43 UTC",
    "updated_date": "2025-01-29 15:20:43 UTC"
  },
  {
    "arxiv_id": "2501.17699v1",
    "title": "PulmoFusion: Advancing Pulmonary Health with Efficient Multi-Modal Fusion",
    "authors": [
      "Ahmed Sharshar",
      "Yasser Attia",
      "Mohammad Yaqub",
      "Mohsen Guizani"
    ],
    "abstract": "Traditional remote spirometry lacks the precision required for effective\npulmonary monitoring. We present a novel, non-invasive approach using\nmultimodal predictive models that integrate RGB or thermal video data with\npatient metadata. Our method leverages energy-efficient Spiking Neural Networks\n(SNNs) for the regression of Peak Expiratory Flow (PEF) and classification of\nForced Expiratory Volume (FEV1) and Forced Vital Capacity (FVC), using\nlightweight CNNs to overcome SNN limitations in regression tasks. Multimodal\ndata integration is improved with a Multi-Head Attention Layer, and we employ\nK-Fold validation and ensemble learning to boost robustness. Using thermal\ndata, our SNN models achieve 92% accuracy on a breathing-cycle basis and 99.5%\npatient-wise. PEF regression models attain Relative RMSEs of 0.11 (thermal) and\n0.26 (RGB), with an MAE of 4.52% for FEV1/FVC predictions, establishing\nstate-of-the-art performance. Code and dataset can be found on\nhttps://github.com/ahmed-sharshar/RespiroDynamics.git",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17699v1",
    "published_date": "2025-01-29 15:10:09 UTC",
    "updated_date": "2025-01-29 15:10:09 UTC"
  },
  {
    "arxiv_id": "2501.17690v2",
    "title": "Segmentation-Aware Generative Reinforcement Network (GRN) for Tissue Layer Segmentation in 3-D Ultrasound Images for Chronic Low-back Pain (cLBP) Assessment",
    "authors": [
      "Zixue Zeng",
      "Xiaoyan Zhao",
      "Matthew Cartier",
      "Tong Yu",
      "Jing Wang",
      "Xin Meng",
      "Zhiyu Sheng",
      "Maryam Satarpour",
      "John M Cormack",
      "Allison Bean",
      "Ryan Nussbaum",
      "Maya Maurer",
      "Emily Landis-Walkenhorst",
      "Dinesh Kumbhare",
      "Kang Kim",
      "Ajay Wasan",
      "Jiantao Pu"
    ],
    "abstract": "We introduce a novel segmentation-aware joint training framework called\ngenerative reinforcement network (GRN) that integrates segmentation loss\nfeedback to optimize both image generation and segmentation performance in a\nsingle stage. An image enhancement technique called segmentation-guided\nenhancement (SGE) is also developed, where the generator produces images\ntailored specifically for the segmentation model. Two variants of GRN were also\ndeveloped, including GRN for sample-efficient learning (GRN-SEL) and GRN for\nsemi-supervised learning (GRN-SSL). GRN's performance was evaluated using a\ndataset of 69 fully annotated 3D ultrasound scans from 29 subjects. The\nannotations included six anatomical structures: dermis, superficial fat,\nsuperficial fascial membrane (SFM), deep fat, deep fascial membrane (DFM), and\nmuscle. Our results show that GRN-SEL with SGE reduces labeling efforts by up\nto 70% while achieving a 1.98% improvement in the Dice Similarity Coefficient\n(DSC) compared to models trained on fully labeled datasets. GRN-SEL alone\nreduces labeling efforts by 60%, GRN-SSL with SGE decreases labeling\nrequirements by 70%, and GRN-SSL alone by 60%, all while maintaining\nperformance comparable to fully supervised models. These findings suggest the\neffectiveness of the GRN framework in optimizing segmentation performance with\nsignificantly less labeled data, offering a scalable and efficient solution for\nultrasound image analysis and reducing the burdens associated with data\nannotation.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17690v2",
    "published_date": "2025-01-29 14:58:48 UTC",
    "updated_date": "2025-04-30 14:19:58 UTC"
  },
  {
    "arxiv_id": "2501.17688v3",
    "title": "ContourFormer: Real-Time Contour-Based End-to-End Instance Segmentation Transformer",
    "authors": [
      "Weiwei Yao",
      "Chen Li",
      "Minjun Xiong",
      "Wenbo Dong",
      "Hao Chen",
      "Xiong Xiao"
    ],
    "abstract": "This paper presents Contourformer, a real-time contour-based instance\nsegmentation algorithm. The method is fully based on the DETR paradigm and\nachieves end-to-end inference through iterative and progressive mechanisms to\noptimize contours. To improve efficiency and accuracy, we develop two novel\ntechniques: sub-contour decoupling mechanisms and contour fine-grained\ndistribution refinement. In the sub-contour decoupling mechanism, we propose a\ndeformable attention-based module that adaptively selects sampling regions\nbased on the current predicted contour, enabling more effective capturing of\nobject boundary information. Additionally, we design a multi-stage optimization\nprocess to enhance segmentation precision by progressively refining\nsub-contours. The contour fine-grained distribution refinement technique aims\nto further improve the ability to express fine details of contours. These\ninnovations enable Contourformer to achieve stable and precise segmentation for\neach instance while maintaining real-time performance. Extensive experiments\ndemonstrate the superior performance of Contourformer on multiple benchmark\ndatasets, including SBD, COCO, and KINS. We conduct comprehensive evaluations\nand comparisons with existing state-of-the-art methods, showing significant\nimprovements in both accuracy and inference speed. This work provides a new\nsolution for contour-based instance segmentation tasks and lays a foundation\nfor future research, with the potential to become a strong baseline method in\nthis field.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17688v3",
    "published_date": "2025-01-29 14:56:27 UTC",
    "updated_date": "2025-04-15 01:28:50 UTC"
  },
  {
    "arxiv_id": "2502.17445v1",
    "title": "Interpretable Dual-Filter Fuzzy Neural Networks for Affective Brain-Computer Interfaces",
    "authors": [
      "Xiaowei Jiang",
      "Yanan Chen",
      "Nikhil Ranjan Pal",
      "Yu-Cheng Chang",
      "Yunkai Yang",
      "Thomas Do",
      "Chin-Teng Lin"
    ],
    "abstract": "Fuzzy logic provides a robust framework for enhancing explainability,\nparticularly in domains requiring the interpretation of complex and ambiguous\nsignals, such as brain-computer interface (BCI) systems. Despite significant\nadvances in deep learning, interpreting human emotions remains a formidable\nchallenge. In this work, we present iFuzzyAffectDuo, a novel computational\nmodel that integrates a dual-filter fuzzy neural network architecture for\nimproved detection and interpretation of emotional states from neuroimaging\ndata. The model introduces a new membership function (MF) based on the Laplace\ndistribution, achieving superior accuracy and interpretability compared to\ntraditional approaches. By refining the extraction of neural signals associated\nwith specific emotions, iFuzzyAffectDuo offers a human-understandable framework\nthat unravels the underlying decision-making processes. We validate our\napproach across three neuroimaging datasets using functional Near-Infrared\nSpectroscopy (fNIRS) and Electroencephalography (EEG), demonstrating its\npotential to advance affective computing. These findings open new pathways for\nunderstanding the neural basis of emotions and their application in enhancing\nhuman-computer interaction.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.HC",
      "q-bio.NC"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17445v1",
    "published_date": "2025-01-29 14:31:57 UTC",
    "updated_date": "2025-01-29 14:31:57 UTC"
  },
  {
    "arxiv_id": "2501.17905v2",
    "title": "DReSS: Data-driven Regularized Structured Streamlining for Large Language Models",
    "authors": [
      "Mingkuan Feng",
      "Jinyang Wu",
      "Shuai Zhang",
      "Pengpeng Shao",
      "Ruihan Jin",
      "Zhengqi Wen",
      "Jianhua Tao",
      "Feihu Che"
    ],
    "abstract": "Large language models (LLMs) have achieved significant progress across\nvarious domains, but their increasing scale results in high computational and\nmemory costs. Recent studies have revealed that LLMs exhibit sparsity,\nproviding the potential to reduce model size through pruning techniques.\nHowever, existing pruning methods typically follow a prune-then-finetune\nparadigm. Since the pruned components still contain valuable information, their\ndirect removal often leads to irreversible performance degradation, imposing a\nsubstantial computational burden to recover performance during finetuning. In\nthis paper, we propose a novel paradigm that first applies regularization, then\nprunes, and finally finetunes. Based on this paradigm, we introduce DReSS, a\nsimple and effective Data-driven Regularized Structured Streamlining method for\nLLMs. By leveraging a small amount of data to regularize the components to be\npruned, DReSS explicitly transfers the important information to the remaining\nparts of the model in advance. Compared to direct pruning, this can reduce the\ninformation loss caused by parameter removal, thereby enhancing its language\nmodeling capabilities. Experimental results demonstrate that DReSS\nsignificantly outperforms existing pruning methods even under extreme pruning\nratios, significantly reducing latency and increasing throughput.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17905v2",
    "published_date": "2025-01-29 14:28:11 UTC",
    "updated_date": "2025-02-10 04:07:04 UTC"
  },
  {
    "arxiv_id": "2502.00055v1",
    "title": "Towards Recommender Systems LLMs Playground (RecSysLLMsP): Exploring Polarization and Engagement in Simulated Social Networks",
    "authors": [
      "Ljubisa Bojic",
      "Zorica Dodevska",
      "Yashar Deldjoo",
      "Nenad Pantelic"
    ],
    "abstract": "Given the exponential advancement in AI technologies and the potential\nescalation of harmful effects from recommendation systems, it is crucial to\nsimulate and evaluate these effects early on. Doing so can help prevent\npossible damage to both societies and technology companies. This paper\nintroduces the Recommender Systems LLMs Playground (RecSysLLMsP), a novel\nsimulation framework leveraging Large Language Models (LLMs) to explore the\nimpacts of different content recommendation setups on user engagement and\npolarization in social networks. By creating diverse AI agents (AgentPrompts)\nwith descriptive, static, and dynamic attributes, we assess their autonomous\nbehaviour across three scenarios: Plurality, Balanced, and Similarity. Our\nfindings reveal that the Similarity Scenario, which aligns content with user\npreferences, maximizes engagement while potentially fostering echo chambers.\nConversely, the Plurality Scenario promotes diverse interactions but produces\nmixed engagement results. Our study emphasizes the need for a careful balance\nin recommender system designs to enhance user satisfaction while mitigating\nsocietal polarization. It underscores the unique value and challenges of\nincorporating LLMs into simulation environments. The benefits of RecSysLLMsP\nlie in its potential to calculate polarization effects, which is crucial for\nassessing societal impacts and determining user engagement levels with diverse\nrecommender system setups. This advantage is essential for developing and\nmaintaining a successful business model for social media companies. However,\nthe study's limitations revolve around accurately emulating reality. Future\nefforts should validate the similarity in behaviour between real humans and\nAgentPrompts and establish metrics for measuring polarization scores.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.CY",
      "cs.HC",
      "cs.IR"
    ],
    "primary_category": "cs.SI",
    "comment": "8 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.00055v1",
    "published_date": "2025-01-29 14:23:34 UTC",
    "updated_date": "2025-01-29 14:23:34 UTC"
  },
  {
    "arxiv_id": "2501.17665v1",
    "title": "Planning with Vision-Language Models and a Use Case in Robot-Assisted Teaching",
    "authors": [
      "Xuzhe Dang",
      "Lada Kudl√°ƒçkov√°",
      "Stefan Edelkamp"
    ],
    "abstract": "Automating the generation of Planning Domain Definition Language (PDDL) with\nLarge Language Model (LLM) opens new research topic in AI planning,\nparticularly for complex real-world tasks. This paper introduces Image2PDDL, a\nnovel framework that leverages Vision-Language Models (VLMs) to automatically\nconvert images of initial states and descriptions of goal states into PDDL\nproblems. By providing a PDDL domain alongside visual inputs, Imasge2PDDL\naddresses key challenges in bridging perceptual understanding with symbolic\nplanning, reducing the expertise required to create structured problem\ninstances, and improving scalability across tasks of varying complexity. We\nevaluate the framework on various domains, including standard planning domains\nlike blocksworld and sliding tile puzzles, using datasets with multiple\ndifficulty levels. Performance is assessed on syntax correctness, ensuring\ngrammar and executability, and content correctness, verifying accurate state\nrepresentation in generated PDDL problems. The proposed approach demonstrates\npromising results across diverse task complexities, suggesting its potential\nfor broader applications in AI planning. We will discuss a potential use case\nin robot-assisted teaching of students with Autism Spectrum Disorder.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17665v1",
    "published_date": "2025-01-29 14:04:54 UTC",
    "updated_date": "2025-01-29 14:04:54 UTC"
  },
  {
    "arxiv_id": "2501.17654v1",
    "title": "Exploring Vision Language Models for Multimodal and Multilingual Stance Detection",
    "authors": [
      "Jake Vasilakes",
      "Carolina Scarton",
      "Zhixue Zhao"
    ],
    "abstract": "Social media's global reach amplifies the spread of information, highlighting\nthe need for robust Natural Language Processing tasks like stance detection\nacross languages and modalities. Prior research predominantly focuses on\ntext-only inputs, leaving multimodal scenarios, such as those involving both\nimages and text, relatively underexplored. Meanwhile, the prevalence of\nmultimodal posts has increased significantly in recent years. Although\nstate-of-the-art Vision-Language Models (VLMs) show promise, their performance\non multimodal and multilingual stance detection tasks remains largely\nunexamined. This paper evaluates state-of-the-art VLMs on a newly extended\ndataset covering seven languages and multimodal inputs, investigating their use\nof visual cues, language-specific performance, and cross-modality interactions.\nOur results show that VLMs generally rely more on text than images for stance\ndetection and this trend persists across languages. Additionally, VLMs rely\nsignificantly more on text contained within the images than other visual\ncontent. Regarding multilinguality, the models studied tend to generate\nconsistent predictions across languages whether they are explicitly\nmultilingual or not, although there are outliers that are incongruous with\nmacro F1, language support, and model size.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Submitted to the International AAAI Conference on Web and Social\n  Media (ICWSM) 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.17654v1",
    "published_date": "2025-01-29 13:39:53 UTC",
    "updated_date": "2025-01-29 13:39:53 UTC"
  },
  {
    "arxiv_id": "2501.17643v1",
    "title": "Tonguescape: Exploring Language Models Understanding of Vowel Articulation",
    "authors": [
      "Haruki Sakajo",
      "Yusuke Sakai",
      "Hidetaka Kamigaito",
      "Taro Watanabe"
    ],
    "abstract": "Vowels are primarily characterized by tongue position. Humans have discovered\nthese features of vowel articulation through their own experience and explicit\nobjective observation such as using MRI. With this knowledge and our\nexperience, we can explain and understand the relationship between tongue\npositions and vowels, and this knowledge is helpful for language learners to\nlearn pronunciation. Since language models (LMs) are trained on a large amount\nof data that includes linguistic and medical fields, our preliminary studies\nindicate that an LM is able to explain the pronunciation mechanisms of vowels.\nHowever, it is unclear whether multi-modal LMs, such as vision LMs, align\ntextual information with visual information. One question arises: do LMs\nassociate real tongue positions with vowel articulation? In this study, we\ncreated video and image datasets from the existing real-time MRI dataset and\ninvestigated whether LMs can understand vowel articulation based on tongue\npositions using vision-based information. Our findings suggest that LMs exhibit\npotential for understanding vowels and tongue positions when reference examples\nare provided while they have difficulties without them. Our code for dataset\nbuilding is available on GitHub.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to NAACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.17643v1",
    "published_date": "2025-01-29 13:25:20 UTC",
    "updated_date": "2025-01-29 13:25:20 UTC"
  },
  {
    "arxiv_id": "2501.18645v2",
    "title": "Layered Chain-of-Thought Prompting for Multi-Agent LLM Systems: A Comprehensive Approach to Explainable Large Language Models",
    "authors": [
      "Manish Sanwal"
    ],
    "abstract": "Large Language Models (LLMs) leverage chain-of-thought (CoT) prompting to\nprovide step-by-step rationales, improving performance on complex tasks.\nDespite its benefits, vanilla CoT often fails to fully verify intermediate\ninferences and can produce misleading explanations. In this work, we propose\nLayered Chain-of-Thought (Layered-CoT) Prompting, a novel framework that\nsystematically segments the reasoning process into multiple layers, each\nsubjected to external checks and optional user feedback. We expand on the key\nconcepts, present three scenarios -- medical triage, financial risk assessment,\nand agile engineering -- and demonstrate how Layered-CoT surpasses vanilla CoT\nin terms of transparency, correctness, and user engagement. By integrating\nreferences from recent arXiv papers on interactive explainability, multi-agent\nframeworks, and agent-based collaboration, we illustrate how Layered-CoT paves\nthe way for more reliable and grounded explanations in high-stakes domains.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18645v2",
    "published_date": "2025-01-29 13:21:09 UTC",
    "updated_date": "2025-02-03 15:51:11 UTC"
  },
  {
    "arxiv_id": "2501.17635v2",
    "title": "In-Context Meta LoRA Generation",
    "authors": [
      "Yihua Shao",
      "Minxi Yan",
      "Yang Liu",
      "Siyu Chen",
      "Wenjie Chen",
      "Xinwei Long",
      "Ziyang Yan",
      "Lei Li",
      "Chenyu Zhang",
      "Nicu Sebe",
      "Hao Tang",
      "Yan Wang",
      "Hao Zhao",
      "Mengzhu Wang",
      "Jingcai Guo"
    ],
    "abstract": "Low-rank Adaptation (LoRA) has demonstrated remarkable capabilities for task\nspecific fine-tuning. However, in scenarios that involve multiple tasks,\ntraining a separate LoRA model for each one results in considerable\ninefficiency in terms of storage and inference. Moreover, existing parameter\ngeneration methods fail to capture the correlations among these tasks, making\nmulti-task LoRA parameter generation challenging. To address these limitations,\nwe propose In-Context Meta LoRA (ICM-LoRA), a novel approach that efficiently\nachieves task-specific customization of large language models (LLMs).\nSpecifically, we use training data from all tasks to train a tailored\ngenerator, Conditional Variational Autoencoder (CVAE). CVAE takes task\ndescriptions as inputs and produces task-aware LoRA weights as outputs. These\nLoRA weights are then merged with LLMs to create task-specialized models\nwithout the need for additional fine-tuning. Furthermore, we utilize in-context\nmeta-learning for knowledge enhancement and task mapping, to capture the\nrelationship between tasks and parameter distributions. As a result, our method\nachieves more accurate LoRA parameter generation for diverse tasks using CVAE.\nICM-LoRA enables more accurate LoRA parameter reconstruction than current\nparameter reconstruction methods and is useful for implementing task-specific\nenhancements of LoRA parameters. At the same time, our method occupies 283MB,\nonly 1\\% storage compared with the original LoRA.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17635v2",
    "published_date": "2025-01-29 13:12:01 UTC",
    "updated_date": "2025-01-30 17:59:08 UTC"
  },
  {
    "arxiv_id": "2501.17629v1",
    "title": "The Imitation Game According To Turing",
    "authors": [
      "Sharon Temtsin",
      "Diane Proudfoot",
      "David Kaber",
      "Christoph Bartneck"
    ],
    "abstract": "The current cycle of hype and anxiety concerning the benefits and risks to\nhuman society of Artificial Intelligence is fuelled, not only by the increasing\nuse of generative AI and other AI tools by the general public, but also by\nclaims made on behalf of such technology by popularizers and scientists. In\nparticular, recent studies have claimed that Large Language Models (LLMs) can\npass the Turing Test-a goal for AI since the 1950s-and therefore can \"think\".\nLarge-scale impacts on society have been predicted as a result. Upon detailed\nexamination, however, none of these studies has faithfully applied Turing's\noriginal instructions. Consequently, we conducted a rigorous Turing Test with\nGPT-4-Turbo that adhered closely to Turing's instructions for a three-player\nimitation game. We followed established scientific standards where Turing's\ninstructions were ambiguous or missing. For example, we performed a\nComputer-Imitates-Human Game (CIHG) without constraining the time duration and\nconducted a Man-Imitates-Woman Game (MIWG) as a benchmark. All but one\nparticipant correctly identified the LLM, showing that one of today's most\nadvanced LLMs is unable to pass a rigorous Turing Test. We conclude that recent\nextravagant claims for such models are unsupported, and do not warrant either\noptimism or concern about the social impact of thinking machines.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17629v1",
    "published_date": "2025-01-29 13:08:17 UTC",
    "updated_date": "2025-01-29 13:08:17 UTC"
  },
  {
    "arxiv_id": "2501.17903v2",
    "title": "Free Agent in Agent-Based Mixture-of-Experts Generative AI Framework",
    "authors": [
      "Jung-Hua Liu"
    ],
    "abstract": "Multi-agent systems commonly distribute tasks among specialized, autonomous\nagents, yet they often lack mechanisms to replace or reassign underperforming\nagents in real time. Inspired by the free-agency model of Major League\nBaseball, the Reinforcement Learning Free Agent (RLFA) algorithm introduces a\nreward-based mechanism to detect and remove agents exhibiting persistent\nunderperformance and seamlessly insert more capable ones. Each agent internally\nuses a mixture-of-experts (MoE) approach, delegating incoming tasks to\nspecialized sub-models under the guidance of a gating function. A primary use\ncase is fraud detection, where RLFA promptly swaps out an agent whose detection\naccuracy dips below a preset threshold. A new agent is tested in a probationary\nmode, and upon demonstrating superior performance, fully replaces the\nunderperformer. This dynamic, free-agency cycle ensures sustained accuracy,\nquicker adaptation to emerging threats, and minimal disruption to ongoing\noperations. By continually refreshing its roster of agents, the system fosters\nongoing improvements and more resilient collaboration in multi-agent Generative\nAI environments.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17903v2",
    "published_date": "2025-01-29 13:00:22 UTC",
    "updated_date": "2025-02-10 16:13:08 UTC"
  },
  {
    "arxiv_id": "2501.17612v1",
    "title": "VoicePrompter: Robust Zero-Shot Voice Conversion with Voice Prompt and Conditional Flow Matching",
    "authors": [
      "Ha-Yeong Choi",
      "Jaehan Park"
    ],
    "abstract": "Despite remarkable advancements in recent voice conversion (VC) systems,\nenhancing speaker similarity in zero-shot scenarios remains challenging. This\nchallenge arises from the difficulty of generalizing and adapting speaker\ncharacteristics in speech within zero-shot environments, which is further\ncomplicated by mismatch between the training and inference processes. To\naddress these challenges, we propose VoicePrompter, a robust zero-shot VC model\nthat leverages in-context learning with voice prompts. VoicePrompter is\ncomposed of (1) a factorization method that disentangles speech components and\n(2) a DiT-based conditional flow matching (CFM) decoder that conditions on\nthese factorized features and voice prompts. Additionally, (3) latent mixup is\nused to enhance in-context learning by combining various speaker features. This\napproach improves speaker similarity and naturalness in zero-shot VC by\napplying mixup to latent representations. Experimental results demonstrate that\nVoicePrompter outperforms existing zero-shot VC systems in terms of speaker\nsimilarity, speech intelligibility, and audio quality. Our demo is available at\n\\url{https://hayeong0.github.io/VoicePrompter-demo/}.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS",
      "eess.SP"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted at ICASSP 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.17612v1",
    "published_date": "2025-01-29 12:34:58 UTC",
    "updated_date": "2025-01-29 12:34:58 UTC"
  },
  {
    "arxiv_id": "2501.17581v2",
    "title": "CSEval: Towards Automated, Multi-Dimensional, and Reference-Free Counterspeech Evaluation using Auto-Calibrated LLMs",
    "authors": [
      "Amey Hengle",
      "Aswini Kumar",
      "Anil Bandhakavi",
      "Tanmoy Chakraborty"
    ],
    "abstract": "Counterspeech has emerged as a popular and effective strategy for combating\nonline hate speech, sparking growing research interest in automating its\ngeneration using language models. However, the field still lacks standardised\nevaluation protocols and reliable automated evaluation metrics that align with\nhuman judgement. Current automatic evaluation methods, primarily based on\nsimilarity metrics, do not effectively capture the complex and independent\nattributes of counterspeech quality, such as contextual relevance,\naggressiveness, or argumentative coherence. This has led to an increased\ndependency on labor-intensive human evaluations to assess automated\ncounter-speech generation methods. To address these challenges, we introduce\nCSEval, a novel dataset and framework for evaluating counterspeech quality\nacross four dimensions: contextual-relevance, aggressiveness,\nargument-coherence, and suitableness. Furthermore, we propose Auto-Calibrated\nCOT for Counterspeech Evaluation (Auto-CSEval), a prompt-based method with\nauto-calibrated chain-of-thoughts (CoT) for scoring counterspeech using large\nlanguage models. Our experiments show that Auto-CSEval outperforms traditional\nmetrics like ROUGE, METEOR, and BertScore in correlating with human judgement,\nindicating a significant improvement in automated counterspeech evaluation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.SI"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.17581v2",
    "published_date": "2025-01-29 11:38:29 UTC",
    "updated_date": "2025-02-09 17:49:08 UTC"
  },
  {
    "arxiv_id": "2501.17578v1",
    "title": "Music2Latent2: Audio Compression with Summary Embeddings and Autoregressive Decoding",
    "authors": [
      "Marco Pasini",
      "Stefan Lattner",
      "George Fazekas"
    ],
    "abstract": "Efficiently compressing high-dimensional audio signals into a compact and\ninformative latent space is crucial for various tasks, including generative\nmodeling and music information retrieval (MIR). Existing audio autoencoders,\nhowever, often struggle to achieve high compression ratios while preserving\naudio fidelity and facilitating efficient downstream applications. We introduce\nMusic2Latent2, a novel audio autoencoder that addresses these limitations by\nleveraging consistency models and a novel approach to representation learning\nbased on unordered latent embeddings, which we call summary embeddings. Unlike\nconventional methods that encode local audio features into ordered sequences,\nMusic2Latent2 compresses audio signals into sets of summary embeddings, where\neach embedding can capture distinct global features of the input sample. This\nenables to achieve higher reconstruction quality at the same compression ratio.\nTo handle arbitrary audio lengths, Music2Latent2 employs an autoregressive\nconsistency model trained on two consecutive audio chunks with causal masking,\nensuring coherent reconstruction across segment boundaries. Additionally, we\npropose a novel two-step decoding procedure that leverages the denoising\ncapabilities of consistency models to further refine the generated audio at no\nadditional cost. Our experiments demonstrate that Music2Latent2 outperforms\nexisting continuous audio autoencoders regarding audio quality and performance\non downstream tasks. Music2Latent2 paves the way for new possibilities in audio\ncompression.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted to ICASSP 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.17578v1",
    "published_date": "2025-01-29 11:34:19 UTC",
    "updated_date": "2025-01-29 11:34:19 UTC"
  },
  {
    "arxiv_id": "2501.17567v2",
    "title": "Exploring the Potential of Wireless-enabled Multi-Chip AI Accelerators",
    "authors": [
      "Emmanuel Irabor",
      "Mariam Musavi",
      "Abhijit Das",
      "Sergi Abadal"
    ],
    "abstract": "The insatiable appetite of Artificial Intelligence (AI) workloads for\ncomputing power is pushing the industry to develop faster and more efficient\naccelerators. The rigidity of custom hardware, however, conflicts with the need\nfor scalable and versatile architectures capable of catering to the needs of\nthe evolving and heterogeneous pool of Machine Learning (ML) models in the\nliterature. In this context, multi-chiplet architectures assembling multiple\n(perhaps heterogeneous) accelerators are an appealing option that is\nunfortunately hindered by the still rigid and inefficient chip-to-chip\ninterconnects. In this paper, we explore the potential of wireless technology\nas a complement to existing wired interconnects in this multi-chiplet approach.\nUsing an evaluation framework from the state-of-the-art, we show that wireless\ninterconnects can lead to speedups of 10% on average and 20% maximum. We also\nhighlight the importance of load balancing between the wired and wireless\ninterconnects, which will be further explored in future work.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "Accepted in AccML @ HiPEAC 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.17567v2",
    "published_date": "2025-01-29 11:00:09 UTC",
    "updated_date": "2025-04-28 05:42:09 UTC"
  },
  {
    "arxiv_id": "2501.17559v1",
    "title": "Solving Urban Network Security Games: Learning Platform, Benchmark, and Challenge for AI Research",
    "authors": [
      "Shuxin Zhuang",
      "Shuxin Li",
      "Tianji Yang",
      "Muheng Li",
      "Xianjie Shi",
      "Bo An",
      "Youzhi Zhang"
    ],
    "abstract": "After the great achievement of solving two-player zero-sum games, more and\nmore AI researchers focus on solving multiplayer games. To facilitate the\ndevelopment of designing efficient learning algorithms for solving multiplayer\ngames, we propose a multiplayer game platform for solving Urban Network\nSecurity Games (\\textbf{UNSG}) that model real-world scenarios. That is,\npreventing criminal activity is a highly significant responsibility assigned to\npolice officers in cities, and police officers have to allocate their limited\nsecurity resources to interdict the escaping criminal when a crime takes place\nin a city. This interaction between multiple police officers and the escaping\ncriminal can be modeled as a UNSG. The variants of UNSGs can model different\nreal-world settings, e.g., whether real-time information is available or not,\nand whether police officers can communicate or not. The main challenges of\nsolving this game include the large size of the game and the co-existence of\ncooperation and competition. While previous efforts have been made to tackle\nUNSGs, they have been hampered by performance and scalability issues.\nTherefore, we propose an open-source UNSG platform (\\textbf{GraphChase}) for\ndesigning efficient learning algorithms for solving UNSGs. Specifically,\nGraphChase offers a unified and flexible game environment for modeling various\nvariants of UNSGs, supporting the development, testing, and benchmarking of\nalgorithms. We believe that GraphChase not only facilitates the development of\nefficient algorithms for solving real-world problems but also paves the way for\nsignificant advancements in algorithmic development for solving general\nmultiplayer games.",
    "categories": [
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17559v1",
    "published_date": "2025-01-29 10:46:57 UTC",
    "updated_date": "2025-01-29 10:46:57 UTC"
  },
  {
    "arxiv_id": "2501.17555v1",
    "title": "An Exceptional Dataset For Rare Pancreatic Tumor Segmentation",
    "authors": [
      "Wenqi Li",
      "Yingli Chen",
      "Keyang Zhou",
      "Xiaoxiao Hu",
      "Zilu Zheng",
      "Yue Yan",
      "Xinpeng Zhang",
      "Wei Tang",
      "Zhenxing Qian"
    ],
    "abstract": "Pancreatic NEuroendocrine Tumors (pNETs) are very rare endocrine neoplasms\nthat account for less than 5% of all pancreatic malignancies, with an incidence\nof only 1-1.5 cases per 100,000. Early detection of pNETs is critical for\nimproving patient survival, but the rarity of pNETs makes segmenting them from\nCT a very challenging problem. So far, there has not been a dataset\nspecifically for pNETs available to researchers. To address this issue, we\npropose a pNETs dataset, a well-annotated Contrast-Enhanced Computed Tomography\n(CECT) dataset focused exclusively on Pancreatic Neuroendocrine Tumors,\ncontaining data from 469 patients. This is the first dataset solely dedicated\nto pNETs, distinguishing it from previous collections. Additionally, we provide\nthe baseline detection networks with a new slice-wise weight loss function\ndesigned for the UNet-based model, improving the overall pNET segmentation\nperformance. We hope that our dataset can enhance the understanding and\ndiagnosis of pNET Tumors within the medical community, facilitate the\ndevelopment of more accurate diagnostic tools, and ultimately improve patient\noutcomes and advance the field of oncology.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17555v1",
    "published_date": "2025-01-29 10:43:07 UTC",
    "updated_date": "2025-01-29 10:43:07 UTC"
  },
  {
    "arxiv_id": "2501.17546v1",
    "title": "Is Conversational XAI All You Need? Human-AI Decision Making With a Conversational XAI Assistant",
    "authors": [
      "Gaole He",
      "Nilay Aishwarya",
      "Ujwal Gadiraju"
    ],
    "abstract": "Explainable artificial intelligence (XAI) methods are being proposed to help\ninterpret and understand how AI systems reach specific predictions. Inspired by\nprior work on conversational user interfaces, we argue that augmenting existing\nXAI methods with conversational user interfaces can increase user engagement\nand boost user understanding of the AI system. In this paper, we explored the\nimpact of a conversational XAI interface on users' understanding of the AI\nsystem, their trust, and reliance on the AI system. In comparison to an XAI\ndashboard, we found that the conversational XAI interface can bring about a\nbetter understanding of the AI system among users and higher user trust.\nHowever, users of both the XAI dashboard and conversational XAI interfaces\nshowed clear overreliance on the AI system. Enhanced conversations powered by\nlarge language model (LLM) agents amplified over-reliance. Based on our\nfindings, we reason that the potential cause of such overreliance is the\nillusion of explanatory depth that is concomitant with both XAI interfaces. Our\nfindings have important implications for designing effective conversational XAI\ninterfaces to facilitate appropriate reliance and improve human-AI\ncollaboration. Code can be found at\nhttps://github.com/delftcrowd/IUI2025_ConvXAI",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "conditionally accepted to IUI 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.17546v1",
    "published_date": "2025-01-29 10:29:27 UTC",
    "updated_date": "2025-01-29 10:29:27 UTC"
  },
  {
    "arxiv_id": "2501.17518v1",
    "title": "RegD: Hierarchical Embeddings via Distances over Geometric Regions",
    "authors": [
      "Hui Yang",
      "Jiaoyan Chen"
    ],
    "abstract": "Hierarchical data are common in many domains like life sciences and\ne-commerce, and their embeddings often play a critical role. Although\nhyperbolic embeddings offer a grounded approach to representing hierarchical\nstructures in low-dimensional spaces, their utility is hindered by optimization\ndifficulties in hyperbolic space and dependence on handcrafted structural\nconstraints. We propose RegD, a novel Euclidean framework that addresses these\nlimitations by representing hierarchical data as geometric regions with two new\nmetrics: (1) depth distance, which preserves the representational power of\nhyperbolic spaces for hierarchical data, and (2) boundary distance, which\nexplicitly encodes set-inclusion relationships between regions in a general\nway. Our empirical evaluation on diverse real-world datasets shows consistent\nperformance gains over state-of-the-art methods and demonstrates RegD's\npotential for broader applications beyond hierarchy alone tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17518v1",
    "published_date": "2025-01-29 09:44:03 UTC",
    "updated_date": "2025-01-29 09:44:03 UTC"
  },
  {
    "arxiv_id": "2501.17510v1",
    "title": "LLM Assistance for Pediatric Depression",
    "authors": [
      "Mariia Ignashina",
      "Paulina Bondaronek",
      "Dan Santel",
      "John Pestian",
      "Julia Ive"
    ],
    "abstract": "Traditional depression screening methods, such as the PHQ-9, are particularly\nchallenging for children in pediatric primary care due to practical\nlimitations. AI has the potential to help, but the scarcity of annotated\ndatasets in mental health, combined with the computational costs of training,\nhighlights the need for efficient, zero-shot approaches. In this work, we\ninvestigate the feasibility of state-of-the-art LLMs for depressive symptom\nextraction in pediatric settings (ages 6-24). This approach aims to complement\ntraditional screening and minimize diagnostic errors.\n  Our findings show that all LLMs are 60% more efficient than word match, with\nFlan leading in precision (average F1: 0.65, precision: 0.78), excelling in the\nextraction of more rare symptoms like \"sleep problems\" (F1: 0.92) and\n\"self-loathing\" (F1: 0.8). Phi strikes a balance between precision (0.44) and\nrecall (0.60), performing well in categories like \"Feeling depressed\" (0.69)\nand \"Weight change\" (0.78). Llama 3, with the highest recall (0.90),\novergeneralizes symptoms, making it less suitable for this type of analysis.\nChallenges include the complexity of clinical notes and overgeneralization from\nPHQ-9 scores. The main challenges faced by LLMs include navigating the complex\nstructure of clinical notes with content from different times in the patient\ntrajectory, as well as misinterpreting elevated PHQ-9 scores.\n  We finally demonstrate the utility of symptom annotations provided by Flan as\nfeatures in an ML algorithm, which differentiates depression cases from\ncontrols with high precision of 0.78, showing a major performance boost\ncompared to a baseline that does not use these features.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17510v1",
    "published_date": "2025-01-29 09:27:27 UTC",
    "updated_date": "2025-01-29 09:27:27 UTC"
  },
  {
    "arxiv_id": "2501.17507v1",
    "title": "Reflections on \"Can AI Understand Our Universe?\"",
    "authors": [
      "Yu Wang"
    ],
    "abstract": "This article briefly discusses the philosophical and technical aspects of AI.\nIt focuses on two concepts of understanding: intuition and causality, and\nhighlights three AI technologies: Transformers, chain-of-thought reasoning, and\nmultimodal processing. We anticipate that in principle AI could form\nunderstanding, with these technologies representing promising advancements.",
    "categories": [
      "cs.AI",
      "astro-ph.HE",
      "astro-ph.IM"
    ],
    "primary_category": "cs.AI",
    "comment": "Invited talk at the 17th Marcel Grossmann Meeting, associated with\n  arXiv:2404.10019, to be published in the International Journal of Modern\n  Physics D",
    "pdf_url": "http://arxiv.org/pdf/2501.17507v1",
    "published_date": "2025-01-29 09:24:47 UTC",
    "updated_date": "2025-01-29 09:24:47 UTC"
  },
  {
    "arxiv_id": "2501.17496v2",
    "title": "SemML: Enhancing Automata-Theoretic LTL Synthesis with Machine Learning",
    "authors": [
      "Jan Kretinsky",
      "Tobias Meggendorfer",
      "Maximilian Prokop",
      "Ashkan Zarkhah"
    ],
    "abstract": "Synthesizing a reactive system from specifications given in linear temporal\nlogic (LTL) is a classical problem, finding its applications in safety-critical\nsystems design. We present our tool SemML, which won this year's LTL\nrealizability tracks of SYNTCOMP, after years of domination by Strix. While\nboth tools are based on the automata-theoretic approach, ours relies heavily on\n(i) Semantic labelling, additional information of logical nature, coming from\nrecent LTL-to-automata translations and decorating the resulting parity game,\nand (ii) Machine Learning approaches turning this information into a guidance\noracle for on-the-fly exploration of the parity game (whence the name SemML).\nOur tool fills the missing gaps of previous suggestions to use such an oracle\nand provides an efficeint implementation with additional algorithmic\nimprovements. We evaluate SemML both on the entire set of SYNTCOMP as well as a\nsynthetic data set, compare it to Strix, and analyze the advantages and\nlimitations. As SemML solves more instances on SYNTCOMP and does so\nsignificantly faster on larger instances, this demonstrates for the first time\nthat machine-learning-aided approaches can out-perform state-of-the-art tools\nin real LTL synthesis.",
    "categories": [
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17496v2",
    "published_date": "2025-01-29 09:06:19 UTC",
    "updated_date": "2025-04-17 13:54:55 UTC"
  },
  {
    "arxiv_id": "2501.17493v1",
    "title": "Certifying Pareto-Optimality in Multi-Objective Maximum Satisfiability",
    "authors": [
      "Christoph Jabs",
      "Jeremias Berg",
      "Bart Bogaerts",
      "Matti J√§rvisalo"
    ],
    "abstract": "Due to the wide employment of automated reasoning in the analysis and\nconstruction of correct systems, the results reported by automated reasoning\nengines must be trustworthy. For Boolean satisfiability (SAT) solvers - and\nmore recently SAT-based maximum satisfiability (MaxSAT) solvers -\ntrustworthiness is obtained by integrating proof logging into solvers, making\nsolvers capable of emitting machine-verifiable proofs to certify correctness of\nthe reasoning steps performed. In this work, we enable for the first time proof\nlogging based on the VeriPB proof format for multi-objective MaxSAT (MO-MaxSAT)\noptimization techniques. Although VeriPB does not offer direct support for\nmulti-objective problems, we detail how preorders in VeriPB can be used to\nprovide certificates for MO-MaxSAT algorithms computing a representative\nsolution for each element in the non-dominated set of the search space under\nPareto-optimality, without extending the VeriPB format or the proof checker. By\nimplementing VeriPB proof logging into a state-of-the-art multi-objective\nMaxSAT solver, we show empirically that proof logging can be made scalable for\nMO-MaxSAT with reasonable overhead.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17493v1",
    "published_date": "2025-01-29 09:01:26 UTC",
    "updated_date": "2025-01-29 09:01:26 UTC"
  },
  {
    "arxiv_id": "2501.17489v1",
    "title": "Neural Spelling: A Spell-Based BCI System for Language Neural Decoding",
    "authors": [
      "Xiaowei Jiang",
      "Charles Zhou",
      "Yiqun Duan",
      "Ziyi Zhao",
      "Thomas Do",
      "Chin-Teng Lin"
    ],
    "abstract": "Brain-computer interfaces (BCIs) present a promising avenue by translating\nneural activity directly into text, eliminating the need for physical actions.\nHowever, existing non-invasive BCI systems have not successfully covered the\nentire alphabet, limiting their practicality. In this paper, we propose a novel\nnon-invasive EEG-based BCI system with Curriculum-based Neural Spelling\nFramework, which recognizes all 26 alphabet letters by decoding neural signals\nassociated with handwriting first, and then apply a Generative AI (GenAI) to\nenhance spell-based neural language decoding tasks. Our approach combines the\nease of handwriting with the accessibility of EEG technology, utilizing\nadvanced neural decoding algorithms and pre-trained large language models\n(LLMs) to translate EEG patterns into text with high accuracy. This system show\nhow GenAI can improve the performance of typical spelling-based neural language\ndecoding task, and addresses the limitations of previous methods, offering a\nscalable and user-friendly solution for individuals with communication\nimpairments, thereby enhancing inclusive communication options.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17489v1",
    "published_date": "2025-01-29 08:57:51 UTC",
    "updated_date": "2025-01-29 08:57:51 UTC"
  },
  {
    "arxiv_id": "2501.17486v1",
    "title": "DINT Transformer",
    "authors": [
      "Yueyang Cang",
      "Yuhang Liu",
      "Xiaoteng Zhang",
      "Erlu Zhao",
      "Li Shi"
    ],
    "abstract": "DIFF Transformer addresses the issue of irrelevant context interference by\nintroducing a differential attention mechanism that enhances the robustness of\nlocal attention. However, it has two critical limitations: the lack of global\ncontext modeling, which is essential for identifying globally significant\ntokens, and numerical instability due to the absence of strict row\nnormalization in the attention matrix. To overcome these challenges, we propose\nDINT Transformer, which extends DIFF Transformer by incorporating a\ndifferential-integral mechanism. By computing global importance scores and\nintegrating them into the attention matrix, DINT Transformer improves its\nability to capture global dependencies. Moreover, the unified parameter design\nenforces row-normalized attention matrices, improving numerical stability.\nExperimental results demonstrate that DINT Transformer excels in accuracy and\nrobustness across various practical applications, such as long-context language\nmodeling and key information retrieval. These results position DINT Transformer\nas a highly effective and promising architecture.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "arXiv admin note: text overlap with arXiv:2410.05258 by other authors",
    "pdf_url": "http://arxiv.org/pdf/2501.17486v1",
    "published_date": "2025-01-29 08:53:29 UTC",
    "updated_date": "2025-01-29 08:53:29 UTC"
  },
  {
    "arxiv_id": "2501.17479v2",
    "title": "DFPE: A Diverse Fingerprint Ensemble for Enhancing LLM Performance",
    "authors": [
      "Seffi Cohen",
      "Niv Goldshlager",
      "Nurit Cohen-Inger",
      "Bracha Shapira",
      "Lior Rokach"
    ],
    "abstract": "Large Language Models (LLMs) have shown remarkable capabilities across\nvarious natural language processing tasks but often struggle to excel uniformly\nin diverse or complex domains. We propose a novel ensemble method - Diverse\nFingerprint Ensemble (DFPE), which leverages the complementary strengths of\nmultiple LLMs to achieve more robust performance. Our approach involves: (1)\nclustering models based on response \"fingerprints\" patterns, (2) applying a\nquantile-based filtering mechanism to remove underperforming models at a\nper-subject level, and (3) assigning adaptive weights to remaining models based\non their subject-wise validation accuracy. In experiments on the Massive\nMultitask Language Understanding (MMLU) benchmark, DFPE outperforms the best\nsingle model by 3% overall accuracy and 5% in discipline-level accuracy. This\nmethod increases the robustness and generalization of LLMs and underscores how\nmodel selection, diversity preservation, and performance-driven weighting can\neffectively address challenging, multi-faceted language understanding tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17479v2",
    "published_date": "2025-01-29 08:44:45 UTC",
    "updated_date": "2025-02-06 21:47:55 UTC"
  },
  {
    "arxiv_id": "2501.17459v1",
    "title": "Large Language Models for Single-Step and Multi-Step Flight Trajectory Prediction",
    "authors": [
      "Kaiwei Luo",
      "Jiliu Zhou"
    ],
    "abstract": "Flight trajectory prediction is a critical time series task in aviation.\nWhile deep learning methods have shown significant promise, the application of\nlarge language models (LLMs) to this domain remains underexplored. This study\npioneers the use of LLMs for flight trajectory prediction by reframing it as a\nlanguage modeling problem. Specifically, We extract features representing the\naircraft's position and status from ADS-B flight data to construct a\nprompt-based dataset, where trajectory waypoints are converted into language\ntokens. The dataset is then employed to fine-tune LLMs, enabling them to learn\ncomplex spatiotemporal patterns for accurate predictions. Comprehensive\nexperiments demonstrate that LLMs achieve notable performance improvements in\nboth single-step and multi-step predictions compared to traditional methods,\nwith LLaMA-3.1 model achieving the highest overall accuracy. However, the high\ninference latency of LLMs poses a challenge for real-time applications,\nunderscoring the need for further research in this promising direction.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.17459v1",
    "published_date": "2025-01-29 07:35:56 UTC",
    "updated_date": "2025-01-29 07:35:56 UTC"
  },
  {
    "arxiv_id": "2501.17441v1",
    "title": "Towards Making Flowchart Images Machine Interpretable",
    "authors": [
      "Shreya Shukla",
      "Prajwal Gatti",
      "Yogesh Kumar",
      "Vikash Yadav",
      "Anand Mishra"
    ],
    "abstract": "Computer programming textbooks and software documentations often contain\nflowcharts to illustrate the flow of an algorithm or procedure. Modern OCR\nengines often tag these flowcharts as graphics and ignore them in further\nprocessing. In this paper, we work towards making flowchart images\nmachine-interpretable by converting them to executable Python codes. To this\nend, inspired by the recent success in natural language to code generation\nliterature, we present a novel transformer-based framework, namely FloCo-T5.\nOur model is well-suited for this task,as it can effectively learn semantics,\nstructure, and patterns of programming languages, which it leverages to\ngenerate syntactically correct code. We also used a task-specific pre-training\nobjective to pre-train FloCo-T5 using a large number of logic-preserving\naugmented code samples. Further, to perform a rigorous study of this problem,\nwe introduce theFloCo dataset that contains 11,884 flowchart images and their\ncorresponding Python codes. Our experiments show promising results, and\nFloCo-T5 clearly outperforms related competitive baselines on code generation\nmetrics. We make our dataset and implementation publicly available.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.DL",
      "cs.SE"
    ],
    "primary_category": "cs.CV",
    "comment": "Published at: ICDAR 2023, Project Page:\n  https://vl2g.github.io/projects/floco/",
    "pdf_url": "http://arxiv.org/pdf/2501.17441v1",
    "published_date": "2025-01-29 06:43:38 UTC",
    "updated_date": "2025-01-29 06:43:38 UTC"
  },
  {
    "arxiv_id": "2501.17433v1",
    "title": "Virus: Harmful Fine-tuning Attack for Large Language Models Bypassing Guardrail Moderation",
    "authors": [
      "Tiansheng Huang",
      "Sihao Hu",
      "Fatih Ilhan",
      "Selim Furkan Tekin",
      "Ling Liu"
    ],
    "abstract": "Recent research shows that Large Language Models (LLMs) are vulnerable to\nharmful fine-tuning attacks -- models lose their safety alignment ability after\nfine-tuning on a few harmful samples. For risk mitigation, a guardrail is\ntypically used to filter out harmful samples before fine-tuning. By designing a\nnew red-teaming method, we in this paper show that purely relying on the\nmoderation guardrail for data filtration is not reliable. Our proposed attack\nmethod, dubbed Virus, easily bypasses the guardrail moderation by slightly\nmodifying the harmful data. Experimental results show that the harmful data\noptimized by Virus is not detectable by the guardrail with up to 100\\% leakage\nratio, and can simultaneously achieve superior attack performance. Finally, the\nkey message we want to convey through this paper is that: \\textbf{it is\nreckless to consider guardrail moderation as a clutch at straws towards harmful\nfine-tuning attack}, as it cannot solve the inherent safety issue of the\npre-trained LLMs. Our code is available at https://github.com/git-disl/Virus",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17433v1",
    "published_date": "2025-01-29 06:24:58 UTC",
    "updated_date": "2025-01-29 06:24:58 UTC"
  },
  {
    "arxiv_id": "2501.17429v1",
    "title": "Algorithmic Segmentation and Behavioral Profiling for Ransomware Detection Using Temporal-Correlation Graphs",
    "authors": [
      "Ignatius Rollere",
      "Caspian Hartsfield",
      "Seraphina Courtenay",
      "Lucian Fenwick",
      "Aurelia Grunwald"
    ],
    "abstract": "The rapid evolution of cyber threats has outpaced traditional detection\nmethodologies, necessitating innovative approaches capable of addressing the\nadaptive and complex behaviors of modern adversaries. A novel framework was\nintroduced, leveraging Temporal-Correlation Graphs to model the intricate\nrelationships and temporal patterns inherent in malicious operations. The\napproach dynamically captured behavioral anomalies, offering a robust mechanism\nfor distinguishing between benign and malicious activities in real-time\nscenarios. Extensive experiments demonstrated the framework's effectiveness\nacross diverse ransomware families, with consistently high precision, recall,\nand overall detection accuracy. Comparative evaluations highlighted its better\nperformance over traditional signature-based and heuristic methods,\nparticularly in handling polymorphic and previously unseen ransomware variants.\nThe architecture was designed with scalability and modularity in mind, ensuring\ncompatibility with enterprise-scale environments while maintaining resource\nefficiency. Analysis of encryption speeds, anomaly patterns, and temporal\ncorrelations provided deeper insights into the operational strategies of\nransomware, validating the framework's adaptability to evolving threats. The\nresearch contributes to advancing cybersecurity technologies by integrating\ndynamic graph analytics and machine learning for future innovations in threat\ndetection. Results from this study underline the potential for transforming the\nway organizations detect and mitigate complex cyberattacks.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17429v1",
    "published_date": "2025-01-29 06:09:25 UTC",
    "updated_date": "2025-01-29 06:09:25 UTC"
  },
  {
    "arxiv_id": "2501.17420v1",
    "title": "Actions Speak Louder than Words: Agent Decisions Reveal Implicit Biases in Language Models",
    "authors": [
      "Yuxuan Li",
      "Hirokazu Shirado",
      "Sauvik Das"
    ],
    "abstract": "While advances in fairness and alignment have helped mitigate overt biases\nexhibited by large language models (LLMs) when explicitly prompted, we\nhypothesize that these models may still exhibit implicit biases when simulating\nhuman behavior. To test this hypothesis, we propose a technique to\nsystematically uncover such biases across a broad range of sociodemographic\ncategories by assessing decision-making disparities among agents with\nLLM-generated, sociodemographically-informed personas. Using our technique, we\ntested six LLMs across three sociodemographic groups and four decision-making\nscenarios. Our results show that state-of-the-art LLMs exhibit significant\nsociodemographic disparities in nearly all simulations, with more advanced\nmodels exhibiting greater implicit biases despite reducing explicit biases.\nFurthermore, when comparing our findings to real-world disparities reported in\nempirical studies, we find that the biases we uncovered are directionally\naligned but markedly amplified. This directional alignment highlights the\nutility of our technique in uncovering systematic biases in LLMs rather than\nrandom variations; moreover, the presence and amplification of implicit biases\nemphasizes the need for novel strategies to address these biases.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17420v1",
    "published_date": "2025-01-29 05:21:31 UTC",
    "updated_date": "2025-01-29 05:21:31 UTC"
  },
  {
    "arxiv_id": "2501.17414v1",
    "title": "Reqo: A Robust and Explainable Query Optimization Cost Model",
    "authors": [
      "Baoming Chang",
      "Amin Kamali",
      "Verena Kantere"
    ],
    "abstract": "In recent years, there has been a growing interest in using machine learning\n(ML) in query optimization to select more efficient plans. Existing\nlearning-based query optimizers use certain model architectures to convert\ntree-structured query plans into representations suitable for downstream ML\ntasks. As the design of these architectures significantly impacts cost\nestimation, we propose a tree model architecture based on Bidirectional Graph\nNeural Networks (Bi-GNN) aggregated by Gated Recurrent Units (GRUs) to achieve\nmore accurate cost estimates. The inherent uncertainty of data and model\nparameters also leads to inaccurate cost estimates, resulting in suboptimal\nplans and less robust query performance. To address this, we implement a novel\nlearning-to-rank cost model that effectively quantifies the uncertainty in cost\nestimates using approximate probabilistic ML. This model adaptively integrates\nquantified uncertainty with estimated costs and learns from comparing pairwise\nplans, achieving more robust performance. In addition, we propose the first\nexplainability technique specifically designed for learning-based cost models.\nThis technique explains the contribution of any subgraphs in the query plan to\nthe final predicted cost, which can be integrated and trained with any\nlearning-based cost model to significantly boost the model's explainability. By\nincorporating these innovations, we propose a cost model for a Robust and\nExplainable Query Optimizer, Reqo, that improves the accuracy, robustness, and\nexplainability of cost estimation, outperforming state-of-the-art approaches in\nall three dimensions.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17414v1",
    "published_date": "2025-01-29 04:48:51 UTC",
    "updated_date": "2025-01-29 04:48:51 UTC"
  },
  {
    "arxiv_id": "2501.17899v2",
    "title": "The Right to AI",
    "authors": [
      "Rashid Mushkani",
      "Hugo Berard",
      "Allison Cohen",
      "Shin Koeski"
    ],
    "abstract": "This paper proposes a Right to AI, which asserts that individuals and\ncommunities should meaningfully participate in the development and governance\nof the AI systems that shape their lives. Motivated by the increasing\ndeployment of AI in critical domains and inspired by Henri Lefebvre's concept\nof the Right to the City, we reconceptualize AI as a societal infrastructure,\nrather than merely a product of expert design. In this paper, we critically\nevaluate how generative agents, large-scale data extraction, and diverse\ncultural values bring new complexities to AI oversight. The paper proposes that\ngrassroots participatory methodologies can mitigate biased outcomes and enhance\nsocial responsiveness. It asserts that data is socially produced and should be\nmanaged and owned collectively. Drawing on Sherry Arnstein's Ladder of Citizen\nParticipation and analyzing nine case studies, the paper develops a four-tier\nmodel for the Right to AI that situates the current paradigm and envisions an\naspirational future. It proposes recommendations for inclusive data ownership,\ntransparent design processes, and stakeholder-driven oversight. We also discuss\nmarket-led and state-centric alternatives and argue that participatory\napproaches offer a better balance between technical efficiency and democratic\nlegitimacy.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "ICML 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.17899v2",
    "published_date": "2025-01-29 04:32:41 UTC",
    "updated_date": "2025-05-08 02:28:58 UTC"
  },
  {
    "arxiv_id": "2501.17411v1",
    "title": "A Genetic Algorithm-Based Approach for Automated Optimization of Kolmogorov-Arnold Networks in Classification Tasks",
    "authors": [
      "Quan Long",
      "Bin Wang",
      "Bing Xue",
      "Mengjie Zhang"
    ],
    "abstract": "To address the issue of interpretability in multilayer perceptrons (MLPs),\nKolmogorov-Arnold Networks (KANs) are introduced in 2024. However, optimizing\nKAN structures is labor-intensive, typically requiring manual intervention and\nparameter tuning. This paper proposes GA-KAN, a genetic algorithm-based\napproach that automates the optimization of KANs, requiring no human\nintervention in the design process. To the best of our knowledge, this is the\nfirst time that evolutionary computation is explored to optimize KANs\nautomatically. Furthermore, inspired by the use of sparse connectivity in MLPs\nin effectively reducing the number of parameters, GA-KAN further explores\nsparse connectivity to tackle the challenge of extensive parameter spaces in\nKANs. GA-KAN is validated on two toy datasets, achieving optimal results\nwithout the manual tuning required by the original KAN. Additionally, GA-KAN\ndemonstrates superior performance across five classification datasets,\noutperforming traditional methods on all datasets and providing interpretable\nsymbolic formulae for the Wine and Iris datasets, thereby enhancing model\ntransparency. Furthermore, GA-KAN significantly reduces the number of\nparameters over the standard KAN across all the five datasets. The core\ncontributions of GA-KAN include automated optimization, a new encoding\nstrategy, and a new decoding process, which together improve the accuracy and\ninterpretability, and reduce the number of parameters.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17411v1",
    "published_date": "2025-01-29 04:32:36 UTC",
    "updated_date": "2025-01-29 04:32:36 UTC"
  },
  {
    "arxiv_id": "2501.18643v2",
    "title": "3D Reconstruction of Shoes for Augmented Reality",
    "authors": [
      "Pratik Shrestha",
      "Sujan Kapali",
      "Swikar Gautam",
      "Vishal Pokharel",
      "Santosh Giri"
    ],
    "abstract": "This paper introduces a mobile-based solution that enhances online shoe\nshopping through 3D modeling and Augmented Reality (AR), leveraging the\nefficiency of 3D Gaussian Splatting. Addressing the limitations of static 2D\nimages, the framework generates realistic 3D shoe models from 2D images,\nachieving an average Peak Signal-to-Noise Ratio (PSNR) of 32, and enables\nimmersive AR interactions via smartphones. A custom shoe segmentation dataset\nof 3120 images was created, with the best-performing segmentation model\nachieving an Intersection over Union (IoU) score of 0.95. This paper\ndemonstrates the potential of 3D modeling and AR to revolutionize online\nshopping by offering realistic virtual interactions, with applicability across\nbroader fashion categories.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18643v2",
    "published_date": "2025-01-29 04:18:51 UTC",
    "updated_date": "2025-02-17 05:11:30 UTC"
  },
  {
    "arxiv_id": "2501.17403v1",
    "title": "General Scene Adaptation for Vision-and-Language Navigation",
    "authors": [
      "Haodong Hong",
      "Yanyuan Qiao",
      "Sen Wang",
      "Jiajun Liu",
      "Qi Wu"
    ],
    "abstract": "Vision-and-Language Navigation (VLN) tasks mainly evaluate agents based on\none-time execution of individual instructions across multiple environments,\naiming to develop agents capable of functioning in any environment in a\nzero-shot manner. However, real-world navigation robots often operate in\npersistent environments with relatively consistent physical layouts, visual\nobservations, and language styles from instructors. Such a gap in the task\nsetting presents an opportunity to improve VLN agents by incorporating\ncontinuous adaptation to specific environments. To better reflect these\nreal-world conditions, we introduce GSA-VLN, a novel task requiring agents to\nexecute navigation instructions within a specific scene and simultaneously\nadapt to it for improved performance over time. To evaluate the proposed task,\none has to address two challenges in existing VLN datasets: the lack of OOD\ndata, and the limited number and style diversity of instructions for each\nscene. Therefore, we propose a new dataset, GSA-R2R, which significantly\nexpands the diversity and quantity of environments and instructions for the R2R\ndataset to evaluate agent adaptability in both ID and OOD contexts.\nFurthermore, we design a three-stage instruction orchestration pipeline that\nleverages LLMs to refine speaker-generated instructions and apply role-playing\ntechniques to rephrase instructions into different speaking styles. This is\nmotivated by the observation that each individual user often has consistent\nsignatures or preferences in their instructions. We conducted extensive\nexperiments on GSA-R2R to thoroughly evaluate our dataset and benchmark various\nmethods. Based on our findings, we propose a novel method, GR-DUET, which\nincorporates memory-based navigation graphs with an environment-specific\ntraining strategy, achieving state-of-the-art results on all GSA-R2R splits.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.17403v1",
    "published_date": "2025-01-29 03:57:56 UTC",
    "updated_date": "2025-01-29 03:57:56 UTC"
  },
  {
    "arxiv_id": "2501.17399v2",
    "title": "MultiChallenge: A Realistic Multi-Turn Conversation Evaluation Benchmark Challenging to Frontier LLMs",
    "authors": [
      "Ved Sirdeshmukh",
      "Kaustubh Deshpande",
      "Johannes Mols",
      "Lifeng Jin",
      "Ed-Yeremai Cardona",
      "Dean Lee",
      "Jeremy Kritz",
      "Willow Primack",
      "Summer Yue",
      "Chen Xing"
    ],
    "abstract": "We present MultiChallenge, a pioneering benchmark evaluating large language\nmodels (LLMs) on conducting multi-turn conversations with human users, a\ncrucial yet underexamined capability for their applications. MultiChallenge\nidentifies four categories of challenges in multi-turn conversations that are\nnot only common and realistic among current human-LLM interactions, but are\nalso challenging to all current frontier LLMs. All 4 challenges require\naccurate instruction-following, context allocation, and in-context reasoning at\nthe same time. We also develop LLM as judge with instance-level rubrics to\nfacilitate an automatic evaluation method with fair agreement with experienced\nhuman raters. Despite achieving near-perfect scores on existing multi-turn\nevaluation benchmarks, all frontier models have less than 50% accuracy on\nMultiChallenge, with the top-performing Claude 3.5 Sonnet (June 2024) achieving\njust a 41.4% average accuracy.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17399v2",
    "published_date": "2025-01-29 03:29:24 UTC",
    "updated_date": "2025-03-06 04:41:56 UTC"
  },
  {
    "arxiv_id": "2501.17393v1",
    "title": "Intensional Inheritance Between Concepts: An Information-Theoretic Interpretation",
    "authors": [
      "Ben Goertzel"
    ],
    "abstract": "This paper addresses the problem of formalizing and quantifying the concept\nof \"intensional inheritance\" between two concepts. We begin by conceiving the\nintensional inheritance of $W$ from $F$ as the amount of information the\nproposition \"x is $F$ \" provides about the proposition \"x is $W$. To flesh this\nout, we consider concepts $F$ and $W$ defined by sets of properties\n$\\left\\{F_{1}, F_{2}, \\ldots, F_{n}\\right\\}$ and $\\left\\{W_{1}, W_{2}, \\ldots,\nW_{m}\\right\\}$ with associated degrees $\\left\\{d_{1}, d_{2}, \\ldots,\nd_{n}\\right\\}$ and $\\left\\{e_{1}, e_{2}, \\ldots, e_{m}\\right\\}$, respectively,\nwhere the properties may overlap. We then derive formulas for the intensional\ninheritance using both Shannon information theory and algorithmic information\ntheory, incorporating interaction information among properties. We examine a\nspecial case where all properties are mutually exclusive and calculate the\nintensional inheritance in this case in both frameworks. We also derive\nexpressions for $P(W \\mid F)$ based on the mutual information formula. Finally\nwe consider the relationship between intensional inheritance and conventional\nset-theoretic \"extensional\" inheritance, concluding that in our\ninformation-theoretic framework, extensional inheritance emerges as a special\ncase of intensional inheritance.",
    "categories": [
      "cs.AI",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17393v1",
    "published_date": "2025-01-29 03:01:29 UTC",
    "updated_date": "2025-01-29 03:01:29 UTC"
  },
  {
    "arxiv_id": "2501.17391v2",
    "title": "Learning Free Token Reduction for Multi-Modal Large Language Models",
    "authors": [
      "Zihui Zhao",
      "Yingxin Li",
      "Yang Li"
    ],
    "abstract": "Vision-Language Models (VLMs) have achieved remarkable success across a range\nof multimodal tasks; however, their practical deployment is often constrained\nby high computational costs and prolonged inference times. Since the vision\nmodality typically carries more information than the text modality, compressing\nvisual prompts offers a promising solution to alleviate these challenges.\nExisting approaches predominantly focus on refining model architectures or\ndirectly reducing the number of visual tokens. However, these methods often\ncompromise inference performance due to a lack of consideration for the unique\nspatial and temporal characteristics of visual data. In this work, we propose a\ntoken compression paradigm that operates on both spatial and temporal\ndimensions. Our approach includes a learning-free, plug-and-play compression\npipeline that can be seamlessly integrated into most Multimodal Large Language\nModel (MLLM) frameworks. By leveraging this method, we enhance the model\ninference capability while simultaneously reducing its computational cost.\nExperimental results on the Video-QA task demonstrate the effectiveness of the\nproposed approach, showcasing significant improvements in efficiency without\nsacrificing performance.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17391v2",
    "published_date": "2025-01-29 02:52:32 UTC",
    "updated_date": "2025-04-14 17:34:19 UTC"
  },
  {
    "arxiv_id": "2501.17386v2",
    "title": "Context-Aware Semantic Recomposition Mechanism for Large Language Models",
    "authors": [
      "Richard Katrix",
      "Quentin Carroway",
      "Rowan Hawkesbury",
      "Matthias Heathfield"
    ],
    "abstract": "Context-aware processing mechanisms have increasingly become a critical area\nof exploration for improving the semantic and contextual capabilities of\nlanguage generation models. The Context-Aware Semantic Recomposition Mechanism\n(CASRM) was introduced as a novel framework designed to address limitations in\ncoherence, contextual adaptability, and error propagation in large-scale text\ngeneration tasks. Through the integration of dynamically generated context\nvectors and attention modulation layers, CASRM enhances the alignment between\ntoken-level representations and broader contextual dependencies. Experimental\nevaluations demonstrated significant improvements in semantic coherence across\nmultiple domains, including technical, conversational, and narrative text. The\nability to adapt to unseen domains and ambiguous inputs was evaluated using a\ndiverse set of test scenarios, highlighting the robustness of the proposed\nmechanism. A detailed computational analysis revealed that while CASRM\nintroduces additional processing overhead, the gains in linguistic precision\nand contextual relevance outweigh the marginal increase in complexity. The\nframework also successfully mitigates error propagation in sequential tasks,\nimproving performance in dialogue continuation and multi-step text synthesis.\nAdditional investigations into token-level attention distribution emphasized\nthe dynamic focus shifts enabled through context-aware enhancements. The\nfindings suggest that CASRM offers a scalable and flexible solution for\nintegrating contextual intelligence into existing language model architectures.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "arXiv admin note: This paper has been withdrawn by arXiv due to\n  disputed and unverifiable authorship",
    "pdf_url": "http://arxiv.org/pdf/2501.17386v2",
    "published_date": "2025-01-29 02:38:28 UTC",
    "updated_date": "2025-03-26 15:57:24 UTC"
  },
  {
    "arxiv_id": "2501.17384v1",
    "title": "A Dual-Agent Adversarial Framework for Robust Generalization in Deep Reinforcement Learning",
    "authors": [
      "Zhengpeng Xie",
      "Jiahang Cao",
      "Yulong Zhang",
      "Qiang Zhang",
      "Renjing Xu"
    ],
    "abstract": "Recently, empowered with the powerful capabilities of neural networks,\nreinforcement learning (RL) has successfully tackled numerous challenging\ntasks. However, while these models demonstrate enhanced decision-making\nabilities, they are increasingly prone to overfitting. For instance, a trained\nRL model often fails to generalize to even minor variations of the same task,\nsuch as a change in background color or other minor semantic differences. To\naddress this issue, we propose a dual-agent adversarial policy learning\nframework, which allows agents to spontaneously learn the underlying semantics\nwithout introducing any human prior knowledge. Specifically, our framework\ninvolves a game process between two agents: each agent seeks to maximize the\nimpact of perturbing on the opponent's policy by producing representation\ndifferences for the same state, while maintaining its own stability against\nsuch perturbations. This interaction encourages agents to learn generalizable\npolicies, capable of handling irrelevant features from the high-dimensional\nobservations. Extensive experimental results on the Procgen benchmark\ndemonstrate that the adversarial process significantly improves the\ngeneralization performance of both agents, while also being applied to various\nRL algorithms, e.g., Proximal Policy Optimization (PPO). With the adversarial\nframework, the RL agent outperforms the baseline methods by a significant\nmargin, especially in hard-level tasks, marking a significant step forward in\nthe generalization capabilities of deep reinforcement learning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17384v1",
    "published_date": "2025-01-29 02:36:47 UTC",
    "updated_date": "2025-01-29 02:36:47 UTC"
  },
  {
    "arxiv_id": "2501.17377v1",
    "title": "ASAP: Learning Generalizable Online Bin Packing via Adaptive Selection After Pruning",
    "authors": [
      "Han Fang",
      "Paul Weng",
      "Yutong Ban"
    ],
    "abstract": "Recently, deep reinforcement learning (DRL) has achieved promising results in\nsolving online 3D Bin Packing Problems (3D-BPP). However, these DRL-based\npolicies may perform poorly on new instances due to distribution shift. Besides\ngeneralization, we also consider adaptation, completely overlooked by previous\nwork, which aims at rapidly finetuning these policies to a new test\ndistribution. To tackle both generalization and adaptation issues, we propose\nAdaptive Selection After Pruning (ASAP), which decomposes a solver's\ndecision-making into two policies, one for pruning and one for selection. The\nrole of the pruning policy is to remove inherently bad actions, which allows\nthe selection policy to choose among the remaining most valuable actions. To\nlearn these policies, we propose a training scheme based on a meta-learning\nphase of both policies followed by a finetuning phase of the sole selection\npolicy to rapidly adapt it to a test distribution. Our experiments demonstrate\nthat ASAP exhibits excellent generalization and adaptation capabilities on\nin-distribution and out-of-distribution instances under both discrete and\ncontinuous setup.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17377v1",
    "published_date": "2025-01-29 02:12:34 UTC",
    "updated_date": "2025-01-29 02:12:34 UTC"
  },
  {
    "arxiv_id": "2501.17374v1",
    "title": "A Geometric Perspective for High-Dimensional Multiplex Graphs",
    "authors": [
      "Kamel Abdous",
      "Nairouz Mrabah",
      "Mohamed Bouguessa"
    ],
    "abstract": "High-dimensional multiplex graphs are characterized by their high number of\ncomplementary and divergent dimensions. The existence of multiple hierarchical\nlatent relations between the graph dimensions poses significant challenges to\nembedding methods. In particular, the geometric distortions that might occur in\nthe representational space have been overlooked in the literature. This work\nstudies the problem of high-dimensional multiplex graph embedding from a\ngeometric perspective. We find that the node representations reside on highly\ncurved manifolds, thus rendering their exploitation more challenging for\ndownstream tasks. Moreover, our study reveals that increasing the number of\ngraph dimensions can cause further distortions to the highly curved manifolds.\nTo address this problem, we propose a novel multiplex graph embedding method\nthat harnesses hierarchical dimension embedding and Hyperbolic Graph Neural\nNetworks. The proposed approach hierarchically extracts hyperbolic node\nrepresentations that reside on Riemannian manifolds while gradually learning\nfewer and more expressive latent dimensions of the multiplex graph.\nExperimental results on real-world high-dimensional multiplex graphs show that\nthe synergy between hierarchical and hyperbolic embeddings incurs much fewer\ngeometric distortions and brings notable improvements over state-of-the-art\napproaches on downstream tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.6"
    ],
    "primary_category": "cs.LG",
    "comment": "Published in Proceedings of the ACM Conference on Information and\n  Knowledge Management (CIKM) 2024, DOI: 10.1145/3627673.3679541",
    "pdf_url": "http://arxiv.org/pdf/2501.17374v1",
    "published_date": "2025-01-29 02:02:37 UTC",
    "updated_date": "2025-01-29 02:02:37 UTC"
  },
  {
    "arxiv_id": "2501.17366v1",
    "title": "Forecasting S&P 500 Using LSTM Models",
    "authors": [
      "Prashant Pilla",
      "Raji Mekonen"
    ],
    "abstract": "With the volatile and complex nature of financial data influenced by external\nfactors, forecasting the stock market is challenging. Traditional models such\nas ARIMA and GARCH perform well with linear data but struggle with non-linear\ndependencies. Machine learning and deep learning models, particularly Long\nShort-Term Memory (LSTM) networks, address these challenges by capturing\nintricate patterns and long-term dependencies. This report compares ARIMA and\nLSTM models in predicting the S&P 500 index, a major financial benchmark.\n  Using historical price data and technical indicators, we evaluated these\nmodels using Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE). The\nARIMA model showed reasonable performance with an MAE of 462.1, RMSE of 614,\nand 89.8 percent accuracy, effectively capturing short-term trends but limited\nby its linear assumptions. The LSTM model, leveraging sequential processing\ncapabilities, outperformed ARIMA with an MAE of 369.32, RMSE of 412.84, and\n92.46 percent accuracy, capturing both short- and long-term dependencies.\nNotably, the LSTM model without additional features performed best, achieving\nan MAE of 175.9, RMSE of 207.34, and 96.41 percent accuracy, showcasing its\nability to handle market data efficiently.\n  Accurately predicting stock movements is crucial for investment strategies,\nrisk assessments, and market stability. Our findings confirm the potential of\ndeep learning models in handling volatile financial data compared to\ntraditional ones. The results highlight the effectiveness of LSTM and suggest\navenues for further improvements. This study provides insights into financial\nforecasting, offering a comparative analysis of ARIMA and LSTM while outlining\ntheir strengths and limitations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-fin.CP",
      "q-fin.TR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17366v1",
    "published_date": "2025-01-29 01:31:56 UTC",
    "updated_date": "2025-01-29 01:31:56 UTC"
  },
  {
    "arxiv_id": "2501.17361v1",
    "title": "The M-factor: A Novel Metric for Evaluating Neural Architecture Search in Resource-Constrained Environments",
    "authors": [
      "Srikanth Thudumu",
      "Hy Nguyen",
      "Hung Du",
      "Nhat Duong",
      "Zafaryab Rasool",
      "Rena Logothetis",
      "Scott Barnett",
      "Rajesh Vasa",
      "Kon Mouzakis"
    ],
    "abstract": "Neural Architecture Search (NAS) aims to automate the design of deep neural\nnetworks. However, existing NAS techniques often focus on maximising accuracy,\nneglecting model efficiency. This limitation restricts their use in\nresource-constrained environments like mobile devices and edge computing\nsystems. Moreover, current evaluation metrics prioritise performance over\nefficiency, lacking a balanced approach for assessing architectures suitable\nfor constrained scenarios. To address these challenges, this paper introduces\nthe M-factor, a novel metric combining model accuracy and size. Four diverse\nNAS techniques are compared: Policy-Based Reinforcement Learning, Regularised\nEvolution, Tree-structured Parzen Estimator (TPE), and Multi-trial Random\nSearch. These techniques represent different NAS paradigms, providing a\ncomprehensive evaluation of the M-factor. The study analyses ResNet\nconfigurations on the CIFAR-10 dataset, with a search space of 19,683\nconfigurations. Experiments reveal that Policy-Based Reinforcement Learning and\nRegularised Evolution achieved M-factor values of 0.84 and 0.82, respectively,\nwhile Multi-trial Random Search attained 0.75, and TPE reached 0.67.\nPolicy-Based Reinforcement Learning exhibited performance changes after 39\ntrials, while Regularised Evolution optimised within 20 trials. The research\ninvestigates the optimisation dynamics and trade-offs between accuracy and\nmodel size for each strategy. Findings indicate that, in some cases, random\nsearch performed comparably to more complex algorithms when assessed using the\nM-factor. These results highlight how the M-factor addresses the limitations of\nexisting metrics by guiding NAS towards balanced architectures, offering\nvaluable insights for selecting strategies in scenarios requiring both\nperformance and efficiency.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17361v1",
    "published_date": "2025-01-29 00:57:02 UTC",
    "updated_date": "2025-01-29 00:57:02 UTC"
  },
  {
    "arxiv_id": "2501.17894v1",
    "title": "Progress in Artificial Intelligence and its Determinants",
    "authors": [
      "Michael R. Douglas",
      "Sergiy Verstyuk"
    ],
    "abstract": "We study long-run progress in artificial intelligence in a quantitative way.\nMany measures, including traditional ones such as patents and publications,\nmachine learning benchmarks, and a new Aggregate State of the Art in ML (or\nASOTA) Index we have constructed from these, show exponential growth at roughly\nconstant rates over long periods. Production of patents and publications\ndoubles every ten years, by contrast with the growth of computing resources\ndriven by Moore's Law, roughly a doubling every two years. We argue that the\ninput of AI researchers is also crucial and its contribution can be objectively\nestimated. Consequently, we give a simple argument that explains the 5:1\nrelation between these two rates. We then discuss the application of this\nargument to different output measures and compare our analyses with predictions\nbased on machine learning scaling laws proposed in existing literature. Our\nquantitative framework facilitates understanding, predicting, and modulating\nthe development of these important technologies.",
    "categories": [
      "econ.GN",
      "cs.AI",
      "cs.CY",
      "cs.LG",
      "physics.soc-ph",
      "q-fin.EC"
    ],
    "primary_category": "econ.GN",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17894v1",
    "published_date": "2025-01-29 00:43:27 UTC",
    "updated_date": "2025-01-29 00:43:27 UTC"
  },
  {
    "arxiv_id": "2501.17356v1",
    "title": "On the Coexistence and Ensembling of Watermarks",
    "authors": [
      "Aleksandar Petrov",
      "Shruti Agarwal",
      "Philip H. S. Torr",
      "Adel Bibi",
      "John Collomosse"
    ],
    "abstract": "Watermarking, the practice of embedding imperceptible information into media\nsuch as images, videos, audio, and text, is essential for intellectual property\nprotection, content provenance and attribution. The growing complexity of\ndigital ecosystems necessitates watermarks for different uses to be embedded in\nthe same media. However, to detect and decode all watermarks, they need to\ncoexist well with one another. We perform the first study of coexistence of\ndeep image watermarking methods and, contrary to intuition, we find that\nvarious open-source watermarks can coexist with only minor impacts on image\nquality and decoding robustness. The coexistence of watermarks also opens the\navenue for ensembling watermarking methods. We show how ensembling can increase\nthe overall message capacity and enable new trade-offs between capacity,\naccuracy, robustness and image quality, without needing to retrain the base\nmodels.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17356v1",
    "published_date": "2025-01-29 00:37:06 UTC",
    "updated_date": "2025-01-29 00:37:06 UTC"
  }
]