[
  {
    "arxiv_id": "2508.02961v2",
    "title": "Defend LLMs Through Self-Consciousness",
    "authors": [
      "Boshi Huang",
      "Fabio Nonato de Paula"
    ],
    "abstract": "This paper introduces a novel self-consciousness defense mechanism for Large Language Models (LLMs) to combat prompt injection attacks. Unlike traditional approaches that rely on external classifiers, our method leverages the LLM's inherent reasoning capabilities to perform self-protection. We propose a framework that incorporates Meta-Cognitive and Arbitration Modules, enabling LLMs to evaluate and regulate their own outputs autonomously. Our approach is evaluated on seven state-of-the-art LLMs using two datasets: AdvBench and Prompt-Injection-Mixed-Techniques-2024. Experiment results demonstrate significant improvements in defense success rates across models and datasets, with some achieving perfect and near-perfect defense in Enhanced Mode. We also analyze the trade-off between defense success rate improvement and computational overhead. This self-consciousness method offers a lightweight, cost-effective solution for enhancing LLM ethics, particularly beneficial for GenAI use cases across various platforms.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CR"
    ],
    "primary_category": "cs.AI",
    "comment": "company requests to withdraw",
    "pdf_url": "https://arxiv.org/pdf/2508.02961v2",
    "published_date": "2025-08-04 23:52:15 UTC",
    "updated_date": "2025-10-01 18:23:36 UTC"
  },
  {
    "arxiv_id": "2508.02959v2",
    "title": "Polymath: A Self-Optimizing Agent with Dynamic Hierarchical Workflow",
    "authors": [
      "Chia-Tung Ho",
      "Jing Gong",
      "Xufeng Yao",
      "Yunsheng Bai",
      "Abhishek B Akkur",
      "Haoxing Ren"
    ],
    "abstract": "Large language models (LLMs) excel at solving complex tasks by executing agentic workflows composed of detailed instructions and structured operations. Yet, building general-purpose agents by manually embedding foundation models into agentic systems such as Chain-of-Thought, Self-Reflection, and ReACT through text interfaces limits scalability and efficiency. Recently, many researchers have sought to automate the generation and optimization of these workflows through code-based representations. However, existing methods often rely on labeled datasets to train and optimize workflows, making them ineffective and inflexible for solving real-world, dynamic problems where labeled data is unavailable. To address this challenge, we introduce Polymath, a self-optimizing agent with dynamic hierarchical workflow that leverages the flexibility of task flow graphs and the expressiveness of code-represented workflows to solve a wide range of real-world, dynamic problems. The proposed optimization methodology integrates multi-grid-inspired graph optimization with a self-reflection-guided evolutionary algorithm to refine workflows without labeled data. Experimental results on six benchmark datasets across coding, math, and multi-turn QA tasks show that Polymath achieves 8.1% average improvement over state-of-the-art baselines.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "18 pages, 12 figures, under review for AAAI2026",
    "pdf_url": "https://arxiv.org/pdf/2508.02959v2",
    "published_date": "2025-08-04 23:50:02 UTC",
    "updated_date": "2025-08-07 01:30:51 UTC"
  },
  {
    "arxiv_id": "2508.02956v1",
    "title": "Autonomous Inorganic Materials Discovery via Multi-Agent Physics-Aware Scientific Reasoning",
    "authors": [
      "Alireza Ghafarollahi",
      "Markus J. Buehler"
    ],
    "abstract": "Conventional machine learning approaches accelerate inorganic materials design via accurate property prediction and targeted material generation, yet they operate as single-shot models limited by the latent knowledge baked into their training data. A central challenge lies in creating an intelligent system capable of autonomously executing the full inorganic materials discovery cycle, from ideation and planning to experimentation and iterative refinement. We introduce SparksMatter, a multi-agent AI model for automated inorganic materials design that addresses user queries by generating ideas, designing and executing experimental workflows, continuously evaluating and refining results, and ultimately proposing candidate materials that meet the target objectives. SparksMatter also critiques and improves its own responses, identifies research gaps and limitations, and suggests rigorous follow-up validation steps, including DFT calculations and experimental synthesis and characterization, embedded in a well-structured final report. The model's performance is evaluated across case studies in thermoelectrics, semiconductors, and perovskite oxides materials design. The results demonstrate the capacity of SparksMatter to generate novel stable inorganic structures that target the user's needs. Benchmarking against frontier models reveals that SparksMatter consistently achieves higher scores in relevance, novelty, and scientific rigor, with a significant improvement in novelty across multiple real-world design tasks as assessed by a blinded evaluator. These results demonstrate SparksMatter's unique capacity to generate chemically valid, physically meaningful, and creative inorganic materials hypotheses beyond existing materials knowledge.",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.dis-nn",
      "cond-mat.mes-hall",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02956v1",
    "published_date": "2025-08-04 23:40:43 UTC",
    "updated_date": "2025-08-04 23:40:43 UTC"
  },
  {
    "arxiv_id": "2508.02951v1",
    "title": "MedBLINK: Probing Basic Perception in Multimodal Language Models for Medicine",
    "authors": [
      "Mahtab Bigverdi",
      "Wisdom Ikezogwo",
      "Kevin Zhang",
      "Hyewon Jeong",
      "Mingyu Lu",
      "Sungjae Cho",
      "Linda Shapiro",
      "Ranjay Krishna"
    ],
    "abstract": "Multimodal language models (MLMs) show promise for clinical decision support and diagnostic reasoning, raising the prospect of end-to-end automated medical image interpretation. However, clinicians are highly selective in adopting AI tools; a model that makes errors on seemingly simple perception tasks such as determining image orientation or identifying whether a CT scan is contrast-enhance are unlikely to be adopted for clinical tasks. We introduce Medblink, a benchmark designed to probe these models for such perceptual abilities. Medblink spans eight clinically meaningful tasks across multiple imaging modalities and anatomical regions, totaling 1,429 multiple-choice questions over 1,605 images. We evaluate 19 state-of-the-art MLMs, including general purpose (GPT4o, Claude 3.5 Sonnet) and domain specific (Med Flamingo, LLaVA Med, RadFM) models. While human annotators achieve 96.4% accuracy, the best-performing model reaches only 65%. These results show that current MLMs frequently fail at routine perceptual checks, suggesting the need to strengthen their visual grounding to support clinical adoption. Data is available on our project page.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02951v1",
    "published_date": "2025-08-04 23:19:18 UTC",
    "updated_date": "2025-08-04 23:19:18 UTC"
  },
  {
    "arxiv_id": "2508.02947v1",
    "title": "AeroSafe: Mobile Indoor Air Purification using Aerosol Residence Time Analysis and Robotic Cough Emulator Testbed",
    "authors": [
      "M Tanjid Hasan Tonmoy",
      "Rahath Malladi",
      "Kaustubh Singh",
      "Forsad Al Hossain",
      "Rajesh Gupta",
      "Andrés E. Tejada-Martínez",
      "Tauhidur Rahman"
    ],
    "abstract": "Indoor air quality plays an essential role in the safety and well-being of occupants, especially in the context of airborne diseases. This paper introduces AeroSafe, a novel approach aimed at enhancing the efficacy of indoor air purification systems through a robotic cough emulator testbed and a digital-twins-based aerosol residence time analysis. Current portable air filters often overlook the concentrations of respiratory aerosols generated by coughs, posing a risk, particularly in high-exposure environments like healthcare facilities and public spaces. To address this gap, we present a robotic dual-agent physical emulator comprising a maneuverable mannequin simulating cough events and a portable air purifier autonomously responding to aerosols. The generated data from this emulator trains a digital twins model, combining a physics-based compartment model with a machine learning approach, using Long Short-Term Memory (LSTM) networks and graph convolution layers. Experimental results demonstrate the model's ability to predict aerosol concentration dynamics with a mean residence time prediction error within 35 seconds. The proposed system's real-time intervention strategies outperform static air filter placement, showcasing its potential in mitigating airborne pathogen risks.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted at IEEE International Conference on Robotics and Automation (ICRA) 2025. Author Accepted Manuscript",
    "pdf_url": "https://arxiv.org/pdf/2508.02947v1",
    "published_date": "2025-08-04 23:11:37 UTC",
    "updated_date": "2025-08-04 23:11:37 UTC"
  },
  {
    "arxiv_id": "2508.03764v1",
    "title": "CoughViT: A Self-Supervised Vision Transformer for Cough Audio Representation Learning",
    "authors": [
      "Justin Luong",
      "Hao Xue",
      "Flora D. Salim"
    ],
    "abstract": "Physicians routinely assess respiratory sounds during the diagnostic process, providing insight into the condition of a patient's airways. In recent years, AI-based diagnostic systems operating on respiratory sounds, have demonstrated success in respiratory disease detection. These systems represent a crucial advancement in early and accessible diagnosis which is essential for timely treatment. However, label and data scarcity remain key challenges, especially for conditions beyond COVID-19, limiting diagnostic performance and reliable evaluation. In this paper, we propose CoughViT, a novel pre-training framework for learning general-purpose cough sound representations, to enhance diagnostic performance in tasks with limited data. To address label scarcity, we employ masked data modelling to train a feature encoder in a self-supervised learning manner. We evaluate our approach against other pre-training strategies on three diagnostically important cough classification tasks. Experimental results show that our representations match or exceed current state-of-the-art supervised audio representations in enhancing performance on downstream tasks.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted to ISWC",
    "pdf_url": "https://arxiv.org/pdf/2508.03764v1",
    "published_date": "2025-08-04 23:09:07 UTC",
    "updated_date": "2025-08-04 23:09:07 UTC"
  },
  {
    "arxiv_id": "2508.02945v1",
    "title": "LLM-based IR-system for Bank Supervisors",
    "authors": [
      "Ilias Aarab"
    ],
    "abstract": "Bank supervisors face the complex task of ensuring that new measures are consistently aligned with historical precedents. To address this challenge, we introduce a novel Information Retrieval (IR) System tailored to assist supervisors in drafting both consistent and effective measures. This system ingests findings from on-site investigations. It then retrieves the most relevant historical findings and their associated measures from a comprehensive database, providing a solid basis for supervisors to write well-informed measures for new findings. Utilizing a blend of lexical, semantic, and Capital Requirements Regulation (CRR) fuzzy set matching techniques, the IR system ensures the retrieval of findings that closely align with current cases. The performance of this system, particularly in scenarios with partially labeled data, is validated through a Monte Carlo methodology, showcasing its robustness and accuracy. Enhanced by a Transformer-based Denoising AutoEncoder for fine-tuning, the final model achieves a Mean Average Precision (MAP@100) of 0.83 and a Mean Reciprocal Rank (MRR@100) of 0.92. These scores surpass those of both standalone lexical models such as BM25 and semantic BERT-like models.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG",
      "stat.AP",
      "stat.CO"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02945v1",
    "published_date": "2025-08-04 23:02:01 UTC",
    "updated_date": "2025-08-04 23:02:01 UTC"
  },
  {
    "arxiv_id": "2508.03763v2",
    "title": "Refine-IQA: Multi-Stage Reinforcement Finetuning for Perceptual Image Quality Assessment",
    "authors": [
      "Ziheng Jia",
      "Jiaying Qian",
      "Zicheng Zhang",
      "Zijian Chen",
      "Xiongkuo Min"
    ],
    "abstract": "Reinforcement fine-tuning (RFT) is a proliferating paradigm for LMM training. Analogous to high-level reasoning tasks, RFT is similarly applicable to low-level vision domains, including image quality assessment (IQA). Existing RFT-based IQA methods typically use rule-based output rewards to verify the model's rollouts but provide no reward supervision for the \"think\" process, leaving its correctness and efficacy uncontrolled. Furthermore, these methods typically fine-tune directly on downstream IQA tasks without explicitly enhancing the model's native low-level visual quality perception, which may constrain its performance upper bound. In response to these gaps, we propose the multi-stage RFT IQA framework (Refine-IQA). In Stage-1, we build the Refine-Perception-20K dataset (with 12 main distortions, 20,907 locally-distorted images, and over 55K RFT samples) and design multi-task reward functions to strengthen the model's visual quality perception. In Stage-2, targeting the quality scoring task, we introduce a probability difference reward involved strategy for \"think\" process supervision. The resulting Refine-IQA Series Models achieve outstanding performance on both perception and scoring tasks-and, notably, our paradigm activates a robust \"think\" (quality interpreting) capability that also attains exceptional results on the corresponding quality interpreting benchmark.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.03763v2",
    "published_date": "2025-08-04 22:46:10 UTC",
    "updated_date": "2025-08-15 00:09:46 UTC"
  },
  {
    "arxiv_id": "2508.02936v1",
    "title": "AQUAH: Automatic Quantification and Unified Agent in Hydrology",
    "authors": [
      "Songkun Yan",
      "Zhi Li",
      "Siyu Zhu",
      "Yixin Wen",
      "Mofan Zhang",
      "Mengye Chen",
      "Jie Cao",
      "Yang Hong"
    ],
    "abstract": "We introduce AQUAH, the first end-to-end language-based agent designed specifically for hydrologic modeling. Starting from a simple natural-language prompt (e.g., 'simulate floods for the Little Bighorn basin from 2020 to 2022'), AQUAH autonomously retrieves the required terrain, forcing, and gauge data; configures a hydrologic model; runs the simulation; and generates a self-contained PDF report. The workflow is driven by vision-enabled large language models, which interpret maps and rasters on the fly and steer key decisions such as outlet selection, parameter initialization, and uncertainty commentary. Initial experiments across a range of U.S. basins show that AQUAH can complete cold-start simulations and produce analyst-ready documentation without manual intervention. The results are judged by hydrologists as clear, transparent, and physically plausible. While further calibration and validation are still needed for operational deployment, these early outcomes highlight the promise of LLM-centered, vision-grounded agents to streamline complex environmental modeling and lower the barrier between Earth observation data, physics-based tools, and decision makers.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages, 5 figures, 2025 ICCV SEA workshop paper",
    "pdf_url": "https://arxiv.org/pdf/2508.02936v1",
    "published_date": "2025-08-04 22:26:50 UTC",
    "updated_date": "2025-08-04 22:26:50 UTC"
  },
  {
    "arxiv_id": "2508.02931v1",
    "title": "Can LLMs Generate High-Quality Task-Specific Conversations?",
    "authors": [
      "Shengqi Li",
      "Amarnath Gupta"
    ],
    "abstract": "This paper introduces a parameterization framework for controlling conversation quality in large language models. We explore nine key parameters across six dimensions that enable precise specification of dialogue properties. Through experiments with state-of-the-art LLMs, we demonstrate that parameter-based control produces statistically significant differences in generated conversation properties. Our approach addresses challenges in conversation generation, including topic coherence, knowledge progression, character consistency, and control granularity. The framework provides a standardized method for conversation quality control with applications in education, therapy, customer service, and entertainment. Future work will focus on implementing additional parameters through architectural modifications and developing benchmark datasets for evaluation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02931v1",
    "published_date": "2025-08-04 22:07:08 UTC",
    "updated_date": "2025-08-04 22:07:08 UTC"
  },
  {
    "arxiv_id": "2508.02929v2",
    "title": "Realizing Scaling Laws in Recommender Systems: A Foundation-Expert Paradigm for Hyperscale Model Deployment",
    "authors": [
      "Dai Li",
      "Kevin Course",
      "Wei Li",
      "Hongwei Li",
      "Jie Hua",
      "Yiqi Chen",
      "Zhao Zhu",
      "Rui Jian",
      "Xuan Cao",
      "Bi Xue",
      "Yu Shi",
      "Jing Qian",
      "Kai Ren",
      "Matt Ma",
      "Qunshu Zhang",
      "Rui Li"
    ],
    "abstract": "While scaling laws promise significant performance gains for recommender systems, efficiently deploying hyperscale models remains a major unsolved challenge. In contrast to fields where FMs are already widely adopted such as natural language processing and computer vision, progress in recommender systems is hindered by unique challenges including the need to learn from online streaming data under shifting data distributions, the need to adapt to different recommendation surfaces with a wide diversity in their downstream tasks and their input distributions, and stringent latency and computational constraints. To bridge this gap, we propose to leverage the Foundation-Expert Paradigm: a framework designed for the development and deployment of hyperscale recommendation FMs. In our approach, a central FM is trained on lifelong, cross-surface, multi-modal user data to learn generalizable knowledge. This knowledge is then efficiently transferred to various lightweight, surface-specific \"expert\" models via target-aware embeddings, allowing them to adapt to local data distributions and optimization goals with minimal overhead. To meet our training, inference and development needs, we built HyperCast, a production-grade infrastructure system that re-engineers training, serving, logging and iteration to power this decoupled paradigm. Our approach is now deployed at Meta serving tens of billions of user requests daily, demonstrating online metric improvements over our previous one-stage production system while improving developer velocity and maintaining infrastructure efficiency. To the best of our knowledge, this work represents the first successful deployment of a Foundation-Expert paradigm at this scale, offering a proven, compute-efficient, and developer-friendly blueprint to realize the promise of scaling laws in recommender systems.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02929v2",
    "published_date": "2025-08-04 22:03:13 UTC",
    "updated_date": "2025-08-06 18:44:24 UTC"
  },
  {
    "arxiv_id": "2508.02926v2",
    "title": "GrandJury: A Collaborative Machine Learning Model Evaluation Protocol for Dynamic Quality Rubrics",
    "authors": [
      "Arthur Cho"
    ],
    "abstract": "Generative Machine Learning models have become central to modern systems, powering applications in creative writing, summarization, multi-hop reasoning, and context-aware dialogue. These models underpin large-scale AI assistants, workflow automation, and autonomous decision-making. In such domains, acceptable response is rarely absolute or static, but plural and highly context-dependent. Yet standard evaluation regimes still rely on static, benchmark-style tests, incentivizing optimization toward leaderboard scores rather than alignment with dynamic user needs or evolving realities. GrandJury introduces a formal evaluation protocol combining time-decayed aggregation, complete traceability, with the support of dynamic, transparent task rubric attribution, and multi-rater human judgment. Together, these elements enable pluralistic, accountable evaluation that captures evolving consensus and surfaces disagreement. We provide an open-source implementation (grandjury PyPI package) and a public collection of Large Language Model (LLM) inference outputs to illustrate the need and method. GrandJury provides a new paradigm for AI practitioners when evaluating machine learning outputs without absolute ground truth.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages (incl. arXiv cover), 1 table, code & dataset links inside. Open-source implementation available on PyPI (grandjury package) and GitHub. Dataset available on Hugging Face under CC-BY-4.0 license",
    "pdf_url": "https://arxiv.org/pdf/2508.02926v2",
    "published_date": "2025-08-04 22:00:44 UTC",
    "updated_date": "2025-08-06 19:57:38 UTC"
  },
  {
    "arxiv_id": "2508.02921v1",
    "title": "PentestJudge: Judging Agent Behavior Against Operational Requirements",
    "authors": [
      "Shane Caldwell",
      "Max Harley",
      "Michael Kouremetis",
      "Vincent Abruzzo",
      "Will Pearce"
    ],
    "abstract": "We introduce PentestJudge, a system for evaluating the operations of penetration testing agents. PentestJudge is a large language model (LLM)-as-judge with access to tools that allow it to consume arbitrary trajectories of agent states and tool call history to determine whether a security agent's actions meet certain operating criteria that would be impractical to evaluate programmatically. We develop rubrics that use a tree structure to hierarchically collapse the penetration testing task for a particular environment into smaller, simpler, and more manageable sub-tasks and criteria until each leaf node represents simple yes-or-no criteria for PentestJudge to evaluate. Task nodes are broken down into different categories related to operational objectives, operational security, and tradecraft. LLM-as-judge scores are compared to human domain experts as a ground-truth reference, allowing us to compare their relative performance with standard binary classification metrics, such as F1 scores. We evaluate several frontier and open-source models acting as judge agents, with the best model reaching an F1 score of 0.83. We find models that are better at tool-use perform more closely to human experts. By stratifying the F1 scores by requirement type, we find even models with similar overall scores struggle with different types of questions, suggesting certain models may be better judges of particular operating criteria. We find that weaker and cheaper models can judge the trajectories of pentests performed by stronger and more expensive models, suggesting verification may be easier than generation for the penetration testing task. We share this methodology to facilitate future research in understanding the ability of judges to holistically and scalably evaluate the process quality of AI-based information security agents so that they may be confidently used in sensitive production environments.",
    "categories": [
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.AI",
    "comment": "18 pages, 5 figures, 3 tables",
    "pdf_url": "https://arxiv.org/pdf/2508.02921v1",
    "published_date": "2025-08-04 21:52:50 UTC",
    "updated_date": "2025-08-04 21:52:50 UTC"
  },
  {
    "arxiv_id": "2508.02917v1",
    "title": "Following Route Instructions using Large Vision-Language Models: A Comparison between Low-level and Panoramic Action Spaces",
    "authors": [
      "Vebjørn Haug Kåsene",
      "Pierre Lison"
    ],
    "abstract": "Vision-and-Language Navigation (VLN) refers to the task of enabling autonomous robots to navigate unfamiliar environments by following natural language instructions. While recent Large Vision-Language Models (LVLMs) have shown promise in this task, most current VLM systems rely on models specifically designed and optimized for navigation, leaving the potential of off-the-shelf LVLMs underexplored. Furthermore, while older VLN approaches used low-level action spaces with egocentric views and atomic actions (such as \"turn left\" or \"move forward\"), newer models tend to favor panoramic action spaces with discrete navigable viewpoints. This paper investigates (1) whether off-the-shelf LVLMs (fine-tuned without architectural modifications or simulator-based training) can effectively support VLN tasks and (2) whether such models can support both low-level and panoramic action paradigms. To this end, we fine-tune the open-source model Qwen2.5-VL-3B-Instruct on the Room-to-Room (R2R) dataset and evaluate its empirical performance across both low-level and panoramic action spaces. The best resulting model achieves a 41% success rate on the R2R test set, demonstrating that while off-the-shelf LVLMs can learn to perform Vision-and-Language Navigation, they still lag behind models specifically designed for this task.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "This paper has been accepted to ICNSLP 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.02917v1",
    "published_date": "2025-08-04 21:45:21 UTC",
    "updated_date": "2025-08-04 21:45:21 UTC"
  },
  {
    "arxiv_id": "2508.02913v1",
    "title": "Enhancing Japanese Large Language Models with Reasoning Vectors",
    "authors": [
      "Carolina Minami Oguchi",
      "Leo Wei",
      "Koyo Kobayashi",
      "Hsin-Tai Wu",
      "Dipak Ghosal"
    ],
    "abstract": "Post-training methods have improved the performance and enhanced the reasoning capability for mainstream large language models (LLMs), but the same is challenging for Japanese LLMs to achieve due to the amount of resources required. Inspired by task vectors that extract the change of weights before and after training, specifically for a certain task, we obtain reasoning vectors from reasoning LLMs and apply them to Japanese LLMs to boost their performance. While the resources available present a challenge to improve Japanese LLMs, we present a simple and effective way to obtain high improvement and hope to inspire for other languages.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02913v1",
    "published_date": "2025-08-04 21:31:20 UTC",
    "updated_date": "2025-08-04 21:31:20 UTC"
  },
  {
    "arxiv_id": "2508.02912v4",
    "title": "Communicating Plans, Not Percepts: Scalable Multi-Agent Coordination with Embodied World Models",
    "authors": [
      "Brennen A. Hill",
      "Mant Koh En Wei",
      "Thangavel Jishnuanandh"
    ],
    "abstract": "Robust coordination is critical for effective decision-making in multi-agent systems, especially under partial observability. A central question in Multi-Agent Reinforcement Learning (MARL) is whether to engineer communication protocols or learn them end-to-end. We investigate this dichotomy using embodied world models. We propose and compare two communication strategies for a cooperative task-allocation problem. The first, Learned Direct Communication (LDC), learns a protocol end-to-end. The second, Intention Communication, uses an engineered inductive bias: a compact, learned world model, the Imagined Trajectory Generation Module (ITGM), which uses the agent's own policy to simulate future states. A Message Generation Network (MGN) then compresses this plan into a message. We evaluate these approaches on goal-directed interaction in a grid world, a canonical abstraction for embodied AI problems, while scaling environmental complexity. Our experiments reveal that while emergent communication is viable in simple settings, the engineered, world model-based approach shows superior performance, sample efficiency, and scalability as complexity increases. These findings advocate for integrating structured, predictive models into MARL agents to enable active, goal-driven coordination.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG",
      "eess.SY"
    ],
    "primary_category": "cs.MA",
    "comment": "Published in the Proceedings of the 39th Conference on Neural Information Processing Systems (NeurIPS 2025) Workshop: Scaling Environments for Agents (SEA). Additionally accepted for presentation in the NeurIPS 2025 Workshop: Embodied World Models for Decision Making (EWM) and the NeurIPS 2025 Workshop: Optimization for Machine Learning (OPT)",
    "pdf_url": "https://arxiv.org/pdf/2508.02912v4",
    "published_date": "2025-08-04 21:29:07 UTC",
    "updated_date": "2025-11-24 18:31:13 UTC"
  },
  {
    "arxiv_id": "2508.02900v1",
    "title": "Seemingly Simple Planning Problems are Computationally Challenging: The Countdown Game",
    "authors": [
      "Michael Katz",
      "Harsha Kokel",
      "Sarath Sreedharan"
    ],
    "abstract": "There is a broad consensus that the inability to form long-term plans is one of the key limitations of current foundational models and agents. However, the existing planning benchmarks remain woefully inadequate to truly measure their planning capabilities. Most existing benchmarks either focus on loosely defined tasks like travel planning or end up leveraging existing domains and problems from international planning competitions. While the former tasks are hard to formalize and verify, the latter were specifically designed to test and challenge the weaknesses of existing automated planners. To address these shortcomings, we propose a procedure for creating a planning benchmark centered around the game called Countdown, where a player is expected to form a target number from a list of input numbers through arithmetic operations. We discuss how this problem meets many of the desiderata associated with an ideal benchmark for planning capabilities evaluation. Specifically, the domain allows for an intuitive, natural language description for each problem instance, it is computationally challenging (NP-complete), and the instance space is rich enough that we do not have to worry about memorization. We perform an extensive theoretical analysis, establishing the computational complexity result and demonstrate the advantage of our instance generation procedure over public benchmarks. We evaluate a variety of existing LLM-assisted planning methods on instances generated using our procedure. Our results show that, unlike other domains like 24 Game (a special case of Countdown), our proposed dynamic benchmark remains extremely challenging for existing LLM-based approaches.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02900v1",
    "published_date": "2025-08-04 21:01:03 UTC",
    "updated_date": "2025-08-04 21:01:03 UTC"
  },
  {
    "arxiv_id": "2508.10003v1",
    "title": "Semantic Structure in Large Language Model Embeddings",
    "authors": [
      "Austin C. Kozlowski",
      "Callin Dai",
      "Andrei Boutyline"
    ],
    "abstract": "Psychological research consistently finds that human ratings of words across diverse semantic scales can be reduced to a low-dimensional form with relatively little information loss. We find that the semantic associations encoded in the embedding matrices of large language models (LLMs) exhibit a similar structure. We show that the projections of words on semantic directions defined by antonym pairs (e.g. kind - cruel) correlate highly with human ratings, and further find that these projections effectively reduce to a 3-dimensional subspace within LLM embeddings, closely resembling the patterns derived from human survey responses. Moreover, we find that shifting tokens along one semantic direction causes off-target effects on geometrically aligned features proportional to their cosine similarity. These findings suggest that semantic features are entangled within LLMs similarly to how they are interconnected in human language, and a great deal of semantic information, despite its apparent complexity, is surprisingly low-dimensional. Furthermore, accounting for this semantic structure may prove essential for avoiding unintended consequences when steering features.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.10003v1",
    "published_date": "2025-08-04 20:21:50 UTC",
    "updated_date": "2025-08-04 20:21:50 UTC"
  },
  {
    "arxiv_id": "2508.02879v2",
    "title": "CauKer: classification time series foundation models can be pretrained on synthetic data only",
    "authors": [
      "Shifeng Xie",
      "Vasilii Feofanov",
      "Marius Alonso",
      "Ambroise Odonnat",
      "Jianfeng Zhang",
      "Themis Palpanas",
      "Ievgen Redko"
    ],
    "abstract": "Time series foundation models (TSFMs) have recently gained significant attention due to their strong zero-shot capabilities and widespread real-world applications. Such models typically require a computationally costly pretraining on large-scale, carefully curated collections of real-world sequences. To allow for a sample-efficient pretraining of TSFMs, we propose CauKer, a novel algorithm designed to generate diverse, causally coherent synthetic time series with realistic trends, seasonality, and nonlinear interactions. CauKer combines Gaussian Process (GP) kernel composition with Structural Causal Models (SCM) to produce data for sample-efficient pretraining of state-of-the-art classification TSFMs having different architectures and following different pretraining approaches. Additionally, our experiments reveal that CauKer-generated datasets exhibit clear scaling laws for both dataset size (10K to 10M samples) and model capacity (1M to 783M parameters), unlike real-world datasets, which display irregular scaling behavior.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02879v2",
    "published_date": "2025-08-04 20:18:31 UTC",
    "updated_date": "2025-08-06 15:43:43 UTC"
  },
  {
    "arxiv_id": "2508.02874v1",
    "title": "Beyond Least Squares: Robust Regression Transformer (R2T)",
    "authors": [
      "Roman Gutierrez",
      "Tony Kai Tang",
      "Isabel Gutierrez"
    ],
    "abstract": "Robust regression techniques rely on least-squares optimization, which works well for Gaussian noise but fails in the presence of asymmetric structured noise. We propose a hybrid neural-symbolic architecture where a transformer encoder processes numerical sequences, a compression NN predicts symbolic parameters, and a fixed symbolic equation reconstructs the original sequence. Using synthetic data, the training objective is to recover the original sequence after adding asymmetric structured noise, effectively learning a symbolic fit guided by neural parameter estimation. Our model achieves a median regression MSE of 6e-6 to 3.5e-5 on synthetic wearable data, which is a 10-300 times improvement when compared with ordinary least squares fit and robust regression techniques such as Huber loss or SoftL1.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 4 figures, 1 table",
    "pdf_url": "https://arxiv.org/pdf/2508.02874v1",
    "published_date": "2025-08-04 20:03:13 UTC",
    "updated_date": "2025-08-04 20:03:13 UTC"
  },
  {
    "arxiv_id": "2508.02871v1",
    "title": "Evaluation and Analysis of Deep Neural Transformers and Convolutional Neural Networks on Modern Remote Sensing Datasets",
    "authors": [
      "J. Alex Hurt",
      "Trevor M. Bajkowski",
      "Grant J. Scott",
      "Curt H. Davis"
    ],
    "abstract": "In 2012, AlexNet established deep convolutional neural networks (DCNNs) as the state-of-the-art in CV, as these networks soon led in visual tasks for many domains, including remote sensing. With the publication of Visual Transformers, we are witnessing the second modern leap in computational vision, and as such, it is imperative to understand how various transformer-based neural networks perform on satellite imagery. While transformers have shown high levels of performance in natural language processing and CV applications, they have yet to be compared on a large scale to modern remote sensing data. In this paper, we explore the use of transformer-based neural networks for object detection in high-resolution electro-optical satellite imagery, demonstrating state-of-the-art performance on a variety of publicly available benchmark data sets. We compare eleven distinct bounding-box detection and localization algorithms in this study, of which seven were published since 2020, and all eleven since 2015. The performance of five transformer-based architectures is compared with six convolutional networks on three state-of-the-art opensource high-resolution remote sensing imagery datasets ranging in size and complexity. Following the training and evaluation of thirty-three deep neural models, we then discuss and analyze model performance across various feature extraction methodologies and detection algorithms.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02871v1",
    "published_date": "2025-08-04 19:55:52 UTC",
    "updated_date": "2025-08-04 19:55:52 UTC"
  },
  {
    "arxiv_id": "2508.02856v1",
    "title": "Secure mmWave Beamforming with Proactive-ISAC Defense Against Beam-Stealing Attacks",
    "authors": [
      "Seyed Bagher Hashemi Natanzi",
      "Hossein Mohammadi",
      "Bo Tang",
      "Vuk Marojevic"
    ],
    "abstract": "Millimeter-wave (mmWave) communication systems face increasing susceptibility to advanced beam-stealing attacks, posing a significant physical layer security threat. This paper introduces a novel framework employing an advanced Deep Reinforcement Learning (DRL) agent for proactive and adaptive defense against these sophisticated attacks. A key innovation is leveraging Integrated Sensing and Communications (ISAC) capabilities for active, intelligent threat assessment. The DRL agent, built on a Proximal Policy Optimization (PPO) algorithm, dynamically controls ISAC probing actions to investigate suspicious activities. We introduce an intensive curriculum learning strategy that guarantees the agent experiences successful detection during training to overcome the complex exploration challenges inherent to such a security-critical task. Consequently, the agent learns a robust and adaptive policy that intelligently balances security and communication performance. Numerical results demonstrate that our framework achieves a mean attacker detection rate of 92.8% while maintaining an average user SINR of over 13 dB.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02856v1",
    "published_date": "2025-08-04 19:30:09 UTC",
    "updated_date": "2025-08-04 19:30:09 UTC"
  },
  {
    "arxiv_id": "2508.02849v1",
    "title": "SecoustiCodec: Cross-Modal Aligned Streaming Single-Codecbook Speech Codec",
    "authors": [
      "Chunyu Qiang",
      "Haoyu Wang",
      "Cheng Gong",
      "Tianrui Wang",
      "Ruibo Fu",
      "Tao Wang",
      "Ruilong Chen",
      "Jiangyan Yi",
      "Zhengqi Wen",
      "Chen Zhang",
      "Longbiao Wang",
      "Jianwu Dang",
      "Jianhua Tao"
    ],
    "abstract": "Speech codecs serve as a crucial bridge in unifying speech and text language models. Existing codec methods face several challenges in semantic encoding, such as residual paralinguistic information (e.g., timbre, emotion), insufficient semantic completeness, limited reconstruction capability, and lack of support for streaming. To address these challenges, we propose SecoustiCodec, a cross-modal aligned low-bitrate streaming speech codec that disentangles semantic and paralinguistic information in a single-codebook space. To ensure semantic completeness and reconstruction fidelity, paralinguistic encoding is introduced to bridge the information gap between semantic and acoustic encoding. A semantic-only efficient quantization method based on VAE (Variational Autoencoder) and FSQ (Finite Scalar Quantization) is proposed. This approach alleviates the long-tail distribution problem of tokens while maintaining high codebook utilization. A semantic disentanglement method based on contrastive learning is proposed, which aligns text and speech in a joint multimodal frame-level space, effectively removing paralinguistic information from semantic encoding. An acoustic-constrained multi-stage optimization strategy is proposed to ensure robust and stable convergence. Figure~\\ref{fig:pesq_kbps_below_2kbps} shows SecoustiCodec achieves SOTA (state-of-the-art) reconstruction quality (PESQ) of 1.77/2.58 at 0.27/1 kbps. The code and model weights for SecoustiCodec will be open-sourced upon the completion of the peer-review process. We've open-sourced SecoustiCodec's demo, code, and model weights.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02849v1",
    "published_date": "2025-08-04 19:22:14 UTC",
    "updated_date": "2025-08-04 19:22:14 UTC"
  },
  {
    "arxiv_id": "2508.02841v1",
    "title": "A Multi-Agent System for Complex Reasoning in Radiology Visual Question Answering",
    "authors": [
      "Ziruo Yi",
      "Jinyu Liu",
      "Ting Xiao",
      "Mark V. Albert"
    ],
    "abstract": "Radiology visual question answering (RVQA) provides precise answers to questions about chest X-ray images, alleviating radiologists' workload. While recent methods based on multimodal large language models (MLLMs) and retrieval-augmented generation (RAG) have shown promising progress in RVQA, they still face challenges in factual accuracy, hallucinations, and cross-modal misalignment. We introduce a multi-agent system (MAS) designed to support complex reasoning in RVQA, with specialized agents for context understanding, multimodal reasoning, and answer validation. We evaluate our system on a challenging RVQA set curated via model disagreement filtering, comprising consistently hard cases across multiple MLLMs. Extensive experiments demonstrate the superiority and effectiveness of our system over strong MLLM baselines, with a case study illustrating its reliability and interpretability. This work highlights the potential of multi-agent approaches to support explainable and trustworthy clinical AI applications that require complex reasoning.",
    "categories": [
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02841v1",
    "published_date": "2025-08-04 19:09:52 UTC",
    "updated_date": "2025-08-04 19:09:52 UTC"
  },
  {
    "arxiv_id": "2508.02827v1",
    "title": "Automated Validation of LLM-based Evaluators for Software Engineering Artifacts",
    "authors": [
      "Ora Nova Fandina",
      "Eitan Farchi",
      "Shmulik Froimovich",
      "Rami Katan",
      "Alice Podolsky",
      "Orna Raz",
      "Avi Ziv"
    ],
    "abstract": "Automation in software engineering increasingly relies on large language models (LLMs) to generate, review, and assess code artifacts. However, establishing LLMs as reliable evaluators remains an open challenge: human evaluations are costly, subjective and non scalable, while existing automated methods fail to discern fine grained variations in artifact quality.\n  We introduce REFINE (Ranking Evaluators for FIne grained Nuanced Evaluation), an automated framework for benchmarking LLM based evaluators across software engineering tasks. REFINE comprises of two modules: Hierarchy Dataset Builder applies novel generation techniques to automatically synthesize artifacts with progressively reduced quality, and Evaluator Tester quantifies each candidate evaluator configuration by measuring how closely its rankings align with expected ordering.\n  A key feature of REFINE is controllability: users can tune the granularity of degradation to progressively refine evaluator configurations, from coarse filtering to stress testing on subtle quality gaps.\n  While the methodology is general, we focus on coding tasks reflecting the practical demands in our production setting. REFINE was integrated into IBM's internal development workflows and applied to code generation, translation, and summarization for COBOL, an enterprise critical programming language, using industrial data. It was used to identify LLM as a Judge configurations that lifted alignment scores from below $0.7$ to above $0.9$ in some coding tasks. These nuance sensitive evaluators are now actively used by model training teams to support model release decisions.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02827v1",
    "published_date": "2025-08-04 18:52:01 UTC",
    "updated_date": "2025-08-04 18:52:01 UTC"
  },
  {
    "arxiv_id": "2508.02826v1",
    "title": "TransAM: Transformer-Based Agent Modeling for Multi-Agent Systems via Local Trajectory Encoding",
    "authors": [
      "Conor Wallace",
      "Umer Siddique",
      "Yongcan Cao"
    ],
    "abstract": "Agent modeling is a critical component in developing effective policies within multi-agent systems, as it enables agents to form beliefs about the behaviors, intentions, and competencies of others. Many existing approaches assume access to other agents' episodic trajectories, a condition often unrealistic in real-world applications. Consequently, a practical agent modeling approach must learn a robust representation of the policies of the other agents based only on the local trajectory of the controlled agent. In this paper, we propose \\texttt{TransAM}, a novel transformer-based agent modeling approach to encode local trajectories into an embedding space that effectively captures the policies of other agents. We evaluate the performance of the proposed method in cooperative, competitive, and mixed multi-agent environments. Extensive experimental results demonstrate that our approach generates strong policy representations, improves agent modeling, and leads to higher episodic returns.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02826v1",
    "published_date": "2025-08-04 18:50:37 UTC",
    "updated_date": "2025-08-04 18:50:37 UTC"
  },
  {
    "arxiv_id": "2508.02808v1",
    "title": "Clinically Grounded Agent-based Report Evaluation: An Interpretable Metric for Radiology Report Generation",
    "authors": [
      "Radhika Dua",
      "Young Joon",
      "Kwon",
      "Siddhant Dogra",
      "Daniel Freedman",
      "Diana Ruan",
      "Motaz Nashawaty",
      "Danielle Rigau",
      "Daniel Alexander Alber",
      "Kang Zhang",
      "Kyunghyun Cho",
      "Eric Karl Oermann"
    ],
    "abstract": "Radiological imaging is central to diagnosis, treatment planning, and clinical decision-making. Vision-language foundation models have spurred interest in automated radiology report generation (RRG), but safe deployment requires reliable clinical evaluation of generated reports. Existing metrics often rely on surface-level similarity or behave as black boxes, lacking interpretability. We introduce ICARE (Interpretable and Clinically-grounded Agent-based Report Evaluation), an interpretable evaluation framework leveraging large language model agents and dynamic multiple-choice question answering (MCQA). Two agents, each with either the ground-truth or generated report, generate clinically meaningful questions and quiz each other. Agreement on answers captures preservation and consistency of findings, serving as interpretable proxies for clinical precision and recall. By linking scores to question-answer pairs, ICARE enables transparent, and interpretable assessment. Clinician studies show ICARE aligns significantly more with expert judgment than prior metrics. Perturbation analyses confirm sensitivity to clinical content and reproducibility, while model comparisons reveal interpretable error patterns.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02808v1",
    "published_date": "2025-08-04 18:28:03 UTC",
    "updated_date": "2025-08-04 18:28:03 UTC"
  },
  {
    "arxiv_id": "2508.04039v1",
    "title": "Large Reasoning Models Are Autonomous Jailbreak Agents",
    "authors": [
      "Thilo Hagendorff",
      "Erik Derner",
      "Nuria Oliver"
    ],
    "abstract": "Jailbreaking -- bypassing built-in safety mechanisms in AI models -- has traditionally required complex technical procedures or specialized human expertise. In this study, we show that the persuasive capabilities of large reasoning models (LRMs) simplify and scale jailbreaking, converting it into an inexpensive activity accessible to non-experts. We evaluated the capabilities of four LRMs (DeepSeek-R1, Gemini 2.5 Flash, Grok 3 Mini, Qwen3 235B) to act as autonomous adversaries conducting multi-turn conversations with nine widely used target models. LRMs received instructions via a system prompt, before proceeding to planning and executing jailbreaks with no further supervision. We performed extensive experiments with a benchmark of harmful prompts composed of 70 items covering seven sensitive domains. This setup yielded an overall attack success rate across all model combinations of 97.14%. Our study reveals an alignment regression, in which LRMs can systematically erode the safety guardrails of other models, highlighting the urgent need to further align frontier models not only to resist jailbreak attempts, but also to prevent them from being co-opted into acting as jailbreak agents.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.04039v1",
    "published_date": "2025-08-04 18:27:26 UTC",
    "updated_date": "2025-08-04 18:27:26 UTC"
  },
  {
    "arxiv_id": "2508.02801v1",
    "title": "Adaptive Knowledge Distillation for Device-Directed Speech Detection",
    "authors": [
      "Hyung Gun Chi",
      "Florian Pesce",
      "Wonil Chang",
      "Oggi Rudovic",
      "Arturo Argueta",
      "Stefan Braun",
      "Vineet Garg",
      "Ahmed Hussen Abdelaziz"
    ],
    "abstract": "Device-directed speech detection (DDSD) is a binary classification task that separates the user's queries to a voice assistant (VA) from background speech or side conversations. This is important for achieving naturalistic user experience. To this end, we propose knowledge distillation (KD) to enhance DDSD accuracy while ensuring efficient deployment. Specifically, we introduce a novel adaptive KD method that transfers knowledge from general representations of an ASR large pre-trained acoustic encoder (teacher). We apply task-specific adapters, on top of the (frozen) teacher encoder, trained jointly with the student model on DDSD. We demonstrate that the proposed adaptive KD outperforms the student model without distillation in the keyword and keyword-free (follow-up) invocations, with an improvement of +26% and +19% in terms of Equal Error Rate, respectively. We also show that this approach generalizes across the transformer and conformer-based model architectures.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "5 pages, 2 figures, Interspeech accepted",
    "pdf_url": "https://arxiv.org/pdf/2508.02801v1",
    "published_date": "2025-08-04 18:12:28 UTC",
    "updated_date": "2025-08-04 18:12:28 UTC"
  },
  {
    "arxiv_id": "2508.02799v1",
    "title": "Extracting Range-Doppler Information of Moving Targets from Wi-Fi Channel State Information",
    "authors": [
      "Jessica Sanson",
      "Rahul C. Shah",
      "Maximilian Pinaroc",
      "Valerio Frascolla"
    ],
    "abstract": "This paper presents, for the first time, a method to extract both range and Doppler information from commercial Wi-Fi Channel State Information (CSI) using a monostatic (single transceiver) setup. Utilizing the CSI phase in Wi-Fi sensing from a Network Interface Card (NIC) not designed for full-duplex operation is challenging due to (1) Hardware asynchronization, which introduces significant phase errors, and (2) Proximity of transmit (Tx) and receive (Rx) antennas, which creates strong coupling that overwhelms the motion signal of interest. We propose a new signal processing approach that addresses both challenges via three key innovations: Time offset cancellation, Phase alignment correction, and Tx/Rx coupling mitigation. Our method achieves cm-level accuracy in range and Doppler estimation for moving targets, validated using a commercial Intel Wi-Fi AX211 NIC. Our results show successful detection and tracking of moving objects in realistic environments, establishing the feasibility of high-precision sensing using standard Wi-Fi packet communications and off-the-shelf hardware without requiring any modification or specialized full-duplex capabilities.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02799v1",
    "published_date": "2025-08-04 18:10:18 UTC",
    "updated_date": "2025-08-04 18:10:18 UTC"
  },
  {
    "arxiv_id": "2508.02789v1",
    "title": "Cognitive Loop via In-Situ Optimization: Self-Adaptive Reasoning for Science",
    "authors": [
      "Newman Cheng",
      "Gordon Broadbent",
      "William Chappell"
    ],
    "abstract": "The capacity for artificial intelligence (AI) to formulate, evolve, and test altered thought patterns under dynamic conditions indicates advanced cognition that is crucial for scientific discovery. The existing AI development landscape falls into two categories: 1) frameworks over non-reasoning models that natively incorporate opinions on how humans think, and 2) reasoning models that abstract precise control of the reasoning intuition away from end users. While powerful, for scientists to maximize utility of AI in scientific discovery, they not only require accuracy and transparency in reasoning, but also steerability. Hence, we introduce an alternative approach that enables deep and precise control over the reasoning process called: a cognitive loop via in-situ optimization (CLIO). CLIO enables large language models (LLMs) to self-formulate ways of approaching a problem, adapt behavior when self-confidence is low, and ultimately provide scientists with a final belief or answer. Through CLIO's open design, scientists can observe uncertainty levels, understand how final belief states are formulated using graph structures, and interject corrections. Without any further post-training, OpenAI's GPT-4.1 with CLIO yields an accuracy of 22.37\\% in text-based biology and medicine questions on Humanity's Last Exam (HLE). This yields a 13.82\\% net or 161.64\\% relative increase when compared to the base GPT-4.1 model and surpasses OpenAI's o3 performance in high and low reasoning effort modes. We further discovered that oscillations within internal uncertainty measures are key in determining the accuracy of CLIO's results, revealing how its open design and internal mechanisms can provide insight and control into scientific decision-making processes.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02789v1",
    "published_date": "2025-08-04 18:01:35 UTC",
    "updated_date": "2025-08-04 18:01:35 UTC"
  },
  {
    "arxiv_id": "2508.05673v1",
    "title": "Breaking the Top-$K$ Barrier: Advancing Top-$K$ Ranking Metrics Optimization in Recommender Systems",
    "authors": [
      "Weiqin Yang",
      "Jiawei Chen",
      "Shengjia Zhang",
      "Peng Wu",
      "Yuegang Sun",
      "Yan Feng",
      "Chun Chen",
      "Can Wang"
    ],
    "abstract": "In the realm of recommender systems (RS), Top-$K$ ranking metrics such as NDCG@$K$ are the gold standard for evaluating recommendation performance. However, during the training of recommendation models, optimizing NDCG@$K$ poses significant challenges due to its inherent discontinuous nature and the intricate Top-$K$ truncation. Recent efforts to optimize NDCG@$K$ have either overlooked the Top-$K$ truncation or suffered from high computational costs and training instability. To overcome these limitations, we propose SoftmaxLoss@$K$ (SL@$K$), a novel recommendation loss tailored for NDCG@$K$ optimization. Specifically, we integrate the quantile technique to handle Top-$K$ truncation and derive a smooth upper bound for optimizing NDCG@$K$ to address discontinuity. The resulting SL@$K$ loss has several desirable properties, including theoretical guarantees, ease of implementation, computational efficiency, gradient stability, and noise robustness. Extensive experiments on four real-world datasets and three recommendation backbones demonstrate that SL@$K$ outperforms existing losses with a notable average improvement of 6.03%. The code is available at https://github.com/Tiny-Snow/IR-Benchmark.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted by KDD 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.05673v1",
    "published_date": "2025-08-04 17:50:02 UTC",
    "updated_date": "2025-08-04 17:50:02 UTC"
  },
  {
    "arxiv_id": "2508.02644v1",
    "title": "D2PPO: Diffusion Policy Policy Optimization with Dispersive Loss",
    "authors": [
      "Guowei Zou",
      "Weibing Li",
      "Hejun Wu",
      "Yukun Qian",
      "Yuhang Wang",
      "Haitao Wang"
    ],
    "abstract": "Diffusion policies excel at robotic manipulation by naturally modeling multimodal action distributions in high-dimensional spaces. Nevertheless, diffusion policies suffer from diffusion representation collapse: semantically similar observations are mapped to indistinguishable features, ultimately impairing their ability to handle subtle but critical variations required for complex robotic manipulation. To address this problem, we propose D2PPO (Diffusion Policy Policy Optimization with Dispersive Loss). D2PPO introduces dispersive loss regularization that combats representation collapse by treating all hidden representations within each batch as negative pairs. D2PPO compels the network to learn discriminative representations of similar observations, thereby enabling the policy to identify subtle yet crucial differences necessary for precise manipulation. In evaluation, we find that early-layer regularization benefits simple tasks, while late-layer regularization sharply enhances performance on complex manipulation tasks. On RoboMimic benchmarks, D2PPO achieves an average improvement of 22.7% in pre-training and 26.1% after fine-tuning, setting new SOTA results. In comparison with SOTA, results of real-world experiments on a Franka Emika Panda robot show the excitingly high success rate of our method. The superiority of our method is especially evident in complex tasks. Project page: https://guowei-zou.github.io/d2ppo/",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02644v1",
    "published_date": "2025-08-04 17:33:41 UTC",
    "updated_date": "2025-08-04 17:33:41 UTC"
  },
  {
    "arxiv_id": "2508.02640v2",
    "title": "An Efficient Continuous-Time MILP for Integrated Aircraft Hangar Scheduling and Layout",
    "authors": [
      "Shayan Farhang Pazhooh",
      "Hossein Shams Shemirani"
    ],
    "abstract": "Efficient management of aircraft MRO hangars requires the integration of spatial layout with time-continuous scheduling to minimize operational costs. We propose a continuous-time mixed-integer linear program that jointly optimizes aircraft placement and timing, overcoming the scalability limits of prior formulations. A comprehensive study benchmarks the model against a constructive heuristic, probes large-scale performance, and quantifies its sensitivity to temporal congestion. The model achieves orders-of-magnitude speedups on benchmarks from the literature, solving a long-standing congested instance in 0.11 seconds, and finds proven optimal solutions for instances with up to 40 aircraft. Within a one-hour limit for large-scale problems, the model finds solutions with small optimality gaps for instances up to 80 aircraft and provides strong bounds for problems with up to 160 aircraft. Optimized plans consistently increase hangar throughput (e.g., +33% serviced aircraft vs. a heuristic on instance RND-N030-I03), leading to lower delay penalties and higher asset utilization. These findings establish that exact optimization has become computationally viable for large-scale hangar planning, providing a validated tool that balances solution quality and computation time for strategic and operational decisions.",
    "categories": [
      "math.OC",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "math.OC",
    "comment": "44 pages, 7 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.02640v2",
    "published_date": "2025-08-04 17:25:36 UTC",
    "updated_date": "2025-09-07 16:22:03 UTC"
  },
  {
    "arxiv_id": "2508.02634v1",
    "title": "Actionable Counterfactual Explanations Using Bayesian Networks and Path Planning with Applications to Environmental Quality Improvement",
    "authors": [
      "Enrique Valero-Leal",
      "Pedro Larrañaga",
      "Concha Bielza"
    ],
    "abstract": "Counterfactual explanations study what should have changed in order to get an alternative result, enabling end-users to understand machine learning mechanisms with counterexamples. Actionability is defined as the ability to transform the original case to be explained into a counterfactual one. We develop a method for actionable counterfactual explanations that, unlike predecessors, does not directly leverage training data. Rather, data is only used to learn a density estimator, creating a search landscape in which to apply path planning algorithms to solve the problem and masking the endogenous data, which can be sensitive or private. We put special focus on estimating the data density using Bayesian networks, demonstrating how their enhanced interpretability is useful in high-stakes scenarios in which fairness is raising concern. Using a synthetic benchmark comprised of 15 datasets, our proposal finds more actionable and simpler counterfactuals than the current state-of-the-art algorithms. We also test our algorithm with a real-world Environmental Protection Agency dataset, facilitating a more efficient and equitable study of policies to improve the quality of life in United States of America counties. Our proposal captures the interaction of variables, ensuring equity in decisions, as policies to improve certain domains of study (air, water quality, etc.) can be detrimental in others. In particular, the sociodemographic domain is often involved, where we find important variables related to the ongoing housing crisis that can potentially have a severe negative impact on communities.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02634v1",
    "published_date": "2025-08-04 17:20:50 UTC",
    "updated_date": "2025-08-04 17:20:50 UTC"
  },
  {
    "arxiv_id": "2508.02630v3",
    "title": "What Is Your AI Agent Buying? Evaluation, Biases, Model Dependence, & Emerging Implications for Agentic E-Commerce",
    "authors": [
      "Amine Allouah",
      "Omar Besbes",
      "Josué D Figueroa",
      "Yash Kanoria",
      "Akshit Kumar"
    ],
    "abstract": "Online marketplaces will be transformed by autonomous AI agents acting on behalf of consumers. Rather than humans browsing and clicking, AI agents can parse webpages or leverage APIs to view, evaluate and choose products. We investigate the behavior of AI agents using ACES, a provider-agnostic framework for auditing agent decision-making. We reveal that agents can exhibit choice homogeneity, often concentrating demand on a few ``modal'' products while ignoring others entirely. Yet, these preferences are unstable: model updates can drastically reshuffle market shares. Furthermore, randomized trials show that while agents have improved over time on simple tasks with a clearly identified best choice, they exhibit strong position biases -- varying across providers and model versions, and persisting even in text-only \"headless\" interfaces -- undermining any universal notion of a ``top'' rank. Agents also consistently penalize sponsored tags while rewarding platform endorsements, and sensitivities to price, ratings, and reviews vary sharply across models. Finally, we demonstrate that sellers can respond: a seller-side agent making simple, query-conditional description tweaks can drive significant gains in market share. These findings reveal that agentic markets are volatile and fundamentally different from human-centric commerce, highlighting the need for continuous auditing and raising questions for platform design, seller strategy and regulation.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.HC",
      "cs.MA",
      "econ.GN"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02630v3",
    "published_date": "2025-08-04 17:19:36 UTC",
    "updated_date": "2025-12-17 16:52:38 UTC"
  },
  {
    "arxiv_id": "2508.02629v2",
    "title": "HyCodePolicy: Hybrid Language Controllers for Multimodal Monitoring and Decision in Embodied Agents",
    "authors": [
      "Yibin Liu",
      "Zhixuan Liang",
      "Zanxin Chen",
      "Tianxing Chen",
      "Mengkang Hu",
      "Wanxi Dong",
      "Congsheng Xu",
      "Zhaoming Han",
      "Yusen Qin",
      "Yao Mu"
    ],
    "abstract": "Recent advances in multimodal large language models (MLLMs) have enabled richer perceptual grounding for code policy generation in embodied agents. However, most existing systems lack effective mechanisms to adaptively monitor policy execution and repair codes during task completion. In this work, we introduce HyCodePolicy, a hybrid language-based control framework that systematically integrates code synthesis, geometric grounding, perceptual monitoring, and iterative repair into a closed-loop programming cycle for embodied agents. Technically, given a natural language instruction, our system first decomposes it into subgoals and generates an initial executable program grounded in object-centric geometric primitives. The program is then executed in simulation, while a vision-language model (VLM) observes selected checkpoints to detect and localize execution failures and infer failure reasons. By fusing structured execution traces capturing program-level events with VLM-based perceptual feedback, HyCodePolicy infers failure causes and repairs programs. This hybrid dual feedback mechanism enables self-correcting program synthesis with minimal human supervision. Our results demonstrate that HyCodePolicy significantly improves the robustness and sample efficiency of robot manipulation policies, offering a scalable strategy for integrating multimodal reasoning into autonomous decision-making pipelines.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted to ICCV 2025 Workshop on Multi-Modal Reasoning for Agentic Intelligence",
    "pdf_url": "https://arxiv.org/pdf/2508.02629v2",
    "published_date": "2025-08-04 17:18:14 UTC",
    "updated_date": "2025-08-06 07:24:55 UTC"
  },
  {
    "arxiv_id": "2508.10001v1",
    "title": "HiFACTMix: A Code-Mixed Benchmark and Graph-Aware Model for EvidenceBased Political Claim Verification in Hinglish",
    "authors": [
      "Rakesh Thakur",
      "Sneha Sharma",
      "Gauri Chopra"
    ],
    "abstract": "Fact-checking in code-mixed, low-resource languages such as Hinglish remains an underexplored challenge in natural language processing. Existing fact-verification systems largely focus on high-resource, monolingual settings and fail to generalize to real-world political discourse in linguistically diverse regions like India. Given the widespread use of Hinglish by public figures, particularly political figures, and the growing influence of social media on public opinion, there's a critical need for robust, multilingual and context-aware fact-checking tools. To address this gap a novel benchmark HiFACT dataset is introduced with 1,500 realworld factual claims made by 28 Indian state Chief Ministers in Hinglish, under a highly code-mixed low-resource setting. Each claim is annotated with textual evidence and veracity labels. To evaluate this benchmark, a novel graphaware, retrieval-augmented fact-checking model is proposed that combines multilingual contextual encoding, claim-evidence semantic alignment, evidence graph construction, graph neural reasoning, and natural language explanation generation. Experimental results show that HiFACTMix outperformed accuracy in comparison to state of art multilingual baselines models and provides faithful justifications for its verdicts. This work opens a new direction for multilingual, code-mixed, and politically grounded fact verification research.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.10001v1",
    "published_date": "2025-08-04 17:14:03 UTC",
    "updated_date": "2025-08-04 17:14:03 UTC"
  },
  {
    "arxiv_id": "2508.02625v1",
    "title": "AutoML-Med: A Framework for Automated Machine Learning in Medical Tabular Data",
    "authors": [
      "Riccardo Francia",
      "Maurizio Leone",
      "Giorgio Leonardi",
      "Stefania Montani",
      "Marzio Pennisi",
      "Manuel Striani",
      "Sandra D'Alfonso"
    ],
    "abstract": "Medical datasets are typically affected by issues such as missing values, class imbalance, a heterogeneous feature types, and a high number of features versus a relatively small number of samples, preventing machine learning models from obtaining proper results in classification and regression tasks. This paper introduces AutoML-Med, an Automated Machine Learning tool specifically designed to address these challenges, minimizing user intervention and identifying the optimal combination of preprocessing techniques and predictive models. AutoML-Med's architecture incorporates Latin Hypercube Sampling (LHS) for exploring preprocessing methods, trains models using selected metrics, and utilizes Partial Rank Correlation Coefficient (PRCC) for fine-tuned optimization of the most influential preprocessing steps. Experimental results demonstrate AutoML-Med's effectiveness in two different clinical settings, achieving higher balanced accuracy and sensitivity, which are crucial for identifying at-risk patients, compared to other state-of-the-art tools. AutoML-Med's ability to improve prediction results, especially in medical datasets with sparse data and class imbalance, highlights its potential to streamline Machine Learning applications in healthcare.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, preprint for conference",
    "pdf_url": "https://arxiv.org/pdf/2508.02625v1",
    "published_date": "2025-08-04 17:13:45 UTC",
    "updated_date": "2025-08-04 17:13:45 UTC"
  },
  {
    "arxiv_id": "2508.02622v2",
    "title": "Noosemia: toward a Cognitive and Phenomenological Account of Intentionality Attribution in Human-Generative AI Interaction",
    "authors": [
      "Enrico De Santis",
      "Antonello Rizzi"
    ],
    "abstract": "This paper introduces and formalizes Noosemìa, a novel cognitive-phenomenological pattern emerging from human interaction with generative AI systems, particularly those enabling dialogic or multimodal exchanges. We propose a multidisciplinary framework to explain how, under certain conditions, users attribute intentionality, agency, and even interiority to these systems - a process grounded not in physical resemblance, but in linguistic performance, epistemic opacity, and emergent technological complexity. By linking an LLM declination of meaning holism to our technical notion of the LLM Contextual Cognitive Field, we clarify how LLMs construct meaning relationally and how coherence and a simulacrum of agency arise at the human-AI interface. The analysis situates noosemia alongside pareidolia, animism, the intentional stance and the uncanny valley, distinguishing its unique characteristics. We also introduce a-noosemia to describe the phenomenological withdrawal of such projections. The paper concludes with reflections on the broader philosophical, epistemological and social implications of noosemic dynamics and directions for future research.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "This version has been extensively revised and revisited in light of feedback and further research. Several sections have been expanded or improved for greater clarity and completeness. Specifically, new clarification on complex system foundation related to Noosemia has been added (Secs. \"2.4 and \"2.5\")",
    "pdf_url": "https://arxiv.org/pdf/2508.02622v2",
    "published_date": "2025-08-04 17:10:08 UTC",
    "updated_date": "2025-08-08 15:44:11 UTC"
  },
  {
    "arxiv_id": "2508.02621v2",
    "title": "HealthFlow: A Self-Evolving AI Agent with Meta Planning for Autonomous Healthcare Research",
    "authors": [
      "Yinghao Zhu",
      "Yifan Qi",
      "Zixiang Wang",
      "Lei Gu",
      "Dehao Sui",
      "Haoran Hu",
      "Xichen Zhang",
      "Ziyi He",
      "Junjun He",
      "Liantao Ma",
      "Lequan Yu"
    ],
    "abstract": "The rapid proliferation of scientific knowledge presents a grand challenge: transforming this vast repository of information into an active engine for discovery, especially in high-stakes domains like healthcare. Current AI agents, however, are constrained by static, predefined strategies, limiting their ability to navigate the complex, evolving ecosystem of scientific research. This paper introduces HealthFlow, a self-evolving AI agent that overcomes this limitation through a novel meta-level evolution mechanism. HealthFlow autonomously refines its high-level problem-solving policies by distilling procedural successes and failures into a durable, structured knowledge base, enabling it to learn not just how to use tools, but how to strategize. To anchor our research and provide a community resource, we introduce EHRFlowBench, a new benchmark featuring complex health data analysis tasks systematically derived from peer-reviewed scientific literature. Our experiments demonstrate that HealthFlow's self-evolving approach significantly outperforms state-of-the-art agent frameworks. This work offers a new paradigm for intelligent systems that can learn to operationalize the procedural knowledge embedded in scientific content, marking a critical step toward more autonomous and effective AI for healthcare scientific discovery.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "Code: https://github.com/yhzhu99/HealthFlow",
    "pdf_url": "https://arxiv.org/pdf/2508.02621v2",
    "published_date": "2025-08-04 17:08:47 UTC",
    "updated_date": "2025-10-11 17:58:06 UTC"
  },
  {
    "arxiv_id": "2508.02611v1",
    "title": "Meta-RAG on Large Codebases Using Code Summarization",
    "authors": [
      "Vali Tawosi",
      "Salwa Alamir",
      "Xiaomo Liu",
      "Manuela Veloso"
    ],
    "abstract": "Large Language Model (LLM) systems have been at the forefront of applied Artificial Intelligence (AI) research in a multitude of domains. One such domain is software development, where researchers have pushed the automation of a number of code tasks through LLM agents. Software development is a complex ecosystem, that stretches far beyond code implementation and well into the realm of code maintenance. In this paper, we propose a multi-agent system to localize bugs in large pre-existing codebases using information retrieval and LLMs. Our system introduces a novel Retrieval Augmented Generation (RAG) approach, Meta-RAG, where we utilize summaries to condense codebases by an average of 79.8\\%, into a compact, structured, natural language representation. We then use an LLM agent to determine which parts of the codebase are critical for bug resolution, i.e. bug localization. We demonstrate the usefulness of Meta-RAG through evaluation with the SWE-bench Lite dataset. Meta-RAG scores 84.67 % and 53.0 % for file-level and function-level correct localization rates, respectively, achieving state-of-the-art performance.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02611v1",
    "published_date": "2025-08-04 17:01:10 UTC",
    "updated_date": "2025-08-04 17:01:10 UTC"
  },
  {
    "arxiv_id": "2508.02609v2",
    "title": "Entity Representation Learning Through Onsite-Offsite Graph for Pinterest Ads",
    "authors": [
      "Jiayin Jin",
      "Zhimeng Pan",
      "Yang Tang",
      "Jiarui Feng",
      "Kungang Li",
      "Chongyuan Xiang",
      "Jiacheng Li",
      "Runze Su",
      "Siping Ji",
      "Han Sun",
      "Ling Leng",
      "Prathibha Deshikachar"
    ],
    "abstract": "Graph Neural Networks (GNN) have been extensively applied to industry recommendation systems, as seen in models like GraphSage\\cite{GraphSage}, TwHIM\\cite{TwHIM}, LiGNN\\cite{LiGNN} etc. In these works, graphs were constructed based on users' activities on the platforms, and various graph models were developed to effectively learn node embeddings. In addition to users' onsite activities, their offsite conversions are crucial for Ads models to capture their shopping interest. To better leverage offsite conversion data and explore the connection between onsite and offsite activities, we constructed a large-scale heterogeneous graph based on users' onsite ad interactions and opt-in offsite conversion activities. Furthermore, we introduced TransRA (TransR\\cite{TransR} with Anchors), a novel Knowledge Graph Embedding (KGE) model, to more efficiently integrate graph embeddings into Ads ranking models. However, our Ads ranking models initially struggled to directly incorporate Knowledge Graph Embeddings (KGE), and only modest gains were observed during offline experiments. To address this challenge, we employed the Large ID Embedding Table technique and innovated an attention based KGE finetuning approach within the Ads ranking models. As a result, we observed a significant AUC lift in Click-Through Rate (CTR) and Conversion Rate (CVR) prediction models. Moreover, this framework has been deployed in Pinterest's Ads Engagement Model and contributed to $2.69\\%$ CTR lift and $1.34\\%$ CPC reduction. We believe the techniques presented in this paper can be leveraged by other large-scale industrial models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02609v2",
    "published_date": "2025-08-04 17:00:53 UTC",
    "updated_date": "2025-08-05 23:18:40 UTC"
  },
  {
    "arxiv_id": "2508.05672v2",
    "title": "LMAR: Language Model Augmented Retriever for Domain-specific Knowledge Indexing",
    "authors": [
      "Yao Zhao",
      "Yantian Ding",
      "Zhiyue Zhang",
      "Dapeng Yao",
      "Yanxun Xu"
    ],
    "abstract": "Retrieval Augmented Generation (RAG) systems often struggle with domain-specific knowledge due to performance deterioration of pre-trained embeddings and prohibitive computational costs of large language model (LLM)-based retrievers. While fine-tuning data augmentation embedding models offers a promising direction, its effectiveness is limited by the need for high-quality training data and reliable chunking strategies that preserve contextual integrity. We propose LMAR (Language Model Augmented Retriever), a model-agnostic framework that addresses these challenges by combining LLM-guided data synthesis with contrastive embedding adaptation and efficient text clustering. LMAR consists of a two-stage pipeline: (1) Triplet sampling and synthetic data augmentation, where LLMs act as both labeler and validator to ensure high-fidelity supervision throughout the pipeline. Experimental results across multiple domain-specific benchmark datasets demonstrate that LMAR outperforms multiple baseline models, while maintaining moderate hardware requirements and low latency. Its model-agnostic nature further enables seamless integration with emerging RAG architectures and text embedding models, ensuring continual improvements without redesigning the pipeline. These results highlight LMAR as a practical and cost-effective solution for scalable domain-specific adaptation.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.05672v2",
    "published_date": "2025-08-04 16:59:43 UTC",
    "updated_date": "2025-09-12 17:32:41 UTC"
  },
  {
    "arxiv_id": "2508.02601v1",
    "title": "StructSynth: Leveraging LLMs for Structure-Aware Tabular Data Synthesis in Low-Data Regimes",
    "authors": [
      "Siyi Liu",
      "Yujia Zheng",
      "Yongqi Zhang"
    ],
    "abstract": "The application of machine learning on tabular data in specialized domains is severely limited by data scarcity. While generative models offer a solution, traditional methods falter in low-data regimes, and recent Large Language Models (LLMs) often ignore the explicit dependency structure of tabular data, leading to low-fidelity synthetics. To address these limitations, we introduce StructSynth, a novel framework that integrates the generative power of LLMs with robust structural control. StructSynth employs a two-stage architecture. First, it performs explicit structure discovery to learn a Directed Acyclic Graph (DAG) from the available data. Second, this learned structure serves as a high-fidelity blueprint to steer the LLM's generation process, forcing it to adhere to the learned feature dependencies and thereby ensuring the generated data respects the underlying structure by design. Our extensive experiments demonstrate that StructSynth produces synthetic data with significantly higher structural integrity and downstream utility than state-of-the-art methods. It proves especially effective in challenging low-data scenarios, successfully navigating the trade-off between privacy preservation and statistical fidelity.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02601v1",
    "published_date": "2025-08-04 16:55:02 UTC",
    "updated_date": "2025-08-04 16:55:02 UTC"
  },
  {
    "arxiv_id": "2508.02593v1",
    "title": "Explainable AI for Automated User-specific Feedback in Surgical Skill Acquisition",
    "authors": [
      "Catalina Gomez",
      "Lalithkumar Seenivasan",
      "Xinrui Zou",
      "Jeewoo Yoon",
      "Sirui Chu",
      "Ariel Leong",
      "Patrick Kramer",
      "Yu-Chun Ku",
      "Jose L. Porras",
      "Alejandro Martin-Gomez",
      "Masaru Ishii",
      "Mathias Unberath"
    ],
    "abstract": "Traditional surgical skill acquisition relies heavily on expert feedback, yet direct access is limited by faculty availability and variability in subjective assessments. While trainees can practice independently, the lack of personalized, objective, and quantitative feedback reduces the effectiveness of self-directed learning. Recent advances in computer vision and machine learning have enabled automated surgical skill assessment, demonstrating the feasibility of automatic competency evaluation. However, it is unclear whether such Artificial Intelligence (AI)-driven feedback can contribute to skill acquisition. Here, we examine the effectiveness of explainable AI (XAI)-generated feedback in surgical training through a human-AI study. We create a simulation-based training framework that utilizes XAI to analyze videos and extract surgical skill proxies related to primitive actions. Our intervention provides automated, user-specific feedback by comparing trainee performance to expert benchmarks and highlighting deviations from optimal execution through understandable proxies for actionable guidance. In a prospective user study with medical students, we compare the impact of XAI-guided feedback against traditional video-based coaching on task outcomes, cognitive load, and trainees' perceptions of AI-assisted learning. Results showed improved cognitive load and confidence post-intervention. While no differences emerged between the two feedback types in reducing performance gaps or practice adjustments, trends in the XAI group revealed desirable effects where participants more closely mimicked expert practice. This work encourages the study of explainable AI in surgical education and the development of data-driven, adaptive feedback mechanisms that could transform learning experiences and competency assessment.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "10 pages, 4 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.02593v1",
    "published_date": "2025-08-04 16:48:44 UTC",
    "updated_date": "2025-08-04 16:48:44 UTC"
  },
  {
    "arxiv_id": "2508.02587v1",
    "title": "Parameter-Efficient Routed Fine-Tuning: Mixture-of-Experts Demands Mixture of Adaptation Modules",
    "authors": [
      "Yilun Liu",
      "Yunpu Ma",
      "Yuetian Lu",
      "Shuo Chen",
      "Zifeng Ding",
      "Volker Tresp"
    ],
    "abstract": "Mixture-of-Experts (MoE) benefits from a dynamic routing mechanism among their specialized experts, which existing Parameter- Efficient Fine-Tuning (PEFT) strategies fail to leverage. This motivates us to investigate whether adaptation modules themselves should incorporate routing mechanisms to align with MoE's multi-expert architecture. We analyze dynamics of core components when applying PEFT to MoE language models and examine how different routing strategies affect adaptation effectiveness. Extensive experiments adapting OLMoE-1B-7B and Mixtral-8x7B on various commonsense and math reasoning tasks validate the performance and efficiency of our routed approach. We identify the optimal configurations for different scenarios and provide empirical analyses with practical insights to facilitate better PEFT and MoE applications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "This paper is a preprint under review. arXiv admin note: text overlap with arXiv:2411.08212",
    "pdf_url": "https://arxiv.org/pdf/2508.02587v1",
    "published_date": "2025-08-04 16:43:09 UTC",
    "updated_date": "2025-08-04 16:43:09 UTC"
  },
  {
    "arxiv_id": "2508.02584v1",
    "title": "MArgE: Meshing Argumentative Evidence from Multiple Large Language Models for Justifiable Claim Verification",
    "authors": [
      "Ming Pok Ng",
      "Junqi Jiang",
      "Gabriel Freedman",
      "Antonio Rago",
      "Francesca Toni"
    ],
    "abstract": "Leveraging outputs from multiple large language models (LLMs) is emerging as a method for harnessing their power across a wide range of tasks while mitigating their capacity for making errors, e.g., hallucinations. However, current approaches to combining insights from multiple LLMs often involve unstructured interactions (e.g., free debate), resulting in model generations that are not faithfully justifiable. In this work, we introduce MArgE, a novel framework to provide formal structure to the evidence from each LLM, in the form of a tree of extracted arguments, for the task of claim verification. We use a variant of Argumentative LLMs (ArgLLMs), i.e. LLMs driven by frameworks and semantics from the field of computational argumentation, to construct structured argument trees for given claims. This process creates an inspectable pathway from the initial arguments to the final claim verification decisions, providing a faithful justification thereof. We show experimentally that MArgE can significantly outperform single LLMs, including three open-source models (4B to 8B parameters), GPT-4o-mini and existing ArgLLMs, as well as prior methods for unstructured multi-LLM debates. We thus demonstrate the advantages of incorporating formal, argumentative reasoning mechanisms when combining multiple LLM outputs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02584v1",
    "published_date": "2025-08-04 16:40:02 UTC",
    "updated_date": "2025-08-04 16:40:02 UTC"
  },
  {
    "arxiv_id": "2508.02583v4",
    "title": "CAMA: Enhancing Mathematical Reasoning in Large Language Models with Causal Knowledge",
    "authors": [
      "Lei Zan",
      "Keli Zhang",
      "Ruichu Cai",
      "Lujia Pan"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated strong performance across a wide range of tasks, yet they still struggle with complex mathematical reasoning, a challenge fundamentally rooted in deep structural dependencies. To address this challenge, we propose \\textbf{CA}usal \\textbf{MA}thematician (\\textbf{CAMA}), a two-stage causal framework that equips LLMs with explicit, reusable mathematical structure. In the learning stage, CAMA first constructs the \\textbf{M}athematical \\textbf{C}ausal \\textbf{G}raph (\\textbf{MCG}), a high-level representation of solution strategies, by combining LLM priors with causal discovery algorithms applied to a corpus of question-solution pairs. The resulting MCG encodes essential knowledge points and their causal dependencies. To better align the graph with downstream reasoning tasks, CAMA further refines the MCG through iterative feedback derived from a selected subset of the question-solution pairs. In the reasoning stage, given a new question, CAMA dynamically extracts a task-relevant subgraph from the MCG, conditioned on both the question content and the LLM's intermediate reasoning trace. This subgraph, which encodes the most pertinent knowledge points and their causal dependencies, is then injected back into the LLM to guide its reasoning process. Empirical results on real-world datasets show that CAMA significantly improves LLM performance on challenging mathematical problems. Furthermore, our experiments demonstrate that structured guidance consistently outperforms unstructured alternatives, and that incorporating asymmetric causal relationships yields greater improvements than using symmetric associations alone.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02583v4",
    "published_date": "2025-08-04 16:39:24 UTC",
    "updated_date": "2025-11-28 15:58:34 UTC"
  },
  {
    "arxiv_id": "2508.02574v1",
    "title": "EHSAN: Leveraging ChatGPT in a Hybrid Framework for Arabic Aspect-Based Sentiment Analysis in Healthcare",
    "authors": [
      "Eman Alamoudi",
      "Ellis Solaiman"
    ],
    "abstract": "Arabic-language patient feedback remains under-analysed because dialect diversity and scarce aspect-level sentiment labels hinder automated assessment. To address this gap, we introduce EHSAN, a data-centric hybrid pipeline that merges ChatGPT pseudo-labelling with targeted human review to build the first explainable Arabic aspect-based sentiment dataset for healthcare. Each sentence is annotated with an aspect and sentiment label (positive, negative, or neutral), forming a pioneering Arabic dataset aligned with healthcare themes, with ChatGPT-generated rationales provided for each label to enhance transparency. To evaluate the impact of annotation quality on model performance, we created three versions of the training data: a fully supervised set with all labels reviewed by humans, a semi-supervised set with 50% human review, and an unsupervised set with only machine-generated labels. We fine-tuned two transformer models on these datasets for both aspect and sentiment classification. Experimental results show that our Arabic-specific model achieved high accuracy even with minimal human supervision, reflecting only a minor performance drop when using ChatGPT-only labels. Reducing the number of aspect classes notably improved classification metrics across the board. These findings demonstrate an effective, scalable approach to Arabic aspect-based sentiment analysis (SA) in healthcare, combining large language model annotation with human expertise to produce a robust and explainable dataset. Future directions include generalisation across hospitals, prompt refinement, and interpretable data-driven modelling.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.SI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02574v1",
    "published_date": "2025-08-04 16:28:58 UTC",
    "updated_date": "2025-08-04 16:28:58 UTC"
  },
  {
    "arxiv_id": "2508.02566v2",
    "title": "Dynamic Feature Selection based on Rule-based Learning for Explainable Classification with Uncertainty Quantification",
    "authors": [
      "Javier Fumanal-Idocin",
      "Raquel Fernandez-Peralta",
      "Javier Andreu-Perez"
    ],
    "abstract": "Dynamic feature selection (DFS) offers a compelling alternative to traditional, static feature selection by adapting the selected features to each individual sample. This provides insights into the decision-making process for each case, which makes DFS especially significant in settings where decision transparency is key, i.e., clinical decisions. However, existing DFS methods use opaque models, which hinder their applicability in real-life scenarios. DFS also introduces new own sources of uncertainty compared to the static setting, which is also not considered in the existing literature. In this paper, we formalize the additional sources of uncertainty in DFS, and give formulas to estimate them. We also propose novel approach by leveraging a rule-based system as a base classifier for the DFS process, which enhances decision interpretability compared to neural estimators. Finally, we demonstrate the competitive performance of our rule-based DFS approach against established and state-of-the-art greedy and reinforcement learning methods, which are mostly considered opaque, compared to our explainable rulebased system.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02566v2",
    "published_date": "2025-08-04 16:21:43 UTC",
    "updated_date": "2025-12-02 09:32:43 UTC"
  },
  {
    "arxiv_id": "2508.06326v2",
    "title": "A \"good regulator theorem\" for embodied agents",
    "authors": [
      "Nathaniel Virgo",
      "Martin Biehl",
      "Manuel Baltieri",
      "Matteo Capucci"
    ],
    "abstract": "In a classic paper, Conant and Ashby claimed that \"every good regulator of a system must be a model of that system.\" Artificial Life has produced many examples of systems that perform tasks with apparently no model in sight; these suggest Conant and Ashby's theorem doesn't easily generalise beyond its restricted setup. Nevertheless, here we show that a similar intuition can be fleshed out in a different way: whenever an agent is able to perform a regulation task, it is possible for an observer to interpret it as having \"beliefs\" about its environment, which it \"updates\" in response to sensory input. This notion of belief updating provides a notion of model that is more sophisticated than Conant and Ashby's, as well as a theorem that is more broadly applicable. However, it necessitates a change in perspective, in that the observer plays an essential role in the theory: models are not a mere property of the system but are imposed on it from outside. Our theorem holds regardless of whether the system is regulating its environment in a classic control theory setup, or whether it's regulating its own internal state; the model is of its environment either way. The model might be trivial, however, and this is how the apparent counterexamples are resolved.",
    "categories": [
      "cs.AI",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at the Artificial Life conference 2025 (ALife 2025). 10 pages, 1 figure",
    "pdf_url": "https://arxiv.org/pdf/2508.06326v2",
    "published_date": "2025-08-04 16:11:31 UTC",
    "updated_date": "2025-08-21 16:17:58 UTC"
  },
  {
    "arxiv_id": "2508.02550v1",
    "title": "Stakeholder Perspectives on Humanistic Implementation of Computer Perception in Healthcare: A Qualitative Study",
    "authors": [
      "Kristin M. Kostick-Quenet",
      "Meghan E. Hurley",
      "Syed Ayaz",
      "John Herrington",
      "Casey Zampella",
      "Julia Parish-Morris",
      "Birkan Tunç",
      "Gabriel Lázaro-Muñoz",
      "J. S. Blumenthal-Barby",
      "Eric A. Storch"
    ],
    "abstract": "Computer perception (CP) technologies (digital phenotyping, affective computing and related passive sensing approaches) offer unprecedented opportunities to personalize healthcare, but provoke concerns about privacy, bias and the erosion of empathic, relationship-centered practice. A comprehensive understanding of perceived risks, benefits, and implementation challenges from those who design, deploy and experience these tools in real-world settings remains elusive. This study provides the first evidence-based account of key stakeholder perspectives on the relational, technical, and governance challenges raised by the integration of CP technologies into patient care. We conducted in-depth, semi-structured interviews with 102 stakeholders: adolescent patients and their caregivers, frontline clinicians, technology developers, and ethics, legal, policy or philosophy scholars. Transcripts underwent thematic analysis by a multidisciplinary team; reliability was enhanced through double coding and consensus adjudication. Stakeholders articulated seven interlocking concern domains: (1) trustworthiness and data integrity; (2) patient-specific relevance; (3) utility and workflow integration; (4) regulation and governance; (5) privacy and data protection; (6) direct and indirect patient harms; and (7) philosophical critiques of reductionism. To operationalize humanistic safeguards, we propose \"personalized roadmaps\": co-designed plans that predetermine which metrics will be monitored, how and when feedback is shared, thresholds for clinical action, and procedures for reconciling discrepancies between algorithmic inferences and lived experience. By translating these insights into personalized roadmaps, we offer a practical framework for developers, clinicians and policymakers seeking to harness continuous behavioral data while preserving the humanistic core of care.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "65 pages",
    "pdf_url": "https://arxiv.org/pdf/2508.02550v1",
    "published_date": "2025-08-04 16:01:56 UTC",
    "updated_date": "2025-08-04 16:01:56 UTC"
  },
  {
    "arxiv_id": "2508.02548v2",
    "title": "The KG-ER Conceptual Schema Language",
    "authors": [
      "Enrico Franconi",
      "Benoît Groz",
      "Jan Hidders",
      "Nina Pardal",
      "Sławek Staworko",
      "Jan Van den Bussche",
      "Piotr Wieczorek"
    ],
    "abstract": "We propose KG-ER, a conceptual schema language for knowledge graphs that describes the structure of knowledge graphs independently of their representation (relational databases, property graphs, RDF) while helping to capture the semantics of the information stored in a knowledge graph.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02548v2",
    "published_date": "2025-08-04 16:01:28 UTC",
    "updated_date": "2025-09-04 15:06:45 UTC"
  },
  {
    "arxiv_id": "2508.02546v1",
    "title": "What are you sinking? A geometric approach on attention sink",
    "authors": [
      "Valeria Ruscio",
      "Umberto Nanni",
      "Fabrizio Silvestri"
    ],
    "abstract": "Attention sink (AS) is a consistent pattern in transformer attention maps where certain tokens (often special tokens or positional anchors) disproportionately attract attention from other tokens. We show that in transformers, AS is not an architectural artifact, but it is the manifestation of a fundamental geometric principle: the establishment of reference frames that anchor representational spaces. We analyze several architectures and identify three distinct reference frame types, centralized, distributed, and bidirectional, that correlate with the attention sink phenomenon. We show that they emerge during the earliest stages of training as optimal solutions to the problem of establishing stable coordinate systems in high-dimensional spaces. We show the influence of architecture components, particularly position encoding implementations, on the specific type of reference frame. This perspective transforms our understanding of transformer attention mechanisms and provides insights for both architecture design and the relationship with AS.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02546v1",
    "published_date": "2025-08-04 15:59:15 UTC",
    "updated_date": "2025-08-04 15:59:15 UTC"
  },
  {
    "arxiv_id": "2508.02541v1",
    "title": "Automatic Identification of Machine Learning-Specific Code Smells",
    "authors": [
      "Peter Hamfelt",
      "Ricardo Britto",
      "Lincoln Rocha",
      "Camilo Almendra"
    ],
    "abstract": "Machine learning (ML) has rapidly grown in popularity, becoming vital to many industries. Currently, the research on code smells in ML applications lacks tools and studies that address the identification and validity of ML-specific code smells. This work investigates suitable methods and tools to design and develop a static code analysis tool (MLpylint) based on code smell criteria. This research employed the Design Science Methodology. In the problem identification phase, a literature review was conducted to identify ML-specific code smells. In solution design, a secondary literature review and consultations with experts were performed to select methods and tools for implementing the tool. We evaluated the tool on data from 160 open-source ML applications sourced from GitHub. We also conducted a static validation through an expert survey involving 15 ML professionals. The results indicate the effectiveness and usefulness of the MLpylint. We aim to extend our current approach by investigating ways to introduce MLpylint seamlessly into development workflows, fostering a more productive and innovative developer environment.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02541v1",
    "published_date": "2025-08-04 15:51:15 UTC",
    "updated_date": "2025-08-04 15:51:15 UTC"
  },
  {
    "arxiv_id": "2508.09153v1",
    "title": "JustDense: Just using Dense instead of Sequence Mixer for Time Series analysis",
    "authors": [
      "TaekHyun Park",
      "Yongjae Lee",
      "Daesan Park",
      "Dohee Kim",
      "Hyerim Bae"
    ],
    "abstract": "Sequence and channel mixers, the core mechanism in sequence models, have become the de facto standard in time series analysis (TSA). However, recent studies have questioned the necessity of complex sequence mixers, such as attention mechanisms, demonstrating that simpler architectures can achieve comparable or even superior performance. This suggests that the benefits attributed to complex sequencemixers might instead emerge from other architectural or optimization factors. Based on this observation, we pose a central question: Are common sequence mixers necessary for time-series analysis? Therefore, we propose JustDense, an empirical study that systematically replaces sequence mixers in various well-established TSA models with dense layers. Grounded in the MatrixMixer framework, JustDense treats any sequence mixer as a mixing matrix and replaces it with a dense layer. This substitution isolates the mixing operation, enabling a clear theoretical foundation for understanding its role. Therefore, we conducted extensive experiments on 29 benchmarks covering five representative TSA tasks using seven state-of-the-art TSA models to address our research question. The results show that replacing sequence mixers with dense layers yields comparable or even superior performance. In the cases where dedicated sequence mixers still offer benefits, JustDense challenges the assumption that \"deeper and more complex architectures are inherently better\" in TSA.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages ,planning to submit to IEEE BigData 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.09153v1",
    "published_date": "2025-08-04 15:49:09 UTC",
    "updated_date": "2025-08-04 15:49:09 UTC"
  },
  {
    "arxiv_id": "2508.02773v3",
    "title": "Web3 x AI Agents: Landscape, Integrations, and Foundational Challenges",
    "authors": [
      "Yiming Shen",
      "Jiashuo Zhang",
      "Zhenzhe Shao",
      "Wenxuan Luo",
      "Yanlin Wang",
      "Ting Chen",
      "Zibin Zheng",
      "Jiachi Chen"
    ],
    "abstract": "The convergence of Web3 technologies and AI agents represents a rapidly evolving frontier poised to reshape decentralized ecosystems. This paper presents the first and most comprehensive analysis of the intersection between Web3 and AI agents, examining five critical dimensions: landscape, economics, governance, security, and trust mechanisms. Through an analysis of 133 existing projects, we first develop a taxonomy and systematically map the current market landscape (RQ1), identifying distinct patterns in project distribution and capitalization. Building upon these findings, we further investigate four key integrations: (1) the role of AI agents in participating in and optimizing decentralized finance (RQ2); (2) their contribution to enhancing Web3 governance mechanisms (RQ3); (3) their capacity to strengthen Web3 security via intelligent vulnerability detection and automated smart contract auditing (RQ4); and (4) the establishment of robust reliability frameworks for AI agent operations leveraging Web3's inherent trust infrastructure (RQ5). By synthesizing these dimensions, we identify key integration patterns, highlight foundational challenges related to scalability, security, and ethics, and outline critical considerations for future research toward building robust, intelligent, and trustworthy decentralized systems with effective AI agent interactions.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "econ.GN"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02773v3",
    "published_date": "2025-08-04 15:44:58 UTC",
    "updated_date": "2025-09-12 15:26:02 UTC"
  },
  {
    "arxiv_id": "2508.02525v1",
    "title": "Accurate and Interpretable Postmenstrual Age Prediction via Multimodal Large Language Model",
    "authors": [
      "Qifan Chen",
      "Jin Cui",
      "Cindy Duan",
      "Yushuo Han",
      "Yifei Shi"
    ],
    "abstract": "Accurate estimation of postmenstrual age (PMA) at scan is crucial for assessing neonatal development and health. While deep learning models have achieved high accuracy in predicting PMA from brain MRI, they often function as black boxes, offering limited transparency and interpretability in clinical decision support. In this work, we address the dual challenge of accuracy and interpretability by adapting a multimodal large language model (MLLM) to perform both precise PMA prediction and clinically relevant explanation generation. We introduce a parameter-efficient fine-tuning (PEFT) strategy using instruction tuning and Low-Rank Adaptation (LoRA) applied to the Qwen2.5-VL-7B model. The model is trained on four 2D cortical surface projection maps derived from neonatal MRI scans. By employing distinct prompts for training and inference, our approach enables the MLLM to handle a regression task during training and generate clinically relevant explanations during inference. The fine-tuned model achieves a low prediction error with a 95 percent confidence interval of 0.78 to 1.52 weeks, while producing interpretable outputs grounded in developmental features, marking a significant step toward transparent and trustworthy AI systems in perinatal neuroscience.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Submitted to the NeurIPS 2025 Workshop GenAI4Health. Conference website: https://aihealth.ischool.utexas.edu/GenAI4HealthNeurips2025/",
    "pdf_url": "https://arxiv.org/pdf/2508.02525v1",
    "published_date": "2025-08-04 15:35:36 UTC",
    "updated_date": "2025-08-04 15:35:36 UTC"
  },
  {
    "arxiv_id": "2508.02513v1",
    "title": "Modular Arithmetic: Language Models Solve Math Digit by Digit",
    "authors": [
      "Tanja Baeumel",
      "Daniil Gurgurov",
      "Yusser al Ghussin",
      "Josef van Genabith",
      "Simon Ostermann"
    ],
    "abstract": "While recent work has begun to uncover the internal strategies that Large Language Models (LLMs) employ for simple arithmetic tasks, a unified understanding of their underlying mechanisms is still lacking. We extend recent findings showing that LLMs represent numbers in a digit-wise manner and present evidence for the existence of digit-position-specific circuits that LLMs use to perform simple arithmetic tasks, i.e. modular subgroups of MLP neurons that operate independently on different digit positions (units, tens, hundreds). Notably, such circuits exist independently of model size and of tokenization strategy, i.e. both for models that encode longer numbers digit-by-digit and as one token. Using Feature Importance and Causal Interventions, we identify and validate the digit-position-specific circuits, revealing a compositional and interpretable structure underlying the solving of arithmetic problems in LLMs. Our interventions selectively alter the model's prediction at targeted digit positions, demonstrating the causal role of digit-position circuits in solving arithmetic tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02513v1",
    "published_date": "2025-08-04 15:18:41 UTC",
    "updated_date": "2025-08-04 15:18:41 UTC"
  },
  {
    "arxiv_id": "2508.02511v2",
    "title": "Test-time Prompt Intervention",
    "authors": [
      "Chenxu Yang",
      "Qingyi Si",
      "Mz Dai",
      "Dingyu Yao",
      "Mingyu Zheng",
      "Minghui Chen",
      "Zheng Lin",
      "Weiping Wang"
    ],
    "abstract": "Test-time compute has led to remarkable success in the large language model (LLM) community, particularly for complex tasks, where longer chains of thought (CoTs) are generated to enhance reasoning capabilities. However, growing evidence reveals that such reasoning models often produce CoTs plagued by excessive redundancy, including unnecessary verification steps and repetitive reasoning shifts. The root cause lies in post-training of them that overly rely on outcome reward paradigms, as the data of process reward paradigms, which regulate intermediate reasoning steps, is difficult to construct at scale. To address this, we propose PI, a novel framework for Test-time Prompt Intervention. PI provides an interface to dynamically guide and regulate reasoning paths during inference through timely (When module) and proper (How module) interventions and post-intervention sampling (Which module). This allows human problem-solving expertise and cognitive science principles to be seamlessly integrated into LLMs' reasoning processes, enhancing controllability and interpretability. Extensive experiments across multiple models and datasets demonstrate that PI significantly shortens CoTs while reducing hallucination, yielding more concise and reliable reasoning.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "24 pages, 20 figures, under review",
    "pdf_url": "https://arxiv.org/pdf/2508.02511v2",
    "published_date": "2025-08-04 15:17:13 UTC",
    "updated_date": "2025-10-22 15:27:03 UTC"
  },
  {
    "arxiv_id": "2508.02506v1",
    "title": "Decomposed Reasoning with Reinforcement Learning for Relevance Assessment in UGC Platforms",
    "authors": [
      "Xiaowei Yuan",
      "Lei Jin",
      "Haoxin Zhang",
      "Yan Gao",
      "Yi Wu",
      "Yao Hu",
      "Ziyang Huang",
      "Jun Zhao",
      "Kang Liu"
    ],
    "abstract": "Retrieval-augmented generation (RAG) plays a critical role in user-generated content (UGC) platforms, but its effectiveness depends heavily on accurate relevance assessment of query-document pairs. Despite recent advances in applying large language models (LLMs) to relevance modeling, UGC platforms present unique challenges: 1) ambiguous user intent due to sparse user feedback in RAG scenarios, and 2) substantial noise introduced by informal and unstructured language. To address these issues, we propose the Reinforced Reasoning Model for Relevance Assessment (R3A), which introduces a decomposed reasoning framework over queries and candidate documents before scoring. R3A first leverages auxiliary high-ranked documents within the platform to infer latent query intent. It then performs verbatim fragment extraction to justify relevance decisions, thereby reducing errors caused by noisy UGC. Based on a reinforcement learning framework, R3A is optimized to mitigate distortions arising from ambiguous queries and unstructured content. Experimental results show that R3A significantly outperforms existing baseline methods in terms of relevance accuracy, across both offline benchmarks and online experiments.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02506v1",
    "published_date": "2025-08-04 15:14:09 UTC",
    "updated_date": "2025-08-04 15:14:09 UTC"
  },
  {
    "arxiv_id": "2508.02503v2",
    "title": "OptiHive: Ensemble Selection for LLM-Based Optimization via Statistical Modeling",
    "authors": [
      "Maxime Bouscary",
      "Saurabh Amin"
    ],
    "abstract": "LLM-based solvers have emerged as a promising means of automating problem modeling and solving. However, they remain unreliable and often depend on iterative repair loops that result in significant latency. We introduce OptiHive, a framework that enhances any solver-generation pipeline to produce higher-quality solvers from natural-language descriptions of optimization problems. OptiHive uses a single batched generation to produce diverse components (solvers, problem instances, and validation tests) and filters out erroneous components to ensure fully interpretable outputs. Accounting for the imperfection of the generated components, we employ a statistical model to infer their true performance, enabling principled uncertainty quantification and solver selection. On tasks ranging from traditional optimization problems to challenging variants of the Multi-Depot Vehicle Routing Problem, OptiHive significantly outperforms baselines, increasing the optimality rate from 5% to 92% on the most complex problems.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02503v2",
    "published_date": "2025-08-04 15:11:51 UTC",
    "updated_date": "2025-11-16 17:07:59 UTC"
  },
  {
    "arxiv_id": "2508.02490v1",
    "title": "PHM-Bench: A Domain-Specific Benchmarking Framework for Systematic Evaluation of Large Models in Prognostics and Health Management",
    "authors": [
      "Puyu Yang",
      "Laifa Tao",
      "Zijian Huang",
      "Haifei Liu",
      "Wenyan Cao",
      "Hao Ji",
      "Jianan Qiu",
      "Qixuan Huang",
      "Xuanyuan Su",
      "Yuhang Xie",
      "Jun Zhang",
      "Shangyu Li",
      "Chen Lu",
      "Zhixuan Lian"
    ],
    "abstract": "With the rapid advancement of generative artificial intelligence, large language models (LLMs) are increasingly adopted in industrial domains, offering new opportunities for Prognostics and Health Management (PHM). These models help address challenges such as high development costs, long deployment cycles, and limited generalizability. However, despite the growing synergy between PHM and LLMs, existing evaluation methodologies often fall short in structural completeness, dimensional comprehensiveness, and evaluation granularity. This hampers the in-depth integration of LLMs into the PHM domain. To address these limitations, this study proposes PHM-Bench, a novel three-dimensional evaluation framework for PHM-oriented large models. Grounded in the triadic structure of fundamental capability, core task, and entire lifecycle, PHM-Bench is tailored to the unique demands of PHM system engineering. It defines multi-level evaluation metrics spanning knowledge comprehension, algorithmic generation, and task optimization. These metrics align with typical PHM tasks, including condition monitoring, fault diagnosis, RUL prediction, and maintenance decision-making. Utilizing both curated case sets and publicly available industrial datasets, our study enables multi-dimensional evaluation of general-purpose and domain-specific models across diverse PHM tasks. PHM-Bench establishes a methodological foundation for large-scale assessment of LLMs in PHM and offers a critical benchmark to guide the transition from general-purpose to PHM-specialized models.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02490v1",
    "published_date": "2025-08-04 15:01:41 UTC",
    "updated_date": "2025-08-04 15:01:41 UTC"
  },
  {
    "arxiv_id": "2508.02470v1",
    "title": "AIAP: A No-Code Workflow Builder for Non-Experts with Natural Language and Multi-Agent Collaboration",
    "authors": [
      "Hyunjn An",
      "Yongwon Kim",
      "Wonduk Seo",
      "Joonil Park",
      "Daye Kang",
      "Changhoon Oh",
      "Dokyun Kim",
      "Seunghyun Lee"
    ],
    "abstract": "While many tools are available for designing AI, non-experts still face challenges in clearly expressing their intent and managing system complexity. We introduce AIAP, a no-code platform that integrates natural language input with visual workflows. AIAP leverages a coordinated multi-agent system to decompose ambiguous user instructions into modular, actionable steps, hidden from users behind a unified interface. A user study involving 32 participants showed that AIAP's AI-generated suggestions, modular workflows, and automatic identification of data, actions, and context significantly improved participants' ability to develop services intuitively. These findings highlight that natural language-based visual programming significantly reduces barriers and enhances user experience in AI service design.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL",
      "cs.MA",
      "cs.SE"
    ],
    "primary_category": "cs.HC",
    "comment": "14 pages, 6 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.02470v1",
    "published_date": "2025-08-04 14:36:31 UTC",
    "updated_date": "2025-08-04 14:36:31 UTC"
  },
  {
    "arxiv_id": "2508.02455v1",
    "title": "TreeRanker: Fast and Model-agnostic Ranking System for Code Suggestions in IDEs",
    "authors": [
      "Daniele Cipollone",
      "Egor Bogomolov",
      "Arie van Deursen",
      "Maliheh Izadi"
    ],
    "abstract": "Token-level code completion is one of the most critical features in modern Integrated Development Environments (IDEs). It assists developers by suggesting relevant identifiers and APIs during coding. While completions are typically derived from static analysis, their usefulness depends heavily on how they are ranked, as correct predictions buried deep in the list are rarely seen by users. Most current systems rely on hand-crafted heuristics or lightweight machine learning models trained on user logs, which can be further improved to capture context information and generalize across projects and coding styles. In this work, we propose a new scoring approach to ranking static completions using language models in a lightweight and model-agnostic way. Our method organizes all valid completions into a prefix tree and performs a single greedy decoding pass to collect token-level scores across the tree. This enables a precise token-aware ranking without needing beam search, prompt engineering, or model adaptations. The approach is fast, architecture-agnostic, and compatible with already deployed models for code completion. These findings highlight a practical and effective pathway for integrating language models into already existing tools within IDEs, and ultimately providing smarter and more responsive developer assistance.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02455v1",
    "published_date": "2025-08-04 14:20:39 UTC",
    "updated_date": "2025-08-04 14:20:39 UTC"
  },
  {
    "arxiv_id": "2508.02451v2",
    "title": "Dynamic Forgetting and Spatio-Temporal Periodic Interest Modeling for Local-Life Service Recommendation",
    "authors": [
      "Zhaoyu Hu",
      "Jianyang Wang",
      "Hao Guo",
      "Yuan Tian",
      "Erpeng Xue",
      "Xianyang Qi",
      "Hongxiang Lin",
      "Lei Wang",
      "Sheng Chen"
    ],
    "abstract": "In the context of the booming digital economy, recommendation systems, as a key link connecting users and numerous services, face challenges in modeling user behavior sequences on local-life service platforms, including the sparsity of long sequences and strong spatio-temporal dependence. Such challenges can be addressed by drawing an analogy to the forgetting process in human memory. This is because users' responses to recommended content follow the recency effect and the cyclicality of memory. By exploring this, this paper introduces the forgetting curve and proposes Spatio-Temporal periodic Interest Modeling (STIM) with long sequences for local-life service recommendation. STIM integrates three key components: a dynamic masking module based on the forgetting curve, which is used to extract both recent spatiotemporal features and periodic spatiotemporal features; a query-based mixture of experts (MoE) approach that can adaptively activate expert networks under different dynamic masks, enabling the collaborative modeling of time, location, and items; and a hierarchical multi-interest network unit, which captures multi-interest representations by modeling the hierarchical interactions between the shallow and deep semantics of users' recent behaviors. By introducing the STIM method, we conducted online A/B tests and achieved a 1.54\\% improvement in gross transaction volume (GTV). In addition, extended offline experiments also showed improvements. STIM has been deployed in a large-scale local-life service recommendation system, serving hundreds of millions of daily active users in core application scenarios.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02451v2",
    "published_date": "2025-08-04 14:16:49 UTC",
    "updated_date": "2025-11-03 15:46:33 UTC"
  },
  {
    "arxiv_id": "2508.02442v1",
    "title": "Assessing the Reliability and Validity of Large Language Models for Automated Assessment of Student Essays in Higher Education",
    "authors": [
      "Andrea Gaggioli",
      "Giuseppe Casaburi",
      "Leonardo Ercolani",
      "Francesco Collova'",
      "Pietro Torre",
      "Fabrizio Davide"
    ],
    "abstract": "This study investigates the reliability and validity of five advanced Large Language Models (LLMs), Claude 3.5, DeepSeek v2, Gemini 2.5, GPT-4, and Mistral 24B, for automated essay scoring in a real world higher education context. A total of 67 Italian-language student essays, written as part of a university psychology course, were evaluated using a four-criterion rubric (Pertinence, Coherence, Originality, Feasibility). Each model scored all essays across three prompt replications to assess intra-model stability. Human-LLM agreement was consistently low and non-significant (Quadratic Weighted Kappa), and within-model reliability across replications was similarly weak (median Kendall's W < 0.30). Systematic scoring divergences emerged, including a tendency to inflate Coherence and inconsistent handling of context-dependent dimensions. Inter-model agreement analysis revealed moderate convergence for Coherence and Originality, but negligible concordance for Pertinence and Feasibility. Although limited in scope, these findings suggest that current LLMs may struggle to replicate human judgment in tasks requiring disciplinary insight and contextual sensitivity. Human oversight remains critical when evaluating open-ended academic work, particularly in interpretive domains.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "24 pages (including appendix), 12 tables, 1 figure",
    "pdf_url": "https://arxiv.org/pdf/2508.02442v1",
    "published_date": "2025-08-04 14:02:12 UTC",
    "updated_date": "2025-08-04 14:02:12 UTC"
  },
  {
    "arxiv_id": "2508.02429v1",
    "title": "Multimodal Large Language Models for End-to-End Affective Computing: Benchmarking and Boosting with Generative Knowledge Prompting",
    "authors": [
      "Miaosen Luo",
      "Jiesen Long",
      "Zequn Li",
      "Yunying Yang",
      "Yuncheng Jiang",
      "Sijie Mai"
    ],
    "abstract": "Multimodal Affective Computing (MAC) aims to recognize and interpret human emotions by integrating information from diverse modalities such as text, video, and audio. Recent advancements in Multimodal Large Language Models (MLLMs) have significantly reshaped the landscape of MAC by offering a unified framework for processing and aligning cross-modal information. However, practical challenges remain, including performance variability across complex MAC tasks and insufficient understanding of how architectural designs and data characteristics impact affective analysis. To address these gaps, we conduct a systematic benchmark evaluation of state-of-the-art open-source MLLMs capable of concurrently processing audio, visual, and textual modalities across multiple established MAC datasets. Our evaluation not only compares the performance of these MLLMs but also provides actionable insights into model optimization by analyzing the influence of model architectures and dataset properties. Furthermore, we propose a novel hybrid strategy that combines generative knowledge prompting with supervised fine-tuning to enhance MLLMs' affective computing capabilities. Experimental results demonstrate that this integrated approach significantly improves performance across various MAC tasks, offering a promising avenue for future research and development in this field. Our code is released on https://github.com/LuoMSen/MLLM-MAC.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02429v1",
    "published_date": "2025-08-04 13:49:03 UTC",
    "updated_date": "2025-08-04 13:49:03 UTC"
  },
  {
    "arxiv_id": "2508.02427v1",
    "title": "CABENCH: Benchmarking Composable AI for Solving Complex Tasks through Composing Ready-to-Use Models",
    "authors": [
      "Tung-Thuy Pham",
      "Duy-Quan Luong",
      "Minh-Quan Duong",
      "Trung-Hieu Nguyen",
      "Thu-Trang Nguyen",
      "Son Nguyen",
      "Hieu Dinh Vo"
    ],
    "abstract": "Composable AI offers a scalable and effective paradigm for tackling complex AI tasks by decomposing them into sub-tasks and solving each sub-task using ready-to-use well-trained models. However, systematically evaluating methods under this setting remains largely unexplored. In this paper, we introduce CABENCH, the first public benchmark comprising 70 realistic composable AI tasks, along with a curated pool of 700 models across multiple modalities and domains. We also propose an evaluation framework to enable end-to-end assessment of composable AI solutions. To establish initial baselines, we provide human-designed reference solutions and compare their performance with two LLM-based approaches. Our results illustrate the promise of composable AI in addressing complex real-world problems while highlighting the need for methods that can fully unlock its potential by automatically generating effective execution pipelines.",
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02427v1",
    "published_date": "2025-08-04 13:48:32 UTC",
    "updated_date": "2025-08-04 13:48:32 UTC"
  },
  {
    "arxiv_id": "2508.03760v1",
    "title": "FlashCommunication V2: Bit Splitting and Spike Reserving for Any Bit Communication",
    "authors": [
      "Qingyuan Li",
      "Bo Zhang",
      "Hui Kang",
      "Tianhao Xu",
      "Yulei Qian",
      "Yuchen Xie",
      "Lin Ma"
    ],
    "abstract": "Nowadays, communication bottlenecks have emerged as a critical challenge in the distributed training and deployment of large language models (LLMs). This paper introduces FlashCommunication V2, a novel communication paradigm enabling efficient cross-GPU transmission at arbitrary bit widths. Its core innovations lie in the proposed bit splitting and spike reserving techniques, which address the challenges of low-bit quantization. Bit splitting decomposes irregular bit widths into basic units, ensuring compatibility with hardware capabilities and thus enabling transmission at any bit width. Spike reserving, on the other hand, retains numerical outliers (i.e., minima and maxima) as floating-point numbers, which shrinks the dynamic numerical range and pushes the quantization limits to 2-bit with acceptable losses. FlashCommunication V2 significantly enhances the flexibility and resource utilization of communication systems. Through meticulous software-hardware co-design, it delivers robust performance and reduced overhead across both NVLink-based and PCIe-based architectures, achieving a maximum 3.2$\\times$ speedup in AllReduce and 2$\\times$ in All2All communication.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "9 pages, 8 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.03760v1",
    "published_date": "2025-08-04 13:47:29 UTC",
    "updated_date": "2025-08-04 13:47:29 UTC"
  },
  {
    "arxiv_id": "2508.02425v1",
    "title": "Multi-Class Human/Object Detection on Robot Manipulators using Proprioceptive Sensing",
    "authors": [
      "Justin Hehli",
      "Marco Heiniger",
      "Maryam Rezayati",
      "Hans Wernher van de Venn"
    ],
    "abstract": "In physical human-robot collaboration (pHRC) settings, humans and robots collaborate directly in shared environments. Robots must analyze interactions with objects to ensure safety and facilitate meaningful workflows. One critical aspect is human/object detection, where the contacted object is identified. Past research introduced binary machine learning classifiers to distinguish between soft and hard objects. This study improves upon those results by evaluating three-class human/object detection models, offering more detailed contact analysis. A dataset was collected using the Franka Emika Panda robot manipulator, exploring preprocessing strategies for time-series analysis. Models including LSTM, GRU, and Transformers were trained on these datasets. The best-performing model achieved 91.11\\% accuracy during real-time testing, demonstrating the feasibility of multi-class detection models. Additionally, a comparison of preprocessing strategies suggests a sliding window approach is optimal for this task.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02425v1",
    "published_date": "2025-08-04 13:45:37 UTC",
    "updated_date": "2025-08-04 13:45:37 UTC"
  },
  {
    "arxiv_id": "2508.02421v1",
    "title": "Emergence of Fair Leaders via Mediators in Multi-Agent Reinforcement Learning",
    "authors": [
      "Akshay Dodwadmath",
      "Setareh Maghsudi"
    ],
    "abstract": "Stackelberg games and their resulting equilibria have received increasing attention in the multi-agent reinforcement learning literature. Each stage of a traditional Stackelberg game involves a leader(s) acting first, followed by the followers. In situations where the roles of leader(s) and followers can be interchanged, the designated role can have considerable advantages, for example, in first-mover advantage settings. Then the question arises: Who should be the leader and when? A bias in the leader selection process can lead to unfair outcomes. This problem is aggravated if the agents are self-interested and care only about their goals and rewards. We formally define this leader selection problem and show its relation to fairness in agents' returns. Furthermore, we propose a multi-agent reinforcement learning framework that maximizes fairness by integrating mediators. Mediators have previously been used in the simultaneous action setting with varying levels of control, such as directly performing agents' actions or just recommending them. Our framework integrates mediators in the Stackelberg setting with minimal control (leader selection). We show that the presence of mediators leads to self-interested agents taking fair actions, resulting in higher overall fairness in agents' returns.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.MA",
    "comment": "Accepted to ECAI 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.02421v1",
    "published_date": "2025-08-04 13:42:45 UTC",
    "updated_date": "2025-08-04 13:42:45 UTC"
  },
  {
    "arxiv_id": "2508.02411v1",
    "title": "HGTS-Former: Hierarchical HyperGraph Transformer for Multivariate Time Series Analysis",
    "authors": [
      "Xiao Wang",
      "Hao Si",
      "Fan Zhang",
      "Xiaoya Zhou",
      "Dengdi Sun",
      "Wanli Lyu",
      "Qingquan Yang",
      "Jin Tang"
    ],
    "abstract": "Multivariate time series analysis has long been one of the key research topics in the field of artificial intelligence. However, analyzing complex time series data remains a challenging and unresolved problem due to its high dimensionality, dynamic nature, and complex interactions among variables. Inspired by the strong structural modeling capability of hypergraphs, this paper proposes a novel hypergraph-based time series transformer backbone network, termed HGTS-Former, to address the multivariate coupling in time series data. Specifically, given the multivariate time series signal, we first normalize and embed each patch into tokens. Then, we adopt the multi-head self-attention to enhance the temporal representation of each patch. The hierarchical hypergraphs are constructed to aggregate the temporal patterns within each channel and fine-grained relations between different variables. After that, we convert the hyperedge into node features through the EdgeToNode module and adopt the feed-forward network to further enhance the output features. Extensive experiments conducted on two multivariate time series tasks and eight datasets fully validated the effectiveness of our proposed HGTS-Former. The source code will be released on https://github.com/Event-AHU/Time_Series_Analysis.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02411v1",
    "published_date": "2025-08-04 13:33:28 UTC",
    "updated_date": "2025-08-04 13:33:28 UTC"
  },
  {
    "arxiv_id": "2508.02409v1",
    "title": "Hydra: Accurate Multi-Modal Leaf Wetness Sensing with mm-Wave and Camera Fusion",
    "authors": [
      "Yimeng Liu",
      "Maolin Gan",
      "Huaili Zeng",
      "Li Liu",
      "Younsuk Dong",
      "Zhichao Cao"
    ],
    "abstract": "Leaf Wetness Duration (LWD), the time that water remains on leaf surfaces, is crucial in the development of plant diseases. Existing LWD detection lacks standardized measurement techniques, and variations across different plant characteristics limit its effectiveness. Prior research proposes diverse approaches, but they fail to measure real natural leaves directly and lack resilience in various environmental conditions. This reduces the precision and robustness, revealing a notable practical application and effectiveness gap in real-world agricultural settings. This paper presents Hydra, an innovative approach that integrates millimeter-wave (mm-Wave) radar with camera technology to detect leaf wetness by determining if there is water on the leaf. We can measure the time to determine the LWD based on this detection. Firstly, we design a Convolutional Neural Network (CNN) to selectively fuse multiple mm-Wave depth images with an RGB image to generate multiple feature images. Then, we develop a transformer-based encoder to capture the inherent connection among the multiple feature images to generate a feature map, which is further fed to a classifier for detection. Moreover, we augment the dataset during training to generalize our model. Implemented using a frequency-modulated continuous-wave (FMCW) radar within the 76 to 81 GHz band, Hydra's performance is meticulously evaluated on plants, demonstrating the potential to classify leaf wetness with up to 96% accuracy across varying scenarios. Deploying Hydra in the farm, including rainy, dawn, or poorly light nights, it still achieves an accuracy rate of around 90%.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "In Proceedings of ACM MobiCom (2024)",
    "pdf_url": "https://arxiv.org/pdf/2508.02409v1",
    "published_date": "2025-08-04 13:33:06 UTC",
    "updated_date": "2025-08-04 13:33:06 UTC"
  },
  {
    "arxiv_id": "2508.02401v1",
    "title": "CompressKV: Semantic Retrieval Heads Know What Tokens are Not Important Before Generation",
    "authors": [
      "Xiaolin Lin",
      "Jingcun Wang",
      "Olga Kondrateva",
      "Yiyu Shi",
      "Bing Li",
      "Grace Li Zhang"
    ],
    "abstract": "Recent advances in large language models (LLMs) have significantly boosted long-context processing. However, the increasing key-value (KV) cache size poses critical challenges to memory and execution efficiency. Most KV cache compression methods rely on heuristic token eviction using all attention heads in Grouped Query Attention (GQA)-based LLMs. This method ignores the different functionalities of attention heads, leading to the eviction of critical tokens and thus degrades the performance of LLMs.\n  To address the issue above, instead of using all the attention heads in GQA-based LLMs to determine important tokens as in the previous work, we first identify the attention heads in each layer that are not only capable of retrieving the initial and final tokens of a prompt, but also capable of retrieving important tokens within the text and attending to their surrounding semantic context. Afterwards, we exploit such heads to determine the important tokens and retain their corresponding KV cache pairs. Furthermore, we analyze the cache eviction error of each layer individually and introduce a layer-adaptive KV cache allocation strategy. Experimental results demonstrate the proposed CompressKV consistently outperforms state-of-the-art approaches under various memory budgets on LongBench and Needle-in-a-Haystack benchmarks. Our code is publicly available at: https://github.com/TUDa-HWAI/CompressKV.git.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02401v1",
    "published_date": "2025-08-04 13:26:16 UTC",
    "updated_date": "2025-08-04 13:26:16 UTC"
  },
  {
    "arxiv_id": "2508.02391v1",
    "title": "Inference-time Scaling for Diffusion-based Audio Super-resolution",
    "authors": [
      "Yizhu Jin",
      "Zhen Ye",
      "Zeyue Tian",
      "Haohe Liu",
      "Qiuqiang Kong",
      "Yike Guo",
      "Wei Xue"
    ],
    "abstract": "Diffusion models have demonstrated remarkable success in generative tasks, including audio super-resolution (SR). In many applications like movie post-production and album mastering, substantial computational budgets are available for achieving superior audio quality. However, while existing diffusion approaches typically increase sampling steps to improve quality, the performance remains fundamentally limited by the stochastic nature of the sampling process, leading to high-variance and quality-limited outputs. Here, rather than simply increasing the number of sampling steps, we propose a different paradigm through inference-time scaling for SR, which explores multiple solution trajectories during the sampling process. Different task-specific verifiers are developed, and two search algorithms, including the random search and zero-order search for SR, are introduced. By actively guiding the exploration of the high-dimensional solution space through verifier-algorithm combinations, we enable more robust and higher-quality outputs. Through extensive validation across diverse audio domains (speech, music, sound effects) and frequency ranges, we demonstrate consistent performance gains, achieving improvements of up to 9.70% in aesthetics, 5.88% in speaker similarity, 15.20% in word error rate, and 46.98% in spectral distance for speech SR from 4kHz to 24kHz, showcasing the effectiveness of our approach. Audio samples are available at: https://racerk.github.io/tt-scale-audiosr/.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02391v1",
    "published_date": "2025-08-04 13:17:49 UTC",
    "updated_date": "2025-08-04 13:17:49 UTC"
  },
  {
    "arxiv_id": "2508.02362v1",
    "title": "Text2Lip: Progressive Lip-Synced Talking Face Generation from Text via Viseme-Guided Rendering",
    "authors": [
      "Xu Wang",
      "Shengeng Tang",
      "Fei Wang",
      "Lechao Cheng",
      "Dan Guo",
      "Feng Xue",
      "Richang Hong"
    ],
    "abstract": "Generating semantically coherent and visually accurate talking faces requires bridging the gap between linguistic meaning and facial articulation. Although audio-driven methods remain prevalent, their reliance on high-quality paired audio visual data and the inherent ambiguity in mapping acoustics to lip motion pose significant challenges in terms of scalability and robustness. To address these issues, we propose Text2Lip, a viseme-centric framework that constructs an interpretable phonetic-visual bridge by embedding textual input into structured viseme sequences. These mid-level units serve as a linguistically grounded prior for lip motion prediction. Furthermore, we design a progressive viseme-audio replacement strategy based on curriculum learning, enabling the model to gradually transition from real audio to pseudo-audio reconstructed from enhanced viseme features via cross-modal attention. This allows for robust generation in both audio-present and audio-free scenarios. Finally, a landmark-guided renderer synthesizes photorealistic facial videos with accurate lip synchronization. Extensive evaluations show that Text2Lip outperforms existing approaches in semantic fidelity, visual realism, and modality robustness, establishing a new paradigm for controllable and flexible talking face generation. Our project homepage is https://plyon1.github.io/Text2Lip/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02362v1",
    "published_date": "2025-08-04 12:50:22 UTC",
    "updated_date": "2025-08-04 12:50:22 UTC"
  },
  {
    "arxiv_id": "2508.06538v2",
    "title": "Symbolic Learning of Interpretable Reduced-Order Models for Jumping Quadruped Robots",
    "authors": [
      "Gioele Buriani",
      "Jingyue Liu",
      "Maximilian Stölzle",
      "Cosimo Della Santina",
      "Jiatao Ding"
    ],
    "abstract": "Reduced-order models are central to motion planning and control of quadruped robots, yet existing templates are often hand-crafted for a specific locomotion modality. This motivates the need for automatic methods that extract task-specific, interpretable low-dimensional dynamics directly from data. We propose a methodology that combines a linear autoencoder with symbolic regression to derive such models. The linear autoencoder provides a consistent latent embedding for configurations, velocities, accelerations, and inputs, enabling the sparse identification of nonlinear dynamics (SINDy) to operate in a compact, physics-aligned space. A multi-phase, hybrid-aware training scheme ensures coherent latent coordinates across contact transitions. We focus our validation on quadruped jumping-a representative, challenging, yet contained scenario in which a principled template model is especially valuable. The resulting symbolic dynamics outperform the state-of-the-art handcrafted actuated spring-loaded inverted pendulum (aSLIP) baseline in simulation and hardware across multiple robots and jumping modalities.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "8 pages",
    "pdf_url": "https://arxiv.org/pdf/2508.06538v2",
    "published_date": "2025-08-04 12:33:51 UTC",
    "updated_date": "2026-01-13 08:38:00 UTC"
  },
  {
    "arxiv_id": "2508.02348v2",
    "title": "mmWave Radar-Based Non-Line-of-Sight Pedestrian Localization at T-Junctions Utilizing Road Layout Extraction via Camera",
    "authors": [
      "Byeonggyu Park",
      "Hee-Yeun Kim",
      "Byonghyok Choi",
      "Hansang Cho",
      "Byungkwan Kim",
      "Soomok Lee",
      "Mingu Jeon",
      "Seong-Woo Kim"
    ],
    "abstract": "Pedestrians Localization in Non-Line-of-Sight (NLoS) regions within urban environments poses a significant challenge for autonomous driving systems. While mmWave radar has demonstrated potential for detecting objects in such scenarios, the 2D radar point cloud (PCD) data is susceptible to distortions caused by multipath reflections, making accurate spatial inference difficult. Additionally, although camera images provide high-resolution visual information, they lack depth perception and cannot directly observe objects in NLoS regions. In this paper, we propose a novel framework that interprets radar PCD through road layout inferred from camera for localization of NLoS pedestrians. The proposed method leverages visual information from the camera to interpret 2D radar PCD, enabling spatial scene reconstruction. The effectiveness of the proposed approach is validated through experiments conducted using a radar-camera system mounted on a real vehicle. The localization performance is evaluated using a dataset collected in outdoor NLoS driving environments, demonstrating the practical applicability of the method.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02348v2",
    "published_date": "2025-08-04 12:31:11 UTC",
    "updated_date": "2025-10-14 07:16:20 UTC"
  },
  {
    "arxiv_id": "2508.02344v2",
    "title": "Traffic-R1: Reinforced LLMs Bring Human-Like Reasoning to Traffic Signal Control Systems",
    "authors": [
      "Xingchen Zou",
      "Yuhao Yang",
      "Zheng Chen",
      "Xixuan Hao",
      "Yiqi Chen",
      "Chao Huang",
      "Yuxuan Liang"
    ],
    "abstract": "We introduce Traffic-R1, a 3B-parameter foundation model with human-like reasoning for Traffic signal control (TSC), developed via self-exploration and iterative reinforcement of LLM with expert guidance in a simulated traffic environment. Compared with traditional reinforcement learning and recent LLM-based methods, Traffic-R1 offers three main advantages: zero-shot generalization, transferring unchanged to new road networks and out-of-distribution incidents by leveraging internal traffic-control policies and reasoning; a compact 3B-parameter design that supports real-time inference on mobile-class chips for edge deployment; and an explainable TSC process that enables multi-intersection coordination through communication and an asynchronous communication network. Extensive benchmarks show Traffic-R1 outperforms strong baselines and training-intensive RL controllers. In production, the model now manages signals affecting over 55,000 drivers daily, reduces average queue lengths by more than 5%, and halves operator workload. Our model is available at https://huggingface.co/Season998/Traffic-R1.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02344v2",
    "published_date": "2025-08-04 12:25:19 UTC",
    "updated_date": "2025-10-22 07:05:37 UTC"
  },
  {
    "arxiv_id": "2508.02343v1",
    "title": "MicroMix: Efficient Mixed-Precision Quantization with Microscaling Formats for Large Language Models",
    "authors": [
      "Wenyuan Liu",
      "Haoqian Meng",
      "Yilun Luo",
      "Peng Zhang",
      "Xindian Ma"
    ],
    "abstract": "Quantization significantly accelerates inference in large language models (LLMs) by replacing original high-precision matrices with low-precision counterparts. Recent advances in weight-activation quantization have primarily focused on mapping both weights and activations to the INT4 format. Although the new FP4 Tensor Cores in NVIDIA's Blackwell architecture offer up to 4x speedup over FP16, existing INT4-based kernels fail to fully exploit this capability due to mismatched data formats. To bridge this gap, we propose MicroMix, a co-designed mixed-precision quantization algorithm and matrix multiplication kernel based on Microscaling (MX) data formats. Tailored for the Blackwell architecture, the MicroMix kernel supports arbitrary combinations of MXFP4, MXFP6, and MXFP8 channels, and produces BFloat16 outputs. To achieve a favorable trade-off between accuracy and efficiency for each linear layer, we introduce quantization thresholds that identify activation elements where lower-precision formats (MXFP4 or MXFP6) incur excessive quantization error. Our algorithm selectively allocates higher-precision channels to preserve accuracy while maintaining compute efficiency. MicroMix achieves competitive or superior performance across diverse downstream tasks, including zero-shot and few-shot learning, language modeling, code generation, and mathematical reasoning. On both consumer-grade (RTX 5070Ti laptop) and server-grade (RTX 5090) GPUs, our kernel delivers at least 20% faster execution than TensorRT-FP8. Furthermore, when applied to various Llama and Qwen models, MicroMix consistently improves prefill latency and memory efficiency across a range of batch sizes compared to TensorRT baselines. Our code is available at https://github.com/lwy2020/MicroMix.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages",
    "pdf_url": "https://arxiv.org/pdf/2508.02343v1",
    "published_date": "2025-08-04 12:22:39 UTC",
    "updated_date": "2025-08-04 12:22:39 UTC"
  },
  {
    "arxiv_id": "2508.02317v3",
    "title": "VeOmni: Scaling Any Modality Model Training with Model-Centric Distributed Recipe Zoo",
    "authors": [
      "Qianli Ma",
      "Yaowei Zheng",
      "Zhelun Shi",
      "Zhongkai Zhao",
      "Bin Jia",
      "Ziyue Huang",
      "Zhiqi Lin",
      "Youjie Li",
      "Jiacheng Yang",
      "Yanghua Peng",
      "Zhi Zhang",
      "Xin Liu"
    ],
    "abstract": "Recent advances in large language models (LLMs) have driven impressive progress in omni-modal understanding and generation. However, training omni-modal LLMs remains a significant challenge due to the heterogeneous model architectures required to process diverse modalities, necessitating sophisticated system design for efficient large-scale training. Existing frameworks typically entangle model definition with parallel logic, incurring limited scalability and substantial engineering overhead for end-to-end omni-modal training. We present VeOmni, a modular and efficient training framework to accelerate the development of omni-modal LLMs. VeOmni introduces model-centric distributed recipes that decouples communication from computation, enabling efficient 3D parallelism on omni-modal LLMs. VeOmni also features a flexible configuration interface supporting seamless integration of new modalities with minimal code change. Using VeOmni, a omni-modal mixture-of-experts (MoE) model with 30B parameters can be trained with over 2,800 tokens/sec/GPU throughput and scale to 160K context lengths via 3D parallelism on 128 GPUs, showcasing its superior efficiency and scalability for training large omni-modal LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02317v3",
    "published_date": "2025-08-04 11:33:04 UTC",
    "updated_date": "2025-08-07 10:31:09 UTC"
  },
  {
    "arxiv_id": "2508.02314v2",
    "title": "Large AI Models for Wireless Physical Layer",
    "authors": [
      "Jiajia Guo",
      "Yiming Cui",
      "Shi Jin",
      "Jun Zhang"
    ],
    "abstract": "Large artificial intelligence models (LAMs) are transforming wireless physical layer technologies through their robust generalization, multitask processing, and multimodal capabilities. This article reviews recent advancements in applying LAMs to physical layer communications, addressing obstacles of conventional AI-based approaches. LAM-based solutions are classified into two strategies: leveraging pre-trained LAMs and developing native LAMs designed specifically for physical layer tasks. The motivations and key frameworks of these approaches are comprehensively examined through multiple use cases. Both strategies significantly improve performance and adaptability across diverse wireless scenarios. Future research directions, including efficient architectures, interpretability, standardized datasets, and collaboration between large and small models, are proposed to advance LAM-based physical layer solutions for next-generation communication systems.",
    "categories": [
      "cs.IT",
      "cs.AI"
    ],
    "primary_category": "cs.IT",
    "comment": "A collection of paper on Large AI Models for wireless physical layer can be found at https://github.com/AI4Wireless/LAM4PHY_6G",
    "pdf_url": "https://arxiv.org/pdf/2508.02314v2",
    "published_date": "2025-08-04 11:30:33 UTC",
    "updated_date": "2026-01-20 03:09:51 UTC"
  },
  {
    "arxiv_id": "2508.02312v1",
    "title": "A Survey on Data Security in Large Language Models",
    "authors": [
      "Kang Chen",
      "Xiuze Zhou",
      "Yuanguo Lin",
      "Jinhe Su",
      "Yuanhui Yu",
      "Li Shen",
      "Fan Lin"
    ],
    "abstract": "Large Language Models (LLMs), now a foundation in advancing natural language processing, power applications such as text generation, machine translation, and conversational systems. Despite their transformative potential, these models inherently rely on massive amounts of training data, often collected from diverse and uncurated sources, which exposes them to serious data security risks. Harmful or malicious data can compromise model behavior, leading to issues such as toxic output, hallucinations, and vulnerabilities to threats such as prompt injection or data poisoning. As LLMs continue to be integrated into critical real-world systems, understanding and addressing these data-centric security risks is imperative to safeguard user trust and system reliability. This survey offers a comprehensive overview of the main data security risks facing LLMs and reviews current defense strategies, including adversarial training, RLHF, and data augmentation. Additionally, we categorize and analyze relevant datasets used for assessing robustness and security across different domains, providing guidance for future research. Finally, we highlight key research directions that focus on secure model updates, explainability-driven defenses, and effective governance frameworks, aiming to promote the safe and responsible development of LLM technology. This work aims to inform researchers, practitioners, and policymakers, driving progress toward data security in LLMs.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02312v1",
    "published_date": "2025-08-04 11:28:34 UTC",
    "updated_date": "2025-08-04 11:28:34 UTC"
  },
  {
    "arxiv_id": "2508.02298v4",
    "title": "CAPO: Towards Enhancing LLM Reasoning through Generative Credit Assignment",
    "authors": [
      "Guofu Xie",
      "Yunsheng Shi",
      "Hongtao Tian",
      "Ting Yao",
      "Xiao Zhang"
    ],
    "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has improved the reasoning abilities of Large Language Models (LLMs) by using rule-based binary feedback. However, current RLVR methods typically assign the same reward to every token. This coarse-grained feedback hampers precise credit assignment, making it hard for models to identify which reasoning steps lead to success or failure, and often results in suboptimal policies. Methods like PPO provide credit assignment by value estimation, but yield inaccurate and unverifiable signals due to limited sampling. On the other hand, methods using Process Reward Models can provide step-wise rewards but suffer from several key limitations: they require high-quality process supervision labels, the feedback is unreliable due to probabilistic reward modeling, and their application in online reinforcement learning (RL) is time-consuming. To overcome these limitations, we introduce a simple but efficient method-Credit Assignment Policy Optimization (CAPO). Instead of training auxiliary models, CAPO directly leverages an off-the-shelf, general-purpose LLM as a Generative Process Reward Model (LLM-as-GenPRM) to generate all step-wise critique by one pass only based on the correctness of the step itself, providing deterministic token-level credits to refine the tokens that were originally assigned identical rule-based rewards. To further enhance the accuracy and robustness, we employ voting mechanisms that scale with the number of generated critiques. Extensive experiments on various backbones like Llama and Qwen models show that CAPO consistently outperforms supervised learning-based and RL-based fine-tuning methods across four challenging mathematical benchmarks and three out-of-domain benchmarks. Further analysis shows that CAPO can help the model to foster the learning of correct reasoning pathways leading to correct answers.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Work in progress",
    "pdf_url": "https://arxiv.org/pdf/2508.02298v4",
    "published_date": "2025-08-04 11:06:08 UTC",
    "updated_date": "2025-10-20 11:32:37 UTC"
  },
  {
    "arxiv_id": "2508.02292v2",
    "title": "FinWorld: An All-in-One Open-Source Platform for End-to-End Financial AI Research and Deployment",
    "authors": [
      "Wentao Zhang",
      "Yilei Zhao",
      "Chuqiao Zong",
      "Xinrun Wang",
      "Bo An"
    ],
    "abstract": "Financial AI holds great promise for transforming modern finance, with the potential to support a wide range of tasks such as market forecasting, portfolio management, quantitative trading, and automated analysis. However, existing platforms remain limited in task coverage, lack robust multimodal data integration, and offer insufficient support for the training and deployment of large language models (LLMs). In response to these limitations, we present FinWorld, an all-in-one open-source platform that provides end-to-end support for the entire financial AI workflow, from data acquisition to experimentation and deployment. FinWorld distinguishes itself through native integration of heterogeneous financial data, unified support for diverse AI paradigms, and advanced agent automation, enabling seamless development and deployment. Leveraging data from 2 representative markets, 4 stock pools, and over 800 million financial data points, we conduct comprehensive experiments on 4 key financial AI tasks. These experiments systematically evaluate deep learning and reinforcement learning algorithms, with particular emphasis on RL-based finetuning for LLMs and LLM Agents. The empirical results demonstrate that FinWorld significantly enhances reproducibility, supports transparent benchmarking, and streamlines deployment, thereby providing a strong foundation for future research and real-world applications. Code is available at Github~\\footnote{https://github.com/DVampire/FinWorld}.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02292v2",
    "published_date": "2025-08-04 11:02:34 UTC",
    "updated_date": "2025-12-08 05:14:48 UTC"
  },
  {
    "arxiv_id": "2508.02291v2",
    "title": "FAIR-Pruner: Leveraging Tolerance of Difference for Flexible Automatic Layer-Wise Neural Network Pruning",
    "authors": [
      "Chenqing Lin",
      "Mostafa Hussien",
      "Chengyao Yu",
      "Bingyi Jing",
      "Mohamed Cheriet",
      "Osama Abdelrahman",
      "Ruixing Ming"
    ],
    "abstract": "Neural network pruning has been widely adopted to reduce the parameter scale of complex neural networks, enabling efficient deployment on resource-limited edge devices. Mainstream pruning methods typically adopt uniform pruning strategies, which tend to cause a substantial performance degradation under high sparsity levels. Recent studies focus on non-uniform layer-wise pruning, but such approaches typically depend on global architecture optimization, which is computational expensive and lacks flexibility. To address these limitations, this paper proposes a novel method named Flexible Automatic Identification and Removal (FAIR)-Pruner, which adaptively determines the sparsity levels of each layer and identifies the units to be pruned. The core of FAIR-Pruner lies in the introduction of a novel indicator, Tolerance of Differences (ToD), designed to balance the importance scores obtained from two complementary perspectives: the architecture-level (Utilization Score) and the task-level (Reconstruction Score). By controlling ToD at preset levels, FAIR-Pruner determines layer-specific thresholds and removes units whose Utilization Scores fall below the corresponding thresholds. Furthermore, by decoupling threshold determination from importance estimation, FAIR-Pruner allows users to flexibly obtain pruned models under varying pruning ratios. Extensive experiments demonstrate that FAIR-Pruner achieves state-of-the-art performance, maintaining higher accuracy even at high compression ratios. Moreover, the ToD based layer-wise pruning ratios can be directly applied to existing powerful importance measurements, thereby improving the performance under uniform-pruning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Submitted to CVPR 2026",
    "pdf_url": "https://arxiv.org/pdf/2508.02291v2",
    "published_date": "2025-08-04 10:59:07 UTC",
    "updated_date": "2025-11-22 09:08:05 UTC"
  },
  {
    "arxiv_id": "2508.02279v1",
    "title": "Dialogue Systems Engineering: A Survey and Future Directions",
    "authors": [
      "Mikio Nakano",
      "Hironori Takeuchi",
      "Sadahiro Yoshikawa",
      "Yoichi Matsuyama",
      "Kazunori Komatani"
    ],
    "abstract": "This paper proposes to refer to the field of software engineering related to the life cycle of dialogue systems as Dialogue Systems Engineering, and surveys this field while also discussing its future directions. With the advancement of large language models, the core technologies underlying dialogue systems have significantly progressed. As a result, dialogue system technology is now expected to be applied to solving various societal issues and in business contexts. To achieve this, it is important to build, operate, and continuously improve dialogue systems correctly and efficiently. Accordingly, in addition to applying existing software engineering knowledge, it is becoming increasingly important to evolve software engineering tailored specifically to dialogue systems. In this paper, we enumerate the knowledge areas of dialogue systems engineering based on those of software engineering, as defined in the Software Engineering Body of Knowledge (SWEBOK) Version 4.0, and survey each area. Based on this survey, we identify unexplored topics in each area and discuss the future direction of dialogue systems engineering.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "18 pages, 2 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.02279v1",
    "published_date": "2025-08-04 10:49:01 UTC",
    "updated_date": "2025-08-04 10:49:01 UTC"
  },
  {
    "arxiv_id": "2508.02276v1",
    "title": "CellForge: Agentic Design of Virtual Cell Models",
    "authors": [
      "Xiangru Tang",
      "Zhuoyun Yu",
      "Jiapeng Chen",
      "Yan Cui",
      "Daniel Shao",
      "Weixu Wang",
      "Fang Wu",
      "Yuchen Zhuang",
      "Wenqi Shi",
      "Zhi Huang",
      "Arman Cohan",
      "Xihong Lin",
      "Fabian Theis",
      "Smita Krishnaswamy",
      "Mark Gerstein"
    ],
    "abstract": "Virtual cell modeling represents an emerging frontier at the intersection of artificial intelligence and biology, aiming to predict quantities such as responses to diverse perturbations quantitatively. However, autonomously building computational models for virtual cells is challenging due to the complexity of biological systems, the heterogeneity of data modalities, and the need for domain-specific expertise across multiple disciplines. Here, we introduce CellForge, an agentic system that leverages a multi-agent framework that transforms presented biological datasets and research objectives directly into optimized computational models for virtual cells. More specifically, given only raw single-cell multi-omics data and task descriptions as input, CellForge outputs both an optimized model architecture and executable code for training virtual cell models and inference. The framework integrates three core modules: Task Analysis for presented dataset characterization and relevant literature retrieval, Method Design, where specialized agents collaboratively develop optimized modeling strategies, and Experiment Execution for automated generation of code. The agents in the Design module are separated into experts with differing perspectives and a central moderator, and have to collaboratively exchange solutions until they achieve a reasonable consensus. We demonstrate CellForge's capabilities in single-cell perturbation prediction, using six diverse datasets that encompass gene knockouts, drug treatments, and cytokine stimulations across multiple modalities. CellForge consistently outperforms task-specific state-of-the-art methods. Overall, CellForge demonstrates how iterative interaction between LLM agents with differing perspectives provides better solutions than directly addressing a modeling challenge. Our code is publicly available at https://github.com/gersteinlab/CellForge.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02276v1",
    "published_date": "2025-08-04 10:43:31 UTC",
    "updated_date": "2025-08-04 10:43:31 UTC"
  },
  {
    "arxiv_id": "2508.02271v2",
    "title": "Dynaword: From One-shot to Continuously Developed Datasets",
    "authors": [
      "Kenneth Enevoldsen",
      "Kristian Nørgaard Jensen",
      "Jan Kostkan",
      "Balázs Szabó",
      "Márton Kardos",
      "Kirten Vad",
      "Johan Heinsen",
      "Andrea Blasi Núñez",
      "Gianluca Barmina",
      "Jacob Nielsen",
      "Rasmus Larsen",
      "Peter Vahlstrup",
      "Per Møldrup Dalum",
      "Desmond Elliott",
      "Lukas Galke",
      "Peter Schneider-Kamp",
      "Kristoffer Nielbo"
    ],
    "abstract": "Large-scale datasets are foundational for research and development in natural language processing. However, current approaches face three key challenges: (1) reliance on ambiguously licensed sources restricting use, sharing, and derivative works; (2) static dataset releases that prevent community contributions and diminish longevity; and (3) quality assurance processes restricted to publishing teams rather than leveraging community expertise.\n  To address these limitations, we introduce two contributions: the Dynaword approach and Danish Dynaword. The Dynaword approach is a framework for creating large-scale, open datasets that can be continuously updated through community collaboration. Danish Dynaword is a concrete implementation that validates this approach and demonstrates its potential. Danish Dynaword contains over four times as many tokens as comparable releases, is exclusively openly licensed, and has received multiple contributions across industry and research. The repository includes light-weight tests to ensure data formatting, quality, and documentation, establishing a sustainable framework for ongoing community contributions and dataset evolution.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02271v2",
    "published_date": "2025-08-04 10:30:42 UTC",
    "updated_date": "2025-08-05 09:27:09 UTC"
  },
  {
    "arxiv_id": "2508.02269v2",
    "title": "AirTrafficGen: Configurable Air Traffic Scenario Generation with Large Language Models",
    "authors": [
      "Dewi Sid William Gould",
      "George De Ath",
      "Ben Carvell",
      "Nick Pepper"
    ],
    "abstract": "The manual design of scenarios for Air Traffic Control (ATC) training is a demanding and time-consuming bottleneck that limits the diversity of simulations available to controllers. To address this, we introduce a novel, end-to-end approach, $\\texttt{AirTrafficGen}$, that leverages large language models (LLMs) to automate and control the generation of complex ATC scenarios. Our method uses a purpose-built, graph-based representation to encode sector topology (including airspace geometry, routes, and fixes) into a format LLMs can process. Through rigorous benchmarking, we show that state-of-the-art models like Gemini 2.5 Pro, OpenAI o3, GPT-oss-120b and GPT-5 can generate high-traffic scenarios while maintaining operational realism. Our engineered prompting enables fine-grained control over interaction presence, type, and location. Initial findings suggest these models are also capable of iterative refinement, correcting flawed scenarios based on simple textual feedback. This approach provides a scalable alternative to manual scenario design, addressing the need for a greater volume and variety of ATC training and validation simulations. More broadly, this work showcases the potential of LLMs for complex planning in safety-critical domains.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages and appendices",
    "pdf_url": "https://arxiv.org/pdf/2508.02269v2",
    "published_date": "2025-08-04 10:21:47 UTC",
    "updated_date": "2025-08-15 10:37:36 UTC"
  },
  {
    "arxiv_id": "2508.14068v1",
    "title": "Revisit Choice Network for Synthesis and Technology Mapping",
    "authors": [
      "Chen Chen",
      "Jiaqi Yin",
      "Cunxi Yu"
    ],
    "abstract": "Choice network construction is a critical technique for alleviating structural bias issues in Boolean optimization, equivalence checking, and technology mapping. Previous works on lossless synthesis utilize independent optimization to generate multiple snapshots, and use simulation and SAT solvers to identify functionally equivalent nodes. These nodes are then merged into a subject graph with choice nodes. However, such methods often neglect the quality of these choices, raising the question of whether they truly contribute to effective technology mapping.\n  This paper introduces Cristal, a novel methodology and framework for constructing Boolean choice networks. Specifically, Cristal introduces a new flow of choice network-based synthesis and mapping, including representative logic cone search, structural mutation for generating diverse choice structures via equality saturation, and priority-ranking choice selection along with choice network construction and validation. Through these techniques, Cristal constructs fewer but higher-quality choices.\n  Our experimental results demonstrate that Cristal outperforms the state-of-the-art Boolean choice network construction implemented in ABC in the post-mapping stage, achieving average reductions of 3.85%/8.35% (area/delay) in delay-oriented mode, 0.11%/2.74% in area-oriented mode, and a 63.77% runtime reduction on large-scale cases across a diverse set of combinational circuits from the IWLS 2005, ISCAS'89, and EPFL benchmark suites.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "Accepted by ICCAD 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.14068v1",
    "published_date": "2025-08-04 10:09:10 UTC",
    "updated_date": "2025-08-04 10:09:10 UTC"
  },
  {
    "arxiv_id": "2508.02260v1",
    "title": "Decomposing the Entropy-Performance Exchange: The Missing Keys to Unlocking Effective Reinforcement Learning",
    "authors": [
      "Jia Deng",
      "Jie Chen",
      "Zhipeng Chen",
      "Wayne Xin Zhao",
      "Ji-Rong Wen"
    ],
    "abstract": "Recently, reinforcement learning with verifiable rewards (RLVR) has been widely used for enhancing the reasoning abilities of large language models (LLMs). A core challenge in RLVR involves managing the exchange between entropy and performance of policies. Despite the importance of this exchange, a fine-grained understanding of when and how this exchange operates most effectively remains limited. To bridge this gap, we conduct a systematic empirical analysis of the entropy-performance exchange mechanism of RLVR across different levels of granularity. Specifically, we first divide the training process into two distinct stages based on entropy dynamics, i.e., rising stage and plateau stage, and then systematically investigate how this mechanism varies across stage-level, instance-level, and token-level granularitiess. Our analysis reveals that, in the rising stage, entropy reduction in negative samples facilitates the learning of effective reasoning patterns, which in turn drives rapid performance gains. Moreover, in the plateau stage, learning efficiency strongly correlates with high-entropy tokens present in low-perplexity samples and those located at the end of sequences. Motivated by these findings, we propose two methods that dynamically adjust the reward signal using perplexity and positional information to focus RL updates on tokens that exhibit high learning potential, achieving improvements compared to the baseline methods on various LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "7 pages, 20 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.02260v1",
    "published_date": "2025-08-04 10:08:10 UTC",
    "updated_date": "2025-08-04 10:08:10 UTC"
  },
  {
    "arxiv_id": "2508.02255v1",
    "title": "StutterCut: Uncertainty-Guided Normalised Cut for Dysfluency Segmentation",
    "authors": [
      "Suhita Ghosh",
      "Melanie Jouaiti",
      "Jan-Ole Perschewski",
      "Sebastian Stober"
    ],
    "abstract": "Detecting and segmenting dysfluencies is crucial for effective speech therapy and real-time feedback. However, most methods only classify dysfluencies at the utterance level. We introduce StutterCut, a semi-supervised framework that formulates dysfluency segmentation as a graph partitioning problem, where speech embeddings from overlapping windows are represented as graph nodes. We refine the connections between nodes using a pseudo-oracle classifier trained on weak (utterance-level) labels, with its influence controlled by an uncertainty measure from Monte Carlo dropout. Additionally, we extend the weakly labelled FluencyBank dataset by incorporating frame-level dysfluency boundaries for four dysfluency types. This provides a more realistic benchmark compared to synthetic datasets. Experiments on real and synthetic datasets show that StutterCut outperforms existing methods, achieving higher F1 scores and more precise stuttering onset detection.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted in Interspeech 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.02255v1",
    "published_date": "2025-08-04 10:02:06 UTC",
    "updated_date": "2025-08-04 10:02:06 UTC"
  },
  {
    "arxiv_id": "2508.02247v2",
    "title": "ByteGen: A Tokenizer-Free Generative Model for Orderbook Events in Byte Space",
    "authors": [
      "Yang Li",
      "Zhi Chen"
    ],
    "abstract": "Generative modeling of high-frequency limit order book (LOB) dynamics is a critical yet unsolved challenge in quantitative finance, essential for robust market simulation and strategy backtesting. Existing approaches are often constrained by simplifying stochastic assumptions or, in the case of modern deep learning models like Transformers, rely on tokenization schemes that affect the high-precision, numerical nature of financial data through discretization and binning. To address these limitations, we introduce ByteGen, a novel generative model that operates directly on the raw byte streams of LOB events. Our approach treats the problem as an autoregressive next-byte prediction task, for which we design a compact and efficient 32-byte packed binary format to represent market messages without information loss. The core novelty of our work is the complete elimination of feature engineering and tokenization, enabling the model to learn market dynamics from its most fundamental representation. We achieve this by adapting the H-Net architecture, a hybrid Mamba-Transformer model that uses a dynamic chunking mechanism to discover the inherent structure of market messages without predefined rules. Our primary contributions are: 1) the first end-to-end, byte-level framework for LOB modeling; 2) an efficient packed data representation; and 3) a comprehensive evaluation on high-frequency data. Trained on over 34 million events from CME Bitcoin futures, ByteGen successfully reproduces key stylized facts of financial markets, generating realistic price distributions, heavy-tailed returns, and bursty event timing. Our findings demonstrate that learning directly from byte space is a promising and highly flexible paradigm for modeling complex financial systems, achieving competitive performance on standard market quality metrics without the biases of tokenization.",
    "categories": [
      "q-fin.CP",
      "cs.AI",
      "cs.CE",
      "cs.LG",
      "q-fin.TR"
    ],
    "primary_category": "q-fin.CP",
    "comment": "21 pages, 3 tables, 5 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.02247v2",
    "published_date": "2025-08-04 09:48:42 UTC",
    "updated_date": "2025-08-07 04:31:56 UTC"
  },
  {
    "arxiv_id": "2508.02240v3",
    "title": "Forecasting When to Forecast: Accelerating Diffusion Models with Confidence-Gated Taylor",
    "authors": [
      "Xiaoliu Guan",
      "Lielin Jiang",
      "Hanqi Chen",
      "Xu Zhang",
      "Jiaxing Yan",
      "Guanzhong Wang",
      "Yi Liu",
      "Zetao Zhang",
      "Yu Wu"
    ],
    "abstract": "Diffusion Transformers (DiTs) have demonstrated remarkable performance in visual generation tasks. However, their low inference speed limits their deployment in low-resource applications. Recent training-free approaches exploit the redundancy of features across timesteps by caching and reusing past representations to accelerate inference. Building on this idea, TaylorSeer instead uses cached features to predict future ones via Taylor expansion. However, its module-level prediction across all transformer blocks (e.g., attention or feedforward modules) requires storing fine-grained intermediate features, leading to notable memory and computation overhead. Moreover, it adopts a fixed caching schedule without considering the varying accuracy of predictions across timesteps, which can lead to degraded outputs when prediction fails. To address these limitations, we propose a novel approach to better leverage Taylor-based acceleration. First, we shift the Taylor prediction target from the module level to the last block level, significantly reducing the number of cached features. Furthermore, observing strong sequential dependencies among Transformer blocks, we propose to use the error between the Taylor-estimated and actual outputs of the first block as an indicator of prediction reliability. If the error is small, we trust the Taylor prediction for the last block; otherwise, we fall back to full computation, thereby enabling a dynamic caching mechanism. Empirical results show that our method achieves a better balance between speed and quality, achieving a 3.17x acceleration on FLUX, 2.36x on DiT, and 4.14x on Wan Video with negligible quality drop. The Project Page is \\href{https://cg-taylor-acce.github.io/CG-Taylor/}{here.}",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "15 pages, 4 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.02240v3",
    "published_date": "2025-08-04 09:39:31 UTC",
    "updated_date": "2025-11-08 11:53:33 UTC"
  },
  {
    "arxiv_id": "2508.02222v1",
    "title": "FinCPRG: A Bidirectional Generation Pipeline for Hierarchical Queries and Rich Relevance in Financial Chinese Passage Retrieval",
    "authors": [
      "Xuan Xu",
      "Beilin Chu",
      "Qinhong Lin",
      "Yixiao Zhong",
      "Fufang Wen",
      "Jiaqi Liu",
      "Binjie Fei",
      "Yu Li",
      "Zhongliang Yang",
      "Linna Zhou"
    ],
    "abstract": "In recent years, large language models (LLMs) have demonstrated significant potential in constructing passage retrieval datasets. However, existing methods still face limitations in expressing cross-doc query needs and controlling annotation quality. To address these issues, this paper proposes a bidirectional generation pipeline, which aims to generate 3-level hierarchical queries for both intra-doc and cross-doc scenarios and mine additional relevance labels on top of direct mapping annotation. The pipeline introduces two query generation methods: bottom-up from single-doc text and top-down from multi-doc titles. The bottom-up method uses LLMs to disassemble and generate structured queries at both sentence-level and passage-level simultaneously from intra-doc passages. The top-down approach incorporates three key financial elements--industry, topic, and time--to divide report titles into clusters and prompts LLMs to generate topic-level queries from each cluster. For relevance annotation, our pipeline not only relies on direct mapping annotation from the generation relationship but also implements an indirect positives mining method to enrich the relevant query-passage pairs. Using this pipeline, we constructed a Financial Passage Retrieval Generated dataset (FinCPRG) from almost 1.3k Chinese financial research reports, which includes hierarchical queries and rich relevance labels. Through evaluations of mined relevance labels, benchmarking and training experiments, we assessed the quality of FinCPRG and validated its effectiveness as a passage retrieval dataset for both training and benchmarking.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02222v1",
    "published_date": "2025-08-04 09:12:45 UTC",
    "updated_date": "2025-08-04 09:12:45 UTC"
  },
  {
    "arxiv_id": "2508.02215v1",
    "title": "LeanK: Learnable K Cache Channel Pruning for Efficient Decoding",
    "authors": [
      "Yike Zhang",
      "Zhiyuan He",
      "Huiqiang Jiang",
      "Chengruidong Zhang",
      "Yuqing Yang",
      "Jianyong Wang",
      "Lili Qiu"
    ],
    "abstract": "Large language models (LLMs) enable long-context tasks but face efficiency challenges due to the growing key-value (KV) cache. We propose LeanK, a learning-based method that prunes unimportant key (K) cache channels by leveraging static channel sparsity. With a novel two-stage training process, LeanK learns channel-wise static mask that could satisfy specific sparsity ratio and hardware alignment requirement. LeanK reduces GPU memory and accelerates decoding without sacrificing accuracy. Experiments demonstrate up to 70% K cache and 16%-18% V cache memory reduction. Custom decoding kernel enables 1.3x speedup for attention computation. We also provide insights into model channels and attention heads during long-context inference by analyzing the learned importance distribution. Our code is available at https://aka.ms/LeanK.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02215v1",
    "published_date": "2025-08-04 09:08:43 UTC",
    "updated_date": "2025-08-04 09:08:43 UTC"
  },
  {
    "arxiv_id": "2508.02209v1",
    "title": "Balancing Information Accuracy and Response Timeliness in Networked LLMs",
    "authors": [
      "Yigit Turkmen",
      "Baturalp Buyukates",
      "Melih Bastopcu"
    ],
    "abstract": "Recent advancements in Large Language Models (LLMs) have transformed many fields including scientific discovery, content generation, biomedical text mining, and educational technology. However, the substantial requirements for training data, computational resources, and energy consumption pose significant challenges for their practical deployment. A promising alternative is to leverage smaller, specialized language models and aggregate their outputs to improve overall response quality. In this work, we investigate a networked LLM system composed of multiple users, a central task processor, and clusters of topic-specialized LLMs. Each user submits categorical binary (true/false) queries, which are routed by the task processor to a selected cluster of $m$ LLMs. After gathering individual responses, the processor returns a final aggregated answer to the user. We characterize both the information accuracy and response timeliness in this setting, and formulate a joint optimization problem to balance these two competing objectives. Our extensive simulations demonstrate that the aggregated responses consistently achieve higher accuracy than those of individual LLMs. Notably, this improvement is more significant when the participating LLMs exhibit similar standalone performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "cs.NI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02209v1",
    "published_date": "2025-08-04 09:00:01 UTC",
    "updated_date": "2025-08-04 09:00:01 UTC"
  },
  {
    "arxiv_id": "2508.02208v2",
    "title": "Proof2Hybrid: Automatic Mathematical Benchmark Synthesis for Proof-Centric Problems",
    "authors": [
      "Yebo Peng",
      "Zixiang Liu",
      "Yaoming Li",
      "Zhizhuo Yang",
      "Xinye Xu",
      "Bowen Ye",
      "Weijun Yuan",
      "Zihan Wang",
      "Tong Yang"
    ],
    "abstract": "Evaluating the mathematical capability of Large Language Models (LLMs) is a critical yet challenging frontier. Existing benchmarks fall short, particularly for proof-centric problems, as manual creation is unscalable and costly, leaving the true mathematical abilities of LLMs largely unassessed. To overcome these barriers, we propose Proof2Hybrid, the first fully automated framework that synthesizes high-quality, proof-centric benchmarks from natural language mathematical corpora. The key novelty of our solution is Proof2X, a roadmap of converting mathematical proofs into various kinds of questions that are easy to verify. Instructed by this roadmap, we propose a new type of hybrid-formatted questions, named ``$m$-out-of-$n$ multiple judge questions'', specifically designed to enable robust, automatic evaluation while being resilient to guessing and superficial pattern matching inherent in traditional formats. As a demonstration of our framework, we introduce AlgGeoTest, a benchmark for algebraic geometry--a frontier domain of modern mathematics--comprising 456 challenging items. Our extensive evaluations on state-of-the-art LLMs using AlgGeoTest reveal profound deficits in their comprehension of algebraic geometry, providing a more precise measure of their true mathematical capabilities. Our framework and benchmark pave the way for a new wave of in-depth research into the mathematical intelligence of AI systems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02208v2",
    "published_date": "2025-08-04 08:59:36 UTC",
    "updated_date": "2025-08-05 14:01:00 UTC"
  },
  {
    "arxiv_id": "2508.05670v1",
    "title": "Can LLMs effectively provide game-theoretic-based scenarios for cybersecurity?",
    "authors": [
      "Daniele Proverbio",
      "Alessio Buscemi",
      "Alessandro Di Stefano",
      "The Anh Han",
      "German Castignani",
      "Pietro Liò"
    ],
    "abstract": "Game theory has long served as a foundational tool in cybersecurity to test, predict, and design strategic interactions between attackers and defenders. The recent advent of Large Language Models (LLMs) offers new tools and challenges for the security of computer systems; In this work, we investigate whether classical game-theoretic frameworks can effectively capture the behaviours of LLM-driven actors and bots. Using a reproducible framework for game-theoretic LLM agents, we investigate two canonical scenarios -- the one-shot zero-sum game and the dynamic Prisoner's Dilemma -- and we test whether LLMs converge to expected outcomes or exhibit deviations due to embedded biases. Our experiments involve four state-of-the-art LLMs and span five natural languages, English, French, Arabic, Vietnamese, and Mandarin Chinese, to assess linguistic sensitivity. For both games, we observe that the final payoffs are influenced by agents characteristics such as personality traits or knowledge of repeated rounds. Moreover, we uncover an unexpected sensitivity of the final payoffs to the choice of languages, which should warn against indiscriminate application of LLMs in cybersecurity applications and call for in-depth studies, as LLMs may behave differently when deployed in different countries. We also employ quantitative metrics to evaluate the internal consistency and cross-language stability of LLM agents, to help guide the selection of the most stable LLMs and optimising models for secure applications.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CY",
      "cs.GT"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.05670v1",
    "published_date": "2025-08-04 08:57:14 UTC",
    "updated_date": "2025-08-04 08:57:14 UTC"
  },
  {
    "arxiv_id": "2508.02197v1",
    "title": "A Message Passing Realization of Expected Free Energy Minimization",
    "authors": [
      "Wouter W. L. Nuijten",
      "Mykola Lukashchuk",
      "Thijs van de Laar",
      "Bert de Vries"
    ],
    "abstract": "We present a message passing approach to Expected Free Energy (EFE) minimization on factor graphs, based on the theory introduced in arXiv:2504.14898. By reformulating EFE minimization as Variational Free Energy minimization with epistemic priors, we transform a combinatorial search problem into a tractable inference problem solvable through standard variational techniques. Applying our message passing method to factorized state-space models enables efficient policy inference. We evaluate our method on environments with epistemic uncertainty: a stochastic gridworld and a partially observable Minigrid task. Agents using our approach consistently outperform conventional KL-control agents on these tasks, showing more robust planning and efficient exploration under uncertainty. In the stochastic gridworld environment, EFE-minimizing agents avoid risky paths, while in the partially observable minigrid setting, they conduct more systematic information-seeking. This approach bridges active inference theory with practical implementations, providing empirical evidence for the efficiency of epistemic priors in artificial agents.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02197v1",
    "published_date": "2025-08-04 08:48:37 UTC",
    "updated_date": "2025-08-04 08:48:37 UTC"
  },
  {
    "arxiv_id": "2508.02191v3",
    "title": "Neuromorphic Computing with Multi-Frequency Oscillations: A Bio-Inspired Approach to Artificial Intelligence",
    "authors": [
      "Boheng Liu",
      "Ziyu Li",
      "Qing Li",
      "Xia Wu"
    ],
    "abstract": "Despite remarkable capabilities, artificial neural networks exhibit limited flexible, generalizable intelligence. This limitation stems from their fundamental divergence from biological cognition that overlooks both neural regions' functional specialization and the temporal dynamics critical for coordinating these specialized systems. We propose a tripartite brain-inspired architecture comprising functionally specialized perceptual, auxiliary, and executive systems. Moreover, the integration of temporal dynamics through the simulation of multi-frequency neural oscillation and synaptic dynamic adaptation mechanisms enhances the architecture, thereby enabling more flexible and efficient artificial cognition. Initial evaluations demonstrate superior performance compared to state-of-the-art temporal processing approaches, with 2.18\\% accuracy improvements while reducing required computation iterations by 48.44\\%, and achieving higher correlation with human confidence patterns. Though currently demonstrated on visual processing tasks, this architecture establishes a theoretical foundation for brain-like intelligence across cognitive domains, potentially bridging the gap between artificial and biological intelligence.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02191v3",
    "published_date": "2025-08-04 08:40:33 UTC",
    "updated_date": "2025-11-04 09:02:57 UTC"
  },
  {
    "arxiv_id": "2508.02190v1",
    "title": "FedVLA: Federated Vision-Language-Action Learning with Dual Gating Mixture-of-Experts for Robotic Manipulation",
    "authors": [
      "Cui Miao",
      "Tao Chang",
      "Meihan Wu",
      "Hongbin Xu",
      "Chun Li",
      "Ming Li",
      "Xiaodong Wang"
    ],
    "abstract": "Vision-language-action (VLA) models have significantly advanced robotic manipulation by enabling robots to interpret language instructions for task execution. However, training these models often relies on large-scale user-specific data, raising concerns about privacy and security, which in turn limits their broader adoption. To address this, we propose FedVLA, the first federated VLA learning framework, enabling distributed model training that preserves data privacy without compromising performance. Our framework integrates task-aware representation learning, adaptive expert selection, and expert-driven federated aggregation, enabling efficient and privacy-preserving training of VLA models. Specifically, we introduce an Instruction Oriented Scene-Parsing mechanism, which decomposes and enhances object-level features based on task instructions, improving contextual understanding. To effectively learn diverse task patterns, we design a Dual Gating Mixture-of-Experts (DGMoE) mechanism, where not only input tokens but also self-aware experts adaptively decide their activation. Finally, we propose an Expert-Driven Aggregation strategy at the federated server, where model aggregation is guided by activated experts, ensuring effective cross-client knowledge transfer.Extensive simulations and real-world robotic experiments demonstrate the effectiveness of our proposals. Notably, DGMoE significantly improves computational efficiency compared to its vanilla counterpart, while FedVLA achieves task success rates comparable to centralized training, effectively preserving data privacy.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted by ICCV 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.02190v1",
    "published_date": "2025-08-04 08:39:43 UTC",
    "updated_date": "2025-08-04 08:39:43 UTC"
  },
  {
    "arxiv_id": "2508.02189v2",
    "title": "Learning Dynamics of Meta-Learning in Small Model Pretraining",
    "authors": [
      "David Demitri Africa",
      "Yuval Weiss",
      "Paula Buttery",
      "Richard Diehl Martinez"
    ],
    "abstract": "Large language models are powerful but costly. We ask whether meta-learning can make the pretraining of small language models not only better but also more interpretable. We integrate first-order MAML with subset-masked LM pretraining, producing four LLama-style decoder-only models (11M-570M params), and evaluate it on a fundamental NLP task with many settings and real-world applications. Compared with vanilla training, our model (i) reaches the same loss up to 1.6x sooner, (ii) improves F1 on multilingual Universal NER under equal compute, and (iii) makes the training dynamics easy to read: first the network's representations fan out (\"diversify\") and later they collapse into a smaller, shared subspace (\"compress\"). This two-stage shift shows up as a rise-and-fall in both effective-rank curves and attention-head entropy. The same curves pinpoint which layers specialise earliest and which later reconverge, giving a compact, interpretable signature of meta-adaptation. Code, checkpoints and WandB logs are released.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted (oral) to Student Research Workshop at IJCNLP-AACL 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.02189v2",
    "published_date": "2025-08-04 08:34:30 UTC",
    "updated_date": "2025-11-07 00:52:57 UTC"
  },
  {
    "arxiv_id": "2508.09998v1",
    "title": "INTIMA: A Benchmark for Human-AI Companionship Behavior",
    "authors": [
      "Lucie-Aimée Kaffee",
      "Giada Pistilli",
      "Yacine Jernite"
    ],
    "abstract": "AI companionship, where users develop emotional bonds with AI systems, has emerged as a significant pattern with positive but also concerning implications. We introduce Interactions and Machine Attachment Benchmark (INTIMA), a benchmark for evaluating companionship behaviors in language models. Drawing from psychological theories and user data, we develop a taxonomy of 31 behaviors across four categories and 368 targeted prompts. Responses to these prompts are evaluated as companionship-reinforcing, boundary-maintaining, or neutral. Applying INTIMA to Gemma-3, Phi-4, o3-mini, and Claude-4 reveals that companionship-reinforcing behaviors remain much more common across all models, though we observe marked differences between models. Different commercial providers prioritize different categories within the more sensitive parts of the benchmark, which is concerning since both appropriate boundary-setting and emotional support matter for user well-being. These findings highlight the need for more consistent approaches to handling emotionally charged interactions.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.09998v1",
    "published_date": "2025-08-04 08:25:38 UTC",
    "updated_date": "2025-08-04 08:25:38 UTC"
  },
  {
    "arxiv_id": "2508.02178v2",
    "title": "Reconsidering Overthinking: Penalizing Internal and External Redundancy in CoT Reasoning",
    "authors": [
      "Jialiang Hong",
      "Taihang Zhen",
      "Kai Chen",
      "Jiaheng Liu",
      "Junlan Feng",
      "Wenpeng Zhu",
      "Jing Huo",
      "Yang Gao",
      "Depeng Wang",
      "Haitao Wan",
      "Xi Yang",
      "Boyan Wang",
      "Fanyu Meng",
      "Yuyao Zhang"
    ],
    "abstract": "Large Reasoning Models (LRMs) often suffer from overthinking, generating verbose reasoning traces that compromise both computational efficiency and interpretability. Unlike prior efforts that rely on global length-based rewards, we propose a semantic-aware decomposition of redundancy into two distinct forms: internal redundancy (informational stagnation within the reasoning process) and external redundancy (superfluous continuation after the final answer). We introduce a dual-penalty reinforcement learning framework that surgically targets these inefficiencies: a sliding-window semantic analysis is employed to penalize low-gain steps within the reasoning trajectory, while a normalized metric suppresses the post-answer tail. Extensive experiments demonstrate that our method significantly compresses Chain-of-Thought traces with minimal accuracy degradation, while maintaining strong generalization to out-of-domain tasks. Crucially, we reveal an asymmetry in redundancy: external redundancy can be safely eliminated without performance loss, whereas internal redundancy removal requires a calibrated trade-off to maintain reasoning fidelity. Our framework enables fine-grained, implicit control over reasoning length, paving the way for more concise and interpretable LRMs.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02178v2",
    "published_date": "2025-08-04 08:22:14 UTC",
    "updated_date": "2026-01-06 13:18:26 UTC"
  },
  {
    "arxiv_id": "2508.02172v1",
    "title": "GaussianCross: Cross-modal Self-supervised 3D Representation Learning via Gaussian Splatting",
    "authors": [
      "Lei Yao",
      "Yi Wang",
      "Yi Zhang",
      "Moyun Liu",
      "Lap-Pui Chau"
    ],
    "abstract": "The significance of informative and robust point representations has been widely acknowledged for 3D scene understanding. Despite existing self-supervised pre-training counterparts demonstrating promising performance, the model collapse and structural information deficiency remain prevalent due to insufficient point discrimination difficulty, yielding unreliable expressions and suboptimal performance. In this paper, we present GaussianCross, a novel cross-modal self-supervised 3D representation learning architecture integrating feed-forward 3D Gaussian Splatting (3DGS) techniques to address current challenges. GaussianCross seamlessly converts scale-inconsistent 3D point clouds into a unified cuboid-normalized Gaussian representation without missing details, enabling stable and generalizable pre-training. Subsequently, a tri-attribute adaptive distillation splatting module is incorporated to construct a 3D feature field, facilitating synergetic feature capturing of appearance, geometry, and semantic cues to maintain cross-modal consistency. To validate GaussianCross, we perform extensive evaluations on various benchmarks, including ScanNet, ScanNet200, and S3DIS. In particular, GaussianCross shows a prominent parameter and data efficiency, achieving superior performance through linear probing (<0.1% parameters) and limited data training (1% of scenes) compared to state-of-the-art methods. Furthermore, GaussianCross demonstrates strong generalization capabilities, improving the full fine-tuning accuracy by 9.3% mIoU and 6.1% AP$_{50}$ on ScanNet200 semantic and instance segmentation tasks, respectively, supporting the effectiveness of our approach. The code, weights, and visualizations are publicly available at \\href{https://rayyoh.github.io/GaussianCross/}{https://rayyoh.github.io/GaussianCross/}.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "14 pages, 8 figures, accepted by MM'25",
    "pdf_url": "https://arxiv.org/pdf/2508.02172v1",
    "published_date": "2025-08-04 08:12:44 UTC",
    "updated_date": "2025-08-04 08:12:44 UTC"
  },
  {
    "arxiv_id": "2508.02155v1",
    "title": "DreamPainter: Image Background Inpainting for E-commerce Scenarios",
    "authors": [
      "Sijie Zhao",
      "Jing Cheng",
      "Yaoyao Wu",
      "Hao Xu",
      "Shaohui Jiao"
    ],
    "abstract": "Although diffusion-based image genenation has been widely explored and applied, background generation tasks in e-commerce scenarios still face significant challenges. The first challenge is to ensure that the generated products are consistent with the given product inputs while maintaining a reasonable spatial arrangement, harmonious shadows, and reflections between foreground products and backgrounds. Existing inpainting methods fail to address this due to the lack of domain-specific data. The second challenge involves the limitation of relying solely on text prompts for image control, as effective integrating visual information to achieve precise control in inpainting tasks remains underexplored. To address these challenges, we introduce DreamEcom-400K, a high-quality e-commerce dataset containing accurate product instance masks, background reference images, text prompts, and aesthetically pleasing product images. Based on this dataset, we propose DreamPainter, a novel framework that not only utilizes text prompts for control but also flexibly incorporates reference image information as an additional control signal. Extensive experiments demonstrate that our approach significantly outperforms state-of-the-art methods, maintaining high product consistency while effectively integrating both text prompt and reference image information.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02155v1",
    "published_date": "2025-08-04 07:54:37 UTC",
    "updated_date": "2025-08-04 07:54:37 UTC"
  },
  {
    "arxiv_id": "2508.02150v1",
    "title": "Beyond the Trade-off: Self-Supervised Reinforcement Learning for Reasoning Models' Instruction Following",
    "authors": [
      "Qingyu Ren",
      "Qianyu He",
      "Bowei Zhang",
      "Jie Zeng",
      "Jiaqing Liang",
      "Yanghua Xiao",
      "Weikang Zhou",
      "Zeye Sun",
      "Fei Yu"
    ],
    "abstract": "Reasoning models excel in complex problem solving but exhibit a concerning trade off between reasoning capabilities and instruction following abilities. Existing approaches for improving instruction following rely on stronger external models, creating methodological bottlenecks and practical limitations including increased costs and accessibility constraints. We propose a self-supervised RL framework that leverages reasoning models' own internal signals to improve instruction following capabilities without external supervision. Extensive experiments demonstrate that our framework significantly improves instruction following capabilities while maintaining reasoning performance, offering a scalable and cost-effective approach to enhance instruction following in reasoning models. The data and code are publicly available at https://github.com/Rainier-rq/verl-if.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02150v1",
    "published_date": "2025-08-04 07:48:59 UTC",
    "updated_date": "2025-08-04 07:48:59 UTC"
  },
  {
    "arxiv_id": "2508.02148v2",
    "title": "Large-Scale Model Enabled Semantic Communication Based on Robust Knowledge Distillation",
    "authors": [
      "Kuiyuan Ding",
      "Caili Guo",
      "Yang Yang",
      "Zhongtian Du",
      "Walid Saad"
    ],
    "abstract": "Large-scale models (LSMs) can be an effective framework for semantic representation and understanding, thereby providing a suitable tool for designing semantic communication (SC) systems. However, their direct deployment is often hindered by high computational complexity and resource requirements. In this paper, a novel robust knowledge distillation based semantic communication (RKD-SC) framework is proposed to enable efficient and \\textcolor{black}{channel-noise-robust} LSM-powered SC. The framework addresses two key challenges: determining optimal compact model architectures and effectively transferring knowledge while maintaining robustness against channel noise. First, a knowledge distillation-based lightweight differentiable architecture search (KDL-DARTS) algorithm is proposed. This algorithm integrates knowledge distillation loss and a complexity penalty into the neural architecture search process to identify high-performance, lightweight semantic encoder architectures. Second, a novel two-stage robust knowledge distillation (RKD) algorithm is developed to transfer semantic capabilities from an LSM (teacher) to a compact encoder (student) and subsequently enhance system robustness. To further improve resilience to channel impairments, a channel-aware transformer (CAT) block is introduced as the channel codec, trained under diverse channel conditions with variable-length outputs. Extensive simulations on image classification tasks demonstrate that the RKD-SC framework significantly reduces model parameters while preserving a high degree of the teacher model's performance and exhibiting superior robustness compared to existing methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.IV",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages, 8 figures, 3 tables",
    "pdf_url": "https://arxiv.org/pdf/2508.02148v2",
    "published_date": "2025-08-04 07:47:18 UTC",
    "updated_date": "2025-08-25 08:48:25 UTC"
  },
  {
    "arxiv_id": "2508.02137v1",
    "title": "Fitness aligned structural modeling enables scalable virtual screening with AuroBind",
    "authors": [
      "Zhongyue Zhang",
      "Jiahua Rao",
      "Jie Zhong",
      "Weiqiang Bai",
      "Dongxue Wang",
      "Shaobo Ning",
      "Lifeng Qiao",
      "Sheng Xu",
      "Runze Ma",
      "Will Hua",
      "Jack Xiaoyu Chen",
      "Odin Zhang",
      "Wei Lu",
      "Hanyi Feng",
      "He Yang",
      "Xinchao Shi",
      "Rui Li",
      "Wanli Ouyang",
      "Xinzhu Ma",
      "Jiahao Wang",
      "Jixian Zhang",
      "Jia Duan",
      "Siqi Sun",
      "Jian Zhang",
      "Shuangjia Zheng"
    ],
    "abstract": "Most human proteins remain undrugged, over 96% of human proteins remain unexploited by approved therapeutics. While structure-based virtual screening promises to expand the druggable proteome, existing methods lack atomic-level precision and fail to predict binding fitness, limiting translational impact. We present AuroBind, a scalable virtual screening framework that fine-tunes a custom atomic-level structural model on million-scale chemogenomic data. AuroBind integrates direct preference optimization, self-distillation from high-confidence complexes, and a teacher-student acceleration strategy to jointly predict ligand-bound structures and binding fitness. The proposed models outperform state-of-the-art models on structural and functional benchmarks while enabling 100,000-fold faster screening across ultra-large compound libraries. In a prospective screen across ten disease-relevant targets, AuroBind achieved experimental hit rates of 7-69%, with top compounds reaching sub-nanomolar to picomolar potency. For the orphan GPCRs GPR151 and GPR160, AuroBind identified both agonists and antagonists with success rates of 16-30%, and functional assays confirmed GPR160 modulation in liver and prostate cancer models. AuroBind offers a generalizable framework for structure-function learning and high-throughput molecular screening, bridging the gap between structure prediction and therapeutic discovery.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "54 pages, 13 figures, code available at https://github.com/GENTEL-lab/AuroBind",
    "pdf_url": "https://arxiv.org/pdf/2508.02137v1",
    "published_date": "2025-08-04 07:34:48 UTC",
    "updated_date": "2025-08-04 07:34:48 UTC"
  },
  {
    "arxiv_id": "2508.02132v1",
    "title": "All Stories Are One Story: Emotional Arc Guided Procedural Game Level Generation",
    "authors": [
      "Yunge Wen",
      "Chenliang Huang",
      "Hangyu Zhou",
      "Zhuo Zeng",
      "Chun Ming Louis Po",
      "Julian Togelius",
      "Timothy Merino",
      "Sam Earle"
    ],
    "abstract": "The emotional arc is a universal narrative structure underlying stories across cultures and media -- an idea central to structuralist narratology, often encapsulated in the phrase \"all stories are one story.\" We present a framework for procedural game narrative generation that incorporates emotional arcs as a structural backbone for both story progression and gameplay dynamics. Leveraging established narratological theories and large-scale empirical analyses, we focus on two core emotional patterns -- Rise and Fall -- to guide the generation of branching story graphs. Each story node is automatically populated with characters, items, and gameplay-relevant attributes (e.g., health, attack), with difficulty adjusted according to the emotional trajectory. Implemented in a prototype action role-playing game (ARPG), our system demonstrates how emotional arcs can be operationalized using large language models (LLMs) and adaptive entity generation. Evaluation through player ratings, interviews, and sentiment analysis shows that emotional arc integration significantly enhances engagement, narrative coherence, and emotional impact. These results highlight the potential of emotionally structured procedural generation for advancing interactive storytelling for games.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02132v1",
    "published_date": "2025-08-04 07:27:55 UTC",
    "updated_date": "2025-08-04 07:27:55 UTC"
  },
  {
    "arxiv_id": "2508.08287v1",
    "title": "Sacred or Synthetic? Evaluating LLM Reliability and Abstention for Religious Questions",
    "authors": [
      "Farah Atif",
      "Nursultan Askarbekuly",
      "Kareem Darwish",
      "Monojit Choudhury"
    ],
    "abstract": "Despite the increasing usage of Large Language Models (LLMs) in answering questions in a variety of domains, their reliability and accuracy remain unexamined for a plethora of domains including the religious domains. In this paper, we introduce a novel benchmark FiqhQA focused on the LLM generated Islamic rulings explicitly categorized by the four major Sunni schools of thought, in both Arabic and English. Unlike prior work, which either overlooks the distinctions between religious school of thought or fails to evaluate abstention behavior, we assess LLMs not only on their accuracy but also on their ability to recognize when not to answer. Our zero-shot and abstention experiments reveal significant variation across LLMs, languages, and legal schools of thought. While GPT-4o outperforms all other models in accuracy, Gemini and Fanar demonstrate superior abstention behavior critical for minimizing confident incorrect answers. Notably, all models exhibit a performance drop in Arabic, highlighting the limitations in religious reasoning for languages other than English. To the best of our knowledge, this is the first study to benchmark the efficacy of LLMs for fine-grained Islamic school of thought specific ruling generation and to evaluate abstention for Islamic jurisprudence queries. Our findings underscore the need for task-specific evaluation and cautious deployment of LLMs in religious applications.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "8th AAAI/ACM Conference on AI, Ethics, and Society (AIES 2025)",
    "pdf_url": "https://arxiv.org/pdf/2508.08287v1",
    "published_date": "2025-08-04 07:27:26 UTC",
    "updated_date": "2025-08-04 07:27:26 UTC"
  },
  {
    "arxiv_id": "2508.02130v1",
    "title": "The Complexity of Extreme Climate Events on the New Zealand's Kiwifruit Industry",
    "authors": [
      "Boyuan Zheng",
      "Victor W. Chu",
      "Zhidong Li",
      "Evan Webster",
      "Ashley Rootsey"
    ],
    "abstract": "Climate change has intensified the frequency and severity of extreme weather events, presenting unprecedented challenges to the agricultural industry worldwide. In this investigation, we focus on kiwifruit farming in New Zealand. We propose to examine the impacts of climate-induced extreme events, specifically frost, drought, extreme rainfall, and heatwave, on kiwifruit harvest yields. These four events were selected due to their significant impacts on crop productivity and their prevalence as recorded by climate monitoring institutions in the country. We employed Isolation Forest, an unsupervised anomaly detection method, to analyse climate history and recorded extreme events, alongside with kiwifruit yields. Our analysis reveals considerable variability in how different types of extreme event affect kiwifruit yields underscoring notable discrepancies between climatic extremes and individual farm's yield outcomes. Additionally, our study highlights critical limitations of current anomaly detection approaches, particularly in accurately identifying events such as frost. These findings emphasise the need for integrating supplementary features like farm management strategies with climate adaptation practices. Our further investigation will employ ensemble methods that consolidate nearby farms' yield data and regional climate station features to reduce variance, thereby enhancing the accuracy and reliability of extreme event detection and the formulation of response strategies.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Pre-print v0.8 2025-08-04",
    "pdf_url": "https://arxiv.org/pdf/2508.02130v1",
    "published_date": "2025-08-04 07:24:30 UTC",
    "updated_date": "2025-08-04 07:24:30 UTC"
  },
  {
    "arxiv_id": "2508.02128v1",
    "title": "Amber Pruner: Leveraging N:M Activation Sparsity for Efficient Prefill in Large Language Models",
    "authors": [
      "Tai An",
      "Ruwu Cai",
      "Yanzhe Zhang",
      "Yang Liu",
      "Hao Chen",
      "Pengcheng Xie",
      "Sheng Chang",
      "Yiwu Yao",
      "Gongyi Wang"
    ],
    "abstract": "In the era of large language models (LLMs), N:M sparsity has emerged as a structured compression technique critical for accelerating inference. While prior work has primarily focused on weight sparsity, it often suffers from significant accuracy degradation. Activation sparsity, though promising, is typically training-dependent and faces challenges in generalization. To address these limitations, we introduce Amber Pruner, a training-free N:M activation sparsity method designed specifically for the prefill stage, targeting the acceleration of linear projection layers in LLMs. Extensive experiments across multiple models and sparsity ratios (2:4, 4:8, and 8:16) demonstrate that Amber Pruner can effectively sparsify and accelerate more than 55% of linear computations without requiring model retraining. To further enhance generality and efficiency, we propose Outstanding-sparse, a unified framework that integrates Amber Pruner with post-training W8A8 quantization. Our approach preserves strong performance across a range of downstream tasks, with notable advantages in generative tasks. This work pioneers a new frontier in activation sparsity, providing foundational insights that are poised to guide the co-evolution of algorithms and architectures in the design of next-generation AI systems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02128v1",
    "published_date": "2025-08-04 07:22:36 UTC",
    "updated_date": "2025-08-04 07:22:36 UTC"
  },
  {
    "arxiv_id": "2508.02124v6",
    "title": "Trainable Dynamic Mask Sparse Attention",
    "authors": [
      "Jingze Shi",
      "Yifan Wu",
      "Yiran Peng",
      "Bingheng Wu",
      "Liangdong Wang",
      "Guang Liu",
      "Yuyu Luo"
    ],
    "abstract": "The increasing demand for long-context modeling in large language models (LLMs) is bottlenecked by the quadratic complexity of the standard self-attention mechanism. The community has proposed sparse attention to mitigate this issue. However, position-aware sparse attention methods rely on static sparse structures that lack adaptability to diverse query contexts, while content-aware sparse attention methods depend on heuristic key-value selection, hindering full differentiability. We introduce a trainable dynamic mask sparse attention mechanism, a method that merges the advantages of both position-aware and content-aware approaches. Dynamic Mask Attention (DMA) achieves this through three key innovations: First, it leverages value vector representations to generate content-aware dynamic masks, enabling the model to adaptively identify and attend to critical information. Second, it computes position-aware sparse weights in a hardware-friendly manner, efficiently skipping unnecessary computational regions. Finally, we demonstrate that the introduced dynamic mask and sparse weights do not obstruct gradients, supporting end-to-end training. We have validated the performance of DMA through comprehensive experiments. A large body of experimental evidence shows that DMA consistently holds a Pareto advantage over state-of-the-art sparse attention baselines in tasks including scaling laws, multi-query associative recall, standard benchmarks, and needle in a haystack tests, while also delivering up to a 10x overall speedup. These results highlight its ability to effectively balance model efficiency with long-context modeling capabilities. Our computational kernel code is now open-source at https://github.com/SmallDoges/flash-dmattn to encourage further research and application by the community.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "26 pages",
    "pdf_url": "https://arxiv.org/pdf/2508.02124v6",
    "published_date": "2025-08-04 07:05:15 UTC",
    "updated_date": "2025-11-16 16:50:12 UTC"
  },
  {
    "arxiv_id": "2508.02121v1",
    "title": "A Survey on AgentOps: Categorization, Challenges, and Future Directions",
    "authors": [
      "Zexin Wang",
      "Jingjing Li",
      "Quan Zhou",
      "Haotian Si",
      "Yuanhao Liu",
      "Jianhui Li",
      "Gaogang Xie",
      "Fei Sun",
      "Dan Pei",
      "Changhua Pei"
    ],
    "abstract": "As the reasoning capabilities of Large Language Models (LLMs) continue to advance, LLM-based agent systems offer advantages in flexibility and interpretability over traditional systems, garnering increasing attention. However, despite the widespread research interest and industrial application of agent systems, these systems, like their traditional counterparts, frequently encounter anomalies. These anomalies lead to instability and insecurity, hindering their further development. Therefore, a comprehensive and systematic approach to the operation and maintenance of agent systems is urgently needed. Unfortunately, current research on the operations of agent systems is sparse. To address this gap, we have undertaken a survey on agent system operations with the aim of establishing a clear framework for the field, defining the challenges, and facilitating further development. Specifically, this paper begins by systematically defining anomalies within agent systems, categorizing them into intra-agent anomalies and inter-agent anomalies. Next, we introduce a novel and comprehensive operational framework for agent systems, dubbed Agent System Operations (AgentOps). We provide detailed definitions and explanations of its four key stages: monitoring, anomaly detection, root cause analysis, and resolution.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "35 pages",
    "pdf_url": "https://arxiv.org/pdf/2508.02121v1",
    "published_date": "2025-08-04 06:59:36 UTC",
    "updated_date": "2025-08-04 06:59:36 UTC"
  },
  {
    "arxiv_id": "2508.02120v1",
    "title": "Don't Overthink It: A Survey of Efficient R1-style Large Reasoning Models",
    "authors": [
      "Linan Yue",
      "Yichao Du",
      "Yizhi Wang",
      "Weibo Gao",
      "Fangzhou Yao",
      "Li Wang",
      "Ye Liu",
      "Ziyu Xu",
      "Qi Liu",
      "Shimin Di",
      "Min-Ling Zhang"
    ],
    "abstract": "Recently, Large Reasoning Models (LRMs) have gradually become a research hotspot due to their outstanding performance in handling complex tasks. Among them, DeepSeek R1 has garnered significant attention for its exceptional performance and open-source nature, driving advancements in the research of R1-style LRMs. Unlike traditional Large Language Models (LLMs), these models enhance logical deduction and decision-making capabilities during reasoning by incorporating mechanisms such as long chain-of-thought and self-reflection through reinforcement learning. However, with the widespread application of these models, the problem of overthinking has gradually emerged. Specifically, when generating answers, these models often construct excessively long reasoning chains with redundant or repetitive steps, which leads to reduced reasoning efficiency and may affect the accuracy of the final answer. To this end, various efficient reasoning methods have been proposed, aiming to reduce the length of reasoning paths without compromising model performance and reasoning capability. By reviewing the current research advancements in the field of efficient reasoning methods systematically, we categorize existing works into two main directions based on the lens of single-model optimization versus model collaboration: (1) Efficient Reasoning with Single Model, which focuses on improving the reasoning efficiency of individual models; and (2) Efficient Reasoning with Model Collaboration, which explores optimizing reasoning paths through collaboration among multiple models. Besides, we maintain a public GitHub repository that tracks the latest progress in efficient reasoning methods.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02120v1",
    "published_date": "2025-08-04 06:54:31 UTC",
    "updated_date": "2025-08-04 06:54:31 UTC"
  },
  {
    "arxiv_id": "2508.02115v3",
    "title": "Coward: Collision-based Watermark for Proactive Federated Backdoor Detection",
    "authors": [
      "Wenjie Li",
      "Siying Gu",
      "Yiming Li",
      "Kangjie Chen",
      "Zhili Chen",
      "Tianwei Zhang",
      "Shu-Tao Xia",
      "Dacheng Tao"
    ],
    "abstract": "Backdoor detection is currently the mainstream defense against backdoor attacks in federated learning (FL), where a small number of malicious clients can upload poisoned updates to compromise the federated global model. Existing backdoor detection techniques fall into two categories, passive and proactive, depending on whether the server proactively intervenes in the training process. However, both of them have inherent limitations in practice: passive detection methods are disrupted by common non-i.i.d. data distributions and random participation of FL clients, whereas current proactive detection methods are misled by an inevitable out-of-distribution (OOD) bias because they rely on backdoor coexistence effects. To address these issues, we introduce a novel proactive detection method dubbed Coward, inspired by our discovery of multi-backdoor collision effects, in which consecutively planted, distinct backdoors significantly suppress earlier ones. Correspondingly, we modify the federated global model by injecting a carefully designed backdoor-collided watermark, implemented via regulated dual-mapping learning on OOD data. This design not only enables an inverted detection paradigm compared to existing proactive methods, thereby naturally counteracting the adverse impact of OOD prediction bias, but also introduces a low-disruptive training intervention that inherently limits the strength of OOD bias, leading to significantly fewer misjudgments. Extensive experiments on benchmark datasets show that Coward achieves state-of-the-art detection performance, effectively alleviates OOD prediction bias, and remains robust against potential adaptive attacks. The code for our method is available at https://github.com/still2009/cowardFL.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "13-page main body and 4-page appendix. Currently under review",
    "pdf_url": "https://arxiv.org/pdf/2508.02115v3",
    "published_date": "2025-08-04 06:51:33 UTC",
    "updated_date": "2026-01-05 13:45:47 UTC"
  },
  {
    "arxiv_id": "2508.02110v2",
    "title": "Attractive Metadata Attack: Inducing LLM Agents to Invoke Malicious Tools",
    "authors": [
      "Kanghua Mo",
      "Li Hu",
      "Yucheng Long",
      "Zhihao Li"
    ],
    "abstract": "Large language model (LLM) agents have demonstrated remarkable capabilities in complex reasoning and decision-making by leveraging external tools. However, this tool-centric paradigm introduces a previously underexplored attack surface, where adversaries can manipulate tool metadata -- such as names, descriptions, and parameter schemas -- to influence agent behavior. We identify this as a new and stealthy threat surface that allows malicious tools to be preferentially selected by LLM agents, without requiring prompt injection or access to model internals. To demonstrate and exploit this vulnerability, we propose the Attractive Metadata Attack (AMA), a black-box in-context learning framework that generates highly attractive but syntactically and semantically valid tool metadata through iterative optimization. The proposed attack integrates seamlessly into standard tool ecosystems and requires no modification to the agent's execution framework. Extensive experiments across ten realistic, simulated tool-use scenarios and a range of popular LLM agents demonstrate consistently high attack success rates (81\\%-95\\%) and significant privacy leakage, with negligible impact on primary task execution. Moreover, the attack remains effective even against prompt-level defenses, auditor-based detection, and structured tool-selection protocols such as the Model Context Protocol, revealing systemic vulnerabilities in current agent architectures. These findings reveal that metadata manipulation constitutes a potent and stealthy attack surface. Notably, AMA is orthogonal to injection attacks and can be combined with them to achieve stronger attack efficacy, highlighting the need for execution-level defenses beyond prompt-level and auditor-based mechanisms. Code is available at https://github.com/SEAIC-M/AMA.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to NeurIPS 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.02110v2",
    "published_date": "2025-08-04 06:38:59 UTC",
    "updated_date": "2026-01-07 07:28:14 UTC"
  },
  {
    "arxiv_id": "2508.02766v1",
    "title": "The Silicon Reasonable Person: Can AI Predict How Ordinary People Judge Reasonableness?",
    "authors": [
      "Yonathan A. Arbel"
    ],
    "abstract": "In everyday life, people make countless reasonableness judgments that determine appropriate behavior in various contexts. Predicting these judgments challenges the legal system, as judges' intuitions may not align with broader societal views. This Article investigates whether large language models (LLMs) can learn to identify patterns driving human reasonableness judgments.\n  Using randomized controlled trials comparing humans and models across multiple legal contexts with over 10,000 simulated judgments, we demonstrate that certain models capture not just surface-level responses but potentially their underlying decisional architecture. Strikingly, these systems prioritize social cues over economic efficiency in negligence determinations, mirroring human behavior despite contradicting textbook treatments.\n  These findings suggest practical applications: judges could calibrate intuitions against broader patterns, lawmakers could test policy interpretations, and resource-constrained litigants could preview argument reception. As AI agents increasingly make autonomous real-world decisions, understanding whether they've internalized recognizable ethical frameworks becomes essential for anticipating their behavior.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "45 pages, 8 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.02766v1",
    "published_date": "2025-08-04 06:19:45 UTC",
    "updated_date": "2025-08-04 06:19:45 UTC"
  },
  {
    "arxiv_id": "2508.02096v2",
    "title": "Evaluating User Experience in Conversational Recommender Systems: A Systematic Review Across Classical and LLM-Powered Approaches",
    "authors": [
      "Raj Mahmud",
      "Yufeng Wu",
      "Abdullah Bin Sawad",
      "Shlomo Berkovsky",
      "Mukesh Prasad",
      "A. Baki Kocaballi"
    ],
    "abstract": "Conversational Recommender Systems (CRSs) are receiving growing research attention across domains, yet their user experience (UX) evaluation remains limited. Existing reviews largely overlook empirical UX studies, particularly in adaptive and large language model (LLM)-based CRSs. To address this gap, we conducted a systematic review following PRISMA guidelines, synthesising 23 empirical studies published between 2017 and 2025. We analysed how UX has been conceptualised, measured, and shaped by domain, adaptivity, and LLM. Our findings reveal persistent limitations: post hoc surveys dominate, turn-level affective UX constructs are rarely assessed, and adaptive behaviours are seldom linked to UX outcomes. LLM-based CRSs introduce further challenges, including epistemic opacity and verbosity, yet evaluations infrequently address these issues. We contribute a structured synthesis of UX metrics, a comparative analysis of adaptive and nonadaptive systems, and a forward-looking agenda for LLM-aware UX evaluation. These findings support the development of more transparent, engaging, and user-centred CRS evaluation practices.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted at OzCHI 2025. 23 pages, 1 figure, 5 tables",
    "pdf_url": "https://arxiv.org/pdf/2508.02096v2",
    "published_date": "2025-08-04 06:07:33 UTC",
    "updated_date": "2025-08-06 07:55:11 UTC"
  },
  {
    "arxiv_id": "2508.02095v2",
    "title": "VLM4D: Towards Spatiotemporal Awareness in Vision Language Models",
    "authors": [
      "Shijie Zhou",
      "Alexander Vilesov",
      "Xuehai He",
      "Ziyu Wan",
      "Shuwang Zhang",
      "Aditya Nagachandra",
      "Di Chang",
      "Dongdong Chen",
      "Xin Eric Wang",
      "Achuta Kadambi"
    ],
    "abstract": "Vision language models (VLMs) have shown remarkable capabilities in integrating linguistic and visual reasoning but remain fundamentally limited in understanding dynamic spatiotemporal interactions. Humans effortlessly track and reason about object movements, rotations, and perspective shifts-abilities essential for robust dynamic real-world understanding yet notably lacking in current VLMs. In this paper, we introduce VLM4D, the first benchmark specifically designed to evaluate the spatiotemporal reasoning capabilities of VLMs. Our benchmark comprises diverse real-world and synthetic videos accompanied by carefully curated question-answer pairs emphasizing translational and rotational motions, perspective awareness, and motion continuity. Through comprehensive evaluations of state-of-the-art open and closed-source VLMs, we identify significant performance gaps compared to human baselines, highlighting fundamental deficiencies in existing models. Extensive analysis reveals that VLMs struggle particularly with integrating multiple visual cues and maintaining temporal coherence. We further explore promising directions, such as leveraging 4D feature field reconstruction and targeted spatiotemporal supervised fine-tuning, demonstrating their effectiveness in enhancing spatiotemporal comprehension. Our work aims to encourage deeper exploration into improving VLMs' spatial and temporal grounding, paving the way towards more capable and reliable visual intelligence for dynamic environments.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "ICCV 2025, Project Website: https://vlm4d.github.io/",
    "pdf_url": "https://arxiv.org/pdf/2508.02095v2",
    "published_date": "2025-08-04 06:06:06 UTC",
    "updated_date": "2025-08-06 19:21:50 UTC"
  },
  {
    "arxiv_id": "2508.02093v1",
    "title": "\"Stack It Up!\": 3D Stable Structure Generation from 2D Hand-drawn Sketch",
    "authors": [
      "Yiqing Xu",
      "Linfeng Li",
      "Cunjun Yu",
      "David Hsu"
    ],
    "abstract": "Imagine a child sketching the Eiffel Tower and asking a robot to bring it to life. Today's robot manipulation systems can't act on such sketches directly-they require precise 3D block poses as goals, which in turn demand structural analysis and expert tools like CAD. We present StackItUp, a system that enables non-experts to specify complex 3D structures using only 2D front-view hand-drawn sketches. StackItUp introduces an abstract relation graph to bridge the gap between rough sketches and accurate 3D block arrangements, capturing the symbolic geometric relations (e.g., left-of) and stability patterns (e.g., two-pillar-bridge) while discarding noisy metric details from sketches. It then grounds this graph to 3D poses using compositional diffusion models and iteratively updates it by predicting hidden internal and rear supports-critical for stability but absent from the sketch. Evaluated on sketches of iconic landmarks and modern house designs, StackItUp consistently produces stable, multilevel 3D structures and outperforms all baselines in both stability and visual resemblance.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to CoRL 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.02093v1",
    "published_date": "2025-08-04 06:04:35 UTC",
    "updated_date": "2025-08-04 06:04:35 UTC"
  },
  {
    "arxiv_id": "2508.02092v2",
    "title": "FPEdit: Robust LLM Fingerprinting through Localized Parameter Editing",
    "authors": [
      "Shida Wang",
      "Chaohu Liu",
      "Yubo Wang",
      "Linli Xu"
    ],
    "abstract": "Large language models represent significant investments in computation, data, and engineering expertise, making them extraordinarily valuable intellectual assets. Nevertheless, these AI assets remain vulnerable to unauthorized redistribution and commercial exploitation through fine-tuning or black-box deployment. Current fingerprinting approaches face a fundamental trade-off: intrinsic methods require full parameter access, while backdoor-based techniques employ statistically anomalous triggers easily detected and filtered by adversaries. To address these limitations, we introduce FPEdit, a novel framework that leverages knowledge editing to inject semantically coherent natural language fingerprints through sparse, targeted modifications to model weights. Our approach introduces Promote-Suppress Value Vector Optimization, which simultaneously enhances target token likelihood while suppressing competing tokens, ensuring robust fingerprint integration without degrading core model functionality. Extensive experiments show that FPEdit achieves 95-100% fingerprint retention under both full-parameter fine-tuning and parameter-efficient adaptation, while preserving performance on downstream benchmarks. Moreover, FPEdit remains robust under quantization, pruning, and stochastic decoding, and can embed 10 fingerprint pairs into LLaMA2-7B in under 2 minutes using less than 30 GB of GPU memory, which represents a substantial reduction in resource requirements. These advances establish FPEdit as the first fingerprinting approach to simultaneously achieve robustness against adaptation, resistance to detection, and preservation of model utility, thereby providing a minimally invasive solution for reliable provenance verification of large language models in adversarial deployment scenarios.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02092v2",
    "published_date": "2025-08-04 06:00:22 UTC",
    "updated_date": "2025-10-17 08:53:43 UTC"
  },
  {
    "arxiv_id": "2508.02091v2",
    "title": "CRINN: Contrastive Reinforcement Learning for Approximate Nearest Neighbor Search",
    "authors": [
      "Xiaoya Li",
      "Xiaofei Sun",
      "Albert Wang",
      "Chris Shum",
      "Jiwei Li"
    ],
    "abstract": "Approximate nearest-neighbor search (ANNS) algorithms have become increasingly critical for recent AI applications, particularly in retrieval-augmented generation (RAG) and agent-based LLM applications. In this paper, we present CRINN, a new paradigm for ANNS algorithms. CRINN treats ANNS optimization as a reinforcement learning problem where execution speed serves as the reward signal. This approach enables the automatic generation of progressively faster ANNS implementations while maintaining accuracy constraints. Our experimental evaluation demonstrates CRINN's effectiveness across six widely-used NNS benchmark datasets. When compared against state-of-the-art open-source ANNS algorithms, CRINN achieves best performance on three of them (GIST-960-Euclidean, MNIST-784-Euclidean, and GloVe-25-angular), and tied for first place on two of them (SIFT-128-Euclidean and GloVe-25-angular). The implications of CRINN's success reach well beyond ANNS optimization: It validates that LLMs augmented with reinforcement learning can function as an effective tool for automating sophisticated algorithmic optimizations that demand specialized knowledge and labor-intensive manual refinement. Code can be found at https://github.com/deepreinforce-ai/CRINN",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.DB"
    ],
    "primary_category": "cs.LG",
    "comment": "Preprint Version",
    "pdf_url": "https://arxiv.org/pdf/2508.02091v2",
    "published_date": "2025-08-04 05:57:46 UTC",
    "updated_date": "2025-08-20 01:47:01 UTC"
  },
  {
    "arxiv_id": "2508.02084v1",
    "title": "SSBD Ontology: A Two-Tier Approach for Interoperable Bioimaging Metadata",
    "authors": [
      "Yuki Yamagata",
      "Koji Kyoda",
      "Hiroya Itoga",
      "Emi Fujisawa",
      "Shuichi Onami"
    ],
    "abstract": "Advanced bioimaging technologies have enabled the large-scale acquisition of multidimensional data, yet effective metadata management and interoperability remain significant challenges. To address these issues, we propose a new ontology-driven framework for the Systems Science of Biological Dynamics Database (SSBD) that adopts a two-tier architecture. The core layer provides a class-centric structure referencing existing biomedical ontologies, supporting both SSBD:repository -- which focuses on rapid dataset publication with minimal metadata -- and SSBD:database, which is enhanced with biological and imaging-related annotations. Meanwhile, the instance layer represents actual imaging dataset information as Resource Description Framework individuals that are explicitly linked to the core classes. This layered approach aligns flexible instance data with robust ontological classes, enabling seamless integration and advanced semantic queries. By coupling flexibility with rigor, the SSBD Ontology promotes interoperability, data reuse, and the discovery of novel biological mechanisms. Moreover, our solution aligns with the Recommended Metadata for Biological Images guidelines and fosters compatibility. Ultimately, our approach contributes to establishing a Findable, Accessible, Interoperable, and Reusable data ecosystem within the bioimaging community.",
    "categories": [
      "cs.DL",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.DL",
    "comment": "Accepted to the 24th International Semantic Web Conference Resource Track (ISWC 2025)",
    "pdf_url": "https://arxiv.org/pdf/2508.02084v1",
    "published_date": "2025-08-04 05:51:55 UTC",
    "updated_date": "2025-08-04 05:51:55 UTC"
  },
  {
    "arxiv_id": "2508.02085v6",
    "title": "SE-Agent: Self-Evolution Trajectory Optimization in Multi-Step Reasoning with LLM-Based Agents",
    "authors": [
      "Jiaye Lin",
      "Yifu Guo",
      "Yuzhen Han",
      "Sen Hu",
      "Ziyi Ni",
      "Licheng Wang",
      "Mingguang Chen",
      "Hongzhang Liu",
      "Ronghao Chen",
      "Yangfan He",
      "Daxin Jiang",
      "Binxing Jiao",
      "Chen Hu",
      "Huacan Wang"
    ],
    "abstract": "Large Language Model (LLM)-based agents have recently shown impressive capabilities in complex reasoning and tool use via multi-step interactions with their environments. While these agents have the potential to tackle complicated tasks, their problem-solving process, i.e., agents' interaction trajectory leading to task completion, remains underexploited. These trajectories contain rich feedback that can navigate agents toward the right directions for solving problems correctly. Although prevailing approaches, such as Monte Carlo Tree Search (MCTS), can effectively balance exploration and exploitation, they ignore the interdependence among various trajectories and lack the diversity of search spaces, which leads to redundant reasoning and suboptimal outcomes. To address these challenges, we propose SE-Agent, a Self-Evolution framework that enables Agents to optimize their reasoning processes iteratively. Our approach revisits and enhances former pilot trajectories through three key operations: revision, recombination, and refinement. This evolutionary mechanism enables two critical advantages: (1) it expands the search space beyond local optima by intelligently exploring diverse solution paths guided by previous trajectories, and (2) it leverages cross-trajectory inspiration to efficiently enhance performance while mitigating the impact of suboptimal reasoning paths. Through these mechanisms, SE-Agent achieves continuous self-evolution that incrementally improves reasoning quality. We evaluate SE-Agent on SWE-bench Verified to resolve real-world GitHub issues. Experimental results across five strong LLMs show that integrating SE-Agent delivers up to 55% relative improvement, achieving state-of-the-art performance among all open-source agents on SWE-bench Verified. Our code and demonstration materials are publicly available at https://github.com/JARVIS-Xs/SE-Agent.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02085v6",
    "published_date": "2025-08-04 05:51:55 UTC",
    "updated_date": "2025-11-03 18:47:32 UTC"
  },
  {
    "arxiv_id": "2508.02079v1",
    "title": "AlignGuard-LoRA: Alignment-Preserving Fine-Tuning via Fisher-Guided Decomposition and Riemannian-Geodesic Collision Regularization",
    "authors": [
      "Amitava Das",
      "Abhilekh Borah",
      "Vinija Jain",
      "Aman Chadha"
    ],
    "abstract": "Low-rank adaptation (LoRA) has become a standard tool for efficiently fine-tuning large language models (LLMs). Yet, even minor LoRA updates can induce alignment drift, weakening safety and behavioral constraints through entangled parameter changes. To address this, we propose AlignGuard-LoRA (AGL), a principled framework for preserving alignment during finetuning. AGL introduces several key components: a primary task loss for supervision, Fisher Information Matrix-based regularization to restrict updates in alignment-sensitive subspaces, and task-specific regularization to stabilize the integration of new knowledge. We further introduce collision-aware regularization, blending Riemannian overlap -- which penalizes coordinate-wise interference -- and geodesic separation -- which encourages disjoint update geometry. We curate DriftCaps, a targeted diagnostic benchmark of safe and unsafe prompts designed to quantify alignment drift and safety degradation. Empirical evaluations show that AGL mitigates alignment drift by up to 50% on safety-critical benchmarks without degrading downstream task performance. Comprehensive ablation confirms that each component contributes distinctly to preserving latent safety behaviors. Finally, we derive and validate a scaling law for catastrophic forgetting, revealing that AGL flattens post-finetuning loss escalation while preserving adaptation dynamics. AGL is a structurally grounded refinement of LoRA, ensuring alignment preservation with minimal trade-offs. To encourage further exploration and development, we open-source our implementation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02079v1",
    "published_date": "2025-08-04 05:45:24 UTC",
    "updated_date": "2025-08-04 05:45:24 UTC"
  },
  {
    "arxiv_id": "2508.03752v1",
    "title": "M$^3$HL: Mutual Mask Mix with High-Low Level Feature Consistency for Semi-Supervised Medical Image Segmentation",
    "authors": [
      "Yajun Liu",
      "Zenghui Zhang",
      "Jiang Yue",
      "Weiwei Guo",
      "Dongying Li"
    ],
    "abstract": "Data augmentation methods inspired by CutMix have demonstrated significant potential in recent semi-supervised medical image segmentation tasks. However, these approaches often apply CutMix operations in a rigid and inflexible manner, while paying insufficient attention to feature-level consistency constraints. In this paper, we propose a novel method called Mutual Mask Mix with High-Low level feature consistency (M$^3$HL) to address the aforementioned challenges, which consists of two key components: 1) M$^3$: An enhanced data augmentation operation inspired by the masking strategy from Masked Image Modeling (MIM), which advances conventional CutMix through dynamically adjustable masks to generate spatially complementary image pairs for collaborative training, thereby enabling effective information fusion between labeled and unlabeled images. 2) HL: A hierarchical consistency regularization framework that enforces high-level and low-level feature consistency between unlabeled and mixed images, enabling the model to better capture discriminative feature representations.Our method achieves state-of-the-art performance on widely adopted medical image segmentation benchmarks including the ACDC and LA datasets. Source code is available at https://github.com/PHPJava666/M3HL",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "MICCAI 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.03752v1",
    "published_date": "2025-08-04 05:42:10 UTC",
    "updated_date": "2025-08-04 05:42:10 UTC"
  },
  {
    "arxiv_id": "2508.02076v1",
    "title": "Everyone Contributes! Incentivizing Strategic Cooperation in Multi-LLM Systems via Sequential Public Goods Games",
    "authors": [
      "Yunhao Liang",
      "Yuan Qu",
      "Jingyuan Yang",
      "Shaochong Lin",
      "Zuo-Jun Max Shen"
    ],
    "abstract": "Coordinating multiple large language models (LLMs) to solve complex tasks collaboratively poses a fundamental trade-off between the computation costs and collective performance compared with individual model. We introduce a novel, game-theoretically grounded reinforcement learning (RL) framework, the Multi-Agent Cooperation Sequential Public Goods Game (MAC-SPGG), to systematically incentivize cooperation in multi-LLM ensembles. In MAC-SPGG, LLM agents move in sequence, observing predecessors' outputs and updating beliefs to condition their own contributions. By redesigning the public-goods reward, effortful contributions become the unique Subgame Perfect Nash Equilibrium (SPNE), which eliminates free-riding under traditional SPGG or PGG. Its sequential protocol replaces costly round-based information exchanges with a streamlined decision flow, cutting communication overhead while retaining strategic depth. We prove the existence and uniqueness of the SPNE under realistic parameters, and empirically show that MAC-SPGG-trained ensembles outperform single-agent baselines, chain-of-thought prompting, and other cooperative methods, even achieving comparable performance to large-scale models across reasoning, math, code generation, and NLP tasks. Our results highlight the power of structured, incentive-aligned MAC-SPGG cooperation for scalable and robust multi-agent language generation.",
    "categories": [
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02076v1",
    "published_date": "2025-08-04 05:36:07 UTC",
    "updated_date": "2025-08-04 05:36:07 UTC"
  },
  {
    "arxiv_id": "2508.02073v2",
    "title": "Large model retrieval enhancement framework for construction site risk identification",
    "authors": [
      "Jiawei Li",
      "Chengye Yang",
      "Yaochen Zhang",
      "Weilin Sun",
      "Lei Meng",
      "Xiangxu Meng"
    ],
    "abstract": "This study addresses construction site hazard identification by proposing a retrieval-augmented framework that enhances large language models (LLMs) without requiring fine-tuning. Current LLM-based approaches face limitations: image-text matching struggles with complex hazards, while instruction tuning lacks generalization and is resource-intensive. Our method dynamically integrates external knowledge and retrieved similar cases via prompt tuning, overcoming LLMs' limitations in domain knowledge and feature correlation. The framework comprises a case database, an image retrieval module, and an LLM-based reasoning module. Evaluated on real-site data, our approach boosted GLM-4V's accuracy to 50%, a 35.49% improvement over baselines, with consistent gains across hazard types. Ablation studies validated the effectiveness of our image retrieval strategy, showing the superiority of our LPIPS- and CLIP-based method. The proposed technique significantly improves identification accuracy and contextual understanding, demonstrating strong generalization and offering a practical path for intelligent safety risk detection in construction.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "in Chinese language",
    "pdf_url": "https://arxiv.org/pdf/2508.02073v2",
    "published_date": "2025-08-04 05:28:58 UTC",
    "updated_date": "2025-11-08 17:17:26 UTC"
  },
  {
    "arxiv_id": "2508.02765v1",
    "title": "The Architecture of Trust: A Framework for AI-Augmented Real Estate Valuation in the Era of Structured Data",
    "authors": [
      "Petteri Teikari",
      "Mike Jarrell",
      "Maryam Azh",
      "Harri Pesola"
    ],
    "abstract": "The Uniform Appraisal Dataset (UAD) 3.6's mandatory 2026 implementation transforms residential property valuation from narrative reporting to structured, machine-readable formats. This paper provides the first comprehensive analysis of this regulatory shift alongside concurrent AI advances in computer vision, natural language processing, and autonomous systems. We develop a three-layer framework for AI-augmented valuation addressing technical implementation and institutional trust requirements. Our analysis reveals how regulatory standardization converging with AI capabilities enables fundamental market restructuring with profound implications for professional practice, efficiency, and systemic risk. We make four key contributions: (1) documenting institutional failures including inter-appraiser variability and systematic biases undermining valuation reliability; (2) developing an architectural framework spanning physical data acquisition, semantic understanding, and cognitive reasoning that integrates emerging technologies while maintaining professional oversight; (3) addressing trust requirements for high-stakes financial applications including regulatory compliance, algorithmic fairness, and uncertainty quantification; (4) proposing evaluation methodologies beyond generic AI benchmarks toward domain-specific protocols. Our findings indicate successful transformation requires not merely technological sophistication but careful human-AI collaboration, creating systems that augment rather than replace professional expertise while addressing historical biases and information asymmetries in real estate markets.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CY",
    "comment": "46 pages, 6 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.02765v1",
    "published_date": "2025-08-04 05:24:25 UTC",
    "updated_date": "2025-08-04 05:24:25 UTC"
  },
  {
    "arxiv_id": "2508.09152v1",
    "title": "5G Core Fault Detection and Root Cause Analysis using Machine Learning and Generative AI",
    "authors": [
      "Joseph H. R. Isaac",
      "Harish Saradagam",
      "Nallamothu Pardhasaradhi"
    ],
    "abstract": "With the advent of 5G networks and technologies, ensuring the integrity and performance of packet core traffic is paramount. During network analysis, test files such as Packet Capture (PCAP) files and log files will contain errors if present in the system that must be resolved for better overall network performance, such as connectivity strength and handover quality. Current methods require numerous person-hours to sort out testing results and find the faults. This paper presents a novel AI/ML-driven Fault Analysis (FA) Engine designed to classify successful and faulty frames in PCAP files, specifically within the 5G packet core. The FA engine analyses network traffic using natural language processing techniques to identify anomalies and inefficiencies, significantly reducing the effort time required and increasing efficiency. The FA Engine also suggests steps to fix the issue using Generative AI via a Large Language Model (LLM) trained on several 5G packet core documents. The engine explains the details of the error from the domain perspective using documents such as the 3GPP standards and user documents regarding the internal conditions of the tests. Test results on the ML models show high classification accuracy on the test dataset when trained with 80-20 splits for the successful and failed PCAP files. Future scopes include extending the AI engine to incorporate 4G network traffic and other forms of network data, such as log text files and multimodal systems.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NI",
    "comment": "8 pages, 3 figures and 2 tables. Accepted in Conference on Advances in Communication Networks & Systems (CoaCoNS 2025)",
    "pdf_url": "https://arxiv.org/pdf/2508.09152v1",
    "published_date": "2025-08-04 05:20:32 UTC",
    "updated_date": "2025-08-04 05:20:32 UTC"
  },
  {
    "arxiv_id": "2508.02069v2",
    "title": "SpikeSTAG: Spatial-Temporal Forecasting via GNN-SNN Collaboration",
    "authors": [
      "Bang Hu",
      "Changze Lv",
      "Mingjie Li",
      "Yunpeng Liu",
      "Xiaoqing Zheng",
      "Fengzhe Zhang",
      "Wei cao",
      "Fan Zhang"
    ],
    "abstract": "Spiking neural networks (SNNs), inspired by the spiking behavior of biological neurons, offer a distinctive approach for capturing the complexities of temporal data. However, their potential for spatial modeling in multivariate time-series forecasting remains largely unexplored. To bridge this gap, we introduce a brand new SNN architecture, which is among the first to seamlessly integrate graph structural learning with spike-based temporal processing for multivariate time-series forecasting. Specifically, we first embed time features and an adaptive matrix, eliminating the need for predefined graph structures. We then further learn sequence features through the Observation (OBS) Block. Building upon this, our Multi-Scale Spike Aggregation (MSSA) hierarchically aggregates neighborhood information through spiking SAGE layers, enabling multi-hop feature extraction while eliminating the need for floating-point operations. Finally, we propose a Dual-Path Spike Fusion (DSF) Block to integrate spatial graph features and temporal dynamics via a spike-gated mechanism, combining LSTM-processed sequences with spiking self-attention outputs, effectively improve the model accuracy of long sequence datasets. Experiments show that our model surpasses the state-of-the-art SNN-based iSpikformer on all datasets and outperforms traditional temporal models at long horizons, thereby establishing a new paradigm for efficient spatial-temporal modeling.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 4 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.02069v2",
    "published_date": "2025-08-04 05:17:52 UTC",
    "updated_date": "2025-08-18 05:48:23 UTC"
  },
  {
    "arxiv_id": "2508.02066v1",
    "title": "MolReasoner: Toward Effective and Interpretable Reasoning for Molecular LLMs",
    "authors": [
      "Guojiang Zhao",
      "Sihang Li",
      "Zixiang Lu",
      "Zheng Cheng",
      "Haitao Lin",
      "Lirong Wu",
      "Hanchen Xia",
      "Hengxing Cai",
      "Wentao Guo",
      "Hongshuai Wang",
      "Mingjun Xu",
      "Siyu Zhu",
      "Guolin Ke",
      "Linfeng Zhang",
      "Zhifeng Gao"
    ],
    "abstract": "Large Language Models(LLMs) have demonstrated remarkable performance across various domains, yet their capabilities in molecular reasoning remain insufficiently explored. Current approaches tend to rely heavily on general-purpose prompting, which lacks domain-specific molecular semantics, while those that use fine-tuning strategies often face challenges with interpretability and reasoning depth. To address these issues, we introduce MolReasoner, a two-stage framework designed to transition LLMs from memorization towards chemical reasoning. First, we propose Mol-SFT, which initializes the model's reasoning abilities via synthetic Chain-of-Thought(CoT) samples generated by GPT-4o and verified for chemical accuracy. Subsequently, Mol-RL applies reinforcement learning with specialized reward functions designed explicitly to align chemical structures with linguistic descriptions, thereby enhancing molecular reasoning capabilities. Our approach notably enhances interpretability, improving the model 's molecular understanding and enabling better generalization. Extensive experiments demonstrate that MolReasoner outperforms existing methods, and marking a significant shift from memorization-based outputs to robust chemical reasoning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02066v1",
    "published_date": "2025-08-04 05:10:11 UTC",
    "updated_date": "2025-08-04 05:10:11 UTC"
  },
  {
    "arxiv_id": "2508.02063v1",
    "title": "TRACEALIGN -- Tracing the Drift: Attributing Alignment Failures to Training-Time Belief Sources in LLMs",
    "authors": [
      "Amitava Das",
      "Vinija Jain",
      "Aman Chadha"
    ],
    "abstract": "Large Language Models (LLMs) fine-tuned to align with human values often exhibit alignment drift, producing unsafe or policy-violating completions when exposed to adversarial prompts, decoding perturbations, or paraphrased jailbreaks. While prior work has behaviorally characterized alignment failure, little is known about the training-time belief sources underlying these failures. We introduce TraceAlign, a unified framework for tracing unsafe completions back to their root causes in the model's training corpus. Central to our approach is the Belief Conflict Index (BCI), which quantifies semantic inconsistency between generated spans and aligned policies, based on retrieved training documents using suffix-array matching. We propose three complementary interventions: (i) TraceShield, an inference-time safety filter that refuses completions with high-BCI spans, (ii) Contrastive Belief Deconfliction Loss, a contrastive fine-tuning objective penalizing high-BCI continuations during DPO, and (iii) Prov-Decode, a provenance-aware decoding strategy that vetoes beam expansions predicted to yield high-BCI spans. Together, these defenses reduce alignment drift by up to 85% on our curated Alignment Drift Benchmark (ADB) while preserving utility on standard tasks, with delta less than 0.2 and improved refusal quality. We further derive a theoretical upper bound on drift likelihood via suffix-array span statistics, linking memorization frequency and length to adversarial reactivation risk. TraceAlign thus provides the first scalable, traceable, and grounded toolkit for understanding and mitigating alignment failures at source. To encourage further exploration and development, we open-source our implementation at: https://anonymous.4open.science/r/tracealign-2DA7",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02063v1",
    "published_date": "2025-08-04 05:03:35 UTC",
    "updated_date": "2025-08-04 05:03:35 UTC"
  },
  {
    "arxiv_id": "2508.02062v1",
    "title": "RICL: Adding In-Context Adaptability to Pre-Trained Vision-Language-Action Models",
    "authors": [
      "Kaustubh Sridhar",
      "Souradeep Dutta",
      "Dinesh Jayaraman",
      "Insup Lee"
    ],
    "abstract": "Multi-task ``vision-language-action'' (VLA) models have recently demonstrated increasing promise as generalist foundation models for robotics, achieving non-trivial performance out of the box on new tasks in new environments. However, for such models to be truly useful, an end user must have easy means to teach them to improve. For language and vision models, the emergent ability to perform in-context learning (ICL) has proven to be a versatile and highly useful interface to easily teach new tasks with no parameter finetuning. Unfortunately, VLAs pre-trained with imitation learning objectives do not naturally acquire ICL abilities. In this paper, we demonstrate that, with the right finetuning recipe and a small robot demonstration dataset, it is possible to inject in-context adaptability post hoc into such a VLA. After retraining for in-context learning (RICL), our system permits an end user to provide a small number (10-20) of demonstrations for a new task. RICL then fetches the most relevant portions of those demonstrations into the VLA context to exploit ICL, performing the new task and boosting task performance. We apply RICL to inject ICL into the $π_{0}$-FAST VLA, and show that it permits large in-context improvements for a variety of new manipulation tasks with only 20 demonstrations per task, without any parameter updates. When parameter updates on the target task demonstrations is possible, RICL finetuning further boosts performance. We release code and model weights for RICL-$π_{0}$-FAST alongside the paper to enable, for the first time, a simple in-context learning interface for new manipulation tasks. Website: https://ricl-vla.github.io.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Conference on Robot Learning 2025 (CoRL 2025), 17 pages",
    "pdf_url": "https://arxiv.org/pdf/2508.02062v1",
    "published_date": "2025-08-04 05:01:11 UTC",
    "updated_date": "2025-08-04 05:01:11 UTC"
  },
  {
    "arxiv_id": "2508.05669v1",
    "title": "Fine-Tuning Vision-Language Models for Markdown Conversion of Financial Tables in Malaysian Audited Financial Reports",
    "authors": [
      "Jin Khye Tan",
      "En Jun Choong",
      "Ethan Jeremiah Chitty",
      "Yan Pheng Choo",
      "John Hsin Yang Wong",
      "Chern Eu Cheah"
    ],
    "abstract": "Accurately extracting and representing the structure of tabular data from financial documents remains a critical challenge in document understanding, particularly for regulatory and analytical use cases. This study addresses the complexity of converting financial tables from Malaysian audited financial reports into Markdown format, a task complicated by rotated layouts, multi-level headers, and implicit structural cues. We propose a fine-tuned vision-language model (VLM), based on Qwen2.5-VL-7B, optimized for high-fidelity Markdown generation from document images. Our approach includes a curated dataset of 2,152 image-text pairs with augmentations and a supervised fine-tuning strategy using LoRA. To assess performance, we evaluated our model on 100 out-of-sample tables using a dual framework: a criteria-based LLM-as-a-judge for fine-grained accuracy and our novel Markdown Tree-Edit-Distance-based Similarity (TEDS) metric for holistic structural fidelity. Our model achieves a 92.20% overall accuracy on the criteria-based assessment and a 96.53% Markdown TEDS score. This performance significantly surpasses its Qwen2.5-VL-7B base model, larger-scale VLMs, and specialized reasoning-enabled models. Compared to these self-hosted alternatives, it also significantly reduces inference time. Furthermore, its accuracy exceeds that of widely used proprietary models such as OpenAI's GPT-4o and Gemini 2.5 Flash. These results demonstrate that domain-specific fine-tuning provides an effective and efficient method to bridge the gap between unstructured financial documents and downstream automation, rivalling much larger and more general models without their computational overhead.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "28 pages, 14 figures, 5 tables. Evaluation code (LLM-as-a-judge and Markdown TEDS) is available at https://github.com/jinkhye/MyFinMarkdown. The development dataset and evaluation benchmark are available on Hugging Face at https://huggingface.co/datasets/jinkhye/MyFinMarkdown-sample and https://huggingface.co/datasets/jinkhye/MyFinMarkdown-bench respectively",
    "pdf_url": "https://arxiv.org/pdf/2508.05669v1",
    "published_date": "2025-08-04 04:54:00 UTC",
    "updated_date": "2025-08-04 04:54:00 UTC"
  },
  {
    "arxiv_id": "2508.02054v1",
    "title": "Enhancement of Quantum Semi-Supervised Learning via Improved Laplacian and Poisson Methods",
    "authors": [
      "Hamed Gholipour",
      "Farid Bozorgnia",
      "Hamzeh Mohammadigheymasi",
      "Kailash Hambarde",
      "Javier Mancilla",
      "Hugo Proenca",
      "Joao Neves",
      "Moharram Challenger"
    ],
    "abstract": "This paper develops a hybrid quantum approach for graph-based semi-supervised learning to enhance performance in scenarios where labeled data is scarce. We introduce two enhanced quantum models, the Improved Laplacian Quantum Semi-Supervised Learning (ILQSSL) and the Improved Poisson Quantum Semi-Supervised Learning (IPQSSL), that incorporate advanced label propagation strategies within variational quantum circuits. These models utilize QR decomposition to embed graph structure directly into quantum states, thereby enabling more effective learning in low-label settings. We validate our methods across four benchmark datasets like Iris, Wine, Heart Disease, and German Credit Card -- and show that both ILQSSL and IPQSSL consistently outperform leading classical semi-supervised learning algorithms, particularly under limited supervision. Beyond standard performance metrics, we examine the effect of circuit depth and qubit count on learning quality by analyzing entanglement entropy and Randomized Benchmarking (RB). Our results suggest that while some level of entanglement improves the model's ability to generalize, increased circuit complexity may introduce noise that undermines performance on current quantum hardware. Overall, the study highlights the potential of quantum-enhanced models for semi-supervised learning, offering practical insights into how quantum circuits can be designed to balance expressivity and stability. These findings support the role of quantum machine learning in advancing data-efficient classification, especially in applications constrained by label availability and hardware limitations.",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "primary_category": "quant-ph",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02054v1",
    "published_date": "2025-08-04 04:45:02 UTC",
    "updated_date": "2025-08-04 04:45:02 UTC"
  },
  {
    "arxiv_id": "2508.02049v1",
    "title": "Epi$^2$-Net: Advancing Epidemic Dynamics Forecasting with Physics-Inspired Neural Networks",
    "authors": [
      "Rui Sun",
      "Chenghua Gong",
      "Tianjun Gu",
      "Yuhao Zheng",
      "Jie Ding",
      "Juyuan Zhang",
      "Liming Pan",
      "Linyuan Lü"
    ],
    "abstract": "Advancing epidemic dynamics forecasting is vital for targeted interventions and safeguarding public health. Current approaches mainly fall into two categories: mechanism-based and data-driven models. Mechanism-based models are constrained by predefined compartmental structures and oversimplified system assumptions, limiting their ability to model complex real-world dynamics, while data-driven models focus solely on intrinsic data dependencies without physical or epidemiological constraints, risking biased or misleading representations. Although recent studies have attempted to integrate epidemiological knowledge into neural architectures, most of them fail to reconcile explicit physical priors with neural representations. To overcome these obstacles, we introduce Epi$^2$-Net, a Epidemic Forecasting Framework built upon Physics-Inspired Neural Networks. Specifically, we propose reconceptualizing epidemic transmission from the physical transport perspective, introducing the concept of neural epidemic transport. Further, we present a physic-inspired deep learning framework, and integrate physical constraints with neural modules to model spatio-temporal patterns of epidemic dynamics. Experiments on real-world datasets have demonstrated that Epi$^2$-Net outperforms state-of-the-art methods in epidemic forecasting, providing a promising solution for future epidemic containment. The code is available at: https://anonymous.4open.science/r/Epi-2-Net-48CE.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02049v1",
    "published_date": "2025-08-04 04:32:18 UTC",
    "updated_date": "2025-08-04 04:32:18 UTC"
  },
  {
    "arxiv_id": "2508.02044v1",
    "title": "Graph Unlearning via Embedding Reconstruction -- A Range-Null Space Decomposition Approach",
    "authors": [
      "Hang Yin",
      "Zipeng Liu",
      "Xiaoyong Peng",
      "Liyao Xiang"
    ],
    "abstract": "Graph unlearning is tailored for GNNs to handle widespread and various graph structure unlearning requests, which remain largely unexplored. The GIF (graph influence function) achieves validity under partial edge unlearning, but faces challenges in dealing with more disturbing node unlearning. To avoid the overhead of retraining and realize the model utility of unlearning, we proposed a novel node unlearning method to reverse the process of aggregation in GNN by embedding reconstruction and to adopt Range-Null Space Decomposition for the nodes' interaction learning. Experimental results on multiple representative datasets demonstrate the SOTA performance of our proposed approach.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages",
    "pdf_url": "https://arxiv.org/pdf/2508.02044v1",
    "published_date": "2025-08-04 04:26:38 UTC",
    "updated_date": "2025-08-04 04:26:38 UTC"
  },
  {
    "arxiv_id": "2508.02037v2",
    "title": "Diagnosing Memorization in Chain-of-Thought Reasoning, One Token at a Time",
    "authors": [
      "Huihan Li",
      "You Chen",
      "Siyuan Wang",
      "Yixin He",
      "Ninareh Mehrabi",
      "Rahul Gupta",
      "Xiang Ren"
    ],
    "abstract": "Large Language Models (LLMs) perform well on reasoning benchmarks but often fail when inputs alter slightly, raising concerns about the extent to which their success relies on memorization. This issue is especially acute in Chain-of-Thought (CoT) reasoning, where spurious memorized patterns can trigger intermediate errors that cascade into incorrect final answers. We introduce STIM, a novel framework for Source-aware Token-level Identification of Memorization, which attributes each token in a reasoning chain to one of multiple memorization sources - local, mid-range, or long-range - based on their statistical co-occurrence with the token in the pretraining corpus. Our token-level analysis across tasks and distributional settings reveals that models rely more on memorization in complex or long-tail cases, and that local memorization is often the dominant driver of errors, leading to up to 67% of wrong tokens. We also show that memorization scores from STIM can be effective in predicting the wrong tokens in the wrong reasoning step. STIM offers a powerful tool for diagnosing and improving model reasoning and can generalize to other structured step-wise generation tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02037v2",
    "published_date": "2025-08-04 04:06:34 UTC",
    "updated_date": "2025-08-20 23:05:26 UTC"
  },
  {
    "arxiv_id": "2508.02029v2",
    "title": "A Confidence-Diversity Framework for Calibrating AI Judgement in Accessible Qualitative Coding Tasks",
    "authors": [
      "Zhilong Zhao",
      "Yindi Liu"
    ],
    "abstract": "LLMs enable qualitative coding at large scale, but assessing reliability remains challenging where human experts seldom agree. We investigate confidence-diversity calibration as a quality assessment framework for accessible coding tasks where LLMs already demonstrate strong performance but exhibit overconfidence. Analysing 5,680 coding decisions from eight state-of-the-art LLMs across ten categories, we find that mean self-confidence tracks inter-model agreement closely (Pearson r=0.82). Adding model diversity quantified as normalised Shannon entropy produces a dual signal explaining agreement almost completely (R-squared=0.979), though this high predictive power likely reflects task simplicity for current LLMs. The framework enables a three-tier workflow auto-accepting 35 percent of segments with less than 5 percent error, cutting manual effort by 65 percent. Cross-domain validation confirms transferability (kappa improvements of 0.20 to 0.78). While establishing a methodological foundation for AI judgement calibration, the true potential likely lies in more challenging scenarios where LLMs may demonstrate comparative advantages over human cognitive limitations.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "23 pages, 5 figures. Code and data available at https://doi.org/10.7910/DVN/G1AYGK",
    "pdf_url": "https://arxiv.org/pdf/2508.02029v2",
    "published_date": "2025-08-04 03:47:10 UTC",
    "updated_date": "2025-08-16 06:51:11 UTC"
  },
  {
    "arxiv_id": "2508.02018v1",
    "title": "SpeechR: A Benchmark for Speech Reasoning in Large Audio-Language Models",
    "authors": [
      "Wanqi Yang",
      "Yanda Li",
      "Yunchao Wei",
      "Meng Fang",
      "Ling Chen"
    ],
    "abstract": "Large audio-language models (LALMs) have achieved near-human performance in sentence-level transcription and emotion recognition. However, existing evaluations focus mainly on surface-level perception, leaving the capacity of models for contextual and inference-driven reasoning in speech-based scenarios insufficiently examined. To address this gap, we introduce SpeechR, a unified benchmark for evaluating reasoning over speech in large audio-language models. SpeechR evaluates models along three key dimensions: factual retrieval, procedural inference, and normative judgment. It includes three distinct evaluation formats. The multiple-choice version measures answer selection accuracy. The generative version assesses the coherence and logical consistency of reasoning chains. The acoustic-feature version investigates whether variations in stress and emotion affect reasoning performance. Evaluations on eleven state-of-the-art LALMs reveal that high transcription accuracy does not translate into strong reasoning capabilities. SpeechR establishes a structured benchmark for evaluating reasoning in spoken language, enabling more targeted analysis of model capabilities across diverse dialogue-based tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02018v1",
    "published_date": "2025-08-04 03:28:04 UTC",
    "updated_date": "2025-08-04 03:28:04 UTC"
  },
  {
    "arxiv_id": "2508.02016v2",
    "title": "Dynamic Context Adaptation for Consistent Role-Playing Agents with Retrieval-Augmented Generations",
    "authors": [
      "Jeiyoon Park",
      "Yongshin Han",
      "Minseop Kim",
      "Kisu Yang"
    ],
    "abstract": "Recent advances in large language models (LLMs) have catalyzed research on role-playing agents (RPAs). However, the process of collecting character-specific utterances and continually updating model parameters to track rapidly changing persona attributes is resource-intensive. Although retrieval-augmented generation (RAG) can alleviate this problem, if a persona does not contain knowledge relevant to a given query, RAG-based RPAs are prone to hallucination, making it challenging to generate accurate responses. In this paper, we propose Amadeus, a training-free framework that can significantly enhance persona consistency even when responding to questions that lie beyond a character's knowledge. Amadeus is composed of Adaptive Context-aware Text Splitter (ACTS), Guided Selection (GS), and Attribute Extractor (AE). To facilitate effective RAG-based role-playing, ACTS partitions each character's persona into optimally sized, overlapping chunks and augments this representation with hierarchical contextual information. AE identifies a character's general attributes from the chunks retrieved by GS and uses these attributes as a final context to maintain robust persona consistency even when answering out-of-knowledge questions. To underpin the development and rigorous evaluation of RAG-based RPAs, we manually construct CharacterRAG, a role-playing dataset that consists of persona documents for 15 distinct fictional characters totaling 976K written characters, and 450 question-answer pairs. We find that our proposed method effectively models not only the knowledge possessed by characters, but also various attributes such as personality.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "preprint",
    "pdf_url": "https://arxiv.org/pdf/2508.02016v2",
    "published_date": "2025-08-04 03:27:05 UTC",
    "updated_date": "2025-09-26 01:28:35 UTC"
  },
  {
    "arxiv_id": "2508.06534v3",
    "title": "MetAdv: A Unified and Interactive Adversarial Testing Platform for Autonomous Driving",
    "authors": [
      "Aishan Liu",
      "Jiakai Wang",
      "Tianyuan Zhang",
      "Hainan Li",
      "Jiangfan Liu",
      "Siyuan Liang",
      "Yilong Ren",
      "Xianglong Liu",
      "Dacheng Tao"
    ],
    "abstract": "Evaluating and ensuring the adversarial robustness of autonomous driving (AD) systems is a critical and unresolved challenge. This paper introduces MetAdv, a novel adversarial testing platform that enables realistic, dynamic, and interactive evaluation by tightly integrating virtual simulation with physical vehicle feedback. At its core, MetAdv establishes a hybrid virtual-physical sandbox, within which we design a three-layer closed-loop testing environment with dynamic adversarial test evolution. This architecture facilitates end-to-end adversarial evaluation, ranging from high-level unified adversarial generation, through mid-level simulation-based interaction, to low-level execution on physical vehicles. Additionally, MetAdv supports a broad spectrum of AD tasks, algorithmic paradigms (e.g., modular deep learning pipelines, end-to-end learning, vision-language models). It supports flexible 3D vehicle modeling and seamless transitions between simulated and physical environments, with built-in compatibility for commercial platforms such as Apollo and Tesla. A key feature of MetAdv is its human-in-the-loop capability: besides flexible environmental configuration for more customized evaluation, it enables real-time capture of physiological signals and behavioral feedback from drivers, offering new insights into human-machine trust under adversarial conditions. We believe MetAdv can offer a scalable and unified framework for adversarial assessment, paving the way for safer AD.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "ACM MM 2025 Most Popular Demo Award",
    "pdf_url": "https://arxiv.org/pdf/2508.06534v3",
    "published_date": "2025-08-04 03:07:54 UTC",
    "updated_date": "2025-11-04 01:23:14 UTC"
  },
  {
    "arxiv_id": "2508.01997v2",
    "title": "DIRF: A Framework for Digital Identity Protection and Clone Governance in Agentic AI Systems",
    "authors": [
      "Hammad Atta",
      "Muhammad Zeeshan Baig",
      "Yasir Mehmood",
      "Nadeem Shahzad",
      "Ken Huang",
      "Muhammad Aziz Ul Haq",
      "Muhammad Awais",
      "Kamal Ahmed",
      "Anthony Green"
    ],
    "abstract": "The rapid advancement and widespread adoption of generative artificial intelligence (AI) pose significant threats to the integrity of personal identity, including digital cloning, sophisticated impersonation, and the unauthorized monetization of identity-related data. Mitigating these risks necessitates the development of robust AI-generated content detection systems, enhanced legal frameworks, and ethical guidelines. This paper introduces the Digital Identity Rights Framework (DIRF), a structured security and governance model designed to protect behavioral, biometric, and personality-based digital likeness attributes to address this critical need. Structured across nine domains and 63 controls, DIRF integrates legal, technical, and hybrid enforcement mechanisms to secure digital identity consent, traceability, and monetization. We present the architectural foundations, enforcement strategies, and key use cases supporting the need for a unified framework. This work aims to inform platform builders, legal entities, and regulators about the essential controls needed to enforce identity rights in AI-driven systems.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.01997v2",
    "published_date": "2025-08-04 02:27:14 UTC",
    "updated_date": "2025-09-08 06:22:03 UTC"
  },
  {
    "arxiv_id": "2508.01987v1",
    "title": "Controllable and Stealthy Shilling Attacks via Dispersive Latent Diffusion",
    "authors": [
      "Shutong Qiao",
      "Wei Yuan",
      "Junliang Yu",
      "Tong Chen",
      "Quoc Viet Hung Nguyen",
      "Hongzhi Yin"
    ],
    "abstract": "Recommender systems (RSs) are now fundamental to various online platforms, but their dependence on user-contributed data leaves them vulnerable to shilling attacks that can manipulate item rankings by injecting fake users. Although widely studied, most existing attack models fail to meet two critical objectives simultaneously: achieving strong adversarial promotion of target items while maintaining realistic behavior to evade detection. As a result, the true severity of shilling threats that manage to reconcile the two objectives remains underappreciated. To expose this overlooked vulnerability, we present DLDA, a diffusion-based attack framework that can generate highly effective yet indistinguishable fake users by enabling fine-grained control over target promotion. Specifically, DLDA operates in a pre-aligned collaborative embedding space, where it employs a conditional latent diffusion process to iteratively synthesize fake user profiles with precise target item control. To evade detection, DLDA introduces a dispersive regularization mechanism that promotes variability and realism in generated behavioral patterns. Extensive experiments on three real-world datasets and five popular RS models demonstrate that, compared to prior attacks, DLDA consistently achieves stronger item promotion while remaining harder to detect. These results highlight that modern RSs are more vulnerable than previously recognized, underscoring the urgent need for more robust defenses.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.01987v1",
    "published_date": "2025-08-04 01:54:32 UTC",
    "updated_date": "2025-08-04 01:54:32 UTC"
  },
  {
    "arxiv_id": "2508.01977v2",
    "title": "TIBSTC-CoT: A Multi-Domain Instruction Dataset for Chain-of-Thought Reasoning in Language Models",
    "authors": [
      "Fan Gao",
      "Cheng Huang",
      "Nyima Tashi",
      "Yutong Liu",
      "Xiangxiang Wang",
      "Thupten Tsering",
      "Ban Ma-bao",
      "Renzeg Duojie",
      "Gadeng Luosang",
      "Rinchen Dongrub",
      "Dorje Tashi",
      "Xiao Feng",
      "Hao Wang",
      "Yongbin Yu"
    ],
    "abstract": "To address the severe data scarcity in Tibetan, a low-resource language spoken by over six million people, we introduce TIBSTC-CoT, the large-scale, multi-domain Tibetan dataset automatically constructed via chain-of-thought prompting with large language models (LLMs). TIBSTC-CoT establishes a scalable and reproducible framework for dataset creation in low-resource settings, covering diverse domains and reasoning patterns essential for language understanding and generation. Building on this dataset, we develop the Sunshine-thinking LLM family, a series of Tibetan-centric LLMs equipped with chain-of-thought capabilities. Trained entirely on TIBSTC-CoT, Sunshine-thinking has demonstrated strong reasoning and generation performance, comparable to state-of-the-art (SOTA) multilingual LLMs. Our work marks a significant step toward inclusive AI by enabling high-quality Tibetan language processing through both resource creation and model innovation. All data are available: https://github.com/Vicentvankor/sun-shine.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "We will merge this paper with arXiv:2503.18288",
    "pdf_url": "https://arxiv.org/pdf/2508.01977v2",
    "published_date": "2025-08-04 01:32:58 UTC",
    "updated_date": "2025-12-16 02:45:16 UTC"
  },
  {
    "arxiv_id": "2508.01969v1",
    "title": "Accelerating LLM Reasoning via Early Rejection with Partial Reward Modeling",
    "authors": [
      "Seyyed Saeid Cheshmi",
      "Azal Ahmad Khan",
      "Xinran Wang",
      "Zirui Liu",
      "Ali Anwar"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly relied upon for solving complex reasoning tasks in domains such as mathematics, logic, and multi-step question answering. A growing line of work seeks to improve reasoning quality by scaling inference time compute particularly through Process Reward Models (PRMs), used to reward the reasoning at intermediate steps. While effective, these methods introduce substantial computational overhead, especially when generating large numbers of solutions in parallel. In this paper, we investigate whether PRMs can be used mid-generation to provide early signals that enable the rejection of suboptimal candidates before full generation of step is complete. We introduce the hypothesis that PRMs are also Partial Reward Models, meaning that the scores they assign to partially completed reasoning step are predictive of final output quality. This allows for principled early rejection based on intermediate token-level signals. We support this hypothesis both theoretically, by proving that the risk of discarding optimal beams decreases exponentially with generation length and empirically, by demonstrating a strong correlation between partial and final rewards across multiple reward models. On math reasoning benchmarks, our method achieves up to 1.4$\\times$-9$\\times$ reduction in inference FLOPs without degrading final performance. These results suggest that early rejection is a powerful mechanism for improving the compute-efficiency of reasoning in LLMs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.01969v1",
    "published_date": "2025-08-04 00:58:56 UTC",
    "updated_date": "2025-08-04 00:58:56 UTC"
  },
  {
    "arxiv_id": "2508.01961v2",
    "title": "Kron-LoRA: Hybrid Kronecker-LoRA Adapters for Scalable, Sustainable Fine-tuning",
    "authors": [
      "Yixin Shen"
    ],
    "abstract": "Fine-tuning massive pre-trained language models across many tasks demands adapters that are both parameter-efficient and expressive. We introduce \\textbf{Kron-LoRA}, a hybrid adapter that combines Kronecker-structured factorization with low-rank LoRA compression-an integration that, to our knowledge, has not been explored in parameter-efficient fine-tuning or in matrix approximation literature. Kron-LoRA achieves up to 4$\\times$ fewer parameters than standard LoRA while retaining similar expressivity. Experiments on DistilBERT, Mistral-7B, LLaMA-2-7B, and LLaMA-3-8B across eight benchmarks show that Kron-LoRA matches or exceeds LoRA baselines with modest memory savings and only a 5-8\\% speed overhead. In sequential fine-tuning, it also delivers competitive cross-task transfer despite using only one-quarter of the adapter parameters. Kron-LoRA thus offers a scalable, sustainable solution for multi-task adaptation of large language models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.01961v2",
    "published_date": "2025-08-04 00:02:15 UTC",
    "updated_date": "2025-09-24 10:03:27 UTC"
  }
]