[
  {
    "arxiv_id": "2503.18945v2",
    "title": "Aether: Geometric-Aware Unified World Modeling",
    "authors": [
      "Aether Team",
      "Haoyi Zhu",
      "Yifan Wang",
      "Jianjun Zhou",
      "Wenzheng Chang",
      "Yang Zhou",
      "Zizun Li",
      "Junyi Chen",
      "Chunhua Shen",
      "Jiangmiao Pang",
      "Tong He"
    ],
    "abstract": "The integration of geometric reconstruction and generative modeling remains a\ncritical challenge in developing AI systems capable of human-like spatial\nreasoning. This paper proposes Aether, a unified framework that enables\ngeometry-aware reasoning in world models by jointly optimizing three core\ncapabilities: (1) 4D dynamic reconstruction, (2) action-conditioned video\nprediction, and (3) goal-conditioned visual planning. Through task-interleaved\nfeature learning, Aether achieves synergistic knowledge sharing across\nreconstruction, prediction, and planning objectives. Building upon video\ngeneration models, our framework demonstrates unprecedented synthetic-to-real\ngeneralization despite never observing real-world data during training.\nFurthermore, our approach achieves zero-shot generalization in both action\nfollowing and reconstruction tasks, thanks to its intrinsic geometric modeling.\nRemarkably, even without real-world data, its reconstruction performance is\ncomparable with or even better than that of domain-specific models.\nAdditionally, Aether employs camera trajectories as geometry-informed action\nspaces, enabling effective action-conditioned prediction and visual planning.\nWe hope our work inspires the community to explore new frontiers in\nphysically-reasonable world modeling and its applications.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "Project Page: https://aether-world.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2503.18945v2",
    "published_date": "2025-03-24 17:59:51 UTC",
    "updated_date": "2025-03-25 15:31:25 UTC"
  },
  {
    "arxiv_id": "2503.18942v1",
    "title": "Video-T1: Test-Time Scaling for Video Generation",
    "authors": [
      "Fangfu Liu",
      "Hanyang Wang",
      "Yimo Cai",
      "Kaiyan Zhang",
      "Xiaohang Zhan",
      "Yueqi Duan"
    ],
    "abstract": "With the scale capability of increasing training data, model size, and\ncomputational cost, video generation has achieved impressive results in digital\ncreation, enabling users to express creativity across various domains.\nRecently, researchers in Large Language Models (LLMs) have expanded the scaling\nto test-time, which can significantly improve LLM performance by using more\ninference-time computation. Instead of scaling up video foundation models\nthrough expensive training costs, we explore the power of Test-Time Scaling\n(TTS) in video generation, aiming to answer the question: if a video generation\nmodel is allowed to use non-trivial amount of inference-time compute, how much\ncan it improve generation quality given a challenging text prompt. In this\nwork, we reinterpret the test-time scaling of video generation as a searching\nproblem to sample better trajectories from Gaussian noise space to the target\nvideo distribution. Specifically, we build the search space with test-time\nverifiers to provide feedback and heuristic algorithms to guide searching\nprocess. Given a text prompt, we first explore an intuitive linear search\nstrategy by increasing noise candidates at inference time. As full-step\ndenoising all frames simultaneously requires heavy test-time computation costs,\nwe further design a more efficient TTS method for video generation called\nTree-of-Frames (ToF) that adaptively expands and prunes video branches in an\nautoregressive manner. Extensive experiments on text-conditioned video\ngeneration benchmarks demonstrate that increasing test-time compute\nconsistently leads to significant improvements in the quality of videos.\nProject page: https://liuff19.github.io/Video-T1",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page: https://liuff19.github.io/Video-T1",
    "pdf_url": "http://arxiv.org/pdf/2503.18942v1",
    "published_date": "2025-03-24 17:59:04 UTC",
    "updated_date": "2025-03-24 17:59:04 UTC"
  },
  {
    "arxiv_id": "2503.18938v1",
    "title": "AdaWorld: Learning Adaptable World Models with Latent Actions",
    "authors": [
      "Shenyuan Gao",
      "Siyuan Zhou",
      "Yilun Du",
      "Jun Zhang",
      "Chuang Gan"
    ],
    "abstract": "World models aim to learn action-controlled prediction models and have proven\nessential for the development of intelligent agents. However, most existing\nworld models rely heavily on substantial action-labeled data and costly\ntraining, making it challenging to adapt to novel environments with\nheterogeneous actions through limited interactions. This limitation can hinder\ntheir applicability across broader domains. To overcome this challenge, we\npropose AdaWorld, an innovative world model learning approach that enables\nefficient adaptation. The key idea is to incorporate action information during\nthe pretraining of world models. This is achieved by extracting latent actions\nfrom videos in a self-supervised manner, capturing the most critical\ntransitions between frames. We then develop an autoregressive world model that\nconditions on these latent actions. This learning paradigm enables highly\nadaptable world models, facilitating efficient transfer and learning of new\nactions even with limited interactions and finetuning. Our comprehensive\nexperiments across multiple environments demonstrate that AdaWorld achieves\nsuperior performance in both simulation quality and visual planning.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "Project page: https://adaptable-world-model.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2503.18938v1",
    "published_date": "2025-03-24 17:58:15 UTC",
    "updated_date": "2025-03-24 17:58:15 UTC"
  },
  {
    "arxiv_id": "2503.18899v1",
    "title": "Statistical Proof of Execution (SPEX)",
    "authors": [
      "Michele Dallachiesa",
      "Antonio Pitasi",
      "David Pinger",
      "Josh Goodbody",
      "Luis Vaello"
    ],
    "abstract": "Many real-world applications are increasingly incorporating automated\ndecision-making, driven by the widespread adoption of ML/AI inference for\nplanning and guidance. This study examines the growing need for verifiable\ncomputing in autonomous decision-making. We formalize the problem of verifiable\ncomputing and introduce a sampling-based protocol that is significantly faster,\nmore cost-effective, and simpler than existing methods. Furthermore, we tackle\nthe challenges posed by non-determinism, proposing a set of strategies to\neffectively manage common scenarios.",
    "categories": [
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18899v1",
    "published_date": "2025-03-24 17:13:25 UTC",
    "updated_date": "2025-03-24 17:13:25 UTC"
  },
  {
    "arxiv_id": "2503.18892v1",
    "title": "SimpleRL-Zoo: Investigating and Taming Zero Reinforcement Learning for Open Base Models in the Wild",
    "authors": [
      "Weihao Zeng",
      "Yuzhen Huang",
      "Qian Liu",
      "Wei Liu",
      "Keqing He",
      "Zejun Ma",
      "Junxian He"
    ],
    "abstract": "DeepSeek-R1 has shown that long chain-of-thought (CoT) reasoning can\nnaturally emerge through a simple reinforcement learning (RL) framework with\nrule-based rewards, where the training may directly start from the base\nmodels-a paradigm referred to as zero RL training. Most recent efforts to\nreproduce zero RL training have primarily focused on the Qwen2.5 model series,\nwhich may not be representative as we find the base models already exhibit\nstrong instruction-following and self-reflection abilities. In this work, we\ninvestigate zero RL training across 10 diverse base models, spanning different\nfamilies and sizes including LLama3-8B, Mistral-7B/24B, DeepSeek-Math-7B,\nQwen2.5-math-7B, and all Qwen2.5 models from 0.5B to 32B. Leveraging several\nkey design strategies-such as adjusting format reward and controlling query\ndifficulty-we achieve substantial improvements in both reasoning accuracy and\nresponse length across most settings. However, by carefully monitoring the\ntraining dynamics, we observe that different base models exhibit distinct\npatterns during training. For instance, the increased response length does not\nalways correlate with the emergence of certain cognitive behaviors such as\nverification (i.e., the \"aha moment\"). Notably, we observe the \"aha moment\" for\nthe first time in small models not from the Qwen family. We share the key\ndesigns that enable successful zero RL training, along with our findings and\npractices. To facilitate further research, we open-source the code, models, and\nanalysis tools.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18892v1",
    "published_date": "2025-03-24 17:06:10 UTC",
    "updated_date": "2025-03-24 17:06:10 UTC"
  },
  {
    "arxiv_id": "2503.18891v1",
    "title": "AgentDropout: Dynamic Agent Elimination for Token-Efficient and High-Performance LLM-Based Multi-Agent Collaboration",
    "authors": [
      "Zhexuan Wang",
      "Yutong Wang",
      "Xuebo Liu",
      "Liang Ding",
      "Miao Zhang",
      "Jie Liu",
      "Min Zhang"
    ],
    "abstract": "Multi-agent systems (MAS) based on large language models (LLMs) have\ndemonstrated significant potential in collaborative problem-solving. However,\nthey still face substantial challenges of low communication efficiency and\nsuboptimal task performance, making the careful design of the agents'\ncommunication topologies particularly important. Inspired by the management\ntheory that roles in an efficient team are often dynamically adjusted, we\npropose AgentDropout, which identifies redundant agents and communication\nacross different communication rounds by optimizing the adjacency matrices of\nthe communication graphs and eliminates them to enhance both token efficiency\nand task performance. Compared to state-of-the-art methods, AgentDropout\nachieves an average reduction of 21.6% in prompt token consumption and 18.4% in\ncompletion token consumption, along with a performance improvement of 1.14 on\nthe tasks. Furthermore, the extended experiments demonstrate that AgentDropout\nachieves notable domain transferability and structure robustness, revealing its\nreliability and effectiveness. We release our code at\nhttps://github.com/wangzx1219/AgentDropout.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18891v1",
    "published_date": "2025-03-24 17:04:55 UTC",
    "updated_date": "2025-03-24 17:04:55 UTC"
  },
  {
    "arxiv_id": "2503.18871v1",
    "title": "Bootstrapped Model Predictive Control",
    "authors": [
      "Yuhang Wang",
      "Hanwei Guo",
      "Sizhe Wang",
      "Long Qian",
      "Xuguang Lan"
    ],
    "abstract": "Model Predictive Control (MPC) has been demonstrated to be effective in\ncontinuous control tasks. When a world model and a value function are\navailable, planning a sequence of actions ahead of time leads to a better\npolicy. Existing methods typically obtain the value function and the\ncorresponding policy in a model-free manner. However, we find that such an\napproach struggles with complex tasks, resulting in poor policy learning and\ninaccurate value estimation. To address this problem, we leverage the strengths\nof MPC itself. In this work, we introduce Bootstrapped Model Predictive Control\n(BMPC), a novel algorithm that performs policy learning in a bootstrapped\nmanner. BMPC learns a network policy by imitating an MPC expert, and in turn,\nuses this policy to guide the MPC process. Combined with model-based\nTD-learning, our policy learning yields better value estimation and further\nboosts the efficiency of MPC. We also introduce a lazy reanalyze mechanism,\nwhich enables computationally efficient imitation learning. Our method achieves\nsuperior performance over prior works on diverse continuous control tasks. In\nparticular, on challenging high-dimensional locomotion tasks, BMPC\nsignificantly improves data efficiency while also enhancing asymptotic\nperformance and training stability, with comparable training time and smaller\nnetwork sizes. Code is available at https://github.com/wertyuilife2/bmpc.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "Published as a conference paper at ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.18871v1",
    "published_date": "2025-03-24 16:46:36 UTC",
    "updated_date": "2025-03-24 16:46:36 UTC"
  },
  {
    "arxiv_id": "2503.18866v1",
    "title": "Reasoning to Learn from Latent Thoughts",
    "authors": [
      "Yangjun Ruan",
      "Neil Band",
      "Chris J. Maddison",
      "Tatsunori Hashimoto"
    ],
    "abstract": "Compute scaling for language model (LM) pretraining has outpaced the growth\nof human-written texts, leading to concerns that data will become the\nbottleneck to LM scaling. To continue scaling pretraining in this\ndata-constrained regime, we propose that explicitly modeling and inferring the\nlatent thoughts that underlie the text generation process can significantly\nimprove pretraining data efficiency. Intuitively, our approach views web text\nas the compressed final outcome of a verbose human thought process and that the\nlatent thoughts contain important contextual knowledge and reasoning steps that\nare critical to data-efficient learning. We empirically demonstrate the\neffectiveness of our approach through data-constrained continued pretraining\nfor math. We first show that synthetic data approaches to inferring latent\nthoughts significantly improve data efficiency, outperforming training on the\nsame amount of raw data (5.7\\% $\\rightarrow$ 25.4\\% on MATH). Furthermore, we\ndemonstrate latent thought inference without a strong teacher, where an LM\nbootstraps its own performance by using an EM algorithm to iteratively improve\nthe capability of the trained LM and the quality of thought-augmented\npretraining data. We show that a 1B LM can bootstrap its performance across at\nleast three iterations and significantly outperform baselines trained on raw\ndata, with increasing gains from additional inference compute when performing\nthe E-step. The gains from inference scaling and EM iterations suggest new\nopportunities for scaling data-constrained pretraining.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18866v1",
    "published_date": "2025-03-24 16:41:23 UTC",
    "updated_date": "2025-03-24 16:41:23 UTC"
  },
  {
    "arxiv_id": "2503.18865v2",
    "title": "Structuring Scientific Innovation: A Framework for Modeling and Discovering Impactful Knowledge Combinations",
    "authors": [
      "Junlan Chen",
      "Kexin Zhang",
      "Daifeng Li",
      "Yangyang Feng",
      "Yuxuan Zhang",
      "Bowen Deng"
    ],
    "abstract": "The emergence of large language models offers new possibilities for\nstructured exploration of scientific knowledge. Rather than viewing scientific\ndiscovery as isolated ideas or content, we propose a structured approach that\nemphasizes the role of method combinations in shaping disruptive insights.\nSpecifically, we investigate how knowledge unit--especially those tied to\nmethodological design--can be modeled and recombined to yield research\nbreakthroughs. Our proposed framework addresses two key challenges. First, we\nintroduce a contrastive learning-based mechanism to identify distinguishing\nfeatures of historically disruptive method combinations within problem-driven\ncontexts. Second, we propose a reasoning-guided Monte Carlo search algorithm\nthat leverages the chain-of-thought capability of LLMs to identify promising\nknowledge recombinations for new problem statements.Empirical studies across\nmultiple domains show that the framework is capable of modeling the structural\ndynamics of innovation and successfully highlights combinations with high\ndisruptive potential. This research provides a new path for computationally\nguided scientific ideation grounded in structured reasoning and historical data\nmodeling.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18865v2",
    "published_date": "2025-03-24 16:41:17 UTC",
    "updated_date": "2025-03-25 14:21:15 UTC"
  },
  {
    "arxiv_id": "2503.18862v1",
    "title": "Exploring the Integration of Key-Value Attention Into Pure and Hybrid Transformers for Semantic Segmentation",
    "authors": [
      "DeShin Hwa",
      "Tobias Holmes",
      "Klaus Drechsler"
    ],
    "abstract": "While CNNs were long considered state of the art for image processing, the\nintroduction of Transformer architectures has challenged this position. While\nachieving excellent results in image classification and segmentation,\nTransformers remain inherently reliant on large training datasets and remain\ncomputationally expensive. A newly introduced Transformer derivative named KV\nTransformer shows promising results in synthetic, NLP, and image classification\ntasks, while reducing complexity and memory usage. This is especially conducive\nto use cases where local inference is required, such as medical screening\napplications. We endeavoured to further evaluate the merit of KV Transformers\non semantic segmentation tasks, specifically in the domain of medical imaging.\nBy directly comparing traditional and KV variants of the same base\narchitectures, we provide further insight into the practical tradeoffs of\nreduced model complexity. We observe a notable reduction in parameter count and\nmultiply accumulate operations, while achieving similar performance from most\nof the KV variant models when directly compared to their QKV implementation.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "6 pages, 3 figures, Preprint. Final version published in:\n  Bildverarbeitung f\\\"ur die Medizin 2025, Springer. DOI:\n  https://doi.org/10.1007/978-3-658-47422-5_71",
    "pdf_url": "http://arxiv.org/pdf/2503.18862v1",
    "published_date": "2025-03-24 16:38:31 UTC",
    "updated_date": "2025-03-24 16:38:31 UTC"
  },
  {
    "arxiv_id": "2503.18854v2",
    "title": "MC-LLaVA: Multi-Concept Personalized Vision-Language Model",
    "authors": [
      "Ruichuan An",
      "Sihan Yang",
      "Ming Lu",
      "Renrui Zhang",
      "Kai Zeng",
      "Yulin Luo",
      "Jiajun Cao",
      "Hao Liang",
      "Ying Chen",
      "Qi She",
      "Shanghang Zhang",
      "Wentao Zhang"
    ],
    "abstract": "Current vision-language models (VLMs) show exceptional abilities across\ndiverse tasks, such as visual question answering. To enhance user experience,\nrecent studies investigate VLM personalization to understand user-provided\nconcepts. However, they mainly focus on single-concept personalization,\nneglecting the existence and interplay of multiple concepts, which limits\nreal-world applicability. This paper proposes the first multi-concept\npersonalization paradigm, MC-LLaVA. Specifically, MC-LLaVA employs a\nmulti-concept instruction tuning strategy, effectively integrating multiple\nconcepts in a single training step. To reduce the costs related to joint\ntraining, we propose a personalized textual prompt that uses visual token\ninformation to initialize concept tokens. Additionally, we introduce a\npersonalized visual prompt during inference, aggregating location confidence\nmaps for enhanced recognition and grounding capabilities. To advance\nmulti-concept personalization research, we further contribute a high-quality\ninstruction tuning dataset. We carefully collect images with multiple\ncharacters and objects from movies and manually generate question-answer\nsamples for multi-concept scenarios, featuring superior diversity.\nComprehensive qualitative and quantitative experiments demonstrate that\nMC-LLaVA can achieve impressive multi-concept personalized responses, paving\nthe way for VLMs to become better user-specific assistants. The code and\ndataset will be publicly available at https://github.com/arctanxarc/MC-LLaVA}.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "I sincerely apologize for any inconvenience caused. We actually\n  uploaded this paper to arXiv in November 2024, as arXiv:2411.11706. During\n  this update, we did not consider the replacement operation of arXiv, which\n  led to duplicate submissions. We have made modifications at the original\n  address arXiv:2411.11706",
    "pdf_url": "http://arxiv.org/pdf/2503.18854v2",
    "published_date": "2025-03-24 16:32:17 UTC",
    "updated_date": "2025-03-25 13:50:20 UTC"
  },
  {
    "arxiv_id": "2503.18852v1",
    "title": "Self-Organizing Graph Reasoning Evolves into a Critical State for Continuous Discovery Through Structural-Semantic Dynamics",
    "authors": [
      "Markus J. Buehler"
    ],
    "abstract": "We report fundamental insights into how agentic graph reasoning systems\nspontaneously evolve toward a critical state that sustains continuous semantic\ndiscovery. By rigorously analyzing structural (Von Neumann graph entropy) and\nsemantic (embedding) entropy, we identify a subtle yet robust regime in which\nsemantic entropy persistently dominates over structural entropy. This interplay\nis quantified by a dimensionless Critical Discovery Parameter that stabilizes\nat a small negative value, indicating a consistent excess of semantic entropy.\nEmpirically, we observe a stable fraction (12%) of \"surprising\" edges, links\nbetween semantically distant concepts, providing evidence of long-range or\ncross-domain connections that drive continuous innovation. Concomitantly, the\nsystem exhibits scale-free and small-world topological features, alongside a\nnegative cross-correlation between structural and semantic measures,\nreinforcing the analogy to self-organized criticality. These results establish\nclear parallels with critical phenomena in physical, biological, and cognitive\ncomplex systems, revealing an entropy-based principle governing adaptability\nand continuous innovation. Crucially, semantic richness emerges as the\nunderlying driver of sustained exploration, despite not being explicitly used\nby the reasoning process. Our findings provide interdisciplinary insights and\npractical strategies for engineering intelligent systems with intrinsic\ncapacities for long-term discovery and adaptation, and offer insights into how\nmodel training strategies can be developed that reinforce critical discovery.",
    "categories": [
      "cs.AI",
      "cond-mat.mes-hall",
      "cs.LG",
      "nlin.AO",
      "physics.app-ph"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18852v1",
    "published_date": "2025-03-24 16:30:37 UTC",
    "updated_date": "2025-03-24 16:30:37 UTC"
  },
  {
    "arxiv_id": "2503.18842v1",
    "title": "Three Kinds of AI Ethics",
    "authors": [
      "Emanuele Ratti"
    ],
    "abstract": "There is an overwhelmingly abundance of works in AI Ethics. This growth is\nchaotic because of how sudden it is, its volume, and its multidisciplinary\nnature. This makes difficult to keep track of debates, and to systematically\ncharacterize goals, research questions, methods, and expertise required by AI\nethicists. In this article, I show that the relation between AI and ethics can\nbe characterized in at least three ways, which correspond to three\nwell-represented kinds of AI ethics: ethics and AI; ethics in AI; ethics of AI.\nI elucidate the features of these three kinds of AI Ethics, characterize their\nresearch questions, and identify the kind of expertise that each kind needs. I\nalso show how certain criticisms to AI ethics are misplaced, as being done from\nthe point of view of one kind of AI ethics, to another kind with different\ngoals. All in all, this work sheds light on the nature of AI ethics, and set\nthe grounds for more informed discussions about scope, methods, and trainings\nof AI ethicists.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "16 pages, two figures",
    "pdf_url": "http://arxiv.org/pdf/2503.18842v1",
    "published_date": "2025-03-24 16:15:03 UTC",
    "updated_date": "2025-03-24 16:15:03 UTC"
  },
  {
    "arxiv_id": "2503.18836v1",
    "title": "Dual-domain Multi-path Self-supervised Diffusion Model for Accelerated MRI Reconstruction",
    "authors": [
      "Yuxuan Zhang",
      "Jinkui Hao",
      "Bo Zhou"
    ],
    "abstract": "Magnetic resonance imaging (MRI) is a vital diagnostic tool, but its\ninherently long acquisition times reduce clinical efficiency and patient\ncomfort. Recent advancements in deep learning, particularly diffusion models,\nhave improved accelerated MRI reconstruction. However, existing diffusion\nmodels' training often relies on fully sampled data, models incur high\ncomputational costs, and often lack uncertainty estimation, limiting their\nclinical applicability. To overcome these challenges, we propose a novel\nframework, called Dual-domain Multi-path Self-supervised Diffusion Model\n(DMSM), that integrates a self-supervised dual-domain diffusion model training\nscheme, a lightweight hybrid attention network for the reconstruction diffusion\nmodel, and a multi-path inference strategy, to enhance reconstruction accuracy,\nefficiency, and explainability. Unlike traditional diffusion-based models, DMSM\neliminates the dependency on training from fully sampled data, making it more\npractical for real-world clinical settings. We evaluated DMSM on two human MRI\ndatasets, demonstrating that it achieves favorable performance over several\nsupervised and self-supervised baselines, particularly in preserving fine\nanatomical structures and suppressing artifacts under high acceleration\nfactors. Additionally, our model generates uncertainty maps that correlate\nreasonably well with reconstruction errors, offering valuable clinically\ninterpretable guidance and potentially enhancing diagnostic confidence.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "10 pages, 8 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2503.18836v1",
    "published_date": "2025-03-24 16:10:51 UTC",
    "updated_date": "2025-03-24 16:10:51 UTC"
  },
  {
    "arxiv_id": "2503.18826v1",
    "title": "Interpretable and Fair Mechanisms for Abstaining Classifiers",
    "authors": [
      "Daphne Lenders",
      "Andrea Pugnana",
      "Roberto Pellungrini",
      "Toon Calders",
      "Dino Pedreschi",
      "Fosca Giannotti"
    ],
    "abstract": "Abstaining classifiers have the option to refrain from providing a prediction\nfor instances that are difficult to classify. The abstention mechanism is\ndesigned to trade off the classifier's performance on the accepted data while\nensuring a minimum number of predictions. In this setting, often fairness\nconcerns arise when the abstention mechanism solely reduces errors for the\nmajority groups of the data, resulting in increased performance differences\nacross demographic groups. While there exist a bunch of methods that aim to\nreduce discrimination when abstaining, there is no mechanism that can do so in\nan explainable way. In this paper, we fill this gap by introducing\nInterpretable and Fair Abstaining Classifier IFAC, an algorithm that can reject\npredictions both based on their uncertainty and their unfairness. By rejecting\npossibly unfair predictions, our method reduces error and positive decision\nrate differences across demographic groups of the non-rejected data. Since the\nunfairness-based rejections are based on an interpretable-by-design method,\ni.e., rule-based fairness checks and situation testing, we create a transparent\nprocess that can empower human decision-makers to review the unfair predictions\nand make more just decisions for them. This explainable aspect is especially\nimportant in light of recent AI regulations, mandating that any high-risk\ndecision task should be overseen by human experts to reduce discrimination\nrisks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "25 pages, 8 figures. In: Machine Learning and Knowledge Discovery in\n  Databases. Research Track. ECML PKDD 2024",
    "pdf_url": "http://arxiv.org/pdf/2503.18826v1",
    "published_date": "2025-03-24 16:06:43 UTC",
    "updated_date": "2025-03-24 16:06:43 UTC"
  },
  {
    "arxiv_id": "2503.18825v1",
    "title": "EconEvals: Benchmarks and Litmus Tests for LLM Agents in Unknown Environments",
    "authors": [
      "Sara Fish",
      "Julia Shephard",
      "Minkai Li",
      "Ran I. Shorrer",
      "Yannai A. Gonczarowski"
    ],
    "abstract": "We develop benchmarks for LLM agents that act in, learn from, and strategize\nin unknown environments, the specifications of which the LLM agent must learn\nover time from deliberate exploration. Our benchmarks consist of\ndecision-making tasks derived from key problems in economics. To forestall\nsaturation, the benchmark tasks are synthetically generated with scalable\ndifficulty levels. Additionally, we propose litmus tests, a new kind of\nquantitative measure for LLMs and LLM agents. Unlike benchmarks, litmus tests\nquantify differences in character, values, and tendencies of LLMs and LLM\nagents, by considering their behavior when faced with tradeoffs (e.g.,\nefficiency versus equality) where there is no objectively right or wrong\nbehavior. Overall, our benchmarks and litmus tests assess the abilities and\ntendencies of LLM agents in tackling complex economic problems in diverse\nsettings spanning procurement, scheduling, task allocation, and pricing --\napplications that should grow in importance as such agents are further\nintegrated into the economy.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.GT"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18825v1",
    "published_date": "2025-03-24 16:06:04 UTC",
    "updated_date": "2025-03-24 16:06:04 UTC"
  },
  {
    "arxiv_id": "2503.18817v1",
    "title": "Enhanced OoD Detection through Cross-Modal Alignment of Multi-Modal Representations",
    "authors": [
      "Jeonghyeon Kim",
      "Sangheum Hwang"
    ],
    "abstract": "Prior research on out-of-distribution detection (OoDD) has primarily focused\non single-modality models. Recently, with the advent of large-scale pretrained\nvision-language models such as CLIP, OoDD methods utilizing such multi-modal\nrepresentations through zero-shot and prompt learning strategies have emerged.\nHowever, these methods typically involve either freezing the pretrained weights\nor only partially tuning them, which can be suboptimal for downstream datasets.\nIn this paper, we highlight that multi-modal fine-tuning (MMFT) can achieve\nnotable OoDD performance. Despite some recent works demonstrating the impact of\nfine-tuning methods for OoDD, there remains significant potential for\nperformance improvement. We investigate the limitation of na\\\"ive fine-tuning\nmethods, examining why they fail to fully leverage the pretrained knowledge.\nOur empirical analysis suggests that this issue could stem from the modality\ngap within in-distribution (ID) embeddings. To address this, we propose a\ntraining objective that enhances cross-modal alignment by regularizing the\ndistances between image and text embeddings of ID data. This adjustment helps\nin better utilizing pretrained textual information by aligning similar\nsemantics from different modalities (i.e., text and image) more closely in the\nhyperspherical representation space. We theoretically demonstrate that the\nproposed regularization corresponds to the maximum likelihood estimation of an\nenergy-based model on a hypersphere. Utilizing ImageNet-1k OoD benchmark\ndatasets, we show that our method, combined with post-hoc OoDD approaches\nleveraging pretrained knowledge (e.g., NegLabel), significantly outperforms\nexisting methods, achieving state-of-the-art OoDD performance and leading ID\naccuracy.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.18817v1",
    "published_date": "2025-03-24 16:00:21 UTC",
    "updated_date": "2025-03-24 16:00:21 UTC"
  },
  {
    "arxiv_id": "2503.18816v1",
    "title": "Learning Multi-Robot Coordination through Locality-Based Factorized Multi-Agent Actor-Critic Algorithm",
    "authors": [
      "Chak Lam Shek",
      "Amrit Singh Bedi",
      "Anjon Basak",
      "Ellen Novoseller",
      "Nick Waytowich",
      "Priya Narayanan",
      "Dinesh Manocha",
      "Pratap Tokekar"
    ],
    "abstract": "In this work, we present a novel cooperative multi-agent reinforcement\nlearning method called \\textbf{Loc}ality based \\textbf{Fac}torized\n\\textbf{M}ulti-Agent \\textbf{A}ctor-\\textbf{C}ritic (Loc-FACMAC). Existing\nstate-of-the-art algorithms, such as FACMAC, rely on global reward information,\nwhich may not accurately reflect the quality of individual robots' actions in\ndecentralized systems. We integrate the concept of locality into critic\nlearning, where strongly related robots form partitions during training. Robots\nwithin the same partition have a greater impact on each other, leading to more\nprecise policy evaluation. Additionally, we construct a dependency graph to\ncapture the relationships between robots, facilitating the partitioning\nprocess. This approach mitigates the curse of dimensionality and prevents\nrobots from using irrelevant information. Our method improves existing\nalgorithms by focusing on local rewards and leveraging partition-based learning\nto enhance training efficiency and performance. We evaluate the performance of\nLoc-FACMAC in three environments: Hallway, Multi-cartpole, and\nBounded-Cooperative-Navigation. We explore the impact of partition sizes on the\nperformance and compare the result with baseline MARL algorithms such as LOMAQ,\nFACMAC, and QMIX. The experiments reveal that, if the locality structure is\ndefined properly, Loc-FACMAC outperforms these baseline algorithms up to 108\\%,\nindicating that exploiting the locality structure in the actor-critic framework\nimproves the MARL performance.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18816v1",
    "published_date": "2025-03-24 16:00:16 UTC",
    "updated_date": "2025-03-24 16:00:16 UTC"
  },
  {
    "arxiv_id": "2503.18814v1",
    "title": "Towards Responsible AI Music: an Investigation of Trustworthy Features for Creative Systems",
    "authors": [
      "Jacopo de Berardinis",
      "Lorenzo Porcaro",
      "Albert Meroño-Peñuela",
      "Angelo Cangelosi",
      "Tess Buckley"
    ],
    "abstract": "Generative AI is radically changing the creative arts, by fundamentally\ntransforming the way we create and interact with cultural artefacts. While\noffering unprecedented opportunities for artistic expression and\ncommercialisation, this technology also raises ethical, societal, and legal\nconcerns. Key among these are the potential displacement of human creativity,\ncopyright infringement stemming from vast training datasets, and the lack of\ntransparency, explainability, and fairness mechanisms. As generative systems\nbecome pervasive in this domain, responsible design is crucial. Whilst previous\nwork has tackled isolated aspects of generative systems (e.g., transparency,\nevaluation, data), we take a comprehensive approach, grounding these efforts\nwithin the Ethics Guidelines for Trustworthy Artificial Intelligence produced\nby the High-Level Expert Group on AI appointed by the European Commission - a\nframework for designing responsible AI systems across seven macro requirements.\nFocusing on generative music AI, we illustrate how these requirements can be\ncontextualised for the field, addressing trustworthiness across multiple\ndimensions and integrating insights from the existing literature. We further\npropose a roadmap for operationalising these contextualised requirements,\nemphasising interdisciplinary collaboration and stakeholder engagement. Our\nwork provides a foundation for designing and evaluating responsible music\ngeneration systems, calling for collaboration among AI experts, ethicists,\nlegal scholars, and artists. This manuscript is accompanied by a website:\nhttps://amresearchlab.github.io/raim-framework/.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18814v1",
    "published_date": "2025-03-24 15:54:47 UTC",
    "updated_date": "2025-03-24 15:54:47 UTC"
  },
  {
    "arxiv_id": "2503.18813v1",
    "title": "Defeating Prompt Injections by Design",
    "authors": [
      "Edoardo Debenedetti",
      "Ilia Shumailov",
      "Tianqi Fan",
      "Jamie Hayes",
      "Nicholas Carlini",
      "Daniel Fabian",
      "Christoph Kern",
      "Chongyang Shi",
      "Andreas Terzis",
      "Florian Tramèr"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly deployed in agentic systems\nthat interact with an external environment. However, LLM agents are vulnerable\nto prompt injection attacks when handling untrusted data. In this paper we\npropose CaMeL, a robust defense that creates a protective system layer around\nthe LLM, securing it even when underlying models may be susceptible to attacks.\nTo operate, CaMeL explicitly extracts the control and data flows from the\n(trusted) query; therefore, the untrusted data retrieved by the LLM can never\nimpact the program flow. To further improve security, CaMeL relies on a notion\nof a capability to prevent the exfiltration of private data over unauthorized\ndata flows. We demonstrate effectiveness of CaMeL by solving $67\\%$ of tasks\nwith provable security in AgentDojo [NeurIPS 2024], a recent agentic security\nbenchmark.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18813v1",
    "published_date": "2025-03-24 15:54:10 UTC",
    "updated_date": "2025-03-24 15:54:10 UTC"
  },
  {
    "arxiv_id": "2503.18809v1",
    "title": "Classical Planning with LLM-Generated Heuristics: Challenging the State of the Art with Python Code",
    "authors": [
      "Augusto B. Corrêa",
      "André G. Pereira",
      "Jendrik Seipp"
    ],
    "abstract": "In recent years, large language models (LLMs) have shown remarkable\ncapabilities in various artificial intelligence problems. However, they fail to\nplan reliably, even when prompted with a detailed definition of the planning\ntask. Attempts to improve their planning capabilities, such as chain-of-thought\nprompting, fine-tuning, and explicit \"reasoning\" still yield incorrect plans\nand usually fail to generalize to larger tasks. In this paper, we show how to\nuse LLMs to generate correct plans, even for out-of-distribution tasks of\nincreasing size. For a given planning domain, we ask an LLM to generate several\ndomain-dependent heuristic functions in the form of Python code, evaluate them\non a set of training tasks within a greedy best-first search, and choose the\nstrongest one. The resulting LLM-generated heuristics solve many more unseen\ntest tasks than state-of-the-art domain-independent heuristics for classical\nplanning. They are even competitive with the strongest learning algorithm for\ndomain-dependent planning. These findings are especially remarkable given that\nour proof-of-concept implementation is based on an unoptimized Python planner\nand the baselines all build upon highly optimized C++ code. In some domains,\nthe LLM-generated heuristics expand fewer states than the baselines, revealing\nthat they are not only efficiently computable, but sometimes even more\ninformative than the state-of-the-art heuristics. Overall, our results show\nthat sampling a set of planning heuristic function programs can significantly\nimprove the planning capabilities of LLMs.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18809v1",
    "published_date": "2025-03-24 15:50:20 UTC",
    "updated_date": "2025-03-24 15:50:20 UTC"
  },
  {
    "arxiv_id": "2503.18792v1",
    "title": "REALM: A Dataset of Real-World LLM Use Cases",
    "authors": [
      "Jingwen Cheng",
      "Kshitish Ghate",
      "Wenyue Hua",
      "William Yang Wang",
      "Hong Shen",
      "Fei Fang"
    ],
    "abstract": "Large Language Models, such as the GPT series, have driven significant\nindustrial applications, leading to economic and societal transformations.\nHowever, a comprehensive understanding of their real-world applications remains\nlimited. To address this, we introduce REALM, a dataset of over 94,000 LLM use\ncases collected from Reddit and news articles. REALM captures two key\ndimensions: the diverse applications of LLMs and the demographics of their\nusers. It categorizes LLM applications and explores how users' occupations\nrelate to the types of applications they use. By integrating real-world data,\nREALM offers insights into LLM adoption across different domains, providing a\nfoundation for future research on their evolving societal roles. A dedicated\ndashboard https://realm-e7682.web.app/ presents the data.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "9 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.18792v1",
    "published_date": "2025-03-24 15:39:25 UTC",
    "updated_date": "2025-03-24 15:39:25 UTC"
  },
  {
    "arxiv_id": "2503.18783v2",
    "title": "Frequency Dynamic Convolution for Dense Image Prediction",
    "authors": [
      "Linwei Chen",
      "Lin Gu",
      "Liang Li",
      "Chenggang Yan",
      "Ying Fu"
    ],
    "abstract": "While Dynamic Convolution (DY-Conv) has shown promising performance by\nenabling adaptive weight selection through multiple parallel weights combined\nwith an attention mechanism, the frequency response of these weights tends to\nexhibit high similarity, resulting in high parameter costs but limited\nadaptability. In this work, we introduce Frequency Dynamic Convolution\n(FDConv), a novel approach that mitigates these limitations by learning a fixed\nparameter budget in the Fourier domain. FDConv divides this budget into\nfrequency-based groups with disjoint Fourier indices, enabling the construction\nof frequency-diverse weights without increasing the parameter cost. To further\nenhance adaptability, we propose Kernel Spatial Modulation (KSM) and Frequency\nBand Modulation (FBM). KSM dynamically adjusts the frequency response of each\nfilter at the spatial level, while FBM decomposes weights into distinct\nfrequency bands in the frequency domain and modulates them dynamically based on\nlocal content. Extensive experiments on object detection, segmentation, and\nclassification validate the effectiveness of FDConv. We demonstrate that when\napplied to ResNet-50, FDConv achieves superior performance with a modest\nincrease of +3.6M parameters, outperforming previous methods that require\nsubstantial increases in parameter budgets (e.g., CondConv +90M, KW +76.5M).\nMoreover, FDConv seamlessly integrates into a variety of architectures,\nincluding ConvNeXt, Swin-Transformer, offering a flexible and efficient\nsolution for modern vision tasks. The code is made publicly available at\nhttps://github.com/Linwei-Chen/FDConv.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.18783v2",
    "published_date": "2025-03-24 15:32:06 UTC",
    "updated_date": "2025-03-25 03:09:17 UTC"
  },
  {
    "arxiv_id": "2503.18778v1",
    "title": "The case for delegated AI autonomy for Human AI teaming in healthcare",
    "authors": [
      "Yan Jia",
      "Harriet Evans",
      "Zoe Porter",
      "Simon Graham",
      "John McDermid",
      "Tom Lawton",
      "David Snead",
      "Ibrahim Habli"
    ],
    "abstract": "In this paper we propose an advanced approach to integrating artificial\nintelligence (AI) into healthcare: autonomous decision support. This approach\nallows the AI algorithm to act autonomously for a subset of patient cases\nwhilst serving a supportive role in other subsets of patient cases based on\ndefined delegation criteria. By leveraging the complementary strengths of both\nhumans and AI, it aims to deliver greater overall performance than existing\nhuman-AI teaming models. It ensures safe handling of patient cases and\npotentially reduces clinician review time, whilst being mindful of AI tool\nlimitations. After setting the approach within the context of current human-AI\nteaming models, we outline the delegation criteria and apply them to a specific\nAI-based tool used in histopathology. The potential impact of the approach and\nthe regulatory requirements for its successful implementation are then\ndiscussed.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18778v1",
    "published_date": "2025-03-24 15:26:54 UTC",
    "updated_date": "2025-03-24 15:26:54 UTC"
  },
  {
    "arxiv_id": "2503.18773v1",
    "title": "BitDecoding: Unlocking Tensor Cores for Long-Context LLMs Decoding with Low-Bit KV Cache",
    "authors": [
      "Dayou Du",
      "Shijie Cao",
      "Jianyi Cheng",
      "Ting Cao",
      "Mao Yang"
    ],
    "abstract": "The growing adoption of long-context Large Language Models (LLMs) has\nintroduced significant memory and computational challenges in autoregressive\ndecoding due to the expanding Key-Value (KV) cache. KV cache quantization has\nemerged as a promising solution, with prior work showing that 4-bit or even\n2-bit quantization can maintain model accuracy while reducing memory costs.\nHowever, despite these benefits, preliminary implementations for the low-bit KV\ncache struggle to deliver the expected speedup due to quantization and\ndequantization overheads and the lack of Tensor Cores utilization. In this\nwork, we propose BitDecoding, a GPU-optimized framework that unlocks Tensor\nCores for efficient decoding with low-bit KV cache. Efficiently leveraging\nTensor Cores for low-bit KV cache is challenging due to the dynamic nature of\nKV cache generation at each decoding step. BitDecoding addresses these\nchallenges with a Tensor Cores-Centric BitFusion Scheme that ensures data\nlayout compatibility to enable high utilization of Tensor Cores. Additionally,\nBitDecoding incorporates a warp-efficient parallel decoding kernel and a\nfine-grained asynchronous pipeline, minimizing dequantization overhead and\nimproving computational efficiency. Experiments show that BitDecoding achieves\nup to 7.5x speedup on RTX 4090, 4.8x on A100, and 8.9x on H100, compared to\nFP16 FlashDecoding-v2. It also outperforms the state-of-the-art low-bit KV\ncache implementation (QServe) by up to 4.3x. On LLaMA-3.1-8B with a 128K\nsequence length, BitDecoding reduces single-batch decoding latency by 3x,\ndemonstrating its effectiveness in long-context generation scenarios. The code\nis available at https://github.com/DD-DuDa/BitDecoding.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.CL",
      "cs.PF"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18773v1",
    "published_date": "2025-03-24 15:22:41 UTC",
    "updated_date": "2025-03-24 15:22:41 UTC"
  },
  {
    "arxiv_id": "2503.18762v1",
    "title": "Mechanistic Interpretability of Fine-Tuned Vision Transformers on Distorted Images: Decoding Attention Head Behavior for Transparent and Trustworthy AI",
    "authors": [
      "Nooshin Bahador"
    ],
    "abstract": "Mechanistic interpretability improves the safety, reliability, and robustness\nof large AI models. This study examined individual attention heads in vision\ntransformers (ViTs) fine tuned on distorted 2D spectrogram images containing\nnon relevant content (axis labels, titles, color bars). By introducing\nextraneous features, the study analyzed how transformer components processed\nunrelated information, using mechanistic interpretability to debug issues and\nreveal insights into transformer architectures. Attention maps assessed head\ncontributions across layers. Heads in early layers (1 to 3) showed minimal task\nimpact with ablation increased MSE loss slightly ({\\mu}=0.11%, {\\sigma}=0.09%),\nindicating focus on less critical low level features. In contrast, deeper heads\n(e.g., layer 6) caused a threefold higher loss increase ({\\mu}=0.34%,\n{\\sigma}=0.02%), demonstrating greater task importance. Intermediate layers (6\nto 11) exhibited monosemantic behavior, attending exclusively to chirp regions.\nSome early heads (1 to 4) were monosemantic but non task relevant (e.g. text\ndetectors, edge or corner detectors). Attention maps distinguished monosemantic\nheads (precise chirp localization) from polysemantic heads (multiple irrelevant\nregions). These findings revealed functional specialization in ViTs, showing\nhow heads processed relevant vs. extraneous information. By decomposing\ntransformers into interpretable components, this work enhanced model\nunderstanding, identified vulnerabilities, and advanced safer, more transparent\nAI.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.18762v1",
    "published_date": "2025-03-24 15:11:24 UTC",
    "updated_date": "2025-03-24 15:11:24 UTC"
  },
  {
    "arxiv_id": "2503.18755v1",
    "title": "EgoSurgery-HTS: A Dataset for Egocentric Hand-Tool Segmentation in Open Surgery Videos",
    "authors": [
      "Nathan Darjana",
      "Ryo Fujii",
      "Hideo Saito",
      "Hiroki Kajita"
    ],
    "abstract": "Egocentric open-surgery videos capture rich, fine-grained details essential\nfor accurately modeling surgical procedures and human behavior in the operating\nroom. A detailed, pixel-level understanding of hands and surgical tools is\ncrucial for interpreting a surgeon's actions and intentions. We introduce\nEgoSurgery-HTS, a new dataset with pixel-wise annotations and a benchmark suite\nfor segmenting surgical tools, hands, and interacting tools in egocentric\nopen-surgery videos. Specifically, we provide a labeled dataset for (1) tool\ninstance segmentation of 14 distinct surgical tools, (2) hand instance\nsegmentation, and (3) hand-tool segmentation to label hands and the tools they\nmanipulate. Using EgoSurgery-HTS, we conduct extensive evaluations of\nstate-of-the-art segmentation methods and demonstrate significant improvements\nin the accuracy of hand and hand-tool segmentation in egocentric open-surgery\nvideos compared to existing datasets. The dataset will be released at\nhttps://github.com/Fujiry0/EgoSurgery.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18755v1",
    "published_date": "2025-03-24 15:04:32 UTC",
    "updated_date": "2025-03-24 15:04:32 UTC"
  },
  {
    "arxiv_id": "2503.18751v1",
    "title": "Construction Identification and Disambiguation Using BERT: A Case Study of NPN",
    "authors": [
      "Wesley Scivetti",
      "Nathan Schneider"
    ],
    "abstract": "Construction Grammar hypothesizes that knowledge of a language consists\nchiefly of knowledge of form-meaning pairs (''constructions'') that include\nvocabulary, general grammar rules, and even idiosyncratic patterns. Recent work\nhas shown that transformer language models represent at least some\nconstructional patterns, including ones where the construction is rare overall.\nIn this work, we probe BERT's representation of the form and meaning of a minor\nconstruction of English, the NPN (noun-preposition-noun) construction --\nexhibited in such expressions as face to face and day to day -- which is known\nto be polysemous. We construct a benchmark dataset of semantically annotated\ncorpus instances (including distractors that superficially resemble the\nconstruction). With this dataset, we train and evaluate probing classifiers.\nThey achieve decent discrimination of the construction from distractors, as\nwell as sense disambiguation among true instances of the construction,\nrevealing that BERT embeddings carry indications of the construction's\nsemantics. Moreover, artificially permuting the word order of true construction\ninstances causes them to be rejected, indicating sensitivity to matters of\nform. We conclude that BERT does latently encode at least some knowledge of the\nNPN construction going beyond a surface syntactic pattern and lexical cues.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages, ACL long-paper format (preprint)",
    "pdf_url": "http://arxiv.org/pdf/2503.18751v1",
    "published_date": "2025-03-24 14:59:39 UTC",
    "updated_date": "2025-03-24 14:59:39 UTC"
  },
  {
    "arxiv_id": "2503.18706v1",
    "title": "Energy-Efficient Dynamic Training and Inference for GNN-Based Network Modeling",
    "authors": [
      "Chetna Singhal",
      "Yassine Hadjadj-Aoul"
    ],
    "abstract": "Efficient network modeling is essential for resource optimization and network\nplanning in next-generation large-scale complex networks. Traditional\napproaches, such as queuing theory-based modeling and packet-based simulators,\ncan be inefficient due to the assumption made and the computational expense,\nrespectively. To address these challenges, we propose an innovative\nenergy-efficient dynamic orchestration of Graph Neural Networks (GNN) based\nmodel training and inference framework for context-aware network modeling and\npredictions. We have developed a low-complexity solution framework, QAG, that\nis a Quantum approximation optimization (QAO) algorithm for Adaptive\norchestration of GNN-based network modeling. We leverage the tripartite graph\nmodel to represent a multi-application system with many compute nodes.\nThereafter, we apply the constrained graph-cutting using QAO to find the\nfeasible energy-efficient configurations of the GNN-based model and deploying\nthem on the available compute nodes to meet the network modeling application\nrequirements. The proposed QAG scheme closely matches the optimum and offers\natleast a 50% energy saving while meeting the application requirements with 60%\nlower churn-rate.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.ET",
      "cs.LG"
    ],
    "primary_category": "cs.NI",
    "comment": "Accepted in IEEE WCNC 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.18706v1",
    "published_date": "2025-03-24 14:17:57 UTC",
    "updated_date": "2025-03-24 14:17:57 UTC"
  },
  {
    "arxiv_id": "2503.18684v1",
    "title": "Efficient Continual Adaptation of Pretrained Robotic Policy with Online Meta-Learned Adapters",
    "authors": [
      "Ruiqi Zhu",
      "Endong Sun",
      "Guanhe Huang",
      "Oya Celiktutan"
    ],
    "abstract": "Continual adaptation is essential for general autonomous agents. For example,\na household robot pretrained with a repertoire of skills must still adapt to\nunseen tasks specific to each household. Motivated by this, building upon\nparameter-efficient fine-tuning in language models, prior works have explored\nlightweight adapters to adapt pretrained policies, which can preserve learned\nfeatures from the pretraining phase and demonstrate good adaptation\nperformances. However, these approaches treat task learning separately,\nlimiting knowledge transfer between tasks. In this paper, we propose Online\nMeta-Learned adapters (OMLA). Instead of applying adapters directly, OMLA can\nfacilitate knowledge transfer from previously learned tasks to current learning\ntasks through a novel meta-learning objective. Extensive experiments in both\nsimulated and real-world environments demonstrate that OMLA can lead to better\nadaptation performances compared to the baseline methods. The project link:\nhttps://ricky-zhu.github.io/OMLA/.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Project link: https://ricky-zhu.github.io/OMLA/",
    "pdf_url": "http://arxiv.org/pdf/2503.18684v1",
    "published_date": "2025-03-24 13:55:47 UTC",
    "updated_date": "2025-03-24 13:55:47 UTC"
  },
  {
    "arxiv_id": "2503.18681v2",
    "title": "Commander-GPT: Fully Unleashing the Sarcasm Detection Capability of Multi-Modal Large Language Models",
    "authors": [
      "Yazhou Zhang",
      "Chunwang Zou",
      "Bo Wang",
      "Jing Qin"
    ],
    "abstract": "Sarcasm detection, as a crucial research direction in the field of Natural\nLanguage Processing (NLP), has attracted widespread attention. Traditional\nsarcasm detection tasks have typically focused on single-modal approaches\n(e.g., text), but due to the implicit and subtle nature of sarcasm, such\nmethods often fail to yield satisfactory results. In recent years, researchers\nhave shifted the focus of sarcasm detection to multi-modal approaches. However,\neffectively leveraging multi-modal information to accurately identify sarcastic\ncontent remains a challenge that warrants further exploration. Leveraging the\npowerful integrated processing capabilities of Multi-Modal Large Language\nModels (MLLMs) for various information sources, we propose an innovative\nmulti-modal Commander-GPT framework. Inspired by military strategy, we first\ndecompose the sarcasm detection task into six distinct sub-tasks. A central\ncommander (decision-maker) then assigns the best-suited large language model to\naddress each specific sub-task. Ultimately, the detection results from each\nmodel are aggregated to identify sarcasm. We conducted extensive experiments on\nMMSD and MMSD 2.0, utilizing four multi-modal large language models and six\nprompting strategies. Our experiments demonstrate that our approach achieves\nstate-of-the-art performance, with a 19.3% improvement in F1 score, without\nnecessitating fine-tuning or ground-truth rationales.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18681v2",
    "published_date": "2025-03-24 13:53:00 UTC",
    "updated_date": "2025-03-25 04:33:15 UTC"
  },
  {
    "arxiv_id": "2503.18673v2",
    "title": "Any6D: Model-free 6D Pose Estimation of Novel Objects",
    "authors": [
      "Taeyeop Lee",
      "Bowen Wen",
      "Minjun Kang",
      "Gyuree Kang",
      "In So Kweon",
      "Kuk-Jin Yoon"
    ],
    "abstract": "We introduce Any6D, a model-free framework for 6D object pose estimation that\nrequires only a single RGB-D anchor image to estimate both the 6D pose and size\nof unknown objects in novel scenes. Unlike existing methods that rely on\ntextured 3D models or multiple viewpoints, Any6D leverages a joint object\nalignment process to enhance 2D-3D alignment and metric scale estimation for\nimproved pose accuracy. Our approach integrates a render-and-compare strategy\nto generate and refine pose hypotheses, enabling robust performance in\nscenarios with occlusions, non-overlapping views, diverse lighting conditions,\nand large cross-environment variations. We evaluate our method on five\nchallenging datasets: REAL275, Toyota-Light, HO3D, YCBINEOAT, and LM-O,\ndemonstrating its effectiveness in significantly outperforming state-of-the-art\nmethods for novel object pose estimation. Project page:\nhttps://taeyeop.com/any6d",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2025, Project Page: https://taeyeop.com/any6d",
    "pdf_url": "http://arxiv.org/pdf/2503.18673v2",
    "published_date": "2025-03-24 13:46:21 UTC",
    "updated_date": "2025-03-25 06:18:47 UTC"
  },
  {
    "arxiv_id": "2503.18666v1",
    "title": "AgentSpec: Customizable Runtime Enforcement for Safe and Reliable LLM Agents",
    "authors": [
      "Haoyu Wang",
      "Christopher M. Poskitt",
      "Jun Sun"
    ],
    "abstract": "Agents built on LLMs are increasingly deployed across diverse domains,\nautomating complex decision-making and task execution. However, their autonomy\nintroduces safety risks, including security vulnerabilities, legal violations,\nand unintended harmful actions. Existing mitigation methods, such as\nmodel-based safeguards and early enforcement strategies, fall short in\nrobustness, interpretability, and adaptability. To address these challenges, we\npropose AgentSpec, a lightweight domain-specific language for specifying and\nenforcing runtime constraints on LLM agents. With AgentSpec, users define\nstructured rules that incorporate triggers, predicates, and enforcement\nmechanisms, ensuring agents operate within predefined safety boundaries. We\nimplement AgentSpec across multiple domains, including code execution, embodied\nagents, and autonomous driving, demonstrating its adaptability and\neffectiveness. Our evaluation shows that AgentSpec successfully prevents unsafe\nexecutions in over 90% of code agent cases, eliminates all hazardous actions in\nembodied agent tasks, and enforces 100% compliance by autonomous vehicles\n(AVs). Despite its strong safety guarantees, AgentSpec remains computationally\nlightweight, with overheads in milliseconds. By combining interpretability,\nmodularity, and efficiency, AgentSpec provides a practical and scalable\nsolution for enforcing LLM agent safety across diverse applications. We also\nautomate the generation of rules using LLMs and assess their effectiveness. Our\nevaluation shows that the rules generated by OpenAI o1 achieve a precision of\n95.56% and recall of 70.96% for embodied agents, successfully identifying\n87.26% of the risky code, and prevent AVs from breaking laws in 5 out of 8\nscenarios.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18666v1",
    "published_date": "2025-03-24 13:31:48 UTC",
    "updated_date": "2025-03-24 13:31:48 UTC"
  },
  {
    "arxiv_id": "2503.18641v1",
    "title": "From Fragment to One Piece: A Survey on AI-Driven Graphic Design",
    "authors": [
      "Xingxing Zou",
      "Wen Zhang",
      "Nanxuan Zhao"
    ],
    "abstract": "This survey provides a comprehensive overview of the advancements in\nArtificial Intelligence in Graphic Design (AIGD), focusing on integrating AI\ntechniques to support design interpretation and enhance the creative process.\nWe categorize the field into two primary directions: perception tasks, which\ninvolve understanding and analyzing design elements, and generation tasks,\nwhich focus on creating new design elements and layouts. The survey covers\nvarious subtasks, including visual element perception and generation, aesthetic\nand semantic understanding, layout analysis, and generation. We highlight the\nrole of large language models and multimodal approaches in bridging the gap\nbetween localized visual features and global design intent. Despite significant\nprogress, challenges remain to understanding human intent, ensuring\ninterpretability, and maintaining control over multilayered compositions. This\nsurvey serves as a guide for researchers, providing information on the current\nstate of AIGD and potential future\ndirections\\footnote{https://github.com/zhangtianer521/excellent\\_Intelligent\\_graphic\\_design}.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18641v1",
    "published_date": "2025-03-24 13:05:09 UTC",
    "updated_date": "2025-03-24 13:05:09 UTC"
  },
  {
    "arxiv_id": "2503.18629v1",
    "title": "Towards Human-Understandable Multi-Dimensional Concept Discovery",
    "authors": [
      "Arne Grobrügge",
      "Niklas Kühl",
      "Gerhard Satzger",
      "Philipp Spitzer"
    ],
    "abstract": "Concept-based eXplainable AI (C-XAI) aims to overcome the limitations of\ntraditional saliency maps by converting pixels into human-understandable\nconcepts that are consistent across an entire dataset. A crucial aspect of\nC-XAI is completeness, which measures how well a set of concepts explains a\nmodel's decisions. Among C-XAI methods, Multi-Dimensional Concept Discovery\n(MCD) effectively improves completeness by breaking down the CNN latent space\ninto distinct and interpretable concept subspaces. However, MCD's explanations\ncan be difficult for humans to understand, raising concerns about their\npractical utility. To address this, we propose Human-Understandable\nMulti-dimensional Concept Discovery (HU-MCD). HU-MCD uses the Segment Anything\nModel for concept identification and implements a CNN-specific input masking\ntechnique to reduce noise introduced by traditional masking methods. These\nchanges to MCD, paired with the completeness relation, enable HU-MCD to enhance\nconcept understandability while maintaining explanation faithfulness. Our\nexperiments, including human subject studies, show that HU-MCD provides more\nprecise and reliable explanations than existing C-XAI methods. The code is\navailable at https://github.com/grobruegge/hu-mcd.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18629v1",
    "published_date": "2025-03-24 12:45:52 UTC",
    "updated_date": "2025-03-24 12:45:52 UTC"
  },
  {
    "arxiv_id": "2503.18627v1",
    "title": "Dig2DIG: Dig into Diffusion Information Gains for Image Fusion",
    "authors": [
      "Bing Cao",
      "Baoshuo Cai",
      "Changqing Zhang",
      "Qinghua Hu"
    ],
    "abstract": "Image fusion integrates complementary information from multi-source images to\ngenerate more informative results. Recently, the diffusion model, which\ndemonstrates unprecedented generative potential, has been explored in image\nfusion. However, these approaches typically incorporate predefined multimodal\nguidance into diffusion, failing to capture the dynamically changing\nsignificance of each modality, while lacking theoretical guarantees. To address\nthis issue, we reveal a significant spatio-temporal imbalance in image\ndenoising; specifically, the diffusion model produces dynamic information gains\nin different image regions with denoising steps. Based on this observation, we\nDig into the Diffusion Information Gains (Dig2DIG) and theoretically derive a\ndiffusion-based dynamic image fusion framework that provably reduces the upper\nbound of the generalization error. Accordingly, we introduce diffusion\ninformation gains (DIG) to quantify the information contribution of each\nmodality at different denoising steps, thereby providing dynamic guidance\nduring the fusion process. Extensive experiments on multiple fusion scenarios\nconfirm that our method outperforms existing diffusion-based approaches in\nterms of both fusion quality and inference efficiency.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18627v1",
    "published_date": "2025-03-24 12:43:11 UTC",
    "updated_date": "2025-03-24 12:43:11 UTC"
  },
  {
    "arxiv_id": "2503.18612v1",
    "title": "Adventurer: Exploration with BiGAN for Deep Reinforcement Learning",
    "authors": [
      "Yongshuai Liu",
      "Xin Liu"
    ],
    "abstract": "Recent developments in deep reinforcement learning have been very successful\nin learning complex, previously intractable problems. Sample efficiency and\nlocal optimality, however, remain significant challenges. To address these\nchallenges, novelty-driven exploration strategies have emerged and shown\npromising potential. Unfortunately, no single algorithm outperforms all others\nin all tasks and most of them struggle with tasks with high-dimensional and\ncomplex observations. In this work, we propose Adventurer, a novelty-driven\nexploration algorithm that is based on Bidirectional Generative Adversarial\nNetworks (BiGAN), where BiGAN is trained to estimate state novelty.\nIntuitively, a generator that has been trained on the distribution of visited\nstates should only be able to generate a state coming from the distribution of\nvisited states. As a result, novel states using the generator to reconstruct\ninput states from certain latent representations would lead to larger\nreconstruction errors. We show that BiGAN performs well in estimating state\nnovelty for complex observations. This novelty estimation method can be\ncombined with intrinsic-reward-based exploration. Our empirical results show\nthat Adventurer produces competitive results on a range of popular benchmark\ntasks, including continuous robotic manipulation tasks (e.g. Mujoco robotics)\nand high-dimensional image-based tasks (e.g. Atari games).",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at Applied Intelligence",
    "pdf_url": "http://arxiv.org/pdf/2503.18612v1",
    "published_date": "2025-03-24 12:13:24 UTC",
    "updated_date": "2025-03-24 12:13:24 UTC"
  },
  {
    "arxiv_id": "2503.18607v1",
    "title": "Reinforcement Learning in Switching Non-Stationary Markov Decision Processes: Algorithms and Convergence Analysis",
    "authors": [
      "Mohsen Amiri",
      "Sindri Magnússon"
    ],
    "abstract": "Reinforcement learning in non-stationary environments is challenging due to\nabrupt and unpredictable changes in dynamics, often causing traditional\nalgorithms to fail to converge. However, in many real-world cases,\nnon-stationarity has some structure that can be exploited to develop algorithms\nand facilitate theoretical analysis. We introduce one such structure, Switching\nNon-Stationary Markov Decision Processes (SNS-MDP), where environments switch\nover time based on an underlying Markov chain. Under a fixed policy, the value\nfunction of an SNS-MDP admits a closed-form solution determined by the Markov\nchain's statistical properties, and despite the inherent non-stationarity,\nTemporal Difference (TD) learning methods still converge to the correct value\nfunction. Furthermore, policy improvement can be performed, and it is shown\nthat policy iteration converges to the optimal policy. Moreover, since\nQ-learning converges to the optimal Q-function, it likewise yields the\ncorresponding optimal policy. To illustrate the practical advantages of\nSNS-MDPs, we present an example in communication networks where channel noise\nfollows a Markovian pattern, demonstrating how this framework can effectively\nguide decision-making in complex, time-varying contexts.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18607v1",
    "published_date": "2025-03-24 12:05:30 UTC",
    "updated_date": "2025-03-24 12:05:30 UTC"
  },
  {
    "arxiv_id": "2503.18595v1",
    "title": "Adaptive Unimodal Regulation for Balanced Multimodal Information Acquisition",
    "authors": [
      "Chengxiang Huang",
      "Yake Wei",
      "Zequn Yang",
      "Di Hu"
    ],
    "abstract": "Sensory training during the early ages is vital for human development.\nInspired by this cognitive phenomenon, we observe that the early training stage\nis also important for the multimodal learning process, where dataset\ninformation is rapidly acquired. We refer to this stage as the prime learning\nwindow. However, based on our observation, this prime learning window in\nmultimodal learning is often dominated by information-sufficient modalities,\nwhich in turn suppresses the information acquisition of\ninformation-insufficient modalities. To address this issue, we propose\nInformation Acquisition Regulation (InfoReg), a method designed to balance\ninformation acquisition among modalities. Specifically, InfoReg slows down the\ninformation acquisition process of information-sufficient modalities during the\nprime learning window, which could promote information acquisition of\ninformation-insufficient modalities. This regulation enables a more balanced\nlearning process and improves the overall performance of the multimodal\nnetwork. Experiments show that InfoReg outperforms related multimodal\nimbalanced methods across various datasets, achieving superior model\nperformance. The code is available at\nhttps://github.com/GeWu-Lab/InfoReg_CVPR2025.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "10pages, 16 figures, CVPR2025",
    "pdf_url": "http://arxiv.org/pdf/2503.18595v1",
    "published_date": "2025-03-24 11:52:57 UTC",
    "updated_date": "2025-03-24 11:52:57 UTC"
  },
  {
    "arxiv_id": "2503.18594v1",
    "title": "ClinText-SP and RigoBERTa Clinical: a new set of open resources for Spanish Clinical NLP",
    "authors": [
      "Guillem García Subies",
      "Álvaro Barbero Jiménez",
      "Paloma Martínez Fernández"
    ],
    "abstract": "We present a novel contribution to Spanish clinical natural language\nprocessing by introducing the largest publicly available clinical corpus,\nClinText-SP, along with a state-of-the-art clinical encoder language model,\nRigoBERTa Clinical. Our corpus was meticulously curated from diverse open\nsources, including clinical cases from medical journals and annotated corpora\nfrom shared tasks, providing a rich and diverse dataset that was previously\ndifficult to access. RigoBERTa Clinical, developed through domain-adaptive\npretraining on this comprehensive dataset, significantly outperforms existing\nmodels on multiple clinical NLP benchmarks. By publicly releasing both the\ndataset and the model, we aim to empower the research community with robust\nresources that can drive further advancements in clinical NLP and ultimately\ncontribute to improved healthcare applications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18594v1",
    "published_date": "2025-03-24 11:52:17 UTC",
    "updated_date": "2025-03-24 11:52:17 UTC"
  },
  {
    "arxiv_id": "2503.18592v1",
    "title": "The Role of Artificial Intelligence in Enhancing Insulin Recommendations and Therapy Outcomes",
    "authors": [
      "Maria Panagiotou",
      "Knut Stroemmen",
      "Lorenzo Brigato",
      "Bastiaan E. de Galan",
      "Stavroula Mougiakakou"
    ],
    "abstract": "The growing worldwide incidence of diabetes requires more effective\napproaches for managing blood glucose levels. Insulin delivery systems have\nadvanced significantly, with artificial intelligence (AI) playing a key role in\nimproving their precision and adaptability. AI algorithms, particularly those\nbased on reinforcement learning, allow for personalised insulin dosing by\ncontinuously adapting to an individual's responses. Despite these advancements,\nchallenges such as data privacy, algorithm transparency, and accessibility\nstill need to be addressed. Continued progress and validation in AI-driven\ninsulin delivery systems promise to improve therapy outcomes further, offering\npeople more effective and individualised management of their diabetes. This\npaper presents an overview of current strategies, key challenges, and future\ndirections.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "physics.med-ph"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18592v1",
    "published_date": "2025-03-24 11:50:14 UTC",
    "updated_date": "2025-03-24 11:50:14 UTC"
  },
  {
    "arxiv_id": "2503.18578v1",
    "title": "Galaxy Walker: Geometry-aware VLMs For Galaxy-scale Understanding",
    "authors": [
      "Tianyu Chen",
      "Xingcheng Fu",
      "Yisen Gao",
      "Haodong Qian",
      "Yuecen Wei",
      "Kun Yan",
      "Haoyi Zhou",
      "Jianxin Li"
    ],
    "abstract": "Modern vision-language models (VLMs) develop patch embedding and convolution\nbackbone within vector space, especially Euclidean ones, at the very founding.\nWhen expanding VLMs to a galaxy scale for understanding astronomical phenomena,\nthe integration of spherical space for planetary orbits and hyperbolic spaces\nfor black holes raises two formidable challenges. a) The current pre-training\nmodel is confined to Euclidean space rather than a comprehensive geometric\nembedding. b) The predominant architecture lacks suitable backbones for\nanisotropic physical geometries. In this paper, we introduced Galaxy-Walker, a\ngeometry-aware VLM, for the universe-level vision understanding tasks. We\nproposed the geometry prompt that generates geometry tokens by random walks\nacross diverse spaces on a multi-scale physical graph, along with a geometry\nadapter that compresses and reshapes the space anisotropy in a\nmixture-of-experts manner. Extensive experiments demonstrate the effectiveness\nof our approach, with Galaxy-Walker achieving state-of-the-art performance in\nboth galaxy property estimation ($R^2$ scores up to $0.91$) and morphology\nclassification tasks (up to $+0.17$ F1 improvement in challenging features),\nsignificantly outperforming both domain-specific models and general-purpose\nVLMs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18578v1",
    "published_date": "2025-03-24 11:35:56 UTC",
    "updated_date": "2025-03-24 11:35:56 UTC"
  },
  {
    "arxiv_id": "2503.18572v1",
    "title": "Identifying and Characterising Higher Order Interactions in Mobility Networks Using Hypergraphs",
    "authors": [
      "Prathyush Sambaturu",
      "Bernardo Gutierrez",
      "Moritz U. G. Kraemer"
    ],
    "abstract": "Understanding human mobility is essential for applications ranging from urban\nplanning to public health. Traditional mobility models such as flow networks\nand colocation matrices capture only pairwise interactions between discrete\nlocations, overlooking higher-order relationships among locations (i.e.,\nmobility flow among two or more locations). To address this, we propose\nco-visitation hypergraphs, a model that leverages temporal observation windows\nto extract group interactions between locations from individual mobility\ntrajectory data. Using frequent pattern mining, our approach constructs\nhypergraphs that capture dynamic mobility behaviors across different spatial\nand temporal scales. We validate our method on a publicly available mobility\ndataset and demonstrate its effectiveness in analyzing city-scale mobility\npatterns, detecting shifts during external disruptions such as extreme weather\nevents, and examining how a location's connectivity (degree) relates to the\nnumber of points of interest (POIs) within it. Our results demonstrate that our\nhypergraph-based mobility analysis framework is a valuable tool with potential\napplications in diverse fields such as public health, disaster resilience, and\nurban planning.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.DB",
      "cs.DM",
      "math.CO"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18572v1",
    "published_date": "2025-03-24 11:29:06 UTC",
    "updated_date": "2025-03-24 11:29:06 UTC"
  },
  {
    "arxiv_id": "2503.18569v1",
    "title": "Anchor-based oversampling for imbalanced tabular data via contrastive and adversarial learning",
    "authors": [
      "Hadi Mohammadi",
      "Ehsan Nazerfard",
      "Mostafa Haghir Chehreghani"
    ],
    "abstract": "Imbalanced data represent a distribution with more frequencies of one class\n(majority) than the other (minority). This phenomenon occurs across various\ndomains, such as security, medical care and human activity. In imbalanced\nlearning, classification algorithms are typically inclined to classify the\nmajority class accurately, resulting in artificially high accuracy rates. As a\nresult, many minority samples are mistakenly labelled as majority-class\ninstances, resulting in a bias that benefits the majority class. This study\npresents a framework based on boundary anchor samples to tackle the imbalance\nlearning challenge. First, we select and use anchor samples to train a\nmultilayer perceptron (MLP) classifier, which acts as a prior knowledge model\nand aids the adversarial and contrastive learning procedures. Then, we designed\na novel deep generative model called Anchor Stabilized Conditional Generative\nAdversarial Network or Anch-SCGAN in short. Anch-SCGAN is supported with two\ngenerators for the minority and majority classes and a discriminator\nincorporating additional class-specific information from the pre-trained\nfeature extractor MLP. In addition, we facilitate the generator's training\nprocedure in two ways. First, we define a new generator loss function based on\nreprocessed anchor samples and contrastive learning. Second, we apply a scoring\nstrategy to stabilize the adversarial training part in generators. We train\nAnch-SCGAN and further finetune it with anchor samples to improve the precision\nof the generated samples. Our experiments on 16 real-world imbalanced datasets\nillustrate that Anch-SCGAN outperforms the renowned methods in imbalanced\nlearning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18569v1",
    "published_date": "2025-03-24 11:25:21 UTC",
    "updated_date": "2025-03-24 11:25:21 UTC"
  },
  {
    "arxiv_id": "2503.18565v1",
    "title": "Distil-xLSTM: Learning Attention Mechanisms through Recurrent Structures",
    "authors": [
      "Abdoul Majid O. Thiombiano",
      "Brahim Hnich",
      "Ali Ben Mrad",
      "Mohamed Wiem Mkaouer"
    ],
    "abstract": "The current era of Natural Language Processing (NLP) is dominated by\nTransformer models. However, novel architectures relying on recurrent\nmechanisms, such as xLSTM and Mamba, have been proposed as alternatives to\nattention-based models. Although computation is done differently than with the\nattention mechanism mechanism, these recurrent models yield good results and\nsometimes even outperform state-of-the-art attention-based models. In this\nwork, we propose Distil-xLSTM, an xLSTM-based Small Language Model (SLM)\ntrained by distilling knowledge from a Large Language Model (LLM) that shows\npromising results while being compute and scale efficient. Our Distil-xLSTM\nfocuses on approximating a transformer-based model attention parametrization\nusing its recurrent sequence mixing components and shows good results with\nminimal training.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18565v1",
    "published_date": "2025-03-24 11:18:25 UTC",
    "updated_date": "2025-03-24 11:18:25 UTC"
  },
  {
    "arxiv_id": "2503.18562v1",
    "title": "Self-Reported Confidence of Large Language Models in Gastroenterology: Analysis of Commercial, Open-Source, and Quantized Models",
    "authors": [
      "Nariman Naderi",
      "Seyed Amir Ahmad Safavi-Naini",
      "Thomas Savage",
      "Zahra Atf",
      "Peter Lewis",
      "Girish Nadkarni",
      "Ali Soroush"
    ],
    "abstract": "This study evaluated self-reported response certainty across several large\nlanguage models (GPT, Claude, Llama, Phi, Mistral, Gemini, Gemma, and Qwen)\nusing 300 gastroenterology board-style questions. The highest-performing models\n(GPT-o1 preview, GPT-4o, and Claude-3.5-Sonnet) achieved Brier scores of\n0.15-0.2 and AUROC of 0.6. Although newer models demonstrated improved\nperformance, all exhibited a consistent tendency towards overconfidence.\nUncertainty estimation presents a significant challenge to the safe use of LLMs\nin healthcare. Keywords: Large Language Models; Confidence Elicitation;\nArtificial Intelligence; Gastroenterology; Uncertainty Quantification",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "35 pages, 5 figures, 1 table, 7 supplementary figures",
    "pdf_url": "http://arxiv.org/pdf/2503.18562v1",
    "published_date": "2025-03-24 11:16:41 UTC",
    "updated_date": "2025-03-24 11:16:41 UTC"
  },
  {
    "arxiv_id": "2503.18552v1",
    "title": "EvAnimate: Event-conditioned Image-to-Video Generation for Human Animation",
    "authors": [
      "Qiang Qu",
      "Ming Li",
      "Xiaoming Chen",
      "Tongliang Liu"
    ],
    "abstract": "Conditional human animation transforms a static reference image into a\ndynamic sequence by applying motion cues such as poses. These motion cues are\ntypically derived from video data but are susceptible to limitations including\nlow temporal resolution, motion blur, overexposure, and inaccuracies under\nlow-light conditions. In contrast, event cameras provide data streams with\nexceptionally high temporal resolution, a wide dynamic range, and inherent\nresistance to motion blur and exposure issues. In this work, we propose\nEvAnimate, a framework that leverages event streams as motion cues to animate\nstatic human images. Our approach employs a specialized event representation\nthat transforms asynchronous event streams into 3-channel slices with\ncontrollable slicing rates and appropriate slice density, ensuring\ncompatibility with diffusion models. Subsequently, a dual-branch architecture\ngenerates high-quality videos by harnessing the inherent motion dynamics of the\nevent streams, thereby enhancing both video quality and temporal consistency.\nSpecialized data augmentation strategies further enhance cross-person\ngeneralization. Finally, we establish a new benchmarking, including simulated\nevent data for training and validation, and a real-world event dataset\ncapturing human actions under normal and extreme scenarios. The experiment\nresults demonstrate that EvAnimate achieves high temporal fidelity and robust\nperformance in scenarios where traditional video-derived cues fall short.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18552v1",
    "published_date": "2025-03-24 11:05:41 UTC",
    "updated_date": "2025-03-24 11:05:41 UTC"
  },
  {
    "arxiv_id": "2503.18551v1",
    "title": "Discriminative protein sequence modelling with Latent Space Diffusion",
    "authors": [
      "Eoin Quinn",
      "Ghassene Jebali",
      "Maxime Seince",
      "Oliver Bent"
    ],
    "abstract": "We explore a framework for protein sequence representation learning that\ndecomposes the task between manifold learning and distributional modelling.\nSpecifically we present a Latent Space Diffusion architecture which combines a\nprotein sequence autoencoder with a denoising diffusion model operating on its\nlatent space. We obtain a one-parameter family of learned representations from\nthe diffusion model, along with the autoencoder's latent representation. We\npropose and evaluate two autoencoder architectures: a homogeneous model forcing\namino acids of the same type to be identically distributed in the latent space,\nand an inhomogeneous model employing a noise-based variant of masking. As a\nbaseline we take a latent space learned by masked language modelling, and\nevaluate discriminative capability on a range of protein property prediction\ntasks. Our finding is twofold: the diffusion models trained on both our\nproposed variants display higher discriminative power than the one trained on\nthe masked language model baseline, none of the diffusion representations\nachieve the performance of the masked language model embeddings themselves.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18551v1",
    "published_date": "2025-03-24 11:03:57 UTC",
    "updated_date": "2025-03-24 11:03:57 UTC"
  },
  {
    "arxiv_id": "2503.18549v1",
    "title": "RLCAD: Reinforcement Learning Training Gym for Revolution Involved CAD Command Sequence Generation",
    "authors": [
      "Xiaolong Yin",
      "Xingyu Lu",
      "Jiahang Shen",
      "Jingzhe Ni",
      "Hailong Li",
      "Ruofeng Tong",
      "Min Tang",
      "Peng Du"
    ],
    "abstract": "A CAD command sequence is a typical parametric design paradigm in 3D CAD\nsystems where a model is constructed by overlaying 2D sketches with operations\nsuch as extrusion, revolution, and Boolean operations. Although there is\ngrowing academic interest in the automatic generation of command sequences,\nexisting methods and datasets only support operations such as 2D sketching,\nextrusion,and Boolean operations. This limitation makes it challenging to\nrepresent more complex geometries. In this paper, we present a reinforcement\nlearning (RL) training environment (gym) built on a CAD geometric engine. Given\nan input boundary representation (B-Rep) geometry, the policy network in the RL\nalgorithm generates an action. This action, along with previously generated\nactions, is processed within the gym to produce the corresponding CAD geometry,\nwhich is then fed back into the policy network. The rewards, determined by the\ndifference between the generated and target geometries within the gym, are used\nto update the RL network. Our method supports operations beyond sketches,\nBoolean, and extrusion, including revolution operations. With this training\ngym, we achieve state-of-the-art (SOTA) quality in generating command sequences\nfrom B-Rep geometries. In addition, our method can significantly improve the\nefficiency of command sequence generation by a factor of 39X compared with the\nprevious training gym.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18549v1",
    "published_date": "2025-03-24 11:01:05 UTC",
    "updated_date": "2025-03-24 11:01:05 UTC"
  },
  {
    "arxiv_id": "2503.18542v1",
    "title": "An Identity and Interaction Based Network Forensic Analysis",
    "authors": [
      "Nathan Clarke",
      "Gaseb Alotibi",
      "Dany Joy",
      "Fudong Li",
      "Steven Furnell",
      "Ali Alshumrani",
      "Hussan Mohammed"
    ],
    "abstract": "In todays landscape of increasing electronic crime, network forensics plays a\npivotal role in digital investigations. It aids in understanding which systems\nto analyse and as a supplement to support evidence found through more\ntraditional computer based investigations. However, the nature and\nfunctionality of the existing Network Forensic Analysis Tools (NFATs) fall\nshort compared to File System Forensic Analysis Tools (FS FATs) in providing\nusable data. The analysis tends to focus upon IP addresses, which are not\nsynonymous with user identities, a point of significant interest to\ninvestigators. This paper presents several experiments designed to create a\nnovel NFAT approach that can identify users and understand how they are using\nnetwork based applications whilst the traffic remains encrypted. The\nexperiments build upon the prior art and investigate how effective this\napproach is in classifying users and their actions. Utilising an in-house\ndataset composed of 50 million packers, the experiments are formed of three\nincremental developments that assist in improving performance. Building upon\nthe successful experiments, a proposed NFAT interface is presented to\nillustrate the ease at which investigators would be able to ask relevant\nquestions of user interactions. The experiments profiled across 27 users, has\nyielded an average 93.3% True Positive Identification Rate (TPIR), with 41% of\nusers experiencing 100% TPIR. Skype, Wikipedia and Hotmail services achieved a\nnotably high level of recognition performance. The study has developed and\nevaluated an approach to analyse encrypted network traffic more effectively\nthrough the modelling of network traffic and to subsequently visualise these\ninteractions through a novel network forensic analysis tool.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18542v1",
    "published_date": "2025-03-24 10:52:23 UTC",
    "updated_date": "2025-03-24 10:52:23 UTC"
  },
  {
    "arxiv_id": "2503.18541v1",
    "title": "UniPCGC: Towards Practical Point Cloud Geometry Compression via an Efficient Unified Approach",
    "authors": [
      "Kangli Wang",
      "Wei Gao"
    ],
    "abstract": "Learning-based point cloud compression methods have made significant progress\nin terms of performance. However, these methods still encounter challenges\nincluding high complexity, limited compression modes, and a lack of support for\nvariable rate, which restrict the practical application of these methods. In\norder to promote the development of practical point cloud compression, we\npropose an efficient unified point cloud geometry compression framework, dubbed\nas UniPCGC. It is a lightweight framework that supports lossy compression,\nlossless compression, variable rate and variable complexity. First, we\nintroduce the Uneven 8-Stage Lossless Coder (UELC) in the lossless mode, which\nallocates more computational complexity to groups with higher coding\ndifficulty, and merges groups with lower coding difficulty. Second, Variable\nRate and Complexity Module (VRCM) is achieved in the lossy mode through joint\nadoption of a rate modulation module and dynamic sparse convolution. Finally,\nthrough the dynamic combination of UELC and VRCM, we achieve lossy compression,\nlossless compression, variable rate and complexity within a unified framework.\nCompared to the previous state-of-the-art method, our method achieves a\ncompression ratio (CR) gain of 8.1\\% on lossless compression, and a Bjontegaard\nDelta Rate (BD-Rate) gain of 14.02\\% on lossy compression, while also\nsupporting variable rate and variable complexity.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.18541v1",
    "published_date": "2025-03-24 10:51:28 UTC",
    "updated_date": "2025-03-24 10:51:28 UTC"
  },
  {
    "arxiv_id": "2503.18540v1",
    "title": "HiRes-FusedMIM: A High-Resolution RGB-DSM Pre-trained Model for Building-Level Remote Sensing Applications",
    "authors": [
      "Guneet Mutreja",
      "Philipp Schuegraf",
      "Ksenia Bittner"
    ],
    "abstract": "Recent advances in self-supervised learning have led to the development of\nfoundation models that have significantly advanced performance in various\ncomputer vision tasks. However, despite their potential, these models often\noverlook the crucial role of high-resolution digital surface models (DSMs) in\nunderstanding urban environments, particularly for building-level analysis,\nwhich is essential for applications like digital twins. To address this gap, we\nintroduce HiRes-FusedMIM, a novel pre-trained model specifically designed to\nleverage the rich information contained within high-resolution RGB and DSM\ndata. HiRes-FusedMIM utilizes a dual-encoder simple masked image modeling\n(SimMIM) architecture with a multi-objective loss function that combines\nreconstruction and contrastive objectives, enabling it to learn powerful, joint\nrepresentations from both modalities. We conducted a comprehensive evaluation\nof HiRes-FusedMIM on a diverse set of downstream tasks, including\nclassification, semantic segmentation, and instance segmentation. Our results\ndemonstrate that: 1) HiRes-FusedMIM outperforms previous state-of-the-art\ngeospatial methods on several building-related datasets, including WHU Aerial\nand LoveDA, demonstrating its effectiveness in capturing and leveraging\nfine-grained building information; 2) Incorporating DSMs during pre-training\nconsistently improves performance compared to using RGB data alone,\nhighlighting the value of elevation information for building-level analysis; 3)\nThe dual-encoder architecture of HiRes-FusedMIM, with separate encoders for RGB\nand DSM data, significantly outperforms a single-encoder model on the Vaihingen\nsegmentation task, indicating the benefits of learning specialized\nrepresentations for each modality. To facilitate further research and\napplications in this direction, we will publicly release the trained model\nweights.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18540v1",
    "published_date": "2025-03-24 10:49:55 UTC",
    "updated_date": "2025-03-24 10:49:55 UTC"
  },
  {
    "arxiv_id": "2503.18539v1",
    "title": "Natural Language Processing for Electronic Health Records in Scandinavian Languages: Norwegian, Swedish, and Danish",
    "authors": [
      "Ashenafi Zebene Woldaregay",
      "Jørgen Aarmo Lund",
      "Phuong Dinh Ngo",
      "Mariyam Tayefi",
      "Joel Burman",
      "Stine Hansen",
      "Martin Hylleholt Sillesen",
      "Hercules Dalianis",
      "Robert Jenssen",
      "Lindsetmo Rolf Ole",
      "Karl Øyvind Mikalsen"
    ],
    "abstract": "Background: Clinical natural language processing (NLP) refers to the use of\ncomputational methods for extracting, processing, and analyzing unstructured\nclinical text data, and holds a huge potential to transform healthcare in\nvarious clinical tasks. Objective: The study aims to perform a systematic\nreview to comprehensively assess and analyze the state-of-the-art NLP methods\nfor the mainland Scandinavian clinical text. Method: A literature search was\nconducted in various online databases including PubMed, ScienceDirect, Google\nScholar, ACM digital library, and IEEE Xplore between December 2022 and\nFebruary 2024. Further, relevant references to the included articles were also\nused to solidify our search. The final pool includes articles that conducted\nclinical NLP in the mainland Scandinavian languages and were published in\nEnglish between 2010 and 2024. Results: Out of the 113 articles, 18% (n=21)\nfocus on Norwegian clinical text, 64% (n=72) on Swedish, 10% (n=11) on Danish,\nand 8% (n=9) focus on more than one language. Generally, the review identified\npositive developments across the region despite some observable gaps and\ndisparities between the languages. There are substantial disparities in the\nlevel of adoption of transformer-based models. In essential tasks such as\nde-identification, there is significantly less research activity focusing on\nNorwegian and Danish compared to Swedish text. Further, the review identified a\nlow level of sharing resources such as data, experimentation code, pre-trained\nmodels, and rate of adaptation and transfer learning in the region. Conclusion:\nThe review presented a comprehensive assessment of the state-of-the-art\nClinical NLP for electronic health records (EHR) text in mainland Scandinavian\nlanguages and, highlighted the potential barriers and challenges that hinder\nthe rapid advancement of the field in the region.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "45 pages including the appendix, 9 figures in the main manuscript and\n  11 figures in the Appendix",
    "pdf_url": "http://arxiv.org/pdf/2503.18539v1",
    "published_date": "2025-03-24 10:47:32 UTC",
    "updated_date": "2025-03-24 10:47:32 UTC"
  },
  {
    "arxiv_id": "2503.18533v1",
    "title": "MMCR: Advancing Visual Language Model in Multimodal Multi-Turn Contextual Reasoning",
    "authors": [
      "Dawei Yan",
      "Yang Li",
      "Qing-Guo Chen",
      "Weihua Luo",
      "Peng Wang",
      "Haokui Zhang",
      "Chunhua Shen"
    ],
    "abstract": "Compared to single-turn dialogue, multi-turn dialogue involving multiple\nimages better aligns with the needs of real-world human-AI interactions.\nAdditionally, as training data, it provides richer contextual reasoning\ninformation, thereby guiding the model to achieve better performance. However,\nexisting vision-language models (VLMs) primarily rely on single-turn dialogue\ntraining and evaluation benchmarks. In this paper, following the\ncharacteristics of human dialogue, such as focused topics and concise, clear\ncontent, we present MMCR (Multimodal Multi-turn Contextual Reasoning), a novel\ndataset comprising: (1) MMCR-310k -- the largest multi-image multi-turn\ninstruction tuning dataset with 310K contextual dialogues, each covering 1-4\nimages and 4 or 8 dialogue turns; and (2) MMCR-Bench -- a diagnostic benchmark\nfeaturing dialogues, spanning 8 domains (Humanities, Natural, Science,\nEducation, etc.) and 40 sub-topics. Extensive evaluations demonstrate that\nmodels fine-tuned with MMCR-310k achieve 5.2\\% higher contextual accuracy on\nMMCR-Bench, while showing consistent improvements on existing benchmarks\n(+1.1\\% on AI2D, +1.2\\% on MMMU and MMVet). MMCR and prompt engineering will be\nreleased publicly.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18533v1",
    "published_date": "2025-03-24 10:40:33 UTC",
    "updated_date": "2025-03-24 10:40:33 UTC"
  },
  {
    "arxiv_id": "2503.18526v1",
    "title": "SciClaims: An End-to-End Generative System for Biomedical Claim Analysis",
    "authors": [
      "Raúl Ortega",
      "José Manuel Gómez-Pérez"
    ],
    "abstract": "Validating key claims in scientific literature, particularly in biomedical\nresearch, is essential for ensuring accuracy and advancing knowledge. This\nprocess is critical in sectors like the pharmaceutical industry, where rapid\nscientific progress requires automation and deep domain expertise. However,\ncurrent solutions have significant limitations. They lack end-to-end pipelines\nencompassing all claim extraction, evidence retrieval, and verification steps;\nrely on complex NLP and information retrieval pipelines prone to multiple\nfailure points; and often fail to provide clear, user-friendly justifications\nfor claim verification outcomes. To address these challenges, we introduce\nSciClaims, an advanced system powered by state-of-the-art large language models\n(LLMs) that seamlessly integrates the entire scientific claim analysis process.\nSciClaims outperforms previous approaches in both claim extraction and\nverification without requiring additional fine-tuning, setting a new benchmark\nfor automated scientific claim analysis.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DL"
    ],
    "primary_category": "cs.CL",
    "comment": "Pre-print version",
    "pdf_url": "http://arxiv.org/pdf/2503.18526v1",
    "published_date": "2025-03-24 10:31:31 UTC",
    "updated_date": "2025-03-24 10:31:31 UTC"
  },
  {
    "arxiv_id": "2503.18509v1",
    "title": "Neuro-symbolic Weak Supervision: Theory and Semantics",
    "authors": [
      "Nijesh Upreti",
      "Vaishak Belle"
    ],
    "abstract": "Weak supervision allows machine learning models to learn from limited or\nnoisy labels, but it introduces challenges in interpretability and reliability\n- particularly in multi-instance partial label learning (MI-PLL), where models\nmust resolve both ambiguous labels and uncertain instance-label mappings. We\npropose a semantics for neuro-symbolic framework that integrates Inductive\nLogic Programming (ILP) to improve MI-PLL by providing structured relational\nconstraints that guide learning. Within our semantic characterization, ILP\ndefines a logical hypothesis space for label transitions, clarifies classifier\nsemantics, and establishes interpretable performance standards. This hybrid\napproach improves robustness, transparency, and accountability in weakly\nsupervised settings, ensuring neural predictions align with domain knowledge.\nBy embedding weak supervision into a logical framework, we enhance both\ninterpretability and learning, making weak supervision more suitable for\nreal-world, high-stakes applications.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18509v1",
    "published_date": "2025-03-24 10:02:51 UTC",
    "updated_date": "2025-03-24 10:02:51 UTC"
  },
  {
    "arxiv_id": "2503.18497v1",
    "title": "Statistically Testing Training Data for Unwanted Error Patterns using Rule-Oriented Regression",
    "authors": [
      "Stefan Rass",
      "Martin Dallinger"
    ],
    "abstract": "Artificial intelligence models trained from data can only be as good as the\nunderlying data is. Biases in training data propagating through to the output\nof a machine learning model are a well-documented and well-understood\nphenomenon, but the machinery to prevent these undesired effects is much less\ndeveloped. Efforts to ensure data is clean during collection, such as using\nbias-aware sampling, are most effective when the entity controlling data\ncollection also trains the AI. In cases where the data is already available,\nhow do we find out if the data was already manipulated, i.e., ``poisoned'', so\nthat an undesired behavior would be trained into a machine learning model? This\nis a challenge fundamentally different to (just) improving approximation\naccuracy or efficiency, and we provide a method to test training data for\nflaws, to establish a trustworthy ground-truth for a subsequent training of\nmachine learning models (of any kind). Unlike the well-studied problem of\napproximating data using fuzzy rules that are generated from the data, our\nmethod hinges on a prior definition of rules to happen before seeing the data\nto be tested. Therefore, the proposed method can also discover hidden error\npatterns, which may also have substantial influence. Our approach extends the\nabilities of conventional statistical testing by letting the ``test-condition''\nbe any Boolean condition to describe a pattern in the data, whose presence we\nwish to determine. The method puts fuzzy inference into a regression model, to\nget the best of the two: explainability from fuzzy logic with statistical\nproperties and diagnostics from the regression, and finally also being\napplicable to ``small data'', hence not requiring large datasets as deep\nlearning methods do. We provide an open source implementation for demonstration\nand experiments.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "68T10 (Primary), 68M25, 62J86 (Secondary)"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18497v1",
    "published_date": "2025-03-24 09:52:36 UTC",
    "updated_date": "2025-03-24 09:52:36 UTC"
  },
  {
    "arxiv_id": "2503.18494v1",
    "title": "Verbal Process Supervision Elicits Better Coding Agents",
    "authors": [
      "Hao-Yuan Chen",
      "Cheng-Pong Huang",
      "Jui-Ming Yao"
    ],
    "abstract": "The emergence of large language models and their applications as AI agents\nhave significantly advanced state-of-the-art code generation benchmarks,\ntransforming modern software engineering tasks. However, even with test-time\ncomputed reasoning models, these systems still struggle with complex software\nengineering challenges. This work introduces CURA, a code understanding and\nreasoning agent system enhanced with verbal process supervision (VPS),\nachieving a 3.65\\% improvement over baseline models on challenging benchmarks\nlike BigCodeBench. Furthermore, CURA, when paired with the o3-mini model and\nVPS techniques, attains state-of-the-art performance. This work represents a\nstep forward in integrating reasoning-driven architectures with LLM-based code\ngeneration, enabling agentic reasoning for language models to solve complex\nsoftware engineering tasks.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18494v1",
    "published_date": "2025-03-24 09:48:59 UTC",
    "updated_date": "2025-03-24 09:48:59 UTC"
  },
  {
    "arxiv_id": "2503.18492v1",
    "title": "Safeguarding Mobile GUI Agent via Logic-based Action Verification",
    "authors": [
      "Jungjae Lee",
      "Dongjae Lee",
      "Chihun Choi",
      "Youngmin Im",
      "Jaeyoung Wi",
      "Kihong Heo",
      "Sangeun Oh",
      "Sunjae Lee",
      "Insik Shin"
    ],
    "abstract": "Large Foundation Models (LFMs) have unlocked new possibilities in\nhuman-computer interaction, particularly with the rise of mobile Graphical User\nInterface (GUI) Agents capable of interpreting GUIs. These agents promise to\nrevolutionize mobile computing by allowing users to automate complex mobile\ntasks through simple natural language instructions. However, the inherent\nprobabilistic nature of LFMs, coupled with the ambiguity and context-dependence\nof mobile tasks, makes LFM-based automation unreliable and prone to errors. To\naddress this critical challenge, we introduce VeriSafe Agent (VSA): a formal\nverification system that serves as a logically grounded safeguard for Mobile\nGUI Agents. VSA is designed to deterministically ensure that an agent's actions\nstrictly align with user intent before conducting an action. At its core, VSA\nintroduces a novel autoformalization technique that translates natural language\nuser instructions into a formally verifiable specification, expressed in our\ndomain-specific language (DSL). This enables runtime, rule-based verification,\nallowing VSA to detect and prevent erroneous actions executing an action,\neither by providing corrective feedback or halting unsafe behavior. To the best\nof our knowledge, VSA is the first attempt to bring the rigor of formal\nverification to GUI agent. effectively bridging the gap between LFM-driven\nautomation and formal software verification. We implement VSA using\noff-the-shelf LLM services (GPT-4o) and evaluate its performance on 300 user\ninstructions across 18 widely used mobile apps. The results demonstrate that\nVSA achieves 94.3%-98.33% accuracy in verifying agent actions, representing a\nsignificant 20.4%-25.6% improvement over existing LLM-based verification\nmethods, and consequently increases the GUI agent's task completion rate by\n90%-130%.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18492v1",
    "published_date": "2025-03-24 09:46:05 UTC",
    "updated_date": "2025-03-24 09:46:05 UTC"
  },
  {
    "arxiv_id": "2503.18487v1",
    "title": "Large Language Models powered Network Attack Detection: Architecture, Opportunities and Case Study",
    "authors": [
      "Xinggong Zhang",
      "Qingyang Li",
      "Yunpeng Tan",
      "Zongming Guo",
      "Lei Zhang",
      "Yong Cui"
    ],
    "abstract": "Network attack detection is a pivotal technology to identify network anomaly\nand classify malicious traffic. Large Language Models (LLMs) are trained on a\nvast corpus of text, have amassed remarkable capabilities of\ncontext-understanding and commonsense knowledge. This has opened up a new door\nfor network threat detection. Researchers have already initiated discussions\nregarding the application of LLMs on specific cyber-security tasks.\nUnfortunately, there is still a lack of comprehensive elaboration how to mine\nLLMs' potentials in network threat detections, as well as the opportunities and\nchallenges. In this paper, we mainly focus on the classification of malicious\ntraffic from the perspective of LLMs' capability. We present a holistic view of\nthe architecture of LLM-powered network attack detection, including\nPre-training, Fine-tuning, and Detection. Especially, by exploring the\nknowledge and capabilities of LLM, we identify three distinct roles LLM can act\nin network attack detection: \\textit{Classifier, Encoder, and Predictor}. For\neach of them, the modeling paradigm, opportunities and challenges are\nelaborated. Finally, we present our design on LLM-powered DDoS detection as a\ncase study. The proposed framework attains accurate detection on carpet bombing\nDDoS by exploiting LLMs' capabilities in contextual mining. The evaluation\nshows its efficacy, exhibiting a nearly $35$\\% improvement compared to existing\nsystems.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.NI",
    "comment": "submitted for peer-review",
    "pdf_url": "http://arxiv.org/pdf/2503.18487v1",
    "published_date": "2025-03-24 09:40:46 UTC",
    "updated_date": "2025-03-24 09:40:46 UTC"
  },
  {
    "arxiv_id": "2503.18471v1",
    "title": "Words as Bridges: Exploring Computational Support for Cross-Disciplinary Translation Work",
    "authors": [
      "Calvin Bao",
      "Yow-Ting Shiue",
      "Marine Carpuat",
      "Joel Chan"
    ],
    "abstract": "Scholars often explore literature outside of their home community of study.\nThis exploration process is frequently hampered by field-specific jargon. Past\ncomputational work often focuses on supporting translation work by removing\njargon through simplification and summarization; here, we explore a different\napproach that preserves jargon as useful bridges to new conceptual spaces.\nSpecifically, we cast different scholarly domains as different language-using\ncommunities, and explore how to adapt techniques from unsupervised\ncross-lingual alignment of word embeddings to explore conceptual alignments\nbetween domain-specific word embedding spaces.We developed a prototype\ncross-domain search engine that uses aligned domain-specific embeddings to\nsupport conceptual exploration, and tested this prototype in two case studies.\nWe discuss qualitative insights into the promises and pitfalls of this approach\nto translation work, and suggest design insights for future interfaces that\nprovide computational support for cross-domain information seeking.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "26 pages, 8 tables, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.18471v1",
    "published_date": "2025-03-24 09:19:29 UTC",
    "updated_date": "2025-03-24 09:19:29 UTC"
  },
  {
    "arxiv_id": "2503.18470v1",
    "title": "MetaSpatial: Reinforcing 3D Spatial Reasoning in VLMs for the Metaverse",
    "authors": [
      "Zhenyu Pan",
      "Han Liu"
    ],
    "abstract": "We present MetaSpatial, the first reinforcement learning (RL)-based framework\ndesigned to enhance 3D spatial reasoning in vision-language models (VLMs),\nenabling real-time 3D scene generation without the need for hard-coded\noptimizations. MetaSpatial addresses two core challenges: (i) the lack of\ninternalized 3D spatial reasoning in VLMs, which limits their ability to\ngenerate realistic layouts, and (ii) the inefficiency of traditional supervised\nfine-tuning (SFT) for layout generation tasks, as perfect ground truth\nannotations are unavailable. Our key innovation is a multi-turn RL-based\noptimization mechanism that integrates physics-aware constraints and rendered\nimage evaluations, ensuring generated 3D layouts are coherent, physically\nplausible, and aesthetically consistent. Methodologically, MetaSpatial\nintroduces an adaptive, iterative reasoning process, where the VLM refines\nspatial arrangements over multiple turns by analyzing rendered outputs,\nimproving scene coherence progressively. Empirical evaluations demonstrate that\nMetaSpatial significantly enhances the spatial consistency and formatting\nstability of various scale models. Post-training, object placements are more\nrealistic, aligned, and functionally coherent, validating the effectiveness of\nRL for 3D spatial reasoning in metaverse, AR/VR, digital twins, and game\ndevelopment applications. Our code, data, and training pipeline are publicly\navailable at https://github.com/PzySeere/MetaSpatial.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Working Paper",
    "pdf_url": "http://arxiv.org/pdf/2503.18470v1",
    "published_date": "2025-03-24 09:18:01 UTC",
    "updated_date": "2025-03-24 09:18:01 UTC"
  },
  {
    "arxiv_id": "2503.18462v1",
    "title": "PALATE: Peculiar Application of the Law of Total Expectation to Enhance the Evaluation of Deep Generative Models",
    "authors": [
      "Tadeusz Dziarmaga",
      "Marcin Kądziołka",
      "Artur Kasymov",
      "Marcin Mazur"
    ],
    "abstract": "Deep generative models (DGMs) have caused a paradigm shift in the field of\nmachine learning, yielding noteworthy advancements in domains such as image\nsynthesis, natural language processing, and other related areas. However, a\ncomprehensive evaluation of these models that accounts for the trichotomy\nbetween fidelity, diversity, and novelty in generated samples remains a\nformidable challenge. A recently introduced solution that has emerged as a\npromising approach in this regard is the Feature Likelihood Divergence (FLD), a\nmethod that offers a theoretically motivated practical tool, yet also exhibits\nsome computational challenges. In this paper, we propose PALATE, a novel\nenhancement to the evaluation of DGMs that addresses limitations of existing\nmetrics. Our approach is based on a peculiar application of the law of total\nexpectation to random variables representing accessible real data. When\ncombined with the MMD baseline metric and DINOv2 feature extractor, PALATE\noffers a holistic evaluation framework that matches or surpasses\nstate-of-the-art solutions while providing superior computational efficiency\nand scalability to large-scale datasets. Through a series of experiments, we\ndemonstrate the effectiveness of the PALATE enhancement, contributing a\ncomputationally efficient, holistic evaluation approach that advances the field\nof DGMs assessment, especially in detecting sample memorization and evaluating\ngeneralization capabilities.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18462v1",
    "published_date": "2025-03-24 09:06:45 UTC",
    "updated_date": "2025-03-24 09:06:45 UTC"
  },
  {
    "arxiv_id": "2503.18460v1",
    "title": "ModiGen: A Large Language Model-Based Workflow for Multi-Task Modelica Code Generation",
    "authors": [
      "Jiahui Xiang",
      "Tong Ye",
      "Peiyu Liu",
      "Yinan Zhang",
      "Wenhai Wang"
    ],
    "abstract": "Modelica is a widely adopted language for simulating complex physical\nsystems, yet effective model creation and optimization require substantial\ndomain expertise. Although large language models (LLMs) have demonstrated\npromising capabilities in code generation, their application to modeling\nremains largely unexplored. To address this gap, we have developed benchmark\ndatasets specifically designed to evaluate the performance of LLMs in\ngenerating Modelica component models and test cases. Our evaluation reveals\nsubstantial limitations in current LLMs, as the generated code often fails to\nsimulate successfully. To overcome these challenges, we propose a specialized\nworkflow that integrates supervised fine-tuning, graph retrieval-augmented\ngeneration, and feedback optimization to improve the accuracy and reliability\nof Modelica code generation. The evaluation results demonstrate significant\nperformance gains: the maximum improvement in pass@1 reached 0.3349 for the\ncomponent generation task and 0.2457 for the test case generation task. This\nresearch underscores the potential of LLMs to advance intelligent modeling\ntools and offers valuable insights for future developments in system modeling\nand engineering applications.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18460v1",
    "published_date": "2025-03-24 09:04:49 UTC",
    "updated_date": "2025-03-24 09:04:49 UTC"
  },
  {
    "arxiv_id": "2503.18432v1",
    "title": "Teaching LLMs for Step-Level Automatic Math Correction via Reinforcement Learning",
    "authors": [
      "Junsong Li",
      "Jie Zhou",
      "Yutao Yang",
      "Bihao Zhan",
      "Qianjun Pan",
      "Yuyang Ding",
      "Qin Chen",
      "Jiang Bo",
      "Xin Lin",
      "Liang He"
    ],
    "abstract": "Automatic math correction aims to check students' solutions to mathematical\nproblems via artificial intelligence technologies. Most existing studies focus\non judging the final answer at the problem level, while they ignore detailed\nfeedback on each step in a math problem-solving process, which requires\nabilities of semantic understanding and reasoning. In this paper, we propose a\nreinforcement learning (RL)-based method to boost large language model (LLM)\nfor step-level automatic math correction, named StepAMC. Particularly, we\nconvert the step-level automatic math correction within the text classification\ntask into an RL problem to enhance the reasoning capabilities of LLMs. Then, we\ndesign a space-constrained policy network to improve the stability of RL. Then,\nwe introduce a fine-grained reward network to convert the binary human feedback\ninto a continuous value. We conduct extensive experiments over two benchmark\ndatasets and the results show that our model outperforms the eleven strong\nbaselines.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18432v1",
    "published_date": "2025-03-24 08:28:34 UTC",
    "updated_date": "2025-03-24 08:28:34 UTC"
  },
  {
    "arxiv_id": "2503.18419v1",
    "title": "Generative AI in Knowledge Work: Design Implications for Data Navigation and Decision-Making",
    "authors": [
      "Bhada Yun",
      "Dana Feng",
      "Ace S. Chen",
      "Afshin Nikzad",
      "Niloufar Salehi"
    ],
    "abstract": "Our study of 20 knowledge workers revealed a common challenge: the difficulty\nof synthesizing unstructured information scattered across multiple platforms to\nmake informed decisions. Drawing on their vision of an ideal knowledge\nsynthesis tool, we developed Yodeai, an AI-enabled system, to explore both the\nopportunities and limitations of AI in knowledge work. Through a user study\nwith 16 product managers, we identified three key requirements for Generative\nAI in knowledge work: adaptable user control, transparent collaboration\nmechanisms, and the ability to integrate background knowledge with external\ninformation. However, we also found significant limitations, including\noverreliance on AI, user isolation, and contextual factors outside the AI's\nreach. As AI tools become increasingly prevalent in professional settings, we\npropose design principles that emphasize adaptability to diverse workflows,\naccountability in personal and collaborative contexts, and context-aware\ninteroperability to guide the development of human-centered AI systems for\nproduct managers and knowledge workers.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.ET",
      "H.5.m"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted to CHI '25 (Conference on Human Factors in Computing\n  Systems), to appear April 26-May 1, 2025, Yokohama, Japan",
    "pdf_url": "http://arxiv.org/pdf/2503.18419v1",
    "published_date": "2025-03-24 08:02:44 UTC",
    "updated_date": "2025-03-24 08:02:44 UTC"
  },
  {
    "arxiv_id": "2503.18403v1",
    "title": "Knowledge Graph Enhanced Generative Multi-modal Models for Class-Incremental Learning",
    "authors": [
      "Xusheng Cao",
      "Haori Lu",
      "Linlan Huang",
      "Fei Yang",
      "Xialei Liu",
      "Ming-Ming Cheng"
    ],
    "abstract": "Continual learning in computer vision faces the critical challenge of\ncatastrophic forgetting, where models struggle to retain prior knowledge while\nadapting to new tasks. Although recent studies have attempted to leverage the\ngeneralization capabilities of pre-trained models to mitigate overfitting on\ncurrent tasks, models still tend to forget details of previously learned\ncategories as tasks progress, leading to misclassification. To address these\nlimitations, we introduce a novel Knowledge Graph Enhanced Generative\nMulti-modal model (KG-GMM) that builds an evolving knowledge graph throughout\nthe learning process. Our approach utilizes relationships within the knowledge\ngraph to augment the class labels and assigns different relations to similar\ncategories to enhance model differentiation. During testing, we propose a\nKnowledge Graph Augmented Inference method that locates specific categories by\nanalyzing relationships within the generated text, thereby reducing the loss of\ndetailed information about old classes when learning new knowledge and\nalleviating forgetting. Experiments demonstrate that our method effectively\nleverages relational information to help the model correct mispredictions,\nachieving state-of-the-art results in both conventional CIL and few-shot CIL\nsettings, confirming the efficacy of knowledge graphs at preserving knowledge\nin the continual learning scenarios.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18403v1",
    "published_date": "2025-03-24 07:20:43 UTC",
    "updated_date": "2025-03-24 07:20:43 UTC"
  },
  {
    "arxiv_id": "2503.18395v1",
    "title": "PRECTR: A Synergistic Framework for Integrating Personalized Search Relevance Matching and CTR Prediction",
    "authors": [
      "Rong Chen",
      "Shuzhi Cao",
      "Ailong He",
      "Shuguang Han",
      "Jufeng Chen"
    ],
    "abstract": "The two primary tasks in the search recommendation system are search\nrelevance matching and click-through rate (CTR) prediction -- the former\nfocuses on seeking relevant items for user queries whereas the latter forecasts\nwhich item may better match user interest. Prior research typically develops\ntwo models to predict the CTR and search relevance separately, then ranking\ncandidate items based on the fusion of the two outputs. However, such a\ndivide-and-conquer paradigm creates the inconsistency between different models.\nMeanwhile, the search relevance model mainly concentrates on the degree of\nobjective text matching while neglecting personalized differences among\ndifferent users, leading to restricted model performance. To tackle these\nissues, we propose a unified \\textbf{P}ersonalized Search RElevance Matching\nand CTR Prediction Fusion Model(PRECTR). Specifically, based on the conditional\nprobability fusion mechanism, PRECTR integrates the CTR prediction and search\nrelevance matching into one framework to enhance the interaction and\nconsistency of the two modules. However, directly optimizing CTR binary\nclassification loss may bring challenges to the fusion model's convergence and\nindefinitely promote the exposure of items with high CTR, regardless of their\nsearch relevance. Hence, we further introduce two-stage training and semantic\nconsistency regularization to accelerate the model's convergence and restrain\nthe recommendation of irrelevant items. Finally, acknowledging that different\nusers may have varied relevance preferences, we assessed current users'\nrelevance preferences by analyzing past users' preferences for similar queries\nand tailored incentives for different candidate items accordingly. Extensive\nexperimental results on our production dataset and online A/B testing\ndemonstrate the effectiveness and superiority of our proposed PRECTR method.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18395v1",
    "published_date": "2025-03-24 07:07:04 UTC",
    "updated_date": "2025-03-24 07:07:04 UTC"
  },
  {
    "arxiv_id": "2503.18387v1",
    "title": "Manipulation and the AI Act: Large Language Model Chatbots and the Danger of Mirrors",
    "authors": [
      "Joshua Krook"
    ],
    "abstract": "Large Language Model chatbots are increasingly taking the form and visage of\nhuman beings, adapting human faces, names, voices, personalities, and quirks,\nincluding those of celebrities and well-known political figures. Personifying\nAI chatbots could foreseeably increase their trust with users. However, it\ncould also make them more capable of manipulation, by creating the illusion of\na close and intimate relationship with an artificial entity. The European\nCommission has finalized the AI Act, with the EU Parliament making amendments\nbanning manipulative and deceptive AI systems that cause significant harm to\nusers. Although the AI Act covers harms that accumulate over time, it is\nunlikely to prevent harms associated with prolonged discussions with AI\nchatbots. Specifically, a chatbot could reinforce a person's negative emotional\nstate over weeks, months, or years through negative feedback loops, prolonged\nconversations, or harmful recommendations, contributing to a user's\ndeteriorating mental health.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18387v1",
    "published_date": "2025-03-24 06:56:29 UTC",
    "updated_date": "2025-03-24 06:56:29 UTC"
  },
  {
    "arxiv_id": "2503.18386v1",
    "title": "Resource-Efficient Motion Control for Video Generation via Dynamic Mask Guidance",
    "authors": [
      "Sicong Feng",
      "Jielong Yang",
      "Li Peng"
    ],
    "abstract": "Recent advances in diffusion models bring new vitality to visual content\ncreation. However, current text-to-video generation models still face\nsignificant challenges such as high training costs, substantial data\nrequirements, and difficulties in maintaining consistency between given text\nand motion of the foreground object. To address these challenges, we propose\nmask-guided video generation, which can control video generation through mask\nmotion sequences, while requiring limited training data. Our model enhances\nexisting architectures by incorporating foreground masks for precise\ntext-position matching and motion trajectory control. Through mask motion\nsequences, we guide the video generation process to maintain consistent\nforeground objects throughout the sequence. Additionally, through a first-frame\nsharing strategy and autoregressive extension approach, we achieve more stable\nand longer video generation. Extensive qualitative and quantitative experiments\ndemonstrate that this approach excels in various video generation tasks, such\nas video editing and generating artistic videos, outperforming previous methods\nin terms of consistency and quality. Our generated results can be viewed in the\nsupplementary materials.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18386v1",
    "published_date": "2025-03-24 06:53:08 UTC",
    "updated_date": "2025-03-24 06:53:08 UTC"
  },
  {
    "arxiv_id": "2503.18385v1",
    "title": "RoCA: Robust Contrastive One-class Time Series Anomaly Detection with Contaminated Data",
    "authors": [
      "Xudong Mou",
      "Rui Wang",
      "Bo Li",
      "Tianyu Wo",
      "Jie Sun",
      "Hui Wang",
      "Xudong Liu"
    ],
    "abstract": "The accumulation of time-series signals and the absence of labels make\ntime-series Anomaly Detection (AD) a self-supervised task of deep learning.\nMethods based on normality assumptions face the following three limitations:\n(1) A single assumption could hardly characterize the whole normality or lead\nto some deviation. (2) Some assumptions may go against the principle of AD. (3)\nTheir basic assumption is that the training data is uncontaminated (free of\nanomalies), which is unrealistic in practice, leading to a decline in\nrobustness. This paper proposes a novel robust approach, RoCA, which is the\nfirst to address all of the above three challenges, as far as we are aware. It\nfuses the separated assumptions of one-class classification and contrastive\nlearning in a single training process to characterize a more complete so-called\nnormality. Additionally, it monitors the training data and computes a carefully\ndesigned anomaly score throughout the training process. This score helps\nidentify latent anomalies, which are then used to define the classification\nboundary, inspired by the concept of outlier exposure. The performance on AIOps\ndatasets improved by 6% compared to when contamination was not considered\n(COCA). On two large and high-dimensional multivariate datasets, the\nperformance increased by 5% to 10%. RoCA achieves the highest average\nperformance on both univariate and multivariate datasets. The source code is\navailable at https://github.com/ruiking04/RoCA.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18385v1",
    "published_date": "2025-03-24 06:52:28 UTC",
    "updated_date": "2025-03-24 06:52:28 UTC"
  },
  {
    "arxiv_id": "2503.18382v1",
    "title": "PP-FormulaNet: Bridging Accuracy and Efficiency in Advanced Formula Recognition",
    "authors": [
      "Hongen Liu",
      "Cheng Cui",
      "Yuning Du",
      "Yi Liu",
      "Gang Pan"
    ],
    "abstract": "Formula recognition is an important task in document intelligence. It\ninvolves converting mathematical expressions from document images into\nstructured symbolic formats that computers can easily work with. LaTeX is the\nmost common format used for this purpose. In this work, we present\nPP-FormulaNet, a state-of-the-art formula recognition model that excels in both\naccuracy and efficiency. To meet the diverse needs of applications, we have\ndeveloped two specialized models: PP-FormulaNet-L, tailored for high-accuracy\nscenarios, and PP-FormulaNet-S, optimized for high-efficiency contexts. Our\nextensive evaluations reveal that PP-FormulaNet-L attains accuracy levels that\nsurpass those of prominent models such as UniMERNet by a significant 6%.\nConversely, PP-FormulaNet-S operates at speeds that are over 16 times faster.\nThese advancements facilitate seamless integration of PP-FormulaNet into a\nbroad spectrum of document processing environments that involve intricate\nmathematical formulas. Furthermore, we introduce a Formula Mining System, which\nis capable of extracting a vast amount of high-quality formula data. This\nsystem further enhances the robustness and applicability of our formula\nrecognition model. Code and models are publicly available at\nPaddleOCR(https://github.com/PaddlePaddle/PaddleOCR) and\nPaddleX(https://github.com/PaddlePaddle/PaddleX).",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18382v1",
    "published_date": "2025-03-24 06:39:51 UTC",
    "updated_date": "2025-03-24 06:39:51 UTC"
  },
  {
    "arxiv_id": "2503.18377v1",
    "title": "Maximum Redundancy Pruning: A Principle-Driven Layerwise Sparsity Allocation for LLMs",
    "authors": [
      "Chang Gao",
      "Kang Zhao",
      "Jianfei Chen",
      "Liping Jing"
    ],
    "abstract": "Large language models (LLMs) have demonstrated impressive capabilities, but\ntheir enormous size poses significant challenges for deployment in real-world\napplications. To address this issue, researchers have sought to apply network\npruning techniques to LLMs. A critical challenge in pruning is allocation the\nsparsity for each layer. Recent sparsity allocation methods is often based on\nheuristics or search that can easily lead to suboptimal performance. In this\npaper, we conducted an extensive investigation into various LLMs and revealed\nthree significant discoveries: (1) the layerwise pruning sensitivity (LPS) of\nLLMs is highly non-uniform, (2) the choice of pruning metric affects LPS, and\n(3) the performance of a sparse model is related to the uniformity of its\nlayerwise redundancy level. Based on these observations, we propose that the\nlayerwise sparsity of LLMs should adhere to three principles:\n\\emph{non-uniformity}, \\emph{pruning metric dependency}, and \\emph{uniform\nlayerwise redundancy level} in the pruned model. To this end, we proposed\nMaximum Redundancy Pruning (MRP), an iterative pruning algorithm that prunes in\nthe most redundant layers (\\emph{i.e.}, those with the highest non-outlier\nratio) at each iteration. The achieved layerwise sparsity aligns with the\noutlined principles. We conducted extensive experiments on publicly available\nLLMs, including the LLaMA2 and OPT, across various benchmarks. Experimental\nresults validate the effectiveness of MRP, demonstrating its superiority over\nprevious methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18377v1",
    "published_date": "2025-03-24 06:17:30 UTC",
    "updated_date": "2025-03-24 06:17:30 UTC"
  },
  {
    "arxiv_id": "2503.18347v1",
    "title": "Latent Embedding Adaptation for Human Preference Alignment in Diffusion Planners",
    "authors": [
      "Wen Zheng Terence Ng",
      "Jianda Chen",
      "Yuan Xu",
      "Tianwei Zhang"
    ],
    "abstract": "This work addresses the challenge of personalizing trajectories generated in\nautomated decision-making systems by introducing a resource-efficient approach\nthat enables rapid adaptation to individual users' preferences. Our method\nleverages a pretrained conditional diffusion model with Preference Latent\nEmbeddings (PLE), trained on a large, reward-free offline dataset. The PLE\nserves as a compact representation for capturing specific user preferences. By\nadapting the pretrained model using our proposed preference inversion method,\nwhich directly optimizes the learnable PLE, we achieve superior alignment with\nhuman preferences compared to existing solutions like Reinforcement Learning\nfrom Human Feedback (RLHF) and Low-Rank Adaptation (LoRA). To better reflect\npractical applications, we create a benchmark experiment using real human\npreferences on diverse, high-reward trajectories.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.18347v1",
    "published_date": "2025-03-24 05:11:58 UTC",
    "updated_date": "2025-03-24 05:11:58 UTC"
  },
  {
    "arxiv_id": "2503.18331v1",
    "title": "Optimizing Influence Campaigns: Nudging under Bounded Confidence",
    "authors": [
      "Yen-Shao Chen",
      "Tauhid Zaman"
    ],
    "abstract": "Influence campaigns in online social networks are often run by organizations,\npolitical parties, and nation states to influence large audiences. These\ncampaigns are employed through the use of agents in the network that share\npersuasive content. Yet, their impact might be minimal if the audiences remain\nunswayed, often due to the bounded confidence phenomenon, where only a narrow\nspectrum of viewpoints can influence them. Here we show that to persuade under\nbounded confidence, an agent must nudge its targets to gradually shift their\nopinions. Using a control theory approach, we show how to construct an agent's\nnudging policy under the bounded confidence opinion dynamics model and also how\nto select targets for multiple agents in an influence campaign on a social\nnetwork. Simulations on real Twitter networks show that a multi-agent nudging\npolicy can shift the mean opinion, decrease opinion polarization, or even\nincrease it. We find that our nudging based policies outperform other common\ntechniques that do not consider the bounded confidence effect. Finally, we show\nhow to craft prompts for large language models, such as ChatGPT, to generate\ntext-based content for real nudging policies. This illustrates the practical\nfeasibility of our approach, allowing one to go from mathematical nudging\npolicies to real social media content.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18331v1",
    "published_date": "2025-03-24 04:30:58 UTC",
    "updated_date": "2025-03-24 04:30:58 UTC"
  },
  {
    "arxiv_id": "2503.18324v1",
    "title": "Plug-and-Play Interpretable Responsible Text-to-Image Generation via Dual-Space Multi-facet Concept Control",
    "authors": [
      "Basim Azam",
      "Naveed Akhtar"
    ],
    "abstract": "Ethical issues around text-to-image (T2I) models demand a comprehensive\ncontrol over the generative content. Existing techniques addressing these\nissues for responsible T2I models aim for the generated content to be fair and\nsafe (non-violent/explicit). However, these methods remain bounded to handling\nthe facets of responsibility concepts individually, while also lacking in\ninterpretability. Moreover, they often require alteration to the original\nmodel, which compromises the model performance. In this work, we propose a\nunique technique to enable responsible T2I generation by simultaneously\naccounting for an extensive range of concepts for fair and safe content\ngeneration in a scalable manner. The key idea is to distill the target T2I\npipeline with an external plug-and-play mechanism that learns an interpretable\ncomposite responsible space for the desired concepts, conditioned on the target\nT2I pipeline. We use knowledge distillation and concept whitening to enable\nthis. At inference, the learned space is utilized to modulate the generative\ncontent. A typical T2I pipeline presents two plug-in points for our approach,\nnamely; the text embedding space and the diffusion model latent space. We\ndevelop modules for both points and show the effectiveness of our approach with\na range of strong results.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18324v1",
    "published_date": "2025-03-24 04:06:39 UTC",
    "updated_date": "2025-03-24 04:06:39 UTC"
  },
  {
    "arxiv_id": "2503.18320v1",
    "title": "Bridging Writing Manner Gap in Visual Instruction Tuning by Creating LLM-aligned Instructions",
    "authors": [
      "Dong Jing",
      "Nanyi Fei",
      "Zhiwu Lu"
    ],
    "abstract": "In the realm of Large Multi-modal Models (LMMs), the instruction quality\nduring the visual instruction tuning stage significantly influences the\nperformance of modality alignment. In this paper, we assess the instruction\nquality from a unique perspective termed \\textbf{Writing Manner}, which\nencompasses the selection of vocabulary, grammar and sentence structure to\nconvey specific semantics. We argue that there exists a substantial writing\nmanner gap between the visual instructions and the base Large Language Models\n(LLMs) within LMMs. This gap forces the pre-trained base LLMs to deviate from\ntheir original writing styles, leading to capability degradation of both base\nLLMs and LMMs. To bridge the writing manner gap while preserving the original\nsemantics, we propose directly leveraging the base LLM to align the writing\nmanner of soft-format visual instructions with that of the base LLM itself,\nresulting in novel LLM-aligned instructions. The manual writing manner\nevaluation results demonstrate that our approach successfully minimizes the\nwriting manner gap. By utilizing LLM-aligned instructions, the baseline models\nLLaVA-7B and QwenVL demonstrate enhanced resistance to hallucinations and\nnon-trivial comprehensive improvements across all $15$ visual and language\nbenchmarks.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18320v1",
    "published_date": "2025-03-24 03:59:06 UTC",
    "updated_date": "2025-03-24 03:59:06 UTC"
  },
  {
    "arxiv_id": "2503.18314v2",
    "title": "LoTUS: Large-Scale Machine Unlearning with a Taste of Uncertainty",
    "authors": [
      "Christoforos N. Spartalis",
      "Theodoros Semertzidis",
      "Efstratios Gavves",
      "Petros Daras"
    ],
    "abstract": "We present LoTUS, a novel Machine Unlearning (MU) method that eliminates the\ninfluence of training samples from pre-trained models, avoiding retraining from\nscratch. LoTUS smooths the prediction probabilities of the model up to an\ninformation-theoretic bound, mitigating its over-confidence stemming from data\nmemorization. We evaluate LoTUS on Transformer and ResNet18 models against\neight baselines across five public datasets. Beyond established MU benchmarks,\nwe evaluate unlearning on ImageNet1k, a large-scale dataset, where retraining\nis impractical, simulating real-world conditions. Moreover, we introduce the\nnovel Retrain-Free Jensen-Shannon Divergence (RF-JSD) metric to enable\nevaluation under real-world conditions. The experimental results show that\nLoTUS outperforms state-of-the-art methods in terms of both efficiency and\neffectiveness. Code: https://github.com/cspartalis/LoTUS.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted as a main conference paper at CVPR 2025\n  (https://cvpr.thecvf.com/virtual/2025/poster/33292)",
    "pdf_url": "http://arxiv.org/pdf/2503.18314v2",
    "published_date": "2025-03-24 03:34:23 UTC",
    "updated_date": "2025-03-25 06:23:57 UTC"
  },
  {
    "arxiv_id": "2503.18313v1",
    "title": "DeepFund: Will LLM be Professional at Fund Investment? A Live Arena Perspective",
    "authors": [
      "Changlun Li",
      "Yao Shi",
      "Yuyu Luo",
      "Nan Tang"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities across\nvarious domains, but their effectiveness in financial decision making,\nparticularly in fund investment, remains inadequately evaluated. Current\nbenchmarks primarily assess LLMs understanding of financial documents rather\nthan their ability to manage assets or analyze trading opportunities in dynamic\nmarket conditions. A critical limitation in existing evaluation methodologies\nis the backtesting approach, which suffers from information leakage when LLMs\nare evaluated on historical data they may have encountered during pretraining.\nThis paper introduces DeepFund, a comprehensive platform for evaluating LLM\nbased trading strategies in a simulated live environment. Our approach\nimplements a multi agent framework where LLMs serve as both analysts and\nmanagers, creating a realistic simulation of investment decision making. The\nplatform employs a forward testing methodology that mitigates information\nleakage by evaluating models on market data released after their training\ncutoff dates. We provide a web interface that visualizes model performance\nacross different market conditions and investment parameters, enabling detailed\ncomparative analysis. Through DeepFund, we aim to provide a more accurate and\nfair assessment of LLMs capabilities in fund investment, offering insights into\ntheir potential real world applications in financial markets.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CE",
      "cs.HC"
    ],
    "primary_category": "cs.MA",
    "comment": "Work in progress",
    "pdf_url": "http://arxiv.org/pdf/2503.18313v1",
    "published_date": "2025-03-24 03:32:13 UTC",
    "updated_date": "2025-03-24 03:32:13 UTC"
  },
  {
    "arxiv_id": "2503.18303v1",
    "title": "How to Capture and Study Conversations Between Research Participants and ChatGPT: GPT for Researchers (g4r.org)",
    "authors": [
      "Jin Kim"
    ],
    "abstract": "As large language models (LLMs) like ChatGPT become increasingly integrated\ninto our everyday lives--from customer service and education to creative work\nand personal productivity--understanding how people interact with these AI\nsystems has become a pressing issue. Despite the widespread use of LLMs,\nresearchers lack standardized tools for systematically studying people's\ninteractions with LLMs. To address this issue, we introduce GPT for Researchers\n(G4R), or g4r.org, a free website that researchers can use to easily create and\nintegrate a GPT Interface into their studies. At g4r.org, researchers can (1)\nenable their study participants to interact with GPT (such as ChatGPT), (2)\ncustomize GPT Interfaces to guide participants' interactions with GPT (e.g.,\nset constraints on topics or adjust GPT's tone or response style), and (3)\ncapture participants' interactions with GPT by downloading data on messages\nexchanged between participants and GPT. By facilitating study participants'\ninteractions with GPT and providing detailed data on these interactions, G4R\ncan support research on topics such as consumer interactions with AI agents or\nLLMs, AI-assisted decision-making, and linguistic patterns in human-AI\ncommunication. With this goal in mind, we provide a step-by-step guide to using\nG4R at g4r.org.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18303v1",
    "published_date": "2025-03-24 03:10:12 UTC",
    "updated_date": "2025-03-24 03:10:12 UTC"
  },
  {
    "arxiv_id": "2503.18302v1",
    "title": "DiffMove: Group Mobility Tendency Enhanced Trajectory Recovery via Diffusion Model",
    "authors": [
      "Qingyue Long",
      "Can Rong",
      "Huandong Wang",
      "Shaw Rajib",
      "Yong Li"
    ],
    "abstract": "In the real world, trajectory data is often sparse and incomplete due to low\ncollection frequencies or limited device coverage. Trajectory recovery aims to\nrecover these missing trajectory points, making the trajectories denser and\nmore complete. However, this task faces two key challenges: 1) The excessive\nsparsity of individual trajectories makes it difficult to effectively leverage\nhistorical information for recovery; 2) Sparse trajectories make it harder to\ncapture complex individual mobility preferences. To address these challenges,\nwe propose a novel method called DiffMove. Firstly, we harness crowd wisdom for\ntrajectory recovery. Specifically, we construct a group tendency graph using\nthe collective trajectories of all users and then integrate the group mobility\ntrends into the location representations via graph embedding. This solves the\nchallenge of sparse trajectories being unable to rely on individual historical\ntrajectories for recovery. Secondly, we capture individual mobility preferences\nfrom both historical and current perspectives. Finally, we integrate group\nmobility tendencies and individual preferences into the spatiotemporal\ndistribution of the trajectory to recover high-quality trajectories. Extensive\nexperiments on two real-world datasets demonstrate that DiffMove outperforms\nexisting state-of-the-art methods. Further analysis validates the robustness of\nour method.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18302v1",
    "published_date": "2025-03-24 03:08:21 UTC",
    "updated_date": "2025-03-24 03:08:21 UTC"
  },
  {
    "arxiv_id": "2503.18290v1",
    "title": "When is dataset cartography ineffective? Using training dynamics does not improve robustness against Adversarial SQuAD",
    "authors": [
      "Paul K. Mandal"
    ],
    "abstract": "In this paper, I investigate the effectiveness of dataset cartography for\nextractive question answering on the SQuAD dataset. I begin by analyzing\nannotation artifacts in SQuAD and evaluate the impact of two adversarial\ndatasets, AddSent and AddOneSent, on an ELECTRA-small model. Using training\ndynamics, I partition SQuAD into easy-to-learn, ambiguous, and hard-to-learn\nsubsets. I then compare the performance of models trained on these subsets to\nthose trained on randomly selected samples of equal size. Results show that\ntraining on cartography-based subsets does not improve generalization to the\nSQuAD validation set or the AddSent adversarial set. While the hard-to-learn\nsubset yields a slightly higher F1 score on the AddOneSent dataset, the overall\ngains are limited. These findings suggest that dataset cartography provides\nlittle benefit for adversarial robustness in SQuAD-style QA tasks. I conclude\nby comparing these results to prior findings on SNLI and discuss possible\nreasons for the observed differences.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7; I.2.6; I.5.1"
    ],
    "primary_category": "cs.CL",
    "comment": "5 pages, 3 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2503.18290v1",
    "published_date": "2025-03-24 02:24:18 UTC",
    "updated_date": "2025-03-24 02:24:18 UTC"
  },
  {
    "arxiv_id": "2503.18283v1",
    "title": "Voxel-based Point Cloud Geometry Compression with Space-to-Channel Context",
    "authors": [
      "Bojun Liu",
      "Yangzhi Ma",
      "Ao Luo",
      "Li Li",
      "Dong Liu"
    ],
    "abstract": "Voxel-based methods are among the most efficient for point cloud geometry\ncompression, particularly with dense point clouds. However, they face\nlimitations due to a restricted receptive field, especially when handling\nhigh-bit depth point clouds. To overcome this issue, we introduce a stage-wise\nSpace-to-Channel (S2C) context model for both dense point clouds and low-level\nsparse point clouds. This model utilizes a channel-wise autoregressive strategy\nto effectively integrate neighborhood information at a coarse resolution. For\nhigh-level sparse point clouds, we further propose a level-wise S2C context\nmodel that addresses resolution limitations by incorporating Geometry Residual\nCoding (GRC) for consistent-resolution cross-level prediction. Additionally, we\nuse the spherical coordinate system for its compact representation and enhance\nour GRC approach with a Residual Probability Approximation (RPA) module, which\nfeatures a large kernel size. Experimental results show that our S2C context\nmodel not only achieves bit savings while maintaining or improving\nreconstruction quality but also reduces computational complexity compared to\nstate-of-the-art voxel-based compression methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18283v1",
    "published_date": "2025-03-24 01:56:08 UTC",
    "updated_date": "2025-03-24 01:56:08 UTC"
  },
  {
    "arxiv_id": "2503.18278v1",
    "title": "TopV: Compatible Token Pruning with Inference Time Optimization for Fast and Low-Memory Multimodal Vision Language Model",
    "authors": [
      "Cheng Yang",
      "Yang Sui",
      "Jinqi Xiao",
      "Lingyi Huang",
      "Yu Gong",
      "Chendi Li",
      "Jinghua Yan",
      "Yu Bai",
      "Ponnuswamy Sadayappan",
      "Xia Hu",
      "Bo Yuan"
    ],
    "abstract": "Vision-Language Models (VLMs) demand substantial computational resources\nduring inference, largely due to the extensive visual input tokens for\nrepresenting visual information. Previous studies have noted that visual tokens\ntend to receive less attention than text tokens, suggesting their lower\nimportance during inference and potential for pruning. However, their methods\nencounter several challenges: reliance on greedy heuristic criteria for token\nimportance and incompatibility with FlashAttention and KV cache. To address\nthese issues, we introduce \\textbf{TopV}, a compatible \\textbf{TO}ken\n\\textbf{P}runing with inference Time Optimization for fast and low-memory\n\\textbf{V}LM, achieving efficient pruning without additional training or\nfine-tuning. Instead of relying on attention scores, we formulate token pruning\nas an optimization problem, accurately identifying important visual tokens\nwhile remaining compatible with FlashAttention. Additionally, since we only\nperform this pruning once during the prefilling stage, it effectively reduces\nKV cache size. Our optimization framework incorporates a visual-aware cost\nfunction considering factors such as Feature Similarity, Relative Spatial\nDistance, and Absolute Central Distance, to measure the importance of each\nsource visual token, enabling effective pruning of low-importance tokens.\nExtensive experiments demonstrate that our method outperforms previous token\npruning methods, validating the effectiveness and efficiency of our approach.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.18278v1",
    "published_date": "2025-03-24 01:47:26 UTC",
    "updated_date": "2025-03-24 01:47:26 UTC"
  },
  {
    "arxiv_id": "2503.18265v1",
    "title": "Risk Management for Distributed Arbitrage Systems: Integrating Artificial Intelligence",
    "authors": [
      "Akaash Vishal Hazarika",
      "Mahak Shah",
      "Swapnil Patil",
      "Pradyumna Shukla"
    ],
    "abstract": "Effective risk management solutions become absolutely crucial when financial\nmarkets embrace distributed technology and decentralized financing (DeFi). This\nstudy offers a thorough survey and comparative analysis of the integration of\nartificial intelligence (AI) in risk management for distributed arbitrage\nsystems. We examine several modern caching techniques namely in memory caching,\ndistributed caching, and proxy caching and their functions in enhancing\nperformance in decentralized settings. Through literature review we examine the\nutilization of AI techniques for alleviating risks related to market\nvolatility, liquidity challenges, operational failures, regulatory compliance,\nand security threats. This comparison research evaluates various case studies\nfrom prominent DeFi technologies, emphasizing critical performance metrics like\nlatency reduction, load balancing, and system resilience. Additionally, we\nexamine the problems and trade offs associated with these technologies,\nemphasizing their effects on consistency, scalability, and fault tolerance. By\nmeticulously analyzing real world applications, specifically centering on the\nAave platform as our principal case study, we illustrate how the purposeful\namalgamation of AI with contemporary caching methodologies has revolutionized\nrisk management in distributed arbitrage systems.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG",
      "I.2.11; G.3"
    ],
    "primary_category": "cs.DC",
    "comment": "International Conference on AI and Financial Innovation AIFI-2025",
    "pdf_url": "http://arxiv.org/pdf/2503.18265v1",
    "published_date": "2025-03-24 01:15:43 UTC",
    "updated_date": "2025-03-24 01:15:43 UTC"
  },
  {
    "arxiv_id": "2503.18258v1",
    "title": "Severing Spurious Correlations with Data Pruning",
    "authors": [
      "Varun Mulchandani",
      "Jung-Eun Kim"
    ],
    "abstract": "Deep neural networks have been shown to learn and rely on spurious\ncorrelations present in the data that they are trained on. Reliance on such\ncorrelations can cause these networks to malfunction when deployed in the real\nworld, where these correlations may no longer hold. To overcome the learning of\nand reliance on such correlations, recent studies propose approaches that yield\npromising results. These works, however, study settings where the strength of\nthe spurious signal is significantly greater than that of the core, invariant\nsignal, making it easier to detect the presence of spurious features in\nindividual training samples and allow for further processing. In this paper, we\nidentify new settings where the strength of the spurious signal is relatively\nweaker, making it difficult to detect any spurious information while continuing\nto have catastrophic consequences. We also discover that spurious correlations\nare learned primarily due to only a handful of all the samples containing the\nspurious feature and develop a novel data pruning technique that identifies and\nprunes small subsets of the training data that contain these samples. Our\nproposed technique does not require inferred domain knowledge, information\nregarding the sample-wise presence or nature of spurious information, or human\nintervention. Finally, we show that such data pruning attains state-of-the-art\nperformance on previously studied settings where spurious information is\nidentifiable.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2025, Spotlight",
    "pdf_url": "http://arxiv.org/pdf/2503.18258v1",
    "published_date": "2025-03-24 00:57:32 UTC",
    "updated_date": "2025-03-24 00:57:32 UTC"
  },
  {
    "arxiv_id": "2503.18255v1",
    "title": "The Human-Machine Identity Blur: A Unified Framework for Cybersecurity Risk Management in 2025",
    "authors": [
      "Kush Janani"
    ],
    "abstract": "The modern enterprise is facing an unprecedented surge in digital identities,\nwith machine identities now significantly outnumbering human identities. This\npaper examines the cybersecurity risks emerging from what we define as the\n\"human-machine identity blur\" - the point at which human and machine identities\nintersect, delegate authority, and create new attack surfaces. Drawing from\nindustry data, expert insights, and real-world incident analysis, we identify\nkey governance gaps in current identity management models that treat human and\nmachine entities as separate domains. To address these challenges, we propose a\nUnified Identity Governance Framework based on four core principles: treating\nidentity as a continuum rather than a binary distinction, applying consistent\nrisk evaluation across all identity types, implementing continuous verification\nguided by zero trust principles, and maintaining governance throughout the\nentire identity lifecycle. Our research shows that organizations adopting this\nunified approach experience a 47 percent reduction in identity-related security\nincidents and a 62 percent improvement in incident response time. We conclude\nby offering a practical implementation roadmap and outlining future research\ndirections as AI-driven systems become increasingly autonomous.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "9 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.18255v1",
    "published_date": "2025-03-24 00:37:14 UTC",
    "updated_date": "2025-03-24 00:37:14 UTC"
  }
]