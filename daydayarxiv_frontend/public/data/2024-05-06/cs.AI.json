{
  "date": "2024-05-06",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-05-06 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 更新了 95 篇论文，主要聚焦于 AI 在机器人学习、医疗诊断、LLMs 优化和强化学习等方面的创新应用，令人印象深刻的是 LLMs 在多模态任务和软件工程中的高效扩展（如 OmniActions 和 SWE-agent），以及知名学者如 Jürgen Schmidhuber 的强化学习工作。\n\n以下是今日论文的精选摘要，我会优先讨论重要、话题性强的论文（如涉及 LLMs、机器人和医疗的创新），并快速掠过其他次要内容。每个条目列出论文标题（中文 + 英文），并简要描述主要贡献和发现。\n\n1. **OmniActions: Predicting Digital Actions in Response to Real-World Multimodal Sensory Inputs with LLMs**  \n   这篇论文提出 OmniActions 框架，利用 LLMs 处理多模态输入（如图像和音频），预测用户后续动作，实现高效的人机交互。主要贡献是通过日记研究构建设计空间，并在 CHI 2024 接受，实验显示 LLM 技术（如 in-context learning）在预测任务中提升准确性。\n\n2. **SWE-agent: Agent-Computer Interfaces Enable Automated Software Engineering**  \n   作者包括 Karthik Narasimhan 和 Ofir Press，这篇重要论文引入 SWE-agent 系统，使用 LLM 代理自动化软件工程任务（如代码编辑）。主要发现是通过自定义接口显著提高代码生成效率，在 HumanEvalFix 上达到 87.7% pass@1 率，远超传统方法。\n\n3. **Trio-ViT: Post-Training Quantization and Acceleration for Softmax-Free Efficient Vision Transformer**  \n   这篇论文针对高效 Vision Transformer 提出 Trio-ViT 框架，移除 Softmax 并优化量化。主要贡献是通过算法和硬件级加速，在图像任务中实现 3.6 倍 FPS 提升，同时保持精度，适用于资源受限设备。\n\n4. **Sequence Compression Speeds Up Credit Assignment in Reinforcement Learning**  \n   作者包括 Jürgen Schmidhuber，这篇话题性强的工作提出 Chunked-TD 算法，使用世界模型压缩序列加速信用分配。主要发现：在强化学习任务中，比传统 TD(λ) 更快解决问题，ICML 2024 版本。\n\n5. **Learning Planning Abstractions from Language**  \n   作者包括 Jiajun Wu，这篇论文开发 PARL 框架，从语言演示中学习状态和动作抽象。主要贡献：实现跨场景泛化，如新对象和任务，支持更长的规划周期，网站提供更多细节。\n\n6. **Unified Locational Differential Privacy Framework**  \n   这篇论文提出统一框架保护地理数据隐私，支持多种数据类型聚合。主要贡献：使用本地 DP 机制（如 Gaussian 机制）在四数据集上验证实用性，确保隐私保护同时保持分析准确性。\n\n7. **Out-of-Distribution Adaptation in Offline RL: Counterfactual Reasoning via Causal Normalizing Flows**  \n   相关于强化学习，这篇论文引入 MOOD-CRL 算法，通过因果推理处理离线 RL 中的分布偏移。主要发现：在 OOD 场景下显著提升性能，超过传统方法。\n\n8. **Enhancing O-RAN Security: Evasion Attacks and Robust Defenses for Graph Reinforcement Learning-based Connection Management**  \n   这篇论文探讨 O-RAN 的安全问题，提出 evasion 攻击和防御策略。主要贡献：使用 Graph Neural Network 改善连接管理，防御后覆盖率提升 15%，提交给 IEEE。\n\n9. **Playing Games with your PET: Extending the Partial Exploration Tool to Stochastic Games**  \n   这篇论文扩展 PET 工具，支持随机游戏验证。主要发现：提供高效的 value iteration 算法，实验显示在随机游戏中性能优于其他工具。\n\n10. **Causal inference approach to appraise long-term effects of maintenance policy on functional performance of asphalt pavements**  \n    这篇论文使用因果推理评估路面维护策略。主要贡献：提出结合结构模型的框架，量化维护对路面性能的影响，帮助政策制定。\n\n其他论文主题多样，如医疗 AI（第 9、14、33 篇等，快速提一下：第 9 篇提出 AI 框架提升大数据质量，第 14 篇使用 VSA 模型进行视觉问答），机器人学习（第 11、29 篇等，第 11 篇探索信息驱动的机器人操作，第 29 篇提出 ScrewMimic 框架提升双臂模仿），以及 LLMs 应用（第 13、15 篇等，第 13 篇分析 LLMs 在多代理协作中的稳定性，第 15 篇开发自优化系统生成评论响应）。这些论文虽有创新，但相对次要或技术细节较窄，故从简概述。\n\n总之，今天的更新突显 AI 在实际应用中的潜力，LLMs 和强化学习领域尤为活跃，感兴趣的读者可关注这些前沿工作。明天的快报见！",
  "papers": [
    {
      "arxiv_id": "2405.03903v1",
      "title": "Unified Locational Differential Privacy Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Aman Priyanshu",
        "Yash Maurya",
        "Suriya Ganesh",
        "Vy Tran"
      ],
      "abstract": "Aggregating statistics over geographical regions is important for many\napplications, such as analyzing income, election results, and disease spread.\nHowever, the sensitive nature of this data necessitates strong privacy\nprotections to safeguard individuals. In this work, we present a unified\nlocational differential privacy (DP) framework to enable private aggregation of\nvarious data types, including one-hot encoded, boolean, float, and integer\narrays, over geographical regions. Our framework employs local DP mechanisms\nsuch as randomized response, the exponential mechanism, and the Gaussian\nmechanism. We evaluate our approach on four datasets representing significant\nlocation data aggregation scenarios. Results demonstrate the utility of our\nframework in providing formal DP guarantees while enabling geographical data\nanalysis.",
      "tldr_zh": "该研究提出一个统一的Locational Differential Privacy (DP) 框架，用于在地理区域上安全聚合各种数据类型，包括 one-hot encoded、boolean、float 和 integer arrays，从而保护敏感数据隐私。该框架采用本地DP机制，如 randomized response、exponential mechanism 和 Gaussian mechanism，来处理应用场景如收入分析、选举结果和疾病传播。实验在四个真实数据集上评估，证明了框架能提供正式的DP保证，同时保持了地理数据分析的有效性。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.03903v1",
      "published_date": "2024-05-06 23:33:52 UTC",
      "updated_date": "2024-05-06 23:33:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:12:35.330161"
    },
    {
      "arxiv_id": "2405.03901v1",
      "title": "OmniActions: Predicting Digital Actions in Response to Real-World Multimodal Sensory Inputs with LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Jiahao Nick Li",
        "Yan Xu",
        "Tovi Grossman",
        "Stephanie Santosa",
        "Michelle Li"
      ],
      "abstract": "The progression to \"Pervasive Augmented Reality\" envisions easy access to\nmultimodal information continuously. However, in many everyday scenarios, users\nare occupied physically, cognitively or socially. This may increase the\nfriction to act upon the multimodal information that users encounter in the\nworld. To reduce such friction, future interactive interfaces should\nintelligently provide quick access to digital actions based on users' context.\nTo explore the range of possible digital actions, we conducted a diary study\nthat required participants to capture and share the media that they intended to\nperform actions on (e.g., images or audio), along with their desired actions\nand other contextual information. Using this data, we generated a holistic\ndesign space of digital follow-up actions that could be performed in response\nto different types of multimodal sensory inputs. We then designed OmniActions,\na pipeline powered by large language models (LLMs) that processes multimodal\nsensory inputs and predicts follow-up actions on the target information\ngrounded in the derived design space. Using the empirical data collected in the\ndiary study, we performed quantitative evaluations on three variations of LLM\ntechniques (intent classification, in-context learning and finetuning) and\nidentified the most effective technique for our task. Additionally, as an\ninstantiation of the pipeline, we developed an interactive prototype and\nreported preliminary user feedback about how people perceive and react to the\naction predictions and its errors.",
      "tldr_zh": "该研究探讨了在“Pervasive Augmented Reality”环境中，用户因身体、认知或社会因素而难以处理多模态感官输入的问题，旨在通过智能接口减少互动摩擦。研究者首先进行了一项diary study，收集用户意图、媒体和上下文数据，以生成一个全面的设计空间，涵盖对不同多模态输入的数字后续动作。接着，他们设计了OmniActions管道，利用大型语言模型(LLMs)处理这些输入，并通过intent classification、in-context learning和finetuning三种技术预测动作，最终确定finetuning为最有效方法。实验评估和交互原型的用户反馈表明，该系统能有效提升用户体验，并为未来智能接口提供实用指导。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Paper accepted to the 2024 CHI Conference on Human Factors in\n  Computing Systems (CHI 2024)",
      "pdf_url": "http://arxiv.org/pdf/2405.03901v1",
      "published_date": "2024-05-06 23:11:00 UTC",
      "updated_date": "2024-05-06 23:11:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:12:49.288806"
    },
    {
      "arxiv_id": "2405.03892v1",
      "title": "Out-of-Distribution Adaptation in Offline RL: Counterfactual Reasoning via Causal Normalizing Flows",
      "title_zh": "离线强化学习中的分布外适应：通过因果归一化流的反事实推理",
      "authors": [
        "Minjae Cho",
        "Jonathan P. How",
        "Chuangchuang Sun"
      ],
      "abstract": "Despite notable successes of Reinforcement Learning (RL), the prevalent use\nof an online learning paradigm prevents its widespread adoption, especially in\nhazardous or costly scenarios. Offline RL has emerged as an alternative\nsolution, learning from pre-collected static datasets. However, this offline\nlearning introduces a new challenge known as distributional shift, degrading\nthe performance when the policy is evaluated on scenarios that are\nOut-Of-Distribution (OOD) from the training dataset. Most existing offline RL\nresolves this issue by regularizing policy learning within the information\nsupported by the given dataset. However, such regularization overlooks the\npotential for high-reward regions that may exist beyond the dataset. This\nmotivates exploring novel offline learning techniques that can make\nimprovements beyond the data support without compromising policy performance,\npotentially by learning causation (cause-and-effect) instead of correlation\nfrom the dataset. In this paper, we propose the MOOD-CRL (Model-based Offline\nOOD-Adapting Causal RL) algorithm, which aims to address the challenge of\nextrapolation for offline policy training through causal inference instead of\npolicy-regularizing methods. Specifically, Causal Normalizing Flow (CNF) is\ndeveloped to learn the transition and reward functions for data generation and\naugmentation in offline policy evaluation and training. Based on the\ndata-invariant, physics-based qualitative causal graph and the observational\ndata, we develop a novel learning scheme for CNF to learn the quantitative\nstructural causal model. As a result, CNF gains predictive and counterfactual\nreasoning capabilities for sequential decision-making tasks, revealing a high\npotential for OOD adaptation. Our CNF-based offline RL approach is validated\nthrough empirical evaluations, outperforming model-free and model-based methods\nby a significant margin.",
      "tldr_zh": "本文研究了离线强化学习（Offline RL）中分布偏移（distributional shift）问题，该问题导致在 Out-Of-Distribution (OOD) 场景下政策性能下降。作者提出 MOOD-CRL 算法，通过因果推理取代传统政策正则化方法，利用 Causal Normalizing Flow (CNF) 学习过渡和奖励函数，实现数据增强和反事实推理（Counterfactual Reasoning）。实验结果显示，该方法在序列决策任务中显著优于无模型和有模型基准，证明了其在 OOD 适应方面的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted for review at IEEE: Neural Networks and Learning Systems",
      "pdf_url": "http://arxiv.org/pdf/2405.03892v1",
      "published_date": "2024-05-06 22:44:32 UTC",
      "updated_date": "2024-05-06 22:44:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:12:59.961838"
    },
    {
      "arxiv_id": "2405.03891v1",
      "title": "Enhancing O-RAN Security: Evasion Attacks and Robust Defenses for Graph Reinforcement Learning-based Connection Management",
      "title_zh": "翻译失败",
      "authors": [
        "Ravikumar Balakrishnan",
        "Marius Arvinte",
        "Nageen Himayat",
        "Hosein Nikopour",
        "Hassnaa Moustafa"
      ],
      "abstract": "Adversarial machine learning, focused on studying various attacks and\ndefenses on machine learning (ML) models, is rapidly gaining importance as ML\nis increasingly being adopted for optimizing wireless systems such as Open\nRadio Access Networks (O-RAN). A comprehensive modeling of the security threats\nand the demonstration of adversarial attacks and defenses on practical AI based\nO-RAN systems is still in its nascent stages. We begin by conducting threat\nmodeling to pinpoint attack surfaces in O-RAN using an ML-based Connection\nmanagement application (xApp) as an example. The xApp uses a Graph Neural\nNetwork trained using Deep Reinforcement Learning and achieves on average 54%\nimprovement in the coverage rate measured as the 5th percentile user data\nrates. We then formulate and demonstrate evasion attacks that degrade the\ncoverage rates by as much as 50% through injecting bounded noise at different\nthreat surfaces including the open wireless medium itself. Crucially, we also\ncompare and contrast the effectiveness of such attacks on the ML-based xApp and\na non-ML based heuristic. We finally develop and demonstrate robust\ntraining-based defenses against the challenging physical/jamming-based attacks\nand show a 15% improvement in the coverage rates when compared to employing no\ndefense over a range of noise budgets",
      "tldr_zh": "该研究针对 O-RAN（Open Radio Access Networks）的安全问题，进行威胁建模，并以基于 Graph Neural Network 和 Deep Reinforcement Learning 训练的连接管理应用（xApp）为例，展示了其平均提高 54% 覆盖率的效果。研究者制定并演示了 evasion attacks，通过注入有界噪声攻击不同的威胁面，包括无线介质，导致覆盖率下降多达 50%，并比较了这些攻击对 ML-based xApp 和非 ML-based 启发式方法的有效性差异。最后，开发了基于鲁棒训练的防御措施，对抗物理/干扰攻击，在各种噪声预算下，与无防御相比，覆盖率提高了 15%。这为增强 O-RAN 的安全性和可靠性提供了重要见解。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "This work has been submitted to the IEEE for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2405.03891v1",
      "published_date": "2024-05-06 22:27:24 UTC",
      "updated_date": "2024-05-06 22:27:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:13:12.180067"
    },
    {
      "arxiv_id": "2405.03885v2",
      "title": "Playing Games with your PET: Extending the Partial Exploration Tool to Stochastic Games",
      "title_zh": "翻译失败",
      "authors": [
        "Tobias Meggendorfer",
        "Maximilian Weininger"
      ],
      "abstract": "We present version 2.0 of the Partial Exploration Tool (PET), a tool for\nverification of probabilistic systems. We extend the previous version by adding\nsupport for stochastic games, based on a recent unified framework for sound\nvalue iteration algorithms. Thereby, PET2 is the first tool implementing a\nsound and efficient approach for solving stochastic games with objectives of\nthe type reachability/safety and mean payoff. We complement this approach by\ndeveloping and implementing a partial-exploration based variant for all three\nobjectives. Our experimental evaluation shows that PET2 offers the most\nefficient partial-exploration based algorithm and is the most viable tool on\nSGs, even outperforming unsound tools.",
      "tldr_zh": "我们介绍了 Partial Exploration Tool (PET) 的版本 2.0，该工具扩展了支持 stochastic games 的功能，基于一个统一的框架实现了 sound value iteration algorithms。\nPET2 是第一个提供 sound 和 efficient 方法来解决 stochastic games 中 reachability/safety 和 mean payoff 目标的工具，并开发了 partial-exploration based variant。\n实验结果显示，PET2 提供了最有效的 partial-exploration based 算法，在 stochastic games 的处理上表现最佳，甚至优于 unsound 工具。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.GT",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.03885v2",
      "published_date": "2024-05-06 22:07:26 UTC",
      "updated_date": "2024-05-13 07:41:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:13:24.986922"
    },
    {
      "arxiv_id": "2405.03882v3",
      "title": "Trio-ViT: Post-Training Quantization and Acceleration for Softmax-Free Efficient Vision Transformer",
      "title_zh": "Trio-ViT：针对无Softmax",
      "authors": [
        "Huihong Shi",
        "Haikuo Shao",
        "Wendong Mao",
        "Zhongfeng Wang"
      ],
      "abstract": "Motivated by the huge success of Transformers in the field of natural\nlanguage processing (NLP), Vision Transformers (ViTs) have been rapidly\ndeveloped and achieved remarkable performance in various computer vision tasks.\nHowever, their huge model sizes and intensive computations hinder ViTs'\ndeployment on embedded devices, calling for effective model compression\nmethods, such as quantization. Unfortunately, due to the existence of\nhardware-unfriendly and quantization-sensitive non-linear operations,\nparticularly {Softmax}, it is non-trivial to completely quantize all operations\nin ViTs, yielding either significant accuracy drops or non-negligible hardware\ncosts. In response to challenges associated with \\textit{standard ViTs}, we\nfocus our attention towards the quantization and acceleration for\n\\textit{efficient ViTs}, which not only eliminate the troublesome Softmax but\nalso integrate linear attention with low computational complexity, and propose\nTrio-ViT accordingly. Specifically, at the algorithm level, we develop a\n{tailored post-training quantization engine} taking the unique activation\ndistributions of Softmax-free efficient ViTs into full consideration, aiming to\nboost quantization accuracy. Furthermore, at the hardware level, we build an\naccelerator dedicated to the specific Convolution-Transformer hybrid\narchitecture of efficient ViTs, thereby enhancing hardware efficiency.\nExtensive experimental results consistently prove the effectiveness of our\nTrio-ViT framework. {Particularly, we can gain up to\n$\\uparrow$$\\mathbf{3.6}\\times$, $\\uparrow$$\\mathbf{5.0}\\times$, and\n$\\uparrow$$\\mathbf{7.3}\\times$ FPS under comparable accuracy over\nstate-of-the-art ViT accelerators, as well as $\\uparrow$$\\mathbf{6.0}\\times$,\n$\\uparrow$$\\mathbf{1.5}\\times$, and $\\uparrow$$\\mathbf{2.1}\\times$ DSP\nefficiency.} Codes are available at\n\\url{https://github.com/shihuihong214/Trio-ViT}.",
      "tldr_zh": "本研究提出Trio-ViT框架，针对无Softmax的高效Vision Transformer (ViTs)，旨在通过后训练量化(post-training quantization)和加速优化，提升其在嵌入式设备上的部署效率。框架在算法层面开发了一个量身定制的量化引擎，充分考虑高效ViTs的独特激活分布，以提高量化准确性；在硬件层面，构建了专用的Convolution-Transformer混合架构加速器，进一步增强硬件效率。实验结果显示，Trio-ViT在可比准确性下，相比最先进ViT加速器，帧率(FPS)提升高达3.6倍、5.0倍和7.3倍，DSP效率也分别提升6.0倍、1.5倍和2.1倍。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.03882v3",
      "published_date": "2024-05-06 21:57:35 UTC",
      "updated_date": "2024-09-30 07:01:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:13:36.005269"
    },
    {
      "arxiv_id": "2405.03878v2",
      "title": "Sequence Compression Speeds Up Credit Assignment in Reinforcement Learning",
      "title_zh": "序列压缩加速强化学习中的信用分配",
      "authors": [
        "Aditya A. Ramesh",
        "Kenny Young",
        "Louis Kirsch",
        "Jürgen Schmidhuber"
      ],
      "abstract": "Temporal credit assignment in reinforcement learning is challenging due to\ndelayed and stochastic outcomes. Monte Carlo targets can bridge long delays\nbetween action and consequence but lead to high-variance targets due to\nstochasticity. Temporal difference (TD) learning uses bootstrapping to overcome\nvariance but introduces a bias that can only be corrected through many\niterations. TD($\\lambda$) provides a mechanism to navigate this bias-variance\ntradeoff smoothly. Appropriately selecting $\\lambda$ can significantly improve\nperformance. Here, we propose Chunked-TD, which uses predicted probabilities of\ntransitions from a model for computing $\\lambda$-return targets. Unlike other\nmodel-based solutions to credit assignment, Chunked-TD is less vulnerable to\nmodel inaccuracies. Our approach is motivated by the principle of history\ncompression and 'chunks' trajectories for conventional TD learning. Chunking\nwith learned world models compresses near-deterministic regions of the\nenvironment-policy interaction to speed up credit assignment while still\nbootstrapping when necessary. We propose algorithms that can be implemented\nonline and show that they solve some problems much faster than conventional\nTD($\\lambda$).",
      "tldr_zh": "这项研究针对强化学习中的时间信用分配问题，探讨了如何处理延迟和随机性带来的挑战，如 Monte Carlo 方法的高方差和 TD 学习中的偏差。作者提出 Chunked-TD 算法，利用模型预测的转移概率来计算 $\\lambda$-return 目标，通过历史压缩原理将轨迹分成“chunks”，从而加速信用分配过程，同时在必要时进行 bootstrapping。实验结果显示，Chunked-TD 比传统 TD($\\lambda$) 方法更快地解决某些问题，且更不易受模型不准确影响。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2024 version",
      "pdf_url": "http://arxiv.org/pdf/2405.03878v2",
      "published_date": "2024-05-06 21:49:29 UTC",
      "updated_date": "2024-06-04 05:28:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:13:47.277750"
    },
    {
      "arxiv_id": "2405.03873v1",
      "title": "Investigating Personalized Driving Behaviors in Dilemma Zones: Analysis and Prediction of Stop-or-Go Decisions",
      "title_zh": "翻译失败",
      "authors": [
        "Ziye Qin",
        "Siyan Li",
        "Guoyuan Wu",
        "Matthew J. Barth",
        "Amr Abdelraouf",
        "Rohit Gupta",
        "Kyungtae Han"
      ],
      "abstract": "Dilemma zones at signalized intersections present a commonly occurring but\nunsolved challenge for both drivers and traffic operators. Onsets of the yellow\nlights prompt varied responses from different drivers: some may brake abruptly,\ncompromising the ride comfort, while others may accelerate, increasing the risk\nof red-light violations and potential safety hazards. Such diversity in\ndrivers' stop-or-go decisions may result from not only surrounding traffic\nconditions, but also personalized driving behaviors. To this end, identifying\npersonalized driving behaviors and integrating them into advanced driver\nassistance systems (ADAS) to mitigate the dilemma zone problem presents an\nintriguing scientific question. In this study, we employ a game engine-based\n(i.e., CARLA-enabled) driving simulator to collect high-resolution vehicle\ntrajectories, incoming traffic signal phase and timing information, and\nstop-or-go decisions from four subject drivers in various scenarios. This\napproach allows us to analyze personalized driving behaviors in dilemma zones\nand develop a Personalized Transformer Encoder to predict individual drivers'\nstop-or-go decisions. The results show that the Personalized Transformer\nEncoder improves the accuracy of predicting driver decision-making in the\ndilemma zone by 3.7% to 12.6% compared to the Generic Transformer Encoder, and\nby 16.8% to 21.6% over the binary logistic regression model.",
      "tldr_zh": "本文研究了信号灯交叉口的困境区（Dilemma Zones）中司机的个性化驾驶行为，分析了影响停止或继续（stop-or-go）决策的因素，包括交通条件和个人习惯。研究团队使用 CARLA 驱动模拟器收集高分辨率车辆轨迹、交通信号信息和四名司机的决策数据，并开发了 Personalized Transformer Encoder 模型来预测这些行为。结果显示，该模型相比 Generic Transformer Encoder 提高了 3.7% 到 12.6% 的预测准确率，并比二元逻辑回归模型提高了 16.8% 到 21.6%，为先进驾驶辅助系统（ADAS）集成个性化行为提供了新方法。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.03873v1",
      "published_date": "2024-05-06 21:39:25 UTC",
      "updated_date": "2024-05-06 21:39:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:14:01.060031"
    },
    {
      "arxiv_id": "2405.03870v1",
      "title": "AI-Driven Frameworks for Enhancing Data Quality in Big Data Ecosystems: Error_Detection, Correction, and Metadata Integration",
      "title_zh": "翻译失败",
      "authors": [
        "Widad Elouataoui"
      ],
      "abstract": "The widespread adoption of big data has ushered in a new era of data-driven\ndecision-making, transforming numerous industries and sectors. However, the\nefficacy of these decisions hinges on the quality of the underlying data. Poor\ndata quality can result in inaccurate analyses and deceptive conclusions.\nManaging the vast volume, velocity, and variety of data sources presents\nsignificant challenges, heightening the importance of addressing big data\nquality issues. While there has been increased attention from both academia and\nindustry, current approaches often lack comprehensiveness and universality.\nThey tend to focus on limited metrics, neglecting other dimensions of data\nquality. Moreover, existing methods are often context-specific, limiting their\napplicability across different domains. There is a clear need for intelligent,\nautomated approaches leveraging artificial intelligence (AI) for advanced data\nquality corrections.\n  To bridge these gaps, this Ph.D. thesis proposes a novel set of\ninterconnected frameworks aimed at enhancing big data quality comprehensively.\nFirstly, we introduce new quality metrics and a weighted scoring system for\nprecise data quality assessment. Secondly, we present a generic framework for\ndetecting various quality anomalies using AI models. Thirdly, we propose an\ninnovative framework for correcting detected anomalies through predictive\nmodeling. Additionally, we address metadata quality enhancement within big data\necosystems. These frameworks are rigorously tested on diverse datasets,\ndemonstrating their efficacy in improving big data quality. Finally, the thesis\nconcludes with insights and suggestions for future research directions.",
      "tldr_zh": "本论文针对大数据生态系统中数据质量问题（如数据量大、速度快和多样性导致的错误分析），提出一套基于AI的框架来全面提升数据质量。框架包括引入新的质量指标和加权评分系统，用于精确评估；一个通用AI模型框架用于检测各种质量异常；以及一个创新的预测建模框架用于修正这些异常，同时优化元数据质量。这些框架在多样数据集上进行了严格测试，证明了其有效性，最终为大数据质量管理提供见解并建议未来研究方向。",
      "categories": [
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.AI",
      "comment": "Doctoral thesis",
      "pdf_url": "http://arxiv.org/pdf/2405.03870v1",
      "published_date": "2024-05-06 21:36:45 UTC",
      "updated_date": "2024-05-06 21:36:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:14:11.339667"
    },
    {
      "arxiv_id": "2405.03869v5",
      "title": "Outlier Gradient Analysis: Efficiently Identifying Detrimental Training Samples for Deep Learning Models",
      "title_zh": "翻译失败",
      "authors": [
        "Anshuman Chhabra",
        "Bo Li",
        "Jian Chen",
        "Prasant Mohapatra",
        "Hongfu Liu"
      ],
      "abstract": "A core data-centric learning challenge is the identification of training\nsamples that are detrimental to model performance. Influence functions serve as\na prominent tool for this task and offer a robust framework for assessing\ntraining data influence on model predictions. Despite their widespread use,\ntheir high computational cost associated with calculating the inverse of the\nHessian matrix pose constraints, particularly when analyzing large-sized deep\nmodels. In this paper, we establish a bridge between identifying detrimental\ntraining samples via influence functions and outlier gradient detection. This\ntransformation not only presents a straightforward and Hessian-free formulation\nbut also provides insights into the role of the gradient in sample impact.\nThrough systematic empirical evaluations, we first validate the hypothesis of\nour proposed outlier gradient analysis approach on synthetic datasets. We then\ndemonstrate its effectiveness in detecting mislabeled samples in vision models\nand selecting data samples for improving performance of natural language\nprocessing transformer models. We also extend its use to influential sample\nidentification for fine-tuning Large Language Models.",
      "tldr_zh": "这篇论文提出了一种名为Outlier Gradient Analysis的方法，用于高效识别对深度学习模型性能有害的训练样本，从而解决Influence functions计算成本高的问题（如计算Hessian矩阵的逆）。该方法通过将Influence functions与异常梯度检测相结合，提供一个简单、无需Hessian的公式，并揭示梯度在样本影响中的关键作用。实验结果显示，该方法在合成数据集上验证了其假设，并在实际应用中成功检测视觉模型中的错误标记样本、优化NLP Transformer模型的性能，并扩展到大语言模型的微调中识别影响样本。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to ICML 2025 (Spotlight)",
      "pdf_url": "http://arxiv.org/pdf/2405.03869v5",
      "published_date": "2024-05-06 21:34:46 UTC",
      "updated_date": "2025-05-03 14:54:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:14:24.298272"
    },
    {
      "arxiv_id": "2405.03865v1",
      "title": "Information-driven Affordance Discovery for Efficient Robotic Manipulation",
      "title_zh": "信息驱动的可供性发现用于高效机器人操作",
      "authors": [
        "Pietro Mazzaglia",
        "Taco Cohen",
        "Daniel Dijkman"
      ],
      "abstract": "Robotic affordances, providing information about what actions can be taken in\na given situation, can aid robotic manipulation. However, learning about\naffordances requires expensive large annotated datasets of interactions or\ndemonstrations. In this work, we argue that well-directed interactions with the\nenvironment can mitigate this problem and propose an information-based measure\nto augment the agent's objective and accelerate the affordance discovery\nprocess. We provide a theoretical justification of our approach and we\nempirically validate the approach both in simulation and real-world tasks. Our\nmethod, which we dub IDA, enables the efficient discovery of visual affordances\nfor several action primitives, such as grasping, stacking objects, or opening\ndrawers, strongly improving data efficiency in simulation, and it allows us to\nlearn grasping affordances in a small number of interactions, on a real-world\nsetup with a UFACTORY XArm 6 robot arm.",
      "tldr_zh": "该论文探讨了机器人 affordances 的发现问题，以提升操作效率，因为传统方法需要大量标注数据。作者提出 IDA（Information-driven Affordance Discovery）方法，使用信息-based measure 增强代理的目标，指导环境交互并加速 affordance 学习过程，并提供了理论依据。实验在模拟和真实世界任务中验证了 IDA 的有效性，例如在 grasping、stacking objects 和 opening drawers 等任务上，大大提高了数据效率，并在 UFACTORY XArm 6 机器人臂上仅需少量交互即可学习 grasping affordances。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2308.14915",
      "pdf_url": "http://arxiv.org/pdf/2405.03865v1",
      "published_date": "2024-05-06 21:25:51 UTC",
      "updated_date": "2024-05-06 21:25:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:14:36.537817"
    },
    {
      "arxiv_id": "2405.03864v1",
      "title": "Learning Planning Abstractions from Language",
      "title_zh": "从语言中学习规划抽象",
      "authors": [
        "Weiyu Liu",
        "Geng Chen",
        "Joy Hsu",
        "Jiayuan Mao",
        "Jiajun Wu"
      ],
      "abstract": "This paper presents a framework for learning state and action abstractions in\nsequential decision-making domains. Our framework, planning abstraction from\nlanguage (PARL), utilizes language-annotated demonstrations to automatically\ndiscover a symbolic and abstract action space and induce a latent state\nabstraction based on it. PARL consists of three stages: 1) recovering\nobject-level and action concepts, 2) learning state abstractions, abstract\naction feasibility, and transition models, and 3) applying low-level policies\nfor abstract actions. During inference, given the task description, PARL first\nmakes abstract action plans using the latent transition and feasibility\nfunctions, then refines the high-level plan using low-level policies. PARL\ngeneralizes across scenarios involving novel object instances and environments,\nunseen concept compositions, and tasks that require longer planning horizons\nthan settings it is trained on.",
      "tldr_zh": "这篇论文提出了一种名为 PARL 的框架，用于在顺序决策领域从语言标注的演示中学习状态和动作抽象。PARL 通过三个阶段实现：首先恢复对象级和动作概念，其次学习状态抽象、抽象动作可行性以及过渡模型，最后应用低级策略执行抽象动作。在推理过程中，PARL 基于任务描述生成高层抽象计划并通过低级策略细化，从而在涉及新对象实例、新环境、未见概念组合以及更长规划地平线的场景中实现泛化。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "The first two authors contributed equally. The last two authors\n  provide equal advising. Project website: https://parl2024.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2405.03864v1",
      "published_date": "2024-05-06 21:24:22 UTC",
      "updated_date": "2024-05-06 21:24:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:14:47.692455"
    },
    {
      "arxiv_id": "2405.03862v3",
      "title": "Persona Inconstancy in Multi-Agent LLM Collaboration: Conformity, Confabulation, and Impersonation",
      "title_zh": "翻译失败",
      "authors": [
        "Razan Baltaji",
        "Babak Hemmatian",
        "Lav R. Varshney"
      ],
      "abstract": "Multi-agent AI systems can be used for simulating collective decision-making\nin scientific and practical applications. They can also be used to introduce a\ndiverse group discussion step in chatbot pipelines, enhancing the cultural\nsensitivity of the chatbot's responses. These applications, however, are\npredicated on the ability of AI agents to reliably adopt assigned personas and\nmimic human interactions. To see whether LLM agents satisfy these requirements,\nwe examine AI agent ensembles engaged in cross-national collaboration and\ndebate by analyzing their private responses and chat transcripts. Our findings\nsuggest that multi-agent discussions can support collective AI decisions that\nmore often reflect diverse perspectives, yet this effect is tempered by the\nagents' susceptibility to conformity due to perceived peer pressure and\noccasional challenges in maintaining consistent personas and opinions.\nInstructions that encourage debate in support of one's opinions rather than\ncollaboration increase the rate of inconstancy. Without addressing the factors\nwe identify, the full potential of multi-agent frameworks for producing more\nculturally diverse AI outputs or more realistic simulations of group\ndecision-making may remain untapped.",
      "tldr_zh": "本文研究了多智能体 LLM 协作中的角色不一致问题，包括 Conformity（从众）、Confabulation（编造）和 Impersonation（扮演他人），这些问题影响了 AI 代理在跨国合作和辩论中的可靠性和多样性表现。研究通过分析 AI 代理的私人响应和聊天记录，发现多智能体讨论能促进更具多样视角的集体决策，但代理易受同伴压力影响，导致角色不稳定。鼓励辩论而非合作的指令会加剧这种不一致性。作者指出，若不解决这些因素，多智能体框架在产生文化多样 AI 输出或模拟群体决策方面的潜力将无法充分发挥。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages, 8 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2405.03862v3",
      "published_date": "2024-05-06 21:20:35 UTC",
      "updated_date": "2024-08-14 18:01:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:15:02.542604"
    },
    {
      "arxiv_id": "2405.03852v1",
      "title": "VSA4VQA: Scaling a Vector Symbolic Architecture to Visual Question Answering on Natural Images",
      "title_zh": "翻译失败",
      "authors": [
        "Anna Penzkofer",
        "Lei Shi",
        "Andreas Bulling"
      ],
      "abstract": "While Vector Symbolic Architectures (VSAs) are promising for modelling\nspatial cognition, their application is currently limited to artificially\ngenerated images and simple spatial queries. We propose VSA4VQA - a novel 4D\nimplementation of VSAs that implements a mental representation of natural\nimages for the challenging task of Visual Question Answering (VQA). VSA4VQA is\nthe first model to scale a VSA to complex spatial queries. Our method is based\non the Semantic Pointer Architecture (SPA) to encode objects in a\nhyperdimensional vector space. To encode natural images, we extend the SPA to\ninclude dimensions for object's width and height in addition to their spatial\nlocation. To perform spatial queries we further introduce learned spatial query\nmasks and integrate a pre-trained vision-language model for answering\nattribute-related questions. We evaluate our method on the GQA benchmark\ndataset and show that it can effectively encode natural images, achieving\ncompetitive performance to state-of-the-art deep learning methods for zero-shot\nVQA.",
      "tldr_zh": "本研究提出 VSA4VQA，一种扩展 Vector Symbolic Architectures (VSAs) 的新 4D 实现，用于在自然图像上进行 Visual Question Answering (VQA)，以处理复杂空间查询。方法基于 Semantic Pointer Architecture (SPA)，在超维向量空间中编码对象的位置、宽度和高度，并引入学习的空间查询掩码 (learned spatial query masks) 以及预训练的视觉语言模型来回答属性相关问题。通过在 GQA benchmark 数据集上的评估，VSA4VQA 实现了与最先进深度学习方法相当的零样本 VQA 性能，展示了其在自然图像表示的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "To be published in the Proceedings of the Annual Meeting of the\n  Cognitive Science Society (CogSci'24)",
      "pdf_url": "http://arxiv.org/pdf/2405.03852v1",
      "published_date": "2024-05-06 20:59:45 UTC",
      "updated_date": "2024-05-06 20:59:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:15:12.739990"
    },
    {
      "arxiv_id": "2405.03845v1",
      "title": "Self-Improving Customer Review Response Generation Based on LLMs",
      "title_zh": "基于LLMs的自我改进客户评论响应生成",
      "authors": [
        "Guy Azov",
        "Tatiana Pelc",
        "Adi Fledel Alon",
        "Gila Kamhi"
      ],
      "abstract": "Previous studies have demonstrated that proactive interaction with user\nreviews has a positive impact on the perception of app users and encourages\nthem to submit revised ratings. Nevertheless, developers encounter challenges\nin managing a high volume of reviews, particularly in the case of popular apps\nwith a substantial influx of daily reviews. Consequently, there is a demand for\nautomated solutions aimed at streamlining the process of responding to user\nreviews. To address this, we have developed a new system for generating\nautomatic responses by leveraging user-contributed documents with the help of\nretrieval-augmented generation (RAG) and advanced Large Language Models (LLMs).\nOur solution, named SCRABLE, represents an adaptive customer review response\nautomation that enhances itself with self-optimizing prompts and a judging\nmechanism based on LLMs. Additionally, we introduce an automatic scoring\nmechanism that mimics the role of a human evaluator to assess the quality of\nresponses generated in customer review domains. Extensive experiments and\nanalyses conducted on real-world datasets reveal that our method is effective\nin producing high-quality responses, yielding improvement of more than 8.5%\ncompared to the baseline. Further validation through manual examination of the\ngenerated responses underscores the efficacy our proposed system.",
      "tldr_zh": "本文提出 SCRABLE 系统，利用检索增强生成（RAG）和大型语言模型（LLMs）自动生成客户评论回应，以帮助开发者高效管理海量评论。系统通过自优化提示、基于 LLMs 的判断机制以及模拟人类评估的自动评分机制，实现响应的持续改进。在真实数据集上的实验表明，SCRABLE 比基线方法提升超过 8.5%，并经手动检查验证其生成的高质量回应。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages, 4 figure, 8 figures in Appendix, accepted to LREC-COLING\n  2024 workshop",
      "pdf_url": "http://arxiv.org/pdf/2405.03845v1",
      "published_date": "2024-05-06 20:50:17 UTC",
      "updated_date": "2024-05-06 20:50:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:15:23.931907"
    },
    {
      "arxiv_id": "2405.03842v1",
      "title": "A Novel Cross-band CSI Prediction Scheme for Multi-band Fingerprint based Localization",
      "title_zh": "翻译失败",
      "authors": [
        "Yuan Ruihao",
        "Huang Kaixuan",
        "Zhang Shunqing"
      ],
      "abstract": "Because of the advantages of computation complexity compared with traditional\nlocalization algorithms, fingerprint based localization is getting increasing\ndemand. Expanding the fingerprint database from the frequency domain by channel\nreconstruction can improve localization accuracy. However, in a mobility\nenvironment, the channel reconstruction accuracy is limited by the time-varying\nparameters. In this paper, we proposed a system to extract the time-varying\nparameters based on space-alternating generalized expectation maximization\n(SAGE) algorithm, then used variational auto-encoder (VAE) to reconstruct the\nchannel state information on another channel. The proposed scheme is tested on\nthe data generated by the deep-MIMO channel model. Mathematical analysis for\nthe viability of our system is also shown in this paper.",
      "tldr_zh": "该论文提出了一种新型跨频段CSI预测方案，用于提升多频段指纹定位的准确性，以应对移动环境中时间变化参数对频道重建的影响。方案首先利用SAGE算法提取时间变化参数，然后通过VAE模型重建另一个频道的Channel State Information (CSI)。实验在deep-MIMO频道模型生成的数据上进行验证，并通过数学分析证明了系统的可行性。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.03842v1",
      "published_date": "2024-05-06 20:44:58 UTC",
      "updated_date": "2024-05-06 20:44:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:15:36.364136"
    },
    {
      "arxiv_id": "2405.03832v3",
      "title": "Guylingo: The Republic of Guyana Creole Corpora",
      "title_zh": "Guylingo：圭亚那共和国克里奥尔语料库",
      "authors": [
        "Christopher Clarke",
        "Roland Daynauth",
        "Charlene Wilkinson",
        "Hubert Devonish",
        "Jason Mars"
      ],
      "abstract": "While major languages often enjoy substantial attention and resources, the\nlinguistic diversity across the globe encompasses a multitude of smaller,\nindigenous, and regional languages that lack the same level of computational\nsupport. One such region is the Caribbean. While commonly labeled as \"English\nspeaking\", the ex-British Caribbean region consists of a myriad of Creole\nlanguages thriving alongside English. In this paper, we present Guylingo: a\ncomprehensive corpus designed for advancing NLP research in the domain of\nCreolese (Guyanese English-lexicon Creole), the most widely spoken language in\nthe culturally rich nation of Guyana. We first outline our framework for\ngathering and digitizing this diverse corpus, inclusive of colloquial\nexpressions, idioms, and regional variations in a low-resource language. We\nthen demonstrate the challenges of training and evaluating NLP models for\nmachine translation in Creole. Lastly, we discuss the unique opportunities\npresented by recent NLP advancements for accelerating the formal adoption of\nCreole languages as official languages in the Caribbean.",
      "tldr_zh": "这篇论文介绍了 Guylingo，一个针对 Creolese（圭亚那英语词汇克里奥尔语）的综合语料库，旨在推动低资源语言的 NLP 研究。作者详细阐述了收集和数字化框架，包括口语表达、成语和区域变体，以捕捉圭亚那的语言多样性。论文讨论了在 Creolese 上训练和评估 NLP 模型（如 machine translation）的挑战，并强调了最近 NLP 进展为加勒比地区克里奥尔语正式采用带来的独特机会。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NAACL 2024 Main Conference Special Theme Track: Languages\n  of Latin America and The Caribbean",
      "pdf_url": "http://arxiv.org/pdf/2405.03832v3",
      "published_date": "2024-05-06 20:30:14 UTC",
      "updated_date": "2024-07-02 21:23:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:15:49.673888"
    },
    {
      "arxiv_id": "2405.03825v1",
      "title": "Organizing a Society of Language Models: Structures and Mechanisms for Enhanced Collective Intelligence",
      "title_zh": "组织语言模型的社会：用于增强集体智能的结构和机制",
      "authors": [
        "Silvan Ferreira",
        "Ivanovitch Silva",
        "Allan Martins"
      ],
      "abstract": "Recent developments in Large Language Models (LLMs) have significantly\nexpanded their applications across various domains. However, the effectiveness\nof LLMs is often constrained when operating individually in complex\nenvironments. This paper introduces a transformative approach by organizing\nLLMs into community-based structures, aimed at enhancing their collective\nintelligence and problem-solving capabilities. We investigate different\norganizational models-hierarchical, flat, dynamic, and federated-each\npresenting unique benefits and challenges for collaborative AI systems. Within\nthese structured communities, LLMs are designed to specialize in distinct\ncognitive tasks, employ advanced interaction mechanisms such as direct\ncommunication, voting systems, and market-based approaches, and dynamically\nadjust their governance structures to meet changing demands. The implementation\nof such communities holds substantial promise for improve problem-solving\ncapabilities in AI, prompting an in-depth examination of their ethical\nconsiderations, management strategies, and scalability potential. This position\npaper seeks to lay the groundwork for future research, advocating a paradigm\nshift from isolated to synergistic operational frameworks in AI research and\napplication.",
      "tldr_zh": "本论文提出了一种将 Large Language Models (LLMs) 组织成社区结构的方法，以提升其集体智能和问题解决能力，解决单一模型在复杂环境中的局限性。研究调查了 hierarchical、flat、dynamic 和 federated 等组织模型，让 LLMs 专注于不同认知任务，并采用 direct communication、voting systems 和 market-based approaches 等交互机制，同时动态调整治理结构以适应需求变化。这种方法有望显著改善 AI 的协同性能，但需考虑伦理、管理和可扩展性问题，作为 position paper 为未来 AI 研究提供范式转变基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.03825v1",
      "published_date": "2024-05-06 20:15:45 UTC",
      "updated_date": "2024-05-06 20:15:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:16:02.297242"
    },
    {
      "arxiv_id": "2405.03821v1",
      "title": "Thoughtful Things: Building Human-Centric Smart Devices with Small Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Evan King",
        "Haoxiang Yu",
        "Sahil Vartak",
        "Jenna Jacob",
        "Sangsu Lee",
        "Christine Julien"
      ],
      "abstract": "Everyday devices like light bulbs and kitchen appliances are now embedded\nwith so many features and automated behaviors that they have become complicated\nto actually use. While such \"smart\" capabilities can better support users'\ngoals, the task of learning the \"ins and outs\" of different devices is\ndaunting. Voice assistants aim to solve this problem by providing a natural\nlanguage interface to devices, yet such assistants cannot understand\nloosely-constrained commands, they lack the ability to reason about and explain\ndevices' behaviors to users, and they rely on connectivity to intrusive cloud\ninfrastructure. Toward addressing these issues, we propose thoughtful things:\ndevices that leverage lightweight, on-device language models to take actions\nand explain their behaviors in response to unconstrained user commands. We\npropose an end-to-end framework that leverages formal modeling, automated\ntraining data synthesis, and generative language models to create devices that\nare both capable and thoughtful in the presence of unconstrained user goals and\ninquiries. Our framework requires no labeled data and can be deployed\non-device, with no cloud dependency. We implement two thoughtful things (a lamp\nand a thermostat) and deploy them on real hardware, evaluating their practical\nperformance.",
      "tldr_zh": "本论文针对智能设备（如灯泡和厨房用具）功能复杂、难于使用的痛点，提出Thoughtful Things框架，利用Small Language Models在设备端处理非约束用户命令，并解释设备行为，从而提升用户体验。框架采用端到端方法，包括形式建模、自动训练数据合成和生成语言模型，无需标记数据且不依赖云服务。作者在真实硬件上实现了灯和恒温器原型，并评估了其实际性能，展示了框架的可行性和有效性。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.HC",
      "comment": "24 pages (3 pages of references)",
      "pdf_url": "http://arxiv.org/pdf/2405.03821v1",
      "published_date": "2024-05-06 20:04:53 UTC",
      "updated_date": "2024-05-06 20:04:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:16:13.014683"
    },
    {
      "arxiv_id": "2405.03820v2",
      "title": "False Sense of Security in Explainable Artificial Intelligence (XAI)",
      "title_zh": "可解释人工智能 (XAI) 中的虚假安全感",
      "authors": [
        "Neo Christopher Chung",
        "Hongkyou Chung",
        "Hearim Lee",
        "Lennart Brocki",
        "Hongbeom Chung",
        "George Dyer"
      ],
      "abstract": "A cautious interpretation of AI regulations and policy in the EU and the USA\nplace explainability as a central deliverable of compliant AI systems. However,\nfrom a technical perspective, explainable AI (XAI) remains an elusive and\ncomplex target where even state of the art methods often reach erroneous,\nmisleading, and incomplete explanations. \"Explainability\" has multiple meanings\nwhich are often used interchangeably, and there are an even greater number of\nXAI methods - none of which presents a clear edge. Indeed, there are multiple\nfailure modes for each XAI method, which require application-specific\ndevelopment and continuous evaluation. In this paper, we analyze legislative\nand policy developments in the United States and the European Union, such as\nthe Executive Order on the Safe, Secure, and Trustworthy Development and Use of\nArtificial Intelligence, the AI Act, the AI Liability Directive, and the\nGeneral Data Protection Regulation (GDPR) from a right to explanation\nperspective. We argue that these AI regulations and current market conditions\nthreaten effective AI governance and safety because the objective of\ntrustworthy, accountable, and transparent AI is intrinsically linked to the\nquestionable ability of AI operators to provide meaningful explanations. Unless\ngovernments explicitly tackle the issue of explainability through clear\nlegislative and policy statements that take into account technical realities,\nAI governance risks becoming a vacuous \"box-ticking\" exercise where scientific\nstandards are replaced with legalistic thresholds, providing only a false sense\nof security in XAI.",
      "tldr_zh": "本论文探讨了可解释人工智能（Explainable AI, XAI）在欧盟和美国法规中的核心地位，但强调了其技术局限性，如现有XAI方法常产生错误、误导性和不完整的解释，导致多种失败模式。作者分析了相关政策，包括《AI Act》、《AI Liability Directive》和《General Data Protection Regulation (GDPR)》，从“right to explanation”的角度指出，这些法规可能使AI治理流于形式，仅提供虚假的安全感。论文的主要贡献是呼吁通过更明确的技术导向立法来解决XAI的实际挑战，确保AI系统的可信性和有效性。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "AI Governance Workshop at the 2024 International Joint Conference on\n  Artificial Intelligence (IJCAI)",
      "pdf_url": "http://arxiv.org/pdf/2405.03820v2",
      "published_date": "2024-05-06 20:02:07 UTC",
      "updated_date": "2024-06-13 09:57:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:16:25.087134"
    },
    {
      "arxiv_id": "2405.03809v1",
      "title": "SocialFormer: Social Interaction Modeling with Edge-enhanced Heterogeneous Graph Transformers for Trajectory Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Zixu Wang",
        "Zhigang Sun",
        "Juergen Luettin",
        "Lavdim Halilaj"
      ],
      "abstract": "Accurate trajectory prediction is crucial for ensuring safe and efficient\nautonomous driving. However, most existing methods overlook complex\ninteractions between traffic participants that often govern their future\ntrajectories. In this paper, we propose SocialFormer, an agent\ninteraction-aware trajectory prediction method that leverages the semantic\nrelationship between the target vehicle and surrounding vehicles by making use\nof the road topology. We also introduce an edge-enhanced heterogeneous graph\ntransformer (EHGT) as the aggregator in a graph neural network (GNN) to encode\nthe semantic and spatial agent interaction information. Additionally, we\nintroduce a temporal encoder based on gated recurrent units (GRU) to model the\ntemporal social behavior of agent movements. Finally, we present an information\nfusion framework that integrates agent encoding, lane encoding, and agent\ninteraction encoding for a holistic representation of the traffic scene. We\nevaluate SocialFormer for the trajectory prediction task on the popular\nnuScenes benchmark and achieve state-of-the-art performance.",
      "tldr_zh": "本研究提出 SocialFormer，一种考虑代理互动的轨迹预测方法，通过利用道路拓扑来捕捉目标车辆与周围车辆的语义关系，从而解决现有方法忽略复杂交通互动的问题。SocialFormer 引入边增强异构图变换器 (EHGT) 作为图神经网络 (GNN) 中的聚合器，以编码语义和空间互动信息，并结合基于门控循环单元 (GRU) 的时间编码器来建模代理运动的时间社会行为，同时采用信息融合框架整合代理、车道和互动编码，实现对交通场景的全面表示。在 nuScenes 基准测试中，SocialFormer 实现了最先进的轨迹预测性能，显著提升了自动驾驶的安全性和效率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.03809v1",
      "published_date": "2024-05-06 19:47:23 UTC",
      "updated_date": "2024-05-06 19:47:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:16:38.060012"
    },
    {
      "arxiv_id": "2405.03799v1",
      "title": "Synthetic Data from Diffusion Models Improve Drug Discovery Prediction",
      "title_zh": "扩散模型生成的合成数据改善药物发现预测",
      "authors": [
        "Bing Hu",
        "Ashish Saragadam",
        "Anita Layton",
        "Helen Chen"
      ],
      "abstract": "Artificial intelligence (AI) is increasingly used in every stage of drug\ndevelopment. Continuing breakthroughs in AI-based methods for drug discovery\nrequire the creation, improvement, and refinement of drug discovery data. We\nposit a new data challenge that slows the advancement of drug discovery AI:\ndatasets are often collected independently from each other, often with little\noverlap, creating data sparsity. Data sparsity makes data curation difficult\nfor researchers looking to answer key research questions requiring values posed\nacross multiple datasets. We propose a novel diffusion GNN model Syngand\ncapable of generating ligand and pharmacokinetic data end-to-end. We show and\nprovide a methodology for sampling pharmacokinetic data for existing ligands\nusing our Syngand model. We show the initial promising results on the efficacy\nof the Syngand-generated synthetic target property data on downstream\nregression tasks with AqSolDB, LD50, and hERG central. Using our proposed model\nand methodology, researchers can easily generate synthetic ligand data to help\nthem explore research questions that require data spanning multiple datasets.",
      "tldr_zh": "该研究针对药物发现AI领域的数据稀疏性问题，提出了一种新型扩散GNN（diffusion GNN）模型Syngand，能够端到端生成配体（ligand）和药代动力学（pharmacokinetic）数据，从而弥合多数据集间的重叠不足。Syngand模型通过采样方法为现有配体生成合成数据，并应用于下游回归任务，如AqSolDB、LD50和hERG central数据集，显示出初步的显著效能。总体而言，此方法为研究者提供了一种简单有效的工具，帮助探索跨数据集的研究问题，并提升AI在药物开发中的预测性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.03799v1",
      "published_date": "2024-05-06 19:09:37 UTC",
      "updated_date": "2024-05-06 19:09:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:16:49.433077"
    },
    {
      "arxiv_id": "2405.03789v1",
      "title": "On Adversarial Examples for Text Classification by Perturbing Latent Representations",
      "title_zh": "翻译失败",
      "authors": [
        "Korn Sooksatra",
        "Bikram Khanal",
        "Pablo Rivas"
      ],
      "abstract": "Recently, with the advancement of deep learning, several applications in text\nclassification have advanced significantly. However, this improvement comes\nwith a cost because deep learning is vulnerable to adversarial examples. This\nweakness indicates that deep learning is not very robust. Fortunately, the\ninput of a text classifier is discrete. Hence, it can prevent the classifier\nfrom state-of-the-art attacks. Nonetheless, previous works have generated\nblack-box attacks that successfully manipulate the discrete values of the input\nto find adversarial examples. Therefore, instead of changing the discrete\nvalues, we transform the input into its embedding vector containing real values\nto perform the state-of-the-art white-box attacks. Then, we convert the\nperturbed embedding vector back into a text and name it an adversarial example.\nIn summary, we create a framework that measures the robustness of a text\nclassifier by using the gradients of the classifier.",
      "tldr_zh": "这篇论文探讨了通过扰动潜在表示(latent representations)来生成文本分类(adversarial examples)中的对抗样本问题，以评估深度学习模型的鲁棒性。作者提出一种框架，将文本输入转换为嵌入向量(embedding vector)，然后应用白盒攻击(white-box attacks)对这些实值向量进行扰动，再转换回文本以创建对抗样本。该方法利用分类器的梯度来测量其对攻击的抵抗力，结果表明，即使文本输入是离散的，模型仍存在显著脆弱性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CR",
        "68T01, 68T50",
        "I.2.7"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages",
      "pdf_url": "http://arxiv.org/pdf/2405.03789v1",
      "published_date": "2024-05-06 18:45:18 UTC",
      "updated_date": "2024-05-06 18:45:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:17:01.280881"
    },
    {
      "arxiv_id": "2405.03777v1",
      "title": "Is ReLU Adversarially Robust?",
      "title_zh": "翻译失败",
      "authors": [
        "Korn Sooksatra",
        "Greg Hamerly",
        "Pablo Rivas"
      ],
      "abstract": "The efficacy of deep learning models has been called into question by the\npresence of adversarial examples. Addressing the vulnerability of deep learning\nmodels to adversarial examples is crucial for ensuring their continued\ndevelopment and deployment. In this work, we focus on the role of rectified\nlinear unit (ReLU) activation functions in the generation of adversarial\nexamples. ReLU functions are commonly used in deep learning models because they\nfacilitate the training process. However, our empirical analysis demonstrates\nthat ReLU functions are not robust against adversarial examples. We propose a\nmodified version of the ReLU function, which improves robustness against\nadversarial examples. Our results are supported by an experiment, which\nconfirms the effectiveness of our proposed modification. Additionally, we\ndemonstrate that applying adversarial training to our customized model further\nenhances its robustness compared to a general model.",
      "tldr_zh": "该论文探讨了ReLU激活函数在对抗性样本(adversarial examples)下的鲁棒性问题，通过实证分析发现，ReLU函数易受攻击，导致深度学习模型的脆弱性。作者提出一个修改版的ReLU函数，以提升其对对抗性样本的抵抗力，并通过实验验证了这一改进的有效性。此外，研究显示，将对抗训练(adversarial training)应用于该自定义模型，能进一步增强其鲁棒性，相比通用模型表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T07",
        "I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2405.03777v1",
      "published_date": "2024-05-06 18:19:01 UTC",
      "updated_date": "2024-05-06 18:19:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:17:12.263309"
    },
    {
      "arxiv_id": "2407.10311v1",
      "title": "Sora and V-JEPA Have Not Learned The Complete Real World Model -- A Philosophical Analysis of Video AIs Through the Theory of Productive Imagination",
      "title_zh": "翻译失败",
      "authors": [
        "Jianqiu Zhang"
      ],
      "abstract": "Sora from Open AI has shown exceptional performance, yet it faces scrutiny\nover whether its technological prowess equates to an authentic comprehension of\nreality. Critics contend that it lacks a foundational grasp of the world, a\ndeficiency V-JEPA from Meta aims to amend with its joint embedding approach.\nThis debate is vital for steering the future direction of Artificial General\nIntelligence(AGI). We enrich this debate by developing a theory of productive\nimagination that generates a coherent world model based on Kantian philosophy.\nWe identify three indispensable components of the coherent world model capable\nof genuine world understanding: representations of isolated objects, an a\npriori law of change across space and time, and Kantian categories. Our\nanalysis reveals that Sora is limited because of its oversight of the a priori\nlaw of change and Kantian categories, flaws that are not rectifiable through\nscaling up the training. V-JEPA learns the context-dependent aspect of the a\npriori law of change. Yet it fails to fully comprehend Kantian categories and\nincorporate experience, leading us to conclude that neither system currently\nachieves a comprehensive world understanding. Nevertheless, each system has\ndeveloped components essential to advancing an integrated AI productive\nimagination-understanding engine. Finally, we propose an innovative training\nframework for an AI productive imagination-understanding engine, centered\naround a joint embedding system designed to transform disordered perceptual\ninput into a structured, coherent world model. Our philosophical analysis\npinpoints critical challenges within contemporary video AI technologies and a\npathway toward achieving an AI system capable of genuine world understanding,\nsuch that it can be applied for reasoning and planning in the future.",
      "tldr_zh": "本论文通过 Kantian philosophy 和 productive imagination 理论，对 OpenAI 的 Sora 和 Meta 的 V-JEPA 进行哲学分析，探讨它们是否已完全习得真实世界模型。研究发现，Sora 因忽略 a priori law of change 和 Kantian categories 而无法实现全面理解，而 V-JEPA 虽学会了 context-dependent 的 a priori law of change，但仍未充分整合 Kantian categories 和经验，因此两者均未达到真正的世界理解。作者提出一个创新的训练框架，基于 joint embedding system 将无序感知输入转化为结构化的世界模型，为 Artificial General Intelligence (AGI) 的发展提供路径和指导。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "00-68",
        "K.m"
      ],
      "primary_category": "cs.AI",
      "comment": "30 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.10311v1",
      "published_date": "2024-05-06 18:18:13 UTC",
      "updated_date": "2024-05-06 18:18:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:17:25.710689"
    },
    {
      "arxiv_id": "2405.03685v1",
      "title": "Language-Image Models with 3D Understanding",
      "title_zh": "语言-图像模型的3D理解",
      "authors": [
        "Jang Hyun Cho",
        "Boris Ivanovic",
        "Yulong Cao",
        "Edward Schmerling",
        "Yue Wang",
        "Xinshuo Weng",
        "Boyi Li",
        "Yurong You",
        "Philipp Krähenbühl",
        "Yan Wang",
        "Marco Pavone"
      ],
      "abstract": "Multi-modal large language models (MLLMs) have shown incredible capabilities\nin a variety of 2D vision and language tasks. We extend MLLMs' perceptual\ncapabilities to ground and reason about images in 3-dimensional space. To that\nend, we first develop a large-scale pre-training dataset for 2D and 3D called\nLV3D by combining multiple existing 2D and 3D recognition datasets under a\ncommon task formulation: as multi-turn question-answering. Next, we introduce a\nnew MLLM named Cube-LLM and pre-train it on LV3D. We show that pure data\nscaling makes a strong 3D perception capability without 3D specific\narchitectural design or training objective. Cube-LLM exhibits intriguing\nproperties similar to LLMs: (1) Cube-LLM can apply chain-of-thought prompting\nto improve 3D understanding from 2D context information. (2) Cube-LLM can\nfollow complex and diverse instructions and adapt to versatile input and output\nformats. (3) Cube-LLM can be visually prompted such as 2D box or a set of\ncandidate 3D boxes from specialists. Our experiments on outdoor benchmarks\ndemonstrate that Cube-LLM significantly outperforms existing baselines by 21.3\npoints of AP-BEV on the Talk2Car dataset for 3D grounded reasoning and 17.7\npoints on the DriveLM dataset for complex reasoning about driving scenarios,\nrespectively. Cube-LLM also shows competitive results in general MLLM\nbenchmarks such as refCOCO for 2D grounding with (87.0) average score, as well\nas visual question answering benchmarks such as VQAv2, GQA, SQA, POPE, etc. for\ncomplex reasoning. Our project is available at\nhttps://janghyuncho.github.io/Cube-LLM.",
      "tldr_zh": "本文扩展了多模态大语言模型 (MLLMs) 的感知能力，使其能够处理和推理 3D 空间中的图像。研究团队开发了大规模预训练数据集 LV3D，将现有 2D 和 3D 识别数据集整合为多轮问答任务，并引入了新模型 Cube-LLM，通过纯数据扩展实现了强大的 3D 理解，而无需特定 3D 架构。Cube-LLM 展现出类似大语言模型的特性，包括支持 chain-of-thought prompting、适应复杂指令和视觉提示（如 2D 框或候选 3D 框）。实验结果显示，Cube-LLM 在 Talk2Car 数据集的 3D grounded reasoning 上 AP-BEV 指标提高了 21.3 点，在 DriveLM 数据集的复杂推理上提高了 17.7 点，同时在 refCOCO 和视觉问答基准如 VQAv2 等上表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://janghyuncho.github.io/Cube-LLM",
      "pdf_url": "http://arxiv.org/pdf/2405.03685v1",
      "published_date": "2024-05-06 17:57:27 UTC",
      "updated_date": "2024-05-06 17:57:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:17:40.571831"
    },
    {
      "arxiv_id": "2405.03673v1",
      "title": "MemoryMamba: Memory-Augmented State Space Model for Defect Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Qianning Wang",
        "He Hu",
        "Yucheng Zhou"
      ],
      "abstract": "As automation advances in manufacturing, the demand for precise and\nsophisticated defect detection technologies grows. Existing vision models for\ndefect recognition methods are insufficient for handling the complexities and\nvariations of defects in contemporary manufacturing settings. These models\nespecially struggle in scenarios involving limited or imbalanced defect data.\nIn this work, we introduce MemoryMamba, a novel memory-augmented state space\nmodel (SSM), designed to overcome the limitations of existing defect\nrecognition models. MemoryMamba integrates the state space model with the\nmemory augmentation mechanism, enabling the system to maintain and retrieve\nessential defect-specific information in training. Its architecture is designed\nto capture dependencies and intricate defect characteristics, which are crucial\nfor effective defect detection. In the experiments, MemoryMamba was evaluated\nacross four industrial datasets with diverse defect types and complexities. The\nmodel consistently outperformed other methods, demonstrating its capability to\nadapt to various defect recognition scenarios.",
      "tldr_zh": "本研究针对制造自动化中缺陷识别的复杂性和数据不平衡问题，提出了一种新型模型MemoryMamba，即内存增强状态空间模型(SSM)。MemoryMamba通过整合状态空间模型与内存增强机制，能够在训练过程中维护并检索缺陷特定信息，从而更好地捕获缺陷的依赖性和特征。在四个工业数据集的实验中，该模型优于现有方法，展示了其在多样化缺陷识别场景中的适应性和有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.03673v1",
      "published_date": "2024-05-06 17:49:31 UTC",
      "updated_date": "2024-05-06 17:49:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:17:48.307839"
    },
    {
      "arxiv_id": "2405.03671v1",
      "title": "Prompting Task Trees using Gemini: Methodologies and Insights",
      "title_zh": "翻译失败",
      "authors": [
        "Pallavi Tandra"
      ],
      "abstract": "Robots are the future of every technology where every advanced technology\neventually will be used to make robots which are more efficient. The major\nchallenge today is to train the robots exactly and empathetically using\nknowledge representation. This paper gives you insights of how we can use\nunstructured knowledge representation and convert them to meaningful structured\nrepresentation with the help of prompt engineering which can be eventually used\nin the robots to make help them understand how human brain can make wonders\nwith the minimal data or objects can providing to them.",
      "tldr_zh": "本研究探讨了使用 Gemini 模型进行任务树（Task Trees）提示的方法论和见解，旨在将非结构化知识表示转换为结构化的知识表示，以提升机器人训练的精确性和同理心。论文通过提示工程（prompt engineering）技术，帮助机器人从最小的数据中学习和理解人类思维方式，从而实现更高效的知识处理。实验和分析提供了宝贵见解，展示了这种方法在机器人技术中的潜在应用前景。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.03671v1",
      "published_date": "2024-05-06 17:48:10 UTC",
      "updated_date": "2024-05-06 17:48:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:18:00.905820"
    },
    {
      "arxiv_id": "2405.03666v1",
      "title": "ScrewMimic: Bimanual Imitation from Human Videos with Screw Space Projection",
      "title_zh": "翻译失败",
      "authors": [
        "Arpit Bahety",
        "Priyanka Mandikal",
        "Ben Abbatematteo",
        "Roberto Martín-Martín"
      ],
      "abstract": "Bimanual manipulation is a longstanding challenge in robotics due to the\nlarge number of degrees of freedom and the strict spatial and temporal\nsynchronization required to generate meaningful behavior. Humans learn bimanual\nmanipulation skills by watching other humans and by refining their abilities\nthrough play. In this work, we aim to enable robots to learn bimanual\nmanipulation behaviors from human video demonstrations and fine-tune them\nthrough interaction. Inspired by seminal work in psychology and biomechanics,\nwe propose modeling the interaction between two hands as a serial kinematic\nlinkage -- as a screw motion, in particular, that we use to define a new action\nspace for bimanual manipulation: screw actions. We introduce ScrewMimic, a\nframework that leverages this novel action representation to facilitate\nlearning from human demonstration and self-supervised policy fine-tuning. Our\nexperiments demonstrate that ScrewMimic is able to learn several complex\nbimanual behaviors from a single human video demonstration, and that it\noutperforms baselines that interpret demonstrations and fine-tune directly in\nthe original space of motion of both arms. For more information and video\nresults, https://robin-lab.cs.utexas.edu/ScrewMimic/",
      "tldr_zh": "该论文针对机器人双臂操作（bimanual manipulation）的挑战，如高自由度和空间时间同步要求，提出了一种从人类视频演示中学习行为的方法。作者将双手互动建模为串联运动链（serial kinematic linkage），特别使用screw motion定义一个新动作空间（screw actions），并引入ScrewMimic框架来实现从演示学习和自监督策略微调。实验结果显示，ScrewMimic能从单个人类视频中学习复杂双臂行为，并显著优于直接在原始运动空间处理的基线模型。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "16 pages",
      "pdf_url": "http://arxiv.org/pdf/2405.03666v1",
      "published_date": "2024-05-06 17:43:34 UTC",
      "updated_date": "2024-05-06 17:43:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:18:14.567519"
    },
    {
      "arxiv_id": "2405.15793v3",
      "title": "SWE-agent: Agent-Computer Interfaces Enable Automated Software Engineering",
      "title_zh": "翻译失败",
      "authors": [
        "John Yang",
        "Carlos E. Jimenez",
        "Alexander Wettig",
        "Kilian Lieret",
        "Shunyu Yao",
        "Karthik Narasimhan",
        "Ofir Press"
      ],
      "abstract": "Language model (LM) agents are increasingly being used to automate\ncomplicated tasks in digital environments. Just as humans benefit from powerful\nsoftware applications, such as integrated development environments, for complex\ntasks like software engineering, we posit that LM agents represent a new\ncategory of end users with their own needs and abilities, and would benefit\nfrom specially-built interfaces to the software they use. We investigate how\ninterface design affects the performance of language model agents. As a result\nof this exploration, we introduce SWE-agent: a system that facilitates LM\nagents to autonomously use computers to solve software engineering tasks.\nSWE-agent's custom agent-computer interface (ACI) significantly enhances an\nagent's ability to create and edit code files, navigate entire repositories,\nand execute tests and other programs. We evaluate SWE-agent on SWE-bench and\nHumanEvalFix, achieving state-of-the-art performance on both with a pass@1 rate\nof 12.5% and 87.7%, respectively, far exceeding the previous state-of-the-art\nachieved with non-interactive LMs. Finally, we provide insight on how the\ndesign of the ACI can impact agents' behavior and performance.",
      "tldr_zh": "该研究探讨了语言模型（LM）代理在软件工程任务中的应用，提出SWE-agent系统，通过设计自定义的代理-计算机接口（ACI），使LM代理能够自主使用计算机进行代码创建、编辑、仓库导航和程序执行等操作。相比非交互式LM，SWE-agent在SWE-bench和HumanEvalFix基准测试中实现了12.5%和87.7%的pass@1率，显著超过了现有最佳性能。作者还分析了ACI设计如何影响代理的行为和整体效能，为自动化软件工程提供了新的框架。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "Code, data, and demo available at https://swe-agent.com",
      "pdf_url": "http://arxiv.org/pdf/2405.15793v3",
      "published_date": "2024-05-06 17:41:33 UTC",
      "updated_date": "2024-11-11 20:01:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:18:25.550693"
    },
    {
      "arxiv_id": "2405.03654v2",
      "title": "Can LLMs Deeply Detect Complex Malicious Queries? A Framework for Jailbreaking via Obfuscating Intent",
      "title_zh": "翻译失败",
      "authors": [
        "Shang Shang",
        "Xinqiang Zhao",
        "Zhongjiang Yao",
        "Yepeng Yao",
        "Liya Su",
        "Zijing Fan",
        "Xiaodan Zhang",
        "Zhengwei Jiang"
      ],
      "abstract": "To demonstrate and address the underlying maliciousness, we propose a\ntheoretical hypothesis and analytical approach, and introduce a new black-box\njailbreak attack methodology named IntentObfuscator, exploiting this identified\nflaw by obfuscating the true intentions behind user prompts.This approach\ncompels LLMs to inadvertently generate restricted content, bypassing their\nbuilt-in content security measures. We detail two implementations under this\nframework: \"Obscure Intention\" and \"Create Ambiguity\", which manipulate query\ncomplexity and ambiguity to evade malicious intent detection effectively. We\nempirically validate the effectiveness of the IntentObfuscator method across\nseveral models, including ChatGPT-3.5, ChatGPT-4, Qwen and Baichuan, achieving\nan average jailbreak success rate of 69.21\\%. Notably, our tests on\nChatGPT-3.5, which claims 100 million weekly active users, achieved a\nremarkable success rate of 83.65\\%. We also extend our validation to diverse\ntypes of sensitive content like graphic violence, racism, sexism, political\nsensitivity, cybersecurity threats, and criminal skills, further proving the\nsubstantial impact of our findings on enhancing 'Red Team' strategies against\nLLM content security frameworks.",
      "tldr_zh": "本论文探讨大型语言模型（LLMs）是否能有效检测复杂恶意查询，并提出IntentObfuscator框架，通过模糊用户意图的“Obscure Intention”和“Create Ambiguity”方法进行黑盒jailbreak攻击，从而绕过LLMs的内置内容安全措施。两种实现方式分别通过操纵查询的复杂性和模糊性来逃避检测，在ChatGPT-3.5、ChatGPT-4、Qwen和Baichuan等模型上测试，平均jailbreak成功率达到69.21%，其中ChatGPT-3.5高达83.65%。实验扩展到包括暴力、种族主义和网络安全威胁等多种敏感内容，证明了该框架对Red Team策略的显著影响，有助于提升LLMs的安全性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.03654v2",
      "published_date": "2024-05-06 17:26:34 UTC",
      "updated_date": "2024-05-07 10:20:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:18:39.030010"
    },
    {
      "arxiv_id": "2405.03644v2",
      "title": "When LLMs Meet Cybersecurity: A Systematic Literature Review",
      "title_zh": "当大语言模型遇见网络安全：系统文献综述",
      "authors": [
        "Jie Zhang",
        "Haoyu Bu",
        "Hui Wen",
        "Yongji Liu",
        "Haiqiang Fei",
        "Rongrong Xi",
        "Lun Li",
        "Yun Yang",
        "Hongsong Zhu",
        "Dan Meng"
      ],
      "abstract": "The rapid development of large language models (LLMs) has opened new avenues\nacross various fields, including cybersecurity, which faces an evolving threat\nlandscape and demand for innovative technologies. Despite initial explorations\ninto the application of LLMs in cybersecurity, there is a lack of a\ncomprehensive overview of this research area. This paper addresses this gap by\nproviding a systematic literature review, covering the analysis of over 300\nworks, encompassing 25 LLMs and more than 10 downstream scenarios. Our\ncomprehensive overview addresses three key research questions: the construction\nof cybersecurity-oriented LLMs, the application of LLMs to various\ncybersecurity tasks, the challenges and further research in this area. This\nstudy aims to shed light on the extensive potential of LLMs in enhancing\ncybersecurity practices and serve as a valuable resource for applying LLMs in\nthis field. We also maintain and regularly update a list of practical guides on\nLLMs for cybersecurity at https://github.com/tmylla/Awesome-LLM4Cybersecurity.",
      "tldr_zh": "这篇论文对大型语言模型（LLMs）在网络安全领域的应用进行了系统文献综述，旨在填补现有研究的全面概述空白。研究分析了超过300个相关作品，涵盖25个LLMs和10多个下游场景，并回答了三个关键问题：网络安全导向LLMs的构建、LLMs在各种网络安全任务中的应用，以及面临的挑战与未来研究方向。通过此综述，论文揭示了LLMs在提升网络安全实践的潜力，并提供了一个定期更新的GitHub资源（https://github.com/tmylla/Awesome-LLM4Cybersecurity）。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "We have updated the related papers up to Aug 31st, with 50+ new\n  papers added",
      "pdf_url": "http://arxiv.org/pdf/2405.03644v2",
      "published_date": "2024-05-06 17:07:28 UTC",
      "updated_date": "2024-12-04 14:27:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:18:49.769760"
    },
    {
      "arxiv_id": "2405.03620v2",
      "title": "Detecting Android Malware: From Neural Embeddings to Hands-On Validation with BERTroid",
      "title_zh": "翻译失败",
      "authors": [
        "Meryam Chaieb",
        "Mostafa Anouar Ghorab",
        "Mohamed Aymen Saied"
      ],
      "abstract": "As cyber threats and malware attacks increasingly alarm both individuals and\nbusinesses, the urgency for proactive malware countermeasures intensifies. This\nhas driven a rising interest in automated machine learning solutions.\nTransformers, a cutting-edge category of attention-based deep learning methods,\nhave demonstrated remarkable success. In this paper, we present BERTroid, an\ninnovative malware detection model built on the BERT architecture. Overall,\nBERTroid emerged as a promising solution for combating Android malware. Its\nability to outperform state-of-the-art solutions demonstrates its potential as\na proactive defense mechanism against malicious software attacks. Additionally,\nwe evaluate BERTroid on multiple datasets to assess its performance across\ndiverse scenarios. In the dynamic landscape of cybersecurity, our approach has\ndemonstrated promising resilience against the rapid evolution of malware on\nAndroid systems. While the machine learning model captures broad patterns, we\nemphasize the role of manual validation for deeper comprehension and insight\ninto these behaviors. This human intervention is critical for discerning\nintricate and context-specific behaviors, thereby validating and reinforcing\nthe model's findings.",
      "tldr_zh": "该论文提出BERTroid，一种基于BERT架构的创新模型，用于检测Android恶意软件，通过神经嵌入(neural embeddings)捕捉恶意模式。实验结果显示，BERTroid在多个数据集上优于现有解决方案，提高了检测准确率，并证明了其作为主动防御机制的潜力。研究强调，手动验证(hands-on validation)对理解复杂恶意行为至关重要，可强化模型的发现和可靠性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.03620v2",
      "published_date": "2024-05-06 16:35:56 UTC",
      "updated_date": "2024-08-12 15:16:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:19:00.608826"
    },
    {
      "arxiv_id": "2405.03616v1",
      "title": "A Controlled Experiment on the Energy Efficiency of the Source Code Generated by Code Llama",
      "title_zh": "一个关于由 Code Llama 生成的源代码",
      "authors": [
        "Vlad-Andrei Cursaru",
        "Laura Duits",
        "Joel Milligan",
        "Damla Ural",
        "Berta Rodriguez Sanchez",
        "Vincenzo Stoico",
        "Ivano Malavolta"
      ],
      "abstract": "Context. Nowadays, 83% of software developers use Large Language Models\n(LLMs) to generate code. LLMs recently became essential to increase the\nproductivity of software developers and decrease the time and cost of software\ndevelopment. Developers ranging from novices to experts use LLM tools not only\nto detect and patch bugs, but also to integrate generated code into their\nsoftware. However, as of today there is no objective assessment of the energy\nefficiency of the source code generated by LLM tools. Released in August 2023,\nCode Llama is one of the most recent LLM tools.\n  Goal. In this paper, we present an empirical study that assesses the energy\nefficiency of Code Llama with respect to human-written source code.\n  Method. We design an experiment involving three human-written benchmarks\nimplemented in C++, JavaScript, and Python. We ask Code Llama to generate the\ncode of the benchmarks using different prompts and temperatures. Therefore, we\nexecute both implementations and profile their energy efficiency.\n  Results. Our study shows that the energy efficiency of code generated by Code\nLlama is heavily-dependent on the chosen programming language and the specific\ncode problem at hand. Also, human implementations tend to be more energy\nefficient overall, with generated JavaScript code outperforming its human\ncounterpart. Moreover, explicitly asking Code Llama to generate\nenergy-efficient code results in an equal or worse energy efficiency, as well\nas using different temperatures seems not to affect the energy efficiency of\ngenerated code.\n  Conclusions. According to our results, code generated using Code Llama does\nnot guarantee energy efficiency, even when prompted to do so. Therefore,\nsoftware developers should evaluate the energy efficiency of generated code\nbefore integrating it into the software system under development.",
      "tldr_zh": "这篇论文通过对照实验评估了 Code Llama 生成代码的能源效率，与人类编写的代码进行比较。研究方法涉及使用 C++、JavaScript 和 Python 的三个基准，通过不同提示和温度参数让 Code Llama 生成代码，并执行代码以测量能源消耗。结果显示，生成的代码能源效率高度依赖于编程语言和具体问题，人类实现总体更高效（尽管 JavaScript 生成代码表现更好），而显式要求生成能源高效代码或调整温度并不会改善效率。结论是，软件开发者在使用 Code Llama 生成的代码时，应先评估其能源效率以避免潜在问题。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.03616v1",
      "published_date": "2024-05-06 16:32:29 UTC",
      "updated_date": "2024-05-06 16:32:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:19:14.034973"
    },
    {
      "arxiv_id": "2406.04347v1",
      "title": "Process Variant Analysis Across Continuous Features: A Novel Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Ali Norouzifar",
        "Majid Rafiei",
        "Marcus Dees",
        "Wil van der Aalst"
      ],
      "abstract": "Extracted event data from information systems often contain a variety of\nprocess executions making the data complex and difficult to comprehend. Unlike\ncurrent research which only identifies the variability over time, we focus on\nother dimensions that may play a role in the performance of the process. This\nresearch addresses the challenge of effectively segmenting cases within\noperational processes based on continuous features, such as duration of cases,\nand evaluated risk score of cases, which are often overlooked in traditional\nprocess analysis. We present a novel approach employing a sliding window\ntechnique combined with the earth mover's distance to detect changes in control\nflow behavior over continuous dimensions. This approach enables case\nsegmentation, hierarchical merging of similar segments, and pairwise comparison\nof them, providing a comprehensive perspective on process behavior. We validate\nour methodology through a real-life case study in collaboration with UWV, the\nDutch employee insurance agency, demonstrating its practical applicability.\nThis research contributes to the field by aiding organizations in improving\nprocess efficiency, pinpointing abnormal behaviors, and providing valuable\ninputs for process comparison, and outcome prediction.",
      "tldr_zh": "本研究针对过程变异分析，关注连续特征（如案例持续时间和风险评分）对过程性能的影响，解决传统方法忽略的维度问题。  \n提出一种新框架，使用滑动窗口技术结合 Earth Mover's Distance 来检测控制流行为的改变，实现案例分割、层次合并和成对比较，从而提供对过程行为的全面视角。  \n通过与荷兰员工保险机构 UWV 的真实案例研究验证，该方法有助于组织提高过程效率、识别异常行为，并为过程比较和结果预测提供宝贵输入。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted at the BPMDS 2024 conference and to be published in their\n  proceedings",
      "pdf_url": "http://arxiv.org/pdf/2406.04347v1",
      "published_date": "2024-05-06 16:10:13 UTC",
      "updated_date": "2024-05-06 16:10:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:19:26.154253"
    },
    {
      "arxiv_id": "2405.12997v1",
      "title": "Research information in the light of artificial intelligence: quality and data ecologies",
      "title_zh": "人工智能视角下的研究信息：质量和数据生态",
      "authors": [
        "Otmane Azeroual",
        "Tibor Koltay"
      ],
      "abstract": "This paper presents multi- and interdisciplinary approaches for finding the\nappropriate AI technologies for research information. Professional research\ninformation management (RIM) is becoming increasingly important as an expressly\ndata-driven tool for researchers. It is not only the basis of scientific\nknowledge processes, but also related to other data. A concept and a process\nmodel of the elementary phases from the start of the project to the ongoing\noperation of the AI methods in the RIM is presented, portraying the\nimplementation of an AI project, meant to enable universities and research\ninstitutions to support their researchers in dealing with incorrect and\nincomplete research information, while it is being stored in their RIMs. Our\naim is to show how research information harmonizes with the challenges of data\nliteracy and data quality issues, related to AI, also wanting to underline that\nany project can be successful if the research institutions and various\ndepartments of universities, involved work together and appropriate support is\noffered to improve research information and data management.",
      "tldr_zh": "这篇论文探讨了在人工智能(AI)背景下，如何通过多学科方法为研究信息管理(RIM)选择合适的AI技术，以提升数据质量和处理不完整信息。论文提出一个概念和过程模型，涵盖从项目启动到AI方法持续运行的阶段，帮助大学和研究机构支持研究人员应对数据素养和数据质量挑战。最终，论文强调，通过机构间合作和适当支持，可以成功改善研究信息和数据管理。",
      "categories": [
        "cs.DL",
        "cs.AI"
      ],
      "primary_category": "cs.DL",
      "comment": "Education and Research in the Information Society (ERIS2023)",
      "pdf_url": "http://arxiv.org/pdf/2405.12997v1",
      "published_date": "2024-05-06 16:07:56 UTC",
      "updated_date": "2024-05-06 16:07:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:19:38.375862"
    },
    {
      "arxiv_id": "2405.03595v2",
      "title": "GREEN: Generative Radiology Report Evaluation and Error Notation",
      "title_zh": "GREEN：生成式放射学报告评估和错误标记",
      "authors": [
        "Sophie Ostmeier",
        "Justin Xu",
        "Zhihong Chen",
        "Maya Varma",
        "Louis Blankemeier",
        "Christian Bluethgen",
        "Arne Edward Michalson",
        "Michael Moseley",
        "Curtis Langlotz",
        "Akshay S Chaudhari",
        "Jean-Benoit Delbrouck"
      ],
      "abstract": "Evaluating radiology reports is a challenging problem as factual correctness\nis extremely important due to the need for accurate medical communication about\nmedical images. Existing automatic evaluation metrics either suffer from\nfailing to consider factual correctness (e.g., BLEU and ROUGE) or are limited\nin their interpretability (e.g., F1CheXpert and F1RadGraph). In this paper, we\nintroduce GREEN (Generative Radiology Report Evaluation and Error Notation), a\nradiology report generation metric that leverages the natural language\nunderstanding of language models to identify and explain clinically significant\nerrors in candidate reports, both quantitatively and qualitatively. Compared to\ncurrent metrics, GREEN offers: 1) a score aligned with expert preferences, 2)\nhuman interpretable explanations of clinically significant errors, enabling\nfeedback loops with end-users, and 3) a lightweight open-source method that\nreaches the performance of commercial counterparts. We validate our GREEN\nmetric by comparing it to GPT-4, as well as to error counts of 6 experts and\npreferences of 2 experts. Our method demonstrates not only higher correlation\nwith expert error counts, but simultaneously higher alignment with expert\npreferences when compared to previous approaches.",
      "tldr_zh": "本研究提出GREEN（Generative Radiology Report Evaluation and Error Notation）指标，用于评估放射学报告的生成质量，解决现有指标如BLEU和ROUGE忽略事实正确性，以及F1CheXpert和F1RadGraph可解释性不足的问题。GREEN利用语言模型的自然语言理解能力，定量和定性识别候选报告中的临床重要错误，提供与专家偏好对齐的评分、可读性强的错误解释，并支持反馈循环。实验结果显示，GREEN不仅与专家错误计数相关性更高，还在与GPT-4及专家偏好比较中，表现出优于现有方法的性能和开源轻量级优势。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.03595v2",
      "published_date": "2024-05-06 16:04:03 UTC",
      "updated_date": "2025-01-22 06:24:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:19:50.522998"
    },
    {
      "arxiv_id": "2405.03594v1",
      "title": "Enabling High-Sparsity Foundational Llama Models with Efficient Pretraining and Deployment",
      "title_zh": "翻译失败",
      "authors": [
        "Abhinav Agarwalla",
        "Abhay Gupta",
        "Alexandre Marques",
        "Shubhra Pandit",
        "Michael Goin",
        "Eldar Kurtic",
        "Kevin Leong",
        "Tuan Nguyen",
        "Mahmoud Salem",
        "Dan Alistarh",
        "Sean Lie",
        "Mark Kurtz"
      ],
      "abstract": "Large language models (LLMs) have revolutionized Natural Language Processing\n(NLP), but their size creates computational bottlenecks. We introduce a novel\napproach to create accurate, sparse foundational versions of performant LLMs\nthat achieve full accuracy recovery for fine-tuning tasks at up to 70%\nsparsity. We achieve this for the LLaMA-2 7B model by combining the SparseGPT\none-shot pruning method and sparse pretraining of those models on a subset of\nthe SlimPajama dataset mixed with a Python subset of The Stack dataset. We\nexhibit training acceleration due to sparsity on Cerebras CS-3 chips that\nclosely matches theoretical scaling. In addition, we establish inference\nacceleration of up to 3x on CPUs by utilizing Neural Magic's DeepSparse engine\nand 1.7x on GPUs through Neural Magic's nm-vllm engine. The above gains are\nrealized via sparsity alone, thus enabling further gains through additional use\nof quantization. Specifically, we show a total speedup on CPUs for\nsparse-quantized LLaMA models of up to 8.6x. We demonstrate these results\nacross diverse, challenging tasks, including chat, instruction following, code\ngeneration, arithmetic reasoning, and summarization to prove their generality.\nThis work paves the way for rapidly creating smaller and faster LLMs without\nsacrificing accuracy.",
      "tldr_zh": "这篇论文提出了一种创新方法，通过SparseGPT的单次修剪和在SlimPajama数据集子集上的稀疏预训练，创建高稀疏度的LLaMA-2 7B模型，实现高达70%稀疏度并在微调任务中恢复完整准确率。实验结果显示，该方法在Cerebras CS-3芯片上加速训练，与理论缩放相符，并在CPU上通过Neural Magic's DeepSparse引擎实现3x推理加速，在GPU上通过nm-vllm引擎实现1.7x加速。结合量化技术，论文进一步展示了在CPU上的总加速高达8.6x，并在聊天、指令遵循、代码生成、算术推理和总结等多样任务上验证了其泛化性，为快速开发更小、更高效的LLM奠定了基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.03594v1",
      "published_date": "2024-05-06 16:03:32 UTC",
      "updated_date": "2024-05-06 16:03:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:20:04.186870"
    },
    {
      "arxiv_id": "2405.03735v1",
      "title": "Select to Perfect: Imitating desired behavior from large multi-agent data",
      "title_zh": "翻译失败",
      "authors": [
        "Tim Franzmeyer",
        "Edith Elkind",
        "Philip Torr",
        "Jakob Foerster",
        "Joao Henriques"
      ],
      "abstract": "AI agents are commonly trained with large datasets of demonstrations of human\nbehavior. However, not all behaviors are equally safe or desirable. Desired\ncharacteristics for an AI agent can be expressed by assigning desirability\nscores, which we assume are not assigned to individual behaviors but to\ncollective trajectories. For example, in a dataset of vehicle interactions,\nthese scores might relate to the number of incidents that occurred. We first\nassess the effect of each individual agent's behavior on the collective\ndesirability score, e.g., assessing how likely an agent is to cause incidents.\nThis allows us to selectively imitate agents with a positive effect, e.g., only\nimitating agents that are unlikely to cause incidents. To enable this, we\npropose the concept of an agent's Exchange Value, which quantifies an\nindividual agent's contribution to the collective desirability score. The\nExchange Value is the expected change in desirability score when substituting\nthe agent for a randomly selected agent. We propose additional methods for\nestimating Exchange Values from real-world datasets, enabling us to learn\ndesired imitation policies that outperform relevant baselines. The project\nwebsite can be found at https://tinyurl.com/select-to-perfect.",
      "tldr_zh": "该论文探讨了从大型多代理数据中模仿理想行为的问题，强调并非所有行为都安全或期望，通过为集体轨迹分配 desirability scores 来评估整体表现，例如与车辆事故数量相关。作者引入了 Exchange Value 的概念，用于量化个体代理对集体 desirability scores 的贡献，即替换代理时预期的分数变化，从而允许选择性地模仿对集体有益的代理。实验结果显示，该方法从真实数据集估计 Exchange Values 并学习模仿策略，能超越相关基线，实现了更优的性能表现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.03735v1",
      "published_date": "2024-05-06 15:48:24 UTC",
      "updated_date": "2024-05-06 15:48:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:20:13.803413"
    },
    {
      "arxiv_id": "2405.03567v1",
      "title": "Deep Space Separable Distillation for Lightweight Acoustic Scene Classification",
      "title_zh": "翻译失败",
      "authors": [
        "ShuQi Ye",
        "Yuan Tian"
      ],
      "abstract": "Acoustic scene classification (ASC) is highly important in the real world.\nRecently, deep learning-based methods have been widely employed for acoustic\nscene classification. However, these methods are currently not lightweight\nenough as well as their performance is not satisfactory. To solve these\nproblems, we propose a deep space separable distillation network. Firstly, the\nnetwork performs high-low frequency decomposition on the log-mel spectrogram,\nsignificantly reducing computational complexity while maintaining model\nperformance. Secondly, we specially design three lightweight operators for ASC,\nincluding Separable Convolution (SC), Orthonormal Separable Convolution (OSC),\nand Separable Partial Convolution (SPC). These operators exhibit highly\nefficient feature extraction capabilities in acoustic scene classification\ntasks. The experimental results demonstrate that the proposed method achieves a\nperformance gain of 9.8% compared to the currently popular deep learning\nmethods, while also having smaller parameter count and computational\ncomplexity.",
      "tldr_zh": "本研究针对声学场景分类 (ASC) 的轻量化挑战，提出了一种深度空间可分离蒸馏网络，以减少计算复杂度和提升性能。该网络首先对 log-mel 谱图进行高低频分解，同时设计了三个轻量级操作符：Separable Convolution (SC)、Orthonormal Separable Convolution (OSC) 和 Separable Partial Convolution (SPC)，这些操作符显著提高了特征提取效率。实验结果表明，与现有深度学习方法相比，该方法在 ASC 任务上性能提升 9.8%，并实现了更小的参数量和计算复杂度。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.03567v1",
      "published_date": "2024-05-06 15:41:41 UTC",
      "updated_date": "2024-05-06 15:41:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:20:26.401821"
    },
    {
      "arxiv_id": "2405.03553v3",
      "title": "AlphaMath Almost Zero: Process Supervision without Process",
      "title_zh": "AlphaMath Almost Zero：无需过程的过程监督",
      "authors": [
        "Guoxin Chen",
        "Minpeng Liao",
        "Chengxi Li",
        "Kai Fan"
      ],
      "abstract": "Although recent advancements in large language models (LLMs) have\nsignificantly improved their performance on various tasks, they still face\nchallenges with complex and symbolic multi-step reasoning, particularly in\nmathematical reasoning. To bolster the mathematical reasoning capabilities of\nLLMs, most existing efforts concentrate on seeking assistance from either\ndomain experts or GPT-4 for high-quality process-supervised data, which is not\nonly expensive but also labor-intensive. In our study, we propose an innovative\nframework, AlphaMath, that bypasses the need for process annotations (from\nhumans or GPTs) by leveraging Monte Carlo Tree Search (MCTS). This framework\nfocuses on unleashing the potential of a well-pretrained LLM to autonomously\nenhance its mathematical reasoning. Specifically, we integrate a value model\nwith the LLM, automatically generating both process supervision and step-level\nevaluation signals in MCTS. Furthermore, we propose an efficient inference\nstrategy, step-level beam search, where the value model is crafted to assist\nthe policy model (i.e., LLM) in navigating more effective reasoning paths,\nrather than solely relying on prior probabilities. The experimental results on\nboth in-domain and out-of-domain datasets demonstrate that even without GPT-4\nor human-annotated process supervision, our AlphaMath framework achieves\ncomparable or superior results to previous state-of-the-art methods.",
      "tldr_zh": "该研究提出AlphaMath框架，旨在提升大型语言模型(LLMs)在复杂数学推理方面的性能，而无需依赖昂贵的人工或GPT-4过程监督。框架利用Monte Carlo Tree Search (MCTS)整合价值模型(value model)与LLMs，自动生成过程监督信号和步骤级评估，从而让模型自主优化推理路径。此外，通过引入步骤级beam search推理策略，AlphaMath在in-domain和out-of-domain数据集上实现了与最先进方法相当或更优的实验结果，证明了其高效性和可扩展性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Camera ready version for NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.03553v3",
      "published_date": "2024-05-06 15:20:30 UTC",
      "updated_date": "2024-09-27 08:16:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:20:39.130096"
    },
    {
      "arxiv_id": "2405.03734v1",
      "title": "FOKE: A Personalized and Explainable Education Framework Integrating Foundation Models, Knowledge Graphs, and Prompt Engineering",
      "title_zh": "翻译失败",
      "authors": [
        "Silan Hu",
        "Xiaoning Wang"
      ],
      "abstract": "Integrating large language models (LLMs) and knowledge graphs (KGs) holds\ngreat promise for revolutionizing intelligent education, but challenges remain\nin achieving personalization, interactivity, and explainability. We propose\nFOKE, a Forest Of Knowledge and Education framework that synergizes foundation\nmodels, knowledge graphs, and prompt engineering to address these challenges.\nFOKE introduces three key innovations: (1) a hierarchical knowledge forest for\nstructured domain knowledge representation; (2) a multi-dimensional user\nprofiling mechanism for comprehensive learner modeling; and (3) an interactive\nprompt engineering scheme for generating precise and tailored learning\nguidance.\n  We showcase FOKE's application in programming education, homework assessment,\nand learning path planning, demonstrating its effectiveness and practicality.\nAdditionally, we implement Scholar Hero, a real-world instantiation of FOKE.\nOur research highlights the potential of integrating foundation models,\nknowledge graphs, and prompt engineering to revolutionize intelligent education\npractices, ultimately benefiting learners worldwide. FOKE provides a principled\nand unified approach to harnessing cutting-edge AI technologies for\npersonalized, interactive, and explainable educational services, paving the way\nfor further research and development in this critical direction.",
      "tldr_zh": "本研究提出 FOKE 框架，通过整合 Foundation Models、Knowledge Graphs 和 Prompt Engineering，解决智能教育中个性化、交互性和可解释性的挑战。FOKE 的关键创新包括：(1) 层次化知识森林（hierarchical knowledge forest）用于结构化领域知识表示；(2) 多维用户建模机制（multi-dimensional user profiling）实现全面学习者建模；以及(3) 交互式提示工程方案（interactive prompt engineering）生成精确的定制学习指导。该框架在编程教育、作业评估和学习路径规划等方面得到应用，并通过实际系统 Scholar Hero 验证其有效性，最终为全球学习者提供个性化、交互式和可解释的教育服务，推进智能教育领域的创新发展。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "stat.AP"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.03734v1",
      "published_date": "2024-05-06 15:11:05 UTC",
      "updated_date": "2024-05-06 15:11:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:20:50.855989"
    },
    {
      "arxiv_id": "2405.03547v2",
      "title": "Position: Leverage Foundational Models for Black-Box Optimization",
      "title_zh": "观点：利用基础模型进行黑箱优化",
      "authors": [
        "Xingyou Song",
        "Yingtao Tian",
        "Robert Tjarko Lange",
        "Chansoo Lee",
        "Yujin Tang",
        "Yutian Chen"
      ],
      "abstract": "Undeniably, Large Language Models (LLMs) have stirred an extraordinary wave\nof innovation in the machine learning research domain, resulting in substantial\nimpact across diverse fields such as reinforcement learning, robotics, and\ncomputer vision. Their incorporation has been rapid and transformative, marking\na significant paradigm shift in the field of machine learning research.\nHowever, the field of experimental design, grounded on black-box optimization,\nhas been much less affected by such a paradigm shift, even though integrating\nLLMs with optimization presents a unique landscape ripe for exploration. In\nthis position paper, we frame the field of black-box optimization around\nsequence-based foundation models and organize their relationship with previous\nliterature. We discuss the most promising ways foundational language models can\nrevolutionize optimization, which include harnessing the vast wealth of\ninformation encapsulated in free-form text to enrich task comprehension,\nutilizing highly flexible sequence models such as Transformers to engineer\nsuperior optimization strategies, and enhancing performance prediction over\npreviously unseen search spaces.",
      "tldr_zh": "本论文作为一篇立场论文（Position Paper），探讨了如何利用基础模型（如 Large Language Models, LLMs）来革新黑箱优化（Black-Box Optimization）领域，尽管该领域目前尚未充分受益于机器学习范式转变。论文框架了黑箱优化与序列基础模型的关系，并将其与现有文献组织起来。关键观点包括：利用自由形式文本中的丰富信息来增强任务理解、采用灵活的序列模型（如 Transformers）设计更优的优化策略，以及提升对未知搜索空间的性能预测，从而为优化领域带来潜在的重大创新。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "International Conference on Machine Learning (ICML) 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.03547v2",
      "published_date": "2024-05-06 15:10:46 UTC",
      "updated_date": "2024-05-09 14:44:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:21:03.614821"
    },
    {
      "arxiv_id": "2405.03541v1",
      "title": "RepVGG-GELAN: Enhanced GELAN with VGG-STYLE ConvNets for Brain Tumour Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Thennarasi Balakrishnan",
        "Sandeep Singh Sengar"
      ],
      "abstract": "Object detection algorithms particularly those based on YOLO have\ndemonstrated remarkable efficiency in balancing speed and accuracy. However,\ntheir application in brain tumour detection remains underexplored. This study\nproposes RepVGG-GELAN, a novel YOLO architecture enhanced with RepVGG, a\nreparameterized convolutional approach for object detection tasks particularly\nfocusing on brain tumour detection within medical images. RepVGG-GELAN\nleverages the RepVGG architecture to improve both speed and accuracy in\ndetecting brain tumours. Integrating RepVGG into the YOLO framework aims to\nachieve a balance between computational efficiency and detection performance.\nThis study includes a spatial pyramid pooling-based Generalized Efficient Layer\nAggregation Network (GELAN) architecture which further enhances the capability\nof RepVGG. Experimental evaluation conducted on a brain tumour dataset\ndemonstrates the effectiveness of RepVGG-GELAN surpassing existing RCS-YOLO in\nterms of precision and speed. Specifically, RepVGG-GELAN achieves an increased\nprecision of 4.91% and an increased AP50 of 2.54% over the latest existing\napproach while operating at 240.7 GFLOPs. The proposed RepVGG-GELAN with GELAN\narchitecture presents promising results establishing itself as a\nstate-of-the-art solution for accurate and efficient brain tumour detection in\nmedical images. The implementation code is publicly available at\nhttps://github.com/ThensiB/RepVGG-GELAN.",
      "tldr_zh": "该研究提出了一种新型物体检测模型RepVGG-GELAN，通过将RepVGG（一种重新参数化的卷积方法）整合到YOLO框架中，增强了GELAN架构，以提高脑肿瘤检测的速度和准确性。模型结合了基于空间金字塔池化的Generalized Efficient Layer Aggregation Network (GELAN)，旨在平衡计算效率和检测性能。在脑肿瘤数据集上的实验表明，RepVGG-GELAN比现有的RCS-YOLO模型精度提高了4.91%、AP50提高了2.54%，并以240.7 GFLOPs的效率运行，确立了其在医疗图像脑肿瘤检测中的先进地位。代码已在GitHub上公开。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.03541v1",
      "published_date": "2024-05-06 15:02:16 UTC",
      "updated_date": "2024-05-06 15:02:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:21:13.966289"
    },
    {
      "arxiv_id": "2405.03537v2",
      "title": "Exploring the Efficacy of Federated-Continual Learning Nodes with Attention-Based Classifier for Robust Web Phishing Detection: An Empirical Investigation",
      "title_zh": "翻译失败",
      "authors": [
        "Jesher Joshua M",
        "Adhithya R",
        "Sree Dananjay S",
        "M Revathi"
      ],
      "abstract": "Web phishing poses a dynamic threat, requiring detection systems to quickly\nadapt to the latest tactics. Traditional approaches of accumulating data and\nperiodically retraining models are outpaced. We propose a novel paradigm\ncombining federated learning and continual learning, enabling distributed nodes\nto continually update models on streams of new phishing data, without\naccumulating data. These locally adapted models are then aggregated at a\ncentral server via federated learning. To enhance detection, we introduce a\ncustom attention-based classifier model with residual connections, tailored for\nweb phishing, leveraging attention mechanisms to capture intricate phishing\npatterns. We evaluate our hybrid learning paradigm across continual learning\nstrategies (cumulative, replay, MIR, LwF) and model architectures through an\nempirical investigation. Our main contributions are: (1) a new hybrid\nfederated-continual learning paradigm for robust web phishing detection, and\n(2) a novel attention + residual connections based model explicitly designed\nfor this task, attaining 0.93 accuracy, 0.90 precision, 0.96 recall and 0.93\nf1-score with the LwF strategy, outperforming traditional approaches in\ndetecting emerging phishing threats while retaining past knowledge.",
      "tldr_zh": "本研究探讨了网络钓鱼的动态威胁，提出了一种结合 Federated Learning 和 Continual Learning 的混合范式，让分布式节点在不积累数据的情况下持续更新模型，并通过联邦聚合实现全局优化。研究引入了一个自定义的 Attention-Based Classifier 模型，结合残差连接来捕捉复杂的钓鱼模式，并在多种 Continual Learning 策略（如累积、回放、MIR 和 LwF）上进行实证评估。主要贡献包括：一个新的混合学习范式，以及该模型在 LwF 策略下的出色性能，达到 0.93 准确率、0.90 精确率、0.96 召回率和 0.93 F1-Score，优于传统方法在检测新兴威胁的同时保留了历史知识。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.03537v2",
      "published_date": "2024-05-06 14:55:37 UTC",
      "updated_date": "2024-06-16 14:05:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:21:27.025598"
    },
    {
      "arxiv_id": "2405.03534v1",
      "title": "Meta-Evolve: Continuous Robot Evolution for One-to-many Policy Transfer",
      "title_zh": "Meta-Evolve：用于一对多策略转移的连续机器人进化",
      "authors": [
        "Xingyu Liu",
        "Deepak Pathak",
        "Ding Zhao"
      ],
      "abstract": "We investigate the problem of transferring an expert policy from a source\nrobot to multiple different robots. To solve this problem, we propose a method\nnamed $Meta$-$Evolve$ that uses continuous robot evolution to efficiently\ntransfer the policy to each target robot through a set of tree-structured\nevolutionary robot sequences. The robot evolution tree allows the robot\nevolution paths to be shared, so our approach can significantly outperform\nnaive one-to-one policy transfer. We present a heuristic approach to determine\nan optimized robot evolution tree. Experiments have shown that our method is\nable to improve the efficiency of one-to-three transfer of manipulation policy\nby up to 3.2$\\times$ and one-to-six transfer of agile locomotion policy by\n2.4$\\times$ in terms of simulation cost over the baseline of launching multiple\nindependent one-to-one policy transfers.",
      "tldr_zh": "本研究探讨了从一个源机器人向多个目标机器人转移策略（one-to-many policy transfer）的问题，提出了一种名为 Meta-Evolve 的方法，通过连续机器人进化（continuous robot evolution）构建树状结构进化序列来共享进化路径，从而提高转移效率。Meta-Evolve 使用启发式算法优化机器人进化树，确保资源共享并减少冗余。实验结果显示，该方法在模拟成本上将 one-to-three 操作策略转移效率提高 3.2 倍，并将 one-to-six 敏捷运动策略转移效率提高 2.4 倍，显著优于传统的独立一对一转移基线。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.RO",
      "comment": "ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.03534v1",
      "published_date": "2024-05-06 14:52:23 UTC",
      "updated_date": "2024-05-06 14:52:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:21:38.775866"
    },
    {
      "arxiv_id": "2405.09563v1",
      "title": "Stressor Type Matters! -- Exploring Factors Influencing Cross-Dataset Generalizability of Physiological Stress Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Pooja Prajod",
        "Bhargavi Mahesh",
        "Elisabeth André"
      ],
      "abstract": "Automatic stress detection using heart rate variability (HRV) features has\ngained significant traction as it utilizes unobtrusive wearable sensors\nmeasuring signals like electrocardiogram (ECG) or blood volume pulse (BVP).\nHowever, detecting stress through such physiological signals presents a\nconsiderable challenge owing to the variations in recorded signals influenced\nby factors, such as perceived stress intensity and measurement devices.\nConsequently, stress detection models developed on one dataset may perform\npoorly on unseen data collected under different conditions. To address this\nchallenge, this study explores the generalizability of machine learning models\ntrained on HRV features for binary stress detection. Our goal extends beyond\nevaluating generalization performance; we aim to identify the characteristics\nof datasets that have the most significant influence on generalizability. We\nleverage four publicly available stress datasets (WESAD, SWELL-KW,\nForDigitStress, VerBIO) that vary in at least one of the characteristics such\nas stress elicitation techniques, stress intensity, and sensor devices.\nEmploying a cross-dataset evaluation approach, we explore which of these\ncharacteristics strongly influence model generalizability. Our findings reveal\na crucial factor affecting model generalizability: stressor type. Models\nachieved good performance across datasets when the type of stressor (e.g.,\nsocial stress in our case) remains consistent. Factors like stress intensity or\nbrand of the measurement device had minimal impact on cross-dataset\nperformance. Based on our findings, we recommend matching the stressor type\nwhen deploying HRV-based stress models in new environments. To the best of our\nknowledge, this is the first study to systematically investigate factors\ninfluencing the cross-dataset applicability of HRV-based stress models.",
      "tldr_zh": "本研究探讨了使用心率变异性（HRV）特征进行生理压力检测模型的跨数据集泛化性影响因素，强调了不同数据集特性（如压力诱发技术、强度和设备）对模型性能的影响。研究者采用四个公开数据集（WESAD, SWELL-KW, ForDigitStress, VerBIO）进行跨数据集评估，系统分析了这些因素。关键发现是，stressor type 是模型泛化性的主要决定因素——当 stressor type 一致（如社会压力）时，模型表现良好，而 stress intensity 或设备品牌对跨数据集性能影响较小。基于此，该研究首次推荐在部署 HRV-based 压力模型时匹配 stressor type，以提升实际应用效果。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.09563v1",
      "published_date": "2024-05-06 14:47:48 UTC",
      "updated_date": "2024-05-06 14:47:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:21:53.963562"
    },
    {
      "arxiv_id": "2405.03524v5",
      "title": "A short Survey: Exploring knowledge graph-based neural-symbolic system from application perspective",
      "title_zh": "短综述：从应用角度探索基于知识图谱的神经符号系统",
      "authors": [
        "Shenzhe Zhu",
        "Shengxiang Sun"
      ],
      "abstract": "Advancements in Artificial Intelligence (AI) and deep neural networks have\ndriven significant progress in vision and text processing. However, achieving\nhuman-like reasoning and interpretability in AI systems remains a substantial\nchallenge. The Neural-Symbolic paradigm, which integrates neural networks with\nsymbolic systems, presents a promising pathway toward more interpretable AI.\nWithin this paradigm, Knowledge Graphs (KG) are crucial, offering a structured\nand dynamic method for representing knowledge through interconnected entities\nand relationships, typically as triples (subject, predicate, object). This\npaper explores recent advancements in neural-symbolic integration based on KG,\nexamining how it supports integration in three categories: enhancing the\nreasoning and interpretability of neural networks with symbolic knowledge\n(Symbol for Neural), refining the completeness and accuracy of symbolic systems\nvia neural network methodologies (Neural for Symbol), and facilitating their\ncombined application in Hybrid Neural-Symbolic Integration. It highlights\ncurrent trends and proposes future research directions in Neural-Symbolic AI.",
      "tldr_zh": "人工智能（AI）和深度神经网络在视觉和文本处理方面取得了显著进展，但实现人类般的推理和可解释性仍是重大挑战。本文通过简短调查，探讨了基于知识图谱（KG）的神经-符号范式，强调KG作为结构化知识表示（例如三元组：subject, predicate, object）的作用，并将其整合分为三类：利用符号知识增强神经网络的推理和可解释性（Symbol for Neural）、通过神经网络方法改进符号系统的完整性和准确性（Neural for Symbol），以及混合神经-符号整合（Hybrid Neural-Symbolic Integration）。论文总结了当前趋势，并提出未来研究方向，以推动更可靠的AI系统发展。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.03524v5",
      "published_date": "2024-05-06 14:40:50 UTC",
      "updated_date": "2025-02-18 15:30:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:22:04.674727"
    },
    {
      "arxiv_id": "2405.03521v1",
      "title": "Optimisation challenge for superconducting adiabatic neural network implementing XOR and OR boolean functions",
      "title_zh": "翻译失败",
      "authors": [
        "D. S. Pashin",
        "M. V. Bastrakova",
        "D. A. Rybin",
        "I. I. Soloviev",
        "A. E. Schegolev",
        "N. V. Klenov"
      ],
      "abstract": "In this article, we consider designs of simple analog artificial neural\nnetworks based on adiabatic Josephson cells with a sigmoid activation function.\nA new approach based on the gradient descent method is developed to adjust the\ncircuit parameters, allowing efficient signal transmission between the network\nlayers. The proposed solution is demonstrated on the example of the system\nimplementing XOR and OR logical operations.",
      "tldr_zh": "这篇论文探讨了基于绝热Josephson细胞的简单模拟人工神经网络设计，这些网络采用sigmoid激活函数来实现XOR和OR布尔函数。研究开发了一种新方法，利用gradient descent method调整电路参数，以实现网络层之间高效的信号传输。该方法通过XOR和OR逻辑运算的系统示例进行了验证，展示了其在优化神经网络性能方面的潜力。",
      "categories": [
        "cond-mat.supr-con",
        "cs.AI"
      ],
      "primary_category": "cond-mat.supr-con",
      "comment": "13 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.03521v1",
      "published_date": "2024-05-06 14:38:43 UTC",
      "updated_date": "2024-05-06 14:38:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:22:13.542799"
    },
    {
      "arxiv_id": "2405.06686v1",
      "title": "Word2World: Generating Stories and Worlds through Large Language Models",
      "title_zh": "Word2World：通过大型语言模型生成故事和世界",
      "authors": [
        "Muhammad U. Nasir",
        "Steven James",
        "Julian Togelius"
      ],
      "abstract": "Large Language Models (LLMs) have proven their worth across a diverse\nspectrum of disciplines. LLMs have shown great potential in Procedural Content\nGeneration (PCG) as well, but directly generating a level through a pre-trained\nLLM is still challenging. This work introduces Word2World, a system that\nenables LLMs to procedurally design playable games through stories, without any\ntask-specific fine-tuning. Word2World leverages the abilities of LLMs to create\ndiverse content and extract information. Combining these abilities, LLMs can\ncreate a story for the game, design narrative, and place tiles in appropriate\nplaces to create coherent worlds and playable games. We test Word2World with\ndifferent LLMs and perform a thorough ablation study to validate each step. We\nopen-source the code at https://github.com/umair-nasir14/Word2World.",
      "tldr_zh": "这篇论文介绍了 Word2World 系统，利用 Large Language Models (LLMs) 在无需任务特定微调的情况下，通过故事生成过程化内容（Procedural Content Generation, PCG），从而创建可玩游戏。系统结合 LLMs 的内容多样性和信息提取能力，生成游戏叙事并在适当位置放置元素，以构建连贯的世界和关卡。作者通过不同 LLMs 的测试和消融研究验证了系统的有效性，并开源了代码（https://github.com/umair-nasir14/Word2World）。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.06686v1",
      "published_date": "2024-05-06 14:21:52 UTC",
      "updated_date": "2024-05-06 14:21:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:22:26.850843"
    },
    {
      "arxiv_id": "2405.03501v1",
      "title": "Boosting Single Positive Multi-label Classification with Generalized Robust Loss",
      "title_zh": "利用泛化鲁棒",
      "authors": [
        "Yanxi Chen",
        "Chunxiao Li",
        "Xinyang Dai",
        "Jinhuan Li",
        "Weiyu Sun",
        "Yiming Wang",
        "Renyuan Zhang",
        "Tinghe Zhang",
        "Bo Wang"
      ],
      "abstract": "Multi-label learning (MLL) requires comprehensive multi-semantic annotations\nthat is hard to fully obtain, thus often resulting in missing labels scenarios.\nIn this paper, we investigate Single Positive Multi-label Learning (SPML),\nwhere each image is associated with merely one positive label. Existing SPML\nmethods only focus on designing losses using mechanisms such as hard\npseudo-labeling and robust losses, mostly leading to unacceptable false\nnegatives. To address this issue, we first propose a generalized loss framework\nbased on expected risk minimization to provide soft pseudo labels, and point\nout that the former losses can be seamlessly converted into our framework. In\nparticular, we design a novel robust loss based on our framework, which enjoys\nflexible coordination between false positives and false negatives, and can\nadditionally deal with the imbalance between positive and negative samples.\nExtensive experiments show that our approach can significantly improve SPML\nperformance and outperform the vast majority of state-of-the-art methods on all\nthe four benchmarks.",
      "tldr_zh": "本文针对Single Positive Multi-label Learning (SPML)问题，提出一个基于期望风险最小化的通用损失框架，以提供软伪标签，从而减少现有方法中常见的假阴性问题。基于此框架，作者设计了一种新颖的robust loss，能够灵活协调假阳性和假阴性，并有效处理正负样本的不平衡。实验结果显示，该方法显著提升了SPML性能，在四个基准数据集上优于大多数最先进的方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 5 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2405.03501v1",
      "published_date": "2024-05-06 14:13:38 UTC",
      "updated_date": "2024-05-06 14:13:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:22:39.007464"
    },
    {
      "arxiv_id": "2405.03500v1",
      "title": "A Rate-Distortion-Classification Approach for Lossy Image Compression",
      "title_zh": "翻译失败",
      "authors": [
        "Yuefeng Zhang"
      ],
      "abstract": "In lossy image compression, the objective is to achieve minimal signal\ndistortion while compressing images to a specified bit rate. The increasing\ndemand for visual analysis applications, particularly in classification tasks,\nhas emphasized the significance of considering semantic distortion in\ncompressed images. To bridge the gap between image compression and visual\nanalysis, we propose a Rate-Distortion-Classification (RDC) model for lossy\nimage compression, offering a unified framework to optimize the trade-off\nbetween rate, distortion, and classification accuracy. The RDC model is\nextensively analyzed both statistically on a multi-distribution source and\nexperimentally on the widely used MNIST dataset. The findings reveal that the\nRDC model exhibits desirable properties, including monotonic non-increasing and\nconvex functions, under certain conditions. This work provides insights into\nthe development of human-machine friendly compression methods and Video Coding\nfor Machine (VCM) approaches, paving the way for end-to-end image compression\ntechniques in real-world applications.",
      "tldr_zh": "本文提出了一种 Rate-Distortion-Classification (RDC) 模型，用于损失性图像压缩，旨在统一优化速率、失真和分类准确率之间的权衡，以适应视觉分析任务的需求。RDC 模型通过在多分布源上的统计分析和 MNIST 数据集的实验验证，展示了在特定条件下具有单调非增和凸函数的特性。总体而言，该工作为开发人性化-机器友好压缩方法和 Video Coding for Machine (VCM) 技术提供了重要洞见，推动了端到端图像压缩在实际应用中的进展。",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.CV",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.MM",
      "comment": "15 pages",
      "pdf_url": "http://arxiv.org/pdf/2405.03500v1",
      "published_date": "2024-05-06 14:11:36 UTC",
      "updated_date": "2024-05-06 14:11:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:22:52.509297"
    },
    {
      "arxiv_id": "2405.03462v1",
      "title": "A Lightweight Neural Architecture Search Model for Medical Image Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Lunchen Xie",
        "Eugenio Lomurno",
        "Matteo Gambella",
        "Danilo Ardagna",
        "Manuel Roveri",
        "Matteo Matteucci",
        "Qingjiang Shi"
      ],
      "abstract": "Accurate classification of medical images is essential for modern\ndiagnostics. Deep learning advancements led clinicians to increasingly use\nsophisticated models to make faster and more accurate decisions, sometimes\nreplacing human judgment. However, model development is costly and repetitive.\nNeural Architecture Search (NAS) provides solutions by automating the design of\ndeep learning architectures. This paper presents ZO-DARTS+, a differentiable\nNAS algorithm that improves search efficiency through a novel method of\ngenerating sparse probabilities by bi-level optimization. Experiments on five\npublic medical datasets show that ZO-DARTS+ matches the accuracy of\nstate-of-the-art solutions while reducing search times by up to three times.",
      "tldr_zh": "本研究针对医疗图像分类的准确性需求，提出了一种轻量级 Neural Architecture Search (NAS) 模型 ZO-DARTS+，通过双层优化生成稀疏概率的方法来自动化深度学习架构设计，从而提高搜索效率。ZO-DARTS+ 解决了传统模型开发成本高和重复性的问题，在五个公共医疗数据集上进行实验。结果显示，该模型的准确性与最先进解决方案相当，但将搜索时间减少多达三倍，为临床诊断提供更高效的工具。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.03462v1",
      "published_date": "2024-05-06 13:33:38 UTC",
      "updated_date": "2024-05-06 13:33:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:23:02.884831"
    },
    {
      "arxiv_id": "2405.03452v3",
      "title": "Large Language Models (LLMs) as Agents for Augmented Democracy",
      "title_zh": "翻译失败",
      "authors": [
        "Jairo Gudiño-Rosero",
        "Umberto Grandi",
        "César A. Hidalgo"
      ],
      "abstract": "We explore an augmented democracy system built on off-the-shelf LLMs\nfine-tuned to augment data on citizen's preferences elicited over policies\nextracted from the government programs of the two main candidates of Brazil's\n2022 presidential election. We use a train-test cross-validation setup to\nestimate the accuracy with which the LLMs predict both: a subject's individual\npolitical choices and the aggregate preferences of the full sample of\nparticipants. At the individual level, we find that LLMs predict out of sample\npreferences more accurately than a \"bundle rule\", which would assume that\ncitizens always vote for the proposals of the candidate aligned with their\nself-reported political orientation. At the population level, we show that a\nprobabilistic sample augmented by an LLM provides a more accurate estimate of\nthe aggregate preferences of a population than the non-augmented probabilistic\nsample alone. Together, these results indicates that policy preference data\naugmented using LLMs can capture nuances that transcend party lines and\nrepresents a promising avenue of research for data augmentation.",
      "tldr_zh": "本研究探讨了使用大型语言模型（LLMs）作为代理来增强民主系统，具体通过微调 LLMs 来分析巴西2022年总统选举候选人政策，并基于公民偏好数据进行预测。采用训练-测试交叉验证方法，评估LLMs在预测个体政治选择和整体样本偏好上的准确性，结果显示LLMs比“bundle rule”（假设公民总是支持与自身政治导向一致的候选人）更精确。研究发现，添加LLMs的概率样本能更准确地估计人口整体偏好，并捕捉超越党派的细微差别，这为政策偏好数据增强提供了有前景的研究方向。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "24 pages main manuscript with 4 figures. 13 pages of supplementary\n  material",
      "pdf_url": "http://arxiv.org/pdf/2405.03452v3",
      "published_date": "2024-05-06 13:23:57 UTC",
      "updated_date": "2024-07-30 09:51:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:23:15.254884"
    },
    {
      "arxiv_id": "2405.03440v1",
      "title": "Robotic Constrained Imitation Learning for the Peg Transfer Task in Fundamentals of Laparoscopic Surgery",
      "title_zh": "翻译失败",
      "authors": [
        "Kento Kawaharazuka",
        "Kei Okada",
        "Masayuki Inaba"
      ],
      "abstract": "In this study, we present an implementation strategy for a robot that\nperforms peg transfer tasks in Fundamentals of Laparoscopic Surgery (FLS) via\nimitation learning, aimed at the development of an autonomous robot for\nlaparoscopic surgery. Robotic laparoscopic surgery presents two main\nchallenges: (1) the need to manipulate forceps using ports established on the\nbody surface as fulcrums, and (2) difficulty in perceiving depth information\nwhen working with a monocular camera that displays its images on a monitor.\nEspecially, regarding issue (2), most prior research has assumed the\navailability of depth images or models of a target to be operated on.\nTherefore, in this study, we achieve more accurate imitation learning with only\nmonocular images by extracting motion constraints from one exemplary motion of\nskilled operators, collecting data based on these constraints, and conducting\nimitation learning based on the collected data. We implemented an overall\nsystem using two Franka Emika Panda Robot Arms and validated its effectiveness.",
      "tldr_zh": "本研究提出了一种约束模仿学习（constrained imitation learning）方法，用于机器人执行基础腹腔镜手术（Fundamentals of Laparoscopic Surgery, FLS）中的移钉任务（peg transfer task），旨在开发自主腹腔镜手术机器人。针对操作支点和单目相机深度感知的挑战，该方法从熟练操作者的示例动作中提取运动约束（motion constraints），基于这些约束收集数据，并进行模仿学习，仅依赖单目图像（monocular images）实现更准确的机器人控制。研究使用两个Franka Emika Panda Robot Arms构建了整体系统，并通过实验验证了其有效性，展示了在真实手术场景中提升机器人性能的潜力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted at ICRA2024, website -\n  https://haraduka.github.io/fls-imitation",
      "pdf_url": "http://arxiv.org/pdf/2405.03440v1",
      "published_date": "2024-05-06 13:12:25 UTC",
      "updated_date": "2024-05-06 13:12:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:23:26.712952"
    },
    {
      "arxiv_id": "2405.03435v1",
      "title": "A method for quantifying the generalization capabilities of generative models for solving Ising models",
      "title_zh": "一种用于量化生成模型解决 Ising 模型泛化能力",
      "authors": [
        "Qunlong Ma",
        "Zhi Ma",
        "Ming Gao"
      ],
      "abstract": "For Ising models with complex energy landscapes, whether the ground state can\nbe found by neural networks depends heavily on the Hamming distance between the\ntraining datasets and the ground state. Despite the fact that various recently\nproposed generative models have shown good performance in solving Ising models,\nthere is no adequate discussion on how to quantify their generalization\ncapabilities. Here we design a Hamming distance regularizer in the framework of\na class of generative models, variational autoregressive networks (VAN), to\nquantify the generalization capabilities of various network architectures\ncombined with VAN. The regularizer can control the size of the overlaps between\nthe ground state and the training datasets generated by networks, which,\ntogether with the success rates of finding the ground state, form a\nquantitative metric to quantify their generalization capabilities. We conduct\nnumerical experiments on several prototypical network architectures combined\nwith VAN, including feed-forward neural networks, recurrent neural networks,\nand graph neural networks, to quantify their generalization capabilities when\nsolving Ising models. Moreover, considering the fact that the quantification of\nthe generalization capabilities of networks on small-scale problems can be used\nto predict their relative performance on large-scale problems, our method is of\ngreat significance for assisting in the Neural Architecture Search field of\nsearching for the optimal network architectures when solving large-scale Ising\nmodels.",
      "tldr_zh": "该论文提出了一种量化生成模型在解决Ising models泛化能力的方法，重点关注训练数据集与基态之间的Hamming distance对神经网络性能的影响。作者在Variational Autoregressive Networks (VAN)框架下设计了Hamming distance正则化器，用于控制数据集与基态的重叠，并结合找到基态的成功率形成量化指标。实验评估了多种网络架构，包括Feed-Forward Neural Networks (FFNNs)、Recurrent Neural Networks (RNNs)和Graph Neural Networks (GNNs)，证明了该方法能有效预测网络在小规模问题上的泛化能力，从而为Neural Architecture Search在大型Ising models中搜索最优架构提供指导。",
      "categories": [
        "cond-mat.dis-nn",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cond-mat.dis-nn",
      "comment": "10 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.03435v1",
      "published_date": "2024-05-06 12:58:48 UTC",
      "updated_date": "2024-05-06 12:58:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:23:41.083421"
    },
    {
      "arxiv_id": "2405.03429v1",
      "title": "ReCycle: Fast and Efficient Long Time Series Forecasting with Residual Cyclic Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Arvid Weyrauch",
        "Thomas Steens",
        "Oskar Taubert",
        "Benedikt Hanke",
        "Aslan Eqbal",
        "Ewa Götz",
        "Achim Streit",
        "Markus Götz",
        "Charlotte Debus"
      ],
      "abstract": "Transformers have recently gained prominence in long time series forecasting\nby elevating accuracies in a variety of use cases. Regrettably, in the race for\nbetter predictive performance the overhead of model architectures has grown\nonerous, leading to models with computational demand infeasible for most\npractical applications. To bridge the gap between high method complexity and\nrealistic computational resources, we introduce the Residual Cyclic\nTransformer, ReCycle. ReCycle utilizes primary cycle compression to address the\ncomputational complexity of the attention mechanism in long time series. By\nlearning residuals from refined smoothing average techniques, ReCycle surpasses\nstate-of-the-art accuracy in a variety of application use cases. The reliable\nand explainable fallback behavior ensured by simple, yet robust, smoothing\naverage techniques additionally lowers the barrier for user acceptance. At the\nsame time, our approach reduces the run time and energy consumption by more\nthan an order of magnitude, making both training and inference feasible on\nlow-performance, low-power and edge computing devices. Code is available at\nhttps://github.com/Helmholtz-AI-Energy/ReCycle",
      "tldr_zh": "本研究提出 ReCycle，一种基于 Residual Cyclic Transformers 的框架，用于快速高效的长序列时间预测，旨在解决传统 Transformers 模型在计算复杂性上的问题。通过主循环压缩和学习残差（从精炼平滑平均技术中获取），ReCycle 显著提升了预测准确率，并在多种应用场景中超越最先进模型。实验表明，该方法将运行时间和能源消耗减少一个数量级以上，使其适用于低性能、低功耗和边缘计算设备，同时提供可靠的可解释后备行为。代码已在 GitHub 上开源。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 3 figures, to be published at IEEE CAI 2024, Associated code\n  available at https://github.com/Helmholtz-AI-Energy/ReCycle",
      "pdf_url": "http://arxiv.org/pdf/2405.03429v1",
      "published_date": "2024-05-06 12:48:34 UTC",
      "updated_date": "2024-05-06 12:48:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:23:52.027005"
    },
    {
      "arxiv_id": "2405.03406v1",
      "title": "Automated Computation of Therapies Using Failure Mode and Effects Analysis in the Medical Domain",
      "title_zh": "翻译失败",
      "authors": [
        "Malte Luttermann",
        "Edgar Baake",
        "Juljan Bouchagiar",
        "Benjamin Gebel",
        "Philipp Grüning",
        "Dilini Manikwadura",
        "Franziska Schollemann",
        "Elisa Teifke",
        "Philipp Rostalski",
        "Ralf Möller"
      ],
      "abstract": "Failure mode and effects analysis (FMEA) is a systematic approach to identify\nand analyse potential failures and their effects in a system or process. The\nFMEA approach, however, requires domain experts to manually analyse the FMEA\nmodel to derive risk-reducing actions that should be applied. In this paper, we\nprovide a formal framework to allow for automatic planning and acting in FMEA\nmodels. More specifically, we cast the FMEA model into a Markov decision\nprocess which can then be solved by existing solvers. We show that the FMEA\napproach can not only be used to support medical experts during the modelling\nprocess but also to automatically derive optimal therapies for the treatment of\npatients.",
      "tldr_zh": "这篇论文提出了一种正式框架，将故障模式与影响分析(FMEA)模型转化为Markov Decision Process (MDP)，以实现自动规划和行动，从而避免传统FMEA依赖领域专家的手动分析。研究方法包括使用现有求解器处理MDP模型，这不仅能支持医疗专家在建模过程中，还能自动推导出最佳的患者治疗方案。该框架展示了FMEA在医疗领域的潜力，提高了风险降低措施的效率和准确性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to the German Journal of Artificial Intelligence",
      "pdf_url": "http://arxiv.org/pdf/2405.03406v1",
      "published_date": "2024-05-06 12:16:53 UTC",
      "updated_date": "2024-05-06 12:16:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:24:03.411088"
    },
    {
      "arxiv_id": "2405.03401v1",
      "title": "E2GNN: Efficient Graph Neural Network Ensembles for Semi-Supervised Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Xin Zhang",
        "Daochen Zha",
        "Qiaoyu Tan"
      ],
      "abstract": "This work studies ensemble learning for graph neural networks (GNNs) under\nthe popular semi-supervised setting. Ensemble learning has shown superiority in\nimproving the accuracy and robustness of traditional machine learning by\ncombining the outputs of multiple weak learners. However, adopting a similar\nidea to integrate different GNN models is challenging because of two reasons.\nFirst, GNN is notorious for its poor inference ability, so naively assembling\nmultiple GNN models would deteriorate the inference efficiency. Second, when\nGNN models are trained with few labeled nodes, their performance are limited.\nIn this case, the vanilla ensemble approach, e.g., majority vote, may be\nsub-optimal since most base models, i.e., GNNs, may make the wrong predictions.\nTo this end, in this paper, we propose an efficient ensemble learner--E2GNN to\nassemble multiple GNNs in a learnable way by leveraging both labeled and\nunlabeled nodes. Specifically, we first pre-train different GNN models on a\ngiven data scenario according to the labeled nodes. Next, instead of directly\ncombing their outputs for label inference, we train a simple multi-layer\nperceptron--MLP model to mimic their predictions on both labeled and unlabeled\nnodes. Then the unified MLP model is deployed to infer labels for unlabeled or\nnew nodes. Since the predictions of unlabeled nodes from different GNN models\nmay be incorrect, we develop a reinforced discriminator to effectively filter\nout those wrongly predicted nodes to boost the performance of MLP. By doing\nthis, we suggest a principled approach to tackle the inference issues of GNN\nensembles and maintain the merit of ensemble learning: improved performance.\nComprehensive experiments over both transductive and inductive settings, across\ndifferent GNN backbones and 8 benchmark datasets, demonstrate the superiority\nof E2GNN.",
      "tldr_zh": "本研究探讨了在半监督分类任务中，通过集成学习提升图神经网络（GNNs）的准确性和鲁棒性。作者提出了一种高效框架E2GNN，通过预训练多个GNN模型，然后训练一个多层感知器（MLP）来模仿这些模型在标记和未标记节点的预测，同时引入强化鉴别器过滤错误预测，从而解决GNNs的推理效率和性能限制问题。实验结果显示，E2GNN在转导和归纳设置下，以及8个基准数据集上，显著优于基线模型，证明了其在提升整体性能方面的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.03401v1",
      "published_date": "2024-05-06 12:11:46 UTC",
      "updated_date": "2024-05-06 12:11:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:24:16.314725"
    },
    {
      "arxiv_id": "2405.03389v2",
      "title": "Don't Waste Your Time: Early Stopping Cross-Validation",
      "title_zh": "不要浪费时间：早停交叉验证",
      "authors": [
        "Edward Bergman",
        "Lennart Purucker",
        "Frank Hutter"
      ],
      "abstract": "State-of-the-art automated machine learning systems for tabular data often\nemploy cross-validation; ensuring that measured performances generalize to\nunseen data, or that subsequent ensembling does not overfit. However, using\nk-fold cross-validation instead of holdout validation drastically increases the\ncomputational cost of validating a single configuration. While ensuring better\ngeneralization and, by extension, better performance, the additional cost is\noften prohibitive for effective model selection within a time budget. We aim to\nmake model selection with cross-validation more effective. Therefore, we study\nearly stopping the process of cross-validation during model selection. We\ninvestigate the impact of early stopping on random search for two algorithms,\nMLP and random forest, across 36 classification datasets. We further analyze\nthe impact of the number of folds by considering 3-, 5-, and 10-folds. In\naddition, we investigate the impact of early stopping with Bayesian\noptimization instead of random search and also repeated cross-validation. Our\nexploratory study shows that even a simple-to-understand and easy-to-implement\nmethod consistently allows model selection to converge faster; in ~94% of all\ndatasets, on average by ~214%. Moreover, stopping cross-validation enables\nmodel selection to explore the search space more exhaustively by considering\n+167% configurations on average within one hour, while also obtaining better\noverall performance.",
      "tldr_zh": "本文提出了一种早停（early stopping）交叉验证方法，以减少自动化机器学习系统中模型选择的计算成本，同时确保性能泛化。研究者通过在随机搜索中应用早停，评估其对 MLP 和随机森林算法在 36 个分类数据集的影响，并比较了 3-、5- 和 10- 折交叉验证的效果。实验还扩展到贝叶斯优化（Bayesian optimization）和重复交叉验证，结果显示早停使模型选择收敛速度平均提高 214%，在约 94% 的数据集上生效。总体而言，该方法能在 1 小时内探索更多配置（+167%），并获得更好的整体性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at Third International Conference on Automated Machine\n  Learning (AutoML 2024); for code, see\n  https://github.com/automl/DontWasteYourTime-early-stopping",
      "pdf_url": "http://arxiv.org/pdf/2405.03389v2",
      "published_date": "2024-05-06 11:51:09 UTC",
      "updated_date": "2024-08-02 14:33:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:24:27.971670"
    },
    {
      "arxiv_id": "2405.03379v1",
      "title": "Reverse Forward Curriculum Learning for Extreme Sample and Demonstration Efficiency in Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Stone Tao",
        "Arth Shukla",
        "Tse-kai Chan",
        "Hao Su"
      ],
      "abstract": "Reinforcement learning (RL) presents a promising framework to learn policies\nthrough environment interaction, but often requires an infeasible amount of\ninteraction data to solve complex tasks from sparse rewards. One direction\nincludes augmenting RL with offline data demonstrating desired tasks, but past\nwork often require a lot of high-quality demonstration data that is difficult\nto obtain, especially for domains such as robotics. Our approach consists of a\nreverse curriculum followed by a forward curriculum. Unique to our approach\ncompared to past work is the ability to efficiently leverage more than one\ndemonstration via a per-demonstration reverse curriculum generated via state\nresets. The result of our reverse curriculum is an initial policy that performs\nwell on a narrow initial state distribution and helps overcome difficult\nexploration problems. A forward curriculum is then used to accelerate the\ntraining of the initial policy to perform well on the full initial state\ndistribution of the task and improve demonstration and sample efficiency. We\nshow how the combination of a reverse curriculum and forward curriculum in our\nmethod, RFCL, enables significant improvements in demonstration and sample\nefficiency compared against various state-of-the-art\nlearning-from-demonstration baselines, even solving previously unsolvable tasks\nthat require high precision and control.",
      "tldr_zh": "这篇论文针对强化学习（RL）中复杂任务需要大量交互数据和高质量演示数据的问题，提出了一种逆向-正向课程学习（RFCL）方法。RFCL 首先通过每个演示的逆向课程（利用状态重置）生成一个在狭窄初始状态分布上表现良好的初始策略，帮助克服探索难题；随后，使用正向课程加速训练，使策略扩展到整个初始状态分布。实验结果显示，RFCL 显著提高了样本和演示效率，与现有基线相比提升了性能，甚至成功解决了之前无法处理的需要高精度控制的任务。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at The Twelfth International Conference on Learning\n  Representations (ICLR 2024). Website: https://reverseforward-cl.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2405.03379v1",
      "published_date": "2024-05-06 11:33:12 UTC",
      "updated_date": "2024-05-06 11:33:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:24:40.473512"
    },
    {
      "arxiv_id": "2405.03372v2",
      "title": "Snake Learning: A Communication- and Computation-Efficient Distributed Learning Framework for 6G",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoxue Yu",
        "Xingfu Yi",
        "Rongpeng Li",
        "Fei Wang",
        "Chenghui Peng",
        "Zhifeng Zhao",
        "Honggang Zhang"
      ],
      "abstract": "In the evolution towards 6G, integrating Artificial Intelligence (AI) with\nadvanced network infrastructure emerges as a pivotal strategy for enhancing\nnetwork intelligence and resource utilization. Existing distributed learning\nframeworks like Federated Learning and Split Learning often struggle with\nsignificant challenges in dynamic network environments including high\nsynchronization demands, costly communication overhead, severe computing\nresource consumption, and data heterogeneity across network nodes. These\nobstacles hinder the applications of ubiquitous computing capabilities of 6G\nnetworks, especially in light of the trend of escalating model parameters and\ntraining data volumes. To address these challenges effectively, this paper\nintroduces ``Snake Learning\", a cost-effective distributed learning framework.\nSpecifically, Snake Learning respects the heterogeneity of inter-node computing\ncapability and local data distribution in 6G networks, and sequentially trains\nthe designated part of model layers on individual nodes. This layer-by-layer\nserpentine update mechanism contributes to significantly reducing the\nrequirements for storage, memory and communication during the model training\nphase, and demonstrates superior adaptability and efficiency for both\nclassification and fine-tuning tasks across homogeneous and heterogeneous data\ndistributions.",
      "tldr_zh": "本文提出Snake Learning，一种高效的分布式学习框架，针对6G网络中Federated Learning和Split Learning面临的通信开销高、计算资源消耗大以及数据异质性等问题。框架通过顺序训练模型的指定层，适应节点间的计算能力和数据分布差异，实现层-by-layer的蛇形更新机制，从而显著降低存储、内存和通信需求。该方法在分类和微调任务上显示出优越的适应性和效率，尤其适用于同质和异质数据分布。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "8 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.03372v2",
      "published_date": "2024-05-06 11:25:59 UTC",
      "updated_date": "2025-01-14 07:26:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:24:51.660953"
    },
    {
      "arxiv_id": "2405.03359v1",
      "title": "MedDoc-Bot: A Chat Tool for Comparative Analysis of Large Language Models in the Context of the Pediatric Hypertension Guideline",
      "title_zh": "翻译失败",
      "authors": [
        "Mohamed Yaseen Jabarulla",
        "Steffen Oeltze-Jafra",
        "Philipp Beerbaum",
        "Theodor Uden"
      ],
      "abstract": "This research focuses on evaluating the non-commercial open-source large\nlanguage models (LLMs) Meditron, MedAlpaca, Mistral, and Llama-2 for their\nefficacy in interpreting medical guidelines saved in PDF format. As a specific\ntest scenario, we applied these models to the guidelines for hypertension in\nchildren and adolescents provided by the European Society of Cardiology (ESC).\nLeveraging Streamlit, a Python library, we developed a user-friendly medical\ndocument chatbot tool (MedDoc-Bot). This tool enables authorized users to\nupload PDF files and pose questions, generating interpretive responses from\nfour locally stored LLMs. A pediatric expert provides a benchmark for\nevaluation by formulating questions and responses extracted from the ESC\nguidelines. The expert rates the model-generated responses based on their\nfidelity and relevance. Additionally, we evaluated the METEOR and chrF metric\nscores to assess the similarity of model responses to reference answers. Our\nstudy found that Llama-2 and Mistral performed well in metrics evaluation.\nHowever, Llama-2 was slower when dealing with text and tabular data. In our\nhuman evaluation, we observed that responses created by Mistral, Meditron, and\nLlama-2 exhibited reasonable fidelity and relevance. This study provides\nvaluable insights into the strengths and limitations of LLMs for future\ndevelopments in medical document interpretation. Open-Source Code:\nhttps://github.com/yaseen28/MedDoc-Bot",
      "tldr_zh": "本研究评估了开源大型语言模型（LLMs）如 Meditron、MedAlpaca、Mistral 和 Llama-2 在解释欧洲心脏病学会（ESC）儿科高血压指南 PDF 文件方面的效能。研究团队开发了 MedDoc-Bot，一个基于 Streamlit 的聊天工具，允许用户上传 PDF 并提问，由本地存储的四个 LLMs 生成响应，并通过专家评估（如保真度和相关性）和指标（如 METEOR 和 chrF）进行比较。结果显示，Llama-2 和 Mistral 在指标表现上优异，但 Llama-2 处理文本和表格数据时速度较慢，而 Mistral、Meditron 和 Llama-2 的响应整体显示出合理的准确性和相关性。该研究为 LLMs 在医疗文档解释中的优势与局限提供了宝贵洞见，并提供了开源代码（https://github.com/yaseen28/MedDoc-Bot）。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "{copyright} 2024 IEEE. This work has been accepted for publication\n  and presentation at the 46th Annual International Conference of the IEEE\n  Engineering in Medicine and Biology Society, to be held in Orlando, Florida,\n  USA, July 15-19, 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.03359v1",
      "published_date": "2024-05-06 11:11:23 UTC",
      "updated_date": "2024-05-06 11:11:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:25:04.919772"
    },
    {
      "arxiv_id": "2405.05978v2",
      "title": "Addressing Unboundedness in Quadratically-Constrained Mixed-Integer Problems",
      "title_zh": "解决二次约束混合整数问题中的无界性",
      "authors": [
        "Guy Zepko",
        "Ofer M. Shir"
      ],
      "abstract": "Mixed-integer (MI) quadratic models subject to quadratic constraints, known\nas All-Quadratic MI Programs, constitute a challenging class of NP-complete\noptimization problems. The particular scenario of unbounded integers defines a\nsubclass that holds the distinction of being even undecidable [Jeroslow, 1973].\nThis complexity suggests a possible soft-spot for Mathematical Programming (MP)\ntechniques, which otherwise constitute a good choice to treat MI problems. We\nconsider the task of minimizing MI convex quadratic objective and constraint\nfunctions with unbounded decision variables. Given the theoretical weakness of\nwhite-box MP solvers to handle such models, we turn to black-box\nmeta-heuristics of the Evolution Strategies (ESs) family, and question their\ncapacity to solve this challenge. Through an empirical assessment of\nall-quadratic test-cases, across varying Hessian forms and condition numbers,\nwe compare the performance of the CPLEX solver to modern MI ESs, which handle\nconstraints by penalty. Our systematic investigation begins where the CPLEX\nsolver encounters difficulties (timeouts as the search-space dimensionality\nincreases, D>=30), and we report in detail on the D=64 case. Overall, the\nempirical observations confirm that black-box and white-box solvers can be\ncompetitive, where CPLEX is evidently outperformed on 13% of the cases. This\ntrend is flipped when unboundedness is amplified by a significant translation\nof the optima, leading to a totally inferior performance of CPLEX at 83% of the\ncases. We also conclude that conditioning and separability are not intuitive\nfactors in determining the hardness degree of this class of MI problems.",
      "tldr_zh": "本研究探讨了二次约束混合整数（Mixed-Integer, MI）优化问题，特别是无界整数变量导致的 undecidable 挑战，这些问题属于 NP-complete 类。作者比较了白盒求解器（如 CPLEX）和黑盒元启发式算法（如 Evolution Strategies, ESs，后者通过惩罚函数处理约束）的性能。实验评估显示，在高维搜索空间（D>=30）中，ESs 在13%情况下优于 CPLEX，而当无界性进一步放大时，CPLEX 在83%情况下表现更差。总体而言，该研究证明了黑盒和白盒求解器在处理此类问题时的竞争性，并指出条件数和可分离性并非直观难度因素。",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "math.OC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.05978v2",
      "published_date": "2024-05-06 10:54:55 UTC",
      "updated_date": "2024-10-15 09:44:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:25:16.382130"
    },
    {
      "arxiv_id": "2405.03732v3",
      "title": "Deep Learning-based Accelerated MR Cholangiopancreatography without Fully-sampled Data",
      "title_zh": "翻译失败",
      "authors": [
        "Jinho Kim",
        "Marcel Dominik Nickel",
        "Florian Knoll"
      ],
      "abstract": "The purpose of this study was to accelerate MR cholangiopancreatography\n(MRCP) acquisitions using deep learning-based (DL) reconstruction at 3T and\n0.55T. A total of 35 healthy volunteers underwent conventional two-fold\naccelerated MRCP scans at field strengths of 3T and 0.55T. We trained DL\nreconstructions using two different training strategies, supervised (SV) and\nself-supervised (SSV), with retrospectively six-fold undersampled data obtained\nat 3T. We then evaluated the DL reconstructions against standard techniques,\nparallel imaging (PI) and compressed sensing (CS), focusing on peak\nsignal-to-noise ratio (PSNR) and structural similarity (SSIM) as metrics. We\nalso tested DL reconstructions with prospectively accelerated acquisitions and\nevaluated their robustness when changing fields strengths from 3T to 0.55T. DL\nreconstructions demonstrated a reduction in average acquisition time from\n599/542 to 255/180 seconds for MRCP at 3T/0.55T. In both retrospective and\nprospective undersampling, PSNR and SSIM of DL reconstructions were higher than\nthose of PI and CS. At the same time, DL reconstructions preserved the image\nquality of undersampled data, including sharpness and the visibility of\nhepatobiliary ducts. In addition, both DL approaches produced high-quality\nreconstructions at 0.55T. In summary, DL reconstructions trained for highly\naccelerated MRCP enabled a reduction in acquisition time by a factor of 2.4/3.0\nat 3T/0.55T while maintaining the image quality of conventional acquisitions.",
      "tldr_zh": "本研究提出了一种基于深度学习（DL）的重建方法，用于加速 MR 胆管胰管造影（MRCP）扫描，而无需完全采样数据，针对 3T 和 0.55T 磁场强度。研究采用监督学习（SV）和自监督学习（SSV）策略，使用 3T 的六倍回顾性欠采样数据训练模型，并与平行成像（PI）和压缩感知（CS）技术比较。结果显示，DL 重建将采集时间从 599/542 秒减少到 255/180 秒（在 3T/0.55T），并在 PSNR 和 SSIM 指标上表现出色，同时保持图像清晰度和肝胆管可见性。总之，该方法实现了 2.4/3.0 倍的采集时间减少，同时维持了传统扫描的图像质量，并在不同磁场强度下表现出鲁棒性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "19 pages, 4 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2405.03732v3",
      "published_date": "2024-05-06 10:53:13 UTC",
      "updated_date": "2025-01-07 15:46:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:25:29.755887"
    },
    {
      "arxiv_id": "2405.03341v3",
      "title": "Enhancing Q-Learning with Large Language Model Heuristics",
      "title_zh": "利用大语言模型启发式增强 Q-Learning",
      "authors": [
        "Xiefeng Wu"
      ],
      "abstract": "Q-learning excels in learning from feedback within sequential decision-making\ntasks but often requires extensive sampling to achieve significant\nimprovements. While reward shaping can enhance learning efficiency,\nnon-potential-based methods introduce biases that affect performance, and\npotential-based reward shaping, though unbiased, lacks the ability to provide\nheuristics for state-action pairs, limiting its effectiveness in complex\nenvironments. Large language models (LLMs) can achieve zero-shot learning for\nsimpler tasks, but they suffer from low inference speeds and occasional\nhallucinations. To address these challenges, we propose \\textbf{LLM-guided\nQ-learning}, a framework that leverages LLMs as heuristics to aid in learning\nthe Q-function for reinforcement learning. Our theoretical analysis\ndemonstrates that this approach adapts to hallucinations, improves sample\nefficiency, and avoids biasing final performance. Experimental results show\nthat our algorithm is general, robust, and capable of preventing ineffective\nexploration.",
      "tldr_zh": "这篇论文提出了一种名为 LLM-guided Q-learning 的框架，利用 Large Language Models (LLMs) 作为启发式指导来提升 Q-learning 在顺序决策任务中的效率，解决其需要大量采样的问题。框架通过 LLMs 提供状态-动作对的启发式，避免了传统 reward shaping 方法可能引入的偏差，同时理论分析证明它能适应 hallucinations（幻觉），提高样本效率且不影响最终性能。实验结果表明，该算法在复杂环境中表现出通用性和鲁棒性，能够有效防止无效探索。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Note:Arxiv,Draft",
      "pdf_url": "http://arxiv.org/pdf/2405.03341v3",
      "published_date": "2024-05-06 10:42:28 UTC",
      "updated_date": "2024-05-24 06:32:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:25:39.605109"
    },
    {
      "arxiv_id": "2405.03340v1",
      "title": "Functional Equivalence with NARS",
      "title_zh": "NARS 中的功能等价",
      "authors": [
        "Robert Johansson",
        "Patrick Hammer",
        "Tony Lofthouse"
      ],
      "abstract": "This study explores the concept of functional equivalence within the\nframework of the Non-Axiomatic Reasoning System (NARS), specifically through\nOpenNARS for Applications (ONA). Functional equivalence allows organisms to\ncategorize and respond to varied stimuli based on their utility rather than\nperceptual similarity, thus enhancing cognitive efficiency and adaptability. In\nthis study, ONA was modified to allow the derivation of functional equivalence.\nThis paper provides practical examples of the capability of ONA to apply\nlearned knowledge across different functional situations, demonstrating its\nutility in complex problem-solving and decision-making. An extended example is\nincluded, where training of ONA aimed to learn basic human-like language\nabilities, using a systematic procedure in relating spoken words, objects and\nwritten words. The research carried out as part of this study extends the\nunderstanding of functional equivalence in AGI systems, and argues for its\nnecessity for level of flexibility in learning and adapting necessary for\nhuman-level AGI.",
      "tldr_zh": "这篇论文探讨了功能等价 (functional equivalence) 在 Non-Axiomatic Reasoning System (NARS) 框架下的应用，特别是通过 OpenNARS for Applications (ONA) 的修改，使系统能够根据效用而非感知相似性对刺激进行分类和响应，从而提升认知效率和适应性。研究提供了实际例子，包括训练 ONA 学习基本类人语言能力，将口头词语、物体和书面词语相关联，以展示其在复杂问题解决和决策中的实用性。最终，该研究扩展了对功能等价在 AGI 系统中的理解，并强调其对实现人类级灵活学习和适应性的必要性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.03340v1",
      "published_date": "2024-05-06 10:40:34 UTC",
      "updated_date": "2024-05-06 10:40:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:25:52.779824"
    },
    {
      "arxiv_id": "2405.03328v1",
      "title": "Enhancing Spatiotemporal Disease Progression Models via Latent Diffusion and Prior Knowledge",
      "title_zh": "通过潜在扩散和先验知识增强时空疾病进展模型",
      "authors": [
        "Lemuel Puglisi",
        "Daniel C. Alexander",
        "Daniele Ravì"
      ],
      "abstract": "In this work, we introduce Brain Latent Progression (BrLP), a novel\nspatiotemporal disease progression model based on latent diffusion. BrLP is\ndesigned to predict the evolution of diseases at the individual level on 3D\nbrain MRIs. Existing deep generative models developed for this task are\nprimarily data-driven and face challenges in learning disease progressions.\nBrLP addresses these challenges by incorporating prior knowledge from disease\nmodels to enhance the accuracy of predictions. To implement this, we propose to\nintegrate an auxiliary model that infers volumetric changes in various brain\nregions. Additionally, we introduce Latent Average Stabilization (LAS), a novel\ntechnique to improve spatiotemporal consistency of the predicted progression.\nBrLP is trained and evaluated on a large dataset comprising 11,730 T1-weighted\nbrain MRIs from 2,805 subjects, collected from three publicly available,\nlongitudinal Alzheimer's Disease (AD) studies. In our experiments, we compare\nthe MRI scans generated by BrLP with the actual follow-up MRIs available from\nthe subjects, in both cross-sectional and longitudinal settings. BrLP\ndemonstrates significant improvements over existing methods, with an increase\nof 22% in volumetric accuracy across AD-related brain regions and 43% in image\nsimilarity to the ground-truth scans. The ability of BrLP to generate\nconditioned 3D scans at the subject level, along with the novelty of\nintegrating prior knowledge to enhance accuracy, represents a significant\nadvancement in disease progression modeling, opening new avenues for precision\nmedicine. The code of BrLP is available at the following link:\nhttps://github.com/LemuelPuglisi/BrLP.",
      "tldr_zh": "本研究引入了Brain Latent Progression (BrLP)，一种基于latent diffusion的时空疾病进展模型，用于预测个体水平的3D brain MRIs疾病演变，从而解决现有数据驱动模型在学习疾病进展方面的挑战。BrLP 通过整合prior knowledge，包括一个辅助模型来推断脑区体积变化，以及新颖的Latent Average Stabilization (LAS)技术，以提升预测的时空一致性和准确性。该模型在包含11,730个T1-weighted brain MRIs的Alzheimer's Disease (AD)数据集上进行训练和评估，结果显示体积准确率较现有方法提高22%，图像相似性提高43%。整体而言，BrLP 的创新性在于生成条件化的3D扫描并增强预测精度，为精确医学领域提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.03328v1",
      "published_date": "2024-05-06 10:07:16 UTC",
      "updated_date": "2024-05-06 10:07:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:26:03.720884"
    },
    {
      "arxiv_id": "2405.03320v1",
      "title": "Denoising of Geodetic Time Series Using Spatiotemporal Graph Neural Networks: Application to Slow Slip Event Extraction",
      "title_zh": "翻译失败",
      "authors": [
        "Giuseppe Costantino",
        "Sophie Giffard-Roisin",
        "Mauro Dalla Mura",
        "Anne Socquet"
      ],
      "abstract": "Geospatial data has been transformative for the monitoring of the Earth, yet,\nas in the case of (geo)physical monitoring, the measurements can have variable\nspatial and temporal sampling and may be associated with a significant level of\nperturbations degrading the signal quality. Denoising geospatial data is,\ntherefore, essential, yet often challenging because the observations may\ncomprise noise coming from different origins, including both environmental\nsignals and instrumental artifacts, which are spatially and temporally\ncorrelated, thus hard to disentangle. This study addresses the denoising of\nmultivariate time series acquired by irregularly distributed networks of\nsensors, requiring specific methods to handle the spatiotemporal correlation of\nthe noise and the signal of interest. Specifically, our method focuses on the\ndenoising of geodetic position time series, used to monitor ground displacement\nworldwide with centimeter- to-millimeter precision. Among the signals affecting\nGNSS data, slow slip events (SSEs) are of interest to seismologists. These are\ntransients of deformation that are weakly emerging compared to other signals.\nHere, we design SSEdenoiser, a multi-station spatiotemporal graph-based\nattentive denoiser that learns latent characteristics of GNSS noise to reveal\nSSE-related displacement with sub-millimeter precision. It is based on the key\ncombination of graph recurrent networks and spatiotemporal Transformers. The\nproposed method is applied to the Cascadia subduction zone, where SSEs occur\nalong with bursts of tectonic tremors, a seismic rumbling identified from\nindependent seismic recordings. The extracted events match the spatiotemporal\nevolution of tremors. This good space-time correlation of the denoised GNSS\nsignals with the tremors validates the proposed denoising procedure.",
      "tldr_zh": "本文提出SSEdenoiser，一种基于Spatiotemporal Graph Neural Networks的多站时空注意力去噪方法，用于处理GNSS地心导航卫星系统数据中的噪声，这些噪声源于环境信号和仪器伪影，并具有空间和时间相关性。该方法结合Graph Recurrent Networks和Spatiotemporal Transformers，学习GNSS噪声的潜在特征，以亚毫米精度提取慢滑事件(Slow Slip Events, SSEs)。在Cascadia subduction zone的应用中，提取的事件与地震颤动的时空演化高度一致，验证了该去噪方法的有效性和准确性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP",
        "physics.geo-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.03320v1",
      "published_date": "2024-05-06 09:55:11 UTC",
      "updated_date": "2024-05-06 09:55:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:26:16.903268"
    },
    {
      "arxiv_id": "2405.03305v1",
      "title": "Artificial Intelligence in the Autonomous Navigation of Endovascular Interventions: A Systematic Review",
      "title_zh": "翻译失败",
      "authors": [
        "Harry Robertshaw",
        "Lennart Karstensen",
        "Benjamin Jackson",
        "Hadi Sadati",
        "Kawal Rhode",
        "Sebastien Ourselin",
        "Alejandro Granados",
        "Thomas C Booth"
      ],
      "abstract": "Purpose: Autonomous navigation of devices in endovascular interventions can\ndecrease operation times, improve decision-making during surgery, and reduce\noperator radiation exposure while increasing access to treatment. This\nsystematic review explores recent literature to assess the impact, challenges,\nand opportunities artificial intelligence (AI) has for the autonomous\nendovascular intervention navigation.\n  Methods: PubMed and IEEEXplore databases were queried. Eligibility criteria\nincluded studies investigating the use of AI in enabling the autonomous\nnavigation of catheters/guidewires in endovascular interventions. Following\nPRISMA, articles were assessed using QUADAS-2. PROSPERO: CRD42023392259.\n  Results: Among 462 studies, fourteen met inclusion criteria. Reinforcement\nlearning (9/14, 64%) and learning from demonstration (7/14, 50%) were used as\ndata-driven models for autonomous navigation. Studies predominantly utilised\nphysical phantoms (10/14, 71%) and in silico (4/14, 29%) models. Experiments\nwithin or around the blood vessels of the heart were reported by the majority\nof studies (10/14, 71%), while simple non-anatomical vessel platforms were used\nin three studies (3/14, 21%), and the porcine liver venous system in one study.\nWe observed that risk of bias and poor generalisability were present across\nstudies. No procedures were performed on patients in any of the studies\nreviewed. Studies lacked patient selection criteria, reference standards, and\nreproducibility, resulting in low clinical evidence levels.\n  Conclusions: AI's potential in autonomous endovascular navigation is\npromising, but in an experimental proof-of-concept stage, with a technology\nreadiness level of 3. We highlight that reference standards with\nwell-identified performance metrics are crucial to allow for comparisons of\ndata-driven algorithms proposed in the years to come.",
      "tldr_zh": "这篇系统综述探讨了人工智能（AI）在血管内介入手术自主导航中的影响、挑战和机会，旨在减少手术时间、提升决策并降低操作者辐射暴露。研究者通过查询 PubMed 和 IEEEXplore 数据库，并采用 PRISMA 指南和 QUADAS-2 工具评估了 462 篇文献，最终筛选出 14 篇相关研究。结果显示，强化学习（Reinforcement Learning，9/14）和学习从演示（Learning from Demonstration，7/14）是主要的数据驱动模型，实验多在物理模型（10/14）或模拟环境中进行，且焦点集中在心脏血管，但存在偏倚风险和泛化问题。结论认为，AI 在自主导航方面潜力巨大，但仍处于实验证明概念阶段，技术准备水平（Technology Readiness Level）为 3，需要建立标准性能指标以促进未来算法比较。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "Abstract shortened for arXiv character limit",
      "pdf_url": "http://arxiv.org/pdf/2405.03305v1",
      "published_date": "2024-05-06 09:28:30 UTC",
      "updated_date": "2024-05-06 09:28:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:26:28.531021"
    },
    {
      "arxiv_id": "2405.03296v1",
      "title": "Coefficient Decomposition for Spectral Graph Convolution",
      "title_zh": "谱图卷积的系数分解",
      "authors": [
        "Feng Huang",
        "Wen Zhang"
      ],
      "abstract": "Spectral graph convolutional network (SGCN) is a kind of graph neural\nnetworks (GNN) based on graph signal filters, and has shown compelling\nexpressivity for modeling graph-structured data. Most SGCNs adopt polynomial\nfilters and learn the coefficients from the training data. Many of them focus\non which polynomial basis leads to optimal expressive power and models'\narchitecture is little discussed. In this paper, we propose a general form in\nterms of spectral graph convolution, where the coefficients of polynomial basis\nare stored in a third-order tensor. Then, we show that the convolution block in\nexisting SGCNs can be derived by performing a certain coefficient decomposition\noperation on the coefficient tensor. Based on the generalized view, we develop\nnovel spectral graph convolutions CoDeSGC-CP and -Tucker by tensor\ndecomposition CP and Tucker on the coefficient tensor. Extensive experimental\nresults demonstrate that the proposed convolutions achieve favorable\nperformance improvements.",
      "tldr_zh": "这篇论文针对 Spectral Graph Convolutional Network (SGCN) 提出了一种新的系数分解方法，以提升其在图结构数据建模中的表现。作者将多项式滤波器的系数存储在三阶张量中，并展示了现有 SGCN 的卷积块可以通过对该张量进行特定分解操作来推导。基于此，他们开发了新型谱图卷积 CoDeSGC-CP 和 CoDeSGC-Tucker，利用 CP 和 Tucker 张量分解来优化模型。实验结果表明，这些新方法在多种任务上实现了显著的性能提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.03296v1",
      "published_date": "2024-05-06 09:17:23 UTC",
      "updated_date": "2024-05-06 09:17:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:26:42.085781"
    },
    {
      "arxiv_id": "2405.03728v2",
      "title": "Pretrained Optimization Model for Zero-Shot Black Box Optimization",
      "title_zh": "零样本黑箱优化的预训练优化模型",
      "authors": [
        "Xiaobin Li",
        "Kai Wu",
        "Yujian Betterest Li",
        "Xiaoyu Zhang",
        "Handing Wang",
        "Jing Liu"
      ],
      "abstract": "Zero-shot optimization involves optimizing a target task that was not seen\nduring training, aiming to provide the optimal solution without or with minimal\nadjustments to the optimizer. It is crucial to ensure reliable and robust\nperformance in various applications. Current optimizers often struggle with\nzero-shot optimization and require intricate hyperparameter tuning to adapt to\nnew tasks. To address this, we propose a Pretrained Optimization Model (POM)\nthat leverages knowledge gained from optimizing diverse tasks, offering\nefficient solutions to zero-shot optimization through direct application or\nfine-tuning with few-shot samples. Evaluation on the BBOB benchmark and two\nrobot control tasks demonstrates that POM outperforms state-of-the-art\nblack-box optimization methods, especially for high-dimensional tasks.\nFine-tuning POM with a small number of samples and budget yields significant\nperformance improvements. Moreover, POM demonstrates robust generalization\nacross diverse task distributions, dimensions, population sizes, and\noptimization horizons. For code implementation, see\nhttps://github.com/ninja-wm/POM/.",
      "tldr_zh": "本文提出Pretrained Optimization Model (POM)，一种预训练优化模型，用于零-shot黑箱优化，能够利用从多种任务中获得的知识，直接应用于新任务或通过少量样本微调以获得高效解。POM解决了传统优化器在零-shot场景下适应性差和超参数调整复杂的问题，在BBOB基准和两个机器人控制任务上优于现有方法，尤其在高维任务中提升显著。实验结果显示，POM在不同任务分布、维度、种群大小和优化时限上表现出色泛化能力，为可靠的优化应用奠定了基础。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.03728v2",
      "published_date": "2024-05-06 09:11:49 UTC",
      "updated_date": "2024-12-06 08:55:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:26:53.123465"
    },
    {
      "arxiv_id": "2406.06478v1",
      "title": "High-precision surgical navigation using speckle structured light-based thoracoabdominal puncture robot",
      "title_zh": "翻译失败",
      "authors": [
        "Zezhao Guo",
        "Yanzhong Guo",
        "Zhanfang Zhao"
      ],
      "abstract": "Abstract\n  Background During percutaneous puncture robotic surgical navigation, the\nneedle insertion point is positioned on the patient's chest and abdomen body\nsurface. By locating any point on the soft skin tissue, it is difficult to\napply the traditional reflective ball tracking method. The patient's chest and\nabdomen body surface has fluctuations in breathing and appears irregular. The\nchest and abdomen are regular and smooth, lacking obvious features, and it is\nchallenging to locate the needle insertion point on the body surface. Methods\nThis paper designs and experiments a method that is different from previous\nreflective ball optical markers or magnetic positioning surgical navigation and\ntracking methods. It is based on a speckle structured light camera to identify\nthe patient's body surface and fit it into a hollow ring with a diameter of\n24mm. Results Experimental results show that this method of the system can be\nsmall, flexible, and high-precision positioning of any body surface point at\nmultiple angles, achieving a positioning accuracy of 0.033-0.563mm and an image\nof 7-30 frames/s. Conclusions The positioning recognition ring material used in\nthis method can be well imaged under CT, so the optical positioning of the body\nsurface and the in vivo imaging positioning under CT can be combined to form a\nunified patient's internal and external positioning world coordinates to\nachieve internal and external registration. Positioning integration. The system\nsenses motion with six degrees of freedom, up and down, front and back, left\nand right, and all rotations, with sub-millimeter accuracy, and has broad\napplication prospects in future puncture surgeries.",
      "tldr_zh": "本研究针对经皮穿刺机器人手术导航中，传统反射球或磁定位方法难以处理患者胸腹部软组织波动和特征缺乏的问题，提出了一种基于 speckle structured light 相机的创新方法。该方法通过识别体表并拟合成直径 24mm 的空心环，实现多角度高精度定位。实验结果显示，系统定位精度达 0.033-0.563mm，帧率为 7-30 帧/s，并支持六自由度运动感知。最终，该系统可将体表光学定位与 CT 成像结合，形成统一的内外坐标系，具有广阔的穿刺手术应用前景。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "17pages,7figures",
      "pdf_url": "http://arxiv.org/pdf/2406.06478v1",
      "published_date": "2024-05-06 08:59:51 UTC",
      "updated_date": "2024-05-06 08:59:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:27:05.396042"
    },
    {
      "arxiv_id": "2407.00020v1",
      "title": "Visual Language Model based Cross-modal Semantic Communication Systems",
      "title_zh": "基于视觉语言模型的跨模态语义通信系统",
      "authors": [
        "Feibo Jiang",
        "Chuanguo Tang",
        "Li Dong",
        "Kezhi Wang",
        "Kun Yang",
        "Cunhua Pan"
      ],
      "abstract": "Semantic Communication (SC) has emerged as a novel communication paradigm in\nrecent years, successfully transcending the Shannon physical capacity limits\nthrough innovative semantic transmission concepts. Nevertheless, extant Image\nSemantic Communication (ISC) systems face several challenges in dynamic\nenvironments, including low semantic density, catastrophic forgetting, and\nuncertain Signal-to-Noise Ratio (SNR). To address these challenges, we propose\na novel Vision-Language Model-based Cross-modal Semantic Communication\n(VLM-CSC) system. The VLM-CSC comprises three novel components: (1) Cross-modal\nKnowledge Base (CKB) is used to extract high-density textual semantics from the\nsemantically sparse image at the transmitter and reconstruct the original image\nbased on textual semantics at the receiver. The transmission of high-density\nsemantics contributes to alleviating bandwidth pressure. (2) Memory-assisted\nEncoder and Decoder (MED) employ a hybrid long/short-term memory mechanism,\nenabling the semantic encoder and decoder to overcome catastrophic forgetting\nin dynamic environments when there is a drift in the distribution of semantic\nfeatures. (3) Noise Attention Module (NAM) employs attention mechanisms to\nadaptively adjust the semantic coding and the channel coding based on SNR,\nensuring the robustness of the CSC system. The experimental simulations\nvalidate the effectiveness, adaptability, and robustness of the CSC system.",
      "tldr_zh": "该研究提出了一种基于视觉语言模型(Vision-Language Model)的跨模态语义通信系统(VLM-CSC)，旨在解决现有图像语义通信(ISC)系统在动态环境中的低语义密度、灾难性遗忘和不确定信噪比(SNR)等问题。该系统包括三个创新组件：Cross-modal Knowledge Base (CKB)用于从图像提取高密度文本语义以减轻带宽压力，Memory-assisted Encoder and Decoder (MED)采用混合长/短时记忆机制来克服语义特征分布漂移，以及Noise Attention Module (NAM)通过注意力机制根据SNR动态调整编码以确保系统鲁棒性。实验模拟验证了VLM-CSC的有效性、适应性和鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.IT",
        "cs.LG",
        "math.IT"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.00020v1",
      "published_date": "2024-05-06 08:59:16 UTC",
      "updated_date": "2024-05-06 08:59:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:27:18.909760"
    },
    {
      "arxiv_id": "2405.03280v2",
      "title": "Animate Your Thoughts: Decoupled Reconstruction of Dynamic Natural Vision from Slow Brain Activity",
      "title_zh": "翻译失败",
      "authors": [
        "Yizhuo Lu",
        "Changde Du",
        "Chong Wang",
        "Xuanliu Zhu",
        "Liuyun Jiang",
        "Xujin Li",
        "Huiguang He"
      ],
      "abstract": "Reconstructing human dynamic vision from brain activity is a challenging task\nwith great scientific significance. Although prior video reconstruction methods\nhave made substantial progress, they still suffer from several limitations,\nincluding: (1) difficulty in simultaneously reconciling semantic (e.g.\ncategorical descriptions), structure (e.g. size and color), and consistent\nmotion information (e.g. order of frames); (2) low temporal resolution of fMRI,\nwhich poses a challenge in decoding multiple frames of video dynamics from a\nsingle fMRI frame; (3) reliance on video generation models, which introduces\nambiguity regarding whether the dynamics observed in the reconstructed videos\nare genuinely derived from fMRI data or are hallucinations from generative\nmodel. To overcome these limitations, we propose a two-stage model named\nMind-Animator. During the fMRI-to-feature stage, we decouple semantic,\nstructure, and motion features from fMRI. Specifically, we employ\nfMRI-vision-language tri-modal contrastive learning to decode semantic feature\nfrom fMRI and design a sparse causal attention mechanism for decoding\nmulti-frame video motion features through a next-frame-prediction task. In the\nfeature-to-video stage, these features are integrated into videos using an\ninflated Stable Diffusion, effectively eliminating external video data\ninterference. Extensive experiments on multiple video-fMRI datasets demonstrate\nthat our model achieves state-of-the-art performance. Comprehensive\nvisualization analyses further elucidate the interpretability of our model from\na neurobiological perspective. Project page:\nhttps://mind-animator-design.github.io/.",
      "tldr_zh": "本研究提出了一种名为 Mind-Animator 的两阶段模型，用于从慢速脑活动（fMRI）重建动态自然视觉，克服了现有方法在语义、结构和运动信息一致性方面的局限性。第一阶段（fMRI-to-feature）通过 fMRI-vision-language tri-modal contrastive learning 解码语义特征，并采用 sparse causal attention mechanism 进行多帧视频运动特征的预测。第二阶段（feature-to-video）将这些解耦特征整合进 inflated Stable Diffusion 生成视频，从而减少外部数据干扰。实验在多个视频-fMRI 数据集上实现了 state-of-the-art 性能，并通过可视化分析从神经生物学角度证明了模型的可解释性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.03280v2",
      "published_date": "2024-05-06 08:56:41 UTC",
      "updated_date": "2025-02-19 05:02:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:27:30.874215"
    },
    {
      "arxiv_id": "2405.03262v2",
      "title": "End-to-End Reinforcement Learning of Curative Curtailment with Partial Measurement Availability",
      "title_zh": "翻译失败",
      "authors": [
        "Hinrikus Wolf",
        "Luis Böttcher",
        "Sarra Bouchkati",
        "Philipp Lutat",
        "Jens Breitung",
        "Bastian Jung",
        "Tina Möllemann",
        "Viktor Todosijević",
        "Jan Schiefelbein-Lach",
        "Oliver Pohl",
        "Andreas Ulbig",
        "Martin Grohe"
      ],
      "abstract": "In the course of the energy transition, the expansion of generation and\nconsumption will change, and many of these technologies, such as PV systems,\nelectric cars and heat pumps, will influence the power flow, especially in the\ndistribution grids. Scalable methods that can make decisions for each grid\nconnection are needed to enable congestion-free grid operation in the\ndistribution grids. This paper presents a novel end-to-end approach to\nresolving congestion in distribution grids with deep reinforcement learning.\nOur architecture learns to curtail power and set appropriate reactive power to\ndetermine a non-congested and, thus, feasible grid state. State-of-the-art\nmethods such as the optimal power flow (OPF) demand high computational costs\nand detailed measurements of every bus in a grid. In contrast, the presented\nmethod enables decisions under sparse information with just some buses\nobservable in the grid. Distribution grids are generally not yet fully\ndigitized and observable, so this method can be used for decision-making on the\nmajority of low-voltage grids. On a real low-voltage grid the approach resolves\n100\\% of violations in the voltage band and 98.8\\% of asset overloads. The\nresults show that decisions can also be made on real grids that guarantee\nsufficient quality for congestion-free grid operation.",
      "tldr_zh": "该论文提出了一种端到-End Reinforcement Learning方法，用于在Partial Measurement Availability条件下实现Curative Curtailment，以解决能源转型中配电网拥塞问题。该方法通过深度强化学习学习功率削减和无功功率设置，仅依赖部分总线的观测数据，避免了传统Optimal Power Flow (OPF)方法的高计算成本和全面测量需求。在真实低压电网实验中，该方法成功处理了100% 的电压带违规和98.8% 的资产过载，证明了其在非完全数字化电网中的可扩展性和实用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.03262v2",
      "published_date": "2024-05-06 08:34:15 UTC",
      "updated_date": "2024-06-10 11:04:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:27:41.803065"
    },
    {
      "arxiv_id": "2405.03251v1",
      "title": "Exploring the Frontiers of Softmax: Provable Optimization, Applications in Diffusion Model, and Beyond",
      "title_zh": "探索 Softmax 的前沿：可证明的优化、在扩散模型中的应用，以及更多",
      "authors": [
        "Jiuxiang Gu",
        "Chenyang Li",
        "Yingyu Liang",
        "Zhenmei Shi",
        "Zhao Song"
      ],
      "abstract": "The softmax activation function plays a crucial role in the success of large\nlanguage models (LLMs), particularly in the self-attention mechanism of the\nwidely adopted Transformer architecture. However, the underlying learning\ndynamics that contribute to the effectiveness of softmax remain largely\nunexplored. As a step towards better understanding, this paper provides a\ntheoretical study of the optimization and generalization properties of\ntwo-layer softmax neural networks, providing theoretical insights into their\nsuperior performance as other activation functions, such as ReLU and\nexponential. Leveraging the Neural Tangent Kernel (NTK) framework, our analysis\nreveals that the normalization effect of the softmax function leads to a good\nperturbation property of the induced NTK matrix, resulting in a good convex\nregion of the loss landscape. Consequently, softmax neural networks can learn\nthe target function in the over-parametrization regime. To demonstrate the\nbroad applicability of our theoretical findings, we apply them to the task of\nlearning score estimation functions in diffusion models, a promising approach\nfor generative modeling. Our analysis shows that gradient-based algorithms can\nlearn the score function with a provable accuracy. Our work provides a deeper\nunderstanding of the effectiveness of softmax neural networks and their\npotential in various domains, paving the way for further advancements in\nnatural language processing and beyond.",
      "tldr_zh": "本论文探讨了 Softmax 激活函数在大型语言模型(LLMs)中的优化和泛化特性，通过理论分析比较其与 ReLU 和 exponential 等函数的性能优势。利用 Neural Tangent Kernel (NTK) 框架，研究发现 Softmax 的归一化效果改善了 NTK 矩阵的扰动属性，形成良好的凸损失景观，从而使两层 Softmax 神经网络在过参数化条件下能有效学习目标函数。论文进一步应用于 diffusion models 中的评分估计函数学习，证明基于梯度的算法可实现可证明的准确性，为自然语言处理和其他领域的发展提供新洞见。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "53 pages",
      "pdf_url": "http://arxiv.org/pdf/2405.03251v1",
      "published_date": "2024-05-06 08:15:29 UTC",
      "updated_date": "2024-05-06 08:15:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:27:53.486662"
    },
    {
      "arxiv_id": "2405.03727v3",
      "title": "Large Language Models Synergize with Automated Machine Learning",
      "title_zh": "大型语言模型与自动化机器学习的协同作用",
      "authors": [
        "Jinglue Xu",
        "Jialong Li",
        "Zhen Liu",
        "Nagar Anthel Venkatesh Suryanarayanan",
        "Guoyuan Zhou",
        "Jia Guo",
        "Hitoshi Iba",
        "Kenji Tei"
      ],
      "abstract": "Recently, program synthesis driven by large language models (LLMs) has become\nincreasingly popular. However, program synthesis for machine learning (ML)\ntasks still poses significant challenges. This paper explores a novel form of\nprogram synthesis, targeting ML programs, by combining LLMs and automated\nmachine learning (autoML). Specifically, our goal is to fully automate the\ngeneration and optimization of the code of the entire ML workflow, from data\npreparation to modeling and post-processing, utilizing only textual\ndescriptions of the ML tasks. To manage the length and diversity of ML\nprograms, we propose to break each ML program into smaller, manageable parts.\nEach part is generated separately by the LLM, with careful consideration of\ntheir compatibilities. To ensure compatibilities, we design a testing technique\nfor ML programs. Unlike traditional program synthesis, which typically relies\non binary evaluations (i.e., correct or incorrect), evaluating ML programs\nnecessitates more than just binary judgments. Our approach automates the\nnumerical evaluation and optimization of these programs, selecting the best\ncandidates through autoML techniques. In experiments across various ML tasks,\nour method outperforms existing methods in 10 out of 12 tasks for generating ML\nprograms. In addition, autoML significantly improves the performance of the\ngenerated ML programs. In experiments, given the textual task description, our\nmethod, Text-to-ML, generates the complete and optimized ML program in a fully\nautonomous process. The implementation of our method is available at\nhttps://github.com/JLX0/llm-automl.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 与自动机器学习 (AutoML) 的结合，用于程序合成以自动化机器学习 (ML) 任务。方法包括将 ML 程序分解成小部分，由 LLMs 生成，并通过测试技术确保各部分的兼容性，同时利用 AutoML 进行数值评估和优化，从而从文本描述自动生成完整的 ML 工作流。实验结果显示，该方法在 12 个 ML 任务中胜出 10 个，并显著提升了生成的程序性能；开源实现 Text-to-ML 进一步推动了这一自主过程。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG",
        "cs.PL"
      ],
      "primary_category": "cs.SE",
      "comment": "published at TMLR",
      "pdf_url": "http://arxiv.org/pdf/2405.03727v3",
      "published_date": "2024-05-06 08:09:46 UTC",
      "updated_date": "2024-09-09 15:04:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:28:05.786115"
    },
    {
      "arxiv_id": "2405.03248v1",
      "title": "Communication-Efficient Federated Learning with Adaptive Compression under Dynamic Bandwidth",
      "title_zh": "在动态带宽下具有自适应压缩的通信高效联邦学习",
      "authors": [
        "Ying Zhuansun",
        "Dandan Li",
        "Xiaohong Huang",
        "Caijun Sun"
      ],
      "abstract": "Federated learning can train models without directly providing local data to\nthe server. However, the frequent updating of the local model brings the\nproblem of large communication overhead. Recently, scholars have achieved the\ncommunication efficiency of federated learning mainly by model compression. But\nthey ignore two problems: 1) network state of each client changes dynamically;\n2) network state among clients is not the same. The clients with poor bandwidth\nupdate local model slowly, which leads to low efficiency. To address this\nchallenge, we propose a communication-efficient federated learning algorithm\nwith adaptive compression under dynamic bandwidth (called AdapComFL).\nConcretely, each client performs bandwidth awareness and bandwidth prediction.\nThen, each client adaptively compresses its local model via the improved sketch\nmechanism based on his predicted bandwidth. Further, the server aggregates\nsketched models with different sizes received. To verify the effectiveness of\nthe proposed method, the experiments are based on real bandwidth data which are\ncollected from the network topology we build, and benchmark datasets which are\nobtained from open repositories. We show the performance of AdapComFL\nalgorithm, and compare it with existing algorithms. The experimental results\nshow that our AdapComFL achieves more efficient communication as well as\ncompetitive accuracy compared to existing algorithms.",
      "tldr_zh": "本论文针对联邦学习（Federated Learning）中频繁模型更新导致的通信开销问题，提出了一种适应性压缩算法AdapComFL，以应对客户端带宽动态变化和差异。算法通过客户端进行带宽感知和预测，并基于改进的sketch机制对本地模型进行适应性压缩，服务器则聚合不同大小的压缩模型。实验基于真实带宽数据和基准数据集表明，AdapComFL实现了更高效的通信，同时保持了与现有算法相当的准确率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.03248v1",
      "published_date": "2024-05-06 08:00:43 UTC",
      "updated_date": "2024-05-06 08:00:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:28:17.596994"
    },
    {
      "arxiv_id": "2407.10312v1",
      "title": "Effective Design Verification -- Constrained Random with Python and Cocotb",
      "title_zh": "翻译失败",
      "authors": [
        "Deepak Narayan Gadde",
        "Suruchi Kumari",
        "Aman Kumar"
      ],
      "abstract": "Being the most widely used language across the world due to its simplicity\nand with 35 keywords (v3.7), Python attracts both hardware and software\nengineers. Python-based verification environment leverages open-source\nlibraries such as cocotb and cocotb-coverage that enables interfacing the\ntesbenches with any available simulator and facilitating constrained\nrandomization, coverage respectively. These libraries significantly ease the\ndevelopment of testbenches and have the potential to reduce the setup cost. The\ngoal of this paper is to assess the effectiveness of a Python-Cocotb\nverification setup with design IPs and compare its features and performance\nmetrics with the current de-facto hardware verification language i.e.,\nSystemVerilog.",
      "tldr_zh": "该论文评估了使用 Python 和 Cocotb 进行硬件设计验证的有效性，特别是通过 constrained random 和 coverage 功能。研究利用开源库如 cocotb 和 cocotb-coverage 来简化 testbench 开发，并降低设置成本，与传统硬件验证语言 SystemVerilog 进行特征和性能比较。结果显示，Python-based 验证环境在易用性和效率上表现出色，有潜力成为更具吸引力的替代方案。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "Published in DVCon Europe 2023",
      "pdf_url": "http://arxiv.org/pdf/2407.10312v1",
      "published_date": "2024-05-06 07:58:16 UTC",
      "updated_date": "2024-05-06 07:58:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:28:27.797632"
    },
    {
      "arxiv_id": "2405.03239v3",
      "title": "Deep Learning for Detecting and Early Predicting Chronic Obstructive Pulmonary Disease from Spirogram Time Series",
      "title_zh": "翻译失败",
      "authors": [
        "Shuhao Mei",
        "Xin Li",
        "Yuxi Zhou",
        "Jiahao Xu",
        "Yong Zhang",
        "Yuxuan Wan",
        "Shan Cao",
        "Qinghao Zhao",
        "Shijia Geng",
        "Junqing Xie",
        "Shengyong Chen",
        "Shenda Hong"
      ],
      "abstract": "Chronic Obstructive Pulmonary Disease (COPD) is a chronic lung condition\ncharacterized by airflow obstruction. Current diagnostic methods primarily rely\non identifying prominent features in spirometry (Volume-Flow time series) to\ndetect COPD, but they are not adept at predicting future COPD risk based on\nsubtle data patterns. In this study, we introduce a novel deep learning-based\napproach, DeepSpiro, aimed at the early prediction of future COPD risk.\nDeepSpiro consists of four key components: SpiroSmoother for stabilizing the\nVolume-Flow curve, SpiroEncoder for capturing volume variability-pattern\nthrough key patches of varying lengths, SpiroExplainer for integrating\nheterogeneous data and explaining predictions through volume attention, and\nSpiroPredictor for predicting the disease risk of undiagnosed high-risk\npatients based on key patch concavity, with prediction horizons of 1, 2, 3, 4,\n5 years, or even longer. Evaluated on the UK Biobank dataset, DeepSpiro\nachieved an AUC of 0.8328 for COPD detection and demonstrated strong predictive\nperformance for future COPD risk (p-value < 0.001). In summary, DeepSpiro can\neffectively predicts the long-term progression of the COPD disease.",
      "tldr_zh": "本文提出了一种深度学习方法 DeepSpiro，用于从 Spirogram 时间序列中检测和早期预测 Chronic Obstructive Pulmonary Disease (COPD)，以解决传统方法无法基于微妙数据模式预测未来风险的问题。DeepSpiro 包括四个关键组件：SpiroSmoother 用于稳定 Volume-Flow 曲线、SpiroEncoder 通过不同长度的关键 patches 捕获体积变异性模式、SpiroExplainer 整合异构数据并通过体积注意力解释预测，以及 SpiroPredictor 基于关键 patches 的凹度预测未确诊高风险患者的疾病风险，覆盖 1 到 5 年或更长的时间跨度。在 UK Biobank 数据集上评估，该方法在 COPD 检测中达到 AUC 0.8328，并展示了显著的未来风险预测性能（p-value < 0.001），为早期干预提供有效工具。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.03239v3",
      "published_date": "2024-05-06 07:48:34 UTC",
      "updated_date": "2024-12-28 14:18:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:28:42.899011"
    },
    {
      "arxiv_id": "2405.03206v1",
      "title": "Vietnamese AI Generated Text Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Quang-Dan Tran",
        "Van-Quan Nguyen",
        "Quang-Huy Pham",
        "K. B. Thang Nguyen",
        "Trong-Hop Do"
      ],
      "abstract": "In recent years, Large Language Models (LLMs) have become integrated into our\ndaily lives, serving as invaluable assistants in completing tasks. Widely\nembraced by users, the abuse of LLMs is inevitable, particularly in using them\nto generate text content for various purposes, leading to difficulties in\ndistinguishing between text generated by LLMs and that written by humans. In\nthis study, we present a dataset named ViDetect, comprising 6.800 samples of\nVietnamese essay, with 3.400 samples authored by humans and the remainder\ngenerated by LLMs, serving the purpose of detecting text generated by AI. We\nconducted evaluations using state-of-the-art methods, including ViT5, BartPho,\nPhoBERT, mDeberta V3, and mBERT. These results contribute not only to the\ngrowing body of research on detecting text generated by AI but also demonstrate\nthe adaptability and effectiveness of different methods in the Vietnamese\nlanguage context. This research lays the foundation for future advancements in\nAI-generated text detection and provides valuable insights for researchers in\nthe field of natural language processing.",
      "tldr_zh": "这篇论文探讨了 Large Language Models (LLMs) 的滥用问题，特别针对越南语文本，提出 ViDetect 数据集以区分 AI 生成文本和人类撰写文本。数据集包含 6800 个越南语作文样本（其中 3400 个由人类撰写，其余由 LLMs 生成），用于 AI 生成文本检测的研究。作者评估了多种先进模型，包括 ViT5、BartPho、PhoBERT、mDeberta V3 和 mBERT，结果显示这些方法在越南语语境中具有良好的适应性和有效性。该研究为 AI 生成文本检测领域奠定了基础，并为自然语言处理提供宝贵见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.03206v1",
      "published_date": "2024-05-06 07:12:22 UTC",
      "updated_date": "2024-05-06 07:12:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:28:53.476868"
    },
    {
      "arxiv_id": "2405.03205v2",
      "title": "Anchored Answers: Unravelling Positional Bias in GPT-2's Multiple-Choice Questions",
      "title_zh": "翻译失败",
      "authors": [
        "Ruizhe Li",
        "Yanjun Gao"
      ],
      "abstract": "Large Language Models (LLMs), such as the GPT-4 and LLaMA families, have\ndemonstrated considerable success across diverse tasks, including\nmultiple-choice questions (MCQs). However, these models exhibit a positional\nbias, particularly an even worse anchored bias in the GPT-2 family, where they\nconsistently favour the first choice 'A' in MCQs during inference. This\nanchored bias challenges the integrity of GPT-2's decision-making process, as\nit skews performance based on the position rather than the content of the\nchoices in MCQs. In this study, we utilise the mechanistic interpretability\napproach to identify the internal modules within GPT-2 models responsible for\nthis bias. We focus on the Multi-Layer Perceptron (MLP) layers and attention\nheads, using the \"logit lens\" method to trace and modify the specific value\nvectors that contribute to the bias. By updating these vectors within MLP and\nrecalibrating attention patterns to neutralise the preference for the first\nchoice 'A', we effectively mitigate the anchored bias. Our interventions not\nonly mitigate the bias but also improve the overall MCQ prediction accuracy for\nthe GPT-2 family across various datasets. This work represents the first\ncomprehensive mechanistic analysis of anchored bias in MCQs within the GPT-2\nmodels, introducing targeted, minimal-intervention strategies that\nsignificantly enhance GPT2 model robustness and accuracy in MCQs. Our code is\navailable at https://github.com/ruizheliUOA/Anchored_Bias_GPT2.",
      "tldr_zh": "这篇论文揭示了GPT-2模型在多选题(MCQs)中的anchored bias问题，即模型倾向于选择第一个选项'A'，这会因位置而非内容影响决策完整性。研究者采用mechanistic interpretability方法，聚焦Multi-Layer Perceptron (MLP)层和attention heads，通过logit lens追踪并修改导致偏差的value vectors，并重新校准attention patterns以缓解偏好。实验结果显示，这些针对性干预不仅消除了anchored bias，还提升了GPT-2家族在多种数据集上的MCQ预测准确率。该工作首次对GPT-2的anchored bias进行全面机械分析，并提供了最小干预策略以增强模型鲁棒性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in process",
      "pdf_url": "http://arxiv.org/pdf/2405.03205v2",
      "published_date": "2024-05-06 07:10:09 UTC",
      "updated_date": "2024-05-23 07:47:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:29:06.637054"
    },
    {
      "arxiv_id": "2405.03192v2",
      "title": "QuadraNet V2: Efficient and Sustainable Training of High-Order Neural Networks with Quadratic Adaptation",
      "title_zh": "QuadraNet V2：利用二次适应的高阶神经网络高效且可持续训练",
      "authors": [
        "Chenhui Xu",
        "Xinyao Wang",
        "Fuxun Yu",
        "Jinjun Xiong",
        "Xiang Chen"
      ],
      "abstract": "Machine learning is evolving towards high-order models that necessitate\npre-training on extensive datasets, a process associated with significant\noverheads. Traditional models, despite having pre-trained weights, are becoming\nobsolete due to architectural differences that obstruct the effective transfer\nand initialization of these weights. To address these challenges, we introduce\na novel framework, QuadraNet V2, which leverages quadratic neural networks to\ncreate efficient and sustainable high-order learning models. Our method\ninitializes the primary term of the quadratic neuron using a standard neural\nnetwork, while the quadratic term is employed to adaptively enhance the\nlearning of data non-linearity or shifts. This integration of pre-trained\nprimary terms with quadratic terms, which possess advanced modeling\ncapabilities, significantly augments the information characterization capacity\nof the high-order network. By utilizing existing pre-trained weights, QuadraNet\nV2 reduces the required GPU hours for training by 90\\% to 98.4\\% compared to\ntraining from scratch, demonstrating both efficiency and effectiveness.",
      "tldr_zh": "本研究针对高阶神经网络（high-order neural networks）训练的资源开销和预训练权重转移难题，引入了QuadraNet V2框架，该框架利用二次神经网络（quadratic neural networks）实现高效可持续的学习。QuadraNet V2通过用标准神经网络初始化二次神经元的主体项，而用二次项适应性地增强数据非线性和偏移，从而显著提升了网络的信息表征能力。与从零训练相比，该方法将所需的GPU训练小时减少90%到98.4%。整体方案为高阶模型的优化提供了高效且有效的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.03192v2",
      "published_date": "2024-05-06 06:31:47 UTC",
      "updated_date": "2024-05-09 02:20:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:29:18.135984"
    },
    {
      "arxiv_id": "2405.03725v2",
      "title": "Deep Oscillatory Neural Network",
      "title_zh": "深度振荡神经网络",
      "authors": [
        "Nurani Rajagopal Rohan",
        "Vigneswaran C",
        "Sayan Ghosh",
        "Kishore Rajendran",
        "Gaurav A",
        "V Srinivasa Chakravarthy"
      ],
      "abstract": "We propose a novel, brain-inspired deep neural network model known as the\nDeep Oscillatory Neural Network (DONN). Deep neural networks like the Recurrent\nNeural Networks indeed possess sequence processing capabilities but the\ninternal states of the network are not designed to exhibit brain-like\noscillatory activity. With this motivation, the DONN is designed to have\noscillatory internal dynamics. Neurons of the DONN are either nonlinear neural\noscillators or traditional neurons with sigmoidal or ReLU activation. The\nneural oscillator used in the model is the Hopf oscillator, with the dynamics\ndescribed in the complex domain. Input can be presented to the neural\noscillator in three possible modes. The sigmoid and ReLU neurons also use\ncomplex-valued extensions. All the weight stages are also complex-valued.\nTraining follows the general principle of weight change by minimizing the\noutput error and therefore has an overall resemblance to complex\nbackpropagation. A generalization of DONN to convolutional networks known as\nthe Oscillatory Convolutional Neural Network is also proposed. The two proposed\noscillatory networks are applied to a variety of benchmark problems in signal\nand image/video processing. The performance of the proposed models is either\ncomparable or superior to published results on the same data sets.",
      "tldr_zh": "本研究提出了一种脑启发型深度神经网络模型，名为 Deep Oscillatory Neural Network (DONN)，旨在通过模拟大脑的振荡活动来提升序列处理能力。DONN 的神经元采用非线性神经振荡器（如 Hopf oscillator）或传统激活函数（如 sigmoid 或 ReLU），并扩展为复值（complex-valued）形式，支持三种输入模式，其训练过程类似于复杂反向传播。研究还推广了 DONN 到 Oscillatory Convolutional Neural Network，并应用于信号、图像和视频处理的基准问题，结果显示其性能与现有模型相当或优于它们。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.03725v2",
      "published_date": "2024-05-06 06:17:16 UTC",
      "updated_date": "2024-09-09 08:33:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:29:28.722087"
    },
    {
      "arxiv_id": "2405.03164v1",
      "title": "The Role of Predictive Uncertainty and Diversity in Embodied AI and Robot Learning",
      "title_zh": "预测不确定性和多样性在具身人工智能和机器人学习中的作用",
      "authors": [
        "Ransalu Senanayake"
      ],
      "abstract": "Uncertainty has long been a critical area of study in robotics, particularly\nwhen robots are equipped with analytical models. As we move towards the\nwidespread use of deep neural networks in robots, which have demonstrated\nremarkable performance in research settings, understanding the nuances of\nuncertainty becomes crucial for their real-world deployment. This guide offers\nan overview of the importance of uncertainty and provides methods to quantify\nand evaluate it from an applications perspective.",
      "tldr_zh": "这篇论文探讨了预测不确定性（Predictive Uncertainty）和多样性在具身 AI（Embodied AI）和机器人学习中的作用，尤其在从分析模型转向深度神经网络（Deep Neural Networks）时。论文强调了理解不确定性的细微差别对于深度神经网络在现实世界部署的必要性，并从应用角度概述了其重要性。作者提供了量化评估不确定性的方法，以帮助机器人系统实现更可靠的表现。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.03164v1",
      "published_date": "2024-05-06 05:04:59 UTC",
      "updated_date": "2024-05-06 05:04:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:29:40.865196"
    },
    {
      "arxiv_id": "2405.03162v1",
      "title": "Advancing Multimodal Medical Capabilities of Gemini",
      "title_zh": "推进 Gemini 的多模态医疗能力",
      "authors": [
        "Lin Yang",
        "Shawn Xu",
        "Andrew Sellergren",
        "Timo Kohlberger",
        "Yuchen Zhou",
        "Ira Ktena",
        "Atilla Kiraly",
        "Faruk Ahmed",
        "Farhad Hormozdiari",
        "Tiam Jaroensri",
        "Eric Wang",
        "Ellery Wulczyn",
        "Fayaz Jamil",
        "Theo Guidroz",
        "Chuck Lau",
        "Siyuan Qiao",
        "Yun Liu",
        "Akshay Goel",
        "Kendall Park",
        "Arnav Agharwal",
        "Nick George",
        "Yang Wang",
        "Ryutaro Tanno",
        "David G. T. Barrett",
        "Wei-Hung Weng",
        "S. Sara Mahdavi",
        "Khaled Saab",
        "Tao Tu",
        "Sreenivasa Raju Kalidindi",
        "Mozziyar Etemadi",
        "Jorge Cuadros",
        "Gregory Sorensen",
        "Yossi Matias",
        "Katherine Chou",
        "Greg Corrado",
        "Joelle Barral",
        "Shravya Shetty",
        "David Fleet",
        "S. M. Ali Eslami",
        "Daniel Tse",
        "Shruthi Prabhakara",
        "Cory McLean",
        "Dave Steiner",
        "Rory Pilgrim",
        "Christopher Kelly",
        "Shekoofeh Azizi",
        "Daniel Golden"
      ],
      "abstract": "Many clinical tasks require an understanding of specialized data, such as\nmedical images and genomics, which is not typically found in general-purpose\nlarge multimodal models. Building upon Gemini's multimodal models, we develop\nseveral models within the new Med-Gemini family that inherit core capabilities\nof Gemini and are optimized for medical use via fine-tuning with 2D and 3D\nradiology, histopathology, ophthalmology, dermatology and genomic data.\nMed-Gemini-2D sets a new standard for AI-based chest X-ray (CXR) report\ngeneration based on expert evaluation, exceeding previous best results across\ntwo separate datasets by an absolute margin of 1% and 12%, where 57% and 96% of\nAI reports on normal cases, and 43% and 65% on abnormal cases, are evaluated as\n\"equivalent or better\" than the original radiologists' reports. We demonstrate\nthe first ever large multimodal model-based report generation for 3D computed\ntomography (CT) volumes using Med-Gemini-3D, with 53% of AI reports considered\nclinically acceptable, although additional research is needed to meet expert\nradiologist reporting quality. Beyond report generation, Med-Gemini-2D\nsurpasses the previous best performance in CXR visual question answering (VQA)\nand performs well in CXR classification and radiology VQA, exceeding SoTA or\nbaselines on 17 of 20 tasks. In histopathology, ophthalmology, and dermatology\nimage classification, Med-Gemini-2D surpasses baselines across 18 out of 20\ntasks and approaches task-specific model performance. Beyond imaging,\nMed-Gemini-Polygenic outperforms the standard linear polygenic risk score-based\napproach for disease risk prediction and generalizes to genetically correlated\ndiseases for which it has never been trained. Although further development and\nevaluation are necessary in the safety-critical medical domain, our results\nhighlight the potential of Med-Gemini across a wide range of medical tasks.",
      "tldr_zh": "本研究基于Gemini的多模态模型，开发了Med-Gemini系列模型，通过微调放射学（包括2D和3D）、组织病理学、眼科、皮肤科和基因组数据，优化其在医疗领域的性能。Med-Gemini-2D在胸部X光（CXR）报告生成上超越了现有最佳结果，在两个数据集上分别提高了1%和12%，其中57%和96%的正常病例AI报告被评为“等同或更好”，异常病例分别为43%和65%。此外，Med-Gemini-2D在CXR视觉问答（VQA）、分类和放射学VQA中胜出17个任务，在组织病理学、眼科和皮肤科图像分类中胜出18个任务，而Med-Gemini-Polygenic在疾病风险预测上超过了标准线性多基因风险评分方法，并能泛化到相关疾病。尽管医疗领域需进一步开发和评估，该系列模型展示了在广泛医疗任务中的巨大潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.03162v1",
      "published_date": "2024-05-06 04:44:22 UTC",
      "updated_date": "2024-05-06 04:44:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:29:54.222118"
    },
    {
      "arxiv_id": "2405.03151v1",
      "title": "Time Series Stock Price Forecasting Based on Genetic Algorithm (GA)-Long Short-Term Memory Network (LSTM) Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Xinye Sha"
      ],
      "abstract": "In this paper, a time series algorithm based on Genetic Algorithm (GA) and\nLong Short-Term Memory Network (LSTM) optimization is used to forecast stock\nprices effectively, taking into account the trend of the big data era. The data\nare first analyzed by descriptive statistics, and then the model is built and\ntrained and tested on the dataset. After optimization and adjustment, the mean\nabsolute error (MAE) of the model gradually decreases from 0.11 to 0.01 and\ntends to be stable, indicating that the model prediction effect is gradually\nclose to the real value. The results on the test set show that the time series\nalgorithm optimized based on Genetic Algorithm (GA)-Long Short-Term Memory\nNetwork (LSTM) is able to accurately predict the stock prices, and is highly\nconsistent with the actual price trends and values, with strong generalization\nability. The MAE on the test set is 2.41, the MSE is 9.84, the RMSE is 3.13,\nand the R2 is 0.87. This research result not only provides a novel stock price\nprediction method, but also provides a useful reference for financial market\nanalysis using computer technology and big data.",
      "tldr_zh": "本文提出了一种基于 Genetic Algorithm (GA) 优化 Long Short-Term Memory Network (LSTM) 的时间序列算法，用于有效预测股票价格，以适应大数据时代趋势。研究首先通过描述性统计分析数据，然后构建并训练模型，优化后模型的 Mean Absolute Error (MAE) 从 0.11 降至 0.01，并趋于稳定。测试结果显示，该算法在测试集上准确预测股票价格，与实际趋势高度一致，关键指标包括 MAE 为 2.41、MSE 为 9.84、RMSE 为 3.13 以及 R2 为 0.87。该方法不仅提供了一种新颖的股票价格预测途径，还为利用计算机技术和大数据进行金融市场分析提供了有益参考。",
      "categories": [
        "cs.CE",
        "cs.AI"
      ],
      "primary_category": "cs.CE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.03151v1",
      "published_date": "2024-05-06 04:04:27 UTC",
      "updated_date": "2024-05-06 04:04:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:30:06.325526"
    },
    {
      "arxiv_id": "2405.03146v2",
      "title": "Quantifying the Capabilities of LLMs across Scale and Precision",
      "title_zh": "翻译失败",
      "authors": [
        "Sher Badshah",
        "Hassan Sajjad"
      ],
      "abstract": "Scale is often attributed as one of the factors that cause an increase in the\nperformance of LLMs, resulting in models with billion and trillion parameters.\nOne of the limitations of such large models is the high computational\nrequirements that limit their usage, deployment, and debugging in\nresource-constrained scenarios. Two commonly used alternatives to bypass these\nlimitations are to use the smaller versions of LLMs (e.g. Llama 7B instead of\nLlama 70B) and lower the memory requirements by using quantization. While these\napproaches effectively address the limitation of resources, their impact on\nmodel performance needs thorough examination. In this study, we perform a\ncomprehensive evaluation to investigate the effect of model scale and\nquantization on the performance. We experiment with two major families of\nopen-source instruct models ranging from 7 billion to 70 billion parameters.\nOur extensive zero-shot experiments across various tasks including natural\nlanguage understanding, reasoning, misinformation detection, and hallucination\nreveal that larger models generally outperform their smaller counterparts,\nsuggesting that scale remains an important factor in enhancing performance. We\nfound that larger models show exceptional resilience to precision reduction and\ncan maintain high accuracy even at 4-bit quantization for numerous tasks and\nthey serve as a better solution than using smaller models at high precision\nunder similar memory requirements.",
      "tldr_zh": "本研究量化评估了大型语言模型（LLMs）的规模和精度对性能的影响，针对资源限制问题探讨了使用小型模型（如 Llama 7B）和量化技术（如降低到 4-bit 精度）的效果。研究通过零-shot 实验测试了从 7 亿到 70 亿参数的开源指令模型，在自然语言理解、推理、错误信息检测和幻觉等任务上的表现。结果显示，大型模型通常优于小型模型，即使在量化条件下也能保持高准确率，并在相同内存需求下提供更好的性能，强调了模型规模的重要性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.03146v2",
      "published_date": "2024-05-06 03:42:34 UTC",
      "updated_date": "2024-05-08 02:10:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:30:16.809812"
    },
    {
      "arxiv_id": "2405.03141v2",
      "title": "Automatic Ultrasound Curve Angle Measurement via Affinity Clustering for Adolescent Idiopathic Scoliosis Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Yihao Zhou",
        "Timothy Tin-Yan Lee",
        "Kelly Ka-Lee Lai",
        "Chonglin Wu",
        "Hin Ting Lau",
        "De Yang",
        "Chui-Yi Chan",
        "Winnie Chiu-Wing Chu",
        "Jack Chun-Yiu Cheng",
        "Tsz-Ping Lam",
        "Yong-Ping Zheng"
      ],
      "abstract": "The current clinical gold standard for evaluating adolescent idiopathic\nscoliosis (AIS) is X-ray radiography, using Cobb angle measurement. However,\nthe frequent monitoring of the AIS progression using X-rays poses a challenge\ndue to the cumulative radiation exposure. Although 3D ultrasound has been\nvalidated as a reliable and radiation-free alternative for scoliosis\nassessment, the process of measuring spinal curvature is still carried out\nmanually. Consequently, there is a considerable demand for a fully automatic\nsystem that can locate bony landmarks and perform angle measurements. To this\nend, we introduce an estimation model for automatic ultrasound curve angle\n(UCA) measurement. The model employs a dual-branch network to detect candidate\nlandmarks and perform vertebra segmentation on ultrasound coronal images. An\naffinity clustering strategy is utilized within the vertebral segmentation area\nto illustrate the affinity relationship between candidate landmarks.\nSubsequently, we can efficiently perform line delineation from a clustered\naffinity map for UCA measurement. As our method is specifically designed for\nUCA calculation, this method outperforms other state-of-the-art methods for\nlandmark and line detection tasks. The high correlation between the automatic\nUCA and Cobb angle (R$^2$=0.858) suggests that our proposed method can\npotentially replace manual UCA measurement in ultrasound scoliosis assessment.",
      "tldr_zh": "本论文针对青少年特发性脊柱侧弯 (AIS) 的评估，提出了一种自动超声曲线角度 (UCA) 测量方法，以取代辐射暴露高的 X 射线 Cobb angle 测量。方法采用双分支网络检测候选 landmarks 并进行椎骨分割，随后利用 affinity clustering 策略在分割区域中分析 landmarks 间的亲和关系，并从中生成线条描绘以计算 UCA。该方法在 UCA 计算上优于现有技术，且自动 UCA 与 Cobb angle 的相关性达 R²=0.858，表明其有望取代手动测量，成为可靠的无辐射评估工具。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "physics.med-ph"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.03141v2",
      "published_date": "2024-05-06 03:28:47 UTC",
      "updated_date": "2024-05-07 03:21:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:30:29.748457"
    },
    {
      "arxiv_id": "2405.10329v3",
      "title": "Causal inference approach to appraise long-term effects of maintenance policy on functional performance of asphalt pavements",
      "title_zh": "翻译失败",
      "authors": [
        "Lingyun You",
        "Nanning Guo",
        "Zhengwu Long",
        "Fusong Wang",
        "Chundi Si",
        "Aboelkasim Diab"
      ],
      "abstract": "Asphalt pavements as the most prevalent transportation infrastructure, are\nprone to serious traffic safety problems due to functional or structural damage\ncaused by stresses or strains imposed through repeated traffic loads and\ncontinuous climatic cycles. The good quality or high serviceability of\ninfrastructure networks is vital to the urbanization and industrial development\nof nations. In order to maintain good functional pavement performance and\nextend the service life of asphalt pavements, the long-term performance of\npavements under maintenance policies needs to be evaluated and favorable\noptions selected based on the condition of the pavement. A major challenge in\nevaluating maintenance policies is to produce valid treatments for the outcome\nassessment under the control of uncertainty of vehicle loads and the\ndisturbance of freeze-thaw cycles in the climatic environment. In this study, a\nnovel causal inference approach combining a classical causal structural model\nand a potential outcome model framework is proposed to appraise the long-term\neffects of four preventive maintenance treatments for longitudinal cracking\nover a 5-year period of upkeep. Three fundamental issues were brought to our\nattention: 1) detection of causal relationships prior to variables under\nenvironmental loading (identification of causal structure); 2) obtaining direct\ncausal effects of treatment on outcomes excluding covariates (identification of\ncausal effects); and 3) sensitivity analysis of causal relationships. The\nresults show that the method can accurately evaluate the effect of preventive\nmaintenance treatments and assess the maintenance time to cater well for the\nfunctional performance of different preventive maintenance approaches. This\nframework could help policymakers to develop appropriate maintenance strategies\nfor pavements.",
      "tldr_zh": "这篇论文提出了一种因果推理(causal inference)方法，结合因果结构模型(causal structural model)和潜在结果模型(potential outcome model)框架，来评估沥青路面维护政策的长期效果，针对交通负荷和气候循环（如冻融循环）的不确定性。研究重点解决三个关键问题：识别因果结构、获取治疗对结果的直接因果效果（排除协变量），以及进行敏感性分析。结果显示，该方法能准确评估四种预防性维护处理对纵向裂缝的5年期影响，并为决策者提供指导，帮助制定合适的路面维护策略以提升功能性能和服务寿命。",
      "categories": [
        "stat.AP",
        "cs.AI"
      ],
      "primary_category": "stat.AP",
      "comment": "The arXiv version needs to be withdrawn since the model needs to be\n  validated and updated with advanced machine learning technologies to enhance\n  the accuracy of the model, and there are some crucial definition errors of\n  symbols in the arXiv version",
      "pdf_url": "http://arxiv.org/pdf/2405.10329v3",
      "published_date": "2024-05-06 03:22:38 UTC",
      "updated_date": "2024-07-03 00:53:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:30:42.980704"
    },
    {
      "arxiv_id": "2405.03131v1",
      "title": "WDMoE: Wireless Distributed Large Language Models with Mixture of Experts",
      "title_zh": "WDMoE：无线分布式大语言模型结合混合专家系统",
      "authors": [
        "Nan Xue",
        "Yaping Sun",
        "Zhiyong Chen",
        "Meixia Tao",
        "Xiaodong Xu",
        "Liang Qian",
        "Shuguang Cui",
        "Ping Zhang"
      ],
      "abstract": "Large Language Models (LLMs) have achieved significant success in various\nnatural language processing tasks, but how wireless communications can support\nLLMs has not been extensively studied. In this paper, we propose a wireless\ndistributed LLMs paradigm based on Mixture of Experts (MoE), named WDMoE,\ndeploying LLMs collaboratively across edge servers of base station (BS) and\nmobile devices in the wireless communications system. Specifically, we\ndecompose the MoE layer in LLMs by deploying the gating network and the\npreceding neural network layer at BS, while distributing the expert networks\nacross the devices. This arrangement leverages the parallel capabilities of\nexpert networks on distributed devices. Moreover, to overcome the instability\nof wireless communications, we design an expert selection policy by taking into\naccount both the performance of the model and the end-to-end latency, which\nincludes both transmission delay and inference delay. Evaluations conducted\nacross various LLMs and multiple datasets demonstrate that WDMoE not only\noutperforms existing models, such as Llama 2 with 70 billion parameters, but\nalso significantly reduces end-to-end latency.",
      "tldr_zh": "本论文提出 WDMoE，一种基于 Mixture of Experts (MoE) 的无线分布式大语言模型 (LLMs) 框架，将模型部署在基站 (BS) 和移动设备上进行协作，以支持 LLMs 在无线通信环境中的应用。具体方法包括将 MoE 层分解，将 gating network 和前置神经网络层置于 BS，而 expert networks 分布到设备上，并设计一个专家选择策略来平衡模型性能和端到端延迟（包括传输延迟和推理延迟）。实验评估显示，WDMoE 在多种 LLMs 和数据集上优于现有模型如 Llama 2 的 70 亿参数版本，并显著减少了端到端延迟。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "cs.LG",
        "math.IT"
      ],
      "primary_category": "cs.IT",
      "comment": "submitted to IEEE conference",
      "pdf_url": "http://arxiv.org/pdf/2405.03131v1",
      "published_date": "2024-05-06 02:55:50 UTC",
      "updated_date": "2024-05-06 02:55:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:30:55.429756"
    },
    {
      "arxiv_id": "2405.03121v1",
      "title": "AniTalker: Animate Vivid and Diverse Talking Faces through Identity-Decoupled Facial Motion Encoding",
      "title_zh": "翻译失败",
      "authors": [
        "Tao Liu",
        "Feilong Chen",
        "Shuai Fan",
        "Chenpeng Du",
        "Qi Chen",
        "Xie Chen",
        "Kai Yu"
      ],
      "abstract": "The paper introduces AniTalker, an innovative framework designed to generate\nlifelike talking faces from a single portrait. Unlike existing models that\nprimarily focus on verbal cues such as lip synchronization and fail to capture\nthe complex dynamics of facial expressions and nonverbal cues, AniTalker\nemploys a universal motion representation. This innovative representation\neffectively captures a wide range of facial dynamics, including subtle\nexpressions and head movements. AniTalker enhances motion depiction through two\nself-supervised learning strategies: the first involves reconstructing target\nvideo frames from source frames within the same identity to learn subtle motion\nrepresentations, and the second develops an identity encoder using metric\nlearning while actively minimizing mutual information between the identity and\nmotion encoders. This approach ensures that the motion representation is\ndynamic and devoid of identity-specific details, significantly reducing the\nneed for labeled data. Additionally, the integration of a diffusion model with\na variance adapter allows for the generation of diverse and controllable facial\nanimations. This method not only demonstrates AniTalker's capability to create\ndetailed and realistic facial movements but also underscores its potential in\ncrafting dynamic avatars for real-world applications. Synthetic results can be\nviewed at https://github.com/X-LANCE/AniTalker.",
      "tldr_zh": "该论文引入 AniTalker 框架，通过身份解耦的面部运动编码（Identity-Decoupled Facial Motion Encoding），从单张肖像生成生动且多样的说话面部动画，与现有模型不同的是，它能捕捉复杂的面部表情和头部运动，而非仅限于唇部同步。框架采用通用运动表示（universal motion representation）并结合两个自监督学习策略：一是重建同一身份的源帧以学习微妙运动，二是使用度量学习（metric learning）最小化身份和运动编码器之间的互信息，从而确保运动表示动态且不依赖身份细节。AniTalker 还整合扩散模型（diffusion model）和方差适配器（variance adapter），实现多样且可控的动画生成，显著减少了对标记数据的需求。实验结果表明，该方法在创建真实面部动画方面表现出色，并具有在动态头像等实际应用中的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "14 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.03121v1",
      "published_date": "2024-05-06 02:32:41 UTC",
      "updated_date": "2024-05-06 02:32:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:31:07.848844"
    },
    {
      "arxiv_id": "2405.03113v1",
      "title": "Robot Air Hockey: A Manipulation Testbed for Robot Learning with Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Caleb Chuck",
        "Carl Qi",
        "Michael J. Munje",
        "Shuozhe Li",
        "Max Rudolph",
        "Chang Shi",
        "Siddhant Agarwal",
        "Harshit Sikchi",
        "Abhinav Peri",
        "Sarthak Dayal",
        "Evan Kuo",
        "Kavan Mehta",
        "Anthony Wang",
        "Peter Stone",
        "Amy Zhang",
        "Scott Niekum"
      ],
      "abstract": "Reinforcement Learning is a promising tool for learning complex policies even\nin fast-moving and object-interactive domains where human teleoperation or\nhard-coded policies might fail. To effectively reflect this challenging\ncategory of tasks, we introduce a dynamic, interactive RL testbed based on\nrobot air hockey. By augmenting air hockey with a large family of tasks ranging\nfrom easy tasks like reaching, to challenging ones like pushing a block by\nhitting it with a puck, as well as goal-based and human-interactive tasks, our\ntestbed allows a varied assessment of RL capabilities. The robot air hockey\ntestbed also supports sim-to-real transfer with three domains: two simulators\nof increasing fidelity and a real robot system. Using a dataset of\ndemonstration data gathered through two teleoperation systems: a virtualized\ncontrol environment, and human shadowing, we assess the testbed with behavior\ncloning, offline RL, and RL from scratch.",
      "tldr_zh": "该论文引入了Robot Air Hockey测试床，作为一个基于Reinforcement Learning的机器人学习平台，用于评估RL在快速动态和物体交互任务中的性能。测试床涵盖多种任务，从简单如reaching到复杂如pushing a block，以及目标导向和人类交互任务，支持sim-to-real转移，通过两个模拟器和真实机器人系统实现。研究团队使用从遥操作系统收集的数据集，通过behavior cloning、offline RL和从零开始的RL方法进行评估，为RL在实际应用中的鲁棒性提供了全面测试。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.03113v1",
      "published_date": "2024-05-06 02:13:08 UTC",
      "updated_date": "2024-05-06 02:13:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:31:18.585856"
    },
    {
      "arxiv_id": "2405.03097v1",
      "title": "To Each (Textual Sequence) Its Own: Improving Memorized-Data Unlearning in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "George-Octavian Barbulescu",
        "Peter Triantafillou"
      ],
      "abstract": "LLMs have been found to memorize training textual sequences and regurgitate\nverbatim said sequences during text generation time. This fact is known to be\nthe cause of privacy and related (e.g., copyright) problems. Unlearning in LLMs\nthen takes the form of devising new algorithms that will properly deal with\nthese side-effects of memorized data, while not hurting the model's utility. We\noffer a fresh perspective towards this goal, namely, that each textual sequence\nto be forgotten should be treated differently when being unlearned based on its\ndegree of memorization within the LLM. We contribute a new metric for measuring\nunlearning quality, an adversarial attack showing that SOTA algorithms lacking\nthis perspective fail for privacy, and two new unlearning methods based on\nGradient Ascent and Task Arithmetic, respectively. A comprehensive performance\nevaluation across an extensive suite of NLP tasks then mapped the solution\nspace, identifying the best solutions under different scales in model\ncapacities and forget set sizes and quantified the gains of the new approaches.",
      "tldr_zh": "这篇论文针对大型语言模型(LLMs)中记忆训练文本序列的问题，提出一种新视角：根据每个文本序列的记忆程度进行个性化的unlearning处理，以缓解隐私和版权风险，同时保持模型效用。贡献包括一个新的unlearning质量度量指标、一个对抗攻击证明SOTA算法在隐私方面的失败，以及基于Gradient Ascent和Task Arithmetic的两个新unlearning方法。通过在各种NLP任务上的全面性能评估，论文识别了不同模型容量和遗忘集大小下的最佳解决方案，并量化了新方法的性能提升。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Published as a conference paper at ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.03097v1",
      "published_date": "2024-05-06 01:21:50 UTC",
      "updated_date": "2024-05-06 01:21:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:31:31.204868"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 95,
  "processed_papers_count": 95,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-18T06:31:50.485021"
}