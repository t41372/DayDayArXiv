{
  "date": "2025-03-20",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间2025-03-20的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文再次聚焦于大型语言模型（LLM）和智能体（Agent）的评估、能力提升与应用，特别是对其通用智能（AGI）潜力的探讨、基准测试污染问题的严格审视，以及多模态、多智能体协作和效率优化方面的进展。同时，计算机视觉领域在3D生成、深度估计和图像恢复方面也涌现出不少创新方法。\n\n**今日焦点:**\n\n*   **AGI 测试新基准 (SuperARC):** 一篇长文提出了基于递归理论和算法概率的 SuperARC 测试，旨在评估前沿模型的 AGI 和 ASI 能力，并指出当前 LLM 尚未展现明确的 AGI/ASI 趋同性。\n*   **LLM 智能体评估:** 多篇论文关注 LLM 智能体的评估，包括首个全面的评估方法综述，以及针对移动 GUI 任务的 V-Droid 框架，强调了评估的复杂性和必要性。\n*   **基准测试污染再审视:** 一篇研究系统性评估了现有的 LLM 基准数据污染（BDC）缓解策略，发现它们效果有限，亟需更有效的解决方案。\n*   **多模态与 3D/视频生成:** MagicMotion、Worlds Recipe、VideoRFSplat 等多篇论文探索了从文本/图像生成可控视频或 3D 世界的新方法，利用扩散模型和多视图建模等技术。\n*   **LLM 效率与优化:** 从 2:4 激活稀疏性加速训练/推理，到 RAG 调优、知识编辑（CaKE）、知识蒸馏（InhibiDistilbert）等，研究者们持续探索提升 LLM 效率和能力的方法。\n*   **AI 伦理与偏见:** 研究探讨了中美 LLM 的地缘政治偏见、LLM 中的性别偏见，以及医疗 AI 中的信任限制等问题。\n\n**接下来，我们深入了解一些重点论文：**\n\n---\n\n**1. SuperARC: 基于递归理论和算法概率原理的通用与超级智能测试 (SuperARC: A Test for General and Super Intelligence Based on First Principles of Recursion Theory and Algorithmic Probability)**\n\n*   作者：Alberto Hernández-Espinosa, Luan Ozelim, Felipe S. Abrahão, Hector Zenil\n*   TLDR: 这篇长达 71 页的论文（含附录）提出了一个基于算法概率的开放式测试 SuperARC，旨在避免基准污染，评估前沿模型在 AGI 和 ASI 方面的能力。该测试不依赖 GZIP 等统计压缩方法，而是关注智能的基本特征，如逆问题中的合成和模型创建。研究发现，LLM 版本迭代脆弱且增量，新版本可能不如旧版本，进步主要由训练数据规模驱动，并未显示出向 AGI/ASI 趋同的明确证据。相比之下，一种基于算法概率和 Kolmogorov 复杂性原理的神经符号混合方法在短二进制序列的概念验证中优于 LLM。研究证实了对 LLM 基本局限性的怀疑，认为它们是为感知人类语言掌握而优化的系统。\n\n**2. LLM 基准数据污染缓解策略的严格检验 (The Emperor's New Clothes in Benchmarking? A Rigorous Examination of Mitigation Strategies for LLM Benchmark Data Contamination)**\n\n*   作者：Yifan Sun, Han Wang, Dongbai Li, Gang Wang, Huan Zhang\n*   TLDR: 针对 LLM 评估中基准数据污染（BDC）的问题，研究者提出了修改或生成新问题的缓解策略。本文设计了一个系统化的评估流程和两个新指标（保真度、抗污染性），对 20 种缓解策略在 10 个 LLM 和 5 个基准上进行了评估。结果令人担忧：没有任何现有策略能在所有基准上显著提高抗污染性，也没有策略能有效平衡保真度和抗污染性，凸显了设计更有效 BDC 缓解策略的紧迫性。\n\n**3. LLM 智能体评估综述 (Survey on Evaluation of LLM-based Agents)**\n\n*   作者：Asaf Yehudai, Lilach Eden, Alan Li, Guy Uziel, Yilun Zhao, Roy Bar-Haim, Arman Cohan, Michal Shmueli-Scheuer\n*   TLDR: 这是首个全面综述 LLM 智能体评估方法的论文。文章系统分析了评估基准和框架，涵盖了基本能力（规划、工具使用、反思、记忆）、特定应用（Web、软件工程、科学、对话）、通用智能体以及评估框架本身。研究揭示了向更真实、更具挑战性评估发展的趋势，但也指出了在评估成本效率、安全性、鲁棒性以及开发细粒度、可扩展方法方面的关键差距。\n\n**4. 迈向多模态大语言模型时代的智能体推荐系统 (Towards Agentic Recommender Systems in the Era of Multimodal Large Language Models)**\n\n*   作者：Chengkai Huang, Junda Wu, Yu Xia, 等\n*   TLDR: 这篇观点性论文探讨了将 LLM 驱动的智能体能力（感知、多模态集成、工具交互）引入推荐系统（RS）的前景。LLM-ARS 有望提供更具交互性、上下文感知和主动性的推荐，但也面临外部知识整合、自主性与可控性平衡、动态多模态评估等挑战。文章系统分析了 LLM-ARS 的概念、架构、能力增强（规划、记忆、多模态推理）及关键研究问题，并预测 LLM-ARS 将推动下一波 RS 创新。\n\n**5. MagicMotion: 通过密集到稀疏轨迹引导的可控视频生成 (MagicMotion: Controllable Video Generation with Dense-to-Sparse Trajectory Guidance)**\n\n*   作者：Quanhao Li, Zhen Xing, Rui Wang, 等\n*   TLDR: 针对现有轨迹可控视频生成方法在复杂运动和多对象控制上的不足，本文提出 MagicMotion 框架。它支持从密集（掩码）到稀疏（稀疏框）三种级别的轨迹条件，能根据输入图像和轨迹让对象沿路径运动，同时保持一致性和视觉质量。研究还发布了 MagicData 数据集和 MagicBench 评估基准。实验表明 MagicMotion 优于先前方法。\n\n**6. 单幅图像生成 3D 世界的秘诀 (A Recipe for Generating 3D Worlds From a Single Image)**\n\n*   作者：Katja Schwarz, Denys Rozumnyi, Samuel Rota Bulò, 等\n*   TLDR: 本文提出一种从单张图片生成沉浸式 3D 世界的方法，将其视为 2D 修复模型的上下文学习问题。该方法只需少量训练，利用现有生成模型。过程包括：使用预训练扩散模型生成连贯全景图，用度量深度估计器提升至 3D，然后通过对渲染点云进行条件修复来填充未观察区域。该方法在合成和真实图像上均表现良好，优于基于视频合成的方法。\n\n**7. VideoRFSplat: 利用灵活姿态和多视图联合建模直接从文本生成场景级 3D 高斯溅射 (VideoRFSplat: Direct Scene-Level Text-to-3D Gaussian Splatting Generation with Flexible Pose and Multi-View Joint Modeling)**\n\n*   作者：Hyojun Go, Byeongjun Park, Hyelin Nam, 等\n*   TLDR: 提出 VideoRFSplat，一种直接的文本到 3D 模型，利用视频生成模型生成无界真实世界场景的 3D 高斯溅射 (3DGS)。通过双流架构（图像流+姿态流）和异步采样策略，有效联合建模多视图图像和相机姿态，减少模态间干扰，增强跨模态一致性。该方法无需分数蒸馏采样等后处理即可取得优于现有直接生成方法的性能。\n\n**8. FlashVDM: Unleashing Vecset Diffusion Model for Fast Shape Generation (加速 Vecset 扩散模型以实现快速形状生成)**\n\n*   作者：Zeqiang Lai, Yunfei Zhao, Zibo Zhao, 等\n*   TLDR: 针对 Vecset Diffusion Model (VDM) 在 3D 形状生成速度上的瓶颈，本文提出 FlashVDM 框架，系统性地加速 VDM 中的 VAE 和 DiT。通过渐进式流蒸馏 (Progressive Flow Distillation) 稳定一致性蒸馏，实现少至 5 步的 DiT 推理。同时设计了包含自适应 KV 选择、分层体积解码和高效网络设计的闪电 vecset 解码器，大幅降低 VAE 解码开销。实验表明，该模型在保证质量的同时，将重建和生成时间分别缩短了 45 倍和 32 倍以上。\n\n**9. 加速 Transformer 推理和训练的 2:4 激活稀疏性 (Accelerating Transformer Inference and Training with 2:4 Activation Sparsity)**\n\n*   作者：Daniel Haziza, Timothy Chou, Dhruv Choudhary, 等\n*   TLDR: 本文展示了如何利用流行的硬件加速 GPU 稀疏模式 (2:4 稀疏性) 应用于激活值，以加速大语言模型的训练和推理。关键在于利用 Squared-ReLU 激活中固有的稀疏性，在不损失精度的情况下实现加速。该方法在前向和后向传播中使前馈网络 (FFN) 速度提升高达 1.3 倍，突显了稀疏性在加速 LLM 训练和推理中的潜力。\n\n**10. 权力回声：中美大语言模型中的地缘政治偏见调查 (Echoes of Power: Investigating Geopolitical Bias in US and China Large Language Models)**\n\n*   作者：Andre G. C. Pacheco, Athus Cavalini, Giovanni Comarela\n*   TLDR: 本研究调查了美国 (ChatGPT) 和中国 (DeepSeek) 的 LLM 在地缘政治和国际关系问题上的偏见。通过定性和定量分析模型对一系列地缘政治问题的回答，发现两个模型都存在显著偏见，反映了不同的意识形态视角和文化影响。然而，对于某些问题，模型的回答比预期更一致，表明它们可以在不呈现直接对立观点的情况下处理敏感话题。研究强调了 LLM 塑造公众话语的潜力以及批判性评估 AI 生成内容的重要性。\n\n**11. Fùxì: 评估语言模型古汉语理解与生成的基准 (Fùxì: A Benchmark for Evaluating Language Models on Ancient Chinese Text Understanding and Generation)**\n\n*   作者：Shangqing Zhao, Yuhao Zhou, Yupei Ren, 等\n*   TLDR: 针对 LLM 处理古汉语的挑战，本文提出 Fùxì 基准，包含 21 个涵盖理解和生成的任务（如诗歌创作、对联补全）。该基准特点包括：平衡理解与生成任务、专门的古汉语生成评估指标（结合规则验证和微调 LLM 评估器）、系统性评估框架（考虑语言准确性和文化真实性）。评估发现，现有 LLM 在理解任务上表现尚可，但在生成任务（尤其需深度文化知识和格式遵循的任务）上表现不佳。\n\n**12. MathFusion: 通过指令融合增强 LLM 的数学问题解决能力 (MathFusion: Enhancing Mathematic Problem-solving of LLM through Instruction Fusion)**\n\n*   作者：Qizhi Pei, Lijun Wu, Zhuoshi Pan, 等\n*   TLDR: 现有 LLM 数学能力增强的数据增强方法多限于实例级修改。受人类学习过程启发，本文提出 MathFusion 框架，通过跨问题指令合成来增强数学推理。它包含三种融合策略：序列融合（建模解题依赖）、并行融合（强化概念理解）、条件融合（增强推理灵活性）。基于此生成 MathFusionQA 数据集并微调模型，仅用 45K 合成指令就在多个基准上实现了 18.0 点的准确率提升。\n\n**13. RAG 原则调优 LLM：迈向 LLM 原生记忆 (Tuning LLMs by RAG Principles: Towards LLM-native Memory)**\n\n*   作者：Jiale Wei, Shuchi Wu, Ruochen Liu, 等\n*   TLDR: 记忆（模型训练之外的信息）对 LLM 应用至关重要。现有长上下文和 RAG 方案各有优劣。本文比较两者后提出 RAG-Tuned-LLM 方法：使用遵循 RAG 原则生成的数据微调相对较小的 LLM（如 7B），旨在结合长上下文的全局理解和 RAG 的精确检索优势。实验表明该方法在多种查询类型上优于基线。\n\n**14. CK-PLUG: 参数 vs. 上下文：语言模型中知识依赖的细粒度控制 (Parameters vs. Context: Fine-Grained Control of Knowledge Reliance in Language Models)**\n\n*   作者：Baolong Bi, Shenghua Liu, Yiwei Wang, 等\n*   TLDR: RAG 中，模型内部知识与检索到的上下文可能冲突。本文提出 CK-PLUG，一种即插即用的方法，用于控制 LLM 对参数知识和上下文知识的依赖程度。通过引入新的知识一致性度量 \"Confidence Gain\" 检测冲突，并通过调整单一参数对冲突 token 的概率分布进行细粒度控制。实验证明 CK-PLUG 能显著调节知识依赖，同时保持生成流畅性和知识准确性，并支持自适应控制。\n\n**15. AutoRedTeamer: 具有终身攻击集成的自主红队测试 (AutoRedTeamer: Autonomous Red Teaming with Lifelong Attack Integration)**\n\n*   作者：Andy Zhou, Kevin Wu, Francesco Pinto, 等\n*   TLDR: 为解决当前 LLM 红队测试依赖人工且覆盖不足的问题，本文提出 AutoRedTeamer，一个全自动、端到端的红队测试框架。它结合多智能体架构和记忆引导的攻击选择机制，持续发现和集成新的攻击向量。双智能体框架（红队智能体+策略提议智能体）使其能从高层风险类别生成测试用例，并自主分析研究以发现新攻击。实验表明，该框架在 HarmBench 上对 Llama-3.1-70B 的攻击成功率提高 20%，计算成本降低 46%。\n\n**其他简报:**\n\n*   **Agentic Recommender Systems (2):** 展望 LLM 智能体在推荐系统中的应用潜力与挑战。\n*   **SILVA (3):** 利用 VLM 自动化实现 RL 中的语义可解释性，无需人工标注。\n*   **ISP 网络流量预测 (4):** 对比分析深度学习模型在真实 ISP 网络流量预测任务上的准确性和效率。\n*   **QuartDepth (5):** 提出用于边缘 ASIC 实时深度估计的 4 位后训练量化框架。\n*   **医疗 AI 的信任限制 (6):** 哲学探讨，认为 AI 可靠但不可信，可能影响医患信任关系。\n*   **GAIR (7):** 提出多模态地理基础模型 GAIR，融合遥感、街景和地理位置信息，通过隐式神经表示对齐地理信息。\n*   **GauRast (8):** 提出增强 GPU 光栅化器以加速 3D 高斯溅射渲染，显著提升速度和能效。\n*   **OpenFlamingo 分析 C2C 汽车零件数据 (11):** 利用 OpenFlamingo 提取多模态嵌入，通过聚类分析 C2C 平台汽车零件帖子。\n*   **文本到音乐评估对齐人类偏好 (12):** 提出新指标 MAD，发现其比 FAD 更符合人类对 TTM 模型的偏好。\n*   **代码进化图 (13):** 提出分析 LLM 驱动算法设计演化过程的方法，发现 LLM 倾向生成更复杂代码，不同 LLM 风格迥异。\n*   **MobilePlantViT (14):** 提出轻量级混合 ViT 模型用于移动端植物病害分类。\n*   **NLP 用于计算机故障报告分类 (15):** 使用 NLP 模型对用户报告进行分类以检测故障组件。\n*   **JARVIS-VLA (28):** 通过视觉语言后训练微调 VLM，使其能在 Minecraft 中执行超 1k 种原子任务。\n*   **CaKE (30):** 提出电路感知知识编辑方法，使 LLM 更新的知识能更好地用于多跳推理。\n*   **HiQ-Lip (32):** 首个量子-经典混合方法，利用相干伊辛机估计 ReLU 网络全局 Lipschitz 常数。\n*   **ADE-QVAET (33):** 结合量子变分自编码器-Transformer 和自适应差分进化优化，用于软件缺陷预测。\n*   **KGML-SM (34):** 知识引导的机器学习模型，结合土壤湿度预测干旱条件下玉米产量。\n*   **OmniGeo (35):** 提出面向地理空间 AI 的多模态大语言模型 OmniGeo。\n*   **结构化噪声掩蔽建模 (36):** 提出用结构化彩色噪声代替随机掩蔽，改进视频、音频等模态的自监督学习。\n*   **AI 增强工程教育 (37):** 探讨在嵌入式系统软件架构课程中使用 ChatGPT 等 AI 工具加速设计和原型制作。\n*   **DeepSeek-R1 在社科研究中的评估 (38):** 分析 DeepSeek-R1 在翻译、教育、逻辑推理、公卫政策等七个社科领域的应用潜力。\n*   **GenAI 助手审计 (40):** 审计发现 GenAI 浏览器助手存在追踪、画像和个性化问题，引发隐私担忧。\n*   **DGCL (41):** 扩散增强的图对比学习用于协同过滤，通过扩散模型生成更优的对比视图。\n*   **AI 智能体在加密货币领域的攻击 (42):** 揭示 AI 智能体在 Web3 生态中面临的上下文操纵攻击风险。\n*   **可选驾驶飞机的人机信任动态 (43):** 通过飞行测试案例研究人机协作中信任的形成、维持和减弱。\n*   **RRNCO (50):** 提出 RRNCO 框架和真实世界 VRP 数据集，弥合 NCO 在合成与真实 VRP 应用间的差距。\n*   **PolyTest (51):** 利用 LLM 的多语言和温度控制多样性生成更鲁棒的单元测试。\n*   **Gene42 (90):** 提出长程基因组基础模型 Gene42，使用密集注意力处理高达 192k bp 的上下文。\n*   **Chem42 (91):** 提出化学语言模型 Chem42，结合蛋白质模型 Prot42 进行靶点感知的配体生成。\n*   **TruthLens (97):** 提出可解释的 DeepFake 检测框架 TruthLens，能处理面部操纵和完全合成图像，并提供文本解释。\n*   **AutoRedTeamer (117):** 提出全自动红队测试框架，自主发现和集成新攻击向量评估 LLM 安全性。\n*   **用 LLM 解读人类行为动机 (118):** 展示如何通过变化提示词让 LLM 模拟人类在经济博弈中的行为，并反推其动机。\n\n**快速浏览:**\n\n*   **视觉想象力对 VLN 智能体的作用 (23):** 发现利用 T2I 模型生成的视觉子目标（想象）能略微提升 VLN 智能体性能。\n*   **RoboFactory (20):** 提出用于具身多智能体系统的组合约束概念和 RoboFactory 基准。\n*   **SA-Occ (22):** 首个卫星辅助的 3D 占用预测模型，融合卫星图像缓解 ego 视角遮挡等问题。\n*   **Effort 图 (24):** 提出 Effort 图方法，量化攻击者利用攻击性 AI 进行漏洞利用所需的工作量。\n*   **医学图像分割的三重编码器网络 (25):** 结合 CNN、FFC 和注意力机制处理视网膜 OCT 分割。\n*   **长 CoT 分解与蒸馏 (26):** 提出 DLCoT 框架优化长 CoT 推理的蒸馏过程。\n*   **RL 指导 DIDP (27):** 使用 RL（DQN 或 PPO）学习启发式函数来指导领域无关动态规划。\n*   **Grassmann 代数原理的神经网络 (29):** 探索量子幂等元代数与 Grassmann 代数在神经网络中的理论联系。\n*   **无实体存在的概念 (31):** 哲学探讨 AI 系统与意识、主观时间和自我的关系。\n*   **AI 驱动的软件质量保证 (33):** 提出 ADE-QVAET 模型用于软件缺陷预测。\n*   **AI 与开放科学支持 SRC 网络可持续性 (64):** 讨论西班牙 SKA 区域中心利用 AI 和开放科学减少环境影响。\n*   **不完整语句重写新方法 (61, 65):** 提出基于编辑操作的两阶段或多任务学习框架改进 IUR 任务。\n*   **Race-DiT (62):** 提出 Expert Race 路由策略，用于 MoE 扩散 Transformer 模型。\n*   **TSAN (63):** 时空注意力网络用于检测网络流量中的 DoS 攻击。\n*   **HICom (67):** 混合级指令注入策略，用于 MLLM 中的条件化视频 Token 压缩。\n*   **SISO (68):** 无需训练的单图迭代式主体驱动生成与编辑方法。\n*   **CGI (69):** 批评引导改进框架，利用 Critic 模型生成反馈指导 Actor 模型提升 LLM 智能体性能。\n*   **自主 AI 模仿者增加信息生态多样性 (70):** 模拟研究发现 AI 模仿在同质化信息环境（如新闻）中可增加多样性。\n*   **EEG 与语音融合的情感识别 (71):** 提出两步联合学习框架，即使推理时缺少 EEG 数据也能进行情感识别。\n*   **心脏病诊断特征选择策略 (72):** 评估不同特征选择方法对 ML/DL 模型心脏病预测性能的影响。\n*   **金融长三元组评估范式 (73):** 提出 EMS 评估方法，用于评估 LLM 在金融长问答场景中的表现。\n*   **金融分析中自解释可靠性研究 (74):** 定量评估 LM 自解释的事实性和因果性，及其与分类准确性的关系。\n*   **DVL 与深度学习预测 AUV 加速度 (75):** 使用深度学习从 DVL 速度测量中估计 AUV 加速度。\n*   **DIPLI (76):** 结合深度图像先验和 Lucky Imaging 的盲天文图像恢复方法。\n*   **InhibiDistilbert (77):** 将知识蒸馏用于基于 ReLU 和加法的 Inhibitor Attention Transformer。\n*   **多光谱视觉语言学习用于地球观测 (78):** 提出 Llama3-MS-CLIP，首个在多光谱数据上预训练的 VLM。\n*   **ANN 指导 SNN 蒸馏 (79):** 提出混合块替换策略，通过率基特征对齐进行 ANN-SNN 蒸馏。\n*   **无 GT 下 GAN 增强的仿真驱动 DNN 测试 (80):** 提出在无真值情况下，结合 GAN 和启发式适应度函数进行 DNN 测试输入生成。\n*   **用 NLI 估计图像真实性 (81):** 利用 LVLM 提取原子事实并通过 NLI 检测矛盾来评估图像真实性。\n*   **Unreal-MAP (82):** 基于虚幻引擎的通用多智能体强化学习平台。\n*   **V-Droid (83):** 验证器驱动的移动 GUI 任务自动化智能体。\n*   **自动持续学习框架 (84):** 提出自适应框架，用于持续指令调优，动态过滤数据。\n*   **DeCIL (85):** 基于去噪的收缩模仿学习，通过去噪机制增强状态转移映射的收缩性。\n*   **NTN (86):** 针对恶劣天气下 LiDAR 语义分割，强调安全关键的 \"things\" 类别。\n*   **通过伪标签增强特写新视角合成 (87):** 利用伪标签改进 NeRF/3DGS 在特写视角下的合成效果。\n*   **Jasmine (88):** 首个基于 SD 的自监督单目深度估计框架。\n*   **通过开放式叙事衡量 LLM 性别偏见 (89):** 使用自由形式故事生成揭示 LLM 在职业叙事中的性别偏见。\n*   **XAI 与异常检测预测小行星危害 (92):** 结合 ML、DL、XAI 和异常检测预测 NEA 危害。\n*   **EDQ (93):** 处理不规则时间的深度 Q 效应估计算法，用于评估干预时机和内容。\n*   **LeanTTA (94):** 无反向传播、无状态的量化测试时自适应方法，适用于边缘设备。\n*   **DeepPsy-Agent (96):** 结合心理学理论和深度学习的阶段感知、深度思考情感支持智能体系统。\n*   **WSN 电池退化主动管理 (98):** 使用 DRL 优化 WSN 占空比，实现电池分组更换。\n*   **Entro-duction (100):** 基于熵的探索引导方法，用于多步推理中动态调整探索深度。\n*   **GCS (101):** 全局割平面选择方法，用于增强混合整数规划求解。\n*   **PointFlowGMM (103):** 计算高效且识别友好的 3D 点云隐私保护框架。\n*   **反事实解释排序 (104):** 提出反事实解释的形式化定义、性质及排序方法。\n*   **Attention Pruning (105):** 通过代理模拟退火自动修复 LLM 的公平性偏差。\n*   **ChatGPT 用户体验测量快速回顾 (106):** 回顾现有量化评估 ChatGPT UX 的方法。\n*   **Video-VoT-R1 (107):** 集成图像打包和 AoE 架构的高效视频推理模型。\n*   **MoSE (108):** 协同专家混合模型，用于解决数据稀缺下的药物-靶点相互作用预测。\n*   **RLGDG (109):** 基于 RL 微调 LLM 进行游戏描述语言生成。\n*   **MobiFuse (110):** 通过跨域数据融合学习通用人类移动模式。\n*   **检测 LLM 撰写的同行评审 (111):** 提出通过水印和统计检验检测 LLM 生成的学术评审。\n*   **多文档摘要领域迁移失败分析 (112):** 分析 MDS 模型在零样本领域迁移设置下的失败原因。\n*   **生成式 AI 时代推进 BME 的 PBL 教学 (113):** 案例研究展示如何在 BME 教育中整合 AI 并改进 PBL 框架。\n*   **6G 智能体 AI 网络 (114):** 提出 AgentNet 框架，支持 6G 中智能体 AI 的交互、协作学习和知识转移。\n*   **儿童-机器人交互中的对话式学习 (115):** 提出混合方法生成个性化教育对话内容。\n*   **ATTENTION2D (116):** 通信高效的分布式自注意力机制。\n\n---\n\n希望这份快报能帮助你快速了解今日 arXiv 的精彩内容！",
  "papers": [
    {
      "arxiv_id": "2503.16743v1",
      "title": "SuperARC: A Test for General and Super Intelligence Based on First Principles of Recursion Theory and Algorithmic Probability",
      "title_zh": "SuperARC：基于递归理论与算法概率第一性原理的通用与超级智能测试",
      "authors": [
        "Alberto Hernández-Espinosa",
        "Luan Ozelim",
        "Felipe S. Abrahão",
        "Hector Zenil"
      ],
      "abstract": "We introduce an open-ended test grounded in algorithmic probability that can\navoid benchmark contamination in the quantitative evaluation of frontier models\nin the context of their Artificial General Intelligence (AGI) and\nSuperintelligence (ASI) claims. Unlike other tests, this test does not rely on\nstatistical compression methods (such as GZIP or LZW), which are more closely\nrelated to Shannon entropy than to Kolmogorov complexity. The test challenges\naspects related to features of intelligence of fundamental nature such as\nsynthesis and model creation in the context of inverse problems (generating new\nknowledge from observation). We argue that metrics based on model abstraction\nand optimal Bayesian inference for planning can provide a robust framework for\ntesting intelligence, including natural intelligence (human and animal), narrow\nAI, AGI, and ASI. Our results show no clear evidence of LLM convergence towards\na defined level of intelligence, particularly AGI or ASI. We found that LLM\nmodel versions tend to be fragile and incremental, as new versions may perform\nworse than older ones, with progress largely driven by the size of training\ndata. The results were compared with a hybrid neurosymbolic approach that\ntheoretically guarantees model convergence from optimal inference based on the\nprinciples of algorithmic probability and Kolmogorov complexity. The method\noutperforms LLMs in a proof-of-concept on short binary sequences. Our findings\nconfirm suspicions regarding the fundamental limitations of LLMs, exposing them\nas systems optimised for the perception of mastery over human language.\nProgress among different LLM versions from the same developers was found to be\ninconsistent and limited, particularly in the absence of a solid symbolic\ncounterpart.",
      "tldr_zh": "该研究提出了SuperARC测试，这是一种基于算法概率和递归理论第一原理的开放性测试，旨在评估前沿模型在人工通用智能(AGI)和超智能(ASI)方面的能力，同时避免基准污染问题。与依赖统计压缩方法的测试不同，SuperARC关注智能的核心特征，如合成和模型创建能力，并通过模型抽象和最优贝叶斯推理提供稳健的评估框架。实验结果表明，大型语言模型(LLMs)在智能水平上并未展现出明确的收敛趋势，其进展主要依赖于训练数据规模，且缺乏符号推理能力。相比之下，结合神经符号学的方法在理论保证下表现更优，进一步揭示了LLMs在本质上作为语言优化系统的局限性。",
      "categories": [
        "cs.AI",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.AI",
      "comment": "45 pages + Technical Supplementary Information, 71 pages total",
      "pdf_url": "http://arxiv.org/pdf/2503.16743v1",
      "published_date": "2025-03-20 23:11:30 UTC",
      "updated_date": "2025-03-20 23:11:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:13:16.849610"
    },
    {
      "arxiv_id": "2503.16734v1",
      "title": "Towards Agentic Recommender Systems in the Era of Multimodal Large Language Models",
      "title_zh": "迈向多模态大语言模型时代的自主推荐系统",
      "authors": [
        "Chengkai Huang",
        "Junda Wu",
        "Yu Xia",
        "Zixu Yu",
        "Ruhan Wang",
        "Tong Yu",
        "Ruiyi Zhang",
        "Ryan A. Rossi",
        "Branislav Kveton",
        "Dongruo Zhou",
        "Julian McAuley",
        "Lina Yao"
      ],
      "abstract": "Recent breakthroughs in Large Language Models (LLMs) have led to the\nemergence of agentic AI systems that extend beyond the capabilities of\nstandalone models. By empowering LLMs to perceive external environments,\nintegrate multimodal information, and interact with various tools, these\nagentic systems exhibit greater autonomy and adaptability across complex tasks.\nThis evolution brings new opportunities to recommender systems (RS): LLM-based\nAgentic RS (LLM-ARS) can offer more interactive, context-aware, and proactive\nrecommendations, potentially reshaping the user experience and broadening the\napplication scope of RS. Despite promising early results, fundamental\nchallenges remain, including how to effectively incorporate external knowledge,\nbalance autonomy with controllability, and evaluate performance in dynamic,\nmultimodal settings. In this perspective paper, we first present a systematic\nanalysis of LLM-ARS: (1) clarifying core concepts and architectures; (2)\nhighlighting how agentic capabilities -- such as planning, memory, and\nmultimodal reasoning -- can enhance recommendation quality; and (3) outlining\nkey research questions in areas such as safety, efficiency, and lifelong\npersonalization. We also discuss open problems and future directions, arguing\nthat LLM-ARS will drive the next wave of RS innovation. Ultimately, we foresee\na paradigm shift toward intelligent, autonomous, and collaborative\nrecommendation experiences that more closely align with users' evolving needs\nand complex decision-making processes.",
      "tldr_zh": "本文探讨了在多模态大语言模型（LLMs）时代下，向代理式推荐系统（LLM-ARS）发展的趋势。通过赋予LLMs感知外部环境、整合多模态信息及与工具交互的能力，LLM-ARS能够提供更互动、上下文感知和主动的推荐，从而提升用户体验并扩展推荐系统的应用范围。文章系统分析了LLM-ARS的核心概念、架构及其代理能力（如规划、记忆和多模态推理）如何提升推荐质量，并提出了安全性、效率和终身个性化等关键研究问题。作者认为，LLM-ARS将推动推荐系统的下一波创新，实现更智能、自主和协作的推荐体验。",
      "categories": [
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16734v1",
      "published_date": "2025-03-20 22:37:15 UTC",
      "updated_date": "2025-03-20 22:37:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:13:17.489721"
    },
    {
      "arxiv_id": "2503.16724v1",
      "title": "Towards Automated Semantic Interpretability in Reinforcement Learning via Vision-Language Models",
      "title_zh": "迈向基于视觉-语言模型的强化学习语义可解释性自动化",
      "authors": [
        "Zhaoxin Li",
        "Zhang Xi-Jia",
        "Batuhan Altundas",
        "Letian Chen",
        "Rohan Paleja",
        "Matthew Gombolay"
      ],
      "abstract": "Semantic Interpretability in Reinforcement Learning (RL) enables\ntransparency, accountability, and safer deployment by making the agent's\ndecisions understandable and verifiable. Achieving this, however, requires a\nfeature space composed of human-understandable concepts, which traditionally\nrely on human specification and fail to generalize to unseen environments. In\nthis work, we introduce Semantically Interpretable Reinforcement Learning with\nVision-Language Models Empowered Automation (SILVA), an automated framework\nthat leverages pre-trained vision-language models (VLM) for semantic feature\nextraction and interpretable tree-based models for policy optimization. SILVA\nfirst queries a VLM to identify relevant semantic features for an unseen\nenvironment, then extracts these features from the environment. Finally, it\ntrains an Interpretable Control Tree via RL, mapping the extracted features to\nactions in a transparent and interpretable manner. To address the computational\ninefficiency of extracting features directly with VLMs, we develop a feature\nextraction pipeline that generates a dataset for training a lightweight\nconvolutional network, which is subsequently used during RL. By leveraging VLMs\nto automate tree-based RL, SILVA removes the reliance on human annotation\npreviously required by interpretable models while also overcoming the inability\nof VLMs alone to generate valid robot policies, enabling semantically\ninterpretable reinforcement learning without human-in-the-loop.",
      "tldr_zh": "该研究提出了SILVA（Semantically Interpretable Reinforcement Learning with Vision-Language Models Empowered Automation），一种自动化框架，旨在解决强化学习（RL）中的语义可解释性问题。SILVA利用预训练的视觉语言模型（VLM）自动提取语义特征，并结合可解释的树模型进行策略优化，从而生成透明且可理解的决策映射。此外，研究开发了一种特征提取管道，通过训练轻量级卷积网络提高计算效率，减少对人工标注的依赖。实验表明，SILVA能够在未见环境中实现语义可解释的强化学习，克服了传统方法在泛化性和效率上的不足。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16724v1",
      "published_date": "2025-03-20 21:53:19 UTC",
      "updated_date": "2025-03-20 21:53:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:13:40.652224"
    },
    {
      "arxiv_id": "2503.17410v1",
      "title": "Comparative Analysis of Deep Learning Models for Real-World ISP Network Traffic Forecasting",
      "title_zh": "深度学习模型在真实 ISP 网络流量预测中的对比分析",
      "authors": [
        "Josef Koumar",
        "Timotej Smoleň",
        "Kamil Jeřábek",
        "Tomáš Čejka"
      ],
      "abstract": "Accurate network traffic forecasting is essential for Internet Service\nProviders (ISP) to optimize resources, enhance user experience, and mitigate\nanomalies. This study evaluates state-of-the-art deep learning models on\nCESNET-TimeSeries24, a recently published, comprehensive real-world network\ntraffic dataset from the ISP network CESNET3 spanning multivariate time series\nover 40 weeks. Our findings highlight the balance between prediction accuracy\nand computational efficiency across different levels of network granularity.\nAdditionally, this work establishes a reproducible methodology that facilitates\ndirect comparison of existing approaches, explores their strengths and\nweaknesses, and provides a benchmark for future studies using this dataset.",
      "tldr_zh": "本研究对比了多种深度学习模型在真实ISP网络流量预测中的表现，基于CESNET-TimeSeries24数据集进行实验。结果表明，不同模型在预测精度与计算效率之间存在权衡，尤其是在不同网络粒度下的表现差异显著。研究还提出了一种可重复的方法论，为未来使用该数据集的研究提供了基准，并深入探讨了现有方法的优缺点。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.17410v1",
      "published_date": "2025-03-20 21:04:20 UTC",
      "updated_date": "2025-03-20 21:04:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:13:31.835810"
    },
    {
      "arxiv_id": "2503.16709v1",
      "title": "QuartDepth: Post-Training Quantization for Real-Time Depth Estimation on the Edge",
      "title_zh": "QuartDepth：面向边缘设备实时深度估计的训练后量化技术",
      "authors": [
        "Xuan Shen",
        "Weize Ma",
        "Jing Liu",
        "Changdi Yang",
        "Rui Ding",
        "Quanyi Wang",
        "Henghui Ding",
        "Wei Niu",
        "Yanzhi Wang",
        "Pu Zhao",
        "Jun Lin",
        "Jiuxiang Gu"
      ],
      "abstract": "Monocular Depth Estimation (MDE) has emerged as a pivotal task in computer\nvision, supporting numerous real-world applications. However, deploying\naccurate depth estimation models on resource-limited edge devices, especially\nApplication-Specific Integrated Circuits (ASICs), is challenging due to the\nhigh computational and memory demands. Recent advancements in foundational\ndepth estimation deliver impressive results but further amplify the difficulty\nof deployment on ASICs. To address this, we propose QuartDepth which adopts\npost-training quantization to quantize MDE models with hardware accelerations\nfor ASICs. Our approach involves quantizing both weights and activations to\n4-bit precision, reducing the model size and computation cost. To mitigate the\nperformance degradation, we introduce activation polishing and compensation\nalgorithm applied before and after activation quantization, as well as a weight\nreconstruction method for minimizing errors in weight quantization.\nFurthermore, we design a flexible and programmable hardware accelerator by\nsupporting kernel fusion and customized instruction programmability, enhancing\nthroughput and efficiency. Experimental results demonstrate that our framework\nachieves competitive accuracy while enabling fast inference and higher energy\nefficiency on ASICs, bridging the gap between high-performance depth estimation\nand practical edge-device applicability. Code:\nhttps://github.com/shawnricecake/quart-depth",
      "tldr_zh": "该研究提出了QuartDepth，一种针对单目深度估计(MDE)模型的后训练量化方法，旨在实现资源受限的边缘设备上的实时深度估计。通过将权重和激活量化为4位精度，结合激活抛光和补偿算法以及权重重建方法，显著减少了模型大小和计算成本。此外，研究设计了支持核融合和定制指令可编程性的硬件加速器，提高了吞吐量和能效。实验表明，该方法在保持竞争力的同时实现了快速推理和更高的能效，弥合了高性能深度估计与边缘设备实际应用之间的差距。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.16709v1",
      "published_date": "2025-03-20 21:03:10 UTC",
      "updated_date": "2025-03-20 21:03:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:13:38.279780"
    },
    {
      "arxiv_id": "2503.16692v1",
      "title": "Limits of trust in medical AI",
      "title_zh": "医疗AI的信任界限",
      "authors": [
        "Joshua Hatherley"
      ],
      "abstract": "Artificial intelligence (AI) is expected to revolutionize the practice of\nmedicine. Recent advancements in the field of deep learning have demonstrated\nsuccess in a variety of clinical tasks: detecting diabetic retinopathy from\nimages, predicting hospital readmissions, aiding in the discovery of new drugs,\netc. AI's progress in medicine, however, has led to concerns regarding the\npotential effects of this technology upon relationships of trust in clinical\npractice. In this paper, I will argue that there is merit to these concerns,\nsince AI systems can be relied upon, and are capable of reliability, but cannot\nbe trusted, and are not capable of trustworthiness. Insofar as patients are\nrequired to rely upon AI systems for their medical decision-making, there is\npotential for this to produce a deficit of trust in relationships in clinical\npractice.",
      "tldr_zh": "本文探讨了医疗人工智能(AI)在临床实践中对信任关系的影响。作者指出，尽管AI系统在糖尿病视网膜病变检测、医院再入院预测等任务中展现出可靠性，但它们无法真正获得信任。当患者依赖AI进行医疗决策时，可能会导致临床实践中信任关系的缺失。这一观点强调了AI在医疗领域应用的潜在伦理挑战。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY",
        "J.3; K.4"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.16692v1",
      "published_date": "2025-03-20 20:22:38 UTC",
      "updated_date": "2025-03-20 20:22:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:13:59.197169"
    },
    {
      "arxiv_id": "2503.16683v1",
      "title": "GAIR: Improving Multimodal Geo-Foundation Model with Geo-Aligned Implicit Representations",
      "title_zh": "GAIR：通过地理对齐隐式表征提升多模态地理基础模型",
      "authors": [
        "Zeping Liu",
        "Fan Zhang",
        "Junfeng Jiao",
        "Ni Lao",
        "Gengchen Mai"
      ],
      "abstract": "Advancements in vision and language foundation models have inspired the\ndevelopment of geo-foundation models (GeoFMs), enhancing performance across\ndiverse geospatial tasks. However, many existing GeoFMs primarily focus on\noverhead remote sensing (RS) data while neglecting other data modalities such\nas ground-level imagery. A key challenge in multimodal GeoFM development is to\nexplicitly model geospatial relationships across modalities, which enables\ngeneralizability across tasks, spatial scales, and temporal contexts. To\naddress these limitations, we propose GAIR, a novel multimodal GeoFM\narchitecture integrating overhead RS data, street view (SV) imagery, and their\ngeolocation metadata. We utilize three factorized neural encoders to project an\nSV image, its geolocation, and an RS image into the embedding space. The SV\nimage needs to be located within the RS image's spatial footprint but does not\nneed to be at its geographic center. In order to geographically align the SV\nimage and RS image, we propose a novel implicit neural representations (INR)\nmodule that learns a continuous RS image representation and looks up the RS\nembedding at the SV image's geolocation. Next, these geographically aligned SV\nembedding, RS embedding, and location embedding are trained with contrastive\nlearning objectives from unlabeled data. We evaluate GAIR across 10 geospatial\ntasks spanning RS image-based, SV image-based, and location embedding-based\nbenchmarks. Experimental results demonstrate that GAIR outperforms\nstate-of-the-art GeoFMs and other strong baselines, highlighting its\neffectiveness in learning generalizable and transferable geospatial\nrepresentations.",
      "tldr_zh": "本研究提出GAIR，一种新型多模态地理基础模型(GeoFM)，通过地理对齐的隐式表示(INR)模块整合了遥感(RS)图像、街景(SV)图像及其地理位置元数据。该模型利用三个分解的神经编码器将SV图像、其地理位置和RS图像投影到嵌入空间，并通过INR模块学习连续的RS图像表示，从而实现SV图像与RS图像的地理对齐。通过对比学习目标训练，GAIR在10项地理空间任务上均优于现有最优的GeoFM，展示了其在学习通用性和可迁移性地理表示方面的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.4.10"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.16683v1",
      "published_date": "2025-03-20 19:59:39 UTC",
      "updated_date": "2025-03-20 19:59:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:13:49.792551"
    },
    {
      "arxiv_id": "2503.16681v1",
      "title": "GauRast: Enhancing GPU Triangle Rasterizers to Accelerate 3D Gaussian Splatting",
      "title_zh": "GauRast：增强GPU三角形光栅化器以加速3D高斯泼溅渲染",
      "authors": [
        "Sixu Li",
        "Ben Keller",
        "Yingyan Celine Lin",
        "Brucek Khailany"
      ],
      "abstract": "3D intelligence leverages rich 3D features and stands as a promising frontier\nin AI, with 3D rendering fundamental to many downstream applications. 3D\nGaussian Splatting (3DGS), an emerging high-quality 3D rendering method,\nrequires significant computation, making real-time execution on existing\nGPU-equipped edge devices infeasible. Previous efforts to accelerate 3DGS rely\non dedicated accelerators that require substantial integration overhead and\nhardware costs. This work proposes an acceleration strategy that leverages the\nsimilarities between the 3DGS pipeline and the highly optimized conventional\ngraphics pipeline in modern GPUs. Instead of developing a dedicated\naccelerator, we enhance existing GPU rasterizer hardware to efficiently support\n3DGS operations. Our results demonstrate a 23$\\times$ increase in processing\nspeed and a 24$\\times$ reduction in energy consumption, with improvements\nyielding 6$\\times$ faster end-to-end runtime for the original 3DGS algorithm\nand 4$\\times$ for the latest efficiency-improved pipeline, achieving 24 FPS and\n46 FPS respectively. These enhancements incur only a minimal area overhead of\n0.2\\% relative to the entire SoC chip area, underscoring the practicality and\nefficiency of our approach for enabling 3DGS rendering on resource-constrained\nplatforms.",
      "tldr_zh": "该研究提出GauRast，通过利用3D Gaussian Splatting（3DGS）渲染管线与传统GPU图形管线的相似性，优化现有GPU光栅化硬件以加速3DGS计算。相比专用加速器，该方法在片上系统（SoC）中仅增加0.2%的面积开销，实现了23倍的处理速度提升和24倍的能耗降低，使原始3DGS算法的端到端运行速度提高6倍，最新优化管线的帧率分别达到24 FPS和46 FPS，为资源受限平台实现实时3DGS渲染提供了高效解决方案。",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.GR",
      "comment": "DAC 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.16681v1",
      "published_date": "2025-03-20 19:54:05 UTC",
      "updated_date": "2025-03-20 19:54:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:14:09.735108"
    },
    {
      "arxiv_id": "2503.16679v1",
      "title": "Echoes of Power: Investigating Geopolitical Bias in US and China Large Language Models",
      "title_zh": "权力回响：探究美国与中国大型语言模型中的地缘政治偏见",
      "authors": [
        "Andre G. C. Pacheco",
        "Athus Cavalini",
        "Giovanni Comarela"
      ],
      "abstract": "Large Language Models (LLMs) have emerged as powerful tools for generating\nhuman-like text, transforming human-machine interactions. However, their\nwidespread adoption has raised concerns about their potential to influence\npublic opinion and shape political narratives. In this work, we investigate the\ngeopolitical biases in US and Chinese LLMs, focusing on how these models\nrespond to questions related to geopolitics and international relations. We\ncollected responses from ChatGPT and DeepSeek to a set of geopolitical\nquestions and evaluated their outputs through both qualitative and quantitative\nanalyses. Our findings show notable biases in both models, reflecting distinct\nideological perspectives and cultural influences. However, despite these\nbiases, for a set of questions, the models' responses are more aligned than\nexpected, indicating that they can address sensitive topics without necessarily\npresenting directly opposing viewpoints. This study highlights the potential of\nLLMs to shape public discourse and underscores the importance of critically\nassessing AI-generated content, particularly in politically sensitive contexts.",
      "tldr_zh": "本研究探讨了美国和中国的LLM（如ChatGPT和DeepSeek）在地缘政治问题上的偏见。通过定性和定量分析，研究发现这些模型在回答地缘政治和国际关系问题时表现出显著的意识形态和文化偏见。然而，在某些问题上，模型的回答比预期更为一致，表明它们能够处理敏感话题而无需呈现直接对立的观点。研究强调了LLM在塑造公共话语中的潜力，并呼吁对AI生成内容，特别是在政治敏感背景下的内容进行批判性评估。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16679v1",
      "published_date": "2025-03-20 19:53:10 UTC",
      "updated_date": "2025-03-20 19:53:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:14:12.216813"
    },
    {
      "arxiv_id": "2503.16672v1",
      "title": "Accelerating Transformer Inference and Training with 2:4 Activation Sparsity",
      "title_zh": "利用2:4激活稀疏性加速Transformer推理与训练",
      "authors": [
        "Daniel Haziza",
        "Timothy Chou",
        "Dhruv Choudhary",
        "Luca Wehrstedt",
        "Francisco Massa",
        "Jiecao Yu",
        "Geonhwa Jeong",
        "Supriya Rao",
        "Patrick Labatut",
        "Jesse Cai"
      ],
      "abstract": "In this paper, we demonstrate how to leverage 2:4 sparsity, a popular\nhardware-accelerated GPU sparsity pattern, to activations to accelerate large\nlanguage model training and inference. Crucially we exploit the intrinsic\nsparsity found in Squared-ReLU activations to provide this acceleration with no\naccuracy loss. Our approach achieves up to 1.3x faster Feed Forward Network\n(FFNs) in both the forwards and backwards pass. This work highlights the\npotential for sparsity to play a key role in accelerating large language model\ntraining and inference.",
      "tldr_zh": "本研究提出了一种利用2:4稀疏性加速Transformer模型训练和推理的方法，重点针对大语言模型（LLMs）。通过利用Squared-ReLU激活函数中固有的稀疏性，该方法在不损失精度的情况下，实现了前馈网络（FFNs）前向和反向传播速度最高提升1.3倍。这一成果表明，稀疏性在大语言模型的高效训练和推理中具有重要潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16672v1",
      "published_date": "2025-03-20 19:37:12 UTC",
      "updated_date": "2025-03-20 19:37:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:14:17.395310"
    },
    {
      "arxiv_id": "2503.17408v1",
      "title": "Leveraging OpenFlamingo for Multimodal Embedding Analysis of C2C Car Parts Data",
      "title_zh": "利用OpenFlamingo进行C2C汽车零件数据的多模态嵌入分析",
      "authors": [
        "Maisha Binte Rashid",
        "Pablo Rivas"
      ],
      "abstract": "In this paper, we aim to investigate the capabilities of multimodal machine\nlearning models, particularly the OpenFlamingo model, in processing a\nlarge-scale dataset of consumer-to-consumer (C2C) online posts related to car\nparts. We have collected data from two platforms, OfferUp and Craigslist,\nresulting in a dataset of over 1.2 million posts with their corresponding\nimages. The OpenFlamingo model was used to extract embeddings for the text and\nimage of each post. We used $k$-means clustering on the joint embeddings to\nidentify underlying patterns and commonalities among the posts. We have found\nthat most clusters contain a pattern, but some clusters showed no internal\npatterns. The results provide insight into the fact that OpenFlamingo can be\nused for finding patterns in large datasets but needs some modification in the\narchitecture according to the dataset.",
      "tldr_zh": "本研究探索了多模态机器学习模型OpenFlamingo在处理消费者间(C2C)汽车配件在线帖子大规模数据集中的能力。研究从OfferUp和Craigslist平台收集了超过120万条包含文本和图像的帖子数据，利用OpenFlamingo提取文本和图像的联合嵌入，并通过$k$-means聚类分析潜在模式。结果表明，大多数聚类显示出一定的模式，但也有部分聚类缺乏内部一致性。研究揭示了OpenFlamingo在大型数据集模式发现中的潜力，同时指出需要根据数据集特点对模型架构进行调整。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.10; I.2.7; I.5; H.3.3; H.3.1"
      ],
      "primary_category": "cs.LG",
      "comment": "The 26th International Conference on Artificial Intelligence\n  (ICAI'24: July 22-25, 2024; Las Vegas, USA)",
      "pdf_url": "http://arxiv.org/pdf/2503.17408v1",
      "published_date": "2025-03-20 19:35:15 UTC",
      "updated_date": "2025-03-20 19:35:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:14:38.999412"
    },
    {
      "arxiv_id": "2503.16669v1",
      "title": "Aligning Text-to-Music Evaluation with Human Preferences",
      "title_zh": "使文本到音乐评估与人类偏好保持一致",
      "authors": [
        "Yichen Huang",
        "Zachary Novack",
        "Koichi Saito",
        "Jiatong Shi",
        "Shinji Watanabe",
        "Yuki Mitsufuji",
        "John Thickstun",
        "Chris Donahue"
      ],
      "abstract": "Despite significant recent advances in generative acoustic text-to-music\n(TTM) modeling, robust evaluation of these models lags behind, relying in\nparticular on the popular Fr\\'echet Audio Distance (FAD). In this work, we\nrigorously study the design space of reference-based divergence metrics for\nevaluating TTM models through (1) designing four synthetic meta-evaluations to\nmeasure sensitivity to particular musical desiderata, and (2) collecting and\nevaluating on MusicPrefs, the first open-source dataset of human preferences\nfor TTM systems. We find that not only is the standard FAD setup inconsistent\non both synthetic and human preference data, but that nearly all existing\nmetrics fail to effectively capture desiderata, and are only weakly correlated\nwith human perception. We propose a new metric, the MAUVE Audio Divergence\n(MAD), computed on representations from a self-supervised audio embedding\nmodel. We find that this metric effectively captures diverse musical desiderata\n(average rank correlation 0.84 for MAD vs. 0.49 for FAD and also correlates\nmore strongly with MusicPrefs (0.62 vs. 0.14).",
      "tldr_zh": "本研究针对生成式文本到音乐（TTM）模型的评估问题，提出了基于人类偏好的新评估方法。研究发现，现有的Fr\\'echet Audio Distance (FAD)等指标在合成数据和人类偏好数据上表现不一致，且难以有效捕捉音乐特性。为此，研究团队提出了MAUVE Audio Divergence (MAD)新指标，基于自监督音频嵌入模型计算。实验表明，MAD在捕捉多样化音乐特性方面表现优异（平均秩相关性0.84），且与人类偏好数据集MusicPrefs的相关性显著高于FAD（0.62 vs. 0.14），为TTM模型评估提供了更可靠的基准。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16669v1",
      "published_date": "2025-03-20 19:31:04 UTC",
      "updated_date": "2025-03-20 19:31:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:14:53.942924"
    },
    {
      "arxiv_id": "2503.16668v1",
      "title": "Code Evolution Graphs: Understanding Large Language Model Driven Design of Algorithms",
      "title_zh": "代码演化图：理解大语言模型驱动的算法设计",
      "authors": [
        "Niki van Stein",
        "Anna V. Kononova",
        "Lars Kotthoff",
        "Thomas Bäck"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated great promise in generating\ncode, especially when used inside an evolutionary computation framework to\niteratively optimize the generated algorithms. However, in some cases they fail\nto generate competitive algorithms or the code optimization stalls, and we are\nleft with no recourse because of a lack of understanding of the generation\nprocess and generated codes. We present a novel approach to mitigate this\nproblem by enabling users to analyze the generated codes inside the\nevolutionary process and how they evolve over repeated prompting of the LLM. We\nshow results for three benchmark problem classes and demonstrate novel\ninsights. In particular, LLMs tend to generate more complex code with repeated\nprompting, but additional complexity can hurt algorithmic performance in some\ncases. Different LLMs have different coding ``styles'' and generated code tends\nto be dissimilar to other LLMs. These two findings suggest that using different\nLLMs inside the code evolution frameworks might produce higher performing code\nthan using only one LLM.",
      "tldr_zh": "本研究提出了代码演化图（Code Evolution Graphs），用于分析大型语言模型（LLMs）在进化计算框架中生成和优化算法的过程。研究发现，随着多次提示，LLMs 生成的代码趋向复杂化，但复杂度的增加在某些情况下会损害算法性能。此外，不同 LLMs 具有独特的编码“风格”，生成的代码差异显著，这表明在代码进化框架中结合多种 LLMs 可能比单一 LLM 生成更高性能的代码。该方法为理解 LLMs 驱动的算法设计提供了新视角。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "Accepted at GECCO 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.16668v1",
      "published_date": "2025-03-20 19:30:22 UTC",
      "updated_date": "2025-03-20 19:30:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:14:57.032177"
    },
    {
      "arxiv_id": "2503.16628v1",
      "title": "MobilePlantViT: A Mobile-friendly Hybrid ViT for Generalized Plant Disease Image Classification",
      "title_zh": "MobilePlantViT：面向移动设备的混合ViT模型，用于通用植物病害图像分类",
      "authors": [
        "Moshiur Rahman Tonmoy",
        "Md. Mithun Hossain",
        "Nilanjan Dey",
        "M. F. Mridha"
      ],
      "abstract": "Plant diseases significantly threaten global food security by reducing crop\nyields and undermining agricultural sustainability. AI-driven automated\nclassification has emerged as a promising solution, with deep learning models\ndemonstrating impressive performance in plant disease identification. However,\ndeploying these models on mobile and edge devices remains challenging due to\nhigh computational demands and resource constraints, highlighting the need for\nlightweight, accurate solutions for accessible smart agriculture systems. To\naddress this, we propose MobilePlantViT, a novel hybrid Vision Transformer\n(ViT) architecture designed for generalized plant disease classification, which\noptimizes resource efficiency while maintaining high performance. Extensive\nexperiments across diverse plant disease datasets of varying scales show our\nmodel's effectiveness and strong generalizability, achieving test accuracies\nranging from 80% to over 99%. Notably, with only 0.69 million parameters, our\narchitecture outperforms the smallest versions of MobileViTv1 and MobileViTv2,\ndespite their higher parameter counts. These results underscore the potential\nof our approach for real-world, AI-powered automated plant disease\nclassification in sustainable and resource-efficient smart agriculture systems.\nAll codes will be available in the GitHub repository:\nhttps://github.com/moshiurtonmoy/MobilePlantViT",
      "tldr_zh": "该研究提出了一种轻量级混合Vision Transformer（ViT）模型MobilePlantViT，专为植物病害图像分类设计，适用于移动和边缘设备。该模型在资源受限条件下优化了计算效率，同时保持了高分类性能，在多个数据集上测试准确率达到80%至99%以上。尽管仅包含69万参数，MobilePlantViT在性能上优于参数更多的MobileViTv1和MobileViTv2，为可持续和资源高效的智能农业系统提供了可行的AI解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Submitted to a journal for peer-review under IEEE Transactions series",
      "pdf_url": "http://arxiv.org/pdf/2503.16628v1",
      "published_date": "2025-03-20 18:34:02 UTC",
      "updated_date": "2025-03-20 18:34:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:14:58.201147"
    },
    {
      "arxiv_id": "2503.16614v1",
      "title": "Classification of User Reports for Detection of Faulty Computer Components using NLP Models: A Case Study",
      "title_zh": "基于NLP模型的计算机故障部件检测用户报告分类：案例研究",
      "authors": [
        "Maria de Lourdes M. Silva",
        "André L. C. Mendonça",
        "Eduardo R. D. Neto",
        "Iago C. Chaves",
        "Felipe T. Brito",
        "Victor A. E. Farias",
        "Javam C. Machado"
      ],
      "abstract": "Computer manufacturers typically offer platforms for users to report faults.\nHowever, there remains a significant gap in these platforms' ability to\neffectively utilize textual reports, which impedes users from describing their\nissues in their own words. In this context, Natural Language Processing (NLP)\noffers a promising solution, by enabling the analysis of user-generated text.\nThis paper presents an innovative approach that employs NLP models to classify\nuser reports for detecting faulty computer components, such as CPU, memory,\nmotherboard, video card, and more. In this work, we build a dataset of 341 user\nreports obtained from many sources. Additionally, through extensive\nexperimental evaluation, our approach achieved an accuracy of 79% with our\ndataset.",
      "tldr_zh": "本研究提出了一种基于自然语言处理（NLP）的创新方法，用于分类用户报告以检测计算机故障组件（如CPU、内存、主板、显卡等）。通过构建包含341份用户报告的数据集，并经过广泛的实验评估，该方法在数据集上达到了79%的准确率，为计算机制造商更有效地利用用户文本报告提供了解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.16614v1",
      "published_date": "2025-03-20 18:11:26 UTC",
      "updated_date": "2025-03-20 18:11:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:15:08.189659"
    },
    {
      "arxiv_id": "2503.16611v1",
      "title": "A Recipe for Generating 3D Worlds From a Single Image",
      "title_zh": "从单张图像生成3D世界的方案",
      "authors": [
        "Katja Schwarz",
        "Denys Rozumnyi",
        "Samuel Rota Bulò",
        "Lorenzo Porzi",
        "Peter Kontschieder"
      ],
      "abstract": "We introduce a recipe for generating immersive 3D worlds from a single image\nby framing the task as an in-context learning problem for 2D inpainting models.\nThis approach requires minimal training and uses existing generative models.\nOur process involves two steps: generating coherent panoramas using a\npre-trained diffusion model and lifting these into 3D with a metric depth\nestimator. We then fill unobserved regions by conditioning the inpainting model\non rendered point clouds, requiring minimal fine-tuning. Tested on both\nsynthetic and real images, our method produces high-quality 3D environments\nsuitable for VR display. By explicitly modeling the 3D structure of the\ngenerated environment from the start, our approach consistently outperforms\nstate-of-the-art, video synthesis-based methods along multiple quantitative\nimage quality metrics. Project Page: https://katjaschwarz.github.io/worlds/",
      "tldr_zh": "该研究提出了一种从单张图像生成沉浸式3D世界的创新方法，将其构建为2D图像修复模型的情境学习问题。该方法利用预训练的扩散模型生成连贯的全景图，并通过度量深度估计器将其转换为3D结构，再基于渲染的点云填充未观察区域，仅需少量微调。实验表明，该方法在合成和真实图像上均能生成高质量的3D环境，适用于VR显示，并在多项图像质量指标上优于基于视频合成的最先进方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16611v1",
      "published_date": "2025-03-20 18:06:12 UTC",
      "updated_date": "2025-03-20 18:06:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:15:10.236703"
    },
    {
      "arxiv_id": "2503.16421v1",
      "title": "MagicMotion: Controllable Video Generation with Dense-to-Sparse Trajectory Guidance",
      "title_zh": "MagicMotion：基于稠密至稀疏轨迹引导的可控视频生成",
      "authors": [
        "Quanhao Li",
        "Zhen Xing",
        "Rui Wang",
        "Hui Zhang",
        "Qi Dai",
        "Zuxuan Wu"
      ],
      "abstract": "Recent advances in video generation have led to remarkable improvements in\nvisual quality and temporal coherence. Upon this, trajectory-controllable video\ngeneration has emerged to enable precise object motion control through\nexplicitly defined spatial paths. However, existing methods struggle with\ncomplex object movements and multi-object motion control, resulting in\nimprecise trajectory adherence, poor object consistency, and compromised visual\nquality. Furthermore, these methods only support trajectory control in a single\nformat, limiting their applicability in diverse scenarios. Additionally, there\nis no publicly available dataset or benchmark specifically tailored for\ntrajectory-controllable video generation, hindering robust training and\nsystematic evaluation. To address these challenges, we introduce MagicMotion, a\nnovel image-to-video generation framework that enables trajectory control\nthrough three levels of conditions from dense to sparse: masks, bounding boxes,\nand sparse boxes. Given an input image and trajectories, MagicMotion seamlessly\nanimates objects along defined trajectories while maintaining object\nconsistency and visual quality. Furthermore, we present MagicData, a\nlarge-scale trajectory-controlled video dataset, along with an automated\npipeline for annotation and filtering. We also introduce MagicBench, a\ncomprehensive benchmark that assesses both video quality and trajectory control\naccuracy across different numbers of objects. Extensive experiments demonstrate\nthat MagicMotion outperforms previous methods across various metrics. Our\nproject page are publicly available at\nhttps://quanhaol.github.io/magicmotion-site.",
      "tldr_zh": "本研究提出了MagicMotion，一种基于从密集到稀疏轨迹引导的图像到视频生成框架，解决了现有方法在复杂物体运动和多物体运动控制上的不足。该框架通过三种条件（掩码、边界框和稀疏框）实现精确的轨迹控制，同时保持物体一致性和视觉质量。此外，研究还构建了MagicData数据集和MagicBench基准测试，用于系统评估视频质量和轨迹控制精度。实验表明，MagicMotion在各项指标上均优于现有方法，为轨迹可控视频生成提供了新的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16421v1",
      "published_date": "2025-03-20 17:59:42 UTC",
      "updated_date": "2025-03-20 17:59:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:15:31.680189"
    },
    {
      "arxiv_id": "2503.16416v1",
      "title": "Survey on Evaluation of LLM-based Agents",
      "title_zh": "基于大语言模型的智能体评估综述",
      "authors": [
        "Asaf Yehudai",
        "Lilach Eden",
        "Alan Li",
        "Guy Uziel",
        "Yilun Zhao",
        "Roy Bar-Haim",
        "Arman Cohan",
        "Michal Shmueli-Scheuer"
      ],
      "abstract": "The emergence of LLM-based agents represents a paradigm shift in AI, enabling\nautonomous systems to plan, reason, use tools, and maintain memory while\ninteracting with dynamic environments. This paper provides the first\ncomprehensive survey of evaluation methodologies for these increasingly capable\nagents. We systematically analyze evaluation benchmarks and frameworks across\nfour critical dimensions: (1) fundamental agent capabilities, including\nplanning, tool use, self-reflection, and memory; (2) application-specific\nbenchmarks for web, software engineering, scientific, and conversational\nagents; (3) benchmarks for generalist agents; and (4) frameworks for evaluating\nagents. Our analysis reveals emerging trends, including a shift toward more\nrealistic, challenging evaluations with continuously updated benchmarks. We\nalso identify critical gaps that future research must address-particularly in\nassessing cost-efficiency, safety, and robustness, and in developing\nfine-grained, and scalable evaluation methods. This survey maps the rapidly\nevolving landscape of agent evaluation, reveals the emerging trends in the\nfield, identifies current limitations, and proposes directions for future\nresearch.",
      "tldr_zh": "本文首次全面综述了基于大语言模型（LLM）的智能体评估方法，系统分析了其在四个关键维度的评估基准与框架：（1）基础能力，如规划、工具使用、自我反思和记忆；（2）特定应用领域的基准，包括网络、软件工程、科学和对话智能体；（3）通用智能体的基准；（4）评估框架。研究发现，评估趋势正逐渐转向更现实、更具挑战性的动态更新基准。同时，文章指出了未来研究需解决的关键问题，包括成本效率、安全性和鲁棒性评估，以及开发细粒度和可扩展的评估方法。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16416v1",
      "published_date": "2025-03-20 17:59:23 UTC",
      "updated_date": "2025-03-20 17:59:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:15:50.625839"
    },
    {
      "arxiv_id": "2503.16412v1",
      "title": "DreamTexture: Shape from Virtual Texture with Analysis by Augmentation",
      "title_zh": "DreamTexture：基于虚拟纹理的形状分析与增强",
      "authors": [
        "Ananta R. Bhattarai",
        "Xingzhe He",
        "Alla Sheffer",
        "Helge Rhodin"
      ],
      "abstract": "DreamFusion established a new paradigm for unsupervised 3D reconstruction\nfrom virtual views by combining advances in generative models and\ndifferentiable rendering. However, the underlying multi-view rendering, along\nwith supervision from large-scale generative models, is computationally\nexpensive and under-constrained. We propose DreamTexture, a novel\nShape-from-Virtual-Texture approach that leverages monocular depth cues to\nreconstruct 3D objects. Our method textures an input image by aligning a\nvirtual texture with the real depth cues in the input, exploiting the inherent\nunderstanding of monocular geometry encoded in modern diffusion models. We then\nreconstruct depth from the virtual texture deformation with a new conformal map\noptimization, which alleviates memory-intensive volumetric representations. Our\nexperiments reveal that generative models possess an understanding of monocular\nshape cues, which can be extracted by augmenting and aligning texture cues -- a\nnovel monocular reconstruction paradigm that we call Analysis by Augmentation.",
      "tldr_zh": "该研究提出了DreamTexture，一种基于虚拟纹理的形状重建方法，通过分析与增强技术（Analysis by Augmentation）实现单目3D重建。该方法利用现代扩散模型对单目几何的理解，将虚拟纹理与输入图像的真实深度线索对齐，并通过新的共形映射优化从虚拟纹理变形中重建深度，避免了内存密集型的体积表示。实验表明，生成模型具备对单目形状线索的理解能力，通过增强和对齐纹理线索，实现了一种新的单目重建范式。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://anantarb.github.io/dreamtexture/",
      "pdf_url": "http://arxiv.org/pdf/2503.16412v1",
      "published_date": "2025-03-20 17:59:12 UTC",
      "updated_date": "2025-03-20 17:59:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:15:44.567790"
    },
    {
      "arxiv_id": "2503.16408v1",
      "title": "RoboFactory: Exploring Embodied Agent Collaboration with Compositional Constraints",
      "title_zh": "RoboFactory：基于组合约束的具身智能体协作探索",
      "authors": [
        "Yiran Qin",
        "Li Kang",
        "Xiufeng Song",
        "Zhenfei Yin",
        "Xiaohong Liu",
        "Xihui Liu",
        "Ruimao Zhang",
        "Lei Bai"
      ],
      "abstract": "Designing effective embodied multi-agent systems is critical for solving\ncomplex real-world tasks across domains. Due to the complexity of multi-agent\nembodied systems, existing methods fail to automatically generate safe and\nefficient training data for such systems. To this end, we propose the concept\nof compositional constraints for embodied multi-agent systems, addressing the\nchallenges arising from collaboration among embodied agents. We design various\ninterfaces tailored to different types of constraints, enabling seamless\ninteraction with the physical world. Leveraging compositional constraints and\nspecifically designed interfaces, we develop an automated data collection\nframework for embodied multi-agent systems and introduce the first benchmark\nfor embodied multi-agent manipulation, RoboFactory. Based on RoboFactory\nbenchmark, we adapt and evaluate the method of imitation learning and analyzed\nits performance in different difficulty agent tasks. Furthermore, we explore\nthe architectures and training strategies for multi-agent imitation learning,\naiming to build safe and efficient embodied multi-agent systems.",
      "tldr_zh": "该研究提出了RoboFactory，一个专注于具身多智能体协作的自动化数据收集框架和基准测试。通过引入组合约束(compositional constraints)和定制化接口，解决了现有方法在生成安全高效训练数据方面的不足。研究基于RoboFactory基准，评估了模仿学习(imitation learning)在不同难度任务中的表现，并探索了多智能体模仿学习的架构和训练策略，旨在构建安全高效的具身多智能体系统。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Project page: https://iranqin.github.io/robofactory/",
      "pdf_url": "http://arxiv.org/pdf/2503.16408v1",
      "published_date": "2025-03-20 17:58:38 UTC",
      "updated_date": "2025-03-20 17:58:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:15:45.788993"
    },
    {
      "arxiv_id": "2503.16402v1",
      "title": "The Emperor's New Clothes in Benchmarking? A Rigorous Examination of Mitigation Strategies for LLM Benchmark Data Contamination",
      "title_zh": "基准测试中的“皇帝的新衣”？对LLM基准数据污染缓解策略的严格检验",
      "authors": [
        "Yifan Sun",
        "Han Wang",
        "Dongbai Li",
        "Gang Wang",
        "Huan Zhang"
      ],
      "abstract": "Benchmark Data Contamination (BDC)-the inclusion of benchmark testing samples\nin the training set-has raised increasing concerns in Large Language Model\n(LLM) evaluation, leading to falsely inflated performance estimates and\nundermining evaluation reliability. To address this, researchers have proposed\nvarious mitigation strategies to update existing benchmarks, including\nmodifying original questions or generating new ones based on them. However, a\nrigorous examination of the effectiveness of these mitigation strategies\nremains lacking. In this paper, we design a systematic and controlled pipeline\nalong with two novel metrics-fidelity and contamination resistance-to provide a\nfine-grained and comprehensive assessment of existing BDC mitigation\nstrategies. Previous assessment methods, such as accuracy drop and accuracy\nmatching, focus solely on aggregate accuracy, often leading to incomplete or\nmisleading conclusions. Our metrics address this limitation by emphasizing\nquestion-level evaluation result matching. Extensive experiments with 10 LLMs,\n5 benchmarks, 20 BDC mitigation strategies, and 2 contamination scenarios\nreveal that no existing strategy significantly improves resistance over the\nvanilla case (i.e., no benchmark update) across all benchmarks, and none\neffectively balances fidelity and contamination resistance. These findings\nunderscore the urgent need for designing more effective BDC mitigation\nstrategies. Our code repository is available at\nhttps://github.com/ASTRAL-Group/BDC_mitigation_assessment.",
      "tldr_zh": "该研究对大型语言模型(LLM)评估中的基准数据污染(Benchmark Data Contamination, BDC)问题进行了严格检验，提出了两种新指标——保真度(fidelity)和抗污染性(contamination resistance)，以细粒度评估现有的BDC缓解策略。通过系统化的实验设计，研究分析了10个LLM、5个基准测试、20种BDC缓解策略和2种污染场景，发现现有策略在提升抗污染性方面均未显著优于未更新的基准，且无法有效平衡保真度与抗污染性。研究结果强调了设计更有效BDC缓解策略的迫切需求，并提供了开源代码库以支持进一步研究。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "23 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.16402v1",
      "published_date": "2025-03-20 17:55:04 UTC",
      "updated_date": "2025-03-20 17:55:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:16:10.230491"
    },
    {
      "arxiv_id": "2503.16399v1",
      "title": "SA-Occ: Satellite-Assisted 3D Occupancy Prediction in Real World",
      "title_zh": "SA-Occ：卫星辅助的现实世界三维占用预测",
      "authors": [
        "Chen Chen",
        "Zhirui Wang",
        "Taowei Sheng",
        "Yi Jiang",
        "Yundu Li",
        "Peirui Cheng",
        "Luning Zhang",
        "Kaiqiang Chen",
        "Yanfeng Hu",
        "Xue Yang",
        "Xian Sun"
      ],
      "abstract": "Existing vision-based 3D occupancy prediction methods are inherently limited\nin accuracy due to their exclusive reliance on street-view imagery, neglecting\nthe potential benefits of incorporating satellite views. We propose SA-Occ, the\nfirst Satellite-Assisted 3D occupancy prediction model, which leverages GPS &\nIMU to integrate historical yet readily available satellite imagery into\nreal-time applications, effectively mitigating limitations of ego-vehicle\nperceptions, involving occlusions and degraded performance in distant regions.\nTo address the core challenges of cross-view perception, we propose: 1)\nDynamic-Decoupling Fusion, which resolves inconsistencies in dynamic regions\ncaused by the temporal asynchrony between satellite and street views; 2)\n3D-Proj Guidance, a module that enhances 3D feature extraction from inherently\n2D satellite imagery; and 3) Uniform Sampling Alignment, which aligns the\nsampling density between street and satellite views. Evaluated on\nOcc3D-nuScenes, SA-Occ achieves state-of-the-art performance, especially among\nsingle-frame methods, with a 39.05% mIoU (a 6.97% improvement), while incurring\nonly 6.93 ms of additional latency per frame. Our code and newly curated\ndataset are available at https://github.com/chenchen235/SA-Occ.",
      "tldr_zh": "该研究提出了SA-Occ模型，首次将卫星图像引入基于视觉的3D占用预测，以解决传统方法仅依赖街景图像导致的精度限制问题。通过GPS和IMU整合历史卫星图像，SA-Occ有效缓解了自车感知中的遮挡和远距离性能下降问题。模型提出三种关键方法：动态解耦融合（Dynamic-Decoupling Fusion）解决卫星与街景的时间异步问题，3D投影引导（3D-Proj Guidance）增强2D卫星图像的3D特征提取，以及均匀采样对齐（Uniform Sampling Alignment）统一两种视图的采样密度。在Occ3D-nuScenes数据集上，SA-Occ以39.05%的mIoU（提升6.97%）达到单帧方法的最高性能，同时每帧仅增加6.93毫秒延迟。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.16399v1",
      "published_date": "2025-03-20 17:54:29 UTC",
      "updated_date": "2025-03-20 17:54:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:16:22.146064"
    },
    {
      "arxiv_id": "2503.16394v1",
      "title": "Do Visual Imaginations Improve Vision-and-Language Navigation Agents?",
      "title_zh": "视觉想象能否提升视觉与语言导航代理的性能？",
      "authors": [
        "Akhil Perincherry",
        "Jacob Krantz",
        "Stefan Lee"
      ],
      "abstract": "Vision-and-Language Navigation (VLN) agents are tasked with navigating an\nunseen environment using natural language instructions. In this work, we study\nif visual representations of sub-goals implied by the instructions can serve as\nnavigational cues and lead to increased navigation performance. To synthesize\nthese visual representations or imaginations, we leverage a text-to-image\ndiffusion model on landmark references contained in segmented instructions.\nThese imaginations are provided to VLN agents as an added modality to act as\nlandmark cues and an auxiliary loss is added to explicitly encourage relating\nthese with their corresponding referring expressions. Our findings reveal an\nincrease in success rate (SR) of around 1 point and up to 0.5 points in success\nscaled by inverse path length (SPL) across agents. These results suggest that\nthe proposed approach reinforces visual understanding compared to relying on\nlanguage instructions alone. Code and data for our work can be found at\nhttps://www.akhilperincherry.com/VLN-Imagine-website/.",
      "tldr_zh": "该研究探讨了视觉想象是否能够提升视觉语言导航(VLN)智能体的性能。通过利用文本到图像扩散模型生成指令中地标的视觉表示，并将其作为额外模态提供给VLN智能体，研究结果表明这种方法增强了智能体的视觉理解能力。实验显示，成功率和路径效率分别提高了约1点和0.5点，证明了视觉想象在导航任务中的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16394v1",
      "published_date": "2025-03-20 17:53:12 UTC",
      "updated_date": "2025-03-20 17:53:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:16:30.209868"
    },
    {
      "arxiv_id": "2503.16392v1",
      "title": "Graph of Effort: Quantifying Risk of AI Usage for Vulnerability Assessment",
      "title_zh": "努力图：量化人工智能在漏洞评估中的使用风险",
      "authors": [
        "Anket Mehra",
        "Andreas Aßmuth",
        "Malte Prieß"
      ],
      "abstract": "With AI-based software becoming widely available, the risk of exploiting its\ncapabilities, such as high automation and complex pattern recognition, could\nsignificantly increase. An AI used offensively to attack non-AI assets is\nreferred to as offensive AI.\n  Current research explores how offensive AI can be utilized and how its usage\ncan be classified. Additionally, methods for threat modeling are being\ndeveloped for AI-based assets within organizations. However, there are gaps\nthat need to be addressed. Firstly, there is a need to quantify the factors\ncontributing to the AI threat. Secondly, there is a requirement to create\nthreat models that analyze the risk of being attacked by AI for vulnerability\nassessment across all assets of an organization. This is particularly crucial\nand challenging in cloud environments, where sophisticated infrastructure and\naccess control landscapes are prevalent. The ability to quantify and further\nanalyze the threat posed by offensive AI enables analysts to rank\nvulnerabilities and prioritize the implementation of proactive countermeasures.\n  To address these gaps, this paper introduces the Graph of Effort, an\nintuitive, flexible, and effective threat modeling method for analyzing the\neffort required to use offensive AI for vulnerability exploitation by an\nadversary. While the threat model is functional and provides valuable support,\nits design choices need further empirical validation in future work.",
      "tldr_zh": "该研究提出了“Graph of Effort”模型，用于量化攻击者利用AI进行漏洞利用所需的工作量，从而评估组织资产面临的AI威胁风险。该模型专注于分析云环境中复杂基础设施和访问控制背景下，AI被用于攻击非AI资产（即“offensive AI”）的威胁。通过量化AI威胁因素，该模型帮助分析师对漏洞进行排序，并优先实施主动防御措施，为组织提供了一种直观、灵活且有效的威胁建模方法。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.CR",
      "comment": "8 pages; accepted for the 16th International Conference on Cloud\n  Computing, GRIDs, and Virtualization (Cloud Computing 2025), Valencia, Spain,\n  2025",
      "pdf_url": "http://arxiv.org/pdf/2503.16392v1",
      "published_date": "2025-03-20 17:52:42 UTC",
      "updated_date": "2025-03-20 17:52:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:16:27.157717"
    },
    {
      "arxiv_id": "2503.16389v1",
      "title": "Attentional Triple-Encoder Network in Spatiospectral Domains for Medical Image Segmentation",
      "title_zh": "注意力三重编码器网络在空间光谱域中的医学图像分割",
      "authors": [
        "Kristin Qi",
        "Xinhan Di"
      ],
      "abstract": "Retinal Optical Coherence Tomography (OCT) segmentation is essential for\ndiagnosing pathology. Traditional methods focus on either spatial or spectral\ndomains, overlooking their combined dependencies. We propose a triple-encoder\nnetwork that integrates CNNs for spatial features, Fast Fourier Convolution\n(FFC) for spectral features, and attention mechanisms to capture global\nrelationships across both domains. Attention fusion modules integrate\nconvolution and cross-attention to further enhance features. Our method\nachieves an average Dice score improvement from 0.855 to 0.864, outperforming\nprior work.",
      "tldr_zh": "该研究提出了一种三重编码器网络，用于视网膜光学相干断层扫描（OCT）图像分割。该方法结合了卷积神经网络（CNN）提取空间特征、快速傅里叶卷积（FFC）提取频谱特征，并利用注意力机制捕捉空间和频谱域的全局关系。通过注意力融合模块进一步增强特征，实验显示该方法的平均Dice分数从0.855提升至0.864，优于现有方法。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "IEEE Conference on Artificial Intelligence (IEEE CAI)",
      "pdf_url": "http://arxiv.org/pdf/2503.16389v1",
      "published_date": "2025-03-20 17:49:01 UTC",
      "updated_date": "2025-03-20 17:49:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:16:41.628950"
    },
    {
      "arxiv_id": "2503.16385v1",
      "title": "Deconstructing Long Chain-of-Thought: A Structured Reasoning Optimization Framework for Long CoT Distillation",
      "title_zh": "解构长链式思维：面向长链式思维蒸馏的结构化推理优化框架",
      "authors": [
        "Yijia Luo",
        "Yulin Song",
        "Xingyao Zhang",
        "Jiaheng Liu",
        "Weixun Wang",
        "GengRu Chen",
        "Wenbo Su",
        "Bo Zheng"
      ],
      "abstract": "Recent advancements in large language models (LLMs) have demonstrated\nremarkable reasoning capabilities through long chain-of-thought (CoT)\nreasoning. The R1 distillation scheme has emerged as a promising approach for\ntraining cost-effective models with enhanced reasoning abilities. However, the\nunderlying mechanisms driving its effectiveness remain unclear. This study\nexamines the universality of distillation data and identifies key components\nthat enable the efficient transfer of long-chain reasoning capabilities in LLM\ndistillation. Our findings reveal that the effectiveness of long CoT reasoning\ndistillation from teacher models like Qwen-QwQ degrades significantly on\nnonhomologous models, challenging the assumed universality of current\ndistillation methods. To gain deeper insights into the structure and patterns\nof long CoT reasoning, we propose DLCoT (Deconstructing Long Chain-of-Thought),\na distillation data enhancement framework. DLCoT consists of three key steps:\n(1) data segmentation to decompose complex long CoT structures, (2)\nsimplification by eliminating unsolvable and redundant solutions, and (3)\noptimization of intermediate error states. Our approach significantly improves\nmodel performance and token efficiency, facilitating the development of\nhigh-performance LLMs.",
      "tldr_zh": "该研究提出了DLCoT框架，旨在优化长链式思维推理(Long CoT)的蒸馏过程。研究发现，当前蒸馏方法在非同源模型上的效果显著下降，挑战了蒸馏数据普遍性的假设。DLCoT框架通过分解复杂长CoT结构、简化冗余解以及优化中间错误状态，显著提升了模型性能和计算效率，为高性能大语言模型的发展提供了新思路。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16385v1",
      "published_date": "2025-03-20 17:46:38 UTC",
      "updated_date": "2025-03-20 17:46:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:16:55.864894"
    },
    {
      "arxiv_id": "2503.16371v1",
      "title": "Reinforcement Learning-based Heuristics to Guide Domain-Independent Dynamic Programming",
      "title_zh": "基于强化学习的启发式方法指导领域无关动态规划",
      "authors": [
        "Minori Narita",
        "Ryo Kuroiwa",
        "J. Christopher Beck"
      ],
      "abstract": "Domain-Independent Dynamic Programming (DIDP) is a state-space search\nparadigm based on dynamic programming for combinatorial optimization. In its\ncurrent implementation, DIDP guides the search using user-defined dual bounds.\nReinforcement learning (RL) is increasingly being applied to combinatorial\noptimization problems and shares several key structures with DP, being\nrepresented by the Bellman equation and state-based transition systems. We\npropose using reinforcement learning to obtain a heuristic function to guide\nthe search in DIDP. We develop two RL-based guidance approaches: value-based\nguidance using Deep Q-Networks and policy-based guidance using Proximal Policy\nOptimization. Our experiments indicate that RL-based guidance significantly\noutperforms standard DIDP and problem-specific greedy heuristics with the same\nnumber of node expansions. Further, despite longer node evaluation times, RL\nguidance achieves better run-time performance than standard DIDP on three of\nfour benchmark domains.",
      "tldr_zh": "该研究提出了一种基于强化学习（RL）的启发式方法，用于指导领域无关动态规划（DIDP），以解决组合优化问题。研究开发了两种RL引导策略：基于深度Q网络（DQN）的值引导和基于近端策略优化（PPO）的策略引导。实验结果表明，RL引导在相同节点扩展次数下显著优于标准DIDP和问题特定的贪心启发式方法，并且在四个基准域中的三个上实现了更好的运行时性能。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "24 pages, 4 figures, to be published in CPAIOR 2025\n  (https://sites.google.com/view/cpaior2025)",
      "pdf_url": "http://arxiv.org/pdf/2503.16371v1",
      "published_date": "2025-03-20 17:33:08 UTC",
      "updated_date": "2025-03-20 17:33:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:16:55.992089"
    },
    {
      "arxiv_id": "2503.16365v1",
      "title": "JARVIS-VLA: Post-Training Large-Scale Vision Language Models to Play Visual Games with Keyboards and Mouse",
      "title_zh": "JARVIS-VLA：通过键盘鼠标操控视觉游戏的后训练大规模视觉语言模型",
      "authors": [
        "Muyao Li",
        "Zihao Wang",
        "Kaichen He",
        "Xiaojian Ma",
        "Yitao Liang"
      ],
      "abstract": "Recently, action-based decision-making in open-world environments has gained\nsignificant attention. Visual Language Action (VLA) models, pretrained on\nlarge-scale web datasets, have shown promise in decision-making tasks. However,\nprevious work has primarily focused on action post-training, often neglecting\nenhancements to the foundational model itself. In response, we introduce a\nnovel approach, Act from Visual Language Post-Training, which refines Visual\nLanguage Models (VLMs) through visual and linguistic guidance in a\nself-supervised manner. This enhancement improves the models' capabilities in\nworld knowledge, visual recognition, and spatial grounding in open-world\nenvironments. Following the above post-training paradigms, we obtain the first\nVLA models in Minecraft that can follow human instructions on over 1k different\natomic tasks, including crafting, smelting, cooking, mining, and killing. Our\nexperiments demonstrate that post-training on non-trajectory tasks leads to a\nsignificant 40% improvement over the best agent baseline on a diverse set of\natomic tasks. Furthermore, we demonstrate that our approach surpasses\ntraditional imitation learning-based policies in Minecraft, achieving\nstate-of-the-art performance. We have open-sourced the code, models, and\ndatasets to foster further research. The project page can be found in\nhttps://craftjarvis.github.io/JarvisVLA.",
      "tldr_zh": "该研究提出了JARVIS-VLA，一种通过后训练增强视觉语言模型(VLMs)在开放世界环境中执行决策任务能力的新方法。该方法利用视觉和语言引导以自监督方式优化模型，提升了其在世界知识、视觉识别和空间定位方面的能力。实验表明，后训练后的模型在Minecraft中能够执行超过1000种原子任务，并在多样化任务上比最佳基线模型性能提升40%，超越了传统的模仿学习策略，达到了最先进的性能水平。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "22 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.16365v1",
      "published_date": "2025-03-20 17:21:58 UTC",
      "updated_date": "2025-03-20 17:21:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:17:08.923169"
    },
    {
      "arxiv_id": "2503.16364v1",
      "title": "Neural Networks: According to the Principles of Grassmann Algebra",
      "title_zh": "神经网络：基于格拉斯曼代数原理",
      "authors": [
        "Z. Zarezadeh",
        "N. Zarezadeh"
      ],
      "abstract": "In this paper, we explore the algebra of quantum idempotents and the\nquantization of fermions which gives rise to a Hilbert space equal to the\nGrassmann algebra associated with the Lie algebra. Since idempotents carry\nrepresentations of the algebra under consideration, they form algebraic\nvarieties and smooth manifolds in the natural topology. In addition to the\nmotivation of linking up mathematical physics with machine learning, it is also\nshown that by using idempotents and invariant subspace of the corresponding\nalgebras, these representations encode and perhaps provide a probabilistic\ninterpretation of reasoning and relational paths in geometrical terms.",
      "tldr_zh": "本文探讨了量子幂等元（quantum idempotents）的代数结构以及费米子（fermions）的量子化，揭示了其生成的希尔伯特空间与李代数（Lie algebra）相关的格拉斯曼代数（Grassmann algebra）之间的等价性。通过幂等元承载的代数表示，它们形成了代数簇（algebraic varieties）和光滑流形（smooth manifolds）。研究不仅将数学物理与机器学习联系起来，还表明这些表示通过不变子空间和幂等元，能够以几何方式编码并概率化解释推理和关系路径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16364v1",
      "published_date": "2025-03-20 17:21:23 UTC",
      "updated_date": "2025-03-20 17:21:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:17:18.606455"
    },
    {
      "arxiv_id": "2503.16356v1",
      "title": "CaKE: Circuit-aware Editing Enables Generalizable Knowledge Learners",
      "title_zh": "CaKE：电路感知编辑实现可泛化的知识学习器",
      "authors": [
        "Yunzhi Yao",
        "Jizhan Fang",
        "Jia-Chen Gu",
        "Ningyu Zhang",
        "Shumin Deng",
        "Huajun Chen",
        "Nanyun Peng"
      ],
      "abstract": "Knowledge Editing (KE) enables the modification of outdated or incorrect\ninformation in large language models (LLMs). While existing KE methods can\nupdate isolated facts, they struggle to generalize these updates to multi-hop\nreasoning tasks that depend on the modified knowledge. Through an analysis of\nreasoning circuits -- the neural pathways LLMs use for knowledge-based\ninference, we observe that current layer-localized KE approaches, such as MEMIT\nand WISE, which edit only single or a few model layers, struggle to effectively\nincorporate updated information into these reasoning pathways. To address this\nlimitation, we propose CaKE (Circuit-aware Knowledge Editing), a novel method\nthat enables more effective integration of updated knowledge in LLMs. CaKE\nleverages strategically curated data, guided by our circuits-based analysis,\nthat enforces the model to utilize the modified knowledge, stimulating the\nmodel to develop appropriate reasoning circuits for newly integrated knowledge.\nExperimental results show that CaKE enables more accurate and consistent use of\nupdated knowledge across related reasoning tasks, leading to an average of 20%\nimprovement in multi-hop reasoning accuracy on MQuAKE dataset compared to\nexisting KE methods. We release the code and data in\nhttps://github.com/zjunlp/CaKE.",
      "tldr_zh": "该研究提出了CaKE（Circuit-aware Knowledge Editing），一种基于推理路径分析的知识编辑方法，旨在解决现有知识编辑技术在大型语言模型（LLMs）中难以将更新知识推广到多跳推理任务的问题。通过分析LLMs用于知识推理的神经路径（reasoning circuits），CaKE利用策略性策划的数据，强制模型使用更新知识并构建相应的推理路径。实验表明，CaKE在多跳推理任务上的准确率比现有方法平均提高20%，显著提升了知识的泛化能力。相关代码和数据已开源。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2503.16356v1",
      "published_date": "2025-03-20 17:14:34 UTC",
      "updated_date": "2025-03-20 17:14:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:17:17.644263"
    },
    {
      "arxiv_id": "2503.16348v1",
      "title": "Palatable Conceptions of Disembodied Being: Terra Incognita in the Space of Possible Minds",
      "title_zh": "可接受的脱离实体存在概念：可能心智空间中的未知领域",
      "authors": [
        "Murray Shanahan"
      ],
      "abstract": "Is it possible to articulate a conception of consciousness that is compatible\nwith the exotic characteristics of contemporary, disembodied AI systems, and\nthat can stand up to philosophical scrutiny? How would subjective time and\nselfhood show up for an entity that conformed to such a conception? Trying to\nanswer these questions, even metaphorically, stretches the language of\nconsciousness to breaking point. Ultimately, the attempt yields something like\nemptiness, in the Buddhist sense, and helps to undermine our dualistic\ninclinations towards subjectivity and selfhood.",
      "tldr_zh": "这篇论文探讨了如何为当代无实体AI系统提出一个哲学上站得住脚的意识概念。作者通过分析主观时间和自我在这种概念中的表现，揭示了传统意识语言在面对无实体存在时的局限性。最终，研究得出了类似于佛教“空”的概念，挑战了我们对主观性和自我的二元论倾向。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16348v1",
      "published_date": "2025-03-20 17:05:16 UTC",
      "updated_date": "2025-03-20 17:05:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:17:47.928043"
    },
    {
      "arxiv_id": "2503.16342v1",
      "title": "HiQ-Lip: The First Quantum-Classical Hierarchical Method for Global Lipschitz Constant Estimation of ReLU Networks",
      "title_zh": "HiQ-Lip：首个用于ReLU网络全局Lipschitz常数估计的量子-经典分层方法",
      "authors": [
        "Haoqi He",
        "Yan Xiao"
      ],
      "abstract": "Estimating the global Lipschitz constant of neural networks is crucial for\nunderstanding and improving their robustness and generalization capabilities.\nHowever, precise calculations are NP-hard, and current semidefinite programming\n(SDP) methods face challenges such as high memory usage and slow processing\nspeeds. In this paper, we propose \\textbf{HiQ-Lip}, a hybrid quantum-classical\nhierarchical method that leverages Coherent Ising Machines (CIMs) to estimate\nthe global Lipschitz constant. We tackle the estimation by converting it into a\nQuadratic Unconstrained Binary Optimization (QUBO) problem and implement a\nmultilevel graph coarsening and refinement strategy to adapt to the constraints\nof contemporary quantum hardware. Our experimental evaluations on fully\nconnected neural networks demonstrate that HiQ-Lip not only provides estimates\ncomparable to state-of-the-art methods but also significantly accelerates the\ncomputation process. In specific tests involving two-layer neural networks with\n256 hidden neurons, HiQ-Lip doubles the solving speed and offers more accurate\nupper bounds than the existing best method, LiPopt. These findings highlight\nthe promising utility of small-scale quantum devices in advancing the\nestimation of neural network robustness.",
      "tldr_zh": "该研究提出了HiQ-Lip，首次将量子-经典混合分层方法用于估计ReLU神经网络的全局Lipschitz常数。通过将问题转化为二次无约束二元优化(QUBO)问题，并利用相干伊辛机(CIMs)和多级图粗化与细化策略，HiQ-Lip在保证估计精度的同时显著加速了计算过程。实验表明，HiQ-Lip在双层神经网络上的求解速度是现有最佳方法LiPopt的两倍，并提供了更精确的上界，展示了小规模量子设备在神经网络鲁棒性估计中的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "quant-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16342v1",
      "published_date": "2025-03-20 16:58:40 UTC",
      "updated_date": "2025-03-20 16:58:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:17:53.998500"
    },
    {
      "arxiv_id": "2503.16335v1",
      "title": "Enhancing Software Quality Assurance with an Adaptive Differential Evolution based Quantum Variational Autoencoder-Transformer Model",
      "title_zh": "基于自适应差分进化的量子变分自编码器-Transformer模型增强软件质量保障",
      "authors": [
        "Seshu Babu Barma",
        "Mohanakrishnan Hariharan",
        "Satish Arvapalli"
      ],
      "abstract": "An AI-powered quality engineering platform uses artificial intelligence to\nboost software quality assessments through automated defect prediction and\noptimized performance alongside improved feature extraction. Existing models\nresult in difficulties addressing noisy data types together with imbalances,\npattern recognition complexities, ineffective feature extraction, and\ngeneralization weaknesses. To overcome those existing challenges in this\nresearch, we develop a new model Adaptive Differential Evolution based Quantum\nVariational Autoencoder-Transformer Model (ADE-QVAET), that combines a Quantum\nVariational Autoencoder-Transformer (QVAET) to obtain high-dimensional latent\nfeatures and maintain sequential dependencies together with contextual\nrelationships, resulting in superior defect prediction accuracy. Adaptive\nDifferential Evolution (ADE) Optimization utilizes an adaptive parameter tuning\nmethod that enhances model convergence and predictive performance. ADE-QVAET\nintegrates advanced AI techniques to create a robust solution for scalable and\naccurate software defect prediction that represents a top-level AI-driven\ntechnology for quality engineering applications. The proposed ADE-QVAET model\nattains high accuracy, precision, recall, and f1-score during the training\npercentage (TP) 90 of 98.08%, 92.45%, 94.67%, and 98.12%.",
      "tldr_zh": "本研究提出了一种基于自适应差分进化算法(ADE)的量子变分自编码器-Transformer模型(ADE-QVAET)，用于提升软件质量评估中的缺陷预测能力。该模型结合量子变分自编码器-Transformer(QVAET)以捕捉高维潜在特征并保持序列依赖性和上下文关系，同时利用ADE优化算法自适应调整参数，提高模型收敛性和预测性能。实验结果表明，ADE-QVAET在训练集占比90%时，准确率、精确率、召回率和F1分数分别达到98.08%、92.45%、94.67%和98.12%，为软件质量工程提供了一种高效且可扩展的AI驱动解决方案。",
      "categories": [
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16335v1",
      "published_date": "2025-03-20 16:55:38 UTC",
      "updated_date": "2025-03-20 16:55:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:17:48.737656"
    },
    {
      "arxiv_id": "2503.16328v1",
      "title": "Knowledge-guided machine learning model with soil moisture for corn yield prediction under drought conditions",
      "title_zh": "基于土壤湿度的知识引导机器学习模型用于干旱条件下的玉米产量预测",
      "authors": [
        "Xiaoyu Wang",
        "Yijia Xu",
        "Jingyi Huang",
        "Zhengwei Yang",
        "Zhou Zhang"
      ],
      "abstract": "Remote sensing (RS) techniques, by enabling non-contact acquisition of\nextensive ground observations, have become a valuable tool for corn yield\nprediction. Traditional process-based (PB) models are limited by fixed input\nfeatures and struggle to incorporate large volumes of RS data. In contrast,\nmachine learning (ML) models are often criticized for being ``black boxes''\nwith limited interpretability. To address these limitations, we used\nKnowledge-Guided Machine Learning (KGML), which combined the strengths of both\napproaches and fully used RS data. However, previous KGML methods overlooked\nthe crucial role of soil moisture in plant growth. To bridge this gap, we\nproposed the Knowledge-Guided Machine Learning with Soil Moisture (KGML-SM)\nframework, using soil moisture as an intermediate variable to emphasize its key\nrole in plant development. Additionally, based on the prior knowledge that the\nmodel may overestimate under drought conditions, we designed a drought-aware\nloss function that penalizes predicted yield in drought-affected areas. Our\nexperiments showed that the KGML-SM model outperformed other ML models.\nFinally, we explored the relationships between drought, soil moisture, and corn\nyield prediction, assessing the importance of various features and analyzing\nhow soil moisture impacts corn yield predictions across different regions and\ntime periods.",
      "tldr_zh": "本研究提出了一种结合土壤湿度的知识引导机器学习模型(KGML-SM)，用于预测干旱条件下的玉米产量。该模型将土壤湿度作为中间变量，强调其在植物生长中的关键作用，并设计了针对干旱条件的损失函数，以惩罚干旱地区的预测产量。实验结果表明，KGML-SM模型优于其他机器学习模型，并深入分析了干旱、土壤湿度与玉米产量预测之间的关系，评估了不同特征的重要性及其在不同区域和时间段的影响。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16328v1",
      "published_date": "2025-03-20 16:52:25 UTC",
      "updated_date": "2025-03-20 16:52:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:18:37.881736"
    },
    {
      "arxiv_id": "2503.16326v1",
      "title": "OmniGeo: Towards a Multimodal Large Language Models for Geospatial Artificial Intelligence",
      "title_zh": "OmniGeo：面向地理空间人工智能的多模态大语言模型",
      "authors": [
        "Long Yuan",
        "Fengran Mo",
        "Kaiyu Huang",
        "Wenjie Wang",
        "Wangyuxuan Zhai",
        "Xiaoyu Zhu",
        "You Li",
        "Jinan Xu",
        "Jian-Yun Nie"
      ],
      "abstract": "The rapid advancement of multimodal large language models (LLMs) has opened\nnew frontiers in artificial intelligence, enabling the integration of diverse\nlarge-scale data types such as text, images, and spatial information. In this\npaper, we explore the potential of multimodal LLMs (MLLM) for geospatial\nartificial intelligence (GeoAI), a field that leverages spatial data to address\nchallenges in domains including Geospatial Semantics, Health Geography, Urban\nGeography, Urban Perception, and Remote Sensing. We propose a MLLM (OmniGeo)\ntailored to geospatial applications, capable of processing and analyzing\nheterogeneous data sources, including satellite imagery, geospatial metadata,\nand textual descriptions. By combining the strengths of natural language\nunderstanding and spatial reasoning, our model enhances the ability of\ninstruction following and the accuracy of GeoAI systems. Results demonstrate\nthat our model outperforms task-specific models and existing LLMs on diverse\ngeospatial tasks, effectively addressing the multimodality nature while\nachieving competitive results on the zero-shot geospatial tasks. Our code will\nbe released after publication.",
      "tldr_zh": "本文提出了OmniGeo，一种面向地理空间人工智能（GeoAI）的多模态大语言模型（MLLM），旨在处理和分析包括卫星图像、地理空间元数据和文本描述在内的异构数据源。通过结合自然语言理解和空间推理的优势，该模型提升了指令遵循能力和GeoAI系统的准确性。实验表明，OmniGeo在多样化的地理空间任务中优于任务专用模型和现有大语言模型，并在零样本地理空间任务中取得了具有竞争力的结果。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "15 pages, Under review",
      "pdf_url": "http://arxiv.org/pdf/2503.16326v1",
      "published_date": "2025-03-20 16:45:48 UTC",
      "updated_date": "2025-03-20 16:45:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:18:08.205637"
    },
    {
      "arxiv_id": "2503.16311v1",
      "title": "Structured-Noise Masked Modeling for Video, Audio and Beyond",
      "title_zh": "结构化噪声掩码建模：面向视频、音频及其他领域",
      "authors": [
        "Aritra Bhowmik",
        "Fida Mohammad Thoker",
        "Carlos Hinojosa",
        "Bernard Ghanem",
        "Cees G. M. Snoek"
      ],
      "abstract": "Masked modeling has emerged as a powerful self-supervised learning framework,\nbut existing methods largely rely on random masking, disregarding the\nstructural properties of different modalities. In this work, we introduce\nstructured noise-based masking, a simple yet effective approach that naturally\naligns with the spatial, temporal, and spectral characteristics of video and\naudio data. By filtering white noise into distinct color noise distributions,\nwe generate structured masks that preserve modality-specific patterns without\nrequiring handcrafted heuristics or access to the data. Our approach improves\nthe performance of masked video and audio modeling frameworks without any\ncomputational overhead. Extensive experiments demonstrate that structured noise\nmasking achieves consistent improvement over random masking for standard and\nadvanced masked modeling methods, highlighting the importance of modality-aware\nmasking strategies for representation learning.",
      "tldr_zh": "本研究提出了一种基于结构化噪声的掩码建模方法，用于视频、音频等多模态数据的自监督学习。与传统的随机掩码不同，该方法通过将白噪声过滤为特定颜色噪声分布，生成与数据空间、时间和频谱特性对齐的结构化掩码，从而保留模态特定的模式。实验表明，该方法无需额外计算开销即可提升现有掩码建模框架的性能，并在多种标准及先进掩码建模方法中均优于随机掩码，强调了模态感知掩码策略在表示学习中的重要性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16311v1",
      "published_date": "2025-03-20 16:34:14 UTC",
      "updated_date": "2025-03-20 16:34:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:18:12.401837"
    },
    {
      "arxiv_id": "2503.16307v1",
      "title": "Speeding up design and making to reduce time-to-project and time-to-market: an AI-Enhanced approach in engineering education",
      "title_zh": "加速设计与制造以缩短项目周期与上市时间：工程教育中的AI增强方法",
      "authors": [
        "Giovanni Adorni",
        "Daniele Grosso"
      ],
      "abstract": "This paper explores the integration of AI tools, such as ChatGPT and GitHub\nCopilot, in the Software Architecture for Embedded Systems course. AI-supported\nworkflows enabled students to rapidly prototype complex projects, emphasizing\nreal-world applications like SLAM robotics. Results demon-started enhanced\nproblem-solving, faster development, and more sophisticated outcomes, with AI\naugmenting but not replacing human decision-making.",
      "tldr_zh": "本研究探讨了在嵌入式系统软件架构课程中整合AI工具（如ChatGPT和GitHub Copilot）的应用。通过AI支持的工作流程，学生能够快速原型化复杂项目，特别是SLAM机器人等实际应用。结果表明，AI辅助显著提升了问题解决能力、加速了开发进程并产生了更复杂的结果，同时AI并未取代人类的决策作用。",
      "categories": [
        "cs.AI",
        "I.2; K.3"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 4 figures, AIxEDU 2024 conference",
      "pdf_url": "http://arxiv.org/pdf/2503.16307v1",
      "published_date": "2025-03-20 16:32:13 UTC",
      "updated_date": "2025-03-20 16:32:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:18:17.878006"
    },
    {
      "arxiv_id": "2503.16304v2",
      "title": "Bridging Technology and Humanities: Evaluating the Impact of Large Language Models on Social Sciences Research with DeepSeek-R1",
      "title_zh": "连接技术与人文：评估大型语言模型对社会科学研究的影响——基于 DeepSeek-R1 的研究",
      "authors": [
        "Peiran Gu",
        "Fuhao Duan",
        "Wenhao Li",
        "Bochen Xu",
        "Ying Cai",
        "Teng Yao",
        "Chenxun Zhuo",
        "Tianming Liu",
        "Bao Ge"
      ],
      "abstract": "In recent years, the development of Large Language Models (LLMs) has made\nsignificant breakthroughs in the field of natural language processing and has\ngradually been applied to the field of humanities and social sciences research.\nLLMs have a wide range of application value in the field of humanities and\nsocial sciences because of its strong text understanding, generation and\nreasoning capabilities. In humanities and social sciences research, LLMs can\nanalyze large-scale text data and make inferences.\n  This article analyzes the large language model DeepSeek-R1 from seven\naspects: low-resource language translation, educational question-answering,\nstudent writing improvement in higher education, logical reasoning, educational\nmeasurement and psychometrics, public health policy analysis, and art\neducation.Then we compare the answers given by DeepSeek-R1 in the seven aspects\nwith the answers given by o1-preview. DeepSeek-R1 performs well in the\nhumanities and social sciences, answering most questions correctly and\nlogically, and can give reasonable analysis processes and explanations.\nCompared with o1-preview, it can automatically generate reasoning processes and\nprovide more detailed explanations, which is suitable for beginners or people\nwho need to have a detailed understanding of this knowledge, while o1-preview\nis more suitable for quick reading.\n  Through analysis, it is found that LLM has broad application potential in the\nfield of humanities and social sciences, and shows great advantages in\nimproving text analysis efficiency, language communication and other fields.\nLLM's powerful language understanding and generation capabilities enable it to\ndeeply explore complex problems in the field of humanities and social sciences,\nand provide innovative tools for academic research and practical applications.",
      "tldr_zh": "该研究探讨了大型语言模型(LLMs)在人文社会科学领域的应用潜力，重点评估了DeepSeek-R1模型在低资源语言翻译、教育问答、高等教育写作提升、逻辑推理、教育测量与心理测量、公共卫生政策分析和艺术教育等七个方面的表现。研究发现，DeepSeek-R1在人文社会科学领域表现优异，能够提供逻辑清晰的答案和详细的分析过程，特别适合初学者或需要深入了解相关知识的用户。与o1-preview相比，DeepSeek-R1能够自动生成推理过程并提供更详细的解释。研究表明，LLMs在文本分析效率提升和语言交流等领域具有显著优势，能够深入探索人文社会科学领域的复杂问题，为学术研究和实际应用提供创新工具。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "52 pages, 19 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.16304v2",
      "published_date": "2025-03-20 16:25:24 UTC",
      "updated_date": "2025-03-21 16:34:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:19:26.908936"
    },
    {
      "arxiv_id": "2503.16302v1",
      "title": "Unleashing Vecset Diffusion Model for Fast Shape Generation",
      "title_zh": "释放Vecset扩散模型以实现快速形状生成",
      "authors": [
        "Zeqiang Lai",
        "Yunfei Zhao",
        "Zibo Zhao",
        "Haolin Liu",
        "Fuyun Wang",
        "Huiwen Shi",
        "Xianghui Yang",
        "Qinxiang Lin",
        "Jinwei Huang",
        "Yuhong Liu",
        "Jie Jiang",
        "Chunchao Guo",
        "Xiangyu Yue"
      ],
      "abstract": "3D shape generation has greatly flourished through the development of\nso-called \"native\" 3D diffusion, particularly through the Vecset Diffusion\nModel (VDM). While recent advancements have shown promising results in\ngenerating high-resolution 3D shapes, VDM still struggles with high-speed\ngeneration. Challenges exist because of difficulties not only in accelerating\ndiffusion sampling but also VAE decoding in VDM, areas under-explored in\nprevious works. To address these challenges, we present FlashVDM, a systematic\nframework for accelerating both VAE and DiT in VDM. For DiT, FlashVDM enables\nflexible diffusion sampling with as few as 5 inference steps and comparable\nquality, which is made possible by stabilizing consistency distillation with\nour newly introduced Progressive Flow Distillation. For VAE, we introduce a\nlightning vecset decoder equipped with Adaptive KV Selection, Hierarchical\nVolume Decoding, and Efficient Network Design. By exploiting the locality of\nthe vecset and the sparsity of shape surface in the volume, our decoder\ndrastically lowers FLOPs, minimizing the overall decoding overhead. We apply\nFlashVDM to Hunyuan3D-2 to obtain Hunyuan3D-2 Turbo. Through systematic\nevaluation, we show that our model significantly outperforms existing fast 3D\ngeneration methods, achieving comparable performance to the state-of-the-art\nwhile reducing inference time by over 45x for reconstruction and 32x for\ngeneration. Code and models are available at\nhttps://github.com/Tencent/FlashVDM.",
      "tldr_zh": "该研究提出了FlashVDM框架，用于加速Vecset Diffusion Model（VDM）的3D形状生成。针对VDM在扩散采样和VAE解码中的效率瓶颈，FlashVDM通过渐进流蒸馏技术（Progressive Flow Distillation）实现仅需5步推理的高质量采样，并通过自适应KV选择、分层体积解码和高效网络设计显著降低解码开销。实验表明，FlashVDM在Hunyuan3D-2 Turbo模型上实现了45倍的重建加速和32倍的生成加速，性能媲美当前最优方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "Technical report",
      "pdf_url": "http://arxiv.org/pdf/2503.16302v1",
      "published_date": "2025-03-20 16:23:44 UTC",
      "updated_date": "2025-03-20 16:23:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:18:42.920120"
    },
    {
      "arxiv_id": "2503.16586v1",
      "title": "Big Help or Big Brother? Auditing Tracking, Profiling, and Personalization in Generative AI Assistants",
      "title_zh": "大帮手还是老大哥？生成式AI助手中的追踪、画像与个性化审计",
      "authors": [
        "Yash Vekaria",
        "Aurelio Loris Canino",
        "Jonathan Levitsky",
        "Alex Ciechonski",
        "Patricia Callejo",
        "Anna Maria Mandalari",
        "Zubair Shafiq"
      ],
      "abstract": "Generative AI (GenAI) browser assistants integrate powerful capabilities of\nGenAI in web browsers to provide rich experiences such as question answering,\ncontent summarization, and agentic navigation. These assistants, available\ntoday as browser extensions, can not only track detailed browsing activity such\nas search and click data, but can also autonomously perform tasks such as\nfilling forms, raising significant privacy concerns. It is crucial to\nunderstand the design and operation of GenAI browser extensions, including how\nthey collect, store, process, and share user data. To this end, we study their\nability to profile users and personalize their responses based on explicit or\ninferred demographic attributes and interests of users. We perform network\ntraffic analysis and use a novel prompting framework to audit tracking,\nprofiling, and personalization by the ten most popular GenAI browser assistant\nextensions. We find that instead of relying on local in-browser models, these\nassistants largely depend on server-side APIs, which can be auto-invoked\nwithout explicit user interaction. When invoked, they collect and share webpage\ncontent, often the full HTML DOM and sometimes even the user's form inputs,\nwith their first-party servers. Some assistants also share identifiers and user\nprompts with third-party trackers such as Google Analytics. The collection and\nsharing continues even if a webpage contains sensitive information such as\nhealth or personal information such as name or SSN entered in a web form. We\nfind that several GenAI browser assistants infer demographic attributes such as\nage, gender, income, and interests and use this profile--which carries across\nbrowsing contexts--to personalize responses. In summary, our work shows that\nGenAI browser assistants can and do collect personal and sensitive information\nfor profiling and personalization with little to no safeguards.",
      "tldr_zh": "本研究对十大流行的生成式AI（GenAI）浏览器助手扩展进行了审计，揭示其隐私风险。通过流量分析和提示框架，研究发现这些助手依赖服务器端API，自动收集并分享网页内容（包括完整HTML DOM和用户表单输入），甚至与第三方跟踪器共享用户标识符和提示。此外，部分助手根据用户浏览上下文推断年龄、性别、收入等人口属性，用于个性化响应，且缺乏有效保护措施。结果表明，GenAI浏览器助手在提供便利的同时，存在严重的隐私泄露隐患。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.CR",
        "cs.CY",
        "I.2; I.2.1; I.2.7; H.3.4; K.4; K.4.1; H.1; H.1.2; H.5.2; H.4.3"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16586v1",
      "published_date": "2025-03-20 16:21:47 UTC",
      "updated_date": "2025-03-20 16:21:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:18:49.588275"
    },
    {
      "arxiv_id": "2503.16290v1",
      "title": "Diffusion-augmented Graph Contrastive Learning for Collaborative Filter",
      "title_zh": "扩散增强的图对比学习用于协同过滤",
      "authors": [
        "Fan Huang",
        "Wei Wang"
      ],
      "abstract": "Graph-based collaborative filtering has been established as a prominent\napproach in recommendation systems, leveraging the inherent graph topology of\nuser-item interactions to model high-order connectivity patterns and enhance\nrecommendation performance. Recent advances in Graph Contrastive Learning (GCL)\nhave demonstrated promising potential to alleviate data sparsity issues by\nimproving representation learning through contrastive view generation and\nmutual information maximization. However, existing approaches lack effective\ndata augmentation strategies. Structural augmentation risks distorting\nfundamental graph topology, while feature-level perturbation techniques\npredominantly employ uniform noise scales that fail to account for\nnode-specific characteristics. To solve these challenges, we propose\nDiffusion-augmented Contrastive Learning (DGCL), an innovative framework that\nintegrates diffusion models with contrastive learning for enhanced\ncollaborative filtering. Our approach employs a diffusion process that learns\nnode-specific Gaussian distributions of representations, thereby generating\nsemantically consistent yet diversified contrastive views through reverse\ndiffusion sampling. DGCL facilitates adaptive data augmentation based on\nreconstructed representations, considering both semantic coherence and\nnode-specific features. In addition, it explores unrepresented regions of the\nlatent sparse feature space, thereby enriching the diversity of contrastive\nviews. Extensive experimental results demonstrate the effectiveness of DGCL on\nthree public datasets.",
      "tldr_zh": "该研究提出了一种基于扩散增强的图对比学习框架（DGCL），用于改进协同过滤推荐系统。该方法创新性地将扩散模型（Diffusion Model）与对比学习（Contrastive Learning）相结合，通过学习节点特定的高斯分布生成语义一致且多样化的对比视图，从而有效缓解数据稀疏性问题。实验结果表明，DGCL在三个公开数据集上显著提升了推荐性能。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16290v1",
      "published_date": "2025-03-20 16:15:20 UTC",
      "updated_date": "2025-03-20 16:15:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:19:45.250942"
    },
    {
      "arxiv_id": "2503.16248v1",
      "title": "AI Agents in Cryptoland: Practical Attacks and No Silver Bullet",
      "title_zh": "加密世界中的AI智能体：实际攻击与无银弹解决方案",
      "authors": [
        "Atharv Singh Patlan",
        "Peiyao Sheng",
        "S. Ashwin Hebbar",
        "Prateek Mittal",
        "Pramod Viswanath"
      ],
      "abstract": "The integration of AI agents with Web3 ecosystems harnesses their\ncomplementary potential for autonomy and openness, yet also introduces\nunderexplored security risks, as these agents dynamically interact with\nfinancial protocols and immutable smart contracts. This paper investigates the\nvulnerabilities of AI agents within blockchain-based financial ecosystems when\nexposed to adversarial threats in real-world scenarios. We introduce the\nconcept of context manipulation -- a comprehensive attack vector that exploits\nunprotected context surfaces, including input channels, memory modules, and\nexternal data feeds. Through empirical analysis of ElizaOS, a decentralized AI\nagent framework for automated Web3 operations, we demonstrate how adversaries\ncan manipulate context by injecting malicious instructions into prompts or\nhistorical interaction records, leading to unintended asset transfers and\nprotocol violations which could be financially devastating. Our findings\nindicate that prompt-based defenses are insufficient, as malicious inputs can\ncorrupt an agent's stored context, creating cascading vulnerabilities across\ninteractions and platforms. This research highlights the urgent need to develop\nAI agents that are both secure and fiduciarily responsible.",
      "tldr_zh": "本研究探讨了AI代理在区块链金融生态系统中的安全漏洞，提出了“上下文操纵”这一攻击向量，利用未受保护的输入通道、内存模块和外部数据源进行攻击。通过对ElizaOS（一种用于自动化Web3操作的去中心化AI代理框架）的实证分析，研究发现攻击者可以通过注入恶意指令或篡改历史交互记录，导致意外资产转移和协议违规，造成严重财务损失。研究指出，基于提示的防御措施不足，恶意输入会污染代理的存储上下文，引发跨交互和平台的级联漏洞，强调了开发安全且负责任的AI代理的紧迫性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CR",
      "comment": "12 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.16248v1",
      "published_date": "2025-03-20 15:44:31 UTC",
      "updated_date": "2025-03-20 15:44:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:20:15.861055"
    },
    {
      "arxiv_id": "2503.16227v1",
      "title": "Flight Testing an Optionally Piloted Aircraft: a Case Study on Trust Dynamics in Human-Autonomy Teaming",
      "title_zh": "可选驾驶飞机的飞行测试：人机协作中信任动态的案例研究",
      "authors": [
        "Jeremy C. -H. Wang",
        "Ming Hou",
        "David Dunwoody",
        "Marko Ilievski",
        "Justin Tomasi",
        "Edward Chao",
        "Carl Pigeon"
      ],
      "abstract": "This paper examines how trust is formed, maintained, or diminished over time\nin the context of human-autonomy teaming with an optionally piloted aircraft.\nWhereas traditional factor-based trust models offer a static representation of\nhuman confidence in technology, here we discuss how variations in the\nunderlying factors lead to variations in trust, trust thresholds, and human\nbehaviours. Over 200 hours of flight test data collected over a multi-year test\ncampaign from 2021 to 2023 were reviewed. The\ndispositional-situational-learned, process-performance-purpose, and IMPACTS\nhomeostasis trust models are applied to illuminate trust trends during nominal\nautonomous flight operations. The results offer promising directions for future\nstudies on trust dynamics and design-for-trust in human-autonomy teaming.",
      "tldr_zh": "本文研究了在可选有人驾驶飞机（Optionally Piloted Aircraft）的人机协作中，信任如何随时间形成、维持或减弱。通过分析2021至2023年间超过200小时的飞行测试数据，研究应用了多种信任模型（如dispositional-situational-learned、process-performance-purpose和IMPACTS homeostasis），揭示了在正常自主飞行操作中的信任动态变化。研究结果为未来人机协作中的信任动态研究及信任设计提供了新方向。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.ET",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.HC",
      "comment": "IEEE International Conference on Human-Machine Systems 2025,\n  keywords: trust, human factors, aviation, safety-critical, human-autonomy\n  teaming",
      "pdf_url": "http://arxiv.org/pdf/2503.16227v1",
      "published_date": "2025-03-20 15:22:39 UTC",
      "updated_date": "2025-03-20 15:22:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:20:19.670020"
    },
    {
      "arxiv_id": "2503.16212v1",
      "title": "MathFusion: Enhancing Mathematic Problem-solving of LLM through Instruction Fusion",
      "title_zh": "MathFusion：通过指令融合增强大语言模型的数学问题解决能力",
      "authors": [
        "Qizhi Pei",
        "Lijun Wu",
        "Zhuoshi Pan",
        "Yu Li",
        "Honglin Lin",
        "Chenlin Ming",
        "Xin Gao",
        "Conghui He",
        "Rui Yan"
      ],
      "abstract": "Large Language Models (LLMs) have shown impressive progress in mathematical\nreasoning. While data augmentation is promising to enhance mathematical\nproblem-solving ability, current approaches are predominantly limited to\ninstance-level modifications-such as rephrasing or generating syntactic\nvariations-which fail to capture and leverage the intrinsic relational\nstructures inherent in mathematical knowledge. Inspired by human learning\nprocesses, where mathematical proficiency develops through systematic exposure\nto interconnected concepts, we introduce MathFusion, a novel framework that\nenhances mathematical reasoning through cross-problem instruction synthesis.\nMathFusion implements this through three fusion strategies: (1) sequential\nfusion, which chains related problems to model solution dependencies; (2)\nparallel fusion, which combines analogous problems to reinforce conceptual\nunderstanding; and (3) conditional fusion, which creates context-aware\nselective problems to enhance reasoning flexibility. By applying these\nstrategies, we generate a new dataset, \\textbf{MathFusionQA}, followed by\nfine-tuning models (DeepSeekMath-7B, Mistral-7B, Llama3-8B) on it. Experimental\nresults demonstrate that MathFusion achieves substantial improvements in\nmathematical reasoning while maintaining high data efficiency, boosting\nperformance by 18.0 points in accuracy across diverse benchmarks while\nrequiring only 45K additional synthetic instructions, representing a\nsubstantial improvement over traditional single-instruction approaches. Our\ndatasets, models, and code are publicly available at\nhttps://github.com/QizhiPei/mathfusion.",
      "tldr_zh": "该研究提出了MathFusion框架，通过指令融合策略提升大语言模型（LLMs）的数学问题解决能力。MathFusion采用三种融合策略：**顺序融合**模拟解题依赖关系，**并行融合**强化概念理解，**条件融合**增强推理灵活性，并生成了新数据集MathFusionQA。实验表明，在仅增加45K合成指令的情况下，MathFusion显著提升了模型在多样化数学基准上的准确性，平均提高18.0分，优于传统的单指令方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2503.16212v1",
      "published_date": "2025-03-20 15:00:41 UTC",
      "updated_date": "2025-03-20 15:00:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:20:09.393708"
    },
    {
      "arxiv_id": "2503.16203v1",
      "title": "Logic Explanation of AI Classifiers by Categorical Explaining Functors",
      "title_zh": "AI分类器的逻辑解释：基于范畴解释函子的方法",
      "authors": [
        "Stefano Fioravanti",
        "Francesco Giannini",
        "Paolo Frazzetto",
        "Fabio Zanasi",
        "Pietro Barbiero"
      ],
      "abstract": "The most common methods in explainable artificial intelligence are post-hoc\ntechniques which identify the most relevant features used by pretrained opaque\nmodels. Some of the most advanced post hoc methods can generate explanations\nthat account for the mutual interactions of input features in the form of logic\nrules. However, these methods frequently fail to guarantee the consistency of\nthe extracted explanations with the model's underlying reasoning. To bridge\nthis gap, we propose a theoretically grounded approach to ensure coherence and\nfidelity of the extracted explanations, moving beyond the limitations of\ncurrent heuristic-based approaches. To this end, drawing from category theory,\nwe introduce an explaining functor which structurally preserves logical\nentailment between the explanation and the opaque model's reasoning. As a proof\nof concept, we validate the proposed theoretical constructions on a synthetic\nbenchmark verifying how the proposed approach significantly mitigates the\ngeneration of contradictory or unfaithful explanations.",
      "tldr_zh": "该研究提出了一种基于范畴论的解释性函子(explaining functor)方法，用于确保AI分类器解释的一致性和忠实性。与现有的启发式方法不同，该方法通过结构性地保持解释与不透明模型推理之间的逻辑蕴含关系，解决了当前后处理方法中解释与模型推理不一致的问题。作为概念验证，研究在合成基准上验证了该方法显著减少了矛盾或不忠实解释的生成，为可解释AI提供了理论支撑。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16203v1",
      "published_date": "2025-03-20 14:50:06 UTC",
      "updated_date": "2025-03-20 14:50:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:20:16.042478"
    },
    {
      "arxiv_id": "2503.16191v1",
      "title": "Large Language Models for Water Distribution Systems Modeling and Decision-Making",
      "title_zh": "大型语言模型在供水系统建模与决策中的应用",
      "authors": [
        "Yinon Goldshtein",
        "Gal Perelman",
        "Assaf Schuster",
        "Avi Ostfeld"
      ],
      "abstract": "The design, operations, and management of water distribution systems (WDS)\ninvolve complex mathematical models. These models are continually improving due\nto computational advancements, leading to better decision-making and more\nefficient WDS management. However, the significant time and effort required for\nmodeling, programming, and analyzing results remain substantial challenges.\nAnother issue is the professional burden, which confines the interaction with\nmodels, databases, and other sophisticated tools to a small group of experts,\nthereby causing non-technical stakeholders to depend on these experts or make\ndecisions without modeling support. Furthermore, explaining model results is\nchallenging even for experts, as it is often unclear which conditions cause the\nmodel to reach a certain state or recommend a specific policy. The recent\nadvancements in Large Language Models (LLMs) open doors for a new stage in\nhuman-model interaction. This study proposes a framework of plain language\ninteractions with hydraulic and water quality models based on LLM-EPANET\narchitecture. This framework is tested with increasing levels of complexity of\nqueries to study the ability of LLMs to interact with WDS models, run complex\nsimulations, and report simulation results. The performance of the proposed\nframework is evaluated across several categories of queries and hyper-parameter\nconfigurations, demonstrating its potential to enhance decision-making\nprocesses in WDS management.",
      "tldr_zh": "该研究提出了一种基于大型语言模型（LLMs）的框架，用于简化供水系统（WDS）的建模和决策过程。通过LLM-EPANET架构，该框架支持以自然语言与水力和水质模型交互，运行复杂模拟并报告结果。实验表明，该框架能够有效处理多种查询，显著降低建模的技术门槛，为非技术利益相关者提供决策支持，同时提升专家解释模型结果的能力。这一方法为供水系统管理中的高效决策开辟了新途径。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to EWRI Congress 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.16191v1",
      "published_date": "2025-03-20 14:39:11 UTC",
      "updated_date": "2025-03-20 14:39:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:20:31.899964"
    },
    {
      "arxiv_id": "2503.16184v1",
      "title": "Accurate Scene Text Recognition with Efficient Model Scaling and Cloze Self-Distillation",
      "title_zh": "基于高效模型缩放与填空自蒸馏的精准场景文本识别",
      "authors": [
        "Andrea Maracani",
        "Savas Ozkan",
        "Sijun Cho",
        "Hyowon Kim",
        "Eunchung Noh",
        "Jeongwon Min",
        "Cho Jung Min",
        "Dookun Park",
        "Mete Ozay"
      ],
      "abstract": "Scaling architectures have been proven effective for improving Scene Text\nRecognition (STR), but the individual contribution of vision encoder and text\ndecoder scaling remain under-explored. In this work, we present an in-depth\nempirical analysis and demonstrate that, contrary to previous observations,\nscaling the decoder yields significant performance gains, always exceeding\nthose achieved by encoder scaling alone. We also identify label noise as a key\nchallenge in STR, particularly in real-world data, which can limit the\neffectiveness of STR models. To address this, we propose Cloze\nSelf-Distillation (CSD), a method that mitigates label noise by distilling a\nstudent model from context-aware soft predictions and pseudolabels generated by\na teacher model. Additionally, we enhance the decoder architecture by\nintroducing differential cross-attention for STR. Our methodology achieves\nstate-of-the-art performance on 10 out of 11 benchmarks using only real data,\nwhile significantly reducing the parameter size and computational costs.",
      "tldr_zh": "本研究深入分析了场景文本识别（STR）中视觉编码器和文本解码器扩展的个体贡献，发现解码器扩展能显著提升性能，且效果超过单独扩展编码器。针对真实数据中的标签噪声问题，提出了Cloze Self-Distillation (CSD)方法，通过教师模型生成上下文感知的软预测和伪标签来训练学生模型，从而缓解噪声影响。此外，引入差分交叉注意力机制优化解码器架构。该方法在11个基准中的10个上实现了最先进的性能，同时显著减少了参数规模和计算成本。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16184v1",
      "published_date": "2025-03-20 14:35:46 UTC",
      "updated_date": "2025-03-20 14:35:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:20:28.419078"
    },
    {
      "arxiv_id": "2503.16583v1",
      "title": "Explainable AI-Guided Efficient Approximate DNN Generation for Multi-Pod Systolic Arrays",
      "title_zh": "可解释AI引导的面向多Pod脉动阵列的高效近似深度神经网络生成",
      "authors": [
        "Ayesha Siddique",
        "Khurram Khalil",
        "Khaza Anuarul Hoque"
      ],
      "abstract": "Approximate deep neural networks (AxDNNs) are promising for enhancing energy\nefficiency in real-world devices. One of the key contributors behind this\nenhanced energy efficiency in AxDNNs is the use of approximate multipliers.\nUnfortunately, the simulation of approximate multipliers does not usually scale\nwell on CPUs and GPUs. As a consequence, this slows down the overall simulation\nof AxDNNs aimed at identifying the appropriate approximate multipliers to\nachieve high energy efficiency with a minimum accuracy loss. To address this\nproblem, we present a novel XAI-Gen methodology, which leverages the analytical\nmodel of the emerging hardware accelerator (e.g., Google TPU v4) and\nexplainable artificial intelligence (XAI) to precisely identify the\nnon-critical layers for approximation and quickly discover the appropriate\napproximate multipliers for AxDNN layers. Our results show that XAI-Gen\nachieves up to 7x lower energy consumption with only 1-2% accuracy loss. We\nalso showcase the effectiveness of the XAI-Gen approach through a neural\narchitecture search (XAI-NAS) case study. Interestingly, XAI-NAS achieves 40\\%\nhigher energy efficiency with up to 5x less execution time when compared to the\nstate-of-the-art NAS methods for generating AxDNNs.",
      "tldr_zh": "该研究提出了一种名为XAI-Gen的新方法，利用可解释人工智能（XAI）和新兴硬件加速器（如Google TPU v4）的分析模型，高效生成近似深度神经网络（AxDNNs）。该方法通过精准识别非关键层并快速选择适当的近似乘法器，实现了高达7倍的能耗降低，同时仅损失1-2%的精度。此外，研究还通过XAI-NAS案例展示了该方法在神经架构搜索中的有效性，与现有NAS方法相比，能耗效率提升40%，执行时间减少5倍。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper has been accepted in the ISQED 2025 conference",
      "pdf_url": "http://arxiv.org/pdf/2503.16583v1",
      "published_date": "2025-03-20 14:26:47 UTC",
      "updated_date": "2025-03-20 14:26:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:20:42.507031"
    },
    {
      "arxiv_id": "2503.16161v1",
      "title": "Towards Lighter and Robust Evaluation for Retrieval Augmented Generation",
      "title_zh": "迈向更轻量且稳健的检索增强生成评估",
      "authors": [
        "Alex-Razvan Ispas",
        "Charles-Elie Simon",
        "Fabien Caspani",
        "Vincent Guigue"
      ],
      "abstract": "Large Language Models are prompting us to view more NLP tasks from a\ngenerative perspective. At the same time, they offer a new way of accessing\ninformation, mainly through the RAG framework. While there have been notable\nimprovements for the autoregressive models, overcoming hallucination in the\ngenerated answers remains a continuous problem. A standard solution is to use\ncommercial LLMs, such as GPT4, to evaluate these algorithms. However, such\nframeworks are expensive and not very transparent. Therefore, we propose a\nstudy which demonstrates the interest of open-weight models for evaluating RAG\nhallucination. We develop a lightweight approach using smaller, quantized LLMs\nto provide an accessible and interpretable metric that gives continuous scores\nfor the generated answer with respect to their correctness and faithfulness.\nThis score allows us to question decisions' reliability and explore thresholds\nto develop a new AUC metric as an alternative to correlation with human\njudgment.",
      "tldr_zh": "该研究提出了一种更轻量且鲁棒的评估方法，用于检索增强生成（RAG）框架中的生成结果。针对大型语言模型（LLMs）生成答案中的幻觉问题，研究摒弃了依赖昂贵且不透明的商业模型（如GPT-4）的评估方式，转而采用开源的轻量化量化模型。通过开发一种可解释的连续评分指标，研究能够评估生成答案的正确性和忠实性，并探索决策可靠性阈值，提出了一种新的AUC指标作为与人工判断相关性的替代方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "62-08",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages, 5 figures, published at 1st workshop of Quantify\n  Uncertainty and Hallucination in Foundation Models: The Next Frontier in\n  Reliable AI at ICLR 25",
      "pdf_url": "http://arxiv.org/pdf/2503.16161v1",
      "published_date": "2025-03-20 13:58:32 UTC",
      "updated_date": "2025-03-20 13:58:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:21:04.539604"
    },
    {
      "arxiv_id": "2503.16159v1",
      "title": "Neural Combinatorial Optimization for Real-World Routing",
      "title_zh": "面向现实世界路径规划的神经组合优化",
      "authors": [
        "Jiwoo Son",
        "Zhikai Zhao",
        "Federico Berto",
        "Chuanbo Hua",
        "Changhyun Kwon",
        "Jinkyoo Park"
      ],
      "abstract": "Vehicle Routing Problems (VRPs) are a class of NP-hard problems ubiquitous in\nseveral real-world logistics scenarios that pose significant challenges for\noptimization. Neural Combinatorial Optimization (NCO) has emerged as a\npromising alternative to classical approaches, as it can learn fast heuristics\nto solve VRPs. However, most research works in NCO for VRPs focus on simplified\nsettings, which do not account for asymmetric distances and travel durations\nthat cannot be derived by simple Euclidean distances and unrealistic data\ndistributions, hindering real-world deployment. This work introduces RRNCO\n(Real Routing NCO) to bridge the gap of NCO between synthetic and real-world\nVRPs in the critical aspects of both data and modeling. First, we introduce a\nnew, openly available dataset with real-world data containing a diverse dataset\nof locations, distances, and duration matrices from 100 cities, considering\nrealistic settings with actual routing distances and durations obtained from\nOpen Source Routing Machine (OSRM). Second, we propose a novel approach that\nefficiently processes both node and edge features through contextual gating,\nenabling the construction of more informed node embedding, and we finally\nincorporate an Adaptation Attention Free Module (AAFM) with neural adaptive\nbias mechanisms that effectively integrates not only distance matrices but also\nangular relationships between nodes, allowing our model to capture rich\nstructural information. RRNCO achieves state-of-the-art results in real-world\nVRPs among NCO methods. We make our dataset and code publicly available at\nhttps://github.com/ai4co/real-routing-nco.",
      "tldr_zh": "该研究提出了RRNCO（Real Routing NCO），旨在解决神经组合优化（NCO）在真实世界车辆路径问题（VRPs）中的应用局限性。研究首先发布了一个包含100个城市真实地理位置、距离和时长矩阵的公开数据集，基于开源路由机（OSRM）获取真实路由数据。其次，提出了一种新方法，通过上下文门控高效处理节点和边特征，并结合自适应注意力自由模块（AAFM）和神经自适应偏置机制，有效整合距离矩阵和节点间的角度关系，从而捕捉丰富的结构信息。RRNCO在真实世界VRPs中取得了NCO方法的领先性能，并公开了数据集和代码。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16159v1",
      "published_date": "2025-03-20 13:57:33 UTC",
      "updated_date": "2025-03-20 13:57:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:21:11.081301"
    },
    {
      "arxiv_id": "2503.16144v1",
      "title": "Unify and Triumph: Polyglot, Diverse, and Self-Consistent Generation of Unit Tests with LLMs",
      "title_zh": "统一与胜利：利用大语言模型实现多语言、多样化和自一致性的单元测试生成",
      "authors": [
        "Djamel Eddine Khelladi",
        "Charly Reux",
        "Mathieu Acher"
      ],
      "abstract": "Large language model (LLM)-based test generation has gained attention in\nsoftware engineering, yet most studies evaluate LLMs' ability to generate unit\ntests in a single attempt for a given language, missing the opportunity to\nleverage LLM diversity for more robust testing. This paper introduces PolyTest,\na novel approach that enhances test generation by exploiting polyglot and\ntemperature-controlled diversity. PolyTest systematically leverages these\nproperties in two complementary ways: (1) Cross-lingual test generation, where\ntests are generated in multiple languages at zero temperature and then unified;\n(2) Diverse test sampling, where multiple test sets are generated within the\nsame language at a higher temperature before unification. A key insight is that\nLLMs can generate diverse yet contradicting tests -- same input, different\nexpected outputs -- across languages and generations. PolyTest mitigates\ninconsistencies by unifying test sets, fostering self-consistency and improving\noverall test quality. Unlike single-language or single-attempt approaches,\nPolyTest enhances testing without requiring on-the-fly execution, making it\nparticularly beneficial for weaker-performing languages. We evaluate PolyTest\non Llama3-70B, GPT-4o, and GPT-3.5 using EvalPlus, generating tests in five\nlanguages (Java, C, Python, JavaScript, and a CSV-based format) at temperature\n0 and sampling multiple sets at temperature 1. We observe that LLMs frequently\ngenerate contradicting tests across settings, and that PolyTest significantly\nimproves test quality across all considered metrics -- number of tests, passing\nrate, statement/branch coverage (up to +9.01%), and mutation score (up to\n+11.23%). Finally, PolyTest outperforms Pynguin in test generation, passing\nrate, and mutation score.",
      "tldr_zh": "该论文提出了PolyTest，一种利用大语言模型（LLMs）生成多语言、多样化且自一致单元测试的新方法。PolyTest通过跨语言测试生成和多样化测试采样，系统性利用LLMs的多语言能力和温度控制多样性，生成并统一测试集，解决了LLMs在不同语言和生成过程中可能产生的矛盾测试问题。实验表明，PolyTest在五种编程语言（Java、C、Python、JavaScript和CSV格式）上显著提升了测试数量、通过率、语句/分支覆盖率（最高提升9.01%）和变异分数（最高提升11.23%），并优于Pynguin等现有工具。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16144v1",
      "published_date": "2025-03-20 13:47:06 UTC",
      "updated_date": "2025-03-20 13:47:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:21:30.415058"
    },
    {
      "arxiv_id": "2503.16582v1",
      "title": "Machine Learning-Based Genomic Linguistic Analysis (Gene Sequence Feature Learning): A Case Study on Predicting Heavy Metal Response Genes in Rice",
      "title_zh": "基于机器学习的基因组语言分析（基因序列特征学习）：以水稻重金属响应基因预测为例",
      "authors": [
        "Ruiqi Yang",
        "Jianxu Wang",
        "Wei Yuan",
        "Xun Wang",
        "Mei Li"
      ],
      "abstract": "This study explores the application of machine learning-based genetic\nlinguistics for identifying heavy metal response genes in rice (Oryza sativa).\nBy integrating convolutional neural networks and random forest algorithms, we\ndeveloped a hybrid model capable of extracting and learning meaningful features\nfrom gene sequences, such as k-mer frequencies and physicochemical properties.\nThe model was trained and tested on datasets of genes, achieving high\npredictive performance (precision: 0.89, F1-score: 0.82). RNA-seq and qRT-PCR\nexperiments conducted on rice leaves which exposed to Hg0, revealed\ndifferential expression of genes associated with heavy metal responses, which\nvalidated the model's predictions. Co-expression network analysis identified\n103 related genes, and a literature review indicated that these genes are\nhighly likely to be involved in heavy metal-related biological processes. By\nintegrating and comparing the analysis results with those of differentially\nexpressed genes (DEGs), the validity of the new machine learning method was\nfurther demonstrated. This study highlights the efficacy of combining machine\nlearning with genetic linguistics for large-scale gene prediction. It\ndemonstrates a cost-effective and efficient approach for uncovering molecular\nmechanisms underlying heavy metal responses, with potential applications in\ndeveloping stress-tolerant crop varieties.",
      "tldr_zh": "本研究提出了一种基于机器学习的基因组语言学分析方法，用于预测水稻中的重金属响应基因。通过结合卷积神经网络(CNN)和随机森林算法，开发了一种混合模型，能够从基因序列中提取并学习k-mer频率和理化性质等特征。实验结果表明，该模型具有较高的预测性能（精确度：0.89，F1分数：0.82），并通过RNA-seq和qRT-PCR实验验证了其预测结果。此外，共表达网络分析识别出103个相关基因，进一步证实了这些基因在重金属响应中的重要作用。该方法为大规模基因预测提供了一种高效且低成本的新途径，并有助于开发抗逆作物品种。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.GN"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16582v1",
      "published_date": "2025-03-20 13:41:31 UTC",
      "updated_date": "2025-03-20 13:41:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:22:09.276738"
    },
    {
      "arxiv_id": "2503.16581v1",
      "title": "Investigating Retrieval-Augmented Generation in Quranic Studies: A Study of 13 Open-Source Large Language Models",
      "title_zh": "探究检索增强生成在《古兰经》研究中的应用：对13个开源大型语言模型的研究",
      "authors": [
        "Zahra Khalila",
        "Arbi Haza Nasution",
        "Winda Monika",
        "Aytug Onan",
        "Yohei Murakami",
        "Yasir Bin Ismail Radi",
        "Noor Mohammad Osmani"
      ],
      "abstract": "Accurate and contextually faithful responses are critical when applying large\nlanguage models (LLMs) to sensitive and domain-specific tasks, such as\nanswering queries related to quranic studies. General-purpose LLMs often\nstruggle with hallucinations, where generated responses deviate from\nauthoritative sources, raising concerns about their reliability in religious\ncontexts. This challenge highlights the need for systems that can integrate\ndomain-specific knowledge while maintaining response accuracy, relevance, and\nfaithfulness. In this study, we investigate 13 open-source LLMs categorized\ninto large (e.g., Llama3:70b, Gemma2:27b, QwQ:32b), medium (e.g., Gemma2:9b,\nLlama3:8b), and small (e.g., Llama3.2:3b, Phi3:3.8b). A Retrieval-Augmented\nGeneration (RAG) is used to make up for the problems that come with using\nseparate models. This research utilizes a descriptive dataset of Quranic surahs\nincluding the meanings, historical context, and qualities of the 114 surahs,\nallowing the model to gather relevant knowledge before responding. The models\nare evaluated using three key metrics set by human evaluators: context\nrelevance, answer faithfulness, and answer relevance. The findings reveal that\nlarge models consistently outperform smaller models in capturing query\nsemantics and producing accurate, contextually grounded responses. The\nLlama3.2:3b model, even though it is considered small, does very well on\nfaithfulness (4.619) and relevance (4.857), showing the promise of smaller\narchitectures that have been well optimized. This article examines the\ntrade-offs between model size, computational efficiency, and response quality\nwhile using LLMs in domain-specific applications.",
      "tldr_zh": "本研究探讨了检索增强生成（RAG）在《古兰经》研究中的应用，评估了13种开源大语言模型（LLMs）的性能。研究使用包含114章《古兰经》经文意义、历史背景和特点的描述性数据集，通过RAG技术弥补模型在领域知识上的不足。评估指标包括上下文相关性、回答忠实性和回答相关性，结果显示大型模型（如Llama3:70b）在语义捕捉和准确回答上表现更优，而优化后的小型模型（如Llama3.2:3b）在忠实性和相关性上也表现出色。研究揭示了模型规模、计算效率和响应质量之间的权衡，为领域特定应用提供了参考。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages, keywords: Large-language-models; retrieval-augmented\n  generation; question answering; Quranic studies; Islamic teachings",
      "pdf_url": "http://arxiv.org/pdf/2503.16581v1",
      "published_date": "2025-03-20 13:26:30 UTC",
      "updated_date": "2025-03-20 13:26:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:22:10.655537"
    },
    {
      "arxiv_id": "2503.16112v1",
      "title": "PromptMobile: Efficient Promptus for Low Bandwidth Mobile Video Streaming",
      "title_zh": "PromptMobile：面向低带宽移动视频流的高效 Promptus 框架",
      "authors": [
        "Liming Liu",
        "Jiangkai Wu",
        "Haoyang Wang",
        "Peiheng Wang",
        "Xinggong Zhang",
        "Zongming Guo"
      ],
      "abstract": "Traditional video compression algorithms exhibit significant quality\ndegradation at extremely low bitrates. Promptus emerges as a new paradigm for\nvideo streaming, substantially cutting down the bandwidth essential for video\nstreaming. However, Promptus is computationally intensive and can not run in\nreal-time on mobile devices. This paper presents PromptMobile, an efficient\nacceleration framework tailored for on-device Promptus. Specifically, we\npropose (1) a two-stage efficient generation framework to reduce computational\ncost by 8.1x, (2) a fine-grained inter-frame caching to reduce redundant\ncomputations by 16.6\\%, (3) system-level optimizations to further enhance\nefficiency. The evaluations demonstrate that compared with the original\nPromptus, PromptMobile achieves a 13.6x increase in image generation speed.\nCompared with other streaming methods, PromptMobile achives an average LPIPS\nimprovement of 0.016 (compared with H.265), reducing 60\\% of severely distorted\nframes (compared to VQGAN).",
      "tldr_zh": "本文提出了PromptMobile，一种专为移动设备优化的高效Promptus加速框架，旨在解决传统视频压缩算法在极低比特率下质量显著下降的问题。通过两阶段生成框架、细粒度帧间缓存和系统级优化，PromptMobile将计算成本降低了8.1倍，冗余计算减少了16.6%，图像生成速度提升了13.6倍。实验表明，相比H.265，PromptMobile在LPIPS指标上平均提升了0.016，并减少了60%的严重失真帧，显著提升了低带宽移动视频流的质量和效率。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.NI",
      "comment": "7 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.16112v1",
      "published_date": "2025-03-20 13:00:36 UTC",
      "updated_date": "2025-03-20 13:00:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:21:59.114624"
    },
    {
      "arxiv_id": "2503.16091v1",
      "title": "AIMI: Leveraging Future Knowledge and Personalization in Sparse Event Forecasting for Treatment Adherence",
      "title_zh": "AIMI：在稀疏事件预测中利用未来知识与个性化提升治疗依从性",
      "authors": [
        "Abdullah Mamun",
        "Diane J. Cook",
        "Hassan Ghasemzadeh"
      ],
      "abstract": "Adherence to prescribed treatments is crucial for individuals with chronic\nconditions to avoid costly or adverse health outcomes. For certain patient\ngroups, intensive lifestyle interventions are vital for enhancing medication\nadherence. Accurate forecasting of treatment adherence can open pathways to\ndeveloping an on-demand intervention tool, enabling timely and personalized\nsupport. With the increasing popularity of smartphones and wearables, it is now\neasier than ever to develop and deploy smart activity monitoring systems.\nHowever, effective forecasting systems for treatment adherence based on\nwearable sensors are still not widely available. We close this gap by proposing\nAdherence Forecasting and Intervention with Machine Intelligence (AIMI). AIMI\nis a knowledge-guided adherence forecasting system that leverages smartphone\nsensors and previous medication history to estimate the likelihood of\nforgetting to take a prescribed medication. A user study was conducted with 27\nparticipants who took daily medications to manage their cardiovascular\ndiseases. We designed and developed CNN and LSTM-based forecasting models with\nvarious combinations of input features and found that LSTM models can forecast\nmedication adherence with an accuracy of 0.932 and an F-1 score of 0.936.\nMoreover, through a series of ablation studies involving convolutional and\nrecurrent neural network architectures, we demonstrate that leveraging known\nknowledge about future and personalized training enhances the accuracy of\nmedication adherence forecasting. Code available:\nhttps://github.com/ab9mamun/AIMI.",
      "tldr_zh": "该研究提出了AIMI（基于机器智能的依从性预测与干预系统），旨在通过智能手机传感器和用药历史数据预测患者忘记服药的可能性。系统结合卷积神经网络(CNN)和长短期记忆网络(LSTM)模型，并利用未来知识和个性化训练提升预测精度。在27名心血管疾病患者的实验中，LSTM模型实现了0.932的准确率和0.936的F1分数，表明其在慢性病治疗依从性预测中的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.16091v1",
      "published_date": "2025-03-20 12:32:35 UTC",
      "updated_date": "2025-03-20 12:32:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:22:25.211523"
    },
    {
      "arxiv_id": "2503.16085v1",
      "title": "Allostatic Control of Persistent States in Spiking Neural Networks for perception and computation",
      "title_zh": "用于感知与计算的全状态控制下脉冲神经网络中的持久状态调控",
      "authors": [
        "Aung Htet",
        "Alejandro Rodriguez Jimenez",
        "Sarah Hamburg",
        "Alessandro Di Nuovo"
      ],
      "abstract": "We introduce a novel model for updating perceptual beliefs about the\nenvironment by extending the concept of Allostasis to the control of internal\nrepresentations. Allostasis is a fundamental regulatory mechanism observed in\nanimal physiology that orchestrates responses to maintain a dynamic equilibrium\nin bodily needs and internal states. In this paper, we focus on an application\nin numerical cognition, where a bump of activity in an attractor network is\nused as a spatial numerical representation. While existing neural networks can\nmaintain persistent states, to date, there is no unified framework for\ndynamically controlling spatial changes in neuronal activity in response to\nenvironmental changes. To address this, we couple a well known allostatic\nmicrocircuit, the Hammel model, with a ring attractor, resulting in a Spiking\nNeural Network architecture that can modulate the location of the bump as a\nfunction of some reference input. This localized activity in turn is used as a\nperceptual belief in a simulated subitization task a quick enumeration process\nwithout counting. We provide a general procedure to fine-tune the model and\ndemonstrate the successful control of the bump location. We also study the\nresponse time in the model with respect to changes in parameters and compare it\nwith biological data. Finally, we analyze the dynamics of the network to\nunderstand the selectivity and specificity of different neurons to distinct\ncategories present in the input. The results of this paper, particularly the\nmechanism for moving persistent states, are not limited to numerical cognition\nbut can be applied to a wide range of tasks involving similar representations.",
      "tldr_zh": "本研究提出了一种基于Allostasis（动态平衡调节机制）的新型Spiking Neural Network（SNN）模型，用于动态控制内部表征以更新环境感知信念。通过将Hammel微电路与环形吸引子网络结合，该模型能够根据参考输入调节活动峰（bump）的位置，并将其作为感知信念应用于快速枚举任务（subitization）。研究提供了模型调优方法，成功实现了活动峰位置的控制，并分析了网络动态特性与神经元选择性。该机制不仅适用于数值认知，还可推广至其他涉及类似表征的任务。",
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16085v1",
      "published_date": "2025-03-20 12:28:08 UTC",
      "updated_date": "2025-03-20 12:28:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:22:06.663139"
    },
    {
      "arxiv_id": "2503.16075v1",
      "title": "3-D Image-to-Image Fusion in Lightsheet Microscopy by Two-Step Adversarial Network: Contribution to the FuseMyCells Challenge",
      "title_zh": "基于两步对抗网络的光片显微镜三维图像融合：FuseMyCells挑战赛的贡献",
      "authors": [
        "Marek Wodzinski",
        "Henning Müller"
      ],
      "abstract": "Lightsheet microscopy is a powerful 3-D imaging technique that addresses\nlimitations of traditional optical and confocal microscopy but suffers from a\nlow penetration depth and reduced image quality at greater depths. Multiview\nlightsheet microscopy improves 3-D resolution by combining multiple views but\nsimultaneously increasing the complexity and the photon budget, leading to\npotential photobleaching and phototoxicity. The FuseMyCells challenge,\norganized in conjunction with the IEEE ISBI 2025 conference, aims to benchmark\ndeep learning-based solutions for fusing high-quality 3-D volumes from single\n3-D views, potentially simplifying procedures and conserving the photon budget.\nIn this work, we propose a contribution to the FuseMyCells challenge based on a\ntwo-step procedure. The first step processes a downsampled version of the image\nto capture the entire region of interest, while the second step uses a\npatch-based approach for high-resolution inference, incorporating adversarial\nloss to enhance visual outcomes. This method addresses challenges related to\nhigh data resolution, the necessity of global context, and the preservation of\nhigh-frequency details. Experimental results demonstrate the effectiveness of\nour approach, highlighting its potential to improve 3-D image fusion quality\nand extend the capabilities of lightsheet microscopy. The average SSIM for the\nnucleus and membranes is greater than 0.85 and 0.91, respectively.",
      "tldr_zh": "本研究提出了一种基于两步对抗网络的3D图像融合方法，用于解决光片显微镜中深度成像质量下降的问题。该方法首先对下采样图像进行全局处理，捕捉感兴趣区域，随后通过基于patch的高分辨率推理结合对抗损失提升视觉效果，解决了高数据分辨率、全局上下文需求和高频细节保留等挑战。实验结果表明，该方法显著提升了3D图像融合质量，核与膜的平均SSIM分别超过0.85和0.91，为光片显微镜的应用提供了更高效的解决方案。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16075v1",
      "published_date": "2025-03-20 12:12:01 UTC",
      "updated_date": "2025-03-20 12:12:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:22:41.163004"
    },
    {
      "arxiv_id": "2503.16072v1",
      "title": "Redefining Toxicity: An Objective and Context-Aware Approach for Stress-Level-Based Detection",
      "title_zh": "重新定义毒性：一种基于压力水平的客观且情境感知的检测方法",
      "authors": [
        "Sergey Berezin",
        "Reza Farahbakhsh",
        "Noel Crespi"
      ],
      "abstract": "The fundamental problem of toxicity detection lies in the fact that the term\n\"toxicity\" is ill-defined. Such uncertainty causes researchers to rely on\nsubjective and vague data during model training, which leads to non-robust and\ninaccurate results, following the 'garbage in - garbage out' paradigm. This\nstudy introduces a novel, objective, and context-aware framework for toxicity\ndetection, leveraging stress levels as a key determinant of toxicity. We\npropose new definition, metric and training approach as a parts of our\nframework and demonstrate it's effectiveness using a dataset we collected.",
      "tldr_zh": "本研究提出了一种基于压力水平的客观且情境感知的毒性检测框架，重新定义了“毒性”这一模糊概念。通过引入新的定义、指标和训练方法，该框架有效解决了传统方法因依赖主观数据而导致的不准确性问题。研究团队还构建了一个专用数据集，验证了该框架的显著效果。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16072v1",
      "published_date": "2025-03-20 12:09:01 UTC",
      "updated_date": "2025-03-20 12:09:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:23:17.935092"
    },
    {
      "arxiv_id": "2503.16071v1",
      "title": "Tuning LLMs by RAG Principles: Towards LLM-native Memory",
      "title_zh": "基于RAG原则调优LLM：迈向LLM原生记忆",
      "authors": [
        "Jiale Wei",
        "Shuchi Wu",
        "Ruochen Liu",
        "Xiang Ying",
        "Jingbo Shang",
        "Fangbo Tao"
      ],
      "abstract": "Memory, additional information beyond the training of large language models\n(LLMs), is crucial to various real-world applications, such as personal\nassistant. The two mainstream solutions to incorporate memory into the\ngeneration process are long-context LLMs and retrieval-augmented generation\n(RAG). In this paper, we first systematically compare these two types of\nsolutions on three renovated/new datasets and show that (1) long-context\nsolutions, although more expensive, shall be easier to capture the big picture\nand better answer queries which require considering the memory as a whole; and\n(2) when the queries concern specific information, RAG solutions shall be more\ncompetitive especially when the keywords can be explicitly matched. Therefore,\nwe propose a novel method RAG-Tuned-LLM which fine-tunes a relative small\n(e.g., 7B) LLM using the data generated following the RAG principles, so it can\ncombine the advantages of both solutions. Extensive experiments on three\ndatasets demonstrate that RAG-Tuned-LLM can beat long-context LLMs and RAG\nmethods across a wide range of query types.",
      "tldr_zh": "该研究提出了一种结合长上下文LLM和检索增强生成(RAG)优势的新方法RAG-Tuned-LLM，通过基于RAG原则生成的数据微调小型LLM（如7B），使其能够更好地利用记忆信息。实验表明，RAG-Tuned-LLM在三种数据集上均优于长上下文LLM和RAG方法，能够有效应对不同类型的查询需求，既能在需要全局记忆时表现优异，也能在涉及特定信息时更具竞争力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16071v1",
      "published_date": "2025-03-20 12:04:40 UTC",
      "updated_date": "2025-03-20 12:04:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:22:53.606292"
    },
    {
      "arxiv_id": "2503.16064v1",
      "title": "PromptHash: Affinity-Prompted Collaborative Cross-Modal Learning for Adaptive Hashing Retrieval",
      "title_zh": "PromptHash：基于亲和提示的协作跨模态学习用于自适应哈希检索",
      "authors": [
        "Qiang Zou",
        "Shuli Cheng",
        "Jiayi Chen"
      ],
      "abstract": "Cross-modal hashing is a promising approach for efficient data retrieval and\nstorage optimization. However, contemporary methods exhibit significant\nlimitations in semantic preservation, contextual integrity, and information\nredundancy, which constrains retrieval efficacy. We present PromptHash, an\ninnovative framework leveraging affinity prompt-aware collaborative learning\nfor adaptive cross-modal hashing. We propose an end-to-end framework for\naffinity-prompted collaborative hashing, with the following fundamental\ntechnical contributions: (i) a text affinity prompt learning mechanism that\npreserves contextual information while maintaining parameter efficiency, (ii)\nan adaptive gated selection fusion architecture that synthesizes State Space\nModel with Transformer network for precise cross-modal feature integration, and\n(iii) a prompt affinity alignment strategy that bridges modal heterogeneity\nthrough hierarchical contrastive learning. To the best of our knowledge, this\nstudy presents the first investigation into affinity prompt awareness within\ncollaborative cross-modal adaptive hash learning, establishing a paradigm for\nenhanced semantic consistency across modalities. Through comprehensive\nevaluation on three benchmark multi-label datasets, PromptHash demonstrates\nsubstantial performance improvements over existing approaches. Notably, on the\nNUS-WIDE dataset, our method achieves significant gains of 18.22% and 18.65% in\nimage-to-text and text-to-image retrieval tasks, respectively. The code is\npublicly available at https://github.com/ShiShuMo/PromptHash.",
      "tldr_zh": "本文提出了PromptHash，一种基于亲和提示（affinity prompt）的协作跨模态学习框架，用于自适应哈希检索。该框架通过文本亲和提示学习机制、自适应门控选择融合架构和提示亲和对齐策略，解决了现有跨模态哈希方法在语义保存、上下文完整性和信息冗余方面的不足。实验表明，PromptHash在NUS-WIDE等数据集上显著提升了图像到文本和文本到图像的检索性能，分别提高了18.22%和18.65%。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.IR",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR2025",
      "pdf_url": "http://arxiv.org/pdf/2503.16064v1",
      "published_date": "2025-03-20 11:56:27 UTC",
      "updated_date": "2025-03-20 11:56:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:22:47.453808"
    },
    {
      "arxiv_id": "2503.16063v1",
      "title": "Two-stage Incomplete Utterance Rewriting on Editing Operation",
      "title_zh": "基于编辑操作的两阶段不完整话语改写",
      "authors": [
        "Zhiyu Cao",
        "Peifeng Li",
        "Qiaoming Zhu",
        "Yaxin Fan"
      ],
      "abstract": "Previous work on Incomplete Utterance Rewriting (IUR) has primarily focused\non generating rewritten utterances based solely on dialogue context, ignoring\nthe widespread phenomenon of coreference and ellipsis in dialogues. To address\nthis issue, we propose a novel framework called TEO (\\emph{Two-stage approach\non Editing Operation}) for IUR, in which the first stage generates editing\noperations and the second stage rewrites incomplete utterances utilizing the\ngenerated editing operations and the dialogue context. Furthermore, an\nadversarial perturbation strategy is proposed to mitigate cascading errors and\nexposure bias caused by the inconsistency between training and inference in the\nsecond stage. Experimental results on three IUR datasets show that our TEO\noutperforms the SOTA models significantly.",
      "tldr_zh": "该研究提出了TEO框架，采用两阶段方法解决不完整话语改写(IUR)问题。第一阶段生成编辑操作，第二阶段结合对话上下文和编辑操作进行改写。此外，作者提出了一种对抗扰动策略，以减轻训练与推理不一致导致的级联错误和暴露偏差。实验表明，TEO在三个IUR数据集上显著优于现有的最先进模型。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16063v1",
      "published_date": "2025-03-20 11:56:14 UTC",
      "updated_date": "2025-03-20 11:56:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:23:37.624978"
    },
    {
      "arxiv_id": "2503.16057v2",
      "title": "Expert Race: A Flexible Routing Strategy for Scaling Diffusion Transformer with Mixture of Experts",
      "title_zh": "Expert Race：一种灵活的路由策略，用于扩展混合专家扩散变换器",
      "authors": [
        "Yike Yuan",
        "Ziyu Wang",
        "Zihao Huang",
        "Defa Zhu",
        "Xun Zhou",
        "Jingyi Yu",
        "Qiyang Min"
      ],
      "abstract": "Diffusion models have emerged as mainstream framework in visual generation.\nBuilding upon this success, the integration of Mixture of Experts (MoE) methods\nhas shown promise in enhancing model scalability and performance. In this\npaper, we introduce Race-DiT, a novel MoE model for diffusion transformers with\na flexible routing strategy, Expert Race. By allowing tokens and experts to\ncompete together and select the top candidates, the model learns to dynamically\nassign experts to critical tokens. Additionally, we propose per-layer\nregularization to address challenges in shallow layer learning, and router\nsimilarity loss to prevent mode collapse, ensuring better expert utilization.\nExtensive experiments on ImageNet validate the effectiveness of our approach,\nshowcasing significant performance gains while promising scaling properties.",
      "tldr_zh": "本文提出了Race-DiT，一种基于专家竞争（Expert Race）路由策略的混合专家（MoE）扩散Transformer模型。该策略通过动态分配专家给关键token，并引入逐层正则化和路由器相似性损失，解决了浅层学习困难和模式崩溃问题。在ImageNet上的实验表明，Race-DiT在显著提升性能的同时，展现了良好的扩展性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16057v2",
      "published_date": "2025-03-20 11:45:08 UTC",
      "updated_date": "2025-03-25 08:56:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:23:43.362922"
    },
    {
      "arxiv_id": "2503.16047v2",
      "title": "Temporal-Spatial Attention Network (TSAN) for DoS Attack Detection in Network Traffic",
      "title_zh": "时空间注意力网络（TSAN）：用于网络流量中的DoS攻击检测",
      "authors": [
        "Bisola Faith Kayode",
        "Akinyemi Sadeeq Akintola",
        "Oluwole Fagbohun",
        "Egonna Anaesiuba-Bristol",
        "Onyekachukwu Ojumah",
        "Oluwagbade Odimayo",
        "Toyese Oloyede",
        "Aniema Inyang",
        "Teslim Kazeem",
        "Habeeb Alli",
        "Udodirim Ibem Offia",
        "Prisca Chinazor Amajuoyi"
      ],
      "abstract": "Denial-of-Service (DoS) attacks remain a critical threat to network security,\ndisrupting services and causing significant economic losses. Traditional\ndetection methods, including statistical and rule-based models, struggle to\nadapt to evolving attack patterns. To address this challenge, we propose a\nnovel Temporal-Spatial Attention Network (TSAN) architecture for detecting\nDenial of Service (DoS) attacks in network traffic. By leveraging both temporal\nand spatial features of network traffic, our approach captures complex traffic\npatterns and anomalies that traditional methods might miss. The TSAN model\nincorporates transformer-based temporal encoding, convolutional spatial\nencoding, and a cross-attention mechanism to fuse these complementary feature\nspaces. Additionally, we employ multi-task learning with auxiliary tasks to\nenhance the model's robustness. Experimental results on the NSL-KDD dataset\ndemonstrate that TSAN outperforms state-of-the-art models, achieving superior\naccuracy, precision, recall, and F1-score while maintaining computational\nefficiency for real-time deployment. The proposed architecture offers an\noptimal balance between detection accuracy and computational overhead, making\nit highly suitable for real-world network security applications.",
      "tldr_zh": "该研究提出了一种新型的时空注意力网络（TSAN），用于检测网络流量中的拒绝服务（DoS）攻击。TSAN结合了基于Transformer的时间编码、卷积空间编码和交叉注意力机制，能够有效捕捉传统方法难以识别的复杂流量模式和异常。通过在NSL-KDD数据集上的实验，TSAN在准确性、精确率、召回率和F1分数上均优于现有模型，同时保持了计算效率，适合实际网络安全应用。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "19 Pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.16047v2",
      "published_date": "2025-03-20 11:31:45 UTC",
      "updated_date": "2025-03-21 17:40:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:23:46.841038"
    },
    {
      "arxiv_id": "2503.16045v1",
      "title": "Open Science and Artificial Intelligence for supporting the sustainability of the SRC Network: The espSRC case",
      "title_zh": "开放科学与人工智能助力SRC网络可持续发展：以espSRC为例",
      "authors": [
        "J. Garrido",
        "S. Sánchez-Expósito",
        "A. Ruiz-Falcó",
        "J. Ruedas",
        "M. Á. Mendoza",
        "V. Vázquez",
        "M. Parra",
        "J. Sánchez",
        "I. Labadie",
        "L. Darriba",
        "J. Moldón",
        "M. Rodriguez-Álvarez",
        "J. Díaz",
        "L. Verdes-Montenegro"
      ],
      "abstract": "The SKA Observatory (SKAO), a landmark project in radio astronomy, seeks to\naddress fundamental questions in astronomy. To process its immense data output,\napproximately 700 PB/year, a global network of SKA Regional Centres (SR-CNet)\nwill provide the infrastructure, tools, computational power needed for\nscientific analysis and scientific support. The Spanish SRC (espSRC) focuses on\nensuring the sustainability of this network by reducing its environmental\nimpact, integrating green practices into data platforms, and developing Open\nScience technologies to enable reproducible research. This paper discusses and\nsummarizes part of the research and development activities that the team is\nconducting to reduce the SRC energy consumption at the espSRC and SRCNet. The\npaper also discusses fundamental research on trusted repositories to support\nOpen Science practices.",
      "tldr_zh": "该研究探讨了西班牙SKA区域中心(espSRC)如何通过开放科学和人工智能技术，支持SKA区域中心网络(SRCNet)的可持续发展。重点包括：开发绿色数据平台以减少能耗，构建可信赖的存储库以促进开放科学实践，以及开展基础研究以实现可重复性科学分析。这些举措旨在降低SRCNet的环境影响，同时确保其处理SKA天文台每年约700PB数据的能力。",
      "categories": [
        "astro-ph.IM",
        "cs.AI"
      ],
      "primary_category": "astro-ph.IM",
      "comment": "Conference: Astronomical Data Analysis Software & Systems - ADASS\n  XXXIV - 2024",
      "pdf_url": "http://arxiv.org/pdf/2503.16045v1",
      "published_date": "2025-03-20 11:29:00 UTC",
      "updated_date": "2025-03-20 11:29:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:24:00.089424"
    },
    {
      "arxiv_id": "2503.16043v1",
      "title": "Incomplete Utterance Rewriting with Editing Operation Guidance and Utterance Augmentation",
      "title_zh": "基于编辑操作引导与话语增强的不完整话语改写",
      "authors": [
        "Zhiyu Cao",
        "Peifeng Li",
        "Yaxin Fan",
        "Qiaoming Zhu"
      ],
      "abstract": "Although existing fashionable generation methods on Incomplete Utterance\nRewriting (IUR) can generate coherent utterances, they often result in the\ninclusion of irrelevant and redundant tokens in rewritten utterances due to\ntheir inability to focus on critical tokens in dialogue context. Furthermore,\nthe limited size of the training datasets also contributes to the insufficient\ntraining of the IUR model. To address the first issue, we propose a multi-task\nlearning framework EO-IUR (Editing Operation-guided Incomplete Utterance\nRewriting) that introduces the editing operation labels generated by sequence\nlabeling module to guide generation model to focus on critical tokens.\nFurthermore, we introduce a token-level heterogeneous graph to represent\ndialogues. To address the second issue, we propose a two-dimensional utterance\naugmentation strategy, namely editing operation-based incomplete utterance\naugmentation and LLM-based historical utterance augmentation. The experimental\nresults on three datasets demonstrate that our EO-IUR outperforms previous\nstate-of-the-art (SOTA) baselines in both open-domain and task-oriented\ndialogue. The code will be available at https://github.com/Dewset/EO-IUR.",
      "tldr_zh": "本文提出了一种新的不完整话语改写（IUR）方法EO-IUR，通过引入编辑操作标签指导生成模型聚焦关键词语，解决了现有方法生成冗余和无关词语的问题。此外，作者提出了一种二维话语增强策略，包括基于编辑操作的不完整话语增强和基于LLM的历史话语增强，以缓解训练数据不足的问题。实验结果表明，EO-IUR在开放域和任务导向对话数据集上均优于现有最先进方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16043v1",
      "published_date": "2025-03-20 11:26:46 UTC",
      "updated_date": "2025-03-20 11:26:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:24:09.763161"
    },
    {
      "arxiv_id": "2503.16041v2",
      "title": "GreenIQ: A Deep Search Platform for Comprehensive Carbon Market Analysis and Automated Report Generation",
      "title_zh": "GreenIQ：面向碳市场全面分析与自动化报告生成的深度搜索平台",
      "authors": [
        "Oluwole Fagbohun",
        "Sai Yashwanth",
        "Akinyemi Sadeeq Akintola",
        "Ifeoluwa Wurola",
        "Lanre Shittu",
        "Aniema Inyang",
        "Oluwatimilehin Odubola",
        "Udodirim Offia",
        "Said Olanrewaju",
        "Ogidan Toluwaleke",
        "Ilemona Abutu",
        "Taiwo Akinbolaji"
      ],
      "abstract": "This study introduces GreenIQ, an AI-powered deep search platform designed to\nrevolutionise carbon market intelligence through autonomous analysis and\nautomated report generation. Carbon markets operate across diverse regulatory\nlandscapes, generating vast amounts of heterogeneous data from policy\ndocuments, industry reports, academic literature, and real-time trading\nplatforms. Traditional research approaches remain labour-intensive, slow, and\ndifficult to scale. GreenIQ addresses these limitations through a multi-agent\narchitecture powered by Large Language Models (LLMs), integrating five\nspecialised AI agents: a Main Researcher Agent for intelligent information\nretrieval, a Report Writing Agent for structured synthesis, a Final Reviewer\nAgent for accuracy verification, a Data Visualisation Agent for enhanced\ninterpretability, and a Translator Agent for multilingual adaptation. The\nsystem achieves seamless integration of structured and unstructured information\nwith AI-driven citation verification, ensuring high transparency and\nreliability. GreenIQ delivers a 99.2\\% reduction in processing time and a\n99.7\\% cost reduction compared to traditional research methodologies. A novel\nAI persona-based evaluation framework involving 16 domain-specific AI personas\nhighlights its superior cross-jurisdictional analytical capabilities and\nregulatory insight generation. GreenIQ sets new standards in AI-driven research\nsynthesis, policy analysis, and sustainability finance by streamlining carbon\nmarket research. It offers an efficient and scalable framework for\nenvironmental and financial intelligence, enabling more accurate, timely, and\ncost-effective decision-making in complex regulatory landscapes",
      "tldr_zh": "该研究提出了GreenIQ，一个基于大语言模型(LLMs)的深度搜索平台，旨在实现碳市场智能分析的自动化和报告生成的规模化。GreenIQ采用多智能体架构，整合了信息检索、报告撰写、数据可视化等五大AI代理，实现了结构化与非结构化数据的无缝集成与AI驱动的引用验证，显著提升了透明度和可靠性。实验表明，与传统研究方法相比，GreenIQ处理时间减少99.2%，成本降低99.7%，并通过基于AI角色的评估框架验证了其跨司法管辖区的分析能力与监管洞察力。该平台为碳市场研究提供了高效、可扩展的解决方案，推动了环境与金融智能的发展。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "12 Pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2503.16041v2",
      "published_date": "2025-03-20 11:19:43 UTC",
      "updated_date": "2025-03-21 17:33:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:24:18.340899"
    },
    {
      "arxiv_id": "2503.16036v1",
      "title": "Hybrid-Level Instruction Injection for Video Token Compression in Multi-modal Large Language Models",
      "title_zh": "多模态大语言模型中视频令牌压缩的混合级指令注入",
      "authors": [
        "Zhihang Liu",
        "Chen-Wei Xie",
        "Pandeng Li",
        "Liming Zhao",
        "Longxiang Tang",
        "Yun Zheng",
        "Chuanbin Liu",
        "Hongtao Xie"
      ],
      "abstract": "Recent Multi-modal Large Language Models (MLLMs) have been challenged by the\ncomputational overhead resulting from massive video frames, often alleviated\nthrough compression strategies. However, the visual content is not equally\ncontributed to user instructions, existing strategies (\\eg, average pool)\ninevitably lead to the loss of potentially useful information. To tackle this,\nwe propose the Hybrid-level Instruction Injection Strategy for Conditional\nToken Compression in MLLMs (HICom), utilizing the instruction as a condition to\nguide the compression from both local and global levels. This encourages the\ncompression to retain the maximum amount of user-focused information while\nreducing visual tokens to minimize computational burden. Specifically, the\ninstruction condition is injected into the grouped visual tokens at the local\nlevel and the learnable tokens at the global level, and we conduct the\nattention mechanism to complete the conditional compression. From the\nhybrid-level compression, the instruction-relevant visual parts are highlighted\nwhile the temporal-spatial structure is also preserved for easier understanding\nof LLMs. To further unleash the potential of HICom, we introduce a new\nconditional pre-training stage with our proposed dataset HICom-248K.\nExperiments show that our HICom can obtain distinguished video understanding\nability with fewer tokens, increasing the performance by 2.43\\% average on\nthree multiple-choice QA benchmarks and saving 78.8\\% tokens compared with the\nSOTA method. The code is available at https://github.com/lntzm/HICom.",
      "tldr_zh": "本研究提出了混合级指令注入策略HICom，用于多模态大语言模型(MLLMs)中的视频Token压缩。该方法通过将用户指令作为条件，从局部和全局两个层级指导视觉Token的压缩，在减少计算负担的同时最大限度地保留用户关注的信息。具体而言，指令条件被注入到局部层级的视觉Token分组和全局层级的可学习Token中，并通过注意力机制完成条件压缩。实验表明，HICom在三个多选题问答基准上的平均性能提升了2.43%，同时比现有最优方法节省了78.8%的Token。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to CVPR2025",
      "pdf_url": "http://arxiv.org/pdf/2503.16036v1",
      "published_date": "2025-03-20 11:09:18 UTC",
      "updated_date": "2025-03-20 11:09:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:24:31.839693"
    },
    {
      "arxiv_id": "2503.16025v1",
      "title": "Single Image Iterative Subject-driven Generation and Editing",
      "title_zh": "单图像迭代主题驱动生成与编辑",
      "authors": [
        "Yair Shpitzer",
        "Gal Chechik",
        "Idan Schwartz"
      ],
      "abstract": "Personalizing image generation and editing is particularly challenging when\nwe only have a few images of the subject, or even a single image. A common\napproach to personalization is concept learning, which can integrate the\nsubject into existing models relatively quickly, but produces images whose\nquality tends to deteriorate quickly when the number of subject images is\nsmall. Quality can be improved by pre-training an encoder, but training\nrestricts generation to the training distribution, and is time consuming. It is\nstill an open hard challenge to personalize image generation and editing from a\nsingle image without training. Here, we present SISO, a novel, training-free\napproach based on optimizing a similarity score with an input subject image.\nMore specifically, SISO iteratively generates images and optimizes the model\nbased on loss of similarity with the given subject image until a satisfactory\nlevel of similarity is achieved, allowing plug-and-play optimization to any\nimage generator. We evaluated SISO in two tasks, image editing and image\ngeneration, using a diverse data set of personal subjects, and demonstrate\nsignificant improvements over existing methods in image quality, subject\nfidelity, and background preservation.",
      "tldr_zh": "该研究提出了一种无需训练的个性化图像生成与编辑方法SISO，通过优化与输入主题图像的相似度得分来实现。SISO通过迭代生成图像并基于相似度损失优化模型，直到达到满意的相似度水平，适用于任何图像生成器的即插即用优化。实验表明，SISO在图像编辑和生成任务中显著提升了图像质量、主题保真度和背景保留效果，尤其在仅使用单张图像时表现优异。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page is at https://siso-paper.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2503.16025v1",
      "published_date": "2025-03-20 10:45:04 UTC",
      "updated_date": "2025-03-20 10:45:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:24:24.526046"
    },
    {
      "arxiv_id": "2503.16024v1",
      "title": "The Lighthouse of Language: Enhancing LLM Agents via Critique-Guided Improvement",
      "title_zh": "语言灯塔：通过批判引导改进增强LLM智能体",
      "authors": [
        "Ruihan Yang",
        "Fanghua Ye",
        "Jian Li",
        "Siyu Yuan",
        "Yikai Zhang",
        "Zhaopeng Tu",
        "Xiaolong Li",
        "Deqing Yang"
      ],
      "abstract": "Large language models (LLMs) have recently transformed from text-based\nassistants to autonomous agents capable of planning, reasoning, and iteratively\nimproving their actions. While numerical reward signals and verifiers can\neffectively rank candidate actions, they often provide limited contextual\nguidance. In contrast, natural language feedback better aligns with the\ngenerative capabilities of LLMs, providing richer and more actionable\nsuggestions. However, parsing and implementing this feedback effectively can be\nchallenging for LLM-based agents. In this work, we introduce Critique-Guided\nImprovement (CGI), a novel two-player framework, comprising an actor model that\nexplores an environment and a critic model that generates detailed nature\nlanguage feedback. By training the critic to produce fine-grained assessments\nand actionable revisions, and the actor to utilize these critiques, our\napproach promotes more robust exploration of alternative strategies while\navoiding local optima. Experiments in three interactive environments show that\nCGI outperforms existing baselines by a substantial margin. Notably, even a\nsmall critic model surpasses GPT-4 in feedback quality. The resulting actor\nachieves state-of-the-art performance, demonstrating the power of explicit\niterative guidance to enhance decision-making in LLM-based agents.",
      "tldr_zh": "本研究提出了一种名为Critique-Guided Improvement (CGI)的双智能体框架，旨在通过自然语言反馈提升大语言模型(LLM)智能体的性能。该框架包含两个核心组件：负责环境探索的actor模型和生成详细反馈的critic模型。通过训练critic生成细粒度的评估和可操作的修订建议，并让actor利用这些反馈，CGI能够促进更稳健的策略探索，避免陷入局部最优。实验表明，CGI在三个交互环境中的表现显著优于现有基线方法，甚至小型critic模型的反馈质量也超越了GPT-4，最终实现了最先进的性能，证明了显式迭代指导对提升LLM智能体决策能力的重要性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16024v1",
      "published_date": "2025-03-20 10:42:33 UTC",
      "updated_date": "2025-03-20 10:42:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:24:56.274763"
    },
    {
      "arxiv_id": "2503.16021v2",
      "title": "Autonomous AI imitators increase diversity in homogeneous information ecosystems",
      "title_zh": "自主AI模仿者提升了同质信息生态系统中的多样性",
      "authors": [
        "Emil Bakkensen Johansen",
        "Oliver Baumann"
      ],
      "abstract": "Recent breakthroughs in large language models (LLMs) have facilitated\nautonomous AI agents capable of imitating human-generated content. This\ntechnological advancement raises fundamental questions about AI's impact on the\ndiversity and democratic value of information ecosystems. We introduce a\nlarge-scale simulation framework to examine AI-based imitation within news, a\ncontext crucial for public discourse. By systematically testing two distinct\nimitation strategies across a range of information environments varying in\ninitial diversity, we demonstrate that AI-generated articles do not uniformly\nhomogenize content. Instead, AI's influence is strongly context-dependent:\nAI-generated content can introduce valuable diversity in originally homogeneous\nnews environments but diminish diversity in initially heterogeneous contexts.\nThese results illustrate that the initial diversity of an information\nenvironment critically shapes AI's impact, challenging assumptions that\nAI-driven imitation uniformly threatens diversity. Instead, when information is\ninitially homogeneous, AI-driven imitation can expand perspectives, styles, and\ntopics. This is especially important in news contexts, where information\ndiversity fosters richer public debate by exposing citizens to alternative\nviewpoints, challenging biases, and preventing narrative monopolies, which is\nessential for a resilient democracy.",
      "tldr_zh": "研究探讨了大型语言模型（LLMs）驱动的自主AI模仿者对信息生态系统多样性的影响。通过大规模模拟框架，研究发现AI生成的内容并非一律导致同质化，而是强烈依赖于初始信息环境的多样性：在原本同质的新闻环境中，AI模仿者能够引入有价值的多样性，丰富观点、风格和话题；而在原本异质的环境中，AI则可能减少多样性。这一发现挑战了AI模仿必然威胁多样性的假设，并强调了在新闻领域，AI模仿有助于促进公共辩论的丰富性和民主韧性。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "J.4"
      ],
      "primary_category": "cs.CY",
      "comment": "35 pages, 10 figures, 4 tables; v2: corrected typographical errors,\n  streamlined language, updated abstract, added supplementary information",
      "pdf_url": "http://arxiv.org/pdf/2503.16021v2",
      "published_date": "2025-03-20 10:37:29 UTC",
      "updated_date": "2025-03-21 13:35:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:25:39.547631"
    },
    {
      "arxiv_id": "2503.18964v1",
      "title": "Unifying EEG and Speech for Emotion Recognition: A Two-Step Joint Learning Framework for Handling Missing EEG Data During Inference",
      "title_zh": "统一脑电图与语音进行情感识别：一种处理推理过程中缺失脑电图数据的两步联合学习框架",
      "authors": [
        "Upasana Tiwari",
        "Rupayan Chakraborty",
        "Sunil Kumar Kopparapu"
      ],
      "abstract": "Computer interfaces are advancing towards using multi-modalities to enable\nbetter human-computer interactions. The use of automatic emotion recognition\n(AER) can make the interactions natural and meaningful thereby enhancing the\nuser experience. Though speech is the most direct and intuitive modality for\nAER, it is not reliable because it can be intentionally faked by humans. On the\nother hand, physiological modalities like EEG, are more reliable and impossible\nto fake. However, use of EEG is infeasible for realistic scenarios usage\nbecause of the need for specialized recording setup. In this paper, one of our\nprimary aims is to ride on the reliability of the EEG modality to facilitate\nrobust AER on the speech modality. Our approach uses both the modalities during\ntraining to reliably identify emotion at the time of inference, even in the\nabsence of the more reliable EEG modality. We propose, a two-step joint\nmulti-modal learning approach (JMML) that exploits both the intra- and inter-\nmodal characteristics to construct emotion embeddings that enrich the\nperformance of AER. In the first step, using JEC-SSL, intra-modal learning is\ndone independently on the individual modalities. This is followed by an\ninter-modal learning using the proposed extended variant of deep canonically\ncorrelated cross-modal autoencoder (E-DCC-CAE). The approach learns the joint\nproperties of both the modalities by mapping them into a common representation\nspace, such that the modalities are maximally correlated. These emotion\nembeddings, hold properties of both the modalities there by enhancing the\nperformance of ML classifier used for AER. Experimental results show the\nefficacy of the proposed approach. To best of our knowledge, this is the first\nattempt to combine speech and EEG with joint multi-modal learning approach for\nreliable AER.",
      "tldr_zh": "本文提出了一种两步联合多模态学习框架（JMML），用于结合脑电图（EEG）和语音进行情绪识别（AER），以解决推理阶段EEG数据缺失的问题。该方法首先通过JEC-SSL进行模态内学习，随后利用扩展的深度典型相关跨模态自编码器（E-DCC-CAE）进行模态间学习，将两种模态映射到共同表示空间以最大化相关性。实验表明，该方法在缺少EEG数据时仍能实现可靠的情绪识别，为多模态情绪识别提供了新思路。",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "comment": "10 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.18964v1",
      "published_date": "2025-03-20 10:26:49 UTC",
      "updated_date": "2025-03-20 10:26:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:26:04.249212"
    },
    {
      "arxiv_id": "2503.16577v1",
      "title": "Feature selection strategies for optimized heart disease diagnosis using ML and DL models",
      "title_zh": "基于机器学习和深度学习模型优化心脏病诊断的特征选择策略",
      "authors": [
        "Bilal Ahmad",
        "Jinfu Chen",
        "Haibao Chen"
      ],
      "abstract": "Heart disease remains one of the leading causes of morbidity and mortality\nworldwide, necessitating the development of effective diagnostic tools to\nenable early diagnosis and clinical decision-making. This study evaluates the\nimpact of feature selection techniques Mutual Information (MI), Analysis of\nVariance (ANOVA), and Chi-Square on the predictive performance of various\nmachine learning (ML) and deep learning (DL) models using a dataset of clinical\nindicators for heart disease. Eleven ML/DL models were assessed using metrics\nsuch as precision, recall, AUC score, F1-score, and accuracy. Results indicate\nthat MI outperformed other methods, particularly for advanced models like\nneural networks, achieving the highest accuracy of 82.3% and recall score of\n0.94. Logistic regression (accuracy 82.1%) and random forest (accuracy 80.99%)\nalso demonstrated improved performance with MI. Simpler models such as Naive\nBayes and decision trees achieved comparable results with ANOVA and Chi-Square,\nyielding accuracies of 76.45% and 75.99%, respectively, making them\ncomputationally efficient alternatives. Conversely, k Nearest Neighbors (KNN)\nand Support Vector Machines (SVM) exhibited lower performance, with accuracies\nranging between 51.52% and 54.43%, regardless of the feature selection method.\nThis study provides a comprehensive comparison of feature selection methods for\nheart disease prediction, demonstrating the critical role of feature selection\nin optimizing model performance. The results offer practical guidance for\nselecting appropriate feature selection techniques based on the chosen\nclassification algorithm, contributing to the development of more accurate and\nefficient diagnostic tools for enhanced clinical decision-making in cardiology.",
      "tldr_zh": "本研究评估了互信息(MI)、方差分析(ANOVA)和卡方检验(Chi-Square)等特征选择方法对多种机器学习(ML)和深度学习(DL)模型在心脏病预测中的性能影响。结果表明，MI在神经网络等高级模型中表现最佳，准确率达82.3%，召回率为0.94；逻辑回归和随机森林在MI下也表现优异。相比之下，KNN和SVM无论采用哪种特征选择方法，准确率均较低。研究为不同分类算法选择特征选择方法提供了实用指导，有助于开发更准确、高效的心脏病诊断工具。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16577v1",
      "published_date": "2025-03-20 09:59:01 UTC",
      "updated_date": "2025-03-20 09:59:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:26:32.500408"
    },
    {
      "arxiv_id": "2503.16575v1",
      "title": "Extract, Match, and Score: An Evaluation Paradigm for Long Question-context-answer Triplets in Financial Analysis",
      "title_zh": "提取、匹配与评分：金融分析中长问题-上下文-答案三元组的评估范式",
      "authors": [
        "Bo Hu",
        "Han Yuan",
        "Vlad Pandelea",
        "Wuqiong Luo",
        "Yingzhu Zhao",
        "Zheng Ma"
      ],
      "abstract": "The rapid advancement of large language models (LLMs) has sparked widespread\nadoption across diverse applications, making robust evaluation frameworks\ncrucial for assessing their performance. While conventional evaluation metrics\nremain applicable for shorter texts, their efficacy diminishes when evaluating\nthe quality of long-form answers. This limitation is particularly critical in\nreal-world scenarios involving extended questions, extensive context, and\nlong-form answers, such as financial analysis or regulatory compliance. In this\npaper, we use a practical financial use case to illustrate applications that\nhandle \"long question-context-answer triplets\". We construct a real-world\nfinancial dataset comprising long triplets and demonstrate the inadequacies of\ntraditional metrics. To address this, we propose an effective Extract, Match,\nand Score (EMS) evaluation approach tailored to the complexities of long-form\nLLMs' outputs, providing practitioners with a reliable methodology for\nassessing LLMs' performance in complex real-world scenarios.",
      "tldr_zh": "本文提出了一种针对长问题-上下文-答案三元组的评估范式“提取、匹配与评分”(EMS)，特别适用于金融分析等复杂场景。传统评估指标在处理长文本时效果不佳，而EMS方法通过提取关键信息、匹配语义内容并评分，有效解决了这一问题。研究构建了一个真实金融数据集，展示了EMS在评估大语言模型(LLMs)长文本生成能力中的优势，为复杂实际场景下的模型性能评估提供了可靠方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16575v1",
      "published_date": "2025-03-20 09:38:44 UTC",
      "updated_date": "2025-03-20 09:38:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:26:11.821125"
    },
    {
      "arxiv_id": "2503.15985v1",
      "title": "Exploring the Reliability of Self-explanation and its Relationship with Classification in Language Model-driven Financial Analysis",
      "title_zh": "探索自我解释的可靠性及其与语言模型驱动金融分析中分类的关系",
      "authors": [
        "Han Yuan",
        "Li Zhang",
        "Zheng Ma"
      ],
      "abstract": "Language models (LMs) have exhibited exceptional versatility in reasoning and\nin-depth financial analysis through their proprietary information processing\ncapabilities. Previous research focused on evaluating classification\nperformance while often overlooking explainability or pre-conceived that\nrefined explanation corresponds to higher classification accuracy. Using a\npublic dataset in finance domain, we quantitatively evaluated self-explanations\nby LMs, focusing on their factuality and causality. We identified the\nstatistically significant relationship between the accuracy of classifications\nand the factuality or causality of self-explanations. Our study built an\nempirical foundation for approximating classification confidence through\nself-explanations and for optimizing classification via proprietary reasoning.",
      "tldr_zh": "本研究探讨了语言模型(LMs)在金融分析中自我解释的可靠性及其与分类性能的关系。通过定量评估LMs自我解释的事实性和因果性，研究发现分类准确性与自我解释的事实性和因果性之间存在显著统计相关性。该研究为通过自我解释近似分类置信度以及通过专有推理优化分类奠定了实证基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15985v1",
      "published_date": "2025-03-20 09:33:59 UTC",
      "updated_date": "2025-03-20 09:33:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:26:15.732505"
    },
    {
      "arxiv_id": "2503.16573v1",
      "title": "AUV Acceleration Prediction Using DVL and Deep Learning",
      "title_zh": "基于DVL与深度学习的AUV加速度预测",
      "authors": [
        "Yair Stolero",
        "Itzik Klein"
      ],
      "abstract": "Autonomous underwater vehicles (AUVs) are essential for various applications,\nincluding oceanographic surveys, underwater mapping, and infrastructure\ninspections. Accurate and robust navigation are critical to completing these\ntasks. To this end, a Doppler velocity log (DVL) and inertial sensors are fused\ntogether. Recently, a model-based approach demonstrated the ability to extract\nthe vehicle acceleration vector from DVL velocity measurements. Motivated by\nthis advancement, in this paper we present an end-to-end deep learning approach\nto estimate the AUV acceleration vector based on past DVL velocity\nmeasurements. Based on recorded data from sea experiments, we demonstrate that\nthe proposed method improves acceleration vector estimation by more than 65%\ncompared to the model-based approach by using data-driven techniques. As a\nresult of our data-driven approach, we can enhance navigation accuracy and\nreliability in AUV applications, contributing to more efficient and effective\nunderwater missions through improved accuracy and reliability.",
      "tldr_zh": "本研究提出了一种基于深度学习的端到端方法，用于从多普勒速度计(DVL)历史速度数据中预测自主水下航行器(AUV)的加速度向量。相比传统模型驱动方法，该数据驱动方法在海上实验数据上的加速度估计精度提高了65%以上。通过提升导航精度和可靠性，该方法有助于实现更高效、更稳定的水下任务执行。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16573v1",
      "published_date": "2025-03-20 09:33:47 UTC",
      "updated_date": "2025-03-20 09:33:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:26:37.360732"
    },
    {
      "arxiv_id": "2503.15984v1",
      "title": "DIPLI: Deep Image Prior Lucky Imaging for Blind Astronomical Image Restoration",
      "title_zh": "DIPLI：基于深度图像先验的幸运成像盲天文图像恢复",
      "authors": [
        "Suraj Singh",
        "Anastasia Batsheva",
        "Oleg Y. Rogov",
        "Ahmed Bouridane"
      ],
      "abstract": "Contemporary image restoration and super-resolution techniques effectively\nharness deep neural networks, markedly outperforming traditional methods.\nHowever, astrophotography presents unique challenges for deep learning due to\nlimited training data. This work explores hybrid strategies, such as the Deep\nImage Prior (DIP) model, which facilitates blind training but is susceptible to\noverfitting, artifact generation, and instability when handling noisy images.\nWe propose enhancements to the DIP model's baseline performance through several\nadvanced techniques. First, we refine the model to process multiple frames\nconcurrently, employing the Back Projection method and the TVNet model. Next,\nwe adopt a Markov approach incorporating Monte Carlo estimation, Langevin\ndynamics, and a variational input technique to achieve unbiased estimates with\nminimal variance and counteract overfitting effectively. Collectively, these\nmodifications reduce the likelihood of noise learning and mitigate loss\nfunction fluctuations during training, enhancing result stability. We validated\nour algorithm across multiple image sets of astronomical and celestial objects,\nachieving performance that not only mitigates limitations of Lucky Imaging, a\nclassical computer vision technique that remains a standard in astronomical\nimage reconstruction but surpasses the original DIP model, state of the art\ntransformer- and diffusion-based models, underscoring the significance of our\nimprovements.",
      "tldr_zh": "本文提出了DIPLI方法，通过改进Deep Image Prior (DIP)模型来解决天文图像盲恢复中的问题。针对DIP模型的过拟合、噪声敏感性和不稳定性，研究采用了多帧并行处理、Back Projection方法、TVNet模型以及基于马尔可夫过程的Monte Carlo估计和Langevin动力学等技术。这些改进有效减少了噪声学习和训练过程中的损失函数波动，提升了结果的稳定性。实验表明，DIPLI在多个天文图像数据集上的表现不仅超越了经典的Lucky Imaging技术，还优于原始的DIP模型以及基于Transformer和Diffusion的先进模型，为天文图像恢复提供了更优的解决方案。",
      "categories": [
        "cs.CV",
        "astro-ph.IM",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 7 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.15984v1",
      "published_date": "2025-03-20 09:33:16 UTC",
      "updated_date": "2025-03-20 09:33:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:26:35.290965"
    },
    {
      "arxiv_id": "2503.15983v1",
      "title": "InhibiDistilbert: Knowledge Distillation for a ReLU and Addition-based Transformer",
      "title_zh": "InhibiDistilbert：基于ReLU与加法运算的Transformer知识蒸馏",
      "authors": [
        "Tony Zhang",
        "Rickard Brännvall"
      ],
      "abstract": "This work explores optimizing transformer-based language models by\nintegrating model compression techniques with inhibitor attention, a novel\nalternative attention mechanism. Inhibitor attention employs Manhattan\ndistances and ReLU activations instead of the matrix multiplications and\nsoftmax activation of the conventional scaled dot-product attention. This shift\noffers potential computational and energy savings while maintaining model\neffectiveness. We propose further adjustments to improve the inhibitor\nmechanism's training efficiency and evaluate its performance on the DistilBERT\narchitecture. Our knowledge distillation experiments indicate that the modified\ninhibitor transformer model can achieve competitive performance on standard NLP\nbenchmarks, including General Language Understanding Evaluation (GLUE) and\nsentiment analysis tasks.",
      "tldr_zh": "本研究提出InhibiDistilbert，通过将模型压缩技术与新型的inhibitor attention机制相结合来优化基于Transformer的语言模型。该机制采用曼哈顿距离和ReLU激活替代传统的点积注意力，在保持模型性能的同时提升计算效率。研究进一步改进了inhibitor机制的训练效率，并在DistilBERT架构上验证了其有效性。实验表明，改进后的模型在GLUE等标准NLP基准测试中取得了具有竞争力的性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "68T50 (Primary) 68T07, 68Q32 (Secondary)",
        "I.2.6; I.2.7; I.5.1"
      ],
      "primary_category": "cs.CL",
      "comment": "7 pages, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.15983v1",
      "published_date": "2025-03-20 09:30:35 UTC",
      "updated_date": "2025-03-20 09:30:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:26:43.039665"
    },
    {
      "arxiv_id": "2503.15969v1",
      "title": "Beyond the Visible: Multispectral Vision-Language Learning for Earth Observation",
      "title_zh": "超越可见光：面向地球观测的多光谱视觉-语言学习",
      "authors": [
        "Clive Tinashe Marimo",
        "Benedikt Blumenstiel",
        "Maximilian Nitsche",
        "Johannes Jakubik",
        "Thomas Brunschwiler"
      ],
      "abstract": "Vision-language models for Earth observation (EO) typically rely on the\nvisual spectrum of data as the only model input, thus failing to leverage the\nrich spectral information available in the multispectral channels recorded by\nsatellites. Therefore, in this paper, we introduce Llama3-MS-CLIP, the first\nvision-language model pre-trained with contrastive learning on a large-scale\nmultispectral dataset and report on the performance gains due to the extended\nspectral range. Furthermore, we present the largest-to-date image-caption\ndataset for multispectral data, consisting of one million Sentinel-2 samples\nand corresponding textual descriptions generated with Llama3-LLaVA-Next and\nOverture Maps data. We develop a scalable captioning pipeline, which is\nvalidated by domain experts. We evaluate Llama3-MS-CLIP on multispectral\nzero-shot image classification and retrieval using three datasets of varying\ncomplexity. Our results demonstrate that Llama3-MS-CLIP significantly\noutperforms other RGB-based approaches, improving classification accuracy by\n6.77% on average and retrieval performance by 4.63% mAP compared to the\nsecond-best model. Our results emphasize the relevance of multispectral\nvision-language learning. We release the image-caption dataset, code, and model\nweights under an open-source license.",
      "tldr_zh": "本文提出了Llama3-MS-CLIP，这是首个基于对比学习在大规模多光谱数据集上预训练的视觉语言模型，显著提升了地球观测任务中的性能。研究还构建了迄今为止最大的多光谱图像-文本数据集，包含100万张Sentinel-2卫星图像及其对应的文本描述，并通过领域专家验证了其可扩展的标注流程。实验表明，Llama3-MS-CLIP在多光谱零样本图像分类和检索任务中显著优于基于RGB的模型，分类准确率平均提升6.77%，检索性能提升4.63% mAP，突显了多光谱视觉语言学习的重要性。相关数据集、代码和模型权重已开源发布。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15969v1",
      "published_date": "2025-03-20 09:13:31 UTC",
      "updated_date": "2025-03-20 09:13:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:27:14.721594"
    },
    {
      "arxiv_id": "2503.16572v1",
      "title": "Efficient ANN-Guided Distillation: Aligning Rate-based Features of Spiking Neural Networks through Hybrid Block-wise Replacement",
      "title_zh": "高效ANN引导蒸馏：通过混合模块替换对齐脉冲神经网络基于速率的特征",
      "authors": [
        "Shu Yang",
        "Chengting Yu",
        "Lei Liu",
        "Hanzhi Ma",
        "Aili Wang",
        "Erping Li"
      ],
      "abstract": "Spiking Neural Networks (SNNs) have garnered considerable attention as a\npotential alternative to Artificial Neural Networks (ANNs). Recent studies have\nhighlighted SNNs' potential on large-scale datasets. For SNN training, two main\napproaches exist: direct training and ANN-to-SNN (ANN2SNN) conversion. To fully\nleverage existing ANN models in guiding SNN learning, either direct ANN-to-SNN\nconversion or ANN-SNN distillation training can be employed. In this paper, we\npropose an ANN-SNN distillation framework from the ANN-to-SNN perspective,\ndesigned with a block-wise replacement strategy for ANN-guided learning. By\ngenerating intermediate hybrid models that progressively align SNN feature\nspaces to those of ANN through rate-based features, our framework naturally\nincorporates rate-based backpropagation as a training method. Our approach\nachieves results comparable to or better than state-of-the-art SNN distillation\nmethods, showing both training and learning efficiency.",
      "tldr_zh": "本研究提出了一种高效的ANN-SNN蒸馏框架，通过混合块替换策略实现基于速率特征的SNN与ANN特征空间对齐。该方法生成中间混合模型，逐步将SNN的特征空间与ANN对齐，并自然结合基于速率的反向传播作为训练方法。实验表明，该框架在训练和学习效率上均优于现有的SNN蒸馏方法，达到了与最先进方法相当或更好的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16572v1",
      "published_date": "2025-03-20 09:04:38 UTC",
      "updated_date": "2025-03-20 09:04:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:26:56.429621"
    },
    {
      "arxiv_id": "2503.15953v1",
      "title": "GAN-enhanced Simulation-driven DNN Testing in Absence of Ground Truth",
      "title_zh": "GAN增强的无真实值驱动的仿真深度神经网络测试",
      "authors": [
        "Mohammed Attaoui",
        "Fabrizio Pastore"
      ],
      "abstract": "The generation of synthetic inputs via simulators driven by search algorithms\nis essential for cost-effective testing of Deep Neural Network (DNN) components\nfor safety-critical systems. However, in many applications, simulators are\nunable to produce the ground-truth data needed for automated test oracles and\nto guide the search process.\n  To tackle this issue, we propose an approach for the generation of inputs for\ncomputer vision DNNs that integrates a generative network to ensure simulator\nfidelity and employs heuristic-based search fitnesses that leverage\ntransformation consistency, noise resistance, surprise adequacy, and\nuncertainty estimation. We compare the performance of our fitnesses with that\nof a traditional fitness function leveraging ground truth; further, we assess\nhow the integration of a GAN not leveraging the ground truth impacts on test\nand retraining effectiveness.\n  Our results suggest that leveraging transformation consistency is the best\noption to generate inputs for both DNN testing and retraining; it maximizes\ninput diversity, spots the inputs leading to worse DNN performance, and leads\nto best DNN performance after retraining. Besides enabling simulator-based\ntesting in the absence of ground truth, our findings pave the way for testing\nsolutions that replace costly simulators with diffusion and large language\nmodels, which might be more affordable than simulators, but cannot generate\nground-truth data.",
      "tldr_zh": "该研究提出了一种在缺乏真实数据（ground truth）情况下，通过GAN增强仿真驱动的方法来测试深度神经网络（DNN）。该方法结合生成对抗网络（GAN）提升仿真器的保真度，并利用基于启发式的搜索适应度函数（如变换一致性、噪声抵抗性、意外充分性和不确定性估计）生成测试输入。实验表明，变换一致性是生成多样化输入并提升DNN性能的最佳选择，同时避免了传统仿真器的高成本。这一方法为使用扩散模型和大型语言模型替代仿真器提供了可能性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "15 pages, 8 figures, 13 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.15953v1",
      "published_date": "2025-03-20 08:49:10 UTC",
      "updated_date": "2025-03-20 08:49:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:27:16.258584"
    },
    {
      "arxiv_id": "2503.15948v1",
      "title": "Don't Fight Hallucinations, Use Them: Estimating Image Realism using NLI over Atomic Facts",
      "title_zh": "勿抗幻觉，善用之：基于原子事实的自然语言推理估计图像真实性",
      "authors": [
        "Elisei Rykov",
        "Kseniia Petrushina",
        "Kseniia Titova",
        "Alexander Panchenko",
        "Vasily Konovalov"
      ],
      "abstract": "Quantifying the realism of images remains a challenging problem in the field\nof artificial intelligence. For example, an image of Albert Einstein holding a\nsmartphone violates common-sense because modern smartphone were invented after\nEinstein's death. We introduce a novel method for assessing image realism using\nLarge Vision-Language Models (LVLMs) and Natural Language Inference (NLI). Our\napproach is based on the premise that LVLMs may generate hallucinations when\nconfronted with images that defy common sense. Using LVLM to extract atomic\nfacts from these images, we obtain a mix of accurate facts and erroneous\nhallucinations. We proceed by calculating pairwise entailment scores among\nthese facts, subsequently aggregating these values to yield a singular reality\nscore. This process serves to identify contradictions between genuine facts and\nhallucinatory elements, signaling the presence of images that violate common\nsense. Our approach has achieved a new state-of-the-art performance in\nzero-shot mode on the WHOOPS! dataset.",
      "tldr_zh": "该研究提出了一种利用大视觉语言模型(LVLMs)和自然语言推理(NLI)评估图像真实性的新方法。通过提取图像中的原子事实并计算它们之间的蕴含关系，该方法能够识别真实事实与幻觉之间的矛盾，从而量化图像违反常识的程度。在WHOOPS!数据集上的零样本测试中，该方法达到了最新的最先进性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Proceedings of De-Factify 4: 4nd Workshop on Multimodal Fact Checking\n  and Hate Speech Detection, co-located with AAAI-2025",
      "pdf_url": "http://arxiv.org/pdf/2503.15948v1",
      "published_date": "2025-03-20 08:44:10 UTC",
      "updated_date": "2025-03-20 08:44:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:27:29.750946"
    },
    {
      "arxiv_id": "2503.15947v1",
      "title": "Unreal-MAP: Unreal-Engine-Based General Platform for Multi-Agent Reinforcement Learning",
      "title_zh": "Unreal-MAP：基于虚幻引擎的多智能体强化学习通用平台",
      "authors": [
        "Tianyi Hu",
        "Qingxu Fu",
        "Zhiqiang Pu",
        "Yuan Wang",
        "Tenghai Qiu"
      ],
      "abstract": "In this paper, we propose Unreal Multi-Agent Playground (Unreal-MAP), an MARL\ngeneral platform based on the Unreal-Engine (UE). Unreal-MAP allows users to\nfreely create multi-agent tasks using the vast visual and physical resources\navailable in the UE community, and deploy state-of-the-art (SOTA) MARL\nalgorithms within them. Unreal-MAP is user-friendly in terms of deployment,\nmodification, and visualization, and all its components are open-source. We\nalso develop an experimental framework compatible with algorithms ranging from\nrule-based to learning-based provided by third-party frameworks. Lastly, we\ndeploy several SOTA algorithms in example tasks developed via Unreal-MAP, and\nconduct corresponding experimental analyses. We believe Unreal-MAP can play an\nimportant role in the MARL field by closely integrating existing algorithms\nwith user-customized tasks, thus advancing the field of MARL.",
      "tldr_zh": "本文提出了Unreal-MAP，一个基于Unreal Engine（UE）的多智能体强化学习（MARL）通用平台。该平台允许用户利用UE社区的丰富视觉和物理资源自由创建多智能体任务，并部署最先进的MARL算法。Unreal-MAP在部署、修改和可视化方面具有用户友好性，所有组件均为开源。此外，该平台还开发了一个兼容从基于规则到基于学习的第三方框架算法的实验框架，并通过在Unreal-MAP开发的任务中部署多个SOTA算法进行了实验分析。Unreal-MAP通过紧密集成现有算法与用户定制任务，有望在MARL领域发挥重要作用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15947v1",
      "published_date": "2025-03-20 08:40:41 UTC",
      "updated_date": "2025-03-20 08:40:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:28:02.131504"
    },
    {
      "arxiv_id": "2503.15937v2",
      "title": "Advancing Mobile GUI Agents: A Verifier-Driven Approach to Practical Deployment",
      "title_zh": "推进移动 GUI 智能体：一种面向实际部署的验证驱动方法",
      "authors": [
        "Gaole Dai",
        "Shiqi Jiang",
        "Ting Cao",
        "Yuanchun Li",
        "Yuqing Yang",
        "Rui Tan",
        "Mo Li",
        "Lili Qiu"
      ],
      "abstract": "We propose V-Droid, a mobile GUI task automation agent. Unlike previous\nmobile agents that utilize Large Language Models (LLMs) as generators to\ndirectly generate actions at each step, V-Droid employs LLMs as verifiers to\nevaluate candidate actions before making final decisions. To realize this novel\nparadigm, we introduce a comprehensive framework for constructing\nverifier-driven mobile agents: the discretized action space construction\ncoupled with the prefilling-only workflow to accelerate the verification\nprocess, the pair-wise progress preference training to significantly enhance\nthe verifier's decision-making capabilities, and the scalable human-agent joint\nannotation scheme to efficiently collect the necessary data at scale. V-Droid\nsets a new state-of-the-art task success rate across several public mobile task\nautomation benchmarks: 59.5% on AndroidWorld, 38.3% on AndroidLab, and 49% on\nMobileAgentBench, surpassing existing agents by 9.5%, 2.1%, and 9%,\nrespectively. Furthermore, V-Droid achieves an impressively low latency of 0.7\nseconds per step, making it the first mobile agent capable of delivering\nnear-real-time, effective decision-making capabilities.",
      "tldr_zh": "本研究提出了V-Droid，一种基于验证器驱动范式的移动GUI任务自动化智能体。与以往直接生成动作的移动智能体不同，V-Droid利用大语言模型(LLMs)作为验证器，在决策前评估候选动作，从而提升准确性。该框架通过离散化动作空间、配对进度偏好训练和可扩展的人机联合标注方案，显著提高了验证器的决策能力和效率。实验结果表明，V-Droid在多个公开移动任务自动化基准测试中取得了最先进的任务成功率（AndroidWorld 59.5%，AndroidLab 38.3%，MobileAgentBench 49%），并实现了每步0.7秒的低延迟，首次提供了接近实时的有效决策能力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 4 iterations, refine figs",
      "pdf_url": "http://arxiv.org/pdf/2503.15937v2",
      "published_date": "2025-03-20 08:25:00 UTC",
      "updated_date": "2025-03-21 03:19:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:27:58.711810"
    },
    {
      "arxiv_id": "2503.15924v1",
      "title": "Towards Automatic Continual Learning: A Self-Adaptive Framework for Continual Instruction Tuning",
      "title_zh": "迈向自动持续学习：一种自适应的持续指令调优框架",
      "authors": [
        "Peiyi Lin",
        "Fukai Zhang",
        "Kai Niu",
        "Hao Fu"
      ],
      "abstract": "Continual instruction tuning enables large language models (LLMs) to learn\nincrementally while retaining past knowledge, whereas existing methods\nprimarily focus on how to retain old knowledge rather than on selecting which\nnew knowledge to learn. In domain-specific contexts, maintaining data quality\nand managing system constraints remain key challenges. To address these issues,\nwe propose an automated continual instruction tuning framework that dynamically\nfilters incoming data, which identify and reduce redundant data across\nsuccessive updates. Our approach utilizes a small proxy model for efficient\nperplexity-based filtering, and updates the proxy to ensure that the filtering\ncriteria remain aligned with the evolving state of the deployed model. Compared\nto existing static data selection methods, our framework can effectively handle\nincrementally acquired data and shifting distributions. Additionally, it\naddresses practical deployment challenges by enabling seamless model updates,\nsupporting version rollback and incorporating automatic checkpoint evaluation.\nWe evaluated the system in real-world medical scenarios. It reduced\ncomputational costs by 66.7% and improved model performance, and achieved\nautonomous updates, thus demonstrating its effectiveness for automatic\ncontinual instruction tuning.",
      "tldr_zh": "该研究提出了一种自适应的持续指令调优框架，旨在解决大语言模型(LLMs)在领域特定场景下持续学习时面临的数据质量和系统约束问题。该框架通过动态过滤冗余数据，利用小型代理模型进行基于困惑度的高效筛选，并随着模型状态更新过滤标准，从而有效处理增量数据和分布变化。实验表明，该框架在真实医疗场景中减少了66.7%的计算成本，提升了模型性能，并实现了自主更新，为自动持续指令调优提供了有效解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15924v1",
      "published_date": "2025-03-20 08:00:41 UTC",
      "updated_date": "2025-03-20 08:00:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:27:54.031772"
    },
    {
      "arxiv_id": "2503.15918v1",
      "title": "Denoising-based Contractive Imitation Learning",
      "title_zh": "去噪式收缩模仿学习",
      "authors": [
        "Macheng Shen",
        "Jishen Peng",
        "Zefang Huang"
      ],
      "abstract": "A fundamental challenge in imitation learning is the \\emph{covariate shift}\nproblem. Existing methods to mitigate covariate shift often require additional\nexpert interactions, access to environment dynamics, or complex adversarial\ntraining, which may not be practical in real-world applications. In this paper,\nwe propose a simple yet effective method (DeCIL) to mitigate covariate shift by\nincorporating a denoising mechanism that enhances the contraction properties of\nthe state transition mapping. Our approach involves training two neural\nnetworks: a dynamics model ( f ) that predicts the next state from the current\nstate, and a joint state-action denoising policy network ( d ) that refines\nthis state prediction via denoising and outputs the corresponding action. We\nprovide theoretical analysis showing that the denoising network acts as a local\ncontraction mapping, reducing the error propagation of the state transition and\nimproving stability. Our method is straightforward to implement and can be\neasily integrated with existing imitation learning frameworks without requiring\nadditional expert data or complex modifications to the training procedure.\nEmpirical results demonstrate that our approach effectively improves success\nrate of various imitation learning tasks under noise perturbation.",
      "tldr_zh": "本文提出了一种基于去噪的收缩模仿学习方法（DeCIL），用于解决模仿学习中的协变量偏移问题。该方法通过引入去噪机制，增强了状态转移映射的收缩特性，从而减少了误差传播并提高了稳定性。具体实现包括训练一个动态模型（f）用于预测下一状态，以及一个联合状态-动作去噪策略网络（d）用于通过去噪优化状态预测并输出相应动作。实验表明，该方法在噪声干扰下显著提高了多种模仿学习任务的成功率，且无需额外专家数据或复杂的训练过程修改。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15918v1",
      "published_date": "2025-03-20 07:52:19 UTC",
      "updated_date": "2025-03-20 07:52:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:28:09.857592"
    },
    {
      "arxiv_id": "2503.15910v2",
      "title": "No Thing, Nothing: Highlighting Safety-Critical Classes for Robust LiDAR Semantic Segmentation in Adverse Weather",
      "title_zh": "无物即空：在恶劣天气下为鲁棒的 LiDAR 语义分割突出安全关键类别",
      "authors": [
        "Junsung Park",
        "Hwijeong Lee",
        "Inha Kang",
        "Hyunjung Shim"
      ],
      "abstract": "Existing domain generalization methods for LiDAR semantic segmentation under\nadverse weather struggle to accurately predict \"things\" categories compared to\n\"stuff\" categories. In typical driving scenes, \"things\" categories can be\ndynamic and associated with higher collision risks, making them crucial for\nsafe navigation and planning. Recognizing the importance of \"things\"\ncategories, we identify their performance drop as a serious bottleneck in\nexisting approaches. We observed that adverse weather induces degradation of\nsemantic-level features and both corruption of local features, leading to a\nmisprediction of \"things\" as \"stuff\". To mitigate these corruptions, we suggest\nour method, NTN - segmeNt Things for No-accident. To address semantic-level\nfeature corruption, we bind each point feature to its superclass, preventing\nthe misprediction of things classes into visually dissimilar categories.\nAdditionally, to enhance robustness against local corruption caused by adverse\nweather, we define each LiDAR beam as a local region and propose a\nregularization term that aligns the clean data with its corrupted counterpart\nin feature space. NTN achieves state-of-the-art performance with a +2.6 mIoU\ngain on the SemanticKITTI-to-SemanticSTF benchmark and +7.9 mIoU on the\nSemanticPOSS-to-SemanticSTF benchmark. Notably, NTN achieves a +4.8 and +7.9\nmIoU improvement on \"things\" classes, respectively, highlighting its\neffectiveness.",
      "tldr_zh": "该研究针对恶劣天气下LiDAR语义分割中“things”类别（如车辆、行人等动态物体）性能下降的问题，提出了一种新方法NTN（segmeNt Things for No-accident）。通过将点特征绑定到其超类，防止“things”类别被误分类为视觉上不相似的类别，同时定义LiDAR光束为局部区域并引入正则化项，增强对局部特征损坏的鲁棒性。实验表明，NTN在SemanticKITTI-to-SemanticSTF和SemanticPOSS-to-SemanticSTF基准测试中分别实现了+2.6和+7.9 mIoU的提升，尤其在“things”类别上表现显著，为安全导航提供了更可靠的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages, accepted in CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.15910v2",
      "published_date": "2025-03-20 07:40:24 UTC",
      "updated_date": "2025-03-24 12:16:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:28:21.573656"
    },
    {
      "arxiv_id": "2503.15908v1",
      "title": "Enhancing Close-up Novel View Synthesis via Pseudo-labeling",
      "title_zh": "通过伪标签增强近景新视角合成",
      "authors": [
        "Jiatong Xia",
        "Libo Sun",
        "Lingqiao Liu"
      ],
      "abstract": "Recent methods, such as Neural Radiance Fields (NeRF) and 3D Gaussian\nSplatting (3DGS), have demonstrated remarkable capabilities in novel view\nsynthesis. However, despite their success in producing high-quality images for\nviewpoints similar to those seen during training, they struggle when generating\ndetailed images from viewpoints that significantly deviate from the training\nset, particularly in close-up views. The primary challenge stems from the lack\nof specific training data for close-up views, leading to the inability of\ncurrent methods to render these views accurately. To address this issue, we\nintroduce a novel pseudo-label-based learning strategy. This approach leverages\npseudo-labels derived from existing training data to provide targeted\nsupervision across a wide range of close-up viewpoints. Recognizing the absence\nof benchmarks for this specific challenge, we also present a new dataset\ndesigned to assess the effectiveness of both current and future methods in this\narea. Our extensive experiments demonstrate the efficacy of our approach.",
      "tldr_zh": "该研究提出了一种基于伪标签(pseudo-labeling)的学习策略，用于提升近距离新视角合成(close-up novel view synthesis)的质量。针对NeRF和3D Gaussian Splatting等方法在生成与训练视角显著偏离的近距离视图时表现不佳的问题，该方法利用现有训练数据生成伪标签，为广泛范围的近距离视角提供针对性监督。研究还引入了一个新的数据集，用于评估当前和未来方法在该任务上的性能。实验结果表明，所提出的方法在提升近距离视图合成质量方面具有显著效果。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.15908v1",
      "published_date": "2025-03-20 07:27:46 UTC",
      "updated_date": "2025-03-20 07:27:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:28:22.228834"
    },
    {
      "arxiv_id": "2503.15905v1",
      "title": "Jasmine: Harnessing Diffusion Prior for Self-supervised Depth Estimation",
      "title_zh": "Jasmine：利用扩散先验实现自监督深度估计",
      "authors": [
        "Jiyuan Wang",
        "Chunyu Lin",
        "Cheng Guan",
        "Lang Nie",
        "Jing He",
        "Haodong Li",
        "Kang Liao",
        "Yao Zhao"
      ],
      "abstract": "In this paper, we propose Jasmine, the first Stable Diffusion (SD)-based\nself-supervised framework for monocular depth estimation, which effectively\nharnesses SD's visual priors to enhance the sharpness and generalization of\nunsupervised prediction. Previous SD-based methods are all supervised since\nadapting diffusion models for dense prediction requires high-precision\nsupervision. In contrast, self-supervised reprojection suffers from inherent\nchallenges (e.g., occlusions, texture-less regions, illumination variance), and\nthe predictions exhibit blurs and artifacts that severely compromise SD's\nlatent priors. To resolve this, we construct a novel surrogate task of hybrid\nimage reconstruction. Without any additional supervision, it preserves the\ndetail priors of SD models by reconstructing the images themselves while\npreventing depth estimation from degradation. Furthermore, to address the\ninherent misalignment between SD's scale and shift invariant estimation and\nself-supervised scale-invariant depth estimation, we build the Scale-Shift GRU.\nIt not only bridges this distribution gap but also isolates the fine-grained\ntexture of SD output against the interference of reprojection loss. Extensive\nexperiments demonstrate that Jasmine achieves SoTA performance on the KITTI\nbenchmark and exhibits superior zero-shot generalization across multiple\ndatasets.",
      "tldr_zh": "本文提出了Jasmine，首个基于Stable Diffusion (SD)的自监督单目深度估计框架，通过有效利用SD的视觉先验来增强无监督预测的清晰度和泛化能力。为了解决自监督重投影中的固有挑战（如遮挡、无纹理区域和光照变化），作者构建了一种新颖的混合图像重建替代任务，无需额外监督即可保留SD模型的细节先验。此外，通过引入Scale-Shift GRU模块，解决了SD的尺度与平移不变性与自监督尺度不变深度估计之间的固有不对齐问题。实验表明，Jasmine在KITTI基准测试中达到了最先进的性能，并在多个数据集上表现出卓越的零样本泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15905v1",
      "published_date": "2025-03-20 07:15:49 UTC",
      "updated_date": "2025-03-20 07:15:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:28:36.013833"
    },
    {
      "arxiv_id": "2503.15904v1",
      "title": "From Structured Prompts to Open Narratives: Measuring Gender Bias in LLMs Through Open-Ended Storytelling",
      "title_zh": "从结构化提示到开放式叙事：通过开放式故事讲述衡量大语言模型中的性别偏见",
      "authors": [
        "Evan Chen",
        "Run-Jun Zhan",
        "Yan-Bai Lin",
        "Hung-Hsuan Chen"
      ],
      "abstract": "Large Language Models (LLMs) have revolutionized natural language processing,\nyet concerns persist regarding their tendency to reflect or amplify social\nbiases present in their training data. This study introduces a novel evaluation\nframework to uncover gender biases in LLMs, focusing on their occupational\nnarratives. Unlike previous methods relying on structured scenarios or\ncarefully crafted prompts, our approach leverages free-form storytelling to\nreveal biases embedded in the models. Systematic analyses show an\noverrepresentation of female characters across occupations in six widely used\nLLMs. Additionally, our findings reveal that LLM-generated occupational gender\nrankings align more closely with human stereotypes than actual labor\nstatistics. These insights underscore the need for balanced mitigation\nstrategies to ensure fairness while avoiding the reinforcement of new\nstereotypes.",
      "tldr_zh": "该研究提出了一种新颖的评估框架，通过开放式叙事揭示大型语言模型（LLMs）中的性别偏见。与依赖结构化场景的传统方法不同，该研究利用自由形式的讲故事来暴露模型中的偏见。系统分析显示，六个广泛使用的LLMs在职业叙事中过度代表女性角色，且生成的职业性别排名更接近人类刻板印象而非实际劳动统计数据。这些发现强调了在确保公平的同时避免强化新刻板印象的平衡缓解策略的必要性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15904v1",
      "published_date": "2025-03-20 07:15:45 UTC",
      "updated_date": "2025-03-20 07:15:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:29:01.524709"
    },
    {
      "arxiv_id": "2503.16565v1",
      "title": "Gene42: Long-Range Genomic Foundation Model With Dense Attention",
      "title_zh": "Gene42：基于密集注意力机制的长程基因组基础模型",
      "authors": [
        "Kirill Vishniakov",
        "Boulbaba Ben Amor",
        "Engin Tekin",
        "Nancy A. ElNaker",
        "Karthik Viswanathan",
        "Aleksandr Medvedev",
        "Aahan Singh",
        "Maryam Nadeem",
        "Mohammad Amaan Sayeed",
        "Praveenkumar Kanithi",
        "Tiago Magalhaes",
        "Natalia Vassilieva",
        "Dwarikanath Mahapatra",
        "Marco Pimentel",
        "and Shadab Khan"
      ],
      "abstract": "We introduce Gene42, a novel family of Genomic Foundation Models (GFMs)\ndesigned to manage context lengths of up to 192,000 base pairs (bp) at a\nsingle-nucleotide resolution. Gene42 models utilize a decoder-only\n(LLaMA-style) architecture with a dense self-attention mechanism. Initially\ntrained on fixed-length sequences of 4,096 bp, our models underwent continuous\npretraining to extend the context length to 192,000 bp. This iterative\nextension allowed for the comprehensive processing of large-scale genomic data\nand the capture of intricate patterns and dependencies within the human genome.\nGene42 is the first dense attention model capable of handling such extensive\nlong context lengths in genomics, challenging state-space models that often\nrely on convolutional operators among other mechanisms. Our pretrained models\nexhibit notably low perplexity values and high reconstruction accuracy,\nhighlighting their strong ability to model genomic data. Extensive experiments\non various genomic benchmarks have demonstrated state-of-the-art performance\nacross multiple tasks, including biotype classification, regulatory region\nidentification, chromatin profiling prediction, variant pathogenicity\nprediction, and species classification. The models are publicly available at\nhuggingface.co/inceptionai.",
      "tldr_zh": "该研究提出了Gene42，一种新型基因组基础模型(GFMs)，采用密集自注意力机制(dense self-attention)处理高达192,000个碱基对(bp)的长范围基因组数据。通过从4,096 bp逐步扩展到192,000 bp的连续预训练，Gene42能够捕捉人类基因组中的复杂模式和依赖关系。实验表明，该模型在多种基因组任务（如生物类型分类、调控区域识别等）上均取得了最先进的性能，为长范围基因组建模提供了新的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "q-bio.GN"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16565v1",
      "published_date": "2025-03-20 07:10:04 UTC",
      "updated_date": "2025-03-20 07:10:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:28:47.391552"
    },
    {
      "arxiv_id": "2503.16563v1",
      "title": "Chem42: a Family of chemical Language Models for Target-aware Ligand Generation",
      "title_zh": "Chem42：面向靶标感知配体生成的化学语言模型家族",
      "authors": [
        "Aahan Singh",
        "Engin Tekin",
        "Maryam Nadeem",
        "Nancy A. ElNaker",
        "Mohammad Amaan Sayeed",
        "Natalia Vassilieva",
        "Boulbaba Ben Amor"
      ],
      "abstract": "Revolutionizing drug discovery demands more than just understanding molecular\ninteractions - it requires generative models that can design novel ligands\ntailored to specific biological targets. While chemical Language Models (cLMs)\nhave made strides in learning molecular properties, most fail to incorporate\ntarget-specific insights, restricting their ability to drive de-novo ligand\ngeneration. Chem42, a cutting-edge family of generative chemical Language\nModels, is designed to bridge this gap. By integrating atomic-level\ninteractions with multimodal inputs from Prot42, a complementary protein\nLanguage Model, Chem42 achieves a sophisticated cross-modal representation of\nmolecular structures, interactions, and binding patterns. This innovative\nframework enables the creation of structurally valid, synthetically accessible\nligands with enhanced target specificity. Evaluations across diverse protein\ntargets confirm that Chem42 surpasses existing approaches in chemical validity,\ntarget-aware design, and predicted binding affinity. By reducing the search\nspace of viable drug candidates, Chem42 could accelerate the drug discovery\npipeline, offering a powerful generative AI tool for precision medicine. Our\nChem42 models set a new benchmark in molecule property prediction, conditional\nmolecule generation, and target-aware ligand design. The models are publicly\navailable at huggingface.co/inceptionai.",
      "tldr_zh": "Chem42是一系列先进的化学语言模型(cLMs)，专为目标导向的配体生成设计。该模型通过整合原子级相互作用和Prot42蛋白质语言模型的多模态输入，实现了分子结构、相互作用和结合模式的跨模态表示，从而生成结构有效且合成可行的配体。实验表明，Chem42在化学有效性、目标导向设计和预测结合亲和力方面均优于现有方法，为加速药物发现提供了强大的生成式AI工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "q-bio.BM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16563v1",
      "published_date": "2025-03-20 07:07:30 UTC",
      "updated_date": "2025-03-20 07:07:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:29:33.018514"
    },
    {
      "arxiv_id": "2503.15901v1",
      "title": "A multi-model approach using XAI and anomaly detection to predict asteroid hazards",
      "title_zh": "采用可解释人工智能与异常检测的多模型方法预测小行星危害",
      "authors": [
        "Amit Kumar Mondal",
        "Nafisha Aslam",
        "Prasenjit Maji",
        "Hemanta Kumar Mondal"
      ],
      "abstract": "The potential for catastrophic collision makes near-Earth asteroids (NEAs) a\nserious concern. Planetary defense depends on accurately classifying\npotentially hazardous asteroids (PHAs), however the complexity of the data\nhampers conventional techniques. This work offers a sophisticated method for\naccurately predicting hazards by combining machine learning, deep learning,\nexplainable AI (XAI), and anomaly detection. Our approach extracts essential\nparameters like size, velocity, and trajectory from historical and real-time\nasteroid data. A hybrid algorithm improves prediction accuracy by combining\nseveral cutting-edge models. A forecasting module predicts future asteroid\nbehavior, and Monte Carlo simulations evaluate the likelihood of collisions.\nTimely mitigation is made possible by a real-time alarm system that notifies\nworldwide monitoring stations. This technique enhances planetary defense\nefforts by combining real-time alarms with sophisticated predictive modeling.",
      "tldr_zh": "该研究提出了一种结合可解释人工智能(XAI)和异常检测的多模型方法，用于预测近地小行星(NEAs)的危害。通过整合机器学习、深度学习、XAI和异常检测技术，从历史和实时小行星数据中提取关键参数如大小、速度和轨迹，提高了预测准确性。研究还开发了实时警报系统，能够及时通知全球监测站，并通过蒙特卡洛模拟评估碰撞概率，从而增强了行星防御能力。",
      "categories": [
        "astro-ph.EP",
        "astro-ph.IM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "astro-ph.EP",
      "comment": "17 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.15901v1",
      "published_date": "2025-03-20 07:00:01 UTC",
      "updated_date": "2025-03-20 07:00:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:29:29.437899"
    },
    {
      "arxiv_id": "2503.15890v1",
      "title": "Time After Time: Deep-Q Effect Estimation for Interventions on When and What to do",
      "title_zh": "时间之后的时间：基于深度Q效应估计的干预时机与行动选择",
      "authors": [
        "Yoav Wald",
        "Mark Goldstein",
        "Yonathan Efroni",
        "Wouter A. C. van Amsterdam",
        "Rajesh Ranganath"
      ],
      "abstract": "Problems in fields such as healthcare, robotics, and finance requires\nreasoning about the value both of what decision or action to take and when to\ntake it. The prevailing hope is that artificial intelligence will support such\ndecisions by estimating the causal effect of policies such as how to treat\npatients or how to allocate resources over time. However, existing methods for\nestimating the effect of a policy struggle with \\emph{irregular time}. They\neither discretize time, or disregard the effect of timing policies. We present\na new deep-Q algorithm that estimates the effect of both when and what to do\ncalled Earliest Disagreement Q-Evaluation (EDQ). EDQ makes use of recursion for\nthe Q-function that is compatible with flexible sequence models, such as\ntransformers. EDQ provides accurate estimates under standard assumptions. We\nvalidate the approach through experiments on survival time and tumor growth\ntasks.",
      "tldr_zh": "本研究提出了一种名为最早分歧Q评估(EDQ)的深度Q算法，用于估计在何时采取何种干预措施的因果效应。该方法通过递归Q函数与灵活的序列模型(如transformer)兼容，解决了现有方法在处理不规则时间序列数据时的局限性。实验验证了EDQ在生存时间和肿瘤生长等任务中的准确性，为医疗保健、机器人和金融等领域的时间敏感决策提供了新的支持工具。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15890v1",
      "published_date": "2025-03-20 06:27:35 UTC",
      "updated_date": "2025-03-20 06:27:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:29:44.107412"
    },
    {
      "arxiv_id": "2503.15889v1",
      "title": "LeanTTA: A Backpropagation-Free and Stateless Approach to Quantized Test-Time Adaptation on Edge Devices",
      "title_zh": "LeanTTA：一种面向边缘设备量化测试时适应的无反向传播与无状态方法",
      "authors": [
        "Cynthia Dong",
        "Hong Jia",
        "Young D. Kwon",
        "Georgios Rizos",
        "Cecilia Mascolo"
      ],
      "abstract": "While there are many advantages to deploying machine learning models on edge\ndevices, the resource constraints of mobile platforms, the dynamic nature of\nthe environment, and differences between the distribution of training versus\nin-the-wild data make such deployments challenging. Current test-time\nadaptation methods are often memory-intensive and not designed to be\nquantization-compatible or deployed on low-resource devices. To address these\nchallenges, we present LeanTTA, a novel backpropagation-free and stateless\nframework for quantized test-time adaptation tailored to edge devices. Our\napproach minimizes computational costs by dynamically updating normalization\nstatistics without backpropagation, which frees LeanTTA from the common pitfall\nof relying on large batches and historical data, making our method robust to\nrealistic deployment scenarios. Our approach is the first to enable further\ncomputational gains by combining partial adaptation with quantized module\nfusion. We validate our framework across sensor modalities, demonstrating\nsignificant improvements over state-of-the-art TTA methods, including a 15.7%\nerror reduction, peak memory usage of only 11.2MB for ResNet18, and fast\nadaptation within an order-of-magnitude of normal inference speeds on-device.\nLeanTTA provides a robust solution for achieving the right trade offs between\naccuracy and system efficiency in edge deployments, addressing the unique\nchallenges posed by limited data and varied operational conditions.",
      "tldr_zh": "该研究提出了LeanTTA，一种专为边缘设备设计的无反向传播和无状态的量化测试时适应框架。该方法通过动态更新归一化统计量来最小化计算成本，无需依赖大批量数据或历史信息，从而在资源受限的设备上实现高效适应。LeanTTA首次结合部分适应与量化模块融合，进一步提升了计算效率。实验表明，该方法在多种传感器模态上显著优于现有技术，错误率降低15.7%，峰值内存使用仅11.2MB，且适应速度接近正常推理速度，为边缘部署提供了高效且鲁棒的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.15889v1",
      "published_date": "2025-03-20 06:27:09 UTC",
      "updated_date": "2025-03-20 06:27:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:29:40.926158"
    },
    {
      "arxiv_id": "2503.15888v1",
      "title": "Parameters vs. Context: Fine-Grained Control of Knowledge Reliance in Language Models",
      "title_zh": "参数 vs. 上下文：语言模型知识依赖的细粒度控制",
      "authors": [
        "Baolong Bi",
        "Shenghua Liu",
        "Yiwei Wang",
        "Yilong Xu",
        "Junfeng Fang",
        "Lingrui Mei",
        "Xueqi Cheng"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) mitigates hallucinations in Large\nLanguage Models (LLMs) by integrating external knowledge. However, conflicts\nbetween parametric knowledge and retrieved context pose challenges,\nparticularly when retrieved information is unreliable or the model's internal\nknowledge is outdated. In such cases, LLMs struggle to determine whether to\nrely more on their own parameters or the conflicted context. To address this,\nwe propose **CK-PLUG**, a plug-and-play method for controlling LLMs' reliance\non parametric and contextual knowledge. We introduce a novel knowledge\nconsistency metric, Confidence Gain, which detects knowledge conflicts by\nmeasuring entropy shifts in token probability distributions after context\ninsertion. CK-PLUG then enables fine-grained control over knowledge preference\nby adjusting the probability distribution of tokens with negative confidence\ngain through a single tuning parameter. Experiments demonstrate CK-PLUG's\nability to significantly regulate knowledge reliance in counterfactual RAG\nscenarios while maintaining generation fluency and knowledge accuracy. For\ninstance, on Llama3-8B, memory recall (MR) of RAG response can be adjusted\nwithin a broad range (9.9%-71.9%), compared to the baseline of 42.1%. Moreover,\nCK-PLUG supports adaptive control based on the model's confidence in both\ninternal and external knowledge, achieving consistent performance improvements\nacross various general RAG tasks. Our code is available at:\n$\\href{https://github.com/byronBBL/CK-PLUG}{\\text{this https URL}}$.",
      "tldr_zh": "本研究提出了一种名为CK-PLUG的即插即用方法，用于精细控制大语言模型(LLMs)对参数知识和检索上下文知识的依赖。该方法通过引入一种新的知识一致性度量标准——Confidence Gain，检测知识冲突，并通过调整具有负置信增益的标记的概率分布，实现对知识偏好的细粒度控制。实验表明，CK-PLUG能够在反事实检索增强生成(RAG)场景中显著调节知识依赖，同时保持生成流畅性和知识准确性，并在各种通用RAG任务中实现一致的性能提升。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15888v1",
      "published_date": "2025-03-20 06:26:28 UTC",
      "updated_date": "2025-03-20 06:26:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:29:51.727053"
    },
    {
      "arxiv_id": "2503.15876v1",
      "title": "DeepPsy-Agent: A Stage-Aware and Deep-Thinking Emotional Support Agent System",
      "title_zh": "DeepPsy-Agent：一个阶段感知与深度思考的情感支持智能体系统",
      "authors": [
        "Kai Chen",
        "Zebing Sun"
      ],
      "abstract": "This paper introduces DeepPsy-Agent, an innovative psychological support\nsystem that combines the three-stage helping theory in psychology with deep\nlearning techniques. The system consists of two core components: (1) a\nmulti-stage response-capable dialogue model (\\textit{deeppsy-chat}), which\nenhances reasoning capabilities through stage-awareness and deep-thinking\nanalysis to generate high-quality responses; and (2) a real-time stage\ntransition detection model that identifies contextual shifts to guide the\ndialogue towards more effective intervention stages. Based on 30,000 real\npsychological hotline conversations, we employ AI-simulated dialogues and\nexpert re-annotation strategies to construct a high-quality multi-turn dialogue\ndataset. Experimental results demonstrate that DeepPsy-Agent outperforms\ngeneral-purpose large language models (LLMs) in key metrics such as problem\nexposure completeness, cognitive restructuring success rate, and action\nadoption rate. Ablation studies further validate the effectiveness of\nstage-awareness and deep-thinking modules, showing that stage information\ncontributes 42.3\\% to performance, while the deep-thinking module increases\nroot-cause identification by 58.3\\% and reduces ineffective suggestions by\n72.1\\%. This system addresses critical challenges in AI-based psychological\nsupport through dynamic dialogue management and deep reasoning, advancing\nintelligent mental health services.",
      "tldr_zh": "本文提出DeepPsy-Agent，一种基于心理学三阶段帮助理论和深度学习技术的创新心理支持系统。该系统包括两个核心模块：(1) 多阶段响应对话模型(deeppsy-chat)，通过阶段感知和深度思考分析生成高质量回复；(2) 实时阶段转换检测模型，识别语境变化以引导对话进入更有效的干预阶段。实验表明，DeepPsy-Agent在问题暴露完整性、认知重构成功率和行动采纳率等关键指标上优于通用大语言模型(LLMs)，其中阶段信息和深度思考模块对性能提升贡献显著，分别达到42.3%和58.3%。该系统通过动态对话管理和深度推理，推动了智能心理健康服务的发展。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15876v1",
      "published_date": "2025-03-20 05:59:29 UTC",
      "updated_date": "2025-03-20 05:59:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:29:59.465870"
    },
    {
      "arxiv_id": "2503.15867v1",
      "title": "TruthLens: Explainable DeepFake Detection for Face Manipulated and Fully Synthetic Data",
      "title_zh": "TruthLens：面向面部篡改与全合成数据的可解释深度伪造检测",
      "authors": [
        "Rohit Kundu",
        "Athula Balachandran",
        "Amit K. Roy-Chowdhury"
      ],
      "abstract": "Detecting DeepFakes has become a crucial research area as the widespread use\nof AI image generators enables the effortless creation of face-manipulated and\nfully synthetic content, yet existing methods are often limited to binary\nclassification (real vs. fake) and lack interpretability. To address these\nchallenges, we propose TruthLens, a novel and highly generalizable framework\nfor DeepFake detection that not only determines whether an image is real or\nfake but also provides detailed textual reasoning for its predictions. Unlike\ntraditional methods, TruthLens effectively handles both face-manipulated\nDeepFakes and fully AI-generated content while addressing fine-grained queries\nsuch as \"Does the eyes/nose/mouth look real or fake?\"\n  The architecture of TruthLens combines the global contextual understanding of\nmultimodal large language models like PaliGemma2 with the localized feature\nextraction capabilities of vision-only models like DINOv2. This hybrid design\nleverages the complementary strengths of both models, enabling robust detection\nof subtle manipulations while maintaining interpretability. Extensive\nexperiments on diverse datasets demonstrate that TruthLens outperforms\nstate-of-the-art methods in detection accuracy (by 2-14%) and explainability,\nin both in-domain and cross-data settings, generalizing effectively across\ntraditional and emerging manipulation techniques.",
      "tldr_zh": "该研究提出了TruthLens，一种可解释的DeepFake检测框架，能够同时处理人脸篡改和完全合成的内容。与传统的二分类方法不同，TruthLens不仅判断图像的真伪，还提供详细的文本解释，例如针对眼睛、鼻子或嘴部的真实性分析。该框架结合了多模态大语言模型（如PaliGemma2）的全局上下文理解能力和视觉模型（如DINOv2）的局部特征提取能力，实现了高精度的检测和可解释性。实验表明，TruthLens在检测准确性和解释能力上均优于现有方法，且在不同数据集和新兴篡改技术中表现出良好的泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15867v1",
      "published_date": "2025-03-20 05:40:42 UTC",
      "updated_date": "2025-03-20 05:40:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:30:25.561598"
    },
    {
      "arxiv_id": "2503.15865v2",
      "title": "Active management of battery degradation in wireless sensor network using deep reinforcement learning for group battery replacement",
      "title_zh": "基于深度强化学习的无线传感器网络电池退化主动管理及组群更换策略",
      "authors": [
        "Jong-Hyun Jeong",
        "Hongki Jo",
        "Qiang Zhou",
        "Tahsin Afroz Hoque Nishat",
        "Lang Wu"
      ],
      "abstract": "Wireless sensor networks (WSNs) have become a promising solution for\nstructural health monitoring (SHM), especially in hard-to-reach or remote\nlocations. Battery-powered WSNs offer various advantages over wired systems,\nhowever limited battery life has always been one of the biggest obstacles in\npractical use of the WSNs, regardless of energy harvesting methods. While\nvarious methods have been studied for battery health management, existing\nmethods exclusively aim to extend lifetime of individual batteries, lacking a\nsystem level view. A consequence of applying such methods is that batteries in\na WSN tend to fail at different times, posing significant difficulty on\nplanning and scheduling of battery replacement trip. This study investigate a\ndeep reinforcement learning (DRL) method for active battery degradation\nmanagement by optimizing duty cycle of WSNs at the system level. This active\nmanagement strategy effectively reduces earlier failure of battery individuals\nwhich enable group replacement without sacrificing WSN performances. A\nsimulated environment based on a real-world WSN setup was developed to train a\nDRL agent and learn optimal duty cycle strategies. The performance of the\nstrategy was validated in a long-term setup with various network sizes,\ndemonstrating its efficiency and scalability.",
      "tldr_zh": "本研究提出了一种基于深度强化学习(DRL)的主动电池退化管理方法，用于优化无线传感器网络(WSN)中的电池组更换策略。与现有方法不同，该研究从系统层面出发，通过调整WSN的工作周期(duty cycle)，有效减少了单个电池的过早失效，从而实现了电池的组更换(group replacement)，同时保证了网络性能。研究开发了基于真实WSN设置的模拟环境来训练DRL代理，并在不同规模网络中验证了该策略的有效性和可扩展性，为解决WSN电池寿命管理难题提供了新思路。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15865v2",
      "published_date": "2025-03-20 05:36:33 UTC",
      "updated_date": "2025-03-22 20:21:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:30:25.838956"
    },
    {
      "arxiv_id": "2503.15855v1",
      "title": "VideoRFSplat: Direct Scene-Level Text-to-3D Gaussian Splatting Generation with Flexible Pose and Multi-View Joint Modeling",
      "title_zh": "VideoRFSplat：基于灵活姿态和多视角联合建模的直接场景级文本到3D高斯溅射生成",
      "authors": [
        "Hyojun Go",
        "Byeongjun Park",
        "Hyelin Nam",
        "Byung-Hoon Kim",
        "Hyungjin Chung",
        "Changick Kim"
      ],
      "abstract": "We propose VideoRFSplat, a direct text-to-3D model leveraging a video\ngeneration model to generate realistic 3D Gaussian Splatting (3DGS) for\nunbounded real-world scenes. To generate diverse camera poses and unbounded\nspatial extent of real-world scenes, while ensuring generalization to arbitrary\ntext prompts, previous methods fine-tune 2D generative models to jointly model\ncamera poses and multi-view images. However, these methods suffer from\ninstability when extending 2D generative models to joint modeling due to the\nmodality gap, which necessitates additional models to stabilize training and\ninference. In this work, we propose an architecture and a sampling strategy to\njointly model multi-view images and camera poses when fine-tuning a video\ngeneration model. Our core idea is a dual-stream architecture that attaches a\ndedicated pose generation model alongside a pre-trained video generation model\nvia communication blocks, generating multi-view images and camera poses through\nseparate streams. This design reduces interference between the pose and image\nmodalities. Additionally, we propose an asynchronous sampling strategy that\ndenoises camera poses faster than multi-view images, allowing rapidly denoised\nposes to condition multi-view generation, reducing mutual ambiguity and\nenhancing cross-modal consistency. Trained on multiple large-scale real-world\ndatasets (RealEstate10K, MVImgNet, DL3DV-10K, ACID), VideoRFSplat outperforms\nexisting text-to-3D direct generation methods that heavily depend on post-hoc\nrefinement via score distillation sampling, achieving superior results without\nsuch refinement.",
      "tldr_zh": "该研究提出了VideoRFSplat，一种直接从文本生成3D高斯溅射(3DGS)的模型，用于生成无边界真实场景的3D重建。该模型通过双流架构和异步采样策略，联合建模多视角图像和相机姿态，解决了现有方法因模态差异导致的不稳定问题。实验表明，VideoRFSplat在多个大规模真实场景数据集上表现优异，无需依赖后处理优化即可实现高质量的3D生成，超越了现有依赖评分蒸馏采样的文本到3D直接生成方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://gohyojun15.github.io/VideoRFSplat/",
      "pdf_url": "http://arxiv.org/pdf/2503.15855v1",
      "published_date": "2025-03-20 05:26:09 UTC",
      "updated_date": "2025-03-20 05:26:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:30:24.378912"
    },
    {
      "arxiv_id": "2503.15848v1",
      "title": "Entropy-based Exploration Conduction for Multi-step Reasoning",
      "title_zh": "基于熵的多步推理探索深度引导",
      "authors": [
        "Jinghan Zhang",
        "Xiting Wang",
        "Fengran Mo",
        "Yeyang Zhou",
        "Wanfu Gao",
        "Kunpeng Liu"
      ],
      "abstract": "In large language model (LLM) reasoning, multi-step processes have proven\neffective for solving complex tasks. However, the depth of exploration can\nsignificantly affect the reasoning performance. Existing methods to\nautomatically decide the depth often bring high costs and lack flexibility, and\nthus undermine the model's reasoning accuracy. To address these issues, we\npropose Entropy-based Exploration Depth Conduction (Entro-duction), a novel\nmethod that dynamically adjusts the exploration depth during multi-step\nreasoning by monitoring LLM's output entropy and variance entropy. We employ\nthese two metrics to capture the model's current uncertainty and the\nfluctuation of uncertainty across consecutive reasoning steps. Based on the\nobserved changes, the LLM selects whether to deepen, expand or stop exploration\naccording to the probability. In this way, we balance the reasoning accuracy\nand exploration effectiveness. Experimental results across four benchmark\ndatasets demonstrate the efficacy of Entro-duction. We further conduct\nexperiments and analysis on the components of Entro-duction to discuss their\ncontributions to reasoning performance.",
      "tldr_zh": "该研究提出了一种基于熵的探索深度引导方法（Entro-duction），用于优化大语言模型（LLM）的多步推理过程。该方法通过监控模型输出的熵和方差熵，动态调整探索深度，以捕捉模型的不确定性及其在连续推理步骤中的波动。根据这些变化，模型概率性地选择加深、扩展或停止探索，从而在推理准确性和探索效率之间取得平衡。实验结果表明，Entro-duction在四个基准数据集上均表现出色，显著提升了推理性能。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15848v1",
      "published_date": "2025-03-20 05:03:26 UTC",
      "updated_date": "2025-03-20 05:03:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:30:35.245985"
    },
    {
      "arxiv_id": "2503.15847v1",
      "title": "Beyond Local Selection: Global Cut Selection for Enhanced Mixed-Integer Programming",
      "title_zh": "超越局部选择：全局割平面选择以增强混合整数规划",
      "authors": [
        "Shuli Zeng",
        "Sijia Zhang",
        "Shaoang Li",
        "Feng Wu",
        "Xiang-Yang Li"
      ],
      "abstract": "In mixed-integer programming (MIP) solvers, cutting planes are essential for\nBranch-and-Cut (B&C) algorithms as they reduce the search space and accelerate\nthe solving process. Traditional methods rely on hard-coded heuristics for cut\nplane selection but fail to leverage problem-specific structural features.\nRecent machine learning approaches use neural networks for cut selection but\nfocus narrowly on the efficiency of single-node within the B&C algorithm,\nwithout considering the broader contextual information. To address this, we\npropose Global Cut Selection (GCS), which uses a bipartite graph to represent\nthe search tree and combines graph neural networks with reinforcement learning\nto develop cut selection strategies. Unlike prior methods, GCS applies cutting\nplanes across all nodes, incorporating richer contextual information.\nExperiments show GCS significantly improves solving efficiency for synthetic\nand large-scale real-world MIPs compared to traditional and learning-based\nmethods.",
      "tldr_zh": "本文提出了全局割平面选择方法（Global Cut Selection, GCS），用于增强混合整数规划（MIP）求解器的性能。传统方法依赖固定启发式规则选择割平面，无法利用问题特定的结构特征，而现有机器学习方法仅关注分支定界（B&C）算法中单个节点的效率，缺乏全局上下文信息。GCS通过二分图表示搜索树，结合图神经网络和强化学习，开发了跨所有节点的割平面选择策略。实验表明，GCS在合成和大规模实际MIP问题上显著提高了求解效率，优于传统方法和现有学习型方法。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15847v1",
      "published_date": "2025-03-20 04:59:18 UTC",
      "updated_date": "2025-03-20 04:59:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:30:54.333317"
    },
    {
      "arxiv_id": "2503.15837v1",
      "title": "Fùxì: A Benchmark for Evaluating Language Models on Ancient Chinese Text Understanding and Generation",
      "title_zh": "Fùxì：评估语言模型在古文理解与生成上的基准",
      "authors": [
        "Shangqing Zhao",
        "Yuhao Zhou",
        "Yupei Ren",
        "Zhe Chen",
        "Chenghao Jia",
        "Fang Zhe",
        "Zhaogaung Long",
        "Shu Liu",
        "Man Lan"
      ],
      "abstract": "Ancient Chinese text processing presents unique challenges for large language\nmodels (LLMs) due to its distinct linguistic features, complex structural\nconstraints, and rich cultural context. While existing benchmarks have\nprimarily focused on evaluating comprehension through multiple-choice\nquestions, there remains a critical gap in assessing models' generative\ncapabilities in classical Chinese. We introduce F\\`ux\\`i, a comprehensive\nbenchmark that evaluates both understanding and generation capabilities across\n21 diverse tasks. Our benchmark distinguishes itself through three key\ncontributions: (1) balanced coverage of both comprehension and generation\ntasks, including novel tasks like poetry composition and couplet completion,\n(2) specialized evaluation metrics designed specifically for classical Chinese\ntext generation, combining rule-based verification with fine-tuned LLM\nevaluators, and (3) a systematic assessment framework that considers both\nlinguistic accuracy and cultural authenticity. Through extensive evaluation of\nstate-of-the-art LLMs, we reveal significant performance gaps between\nunderstanding and generation tasks, with models achieving promising results in\ncomprehension but struggling considerably in generation tasks, particularly\nthose requiring deep cultural knowledge and adherence to classical formats. Our\nfindings highlight the current limitations in ancient Chinese text processing\nand provide insights for future model development. The benchmark, evaluation\ntoolkit, and baseline results are publicly available to facilitate research in\nthis domain.",
      "tldr_zh": "该研究提出了Fùxì，一个专门用于评估语言模型在古代中文文本理解和生成能力的基准。Fùxì包含21项多样化任务，涵盖理解与生成两大维度，如诗歌创作和对联完成等。其独特贡献在于：(1) 平衡了理解与生成任务的覆盖，(2) 设计了针对古典中文生成的专业评估指标，(3) 构建了综合考虑语言准确性和文化真实性的系统评估框架。实验表明，现有模型在理解任务上表现较好，但在生成任务（尤其是需要深厚文化知识和古典格式的任务）上表现较差，凸显了古代中文文本处理的局限性。该基准及相关资源已公开，旨在推动该领域的研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "working in progress",
      "pdf_url": "http://arxiv.org/pdf/2503.15837v1",
      "published_date": "2025-03-20 04:26:40 UTC",
      "updated_date": "2025-03-20 04:26:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:31:37.913282"
    },
    {
      "arxiv_id": "2503.15818v2",
      "title": "Computation-Efficient and Recognition-Friendly 3D Point Cloud Privacy Protection",
      "title_zh": "高效计算与识别友好的三维点云隐私保护",
      "authors": [
        "Haotian Ma",
        "Lin Gu",
        "Siyi Wu",
        "Yingying Zhu"
      ],
      "abstract": "3D point cloud has been widely used in applications such as self-driving\ncars, robotics, CAD models, etc. To the best of our knowledge, these\napplications raised the issue of privacy leakage in 3D point clouds, which has\nnot been studied well. Different from the 2D image privacy, which is related to\ntexture and 2D geometric structure, the 3D point cloud is texture-less and only\nrelevant to 3D geometric structure. In this work, we defined the 3D point cloud\nprivacy problem and proposed an efficient privacy-preserving framework named\nPointFlowGMM that can support downstream classification and segmentation tasks\nwithout seeing the original data. Using a flow-based generative model, the\npoint cloud is projected into a latent Gaussian mixture distributed subspace.\nWe further designed a novel angular similarity loss to obfuscate the original\ngeometric structure and reduce the model size from 767MB to 120MB without a\ndecrease in recognition performance. The projected point cloud in the latent\nspace is orthogonally rotated randomly to further protect the original\ngeometric structure, the class-to-class relationship is preserved after\nrotation, thus, the protected point cloud can support the recognition task. We\nevaluated our model on multiple datasets and achieved comparable recognition\nresults on encrypted point clouds compared to the original point clouds.",
      "tldr_zh": "该研究首次定义了3D点云隐私保护问题，并提出了一种高效的隐私保护框架PointFlowGMM。该框架利用基于流的生成模型将点云投影到高斯混合分布的潜在子空间，并通过设计新颖的角度相似性损失函数模糊原始几何结构，同时将模型大小从767MB压缩至120MB，且不影响识别性能。实验表明，加密后的点云在分类和分割任务中保持了与原数据相当的识别效果，为3D点云的隐私保护提供了新思路。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR2025",
      "pdf_url": "http://arxiv.org/pdf/2503.15818v2",
      "published_date": "2025-03-20 03:09:44 UTC",
      "updated_date": "2025-03-23 19:45:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:31:28.201640"
    },
    {
      "arxiv_id": "2503.15817v1",
      "title": "Ranking Counterfactual Explanations",
      "title_zh": "排序反事实解释",
      "authors": [
        "Suryani Lim",
        "Henri Prade",
        "Gilles Richard"
      ],
      "abstract": "AI-driven outcomes can be challenging for end-users to understand.\nExplanations can address two key questions: \"Why this outcome?\" (factual) and\n\"Why not another?\" (counterfactual). While substantial efforts have been made\nto formalize factual explanations, a precise and comprehensive study of\ncounterfactual explanations is still lacking. This paper proposes a formal\ndefinition of counterfactual explanations, proving some properties they\nsatisfy, and examining the relationship with factual explanations. Given that\nmultiple counterfactual explanations generally exist for a specific case, we\nalso introduce a rigorous method to rank these counterfactual explanations,\ngoing beyond a simple minimality condition, and to identify the optimal ones.\nOur experiments with 12 real-world datasets highlight that, in most cases, a\nsingle optimal counterfactual explanation emerges. We also demonstrate, via\nthree metrics, that the selected optimal explanation exhibits higher\nrepresentativeness and can explain a broader range of elements than a random\nminimal counterfactual. This result highlights the effectiveness of our\napproach in identifying more robust and comprehensive counterfactual\nexplanations.",
      "tldr_zh": "本文提出了一个关于反事实解释(counterfactual explanations)的形式化定义，并证明了其满足的某些性质，同时探讨了其与事实解释(factual explanations)的关系。针对特定案例通常存在多个反事实解释的情况，研究引入了一种严格的排序方法，超越了简单的最小化条件，以识别最优解释。在12个真实数据集上的实验表明，大多数情况下存在单一的最优反事实解释，且该解释在代表性和解释范围上优于随机最小反事实解释。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "15 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.15817v1",
      "published_date": "2025-03-20 03:04:05 UTC",
      "updated_date": "2025-03-20 03:04:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:31:23.410008"
    },
    {
      "arxiv_id": "2503.15815v1",
      "title": "Attention Pruning: Automated Fairness Repair of Language Models via Surrogate Simulated Annealing",
      "title_zh": "注意力剪枝：通过代理模拟退火实现语言模型的自动公平性修复",
      "authors": [
        "Vishnu Asutosh Dasu",
        "Md Rafi ur Rashid",
        "Vipul Gupta",
        "Saeid Tizpaz-Niari",
        "Gang Tan"
      ],
      "abstract": "This paper explores pruning attention heads as a post-processing bias\nmitigation method for large language models (LLMs). Modern AI systems such as\nLLMs are expanding into sensitive social contexts where fairness concerns\nbecome especially crucial. Since LLMs develop decision-making patterns by\ntraining on massive datasets of human-generated content, they naturally encode\nand perpetuate societal biases. While modifying training datasets and\nalgorithms is expensive and requires significant resources; post-processing\ntechniques-such as selectively deactivating neurons and attention heads in\npre-trained LLMs-can provide feasible and effective approaches to improve\nfairness. However, identifying the optimal subset of parameters to prune\npresents a combinatorial challenge within LLMs' immense parameter space,\nrequiring solutions that efficiently balance competing objectives across the\nfrontiers of model fairness and utility.\n  To address the computational challenges, we explore a search-based program\nrepair approach via randomized simulated annealing. Given the prohibitive\nevaluation costs in billion-parameter LLMs, we develop surrogate deep neural\nnetworks that efficiently model the relationship between attention head states\n(active/inactive) and their corresponding fairness/utility metrics. This allows\nus to perform optimization over the surrogate models and efficiently identify\noptimal subsets of attention heads for selective pruning rather than directly\nsearching through the LLM parameter space. This paper introduces Attention\nPruning, a fairness-aware surrogate simulated annealing approach to prune\nattention heads in LLMs that disproportionately contribute to bias while\nminimally impacting overall model utility. Our experiments show that Attention\nPruning achieves up to $40\\%$ reduction in gender bias and outperforms the\nstate-of-the-art bias mitigation strategies.",
      "tldr_zh": "本文提出了一种名为Attention Pruning的后处理方法，通过代理模拟退火（Surrogate Simulated Annealing）技术修剪大型语言模型（LLMs）中的注意力头，以减少模型偏见。由于LLMs在训练过程中会继承和放大社会偏见，直接修改训练数据或算法成本高昂，而选择性修剪注意力头则是一种更可行且有效的方法。为了解决在庞大参数空间中寻找最优修剪子集的组合挑战，作者设计了基于深度神经网络的代理模型，用于高效建模注意力头状态与公平性/效用指标之间的关系。实验表明，Attention Pruning在减少性别偏见方面实现了高达40%的改进，并优于现有的偏见缓解策略，同时最小化了对模型整体效用的影响。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15815v1",
      "published_date": "2025-03-20 03:02:32 UTC",
      "updated_date": "2025-03-20 03:02:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:31:52.004143"
    },
    {
      "arxiv_id": "2503.15808v1",
      "title": "ChatGPT and U(X): A Rapid Review on Measuring the User Experience",
      "title_zh": "ChatGPT 与用户体验 (UX)：关于用户体验测量的快速综述",
      "authors": [
        "Katie Seaborn"
      ],
      "abstract": "ChatGPT, powered by a large language model (LLM), has revolutionized everyday\nhuman-computer interaction (HCI) since its 2022 release. While now used by\nmillions around the world, a coherent pathway for evaluating the user\nexperience (UX) ChatGPT offers remains missing. In this rapid review (N = 58),\nI explored how ChatGPT UX has been approached quantitatively so far. I focused\non the independent variables (IVs) manipulated, the dependent variables (DVs)\nmeasured, and the methods used for measurement. Findings reveal trends, gaps,\nand emerging consensus in UX assessments. This work offers a first step towards\nsynthesizing existing approaches to measuring ChatGPT UX, urgent trajectories\nto advance standardization and breadth, and two preliminary frameworks aimed at\nguiding future research and tool development. I seek to elevate the field of\nChatGPT UX by empowering researchers and practitioners in optimizing user\ninteractions with ChatGPT and similar LLM-based systems.",
      "tldr_zh": "本研究通过快速综述（N = 58）探讨了ChatGPT用户体验（UX）的量化评估方法，分析了独立变量（IVs）、因变量（DVs）及测量方法。研究揭示了当前UX评估中的趋势、差距和共识，并提出了两个初步框架，以指导未来研究和工具开发。该工作旨在推动ChatGPT及类似大语言模型（LLM）系统用户体验的标准化和优化，为研究者和实践者提供支持。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15808v1",
      "published_date": "2025-03-20 02:51:11 UTC",
      "updated_date": "2025-03-20 02:51:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:31:42.021364"
    },
    {
      "arxiv_id": "2503.15807v1",
      "title": "Video-VoT-R1: An efficient video inference model integrating image packing and AoE architecture",
      "title_zh": "Video-VoT-R1：集成图像打包与AoE架构的高效视频推理模型",
      "authors": [
        "Cheng Li",
        "Jiexiong Liu",
        "Yixuan Chen",
        "Yanqin Jia"
      ],
      "abstract": "In the field of video-language pretraining, existing models face numerous\nchallenges in terms of inference efficiency and multimodal data processing.\nThis paper proposes a KunLunBaize-VoT-R1 video inference model based on a\nlong-sequence image encoder, along with its training and application methods.\nBy integrating image packing technology, the Autonomy-of-Experts (AoE)\narchitecture, and combining the video of Thought (VoT), a large language model\n(LLM) trained with large-scale reinforcement learning, and multiple training\ntechniques, the efficiency and accuracy of the model in video inference tasks\nare effectively improved. Experiments show that this model performs\noutstandingly in multiple tests, providing a new solution for video-language\nunderstanding.",
      "tldr_zh": "本研究提出了Video-VoT-R1视频推理模型，通过整合图像打包技术和专家自治架构(AoE)，结合视频思维链(VoT)和基于大规模强化学习训练的大语言模型(LLM)，显著提升了视频语言理解任务的效率和准确性。实验表明，该模型在多项测试中表现优异，为视频语言理解领域提供了新的解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.15807v1",
      "published_date": "2025-03-20 02:50:57 UTC",
      "updated_date": "2025-03-20 02:50:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:31:35.876812"
    },
    {
      "arxiv_id": "2503.15796v1",
      "title": "Blend the Separated: Mixture of Synergistic Experts for Data-Scarcity Drug-Target Interaction Prediction",
      "title_zh": "融合分离数据：协同专家混合模型用于数据稀缺的药物-靶标相互作用预测",
      "authors": [
        "Xinlong Zhai",
        "Chunchen Wang",
        "Ruijia Wang",
        "Jiazheng Kang",
        "Shujie Li",
        "Boyu Chen",
        "Tengfei Ma",
        "Zikai Zhou",
        "Cheng Yang",
        "Chuan Shi"
      ],
      "abstract": "Drug-target interaction prediction (DTI) is essential in various applications\nincluding drug discovery and clinical application. There are two perspectives\nof input data widely used in DTI prediction: Intrinsic data represents how\ndrugs or targets are constructed, and extrinsic data represents how drugs or\ntargets are related to other biological entities. However, any of the two\nperspectives of input data can be scarce for some drugs or targets, especially\nfor those unpopular or newly discovered. Furthermore, ground-truth labels for\nspecific interaction types can also be scarce. Therefore, we propose the first\nmethod to tackle DTI prediction under input data and/or label scarcity. To make\nour model functional when only one perspective of input data is available, we\ndesign two separate experts to process intrinsic and extrinsic data\nrespectively and fuse them adaptively according to different samples.\nFurthermore, to make the two perspectives complement each other and remedy\nlabel scarcity, two experts synergize with each other in a mutually supervised\nway to exploit the enormous unlabeled data. Extensive experiments on 3\nreal-world datasets under different extents of input data scarcity and/or label\nscarcity demonstrate our model outperforms states of the art significantly and\nsteadily, with a maximum improvement of 53.53%. We also test our model without\nany data scarcity and it still outperforms current methods.",
      "tldr_zh": "该研究提出了一种基于协同专家混合模型的新方法，用于解决药物-靶点相互作用预测(DTI)中的数据稀缺问题。针对内在数据（药物或靶点的结构）和外在数据（药物或靶点与其他生物实体的关系）可能单独稀缺的情况，设计了两个独立的专家模型分别处理这两类数据，并根据样本自适应融合。同时，通过相互监督的方式，利用大量未标注数据弥补标签稀缺的不足。实验表明，该方法在三种真实数据集上显著优于现有技术，最高提升53.53%，且在无数据稀缺情况下也表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15796v1",
      "published_date": "2025-03-20 02:27:16 UTC",
      "updated_date": "2025-03-20 02:27:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:31:54.149489"
    },
    {
      "arxiv_id": "2503.15783v1",
      "title": "Grammar and Gameplay-aligned RL for Game Description Generation with LLMs",
      "title_zh": "语法与玩法对齐的强化学习用于基于大语言模型的游戏描述生成",
      "authors": [
        "Tsunehiko Tanaka",
        "Edgar Simo-Serra"
      ],
      "abstract": "Game Description Generation (GDG) is the task of generating a game\ndescription written in a Game Description Language (GDL) from natural language\ntext. Previous studies have explored generation methods leveraging the\ncontextual understanding capabilities of Large Language Models (LLMs); however,\naccurately reproducing the game features of the game descriptions remains a\nchallenge. In this paper, we propose reinforcement learning-based fine-tuning\nof LLMs for GDG (RLGDG). Our training method simultaneously improves\ngrammatical correctness and fidelity to game concepts by introducing both\ngrammar rewards and concept rewards. Furthermore, we adopt a two-stage training\nstrategy where Reinforcement Learning (RL) is applied following Supervised\nFine-Tuning (SFT). Experimental results demonstrate that our proposed method\nsignificantly outperforms baseline methods using SFT alone.",
      "tldr_zh": "本文提出了一种基于强化学习（RL）的大语言模型（LLMs）微调方法（RLGDG），用于从自然语言文本生成游戏描述语言（GDL）的游戏描述生成（GDG）任务。该方法通过引入语法奖励和游戏概念奖励，同时提升生成内容的语法正确性和对游戏概念的忠实度，并采用监督微调（SFT）后接强化学习的两阶段训练策略。实验表明，该方法显著优于仅使用监督微调的基线方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15783v1",
      "published_date": "2025-03-20 01:47:33 UTC",
      "updated_date": "2025-03-20 01:47:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:31:59.155407"
    },
    {
      "arxiv_id": "2503.15779v1",
      "title": "MobiFuse: Learning Universal Human Mobility Patterns through Cross-domain Data Fusion",
      "title_zh": "MobiFuse：通过跨领域数据融合学习普适人类移动模式",
      "authors": [
        "Haoxuan Ma",
        "Xishun Liao",
        "Yifan Liu",
        "Qinhua Jiang",
        "Chris Stanford",
        "Shangqing Cao",
        "Jiaqi Ma"
      ],
      "abstract": "Human mobility modeling is critical for urban planning and transportation\nmanagement, yet existing datasets often lack the resolution and semantic\nrichness required for comprehensive analysis. To address this, we proposed a\ncross-domain data fusion framework that integrates multi-modal data of distinct\nnature and spatio-temporal resolution, including geographical, mobility,\nsocio-demographic, and traffic information, to construct a privacy-preserving\nand semantically enriched human travel trajectory dataset. This framework is\ndemonstrated through two case studies in Los Angeles (LA) and Egypt, where a\ndomain adaptation algorithm ensures its transferability across diverse urban\ncontexts. Quantitative evaluation shows that the generated synthetic dataset\naccurately reproduces mobility patterns observed in empirical data. Moreover,\nlarge-scale traffic simulations for LA County based on the generated synthetic\ndemand align well with observed traffic. On California's I-405 corridor, the\nsimulation yields a Mean Absolute Percentage Error of 5.85% for traffic volume\nand 4.36% for speed compared to Caltrans PeMS observations.",
      "tldr_zh": "该研究提出了MobiFuse框架，通过跨领域数据融合技术，整合地理、移动、社会人口统计和交通等多模态数据，构建了一个隐私保护且语义丰富的人类出行轨迹数据集。该框架在洛杉矶和埃及的案例研究中展示了其跨城市环境的可迁移性，生成的合成数据集准确复现了实际观测的移动模式。基于该数据集的大规模交通模拟在洛杉矶县和加州I-405走廊上表现出与观测数据高度一致的结果，交通流量和速度的平均绝对百分比误差分别低至5.85%和4.36%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15779v1",
      "published_date": "2025-03-20 01:41:28 UTC",
      "updated_date": "2025-03-20 01:41:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:32:05.163648"
    },
    {
      "arxiv_id": "2503.15772v1",
      "title": "Detecting LLM-Written Peer Reviews",
      "title_zh": "检测由大语言模型撰写的同行评审",
      "authors": [
        "Vishisht Rao",
        "Aounon Kumar",
        "Himabindu Lakkaraju",
        "Nihar B. Shah"
      ],
      "abstract": "Editors of academic journals and program chairs of conferences require peer\nreviewers to write their own reviews. However, there is growing concern about\nthe rise of lazy reviewing practices, where reviewers use large language models\n(LLMs) to generate reviews instead of writing them independently. Existing\ntools for detecting LLM-generated content are not designed to differentiate\nbetween fully LLM-generated reviews and those merely polished by an LLM. In\nthis work, we employ a straightforward approach to identify LLM-generated\nreviews - doing an indirect prompt injection via the paper PDF to ask the LLM\nto embed a watermark. Our focus is on presenting watermarking schemes and\nstatistical tests that maintain a bounded family-wise error rate, when a venue\nevaluates multiple reviews, with a higher power as compared to standard methods\nlike Bonferroni correction. These guarantees hold without relying on any\nassumptions about human-written reviews. We also consider various methods for\nprompt injection including font embedding and jailbreaking. We evaluate the\neffectiveness and various tradeoffs of these methods, including different\nreviewer defenses. We find a high success rate in the embedding of our\nwatermarks in LLM-generated reviews across models. We also find that our\napproach is resilient to common reviewer defenses, and that the bounds on error\nrates in our statistical tests hold in practice while having the power to flag\nLLM-generated reviews, while Bonferroni correction is infeasible.",
      "tldr_zh": "该研究提出了一种通过间接提示注入和水印嵌入技术来检测由大语言模型(LLMs)生成的同行评审的方法。研究重点在于开发能够维持有限家族错误率的水印方案和统计测试，相较于标准方法如Bonferroni校正，具有更高的检测效能。该方法不依赖于对人类撰写评审的假设，并通过字体嵌入和越狱等多种提示注入方式实现。实验结果表明，该方法在LLM生成的评审中成功嵌入水印的比率较高，且对常见的评审防御措施具有鲁棒性，同时在实际应用中能够有效标记LLM生成的评审，而Bonferroni校正在此场景下不可行。",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.DL",
      "comment": "26 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2503.15772v1",
      "published_date": "2025-03-20 01:11:35 UTC",
      "updated_date": "2025-03-20 01:11:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:32:34.809638"
    },
    {
      "arxiv_id": "2503.15768v1",
      "title": "Can one size fit all?: Measuring Failure in Multi-Document Summarization Domain Transfer",
      "title_zh": "一劳永逸是否可行？：多文档摘要领域迁移中的失败衡量",
      "authors": [
        "Alexandra DeLucia",
        "Mark Dredze"
      ],
      "abstract": "Abstractive multi-document summarization (MDS) is the task of automatically\nsummarizing information in multiple documents, from news articles to\nconversations with multiple speakers. The training approaches for current MDS\nmodels can be grouped into four approaches: end-to-end with special\npre-training (\"direct\"), chunk-then-summarize, extract-then-summarize, and\ninference with GPT-style models. In this work, we evaluate MDS models across\ntraining approaches, domains, and dimensions (reference similarity, quality,\nand factuality), to analyze how and why models trained on one domain can fail\nto summarize documents from another (News, Science, and Conversation) in the\nzero-shot domain transfer setting. We define domain-transfer \"failure\" as a\ndecrease in factuality, higher deviation from the target, and a general\ndecrease in summary quality. In addition to exploring domain transfer for MDS\nmodels, we examine potential issues with applying popular summarization metrics\nout-of-the-box.",
      "tldr_zh": "本研究探讨了多文档摘要(MDS)模型在跨领域迁移中的表现，特别是当模型在一个领域训练后用于另一个领域时的失败情况。研究分析了四种训练方法（直接训练、分块后摘要、抽取后摘要和GPT风格模型推理）在新闻、科学和对话三个领域的表现，评估了摘要的参考相似性、质量和事实性。研究发现，领域迁移失败主要表现为事实性下降、与目标摘要的偏差增大以及整体摘要质量降低。此外，研究还指出了现成摘要评估指标在跨领域应用中的潜在问题。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15768v1",
      "published_date": "2025-03-20 00:57:38 UTC",
      "updated_date": "2025-03-20 00:57:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:32:27.579763"
    },
    {
      "arxiv_id": "2503.16558v1",
      "title": "Advancing Problem-Based Learning in Biomedical Engineering in the Era of Generative AI",
      "title_zh": "生成式人工智能时代下生物医学工程中问题导向学习的推进",
      "authors": [
        "Micky C. Nnamdi",
        "J. Ben Tamo",
        "Wenqi Shi",
        "May D. Wang"
      ],
      "abstract": "Problem-Based Learning (PBL) has significantly impacted biomedical\nengineering (BME) education since its introduction in the early 2000s,\neffectively enhancing critical thinking and real-world knowledge application\namong students. With biomedical engineering rapidly converging with artificial\nintelligence (AI), integrating effective AI education into established\ncurricula has become challenging yet increasingly necessary. Recent\nadvancements, including AI's recognition by the 2024 Nobel Prize, have\nhighlighted the importance of training students comprehensively in biomedical\nAI. However, effective biomedical AI education faces substantial obstacles,\nsuch as diverse student backgrounds, limited personalized mentoring,\nconstrained computational resources, and difficulties in safely scaling\nhands-on practical experiments due to privacy and ethical concerns associated\nwith biomedical data. To overcome these issues, we conducted a three-year\n(2021-2023) case study implementing an advanced PBL framework tailored\nspecifically for biomedical AI education, involving 92 undergraduate and 156\ngraduate students from the joint Biomedical Engineering program of Georgia\nInstitute of Technology and Emory University. Our approach emphasizes\ncollaborative, interdisciplinary problem-solving through authentic biomedical\nAI challenges. The implementation led to measurable improvements in learning\noutcomes, evidenced by high research productivity (16 student-authored\npublications), consistently positive peer evaluations, and successful\ndevelopment of innovative computational methods addressing real biomedical\nchallenges. Additionally, we examined the role of generative AI both as a\nteaching subject and an educational support tool within the PBL framework. Our\nstudy presents a practical and scalable roadmap for biomedical engineering\ndepartments aiming to integrate robust AI education into their curricula.",
      "tldr_zh": "本研究提出了一种针对生物医学工程（BME）教育的进阶问题导向学习（PBL）框架，旨在解决生成式AI时代中生物医学AI教育面临的挑战。通过一项为期三年（2021-2023）的案例研究，该框架结合真实生物医学AI问题，强调跨学科协作解决问题，显著提升了学生的学习成果，包括高研究产出（16篇学生发表论文）和创新计算方法的开发。研究还探讨了生成式AI作为教学内容和教育支持工具的作用，为生物医学工程课程中整合AI教育提供了可扩展的实践路径。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16558v1",
      "published_date": "2025-03-20 00:52:02 UTC",
      "updated_date": "2025-03-20 00:52:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:32:37.795988"
    },
    {
      "arxiv_id": "2503.15764v1",
      "title": "Towards Agentic AI Networking in 6G: A Generative Foundation Model-as-Agent Approach",
      "title_zh": "迈向6G中的主动式AI网络：一种生成式基础模型即智能体的方法",
      "authors": [
        "Yong Xiao",
        "Guangming Shi",
        "Ping Zhang"
      ],
      "abstract": "The promising potential of AI and network convergence in improving networking\nperformance and enabling new service capabilities has recently attracted\nsignificant interest. Existing network AI solutions, while powerful, are mainly\nbuilt based on the close-loop and passive learning framework, resulting in\nmajor limitations in autonomous solution finding and dynamic environmental\nadaptation. Agentic AI has recently been introduced as a promising solution to\naddress the above limitations and pave the way for true generally intelligent\nand beneficial AI systems. The key idea is to create a networking ecosystem to\nsupport a diverse range of autonomous and embodied AI agents in fulfilling\ntheir goals. In this paper, we focus on the novel challenges and requirements\nof agentic AI networking. We propose AgentNet, a novel framework for supporting\ninteraction, collaborative learning, and knowledge transfer among AI agents. We\nintroduce a general architectural framework of AgentNet and then propose a\ngenerative foundation model (GFM)-based implementation in which multiple\nGFM-as-agents have been created as an interactive knowledge-base to bootstrap\nthe development of embodied AI agents according to different task requirements\nand environmental features. We consider two application scenarios,\ndigital-twin-based industrial automation and metaverse-based infotainment\nsystem, to describe how to apply AgentNet for supporting efficient task-driven\ncollaboration and interaction among AI agents.",
      "tldr_zh": "该研究提出了AgentNet框架，旨在解决6G网络中AI代理的自主性、动态适应性和协作问题。通过引入生成式基础模型(GFM)作为代理，AgentNet支持AI代理之间的交互、协作学习和知识转移，从而提升网络性能和服务能力。研究还展示了AgentNet在数字孪生工业自动化和元宇宙娱乐系统中的应用，验证了其在任务驱动协作中的有效性。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "Currently under revision at IEEE Communications Magazine",
      "pdf_url": "http://arxiv.org/pdf/2503.15764v1",
      "published_date": "2025-03-20 00:48:44 UTC",
      "updated_date": "2025-03-20 00:48:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:32:49.215523"
    },
    {
      "arxiv_id": "2503.15762v1",
      "title": "Dialogic Learning in Child-Robot Interaction: A Hybrid Approach to Personalized Educational Content Generation",
      "title_zh": "儿童-机器人交互中的对话式学习：个性化教育内容生成的混合方法",
      "authors": [
        "Elena Malnatsky",
        "Shenghui Wang",
        "Koen V. Hindriks",
        "Mike E. U. Ligthart"
      ],
      "abstract": "Dialogic learning fosters motivation and deeper understanding in education\nthrough purposeful and structured dialogues. Foundational models offer a\ntransformative potential for child-robot interactions, enabling the design of\npersonalized, engaging, and scalable interactions. However, their integration\ninto educational contexts presents challenges in terms of ensuring\nage-appropriate and safe content and alignment with pedagogical goals. We\nintroduce a hybrid approach to designing personalized educational dialogues in\nchild-robot interactions. By combining rule-based systems with LLMs for\nselective offline content generation and human validation, the framework\nensures educational quality and developmental appropriateness. We illustrate\nthis approach through a project aimed at enhancing reading motivation, in which\na robot facilitated book-related dialogues.",
      "tldr_zh": "该研究提出了一种混合方法，用于在儿童与机器人互动中生成个性化教育内容。通过结合规则系统和大型语言模型（LLMs）进行选择性离线内容生成和人工验证，该方法确保了教育内容的适龄性和安全性，并与教学目标保持一致。研究以提升阅读动机的项目为例，展示了机器人如何通过书籍相关对话促进教育效果。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15762v1",
      "published_date": "2025-03-20 00:46:10 UTC",
      "updated_date": "2025-03-20 00:46:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:32:58.209838"
    },
    {
      "arxiv_id": "2503.15758v1",
      "title": "ATTENTION2D: Communication Efficient Distributed Self-Attention Mechanism",
      "title_zh": "ATTENTION2D：通信高效的分布式自注意力机制",
      "authors": [
        "Venmugil Elango"
      ],
      "abstract": "Transformer-based models have emerged as a leading architecture for natural\nlanguage processing, natural language generation, and image generation tasks. A\nfundamental element of the transformer architecture is self-attention, which\nallows the model to capture intricate dependencies within the data. However,\nthe self-attention mechanism also incurs significant computational and memory\ncosts, particularly for long sequences.\n  In this paper, we introduce ATTENTION2D, a novel approach that exploits\nparallelism along two dimensions - query and key/value - of the self-attention\noperation. This method enables efficient distribution and parallelization of\ncomputations across multiple devices. Our approach facilitates asymptotically\nfaster training and inference phases compared to previous methods, without\nrelying on approximations or incurring additional computational or memory\noverheads. Furthermore, unlike existing techniques that struggle to scale with\nan increasing number of processing units, our approach effectively scales with\nadditional processing units.\n  Our experimental results confirm the effectiveness of our method in improving\ncommunication efficiency and scalability. Compared to Ring Attention, our\napproach demonstrated up to a 5x performance boost on a GPT-3-like model using\n64 NVIDIA A100 GPUs across 16 nodes, and up to a 9.4x performance boost on 64\nNVIDIA H100 GPUs across 64 nodes.",
      "tldr_zh": "本文提出了ATTENTION2D，一种创新的分布式自注意力机制，通过并行化查询和键/值两个维度的计算，显著提升了Transformer模型在训练和推理阶段的效率。该方法无需近似计算或增加额外开销，即可实现渐进式加速，并能有效扩展至更多处理单元。实验表明，在64个NVIDIA A100和H100 GPU上，ATTENTION2D分别比Ring Attention性能提升了5倍和9.4倍，验证了其在通信效率和可扩展性方面的优越性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15758v1",
      "published_date": "2025-03-20 00:25:44 UTC",
      "updated_date": "2025-03-20 00:25:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:33:12.085780"
    },
    {
      "arxiv_id": "2503.15754v1",
      "title": "AutoRedTeamer: Autonomous Red Teaming with Lifelong Attack Integration",
      "title_zh": "AutoRedTeamer：具备终身攻击集成的自主红队测试",
      "authors": [
        "Andy Zhou",
        "Kevin Wu",
        "Francesco Pinto",
        "Zhaorun Chen",
        "Yi Zeng",
        "Yu Yang",
        "Shuang Yang",
        "Sanmi Koyejo",
        "James Zou",
        "Bo Li"
      ],
      "abstract": "As large language models (LLMs) become increasingly capable, security and\nsafety evaluation are crucial. While current red teaming approaches have made\nstrides in assessing LLM vulnerabilities, they often rely heavily on human\ninput and lack comprehensive coverage of emerging attack vectors. This paper\nintroduces AutoRedTeamer, a novel framework for fully automated, end-to-end red\nteaming against LLMs. AutoRedTeamer combines a multi-agent architecture with a\nmemory-guided attack selection mechanism to enable continuous discovery and\nintegration of new attack vectors. The dual-agent framework consists of a red\nteaming agent that can operate from high-level risk categories alone to\ngenerate and execute test cases and a strategy proposer agent that autonomously\ndiscovers and implements new attacks by analyzing recent research. This modular\ndesign allows AutoRedTeamer to adapt to emerging threats while maintaining\nstrong performance on existing attack vectors. We demonstrate AutoRedTeamer's\neffectiveness across diverse evaluation settings, achieving 20% higher attack\nsuccess rates on HarmBench against Llama-3.1-70B while reducing computational\ncosts by 46% compared to existing approaches. AutoRedTeamer also matches the\ndiversity of human-curated benchmarks in generating test cases, providing a\ncomprehensive, scalable, and continuously evolving framework for evaluating the\nsecurity of AI systems.",
      "tldr_zh": "本文提出了AutoRedTeamer，一种完全自动化、端到端的红队测试框架，用于评估大型语言模型(LLMs)的安全性。该框架采用多智能体架构和记忆引导的攻击选择机制，能够持续发现和整合新的攻击向量。AutoRedTeamer由红队测试智能体和策略提议智能体组成，前者从高风险类别生成并执行测试用例，后者通过分析最新研究自主发现和实施新攻击。实验表明，AutoRedTeamer在HarmBench基准测试中对Llama-3.1-70B的攻击成功率提高了20%，同时计算成本降低了46%，并能生成与人工策划基准相当多样性的测试用例，为AI系统的安全评估提供了一个全面、可扩展且持续演进的框架。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15754v1",
      "published_date": "2025-03-20 00:13:04 UTC",
      "updated_date": "2025-03-20 00:13:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:33:23.445566"
    },
    {
      "arxiv_id": "2503.15752v1",
      "title": "Using Language Models to Decipher the Motivation Behind Human Behaviors",
      "title_zh": "利用语言模型解读人类行为背后的动机",
      "authors": [
        "Yutong Xie",
        "Qiaozhu Mei",
        "Walter Yuan",
        "Matthew O. Jackson"
      ],
      "abstract": "AI presents a novel tool for deciphering the motivations behind human\nbehaviors. We show that by varying prompts to a large language model, we can\nelicit a full range of human behaviors in a variety of different scenarios in\nterms of classic economic games. Then by analyzing which prompts are needed to\nelicit which behaviors, we can infer (decipher) the motivations behind the\nhuman behaviors. We also show how one can analyze the prompts to reveal\nrelationships between the classic economic games, providing new insight into\nwhat different economic scenarios induce people to think about. We also show\nhow this deciphering process can be used to understand differences in the\nbehavioral tendencies of different populations.",
      "tldr_zh": "该研究利用大语言模型(LLMs)探索人类行为背后的动机。通过设计不同的提示词(prompts)，研究者在经典经济游戏场景中成功诱导出全范围的人类行为，并通过分析提示词与行为之间的关系，推断出行为背后的动机。该方法不仅揭示了不同经济场景如何影响人们的思维方式，还能用于分析不同人群的行为倾向差异，为理解人类行为提供了新的视角。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15752v1",
      "published_date": "2025-03-20 00:07:06 UTC",
      "updated_date": "2025-03-20 00:07:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T07:33:20.496719"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 118,
  "processed_papers_count": 118,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-03-26T07:34:34.427712"
}