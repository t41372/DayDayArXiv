{
  "date": "2024-11-26",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-11-26 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 106 篇论文，主要聚焦于 AI 生成模型、图神经网络、机器人学习和多模态理解等领域，亮点包括高效的 3D 内容生成（如 MARVEL-40M+）和 LLM 在对话与推理中的应用（如 AI2T 和 GrokFormer），以及一些知名学者（如 Yisen Wang 在图后门防御）的工作，这些论文展示了 AI 在实际应用中的潜力。\n\n下面，我挑选并简要讨论了部分重要、话题度和影响大的论文，先从 AI 生成与 LLM 相关的内容入手，再聊图学习和机器人领域。其他较常规或应用性不强的论文（如某些实验优化或小数据集分析）将快速掠过，仅列出标题。\n\n### AI 生成模型与 LLM 应用\n- **MARVEL-40M+: Multi-Level Visual Elaboration for High-Fidelity Text-to-3D Content Creation**  \n  这篇论文引入了一个 4000 万标注的 3D 数据集和多阶段标注管道，使用预训练的视觉语言模型提升文本到 3D 生成的质量。主要贡献是减少了 VLM 的幻觉问题，并在评估中胜过现有数据集，适用于细粒度 3D 重建。\n\n- **Evaluating Generative AI-Enhanced Content: A Conceptual Framework Using Qualitative, Quantitative, and Mixed-Methods Approaches**  \n  作者提出一个框架评估生成式 AI 在科学写作中的性能，使用混合方法（如 BLEU 和主题分析）分析 AI 的语言连贯性和准确性。主要发现是 AI 可量化提升内容质量，但需关注技术准确性和伦理问题。\n\n- **Neural Networks Use Distance Metrics**  \n  这篇简短论文（8 页）提供实证证据，显示 ReLU 和绝对值激活的神经网络更依赖距离度量而非强度。关键发现挑战了传统解释，并提供了代码，支持网络决策过程的理解。\n\n- **AI2T: Building Trustable AI Tutors by Interactively Teaching a Self-Aware Learning Agent**  \n  论文开发了一个交互式 AI 教学系统，通过用户反馈训练智能导师模型。主要贡献是算法 STAND 提升了模型的自知觉，实现高效教学，显著减少了传统编程时间。\n\n- **Can LLMs plan paths in the real world?**  \n  这篇实验性工作测试 LLMs 在真实路径规划中的可靠性，结果显示 LLMs 易出错。作者建议未来聚焦现实检查和更小模型，强调 LLMs 在机器人导航中的局限性。\n\n- **GrokFormer: Graph Fourier Kolmogorov-Arnold Transformers**  \n  论文提出一种新图 Transformer，使用自适应谱滤波器处理图数据。主要发现是它在节点分类任务中优于现有方法，展示了图神经网络的鲁棒性。\n\n- **StableAnimator: High-Quality Identity-Preserving Human Image Animation**  \n  作者设计了一个端到端框架，生成高质量的人像动画视频。关键创新是 Hamilton-Jacobi-Bellman 优化，确保身份一致性，在基准测试中表现出色。\n\n- **SVGDreamer++: Advancing Editability and Diversity in Text-Guided SVG Generation**  \n  这篇工作提升了文本到 SVG 生成的编辑性和多样性，使用分层框架和奖励模型。主要贡献是支持多风格生成，代码已开源。\n\n### 图学习与后门防御\n- **MADE: Graph Backdoor Defense with Masked Unlearning**  \n  Yisen Wang 等作者提出了一种图神经网络后门防御方法，通过掩码机制消除触发器影响。在图分类任务中，显著降低了攻击成功率，同时保持高准确性。\n\n- **GraphSubDetector: Time Series Subsequence Anomaly Detection via Density-Aware Adaptive Graph Neural Network**  \n  论文针对时间序列异常检测，开发了一个自适应图神经网络。主发现是它能有效处理数据噪声，提高检测精度，适用于工业预测。\n\n### 机器人与多模态学习\n- **MALMM: Multi-Agent Large Language Models for Zero-Shot Robotics Manipulation**  \n  作者构建了一个多代理 LLM 框架，实现零样本机器人操作。关键是它能处理长时任务，避免幻觉问题，在 RLBench 上表现突出。\n\n- **What's in the Image? A Deep-Dive into the Vision of Vision Language Models**  \n  这篇分析 VLMs 的视觉处理机制，揭示了注意力模块如何提取图像细节。主贡献是定量评估和实用洞见，支持高效视觉任务。\n\n其他论文如时间序列预测、医疗图像处理和环境建模等（如 Spatio-temporal Causal Learning、Self-supervised Monocular Depth），虽有技术创新，但影响力较小，仅快速提及：它们主要优化了特定领域模型，如使用机器学习提升流速预测或医学图像分割精度，但未带来革命性突破。\n\n总之，今天的论文突出了 AI 模型的优化和实际应用潜力，建议关注 MARVEL-40M+ 和 AI2T 等工作，以推动高效生成和教育创新。更多细节可查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2411.17945v2",
      "title": "MARVEL-40M+: Multi-Level Visual Elaboration for High-Fidelity Text-to-3D Content Creation",
      "title_zh": "翻译失败",
      "authors": [
        "Sankalp Sinha",
        "Mohammad Sadil Khan",
        "Muhammad Usama",
        "Shino Sam",
        "Didier Stricker",
        "Sk Aziz Ali",
        "Muhammad Zeshan Afzal"
      ],
      "abstract": "Generating high-fidelity 3D content from text prompts remains a significant\nchallenge in computer vision due to the limited size, diversity, and annotation\ndepth of the existing datasets. To address this, we introduce MARVEL-40M+, an\nextensive dataset with 40 million text annotations for over 8.9 million 3D\nassets aggregated from seven major 3D datasets. Our contribution is a novel\nmulti-stage annotation pipeline that integrates open-source pretrained\nmulti-view VLMs and LLMs to automatically produce multi-level descriptions,\nranging from detailed (150-200 words) to concise semantic tags (10-20 words).\nThis structure supports both fine-grained 3D reconstruction and rapid\nprototyping. Furthermore, we incorporate human metadata from source datasets\ninto our annotation pipeline to add domain-specific information in our\nannotation and reduce VLM hallucinations. Additionally, we develop MARVEL-FX3D,\na two-stage text-to-3D pipeline. We fine-tune Stable Diffusion with our\nannotations and use a pretrained image-to-3D network to generate 3D textured\nmeshes within 15s. Extensive evaluations show that MARVEL-40M+ significantly\noutperforms existing datasets in annotation quality and linguistic diversity,\nachieving win rates of 72.41% by GPT-4 and 73.40% by human evaluators. Project\npage is available at https://sankalpsinha-cmos.github.io/MARVEL/.",
      "tldr_zh": "本文提出 MARVEL-40M+ 数据集，包含 4000 万文本注释和 890 万 3D 资产，旨在解决现有数据集规模有限和多样性不足的问题，支持高保真文本到 3D 内容生成。研究采用多阶段注释管道，结合开源预训练的多视图 VLM 和 LLM 自动生成多级描述（从 150-200 字详细描述到 10-20 字语义标签），并整合人类元数据以减少 VLM 幻觉和添加领域特定信息。同时，开发了 MARVEL-FX3D 两阶段管道，通过微调 Stable Diffusion 和预训练 image-to-3D 网络，在 15 秒内生成 3D 纹理网格。评估结果显示，MARVEL-40M+ 在注释质量和语言多样性上优于现有数据集，GPT-4 和人类评估者胜率分别为 72.41% 和 73.40%。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17945v2",
      "published_date": "2024-11-26 23:39:43 UTC",
      "updated_date": "2025-03-26 11:06:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:29:10.780159"
    },
    {
      "arxiv_id": "2411.17943v1",
      "title": "Evaluating Generative AI-Enhanced Content: A Conceptual Framework Using Qualitative, Quantitative, and Mixed-Methods Approaches",
      "title_zh": "评估 Generative AI 增强内容：一个使用定性、定量和混合方法方法的概念框架",
      "authors": [
        "Saman Sarraf"
      ],
      "abstract": "Generative AI (GenAI) has revolutionized content generation, offering\ntransformative capabilities for improving language coherence, readability, and\noverall quality. This manuscript explores the application of qualitative,\nquantitative, and mixed-methods research approaches to evaluate the performance\nof GenAI models in enhancing scientific writing. Using a hypothetical use case\ninvolving a collaborative medical imaging manuscript, we demonstrate how each\nmethod provides unique insights into the impact of GenAI. Qualitative methods\ngather in-depth feedback from expert reviewers, analyzing their responses using\nthematic analysis tools to capture nuanced improvements and identify\nlimitations. Quantitative approaches employ automated metrics such as BLEU,\nROUGE, and readability scores, as well as user surveys, to objectively measure\nimprovements in coherence, fluency, and structure. Mixed-methods research\nintegrates these strengths, combining statistical evaluations with detailed\nqualitative insights to provide a comprehensive assessment. These research\nmethods enable quantifying improvement levels in GenAI-generated content,\naddressing critical aspects of linguistic quality and technical accuracy. They\nalso offer a robust framework for benchmarking GenAI tools against traditional\nediting processes, ensuring the reliability and effectiveness of these\ntechnologies. By leveraging these methodologies, researchers can evaluate the\nperformance boost driven by GenAI, refine its applications, and guide its\nresponsible adoption in high-stakes domains like healthcare and scientific\nresearch. This work underscores the importance of rigorous evaluation\nframeworks for advancing trust and innovation in GenAI.",
      "tldr_zh": "这篇论文提出一个概念框架，用于评估 Generative AI (GenAI) 增强内容的表现，结合 qualitative methods、quantitative approaches 和 mixed-methods research 来分析 GenAI 在提升科学写作（如语言连贯性和可读性）方面的影响。  \n通过一个假设的协作医学成像手稿案例，定性方法利用主题分析工具收集专家反馈以捕捉细微改进和限制，而定量方法则采用 BLEU、ROUGE 和可读性分数等指标进行客观测量。  \n混合方法整合这些优势，提供全面评估，帮助基准测试 GenAI 与传统编辑过程，并指导其在高风险领域如医疗和科学研究中的负责任采用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17943v1",
      "published_date": "2024-11-26 23:34:07 UTC",
      "updated_date": "2024-11-26 23:34:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:29:22.755459"
    },
    {
      "arxiv_id": "2411.17937v1",
      "title": "Spatio-temporal Causal Learning for Streamflow Forecasting",
      "title_zh": "用于径流预报的时空因果学习",
      "authors": [
        "Shu Wan",
        "Reepal Shah",
        "Qi Deng",
        "John Sabo",
        "Huan Liu",
        "K. Selçuk"
      ],
      "abstract": "Streamflow plays an essential role in the sustainable planning and management\nof national water resources. Traditional hydrologic modeling approaches\nsimulate streamflow by establishing connections across multiple physical\nprocesses, such as rainfall and runoff. These data, inherently connected both\nspatially and temporally, possess intrinsic causal relations that can be\nleveraged for robust and accurate forecasting. Recently, spatio-temporal graph\nneural networks (STGNNs) have been adopted, excelling in various domains, such\nas urban traffic management, weather forecasting, and pandemic control, and\nthey also promise advances in streamflow management. However, learning causal\nrelationships directly from vast observational data is theoretically and\ncomputationally challenging. In this study, we employ a river flow graph as\nprior knowledge to facilitate the learning of the causal structure and then use\nthe learned causal graph to predict streamflow at targeted sites. The proposed\nmodel, Causal Streamflow Forecasting (CSF) is tested in a real-world study in\nthe Brazos River basin in Texas. Our results demonstrate that our method\noutperforms regular spatio-temporal graph neural networks and achieves higher\ncomputational efficiency compared to traditional simulation methods. By\neffectively integrating river flow graphs with STGNNs, this research offers a\nnovel approach to streamflow prediction, showcasing the potential of combining\nadvanced neural network techniques with domain-specific knowledge for enhanced\nperformance in hydrologic modeling.",
      "tldr_zh": "本研究探讨了利用空间-时间因果学习来预测流量的方法，以提升水资源管理的准确性和鲁棒性。作者提出 Causal Streamflow Forecasting (CSF) 模型，通过河流流量图作为先验知识辅助学习因果结构，并结合 spatio-temporal graph neural networks (STGNNs) 来预测目标地点的流量。实验在德克萨斯 Brazos 河盆地进行，结果显示 CSF 模型优于常规 STGNNs，并在计算效率上超越传统模拟方法，展示了领域知识与神经网络技术融合的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "To be published at IEEE Big Data 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.17937v1",
      "published_date": "2024-11-26 23:19:56 UTC",
      "updated_date": "2024-11-26 23:19:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:31:26.729821"
    },
    {
      "arxiv_id": "2411.17932v1",
      "title": "Neural Networks Use Distance Metrics",
      "title_zh": "神经网络使用距离度量",
      "authors": [
        "Alan Oursland"
      ],
      "abstract": "We present empirical evidence that neural networks with ReLU and Absolute\nValue activations learn distance-based representations. We independently\nmanipulate both distance and intensity properties of internal activations in\ntrained models, finding that both architectures are highly sensitive to small\ndistance-based perturbations while maintaining robust performance under large\nintensity-based perturbations. These findings challenge the prevailing\nintensity-based interpretation of neural network activations and offer new\ninsights into their learning and decision-making processes.",
      "tldr_zh": "本研究通过实证证据证明，使用 ReLU 和 Absolute Value 激活函数的 Neural Networks 会学习基于距离的表示。研究者独立操纵训练模型中激活的距离和强度属性，发现这些网络对微小的距离-based 扰动高度敏感，而在大型强度-based 扰动下仍保持鲁棒性能。这些发现挑战了传统的强度-based 解释，为理解 Neural Networks 的学习和决策过程提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages excluding references and appendix. 12 pages total. 3 figures.\n  The code for the experiments in this paper is available at\n  https://github.com/alanoursland/neural_networks_use_distance_metrics",
      "pdf_url": "http://arxiv.org/pdf/2411.17932v1",
      "published_date": "2024-11-26 23:04:56 UTC",
      "updated_date": "2024-11-26 23:04:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:29:44.479846"
    },
    {
      "arxiv_id": "2411.17931v3",
      "title": "Combining Threat Intelligence with IoT Scanning to Predict Cyber Attack",
      "title_zh": "将威胁情报与 IoT 扫描相结合以预测网络攻击",
      "authors": [
        "Jubin Abhishek Soni"
      ],
      "abstract": "While the Web has become a global platform for communication; malicious\nactors, including hackers and hacktivist groups, often disseminate ideological\ncontent and coordinate activities through the \"Dark Web\" an obscure counterpart\nof the conventional web. Presently, challenges such as information overload and\nthe fragmented nature of cyber threat data impede comprehensive profiling of\nthese actors, thereby limiting the efficacy of predictive analyses of their\nonline activities. Concurrently, the proliferation of internet-connected\ndevices has surpassed the global human population, with this disparity\nprojected to widen as the Internet of Things (IoT) expands. Technical\ncommunities are actively advancing IoT-related research to address its growing\nsocietal integration. This paper proposes a novel predictive threat\nintelligence framework designed to systematically collect, analyze, and\nvisualize Dark Web data to identify malicious websites and correlate this\ninformation with potential IoT vulnerabilities. The methodology integrates\nautomated data harvesting, analytical techniques, and visual mapping tools,\nwhile also examining vulnerabilities in IoT devices to assess exploitability.\nBy bridging gaps in cybersecurity research, this study aims to enhance\npredictive threat modeling and inform policy development, thereby contributing\nto intelligence research initiatives focused on mitigating cyber risks in an\nincreasingly interconnected digital ecosystem.",
      "tldr_zh": "这篇论文提出一个新型预测威胁情报框架，将Threat Intelligence与IoT扫描相结合，旨在通过系统收集、分析和可视化Dark Web数据来识别恶意网站，并将其与潜在IoT漏洞关联。框架采用自动化数据采集、分析技术和可视化工具，评估IoT设备的可利用性，以克服信息过载和数据碎片化等挑战。研究结果有助于提升预测威胁建模、支持政策制定，并缓解日益互联的数字生态系统中的网络风险。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CY",
        "cs.NI"
      ],
      "primary_category": "cs.CR",
      "comment": "17 pages, 6 figures, 2 tables. This manuscript has been submitted to\n  Springer for review (Manuscript ID: PDSE-D-24-00163) and is under\n  consideration. It has not yet been peer-reviewed or published. Researchers\n  are welcome to read and build upon this work; please cite it appropriately.\n  For questions or clarifications, feel free to contact me",
      "pdf_url": "http://arxiv.org/pdf/2411.17931v3",
      "published_date": "2024-11-26 23:00:51 UTC",
      "updated_date": "2025-04-07 06:33:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:29:56.416957"
    },
    {
      "arxiv_id": "2411.18648v2",
      "title": "MADE: Graph Backdoor Defense with Masked Unlearning",
      "title_zh": "翻译失败",
      "authors": [
        "Xiao Lin",
        "Mingjie Li",
        "Yisen Wang"
      ],
      "abstract": "Graph Neural Networks (GNNs) have garnered significant attention from\nresearchers due to their outstanding performance in handling graph-related\ntasks, such as social network analysis, protein design, and so on. Despite\ntheir widespread application, recent research has demonstrated that GNNs are\nvulnerable to backdoor attacks, implemented by injecting triggers into the\ntraining datasets. Trained on the poisoned data, GNNs will predict target\nlabels when attaching trigger patterns to inputs. This vulnerability poses\nsignificant security risks for applications of GNNs in sensitive domains, such\nas drug discovery. While there has been extensive research into backdoor\ndefenses for images, strategies to safeguard GNNs against such attacks remain\nunderdeveloped. Furthermore, we point out that conventional backdoor defense\nmethods designed for images cannot work well when directly implemented on graph\ndata. In this paper, we first analyze the key difference between image backdoor\nand graph backdoor attacks. Then we tackle the graph defense problem by\npresenting a novel approach called MADE, which devises an adversarial mask\ngeneration mechanism that selectively preserves clean sub-graphs and further\nleverages masks on edge weights to eliminate the influence of triggers\neffectively. Extensive experiments across various graph classification tasks\ndemonstrate the effectiveness of MADE in significantly reducing the attack\nsuccess rate (ASR) while maintaining a high classification accuracy.",
      "tldr_zh": "该研究探讨了图神经网络(GNNs)在面对后门攻击时的脆弱性，这些攻击通过在训练数据中注入触发器，使模型在特定输入时预测目标标签，从而威胁敏感领域如药物发现的安全。论文分析了图后门攻击与图像后门攻击的关键差异，并提出了一种新型防御方法MADE(Masked Unlearning)，该方法利用对抗性掩码生成机制选择性地保留干净子图，并通过掩码边权重来有效消除触发器的影响。实验结果显示，MADE在多种图分类任务中显著降低了攻击成功率(ASR)，同时保持了高分类准确率。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG",
        "E.1"
      ],
      "primary_category": "cs.CR",
      "comment": "15 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.18648v2",
      "published_date": "2024-11-26 22:50:53 UTC",
      "updated_date": "2024-12-31 02:11:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:30:09.550931"
    },
    {
      "arxiv_id": "2412.08654v1",
      "title": "A Behavior Tree-inspired programming language for autonomous agents",
      "title_zh": "一种受行为树启发的自主代理编程语言",
      "authors": [
        "Oliver Biggar",
        "Iman Shames"
      ],
      "abstract": "We propose a design for a functional programming language for autonomous\nagents, built off the ideas and motivations of Behavior Trees (BTs). BTs are a\npopular model for designing agents behavior in robotics and AI. However, as\ntheir growth has increased dramatically, the simple model of BTs has come to be\nlimiting. There is a growing push to increase the functionality of BTs, with\nthe end goal of BTs evolving into a programming language in their own right,\ncentred around the defining BT properties of modularity and reactiveness.\n  In this paper, we examine how the BT model must be extended in order to grow\ninto such a language. We identify some fundamental problems which must be\nsolved: implementing `reactive' selection, 'monitoring' safety-critical\nconditions, and passing data between actions. We provide a variety of small\nexamples which demonstrate that these problems are complex, and that current BT\napproaches do not handle them in a manner consistent with modularity. We\ninstead provide a simple set of modular programming primitives for handling\nthese use cases, and show how they can be combined to build complex programs.\nWe present a full specification for our BT-inspired language, and give an\nimplementation in the functional programming language Haskell. Finally, we\ndemonstrate our language by translating a large and complex BT into a simple,\nunambiguous program.",
      "tldr_zh": "这篇论文提出了一种受 Behavior Trees (BTs) 启发的功能性编程语言设计，用于自治代理，以解决 BTs 在模块性和反应性方面的局限性。论文识别了关键问题，包括实现 'reactive' 选择、'monitoring' 安全关键条件以及在动作之间传递数据，并提供了模块化编程原语来处理这些问题。最终，作者给出了语言的完整规范，并用 Haskell 实现了它，通过翻译一个复杂 BT 展示了其构建简单、无歧义程序的能力。",
      "categories": [
        "cs.PL",
        "cs.AI",
        "cs.RO",
        "cs.SE"
      ],
      "primary_category": "cs.PL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.08654v1",
      "published_date": "2024-11-26 22:47:06 UTC",
      "updated_date": "2024-11-26 22:47:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:30:21.415435"
    },
    {
      "arxiv_id": "2411.17924v1",
      "title": "AI2T: Building Trustable AI Tutors by Interactively Teaching a Self-Aware Learning Agent",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Weitekamp",
        "Erik Harpstead",
        "Kenneth Koedinger"
      ],
      "abstract": "AI2T is an interactively teachable AI for authoring intelligent tutoring\nsystems (ITSs). Authors tutor AI2T by providing a few step-by-step solutions\nand then grading AI2T's own problem-solving attempts. From just 20-30 minutes\nof interactive training, AI2T can induce robust rules for step-by-step solution\ntracking (i.e., model-tracing). As AI2T learns it can accurately estimate its\ncertainty of performing correctly on unseen problem steps using STAND: a\nself-aware precondition learning algorithm that outperforms state-of-the-art\nmethods like XGBoost. Our user study shows that authors can use STAND's\ncertainty heuristic to estimate when AI2T has been trained on enough diverse\nproblems to induce correct and complete model-tracing programs. AI2T-induced\nprograms are more reliable than hallucination-prone LLMs and prior\nauthoring-by-tutoring approaches. With its self-aware induction of hierarchical\nrules, AI2T offers a path toward trustable data-efficient authoring-by-tutoring\nfor complex ITSs that normally require as many as 200-300 hours of programming\nper hour of instruction.",
      "tldr_zh": "该研究提出 AI2T，一种可交互式教学的 AI 系统，用于高效构建可信赖的智能辅导系统 (ITS)。作者通过提供少量逐步解决方案并对 AI2T 的问题解决尝试进行评分，仅需 20-30 分钟即可训练 AI2T 推导出稳健的模型跟踪规则。AI2T 采用自感知算法 STAND 来估计其在未见问题上的准确性，该算法优于 XGBoost，并经用户研究证实，可帮助作者判断训练充分性，使 AI2T 生成的程序比 LLMs 和传统方法更可靠，从而将复杂 ITS 的开发时间从 200-300 小时减少至数据高效的交互式过程。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG",
        "I.2.6; I.2.2"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17924v1",
      "published_date": "2024-11-26 22:39:11 UTC",
      "updated_date": "2024-11-26 22:39:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:30:35.097559"
    },
    {
      "arxiv_id": "2411.17914v1",
      "title": "Enhancing Project Performance Forecasting using Machine Learning Techniques",
      "title_zh": "使用机器学习技术增强项目绩效预测",
      "authors": [
        "Soheila Sadeghi"
      ],
      "abstract": "Accurate forecasting of project performance metrics is crucial for\nsuccessfully managing and delivering urban road reconstruction projects.\nTraditional methods often rely on static baseline plans and fail to consider\nthe dynamic nature of project progress and external factors. This research\nproposes a machine learning-based approach to forecast project performance\nmetrics, such as cost variance and earned value, for each Work Breakdown\nStructure (WBS) category in an urban road reconstruction project. The proposed\nmodel utilizes time series forecasting techniques, including Autoregressive\nIntegrated Moving Average (ARIMA) and Long Short-Term Memory (LSTM) networks,\nto predict future performance based on historical data and project progress.\nThe model also incorporates external factors, such as weather patterns and\nresource availability, as features to enhance the accuracy of forecasts. By\napplying the predictive power of machine learning, the performance forecasting\nmodel enables proactive identification of potential deviations from the\nbaseline plan, which allows project managers to take timely corrective actions.\nThe research aims to validate the effectiveness of the proposed approach using\na case study of an urban road reconstruction project, comparing the model's\nforecasts with actual project performance data. The findings of this research\ncontribute to the advancement of project management practices in the\nconstruction industry, offering a data-driven solution for improving project\nperformance monitoring and control.",
      "tldr_zh": "本研究针对城市道路重建项目的性能预测问题，提出了一种基于机器学习技术的解决方案，以克服传统静态方法忽略项目动态和外部因素的局限性。该模型利用时间序列预测技术，包括Autoregressive Integrated Moving Average (ARIMA)和Long Short-Term Memory (LSTM)网络，结合历史数据、项目进度以及外部因素如天气模式和资源可用性，来预测Work Breakdown Structure (WBS)类别的性能指标，如成本差异和earned value。通过这种方法，项目经理能够及早识别潜在偏差并采取纠正措施。研究通过一个城市道路重建项目的案例研究验证了模型的有效性，为建筑业项目管理提供了数据驱动的改进路径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY",
        "stat.AP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17914v1",
      "published_date": "2024-11-26 22:09:55 UTC",
      "updated_date": "2024-11-26 22:09:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:30:44.653546"
    },
    {
      "arxiv_id": "2411.17912v2",
      "title": "Can LLMs plan paths in the real world?",
      "title_zh": "翻译失败",
      "authors": [
        "Wanyi Chen",
        "Meng-Wen Su",
        "Nafisa Mehjabin",
        "Mary L. Cummings"
      ],
      "abstract": "As large language models (LLMs) increasingly integrate into vehicle\nnavigation systems, understanding their path-planning capability is crucial. We\ntested three LLMs through six real-world path-planning scenarios in various\nsettings and with various difficulties. Our experiments showed that all LLMs\nmade numerous errors in all scenarios, revealing that they are unreliable path\nplanners. We suggest that future work focus on implementing mechanisms for\nreality checks, enhancing model transparency, and developing smaller models.",
      "tldr_zh": "这篇论文评估了大型语言模型（LLMs）在真实世界路径规划中的能力，通过测试三个 LLMs 在六个不同场景和难度下的表现。结果显示，所有 LLMs 在所有场景中都犯了许多错误，表明它们作为路径规划器不可靠。作者建议未来研究应着重于实施现实检查机制、提升模型透明度以及开发更小的模型。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17912v2",
      "published_date": "2024-11-26 22:06:39 UTC",
      "updated_date": "2024-12-02 02:42:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:30:56.687999"
    },
    {
      "arxiv_id": "2411.17897v1",
      "title": "Automating grapevine LAI features estimation with UAV imagery and machine learning",
      "title_zh": "基于无人机图像和机器学习的葡萄藤",
      "authors": [
        "Muhammad Waseem Akram",
        "Marco Vannucci",
        "Giorgio Buttazzo",
        "Valentina Colla",
        "Stefano Roccella",
        "Andrea Vannini",
        "Giovanni Caruso",
        "Simone Nesi",
        "Alessandra Francini",
        "Luca Sebastiani"
      ],
      "abstract": "The leaf area index determines crop health and growth. Traditional methods\nfor calculating it are time-consuming, destructive, costly, and limited to a\nscale. In this study, we automate the index estimation method using drone image\ndata of grapevine plants and a machine learning model. Traditional feature\nextraction and deep learning methods are used to obtain helpful information\nfrom the data and enhance the performance of the different machine learning\nmodels employed for the leaf area index prediction. The results showed that\ndeep learning based feature extraction is more effective than traditional\nmethods. The new approach is a significant improvement over old methods,\noffering a faster, non-destructive, and cost-effective leaf area index\ncalculation, which enhances precision agriculture practices.",
      "tldr_zh": "这篇论文介绍了使用无人机（UAV）图像和机器学习自动估算葡萄藤叶面积指数（LAI）的方法，以解决传统计算方式耗时、破坏性和成本高的局限性。研究结合传统特征提取和深度学习技术，从UAV图像数据中提取关键信息，提升机器学习模型的预测性能。结果显示，深度学习方法比传统特征提取更有效，新方法显著提高了LAI计算的速度和准确性，为精准农业实践提供了更高效、非破坏性的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.ET",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted in 2024 IEEE INTERNATIONAL WORKSHOP ON Metrology for\n  Agriculture and Forestry",
      "pdf_url": "http://arxiv.org/pdf/2411.17897v1",
      "published_date": "2024-11-26 21:24:27 UTC",
      "updated_date": "2024-11-26 21:24:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:31:37.948764"
    },
    {
      "arxiv_id": "2411.17891v1",
      "title": "HOPPR Medical-Grade Platform for Medical Imaging AI",
      "title_zh": "翻译失败",
      "authors": [
        "Kalina P. Slavkova",
        "Melanie Traughber",
        "Oliver Chen",
        "Robert Bakos",
        "Shayna Goldstein",
        "Dan Harms",
        "Bradley J. Erickson",
        "Khan M. Siddiqui"
      ],
      "abstract": "Technological advances in artificial intelligence (AI) have enabled the\ndevelopment of large vision language models (LVLMs) that are trained on\nmillions of paired image and text samples. Subsequent research efforts have\ndemonstrated great potential of LVLMs to achieve high performance in medical\nimaging use cases (e.g., radiology report generation), but there remain\nbarriers that hinder the ability to deploy these solutions broadly. These\ninclude the cost of extensive computational requirements for developing large\nscale models, expertise in the development of sophisticated AI models, and the\ndifficulty in accessing substantially large, high-quality datasets that\nadequately represent the population in which the LVLM solution is to be\ndeployed. The HOPPR Medical-Grade Platform addresses these barriers by\nproviding powerful computational infrastructure, a suite of foundation models\non top of which developers can fine-tune for their specific use cases, and a\nrobust quality management system that sets a standard for evaluating fine-tuned\nmodels for deployment in clinical settings. The HOPPR Platform has access to\nmillions of imaging studies and text reports sourced from hundreds of imaging\ncenters from diverse populations to pretrain foundation models and enable use\ncase-specific cohorts for fine-tuning. All data are deidentified and securely\nstored for HIPAA compliance. Additionally, developers can securely host models\non the HOPPR platform and access them via an API to make inferences using these\nmodels within established clinical workflows. With the Medical-Grade Platform,\nHOPPR's mission is to expedite the deployment of LVLM solutions for medical\nimaging and ultimately optimize radiologist's workflows and meet the growing\ndemands of the field.",
      "tldr_zh": "该论文介绍了 HOPPR Medical-Grade Platform，这是一个医疗级平台，旨在解决大型视觉语言模型 (LVLMs) 在医疗成像 AI 部署中的障碍，包括计算成本高、开发专业知识不足以及高质量数据集的获取困难。平台提供强大的计算基础设施、一套可供开发者微调的基础模型，以及一个稳健的质量管理系统，以评估和部署临床模型。HOPPR 通过访问数百万的成像研究和文本报告，并确保 HIPAA 合规和数据安全，允许开发者通过 API 安全托管和访问模型，最终加速 LVLM 解决方案的部署，并优化放射科医生的临床工作流程。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.17891v1",
      "published_date": "2024-11-26 21:21:45 UTC",
      "updated_date": "2024-11-26 21:21:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:31:49.700236"
    },
    {
      "arxiv_id": "2411.17863v1",
      "title": "LongKey: Keyphrase Extraction for Long Documents",
      "title_zh": "LongKey：长文档关键短语提取",
      "authors": [
        "Jeovane Honorio Alves",
        "Radu State",
        "Cinthia Obladen de Almendra Freitas",
        "Jean Paul Barddal"
      ],
      "abstract": "In an era of information overload, manually annotating the vast and growing\ncorpus of documents and scholarly papers is increasingly impractical. Automated\nkeyphrase extraction addresses this challenge by identifying representative\nterms within texts. However, most existing methods focus on short documents (up\nto 512 tokens), leaving a gap in processing long-context documents. In this\npaper, we introduce LongKey, a novel framework for extracting keyphrases from\nlengthy documents, which uses an encoder-based language model to capture\nextended text intricacies. LongKey uses a max-pooling embedder to enhance\nkeyphrase candidate representation. Validated on the comprehensive LDKP\ndatasets and six diverse, unseen datasets, LongKey consistently outperforms\nexisting unsupervised and language model-based keyphrase extraction methods.\nOur findings demonstrate LongKey's versatility and superior performance,\nmarking an advancement in keyphrase extraction for varied text lengths and\ndomains.",
      "tldr_zh": "在信息过载时代，手动标注文档变得不切实际，本文引入 LongKey，一种新型框架，专门针对长文档（超过 512 tokens）进行 keyphrase extraction，使用 encoder-based language model 捕获文本复杂性，并通过 max-pooling embedder 增强关键短语候选的表示。LongKey 在 LDKP 数据集以及六个多样化的未见数据集上，表现优于现有无监督和基于语言模型的方法，展示了其一致的性能提升。该框架的多功能性推进了 keyphrase extraction 在不同文本长度和领域的应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted for presentation at the 2024 IEEE International Conference\n  on Big Data (IEEE BigData 2024). Code available at\n  https://github.com/jeohalves/longkey",
      "pdf_url": "http://arxiv.org/pdf/2411.17863v1",
      "published_date": "2024-11-26 20:26:47 UTC",
      "updated_date": "2024-11-26 20:26:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:32:02.250998"
    },
    {
      "arxiv_id": "2411.17861v3",
      "title": "Accelerating Proximal Policy Optimization Learning Using Task Prediction for Solving Environments with Delayed Rewards",
      "title_zh": "利用任务预测加速近端策略优化学习以解决延迟奖励环境",
      "authors": [
        "Ahmad Ahmad",
        "Mehdi Kermanshah",
        "Kevin Leahy",
        "Zachary Serlin",
        "Ho Chit Siu",
        "Makai Mann",
        "Cristian-Ioan Vasile",
        "Roberto Tron",
        "Calin Belta"
      ],
      "abstract": "In this paper, we tackle the challenging problem of delayed rewards in\nreinforcement learning (RL). While Proximal Policy Optimization (PPO) has\nemerged as a leading Policy Gradient method, its performance can degrade under\ndelayed rewards. We introduce two key enhancements to PPO: a hybrid policy\narchitecture that combines an offline policy (trained on expert demonstrations)\nwith an online PPO policy, and a reward shaping mechanism using Time Window\nTemporal Logic (TWTL). The hybrid architecture leverages offline data\nthroughout training while maintaining PPO's theoretical guarantees. Building on\nthe monotonic improvement framework of Trust Region Policy Optimization (TRPO),\nwe prove that our approach ensures improvement over both the offline policy and\nprevious iterations, with a bounded performance gap of\n$(2\\varsigma\\gamma\\alpha^2)/(1-\\gamma)^2$, where $\\alpha$ is the mixing\nparameter, $\\gamma$ is the discount factor, and $\\varsigma$ bounds the expected\nadvantage. Additionally, we prove that our TWTL-based reward shaping preserves\nthe optimal policy of the original problem. TWTL enables formal translation of\ntemporal objectives into immediate feedback signals that guide learning. We\ndemonstrate the effectiveness of our approach through extensive experiments on\nan inverted pendulum and a lunar lander environments, showing improvements in\nboth learning speed and final performance compared to standard PPO and\noffline-only approaches.",
      "tldr_zh": "本研究针对强化学习（RL）中延迟奖励问题，提出了一种增强Proximal Policy Optimization (PPO)的方法，以加速学习过程。该方法包括混合策略架构，将基于专家演示的离线策略与在线PPO策略结合，并使用Time Window Temporal Logic (TWTL)进行奖励整形，确保及时反馈并保留原问题的最优策略。理论证明显示，该方法在TRPO的单调改进框架下，提供有界的性能提升，差距为$(2\\varsigma\\gamma\\alpha^2)/(1-\\gamma)^2$。实验在倒立摆和月球着陆器环境中验证了其有效性，相比标准PPO和纯离线方法，显著提高了学习速度和最终性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17861v3",
      "published_date": "2024-11-26 20:22:31 UTC",
      "updated_date": "2024-12-05 02:30:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:32:13.490232"
    },
    {
      "arxiv_id": "2411.17855v2",
      "title": "\"Give me the code\" -- Log Analysis of First-Year CS Students' Interactions With GPT",
      "title_zh": "翻译失败",
      "authors": [
        "Pedro Alves",
        "Bruno Pereira Cipriano"
      ],
      "abstract": "The impact of Large Language Models (LLMs) like GPT-3, GPT-4, and Bard in\ncomputer science (CS) education is expected to be profound. Students now have\nthe power to generate code solutions for a wide array of programming\nassignments. For first-year students, this may be particularly problematic\nsince the foundational skills are still in development and an over-reliance on\ngenerative AI tools can hinder their ability to grasp essential programming\nconcepts. This paper analyzes the prompts used by 69 freshmen undergraduate\nstudents to solve a certain programming problem within a project assignment,\nwithout giving them prior prompt training. We also present the rules of the\nexercise that motivated the prompts, designed to foster critical thinking\nskills during the interaction. Despite using unsophisticated prompting\ntechniques, our findings suggest that the majority of students successfully\nleveraged GPT, incorporating the suggested solutions into their projects.\nAdditionally, half of the students demonstrated the ability to exercise\njudgment in selecting from multiple GPT-generated solutions, showcasing the\ndevelopment of their critical thinking skills in evaluating AI-generated code.",
      "tldr_zh": "这篇论文研究了大型语言模型(LLMs)如GPT对大一计算机科学学生的影响，重点分析69名学生在未接受提示训练的情况下，使用GPT解决特定编程问题的提示日志。研究设计旨在通过规则鼓励学生培养批判性思维，尽管他们采用的提示技术较为简单。结果显示，大多数学生成功利用GPT生成并整合代码解决方案，同时约半数学生展示了判断和选择多个AI生成方案的能力，表明其批判性思维得到发展。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.ET",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "This is the author's version of the work. It is posted here for your\n  personal use. Not for redistribution",
      "pdf_url": "http://arxiv.org/pdf/2411.17855v2",
      "published_date": "2024-11-26 20:11:46 UTC",
      "updated_date": "2024-12-01 19:02:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:32:25.074888"
    },
    {
      "arxiv_id": "2411.17847v1",
      "title": "SoftmAP: Software-Hardware Co-design for Integer-Only Softmax on Associative Processors",
      "title_zh": "翻译失败",
      "authors": [
        "Mariam Rakka",
        "Jinhao Li",
        "Guohao Dai",
        "Ahmed Eltawil",
        "Mohammed E. Fouda",
        "Fadi Kurdahi"
      ],
      "abstract": "Recent research efforts focus on reducing the computational and memory\noverheads of Large Language Models (LLMs) to make them feasible on\nresource-constrained devices. Despite advancements in compression techniques,\nnon-linear operators like Softmax and Layernorm remain bottlenecks due to their\nsensitivity to quantization. We propose SoftmAP, a software-hardware co-design\nmethodology that implements an integer-only low-precision Softmax using\nIn-Memory Compute (IMC) hardware. Our method achieves up to three orders of\nmagnitude improvement in the energy-delay product compared to A100 and RTX3090\nGPUs, making LLMs more deployable without compromising performance.",
      "tldr_zh": "该研究针对 Large Language Models (LLMs) 的计算和内存开销问题，提出 SoftmAP，一种软件-硬件联合设计方法，用于在 Associative Processors 上实现整数-only 的 Softmax 操作，以解决非线性操作（如 Softmax）对量化的敏感性。SoftmAP 利用 In-Memory Compute (IMC) 硬件，显著降低了能量-延迟乘积，与 A100 和 RTX3090 GPUs 相比改善三个数量级。实验结果表明，该方法使 LLMs 在资源受限设备上更易部署，同时保持性能不变。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "Accepted in DATE 2025",
      "pdf_url": "http://arxiv.org/pdf/2411.17847v1",
      "published_date": "2024-11-26 20:00:54 UTC",
      "updated_date": "2024-11-26 20:00:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:33:47.920617"
    },
    {
      "arxiv_id": "2411.17840v1",
      "title": "Basic Research, Lethal Effects: Military AI Research Funding as Enlistment",
      "title_zh": "翻译失败",
      "authors": [
        "David Gray Widder",
        "Sireesh Gururaja",
        "Lucy Suchman"
      ],
      "abstract": "In the context of unprecedented U.S. Department of Defense (DoD) budgets,\nthis paper examines the recent history of DoD funding for academic research in\nalgorithmically based warfighting. We draw from a corpus of DoD grant\nsolicitations from 2007 to 2023, focusing on those addressed to researchers in\nthe field of artificial intelligence (AI). Considering the implications of DoD\nfunding for academic research, the paper proceeds through three analytic\nsections. In the first, we offer a critical examination of the distinction\nbetween basic and applied research, showing how funding calls framed as basic\nresearch nonetheless enlist researchers in a war fighting agenda. In the\nsecond, we offer a diachronic analysis of the corpus, showing how a 'one small\nproblem' caveat, in which affirmation of progress in military technologies is\nqualified by acknowledgement of outstanding problems, becomes justification for\nadditional investments in research. We close with an analysis of DoD\naspirations based on a subset of Defense Advanced Research Projects Agency\n(DARPA) grant solicitations for the use of AI in battlefield applications.\nTaken together, we argue that grant solicitations work as a vehicle for the\nmutual enlistment of DoD funding agencies and the academic AI research\ncommunity in setting research agendas. The trope of basic research in this\ncontext offers shelter from significant moral questions that military\napplications of one's research would raise, by obscuring the connections that\nimplicate researchers in U.S. militarism.",
      "tldr_zh": "这篇论文考察了美国国防部（DoD）从 2007 到 2023 年对算法战争相关人工智能（AI）学术研究的资助历史，基于资助申请语料库进行分析。作者批判性地审视了基本研究与应用研究的界限，揭示这些被框架为基本研究的资助实际上在招募研究者参与战争议程。论文通过历时分析（diachronic analysis）显示，“一个小型问题”的警告常被用作理由来推动更多军事技术投资，并在对 Defense Advanced Research Projects Agency (DARPA) 资助的子集分析中，论证了 AI 在战场应用的野心。总体而言，该研究强调资助申请机制促进了 DoD 和学术 AI 社区的相互招募，同时通过基本研究的说辞回避了研究者对美国军事主义的道德责任。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "22 pages, 9945 words",
      "pdf_url": "http://arxiv.org/pdf/2411.17840v1",
      "published_date": "2024-11-26 19:29:27 UTC",
      "updated_date": "2024-11-26 19:29:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:32:50.761288"
    },
    {
      "arxiv_id": "2411.17832v2",
      "title": "SVGDreamer++: Advancing Editability and Diversity in Text-Guided SVG Generation",
      "title_zh": "SVGDreamer++：提升文本引导 SVG 生成中的可编辑性和多样性",
      "authors": [
        "Ximing Xing",
        "Qian Yu",
        "Chuang Wang",
        "Haitao Zhou",
        "Jing Zhang",
        "Dong Xu"
      ],
      "abstract": "Recently, text-guided scalable vector graphics (SVG) synthesis has\ndemonstrated significant potential in domains such as iconography and\nsketching. However, SVGs generated from existing Text-to-SVG methods often lack\neditability and exhibit deficiencies in visual quality and diversity. In this\npaper, we propose a novel text-guided vector graphics synthesis method to\naddress these limitations. To enhance the editability of output SVGs, we\nintroduce a Hierarchical Image VEctorization (HIVE) framework that operates at\nthe semantic object level and supervises the optimization of components within\nthe vector object. This approach facilitates the decoupling of vector graphics\ninto distinct objects and component levels. Our proposed HIVE algorithm,\ninformed by image segmentation priors, not only ensures a more precise\nrepresentation of vector graphics but also enables fine-grained editing\ncapabilities within vector objects. To improve the diversity of output SVGs, we\npresent a Vectorized Particle-based Score Distillation (VPSD) approach. VPSD\naddresses over-saturation issues in existing methods and enhances sample\ndiversity. A pre-trained reward model is incorporated to re-weight vector\nparticles, improving aesthetic appeal and enabling faster convergence.\nAdditionally, we design a novel adaptive vector primitives control strategy,\nwhich allows for the dynamic adjustment of the number of primitives, thereby\nenhancing the presentation of graphic details. Extensive experiments validate\nthe effectiveness of the proposed method, demonstrating its superiority over\nbaseline methods in terms of editability, visual quality, and diversity. We\nalso show that our new method supports up to six distinct vector styles,\ncapable of generating high-quality vector assets suitable for stylized vector\ndesign and poster design. Code and demo will be released at:\nhttp://ximinng.github.io/SVGDreamerV2Project/",
      "tldr_zh": "本论文提出 SVGDreamer++ 方法，旨在提升文本引导 SVG 生成的可编辑性和多样性，以解决现有方法的视觉质量和多样性不足问题。通过 Hierarchical Image VEctorization (HIVE) 框架，该方法在语义对象级别优化向量组件，利用图像分割先验实现 SVG 的解耦和细粒度编辑。同时，Vectorized Particle-based Score Distillation (VPSD) 技术结合预训练奖励模型，解决过饱和问题，提高样本多样性和美学吸引力，并引入 adaptive vector primitives control 策略动态调整基元数量以增强细节呈现。实验结果显示，SVGDreamer++ 在可编辑性、视觉质量和多样性方面优于基线方法，支持六种向量样式，适用于风格化设计和海报制作。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "17 pages, 17 figures. Project Page:\n  http://ximinng.github.io/SVGDreamerV2Project/. arXiv admin note: text overlap\n  with arXiv:2312.16476",
      "pdf_url": "http://arxiv.org/pdf/2411.17832v2",
      "published_date": "2024-11-26 19:13:38 UTC",
      "updated_date": "2024-12-13 11:40:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:33:02.403959"
    },
    {
      "arxiv_id": "2411.17697v2",
      "title": "StableAnimator: High-Quality Identity-Preserving Human Image Animation",
      "title_zh": "StableAnimator: 高质量身份保持人类图像动画",
      "authors": [
        "Shuyuan Tu",
        "Zhen Xing",
        "Xintong Han",
        "Zhi-Qi Cheng",
        "Qi Dai",
        "Chong Luo",
        "Zuxuan Wu"
      ],
      "abstract": "Current diffusion models for human image animation struggle to ensure\nidentity (ID) consistency. This paper presents StableAnimator, the first\nend-to-end ID-preserving video diffusion framework, which synthesizes\nhigh-quality videos without any post-processing, conditioned on a reference\nimage and a sequence of poses. Building upon a video diffusion model,\nStableAnimator contains carefully designed modules for both training and\ninference striving for identity consistency. In particular, StableAnimator\nbegins by computing image and face embeddings with off-the-shelf extractors,\nrespectively and face embeddings are further refined by interacting with image\nembeddings using a global content-aware Face Encoder. Then, StableAnimator\nintroduces a novel distribution-aware ID Adapter that prevents interference\ncaused by temporal layers while preserving ID via alignment. During inference,\nwe propose a novel Hamilton-Jacobi-Bellman (HJB) equation-based optimization to\nfurther enhance the face quality. We demonstrate that solving the HJB equation\ncan be integrated into the diffusion denoising process, and the resulting\nsolution constrains the denoising path and thus benefits ID preservation.\nExperiments on multiple benchmarks show the effectiveness of StableAnimator\nboth qualitatively and quantitatively.",
      "tldr_zh": "该论文提出StableAnimator，一种端到端的视频扩散框架，用于实现高质量的身份（ID）保持人类图像动画，避免了传统模型在ID一致性上的不足。框架基于参考图像和姿势序列，通过计算图像及面部嵌入、利用全局内容感知Face Encoder优化嵌入，以及引入Distribution-Aware ID Adapter进行对齐，以防止时间层干扰并保持ID。推理阶段采用Hamilton-Jacobi-Bellman (HJB)方程优化进一步提升面部质量，并在多个基准测试中证明了StableAnimator的定性和定量优势。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17697v2",
      "published_date": "2024-11-26 18:59:22 UTC",
      "updated_date": "2024-11-27 07:39:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:33:13.564743"
    },
    {
      "arxiv_id": "2412.00077v1",
      "title": "Selfish Evolution: Making Discoveries in Extreme Label Noise with the Help of Overfitting Dynamics",
      "title_zh": "翻译失败",
      "authors": [
        "Nima Sedaghat",
        "Tanawan Chatchadanoraset",
        "Colin Orion Chandler",
        "Ashish Mahabal",
        "Maryam Eslami"
      ],
      "abstract": "Motivated by the scarcity of proper labels in an astrophysical application,\nwe have developed a novel technique, called Selfish Evolution, which allows for\nthe detection and correction of corrupted labels in a weakly supervised\nfashion. Unlike methods based on early stopping, we let the model train on the\nnoisy dataset. Only then do we intervene and allow the model to overfit to\nindividual samples. The ``evolution'' of the model during this process reveals\npatterns with enough information about the noisiness of the label, as well as\nits correct version. We train a secondary network on these spatiotemporal\n``evolution cubes'' to correct potentially corrupted labels. We incorporate the\ntechnique in a closed-loop fashion, allowing for automatic convergence towards\na mostly clean dataset, without presumptions about the state of the network in\nwhich we intervene. We evaluate on the main task of the Supernova-hunting\ndataset but also demonstrate efficiency on the more standard MNIST dataset.",
      "tldr_zh": "该研究提出了一种名为 Selfish Evolution 的新颖技术，用于在极端标签噪声环境下检测和修正被破坏的标签，采用弱监督方式。该方法让模型在噪声数据集上充分训练，然后允许模型过度拟合（overfitting）到单个样本，通过分析模型的时空“演化立方体”（spatiotemporal evolution cubes）来揭示标签噪声模式及其正确版本，并使用次级网络进行标签修正。Selfish Evolution 以闭环方式整合，实现自动收敛到大部分干净的数据集，而无需预设干预时机。在 Supernova-hunting 和 MNIST 数据集上的实验证明，该技术有效提高了标签修正的准确性。",
      "categories": [
        "cs.CV",
        "astro-ph.IM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.00077v1",
      "published_date": "2024-11-26 18:51:43 UTC",
      "updated_date": "2024-11-26 18:51:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:33:25.015945"
    },
    {
      "arxiv_id": "2411.17684v1",
      "title": "RealSeal: Revolutionizing Media Authentication with Real-Time Realism Scoring",
      "title_zh": "RealSeal：通过实时真实性评分革新媒体认证",
      "authors": [
        "Bhaktipriya Radharapu",
        "Harish Krishna"
      ],
      "abstract": "The growing threat of deepfakes and manipulated media necessitates a radical\nrethinking of media authentication. Existing methods for watermarking synthetic\ndata fall short, as they can be easily removed or altered, and current deepfake\ndetection algorithms do not achieve perfect accuracy. Provenance techniques,\nwhich rely on metadata to verify content origin, fail to address the\nfundamental problem of staged or fake media.\n  This paper introduces a groundbreaking paradigm shift in media authentication\nby advocating for the watermarking of real content at its source, as opposed to\nwatermarking synthetic data. Our innovative approach employs multisensory\ninputs and machine learning to assess the realism of content in real-time and\nacross different contexts. We propose embedding a robust realism score within\nthe image metadata, fundamentally transforming how images are trusted and\ncirculated. By combining established principles of human reasoning about\nreality, rooted in firmware and hardware security, with the sophisticated\nreasoning capabilities of contemporary machine learning systems, we develop a\nholistic approach that analyzes information from multiple perspectives.\n  This ambitious, blue sky approach represents a significant leap forward in\nthe field, pushing the boundaries of media authenticity and trust. By embracing\ncutting-edge advancements in technology and interdisciplinary research, we aim\nto establish a new standard for verifying the authenticity of digital media.",
      "tldr_zh": "这篇论文针对deepfakes和操纵媒体的威胁，提出了一种革命性的媒体认证方法RealSeal，通过在媒体源头水印真实内容来取代传统的合成数据watermarking。方法利用多感官输入和machine learning实时评估内容的真实性，并在图像metadata中嵌入一个鲁棒的realism score，实现多角度分析。RealSeal结合硬件安全和机器学习的整体框架，旨在推动媒体真实性和信任的新标准，提供更可靠的数字媒体认证解决方案。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Best Paper Award, Blue Sky Track at 26th ACM International Conference\n  on Multimodal Interaction, Nov 2024, San Jose, Costa Rica",
      "pdf_url": "http://arxiv.org/pdf/2411.17684v1",
      "published_date": "2024-11-26 18:48:23 UTC",
      "updated_date": "2024-11-26 18:48:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:34:27.366871"
    },
    {
      "arxiv_id": "2411.17800v1",
      "title": "STAR: Synthesis of Tailored Architectures",
      "title_zh": "翻译失败",
      "authors": [
        "Armin W. Thomas",
        "Rom Parnichkun",
        "Alexander Amini",
        "Stefano Massaroli",
        "Michael Poli"
      ],
      "abstract": "Iterative improvement of model architectures is fundamental to deep learning:\nTransformers first enabled scaling, and recent advances in model hybridization\nhave pushed the quality-efficiency frontier. However, optimizing architectures\nremains challenging and expensive. Current automated or manual approaches fall\nshort, largely due to limited progress in the design of search spaces and due\nto the simplicity of resulting patterns and heuristics. In this work, we\npropose a new approach for the synthesis of tailored architectures (STAR). Our\napproach combines a novel search space based on the theory of linear\ninput-varying systems, supporting a hierarchical numerical encoding into\narchitecture genomes. STAR genomes are automatically refined and recombined\nwith gradient-free, evolutionary algorithms to optimize for multiple model\nquality and efficiency metrics. Using STAR, we optimize large populations of\nnew architectures, leveraging diverse computational units and interconnection\npatterns, improving over highly-optimized Transformers and striped hybrid\nmodels on the frontier of quality, parameter size, and inference cache for\nautoregressive language modeling.",
      "tldr_zh": "本文提出 STAR 方法，用于合成定制模型架构，以解决深度学习中架构优化面临的挑战，如搜索空间设计有限和优化效率低下。STAR 基于线性输入可变系统理论构建新型搜索空间，支持层级数值编码到架构基因组，并使用无梯度演化算法自动精炼和重组基因组，以优化模型质量、效率指标。实验结果显示，STAR 在自回归语言建模中超越高度优化的 Transformers 和混合模型，在质量、参数大小和推理缓存方面显著提升。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17800v1",
      "published_date": "2024-11-26 18:42:42 UTC",
      "updated_date": "2024-11-26 18:42:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:34:10.768642"
    },
    {
      "arxiv_id": "2411.17645v3",
      "title": "Explainable AI for Classifying UTI Risk Groups Using a Real-World Linked EHR and Pathology Lab Dataset",
      "title_zh": "翻译失败",
      "authors": [
        "Yujie Dai",
        "Brian Sullivan",
        "Axel Montout",
        "Amy Dillon",
        "Chris Waller",
        "Peter Acs",
        "Rachel Denholm",
        "Philip Williams",
        "Alastair D Hay",
        "Raul Santos-Rodriguez",
        "Andrew Dowsey"
      ],
      "abstract": "The use of machine learning and AI on electronic health records (EHRs) holds\nsubstantial potential for clinical insight. However, this approach faces\nchallenges due to data heterogeneity, sparsity, temporal misalignment, and\nlimited labeled outcomes. In this context, we leverage a linked EHR dataset of\napproximately one million de-identified individuals from Bristol, North\nSomerset, and South Gloucestershire, UK, to characterize urinary tract\ninfections (UTIs). We implemented a data pre-processing and curation pipeline\nthat transforms the raw EHR data into a structured format suitable for\ndeveloping predictive models focused on data fairness, accountability and\ntransparency. Given the limited availability and biases of ground truth UTI\noutcomes, we introduce a UTI risk estimation framework informed by clinical\nexpertise to estimate UTI risk across individual patient timelines. Pairwise\nXGBoost models are trained using this framework to differentiate UTI risk\ncategories with explainable AI techniques applied to identify key predictors\nand support interpretability. Our findings reveal differences in clinical and\ndemographic predictors across risk groups. While this study highlights the\npotential of AI-driven insights to support UTI clinical decision-making,\nfurther investigation of patient sub-strata and extensive validation are needed\nto ensure robustness and applicability in clinical practice.",
      "tldr_zh": "这篇论文利用英国约一百万匿名个体的链接电子健康记录（EHR）数据集，开发了一个UTI风险分类框架，以应对数据异质性、稀疏性和标签有限等挑战。研究者实施了数据预处理管道和基于临床专业知识的UTI风险估计框架，使用Pairwise XGBoost模型结合Explainable AI技术来区分风险组，并识别关键临床和人口统计预测因子。结果显示不同UTI风险组的预测因子存在差异，突显AI在支持UTI临床决策的潜力，但强调需要进一步验证患者子群以确保稳健性和临床适用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17645v3",
      "published_date": "2024-11-26 18:10:51 UTC",
      "updated_date": "2025-02-28 15:16:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:34:24.075562"
    },
    {
      "arxiv_id": "2411.17798v1",
      "title": "DapPep: Domain Adaptive Peptide-agnostic Learning for Universal T-cell Receptor-antigen Binding Affinity Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Jiangbin Zheng",
        "Qianhui Xu",
        "Ruichen Xia",
        "Stan Z. Li"
      ],
      "abstract": "Identifying T-cell receptors (TCRs) that interact with antigenic peptides\nprovides the technical basis for developing vaccines and immunotherapies. The\nemergent deep learning methods excel at learning antigen binding patterns from\nknown TCRs but struggle with novel or sparsely represented antigens. However,\nbinding specificity for unseen antigens or exogenous peptides is critical. We\nintroduce a domain-adaptive peptide-agnostic learning framework DapPep for\nuniversal TCR-antigen binding affinity prediction to address this challenge.\nThe lightweight self-attention architecture combines a pre-trained protein\nlanguage model with an inner-loop self-supervised regime to enable robust\nTCR-peptide representations. Extensive experiments on various benchmarks\ndemonstrate that DapPep consistently outperforms existing tools, showcasing\nrobust generalization capability, especially for data-scarce settings and\nunseen peptides. Moreover, DapPep proves effective in challenging clinical\ntasks such as sorting reactive T cells in tumor neoantigen therapy and\nidentifying key positions in 3D structures.",
      "tldr_zh": "本研究引入了DapPep框架，这是一种domain-adaptive peptide-agnostic learning方法，用于实现T-cell Receptor (TCR)-antigen结合亲和力的通用预测，旨在解决现有深度学习模型在新颖或稀少抗原上的局限性。DapPep采用轻量级self-attention架构，结合pre-trained protein language model和inner-loop self-supervised regime，生成鲁棒的TCR-peptide表示，从而提升模型的泛化能力。在各种基准测试中，DapPep显著优于现有工具，尤其在数据稀缺场景和未见peptides的条件下；此外，它在临床任务中表现出色，如排序reactive T cells用于tumor neoantigen therapy和识别3D结构中的关键位置。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17798v1",
      "published_date": "2024-11-26 18:06:42 UTC",
      "updated_date": "2024-11-26 18:06:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:34:35.189797"
    },
    {
      "arxiv_id": "2412.08653v1",
      "title": "What AI evaluations for preventing catastrophic risks can and cannot do",
      "title_zh": "翻译失败",
      "authors": [
        "Peter Barnett",
        "Lisa Thiergart"
      ],
      "abstract": "AI evaluations are an important component of the AI governance toolkit,\nunderlying current approaches to safety cases for preventing catastrophic\nrisks. Our paper examines what these evaluations can and cannot tell us.\nEvaluations can establish lower bounds on AI capabilities and assess certain\nmisuse risks given sufficient effort from evaluators.\n  Unfortunately, evaluations face fundamental limitations that cannot be\novercome within the current paradigm. These include an inability to establish\nupper bounds on capabilities, reliably forecast future model capabilities, or\nrobustly assess risks from autonomous AI systems. This means that while\nevaluations are valuable tools, we should not rely on them as our main way of\nensuring AI systems are safe. We conclude with recommendations for incremental\nimprovements to frontier AI safety, while acknowledging these fundamental\nlimitations remain unsolved.",
      "tldr_zh": "这篇论文探讨了 AI evaluations 在防止灾难性风险(catastrophic risks)中的作用及其局限性。论文指出，AI evaluations 可以建立 AI 能力的下限(lower bounds on AI capabilities)，并评估某些误用风险(misuse risks)，前提是评估者投入足够努力。另一方面，它们无法确定能力的上限(upper bounds on capabilities)、可靠预测未来模型能力，或稳健评估自主 AI 系统(autonomous AI systems)的风险。最终，论文建议对前沿 AI 安全进行渐进式改进，但强调这些根本限制仍未解决，因此不应依赖评估作为确保 AI 系统安全的主要手段。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.08653v1",
      "published_date": "2024-11-26 18:00:36 UTC",
      "updated_date": "2024-11-26 18:00:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:34:47.054291"
    },
    {
      "arxiv_id": "2411.17636v1",
      "title": "MALMM: Multi-Agent Large Language Models for Zero-Shot Robotics Manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Harsh Singh",
        "Rocktim Jyoti Das",
        "Mingfei Han",
        "Preslav Nakov",
        "Ivan Laptev"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable planning abilities\nacross various domains, including robotics manipulation and navigation. While\nrecent efforts in robotics have leveraged LLMs both for high-level and\nlow-level planning, these approaches often face significant challenges, such as\nhallucinations in long-horizon tasks and limited adaptability due to the\ngeneration of plans in a single pass without real-time feedback. To address\nthese limitations, we propose a novel multi-agent LLM framework, Multi-Agent\nLarge Language Model for Manipulation (MALMM) that distributes high-level\nplanning and low-level control code generation across specialized LLM agents,\nsupervised by an additional agent that dynamically manages transitions. By\nincorporating observations from the environment after each step, our framework\neffectively handles intermediate failures and enables adaptive re-planning.\nUnlike existing methods, our approach does not rely on pre-trained skill\npolicies or in-context learning examples and generalizes to a variety of new\ntasks. We evaluate our approach on nine RLBench tasks, including long-horizon\ntasks, and demonstrate its ability to solve robotics manipulation in a\nzero-shot setting, thereby overcoming key limitations of existing LLM-based\nmanipulation methods.",
      "tldr_zh": "这篇论文提出了 MALMM，一种多智能体 Large Language Models (LLMs) 框架，用于实现零样本 (zero-shot) 机器人操作，旨在解决现有方法在长时任务中的幻觉 (hallucinations) 和缺乏适应性问题。MALMM 将高层规划和低层控制代码生成分配给专门的 LLM 智能体，由一个监督智能体动态管理过渡，并通过每个步骤的环境观察实现中间失败处理和自适应重新规划。与传统方法不同，该框架不依赖预训练技能策略或上下文学习示例，能够泛化到各种新任务。在九个 RLBench 任务上实验表明，MALMM 在零样本设置下成功解决了机器人操作问题，显著克服了现有 LLM 方法的局限性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "48 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.17636v1",
      "published_date": "2024-11-26 17:53:44 UTC",
      "updated_date": "2024-11-26 17:53:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:34:59.399898"
    },
    {
      "arxiv_id": "2411.17795v1",
      "title": "Pan-protein Design Learning Enables Task-adaptive Generalization for Low-resource Enzyme Design",
      "title_zh": "翻译失败",
      "authors": [
        "Jiangbin Zheng",
        "Ge Wang",
        "Han Zhang",
        "Stan Z. Li"
      ],
      "abstract": "Computational protein design (CPD) offers transformative potential for\nbioengineering, but current deep CPD models, focused on universal domains,\nstruggle with function-specific designs. This work introduces a novel CPD\nparadigm tailored for functional design tasks, particularly for enzymes-a key\nprotein class often lacking specific application efficiency. To address\nstructural data scarcity, we present CrossDesign, a domain-adaptive framework\nthat leverages pretrained protein language models (PPLMs). By aligning protein\nstructures with sequences, CrossDesign transfers pretrained knowledge to\nstructure models, overcoming the limitations of limited structural data. The\nframework combines autoregressive (AR) and non-autoregressive (NAR) states in\nits encoder-decoder architecture, applying it to enzyme datasets and\npan-proteins. Experimental results highlight CrossDesign's superior performance\nand robustness, especially with out-of-domain enzymes. Additionally, the model\nexcels in fitness prediction when tested on large-scale mutation data,\nshowcasing its stability.",
      "tldr_zh": "该研究提出了一种新型计算蛋白质设计 (CPD) 范式，针对功能特定任务（如酶设计）中的数据稀缺问题，引入 CrossDesign 框架，利用预训练的蛋白质语言模型 (PPLMs) 通过结构与序列对齐，将预训练知识转移到结构模型中。框架采用结合自回归 (AR) 和非自回归 (NAR) 状态的编码器-解码器架构，适用于酶数据集和泛蛋白设计。实验结果显示，CrossDesign 在领域外酶上表现出色，并在大规模突变数据测试中展现出优越的性能和稳定性。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17795v1",
      "published_date": "2024-11-26 17:51:33 UTC",
      "updated_date": "2024-11-26 17:51:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:35:11.453828"
    },
    {
      "arxiv_id": "2411.17793v1",
      "title": "Engineering AI Judge Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Jiahuei Lin",
        "Dayi Lin",
        "Sky Zhang",
        "Ahmed E. Hassan"
      ],
      "abstract": "AI judge systems are designed to automatically evaluate Foundation\nModel-powered software (i.e., FMware). Due to the intrinsic dynamic and\nstochastic nature of FMware, the development of AI judge systems requires a\nunique engineering life cycle and presents new challenges. In this paper, we\ndiscuss the challenges based on our industrial experiences in developing AI\njudge systems for FMware. These challenges lead to substantial time\nconsumption, cost and inaccurate judgments. We propose a framework that tackles\nthe challenges with the goal of improving the productivity of developing\nhigh-quality AI judge systems. Finally, we evaluate our framework with a case\nstudy on judging a commit message generation FMware. The accuracy of the\njudgments made by the AI judge system developed with our framework outperforms\nthose made by the AI judge system that is developed without our framework by up\nto 6.2%, with a significant reduction in development effort.",
      "tldr_zh": "这篇论文讨论了开发 AI judge systems 用于评估 Foundation Model-powered software (FMware) 的挑战，这些挑战源于 FMware 的动态和随机特性，导致时间消耗、成本增加和判断不准确。作者基于工业经验提出一个框架，通过优化工程生命周期来解决这些问题，提高 AI judge systems 的开发效率和质量。在一个针对提交消息生成 FMware 的案例研究中，该框架使判断准确率提升最多 6.2%，并显著减少了开发努力。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17793v1",
      "published_date": "2024-11-26 17:43:32 UTC",
      "updated_date": "2024-11-26 17:43:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:35:22.485104"
    },
    {
      "arxiv_id": "2411.17792v1",
      "title": "$H^3$Fusion: Helpful, Harmless, Honest Fusion of Aligned LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Selim Furkan Tekin",
        "Fatih Ilhan",
        "Tiansheng Huang",
        "Sihao Hu",
        "Zachary Yahn",
        "Ling Liu"
      ],
      "abstract": "Alignment of pretrained LLMs using instruction-based datasets is critical for\ncreating fine-tuned models that reflect human preference. A growing number of\nalignment-based fine-tuning algorithms and benchmarks emerged recently, fueling\nthe efforts on effective alignments of pre-trained LLMs to ensure helpful,\nharmless, and honest answers from both open-source and closed-source LLMs. This\npaper tackles this problem by developing an alignment fusion approach, coined\nas $H^3$Fusion, with three unique characteristics. First, $H^3$Fusion ensembles\nmultiple individually aligned LLMs to create a final fine-tuned alignment model\nwith enhanced capabilities beyond those of individual models, delivering robust\nalignment through promoting helpful, harmless, honest fusion. Second,\n$H^3$Fusion leverages the mixture-of-experts (MoE) methodology in two steps. We\nfirst freeze the multi-head attention weights of each individual model while\ntuning the FFN layer during alignment fusion. Then we merge the aligned model\nweights with an expert router according to the type of input instruction and\ndynamically select a subset of experts that are best suited for producing the\noutput response. Finally, we boost the performance of the resulting\n$H^3$3Fusion model by introducing gating loss and regularization terms. The\nformer penalizes the selection errors of the expert-router, and the latter\nmediates the expert weights drifting during fine-tuning and dynamically adjusts\nthe fusion behavior of the resulting model by canalizing the activations on the\nexperts. Extensive evaluations on three benchmark datasets show that\n$H^3$3Fusion is more helpful, less harmful, and more honest from two aspects:\nit outperforms each individually aligned model by $11.37\\%$, and it provides\nstronger robustness compared to the state-of-the-art LLM ensemble approaches by\n$13.77\\%$. Code is available at github.com/sftekin/h3fusion.",
      "tldr_zh": "本研究提出了一种名为$H^3$Fusion的对齐融合方法，用于提升预训练LLMs（大型语言模型）的对齐性能，确保模型输出更helpful（有帮助）、harmless（无害）和honest（诚实）。$H^3$Fusion通过集成多个独立对齐的LLM，并采用mixture-of-experts (MoE)方法，包括冻结multi-head attention权重、微调FFN层、动态选择专家子集，以及引入gating loss和regularization terms来优化融合过程，从而减少专家路由错误并稳定权重。实验结果显示，在三个基准数据集上，$H^3$Fusion比单个对齐模型提升11.37%的性能，并比最先进LLM集成方法提高13.77%的鲁棒性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17792v1",
      "published_date": "2024-11-26 17:42:38 UTC",
      "updated_date": "2024-11-26 17:42:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:35:35.597992"
    },
    {
      "arxiv_id": "2411.17629v2",
      "title": "Learning Chemical Reaction Representation with Reactant-Product Alignment",
      "title_zh": "基于反应物-产物对齐的化学反应表示学习",
      "authors": [
        "Kaipeng Zeng",
        "Xianbin Liu",
        "Yu Zhang",
        "Xiaokang Yang",
        "Yaohui Jin",
        "Yanyan Xu"
      ],
      "abstract": "Organic synthesis stands as a cornerstone of the chemical industry. The\ndevelopment of robust machine learning models to support tasks associated with\norganic reactions is of significant interest. However, current methods rely on\nhand-crafted features or direct adaptations of model architectures from other\ndomains, which lack feasibility as data scales increase or ignore the rich\nchemical information inherent in reactions. To address these issues, this paper\nintroduces RAlign, a novel chemical reaction representation learning model for\nvarious organic reaction-related tasks. By integrating atomic correspondence\nbetween reactants and products, our model discerns the molecular\ntransformations that occur during the reaction, thereby enhancing comprehension\nof the reaction mechanism. We have designed an adapter structure to incorporate\nreaction conditions into the chemical reaction representation, allowing the\nmodel to handle various reaction conditions and to adapt to various datasets\nand downstream tasks. Additionally, we introduce a reaction-center-aware\nattention mechanism that enables the model to concentrate on key functional\ngroups, thereby generating potent representations for chemical reactions. Our\nmodel has been evaluated on a range of downstream tasks. Experimental results\nindicate that our model markedly outperforms existing chemical reaction\nrepresentation learning architectures on most of the datasets. We plan to\nopen-source the code contingent upon the acceptance of the paper.",
      "tldr_zh": "本论文提出RAlign，一种新型化学反应表示学习模型，旨在解决现有方法依赖手工特征或直接改编架构的问题，从而更好地捕捉有机反应的丰富化学信息。通过整合反应物和产物的atomic correspondence，模型能够理解分子转变并提升对反应机制的认知。RAlign还引入了adapter structure来整合反应条件，以及reaction-center-aware attention mechanism来关注关键功能团，使其适用于多种数据集和下游任务。实验结果显示，该模型在大多数数据集上显著优于现有架构，作者计划开源代码以促进进一步研究。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17629v2",
      "published_date": "2024-11-26 17:41:44 UTC",
      "updated_date": "2025-01-03 16:55:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:35:46.494109"
    },
    {
      "arxiv_id": "2411.17624v1",
      "title": "Machine Learning and Multi-source Remote Sensing in Forest Carbon Stock Estimation: A Review",
      "title_zh": "机器学习和多源遥感在森林碳储量估算中的应用：综述",
      "authors": [
        "Autumn Nguyen",
        "Sulagna Saha"
      ],
      "abstract": "Quantifying forest carbon is crucial for informing decisions and policies\nthat will protect the planet. Machine learning (ML) and remote sensing (RS)\ntechniques have been used to do this task more effectively, yet there lacks a\nsystematic review on the most recent ML methods and RS combinations, especially\nwith the consideration of forest characteristics. This study systematically\nanalyzed 25 papers meeting strict inclusion criteria from over 80 related\nstudies, identifying 28 ML methods and key combinations of RS data. Random\nForest had the most frequent appearance (88\\% of studies), while Extreme\nGradient Boosting showed superior performance in 75\\% of the studies in which\nit was compared with other methods. Sentinel-1 emerged as the most utilized\nremote sensing source, with multi-sensor approaches (e.g., Sentinel-1,\nSentinel-2, and LiDAR) proving especially effective. Our findings provide\ngrounds for recommending best practices in integrating machine learning and\nremote sensing for accurate and scalable forest carbon stock estimation.",
      "tldr_zh": "这篇综述论文审视了 Machine Learning (ML) 和多源 Remote Sensing (RS) 在森林碳储量估算中的应用，强调其对决策和政策的重要性。研究分析了 25 篇符合严格标准的论文，识别了 28 种 ML 方法和关键 RS 数据组合，其中 Random Forest 是最常用方法（88% 的研究），而 Extreme Gradient Boosting 在 75% 的比较中表现出优越性能。Sentinel-1 作为最常使用的遥感源，多传感器方法（如 Sentinel-1、Sentinel-2 和 LiDAR）被证明特别有效。该研究提供了整合 ML 和 RS 的最佳实践建议，以实现准确且可扩展的森林碳储量估算。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "First author and corresponding author: Autumn Nguyen",
      "pdf_url": "http://arxiv.org/pdf/2411.17624v1",
      "published_date": "2024-11-26 17:34:59 UTC",
      "updated_date": "2024-11-26 17:34:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:36:00.174280"
    },
    {
      "arxiv_id": "2411.17614v1",
      "title": "Automating Chapter-Level Classification for Electronic Theses and Dissertations",
      "title_zh": "翻译失败",
      "authors": [
        "Bipasha Banerjee",
        "William A. Ingram",
        "Edward A. Fox"
      ],
      "abstract": "Traditional archival practices for describing electronic theses and\ndissertations (ETDs) rely on broad, high-level metadata schemes that fail to\ncapture the depth, complexity, and interdisciplinary nature of these long\nscholarly works. The lack of detailed, chapter-level content descriptions\nimpedes researchers' ability to locate specific sections or themes, thereby\nreducing discoverability and overall accessibility. By providing chapter-level\nmetadata information, we improve the effectiveness of ETDs as research\nresources. This makes it easier for scholars to navigate them efficiently and\nextract valuable insights. The absence of such metadata further obstructs\ninterdisciplinary research by obscuring connections across fields, hindering\nnew academic discoveries and collaboration. In this paper, we propose a machine\nlearning and AI-driven solution to automatically categorize ETD chapters. This\nsolution is intended to improve discoverability and promote understanding of\nchapters. Our approach enriches traditional archival practices by providing\ncontext-rich descriptions that facilitate targeted navigation and improved\naccess. We aim to support interdisciplinary research and make ETDs more\naccessible. By providing chapter-level classification labels and using them to\nindex in our developed prototype system, we make content in ETD chapters more\ndiscoverable and usable for a diverse range of scholarly needs. Implementing\nthis AI-enhanced approach allows archives to serve researchers better, enabling\nefficient access to relevant information and supporting deeper engagement with\nETDs. This will increase the impact of ETDs as research tools, foster\ninterdisciplinary exploration, and reinforce the role of archives in scholarly\ncommunication within the data-intensive academic landscape.",
      "tldr_zh": "传统ETD（Electronic Theses and Dissertations）的存档实践依赖于宽泛的元数据方案，无法捕捉章节级细节，导致研究者难以定位特定主题并阻碍跨学科研究。论文提出一种基于机器学习和AI的解决方案，通过自动分类ETD章节并生成章节级标签来丰富元数据。利用这些标签在开发的原型系统中进行索引，该方法显著提升了ETD的可发现性和可用性，支持学者高效导航、提取洞见，并促进学术合作和跨领域探索。最终，这有助于强化ETD作为研究工具的作用，在数据密集型学术环境中提升其影响力。",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.DL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17614v1",
      "published_date": "2024-11-26 17:27:18 UTC",
      "updated_date": "2024-11-26 17:27:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:36:10.910960"
    },
    {
      "arxiv_id": "2411.17608v2",
      "title": "Mixed-State Quantum Denoising Diffusion Probabilistic Model",
      "title_zh": "混合态量子去噪扩散概率模型",
      "authors": [
        "Gino Kwun",
        "Bingzhi Zhang",
        "Quntao Zhuang"
      ],
      "abstract": "Generative quantum machine learning has gained significant attention for its\nability to produce quantum states with desired distributions. Among various\nquantum generative models, quantum denoising diffusion probabilistic models\n(QuDDPMs) [Phys. Rev. Lett. 132, 100602 (2024)] provide a promising approach\nwith stepwise learning that resolves the training issues. However, the\nrequirement of high-fidelity scrambling unitaries in QuDDPM poses a challenge\nin near-term implementation. We propose the \\textit{mixed-state quantum\ndenoising diffusion probabilistic model} (MSQuDDPM) to eliminate the need for\nscrambling unitaries. Our approach focuses on adapting the quantum noise\nchannels to the model architecture, which integrates depolarizing noise\nchannels in the forward diffusion process and parameterized quantum circuits\nwith projective measurements in the backward denoising steps. We also introduce\nseveral techniques to improve MSQuDDPM, including a cosine-exponent schedule of\nnoise interpolation, the use of single-qubit random ancilla, and\nsuperfidelity-based cost functions to enhance the convergence. We evaluate\nMSQuDDPM on quantum ensemble generation tasks, demonstrating its successful\nperformance.",
      "tldr_zh": "本文提出混合状态量子去噪扩散概率模型 (MSQuDDPM)，旨在解决传统量子去噪扩散概率模型 (QuDDPM) 对高保真度混沌酉变换的依赖问题，从而提升近中期量子生成任务的可实现性。该模型通过在前向扩散过程中整合去极化噪声通道，以及在后向去噪步骤中使用参数化量子电路和投影测量，适应量子噪声特性以生成期望的量子状态。此外，引入余弦指数噪声插值时间表、单比特随机辅助比特以及基于超保真度的成本函数等技术，以改善模型的收敛性能。实验结果表明，MSQuDDPM 在量子集合生成任务上表现出成功性能，证明了其有效性。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "8 pages, 8 figures; Fig.8 added, appendix C added",
      "pdf_url": "http://arxiv.org/pdf/2411.17608v2",
      "published_date": "2024-11-26 17:20:58 UTC",
      "updated_date": "2025-03-04 05:15:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:36:23.388197"
    },
    {
      "arxiv_id": "2411.17600v1",
      "title": "Making History Readable",
      "title_zh": "让历史变得可读",
      "authors": [
        "Bipasha Banerjee",
        "Jennifer Goyne",
        "William A. Ingram"
      ],
      "abstract": "The Virginia Tech University Libraries (VTUL) Digital Library Platform (DLP)\nhosts digital collections that offer our users access to a wide variety of\ndocuments of historical and cultural importance. These collections are not only\nof academic importance but also provide our users with a glance at local\nhistorical events. Our DLP contains collections comprising digital objects\nfeaturing complex layouts, faded imagery, and hard-to-read handwritten text,\nwhich makes providing online access to these materials challenging. To address\nthese issues, we integrate AI into our DLP workflow and convert the text in the\ndigital objects into a machine-readable format. To enhance the user experience\nwith our historical collections, we use custom AI agents for handwriting\nrecognition, text extraction, and large language models (LLMs) for\nsummarization. This poster highlights three collections focusing on handwritten\nletters, newspapers, and digitized topographic maps. We discuss the challenges\nwith each collection and detail our approaches to address them. Our proposed\nmethods aim to enhance the user experience by making the contents in these\ncollections easier to search and navigate.",
      "tldr_zh": "弗吉尼亚理工大学图书馆的数字图书馆平台（DLP）托管了各种历史数字收藏，这些材料包括复杂布局、褪色图像和难读的手写文本，导致在线访问挑战。研究团队通过整合 AI 技术，使用自定义 AI agents 进行手写识别和文本提取，以及大型语言模型 (LLMs) 进行总结，将文本转换为机器可读格式。针对手写信件、报纸和数字化地形图等三个收藏，他们讨论了具体挑战并提出解决方案，最终提升用户体验，使这些历史内容更容易搜索和导航。",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.DL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17600v1",
      "published_date": "2024-11-26 17:06:58 UTC",
      "updated_date": "2024-11-26 17:06:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:36:34.736889"
    },
    {
      "arxiv_id": "2411.17598v1",
      "title": "Agentic AI for Improving Precision in Identifying Contributions to Sustainable Development Goals",
      "title_zh": "翻译失败",
      "authors": [
        "William A. Ingram",
        "Bipasha Banerjee",
        "Edward A. Fox"
      ],
      "abstract": "As research institutions increasingly commit to supporting the United\nNations' Sustainable Development Goals (SDGs), there is a pressing need to\naccurately assess their research output against these goals. Current\napproaches, primarily reliant on keyword-based Boolean search queries, conflate\nincidental keyword matches with genuine contributions, reducing retrieval\nprecision and complicating benchmarking efforts. This study investigates the\napplication of autoregressive Large Language Models (LLMs) as evaluation agents\nto identify relevant scholarly contributions to SDG targets in scholarly\npublications. Using a dataset of academic abstracts retrieved via SDG-specific\nkeyword queries, we demonstrate that small, locally-hosted LLMs can\ndifferentiate semantically relevant contributions to SDG targets from documents\nretrieved due to incidental keyword matches, addressing the limitations of\ntraditional methods. By leveraging the contextual understanding of LLMs, this\napproach provides a scalable framework for improving SDG-related research\nmetrics and informing institutional reporting.",
      "tldr_zh": "这篇论文探讨了使用 Agentic AI，即 autoregressive Large Language Models (LLMs)，来提升识别学术研究对 Sustainable Development Goals (SDGs) 贡献的精确度，解决当前关键词搜索方法因 incidental keyword matches 而导致的误匹配问题。研究团队利用一个基于 SDG 特定关键词查询的学术摘要数据集，证明小型本地托管的 LLMs 能够通过语义理解区分真正的相关贡献。结果显示，这种方法提供了一个可扩展的框架，提高了 SDG 相关研究指标的准确性，并支持机构报告的优化。",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.DL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17598v1",
      "published_date": "2024-11-26 17:06:30 UTC",
      "updated_date": "2024-11-26 17:06:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:36:47.301420"
    },
    {
      "arxiv_id": "2411.17593v3",
      "title": "What Differentiates Educational Literature? A Multimodal Fusion Approach of Transformers and Computational Linguistics",
      "title_zh": "翻译失败",
      "authors": [
        "Jordan J. Bird"
      ],
      "abstract": "The integration of new literature into the English curriculum remains a\nchallenge since educators often lack scalable tools to rapidly evaluate\nreadability and adapt texts for diverse classroom needs. This study proposes to\naddress this gap through a multimodal approach that combines transformer-based\ntext classification with linguistic feature analysis to align texts with UK Key\nStages. Eight state-of-the-art Transformers were fine-tuned on segmented text\ndata, with BERT achieving the highest unimodal F1 score of 0.75. In parallel,\n500 deep neural network topologies were searched for the classification of\nlinguistic characteristics, achieving an F1 score of 0.392. The fusion of these\nmodalities shows a significant improvement, with every multimodal approach\noutperforming all unimodal models. In particular, the ELECTRA Transformer fused\nwith the neural network achieved an F1 score of 0.996. Unimodal and multimodal\napproaches are shown to have statistically significant differences in all\nvalidation metrics (accuracy, precision, recall, F1 score) except for inference\ntime. The proposed approach is finally encapsulated in a stakeholder-facing web\napplication, providing non-technical stakeholder access to real-time insights\non text complexity, reading difficulty, curriculum alignment, and\nrecommendations for learning age range. The application empowers data-driven\ndecision making and reduces manual workload by integrating AI-based\nrecommendations into lesson planning for English literature.",
      "tldr_zh": "这篇论文探讨了教育文学整合到英语课程中的挑战，提出了一种多模态融合方法，将 Transformer-based 文本分类（如 BERT，最高单模态 F1 score 达 0.75）和计算语言学特征分析（如深度神经网络，F1 score 0.392）相结合，以评估文本的可读性和与 UK Key Stages 的对齐。实验结果显示，多模态融合显著提升性能，特别是 ELECTRA 与神经网络的融合达到了 0.996 的 F1 score，并在准确率、精确率、召回率上优于单模态模型。最终，该方法封装到一个面向利益相关者的 web 应用中，提供实时洞察和 AI 推荐，帮助教育者减少手动工作量，实现数据驱动的课程规划。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17593v3",
      "published_date": "2024-11-26 17:01:27 UTC",
      "updated_date": "2024-12-02 17:43:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:36:59.720777"
    },
    {
      "arxiv_id": "2411.17570v1",
      "title": "Learning Explainable Treatment Policies with Clinician-Informed Representations: A Practical Approach",
      "title_zh": "基于临床医生指导的表示学习可解释治疗策略：一个实用方法",
      "authors": [
        "Johannes O. Ferstad",
        "Emily B. Fox",
        "David Scheinker",
        "Ramesh Johari"
      ],
      "abstract": "Digital health interventions (DHIs) and remote patient monitoring (RPM) have\nshown great potential in improving chronic disease management through\npersonalized care. However, barriers like limited efficacy and workload\nconcerns hinder adoption of existing DHIs; while limited sample sizes and lack\nof interpretability limit the effectiveness and adoption of purely black-box\nalgorithmic DHIs. In this paper, we address these challenges by developing a\npipeline for learning explainable treatment policies for RPM-enabled DHIs. We\napply our approach in the real-world setting of RPM using a DHI to improve\nglycemic control of youth with type 1 diabetes. Our main contribution is to\nreveal the importance of clinical domain knowledge in developing state and\naction representations for effective, efficient, and interpretable targeting\npolicies. We observe that policies learned from clinician-informed\nrepresentations are significantly more efficacious and efficient than policies\nlearned from black-box representations. This work emphasizes the importance of\ncollaboration between ML researchers and clinicians for developing effective\nDHIs in the real world.",
      "tldr_zh": "本研究针对数字健康干预（DHIs）和远程患者监测（RPM）在慢性病管理中的挑战，如效能有限、工作量问题以及黑盒算法的可解释性缺失，提出了一种学习可解释治疗策略的管道。方法强调利用临床领域知识来构建状态和行动表示，并在青少年1型糖尿病患者的血糖控制场景中进行实际应用。结果显示，使用临床专家信息表示的策略比黑盒表示的策略更有效和高效，显著提升了干预效能。该工作突出了机器学习（ML）研究者与临床专家合作的重要性，以开发更可靠的真实世界DHIs。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.AP",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Proceedings of Machine Learning for Health (ML4H) 2024. Code\n  available at: https://github.com/jferstad/ml4h-explainable-policies",
      "pdf_url": "http://arxiv.org/pdf/2411.17570v1",
      "published_date": "2024-11-26 16:32:08 UTC",
      "updated_date": "2024-11-26 16:32:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:37:11.321833"
    },
    {
      "arxiv_id": "2411.17557v1",
      "title": "A Bilayer Segmentation-Recombination Network for Accurate Segmentation of Overlapping C. elegans",
      "title_zh": "翻译失败",
      "authors": [
        "Mengqian Dinga",
        "Jun Liua",
        "Yang Luo",
        "Jinshan Tang"
      ],
      "abstract": "Caenorhabditis elegans (C. elegans) is an excellent model organism because of\nits short lifespan and high degree of homology with human genes, and it has\nbeen widely used in a variety of human health and disease models. However, the\nsegmentation of C. elegans remains challenging due to the following reasons: 1)\nthe activity trajectory of C. elegans is uncontrollable, and multiple nematodes\noften overlap, resulting in blurred boundaries of C. elegans. This makes it\nimpossible to clearly study the life trajectory of a certain nematode; and 2)\nin the microscope images of overlapping C. elegans, the translucent tissues at\nthe edges obscure each other, leading to inaccurate boundary segmentation. To\nsolve these problems, a Bilayer Segmentation-Recombination Network (BR-Net) for\nthe segmentation of C. elegans instances is proposed. The network consists of\nthree parts: A Coarse Mask Segmentation Module (CMSM), a Bilayer Segmentation\nModule (BSM), and a Semantic Consistency Recombination Module (SCRM). The CMSM\nis used to extract the coarse mask, and we introduce a Unified Attention Module\n(UAM) in CMSM to make CMSM better aware of nematode instances. The Bilayer\nSegmentation Module (BSM) segments the aggregated C. elegans into overlapping\nand non-overlapping regions. This is followed by integration by the SCRM, where\nsemantic consistency regularization is introduced to segment nematode instances\nmore accurately. Finally, the effectiveness of the method is verified on the C.\nelegans dataset. The experimental results show that BR-Net exhibits good\ncompetitiveness and outperforms other recently proposed instance segmentation\nmethods in processing C. elegans occlusion images.",
      "tldr_zh": "该论文针对 C. elegans 的重叠图像分割挑战，提出了一种 Bilayer Segmentation-Recombination Network (BR-Net)，以解决 nematodes 重叠导致的边界模糊和分割不准确问题。BR-Net 由 Coarse Mask Segmentation Module (CMSM) 提取粗糙掩码并引入 Unified Attention Module (UAM)、Bilayer Segmentation Module (BSM) 分割重叠和非重叠区域，以及 Semantic Consistency Recombination Module (SCRM) 通过语义一致性正则化实现精确实例整合。实验结果显示，BR-Net 在 C. elegans 数据集上优于其他实例分割方法，尤其在处理重叠图像时表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17557v1",
      "published_date": "2024-11-26 16:18:59 UTC",
      "updated_date": "2024-11-26 16:18:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:37:23.648224"
    },
    {
      "arxiv_id": "2411.17543v1",
      "title": "Rapid Deployment of Domain-specific Hyperspectral Image Processors with Application to Autonomous Driving",
      "title_zh": "领域特定超光谱图像处理器的快速部署及其在自动驾驶中的应用",
      "authors": [
        "Jon Gutiérrez-Zaballa",
        "Koldo Basterretxea",
        "Javier Echanobe",
        "Óscar Mata-Carballeira",
        "M. Victoria Martínez"
      ],
      "abstract": "The article discusses the use of low cost System-On-Module (SOM) platforms\nfor the implementation of efficient hyperspectral imaging (HSI) processors for\napplication in autonomous driving. The work addresses the challenges of shaping\nand deploying multiple layer fully convolutional networks (FCN) for\nlow-latency, on-board image semantic segmentation using resource- and\npower-constrained processing devices. The paper describes in detail the steps\nfollowed to redesign and customize a successfully trained HSI segmentation\nlightweight FCN that was previously tested on a high-end heterogeneous\nmultiprocessing system-on-chip (MPSoC) to accommodate it to the constraints\nimposed by a low-cost SOM. This SOM features a lower-end but much cheaper MPSoC\nsuitable for the deployment of automatic driving systems (ADS). In particular\nthe article reports the data- and hardware-specific quantization techniques\nutilized to fit the FCN into a commercial fixed-point programmable AI\ncoprocessor IP, and proposes a full customized post-training quantization\nscheme to reduce computation and storage costs without compromising\nsegmentation accuracy.",
      "tldr_zh": "本论文探讨了使用低成本System-On-Module (SOM)平台快速部署域特定超光谱成像 (HSI) 处理器的方法，针对自动驾驶应用中的低延迟图像语义分割挑战。研究团队通过重新设计和自定义一个轻量级fully convolutional networks (FCN)，将其从高端heterogeneous multiprocessing system-on-chip (MPSoC)移植到更便宜的低端MPSoC平台，并应用数据和硬件特定的量化技术，以适应商业固定点可编程AI协处理器IP。最终，提出的全自定义后训练量化方案显著降低了计算和存储成本，同时保持了HSI分割的准确性，为资源受限的自动驾驶系统 (ADS) 提供了高效部署方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.AR",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17543v1",
      "published_date": "2024-11-26 16:04:20 UTC",
      "updated_date": "2024-11-26 16:04:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:37:36.205878"
    },
    {
      "arxiv_id": "2411.17539v1",
      "title": "AI-Augmented Ethical Hacking: A Practical Examination of Manual Exploitation and Privilege Escalation in Linux Environments",
      "title_zh": "AI 增强的道德黑客：Linux 环境中手动漏洞利用和权限提升的实际考察",
      "authors": [
        "Haitham S. Al-Sinani",
        "Chris J. Mitchell"
      ],
      "abstract": "This study explores the application of generative AI (GenAI) within manual\nexploitation and privilege escalation tasks in Linux-based penetration testing\nenvironments, two areas critical to comprehensive cybersecurity assessments.\nBuilding on previous research into the role of GenAI in the ethical hacking\nlifecycle, this paper presents a hands-on experimental analysis conducted in a\ncontrolled virtual setup to evaluate the utility of GenAI in supporting these\ncrucial, often manual, tasks. Our findings demonstrate that GenAI can\nstreamline processes, such as identifying potential attack vectors and parsing\ncomplex outputs for sensitive data during privilege escalation. The study also\nidentifies key benefits and challenges associated with GenAI, including\nenhanced efficiency and scalability, alongside ethical concerns related to data\nprivacy, unintended discovery of vulnerabilities, and potential for misuse.\nThis work contributes to the growing field of AI-assisted cybersecurity by\nemphasising the importance of human-AI collaboration, especially in contexts\nrequiring careful decision-making, rather than the complete replacement of\nhuman input.",
      "tldr_zh": "这篇论文探讨了生成式 AI (GenAI) 在 Linux 环境中的手动利用和权限提升任务中的应用，通过受控虚拟实验评估其在渗透测试中的效用。研究发现，GenAI 可以简化过程，如识别潜在攻击向量和解析复杂输出以获取敏感数据，从而提升效率和可扩展性。论文同时指出了伦理挑战，包括数据隐私风险、意外发现漏洞以及潜在误用，并强调人类-AI 协作在需要谨慎决策的场景中的重要性，而不是完全取代人类输入。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.CR",
      "comment": "101 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.17539v1",
      "published_date": "2024-11-26 15:55:15 UTC",
      "updated_date": "2024-11-26 15:55:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:37:47.060800"
    },
    {
      "arxiv_id": "2411.17530v1",
      "title": "HSI-Drive v2.0: More Data for New Challenges in Scene Understanding for Autonomous Driving",
      "title_zh": "HSI-Drive v2.0：更多数据用于自动驾驶场景理解的新挑战",
      "authors": [
        "Jon Gutiérrez-Zaballa",
        "Koldo Basterretxea",
        "Javier Echanobe",
        "M. Victoria Martínez",
        "Unai Martínez-Corral"
      ],
      "abstract": "We present the updated version of the HSI-Drive dataset aimed at developing\nautomated driving systems (ADS) using hyperspectral imaging (HSI). The v2.0\nversion includes new annotated images from videos recorded during winter and\nfall in real driving scenarios. Added to the spring and summer images included\nin the previous v1.1 version, the new dataset contains 752 images covering the\nfour seasons. In this paper, we show the improvements achieved over previously\npublished results obtained on the v1.1 dataset, showcasing the enhanced\nperformance of models trained on the new v2.0 dataset. We also show the\nprogress made in comprehensive scene understanding by experimenting with more\ncapable image segmentation models. These models include new segmentation\ncategories aimed at the identification of essential road safety objects such as\nthe presence of vehicles and road signs, as well as highly vulnerable groups\nlike pedestrians and cyclists. In addition, we provide evidence of the\nperformance and robustness of the models when applied to segmenting HSI video\nsequences captured in various environments and conditions. Finally, for a\ncorrect assessment of the results described in this work, the constraints\nimposed by the processing platforms that can sensibly be deployed in vehicles\nfor ADS must be taken into account. Thus, and although implementation details\nare out of the scope of this paper, we focus our research on the development of\ncomputationally efficient, lightweight ML models that can eventually operate at\nhigh throughput rates. The dataset and some examples of segmented videos are\navailable in https://ipaccess.ehu.eus/HSI-Drive/.",
      "tldr_zh": "本研究介绍了 HSI-Drive v2.0 数据集的更新版本，该数据集针对自主驾驶系统 (ADS) 使用 hyperspectral imaging (HSI) 技术，新增了冬季和秋季的真实驾驶场景图像，总共包含覆盖四个季节的 752 张标注图像。相比 v1.1 版本，研究者通过训练更先进的图像分割模型，显著提升了场景理解性能，例如更好地识别车辆、路标、行人和骑行者等关键安全对象。实验结果显示，模型在各种环境和条件下表现出更高的准确性和鲁棒性，同时注重开发计算高效的轻量级机器学习模型，以适应车辆部署需求。数据集及其分割视频示例可从指定链接获取。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17530v1",
      "published_date": "2024-11-26 15:45:59 UTC",
      "updated_date": "2024-11-26 15:45:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:37:59.997762"
    },
    {
      "arxiv_id": "2411.17790v2",
      "title": "Self-supervised Monocular Depth and Pose Estimation for Endoscopy with Generative Latent Priors",
      "title_zh": "翻译失败",
      "authors": [
        "Ziang Xu",
        "Bin Li",
        "Yang Hu",
        "Chenyu Zhang",
        "James East",
        "Sharib Ali",
        "Jens Rittscher"
      ],
      "abstract": "Accurate 3D mapping in endoscopy enables quantitative, holistic lesion\ncharacterization within the gastrointestinal (GI) tract, requiring reliable\ndepth and pose estimation. However, endoscopy systems are monocular, and\nexisting methods relying on synthetic datasets or complex models often lack\ngeneralizability in challenging endoscopic conditions. We propose a robust\nself-supervised monocular depth and pose estimation framework that incorporates\na Generative Latent Bank and a Variational Autoencoder (VAE). The Generative\nLatent Bank leverages extensive depth scenes from natural images to condition\nthe depth network, enhancing realism and robustness of depth predictions\nthrough latent feature priors. For pose estimation, we reformulate it within a\nVAE framework, treating pose transitions as latent variables to regularize\nscale, stabilize z-axis prominence, and improve x-y sensitivity. This dual\nrefinement pipeline enables accurate depth and pose predictions, effectively\naddressing the GI tract's complex textures and lighting. Extensive evaluations\non SimCol and EndoSLAM datasets confirm our framework's superior performance\nover published self-supervised methods in endoscopic depth and pose estimation.",
      "tldr_zh": "本研究提出了一种自监督的单目深度和姿态估计框架，用于内窥镜系统，以解决现有方法在复杂内窥镜条件下泛化性不足的问题。框架整合了Generative Latent Bank，利用自然图像的深度场景作为潜在特征先验来增强深度网络的真实性和鲁棒性；同时，通过Variational Autoencoder (VAE)重新表述姿态估计，将姿态转换视为潜在变量，以调节尺度、稳定z轴突出度和改善x-y敏感性。该双重精炼管道有效处理胃肠道复杂纹理和光照，在SimCol和EndoSLAM数据集上的评估显示，该框架在自监督内窥镜深度和姿态估计方面优于现有方法。总的来说，此框架为准确的3D映射和病变表征提供了可靠基础。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17790v2",
      "published_date": "2024-11-26 15:43:06 UTC",
      "updated_date": "2024-12-09 14:14:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:39:39.259351"
    },
    {
      "arxiv_id": "2411.17522v1",
      "title": "On Statistical Rates of Conditional Diffusion Transformers: Approximation, Estimation and Minimax Optimality",
      "title_zh": "翻译失败",
      "authors": [
        "Jerry Yao-Chieh Hu",
        "Weimin Wu",
        "Yi-Chen Lee",
        "Yu-Chao Huang",
        "Minshuo Chen",
        "Han Liu"
      ],
      "abstract": "We investigate the approximation and estimation rates of conditional\ndiffusion transformers (DiTs) with classifier-free guidance. We present a\ncomprehensive analysis for ``in-context'' conditional DiTs under four common\ndata assumptions. We show that both conditional DiTs and their latent variants\nlead to the minimax optimality of unconditional DiTs under identified settings.\nSpecifically, we discretize the input domains into infinitesimal grids and then\nperform a term-by-term Taylor expansion on the conditional diffusion score\nfunction under H\\\"older smooth data assumption. This enables fine-grained use\nof transformers' universal approximation through a more detailed piecewise\nconstant approximation and hence obtains tighter bounds. Additionally, we\nextend our analysis to the latent setting under the linear latent subspace\nassumption. We not only show that latent conditional DiTs achieve lower bounds\nthan conditional DiTs both in approximation and estimation, but also show the\nminimax optimality of latent unconditional DiTs. Our findings establish\nstatistical limits for conditional and unconditional DiTs, and offer practical\nguidance toward developing more efficient and accurate DiT models.",
      "tldr_zh": "本文研究了条件扩散变换器 (conditional diffusion transformers, DiTs) 的逼近和估计率，采用无分类器引导 (classifier-free guidance)，并在四种常见数据假设下分析了“in-context”条件 DiTs 的性能。作者通过将输入域离散化为微小网格，进行逐项 Taylor 展开并结合 Hölder 平滑数据假设，实现了 transformers 的精细化通用逼近，从而获得了更紧凑的边界。研究发现，条件 DiTs 及其潜在变体 (latent variants) 在特定设置下达到了无条件 DiTs 的最小最大最优性 (minimax optimality)，而潜在条件 DiTs 在逼近和估计方面表现出色。总体而言，该工作确立了 DiTs 的统计限制，并为开发更高效、准确的模型提供了实用指导。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17522v1",
      "published_date": "2024-11-26 15:30:48 UTC",
      "updated_date": "2024-11-26 15:30:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:38:24.123287"
    },
    {
      "arxiv_id": "2411.17788v2",
      "title": "Geometric Point Attention Transformer for 3D Shape Reassembly",
      "title_zh": "几何点注意力变换器用于3D形状重组",
      "authors": [
        "Jiahan Li",
        "Chaoran Cheng",
        "Jianzhu Ma",
        "Ge Liu"
      ],
      "abstract": "Shape assembly, which aims to reassemble separate parts into a complete\nobject, has gained significant interest in recent years. Existing methods\nprimarily rely on networks to predict the poses of individual parts, but often\nfail to effectively capture the geometric interactions between the parts and\ntheir poses. In this paper, we present the Geometric Point Attention\nTransformer (GPAT), a network specifically designed to address the challenges\nof reasoning about geometric relationships. In the geometric point attention\nmodule, we integrate both global shape information and local pairwise geometric\nfeatures, along with poses represented as rotation and translation vectors for\neach part. To enable iterative updates and dynamic reasoning, we introduce a\ngeometric recycling scheme, where each prediction is fed into the next\niteration for refinement. We evaluate our model on both the semantic and\ngeometric assembly tasks, showing that it outperforms previous methods in\nabsolute pose estimation, achieving accurate pose predictions and high\nalignment accuracy.",
      "tldr_zh": "本文提出 Geometric Point Attention Transformer (GPAT)，一种针对 3D 形状重新组装的网络，旨在解决现有方法在捕捉部分之间几何交互方面的不足。GPAT 通过几何点注意力模块整合全局形状信息、局部成对几何特征以及每个部分的旋转和平移向量表示的姿势，并引入几何回收方案进行迭代更新和动态推理。在语义和几何装配任务上，GPAT 在绝对姿势估计中优于先前方法，实现了更准确的姿势预测和高对齐精度。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17788v2",
      "published_date": "2024-11-26 15:29:38 UTC",
      "updated_date": "2024-12-01 08:00:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:39:39.436973"
    },
    {
      "arxiv_id": "2411.18463v3",
      "title": "Hotspot-Driven Peptide Design via Multi-Fragment Autoregressive Extension",
      "title_zh": "基于多片段自回归扩展的热点驱动肽设计",
      "authors": [
        "Jiahan Li",
        "Tong Chen",
        "Shitong Luo",
        "Chaoran Cheng",
        "Jiaqi Guan",
        "Ruihan Guo",
        "Sheng Wang",
        "Ge Liu",
        "Jian Peng",
        "Jianzhu Ma"
      ],
      "abstract": "Peptides, short chains of amino acids, interact with target proteins, making\nthem a unique class of protein-based therapeutics for treating human diseases.\nRecently, deep generative models have shown great promise in peptide\ngeneration. However, several challenges remain in designing effective peptide\nbinders. First, not all residues contribute equally to peptide-target\ninteractions. Second, the generated peptides must adopt valid geometries due to\nthe constraints of peptide bonds. Third, realistic tasks for peptide drug\ndevelopment are still lacking. To address these challenges, we introduce\nPepHAR, a hot-spot-driven autoregressive generative model for designing\npeptides targeting specific proteins. Building on the observation that certain\nhot spot residues have higher interaction potentials, we first use an\nenergy-based density model to fit and sample these key residues. Next, to\nensure proper peptide geometry, we autoregressively extend peptide fragments by\nestimating dihedral angles between residue frames. Finally, we apply an\noptimization process to iteratively refine fragment assembly, ensuring correct\npeptide structures. By combining hot spot sampling with fragment-based\nextension, our approach enables de novo peptide design tailored to a target\nprotein and allows the incorporation of key hot spot residues into peptide\nscaffolds. Extensive experiments, including peptide design and peptide scaffold\ngeneration, demonstrate the strong potential of PepHAR in computational peptide\nbinder design. Source code will be available at\nhttps://github.com/Ced3-han/PepHAR.",
      "tldr_zh": "本文提出了一种名为 PepHAR 的热点驱动自回归生成模型，用于设计针对特定蛋白的 peptides，以解决肽生成中的不均等残基贡献、几何约束和任务缺失等问题。该模型首先利用 energy-based density model 拟合并采样关键 hot spot residues，然后通过估计 dihedral angles 的多片段自回归扩展来确保肽结构的正确性，并采用迭代优化过程组装片段。实验结果显示，PepHAR 在 de novo peptide design 和肽支架生成任务中表现出色，证明了其在计算肽结合物设计中的强大潜力。",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.BM",
      "comment": "Published as a conference paper at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2411.18463v3",
      "published_date": "2024-11-26 15:13:17 UTC",
      "updated_date": "2025-05-20 14:55:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:38:47.307843"
    },
    {
      "arxiv_id": "2411.17501v2",
      "title": "Inference Scaling fLaws: The Limits of LLM Resampling with Imperfect Verifiers",
      "title_zh": "翻译失败",
      "authors": [
        "Benedikt Stroebl",
        "Sayash Kapoor",
        "Arvind Narayanan"
      ],
      "abstract": "Recent research has generated hope that inference scaling could allow weaker\nlanguage models to match or exceed the accuracy of stronger models, such as by\nrepeatedly sampling solutions to a coding problem until it passes unit tests.\nThe central thesis of this paper is that there is no free lunch for inference\nscaling: indefinite accuracy improvement through resampling can only be\nrealized if the \"verifier\" (in this case, a set of unit tests) is perfect. When\nthe verifier is imperfect, as it almost always is in domains such as reasoning\nor coding (for example, unit tests have imperfect coverage), there is a nonzero\nprobability of false positives: incorrect solutions that pass the verifier.\nResampling cannot decrease this probability, so it imposes an upper bound to\nthe accuracy of resampling-based inference scaling even with an infinite\ncompute budget. We find that there is a very strong correlation between the\nmodel's single-sample accuracy (i.e. accuracy without unit tests) and its false\npositive rate on coding benchmarks HumanEval and MBPP, whose unit tests have\nlimited coverage. Therefore, no amount of inference scaling of weaker models\ncan enable them to match the single-sample accuracy of a sufficiently strong\nmodel (Fig. 1a). When we consider that false positives have a negative utility\ncompared to abstaining from producing a solution, it bends the inference\nscaling curve further downward. Empirically, we find that the optimal number of\nsamples can be less than 10 under realistic assumptions (Fig. 1b). Finally, we\nshow that beyond accuracy, false positives may have other undesirable\nqualities, such as poor adherence to coding style conventions.",
      "tldr_zh": "这篇论文揭示了LLM（Large Language Models）通过resampling进行inference scaling的局限性，即当verifiers（如单元测试）不完美时，无法无限提升准确性。核心论点是，imperfect verifiers会导致false positives（错误的解决方案通过验证），从而为resampling-based inference scaling设置了准确性上限，即使计算资源无限。研究发现，模型的single-sample accuracy与false positives率在HumanEval和MBPP基准上高度相关，因此较弱模型无法通过resampling达到强模型的水平。实验结果显示，考虑false positives的负面效用（如降低整体效用和不符合编码风格），最优样本数通常少于10，这为LLM应用提供了重要启示。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17501v2",
      "published_date": "2024-11-26 15:13:06 UTC",
      "updated_date": "2024-12-02 18:54:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:39:00.696720"
    },
    {
      "arxiv_id": "2411.17786v1",
      "title": "DreamCache: Finetuning-Free Lightweight Personalized Image Generation via Feature Caching",
      "title_zh": "翻译失败",
      "authors": [
        "Emanuele Aiello",
        "Umberto Michieli",
        "Diego Valsesia",
        "Mete Ozay",
        "Enrico Magli"
      ],
      "abstract": "Personalized image generation requires text-to-image generative models that\ncapture the core features of a reference subject to allow for controlled\ngeneration across different contexts. Existing methods face challenges due to\ncomplex training requirements, high inference costs, limited flexibility, or a\ncombination of these issues. In this paper, we introduce DreamCache, a scalable\napproach for efficient and high-quality personalized image generation. By\ncaching a small number of reference image features from a subset of layers and\na single timestep of the pretrained diffusion denoiser, DreamCache enables\ndynamic modulation of the generated image features through lightweight, trained\nconditioning adapters. DreamCache achieves state-of-the-art image and text\nalignment, utilizing an order of magnitude fewer extra parameters, and is both\nmore computationally effective and versatile than existing models.",
      "tldr_zh": "这篇论文介绍了 DreamCache，一种无需微调(Finetuning-Free)的轻量级个性化图像生成方法，通过缓存参考图像的少量特征（来自预训练扩散去噪器的子集层和单个时间步）来实现高效生成。DreamCache 利用轻量级条件适配器动态调节生成的图像特征，从而提升图像和文本对齐的灵活性。相比现有模型，该方法使用数量级更少的额外参数，实现了最先进的性能，同时更高效和多功能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "16 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.17786v1",
      "published_date": "2024-11-26 15:03:14 UTC",
      "updated_date": "2024-11-26 15:03:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:39:10.740516"
    },
    {
      "arxiv_id": "2411.17491v1",
      "title": "What's in the Image? A Deep-Dive into the Vision of Vision Language Models",
      "title_zh": "图像中有什么？ 视觉语言模型视觉能力的深入剖析",
      "authors": [
        "Omri Kaduri",
        "Shai Bagon",
        "Tali Dekel"
      ],
      "abstract": "Vision-Language Models (VLMs) have recently demonstrated remarkable\ncapabilities in comprehending complex visual content. However, the mechanisms\nunderlying how VLMs process visual information remain largely unexplored. In\nthis paper, we conduct a thorough empirical analysis, focusing on attention\nmodules across layers. We reveal several key insights about how these models\nprocess visual data: (i) the internal representation of the query tokens (e.g.,\nrepresentations of \"describe the image\"), is utilized by VLMs to store global\nimage information; we demonstrate that these models generate surprisingly\ndescriptive responses solely from these tokens, without direct access to image\ntokens. (ii) Cross-modal information flow is predominantly influenced by the\nmiddle layers (approximately 25% of all layers), while early and late layers\ncontribute only marginally.(iii) Fine-grained visual attributes and object\ndetails are directly extracted from image tokens in a spatially localized\nmanner, i.e., the generated tokens associated with a specific object or\nattribute attend strongly to their corresponding regions in the image. We\npropose novel quantitative evaluation to validate our observations, leveraging\nreal-world complex visual scenes. Finally, we demonstrate the potential of our\nfindings in facilitating efficient visual processing in state-of-the-art VLMs.",
      "tldr_zh": "本论文深入探讨了Vision Language Models (VLMs)处理视觉信息的过程，通过对注意力模块的实证分析，揭示了VLMs的关键机制：查询标记（如“describe the image”）可独立存储全局图像信息并生成描述性响应，而无需直接访问图像标记。研究发现，跨模态信息流动主要发生在中间层（约25%的层），早晚层贡献有限，且细粒度视觉属性和对象细节以空间本地化方式从图像标记中提取。作者提出了新颖的定量评估方法，使用真实复杂视觉场景验证这些观察，并展示了这些发现如何促进VLMs的高效视觉处理。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17491v1",
      "published_date": "2024-11-26 14:59:06 UTC",
      "updated_date": "2024-11-26 14:59:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:39:23.241416"
    },
    {
      "arxiv_id": "2411.17489v2",
      "title": "Puzzle Similarity: A Perceptually-guided Cross-Reference Metric for Artifact Detection in 3D Scene Reconstructions",
      "title_zh": "翻译失败",
      "authors": [
        "Nicolai Hermann",
        "Jorge Condor",
        "Piotr Didyk"
      ],
      "abstract": "Modern reconstruction techniques can effectively model complex 3D scenes from\nsparse 2D views. However, automatically assessing the quality of novel views\nand identifying artifacts is challenging due to the lack of ground truth images\nand the limitations of No-Reference image metrics in predicting reliable\nartifact maps. The absence of such metrics hinders the assessment of the\nquality of novel views and limits the adoption of post-processing techniques,\nsuch as inpainting, to enhance reconstruction quality. To tackle this, recent\nwork has established a new category of metrics (Cross-Reference), predicting\nimage quality solely by leveraging context from alternate viewpoint captures\n(arXiv:2404.14409). In this work, we propose a new Cross-Reference metric,\nPuzzle Similarity, which is designed to localize artifacts in novel views. Our\napproach utilizes image patch statistics from the input views to establish a\nscene-specific distribution, later used to identify poorly reconstructed\nregions in the novel views. Given the lack of good measures to evaluate\nCross-Reference methods in the context of 3D reconstruction, we collected a\nnovel human-labeled dataset of artifact and distortion maps in unseen\nreconstructed views. Through this dataset, we demonstrate that our method\nachieves state-of-the-art localization of artifacts in novel views, correlating\nwith human assessment, even without aligned references. We can leverage our new\nmetric to enhance applications like automatic image restoration, guided\nacquisition, or 3D reconstruction from sparse inputs. Find the project page at\nhttps://nihermann.github.io/puzzlesim/ .",
      "tldr_zh": "本文提出了一种感知引导的Cross-Reference指标，Puzzle Similarity，用于检测3D Scene Reconstructions中的伪像。该方法利用输入视图的图像补丁统计建立场景特定分布，从而识别新视图中重建不佳的区域。针对评估Cross-Reference方法的不足，研究者收集了一个新的人类标记数据集，包含未见重建视图的伪像和扭曲地图。实验结果显示，Puzzle Similarity在伪像定位方面达到了最先进水平，与人类评估高度相关，并可应用于自动图像修复、引导数据获取和从稀疏输入的3D重建优化。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG",
        "68T07, 68T45, 68T10",
        "I.4; I.3; I.2"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17489v2",
      "published_date": "2024-11-26 14:57:30 UTC",
      "updated_date": "2025-03-12 09:04:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:39:36.325736"
    },
    {
      "arxiv_id": "2411.17465v1",
      "title": "ShowUI: One Vision-Language-Action Model for GUI Visual Agent",
      "title_zh": "翻译失败",
      "authors": [
        "Kevin Qinghong Lin",
        "Linjie Li",
        "Difei Gao",
        "Zhengyuan Yang",
        "Shiwei Wu",
        "Zechen Bai",
        "Weixian Lei",
        "Lijuan Wang",
        "Mike Zheng Shou"
      ],
      "abstract": "Building Graphical User Interface (GUI) assistants holds significant promise\nfor enhancing human workflow productivity. While most agents are\nlanguage-based, relying on closed-source API with text-rich meta-information\n(e.g., HTML or accessibility tree), they show limitations in perceiving UI\nvisuals as humans do, highlighting the need for GUI visual agents. In this\nwork, we develop a vision-language-action model in digital world, namely\nShowUI, which features the following innovations: (i) UI-Guided Visual Token\nSelection to reduce computational costs by formulating screenshots as an UI\nconnected graph, adaptively identifying their redundant relationship and serve\nas the criteria for token selection during self-attention blocks; (ii)\nInterleaved Vision-Language-Action Streaming that flexibly unifies diverse\nneeds within GUI tasks, enabling effective management of visual-action history\nin navigation or pairing multi-turn query-action sequences per screenshot to\nenhance training efficiency; (iii) Small-scale High-quality GUI\nInstruction-following Datasets by careful data curation and employing a\nresampling strategy to address significant data type imbalances. With above\ncomponents, ShowUI, a lightweight 2B model using 256K data, achieves a strong\n75.1% accuracy in zero-shot screenshot grounding. Its UI-guided token selection\nfurther reduces 33% of redundant visual tokens during training and speeds up\nthe performance by 1.4x. Navigation experiments across web Mind2Web, mobile\nAITW, and online MiniWob environments further underscore the effectiveness and\npotential of our model in advancing GUI visual agents. The models are available\nat https://github.com/showlab/ShowUI.",
      "tldr_zh": "这篇论文介绍了ShowUI，一种集成视觉-语言-动作的模型，旨在为图形用户界面(GUI)视觉代理提供高效解决方案，以更好地模仿人类对UI视觉的感知。创新点包括UI-Guided Visual Token Selection，通过将截图建模为UI连接图来适应性选择标记，减少33%的冗余计算并加速性能1.4倍；Interleaved Vision-Language-Action Streaming，用于统一任务管理并提升多轮查询训练效率；以及小规模高质量GUI指令数据集，通过数据精选和重采样策略解决数据不平衡问题。实验结果显示，该轻量级2B模型在零样本截图grounding任务上达到75.1%准确率，并在Mind2Web、AITW和MiniWob等导航环境中表现出色，证明了其在提升GUI代理有效性的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.CV",
      "comment": "Technical Report. Github: https://github.com/showlab/ShowUI",
      "pdf_url": "http://arxiv.org/pdf/2411.17465v1",
      "published_date": "2024-11-26 14:29:47 UTC",
      "updated_date": "2024-11-26 14:29:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:39:48.278744"
    },
    {
      "arxiv_id": "2411.17461v3",
      "title": "SoK: Decentralized AI (DeAI)",
      "title_zh": "SoK: 去中心化 AI (DeAI)",
      "authors": [
        "Zhipeng Wang",
        "Rui Sun",
        "Elizabeth Lui",
        "Vatsal Shah",
        "Xihan Xiong",
        "Jiahao Sun",
        "Davide Crapis",
        "William Knottenbelt"
      ],
      "abstract": "Centralization enhances the efficiency of Artificial Intelligence (AI), but\nit also brings critical challenges, such as single points of failure, inherent\nbiases, data privacy concerns, and scalability issues, for AI systems. These\nproblems are especially common in closed-source large language models (LLMs),\nwhere user data is collected and used with full transparency. To address these\nissues, blockchain-based decentralized AI (DeAI) has been introduced. DeAI\nleverages the strengths of blockchain technologies to enhance the transparency,\nsecurity, decentralization, as well as trustworthiness of AI systems. Although\nDeAI has been widely developed in industry, a comprehensive understanding of\nstate-of-the-art practical DeAI solutions is still lacking. In this work, we\npresent a Systematization of Knowledge (SoK) for blockchain-based DeAI\nsolutions. We propose a taxonomy to classify existing DeAI protocols based on\nthe model lifecycle. Based on this taxonomy, we provide a structured way to\nclarify the landscape of DeAI protocols and identify their similarities and\ndifferences. Specifically, we analyze the functionalities of blockchain in\nDeAI, investigate how blockchain features contribute to enhancing the security,\ntransparency, and trustworthiness of AI processes, and also ensure fair\nincentives for AI data and model contributors. In addition, we provide key\ninsights and research gaps in developing DeAI protocols for future research.",
      "tldr_zh": "这篇论文（SoK: Decentralized AI (DeAI)）系统化了区块链-based DeAI 解决方案，针对中央化 AI 的问题如单点故障、偏见和数据隐私担忧，强调区块链如何提升 AI 的透明度、安全性和可信度。作者提出一个基于模型生命周期的分类法（taxonomy），用于分类现有 DeAI 协议，并分析区块链的功能以确保公平激励 AI 数据和模型贡献者。最终，论文总结了 DeAI 领域的关键洞见和研究空白，为未来 DeAI 协议开发提供了指导。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "This is a Systematization of Knowledge (SoK) for the rapidly evolving\n  field of Decentralized AI (DeAI). We welcome valuable comments, suggestions,\n  and collaboration to further refine and enhance this work. We hope our\n  contribution will help accelerate the advancement of DeAI",
      "pdf_url": "http://arxiv.org/pdf/2411.17461v3",
      "published_date": "2024-11-26 14:28:25 UTC",
      "updated_date": "2025-04-16 12:51:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:39:59.330967"
    },
    {
      "arxiv_id": "2411.17459v3",
      "title": "WF-VAE: Enhancing Video VAE by Wavelet-Driven Energy Flow for Latent Video Diffusion Model",
      "title_zh": "WF-VAE：通过小波驱动的能量流动增强视频 VAE 用于潜在视频扩散模型",
      "authors": [
        "Zongjian Li",
        "Bin Lin",
        "Yang Ye",
        "Liuhan Chen",
        "Xinhua Cheng",
        "Shenghai Yuan",
        "Li Yuan"
      ],
      "abstract": "Video Variational Autoencoder (VAE) encodes videos into a low-dimensional\nlatent space, becoming a key component of most Latent Video Diffusion Models\n(LVDMs) to reduce model training costs. However, as the resolution and duration\nof generated videos increase, the encoding cost of Video VAEs becomes a\nlimiting bottleneck in training LVDMs. Moreover, the block-wise inference\nmethod adopted by most LVDMs can lead to discontinuities of latent space when\nprocessing long-duration videos. The key to addressing the computational\nbottleneck lies in decomposing videos into distinct components and efficiently\nencoding the critical information. Wavelet transform can decompose videos into\nmultiple frequency-domain components and improve the efficiency significantly,\nwe thus propose Wavelet Flow VAE (WF-VAE), an autoencoder that leverages\nmulti-level wavelet transform to facilitate low-frequency energy flow into\nlatent representation. Furthermore, we introduce a method called Causal Cache,\nwhich maintains the integrity of latent space during block-wise inference.\nCompared to state-of-the-art video VAEs, WF-VAE demonstrates superior\nperformance in both PSNR and LPIPS metrics, achieving 2x higher throughput and\n4x lower memory consumption while maintaining competitive reconstruction\nquality. Our code and models are available at\nhttps://github.com/PKU-YuanGroup/WF-VAE.",
      "tldr_zh": "该研究针对 Video VAE 在 Latent Video Diffusion Models (LVDMs) 中的编码瓶颈问题，提出了一种名为 WF-VAE 的框架，利用多级 Wavelet transform 分解视频成不同频率组件，并通过 Wavelet-Driven Energy Flow 将低频能量引导至潜在表示，以提高编码效率。 此外，WF-VAE 引入 Causal Cache 方法，确保块式推理过程中长视频潜在空间的连续性和完整性。 与现有视频 VAEs 相比，该方法在 PSNR 和 LPIPS 指标上表现出优越性能，同时实现了 2 倍更高的吞吐量和 4 倍更低的内存消耗，同时保持了竞争力的视频重建质量。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.17459v3",
      "published_date": "2024-11-26 14:23:53 UTC",
      "updated_date": "2025-04-11 12:31:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:40:12.109086"
    },
    {
      "arxiv_id": "2411.17458v1",
      "title": "Spatially Visual Perception for End-to-End Robotic Learning",
      "title_zh": "空间视觉感知用于端到端机器人学习",
      "authors": [
        "Travis Davies",
        "Jiahuan Yan",
        "Xiang Chen",
        "Yu Tian",
        "Yueting Zhuang",
        "Yiqi Huang",
        "Luhui Hu"
      ],
      "abstract": "Recent advances in imitation learning have shown significant promise for\nrobotic control and embodied intelligence. However, achieving robust\ngeneralization across diverse mounted camera observations remains a critical\nchallenge. In this paper, we introduce a video-based spatial perception\nframework that leverages 3D spatial representations to address environmental\nvariability, with a focus on handling lighting changes. Our approach integrates\na novel image augmentation technique, AugBlender, with a state-of-the-art\nmonocular depth estimation model trained on internet-scale data. Together,\nthese components form a cohesive system designed to enhance robustness and\nadaptability in dynamic scenarios. Our results demonstrate that our approach\nsignificantly boosts the success rate across diverse camera exposures, where\nprevious models experience performance collapse. Our findings highlight the\npotential of video-based spatial perception models in advancing robustness for\nend-to-end robotic learning, paving the way for scalable, low-cost solutions in\nembodied intelligence.",
      "tldr_zh": "这篇论文提出了一种基于视频的空间感知框架，利用 3D spatial representations 来解决模仿 learning 在不同摄像头观察下的泛化挑战，特别是光照变化问题。该框架整合了新型图像增强技术 AugBlender 和一个基于互联网规模数据的 monocular depth estimation 模型，提升了动态场景中的鲁棒性和适应性。实验结果显示，该方法显著提高了各种摄像头曝光条件下的成功率，而先前模型则出现性能下降，为端到端 robotic learning 提供了可扩展、低成本的智能体解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.17458v1",
      "published_date": "2024-11-26 14:23:42 UTC",
      "updated_date": "2024-11-26 14:23:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:40:23.163514"
    },
    {
      "arxiv_id": "2411.17438v2",
      "title": "Object-centric proto-symbolic behavioural reasoning from pixels",
      "title_zh": "翻译失败",
      "authors": [
        "Ruben van Bergen",
        "Justus Hübotter",
        "Pablo Lanillos"
      ],
      "abstract": "Autonomous intelligent agents must bridge computational challenges at\ndisparate levels of abstraction, from the low-level spaces of sensory input and\nmotor commands to the high-level domain of abstract reasoning and planning. A\nkey question in designing such agents is how best to instantiate the\nrepresentational space that will interface between these two levels -- ideally\nwithout requiring supervision in the form of expensive data annotations. These\nobjectives can be efficiently achieved by representing the world in terms of\nobjects (grounded in perception and action). In this work, we present a novel,\nbrain-inspired, deep-learning architecture that learns from pixels to\ninterpret, control, and reason about its environment, using object-centric\nrepresentations. We show the utility of our approach through tasks in synthetic\nenvironments that require a combination of (high-level) logical reasoning and\n(low-level) continuous control. Results show that the agent can learn emergent\nconditional behavioural reasoning, such as $(A \\to B) \\land (\\neg A \\to C)$, as\nwell as logical composition $(A \\to B) \\land (A \\to C) \\vdash A \\to (B \\land\nC)$ and XOR operations, and successfully controls its environment to satisfy\nobjectives deduced from these logical rules. The agent can adapt online to\nunexpected changes in its environment and is robust to mild violations of its\nworld model, thanks to dynamic internal desired goal generation. While the\npresent results are limited to synthetic settings (2D and 3D activated versions\nof dSprites), which fall short of real-world levels of complexity, the proposed\narchitecture shows how to manipulate grounded object representations, as a key\ninductive bias for unsupervised learning, to enable behavioral reasoning.",
      "tldr_zh": "该论文提出了一种脑启发的深度学习架构，使用 object-centric representations，从像素直接学习环境解释、控制和推理，从而桥接低级感官输入与高级抽象推理，而无需监督标注。架构通过物体中心表示支持代理在合成环境中执行逻辑推理和连续控制任务，例如学习紧急条件行为推理如 $(A \\to B) \\land (\\neg A \\to C)$、逻辑组合 $(A \\to B) \\land (A \\to C) \\vdash A \\to (B \\land C)$ 以及 XOR 操作。实验结果显示，代理能在线适应环境变化，并对世界模型的轻微违反保持鲁棒性。总体而言，此方法强调了 object-centric representations 作为无监督学习的归纳偏差，在促进行为推理方面具有潜力，尽管目前限于合成设置如 2D 和 3D dSprites。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.NE",
        "I.2.0; I.2.6; I.2.10"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17438v2",
      "published_date": "2024-11-26 13:54:24 UTC",
      "updated_date": "2025-02-11 11:10:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:40:36.729188"
    },
    {
      "arxiv_id": "2411.17433v1",
      "title": "LC-SVD-DLinear: A low-cost physics-based hybrid machine learning model for data forecasting using sparse measurements",
      "title_zh": "翻译失败",
      "authors": [
        "Ashton Hetherington",
        "Javier López Leonés",
        "Soledad Le Clainche"
      ],
      "abstract": "This article introduces a novel methodology that integrates singular value\ndecomposition (SVD) with a shallow linear neural network for forecasting high\nresolution fluid mechanics data. The method, termed LC-SVD-DLinear, combines a\nlow-cost variant of singular value decomposition (LC-SVD) with the DLinear\narchitecture, which decomposes the input features-specifically, the temporal\ncoefficients-into trend and seasonality components, enabling a shallow neural\nnetwork to capture the non-linear dynamics of the temporal data. This\nmethodology uses under-resolved data, which can either be input directly into\nthe hybrid model or downsampled from high resolution using two distinct\ntechniques provided by the methodology. Working with under-resolved cases helps\nreduce the overall computational cost. Additionally, we present a variant of\nthe method, LC-HOSVD-DLinear, which combines a low-cost version of the\nhigh-order singular value decomposition (LC-HOSVD) algorithm with the DLinear\nnetwork, designed for high-order data. These approaches have been validated\nusing two datasets: first, a numerical simulation of three-dimensional flow\npast a circular cylinder at $Re = 220$; and second, an experimental dataset of\nturbulent flow passing a circular cylinder at $Re = 2600$. The combination of\nthese datasets demonstrates the robustness of the method. The forecasting and\nreconstruction results are evaluated through various error metrics, including\nuncertainty quantification. The work developed in this article will be included\nin the next release of ModelFLOWs-app",
      "tldr_zh": "本论文提出了一种低成本的混合机器学习模型LC-SVD-DLinear，用于利用稀疏测量进行高分辨率流体力学数据的预测。该模型结合了低成本奇异值分解(LC-SVD)和DLinear架构，将输入特征分解为趋势和季节性组件，以捕捉非线性动态，并通过两种下采样技术处理欠解析数据，从而降低计算成本。同时，论文引入了LC-HOSVD-DLinear变体，用于高阶数据的处理，并在Re=220的数值模拟和Re=2600的实验数据集上验证了方法的鲁棒性。结果显示，该方法在预测和重建任务中表现出色，通过各种错误指标和不确定性量化评估了其准确性。该工作将纳入ModelFLOWs-app的下一个版本中。",
      "categories": [
        "physics.flu-dyn",
        "cs.AI"
      ],
      "primary_category": "physics.flu-dyn",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17433v1",
      "published_date": "2024-11-26 13:43:50 UTC",
      "updated_date": "2024-11-26 13:43:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:40:48.640721"
    },
    {
      "arxiv_id": "2411.17429v1",
      "title": "Rewiring Techniques to Mitigate Oversquashing and Oversmoothing in GNNs: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Hugo Attali",
        "Davide Buscaldi",
        "Nathalie Pernelle"
      ],
      "abstract": "Graph Neural Networks (GNNs) are powerful tools for learning from\ngraph-structured data, but their effectiveness is often constrained by two\ncritical challenges: oversquashing, where the excessive compression of\ninformation from distant nodes results in significant information loss, and\noversmoothing, where repeated message-passing iterations homogenize node\nrepresentations, obscuring meaningful distinctions. These issues, intrinsically\nlinked to the underlying graph structure, hinder information flow and constrain\nthe expressiveness of GNNs. In this survey, we examine graph rewiring\ntechniques, a class of methods designed to address these structural bottlenecks\nby modifying graph topology to enhance information diffusion. We provide a\ncomprehensive review of state-of-the-art rewiring approaches, delving into\ntheir theoretical underpinnings, practical implementations, and performance\ntrade-offs.",
      "tldr_zh": "这篇调查论文探讨了Graph Neural Networks (GNNs) 面临的两个关键挑战：oversquashing（远端节点信息过度压缩导致信息丢失）和oversmoothing（重复消息传递使节点表示同质化，模糊重要区别），这些问题源于图结构并限制了GNNs的信息流动和表达能力。论文重点审查了graph rewiring techniques，这类方法通过修改图拓扑来增强信息扩散。调查涵盖了最先进rewiring方法的理论基础、实际实现以及性能权衡，为缓解这些瓶颈并提升GNNs的整体性能提供了全面见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17429v1",
      "published_date": "2024-11-26 13:38:12 UTC",
      "updated_date": "2024-11-26 13:38:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:40:59.248184"
    },
    {
      "arxiv_id": "2411.17426v3",
      "title": "CLOVER: Cross-Layer Orthogonal Vectors Pruning and Fine-Tuning",
      "title_zh": "CLOVER：跨层正交向量剪枝",
      "authors": [
        "Fanxu Meng",
        "Pingzhi Tang",
        "Fan jiang",
        "Muhan Zhang"
      ],
      "abstract": "Decoder-only models generate tokens autoregressively by caching key/value\nvectors, but as the cache grows, inference becomes memory-bound. To address\nthis issue, we introduce CLOVER (Cross-Layer Orthogonal Vectors), a novel\napproach that treats pairs of attention layers as a set of low-rank\ndecompositions. CLOVER applies Singular Value Decomposition (SVD) to the \\( Q\n\\)-\\( K \\) and \\( V \\)-\\( O \\) pairs within each attention head. The resulting\nsingular values can either guide pruning or serve as trainable parameters for\nefficient fine-tuning of all orthogonal vectors. After pruning or fine-tuning,\nthese values are reintegrated into the model without increasing its parameter\ncount. We apply CLOVER to various models, including GPT-2 XL, DeepSeek-V2-Lite,\nWhisper-Large-v3, Stable Diffusion XL, and LLaMA-3.2-11B-Vision. Our results\ndemonstrate that CLOVER significantly improves pruning efficiency. For\ninstance, the perplexity of pruning 70\\% of the \\( Q \\)-\\( K \\) pairs in GPT-2\nXL is similar to that of pruning just 8\\% with vanilla methods. Fine-tuning the\nsingular values further results in a full-rank update, outperforming\nstate-of-the-art methods (LoRA, DoRA, HiRA, and PiSSA) by 7.6\\%, 5.5\\%, 3.8\\%,\nand 0.7\\%, respectively, on eight commonsense tasks for LLaMA-2 7B.",
      "tldr_zh": "本文提出CLOVER，一种创新的Cross-Layer Orthogonal Vectors方法，用于解决Decoder-only模型在推理过程中缓存key/value向量导致的内存限制问题，通过Singular Value Decomposition (SVD)对注意力头的Q-K和V-O对进行低秩分解，实现高效剪枝和微调。CLOVER的奇异值可指导剪枝或作为可训练参数重新整合到模型中，而不增加参数数量。实验在GPT-2 XL、LLaMA-2 7B等模型上显示，该方法使剪枝效率大幅提升，例如GPT-2 XL剪枝70%的Q-K对时，困惑度与传统方法剪枝8%相当，且在微调性能上优于LoRA、DoRA等方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "https://github.com/GraphPKU/PiSSA",
      "pdf_url": "http://arxiv.org/pdf/2411.17426v3",
      "published_date": "2024-11-26 13:34:02 UTC",
      "updated_date": "2025-01-31 14:13:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:41:12.491824"
    },
    {
      "arxiv_id": "2411.17404v3",
      "title": "BPP-Search: Enhancing Tree of Thought Reasoning for Mathematical Modeling Problem Solving",
      "title_zh": "翻译失败",
      "authors": [
        "Teng Wang",
        "Wing-Yin Yu",
        "Zhenqi He",
        "Zehua Liu",
        "Hailei Gong",
        "Han Wu",
        "Xiongwei Han",
        "Wei Shi",
        "Ruifeng She",
        "Fangzhou Zhu",
        "Tao Zhong"
      ],
      "abstract": "LLMs exhibit advanced reasoning capabilities, offering the potential to\ntransform natural language questions into mathematical models. However,\nexisting open-source datasets in operations research domain lack detailed\nannotations of the modeling process, such as variable definitions, focusing\nsolely on objective values, which hinders reinforcement learning applications.\nTo address this, we release the StructuredOR dataset, annotated with\ncomprehensive labels that capture the complete mathematical modeling process.\nWe further propose BPP-Search, an algorithm that integrates reinforcement\nlearning into a tree-of-thought structure using Beam search, a Process reward\nmodel, and a pairwise Preference algorithm. This approach enables efficient\nexploration of tree structures, avoiding exhaustive search while improving\naccuracy. Extensive experiments on StructuredOR, NL4OPT, and MAMO-ComplexLP\ndatasets show that BPP-Search significantly outperforms state-of-the-art\nmethods. In tree-based reasoning, BPP-Search excels in accuracy and efficiency,\nenabling faster retrieval of correct solutions. The StructuredOR dataset is\navailable at https://github.com/tengwang0318/StructuredOR.",
      "tldr_zh": "该论文指出，大型语言模型（LLMs）在将自然语言问题转化为数学模型时面临挑战，因为现有开源数据集缺乏详细的建模过程注解，如变量定义，仅关注目标值，从而阻碍强化学习应用。为此，研究团队发布了 StructuredOR 数据集，该数据集包含全面标签以捕捉完整的数学建模过程。论文提出 BPP-Search 算法，将强化学习整合到 Tree of Thought 结构中，通过 Beam search、Process reward model 和 pairwise Preference algorithm 实现高效的树结构探索，避免穷举搜索。在 StructuredOR、NL4OPT 和 MAMO-ComplexLP 数据集上的实验表明，BPP-Search 在准确性和效率上显著优于现有方法。StructuredOR 数据集可从 https://github.com/tengwang0318/StructuredOR 获取。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17404v3",
      "published_date": "2024-11-26 13:05:53 UTC",
      "updated_date": "2025-04-16 16:21:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:41:25.269751"
    },
    {
      "arxiv_id": "2411.17388v3",
      "title": "Can LLMs be Good Graph Judge for Knowledge Graph Construction?",
      "title_zh": "翻译失败",
      "authors": [
        "Haoyu Huang",
        "Chong Chen",
        "Zeang Sheng",
        "Yang Li",
        "Wentao Zhang"
      ],
      "abstract": "In real-world scenarios, most of the data obtained from the information\nretrieval (IR) system is unstructured. Converting natural language sentences\ninto structured Knowledge Graphs (KGs) remains a critical challenge. We\nidentified three limitations with respect to existing KG construction methods:\n(1) There could be a large amount of noise in real-world documents, which could\nresult in extracting messy information. (2) Naive LLMs usually extract\ninaccurate knowledge from some domain-specific documents. (3) Hallucination\nphenomenon cannot be overlooked when directly using LLMs to construct KGs. In\nthis paper, we propose \\textbf{GraphJudge}, a KG construction framework to\naddress the aforementioned challenges. In this framework, we designed an\nentity-centric strategy to eliminate the noise information in the documents.\nAnd we fine-tuned a LLM as a graph judge to finally enhance the quality of\ngenerated KGs. Experiments conducted on two general and one domain-specific\ntext-graph pair datasets demonstrate state-of-the-art performance against\nvarious baseline methods with strong generalization abilities. Our code is\navailable at\n\\href{https://github.com/hhy-huang/GraphJudge}{https://github.com/hhy-huang/GraphJudge}.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 在知识图谱 (KGs) 构建中的潜力，针对信息检索 (IR) 系统中的非结构化数据问题，包括文档噪声、提取不准确性和幻觉现象。作者提出了 GraphJudge 框架，该框架采用实体中心策略消除噪声信息，并通过微调 LLM 作为图谱判断器来提升生成的 KGs 质量。实验在两个通用和一个领域特定数据集上证明，GraphJudge 比多种基线方法取得了最先进性能，并展示了强大的泛化能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17388v3",
      "published_date": "2024-11-26 12:46:57 UTC",
      "updated_date": "2025-05-20 16:24:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:41:35.523965"
    },
    {
      "arxiv_id": "2411.17374v1",
      "title": "Fairness And Performance In Harmony: Data Debiasing Is All You Need",
      "title_zh": "公平与性能的和谐：数据去偏置就是你所需要的全部",
      "authors": [
        "Junhua Liu",
        "Wendy Wan Yee Hui",
        "Roy Ka-Wei Lee",
        "Kwan Hui Lim"
      ],
      "abstract": "Fairness in both machine learning (ML) predictions and human decisions is\ncritical, with ML models prone to algorithmic and data bias, and human\ndecisions affected by subjectivity and cognitive bias. This study investigates\nfairness using a real-world university admission dataset with 870 profiles,\nleveraging three ML models, namely XGB, Bi-LSTM, and KNN. Textual features are\nencoded with BERT embeddings. For individual fairness, we assess decision\nconsistency among experts with varied backgrounds and ML models, using a\nconsistency score. Results show ML models outperform humans in fairness by\n14.08% to 18.79%. For group fairness, we propose a gender-debiasing pipeline\nand demonstrate its efficacy in removing gender-specific language without\ncompromising prediction performance. Post-debiasing, all models maintain or\nimprove their classification accuracy, validating the hypothesis that fairness\nand performance can coexist. Our findings highlight ML's potential to enhance\nfairness in admissions while maintaining high accuracy, advocating a hybrid\napproach combining human judgement and ML models.",
      "tldr_zh": "本研究探讨机器学习(ML)模型与人类决策在公平性方面的比较，使用一个包含870个真实大学录取档案的数据集，涉及XGB、Bi-LSTM和KNN模型，并采用BERT嵌入进行文本特征编码。\n在个体公平性评估中，ML模型通过一致性分数显示出比人类决策高出14.08%至18.79%的公平性表现。\n研究提出了一种性别去偏置管道，能够有效移除性别特定语言，同时维持或提升模型的分类准确率，验证了公平性和性能可以共存。\n这些发现支持将ML模型与人类判断相结合，以提升录取过程的公平性和准确性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17374v1",
      "published_date": "2024-11-26 12:31:10 UTC",
      "updated_date": "2024-11-26 12:31:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:41:48.968008"
    },
    {
      "arxiv_id": "2411.17782v1",
      "title": "Joint Resource Optimization, Computation Offloading and Resource Slicing for Multi-Edge Traffic-Cognitive Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Ting Xiaoyang",
        "Minfeng Zhang",
        "Shu gonglee",
        "Saimin Chen Zhang"
      ],
      "abstract": "The evolving landscape of edge computing envisions platforms operating as\ndynamic intermediaries between application providers and edge servers (ESs),\nwhere task offloading is coupled with payments for computational services.\nEnsuring efficient resource utilization and meeting stringent Quality of\nService (QoS) requirements necessitates incentivizing ESs while optimizing the\nplatforms operational objectives. This paper investigates a multi-agent system\nwhere both the platform and ESs are self-interested entities, addressing the\njoint optimization of revenue maximization, resource allocation, and task\noffloading. We propose a novel Stackelberg game-based framework to model\ninteractions between stakeholders and solve the optimization problem using a\nBayesian Optimization-based centralized algorithm. Recognizing practical\nchallenges in information collection due to privacy concerns, we further design\na decentralized solution leveraging neural network optimization and a\nprivacy-preserving information exchange protocol. Extensive numerical\nevaluations demonstrate the effectiveness of the proposed mechanisms in\nachieving superior performance compared to existing baselines.",
      "tldr_zh": "该论文探讨了边缘计算环境中联合资源优化、计算卸载和资源切片的问题，针对多智能体系统中的平台和边缘服务器（ESs）作为自利实体，目标是最大化收入并满足QoS要求。研究提出一个基于Stackelberg game的框架，使用Bayesian Optimization的集中式算法进行优化，并设计了去中心化解决方案，结合神经网络优化和隐私保护信息交换协议来处理实际信息收集挑战。数值评估结果表明，该机制在性能上优于现有基线，为高效的交通认知多边缘网络提供了有效策略。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17782v1",
      "published_date": "2024-11-26 11:51:10 UTC",
      "updated_date": "2024-11-26 11:51:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:42:00.108839"
    },
    {
      "arxiv_id": "2411.17339v1",
      "title": "Knowledge-aware Evolutionary Graph Neural Architecture Search",
      "title_zh": "知识感知的进化图神经架构搜索",
      "authors": [
        "Chao Wang",
        "Jiaxuan Zhao",
        "Lingling Li",
        "Licheng Jiao",
        "Fang Liu",
        "Xu Liu",
        "Shuyuan Yang"
      ],
      "abstract": "Graph neural architecture search (GNAS) can customize high-performance graph\nneural network architectures for specific graph tasks or datasets. However,\nexisting GNAS methods begin searching for architectures from a zero-knowledge\nstate, ignoring the prior knowledge that may improve the search efficiency. The\navailable knowledge base (e.g. NAS-Bench-Graph) contains many rich\narchitectures and their multiple performance metrics, such as the accuracy\n(#Acc) and number of parameters (#Params). This study proposes exploiting such\nprior knowledge to accelerate the multi-objective evolutionary search on a new\ngraph dataset, named knowledge-aware evolutionary GNAS (KEGNAS). KEGNAS employs\nthe knowledge base to train a knowledge model and a deep multi-output Gaussian\nprocess (DMOGP) in one go, which generates and evaluates transfer architectures\nin only a few GPU seconds. The knowledge model first establishes a\ndataset-to-architecture mapping, which can quickly generate candidate transfer\narchitectures for a new dataset. Subsequently, the DMOGP with architecture and\ndataset encodings is designed to predict multiple performance metrics for\ncandidate transfer architectures on the new dataset. According to the predicted\nmetrics, non-dominated candidate transfer architectures are selected to\nwarm-start the multi-objective evolutionary algorithm for optimizing the #Acc\nand #Params on a new dataset. Empirical studies on NAS-Bench-Graph and five\nreal-world datasets show that KEGNAS swiftly generates top-performance\narchitectures, achieving 4.27% higher accuracy than advanced evolutionary\nbaselines and 11.54% higher accuracy than advanced differentiable baselines. In\naddition, ablation studies demonstrate that the use of prior knowledge\nsignificantly improves the search performance.",
      "tldr_zh": "本文提出了一种知识感知的进化图神经架构搜索方法（KEGNAS），旨在利用现有知识库（如 NAS-Bench-Graph）中的架构和性能指标（如 #Acc 和 #Params）来加速 GNAS 的多目标搜索过程。KEGNAS 通过训练知识模型建立数据集到架构的映射，并结合深度多输出高斯过程（DMOGP）快速生成和评估候选转移架构，从而启动进化算法优化准确率和参数量。实验结果显示，KEGNAS 在 NAS-Bench-Graph 和五个真实数据集上比先进进化基线提高 4.27% 准确率、比可微基线提高 11.54%，并证明了先验知识对搜索性能的显著提升。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "This work has been accepted by Knowledge-Based Systems",
      "pdf_url": "http://arxiv.org/pdf/2411.17339v1",
      "published_date": "2024-11-26 11:32:45 UTC",
      "updated_date": "2024-11-26 11:32:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:42:13.370227"
    },
    {
      "arxiv_id": "2411.17338v1",
      "title": "Different Bias Under Different Criteria: Assessing Bias in LLMs with a Fact-Based Approach",
      "title_zh": "在不同标准下的不同偏见：使用基于事实的方法评估LLMs中的偏见",
      "authors": [
        "Changgeon Ko",
        "Jisu Shin",
        "Hoyun Song",
        "Jeongyeon Seo",
        "Jong C. Park"
      ],
      "abstract": "Large language models (LLMs) often reflect real-world biases, leading to\nefforts to mitigate these effects and make the models unbiased. Achieving this\ngoal requires defining clear criteria for an unbiased state, with any deviation\nfrom these criteria considered biased. Some studies define an unbiased state as\nequal treatment across diverse demographic groups, aiming for balanced outputs\nfrom LLMs. However, differing perspectives on equality and the importance of\npluralism make it challenging to establish a universal standard. Alternatively,\nother approaches propose using fact-based criteria for more consistent and\nobjective evaluations, though these methods have not yet been fully applied to\nLLM bias assessments. Thus, there is a need for a metric with objective\ncriteria that offers a distinct perspective from equality-based approaches.\nMotivated by this need, we introduce a novel metric to assess bias using\nfact-based criteria and real-world statistics. In this paper, we conducted a\nhuman survey demonstrating that humans tend to perceive LLM outputs more\npositively when they align closely with real-world demographic distributions.\nEvaluating various LLMs with our proposed metric reveals that model bias varies\ndepending on the criteria used, highlighting the need for multi-perspective\nassessment.",
      "tldr_zh": "本研究探讨了大型语言模型(LLMs)中的偏见评估问题，指出传统基于平等的标准（如跨群体平衡输出）难以建立统一规范，因此提出了一种基于事实-based criteria的新指标，利用real-world statistics进行更客观的评估。研究通过人类调查发现，人们更倾向于LLMs输出与实际人口分布一致的结果，这突显了事实导向方法的优势。在实验中，评估多种LLMs时发现，模型偏见会因评估标准不同而变化，强调了进行多-perspective评估的必要性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted in NeurIPS 2024 Workshop on Socially Responsible Language\n  Modelling Research (SoLaR)",
      "pdf_url": "http://arxiv.org/pdf/2411.17338v1",
      "published_date": "2024-11-26 11:32:43 UTC",
      "updated_date": "2024-11-26 11:32:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:42:23.192703"
    },
    {
      "arxiv_id": "2411.17326v1",
      "title": "Towards Intention Recognition for Robotic Assistants Through Online POMDP Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Juan Carlos Saborio",
        "Joachim Hertzberg"
      ],
      "abstract": "Intention recognition, or the ability to anticipate the actions of another\nagent, plays a vital role in the design and development of automated assistants\nthat can support humans in their daily tasks. In particular, industrial\nsettings pose interesting challenges that include potential distractions for a\ndecision-maker as well as noisy or incomplete observations. In such a setting,\na robotic assistant tasked with helping and supporting a human worker must\ninterleave information gathering actions with proactive tasks of its own, an\napproach that has been referred to as active goal recognition. In this paper we\ndescribe a partially observable model for online intention recognition, show\nsome preliminary experimental results and discuss some of the challenges\npresent in this family of problems.",
      "tldr_zh": "这篇论文探讨了在工业环境中实现机器人助手意图识别(Intention Recognition)的挑战，包括决策者分心和观察噪声等问题。作者提出一个部分可观察模型(Partially Observable Model)结合在线POMDP规划(Online POMDP Planning)，允许机器人助手交替进行信息收集和主动任务(Active Goal Recognition)。初步实验结果显示了该方法的有效性，并讨论了此类问题中的潜在挑战，为自动化助手的设计提供了新思路。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "Presented at the ICAPS 2023 workshop \"PAIR: Plan, Activity, and\n  Intent Recognition\"",
      "pdf_url": "http://arxiv.org/pdf/2411.17326v1",
      "published_date": "2024-11-26 11:13:00 UTC",
      "updated_date": "2024-11-26 11:13:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:42:35.652707"
    },
    {
      "arxiv_id": "2411.17309v1",
      "title": "PIM-AI: A Novel Architecture for High-Efficiency LLM Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Cristobal Ortega",
        "Yann Falevoz",
        "Renaud Ayrignac"
      ],
      "abstract": "Large Language Models (LLMs) have become essential in a variety of\napplications due to their advanced language understanding and generation\ncapabilities. However, their computational and memory requirements pose\nsignificant challenges to traditional hardware architectures.\nProcessing-in-Memory (PIM), which integrates computational units directly into\nmemory chips, offers several advantages for LLM inference, including reduced\ndata transfer bottlenecks and improved power efficiency.\n  This paper introduces PIM-AI, a novel DDR5/LPDDR5 PIM architecture designed\nfor LLM inference without modifying the memory controller or DDR/LPDDR memory\nPHY. We have developed a simulator to evaluate the performance of PIM-AI in\nvarious scenarios and demonstrate its significant advantages over conventional\narchitectures. In cloud-based scenarios, PIM-AI reduces the 3-year TCO per\nqueries-per-second by up to 6.94x compared to state-of-the-art GPUs, depending\non the LLM model used. In mobile scenarios, PIM-AI achieves a 10- to 20-fold\nreduction in energy per token compared to state-of-the-art mobile SoCs,\nresulting in 25 to 45~\\% more queries per second and 6.9x to 13.4x less energy\nper query, extending battery life and enabling more inferences per charge.\nThese results highlight PIM-AI's potential to revolutionize LLM deployments,\nmaking them more efficient, scalable, and sustainable.",
      "tldr_zh": "这篇论文提出了 PIM-AI，一种新型的 DDR5/LPDDR5 Processing-in-Memory (PIM) 架构，旨在提升 Large Language Models (LLMs) 推理的效率，同时避免修改内存控制器或 DDR/LPDDR 内存 PHY。PIM-AI 通过将计算单元集成到内存芯片中，显著减少数据传输瓶颈和功率消耗。实验结果显示，在云端场景下，PIM-AI 比最先进的 GPU 降低 3-year TCO per queries-per-second 最多 6.94 倍；在移动场景下，比最先进的 mobile SoCs 减少能量消耗 10-20 倍，提高查询速度 25-45%，并实现 6.9x 到 13.4x 的能量节省，从而使 LLM 部署更高效、可扩展和可持续。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.DC",
        "cs.ET"
      ],
      "primary_category": "cs.AR",
      "comment": "14 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.17309v1",
      "published_date": "2024-11-26 10:54:19 UTC",
      "updated_date": "2024-11-26 10:54:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:42:49.599284"
    },
    {
      "arxiv_id": "2411.17304v1",
      "title": "Meaningless is better: hashing bias-inducing words in LLM prompts improves performance in logical reasoning and statistical learning",
      "title_zh": "翻译失败",
      "authors": [
        "Milena Chadimová",
        "Eduard Jurášek",
        "Tomáš Kliegr"
      ],
      "abstract": "This paper introduces a novel method, referred to as \"hashing\", which\ninvolves masking potentially bias-inducing words in large language models\n(LLMs) with hash-like meaningless identifiers to reduce cognitive biases and\nreliance on external knowledge. The method was tested across three sets of\nexperiments involving a total of 490 prompts. Statistical analysis using\nchi-square tests showed significant improvements in all tested scenarios, which\ncovered LLama, ChatGPT, Copilot, Gemini and Mixtral models. In the first\nexperiment, hashing decreased the fallacy rate in a modified version of the\n\"Linda\" problem aimed at evaluating susceptibility to cognitive biases. In the\nsecond experiment, it improved LLM results on the frequent itemset extraction\ntask. In the third experiment, we found hashing is also effective when the\nLinda problem is presented in a tabular format rather than text, indicating\nthat the technique works across various input representations. Overall, the\nmethod was shown to improve bias reduction and incorporation of external\nknowledge. Despite bias reduction, hallucination rates were inconsistently\nreduced across types of LLM models. These findings suggest that masking\nbias-inducing terms can improve LLM performance, although its effectiveness is\nmodel- and task-dependent.",
      "tldr_zh": "本文提出了一种名为“hashing”的方法，通过用无意义标识符掩盖LLM提示中的偏见诱导词（bias-inducing words），以减少认知偏见（cognitive biases）和对外部知识的依赖，从而提升LLM在逻辑推理和统计学习任务中的性能。实验涉及490个提示和多种模型（如LLama、ChatGPT、Copilot、Gemini和Mixtral），统计分析显示hashing显著降低了修改版“Linda”问题中的谬误率，并改善了频繁项集提取（frequent itemset extraction）任务的效果，即使在表格格式下也适用。总体发现表明，该方法能有效减少偏见并整合外部知识，但对幻觉率（hallucination rates）的降低因模型和任务而异。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17304v1",
      "published_date": "2024-11-26 10:52:08 UTC",
      "updated_date": "2024-11-26 10:52:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:43:00.693117"
    },
    {
      "arxiv_id": "2411.17301v2",
      "title": "ReFINE: A Reward-Based Framework for Interpretable and Nuanced Evaluation of Radiology Report Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Yunyi Liu",
        "Yingshu Li",
        "Zhanyu Wang",
        "Xinyu Liang",
        "Lingqiao Liu",
        "Lei Wang",
        "Luping Zhou"
      ],
      "abstract": "Automated radiology report generation (R2Gen) has advanced significantly,\nintroducing challenges in accurate evaluation due to its complexity.\nTraditional metrics often fall short by relying on rigid word-matching or\nfocusing only on pathological entities, leading to inconsistencies with human\nassessments. To bridge this gap, we introduce ReFINE, an automatic evaluation\nmetric designed specifically for R2Gen. Our metric utilizes a reward model,\nguided by our margin-based reward enforcement loss, along with a tailored\ntraining data design that enables customization of evaluation criteria to suit\nuser-defined needs. It not only scores reports according to user-specified\ncriteria but also provides detailed sub-scores, enhancing interpretability and\nallowing users to adjust the criteria between different aspects of reports.\nLeveraging GPT-4, we designed an easy-to-use data generation pipeline, enabling\nus to produce extensive training data based on two distinct scoring systems,\neach containing reports of varying quality along with corresponding scores.\nThese GPT-generated reports are then paired as accepted and rejected samples\nthrough our pairing rule to train an LLM towards our fine-grained reward model,\nwhich assigns higher rewards to the report with high quality. Our\nreward-control loss enables this model to simultaneously output multiple\nindividual rewards corresponding to the number of evaluation criteria, with\ntheir summation as our final ReFINE. Our experiments demonstrate ReFINE's\nheightened correlation with human judgments and superior performance in model\nselection compared to traditional metrics. Notably, our model provides both an\noverall score and individual scores for each evaluation item, enhancing\ninterpretability. We also demonstrate its flexible training across various\nevaluation systems.",
      "tldr_zh": "该论文提出 ReFINE，一种基于奖励模型的框架，用于放射学报告生成（R2Gen）的自动评估，旨在解决传统指标（如刚性词匹配）与人类判断不一致的问题。ReFINE 通过 margin-based reward enforcement loss 和定制训练数据（利用 GPT-4 生成不同质量报告并配对训练 LLM），允许用户自定义评估标准并输出详细子分数，提升评估的解释性和细致度。实验结果显示，ReFINE 与人类判断的相关性更高，在模型选择上优于传统指标，并支持灵活适应各种评估系统。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17301v2",
      "published_date": "2024-11-26 10:48:55 UTC",
      "updated_date": "2025-02-13 12:25:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:43:12.151995"
    },
    {
      "arxiv_id": "2411.17296v2",
      "title": "GrokFormer: Graph Fourier Kolmogorov-Arnold Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Guoguo Ai",
        "Guansong Pang",
        "Hezhe Qiao",
        "Yuan Gao",
        "Hui Yan"
      ],
      "abstract": "Graph Transformers (GTs) have demonstrated remarkable performance in graph\nrepresentation learning over popular graph neural networks (GNNs). However,\nself--attention, the core module of GTs, preserves only low-frequency signals\nin graph features, leading to ineffectiveness in capturing other important\nsignals like high-frequency ones. Some recent GT models help alleviate this\nissue, but their flexibility and expressiveness are still limited since the\nfilters they learn are fixed on predefined graph spectrum or order. To tackle\nthis challenge, we propose a Graph Fourier Kolmogorov-Arnold Transformer\n(GrokFormer), a novel GT model that learns highly expressive spectral filters\nwith adaptive graph spectrum and order through a Fourier series modeling over\nlearnable activation functions. We demonstrate theoretically and empirically\nthat the proposed GrokFormer filter offers better expressiveness than other\nspectral methods. Comprehensive experiments on 10 real-world node\nclassification datasets across various domains, scales, and graph properties,\nas well as 5 graph classification datasets, show that GrokFormer outperforms\nstate-of-the-art GTs and GNNs. Our code is available at\nhttps://github.com/GGA23/GrokFormer",
      "tldr_zh": "该研究指出，现有的 Graph Transformers (GTs) 由于自注意力机制仅保留低频信号，导致在图表示学习中无法有效捕获高频信号。论文提出了一种新型模型 Graph Fourier Kolmogorov-Arnold Transformer (GrokFormer)，通过傅立叶系列(Fourier series)建模可学习的激活函数，来学习高度表达性的谱过滤器，支持自适应图谱和顺序。理论分析和实验结果显示，GrokFormer 的过滤器比其他谱方法更具表达力，并在10个节点分类数据集和5个图分类数据集上，超越了最先进的GTs和Graph Neural Networks (GNNs)。这项工作为图表示学习提供了更灵活的框架，并提供了开源代码。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages, 7 figures, 9 tables",
      "pdf_url": "http://arxiv.org/pdf/2411.17296v2",
      "published_date": "2024-11-26 10:38:00 UTC",
      "updated_date": "2025-02-09 06:33:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:43:24.413201"
    },
    {
      "arxiv_id": "2412.07791v1",
      "title": "Digital Democracy in the Age of Artificial Intelligence",
      "title_zh": "人工智能时代的数字民主",
      "authors": [
        "Claudio Novelli",
        "Giulia Sandri"
      ],
      "abstract": "This chapter explores the influence of Artificial Intelligence (AI) on\ndigital democracy, focusing on four main areas: citizenship, participation,\nrepresentation, and the public sphere. It traces the evolution from electronic\nto virtual and network democracy, underscoring how each stage has broadened\ndemocratic engagement through technology. Focusing on digital citizenship, the\nchapter examines how AI can improve online engagement and promote ethical\nbehaviour while posing privacy risks and fostering identity stereotyping.\nRegarding political participation, it highlights AI's dual role in mobilising\ncivic actions and spreading misinformation. Regarding representation, AI's\ninvolvement in electoral processes can enhance voter registration, e-voting,\nand the efficiency of result tabulation but raises concerns regarding privacy\nand public trust. Also, AI's predictive capabilities shift the dynamics of\npolitical competition, posing ethical questions about manipulation and the\nlegitimacy of democracy. Finally, the chapter examines how integrating AI and\ndigital technologies can facilitate democratic political advocacy and\npersonalised communication. However, this also comes with higher risks of\nmisinformation and targeted propaganda.",
      "tldr_zh": "本章探讨了人工智能(AI)对数字民主的影响，聚焦于公民身份、参与、代表性和公共领域四个方面，并追溯了从电子民主到虚拟和网络民主的演变过程。AI通过提升在线参与、促进道德行为、优化选举流程（如电子投票和结果统计）以及支持个性化政治倡导等方式增强民主参与，但同时带来隐私风险、身份刻板印象、误信息传播和政治操纵等问题。该研究强调AI的双重作用，呼吁在推广数字民主时平衡技术益处与潜在伦理挑战，以维护民主的合法性和公信力。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07791v1",
      "published_date": "2024-11-26 10:20:53 UTC",
      "updated_date": "2024-11-26 10:20:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:43:35.312195"
    },
    {
      "arxiv_id": "2411.17282v1",
      "title": "Social Distancing Induced Coronavirus Optimization Algorithm (COVO): Application to Multimodal Function Optimization and Noise Removal",
      "title_zh": "翻译失败",
      "authors": [
        "Om Ramakisan Varma",
        "Mala Kalra"
      ],
      "abstract": "The metaheuristic optimization technique attained more awareness for handling\ncomplex optimization problems. Over the last few years, numerous optimization\ntechniques have been developed that are inspired by natural phenomena.\nRecently, the propagation of the new COVID-19 implied a burden on the public\nhealth system to suffer several deaths. Vaccination, masks, and social\ndistancing are the major steps taken to minimize the spread of the deadly\nCOVID-19 virus. Considering the social distance to combat the coronavirus\nepidemic, a novel bio-inspired metaheuristic optimization model is proposed in\nthis work, and it is termed as Social Distancing Induced Coronavirus\nOptimization Algorithm (COVO). The pace of propagation of the coronavirus can\nindeed be slowed by maintaining social distance. Thirteen benchmark functions\nare used to evaluate the COVO performance for discrete, continuous, and complex\nproblems, and the COVO model performance is compared with other well-known\noptimization algorithms. The main motive of COVO optimization is to obtain a\nglobal solution to various applications by solving complex problems with faster\nconvergence. At last, the validated results depict that the proposed COVO\noptimization has a reasonable and acceptable performance.",
      "tldr_zh": "本研究提出了一种新型生物启发式优化算法COVO（Social Distancing Induced Coronavirus Optimization Algorithm），其灵感来源于COVID-19疫情期间的社交距离措施，用于解决复杂优化问题。\n该算法通过模拟病毒传播减缓机制，应用于多模态函数优化和噪声去除，并使用13个benchmark functions评估其在离散、连续和复杂问题上的性能，与其他知名优化算法进行比较。\n结果表明，COVO实现了更快收敛并提供全局解决方案，整体性能合理且可接受。",
      "categories": [
        "cs.CC",
        "cs.AI"
      ],
      "primary_category": "cs.CC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17282v1",
      "published_date": "2024-11-26 10:09:36 UTC",
      "updated_date": "2024-11-26 10:09:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:43:48.440979"
    },
    {
      "arxiv_id": "2411.17774v1",
      "title": "Leaning Time-Varying Instruments for Identifying Causal Effects in Time-Series Data",
      "title_zh": "翻译失败",
      "authors": [
        "Debo Cheng",
        "Ziqi Xu",
        "Jiuyong Li",
        "Lin Liu",
        "Thuc duy Le",
        "Xudong Guo",
        "Shichao Zhang"
      ],
      "abstract": "Querying causal effects from time-series data is important across various\nfields, including healthcare, economics, climate science, and epidemiology.\nHowever, this task becomes complex in the existence of time-varying latent\nconfounders, which affect both treatment and outcome variables over time and\ncan introduce bias in causal effect estimation. Traditional instrumental\nvariable (IV) methods are limited in addressing such complexities due to the\nneed for predefined IVs or strong assumptions that do not hold in dynamic\nsettings. To tackle these issues, we develop a novel Time-varying Conditional\nInstrumental Variables (CIV) for Debiasing causal effect estimation, referred\nto as TDCIV. TDCIV leverages Long Short-Term Memory (LSTM) and Variational\nAutoencoder (VAE) models to disentangle and learn the representations of\ntime-varying CIV and its conditioning set from proxy variables without prior\nknowledge. Under the assumptions of the Markov property and availability of\nproxy variables, we theoretically establish the validity of these learned\nrepresentations for addressing the biases from time-varying latent confounders,\nthus enabling accurate causal effect estimation. Our proposed TDCIV is the\nfirst to effectively learn time-varying CIV and its associated conditioning set\nwithout relying on domain-specific knowledge.",
      "tldr_zh": "这篇论文解决了从时间序列数据中识别因果效应的挑战，特别是当存在时间-varying latent confounders 时，这些因素会影响治疗和结果变量，导致估计偏差。作者提出了一种新方法 Time-varying Conditional Instrumental Variables (TDCIV)，利用 Long Short-Term Memory (LSTM) 和 Variational Autoencoder (VAE) 从代理变量中学习时间变化的 CIV 和其条件集，而无需先验知识或预定义的 Instrumental Variables (IV)。在 Markov 属性和代理变量可用性的假设下，论文理论证明了 TDCIV 可以有效去除偏差，从而实现准确的因果效应估计。TDCIV 是首个不依赖领域特定知识的学习时间变化 CIV 的方法，为医疗、经济和气候科学等领域提供可靠工具。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.17774v1",
      "published_date": "2024-11-26 09:47:24 UTC",
      "updated_date": "2024-11-26 09:47:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:44:01.223600"
    },
    {
      "arxiv_id": "2411.17261v1",
      "title": "HEIE: MLLM-Based Hierarchical Explainable AIGC Image Implausibility Evaluator",
      "title_zh": "翻译失败",
      "authors": [
        "Fan Yang",
        "Ru Zhen",
        "Jianing Wang",
        "Yanhao Zhang",
        "Haoxiang Chen",
        "Haonan Lu",
        "Sicheng Zhao",
        "Guiguang Ding"
      ],
      "abstract": "AIGC images are prevalent across various fields, yet they frequently suffer\nfrom quality issues like artifacts and unnatural textures. Specialized models\naim to predict defect region heatmaps but face two primary challenges: (1) lack\nof explainability, failing to provide reasons and analyses for subtle defects,\nand (2) inability to leverage common sense and logical reasoning, leading to\npoor generalization. Multimodal large language models (MLLMs) promise better\ncomprehension and reasoning but face their own challenges: (1) difficulty in\nfine-grained defect localization due to the limitations in capturing tiny\ndetails; and (2) constraints in providing pixel-wise outputs necessary for\nprecise heatmap generation. To address these challenges, we propose HEIE: a\nnovel MLLM-Based Hierarchical Explainable image Implausibility Evaluator. We\nintroduce the CoT-Driven Explainable Trinity Evaluator, which integrates\nheatmaps, scores, and explanation outputs, using CoT to decompose complex tasks\ninto subtasks of increasing difficulty and enhance interpretability. Our\nAdaptive Hierarchical Implausibility Mapper synergizes low-level image features\nwith high-level mapper tokens from LLMs, enabling precise local-to-global\nhierarchical heatmap predictions through an uncertainty-based adaptive token\napproach. Moreover, we propose a new dataset: Expl-AIGI-Eval, designed to\nfacilitate interpretable implausibility evaluation of AIGC images. Our method\ndemonstrates state-of-the-art performance through extensive experiments.",
      "tldr_zh": "该论文提出 HEIE，一种基于 MLLM 的 Hierarchical Explainable AIGC Image Implausibility Evaluator，用于评估 AIGC 图像的质量问题，如 artifacts 和 unnatural textures，同时解决现有模型的 explainability 缺失和 generalization 不足。核心方法包括 CoT-Driven Explainable Trinity Evaluator，它通过 Chain-of-Thought 推理将任务分解为子任务，输出 heatmaps、scores 和解释以提升可解释性；以及 Adaptive Hierarchical Implausibility Mapper，该模块结合 low-level image features 和 high-level mapper tokens，通过 uncertainty-based adaptive token 实现精确的局部到全局 heatmap 预测。作者还构建了新数据集 Expl-AIGI-Eval，并通过广泛实验证明了该方法的 state-of-the-art 性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17261v1",
      "published_date": "2024-11-26 09:37:59 UTC",
      "updated_date": "2024-11-26 09:37:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:44:12.513773"
    },
    {
      "arxiv_id": "2411.17260v1",
      "title": "MiceBoneChallenge: Micro-CT public dataset and six solutions for automatic growth plate detection in micro-CT mice bone scans",
      "title_zh": "翻译失败",
      "authors": [
        "Nikolay Burlutskiy",
        "Marija Kekic",
        "Jordi de la Torre",
        "Philipp Plewa",
        "Mehdi Boroumand",
        "Julia Jurkowska",
        "Borjan Venovski",
        "Maria Chiara Biagi",
        "Yeman Brhane Hagos",
        "Roksana Malinowska-Traczyk",
        "Yibo Wang",
        "Jacek Zalewski",
        "Paula Sawczuk",
        "Karlo Pintarić",
        "Fariba Yousefi",
        "Leif Hultin"
      ],
      "abstract": "Detecting and quantifying bone changes in micro-CT scans of rodents is a\ncommon task in preclinical drug development studies. However, this task is\nmanual, time-consuming and subject to inter- and intra-observer variability. In\n2024, Anonymous Company organized an internal challenge to develop models for\nautomatic bone quantification. We prepared and annotated a high-quality dataset\nof 3D $\\mu$CT bone scans from $83$ mice. The challenge attracted over $80$ AI\nscientists from around the globe who formed $23$ teams. The participants were\ntasked with developing a solution to identify the plane where the bone growth\nhappens, which is essential for fully automatic segmentation of trabecular\nbone. As a result, six computer vision solutions were developed that can\naccurately identify the location of the growth plate plane. The solutions\nachieved the mean absolute error of $1.91\\pm0.87$ planes from the ground truth\non the test set, an accuracy level acceptable for practical use by a\nradiologist. The annotated 3D scans dataset along with the six solutions and\nsource code, is being made public, providing researchers with opportunities to\ndevelop and benchmark their own approaches. The code, trained models, and the\ndata will be shared.",
      "tldr_zh": "本研究介绍了MiceBoneChallenge，这是一个针对微CT（Micro-CT）小鼠骨扫描的公开数据集和挑战赛，旨在解决手动检测骨骼变化的耗时问题，该数据集包括83只小鼠的标注3D μCT扫描。研究组织了内部挑战赛，吸引了23个团队的80多名AI科学家开发计算机视觉解决方案，以自动识别骨骼生长板（growth plate）的平面位置，从而实现海绵骨（trabecular bone）的全自动分割。这些解决方案在测试集上达到了1.91±0.87 planes的平均绝对误差（mean absolute error），精度足以应用于实际放射学实践，并将数据集、源代码和训练模型公开，以供研究人员进一步开发和基准测试。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "stat.ML"
      ],
      "primary_category": "eess.IV",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2411.17260v1",
      "published_date": "2024-11-26 09:37:47 UTC",
      "updated_date": "2024-11-26 09:37:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:44:24.201528"
    },
    {
      "arxiv_id": "2411.17257v1",
      "title": "Disentangled Interpretable Representation for Efficient Long-term Time Series Forecasting",
      "title_zh": "高效长期时间序列预测的解耦可解释表示",
      "authors": [
        "Yuang Zhao",
        "Tianyu Li",
        "Jiadong Chen",
        "Shenrong Ye",
        "Fuxin Jiang",
        "Tieying Zhang",
        "Xiaofeng Gao"
      ],
      "abstract": "Industry 5.0 introduces new challenges for Long-term Time Series Forecasting\n(LTSF), characterized by high-dimensional, high-resolution data and high-stakes\napplication scenarios. Against this backdrop, developing efficient and\ninterpretable models for LTSF becomes a key challenge. Existing deep learning\nand linear models often suffer from excessive parameter complexity and lack\nintuitive interpretability. To address these issues, we propose DiPE-Linear, a\nDisentangled interpretable Parameter-Efficient Linear network. DiPE-Linear\nincorporates three temporal components: Static Frequential Attention (SFA),\nStatic Temporal Attention (STA), and Independent Frequential Mapping (IFM).\nThese components alternate between learning in the frequency and time domains\nto achieve disentangled interpretability. The decomposed model structure\nreduces parameter complexity from quadratic in fully connected networks (FCs)\nto linear and computational complexity from quadratic to log-linear.\nAdditionally, a Low-Rank Weight Sharing policy enhances the model's ability to\nhandle multivariate series. Despite operating within a subspace of FCs with\nlimited expressive capacity, DiPE-Linear demonstrates comparable or superior\nperformance to both FCs and nonlinear models across multiple open-source and\nreal-world LTSF datasets, validating the effectiveness of its sophisticatedly\ndesigned structure. The combination of efficiency, accuracy, and\ninterpretability makes DiPE-Linear a strong candidate for advancing LTSF in\nboth research and real-world applications. The source code is available at\nhttps://github.com/wintertee/DiPE-Linear.",
      "tldr_zh": "本研究针对Industry 5.0时代的高维高分辨率数据挑战，提出DiPE-Linear模型，这是一种解耦的可解释参数高效线性网络，用于高效的长期时间序列预测(LTSF)。DiPE-Linear通过Static Frequential Attention (SFA)、Static Temporal Attention (STA)和Independent Frequential Mapping (IFM)组件，在频率和时间域交替学习，实现参数复杂度从二次方降至线性、计算复杂度从二次方降至对数线性，并引入Low-Rank Weight Sharing策略来处理多变量序列。实验结果显示，DiPE-Linear在多个开源和真实数据集上表现出与全连接网络(FCs)和非线性模型相当或优越的性能，结合其效率和可解释性，为LTSF在研究和实际应用中提供了有力工具。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This work is submitted to IEEE International Conference on Data\n  Engineering (ICDE) 2025",
      "pdf_url": "http://arxiv.org/pdf/2411.17257v1",
      "published_date": "2024-11-26 09:33:09 UTC",
      "updated_date": "2024-11-26 09:33:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:44:37.442632"
    },
    {
      "arxiv_id": "2411.17255v2",
      "title": "APT: Architectural Planning and Text-to-Blueprint Construction Using Large Language Models for Open-World Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Jun Yu Chen",
        "Tao Gao"
      ],
      "abstract": "We present APT, an advanced Large Language Model (LLM)-driven framework that\nenables autonomous agents to construct complex and creative structures within\nthe Minecraft environment. Unlike previous approaches that primarily\nconcentrate on skill-based open-world tasks or rely on image-based diffusion\nmodels for generating voxel-based structures, our method leverages the\nintrinsic spatial reasoning capabilities of LLMs. By employing chain-of-thought\ndecomposition along with multimodal inputs, the framework generates detailed\narchitectural layouts and blueprints that the agent can execute under zero-shot\nor few-shot learning scenarios. Our agent incorporates both memory and\nreflection modules to facilitate lifelong learning, adaptive refinement, and\nerror correction throughout the building process. To rigorously evaluate the\nagent's performance in this emerging research area, we introduce a\ncomprehensive benchmark consisting of diverse construction tasks designed to\ntest creativity, spatial reasoning, adherence to in-game rules, and the\neffective integration of multimodal instructions. Experimental results using\nvarious GPT-based LLM backends and agent configurations demonstrate the agent's\ncapacity to accurately interpret extensive instructions involving numerous\nitems, their positions, and orientations. The agent successfully produces\ncomplex structures complete with internal functionalities such as\nRedstone-powered systems. A/B testing indicates that the inclusion of a memory\nmodule leads to a significant increase in performance, emphasizing its role in\nenabling continuous learning and the reuse of accumulated experience.\nAdditionally, the agent's unexpected emergence of scaffolding behavior\nhighlights the potential of future LLM-driven agents to utilize subroutine\nplanning and leverage the emergence ability of LLMs to autonomously develop\nhuman-like problem-solving techniques.",
      "tldr_zh": "我们介绍了 APT 框架，这是一种基于 Large Language Models (LLMs) 的系统，允许自主代理在 Minecraft 环境中构建复杂结构，通过 chain-of-thought decomposition 和 multimodal inputs 生成详细的建筑布局和蓝图，实现零样本或少样本学习。框架还整合了记忆和反思模块，以支持终身学习、适应性改进和错误修正。实验结果显示，使用 GPT 模型的代理在基准测试中表现出色，能准确处理多项指令并构建功能性结构，如 Redstone 系统，且添加记忆模块显著提升性能，同时揭示了 LLMs 的新兴能力，如自主开发类似人类的脚手架行为。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.17255v2",
      "published_date": "2024-11-26 09:31:28 UTC",
      "updated_date": "2024-11-29 23:23:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:44:48.777970"
    },
    {
      "arxiv_id": "2411.17254v1",
      "title": "Semantic Data Augmentation for Long-tailed Facial Expression Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Zijian Li",
        "Yan Wang",
        "Bowen Guan",
        "JianKai Yin"
      ],
      "abstract": "Facial Expression Recognition has a wide application prospect in social\nrobotics, health care, driver fatigue monitoring, and many other practical\nscenarios. Automatic recognition of facial expressions has been extensively\nstudied by the Computer Vision research society. But Facial Expression\nRecognition in real-world is still a challenging task, partially due to the\nlong-tailed distribution of the dataset. Many recent studies use data\naugmentation for Long-Tailed Recognition tasks. In this paper, we propose a\nnovel semantic augmentation method. By introducing randomness into the encoding\nof the source data in the latent space of VAE-GAN, new samples are generated.\nThen, for facial expression recognition in RAF-DB dataset, we use our\naugmentation method to balance the long-tailed distribution. Our method can be\nused in not only FER tasks, but also more diverse data-hungry scenarios.",
      "tldr_zh": "本文研究了面部表情识别（Facial Expression Recognition）在真实世界中的挑战，特别是数据集的长尾分布（long-tailed distribution），这影响了其在社交机器人、健康护理和驾驶员疲劳监测等场景中的应用。作者提出了一种新型语义数据增强（semantic augmentation）方法，通过在 VAE-GAN 的潜在空间中引入随机性对源数据进行编码，从而生成新样本，以平衡长尾分布。实验在 RAF-DB 数据集上验证了该方法的有效性，用于提升面部表情识别任务的性能。该方法不仅适用于 FER 任务，还可扩展到更多数据饥饿（data-hungry）场景。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17254v1",
      "published_date": "2024-11-26 09:31:12 UTC",
      "updated_date": "2024-11-26 09:31:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:45:00.928838"
    },
    {
      "arxiv_id": "2411.17249v1",
      "title": "Buffer Anytime: Zero-Shot Video Depth and Normal from Image Priors",
      "title_zh": "翻译失败",
      "authors": [
        "Zhengfei Kuang",
        "Tianyuan Zhang",
        "Kai Zhang",
        "Hao Tan",
        "Sai Bi",
        "Yiwei Hu",
        "Zexiang Xu",
        "Milos Hasan",
        "Gordon Wetzstein",
        "Fujun Luan"
      ],
      "abstract": "We present Buffer Anytime, a framework for estimation of depth and normal\nmaps (which we call geometric buffers) from video that eliminates the need for\npaired video--depth and video--normal training data. Instead of relying on\nlarge-scale annotated video datasets, we demonstrate high-quality video buffer\nestimation by leveraging single-image priors with temporal consistency\nconstraints. Our zero-shot training strategy combines state-of-the-art image\nestimation models based on optical flow smoothness through a hybrid loss\nfunction, implemented via a lightweight temporal attention architecture.\nApplied to leading image models like Depth Anything V2 and Marigold-E2E-FT, our\napproach significantly improves temporal consistency while maintaining\naccuracy. Experiments show that our method not only outperforms image-based\napproaches but also achieves results comparable to state-of-the-art video\nmodels trained on large-scale paired video datasets, despite using no such\npaired video data.",
      "tldr_zh": "本研究提出Buffer Anytime框架，实现零-shot视频深度图和法线图（geometric buffers）的估计，无需配对视频-深度或视频-法线训练数据，而是利用单图像先验（image priors）结合时间一致性约束。框架通过混合损失函数和轻量级时间注意架构（temporal attention architecture）整合基于optical flow平滑的先进图像估计模型，如Depth Anything V2和Marigold-E2E-FT，从而显著提升视频的时序一致性，同时保持高准确性。实验结果显示，该方法优于基于图像的基准模型，并与使用大规模配对视频数据集训练的state-of-the-art视频模型性能相当，尽管不依赖任何此类数据。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17249v1",
      "published_date": "2024-11-26 09:28:32 UTC",
      "updated_date": "2024-11-26 09:28:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:45:12.596038"
    },
    {
      "arxiv_id": "2411.17236v1",
      "title": "From Graph Diffusion to Graph Classification",
      "title_zh": "从图扩散到图分类",
      "authors": [
        "Jia Jun Cheng Xian",
        "Sadegh Mahdavi",
        "Renjie Liao",
        "Oliver Schulte"
      ],
      "abstract": "Generative models such as diffusion models have achieved remarkable success\nin state-of-the-art image and text tasks. Recently, score-based diffusion\nmodels have extended their success beyond image generation, showing competitive\nperformance with discriminative methods in image {\\em classification}\ntasks~\\cite{zimmermann2021score}. However, their application to classification\nin the {\\em graph} domain, which presents unique challenges such as complex\ntopologies, remains underexplored. We show how graph diffusion models can be\napplied for graph classification. We find that to achieve competitive\nclassification accuracy, score-based graph diffusion models should be trained\nwith a novel training objective that is tailored to graph classification. In\nexperiments with a sampling-based inference method, our discriminative training\nobjective achieves state-of-the-art graph classification accuracy.",
      "tldr_zh": "本论文探讨了将diffusion models从图像生成扩展到graph classification领域，针对图的复杂拓扑等挑战提出创新方法。作者发现，score-based graph diffusion models需要一个专为graph classification设计的训练目标，以实现竞争性准确率。通过采样-based推理实验，该判别训练目标达到了state-of-the-art的图分类性能，为图域应用提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17236v1",
      "published_date": "2024-11-26 08:57:41 UTC",
      "updated_date": "2024-11-26 08:57:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:45:24.383907"
    },
    {
      "arxiv_id": "2411.17772v2",
      "title": "MVBoost: Boost 3D Reconstruction with Multi-View Refinement",
      "title_zh": "翻译失败",
      "authors": [
        "Xiangyu Liu",
        "Xiaomei Zhang",
        "Zhiyuan Ma",
        "Xiangyu Zhu",
        "Zhen Lei"
      ],
      "abstract": "Recent advancements in 3D object reconstruction have been remarkable, yet\nmost current 3D models rely heavily on existing 3D datasets. The scarcity of\ndiverse 3D datasets results in limited generalization capabilities of 3D\nreconstruction models. In this paper, we propose a novel framework for boosting\n3D reconstruction with multi-view refinement (MVBoost) by generating pseudo-GT\ndata. The key of MVBoost is combining the advantages of the high accuracy of\nthe multi-view generation model and the consistency of the 3D reconstruction\nmodel to create a reliable data source. Specifically, given a single-view input\nimage, we employ a multi-view diffusion model to generate multiple views,\nfollowed by a large 3D reconstruction model to produce consistent 3D data.\nMVBoost then adaptively refines these multi-view images, rendered from the\nconsistent 3D data, to build a large-scale multi-view dataset for training a\nfeed-forward 3D reconstruction model. Additionally, the input view optimization\nis designed to optimize the corresponding viewpoints based on the user's input\nimage, ensuring that the most important viewpoint is accurately tailored to the\nuser's needs. Extensive evaluations demonstrate that our method achieves\nsuperior reconstruction results and robust generalization compared to prior\nworks.",
      "tldr_zh": "该论文提出 MVBoost 框架，通过多视图精炼（Multi-View Refinement）来提升 3D Reconstruction 的性能，解决现有模型因 3D 数据集稀缺而导致的泛化能力有限问题。方法的核心是结合多视图扩散模型（multi-view diffusion model）从单视图输入生成多个视图，并使用大型 3D 重建模型产生一致的 3D 数据，然后自适应精炼这些图像以构建大规模多视图数据集，用于训练前馈 3D 重建模型。此外，输入视图优化（input view optimization）确保视点精确调整以满足用户需求。实验评估表明，MVBoost 在重建结果和泛化能力上优于现有工作。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17772v2",
      "published_date": "2024-11-26 08:55:20 UTC",
      "updated_date": "2024-12-02 09:04:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:45:36.741594"
    },
    {
      "arxiv_id": "2412.03587v2",
      "title": "Not All Adapters Matter: Selective Adapter Freezing for Memory-Efficient Fine-Tuning of Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Hyegang Son",
        "Yonglak Son",
        "Changhoon Kim",
        "Young Geun Kim"
      ],
      "abstract": "Transformer-based large-scale pre-trained models achieve great success.\nFine-tuning is the standard practice for leveraging these models in downstream\ntasks. Among the fine-tuning methods, adapter-tuning provides a\nparameter-efficient fine-tuning by introducing lightweight trainable modules\nwhile keeping most pre-trained parameters frozen. However, existing\nadapter-tuning methods still impose substantial resource usage. Through our\ninvestigation, we show that each adapter unequally contributes to both task\nperformance and resource usage. Motivated by this insight, we propose Selective\nAdapter FrEezing (SAFE), which gradually freezes less important adapters early\nto reduce unnecessary resource usage while maintaining performance. In our\nexperiments, SAFE reduces memory usage, computation amount, and training time\nby 42.85\\%, 34.59\\%, and 11.82\\%, respectively, while achieving comparable or\nbetter task performance compared to the baseline. We also demonstrate that SAFE\ninduces regularization effect, thereby smoothing the loss landscape, which\nenables the model to generalize better by avoiding sharp minima.",
      "tldr_zh": "该研究发现，在Transformer-based语言模型的adapter-tuning fine-tuning方法中，每个adapter对任务性能和资源使用的贡献不均等。为此，提出Selective Adapter FrEezing (SAFE)方法，通过逐步冻结不太重要的adapters，显著减少内存使用（42.85%）、计算量（34.59%）和训练时间（11.82%），同时实现与基线相当或更好的任务性能。SAFE还引入正则化效果，平滑损失景观，帮助模型更好地泛化并避免sharp minima。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "URL: https://aclanthology.org/2025.naacl-long.480/ Volume:\n  Proceedings of the 2025 Conference of the Nations of the Americas Chapter of\n  the Association for Computational Linguistics: Human Language Technologies\n  (Volume 1: Long Papers) Year: 2025 Address: Albuquerque, New Mexico",
      "pdf_url": "http://arxiv.org/pdf/2412.03587v2",
      "published_date": "2024-11-26 08:41:45 UTC",
      "updated_date": "2025-05-15 14:39:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:45:47.900363"
    },
    {
      "arxiv_id": "2411.17218v1",
      "title": "GraphSubDetector: Time Series Subsequence Anomaly Detection via Density-Aware Adaptive Graph Neural Network",
      "title_zh": "GraphSubDetector：基于密度感知自适应图神经网络的时间序列子序列异常检测",
      "authors": [
        "Weiqi Chen",
        "Zhiqiang Zhou",
        "Qingsong Wen",
        "Liang Sun"
      ],
      "abstract": "Time series subsequence anomaly detection is an important task in a large\nvariety of real-world applications ranging from health monitoring to AIOps, and\nis challenging due to the following reasons: 1) how to effectively learn\ncomplex dynamics and dependencies in time series; 2) diverse and complicated\nanomalous subsequences as well as the inherent variance and noise of normal\npatterns; 3) how to determine the proper subsequence length for effective\ndetection, which is a required parameter for many existing algorithms. In this\npaper, we present a novel approach to subsequence anomaly detection, namely\nGraphSubDetector. First, it adaptively learns the appropriate subsequence\nlength with a length selection mechanism that highlights the characteristics of\nboth normal and anomalous patterns. Second, we propose a density-aware adaptive\ngraph neural network (DAGNN), which can generate further robust representations\nagainst variance of normal data for anomaly detection by message passing\nbetween subsequences. The experimental results demonstrate the effectiveness of\nthe proposed algorithm, which achieves superior performance on multiple time\nseries anomaly benchmark datasets compared to state-of-the-art algorithms.",
      "tldr_zh": "这篇论文针对时间序列子序列异常检测的问题，提出了GraphSubDetector方法，以应对复杂动态依赖、异常模式多样性和子序列长度选择的挑战。GraphSubDetector包括一个长度选择机制，能够适应性学习合适的子序列长度，并突出正常和异常模式的特征；同时，它引入了density-aware adaptive graph neural network (DAGNN)，通过子序列之间的消息传递生成对正常数据变异更鲁棒的表示。实验结果显示，该方法在多个时间序列异常基准数据集上，相比最先进算法取得了优越的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17218v1",
      "published_date": "2024-11-26 08:36:07 UTC",
      "updated_date": "2024-11-26 08:36:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:46:00.266796"
    },
    {
      "arxiv_id": "2411.17204v2",
      "title": "Strategic Prompting for Conversational Tasks: A Comparative Analysis of Large Language Models Across Diverse Conversational Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Ratnesh Kumar Joshi",
        "Priyanshu Priya",
        "Vishesh Desai",
        "Saurav Dudhate",
        "Siddhant Senapati",
        "Asif Ekbal",
        "Roshni Ramnani",
        "Anutosh Maitra",
        "Shubhashis Sengupta"
      ],
      "abstract": "Given the advancements in conversational artificial intelligence, the\nevaluation and assessment of Large Language Models (LLMs) play a crucial role\nin ensuring optimal performance across various conversational tasks. In this\npaper, we present a comprehensive study that thoroughly evaluates the\ncapabilities and limitations of five prevalent LLMs: Llama, OPT, Falcon,\nAlpaca, and MPT. The study encompasses various conversational tasks, including\nreservation, empathetic response generation, mental health and legal\ncounseling, persuasion, and negotiation. To conduct the evaluation, an\nextensive test setup is employed, utilizing multiple evaluation criteria that\nspan from automatic to human evaluation. This includes using generic and\ntask-specific metrics to gauge the LMs' performance accurately. From our\nevaluation, no single model emerges as universally optimal for all tasks.\nInstead, their performance varies significantly depending on the specific\nrequirements of each task. While some models excel in certain tasks, they may\ndemonstrate comparatively poorer performance in others. These findings\nemphasize the importance of considering task-specific requirements and\ncharacteristics when selecting the most suitable LM for conversational\napplications.",
      "tldr_zh": "本研究对五个主流大语言模型（LLMs）——Llama、OPT、Falcon、Alpaca 和 MPT——在多种对话任务中的性能进行了全面比较，包括预订、移情响应生成、心理健康和法律咨询、说服以及谈判。研究采用多种评估标准，如自动和人工评估，以及通用和任务特定的指标，来评估这些模型的优缺点。结果显示，没有一个模型在所有任务中表现出色，性能因任务要求而异，这强调了在选择 LLMs 用于对话应用时，需要考虑任务的具体特性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "39 pages, 12 tables",
      "pdf_url": "http://arxiv.org/pdf/2411.17204v2",
      "published_date": "2024-11-26 08:21:24 UTC",
      "updated_date": "2024-11-28 01:04:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:46:11.904957"
    },
    {
      "arxiv_id": "2412.04492v1",
      "title": "Socio-Emotional Response Generation: A Human Evaluation Protocol for LLM-Based Conversational Systems",
      "title_zh": "社会情感响应生成：一种针对基于LLM的对话系统的人类评估协议",
      "authors": [
        "Lorraine Vanel",
        "Ariel R. Ramos Vela",
        "Alya Yacoubi",
        "Chloé Clavel"
      ],
      "abstract": "Conversational systems are now capable of producing impressive and generally\nrelevant responses. However, we have no visibility nor control of the\nsocio-emotional strategies behind state-of-the-art Large Language Models\n(LLMs), which poses a problem in terms of their transparency and thus their\ntrustworthiness for critical applications. Another issue is that current\nautomated metrics are not able to properly evaluate the quality of generated\nresponses beyond the dataset's ground truth. In this paper, we propose a neural\narchitecture that includes an intermediate step in planning socio-emotional\nstrategies before response generation. We compare the performance of\nopen-source baseline LLMs to the outputs of these same models augmented with\nour planning module. We also contrast the outputs obtained from automated\nmetrics and evaluation results provided by human annotators. We describe a\nnovel evaluation protocol that includes a coarse-grained consistency\nevaluation, as well as a finer-grained annotation of the responses on various\nsocial and emotional criteria. Our study shows that predicting a sequence of\nexpected strategy labels and using this sequence to generate a response yields\nbetter results than a direct end-to-end generation scheme. It also highlights\nthe divergences and the limits of current evaluation metrics for generated\ncontent. The code for the annotation platform and the annotated data are made\npublicly available for the evaluation of future models.",
      "tldr_zh": "这篇论文针对大型语言模型(LLMs)驱动的对话系统，探讨了社会情感响应生成的透明度和可信度问题，提出了一种神经架构，通过在响应生成前添加社会情感策略规划的中间步骤来提升输出质量。研究比较了基线LLMs与增强规划模块的模型性能，并设计了一个新的人类评估协议，包括粗粒度一致性评估和细粒度社会情感标准标注，结果显示使用预期策略序列生成响应比直接端到端方案更有效。论文还强调了当前自动化指标的局限性，并公开了代码和标注数据，以支持未来模型的评估。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.SI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.04492v1",
      "published_date": "2024-11-26 08:15:36 UTC",
      "updated_date": "2024-11-26 08:15:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:46:24.329141"
    },
    {
      "arxiv_id": "2411.17201v1",
      "title": "Learning Hierarchical Polynomials of Multiple Nonlinear Features with Three-Layer Networks",
      "title_zh": "利用三层网络学习多个非线性特征的层次多项式",
      "authors": [
        "Hengyu Fu",
        "Zihao Wang",
        "Eshaan Nichani",
        "Jason D. Lee"
      ],
      "abstract": "In deep learning theory, a critical question is to understand how neural\nnetworks learn hierarchical features. In this work, we study the learning of\nhierarchical polynomials of \\textit{multiple nonlinear features} using\nthree-layer neural networks. We examine a broad class of functions of the form\n$f^{\\star}=g^{\\star}\\circ \\bp$, where $\\bp:\\mathbb{R}^{d} \\rightarrow\n\\mathbb{R}^{r}$ represents multiple quadratic features with $r \\ll d$ and\n$g^{\\star}:\\mathbb{R}^{r}\\rightarrow \\mathbb{R}$ is a polynomial of degree $p$.\nThis can be viewed as a nonlinear generalization of the multi-index model\n\\citep{damian2022neural}, and also an expansion upon previous work that focused\nonly on a single nonlinear feature, i.e. $r = 1$\n\\citep{nichani2023provable,wang2023learning}.\n  Our primary contribution shows that a three-layer neural network trained via\nlayerwise gradient descent suffices for\n  \\begin{itemize}\\item complete recovery of the space spanned by the nonlinear\nfeatures\n  \\item efficient learning of the target function $f^{\\star}=g^{\\star}\\circ\n\\bp$ or transfer learning of $f=g\\circ \\bp$ with a different link function\n  \\end{itemize} within $\\widetilde{\\cO}(d^4)$ samples and polynomial time. For\nsuch hierarchical targets, our result substantially improves the sample\ncomplexity ${\\Theta}(d^{2p})$ of the kernel methods, demonstrating the power of\nefficient feature learning. It is important to highlight that{ our results\nleverage novel techniques and thus manage to go beyond all prior settings} such\nas single-index and multi-index models as well as models depending just on one\nnonlinear feature, contributing to a more comprehensive understanding of\nfeature learning in deep learning.",
      "tldr_zh": "这篇论文研究了使用三层神经网络学习多重非线性特征的层次多项式，扩展了多索引模型和单一非线性特征（r=1）的先前工作。作者证明，通过层级梯度下降，三层网络能够在$\\widetilde{\\mathcal{O}}(d^4)$个样本和多项式时间内完全恢复非线性特征空间，并高效学习目标函数$f^{\\star}=g^{\\star}\\circ \\bp$或进行转移学习。相比核方法的样本复杂度$\\Theta(d^{2p})$，该方法显著降低了需求，展示了神经网络在特征学习中的强大优势，并超越了单索引、多索引等现有模型。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.ST",
        "stat.ML",
        "stat.TH"
      ],
      "primary_category": "cs.LG",
      "comment": "78 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.17201v1",
      "published_date": "2024-11-26 08:14:48 UTC",
      "updated_date": "2024-11-26 08:14:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:46:36.885795"
    },
    {
      "arxiv_id": "2411.17176v1",
      "title": "ChatGen: Automatic Text-to-Image Generation From FreeStyle Chatting",
      "title_zh": "翻译失败",
      "authors": [
        "Chengyou Jia",
        "Changliang Xia",
        "Zhuohang Dang",
        "Weijia Wu",
        "Hangwei Qian",
        "Minnan Luo"
      ],
      "abstract": "Despite the significant advancements in text-to-image (T2I) generative\nmodels, users often face a trial-and-error challenge in practical scenarios.\nThis challenge arises from the complexity and uncertainty of tedious steps such\nas crafting suitable prompts, selecting appropriate models, and configuring\nspecific arguments, making users resort to labor-intensive attempts for desired\nimages. This paper proposes Automatic T2I generation, which aims to automate\nthese tedious steps, allowing users to simply describe their needs in a\nfreestyle chatting way. To systematically study this problem, we first\nintroduce ChatGenBench, a novel benchmark designed for Automatic T2I. It\nfeatures high-quality paired data with diverse freestyle inputs, enabling\ncomprehensive evaluation of automatic T2I models across all steps.\nAdditionally, recognizing Automatic T2I as a complex multi-step reasoning task,\nwe propose ChatGen-Evo, a multi-stage evolution strategy that progressively\nequips models with essential automation skills. Through extensive evaluation\nacross step-wise accuracy and image quality, ChatGen-Evo significantly enhances\nperformance over various baselines. Our evaluation also uncovers valuable\ninsights for advancing automatic T2I. All our data, code, and models will be\navailable in \\url{https://chengyou-jia.github.io/ChatGen-Home}",
      "tldr_zh": "本论文针对文本到图像 (T2I) 生成模型的用户试错挑战，提出 Automatic T2I 生成方法，让用户通过自由聊天方式描述需求，自动化提示制作、模型选择和参数配置等步骤。作者引入 ChatGenBench 基准，该基准包含高质量的配对数据，用于全面评估自动 T2I 模型的多步性能。论文还提出 ChatGen-Evo，一个多阶段进化策略，通过逐步推理帮助模型获得自动化技能。实验结果显示，ChatGen-Evo 在逐步准确性和图像质量上显著优于基线模型，并提供了推进该领域的宝贵见解。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17176v1",
      "published_date": "2024-11-26 07:31:12 UTC",
      "updated_date": "2024-11-26 07:31:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:46:48.905930"
    },
    {
      "arxiv_id": "2411.17170v1",
      "title": "Learning Monotonic Attention in Transducer for Streaming Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhengrui Ma",
        "Yang Feng",
        "Min Zhang"
      ],
      "abstract": "Streaming generation models are increasingly utilized across various fields,\nwith the Transducer architecture being particularly popular in industrial\napplications. However, its input-synchronous decoding mechanism presents\nchallenges in tasks requiring non-monotonic alignments, such as simultaneous\ntranslation, leading to suboptimal performance in these contexts. In this\nresearch, we address this issue by tightly integrating Transducer's decoding\nwith the history of input stream via a learnable monotonic attention mechanism.\nOur approach leverages the forward-backward algorithm to infer the posterior\nprobability of alignments between the predictor states and input timestamps,\nwhich is then used to estimate the context representations of monotonic\nattention in training. This allows Transducer models to adaptively adjust the\nscope of attention based on their predictions, avoiding the need to enumerate\nthe exponentially large alignment space. Extensive experiments demonstrate that\nour MonoAttn-Transducer significantly enhances the handling of non-monotonic\nalignments in streaming generation, offering a robust solution for\nTransducer-based frameworks to tackle more complex streaming generation tasks.",
      "tldr_zh": "本研究针对 Transducer 架构在流式生成任务中的问题，特别是处理非单调对齐（如同时翻译）时性能不佳的问题，提出了一种可学习的单调注意力机制（Monotonic Attention）。该方法通过前向-后向算法（forward-backward algorithm）推断预测器状态与输入时间戳的对齐概率，并据此估计注意力的上下文表示，从而使 Transducer 模型能够动态调整注意力范围，避免枚举庞大的对齐空间。实验结果显示，MonoAttn-Transducer 显著提升了非单调对齐的处理能力，为 Transducer 框架应对更复杂的流式生成任务提供了稳健解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Codes: https://github.com/ictnlp/MonoAttn-Transducer",
      "pdf_url": "http://arxiv.org/pdf/2411.17170v1",
      "published_date": "2024-11-26 07:19:26 UTC",
      "updated_date": "2024-11-26 07:19:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:47:01.390268"
    },
    {
      "arxiv_id": "2412.00073v1",
      "title": "Addressing Vulnerabilities in AI-Image Detection: Challenges and Proposed Solutions",
      "title_zh": "翻译失败",
      "authors": [
        "Justin Jiang"
      ],
      "abstract": "The rise of advanced AI models like Generative Adversarial Networks (GANs)\nand diffusion models such as Stable Diffusion has made the creation of highly\nrealistic images accessible, posing risks of misuse in misinformation and\nmanipulation. This study evaluates the effectiveness of convolutional neural\nnetworks (CNNs), as well as DenseNet architectures, for detecting AI-generated\nimages. Using variations of the CIFAKE dataset, including images generated by\ndifferent versions of Stable Diffusion, we analyze the impact of updates and\nmodifications such as Gaussian blurring, prompt text changes, and Low-Rank\nAdaptation (LoRA) on detection accuracy. The findings highlight vulnerabilities\nin current detection methods and propose strategies to enhance the robustness\nand reliability of AI-image detection systems.",
      "tldr_zh": "本研究探讨了AI生成图像检测的漏洞问题，特别是GANs和Stable Diffusion等模型导致的图像误用风险。研究评估了CNNs和DenseNet在检测AI生成图像方面的有效性，使用CIFAKE数据集及其变体，包括Stable Diffusion版本更新、Gaussian blurring、prompt text changes和LoRA的影响因素。结果显示，这些因素显著降低了检测准确性，暴露了当前方法的脆弱性。该研究提出策略来提升AI图像检测系统的鲁棒性和可靠性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.00073v1",
      "published_date": "2024-11-26 06:35:26 UTC",
      "updated_date": "2024-11-26 06:35:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:47:11.584075"
    },
    {
      "arxiv_id": "2411.17137v1",
      "title": "Self-reconfiguration Strategies for Space-distributed Spacecraft",
      "title_zh": "翻译失败",
      "authors": [
        "Tianle Liu",
        "Zhixiang Wang",
        "Yongwei Zhang",
        "Ziwei Wang",
        "Zihao Liu",
        "Yizhai Zhang",
        "Panfeng Huang"
      ],
      "abstract": "This paper proposes a distributed on-orbit spacecraft assembly algorithm,\nwhere future spacecraft can assemble modules with different functions on orbit\nto form a spacecraft structure with specific functions. This form of spacecraft\norganization has the advantages of reconfigurability, fast mission response and\neasy maintenance. Reasonable and efficient on-orbit self-reconfiguration\nalgorithms play a crucial role in realizing the benefits of distributed\nspacecraft. This paper adopts the framework of imitation learning combined with\nreinforcement learning for strategy learning of module handling order. A robot\narm motion algorithm is then designed to execute the handling sequence. We\nachieve the self-reconfiguration handling task by creating a map on the surface\nof the module, completing the path point planning of the robotic arm using A*.\nThe joint planning of the robotic arm is then accomplished through forward and\nreverse kinematics. Finally, the results are presented in Unity3D.",
      "tldr_zh": "该论文提出了一种分布式在轨航天器组装算法，允许模块在轨道上自重构以形成特定功能结构，从而实现可重构性、快速任务响应和易维护的优势。算法采用 imitation learning 结合 reinforcement learning 的框架来学习模块处理顺序，并设计机器人臂运动算法执行序列，包括使用 A* 算法进行路径点规划和正向/反向运动学实现关节规划。最后，结果在 Unity3D 中进行演示，展示了该策略的有效性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17137v1",
      "published_date": "2024-11-26 06:05:44 UTC",
      "updated_date": "2024-11-26 06:05:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:47:23.952832"
    },
    {
      "arxiv_id": "2411.17135v1",
      "title": "LLM-Based Offline Learning for Embodied Agents via Consistency-Guided Reward Ensemble",
      "title_zh": "翻译失败",
      "authors": [
        "Yujeong Lee",
        "Sangwoo Shin",
        "Wei-Jin Park",
        "Honguk Woo"
      ],
      "abstract": "Employing large language models (LLMs) to enable embodied agents has become\npopular, yet it presents several limitations in practice. In this work, rather\nthan using LLMs directly as agents, we explore their use as tools for embodied\nagent learning. Specifically, to train separate agents via offline\nreinforcement learning (RL), an LLM is used to provide dense reward feedback on\nindividual actions in training datasets. In doing so, we present a\nconsistency-guided reward ensemble framework (CoREN), designed for tackling\ndifficulties in grounding LLM-generated estimates to the target environment\ndomain. The framework employs an adaptive ensemble of spatio-temporally\nconsistent rewards to derive domain-grounded rewards in the training datasets,\nthus enabling effective offline learning of embodied agents in different\nenvironment domains. Experiments with the VirtualHome benchmark demonstrate\nthat CoREN significantly outperforms other offline RL agents, and it also\nachieves comparable performance to state-of-the-art LLM-based agents with 8B\nparameters, despite CoREN having only 117M parameters for the agent policy\nnetwork and using LLMs only for training.",
      "tldr_zh": "这篇论文探索使用大型语言模型 (LLMs) 作为工具来训练实体代理，而不是直接作为代理，通过提供训练数据集中的密集奖励反馈来实现离线强化学习 (offline RL)。他们提出了一种一致性引导的奖励集成框架 (CoREN)，该框架采用自适应集成空间-时间一致奖励，以确保 LLM 生成的奖励与目标环境领域紧密结合，从而提升代理的离线学习效果。在 VirtualHome 基准测试中，CoREN 显著优于其他离线 RL 代理，并与最先进的 8B 参数 LLM 代理性能相当，尽管其代理策略网络仅为 117M 参数，且仅在训练中使用 LLMs。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Findings of EMNLP-2024 Camera Ready Version",
      "pdf_url": "http://arxiv.org/pdf/2411.17135v1",
      "published_date": "2024-11-26 06:04:10 UTC",
      "updated_date": "2024-11-26 06:04:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:47:36.493813"
    },
    {
      "arxiv_id": "2411.17125v1",
      "title": "DOGE: Towards Versatile Visual Document Grounding and Referring",
      "title_zh": "翻译失败",
      "authors": [
        "Yinan Zhou",
        "Yuxin Chen",
        "Haokun Lin",
        "Shuyu Yang",
        "Li Zhu",
        "Zhongang Qi",
        "Chen Ma",
        "Ying Shan"
      ],
      "abstract": "In recent years, Multimodal Large Language Models (MLLMs) have increasingly\nemphasized grounding and referring capabilities to achieve detailed\nunderstanding and flexible user interaction. However, in the realm of visual\ndocument understanding, these capabilities lag behind due to the scarcity of\nfine-grained datasets and comprehensive benchmarks. To fill this gap, we\npropose the DOcument Grounding and Eferring data engine (DOGE-Engine), which\nproduces two types of high-quality fine-grained document data: multi-granular\nparsing data for enhancing fundamental text localization and recognition\ncapabilities; and instruction-tuning data to activate MLLM's grounding and\nreferring capabilities during dialogue and reasoning. Additionally, using our\nengine, we construct DOGE-Bench, which encompasses 7 grounding and referring\ntasks across 3 document types (chart, poster, PDF document), providing\ncomprehensive evaluations for fine-grained document understanding. Furthermore,\nleveraging the data generated by our engine, we develop a strong baseline\nmodel, DOGE. This pioneering MLLM is capable of accurately referring and\ngrounding texts at multiple granularities within document images. Our code,\ndata, and model will be open-sourced for community development.",
      "tldr_zh": "本研究针对 Multimodal Large Language Models (MLLMs) 在视觉文档理解中 grounding 和 referring 能力的不足，提出 DOcument Grounding and Eferring data engine (DOGE-Engine)，该引擎生成多粒度解析数据和指令微调数据，以提升文本定位、识别以及对话推理能力。基于此引擎，构建了 DOGE-Bench 基准测试，涵盖 7 个 grounding 和 referring 任务以及 chart、poster 和 PDF document 等 3 种文档类型，提供全面的细粒度文档评估。最终，论文开发了 DOGE 模型作为强基线，实现多粒度文本 grounding 和 referring 的准确处理，并计划开源代码、数据和模型，以推动社区发展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "20 pages, 13 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.17125v1",
      "published_date": "2024-11-26 05:38:34 UTC",
      "updated_date": "2024-11-26 05:38:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:47:50.323619"
    },
    {
      "arxiv_id": "2411.17123v1",
      "title": "Advancing Content Moderation: Evaluating Large Language Models for Detecting Sensitive Content Across Text, Images, and Videos",
      "title_zh": "推进内容审核：评估大语言模型检测文本、图像",
      "authors": [
        "Nouar AlDahoul",
        "Myles Joshua Toledo Tan",
        "Harishwar Reddy Kasireddy",
        "Yasir Zaki"
      ],
      "abstract": "The widespread dissemination of hate speech, harassment, harmful and sexual\ncontent, and violence across websites and media platforms presents substantial\nchallenges and provokes widespread concern among different sectors of society.\nGovernments, educators, and parents are often at odds with media platforms\nabout how to regulate, control, and limit the spread of such content.\nTechnologies for detecting and censoring the media contents are a key solution\nto addressing these challenges. Techniques from natural language processing and\ncomputer vision have been used widely to automatically identify and filter out\nsensitive content such as offensive languages, violence, nudity, and addiction\nin both text, images, and videos, enabling platforms to enforce content\npolicies at scale. However, existing methods still have limitations in\nachieving high detection accuracy with fewer false positives and false\nnegatives. Therefore, more sophisticated algorithms for understanding the\ncontext of both text and image may open rooms for improvement in content\ncensorship to build a more efficient censorship system. In this paper, we\nevaluate existing LLM-based content moderation solutions such as OpenAI\nmoderation model and Llama-Guard3 and study their capabilities to detect\nsensitive contents. Additionally, we explore recent LLMs such as GPT, Gemini,\nand Llama in identifying inappropriate contents across media outlets. Various\ntextual and visual datasets like X tweets, Amazon reviews, news articles, human\nphotos, cartoons, sketches, and violence videos have been utilized for\nevaluation and comparison. The results demonstrate that LLMs outperform\ntraditional techniques by achieving higher accuracy and lower false positive\nand false negative rates. This highlights the potential to integrate LLMs into\nwebsites, social media platforms, and video-sharing services for regulatory and\ncontent moderation purposes.",
      "tldr_zh": "该研究评估了大型语言模型（LLMs）在检测文本、图像和视频中敏感内容（如仇恨言论、骚扰和暴力）的效能，针对现有内容审核技术的局限性提出改进方案。研究比较了现有LLM解决方案，如OpenAI moderation model和Llama-Guard3，以及其他模型如GPT、Gemini和Llama，使用数据集包括X tweets、Amazon reviews、新闻文章、人像照片、卡通、素描和暴力视频。结果显示，LLMs在准确率上优于传统技术，同时降低了假阳性和假阴性率。最终，该论文强调了将LLMs整合到网站、社会媒体和视频平台中，以构建更高效的内容审核系统。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "55 pages, 16 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.17123v1",
      "published_date": "2024-11-26 05:29:18 UTC",
      "updated_date": "2024-11-26 05:29:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:48:01.749087"
    },
    {
      "arxiv_id": "2411.17116v2",
      "title": "Star Attention: Efficient LLM Inference over Long Sequences",
      "title_zh": "翻译失败",
      "authors": [
        "Shantanu Acharya",
        "Fei Jia",
        "Boris Ginsburg"
      ],
      "abstract": "Inference with Transformer-based Large Language Models (LLMs) on long\nsequences is both costly and slow due to the quadratic complexity of the\nself-attention mechanism. We introduce Star Attention, a two-phase block-sparse\napproximation that improves computational efficiency by sharding attention\nacross multiple hosts while minimizing communication overhead. In the first\nphase, the context is processed using blockwise-local attention across hosts,\nin parallel. In the second phase, query and response tokens attend to all prior\ncached tokens through sequence-global attention. Star Attention integrates\nseamlessly with most Transformer-based LLMs trained with global attention,\nreducing memory requirements and inference time by up to 11x while preserving\n97-100% of accuracy.",
      "tldr_zh": "本论文提出 Star Attention，一种两阶段块稀疏近似方法，用于提升 Transformer-based LLMs 在长序列推理中的计算效率，通过在多个主机上分片注意力来最小化通信开销。第一阶段采用块式局部注意力并行处理上下文，第二阶段则让查询和响应标记通过序列全局注意力关注所有先前缓存标记。该方法可与大多数使用全局注意力的 Transformer 模型无缝整合，减少内存需求和推理时间高达 11 倍，同时保持 97-100% 的准确性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Code: https://github.com/NVIDIA/Star-Attention",
      "pdf_url": "http://arxiv.org/pdf/2411.17116v2",
      "published_date": "2024-11-26 05:10:04 UTC",
      "updated_date": "2025-04-20 21:50:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:48:12.840867"
    },
    {
      "arxiv_id": "2411.17764v1",
      "title": "PROGRESSOR: A Perceptually Guided Reward Estimator with Self-Supervised Online Refinement",
      "title_zh": "翻译失败",
      "authors": [
        "Tewodros Ayalew",
        "Xiao Zhang",
        "Kevin Yuanbo Wu",
        "Tianchong Jiang",
        "Michael Maire",
        "Matthew R. Walter"
      ],
      "abstract": "We present PROGRESSOR, a novel framework that learns a task-agnostic reward\nfunction from videos, enabling policy training through goal-conditioned\nreinforcement learning (RL) without manual supervision. Underlying this reward\nis an estimate of the distribution over task progress as a function of the\ncurrent, initial, and goal observations that is learned in a self-supervised\nfashion. Crucially, PROGRESSOR refines rewards adversarially during online RL\ntraining by pushing back predictions for out-of-distribution observations, to\nmitigate distribution shift inherent in non-expert observations. Utilizing this\nprogress prediction as a dense reward together with an adversarial push-back,\nwe show that PROGRESSOR enables robots to learn complex behaviors without any\nexternal supervision. Pretrained on large-scale egocentric human video from\nEPIC-KITCHENS, PROGRESSOR requires no fine-tuning on in-domain task-specific\ndata for generalization to real-robot offline RL under noisy demonstrations,\noutperforming contemporary methods that provide dense visual reward for robotic\nlearning. Our findings highlight the potential of PROGRESSOR for scalable\nrobotic applications where direct action labels and task-specific rewards are\nnot readily available.",
      "tldr_zh": "我们介绍了 PROGRESSOR，一种从视频中学习任务无关奖励函数的框架，通过自监督方式估计任务进展分布（基于当前、初始和目标观察），并在在线强化学习（RL）训练中通过对抗性精炼来缓解分布偏移问题。该框架使用进展预测作为密集奖励，使机器人无需外部监督即可学习复杂行为，并在 EPIC-KITCHENS 数据上预训练后，实现对真实机器人离线 RL 的泛化，优于现有提供密集视觉奖励的方法。总体而言，PROGRESSOR 展示了其在可扩展机器人应用中的潜力，尤其适用于缺乏直接行动标签和任务特定奖励的场景。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "15 pages,13 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.17764v1",
      "published_date": "2024-11-26 04:17:51 UTC",
      "updated_date": "2024-11-26 04:17:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:48:25.795568"
    },
    {
      "arxiv_id": "2412.00071v2",
      "title": "COAP: Memory-Efficient Training with Correlation-Aware Gradient Projection",
      "title_zh": "COAP：相关性感知梯度投影的内存高效训练",
      "authors": [
        "Jinqi Xiao",
        "Shen Sang",
        "Tiancheng Zhi",
        "Jing Liu",
        "Qing Yan",
        "Yuqian Zhang",
        "Linjie Luo",
        "Bo Yuan"
      ],
      "abstract": "Training large-scale neural networks in vision, and multimodal domains\ndemands substantial memory resources, primarily due to the storage of optimizer\nstates. While LoRA, a popular parameter-efficient method, reduces memory usage,\nit often suffers from suboptimal performance due to the constraints of low-rank\nupdates. Low-rank gradient projection methods (e.g., GaLore, Flora) reduce\noptimizer memory by projecting gradients and moment estimates into low-rank\nspaces via singular value decomposition or random projection. However, they\nfail to account for inter-projection correlation, causing performance\ndegradation, and their projection strategies often incur high computational\ncosts. In this paper, we present COAP (Correlation-Aware Gradient Projection),\na memory-efficient method that minimizes computational overhead while\nmaintaining training performance. Evaluated across various vision, language,\nand multimodal tasks, COAP outperforms existing methods in both training speed\nand model performance. For LLaMA-1B, it reduces optimizer memory by 61% with\nonly 2% additional time cost, achieving the same PPL as AdamW. With 8-bit\nquantization, COAP cuts optimizer memory by 81% and achieves 4x speedup over\nGaLore for LLaVA-v1.5-7B fine-tuning, while delivering higher accuracy.",
      "tldr_zh": "本文提出 COAP（Correlation-Aware Gradient Projection），一种内存高效的训练方法，通过考虑梯度投影间的相关性来优化低秩更新，解决现有方法（如 GaLore 和 Flora）忽略相关性导致性能下降和计算成本高的难题。COAP 在视觉、语言和多模态任务上表现出色，例如为 LLaMA-1B 减少 61% 优化器内存，仅增加 2% 时间成本，同时达到 AdamW 相同的 PPL（Perplexity）。在 LLaVA-v1.5-7B 微调中，使用 8-bit 量化后，COAP 进一步降低 81% 内存并实现 4 倍于 GaLore 的速度提升，同时获得更高准确率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.00071v2",
      "published_date": "2024-11-26 03:50:52 UTC",
      "updated_date": "2025-03-12 00:36:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:48:40.230675"
    },
    {
      "arxiv_id": "2411.17080v2",
      "title": "DeepMDV: Learning Global Matching for Multi-depot Vehicle Routing Problems",
      "title_zh": "DeepMDV：针对多仓库车辆路径问题的全局匹配学习",
      "authors": [
        "Saeed Nasehi",
        "Farhana Choudhury",
        "Egemen Tanin"
      ],
      "abstract": "Due to the substantial rise in online retail and e-commerce in recent years,\nthe demand for efficient and fast solutions to Vehicle Routing Problems (VRP)\nhas become critical. To manage the increasing demand, companies have adopted\nthe strategy of adding more depots. However, the presence of multiple depots\nintroduces additional complexities, making existing VRP solutions suboptimal\nfor addressing the Multi-depot Vehicle Routing Problem (MDVRP). Traditional\nmethods for solving the MDVRP often require significant computation time,\nmaking them unsuitable for large-scale instances. Additionally, existing\nlearning-based solutions for the MDVRP struggle with generalizability and fail\nto deliver high-quality results for scenarios involving a large number of\ncustomers. In this paper, we propose a novel solution for MDVRP. Our approach\nemploys an attention mechanism, featuring a decoder with two key layers: one\nlayer to consider the states of all vehicles and learn to select the most\nsuitable vehicle based on the proximity of unassigned customers, and another\nlayer to focus on assigning a customer to the selected vehicle. This approach\ndelivers high-quality solutions for large-scale MDVRP instances and\ndemonstrates remarkable generalizability across varying numbers of customers\nand depots. Its adaptability and performance make it a practical and deployable\nsolution for real-world logistics challenges.",
      "tldr_zh": "该论文针对多仓库车辆路径问题 (MDVRP) 的复杂性提出了一种新方法 DeepMDV，以应对电商增长导致的大规模物流需求挑战。DeepMDV 采用注意力机制 (attention mechanism) 的解码器，包含两个关键层：一个层评估所有车辆的状态并基于未分配客户的 Proximity 选择最适合车辆，另一个层负责将客户分配给选定车辆。该方法在大型 MDVRP 实例上提供高质量解决方案，并展现出卓越的泛化性，可适应不同客户和仓库数量，适用于实际物流部署。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17080v2",
      "published_date": "2024-11-26 03:41:01 UTC",
      "updated_date": "2024-12-10 03:19:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:48:49.787795"
    },
    {
      "arxiv_id": "2411.17077v1",
      "title": "Contrastive CFG: Improving CFG in Diffusion Models by Contrasting Positive and Negative Concepts",
      "title_zh": "翻译失败",
      "authors": [
        "Jinho Chang",
        "Hyungjin Chung",
        "Jong Chul Ye"
      ],
      "abstract": "As Classifier-Free Guidance (CFG) has proven effective in conditional\ndiffusion model sampling for improved condition alignment, many applications\nuse a negated CFG term to filter out unwanted features from samples. However,\nsimply negating CFG guidance creates an inverted probability distribution,\noften distorting samples away from the marginal distribution. Inspired by\nrecent advances in conditional diffusion models for inverse problems, here we\npresent a novel method to enhance negative CFG guidance using contrastive loss.\nSpecifically, our guidance term aligns or repels the denoising direction based\non the given condition through contrastive loss, achieving a nearly identical\nguiding direction to traditional CFG for positive guidance while overcoming the\nlimitations of existing negative guidance methods. Experimental results\ndemonstrate that our approach effectively removes undesirable concepts while\nmaintaining sample quality across diverse scenarios, from simple class\nconditions to complex and overlapping text prompts.",
      "tldr_zh": "这篇论文提出了一种名为 Contrastive CFG 的新方法，用于改进扩散模型中的 Classifier-Free Guidance (CFG)，通过对比正负概念来增强负向指导。传统 CFG 在过滤 unwanted features 时会因简单否定而扭曲样本分布，该方法利用 contrastive loss 调整 denoising direction，使其在正向指导时与传统 CFG 一致，同时克服负向指导的局限。实验结果表明，该方法在从简单类条件到复杂文本提示的多种场景中，能够有效去除 undesirable concepts，同时保持样本质量。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.17077v1",
      "published_date": "2024-11-26 03:29:27 UTC",
      "updated_date": "2024-11-26 03:29:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:49:00.802407"
    },
    {
      "arxiv_id": "2411.17073v1",
      "title": "Path-RAG: Knowledge-Guided Key Region Retrieval for Open-ended Pathology Visual Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Awais Naeem",
        "Tianhao Li",
        "Huang-Ru Liao",
        "Jiawei Xu",
        "Aby M. Mathew",
        "Zehao Zhu",
        "Zhen Tan",
        "Ajay Kumar Jaiswal",
        "Raffi A. Salibian",
        "Ziniu Hu",
        "Tianlong Chen",
        "Ying Ding"
      ],
      "abstract": "Accurate diagnosis and prognosis assisted by pathology images are essential\nfor cancer treatment selection and planning. Despite the recent trend of\nadopting deep-learning approaches for analyzing complex pathology images, they\nfall short as they often overlook the domain-expert understanding of tissue\nstructure and cell composition. In this work, we focus on a challenging\nOpen-ended Pathology VQA (PathVQA-Open) task and propose a novel framework\nnamed Path-RAG, which leverages HistoCartography to retrieve relevant domain\nknowledge from pathology images and significantly improves performance on\nPathVQA-Open. Admitting the complexity of pathology image analysis, Path-RAG\nadopts a human-centered AI approach by retrieving domain knowledge using\nHistoCartography to select the relevant patches from pathology images. Our\nexperiments suggest that domain guidance can significantly boost the accuracy\nof LLaVA-Med from 38% to 47%, with a notable gain of 28% for H&E-stained\npathology images in the PathVQA-Open dataset. For longer-form question and\nanswer pairs, our model consistently achieves significant improvements of 32.5%\nin ARCH-Open PubMed and 30.6% in ARCH-Open Books on H\\&E images. Our code and\ndataset is available here (https://github.com/embedded-robotics/path-rag).",
      "tldr_zh": "该研究针对开放式病理视觉问答（PathVQA-Open）任务，提出Path-RAG框架，利用HistoCartography从病理图像中检索相关领域知识，以弥补深度学习方法忽略组织结构和细胞组成的问题。Path-RAG采用人类中心AI方法，通过选择关键补丁来提升模型性能，显著提高了LLaVA-Med的准确率从38%到47%，尤其在H&E-stained图像上提升28%。此外，在ARCH-Open PubMed和ARCH-Open Books数据集上，该框架在H&E图像的更长问答对上实现了32.5%和30.6%的性能改进。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17073v1",
      "published_date": "2024-11-26 03:22:01 UTC",
      "updated_date": "2024-11-26 03:22:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:49:13.390127"
    },
    {
      "arxiv_id": "2412.00070v1",
      "title": "Recurrent Stochastic Configuration Networks with Hybrid Regularization for Nonlinear Dynamics Modelling",
      "title_zh": "翻译失败",
      "authors": [
        "Gang Dang",
        "Dianhui Wang"
      ],
      "abstract": "Recurrent stochastic configuration networks (RSCNs) have shown great\npotential in modelling nonlinear dynamic systems with uncertainties. This paper\npresents an RSCN with hybrid regularization to enhance both the learning\ncapacity and generalization performance of the network. Given a set of temporal\ndata, the well-known least absolute shrinkage and selection operator (LASSO) is\nemployed to identify the significant order variables. Subsequently, an improved\nRSCN with L2 regularization is introduced to approximate the residuals between\nthe output of the target plant and the LASSO model. The output weights are\nupdated in real-time through a projection algorithm, facilitating a rapid\nresponse to dynamic changes within the system. A theoretical analysis of the\nuniversal approximation property is provided, contributing to the understanding\nof the network's effectiveness in representing various complex nonlinear\nfunctions. Experimental results from a nonlinear system identification problem\nand two industrial predictive tasks demonstrate that the proposed method\noutperforms other models across all testing datasets.",
      "tldr_zh": "本研究提出了一种带有混合正则化的Recurrent Stochastic Configuration Networks (RSCNs)，旨在提升非线性动态系统建模的学习能力和泛化性能。通过采用Least Absolute Shrinkage and Selection Operator (LASSO)来识别重要顺序变量，并结合L2正则化改进RSCNs以近似系统残差，输出权重通过投影算法实现实时更新，从而快速响应系统动态变化。理论分析证明了该网络的通用逼近属性，能够有效表示复杂非线性函数。实验结果显示，在一个非线性系统识别问题和两个工业预测任务中，该方法在所有测试数据集上均优于其他模型。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.00070v1",
      "published_date": "2024-11-26 03:06:39 UTC",
      "updated_date": "2024-11-26 03:06:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:49:25.413071"
    },
    {
      "arxiv_id": "2411.17065v1",
      "title": "Creative Agents: Simulating the Systems Model of Creativity with Generative Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Naomi Imasato",
        "Kazuki Miyazawa",
        "Takayuki Nagai",
        "Takato Horii"
      ],
      "abstract": "With the growing popularity of generative AI for images, video, and music, we\nwitnessed models rapidly improve in quality and performance. However, not much\nattention is paid towards enabling AI's ability to \"be creative\". In this\nstudy, we implemented and simulated the systems model of creativity (proposed\nby Csikszentmihalyi) using virtual agents utilizing large language models\n(LLMs) and text prompts. For comparison, the simulations were conducted with\nthe \"virtual artists\" being: 1)isolated and 2)placed in a multi-agent system.\nBoth scenarios were compared by analyzing the variations and overall\n\"creativity\" in the generated artifacts (measured via a user study and LLM).\nOur results suggest that the generative agents may perform better in the\nframework of the systems model of creativity.",
      "tldr_zh": "本研究探讨了如何通过 generative agents 和大型语言模型（LLMs）模拟 Csikszentmihalyi 的 systems model of creativity，以提升 AI 的创造力表现。研究设计了两种场景进行比较：一是孤立的虚拟艺术家，二是置于 multi-agent system 中的虚拟艺术家，并通过用户研究和 LLM 评估生成的工件（artifacts）的变化和整体创造力。结果表明，在 systems model of creativity 框架下，多代理系统能显著提高 generative agents 的创造力输出。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17065v1",
      "published_date": "2024-11-26 03:06:04 UTC",
      "updated_date": "2024-11-26 03:06:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:49:37.420031"
    },
    {
      "arxiv_id": "2411.17062v1",
      "title": "Graph Structure Learning with Bi-level Optimization",
      "title_zh": "使用双层优化的图结构学习",
      "authors": [
        "Nan Yin"
      ],
      "abstract": "Currently, most Graph Structure Learning (GSL) methods, as a means of\nlearning graph structure, improve the robustness of GNN merely from a local\nview by considering the local information related to each edge and\nindiscriminately applying the mechanism across edges, which may suffer from the\nlocal structure heterogeneity of the graph (\\ie the uneven distribution of\ninter-class connections over nodes). To overcome the cons, we extract the graph\nstructure as a learnable parameter and jointly learn the structure and common\nparameters of GNN from the global view. Excitingly, the common parameters\ncontain the global information for nodes features mapping, which is also\ncrucial for structure optimization (\\ie optimizing the structure relies on\nglobal mapping information). Mathematically, we apply a generic structure\nextractor to abstract the graph structure and transform GNNs in the form of\nlearning structure and common parameters. Then, we model the learning process\nas a novel bi-level optimization, \\ie \\textit{Generic Structure Extraction with\nBi-level Optimization for Graph Structure Learning (GSEBO)}, which optimizes\nGNN parameters in the upper level to obtain the global mapping information and\ngraph structure is optimized in the lower level with the global information\nlearned from the upper level. We instantiate the proposed GSEBO on classical\nGNNs and compare it with the state-of-the-art GSL methods. Extensive\nexperiments validate the effectiveness of the proposed GSEBO on four real-world\ndatasets.",
      "tldr_zh": "现有 Graph Structure Learning (GSL) 方法通常从局部视角优化图结构，仅考虑边缘相关信息，而忽略了图的局部结构异质性（如节点间不均匀的类间连接）。为了解决这一问题，本文提出了一种新框架 GSEBO（Generic Structure Extraction with Bi-level Optimization for Graph Structure Learning），将图结构视为可学习参数，并通过双层优化（bi-level optimization）从全局视角联合学习图结构和 Graph Neural Networks (GNNs) 的常见参数，其中上层优化 GNN 参数获取全局映射信息，下层用此信息优化结构。实验结果显示，在四个真实世界数据集上，GSEBO 比现有最先进 GSL 方法表现出显著提升，验证了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17062v1",
      "published_date": "2024-11-26 03:00:30 UTC",
      "updated_date": "2024-11-26 03:00:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:49:49.312016"
    },
    {
      "arxiv_id": "2411.17058v2",
      "title": "ThreatModeling-LLM: Automating Threat Modeling using Large Language Models for Banking System",
      "title_zh": "ThreatModeling-LLM：使用大型语言模型针对银行系统自动化的威胁建",
      "authors": [
        "Tingmin Wu",
        "Shuiqiao Yang",
        "Shigang Liu",
        "David Nguyen",
        "Seung Jang",
        "Alsharif Abuadbba"
      ],
      "abstract": "Threat modeling is a crucial component of cybersecurity, particularly for\nindustries such as banking, where the security of financial data is paramount.\nTraditional threat modeling approaches require expert intervention and manual\neffort, often leading to inefficiencies and human error. The advent of Large\nLanguage Models (LLMs) offers a promising avenue for automating these\nprocesses, enhancing both efficiency and efficacy. However, this transition is\nnot straightforward due to three main challenges: (1) the lack of publicly\navailable, domain-specific datasets, (2) the need for tailored models to handle\ncomplex banking system architectures, and (3) the requirement for real-time,\nadaptive mitigation strategies that align with compliance standards like NIST\n800-53. In this paper, we introduce ThreatModeling-LLM, a novel and adaptable\nframework that automates threat modeling for banking systems using LLMs.\nThreatModeling-LLM operates in three stages: 1) dataset creation, 2) prompt\nengineering and 3) model fine-tuning. We first generate a benchmark dataset\nusing Microsoft Threat Modeling Tool (TMT). Then, we apply Chain of Thought\n(CoT) and Optimization by PROmpting (OPRO) on the pre-trained LLMs to optimize\nthe initial prompt. Lastly, we fine-tune the LLM using Low-Rank Adaptation\n(LoRA) based on the benchmark dataset and the optimized prompt to improve the\nthreat identification and mitigation generation capabilities of pre-trained\nLLMs.",
      "tldr_zh": "本论文提出ThreatModeling-LLM框架，利用Large Language Models (LLMs)自动化银行系统的威胁建模，以解决传统方法依赖专家和手动操作导致的低效问题，同时应对缺乏领域数据集、处理复杂架构和实时适应策略的挑战。框架分为三个阶段：首先，使用Microsoft Threat Modeling Tool (TMT)创建基准数据集；其次，通过Chain of Thought (CoT)和Optimization by PROmpting (OPRO)优化提示；最后，采用Low-Rank Adaptation (LoRA)基于数据集和优化提示微调LLMs，提升威胁识别和缓解生成能力。该框架有望提高威胁建模的效率和合规性（如NIST 800-53标准），为银行系统安全提供更可靠的自动化解决方案。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17058v2",
      "published_date": "2024-11-26 02:57:28 UTC",
      "updated_date": "2025-05-14 11:00:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:50:01.735609"
    },
    {
      "arxiv_id": "2411.17041v1",
      "title": "Free$^2$Guide: Gradient-Free Path Integral Control for Enhancing Text-to-Video Generation with Large Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jaemin Kim",
        "Bryan S Kim",
        "Jong Chul Ye"
      ],
      "abstract": "Diffusion models have achieved impressive results in generative tasks like\ntext-to-image (T2I) and text-to-video (T2V) synthesis. However, achieving\naccurate text alignment in T2V generation remains challenging due to the\ncomplex temporal dependency across frames. Existing reinforcement learning\n(RL)-based approaches to enhance text alignment often require differentiable\nreward functions or are constrained to limited prompts, hindering their\nscalability and applicability. In this paper, we propose Free$^2$Guide, a novel\ngradient-free framework for aligning generated videos with text prompts without\nrequiring additional model training. Leveraging principles from path integral\ncontrol, Free$^2$Guide approximates guidance for diffusion models using\nnon-differentiable reward functions, thereby enabling the integration of\npowerful black-box Large Vision-Language Models (LVLMs) as reward model.\nAdditionally, our framework supports the flexible ensembling of multiple reward\nmodels, including large-scale image-based models, to synergistically enhance\nalignment without incurring substantial computational overhead. We demonstrate\nthat Free$^2$Guide significantly improves text alignment across various\ndimensions and enhances the overall quality of generated videos.",
      "tldr_zh": "该研究提出 Free$^2$Guide，一种无梯度路径积分控制 (Gradient-Free Path Integral Control) 框架，用于提升文本到视频 (T2V) 生成的文本对齐精度，而无需额外模型训练。框架利用非可微奖励函数整合大型视觉语言模型 (LVLMs) 作为奖励模型，解决现有强化学习 (RL) 方法对可微函数和提示的依赖问题。Free$^2$Guide 支持灵活集成多个奖励模型，包括基于图像的模型，以协同增强视频生成质量，同时避免增加计算开销。实验结果显示，该框架显著改善了文本对齐的各个维度，并提升了生成视频的整体性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.17041v1",
      "published_date": "2024-11-26 02:14:47 UTC",
      "updated_date": "2024-11-26 02:14:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:50:14.317765"
    },
    {
      "arxiv_id": "2411.17030v1",
      "title": "g3D-LF: Generalizable 3D-Language Feature Fields for Embodied Tasks",
      "title_zh": "g3D-LF：可泛化的3D-语言特征场用于具身任务",
      "authors": [
        "Zihan Wang",
        "Gim Hee Lee"
      ],
      "abstract": "We introduce Generalizable 3D-Language Feature Fields (g3D-LF), a 3D\nrepresentation model pre-trained on large-scale 3D-language dataset for\nembodied tasks. Our g3D-LF processes posed RGB-D images from agents to encode\nfeature fields for: 1) Novel view representation predictions from any position\nin the 3D scene; 2) Generations of BEV maps centered on the agent; 3) Querying\ntargets using multi-granularity language within the above-mentioned\nrepresentations. Our representation can be generalized to unseen environments,\nenabling real-time construction and dynamic updates. By volume rendering latent\nfeatures along sampled rays and integrating semantic and spatial relationships\nthrough multiscale encoders, our g3D-LF produces representations at different\nscales and perspectives, aligned with multi-granularity language, via\nmulti-level contrastive learning. Furthermore, we prepare a large-scale\n3D-language dataset to align the representations of the feature fields with\nlanguage. Extensive experiments on Vision-and-Language Navigation under both\nPanorama and Monocular settings, Zero-shot Object Navigation, and Situated\nQuestion Answering tasks highlight the significant advantages and effectiveness\nof our g3D-LF for embodied tasks.",
      "tldr_zh": "本研究提出了一种可泛化 3D-Language Feature Fields（g3D-LF），这是一个在大型 3D-language 数据集上预训练的 3D 表示模型，旨在支持具身任务（embodied tasks）。g3D-LF 通过处理代理的 posed RGB-D 图像，生成新视图表示、BEV（Bird's Eye View）地图，并实现多粒度语言查询，同时利用体积渲染潜在特征和多尺度编码器来整合语义与空间关系，并通过多级对比学习（multi-level contrastive learning）实现表示与语言的对齐。实验结果显示，g3D-LF 在 Vision-and-Language Navigation（包括 Panorama 和 Monocular 设置）、Zero-shot Object Navigation 和 Situated Question Answering 等任务中表现出显著优势，具有良好的泛化性和实时更新能力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17030v1",
      "published_date": "2024-11-26 01:54:52 UTC",
      "updated_date": "2024-11-26 01:54:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:50:26.929104"
    },
    {
      "arxiv_id": "2411.17760v1",
      "title": "Efficient Self-Improvement in Multimodal Large Language Models: A Model-Level Judge-Free Approach",
      "title_zh": "多模态大型语言模型中的高效自提升：一种模型级别的无判断者方法",
      "authors": [
        "Shijian Deng",
        "Wentian Zhao",
        "Yu-Jhe Li",
        "Kun Wan",
        "Daniel Miranda",
        "Ajinkya Kale",
        "Yapeng Tian"
      ],
      "abstract": "Self-improvement in multimodal large language models (MLLMs) is crucial for\nenhancing their reliability and robustness. However, current methods often rely\nheavily on MLLMs themselves as judges, leading to high computational costs and\npotential pitfalls like reward hacking and model collapse. This paper\nintroduces a novel, model-level judge-free self-improvement framework. Our\napproach employs a controlled feedback mechanism while eliminating the need for\nMLLMs in the verification loop. We generate preference learning pairs using a\ncontrollable hallucination mechanism and optimize data quality by leveraging\nlightweight, contrastive language-image encoders to evaluate and reverse pairs\nwhen necessary. Evaluations across public benchmarks and our newly introduced\nIC dataset designed to challenge hallucination control demonstrate that our\nmodel outperforms conventional techniques. We achieve superior precision and\nrecall with significantly lower computational demands. This method offers an\nefficient pathway to scalable self-improvement in MLLMs, balancing performance\ngains with reduced resource requirements.",
      "tldr_zh": "这篇论文提出了一种高效的模型级自改进框架，用于多模态大语言模型(MLLMs)，通过消除依赖模型作为判断者的机制，避免了高计算成本、奖励黑客和模型崩溃等问题。该框架采用可控幻觉机制生成偏好学习对，并利用轻量级对比语言-图像编码器评估和优化数据质量。实验结果显示，在公共基准和新的IC数据集上，该方法实现了更高的精确度和召回率，同时显著降低了资源需求。该创新为MLLMs提供了一种可扩展的自改进路径，平衡了性能提升与计算效率。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17760v1",
      "published_date": "2024-11-26 00:44:37 UTC",
      "updated_date": "2024-11-26 00:44:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:50:37.870015"
    },
    {
      "arxiv_id": "2411.17003v1",
      "title": "Can a Single Tree Outperform an Entire Forest?",
      "title_zh": "翻译失败",
      "authors": [
        "Qiangqiang Mao",
        "Yankai Cao"
      ],
      "abstract": "The prevailing mindset is that a single decision tree underperforms classic\nrandom forests in testing accuracy, despite its advantages in interpretability\nand lightweight structure. This study challenges such a mindset by\nsignificantly improving the testing accuracy of an oblique regression tree\nthrough our gradient-based entire tree optimization framework, making its\nperformance comparable to the classic random forest. Our approach reformulates\ntree training as a differentiable unconstrained optimization task, employing a\nscaled sigmoid approximation strategy. To ameliorate numerical instability, we\npropose an algorithmic scheme that solves a sequence of increasingly accurate\napproximations. Additionally, a subtree polish strategy is implemented to\nreduce approximation errors accumulated across the tree. Extensive experiments\non 16 datasets demonstrate that our optimized tree outperforms the classic\nrandom forest by an average of $2.03\\%$ improvements in testing accuracy.",
      "tldr_zh": "本研究挑战了传统观点，即单个决策树在测试准确率上不如经典 random forest，尽管其在可解释性和轻量级结构上更具优势。研究提出一个 gradient-based entire tree optimization framework，通过将树训练重新表述为可微的无约束优化任务，并采用 scaled sigmoid 近似策略来显著提升 oblique regression tree 的性能。为解决数值不稳定性，该框架包括一个解决序列越来越准确近似的算法方案，以及子树 polish 策略来减少积累错误。在 16 个数据集上的广泛实验显示，优化后的树比经典 random forest 平均提高了 2.03% 的测试准确率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17003v1",
      "published_date": "2024-11-26 00:18:18 UTC",
      "updated_date": "2024-11-26 00:18:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:50:49.415836"
    },
    {
      "arxiv_id": "2411.17000v1",
      "title": "SatVision-TOA: A Geospatial Foundation Model for Coarse-Resolution All-Sky Remote Sensing Imagery",
      "title_zh": "SatVision-TOA：一种用于粗分辨率全天域遥感图像的地理空间基础模型",
      "authors": [
        "Caleb S. Spradlin",
        "Jordan A. Caraballo-Vega",
        "Jian Li",
        "Mark L. Carroll",
        "Jie Gong",
        "Paul M. Montesano"
      ],
      "abstract": "Foundation models have the potential to transform the landscape of remote\nsensing (RS) data analysis by enabling large computer vision models to be\npre-trained on vast amounts of remote sensing data. These models can then be\nfine-tuned with small amounts of labeled training and applied to a variety of\napplications. Most existing foundation models are designed for high spatial\nresolution, cloud-free satellite imagery or photos, limiting their\napplicability in scenarios that require frequent temporal monitoring or broad\nspectral profiles. As a result, foundation models trained solely on cloud-free\nimages have limited utility for applications that involve atmospheric variables\nor require atmospheric corrections. We introduce SatVision-TOA, a novel\nfoundation model pre-trained on 14-band MODIS L1B Top-Of-Atmosphere (TOA)\nradiance imagery, addressing the need for models pre-trained to handle\nmoderate- and coarse-resolution all-sky remote sensing data. The SatVision-TOA\nmodel is pre-trained using a Masked-Image-Modeling (MIM) framework and the\nSwinV2 architecture, and learns detailed contextual representations through\nself-supervised learning without the need for labels. It is a 3 billion\nparameter model that is trained on 100 million images. To our knowledge this is\nthe largest foundation model trained solely on satellite RS imagery. Results\nshow that SatVision-TOA achieves superior performance over baseline methods on\ndownstream tasks such as 3D cloud retrieval. Notably, the model achieves a mean\nintersection over union (mIOU) of 0.46, a substantial improvement over the\nbaseline mIOU of 0.22. Additionally, the rate of false negative results in the\nfine-tuning task were reduced by over 50% compared to the baseline. Our work\nadvances pre-trained vision modeling for multispectral RS by learning from a\nvariety of atmospheric and aerosol conditions to improve cloud and land surface\nmonitoring.",
      "tldr_zh": "本文介绍了SatVision-TOA，一种针对粗分辨率全天遥感图像的地空基础模型，旨在解决现有模型在高分辨率无云图像上的局限性，通过预训练于14波段MODIS L1B Top-Of-Atmosphere (TOA)辐射图像来处理大气变量和光谱需求。模型采用Masked-Image-Modeling (MIM)框架和SwinV2架构进行自监督学习，训练了3亿参数规模的模型，基于1亿张图像，这是目前最大的仅用卫星遥感图像训练的基础模型。实验结果显示，SatVision-TOA在下游任务如3D云检索中显著优于基线，mIOU从0.22提高到0.46，并将假阴性率减少50%以上。该模型通过学习各种大气和气溶胶条件，提升了云和地表监测的准确性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "19 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.17000v1",
      "published_date": "2024-11-26 00:08:00 UTC",
      "updated_date": "2024-11-26 00:08:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:51:02.912271"
    },
    {
      "arxiv_id": "2412.06808v2",
      "title": "Effect of Adaptive Communication Support on LLM-powered Human-Robot Collaboration",
      "title_zh": "自适应通信支持对LLM驱动的人机协作的影响",
      "authors": [
        "Shipeng Liu",
        "FNU Shrutika",
        "Boshen Zhang",
        "Zhehui Huang",
        "Gaurav Sukhatme",
        "Feifei Qian"
      ],
      "abstract": "Effective human-robot collaboration requires robot to adopt their roles and\nlevels of support based on human needs, task requirements, and complexity.\nTraditional human-robot teaming often relies on a pre-determined robot\ncommunication scheme, restricting teamwork adaptability in complex tasks.\nLeveraging strong communication capabilities of Large Language Models (LLMs),\nwe propose a Human-Robot Teaming Framework with Multi-Modal Language feedback\n(HRT-ML), a framework designed to enhance human-robot interaction by adjusting\nthe frequency and content of language-based feedback. HRT-ML framework includes\ntwo core modules: a Coordinator for high-level, low-frequency strategic\nguidance, and a Manager for subtask-specific, high-frequency instructions,\nenabling passive and active interactions with human teammates. To assess the\nimpact of language feedback in collaborative scenarios, we conducted\nexperiments in an enhanced Overcooked environment with varying levels of task\ncomplexity (easy, medium, hard) and feedback frequency (inactive, passive,\nactive, superactive). Our results show that as task complexity increases\nrelative to human capabilities, human teammates exhibited a stronger preference\ntowards robotic agents that can offer frequent, proactive support. However,\nwhen task complexities exceed the LLM's capacity, noisy and inaccurate feedback\nfrom superactive robotic agents can instead hinder team performance, as it\nrequires human teammates to increase their effort to interpret and respond to a\nlarge number of communications, with limited performance return. Our results\noffer a general principle for robotic agents to dynamically adjust their levels\nand frequencies of communications to work seamlessly with humans and achieve\nimproved teaming performance.",
      "tldr_zh": "这篇论文探讨了在LLM驱动的人类-机器人协作中，适应性通信支持的影响，强调机器人需根据人类需求、任务要求和复杂度动态调整其角色。论文提出HRT-ML框架，利用LLM的多模态语言反馈，包括Coordinator模块提供高层低频战略指导，以及Manager模块提供子任务高频指令，支持被动和主动互动。实验在增强的Overcooked环境中测试不同任务复杂度（easy、medium、hard）和反馈频率（inactive、passive、active、superactive），结果显示任务复杂度增加时人类更偏好频繁主动支持，但当任务超出LLM能力时，过多的反馈会干扰性能，导致人类需额外努力解读。总体而言，论文为机器人动态调整通信水平提供了通用原则，以优化团队协作效果。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.RO",
        "68T05",
        "I.2.9"
      ],
      "primary_category": "cs.HC",
      "comment": "13 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.06808v2",
      "published_date": "2024-11-26 00:06:47 UTC",
      "updated_date": "2025-02-11 18:52:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:51:16.049944"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 107,
  "processed_papers_count": 107,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-21T04:51:33.242191"
}