{
  "date": "2024-03-17",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-03-17 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 54 篇论文，主要聚焦 AI 和机器学习领域的创新应用，如 LLM 在自动驾驶和医疗中的扩展、视觉生成模型的鲁棒性提升，以及 AGI 理论探讨；令人印象深刻的文章包括 Anton Korinek 等人关于 AGI 场景的分析（第 4 篇）和 ICLR 2024 接受的 COLEP 框架（第 6 篇），这些工作突出了 AI 在复杂任务中的潜力。\n\n### 重点论文讨论\n我将优先选取重要、话题度高或有潜在影响的论文进行简要概述，将相关主题归类讨论，并快速掠过较基础或小众内容。以下按主题分组，列出论文标题（中文 + 英文）和核心贡献。\n\n#### AI 和 LLM 应用（高话题度领域）\n- **Driving Style Alignment for LLM-powered Driver Agent**（驾驶风格对齐用于 LLM 驱动的驾驶代理）：这篇论文提出一个多对齐框架，使用自然语言数据集训练 LLM，使驾驶代理更好地模仿人类驾驶风格，在 CARLA 模拟器中验证了其有效性，提升了自动驾驶的人性化决策。\n- **Scenarios for the Transition to AGI**（过渡到 AGI 的场景）：Anton Korinek 等人分析了技术进步可能导致的 AGI 场景，讨论了任务复杂性分布对工资和经济的影响，指出如果任务复杂度有限，自动化可能导致工资崩溃；这是一篇有影响力的理论探讨，强调了 AI 经济含义。\n- **COLEP: Certifiably Robust Learning-Reasoning Conformal Prediction via Probabilistic Circuits**（通过概率电路的鲁棒学习-推理保形预测）：ICLR 2024 接受论文，引入 COLEP 框架，使用概率电路处理预测的不确定性，提供端到端鲁棒性证明，在 GTSRB 和 CIFAR-10 数据集上提升了 9-14% 的预测覆盖率，适用于对抗性场景。\n- **StateFlow: Enhancing LLM Task-Solving through State-Driven Workflows**（通过状态驱动工作流增强 LLM 任务解决）：该工作将任务建模为状态机，使用 LLM 优化状态转移，在 InterCode 和 ALFWorld 基准上提高了 13-28% 的成功率，展示了 LLM 在复杂交互任务中的潜力。\n- **SQ-LLaVA: Self-Questioning for Large Vision-Language Assistant**（用于大型视觉语言助手的自提问）：ECCV 2024 论文，提出自监督自提问框架，提升视觉语言模型的泛化理解，通过高质量问题生成改善图像分析，显著优于传统方法。\n- **Logic Query of Thoughts: Guiding Large Language Models to Answer Complex Logic Queries with Knowledge Graphs**（逻辑查询思维：使用知识图指导 LLM 回答复杂逻辑查询）：该方法结合知识图和 LLM，分解复杂查询并聚合答案，在逻辑推理任务上提升 20% 性能，缓解了 LLM 的幻觉问题。\n- **MindEye2: Shared-Subject Models Enable fMRI-To-Image With 1 Hour of Data**（MindEye2：共享主体模型实现 1 小时 fMRI 到图像转换）：Kenneth A. Norman 参与，使用共享模型在 1 小时数据内实现高精度 fMRI 图像重建，State-of-the-art 在图像检索和重建上，展示了脑科学与 AI 的交叉应用。\n- **Correcting misinformation on social media with a large language model**（使用大型语言模型纠正社交媒体错误信息）：该论文提出 MUSE 框架，通过多模态检索纠正错误信息，在各种场景下减少 37% 的错误率，强调了 LLM 在 misinformation 治理中的实际价值。\n- **PhD: A ChatGPT-Prompted Visual hallucination Evaluation Dataset**（PhD：ChatGPT 提示的视觉幻觉评估数据集）：快速掠过，这是一个新数据集，用于评估视觉语言模型的幻觉问题，通过多模式评估提升了模型鲁棒性。\n\n其他 LLM 相关论文（如第 7、10、12、14、32、33、34、36、37、39、40、41、43、46、47、48、49、50、52、53）探讨了翻译、生成和优化，但多数为常规细调方法，贡献较小，故仅简要提及它们在数据增强和鲁棒性上的渐进改进。\n\n#### 计算机视觉和图像处理\n- **TransPeakNet: Solvent-Aware 2D NMR Prediction via Multi-Task Pre-Training and Unsupervised Learning**（TransPeakNet：通过多任务预训练和无监督学习的溶剂感知 2D NMR 预测）：该工作使用无监督框架预测 NMR 谱峰，MAE 达到 2.05 ppm 和 0.165 ppm，显著优于传统方法，在有机化学领域有实际应用。\n- **CPA-Enhancer: Chain-of-Thought Prompted Adaptive Enhancer for Object Detection under Unknown Degradations**（CPA-Enhancer：链式思维提示的自适应增强器，用于未知退化的目标检测）：首次将链式思维用于目标检测，提出自适应增强模型，在未知退化场景下提升检测性能，是 CVPR 2024 的亮点。\n- **Audio-Visual Segmentation via Unlabeled Frame Exploitation**（音频-视觉分割通过无标签帧利用）：该论文利用无标签帧的运动和语义线索提升分割精度，通过自训练策略在视频分析中取得进展。\n\n其他视觉论文（如第 9、11、25、28、38、44）聚焦关键点预测和鲁棒生成，但影响较局限，仅在特定任务中略有提升。\n\n#### 医疗和生物应用\n- **A Survey of IMU Based Cross-Modal Transfer Learning in Human Activity Recognition**（IMU 基于的跨模态迁移学习在人类活动识别中的调查）：这篇综述探讨了 IMU 数据在跨模态学习中的作用，分类了数据集和方法，强调了传感器融合在健康监测中的潜力。\n- **Machine Learning and Transformers for Thyroid Carcinoma Diagnosis: A Review**（机器学习和 Transformer 用于甲状腺癌诊断的综述）：快速掠过，该综述总结了 AI 在癌症诊断中的应用，突出了 Transformer 的作用，但缺乏新实验。\n\n其他医疗论文（如第 17、23、27、29、30、35、51）多为综述或初步方法，贡献一般，不做深入讨论。\n\n#### 自动驾驶和机器人\n- **Pioneering SE(2)-Equivariant Trajectory Planning for Automated Driving**（开创性的 SE(2)-等变轨迹规划用于自动驾驶）：提出等变网络模型，结合 GPS 导航提升轨迹规划的鲁棒性，在 nuScenes 数据集上减少 20.6% 的距离误差。\n- **Independent RL for Cooperative-Competitive Agents: A Mean-Field Perspective**（独立强化学习用于合作-竞争代理：均值场视角）：Tamer Başar 参与，开发了 MRNPG 算法，在多代理环境中实现 Nash 均衡，适用于机器人协作。\n\n其他自动驾驶论文（如第 1、3、8、15）延续了 RL 和规划主题，但未有突破性进展。\n\n#### 其他领域（快速掠过）\n剩余论文（如第 2、5、13、16、19、20、21、22、24、26、31、42、45）涉及特征选择、生成模型和优化，但多为理论或小众应用，例如第 20 篇使用 Feynman 路径积分解释扩散模型，仅提及其在采样方案上的新视角。它们未对主流领域产生重大影响，故不展开。\n\n总之，今天的 arXiv 更新突显了 AI 模型在实际应用中的鲁棒性和泛化潜力，建议关注 AGI 和 LLM 相关工作以把握前沿趋势。更多细节可查阅 arXiv 页面！",
  "papers": [
    {
      "arxiv_id": "2403.11368v1",
      "title": "Driving Style Alignment for LLM-powered Driver Agent",
      "title_zh": "翻译失败",
      "authors": [
        "Ruoxuan Yang",
        "Xinyue Zhang",
        "Anais Fernandez-Laaksonen",
        "Xin Ding",
        "Jiangtao Gong"
      ],
      "abstract": "Recently, LLM-powered driver agents have demonstrated considerable potential\nin the field of autonomous driving, showcasing human-like reasoning and\ndecision-making abilities.However, current research on aligning driver agent\nbehaviors with human driving styles remains limited, partly due to the scarcity\nof high-quality natural language data from human driving behaviors.To address\nthis research gap, we propose a multi-alignment framework designed to align\ndriver agents with human driving styles through demonstrations and feedback.\nNotably, we construct a natural language dataset of human driver behaviors\nthrough naturalistic driving experiments and post-driving interviews, offering\nhigh-quality human demonstrations for LLM alignment. The framework's\neffectiveness is validated through simulation experiments in the CARLA urban\ntraffic simulator and further corroborated by human evaluations. Our research\noffers valuable insights into designing driving agents with diverse driving\nstyles.The implementation of the framework and details of the dataset can be\nfound at the link.",
      "tldr_zh": "本研究针对LLM驱动的驾驶代理在自动驾驶领域虽具备人类般的推理决策能力，但与人类驾驶风格对齐不足的问题，提出了一种多对齐框架，通过人类演示和反馈来实现行为调整。研究团队构建了一个基于自然驾驶实验和后续访谈的自然语言数据集，提供高质量的人类行为演示，用于LLM对齐。实验在CARLA城市交通模拟器中验证了框架的有效性，并通过人类评估进一步确认，为设计具有多样驾驶风格的驾驶代理提供了宝贵见解。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "68T42"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.11368v1",
      "published_date": "2024-03-17 23:07:13 UTC",
      "updated_date": "2024-03-17 23:07:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:16:52.807679"
    },
    {
      "arxiv_id": "2403.11363v1",
      "title": "IGANN Sparse: Bridging Sparsity and Interpretability with Non-linear Insight",
      "title_zh": "IGANN Sparse：通过非线性洞察桥接稀疏性和可解释性",
      "authors": [
        "Theodor Stoecker",
        "Nico Hambauer",
        "Patrick Zschech",
        "Mathias Kraus"
      ],
      "abstract": "Feature selection is a critical component in predictive analytics that\nsignificantly affects the prediction accuracy and interpretability of models.\nIntrinsic methods for feature selection are built directly into model learning,\nproviding a fast and attractive option for large amounts of data. Machine\nlearning algorithms, such as penalized regression models (e.g., lasso) are the\nmost common choice when it comes to in-built feature selection. However, they\nfail to capture non-linear relationships, which ultimately affects their\nability to predict outcomes in intricate datasets. In this paper, we propose\nIGANN Sparse, a novel machine learning model from the family of generalized\nadditive models, which promotes sparsity through a non-linear feature selection\nprocess during training. This ensures interpretability through improved model\nsparsity without sacrificing predictive performance. Moreover, IGANN Sparse\nserves as an exploratory tool for information systems researchers to unveil\nimportant non-linear relationships in domains that are characterized by complex\npatterns. Our ongoing research is directed at a thorough evaluation of the\nIGANN Sparse model, including user studies that allow to assess how well users\nof the model can benefit from the reduced number of features. This will allow\nfor a deeper understanding of the interactions between linear vs. non-linear\nmodeling, number of selected features, and predictive performance.",
      "tldr_zh": "本文提出 IGANN Sparse，一种基于广义可加模型（generalized additive models）的新型机器学习模型，通过非线性特征选择过程在训练中促进 sparsity（稀疏性），从而提升模型的可解释性（interpretability）而不牺牲预测性能。相比传统方法如 lasso，该模型能够更好地捕捉复杂数据集中的非线性关系，并作为探索工具揭示信息系统领域的关键模式。未来研究将通过用户研究评估特征减少对用户益处的实际影响，以及线性 vs. 非线性建模之间的互动。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint conditionally accepted for archival and presentation at the\n  32nd European Conference on Information Systems (ECIS 2024)",
      "pdf_url": "http://arxiv.org/pdf/2403.11363v1",
      "published_date": "2024-03-17 22:44:36 UTC",
      "updated_date": "2024-03-17 22:44:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:17:04.471167"
    },
    {
      "arxiv_id": "2403.15444v1",
      "title": "A Survey of IMU Based Cross-Modal Transfer Learning in Human Activity Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Abhi Kamboj",
        "Minh Do"
      ],
      "abstract": "Despite living in a multi-sensory world, most AI models are limited to\ntextual and visual understanding of human motion and behavior. In fact, full\nsituational awareness of human motion could best be understood through a\ncombination of sensors. In this survey we investigate how knowledge can be\ntransferred and utilized amongst modalities for Human Activity/Action\nRecognition (HAR), i.e. cross-modality transfer learning. We motivate the\nimportance and potential of IMU data and its applicability in cross-modality\nlearning as well as the importance of studying the HAR problem. We categorize\nHAR related tasks by time and abstractness and then compare various types of\nmultimodal HAR datasets. We also distinguish and expound on many related but\ninconsistently used terms in the literature, such as transfer learning, domain\nadaptation, representation learning, sensor fusion, and multimodal learning,\nand describe how cross-modal learning fits with all these concepts. We then\nreview the literature in IMU-based cross-modal transfer for HAR. The two main\napproaches for cross-modal transfer are instance-based transfer, where\ninstances of one modality are mapped to another (e.g. knowledge is transferred\nin the input space), or feature-based transfer, where the model relates the\nmodalities in an intermediate latent space (e.g. knowledge is transferred in\nthe feature space). Finally, we discuss future research directions and\napplications in cross-modal HAR.",
      "tldr_zh": "这篇调查论文探讨了在人类活动识别(Human Activity Recognition, HAR)中，使用IMU（惯性测量单元）数据进行跨模态转移学习的重要性及潜力。论文分类了HAR任务（按时间和抽象性），比较了各种多模态数据集，并澄清了相关术语如转移学习、域适应、表示学习、传感器融合和多模态学习。作者回顾了IMU-based跨模态转移文献，主要分为基于实例的转移（在输入空间映射模态）和基于特征的转移（在潜在空间关联模态），并讨论了未来研究方向和在多传感器应用中的前景。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.15444v1",
      "published_date": "2024-03-17 22:31:14 UTC",
      "updated_date": "2024-03-17 22:31:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:17:14.659946"
    },
    {
      "arxiv_id": "2403.12107v1",
      "title": "Scenarios for the Transition to AGI",
      "title_zh": "翻译失败",
      "authors": [
        "Anton Korinek",
        "Donghyun Suh"
      ],
      "abstract": "We analyze how output and wages behave under different scenarios for\ntechnological progress that may culminate in Artificial General Intelligence\n(AGI), defined as the ability of AI systems to perform all tasks that humans\ncan perform. We assume that human work can be decomposed into atomistic tasks\nthat differ in their complexity. Advances in technology make ever more complex\ntasks amenable to automation. The effects on wages depend on a race between\nautomation and capital accumulation. If the distribution of task complexity\nexhibits a sufficiently thick infinite tail, then there is always enough work\nfor humans, and wages may rise forever. By contrast, if the complexity of tasks\nthat humans can perform is bounded and full automation is reached, then wages\ncollapse. But declines may occur even before if large-scale automation outpaces\ncapital accumulation and makes labor too abundant. Automating productivity\ngrowth may lead to broad-based gains in the returns to all factors. By\ncontrast, bottlenecks to growth from irreproducible scarce factors may\nexacerbate the decline in wages.",
      "tldr_zh": "这篇论文分析了通往人工智能通用智能 (AGI) 的技术进步不同场景下，产出和工资的变化，假设人类工作可分解为不同复杂度的原子任务，而技术进步使更多复杂任务实现自动化。工资变化取决于自动化与资本积累的竞争：如果任务复杂度的分布具有足够厚的无限尾巴，人类工作将永不枯竭，工资可能持续上升；反之，如果人类任务复杂度有限且达到全自动化，工资将崩溃。论文还指出，即使在全自动化前，如果大规模自动化超过资本积累，劳动过剩可能导致工资下降，而自动化驱动的生产力增长可能带来所有因素的广泛回报，但不可复制的稀缺因素瓶颈会加剧工资下滑。",
      "categories": [
        "econ.GN",
        "cs.AI",
        "q-fin.EC"
      ],
      "primary_category": "econ.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.12107v1",
      "published_date": "2024-03-17 22:22:28 UTC",
      "updated_date": "2024-03-17 22:22:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:17:27.958782"
    },
    {
      "arxiv_id": "2403.11353v4",
      "title": "TransPeakNet: Solvent-Aware 2D NMR Prediction via Multi-Task Pre-Training and Unsupervised Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yunrui Li",
        "Hao Xu",
        "Ambrish Kumar",
        "Duosheng Wang",
        "Christian Heiss",
        "Parastoo Azadi",
        "Pengyu Hong"
      ],
      "abstract": "Nuclear Magnetic Resonance (NMR) spectroscopy is essential for revealing\nmolecular structure, electronic environment, and dynamics. Accurate NMR shift\nprediction allows researchers to validate structures by comparing predicted and\nobserved shifts. While Machine Learning (ML) has improved one-dimensional (1D)\nNMR shift prediction, predicting 2D NMR remains challenging due to limited\nannotated data. To address this, we introduce an unsupervised training\nframework for predicting cross-peaks in 2D NMR, specifically Heteronuclear\nSingle Quantum Coherence (HSQC).Our approach pretrains an ML model on an\nannotated 1D dataset of 1H and 13C shifts, then finetunes it in an unsupervised\nmanner using unlabeled HSQC data, which simultaneously generates cross-peak\nannotations. Our model also adjusts for solvent effects. Evaluation on 479\nexpert-annotated HSQC spectra demonstrates our model's superiority over\ntraditional methods (ChemDraw and Mestrenova), achieving Mean Absolute Errors\n(MAEs) of 2.05 ppm and 0.165 ppm for 13C shifts and 1H shifts respectively. Our\nalgorithmic annotations show a 95.21% concordance with experts' assignments,\nunderscoring the approach's potential for structural elucidation in fields like\norganic chemistry, pharmaceuticals, and natural products.",
      "tldr_zh": "该研究提出TransPeakNet，一种考虑溶剂效应的2D NMR预测框架，通过多任务预训练和无监督学习来解决标注数据有限的问题。具体而言，该框架先在标注的1D NMR数据集（包括1H和13C位移）上预训练模型，然后使用无标签HSQC数据进行无监督微调，同时生成交叉峰标注。实验结果显示，在479个专家标注的HSQC谱上，TransPeakNet的13C位移MAE为2.05 ppm、1H位移MAE为0.165 ppm，显著优于传统方法如ChemDraw和Mestrenova，且算法标注与专家一致性达95.21%。这项工作为有机化学、制药和天然产物等领域中的分子结构阐明提供了高效工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.chem-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.11353v4",
      "published_date": "2024-03-17 21:52:51 UTC",
      "updated_date": "2024-12-16 00:31:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:17:40.074979"
    },
    {
      "arxiv_id": "2403.11348v1",
      "title": "COLEP: Certifiably Robust Learning-Reasoning Conformal Prediction via Probabilistic Circuits",
      "title_zh": "翻译失败",
      "authors": [
        "Mintong Kang",
        "Nezihe Merve Gürel",
        "Linyi Li",
        "Bo Li"
      ],
      "abstract": "Conformal prediction has shown spurring performance in constructing\nstatistically rigorous prediction sets for arbitrary black-box machine learning\nmodels, assuming the data is exchangeable. However, even small adversarial\nperturbations during the inference can violate the exchangeability assumption,\nchallenge the coverage guarantees, and result in a subsequent decline in\nempirical coverage. In this work, we propose a certifiably robust\nlearning-reasoning conformal prediction framework (COLEP) via probabilistic\ncircuits, which comprise a data-driven learning component that trains\nstatistical models to learn different semantic concepts, and a reasoning\ncomponent that encodes knowledge and characterizes the relationships among the\ntrained models for logic reasoning. To achieve exact and efficient reasoning,\nwe employ probabilistic circuits (PCs) within the reasoning component.\nTheoretically, we provide end-to-end certification of prediction coverage for\nCOLEP in the presence of bounded adversarial perturbations. We also provide\ncertified coverage considering the finite size of the calibration set.\nFurthermore, we prove that COLEP achieves higher prediction coverage and\naccuracy over a single model as long as the utilities of knowledge models are\nnon-trivial. Empirically, we show the validity and tightness of our certified\ncoverage, demonstrating the robust conformal prediction of COLEP on various\ndatasets, including GTSRB, CIFAR10, and AwA2. We show that COLEP achieves up to\n12% improvement in certified coverage on GTSRB, 9% on CIFAR-10, and 14% on\nAwA2.",
      "tldr_zh": "本文提出 COLEP 框架，利用 probabilistic circuits 实现 certifiably robust 的学习-推理 conformal prediction，以应对对抗性扰动导致的数据交换性问题。该框架结合数据驱动的学习组件（训练统计模型学习语义概念）和推理组件（编码知识并表征模型间关系），确保精确高效的逻辑推理。理论上，COLEP 提供端到端的预测覆盖认证，并证明其在非微不足道知识模型下比单一模型有更高的覆盖和准确性；实验结果显示，在 GTSRB 上提升 12%、CIFAR-10 上提升 9%、AwA2 上提升 14% 的 certified coverage。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.11348v1",
      "published_date": "2024-03-17 21:23:45 UTC",
      "updated_date": "2024-03-17 21:23:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:17:52.118995"
    },
    {
      "arxiv_id": "2403.11346v3",
      "title": "CantonMT: Cantonese to English NMT Platform with Fine-Tuned Models Using Synthetic Back-Translation Data",
      "title_zh": "翻译失败",
      "authors": [
        "Kung Yin Hong",
        "Lifeng Han",
        "Riza Batista-Navarro",
        "Goran Nenadic"
      ],
      "abstract": "Neural Machine Translation (NMT) for low-resource languages is still a\nchallenging task in front of NLP researchers. In this work, we deploy a\nstandard data augmentation methodology by back-translation to a new language\ntranslation direction Cantonese-to-English. We present the models we fine-tuned\nusing the limited amount of real data and the synthetic data we generated using\nback-translation including OpusMT, NLLB, and mBART. We carried out automatic\nevaluation using a range of different metrics including lexical-based and\nembedding-based. Furthermore. we create a user-friendly interface for the\nmodels we included in this\\textsc{ CantonMT} research project and make it\navailable to facilitate Cantonese-to-English MT research. Researchers can add\nmore models into this platform via our open-source\\textsc{ CantonMT} toolkit\n\\url{https://github.com/kenrickkung/CantoneseTranslation}.",
      "tldr_zh": "这篇论文介绍了CantonMT平台，该平台针对低资源语言的Neural Machine Translation (NMT)，专注于粤语到英语的翻译任务，通过back-translation生成合成数据对OpusMT、NLLB和mBART模型进行微调。研究者使用多种指标（如基于词汇和嵌入的自动评估）来评估模型性能，并创建了一个用户友好的界面。最终，他们开源了CantonMT工具包（https://github.com/kenrickkung/CantoneseTranslation），以便研究者添加更多模型并推进相关研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by: The 25th Annual Conference of The European Association\n  for Machine Translation, 24 - 27 June 2024, Sheffield, UK (forthcoming)",
      "pdf_url": "http://arxiv.org/pdf/2403.11346v3",
      "published_date": "2024-03-17 21:16:17 UTC",
      "updated_date": "2024-06-09 22:10:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:18:02.416165"
    },
    {
      "arxiv_id": "2403.11345v2",
      "title": "Independent RL for Cooperative-Competitive Agents: A Mean-Field Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Muhammad Aneeq uz Zaman",
        "Alec Koppel",
        "Mathieu Laurière",
        "Tamer Başar"
      ],
      "abstract": "We address in this paper Reinforcement Learning (RL) among agents that are\ngrouped into teams such that there is cooperation within each team but\ngeneral-sum (non-zero sum) competition across different teams. To develop an RL\nmethod that provably achieves a Nash equilibrium, we focus on a\nlinear-quadratic structure. Moreover, to tackle the non-stationarity induced by\nmulti-agent interactions in the finite population setting, we consider the case\nwhere the number of agents within each team is infinite, i.e., the mean-field\nsetting. This results in a General-Sum LQ Mean-Field Type Game (GS-MFTG). We\ncharacterize the Nash equilibrium (NE) of the GS-MFTG, under a standard\ninvertibility condition. This MFTG NE is then shown to be $O(1/M)$-NE for the\nfinite population game where $M$ is a lower bound on the number of agents in\neach team. These structural results motivate an algorithm called Multi-player\nReceding-horizon Natural Policy Gradient (MRNPG), where each team minimizes its\ncumulative cost \\emph{independently} in a receding-horizon manner. Despite the\nnon-convexity of the problem, we establish that the resulting algorithm\nconverges to a global NE through a novel problem decomposition into\nsub-problems using backward recursive discrete-time Hamilton-Jacobi-Isaacs\n(HJI) equations, in which \\emph{independent natural policy gradient} is shown\nto exhibit linear convergence under time-independent diagonal dominance.\nNumerical studies included corroborate the theoretical results.",
      "tldr_zh": "这篇论文探讨了强化学习（RL）在团队内部合作、团队间竞争的场景中，采用均值场（mean-field）视角来处理多智能体互动的非平稳性。作者引入了 General-Sum LQ Mean-Field Type Game (GS-MFTG) 框架，并证明其 Nash Equilibrium (NE) 在满足一定条件时成立，且在有限人口游戏中近似为 O(1/M)-NE。论文提出 Multi-player Receding-horizon Natural Policy Gradient (MRNPG) 算法，每个团队独立最小化累积成本，通过 backward recursive discrete-time Hamilton-Jacobi-Isaacs (HJI) 方程分解问题，实现算法在非凸优化中的线性收敛；数值实验进一步验证了这些理论结果。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.GT",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.11345v2",
      "published_date": "2024-03-17 21:11:55 UTC",
      "updated_date": "2025-02-08 17:59:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:18:16.767423"
    },
    {
      "arxiv_id": "2403.11337v1",
      "title": "Enhancing Bandwidth Efficiency for Video Motion Transfer Applications using Deep Learning Based Keypoint Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Xue Bai",
        "Tasmiah Haque",
        "Sumit Mohan",
        "Yuliang Cai",
        "Byungheon Jeong",
        "Adam Halasz",
        "Srinjoy Das"
      ],
      "abstract": "We propose a deep learning based novel prediction framework for enhanced\nbandwidth reduction in motion transfer enabled video applications such as video\nconferencing, virtual reality gaming and privacy preservation for patient\nhealth monitoring. To model complex motion, we use the First Order Motion Model\n(FOMM) that represents dynamic objects using learned keypoints along with their\nlocal affine transformations. Keypoints are extracted by a self-supervised\nkeypoint detector and organized in a time series corresponding to the video\nframes. Prediction of keypoints, to enable transmission using lower frames per\nsecond on the source device, is performed using a Variational Recurrent Neural\nNetwork (VRNN). The predicted keypoints are then synthesized to video frames\nusing an optical flow estimator and a generator network. This efficacy of\nleveraging keypoint based representations in conjunction with VRNN based\nprediction for both video animation and reconstruction is demonstrated on three\ndiverse datasets. For real-time applications, our results show the\neffectiveness of our proposed architecture by enabling up to 2x additional\nbandwidth reduction over existing keypoint based video motion transfer\nframeworks without significantly compromising video quality.",
      "tldr_zh": "本研究提出了一种基于深度学习的密钥点预测框架，用于提升视频运动传输应用的带宽效率，适用于视频会议、虚拟现实游戏和患者健康监控隐私保护。框架采用 First Order Motion Model (FOMM) 通过自监督密钥点检测器提取动态对象的密钥点及其局部仿射变换，并使用 Variational Recurrent Neural Network (VRNN) 预测这些密钥点，从而实现源设备以更低帧率传输。预测后的密钥点通过光学流估计器和生成网络合成回视频帧。在三个不同数据集上的实验显示，该方法相较现有密钥点基于框架，可实现高达 2 倍的额外带宽减少，同时视频质量基本不受显著影响。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.11337v1",
      "published_date": "2024-03-17 20:36:43 UTC",
      "updated_date": "2024-03-17 20:36:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:18:26.754018"
    },
    {
      "arxiv_id": "2403.11330v2",
      "title": "Improving Dialogue Agents by Decomposing One Global Explicit Annotation with Local Implicit Multimodal Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Dong Won Lee",
        "Hae Won Park",
        "Yoon Kim",
        "Cynthia Breazeal",
        "Louis-Philippe Morency"
      ],
      "abstract": "We describe an approach for aligning an LLM-based dialogue agent based on\nglobal (i.e., dialogue-level) rewards, while also taking into account\nnaturally-occurring multimodal signals. At a high level, our approach (dubbed\nGELI) learns a local, turn-level reward model by decomposing the human-provided\nGlobal Explicit (GE) session-level reward, using Local Implicit (LI) multimodal\nreward signals to crossmodally shape the reward decomposition step. This\ndecomposed reward model is then used as part of the standard RHLF pipeline\nimprove an LLM-based dialog agent. We run quantitative and qualitative human\nstudies to evaluate the performance of our GELI approach, and find that it\nshows consistent improvements across various conversational metrics compared to\nbaseline methods.",
      "tldr_zh": "本研究提出了一种名为 GELI 的方法，用于改进 LLM 基于的对话代理，通过将全局显式（Global Explicit, GE）会话级奖励分解成局部隐式（Local Implicit, LI）多模态反馈信号，从而实现跨模态奖励塑造。GELI 将这个分解后的奖励模型整合到 RHLF（Reinforcement Learning from Human Feedback）管道中，以优化代理的性能。实验结果显示，GELI 在定量和定性人类评估中，在各种对话指标上比基线方法表现出一致的改善，为对话代理的训练提供了更高效的对齐策略。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 3 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2403.11330v2",
      "published_date": "2024-03-17 20:21:26 UTC",
      "updated_date": "2024-04-23 03:17:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:18:40.255889"
    },
    {
      "arxiv_id": "2403.11328v1",
      "title": "Domain-Guided Masked Autoencoders for Unique Player Identification",
      "title_zh": "翻译失败",
      "authors": [
        "Bavesh Balaji",
        "Jerrin Bright",
        "Sirisha Rambhatla",
        "Yuhao Chen",
        "Alexander Wong",
        "John Zelek",
        "David A Clausi"
      ],
      "abstract": "Unique player identification is a fundamental module in vision-driven sports\nanalytics. Identifying players from broadcast videos can aid with various\ndownstream tasks such as player assessment, in-game analysis, and broadcast\nproduction. However, automatic detection of jersey numbers using deep features\nis challenging primarily due to: a) motion blur, b) low resolution video feed,\nand c) occlusions. With their recent success in various vision tasks, masked\nautoencoders (MAEs) have emerged as a superior alternative to conventional\nfeature extractors. However, most MAEs simply zero-out image patches either\nrandomly or focus on where to mask rather than how to mask. Motivated by human\nvision, we devise a novel domain-guided masking policy for MAEs termed d-MAE to\nfacilitate robust feature extraction in the presence of motion blur for player\nidentification. We further introduce a new spatio-temporal network leveraging\nour novel d-MAE for unique player identification. We conduct experiments on\nthree large-scale sports datasets, including a curated baseball dataset, the\nSoccerNet dataset, and an in-house ice hockey dataset. We preprocess the\ndatasets using an upgraded keyframe identification (KfID) module by focusing on\nframes containing jersey numbers. Additionally, we propose a keyframe-fusion\ntechnique to augment keyframes, preserving spatial and temporal context. Our\nspatio-temporal network showcases significant improvements, surpassing the\ncurrent state-of-the-art by 8.58%, 4.29%, and 1.20% in the test set accuracies,\nrespectively. Rigorous ablations highlight the effectiveness of our\ndomain-guided masking approach and the refined KfID module, resulting in\nperformance enhancements of 1.48% and 1.84% respectively, compared to original\narchitectures.",
      "tldr_zh": "这篇论文针对体育视频中球员识别的挑战（如运动模糊、低分辨率和遮挡），提出了一种新型 domain-guided masking policy 的 Masked Autoencoders（d-MAE），模仿人类视觉来增强特征提取的鲁棒性。作者开发了一个新的时空网络，结合升级的关键帧识别（KfID）模块和关键帧融合技术，用于处理包含球衣号码的关键帧，从而提高识别准确率。在三个大型数据集（棒球、SoccerNet 和冰球）上的实验中，该方法在测试集准确率上分别比现有最先进技术提升了8.58%、4.29%和1.20%，消融实验进一步验证了d-MAE和KfID改进的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Submitted to 21st International Conference on Robots and Vision\n  (CRV'24), Guelph, Ontario, Canada",
      "pdf_url": "http://arxiv.org/pdf/2403.11328v1",
      "published_date": "2024-03-17 20:14:57 UTC",
      "updated_date": "2024-03-17 20:14:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:18:53.564853"
    },
    {
      "arxiv_id": "2403.11322v5",
      "title": "StateFlow: Enhancing LLM Task-Solving through State-Driven Workflows",
      "title_zh": "StateFlow：通过状态驱动工作流增强LLM任务求解",
      "authors": [
        "Yiran Wu",
        "Tianwei Yue",
        "Shaokun Zhang",
        "Chi Wang",
        "Qingyun Wu"
      ],
      "abstract": "It is a notable trend to use Large Language Models (LLMs) to tackle complex\ntasks, e.g., tasks that require a sequence of actions and dynamic interaction\nwith tools and external environments. In this paper, we propose StateFlow, a\nnovel LLM-based task-solving paradigm that conceptualizes complex task-solving\nprocesses as state machines. In StateFlow, we distinguish between \"process\ngrounding\" (via state and state transitions) and \"sub-task solving\" (through\nactions within a state), enhancing control and interpretability of the\ntask-solving procedure. A state represents the status of a running process. The\ntransitions between states are controlled by heuristic rules or decisions made\nby the LLM, allowing for a dynamic and adaptive progression. Upon entering a\nstate, a series of actions is executed, involving not only calling LLMs guided\nby different prompts, but also the utilization of external tools as needed. Our\nresults show that StateFlow significantly enhances LLMs' efficiency. For\ninstance, StateFlow achieves 13% and 28% higher success rates compared to ReAct\nin InterCode SQL and ALFWorld benchmark, with 5x and 3x less cost respectively.\nWe also show that StateFlow can be combined with iterative refining methods\nlike Reflexion to further improve performance.",
      "tldr_zh": "本文提出 StateFlow，一种基于状态驱动工作流的框架，用于提升大语言模型 (LLMs) 在复杂任务解决中的性能，将任务过程建模为状态机，包括状态表示和状态转换。StateFlow 区分“过程 grounding”（通过状态和转换实现）和“子任务解决”（在状态内执行动作，如调用 LLMs 和外部工具），从而提高任务的控制性和可解释性。实验结果显示，该框架在 InterCode SQL 和 ALFWorld 基准上，比 ReAct 分别提升 13% 和 28% 的成功率，同时减少 5 倍和 3 倍的成本；此外，它可与 Reflexion 等迭代改进方法结合，进一步优化性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.11322v5",
      "published_date": "2024-03-17 19:54:16 UTC",
      "updated_date": "2024-09-14 21:55:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:19:07.082660"
    },
    {
      "arxiv_id": "2403.11304v1",
      "title": "Pioneering SE(2)-Equivariant Trajectory Planning for Automated Driving",
      "title_zh": "开创性的 SE(2)-等变轨迹规划用于自动驾驶",
      "authors": [
        "Steffen Hagedorn",
        "Marcel Milich",
        "Alexandru P. Condurache"
      ],
      "abstract": "Planning the trajectory of the controlled ego vehicle is a key challenge in\nautomated driving. As for human drivers, predicting the motions of surrounding\nvehicles is important to plan the own actions. Recent motion prediction methods\nutilize equivariant neural networks to exploit geometric symmetries in the\nscene. However, no existing method combines motion prediction and trajectory\nplanning in a joint step while guaranteeing equivariance under\nroto-translations of the input space. We address this gap by proposing a\nlightweight equivariant planning model that generates multi-modal joint\npredictions for all vehicles and selects one mode as the ego plan. The\nequivariant network design improves sample efficiency, guarantees output\nstability, and reduces model parameters. We further propose equivariant route\nattraction to guide the ego vehicle along a high-level route provided by an\noff-the-shelf GPS navigation system. This module creates a momentum from\nembedded vehicle positions toward the route in latent space while keeping the\nequivariance property. Route attraction enables goal-oriented behavior without\nforcing the vehicle to stick to the exact route. We conduct experiments on the\nchallenging nuScenes dataset to investigate the capability of our planner. The\nresults show that the planned trajectory is stable under roto-translations of\nthe input scene which demonstrates the equivariance of our model. Despite using\nonly a small split of the dataset for training, our method improves L2 distance\nat 3 s by 20.6 % and surpasses the state of the art.",
      "tldr_zh": "这篇论文针对自动驾驶中的轨迹规划挑战，提出了一种首创的 SE(2)-Equivariant 模型，将运动预测和轨迹规划整合为一个等变步骤，确保输出对输入空间的 roto-translations 稳定。模型通过轻量级神经网络生成多模态联合预测，并引入等变路线吸引模块，利用 GPS 导航的高级路线在潜在空间引导自车行为，同时保持等变性，以实现目标导向而不强制严格路径。实验在 nuScenes 数据集上表明，该方法仅使用少量训练数据即将 3 秒内的 L2 distance 改善了 20.6%，超越了现有技术。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.11304v1",
      "published_date": "2024-03-17 18:53:46 UTC",
      "updated_date": "2024-03-17 18:53:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:19:18.423765"
    },
    {
      "arxiv_id": "2403.11299v2",
      "title": "SQ-LLaVA: Self-Questioning for Large Vision-Language Assistant",
      "title_zh": "SQ-LLaVA：针对大型视觉语言助手的自我提问",
      "authors": [
        "Guohao Sun",
        "Can Qin",
        "Jiamian Wang",
        "Zeyuan Chen",
        "Ran Xu",
        "Zhiqiang Tao"
      ],
      "abstract": "Recent advances in vision-language models have shown notable generalization\nin broad tasks through visual instruction tuning. However, bridging the gap\nbetween the pre-trained vision encoder and the large language models (LLMs)\nbecomes the whole network's bottleneck. To improve cross-modality alignment,\nexisting works usually consider more visual instruction data covering a broader\nrange of vision tasks to fine-tune the model for question-answering, which,\nhowever, is costly to obtain and has not thoroughly explored the rich\ncontextual information contained in images. This paper first attempts to\nharness the overlooked context within visual instruction data, training the\nmodel to self-supervised \"learning\" how to ask high-quality questions. In this\nway, we introduce a novel framework named SQ-LLaVA: Self-Questioning for Large\nVision-Language Assistant. SQ-LLaVA exhibits proficiency in generating flexible\nand meaningful image-related questions while analyzing the visual clue and\nprior language knowledge, signifying an advanced level of generalized visual\nunderstanding. Moreover, fine-tuning SQ-LLaVA on higher-quality instruction\ndata shows a performance improvement compared with traditional\nvisual-instruction tuning methods. This improvement highlights the efficacy of\nself-questioning techniques in achieving a deeper and more nuanced\ncomprehension of visual content across various contexts.",
      "tldr_zh": "该研究针对视觉语言模型（vision-language models）中预训练视觉编码器与大型语言模型（LLMs）之间的跨模态对齐（cross-modality alignment）瓶颈，提出了一种新框架 SQ-LLaVA：Self-Questioning for Large Vision-Language Assistant。SQ-LLaVA 通过自监督训练模型“学习”生成高质量的图像相关问题，利用图像中的丰富上下文信息来提升视觉理解和任务泛化能力。实验结果显示，在更高质量的视觉指令数据上微调后，SQ-LLaVA 比传统 visual-instruction tuning 方法表现出性能提升，证明了 self-questioning 技术在深化视觉内容理解方面的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.11299v2",
      "published_date": "2024-03-17 18:42:38 UTC",
      "updated_date": "2024-07-15 17:37:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:19:30.040885"
    },
    {
      "arxiv_id": "2405.15774v1",
      "title": "Comprehensive Autonomous Vehicle Optimal Routing With Dynamic Heuristics",
      "title_zh": "翻译失败",
      "authors": [
        "Ragav V",
        "Jesher Joshua M",
        "Syed Ibrahim S P"
      ],
      "abstract": "Auto manufacturers and research groups are working on autonomous driving for\nlong period and achieved significant progress. Autonomous vehicles (AV) are\nexpected to transform road traffic reduction from current conditions, avoiding\naccidents and congestion. As the implementation of an autonomous vehicle\necosystem includes complex automotive technology, ethics, passenger behaviour,\ntraffic management policies and liability etc., the maturity of AV solutions\nare still evolving. The proposed model to improve AV user experience, uses a\nhybrid AV Network of multiple connected autonomous vehicles which communicate\nwith each other in an environment shared by human driven vehicles. The proposed\nOptimal AV Network (OAVN) solution provides better coordination and\noptimization of autonomous vehicles, improved Transportation efficiency,\nimproved passenger comfort and safety, real-time dynamic adaption of traffic &\nroad conditions along with improved in-cabin assistance with inputs from\nvarious sensors. The true optimal solution for this problem, is to devise an\nautomated guidance system for vehicles in an AV network, to reach destinations\nin best possible routes along with passenger comfort and safety. A custom\ninformed search model is proposed along with other heuristic goals for better\nuser experience. The results are analysed and compared to evaluate the\neffectiveness of the solution and identify gaps and future enhancements.",
      "tldr_zh": "本研究针对自动驾驶车辆（Autonomous Vehicles, AV）的优化路由问题，提出了一种综合框架，以动态启发式（Dynamic Heuristics）提升交通效率和安全性。该框架包括一个混合AV网络（Optimal AV Network, OAVN），允许多个连接的AV相互通信，并在与人类驾驶车辆共享的环境中实现实时协调、优化和适应交通条件，从而改善乘客舒适度和机舱辅助。研究采用自定义的informed search模型结合其他启发式目标，设计自动指导系统，帮助车辆选择最佳路线，同时优先考虑安全和用户体验。实验结果通过分析和比较，证明了该解决方案的有效性，并指出了潜在的改进方向和未来扩展。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.15774v1",
      "published_date": "2024-03-17 18:21:56 UTC",
      "updated_date": "2024-03-17 18:21:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:19:40.378428"
    },
    {
      "arxiv_id": "2403.11292v1",
      "title": "Multi-Relational Graph Neural Network for Out-of-Domain Link Prediction",
      "title_zh": "多关系图神经网络用于出域链接预测",
      "authors": [
        "Asma Sattar",
        "Georgios Deligiorgis",
        "Marco Trincavelli",
        "Davide Bacciu"
      ],
      "abstract": "Dynamic multi-relational graphs are an expressive relational representation\nfor data enclosing entities and relations of different types, and where\nrelationships are allowed to vary in time. Addressing predictive tasks over\nsuch data requires the ability to find structure embeddings that capture the\ndiversity of the relationships involved, as well as their dynamic evolution. In\nthis work, we establish a novel class of challenging tasks for dynamic\nmulti-relational graphs involving out-of-domain link prediction, where the\nrelationship being predicted is not available in the input graph. We then\nintroduce a novel Graph Neural Network model, named GOOD, designed specifically\nto tackle the out-of-domain generalization problem. GOOD introduces a novel\ndesign concept for multi-relation embedding aggregation, based on the idea that\ngood representations are such when it is possible to disentangle the mixing\nproportions of the different relational embeddings that have produced it. We\nalso propose five benchmarks based on two retail domains, where we show that\nGOOD can effectively generalize predictions out of known relationship types and\nachieve state-of-the-art results. Most importantly, we provide insights into\nproblems where out-of-domain prediction might be preferred to an in-domain\nformulation, that is, where the relationship to be predicted has very few\npositive examples.",
      "tldr_zh": "本论文针对动态多关系图（Multi-Relational Graphs），引入了out-of-domain link prediction任务，该任务要求预测输入图中不存在的关系类型，以捕捉关系的多样性和动态演化。作者提出了一种新型Graph Neural Network模型GOOD，通过创新的多关系嵌入聚合设计（如嵌入解耦机制），实现对不同关系嵌入混合比例的分离，从而提升out-of-domain泛化能力。在五个基于零售领域的基准测试中，GOOD模型在未知关系预测上比现有方法表现优越，并提供见解，指出在正例稀少的情况下，out-of-domain方法更具优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 3 figures, 3 Tables, conference [accepted in IEEE WCCI 2024]",
      "pdf_url": "http://arxiv.org/pdf/2403.11292v1",
      "published_date": "2024-03-17 18:08:22 UTC",
      "updated_date": "2024-03-17 18:08:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:19:54.316235"
    },
    {
      "arxiv_id": "2403.13843v2",
      "title": "Machine Learning and Transformers for Thyroid Carcinoma Diagnosis: A Review",
      "title_zh": "翻译失败",
      "authors": [
        "Yassine Habchi",
        "Hamza Kheddar",
        "Yassine Himeur",
        "Mohamed Chahine Ghanem"
      ],
      "abstract": "The growing interest in developing smart diagnostic systems to help medical\nexperts process extensive data for treating incurable diseases has been\nnotable. In particular, the challenge of identifying thyroid cancer (TC) has\nseen progress with the use of machine learning (ML) and big data analysis,\nincorporating Transformers to evaluate TC prognosis and determine the risk of\nmalignancy in individuals. This review article presents a summary of various\nstudies on AI-based approaches, especially those employing Transformers, for\ndiagnosing TC. It introduces a new categorization system for these methods\nbased on artificial intelligence (AI) algorithms, the goals of the framework,\nand the computing environments used. Additionally, it scrutinizes and contrasts\nthe available TC datasets by their features. The paper highlights the\nimportance of AI instruments in aiding the diagnosis and treatment of TC\nthrough supervised, unsupervised, or mixed approaches, with a special focus on\nthe ongoing importance of Transformers and large language models (LLMs) in\nmedical diagnostics and disease management. It further discusses the progress\nmade and the continuing obstacles in this area. Lastly, it explores future\ndirections and focuses within this research field.",
      "tldr_zh": "这篇综述文章回顾了机器学习（ML）和 Transformers 在甲状腺癌（Thyroid Carcinoma, TC）诊断中的应用，总结了各种基于人工智能（AI）的诊断方法，包括监督、非监督和混合方法。文章引入了一个新的分类系统，根据AI算法、框架目标和计算环境对这些方法进行划分，并比较了现有TC数据集的特点。最终，它强调了Transformers和大型语言模型（LLMs）在医疗诊断中的重要作用，讨论了当前进展、面临的挑战以及未来研究方向。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.13843v2",
      "published_date": "2024-03-17 17:45:04 UTC",
      "updated_date": "2025-04-14 15:10:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:20:04.365529"
    },
    {
      "arxiv_id": "2404.04264v5",
      "title": "Logic Query of Thoughts: Guiding Large Language Models to Answer Complex Logic Queries with Knowledge Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Lihui Liu",
        "Zihao Wang",
        "Ruizhong Qiu",
        "Yikun Ban",
        "Eunice Chan",
        "Yangqiu Song",
        "Jingrui He",
        "Hanghang Tong"
      ],
      "abstract": "Despite the superb performance in many tasks, large language models (LLMs)\nbear the risk of generating hallucination or even wrong answers when confronted\nwith tasks that demand the accuracy of knowledge. The issue becomes even more\nnoticeable when addressing logic queries that require multiple logic reasoning\nsteps. On the other hand, knowledge graph (KG) based question answering methods\nare capable of accurately identifying the correct answers with the help of\nknowledge graph, yet its accuracy could quickly deteriorate when the knowledge\ngraph itself is sparse and incomplete. It remains a critical challenge on how\nto integrate knowledge graph reasoning with LLMs in a mutually beneficial way\nso as to mitigate both the hallucination problem of LLMs as well as the\nincompleteness issue of knowledge graphs. In this paper, we propose\n'Logic-Query-of-Thoughts' (LGOT) which is the first of its kind to combine LLMs\nwith knowledge graph based logic query reasoning. LGOT seamlessly combines\nknowledge graph reasoning and LLMs, effectively breaking down complex logic\nqueries into easy to answer subquestions. Through the utilization of both\nknowledge graph reasoning and LLMs, it successfully derives answers for each\nsubquestion. By aggregating these results and selecting the highest quality\ncandidate answers for each step, LGOT achieves accurate results to complex\nquestions. Our experimental findings demonstrate substantial performance\nenhancements, with up to 20% improvement over ChatGPT.",
      "tldr_zh": "这篇论文针对大型语言模型(LLMs)在处理复杂逻辑查询时可能产生的幻觉和错误问题，提出了一种新框架Logic-Query-of-Thoughts (LGOT)，它首次将LLMs与知识图谱(KG)结合。LGOT通过将复杂查询分解为易处理的子问题，利用KG进行推理并借助LLMs回答子问题，然后聚合并选择最佳答案，实现更准确的逻辑查询响应。实验结果显示，LGOT相较于ChatGPT在性能上提升高达20%。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.04264v5",
      "published_date": "2024-03-17 17:01:45 UTC",
      "updated_date": "2024-12-12 23:17:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:20:17.299713"
    },
    {
      "arxiv_id": "2403.11265v2",
      "title": "Forging the Forger: An Attempt to Improve Authorship Verification via Data Augmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Silvia Corbara",
        "Alejandro Moreo"
      ],
      "abstract": "Authorship Verification (AV) is a text classification task concerned with\ninferring whether a candidate text has been written by one specific author or\nby someone else. It has been shown that many AV systems are vulnerable to\nadversarial attacks, where a malicious author actively tries to fool the\nclassifier by either concealing their writing style, or by imitating the style\nof another author. In this paper, we investigate the potential benefits of\naugmenting the classifier training set with (negative) synthetic examples.\nThese synthetic examples are generated to imitate the style of the author of\ninterest. We analyze the improvements in classifier prediction that this\naugmentation brings to bear in the task of AV in an adversarial setting. In\nparticular, we experiment with three different generator architectures (one\nbased on Recurrent Neural Networks, another based on small-scale transformers,\nand another based on the popular GPT model) and with two training strategies\n(one inspired by standard Language Models, and another inspired by Wasserstein\nGenerative Adversarial Networks). We evaluate our hypothesis on five datasets\n(three of which have been specifically collected to represent an adversarial\nsetting) and using two learning algorithms for the AV classifier (Support\nVector Machines and Convolutional Neural Networks). This experimentation has\nyielded negative results, revealing that, although our methodology proves\neffective in many adversarial settings, its benefits are too sporadic for a\npragmatical application.",
      "tldr_zh": "本文探讨了通过数据增强改进 Authorship Verification (AV) 的方法，旨在提升系统对 adversarial attacks 的抵抗力，例如恶意作者隐藏写作风格或模仿他人。研究团队使用三种生成器架构（RNN-based、small-scale transformers 和 GPT-based）以及两种训练策略（Language Models-inspired 和 Wasserstein GAN-inspired）来创建模仿目标作者风格的合成样本，并在五个数据集上进行实验，采用 SVM 和 CNN 作为分类器。结果显示，虽然该方法在某些对抗场景中有效，但整体收益不稳定，因此不适合实际应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.11265v2",
      "published_date": "2024-03-17 16:36:26 UTC",
      "updated_date": "2024-10-29 13:01:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:20:30.470992"
    },
    {
      "arxiv_id": "2403.11262v1",
      "title": "Understanding Diffusion Models by Feynman's Path Integral",
      "title_zh": "通过费曼路径积分理解扩散模型",
      "authors": [
        "Yuji Hirono",
        "Akinori Tanaka",
        "Kenji Fukushima"
      ],
      "abstract": "Score-based diffusion models have proven effective in image generation and\nhave gained widespread usage; however, the underlying factors contributing to\nthe performance disparity between stochastic and deterministic (i.e., the\nprobability flow ODEs) sampling schemes remain unclear. We introduce a novel\nformulation of diffusion models using Feynman's path integral, which is a\nformulation originally developed for quantum physics. We find this formulation\nproviding comprehensive descriptions of score-based generative models, and\ndemonstrate the derivation of backward stochastic differential equations and\nloss functions.The formulation accommodates an interpolating parameter\nconnecting stochastic and deterministic sampling schemes, and we identify this\nparameter as a counterpart of Planck's constant in quantum physics. This\nanalogy enables us to apply the Wentzel-Kramers-Brillouin (WKB) expansion, a\nwell-established technique in quantum physics, for evaluating the negative\nlog-likelihood to assess the performance disparity between stochastic and\ndeterministic sampling schemes.",
      "tldr_zh": "该论文使用Feynman's path integral（费曼路径积分）来重新表述score-based diffusion models，旨在解释随机和确定性采样方案（如概率流ODEs）之间的性能差异。研究发现，这种表述能全面描述扩散模型的生成过程，并推导出后向随机微分方程和损失函数，同时引入一个插值参数作为Planck's constant的对应物，用于连接两种采样方案。通过应用Wentzel-Kramers-Brillouin (WKB) expansion，论文评估了负对数似然，揭示了采样方案差异的潜在原因，为理解和优化diffusion models提供了新视角。",
      "categories": [
        "cs.LG",
        "cond-mat.stat-mech",
        "cs.AI",
        "hep-th"
      ],
      "primary_category": "cs.LG",
      "comment": "27 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.11262v1",
      "published_date": "2024-03-17 16:24:29 UTC",
      "updated_date": "2024-03-17 16:24:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:20:41.365922"
    },
    {
      "arxiv_id": "2403.11261v1",
      "title": "A Lie Group Approach to Riemannian Batch Normalization",
      "title_zh": "李群方法在黎曼批标准化中的应用",
      "authors": [
        "Ziheng Chen",
        "Yue Song",
        "Yunmei Liu",
        "Nicu Sebe"
      ],
      "abstract": "Manifold-valued measurements exist in numerous applications within computer\nvision and machine learning. Recent studies have extended Deep Neural Networks\n(DNNs) to manifolds, and concomitantly, normalization techniques have also been\nadapted to several manifolds, referred to as Riemannian normalization.\nNonetheless, most of the existing Riemannian normalization methods have been\nderived in an ad hoc manner and only apply to specific manifolds. This paper\nestablishes a unified framework for Riemannian Batch Normalization (RBN)\ntechniques on Lie groups. Our framework offers the theoretical guarantee of\ncontrolling both the Riemannian mean and variance. Empirically, we focus on\nSymmetric Positive Definite (SPD) manifolds, which possess three distinct types\nof Lie group structures. Using the deformation concept, we generalize the\nexisting Lie groups on SPD manifolds into three families of parameterized Lie\ngroups. Specific normalization layers induced by these Lie groups are then\nproposed for SPD neural networks. We demonstrate the effectiveness of our\napproach through three sets of experiments: radar recognition, human action\nrecognition, and electroencephalography (EEG) classification. The code is\navailable at https://github.com/GitZH-Chen/LieBN.git.",
      "tldr_zh": "本论文提出了一种基于Lie群的统一框架，用于Riemannian Batch Normalization (RBN)，以解决现有Riemannian normalization方法在特定流形上的局限性。该框架理论上确保了对Riemannian均值和方差的有效控制，并通过变形概念将Symmetric Positive Definite (SPD)流形上的Lie群推广为三族参数化Lie群，从而设计出适用于SPD神经网络的具体归一化层。实验结果显示，该方法在雷达识别、人体动作识别和脑电图(EEG)分类任务中表现出色，证明了其有效性和泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MS"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.11261v1",
      "published_date": "2024-03-17 16:24:07 UTC",
      "updated_date": "2024-03-17 16:24:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:20:54.126849"
    },
    {
      "arxiv_id": "2403.11259v2",
      "title": "A learning-based solution approach to the application placement problem in mobile edge computing under uncertainty",
      "title_zh": "一种基于学习的解决方案方法，用于不确定性下的移动边缘计算应用放置问题",
      "authors": [
        "Taha-Hossein Hejazi",
        "Zahra Ghadimkhani",
        "Arezoo Borji"
      ],
      "abstract": "Placing applications in mobile edge computing servers presents a complex\nchallenge involving many servers, users, and their requests. Existing\nalgorithms take a long time to solve high-dimensional problems with significant\nuncertainty scenarios. Therefore, an efficient approach is required to maximize\nthe quality of service while considering all technical constraints. One of\nthese approaches is machine learning, which emulates optimal solutions for\napplication placement in edge servers. Machine learning models are expected to\nlearn how to allocate user requests to servers based on the spatial positions\nof users and servers. In this study, the problem is formulated as a two-stage\nstochastic programming. A sufficient amount of training records is generated by\nvarying parameters such as user locations, their request rates, and solving the\noptimization model. Then, based on the distance features of each user from the\navailable servers and their request rates, machine learning models generate\ndecision variables for the first stage of the stochastic optimization model,\nwhich is the user-to-server request allocation, and are employed as independent\ndecision agents that reliably mimic the optimization model. Support Vector\nMachines (SVM) and Multi-layer Perceptron (MLP) are used in this research to\nachieve practical decisions from the stochastic optimization models. The\nperformance of each model has shown an execution effectiveness of over 80%.\nThis research aims to provide a more efficient approach for tackling\nhigh-dimensional problems and scenarios with uncertainties in mobile edge\ncomputing by leveraging machine learning models for optimal decision-making in\nrequest allocation to edge servers. These results suggest that machine-learning\nmodels can significantly improve solution times compared to conventional\napproaches.",
      "tldr_zh": "这篇论文针对移动边缘计算（mobile edge computing）中应用放置问题的不确定性，提出了一种基于机器学习的学习型解决方案，以高效最大化服务质量并满足技术约束。研究将问题建模为两阶段随机规划（two-stage stochastic programming），通过生成训练数据（如用户位置和请求率）来训练 Support Vector Machines (SVM) 和 Multi-layer Perceptron (MLP) 模型，这些模型作为独立决策代理模拟最优的用户到服务器请求分配。实验结果显示，模型的执行有效性超过80%，显著缩短了高维不确定性场景的解决方案时间。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.11259v2",
      "published_date": "2024-03-17 16:23:00 UTC",
      "updated_date": "2024-03-23 08:27:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:21:06.343777"
    },
    {
      "arxiv_id": "2403.15443v2",
      "title": "Introducing an ensemble method for the early detection of Alzheimer's disease through the analysis of PET scan images",
      "title_zh": "翻译失败",
      "authors": [
        "Arezoo Borji",
        "Taha-Hossein Hejazi",
        "Abbas Seifi"
      ],
      "abstract": "Alzheimer's disease is a progressive neurodegenerative disorder that\nprimarily affects cognitive functions such as memory, thinking, and behavior.\nIn this disease, there is a critical phase, mild cognitive impairment, that is\nreally important to be diagnosed early since some patients with progressive MCI\nwill develop the disease. This study delves into the challenging task of\nclassifying Alzheimer's disease into four distinct groups: control normal (CN),\nprogressive mild cognitive impairment (pMCI), stable mild cognitive impairment\n(sMCI), and Alzheimer's disease (AD). This classification is based on a\nthorough examination of PET scan images obtained from the ADNI dataset, which\nprovides a thorough understanding of the disease's progression. Several\ndeep-learning and traditional machine-learning models have been used to detect\nAlzheimer's disease. In this paper, three deep-learning models, namely VGG16\nand AlexNet, and a custom Convolutional neural network (CNN) with 8-fold\ncross-validation have been used for classification. Finally, an ensemble\ntechnique is used to improve the overall result of these models. The results\nshow that using deep-learning models to tell the difference between MCI\npatients gives an overall average accuracy of 93.13% and an AUC of 94.4%.",
      "tldr_zh": "这篇论文介绍了通过分析 PET 扫描图像的一种 ensemble 方法，用于早期检测 Alzheimer's disease，并将患者分类为控制正常 (CN)、进行性轻度认知障碍 (pMCI)、稳定轻度认知障碍 (sMCI) 和 Alzheimer's disease (AD)。研究基于 ADNI 数据集，采用了 VGG16、AlexNet 和自定义 CNN 模型，并通过 8-fold cross-validation 和 ensemble 技术来提升分类性能。结果显示，该方法在区分 MCI 患者方面取得了平均准确率 93.13% 和 AUC 94.4%，为阿尔茨海默病的早期诊断提供了有效工具。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.15443v2",
      "published_date": "2024-03-17 16:12:50 UTC",
      "updated_date": "2024-04-01 16:37:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:21:18.813201"
    },
    {
      "arxiv_id": "2403.12106v1",
      "title": "Circular Belief Propagation for Approximate Probabilistic Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Vincent Bouttier",
        "Renaud Jardri",
        "Sophie Deneve"
      ],
      "abstract": "Belief Propagation (BP) is a simple probabilistic inference algorithm,\nconsisting of passing messages between nodes of a graph representing a\nprobability distribution. Its analogy with a neural network suggests that it\ncould have far-ranging applications for neuroscience and artificial\nintelligence. Unfortunately, it is only exact when applied to cycle-free\ngraphs, which restricts the potential of the algorithm. In this paper, we\npropose Circular Belief Propagation (CBP), an extension of BP which limits the\ndetrimental effects of message reverberation caused by cycles by learning to\ndetect and cancel spurious correlations and belief amplifications. We show in\nnumerical experiments involving binary probabilistic graphs that CBP far\noutperforms BP and reaches good performance compared to that of previously\nproposed algorithms.",
      "tldr_zh": "本论文针对 Belief Propagation (BP) 算法在有环图上的局限性提出 Circular Belief Propagation (CBP)，一种扩展方法，通过学习检测和取消循环引起的虚假相关性及信念放大，从而减少消息回响的负面影响。CBP 保留了 BP 的简单性，同时增强了其在概率图上的适用性，特别适用于神经科学和人工智能领域。在二元概率图的数值实验中，CBP 显著优于传统 BP，并与现有算法相比表现出色性能。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.12106v1",
      "published_date": "2024-03-17 15:59:39 UTC",
      "updated_date": "2024-03-17 15:59:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:21:29.326188"
    },
    {
      "arxiv_id": "2403.11220v3",
      "title": "CPA-Enhancer: Chain-of-Thought Prompted Adaptive Enhancer for Object Detection under Unknown Degradations",
      "title_zh": "翻译失败",
      "authors": [
        "Yuwei Zhang",
        "Yan Wu",
        "Yanming Liu",
        "Xinyue Peng"
      ],
      "abstract": "Object detection methods under known single degradations have been\nextensively investigated. However, existing approaches require prior knowledge\nof the degradation type and train a separate model for each, limiting their\npractical applications in unpredictable environments. To address this\nchallenge, we propose a chain-of-thought (CoT) prompted adaptive enhancer,\nCPA-Enhancer, for object detection under unknown degradations. Specifically,\nCPA-Enhancer progressively adapts its enhancement strategy under the\nstep-by-step guidance of CoT prompts, that encode degradation-related\ninformation. To the best of our knowledge, it's the first work that exploits\nCoT prompting for object detection tasks. Overall, CPA-Enhancer is a\nplug-and-play enhancement model that can be integrated into any generic\ndetectors to achieve substantial gains on degraded images, without knowing the\ndegradation type priorly. Experimental results demonstrate that CPA-Enhancer\nnot only sets the new state of the art for object detection but also boosts the\nperformance of other downstream vision tasks under unknown degradations.",
      "tldr_zh": "本研究针对对象检测在未知退化条件下的挑战，提出了一种名为 CPA-Enhancer 的自适应增强器，利用 Chain-of-Thought (CoT) 提示逐步指导增强策略，以编码退化相关信息。不同于现有方法需事先知道退化类型并训练单独模型，CPA-Enhancer 是首个将 CoT 应用于对象检测任务的即插即用模型，可无缝集成到任何通用检测器中。实验结果显示，该方法在退化图像上显著提升对象检测性能，并为其他下游视觉任务带来新的最先进水平。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.11220v3",
      "published_date": "2024-03-17 13:43:10 UTC",
      "updated_date": "2024-03-22 11:42:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:21:42.057718"
    },
    {
      "arxiv_id": "2403.11219v1",
      "title": "Causality from Bottom to Top: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Abraham Itzhak Weinberg",
        "Cristiano Premebida",
        "Diego Resende Faria"
      ],
      "abstract": "Causality has become a fundamental approach for explaining the relationships\nbetween events, phenomena, and outcomes in various fields of study. It has\ninvaded various fields and applications, such as medicine, healthcare,\neconomics, finance, fraud detection, cybersecurity, education, public policy,\nrecommender systems, anomaly detection, robotics, control, sociology,\nmarketing, and advertising. In this paper, we survey its development over the\npast five decades, shedding light on the differences between causality and\nother approaches, as well as the preconditions for using it. Furthermore, the\npaper illustrates how causality interacts with new approaches such as\nArtificial Intelligence (AI), Generative AI (GAI), Machine and Deep Learning,\nReinforcement Learning (RL), and Fuzzy Logic. We study the impact of causality\non various fields, its contribution, and its interaction with state-of-the-art\napproaches. Additionally, the paper exemplifies the trustworthiness and\nexplainability of causality models. We offer several ways to evaluate causality\nmodels and discuss future directions.",
      "tldr_zh": "这篇论文对因果关系(Causality)的发展进行了全面调查，回顾了过去五十年其在医学、健康、经济、金融等领域中的应用，并强调了其与传统方法的不同以及使用的前提条件。论文探讨了Causality如何与现代技术如Artificial Intelligence (AI)、Generative AI (GAI)、Machine Learning、Deep Learning、Reinforcement Learning (RL)和Fuzzy Logic互动，分析了其在这些领域的贡献和可信度。最终，它提供了评估Causality模型的多种方法，并指出了未来的研究方向。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.11219v1",
      "published_date": "2024-03-17 13:39:43 UTC",
      "updated_date": "2024-03-17 13:39:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:21:55.488580"
    },
    {
      "arxiv_id": "2403.11217v1",
      "title": "Research on Personal Credit Risk Assessment Methods Based on Causal Inference",
      "title_zh": "基于因果推理的",
      "authors": [
        "Jiaxin Wang",
        "YiLong Ma"
      ],
      "abstract": "The discussion on causality in human history dates back to ancient Greece,\nyet to this day, there is still no consensus. Fundamentally, this stems from\nthe nature of human cognition, as understanding causality requires abstract\ntools to transcend the limitations of human cognition. In recent decades, the\nrapid development of mathematical and computational tools has provided new\ntheoretical and technical means for exploring causality, creating more avenues\nfor investigation.\n  Based on this, this paper introduces a new definition of causality using\ncategory theory, proposed by Samuel Eilenberg and Saunders Mac Lane in 1945 to\navoid the self-referential contradictions in set theory, notably the Russell\nparadox. Within this framework, the feasibility of indicator synthesis in\ncausal inference is demonstrated. Due to the limitations in the development of\ncategory theory-related technical tools, this paper adopts the widely-used\nprobabilistic causal graph tool proposed by Judea Pearl in 1995 to study the\napplication of causal inference in personal credit risk management. The\nspecific work includes: research on the construction method of causal inference\nindex system, definition of causality and feasibility proof of indicator\nsynthesis causal inference within this framework, application methods of causal\ngraph model and intervention alternative criteria in personal credit risk\nmanagement, and so on.",
      "tldr_zh": "该论文探讨了基于因果推断（causal inference）的个人信用风险评估方法，回顾了因果关系的认知历史，并使用范畴论（category theory）提出新的因果定义，以避免传统理论中的自指矛盾问题。作者证明了指标综合在因果推断框架中的可行性，并采用 Judea Pearl 于1995年提出的概率因果图（probabilistic causal graph）工具，研究了因果推断指标系统的构建和应用方法。最终，该方法应用于个人信用风险管理中，包括因果图模型的干预备选标准，从而提升风险评估的准确性和可靠性。",
      "categories": [
        "cs.AI",
        "math.CT"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.11217v1",
      "published_date": "2024-03-17 13:34:45 UTC",
      "updated_date": "2024-03-17 13:34:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:22:05.221742"
    },
    {
      "arxiv_id": "2403.11207v2",
      "title": "MindEye2: Shared-Subject Models Enable fMRI-To-Image With 1 Hour of Data",
      "title_zh": "翻译失败",
      "authors": [
        "Paul S. Scotti",
        "Mihir Tripathy",
        "Cesar Kadir Torrico Villanueva",
        "Reese Kneeland",
        "Tong Chen",
        "Ashutosh Narang",
        "Charan Santhirasegaran",
        "Jonathan Xu",
        "Thomas Naselaris",
        "Kenneth A. Norman",
        "Tanishq Mathew Abraham"
      ],
      "abstract": "Reconstructions of visual perception from brain activity have improved\ntremendously, but the practical utility of such methods has been limited. This\nis because such models are trained independently per subject where each subject\nrequires dozens of hours of expensive fMRI training data to attain high-quality\nresults. The present work showcases high-quality reconstructions using only 1\nhour of fMRI training data. We pretrain our model across 7 subjects and then\nfine-tune on minimal data from a new subject. Our novel functional alignment\nprocedure linearly maps all brain data to a shared-subject latent space,\nfollowed by a shared non-linear mapping to CLIP image space. We then map from\nCLIP space to pixel space by fine-tuning Stable Diffusion XL to accept CLIP\nlatents as inputs instead of text. This approach improves out-of-subject\ngeneralization with limited training data and also attains state-of-the-art\nimage retrieval and reconstruction metrics compared to single-subject\napproaches. MindEye2 demonstrates how accurate reconstructions of perception\nare possible from a single visit to the MRI facility. All code is available on\nGitHub.",
      "tldr_zh": "该研究提出了 MindEye2 模型，通过共享受试者训练方法，仅需 1 小时 fMRI 数据即可实现高质量的脑活动到图像重建，解决了传统模型对每个受试者需要数十小时数据的问题。MindEye2 采用功能对齐程序将脑数据线性映射到共享受试者潜在空间，然后非线性映射到 CLIP 图像空间，并微调 Stable Diffusion XL 以接受 CLIP 潜在表示作为输入，从而提升了受试者外泛化能力。实验结果显示，该方法在图像检索和重建指标上超越了单受试者方法，并证明了从单次 MRI 访问中获得准确感知重建的可能性，所有代码已在 GitHub 开源。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "cs.CV",
      "comment": "In Forty-first International Conference on Machine Learning, 2024.\n  Code at https://github.com/MedARC-AI/MindEyeV2. Published as a conference\n  paper at ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.11207v2",
      "published_date": "2024-03-17 13:15:22 UTC",
      "updated_date": "2024-06-15 23:07:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:22:19.205025"
    },
    {
      "arxiv_id": "2403.14706v1",
      "title": "Safeguarding Marketing Research: The Generation, Identification, and Mitigation of AI-Fabricated Disinformation",
      "title_zh": "保障市场研究：AI 制造的虚假信息的生成、识别与缓解",
      "authors": [
        "Anirban Mukherjee"
      ],
      "abstract": "Generative AI has ushered in the ability to generate content that closely\nmimics human contributions, introducing an unprecedented threat: Deployed en\nmasse, these models can be used to manipulate public opinion and distort\nperceptions, resulting in a decline in trust towards digital platforms. This\nstudy contributes to marketing literature and practice in three ways. First, it\ndemonstrates the proficiency of AI in fabricating disinformative user-generated\ncontent (UGC) that mimics the form of authentic content. Second, it quantifies\nthe disruptive impact of such UGC on marketing research, highlighting the\nsusceptibility of analytics frameworks to even minimal levels of\ndisinformation. Third, it proposes and evaluates advanced detection frameworks,\nrevealing that standard techniques are insufficient for filtering out\nAI-generated disinformation. We advocate for a comprehensive approach to\nsafeguarding marketing research that integrates advanced algorithmic solutions,\nenhanced human oversight, and a reevaluation of regulatory and ethical\nframeworks. Our study seeks to serve as a catalyst, providing a foundation for\nfuture research and policy-making aimed at navigating the intricate challenges\nat the nexus of technology, ethics, and marketing.",
      "tldr_zh": "这篇论文探讨了生成式AI生成虚假信息（AI-Fabricated Disinformation）对市场研究的影响，强调这种内容能模仿真实用户生成内容（UGC），从而操纵公众意见并削弱对数字平台的信任。研究的主要贡献包括：展示AI高效制造虚假UGC的能力、量化其对市场分析框架的破坏性（即使是少量信息也可能造成重大影响），以及评估高级检测框架，发现标准技术无法有效过滤此类信息。最终，论文倡导采用综合策略，包括高级算法解决方案、增强人为监督以及重新审视监管和伦理框架，以保护市场研究并为未来政策制定提供基础。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14706v1",
      "published_date": "2024-03-17 13:08:28 UTC",
      "updated_date": "2024-03-17 13:08:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:22:30.462084"
    },
    {
      "arxiv_id": "2404.00017v1",
      "title": "Psittacines of Innovation? Assessing the True Novelty of AI Creations",
      "title_zh": "翻译失败",
      "authors": [
        "Anirban Mukherjee"
      ],
      "abstract": "We examine whether Artificial Intelligence (AI) systems generate truly novel\nideas rather than merely regurgitating patterns learned during training.\nUtilizing a novel experimental design, we task an AI with generating project\ntitles for hypothetical crowdfunding campaigns. We compare within AI-generated\nproject titles, measuring repetition and complexity. We compare between the\nAI-generated titles and actual observed field data using an extension of\nmaximum mean discrepancy--a metric derived from the application of kernel mean\nembeddings of statistical distributions to high-dimensional machine learning\n(large language) embedding vectors--yielding a structured analysis of AI output\nnovelty. Results suggest that (1) the AI generates unique content even under\nincreasing task complexity, and at the limits of its computational\ncapabilities, (2) the generated content has face validity, being consistent\nwith both inputs to other generative AI and in qualitative comparison to field\ndata, and (3) exhibits divergence from field data, mitigating concerns relating\nto intellectual property rights. We discuss implications for copyright and\ntrademark law.",
      "tldr_zh": "本研究评估了人工智能（AI）系统是否能生成真正新颖的想法，而非仅重复训练模式，通过设计实验让 AI 生成假设众筹项目标题，并使用 maximum mean discrepancy（基于 kernel mean embeddings 的指标）比较 AI 输出与实际领域数据的差异。结果显示，AI 在任务复杂性增加时仍能产生独特内容，具有面部效度（face validity），且与真实数据存在分歧，从而缓解了知识产权（intellectual property rights）担忧。论文讨论了这些发现对版权和商标法的潜在启示。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.00017v1",
      "published_date": "2024-03-17 13:08:11 UTC",
      "updated_date": "2024-03-17 13:08:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:22:44.090173"
    },
    {
      "arxiv_id": "2403.11204v2",
      "title": "Partitioned Neural Network Training via Synthetic Intermediate Labels",
      "title_zh": "翻译失败",
      "authors": [
        "Cevat Volkan Karadağ",
        "Nezih Topaloğlu"
      ],
      "abstract": "The proliferation of extensive neural network architectures, particularly\ndeep learning models, presents a challenge in terms of resource-intensive\ntraining. GPU memory constraints have become a notable bottleneck in training\nsuch sizable models. Existing strategies, including data parallelism, model\nparallelism, pipeline parallelism, and fully sharded data parallelism, offer\npartial solutions. Model parallelism, in particular, enables the distribution\nof the entire model across multiple GPUs, yet the ensuing data communication\nbetween these partitions slows down training. Additionally, the substantial\nmemory overhead required to store auxiliary parameters on each GPU compounds\ncomputational demands. Instead of using the entire model for training, this\nstudy advocates partitioning the model across GPUs and generating synthetic\nintermediate labels to train individual segments. These labels, produced\nthrough a random process, mitigate memory overhead and computational load. This\napproach results in a more efficient training process that minimizes data\ncommunication while maintaining model accuracy. To validate this method, a\n6-layer fully connected neural network is partitioned into two parts and its\nperformance is assessed on the extended MNIST dataset. Experimental results\nindicate that the proposed approach achieves similar testing accuracies to\nconventional training methods, while significantly reducing memory and\ncomputational requirements. This work contributes to mitigating the\nresource-intensive nature of training large neural networks, paving the way for\nmore efficient deep learning model development.",
      "tldr_zh": "这篇论文提出了一种名为“Partitioned Neural Network Training via Synthetic Intermediate Labels”的方法，以解决大型神经网络训练中 GPU 内存限制和资源密集问题。方法通过将模型分区到多个 GPU 上，并使用通过随机过程生成的 synthetic intermediate labels 来独立训练各部分，从而减少数据通信和内存开销，同时保持模型准确性。在实验中，该方法在扩展 MNIST 数据集上测试一个 6 层全连接神经网络，结果显示测试准确率与传统训练方法相当，但显著降低了计算和内存需求。该研究为高效开发大型神经网络提供了新途径，缓解了深度学习模型训练的资源瓶颈。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "68T01 (Primary) 68T07, 68T05 (Secondary)",
        "I.2.6; I.2.11"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.11204v2",
      "published_date": "2024-03-17 13:06:29 UTC",
      "updated_date": "2025-02-05 19:27:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:22:56.389357"
    },
    {
      "arxiv_id": "2403.11202v2",
      "title": "Data is all you need: Finetuning LLMs for Chip Design via an Automated design-data augmentation framework",
      "title_zh": "翻译失败",
      "authors": [
        "Kaiyan Chang",
        "Kun Wang",
        "Nan Yang",
        "Ying Wang",
        "Dantong Jin",
        "Wenlong Zhu",
        "Zhirong Chen",
        "Cangyuan Li",
        "Hao Yan",
        "Yunhao Zhou",
        "Zhuoliang Zhao",
        "Yuan Cheng",
        "Yudong Pan",
        "Yiqi Liu",
        "Mengdi Wang",
        "Shengwen Liang",
        "Yinhe Han",
        "Huawei Li",
        "Xiaowei Li"
      ],
      "abstract": "Recent advances in large language models have demonstrated their potential\nfor automated generation of hardware description language (HDL) code from\nhigh-level prompts. Researchers have utilized fine-tuning to enhance the\nability of these large language models (LLMs) in the field of Chip Design.\nHowever, the lack of Verilog data hinders further improvement in the quality of\nVerilog generation by LLMs. Additionally, the absence of a Verilog and\nElectronic Design Automation (EDA) script data augmentation framework\nsignificantly increases the time required to prepare the training dataset for\nLLM trainers. This paper proposes an automated design-data augmentation\nframework, which generates high-volume and high-quality natural language\naligned with Verilog and EDA scripts. For Verilog generation, it translates\nVerilog files to an abstract syntax tree and then maps nodes to natural\nlanguage with a predefined template. For Verilog repair, it uses predefined\nrules to generate the wrong verilog file and then pairs EDA Tool feedback with\nthe right and wrong verilog file. For EDA Script generation, it uses existing\nLLM(GPT-3.5) to obtain the description of the Script. To evaluate the\neffectiveness of our data augmentation method, we finetune Llama2-13B and\nLlama2-7B models using the dataset generated by our augmentation framework. The\nresults demonstrate a significant improvement in the Verilog generation tasks\nwith LLMs. Moreover, the accuracy of Verilog generation surpasses that of the\ncurrent state-of-the-art open-source Verilog generation model, increasing from\n58.8% to 70.6% with the same benchmark. Our 13B model (ChipGPT-FT) has a pass\nrate improvement compared with GPT-3.5 in Verilog generation and outperforms in\nEDA script (i.e., SiliconCompiler) generation with only 200 EDA script data.",
      "tldr_zh": "这篇论文提出了一种自动设计数据增强框架，用于微调大型语言模型（LLMs）以生成硬件描述语言（Verilog）和电子设计自动化（EDA）脚本，解决数据缺乏和数据集准备耗时问题。框架通过将 Verilog 文件转换为 abstract syntax tree（AST）并映射节点到自然语言模板、利用预定义规则生成错误 Verilog 文件并配对 EDA 工具反馈，以及使用 GPT-3.5 生成 EDA 脚本描述，来创建高质量的数据集。实验结果显示，微调后的 Llama2-13B 和 Llama2-7B 模型在 Verilog 生成任务上准确率从 58.8% 提高到 70.6%，并在 EDA 脚本生成上超越 GPT-3.5，仅需 200 条数据即实现显著性能提升。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.AR",
      "comment": "DAC 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.11202v2",
      "published_date": "2024-03-17 13:01:03 UTC",
      "updated_date": "2024-07-10 09:06:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:23:11.016927"
    },
    {
      "arxiv_id": "2403.11199v1",
      "title": "Graph Unitary Message Passing",
      "title_zh": "翻译失败",
      "authors": [
        "Haiquan Qiu",
        "Yatao Bian",
        "Quanming Yao"
      ],
      "abstract": "Message passing mechanism contributes to the success of GNNs in various\napplications, but also brings the oversquashing problem. Recent works combat\noversquashing by improving the graph spectrums with rewiring techniques,\ndisrupting the structural bias in graphs, and having limited improvement on\noversquashing in terms of oversquashing measure. Motivated by unitary RNN, we\npropose Graph Unitary Message Passing (GUMP) to alleviate oversquashing in GNNs\nby applying unitary adjacency matrix for message passing. To design GUMP, a\ntransformation is first proposed to make general graphs have unitary adjacency\nmatrix and keep its structural bias. Then, unitary adjacency matrix is obtained\nwith a unitary projection algorithm, which is implemented by utilizing the\nintrinsic structure of unitary adjacency matrix and allows GUMP to be\npermutation-equivariant. Experimental results show the effectiveness of GUMP in\nimproving the performance on various graph learning tasks.",
      "tldr_zh": "这篇论文针对图神经网络（GNNs）中的 oversquashing 问题，提出了一种新的消息传递机制 Graph Unitary Message Passing (GUMP)，受 unitary RNN 启发，以通过 unitary adjacency matrix 缓解该问题。GUMP 的设计首先对图进行转换，使其保持结构偏差的同时获得 unitary adjacency matrix，然后利用 unitary projection 算法实现消息传递，确保模型具有 permutation-equivariant 属性。实验结果显示，GUMP 在多种图学习任务上显著提升了性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.11199v1",
      "published_date": "2024-03-17 12:55:23 UTC",
      "updated_date": "2024-03-17 12:55:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:23:21.264650"
    },
    {
      "arxiv_id": "2403.14705v1",
      "title": "Concept-Best-Matching: Evaluating Compositionality in Emergent Communication",
      "title_zh": "翻译失败",
      "authors": [
        "Boaz Carmeli",
        "Yonatan Belinkov",
        "Ron Meir"
      ],
      "abstract": "Artificial agents that learn to communicate in order to accomplish a given\ntask acquire communication protocols that are typically opaque to a human. A\nlarge body of work has attempted to evaluate the emergent communication via\nvarious evaluation measures, with \\emph{compositionality} featuring as a\nprominent desired trait. However, current evaluation procedures do not directly\nexpose the compositionality of the emergent communication. We propose a\nprocedure to assess the compositionality of emergent communication by finding\nthe best-match between emerged words and natural language concepts. The\nbest-match algorithm provides both a global score and a translation-map from\nemergent words to natural language concepts. To the best of our knowledge, it\nis the first time that such direct and interpretable mapping between emergent\nwords and human concepts is provided.",
      "tldr_zh": "该论文探讨了在紧急通信（emergent communication）中评估组合性（compositionality）的挑战，现有方法无法直接揭示通信协议的透明度。研究提出了一种名为 Concept-Best-Matching 的新程序，通过最佳匹配算法来寻找紧急词汇与自然语言概念的最佳对应。算法不仅提供一个全局分数，还生成从紧急词汇到自然语言概念的翻译映射，这是首次实现这种直接且可解释的映射。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14705v1",
      "published_date": "2024-03-17 12:47:02 UTC",
      "updated_date": "2024-03-17 12:47:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:23:32.392129"
    },
    {
      "arxiv_id": "2403.15442v3",
      "title": "Artificial Intelligence for Cochlear Implants: Review of Strategies, Challenges, and Perspectives",
      "title_zh": "人工智能在人工耳蜗中的应用：策略、挑战和展望的综述",
      "authors": [
        "Billel Essaid",
        "Hamza Kheddar",
        "Noureddine Batel",
        "Muhammad E. H. Chowdhury",
        "Abderrahmane Lakas"
      ],
      "abstract": "Automatic speech recognition (ASR) plays a pivotal role in our daily lives,\noffering utility not only for interacting with machines but also for\nfacilitating communication for individuals with partial or profound hearing\nimpairments. The process involves receiving the speech signal in analog form,\nfollowed by various signal processing algorithms to make it compatible with\ndevices of limited capacities, such as cochlear implants (CIs). Unfortunately,\nthese implants, equipped with a finite number of electrodes, often result in\nspeech distortion during synthesis. Despite efforts by researchers to enhance\nreceived speech quality using various state-of-the-art (SOTA) signal processing\ntechniques, challenges persist, especially in scenarios involving multiple\nsources of speech, environmental noise, and other adverse conditions. The\nadvent of new artificial intelligence (AI) methods has ushered in cutting-edge\nstrategies to address the limitations and difficulties associated with\ntraditional signal processing techniques dedicated to CIs. This review aims to\ncomprehensively cover advancements in CI-based ASR and speech enhancement,\namong other related aspects. The primary objective is to provide a thorough\noverview of metrics and datasets, exploring the capabilities of AI algorithms\nin this biomedical field, and summarizing and commenting on the best results\nobtained. Additionally, the review will delve into potential applications and\nsuggest future directions to bridge existing research gaps in this domain.",
      "tldr_zh": "本综述探讨了人工智能（AI）在人工耳蜗植入物（Cochlear Implants, CIs）中的应用，重点审阅了Automatic Speech Recognition (ASR) 和语音增强策略，以及面临的挑战，如语音失真和噪声环境。论文总结了State-of-the-Art (SOTA) 信号处理技术和AI算法的进展，包括关键指标、数据集和最佳成果，以提升CIs的性能。最终，它指出了潜在应用领域并提出未来方向，以填补现有研究空白并改善听力障碍者的沟通体验。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CV",
        "eess.IV"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.15442v3",
      "published_date": "2024-03-17 11:28:23 UTC",
      "updated_date": "2025-01-12 22:16:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:23:44.814217"
    },
    {
      "arxiv_id": "2403.11175v1",
      "title": "Prior-dependent analysis of posterior sampling reinforcement learning with function approximation",
      "title_zh": "翻译失败",
      "authors": [
        "Yingru Li",
        "Zhi-Quan Luo"
      ],
      "abstract": "This work advances randomized exploration in reinforcement learning (RL) with\nfunction approximation modeled by linear mixture MDPs. We establish the first\nprior-dependent Bayesian regret bound for RL with function approximation; and\nrefine the Bayesian regret analysis for posterior sampling reinforcement\nlearning (PSRL), presenting an upper bound of ${\\mathcal{O}}(d\\sqrt{H^3 T \\log\nT})$, where $d$ represents the dimensionality of the transition kernel, $H$ the\nplanning horizon, and $T$ the total number of interactions. This signifies a\nmethodological enhancement by optimizing the $\\mathcal{O}(\\sqrt{\\log T})$\nfactor over the previous benchmark (Osband and Van Roy, 2014) specified to\nlinear mixture MDPs. Our approach, leveraging a value-targeted model learning\nperspective, introduces a decoupling argument and a variance reduction\ntechnique, moving beyond traditional analyses reliant on confidence sets and\nconcentration inequalities to formalize Bayesian regret bounds more\neffectively.",
      "tldr_zh": "本研究针对函数逼近的强化学习（RL），在线性混合MDPs模型下，首次建立了依赖于先验的Bayesian regret bound，并优化了后验采样强化学习（PSRL）的分析，提供了一个上界\\(\\mathcal{O}(d\\sqrt{H^3 T \\log T})\\)，其中d为过渡核的维度、H为规划地平线、T为总互动次数。相比之前的基准（Osband and Van Roy, 2014），这一上界在\\(\\mathcal{O}(\\sqrt{\\log T})\\)因子上实现了改进。研究引入了价值导向模型学习视角、解耦参数和方差减少技术，超越了传统依赖置信集和集中不等式的分析方法，从而更有效地形式化Bayesian regret bound。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.IT",
        "cs.LG",
        "math.IT",
        "math.ST",
        "stat.TH"
      ],
      "primary_category": "stat.ML",
      "comment": "Published in the 27th International Conference on Artificial\n  Intelligence and Statistics (AISTATS)",
      "pdf_url": "http://arxiv.org/pdf/2403.11175v1",
      "published_date": "2024-03-17 11:23:51 UTC",
      "updated_date": "2024-03-17 11:23:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:23:57.822964"
    },
    {
      "arxiv_id": "2403.11169v4",
      "title": "Correcting misinformation on social media with a large language model",
      "title_zh": "使用大型语言模型纠正社交媒体上的错误信息",
      "authors": [
        "Xinyi Zhou",
        "Ashish Sharma",
        "Amy X. Zhang",
        "Tim Althoff"
      ],
      "abstract": "Real-world misinformation, often multimodal, can be partially or fully\nfactual but misleading using diverse tactics like conflating correlation with\ncausation. Such misinformation is severely understudied, challenging to\naddress, and harms various social domains, particularly on social media, where\nit can spread rapidly. High-quality and timely correction of misinformation\nthat identifies and explains its (in)accuracies effectively reduces false\nbeliefs. Despite the wide acceptance of manual correction, it is difficult to\nbe timely and scalable. While LLMs have versatile capabilities that could\naccelerate misinformation correction, they struggle due to a lack of recent\ninformation, a tendency to produce false content, and limitations in addressing\nmultimodal information. We propose MUSE, an LLM augmented with access to and\ncredibility evaluation of up-to-date information. By retrieving evidence as\nrefutations or supporting context, MUSE identifies and explains content\n(in)accuracies with references. It conducts multimodal retrieval and interprets\nvisual content to verify and correct multimodal content. Given the absence of a\ncomprehensive evaluation approach, we propose 13 dimensions of misinformation\ncorrection quality. Then, fact-checking experts evaluate responses to social\nmedia content that are not presupposed to be misinformation but broadly include\n(partially) incorrect and correct posts that may (not) be misleading. Results\ndemonstrate MUSE's ability to write high-quality responses to potential\nmisinformation--across modalities, tactics, domains, political leanings, and\nfor information that has not previously been fact-checked online--within\nminutes of its appearance on social media. Overall, MUSE outperforms GPT-4 by\n37% and even high-quality responses from laypeople by 29%. Our work provides a\ngeneral methodological and evaluative framework to correct misinformation at\nscale.",
      "tldr_zh": "该研究针对社交媒体上的多模态错误信息（multimodal misinformation），提出了一种增强型大型语言模型（LLM）框架MUSE，以解决传统手动纠正的及时性和可扩展性问题。MUSE通过检索最新证据、评估其可信度，并处理多模态内容（如文本和图像），来识别和解释信息的准确性或不准确性。研究引入了13个维度的错误信息纠正质量评估，并通过专家评估发现，MUSE在各种情境下（如不同策略、领域和政治倾向）生成的高质量响应，优于GPT-4（提高37%）和普通人响应（提高29%）。整体而言，该工作提供了一个可扩展的框架，能够在错误信息出现后几分钟内进行有效纠正。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "50 pages",
      "pdf_url": "http://arxiv.org/pdf/2403.11169v4",
      "published_date": "2024-03-17 10:59:09 UTC",
      "updated_date": "2024-09-03 05:51:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:24:09.652916"
    },
    {
      "arxiv_id": "2403.11162v1",
      "title": "CGI-DM: Digital Copyright Authentication for Diffusion Models via Contrasting Gradient Inversion",
      "title_zh": "CGI-DM：通过对比梯度反演的扩散模型数字版权认证",
      "authors": [
        "Xiaoyu Wu",
        "Yang Hua",
        "Chumeng Liang",
        "Jiaru Zhang",
        "Hao Wang",
        "Tao Song",
        "Haibing Guan"
      ],
      "abstract": "Diffusion Models (DMs) have evolved into advanced image generation tools,\nespecially for few-shot generation where a pretrained model is fine-tuned on a\nsmall set of images to capture a specific style or object. Despite their\nsuccess, concerns exist about potential copyright violations stemming from the\nuse of unauthorized data in this process. In response, we present Contrasting\nGradient Inversion for Diffusion Models (CGI-DM), a novel method featuring\nvivid visual representations for digital copyright authentication. Our approach\ninvolves removing partial information of an image and recovering missing\ndetails by exploiting conceptual differences between the pretrained and\nfine-tuned models. We formulate the differences as KL divergence between latent\nvariables of the two models when given the same input image, which can be\nmaximized through Monte Carlo sampling and Projected Gradient Descent (PGD).\nThe similarity between original and recovered images serves as a strong\nindicator of potential infringements. Extensive experiments on the WikiArt and\nDreambooth datasets demonstrate the high accuracy of CGI-DM in digital\ncopyright authentication, surpassing alternative validation techniques. Code\nimplementation is available at https://github.com/Nicholas0228/Revelio.",
      "tldr_zh": "该研究针对扩散模型(DMs)在少样本图像生成中可能引发的版权侵犯问题，提出了一种新型数字版权认证方法CGI-DM（Contrasting Gradient Inversion for Diffusion Models）。该方法通过移除图像部分信息，并利用预训练模型和微调模型之间的概念差异（如KL divergence）来恢复缺失细节，具体通过Monte Carlo sampling和Projected Gradient Descent (PGD)最大化差异，以评估原始图像和恢复图像的相似度作为侵权指标。在WikiArt和Dreambooth数据集上的实验显示，CGI-DM的认证准确率超过了其他验证技术，为扩散模型的版权保护提供了高效工具。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.11162v1",
      "published_date": "2024-03-17 10:06:38 UTC",
      "updated_date": "2024-03-17 10:06:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:24:21.683696"
    },
    {
      "arxiv_id": "2403.14704v2",
      "title": "A minimal coalition logic",
      "title_zh": "翻译失败",
      "authors": [
        "Yinfeng Li",
        "Fengkui Ju"
      ],
      "abstract": "Coalition Logic is a central logic in logical studies of strategic reasoning,\nwhose models are concurrent game models. In this paper, first, we\nsystematically discuss three assumptions of concurrent game models and argue\nthat they are too strong. The first is seriality; that is, every coalition\nalways has an available joint action. The second is the independence of agents;\nthat is, the merge of two available joint actions of two disjoint coalitions is\nalways an available joint action of the union of the two coalitions. The third\nis determinism; that is, all available joint actions of the grand coalition\nalways have a unique outcome. Second, we present a coalition logic based on\ngeneral concurrent game models which do not have the three assumptions and show\nits completeness. This logic seems minimal for reasoning about coalitional\npowers.",
      "tldr_zh": "论文讨论了 Coalition Logic 在 concurrent game models 中的三个过强假设：seriality（每个联盟总有可用的联合行动）、independence of agents（不相交联盟的联合行动合并总是可用的）和 determinism（大联盟的联合行动总有唯一结果），并认为这些假设限制了其适用性。作者提出了一种基于 general concurrent game models 的新 Coalition Logic，该模型不依赖这些假设，并证明了其完整性。该逻辑被视为关于 coalitional powers 推理的最小框架，为战略推理研究提供了更灵活的基础。",
      "categories": [
        "cs.LO",
        "cs.AI"
      ],
      "primary_category": "cs.LO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14704v2",
      "published_date": "2024-03-17 09:33:37 UTC",
      "updated_date": "2025-01-13 04:47:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:24:32.762044"
    },
    {
      "arxiv_id": "2403.11152v1",
      "title": "Evaluation Ethics of LLMs in Legal Domain",
      "title_zh": "翻译失败",
      "authors": [
        "Ruizhe Zhang",
        "Haitao Li",
        "Yueyue Wu",
        "Qingyao Ai",
        "Yiqun Liu",
        "Min Zhang",
        "Shaoping Ma"
      ],
      "abstract": "In recent years, the utilization of large language models for natural\nlanguage dialogue has gained momentum, leading to their widespread adoption\nacross various domains. However, their universal competence in addressing\nchallenges specific to specialized fields such as law remains a subject of\nscrutiny. The incorporation of legal ethics into the model has been overlooked\nby researchers. We asserts that rigorous ethic evaluation is essential to\nensure the effective integration of large language models in legal domains,\nemphasizing the need to assess domain-specific proficiency and domain-specific\nethic. To address this, we propose a novelty evaluation methodology, utilizing\nauthentic legal cases to evaluate the fundamental language abilities,\nspecialized legal knowledge and legal robustness of large language models\n(LLMs). The findings from our comprehensive evaluation contribute significantly\nto the academic discourse surrounding the suitability and performance of large\nlanguage models in legal domains.",
      "tldr_zh": "近年来，大型语言模型（LLMs）在法律领域的应用日益增多，但其领域特定能力和伦理评估（如legal ethics）尚未得到充分关注。论文提出了一种新颖的评估方法，利用真实法律案例来评估LLMs的基本语言能力、专业法律知识以及legal robustness。研究结果为LLMs在法律领域的适用性和性能提供了重要见解，推动了相关学术讨论。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, in processing of ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.11152v1",
      "published_date": "2024-03-17 09:05:13 UTC",
      "updated_date": "2024-03-17 09:05:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:24:43.892044"
    },
    {
      "arxiv_id": "2403.12100v1",
      "title": "Learning Time Slot Preferences via Mobility Tree for Next POI Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Tianhao Huang",
        "Xuan Pan",
        "Xiangrui Cai",
        "Ying Zhang",
        "Xiaojie Yuan"
      ],
      "abstract": "Next Point-of-Interests (POIs) recommendation task aims to provide a dynamic\nranking of POIs based on users' current check-in trajectories. The\nrecommendation performance of this task is contingent upon a comprehensive\nunderstanding of users' personalized behavioral patterns through Location-based\nSocial Networks (LBSNs) data. While prior studies have adeptly captured\nsequential patterns and transitional relationships within users' check-in\ntrajectories, a noticeable gap persists in devising a mechanism for discerning\nspecialized behavioral patterns during distinct time slots, such as noon,\nafternoon, or evening. In this paper, we introduce an innovative data structure\ntermed the ``Mobility Tree'', tailored for hierarchically describing users'\ncheck-in records. The Mobility Tree encompasses multi-granularity time slot\nnodes to learn user preferences across varying temporal periods. Meanwhile, we\npropose the Mobility Tree Network (MTNet), a multitask framework for\npersonalized preference learning based on Mobility Trees. We develop a\nfour-step node interaction operation to propagate feature information from the\nleaf nodes to the root node. Additionally, we adopt a multitask training\nstrategy to push the model towards learning a robust representation. The\ncomprehensive experimental results demonstrate the superiority of MTNet over\nten state-of-the-art next POI recommendation models across three real-world\nLBSN datasets, substantiating the efficacy of time slot preference learning\nfacilitated by Mobility Tree.",
      "tldr_zh": "本论文针对Next POI Recommendation任务，提出了一种通过Mobility Tree学习用户时间槽偏好的方法，以更好地捕捉用户在不同时间段（如中午、下午或晚上）的个性化行为模式。研究引入Mobility Tree作为一种层次化数据结构，用于描述用户的签到记录，并通过多粒度时间槽节点学习跨时间期的偏好。基于此，他们开发了Mobility Tree Network (MTNet)，一个多任务框架，包含四步节点交互操作和多任务训练策略，以传播特征信息并生成鲁棒的表示。实验结果显示，MTNet在三个真实LBSNs数据集上优于十个最先进模型，验证了时间槽偏好学习的有效性。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.12100v1",
      "published_date": "2024-03-17 08:43:12 UTC",
      "updated_date": "2024-03-17 08:43:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:24:57.777204"
    },
    {
      "arxiv_id": "2403.15441v1",
      "title": "Unified Generative Modeling of 3D Molecules via Bayesian Flow Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxuan Song",
        "Jingjing Gong",
        "Yanru Qu",
        "Hao Zhou",
        "Mingyue Zheng",
        "Jingjing Liu",
        "Wei-Ying Ma"
      ],
      "abstract": "Advanced generative model (e.g., diffusion model) derived from simplified\ncontinuity assumptions of data distribution, though showing promising progress,\nhas been difficult to apply directly to geometry generation applications due to\nthe multi-modality and noise-sensitive nature of molecule geometry. This work\nintroduces Geometric Bayesian Flow Networks (GeoBFN), which naturally fits\nmolecule geometry by modeling diverse modalities in the differentiable\nparameter space of distributions. GeoBFN maintains the SE-(3) invariant density\nmodeling property by incorporating equivariant inter-dependency modeling on\nparameters of distributions and unifying the probabilistic modeling of\ndifferent modalities. Through optimized training and sampling techniques, we\ndemonstrate that GeoBFN achieves state-of-the-art performance on multiple 3D\nmolecule generation benchmarks in terms of generation quality (90.87% molecule\nstability in QM9 and 85.6% atom stability in GEOM-DRUG. GeoBFN can also conduct\nsampling with any number of steps to reach an optimal trade-off between\nefficiency and quality (e.g., 20-times speedup without sacrificing\nperformance).",
      "tldr_zh": "本研究提出 Geometric Bayesian Flow Networks (GeoBFN)，一种统一框架，用于3D分子生成，通过在可微参数空间中建模多样模态，解决了现有生成模型（如diffusion model）在多模态和噪声敏感分子几何中的应用难题。GeoBFN 通过整合等变互依赖建模和SE-(3)不变密度建模，统一了不同模态的概率建模，并优化了训练和采样技术。在多个基准测试中，GeoBFN 实现了最先进性能，包括QM9数据集的90.87%分子稳定性和GEOM-DRUG数据集的85.6%原子稳定性。此外，该框架允许灵活调整采样步骤，实现效率与质量的平衡，例如20倍加速而不牺牲性能。",
      "categories": [
        "physics.chem-ph",
        "cs.AI",
        "cs.LG",
        "q-bio.BM"
      ],
      "primary_category": "physics.chem-ph",
      "comment": "ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.15441v1",
      "published_date": "2024-03-17 08:40:06 UTC",
      "updated_date": "2024-03-17 08:40:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:25:09.762922"
    },
    {
      "arxiv_id": "2403.11124v2",
      "title": "Scaling Data Diversity for Fine-Tuning Language Models in Human Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Feifan Song",
        "Bowen Yu",
        "Hao Lang",
        "Haiyang Yu",
        "Fei Huang",
        "Houfeng Wang",
        "Yongbin Li"
      ],
      "abstract": "Alignment with human preference prevents large language models (LLMs) from\ngenerating misleading or toxic content while requiring high-cost human\nfeedback. Assuming resources of human annotation are limited, there are two\ndifferent ways of allocating considered: more diverse PROMPTS or more diverse\nRESPONSES to be labeled. Nonetheless, a straightforward comparison between\ntheir impact is absent. In this work, we first control the diversity of both\nsides according to the number of samples for fine-tuning, which can directly\nreflect their influence. We find that instead of numerous prompts, more\nresponses but fewer prompts better trigger LLMs for human alignment.\nAdditionally, the concept of diversity for prompts can be more complex than\nresponses that are typically quantified by single digits. Consequently, a new\nformulation of prompt diversity is proposed, further implying a linear\ncorrelation with the final performance of LLMs after fine-tuning. We also\nleverage it on data augmentation and conduct experiments to show its effect on\ndifferent algorithms.",
      "tldr_zh": "这篇论文探讨了在资源有限的情况下，如何通过调整数据多样性来优化大型语言模型(LLMs)的微调，以实现人类偏好对齐，从而减少生成误导性或有毒内容。研究比较了两种策略：增加提示(PROMPTS)的多样性与增加响应(RESPONSES)的多样性，发现使用更多样化的响应但较少的提示更能有效提升LLMs的性能。论文进一步提出了一种新的提示多样性公式，证明其与微调后性能呈线性相关，并通过数据增强实验验证了其在不同算法中的效果。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by LREC-COLING 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.11124v2",
      "published_date": "2024-03-17 07:08:55 UTC",
      "updated_date": "2024-03-30 16:48:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:25:22.145414"
    },
    {
      "arxiv_id": "2403.11116v4",
      "title": "PhD: A ChatGPT-Prompted Visual hallucination Evaluation Dataset",
      "title_zh": "PhD：基于 ChatGPT 提示的视觉幻觉评估数据集",
      "authors": [
        "Jiazhen Liu",
        "Yuhan Fu",
        "Ruobing Xie",
        "Runquan Xie",
        "Xingwu Sun",
        "Fengzong Lian",
        "Zhanhui Kang",
        "Xirong Li"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) hallucinate, resulting in an\nemerging topic of visual hallucination evaluation (VHE). This paper contributes\na ChatGPT-Prompted visual hallucination evaluation Dataset (PhD) for objective\nVHE at a large scale. The essence of VHE is to ask an MLLM questions about\nspecific images to assess its susceptibility to hallucination. Depending on\nwhat to ask (objects, attributes, sentiment, etc.) and how the questions are\nasked, we structure PhD along two dimensions, i.e. task and mode. Five visual\nrecognition tasks, ranging from low-level (object / attribute recognition) to\nmiddle-level (sentiment / position recognition and counting), are considered.\nBesides a normal visual QA mode, which we term PhD-base, PhD also asks\nquestions with specious context (PhD-sec) or with incorrect context ({PhD-icc),\nor with AI-generated counter common sense images (PhD-ccs). We construct PhD by\na ChatGPT-assisted semi-automated pipeline, encompassing four pivotal modules:\ntask-specific hallucinatory item (hitem) selection, hitem-embedded question\ngeneration, specious / incorrect context generation, and counter-common-sense\n(CCS) image generation. With over 14k daily images, 750 CCS images and 102k VQA\ntriplets in total, PhD reveals considerable variability in MLLMs' performance\nacross various modes and tasks, offering valuable insights into the nature of\nhallucination. As such, PhD stands as a potent tool not only for VHE but may\nalso play a significant role in the refinement of MLLMs.",
      "tldr_zh": "该论文提出PhD数据集，这是一个ChatGPT辅助的视觉幻觉评估(visual hallucination evaluation, VHE)工具，用于大规模客观评估Multimodal Large Language Models (MLLMs)的幻觉易感性。数据集沿任务和模式两个维度结构化，包括五种视觉识别任务（如对象/属性识别、情感/位置识别和计数），以及多种模式（PhD-base正常QA、PhD-sec虚假上下文、PhD-icc不正确上下文和PhD-ccs反常识图像）。通过ChatGPT辅助的半自动化管道，论文构建了超过14k日常图像、750反常识图像和102k VQA三元组。实验结果显示，MLLMs在不同模式和任务中的性能存在显著差异，为VHE和MLLMs的优化提供了宝贵洞见。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR 2025, Highlight",
      "pdf_url": "http://arxiv.org/pdf/2403.11116v4",
      "published_date": "2024-03-17 06:53:44 UTC",
      "updated_date": "2025-04-14 12:11:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:25:34.672571"
    },
    {
      "arxiv_id": "2403.11114v1",
      "title": "Phasic Diversity Optimization for Population-Based Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jingcheng Jiang",
        "Haiyin Piao",
        "Yu Fu",
        "Yihang Hao",
        "Chuanlu Jiang",
        "Ziqi Wei",
        "Xin Yang"
      ],
      "abstract": "Reviewing the previous work of diversity Rein-forcement Learning,diversity is\noften obtained via an augmented loss function,which requires a balance between\nreward and diversity.Generally,diversity optimization algorithms use\nMulti-armed Bandits algorithms to select the coefficient in the pre-defined\nspace. However, the dynamic distribution of reward signals for MABs or the\nconflict between quality and diversity limits the performance of these methods.\nWe introduce the Phasic Diversity Optimization (PDO) algorithm, a\nPopulation-Based Training framework that separates reward and diversity\ntraining into distinct phases instead of optimizing a multi-objective function.\nIn the auxiliary phase, agents with poor performance diversified via\ndeterminants will not replace the better agents in the archive. The decoupling\nof reward and diversity allows us to use an aggressive diversity optimization\nin the auxiliary phase without performance degradation. Furthermore, we\nconstruct a dogfight scenario for aerial agents to demonstrate the practicality\nof the PDO algorithm. We introduce two implementations of PDO archive and\nconduct tests in the newly proposed adversarial dogfight and MuJoCo\nsimulations. The results show that our proposed algorithm achieves better\nperformance than baselines.",
      "tldr_zh": "该论文针对基于种群的强化学习（Reinforcement Learning）中的多样性优化问题，指出现有方法依赖增强损失函数和Multi-armed Bandits算法，但容易因奖励信号动态分布或质量与多样性冲突而性能受限。论文提出Phasic Diversity Optimization (PDO)算法，这是一种Population-Based Training框架，将奖励和多样性训练分离为不同阶段，在辅助阶段通过决定因素多样化性能较差的代理，同时确保不替换存档中的更好代理，从而实现积极的多样性优化而不降低整体性能。实验在新建的对抗空战（dogfight）场景和MuJoCo模拟中验证了两种PDO实现，结果显示PDO算法比基线方法取得了更好的表现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "14J60 (Primary)",
        "I.2.9"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.11114v1",
      "published_date": "2024-03-17 06:41:09 UTC",
      "updated_date": "2024-03-17 06:41:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:25:46.267808"
    },
    {
      "arxiv_id": "2403.11106v1",
      "title": "Self-Supervised Quantization-Aware Knowledge Distillation",
      "title_zh": "自监督量化感知知识蒸",
      "authors": [
        "Kaiqi Zhao",
        "Ming Zhao"
      ],
      "abstract": "Quantization-aware training (QAT) and Knowledge Distillation (KD) are\ncombined to achieve competitive performance in creating low-bit deep learning\nmodels. However, existing works applying KD to QAT require tedious\nhyper-parameter tuning to balance the weights of different loss terms, assume\nthe availability of labeled training data, and require complex, computationally\nintensive training procedures for good performance. To address these\nlimitations, this paper proposes a novel Self-Supervised Quantization-Aware\nKnowledge Distillation (SQAKD) framework. SQAKD first unifies the forward and\nbackward dynamics of various quantization functions, making it flexible for\nincorporating various QAT works. Then it formulates QAT as a co-optimization\nproblem that simultaneously minimizes the KL-Loss between the full-precision\nand low-bit models for KD and the discretization error for quantization,\nwithout supervision from labels. A comprehensive evaluation shows that SQAKD\nsubstantially outperforms the state-of-the-art QAT and KD works for a variety\nof model architectures. Our code is at: https://github.com/kaiqi123/SQAKD.git.",
      "tldr_zh": "本文提出了一种名为 SQAKD 的自监督量化感知知识蒸馏(Self-Supervised Quantization-Aware Knowledge Distillation)框架，以解决现有 QAT (Quantization-aware Training) 和 KD (Knowledge Distillation) 方法在超参数调整、依赖标签数据以及训练复杂性上的局限性。SQAKD 统一了各种量化函数的前向和后向动态，将 QAT 表述为一个无监督的共同优化问题，即同时最小化全精度模型与低位模型之间的 KL-Loss 以及量化误差，从而简化了训练过程。实验结果显示，SQAKD 在多种模型架构上显著优于现有 QAT 和 KD 方法，提供更高的性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.11106v1",
      "published_date": "2024-03-17 06:20:28 UTC",
      "updated_date": "2024-03-17 06:20:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:25:56.939953"
    },
    {
      "arxiv_id": "2403.11092v1",
      "title": "Lost in Translation? Translation Errors and Challenges for Fair Assessment of Text-to-Image Models on Multilingual Concepts",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Saxon",
        "Yiran Luo",
        "Sharon Levy",
        "Chitta Baral",
        "Yezhou Yang",
        "William Yang Wang"
      ],
      "abstract": "Benchmarks of the multilingual capabilities of text-to-image (T2I) models\ncompare generated images prompted in a test language to an expected image\ndistribution over a concept set. One such benchmark, \"Conceptual Coverage\nAcross Languages\" (CoCo-CroLa), assesses the tangible noun inventory of T2I\nmodels by prompting them to generate pictures from a concept list translated to\nseven languages and comparing the output image populations. Unfortunately, we\nfind that this benchmark contains translation errors of varying severity in\nSpanish, Japanese, and Chinese. We provide corrections for these errors and\nanalyze how impactful they are on the utility and validity of CoCo-CroLa as a\nbenchmark. We reassess multiple baseline T2I models with the revisions, compare\nthe outputs elicited under the new translations to those conditioned on the\nold, and show that a correction's impactfulness on the image-domain benchmark\nresults can be predicted in the text domain with similarity scores. Our\nfindings will guide the future development of T2I multilinguality metrics by\nproviding analytical tools for practical translation decisions.",
      "tldr_zh": "这篇论文探讨了评估文本到图像(T2I)模型多语言能力时，基准测试（如CoCo-CroLa）中翻译错误的潜在问题，这些错误会影响对多语言概念的公平评估。作者识别并修正了CoCo-CroLa中西班牙语、日语和中文的翻译错误，并重新评估了多个基线T2I模型的输出。研究发现，这些修正通过文本域的相似性分数可以预测对图像域结果的影响，从而提升基准的有效性。最终，该工作为T2I模型多语言度量的发展提供了分析工具和实用指导。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.CY",
        "eess.IV"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL 2024 Main Conference",
      "pdf_url": "http://arxiv.org/pdf/2403.11092v1",
      "published_date": "2024-03-17 05:05:11 UTC",
      "updated_date": "2024-03-17 05:05:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:26:09.470115"
    },
    {
      "arxiv_id": "2403.11082v1",
      "title": "RobustSentEmbed: Robust Sentence Embeddings Using Adversarial Self-Supervised Contrastive Learning",
      "title_zh": "RobustSentEmbed：使用对抗自监督对比学习的鲁棒句子嵌入",
      "authors": [
        "Javad Rafiei Asl",
        "Prajwal Panzade",
        "Eduardo Blanco",
        "Daniel Takabi",
        "Zhipeng Cai"
      ],
      "abstract": "Pre-trained language models (PLMs) have consistently demonstrated outstanding\nperformance across a diverse spectrum of natural language processing tasks.\nNevertheless, despite their success with unseen data, current PLM-based\nrepresentations often exhibit poor robustness in adversarial settings. In this\npaper, we introduce RobustSentEmbed, a self-supervised sentence embedding\nframework designed to improve both generalization and robustness in diverse\ntext representation tasks and against a diverse set of adversarial attacks.\nThrough the generation of high-risk adversarial perturbations and their\nutilization in a novel objective function, RobustSentEmbed adeptly learns\nhigh-quality and robust sentence embeddings. Our experiments confirm the\nsuperiority of RobustSentEmbed over state-of-the-art representations.\nSpecifically, Our framework achieves a significant reduction in the success\nrate of various adversarial attacks, notably reducing the BERTAttack success\nrate by almost half (from 75.51\\% to 38.81\\%). The framework also yields\nimprovements of 1.59\\% and 0.23\\% in semantic textual similarity tasks and\nvarious transfer tasks, respectively.",
      "tldr_zh": "这篇论文提出了 RobustSentEmbed，一种基于对抗自监督对比学习(Adversarial Self-Supervised Contrastive Learning)的句子嵌入框架，旨在提升预训练语言模型(PLMs)在各种文本表示任务中的泛化和鲁棒性。该框架通过生成高风险对抗扰动并融入新颖的目标函数，学习高质量的鲁棒句子嵌入。实验结果显示，RobustSentEmbed 显著降低了对抗攻击成功率，例如将 BERTAttack 的成功率从 75.51% 降至 38.81%，并在语义文本相似任务中提高了 1.59%，在转移任务中提高了 0.23%。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at the Annual Conference of the North American Chapter of\n  the Association for Computational Linguistics (NAACL Findings) 2024.\n  [https://openreview.net/forum?id=9dEAg4lJEA]",
      "pdf_url": "http://arxiv.org/pdf/2403.11082v1",
      "published_date": "2024-03-17 04:29:45 UTC",
      "updated_date": "2024-03-17 04:29:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:26:21.730836"
    },
    {
      "arxiv_id": "2403.11075v2",
      "title": "GOMA: Proactive Embodied Cooperative Communication via Goal-Oriented Mental Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Lance Ying",
        "Kunal Jha",
        "Shivam Aarya",
        "Joshua B. Tenenbaum",
        "Antonio Torralba",
        "Tianmin Shu"
      ],
      "abstract": "Verbal communication plays a crucial role in human cooperation, particularly\nwhen the partners only have incomplete information about the task, environment,\nand each other's mental state. In this paper, we propose a novel cooperative\ncommunication framework, Goal-Oriented Mental Alignment (GOMA). GOMA formulates\nverbal communication as a planning problem that minimizes the misalignment\nbetween the parts of agents' mental states that are relevant to the goals. This\napproach enables an embodied assistant to reason about when and how to\nproactively initialize communication with humans verbally using natural\nlanguage to help achieve better cooperation. We evaluate our approach against\nstrong baselines in two challenging environments, Overcooked (a multiplayer\ngame) and VirtualHome (a household simulator). Our experimental results\ndemonstrate that large language models struggle with generating meaningful\ncommunication that is grounded in the social and physical context. In contrast,\nour approach can successfully generate concise verbal communication for the\nembodied assistant to effectively boost the performance of the cooperation as\nwell as human users' perception of the assistant.",
      "tldr_zh": "本论文提出了一种新型合作通信框架——Goal-Oriented Mental Alignment (GOMA)，旨在通过最小化代理之间与目标相关的心理状态失调来优化口头沟通。GOMA 将通信表述为一个规划问题，使具身助手能够主动使用自然语言初始化对话，从而提升合作效率。实验在 Overcooked（多人游戏）和 VirtualHome（家庭模拟器）环境中进行，结果显示，GOMA 生成的简洁沟通显著优于大语言模型基准，提高了合作性能和用户对助手的感知。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.HC",
      "comment": "8 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.11075v2",
      "published_date": "2024-03-17 03:52:52 UTC",
      "updated_date": "2025-01-14 06:02:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:26:33.421708"
    },
    {
      "arxiv_id": "2403.11074v1",
      "title": "Audio-Visual Segmentation via Unlabeled Frame Exploitation",
      "title_zh": "翻译失败",
      "authors": [
        "Jinxiang Liu",
        "Yikun Liu",
        "Fei Zhang",
        "Chen Ju",
        "Ya Zhang",
        "Yanfeng Wang"
      ],
      "abstract": "Audio-visual segmentation (AVS) aims to segment the sounding objects in video\nframes. Although great progress has been witnessed, we experimentally reveal\nthat current methods reach marginal performance gain within the use of the\nunlabeled frames, leading to the underutilization issue. To fully explore the\npotential of the unlabeled frames for AVS, we explicitly divide them into two\ncategories based on their temporal characteristics, i.e., neighboring frame\n(NF) and distant frame (DF). NFs, temporally adjacent to the labeled frame,\noften contain rich motion information that assists in the accurate localization\nof sounding objects. Contrary to NFs, DFs have long temporal distances from the\nlabeled frame, which share semantic-similar objects with appearance variations.\nConsidering their unique characteristics, we propose a versatile framework that\neffectively leverages them to tackle AVS. Specifically, for NFs, we exploit the\nmotion cues as the dynamic guidance to improve the objectness localization.\nBesides, we exploit the semantic cues in DFs by treating them as valid\naugmentations to the labeled frames, which are then used to enrich data\ndiversity in a self-training manner. Extensive experimental results demonstrate\nthe versatility and superiority of our method, unleashing the power of the\nabundant unlabeled frames.",
      "tldr_zh": "这篇论文针对 Audio-Visual Segmentation (AVS) 的挑战，揭示了现有方法未能充分利用未标注帧的问题，并提出一个创新框架来解决这一问题。作者将未标注帧分为 neighboring frame (NFs) 和 distant frame (DFs)，其中 NFs 通过提取运动线索作为动态指导来提升声音对象定位的准确性，而 DFs 则被视为语义增强数据，通过自训练方式增加数据多样性。实验结果显示，该框架显著提高了 AVS 的性能，充分释放了未标注帧的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.11074v1",
      "published_date": "2024-03-17 03:45:14 UTC",
      "updated_date": "2024-03-17 03:45:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:26:45.862402"
    },
    {
      "arxiv_id": "2403.11073v1",
      "title": "Tokensome: Towards a Genetic Vision-Language GPT for Explainable and Cognitive Karyotyping",
      "title_zh": "翻译失败",
      "authors": [
        "Haoxi Zhang",
        "Xinxu Zhang",
        "Yuanxin Lin",
        "Maiqi Wang",
        "Yi Lai",
        "Yu Wang",
        "Linfeng Yu",
        "Yufeng Xu",
        "Ran Cheng",
        "Edward Szczerbicki"
      ],
      "abstract": "Automatic karyotype analysis is often defined as a visual perception task\nfocused solely on chromosomal object-level modeling. This definition has led\nmost existing methods to overlook componential and holistic information,\nsignificantly constraining model performance. Moreover, the lack of\ninterpretability in current technologies hinders clinical adoption. In this\npaper, we introduce Tokensome, a novel vision-language model based on\nchromosome tokenization for explainable and cognitive karyotyping. Tokensome\nelevates the method from the conventional visual perception layer to the\ncognitive decision-making layer. This elevation enables the integration of\ndomain knowledge and cognitive reasoning via knowledge graphs and LLMs,\nmarkedly enhancing model's explainability and facilitating abnormality\ndetection.",
      "tldr_zh": "本文指出，现有的自动核型分析方法仅关注染色体对象的视觉感知层，忽略了组成部分和整体信息，导致模型性能受限且缺乏可解释性，阻碍临床应用。论文引入 Tokensome，一种基于染色体 tokenization 的视觉语言模型，将分析提升到认知决策层，通过整合知识图谱和 LLMs 融入领域知识和认知推理。Tokensome 显著提高了模型的可解释性，并增强了异常检测能力，为可信赖的遗传学应用奠定基础。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Preprint. Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2403.11073v1",
      "published_date": "2024-03-17 03:38:50 UTC",
      "updated_date": "2024-03-17 03:38:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:26:59.871187"
    },
    {
      "arxiv_id": "2404.13050v1",
      "title": "FlowMind: Automatic Workflow Generation with LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Zhen Zeng",
        "William Watson",
        "Nicole Cho",
        "Saba Rahimi",
        "Shayleen Reynolds",
        "Tucker Balch",
        "Manuela Veloso"
      ],
      "abstract": "The rapidly evolving field of Robotic Process Automation (RPA) has made\nsignificant strides in automating repetitive processes, yet its effectiveness\ndiminishes in scenarios requiring spontaneous or unpredictable tasks demanded\nby users. This paper introduces a novel approach, FlowMind, leveraging the\ncapabilities of Large Language Models (LLMs) such as Generative Pretrained\nTransformer (GPT), to address this limitation and create an automatic workflow\ngeneration system. In FlowMind, we propose a generic prompt recipe for a\nlecture that helps ground LLM reasoning with reliable Application Programming\nInterfaces (APIs). With this, FlowMind not only mitigates the common issue of\nhallucinations in LLMs, but also eliminates direct interaction between LLMs and\nproprietary data or code, thus ensuring the integrity and confidentiality of\ninformation - a cornerstone in financial services. FlowMind further simplifies\nuser interaction by presenting high-level descriptions of auto-generated\nworkflows, enabling users to inspect and provide feedback effectively. We also\nintroduce NCEN-QA, a new dataset in finance for benchmarking question-answering\ntasks from N-CEN reports on funds. We used NCEN-QA to evaluate the performance\nof workflows generated by FlowMind against baseline and ablation variants of\nFlowMind. We demonstrate the success of FlowMind, the importance of each\ncomponent in the proposed lecture recipe, and the effectiveness of user\ninteraction and feedback in FlowMind.",
      "tldr_zh": "该论文提出FlowMind，一种利用大型语言模型(LLMs)如GPT自动生成工作流的系统，旨在解决Robotic Process Automation (RPA)在处理自发或不可预测任务时的局限性。FlowMind采用一个通用提示配方与可靠的Application Programming Interfaces (APIs)结合，减少LLMs的幻觉问题，并确保信息完整性和保密性，特别适用于金融服务领域。系统简化用户交互，通过高层次工作流描述允许反馈，并引入新的NCEN-QA数据集进行金融问答基准测试。实验结果显示，FlowMind在性能上优于基线模型，并验证了各组件和用户反馈机制的重要性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Published in ACM ICAIF 2023",
      "pdf_url": "http://arxiv.org/pdf/2404.13050v1",
      "published_date": "2024-03-17 00:36:37 UTC",
      "updated_date": "2024-03-17 00:36:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:27:11.253887"
    },
    {
      "arxiv_id": "2403.11047v1",
      "title": "From Pixels to Predictions: Spectrogram and Vision Transformer for Better Time Series Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Zhen Zeng",
        "Rachneet Kaur",
        "Suchetha Siddagangappa",
        "Tucker Balch",
        "Manuela Veloso"
      ],
      "abstract": "Time series forecasting plays a crucial role in decision-making across\nvarious domains, but it presents significant challenges. Recent studies have\nexplored image-driven approaches using computer vision models to address these\nchallenges, often employing lineplots as the visual representation of time\nseries data. In this paper, we propose a novel approach that uses\ntime-frequency spectrograms as the visual representation of time series data.\nWe introduce the use of a vision transformer for multimodal learning,\nshowcasing the advantages of our approach across diverse datasets from\ndifferent domains. To evaluate its effectiveness, we compare our method against\nstatistical baselines (EMA and ARIMA), a state-of-the-art deep learning-based\napproach (DeepAR), other visual representations of time series data (lineplot\nimages), and an ablation study on using only the time series as input. Our\nexperiments demonstrate the benefits of utilizing spectrograms as a visual\nrepresentation for time series data, along with the advantages of employing a\nvision transformer for simultaneous learning in both the time and frequency\ndomains.",
      "tldr_zh": "本文提出一种创新方法，将时间序列数据转化为时间-频率spectrogram作为视觉表示，并结合Vision Transformer进行多模态学习，以提升时间序列预测的准确性和鲁棒性。相比传统统计基线（EMA和ARIMA）、深度学习方法（DeepAR）以及其他视觉表示（如线图），该方法在多样领域数据集上表现出显著优势。实验结果显示，利用spectrogram和Vision Transformer能同时在时间和频率域学习，带来更好的预测性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.CV",
      "comment": "Published at ACM ICAIF 2023",
      "pdf_url": "http://arxiv.org/pdf/2403.11047v1",
      "published_date": "2024-03-17 00:14:29 UTC",
      "updated_date": "2024-03-17 00:14:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:27:22.376979"
    },
    {
      "arxiv_id": "2403.11046v2",
      "title": "Regulating Chatbot Output via Inter-Informational Competition",
      "title_zh": "翻译失败",
      "authors": [
        "Jiawei Zhang"
      ],
      "abstract": "The advent of ChatGPT has sparked over a year of regulatory frenzy. However,\nfew existing studies have rigorously questioned the assumption that, if left\nunregulated, AI chatbot's output would inflict tangible, severe real harm on\nhuman affairs. Most researchers have overlooked the critical possibility that\nthe information market itself can effectively mitigate these risks and, as a\nresult, they tend to use regulatory tools to address the issue directly. This\nArticle develops a yardstick for reevaluating both AI-related content risks and\ncorresponding regulatory proposals by focusing on inter-informational\ncompetition among various outlets. The decades-long history of regulating\ninformation and communications technologies indicates that regulators tend to\nerr too much on the side of caution and to put forward excessive regulatory\nmeasures when encountering the uncertainties brought about by new technologies.\nIn fact, a trove of empirical evidence has demonstrated that market competition\namong information outlets can effectively mitigate most risks and that\noverreliance on regulation is not only unnecessary but detrimental, as well.\nThis Article argues that sufficient competition among chatbots and other\ninformation outlets in the information marketplace can sufficiently mitigate\nand even resolve most content risks posed by generative AI technologies. This\nrenders certain loudly advocated regulatory strategies, like mandatory\nprohibitions, licensure, curation of datasets, and notice-and-response regimes,\ntruly unnecessary and even toxic to desirable competition and innovation\nthroughout the AI industry. Ultimately, the ideas that I advance in this\nArticle should pour some much-needed cold water on the regulatory frenzy over\ngenerative AI and steer the issue back to a rational track.",
      "tldr_zh": "这篇论文质疑了未监管 AI 聊天机器人会造成严重实际危害的假设，主张通过 inter-informational competition（信息间竞争）来缓解风险。作者分析了信息和通信技术的历史监管经验以及实证证据，证明市场竞争能有效减轻生成式 AI 的内容风险，并指出过度监管（如强制禁止、许可制度和数据集管理）不仅不必要，还会抑制创新。最终，论文呼吁理性对待 AI 监管，避免监管狂热。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.ET",
        "cs.IT",
        "cs.LG",
        "math.IT"
      ],
      "primary_category": "cs.CY",
      "comment": "50-page legal Article, forthcoming in Northwestern Journal of\n  Technology and Intellectual Property",
      "pdf_url": "http://arxiv.org/pdf/2403.11046v2",
      "published_date": "2024-03-17 00:11:15 UTC",
      "updated_date": "2024-11-19 18:18:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:27:34.748894"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 54,
  "processed_papers_count": 54,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-17T16:28:04.171060"
}