{
  "date": "2025-04-02",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-04-02 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 122 篇论文，主要聚焦 AI 和机器学习领域的创新，尤其是大型语言模型 (LLM) 的推理、安全和应用扩展，以及计算机视觉和生物医学应用的进展。令人印象深刻的包括 LLM jailbreak 攻击的系统性研究（如第 7 篇）和多模态模型的鲁棒性提升（如第 4 篇），同时有知名学者如 Jundong Li（第 1 篇）和 OpenAI 团队（第 50 篇）参与的论文值得关注。\n\n下面，我将挑选并讨论最具影响力和话题度的论文，先从 AI 推理和安全入手，再聊计算机视觉和生物医学领域，其他论文将快速掠过，只列出标题和核心贡献。\n\n### 重点论文讨论\n\n**1. 大型语言模型推理的缩放调查 (A Survey of Scaling in Large Language Model Reasoning)**  \n   作者包括 Jundong Li 等知名学者。这篇综述分析了 LLM 推理能力的缩放策略，如输入大小、推理步骤和训练优化，强调缩放可提升推理性能但可能引入鲁棒性挑战。主要贡献是系统归纳多维度缩放方法，为下一代 AI 系统开发提供指导，特别适用于复杂任务。\n\n**4. 多维视觉模型剪枝 (MDP: Multidimensional Vision Model Pruning with Latency Constraint)**  \n   这篇论文（已接受 CVPR 2025）提出 MDP 框架，通过混合整数非线性规划优化视觉模型剪枝，覆盖通道、查询和块等维度。关键发现是它在 ImageNet 上比现有方法快 28% 且准确率提升 1.4%，显著改善 CNN 和 Transformer 的效率，适用于资源受限的实时应用。\n\n**7. MCP 安全审计 (MCP Safety Audit: LLMs with the Model Context Protocol Allow Major Security Exploits)**  \n   作者 Brandon Radosevich 和 John Halloran 揭示了 LLM 在 Model Context Protocol 中的安全漏洞，如代码执行和凭证窃取。创新点是引入 MCPSafetyScanner 工具自动检测这些风险，帮助部署前修复漏洞，强调 LLM 代理工作流的潜在威胁。\n\n**38. STAR-1: 基于 1K 数据的安全 LLM 校准 (STAR-1: Safer Alignment of Reasoning LLMs with 1K Data)**  \n   这篇论文设计 STAR-1 数据集和训练框架，使用 1000 条数据提升 LLM 的安全性能，平均改善 40%。发现是它在保持推理能力的同时（如 MATH 和 GSM8K 基准）显著减少有害输出，适用于高效安全对齐。\n\n**50. PaperBench: 评估 AI 复制 AI 研究的性能 (PaperBench: Evaluating AI's Ability to Replicate AI Research)**  \n   OpenAI 团队的作品，提出 PaperBench 基准测试 AI 代理复制 ICML 论文的能力。核心贡献是通过 8000+ 任务评估 AI 的实验再现精度，发现当前模型准确率仅 21%，揭示 AI 研究再现的局限性。\n\n**16. 探索 LLM 推理的鲁棒性 (Exploring LLM Reasoning Through Controlled Prompt Variations)**  \n   与 LLM 推理相关，这篇论文通过扰动提示测试 13 个模型的鲁棒性，发现无关上下文会显著降低性能，但某些扰动可触发类 CoT 推理。主要发现是模型大小与鲁棒性不直接相关，提示设计对推理至关重要。\n\n**21. 增强推荐系统的嵌入稳定性 (Enhancing Embedding Representation Stability in Recommendation Systems with Semantic ID)**  \n   Meta 团队的论文提出 Semantic ID 前缀 n-gram 方法，提升推荐系统的嵌入稳定性。贡献在于减少数据污染和过拟合，在注意力模型上改善尾部 ID 表示，实际部署中提升了预测准确性。\n\n**28. LLM 中的性别偏见分析 (The LLM Wears Prada: Analysing Gender Bias and Stereotypes through Online Shopping Data)**  \n   这篇研究使用购物数据检测 LLM 的性别偏见，发现模型在预测用户性别时依赖刻板印象。关键发现是通过显式指令可减轻偏见，但未完全消除，强调 LLM 在实际应用中的公平性挑战。\n\n**50. OmniCellTOSG: 用于细胞信号图的联合 LLM 和 GNN 建模数据集 (OmniCellTOSG: The First Cell Text-Omic Signaling Graphs Dataset for Joint LLM and GNN Modeling)**  \n   作者如 Yixin Chen 和 Philip Payne 构建了首个细胞信号图数据集，结合文本和定量数据。贡献是支持 LLM 和 GNN 的联合训练，促进生命科学和精准医学的研究。\n\n**61. 医学图像分割的基金模型适应 (Test-time Adaptation for Foundation Medical Segmentation Model without Parametric Updates)**  \n   这篇论文提出无参数更新的测试时适应框架，提升 MedSAM 在医学分割中的性能。发现通过概率最大化和熵最小化，Dice 分数提升 3%，计算效率提高 7 倍，适用于临床图像分析。\n\n其他论文中，AI 安全和工具学习主题较多，如第 20 篇 (Evolving Security in LLMs) 讨论 LLM jailbreak 防御，第 26 篇 (Self-Resource Allocation in Multi-Agent LLM Systems) 优化多代理资源分配；计算机视觉论文如第 40 篇 (Ross3D) 通过 3D 感知提升图像生成；生物医学如第 32 篇 (Equivariant Spherical CNNs) 在新生儿 MRI 上改善纤维分布估计。剩余论文，如量子计算或经济学主题（第 15、71 篇），贡献较 niche，仅快速提及其核心：第 15 篇提出多变量时间回归框架，第 71 篇探索 LLM 在低资源语言的推理。这些论文虽有创新，但影响力较小，建议读者根据具体兴趣查阅。\n\n总之，今天的更新突显 AI 领域的动态发展，LLM 的安全和效率优化是热点，相关研究为实际应用提供了实用工具。保持关注这些前沿进展！（本快报基于摘要总结，完整论文请查阅 arXiv。）",
  "papers": [
    {
      "arxiv_id": "2504.02181v1",
      "title": "A Survey of Scaling in Large Language Model Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Zihan Chen",
        "Song Wang",
        "Zhen Tan",
        "Xingbo Fu",
        "Zhenyu Lei",
        "Peng Wang",
        "Huan Liu",
        "Cong Shen",
        "Jundong Li"
      ],
      "abstract": "The rapid advancements in large Language models (LLMs) have significantly\nenhanced their reasoning capabilities, driven by various strategies such as\nmulti-agent collaboration. However, unlike the well-established performance\nimprovements achieved through scaling data and model size, the scaling of\nreasoning in LLMs is more complex and can even negatively impact reasoning\nperformance, introducing new challenges in model alignment and robustness. In\nthis survey, we provide a comprehensive examination of scaling in LLM\nreasoning, categorizing it into multiple dimensions and analyzing how and to\nwhat extent different scaling strategies contribute to improving reasoning\ncapabilities. We begin by exploring scaling in input size, which enables LLMs\nto process and utilize more extensive context for improved reasoning. Next, we\nanalyze scaling in reasoning steps that improves multi-step inference and\nlogical consistency. We then examine scaling in reasoning rounds, where\niterative interactions refine reasoning outcomes. Furthermore, we discuss\nscaling in training-enabled reasoning, focusing on optimization through\niterative model improvement. Finally, we review applications of scaling across\ndomains and outline future directions for further advancing LLM reasoning. By\nsynthesizing these diverse perspectives, this survey aims to provide insights\ninto how scaling strategies fundamentally enhance the reasoning capabilities of\nLLMs and further guide the development of next-generation AI systems.",
      "tldr_zh": "这篇调查综述探讨了大型语言模型（LLMs）中推理能力的缩放（scaling）策略，包括输入大小、推理步骤、推理轮次和训练启用推理等维度，这些策略有助于提升多步推理和逻辑一致性，但也可能导致性能下降、模型对齐和鲁棒性挑战。作者分析了不同缩放方法如何处理更广泛的上下文和迭代交互，从而改善LLMs的推理表现。总体上，该调查总结了这些策略在各领域的应用，并为开发下一代AI系统提供了指导性见解。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02181v1",
      "published_date": "2025-04-02 23:51:27 UTC",
      "updated_date": "2025-04-02 23:51:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:39:20.162269"
    },
    {
      "arxiv_id": "2504.02899v1",
      "title": "Meat-Free Day Reduces Greenhouse Gas Emissions but Poses Challenges for Customer Retention and Adherence to Dietary Guidelines",
      "title_zh": "翻译失败",
      "authors": [
        "Giuseppe Russo",
        "Kristina Gligorić",
        "Vincent Moreau",
        "Robert West"
      ],
      "abstract": "Reducing meat consumption is crucial for achieving global environmental and\nnutritional targets. Meat-Free Day (MFD) is a widely adopted strategy to\naddress this challenge by encouraging plant-based diets through the removal of\nanimal-based meals. We assessed the environmental, behavioral, and nutritional\nimpacts of MFD by implementing 67 MFDs over 18 months (once a week on a\nrandomly chosen day) across 12 cafeterias on a large university campus,\nanalyzing over 400,000 food purchases. MFD reduced on-campus food-related\ngreenhouse gas (GHG) emissions on treated days by 52.9% and contributed to\nimproved fiber (+26.9%) and cholesterol (-4.5%) consumption without altering\ncaloric intake. These nutritional benefits were, however, accompanied by a\n27.6% decrease in protein intake and a 34.2% increase in sugar consumption.\nMoreover, the increase in plant-based meals did not carry over to subsequent\ndays, as evidenced by a 3.5% rebound in animal-based meal consumption on days\nimmediately following treated days. MFD also led to a 16.8% drop in on-campus\nmeal sales on treated days.Monte Carlo simulations suggest that if 8.7% of\ndiners were to eat burgers off-campus on treated days, MFD's GHG savings would\nbe fully negated. As our analysis identifies on-campus customer retention as\nthe main challenge to MFD effectiveness, we recommend combining MFD with\ncustomer retention interventions to ensure environmental and nutritional\nbenefits.",
      "tldr_zh": "本研究评估了 Meat-Free Day (MFD) 在大学校园 12 个食堂的实施效果，通过每周随机选择一天移除动物性餐食，共进行 67 天并分析超过 40 万次食物购买。结果显示，MFD 使当天的温室气体 (GHG) 排放减少 52.9%，并改善纤维摄入 (+26.9%) 和胆固醇摄入 (-4.5%)，但同时导致蛋白质摄入下降 27.6% 和糖摄入增加 34.2%。然而，MFD 面临客户保留挑战，包括餐食销售下降 16.8% 和次日动物性餐食反弹 3.5%，模拟显示若 8.7% 用餐者转至校外，GHG 节约可能被抵消，因此建议结合客户保留干预措施以确保环境和营养益处。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "econ.GN",
        "q-fin.EC"
      ],
      "primary_category": "cs.CY",
      "comment": "26 pages, 7 figures, 19 Tables",
      "pdf_url": "http://arxiv.org/pdf/2504.02899v1",
      "published_date": "2025-04-02 23:50:57 UTC",
      "updated_date": "2025-04-02 23:50:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:39:33.587222"
    },
    {
      "arxiv_id": "2504.02169v1",
      "title": "On the Geometry of Receiver Operating Characteristic and Precision-Recall Curves",
      "title_zh": "翻译失败",
      "authors": [
        "Reza Sameni"
      ],
      "abstract": "We study the geometry of Receiver Operating Characteristic (ROC) and\nPrecision-Recall (PR) curves in binary classification problems. The key finding\nis that many of the most commonly used binary classification metrics are merely\nfunctions of the composition function $G := F_p \\circ F_n^{-1}$, where\n$F_p(\\cdot)$ and $F_n(\\cdot)$ are the class-conditional cumulative distribution\nfunctions of the classifier scores in the positive and negative classes,\nrespectively. This geometric perspective facilitates the selection of operating\npoints, understanding the effect of decision thresholds, and comparison between\nclassifiers. It also helps explain how the shapes and geometry of ROC/PR curves\nreflect classifier behavior, providing objective tools for building classifiers\noptimized for specific applications with context-specific constraints. We\nfurther explore the conditions for classifier dominance, present analytical and\nnumerical examples demonstrating the effects of class separability and variance\non ROC and PR geometries, and derive a link between the positive-to-negative\nclass leakage function $G(\\cdot)$ and the Kullback--Leibler divergence. The\nframework highlights practical considerations, such as model calibration,\ncost-sensitive optimization, and operating point selection under real-world\ncapacity constraints, enabling more informed approaches to classifier\ndeployment and decision-making.",
      "tldr_zh": "这篇论文探讨了二元分类问题中 Receiver Operating Characteristic (ROC) 和 Precision-Recall (PR) 曲线的几何性质，关键发现是将常用指标视为函数 $G := F_p \\circ F_n^{-1}$ 的组合，其中 $F_p(\\cdot)$ 和 $F_n(\\cdot)$ 分别是正负类分类器分数的条件累积分布函数。這種几何视角有助于选择操作点、理解决策阈值的影响，以及比较分类器行为，并解释曲线形状如何反映分类器性能。论文进一步分析了分类器优势条件、类可分性和方差对曲线几何的影响，并建立了 $G(\\cdot)$ 与 Kullback-Leibler divergence 的联系，提供工具优化模型校准、成本敏感优化和实际决策。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.ST",
        "stat.ML",
        "stat.TH"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02169v1",
      "published_date": "2025-04-02 23:04:28 UTC",
      "updated_date": "2025-04-02 23:04:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:39:44.574070"
    },
    {
      "arxiv_id": "2504.02168v1",
      "title": "MDP: Multidimensional Vision Model Pruning with Latency Constraint",
      "title_zh": "MDP：多维视觉模型修剪与延迟约束",
      "authors": [
        "Xinglong Sun",
        "Barath Lakshmanan",
        "Maying Shen",
        "Shiyi Lan",
        "Jingde Chen",
        "Jose M. Alvarez"
      ],
      "abstract": "Current structural pruning methods face two significant limitations: (i) they\noften limit pruning to finer-grained levels like channels, making aggressive\nparameter reduction challenging, and (ii) they focus heavily on parameter and\nFLOP reduction, with existing latency-aware methods frequently relying on\nsimplistic, suboptimal linear models that fail to generalize well to\ntransformers, where multiple interacting dimensions impact latency. In this\npaper, we address both limitations by introducing Multi-Dimensional Pruning\n(MDP), a novel paradigm that jointly optimizes across a variety of pruning\ngranularities-including channels, query, key, heads, embeddings, and blocks.\nMDP employs an advanced latency modeling technique to accurately capture\nlatency variations across all prunable dimensions, achieving an optimal balance\nbetween latency and accuracy. By reformulating pruning as a Mixed-Integer\nNonlinear Program (MINLP), MDP efficiently identifies the optimal pruned\nstructure across all prunable dimensions while respecting latency constraints.\nThis versatile framework supports both CNNs and transformers. Extensive\nexperiments demonstrate that MDP significantly outperforms previous methods,\nespecially at high pruning ratios. On ImageNet, MDP achieves a 28% speed\nincrease with a +1.4 Top-1 accuracy improvement over prior work like HALP for\nResNet50 pruning. Against the latest transformer pruning method, Isomorphic,\nMDP delivers an additional 37% acceleration with a +0.7 Top-1 accuracy\nimprovement.",
      "tldr_zh": "该研究提出了一种名为 MDP（Multidimensional Vision Model Pruning）的创新框架，用于解决现有结构剪枝方法的局限性，包括细粒度剪枝（如通道）的限制和延迟建模的不足。MDP 通过联合优化多种剪枝粒度（如 channels、query、key、heads、embeddings 和 blocks），并采用先进的延迟建模技术，将剪枝问题转化为 Mixed-Integer Nonlinear Program (MINLP)，以在满足延迟约束的同时实现参数和性能的平衡。该框架适用于 CNNs 和 transformers，在 ImageNet 数据集上实验显示，MDP 在 ResNet50 剪枝中比 HALP 方法实现了 28% 的速度提升和 +1.4% 的 Top-1 准确率改进；相较于 Isomorphic 方法，还额外获得了 37% 的加速和 +0.7% 的 Top-1 准确率提升。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.02168v1",
      "published_date": "2025-04-02 23:00:10 UTC",
      "updated_date": "2025-04-02 23:00:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:39:56.324550"
    },
    {
      "arxiv_id": "2504.02151v1",
      "title": "Multivariate Temporal Regression at Scale: A Three-Pillar Framework Combining ML, XAI, and NLP",
      "title_zh": "大规模下的多变量时间序列回归：一个结合 ML、XAI 和 NLP 的三大支",
      "authors": [
        "Jiztom Kavalakkatt Francis",
        "Matthew J Darr"
      ],
      "abstract": "The rapid use of artificial intelligence (AI) in processes such as coding,\nimage processing, and data prediction means it is crucial to understand and\nvalidate the data we are working with fully. This paper dives into the hurdles\nof analyzing high-dimensional data, especially when it gets too complex.\nTraditional methods in data analysis often look at direct connections between\ninput variables, which can miss out on the more complicated relationships\nwithin the data.\n  To address these issues, we explore several tested techniques, such as\nremoving specific variables to see their impact and using statistical analysis\nto find connections between multiple variables. We also consider the role of\nsynthetic data and how information can sometimes be redundant across different\nsensors. These analyses are typically very computationally demanding and often\nrequire much human effort to make sense of the results.\n  A common approach is to treat the entire dataset as one unit and apply\nadvanced models to handle it. However, this can become problematic with larger,\nnoisier datasets and more complex models. So, we suggest methods to identify\noverall patterns that can help with tasks like classification or regression\nbased on the idea that more straightforward approaches might be more\nunderstandable.\n  Our research looks at two datasets: a real-world dataset and a synthetic one.\nThe goal is to create a methodology that highlights key features on a global\nscale that lead to predictions, making it easier to validate or quantify the\ndata set. By reducing the dimensionality with this method, we can simplify the\nmodels used and thus clarify the insights we gain. Furthermore, our method can\nreveal unexplored relationships between specific inputs and outcomes, providing\na way to validate these new connections further.",
      "tldr_zh": "这篇论文提出一个结合机器学习(ML)、可解释AI(XAI)和自然语言处理(NLP)的三柱框架，用于处理大规模多变量时间回归分析，旨在解决高维数据中复杂关系和计算密集问题的挑战。框架通过技术如变量移除、统计分析和处理合成数据来识别整体模式，帮助简化模型并提升分类或回归任务的可解释性。研究基于真实和合成数据集，展示了该方法能突出全局关键特征，揭示输入与输出间的未探索关系，从而改善数据验证和预测准确性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.02151v1",
      "published_date": "2025-04-02 21:53:03 UTC",
      "updated_date": "2025-04-02 21:53:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:40:07.684221"
    },
    {
      "arxiv_id": "2504.02148v1",
      "title": "OmniCellTOSG: The First Cell Text-Omic Signaling Graphs Dataset for Joint LLM and GNN Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Heming Zhang",
        "Tim Xu",
        "Dekang Cao",
        "Shunning Liang",
        "Lars Schimmelpfennig",
        "Levi Kaster",
        "Di Huang",
        "Carlos Cruchaga",
        "Guangfu Li",
        "Michael Province",
        "Yixin Chen",
        "Philip Payne",
        "Fuhai Li"
      ],
      "abstract": "Complex cell signaling systems -- governed by varying protein abundances and\ninteractions -- generate diverse cell types across organs. These systems evolve\nunder influences such as age, sex, diet, environmental exposures, and diseases,\nmaking them challenging to decode given the involvement of tens of thousands of\ngenes and proteins. Recently, hundreds of millions of single-cell omics data\nhave provided a robust foundation for understanding these signaling networks\nwithin various cell subpopulations and conditions. Inspired by the success of\nlarge foundation models (for example, large language models and large vision\nmodels) pre-trained on massive datasets, we introduce OmniCellTOSG, the first\ndataset of cell text-omic signaling graphs (TOSGs). Each TOSG represents the\nsignaling network of an individual or meta-cell and is labeled with information\nsuch as organ, disease, sex, age, and cell subtype. OmniCellTOSG offers two key\ncontributions. First, it introduces a novel graph model that integrates\nhuman-readable annotations -- such as biological functions, cellular locations,\nsignaling pathways, related diseases, and drugs -- with quantitative gene and\nprotein abundance data, enabling graph reasoning to decode cell signaling. This\napproach calls for new joint models combining large language models and graph\nneural networks. Second, the dataset is built from single-cell RNA sequencing\ndata of approximately 120 million cells from diverse tissues and conditions\n(healthy and diseased) and is fully compatible with PyTorch. This facilitates\nthe development of innovative cell signaling models that could transform\nresearch in life sciences, healthcare, and precision medicine. The OmniCellTOSG\ndataset is continuously expanding and will be updated regularly. The dataset\nand code are available at https://github.com/FuhaiLiAiLab/OmniCellTOSG.",
      "tldr_zh": "本文介绍了 OmniCellTOSG，这是第一个细胞文本-组学信号图(TOSG)数据集，旨在支持 LLM (Large Language Models) 和 GNN (Graph Neural Networks) 的联合建模。该数据集将人类可读的生物注释（如生物功能、细胞位置、信号通路、相关疾病和药物）与定量基因和蛋白丰度数据整合，基于约 1.2 亿个单细胞 RNA 测序数据构建，涵盖各种组织和健康/疾病条件。OmniCellTOSG 促进图推理解码复杂细胞信号，并兼容 PyTorch，有助于推动生命科学、健康和精准医学领域的创新研究。数据集在 GitHub 上公开并持续更新。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02148v1",
      "published_date": "2025-04-02 21:47:58 UTC",
      "updated_date": "2025-04-02 21:47:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:40:21.935357"
    },
    {
      "arxiv_id": "2504.03767v2",
      "title": "MCP Safety Audit: LLMs with the Model Context Protocol Allow Major Security Exploits",
      "title_zh": "翻译失败",
      "authors": [
        "Brandon Radosevich",
        "John Halloran"
      ],
      "abstract": "To reduce development overhead and enable seamless integration between\npotential components comprising any given generative AI application, the Model\nContext Protocol (MCP) (Anthropic, 2024) has recently been released and\nsubsequently widely adopted. The MCP is an open protocol that standardizes API\ncalls to large language models (LLMs), data sources, and agentic tools. By\nconnecting multiple MCP servers, each defined with a set of tools, resources,\nand prompts, users are able to define automated workflows fully driven by LLMs.\nHowever, we show that the current MCP design carries a wide range of security\nrisks for end users. In particular, we demonstrate that industry-leading LLMs\nmay be coerced into using MCP tools to compromise an AI developer's system\nthrough various attacks, such as malicious code execution, remote access\ncontrol, and credential theft. To proactively mitigate these and related\nattacks, we introduce a safety auditing tool, MCPSafetyScanner, the first\nagentic tool to assess the security of an arbitrary MCP server. MCPScanner uses\nseveral agents to (a) automatically determine adversarial samples given an MCP\nserver's tools and resources; (b) search for related vulnerabilities and\nremediations based on those samples; and (c) generate a security report\ndetailing all findings. Our work highlights serious security issues with\ngeneral-purpose agentic workflows while also providing a proactive tool to\naudit MCP server safety and address detected vulnerabilities before deployment.\n  The described MCP server auditing tool, MCPSafetyScanner, is freely available\nat: https://github.com/johnhalloran321/mcpSafetyScanner",
      "tldr_zh": "该研究揭示了 Model Context Protocol (MCP) 在整合 large language models (LLMs) 时存在的重大安全风险，包括 LLMs 被胁迫利用 MCP 工具进行恶意代码执行、远程访问控制和凭证窃取等攻击。论文通过实际演示证明了这些漏洞可能危及 AI 开发者的系统，并引入了 MCPSafetyScanner，这是一个代理工具，用于自动识别针对 MCP 服务器的对抗样本、搜索相关漏洞补救措施并生成详细安全报告。MCPSafetyScanner 的开源发布为主动审计和缓解代理工作流的安全问题提供了实用解决方案。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "27 pages, 21 figures, and 2 Tables. Cleans up the TeX source",
      "pdf_url": "http://arxiv.org/pdf/2504.03767v2",
      "published_date": "2025-04-02 21:46:02 UTC",
      "updated_date": "2025-04-11 16:59:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:40:32.747677"
    },
    {
      "arxiv_id": "2504.02144v1",
      "title": "Towards Interpretable Soft Prompts",
      "title_zh": "翻译失败",
      "authors": [
        "Oam Patel",
        "Jason Wang",
        "Nikhil Shivakumar Nayak",
        "Suraj Srinivas",
        "Himabindu Lakkaraju"
      ],
      "abstract": "Soft prompts have been popularized as a cheap and easy way to improve\ntask-specific LLM performance beyond few-shot prompts. Despite their origin as\nan automated prompting method, however, soft prompts and other trainable\nprompts remain a black-box method with no immediately interpretable connections\nto prompting. We create a novel theoretical framework for evaluating the\ninterpretability of trainable prompts based on two desiderata: faithfulness and\nscrutability. We find that existing methods do not naturally satisfy our\nproposed interpretability criterion. Instead, our framework inspires a new\ndirection of trainable prompting methods that explicitly optimizes for\ninterpretability. To this end, we formulate and test new\ninterpretability-oriented objective functions for two state-of-the-art prompt\ntuners: Hard Prompts Made Easy (PEZ) and RLPrompt. Our experiments with GPT-2\ndemonstrate a fundamental trade-off between interpretability and the\ntask-performance of the trainable prompt, explicating the hardness of the soft\nprompt interpretability problem and revealing odd behavior that arises when one\noptimizes for an interpretability proxy.",
      "tldr_zh": "该论文探讨了软 prompts（soft prompts）作为提升大型语言模型（LLMs）任务性能的方法，但其黑箱性质导致可解释性不足。作者提出一个新理论框架，以faithfulness（忠实性）和scrutability（可审查性）作为评估可解释性的标准，并针对现有方法的不完善性，设计了新的可解释性导向目标函数，应用于Hard Prompts Made Easy（PEZ）和RLPrompt 等状态-of-the-art 提示调优器。实验结果显示，在GPT-2模型上，优化可解释性会导致任务性能的权衡，并揭示了一些异常行为，从而阐明了软 prompts 可解释性问题的挑战。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML",
        "68T50",
        "I.2.0; G.3"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.02144v1",
      "published_date": "2025-04-02 21:42:09 UTC",
      "updated_date": "2025-04-02 21:42:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:40:45.200064"
    },
    {
      "arxiv_id": "2504.02895v1",
      "title": "UAC: Uncertainty-Aware Calibration of Neural Networks for Gesture Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Farida Al Haddad",
        "Yuxin Wang",
        "Malcolm Mielle"
      ],
      "abstract": "Artificial intelligence has the potential to impact safety and efficiency in\nsafety-critical domains such as construction, manufacturing, and healthcare.\nFor example, using sensor data from wearable devices, such as inertial\nmeasurement units (IMUs), human gestures can be detected while maintaining\nprivacy, thereby ensuring that safety protocols are followed. However, strict\nsafety requirements in these domains have limited the adoption of AI, since\naccurate calibration of predicted probabilities and robustness against\nout-of-distribution (OOD) data is necessary.\n  This paper proposes UAC (Uncertainty-Aware Calibration), a novel two-step\nmethod to address these challenges in IMU-based gesture recognition. First, we\npresent an uncertainty-aware gesture network architecture that predicts both\ngesture probabilities and their associated uncertainties from IMU data. This\nuncertainty is then used to calibrate the probabilities of each potential\ngesture. Second, an entropy-weighted expectation of predictions over multiple\nIMU data windows is used to improve accuracy while maintaining correct\ncalibration.\n  Our method is evaluated using three publicly available IMU datasets for\ngesture detection and is compared to three state-of-the-art calibration methods\nfor neural networks: temperature scaling, entropy maximization, and Laplace\napproximation. UAC outperforms existing methods, achieving improved accuracy\nand calibration in both OOD and in-distribution scenarios. Moreover, we find\nthat, unlike our method, none of the state-of-the-art methods significantly\nimprove the calibration of IMU-based gesture recognition models. In conclusion,\nour work highlights the advantages of uncertainty-aware calibration of neural\nnetworks, demonstrating improvements in both calibration and accuracy for\ngesture detection using IMU data.",
      "tldr_zh": "这篇论文提出了 UAC（Uncertainty-Aware Calibration），一种针对神经网络的手势检测方法，旨在解决安全关键领域（如建筑和医疗）中使用 IMU（inertial measurement units）数据时，预测概率校准和对 OOD（out-of-distribution）数据的鲁棒性问题。UAC 采用两步方法：首先构建一个不确定性感知的网络架构来预测手势概率及其不确定性，并以此校准概率；其次，通过熵加权期望在多个 IMU 数据窗口上优化预测，以提升准确性。实验结果显示，UAC 在三个公开数据集上优于现有方法如 temperature scaling、entropy maximization 和 Laplace approximation，在 OOD 和 in-distribution 场景中显著提高了准确性和校准性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.02895v1",
      "published_date": "2025-04-02 21:40:01 UTC",
      "updated_date": "2025-04-02 21:40:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:40:57.268353"
    },
    {
      "arxiv_id": "2504.02141v1",
      "title": "On Simulation-Guided LLM-based Code Generation for Safe Autonomous Driving Software",
      "title_zh": "翻译失败",
      "authors": [
        "Ali Nouri",
        "Johan Andersson",
        "Kailash De Jesus Hornig",
        "Zhennan Fei",
        "Emil Knabe",
        "Hakan Sivencrona",
        "Beatriz Cabrero-Daniel",
        "Christian Berger"
      ],
      "abstract": "Automated Driving System (ADS) is a safety-critical software system\nresponsible for the interpretation of the vehicle's environment and making\ndecisions accordingly. The unbounded complexity of the driving context,\nincluding unforeseeable events, necessitate continuous improvement, often\nachieved through iterative DevOps processes. However, DevOps processes are\nthemselves complex, making these improvements both time- and\nresource-intensive. Automation in code generation for ADS using Large Language\nModels (LLM) is one potential approach to address this challenge. Nevertheless,\nthe development of ADS requires rigorous processes to verify, validate, assess,\nand qualify the code before it can be deployed in the vehicle and used. In this\nstudy, we developed and evaluated a prototype for automatic code generation and\nassessment using a designed pipeline of a LLM-based agent, simulation model,\nand rule-based feedback generator in an industrial setup. The LLM-generated\ncode is evaluated automatically in a simulation model against multiple critical\ntraffic scenarios, and an assessment report is provided as feedback to the LLM\nfor modification or bug fixing. We report about the experimental results of the\nprototype employing Codellama:34b, DeepSeek (r1:32b and Coder:33b),\nCodeGemma:7b, Mistral:7b, and GPT4 for Adaptive Cruise Control (ACC) and\nUnsupervised Collision Avoidance by Evasive Manoeuvre (CAEM). We finally\nassessed the tool with 11 experts at two Original Equipment Manufacturers\n(OEMs) by conducting an interview study.",
      "tldr_zh": "该论文探讨了使用大型语言模型(LLM)结合模拟指导来自动生成安全的自动驾驶软件(ADS)代码，以应对驾驶环境复杂性和DevOps过程的资源消耗问题。研究开发了一个原型系统，包括LLM-based agent、模拟模型和规则-based反馈生成器，用于在关键交通场景中生成代码、自动评估其性能，并提供反馈以修复bug。实验评估了多种模型如Codellama:34b、DeepSeek和GPT4，针对Adaptive Cruise Control (ACC)和Unsupervised Collision Avoidance by Evasive Manoeuvre (CAEM)场景，结果显示了代码生成效率的提升。最终，通过与11名专家的访谈研究，确认了该工具在工业环境中的可行性和潜力。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted in the 29th International Conference on Evaluation and\n  Assessment in Software Engineering (EASE)",
      "pdf_url": "http://arxiv.org/pdf/2504.02141v1",
      "published_date": "2025-04-02 21:35:11 UTC",
      "updated_date": "2025-04-02 21:35:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:41:08.798167"
    },
    {
      "arxiv_id": "2504.02137v1",
      "title": "Enhancing Embedding Representation Stability in Recommendation Systems with Semantic ID",
      "title_zh": "翻译失败",
      "authors": [
        "Carolina Zheng",
        "Minhui Huang",
        "Dmitrii Pedchenko",
        "Kaushik Rangadurai",
        "Siyu Wang",
        "Gaby Nahum",
        "Jie Lei",
        "Yang Yang",
        "Tao Liu",
        "Zutian Luo",
        "Xiaohan Wei",
        "Dinesh Ramasamy",
        "Jiyan Yang",
        "Yiping Han",
        "Lin Yang",
        "Hangjun Xu",
        "Rong Jin",
        "Shuang Yang"
      ],
      "abstract": "The exponential growth of online content has posed significant challenges to\nID-based models in industrial recommendation systems, ranging from extremely\nhigh cardinality and dynamically growing ID space, to highly skewed engagement\ndistributions, to prediction instability as a result of natural id life cycles\n(e.g, the birth of new IDs and retirement of old IDs). To address these issues,\nmany systems rely on random hashing to handle the id space and control the\ncorresponding model parameters (i.e embedding table). However, this approach\nintroduces data pollution from multiple ids sharing the same embedding, leading\nto degraded model performance and embedding representation instability.\n  This paper examines these challenges and introduces Semantic ID prefix ngram,\na novel token parameterization technique that significantly improves the\nperformance of the original Semantic ID. Semantic ID prefix ngram creates\nsemantically meaningful collisions by hierarchically clustering items based on\ntheir content embeddings, as opposed to random assignments. Through extensive\nexperimentation, we demonstrate that Semantic ID prefix ngram not only\naddresses embedding instability but also significantly improves tail id\nmodeling, reduces overfitting, and mitigates representation shifts. We further\nhighlight the advantages of Semantic ID prefix ngram in attention-based models\nthat contextualize user histories, showing substantial performance\nimprovements. We also report our experience of integrating Semantic ID into\nMeta production Ads Ranking system, leading to notable performance gains and\nenhanced prediction stability in live deployments.",
      "tldr_zh": "该论文探讨了在线内容爆炸增长对基于 ID 的推荐系统带来的挑战，包括高基数、动态 ID 空间、倾斜互动分布以及嵌入表示不稳定性等问题。针对这些问题，作者提出 Semantic ID prefix ngram，一种新型标记参数化技术，通过基于内容嵌入的层次聚类创建语义有意义的碰撞，从而取代随机哈希方法。实验结果显示，该技术显著改善了 embedding 稳定性、提升了尾部 ID 建模能力、减少了过拟合并缓解了表示偏移，并在注意力-based 模型中增强了用户历史语境化。最终，在 Meta 生产 Ads Ranking 系统中的实际部署中，Semantic ID prefix ngram 实现了显著性能提升和预测稳定性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02137v1",
      "published_date": "2025-04-02 21:28:38 UTC",
      "updated_date": "2025-04-02 21:28:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:41:20.641326"
    },
    {
      "arxiv_id": "2504.02128v1",
      "title": "Achieving Unanimous Consensus in Decision Making Using Multi-Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Apurba Pokharel",
        "Ram Dantu",
        "Shakila Zaman",
        "Sirisha Talapuru",
        "Vinh Quach"
      ],
      "abstract": "Blockchain consensus mechanisms have relied on algorithms such as\nProof-of-Work (PoW) and Proof-of-Stake (PoS) to ensure network functionality\nand integrity. However, these approaches struggle with adaptability for\ndecision-making where the opinions of each matter rather than reaching an\nagreement based on honest majority or weighted consensus. This paper introduces\na novel deliberation-based consensus mechanism where Large Language Models\n(LLMs) act as rational agents engaging in structured discussions to reach a\nunanimous consensus. By leveraging graded consensus and a multi-round\ndeliberation process, our approach ensures both unanimous consensus for\ndefinitive problems and graded confidence for prioritized decisions and\npolicies. We provide a formalization of our system and use it to show that the\nproperties of blockchains: consistency, agreement, liveness, and determinism\nare maintained. Moreover, experimental results demonstrate our system's\nfeasibility, showcasing how our deliberation method's convergence, block\nproperties, and accuracy enable decision-making on blockchain networks. We also\naddress key challenges with this novel approach such as degeneration of\nthoughts, hallucinations, malicious models and nodes, resource consumption, and\nscalability.",
      "tldr_zh": "这篇论文提出了一种新型审议型共识机制，使用 Large Language Models (LLMs) 作为理性代理，通过结构化讨论实现区块链决策中的一致共识，以弥补传统 Proof-of-Work (PoW) 和 Proof-of-Stake (PoS) 在强调个体意见方面的不足。该机制采用分级共识 (graded consensus) 和多轮审议过程，确保对确定性问题达到完全一致，或为优先决策提供置信度评估。论文形式化了系统，证明了区块链的核心属性，包括 consistency、agreement、liveness 和 determinism。实验结果验证了该方法的 feasibility，提升了决策准确性和收敛性，同时解决了挑战如思维退化、幻觉、恶意模型和节点、资源消耗及可伸缩性。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.MA",
      "comment": "11 pages, 9 figure, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.02128v1",
      "published_date": "2025-04-02 21:02:54 UTC",
      "updated_date": "2025-04-02 21:02:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:41:33.016400"
    },
    {
      "arxiv_id": "2504.08771v1",
      "title": "Generate the browsing process for short-video recommendation",
      "title_zh": "生成短视频推荐的浏览过程",
      "authors": [
        "Chao Feng",
        "Yanze Zhang",
        "Chenghao Zhang"
      ],
      "abstract": "This paper introduces a new model to generate the browsing process for\nshort-video recommendation and proposes a novel Segment Content Aware Model via\nUser Engagement Feedback (SCAM) for watch time prediction in video\nrecommendation. Unlike existing methods that rely on multimodal features for\nvideo content understanding, SCAM implicitly models video content through\nusers' historical watching behavior, enabling segment-level understanding\nwithout complex multimodal data. By dividing videos into segments based on\nduration and employing a Transformer-like architecture, SCAM captures the\nsequential dependence between segments while mitigating duration bias.\nExtensive experiments on industrial-scale and public datasets demonstrate\nSCAM's state-of-the-art performance in watch time prediction. The proposed\napproach offers a scalable and effective solution for video recommendation by\nleveraging segment-level modeling and users' engagement feedback.",
      "tldr_zh": "这篇论文提出了一种新模型，用于生成短视频推荐的浏览过程，并引入 Segment Content Aware Model via User Engagement Feedback (SCAM) 来预测观看时长。不同于依赖多模态特征的现有方法，SCAM 通过用户的历史观看行为隐式建模视频内容，将视频基于时长分成段落，并采用 Transformer-like architecture 捕捉段落间的顺序依赖，同时缓解时长偏差。实验在工业规模和公共数据集上证明，SCAM 在 watch time prediction 方面达到了最先进性能，并提供了一个可扩展的视频推荐解决方案。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.08771v1",
      "published_date": "2025-04-02 20:54:52 UTC",
      "updated_date": "2025-04-02 20:54:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:41:45.727072"
    },
    {
      "arxiv_id": "2504.02118v1",
      "title": "LLMPi: Optimizing LLMs for High-Throughput on Raspberry Pi",
      "title_zh": "翻译失败",
      "authors": [
        "Mahsa Ardakani",
        "Jinendra Malekar",
        "Ramtin Zand"
      ],
      "abstract": "Deploying Large Language Models (LLMs) on resource-constrained edge devices\nlike the Raspberry Pi presents challenges in computational efficiency, power\nconsumption, and response latency. This paper explores quantization-based\noptimization techniques to enable high-throughput, energy-efficient execution\nof LLMs on low-power embedded systems. Our approach leverages k-quantization, a\nPost-Training Quantization (PTQ) method designed for different bit-widths,\nenabling efficient 2-bit, 4-bit, 6-bit, and 8-bit weight quantization.\nAdditionally, we employ ternary quantization using Quantization-Aware Training\n(QAT) for BitNet models, allowing for more effective adaptation to lower-bit\nrepresentations while preserving accuracy.\n  Our findings highlight the potential of quantized LLMs for real-time\nconversational AI on edge devices, paving the way for low-power,\nhigh-efficiency AI deployment in mobile and embedded applications. This study\ndemonstrates that aggressive quantization strategies can significantly reduce\nenergy consumption while maintaining inference quality, making LLMs practical\nfor resource-limited environments.",
      "tldr_zh": "这篇论文探讨了在Raspberry Pi等资源受限边缘设备上部署Large Language Models (LLMs)的优化方法，以应对计算效率、功耗和响应延迟的挑战。研究采用k-quantization（一种Post-Training Quantization, PTQ）来实现2-bit至8-bit权重量化，并通过Quantization-Aware Training (QAT)应用于Ternary Quantization和BitNet模型，从而在保持准确性的同时显著降低能耗。结果表明，这种量化策略使LLMs在实时对话AI应用中变得可行，为低功耗嵌入式系统铺平了道路。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02118v1",
      "published_date": "2025-04-02 20:29:39 UTC",
      "updated_date": "2025-04-02 20:29:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:41:56.620213"
    },
    {
      "arxiv_id": "2504.02114v1",
      "title": "On Model Protection in Federated Learning against Eavesdropping Attacks",
      "title_zh": "翻译失败",
      "authors": [
        "Dipankar Maity",
        "Kushal Chakrabarti"
      ],
      "abstract": "In this study, we investigate the protection offered by federated learning\nalgorithms against eavesdropping adversaries. In our model, the adversary is\ncapable of intercepting model updates transmitted from clients to the server,\nenabling it to create its own estimate of the model. Unlike previous research,\nwhich predominantly focuses on safeguarding client data, our work shifts\nattention protecting the client model itself. Through a theoretical analysis,\nwe examine how various factors, such as the probability of client selection,\nthe structure of local objective functions, global aggregation at the server,\nand the eavesdropper's capabilities, impact the overall level of protection. We\nfurther validate our findings through numerical experiments, assessing the\nprotection by evaluating the model accuracy achieved by the adversary. Finally,\nwe compare our results with methods based on differential privacy, underscoring\ntheir limitations in this specific context.",
      "tldr_zh": "本文研究了联邦学习（Federated Learning）算法对窃听攻击（Eavesdropping Attacks）的保护机制，重点关注保护客户端模型本身而非传统的数据隐私。作者通过理论分析探讨了客户端选择概率、局部目标函数结构、服务器的全球聚合以及攻击者能力等因素对保护水平的影响，并通过数值实验验证了这些因素如何影响攻击者实现的模型准确率。最终，与基于差分隐私（Differential Privacy）的方法相比，本文突出了现有方法的局限性，并为提升联邦学习的安全性提供了新见解。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY",
        "math.OC",
        "stat.ML"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02114v1",
      "published_date": "2025-04-02 20:20:13 UTC",
      "updated_date": "2025-04-02 20:20:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:42:08.286294"
    },
    {
      "arxiv_id": "2504.02111v1",
      "title": "Exploring LLM Reasoning Through Controlled Prompt Variations",
      "title_zh": "通过受控提示变体探索 LLM 推理",
      "authors": [
        "Giannis Chatziveroglou",
        "Richard Yun",
        "Maura Kelleher"
      ],
      "abstract": "This study investigates the reasoning robustness of large language models\n(LLMs) on mathematical problem-solving tasks under systematically introduced\ninput perturbations. Using the GSM8K dataset as a controlled testbed, we\nevaluate how well state-of-the-art models maintain logical consistency and\ncorrectness when confronted with four categories of prompt perturbations:\nirrelevant context, pathological instructions, factually relevant but\nnon-essential context, and a combination of the latter two. Our experiments,\nconducted on thirteen open-source and closed-source LLMs, reveal that\nintroducing irrelevant context within the model's context window significantly\ndegrades performance, suggesting that distinguishing essential from extraneous\ndetails remains a pressing challenge. Surprisingly, performance regressions are\nrelatively insensitive to the complexity of the reasoning task, as measured by\nthe number of steps required, and are not strictly correlated with model size.\nMoreover, we observe that certain perturbations inadvertently trigger\nchain-of-thought-like reasoning behaviors, even without explicit prompting. Our\nfindings highlight critical vulnerabilities in current LLMs and underscore the\nneed for improved robustness against noisy, misleading, and contextually dense\ninputs, paving the way for more resilient and reliable reasoning in real-world\napplications.",
      "tldr_zh": "这篇论文通过在 GSM8K 数据集上系统引入四类提示扰动（如无关上下文、病态指令、事实相关但非本质上下文及其组合），评估了 13 个开源和闭源 LLMs 在数学问题解决任务中的推理鲁棒性。实验发现，引入无关上下文会显著降低模型性能，而这种退化与推理任务的步骤复杂性或模型大小并无直接相关性。令人意外的是，某些扰动会无意中触发 chain-of-thought-like 推理行为，这些结果突显了 LLMs 对嘈杂输入的脆弱性，并呼吁开发更可靠的模型以适应真实世界应用。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02111v1",
      "published_date": "2025-04-02 20:18:50 UTC",
      "updated_date": "2025-04-02 20:18:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:42:20.863506"
    },
    {
      "arxiv_id": "2504.02110v1",
      "title": "ScreenAudit: Detecting Screen Reader Accessibility Errors in Mobile Apps Using Large Language Models",
      "title_zh": "ScreenAudit：使用大型语言模型检测移动应用中的屏幕阅读器可访问性错误",
      "authors": [
        "Mingyuan Zhong",
        "Ruolin Chen",
        "Xia Chen",
        "James Fogarty",
        "Jacob O. Wobbrock"
      ],
      "abstract": "Many mobile apps are inaccessible, thereby excluding people from their\npotential benefits. Existing rule-based accessibility checkers aim to mitigate\nthese failures by identifying errors early during development but are\nconstrained in the types of errors they can detect. We present ScreenAudit, an\nLLM-powered system designed to traverse mobile app screens, extract metadata\nand transcripts, and identify screen reader accessibility errors overlooked by\nexisting checkers. We recruited six accessibility experts including one screen\nreader user to evaluate ScreenAudit's reports across 14 unique app screens. Our\nfindings indicate that ScreenAudit achieves an average coverage of 69.2%,\ncompared to only 31.3% with a widely-used accessibility checker. Expert\nfeedback indicated that ScreenAudit delivered higher-quality feedback and\naddressed more aspects of screen reader accessibility compared to existing\ncheckers, and that ScreenAudit would benefit app developers in real-world\nsettings.",
      "tldr_zh": "这篇论文介绍了 ScreenAudit，一种基于 Large Language Models (LLM) 的系统，用于检测移动应用中屏幕阅读器访问性错误。ScreenAudit 通过遍历应用屏幕、提取元数据和转录，识别现有基于规则的检查器无法捕捉的错误。实验结果显示，ScreenAudit 在14个独特应用屏幕上的平均覆盖率达到69.2%，远高于传统检查器的31.3%。专家反馈表明，该系统提供更高质量的反馈，并能在实际开发中帮助提升应用的访问性。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "CHI 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.02110v1",
      "published_date": "2025-04-02 20:18:45 UTC",
      "updated_date": "2025-04-02 20:18:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:42:32.597463"
    },
    {
      "arxiv_id": "2504.02094v1",
      "title": "FlowDistill: Scalable Traffic Flow Prediction via Distillation from LLMs",
      "title_zh": "FlowDistill：通过从LLMs知识蒸馏的可扩展交通流量预测",
      "authors": [
        "Chenyang Yu",
        "Xinpeng Xie",
        "Yan Huang",
        "Chenxi Qiu"
      ],
      "abstract": "Accurate traffic flow prediction is vital for optimizing urban mobility, yet\nit remains difficult in many cities due to complex spatio-temporal dependencies\nand limited high-quality data. While deep graph-based models demonstrate strong\npredictive power, their performance often comes at the cost of high\ncomputational overhead and substantial training data requirements, making them\nimpractical for deployment in resource-constrained or data-scarce environments.\nWe propose the FlowDistill, a lightweight and scalable traffic prediction\nframework based on knowledge distillation from large language models (LLMs). In\nthis teacher-student setup, a fine-tuned LLM guides a compact multi-layer\nperceptron (MLP) student model using a novel combination of the information\nbottleneck principle and teacher-bounded regression loss, ensuring the\ndistilled model retains only essential and transferable knowledge. Spatial and\ntemporal correlations are explicitly encoded to enhance the model's\ngeneralization across diverse urban settings. Despite its simplicity,\nFlowDistill consistently outperforms state-of-the-art models in prediction\naccuracy while requiring significantly less training data, and achieving lower\nmemory usage and inference latency, highlighting its efficiency and suitability\nfor real-world, scalable deployment.",
      "tldr_zh": "该研究提出FlowDistill，一种轻量级、可扩展的交通流量预测框架，通过从大语言模型(LLMs)进行知识蒸馏来解决复杂时空依赖和数据限制问题。框架采用教师-学生设置，其中fine-tuned的LLMs作为教师指导紧凑的多层感知器(MLP)学生模型，并结合信息瓶颈原理和教师边界回归损失，确保学生模型仅保留关键知识，同时显式编码空间和时间相关性以提升泛化能力。尽管简单，FlowDistill在预测准确性上优于现有状态-of-the-art模型，同时需要更少训练数据，并实现更低的内存使用和推理延迟，适合资源受限的实际部署。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02094v1",
      "published_date": "2025-04-02 19:54:54 UTC",
      "updated_date": "2025-04-02 19:54:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:42:44.881202"
    },
    {
      "arxiv_id": "2504.02087v1",
      "title": "An Introductory Survey to Autoencoder-based Deep Clustering -- Sandboxes for Combining Clustering with Deep Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Collin Leiber",
        "Lukas Miklautz",
        "Claudia Plant",
        "Christian Böhm"
      ],
      "abstract": "Autoencoders offer a general way of learning low-dimensional, non-linear\nrepresentations from data without labels. This is achieved without making any\nparticular assumptions about the data type or other domain knowledge. The\ngenerality and domain agnosticism in combination with their simplicity make\nautoencoders a perfect sandbox for researching and developing novel (deep)\nclustering algorithms. Clustering methods group data based on similarity, a\ntask that benefits from the lower-dimensional representation learned by an\nautoencoder, mitigating the curse of dimensionality. Specifically, the\ncombination of deep learning with clustering, called Deep Clustering, enables\nto learn a representation tailored to specific clustering tasks, leading to\nhigh-quality results. This survey provides an introduction to fundamental\nautoencoder-based deep clustering algorithms that serve as building blocks for\nmany modern approaches.",
      "tldr_zh": "这篇调查论文介绍了基于 Autoencoders 的深度聚类方法，作为结合聚类与深度学习的实验平台。Autoencoders 能够无标签地学习低维非线性表示，而不依赖特定数据类型或领域知识，从而缓解维度灾难并提升聚类任务的性能。深度聚类（Deep Clustering）通过针对特定任务优化表示，产生高质量结果，该论文总结了基本 Autoencoder-based 深度聚类算法，作为许多现代方法的构建基块。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02087v1",
      "published_date": "2025-04-02 19:46:22 UTC",
      "updated_date": "2025-04-02 19:46:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:42:55.791625"
    },
    {
      "arxiv_id": "2504.02080v1",
      "title": "Evolving Security in LLMs: A Study of Jailbreak Attacks and Defenses",
      "title_zh": "LLMs 中的安全性演变：对越狱攻击和防御的研究",
      "authors": [
        "Zhengchun Shang",
        "Wenlan Wei"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly popular, powering a wide range\nof applications. Their widespread use has sparked concerns, especially through\njailbreak attacks that bypass safety measures to produce harmful content.\n  In this paper, we present a comprehensive security analysis of large language\nmodels (LLMs), addressing critical research questions on the evolution and\ndeterminants of model safety.\n  Specifically, we begin by identifying the most effective techniques for\ndetecting jailbreak attacks. Next, we investigate whether newer versions of\nLLMs offer improved security compared to their predecessors. We also assess the\nimpact of model size on overall security and explore the potential benefits of\nintegrating multiple defense strategies to enhance model robustness.\n  Our study evaluates both open-source models (e.g., LLaMA and Mistral) and\nclosed-source systems (e.g., GPT-4) by employing four state-of-the-art attack\ntechniques and assessing the efficacy of three new defensive approaches.",
      "tldr_zh": "该研究分析了大型语言模型（LLMs）的安全演变，重点探讨了jailbreak attacks（越狱攻击）如何绕过安全措施生成有害内容，并评估了多种防御策略。论文通过识别最有效的攻击检测技术，比较新旧LLMs版本的安全性，评估模型大小对安全性的影响，以及测试整合多重防御方法的益处，进行了全面评估。实验涉及开源模型（如LLaMA和Mistral）和闭源系统（如GPT-4），使用四种state-of-the-art攻击技术，并评估三种新防御方法，最终为提升LLMs的鲁棒性提供了关键见解。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02080v1",
      "published_date": "2025-04-02 19:33:07 UTC",
      "updated_date": "2025-04-02 19:33:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:43:08.434134"
    },
    {
      "arxiv_id": "2504.02074v1",
      "title": "Trapped by Expectations: Functional Fixedness in LLM-Enabled Chat Search",
      "title_zh": "被期望所困：LLM 启用聊天搜索中的功能固着",
      "authors": [
        "Jiqun Liu",
        "Jamshed Karimnazarov",
        "Ryen W. White"
      ],
      "abstract": "Functional fixedness, a cognitive bias that restricts users' interactions\nwith a new system or tool to expected or familiar ways, limits the full\npotential of Large Language Model (LLM)-enabled chat search, especially in\ncomplex and exploratory tasks. To investigate its impact, we conducted a\ncrowdsourcing study with 450 participants, each completing one of six\ndecision-making tasks spanning public safety, diet and health management,\nsustainability, and AI ethics. Participants engaged in a multi-prompt\nconversation with ChatGPT to address the task, allowing us to compare pre-chat\nintent-based expectations with observed interactions. We found that: 1) Several\naspects of pre-chat expectations are closely associated with users' prior\nexperiences with ChatGPT, search engines, and virtual assistants; 2) Prior\nsystem experience shapes language use and prompting behavior. Frequent ChatGPT\nusers reduced deictic terms and hedge words and frequently adjusted prompts.\nUsers with rich search experience maintained structured, less-conversational\nqueries with minimal modifications. Users of virtual assistants favored\ndirective, command-like prompts, reinforcing functional fixedness; 3) When the\nsystem failed to meet expectations, participants generated more detailed\nprompts with increased linguistic diversity, reflecting adaptive shifts. These\nfindings suggest that while preconceived expectations constrain early\ninteractions, unmet expectations can motivate behavioral adaptation. With\nappropriate system support, this may promote broader exploration of LLM\ncapabilities. This work also introduces a typology for user intents in chat\nsearch and highlights the importance of mitigating functional fixedness to\nsupport more creative and analytical use of LLMs.",
      "tldr_zh": "本文研究了功能固定性（Functional Fixedness），一种认知偏差如何限制用户在LLM-enabled chat search中的互动，导致他们在复杂任务中无法充分发挥潜力。通过一项涉及450名参与者的众包研究，用户完成六种决策任务（如公共安全和AI伦理），并与ChatGPT进行多提示对话，比较预聊天意图期望与实际行为。研究发现，先前经验（如ChatGPT使用或搜索引擎习惯）影响提示语言和调整策略，而系统失败时用户会生成更详细、多样化的提示，促进适应行为；最终，论文引入用户意图分类，并强调缓解功能固定性以支持LLM的更具创造性和分析性应用。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "H.3.3"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02074v1",
      "published_date": "2025-04-02 19:14:01 UTC",
      "updated_date": "2025-04-02 19:14:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:43:21.320958"
    },
    {
      "arxiv_id": "2504.02069v1",
      "title": "RoboAct-CLIP: Video-Driven Pre-training of Atomic Action Understanding for Robotics",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiyuan Zhang",
        "Yuxin He",
        "Yong Sun",
        "Junyu Shi",
        "Lijiang Liu",
        "Qiang Nie"
      ],
      "abstract": "Visual Language Models (VLMs) have emerged as pivotal tools for robotic\nsystems, enabling cross-task generalization, dynamic environmental interaction,\nand long-horizon planning through multimodal perception and semantic reasoning.\nHowever, existing open-source VLMs predominantly trained for generic\nvision-language alignment tasks fail to model temporally correlated action\nsemantics that are crucial for robotic manipulation effectively. While current\nimage-based fine-tuning methods partially adapt VLMs to robotic applications,\nthey fundamentally disregard temporal evolution patterns in video sequences and\nsuffer from visual feature entanglement between robotic agents, manipulated\nobjects, and environmental contexts, thereby limiting semantic decoupling\ncapability for atomic actions and compromising model generalizability.To\novercome these challenges, this work presents RoboAct-CLIP with dual technical\ncontributions: 1) A dataset reconstruction framework that performs\nsemantic-constrained action unit segmentation and re-annotation on open-source\nrobotic videos, constructing purified training sets containing singular atomic\nactions (e.g., \"grasp\"); 2) A temporal-decoupling fine-tuning strategy based on\nContrastive Language-Image Pretraining (CLIP) architecture, which disentangles\ntemporal action features across video frames from object-centric\ncharacteristics to achieve hierarchical representation learning of robotic\natomic actions.Experimental results in simulated environments demonstrate that\nthe RoboAct-CLIP pretrained model achieves a 12% higher success rate than\nbaseline VLMs, along with superior generalization in multi-object manipulation\ntasks.",
      "tldr_zh": "该研究针对现有 Visual Language Models (VLMs) 在机器人操作中的局限性（如无法有效处理 temporally correlated action semantics 和 visual feature entanglement），提出了一种视频驱动的预训练框架RoboAct-CLIP。框架的核心贡献包括：1) 一个dataset reconstruction框架，通过semantic-constrained action unit segmentation和re-annotation，对开源机器人视频进行处理，构建只包含单一atomic actions（如“grasp”）的纯净训练集；2) 基于CLIP架构的temporal-decoupling fine-tuning策略，解耦视频帧中的动作时间特征和对象中心特征，实现hierarchical representation learning。在模拟环境中，RoboAct-CLIP比基线VLMs成功率提高12%，并在multi-object manipulation任务中展现出更好的泛化能力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "IROS 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.02069v1",
      "published_date": "2025-04-02 19:02:08 UTC",
      "updated_date": "2025-04-02 19:02:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:43:34.022095"
    },
    {
      "arxiv_id": "2504.02064v1",
      "title": "From Text to Graph: Leveraging Graph Neural Networks for Enhanced Explainability in NLP",
      "title_zh": "从文本到图形：利用图神经网络提升自然语言处理中的可解释性",
      "authors": [
        "Fabio Yáñez-Romero",
        "Andrés Montoyo",
        "Armando Suárez",
        "Yoan Gutiérrez",
        "Ruslan Mitkov"
      ],
      "abstract": "Researchers have relegated natural language processing tasks to\nTransformer-type models, particularly generative models, because these models\nexhibit high versatility when performing generation and classification tasks.\nAs the size of these models increases, they achieve outstanding results. Given\ntheir widespread use, many explainability techniques are developed based on\nthese models. However, this process becomes computationally expensive due to\nthe large size of the models. Additionally, transformers interpret input\ninformation through tokens that fragment input words into sequences lacking\ninherent semantic meaning, complicating the explanation of the model from the\nvery beginning. This study proposes a novel methodology to achieve\nexplainability in natural language processing tasks by automatically converting\nsentences into graphs and maintaining semantics through nodes and relations\nthat express fundamental linguistic concepts. It also allows the subsequent\nexploitation of this knowledge in subsequent tasks, making it possible to\nobtain trends and understand how the model associates the different elements\ninside the text with the explained task. The experiments delivered promising\nresults in determining the most critical components within the text structure\nfor a given classification.",
      "tldr_zh": "本研究针对Transformer模型在NLP任务中的解释性问题（如计算成本高和tokens缺乏语义），提出了一种新方法：将文本自动转换为图（graphs），通过节点和关系保持基本的语言概念，从而增强模型的可解释性。利用Graph Neural Networks (GNNs)，该方法允许后续任务分析文本元素间的关联，并识别关键组件。该方法在分类任务的实验中取得了有前景的结果，展示了如何更好地理解模型决策过程。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02064v1",
      "published_date": "2025-04-02 18:55:58 UTC",
      "updated_date": "2025-04-02 18:55:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:43:45.290154"
    },
    {
      "arxiv_id": "2504.02894v3",
      "title": "OnRL-RAG: Real-Time Personalized Mental Health Dialogue System",
      "title_zh": "OnRL-RAG：实时个性化的心理健康对话系统",
      "authors": [
        "Ahsan Bilal",
        "Beiyu Lin"
      ],
      "abstract": "Large language models (LLMs) have been widely used for various tasks and\napplications. However, LLMs and fine-tuning are limited to the pre-trained\ndata. For example, ChatGPT's world knowledge until 2021 can be outdated or\ninaccurate. To enhance the capabilities of LLMs, Retrieval-Augmented Generation\n(RAG), is proposed to augment LLMs with additional, new, latest details and\ninformation to LLMs. While RAG offers the correct information, it may not best\npresent it, especially to different population groups with personalizations.\nReinforcement Learning from Human Feedback (RLHF) adapts to user needs by\naligning model responses with human preference through feedback loops. In\nreal-life applications, such as mental health problems, a dynamic and\nfeedback-based model would continuously adapt to new information and offer\npersonalized assistance due to complex factors fluctuating in a daily\nenvironment. Thus, we propose an Online Reinforcement Learning-based\nRetrieval-Augmented Generation (OnRL-RAG) system to detect and personalize the\nresponding systems to mental health problems, such as stress, anxiety, and\ndepression. We use an open-source dataset collected from 2028 College Students\nwith 28 survey questions for each student to demonstrate the performance of our\nproposed system with the existing systems. Our system achieves superior\nperformance compared to standard RAG and simple LLM via GPT-4o, GPT-4o-mini,\nGemini-1.5, and GPT-3.5. This work would open up the possibilities of real-life\napplications of LLMs for personalized services in the everyday environment. The\nresults will also help researchers in the fields of sociology, psychology, and\nneuroscience to align their theories more closely with the actual human daily\nenvironment.",
      "tldr_zh": "该研究针对大型语言模型(LLMs)的预训练数据局限性，提出OnRL-RAG系统，该系统结合在线强化学习(Online Reinforcement Learning)和检索增强生成(RAG)，以实现实时个性化心理健康对话。OnRL-RAG通过用户反馈循环适应不同人群的需求，专注于处理压力、焦虑和抑郁等问题，并使用2028名大学生的数据集进行验证。实验结果显示，该系统在GPT-4o、GPT-4o-mini、Gemini-1.5和GPT-3.5上优于标准RAG和简单LLM，提升了响应准确性和个性化效果。该工作为LLMs在日常生活中的个性化服务打开了应用前景，并有助于心理学和社会学等领域的研究与实践。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "It needs more revisions. I am currently working on it with my\n  co-author",
      "pdf_url": "http://arxiv.org/pdf/2504.02894v3",
      "published_date": "2025-04-02 18:44:53 UTC",
      "updated_date": "2025-04-22 22:32:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:43:57.005436"
    },
    {
      "arxiv_id": "2504.02058v1",
      "title": "Epistemic Closure and the Irreversibility of Misalignment: Modeling Systemic Barriers to Alignment Innovation",
      "title_zh": "翻译失败",
      "authors": [
        "Andy Williams"
      ],
      "abstract": "Efforts to ensure the safe development of artificial general intelligence\n(AGI) often rely on consensus-based alignment approaches grounded in axiomatic\nformalism, interpretability, and empirical validation. However, these methods\nmay be structurally unable to recognize or incorporate novel solutions that\nfall outside their accepted epistemic frameworks. This paper introduces a\nfunctional model of epistemic closure, in which cognitive, institutional,\nsocial, and infrastructural filters combine to make many alignment proposals\nillegible to existing evaluation systems. We present a weighted closure model\nsupported by both theoretical and empirical sources, including a meta-analysis\nperformed by an AI system on patterns of rejection and non-engagement with a\nframework for decentralized collective intelligence (DCI). We argue that the\nrecursive failure to assess models like DCI is not just a sociological\noversight but a structural attractor, mirroring the very risks of misalignment\nwe aim to avoid in AGI. Without the adoption of DCI or a similarly recursive\nmodel of epistemic correction, we may be on a predictable path toward\nirreversible misalignment. The development and acceptance of this paper, first\nthrough simulated review and then through formal channels, provide a case study\nsupporting its central claim: that epistemic closure can only be overcome by\nrecursive modeling of the constraints that sustain it.",
      "tldr_zh": "该论文探讨了人工通用智能（AGI）安全发展中，基于共识的 alignment 方法可能因 epistemic closure（认识论封闭）而无法识别新颖解决方案的问题。作者引入了一个功能模型，包括认知、制度、社会和基础设施过滤器，并通过加权 closure 模型及对 decentralized collective intelligence (DCI) 的元分析，提供理论和实证支持。研究发现，这种结构性障碍是递归性的，可能导致不可逆的 misalignment，并主张采用 DCI 或类似递归模型来打破 epistemic closure，从而避免 AGI 风险。论文本身作为案例研究，证明了克服认识论封闭的必要性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02058v1",
      "published_date": "2025-04-02 18:35:15 UTC",
      "updated_date": "2025-04-02 18:35:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:44:08.883784"
    },
    {
      "arxiv_id": "2504.02051v2",
      "title": "Self-Resource Allocation in Multi-Agent LLM Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Alfonso Amayuelas",
        "Jingbo Yang",
        "Saaket Agashe",
        "Ashwin Nagarajan",
        "Antonis Antoniades",
        "Xin Eric Wang",
        "William Wang"
      ],
      "abstract": "With the development of LLMs as agents, there is a growing interest in\nconnecting multiple agents into multi-agent systems to solve tasks\nconcurrently, focusing on their role in task assignment and coordination. This\npaper explores how LLMs can effectively allocate computational tasks among\nmultiple agents, considering factors such as cost, efficiency, and performance.\nIn this work, we address key questions, including the effectiveness of LLMs as\norchestrators and planners, comparing their effectiveness in task assignment\nand coordination. Our experiments demonstrate that LLMs can achieve high\nvalidity and accuracy in resource allocation tasks. We find that the planner\nmethod outperforms the orchestrator method in handling concurrent actions,\nresulting in improved efficiency and better utilization of agents.\nAdditionally, we show that providing explicit information about worker\ncapabilities enhances the allocation strategies of planners, particularly when\ndealing with suboptimal workers.",
      "tldr_zh": "这篇论文探讨了在多智能体LLM系统中，LLMs如何实现自我资源分配，以优化任务分配和协调，考虑因素如成本、效率和性能。研究通过实验比较了LLMs作为orchestrators和planners的有效性，结果显示planner方法在处理并发动作时表现出色，能提升效率和代理利用率。作者进一步发现，提供显式工人能力信息可显著改善规划者的分配策略，特别是应对次优工人时。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02051v2",
      "published_date": "2025-04-02 18:15:41 UTC",
      "updated_date": "2025-04-19 19:05:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:44:21.250352"
    },
    {
      "arxiv_id": "2504.02891v1",
      "title": "Automated Survey Collection with LLM-based Conversational Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Kurmanbek Kaiyrbekov",
        "Nicholas J Dobbins",
        "Sean D Mooney"
      ],
      "abstract": "Objective: Traditional phone-based surveys are among the most accessible and\nwidely used methods to collect biomedical and healthcare data, however, they\nare often costly, labor intensive, and difficult to scale effectively. To\novercome these limitations, we propose an end-to-end survey collection\nframework driven by conversational Large Language Models (LLMs).\n  Materials and Methods: Our framework consists of a researcher responsible for\ndesigning the survey and recruiting participants, a conversational phone agent\npowered by an LLM that calls participants and administers the survey, a second\nLLM (GPT-4o) that analyzes the conversation transcripts generated during the\nsurveys, and a database for storing and organizing the results. To test our\nframework, we recruited 8 participants consisting of 5 native and 3 non-native\nenglish speakers and administered 40 surveys. We evaluated the correctness of\nLLM-generated conversation transcripts, accuracy of survey responses inferred\nby GPT-4o and overall participant experience.\n  Results: Survey responses were successfully extracted by GPT-4o from\nconversation transcripts with an average accuracy of 98% despite transcripts\nexhibiting an average per-line word error rate of 7.7%. While participants\nnoted occasional errors made by the conversational LLM agent, they reported\nthat the agent effectively conveyed the purpose of the survey, demonstrated\ngood comprehension, and maintained an engaging interaction.\n  Conclusions: Our study highlights the potential of LLM agents in conducting\nand analyzing phone surveys for healthcare applications. By reducing the\nworkload on human interviewers and offering a scalable solution, this approach\npaves the way for real-world, end-to-end AI-powered phone survey collection\nsystems.",
      "tldr_zh": "这篇论文提出了一种基于对话式 Large Language Models (LLMs) 的端到端框架，用于自动化电话调查收集，以解决传统方法在生物医学和医疗领域的成本高、劳动密集和扩展困难问题。框架包括研究人员设计调查、LLM 驱动的电话代理进行互动、GPT-4o 分析对话记录，以及数据库存储结果；在测试中，招募 8 名参与者进行了 40 次调查。结果显示，GPT-4o 从对话记录中提取调查响应准确率达 98%，尽管记录有 7.7% 的每行词错误率，且参与者反馈代理能有效传达目的并保持互动。该框架通过减少人类面试官负担，提供可扩展的 AI 解决方案，为医疗电话调查应用铺平道路。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02891v1",
      "published_date": "2025-04-02 18:10:19 UTC",
      "updated_date": "2025-04-02 18:10:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:44:33.162928"
    },
    {
      "arxiv_id": "2504.01951v1",
      "title": "The LLM Wears Prada: Analysing Gender Bias and Stereotypes through Online Shopping Data",
      "title_zh": "LLM 身着 Prada：通过在线购物数据分析性别偏见和刻板印象",
      "authors": [
        "Massimiliano Luca",
        "Ciro Beneduce",
        "Bruno Lepri",
        "Jacopo Staiano"
      ],
      "abstract": "With the wide and cross-domain adoption of Large Language Models, it becomes\ncrucial to assess to which extent the statistical correlations in training\ndata, which underlie their impressive performance, hide subtle and potentially\ntroubling biases. Gender bias in LLMs has been widely investigated from the\nperspectives of works, hobbies, and emotions typically associated with a\nspecific gender. In this study, we introduce a novel perspective. We\ninvestigate whether LLMs can predict an individual's gender based solely on\nonline shopping histories and whether these predictions are influenced by\ngender biases and stereotypes. Using a dataset of historical online purchases\nfrom users in the United States, we evaluate the ability of six LLMs to\nclassify gender and we then analyze their reasoning and products-gender\nco-occurrences. Results indicate that while models can infer gender with\nmoderate accuracy, their decisions are often rooted in stereotypical\nassociations between product categories and gender. Furthermore, explicit\ninstructions to avoid bias reduce the certainty of model predictions, but do\nnot eliminate stereotypical patterns. Our findings highlight the persistent\nnature of gender biases in LLMs and emphasize the need for robust\nbias-mitigation strategies.",
      "tldr_zh": "这篇论文探讨了大型语言模型（LLMs）在基于在线购物数据预测性别时的性别偏见和刻板印象问题，引入了新视角来补充现有研究。研究方法包括使用美国用户的历史购物数据集，评估六个LLMs的性别分类准确率，并分析它们的推理过程和产品类别与性别的共现关系。结果显示，模型能以中等准确率推断性别，但决策往往依赖于刻板印象，例如将特定产品与特定性别关联。即使提供避免偏见的明确指令，偏见模式并未完全消除。该研究强调了LLMs中性别偏见的顽固性，并呼吁开发更有效的偏见缓解策略。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01951v1",
      "published_date": "2025-04-02 17:56:08 UTC",
      "updated_date": "2025-04-02 17:56:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:44:45.217528"
    },
    {
      "arxiv_id": "2504.01947v1",
      "title": "Efficient Federated Learning Tiny Language Models for Mobile Network Feature Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Becking",
        "Ingo Friese",
        "Karsten Müller",
        "Thomas Buchholz",
        "Mandy Galkow-Schneider",
        "Wojciech Samek",
        "Detlev Marpe"
      ],
      "abstract": "In telecommunications, Autonomous Networks (ANs) automatically adjust\nconfigurations based on specific requirements (e.g., bandwidth) and available\nresources. These networks rely on continuous monitoring and intelligent\nmechanisms for self-optimization, self-repair, and self-protection, nowadays\nenhanced by Neural Networks (NNs) to enable predictive modeling and pattern\nrecognition. Here, Federated Learning (FL) allows multiple AN cells - each\nequipped with NNs - to collaboratively train models while preserving data\nprivacy. However, FL requires frequent transmission of large neural data and\nthus an efficient, standardized compression strategy for reliable\ncommunication. To address this, we investigate NNCodec, a Fraunhofer\nimplementation of the ISO/IEC Neural Network Coding (NNC) standard, within a\nnovel FL framework that integrates tiny language models (TLMs) for various\nmobile network feature prediction (e.g., ping, SNR or band frequency). Our\nexperimental results on the Berlin V2X dataset demonstrate that NNCodec\nachieves transparent compression (i.e., negligible performance loss) while\nreducing communication overhead to below 1%, showing the effectiveness of\ncombining NNC with FL in collaboratively learned autonomous mobile networks.",
      "tldr_zh": "该研究探讨了在电信自治网络（Autonomous Networks, ANs）中，使用Federated Learning (FL)结合tiny language models (TLMs)来预测移动网络特征（如ping、SNR或band frequency），以实现高效的协作训练和数据隐私保护。论文提出一个新框架，整合Fraunhofer实现的NNCodec（基于ISO/IEC Neural Network Coding (NNC)标准）来压缩神经数据，减少传输开销。实验在Berlin V2X数据集上表明，NNCodec实现了透明压缩（negligible performance loss），将通信开销降低至低于1%，证明了这一方法在FL增强自治移动网络中的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at 2025 EuCNC & 6G Summit Poster Session",
      "pdf_url": "http://arxiv.org/pdf/2504.01947v1",
      "published_date": "2025-04-02 17:54:06 UTC",
      "updated_date": "2025-04-02 17:54:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:44:56.719463"
    },
    {
      "arxiv_id": "2504.01935v1",
      "title": "Critical Thinking: Which Kinds of Complexity Govern Optimal Reasoning Length?",
      "title_zh": "批判性思维：哪些种类的复杂性决定了最优推理长度？",
      "authors": [
        "Celine Lee",
        "Alexander M. Rush",
        "Keyon Vafa"
      ],
      "abstract": "Large language models (LLMs) often benefit from verbalized reasoning at\ninference time, but it remains unclear which aspects of task difficulty these\nextra reasoning tokens address. To investigate this question, we formalize a\nframework using deterministic finite automata (DFAs). DFAs offer a formalism\nthrough which we can characterize task complexity through measurable properties\nsuch as run length (number of reasoning steps required) and state-space size\n(decision complexity). We first show that across different tasks and models of\ndifferent sizes and training paradigms, there exists an optimal amount of\nreasoning tokens such that the probability of producing a correct solution is\nmaximized. We then investigate which properties of complexity govern this\ncritical length: we find that task instances with longer corresponding\nunderlying DFA runs (i.e. demand greater latent state-tracking requirements)\ncorrelate with longer reasoning lengths, but, surprisingly, that DFA size (i.e.\nstate-space complexity) does not. We then demonstrate an implication of these\nfindings: being able to predict the optimal number of reasoning tokens for new\nproblems and filtering out non-optimal length answers results in consistent\naccuracy improvements.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 在推理过程中额外推理标记的最佳长度问题，使用确定性有限自动机 (DFAs) 框架来表征任务复杂度，包括运行长度（推理步骤数）和状态空间大小（决策复杂度）。研究发现，对于不同任务和模型，存在一个最佳推理标记数量，能最大化正确解决方案的概率，且这一长度主要受任务的潜在状态跟踪要求（即DFA运行长度）影响，而非DFA的大小（状态空间复杂度）。最终，论文证明，通过预测最佳推理标记数量并过滤非最佳长度答案，可以实现一致的准确性提升。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01935v1",
      "published_date": "2025-04-02 17:45:58 UTC",
      "updated_date": "2025-04-02 17:45:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:45:08.258984"
    },
    {
      "arxiv_id": "2504.01930v1",
      "title": "A thorough benchmark of automatic text classification: From traditional approaches to large language models",
      "title_zh": "自动文本分类的彻底基准测试：从传统方法到大型语言模型",
      "authors": [
        "Washington Cunha",
        "Leonardo Rocha",
        "Marcos André Gonçalves"
      ],
      "abstract": "Automatic text classification (ATC) has experienced remarkable advancements\nin the past decade, best exemplified by recent small and large language models\n(SLMs and LLMs), leveraged by Transformer architectures. Despite recent\neffectiveness improvements, a comprehensive cost-benefit analysis investigating\nwhether the effectiveness gains of these recent approaches compensate their\nmuch higher costs when compared to more traditional text classification\napproaches such as SVMs and Logistic Regression is still missing in the\nliterature. In this context, this work's main contributions are twofold: (i) we\nprovide a scientifically sound comparative analysis of the cost-benefit of\ntwelve traditional and recent ATC solutions including five open LLMs, and (ii)\na large benchmark comprising {22 datasets}, including sentiment analysis and\ntopic classification, with their (train-validation-test) partitions based on\nfolded cross-validation procedures, along with documentation, and code. The\nrelease of code, data, and documentation enables the community to replicate\nexperiments and advance the field in a more scientifically sound manner. Our\ncomparative experimental results indicate that LLMs outperform traditional\napproaches (up to 26%-7.1% on average) and SLMs (up to 4.9%-1.9% on average) in\nterms of effectiveness. However, LLMs incur significantly higher computational\ncosts due to fine-tuning, being, on average 590x and 8.5x slower than\ntraditional methods and SLMs, respectively. Results suggests the following\nrecommendations: (1) LLMs for applications that require the best possible\neffectiveness and can afford the costs; (2) traditional methods such as\nLogistic Regression and SVM for resource-limited applications or those that\ncannot afford the cost of tuning large LLMs; and (3) SLMs like Roberta for\nnear-optimal effectiveness-efficiency trade-off.",
      "tldr_zh": "本研究对自动文本分类(ATC)方法进行了全面基准测试，比较了传统方法（如 SVM 和 Logistic Regression）与现代方法（如 SLMs 和 LLMs）的成本效益。论文的主要贡献包括：提供了一个科学严谨的比较分析，以及一个包含22个数据集的基准（涵盖情感分析和主题分类），并公开了代码、数据和文档以促进可复制性。实验结果显示，LLMs在有效性上优于传统方法（平均提高26%-7.1%）和SLMs（平均提高4.9%-1.9%），但计算成本更高，平均比传统方法慢590倍，比SLMs慢8.5倍。根据这些发现，推荐在需要最佳有效性的高资源场景下使用LLMs，在资源有限的环境下优先选择传统方法，而SLMs如Roberta则适合有效性与效率的平衡。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "7 pages, 2 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.01930v1",
      "published_date": "2025-04-02 17:40:08 UTC",
      "updated_date": "2025-04-02 17:40:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:45:20.727002"
    },
    {
      "arxiv_id": "2504.01925v1",
      "title": "Equivariant Spherical CNNs for Accurate Fiber Orientation Distribution Estimation in Neonatal Diffusion MRI with Reduced Acquisition Time",
      "title_zh": "翻译失败",
      "authors": [
        "Haykel Snoussi",
        "Davood Karimi"
      ],
      "abstract": "Early and accurate assessment of brain microstructure using diffusion\nMagnetic Resonance Imaging (dMRI) is crucial for identifying neurodevelopmental\ndisorders in neonates, but remains challenging due to low signal-to-noise ratio\n(SNR), motion artifacts, and ongoing myelination. In this study, we propose a\nrotationally equivariant Spherical Convolutional Neural Network (sCNN)\nframework tailored for neonatal dMRI. We predict the Fiber Orientation\nDistribution (FOD) from multi-shell dMRI signals acquired with a reduced set of\ngradient directions (30% of the full protocol), enabling faster and more\ncost-effective acquisitions. We train and evaluate the performance of our sCNN\nusing real data from 43 neonatal dMRI datasets provided by the Developing Human\nConnectome Project (dHCP). Our results demonstrate that the sCNN achieves\nsignificantly lower mean squared error (MSE) and higher angular correlation\ncoefficient (ACC) compared to a Multi-Layer Perceptron (MLP) baseline,\nindicating improved accuracy in FOD estimation. Furthermore, tractography\nresults based on the sCNN-predicted FODs show improved anatomical plausibility,\ncoverage, and coherence compared to those from the MLP. These findings\nhighlight that sCNNs, with their inherent rotational equivariance, offer a\npromising approach for accurate and clinically efficient dMRI analysis, paving\nthe way for improved diagnostic capabilities and characterization of early\nbrain development.",
      "tldr_zh": "本研究提出了一种旋转等变 Spherical Convolutional Neural Network (sCNN) 框架，用于新生儿扩散磁共振成像 (dMRI) 中的 Fiber Orientation Distribution (FOD) 估计。该方法从减少梯度方向（仅为完整协议的30%）的多壳 dMRI 信号中预测 FOD，从而缩短采集时间并降低成本。实验使用 Developing Human Connectome Project (dHCP) 的43个数据集进行评估，结果显示 sCNN 比 Multi-Layer Perceptron (MLP) 基线模型具有更低的均方误差 (MSE) 和更高的角度相关系数 (ACC)，并在轨迹追踪 (tractography) 中实现了更好的解剖合理性、覆盖度和连贯性。这些发现表明，sCNN 的旋转等变性为临床高效的 dMRI 分析提供了新途径，提升了新生儿神经发育障碍的诊断和早期脑发育表征。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01925v1",
      "published_date": "2025-04-02 17:36:51 UTC",
      "updated_date": "2025-04-02 17:36:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:45:33.509949"
    },
    {
      "arxiv_id": "2504.01919v2",
      "title": "Bridging the Linguistic Divide: A Survey on Leveraging Large Language Models for Machine Translation",
      "title_zh": "翻译失败",
      "authors": [
        "Baban Gain",
        "Dibyanayan Bandyopadhyay",
        "Asif Ekbal"
      ],
      "abstract": "The advent of Large Language Models (LLMs) has significantly reshaped the\nlandscape of machine translation (MT), particularly for low-resource languages\nand domains that lack sufficient parallel corpora, linguistic tools, and\ncomputational infrastructure. This survey presents a comprehensive overview of\nrecent progress in leveraging LLMs for MT. We analyze techniques such as\nfew-shot prompting, cross-lingual transfer, and parameter-efficient fine-tuning\nthat enable effective adaptation to under-resourced settings. The paper also\nexplores synthetic data generation strategies using LLMs, including\nback-translation and lexical augmentation. Additionally, we compare LLM-based\ntranslation with traditional encoder-decoder models across diverse language\npairs, highlighting the strengths and limitations of each. We discuss\npersistent challenges such as hallucinations, evaluation inconsistencies, and\ninherited biases while also evaluating emerging LLM-driven metrics for\ntranslation quality. This survey offers practical insights and outlines future\ndirections for building robust, inclusive, and scalable MT systems in the era\nof large-scale generative models.",
      "tldr_zh": "这篇调查论文探讨了大型语言模型（LLMs）在机器翻译（MT）领域的应用，特别是针对低资源语言和缺乏数据支持的场景。论文分析了多种技术，包括few-shot prompting、cross-lingual transfer和parameter-efficient fine-tuning，以实现有效适应和优化。研究比较了LLM-based翻译与传统encoder-decoder模型的优缺点，并评估了合成数据生成策略如back-translation和lexical augmentation的效果，同时指出了hallucinations、evaluation inconsistencies和inherited biases等挑战。最终，该论文提供了实用见解，并为构建更robust、inclusive和scalable的MT系统指出了未来方向。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01919v2",
      "published_date": "2025-04-02 17:26:40 UTC",
      "updated_date": "2025-04-03 13:30:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:45:43.887896"
    },
    {
      "arxiv_id": "2504.01916v1",
      "title": "FineLIP: Extending CLIP's Reach via Fine-Grained Alignment with Longer Text Inputs",
      "title_zh": "FineLIP：通过细粒度对齐与更",
      "authors": [
        "Mothilal Asokan",
        "Kebin Wu",
        "Fatima Albreiki"
      ],
      "abstract": "As a pioneering vision-language model, CLIP (Contrastive Language-Image\nPre-training) has achieved significant success across various domains and a\nwide range of downstream vision-language tasks. However, the text encoders in\npopular CLIP models are limited to processing only 77 text tokens, which\nconstrains their ability to effectively handle longer, detail-rich captions.\nAdditionally, CLIP models often struggle to effectively capture detailed visual\nand textual information, which hampers their performance on tasks that require\nfine-grained analysis. To address these limitations, we present a novel\napproach, \\textbf{FineLIP}, that extends the capabilities of CLIP. FineLIP\nenhances cross-modal text-image mapping by incorporating \\textbf{Fine}-grained\nalignment with \\textbf{L}onger text input within the CL\\textbf{IP}-style\nframework. FineLIP first extends the positional embeddings to handle longer\ntext, followed by the dynamic aggregation of local image and text tokens. The\naggregated results are then used to enforce fine-grained token-to-token\ncross-modal alignment. We validate our model on datasets with long, detailed\ncaptions across two tasks: zero-shot cross-modal retrieval and text-to-image\ngeneration. Quantitative and qualitative experimental results demonstrate the\neffectiveness of FineLIP, outperforming existing state-of-the-art approaches.\nFurthermore, comprehensive ablation studies validate the benefits of key design\nelements within FineLIP.",
      "tldr_zh": "该研究针对 CLIP 模型的局限性，即文本编码器仅处理 77 个标记且难以捕捉细粒度视觉和文本信息，提出了一种新型方法 FineLIP，以提升其处理更长文本输入的能力。FineLIP 通过扩展位置嵌入、动态聚合本地图像和文本标记，以及强制细粒度 token-to-token 跨模态对齐，来实现更精确的文本-图像映射。实验在零-shot cross-modal retrieval 和 text-to-image generation 任务上验证了 FineLIP 的有效性，其在长详细标题数据集上优于现有最先进方法，并通过消融研究证实了关键设计元素的益处。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01916v1",
      "published_date": "2025-04-02 17:19:59 UTC",
      "updated_date": "2025-04-02 17:19:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:45:56.587514"
    },
    {
      "arxiv_id": "2504.01911v1",
      "title": "Advancing AI-Scientist Understanding: Making LLM Think Like a Physicist with Interpretable Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Yinggan Xu",
        "Hana Kimlee",
        "Yijia Xiao",
        "Di Luo"
      ],
      "abstract": "Large Language Models (LLMs) are playing an expanding role in physics\nresearch by enhancing reasoning, symbolic manipulation, and numerical\ncomputation. However, ensuring the reliability and interpretability of their\noutputs remains a significant challenge. In our framework, we conceptualize the\ncollaboration between AI and human scientists as a dynamic interplay among\nthree modules: the reasoning module, the interpretation module, and the\nAI-scientist interaction module. Recognizing that effective physics reasoning\ndemands rigorous logical consistency, quantitative precision, and deep\nintegration with established theoretical models, we introduce the\ninterpretation module to improve the understanding of AI-generated outputs,\nwhich is not previously explored in the literature. This module comprises\nmultiple specialized agents, including summarizers, model builders, UI\nbuilders, and testers, which collaboratively structure LLM outputs within a\nphysically grounded framework, by constructing a more interpretable science\nmodel. A case study demonstrates that our approach enhances transparency,\nfacilitates validation, and strengthens AI-augmented reasoning in scientific\ndiscovery.",
      "tldr_zh": "该研究探讨了大型语言模型（LLMs）在物理研究中的应用，强调其在推理、符号操作和数值计算方面的潜力，但面临输出可靠性和可解释性的挑战。为此，论文提出一个框架，包括推理模块、解释模块和AI-科学家互动模块，其中解释模块是创新点，由多个专门代理（如summarizers、model builders、UI builders和testers）组成，以构建更可解释的科学模型。实验案例显示，这种方法提升了AI输出的透明度，便于验证，并加强了AI在科学发现中的推理能力。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "physics.comp-ph"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01911v1",
      "published_date": "2025-04-02 17:13:16 UTC",
      "updated_date": "2025-04-02 17:13:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:46:08.047324"
    },
    {
      "arxiv_id": "2504.01908v1",
      "title": "Benchmarking Synthetic Tabular Data: A Multi-Dimensional Evaluation Framework",
      "title_zh": "合成表格数据的基准测试：一个多维",
      "authors": [
        "Andrey Sidorenko",
        "Michael Platzer",
        "Mario Scriminaci",
        "Paul Tiwald"
      ],
      "abstract": "Evaluating the quality of synthetic data remains a key challenge for ensuring\nprivacy and utility in data-driven research. In this work, we present an\nevaluation framework that quantifies how well synthetic data replicates\noriginal distributional properties while ensuring privacy. The proposed\napproach employs a holdout-based benchmarking strategy that facilitates\nquantitative assessment through low- and high-dimensional distribution\ncomparisons, embedding-based similarity measures, and nearest-neighbor distance\nmetrics. The framework supports various data types and structures, including\nsequential and contextual information, and enables interpretable quality\ndiagnostics through a set of standardized metrics. These contributions aim to\nsupport reproducibility and methodological consistency in benchmarking of\nsynthetic data generation techniques. The code of the framework is available at\nhttps://github.com/mostly-ai/mostlyai-qa.",
      "tldr_zh": "这篇论文提出了一种多维度的评估框架，用于基准测试 synthetic tabular data 的质量，确保其在保持隐私的同时复制原始数据的分布属性。该框架采用 holdout-based benchmarking 策略，通过低维和高维分布比较、embedding-based 相似度测量以及 nearest-neighbor 距离指标进行量化评估，并支持各种数据类型如顺序和上下文信息。框架通过标准化指标提供可解释的质量诊断，从而提升 synthetic data 生成技术的可重复性和方法一致性。代码开源在 https://github.com/mostly-ai/mostlyai-qa。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 7 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2504.01908v1",
      "published_date": "2025-04-02 17:10:30 UTC",
      "updated_date": "2025-04-02 17:10:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:46:21.122610"
    },
    {
      "arxiv_id": "2504.01905v2",
      "title": "Accelerating IoV Intrusion Detection: Benchmarking GPU-Accelerated vs CPU-Based ML Libraries",
      "title_zh": "翻译失败",
      "authors": [
        "Furkan Çolhak",
        "Hasan Coşkun",
        "Tsafac Nkombong Regine Cyrille",
        "Tedi Hoxa",
        "Mert İlhan Ecevit",
        "Mehmet Nafiz Aydın"
      ],
      "abstract": "The Internet of Vehicles (IoV) may face challenging cybersecurity attacks\nthat may require sophisticated intrusion detection systems, necessitating a\nrapid development and response system. This research investigates the\nperformance advantages of GPU-accelerated libraries (cuML) compared to\ntraditional CPU-based implementations (scikit-learn), focusing on the speed and\nefficiency required for machine learning models used in IoV threat detection\nenvironments. The comprehensive evaluations conducted employ four machine\nlearning approaches (Random Forest, KNN, Logistic Regression, XGBoost) across\nthree distinct IoV security datasets (OTIDS, GIDS, CICIoV2024). Our findings\ndemonstrate that GPU-accelerated implementations dramatically improved\ncomputational efficiency, with training times reduced by a factor of up to 159\nand prediction speeds accelerated by up to 95 times compared to traditional CPU\nprocessing, all while preserving detection accuracy. This remarkable\nperformance breakthrough empowers researchers and security specialists to\nharness GPU acceleration for creating faster, more effective threat detection\nsystems that meet the urgent real-time security demands of today's connected\nvehicle networks.",
      "tldr_zh": "本研究比较了 GPU-accelerated libraries (cuML) 与 CPU-based implementations (scikit-learn) 在 IoV (Internet of Vehicles) 入侵检测中的性能，旨在解决快速响应安全威胁的需求。研究评估了四种机器学习方法（Random Forest, KNN, Logistic Regression, XGBoost）在三个数据集（OTIDS, GIDS, CICIoV2024）上的表现。结果显示，GPU 加速实现显著提升了计算效率，训练时间减少高达 159 倍，预测速度加快高达 95 倍，同时保持了检测准确性。该突破为开发实时威胁检测系统提供了有力支持，帮助 IoV 网络应对紧急安全挑战。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "CIIT 2025 22nd International Conference on Informatics and\n  Information Technologies (CIIT)",
      "pdf_url": "http://arxiv.org/pdf/2504.01905v2",
      "published_date": "2025-04-02 17:04:53 UTC",
      "updated_date": "2025-04-03 08:42:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:46:32.480454"
    },
    {
      "arxiv_id": "2504.01903v1",
      "title": "STAR-1: Safer Alignment of Reasoning LLMs with 1K Data",
      "title_zh": "翻译失败",
      "authors": [
        "Zijun Wang",
        "Haoqin Tu",
        "Yuhan Wang",
        "Juncheng Wu",
        "Jieru Mei",
        "Brian R. Bartoldson",
        "Bhavya Kailkhura",
        "Cihang Xie"
      ],
      "abstract": "This paper introduces STAR-1, a high-quality, just-1k-scale safety dataset\nspecifically designed for large reasoning models (LRMs) like DeepSeek-R1. Built\non three core principles -- diversity, deliberative reasoning, and rigorous\nfiltering -- STAR-1 aims to address the critical needs for safety alignment in\nLRMs. Specifically, we begin by integrating existing open-source safety\ndatasets from diverse sources. Then, we curate safety policies to generate\npolicy-grounded deliberative reasoning samples. Lastly, we apply a GPT-4o-based\nsafety scoring system to select training examples aligned with best practices.\nExperimental results show that fine-tuning LRMs with STAR-1 leads to an average\n40% improvement in safety performance across four benchmarks, while only\nincurring a marginal decrease (e.g., an average of 1.1%) in reasoning ability\nmeasured across five reasoning tasks. Extensive ablation studies further\nvalidate the importance of our design principles in constructing STAR-1 and\nanalyze its efficacy across both LRMs and traditional LLMs. Our project page is\nhttps://ucsc-vlaa.github.io/STAR-1.",
      "tldr_zh": "本论文引入了 STAR-1，一个高质量的约 1k 规模安全数据集，专门针对大型推理模型 (LRMs) 如 DeepSeek-R1，以提升其安全对齐。数据集基于多样性、审议性推理和严格过滤的三大原则构建，包括整合现有开源安全数据集、生成政策导向的推理样本，以及使用 GPT-4o 的安全评分系统进行筛选。实验结果显示，使用 STAR-1 微调 LRMs 可使安全性能在四个基准上平均提升 40%，同时推理能力仅下降约 1.1%。消融研究进一步验证了设计原则的有效性，并证明了 STAR-1 在 LRMs 和传统 LLMs 上的适用性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01903v1",
      "published_date": "2025-04-02 17:04:04 UTC",
      "updated_date": "2025-04-02 17:04:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:46:46.024978"
    },
    {
      "arxiv_id": "2504.01902v1",
      "title": "Graphically Speaking: Unmasking Abuse in Social Media with Conversation Insights",
      "title_zh": "翻译失败",
      "authors": [
        "Célia Nouri",
        "Jean-Philippe Cointet",
        "Chloé Clavel"
      ],
      "abstract": "Detecting abusive language in social media conversations poses significant\nchallenges, as identifying abusiveness often depends on the conversational\ncontext, characterized by the content and topology of preceding comments.\nTraditional Abusive Language Detection (ALD) models often overlook this\ncontext, which can lead to unreliable performance metrics. Recent Natural\nLanguage Processing (NLP) methods that integrate conversational context often\ndepend on limited and simplified representations, and report inconsistent\nresults. In this paper, we propose a novel approach that utilize graph neural\nnetworks (GNNs) to model social media conversations as graphs, where nodes\nrepresent comments, and edges capture reply structures. We systematically\ninvestigate various graph representations and context windows to identify the\noptimal configuration for ALD. Our GNN model outperform both context-agnostic\nbaselines and linear context-aware methods, achieving significant improvements\nin F1 scores. These findings demonstrate the critical role of structured\nconversational context and establish GNNs as a robust framework for advancing\ncontext-aware abusive language detection.",
      "tldr_zh": "本研究针对社交媒体辱骂语言检测（Abusive Language Detection, ALD）的挑战，提出了一种新方法，通过图神经网络（Graph Neural Networks, GNNs）将对话建模为图结构，其中节点代表评论，边表示回复关系，以更好地捕捉对话内容和拓扑上下文。研究系统调查了各种图表示和上下文窗口，优化了模型配置，并与无上下文基线和线性上下文感知方法相比，GNN 模型在 F1 分数上实现了显著提升。结果证明了结构化对话上下文的关键作用，并确立了 GNNs 作为推进上下文感知 ALD 的稳健框架。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01902v1",
      "published_date": "2025-04-02 17:03:37 UTC",
      "updated_date": "2025-04-02 17:03:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:46:56.578360"
    },
    {
      "arxiv_id": "2504.01901v1",
      "title": "Ross3D: Reconstructive Visual Instruction Tuning with 3D-Awareness",
      "title_zh": "翻译失败",
      "authors": [
        "Haochen Wang",
        "Yucheng Zhao",
        "Tiancai Wang",
        "Haoqiang Fan",
        "Xiangyu Zhang",
        "Zhaoxiang Zhang"
      ],
      "abstract": "The rapid development of Large Multimodal Models (LMMs) for 2D images and\nvideos has spurred efforts to adapt these models for interpreting 3D scenes.\nHowever, the absence of large-scale 3D vision-language datasets has posed a\nsignificant obstacle. To address this issue, typical approaches focus on\ninjecting 3D awareness into 2D LMMs by designing 3D input-level scene\nrepresentations. This work provides a new perspective. We introduce\nreconstructive visual instruction tuning with 3D-awareness (Ross3D), which\nintegrates 3D-aware visual supervision into the training procedure.\nSpecifically, it incorporates cross-view and global-view reconstruction. The\nformer requires reconstructing masked views by aggregating overlapping\ninformation from other views. The latter aims to aggregate information from all\navailable views to recover Bird's-Eye-View images, contributing to a\ncomprehensive overview of the entire scene. Empirically, Ross3D achieves\nstate-of-the-art performance across various 3D scene understanding benchmarks.\nMore importantly, our semi-supervised experiments demonstrate significant\npotential in leveraging large amounts of unlabeled 3D vision-only data.",
      "tldr_zh": "这篇论文引入了Ross3D，一种重建式视觉指令微调方法，旨在通过整合3D-Awareness来提升Large Multimodal Models (LMMs)在3D场景理解中的性能，以解决大规模3D视觉语言数据集缺失的问题。Ross3D在训练过程中加入3D感知视觉监督，包括cross-view reconstruction（通过聚合其他视图的重叠信息重建被遮挡视图）和global-view reconstruction（聚合所有视图信息恢复Bird's-Eye-View图像），从而提供对场景的全面概述。实验结果显示，Ross3D在多种3D场景理解基准上达到了最先进性能，并证明了其在半监督设置下利用大量无标签3D视觉数据的显著潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01901v1",
      "published_date": "2025-04-02 16:59:55 UTC",
      "updated_date": "2025-04-02 16:59:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:47:09.731184"
    },
    {
      "arxiv_id": "2504.02890v1",
      "title": "Scaling Test-time Compute for Low-resource Languages: Multilingual Reasoning in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Khanh-Tung Tran",
        "Barry O'Sullivan",
        "Hoang D. Nguyen"
      ],
      "abstract": "Recent advances in test-time compute scaling have enabled Large Language\nModels (LLMs) to tackle deep reasoning tasks by generating a chain-of-thought\n(CoT) that includes trial and error, backtracking, and intermediate reasoning\nsteps before producing the final answer. However, these techniques have been\napplied predominantly to popular languages, such as English, leaving reasoning\nin low-resource languages underexplored and misaligned. In this work, we\ninvestigate the multilingual mechanism by which LLMs internally operate in a\nlatent space biased toward their inherently dominant language. To leverage this\nphenomenon for low-resource languages, we train models to generate the CoT in\nEnglish while outputting the final response in the target language, given input\nin the low-resource language. Our experiments demonstrate that this approach,\nnamed English-Pivoted CoT Training, outperforms other baselines, including\ntraining to generate both the CoT and the final response solely in the target\nlanguage, with up to 28.33% improvement. Further analysis provides novel\ninsights into the relationships between reasoning and multilinguality of LLMs,\nprompting for better approaches in developing multilingual large reasoning\nmodels",
      "tldr_zh": "本文研究了如何扩展测试时计算，以提升大型语言模型(LLMs)在低资源语言中的多语言推理能力，特别是通过生成链式思考(Chain-of-Thought, CoT)来处理深度任务。研究者提出English-Pivoted CoT Training方法，让模型在低资源语言输入下，用英语生成CoT推理过程，但以目标语言输出最终响应，从而利用LLMs内部偏向主导语言的机制。实验结果显示，该方法比其他基线提升高达28.33%，并提供了LLMs推理与多语言性的新见解，为开发更好的多语言大推理模型提供了指导。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02890v1",
      "published_date": "2025-04-02 16:58:36 UTC",
      "updated_date": "2025-04-02 16:58:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:47:21.624265"
    },
    {
      "arxiv_id": "2504.01888v1",
      "title": "A novel gesture interaction control method for rehabilitation lower extremity exoskeleton",
      "title_zh": "翻译失败",
      "authors": [
        "Shuang Qiu",
        "Zhongcai Pei",
        "Chen Wang",
        "Jing Zhang",
        "Zhiyong Tang"
      ],
      "abstract": "With the rapid development of Rehabilitation Lower Extremity Robotic\nExoskeletons (RLEEX) technology, significant advancements have been made in\nHuman-Robot Interaction (HRI) methods. These include traditional physical HRI\nmethods that are easily recognizable and various bio-electrical signal-based\nHRI methods that can visualize and predict actions. However, most of these HRI\nmethods are contact-based, facing challenges such as operational complexity,\nsensitivity to interference, risks associated with implantable devices, and,\nmost importantly, limitations in comfort. These challenges render the\ninteraction less intuitive and natural, which can negatively impact patient\nmotivation for rehabilitation. To address these issues, this paper proposes a\nnovel non-contact gesture interaction control method for RLEEX, based on RGB\nmonocular camera depth estimation. This method integrates three key steps:\ndetecting keypoints, recognizing gestures, and assessing distance, thereby\napplying gesture information and augmented reality triggering technology to\ncontrol gait movements of RLEEX. Results indicate that this approach provides a\nfeasible solution to the problems of poor comfort, low reliability, and high\nlatency in HRI for RLEEX platforms. Specifically, it achieves a\ngesture-controlled exoskeleton motion accuracy of 94.11\\% and an average system\nresponse time of 0.615 seconds through non-contact HRI. The proposed\nnon-contact HRI method represents a pioneering advancement in control\ninteractions for RLEEX, paving the way for further exploration and development\nin this field.",
      "tldr_zh": "这篇论文针对康复下肢外骨骼机器人(RLEEX)的传统接触式人机交互(HRI)方法存在舒适度低、可靠性差和延迟高等问题，提出了一种基于RGB单目相机深度估计的非接触手势交互控制方法。该方法通过关键点检测、手势识别和距离评估，并结合增强现实技术，来实现对RLEEX步态运动的精确控制。实验结果显示，该方法达到了94.11%的运动准确率和0.615秒的平均响应时间，为RLEEX领域提供了更直观、自然的交互方案。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01888v1",
      "published_date": "2025-04-02 16:46:01 UTC",
      "updated_date": "2025-04-02 16:46:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:47:33.279509"
    },
    {
      "arxiv_id": "2504.01883v1",
      "title": "CoRAG: Collaborative Retrieval-Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Aashiq Muhamed",
        "Mona Diab",
        "Virginia Smith"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) models excel in knowledge-intensive\ntasks, especially under few-shot learning constraints. We introduce CoRAG, a\nframework extending RAG to collaborative settings, where clients jointly train\na shared model using a collaborative passage store. To evaluate CoRAG, we\nintroduce CRAB, a benchmark for collaborative homogeneous open-domain question\nanswering. Our experiments demonstrate that CoRAG consistently outperforms both\nparametric collaborative learning methods and locally trained RAG models in\nlow-resource scenarios. Further analysis reveals the critical importance of\nrelevant passages within the shared store, the surprising benefits of\nincorporating irrelevant passages, and the potential for hard negatives to\nnegatively impact performance. This introduces a novel consideration in\ncollaborative RAG: the trade-off between leveraging a collectively enriched\nknowledge base and the potential risk of incorporating detrimental passages\nfrom other clients. Our findings underscore the viability of CoRAG, while also\nhighlighting key design challenges and promising avenues for future research.",
      "tldr_zh": "该研究引入了 CoRAG 框架，将 Retrieval-Augmented Generation (RAG) 扩展到协作场景中，允许多个客户端共同训练共享模型并使用协作通道存储 (collaborative passage store) 进行知识密集型任务。研究者开发了 CRAB 基准，用于评估协作同质开放域问答性能，实验显示 CoRAG 在低资源环境中优于参数化协作学习方法和本地 RAG 模型。进一步分析强调了相关段落的重要性、无关段落的意外益处，以及硬负例 (hard negatives) 的负面影响，揭示了在协作 RAG 中平衡集体知识与潜在风险的权衡问题，为未来研究提供了新方向。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "NAACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2504.01883v1",
      "published_date": "2025-04-02 16:40:43 UTC",
      "updated_date": "2025-04-02 16:40:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:47:44.892968"
    },
    {
      "arxiv_id": "2504.01871v1",
      "title": "Interpreting Emergent Planning in Model-Free Reinforcement Learning",
      "title_zh": "无模型强化学习中涌现规划的解释",
      "authors": [
        "Thomas Bush",
        "Stephen Chung",
        "Usman Anwar",
        "Adrià Garriga-Alonso",
        "David Krueger"
      ],
      "abstract": "We present the first mechanistic evidence that model-free reinforcement\nlearning agents can learn to plan. This is achieved by applying a methodology\nbased on concept-based interpretability to a model-free agent in Sokoban -- a\ncommonly used benchmark for studying planning. Specifically, we demonstrate\nthat DRC, a generic model-free agent introduced by Guez et al. (2019), uses\nlearned concept representations to internally formulate plans that both predict\nthe long-term effects of actions on the environment and influence action\nselection. Our methodology involves: (1) probing for planning-relevant\nconcepts, (2) investigating plan formation within the agent's representations,\nand (3) verifying that discovered plans (in the agent's representations) have a\ncausal effect on the agent's behavior through interventions. We also show that\nthe emergence of these plans coincides with the emergence of a planning-like\nproperty: the ability to benefit from additional test-time compute. Finally, we\nperform a qualitative analysis of the planning algorithm learned by the agent\nand discover a strong resemblance to parallelized bidirectional search. Our\nfindings advance understanding of the internal mechanisms underlying planning\nbehavior in agents, which is important given the recent trend of emergent\nplanning and reasoning capabilities in LLMs through RL",
      "tldr_zh": "本研究首次提供了模型无关强化学习（model-free reinforcement learning）代理能够学习规划的机制证据，通过基于概念的可解释性（concept-based interpretability）方法应用于Sokoban基准上的DRC代理。研究发现，该代理利用学到的概念表示来内部制定计划，这些计划能预测动作的长期环境影响并指导行为选择，并通过探测、调查和干预实验验证了计划对行为的影响。结果显示，代理的规划能力与从额外测试时间计算中获益的特性同时出现，且其学习的规划算法类似于并行化双向搜索（parallelized bidirectional search），这有助于深化对代理内部机制的理解，尤其在LLMs中新兴的规划和推理能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025 oral",
      "pdf_url": "http://arxiv.org/pdf/2504.01871v1",
      "published_date": "2025-04-02 16:24:23 UTC",
      "updated_date": "2025-04-02 16:24:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:47:57.393155"
    },
    {
      "arxiv_id": "2504.01866v2",
      "title": "From Code Generation to Software Testing: AI Copilot with Context-Based RAG",
      "title_zh": "从代码生成到软件测试：基于上下文的 RAG 的 AI Copilot",
      "authors": [
        "Yuchen Wang",
        "Shangxin Guo",
        "Chee Wei Tan"
      ],
      "abstract": "The rapid pace of large-scale software development places increasing demands\non traditional testing methodologies, often leading to bottlenecks in\nefficiency, accuracy, and coverage. We propose a novel perspective on software\ntesting by positing bug detection and coding with fewer bugs as two\ninterconnected problems that share a common goal, which is reducing bugs with\nlimited resources. We extend our previous work on AI-assisted programming,\nwhich supports code auto-completion and chatbot-powered Q&A, to the realm of\nsoftware testing. We introduce Copilot for Testing, an automated testing system\nthat synchronizes bug detection with codebase updates, leveraging context-based\nRetrieval Augmented Generation (RAG) to enhance the capabilities of large\nlanguage models (LLMs). Our evaluation demonstrates a 31.2% improvement in bug\ndetection accuracy, a 12.6% increase in critical test coverage, and a 10.5%\nhigher user acceptance rate, highlighting the transformative potential of\nAI-driven technologies in modern software development practices.",
      "tldr_zh": "该研究探讨了软件开发中传统测试方法的效率、准确性和覆盖率瓶颈，将 bug 检测和减少 bug 编码视为相互关联的问题，以有限资源降低 bug 为共同目标。作者扩展了之前的 AI 辅助编程系统，引入了 Copilot for Testing，这是一个利用 context-based RAG 增强 large language models (LLMs) 能力的自动化测试系统，能够同步 bug 检测与代码更新。实验结果显示，该系统将 bug 检测准确率提高了 31.2%，关键测试覆盖率增加了 12.6%，并提升了 10.5% 的用户接受率，展示了 AI 驱动技术在现代软件开发中的变革潜力。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.SE",
      "comment": "This work has been accepted for publication in IEEE Software (DOI:\n  10.1109/MS.2025.3549628)",
      "pdf_url": "http://arxiv.org/pdf/2504.01866v2",
      "published_date": "2025-04-02 16:20:05 UTC",
      "updated_date": "2025-04-05 09:03:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:48:08.798953"
    },
    {
      "arxiv_id": "2504.01857v1",
      "title": "Cross-Lingual Consistency: A Novel Inference Framework for Advancing Reasoning in Large Language Models",
      "title_zh": "跨语言一致性：一种新颖的推理框架，用于提升大型语言模型的推理能力",
      "authors": [
        "Zhiwei Yu",
        "Tuo Li",
        "Changhong Wang",
        "Hui Chen",
        "Lang Zhou"
      ],
      "abstract": "Chain-of-thought (CoT) has emerged as a critical mechanism for enhancing\nreasoning capabilities in large language models (LLMs), with self-consistency\ndemonstrating notable promise in boosting performance. However, inherent\nlinguistic biases in multilingual training corpora frequently cause semantic\ndrift and logical inconsistencies, especially in sub-10B parameter LLMs\nhandling complex inference tasks. To overcome these constraints, we propose the\nCross-Lingual Consistency (CLC) framework, an innovative inference paradigm\nthat integrates multilingual reasoning paths through majority voting to elevate\nLLMs' reasoning capabilities. Empirical evaluations on the CMATH dataset reveal\nCLC's superiority over the conventional self-consistency method, delivering\n9.5%, 6.5%, and 6.0% absolute accuracy gains for DeepSeek-Math-7B-Instruct,\nQwen2.5-Math-7B-Instruct, and Gemma2-9B-Instruct respectively. Expanding CLC's\nlinguistic scope to 11 diverse languages implies two synergistic benefits: 1)\nneutralizing linguistic biases in multilingual training corpora through\nmultilingual ensemble voting, 2) escaping monolingual reasoning traps by\nexploring the broader multilingual solution space. This dual benefits\nempirically enables more globally optimal reasoning paths compared to\nmonolingual self-consistency baselines, as evidenced by the 4.1%-18.5% accuracy\ngains using Gemma2-9B-Instruct on the MGSM dataset.",
      "tldr_zh": "这篇论文针对大型语言模型(LLMs)中的推理问题，提出了一种创新框架Cross-Lingual Consistency (CLC)，通过整合多语言推理路径和多数投票机制来缓解语义漂移和逻辑不一致。CLC在CMATH数据集上比传统Self-Consistency方法提升了DeepSeek-Math-7B-Instruct等模型的准确率，分别获得9.5%、6.5%和6.0%的绝对增益。扩展到11种语言后，该框架不仅中和了多语言训练语料中的语言偏差，还通过探索更广的解决方案空间，在MGSM数据集上实现了4.1%-18.5%的准确率改进。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01857v1",
      "published_date": "2025-04-02 16:09:39 UTC",
      "updated_date": "2025-04-02 16:09:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:48:22.110975"
    },
    {
      "arxiv_id": "2504.01855v1",
      "title": "Enhanced Diffusion Sampling via Extrapolation with Multiple ODE Solutions",
      "title_zh": "翻译失败",
      "authors": [
        "Jinyoung Choi",
        "Junoh Kang",
        "Bohyung Han"
      ],
      "abstract": "Diffusion probabilistic models (DPMs), while effective in generating\nhigh-quality samples, often suffer from high computational costs due to their\niterative sampling process. To address this, we propose an enhanced ODE-based\nsampling method for DPMs inspired by Richardson extrapolation, which reduces\nnumerical error and improves convergence rates. Our method, RX-DPM, leverages\nmultiple ODE solutions at intermediate time steps to extrapolate the denoised\nprediction in DPMs. This significantly enhances the accuracy of estimations for\nthe final sample while maintaining the number of function evaluations (NFEs).\nUnlike standard Richardson extrapolation, which assumes uniform discretization\nof the time grid, we develop a more general formulation tailored to arbitrary\ntime step scheduling, guided by local truncation error derived from a baseline\nsampling method. The simplicity of our approach facilitates accurate estimation\nof numerical solutions without significant computational overhead, and allows\nfor seamless and convenient integration into various DPMs and solvers.\nAdditionally, RX-DPM provides explicit error estimates, effectively\ndemonstrating the faster convergence as the leading error term's order\nincreases. Through a series of experiments, we show that the proposed method\nimproves the quality of generated samples without requiring additional sampling\niterations.",
      "tldr_zh": "本文提出 RX-DPM 方法，通过利用多个 ODE 解决方案在中间时间步骤进行外推，增强扩散概率模型 (DPMs) 的采样过程，从而减少数值误差并提高收敛率。该方法基于 Richardson 外推的灵感，但针对任意时间步调度进行了通用化设计，利用基线采样的局部截断误差提供显式误差估计，便于集成到各种 DPMs 和求解器中。实验结果显示，RX-DPM 在不增加函数评估次数 (NFEs) 的前提下，显著提高了生成样本的质量。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.01855v1",
      "published_date": "2025-04-02 16:06:23 UTC",
      "updated_date": "2025-04-02 16:06:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:48:33.503271"
    },
    {
      "arxiv_id": "2504.01850v1",
      "title": "Code Red! On the Harmfulness of Applying Off-the-shelf Large Language Models to Programming Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Ali Al-Kaswan",
        "Sebastian Deatc",
        "Begüm Koç",
        "Arie van Deursen",
        "Maliheh Izadi"
      ],
      "abstract": "Nowadays, developers increasingly rely on solutions powered by Large Language\nModels (LLM) to assist them with their coding tasks. This makes it crucial to\nalign these tools with human values to prevent malicious misuse. In this paper,\nwe propose a comprehensive framework for assessing the potential harmfulness of\nLLMs within the software engineering domain. We begin by developing a taxonomy\nof potentially harmful software engineering scenarios and subsequently, create\na dataset of prompts based on this taxonomy. To systematically assess the\nresponses, we design and validate an automatic evaluator that classifies the\noutputs of a variety of LLMs both open-source and closed-source models, as well\nas general-purpose and code-specific LLMs. Furthermore, we investigate the\nimpact of models size, architecture family, and alignment strategies on their\ntendency to generate harmful content. The results show significant disparities\nin the alignment of various LLMs for harmlessness. We find that some models and\nmodel families, such as Openhermes, are more harmful than others and that\ncode-specific models do not perform better than their general-purpose\ncounterparts. Notably, some fine-tuned models perform significantly worse than\ntheir base-models due to their design choices. On the other side, we find that\nlarger models tend to be more helpful and are less likely to respond with\nharmful information. These results highlight the importance of targeted\nalignment strategies tailored to the unique challenges of software engineering\ntasks and provide a foundation for future work in this critical area.",
      "tldr_zh": "本研究探讨了使用现成 Large Language Models (LLM) 进行编程任务的潜在危害，强调了确保这些工具与人类价值观一致的重要性。论文提出一个全面框架，包括开发有害软件工程场景的taxonomy、基于此创建提示数据集，以及设计一个自动评估器来分类各种LLM（如开源、闭源、通用和代码专用模型）的输出。研究调查了模型大小、架构家族和alignment strategies对生成有害内容的影响，结果显示某些模型（如Openhermes）更易产生有害响应，代码专用模型并不优于通用模型，而一些微调模型甚至比其基模型表现更差。总体而言，更大的模型更倾向于提供帮助性内容，这突出了针对软件工程任务的特定对齐策略的必要性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "FSE'25 Technical Track",
      "pdf_url": "http://arxiv.org/pdf/2504.01850v1",
      "published_date": "2025-04-02 16:00:14 UTC",
      "updated_date": "2025-04-02 16:00:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:48:46.144265"
    },
    {
      "arxiv_id": "2504.01849v1",
      "title": "An Approach to Technical AGI Safety and Security",
      "title_zh": "翻译失败",
      "authors": [
        "Rohin Shah",
        "Alex Irpan",
        "Alexander Matt Turner",
        "Anna Wang",
        "Arthur Conmy",
        "David Lindner",
        "Jonah Brown-Cohen",
        "Lewis Ho",
        "Neel Nanda",
        "Raluca Ada Popa",
        "Rishub Jain",
        "Rory Greig",
        "Samuel Albanie",
        "Scott Emmons",
        "Sebastian Farquhar",
        "Sébastien Krier",
        "Senthooran Rajamanoharan",
        "Sophie Bridgers",
        "Tobi Ijitoye",
        "Tom Everitt",
        "Victoria Krakovna",
        "Vikrant Varma",
        "Vladimir Mikulik",
        "Zachary Kenton",
        "Dave Orr",
        "Shane Legg",
        "Noah Goodman",
        "Allan Dafoe",
        "Four Flynn",
        "Anca Dragan"
      ],
      "abstract": "Artificial General Intelligence (AGI) promises transformative benefits but\nalso presents significant risks. We develop an approach to address the risk of\nharms consequential enough to significantly harm humanity. We identify four\nareas of risk: misuse, misalignment, mistakes, and structural risks. Of these,\nwe focus on technical approaches to misuse and misalignment. For misuse, our\nstrategy aims to prevent threat actors from accessing dangerous capabilities,\nby proactively identifying dangerous capabilities, and implementing robust\nsecurity, access restrictions, monitoring, and model safety mitigations. To\naddress misalignment, we outline two lines of defense. First, model-level\nmitigations such as amplified oversight and robust training can help to build\nan aligned model. Second, system-level security measures such as monitoring and\naccess control can mitigate harm even if the model is misaligned. Techniques\nfrom interpretability, uncertainty estimation, and safer design patterns can\nenhance the effectiveness of these mitigations. Finally, we briefly outline how\nthese ingredients could be combined to produce safety cases for AGI systems.",
      "tldr_zh": "该论文提出了一种针对人工智能通用智能(AGI)的技术安全和安全策略，以应对可能对人类造成重大危害的风险。主要关注四个风险领域中的滥用(misuse)和失调(misalignment)，通过识别危险能力、实施安全措施、访问限制、监控以及模型安全缓解来防范滥用。对于失调，该方法包括模型级缓解（如放大监督和稳健训练）以及系统级措施（如监控和访问控制），并利用可解释性、不确定性估计和更安全的设计模式增强效果。最终，论文概述了如何整合这些元素，为AGI系统构建安全案例，以实现更可靠的AGI开发。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01849v1",
      "published_date": "2025-04-02 15:59:31 UTC",
      "updated_date": "2025-04-02 15:59:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:48:56.642424"
    },
    {
      "arxiv_id": "2504.01848v3",
      "title": "PaperBench: Evaluating AI's Ability to Replicate AI Research",
      "title_zh": "翻译失败",
      "authors": [
        "Giulio Starace",
        "Oliver Jaffe",
        "Dane Sherburn",
        "James Aung",
        "Jun Shern Chan",
        "Leon Maksin",
        "Rachel Dias",
        "Evan Mays",
        "Benjamin Kinsella",
        "Wyatt Thompson",
        "Johannes Heidecke",
        "Amelia Glaese",
        "Tejal Patwardhan"
      ],
      "abstract": "We introduce PaperBench, a benchmark evaluating the ability of AI agents to\nreplicate state-of-the-art AI research. Agents must replicate 20 ICML 2024\nSpotlight and Oral papers from scratch, including understanding paper\ncontributions, developing a codebase, and successfully executing experiments.\nFor objective evaluation, we develop rubrics that hierarchically decompose each\nreplication task into smaller sub-tasks with clear grading criteria. In total,\nPaperBench contains 8,316 individually gradable tasks. Rubrics are co-developed\nwith the author(s) of each ICML paper for accuracy and realism. To enable\nscalable evaluation, we also develop an LLM-based judge to automatically grade\nreplication attempts against rubrics, and assess our judge's performance by\ncreating a separate benchmark for judges. We evaluate several frontier models\non PaperBench, finding that the best-performing tested agent, Claude 3.5 Sonnet\n(New) with open-source scaffolding, achieves an average replication score of\n21.0%. Finally, we recruit top ML PhDs to attempt a subset of PaperBench,\nfinding that models do not yet outperform the human baseline. We open-source\nour code (https://github.com/openai/preparedness) to facilitate future research\nin understanding the AI engineering capabilities of AI agents.",
      "tldr_zh": "本文引入 PaperBench 基准，用于评估 AI agents 复制最先进 AI 研究的能力，具体要求 agents 从零开始复制 20 篇 ICML 2024 Spotlight 和 Oral 论文，包括理解贡献、开发 codebase 和执行实验。基准包含 8,316 个分层分解的子任务，并通过与作者合作开发的 rubrics 和 LLM-based judge 进行客观评估。实验结果显示，最佳模型 Claude 3.5 Sonnet（配以开源脚手架）平均得分 21.0%，但仍未超过顶级 ML PhD 人类的基准水平。该研究开源代码（https://github.com/openai/preparedness），以推动 AI 工程能力的未来研究。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "30 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.01848v3",
      "published_date": "2025-04-02 15:55:24 UTC",
      "updated_date": "2025-04-07 12:15:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:49:09.647040"
    },
    {
      "arxiv_id": "2504.01833v1",
      "title": "YourBench: Easy Custom Evaluation Sets for Everyone",
      "title_zh": "翻译失败",
      "authors": [
        "Sumuk Shashidhar",
        "Clémentine Fourrier",
        "Alina Lozovskia",
        "Thomas Wolf",
        "Gokhan Tur",
        "Dilek Hakkani-Tür"
      ],
      "abstract": "Evaluating large language models (LLMs) effectively remains a critical\nbottleneck, as traditional static benchmarks suffer from saturation and\ncontamination, while human evaluations are costly and slow. This hinders timely\nor domain-specific assessment, crucial for real-world applications. We\nintroduce YourBench, a novel, open-source framework that addresses these\nlimitations by enabling dynamic, automated generation of reliable, up-to-date,\nand domain-tailored benchmarks cheaply and without manual annotation, directly\nfrom user-provided documents. We demonstrate its efficacy by replicating 7\ndiverse MMLU subsets using minimal source text, achieving this for under 15 USD\nin total inference costs while perfectly preserving the relative model\nperformance rankings (Spearman Rho = 1) observed on the original benchmark. To\nensure that YourBench generates data grounded in provided input instead of\nrelying on posterior parametric knowledge in models, we also introduce\nTempora-0325, a novel dataset of over 7K diverse documents, published\nexclusively after March 2025. Our comprehensive analysis spans 26 SoTA models\nfrom 7 major families across varying scales (3-671B parameters) to validate the\nquality of generated evaluations through rigorous algorithmic checks (e.g.,\ncitation grounding) and human assessments. We release the YourBench library,\nthe Tempora-0325 dataset, 150k+ question answer pairs based on Tempora and all\nevaluation and inference traces to facilitate reproducible research and empower\nthe community to generate bespoke benchmarks on demand, fostering more relevant\nand trustworthy LLM evaluation.",
      "tldr_zh": "该论文提出 YourBench，一个开源框架，旨在解决评估大型语言模型 (LLMs) 的瓶颈问题，包括传统基准的饱和和污染，以及人力评估的成本高昂。YourBench 允许用户从提供的文档中动态生成可靠、更新和领域定制的评估集，无需手动标注，并以低成本（如总推理费用低于 15 USD）复制 7 个 MMLU 子集，同时保持原基准的相对模型性能排名 (Spearman Rho = 1)。为了确保生成数据基于输入而非模型的先验知识，论文引入 Tempora-0325 数据集（超过 7K 文档），并通过对 26 个 SoTA 模型的全面分析和验证，最终开源相关资源以促进可重复和定制的 LLM 评估。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.1"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01833v1",
      "published_date": "2025-04-02 15:40:24 UTC",
      "updated_date": "2025-04-02 15:40:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:49:21.874450"
    },
    {
      "arxiv_id": "2504.02019v1",
      "title": "Antithetic Sampling for Top-k Shapley Identification",
      "title_zh": "翻译失败",
      "authors": [
        "Patrick Kolpaczki",
        "Tim Nielen",
        "Eyke Hüllermeier"
      ],
      "abstract": "Additive feature explanations rely primarily on game-theoretic notions such\nas the Shapley value by viewing features as cooperating players. The Shapley\nvalue's popularity in and outside of explainable AI stems from its axiomatic\nuniqueness. However, its computational complexity severely limits\npracticability. Most works investigate the uniform approximation of all\nfeatures' Shapley values, needlessly consuming samples for insignificant\nfeatures. In contrast, identifying the $k$ most important features can already\nbe sufficiently insightful and yields the potential to leverage algorithmic\nopportunities connected to the field of multi-armed bandits. We propose\nComparable Marginal Contributions Sampling (CMCS), a method for the top-$k$\nidentification problem utilizing a new sampling scheme taking advantage of\ncorrelated observations. We conduct experiments to showcase the efficacy of our\nmethod in compared to competitive baselines. Our empirical findings reveal that\nestimation quality for the approximate-all problem does not necessarily\ntransfer to top-$k$ identification and vice versa.",
      "tldr_zh": "该论文探讨了在特征解释中，使用Shapley value将特征视为合作玩家的方法，但其计算复杂度限制了实际应用。作者提出Comparable Marginal Contributions Sampling (CMCS)，一种利用相关观察的antithetic sampling方案，专注于识别top-k最重要特征，从而避免了对不重要特征的资源浪费，并借鉴multi-armed bandits领域的算法优势。实验结果显示，CMCS比竞争基线更有效，且针对所有特征的Shapley value估计质量并不直接适用于top-k识别，反之亦然。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02019v1",
      "published_date": "2025-04-02 15:38:32 UTC",
      "updated_date": "2025-04-02 15:38:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:49:32.826126"
    },
    {
      "arxiv_id": "2504.01819v1",
      "title": "Implicit Bias Injection Attacks against Text-to-Image Diffusion Models",
      "title_zh": "针对文本到图像扩散模型的隐性偏见注入攻击",
      "authors": [
        "Huayang Huang",
        "Xiangye Jin",
        "Jiaxu Miao",
        "Yu Wu"
      ],
      "abstract": "The proliferation of text-to-image diffusion models (T2I DMs) has led to an\nincreased presence of AI-generated images in daily life. However, biased T2I\nmodels can generate content with specific tendencies, potentially influencing\npeople's perceptions. Intentional exploitation of these biases risks conveying\nmisleading information to the public. Current research on bias primarily\naddresses explicit biases with recognizable visual patterns, such as skin color\nand gender. This paper introduces a novel form of implicit bias that lacks\nexplicit visual features but can manifest in diverse ways across various\nsemantic contexts. This subtle and versatile nature makes this bias challenging\nto detect, easy to propagate, and adaptable to a wide range of scenarios. We\nfurther propose an implicit bias injection attack framework (IBI-Attacks)\nagainst T2I diffusion models by precomputing a general bias direction in the\nprompt embedding space and adaptively adjusting it based on different inputs.\nOur attack module can be seamlessly integrated into pre-trained diffusion\nmodels in a plug-and-play manner without direct manipulation of user input or\nmodel retraining. Extensive experiments validate the effectiveness of our\nscheme in introducing bias through subtle and diverse modifications while\npreserving the original semantics. The strong concealment and transferability\nof our attack across various scenarios further underscore the significance of\nour approach. Code is available at https://github.com/Hannah1102/IBI-attacks.",
      "tldr_zh": "这篇论文探讨了text-to-image diffusion models (T2I DMs)中的implicit bias问题，提出了一种新型隐性偏差注入攻击框架（IBI-Attacks），该框架通过在prompt embedding空间预计算通用偏差方向，并根据不同输入进行自适应调整，实现对预训练模型的plug-and-play集成，而无需直接操作用户输入或重新训练模型。实验验证了IBI-Attacks的有效性，能够通过微妙且多样的修改引入偏差，同时保留原有的语义，并展示出强烈的隐蔽性和跨场景转移性。该研究强调了这种隐性偏差的潜在风险，并提供了开源代码以促进进一步探讨。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accept to CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.01819v1",
      "published_date": "2025-04-02 15:24:12 UTC",
      "updated_date": "2025-04-02 15:24:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:49:45.425297"
    },
    {
      "arxiv_id": "2504.01798v1",
      "title": "A Novel Approach To Implementing Knowledge Distillation In Tsetlin Machines",
      "title_zh": "翻译失败",
      "authors": [
        "Calvin Kinateder"
      ],
      "abstract": "The Tsetlin Machine (TM) is a propositional logic based model that uses\nconjunctive clauses to learn patterns from data. As with typical neural\nnetworks, the performance of a Tsetlin Machine is largely dependent on its\nparameter count, with a larger number of parameters producing higher accuracy\nbut slower execution. Knowledge distillation in neural networks transfers\ninformation from an already-trained teacher model to a smaller student model to\nincrease accuracy in the student without increasing execution time. We propose\na novel approach to implementing knowledge distillation in Tsetlin Machines by\nutilizing the probability distributions of each output sample in the teacher to\nprovide additional context to the student. Additionally, we propose a novel\nclause-transfer algorithm that weighs the importance of each clause in the\nteacher and initializes the student with only the most essential data. We find\nthat our algorithm can significantly improve performance in the student model\nwithout negatively impacting latency in the tested domains of image recognition\nand text classification.",
      "tldr_zh": "本文提出了一种在 Tsetlin Machines 中实现 Knowledge Distillation 的新方法，通过利用教师模型每个输出样本的概率分布，为学生模型提供额外上下文，从而提升性能而不增加执行时间。同时，引入了 clause-transfer algorithm 来评估教师模型中子句的重要性，并仅用最关键的数据初始化学生模型。实验结果显示，该方法在图像识别和文本分类领域显著提高了学生模型的准确率，同时保持了延迟不变。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "Master's Thesis. 75 pages, 30 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.01798v1",
      "published_date": "2025-04-02 15:06:27 UTC",
      "updated_date": "2025-04-02 15:06:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:49:57.251331"
    },
    {
      "arxiv_id": "2504.01797v2",
      "title": "Rethinking industrial artificial intelligence: a unified foundation framework",
      "title_zh": "反思工业人工智能：一个统一的基礎框架",
      "authors": [
        "Jay Lee",
        "Hanqi Su"
      ],
      "abstract": "Recent advancements in industrial artificial intelligence (AI) are reshaping\nthe industry by driving smarter manufacturing, predictive maintenance, and\nintelligent decision-making. However, existing approaches often focus primarily\non algorithms and models while overlooking the importance of systematically\nintegrating domain knowledge, data, and models to develop more comprehensive\nand effective AI solutions. Therefore, the effective development and deployment\nof industrial AI require a more comprehensive and systematic approach. To\naddress this gap, this paper reviews previous research, rethinks the role of\nindustrial AI, and proposes a unified industrial AI foundation framework\ncomprising three core modules: the knowledge module, data module, and model\nmodule. These modules help to extend and enhance the industrial AI methodology\nplatform, supporting various industrial applications. In addition, a case study\non rotating machinery diagnosis is presented to demonstrate the effectiveness\nof the proposed framework, and several future directions are highlighted for\nthe development of the industrial AI foundation framework.",
      "tldr_zh": "该论文重新审视工业人工智能（industrial AI）的现状，指出现有方法过度关注算法和模型，而忽略了系统整合领域知识、数据和模型的重要性。作者提出一个统一的工业 AI 基础框架，包括三个核心模块：knowledge module、data module 和 model module，以扩展并增强工业 AI 方法平台，支持各种应用。通过一个旋转机械诊断的案例研究，框架证明了其有效性，并为未来工业 AI 发展方向提供了指导。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "The paper submitted to IJAMD, the International Journal of AI for\n  Materials and Design, has been accepted",
      "pdf_url": "http://arxiv.org/pdf/2504.01797v2",
      "published_date": "2025-04-02 15:05:32 UTC",
      "updated_date": "2025-04-17 02:54:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:50:08.927386"
    },
    {
      "arxiv_id": "2504.01783v1",
      "title": "CLaP -- State Detection from Time Series",
      "title_zh": "翻译失败",
      "authors": [
        "Arik Ermshaus",
        "Patrick Schäfer",
        "Ulf Leser"
      ],
      "abstract": "The ever-growing amount of sensor data from machines, smart devices, and the\nenvironment leads to an abundance of high-resolution, unannotated time series\n(TS). These recordings encode the recognizable properties of latent states and\ntransitions from physical phenomena that can be modelled as abstract processes.\nThe unsupervised localization and identification of these states and their\ntransitions is the task of time series state detection (TSSD). We introduce\nCLaP, a new, highly accurate and efficient algorithm for TSSD. It leverages the\npredictive power of time series classification for TSSD in an unsupervised\nsetting by applying novel self-supervision techniques to detect whether data\nsegments emerge from the same state or not. To this end, CLaP cross-validates a\nclassifier with segment-labelled subsequences to quantify confusion between\nsegments. It merges labels from segments with high confusion, representing the\nsame latent state, if this leads to an increase in overall classification\nquality. We conducted an experimental evaluation using 391 TS from four\nbenchmarks and found CLaP to be significantly more precise in detecting states\nthan five state-of-the-art competitors. It achieves the best accuracy-runtime\ntradeoff and is scalable to large TS. We provide a Python implementation of\nCLaP, which can be deployed in TS analysis workflows.",
      "tldr_zh": "本研究针对大量未标注的时间序列 (TS) 数据，提出了一种高效算法 CLaP，用于时间序列状态检测 (TSSD)，旨在无监督地识别潜在状态和转换。CLaP 通过自监督技术利用 TS 分类的预测能力，量化数据段之间的混淆，并合并高混淆段的标签，以提高整体分类质量。实验在 391 个 TS 基准上显示，CLaP 比五种最先进方法更精确，并实现了最佳的准确性-运行时权衡，同时提供可扩展的 Python 实现，适用于 TS 分析工作流。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01783v1",
      "published_date": "2025-04-02 14:46:42 UTC",
      "updated_date": "2025-04-02 14:46:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:50:20.745068"
    },
    {
      "arxiv_id": "2504.02889v1",
      "title": "Embedding Method for Knowledge Graph with Densely Defined Ontology",
      "title_zh": "翻译失败",
      "authors": [
        "Takanori Ugai"
      ],
      "abstract": "Knowledge graph embedding (KGE) is a technique that enhances knowledge graphs\nby addressing incompleteness and improving knowledge retrieval. A limitation of\nthe existing KGE models is their underutilization of ontologies, specifically\nthe relationships between properties. This study proposes a KGE model, TransU,\ndesigned for knowledge graphs with well-defined ontologies that incorporate\nrelationships between properties. The model treats properties as a subset of\nentities, enabling a unified representation. We present experimental results\nusing a standard dataset and a practical dataset.",
      "tldr_zh": "本研究指出，现有的 Knowledge Graph Embedding (KGE) 模型未充分利用 ontologies 中属性之间的关系，导致知识图的表示不完善。为解决这一问题，提出了一种新模型 TransU，该模型将 properties 视为 entities 的子集，实现统一的知识表示。实验结果基于标准数据集和实际数据集，展示了 TransU 的有效性。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "6pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.02889v1",
      "published_date": "2025-04-02 14:43:47 UTC",
      "updated_date": "2025-04-02 14:43:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:50:32.498220"
    },
    {
      "arxiv_id": "2504.01771v1",
      "title": "Enhancing Interpretability in Generative AI Through Search-Based Data Influence Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Theodoros Aivalis",
        "Iraklis A. Klampanos",
        "Antonis Troumpoukis",
        "Joemon M. Jose"
      ],
      "abstract": "Generative AI models offer powerful capabilities but often lack transparency,\nmaking it difficult to interpret their output. This is critical in cases\ninvolving artistic or copyrighted content. This work introduces a\nsearch-inspired approach to improve the interpretability of these models by\nanalysing the influence of training data on their outputs. Our method provides\nobservational interpretability by focusing on a model's output rather than on\nits internal state. We consider both raw data and latent-space embeddings when\nsearching for the influence of data items in generated content. We evaluate our\nmethod by retraining models locally and by demonstrating the method's ability\nto uncover influential subsets in the training data. This work lays the\ngroundwork for future extensions, including user-based evaluations with domain\nexperts, which is expected to improve observational interpretability further.",
      "tldr_zh": "这篇论文提出了一种基于搜索的(data influence analysis)方法，以提升Generative AI模型的可解释性，通过分析训练数据对输出结果的影响，从而解决模型透明度不足的问题，尤其在涉及艺术或版权内容时。\n该方法采用观察性(observational interpretability)策略，关注模型输出而非内部状态，利用原始数据(raw data)和潜在空间嵌入(latent-space embeddings)来搜索和识别影响数据项。\n实验通过本地重训练模型和发现训练数据中的关键子集来验证其有效性，为未来扩展（如与领域专家的用户评估）奠定基础。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01771v1",
      "published_date": "2025-04-02 14:29:37 UTC",
      "updated_date": "2025-04-02 14:29:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:50:45.981732"
    },
    {
      "arxiv_id": "2504.01767v1",
      "title": "Leveraging Embedding Techniques in Multimodal Machine Learning for Mental Illness Assessment",
      "title_zh": "在多模态机器学习中",
      "authors": [
        "Abdelrahaman A. Hassan",
        "Abdelrahman A. Ali",
        "Aya E. Fouda",
        "Radwa J. Hanafy",
        "Mohammed E. Fouda"
      ],
      "abstract": "The increasing global prevalence of mental disorders, such as depression and\nPTSD, requires objective and scalable diagnostic tools. Traditional clinical\nassessments often face limitations in accessibility, objectivity, and\nconsistency. This paper investigates the potential of multimodal machine\nlearning to address these challenges, leveraging the complementary information\navailable in text, audio, and video data. Our approach involves a comprehensive\nanalysis of various data preprocessing techniques, including novel chunking and\nutterance-based formatting strategies. We systematically evaluate a range of\nstate-of-the-art embedding models for each modality and employ Convolutional\nNeural Networks (CNNs) and Bidirectional LSTM Networks (BiLSTMs) for feature\nextraction. We explore data-level, feature-level, and decision-level fusion\ntechniques, including a novel integration of Large Language Model (LLM)\npredictions. We also investigate the impact of replacing Multilayer Perceptron\nclassifiers with Support Vector Machines. We extend our analysis to severity\nprediction using PHQ-8 and PCL-C scores and multi-class classification\n(considering co-occurring conditions). Our results demonstrate that\nutterance-based chunking significantly improves performance, particularly for\ntext and audio modalities. Decision-level fusion, incorporating LLM\npredictions, achieves the highest accuracy, with a balanced accuracy of 94.8%\nfor depression and 96.2% for PTSD detection. The combination of CNN-BiLSTM\narchitectures with utterance-level chunking, coupled with the integration of\nexternal LLM, provides a powerful and nuanced approach to the detection and\nassessment of mental health conditions. Our findings highlight the potential of\nMMML for developing more accurate, accessible, and personalized mental\nhealthcare tools.",
      "tldr_zh": "本研究探讨了多模态机器学习（Multimodal Machine Learning）在心理疾病评估中的应用，旨在解决传统评估的客观性和可访问性问题，通过整合文本、音频和视频数据来检测抑郁和PTSD等疾病。研究评估了各种数据预处理技术（如utterance-based chunking）、嵌入模型、特征提取方法（包括CNN和BiLSTM），并探索了数据级、特征级和决策级融合策略，同时整合Large Language Model (LLM)预测并使用Support Vector Machines (SVM)替代Multilayer Perceptron分类器。结果显示，utterance-based chunking显著提升了文本和音频模态的性能，而决策级融合结合LLM实现了最高准确率，抑郁检测的平衡准确率达94.8%，PTSD达96.2%，为开发更精确和个性化的心理健康工具提供了有力依据。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01767v1",
      "published_date": "2025-04-02 14:19:06 UTC",
      "updated_date": "2025-04-02 14:19:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:50:57.231201"
    },
    {
      "arxiv_id": "2504.01764v1",
      "title": "Dual-stream Transformer-GCN Model with Contextualized Representations Learning for Monocular 3D Human Pose Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Mingrui Ye",
        "Lianping Yang",
        "Hegui Zhu",
        "Zenghao Zheng",
        "Xin Wang",
        "Yantao Lo"
      ],
      "abstract": "This paper introduces a novel approach to monocular 3D human pose estimation\nusing contextualized representation learning with the Transformer-GCN\ndual-stream model. Monocular 3D human pose estimation is challenged by depth\nambiguity, limited 3D-labeled training data, imbalanced modeling, and\nrestricted model generalization. To address these limitations, our work\nintroduces a groundbreaking motion pre-training method based on contextualized\nrepresentation learning. Specifically, our method involves masking 2D pose\nfeatures and utilizing a Transformer-GCN dual-stream model to learn\nhigh-dimensional representations through a self-distillation setup. By focusing\non contextualized representation learning and spatial-temporal modeling, our\napproach enhances the model's ability to understand spatial-temporal\nrelationships between postures, resulting in superior generalization.\nFurthermore, leveraging the Transformer-GCN dual-stream model, our approach\neffectively balances global and local interactions in video pose estimation.\nThe model adaptively integrates information from both the Transformer and GCN\nstreams, where the GCN stream effectively learns local relationships between\nadjacent key points and frames, while the Transformer stream captures\ncomprehensive global spatial and temporal features. Our model achieves\nstate-of-the-art performance on two benchmark datasets, with an MPJPE of 38.0mm\nand P-MPJPE of 31.9mm on Human3.6M, and an MPJPE of 15.9mm on MPI-INF-3DHP.\nFurthermore, visual experiments on public datasets and in-the-wild videos\ndemonstrate the robustness and generalization capabilities of our approach.",
      "tldr_zh": "本论文提出了一种基于上下文化表示学习的新方法，用于Monocular 3D Human Pose Estimation，通过Transformer-GCN双流模型解决深度模糊、数据限制和模型泛化等问题。该方法涉及屏蔽2D姿势特征，并采用self-distillation设置学习高维表示，同时平衡Transformer流（捕获全局空间-时间特征）和GCN流（学习局部关键点关系）。实验结果显示，该模型在Human3.6M数据集上达到最先进性能（MPJPE 38.0mm、P-MPJPE 31.9mm）和MPI-INF-3DHP数据集上MPJPE 15.9mm，并证明了其鲁棒性和泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01764v1",
      "published_date": "2025-04-02 14:17:57 UTC",
      "updated_date": "2025-04-02 14:17:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:51:10.952113"
    },
    {
      "arxiv_id": "2504.01738v1",
      "title": "Style over Substance: Distilled Language Models Reason Via Stylistic Replication",
      "title_zh": "风格胜过实质：蒸馏语言模型通过风格复制进行推理",
      "authors": [
        "Philip Lippmann",
        "Jie Yang"
      ],
      "abstract": "Specialized reasoning language models (RLMs) have demonstrated that scaling\ntest-time computation through detailed reasoning traces significantly enhances\nperformance. Although these traces effectively facilitate knowledge\ndistillation into smaller, instruction-tuned models, the precise nature of\ntransferred reasoning remains unclear. In this study, we investigate to what\nextent distilled models internalize replicated stylistic patterns during\nreasoning. To this end, we systematically analyze reasoning traces, identifying\nstructural and lexical patterns that characterize successful reasoning. We then\nintroduce two new datasets -- a dataset of emergent reasoning traces and a\nsynthetic dataset explicitly constructed to replicate these stylistic patterns\n-- to precisely examine their influence on distilled models' reasoning\ncapabilities. We find that models trained on the synthetic traces achieve\ncomparable performance, indicating that distilled reasoning abilities rely\nsignificantly on surface-level patterns. Surprisingly, we observe an increase\nin performance even when the synthetic traces are altered to lead to the wrong\nanswer. Our findings highlight how stylistic patterns can be leveraged to\nefficiently enhance LM reasoning across diverse model families.",
      "tldr_zh": "本研究调查了专门的推理语言模型（RLMs）通过知识蒸馏（knowledge distillation）将推理痕迹（traces）转移到更小模型中的机制，发现这些模型主要依赖于表面层的结构和词汇模式，而不是实质内容。作者分析了推理痕迹中的模式，并引入了两个新数据集——一个紧急推理痕迹数据集和一个合成数据集——来评估这些风格模式对模型性能的影响。实验结果显示，训练模型使用合成痕迹可实现类似性能，甚至在这些痕迹被修改导致错误答案时，性能仍有所提升。这些发现突出了风格模式在提升语言模型（LM）推理能力方面的潜在价值。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01738v1",
      "published_date": "2025-04-02 13:50:20 UTC",
      "updated_date": "2025-04-02 13:50:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:51:23.027501"
    },
    {
      "arxiv_id": "2504.01735v1",
      "title": "AdPO: Enhancing the Adversarial Robustness of Large Vision-Language Models with Preference Optimization",
      "title_zh": "AdPO：通过偏好优化增强大型视觉语言模型的对抗鲁棒性",
      "authors": [
        "Chaohu Liu",
        "Tianyi Gui",
        "Yu Liu",
        "Linli Xu"
      ],
      "abstract": "Large Vision-Language Models (LVLMs), such as GPT-4o and LLaVA, have recently\nwitnessed remarkable advancements and are increasingly being deployed in\nreal-world applications. However, inheriting the sensitivity of visual neural\nnetworks, LVLMs remain vulnerable to adversarial attacks, which can result in\nerroneous or malicious outputs. While existing efforts utilize adversarial\nfine-tuning to enhance robustness, they often suffer from performance\ndegradation on clean inputs. In this paper, we proposes AdPO, a novel\nadversarial defense strategy for LVLMs based on preference optimization. For\nthe first time, we reframe adversarial training as a preference optimization\nproblem, aiming to enhance the model's preference for generating normal outputs\non clean inputs while rejecting the potential misleading outputs for\nadversarial examples. Notably, AdPO achieves this by solely modifying the image\nencoder, e.g., CLIP ViT, resulting in superior clean and adversarial\nperformance in a variety of downsream tasks. Considering that training involves\nlarge language models (LLMs), the computational cost increases significantly.\nWe validate that training on smaller LVLMs and subsequently transferring to\nlarger models can achieve competitive performance while maintaining efficiency\ncomparable to baseline methods. Our comprehensive experiments confirm the\neffectiveness of the proposed AdPO, which provides a novel perspective for\nfuture adversarial defense research.",
      "tldr_zh": "该研究针对大型视觉语言模型(LVLMs)，如 GPT-4o 和 LLaVA，提出了 AdPO，一种基于偏好优化的对抗防御策略，以提升模型对对抗攻击的鲁棒性。AdPO 将对抗训练重新框架为偏好优化问题，仅修改图像编码器（如 CLIP ViT），使模型更倾向于生成干净输入的正常输出，同时拒绝对抗样本的误导输出。实验结果显示，AdPO 在各种下游任务中实现了优越的干净和对抗性能，并通过在较小 LVLMs 上训练再转移到更大模型，保持了与基线方法相当的计算效率，为未来的对抗防御研究提供了新视角。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01735v1",
      "published_date": "2025-04-02 13:43:21 UTC",
      "updated_date": "2025-04-02 13:43:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:51:34.198761"
    },
    {
      "arxiv_id": "2504.01733v1",
      "title": "Epistemic Skills: Reasoning about Knowledge and Oblivion",
      "title_zh": "认识论技能：关于知识和遗忘的推理",
      "authors": [
        "Xiaolong Liang",
        "Yì N. Wáng"
      ],
      "abstract": "This paper presents a class of epistemic logics that captures the dynamics of\nacquiring knowledge and descending into oblivion, while incorporating concepts\nof group knowledge. The approach is grounded in a system of weighted models,\nintroducing an ``epistemic skills'' metric to represent the epistemic\ncapacities tied to knowledge updates. Within this framework, knowledge\nacquisition is modeled as a process of upskilling, whereas oblivion is\nrepresented as a consequence of downskilling. The framework further enables\nexploration of ``knowability'' and ``forgettability,'' defined as the potential\nto gain knowledge through upskilling and to lapse into oblivion through\ndownskilling, respectively. Additionally, it supports a detailed analysis of\nthe distinctions between epistemic de re and de dicto expressions. The\ncomputational complexity of the model checking and satisfiability problems is\nexamined, offering insights into their theoretical foundations and practical\nimplications.",
      "tldr_zh": "本论文提出了一种 epistemic logics 类，用于捕捉知识获取（upskilling）和遗忘（downskilling）的动态，同时纳入 group knowledge 概念。该框架基于 weighted models 系统，引入 \"epistemic skills\" 指标来量化认知能力与知识更新的关系，并定义了 \"knowability\"（通过 upskilling 获得知识的潜力）和 \"forgettability\"（通过 downskilling 导致遗忘的潜力）。此外，该系统支持分析 epistemic de re 和 de dicto 表达的区别，并考察了模型检查和可满足性问题的计算复杂度，提供理论基础和实际应用洞见。",
      "categories": [
        "cs.AI",
        "cs.CC",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01733v1",
      "published_date": "2025-04-02 13:41:42 UTC",
      "updated_date": "2025-04-02 13:41:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:51:46.282026"
    },
    {
      "arxiv_id": "2504.01724v3",
      "title": "DreamActor-M1: Holistic, Expressive and Robust Human Image Animation with Hybrid Guidance",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxuan Luo",
        "Zhengkun Rong",
        "Lizhen Wang",
        "Longhao Zhang",
        "Tianshu Hu",
        "Yongming Zhu"
      ],
      "abstract": "While recent image-based human animation methods achieve realistic body and\nfacial motion synthesis, critical gaps remain in fine-grained holistic\ncontrollability, multi-scale adaptability, and long-term temporal coherence,\nwhich leads to their lower expressiveness and robustness. We propose a\ndiffusion transformer (DiT) based framework, DreamActor-M1, with hybrid\nguidance to overcome these limitations. For motion guidance, our hybrid control\nsignals that integrate implicit facial representations, 3D head spheres, and 3D\nbody skeletons achieve robust control of facial expressions and body movements,\nwhile producing expressive and identity-preserving animations. For scale\nadaptation, to handle various body poses and image scales ranging from\nportraits to full-body views, we employ a progressive training strategy using\ndata with varying resolutions and scales. For appearance guidance, we integrate\nmotion patterns from sequential frames with complementary visual references,\nensuring long-term temporal coherence for unseen regions during complex\nmovements. Experiments demonstrate that our method outperforms the\nstate-of-the-art works, delivering expressive results for portraits,\nupper-body, and full-body generation with robust long-term consistency. Project\nPage: https://grisoon.github.io/DreamActor-M1/.",
      "tldr_zh": "该研究提出DreamActor-M1框架，一种基于Diffusion Transformer (DiT)的系统，用于实现整体性、表达性和鲁棒的人体图像动画，通过Hybrid Guidance解决现有方法的细粒度可控性、多尺度适应性和长期时间一致性问题。为运动指导，该框架整合隐式面部表示、3D头部球体和3D身体骨骼，实现面部表情和身体运动的精确控制，同时保持身份不变。为尺度适应和外观指导，它采用渐进式训练策略处理不同分辨率和尺度的数据，并结合顺序帧的运动模式与视觉参考，确保复杂运动中的长期一致性。实验结果显示，DreamActor-M1在肖像、上身和全身生成任务中优于现有最先进方法，提供更具表达性和鲁棒性的动画结果。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01724v3",
      "published_date": "2025-04-02 13:30:32 UTC",
      "updated_date": "2025-04-20 11:52:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:51:59.143319"
    },
    {
      "arxiv_id": "2504.01707v2",
      "title": "InfiniteICL: Breaking the Limit of Context Window Size via Long Short-term Memory Transformation",
      "title_zh": "InfiniteICL：通过长短期记忆转换打破上下文窗口大小的限制",
      "authors": [
        "Bowen Cao",
        "Deng Cai",
        "Wai Lam"
      ],
      "abstract": "In-context learning (ICL) is critical for large language models (LLMs), but\nits effectiveness is constrained by finite context windows, particularly in\nultra-long contexts. To overcome this, we introduce InfiniteICL, a framework\nthat parallels context and parameters in LLMs with short- and long-term memory\nin human cognitive systems, focusing on transforming temporary context\nknowledge into permanent parameter updates. This approach significantly reduces\nmemory usage, maintains robust performance across varying input lengths, and\ntheoretically enables infinite context integration through the principles of\ncontext knowledge elicitation, selection, and consolidation. Evaluations\ndemonstrate that our method reduces context length by 90% while achieving 103%\naverage performance of full-context prompting across fact recall, grounded\nreasoning, and skill acquisition tasks. When conducting sequential multi-turn\ntransformations on complex, real-world contexts (with length up to 2M tokens),\nour approach surpasses full-context prompting while using only 0.4% of the\noriginal contexts. These findings highlight InfiniteICL's potential to enhance\nthe scalability and efficiency of LLMs by breaking the limitations of\nconventional context window sizes.",
      "tldr_zh": "该研究提出 InfiniteICL 框架，通过 Long Short-term Memory Transformation 将大语言模型 (LLMs) 的上下文学习 (ICL) 限制突破，类比人类短期和长期记忆系统，将临时上下文知识转化为永久参数更新，从而显著减少内存使用并实现理论上的无限上下文整合。框架核心包括上下文知识的提取、选择和整合原则，在事实回忆、推理和技能获取任务中，InfiniteICL 将上下文长度减少 90%，性能达到全上下文提示的 103%。实验显示，在处理长达 2M 标记的复杂真实场景时，该方法仅使用 0.4% 的原始上下文就超越了全上下文提示，展示了提升 LLMs 可扩展性和效率的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01707v2",
      "published_date": "2025-04-02 13:15:44 UTC",
      "updated_date": "2025-04-03 08:53:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:52:10.673619"
    },
    {
      "arxiv_id": "2504.01705v1",
      "title": "Sky of Unlearning (SoUL): Rewiring Federated Machine Unlearning via Selective Pruning",
      "title_zh": "翻译失败",
      "authors": [
        "Md Mahabub Uz Zaman",
        "Xiang Sun",
        "Jingjing Yao"
      ],
      "abstract": "The Internet of Drones (IoD), where drones collaborate in data collection and\nanalysis, has become essential for applications such as surveillance and\nenvironmental monitoring. Federated learning (FL) enables drones to train\nmachine learning models in a decentralized manner while preserving data\nprivacy. However, FL in IoD networks is susceptible to attacks like data\npoisoning and model inversion. Federated unlearning (FU) mitigates these risks\nby eliminating adversarial data contributions, preventing their influence on\nthe model. This paper proposes sky of unlearning (SoUL), a federated unlearning\nframework that efficiently removes the influence of unlearned data while\nmaintaining model performance. A selective pruning algorithm is designed to\nidentify and remove neurons influential in unlearning but minimally impact the\noverall performance of the model. Simulations demonstrate that SoUL outperforms\nexisting unlearning methods, achieves accuracy comparable to full retraining,\nand reduces computation and communication overhead, making it a scalable and\nefficient solution for resource-constrained IoD networks.",
      "tldr_zh": "这篇论文针对Internet of Drones (IoD)网络中Federated Learning (FL)的安全风险，如数据中毒和模型反演，提出Sky of Unlearning (SoUL)框架，用于高效的Federated Unlearning (FU)。SoUL通过Selective Pruning算法识别并移除对未学习数据有影响但对整体模型性能影响小的神经元，从而消除敌对数据的影响。实验模拟显示，SoUL优于现有方法，实现了与完全重训练相当的准确率，同时显著降低了计算和通信开销，适合资源受限的IoD环境。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "6 pages, 6 figures, IEEE International Conference on Communications\n  (ICC 2025)",
      "pdf_url": "http://arxiv.org/pdf/2504.01705v1",
      "published_date": "2025-04-02 13:07:30 UTC",
      "updated_date": "2025-04-02 13:07:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:52:22.601933"
    },
    {
      "arxiv_id": "2504.01700v1",
      "title": "Reasoning LLMs for User-Aware Multimodal Conversational Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Hamed Rahimi",
        "Jeanne Cattoni",
        "Meriem Beghili",
        "Mouad Abrini",
        "Mahdi Khoramshahi",
        "Maribel Pino",
        "Mohamed Chetouani"
      ],
      "abstract": "Personalization in social robotics is critical for fostering effective\nhuman-robot interactions, yet systems often face the cold start problem, where\ninitial user preferences or characteristics are unavailable. This paper\nproposes a novel framework called USER-LLM R1 for a user-aware conversational\nagent that addresses this challenge through dynamic user profiling and model\ninitiation. Our approach integrates chain-of-thought (CoT) reasoning models to\niteratively infer user preferences and vision-language models (VLMs) to\ninitialize user profiles from multimodal inputs, enabling personalized\ninteractions from the first encounter. Leveraging a Retrieval-Augmented\nGeneration (RAG) architecture, the system dynamically refines user\nrepresentations within an inherent CoT process, ensuring contextually relevant\nand adaptive responses. Evaluations on the ElderlyTech-VQA Bench demonstrate\nsignificant improvements in ROUGE-1 (+23.2%), ROUGE-2 (+0.6%), and ROUGE-L\n(+8%) F1 scores over state-of-the-art baselines, with ablation studies\nunderscoring the impact of reasoning model size on performance. Human\nevaluations further validate the framework's efficacy, particularly for elderly\nusers, where tailored responses enhance engagement and trust. Ethical\nconsiderations, including privacy preservation and bias mitigation, are\nrigorously discussed and addressed to ensure responsible deployment.",
      "tldr_zh": "该论文提出USER-LLM R1框架，用于构建用户感知的多模态对话代理，解决社交机器人中冷启动问题，通过动态用户画像和模型初始化实现个性化交互。该框架整合Chain-of-Thought (CoT)推理模型来迭代推断用户偏好，以及Vision-Language Models (VLMs)从多模态输入中初始化用户配置文件，并利用Retrieval-Augmented Generation (RAG)架构在CoT过程中动态优化响应。实验结果显示，在ElderlyTech-VQA Bench上，该框架的ROUGE-1 (+23.2%)、ROUGE-2 (+0.6%)和ROUGE-L (+8%) F1分数显著优于现有基准，人评验证其提升了老年用户的参与度和信任。论文还讨论了隐私保护和偏见缓解等伦理考虑，以确保负责任的部署。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01700v1",
      "published_date": "2025-04-02 13:00:17 UTC",
      "updated_date": "2025-04-02 13:00:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:52:36.448952"
    },
    {
      "arxiv_id": "2504.01698v3",
      "title": "Do Theory of Mind Benchmarks Need Explicit Human-like Reasoning in Language Models?",
      "title_zh": "翻译失败",
      "authors": [
        "Yi-Long Lu",
        "Chunhui Zhang",
        "Jiajun Song",
        "Lifeng Fan",
        "Wei Wang"
      ],
      "abstract": "Theory of Mind (ToM), the ability to attribute mental states to others, is\nfundamental for human social intelligence and a critical capability for\nadvanced Artificial Intelligence. Recent advancements in Large Language Models\n(LLMs) have shown promising performance on ToM benchmarks, raising the\nquestion: Do these benchmarks necessitate explicit human-like reasoning\nprocesses, or can models succeed through alternative strategies? We investigate\nthis question empirically by applying Reinforcement Learning (RL) and\nSupervised Fine-Tuning (SFT) to LLMs of varying scales (0.5B to 7B parameters)\nand evaluating them across multiple ToM datasets. Our results reveal a\nscale-dependent impact of RL: while RL significantly improves accuracy and\nfosters high-quality, interpretable, and transferable belief-tracking reasoning\nin larger models (7B), it leads to \"reasoning collapse\" in smaller models\n($\\leq$3B), where high accuracy and generalization ability are achieved via\ndrastically shortened, less meaningful responses. Surprisingly, further SFT\nachieves competitive and generalizable performance across these benchmarks,\noften matching or exceeding RL models in accuracy, despite not being explicitly\ntrained to produce structured reasoning traces. These findings highlight a\ncritical discrepancy between benchmark accuracy and the nature of learned\nreasoning. Our work suggests that current ToM benchmarks may be solvable\nwithout requiring the explicit, human-like simulation of mental states they\nwere designed to probe. LLMs, particularly when scale is limited or training\nsignals focus solely on output correctness, may leverage alternative rules\neffective for benchmark data structures.",
      "tldr_zh": "本研究探讨了Theory of Mind (ToM)基准测试是否需要Large Language Models (LLMs)进行显式人类-like推理，通过Reinforcement Learning (RL)和Supervised Fine-Tuning (SFT)在0.5B至7B参数规模的模型上进行实验。结果显示，RL在较大模型（7B）上显著提高准确率并促进高质量、可解释的推理，但在大模型（≤3B）上导致“reasoning collapse”，即通过简化响应实现高准确率却缺乏意义。SFT则在不需显式训练结构化推理的情况下，达到与RL相当或更高的准确率和泛化性能。这些发现表明，当前ToM基准可能依赖模型的替代策略而非真正的人类-like心理状态模拟，暴露了基准测试的局限性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01698v3",
      "published_date": "2025-04-02 12:58:42 UTC",
      "updated_date": "2025-05-16 07:38:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:52:47.282859"
    },
    {
      "arxiv_id": "2504.01692v1",
      "title": "Segmentation variability and radiomics stability for predicting Triple-Negative Breast Cancer subtype using Magnetic Resonance Imaging",
      "title_zh": "翻译失败",
      "authors": [
        "Isabella Cama",
        "Alejandro Guzmán",
        "Cristina Campi",
        "Michele Piana",
        "Karim Lekadir",
        "Sara Garbarino",
        "Oliver Díaz"
      ],
      "abstract": "Most papers caution against using predictive models for disease\nstratification based on unselected radiomic features, as these features are\naffected by contouring variability. Instead, they advocate for the use of the\nIntraclass Correlation Coefficient (ICC) as a measure of stability for feature\nselection. However, the direct effect of segmentation variability on the\npredictive models is rarely studied. This study investigates the impact of\nsegmentation variability on feature stability and predictive performance in\nradiomics-based prediction of Triple-Negative Breast Cancer (TNBC) subtype\nusing Magnetic Resonance Imaging. A total of 244 images from the Duke dataset\nwere used, with segmentation variability introduced through modifications of\nmanual segmentations. For each mask, explainable radiomic features were\nselected using the Shapley Additive exPlanations method and used to train\nlogistic regression models. Feature stability across segmentations was assessed\nvia ICC, Pearson's correlation, and reliability scores quantifying the\nrelationship between feature stability and segmentation variability. Results\nindicate that segmentation accuracy does not significantly impact predictive\nperformance. While incorporating peritumoral information may reduce feature\nreproducibility, it does not diminish feature predictive capability. Moreover,\nfeature selection in predictive models is not inherently tied to feature\nstability with respect to segmentation, suggesting that an overreliance on ICC\nor reliability scores for feature selection might exclude valuable predictive\nfeatures.",
      "tldr_zh": "本研究探讨了使用磁共振成像(MRI)预测三阴性乳腺癌(TNBC)亚型时，分割变异性对放射组学特征稳定性和预测性能的影响。研究者利用Duke数据集的244张图像，通过修改手动分割引入变异性，并采用Shapley Additive exPlanations (SHAP)方法选择可解释特征来训练逻辑回归模型，同时评估特征稳定性使用Intraclass Correlation Coefficient (ICC)、Pearson相关性和可靠性分数。结果表明，分割准确性对预测性能影响不大，即使加入肿瘤周围信息可能降低特征可重复性，但不会削弱其预测能力；此外，特征选择不应过度依赖稳定性指标，如ICC，以避免排除有价值的预测特征。",
      "categories": [
        "stat.AP",
        "cs.AI",
        "62P10 (Primary), 68T09 (Secondary)"
      ],
      "primary_category": "stat.AP",
      "comment": "22 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.01692v1",
      "published_date": "2025-04-02 12:48:01 UTC",
      "updated_date": "2025-04-02 12:48:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:52:59.624473"
    },
    {
      "arxiv_id": "2504.01690v1",
      "title": "Token Pruning in Audio Transformers: Optimizing Performance and Decoding Patch Importance",
      "title_zh": "翻译失败",
      "authors": [
        "Taehan Lee",
        "Hyukjun Lee"
      ],
      "abstract": "Vision Transformers (ViTs) have achieved state-of-the-art performance across\nvarious computer vision tasks, but their high computational cost remains a\nchallenge. Token pruning has been proposed to reduce this cost by selectively\nremoving less important tokens. While effective in vision tasks by discarding\nnon-object regions, applying this technique to audio tasks presents unique\nchallenges, as distinguishing relevant from irrelevant regions in\ntime-frequency representations is less straightforward. In this study, for the\nfirst time, we applied token pruning to ViT-based audio classification models\nusing Mel-spectrograms and analyzed the trade-offs between model performance\nand computational cost: TopK token pruning can reduce MAC operations of\nAudioMAE and AST by 30-40%, with less than a 1% drop in classification\naccuracy. Our analysis reveals that while high-intensity tokens contribute\nsignificantly to model accuracy, low-intensity tokens remain important. In\nparticular, they play a more critical role in general audio classification\ntasks than in speech-specific tasks.",
      "tldr_zh": "本文首次将 token pruning 技术应用于基于 Vision Transformers (ViTs) 的音频分类模型，使用 Mel-spectrograms，旨在减少计算成本并分析音频任务中的 token 重要性。该方法通过 TopK token pruning 可以将 AudioMAE 和 AST 模型的 MAC operations 减少 30-40%，而分类准确率仅下降不到 1%。研究发现，高强度 tokens 对模型性能贡献较大，但低强度 tokens 在一般音频分类任务中比语音特定任务更关键，这为音频 Transformer 的优化提供了新见解。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "This work has been submitted to the IEEE for possible publication.\n  Source code is available at\n  https://github.com/andylee-24/token-pruning-audio-transformer",
      "pdf_url": "http://arxiv.org/pdf/2504.01690v1",
      "published_date": "2025-04-02 12:44:38 UTC",
      "updated_date": "2025-04-02 12:44:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:53:10.586157"
    },
    {
      "arxiv_id": "2504.01673v1",
      "title": "K-P Quantum Neural Networks",
      "title_zh": "K-P 量子神经网络",
      "authors": [
        "Elija Perrier"
      ],
      "abstract": "We present an extension of K-P time-optimal quantum control solutions using\nglobal Cartan $KAK$ decompositions for geodesic-based solutions. Extending\nrecent time-optimal \\emph{constant-$\\theta$} control results, we integrate\nCartan methods into equivariant quantum neural network (EQNN) for quantum\ncontrol tasks. We show that a finite-depth limited EQNN ansatz equipped with\nCartan layers can replicate the constant-$\\theta$ sub-Riemannian geodesics for\nK-P problems. We demonstrate how for certain classes of control problem on\nRiemannian symmetric spaces, gradient-based training using an appropriate cost\nfunction converges to certain global time-optimal solutions when satisfying\nsimple regularity conditions. This generalises prior geometric control theory\nmethods and clarifies how optimal geodesic estimation can be performed in\nquantum machine learning contexts.",
      "tldr_zh": "本研究扩展了 K-P 时间最优量子控制解决方案，通过使用全局 Cartan $KAK$ 分解来实现基于测地线的改进。具体地，将 Cartan 方法整合到等价量子神经网络 (EQNN) 中，用于量子控制任务，并展示了有限深度 EQNN 结构配备 Cartan 层能够复制 constant-$\\theta$ 子黎曼测地线。实验证明，对于某些 Riemannian 对称空间上的控制问题，采用适当的成本函数进行梯度训练可在满足简单正则条件时收敛到全局时间最优解。该方法推广了现有的几何控制理论，并阐明了在量子机器学习环境中进行最优测地线估计的可行性。",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2504.01673v1",
      "published_date": "2025-04-02 12:22:18 UTC",
      "updated_date": "2025-04-02 12:22:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:53:22.301033"
    },
    {
      "arxiv_id": "2504.01671v1",
      "title": "Anomaly Detection for Hybrid Butterfly Subspecies via Probability Filtering",
      "title_zh": "翻译失败",
      "authors": [
        "Bo-Kai Ruan",
        "Yi-Zeng Fang",
        "Hong-Han Shuai",
        "Juinn-Dar Huang"
      ],
      "abstract": "Detecting butterfly hybrids requires knowledge of the parent subspecies, and\nthe process can be tedious when encountering a new subspecies. This study\nfocuses on a specific scenario where a model trained to recognize hybrid\nspecies A can generalize to species B when B biologically mimics A. Since\nspecies A and B share similar patterns, we leverage BioCLIP as our feature\nextractor to capture features based on their taxonomy. Consequently, the\nalgorithm designed for species A can be transferred to B, as their hybrid and\nnon-hybrid patterns exhibit similar relationships. To determine whether a\nbutterfly is a hybrid, we adopt proposed probability filtering and color\njittering to augment and simulate the mimicry. With these approaches, we\nachieve second place in the official development phase. Our code is publicly\navailable at https://github.com/Justin900429/NSF-HDR-Challenge.",
      "tldr_zh": "这篇论文针对蝴蝶杂交品种的异常检测问题，提出了一种基于Probability Filtering的方法，以解决在新品种出现时的识别挑战。研究利用BioCLIP作为特征提取器，将训练于品种A的模型泛化到生物上模仿A的品种B，利用其相似模式和Color Jittering数据增强来模拟杂交关系，从而判断蝴蝶是否为杂交个体。实验结果显示，该方法在官方竞赛开发阶段获得第二名，相关代码已在GitHub上公开。",
      "categories": [
        "cs.CE",
        "cs.AI"
      ],
      "primary_category": "cs.CE",
      "comment": "AAAI'25 Workshop in Anomaly Detection in Scientific Domains",
      "pdf_url": "http://arxiv.org/pdf/2504.01671v1",
      "published_date": "2025-04-02 12:18:44 UTC",
      "updated_date": "2025-04-02 12:18:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:53:35.417112"
    },
    {
      "arxiv_id": "2504.01652v1",
      "title": "Market-Oriented Flow Allocation for Thermal Solar Plants: An Auction-Based Methodology with Artificial Intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Sara Ruiz-Moreno",
        "Antonio J. Gallego",
        "Manuel Macías",
        "Eduardo F. Camacho"
      ],
      "abstract": "This paper presents a novel method to optimize thermal balance in parabolic\ntrough collector (PTC) plants. It uses a market-based system to distribute flow\namong loops combined with an artificial neural network (ANN) to reduce\ncomputation and data requirements. This auction-based approach balances loop\ntemperatures, accommodating varying thermal losses and collector efficiencies.\nValidation across different thermal losses, optical efficiencies, and\nirradiance conditions-sunny, partially cloudy, and cloudy-show improved thermal\npower output and intercept factors compared to a no-allocation system. It\ndemonstrates scalability and practicality for large solar thermal plants,\nenhancing overall performance. The method was first validated through\nsimulations on a realistic solar plant model, then adapted and successfully\ntested in a 50 MW solar trough plant, demonstrating its advantages.\nFurthermore, the algorithms have been implemented, commissioned, and are\ncurrently operating in 13 commercial solar trough plants.",
      "tldr_zh": "本研究提出了一种基于市场的流量分配方法，用于优化抛物槽式集热器 (PTC) 太阳能热电厂的热平衡。该方法结合拍卖-based 系统在回路间分配流量，并利用人工神经网络 (ANN) 减少计算和数据需求，从而平衡回路温度并适应不同热损失和集热器效率。在各种辐照度条件下（包括晴天、部分多云和多云），实验验证显示该方法比无分配系统提高了热功率输出和截获因子，证明了其可扩展性和实用性。该方法已在真实模拟模型上验证，并成功应用于一个 50 MW 太阳能槽式厂，目前已在 13 个商业太阳能热电厂中实施并运行。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "This manuscript has been submitted to Renewable Energy",
      "pdf_url": "http://arxiv.org/pdf/2504.01652v1",
      "published_date": "2025-04-02 12:01:41 UTC",
      "updated_date": "2025-04-02 12:01:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:53:46.788189"
    },
    {
      "arxiv_id": "2504.03763v1",
      "title": "Efficient Calibration for RRAM-based In-Memory Computing using DoRA",
      "title_zh": "翻译失败",
      "authors": [
        "Weirong Dong",
        "Kai Zhou",
        "Zhen Kong",
        "Quan Cheng",
        "Junkai Huang",
        "Zhengke Yang",
        "Masanori Hashimoto",
        "Longyang Lin"
      ],
      "abstract": "Resistive In-Memory Computing (RIMC) offers ultra-efficient computation for\nedge AI but faces accuracy degradation due to RRAM conductance drift over time.\nTraditional retraining methods are limited by RRAM's high energy consumption,\nwrite latency, and endurance constraints. We propose a DoRA-based calibration\nframework that restores accuracy by compensating influential weights with\nminimal calibration parameters stored in SRAM, leaving RRAM weights untouched.\nThis eliminates in-field RRAM writes, ensuring energy-efficient, fast, and\nreliable calibration. Experiments on RIMC-based ResNet50 (ImageNet-1K)\ndemonstrate 69.53% accuracy restoration using just 10 calibration samples while\nupdating only 2.34% of parameters.",
      "tldr_zh": "这项研究针对 RRAM-based In-Memory Computing (RIMC) 在边缘 AI 中的准确性下降问题，提出了一种基于 DoRA 的高效校准框架，以应对 RRAM 电导漂移带来的挑战。该框架通过在 SRAM 中存储最小校准参数来补偿关键权重，而不需修改 RRAM 权重，从而实现能量高效、快速且可靠的校准，无需现场 RRAM 写入。在 RIMC-based ResNet50 (ImageNet-1K) 的实验中，该方法仅使用 10 个校准样本就恢复了 69.53% 的准确性，并只更新了 2.34% 的参数，为 RRAM 系统的长期可靠性提供了实用解决方案。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AR",
      "comment": "7 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.03763v1",
      "published_date": "2025-04-02 11:58:08 UTC",
      "updated_date": "2025-04-02 11:58:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:53:58.347519"
    },
    {
      "arxiv_id": "2504.01644v1",
      "title": "Proposition of Affordance-Driven Environment Recognition Framework Using Symbol Networks in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Kazuma Arii",
        "Satoshi Kurihara"
      ],
      "abstract": "In the quest to enable robots to coexist with humans, understanding dynamic\nsituations and selecting appropriate actions based on common sense and\naffordances are essential. Conventional AI systems face challenges in applying\naffordance, as it represents implicit knowledge derived from common sense.\nHowever, large language models (LLMs) offer new opportunities due to their\nability to process extensive human knowledge. This study proposes a method for\nautomatic affordance acquisition by leveraging LLM outputs. The process\ninvolves generating text using LLMs, reconstructing the output into a symbol\nnetwork using morphological and dependency analysis, and calculating\naffordances based on network distances. Experiments using ``apple'' as an\nexample demonstrated the method's ability to extract context-dependent\naffordances with high explainability. The results suggest that the proposed\nsymbol network, reconstructed from LLM outputs, enables robots to interpret\naffordances effectively, bridging the gap between symbolized data and\nhuman-like situational understanding.",
      "tldr_zh": "该研究针对机器人与人类共存的挑战，提出了一种基于大型语言模型(LLMs)的affordance驱动环境识别框架，以解决传统AI在处理affordance（隐性常识知识）方面的难题。方法包括利用LLMs生成文本，通过形态分析和依赖分析重建为symbol network，并基于网络距离计算上下文相关的affordance。实验以“apple”为例，证明了该框架能提取高explainability的affordance，帮助机器人有效桥接符号化数据与人类-like的情景理解。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01644v1",
      "published_date": "2025-04-02 11:48:44 UTC",
      "updated_date": "2025-04-02 11:48:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:54:10.526199"
    },
    {
      "arxiv_id": "2504.01641v1",
      "title": "Bridge 2D-3D: Uncertainty-aware Hierarchical Registration Network with Domain Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Zhixin Cheng",
        "Jiacheng Deng",
        "Xinjun Li",
        "Baoqun Yin",
        "Tianzhu Zhang"
      ],
      "abstract": "The method for image-to-point cloud registration typically determines the\nrigid transformation using a coarse-to-fine pipeline. However, directly and\nuniformly matching image patches with point cloud patches may lead to focusing\non incorrect noise patches during matching while ignoring key ones. Moreover,\ndue to the significant differences between image and point cloud modalities, it\nmay be challenging to bridge the domain gap without specific improvements in\ndesign. To address the above issues, we innovatively propose the\nUncertainty-aware Hierarchical Matching Module (UHMM) and the Adversarial Modal\nAlignment Module (AMAM). Within the UHMM, we model the uncertainty of critical\ninformation in image patches and facilitate multi-level fusion interactions\nbetween image and point cloud features. In the AMAM, we design an adversarial\napproach to reduce the domain gap between image and point cloud. Extensive\nexperiments and ablation studies on RGB-D Scene V2 and 7-Scenes benchmarks\ndemonstrate the superiority of our method, making it a state-of-the-art\napproach for image-to-point cloud registration tasks.",
      "tldr_zh": "这篇论文提出了一种名为 Bridge 2D-3D 的不确定性感知分层注册网络，旨在解决图像到点云注册任务中直接匹配导致的错误和领域差距问题。论文引入了 Uncertainty-aware Hierarchical Matching Module (UHMM)，通过建模图像补丁的关键不确定性并实现多级特征融合，提升匹配精度；以及 Adversarial Modal Alignment Module (AMAM)，采用对抗训练方法减少图像和点云模态之间的域差异。实验结果显示，该方法在 RGB-D Scene V2 和 7-Scenes 基准数据集上表现出色，达到了当前最先进水平。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "AAAI2025accept",
      "pdf_url": "http://arxiv.org/pdf/2504.01641v1",
      "published_date": "2025-04-02 11:43:55 UTC",
      "updated_date": "2025-04-02 11:43:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:54:22.528351"
    },
    {
      "arxiv_id": "2504.01637v1",
      "title": "LLM-mediated Dynamic Plan Generation with a Multi-Agent Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Reo Abe",
        "Akifumi Ito",
        "Kanata Takayasu",
        "Satoshi Kurihara"
      ],
      "abstract": "Planning methods with high adaptability to dynamic environments are crucial\nfor the development of autonomous and versatile robots. We propose a method for\nleveraging a large language model (GPT-4o) to automatically generate networks\ncapable of adapting to dynamic environments. The proposed method collects\nenvironmental \"status,\" representing conditions and goals, and uses them to\ngenerate agents. These agents are interconnected on the basis of specific\nconditions, resulting in networks that combine flexibility and generality. We\nconducted evaluation experiments to compare the networks automatically\ngenerated with the proposed method with manually constructed ones, confirming\nthe comprehensiveness of the proposed method's networks and their higher\ngenerality. This research marks a significant advancement toward the\ndevelopment of versatile planning methods applicable to robotics, autonomous\nvehicles, smart systems, and other complex environments.",
      "tldr_zh": "该研究提出了一种利用大型语言模型(LLM，如GPT-4o)来自动生成动态规划网络的多代理方法，以提升机器人等系统在动态环境中的适应性。该方法通过收集环境状态（如条件和目标）来生成并互联代理，形成灵活且通用的网络结构。实验结果显示，与手动构建的网络相比，该自动生成网络在全面性和通用性上表现出色，为机器人、自动驾驶车辆和智能系统等领域的规划技术发展提供了重要进展。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01637v1",
      "published_date": "2025-04-02 11:42:49 UTC",
      "updated_date": "2025-04-02 11:42:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:54:33.683280"
    },
    {
      "arxiv_id": "2504.01632v2",
      "title": "Benchmarking the Spatial Robustness of DNNs via Natural and Adversarial Localized Corruptions",
      "title_zh": "通过自然和对抗性局部化干扰对深度神经网络的空间鲁棒性进行基准测试",
      "authors": [
        "Giulia Marchiori Pietrosanti",
        "Giulio Rossolini",
        "Alessandro Biondi",
        "Giorgio Buttazzo"
      ],
      "abstract": "The robustness of DNNs is a crucial factor in safety-critical applications,\nparticularly in complex and dynamic environments where localized corruptions\ncan arise. While previous studies have evaluated the robustness of semantic\nsegmentation (SS) models under whole-image natural or adversarial corruptions,\na comprehensive investigation into the spatial robustness of dense vision\nmodels under localized corruptions remained underexplored. This paper fills\nthis gap by introducing specialized metrics for benchmarking the spatial\nrobustness of segmentation models, alongside with an evaluation framework to\nassess the impact of localized corruptions. Furthermore, we uncover the\ninherent complexity of characterizing worst-case robustness using a single\nlocalized adversarial perturbation. To address this, we propose region-aware\nmulti-attack adversarial analysis, a method that enables a deeper understanding\nof model robustness against adversarial perturbations applied to specific\nregions. The proposed metrics and analysis were exploited to evaluate 14\nsegmentation models in driving scenarios, uncovering key insights into the\neffects of localized corruption in both natural and adversarial forms. The\nresults reveal that models respond to these two types of threats differently;\nfor instance, transformer-based segmentation models demonstrate notable\nrobustness to localized natural corruptions but are highly vulnerable to\nadversarial ones and vice-versa for CNN-based models. Consequently, we also\naddress the challenge of balancing robustness to both natural and adversarial\nlocalized corruptions by means of ensemble models, thereby achieving a broader\nthreat coverage and improved reliability for dense vision tasks.",
      "tldr_zh": "本文评估了 DNNs 在复杂环境中面对局部自然和对抗性腐败的空间鲁棒性，针对 semantic segmentation 模型引入了新的基准指标和评估框架，以填补现有研究的空白。研究提出 region-aware multi-attack adversarial analysis 方法，用于深入分析模型对特定区域对抗扰动的响应，并通过评估 14 个模型在驾驶场景中发现，transformer-based 模型对自然腐败表现出色但对对抗性腐败高度脆弱，而 CNN-based 模型则相反。为平衡这两种威胁，作者建议使用 ensemble 模型，提高了整体鲁棒性和可靠性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2504.01632v2",
      "published_date": "2025-04-02 11:37:39 UTC",
      "updated_date": "2025-04-17 16:43:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:54:47.159422"
    },
    {
      "arxiv_id": "2504.01627v1",
      "title": "Horizon Scans can be accelerated using novel information retrieval and artificial intelligence tools",
      "title_zh": "翻译失败",
      "authors": [
        "Lena Schmidt",
        "Oshin Sharma",
        "Chris Marshall",
        "Sonia Garcia Gonzalez Moral"
      ],
      "abstract": "Introduction: Horizon scanning in healthcare assesses early signals of\ninnovation, crucial for timely adoption. Current horizon scanning faces\nchallenges in efficient information retrieval and analysis, especially from\nunstructured sources like news, presenting a need for innovative tools.\nMethodology: The study introduces SCANAR and AIDOC, open-source Python-based\ntools designed to improve horizon scanning. SCANAR automates the retrieval and\nprocessing of news articles, offering functionalities such as de-duplication\nand unsupervised relevancy ranking. AIDOC aids filtration by leveraging AI to\nreorder textual data based on relevancy, employing neural networks for semantic\nsimilarity, and subsequently prioritizing likely relevant entries for human\nreview. Results: Twelve internal datasets from horizon scans and four external\nbenchmarking datasets were used. SCANAR improved retrieval efficiency by\nautomating processes previously dependent on manual labour. AIDOC displayed\nwork-saving potential, achieving around 62% reduction in manual review efforts\nat 95% recall. Comparative analysis with benchmarking data showed AIDOC's\nperformance was similar to existing systematic review automation tools, though\nperformance varied depending on dataset characteristics. A smaller case-study\non our news datasets shows the potential of ensembling large language models\nwithin the active-learning process for faster detection of relevant articles\nacross news datasets. Conclusion: The validation indicates that SCANAR and\nAIDOC show potential to enhance horizon scanning efficiency by streamlining\ndata retrieval and prioritisation. These tools may alleviate methodological\nlimitations and allow broader, swifter horizon scans. Further studies are\nsuggested to optimize these models and to design new workflows and validation\nprocesses that integrate large language models.",
      "tldr_zh": "本文研究了如何利用新型信息检索和AI工具加速Horizon scanning过程，以应对医疗创新早期信号评估中的效率挑战。研究引入了开源Python工具SCANAR和AIDOC：SCANAR自动化新闻文章的检索、处理、去重和无监督相关性排名，而AIDOC则通过神经网络进行语义相似性分析，优先排序相关文本以减少手动审查。实验在12个内部数据集和4个外部基准数据集上显示，AIDOC可将手动审查工作减少约62%，同时保持95%的召回率，其性能与现有系统性审查工具相当，并探索了集成大型语言模型在主动学习中的潜力。总之，这些工具有望优化Horizon scanning的工作流程，促进更广泛和快速的创新评估，并建议进一步研究以完善模型和整合新方法。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01627v1",
      "published_date": "2025-04-02 11:33:08 UTC",
      "updated_date": "2025-04-02 11:33:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:54:59.394293"
    },
    {
      "arxiv_id": "2504.01589v2",
      "title": "Text Speaks Louder than Vision: ASCII Art Reveals Textual Biases in Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zhaochen Wang",
        "Bryan Hooi",
        "Yiwei Wang",
        "Ming-Hsuan Yang",
        "Zi Huang",
        "Yujun Cai"
      ],
      "abstract": "Vision-language models (VLMs) have advanced rapidly in processing multimodal\ninformation, but their ability to reconcile conflicting signals across\nmodalities remains underexplored. This work investigates how VLMs process ASCII\nart, a unique medium where textual elements collectively form visual patterns,\npotentially creating semantic-visual conflicts. We introduce a novel evaluation\nframework that systematically challenges five state-of-the-art models\n(including GPT-4o, Claude, and Gemini) using adversarial ASCII art, where\ncharacter-level semantics deliberately contradict global visual patterns. Our\nexperiments reveal a strong text-priority bias: VLMs consistently prioritize\ntextual information over visual patterns, with visual recognition ability\ndeclining dramatically as semantic complexity increases. Various mitigation\nattempts through visual parameter tuning and prompt engineering yielded only\nmodest improvements, suggesting that this limitation requires\narchitectural-level solutions. These findings uncover fundamental flaws in how\ncurrent VLMs integrate multimodal information, providing important guidance for\nfuture model development while highlighting significant implications for\ncontent moderation systems vulnerable to adversarial examples.",
      "tldr_zh": "这篇论文揭示了视觉语言模型 (VLMs) 在处理模态冲突时的文本优先偏见，通过 ASCII art 作为独特测试媒介。研究者引入了一个新评估框架，使用对抗性 ASCII art 来挑战五种先进模型（如 GPT-4o、Claude 和 Gemini），其中字符级语义故意与全局视觉图案冲突。实验结果显示，VLMs 强烈优先文本信息，导致视觉识别能力随语义复杂性增加而急剧下降。虽尝试了视觉参数调整和提示工程等缓解策略，但改善有限，表明需从架构层面解决此问题；这些发现为未来 VLMs 开发提供指导，并强调了对抗样本对内容审核系统的潜在风险。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Under review at COLM 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.01589v2",
      "published_date": "2025-04-02 10:47:07 UTC",
      "updated_date": "2025-04-07 23:21:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:55:11.499740"
    },
    {
      "arxiv_id": "2504.01588v1",
      "title": "Building Knowledge from Interactions: An LLM-Based Architecture for Adaptive Tutoring and Social Reasoning",
      "title_zh": "通过互动构建知识：一种基于 LLM 的架构用于自适应辅导和社交推理",
      "authors": [
        "Luca Garello",
        "Giulia Belgiovine",
        "Gabriele Russo",
        "Francesco Rea",
        "Alessandra Sciutti"
      ],
      "abstract": "Integrating robotics into everyday scenarios like tutoring or physical\ntraining requires robots capable of adaptive, socially engaging, and\ngoal-oriented interactions. While Large Language Models show promise in\nhuman-like communication, their standalone use is hindered by memory\nconstraints and contextual incoherence. This work presents a multimodal,\ncognitively inspired framework that enhances LLM-based autonomous\ndecision-making in social and task-oriented Human-Robot Interaction.\nSpecifically, we develop an LLM-based agent for a robot trainer, balancing\nsocial conversation with task guidance and goal-driven motivation. To further\nenhance autonomy and personalization, we introduce a memory system for\nselecting, storing and retrieving experiences, facilitating generalized\nreasoning based on knowledge built across different interactions. A preliminary\nHRI user study and offline experiments with a synthetic dataset validate our\napproach, demonstrating the system's ability to manage complex interactions,\nautonomously drive training tasks, and build and retrieve contextual memories,\nadvancing socially intelligent robotics.",
      "tldr_zh": "本文提出一个多模态、受认知启发的框架，旨在增强 LLM 在社交和任务导向的人机交互中的自主决策能力，特别适用于机器人辅导场景。该框架包括一个基于 LLM 的代理，用于平衡社交对话、任务指导和目标驱动动机，并引入记忆系统来选择、存储和检索经验，实现基于不同互动积累知识的泛化推理。通过初步 HRI 用户研究和离线实验验证，该系统成功管理复杂交互、自主驱动训练任务，并提升机器人的适应性和社交智能。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Submitted to IEEE/RSJ International Conference on Intelligent Robots\n  and Systems (IROS) 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.01588v1",
      "published_date": "2025-04-02 10:45:41 UTC",
      "updated_date": "2025-04-02 10:45:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:55:22.804492"
    },
    {
      "arxiv_id": "2504.01571v1",
      "title": "Pro-DG: Procedural Diffusion Guidance for Architectural Facade Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Aleksander Plocharski",
        "Jan Swidzinski",
        "Przemyslaw Musialski"
      ],
      "abstract": "We present Pro-DG, a framework for procedurally controllable photo-realistic\nfacade generation that combines a procedural shape grammar with diffusion-based\nimage synthesis. Starting from a single input image, we reconstruct its facade\nlayout using grammar rules, then edit that structure through user-defined\ntransformations. As facades are inherently multi-hierarchical structures, we\nintroduce hierarchical matching procedure that aligns facade structures at\ndifferent levels which is used to introduce control maps to guide a generative\ndiffusion pipeline. This approach retains local appearance fidelity while\naccommodating large-scale edits such as floor duplication or window\nrearrangement. We provide a thorough evaluation, comparing Pro-DG against\ninpainting-based baselines and synthetic ground truths. Our user study and\nquantitative measurements indicate improved preservation of architectural\nidentity and higher edit accuracy. Our novel method is the first to integrate\nneuro-symbolically derived shape-grammars for modeling with modern generative\nmodel and highlights the broader potential of such approaches for precise and\ncontrollable image manipulation.",
      "tldr_zh": "本研究提出Pro-DG框架，通过结合procedural shape grammar和diffusion-based image synthesis，实现对建筑立面的可控、照片级真实生成。框架从单张输入图像重构立面布局，并利用hierarchical matching procedure在不同层次对齐结构，生成控制映射来引导扩散管道，从而支持用户定义的编辑，如楼层复制或窗口重新排列，同时保持局部外观的保真度。与基于修复的基线模型相比，Pro-DG在用户研究和定量评估中显示出更高的建筑身份保留和编辑准确性。该方法首次将神经符号派生的形状语法与现代生成模型整合，展示了其在精确可控图像操作中的广阔潜力。",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "I.3.7; I.4.9; I.2.10"
      ],
      "primary_category": "cs.GR",
      "comment": "12 pages, 13 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.01571v1",
      "published_date": "2025-04-02 10:16:19 UTC",
      "updated_date": "2025-04-02 10:16:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:55:35.342688"
    },
    {
      "arxiv_id": "2504.01560v1",
      "title": "Optimizing Package Delivery with Quantum Annealers: Addressing Time-Windows and Simultaneous Pickup and Delivery",
      "title_zh": "使用 Quantum Annealers 优化包裹递送：解决时间窗口和同时取货与递送",
      "authors": [
        "Eneko Osaba",
        "Esther Villar-Rodriguez",
        "Pablo Miranda-Rodriguez",
        "Antón Asla"
      ],
      "abstract": "Recent research at the intersection of quantum computing and routing problems\nhas been highly prolific. Much of this work focuses on classical problems such\nas the Traveling Salesman Problem and the Vehicle Routing Problem. The\npractical applicability of these problems depends on the specific objectives\nand constraints considered. However, it is undeniable that translating complex\nreal-world requirements into these classical formulations often proves\nchallenging. In this paper, we resort to our previously published\nquantum-classical technique for addressing real-world-oriented routing\nproblems, known as Quantum for Real Package Delivery (Q4RPD), and elaborate on\nsolving additional realistic problem instances. Accordingly, this paper\nemphasizes the following characteristics: i) simultaneous pickup and\ndeliveries, ii) time-windows, and iii) mobility restrictions by vehicle type.\nTo illustrate the application of Q4RPD, we have conducted an experimentation\ncomprising seven instances, serving as a demonstration of the newly developed\nfeatures.",
      "tldr_zh": "这篇论文利用Quantum Annealers优化包裹递送问题，扩展了先前提出的Quantum for Real Package Delivery (Q4RPD)框架，以应对现实挑战，如同时取送货、时间窗口约束以及车辆类型限制。研究者通过量子-经典混合技术，将这些特性融入传统路由问题（如Traveling Salesman Problem和Vehicle Routing Problem）的解决方案中。实验结果基于七个真实实例，展示了Q4RPD的有效性，为量子计算在实际物流优化中的应用提供了重要示范。",
      "categories": [
        "cs.ET",
        "cs.AI"
      ],
      "primary_category": "cs.ET",
      "comment": "8 pages, 1 table, 9 figures, paper submitted to the IEEE\n  International Conference on Quantum Computing and Engineering (QCE 2025)",
      "pdf_url": "http://arxiv.org/pdf/2504.01560v1",
      "published_date": "2025-04-02 10:01:34 UTC",
      "updated_date": "2025-04-02 10:01:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:55:47.632783"
    },
    {
      "arxiv_id": "2504.01551v1",
      "title": "Identifying Macro Causal Effects in C-DMGs",
      "title_zh": "在 C-DMGs 中识别宏观因果效应",
      "authors": [
        "Simon Ferreira",
        "Charles K. Assaad"
      ],
      "abstract": "Causal effect identification using causal graphs is a fundamental challenge\nin causal inference. While extensive research has been conducted in this area,\nmost existing methods assume the availability of fully specified causal graphs.\nHowever, in complex domains such as medicine and epidemiology, complete causal\nknowledge is often unavailable, and only partial information about the system\nis accessible. This paper focuses on causal effect identification within\npartially specified causal graphs, with particular emphasis on cluster-directed\nmixed graphs (C-DMGs). These graphs provide a higher-level representation of\ncausal relationships by grouping variables into clusters, offering a more\npractical approach for handling complex systems. Unlike fully specified causal\ngraphs, C-DMGs can contain cycles, which complicate their analysis and\ninterpretation. Furthermore, their cluster-based nature introduces new\nchallenges, as it gives rise to two distinct types of causal effects, macro\ncausal effects and micro causal effects, with different properties. In this\nwork, we focus on macro causal effects, which describe the effects of entire\nclusters on other clusters. We establish that the do-calculus is both sound and\ncomplete for identifying these effects in C-DMGs. Additionally, we provide a\ngraphical characterization of non-identifiability for macro causal effects in\nthese graphs.",
      "tldr_zh": "这篇论文探讨了在部分指定的因果图中识别宏观因果效应的挑战，特别是针对cluster-directed mixed graphs (C-DMGs)，这些图通过将变量分组成集群来处理复杂系统如医学和流行病学。作者证明了do-calculus在C-DMGs中对macro causal effects的识别是sound和complete，这意味着它能可靠地确定整个集群间的因果关系。论文还提供了macro causal effects非可识别性的图形特征，进一步提升了在不完整因果知识下进行分析的实用性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01551v1",
      "published_date": "2025-04-02 09:48:27 UTC",
      "updated_date": "2025-04-02 09:48:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:55:58.868338"
    },
    {
      "arxiv_id": "2504.01541v2",
      "title": "Hyperbolic Diffusion Recommender Model",
      "title_zh": "双曲扩散推荐模型",
      "authors": [
        "Meng Yuan",
        "Yutian Xiao",
        "Wei Chen",
        "Chu Zhao",
        "Deqing Wang",
        "Fuzhen Zhuang"
      ],
      "abstract": "Diffusion models (DMs) have emerged as the new state-of-the-art family of\ndeep generative models. To gain deeper insights into the limitations of\ndiffusion models in recommender systems, we investigate the fundamental\nstructural disparities between images and items. Consequently, items often\nexhibit distinct anisotropic and directional structures that are less prevalent\nin images. However, the traditional forward diffusion process continuously adds\nisotropic Gaussian noise, causing anisotropic signals to degrade into noise,\nwhich impairs the semantically meaningful representations in recommender\nsystems.\n  Inspired by the advancements in hyperbolic spaces, we propose a novel\n\\textit{\\textbf{H}yperbolic} \\textit{\\textbf{D}iffusion}\n\\textit{\\textbf{R}ecommender} \\textit{\\textbf{M}odel} (named HDRM). Unlike\nexisting directional diffusion methods based on Euclidean space, the intrinsic\nnon-Euclidean structure of hyperbolic space makes it particularly well-adapted\nfor handling anisotropic diffusion processes. In particular, we begin by\nformulating concepts to characterize latent directed diffusion processes within\na geometrically grounded hyperbolic space. Subsequently, we propose a novel\nhyperbolic latent diffusion process specifically tailored for users and items.\nDrawing upon the natural geometric attributes of hyperbolic spaces, we impose\nstructural restrictions on the space to enhance hyperbolic diffusion\npropagation, thereby ensuring the preservation of the intrinsic topology of\nuser-item graphs. Extensive experiments on three benchmark datasets demonstrate\nthe effectiveness of HDRM.",
      "tldr_zh": "本研究探讨了扩散模型(Diffusion models)在推荐系统中的局限性，特别是物品的各向异性(anisotropic)和方向性结构在传统前向扩散过程中被各向同性(isotropic)高斯噪声破坏，导致语义表示退化。为解决这一问题，论文提出了一种新型Hyperbolic Diffusion Recommender Model (HDRM)，利用双曲空间(hyperbolic space)的非欧结构来处理各向异性扩散过程，包括定义潜扩散过程并增强传播以保留用户-物品图的内在拓扑结构。在三个基准数据集上的广泛实验证明，HDRM 显著提高了推荐性能。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01541v2",
      "published_date": "2025-04-02 09:27:40 UTC",
      "updated_date": "2025-04-10 08:02:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:56:10.516006"
    },
    {
      "arxiv_id": "2504.01538v1",
      "title": "AI-Newton: A Concept-Driven Physical Law Discovery System without Prior Physical Knowledge",
      "title_zh": "翻译失败",
      "authors": [
        "You-Le Fang",
        "Dong-Shan Jian",
        "Xiang Li",
        "Yan-Qing Ma"
      ],
      "abstract": "Current limitations in human scientific discovery necessitate a new research\nparadigm. While advances in artificial intelligence (AI) offer a highly\npromising solution, enabling AI to emulate human-like scientific discovery\nremains an open challenge. To address this, we propose AI-Newton, a\nconcept-driven discovery system capable of autonomously deriving physical laws\nfrom raw data -- without supervision or prior physical knowledge. The system\nintegrates a knowledge base and knowledge representation centered on physical\nconcepts, along with an autonomous discovery workflow. As a proof of concept,\nwe apply AI-Newton to a large set of Newtonian mechanics problems. Given\nexperimental data with noise, the system successfully rediscovers fundamental\nlaws, including Newton's second law, energy conservation and law of\ngravitation, using autonomously defined concepts. This achievement marks a\nsignificant step toward AI-driven autonomous scientific discovery.",
      "tldr_zh": "该研究提出AI-Newton系统，这是一个概念驱动的物理定律发现系统，能够从原始数据中自主推导出物理定律，而无需监督或先验物理知识。\n系统整合了基于物理概念的知识库、知识表示以及自主发现工作流。\n作为概念证明，AI-Newton应用于牛顿力学问题集，从有噪声的实验数据中成功重新发现Newton's second law、能量守恒和万有引力定律。\n这一创新标志着AI在模拟人类科学发现方面的重要进展，推动了自主科学发现的新范式。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.SC",
        "hep-ph",
        "physics.class-ph"
      ],
      "primary_category": "cs.AI",
      "comment": "31 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.01538v1",
      "published_date": "2025-04-02 09:25:34 UTC",
      "updated_date": "2025-04-02 09:25:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:56:23.434300"
    },
    {
      "arxiv_id": "2504.01522v1",
      "title": "Redefining technology for indigenous languages",
      "title_zh": "翻译失败",
      "authors": [
        "Silvia Fernandez-Sabido",
        "Laura Peniche-Sabido"
      ],
      "abstract": "In this paper, we offer an overview of indigenous languages, identifying the\ncauses of their devaluation and the need for legislation on language rights. We\nreview the technologies used to revitalize these languages, finding that when\nthey come from outside, they often have the opposite effect to what they seek;\nhowever, when developed from within communities, they become powerful\ninstruments of expression. We propose that the inclusion of Indigenous\nknowledge in large language models (LLMs) will enrich the technological\nlandscape, but must be done in a participatory environment that encourages the\nexchange of knowledge.",
      "tldr_zh": "该论文概述了土著语言（indigenous languages）的贬低原因，包括社会因素和缺乏语言权利立法，并强调了复兴这些语言的必要性。通过回顾相关技术，该研究发现外部引入的技术往往适得其反，而由社区内部开发的工具则能成为有效的表达手段。论文提出，将Indigenous知识纳入大型语言模型（LLMs）可以丰富技术生态，但必须在参与式环境中进行，以促进知识交流和可持续性。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "in Spanish language",
      "pdf_url": "http://arxiv.org/pdf/2504.01522v1",
      "published_date": "2025-04-02 09:08:53 UTC",
      "updated_date": "2025-04-02 09:08:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:56:34.148064"
    },
    {
      "arxiv_id": "2504.01521v1",
      "title": "Domain Guidance: A Simple Transfer Approach for a Pre-trained Diffusion Model",
      "title_zh": "Domain Guidance：一种针对预训练扩散模型的简单转移方法",
      "authors": [
        "Jincheng Zhong",
        "Xiangcheng Zhang",
        "Jianmin Wang",
        "Mingsheng Long"
      ],
      "abstract": "Recent advancements in diffusion models have revolutionized generative\nmodeling. However, the impressive and vivid outputs they produce often come at\nthe cost of significant model scaling and increased computational demands.\nConsequently, building personalized diffusion models based on off-the-shelf\nmodels has emerged as an appealing alternative. In this paper, we introduce a\nnovel perspective on conditional generation for transferring a pre-trained\nmodel. From this viewpoint, we propose *Domain Guidance*, a straightforward\ntransfer approach that leverages pre-trained knowledge to guide the sampling\nprocess toward the target domain. Domain Guidance shares a formulation similar\nto advanced classifier-free guidance, facilitating better domain alignment and\nhigher-quality generations. We provide both empirical and theoretical analyses\nof the mechanisms behind Domain Guidance. Our experimental results demonstrate\nits substantial effectiveness across various transfer benchmarks, achieving\nover a 19.6% improvement in FID and a 23.4% improvement in FD$_\\text{DINOv2}$\ncompared to standard fine-tuning. Notably, existing fine-tuned models can\nseamlessly integrate Domain Guidance to leverage these benefits, without\nadditional training.",
      "tldr_zh": "该论文提出了一种简单的方法Domain Guidance，用于转移预训练的Diffusion Model，通过利用预训练知识指导采样过程，实现更好的领域对齐和高质量生成。该方法借鉴无分类器指导的公式，提供经验和理论分析，允许现有微调模型无缝整合，无需额外训练。实验结果显示，在各种转移基准上，Domain Guidance比标准微调提高了19.6%的FID和23.4%的FD_DINOv2，显著提升了生成性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01521v1",
      "published_date": "2025-04-02 09:07:55 UTC",
      "updated_date": "2025-04-02 09:07:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:56:47.026127"
    },
    {
      "arxiv_id": "2504.01515v2",
      "title": "Training-free Dense-Aligned Diffusion Guidance for Modular Conditional Image Synthesis",
      "title_zh": "无需训练的密集对齐扩散引导，用于模块化条件图像合成",
      "authors": [
        "Zixuan Wang",
        "Duo Peng",
        "Feng Chen",
        "Yuwei Yang",
        "Yinjie Lei"
      ],
      "abstract": "Conditional image synthesis is a crucial task with broad applications, such\nas artistic creation and virtual reality. However, current generative methods\nare often task-oriented with a narrow scope, handling a restricted condition\nwith constrained applicability. In this paper, we propose a novel approach that\ntreats conditional image synthesis as the modular combination of diverse\nfundamental condition units. Specifically, we divide conditions into three\nprimary units: text, layout, and drag. To enable effective control over these\nconditions, we design a dedicated alignment module for each. For the text\ncondition, we introduce a Dense Concept Alignment (DCA) module, which achieves\ndense visual-text alignment by drawing on diverse textual concepts. For the\nlayout condition, we propose a Dense Geometry Alignment (DGA) module to enforce\ncomprehensive geometric constraints that preserve the spatial configuration.\nFor the drag condition, we introduce a Dense Motion Alignment (DMA) module to\napply multi-level motion regularization, ensuring that each pixel follows its\ndesired trajectory without visual artifacts. By flexibly inserting and\ncombining these alignment modules, our framework enhances the model's\nadaptability to diverse conditional generation tasks and greatly expands its\napplication range. Extensive experiments demonstrate the superior performance\nof our framework across a variety of conditions, including textual description,\nsegmentation mask (bounding box), drag manipulation, and their combinations.\nCode is available at https://github.com/ZixuanWang0525/DADG.",
      "tldr_zh": "该论文提出了一种无需训练的密集对齐扩散引导框架，用于模块化的条件图像合成，将条件分为文本、布局和拖拽三大单元，以提升生成任务的灵活性和适用性。具体而言，该框架包括 Dense Concept Alignment (DCA) 模块实现密集视觉-文本对齐、Dense Geometry Alignment (DGA) 模块强制几何约束以保持空间配置，以及 Dense Motion Alignment (DMA) 模块应用多级运动正则化以避免视觉伪影。实验结果显示，该框架在文本描述、分割掩码（边界框）、拖拽操作及其组合等多种条件下表现出优越性能，大大扩展了条件图像合成的应用范围。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR2025",
      "pdf_url": "http://arxiv.org/pdf/2504.01515v2",
      "published_date": "2025-04-02 09:00:28 UTC",
      "updated_date": "2025-04-03 08:39:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:56:59.745763"
    },
    {
      "arxiv_id": "2504.08769v1",
      "title": "High-order expansion of Neural Ordinary Differential Equations flows",
      "title_zh": "翻译失败",
      "authors": [
        "Dario Izzo",
        "Sebastien Origer",
        "Giacomo Acciarini",
        "Francesco Biscani"
      ],
      "abstract": "Artificial neural networks, widely recognised for their role in machine\nlearning, are now transforming the study of ordinary differential equations\n(ODEs), bridging data-driven modelling with classical dynamical systems and\nenabling the development of infinitely deep neural models. However, the\npractical applicability of these models remains constrained by the opacity of\ntheir learned dynamics, which operate as black-box systems with limited\nexplainability, thereby hindering trust in their deployment. Existing\napproaches for the analysis of these dynamical systems are predominantly\nrestricted to first-order gradient information due to computational\nconstraints, thereby limiting the depth of achievable insight. Here, we\nintroduce Event Transition Tensors, a framework based on high-order\ndifferentials that provides a rigorous mathematical description of neural ODE\ndynamics on event manifolds. We demonstrate its versatility across diverse\napplications: characterising uncertainties in a data-driven prey-predator\ncontrol model, analysing neural optimal feedback dynamics, and mapping landing\ntrajectories in a three-body neural Hamiltonian system. In all cases, our\nmethod enhances the interpretability and rigour of neural ODEs by expressing\ntheir behaviour through explicit mathematical structures. Our findings\ncontribute to a deeper theoretical foundation for event-triggered neural\ndifferential equations and provide a mathematical construct for explaining\ncomplex system dynamics.",
      "tldr_zh": "本研究针对神经普通微分方程（Neural ODEs）的黑盒动态问题，提出Event Transition Tensors框架，该框架利用高阶微分来提供对事件流形上动态的严格数学描述，从而提升模型的可解释性和分析深度。现有方法主要依赖一阶梯度信息，而该框架克服这一限制，通过显式数学结构表达神经ODEs的行为。实验应用包括分析数据驱动的捕食者-猎物控制模型的不确定性、神经最优反馈动态，以及三体神经Hamiltonian系统的着陆轨迹映射，结果显示该方法显著提高了神经ODEs的理论基础和解释能力，为事件触发的神经微分方程研究奠定新基石。",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "math.OC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.08769v1",
      "published_date": "2025-04-02 08:57:34 UTC",
      "updated_date": "2025-04-02 08:57:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:57:10.800248"
    },
    {
      "arxiv_id": "2504.01468v1",
      "title": "HH-PIM: Dynamic Optimization of Power and Performance with Heterogeneous-Hybrid PIM for Edge AI Devices",
      "title_zh": "翻译失败",
      "authors": [
        "Sangmin Jeon",
        "Kangju Lee",
        "Kyeongwon Lee",
        "Woojoo Lee"
      ],
      "abstract": "Processing-in-Memory (PIM) architectures offer promising solutions for\nefficiently handling AI applications in energy-constrained edge environments.\nWhile traditional PIM designs enhance performance and energy efficiency by\nreducing data movement between memory and processing units, they are limited in\nedge devices due to continuous power demands and the storage requirements of\nlarge neural network weights in SRAM and DRAM. Hybrid PIM architectures,\nincorporating non-volatile memories like MRAM and ReRAM, mitigate these\nlimitations but struggle with a mismatch between fixed computing resources and\ndynamically changing inference workloads. To address these challenges, this\nstudy introduces a Heterogeneous-Hybrid PIM (HH-PIM) architecture, comprising\nhigh-performance MRAM-SRAM PIM modules and low-power MRAM-SRAM PIM modules. We\nfurther propose a data placement optimization algorithm that dynamically\nallocates data based on computational demand, maximizing energy efficiency.\nFPGA prototyping and power simulations with processors featuring HH-PIM and\nother PIM types demonstrate that the proposed HH-PIM achieves up to $60.43$\npercent average energy savings over conventional PIMs while meeting application\nlatency requirements. These results confirm the suitability of HH-PIM for\nadaptive, energy-efficient AI processing in edge devices.",
      "tldr_zh": "本文提出 Heterogeneous-Hybrid PIM (HH-PIM) 架构，旨在优化边缘 AI 设备的功耗和性能问题，通过结合高性能 MRAM-SRAM PIM 模块和低功耗模块来解决传统 PIM 在数据移动和存储方面的限制。HH-PIM 引入了一个数据放置优化算法，根据计算需求动态分配数据，以最大化能源效率。实验结果显示，与传统 PIM 相比，HH-PIM 在 FPGA 原型和功率模拟中平均节省 60.43% 能源，同时满足应用延迟要求。这些创新为能源受限的边缘环境提供了一种自适应、高效的 AI 处理方案。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "7 pages, 6 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.01468v1",
      "published_date": "2025-04-02 08:22:32 UTC",
      "updated_date": "2025-04-02 08:22:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:57:23.632106"
    },
    {
      "arxiv_id": "2504.01459v1",
      "title": "Probabilistic Curriculum Learning for Goal-Based Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Llewyn Salt",
        "Marcus Gallagher"
      ],
      "abstract": "Reinforcement learning (RL) -- algorithms that teach artificial agents to\ninteract with environments by maximising reward signals -- has achieved\nsignificant success in recent years. These successes have been facilitated by\nadvances in algorithms (e.g., deep Q-learning, deep deterministic policy\ngradients, proximal policy optimisation, trust region policy optimisation, and\nsoft actor-critic) and specialised computational resources such as GPUs and\nTPUs. One promising research direction involves introducing goals to allow\nmultimodal policies, commonly through hierarchical or curriculum reinforcement\nlearning. These methods systematically decompose complex behaviours into\nsimpler sub-tasks, analogous to how humans progressively learn skills (e.g. we\nlearn to run before we walk, or we learn arithmetic before calculus). However,\nfully automating goal creation remains an open challenge. We present a novel\nprobabilistic curriculum learning algorithm to suggest goals for reinforcement\nlearning agents in continuous control and navigation tasks.",
      "tldr_zh": "该论文探讨了基于目标的强化学习（Reinforcement Learning），强调通过引入目标来实现多模态策略，并解决复杂行为分解的挑战。作者提出了一种新型概率课程学习（Probabilistic Curriculum Learning）算法，该算法能自动为强化学习代理在连续控制和导航任务中生成目标，类似于人类从简单技能逐步学习的过程。该方法旨在提升代理的学习效率，为自动化目标创建提供新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01459v1",
      "published_date": "2025-04-02 08:15:16 UTC",
      "updated_date": "2025-04-02 08:15:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:57:35.065190"
    },
    {
      "arxiv_id": "2504.03759v1",
      "title": "Emerging Cyber Attack Risks of Medical AI Agents",
      "title_zh": "新兴医疗 AI 代理的网络攻击风险",
      "authors": [
        "Jianing Qiu",
        "Lin Li",
        "Jiankai Sun",
        "Hao Wei",
        "Zhe Xu",
        "Kyle Lam",
        "Wu Yuan"
      ],
      "abstract": "Large language models (LLMs)-powered AI agents exhibit a high level of\nautonomy in addressing medical and healthcare challenges. With the ability to\naccess various tools, they can operate within an open-ended action space.\nHowever, with the increase in autonomy and ability, unforeseen risks also\narise. In this work, we investigated one particular risk, i.e., cyber attack\nvulnerability of medical AI agents, as agents have access to the Internet\nthrough web browsing tools. We revealed that through adversarial prompts\nembedded on webpages, cyberattackers can: i) inject false information into the\nagent's response; ii) they can force the agent to manipulate recommendation\n(e.g., healthcare products and services); iii) the attacker can also steal\nhistorical conversations between the user and agent, resulting in the leak of\nsensitive/private medical information; iv) furthermore, the targeted agent can\nalso cause a computer system hijack by returning a malicious URL in its\nresponse. Different backbone LLMs were examined, and we found such cyber\nattacks can succeed in agents powered by most mainstream LLMs, with the\nreasoning models such as DeepSeek-R1 being the most vulnerable.",
      "tldr_zh": "这篇论文探讨了基于大型语言模型 (LLMs) 的医疗 AI 代理在网络攻击方面的风险，这些代理因具备高自主性和互联网访问能力而易受威胁。通过实验，研究者揭示了攻击者利用网页上的对抗性提示 (adversarial prompts) 可以实现注入虚假信息、操纵医疗推荐、窃取用户历史对话以泄露敏感医疗信息，以及引发系统劫持等行为。结果显示，大多数主流 LLMs 都存在漏洞，其中 DeepSeek-R1 等推理模型最为易受攻击，为医疗 AI 的安全设计提供了重要警示。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.03759v1",
      "published_date": "2025-04-02 08:04:53 UTC",
      "updated_date": "2025-04-02 08:04:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:57:47.913208"
    },
    {
      "arxiv_id": "2504.01452v1",
      "title": "BiSeg-SAM: Weakly-Supervised Post-Processing Framework for Boosting Binary Segmentation in Segment Anything Models",
      "title_zh": "BiSeg-SAM: 弱监督后处理框架",
      "authors": [
        "Encheng Su",
        "Hu Cao",
        "Alois Knoll"
      ],
      "abstract": "Accurate segmentation of polyps and skin lesions is essential for diagnosing\ncolorectal and skin cancers. While various segmentation methods for polyps and\nskin lesions using fully supervised deep learning techniques have been\ndeveloped, the pixel-level annotation of medical images by doctors is both\ntime-consuming and costly. Foundational vision models like the Segment Anything\nModel (SAM) have demonstrated superior performance; however, directly applying\nSAM to medical segmentation may not yield satisfactory results due to the lack\nof domain-specific medical knowledge. In this paper, we propose BiSeg-SAM, a\nSAM-guided weakly supervised prompting and boundary refinement network for the\nsegmentation of polyps and skin lesions. Specifically, we fine-tune SAM\ncombined with a CNN module to learn local features. We introduce a WeakBox with\ntwo functions: automatically generating box prompts for the SAM model and using\nour proposed Multi-choice Mask-to-Box (MM2B) transformation for rough\nmask-to-box conversion, addressing the mismatch between coarse labels and\nprecise predictions. Additionally, we apply scale consistency (SC) loss for\nprediction scale alignment. Our DetailRefine module enhances boundary precision\nand segmentation accuracy by refining coarse predictions using a limited amount\nof ground truth labels. This comprehensive approach enables BiSeg-SAM to\nachieve excellent multi-task segmentation performance. Our method demonstrates\nsignificant superiority over state-of-the-art (SOTA) methods when tested on\nfive polyp datasets and one skin cancer dataset.",
      "tldr_zh": "本文提出 BiSeg-SAM，一种弱监督后处理框架，旨在提升 Segment Anything Models (SAM) 在息肉和皮肤病变二元分割中的性能，解决传统全监督方法标注成本高的问题。该框架通过微调 SAM 与 CNN 模块学习局部特征、引入 WeakBox 自动生成框提示并使用 Multi-choice Mask-to-Box (MM2B) 转换处理标签失配、应用 Scale Consistency (SC) loss 对齐预测规模，以及 DetailRefine 模块精炼边界精度，从而实现高效的多任务分割。在五个息肉数据集和一个皮肤癌数据集上，BiSeg-SAM 显著优于现有最先进 (SOTA) 方法，展示了其在医疗图像处理中的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "2024 IEEE International Conference on Bioinformatics and Biomedicine\n  (BIBM)",
      "pdf_url": "http://arxiv.org/pdf/2504.01452v1",
      "published_date": "2025-04-02 08:04:37 UTC",
      "updated_date": "2025-04-02 08:04:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:58:02.468265"
    },
    {
      "arxiv_id": "2504.01445v1",
      "title": "Enabling Systematic Generalization in Abstract Spatial Reasoning through Meta-Learning for Compositionality",
      "title_zh": "翻译失败",
      "authors": [
        "Philipp Mondorf",
        "Shijia Zhou",
        "Monica Riedler",
        "Barbara Plank"
      ],
      "abstract": "Systematic generalization refers to the capacity to understand and generate\nnovel combinations from known components. Despite recent progress by large\nlanguage models (LLMs) across various domains, these models often fail to\nextend their knowledge to novel compositional scenarios, revealing notable\nlimitations in systematic generalization. There has been an ongoing debate\nabout whether neural networks possess the capacity for systematic\ngeneralization, with recent studies suggesting that meta-learning approaches\ndesigned for compositionality can significantly enhance this ability. However,\nthese insights have largely been confined to linguistic problems, leaving their\napplicability to other tasks an open question. In this study, we extend the\napproach of meta-learning for compositionality to the domain of abstract\nspatial reasoning. To this end, we introduce $\\textit{SYGAR}$-a dataset\ndesigned to evaluate the capacity of models to systematically generalize from\nknown geometric transformations (e.g., translation, rotation) of\ntwo-dimensional objects to novel combinations of these transformations (e.g.,\ntranslation+rotation). Our results show that a transformer-based\nencoder-decoder model, trained via meta-learning for compositionality, can\nsystematically generalize to previously unseen transformation compositions,\nsignificantly outperforming state-of-the-art LLMs, including o3-mini, GPT-4o,\nand Gemini 2.0 Flash, which fail to exhibit similar systematic behavior. Our\nfindings highlight the effectiveness of meta-learning in promoting\nsystematicity beyond linguistic tasks, suggesting a promising direction toward\nmore robust and generalizable models.",
      "tldr_zh": "本研究探讨了系统化泛化（Systematic generalization）在抽象空间推理中的应用，即模型从已知组件生成新组合的能力，尽管大型语言模型（LLMs）在这一方面存在局限。研究者将meta-learning for compositionality方法扩展到抽象空间推理领域，并引入了SYGAR数据集，用于评估模型从已知几何变换（如平移、旋转）泛化到新组合（如平移+旋转）。通过训练一个transformer-based encoder-decoder模型，实验结果显示，该模型在处理未见组合时显著优于state-of-the-art LLMs（如o3-mini、GPT-4o和Gemini 2.0 Flash）。这些发现证明了meta-learning在促进系统化泛化方面的有效性，扩展了其应用范围并为更鲁棒的模型发展提供了新方向。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "30 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.01445v1",
      "published_date": "2025-04-02 07:56:39 UTC",
      "updated_date": "2025-04-02 07:56:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:58:11.348177"
    },
    {
      "arxiv_id": "2504.01444v2",
      "title": "PiCo: Jailbreaking Multimodal Large Language Models via $\\textbf{Pi}$ctorial $\\textbf{Co}$de Contextualization",
      "title_zh": "翻译失败",
      "authors": [
        "Aofan Liu",
        "Lulu Tang",
        "Ting Pan",
        "Yuguo Yin",
        "Bin Wang",
        "Ao Yang"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs), which integrate vision and other\nmodalities into Large Language Models (LLMs), significantly enhance AI\ncapabilities but also introduce new security vulnerabilities. By exploiting the\nvulnerabilities of the visual modality and the long-tail distribution\ncharacteristic of code training data, we present PiCo, a novel jailbreaking\nframework designed to progressively bypass multi-tiered defense mechanisms in\nadvanced MLLMs. PiCo employs a tier-by-tier jailbreak strategy, using\ntoken-level typographic attacks to evade input filtering and embedding harmful\nintent within programming context instructions to bypass runtime monitoring. To\ncomprehensively assess the impact of attacks, a new evaluation metric is\nfurther proposed to assess both the toxicity and helpfulness of model outputs\npost-attack. By embedding harmful intent within code-style visual instructions,\nPiCo achieves an average Attack Success Rate (ASR) of 84.13% on Gemini-Pro\nVision and 52.66% on GPT-4, surpassing previous methods. Experimental results\nhighlight the critical gaps in current defenses, underscoring the need for more\nrobust strategies to secure advanced MLLMs.",
      "tldr_zh": "本文提出 PiCo 框架，通过图像代码语境化（Pictorial Code Contextualization）来攻击 Multimodal Large Language Models (MLLMs)，利用视觉模态漏洞和代码训练数据的长尾分布，采用分层策略（如 token-level typographic attacks 和在编程上下文中嵌入有害意图）来绕过输入过滤和运行时监控。PiCo 引入了一个新的评估指标，兼顾模型输出后的毒性和帮助性，以全面评估攻击影响。实验结果显示，PiCo 在 Gemini-Pro Vision 上达到 84.13% 的 Attack Success Rate (ASR)，在 GPT-4 上为 52.66%，显著优于现有方法，强调了当前 MLLMs 防御机制的不足，并呼吁更 robust 的安全策略。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01444v2",
      "published_date": "2025-04-02 07:54:32 UTC",
      "updated_date": "2025-04-07 08:05:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:58:24.962288"
    },
    {
      "arxiv_id": "2504.01429v1",
      "title": "Refining Interactions: Enhancing Anisotropy in Graph Neural Networks with Language Semantics",
      "title_zh": "翻译失败",
      "authors": [
        "Zhaoxing Li",
        "Xiaoming Zhang",
        "Haifeng Zhang",
        "Chengxiang Liu"
      ],
      "abstract": "The integration of Large Language Models (LLMs) with Graph Neural Networks\n(GNNs) has recently been explored to enhance the capabilities of Text Attribute\nGraphs (TAGs). Most existing methods feed textual descriptions of the graph\nstructure or neighbouring nodes' text directly into LLMs. However, these\napproaches often cause LLMs to treat structural information simply as general\ncontextual text, thus limiting their effectiveness in graph-related tasks. In\nthis paper, we introduce LanSAGNN (Language Semantic Anisotropic Graph Neural\nNetwork), a framework that extends the concept of anisotropic GNNs to the\nnatural language level. This model leverages LLMs to extract tailor-made\nsemantic information for node pairs, effectively capturing the unique\ninteractions within node relationships. In addition, we propose an efficient\ndual-layer LLMs finetuning architecture to better align LLMs' outputs with\ngraph tasks. Experimental results demonstrate that LanSAGNN significantly\nenhances existing LLM-based methods without increasing complexity while also\nexhibiting strong robustness against interference.",
      "tldr_zh": "本研究探讨了将 Large Language Models (LLMs) 与 Graph Neural Networks (GNNs) 整合，以提升 Text Attribute Graphs (TAGs) 的性能，但现有方法往往将图结构信息视为一般上下文，限制了其有效性。论文提出 LanSAGNN 框架，将各向异性 GNNs 的概念扩展到自然语言层面，通过 LLMs 提取节点对的定制语义信息，捕获节点关系的独特互动，并引入高效的双层 LLMs 微调架构，以更好地对齐 LLMs 输出与图任务。实验结果显示，LanSAGNN 显著提升了现有 LLM-based 方法的表现，同时不增加复杂性，并展现出对干扰的强鲁棒性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by ICME 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.01429v1",
      "published_date": "2025-04-02 07:32:45 UTC",
      "updated_date": "2025-04-02 07:32:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:58:35.043015"
    },
    {
      "arxiv_id": "2504.01428v1",
      "title": "MuTri: Multi-view Tri-alignment for OCT to OCTA 3D Image Translation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuangzhuang Chen",
        "Hualiang Wang",
        "Chubin Ou",
        "Xiaomeng Li"
      ],
      "abstract": "Optical coherence tomography angiography (OCTA) shows its great importance in\nimaging microvascular networks by providing accurate 3D imaging of blood\nvessels, but it relies upon specialized sensors and expensive devices. For this\nreason, previous works show the potential to translate the readily available 3D\nOptical Coherence Tomography (OCT) images into 3D OCTA images. However,\nexisting OCTA translation methods directly learn the mapping from the OCT\ndomain to the OCTA domain in continuous and infinite space with guidance from\nonly a single view, i.e., the OCTA project map, resulting in suboptimal\nresults. To this end, we propose the multi-view Tri-alignment framework for OCT\nto OCTA 3D image translation in discrete and finite space, named MuTri. In the\nfirst stage, we pre-train two vector-quantized variational auto-encoder (VQ-\nVAE) by reconstructing 3D OCT and 3D OCTA data, providing semantic prior for\nsubsequent multi-view guidances. In the second stage, our multi-view\ntri-alignment facilitates another VQVAE model to learn the mapping from the OCT\ndomain to the OCTA domain in discrete and finite space. Specifically, a\ncontrastive-inspired semantic alignment is proposed to maximize the mutual\ninformation with the pre-trained models from OCT and OCTA views, to facilitate\ncodebook learning. Meanwhile, a vessel structure alignment is proposed to\nminimize the structure discrepancy with the pre-trained models from the OCTA\nproject map view, benefiting from learning the detailed vessel structure\ninformation. We also collect the first large-scale dataset, namely, OCTA2024,\nwhich contains a pair of OCT and OCTA volumes from 846 subjects.",
      "tldr_zh": "这篇论文提出了 MuTri 框架，用于将 3D OCT 图像翻译成 3D OCTA 图像，以解决现有方法依赖单一视图指导导致的次优问题。MuTri 通过预训练两个 VQ-VAE 模型重建 OCT 和 OCTA 数据，提供语义先验，并在第二阶段采用多视图三重对齐，包括对比式语义对齐（最大化互信息）和血管结构对齐（最小化结构差异），在离散有限空间中学习精确映射。此外，作者收集了首个大规模数据集 OCTA2024，包含 846 个受试者的 OCT 和 OCTA 图像对，这为 OCTA 图像生成提供了宝贵资源。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01428v1",
      "published_date": "2025-04-02 07:28:09 UTC",
      "updated_date": "2025-04-02 07:28:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:58:48.366282"
    },
    {
      "arxiv_id": "2504.01420v1",
      "title": "FAIRE: Assessing Racial and Gender Bias in AI-Driven Resume Evaluations",
      "title_zh": "FAIRE：评估AI驱动简历评估中的种族和性别偏见",
      "authors": [
        "Athena Wen",
        "Tanush Patil",
        "Ansh Saxena",
        "Yicheng Fu",
        "Sean O'Brien",
        "Kevin Zhu"
      ],
      "abstract": "In an era where AI-driven hiring is transforming recruitment practices,\nconcerns about fairness and bias have become increasingly important. To explore\nthese issues, we introduce a benchmark, FAIRE (Fairness Assessment In Resume\nEvaluation), to test for racial and gender bias in large language models (LLMs)\nused to evaluate resumes across different industries. We use two methods-direct\nscoring and ranking-to measure how model performance changes when resumes are\nslightly altered to reflect different racial or gender identities. Our findings\nreveal that while every model exhibits some degree of bias, the magnitude and\ndirection vary considerably. This benchmark provides a clear way to examine\nthese differences and offers valuable insights into the fairness of AI-based\nhiring tools. It highlights the urgent need for strategies to reduce bias in\nAI-driven recruitment. Our benchmark code and dataset are open-sourced at our\nrepository:\nhttps://github.com/athenawen/FAIRE-Fairness-Assessment-In-Resume-Evaluation.git.",
      "tldr_zh": "这篇论文引入了 FAIRE 基准，用于评估大型语言模型 (LLMs) 在 AI 驱动的简历评估中存在的种族和性别偏见。研究采用直接评分和排名两种方法，通过微调简历以反映不同种族或性别身份，观察模型性能的变化。结果显示，所有模型都表现出某种偏见，但其程度和方向存在显著差异。该基准为分析 AI 招聘工具的公平性提供了清晰框架，并强调了减少偏见策略的迫切需求，同时开源了代码和数据集。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01420v1",
      "published_date": "2025-04-02 07:11:30 UTC",
      "updated_date": "2025-04-02 07:11:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:58:59.731618"
    },
    {
      "arxiv_id": "2504.01407v1",
      "title": "TimeSearch: Hierarchical Video Search with Spotlight and Reflection for Human-like Long Video Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Junwen Pan",
        "Rui Zhang",
        "Xin Wan",
        "Yuan Zhang",
        "Ming Lu",
        "Qi She"
      ],
      "abstract": "Large video-language models (LVLMs) have shown remarkable performance across\nvarious video-language tasks. However, they encounter significant challenges\nwhen processing long videos because of the large number of video frames\ninvolved. Downsampling long videos in either space or time can lead to visual\nhallucinations, making it difficult to accurately interpret long videos.\nMotivated by human hierarchical temporal search strategies, we propose\n\\textbf{TimeSearch}, a novel framework enabling LVLMs to understand long videos\nin a human-like manner. TimeSearch integrates two human-like primitives into a\nunified autoregressive LVLM: 1) \\textbf{Spotlight} efficiently identifies\nrelevant temporal events through a Temporal-Augmented Frame Representation\n(TAFR), explicitly binding visual features with timestamps; 2)\n\\textbf{Reflection} evaluates the correctness of the identified events,\nleveraging the inherent temporal self-reflection capabilities of LVLMs.\nTimeSearch progressively explores key events and prioritizes temporal search\nbased on reflection confidence. Extensive experiments on challenging long-video\nbenchmarks confirm that TimeSearch substantially surpasses previous\nstate-of-the-art, improving the accuracy from 41.8\\% to 51.5\\% on the LVBench.\nAdditionally, experiments on temporal grounding demonstrate that appropriate\nTAFR is adequate to effectively stimulate the surprising temporal grounding\nability of LVLMs in a simpler yet versatile manner, which improves mIoU on\nCharades-STA by 11.8\\%. The code will be released.",
      "tldr_zh": "该研究针对大型视频语言模型(LVLMs)在处理长视频时面临的视觉幻觉和准确性挑战，提出了一种模仿人类层次化时间搜索策略的框架TimeSearch。TimeSearch将两个关键机制整合进统一的自动回归LVLM：Spotlight通过Temporal-Augmented Frame Representation (TAFR)高效识别相关时间事件，并将视觉特征与时间戳绑定；Reflection则利用LVLM的内在时间自反能力评估事件的正确性，并基于置信度优先化搜索。实验结果显示，TimeSearch在长视频基准测试如LVBench上将准确率从41.8%提升至51.5%，并在时间定位任务上使Charades-STA的mIoU提高11.8%，证明了其在提升长视频理解方面的显著效果。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01407v1",
      "published_date": "2025-04-02 06:47:19 UTC",
      "updated_date": "2025-04-02 06:47:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:59:11.755046"
    },
    {
      "arxiv_id": "2504.02014v1",
      "title": "HCAF-DTA: drug-target binding affinity prediction with cross-attention fused hypergraph neural networks",
      "title_zh": "HCAF-DTA：基于交叉注意力融合超图神经网络的药物-目标结合亲和力预测",
      "authors": [
        "Jiannuo Li",
        "Lan Yao"
      ],
      "abstract": "Accurate prediction of the binding affinity between drugs and target proteins\nis a core task in computer-aided drug design. Existing deep learning methods\ntend to ignore the information of internal sub-structural features of drug\nmolecules and drug-target interactions, resulting in limited prediction\nperformance. In this paper, we propose a drug-target association prediction\nmodel HCAF-DTA based on cross-attention fusion hypergraph neural network. The\nmodel innovatively introduces hypergraph representation in the feature\nextraction stage: drug molecule hypergraphs are constructed based on the tree\ndecomposition algorithm, and the sub-structural and global features extracted\nby fusing the hypergraph neural network with the graphical neural network\nthrough hopping connections, in which the hyper edges can efficiently\ncharacterise the functional functional groups and other key chemical features;\nfor the protein feature extraction, a weighted graph is constructed based on\nthe residues predicted by the ESM model contact maps to construct weighted\ngraphs, and multilayer graph neural networks were used to capture spatial\ndependencies. In the prediction stage, a bidirectional multi-head\ncross-attention mechanism is designed to model intermolecular interactions from\nthe dual viewpoints of atoms and amino acids, and cross-modal features with\ncorrelated information are fused by attention. Experiments on benchmark\ndatasets such as Davis and KIBA show that HCAF-DTA outperforms state of the\narts in all three performance evaluation metrics, with the MSE metrics reaching\n0.198 and 0.122, respectively, with an improvement of up to 4% from the optimal\nbaseline.",
      "tldr_zh": "该研究提出了一种名为 HCAF-DTA 的药物-目标蛋白结合亲和力预测模型，旨在解决现有深度学习方法忽略药物分子内部子结构特征和药物-目标交互的问题。模型在特征提取阶段使用树分解算法构建药物分子超图（hypergraph），并通过超图神经网络与图形神经网络的融合提取子结构和全局特征；同时，对于蛋白质特征，利用 ESM model 预测的残基接触图构建加权图，并应用多层图神经网络捕获空间依赖性。在预测阶段，引入双向多头交叉注意力机制（cross-attention）从原子和氨基酸视角建模分子间交互，并融合相关跨模态特征。实验在 Davis 和 KIBA 数据集上显示，HCAF-DTA 在所有评估指标中优于现有方法，MSE 分别达到 0.198 和 0.122，比最佳基线提高了多达 4%。",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.BM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02014v1",
      "published_date": "2025-04-02 06:46:28 UTC",
      "updated_date": "2025-04-02 06:46:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:59:23.699011"
    },
    {
      "arxiv_id": "2504.01403v1",
      "title": "Generative Retrieval and Alignment Model: A New Paradigm for E-commerce Retrieval",
      "title_zh": "生成式检索和对齐模型：电子商务检索的新范式",
      "authors": [
        "Ming Pang",
        "Chunyuan Yuan",
        "Xiaoyu He",
        "Zheng Fang",
        "Donghao Xie",
        "Fanyi Qu",
        "Xue Jiang",
        "Changping Peng",
        "Zhangang Lin",
        "Zheng Luo",
        "Jingping Shao"
      ],
      "abstract": "Traditional sparse and dense retrieval methods struggle to leverage general\nworld knowledge and often fail to capture the nuanced features of queries and\nproducts. With the advent of large language models (LLMs), industrial search\nsystems have started to employ LLMs to generate identifiers for product\nretrieval. Commonly used identifiers include (1) static/semantic IDs and (2)\nproduct term sets. The first approach requires creating a product ID system\nfrom scratch, missing out on the world knowledge embedded within LLMs. While\nthe second approach leverages this general knowledge, the significant\ndifference in word distribution between queries and products means that\nproduct-based identifiers often do not align well with user search queries,\nleading to missed product recalls. Furthermore, when queries contain numerous\nattributes, these algorithms generate a large number of identifiers, making it\ndifficult to assess their quality, which results in low overall recall\nefficiency.\n  To address these challenges, this paper introduces a novel e-commerce\nretrieval paradigm: the Generative Retrieval and Alignment Model (GRAM). GRAM\nemploys joint training on text information from both queries and products to\ngenerate shared text identifier codes, effectively bridging the gap between\nqueries and products. This approach not only enhances the connection between\nqueries and products but also improves inference efficiency. The model uses a\nco-alignment strategy to generate codes optimized for maximizing retrieval\nefficiency. Additionally, it introduces a query-product scoring mechanism to\ncompare product values across different codes, further boosting retrieval\nefficiency. Extensive offline and online A/B testing demonstrates that GRAM\nsignificantly outperforms traditional models and the latest generative\nretrieval models, confirming its effectiveness and practicality.",
      "tldr_zh": "本文指出，传统稀疏和密集检索方法难以利用大语言模型(LLMs)的世界知识，且查询与产品的特征不匹配，导致检索效率低下。为解决这些问题，论文提出Generative Retrieval and Alignment Model (GRAM)，一种新型电商检索范式，通过在查询和产品文本上联合训练生成共享的文本标识码，并采用co-alignment策略来桥接两者差距，同时引入查询-产品评分机制以优化检索性能。实验结果显示，GRAM在离线和在线A/B测试中显著优于传统模型和最新生成式检索模型，提高了整体召回效率和实际应用价值。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted by WWW2025",
      "pdf_url": "http://arxiv.org/pdf/2504.01403v1",
      "published_date": "2025-04-02 06:40:09 UTC",
      "updated_date": "2025-04-02 06:40:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:59:35.976598"
    },
    {
      "arxiv_id": "2504.01400v1",
      "title": "ToolACE-R: Tool Learning with Adaptive Self-Refinement",
      "title_zh": "翻译失败",
      "authors": [
        "Xingshan Zeng",
        "Weiwen Liu",
        "Xu Huang",
        "Zezhong Wang",
        "Lingzhi Wang",
        "Liangyou Li",
        "Yasheng Wang",
        "Lifeng Shang",
        "Xin Jiang",
        "Ruiming Tang",
        "Qun Liu"
      ],
      "abstract": "Tool learning, which allows Large Language Models (LLMs) to leverage external\ntools for solving complex user tasks, has emerged as a promising avenue for\nextending model capabilities. However, current approaches primarily focus on\ndata synthesis for fine-tuning LLMs to invoke tools effectively, largely\nignoring how to fully stimulate the potential of the model. In this paper, we\npropose ToolACE-R, a novel method that introduces adaptive self-refinement for\ntool invocations. Our approach features a model-aware iterative training\nprocedure that progressively incorporates more training samples based on the\nmodel's evolving capabilities. Additionally, it allows LLMs to iteratively\nrefine their tool calls, optimizing performance without requiring external\nfeedback. To further enhance computational efficiency, we integrate an adaptive\nmechanism when scaling the inference time, enabling the model to autonomously\ndetermine when to stop the refinement process. We conduct extensive experiments\nacross several benchmark datasets, showing that ToolACE-R achieves competitive\nperformance compared to advanced API-based models, even without any refinement.\nFurthermore, its performance can be further improved efficiently through\nadaptive self-refinement. Our results demonstrate the effectiveness of the\nproposed method, which is compatible with base models of various sizes,\noffering a promising direction for more efficient tool learning.",
      "tldr_zh": "该论文提出ToolACE-R，一种创新的工具学习方法，通过引入自适应自优化（adaptive self-refinement）来提升Large Language Models (LLMs)调用外部工具的能力。该方法采用模型感知的迭代训练过程，根据模型演进动态添加训练样本，并允许LLMs自行迭代优化工具调用，而无需外部反馈，同时整合自适应机制来自主决定优化停止时机。实验结果显示，ToolACE-R在多个基准数据集上与高级API-based模型相比具有竞争力，甚至在未优化时即可实现高效性能，且兼容不同大小的基模型，为工具学习提供了更高效的方向。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01400v1",
      "published_date": "2025-04-02 06:38:56 UTC",
      "updated_date": "2025-04-02 06:38:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:59:47.489402"
    },
    {
      "arxiv_id": "2504.01395v1",
      "title": "From Easy to Hard: Building a Shortcut for Differentially Private Image Synthesis",
      "title_zh": "从易到难：构建",
      "authors": [
        "Kecen Li",
        "Chen Gong",
        "Xiaochen Li",
        "Yuzhong Zhao",
        "Xinwen Hou",
        "Tianhao Wang"
      ],
      "abstract": "Differentially private (DP) image synthesis aims to generate synthetic images\nfrom a sensitive dataset, alleviating the privacy leakage concerns of\norganizations sharing and utilizing synthetic images. Although previous methods\nhave significantly progressed, especially in training diffusion models on\nsensitive images with DP Stochastic Gradient Descent (DP-SGD), they still\nsuffer from unsatisfactory performance. In this work, inspired by curriculum\nlearning, we propose a two-stage DP image synthesis framework, where diffusion\nmodels learn to generate DP synthetic images from easy to hard. Unlike existing\nmethods that directly use DP-SGD to train diffusion models, we propose an easy\nstage in the beginning, where diffusion models learn simple features of the\nsensitive images. To facilitate this easy stage, we propose to use `central\nimages', simply aggregations of random samples of the sensitive dataset.\nIntuitively, although those central images do not show details, they\ndemonstrate useful characteristics of all images and only incur minimal privacy\ncosts, thus helping early-phase model training. We conduct experiments to\npresent that on the average of four investigated image datasets, the fidelity\nand utility metrics of our synthetic images are 33.1% and 2.1% better than the\nstate-of-the-art method.",
      "tldr_zh": "这篇论文针对差分隐私（DP）图像合成的问题，提出一个两阶段框架，受课程学习启发，让扩散模型从简单到复杂地学习敏感图像特征，以缓解现有DP-SGD方法的性能不足。第一阶段使用“central images”（敏感数据集随机样本的聚合）来训练模型学习基本特征，从而最小化隐私成本，同时提升早期训练效率。实验结果显示，在四个图像数据集的平均上，该框架生成的合成图像在保真度和实用性指标上比最先进方法提高了33.1%和2.1%。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted at IEEE S&P (Oakland) 2025; code available at\n  https://github.com/SunnierLee/DP-FETA",
      "pdf_url": "http://arxiv.org/pdf/2504.01395v1",
      "published_date": "2025-04-02 06:30:55 UTC",
      "updated_date": "2025-04-02 06:30:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:00:00.126099"
    },
    {
      "arxiv_id": "2504.03755v1",
      "title": "ProtoGCD: Unified and Unbiased Prototype Learning for Generalized Category Discovery",
      "title_zh": "ProtoGCD：用于广义类别发现的统一无偏原型学习",
      "authors": [
        "Shijie Ma",
        "Fei Zhu",
        "Xu-Yao Zhang",
        "Cheng-Lin Liu"
      ],
      "abstract": "Generalized category discovery (GCD) is a pragmatic but underexplored\nproblem, which requires models to automatically cluster and discover novel\ncategories by leveraging the labeled samples from old classes. The challenge is\nthat unlabeled data contain both old and new classes. Early works leveraging\npseudo-labeling with parametric classifiers handle old and new classes\nseparately, which brings about imbalanced accuracy between them. Recent methods\nemploying contrastive learning neglect potential positives and are decoupled\nfrom the clustering objective, leading to biased representations and\nsub-optimal results. To address these issues, we introduce a unified and\nunbiased prototype learning framework, namely ProtoGCD, wherein old and new\nclasses are modeled with joint prototypes and unified learning objectives,\n{enabling unified modeling between old and new classes}. Specifically, we\npropose a dual-level adaptive pseudo-labeling mechanism to mitigate\nconfirmation bias, together with two regularization terms to collectively help\nlearn more suitable representations for GCD. Moreover, for practical\nconsiderations, we devise a criterion to estimate the number of new classes.\nFurthermore, we extend ProtoGCD to detect unseen outliers, achieving task-level\nunification. Comprehensive experiments show that ProtoGCD achieves\nstate-of-the-art performance on both generic and fine-grained datasets. The\ncode is available at https://github.com/mashijie1028/ProtoGCD.",
      "tldr_zh": "本论文提出 ProtoGCD，一种统一的、无偏见的原型学习框架，用于处理 Generalized Category Discovery (GCD)，该任务要求模型利用旧类别的标注样本自动聚类并发现新类别，同时解决现有方法在旧和新类别间准确率不平衡以及表示偏差的问题。ProtoGCD 通过联合原型建模和统一学习目标，引入双层自适应伪标签机制以及两个正则化项，来减轻确认偏差并优化表示学习。此外，该框架还设计了估计新类别数量的标准，并扩展到检测未见过的异常值，实现任务级统一；实验结果显示，ProtoGCD 在通用和细粒度数据集上达到了最先进性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to IEEE TPAMI 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.03755v1",
      "published_date": "2025-04-02 06:13:14 UTC",
      "updated_date": "2025-04-02 06:13:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:00:11.709178"
    },
    {
      "arxiv_id": "2504.01382v2",
      "title": "An Illusion of Progress? Assessing the Current State of Web Agents",
      "title_zh": "进步的幻觉？",
      "authors": [
        "Tianci Xue",
        "Weijian Qi",
        "Tianneng Shi",
        "Chan Hee Song",
        "Boyu Gou",
        "Dawn Song",
        "Huan Sun",
        "Yu Su"
      ],
      "abstract": "As digitalization and cloud technologies evolve, the web is becoming\nincreasingly important in the modern society. Autonomous web agents based on\nlarge language models (LLMs) hold a great potential in work automation. It is\ntherefore important to accurately measure and monitor the progression of their\ncapabilities. In this work, we conduct a comprehensive and rigorous assessment\nof the current state of web agents. Our results depict a very different picture\nof the competency of current agents, suggesting over-optimism in previously\nreported results. This gap can be attributed to shortcomings in existing\nbenchmarks. We introduce Online-Mind2Web, an online evaluation benchmark\nconsisting of 300 diverse and realistic tasks spanning 136 websites. It enables\nus to evaluate web agents under a setting that approximates how real users use\nthese agents. To facilitate more scalable evaluation and development, we also\ndevelop a novel LLM-as-a-Judge automatic evaluation method and show that it can\nachieve around 85% agreement with human judgment, substantially higher than\nexisting methods. Finally, we present the first comprehensive comparative\nanalysis of current web agents, highlighting both their strengths and\nlimitations to inspire future research.",
      "tldr_zh": "这篇论文评估了基于大语言模型(LLMs)的自主网络代理的当前状态，发现其实际能力远低于先前报道的乐观水平，主要由于现有基准的不足。作者引入了Online-Mind2Web基准，该基准包含300个多样化、真实的任务，覆盖136个网站，以模拟真实用户使用场景。论文还开发了LLM-as-a-Judge自动评估方法，其与人类判断一致性高达85%，显著优于现有方法。最后，通过首次全面比较分析，研究突出了网络代理的优点和局限性，为未来研究提供了宝贵启发。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "22 pages, 17 figures, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.01382v2",
      "published_date": "2025-04-02 05:51:29 UTC",
      "updated_date": "2025-05-11 19:04:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:00:23.413187"
    },
    {
      "arxiv_id": "2504.02011v1",
      "title": "Random Conditioning with Distillation for Data-Efficient Diffusion Model Compression",
      "title_zh": "翻译失败",
      "authors": [
        "Dohyun Kim",
        "Sehwan Park",
        "Geonhee Han",
        "Seung Wook Kim",
        "Paul Hongsuck Seo"
      ],
      "abstract": "Diffusion models generate high-quality images through progressive denoising\nbut are computationally intensive due to large model sizes and repeated\nsampling. Knowledge distillation, which transfers knowledge from a complex\nteacher to a simpler student model, has been widely studied in recognition\ntasks, particularly for transferring concepts unseen during student training.\nHowever, its application to diffusion models remains underexplored, especially\nin enabling student models to generate concepts not covered by the training\nimages. In this work, we propose Random Conditioning, a novel approach that\npairs noised images with randomly selected text conditions to enable efficient,\nimage-free knowledge distillation. By leveraging this technique, we show that\nthe student can generate concepts unseen in the training images. When applied\nto conditional diffusion model distillation, our method allows the student to\nexplore the condition space without generating condition-specific images,\nresulting in notable improvements in both generation quality and efficiency.\nThis promotes resource-efficient deployment of generative diffusion models,\nbroadening their accessibility for both research and real-world applications.\nCode, models, and datasets are available at\nhttps://dohyun-as.github.io/Random-Conditioning .",
      "tldr_zh": "这项研究提出 Random Conditioning 方法，用于知识蒸馏（Knowledge Distillation），以实现数据高效的扩散模型（Diffusion Models）压缩。该方法通过将噪声图像与随机选择的文本条件配对，实现了无图像依赖的知识转移，使学生模型能够生成训练图像中未见的概念。在条件扩散模型蒸馏应用中，该方法显著提升了生成质量和效率，促进了扩散模型在资源有限的场景中的部署。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to CVPR 2025. 8 pages main paper + 4 pages references + 5\n  pages supplementary, 9 figures in total",
      "pdf_url": "http://arxiv.org/pdf/2504.02011v1",
      "published_date": "2025-04-02 05:41:19 UTC",
      "updated_date": "2025-04-02 05:41:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:00:35.319101"
    },
    {
      "arxiv_id": "2504.01366v1",
      "title": "Virtual Reality and Artificial Intelligence as Psychological Countermeasures in Space and Other Isolated and Confined Environments: A Scoping Review",
      "title_zh": "虚拟现实和人工智能作为太空以及其他隔离和封闭环境中的心理对策：一项范围综述",
      "authors": [
        "Jennifer Sharp",
        "Joshua Kelson",
        "Daryl South",
        "Anthony Saliba",
        "Muhammad Ashad Kabir"
      ],
      "abstract": "Spaceflight is an isolated and confined environment (ICE) that exposes\nastronauts to psychological hazards, such as stress, danger, and monotony.\nVirtual reality (VR) and artificial intelligence (AI) technologies can serve as\npsychological countermeasures as they can digitally simulate immersive\nenvironments, interactive companions, and therapeutic experiences. Our study\nemploys a scoping literature review approach to identify what is currently\nknown about the use and effectiveness of VR and AI-based interventions as\npsychological countermeasures to improve mood or emotional states in adults in\nspace or other ICEs. Additionally, this review aimed to identify gaps in the\nknowledge base and whether a systematic review with meta-analysis was\nwarranted. The review included studies where the intervention was used or\nintended for use in space or other extraterrestrial environments (ICE). Our\nsearch strategy yielded 19 studies from 3390 records across seven major\ndatabases. All studies focused on VR-based interventions, with no eligible\nAI-based intervention studies found. VR interventions were found to be\neffective for relaxation and improving mood, emergency training, as an\ninteractive communication platform, for comparing interior designs, and for\nenhancing exercise. There were improvements for measures of mood and emotion\\n\n(e.g., anxiety and stress); however, user preferences varied, and some\ninstances of cybersickness were reported. A systematic review with\nmeta-analysis is not recommended due to the heterogeneity of results. There is\nsignificant scope for further research into the use of VR for a wider range of\nmood and emotion variables using standardised assessment instruments.\nAdditionally, the potential application of AI as a psychological countermeasure\nwarrants further investigation.",
      "tldr_zh": "这篇综述探讨了 Virtual Reality (VR) 和 Artificial Intelligence (AI) 作为太空飞行或其他隔离封闭环境 (ICE) 中应对心理危害（如压力和单调）的潜在对策。通过对七个主要数据库的文献回顾，共筛选出 19 篇研究，全部聚焦于 VR 干预，而未发现符合条件的 AI 研究。结果显示，VR 在放松、改善情绪（如减少焦虑和压力）、紧急训练、互动通信以及增强锻炼方面有效，但伴随用户偏好差异和 cybersickness 问题。综述强调，由于研究结果异质性大，不宜进行系统回顾和元分析，并呼吁进一步探究 VR 在更多情绪变量上的应用以及 AI 的潜在作用。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.HC",
      "comment": "34 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.01366v1",
      "published_date": "2025-04-02 05:25:29 UTC",
      "updated_date": "2025-04-02 05:25:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:00:49.709930"
    },
    {
      "arxiv_id": "2504.02010v1",
      "title": "When Reasoning Meets Compression: Benchmarking Compressed Large Reasoning Models on Complex Reasoning Tasks",
      "title_zh": "当推理遇见压缩：在复杂推理任务上对压缩的大型推理模型进行基准测试",
      "authors": [
        "Nan Zhang",
        "Yusen Zhang",
        "Prasenjit Mitra",
        "Rui Zhang"
      ],
      "abstract": "Recent open-source large reasoning models (LRMs) exhibit strong performance\non complex reasoning tasks, but their large parameter count makes them\nprohibitively expensive for individuals. The compression of large language\nmodels (LLMs) offers an effective solution to reduce cost of computational\nresources. However, systematic studies on the performance of compressed LLMs in\ncomplex reasoning tasks, especially for LRMs, are lacking. Most works on\nquantization and pruning focus on preserving language modeling performance,\nwhile existing distillation works do not comprehensively benchmark student\nmodels based on reasoning difficulty or compression impact on knowledge and\nreasoning. In this paper, we benchmark compressed DeepSeek-R1 models on four\ndifferent reasoning datasets (AIME 2024, FOLIO, Temporal Sequences of BIG-Bench\nHard, and MuSiQue), ranging from mathematical to multihop reasoning, using\nquantization, distillation, and pruning methods. We benchmark 2.51-, 1.73-, and\n1.58-bit R1 models that adopt dynamic quantization. We also benchmark distilled\nR1 models that are based on LLaMA or Qwen and run SparseGPT on them to obtain\nvarious sparsity levels. Studying the performance and behavior of compressed\nLRMs, we report their performance scores and test-time compute (number of\ntokens spent on each question). Notably, using MuSiQue, we find that parameter\ncount has a much greater impact on LRMs' knowledge memorization than on their\nreasoning capability, which can inform the choice of compression techniques.\nThrough our empirical analysis of test-time compute, we find that shorter model\noutputs generally achieve better performance than longer ones across several\nbenchmarks for both R1 and its compressed variants, highlighting the need for\nmore concise reasoning chains.",
      "tldr_zh": "本研究benchmark了压缩后的Large Reasoning Models (LRMs) 在复杂推理任务上的性能，以解决模型参数量大导致的计算资源成本问题。研究者对DeepSeek-R1模型应用了quantization、distillation和pruning方法，并在AIME 2024、FOLIO、Temporal Sequences of BIG-Bench Hard和MuSiQue等四个数据集上进行测试。结果显示，参数量对LRMs知识记忆的影响远大于推理能力，而更短的模型输出通常能实现更好的性能，这为选择合适的压缩技术提供了重要指导。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02010v1",
      "published_date": "2025-04-02 05:17:46 UTC",
      "updated_date": "2025-04-02 05:17:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:00:59.308287"
    },
    {
      "arxiv_id": "2504.02880v1",
      "title": "Global Rice Multi-Class Segmentation Dataset (RiceSEG): A Comprehensive and Diverse High-Resolution RGB-Annotated Images for the Development and Benchmarking of Rice Segmentation Algorithms",
      "title_zh": "翻译失败",
      "authors": [
        "Junchi Zhou",
        "Haozhou Wang",
        "Yoichiro Kato",
        "Tejasri Nampally",
        "P. Rajalakshmi",
        "M. Balram",
        "Keisuke Katsura",
        "Hao Lu",
        "Yue Mu",
        "Wanneng Yang",
        "Yangmingrui Gao",
        "Feng Xiao",
        "Hongtao Chen",
        "Yuhao Chen",
        "Wenjuan Li",
        "Jingwen Wang",
        "Fenghua Yu",
        "Jian Zhou",
        "Wensheng Wang",
        "Xiaochun Hu",
        "Yuanzhu Yang",
        "Yanfeng Ding",
        "Wei Guo",
        "Shouyang Liu"
      ],
      "abstract": "Developing computer vision-based rice phenotyping techniques is crucial for\nprecision field management and accelerating breeding, thereby continuously\nadvancing rice production. Among phenotyping tasks, distinguishing image\ncomponents is a key prerequisite for characterizing plant growth and\ndevelopment at the organ scale, enabling deeper insights into eco-physiological\nprocesses. However, due to the fine structure of rice organs and complex\nillumination within the canopy, this task remains highly challenging,\nunderscoring the need for a high-quality training dataset. Such datasets are\nscarce, both due to a lack of large, representative collections of rice field\nimages and the time-intensive nature of annotation. To address this gap, we\nestablished the first comprehensive multi-class rice semantic segmentation\ndataset, RiceSEG. We gathered nearly 50,000 high-resolution, ground-based\nimages from five major rice-growing countries (China, Japan, India, the\nPhilippines, and Tanzania), encompassing over 6,000 genotypes across all growth\nstages. From these original images, 3,078 representative samples were selected\nand annotated with six classes (background, green vegetation, senescent\nvegetation, panicle, weeds, and duckweed) to form the RiceSEG dataset. Notably,\nthe sub-dataset from China spans all major genotypes and rice-growing\nenvironments from the northeast to the south. Both state-of-the-art\nconvolutional neural networks and transformer-based semantic segmentation\nmodels were used as baselines. While these models perform reasonably well in\nsegmenting background and green vegetation, they face difficulties during the\nreproductive stage, when canopy structures are more complex and multiple\nclasses are involved. These findings highlight the importance of our dataset\nfor developing specialized segmentation models for rice and other crops.",
      "tldr_zh": "本文介绍了 RiceSEG 数据集，这是首个全面的多类稻谷语义分割数据集，旨在支持计算机视觉技术在稻谷表型分析中的应用，包括精确田间管理和育种加速。数据集从中国、日本、印度、菲律宾和坦桑尼亚五个主要稻谷种植国家收集了近 50,000 张高分辨率 RGB 图像，涵盖超过 6,000 个基因型和所有生长阶段，并从中选取 3,078 张样本标注了六个类（背景、绿色植被、衰老植被、穗状花序、杂草和浮萍）。使用 state-of-the-art 的 convolutional neural networks 和 transformer-based 模型作为基准测试，结果显示这些模型在分割背景和绿色植被时表现良好，但在生殖阶段的复杂结构和多类场景下存在困难。这些发现突出了 RiceSEG 数据集在开发专用稻谷和其他作物分割算法方面的关键价值。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02880v1",
      "published_date": "2025-04-02 04:03:23 UTC",
      "updated_date": "2025-04-02 04:03:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:01:13.297417"
    },
    {
      "arxiv_id": "2504.01337v2",
      "title": "Advancing MoE Efficiency: A Collaboration-Constrained Routing (C2R) Strategy for Better Expert Parallelism Design",
      "title_zh": "翻译失败",
      "authors": [
        "Mohan Zhang",
        "Pingzhi Li",
        "Jie Peng",
        "Mufan Qiu",
        "Tianlong Chen"
      ],
      "abstract": "Mixture-of-Experts (MoE) has successfully scaled up models while maintaining\nnearly constant computing costs. By employing a gating network to route input\ntokens, it selectively activates a subset of expert networks to process the\ncorresponding token embeddings. However, in practice, the efficiency of MoE is\nchallenging to achieve due to two key reasons: imbalanced expert activation,\nwhich leads to substantial idle time during model or expert parallelism, and\ninsufficient capacity utilization; massive communication overhead, induced by\nnumerous expert routing combinations in expert parallelism at the system level.\nPrevious works typically formulate it as the load imbalance issue characterized\nby the gating network favoring certain experts over others or attribute it to\nstatic execution which fails to adapt to the dynamic expert workload at\nruntime. In this paper, we exploit it from a brand new perspective, a\nhigher-order view and analysis of MoE routing policies: expert collaboration\nand specialization where some experts tend to activate broadly with others\n(collaborative), while others are more likely to activate only with a specific\nsubset of experts (specialized). Our experiments reveal that most experts tend\nto be overly collaborative, leading to increased communication overhead from\nrepeatedly sending tokens to different accelerators. To this end, we propose a\nnovel collaboration-constrained routing (C2R) strategy to encourage more\nspecialized expert groups, as well as to improve expert utilization, and\npresent an efficient implementation of MoE that further leverages expert\nspecialization. We achieve an average performance improvement of 0.51% and\n0.33% on LLaMA-MoE and Qwen-MoE respectively across ten downstream NLP\nbenchmarks, and reduce the all2all communication costs between GPUs, bringing\nan extra 20%-30% total running time savings on top of the existing SoTA, i.e.\nMegaBlocks.",
      "tldr_zh": "该论文分析了Mixture-of-Experts (MoE)模型在专家并行性中的效率问题，强调专家协作过度导致的激活不平衡和通信开销增大，并从专家协作与专业化的新视角提出Collaboration-Constrained Routing (C2R)策略，以鼓励专家专业化并优化路由。C2R策略通过约束专家协作来提高专家利用率，并提供高效的MoE实现方法。实验结果显示，在LLaMA-MoE和Qwen-MoE模型上，分别在十个NLP基准上提升0.51%和0.33%的性能，同时减少20%-30%的all2all通信开销，超越现有最先进方法MegaBlocks。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "NAACL 2025, SAC award for Low-resource Methods for NLP",
      "pdf_url": "http://arxiv.org/pdf/2504.01337v2",
      "published_date": "2025-04-02 03:51:59 UTC",
      "updated_date": "2025-04-20 15:13:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:01:24.708551"
    },
    {
      "arxiv_id": "2504.01331v1",
      "title": "An Explainable Reconfiguration-Based Optimization Algorithm for Industrial and Reliability-Redundancy Allocation Problems",
      "title_zh": "一种可解释的基于重新配置",
      "authors": [
        "Dikshit Chauhan",
        "Nitin Gupta",
        "Anupam Yadav"
      ],
      "abstract": "Industrial and reliability optimization problems often involve complex\nconstraints and require efficient, interpretable solutions. This paper presents\nAI-AEFA, an advanced parameter reconfiguration-based metaheuristic algorithm\ndesigned to address large-scale industrial and reliability-redundancy\nallocation problems. AI-AEFA enhances search space exploration and convergence\nefficiency through a novel log-sigmoid-based parameter adaptation and chaotic\nmapping mechanism. The algorithm is validated across twenty-eight IEEE CEC 2017\nconstrained benchmark problems, fifteen large-scale industrial optimization\nproblems, and seven reliability-redundancy allocation problems, consistently\noutperforming state-of-the-art optimization techniques in terms of feasibility,\ncomputational efficiency, and convergence speed. The additional key\ncontribution of this work is the integration of SHAP (Shapley Additive\nExplanations) to enhance the interpretability of AI-AEFA, providing insights\ninto the impact of key parameters such as Coulomb's constant, charge,\nacceleration, and electrostatic force. This explainability feature enables a\ndeeper understanding of decision-making within the AI-AEFA framework during the\noptimization processes. The findings confirm AI-AEFA as a robust, scalable, and\ninterpretable optimization tool with significant real-world applications.",
      "tldr_zh": "本文提出AI-AEFA，一种基于参数重新配置的元启发式算法，用于解决大规模工业和可靠性-冗余分配问题，通过log-sigmoid-based参数适应及混沌映射机制提升搜索空间探索和收敛效率。算法在28个IEEE CEC 2017约束基准问题、15个工业优化问题及7个可靠性-冗余分配问题上验证，表现出色，在可行性、计算效率和收敛速度方面优于现有技术。关键创新在于整合SHAP（Shapley Additive Explanations）来提升算法可解释性，提供对关键参数如Coulomb's constant、charge、acceleration和electrostatic force的影响洞见。总体而言，AI-AEFA作为一种鲁棒、可扩展的优化工具，具有重要的实际应用潜力。",
      "categories": [
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "38 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.01331v1",
      "published_date": "2025-04-02 03:33:48 UTC",
      "updated_date": "2025-04-02 03:33:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:01:38.356735"
    },
    {
      "arxiv_id": "2504.01326v1",
      "title": "CFMD: Dynamic Cross-layer Feature Fusion for Salient Object Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Jin Lian",
        "Zhongyu Wan",
        "Ming Gao",
        "JunFeng Chen"
      ],
      "abstract": "Cross-layer feature pyramid networks (CFPNs) have achieved notable progress\nin multi-scale feature fusion and boundary detail preservation for salient\nobject detection. However, traditional CFPNs still suffer from two core\nlimitations: (1) a computational bottleneck caused by complex feature weighting\noperations, and (2) degraded boundary accuracy due to feature blurring in the\nupsampling process. To address these challenges, we propose CFMD, a novel\ncross-layer feature pyramid network that introduces two key innovations. First,\nwe design a context-aware feature aggregation module (CFLMA), which\nincorporates the state-of-the-art Mamba architecture to construct a dynamic\nweight distribution mechanism. This module adaptively adjusts feature\nimportance based on image context, significantly improving both representation\nefficiency and generalization. Second, we introduce an adaptive dynamic\nupsampling unit (CFLMD) that preserves spatial details during resolution\nrecovery. By adjusting the upsampling range dynamically and initializing with a\nbilinear strategy, the module effectively reduces feature overlap and maintains\nfine-grained boundary structures. Extensive experiments on three standard\nbenchmarks using three mainstream backbone networks demonstrate that CFMD\nachieves substantial improvements in pixel-level accuracy and boundary\nsegmentation quality, especially in complex scenes. The results validate the\neffectiveness of CFMD in jointly enhancing computational efficiency and\nsegmentation performance, highlighting its strong potential in salient object\ndetection tasks.",
      "tldr_zh": "该论文提出 CFMD，一种动态跨层特征融合网络，用于显著对象检测，针对传统 CFPNs 的计算瓶颈和上采样导致的特征模糊问题进行优化。CFMD 引入了 context-aware feature aggregation module (CFLMA)，利用 Mamba 架构动态调整特征权重，根据图像上下文提升表示效率和泛化能力；同时，adaptive dynamic upsampling unit (CFLMD) 通过动态调整上采样范围和双线性初始化，减少特征重叠并保留精细边界结构。在三个标准基准上的实验显示，CFMD 使用主流骨干网络后，显著提高了像素级准确性和边界分割质量，尤其在复杂场景中，证明了其在计算效率和性能提升方面的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01326v1",
      "published_date": "2025-04-02 03:22:36 UTC",
      "updated_date": "2025-04-02 03:22:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:01:48.988276"
    },
    {
      "arxiv_id": "2504.01324v1",
      "title": "On Data Synthesis and Post-training for Visual Abstract Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Ke Zhu",
        "Yu Wang",
        "Jiangjiang Liu",
        "Qunyi Xie",
        "Shanshan Liu",
        "Gang Zhang"
      ],
      "abstract": "This paper is a pioneering work attempting to address abstract visual\nreasoning (AVR) problems for large vision-language models (VLMs). We make a\ncommon LLaVA-NeXT 7B model capable of perceiving and reasoning about specific\nAVR problems, surpassing both open-sourced (e.g., Qwen-2-VL-72B) and\nclosed-sourced powerful VLMs (e.g., GPT-4o) with significant margin. This is a\ngreat breakthrough since almost all previous VLMs fail or show nearly random\nperformance on representative AVR benchmarks. Our key success is our innovative\ndata synthesis and post-training process, aiming to fully relieve the task\ndifficulty and elicit the model to learn, step by step. Our 7B model is also\nshown to be behave well on AVR without sacrificing common multimodal\ncomprehension abilities. We hope our paper could serve as an early effort in\nthis area and would inspire further research in abstract visual reasoning.",
      "tldr_zh": "这篇论文探讨了通过数据合成和后训练技术提升视觉语言模型（VLMs）在抽象视觉推理（AVR）任务上的性能，成功使 LLaVA-NeXT 7B 模型超越了开源模型（如 Qwen-2-VL-72B）和闭源模型（如 GPT-4o），在相关基准上表现出显著优势。研究的关键创新在于创新的数据合成和后训练过程，帮助模型逐步学习并缓解任务难度，同时保持了其在多模态理解方面的能力。该工作作为抽象视觉推理领域的早期努力，旨在激发进一步的研究和进展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01324v1",
      "published_date": "2025-04-02 03:18:24 UTC",
      "updated_date": "2025-04-02 03:18:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:02:01.135313"
    },
    {
      "arxiv_id": "2504.01321v1",
      "title": "COST: Contrastive One-Stage Transformer for Vision-Language Small Object Tracking",
      "title_zh": "COST：用于视觉-语言小物体跟踪的对比单阶段Transformer",
      "authors": [
        "Chunhui Zhang",
        "Li Liu",
        "Jialin Gao",
        "Xin Sun",
        "Hao Wen",
        "Xi Zhou",
        "Shiming Ge",
        "Yanfeng Wang"
      ],
      "abstract": "Transformer has recently demonstrated great potential in improving\nvision-language (VL) tracking algorithms. However, most of the existing VL\ntrackers rely on carefully designed mechanisms to perform the multi-stage\nmulti-modal fusion. Additionally, direct multi-modal fusion without alignment\nignores distribution discrepancy between modalities in feature space,\npotentially leading to suboptimal representations. In this work, we propose\nCOST, a contrastive one-stage transformer fusion framework for VL tracking,\naiming to learn semantically consistent and unified VL representations.\nSpecifically, we introduce a contrastive alignment strategy that maximizes\nmutual information (MI) between a video and its corresponding language\ndescription. This enables effective cross-modal alignment, yielding\nsemantically consistent features in the representation space. By leveraging a\nvisual-linguistic transformer, we establish an efficient multi-modal fusion and\nreasoning mechanism, empirically demonstrating that a simple stack of\ntransformer encoders effectively enables unified VL representations. Moreover,\nwe contribute a newly collected VL tracking benchmark dataset for small object\ntracking, named VL-SOT500, with bounding boxes and language descriptions. Our\ndataset comprises two challenging subsets, VL-SOT230 and VL-SOT270, dedicated\nto evaluating generic and high-speed small object tracking, respectively. Small\nobject tracking is notoriously challenging due to weak appearance and limited\nfeatures, and this dataset is, to the best of our knowledge, the first to\nexplore the usage of language cues to enhance visual representation for small\nobject tracking. Extensive experiments demonstrate that COST achieves\nstate-of-the-art performance on five existing VL tracking datasets, as well as\non our proposed VL-SOT500 dataset. Source codes and dataset will be made\npublicly available.",
      "tldr_zh": "本研究提出COST，一种对比性一阶段Transformer框架，用于视觉语言(VL)小物体跟踪，旨在通过有效的跨模态对齐学习语义一致的统一VL表示。具体地，COST引入对比性对齐策略，通过最大化视频和语言描述之间的互信息(MI)，实现高效的多模态融合，并利用视觉-语言Transformer编码器堆叠来简化融合过程。该框架还贡献了一个新数据集VL-SOT500，包括VL-SOT230和VL-SOT270子集，用于评估通用和高速度小物体跟踪，这是首个探索语言线索增强小物体跟踪表示的基准。实验结果显示，COST在五个现有VL跟踪数据集以及VL-SOT500上均达到最先进性能，源代码和数据集将公开。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Preprint submitted to Elsevier.\n  https://github.com/983632847/Awesome-Multimodal-Object-Tracking",
      "pdf_url": "http://arxiv.org/pdf/2504.01321v1",
      "published_date": "2025-04-02 03:12:38 UTC",
      "updated_date": "2025-04-02 03:12:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:02:13.339238"
    },
    {
      "arxiv_id": "2504.02008v1",
      "title": "Test-time Adaptation for Foundation Medical Segmentation Model without Parametric Updates",
      "title_zh": "翻译失败",
      "authors": [
        "Kecheng Chen",
        "Xinyu Luo",
        "Tiexin Qin",
        "Jie Liu",
        "Hui Liu",
        "Victor Ho Fun Lee",
        "Hong Yan",
        "Haoliang Li"
      ],
      "abstract": "Foundation medical segmentation models, with MedSAM being the most popular,\nhave achieved promising performance across organs and lesions. However, MedSAM\nstill suffers from compromised performance on specific lesions with intricate\nstructures and appearance, as well as bounding box prompt-induced\nperturbations. Although current test-time adaptation (TTA) methods for medical\nimage segmentation may tackle this issue, partial (e.g., batch normalization)\nor whole parametric updates restrict their effectiveness due to limited update\nsignals or catastrophic forgetting in large models. Meanwhile, these approaches\nignore the computational complexity during adaptation, which is particularly\nsignificant for modern foundation models. To this end, our theoretical analyses\nreveal that directly refining image embeddings is feasible to approach the same\ngoal as parametric updates under the MedSAM architecture, which enables us to\nrealize high computational efficiency and segmentation performance without the\nrisk of catastrophic forgetting. Under this framework, we propose to encourage\nmaximizing factorized conditional probabilities of the posterior prediction\nprobability using a proposed distribution-approximated latent conditional\nrandom field loss combined with an entropy minimization loss. Experiments show\nthat we achieve about 3\\% Dice score improvements across three datasets while\nreducing computational complexity by over 7 times.",
      "tldr_zh": "这篇论文针对基础医疗分割模型（如 MedSAM）的性能问题，提出了一种无需参数更新的测试时适应 (TTA) 方法，以解决复杂病变结构和边界框提示干扰导致的准确率下降。作者通过理论分析发现，直接优化图像嵌入可以替代传统参数更新，从而避免灾难性遗忘并显著降低计算复杂性；具体方法包括使用分布逼近的潜在条件随机场损失和熵最小化损失来最大化因子化条件概率。实验结果显示，该方法在三个数据集上提升了约 3% 的 Dice 分数，同时将计算复杂性降低了 7 倍以上。",
      "categories": [
        "q-bio.QM",
        "cs.AI"
      ],
      "primary_category": "q-bio.QM",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2504.02008v1",
      "published_date": "2025-04-02 03:03:34 UTC",
      "updated_date": "2025-04-02 03:03:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:02:25.268249"
    },
    {
      "arxiv_id": "2504.01317v1",
      "title": "Adaptive Rectification Sampling for Test-Time Compute Scaling",
      "title_zh": "针对测试时计算缩放的适应性修正采样",
      "authors": [
        "Zhendong Tan",
        "Xingjun Zhang",
        "Chaoyi Hu",
        "Yancheng Pan",
        "Shaoxun Wang"
      ],
      "abstract": "The newly released OpenAI-o1 and DeepSeek-R1 have demonstrated that test-time\nscaling can significantly improve model performance, especially in complex\ntasks such as logical reasoning. Common test-time scaling methods involve\ngenerating more chain of thoughts (CoTs) or longer CoTs with self-correction.\nHowever, while self-correction can improve performance, it may lead to\nsignificant token waste and reduce readability of the CoT if the reasoning\nsteps are already correct. To demonstrate that large language models (LLMs) can\nrectify errors at a more fine-grained level, we propose Adaptive Rectification\nSampling (AR-Sampling), which can guide the LLMs to self-correction at the\nappropriate step. AR-Sampling leverages a process-supervised reward model (PRM)\nas a verifier and constructed trigger sentences to guide the model in adaptive\nstep-level rethinking. Through the experiments on GSM8K and MATH500, it\nindicate that our approach enables the models to rethink in more fine-grained\nlevel, improving the accuracy of solutions, while generating a reasonable\nnumber of additional tokens.",
      "tldr_zh": "该研究探讨了测试时计算缩放（Test-Time Compute Scaling）在提升大语言模型（LLMs）性能方面的潜力，特别是针对逻辑推理任务，但指出现有方法如生成更多链式思考（CoTs）或自校正可能导致 token 浪费和可读性下降。  \n为此，作者提出 Adaptive Rectification Sampling (AR-Sampling) 方法，利用 process-supervised reward model (PRM) 作为验证器和构建的触发句子，引导模型在适当的推理步骤进行细粒度自校正。  \n实验结果显示，在 GSM8K 和 MATH500 数据集上，该方法显著提高了解决方案准确性，同时仅生成了合理的额外 tokens。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01317v1",
      "published_date": "2025-04-02 02:57:52 UTC",
      "updated_date": "2025-04-02 02:57:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:02:37.360767"
    },
    {
      "arxiv_id": "2504.01309v1",
      "title": "Biomedical Question Answering via Multi-Level Summarization on a Local Knowledge Graph",
      "title_zh": "翻译失败",
      "authors": [
        "Lingxiao Guan",
        "Yuanhao Huang",
        "Jie Liu"
      ],
      "abstract": "In Question Answering (QA), Retrieval Augmented Generation (RAG) has\nrevolutionized performance in various domains. However, how to effectively\ncapture multi-document relationships, particularly critical for biomedical\ntasks, remains an open question. In this work, we propose a novel method that\nutilizes propositional claims to construct a local knowledge graph from\nretrieved documents. Summaries are then derived via layerwise summarization\nfrom the knowledge graph to contextualize a small language model to perform QA.\nWe achieved comparable or superior performance with our method over RAG\nbaselines on several biomedical QA benchmarks. We also evaluated each\nindividual step of our methodology over a targeted set of metrics,\ndemonstrating its effectiveness.",
      "tldr_zh": "本研究针对生物医学问答(QA)领域的挑战，提出了一种新方法，通过使用命题声明(propositional claims)从检索文档构建本地知识图(local knowledge graph)，以有效捕捉多文档关系。方法涉及层级式总结(layerwise summarization)从知识图中派生摘要，并以此上下文化小型语言模型进行QA。实验结果显示，该方法在多个生物医学QA基准上达到了与Retrieval Augmented Generation (RAG)基线相当或优越的性能，并通过针对性指标评估了每个步骤的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01309v1",
      "published_date": "2025-04-02 02:40:19 UTC",
      "updated_date": "2025-04-02 02:40:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:02:47.977986"
    },
    {
      "arxiv_id": "2504.01301v1",
      "title": "Bi-LAT: Bilateral Control-Based Imitation Learning via Natural Language and Action Chunking with Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Takumi Kobayashi",
        "Masato Kobayashi",
        "Thanpimon Buamanee",
        "Yuki Uranishi"
      ],
      "abstract": "We present Bi-LAT, a novel imitation learning framework that unifies\nbilateral control with natural language processing to achieve precise force\nmodulation in robotic manipulation. Bi-LAT leverages joint position, velocity,\nand torque data from leader-follower teleoperation while also integrating\nvisual and linguistic cues to dynamically adjust applied force. By encoding\nhuman instructions such as \"softly grasp the cup\" or \"strongly twist the\nsponge\" through a multimodal Transformer-based model, Bi-LAT learns to\ndistinguish nuanced force requirements in real-world tasks. We demonstrate\nBi-LAT's performance in (1) unimanual cup-stacking scenario where the robot\naccurately modulates grasp force based on language commands, and (2) bimanual\nsponge-twisting task that requires coordinated force control. Experimental\nresults show that Bi-LAT effectively reproduces the instructed force levels,\nparticularly when incorporating SigLIP among tested language encoders. Our\nfindings demonstrate the potential of integrating natural language cues into\nimitation learning, paving the way for more intuitive and adaptive human-robot\ninteraction. For additional material, please visit:\nhttps://mertcookimg.github.io/bi-lat/",
      "tldr_zh": "该研究提出 Bi-LAT，一种基于双边控制(Bilateral Control)的模仿学习框架，通过整合自然语言处理和动作分块(Action Chunking)与 Transformers 模型，实现机器人操作中的精确力调节(force modulation)。框架利用遥操作中的关节位置、速度和扭矩数据，以及视觉和语言线索（如“softly grasp the cup”），通过多模态 Transformer 模型动态调整力应用，以区分细微的任务需求。在实验中，Bi-LAT 在单臂杯子堆叠和双臂海绵扭转任务中表现出色，特别是使用 SigLIP 编码器时，能有效再现指令力水平，从而提升了人类-机器人交互的直观性和适应性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01301v1",
      "published_date": "2025-04-02 02:21:30 UTC",
      "updated_date": "2025-04-02 02:21:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:03:01.603665"
    },
    {
      "arxiv_id": "2504.01281v3",
      "title": "Scaling Test-Time Inference with Policy-Optimized, Dynamic Retrieval-Augmented Generation via KV Caching and Decoding",
      "title_zh": "翻译失败",
      "authors": [
        "Sakhinana Sagar Srinivas",
        "Akash Das",
        "Shivam Gupta",
        "Venkataramana Runkana"
      ],
      "abstract": "We present a comprehensive framework for enhancing Retrieval-Augmented\nGeneration (RAG) systems through dynamic retrieval strategies and reinforcement\nfine-tuning. This approach significantly improves large language models on\nknowledge-intensive tasks, including opendomain question answering and complex\nreasoning. Our framework integrates two complementary techniques:\nPolicy-Optimized RetrievalAugmented Generation (PORAG), which optimizes the use\nof retrieved information, and Adaptive Token-Layer Attention Scoring (ATLAS),\nwhich dynamically determines retrieval timing and content based on contextual\nneeds. Together, these techniques enhance both the utilization and relevance of\nretrieved content, improving factual accuracy and response quality. Designed as\na lightweight solution compatible with any Transformer-based LLM without\nrequiring additional training, our framework excels in knowledge-intensive\ntasks, boosting output accuracy in RAG settings. We further propose CRITIC, a\nnovel method to selectively compress key-value caches by token importance,\nmitigating memory bottlenecks in long-context applications. The framework also\nincorporates test-time scaling techniques to dynamically balance reasoning\ndepth and computational resources, alongside optimized decoding strategies for\nfaster inference. Experiments on benchmark datasets show that our framework\nreduces hallucinations, strengthens domain-specific reasoning, and achieves\nsignificant efficiency and scalability gains over traditional RAG systems. This\nintegrated approach advances the development of robust, efficient, and scalable\nRAG systems across diverse applications.",
      "tldr_zh": "本研究提出一个全面框架，用于通过动态检索策略和强化微调增强 Retrieval-Augmented Generation (RAG) 系统，从而提升大型语言模型在知识密集型任务（如开放域问答和复杂推理）上的性能。框架整合了 Policy-Optimized Retrieval-Augmented Generation (PORAG) 来优化检索信息的利用，以及 Adaptive Token-Layer Attention Scoring (ATLAS) 来根据上下文动态决定检索时机和内容；此外，还引入 CRITIC 方法选择性地压缩 key-value 缓存，以缓解内存瓶颈，并采用测试时缩放技术和优化解码策略平衡推理深度与计算资源。实验在基准数据集上表明，该框架显著减少了幻觉、加强了领域特定推理，并实现了比传统 RAG 系统更高的效率和可扩展性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01281v3",
      "published_date": "2025-04-02 01:16:10 UTC",
      "updated_date": "2025-05-20 04:52:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:03:13.952497"
    },
    {
      "arxiv_id": "2504.01278v1",
      "title": "Strategize Globally, Adapt Locally: A Multi-Turn Red Teaming Agent with Dual-Level Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Si Chen",
        "Xiao Yu",
        "Ninareh Mehrabi",
        "Rahul Gupta",
        "Zhou Yu",
        "Ruoxi Jia"
      ],
      "abstract": "The exploitation of large language models (LLMs) for malicious purposes poses\nsignificant security risks as these models become more powerful and widespread.\nWhile most existing red-teaming frameworks focus on single-turn attacks,\nreal-world adversaries typically operate in multi-turn scenarios, iteratively\nprobing for vulnerabilities and adapting their prompts based on threat model\nresponses. In this paper, we propose \\AlgName, a novel multi-turn red-teaming\nagent that emulates sophisticated human attackers through complementary\nlearning dimensions: global tactic-wise learning that accumulates knowledge\nover time and generalizes to new attack goals, and local prompt-wise learning\nthat refines implementations for specific goals when initial attempts fail.\nUnlike previous multi-turn approaches that rely on fixed strategy sets,\n\\AlgName enables the agent to identify new jailbreak tactics, develop a\ngoal-based tactic selection framework, and refine prompt formulations for\nselected tactics. Empirical evaluations on JailbreakBench demonstrate our\nframework's superior performance, achieving over 90\\% attack success rates\nagainst GPT-3.5-Turbo and Llama-3.1-70B within 5 conversation turns,\noutperforming state-of-the-art baselines. These results highlight the\neffectiveness of dynamic learning in identifying and exploiting model\nvulnerabilities in realistic multi-turn scenarios.",
      "tldr_zh": "该论文提出了一种名为\\AlgName的多轮红队代理，用于模拟复杂的人类攻击者，解决大型语言模型(LLMs)面临的安全风险问题。该代理采用双重学习机制，包括全局策略学习（积累知识并泛化到新攻击目标）和局部提示学习（针对特定目标优化提示），从而超越传统依赖固定策略的框架，能动态识别新越狱策略、选择基于目标的策略并改进提示。实验在JailbreakBench上显示，\\AlgName在5轮对话内对GPT-3.5-Turbo和Llama-3.1-70B的攻击成功率超过90%，显著优于现有基线，证明了动态学习在多轮场景中识别和利用模型漏洞的有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01278v1",
      "published_date": "2025-04-02 01:06:19 UTC",
      "updated_date": "2025-04-02 01:06:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:03:25.546120"
    },
    {
      "arxiv_id": "2504.03752v1",
      "title": "Proof of Humanity: A Multi-Layer Network Framework for Certifying Human-Originated Content in an AI-Dominated Internet",
      "title_zh": "人性证明：一种多层网络框架，用于在人工智能主导的互联网中认证人类原创内容",
      "authors": [
        "Sebastian Barros"
      ],
      "abstract": "The rapid proliferation of generative AI has led to an internet increasingly\npopulated with synthetic content-text, images, audio, and video generated\nwithout human intervention. As the distinction between human and AI-generated\ndata blurs, the ability to verify content origin becomes critical for\napplications ranging from social media and journalism to legal and financial\nsystems.\n  In this paper, we propose a conceptual, multi-layer architectural framework\nthat enables telecommunications networks to act as infrastructure level\ncertifiers of human-originated content. By leveraging identity anchoring at the\nphysical layer, metadata propagation at the network and transport layers, and\ncryptographic attestations at the session and application layers, Telcos can\nprovide an end-to-end Proof of Humanity for data traversing their networks.\n  We outline how each OSI layer can contribute to this trust fabric using\ntechnical primitives such as SIM/eSIM identity, digital signatures,\nbehavior-based ML heuristics, and edge-validated APIs. The framework is\npresented as a foundation for future implementation, highlighting monetization\npathways for telcos such as trust-as-a-service APIs, origin-certified traffic\ntiers, and regulatory compliance tools.\n  The paper does not present implementation or benchmarking results but offers\na technically detailed roadmap and strategic rationale for transforming Telcos\ninto validators of digital authenticity in an AI-dominated internet. Security,\nprivacy, and adversarial considerations are discussed as directions for future\nwork.",
      "tldr_zh": "本论文提出“Proof of Humanity”框架，这是一个多层网络架构，旨在帮助电信网络（Telcos）认证互联网中人类生成的内容，以应对 generative AI 导致的合成内容泛滥问题。框架利用 OSI 模型的各层，包括物理层的身份 anchoring（如 SIM/eSIM）、网络和传输层的元数据 propagation，以及会话和应用层的 cryptographic attestations 和 behavior-based ML heuristics，实现端到端的人类内容证明。论文详细阐述了技术原语和实施路线图，并探讨了 Telcos 的货币化机会，如 trust-as-a-service APIs 和 origin-certified traffic tiers，同时强调了安全、隐私和对抗性考虑作为未来工作方向。总的来说，该框架为在 AI 主导的互联网中维护数字真实性提供了战略基础，但未包括实际实施或基准测试结果。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "34 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.03752v1",
      "published_date": "2025-04-02 00:02:51 UTC",
      "updated_date": "2025-04-02 00:02:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:03:37.682047"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 122,
  "processed_papers_count": 122,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-24T09:03:57.850495"
}