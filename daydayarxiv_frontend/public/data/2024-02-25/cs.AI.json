{
  "date": "2024-02-25",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-02-25 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 45 篇论文，主要聚焦于 AI 和机器学习领域，包括大型语言模型（LLM）的优化与应用、机器人视觉与生成模型，以及隐私保护等话题；令人印象深刻的是 ChatMusician（音乐生成 LLM）和 GenNBV（3D 重建强化学习），此外还有多名知名学者参与的论文，如涉及 ACL 2024 和 CVPR 2024 的工作。\n\n### 重点论文讨论\n我们先聊聊那些创新性强、可能引发话题的论文，尤其是 LLM 和 AI 应用领域，其余次要论文会简要掠过。\n\n**LLM 优化与应用**  \n- **ChatMusician: Understanding and Generating Music Intrinsically with LLM**（ChatMusician: 使用 LLM 内在理解和生成音乐）  \n  这篇论文由多位学者如 Emmanouil Benetos 和 Gus Xia 合作，提出一种基于 LLaMA2 的 LLM 框架，能直接处理音乐（用 ABC 符号表示），实现文本、和弦与音乐生成，显著提升了音乐理解基准（如 MusicTheoryBench），并开源了数据集和模型，展示了 LLM 在创意领域的潜力。\n\n- **InstructEdit: Instruction-based Knowledge Editing for Large Language Models**（InstructEdit: 基于指令的 LLM 知识编辑）  \n  作者包括 Ningyu Zhang 和 Huajun Chen，开发了一个无需额外训练的指令驱动编辑框架，能同时处理多任务知识编辑，提高了 LLM 的可靠性（Reliability 提升 14.86%），并在 IJCAI 2024 中被接受；这为 LLM 知识更新提供了高效方法。\n\n- **DrAttack: Prompt Decomposition and Reconstruction Makes Powerful LLM Jailbreakers**（DrAttack: 提示分解和重构增强 LLM 越狱攻击）  \n  论文引入提示分解策略，将恶意提示拆分成子提示后重构，显著提高了 LLM 越狱成功率（如 GPT-4 上提升 33.1%），并开源代码；这揭示了 LLM 安全漏洞，提醒开发者关注提示工程的安全性。\n\n- **UrbanGPT: Spatio-Temporal Large Language Models**（UrbanGPT: 时空大型语言模型）  \n  这篇被 KDD 2024 接受的论文，提出 UrbanGPT 框架，将 LLM 应用于时空预测（如城市交通），通过指令微调在数据稀缺场景下表现出色，超越基线模型；它展示了 LLM 在泛化时空任务中的潜力。\n\n**机器人与视觉应用**  \n- **GenNBV: Generalizable Next-Best-View Policy for Active 3D Reconstruction**（GenNBV: 泛化下一最佳视角策略用于主动 3D 重建）  \n  CVPR 2024 接受论文，作者如 Jiangmiao Pang 提出基于强化学习的 GenNBV 框架，支持 5D 自由空间扫描，实现高覆盖率（如 98.26%），并开源项目；这在机器人 3D 重建中提供了高效泛化方法。\n\n- **How Can LLM Guide RL? A Value-Based Approach**（LLM 如何指导强化学习？基于价值的方法）  \n  论文探索 LLM 与强化学习（RL）的结合，提出 LINVIT 算法，使用 LLM 作为正则化因子，提高 RL 的样本效率（如在 ALFWorld 等环境中提升成功率），并开源代码；这为 LLM 在决策任务中的应用提供了新路径。\n\n**隐私与安全**  \n- **RAM-EHR: Retrieval Augmentation Meets Clinical Predictions on Electronic Health Records**（RAM-EHR: 检索增强用于电子健康记录的临床预测）  \n  ACL 2024 Oral 论文，作者包括 Carl Yang，引入检索增强管道改善 EHR 预测，AUROC 提升 3.4%，AUPR 提升 7.2%；这在医疗 AI 中突出了知识总结的重要性。\n\n其他论文如那些聚焦特定数据集或理论分析的（如情感分类、密码学），贡献较窄，我们快速掠过：例如，**State-of-the-Art Approaches to Enhancing Privacy Preservation of Machine Learning Datasets**（最新方法提升机器学习数据集的隐私保护）调研了差分隐私等技术，但未有突破性创新；**PIDformer: Transformer Meets Control Theory**（PIDformer: Transformer 遇上控制理论）将控制理论融入 Transformer，提高了模型鲁棒性，但实验范围有限。\n\n总之，今天的论文突显了 LLM 在音乐、知识编辑和时空预测的创新应用，以及机器人领域的强化学习进展；感兴趣的读者可关注这些开源项目，进一步探索。保持对 AI 安全和泛化的关注，是未来研究的关键。",
  "papers": [
    {
      "arxiv_id": "2403.00815v3",
      "title": "RAM-EHR: Retrieval Augmentation Meets Clinical Predictions on Electronic Health Records",
      "title_zh": "翻译失败",
      "authors": [
        "Ran Xu",
        "Wenqi Shi",
        "Yue Yu",
        "Yuchen Zhuang",
        "Bowen Jin",
        "May D. Wang",
        "Joyce C. Ho",
        "Carl Yang"
      ],
      "abstract": "We present RAM-EHR, a Retrieval AugMentation pipeline to improve clinical\npredictions on Electronic Health Records (EHRs). RAM-EHR first collects\nmultiple knowledge sources, converts them into text format, and uses dense\nretrieval to obtain information related to medical concepts. This strategy\naddresses the difficulties associated with complex names for the concepts.\nRAM-EHR then augments the local EHR predictive model co-trained with\nconsistency regularization to capture complementary information from patient\nvisits and summarized knowledge. Experiments on two EHR datasets show the\nefficacy of RAM-EHR over previous knowledge-enhanced baselines (3.4% gain in\nAUROC and 7.2% gain in AUPR), emphasizing the effectiveness of the summarized\nknowledge from RAM-EHR for clinical prediction tasks. The code will be\npublished at \\url{https://github.com/ritaranx/RAM-EHR}.",
      "tldr_zh": "我们提出了 RAM-EHR，一种检索增强(Retrieval Augmentation)管道，用于提升电子健康记录(EHRs)上的临床预测。该方法首先收集多种知识来源，将其转换为文本格式，并使用 dense retrieval 获取与医疗概念相关的补充信息，以处理复杂概念名称的挑战。随后，通过与 consistency regularization 共同训练的本地 EHR 模型，捕捉患者就诊数据和总结知识的互补信息。在两个 EHR 数据集的实验中，RAM-EHR 比现有知识增强基线提高了 3.4% 的 AUROC 和 7.2% 的 AUPR，展示了其在临床预测任务中的有效性。代码已在 GitHub 上发布。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "q-bio.OT"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL 2024 (Oral)",
      "pdf_url": "http://arxiv.org/pdf/2403.00815v3",
      "published_date": "2024-02-25 23:10:20 UTC",
      "updated_date": "2024-07-26 23:24:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:51:36.109024"
    },
    {
      "arxiv_id": "2402.16200v2",
      "title": "IR2: Information Regularization for Information Retrieval",
      "title_zh": "IR2：信息正则化用于信息检索",
      "authors": [
        "Jianyou Wang",
        "Kaicheng Wang",
        "Xiaoyue Wang",
        "Weili Cao",
        "Ramamohan Paturi",
        "Leon Bergen"
      ],
      "abstract": "Effective information retrieval (IR) in settings with limited training data,\nparticularly for complex queries, remains a challenging task. This paper\nintroduces IR2, Information Regularization for Information Retrieval, a\ntechnique for reducing overfitting during synthetic data generation. This\napproach, representing a novel application of regularization techniques in\nsynthetic data creation for IR, is tested on three recent IR tasks\ncharacterized by complex queries: DORIS-MAE, ArguAna, and WhatsThatBook.\nExperimental results indicate that our regularization techniques not only\noutperform previous synthetic query generation methods on the tasks considered\nbut also reduce cost by up to 50%. Furthermore, this paper categorizes and\nexplores three regularization methods at different stages of the query\nsynthesis pipeline-input, prompt, and output-each offering varying degrees of\nperformance improvement compared to models where no regularization is applied.\nThis provides a systematic approach for optimizing synthetic data generation in\ndata-limited, complex-query IR scenarios. All code, prompts and synthetic data\nare available at\nhttps://github.com/Info-Regularization/Information-Regularization.",
      "tldr_zh": "本研究提出 IR2（Information Regularization for Information Retrieval），一种信息正则化技术，用于减少合成数据生成过程中的过拟合问题，从而提升数据有限的复杂查询场景下的信息检索（IR）性能。IR2 探索了三种正则化方法，分别应用于查询合成管道的输入、提示和输出阶段，这些方法相对于无正则化模型提供了显著的性能提升，并在 DORIS-MAE、ArguAna 和 WhatsThatBook 等三个 IR 任务上超越了现有合成查询生成方法，同时降低了成本高达 50%。这项工作为优化合成数据生成提供了系统性方法，并公开了所有代码、提示和合成数据以促进进一步研究。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted by LREC-COLING 2024 - The 2024 Joint International\n  Conference on Computational Linguistics, Language Resources and Evaluation",
      "pdf_url": "http://arxiv.org/pdf/2402.16200v2",
      "published_date": "2024-02-25 21:25:06 UTC",
      "updated_date": "2025-04-01 20:20:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:51:46.085941"
    },
    {
      "arxiv_id": "2402.16189v1",
      "title": "One-stage Prompt-based Continual Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Youngeun Kim",
        "Yuhang Li",
        "Priyadarshini Panda"
      ],
      "abstract": "Prompt-based Continual Learning (PCL) has gained considerable attention as a\npromising continual learning solution as it achieves state-of-the-art\nperformance while preventing privacy violation and memory overhead issues.\nNonetheless, existing PCL approaches face significant computational burdens\nbecause of two Vision Transformer (ViT) feed-forward stages; one is for the\nquery ViT that generates a prompt query to select prompts inside a prompt pool;\nthe other one is a backbone ViT that mixes information between selected prompts\nand image tokens. To address this, we introduce a one-stage PCL framework by\ndirectly using the intermediate layer's token embedding as a prompt query. This\ndesign removes the need for an additional feed-forward stage for query ViT,\nresulting in ~50% computational cost reduction for both training and inference\nwith marginal accuracy drop < 1%. We further introduce a Query-Pool\nRegularization (QR) loss that regulates the relationship between the prompt\nquery and the prompt pool to improve representation power. The QR loss is only\napplied during training time, so there is no computational overhead at\ninference from the QR loss. With the QR loss, our approach maintains ~ 50%\ncomputational cost reduction during inference as well as outperforms the prior\ntwo-stage PCL methods by ~1.4% on public class-incremental continual learning\nbenchmarks including CIFAR-100, ImageNet-R, and DomainNet.",
      "tldr_zh": "该论文针对Prompt-based Continual Learning (PCL)方法中存在的两个Vision Transformer (ViT)前向阶段导致的计算负担问题，提出了一种one-stage PCL框架，通过直接使用中间层的token embedding作为prompt query，实现了训练和推理计算成本约50%的减少，同时准确率仅下降不到1%。为了提升表示能力，论文引入Query-Pool Regularization (QR) loss来调节prompt query与prompt pool的关系，该损失仅在训练时应用，不会增加推理开销。实验结果显示，该框架在CIFAR-100、ImageNet-R和DomainNet等类增量持续学习基准上，比现有two-stage PCL方法提高了约1.4%的性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16189v1",
      "published_date": "2024-02-25 20:30:05 UTC",
      "updated_date": "2024-02-25 20:30:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:52:00.061116"
    },
    {
      "arxiv_id": "2402.16181v1",
      "title": "How Can LLM Guide RL? A Value-Based Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Shenao Zhang",
        "Sirui Zheng",
        "Shuqi Ke",
        "Zhihan Liu",
        "Wanxin Jin",
        "Jianbo Yuan",
        "Yingxiang Yang",
        "Hongxia Yang",
        "Zhaoran Wang"
      ],
      "abstract": "Reinforcement learning (RL) has become the de facto standard practice for\nsequential decision-making problems by improving future acting policies with\nfeedback. However, RL algorithms may require extensive trial-and-error\ninteractions to collect useful feedback for improvement. On the other hand,\nrecent developments in large language models (LLMs) have showcased impressive\ncapabilities in language understanding and generation, yet they fall short in\nexploration and self-improvement capabilities for planning tasks, lacking the\nability to autonomously refine their responses based on feedback. Therefore, in\nthis paper, we study how the policy prior provided by the LLM can enhance the\nsample efficiency of RL algorithms. Specifically, we develop an algorithm named\nLINVIT that incorporates LLM guidance as a regularization factor in value-based\nRL, leading to significant reductions in the amount of data needed for\nlearning, particularly when the difference between the ideal policy and the\nLLM-informed policy is small, which suggests that the initial policy is close\nto optimal, reducing the need for further exploration. Additionally, we present\na practical algorithm SLINVIT that simplifies the construction of the value\nfunction and employs subgoals to reduce the search complexity. Our experiments\nacross three interactive environments ALFWorld, InterCode, and BlocksWorld\ndemonstrate that our method achieves state-of-the-art success rates and also\nsurpasses previous RL and LLM approaches in terms of sample efficiency. Our\ncode is available at https://github.com/agentification/Language-Integrated-VI.",
      "tldr_zh": "这篇论文探讨如何利用大语言模型 (LLMs) 指导强化学习 (RL) 以提升其样本效率，针对 RL 的试错交互问题。作者提出 LINVIT 算法，将 LLM 的策略先验作为正则化因子融入基于价值的 RL 中，显著减少数据需求，尤其当 LLM 策略接近最优时。另一个算法 SLINVIT 则简化价值函数构建并引入子目标，以降低搜索复杂度。在 ALFWorld、InterCode 和 BlocksWorld 等环境中，实验结果显示该方法实现了最先进的成功率，并超越了现有 RL 和 LLM 方法的样本效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16181v1",
      "published_date": "2024-02-25 20:07:13 UTC",
      "updated_date": "2024-02-25 20:07:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:52:10.239267"
    },
    {
      "arxiv_id": "2402.16174v3",
      "title": "GenNBV: Generalizable Next-Best-View Policy for Active 3D Reconstruction",
      "title_zh": "翻译失败",
      "authors": [
        "Xiao Chen",
        "Quanyi Li",
        "Tai Wang",
        "Tianfan Xue",
        "Jiangmiao Pang"
      ],
      "abstract": "While recent advances in neural radiance field enable realistic digitization\nfor large-scale scenes, the image-capturing process is still time-consuming and\nlabor-intensive. Previous works attempt to automate this process using the\nNext-Best-View (NBV) policy for active 3D reconstruction. However, the existing\nNBV policies heavily rely on hand-crafted criteria, limited action space, or\nper-scene optimized representations. These constraints limit their\ncross-dataset generalizability. To overcome them, we propose GenNBV, an\nend-to-end generalizable NBV policy. Our policy adopts a reinforcement learning\n(RL)-based framework and extends typical limited action space to 5D free space.\nIt empowers our agent drone to scan from any viewpoint, and even interact with\nunseen geometries during training. To boost the cross-dataset generalizability,\nwe also propose a novel multi-source state embedding, including geometric,\nsemantic, and action representations. We establish a benchmark using the Isaac\nGym simulator with the Houses3K and OmniObject3D datasets to evaluate this NBV\npolicy. Experiments demonstrate that our policy achieves a 98.26% and 97.12%\ncoverage ratio on unseen building-scale objects from these datasets,\nrespectively, outperforming prior solutions.",
      "tldr_zh": "本研究针对神经辐射场（neural radiance field）在大型场景数字化中的图像捕获问题，提出了一种可泛化的 Next-Best-View (NBV) 政策，名为 GenNBV，以自动化主动 3D 重建过程。GenNBV 采用强化学习 (RL) 框架，将动作空间扩展到 5D 自由空间，允许代理无人机从任意视角扫描并处理未见几何体，同时引入多源状态嵌入（包括几何、语义和动作表示）来提升跨数据集泛化能力。实验在 Isaac Gym 模拟器上使用 Houses3K 和 OmniObject3D 数据集进行基准测试，结果显示 GenNBV 在未见对象上分别实现了 98.26% 和 97.12% 的覆盖率，优于现有方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2024 accepted paper. Project page: http://gennbv.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2402.16174v3",
      "published_date": "2024-02-25 18:59:29 UTC",
      "updated_date": "2024-07-30 06:05:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:52:23.317883"
    },
    {
      "arxiv_id": "2402.16173v1",
      "title": "Communication Traffic Characteristics Reveal an IoT Devices Identity",
      "title_zh": "通信流量特征揭示物联网设备的身份",
      "authors": [
        "Rajarshi Roy Chowdhury",
        "Debashish Roy",
        "Pg Emeroylariffion Abas"
      ],
      "abstract": "Internet of Things (IoT) is one of the technological advancements of the\ntwenty-first century which can improve living standards. However, it also\nimposes new types of security challenges, including device authentication,\ntraffic types classification, and malicious traffic identification, in the\nnetwork domain. Traditionally, internet protocol (IP) and media access control\n(MAC) addresses are utilized for identifying network-connected devices in a\nnetwork, whilst these addressing schemes are prone to be compromised, including\nspoofing attacks and MAC randomization. Therefore, device identification using\nonly explicit identifiers is a challenging task. Accurate device identification\nplays a key role in securing a network. In this paper, a supervised machine\nlearning-based device fingerprinting (DFP) model has been proposed for\nidentifying network-connected IoT devices using only communication traffic\ncharacteristics (or implicit identifiers). A single transmission control\nprotocol/internet protocol (TCP/IP) packet header features have been utilized\nfor generating unique fingerprints, with the fingerprints represented as a\nvector of 22 features. Experimental results have shown that the proposed DFP\nmethod achieves over 98% in classifying individual IoT devices using the UNSW\ndataset with 22 smart-home IoT devices. This signifies that the proposed\napproach is invaluable to network operators in making their networks more\nsecure.",
      "tldr_zh": "该论文探讨了IoT设备的身份识别问题，指出传统使用IP和MAC地址的方法易受欺骗攻击和MAC随机化影响。研究提出了一种基于监督机器学习的设备指纹识别(DFP)模型，仅利用通信流量特征（如单个TCP/IP数据包头部的22个特征）生成独特指纹，以准确分类IoT设备。实验结果显示，在UNSW数据集上，该方法对22个智能家居IoT设备的分类准确率超过98%，为网络运营商增强网络安全提供了宝贵工具。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "F.2.2; I.2.7"
      ],
      "primary_category": "cs.NI",
      "comment": "16 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.16173v1",
      "published_date": "2024-02-25 18:58:09 UTC",
      "updated_date": "2024-02-25 18:58:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:52:34.388907"
    },
    {
      "arxiv_id": "2402.16168v1",
      "title": "Hitting \"Probe\"rty with Non-Linearity, and More",
      "title_zh": "翻译失败",
      "authors": [
        "Avik Pal",
        "Madhura Pawar"
      ],
      "abstract": "Structural probes learn a linear transformation to find how dependency trees\nare embedded in the hidden states of language models. This simple design may\nnot allow for full exploitation of the structure of the encoded information.\nHence, to investigate the structure of the encoded information to its full\nextent, we incorporate non-linear structural probes. We reformulate the design\nof non-linear structural probes introduced by White et al. making its design\nsimpler yet effective. We also design a visualization framework that lets us\nqualitatively assess how strongly two words in a sentence are connected in the\npredicted dependency tree. We use this technique to understand which non-linear\nprobe variant is good at encoding syntactical information. Additionally, we\nalso use it to qualitatively investigate the structure of dependency trees that\nBERT encodes in each of its layers. We find that the radial basis function\n(RBF) is an effective non-linear probe for the BERT model than the linear\nprobe.",
      "tldr_zh": "本研究探讨了结构探针（structural probes）在语言模型中提取依赖树结构时存在的局限性，提出了一种改进的非线性结构探针设计，以更好地利用编码信息。作者简化了White et al.的非线性探针框架，并开发了一个可视化工具，用于定性评估句子中词语在预测依赖树中的连接强度，从而比较不同探针变体的句法编码效果。在实验中，他们发现径向基函数（RBF）作为非线性探针在BERT模型中比线性探针更有效，揭示了语言模型隐藏状态中更丰富的结构信息。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16168v1",
      "published_date": "2024-02-25 18:33:25 UTC",
      "updated_date": "2024-02-25 18:33:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:52:46.390000"
    },
    {
      "arxiv_id": "2402.16915v1",
      "title": "More Than Routing: Joint GPS and Route Modeling for Refine Trajectory Representation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Zhipeng Ma",
        "Zheyan Tu",
        "Xinhai Chen",
        "Yan Zhang",
        "Deguo Xia",
        "Guyue Zhou",
        "Yilun Chen",
        "Yu Zheng",
        "Jiangtao Gong"
      ],
      "abstract": "Trajectory representation learning plays a pivotal role in supporting various\ndownstream tasks. Traditional methods in order to filter the noise in GPS\ntrajectories tend to focus on routing-based methods used to simplify the\ntrajectories. However, this approach ignores the motion details contained in\nthe GPS data, limiting the representation capability of trajectory\nrepresentation learning. To fill this gap, we propose a novel representation\nlearning framework that Joint GPS and Route Modelling based on self-supervised\ntechnology, namely JGRM. We consider GPS trajectory and route as the two modes\nof a single movement observation and fuse information through inter-modal\ninformation interaction. Specifically, we develop two encoders, each tailored\nto capture representations of route and GPS trajectories respectively. The\nrepresentations from the two modalities are fed into a shared transformer for\ninter-modal information interaction. Eventually, we design three\nself-supervised tasks to train the model. We validate the effectiveness of the\nproposed method on two real datasets based on extensive experiments. The\nexperimental results demonstrate that JGRM outperforms existing methods in both\nroad segment representation and trajectory representation tasks. Our source\ncode is available at Anonymous Github.",
      "tldr_zh": "传统轨迹表示学习方法往往通过路由简化过滤GPS轨迹中的噪声，但忽略了GPS数据中的运动细节，从而限制了表示能力。  \n为此，本文提出JGRM框架，使用self-supervised technology联合GPS和Route Modeling，将GPS轨迹和路由视为两种模式，通过两个专用编码器捕获各自表示，并利用共享Transformer进行互模信息交互，同时设计三个自监督任务训练模型。  \n实验结果显示，在两个真实数据集上，JGRM在路段表示和轨迹表示任务中均优于现有方法，证明了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16915v1",
      "published_date": "2024-02-25 18:27:25 UTC",
      "updated_date": "2024-02-25 18:27:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:52:58.341987"
    },
    {
      "arxiv_id": "2402.16914v3",
      "title": "DrAttack: Prompt Decomposition and Reconstruction Makes Powerful LLM Jailbreakers",
      "title_zh": "翻译失败",
      "authors": [
        "Xirui Li",
        "Ruochen Wang",
        "Minhao Cheng",
        "Tianyi Zhou",
        "Cho-Jui Hsieh"
      ],
      "abstract": "The safety alignment of Large Language Models (LLMs) is vulnerable to both\nmanual and automated jailbreak attacks, which adversarially trigger LLMs to\noutput harmful content. However, current methods for jailbreaking LLMs, which\nnest entire harmful prompts, are not effective at concealing malicious intent\nand can be easily identified and rejected by well-aligned LLMs. This paper\ndiscovers that decomposing a malicious prompt into separated sub-prompts can\neffectively obscure its underlying malicious intent by presenting it in a\nfragmented, less detectable form, thereby addressing these limitations. We\nintroduce an automatic prompt \\textbf{D}ecomposition and\n\\textbf{R}econstruction framework for jailbreak \\textbf{Attack} (DrAttack).\nDrAttack includes three key components: (a) `Decomposition' of the original\nprompt into sub-prompts, (b) `Reconstruction' of these sub-prompts implicitly\nby in-context learning with semantically similar but harmless reassembling\ndemo, and (c) a `Synonym Search' of sub-prompts, aiming to find sub-prompts'\nsynonyms that maintain the original intent while jailbreaking LLMs. An\nextensive empirical study across multiple open-source and closed-source LLMs\ndemonstrates that, with a significantly reduced number of queries, DrAttack\nobtains a substantial gain of success rate over prior SOTA prompt-only\nattackers. Notably, the success rate of 78.0\\% on GPT-4 with merely 15 queries\nsurpassed previous art by 33.1\\%. The project is available at\nhttps://github.com/xirui-li/DrAttack.",
      "tldr_zh": "该论文提出DrAttack框架，通过提示分解和重构来提升对大型语言模型(LLMs)的越狱攻击(jailbreak)效果，解决传统方法易被检测的问题。DrAttack包括三个核心组件：(a) 将恶意提示分解成子提示，(b) 通过上下文学习(In-Context Learning)重构子提示，使用语义相似的无害示例，(c) 搜索子提示的同义词以保持原意同时规避检测。实验结果显示，该框架在多个开源和闭源LLMs上显著提高了成功率，例如在GPT-4上仅用15次查询就达到78.0%的成功率，比现有最先进(prompt-only attackers)方法高出33.1%。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16914v3",
      "published_date": "2024-02-25 17:43:29 UTC",
      "updated_date": "2024-11-11 23:08:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:53:10.412805"
    },
    {
      "arxiv_id": "2404.16847v2",
      "title": "State-of-the-Art Approaches to Enhancing Privacy Preservation of Machine Learning Datasets: A Survey",
      "title_zh": "最先进的机器学习数据集隐私保护增强方法：综述",
      "authors": [
        "Chaoyu Zhang",
        "Shaoyu Li"
      ],
      "abstract": "This paper examines the evolving landscape of machine learning (ML) and its\nprofound impact across various sectors, with a special focus on the emerging\nfield of Privacy-preserving Machine Learning (PPML). As ML applications become\nincreasingly integral to industries like telecommunications, financial\ntechnology, and surveillance, they raise significant privacy concerns,\nnecessitating the development of PPML strategies. The paper highlights the\nunique challenges in safeguarding privacy within ML frameworks, which stem from\nthe diverse capabilities of potential adversaries, including their ability to\ninfer sensitive information from model outputs or training data.\n  We delve into the spectrum of threat models that characterize adversarial\nintentions, ranging from membership and attribute inference to data\nreconstruction. The paper emphasizes the importance of maintaining the\nconfidentiality and integrity of training data, outlining current research\nefforts that focus on refining training data to minimize privacy-sensitive\ninformation and enhancing data processing techniques to uphold privacy.\n  Through a comprehensive analysis of privacy leakage risks and countermeasures\nin both centralized and collaborative learning settings, this paper aims to\nprovide a thorough understanding of effective strategies for protecting ML\ntraining data against privacy intrusions. It explores the balance between data\nprivacy and model utility, shedding light on privacy-preserving techniques that\nleverage cryptographic methods, Differential Privacy, and Trusted Execution\nEnvironments. The discussion extends to the application of these techniques in\nsensitive domains, underscoring the critical role of PPML in ensuring the\nprivacy and security of ML systems.",
      "tldr_zh": "这篇论文对 Privacy-preserving Machine Learning (PPML) 的最新方法进行了全面调查，聚焦于机器学习数据集的隐私保护问题，尤其在电信、金融和监控等领域。论文分析了潜在威胁模型，如成员推断、属性推断和数据重建，并强调了保护训练数据机密性和完整性的挑战，包括在中心化和协作学习环境中的隐私泄漏风险。研究探讨了各种对策，如 Differential Privacy、加密方法和 Trusted Execution Environments，以平衡数据隐私与模型效用，并展示了这些技术在敏感领域的应用潜力。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.16847v2",
      "published_date": "2024-02-25 17:31:06 UTC",
      "updated_date": "2025-01-28 19:03:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:53:21.574638"
    },
    {
      "arxiv_id": "2402.16153v1",
      "title": "ChatMusician: Understanding and Generating Music Intrinsically with LLM",
      "title_zh": "翻译失败",
      "authors": [
        "Ruibin Yuan",
        "Hanfeng Lin",
        "Yi Wang",
        "Zeyue Tian",
        "Shangda Wu",
        "Tianhao Shen",
        "Ge Zhang",
        "Yuhang Wu",
        "Cong Liu",
        "Ziya Zhou",
        "Ziyang Ma",
        "Liumeng Xue",
        "Ziyu Wang",
        "Qin Liu",
        "Tianyu Zheng",
        "Yizhi Li",
        "Yinghao Ma",
        "Yiming Liang",
        "Xiaowei Chi",
        "Ruibo Liu",
        "Zili Wang",
        "Pengfei Li",
        "Jingcheng Wu",
        "Chenghua Lin",
        "Qifeng Liu",
        "Tao Jiang",
        "Wenhao Huang",
        "Wenhu Chen",
        "Emmanouil Benetos",
        "Jie Fu",
        "Gus Xia",
        "Roger Dannenberg",
        "Wei Xue",
        "Shiyin Kang",
        "Yike Guo"
      ],
      "abstract": "While Large Language Models (LLMs) demonstrate impressive capabilities in\ntext generation, we find that their ability has yet to be generalized to music,\nhumanity's creative language. We introduce ChatMusician, an open-source LLM\nthat integrates intrinsic musical abilities. It is based on continual\npre-training and finetuning LLaMA2 on a text-compatible music representation,\nABC notation, and the music is treated as a second language. ChatMusician can\nunderstand and generate music with a pure text tokenizer without any external\nmulti-modal neural structures or tokenizers. Interestingly, endowing musical\nabilities does not harm language abilities, even achieving a slightly higher\nMMLU score. Our model is capable of composing well-structured, full-length\nmusic, conditioned on texts, chords, melodies, motifs, musical forms, etc,\nsurpassing GPT-4 baseline. On our meticulously curated college-level music\nunderstanding benchmark, MusicTheoryBench, ChatMusician surpasses LLaMA2 and\nGPT-3.5 on zero-shot setting by a noticeable margin. Our work reveals that LLMs\ncan be an excellent compressor for music, but there remains significant\nterritory to be conquered. We release our 4B token music-language corpora\nMusicPile, the collected MusicTheoryBench, code, model and demo in GitHub.",
      "tldr_zh": "本研究引入了 ChatMusician，一种开源的 LLM（Large Language Models），旨在将音乐理解和生成能力内化到模型中，通过在 ABC notation 上对 LLaMA2 进行持续预训练和微调，将音乐视为第二语言，使用纯文本标记器而非外部多模态结构。实验结果显示，该模型不仅在文本条件（如和弦、旋律）下生成结构良好、全长音乐的表现超越 GPT-4基准，还在 MusicTheoryBench 音乐理解基准测试中零样本设置下显著优于 LLaMA2 和 GPT-3.5，同时语言能力（如 MMLU 分数）未受影响甚至略有提升。该工作证明了 LLM 可作为音乐的优秀压缩器，并发布了 4B 标记的 MusicPile 语料库、基准测试、代码和模型，以推动相关研究。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.MM",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "GitHub: https://shanghaicannon.github.io/ChatMusician/",
      "pdf_url": "http://arxiv.org/pdf/2402.16153v1",
      "published_date": "2024-02-25 17:19:41 UTC",
      "updated_date": "2024-02-25 17:19:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:53:36.028128"
    },
    {
      "arxiv_id": "2402.16142v1",
      "title": "From Text to Transformation: A Comprehensive Review of Large Language Models' Versatility",
      "title_zh": "从文本到转变：大型语言模型多功能性的全面回顾",
      "authors": [
        "Pravneet Kaur",
        "Gautam Siddharth Kashyap",
        "Ankit Kumar",
        "Md Tabrez Nafis",
        "Sandeep Kumar",
        "Vikrant Shokeen"
      ],
      "abstract": "This groundbreaking study explores the expanse of Large Language Models\n(LLMs), such as Generative Pre-Trained Transformer (GPT) and Bidirectional\nEncoder Representations from Transformers (BERT) across varied domains ranging\nfrom technology, finance, healthcare to education. Despite their established\nprowess in Natural Language Processing (NLP), these LLMs have not been\nsystematically examined for their impact on domains such as fitness, and\nholistic well-being, urban planning, climate modelling as well as disaster\nmanagement. This review paper, in addition to furnishing a comprehensive\nanalysis of the vast expanse and extent of LLMs' utility in diverse domains,\nrecognizes the research gaps and realms where the potential of LLMs is yet to\nbe harnessed. This study uncovers innovative ways in which LLMs can leave a\nmark in the fields like fitness and wellbeing, urban planning, climate\nmodelling and disaster response which could inspire future researches and\napplications in the said avenues.",
      "tldr_zh": "这篇综述论文全面审视了大型语言模型（LLMs）如 Generative Pre-Trained Transformer (GPT) 和 Bidirectional Encoder Representations from Transformers (BERT)在多样领域的应用，包括技术、金融、医疗和教育等领域。论文强调，尽管LLMs在Natural Language Processing (NLP)中表现出色，但尚未系统探讨其在健身、健康、城市规划、气候建模和灾害管理等领域的潜力。研究识别了这些领域的关键研究空白，并提出创新应用方式，以激发未来的LLMs研究和实践。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16142v1",
      "published_date": "2024-02-25 16:47:59 UTC",
      "updated_date": "2024-02-25 16:47:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:53:46.433284"
    },
    {
      "arxiv_id": "2403.03224v1",
      "title": "Reinforcement Learning Jazz Improvisation: When Music Meets Game Theory",
      "title_zh": "强化学习爵士即兴：当音乐遇见博弈论",
      "authors": [
        "Vedant Tapiavala",
        "Joshua Piesner",
        "Sourjyamoy Barman",
        "Feng Fu"
      ],
      "abstract": "Live performances of music are always charming, with the unpredictability of\nimprovisation due to the dynamic between musicians and interactions with the\naudience. Jazz improvisation is a particularly noteworthy example for further\ninvestigation from a theoretical perspective. Here, we introduce a novel\nmathematical game theory model for jazz improvisation, providing a framework\nfor studying music theory and improvisational methodologies. We use\ncomputational modeling, mainly reinforcement learning, to explore diverse\nstochastic improvisational strategies and their paired performance on\nimprovisation. We find that the most effective strategy pair is a strategy that\nreacts to the most recent payoff (Stepwise Changes) with a reinforcement\nlearning strategy limited to notes in the given chord (Chord-Following\nReinforcement Learning). Conversely, a strategy that reacts to the partner's\nlast note and attempts to harmonize with it (Harmony Prediction) strategy pair\nyields the lowest non-control payoff and highest standard deviation, indicating\nthat picking notes based on immediate reactions to the partner player can yield\ninconsistent outcomes. On average, the Chord-Following Reinforcement Learning\nstrategy demonstrates the highest mean payoff, while Harmony Prediction\nexhibits the lowest. Our work lays the foundation for promising applications\nbeyond jazz: including the use of artificial intelligence (AI) models to\nextract data from audio clips to refine musical reward systems, and training\nmachine learning (ML) models on existing jazz solos to further refine\nstrategies within the game.",
      "tldr_zh": "本研究提出了一种基于游戏理论的数学模型，用于分析爵士即兴表演，结合强化学习（Reinforcement Learning）探索各种随机即兴策略及其配对性能。研究发现，最有效的策略组合是Stepwise Changes（对最近回报反应）和Chord-Following Reinforcement Learning（限制在给定和弦的音符上的强化学习），而Harmony Prediction（对伙伴的最后一个音符反应并尝试和谐）策略则导致最低的非控制回报和最高标准差，表明即时反应可能产生不一致结果。总体上，Chord-Following Reinforcement Learning策略显示出最高的平均回报，为AI模型从音频提取数据完善音乐奖励系统，以及用ML模型训练爵士独奏改进策略提供了基础。",
      "categories": [
        "physics.soc-ph",
        "cs.AI",
        "cs.LG",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "physics.soc-ph",
      "comment": "16 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.03224v1",
      "published_date": "2024-02-25 16:46:15 UTC",
      "updated_date": "2024-02-25 16:46:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:53:57.908757"
    },
    {
      "arxiv_id": "2402.16139v3",
      "title": "What Generative Artificial Intelligence Means for Terminological Definitions",
      "title_zh": "生成式人工智能对术语定义意味着什么",
      "authors": [
        "Antonio San Martín"
      ],
      "abstract": "This paper examines the impact of Generative Artificial Intelligence (GenAI)\ntools like ChatGPT on the creation and consumption of terminological\ndefinitions. From the terminologist's point of view, the strategic use of GenAI\ntools can streamline the process of crafting definitions, reducing both time\nand effort, while potentially enhancing quality. GenAI tools enable AI-assisted\nterminography, notably post-editing terminography, where the machine produces a\ndefinition that the terminologist then corrects or refines. However, the\npotential of GenAI tools to fulfill all the terminological needs of a user,\nincluding term definitions, challenges the very existence of terminological\ndefinitions and resources as we know them. Unlike terminological definitions,\nGenAI tools can describe the knowledge activated by a term in a specific\ncontext. However, a main drawback of these tools is that their output can\ncontain errors. For this reason, users requiring reliability will likely still\nresort to terminological resources for definitions. Nevertheless, with the\ninevitable integration of AI into terminology work, the distinction between\nhuman-created and AI-created content will become increasingly blurred.",
      "tldr_zh": "本文探讨 Generative Artificial Intelligence (GenAI) 工具如 ChatGPT 对术语定义的创建和消费的影响，从术语学家的视角出发，指出这些工具可通过 AI-assisted terminography 和 post-editing terminography 简化定义过程，减少时间和努力，同时潜在提升质量。论文强调 GenAI 能根据特定上下文描述术语知识，从而挑战传统术语资源的存在，但其输出可能包含错误，导致可靠性需求的用户仍依赖人类创建的定义。最终，作者预测 AI 与术语工作的整合将模糊人类创建和 AI 创建内容的界限。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "37 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2402.16139v3",
      "published_date": "2024-02-25 16:36:51 UTC",
      "updated_date": "2024-04-19 16:13:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:54:09.753829"
    },
    {
      "arxiv_id": "2402.16132v1",
      "title": "LSTPrompt: Large Language Models as Zero-Shot Time Series Forecasters by Long-Short-Term Prompting",
      "title_zh": "翻译失败",
      "authors": [
        "Haoxin Liu",
        "Zhiyuan Zhao",
        "Jindong Wang",
        "Harshavardhan Kamarthi",
        "B. Aditya Prakash"
      ],
      "abstract": "Time-series forecasting (TSF) finds broad applications in real-world\nscenarios. Prompting off-the-shelf Large Language Models (LLMs) demonstrates\nstrong zero-shot TSF capabilities while preserving computational efficiency.\nHowever, existing prompting methods oversimplify TSF as language next-token\npredictions, overlooking its dynamic nature and lack of integration with\nstate-of-the-art prompt strategies such as Chain-of-Thought. Thus, we propose\nLSTPrompt, a novel approach for prompting LLMs in zero-shot TSF tasks.\nLSTPrompt decomposes TSF into short-term and long-term forecasting sub-tasks,\ntailoring prompts to each. LSTPrompt guides LLMs to regularly reassess\nforecasting mechanisms to enhance adaptability. Extensive evaluations\ndemonstrate consistently better performance of LSTPrompt than existing\nprompting methods, and competitive results compared to foundation TSF models.",
      "tldr_zh": "该论文提出 LSTPrompt，一种创新方法，利用 Large Language Models (LLMs) 通过长短期提示进行零样本时间序列预测 (TSF)，以解决现有提示方法忽略 TSF 的动态性和 Chain-of-Thought 等先进策略的问题。LSTPrompt 将 TSF 分解为短期和长期预测子任务，针对每个子任务定制提示，并引导 LLMs 定期重新评估预测机制以提升适应性。实验结果显示，LSTPrompt 比现有提示方法表现更优，并与基础 TSF 模型竞争，证明了其在实际应用中的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 4 figures, 3 tables, 2 page references, 2 page appendix",
      "pdf_url": "http://arxiv.org/pdf/2402.16132v1",
      "published_date": "2024-02-25 16:14:26 UTC",
      "updated_date": "2024-02-25 16:14:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:54:22.716608"
    },
    {
      "arxiv_id": "2402.16123v2",
      "title": "InstructEdit: Instruction-based Knowledge Editing for Large Language Models",
      "title_zh": "InstructEdit：基于指令的知识编辑技术用于大型语言模型",
      "authors": [
        "Ningyu Zhang",
        "Bozhong Tian",
        "Siyuan Cheng",
        "Xiaozhuan Liang",
        "Yi Hu",
        "Kouying Xue",
        "Yanjie Gou",
        "Xi Chen",
        "Huajun Chen"
      ],
      "abstract": "Knowledge editing for large language models can offer an efficient solution\nto alter a model's behavior without negatively impacting the overall\nperformance. However, the current approaches encounter issues with limited\ngeneralizability across tasks, necessitating one distinct editor for each task,\nsignificantly hindering the broader applications. To address this, we take the\nfirst step to analyze the multi-task generalization issue in knowledge editing.\nSpecifically, we develop an instruction-based editing technique, termed\nInstructEdit, which facilitates the editor's adaptation to various task\nperformances simultaneously using simple instructions. With only one unified\neditor for each LLM, we empirically demonstrate that InstructEdit can improve\nthe editor's control, leading to an average 14.86% increase in Reliability in\nmulti-task editing setting. Furthermore, experiments involving holdout unseen\ntask illustrate that InstructEdit consistently surpass previous strong\nbaselines. To further investigate the underlying mechanisms of\ninstruction-based knowledge editing, we analyze the principal components of the\nediting gradient directions, which unveils that instructions can help control\noptimization direction with stronger OOD generalization. Code and datasets are\navailable in https://github.com/zjunlp/EasyEdit.",
      "tldr_zh": "该研究指出，现有的知识编辑方法在大型语言模型(LLMs)中存在泛化性差的问题，需要为每个任务配备独立编辑器。作者提出 InstructEdit，一种基于指令的编辑技术，使用简单指令使一个统一的编辑器同时适应多种任务，实验结果显示其在多任务设置中提升了 Reliability 平均 14.86%，并在未见任务上超越了强基线。通过分析编辑梯度方向，研究发现指令能有效控制优化方向，提高 OOD 泛化能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "IJCAI 2024; the project website is at\n  https://www.zjukg.org/project/InstructEdit/",
      "pdf_url": "http://arxiv.org/pdf/2402.16123v2",
      "published_date": "2024-02-25 15:46:33 UTC",
      "updated_date": "2024-04-28 12:03:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:54:34.568443"
    },
    {
      "arxiv_id": "2402.16121v1",
      "title": "Towards Accurate Post-training Quantization for Reparameterized Models",
      "title_zh": "翻译失败",
      "authors": [
        "Luoming Zhang",
        "Yefei He",
        "Wen Fei",
        "Zhenyu Lou",
        "Weijia Wu",
        "YangWei Ying",
        "Hong Zhou"
      ],
      "abstract": "Model reparameterization is a widely accepted technique for improving\ninference speed without compromising performance. However, current\nPost-training Quantization (PTQ) methods often lead to significant accuracy\ndegradation when applied to reparameterized models. This is primarily caused by\nchannel-specific and sample-specific outliers, which appear only at specific\nsamples and channels and impact on the selection of quantization parameters. To\naddress this issue, we propose RepAPQ, a novel framework that preserves the\naccuracy of quantized reparameterization models. Different from previous\nframeworks using Mean Squared Error (MSE) as a measurement, we utilize Mean\nAbsolute Error (MAE) to mitigate the influence of outliers on quantization\nparameters. Our framework comprises two main components: Quantization\nProtecting Reparameterization and Across-block Calibration. For effective\ncalibration, Quantization Protecting Reparameterization combines multiple\nbranches into a single convolution with an affine layer. During training, the\naffine layer accelerates convergence and amplifies the output of the\nconvolution to better accommodate samples with outliers. Additionally,\nAcross-block Calibration leverages the measurement of stage output as\nsupervision to address the gradient problem introduced by MAE and enhance the\ninterlayer correlation with quantization parameters. Comprehensive experiments\ndemonstrate the effectiveness of RepAPQ across various models and tasks. Our\nframework outperforms previous methods by approximately 1\\% for 8-bit PTQ and\n2\\% for 6-bit PTQ, showcasing its superior performance. The code is available\nat \\url{https://github.com/ilur98/DLMC-QUANT}.",
      "tldr_zh": "本研究针对模型重参数化(reparameterized models)提高推理速度的优点，指出现有的Post-training Quantization (PTQ) 方法由于channel-specific和sample-specific outliers导致准确度显著下降。作者提出RepAPQ框架，使用Mean Absolute Error (MAE) 代替Mean Squared Error (MSE) 来减少outliers对量化参数的影响，该框架包括Quantization Protecting Reparameterization（将多个分支合并为单卷积并添加仿射层以加速收敛）和Across-block Calibration（利用阶段输出作为监督增强层间相关性）。实验结果显示，RepAPQ在各种模型和任务上优于现有方法，提高约1%在8-bit PTQ和2%在6-bit PTQ的性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16121v1",
      "published_date": "2024-02-25 15:42:12 UTC",
      "updated_date": "2024-02-25 15:42:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:54:47.203766"
    },
    {
      "arxiv_id": "2402.16117v1",
      "title": "RoboCodeX: Multimodal Code Generation for Robotic Behavior Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Yao Mu",
        "Junting Chen",
        "Qinglong Zhang",
        "Shoufa Chen",
        "Qiaojun Yu",
        "Chongjian Ge",
        "Runjian Chen",
        "Zhixuan Liang",
        "Mengkang Hu",
        "Chaofan Tao",
        "Peize Sun",
        "Haibao Yu",
        "Chao Yang",
        "Wenqi Shao",
        "Wenhai Wang",
        "Jifeng Dai",
        "Yu Qiao",
        "Mingyu Ding",
        "Ping Luo"
      ],
      "abstract": "Robotic behavior synthesis, the problem of understanding multimodal inputs\nand generating precise physical control for robots, is an important part of\nEmbodied AI. Despite successes in applying multimodal large language models for\nhigh-level understanding, it remains challenging to translate these conceptual\nunderstandings into detailed robotic actions while achieving generalization\nacross various scenarios. In this paper, we propose a tree-structured\nmultimodal code generation framework for generalized robotic behavior\nsynthesis, termed RoboCodeX. RoboCodeX decomposes high-level human instructions\ninto multiple object-centric manipulation units consisting of physical\npreferences such as affordance and safety constraints, and applies code\ngeneration to introduce generalization ability across various robotics\nplatforms. To further enhance the capability to map conceptual and perceptual\nunderstanding into control commands, a specialized multimodal reasoning dataset\nis collected for pre-training and an iterative self-updating methodology is\nintroduced for supervised fine-tuning. Extensive experiments demonstrate that\nRoboCodeX achieves state-of-the-art performance in both simulators and real\nrobots on four different kinds of manipulation tasks and one navigation task.",
      "tldr_zh": "该研究提出RoboCodeX，一种树结构的多模态代码生成框架，用于实现机器人行为合成，将高层人类指令分解为多个对象中心化的操作单位，并融入物理偏好如affordance和safety约束，以提升跨不同机器人平台的泛化能力。框架通过收集专门的多模态推理数据集进行预训练，并采用迭代自更新方法进行监督微调，从而将概念和感知理解转化为精确的控制命令。在实验中，RoboCodeX在模拟器和真实机器人上，在四种操作任务和一种导航任务中，达到了最先进性能，展示了其在Embodied AI领域的强大潜力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16117v1",
      "published_date": "2024-02-25 15:31:43 UTC",
      "updated_date": "2024-02-25 15:31:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:54:57.891833"
    },
    {
      "arxiv_id": "2402.16091v1",
      "title": "Bayesian Neural Network For Personalized Federated Learning Parameter Selection",
      "title_zh": "贝叶斯神经网络用于个性化联邦学习参数选择",
      "authors": [
        "Mengen Luo",
        "Ercan Engin Kuruoglu"
      ],
      "abstract": "Federated learning's poor performance in the presence of heterogeneous data\nremains one of the most pressing issues in the field. Personalized federated\nlearning departs from the conventional paradigm in which all clients employ the\nsame model, instead striving to discover an individualized model for each\nclient to address the heterogeneity in the data. One of such approach involves\npersonalizing specific layers of neural networks. However, prior endeavors have\nnot provided a dependable rationale, and some have selected personalized layers\nthat are entirely distinct and conflicting. In this work, we take a step\nfurther by proposing personalization at the elemental level, rather than the\ntraditional layer-level personalization. To select personalized parameters, we\nintroduce Bayesian neural networks and rely on the uncertainty they offer to\nguide our selection of personalized parameters. Finally, we validate our\nalgorithm's efficacy on several real-world datasets, demonstrating that our\nproposed approach outperforms existing baselines.",
      "tldr_zh": "本文提出了一种基于 Bayesian Neural Networks 的方法，用于个性化联邦学习（Federated Learning）的参数选择，以解决异构数据导致的性能问题。该方法超越传统层级个性化，转而从参数级别（elemental level）入手，利用 Bayesian Neural Networks 的不确定性来指导个性化参数的选取，从而为每个客户端生成更合适的模型。在多个真实数据集上的实验验证显示，该方法比现有基线表现出色，显著提升了学习效果。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16091v1",
      "published_date": "2024-02-25 13:37:53 UTC",
      "updated_date": "2024-02-25 13:37:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:55:10.900102"
    },
    {
      "arxiv_id": "2402.16086v2",
      "title": "Deep Homography Estimation for Visual Place Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Feng Lu",
        "Shuting Dong",
        "Lijun Zhang",
        "Bingxi Liu",
        "Xiangyuan Lan",
        "Dongmei Jiang",
        "Chun Yuan"
      ],
      "abstract": "Visual place recognition (VPR) is a fundamental task for many applications\nsuch as robot localization and augmented reality. Recently, the hierarchical\nVPR methods have received considerable attention due to the trade-off between\naccuracy and efficiency. They usually first use global features to retrieve the\ncandidate images, then verify the spatial consistency of matched local features\nfor re-ranking. However, the latter typically relies on the RANSAC algorithm\nfor fitting homography, which is time-consuming and non-differentiable. This\nmakes existing methods compromise to train the network only in global feature\nextraction. Here, we propose a transformer-based deep homography estimation\n(DHE) network that takes the dense feature map extracted by a backbone network\nas input and fits homography for fast and learnable geometric verification.\nMoreover, we design a re-projection error of inliers loss to train the DHE\nnetwork without additional homography labels, which can also be jointly trained\nwith the backbone network to help it extract the features that are more\nsuitable for local matching. Extensive experiments on benchmark datasets show\nthat our method can outperform several state-of-the-art methods. And it is more\nthan one order of magnitude faster than the mainstream hierarchical VPR methods\nusing RANSAC. The code is released at https://github.com/Lu-Feng/DHE-VPR.",
      "tldr_zh": "本论文针对视觉场所识别（VPR）的效率和准确性问题，提出了一种基于Transformer的深度同质矩阵估计（DHE）网络。该网络以骨干网络提取的密集特征图为输入，进行快速可学习的几何验证，从而取代传统耗时的RANSAC算法。同时，设计了内点重投影误差损失函数，无需额外标签即可训练DHE网络，并与骨干网络联合优化，以提升局部特征匹配的适用性。实验结果显示，该方法在基准数据集上超越了多项最先进方法，且速度比主流层次化VPR方法快一个数量级以上，代码已开源。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by AAAI2024",
      "pdf_url": "http://arxiv.org/pdf/2402.16086v2",
      "published_date": "2024-02-25 13:22:17 UTC",
      "updated_date": "2024-03-18 09:33:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:55:22.862569"
    },
    {
      "arxiv_id": "2402.16910v2",
      "title": "NeSy is alive and well: A LLM-driven symbolic approach for better code comment data generation and classification",
      "title_zh": "翻译失败",
      "authors": [
        "Hanna Abi Akl"
      ],
      "abstract": "We present a neuro-symbolic (NeSy) workflow combining a symbolic-based\nlearning technique with a large language model (LLM) agent to generate\nsynthetic data for code comment classification in the C programming language.\nWe also show how generating controlled synthetic data using this workflow fixes\nsome of the notable weaknesses of LLM-based generation and increases the\nperformance of classical machine learning models on the code comment\nclassification task. Our best model, a Neural Network, achieves a Macro-F1\nscore of 91.412% with an increase of 1.033% after data augmentation.",
      "tldr_zh": "本研究提出了一种神经符号(NeSy)工作流，将符号-based学习技术与大型语言模型(LLM)代理结合，用于生成C语言代码注释的合成数据。该方法通过控制合成数据的生成，解决了LLM-based生成存在的弱点，提升了经典机器学习模型在代码注释分类任务上的性能。实验结果显示，最佳模型（一个Neural Network）在数据增强后，Macro-F1分数达到91.412%，较基准提高了1.033%。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "19 pages, 5 figures, accepted for the GeNeSy workshop at the Extended\n  Semantic Web Conference (ESWC) 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.16910v2",
      "published_date": "2024-02-25 13:20:13 UTC",
      "updated_date": "2024-05-24 07:11:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:55:33.896763"
    },
    {
      "arxiv_id": "2403.00813v3",
      "title": "UrbanGPT: Spatio-Temporal Large Language Models",
      "title_zh": "UrbanGPT: 时空大语言模型",
      "authors": [
        "Zhonghang Li",
        "Lianghao Xia",
        "Jiabin Tang",
        "Yong Xu",
        "Lei Shi",
        "Long Xia",
        "Dawei Yin",
        "Chao Huang"
      ],
      "abstract": "Spatio-temporal prediction aims to forecast and gain insights into the\never-changing dynamics of urban environments across both time and space. Its\npurpose is to anticipate future patterns, trends, and events in diverse facets\nof urban life, including transportation, population movement, and crime rates.\nAlthough numerous efforts have been dedicated to developing neural network\ntechniques for accurate predictions on spatio-temporal data, it is important to\nnote that many of these methods heavily depend on having sufficient labeled\ndata to generate precise spatio-temporal representations. Unfortunately, the\nissue of data scarcity is pervasive in practical urban sensing scenarios.\nConsequently, it becomes necessary to build a spatio-temporal model with strong\ngeneralization capabilities across diverse spatio-temporal learning scenarios.\nTaking inspiration from the remarkable achievements of large language models\n(LLMs), our objective is to create a spatio-temporal LLM that can exhibit\nexceptional generalization capabilities across a wide range of downstream urban\ntasks. To achieve this objective, we present the UrbanGPT, which seamlessly\nintegrates a spatio-temporal dependency encoder with the instruction-tuning\nparadigm. This integration enables LLMs to comprehend the complex\ninter-dependencies across time and space, facilitating more comprehensive and\naccurate predictions under data scarcity. To validate the effectiveness of our\napproach, we conduct extensive experiments on various public datasets, covering\ndifferent spatio-temporal prediction tasks. The results consistently\ndemonstrate that our UrbanGPT, with its carefully designed architecture,\nconsistently outperforms state-of-the-art baselines. These findings highlight\nthe potential of building large language models for spatio-temporal learning,\nparticularly in zero-shot scenarios where labeled data is scarce.",
      "tldr_zh": "本论文针对城市时空预测问题（如交通和犯罪率），提出 UrbanGPT，这是一个基于大型语言模型 (LLMs) 的框架，旨在解决数据稀缺导致的泛化能力不足。UrbanGPT 通过整合时空依赖编码器与指令微调范式，使模型能够更好地理解时空互依赖，从而在各种下游任务中实现更准确的预测。实验结果显示，UrbanGPT 在多个公共数据集上超越最先进基线，特别是在零样本场景下表现出色，证明了其在数据稀缺环境中的强大潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by KDD'2024 as Full Paper",
      "pdf_url": "http://arxiv.org/pdf/2403.00813v3",
      "published_date": "2024-02-25 12:37:29 UTC",
      "updated_date": "2024-05-19 01:58:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:55:46.887201"
    },
    {
      "arxiv_id": "2402.16075v4",
      "title": "Don't Start from Scratch: Behavioral Refinement via Interpolant-based Policy Diffusion",
      "title_zh": "翻译失败",
      "authors": [
        "Kaiqi Chen",
        "Eugene Lim",
        "Kelvin Lin",
        "Yiyang Chen",
        "Harold Soh"
      ],
      "abstract": "Imitation learning empowers artificial agents to mimic behavior by learning\nfrom demonstrations. Recently, diffusion models, which have the ability to\nmodel high-dimensional and multimodal distributions, have shown impressive\nperformance on imitation learning tasks. These models learn to shape a policy\nby diffusing actions (or states) from standard Gaussian noise. However, the\ntarget policy to be learned is often significantly different from Gaussian and\nthis mismatch can result in poor performance when using a small number of\ndiffusion steps (to improve inference speed) and under limited data. The key\nidea in this work is that initiating from a more informative source than\nGaussian enables diffusion methods to mitigate the above limitations. We\ncontribute both theoretical results, a new method, and empirical findings that\nshow the benefits of using an informative source policy. Our method, which we\ncall BRIDGER, leverages the stochastic interpolants framework to bridge\narbitrary policies, thus enabling a flexible approach towards imitation\nlearning. It generalizes prior work in that standard Gaussians can still be\napplied, but other source policies can be used if available. In experiments on\nchallenging simulation benchmarks and on real robots, BRIDGER outperforms\nstate-of-the-art diffusion policies. We provide further analysis on design\nconsiderations when applying BRIDGER. Code for BRIDGER is available at\nhttps://github.com/clear-nus/bridger.",
      "tldr_zh": "本研究针对模仿学习（Imitation learning）中的扩散模型（Diffusion models）问题，指出从标准高斯噪声开始扩散会导致目标策略与高斯分布不匹配，从而在数据有限或步数少时性能下降。作者提出BRIDGER方法，利用随机插值框架（Stochastic interpolants）桥接任意源策略，使扩散过程从更具信息性的策略起始，从而提升灵活性和效率。该方法不仅推广了现有扩散技术，还通过理论分析和实证实验证明其优势，在模拟基准和真实机器人任务上优于最先进扩散策略。总的来说，BRIDGER为行为细化提供了新途径，提升了模仿学习的鲁棒性和实际应用潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16075v4",
      "published_date": "2024-02-25 12:19:21 UTC",
      "updated_date": "2024-07-11 03:41:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:56:00.627878"
    },
    {
      "arxiv_id": "2402.16073v2",
      "title": "Pfeed: Generating near real-time personalized feeds using precomputed embedding similarities",
      "title_zh": "翻译失败",
      "authors": [
        "Binyam Gebre",
        "Karoliina Ranta",
        "Stef van den Elzen",
        "Ernst Kuiper",
        "Thijs Baars",
        "Tom Heskes"
      ],
      "abstract": "In personalized recommender systems, embeddings are often used to encode\ncustomer actions and items, and retrieval is then performed in the embedding\nspace using approximate nearest neighbor search. However, this approach can\nlead to two challenges: 1) user embeddings can restrict the diversity of\ninterests captured and 2) the need to keep them up-to-date requires an\nexpensive, real-time infrastructure. In this paper, we propose a method that\novercomes these challenges in a practical, industrial setting. The method\ndynamically updates customer profiles and composes a feed every two minutes,\nemploying precomputed embeddings and their respective similarities. We tested\nand deployed this method to personalise promotional items at Bol, one of the\nlargest e-commerce platforms of the Netherlands and Belgium. The method\nenhanced customer engagement and experience, leading to a significant 4.9%\nuplift in conversions.",
      "tldr_zh": "本论文提出Pfeed方法，利用预计算的embedding相似性生成近实时的个性化feed，解决了传统基于embedding的推荐系统在兴趣多样性和实时更新基础设施方面的挑战。该方法通过动态更新客户配置文件，每两分钟生成一次feed，结合预计算相似性来提升推荐效率，并在荷兰和比利时的电商平台Bol上进行了部署。实验结果显示，该方法显著提高了客户参与度和体验，导致转换率提升4.9%。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG",
        "H.3.3"
      ],
      "primary_category": "cs.IR",
      "comment": "9 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.16073v2",
      "published_date": "2024-02-25 12:06:33 UTC",
      "updated_date": "2024-03-06 10:03:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:56:11.882729"
    },
    {
      "arxiv_id": "2402.16068v3",
      "title": "ROS-Causal: A ROS-based Causal Analysis Framework for Human-Robot Interaction Applications",
      "title_zh": "ROS-Causal：一种基于ROS的因果分析框架，用于人-",
      "authors": [
        "Luca Castri",
        "Gloria Beraldo",
        "Sariah Mghames",
        "Marc Hanheide",
        "Nicola Bellotto"
      ],
      "abstract": "Deploying robots in human-shared spaces requires understanding interactions\namong nearby agents and objects. Modelling cause-and-effect relations through\ncausal inference aids in predicting human behaviours and anticipating robot\ninterventions. However, a critical challenge arises as existing causal\ndiscovery methods currently lack an implementation inside the ROS ecosystem,\nthe standard de facto in robotics, hindering effective utilisation in robotics.\nTo address this gap, this paper introduces ROS-Causal, a ROS-based framework\nfor onboard data collection and causal discovery in human-robot spatial\ninteractions. An ad-hoc simulator, integrated with ROS, illustrates the\napproach's effectiveness, showcasing the robot onboard generation of causal\nmodels during data collection. ROS-Causal is available on GitHub:\nhttps://github.com/lcastri/roscausal.git.",
      "tldr_zh": "该论文针对人类共享空间中机器人部署的需求，提出ROS-Causal框架，以因果分析(Causal Analysis)帮助预测人类行为和机器人干预，但现有方法未集成到ROS生态系统。该框架在ROS中实现数据收集和因果发现功能，通过一个与ROS集成的模拟器演示了机器人在线生成因果模型的过程。实验结果证明了该框架的有效性，为Human-Robot Interaction应用提供了实用工具，并已在GitHub上开源。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted by the \"Causal-HRI: Causal Learning for Human-Robot\n  Interaction\" workshop at the 2024 ACM/IEEE International Conference on\n  Human-Robot Interaction (HRI)",
      "pdf_url": "http://arxiv.org/pdf/2402.16068v3",
      "published_date": "2024-02-25 11:37:23 UTC",
      "updated_date": "2024-03-21 11:58:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:56:24.025388"
    },
    {
      "arxiv_id": "2402.16063v4",
      "title": "Citation-Enhanced Generation for LLM-based Chatbots",
      "title_zh": "针对基于LLM的聊天机器人的引文增强生成",
      "authors": [
        "Weitao Li",
        "Junkai Li",
        "Weizhi Ma",
        "Yang Liu"
      ],
      "abstract": "Large language models (LLMs) exhibit powerful general intelligence across\ndiverse scenarios, including their integration into chatbots. However, a vital\nchallenge of LLM-based chatbots is that they may produce hallucinated content\nin responses, which significantly limits their applicability. Various efforts\nhave been made to alleviate hallucination, such as retrieval augmented\ngeneration and reinforcement learning with human feedback, but most of them\nrequire additional training and data annotation. In this paper, we propose a\nnovel post-hoc Citation-Enhanced Generation (CEG) approach combined with\nretrieval argumentation. Unlike previous studies that focus on preventing\nhallucinations during generation, our method addresses this issue in a post-hoc\nway. It incorporates a retrieval module to search for supporting documents\nrelevant to the generated content, and employs a natural language\ninference-based citation generation module. Once the statements in the\ngenerated content lack of reference, our model can regenerate responses until\nall statements are supported by citations. Note that our method is a\ntraining-free plug-and-play plugin that is capable of various LLMs. Experiments\non various hallucination-related datasets show our framework outperforms\nstate-of-the-art methods in both hallucination detection and response\nregeneration on three benchmarks. Our codes and dataset will be publicly\navailable.",
      "tldr_zh": "这篇论文针对大型语言模型（LLM-based chatbots）在响应中可能产生的 hallucination 问题，提出了一种新型后处理方法：Citation-Enhanced Generation (CEG)，结合 retrieval argumentation 来增强生成内容的准确性。CEG 通过检索模块搜索相关支持文档，并使用 natural language inference-based citation generation 模块，确保所有语句都有引用支持，若缺少引用则重新生成响应。该方法是一个 training-free plug-and-play 插件，适用于各种 LLMs，并在多个 hallucination-related datasets 上表现出色，超过了 state-of-the-art 方法在 hallucination detection 和 response regeneration 的性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16063v4",
      "published_date": "2024-02-25 11:24:41 UTC",
      "updated_date": "2025-04-17 17:28:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:56:37.125265"
    },
    {
      "arxiv_id": "2403.12077v1",
      "title": "Evaluating Robustness of Generative Search Engine on Adversarial Factual Questions",
      "title_zh": "翻译失败",
      "authors": [
        "Xuming Hu",
        "Xiaochuan Li",
        "Junzhe Chen",
        "Yinghui Li",
        "Yangning Li",
        "Xiaoguang Li",
        "Yasheng Wang",
        "Qun Liu",
        "Lijie Wen",
        "Philip S. Yu",
        "Zhijiang Guo"
      ],
      "abstract": "Generative search engines have the potential to transform how people seek\ninformation online, but generated responses from existing large language models\n(LLMs)-backed generative search engines may not always be accurate.\nNonetheless, retrieval-augmented generation exacerbates safety concerns, since\nadversaries may successfully evade the entire system by subtly manipulating the\nmost vulnerable part of a claim. To this end, we propose evaluating the\nrobustness of generative search engines in the realistic and high-risk setting,\nwhere adversaries have only black-box system access and seek to deceive the\nmodel into returning incorrect responses. Through a comprehensive human\nevaluation of various generative search engines, such as Bing Chat,\nPerplexityAI, and YouChat across diverse queries, we demonstrate the\neffectiveness of adversarial factual questions in inducing incorrect responses.\nMoreover, retrieval-augmented generation exhibits a higher susceptibility to\nfactual errors compared to LLMs without retrieval. These findings highlight the\npotential security risks of these systems and emphasize the need for rigorous\nevaluation before deployment.",
      "tldr_zh": "本研究评估了生成式搜索引擎(Generative Search Engine)在面对对抗性事实问题(Adversarial Factual Questions)时的鲁棒性，重点关注攻击者通过黑盒访问操纵系统以诱导错误响应的风险。研究采用人类评估方法，测试了如Bing Chat、PerplexityAI和YouChat等系统在多样化查询下的表现。结果显示，检索增强生成(Retrieval-Augmented Generation)比不使用检索的大语言模型(LLMs)更容易出现事实错误，从而加剧了安全隐患。该研究强调了这些系统的潜在风险，并建议在部署前进行严格评估。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "21 pages, 7 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2403.12077v1",
      "published_date": "2024-02-25 11:22:19 UTC",
      "updated_date": "2024-02-25 11:22:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:56:48.719148"
    },
    {
      "arxiv_id": "2402.16052v1",
      "title": "Maximizing UAV Fog Deployment Efficiency for Critical Rescue Operations",
      "title_zh": "翻译失败",
      "authors": [
        "Abdenacer Naouri",
        "Huansheng Ning",
        "Nabil Abdelkader Nouri",
        "Amar Khelloufi",
        "Abdelkarim Ben Sada",
        "Salim Naouri",
        "Attia Qammar",
        "Sahraoui Dhelim"
      ],
      "abstract": "In disaster scenarios and high-stakes rescue operations, integrating Unmanned\nAerial Vehicles (UAVs) as fog nodes has become crucial. This integration\nensures a smooth connection between affected populations and essential health\nmonitoring devices, supported by the Internet of Things (IoT). Integrating UAVs\nin such environments is inherently challenging, where the primary objectives\ninvolve maximizing network connectivity and coverage while extending the\nnetwork's lifetime through energy-efficient strategies to serve the maximum\nnumber of affected individuals. In this paper, We propose a novel model centred\naround dynamic UAV-based fog deployment that optimizes the system's\nadaptability and operational efficacy within the afflicted areas. First, we\ndecomposed the problem into two subproblems. Connectivity and coverage\nsubproblem, and network lifespan optimization subproblem. We shape our UAV fog\ndeployment problem as a uni-objective optimization and introduce a specialized\nUAV fog deployment algorithm tailored specifically for UAV fog nodes deployed\nin rescue missions. While the network lifespan optimization subproblem is\nefficiently solved via a one-dimensional swapping method. Following that, We\nintroduce a novel optimization strategy for UAV fog node placement in dynamic\nnetworks during evacuation scenarios, with a primary focus on ensuring robust\nconnectivity and maximal coverage for mobile users, while extending the\nnetwork's lifespan. Finally, we introduce Adaptive Whale Optimization Algorithm\n(WOA) for fog node deployment in a dynamic network. Its agility, rapid\nconvergence, and low computational demands make it an ideal fit for\nhigh-pressure environments.",
      "tldr_zh": "这篇论文针对灾难救援场景，提出了一种动态无人机（UAV）雾节点部署模型，以最大化网络连接、覆盖范围和系统寿命，同时服务更多受影响人群。研究将问题分解为连接与覆盖子问题，以及网络寿命优化子问题，并引入一个专用UAV雾部署算法和一维交换方法来高效解决这些挑战。此外，论文开发了Adaptive Whale Optimization Algorithm (WOA)，该算法在动态网络中实现快速收敛和低计算需求，提升了救援操作的适应性和效率。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16052v1",
      "published_date": "2024-02-25 10:32:18 UTC",
      "updated_date": "2024-02-25 10:32:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:56:59.785852"
    },
    {
      "arxiv_id": "2402.16048v3",
      "title": "How Likely Do LLMs with CoT Mimic Human Reasoning?",
      "title_zh": "翻译失败",
      "authors": [
        "Guangsheng Bao",
        "Hongbo Zhang",
        "Cunxiang Wang",
        "Linyi Yang",
        "Yue Zhang"
      ],
      "abstract": "Chain-of-thought emerges as a promising technique for eliciting reasoning\ncapabilities from Large Language Models (LLMs). However, it does not always\nimprove task performance or accurately represent reasoning processes, leaving\nunresolved questions about its usage. In this paper, we diagnose the underlying\nmechanism by comparing the reasoning process of LLMs with humans, using causal\nanalysis to understand the relationships between the problem instruction,\nreasoning, and the answer in LLMs. Our empirical study reveals that LLMs often\ndeviate from the ideal causal chain, resulting in spurious correlations and\npotential consistency errors (inconsistent reasoning and answers). We also\nexamine various factors influencing the causal structure, finding that\nin-context learning with examples strengthens it, while post-training\ntechniques like supervised fine-tuning and reinforcement learning on human\nfeedback weaken it. To our surprise, the causal structure cannot be\nstrengthened by enlarging the model size only, urging research on new\ntechniques. We hope that this preliminary study will shed light on\nunderstanding and improving the reasoning process in LLM.",
      "tldr_zh": "这篇论文探讨了Chain-of-Thought (CoT) 技术在Large Language Models (LLMs) 中是否能有效模仿人类推理，通过因果分析比较LLMs 和人类的推理过程，以揭示问题指令、推理和答案之间的关系。研究发现，LLMs 经常偏离理想因果链，导致虚假相关性和一致性错误（如推理与答案不一致）。影响因素包括：in-context learning 可以加强因果结构，而supervised fine-tuning 和reinforcement learning on human feedback 则会削弱它。令人意外的是，仅增大模型大小无法改善这一问题，因此论文呼吁开发新技巧来提升LLMs 的推理能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "COLING 2025 Camera Version (8 pages, 3 figures, 18 tables)",
      "pdf_url": "http://arxiv.org/pdf/2402.16048v3",
      "published_date": "2024-02-25 10:13:04 UTC",
      "updated_date": "2024-12-12 12:01:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:57:12.541873"
    },
    {
      "arxiv_id": "2402.16038v1",
      "title": "Deep Learning Approaches for Improving Question Answering Systems in Hepatocellular Carcinoma Research",
      "title_zh": "翻译失败",
      "authors": [
        "Shuning Huo",
        "Yafei Xiang",
        "Hanyi Yu",
        "Mengran Zhu",
        "Yulu Gong"
      ],
      "abstract": "In recent years, advancements in natural language processing (NLP) have been\nfueled by deep learning techniques, particularly through the utilization of\npowerful computing resources like GPUs and TPUs. Models such as BERT and GPT-3,\ntrained on vast amounts of data, have revolutionized language understanding and\ngeneration. These pre-trained models serve as robust bases for various tasks\nincluding semantic understanding, intelligent writing, and reasoning, paving\nthe way for a more generalized form of artificial intelligence. NLP, as a vital\napplication of AI, aims to bridge the gap between humans and computers through\nnatural language interaction. This paper delves into the current landscape and\nfuture prospects of large-scale model-based NLP, focusing on the\nquestion-answering systems within this domain. Practical cases and developments\nin artificial intelligence-driven question-answering systems are analyzed to\nfoster further exploration and research in the realm of large-scale NLP.",
      "tldr_zh": "这篇论文探讨了深度学习技术（如BERT和GPT-3）在肝细胞癌研究中的问答系统应用，强调这些模型通过大规模数据训练提升了语义理解和推理能力。论文分析了当前NLP领域的进展和未来前景，聚焦于AI驱动的问答系统如何桥接人类与计算机的交互。作者通过实际案例研究，展示了这些方法在促进肝细胞癌相关研究的潜力，并呼吁进一步探索大规模NLP的应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16038v1",
      "published_date": "2024-02-25 09:32:17 UTC",
      "updated_date": "2024-02-25 09:32:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:57:23.497015"
    },
    {
      "arxiv_id": "2402.16035v1",
      "title": "Text Understanding and Generation Using Transformer Models for Intelligent E-commerce Recommendations",
      "title_zh": "基于 Transformer 模型的文本理解和生成用于智能电子商务推荐",
      "authors": [
        "Yafei Xiang",
        "Hanyi Yu",
        "Yulu Gong",
        "Shuning Huo",
        "Mengran Zhu"
      ],
      "abstract": "With the rapid development of artificial intelligence technology, Transformer\nstructural pre-training model has become an important tool for large language\nmodel (LLM) tasks. In the field of e-commerce, these models are especially\nwidely used, from text understanding to generating recommendation systems,\nwhich provide powerful technical support for improving user experience and\noptimizing service processes. This paper reviews the core application scenarios\nof Transformer pre-training model in e-commerce text understanding and\nrecommendation generation, including but not limited to automatic generation of\nproduct descriptions, sentiment analysis of user comments, construction of\npersonalized recommendation system and automated processing of customer service\nconversations. Through a detailed analysis of the model's working principle,\nimplementation process, and application effects in specific cases, this paper\nemphasizes the unique advantages of pre-trained models in understanding complex\nuser intentions and improving the quality of recommendations. In addition, the\nchallenges and improvement directions for the future are also discussed, such\nas how to further improve the generalization ability of the model, the ability\nto handle large-scale data sets, and technical strategies to protect user\nprivacy. Ultimately, the paper points out that the application of Transformer\nstructural pre-training models in e-commerce has not only driven technological\ninnovation, but also brought substantial benefits to merchants and consumers,\nand looking forward, these models will continue to play a key role in\ne-commerce and beyond.",
      "tldr_zh": "这篇论文回顾了Transformer预训练模型在电商领域的应用，特别是用于文本理解和生成智能推荐系统。论文详细分析了模型的核心工作原理及其在具体场景中的实现，如自动生成产品描述、用户评论情感分析、构建个性化推荐系统以及处理客户服务对话，这些应用显著提升了用户体验和推荐质量。尽管模型在理解复杂用户意图方面表现出独特优势，但论文也讨论了未来挑战，包括提升模型的泛化能力、处理大规模数据集以及保护用户隐私。总体而言，Transformer模型的应用不仅推动了电商技术创新，还为商家和消费者带来了实际收益，并有望在更广泛领域发挥关键作用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16035v1",
      "published_date": "2024-02-25 09:19:11 UTC",
      "updated_date": "2024-02-25 09:19:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:57:34.730828"
    },
    {
      "arxiv_id": "2402.16034v2",
      "title": "Emotion Classification in Short English Texts using Deep Learning Techniques",
      "title_zh": "翻译失败",
      "authors": [
        "Siddhanth Bhat"
      ],
      "abstract": "Detecting emotions in limited text datasets from under-resourced languages\npresents a formidable obstacle, demanding specialized frameworks and\ncomputational strategies. This study conducts a thorough examination of deep\nlearning techniques for discerning emotions in short English texts. Deep\nlearning approaches employ transfer learning and word embedding, notably BERT,\nto attain superior accuracy. To evaluate these methods, we introduce the\n\"SmallEnglishEmotions\" dataset, comprising 6372 varied short English texts\nannotated with five primary emotion categories. Our experiments reveal that\ntransfer learning and BERT-based text embedding outperform alternative methods\nin accurately categorizing the text in the dataset.",
      "tldr_zh": "这篇论文探讨了使用深度学习技术对短英语文本进行情绪分类的问题，特别针对资源有限的数据集。研究者引入了\"SmallEnglishEmotions\"数据集，该数据集包含6372条标注了五种主要情绪类别的多样化短文本。实验结果表明，转移学习(Transfer Learning)和BERT-based词嵌入方法在分类准确性上优于其他方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16034v2",
      "published_date": "2024-02-25 09:17:22 UTC",
      "updated_date": "2024-03-10 15:58:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:57:47.347765"
    },
    {
      "arxiv_id": "2402.16030v1",
      "title": "Don't Forget Your Reward Values: Language Model Alignment via Value-based Calibration",
      "title_zh": "翻译失败",
      "authors": [
        "Xin Mao",
        "Feng-Lin Li",
        "Huimin Xu",
        "Wei Zhang",
        "Anh Tuan Luu"
      ],
      "abstract": "While Reinforcement Learning from Human Feedback (RLHF) significantly\nenhances the generation quality of Large Language Models (LLMs), recent studies\nhave raised concerns regarding the complexity and instability associated with\nthe Proximal Policy Optimization (PPO) algorithm, proposing a series of\norder-based calibration methods as viable alternatives. This paper delves\nfurther into current order-based methods, examining their inefficiencies in\nutilizing reward values and addressing misalignment issues. Building upon these\nfindings, we propose a novel \\textbf{V}alue-based \\textbf{C}ali\\textbf{B}ration\n(VCB) method to better align LLMs with human preferences. Experimental results\ndemonstrate that VCB surpasses existing alignment methods on AI assistant and\nsummarization datasets, providing impressive generalizability, robustness, and\nstability in diverse settings.",
      "tldr_zh": "虽然 RLHF 显著提升了大型语言模型 (LLMs) 的生成质量，但 Proximal Policy Optimization (PPO) 算法的复杂性和不稳定性，以及现有 order-based 校准方法的效率不足和 misalignment 问题，限制了其性能。本文提出了一种创新的 Value-based Calibration (VCB) 方法，通过更好地利用奖励值来实现 LLMs 与人类偏好的精确对齐。实验结果显示，VCB 在 AI 助手和总结数据集上超越现有对齐方法，展现出卓越的泛化性、鲁棒性和稳定性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "19 pages, Under review",
      "pdf_url": "http://arxiv.org/pdf/2402.16030v1",
      "published_date": "2024-02-25 08:45:10 UTC",
      "updated_date": "2024-02-25 08:45:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:57:59.411932"
    },
    {
      "arxiv_id": "2402.16021v1",
      "title": "TMT: Tri-Modal Translation between Speech, Image, and Text by Processing Different Modalities as Different Languages",
      "title_zh": "翻译失败",
      "authors": [
        "Minsu Kim",
        "Jee-weon Jung",
        "Hyeongseop Rha",
        "Soumi Maiti",
        "Siddhant Arora",
        "Xuankai Chang",
        "Shinji Watanabe",
        "Yong Man Ro"
      ],
      "abstract": "The capability to jointly process multi-modal information is becoming an\nessential task. However, the limited number of paired multi-modal data and the\nlarge computational requirements in multi-modal learning hinder the\ndevelopment. We propose a novel Tri-Modal Translation (TMT) model that\ntranslates between arbitrary modalities spanning speech, image, and text. We\nintroduce a novel viewpoint, where we interpret different modalities as\ndifferent languages, and treat multi-modal translation as a well-established\nmachine translation problem. To this end, we tokenize speech and image data\ninto discrete tokens, which provide a unified interface across modalities and\nsignificantly decrease the computational cost. In the proposed TMT, a\nmulti-modal encoder-decoder conducts the core translation, whereas\nmodality-specific processing is conducted only within the tokenization and\ndetokenization stages. We evaluate the proposed TMT on all six modality\ntranslation tasks. TMT outperforms single model counterparts consistently,\ndemonstrating that unifying tasks is beneficial not only for practicality but\nalso for performance.",
      "tldr_zh": "本文提出了一种Tri-Modal Translation (TMT)模型，用于在语音、图像和文本之间进行多模态翻译，将不同模态视为不同语言，类似于机器翻译问题。TMT通过将语音和图像数据转化为离散tokens，提供统一的接口，并仅在tokenization和detokenization阶段进行模态特定处理，从而显著降低计算成本。实验结果显示，TMT在六种模态翻译任务上 consistently outperforms单一模型，证明统一任务不仅提升了性能，还增加了实用性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16021v1",
      "published_date": "2024-02-25 07:46:57 UTC",
      "updated_date": "2024-02-25 07:46:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:58:11.915570"
    },
    {
      "arxiv_id": "2402.16014v2",
      "title": "Building Flexible Machine Learning Models for Scientific Computing at Scale",
      "title_zh": "构建灵活的机器学习模型用于大规模科学计算",
      "authors": [
        "Tianyu Chen",
        "Haoyi Zhou",
        "Ying Li",
        "Hao Wang",
        "Chonghan Gao",
        "Rongye Shi",
        "Shanghang Zhang",
        "Jianxin Li"
      ],
      "abstract": "Foundation models have revolutionized language modeling, while whether this\nsuccess is replicated in scientific computing remains unexplored. We present\nOmniArch, the first prototype aiming at solving multi-scale and multi-physics\nscientific computing problems with physical alignment. We addressed all three\nchallenges with one unified architecture. Its pre-training stage contains a\nFourier Encoder-decoder fading out the disharmony across separated dimensions\nand a Transformer backbone integrating quantities through temporal dynamics,\nand the novel PDE-Aligner performs physics-informed fine-tuning under flexible\nconditions. As far as we know, we first conduct 1D-2D-3D united pre-training on\nthe PDEBench, and it sets not only new performance benchmarks for 1D, 2D, and\n3D PDEs but also demonstrates exceptional adaptability to new physics via\nin-context and zero-shot learning approaches, which supports realistic\nengineering applications and foresight physics discovery.",
      "tldr_zh": "本文提出 OmniArch，这是一个统一的机器学习框架，旨在解决多尺度多物理科学计算问题，通过物理对齐方法处理相关挑战。框架的核心组件包括 Fourier Encoder-decoder 用于淡化维度不和谐、Transformer backbone 通过时间动态整合量，以及新型 PDE-Aligner 进行灵活条件的物理信息微调。在 PDEBench 上，首次进行 1D-2D-3D 统一预训练，不仅设定了新的性能基准，还展示了通过 in-context learning 和 zero-shot learning 适应新物理的能力，支持实际工程应用和物理发现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Work in Progress",
      "pdf_url": "http://arxiv.org/pdf/2402.16014v2",
      "published_date": "2024-02-25 07:19:01 UTC",
      "updated_date": "2024-10-13 14:54:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:58:24.817081"
    },
    {
      "arxiv_id": "2403.00812v2",
      "title": "LoRA Meets Dropout under a Unified Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Sheng Wang",
        "Liheng Chen",
        "Jiyue Jiang",
        "Boyang Xue",
        "Lingpeng Kong",
        "Chuan Wu"
      ],
      "abstract": "With the remarkable capabilities, large language models (LLMs) have emerged\nas essential elements in numerous NLP applications, while parameter-efficient\nfinetuning, especially LoRA, has gained popularity as a lightweight approach\nfor model customization. Meanwhile, various dropout methods, initially designed\nfor full finetuning with all the parameters updated, alleviates overfitting\nassociated with excessive parameter redundancy. Hence, a possible contradiction\narises from negligible trainable parameters of LoRA and the effectiveness of\nprevious dropout methods, which has been largely overlooked. To fill this gap,\nwe first confirm that parameter-efficient LoRA is also overfitting-prone. We\nthen revisit transformer-specific dropout methods, and establish their\nequivalence and distinctions mathematically and empirically. Building upon this\ncomparative analysis, we introduce a unified framework for a comprehensive\ninvestigation, which instantiates these methods based on dropping position,\nstructural pattern and compensation measure. Through this framework, we reveal\nthe new preferences and performance comparisons of them when involved with\nlimited trainable parameters. This framework also allows us to amalgamate the\nmost favorable aspects into a novel dropout method named HiddenKey. Extensive\nexperiments verify the remarkable superiority and sufficiency of HiddenKey\nacross multiple models and tasks, which highlights it as the preferred approach\nfor high-performance and parameter-efficient finetuning of LLMs.",
      "tldr_zh": "本研究探讨了在参数高效微调方法LoRA中如何整合dropout技术，以缓解大型语言模型(LLMs)过拟合问题。首先，作者证实LoRA尽管参数少也易于过拟合，并通过数学和经验分析重新审视transformer-specific dropout方法，建立它们的等价性和差异。随后，提出一个统一框架，基于dropping position、structural pattern和compensation measure来比较这些方法，并揭示其在有限可训练参数下的新偏好和性能。最终，作者开发了新dropout方法HiddenKey，将框架中最优方面结合，实验显示HiddenKey在多个模型和任务上表现出显著优势，成为高性能参数高效微调的首选方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.00812v2",
      "published_date": "2024-02-25 07:09:10 UTC",
      "updated_date": "2024-05-27 02:16:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:58:36.153974"
    },
    {
      "arxiv_id": "2402.16012v1",
      "title": "Deep Contrastive Graph Learning with Clustering-Oriented Guidance",
      "title_zh": "翻译失败",
      "authors": [
        "Mulin Chen",
        "Bocheng Wang",
        "Xuelong Li"
      ],
      "abstract": "Graph Convolutional Network (GCN) has exhibited remarkable potential in\nimproving graph-based clustering. To handle the general clustering scenario\nwithout a prior graph, these models estimate an initial graph beforehand to\napply GCN. Throughout the literature, we have witnessed that 1) most models\nfocus on the initial graph while neglecting the original features. Therefore,\nthe discriminability of the learned representation may be corrupted by a\nlow-quality initial graph; 2) the training procedure lacks effective clustering\nguidance, which may lead to the incorporation of clustering-irrelevant\ninformation into the learned graph. To tackle these problems, the Deep\nContrastive Graph Learning (DCGL) model is proposed for general data\nclustering. Specifically, we establish a pseudo-siamese network, which\nincorporates auto-encoder with GCN to emphasize both the graph structure and\nthe original features. On this basis, feature-level contrastive learning is\nintroduced to enhance the discriminative capacity, and the relationship between\nsamples and centroids is employed as the clustering-oriented guidance.\nAfterward, a two-branch graph learning mechanism is designed to extract the\nlocal and global structural relationships, which are further embedded into a\nunified graph under the cluster-level contrastive guidance. Experimental\nresults on several benchmark datasets demonstrate the superiority of DCGL\nagainst state-of-the-art algorithms.",
      "tldr_zh": "本论文提出 Deep Contrastive Graph Learning (DCGL) 模型，用于处理 Graph Convolutional Network (GCN) 在无先验图的聚类场景中存在的缺陷，如忽略原始特征和缺乏聚类指导。DCGL 通过伪孪生网络结合 auto-encoder 和 GCN，强调图结构和特征，并引入 feature-level contrastive learning 来提升表示的判别能力，同时利用样本与 centroids 的关系提供聚类导向。模型还设计了两分支图学习机制，提取局部和全局结构关系，并在 cluster-level contrastive guidance 下融合为统一图。实验结果显示，DCGL 在多个基准数据集上优于最先进算法，证明了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accept at AAAI24",
      "pdf_url": "http://arxiv.org/pdf/2402.16012v1",
      "published_date": "2024-02-25 07:03:37 UTC",
      "updated_date": "2024-02-25 07:03:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:58:48.500793"
    },
    {
      "arxiv_id": "2402.16002v1",
      "title": "Post-Quantum Cryptography Neural Network",
      "title_zh": "后量子密码学神经网络",
      "authors": [
        "Abel C. H. Chen"
      ],
      "abstract": "In recent years, quantum computers and Shor quantum algorithm have posed a\nthreat to current mainstream asymmetric cryptography methods (e.g. RSA and\nElliptic Curve Cryptography (ECC)). Therefore, it is necessary to construct a\nPost-Quantum Cryptography (PQC) method to resist quantum computing attacks.\nTherefore, this study proposes a PQC-based neural network that maps a\ncode-based PQC method to a neural network structure and enhances the security\nof ciphertexts with non-linear activation functions, random perturbation of\nciphertexts, and uniform distribution of ciphertexts. In practical experiments,\nthis study uses cellular network signals as a case study to demonstrate that\nencryption and decryption can be performed by the proposed PQC-based neural\nnetwork with the uniform distribution of ciphertexts. In the future, the\nproposed PQC-based neural network could be applied to various applications.",
      "tldr_zh": "本文针对量子计算机和Shor algorithm对现有非对称加密方法（如RSA和Elliptic Curve Cryptography (ECC)）的威胁，提出了一种基于Post-Quantum Cryptography (PQC)的神经网络，将代码-based PQC方法映射到神经网络结构中。 该网络通过非线性激活函数、随机扰动密文和密文均匀分布等方式增强了密文安全性。 在蜂窝网络信号的实际实验中，该网络成功实现了加密和解密操作，并展示了其在未来各种应用中的潜力。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "2023 International Conference on Smart Systems for applications in\n  Electrical Sciences (ICSSES) 7-8 July 2023. The manuscript was written in\n  Chinese and submitted on 10 March 2023, but it was rejected on 22 April 2023.\n  The appeal was accepted on 24 February 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.16002v1",
      "published_date": "2024-02-25 06:19:04 UTC",
      "updated_date": "2024-02-25 06:19:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:59:00.316151"
    },
    {
      "arxiv_id": "2402.15990v2",
      "title": "An Empirical Study of Challenges in Machine Learning Asset Management",
      "title_zh": "翻译失败",
      "authors": [
        "Zhimin Zhao",
        "Yihao Chen",
        "Abdul Ali Bangash",
        "Bram Adams",
        "Ahmed E. Hassan"
      ],
      "abstract": "In machine learning (ML), efficient asset management, including ML models,\ndatasets, algorithms, and tools, is vital for resource optimization, consistent\nperformance, and a streamlined development lifecycle. This enables quicker\niterations, adaptability, reduced development-to-deployment time, and reliable\noutputs. Despite existing research, a significant knowledge gap remains in\noperational challenges like model versioning, data traceability, and\ncollaboration, which are crucial for the success of ML projects. Our study aims\nto address this gap by analyzing 15,065 posts from developer forums and\nplatforms, employing a mixed-method approach to classify inquiries, extract\nchallenges using BERTopic, and identify solutions through open card sorting and\nBERTopic clustering. We uncover 133 topics related to asset management\nchallenges, grouped into 16 macro-topics, with software dependency, model\ndeployment, and model training being the most discussed. We also find 79\nsolution topics, categorized under 18 macro-topics, highlighting software\ndependency, feature development, and file management as key solutions. This\nresearch underscores the need for further exploration of identified pain points\nand the importance of collaborative efforts across academia, industry, and the\nresearch community.",
      "tldr_zh": "本研究通过实证分析探讨了机器学习 (ML) 资产管理中的挑战，包括模型、数据集、算法和工具的管理，以优化资源、一致性能和开发生命周期。研究者分析了 15,065 个开发论坛帖子，使用混合方法（如分类询问、BERTopic 提取挑战，以及开放卡片排序和 BERTopic 聚类识别解决方案），从而识别出 133 个挑战主题（归类为 16 个宏观主题），其中软件依赖、模型部署和模型训练最为突出。研究还发现了 79 个解决方案主题（归类为 18 个宏观主题），强调软件依赖、特征开发和文件管理作为关键策略。该工作突出了 ML 项目中模型版本控制、数据可追溯性和协作等痛点，并呼吁学术、工业和研究社区加强合作以进一步解决这些问题。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.15990v2",
      "published_date": "2024-02-25 05:05:52 UTC",
      "updated_date": "2024-02-28 05:58:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:59:12.553814"
    },
    {
      "arxiv_id": "2402.15989v1",
      "title": "PIDformer: Transformer Meets Control Theory",
      "title_zh": "翻译失败",
      "authors": [
        "Tam Nguyen",
        "César A. Uribe",
        "Tan M. Nguyen",
        "Richard G. Baraniuk"
      ],
      "abstract": "In this work, we address two main shortcomings of transformer architectures:\ninput corruption and rank collapse in their output representation. We unveil\nself-attention as an autonomous state-space model that inherently promotes\nsmoothness in its solutions, leading to lower-rank outputs and diminished\nrepresentation capacity. Moreover, the steady-state solution of the model is\nsensitive to input perturbations. We incorporate a\nProportional-Integral-Derivative (PID) closed-loop feedback control system with\na reference point into the model to improve robustness and representation\ncapacity. This integration aims to preserve high-frequency details while\nbolstering model stability, rendering it more noise-resilient. The resulting\ncontrolled state-space model is theoretically proven robust and adept at\naddressing the rank collapse. Motivated by this control framework, we derive a\nnovel class of transformers, PID-controlled Transformer (PIDformer), aimed at\nimproving robustness and mitigating the rank-collapse issue inherent in softmax\ntransformers. We empirically evaluate the model for advantages and robustness\nagainst baseline transformers across various practical tasks, including object\nclassification, image segmentation, and language modeling.",
      "tldr_zh": "本文探讨了Transformer架构的两个主要缺陷：输入损坏和输出表示的秩collapse问题。作者揭示自注意力机制本质上是一个自治状态空间模型，导致平滑解、较低秩输出和表示能力减弱，并对输入扰动敏感。为此，他们引入了比例-积分-微分（PID）闭环反馈控制系统，结合参考点来提升模型的鲁棒性和稳定性，同时保留高频细节。实验结果显示，提出的PIDformer在物体分类、图像分割和语言建模等任务上比基线Transformer表现出色，证明了其在缓解秩collapse和提高鲁棒性方面的有效性。",
      "categories": [
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.15989v1",
      "published_date": "2024-02-25 05:04:51 UTC",
      "updated_date": "2024-02-25 05:04:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:59:25.059708"
    },
    {
      "arxiv_id": "2402.15987v3",
      "title": "Likelihood-based Mitigation of Evaluation Bias in Large Language Models",
      "title_zh": "基于似然度的评估偏差缓解在大语言模型中",
      "authors": [
        "Masanari Ohi",
        "Masahiro Kaneko",
        "Ryuto Koike",
        "Mengsay Loem",
        "Naoaki Okazaki"
      ],
      "abstract": "Large Language Models (LLMs) are widely used to evaluate natural language\ngeneration tasks as automated metrics. However, the likelihood, a measure of\nLLM's plausibility for a sentence, can vary due to superficial differences in\nsentences, such as word order and sentence structure. It is therefore possible\nthat there might be a likelihood bias if LLMs are used for evaluation: they\nmight overrate sentences with higher likelihoods while underrating those with\nlower likelihoods. In this paper, we investigate the presence and impact of\nlikelihood bias in LLM-based evaluators. We also propose a method to mitigate\nthe likelihood bias. Our method utilizes highly biased instances as few-shot\nexamples for in-context learning. Our experiments in evaluating the\ndata-to-text and grammatical error correction tasks reveal that several LLMs we\ntest display a likelihood bias. Furthermore, our proposed method successfully\nmitigates this bias, also improving evaluation performance (in terms of\ncorrelation of models with human scores) significantly.",
      "tldr_zh": "本研究探讨了大语言模型 (LLMs) 在评估自然语言生成任务时存在的似然偏差 (likelihood bias)，即 LLMs 可能因句子的表面差异（如词序和句子结构）而高估高似然句子并低估低似然句子。作者提出了一种基于 in-context learning 的缓解方法，利用高度偏差的实例作为 few-shot examples 来调整模型评估。实验结果显示，在 data-to-text 和 grammatical error correction 任务上，该方法成功减轻了偏差，并显著提高了 LLMs 与人类评分的相关性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "5 main pages",
      "pdf_url": "http://arxiv.org/pdf/2402.15987v3",
      "published_date": "2024-02-25 04:52:02 UTC",
      "updated_date": "2024-10-12 09:57:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:59:37.536851"
    },
    {
      "arxiv_id": "2402.15968v2",
      "title": "CoDream: Exchanging dreams instead of models for federated aggregation with heterogeneous models",
      "title_zh": "翻译失败",
      "authors": [
        "Abhishek Singh",
        "Gauri Gupta",
        "Ritvik Kapila",
        "Yichuan Shi",
        "Alex Dang",
        "Sheshank Shankar",
        "Mohammed Ehab",
        "Ramesh Raskar"
      ],
      "abstract": "Federated Learning (FL) enables collaborative optimization of machine\nlearning models across decentralized data by aggregating model parameters. Our\napproach extends this concept by aggregating \"knowledge\" derived from models,\ninstead of model parameters. We present a novel framework called CoDream, where\nclients collaboratively optimize randomly initialized data using federated\noptimization in the input data space, similar to how randomly initialized model\nparameters are optimized in FL. Our key insight is that jointly optimizing this\ndata can effectively capture the properties of the global data distribution.\nSharing knowledge in data space offers numerous benefits: (1) model-agnostic\ncollaborative learning, i.e., different clients can have different model\narchitectures; (2) communication that is independent of the model size,\neliminating scalability concerns with model parameters; (3) compatibility with\nsecure aggregation, thus preserving the privacy benefits of federated learning;\n(4) allowing of adaptive optimization of knowledge shared for personalized\nlearning. We empirically validate CoDream on standard FL tasks, demonstrating\ncompetitive performance despite not sharing model parameters. Our code:\nhttps://mitmedialab.github.io/codream.github.io/",
      "tldr_zh": "该研究提出 CoDream 框架，用于 Federated Learning (FL)，通过聚合模型派生的“知识”而非模型参数，实现异构模型的协作优化。客户端在输入数据空间优化随机初始化的数据，以捕捉全局数据分布的优势，包括模型-agnostic 学习（允许不同模型架构）、独立于模型大小的通信、兼容安全聚合以保护隐私，以及支持个性化学习。实验验证表明，CoDream 在标准 FL 任务上表现出色，尽管不共享模型参数，其性能与传统方法相当。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 12 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2402.15968v2",
      "published_date": "2024-02-25 03:07:32 UTC",
      "updated_date": "2024-02-27 17:55:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:59:49.762009"
    },
    {
      "arxiv_id": "2402.15960v2",
      "title": "Budget-Constrained Tool Learning with Planning",
      "title_zh": "预算约束下的工具学习与规划",
      "authors": [
        "Yuanhang Zheng",
        "Peng Li",
        "Ming Yan",
        "Ji Zhang",
        "Fei Huang",
        "Yang Liu"
      ],
      "abstract": "Despite intensive efforts devoted to tool learning, the problem of\nbudget-constrained tool learning, which focuses on resolving user queries\nwithin a specific budget constraint, has been widely overlooked. This paper\nproposes a novel method for budget-constrained tool learning. Our approach\ninvolves creating a preferable plan under the budget constraint before\nutilizing the tools. This plan outlines the feasible tools and the maximum\nnumber of times they can be employed, offering a comprehensive overview of the\ntool learning process for large language models. This allows them to allocate\nthe budget from a broader perspective. To devise the plan without incurring\nsignificant extra costs, we suggest initially estimating the usefulness of the\ncandidate tools based on past experience. Subsequently, we employ dynamic\nprogramming to formulate the plan. Experimental results demonstrate that our\nmethod can be integrated with various tool learning methods, significantly\nenhancing their effectiveness under strict budget constraints.",
      "tldr_zh": "这篇论文解决了预算约束下的工具学习（budget-constrained tool learning）问题，提出了一种新方法：在使用工具前创建首选计划，以概述可行工具及其最大使用次数，从而帮助大型语言模型从更广泛视角分配预算。该方法首先基于过去经验估计候选工具的有用性，然后运用动态规划（dynamic programming）来制定计划。实验结果显示，该方法可与多种工具学习方法整合，在严格预算约束下显著提升整体有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted for Findings of ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.15960v2",
      "published_date": "2024-02-25 02:46:33 UTC",
      "updated_date": "2024-06-11 01:02:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:00:01.207618"
    },
    {
      "arxiv_id": "2403.00811v3",
      "title": "Cognitive Bias in Decision-Making with LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Jessica Echterhoff",
        "Yao Liu",
        "Abeer Alessa",
        "Julian McAuley",
        "Zexue He"
      ],
      "abstract": "Large language models (LLMs) offer significant potential as tools to support\nan expanding range of decision-making tasks. Given their training on human\n(created) data, LLMs have been shown to inherit societal biases against\nprotected groups, as well as be subject to bias functionally resembling\ncognitive bias. Human-like bias can impede fair and explainable decisions made\nwith LLM assistance. Our work introduces BiasBuster, a framework designed to\nuncover, evaluate, and mitigate cognitive bias in LLMs, particularly in\nhigh-stakes decision-making tasks. Inspired by prior research in psychology and\ncognitive science, we develop a dataset containing 13,465 prompts to evaluate\nLLM decisions on different cognitive biases (e.g., prompt-induced, sequential,\ninherent). We test various bias mitigation strategies, while proposing a novel\nmethod utilizing LLMs to debias their own human-like cognitive bias within\nprompts. Our analysis provides a comprehensive picture of the presence and\neffects of cognitive bias across commercial and open-source models. We\ndemonstrate that our selfhelp debiasing effectively mitigates model answers\nthat display patterns akin to human cognitive bias without having to manually\ncraft examples for each bias.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)在决策任务中的认知偏见问题，这些偏见源于训练数据，可能导致不公平和不可解释的决策。研究引入了BiasBuster框架，受心理学和认知科学启发，开发了一个包含13,465个提示的数据集，用于评估LLMs的各种认知偏见（如prompt-induced、sequential和inherent偏见）。论文测试了多种偏见缓解策略，并提出了一种创新方法，让LLMs自行去偏，而无需手动创建示例，实验结果显示此方法能有效减少模型回答中类似人类认知偏见的模式。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.00811v3",
      "published_date": "2024-02-25 02:35:56 UTC",
      "updated_date": "2024-10-03 21:07:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:00:14.831023"
    },
    {
      "arxiv_id": "2402.18593v1",
      "title": "Sustainable Supercomputing for AI: GPU Power Capping at HPC Scale",
      "title_zh": "面向 AI 的可持续超级计算：HPC 规模下的 GPU 功率限制",
      "authors": [
        "Dan Zhao",
        "Siddharth Samsi",
        "Joseph McDonald",
        "Baolin Li",
        "David Bestor",
        "Michael Jones",
        "Devesh Tiwari",
        "Vijay Gadepally"
      ],
      "abstract": "As research and deployment of AI grows, the computational burden to support\nand sustain its progress inevitably does too. To train or fine-tune\nstate-of-the-art models in NLP, computer vision, etc., some form of AI hardware\nacceleration is virtually a requirement. Recent large language models require\nconsiderable resources to train and deploy, resulting in significant energy\nusage, potential carbon emissions, and massive demand for GPUs and other\nhardware accelerators. However, this surge carries large implications for\nenergy sustainability at the HPC/datacenter level. In this paper, we study the\naggregate effect of power-capping GPUs on GPU temperature and power draw at a\nresearch supercomputing center. With the right amount of power-capping, we show\nsignificant decreases in both temperature and power draw, reducing power\nconsumption and potentially improving hardware life-span with minimal impact on\njob performance. While power-capping reduces power draw by design, the\naggregate system-wide effect on overall energy consumption is less clear; for\ninstance, if users notice job performance degradation from GPU power-caps, they\nmay request additional GPU-jobs to compensate, negating any energy savings or\neven worsening energy consumption. To our knowledge, our work is the first to\nconduct and make available a detailed analysis of the effects of GPU\npower-capping at the supercomputing scale. We hope our work will inspire\nHPCs/datacenters to further explore, evaluate, and communicate the impact of\npower-capping AI hardware accelerators for more sustainable AI.",
      "tldr_zh": "这篇论文探讨了在高性能计算 (HPC) 规模下，通过 GPU Power Capping 来应对 AI 超算的能耗和碳排放问题。研究在超级计算中心对 GPU 进行功率限制实验，结果显示适当的限制可显著降低 GPU 温度和功率消耗，同时对作业性能影响最小，从而潜在延长硬件寿命。论文强调，虽然功率限制能减少系统能耗，但用户可能因性能下降而增加作业请求，从而抵消节能效果。该工作首次提供详细分析，并呼吁 HPC/数据中心进一步评估 GPU Power Capping，以推动更可持续的 AI 发展。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.18593v1",
      "published_date": "2024-02-25 02:22:34 UTC",
      "updated_date": "2024-02-25 02:22:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:00:26.681711"
    },
    {
      "arxiv_id": "2403.00810v1",
      "title": "Bootstrapping Cognitive Agents with a Large Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Feiyu Zhu",
        "Reid Simmons"
      ],
      "abstract": "Large language models contain noisy general knowledge of the world, yet are\nhard to train or fine-tune. On the other hand cognitive architectures have\nexcellent interpretability and are flexible to update but require a lot of\nmanual work to instantiate. In this work, we combine the best of both worlds:\nbootstrapping a cognitive-based model with the noisy knowledge encoded in large\nlanguage models. Through an embodied agent doing kitchen tasks, we show that\nour proposed framework yields better efficiency compared to an agent based\nentirely on large language models. Our experiments indicate that large language\nmodels are a good source of information for cognitive architectures, and the\ncognitive architecture in turn can verify and update the knowledge of large\nlanguage models to a specific domain.",
      "tldr_zh": "本文提出了一种框架，使用 Large Language Model 来引导 Cognitive Agents 的初始化，结合了 LLM 的通用知识和 Cognitive Architectures 的可解释性，以减少手动工作。研究通过一个执行厨房任务的 Embodied Agent 进行实验，结果显示该框架比纯基于 Large Language Models 的代理更高效。实验还表明，Large Language Models 可作为 Cognitive Architectures 的信息来源，而后者能验证和更新这些知识，使其适应特定领域，从而提升代理在特定任务中的性能。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.00810v1",
      "published_date": "2024-02-25 01:40:30 UTC",
      "updated_date": "2024-02-25 01:40:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:00:37.564550"
    },
    {
      "arxiv_id": "2402.15945v2",
      "title": "Attention-GAN for Anomaly Detection: A Cutting-Edge Approach to Cybersecurity Threat Management",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammed Abo Sen"
      ],
      "abstract": "This paper proposes an innovative Attention-GAN framework for enhancing\ncybersecurity, focusing on anomaly detection. In response to the challenges\nposed by the constantly evolving nature of cyber threats, the proposed approach\naims to generate diverse and realistic synthetic attack scenarios, thereby\nenriching the dataset and improving threat identification. Integrating\nattention mechanisms with Generative Adversarial Networks (GANs) is a key\nfeature of the proposed method. The attention mechanism enhances the model's\nability to focus on relevant features, essential for detecting subtle and\ncomplex attack patterns. In addition, GANs address the issue of data scarcity\nby generating additional varied attack data, encompassing known and emerging\nthreats. This dual approach ensures that the system remains relevant and\neffective against the continuously evolving cyberattacks. The KDD Cup and\nCICIDS2017 datasets were used to validate this model, which exhibited\nsignificant improvements in anomaly detection. It achieved an accuracy of\n99.69% on the KDD dataset and 97.93% on the CICIDS2017 dataset, with precision,\nrecall, and F1-scores above 97%, demonstrating its effectiveness in recognizing\ncomplex attack patterns. This study contributes significantly to cybersecurity\nby providing a scalable and adaptable solution for anomaly detection in the\nface of sophisticated and dynamic cyber threats. The exploration of GANs for\ndata augmentation highlights a promising direction for future research,\nparticularly in situations where data limitations restrict the development of\ncybersecurity systems. The attention-GAN framework has emerged as a pioneering\napproach, setting a new benchmark for advanced cyber-defense strategies.",
      "tldr_zh": "本研究提出了一种创新的 Attention-GAN 框架，用于提升网络安全的异常检测能力。该框架通过整合注意力机制和 GANs，生成多样且真实的合成攻击场景，解决数据稀缺问题，并帮助模型专注于相关特征，从而更有效地识别微妙和复杂的网络威胁。在 KDD Cup 和 CICIDS2017 数据集上的实验显示，该方法在 KDD 上达到 99.69% 的准确率，在 CICIDS2017 上达到 97.93%，精确率、召回率和 F1 分数均超过 97%。总体而言，该框架为动态网络威胁提供了一个可扩展、可适应的解决方案，并为未来数据增强相关研究开辟了新方向。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.15945v2",
      "published_date": "2024-02-25 01:10:55 UTC",
      "updated_date": "2024-02-27 19:27:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:00:50.346573"
    },
    {
      "arxiv_id": "2402.16906v6",
      "title": "Debug like a Human: A Large Language Model Debugger via Verifying Runtime Execution Step-by-step",
      "title_zh": "像人类一样调试：通过逐步验证运行时执行的大型语言模型调试器",
      "authors": [
        "Li Zhong",
        "Zilong Wang",
        "Jingbo Shang"
      ],
      "abstract": "Large language models (LLMs) are leading significant progress in code\ngeneration. Beyond one-pass code generation, recent works further integrate\nunit tests and program verifiers into LLMs to iteratively refine the generated\nprograms. However, these works consider the generated programs as an\nindivisible entity, which falls short for LLMs in debugging the programs,\nespecially when the programs contain complex logic flows and data operations.\nIn contrast, when human developers debug programs, they typically set\nbreakpoints and selectively examine runtime execution information. The\nexecution flow and the intermediate variables play a crucial role in the\ndebugging process, yet they are underutilized in the existing literature on\ncode generation. In this study, we introduce Large Language Model Debugger\n(LDB), a novel debugging framework that enables LLMs to refine their generated\nprograms with the runtime execution information. Specifically, LDB segments the\nprograms into basic blocks and tracks the values of intermediate variables\nafter each block throughout the runtime execution. This allows LLMs to\nconcentrate on simpler code units within the overall execution flow, verify\ntheir correctness against the task description block by block, and efficiently\npinpoint any potential errors. Experiments demonstrate that LDB consistently\nenhances the baseline performance by up to 9.8% across the HumanEval, MBPP, and\nTransCoder benchmarks, archiving new state-of-the-art performance in code\ndebugging for various LLM selections.",
      "tldr_zh": "该研究提出 Large Language Model Debugger (LDB)，一种新型框架，让 Large Language Models (LLMs) 通过逐步验证运行时执行信息来调试生成的代码，模仿人类设置断点和检查中间变量的方式。LDB 将程序分割成基本块，跟踪每个块后的中间变量值，并允许 LLMs 逐块验证代码与任务描述的正确性，从而高效定位错误。与传统方法相比，这种方法解决了 LLMs 在处理复杂逻辑和数据操作时的不足。实验结果显示，LDB 在 HumanEval、MBPP 和 TransCoder 基准上将基线性能提升高达 9.8%，实现了代码调试领域的全新最先进性能。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2402.16906v6",
      "published_date": "2024-02-25 00:56:27 UTC",
      "updated_date": "2024-06-06 06:01:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:01:02.196955"
    },
    {
      "arxiv_id": "2402.15943v2",
      "title": "Rethinking Software Engineering in the Foundation Model Era: A Curated Catalogue of Challenges in the Development of Trustworthy FMware",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmed E. Hassan",
        "Dayi Lin",
        "Gopi Krishnan Rajbahadur",
        "Keheliya Gallaba",
        "Filipe R. Cogo",
        "Boyuan Chen",
        "Haoxiang Zhang",
        "Kishanthan Thangarajah",
        "Gustavo Ansaldi Oliva",
        "Jiahuei Lin",
        "Wali Mohammad Abdullah",
        "Zhen Ming Jiang"
      ],
      "abstract": "Foundation models (FMs), such as Large Language Models (LLMs), have\nrevolutionized software development by enabling new use cases and business\nmodels. We refer to software built using FMs as FMware. The unique properties\nof FMware (e.g., prompts, agents, and the need for orchestration), coupled with\nthe intrinsic limitations of FMs (e.g., hallucination) lead to a completely new\nset of software engineering challenges. Based on our industrial experience, we\nidentified 10 key SE4FMware challenges that have caused enterprise FMware\ndevelopment to be unproductive, costly, and risky. In this paper, we discuss\nthese challenges in detail and state the path for innovation that we envision.\nNext, we present FMArts, which is our long-term effort towards creating a\ncradle-to-grave platform for the engineering of trustworthy FMware. Finally, we\n(i) show how the unique properties of FMArts enabled us to design and develop a\ncomplex FMware for a large customer in a timely manner and (ii) discuss the\nlessons that we learned in doing so. We hope that the disclosure of the\naforementioned challenges and our associated efforts to tackle them will not\nonly raise awareness but also promote deeper and further discussions, knowledge\nsharing, and innovative solutions across the software engineering discipline.",
      "tldr_zh": "本研究重新审视了基础模型（Foundation Models, FMs）时代下的软件工程，聚焦于使用 FMs（如 Large Language Models, LLMs）构建的软件（FMware）的开发挑战。作者基于工业经验，识别并详细讨论了 10 个关键软件工程挑战（SE4FMware），包括 FMware 的独特属性（如 prompts、agents 和 orchestration）以及 FMs 的固有限制（如 hallucination），这些因素导致开发过程低效、成本高昂且风险增大。论文提出 FMArts 平台作为一种端到端解决方案，支持可信 FMware 的全生命周期工程，并在实际案例中展示了其如何帮助及时开发复杂 FMware，并分享了经验教训，以促进软件工程领域的讨论、创新和知识共享。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.15943v2",
      "published_date": "2024-02-25 00:53:16 UTC",
      "updated_date": "2024-03-04 04:22:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:01:14.271763"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 49,
  "processed_papers_count": 49,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-17T10:01:32.070131"
}