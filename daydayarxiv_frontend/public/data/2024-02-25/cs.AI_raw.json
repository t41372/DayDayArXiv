[
  {
    "arxiv_id": "2403.00815v3",
    "title": "RAM-EHR: Retrieval Augmentation Meets Clinical Predictions on Electronic Health Records",
    "authors": [
      "Ran Xu",
      "Wenqi Shi",
      "Yue Yu",
      "Yuchen Zhuang",
      "Bowen Jin",
      "May D. Wang",
      "Joyce C. Ho",
      "Carl Yang"
    ],
    "abstract": "We present RAM-EHR, a Retrieval AugMentation pipeline to improve clinical\npredictions on Electronic Health Records (EHRs). RAM-EHR first collects\nmultiple knowledge sources, converts them into text format, and uses dense\nretrieval to obtain information related to medical concepts. This strategy\naddresses the difficulties associated with complex names for the concepts.\nRAM-EHR then augments the local EHR predictive model co-trained with\nconsistency regularization to capture complementary information from patient\nvisits and summarized knowledge. Experiments on two EHR datasets show the\nefficacy of RAM-EHR over previous knowledge-enhanced baselines (3.4% gain in\nAUROC and 7.2% gain in AUPR), emphasizing the effectiveness of the summarized\nknowledge from RAM-EHR for clinical prediction tasks. The code will be\npublished at \\url{https://github.com/ritaranx/RAM-EHR}.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "q-bio.OT"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL 2024 (Oral)",
    "pdf_url": "http://arxiv.org/pdf/2403.00815v3",
    "published_date": "2024-02-25 23:10:20 UTC",
    "updated_date": "2024-07-26 23:24:39 UTC"
  },
  {
    "arxiv_id": "2402.16200v2",
    "title": "IR2: Information Regularization for Information Retrieval",
    "authors": [
      "Jianyou Wang",
      "Kaicheng Wang",
      "Xiaoyue Wang",
      "Weili Cao",
      "Ramamohan Paturi",
      "Leon Bergen"
    ],
    "abstract": "Effective information retrieval (IR) in settings with limited training data,\nparticularly for complex queries, remains a challenging task. This paper\nintroduces IR2, Information Regularization for Information Retrieval, a\ntechnique for reducing overfitting during synthetic data generation. This\napproach, representing a novel application of regularization techniques in\nsynthetic data creation for IR, is tested on three recent IR tasks\ncharacterized by complex queries: DORIS-MAE, ArguAna, and WhatsThatBook.\nExperimental results indicate that our regularization techniques not only\noutperform previous synthetic query generation methods on the tasks considered\nbut also reduce cost by up to 50%. Furthermore, this paper categorizes and\nexplores three regularization methods at different stages of the query\nsynthesis pipeline-input, prompt, and output-each offering varying degrees of\nperformance improvement compared to models where no regularization is applied.\nThis provides a systematic approach for optimizing synthetic data generation in\ndata-limited, complex-query IR scenarios. All code, prompts and synthetic data\nare available at\nhttps://github.com/Info-Regularization/Information-Regularization.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted by LREC-COLING 2024 - The 2024 Joint International\n  Conference on Computational Linguistics, Language Resources and Evaluation",
    "pdf_url": "http://arxiv.org/pdf/2402.16200v2",
    "published_date": "2024-02-25 21:25:06 UTC",
    "updated_date": "2025-04-01 20:20:47 UTC"
  },
  {
    "arxiv_id": "2402.16189v1",
    "title": "One-stage Prompt-based Continual Learning",
    "authors": [
      "Youngeun Kim",
      "Yuhang Li",
      "Priyadarshini Panda"
    ],
    "abstract": "Prompt-based Continual Learning (PCL) has gained considerable attention as a\npromising continual learning solution as it achieves state-of-the-art\nperformance while preventing privacy violation and memory overhead issues.\nNonetheless, existing PCL approaches face significant computational burdens\nbecause of two Vision Transformer (ViT) feed-forward stages; one is for the\nquery ViT that generates a prompt query to select prompts inside a prompt pool;\nthe other one is a backbone ViT that mixes information between selected prompts\nand image tokens. To address this, we introduce a one-stage PCL framework by\ndirectly using the intermediate layer's token embedding as a prompt query. This\ndesign removes the need for an additional feed-forward stage for query ViT,\nresulting in ~50% computational cost reduction for both training and inference\nwith marginal accuracy drop < 1%. We further introduce a Query-Pool\nRegularization (QR) loss that regulates the relationship between the prompt\nquery and the prompt pool to improve representation power. The QR loss is only\napplied during training time, so there is no computational overhead at\ninference from the QR loss. With the QR loss, our approach maintains ~ 50%\ncomputational cost reduction during inference as well as outperforms the prior\ntwo-stage PCL methods by ~1.4% on public class-incremental continual learning\nbenchmarks including CIFAR-100, ImageNet-R, and DomainNet.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.16189v1",
    "published_date": "2024-02-25 20:30:05 UTC",
    "updated_date": "2024-02-25 20:30:05 UTC"
  },
  {
    "arxiv_id": "2402.16181v1",
    "title": "How Can LLM Guide RL? A Value-Based Approach",
    "authors": [
      "Shenao Zhang",
      "Sirui Zheng",
      "Shuqi Ke",
      "Zhihan Liu",
      "Wanxin Jin",
      "Jianbo Yuan",
      "Yingxiang Yang",
      "Hongxia Yang",
      "Zhaoran Wang"
    ],
    "abstract": "Reinforcement learning (RL) has become the de facto standard practice for\nsequential decision-making problems by improving future acting policies with\nfeedback. However, RL algorithms may require extensive trial-and-error\ninteractions to collect useful feedback for improvement. On the other hand,\nrecent developments in large language models (LLMs) have showcased impressive\ncapabilities in language understanding and generation, yet they fall short in\nexploration and self-improvement capabilities for planning tasks, lacking the\nability to autonomously refine their responses based on feedback. Therefore, in\nthis paper, we study how the policy prior provided by the LLM can enhance the\nsample efficiency of RL algorithms. Specifically, we develop an algorithm named\nLINVIT that incorporates LLM guidance as a regularization factor in value-based\nRL, leading to significant reductions in the amount of data needed for\nlearning, particularly when the difference between the ideal policy and the\nLLM-informed policy is small, which suggests that the initial policy is close\nto optimal, reducing the need for further exploration. Additionally, we present\na practical algorithm SLINVIT that simplifies the construction of the value\nfunction and employs subgoals to reduce the search complexity. Our experiments\nacross three interactive environments ALFWorld, InterCode, and BlocksWorld\ndemonstrate that our method achieves state-of-the-art success rates and also\nsurpasses previous RL and LLM approaches in terms of sample efficiency. Our\ncode is available at https://github.com/agentification/Language-Integrated-VI.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.16181v1",
    "published_date": "2024-02-25 20:07:13 UTC",
    "updated_date": "2024-02-25 20:07:13 UTC"
  },
  {
    "arxiv_id": "2402.16174v3",
    "title": "GenNBV: Generalizable Next-Best-View Policy for Active 3D Reconstruction",
    "authors": [
      "Xiao Chen",
      "Quanyi Li",
      "Tai Wang",
      "Tianfan Xue",
      "Jiangmiao Pang"
    ],
    "abstract": "While recent advances in neural radiance field enable realistic digitization\nfor large-scale scenes, the image-capturing process is still time-consuming and\nlabor-intensive. Previous works attempt to automate this process using the\nNext-Best-View (NBV) policy for active 3D reconstruction. However, the existing\nNBV policies heavily rely on hand-crafted criteria, limited action space, or\nper-scene optimized representations. These constraints limit their\ncross-dataset generalizability. To overcome them, we propose GenNBV, an\nend-to-end generalizable NBV policy. Our policy adopts a reinforcement learning\n(RL)-based framework and extends typical limited action space to 5D free space.\nIt empowers our agent drone to scan from any viewpoint, and even interact with\nunseen geometries during training. To boost the cross-dataset generalizability,\nwe also propose a novel multi-source state embedding, including geometric,\nsemantic, and action representations. We establish a benchmark using the Isaac\nGym simulator with the Houses3K and OmniObject3D datasets to evaluate this NBV\npolicy. Experiments demonstrate that our policy achieves a 98.26% and 97.12%\ncoverage ratio on unseen building-scale objects from these datasets,\nrespectively, outperforming prior solutions.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2024 accepted paper. Project page: http://gennbv.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2402.16174v3",
    "published_date": "2024-02-25 18:59:29 UTC",
    "updated_date": "2024-07-30 06:05:31 UTC"
  },
  {
    "arxiv_id": "2402.16173v1",
    "title": "Communication Traffic Characteristics Reveal an IoT Devices Identity",
    "authors": [
      "Rajarshi Roy Chowdhury",
      "Debashish Roy",
      "Pg Emeroylariffion Abas"
    ],
    "abstract": "Internet of Things (IoT) is one of the technological advancements of the\ntwenty-first century which can improve living standards. However, it also\nimposes new types of security challenges, including device authentication,\ntraffic types classification, and malicious traffic identification, in the\nnetwork domain. Traditionally, internet protocol (IP) and media access control\n(MAC) addresses are utilized for identifying network-connected devices in a\nnetwork, whilst these addressing schemes are prone to be compromised, including\nspoofing attacks and MAC randomization. Therefore, device identification using\nonly explicit identifiers is a challenging task. Accurate device identification\nplays a key role in securing a network. In this paper, a supervised machine\nlearning-based device fingerprinting (DFP) model has been proposed for\nidentifying network-connected IoT devices using only communication traffic\ncharacteristics (or implicit identifiers). A single transmission control\nprotocol/internet protocol (TCP/IP) packet header features have been utilized\nfor generating unique fingerprints, with the fingerprints represented as a\nvector of 22 features. Experimental results have shown that the proposed DFP\nmethod achieves over 98% in classifying individual IoT devices using the UNSW\ndataset with 22 smart-home IoT devices. This signifies that the proposed\napproach is invaluable to network operators in making their networks more\nsecure.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "F.2.2; I.2.7"
    ],
    "primary_category": "cs.NI",
    "comment": "16 pages",
    "pdf_url": "http://arxiv.org/pdf/2402.16173v1",
    "published_date": "2024-02-25 18:58:09 UTC",
    "updated_date": "2024-02-25 18:58:09 UTC"
  },
  {
    "arxiv_id": "2402.16168v1",
    "title": "Hitting \"Probe\"rty with Non-Linearity, and More",
    "authors": [
      "Avik Pal",
      "Madhura Pawar"
    ],
    "abstract": "Structural probes learn a linear transformation to find how dependency trees\nare embedded in the hidden states of language models. This simple design may\nnot allow for full exploitation of the structure of the encoded information.\nHence, to investigate the structure of the encoded information to its full\nextent, we incorporate non-linear structural probes. We reformulate the design\nof non-linear structural probes introduced by White et al. making its design\nsimpler yet effective. We also design a visualization framework that lets us\nqualitatively assess how strongly two words in a sentence are connected in the\npredicted dependency tree. We use this technique to understand which non-linear\nprobe variant is good at encoding syntactical information. Additionally, we\nalso use it to qualitatively investigate the structure of dependency trees that\nBERT encodes in each of its layers. We find that the radial basis function\n(RBF) is an effective non-linear probe for the BERT model than the linear\nprobe.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.16168v1",
    "published_date": "2024-02-25 18:33:25 UTC",
    "updated_date": "2024-02-25 18:33:25 UTC"
  },
  {
    "arxiv_id": "2402.16915v1",
    "title": "More Than Routing: Joint GPS and Route Modeling for Refine Trajectory Representation Learning",
    "authors": [
      "Zhipeng Ma",
      "Zheyan Tu",
      "Xinhai Chen",
      "Yan Zhang",
      "Deguo Xia",
      "Guyue Zhou",
      "Yilun Chen",
      "Yu Zheng",
      "Jiangtao Gong"
    ],
    "abstract": "Trajectory representation learning plays a pivotal role in supporting various\ndownstream tasks. Traditional methods in order to filter the noise in GPS\ntrajectories tend to focus on routing-based methods used to simplify the\ntrajectories. However, this approach ignores the motion details contained in\nthe GPS data, limiting the representation capability of trajectory\nrepresentation learning. To fill this gap, we propose a novel representation\nlearning framework that Joint GPS and Route Modelling based on self-supervised\ntechnology, namely JGRM. We consider GPS trajectory and route as the two modes\nof a single movement observation and fuse information through inter-modal\ninformation interaction. Specifically, we develop two encoders, each tailored\nto capture representations of route and GPS trajectories respectively. The\nrepresentations from the two modalities are fed into a shared transformer for\ninter-modal information interaction. Eventually, we design three\nself-supervised tasks to train the model. We validate the effectiveness of the\nproposed method on two real datasets based on extensive experiments. The\nexperimental results demonstrate that JGRM outperforms existing methods in both\nroad segment representation and trajectory representation tasks. Our source\ncode is available at Anonymous Github.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.16915v1",
    "published_date": "2024-02-25 18:27:25 UTC",
    "updated_date": "2024-02-25 18:27:25 UTC"
  },
  {
    "arxiv_id": "2402.16914v3",
    "title": "DrAttack: Prompt Decomposition and Reconstruction Makes Powerful LLM Jailbreakers",
    "authors": [
      "Xirui Li",
      "Ruochen Wang",
      "Minhao Cheng",
      "Tianyi Zhou",
      "Cho-Jui Hsieh"
    ],
    "abstract": "The safety alignment of Large Language Models (LLMs) is vulnerable to both\nmanual and automated jailbreak attacks, which adversarially trigger LLMs to\noutput harmful content. However, current methods for jailbreaking LLMs, which\nnest entire harmful prompts, are not effective at concealing malicious intent\nand can be easily identified and rejected by well-aligned LLMs. This paper\ndiscovers that decomposing a malicious prompt into separated sub-prompts can\neffectively obscure its underlying malicious intent by presenting it in a\nfragmented, less detectable form, thereby addressing these limitations. We\nintroduce an automatic prompt \\textbf{D}ecomposition and\n\\textbf{R}econstruction framework for jailbreak \\textbf{Attack} (DrAttack).\nDrAttack includes three key components: (a) `Decomposition' of the original\nprompt into sub-prompts, (b) `Reconstruction' of these sub-prompts implicitly\nby in-context learning with semantically similar but harmless reassembling\ndemo, and (c) a `Synonym Search' of sub-prompts, aiming to find sub-prompts'\nsynonyms that maintain the original intent while jailbreaking LLMs. An\nextensive empirical study across multiple open-source and closed-source LLMs\ndemonstrates that, with a significantly reduced number of queries, DrAttack\nobtains a substantial gain of success rate over prior SOTA prompt-only\nattackers. Notably, the success rate of 78.0\\% on GPT-4 with merely 15 queries\nsurpassed previous art by 33.1\\%. The project is available at\nhttps://github.com/xirui-li/DrAttack.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.16914v3",
    "published_date": "2024-02-25 17:43:29 UTC",
    "updated_date": "2024-11-11 23:08:20 UTC"
  },
  {
    "arxiv_id": "2404.16847v2",
    "title": "State-of-the-Art Approaches to Enhancing Privacy Preservation of Machine Learning Datasets: A Survey",
    "authors": [
      "Chaoyu Zhang",
      "Shaoyu Li"
    ],
    "abstract": "This paper examines the evolving landscape of machine learning (ML) and its\nprofound impact across various sectors, with a special focus on the emerging\nfield of Privacy-preserving Machine Learning (PPML). As ML applications become\nincreasingly integral to industries like telecommunications, financial\ntechnology, and surveillance, they raise significant privacy concerns,\nnecessitating the development of PPML strategies. The paper highlights the\nunique challenges in safeguarding privacy within ML frameworks, which stem from\nthe diverse capabilities of potential adversaries, including their ability to\ninfer sensitive information from model outputs or training data.\n  We delve into the spectrum of threat models that characterize adversarial\nintentions, ranging from membership and attribute inference to data\nreconstruction. The paper emphasizes the importance of maintaining the\nconfidentiality and integrity of training data, outlining current research\nefforts that focus on refining training data to minimize privacy-sensitive\ninformation and enhancing data processing techniques to uphold privacy.\n  Through a comprehensive analysis of privacy leakage risks and countermeasures\nin both centralized and collaborative learning settings, this paper aims to\nprovide a thorough understanding of effective strategies for protecting ML\ntraining data against privacy intrusions. It explores the balance between data\nprivacy and model utility, shedding light on privacy-preserving techniques that\nleverage cryptographic methods, Differential Privacy, and Trusted Execution\nEnvironments. The discussion extends to the application of these techniques in\nsensitive domains, underscoring the critical role of PPML in ensuring the\nprivacy and security of ML systems.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.16847v2",
    "published_date": "2024-02-25 17:31:06 UTC",
    "updated_date": "2025-01-28 19:03:19 UTC"
  },
  {
    "arxiv_id": "2402.16153v1",
    "title": "ChatMusician: Understanding and Generating Music Intrinsically with LLM",
    "authors": [
      "Ruibin Yuan",
      "Hanfeng Lin",
      "Yi Wang",
      "Zeyue Tian",
      "Shangda Wu",
      "Tianhao Shen",
      "Ge Zhang",
      "Yuhang Wu",
      "Cong Liu",
      "Ziya Zhou",
      "Ziyang Ma",
      "Liumeng Xue",
      "Ziyu Wang",
      "Qin Liu",
      "Tianyu Zheng",
      "Yizhi Li",
      "Yinghao Ma",
      "Yiming Liang",
      "Xiaowei Chi",
      "Ruibo Liu",
      "Zili Wang",
      "Pengfei Li",
      "Jingcheng Wu",
      "Chenghua Lin",
      "Qifeng Liu",
      "Tao Jiang",
      "Wenhao Huang",
      "Wenhu Chen",
      "Emmanouil Benetos",
      "Jie Fu",
      "Gus Xia",
      "Roger Dannenberg",
      "Wei Xue",
      "Shiyin Kang",
      "Yike Guo"
    ],
    "abstract": "While Large Language Models (LLMs) demonstrate impressive capabilities in\ntext generation, we find that their ability has yet to be generalized to music,\nhumanity's creative language. We introduce ChatMusician, an open-source LLM\nthat integrates intrinsic musical abilities. It is based on continual\npre-training and finetuning LLaMA2 on a text-compatible music representation,\nABC notation, and the music is treated as a second language. ChatMusician can\nunderstand and generate music with a pure text tokenizer without any external\nmulti-modal neural structures or tokenizers. Interestingly, endowing musical\nabilities does not harm language abilities, even achieving a slightly higher\nMMLU score. Our model is capable of composing well-structured, full-length\nmusic, conditioned on texts, chords, melodies, motifs, musical forms, etc,\nsurpassing GPT-4 baseline. On our meticulously curated college-level music\nunderstanding benchmark, MusicTheoryBench, ChatMusician surpasses LLaMA2 and\nGPT-3.5 on zero-shot setting by a noticeable margin. Our work reveals that LLMs\ncan be an excellent compressor for music, but there remains significant\nterritory to be conquered. We release our 4B token music-language corpora\nMusicPile, the collected MusicTheoryBench, code, model and demo in GitHub.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "GitHub: https://shanghaicannon.github.io/ChatMusician/",
    "pdf_url": "http://arxiv.org/pdf/2402.16153v1",
    "published_date": "2024-02-25 17:19:41 UTC",
    "updated_date": "2024-02-25 17:19:41 UTC"
  },
  {
    "arxiv_id": "2402.16142v1",
    "title": "From Text to Transformation: A Comprehensive Review of Large Language Models' Versatility",
    "authors": [
      "Pravneet Kaur",
      "Gautam Siddharth Kashyap",
      "Ankit Kumar",
      "Md Tabrez Nafis",
      "Sandeep Kumar",
      "Vikrant Shokeen"
    ],
    "abstract": "This groundbreaking study explores the expanse of Large Language Models\n(LLMs), such as Generative Pre-Trained Transformer (GPT) and Bidirectional\nEncoder Representations from Transformers (BERT) across varied domains ranging\nfrom technology, finance, healthcare to education. Despite their established\nprowess in Natural Language Processing (NLP), these LLMs have not been\nsystematically examined for their impact on domains such as fitness, and\nholistic well-being, urban planning, climate modelling as well as disaster\nmanagement. This review paper, in addition to furnishing a comprehensive\nanalysis of the vast expanse and extent of LLMs' utility in diverse domains,\nrecognizes the research gaps and realms where the potential of LLMs is yet to\nbe harnessed. This study uncovers innovative ways in which LLMs can leave a\nmark in the fields like fitness and wellbeing, urban planning, climate\nmodelling and disaster response which could inspire future researches and\napplications in the said avenues.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.16142v1",
    "published_date": "2024-02-25 16:47:59 UTC",
    "updated_date": "2024-02-25 16:47:59 UTC"
  },
  {
    "arxiv_id": "2403.03224v1",
    "title": "Reinforcement Learning Jazz Improvisation: When Music Meets Game Theory",
    "authors": [
      "Vedant Tapiavala",
      "Joshua Piesner",
      "Sourjyamoy Barman",
      "Feng Fu"
    ],
    "abstract": "Live performances of music are always charming, with the unpredictability of\nimprovisation due to the dynamic between musicians and interactions with the\naudience. Jazz improvisation is a particularly noteworthy example for further\ninvestigation from a theoretical perspective. Here, we introduce a novel\nmathematical game theory model for jazz improvisation, providing a framework\nfor studying music theory and improvisational methodologies. We use\ncomputational modeling, mainly reinforcement learning, to explore diverse\nstochastic improvisational strategies and their paired performance on\nimprovisation. We find that the most effective strategy pair is a strategy that\nreacts to the most recent payoff (Stepwise Changes) with a reinforcement\nlearning strategy limited to notes in the given chord (Chord-Following\nReinforcement Learning). Conversely, a strategy that reacts to the partner's\nlast note and attempts to harmonize with it (Harmony Prediction) strategy pair\nyields the lowest non-control payoff and highest standard deviation, indicating\nthat picking notes based on immediate reactions to the partner player can yield\ninconsistent outcomes. On average, the Chord-Following Reinforcement Learning\nstrategy demonstrates the highest mean payoff, while Harmony Prediction\nexhibits the lowest. Our work lays the foundation for promising applications\nbeyond jazz: including the use of artificial intelligence (AI) models to\nextract data from audio clips to refine musical reward systems, and training\nmachine learning (ML) models on existing jazz solos to further refine\nstrategies within the game.",
    "categories": [
      "physics.soc-ph",
      "cs.AI",
      "cs.LG",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "physics.soc-ph",
    "comment": "16 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.03224v1",
    "published_date": "2024-02-25 16:46:15 UTC",
    "updated_date": "2024-02-25 16:46:15 UTC"
  },
  {
    "arxiv_id": "2402.16139v3",
    "title": "What Generative Artificial Intelligence Means for Terminological Definitions",
    "authors": [
      "Antonio San MartÃ­n"
    ],
    "abstract": "This paper examines the impact of Generative Artificial Intelligence (GenAI)\ntools like ChatGPT on the creation and consumption of terminological\ndefinitions. From the terminologist's point of view, the strategic use of GenAI\ntools can streamline the process of crafting definitions, reducing both time\nand effort, while potentially enhancing quality. GenAI tools enable AI-assisted\nterminography, notably post-editing terminography, where the machine produces a\ndefinition that the terminologist then corrects or refines. However, the\npotential of GenAI tools to fulfill all the terminological needs of a user,\nincluding term definitions, challenges the very existence of terminological\ndefinitions and resources as we know them. Unlike terminological definitions,\nGenAI tools can describe the knowledge activated by a term in a specific\ncontext. However, a main drawback of these tools is that their output can\ncontain errors. For this reason, users requiring reliability will likely still\nresort to terminological resources for definitions. Nevertheless, with the\ninevitable integration of AI into terminology work, the distinction between\nhuman-created and AI-created content will become increasingly blurred.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "37 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2402.16139v3",
    "published_date": "2024-02-25 16:36:51 UTC",
    "updated_date": "2024-04-19 16:13:43 UTC"
  },
  {
    "arxiv_id": "2402.16132v1",
    "title": "LSTPrompt: Large Language Models as Zero-Shot Time Series Forecasters by Long-Short-Term Prompting",
    "authors": [
      "Haoxin Liu",
      "Zhiyuan Zhao",
      "Jindong Wang",
      "Harshavardhan Kamarthi",
      "B. Aditya Prakash"
    ],
    "abstract": "Time-series forecasting (TSF) finds broad applications in real-world\nscenarios. Prompting off-the-shelf Large Language Models (LLMs) demonstrates\nstrong zero-shot TSF capabilities while preserving computational efficiency.\nHowever, existing prompting methods oversimplify TSF as language next-token\npredictions, overlooking its dynamic nature and lack of integration with\nstate-of-the-art prompt strategies such as Chain-of-Thought. Thus, we propose\nLSTPrompt, a novel approach for prompting LLMs in zero-shot TSF tasks.\nLSTPrompt decomposes TSF into short-term and long-term forecasting sub-tasks,\ntailoring prompts to each. LSTPrompt guides LLMs to regularly reassess\nforecasting mechanisms to enhance adaptability. Extensive evaluations\ndemonstrate consistently better performance of LSTPrompt than existing\nprompting methods, and competitive results compared to foundation TSF models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages, 4 figures, 3 tables, 2 page references, 2 page appendix",
    "pdf_url": "http://arxiv.org/pdf/2402.16132v1",
    "published_date": "2024-02-25 16:14:26 UTC",
    "updated_date": "2024-02-25 16:14:26 UTC"
  },
  {
    "arxiv_id": "2402.16123v2",
    "title": "InstructEdit: Instruction-based Knowledge Editing for Large Language Models",
    "authors": [
      "Ningyu Zhang",
      "Bozhong Tian",
      "Siyuan Cheng",
      "Xiaozhuan Liang",
      "Yi Hu",
      "Kouying Xue",
      "Yanjie Gou",
      "Xi Chen",
      "Huajun Chen"
    ],
    "abstract": "Knowledge editing for large language models can offer an efficient solution\nto alter a model's behavior without negatively impacting the overall\nperformance. However, the current approaches encounter issues with limited\ngeneralizability across tasks, necessitating one distinct editor for each task,\nsignificantly hindering the broader applications. To address this, we take the\nfirst step to analyze the multi-task generalization issue in knowledge editing.\nSpecifically, we develop an instruction-based editing technique, termed\nInstructEdit, which facilitates the editor's adaptation to various task\nperformances simultaneously using simple instructions. With only one unified\neditor for each LLM, we empirically demonstrate that InstructEdit can improve\nthe editor's control, leading to an average 14.86% increase in Reliability in\nmulti-task editing setting. Furthermore, experiments involving holdout unseen\ntask illustrate that InstructEdit consistently surpass previous strong\nbaselines. To further investigate the underlying mechanisms of\ninstruction-based knowledge editing, we analyze the principal components of the\nediting gradient directions, which unveils that instructions can help control\noptimization direction with stronger OOD generalization. Code and datasets are\navailable in https://github.com/zjunlp/EasyEdit.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "IJCAI 2024; the project website is at\n  https://www.zjukg.org/project/InstructEdit/",
    "pdf_url": "http://arxiv.org/pdf/2402.16123v2",
    "published_date": "2024-02-25 15:46:33 UTC",
    "updated_date": "2024-04-28 12:03:38 UTC"
  },
  {
    "arxiv_id": "2402.16121v1",
    "title": "Towards Accurate Post-training Quantization for Reparameterized Models",
    "authors": [
      "Luoming Zhang",
      "Yefei He",
      "Wen Fei",
      "Zhenyu Lou",
      "Weijia Wu",
      "YangWei Ying",
      "Hong Zhou"
    ],
    "abstract": "Model reparameterization is a widely accepted technique for improving\ninference speed without compromising performance. However, current\nPost-training Quantization (PTQ) methods often lead to significant accuracy\ndegradation when applied to reparameterized models. This is primarily caused by\nchannel-specific and sample-specific outliers, which appear only at specific\nsamples and channels and impact on the selection of quantization parameters. To\naddress this issue, we propose RepAPQ, a novel framework that preserves the\naccuracy of quantized reparameterization models. Different from previous\nframeworks using Mean Squared Error (MSE) as a measurement, we utilize Mean\nAbsolute Error (MAE) to mitigate the influence of outliers on quantization\nparameters. Our framework comprises two main components: Quantization\nProtecting Reparameterization and Across-block Calibration. For effective\ncalibration, Quantization Protecting Reparameterization combines multiple\nbranches into a single convolution with an affine layer. During training, the\naffine layer accelerates convergence and amplifies the output of the\nconvolution to better accommodate samples with outliers. Additionally,\nAcross-block Calibration leverages the measurement of stage output as\nsupervision to address the gradient problem introduced by MAE and enhance the\ninterlayer correlation with quantization parameters. Comprehensive experiments\ndemonstrate the effectiveness of RepAPQ across various models and tasks. Our\nframework outperforms previous methods by approximately 1\\% for 8-bit PTQ and\n2\\% for 6-bit PTQ, showcasing its superior performance. The code is available\nat \\url{https://github.com/ilur98/DLMC-QUANT}.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.16121v1",
    "published_date": "2024-02-25 15:42:12 UTC",
    "updated_date": "2024-02-25 15:42:12 UTC"
  },
  {
    "arxiv_id": "2402.16117v1",
    "title": "RoboCodeX: Multimodal Code Generation for Robotic Behavior Synthesis",
    "authors": [
      "Yao Mu",
      "Junting Chen",
      "Qinglong Zhang",
      "Shoufa Chen",
      "Qiaojun Yu",
      "Chongjian Ge",
      "Runjian Chen",
      "Zhixuan Liang",
      "Mengkang Hu",
      "Chaofan Tao",
      "Peize Sun",
      "Haibao Yu",
      "Chao Yang",
      "Wenqi Shao",
      "Wenhai Wang",
      "Jifeng Dai",
      "Yu Qiao",
      "Mingyu Ding",
      "Ping Luo"
    ],
    "abstract": "Robotic behavior synthesis, the problem of understanding multimodal inputs\nand generating precise physical control for robots, is an important part of\nEmbodied AI. Despite successes in applying multimodal large language models for\nhigh-level understanding, it remains challenging to translate these conceptual\nunderstandings into detailed robotic actions while achieving generalization\nacross various scenarios. In this paper, we propose a tree-structured\nmultimodal code generation framework for generalized robotic behavior\nsynthesis, termed RoboCodeX. RoboCodeX decomposes high-level human instructions\ninto multiple object-centric manipulation units consisting of physical\npreferences such as affordance and safety constraints, and applies code\ngeneration to introduce generalization ability across various robotics\nplatforms. To further enhance the capability to map conceptual and perceptual\nunderstanding into control commands, a specialized multimodal reasoning dataset\nis collected for pre-training and an iterative self-updating methodology is\nintroduced for supervised fine-tuning. Extensive experiments demonstrate that\nRoboCodeX achieves state-of-the-art performance in both simulators and real\nrobots on four different kinds of manipulation tasks and one navigation task.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.16117v1",
    "published_date": "2024-02-25 15:31:43 UTC",
    "updated_date": "2024-02-25 15:31:43 UTC"
  },
  {
    "arxiv_id": "2402.16091v1",
    "title": "Bayesian Neural Network For Personalized Federated Learning Parameter Selection",
    "authors": [
      "Mengen Luo",
      "Ercan Engin Kuruoglu"
    ],
    "abstract": "Federated learning's poor performance in the presence of heterogeneous data\nremains one of the most pressing issues in the field. Personalized federated\nlearning departs from the conventional paradigm in which all clients employ the\nsame model, instead striving to discover an individualized model for each\nclient to address the heterogeneity in the data. One of such approach involves\npersonalizing specific layers of neural networks. However, prior endeavors have\nnot provided a dependable rationale, and some have selected personalized layers\nthat are entirely distinct and conflicting. In this work, we take a step\nfurther by proposing personalization at the elemental level, rather than the\ntraditional layer-level personalization. To select personalized parameters, we\nintroduce Bayesian neural networks and rely on the uncertainty they offer to\nguide our selection of personalized parameters. Finally, we validate our\nalgorithm's efficacy on several real-world datasets, demonstrating that our\nproposed approach outperforms existing baselines.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.16091v1",
    "published_date": "2024-02-25 13:37:53 UTC",
    "updated_date": "2024-02-25 13:37:53 UTC"
  },
  {
    "arxiv_id": "2402.16086v2",
    "title": "Deep Homography Estimation for Visual Place Recognition",
    "authors": [
      "Feng Lu",
      "Shuting Dong",
      "Lijun Zhang",
      "Bingxi Liu",
      "Xiangyuan Lan",
      "Dongmei Jiang",
      "Chun Yuan"
    ],
    "abstract": "Visual place recognition (VPR) is a fundamental task for many applications\nsuch as robot localization and augmented reality. Recently, the hierarchical\nVPR methods have received considerable attention due to the trade-off between\naccuracy and efficiency. They usually first use global features to retrieve the\ncandidate images, then verify the spatial consistency of matched local features\nfor re-ranking. However, the latter typically relies on the RANSAC algorithm\nfor fitting homography, which is time-consuming and non-differentiable. This\nmakes existing methods compromise to train the network only in global feature\nextraction. Here, we propose a transformer-based deep homography estimation\n(DHE) network that takes the dense feature map extracted by a backbone network\nas input and fits homography for fast and learnable geometric verification.\nMoreover, we design a re-projection error of inliers loss to train the DHE\nnetwork without additional homography labels, which can also be jointly trained\nwith the backbone network to help it extract the features that are more\nsuitable for local matching. Extensive experiments on benchmark datasets show\nthat our method can outperform several state-of-the-art methods. And it is more\nthan one order of magnitude faster than the mainstream hierarchical VPR methods\nusing RANSAC. The code is released at https://github.com/Lu-Feng/DHE-VPR.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by AAAI2024",
    "pdf_url": "http://arxiv.org/pdf/2402.16086v2",
    "published_date": "2024-02-25 13:22:17 UTC",
    "updated_date": "2024-03-18 09:33:47 UTC"
  },
  {
    "arxiv_id": "2402.16910v2",
    "title": "NeSy is alive and well: A LLM-driven symbolic approach for better code comment data generation and classification",
    "authors": [
      "Hanna Abi Akl"
    ],
    "abstract": "We present a neuro-symbolic (NeSy) workflow combining a symbolic-based\nlearning technique with a large language model (LLM) agent to generate\nsynthetic data for code comment classification in the C programming language.\nWe also show how generating controlled synthetic data using this workflow fixes\nsome of the notable weaknesses of LLM-based generation and increases the\nperformance of classical machine learning models on the code comment\nclassification task. Our best model, a Neural Network, achieves a Macro-F1\nscore of 91.412% with an increase of 1.033% after data augmentation.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "19 pages, 5 figures, accepted for the GeNeSy workshop at the Extended\n  Semantic Web Conference (ESWC) 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.16910v2",
    "published_date": "2024-02-25 13:20:13 UTC",
    "updated_date": "2024-05-24 07:11:17 UTC"
  },
  {
    "arxiv_id": "2403.00813v3",
    "title": "UrbanGPT: Spatio-Temporal Large Language Models",
    "authors": [
      "Zhonghang Li",
      "Lianghao Xia",
      "Jiabin Tang",
      "Yong Xu",
      "Lei Shi",
      "Long Xia",
      "Dawei Yin",
      "Chao Huang"
    ],
    "abstract": "Spatio-temporal prediction aims to forecast and gain insights into the\never-changing dynamics of urban environments across both time and space. Its\npurpose is to anticipate future patterns, trends, and events in diverse facets\nof urban life, including transportation, population movement, and crime rates.\nAlthough numerous efforts have been dedicated to developing neural network\ntechniques for accurate predictions on spatio-temporal data, it is important to\nnote that many of these methods heavily depend on having sufficient labeled\ndata to generate precise spatio-temporal representations. Unfortunately, the\nissue of data scarcity is pervasive in practical urban sensing scenarios.\nConsequently, it becomes necessary to build a spatio-temporal model with strong\ngeneralization capabilities across diverse spatio-temporal learning scenarios.\nTaking inspiration from the remarkable achievements of large language models\n(LLMs), our objective is to create a spatio-temporal LLM that can exhibit\nexceptional generalization capabilities across a wide range of downstream urban\ntasks. To achieve this objective, we present the UrbanGPT, which seamlessly\nintegrates a spatio-temporal dependency encoder with the instruction-tuning\nparadigm. This integration enables LLMs to comprehend the complex\ninter-dependencies across time and space, facilitating more comprehensive and\naccurate predictions under data scarcity. To validate the effectiveness of our\napproach, we conduct extensive experiments on various public datasets, covering\ndifferent spatio-temporal prediction tasks. The results consistently\ndemonstrate that our UrbanGPT, with its carefully designed architecture,\nconsistently outperforms state-of-the-art baselines. These findings highlight\nthe potential of building large language models for spatio-temporal learning,\nparticularly in zero-shot scenarios where labeled data is scarce.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by KDD'2024 as Full Paper",
    "pdf_url": "http://arxiv.org/pdf/2403.00813v3",
    "published_date": "2024-02-25 12:37:29 UTC",
    "updated_date": "2024-05-19 01:58:03 UTC"
  },
  {
    "arxiv_id": "2402.16075v4",
    "title": "Don't Start from Scratch: Behavioral Refinement via Interpolant-based Policy Diffusion",
    "authors": [
      "Kaiqi Chen",
      "Eugene Lim",
      "Kelvin Lin",
      "Yiyang Chen",
      "Harold Soh"
    ],
    "abstract": "Imitation learning empowers artificial agents to mimic behavior by learning\nfrom demonstrations. Recently, diffusion models, which have the ability to\nmodel high-dimensional and multimodal distributions, have shown impressive\nperformance on imitation learning tasks. These models learn to shape a policy\nby diffusing actions (or states) from standard Gaussian noise. However, the\ntarget policy to be learned is often significantly different from Gaussian and\nthis mismatch can result in poor performance when using a small number of\ndiffusion steps (to improve inference speed) and under limited data. The key\nidea in this work is that initiating from a more informative source than\nGaussian enables diffusion methods to mitigate the above limitations. We\ncontribute both theoretical results, a new method, and empirical findings that\nshow the benefits of using an informative source policy. Our method, which we\ncall BRIDGER, leverages the stochastic interpolants framework to bridge\narbitrary policies, thus enabling a flexible approach towards imitation\nlearning. It generalizes prior work in that standard Gaussians can still be\napplied, but other source policies can be used if available. In experiments on\nchallenging simulation benchmarks and on real robots, BRIDGER outperforms\nstate-of-the-art diffusion policies. We provide further analysis on design\nconsiderations when applying BRIDGER. Code for BRIDGER is available at\nhttps://github.com/clear-nus/bridger.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.16075v4",
    "published_date": "2024-02-25 12:19:21 UTC",
    "updated_date": "2024-07-11 03:41:42 UTC"
  },
  {
    "arxiv_id": "2402.16073v2",
    "title": "Pfeed: Generating near real-time personalized feeds using precomputed embedding similarities",
    "authors": [
      "Binyam Gebre",
      "Karoliina Ranta",
      "Stef van den Elzen",
      "Ernst Kuiper",
      "Thijs Baars",
      "Tom Heskes"
    ],
    "abstract": "In personalized recommender systems, embeddings are often used to encode\ncustomer actions and items, and retrieval is then performed in the embedding\nspace using approximate nearest neighbor search. However, this approach can\nlead to two challenges: 1) user embeddings can restrict the diversity of\ninterests captured and 2) the need to keep them up-to-date requires an\nexpensive, real-time infrastructure. In this paper, we propose a method that\novercomes these challenges in a practical, industrial setting. The method\ndynamically updates customer profiles and composes a feed every two minutes,\nemploying precomputed embeddings and their respective similarities. We tested\nand deployed this method to personalise promotional items at Bol, one of the\nlargest e-commerce platforms of the Netherlands and Belgium. The method\nenhanced customer engagement and experience, leading to a significant 4.9%\nuplift in conversions.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG",
      "H.3.3"
    ],
    "primary_category": "cs.IR",
    "comment": "9 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.16073v2",
    "published_date": "2024-02-25 12:06:33 UTC",
    "updated_date": "2024-03-06 10:03:06 UTC"
  },
  {
    "arxiv_id": "2402.16068v3",
    "title": "ROS-Causal: A ROS-based Causal Analysis Framework for Human-Robot Interaction Applications",
    "authors": [
      "Luca Castri",
      "Gloria Beraldo",
      "Sariah Mghames",
      "Marc Hanheide",
      "Nicola Bellotto"
    ],
    "abstract": "Deploying robots in human-shared spaces requires understanding interactions\namong nearby agents and objects. Modelling cause-and-effect relations through\ncausal inference aids in predicting human behaviours and anticipating robot\ninterventions. However, a critical challenge arises as existing causal\ndiscovery methods currently lack an implementation inside the ROS ecosystem,\nthe standard de facto in robotics, hindering effective utilisation in robotics.\nTo address this gap, this paper introduces ROS-Causal, a ROS-based framework\nfor onboard data collection and causal discovery in human-robot spatial\ninteractions. An ad-hoc simulator, integrated with ROS, illustrates the\napproach's effectiveness, showcasing the robot onboard generation of causal\nmodels during data collection. ROS-Causal is available on GitHub:\nhttps://github.com/lcastri/roscausal.git.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted by the \"Causal-HRI: Causal Learning for Human-Robot\n  Interaction\" workshop at the 2024 ACM/IEEE International Conference on\n  Human-Robot Interaction (HRI)",
    "pdf_url": "http://arxiv.org/pdf/2402.16068v3",
    "published_date": "2024-02-25 11:37:23 UTC",
    "updated_date": "2024-03-21 11:58:49 UTC"
  },
  {
    "arxiv_id": "2402.16063v4",
    "title": "Citation-Enhanced Generation for LLM-based Chatbots",
    "authors": [
      "Weitao Li",
      "Junkai Li",
      "Weizhi Ma",
      "Yang Liu"
    ],
    "abstract": "Large language models (LLMs) exhibit powerful general intelligence across\ndiverse scenarios, including their integration into chatbots. However, a vital\nchallenge of LLM-based chatbots is that they may produce hallucinated content\nin responses, which significantly limits their applicability. Various efforts\nhave been made to alleviate hallucination, such as retrieval augmented\ngeneration and reinforcement learning with human feedback, but most of them\nrequire additional training and data annotation. In this paper, we propose a\nnovel post-hoc Citation-Enhanced Generation (CEG) approach combined with\nretrieval argumentation. Unlike previous studies that focus on preventing\nhallucinations during generation, our method addresses this issue in a post-hoc\nway. It incorporates a retrieval module to search for supporting documents\nrelevant to the generated content, and employs a natural language\ninference-based citation generation module. Once the statements in the\ngenerated content lack of reference, our model can regenerate responses until\nall statements are supported by citations. Note that our method is a\ntraining-free plug-and-play plugin that is capable of various LLMs. Experiments\non various hallucination-related datasets show our framework outperforms\nstate-of-the-art methods in both hallucination detection and response\nregeneration on three benchmarks. Our codes and dataset will be publicly\navailable.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.16063v4",
    "published_date": "2024-02-25 11:24:41 UTC",
    "updated_date": "2025-04-17 17:28:29 UTC"
  },
  {
    "arxiv_id": "2403.12077v1",
    "title": "Evaluating Robustness of Generative Search Engine on Adversarial Factual Questions",
    "authors": [
      "Xuming Hu",
      "Xiaochuan Li",
      "Junzhe Chen",
      "Yinghui Li",
      "Yangning Li",
      "Xiaoguang Li",
      "Yasheng Wang",
      "Qun Liu",
      "Lijie Wen",
      "Philip S. Yu",
      "Zhijiang Guo"
    ],
    "abstract": "Generative search engines have the potential to transform how people seek\ninformation online, but generated responses from existing large language models\n(LLMs)-backed generative search engines may not always be accurate.\nNonetheless, retrieval-augmented generation exacerbates safety concerns, since\nadversaries may successfully evade the entire system by subtly manipulating the\nmost vulnerable part of a claim. To this end, we propose evaluating the\nrobustness of generative search engines in the realistic and high-risk setting,\nwhere adversaries have only black-box system access and seek to deceive the\nmodel into returning incorrect responses. Through a comprehensive human\nevaluation of various generative search engines, such as Bing Chat,\nPerplexityAI, and YouChat across diverse queries, we demonstrate the\neffectiveness of adversarial factual questions in inducing incorrect responses.\nMoreover, retrieval-augmented generation exhibits a higher susceptibility to\nfactual errors compared to LLMs without retrieval. These findings highlight the\npotential security risks of these systems and emphasize the need for rigorous\nevaluation before deployment.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "21 pages, 7 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2403.12077v1",
    "published_date": "2024-02-25 11:22:19 UTC",
    "updated_date": "2024-02-25 11:22:19 UTC"
  },
  {
    "arxiv_id": "2402.16052v1",
    "title": "Maximizing UAV Fog Deployment Efficiency for Critical Rescue Operations",
    "authors": [
      "Abdenacer Naouri",
      "Huansheng Ning",
      "Nabil Abdelkader Nouri",
      "Amar Khelloufi",
      "Abdelkarim Ben Sada",
      "Salim Naouri",
      "Attia Qammar",
      "Sahraoui Dhelim"
    ],
    "abstract": "In disaster scenarios and high-stakes rescue operations, integrating Unmanned\nAerial Vehicles (UAVs) as fog nodes has become crucial. This integration\nensures a smooth connection between affected populations and essential health\nmonitoring devices, supported by the Internet of Things (IoT). Integrating UAVs\nin such environments is inherently challenging, where the primary objectives\ninvolve maximizing network connectivity and coverage while extending the\nnetwork's lifetime through energy-efficient strategies to serve the maximum\nnumber of affected individuals. In this paper, We propose a novel model centred\naround dynamic UAV-based fog deployment that optimizes the system's\nadaptability and operational efficacy within the afflicted areas. First, we\ndecomposed the problem into two subproblems. Connectivity and coverage\nsubproblem, and network lifespan optimization subproblem. We shape our UAV fog\ndeployment problem as a uni-objective optimization and introduce a specialized\nUAV fog deployment algorithm tailored specifically for UAV fog nodes deployed\nin rescue missions. While the network lifespan optimization subproblem is\nefficiently solved via a one-dimensional swapping method. Following that, We\nintroduce a novel optimization strategy for UAV fog node placement in dynamic\nnetworks during evacuation scenarios, with a primary focus on ensuring robust\nconnectivity and maximal coverage for mobile users, while extending the\nnetwork's lifespan. Finally, we introduce Adaptive Whale Optimization Algorithm\n(WOA) for fog node deployment in a dynamic network. Its agility, rapid\nconvergence, and low computational demands make it an ideal fit for\nhigh-pressure environments.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.16052v1",
    "published_date": "2024-02-25 10:32:18 UTC",
    "updated_date": "2024-02-25 10:32:18 UTC"
  },
  {
    "arxiv_id": "2402.16048v3",
    "title": "How Likely Do LLMs with CoT Mimic Human Reasoning?",
    "authors": [
      "Guangsheng Bao",
      "Hongbo Zhang",
      "Cunxiang Wang",
      "Linyi Yang",
      "Yue Zhang"
    ],
    "abstract": "Chain-of-thought emerges as a promising technique for eliciting reasoning\ncapabilities from Large Language Models (LLMs). However, it does not always\nimprove task performance or accurately represent reasoning processes, leaving\nunresolved questions about its usage. In this paper, we diagnose the underlying\nmechanism by comparing the reasoning process of LLMs with humans, using causal\nanalysis to understand the relationships between the problem instruction,\nreasoning, and the answer in LLMs. Our empirical study reveals that LLMs often\ndeviate from the ideal causal chain, resulting in spurious correlations and\npotential consistency errors (inconsistent reasoning and answers). We also\nexamine various factors influencing the causal structure, finding that\nin-context learning with examples strengthens it, while post-training\ntechniques like supervised fine-tuning and reinforcement learning on human\nfeedback weaken it. To our surprise, the causal structure cannot be\nstrengthened by enlarging the model size only, urging research on new\ntechniques. We hope that this preliminary study will shed light on\nunderstanding and improving the reasoning process in LLM.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "COLING 2025 Camera Version (8 pages, 3 figures, 18 tables)",
    "pdf_url": "http://arxiv.org/pdf/2402.16048v3",
    "published_date": "2024-02-25 10:13:04 UTC",
    "updated_date": "2024-12-12 12:01:43 UTC"
  },
  {
    "arxiv_id": "2402.16038v1",
    "title": "Deep Learning Approaches for Improving Question Answering Systems in Hepatocellular Carcinoma Research",
    "authors": [
      "Shuning Huo",
      "Yafei Xiang",
      "Hanyi Yu",
      "Mengran Zhu",
      "Yulu Gong"
    ],
    "abstract": "In recent years, advancements in natural language processing (NLP) have been\nfueled by deep learning techniques, particularly through the utilization of\npowerful computing resources like GPUs and TPUs. Models such as BERT and GPT-3,\ntrained on vast amounts of data, have revolutionized language understanding and\ngeneration. These pre-trained models serve as robust bases for various tasks\nincluding semantic understanding, intelligent writing, and reasoning, paving\nthe way for a more generalized form of artificial intelligence. NLP, as a vital\napplication of AI, aims to bridge the gap between humans and computers through\nnatural language interaction. This paper delves into the current landscape and\nfuture prospects of large-scale model-based NLP, focusing on the\nquestion-answering systems within this domain. Practical cases and developments\nin artificial intelligence-driven question-answering systems are analyzed to\nfoster further exploration and research in the realm of large-scale NLP.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.16038v1",
    "published_date": "2024-02-25 09:32:17 UTC",
    "updated_date": "2024-02-25 09:32:17 UTC"
  },
  {
    "arxiv_id": "2402.16035v1",
    "title": "Text Understanding and Generation Using Transformer Models for Intelligent E-commerce Recommendations",
    "authors": [
      "Yafei Xiang",
      "Hanyi Yu",
      "Yulu Gong",
      "Shuning Huo",
      "Mengran Zhu"
    ],
    "abstract": "With the rapid development of artificial intelligence technology, Transformer\nstructural pre-training model has become an important tool for large language\nmodel (LLM) tasks. In the field of e-commerce, these models are especially\nwidely used, from text understanding to generating recommendation systems,\nwhich provide powerful technical support for improving user experience and\noptimizing service processes. This paper reviews the core application scenarios\nof Transformer pre-training model in e-commerce text understanding and\nrecommendation generation, including but not limited to automatic generation of\nproduct descriptions, sentiment analysis of user comments, construction of\npersonalized recommendation system and automated processing of customer service\nconversations. Through a detailed analysis of the model's working principle,\nimplementation process, and application effects in specific cases, this paper\nemphasizes the unique advantages of pre-trained models in understanding complex\nuser intentions and improving the quality of recommendations. In addition, the\nchallenges and improvement directions for the future are also discussed, such\nas how to further improve the generalization ability of the model, the ability\nto handle large-scale data sets, and technical strategies to protect user\nprivacy. Ultimately, the paper points out that the application of Transformer\nstructural pre-training models in e-commerce has not only driven technological\ninnovation, but also brought substantial benefits to merchants and consumers,\nand looking forward, these models will continue to play a key role in\ne-commerce and beyond.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.16035v1",
    "published_date": "2024-02-25 09:19:11 UTC",
    "updated_date": "2024-02-25 09:19:11 UTC"
  },
  {
    "arxiv_id": "2402.16034v2",
    "title": "Emotion Classification in Short English Texts using Deep Learning Techniques",
    "authors": [
      "Siddhanth Bhat"
    ],
    "abstract": "Detecting emotions in limited text datasets from under-resourced languages\npresents a formidable obstacle, demanding specialized frameworks and\ncomputational strategies. This study conducts a thorough examination of deep\nlearning techniques for discerning emotions in short English texts. Deep\nlearning approaches employ transfer learning and word embedding, notably BERT,\nto attain superior accuracy. To evaluate these methods, we introduce the\n\"SmallEnglishEmotions\" dataset, comprising 6372 varied short English texts\nannotated with five primary emotion categories. Our experiments reveal that\ntransfer learning and BERT-based text embedding outperform alternative methods\nin accurately categorizing the text in the dataset.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.16034v2",
    "published_date": "2024-02-25 09:17:22 UTC",
    "updated_date": "2024-03-10 15:58:56 UTC"
  },
  {
    "arxiv_id": "2402.16030v1",
    "title": "Don't Forget Your Reward Values: Language Model Alignment via Value-based Calibration",
    "authors": [
      "Xin Mao",
      "Feng-Lin Li",
      "Huimin Xu",
      "Wei Zhang",
      "Anh Tuan Luu"
    ],
    "abstract": "While Reinforcement Learning from Human Feedback (RLHF) significantly\nenhances the generation quality of Large Language Models (LLMs), recent studies\nhave raised concerns regarding the complexity and instability associated with\nthe Proximal Policy Optimization (PPO) algorithm, proposing a series of\norder-based calibration methods as viable alternatives. This paper delves\nfurther into current order-based methods, examining their inefficiencies in\nutilizing reward values and addressing misalignment issues. Building upon these\nfindings, we propose a novel \\textbf{V}alue-based \\textbf{C}ali\\textbf{B}ration\n(VCB) method to better align LLMs with human preferences. Experimental results\ndemonstrate that VCB surpasses existing alignment methods on AI assistant and\nsummarization datasets, providing impressive generalizability, robustness, and\nstability in diverse settings.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "19 pages, Under review",
    "pdf_url": "http://arxiv.org/pdf/2402.16030v1",
    "published_date": "2024-02-25 08:45:10 UTC",
    "updated_date": "2024-02-25 08:45:10 UTC"
  },
  {
    "arxiv_id": "2402.16021v1",
    "title": "TMT: Tri-Modal Translation between Speech, Image, and Text by Processing Different Modalities as Different Languages",
    "authors": [
      "Minsu Kim",
      "Jee-weon Jung",
      "Hyeongseop Rha",
      "Soumi Maiti",
      "Siddhant Arora",
      "Xuankai Chang",
      "Shinji Watanabe",
      "Yong Man Ro"
    ],
    "abstract": "The capability to jointly process multi-modal information is becoming an\nessential task. However, the limited number of paired multi-modal data and the\nlarge computational requirements in multi-modal learning hinder the\ndevelopment. We propose a novel Tri-Modal Translation (TMT) model that\ntranslates between arbitrary modalities spanning speech, image, and text. We\nintroduce a novel viewpoint, where we interpret different modalities as\ndifferent languages, and treat multi-modal translation as a well-established\nmachine translation problem. To this end, we tokenize speech and image data\ninto discrete tokens, which provide a unified interface across modalities and\nsignificantly decrease the computational cost. In the proposed TMT, a\nmulti-modal encoder-decoder conducts the core translation, whereas\nmodality-specific processing is conducted only within the tokenization and\ndetokenization stages. We evaluate the proposed TMT on all six modality\ntranslation tasks. TMT outperforms single model counterparts consistently,\ndemonstrating that unifying tasks is beneficial not only for practicality but\nalso for performance.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.16021v1",
    "published_date": "2024-02-25 07:46:57 UTC",
    "updated_date": "2024-02-25 07:46:57 UTC"
  },
  {
    "arxiv_id": "2402.16014v2",
    "title": "Building Flexible Machine Learning Models for Scientific Computing at Scale",
    "authors": [
      "Tianyu Chen",
      "Haoyi Zhou",
      "Ying Li",
      "Hao Wang",
      "Chonghan Gao",
      "Rongye Shi",
      "Shanghang Zhang",
      "Jianxin Li"
    ],
    "abstract": "Foundation models have revolutionized language modeling, while whether this\nsuccess is replicated in scientific computing remains unexplored. We present\nOmniArch, the first prototype aiming at solving multi-scale and multi-physics\nscientific computing problems with physical alignment. We addressed all three\nchallenges with one unified architecture. Its pre-training stage contains a\nFourier Encoder-decoder fading out the disharmony across separated dimensions\nand a Transformer backbone integrating quantities through temporal dynamics,\nand the novel PDE-Aligner performs physics-informed fine-tuning under flexible\nconditions. As far as we know, we first conduct 1D-2D-3D united pre-training on\nthe PDEBench, and it sets not only new performance benchmarks for 1D, 2D, and\n3D PDEs but also demonstrates exceptional adaptability to new physics via\nin-context and zero-shot learning approaches, which supports realistic\nengineering applications and foresight physics discovery.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Work in Progress",
    "pdf_url": "http://arxiv.org/pdf/2402.16014v2",
    "published_date": "2024-02-25 07:19:01 UTC",
    "updated_date": "2024-10-13 14:54:14 UTC"
  },
  {
    "arxiv_id": "2403.00812v2",
    "title": "LoRA Meets Dropout under a Unified Framework",
    "authors": [
      "Sheng Wang",
      "Liheng Chen",
      "Jiyue Jiang",
      "Boyang Xue",
      "Lingpeng Kong",
      "Chuan Wu"
    ],
    "abstract": "With the remarkable capabilities, large language models (LLMs) have emerged\nas essential elements in numerous NLP applications, while parameter-efficient\nfinetuning, especially LoRA, has gained popularity as a lightweight approach\nfor model customization. Meanwhile, various dropout methods, initially designed\nfor full finetuning with all the parameters updated, alleviates overfitting\nassociated with excessive parameter redundancy. Hence, a possible contradiction\narises from negligible trainable parameters of LoRA and the effectiveness of\nprevious dropout methods, which has been largely overlooked. To fill this gap,\nwe first confirm that parameter-efficient LoRA is also overfitting-prone. We\nthen revisit transformer-specific dropout methods, and establish their\nequivalence and distinctions mathematically and empirically. Building upon this\ncomparative analysis, we introduce a unified framework for a comprehensive\ninvestigation, which instantiates these methods based on dropping position,\nstructural pattern and compensation measure. Through this framework, we reveal\nthe new preferences and performance comparisons of them when involved with\nlimited trainable parameters. This framework also allows us to amalgamate the\nmost favorable aspects into a novel dropout method named HiddenKey. Extensive\nexperiments verify the remarkable superiority and sufficiency of HiddenKey\nacross multiple models and tasks, which highlights it as the preferred approach\nfor high-performance and parameter-efficient finetuning of LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00812v2",
    "published_date": "2024-02-25 07:09:10 UTC",
    "updated_date": "2024-05-27 02:16:43 UTC"
  },
  {
    "arxiv_id": "2402.16012v1",
    "title": "Deep Contrastive Graph Learning with Clustering-Oriented Guidance",
    "authors": [
      "Mulin Chen",
      "Bocheng Wang",
      "Xuelong Li"
    ],
    "abstract": "Graph Convolutional Network (GCN) has exhibited remarkable potential in\nimproving graph-based clustering. To handle the general clustering scenario\nwithout a prior graph, these models estimate an initial graph beforehand to\napply GCN. Throughout the literature, we have witnessed that 1) most models\nfocus on the initial graph while neglecting the original features. Therefore,\nthe discriminability of the learned representation may be corrupted by a\nlow-quality initial graph; 2) the training procedure lacks effective clustering\nguidance, which may lead to the incorporation of clustering-irrelevant\ninformation into the learned graph. To tackle these problems, the Deep\nContrastive Graph Learning (DCGL) model is proposed for general data\nclustering. Specifically, we establish a pseudo-siamese network, which\nincorporates auto-encoder with GCN to emphasize both the graph structure and\nthe original features. On this basis, feature-level contrastive learning is\nintroduced to enhance the discriminative capacity, and the relationship between\nsamples and centroids is employed as the clustering-oriented guidance.\nAfterward, a two-branch graph learning mechanism is designed to extract the\nlocal and global structural relationships, which are further embedded into a\nunified graph under the cluster-level contrastive guidance. Experimental\nresults on several benchmark datasets demonstrate the superiority of DCGL\nagainst state-of-the-art algorithms.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accept at AAAI24",
    "pdf_url": "http://arxiv.org/pdf/2402.16012v1",
    "published_date": "2024-02-25 07:03:37 UTC",
    "updated_date": "2024-02-25 07:03:37 UTC"
  },
  {
    "arxiv_id": "2402.16002v1",
    "title": "Post-Quantum Cryptography Neural Network",
    "authors": [
      "Abel C. H. Chen"
    ],
    "abstract": "In recent years, quantum computers and Shor quantum algorithm have posed a\nthreat to current mainstream asymmetric cryptography methods (e.g. RSA and\nElliptic Curve Cryptography (ECC)). Therefore, it is necessary to construct a\nPost-Quantum Cryptography (PQC) method to resist quantum computing attacks.\nTherefore, this study proposes a PQC-based neural network that maps a\ncode-based PQC method to a neural network structure and enhances the security\nof ciphertexts with non-linear activation functions, random perturbation of\nciphertexts, and uniform distribution of ciphertexts. In practical experiments,\nthis study uses cellular network signals as a case study to demonstrate that\nencryption and decryption can be performed by the proposed PQC-based neural\nnetwork with the uniform distribution of ciphertexts. In the future, the\nproposed PQC-based neural network could be applied to various applications.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "2023 International Conference on Smart Systems for applications in\n  Electrical Sciences (ICSSES) 7-8 July 2023. The manuscript was written in\n  Chinese and submitted on 10 March 2023, but it was rejected on 22 April 2023.\n  The appeal was accepted on 24 February 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.16002v1",
    "published_date": "2024-02-25 06:19:04 UTC",
    "updated_date": "2024-02-25 06:19:04 UTC"
  },
  {
    "arxiv_id": "2402.15990v2",
    "title": "An Empirical Study of Challenges in Machine Learning Asset Management",
    "authors": [
      "Zhimin Zhao",
      "Yihao Chen",
      "Abdul Ali Bangash",
      "Bram Adams",
      "Ahmed E. Hassan"
    ],
    "abstract": "In machine learning (ML), efficient asset management, including ML models,\ndatasets, algorithms, and tools, is vital for resource optimization, consistent\nperformance, and a streamlined development lifecycle. This enables quicker\niterations, adaptability, reduced development-to-deployment time, and reliable\noutputs. Despite existing research, a significant knowledge gap remains in\noperational challenges like model versioning, data traceability, and\ncollaboration, which are crucial for the success of ML projects. Our study aims\nto address this gap by analyzing 15,065 posts from developer forums and\nplatforms, employing a mixed-method approach to classify inquiries, extract\nchallenges using BERTopic, and identify solutions through open card sorting and\nBERTopic clustering. We uncover 133 topics related to asset management\nchallenges, grouped into 16 macro-topics, with software dependency, model\ndeployment, and model training being the most discussed. We also find 79\nsolution topics, categorized under 18 macro-topics, highlighting software\ndependency, feature development, and file management as key solutions. This\nresearch underscores the need for further exploration of identified pain points\nand the importance of collaborative efforts across academia, industry, and the\nresearch community.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.15990v2",
    "published_date": "2024-02-25 05:05:52 UTC",
    "updated_date": "2024-02-28 05:58:18 UTC"
  },
  {
    "arxiv_id": "2402.15989v1",
    "title": "PIDformer: Transformer Meets Control Theory",
    "authors": [
      "Tam Nguyen",
      "CÃ©sar A. Uribe",
      "Tan M. Nguyen",
      "Richard G. Baraniuk"
    ],
    "abstract": "In this work, we address two main shortcomings of transformer architectures:\ninput corruption and rank collapse in their output representation. We unveil\nself-attention as an autonomous state-space model that inherently promotes\nsmoothness in its solutions, leading to lower-rank outputs and diminished\nrepresentation capacity. Moreover, the steady-state solution of the model is\nsensitive to input perturbations. We incorporate a\nProportional-Integral-Derivative (PID) closed-loop feedback control system with\na reference point into the model to improve robustness and representation\ncapacity. This integration aims to preserve high-frequency details while\nbolstering model stability, rendering it more noise-resilient. The resulting\ncontrolled state-space model is theoretically proven robust and adept at\naddressing the rank collapse. Motivated by this control framework, we derive a\nnovel class of transformers, PID-controlled Transformer (PIDformer), aimed at\nimproving robustness and mitigating the rank-collapse issue inherent in softmax\ntransformers. We empirically evaluate the model for advantages and robustness\nagainst baseline transformers across various practical tasks, including object\nclassification, image segmentation, and language modeling.",
    "categories": [
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.15989v1",
    "published_date": "2024-02-25 05:04:51 UTC",
    "updated_date": "2024-02-25 05:04:51 UTC"
  },
  {
    "arxiv_id": "2402.15987v3",
    "title": "Likelihood-based Mitigation of Evaluation Bias in Large Language Models",
    "authors": [
      "Masanari Ohi",
      "Masahiro Kaneko",
      "Ryuto Koike",
      "Mengsay Loem",
      "Naoaki Okazaki"
    ],
    "abstract": "Large Language Models (LLMs) are widely used to evaluate natural language\ngeneration tasks as automated metrics. However, the likelihood, a measure of\nLLM's plausibility for a sentence, can vary due to superficial differences in\nsentences, such as word order and sentence structure. It is therefore possible\nthat there might be a likelihood bias if LLMs are used for evaluation: they\nmight overrate sentences with higher likelihoods while underrating those with\nlower likelihoods. In this paper, we investigate the presence and impact of\nlikelihood bias in LLM-based evaluators. We also propose a method to mitigate\nthe likelihood bias. Our method utilizes highly biased instances as few-shot\nexamples for in-context learning. Our experiments in evaluating the\ndata-to-text and grammatical error correction tasks reveal that several LLMs we\ntest display a likelihood bias. Furthermore, our proposed method successfully\nmitigates this bias, also improving evaluation performance (in terms of\ncorrelation of models with human scores) significantly.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "5 main pages",
    "pdf_url": "http://arxiv.org/pdf/2402.15987v3",
    "published_date": "2024-02-25 04:52:02 UTC",
    "updated_date": "2024-10-12 09:57:43 UTC"
  },
  {
    "arxiv_id": "2402.15968v2",
    "title": "CoDream: Exchanging dreams instead of models for federated aggregation with heterogeneous models",
    "authors": [
      "Abhishek Singh",
      "Gauri Gupta",
      "Ritvik Kapila",
      "Yichuan Shi",
      "Alex Dang",
      "Sheshank Shankar",
      "Mohammed Ehab",
      "Ramesh Raskar"
    ],
    "abstract": "Federated Learning (FL) enables collaborative optimization of machine\nlearning models across decentralized data by aggregating model parameters. Our\napproach extends this concept by aggregating \"knowledge\" derived from models,\ninstead of model parameters. We present a novel framework called CoDream, where\nclients collaboratively optimize randomly initialized data using federated\noptimization in the input data space, similar to how randomly initialized model\nparameters are optimized in FL. Our key insight is that jointly optimizing this\ndata can effectively capture the properties of the global data distribution.\nSharing knowledge in data space offers numerous benefits: (1) model-agnostic\ncollaborative learning, i.e., different clients can have different model\narchitectures; (2) communication that is independent of the model size,\neliminating scalability concerns with model parameters; (3) compatibility with\nsecure aggregation, thus preserving the privacy benefits of federated learning;\n(4) allowing of adaptive optimization of knowledge shared for personalized\nlearning. We empirically validate CoDream on standard FL tasks, demonstrating\ncompetitive performance despite not sharing model parameters. Our code:\nhttps://mitmedialab.github.io/codream.github.io/",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "16 pages, 12 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2402.15968v2",
    "published_date": "2024-02-25 03:07:32 UTC",
    "updated_date": "2024-02-27 17:55:44 UTC"
  },
  {
    "arxiv_id": "2402.15960v2",
    "title": "Budget-Constrained Tool Learning with Planning",
    "authors": [
      "Yuanhang Zheng",
      "Peng Li",
      "Ming Yan",
      "Ji Zhang",
      "Fei Huang",
      "Yang Liu"
    ],
    "abstract": "Despite intensive efforts devoted to tool learning, the problem of\nbudget-constrained tool learning, which focuses on resolving user queries\nwithin a specific budget constraint, has been widely overlooked. This paper\nproposes a novel method for budget-constrained tool learning. Our approach\ninvolves creating a preferable plan under the budget constraint before\nutilizing the tools. This plan outlines the feasible tools and the maximum\nnumber of times they can be employed, offering a comprehensive overview of the\ntool learning process for large language models. This allows them to allocate\nthe budget from a broader perspective. To devise the plan without incurring\nsignificant extra costs, we suggest initially estimating the usefulness of the\ncandidate tools based on past experience. Subsequently, we employ dynamic\nprogramming to formulate the plan. Experimental results demonstrate that our\nmethod can be integrated with various tool learning methods, significantly\nenhancing their effectiveness under strict budget constraints.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted for Findings of ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.15960v2",
    "published_date": "2024-02-25 02:46:33 UTC",
    "updated_date": "2024-06-11 01:02:19 UTC"
  },
  {
    "arxiv_id": "2403.00811v3",
    "title": "Cognitive Bias in Decision-Making with LLMs",
    "authors": [
      "Jessica Echterhoff",
      "Yao Liu",
      "Abeer Alessa",
      "Julian McAuley",
      "Zexue He"
    ],
    "abstract": "Large language models (LLMs) offer significant potential as tools to support\nan expanding range of decision-making tasks. Given their training on human\n(created) data, LLMs have been shown to inherit societal biases against\nprotected groups, as well as be subject to bias functionally resembling\ncognitive bias. Human-like bias can impede fair and explainable decisions made\nwith LLM assistance. Our work introduces BiasBuster, a framework designed to\nuncover, evaluate, and mitigate cognitive bias in LLMs, particularly in\nhigh-stakes decision-making tasks. Inspired by prior research in psychology and\ncognitive science, we develop a dataset containing 13,465 prompts to evaluate\nLLM decisions on different cognitive biases (e.g., prompt-induced, sequential,\ninherent). We test various bias mitigation strategies, while proposing a novel\nmethod utilizing LLMs to debias their own human-like cognitive bias within\nprompts. Our analysis provides a comprehensive picture of the presence and\neffects of cognitive bias across commercial and open-source models. We\ndemonstrate that our selfhelp debiasing effectively mitigates model answers\nthat display patterns akin to human cognitive bias without having to manually\ncraft examples for each bias.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00811v3",
    "published_date": "2024-02-25 02:35:56 UTC",
    "updated_date": "2024-10-03 21:07:09 UTC"
  },
  {
    "arxiv_id": "2402.18593v1",
    "title": "Sustainable Supercomputing for AI: GPU Power Capping at HPC Scale",
    "authors": [
      "Dan Zhao",
      "Siddharth Samsi",
      "Joseph McDonald",
      "Baolin Li",
      "David Bestor",
      "Michael Jones",
      "Devesh Tiwari",
      "Vijay Gadepally"
    ],
    "abstract": "As research and deployment of AI grows, the computational burden to support\nand sustain its progress inevitably does too. To train or fine-tune\nstate-of-the-art models in NLP, computer vision, etc., some form of AI hardware\nacceleration is virtually a requirement. Recent large language models require\nconsiderable resources to train and deploy, resulting in significant energy\nusage, potential carbon emissions, and massive demand for GPUs and other\nhardware accelerators. However, this surge carries large implications for\nenergy sustainability at the HPC/datacenter level. In this paper, we study the\naggregate effect of power-capping GPUs on GPU temperature and power draw at a\nresearch supercomputing center. With the right amount of power-capping, we show\nsignificant decreases in both temperature and power draw, reducing power\nconsumption and potentially improving hardware life-span with minimal impact on\njob performance. While power-capping reduces power draw by design, the\naggregate system-wide effect on overall energy consumption is less clear; for\ninstance, if users notice job performance degradation from GPU power-caps, they\nmay request additional GPU-jobs to compensate, negating any energy savings or\neven worsening energy consumption. To our knowledge, our work is the first to\nconduct and make available a detailed analysis of the effects of GPU\npower-capping at the supercomputing scale. We hope our work will inspire\nHPCs/datacenters to further explore, evaluate, and communicate the impact of\npower-capping AI hardware accelerators for more sustainable AI.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.18593v1",
    "published_date": "2024-02-25 02:22:34 UTC",
    "updated_date": "2024-02-25 02:22:34 UTC"
  },
  {
    "arxiv_id": "2403.00810v1",
    "title": "Bootstrapping Cognitive Agents with a Large Language Model",
    "authors": [
      "Feiyu Zhu",
      "Reid Simmons"
    ],
    "abstract": "Large language models contain noisy general knowledge of the world, yet are\nhard to train or fine-tune. On the other hand cognitive architectures have\nexcellent interpretability and are flexible to update but require a lot of\nmanual work to instantiate. In this work, we combine the best of both worlds:\nbootstrapping a cognitive-based model with the noisy knowledge encoded in large\nlanguage models. Through an embodied agent doing kitchen tasks, we show that\nour proposed framework yields better efficiency compared to an agent based\nentirely on large language models. Our experiments indicate that large language\nmodels are a good source of information for cognitive architectures, and the\ncognitive architecture in turn can verify and update the knowledge of large\nlanguage models to a specific domain.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00810v1",
    "published_date": "2024-02-25 01:40:30 UTC",
    "updated_date": "2024-02-25 01:40:30 UTC"
  },
  {
    "arxiv_id": "2402.15945v2",
    "title": "Attention-GAN for Anomaly Detection: A Cutting-Edge Approach to Cybersecurity Threat Management",
    "authors": [
      "Mohammed Abo Sen"
    ],
    "abstract": "This paper proposes an innovative Attention-GAN framework for enhancing\ncybersecurity, focusing on anomaly detection. In response to the challenges\nposed by the constantly evolving nature of cyber threats, the proposed approach\naims to generate diverse and realistic synthetic attack scenarios, thereby\nenriching the dataset and improving threat identification. Integrating\nattention mechanisms with Generative Adversarial Networks (GANs) is a key\nfeature of the proposed method. The attention mechanism enhances the model's\nability to focus on relevant features, essential for detecting subtle and\ncomplex attack patterns. In addition, GANs address the issue of data scarcity\nby generating additional varied attack data, encompassing known and emerging\nthreats. This dual approach ensures that the system remains relevant and\neffective against the continuously evolving cyberattacks. The KDD Cup and\nCICIDS2017 datasets were used to validate this model, which exhibited\nsignificant improvements in anomaly detection. It achieved an accuracy of\n99.69% on the KDD dataset and 97.93% on the CICIDS2017 dataset, with precision,\nrecall, and F1-scores above 97%, demonstrating its effectiveness in recognizing\ncomplex attack patterns. This study contributes significantly to cybersecurity\nby providing a scalable and adaptable solution for anomaly detection in the\nface of sophisticated and dynamic cyber threats. The exploration of GANs for\ndata augmentation highlights a promising direction for future research,\nparticularly in situations where data limitations restrict the development of\ncybersecurity systems. The attention-GAN framework has emerged as a pioneering\napproach, setting a new benchmark for advanced cyber-defense strategies.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.15945v2",
    "published_date": "2024-02-25 01:10:55 UTC",
    "updated_date": "2024-02-27 19:27:42 UTC"
  },
  {
    "arxiv_id": "2402.16906v6",
    "title": "Debug like a Human: A Large Language Model Debugger via Verifying Runtime Execution Step-by-step",
    "authors": [
      "Li Zhong",
      "Zilong Wang",
      "Jingbo Shang"
    ],
    "abstract": "Large language models (LLMs) are leading significant progress in code\ngeneration. Beyond one-pass code generation, recent works further integrate\nunit tests and program verifiers into LLMs to iteratively refine the generated\nprograms. However, these works consider the generated programs as an\nindivisible entity, which falls short for LLMs in debugging the programs,\nespecially when the programs contain complex logic flows and data operations.\nIn contrast, when human developers debug programs, they typically set\nbreakpoints and selectively examine runtime execution information. The\nexecution flow and the intermediate variables play a crucial role in the\ndebugging process, yet they are underutilized in the existing literature on\ncode generation. In this study, we introduce Large Language Model Debugger\n(LDB), a novel debugging framework that enables LLMs to refine their generated\nprograms with the runtime execution information. Specifically, LDB segments the\nprograms into basic blocks and tracks the values of intermediate variables\nafter each block throughout the runtime execution. This allows LLMs to\nconcentrate on simpler code units within the overall execution flow, verify\ntheir correctness against the task description block by block, and efficiently\npinpoint any potential errors. Experiments demonstrate that LDB consistently\nenhances the baseline performance by up to 9.8% across the HumanEval, MBPP, and\nTransCoder benchmarks, archiving new state-of-the-art performance in code\ndebugging for various LLM selections.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2402.16906v6",
    "published_date": "2024-02-25 00:56:27 UTC",
    "updated_date": "2024-06-06 06:01:41 UTC"
  },
  {
    "arxiv_id": "2402.15943v2",
    "title": "Rethinking Software Engineering in the Foundation Model Era: A Curated Catalogue of Challenges in the Development of Trustworthy FMware",
    "authors": [
      "Ahmed E. Hassan",
      "Dayi Lin",
      "Gopi Krishnan Rajbahadur",
      "Keheliya Gallaba",
      "Filipe R. Cogo",
      "Boyuan Chen",
      "Haoxiang Zhang",
      "Kishanthan Thangarajah",
      "Gustavo Ansaldi Oliva",
      "Jiahuei Lin",
      "Wali Mohammad Abdullah",
      "Zhen Ming Jiang"
    ],
    "abstract": "Foundation models (FMs), such as Large Language Models (LLMs), have\nrevolutionized software development by enabling new use cases and business\nmodels. We refer to software built using FMs as FMware. The unique properties\nof FMware (e.g., prompts, agents, and the need for orchestration), coupled with\nthe intrinsic limitations of FMs (e.g., hallucination) lead to a completely new\nset of software engineering challenges. Based on our industrial experience, we\nidentified 10 key SE4FMware challenges that have caused enterprise FMware\ndevelopment to be unproductive, costly, and risky. In this paper, we discuss\nthese challenges in detail and state the path for innovation that we envision.\nNext, we present FMArts, which is our long-term effort towards creating a\ncradle-to-grave platform for the engineering of trustworthy FMware. Finally, we\n(i) show how the unique properties of FMArts enabled us to design and develop a\ncomplex FMware for a large customer in a timely manner and (ii) discuss the\nlessons that we learned in doing so. We hope that the disclosure of the\naforementioned challenges and our associated efforts to tackle them will not\nonly raise awareness but also promote deeper and further discussions, knowledge\nsharing, and innovative solutions across the software engineering discipline.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.15943v2",
    "published_date": "2024-02-25 00:53:16 UTC",
    "updated_date": "2024-03-04 04:22:37 UTC"
  }
]