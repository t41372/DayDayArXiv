{
  "date": "2024-08-30",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-08-30 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦 AI 模型优化、多模态理解和医疗应用等领域，其中 HERMES 在长视频理解上表现出色，OrthoDoc 利用 LLM 辅助 CT 诊断，Sequence to Sequence Reward Modeling 提升了 LLM 的安全对齐性能，同时有几篇知名学者参与的论文如 Dan Roth 的 MAPWise 等，强调了 AI 在实际场景中的可靠性和扩展性。\n\n下面，我挑选了其中最具影响力和话题度的论文进行简要讨论，先从 AI 安全、多模态和 LLM 优化等核心领域入手，再快速触及医疗和环境应用。其他论文如常规优化或较基础的实验，我会简略掠过，以控制篇幅。\n\n### 1. **HERMES: temporal-coHERent long-forM understanding with Episodes and Semantics**  \n   **核心贡献**：这篇论文提出 HERMES 框架，用于处理长视频理解问题，通过 Episodic COmpressor (ECO) 和 Semantics ReTRiever (SeTR) 捕获视频中的动作序列和语义知识，解决了传统模型在长程依赖和冗余信息处理上的不足。  \n   **主要发现**：在零样本和全监督设置下，HERMES 在多个基准上达到 SOTA 性能，显著提升了视频理解的准确性和效率。由 Winston H. Hsu 等学者主导，这篇论文在多模态 AI 领域有高话题度，值得关注视频处理应用。\n\n### 2. **The Artificial Intelligence Act: critical overview**  \n   **核心贡献**：论文对欧盟 AI Act 进行批判性分析，讨论了其结构、目标和关键规则，如公平性、透明度和高风险系统监管。  \n   **主要发现**：作者 Nuno Sousa e Silva 指出，该法规虽平衡但复杂度高，可能阻碍创新。AI 伦理和法规话题持续热门，这篇论文为 AI 政策研究提供实用洞见，适合 AI 治理从业者。\n\n### 3. **OrthoDoc: Multimodal Large Language Model for Assisting Diagnosis in Computed Tomography**  \n   **核心贡献**：开发 OrthoDoc，一款多模态 LLM，用于 CT 图像诊断，通过 RAG 模块减少幻觉，并处理骨科常见问题如骨折和肿瘤。  \n   **主要发现**：在多个基准上超越 GPT-4，在骨科诊断中表现出色。该论文展示了 LLM 在医疗 AI 中的潜力，作者 Youzhu Jin 等强调了实际应用价值，是医疗领域的重要进展。\n\n### 4. **Sequence to Sequence Reward Modeling: Improving RLHF by Language Feedback**  \n   **核心贡献**：提出 seq2seq 奖励建模方法，使用语言反馈替换标量反馈，提升强化学习从人类反馈 (RLHF) 的性能。  \n   **主要发现**：减少了 LLM 的拒绝响应偏差和长响应偏见，在多个任务上平均胜率达 76.9%。作者 Yaodong Yang 等的工作强化了 AI 安全对齐，LLM 社区应关注此优化。\n\n### 5. **MAPWise: Evaluating Vision-Language Models for Advanced Map Queries**  \n   **核心贡献**：引入 MAPWise 基准，评估 VLM 在地图查询中的性能，包括空间关系和复杂推理。  \n   **主要发现**：基准覆盖多种地图类型，揭示 VLM 在跨视图理解上的不足。作者 Dan Roth 等知名学者的参与，使其成为多模态基准的重要补充，适用于地理和视觉 AI 研究。\n\n其他如量子机器学习 (Quantum Machine Learning for Anomaly Detection) 和野火预测 (Deep learning surrogate models of JULES-INFERNO) 等论文虽有技术创新，但相对基础或领域特定，我仅快速提及：它们分别探讨了 QML 在消费电子异常检测中的框架，以及深度学习在全球野火模拟中的加速，但未达到广泛话题度，故不展开。\n\n总之，今天的论文突显了 AI 在实际应用中的进步，尤其在安全和多模态领域。感兴趣的读者可优先查看 HERMES 和 OrthoDoc，以获取前沿洞见。明天的快报见！",
  "papers": [
    {
      "arxiv_id": "2409.00294v1",
      "title": "Quantum Machine Learning for Anomaly Detection in Consumer Electronics",
      "title_zh": "翻译失败",
      "authors": [
        "Sounak Bhowmik",
        "Himanshu Thapliyal"
      ],
      "abstract": "Anomaly detection is a crucial task in cyber security. Technological\nadvancement brings new cyber-physical threats like network intrusion, financial\nfraud, identity theft, and property invasion. In the rapidly changing world,\nwith frequently emerging new types of anomalies, classical machine learning\nmodels are insufficient to prevent all the threats. Quantum Machine Learning\n(QML) is emerging as a powerful computational tool that can detect anomalies\nmore efficiently. In this work, we have introduced QML and its applications for\nanomaly detection in consumer electronics. We have shown a generic framework\nfor applying QML algorithms in anomaly detection tasks. We have also briefly\ndiscussed popular supervised, unsupervised, and reinforcement learning-based\nQML algorithms and included five case studies of recent works to show their\napplications in anomaly detection in the consumer electronics field.",
      "tldr_zh": "本文探讨了Quantum Machine Learning (QML) 在消费电子领域异常检测的应用，强调了传统机器学习模型在面对新兴威胁（如网络入侵、金融欺诈和身份盗用）时的不足。论文提出一个通用的框架，用于部署QML算法，包括supervised、unsupervised和reinforcement learning-based方法，并通过五个案例研究展示了这些算法在消费电子异常检测中的高效性能。总体而言，该工作突出了QML作为更强大工具的潜力，有助于提升网络安全的响应能力。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "7 pages, 2 figures, 1 table, under ISVLSI 2024 proceedings",
      "pdf_url": "http://arxiv.org/pdf/2409.00294v1",
      "published_date": "2024-08-30 23:28:00 UTC",
      "updated_date": "2024-08-30 23:28:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:57:03.056753"
    },
    {
      "arxiv_id": "2409.00286v1",
      "title": "OnlySportsLM: Optimizing Sports-Domain Language Models with SOTA Performance under Billion Parameters",
      "title_zh": "翻译失败",
      "authors": [
        "Zexin Chen",
        "Chengxi Li",
        "Xiangyu Xie",
        "Parijat Dube"
      ],
      "abstract": "This paper explores the potential of a small, domain-specific language model\ntrained exclusively on sports-related data. We investigate whether extensive\ntraining data with specially designed small model structures can overcome model\nsize constraints. The study introduces the OnlySports collection, comprising\nOnlySportsLM, OnlySports Dataset, and OnlySports Benchmark. Our approach\ninvolves: 1) creating a massive 600 billion tokens OnlySports Dataset from\nFineWeb, 2) optimizing the RWKV architecture for sports-related tasks,\nresulting in a 196M parameters model with 20-layer, 640-dimension structure, 3)\ntraining the OnlySportsLM on part of OnlySports Dataset, and 4) testing the\nresultant model on OnlySports Benchmark. OnlySportsLM achieves a 37.62%/34.08%\naccuracy improvement over previous 135M/360M state-of-the-art models and\nmatches the performance of larger models such as SomlLM 1.7B and Qwen 1.5B in\nthe sports domain. Additionally, the OnlySports collection presents a\ncomprehensive workflow for building high-quality, domain-specific language\nmodels, providing a replicable blueprint for efficient AI development across\nvarious specialized fields.",
      "tldr_zh": "这篇论文介绍了 OnlySportsLM，一种针对体育领域的语言模型，通过优化 RWKV 架构并使用 196M 参数的结构，实现了在亿参数级别下的 SOTA 性能。研究团队构建了 600 亿 tokens 的 OnlySports Dataset，并在其基础上训练模型，同时开发了 OnlySports Benchmark 用于评估。结果显示，OnlySportsLM 在准确率上比之前的 135M/360M 模型提高了 37.62%/34.08%，并在体育任务中匹敌更大模型如 SomlLM 1.7B 和 Qwen 1.5B。该方法提供了一个全面、可复制的工作流程，用于高效构建高质量的领域特定语言模型。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "13 pages, 4 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2409.00286v1",
      "published_date": "2024-08-30 22:39:35 UTC",
      "updated_date": "2024-08-30 22:39:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:57:16.470766"
    },
    {
      "arxiv_id": "2409.00284v2",
      "title": "Reframing Data Value for Large Language Models Through the Lens of Plausibility",
      "title_zh": "翻译失败",
      "authors": [
        "Mohamad Rida Rammal",
        "Ruida Zhou",
        "Suhas Diggavi"
      ],
      "abstract": "Data valuation seeks to answer the important question, \"How much is this data\nworth?\" Existing data valuation methods have largely focused on discriminative\nmodels, primarily examining data value through the lens of its utility in\ntraining. However, with the push for ever-larger language models, relying on\nvaluation methods that require training becomes increasingly expensive and\ndependent on specific techniques. We propose an alternative perspective on the\ndata value problem for language models, centering around the plausibility of\nthe data. We posit that data holds lesser value if it can be plausibly\ngenerated by the model itself. Starting from some intuitive criteria that align\nwith our notions of valuable data, we develop a novel value function that is\ncomputationally tractable and derived from first principles with provable\nproperties. We conduct a theoretical analysis of our value function and\nevaluate it across multiple scenarios and datasets.",
      "tldr_zh": "本论文重新审视了大型语言模型（Large Language Models）的data valuation问题，提出从数据plausibility（可信度）的角度进行评估，认为如果数据能被模型自身合理生成，其价值较低。作者基于直观的标准，开发了一个计算高效的新的价值函数，该函数源于第一原则并具有可证明的属性。论文通过理论分析，并在多个场景和数据集上进行了评估，展示了这一方法的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.00284v2",
      "published_date": "2024-08-30 22:32:24 UTC",
      "updated_date": "2024-10-15 20:04:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:57:27.220751"
    },
    {
      "arxiv_id": "2409.00265v2",
      "title": "Explainable Artificial Intelligence: A Survey of Needs, Techniques, Applications, and Future Direction",
      "title_zh": "翻译失败",
      "authors": [
        "Melkamu Mersha",
        "Khang Lam",
        "Joseph Wood",
        "Ali AlShami",
        "Jugal Kalita"
      ],
      "abstract": "Artificial intelligence models encounter significant challenges due to their\nblack-box nature, particularly in safety-critical domains such as healthcare,\nfinance, and autonomous vehicles. Explainable Artificial Intelligence (XAI)\naddresses these challenges by providing explanations for how these models make\ndecisions and predictions, ensuring transparency, accountability, and fairness.\nExisting studies have examined the fundamental concepts of XAI, its general\nprinciples, and the scope of XAI techniques. However, there remains a gap in\nthe literature as there are no comprehensive reviews that delve into the\ndetailed mathematical representations, design methodologies of XAI models, and\nother associated aspects. This paper provides a comprehensive literature review\nencompassing common terminologies and definitions, the need for XAI,\nbeneficiaries of XAI, a taxonomy of XAI methods, and the application of XAI\nmethods in different application areas. The survey is aimed at XAI researchers,\nXAI practitioners, AI model developers, and XAI beneficiaries who are\ninterested in enhancing the trustworthiness, transparency, accountability, and\nfairness of their AI models.",
      "tldr_zh": "这篇论文对 Explainable Artificial Intelligence (XAI) 进行了全面调查，强调其在解决 AI 模型黑箱问题方面的必要性，特别是针对医疗、金融和自动驾驶等安全关键领域，以提升模型的透明度、问责性和公平性。论文回顾了 XAI 的常见术语、定义、需求、受益者（如研究者和开发者）、方法分类（如各种技术框架），并探讨了其在不同应用领域的实际应用。最终，该调查旨在填补现有文献空白，提供数学表示和设计方法的详细分析，为未来 XAI 研究和实践提供指导。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.00265v2",
      "published_date": "2024-08-30 21:42:17 UTC",
      "updated_date": "2025-01-13 00:29:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:57:41.845910"
    },
    {
      "arxiv_id": "2409.00264v1",
      "title": "The Artificial Intelligence Act: critical overview",
      "title_zh": "翻译失败",
      "authors": [
        "Nuno Sousa e Silva"
      ],
      "abstract": "This article provides a critical overview of the recently approved Artificial\nIntelligence Act. It starts by presenting the main structure, objectives, and\napproach of Regulation (EU) 2024/1689. A definition of key concepts follows,\nand then the material and territorial scope, as well as the timing of\napplication, are analyzed. Although the Regulation does not explicitly set out\nprinciples, the main ideas of fairness, accountability, transparency, and\nequity in AI underly a set of rules of the regulation. This is discussed before\nlooking at the ill-defined set of forbidden AI practices (manipulation and e\nexploitation of vulnerabilities, social scoring, biometric identification and\nclassification, and predictive policing). It is highlighted that those rules\ndeal with behaviors rather than AI systems. The qualification and regulation of\nhigh-risk AI systems are tackled, alongside the obligation of transparency for\ncertain systems, the regulation of general-purpose models, and the rules on\ncertification, supervision, and sanctions. The text concludes that even if the\noverall framework can be deemed adequate and balanced, the approach is so\ncomplex that it risks defeating its own purpose of promoting responsible\ninnovation within the European Union and beyond its borders.",
      "tldr_zh": "这篇文章对欧盟新批准的人工智能法案（Regulation (EU) 2024/1689）进行了批判性概述，分析了其结构、目标、关键概念（如fairness、accountability、transparency和equity）、物质和地域范围以及应用时间。论文讨论了法案中隐含的原则、禁止的AI实践（如manipulation、exploitation of vulnerabilities、social scoring、biometric identification和predictive policing），以及对high-risk AI systems的资格规定、透明义务、general-purpose models的监管、认证、监督和制裁规则。作者认为，尽管整体框架合理且平衡，但其复杂性可能适得其反，阻碍了欧盟境内及境外的负责任创新。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.00264v1",
      "published_date": "2024-08-30 21:38:02 UTC",
      "updated_date": "2024-08-30 21:38:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:57:53.610920"
    },
    {
      "arxiv_id": "2409.00255v1",
      "title": "MAPWise: Evaluating Vision-Language Models for Advanced Map Queries",
      "title_zh": "MAPWise：评估视觉-语言模型处理高级地图查询",
      "authors": [
        "Srija Mukhopadhyay",
        "Abhishek Rajgaria",
        "Prerana Khatiwada",
        "Vivek Gupta",
        "Dan Roth"
      ],
      "abstract": "Vision-language models (VLMs) excel at tasks requiring joint understanding of\nvisual and linguistic information. A particularly promising yet under-explored\napplication for these models lies in answering questions based on various kinds\nof maps. This study investigates the efficacy of VLMs in answering questions\nbased on choropleth maps, which are widely used for data analysis and\nrepresentation. To facilitate and encourage research in this area, we introduce\na novel map-based question-answering benchmark, consisting of maps from three\ngeographical regions (United States, India, China), each containing 1000\nquestions. Our benchmark incorporates 43 diverse question templates, requiring\nnuanced understanding of relative spatial relationships, intricate map\nfeatures, and complex reasoning. It also includes maps with discrete and\ncontinuous values, encompassing variations in color-mapping, category ordering,\nand stylistic patterns, enabling comprehensive analysis. We evaluate the\nperformance of multiple VLMs on this benchmark, highlighting gaps in their\nabilities and providing insights for improving such models.",
      "tldr_zh": "这篇论文评估了Vision-Language Models (VLMs) 在处理高级地图查询的能力，特别关注choropleth maps 用于数据分析的场景。研究者引入了一个新基准，包括美国、印度和中国三个地区的地图，每个地区包含1000个问题，这些问题基于43个多样化模板，需要理解相对空间关系、地图特征和复杂推理。基准还涵盖离散和连续值地图的变体，如颜色映射、类别排序和样式模式。通过测试多个VLMs，该研究突出了模型在地图问答任务中的不足，并提供了改进这些模型的见解。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.GR",
        "cs.HC"
      ],
      "primary_category": "cs.CV",
      "comment": "30 Pages, 46 Tables, 6 Figure",
      "pdf_url": "http://arxiv.org/pdf/2409.00255v1",
      "published_date": "2024-08-30 20:57:34 UTC",
      "updated_date": "2024-08-30 20:57:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:58:04.946962"
    },
    {
      "arxiv_id": "2409.00240v1",
      "title": "One-Frame Calibration with Siamese Network in Facial Action Unit Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Shuangquan Feng",
        "Virginia R. de Sa"
      ],
      "abstract": "Automatic facial action unit (AU) recognition is used widely in facial\nexpression analysis. Most existing AU recognition systems aim for\ncross-participant non-calibrated generalization (NCG) to unseen faces without\nfurther calibration. However, due to the diversity of facial attributes across\ndifferent identities, accurately inferring AU activation from single images of\nan unseen face is sometimes infeasible, even for human experts -- it is crucial\nto first understand how the face appears in its neutral expression, or\nsignificant bias may be incurred. Therefore, we propose to perform one-frame\ncalibration (OFC) in AU recognition: for each face, a single image of its\nneutral expression is used as the reference image for calibration. With this\nstrategy, we develop a Calibrating Siamese Network (CSN) for AU recognition and\ndemonstrate its remarkable effectiveness with a simple iResNet-50 (IR50)\nbackbone. On the DISFA, DISFA+, and UNBC-McMaster datasets, we show that our\nOFC CSN-IR50 model (a) substantially improves the performance of IR50 by\nmitigating facial attribute biases (including biases due to wrinkles, eyebrow\npositions, facial hair, etc.), (b) substantially outperforms the naive OFC\nmethod of baseline subtraction as well as (c) a fine-tuned version of this\nnaive OFC method, and (d) also outperforms state-of-the-art NCG models for both\nAU intensity estimation and AU detection.",
      "tldr_zh": "该研究针对面部动作单元(AU)识别中的跨参与者非校准泛化(NCG)问题，提出了一种一帧校准(OFC)策略，使用单个中性表情图像作为参考来减少面部属性偏差，如皱纹和眉毛位置。作者开发了Calibrating Siamese Network (CSN)，以iResNet-50 (IR50)作为骨干网络，通过Siamese Network结构进行校准，提升了AU识别的准确性。在DISFA、DISFA+和UNBC-McMaster数据集上，CSN-IR50模型显著提高了IR50的性能，超过了基线减法方法和最先进NCG模型，尤其在AU强度估计和检测任务中。总体而言，此方法为更鲁棒的AU识别提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.00240v1",
      "published_date": "2024-08-30 20:20:12 UTC",
      "updated_date": "2024-08-30 20:20:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:58:17.118953"
    },
    {
      "arxiv_id": "2409.00237v1",
      "title": "Deep learning surrogate models of JULES-INFERNO for wildfire prediction on a global scale",
      "title_zh": "JULES-INFERNO 的深度学习代理模型，用于全球规模的野火预测",
      "authors": [
        "Sibo Cheng",
        "Hector Chassagnon",
        "Matthew Kasoar",
        "Yike Guo",
        "Rossella Arcucci"
      ],
      "abstract": "Global wildfire models play a crucial role in anticipating and responding to\nchanging wildfire regimes. JULES-INFERNO is a global vegetation and fire model\nsimulating wildfire emissions and area burnt on a global scale. However,\nbecause of the high data dimensionality and system complexity, JULES-INFERNO's\ncomputational costs make it challenging to apply to fire risk forecasting with\nunseen initial conditions. Typically, running JULES-INFERNO for 30 years of\nprediction will take several hours on High Performance Computing (HPC)\nclusters. To tackle this bottleneck, two data-driven models are built in this\nwork based on Deep Learning techniques to surrogate the JULES-INFERNO model and\nspeed up global wildfire forecasting. More precisely, these machine learning\nmodels take global temperature, vegetation density, soil moisture and previous\nforecasts as inputs to predict the subsequent global area burnt on an iterative\nbasis. Average Error per Pixel (AEP) and Structural Similarity Index Measure\n(SSIM) are used as metrics to evaluate the performance of the proposed\nsurrogate models. A fine tuning strategy is also proposed in this work to\nimprove the algorithm performance for unseen scenarios. Numerical results show\na strong performance of the proposed models, in terms of both computational\nefficiency (less than 20 seconds for 30 years of prediction on a laptop CPU)\nand prediction accuracy (with AEP under 0.3\\% and SSIM over 98\\% compared to\nthe outputs of JULES-INFERNO).",
      "tldr_zh": "这篇论文提出使用深度学习技术构建两个代理模型（surrogate models），以加速 JULES-INFERNO 全球野火预测模型的计算，这些模型以全球温度、植被密度、土壤湿度和先前预测作为输入，迭代预测后续的全球燃烧面积，并引入微调策略来提升对未知场景的性能。相比原模型，新方法显著提高了计算效率，在笔记本 CPU 上只需不到 20 秒即可完成 30 年的预测，同时保持高准确性，Average Error per Pixel (AEP) 低于 0.3% 和 Structural Similarity Index Measure (SSIM) 高于 98%。这项工作为高效的全球野火风险预报提供了可行解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.00237v1",
      "published_date": "2024-08-30 20:05:00 UTC",
      "updated_date": "2024-08-30 20:05:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:58:30.370818"
    },
    {
      "arxiv_id": "2409.00230v2",
      "title": "Spatially-Aware Diffusion Models with Cross-Attention for Global Field Reconstruction with Sparse Observations",
      "title_zh": "翻译失败",
      "authors": [
        "Yilin Zhuang",
        "Sibo Cheng",
        "Karthik Duraisamy"
      ],
      "abstract": "Diffusion models have gained attention for their ability to represent complex\ndistributions and incorporate uncertainty, making them ideal for robust\npredictions in the presence of noisy or incomplete data. In this study, we\ndevelop and enhance score-based diffusion models in field reconstruction tasks,\nwhere the goal is to estimate complete spatial fields from partial\nobservations. We introduce a condition encoding approach to construct a\ntractable mapping mapping between observed and unobserved regions using a\nlearnable integration of sparse observations and interpolated fields as an\ninductive bias. With refined sensing representations and an unraveled temporal\ndimension, our method can handle arbitrary moving sensors and effectively\nreconstruct fields. Furthermore, we conduct a comprehensive benchmark of our\napproach against a deterministic interpolation-based method across various\nstatic and time-dependent PDEs. Our study attempts to addresses the gap in\nstrong baselines for evaluating performance across varying sampling\nhyperparameters, noise levels, and conditioning methods. Our results show that\ndiffusion models with cross-attention and the proposed conditional encoding\ngenerally outperform other methods under noisy conditions, although the\ndeterministic method excels with noiseless data. Additionally, both the\ndiffusion models and the deterministic method surpass the numerical approach in\naccuracy and computational cost for the steady problem. We also demonstrate the\nability of the model to capture possible reconstructions and improve the\naccuracy of fused results in covariance-based correction tasks using ensemble\nsampling.",
      "tldr_zh": "本研究开发了基于 score-based diffusion models 的方法，用于从稀疏观察重建全局空间场，特别强调在噪声或不完整数据下的鲁棒预测。研究引入了条件编码策略和 cross-attention 机制，以建立观察和未观察区域之间的映射，并处理任意移动传感器和时间维度。实验基准测试显示，该方法在各种静态和时间相关的 PDEs 上，在噪声条件下优于确定性插值方法，并在准确性和计算成本上超越数值方法，同时通过 ensemble sampling 提升了协方差-based 校正任务的性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.flu-dyn"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.00230v2",
      "published_date": "2024-08-30 19:46:23 UTC",
      "updated_date": "2024-11-01 19:58:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:58:41.757035"
    },
    {
      "arxiv_id": "2409.00196v1",
      "title": "A Generative Adversarial Network-based Method for LiDAR-Assisted Radar Image Enhancement",
      "title_zh": "基于生成对抗网络的 LiDAR 辅助雷达图像增强方法",
      "authors": [
        "Thakshila Thilakanayake",
        "Oscar De Silva",
        "Thumeera R. Wanasinghe",
        "George K. Mann",
        "Awantha Jayasiri"
      ],
      "abstract": "This paper presents a generative adversarial network (GAN) based approach for\nradar image enhancement. Although radar sensors remain robust for operations\nunder adverse weather conditions, their application in autonomous vehicles\n(AVs) is commonly limited by the low-resolution data they produce. The primary\ngoal of this study is to enhance the radar images to better depict the details\nand features of the environment, thereby facilitating more accurate object\nidentification in AVs. The proposed method utilizes high-resolution,\ntwo-dimensional (2D) projected light detection and ranging (LiDAR) point clouds\nas ground truth images and low-resolution radar images as inputs to train the\nGAN. The ground truth images were obtained through two main steps. First, a\nLiDAR point cloud map was generated by accumulating raw LiDAR scans. Then, a\ncustomized LiDAR point cloud cropping and projection method was employed to\nobtain 2D projected LiDAR point clouds. The inference process of the proposed\nmethod relies solely on radar images to generate an enhanced version of them.\nThe effectiveness of the proposed method is demonstrated through both\nqualitative and quantitative results. These results show that the proposed\nmethod can generate enhanced images with clearer object representation compared\nto the input radar images, even under adverse weather conditions.",
      "tldr_zh": "本论文提出了一种基于 Generative Adversarial Network (GAN) 的方法，利用 LiDAR 点云辅助增强雷达图像，以解决雷达数据分辨率低的问题，从而提升自动驾驶车辆 (AVs) 在恶劣天气下的物体识别准确性。方法以高分辨率 2D LiDAR 点云作为 ground truth，通过积累原始 LiDAR 扫描并进行裁剪和投影来生成训练数据，并使用低分辨率雷达图像作为输入训练 GAN。实验结果显示，该方法能生成更清晰的增强图像，定性和定量评估证明其在物体表示上显著优于原始雷达图像，即使在恶劣天气条件下。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.00196v1",
      "published_date": "2024-08-30 18:22:39 UTC",
      "updated_date": "2024-08-30 18:22:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:58:52.505955"
    },
    {
      "arxiv_id": "2408.17443v3",
      "title": "HERMES: temporal-coHERent long-forM understanding with Episodes and Semantics",
      "title_zh": "翻译失败",
      "authors": [
        "Gueter Josmy Faure",
        "Jia-Fong Yeh",
        "Min-Hung Chen",
        "Hung-Ting Su",
        "Shang-Hong Lai",
        "Winston H. Hsu"
      ],
      "abstract": "Existing research often treats long-form videos as extended short videos,\nleading to several limitations: inadequate capture of long-range dependencies,\ninefficient processing of redundant information, and failure to extract\nhigh-level semantic concepts. To address these issues, we propose a novel\napproach that more accurately reflects human cognition. This paper introduces\nHERMES: temporal-coHERent long-forM understanding with Episodes and Semantics,\na model that simulates episodic memory accumulation to capture action sequences\nand reinforces them with semantic knowledge dispersed throughout the video. Our\nwork makes two key contributions: First, we develop an Episodic COmpressor\n(ECO) that efficiently aggregates crucial representations from micro to\nsemi-macro levels, overcoming the challenge of long-range dependencies. Second,\nwe propose a Semantics ReTRiever (SeTR) that enhances these aggregated\nrepresentations with semantic information by focusing on the broader context,\ndramatically reducing feature dimensionality while preserving relevant\nmacro-level information. This addresses the issues of redundancy and lack of\nhigh-level concept extraction. Extensive experiments demonstrate that HERMES\nachieves state-of-the-art performance across multiple long-video understanding\nbenchmarks in both zero-shot and fully-supervised settings.",
      "tldr_zh": "现有研究在处理长视频时，常将它们视为扩展的短视频，导致无法有效捕捉长程依赖、处理冗余信息和提取高层语义概念。为解决这些问题，本文提出 HERMES 模型，通过模拟人类 episodic memory 积累来捕捉动作序列，并用分散的语义知识进行强化。HERMES 的关键贡献包括开发 Episodic COmpressor (ECO) 以高效聚合微观到半宏观水平的表示，以及提出 Semantics ReTRiever (SeTR) 来增强这些表示并减少特征维度，同时保留宏观信息。实验结果表明，HERMES 在多个长视频理解基准上，在零样本和完全监督设置中均达到最先进性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "This is an improved and expanded version of our EVAL-FoMo Workshop at\n  ECCV'24 (v1 of this paper). Project page:\n  https://joslefaure.github.io/assets/html/hermes.html",
      "pdf_url": "http://arxiv.org/pdf/2408.17443v3",
      "published_date": "2024-08-30 17:52:55 UTC",
      "updated_date": "2024-11-09 06:46:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:59:08.141136"
    },
    {
      "arxiv_id": "2408.17431v1",
      "title": "Advancing Multi-talker ASR Performance with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Mohan Shi",
        "Zengrui Jin",
        "Yaoxun Xu",
        "Yong Xu",
        "Shi-Xiong Zhang",
        "Kun Wei",
        "Yiwen Shao",
        "Chunlei Zhang",
        "Dong Yu"
      ],
      "abstract": "Recognizing overlapping speech from multiple speakers in conversational\nscenarios is one of the most challenging problem for automatic speech\nrecognition (ASR). Serialized output training (SOT) is a classic method to\naddress multi-talker ASR, with the idea of concatenating transcriptions from\nmultiple speakers according to the emission times of their speech for training.\nHowever, SOT-style transcriptions, derived from concatenating multiple related\nutterances in a conversation, depend significantly on modeling long contexts.\nTherefore, compared to traditional methods that primarily emphasize encoder\nperformance in attention-based encoder-decoder (AED) architectures, a novel\napproach utilizing large language models (LLMs) that leverages the capabilities\nof pre-trained decoders may be better suited for such complex and challenging\nscenarios. In this paper, we propose an LLM-based SOT approach for multi-talker\nASR, leveraging pre-trained speech encoder and LLM, fine-tuning them on\nmulti-talker dataset using appropriate strategies. Experimental results\ndemonstrate that our approach surpasses traditional AED-based methods on the\nsimulated dataset LibriMix and achieves state-of-the-art performance on the\nevaluation set of the real-world dataset AMI, outperforming the AED model\ntrained with 1000 times more supervised data in previous works.",
      "tldr_zh": "本文提出了一种基于 Large Language Models (LLMs) 的 Serialized Output Training (SOT) 方法，以提升多说话者自动语音识别 (ASR) 的性能，特别针对对话场景中的重叠语音挑战。方法利用预训练的语音编码器和 LLMs，在多说话者数据集上进行微调，充分利用 LLMs 的解码器能力来处理长上下文。实验结果显示，该方法在 LibriMix 数据集上超越传统 attention-based encoder-decoder (AED) 模型，并在真实数据集 AMI 上达到最先进性能，甚至优于使用 1000 倍监督数据的现有模型。",
      "categories": [
        "eess.AS",
        "cs.AI"
      ],
      "primary_category": "eess.AS",
      "comment": "8 pages, accepted by IEEE SLT 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.17431v1",
      "published_date": "2024-08-30 17:29:25 UTC",
      "updated_date": "2024-08-30 17:29:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:59:21.186953"
    },
    {
      "arxiv_id": "2409.10528v1",
      "title": "From Latent to Engine Manifolds: Analyzing ImageBind's Multimodal Embedding Space",
      "title_zh": "翻译失败",
      "authors": [
        "Andrew Hamara",
        "Pablo Rivas"
      ],
      "abstract": "This study investigates ImageBind's ability to generate meaningful fused\nmultimodal embeddings for online auto parts listings. We propose a simplistic\nembedding fusion workflow that aims to capture the overlapping information of\nimage/text pairs, ultimately combining the semantics of a post into a joint\nembedding. After storing such fused embeddings in a vector database, we\nexperiment with dimensionality reduction and provide empirical evidence to\nconvey the semantic quality of the joint embeddings by clustering and examining\nthe posts nearest to each cluster centroid. Additionally, our initial findings\nwith ImageBind's emergent zero-shot cross-modal retrieval suggest that pure\naudio embeddings can correlate with semantically similar marketplace listings,\nindicating potential avenues for future research.",
      "tldr_zh": "本研究分析了ImageBind的多模态嵌入空间，专注于在线汽车零件列表的图像/文本融合，提出一个简单的嵌入融合工作流来捕捉图像/文本对的重叠信息，并将语义合并成联合嵌入。研究通过将这些嵌入存储在向量数据库中，并使用降维、聚类和最近邻分析，提供经验证据证明了联合嵌入的语义质量。初步发现表明，ImageBind的零样本跨模态检索能力使纯音频嵌入与语义相似的市场列表相关联，为未来多模态应用研究开辟了新方向。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.2.10; I.5.4"
      ],
      "primary_category": "cs.CV",
      "comment": "The 26th International Conference on Artificial Intelligence\n  (ICAI'24)",
      "pdf_url": "http://arxiv.org/pdf/2409.10528v1",
      "published_date": "2024-08-30 17:16:33 UTC",
      "updated_date": "2024-08-30 17:16:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:59:32.493719"
    },
    {
      "arxiv_id": "2408.17422v5",
      "title": "Open-Vocabulary Action Localization with Iterative Visual Prompting",
      "title_zh": "翻译失败",
      "authors": [
        "Naoki Wake",
        "Atsushi Kanehira",
        "Kazuhiro Sasabuchi",
        "Jun Takamatsu",
        "Katsushi Ikeuchi"
      ],
      "abstract": "Video action localization aims to find the timings of specific actions from a\nlong video. Although existing learning-based approaches have been successful,\nthey require annotating videos, which comes with a considerable labor cost.\nThis paper proposes a training-free, open-vocabulary approach based on emerging\noff-the-shelf vision-language models (VLMs). The challenge stems from the fact\nthat VLMs are neither designed to process long videos nor tailored for finding\nactions. We overcome these problems by extending an iterative visual prompting\ntechnique. Specifically, we sample video frames and create a concatenated image\nwith frame index labels, allowing a VLM to identify the frames that most likely\ncorrespond to the start and end of the action. By iteratively narrowing the\nsampling window around the selected frames, the estimation gradually converges\nto more precise temporal boundaries. We demonstrate that this technique yields\nreasonable performance, achieving results comparable to state-of-the-art\nzero-shot action localization. These results support the use of VLMs as a\npractical tool for understanding videos. Sample code is available at\nhttps://microsoft.github.io/VLM-Video-Action-Localization/",
      "tldr_zh": "这篇论文提出了一种无需训练的开放词汇(Open-Vocabulary)视频动作定位方法，利用现成的视觉语言模型(VLMs)来从长视频中识别特定动作的起始和结束时机。方法通过迭代视觉提示(Iterative Visual Prompting)技术，采样视频帧并创建带帧索引标签的拼接图像，然后逐步缩小采样窗口，使定位结果逐步收敛到更精确的时序边界。实验表明，该方法性能与最先进的零样本(Zero-Shot)动作定位方法相当，证明了VLMs作为视频理解实用工具的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages, 5 figures, 6 tables. Published in IEEE Access. Last updated\n  on April 7th, 2025",
      "pdf_url": "http://arxiv.org/pdf/2408.17422v5",
      "published_date": "2024-08-30 17:12:14 UTC",
      "updated_date": "2025-04-07 10:55:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:59:43.346822"
    },
    {
      "arxiv_id": "2408.17404v1",
      "title": "Getting Inspiration for Feature Elicitation: App Store- vs. LLM-based Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Jialiang Wei",
        "Anne-Lise Courbis",
        "Thomas Lambolais",
        "Binbin Xu",
        "Pierre Louis Bernard",
        "Gérard Dray",
        "Walid Maalej"
      ],
      "abstract": "Over the past decade, app store (AppStore)-inspired requirements elicitation\nhas proven to be highly beneficial. Developers often explore competitors' apps\nto gather inspiration for new features. With the advance of Generative AI,\nrecent studies have demonstrated the potential of large language model\n(LLM)-inspired requirements elicitation. LLMs can assist in this process by\nproviding inspiration for new feature ideas. While both approaches are gaining\npopularity in practice, there is a lack of insight into their differences. We\nreport on a comparative study between AppStore- and LLM-based approaches for\nrefining features into sub-features. By manually analyzing 1,200 sub-features\nrecommended from both approaches, we identified their benefits, challenges, and\nkey differences. While both approaches recommend highly relevant sub-features\nwith clear descriptions, LLMs seem more powerful particularly concerning novel\nunseen app scopes. Moreover, some recommended features are imaginary with\nunclear feasibility, which suggests the importance of a human-analyst in the\nelicitation loop.",
      "tldr_zh": "这篇论文比较了基于App Store和LLM的特征提取方法，用于从竞争对手app中获取灵感以细化功能子特征。研究者通过手动分析1200个从两种方法推荐的子特征，评估了它们的优势、挑战和差异，结果显示两者都能提供高度相关且描述清晰的建议。LLM方法在处理新颖的未见app范围时表现出更强的创新潜力，但也可能生成虚构或可行性不明的特征，因此强调了在特征提取过程中加入人类分析师的重要性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "To Appear In Proceedings of 39th IEEE/ACM International Conference on\n  Automated Software Engineering (ASE 2024)",
      "pdf_url": "http://arxiv.org/pdf/2408.17404v1",
      "published_date": "2024-08-30 16:42:26 UTC",
      "updated_date": "2024-08-30 16:42:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:59:55.125711"
    },
    {
      "arxiv_id": "2408.17401v2",
      "title": "Exploring the Effect of Explanation Content and Format on User Comprehension and Trust in Healthcare",
      "title_zh": "探索解释内容和格式对医疗保健中用户理解和信任的影响",
      "authors": [
        "Antonio Rago",
        "Bence Palfi",
        "Purin Sukpanichnant",
        "Hannibal Nabli",
        "Kavyesh Vivek",
        "Olga Kostopoulou",
        "James Kinross",
        "Francesca Toni"
      ],
      "abstract": "AI-driven tools for healthcare are widely acknowledged as potentially\nbeneficial to health practitioners and patients, e.g. the QCancer regression\ntool for cancer risk prediction. However, for these tools to be trusted, they\nneed to be supplemented with explanations. We examine how explanations' content\nand format affect user comprehension and trust when explaining QCancer's\npredictions. Regarding content, we deploy SHAP and Occlusion-1. Regarding\nformat, we present SHAP explanations, conventionally, as charts (SC) and\nOcclusion-1 explanations as charts (OC) as well as text (OT), to which their\nsimpler nature lends itself. We conduct experiments with two sets of\nstakeholders: the general public (representing patients) and medical students\n(representing healthcare practitioners). Our experiments showed higher\nsubjective comprehension and trust for Occlusion-1 over SHAP explanations based\non content. However, when controlling for format, only OT outperformed SC,\nsuggesting this trend is driven by preferences for text. Other findings\ncorroborated that explanation format, rather than content, is often the\ncritical factor.",
      "tldr_zh": "本研究探讨了AI医疗工具（如QCancer癌症风险预测工具）的解释内容和格式对用户理解和信任的影响。研究比较了SHAP和Occlusion-1两种解释内容，并测试了不同格式，包括SHAP的图表（SC）、Occlusion-1的图表（OC）和文本（OT）。实验涉及普通公众（代表患者）和医学生（代表医疗从业者），结果显示Occlusion-1解释在主观理解和信任上优于SHAP，但这一优势主要源于文本格式而非内容本身。最终，论文强调解释格式往往比内容更关键。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages",
      "pdf_url": "http://arxiv.org/pdf/2408.17401v2",
      "published_date": "2024-08-30 16:36:53 UTC",
      "updated_date": "2025-02-17 17:49:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:00:10.815620"
    },
    {
      "arxiv_id": "2408.17383v2",
      "title": "MoRe Fine-Tuning with 10x Fewer Parameters",
      "title_zh": "翻译失败",
      "authors": [
        "Wenxuan Tan",
        "Nicholas Roberts",
        "Tzu-Heng Huang",
        "Jitian Zhao",
        "John Cooper",
        "Samuel Guo",
        "Chengyu Duan",
        "Frederic Sala"
      ],
      "abstract": "Parameter-efficient fine-tuning (PEFT) techniques have unlocked the potential\nto cheaply and easily specialize large pretrained models. However, the most\nprominent approaches, like low-rank adapters (LoRA), depend on heuristics or\nrules-of-thumb for their architectural choices -- potentially limiting their\nperformance for new models and architectures. This limitation suggests that\ntechniques from neural architecture search could be used to obtain optimal\nadapter architectures, but these are often expensive and difficult to\nimplement. We address this challenge with Monarch Rectangular Fine-tuning\n(MoRe), a simple framework to search over adapter architectures that relies on\nthe Monarch matrix class. Theoretically, we show that MoRe is more expressive\nthan LoRA. Empirically, our approach is more parameter-efficient and performant\nthan state-of-the-art PEFTs on a range of tasks and models, with as few as 5\\%\nof LoRA's parameters.",
      "tldr_zh": "该论文提出MoRe（Monarch Rectangular Fine-Tuning）框架，用于参数高效微调（PEFT），通过基于Monarch矩阵类的架构搜索来优化适配器设计，从而避免传统方法如低秩适配器（LoRA）的启发式依赖。MoRe在理论上比LoRA更具表现力，能以更少的参数实现高效微调。实验结果显示，MoRe在多种任务和模型上优于现有PEFT方法，仅使用LoRA的5%参数，实现了显著的性能提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.17383v2",
      "published_date": "2024-08-30 16:24:27 UTC",
      "updated_date": "2025-04-05 19:41:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:00:18.770505"
    },
    {
      "arxiv_id": "2409.00163v1",
      "title": "Deep Neural Networks for Predicting Recurrence and Survival in Patients with Esophageal Cancer After Surgery",
      "title_zh": "深度神经网络用于预测手术后食管癌患者的复发和生存",
      "authors": [
        "Yuhan Zheng",
        "Jessie A Elliott",
        "John V Reynolds",
        "Sheraz R Markar",
        "Bartłomiej W. Papież",
        "ENSURE study group"
      ],
      "abstract": "Esophageal cancer is a major cause of cancer-related mortality\ninternationally, with high recurrence rates and poor survival even among\npatients treated with curative-intent surgery. Investigating relevant\nprognostic factors and predicting prognosis can enhance post-operative clinical\ndecision-making and potentially improve patients' outcomes. In this work, we\nassessed prognostic factor identification and discriminative performances of\nthree models for Disease-Free Survival (DFS) and Overall Survival (OS) using a\nlarge multicenter international dataset from ENSURE study. We first employed\nCox Proportional Hazards (CoxPH) model to assess the impact of each feature on\noutcomes. Subsequently, we utilised CoxPH and two deep neural network\n(DNN)-based models, DeepSurv and DeepHit, to predict DFS and OS. The\nsignificant prognostic factors identified by our models were consistent with\nclinical literature, with post-operative pathologic features showing higher\nsignificance than clinical stage features. DeepSurv and DeepHit demonstrated\ncomparable discriminative accuracy to CoxPH, with DeepSurv slightly\noutperforming in both DFS and OS prediction tasks, achieving C-index of 0.735\nand 0.74, respectively. While these results suggested the potential of DNNs as\nprognostic tools for improving predictive accuracy and providing personalised\nguidance with respect to risk stratification, CoxPH still remains an adequately\ngood prediction model, with the data used in this study.",
      "tldr_zh": "这篇论文利用深度神经网络模型预测食道癌患者手术后的无病生存期(DFS)和整体生存期(OS)，旨在识别预后因素并改善临床决策。研究者使用Cox Proportional Hazards (CoxPH)、DeepSurv和DeepHit模型分析ENSURE数据集，结果显示术后病理特征比临床分期特征更具显著影响。DeepSurv在预测性能上略优于CoxPH，DFS和OS的C-index分别为0.735和0.74，表明DNNs有潜力提供更精确的个性化风险分层，但CoxPH仍是有效的基准模型。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 3 figures, 4 tables. To appear in CaPTion: MICCAI Workshop\n  on Cancer Prevention, detection, and intervenTion, Sharib Ali et al., MICCAI\n  2024, Lecture Notes in Computer Science, Springer",
      "pdf_url": "http://arxiv.org/pdf/2409.00163v1",
      "published_date": "2024-08-30 16:20:47 UTC",
      "updated_date": "2024-08-30 16:20:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:00:32.745254"
    },
    {
      "arxiv_id": "2408.17380v2",
      "title": "Traffic expertise meets residual RL: Knowledge-informed model-based residual reinforcement learning for CAV trajectory control",
      "title_zh": "翻译失败",
      "authors": [
        "Zihao Sheng",
        "Zilin Huang",
        "Sikai Chen"
      ],
      "abstract": "Model-based reinforcement learning (RL) is anticipated to exhibit higher\nsample efficiency compared to model-free RL by utilizing a virtual environment\nmodel. However, it is challenging to obtain sufficiently accurate\nrepresentations of the environmental dynamics due to uncertainties in complex\nsystems and environments. An inaccurate environment model may degrade the\nsample efficiency and performance of model-based RL. Furthermore, while\nmodel-based RL can improve sample efficiency, it often still requires\nsubstantial training time to learn from scratch, potentially limiting its\nadvantages over model-free approaches. To address these challenges, this paper\nintroduces a knowledge-informed model-based residual reinforcement learning\nframework aimed at enhancing learning efficiency by infusing established expert\nknowledge into the learning process and avoiding the issue of beginning from\nzero. Our approach integrates traffic expert knowledge into a virtual\nenvironment model, employing the Intelligent Driver Model (IDM) for basic\ndynamics and neural networks for residual dynamics, thus ensuring adaptability\nto complex scenarios. We propose a novel strategy that combines traditional\ncontrol methods with residual RL, facilitating efficient learning and policy\noptimization without the need to learn from scratch. The proposed approach is\napplied to CAV trajectory control tasks for the dissipation of stop-and-go\nwaves in mixed traffic flow. Experimental results demonstrate that our proposed\napproach enables the CAV agent to achieve superior performance in trajectory\ncontrol compared to the baseline agents in terms of sample efficiency, traffic\nflow smoothness and traffic mobility. The source code and supplementary\nmaterials are available at: https://zihaosheng.github.io/traffic-expertise-RL/.",
      "tldr_zh": "该论文提出了一种知识注入的模型-based 残差强化学习框架，旨在解决模型-based reinforcement learning 在复杂环境中模型不准确和训练效率低的问题。该框架通过整合交通专家知识，如 Intelligent Driver Model (IDM) 来处理基本动态，并使用神经网络学习残差动态，从而避免从零开始训练，并提升学习效率。在 Connected and Automated Vehicles (CAV) 轨迹控制任务中，该方法应用于消散 stop-and-go waves 的混合交通流，实验结果显示其在样本效率、交通流顺畅性和交通流动性方面均优于基线代理。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by Communications in Transportation Research",
      "pdf_url": "http://arxiv.org/pdf/2408.17380v2",
      "published_date": "2024-08-30 16:16:57 UTC",
      "updated_date": "2025-02-03 03:48:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:00:46.381746"
    },
    {
      "arxiv_id": "2408.17379v2",
      "title": "EMPOWER: Embodied Multi-role Open-vocabulary Planning with Online Grounding and Execution",
      "title_zh": "翻译失败",
      "authors": [
        "Francesco Argenziano",
        "Michele Brienza",
        "Vincenzo Suriani",
        "Daniele Nardi",
        "Domenico D. Bloisi"
      ],
      "abstract": "Task planning for robots in real-life settings presents significant\nchallenges. These challenges stem from three primary issues: the difficulty in\nidentifying grounded sequences of steps to achieve a goal; the lack of a\nstandardized mapping between high-level actions and low-level commands; and the\nchallenge of maintaining low computational overhead given the limited resources\nof robotic hardware. We introduce EMPOWER, a framework designed for\nopen-vocabulary online grounding and planning for embodied agents aimed at\naddressing these issues. By leveraging efficient pre-trained foundation models\nand a multi-role mechanism, EMPOWER demonstrates notable improvements in\ngrounded planning and execution. Quantitative results highlight the\neffectiveness of our approach, achieving an average success rate of 0.73 across\nsix different real-life scenarios using a TIAGo robot.",
      "tldr_zh": "该研究针对机器人任务规划的挑战，包括识别接地序列、标准化高低级命令映射以及降低计算开销，提出EMPOWER框架。该框架利用高效的预训练foundation models和multi-role mechanism，实现open-vocabulary online grounding和规划，从而提升embodied agents的规划和执行效果。在六个真实场景中使用TIAGo robot进行实验，平均成功率达到0.73，展示了显著的改进潜力。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted at IROS 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.17379v2",
      "published_date": "2024-08-30 16:15:28 UTC",
      "updated_date": "2024-10-22 16:58:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:00:53.100858"
    },
    {
      "arxiv_id": "2409.00162v1",
      "title": "Sequence to Sequence Reward Modeling: Improving RLHF by Language Feedback",
      "title_zh": "序列到序列奖励建模：通过语言反馈改进 RLHF",
      "authors": [
        "Jiayi Zhou",
        "Jiaming Ji",
        "Juntao Dai",
        "Yaodong Yang"
      ],
      "abstract": "Aligning the behavior of Large language models (LLMs) with human intentions\nand values remains a critical challenge. Reinforcement learning from human\nfeedback (RLHF) aligns LLMs by training a reward model (RM) on human\npreferences and fine-tuning the LLMs to maximize RM feedback. Despite its\neffectiveness and popularity, RLHF is prone to biased local optimization. It\nmeans RM fails to provide feedback that accurately aligns with human\npreference, causing LLMs to explore unexpected generalizations, and failing to\nachieve alignment objectives. To mitigate this issue, we propose a novel\n\\textit{sequence-to-sequence (seq2seq) reward modeling} method. Its key insight\nis that learning from language feedback rather than scalar feedback improves\nRLHF without additional annotations. We replaced the reward modeling target\nfrom binary maximum likelihood estimation (MLE) with sequence MLE. This method\nenables richer and fine-grained language feedback without additional\nannotations, models, or training stages. Our experiments demonstrated its\neffectiveness, specifically, reducing the refusal-to-response paradigm in\nsingle-turn safety dialogues and the long-response bias in text summarization\ntasks. We provide further analysis that seq2seq RM improves RLHF performance\nacross 2B and 7B LLMs on 3 NLP tasks, achieving an average win rate of 76.9\\%.\nWe further show that seq2seq RM can still improve the performance of RLHF under\nout-of-distribution prompts.",
      "tldr_zh": "该论文针对强化学习从人类反馈（RLHF）中存在的偏置问题，提出了一种seq2seq reward modeling方法，通过从语言反馈而非标量反馈中学习来提升LLMs的行为对齐。核心创新是将奖励模型的目标从二元最大似然估计（MLE）替换为序列MLE，从而提供更丰富和细粒度的反馈，而无需额外标注或训练阶段。实验结果显示，该方法在3个NLP任务上显著改善RLHF性能，平均获胜率达76.9%，并在2B和7B LLMs模型中减少拒绝响应和长响应偏差，即使在分布外提示下也能保持有效。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "7 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.00162v1",
      "published_date": "2024-08-30 16:14:35 UTC",
      "updated_date": "2024-08-30 16:14:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:01:07.410982"
    },
    {
      "arxiv_id": "2408.17377v1",
      "title": "NDP: Next Distribution Prediction as a More Broad Target",
      "title_zh": "NDP：下一分布预测作为更广泛的目标",
      "authors": [
        "Junhao Ruan",
        "Abudukeyumu Abudula",
        "Xinyu Liu",
        "Bei Li",
        "Yinqiao Li",
        "Chenglong Wang",
        "Yuchun Fan",
        "Yuan Ge",
        "Tong Xiao",
        "Jingbo Zhu"
      ],
      "abstract": "Large language models (LLMs) trained on next-token prediction (NTP) paradigm\nhave demonstrated powerful capabilities. However, the existing NTP paradigm\ncontains several limitations, particularly related to planned task\ncomplications and error propagation during inference. In our work, we extend\nthe critique of NTP, highlighting its limitation also due to training with a\nnarrow objective: the prediction of a sub-optimal one-hot distribution. To\nsupport this critique, we conducted a pre-experiment treating the output\ndistribution from powerful LLMs as efficient world data compression. By\nevaluating the similarity between the $n$-gram distribution and the one-hot\ndistribution with LLMs, we observed that the $n$-gram distributions align more\nclosely with the output distribution of LLMs. Based on this insight, we\nintroduce Next Distribution Prediction (NDP), which uses $n$-gram distributions\nto replace the one-hot targets, enhancing learning without extra online\ntraining time. We conducted experiments across translation, general task,\nlanguage transfer, and medical domain adaptation. Compared to NTP, NDP can\nachieve up to +2.97 COMET improvement in translation tasks, +0.61 average\nimprovement in general tasks, and incredible +10.75 average improvement in the\nmedical domain. This demonstrates the concrete benefits of addressing the\ntarget narrowing problem, pointing to a new direction for future work on\nimproving NTP.",
      "tldr_zh": "该论文批评了大型语言模型（LLMs）基于 Next-Token Prediction (NTP) 范式的局限性，包括任务复杂性、错误传播和目标过于狭窄（如预测 one-hot 分布）。为了解决这些问题，作者提出 Next Distribution Prediction (NDP) 方法，使用 n-gram 分布替换 one-hot 目标，从而增强模型学习效果，而无需额外在线训练时间。实验结果显示，NDP 在翻译任务上提升高达 +2.97 COMET、在一般任务上平均提高 +0.61、在医疗领域平均提高 +10.75，证明了解决目标狭窄问题的实际益处，并为改进 NTP 提供了新方向。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages,5 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.17377v1",
      "published_date": "2024-08-30 16:13:49 UTC",
      "updated_date": "2024-08-30 16:13:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:01:18.956007"
    },
    {
      "arxiv_id": "2409.00160v1",
      "title": "Learning-Based Finite Element Methods Modeling for Complex Mechanical Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Jiasheng Shi",
        "Fu Lin",
        "Weixiong Rao"
      ],
      "abstract": "Complex mechanic systems simulation is important in many real-world\napplications. The de-facto numeric solver using Finite Element Method (FEM)\nsuffers from computationally intensive overhead. Though with many progress on\nthe reduction of computational time and acceptable accuracy, the recent CNN or\nGNN-based simulation models still struggle to effectively represent complex\nmechanic simulation caused by the long-range spatial dependency of distance\nmesh nodes and independently learning local and global representation. In this\npaper, we propose a novel two-level mesh graph network. The key of the network\nis to interweave the developed Graph Block and Attention Block to better learn\nmechanic interactions even for long-rang spatial dependency. Evaluation on\nthree synthetic and one real datasets demonstrates the superiority of our work.\nFor example, on the Beam dataset, our work leads to 54.3\\% lower prediction\nerrors and 9.87\\% fewer learnable network parameters.",
      "tldr_zh": "该研究针对复杂机械系统模拟的计算密集问题，提出了一种基于学习的学习型有限元方法（Finite Element Method）建模框架，以解决现有CNN或GNN模型在处理长距离空间依赖性和局部/全局表示方面的不足。关键创新是设计一个两级网格图网络，通过交织Graph Block和Attention Block来更好地捕捉机械交互。实验在三个合成数据集和一个真实数据集上验证了该方法的优越性，例如在Beam数据集上，预测错误率降低了54.3%，同时可学习网络参数减少了9.87%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.00160v1",
      "published_date": "2024-08-30 15:56:50 UTC",
      "updated_date": "2024-08-30 15:56:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:01:40.679097"
    },
    {
      "arxiv_id": "2408.17366v1",
      "title": "Leveraging Graph Neural Networks to Forecast Electricity Consumption",
      "title_zh": "利用图神经网络预测电力消耗",
      "authors": [
        "Eloi Campagne",
        "Yvenn Amara-Ouali",
        "Yannig Goude",
        "Argyris Kalogeratos"
      ],
      "abstract": "Accurate electricity demand forecasting is essential for several reasons,\nespecially as the integration of renewable energy sources and the transition to\na decentralized network paradigm introduce greater complexity and uncertainty.\nThe proposed methodology leverages graph-based representations to effectively\ncapture the spatial distribution and relational intricacies inherent in this\ndecentralized network structure. This research work offers a novel approach\nthat extends beyond the conventional Generalized Additive Model framework by\nconsidering models like Graph Convolutional Networks or Graph SAGE. These\ngraph-based models enable the incorporation of various levels of\ninterconnectedness and information sharing among nodes, where each node\ncorresponds to the combined load (i.e. consumption) of a subset of consumers\n(e.g. the regions of a country). More specifically, we introduce a range of\nmethods for inferring graphs tailored to consumption forecasting, along with a\nframework for evaluating the developed models in terms of both performance and\nexplainability. We conduct experiments on electricity forecasting, in both a\nsynthetic and a real framework considering the French mainland regions, and the\nperformance and merits of our approach are discussed.",
      "tldr_zh": "这篇论文提出了一种利用Graph Neural Networks（如Graph Convolutional Networks或Graph SAGE）来预测电力消费的方法，以应对可再生能源整合和去中心化网络带来的复杂性和不确定性。该方法超越了传统的Generalized Additive Model框架，通过图-based表示捕捉节点间（如国家地区）的空间分布和关系互联，并引入了专属的图推断方法和评估框架。实验在合成数据和法国大陆真实数据上进行，展示了该方法的性能优势和可解释性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages, ECML PKDD 2024 Workshop paper",
      "pdf_url": "http://arxiv.org/pdf/2408.17366v1",
      "published_date": "2024-08-30 15:54:50 UTC",
      "updated_date": "2024-08-30 15:54:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:01:53.283763"
    },
    {
      "arxiv_id": "2409.10527v1",
      "title": "Towards Empathetic Conversational Recommender Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoyu Zhang",
        "Ruobing Xie",
        "Yougang Lyu",
        "Xin Xin",
        "Pengjie Ren",
        "Mingfei Liang",
        "Bo Zhang",
        "Zhanhui Kang",
        "Maarten de Rijke",
        "Zhaochun Ren"
      ],
      "abstract": "Conversational recommender systems (CRSs) are able to elicit user preferences\nthrough multi-turn dialogues. They typically incorporate external knowledge and\npre-trained language models to capture the dialogue context. Most CRS\napproaches, trained on benchmark datasets, assume that the standard items and\nresponses in these benchmarks are optimal. However, they overlook that users\nmay express negative emotions with the standard items and may not feel\nemotionally engaged by the standard responses. This issue leads to a tendency\nto replicate the logic of recommenders in the dataset instead of aligning with\nuser needs. To remedy this misalignment, we introduce empathy within a CRS.\nWith empathy we refer to a system's ability to capture and express emotions. We\npropose an empathetic conversational recommender (ECR) framework.\n  ECR contains two main modules: emotion-aware item recommendation and\nemotion-aligned response generation. Specifically, we employ user emotions to\nrefine user preference modeling for accurate recommendations. To generate\nhuman-like emotional responses, ECR applies retrieval-augmented prompts to\nfine-tune a pre-trained language model aligning with emotions and mitigating\nhallucination. To address the challenge of insufficient supervision labels, we\nenlarge our empathetic data using emotion labels annotated by large language\nmodels and emotional reviews collected from external resources. We propose\nnovel evaluation metrics to capture user satisfaction in real-world CRS\nscenarios. Our experiments on the ReDial dataset validate the efficacy of our\nframework in enhancing recommendation accuracy and improving user satisfaction.",
      "tldr_zh": "本论文针对对话推荐系统（CRSs）忽略用户情感的问题，提出了一种移情对话推荐框架（ECR），旨在通过捕捉和表达用户情绪来提升推荐准确性和用户满意度。ECR 包含两个核心模块：emotion-aware item recommendation，利用用户情绪来优化偏好建模；以及 emotion-aligned response generation，通过检索增强提示（RAG）微调预训练语言模型，生成情感对齐的响应。针对监督标签不足的挑战，作者使用大型语言模型标注情感标签，并从外部资源收集情感评论，以扩充数据集。实验在 ReDial 数据集上验证了 ECR 的有效性，显著提高了推荐准确率并改善了用户满意度。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.10527v1",
      "published_date": "2024-08-30 15:43:07 UTC",
      "updated_date": "2024-08-30 15:43:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:01:58.816872"
    },
    {
      "arxiv_id": "2408.17356v1",
      "title": "C-RADAR: A Centralized Deep Learning System for Intrusion Detection in Software Defined Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Osama Mustafa",
        "Khizer Ali",
        "Talha Naqash"
      ],
      "abstract": "The popularity of Software Defined Networks (SDNs) has grown in recent years,\nmainly because of their ability to simplify network management and improve\nnetwork flexibility. However, this also makes them vulnerable to various types\nof cyber attacks. SDNs work on a centralized control plane which makes them\nmore prone to network attacks. Research has demonstrated that deep learning\n(DL) methods can be successful in identifying intrusions in conventional\nnetworks, but their application in SDNs is still an open research area. In this\nresearch, we propose the use of DL techniques for intrusion detection in SDNs.\nWe measure the effectiveness of our method by experimentation on a dataset of\nnetwork traffic and comparing it to existing techniques. Our results show that\nthe DL-based approach outperforms traditional methods in terms of detection\naccuracy and computational efficiency. The deep learning architecture that has\nbeen used in this research is a Long Short Term Memory Network and\nSelf-Attention based architecture i.e. LSTM-Attn which achieves an Fl-score of\n0.9721. Furthermore, this technique can be trained to detect new attack\npatterns and improve the overall security of SDNs.",
      "tldr_zh": "本研究提出C-RADAR，一种基于深度学习的集中式系统，用于检测软件定义网络（SDN）中的入侵，旨在解决SDN因集中式控制平面而易受网络攻击的问题。系统采用Long Short Term Memory Network and Self-Attention based architecture（LSTM-Attn）架构，在网络流量数据集上进行实验，实现了0.9721的F1-score，并在检测准确性和计算效率上优于传统方法。该技术还能训练以识别新攻击模式，从而提升SDN的整体安全性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.17356v1",
      "published_date": "2024-08-30 15:39:37 UTC",
      "updated_date": "2024-08-30 15:39:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:02:10.549559"
    },
    {
      "arxiv_id": "2408.17355v4",
      "title": "Bidirectional Decoding: Improving Action Chunking via Guided Test-Time Sampling",
      "title_zh": "双向解码：通过引导的测试时采样改善动作分块",
      "authors": [
        "Yuejiang Liu",
        "Jubayer Ibn Hamid",
        "Annie Xie",
        "Yoonho Lee",
        "Maximilian Du",
        "Chelsea Finn"
      ],
      "abstract": "Predicting and executing a sequence of actions without intermediate\nreplanning, known as action chunking, is increasingly used in robot learning\nfrom human demonstrations. Yet, its effects on the learned policy remain\ninconsistent: some studies find it crucial for achieving strong results, while\nothers observe decreased performance. In this paper, we first dissect how\naction chunking impacts the divergence between a learner and a demonstrator. We\nfind that action chunking allows the learner to better capture the temporal\ndependencies in demonstrations but at the cost of reduced reactivity to\nunexpected states. To address this tradeoff, we propose Bidirectional Decoding\n(BID), a test-time inference algorithm that bridges action chunking with\nclosed-loop adaptation. At each timestep, BID samples multiple candidate\npredictions and searches for the optimal one based on two criteria: (i)\nbackward coherence, which favors samples that align with previous decisions;\n(ii) forward contrast, which seeks samples of high likelihood for future plans.\nBy coupling decisions within and across action chunks, BID promotes both\nlong-term consistency and short-term reactivity. Experimental results show that\nour method boosts the performance of two state-of-the-art generative policies\nacross seven simulation benchmarks and two real-world tasks. Code and videos\nare available at https://bid-robot.github.io.",
      "tldr_zh": "这篇论文探讨了行动分块（action chunking）在机器人学习中的双重影响：它有助于捕获演示中的时间依赖性，但会降低对意外状态的反应性。作者提出Bidirectional Decoding (BID)算法，作为一种测试时推理方法，通过采样多个候选预测并基于后向一致性（backward coherence）和前向对比（forward contrast）选择最佳方案，从而实现行动分块与闭环适应的平衡。实验结果显示，BID在七个模拟基准和两个真实世界任务上显著提升了两种最先进生成策略的性能。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Project website: https://bid-robot.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2408.17355v4",
      "published_date": "2024-08-30 15:39:34 UTC",
      "updated_date": "2025-04-25 17:27:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:02:21.335740"
    },
    {
      "arxiv_id": "2408.17354v1",
      "title": "Forget to Flourish: Leveraging Machine-Unlearning on Pretrained Language Models for Privacy Leakage",
      "title_zh": "翻译失败",
      "authors": [
        "Md Rafi Ur Rashid",
        "Jing Liu",
        "Toshiaki Koike-Akino",
        "Shagufta Mehnaz",
        "Ye Wang"
      ],
      "abstract": "Fine-tuning large language models on private data for downstream applications\nposes significant privacy risks in potentially exposing sensitive information.\nSeveral popular community platforms now offer convenient distribution of a\nlarge variety of pre-trained models, allowing anyone to publish without\nrigorous verification. This scenario creates a privacy threat, as pre-trained\nmodels can be intentionally crafted to compromise the privacy of fine-tuning\ndatasets. In this study, we introduce a novel poisoning technique that uses\nmodel-unlearning as an attack tool. This approach manipulates a pre-trained\nlanguage model to increase the leakage of private data during the fine-tuning\nprocess. Our method enhances both membership inference and data extraction\nattacks while preserving model utility. Experimental results across different\nmodels, datasets, and fine-tuning setups demonstrate that our attacks\nsignificantly surpass baseline performance. This work serves as a cautionary\nnote for users who download pre-trained models from unverified sources,\nhighlighting the potential risks involved.",
      "tldr_zh": "本研究探讨了微调预训练语言模型时存在的隐私泄露风险，特别是在从未验证来源下载模型时，可能被恶意设计以泄露敏感数据。该论文提出了一种新型投毒技术，利用 machine-unlearning 作为攻击工具，操纵预训练模型以增加微调过程中的隐私泄露，同时提升 membership inference 和 data extraction attacks 的性能，同时保持模型的实用性。实验结果在不同模型、数据集和微调设置下显示，该攻击显著优于基线方法，并作为警醒，提醒用户注意从未经验证平台获取预训练模型的潜在风险。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.17354v1",
      "published_date": "2024-08-30 15:35:09 UTC",
      "updated_date": "2024-08-30 15:35:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:02:32.498866"
    },
    {
      "arxiv_id": "2408.17352v1",
      "title": "AASIST3: KAN-Enhanced AASIST Speech Deepfake Detection using SSL Features and Additional Regularization for the ASVspoof 2024 Challenge",
      "title_zh": "翻译失败",
      "authors": [
        "Kirill Borodin",
        "Vasiliy Kudryavtsev",
        "Dmitrii Korzh",
        "Alexey Efimenko",
        "Grach Mkrtchian",
        "Mikhail Gorodnichev",
        "Oleg Y. Rogov"
      ],
      "abstract": "Automatic Speaker Verification (ASV) systems, which identify speakers based\non their voice characteristics, have numerous applications, such as user\nauthentication in financial transactions, exclusive access control in smart\ndevices, and forensic fraud detection. However, the advancement of deep\nlearning algorithms has enabled the generation of synthetic audio through\nText-to-Speech (TTS) and Voice Conversion (VC) systems, exposing ASV systems to\npotential vulnerabilities. To counteract this, we propose a novel architecture\nnamed AASIST3. By enhancing the existing AASIST framework with\nKolmogorov-Arnold networks, additional layers, encoders, and pre-emphasis\ntechniques, AASIST3 achieves a more than twofold improvement in performance. It\ndemonstrates minDCF results of 0.5357 in the closed condition and 0.1414 in the\nopen condition, significantly enhancing the detection of synthetic voices and\nimproving ASV security.",
      "tldr_zh": "本研究针对自动说话者验证（ASV）系统易受 Text-to-Speech (TTS) 和 Voice Conversion (VC) 生成的合成音频攻击的问题，提出了一种新型架构 AASIST3。AASIST3 在原有 AASIST 框架基础上，融入 Kolmogorov-Arnold networks (KAN)、额外层、编码器以及预强调技术，并结合 SSL Features 和 Additional Regularization，提升了语音深度伪造检测性能。实验结果显示，AASIST3 在 ASVspoof 2024 Challenge 中实现了 minDCF 值为闭合条件 0.5357 和开放条件 0.1414 的成绩，比原有框架性能提升一倍多，从而显著增强了 ASV 系统的安全性和鲁棒性。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "8 pages, 2 figures, 2 tables. Accepted paper at the ASVspoof 2024\n  (the 25th Interspeech Conference)",
      "pdf_url": "http://arxiv.org/pdf/2408.17352v1",
      "published_date": "2024-08-30 15:30:01 UTC",
      "updated_date": "2024-08-30 15:30:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:02:43.669842"
    },
    {
      "arxiv_id": "2408.17344v2",
      "title": "rerankers: A Lightweight Python Library to Unify Ranking Methods",
      "title_zh": "翻译失败",
      "authors": [
        "Benjamin Clavié"
      ],
      "abstract": "This paper presents rerankers, a Python library which provides an easy-to-use\ninterface to the most commonly used re-ranking approaches. Re-ranking is an\nintegral component of many retrieval pipelines; however, there exist numerous\napproaches to it, relying on different implementation methods. rerankers\nunifies these methods into a single user-friendly interface, allowing\npractitioners and researchers alike to explore different methods while only\nchanging a single line of Python code. Moreover ,rerankers ensures that its\nimplementations are done with the fewest dependencies possible, and re-uses the\noriginal implementation whenever possible, guaranteeing that our simplified\ninterface results in no performance degradation compared to more complex ones.\nThe full source code and list of supported models are updated regularly and\navailable at https://github.com/answerdotai/rerankers.",
      "tldr_zh": "这篇论文介绍了 rerankers，一个轻量级的 Python 库，旨在统一常见的 re-ranking 方法，提供一个易于使用的接口。rerankers 允许用户只需修改一行代码即可探索多种 re-ranking 技术，同时通过最小化依赖并复用原实现，确保性能与复杂接口相当。库的源代码和支持模型列表在 GitHub 上定期更新，便于研究者和从业者应用。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.17344v2",
      "published_date": "2024-08-30 15:16:52 UTC",
      "updated_date": "2024-09-03 10:50:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:02:54.836866"
    },
    {
      "arxiv_id": "2409.10526v1",
      "title": "Effective Monitoring of Online Decision-Making Algorithms in Digital Intervention Implementation",
      "title_zh": "数字干预实施中在线决策算法的有效监控",
      "authors": [
        "Anna L. Trella",
        "Susobhan Ghosh",
        "Erin E. Bonar",
        "Lara Coughlin",
        "Finale Doshi-Velez",
        "Yongyi Guo",
        "Pei-Yao Hung",
        "Inbal Nahum-Shani",
        "Vivek Shetty",
        "Maureen Walton",
        "Iris Yan",
        "Kelly W. Zhang",
        "Susan A. Murphy"
      ],
      "abstract": "Online AI decision-making algorithms are increasingly used by digital\ninterventions to dynamically personalize treatment to individuals. These\nalgorithms determine, in real-time, the delivery of treatment based on accruing\ndata. The objective of this paper is to provide guidelines for enabling\neffective monitoring of online decision-making algorithms with the goal of (1)\nsafeguarding individuals and (2) ensuring data quality. We elucidate guidelines\nand discuss our experience in monitoring online decision-making algorithms in\ntwo digital intervention clinical trials (Oralytics and MiWaves). Our\nguidelines include (1) developing fallback methods, pre-specified procedures\nexecuted when an issue occurs, and (2) identifying potential issues\ncategorizing them by severity (red, yellow, and green). Across both trials, the\nmonitoring systems detected real-time issues such as out-of-memory issues,\ndatabase timeout, and failed communication with an external source. Fallback\nmethods prevented participants from not receiving any treatment during the\ntrial and also prevented the use of incorrect data in statistical analyses.\nThese trials provide case studies for how health scientists can build\nmonitoring systems for their digital intervention. Without these algorithm\nmonitoring systems, critical issues would have gone undetected and unresolved.\nInstead, these monitoring systems safeguarded participants and ensured the\nquality of the resulting data for updating the intervention and facilitating\nscientific discovery. These monitoring guidelines and findings give digital\nintervention teams the confidence to include online decision-making algorithms\nin digital interventions.",
      "tldr_zh": "该论文探讨了在线决策算法（online decision-making algorithms）在数字干预（digital interventions）中的有效监控，以保护个体安全并确保数据质量。作者基于Oralytics和MiWaves两个临床试验的经验，提出了指导方针，包括开发备用方法（fallback methods）和按严重性（red, yellow, and green）分类潜在问题。这些监控系统成功检测了实时问题，如内存不足（out-of-memory issues）和数据库超时，从而防止了参与者未获治疗和统计分析中使用错误数据。通过这些案例研究，论文证明了构建监控系统的重要性，为数字干预团队提供信心，支持在线决策算法的应用。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.10526v1",
      "published_date": "2024-08-30 15:13:58 UTC",
      "updated_date": "2024-08-30 15:13:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:03:20.423947"
    },
    {
      "arxiv_id": "2409.00159v3",
      "title": "LLMs Prompted for Graphs: Hallucinations and Generative Capabilities",
      "title_zh": "翻译失败",
      "authors": [
        "Gurvan Richardeau",
        "Samy Chali",
        "Erwan Le Merrer",
        "Camilla Penzo",
        "Gilles Tredan"
      ],
      "abstract": "Large Language Models (LLMs) are nowadays prompted for a wide variety of\ntasks. In this article, we investigate their ability in reciting and generating\ngraphs. We first study the ability of LLMs to regurgitate well known graphs\nfrom the literature (e.g. Karate club or the graph atlas)4. Secondly, we\nquestion the generative capabilities of LLMs by asking for Erdos-Renyi random\ngraphs. As opposed to the possibility that they could memorize some Erdos-Renyi\ngraphs included in their scraped training set, this second investigation aims\nat studying a possible emergent property of LLMs. For both tasks, we propose a\nmetric to assess their errors with the lens of hallucination (i.e. incorrect\ninformation returned as facts). We most notably find that the amplitude of\ngraph hallucinations can characterize the superiority of some LLMs. Indeed, for\nthe recitation task, we observe that graph hallucinations correlate with the\nHallucination Leaderboard, a hallucination rank that leverages 10, 000 times\nmore prompts to obtain its ranking. For the generation task, we find\nsurprisingly good and reproducible results in most of LLMs. We believe this to\nconstitute a starting point for more in-depth studies of this emergent\ncapability and a challenging benchmark for their improvements. Altogether,\nthese two aspects of LLMs capabilities bridge a gap between the network science\nand machine learning communities.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 在处理图 (graphs) 时的幻觉 (hallucinations) 和生成能力，具体考察了 LLMs 复述已知图（如 Karate club 或 graph atlas）和生成 Erdos-Renyi 随机图的性能。研究者提出了一种基于幻觉的度量指标来评估错误，并发现图幻觉的幅度能表征某些 LLMs 的优越性，与 Hallucination Leaderboard 的排名高度相关。实验结果显示，在生成任务中，大多数 LLMs 表现出惊人的良好和可重复性。该工作桥接了网络科学和机器学习社区，并为 LLMs 的新兴能力提供了挑战性基准。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.CL",
      "comment": "A preliminary version of this work appeared in the Complex Networks\n  2024 conference, under the title \"LLMs hallucinate graphs too: a structural\n  perspective\"",
      "pdf_url": "http://arxiv.org/pdf/2409.00159v3",
      "published_date": "2024-08-30 15:04:11 UTC",
      "updated_date": "2025-04-04 10:58:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:03:24.348832"
    },
    {
      "arxiv_id": "2409.00158v1",
      "title": "Developing an End-to-End Framework for Predicting the Social Communication Severity Scores of Children with Autism Spectrum Disorder",
      "title_zh": "翻译失败",
      "authors": [
        "Jihyun Mun",
        "Sunhee Kim",
        "Minhwa Chung"
      ],
      "abstract": "Autism Spectrum Disorder (ASD) is a lifelong condition that significantly\ninfluencing an individual's communication abilities and their social\ninteractions. Early diagnosis and intervention are critical due to the profound\nimpact of ASD's characteristic behaviors on foundational developmental stages.\nHowever, limitations of standardized diagnostic tools necessitate the\ndevelopment of objective and precise diagnostic methodologies. This paper\nproposes an end-to-end framework for automatically predicting the social\ncommunication severity of children with ASD from raw speech data. This\nframework incorporates an automatic speech recognition model, fine-tuned with\nspeech data from children with ASD, followed by the application of fine-tuned\npre-trained language models to generate a final prediction score. Achieving a\nPearson Correlation Coefficient of 0.6566 with human-rated scores, the proposed\nmethod showcases its potential as an accessible and objective tool for the\nassessment of ASD.",
      "tldr_zh": "本文提出一个端到端框架，用于从原始语音数据自动预测自闭症谱系障碍(ASD)儿童的社会沟通严重程度分数，以解决现有诊断工具的局限性。该框架结合fine-tuned的自动语音识别模型和预训练语言模型，对ASD儿童的语音数据进行处理并生成预测分数。实验结果显示，该方法与人工评分的相关系数(Pearson Correlation Coefficient)达到0.6566，证明其有效性。该框架为ASD的早期诊断和干预提供了一个客观、可访问的评估工具。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted for Interspeech 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.00158v1",
      "published_date": "2024-08-30 14:43:58 UTC",
      "updated_date": "2024-08-30 14:43:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:03:33.907916"
    },
    {
      "arxiv_id": "2408.17324v1",
      "title": "Modularity in Transformers: Investigating Neuron Separability & Specialization",
      "title_zh": "翻译失败",
      "authors": [
        "Nicholas Pochinkov",
        "Thomas Jones",
        "Mohammed Rashidur Rahman"
      ],
      "abstract": "Transformer models are increasingly prevalent in various applications, yet\nour understanding of their internal workings remains limited. This paper\ninvestigates the modularity and task specialization of neurons within\ntransformer architectures, focusing on both vision (ViT) and language (Mistral\n7B) models. Using a combination of selective pruning and MoEfication clustering\ntechniques, we analyze the overlap and specialization of neurons across\ndifferent tasks and data subsets. Our findings reveal evidence of task-specific\nneuron clusters, with varying degrees of overlap between related tasks. We\nobserve that neuron importance patterns persist to some extent even in randomly\ninitialized models, suggesting an inherent structure that training refines.\nAdditionally, we find that neuron clusters identified through MoEfication\ncorrespond more strongly to task-specific neurons in earlier and later layers\nof the models. This work contributes to a more nuanced understanding of\ntransformer internals and offers insights into potential avenues for improving\nmodel interpretability and efficiency.",
      "tldr_zh": "本研究调查了Transformer模型中神经元的模块性和专业化，聚焦于视觉模型(ViT)和语言模型(Mistral 7B)。通过结合selective pruning和MoEfication clustering技术，作者分析了神经元在不同任务和数据子集中的重叠与专业化，发现存在任务特定的神经元集群，且相关任务间有不同程度的共享；此外，神经元重要性模式在随机初始化模型中已初步显现，并通过训练进一步优化。MoEfication识别的神经元集群与模型早晚层的任务特定神经元高度相关，该工作为提升Transformer模型的可解释性和效率提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "68T07 (Primary) 68Q32, 68T05 (Secondary)",
        "I.2.4; I.2.6; I.2.7"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.17324v1",
      "published_date": "2024-08-30 14:35:01 UTC",
      "updated_date": "2024-08-30 14:35:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:03:45.163255"
    },
    {
      "arxiv_id": "2408.17322v1",
      "title": "Investigating Neuron Ablation in Attention Heads: The Case for Peak Activation Centering",
      "title_zh": "翻译失败",
      "authors": [
        "Nicholas Pochinkov",
        "Ben Pasero",
        "Skylar Shibayama"
      ],
      "abstract": "The use of transformer-based models is growing rapidly throughout society.\nWith this growth, it is important to understand how they work, and in\nparticular, how the attention mechanisms represent concepts. Though there are\nmany interpretability methods, many look at models through their neuronal\nactivations, which are poorly understood. We describe different lenses through\nwhich to view neuron activations, and investigate the effectiveness in language\nmodels and vision transformers through various methods of neural ablation: zero\nablation, mean ablation, activation resampling, and a novel approach we term\n'peak ablation'. Through experimental analysis, we find that in different\nregimes and models, each method can offer the lowest degradation of model\nperformance compared to other methods, with resampling usually causing the most\nsignificant performance deterioration. We make our code available at\nhttps://github.com/nickypro/investigating-ablation.",
      "tldr_zh": "本研究调查了Transformer模型中注意力头(attention heads)神经元激活的表示方式，重点评估了多种神经元消融方法，包括零消融(zero ablation)、均值消融(mean ablation)、激活重采样(activation resampling)以及一种新方法峰值激活居中(peak activation centering)。通过实验分析，这些方法在语言模型和视觉Transformer上表现出差异，其中每个方法在特定情境下可最小化性能下降，但激活重采样通常导致最显著的性能恶化。该工作为更好地理解神经元激活提供了新视角，并开源了代码以支持进一步研究。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "68T07 (Primary) 68T30, 68T50 (Secondary)",
        "I.2.4; I.2.6; I.2.7"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 2 figures, XAI World Conference 2024 Late-Breaking Work",
      "pdf_url": "http://arxiv.org/pdf/2408.17322v1",
      "published_date": "2024-08-30 14:32:25 UTC",
      "updated_date": "2024-08-30 14:32:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:03:58.768966"
    },
    {
      "arxiv_id": "2408.17316v1",
      "title": "Bridging Domain Knowledge and Process Discovery Using Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Ali Norouzifar",
        "Humam Kourani",
        "Marcus Dees",
        "Wil van der Aalst"
      ],
      "abstract": "Discovering good process models is essential for different process analysis\ntasks such as conformance checking and process improvements. Automated process\ndiscovery methods often overlook valuable domain knowledge. This knowledge,\nincluding insights from domain experts and detailed process documentation,\nremains largely untapped during process discovery. This paper leverages Large\nLanguage Models (LLMs) to integrate such knowledge directly into process\ndiscovery. We use rules derived from LLMs to guide model construction, ensuring\nalignment with both domain knowledge and actual process executions. By\nintegrating LLMs, we create a bridge between process knowledge expressed in\nnatural language and the discovery of robust process models, advancing process\ndiscovery methodologies significantly. To showcase the usability of our\nframework, we conducted a case study with the UWV employee insurance agency,\ndemonstrating its practical benefits and effectiveness.",
      "tldr_zh": "这篇论文探讨了如何利用 Large Language Models (LLMs) 桥接领域知识与过程发现的鸿沟，解决自动化过程发现方法忽略专家见解和文档等知识的问题。研究提出了一种框架，使用从 LLMs 派生的规则指导过程模型构建，确保模型与领域知识和实际执行数据一致，从而提升过程发现的鲁棒性和准确性。通过在 UWV 员工保险机构的案例研究中验证，该方法显著推进了过程分析任务，如一致性检查和过程改进的实际应用。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "This paper is accepted at the AI4BPM 2024 workshop and to be\n  published in their proceedings",
      "pdf_url": "http://arxiv.org/pdf/2408.17316v1",
      "published_date": "2024-08-30 14:23:40 UTC",
      "updated_date": "2024-08-30 14:23:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:04:09.507763"
    },
    {
      "arxiv_id": "2408.17313v1",
      "title": "Fair Best Arm Identification with Fixed Confidence",
      "title_zh": "固定置信",
      "authors": [
        "Alessio Russo",
        "Filippo Vannella"
      ],
      "abstract": "In this work, we present a novel framework for Best Arm Identification (BAI)\nunder fairness constraints, a setting that we refer to as \\textit{F-BAI} (fair\nBAI). Unlike traditional BAI, which solely focuses on identifying the optimal\narm with minimal sample complexity, F-BAI also includes a set of fairness\nconstraints. These constraints impose a lower limit on the selection rate of\neach arm and can be either model-agnostic or model-dependent. For this setting,\nwe establish an instance-specific sample complexity lower bound and analyze the\n\\textit{price of fairness}, quantifying how fairness impacts sample complexity.\nBased on the sample complexity lower bound, we propose F-TaS, an algorithm\nprovably matching the sample complexity lower bound, while ensuring that the\nfairness constraints are satisfied. Numerical results, conducted using both a\nsynthetic model and a practical wireless scheduling application, show the\nefficiency of F-TaS in minimizing the sample complexity while achieving low\nfairness violations.",
      "tldr_zh": "本研究提出了一种新的框架 F-BAI（Fair Best Arm Identification），在固定置信度下解决带公平约束的 Best Arm Identification (BAI) 问题，该框架要求每个 arm 的选择率达到最低下限，支持 model-agnostic 或 model-dependent 约束。论文建立了实例特定的样本复杂度下界，并量化了公平性的代价（price of fairness），展示了公平约束如何增加样本复杂度。基于此下界，作者设计了 F-TaS 算法，该算法能匹配样本复杂度下界，同时确保公平约束得到满足；实验在合成模型和实际无线调度应用中验证了 F-TaS 的效率，实现了最小样本复杂度和低公平违规率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.17313v1",
      "published_date": "2024-08-30 14:18:34 UTC",
      "updated_date": "2024-08-30 14:18:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:04:22.516953"
    },
    {
      "arxiv_id": "2408.17307v1",
      "title": "Hybridizing Base-Line 2D-CNN Model with Cat Swarm Optimization for Enhanced Advanced Persistent Threat Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Ali M. Bakhiet",
        "Salah A. Aly"
      ],
      "abstract": "In the realm of cyber-security, detecting Advanced Persistent Threats (APTs)\nremains a formidable challenge due to their stealthy and sophisticated nature.\nThis research paper presents an innovative approach that leverages\nConvolutional Neural Networks (CNNs) with a 2D baseline model, enhanced by the\ncutting-edge Cat Swarm Optimization (CSO) algorithm, to significantly improve\nAPT detection accuracy. By seamlessly integrating the 2D-CNN baseline model\nwith CSO, we unlock the potential for unprecedented accuracy and efficiency in\nAPT detection. The results unveil an impressive accuracy score of $98.4\\%$,\nmarking a significant enhancement in APT detection across various attack\nstages, illuminating a path forward in combating these relentless and\nsophisticated threats.",
      "tldr_zh": "这篇论文针对网络安全领域中高级持续性威胁 (APTs) 的检测挑战，提出了一种创新方法，将 2D-CNN 基线模型与 Cat Swarm Optimization (CSO) 算法相结合，以提升检测的准确性和效率。通过无缝整合 2D-CNN 和 CSO，该方法显著提高了 APT 检测性能，并在各种攻击阶段表现出色。实验结果显示，该方法的准确率达到 98.4%，为对抗这些隐蔽复杂的威胁提供了新的路径。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG",
        "cs.NI"
      ],
      "primary_category": "cs.CR",
      "comment": "6 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.17307v1",
      "published_date": "2024-08-30 14:11:12 UTC",
      "updated_date": "2024-08-30 14:11:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:04:43.983108"
    },
    {
      "arxiv_id": "2409.09053v1",
      "title": "Deep learning-based classification of breast cancer molecular subtypes from H&E whole-slide images",
      "title_zh": "翻译失败",
      "authors": [
        "Masoud Tafavvoghi",
        "Anders Sildnes",
        "Mehrdad Rakaee",
        "Nikita Shvetsov",
        "Lars Ailo Bongo",
        "Lill-Tove Rasmussen Busund",
        "Kajsa Møllersen"
      ],
      "abstract": "Classifying breast cancer molecular subtypes is crucial for tailoring\ntreatment strategies. While immunohistochemistry (IHC) and gene expression\nprofiling are standard methods for molecular subtyping, IHC can be subjective,\nand gene profiling is costly and not widely accessible in many regions.\nPrevious approaches have highlighted the potential application of deep learning\nmodels on H&E-stained whole slide images (WSI) for molecular subtyping, but\nthese efforts vary in their methods, datasets, and reported performance. In\nthis work, we investigated whether H&E-stained WSIs could be solely leveraged\nto predict breast cancer molecular subtypes (luminal A, B, HER2-enriched, and\nBasal). We used 1,433 WSIs of breast cancer in a two-step pipeline: first,\nclassifying tumor and non-tumor tiles to use only the tumor regions for\nmolecular subtyping; and second, employing a One-vs-Rest (OvR) strategy to\ntrain four binary OvR classifiers and aggregating their results using an\neXtreme Gradient Boosting (XGBoost) model. The pipeline was tested on 221\nhold-out WSIs, achieving an overall macro F1 score of 0.95 for tumor detection\nand 0.73 for molecular subtyping. Our findings suggest that, with further\nvalidation, supervised deep learning models could serve as supportive tools for\nmolecular subtyping in breast cancer. Our codes are made available to\nfacilitate ongoing research and development.",
      "tldr_zh": "本文提出了一种基于深度学习的管道，使用H&E whole-slide images (WSI)来分类乳腺癌分子亚型（包括luminal A, B, HER2-enriched和Basal），以解决immunohistochemistry (IHC)的主观性和gene expression profiling的成本高问题。方法包括两步：首先，通过分类器识别肿瘤和非肿瘤tiles，仅使用肿瘤区域；其次，采用One-vs-Rest (OvR)策略训练四个二元分类器，并使用eXtreme Gradient Boosting (XGBoost)模型聚合结果。在221张测试WSI上，该管道实现了肿瘤检测的宏观F1 score为0.95和分子亚型分类的F1 score为0.73。研究结果表明，这种监督深度学习方法可作为乳腺癌分子亚型的辅助工具，并公开了代码以推动进一步发展。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "16 pages, 5 figures (+4 supplementary figures), 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2409.09053v1",
      "published_date": "2024-08-30 13:57:33 UTC",
      "updated_date": "2024-08-30 13:57:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:04:49.023720"
    },
    {
      "arxiv_id": "2408.17298v1",
      "title": "Accelerating the discovery of steady-states of planetary interior dynamics with machine learning",
      "title_zh": "使用机器学习加速行星内部动力学稳态的发现",
      "authors": [
        "Siddhant Agarwal",
        "Nicola Tosi",
        "Christian Hüttig",
        "David S. Greenberg",
        "Ali Can Bekar"
      ],
      "abstract": "Simulating mantle convection often requires reaching a computationally\nexpensive steady-state, crucial for deriving scaling laws for thermal and\ndynamical flow properties and benchmarking numerical solutions. The strong\ntemperature dependence of the rheology of mantle rocks causes viscosity\nvariations of several orders of magnitude, leading to a slow-evolving stagnant\nlid where heat conduction dominates, overlying a rapidly-evolving and strongly\nconvecting region. Time-stepping methods, while effective for fluids with\nconstant viscosity, are hindered by the Courant criterion, which restricts the\ntime step based on the system's maximum velocity and grid size. Consequently,\nachieving steady-state requires a large number of time steps due to the\ndisparate time scales governing the stagnant and convecting regions.\n  We present a concept for accelerating mantle convection simulations using\nmachine learning. We generate a dataset of 128 two-dimensional simulations with\nmixed basal and internal heating, and pressure- and temperature-dependent\nviscosity. We train a feedforward neural network on 97 simulations to predict\nsteady-state temperature profiles. These can then be used to initialize\nnumerical time stepping methods for different simulation parameters. Compared\nto typical initializations, the number of time steps required to reach\nsteady-state is reduced by a median factor of 3.75. The benefit of this method\nlies in requiring very few simulations to train on, providing a solution with\nno prediction error as we initialize a numerical method, and posing minimal\ncomputational overhead at inference time. We demonstrate the effectiveness of\nour approach and discuss the potential implications for accelerated simulations\nfor advancing mantle convection research.",
      "tldr_zh": "该研究针对地幔对流模拟中达到稳态计算资源密集的问题，提出了一种基于machine learning的方法来加速过程。作者生成一个包含128个二维模拟的数据集，并训练一个feedforward neural network在97个模拟上预测稳态温度分布，以初始化数值时间步进方法。结果显示，与传统初始化相比，该方法将达到稳态所需的时间步数中位数减少了3.75倍，并强调其优势在于训练数据少、无预测误差和推理时计算开销低。该方法有望推进地幔对流研究，推动planetary interior dynamics的模拟效率。",
      "categories": [
        "physics.flu-dyn",
        "astro-ph.EP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "physics.flu-dyn",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.17298v1",
      "published_date": "2024-08-30 13:55:19 UTC",
      "updated_date": "2024-08-30 13:55:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:04:58.819916"
    },
    {
      "arxiv_id": "2408.17286v2",
      "title": "Risk-averse Total-reward MDPs with ERM and EVaR",
      "title_zh": "翻译失败",
      "authors": [
        "Xihong Su",
        "Julien Grand-Clément",
        "Marek Petrik"
      ],
      "abstract": "Optimizing risk-averse objectives in discounted MDPs is challenging because\nmost models do not admit direct dynamic programming equations and require\ncomplex history-dependent policies. In this paper, we show that the risk-averse\n{\\em total reward criterion}, under the Entropic Risk Measure (ERM) and\nEntropic Value at Risk (EVaR) risk measures, can be optimized by a stationary\npolicy, making it simple to analyze, interpret, and deploy. We propose\nexponential value iteration, policy iteration, and linear programming to\ncompute optimal policies. Compared with prior work, our results only require\nthe relatively mild condition of transient MDPs and allow for {\\em both}\npositive and negative rewards. Our results indicate that the total reward\ncriterion may be preferable to the discounted criterion in a broad range of\nrisk-averse reinforcement learning domains.",
      "tldr_zh": "这篇论文探讨了在Markov Decision Processes (MDPs)中优化风险厌恶总奖励标准的风险挑战，特别是使用Entropic Risk Measure (ERM)和Entropic Value at Risk (EVaR)，证明了这些标准可以通过平稳策略实现，从而简化分析、解释和部署。作者提出了指数值迭代、策略迭代和线性规划等方法来计算最优策略，仅需暂态MDPs的条件，并支持正负奖励。与先前工作相比，该方法显示总奖励标准在风险厌恶强化学习领域可能比折扣标准更适用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.17286v2",
      "published_date": "2024-08-30 13:33:18 UTC",
      "updated_date": "2024-12-18 16:10:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:05:15.972034"
    },
    {
      "arxiv_id": "2409.09052v1",
      "title": "OrthoDoc: Multimodal Large Language Model for Assisting Diagnosis in Computed Tomography",
      "title_zh": "翻译失败",
      "authors": [
        "Youzhu Jin",
        "Yichen Zhang"
      ],
      "abstract": "Multimodal large language models (MLLMs) have achieved significant success in\nthe general field of image processing. Their emerging task generalization and\nfreeform conversational capabilities can greatly facilitate medical diagnostic\nassistance, helping patients better understand their conditions and enhancing\ndoctor-patient trust. Computed Tomography (CT) is a non-invasive imaging\ntechnique used to capture the internal mechanisms of a patient's condition and\nis widely utilized. However, in past research, the complex textural features of\nthis imaging data have made accurate interpretation by algorithms challenging,\nimpeding the performance of general LLMs in diagnostic assistance. To address\nthis, we developed OrthoDoc, a MLLM designed for CT diagnostics. OrthoDoc is\ntrained on 120,000 CT images and diagnostic reports and includes a\nRetrieval-Augmented Generation (RAG) module capable of effectively mitigating\nmodel hallucinations. This module is informed by extensive medical literature,\ntextbooks, and explanatory data. Thus, OrthoDoc not only processes complex CT\nimages but also stores, understands, and reasons over medical knowledge and\nlanguage. In extensive experiments, OrthoDoc outperforms commercial models led\nby GPT-4, demonstrating superior diagnostic capabilities and accuracy.\nSpecifically, OrthoDoc significantly surpasses existing models in the diagnosis\nof common orthopedic conditions such as fractures, arthritis, and tumors.\nAdditionally, OrthoDoc exhibits robust generalization and stability when\nhandling rare and complex cases.",
      "tldr_zh": "本文开发了 OrthoDoc，一种 Multimodal Large Language Model (MLLM) 专为 Computed Tomography (CT) 诊断辅助设计，旨在帮助患者理解病情并提升医患信任。OrthoDoc 通过训练于 120,000 张 CT 图像和诊断报告，并整合 Retrieval-Augmented Generation (RAG) 模块，利用医疗文献和教科书来缓解模型幻觉，实现对复杂图像的处理和医疗知识的推理。在实验中，OrthoDoc 优于 GPT-4 等商业模型，尤其在诊断骨科疾病如骨折、关节炎和肿瘤方面表现出色，并展示了处理罕见和复杂病例的强大泛化性和稳定性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "8 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2409.09052v1",
      "published_date": "2024-08-30 13:31:32 UTC",
      "updated_date": "2024-08-30 13:31:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:05:27.523114"
    },
    {
      "arxiv_id": "2408.17280v2",
      "title": "Flexible and Effective Mixing of Large Language Models into a Mixture of Domain Experts",
      "title_zh": "翻译失败",
      "authors": [
        "Rhui Dih Lee",
        "Laura Wynter",
        "Raghu Kiran Ganti"
      ],
      "abstract": "We present a toolkit for creating low-cost Mixture-of-Domain-Experts (MOE)\nfrom trained models. The toolkit can be used for creating a mixture from models\nor from adapters. We perform extensive tests and offer guidance on defining the\narchitecture of the resulting MOE using the toolkit. A public repository is\navailable.",
      "tldr_zh": "本研究提出了一种灵活有效的工具包，用于将大型语言模型(Large Language Models)混合成低成本的 Mixture-of-Domain-Experts (MOE)。该工具包支持从训练好的模型或 adapters 创建混合模型，并通过广泛测试提供关于定义 MOE 架构的指导。实验结果有助于优化 MOE 的设计，并附带公开仓库以便于应用和扩展。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.17280v2",
      "published_date": "2024-08-30 13:28:45 UTC",
      "updated_date": "2024-09-11 02:52:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:05:36.740013"
    },
    {
      "arxiv_id": "2408.17267v3",
      "title": "UrBench: A Comprehensive Benchmark for Evaluating Large Multimodal Models in Multi-View Urban Scenarios",
      "title_zh": "UrBench：用于评估大型多模态模型在多视图城市场景中的全面基准",
      "authors": [
        "Baichuan Zhou",
        "Haote Yang",
        "Dairong Chen",
        "Junyan Ye",
        "Tianyi Bai",
        "Jinhua Yu",
        "Songyang Zhang",
        "Dahua Lin",
        "Conghui He",
        "Weijia Li"
      ],
      "abstract": "Recent evaluations of Large Multimodal Models (LMMs) have explored their\ncapabilities in various domains, with only few benchmarks specifically focusing\non urban environments. Moreover, existing urban benchmarks have been limited to\nevaluating LMMs with basic region-level urban tasks under singular views,\nleading to incomplete evaluations of LMMs' abilities in urban environments. To\naddress these issues, we present UrBench, a comprehensive benchmark designed\nfor evaluating LMMs in complex multi-view urban scenarios. UrBench contains\n11.6K meticulously curated questions at both region-level and role-level that\ncover 4 task dimensions: Geo-Localization, Scene Reasoning, Scene\nUnderstanding, and Object Understanding, totaling 14 task types. In\nconstructing UrBench, we utilize data from existing datasets and additionally\ncollect data from 11 cities, creating new annotations using a cross-view\ndetection-matching method. With these images and annotations, we then integrate\nLMM-based, rule-based, and human-based methods to construct large-scale\nhigh-quality questions. Our evaluations on 21 LMMs show that current LMMs\nstruggle in the urban environments in several aspects. Even the best performing\nGPT-4o lags behind humans in most tasks, ranging from simple tasks such as\ncounting to complex tasks such as orientation, localization and object\nattribute recognition, with an average performance gap of 17.4%. Our benchmark\nalso reveals that LMMs exhibit inconsistent behaviors with different urban\nviews, especially with respect to understanding cross-view relations.",
      "tldr_zh": "该研究引入了UrBench，一个全面的基准，用于评估Large Multimodal Models (LMMs)在多视图城市场景中的性能，以弥补现有基准的局限性。UrBench包含11.6K个精心策划的问题，覆盖Geo-Localization、Scene Reasoning、Scene Understanding和Object Understanding等4个任务维度，总计14种任务类型，并通过现有数据集、新城市数据收集以及跨视图检测匹配方法进行构建。实验评估了21个LMMs，发现当前模型在城市环境中存在显著缺陷，即使表现最好的GPT-4o在多数任务（如计数、方向定位和物体属性识别）中落后于人类，平均差距达17.4%，并显示出在不同视图下理解跨视图关系的不一致性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.17267v3",
      "published_date": "2024-08-30 13:13:35 UTC",
      "updated_date": "2025-03-09 09:48:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:06:03.006950"
    },
    {
      "arxiv_id": "2408.17253v3",
      "title": "VisionTS: Visual Masked Autoencoders Are Free-Lunch Zero-Shot Time Series Forecasters",
      "title_zh": "翻译失败",
      "authors": [
        "Mouxiang Chen",
        "Lefei Shen",
        "Zhuo Li",
        "Xiaoyun Joy Wang",
        "Jianling Sun",
        "Chenghao Liu"
      ],
      "abstract": "Foundation models have emerged as a promising approach in time series\nforecasting (TSF). Existing approaches either repurpose large language models\n(LLMs) or build large-scale time series datasets to develop TSF foundation\nmodels for universal forecasting. However, these methods face challenges due to\nthe severe cross-domain gap or in-domain heterogeneity. This paper explores a\nnew road to building a TSF foundation model from rich, high-quality natural\nimages. Our key insight is that a visual masked autoencoder, pre-trained on the\nImageNet dataset, can naturally be a numeric series forecaster. By\nreformulating TSF as an image reconstruction task, we bridge the gap between\nimage pre-training and TSF downstream tasks. Surprisingly, without further\nadaptation in the time series domain, the proposed VisionTS could achieve\nbetter zero-shot forecast performance than existing TSF foundation models. With\nfine-tuning for one epoch, VisionTS could further improve the forecasting and\nachieve state-of-the-art performance in most cases. Extensive experiments\nreveal intrinsic similarities between images and real-world time series,\nsuggesting that visual models may offer a \"free lunch\" for TSF and highlight\nthe potential for future cross-modality research. Our code is publicly\navailable at https://github.com/Keytoyze/VisionTS.",
      "tldr_zh": "本研究提出VisionTS方法，利用在ImageNet上预训练的视觉Masked Autoencoders，将时间序列预测(TSF)重新表述为图像重建任务，从而桥接图像预训练与TSF下游任务的差距。无需进一步在时间序列领域适应，VisionTS即可实现零样本预测性能优于现有TSF基础模型；经过一轮微调，它进一步提升预测准确性，并在大多数情况下达到最先进水平。实验揭示了图像与真实世界时间序列的内在相似性，表明视觉模型可能为TSF提供“免费午餐”，并为未来跨模态研究打开新机遇。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "v3: add GIFT-EVAL results",
      "pdf_url": "http://arxiv.org/pdf/2408.17253v3",
      "published_date": "2024-08-30 12:51:55 UTC",
      "updated_date": "2025-02-04 04:37:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:06:12.914807"
    },
    {
      "arxiv_id": "2408.17251v1",
      "title": "Abstracted Gaussian Prototypes for One-Shot Concept Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Chelsea Zou",
        "Kenneth J. Kurtz"
      ],
      "abstract": "We introduce a cluster-based generative image segmentation framework to\nencode higher-level representations of visual concepts based on one-shot\nlearning inspired by the Omniglot Challenge. The inferred parameters of each\ncomponent of a Gaussian Mixture Model (GMM) represent a distinct topological\nsubpart of a visual concept. Sampling new data from these parameters generates\naugmented subparts to build a more robust prototype for each concept, i.e., the\nAbstracted Gaussian Prototype (AGP). This framework addresses one-shot\nclassification tasks using a cognitively-inspired similarity metric and\naddresses one-shot generative tasks through a novel AGP-VAE pipeline employing\nvariational autoencoders (VAEs) to generate new class variants. Results from\nhuman judges reveal that the generative pipeline produces novel examples and\nclasses of visual concepts that are broadly indistinguishable from those made\nby humans. The proposed framework leads to impressive but not state-of-the-art\nclassification accuracy; thus, the contribution is two-fold: 1) the system is\nuniquely low in theoretical and computational complexity and operates in a\ncompletely standalone manner compared while existing approaches draw heavily on\npre-training or knowledge engineering; and 2) in contrast with competing neural\nnetwork models, the AGP approach addresses the importance of breadth of task\ncapability emphasized in the Omniglot challenge (i.e., successful performance\non generative tasks). These two points are critical as we advance toward an\nunderstanding of how learning/reasoning systems can produce viable, robust, and\nflexible concepts based on literally nothing more than a single example.",
      "tldr_zh": "本研究提出了一种基于聚类的生成图像分割框架，利用单样本学习（inspired by the Omniglot Challenge）来编码视觉概念的高级表示，核心是Abstracted Gaussian Prototypes (AGP)。该框架使用Gaussian Mixture Model (GMM)的参数表示概念的拓扑子部分，通过采样生成增强的子部分，并结合AGP-VAE管道（employing Variational Autoencoders, VAEs）来处理单样本分类（基于认知启发的相似性度量）和生成任务。实验结果显示，该框架生成的视觉概念示例与人类创作的难以区分，虽然分类准确率未达最先进，但其理论和计算复杂度低，且完全独立运行，无需预训练或知识工程。总之，该方法强调任务能力的广度，有助于理解基于单个示例构建鲁棒概念的学习系统。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.17251v1",
      "published_date": "2024-08-30 12:50:15 UTC",
      "updated_date": "2024-08-30 12:50:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:06:13.907065"
    },
    {
      "arxiv_id": "2409.10525v1",
      "title": "\"Is This It?\": Towards Ecologically Valid Benchmarks for Situated Collaboration",
      "title_zh": "翻译失败",
      "authors": [
        "Dan Bohus",
        "Sean Andrist",
        "Yuwei Bao",
        "Eric Horvitz",
        "Ann Paradiso"
      ],
      "abstract": "We report initial work towards constructing ecologically valid benchmarks to\nassess the capabilities of large multimodal models for engaging in situated\ncollaboration. In contrast to existing benchmarks, in which question-answer\npairs are generated post hoc over preexisting or synthetic datasets via\ntemplates, human annotators, or large language models (LLMs), we propose and\ninvestigate an interactive system-driven approach, where the questions are\ngenerated by users in context, during their interactions with an end-to-end\nsituated AI system. We illustrate how the questions that arise are different in\nform and content from questions typically found in existing embodied question\nanswering (EQA) benchmarks and discuss new real-world challenge problems\nbrought to the fore.",
      "tldr_zh": "本文旨在构建生态有效的基准（ecologically valid benchmarks），以评估大型多模态模型（large multimodal models）在情境协作（situated collaboration）中的能力。不同于现有基准中通过模板或模型事后生成的问题-答案对，本文提出交互式系统驱动的方法，让用户在与端到端情境 AI 系统互动时实时生成问题。研究发现，这些问题在形式和内容上与现有 Embodied Question Answering (EQA) 基准不同，并揭示了新的真实世界挑战问题。",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.MM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.10525v1",
      "published_date": "2024-08-30 12:41:23 UTC",
      "updated_date": "2024-08-30 12:41:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:06:27.531456"
    },
    {
      "arxiv_id": "2409.10524v1",
      "title": "3CSim: CARLA Corner Case Simulation for Control Assessment in Autonomous Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Matúš Čávojský",
        "Eugen Šlapak",
        "Matúš Dopiriak",
        "Gabriel Bugár",
        "Juraj Gazda"
      ],
      "abstract": "We present the CARLA corner case simulation (3CSim) for evaluating autonomous\ndriving (AD) systems within the CARLA simulator. This framework is designed to\naddress the limitations of traditional AD model training by focusing on\nnon-standard, rare, and cognitively challenging scenarios. These corner cases\nare crucial for ensuring vehicle safety and reliability, as they test advanced\ncontrol capabilities under unusual conditions. Our approach introduces a\ntaxonomy of corner cases categorized into state anomalies, behavior anomalies,\nand evidence-based anomalies. We implement 32 unique corner cases with\nadjustable parameters, including 9 predefined weather conditions, timing, and\ntraffic density. The framework enables repeatable and modifiable scenario\nevaluations, facilitating the creation of a comprehensive dataset for further\nanalysis.",
      "tldr_zh": "我们提出了 3CSim，这是一个基于 CARLA 模拟器的框架，用于评估自动驾驶 (AD) 系统的 corner cases，针对非标准、稀有和认知挑战场景，以克服传统模型训练的局限性。\n该框架引入了 corner cases 的分类，包括 state anomalies、behavior anomalies 和 evidence-based anomalies，并实现了 32 个独特场景，支持可调整参数如 9 种预定义天气条件、时间和交通密度。\n通过提供可重复和可修改的场景评估，3CSim 便于生成全面数据集，进一步提升 AD 系统的安全性和控制能力。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.10524v1",
      "published_date": "2024-08-30 12:38:22 UTC",
      "updated_date": "2024-08-30 12:38:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:06:48.264620"
    },
    {
      "arxiv_id": "2408.17235v2",
      "title": "AI-Driven Intrusion Detection Systems (IDS) on the ROAD Dataset: A Comparative Analysis for Automotive Controller Area Network (CAN)",
      "title_zh": "AI驱动的入侵检测系统(IDS)在ROAD数据集上的比较分析：针对汽车控制器区域网络(CAN)",
      "authors": [
        "Lorenzo Guerra",
        "Linhan Xu",
        "Paolo Bellavista",
        "Thomas Chapuis",
        "Guillaume Duc",
        "Pavlo Mozharovskyi",
        "Van-Tam Nguyen"
      ],
      "abstract": "The integration of digital devices in modern vehicles has revolutionized\nautomotive technology, enhancing safety and the overall driving experience. The\nController Area Network (CAN) bus is a central system for managing in-vehicle\ncommunication between the electronic control units (ECUs). However, the CAN\nprotocol poses security challenges due to inherent vulnerabilities, lacking\nencryption and authentication, which, combined with an expanding attack\nsurface, necessitates robust security measures. In response to this challenge,\nnumerous Intrusion Detection Systems (IDS) have been developed and deployed.\nNonetheless, an open, comprehensive, and realistic dataset to test the\neffectiveness of such IDSs remains absent in the existing literature. This\npaper addresses this gap by considering the latest ROAD dataset, containing\nstealthy and sophisticated injections. The methodology involves dataset\nlabelling and the implementation of both state-of-the-art deep learning models\nand traditional machine learning models to show the discrepancy in performance\nbetween the datasets most commonly used in the literature and the ROAD dataset,\na more realistic alternative.",
      "tldr_zh": "本文分析了汽车 Controller Area Network (CAN) 总线的安全漏洞，如缺乏加密和认证，导致潜在入侵风险，并引入了更真实且包含隐秘注入的 ROAD 数据集来填补 IDS 测试的空白。研究方法包括对数据集进行标记，并比较了深度学习模型和传统机器学习模型在 ROAD 数据集与其他常见数据集上的性能表现。结果表明，ROAD 数据集揭示了现有数据集在 IDS 有效性评估中的不足，强调了采用更现实数据集的重要性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.17235v2",
      "published_date": "2024-08-30 12:26:23 UTC",
      "updated_date": "2024-09-05 13:59:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:06:48.472196"
    },
    {
      "arxiv_id": "2408.17233v1",
      "title": "A methodological framework for Resilience as a Service (RaaS) in multimodal urban transportation networks",
      "title_zh": "翻译失败",
      "authors": [
        "Sara Jaber",
        "Mostafa Ameli",
        "S. M. Hassan Mahdavi",
        "Neila Bhouri"
      ],
      "abstract": "Public transportation systems are experiencing an increase in commuter\ntraffic. This increase underscores the need for resilience strategies to manage\nunexpected service disruptions, ensuring rapid and effective responses that\nminimize adverse effects on stakeholders and enhance the system's ability to\nmaintain essential functions and recover quickly. This study aims to explore\nthe management of public transport disruptions through resilience as a service\n(RaaS) strategies, developing an optimization model to effectively allocate\nresources and minimize the cost for operators and passengers. The proposed\nmodel includes multiple transportation options, such as buses, taxis, and\nautomated vans, and evaluates them as bridging alternatives to rail-disrupted\nservices based on factors such as their availability, capacity, speed, and\nproximity to the disrupted station. This ensures that the most suitable\nvehicles are deployed to maintain service continuity. Applied to a case study\nin the Ile de France region, Paris and suburbs, complemented by a microscopic\nsimulation, the model is compared to existing solutions such as bus bridging\nand reserve fleets. The results highlight the model's performance in minimizing\ncosts and enhancing stakeholder satisfaction, optimizing transport management\nduring disruptions.",
      "tldr_zh": "这篇论文提出了一种针对多模式城市交通网络的Resilience as a Service (RaaS)方法框架，旨在通过优化资源分配来管理公共交通中断，确保快速响应并最小化运营商和乘客的成本。研究开发了一个优化模型，评估多种交通选项（如buses、taxis和automated vans）作为铁路服务中断的替代方案，基于factors such as availability、capacity、speed和proximity进行选择。应用于巴黎大区的案例研究并结合microscopic simulation，该模型与现有解决方案（如bus bridging和reserve fleets）比较，结果显示它显著降低了成本并提升了stakeholder satisfaction。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.17233v1",
      "published_date": "2024-08-30 12:22:34 UTC",
      "updated_date": "2024-08-30 12:22:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:07:11.406935"
    },
    {
      "arxiv_id": "2409.00151v1",
      "title": "Speaker Tagging Correction With Non-Autoregressive Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Grigor Kirakosyan",
        "Davit Karamyan"
      ],
      "abstract": "Speech applications dealing with conversations require not only recognizing\nthe spoken words but also determining who spoke when. The task of assigning\nwords to speakers is typically addressed by merging the outputs of two separate\nsystems, namely, an automatic speech recognition (ASR) system and a speaker\ndiarization (SD) system. In practical settings, speaker diarization systems can\nexperience significant degradation in performance due to a variety of factors,\nincluding uniform segmentation with a high temporal resolution, inaccurate word\ntimestamps, incorrect clustering and estimation of speaker numbers, as well as\nbackground noise.\n  Therefore, it is important to automatically detect errors and make\ncorrections if possible. We used a second-pass speaker tagging correction\nsystem based on a non-autoregressive language model to correct mistakes in\nwords placed at the borders of sentences spoken by different speakers. We first\nshow that the employed error correction approach leads to reductions in word\ndiarization error rate (WDER) on two datasets: TAL and test set of Fisher.\nAdditionally, we evaluated our system in the Post-ASR Speaker Tagging\nCorrection challenge and observed significant improvements in cpWER compared to\nbaseline methods.",
      "tldr_zh": "本研究针对语音对话应用中说话者标记（Speaker Tagging）的错误问题，提出了一种基于非自回归语言模型（Non-Autoregressive Language Models）的二阶段修正系统，以缓解自动语音识别（ASR）和说话者识别（SD）系统整合时的缺陷，如不准确的词时间戳和聚类错误。系统重点纠正不同说话者句子边界处的错误，通过检测和自动修正来提升整体性能。实验结果显示，该方法在TAL和Fisher数据集上降低了词说话者错误率（WDER），并在Post-ASR Speaker Tagging Correction挑战中显著提高了cpWER，与基线方法相比取得了实质性改善。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "eess.AS",
        "68T01 General topics in artificial intelligence"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2409.00151v1",
      "published_date": "2024-08-30 11:02:17 UTC",
      "updated_date": "2024-08-30 11:02:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:07:26.567826"
    },
    {
      "arxiv_id": "2408.17198v2",
      "title": "Towards Symbolic XAI -- Explanation Through Human Understandable Logical Relationships Between Features",
      "title_zh": "翻译失败",
      "authors": [
        "Thomas Schnake",
        "Farnoush Rezaei Jafari",
        "Jonas Lederer",
        "Ping Xiong",
        "Shinichi Nakajima",
        "Stefan Gugler",
        "Grégoire Montavon",
        "Klaus-Robert Müller"
      ],
      "abstract": "Explainable Artificial Intelligence (XAI) plays a crucial role in fostering\ntransparency and trust in AI systems, where traditional XAI approaches\ntypically offer one level of abstraction for explanations, often in the form of\nheatmaps highlighting single or multiple input features. However, we ask\nwhether abstract reasoning or problem-solving strategies of a model may also be\nrelevant, as these align more closely with how humans approach solutions to\nproblems. We propose a framework, called Symbolic XAI, that attributes\nrelevance to symbolic queries expressing logical relationships between input\nfeatures, thereby capturing the abstract reasoning behind a model's\npredictions. The methodology is built upon a simple yet general multi-order\ndecomposition of model predictions. This decomposition can be specified using\nhigher-order propagation-based relevance methods, such as GNN-LRP, or\nperturbation-based explanation methods commonly used in XAI. The effectiveness\nof our framework is demonstrated in the domains of natural language processing\n(NLP), vision, and quantum chemistry (QC), where abstract symbolic domain\nknowledge is abundant and of significant interest to users. The Symbolic XAI\nframework provides an understanding of the model's decision-making process that\nis both flexible for customization by the user and human-readable through\nlogical formulas.",
      "tldr_zh": "本研究探讨了Explainable Artificial Intelligence (XAI)的局限性，指出传统方法（如热力图）仅提供单一抽象级别的输入特征解释，而忽略了模型的抽象推理策略。作者提出Symbolic XAI框架，通过符号查询表达输入特征之间的逻辑关系，来捕捉模型预测背后的抽象推理过程。该框架基于模型预测的多阶分解，利用如GNN-LRP的高阶传播相关性方法或基于扰动的解释方法，并在NLP、vision和quantum chemistry (QC)领域验证其有效性，最终提供灵活、可定制且人类可读的逻辑公式解释，以提升AI系统的透明度和信任。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.17198v2",
      "published_date": "2024-08-30 10:52:18 UTC",
      "updated_date": "2024-10-01 11:35:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:07:39.503768"
    },
    {
      "arxiv_id": "2408.17190v1",
      "title": "Reasoning with maximal consistent signatures",
      "title_zh": "翻译失败",
      "authors": [
        "Matthias Thimm",
        "Jandson Santos Ribeiro Santos"
      ],
      "abstract": "We analyse a specific instance of the general approach of reasoning based on\nforgetting by Lang and Marquis. More precisely, we discuss an approach for\nreasoning with inconsistent information using maximal consistent subsignatures,\nwhere a maximal consistent subsignature is a maximal set of propositions such\nthat forgetting the remaining propositions restores consistency. We analyse\nmaximal consistent subsignatures and the corresponding minimal inconsistent\nsubsignatures in-depth and show, among others, that the hitting set duality\napplies for them as well. We further analyse inference relations based on\nmaximal consistent subsignatures wrt. rationality postulates from non-monotonic\nreasoning and computational complexity. We also consider the relationship of\nour approach with inconsistency measurement and paraconsistent reasoning.",
      "tldr_zh": "本论文探讨了一种基于遗忘（forgetting）的推理方法，使用 maximal consistent subsignatures 来处理不一致信息，这些子签名是最大的一组命题集合，通过遗忘剩余命题恢复一致性。论文深入分析了 maximal consistent subsignatures 和对应的 minimal inconsistent subsignatures，证明了 hitting set duality 在其中的适用性，并评估了基于这些子签名的推理关系在 rationality postulates 下的表现以及计算复杂性。最后，论文考察了该方法与 inconsistency measurement 和 paraconsistent reasoning 的关系，为非单调推理提供新视角。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.17190v1",
      "published_date": "2024-08-30 10:43:14 UTC",
      "updated_date": "2024-08-30 10:43:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:08:01.642768"
    },
    {
      "arxiv_id": "2408.17186v1",
      "title": "\"Benefit Game: Alien Seaweed Swarms\" -- Real-time Gamification of Digital Seaweed Ecology",
      "title_zh": "翻译失败",
      "authors": [
        "Dan-Lu Fei",
        "Zi-Wei Wu",
        "Kang Zhang"
      ],
      "abstract": "\"Benefit Game: Alien Seaweed Swarms\" combines artificial life art and\ninteractive game with installation to explore the impact of human activity on\nfragile seaweed ecosystems. The project aims to promote ecological\nconsciousness by creating a balance in digital seaweed ecologies. Inspired by\nthe real species \"Laminaria saccharina\", the author employs Procedural Content\nGeneration via Machine Learning technology to generate variations of virtual\nseaweeds and symbiotic fungi. The audience can explore the consequences of\nhuman activities through gameplay and observe the ecosystem's feedback on the\nbenefits and risks of seaweed aquaculture. This Benefit Game offers dynamic and\nreal-time responsive artificial seaweed ecosystems for an interactive\nexperience that enhances ecological consciousness.",
      "tldr_zh": "该项目“Benefit Game: Alien Seaweed Swarms”将人工智能艺术、互动游戏和安装艺术相结合，探索人类活动对脆弱海藻生态的影响，旨在通过数字生态平衡提升生态意识。受真实物种“Laminaria saccharina”启发，该游戏采用Procedural Content Generation via Machine Learning技术生成虚拟海藻和共生真菌的变异，允许观众通过实时游戏互动观察人类行为的后果，包括海藻养殖的益处与风险。整体设计提供了一个动态、响应迅速的互动体验，有效增强了参与者的生态意识。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.HC",
      "comment": "Paper accepted at ISEA 24, The 29th International Symposium on\n  Electronic Art, Brisbane, Australia, 21-29 June 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.17186v1",
      "published_date": "2024-08-30 10:36:11 UTC",
      "updated_date": "2024-08-30 10:36:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:08:00.969467"
    },
    {
      "arxiv_id": "2408.17183v2",
      "title": "Causal Reasoning in Software Quality Assurance: A Systematic Review",
      "title_zh": "软件质量保证中的因果推理：一项系统综述",
      "authors": [
        "Luca Giamattei",
        "Antonio Guerriero",
        "Roberto Pietrantuono",
        "Stefano Russo"
      ],
      "abstract": "Context: Software Quality Assurance (SQA) is a fundamental part of software\nengineering to ensure stakeholders that software products work as expected\nafter release in operation. Machine Learning (ML) has proven to be able to\nboost SQA activities and contribute to the development of quality software\nsystems. In this context, Causal Reasoning is gaining increasing interest as a\nmethodology to go beyond a purely data-driven approach by exploiting the use of\ncausality for more effective SQA strategies. Objective: Provide a broad and\ndetailed overview of the use of causal reasoning for SQA activities, in order\nto support researchers to access this research field, identifying room for\napplication, main challenges and research opportunities. Methods: A systematic\nreview of the scientific literature on causal reasoning for SQA. The study has\nfound, classified, and analyzed 86 articles, according to established\nguidelines for software engineering secondary studies. Results: Results\nhighlight the primary areas within SQA where causal reasoning has been applied,\nthe predominant methodologies used, and the level of maturity of the proposed\nsolutions. Fault localization is the activity where causal reasoning is more\nexploited, especially in the web services/microservices domain, but other tasks\nlike testing are rapidly gaining popularity. Both causal inference and causal\ndiscovery are exploited, with the Pearl's graphical formulation of causality\nbeing preferred, likely due to its intuitiveness. Tools to favour their\napplication are appearing at a fast pace - most of them after 2021.\nConclusions: The findings show that causal reasoning is a valuable means for\nSQA tasks with respect to multiple quality attributes, especially during V&V,\nevolution and maintenance to ensure reliability, while it is not yet fully\nexploited for phases like ...",
      "tldr_zh": "本研究通过系统文献综述，探讨了Causal Reasoning在Software Quality Assurance (SQA)中的应用，旨在提供全面概述，帮助研究者识别应用领域、主要挑战和研究机会。分析了86篇相关文章，结果显示Causal Reasoning最常用于Fault Localization，尤其在web services/microservices领域，同时测试等任务正快速兴起，并偏好Pearl's graphical formulation作为方法。结论指出，这种推理对SQA的验证与验证(V&V)、演化和维护阶段的可靠性提升有显著价值，但尚未充分应用于其他阶段，未来工具发展（如2021年后涌现的工具）将带来更多机遇。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted to Information and Software Technology journal",
      "pdf_url": "http://arxiv.org/pdf/2408.17183v2",
      "published_date": "2024-08-30 10:34:11 UTC",
      "updated_date": "2024-10-10 11:00:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:08:15.176700"
    },
    {
      "arxiv_id": "2409.00149v1",
      "title": "From Semantics to Hierarchy: A Hybrid Euclidean-Tangent-Hyperbolic Space Model for Temporal Knowledge Graph Reasoning",
      "title_zh": "从语义到层次结构：一种混合欧氏-切线-双曲空间模型用于时序知识图推理",
      "authors": [
        "Siling Feng",
        "Zhisheng Qi",
        "Cong Lin"
      ],
      "abstract": "Temporal knowledge graph (TKG) reasoning predicts future events based on\nhistorical data, but it's challenging due to the complex semantic and\nhierarchical information involved. Existing Euclidean models excel at capturing\nsemantics but struggle with hierarchy. Conversely, hyperbolic models manage\nhierarchical features well but fail to represent complex semantics due to\nlimitations in shallow models' parameters and the absence of proper\nnormalization in deep models relying on the L2 norm. Current solutions, as\ncurvature transformations, are insufficient to address these issues. In this\nwork, a novel hybrid geometric space approach that leverages the strengths of\nboth Euclidean and hyperbolic models is proposed. Our approach transitions from\nsingle-space to multi-space parameter modeling, effectively capturing both\nsemantic and hierarchical information. Initially, complex semantics are\ncaptured through a fact co-occurrence and autoregressive method with\nnormalizations in Euclidean space. The embeddings are then transformed into\nTangent space using a scaling mechanism, preserving semantic information while\nrelearning hierarchical structures through a query-candidate separated modeling\napproach, which are subsequently transformed into Hyperbolic space. Finally, a\nhybrid inductive bias for hierarchical and semantic learning is achieved by\ncombining hyperbolic and Euclidean scoring functions through a learnable\nquery-specific mixing coefficient, utilizing embeddings from hyperbolic and\nEuclidean spaces. Experimental results on four TKG benchmarks demonstrate that\nour method reduces error relatively by up to 15.0% in mean reciprocal rank on\nYAGO compared to previous single-space models. Additionally, enriched\nvisualization analysis validates the effectiveness of our approach, showing\nadaptive capabilities for datasets with varying levels of semantic and\nhierarchical complexity.",
      "tldr_zh": "该论文提出了一种混合几何空间模型，用于Temporal Knowledge Graph (TKG)推理，以同时捕捉复杂语义和层次信息。方法首先在Euclidean空间通过事实共现和自回归机制加归一化捕捉语义，然后将嵌入转换为Tangent空间以保留语义并重新学习层次结构，最后过渡到Hyperbolic空间，并通过可学习的混合系数结合Euclidean和Hyperbolic评分函数实现混合诱导偏差。实验在四个TKG基准上显示，该方法相较于单空间模型将YAGO数据集的mean reciprocal rank错误率降低最多15.0%，并通过可视化分析验证了其对不同语义和层次复杂度的适应能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.00149v1",
      "published_date": "2024-08-30 10:33:08 UTC",
      "updated_date": "2024-08-30 10:33:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:08:27.580944"
    },
    {
      "arxiv_id": "2408.17180v1",
      "title": "Identifying and Clustering Counter Relationships of Team Compositions in PvP Games for Efficient Balance Analysis",
      "title_zh": "在 PvP 游戏中识别和聚类团队组合的克制关系以实现高效平衡分析",
      "authors": [
        "Chiu-Chou Lin",
        "Yu-Wei Shih",
        "Kuei-Ting Kuo",
        "Yu-Cheng Chen",
        "Chien-Hua Chen",
        "Wei-Chen Chiu",
        "I-Chen Wu"
      ],
      "abstract": "How can balance be quantified in game settings? This question is crucial for\ngame designers, especially in player-versus-player (PvP) games, where analyzing\nthe strength relations among predefined team compositions-such as hero\ncombinations in multiplayer online battle arena (MOBA) games or decks in card\ngames-is essential for enhancing gameplay and achieving balance. We have\ndeveloped two advanced measures that extend beyond the simplistic win rate to\nquantify balance in zero-sum competitive scenarios. These measures are derived\nfrom win value estimations, which employ strength rating approximations via the\nBradley-Terry model and counter relationship approximations via vector\nquantization, significantly reducing the computational complexity associated\nwith traditional win value estimations. Throughout the learning process of\nthese models, we identify useful categories of compositions and pinpoint their\ncounter relationships, aligning with the experiences of human players without\nrequiring specific game knowledge. Our methodology hinges on a simple technique\nto enhance codebook utilization in discrete representation with a deterministic\nvector quantization process for an extremely small state space. Our framework\nhas been validated in popular online games, including Age of Empires II,\nHearthstone, Brawl Stars, and League of Legends. The accuracy of the observed\nstrength relations in these games is comparable to traditional pairwise win\nvalue predictions, while also offering a more manageable complexity for\nanalysis. Ultimately, our findings contribute to a deeper understanding of PvP\ngame dynamics and present a methodology that significantly improves game\nbalance evaluation and design.",
      "tldr_zh": "本研究针对 PvP 游戏中团队组合（如英雄或卡组）的对抗关系，开发了两种高级平衡量化措施，这些措施基于 Bradley-Terry 模型的强度评估和向量量化（vector quantization）的对抗关系近似，显著降低了传统胜值估计的计算复杂度。方法通过确定性向量量化过程识别和聚类团队组合的类别及对抗关系，无需特定游戏知识，即可与人类玩家经验一致。实验在 Age of Empires II、Hearthstone、Brawl Stars 和 League of Legends 等游戏中验证，显示其准确性与传统配对胜值预测相当，同时简化了分析复杂度，为提升游戏平衡设计提供了高效框架。",
      "categories": [
        "cs.AI",
        "cs.GT",
        "cs.IR",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "TMLR 09/2024 https://openreview.net/forum?id=2D36otXvBE",
      "pdf_url": "http://arxiv.org/pdf/2408.17180v1",
      "published_date": "2024-08-30 10:28:36 UTC",
      "updated_date": "2024-08-30 10:28:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:08:36.379979"
    },
    {
      "arxiv_id": "2408.17175v3",
      "title": "Codec Does Matter: Exploring the Semantic Shortcoming of Codec for Audio Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Zhen Ye",
        "Peiwen Sun",
        "Jiahe Lei",
        "Hongzhan Lin",
        "Xu Tan",
        "Zheqi Dai",
        "Qiuqiang Kong",
        "Jianyi Chen",
        "Jiahao Pan",
        "Qifeng Liu",
        "Yike Guo",
        "Wei Xue"
      ],
      "abstract": "Recent advancements in audio generation have been significantly propelled by\nthe capabilities of Large Language Models (LLMs). The existing research on\naudio LLM has primarily focused on enhancing the architecture and scale of\naudio language models, as well as leveraging larger datasets, and generally,\nacoustic codecs, such as EnCodec, are used for audio tokenization. However,\nthese codecs were originally designed for audio compression, which may lead to\nsuboptimal performance in the context of audio LLM. Our research aims to\naddress the shortcomings of current audio LLM codecs, particularly their\nchallenges in maintaining semantic integrity in generated audio. For instance,\nexisting methods like VALL-E, which condition acoustic token generation on text\ntranscriptions, often suffer from content inaccuracies and elevated word error\nrates (WER) due to semantic misinterpretations of acoustic tokens, resulting in\nword skipping and errors. To overcome these issues, we propose a\nstraightforward yet effective approach called X-Codec. X-Codec incorporates\nsemantic features from a pre-trained semantic encoder before the Residual\nVector Quantization (RVQ) stage and introduces a semantic reconstruction loss\nafter RVQ. By enhancing the semantic ability of the codec, X-Codec\nsignificantly reduces WER in speech synthesis tasks and extends these benefits\nto non-speech applications, including music and sound generation. Our\nexperiments in text-to-speech, music continuation, and text-to-sound tasks\ndemonstrate that integrating semantic information substantially improves the\noverall performance of language models in audio generation. Our code and demo\nare available (Demo: https://x-codec-audio.github.io Code:\nhttps://github.com/zhenye234/xcodec)",
      "tldr_zh": "该研究探讨了音频语言模型（Audio Language Models）中声学编解码器（如 EnCodec）的语义不足问题，这些编解码器原本设计用于音频压缩，导致生成音频时出现内容不准确、高 WER（Word Error Rate）和词跳过等缺陷。作者提出 X-Codec 方法，通过在 Residual Vector Quantization (RVQ) 阶段前融入预训练语义编码器的语义特征，并添加语义重建损失，提升编解码器的语义能力。实验结果显示，X-Codec 在文本到语音、音乐续写和文本到声音任务中显著降低了 WER，并整体提高了音频生成性能，为音频 LLM 的优化提供了有效途径。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.17175v3",
      "published_date": "2024-08-30 10:24:07 UTC",
      "updated_date": "2024-11-27 11:47:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:08:49.749838"
    },
    {
      "arxiv_id": "2408.17162v1",
      "title": "Deep Feature Embedding for Tabular Data",
      "title_zh": "翻译失败",
      "authors": [
        "Yuqian Wu",
        "Hengyi Luo",
        "Raymond S. T. Lee"
      ],
      "abstract": "Tabular data learning has extensive applications in deep learning but its\nexisting embedding techniques are limited in numerical and categorical features\nsuch as the inability to capture complex relationships and engineering. This\npaper proposes a novel deep embedding framework with leverages lightweight deep\nneural networks to generate effective feature embeddings for tabular data in\nmachine learning research. For numerical features, a two-step feature expansion\nand deep transformation technique is used to capture copious semantic\ninformation. For categorical features, a unique identification vector for each\nentity is referred by a compact lookup table with a parameterized deep\nembedding function to uniform the embedding size dimensions, and transformed\ninto a embedding vector using deep neural network. Experiments are conducted on\nreal-world datasets for performance evaluation.",
      "tldr_zh": "本论文提出了一种新的深度特征嵌入框架，用于处理表格数据（tabular data）学习中的数值和分类特征问题，该框架利用轻量级深度神经网络（deep neural networks）生成有效的特征嵌入（feature embeddings）。对于数值特征，该方法采用两步特征扩展和深度转换技术，以捕获丰富的语义信息；对于分类特征，则通过紧凑查找表和参数化深度嵌入函数统一嵌入尺寸，并使用深度神经网络转换为嵌入向量。实验结果显示，该框架在真实数据集上表现出色，提升了表格数据学习的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 2figures, accepted to ICONIP 2024, Paper ID: 1399",
      "pdf_url": "http://arxiv.org/pdf/2408.17162v1",
      "published_date": "2024-08-30 10:05:24 UTC",
      "updated_date": "2024-08-30 10:05:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:09:02.251797"
    },
    {
      "arxiv_id": "2408.17150v1",
      "title": "Look, Compare, Decide: Alleviating Hallucination in Large Vision-Language Models via Multi-View Multi-Path Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoye Qu",
        "Jiashuo Sun",
        "Wei Wei",
        "Yu Cheng"
      ],
      "abstract": "Recently, Large Vision-Language Models (LVLMs) have demonstrated impressive\ncapabilities in multi-modal context comprehension. However, they still suffer\nfrom hallucination problems referring to generating inconsistent outputs with\nthe image content. To mitigate hallucinations, previous studies mainly focus on\nretraining LVLMs with custom datasets. Although effective, they inherently come\nwith additional computational costs. In this paper, we propose a training-free\nframework, \\textbf{MVP}, that aims to reduce hallucinations by making the most\nof the innate capabilities of the LVLMs via \\textbf{M}ulti-\\textbf{V}iew\nMulti-\\textbf{P}ath Reasoning. Specifically, we first devise a multi-view\ninformation-seeking strategy to thoroughly perceive the comprehensive\ninformation in the image, which enriches the general global information\ncaptured by the original vision encoder in LVLMs. Furthermore, during the\nanswer decoding, we observe that the occurrence of hallucinations has a strong\ncorrelation with the certainty of the answer tokens. Thus, we propose\nmulti-path reasoning for each information view to quantify and aggregate the\ncertainty scores for each potential answer among multiple decoding paths and\nfinally decide the output answer. By fully grasping the information in the\nimage and carefully considering the certainty of the potential answers when\ndecoding, our MVP can effectively reduce hallucinations in LVLMs.The extensive\nexperiments verify that our proposed MVP significantly mitigates the\nhallucination problem across four well-known LVLMs. The source code is\navailable at: \\url{https://github.com/GasolSun36/MVP}.",
      "tldr_zh": "该论文针对 Large Vision-Language Models (LVLMs) 的 hallucination 问题，即生成与图像内容不一致的输出，提出了一种无训练框架 MVP（Multi-View Multi-Path Reasoning）。MVP 通过多视图信息获取策略（multi-view information-seeking）来全面感知图像信息，丰富原始视觉编码器的全局理解；同时，在答案解码阶段，使用多路径推理（multi-path reasoning）量化并聚合潜在答案的确定性分数，以决定最终输出。实验结果显示，MVP 在四个知名 LVLMs 上显著降低了 hallucination 问题，提供了一个高效的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages, 7 tables, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.17150v1",
      "published_date": "2024-08-30 09:40:10 UTC",
      "updated_date": "2024-08-30 09:40:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:09:14.121751"
    },
    {
      "arxiv_id": "2408.17145v1",
      "title": "Towards Hyper-parameter-free Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Geetika",
        "Drishya Uniyal",
        "Bapi Chatterjee"
      ],
      "abstract": "The adaptive synchronization techniques in federated learning (FL) for scaled\nglobal model updates show superior performance over the vanilla federated\naveraging (FedAvg) scheme. However, existing methods employ additional tunable\nhyperparameters on the server to determine the scaling factor. A contrasting\napproach is automated scaling analogous to tuning-free step-size schemes in\nstochastic gradient descent (SGD) methods, which offer competitive convergence\nrates and exhibit good empirical performance. In this work, we introduce two\nalgorithms for automated scaling of global model updates. In our first\nalgorithm, we establish that a descent-ensuring step-size regime at the clients\nensures descent for the server objective. We show that such a scheme enables\nlinear convergence for strongly convex federated objectives. Our second\nalgorithm shows that the average of objective values of sampled clients is a\npractical and effective substitute for the objective function value at the\nserver required for computing the scaling factor, whose computation is\notherwise not permitted. Our extensive empirical results show that the proposed\nmethods perform at par or better than the popular federated learning algorithms\nfor both convex and non-convex problems. Our work takes a step towards\ndesigning hyper-parameter-free federated learning.",
      "tldr_zh": "本研究针对联邦学习（FL）中自适应同步技术的超参数依赖问题，提出两种自动缩放全球模型更新的算法，旨在实现无超参数的FL设计。第一算法通过确保客户端的步长方案维持服务器目标的下降，并证明在强凸目标下实现线性收敛。第二算法使用采样客户端目标值的平均作为服务器目标值的替代，以计算缩放因子，避免直接计算服务器目标。实验结果显示，这些方法在凸和非凸问题上与流行FL算法（如FedAvg）相当或表现出色，从而朝着设计超参数-free FL迈进。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "28 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.17145v1",
      "published_date": "2024-08-30 09:35:36 UTC",
      "updated_date": "2024-08-30 09:35:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:09:27.746763"
    },
    {
      "arxiv_id": "2408.17136v2",
      "title": "Leveraging Digital Twin Technologies for Public Space Protection and Vulnerability Assessment",
      "title_zh": "翻译失败",
      "authors": [
        "Artemis Stefanidou",
        "Jorgen Cani",
        "Thomas Papadopoulos",
        "Panagiotis Radoglou-Grammatikis",
        "Panagiotis Sarigiannidis",
        "Iraklis Varlamis",
        "Georgios Th. Papadopoulos"
      ],
      "abstract": "Over the recent years, the protection of the so-called `soft-targets', i.e.\nlocations easily accessible by the general public with relatively low, though,\nsecurity measures, has emerged as a rather challenging and increasingly\nimportant issue. The complexity and seriousness of this security threat growths\nnowadays exponentially, due to the emergence of new advanced technologies (e.g.\nArtificial Intelligence (AI), Autonomous Vehicles (AVs), 3D printing, etc.);\nespecially when it comes to large-scale, popular and diverse public spaces. In\nthis paper, a novel Digital Twin-as-a-Security-Service (DTaaSS) architecture is\nintroduced for holistically and significantly enhancing the protection of\npublic spaces (e.g. metro stations, leisure sites, urban squares, etc.). The\nproposed framework combines a Digital Twin (DT) conceptualization with\nadditional cutting-edge technologies, including Internet of Things (IoT), cloud\ncomputing, Big Data analytics and AI. In particular, DTaaSS comprises a\nholistic, real-time, large-scale, comprehensive and data-driven security\nsolution for the efficient/robust protection of public spaces, supporting: a)\ndata collection and analytics, b) area monitoring/control and proactive threat\ndetection, c) incident/attack prediction, and d) quantitative and data-driven\nvulnerability assessment. Overall, the designed architecture exhibits increased\npotential in handling complex, hybrid and combined threats over large, critical\nand popular soft-targets. The applicability and robustness of DTaaSS is\ndiscussed in detail against representative and diverse real-world application\nscenarios, including complex attacks to: a) a metro station, b) a leisure site,\nand c) a cathedral square.",
      "tldr_zh": "这篇论文针对公共空间（如地铁站、休闲场所和城市广场）保护的挑战，引入了 Digital Twin-as-a-Security-Service (DTaaSS) 架构，以应对新技术（如 AI 和 Autonomous Vehicles）带来的复杂威胁。DTaaSS 结合 Digital Twin (DT)、Internet of Things (IoT)、云计算、Big Data 分析和 AI，提供了一个整体、实时的数据驱动解决方案，包括数据收集分析、区域监控与威胁检测、攻击预测以及定量脆弱性评估。该框架在真实应用场景中（如对地铁站或休闲场所的攻击）展示了显著的鲁棒性和潜力，提高了公共空间的安全防护能力。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.17136v2",
      "published_date": "2024-08-30 09:27:12 UTC",
      "updated_date": "2024-12-15 11:48:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:09:40.570851"
    },
    {
      "arxiv_id": "2408.17131v1",
      "title": "VQ4DiT: Efficient Post-Training Vector Quantization for Diffusion Transformers",
      "title_zh": "VQ4DiT：高效的训练后向量量化方法，用于扩散变换器",
      "authors": [
        "Juncan Deng",
        "Shuaiting Li",
        "Zeyu Wang",
        "Hong Gu",
        "Kedong Xu",
        "Kejie Huang"
      ],
      "abstract": "The Diffusion Transformers Models (DiTs) have transitioned the network\narchitecture from traditional UNets to transformers, demonstrating exceptional\ncapabilities in image generation. Although DiTs have been widely applied to\nhigh-definition video generation tasks, their large parameter size hinders\ninference on edge devices. Vector quantization (VQ) can decompose model weight\ninto a codebook and assignments, allowing extreme weight quantization and\nsignificantly reducing memory usage. In this paper, we propose VQ4DiT, a fast\npost-training vector quantization method for DiTs. We found that traditional VQ\nmethods calibrate only the codebook without calibrating the assignments. This\nleads to weight sub-vectors being incorrectly assigned to the same assignment,\nproviding inconsistent gradients to the codebook and resulting in a suboptimal\nresult. To address this challenge, VQ4DiT calculates the candidate assignment\nset for each weight sub-vector based on Euclidean distance and reconstructs the\nsub-vector based on the weighted average. Then, using the zero-data and\nblock-wise calibration method, the optimal assignment from the set is\nefficiently selected while calibrating the codebook. VQ4DiT quantizes a DiT\nXL/2 model on a single NVIDIA A100 GPU within 20 minutes to 5 hours depending\non the different quantization settings. Experiments show that VQ4DiT\nestablishes a new state-of-the-art in model size and performance trade-offs,\nquantizing weights to 2-bit precision while retaining acceptable image\ngeneration quality.",
      "tldr_zh": "这篇论文提出 VQ4DiT，一种高效的后训练向量量化方法，用于优化 Diffusion Transformers (DiTs) 的模型大小，以解决其参数量大导致的边缘设备推理问题。VQ4DiT 通过基于欧氏距离计算权重子向量的候选 assignments 集，并结合加权平均重建和零数据块-wise 校准方法，改进传统 VQ 的 codebook 校准不足，提升量化准确性。实验结果显示，该方法可在单块 NVIDIA A100 GPU 上在 20 分钟至 5 小时内量化 DiT XL/2 模型至 2-bit 精度，同时保持可接受的图像生成质量，并在模型大小与性能权衡上建立新标准。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.2; I.4"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.17131v1",
      "published_date": "2024-08-30 09:15:54 UTC",
      "updated_date": "2024-08-30 09:15:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:09:53.540920"
    },
    {
      "arxiv_id": "2408.17129v2",
      "title": "Controllable Edge-Type-Specific Interpretation in Multi-Relational Graph Neural Networks for Drug Response Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaodi Li",
        "Jianfeng Gui",
        "Qian Gao",
        "Haoyuan Shi",
        "Zhenyu Yue"
      ],
      "abstract": "Graph Neural Networks have been widely applied in critical decision-making\nareas that demand interpretable predictions, leading to the flourishing\ndevelopment of interpretability algorithms. However, current graph\ninterpretability algorithms tend to emphasize generality and often overlook\nbiological significance, thereby limiting their applicability in predicting\ncancer drug responses. In this paper, we propose a novel post-hoc\ninterpretability algorithm for cancer drug response prediction, CETExplainer,\nwhich incorporates a controllable edge-type-specific weighting mechanism. It\nconsiders the mutual information between subgraphs and predictions, proposing a\nstructural scoring approach to provide fine-grained, biologically meaningful\nexplanations for predictive models. We also introduce a method for constructing\nground truth based on real-world datasets to quantitatively evaluate the\nproposed interpretability algorithm. Empirical analysis on the real-world\ndataset demonstrates that CETExplainer achieves superior stability and improves\nexplanation quality compared to leading algorithms, thereby offering a robust\nand insightful tool for cancer drug prediction.",
      "tldr_zh": "该论文提出了一种新型后验解释算法 CETExplainer，用于多关系图神经网络（Multi-Relational Graph Neural Networks）在癌症药物反应预测（Drug Response Prediction）中的应用。该算法引入可控的边类型特定加权机制，并通过子图与预测之间的互信息（Mutual Information）计算结构评分，提供细粒度的、生物学上意义丰富的解释。此外，论文开发了一种基于真实数据集构建 ground truth 的量化评估方法，实证分析显示 CETExplainer 比领先算法更稳定并显著提升解释质量，为癌症药物预测提供可靠工具。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.17129v2",
      "published_date": "2024-08-30 09:14:38 UTC",
      "updated_date": "2024-09-03 08:45:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:10:05.347677"
    },
    {
      "arxiv_id": "2409.10523v1",
      "title": "Harnessing Artificial Intelligence for Wildlife Conservation",
      "title_zh": "利用人工智能促进野生动物保护",
      "authors": [
        "Paul Fergus",
        "Carl Chalmers",
        "Steve Longmore",
        "Serge Wich"
      ],
      "abstract": "The rapid decline in global biodiversity demands innovative conservation\nstrategies. This paper examines the use of artificial intelligence (AI) in\nwildlife conservation, focusing on the Conservation AI platform. Leveraging\nmachine learning and computer vision, Conservation AI detects and classifies\nanimals, humans, and poaching-related objects using visual spectrum and thermal\ninfrared cameras. The platform processes this data with convolutional neural\nnetworks (CNNs) and Transformer architectures to monitor species, including\nthose which are critically endangered. Real-time detection provides the\nimmediate responses required for time-critical situations (e.g. poaching),\nwhile non-real-time analysis supports long-term wildlife monitoring and habitat\nhealth assessment. Case studies from Europe, North America, Africa, and\nSoutheast Asia highlight the platform's success in species identification,\nbiodiversity monitoring, and poaching prevention. The paper also discusses\nchallenges related to data quality, model accuracy, and logistical constraints,\nwhile outlining future directions involving technological advancements,\nexpansion into new geographical regions, and deeper collaboration with local\ncommunities and policymakers. Conservation AI represents a significant step\nforward in addressing the urgent challenges of wildlife conservation, offering\na scalable and adaptable solution that can be implemented globally.",
      "tldr_zh": "这篇论文探讨了人工智能(AI)在野生动物保护中的应用，重点介绍了Conservation AI平台，该平台利用机器学习、计算机视觉、convolutional neural networks (CNNs)和Transformer architectures，通过视觉和热红外相机检测并分类动物、人和偷猎相关物体。平台支持实时检测以应对紧急情况（如偷猎）和非实时分析用于长期物种监测及栖息地健康评估。案例研究显示，在欧洲、北美、非洲和东南亚地区，该平台显著提升了物种识别、生物多样性监测和偷猎预防的效果。论文还讨论了数据质量、模型准确性及后勤挑战，并展望未来技术进步、区域扩展及与本地社区的合作，以推动全球可扩展的保护解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages, 13 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.10523v1",
      "published_date": "2024-08-30 09:13:31 UTC",
      "updated_date": "2024-08-30 09:13:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:10:19.212929"
    },
    {
      "arxiv_id": "2409.10522v1",
      "title": "Bridging User Dynamics: Transforming Sequential Recommendations with Schrödinger Bridge and Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Wenjia Xie",
        "Rui Zhou",
        "Hao Wang",
        "Tingjia Shen",
        "Enhong Chen"
      ],
      "abstract": "Sequential recommendation has attracted increasing attention due to its\nability to accurately capture the dynamic changes in user interests. We have\nnoticed that generative models, especially diffusion models, which have\nachieved significant results in fields like image and audio, hold considerable\npromise in the field of sequential recommendation. However, existing sequential\nrecommendation methods based on diffusion models are constrained by a prior\ndistribution limited to Gaussian distribution, hindering the possibility of\nintroducing user-specific information for each recommendation and leading to\ninformation loss. To address these issues, we introduce the Schr\\\"odinger\nBridge into diffusion-based sequential recommendation models, creating the\nSdifRec model. This allows us to replace the Gaussian prior of the diffusion\nmodel with the user's current state, directly modeling the process from a\nuser's current state to the target recommendation. Additionally, to better\nutilize collaborative information in recommendations, we propose an extended\nversion of SdifRec called con-SdifRec, which utilizes user clustering\ninformation as a guiding condition to further enhance the posterior\ndistribution. Finally, extensive experiments on multiple public benchmark\ndatasets have demonstrated the effectiveness of SdifRec and con-SdifRec through\ncomparison with several state-of-the-art methods. Further in-depth analysis has\nvalidated their efficiency and robustness.",
      "tldr_zh": "该论文探讨了顺序推荐（Sequential Recommendation）中捕捉用户动态兴趣的挑战，提出通过引入Schrödinger Bridge改进扩散模型（Diffusion Models），从而创建SdifRec模型。该模型将用户的当前状态作为先验分布，直接建模从用户状态到目标推荐的过程，以解决现有方法的信息丢失问题。为进一步利用协作信息，论文扩展了SdifRec为con-SdifRec，通过用户聚类信息引导后验分布增强推荐准确性。在多个公共基准数据集上的实验表明，SdifRec和con-SdifRec比现有最先进方法更有效，并展示了较高的效率和鲁棒性。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "CIKM '24",
      "pdf_url": "http://arxiv.org/pdf/2409.10522v1",
      "published_date": "2024-08-30 09:10:38 UTC",
      "updated_date": "2024-08-30 09:10:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:10:30.520875"
    },
    {
      "arxiv_id": "2408.17119v1",
      "title": "Exploring User Acceptance Of Portable Intelligent Personal Assistants: A Hybrid Approach Using PLS-SEM And fsQCA",
      "title_zh": "翻译失败",
      "authors": [
        "Gustave Florentin Nkoulou Mvondo",
        "Ben Niu"
      ],
      "abstract": "This research explores the factors driving user acceptance of Rabbit R1, a\nnewly developed portable intelligent personal assistant (PIPA) that aims to\nredefine user interaction and control. The study extends the technology\nacceptance model (TAM) by incorporating artificial intelligence-specific\nfactors (conversational intelligence, task intelligence, and perceived\nnaturalness), user interface design factors (simplicity in information design\nand visual aesthetics), and user acceptance and loyalty. Using a purposive\nsampling method, we gathered data from 824 users in the US and analyzed the\nsample through partial least squares structural equation modeling (PLS-SEM) and\nfuzzy set qualitative comparative analysis (fsQCA). The findings reveal that\nall hypothesized relationships, including both direct and indirect effects, are\nsupported. Additionally, fsQCA supports the PLS-SEM findings and identifies\nthree configurations leading to high and low user acceptance. This research\nenriches the literature and provides valuable insights for system designers and\nmarketers of PIPAs, guiding strategic decisions to foster widespread adoption\nand long-term engagement.",
      "tldr_zh": "这篇论文探讨了便携式智能个人助理(PIPA)如Rabbit R1的用户接受度驱动因素，通过扩展技术接受模型(TAM)并纳入AI特定因素(对话智能、任务智能和感知自然性)以及用户界面设计因素(信息设计简易性和视觉美学)。研究采用目的性抽样从824名美国用户收集数据，并使用PLS-SEM和fsQCA混合方法进行分析，结果显示所有假设关系(直接和间接效果)均得到支持，并识别了三种配置导致高或低用户接受度。该研究丰富了相关文献，为PIPA系统设计师和营销者提供战略指导，以促进广泛采用和长期用户忠诚。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "HCC"
      ],
      "primary_category": "cs.HC",
      "comment": "36,",
      "pdf_url": "http://arxiv.org/pdf/2408.17119v1",
      "published_date": "2024-08-30 09:01:34 UTC",
      "updated_date": "2024-08-30 09:01:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:10:41.549738"
    },
    {
      "arxiv_id": "2408.17103v1",
      "title": "Understanding the User: An Intent-Based Ranking Dataset",
      "title_zh": "理解用户：基于意图的排名数据集",
      "authors": [
        "Abhijit Anand",
        "Jurek Leonhardt",
        "V Venktesh",
        "Avishek Anand"
      ],
      "abstract": "As information retrieval systems continue to evolve, accurate evaluation and\nbenchmarking of these systems become pivotal. Web search datasets, such as MS\nMARCO, primarily provide short keyword queries without accompanying intent or\ndescriptions, posing a challenge in comprehending the underlying information\nneed. This paper proposes an approach to augmenting such datasets to annotate\ninformative query descriptions, with a focus on two prominent benchmark\ndatasets: TREC-DL-21 and TREC-DL-22. Our methodology involves utilizing\nstate-of-the-art LLMs to analyze and comprehend the implicit intent within\nindividual queries from benchmark datasets. By extracting key semantic\nelements, we construct detailed and contextually rich descriptions for these\nqueries. To validate the generated query descriptions, we employ crowdsourcing\nas a reliable means of obtaining diverse human perspectives on the accuracy and\ninformativeness of the descriptions. This information can be used as an\nevaluation set for tasks such as ranking, query rewriting, or others.",
      "tldr_zh": "该论文针对信息检索系统的评估挑战，提出了一种增强数据集的方法，以解决现有查询（如MS MARCO）缺乏意图描述的问题。研究利用先进的LLMs分析TREC-DL-21和TREC-DL-22数据集中的查询，提取关键语义元素并生成详细的意图描述。最终，通过crowdsourcing验证这些描述的准确性和信息性，使其可作为评估集，用于排名、查询重写等任务。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.17103v1",
      "published_date": "2024-08-30 08:40:59 UTC",
      "updated_date": "2024-08-30 08:40:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:10:51.702755"
    },
    {
      "arxiv_id": "2408.17101v1",
      "title": "Strategic Arms with Side Communication Prevail Over Low-Regret MAB Algorithms",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmed Ben Yahmed",
        "Clément Calauzènes",
        "Vianney Perchet"
      ],
      "abstract": "In the strategic multi-armed bandit setting, when arms possess perfect\ninformation about the player's behavior, they can establish an equilibrium\nwhere: 1. they retain almost all of their value, 2. they leave the player with\na substantial (linear) regret. This study illustrates that, even if complete\ninformation is not publicly available to all arms but is shared among them, it\nis possible to achieve a similar equilibrium. The primary challenge lies in\ndesigning a communication protocol that incentivizes the arms to communicate\ntruthfully.",
      "tldr_zh": "本研究探讨了战略 Multi-Armed Bandit (MAB) 设置中，当 arms 通过 side communication 共享信息时，如何建立一个 equilibrium，使 arms 保留几乎全部价值，而玩家遭受线性 regret。相比于低-regret MAB 算法，该机制证明了 arms 在不完全信息条件下仍能主导局面，主要挑战在于设计一个激励 arms 诚实沟通的通信协议。通过这一方法，论文展示了 arms 的战略行为如何超越传统算法，为博弈理论和算法设计提供了新见解。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.17101v1",
      "published_date": "2024-08-30 08:36:45 UTC",
      "updated_date": "2024-08-30 08:36:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:11:05.219593"
    },
    {
      "arxiv_id": "2409.10521v1",
      "title": "LSTM Recurrent Neural Networks for Cybersecurity Named Entity Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Houssem Gasmi",
        "Jannik Laval",
        "Abdelaziz Bouras"
      ],
      "abstract": "The automated and timely conversion of cybersecurity information from\nunstructured online sources, such as blogs and articles to more formal\nrepresentations has become a necessity for many applications in the domain\nnowadays. Named Entity Recognition (NER) is one of the early phases towards\nthis goal. It involves the detection of the relevant domain entities, such as\nproduct, version, attack name, etc. in technical documents. Although generally\nconsidered a simple task in the information extraction field, it is quite\nchallenging in some domains like cybersecurity because of the complex structure\nof its entities. The state of the art methods require time-consuming and labor\nintensive feature engineering that describes the properties of the entities,\ntheir context, domain knowledge, and linguistic characteristics. The model\ndemonstrated in this paper is domain independent and does not rely on any\nfeatures specific to the entities in the cybersecurity domain, hence does not\nrequire expert knowledge to perform feature engineering. The method used relies\non a type of recurrent neural networks called Long Short-Term Memory (LSTM) and\nthe Conditional Random Fields (CRFs) method. The results we obtained showed\nthat this method outperforms the state of the art methods given an annotated\ncorpus of a decent size.",
      "tldr_zh": "本研究针对网络安全领域从非结构化在线来源（如博客和文章）提取信息的 Named Entity Recognition (NER) 挑战，提出了一种基于 Long Short-Term Memory (LSTM) 循环神经网络和 Conditional Random Fields (CRFs) 的模型。该模型是领域独立的，不依赖于特定实体特征，从而避免了耗时的人工特征工程。实验结果显示，在适当大小的标注语料库上，该方法超过了现有最先进方法的性能，为自动化网络安全信息处理提供了高效解决方案。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.10521v1",
      "published_date": "2024-08-30 08:35:48 UTC",
      "updated_date": "2024-08-30 08:35:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:11:20.213855"
    },
    {
      "arxiv_id": "2408.17090v2",
      "title": "FissionVAE: Federated Non-IID Image Generation with Latent Space and Decoder Decomposition",
      "title_zh": "翻译失败",
      "authors": [
        "Chen Hu",
        "Hanchi Ren",
        "Jingjing Deng",
        "Xianghua Xie",
        "Xiaoke Ma"
      ],
      "abstract": "Federated learning is a machine learning paradigm that enables decentralized\nclients to collaboratively learn a shared model while keeping all the training\ndata local. While considerable research has focused on federated image\ngeneration, particularly Generative Adversarial Networks, Variational\nAutoencoders have received less attention. In this paper, we address the\nchallenges of non-IID (independently and identically distributed) data\nenvironments featuring multiple groups of images of different types. Non-IID\ndata distributions can lead to difficulties in maintaining a consistent latent\nspace and can also result in local generators with disparate texture features\nbeing blended during aggregation. We thereby introduce FissionVAE that\ndecouples the latent space and constructs decoder branches tailored to\nindividual client groups. This method allows for customized learning that\naligns with the unique data distributions of each group. Additionally, we\nincorporate hierarchical VAEs and demonstrate the use of heterogeneous decoder\narchitectures within FissionVAE. We also explore strategies for setting the\nlatent prior distributions to enhance the decoupling process. To evaluate our\napproach, we assemble two composite datasets: the first combines MNIST and\nFashionMNIST; the second comprises RGB datasets of cartoon and human faces,\nwild animals, marine vessels, and remote sensing images. Our experiments\ndemonstrate that FissionVAE greatly improves generation quality on these\ndatasets compared to baseline federated VAE models.",
      "tldr_zh": "该论文针对联邦学习中非 IID 数据环境下的图像生成问题，提出 FissionVAE 框架，利用潜在空间 (latent space) 解耦和解码器分支 (decoder branches) 定制化设计，以应对数据分布不一致导致的潜在空间不稳定和特征混合问题。该框架还整合了分层 VAEs (hierarchical VAEs) 并优化潜在先验分布 (latent prior distributions)，允许客户端根据独特数据进行个性化学习。在实验中，使用组合数据集（如 MNIST 与 FashionMNIST，以及 RGB 图像集），FissionVAE 相较于基线联邦 VAE 模型，大幅提升了生成质量。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.17090v2",
      "published_date": "2024-08-30 08:22:30 UTC",
      "updated_date": "2025-05-05 13:51:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:11:34.943666"
    },
    {
      "arxiv_id": "2408.17064v3",
      "title": "Instant Adversarial Purification with Adversarial Consistency Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Chun Tong Lei",
        "Hon Ming Yam",
        "Zhongliang Guo",
        "Yifei Qian",
        "Chun Pong Lau"
      ],
      "abstract": "Neural networks have revolutionized numerous fields with their exceptional\nperformance, yet they remain susceptible to adversarial attacks through subtle\nperturbations. While diffusion-based purification methods like DiffPure offer\npromising defense mechanisms, their computational overhead presents a\nsignificant practical limitation. In this paper, we introduce One Step Control\nPurification (OSCP), a novel defense framework that achieves robust adversarial\npurification in a single Neural Function Evaluation (NFE) within diffusion\nmodels. We propose Gaussian Adversarial Noise Distillation (GAND) as the\ndistillation objective and Controlled Adversarial Purification (CAP) as the\ninference pipeline, which makes OSCP demonstrate remarkable efficiency while\nmaintaining defense efficacy. Our proposed GAND addresses a fundamental tension\nbetween consistency distillation and adversarial perturbation, bridging the gap\nbetween natural and adversarial manifolds in the latent space, while remaining\ncomputationally efficient through Parameter-Efficient Fine-Tuning (PEFT)\nmethods such as LoRA, eliminating the high computational budget request from\nfull parameter fine-tuning. The CAP guides the purification process through the\nunlearnable edge detection operator calculated by the input image as an extra\nprompt, effectively preventing the purified images from deviating from their\noriginal appearance when large purification steps are used. Our experimental\nresults on ImageNet showcase OSCP's superior performance, achieving a 74.19%\ndefense success rate with merely 0.1s per purification -- a 100-fold speedup\ncompared to conventional approaches.",
      "tldr_zh": "本文提出OSCP（One Step Control Purification）框架，通过单次Neural Function Evaluation（NFE）实现高效的对抗纯化，解决神经网络对微小扰动的易感性问题，同时减少传统扩散-based方法的计算开销。OSCP引入GAND（Gaussian Adversarial Noise Distillation）作为蒸馏目标，以桥接自然和对抗流形，并采用CAP（Controlled Adversarial Purification）作为推理管道，利用PEFT（Parameter-Efficient Fine-Tuning）如LoRA保持高效，并通过边缘检测操作符防止图像偏离原貌。实验在ImageNet上，OSCP实现了74.19%的防御成功率，仅需0.1秒每次净化，比传统方法快100倍，展示了显著的性能优势。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR2025",
      "pdf_url": "http://arxiv.org/pdf/2408.17064v3",
      "published_date": "2024-08-30 07:49:35 UTC",
      "updated_date": "2025-03-21 13:58:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:11:49.567716"
    },
    {
      "arxiv_id": "2408.17059v4",
      "title": "A Survey of the Self Supervised Learning Mechanisms for Vision Transformers",
      "title_zh": "视觉 Transformer 的自监督学习机制调查",
      "authors": [
        "Asifullah Khan",
        "Anabia Sohail",
        "Mustansar Fiaz",
        "Mehdi Hassan",
        "Tariq Habib Afridi",
        "Sibghat Ullah Marwat",
        "Farzeen Munir",
        "Safdar Ali",
        "Hannan Naseem",
        "Muhammad Zaigham Zaheer",
        "Kamran Ali",
        "Tangina Sultana",
        "Ziaurrehman Tanoli",
        "Naeem Akhter"
      ],
      "abstract": "Deep supervised learning models require high volume of labeled data to attain\nsufficiently good results. Although, the practice of gathering and annotating\nsuch big data is costly and laborious. Recently, the application of self\nsupervised learning (SSL) in vision tasks has gained significant attention. The\nintuition behind SSL is to exploit the synchronous relationships within the\ndata as a form of self-supervision, which can be versatile. In the current big\ndata era, most of the data is unlabeled, and the success of SSL thus relies in\nfinding ways to utilize this vast amount of unlabeled data available. Thus it\nis better for deep learning algorithms to reduce reliance on human supervision\nand instead focus on self-supervision based on the inherent relationships\nwithin the data. With the advent of ViTs, which have achieved remarkable\nresults in computer vision, it is crucial to explore and understand the various\nSSL mechanisms employed for training these models specifically in scenarios\nwhere there is limited labelled data available. In this survey, we develop a\ncomprehensive taxonomy of systematically classifying the SSL techniques based\nupon their representations and pre-training tasks being applied. Additionally,\nwe discuss the motivations behind SSL, review popular pre-training tasks, and\nhighlight the challenges and advancements in this field. Furthermore, we\npresent a comparative analysis of different SSL methods, evaluate their\nstrengths and limitations, and identify potential avenues for future research.",
      "tldr_zh": "这篇调查论文探讨了自监督学习 (Self-Supervised Learning, SSL) 在 Vision Transformers (ViTs) 中的机制，强调 SSL 通过利用数据内部关系来减少对标注数据的依赖，从而适用于大量未标注数据的场景。作者构建了一个全面的分类体系 (taxonomy)，系统分类 SSL 技术基于其表示形式和预训练任务，并回顾了 SSL 的动机、流行预训练任务以及领域的挑战和进展。该研究通过比较分析不同 SSL 方法的优缺点，评估了它们的优势和局限性，并指出了未来研究的潜在方向。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "34 Pages, 5 Figures, 7 Tables",
      "pdf_url": "http://arxiv.org/pdf/2408.17059v4",
      "published_date": "2024-08-30 07:38:28 UTC",
      "updated_date": "2025-03-20 04:10:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:11:59.135297"
    },
    {
      "arxiv_id": "2409.00147v1",
      "title": "MultiMath: Bridging Visual and Mathematical Reasoning for Large Language Models",
      "title_zh": "MultiMath：桥接视觉与",
      "authors": [
        "Shuai Peng",
        "Di Fu",
        "Liangcai Gao",
        "Xiuqin Zhong",
        "Hongguang Fu",
        "Zhi Tang"
      ],
      "abstract": "The rapid development of large language models (LLMs) has spurred extensive\nresearch into their domain-specific capabilities, particularly mathematical\nreasoning. However, most open-source LLMs focus solely on mathematical\nreasoning, neglecting the integration with visual injection, despite the fact\nthat many mathematical tasks rely on visual inputs such as geometric diagrams,\ncharts, and function plots. To fill this gap, we introduce\n\\textbf{MultiMath-7B}, a multimodal large language model that bridges the gap\nbetween math and vision. \\textbf{MultiMath-7B} is trained through a four-stage\nprocess, focusing on vision-language alignment, visual and math\ninstruction-tuning, and process-supervised reinforcement learning. We also\nconstruct a novel, diverse and comprehensive multimodal mathematical dataset,\n\\textbf{MultiMath-300K}, which spans K-12 levels with image captions and\nstep-wise solutions. MultiMath-7B achieves state-of-the-art (SOTA) performance\namong open-source models on existing multimodal mathematical benchmarks and\nalso excels on text-only mathematical benchmarks. Our model and dataset are\navailable at\n{\\textcolor{blue}{\\url{https://github.com/pengshuai-rin/MultiMath}}}.",
      "tldr_zh": "本研究提出 MultiMath-7B，一种多模态大型语言模型（multimodal large language model），旨在桥接视觉输入（如几何图表）和数学推理，解决现有开源 LLMs（large language models）在数学任务中忽略视觉元素的局限。模型通过四阶段训练过程，包括视觉-语言对齐、视觉和数学指令微调以及过程监督强化学习（process-supervised reinforcement learning），来提升其处理多模态数据的能力。同时，研究构建了 MultiMath-300K 数据集，这是一个覆盖 K-12 级别的多样化多模态数学数据集，包含图像描述和逐步解决方案。实验结果显示，MultiMath-7B 在多模态数学基准上实现了 SOTA（state-of-the-art）性能，并在纯文本数学基准中表现出色，模型和数据集已开源在 GitHub 上。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.00147v1",
      "published_date": "2024-08-30 07:37:38 UTC",
      "updated_date": "2024-08-30 07:37:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:12:21.576950"
    },
    {
      "arxiv_id": "2409.10520v1",
      "title": "Achieving Responsible AI through ESG: Insights and Recommendations from Industry Engagement",
      "title_zh": "翻译失败",
      "authors": [
        "Harsha Perera",
        "Sung Une Lee",
        "Yue Liu",
        "Boming Xia",
        "Qinghua Lu",
        "Liming Zhu",
        "Jessica Cairns",
        "Moana Nottage"
      ],
      "abstract": "As Artificial Intelligence (AI) becomes integral to business operations,\nintegrating Responsible AI (RAI) within Environmental, Social, and Governance\n(ESG) frameworks is essential for ethical and sustainable AI deployment. This\nstudy examines how leading companies align RAI with their ESG goals. Through\ninterviews with 28 industry leaders, we identified a strong link between RAI\nand ESG practices. However, a significant gap exists between internal RAI\npolicies and public disclosures, highlighting the need for greater board-level\nexpertise, robust governance, and employee engagement. We provide key\nrecommendations to strengthen RAI strategies, focusing on transparency,\ncross-functional collaboration, and seamless integration into existing ESG\nframeworks.",
      "tldr_zh": "这篇论文探讨了如何通过 Environmental, Social, and Governance (ESG) 框架实现 Responsible AI (RAI)，以促进 AI 的道德和可持续部署。研究通过对 28 位行业领导者的采访，发现 RAI 与 ESG 实践有紧密联系，但内部 RAI 政策与公开披露之间存在显著差距，强调了需要加强董事会专业知识、稳健治理和员工参与。论文提供了关键推荐，包括提升透明度、推动跨职能合作，以及将 RAI 无缝整合到现有 ESG 框架中，以强化企业 AI 策略。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "10 pages, 1 table, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2409.10520v1",
      "published_date": "2024-08-30 05:48:03 UTC",
      "updated_date": "2024-08-30 05:48:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:12:22.952917"
    },
    {
      "arxiv_id": "2408.17017v3",
      "title": "Reasoning Aware Self-Consistency: Leveraging Reasoning Paths for Efficient LLM Sampling",
      "title_zh": "翻译失败",
      "authors": [
        "Guangya Wan",
        "Yuqi Wu",
        "Jie Chen",
        "Sheng Li"
      ],
      "abstract": "Self-Consistency mitigates hallucinations in Large Language Models (LLMs) by\nsampling multiple reasoning paths,but it lacks a systematic approach to\ndetermine the optimal number of samples or select the most faithful rationale.\nTo address this limitation, we introduce Reasoning-Aware Self-Consistency\n(RASC), a novel framework that enhances sampling efficiency and reasoning\nfaithfulness by dynamically evaluating both outputs and rationales. RASC\nassesses the quality of reasoning and the consistency of answers for each\ngenerated sample, using these assessments to guide early stopping decisions and\nrationale selection. The framework employs criteria-based stopping and weighted\nmajority voting, enabling more informed choices on when to halt sampling and\nwhich rationale to select. Our comprehensive experiments across diverse\nquestion-answering datasets demonstrate that RASC outperforms existing methods,\nreducing sample usage by approximately 70% while maintaining accuracy.\nMoreover, RASC facilitates the selection of high-fidelity rationales, thereby\nimproving the faithfulness of LLM outputs. Our approach effectively addresses\nthe efficiency-accuracy trade-off in LLM reasoning tasks, offering a new\nperspective for more nuanced, faithful, and effective utilization of LLMs in\nresource-constrained environments.",
      "tldr_zh": "本研究提出 Reasoning-Aware Self-Consistency (RASC)，一种新框架，通过动态评估 Large Language Models (LLMs) 的输出和推理路径，提升采样效率并提高推理可靠性。RASC 采用基于标准的早停机制和加权多数投票，指导采样过程的停止决策和最可靠推理的选取，从而解决传统 Self-Consistency 方法在样本数量和推理选择上的局限性。实验在多种问答数据集上表明，RASC 比现有方法减少约70%的样本使用，同时保持准确性，并显著提升了LLMs输出的保真度。该框架为资源受限环境下的LLMs推理任务提供了更高效且可靠的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2408.17017v3",
      "published_date": "2024-08-30 05:14:59 UTC",
      "updated_date": "2025-02-04 03:59:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:12:35.854795"
    },
    {
      "arxiv_id": "2408.17011v2",
      "title": "Disease Classification and Impact of Pretrained Deep Convolution Neural Networks on Diverse Medical Imaging Datasets across Imaging Modalities",
      "title_zh": "翻译失败",
      "authors": [
        "Jutika Borah",
        "Kumaresh Sarmah",
        "Hidam Kumarjit Singh"
      ],
      "abstract": "Imaging techniques such as Chest X-rays, whole slide images, and optical\ncoherence tomography serve as the initial screening and detection for a wide\nvariety of medical pulmonary and ophthalmic conditions respectively. This paper\ninvestigates the intricacies of using pretrained deep convolutional neural\nnetworks with transfer learning across diverse medical imaging datasets with\nvarying modalities for binary and multiclass classification. We conducted a\ncomprehensive performance analysis with ten network architectures and model\nfamilies each with pretraining and random initialization. Our finding showed\nthat the use of pretrained models as fixed feature extractors yields poor\nperformance irrespective of the datasets. Contrary, histopathology microscopy\nwhole slide images have better performance. It is also found that deeper and\nmore complex architectures did not necessarily result in the best performance.\nThis observation implies that the improvements in ImageNet are not parallel to\nthe medical imaging tasks. Within a medical domain, the performance of the\nnetwork architectures varies within model families with shifts in datasets.\nThis indicates that the performance of models within a specific modality may\nnot be conclusive for another modality within the same domain. This study\nprovides a deeper understanding of the applications of deep learning techniques\nin medical imaging and highlights the impact of pretrained networks across\ndifferent medical imaging datasets under five different experimental settings.",
      "tldr_zh": "本论文探讨了使用预训练深度卷积神经网络（pretrained deep convolutional neural networks）结合转移学习（transfer learning）在不同医学成像数据集（如X光、组织病理学显微镜图像和光学相干断层扫描）上进行二元和多类疾病分类，并测试了十种网络架构的性能。研究发现，使用预训练模型作为固定特征提取器通常表现较差，而组织病理学全滑图像数据集的效果更好，且更深更复杂的架构并不总是带来最佳结果，这表明ImageNet上的改进不直接适用于医学成像任务。在同一医学领域内，模型在不同数据集和模式间的性能存在差异，该研究为深度学习在医疗成像中的应用提供了更深入的理解和指导。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "15 pages, 3 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2408.17011v2",
      "published_date": "2024-08-30 04:51:19 UTC",
      "updated_date": "2024-09-02 06:31:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:12:49.305183"
    },
    {
      "arxiv_id": "2408.17010v1",
      "title": "Improving Time Series Classification with Representation Soft Label Smoothing",
      "title_zh": "翻译失败",
      "authors": [
        "Hengyi Ma",
        "Weitong Chen"
      ],
      "abstract": "Previous research has indicated that deep neural network based models for\ntime series classification (TSC) tasks are prone to overfitting. This issue can\nbe mitigated by employing strategies that prevent the model from becoming\noverly confident in its predictions, such as label smoothing and confidence\npenalty. Building upon the concept of label smoothing, we propose a novel\napproach to generate more reliable soft labels, which we refer to as\nrepresentation soft label smoothing. We apply label smoothing, confidence\npenalty, and our method representation soft label smoothing to several TSC\nmodels and compare their performance with baseline method which only uses hard\nlabels for training. Our results demonstrate that the use of these enhancement\ntechniques yields competitive results compared to the baseline method.\nImportantly, our method demonstrates strong performance across models with\nvarying structures and complexities.",
      "tldr_zh": "这项研究针对时间序列分类(TSC)任务中深度神经网络容易过拟合的问题，提出了一种新方法representation soft label smoothing，用于生成更可靠的软标签。该方法基于label smoothing的概念，通过改进标签平滑和confidence penalty等策略，应用于多个TSC模型中。实验结果表明，与仅使用硬标签的基线方法相比，这些增强技术显著提高了模型性能，且representation soft label smoothing在不同结构和复杂度的模型上表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T07",
        "I.2.0"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages,6 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.17010v1",
      "published_date": "2024-08-30 04:50:27 UTC",
      "updated_date": "2024-08-30 04:50:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:12:58.269740"
    },
    {
      "arxiv_id": "2408.17003v5",
      "title": "Safety Layers in Aligned Large Language Models: The Key to LLM Security",
      "title_zh": "翻译失败",
      "authors": [
        "Shen Li",
        "Liuyi Yao",
        "Lan Zhang",
        "Yaliang Li"
      ],
      "abstract": "Aligned LLMs are secure, capable of recognizing and refusing to answer\nmalicious questions. However, the role of internal parameters in maintaining\nsuch security is not well understood yet, further these models can be\nvulnerable to security degradation when subjected to fine-tuning attacks. To\naddress these challenges, our work uncovers the mechanism behind security in\naligned LLMs at the parameter level, identifying a small set of contiguous\nlayers in the middle of the model that are crucial for distinguishing malicious\nqueries from normal ones, referred to as ``safety layers\". We first confirm the\nexistence of these safety layers by analyzing variations in input vectors\nwithin the model's internal layers. Additionally, we leverage the\nover-rejection phenomenon and parameters scaling analysis to precisely locate\nthe safety layers. Building on these findings, we propose a novel fine-tuning\napproach, Safely Partial-Parameter Fine-Tuning (SPPFT), that fixes the gradient\nof the safety layers during fine-tuning to address the security degradation.\nOur experiments demonstrate that the proposed approach can significantly\npreserve LLM security while maintaining performance and reducing computational\nresources compared to full fine-tuning.",
      "tldr_zh": "这篇论文揭示了aligned LLMs中关键的“safety layers”，这些位于模型中间的连续层组，能有效区分恶意查询，是维持LLM安全性的核心机制。研究者通过分析输入向量变化、over-rejection现象和参数缩放，精确确认了这些safety layers的存在。针对微调攻击导致的安全下降，他们提出Safely Partial-Parameter Fine-Tuning (SPPFT)方法，该方法在微调过程中固定safety layers的梯度，以保留模型安全性。实验结果显示，SPPFT显著提升了LLM的安全性，同时保持性能并减少计算资源。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted by ICLR 2025. The code is available at\n  https://github.com/listen0425/Safety-Layers",
      "pdf_url": "http://arxiv.org/pdf/2408.17003v5",
      "published_date": "2024-08-30 04:35:59 UTC",
      "updated_date": "2025-04-07 07:23:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:13:10.231247"
    },
    {
      "arxiv_id": "2409.00143v2",
      "title": "Semantic-Guided Multimodal Sentiment Decoding with Adversarial Temporal-Invariant Learning",
      "title_zh": "语义引导的多模态情感解码，结合对抗时间不变学习",
      "authors": [
        "Guoyang Xu",
        "Junqi Xue",
        "Yuxin Liu",
        "Zirui Wang",
        "Min Zhang",
        "Zhenxi Song",
        "Zhiguo Zhang"
      ],
      "abstract": "Multimodal sentiment analysis aims to learn representations from different\nmodalities to identify human emotions. However, existing works often neglect\nthe frame-level redundancy inherent in continuous time series, resulting in\nincomplete modality representations with noise. To address this issue, we\npropose temporal-invariant learning for the first time, which constrains the\ndistributional variations over time steps to effectively capture long-term\ntemporal dynamics, thus enhancing the quality of the representations and the\nrobustness of the model. To fully exploit the rich semantic information in\ntextual knowledge, we propose a semantic-guided fusion module. By evaluating\nthe correlations between different modalities, this module facilitates\ncross-modal interactions gated by modality-invariant representations.\nFurthermore, we introduce a modality discriminator to disentangle\nmodality-invariant and modality-specific subspaces. Experimental results on two\npublic datasets demonstrate the superiority of our model. Our code is available\nat https://github.com/X-G-Y/SATI.",
      "tldr_zh": "本研究针对多模态情感分析中存在的帧级冗余问题，提出首次引入 temporal-invariant learning 方法，通过约束时间步上的分布变化来捕获长期时间动态，提升模态表示的质量和模型的鲁棒性。同时，引入 semantic-guided fusion module 来利用文本知识的语义信息，通过评估模态间相关性并借助模态不变表示进行门控融合，以及 modality discriminator 来分离模态不变和模态特定子空间。实验结果显示，该模型在两个公共数据集上表现出优越性能，代码已开源于 GitHub。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "change Title, Authors, Abstract",
      "pdf_url": "http://arxiv.org/pdf/2409.00143v2",
      "published_date": "2024-08-30 03:28:40 UTC",
      "updated_date": "2024-09-11 04:44:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:13:22.061617"
    },
    {
      "arxiv_id": "2409.00142v1",
      "title": "Dynamic Depth Decoding: Faster Speculative Decoding for LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Oscar Brown",
        "Zhengjie Wang",
        "Andrea Do",
        "Nikhil Mathew",
        "Cheng Yu"
      ],
      "abstract": "The acceleration of Large Language Models (LLMs) with speculative decoding\nprovides a significant runtime improvement without any loss of accuracy.\nCurrently, EAGLE-2 is the state-of-the-art speculative decoding method,\nimproving on EAGLE with a dynamic draft tree. We introduce Dynamic Depth\nDecoding (DDD), which optimises EAGLE-2's tree drafting method using a dynamic\ndepth. This extends the average speedup that EAGLE-2 achieves over EAGLE by\n$44\\%$, giving DDD an average speedup of $3.16$x.",
      "tldr_zh": "本文提出 Dynamic Depth Decoding (DDD)，一种优化投机解码(speculative decoding)的方法，用于加速 Large Language Models (LLMs) 的运行速度，同时保持准确性不变。DDD 基于 EAGLE-2 的动态草稿树(dynamic draft tree)框架，通过引入动态深度来进一步提升树草稿过程的效率。实验结果显示，DDD 相对于 EAGLE-2 平均加速 44%，整体实现 3.16 倍的加速效果，为 LLM 的高效部署提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.00142v1",
      "published_date": "2024-08-30 03:27:48 UTC",
      "updated_date": "2024-08-30 03:27:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:13:36.305090"
    },
    {
      "arxiv_id": "2408.16984v2",
      "title": "Beyond Preferences in AI Alignment",
      "title_zh": "AI 对齐：超越偏好",
      "authors": [
        "Tan Zhi-Xuan",
        "Micah Carroll",
        "Matija Franklin",
        "Hal Ashton"
      ],
      "abstract": "The dominant practice of AI alignment assumes (1) that preferences are an\nadequate representation of human values, (2) that human rationality can be\nunderstood in terms of maximizing the satisfaction of preferences, and (3) that\nAI systems should be aligned with the preferences of one or more humans to\nensure that they behave safely and in accordance with our values. Whether\nimplicitly followed or explicitly endorsed, these commitments constitute what\nwe term a preferentist approach to AI alignment. In this paper, we characterize\nand challenge the preferentist approach, describing conceptual and technical\nalternatives that are ripe for further research. We first survey the limits of\nrational choice theory as a descriptive model, explaining how preferences fail\nto capture the thick semantic content of human values, and how utility\nrepresentations neglect the possible incommensurability of those values. We\nthen critique the normativity of expected utility theory (EUT) for humans and\nAI, drawing upon arguments showing how rational agents need not comply with\nEUT, while highlighting how EUT is silent on which preferences are normatively\nacceptable. Finally, we argue that these limitations motivate a reframing of\nthe targets of AI alignment: Instead of alignment with the preferences of a\nhuman user, developer, or humanity-writ-large, AI systems should be aligned\nwith normative standards appropriate to their social roles, such as the role of\na general-purpose assistant. Furthermore, these standards should be negotiated\nand agreed upon by all relevant stakeholders. On this alternative conception of\nalignment, a multiplicity of AI systems will be able to serve diverse ends,\naligned with normative standards that promote mutual benefit and limit harm\ndespite our plural and divergent values.",
      "tldr_zh": "本论文挑战了AI校准（AI alignment）中以偏好（preferences）为核心的传统做法，认为它假设偏好能充分代表人类价值观，且人类理性仅通过最大化偏好满足来理解，这存在局限性。作者审视了理性选择理论（rational choice theory）的不足，如偏好无法捕捉人类价值观的丰富语义和潜在不可通约性，并批判了期望效用理论（EUT）的规范性，指出理性代理无需严格遵守EUT，且该理论未解决哪些偏好是可接受的。最终，论文提出重新框架AI校准目标：AI系统应与社会角色相关的规范标准对齐，这些标准需由相关利益相关者协商，以促进多样化AI系统服务多元目标并减少伤害。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "26 pages (excl. references), 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.16984v2",
      "published_date": "2024-08-30 03:14:20 UTC",
      "updated_date": "2024-11-06 20:34:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:13:48.125880"
    },
    {
      "arxiv_id": "2408.16978v2",
      "title": "Training Ultra Long Context Language Model with Fully Pipelined Distributed Transformer",
      "title_zh": "使用完全流水线化分布式 Transformer 训练超长上下文语言模型",
      "authors": [
        "Jinghan Yao",
        "Sam Ade Jacobs",
        "Masahiro Tanaka",
        "Olatunji Ruwase",
        "Hari Subramoni",
        "Dhabaleswar K. Panda"
      ],
      "abstract": "Large Language Models (LLMs) with long context capabilities are integral to\ncomplex tasks in natural language processing and computational biology, such as\ntext generation and protein sequence analysis. However, training LLMs directly\non extremely long contexts demands considerable GPU resources and increased\nmemory, leading to higher costs and greater complexity. Alternative approaches\nthat introduce long context capabilities via downstream finetuning or\nadaptations impose significant design limitations. In this paper, we propose\nFully Pipelined Distributed Transformer (FPDT) for efficiently training\nlong-context LLMs with extreme hardware efficiency. For GPT and Llama models,\nwe achieve a 16x increase in sequence length that can be trained on the same\nhardware compared to current state-of-the-art solutions. With our dedicated\nsequence chunk pipeline design, we can now train 8B LLM with 2 million sequence\nlength on only 4 GPUs, while also maintaining over 55% of MFU. Our proposed\nFPDT is agnostic to existing training techniques and is proven to work\nefficiently across different LLM models.",
      "tldr_zh": "本文研究了训练长上下文大语言模型(LLMs)的挑战，如高GPU资源和内存需求，并提出Fully Pipelined Distributed Transformer (FPDT)方法，以实现高效训练。FPDT通过专有的序列块管道设计，使LLMs在相同硬件上序列长度提高16倍，例如仅用4个GPU即可训练8B模型支持2百万序列长度，同时保持超过55%的MFU。FPDT与现有训练技术兼容，可在不同LLM模型（如GPT和Llama）上高效应用。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "The Eighth Annual Conference on Machine Learning and Systems\n  (MLSys'25)",
      "pdf_url": "http://arxiv.org/pdf/2408.16978v2",
      "published_date": "2024-08-30 02:44:26 UTC",
      "updated_date": "2025-05-13 15:07:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:14:00.369714"
    },
    {
      "arxiv_id": "2408.16975v3",
      "title": "Technical Report of HelixFold3 for Biomolecular Structure Prediction",
      "title_zh": "HelixFold3 的生物分子结构预测技术报告",
      "authors": [
        "Lihang Liu",
        "Shanzhuo Zhang",
        "Yang Xue",
        "Xianbin Ye",
        "Kunrui Zhu",
        "Yuxin Li",
        "Yang Liu",
        "Jie Gao",
        "Wenlai Zhao",
        "Hongkun Yu",
        "Zhihua Wu",
        "Xiaonan Zhang",
        "Xiaomin Fang"
      ],
      "abstract": "The AlphaFold series has transformed protein structure prediction with\nremarkable accuracy, often matching experimental methods. AlphaFold2,\nAlphaFold-Multimer, and the latest AlphaFold3 represent significant strides in\npredicting single protein chains, protein complexes, and biomolecular\nstructures. While AlphaFold2 and AlphaFold-Multimer are open-sourced,\nfacilitating rapid and reliable predictions, AlphaFold3 remains partially\naccessible through a limited online server and has not been open-sourced,\nrestricting further development. To address these challenges, the PaddleHelix\nteam is developing HelixFold3, aiming to replicate AlphaFold3's capabilities.\nLeveraging insights from previous models and extensive datasets, HelixFold3\nachieves accuracy comparable to AlphaFold3 in predicting the structures of the\nconventional ligands, nucleic acids, and proteins. The initial release of\nHelixFold3 is available as open source on GitHub for academic research,\npromising to advance biomolecular research and accelerate discoveries. The\nlatest version will be continuously updated on the HelixFold3 web server,\nproviding both interactive visualization and API access.",
      "tldr_zh": "PaddleHelix 团队开发了 HelixFold3，这是一个开源模型，旨在复制 AlphaFold3 的能力，以解决其未开源导致的开发限制问题。HelixFold3 利用来自 AlphaFold2、AlphaFold-Multimer 的洞见和广泛数据集，实现了在预测常规配体、核酸和蛋白质结构方面的准确性，与 AlphaFold3 相当。HelixFold3 的初始版本已在 GitHub 上公开，用于学术研究，并计划通过 web 服务器持续更新，提供交互式可视化和 API 访问，从而推动生物分子研究的进展。",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.BM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.16975v3",
      "published_date": "2024-08-30 02:36:36 UTC",
      "updated_date": "2024-12-23 04:57:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:14:15.523082"
    },
    {
      "arxiv_id": "2408.16967v1",
      "title": "MemLong: Memory-Augmented Retrieval for Long Text Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Weijie Liu",
        "Zecheng Tang",
        "Juntao Li",
        "Kehai Chen",
        "Min Zhang"
      ],
      "abstract": "Recent advancements in Large Language Models (LLMs) have yielded remarkable\nsuccess across diverse fields. However, handling long contexts remains a\nsignificant challenge for LLMs due to the quadratic time and space complexity\nof attention mechanisms and the growing memory consumption of the key-value\ncache during generation. This work introduces MemLong: Memory-Augmented\nRetrieval for Long Text Generation, a method designed to enhance the\ncapabilities of long-context language modeling by utilizing an external\nretriever for historical information retrieval. MemLong combines a\nnon-differentiable ``ret-mem'' module with a partially trainable decoder-only\nlanguage model and introduces a fine-grained, controllable retrieval attention\nmechanism that leverages semantic-level relevant chunks. Comprehensive\nevaluations on multiple long-context language modeling benchmarks demonstrate\nthat MemLong consistently outperforms other state-of-the-art LLMs. More\nimportantly, MemLong can extend the context length on a single 3090 GPU from 4k\nup to 80k. Our code is available at https://github.com/Bui1dMySea/MemLong",
      "tldr_zh": "这篇论文介绍了 MemLong，一种记忆增强检索方法，用于提升 Large Language Models (LLMs) 在长文本建模中的性能，解决注意力机制的二次复杂性和内存消耗问题。MemLong 结合非微分的 ret-mem 模块、部分可训练的解码器语言模型，以及细粒度的、可控的检索注意力机制，以语义级别相关块来检索历史信息。实验结果显示，MemLong 在多个长上下文基准上超越了最先进模型，并在单个 3090 GPU 上将上下文长度从 4k 扩展到 80k，提供了一个高效的开源实现。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.16967v1",
      "published_date": "2024-08-30 02:01:56 UTC",
      "updated_date": "2024-08-30 02:01:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:14:24.503816"
    },
    {
      "arxiv_id": "2408.16966v2",
      "title": "UserSumBench: A Benchmark Framework for Evaluating User Summarization Approaches",
      "title_zh": "翻译失败",
      "authors": [
        "Chao Wang",
        "Neo Wu",
        "Lin Ning",
        "Jiaxing Wu",
        "Luyang Liu",
        "Jun Xie",
        "Shawn O'Banion",
        "Bradley Green"
      ],
      "abstract": "Large language models (LLMs) have shown remarkable capabilities in generating\nuser summaries from a long list of raw user activity data. These summaries\ncapture essential user information such as preferences and interests, and\ntherefore are invaluable for LLM-based personalization applications, such as\nexplainable recommender systems. However, the development of new summarization\ntechniques is hindered by the lack of ground-truth labels, the inherent\nsubjectivity of user summaries, and human evaluation which is often costly and\ntime-consuming. To address these challenges, we introduce \\UserSumBench, a\nbenchmark framework designed to facilitate iterative development of LLM-based\nsummarization approaches. This framework offers two key components: (1) A\nreference-free summary quality metric. We show that this metric is effective\nand aligned with human preferences across three diverse datasets (MovieLens,\nYelp and Amazon Review). (2) A novel robust summarization method that leverages\ntime-hierarchical summarizer and self-critique verifier to produce high-quality\nsummaries while eliminating hallucination. This method serves as a strong\nbaseline for further innovation in summarization techniques.",
      "tldr_zh": "该论文引入了UserSumBench，一种基准框架，用于评估从用户活动数据生成用户摘要的Large Language Models (LLMs)方法，以支持个性化应用如可解释推荐系统。框架解决了现有挑战，包括缺乏真实标签、摘要主观性和昂贵的人类评估，通过提供一个无参考摘要质量指标，该指标在MovieLens、Yelp和Amazon Review三个数据集上显示出与人类偏好高度一致的效果。同时，框架提出了一种新型鲁棒总结方法，利用time-hierarchical summarizer和self-critique verifier生成高质量摘要并减少幻觉，作为强有力的基线，促进后续总结技术的创新。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.16966v2",
      "published_date": "2024-08-30 01:56:57 UTC",
      "updated_date": "2024-09-05 23:18:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:14:36.491769"
    },
    {
      "arxiv_id": "2408.16958v1",
      "title": "Discovery of False Data Injection Schemes on Frequency Controllers with Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Romesh Prasad",
        "Malik Hassanaly",
        "Xiangyu Zhang",
        "Abhijeet Sahu"
      ],
      "abstract": "While inverter-based distributed energy resources (DERs) play a crucial role\nin integrating renewable energy into the power system, they concurrently\ndiminish the grid's system inertia, elevating the risk of frequency\ninstabilities. Furthermore, smart inverters, interfaced via communication\nnetworks, pose a potential vulnerability to cyber threats if not diligently\nmanaged. To proactively fortify the power grid against sophisticated cyber\nattacks, we propose to employ reinforcement learning (RL) to identify potential\nthreats and system vulnerabilities. This study concentrates on analyzing\nadversarial strategies for false data injection, specifically targeting smart\ninverters involved in primary frequency control. Our findings demonstrate that\nan RL agent can adeptly discern optimal false data injection methods to\nmanipulate inverter settings, potentially causing catastrophic consequences.",
      "tldr_zh": "本研究探讨了逆变器-based分布式能源资源(DERs)在电力系统中整合可再生能源带来的双重影响：虽然提升了可再生能源利用，但也降低了系统惯性并增加了频率不稳定风险，同时智能逆变器通过通信网络易受网络攻击。研究采用Reinforcement Learning (RL)来识别针对参与主频率控制的智能逆变器的假数据注入攻击策略。结果显示，RL代理能够高效发现最佳的假数据注入方法，可能导致灾难性后果，从而为强化电网安全和防范潜在威胁提供重要洞见。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.16958v1",
      "published_date": "2024-08-30 01:09:32 UTC",
      "updated_date": "2024-08-30 01:09:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:14:47.696756"
    },
    {
      "arxiv_id": "2408.16952v1",
      "title": "Transient Fault Tolerant Semantic Segmentation for Autonomous Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Leonardo Iurada",
        "Niccolò Cavagnero",
        "Fernando Fernandes Dos Santos",
        "Giuseppe Averta",
        "Paolo Rech",
        "Tatiana Tommasi"
      ],
      "abstract": "Deep learning models are crucial for autonomous vehicle perception, but their\nreliability is challenged by algorithmic limitations and hardware faults. We\naddress the latter by examining fault-tolerance in semantic segmentation\nmodels. Using established hardware fault models, we evaluate existing hardening\ntechniques both in terms of accuracy and uncertainty and introduce ReLUMax, a\nnovel simple activation function designed to enhance resilience against\ntransient faults. ReLUMax integrates seamlessly into existing architectures\nwithout time overhead. Our experiments demonstrate that ReLUMax effectively\nimproves robustness, preserving performance and boosting prediction confidence,\nthus contributing to the development of reliable autonomous driving systems.",
      "tldr_zh": "该研究针对自动驾驶中语义分割模型的硬件故障问题，评估了现有加固技术（hardening techniques）在准确性和不确定性方面的表现。研究者引入了新型激活函数 ReLUMax，以提升模型对瞬时故障（transient faults）的鲁棒性，该函数可无缝集成到现有架构中而不增加时间开销。实验结果显示，ReLUMax 显著提高了模型性能和预测置信度，从而为开发可靠的自动驾驶系统提供了重要贡献。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted ECCV 2024 UnCV Workshop -\n  https://github.com/iurada/neutron-segmentation",
      "pdf_url": "http://arxiv.org/pdf/2408.16952v1",
      "published_date": "2024-08-30 00:27:46 UTC",
      "updated_date": "2024-08-30 00:27:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:15:00.322922"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 88,
  "processed_papers_count": 88,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-19T20:15:22.484353"
}