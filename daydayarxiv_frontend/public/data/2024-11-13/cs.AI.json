{
  "date": "2024-11-13",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-11-13 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 和机器学习领域的创新，特别是 Large Language Models (LLMs) 在多模态任务、代码生成和强化学习中的应用，以及一些跨领域进展如机器人导航和医学图像分析；令人印象深刻的文章包括 CHAI 框架（提升 LLM 在代码混合语言上的性能）和 Diffusion Models 的研究，而知名学者如 Neil D. Lawrence 的论文则强调系统工程在 AI 应用中的作用。以下我挑选了部分重要或有话题度的论文进行简要讨论，将 AI 相关内容优先呈现，并快速掠过较常规的文章。\n\n### AI 和 LLM 相关\n- **CHAI for LLMs: Improving Code-Mixed Translation in Large Language Models through Reinforcement Learning with AI Feedback**（CHAI for LLMs: 通过 AI 反馈的强化学习提升大语言模型的代码混合翻译）  \n  这篇论文提出 CHAI 框架，利用 LLM 生成偏好数据并通过强化学习（RLAIF）改善多语言模型在代码混合任务中的性能。主要贡献是提升了翻译准确性，实验显示比开源 LLM 高 25.66% 的胜率，适用于更包容性的语言处理。\n\n- **Language-Model Prior Overcomes Cold-Start Items**（Language-Model Prior: 语言模型先验克服冷启动项目）  \n  作者包括 Branislav Kveton，该论文引入语言模型估计算法来处理推荐系统的冷启动问题。通过将语言模型先验整合到经典推荐器中，提高了新项目的相似性估计。发现能提升序列和协作过滤推荐的性能，尤其在真实数据集上。\n\n- **CoCoP: Enhancing Text Classification with LLM through Code Completion Prompt**（CoCoP: 通过代码补全提示提升 LLM 的文本分类）  \n  这篇工作将文本分类转化为代码补全任务，使用 LLM 如 CodeLLaMA 进行优化。关键发现是 CoCoP 显著提高了分类准确性（如 SST2 数据集提升 20%），并在小模型上与少样本学习相当。\n\n- **The Systems Engineering Approach in Times of Large Language Models**（在大型语言模型时代下的系统工程方法）  \n  Neil D. Lawrence 等作者讨论了将系统工程原则应用于 LLM，以解决社会问题。主要贡献是整合可靠性工程和人类因素分析，提供框架提升 AI 系统的可信度，并提出未来研究方向。\n\n- **InterPLM: Discovering Interpretable Features in Protein Language Models via Sparse Autoencoders**（InterPLM: 通过稀疏自编码器发现蛋白质语言模型的可解释特征）  \n  这篇论文使用稀疏自编码器从蛋白质 LLM 中提取可解释特征，如生物概念的关联。发现 LLM 能学习新蛋白质模式，并提供交互平台，扩展了生物信息学应用。\n\n- **The Limited Impact of Medical Adaptation of Large Language and Vision-Language Models**（大型语言和视觉语言模型的医学适配的有限影响）  \n  作者分析医学适配的 LLM 和 VLM 在医疗任务中的表现，发现它们未能一致超越基础模型。主要发现是通用模型已具备强医疗知识，提示未来研究需更注重校准。\n\n### 机器人和强化学习\n- **Liner Shipping Network Design with Reinforcement Learning**（Liner Shipping Network Design with Reinforcement Learning: 使用强化学习的班轮航线网络设计）  \n  这篇论文提出强化学习框架优化航线网络设计，结合启发式求解器。关键贡献是提升了成本效率，并在基准上实现泛化，适用于复杂优化问题。\n\n- **Offline Adaptation of Quadruped Locomotion using Diffusion Models**（Offline Adaptation of Quadruped Locomotion using Diffusion Models: 使用扩散模型的四足机器人离线适应）  \n  作者使用扩散模型从无标签数据中提取目标行为，应用于四足机器人。发现能显著提升运动适应性，实验在 ANYmal 平台验证。\n\n- **Flow reconstruction in time-varying geometries using graph neural networks**（Flow reconstruction in time-varying geometries using graph neural networks: 使用图神经网络的重建时间变化几何流场）  \n  这篇工作使用 GACN 重建动态流场，处理稀疏数据。贡献包括鲁棒性能和实验验证，适用于工程模拟。\n\n### 计算机视觉和图像处理\n- **Drone Detection using Deep Neural Networks Trained on Pure Synthetic Data**（Drone Detection using Deep Neural Networks Trained on Pure Synthetic Data: 使用纯合成数据训练的深度神经网络的无人机检测）  \n  论文使用合成数据训练 Faster-RCNN 模型，实现高精度无人机检测（AP_50 达 97.0%）。主要发现是减少了数据采集成本，并为安全应用如机场检测提供基础。\n\n- **Multimodal Object Detection using Depth and Image Data for Manufacturing Parts**（Multimodal Object Detection using Depth and Image Data for Manufacturing Parts: 用于制造部件的多模态物体检测）  \n  这篇论文融合 RGB 和深度数据改进物体检测，基于 Faster-RCNN。贡献是提升了 mAP（比单模态高 13%），增强了智能制造的鲁棒性。\n\n其他领域如材料科学（e.g., Crystal Structure Generation）和医学（e.g., SAFELOC for indoor localization）论文较多，但相对常规，我这里快速掠过：它们主要贡献了新数据集或框架，如 IDCIA 提供细胞图像数据集，或 SAFELOC 提升了定位精度，但未有突破性创新。\n\n总之，今天的论文突显了 AI 在多领域应用的潜力，LLM 和强化学习方向尤其值得关注。如果您对特定主题感兴趣，建议查看这些论文的摘要！（本快报基于 103 篇论文精选，仅覆盖核心内容。）",
  "papers": [
    {
      "arxiv_id": "2411.09089v1",
      "title": "Set-Based Retrograde Analysis: Precomputing the Solution to 24-card Bridge Double Dummy Deals",
      "title_zh": "翻译失败",
      "authors": [
        "Isaac Stone",
        "Nathan R. Sturtevant",
        "Jonathan Schaeffer"
      ],
      "abstract": "Retrograde analysis is used in game-playing programs to solve states at the\nend of a game, working backwards toward the start of the game. The algorithm\niterates through and computes the perfect-play value for as many states as\nresources allow. We introduce setrograde analysis which achieves the same\nresults by operating on sets of states that have the same game value. The\nalgorithm is demonstrated by computing exact solutions for Bridge double dummy\ncard-play. For deals with 24 cards remaining to be played ($10^{27}$ states,\nwhich can be reduced to $10^{15}$ states using preexisting techniques), we\nstrongly solve all deals. The setrograde algorithm performs a factor of $10^3$\nfewer search operations than a standard retrograde algorithm, producing a\ndatabase with a factor of $10^4$ fewer entries. For applicable domains, this\nallows retrograde searching to reach unprecedented search depths.",
      "tldr_zh": "本论文提出了一种名为setrograde analysis的改进算法，它通过操作具有相同游戏价值的state集合来优化retrograde analysis，从而预计算游戏状态的完美解。该方法应用于Bridge double dummy deals的24张牌局面（原本涉及10^27个states，通过现有技术减至10^15个states），成功strongly solve所有局面。与标准retrograde algorithm相比，setrograde analysis减少了10^3倍的搜索操作和10^4倍的数据库条目。总体而言，这为retrograde searching在相关领域实现前所未有的搜索深度提供了新途径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.09089v1",
      "published_date": "2024-11-13 23:43:01 UTC",
      "updated_date": "2024-11-13 23:43:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:01:07.545098"
    },
    {
      "arxiv_id": "2412.00011v1",
      "title": "The use of knowledge in open-ended systems",
      "title_zh": "翻译失败",
      "authors": [
        "Abigail Devereaux",
        "Roger Koppl"
      ],
      "abstract": "Economists model knowledge use and acquisition as a cause-and-effect calculus\nassociating observations made by a decision-maker about their world with\npossible underlying causes. Knowledge models are well-established for static\ncontexts, but not for contexts of innovative and unbounded change. We develop a\nrepresentation of knowledge use and acquisition in open-ended evolutionary\nsystems and demonstrate its primary results, including that observers embedded\nin open-ended evolutionary systems can agree to disagree and that their ability\nto theorize about their systems is fundamentally local and constrained to their\nframe of reference what we call frame relativity. The results of our framework\nformalize local knowledge use, the many-selves interpretation of reasoning\nthrough time, and motivate the emergence of nonlogical modes of reasoning like\ninstitutional and aesthetic codes.",
      "tldr_zh": "经济学家传统上将知识的使用和获取建模为观察与潜在原因之间的因果计算，这种方法在静态环境中已成熟，但在创新和无限变化的开放式进化系统中尚不完善。本文开发了一个知识在开放式进化系统中的表示框架，展示了关键结果，包括观察者可能“同意不同意”，以及他们的理论化能力受限于框架相对性(frame relativity)。该框架形式化了局部知识使用、多重自我解释，并推动了非逻辑推理模式如制度和美学代码(institutional and aesthetic codes)的出现。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LO",
        "econ.TH"
      ],
      "primary_category": "cs.NE",
      "comment": "44 pages, 0 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.00011v1",
      "published_date": "2024-11-13 23:27:01 UTC",
      "updated_date": "2024-11-13 23:27:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:01:18.432214"
    },
    {
      "arxiv_id": "2411.09077v1",
      "title": "Drone Detection using Deep Neural Networks Trained on Pure Synthetic Data",
      "title_zh": "翻译失败",
      "authors": [
        "Mariusz Wisniewski",
        "Zeeshan A. Rana",
        "Ivan Petrunin",
        "Alan Holt",
        "Stephen Harman"
      ],
      "abstract": "Drone detection has benefited from improvements in deep neural networks, but\nlike many other applications, suffers from the availability of accurate data\nfor training. Synthetic data provides a potential for low-cost data generation\nand has been shown to improve data availability and quality. However, models\ntrained on synthetic datasets need to prove their ability to perform on\nreal-world data, known as the problem of sim-to-real transferability. Here, we\npresent a drone detection Faster-RCNN model trained on a purely synthetic\ndataset that transfers to real-world data. We found that it achieves an AP_50\nof 97.0% when evaluated on the MAV-Vid - a real dataset of flying drones -\ncompared with 97.8% for an equivalent model trained on real-world data. Our\nresults show that using synthetic data for drone detection has the potential to\nreduce data collection costs and improve labelling quality. These findings\ncould be a starting point for more elaborate synthetic drone datasets. For\nexample, realistic recreations of specific scenarios could de-risk the dataset\ngeneration of safety-critical applications such as the detection of drones at\nairports. Further, synthetic data may enable reliable drone detection systems,\nwhich could benefit other areas, such as unmanned traffic management systems.\nThe code is available\nhttps://github.com/mazqtpopx/cranfield-synthetic-drone-detection alongside the\ndatasets\nhttps://huggingface.co/datasets/mazqtpopx/cranfield-synthetic-drone-detection.",
      "tldr_zh": "这篇论文提出了一种使用纯合成数据集训练Faster-RCNN模型的方法，用于无人机检测，以解决真实数据获取的成本和质量问题。实验结果显示，该模型在真实数据集MAV-Vid上达到了97.0%的AP_50，与使用真实数据训练的模型（97.8%）表现相当，证明了合成数据的sim-to-real transferability。研究表明，这种方法可降低数据收集和标注成本，并为安全关键应用（如机场无人机检测）提供更可靠的合成数据集基础。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.09077v1",
      "published_date": "2024-11-13 23:09:53 UTC",
      "updated_date": "2024-11-13 23:09:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:01:30.104967"
    },
    {
      "arxiv_id": "2411.09073v2",
      "title": "CHAI for LLMs: Improving Code-Mixed Translation in Large Language Models through Reinforcement Learning with AI Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Wenbo Zhang",
        "Aditya Majumdar",
        "Amulya Yadav"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across\nvarious NLP tasks but struggle with code-mixed (or code-switched) language\nunderstanding. For example, prior work benchmarking the performance of\nmultilingual LLMs on code-mixed translation tasks has demonstrated that current\nstate-of-the-art multilingual LLMs are ineffective in dealing with code-mixed\nlanguages. However, the question of how to improve the capability of\nmultilingual LLMs to handle code-mixed language has not received any attention\nto date. In this paper, we tackle this research gap by proposing CHAI, a novel\ngeneral-purpose framework for improving the ability of multilingual LLMs to\nhandle code-mixed languages. CHAI relies on three novel contributions made in\nthis paper. First, we explore the ability of LLMs to provide accurate\nannotations for code-mixed translation tasks. Second, we leverage this ability\nof LLMs as annotators to generate preference data for code-mixed translation\ntasks at scale, which are then used within a reinforcement learning from AI\nfeedback (RLAIF) procedure to improve LLMs' capability on code-mixed tasks.\nThird, we conduct a rigorous experimental evaluation across various real-world\ndatasets and settings. Our analysis shows that CHAI-powered LLMs outperform\nstate-of-the-art open-source LLMs by 25.66% (in terms of win rate adjudicated\nby human annotators) in code-mixed translation tasks. This work represents a\nfirst step towards developing more inclusive code-mixed LLMs.",
      "tldr_zh": "本论文针对大型语言模型(LLMs) 在处理代码混合(code-mixed)语言时的不足，提出 CHAI 框架，通过强化学习从 AI 反馈(Reinforcement Learning with AI Feedback)来提升其翻译能力。CHAI 的关键创新包括利用 LLMs 作为注解器生成大规模偏好数据，并应用 RLAIF 优化模型在代码混合任务上的性能。实验评估显示，CHAI 增强的 LLMs 在真实数据集上胜率比最先进的开源模型高出 25.66%，这标志着向更包容的代码混合 LLMs 迈出的重要一步。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "full draft: 8 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.09073v2",
      "published_date": "2024-11-13 22:56:00 UTC",
      "updated_date": "2025-02-26 20:11:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:01:43.068910"
    },
    {
      "arxiv_id": "2411.09068v1",
      "title": "Liner Shipping Network Design with Reinforcement Learning",
      "title_zh": "基于强化学习的班轮航运网络设计",
      "authors": [
        "Utsav Dutta",
        "Yifan Lin",
        "Zhaoyang Larry Jin"
      ],
      "abstract": "This paper proposes a novel reinforcement learning framework to address the\nLiner Shipping Network Design Problem (LSNDP), a challenging combinatorial\noptimization problem focused on designing cost-efficient maritime shipping\nroutes. Traditional methods for solving the LSNDP typically involve decomposing\nthe problem into sub-problems, such as network design and multi-commodity flow,\nwhich are then tackled using approximate heuristics or large neighborhood\nsearch (LNS) techniques. In contrast, our approach employs a model-free\nreinforcement learning algorithm on the network design, integrated with a\nheuristic-based multi-commodity flow solver, to produce competitive results on\nthe publicly available LINERLIB benchmark. Additionally, our method also\ndemonstrates generalization capabilities by producing competitive solutions on\nthe benchmark instances after training on perturbed instances.",
      "tldr_zh": "这篇论文提出了一种新型强化学习(Reinforcement Learning)框架，用于解决Liner Shipping Network Design Problem (LSNDP)，这是一个关于设计成本高效海运路线的组合优化问题。与传统方法相比，该框架采用无模型强化学习算法处理网络设计，并与启发式多商品流求解器集成，从而在LINERLIB基准上产生有竞争力的结果。该方法还展示了泛化能力，通过在扰动实例上训练后，能在基准实例上生成可靠的解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.09068v1",
      "published_date": "2024-11-13 22:49:16 UTC",
      "updated_date": "2024-11-13 22:49:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:01:54.266815"
    },
    {
      "arxiv_id": "2411.09065v1",
      "title": "Language-Model Prior Overcomes Cold-Start Items",
      "title_zh": "翻译失败",
      "authors": [
        "Shiyu Wang",
        "Hao Ding",
        "Yupeng Gu",
        "Sergul Aydore",
        "Kousha Kalantari",
        "Branislav Kveton"
      ],
      "abstract": "The growth of recommender systems (RecSys) is driven by digitization and the\nneed for personalized content in areas such as e-commerce and video streaming.\nThe content in these systems often changes rapidly and therefore they\nconstantly face the ongoing cold-start problem, where new items lack\ninteraction data and are hard to value. Existing solutions for the cold-start\nproblem, such as content-based recommenders and hybrid methods, leverage item\nmetadata to determine item similarities. The main challenge with these methods\nis their reliance on structured and informative metadata to capture detailed\nitem similarities, which may not always be available. This paper introduces a\nnovel approach for cold-start item recommendation that utilizes the language\nmodel (LM) to estimate item similarities, which are further integrated as a\nBayesian prior with classic recommender systems. This approach is generic and\nable to boost the performance of various recommenders. Specifically, our\nexperiments integrate it with both sequential and collaborative filtering-based\nrecommender and evaluate it on two real-world datasets, demonstrating the\nenhanced performance of the proposed approach.",
      "tldr_zh": "本研究针对推荐系统（RecSys）中的冷启动问题（cold-start problem），提出了一种新方法，使用语言模型（LM）来估计项目相似度，并将其作为Bayesian prior整合到经典推荐系统中，以克服项目元数据不足的挑战。该方法通用，能够提升顺序和协同过滤-based recommender的性能。在两个真实数据集上的实验中，该方法显著提高了推荐系统的整体表现。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "This paper is dedicated to cold-start item recommendation using\n  language-model priors",
      "pdf_url": "http://arxiv.org/pdf/2411.09065v1",
      "published_date": "2024-11-13 22:45:52 UTC",
      "updated_date": "2024-11-13 22:45:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:02:05.193080"
    },
    {
      "arxiv_id": "2411.09062v2",
      "title": "Multimodal Object Detection using Depth and Image Data for Manufacturing Parts",
      "title_zh": "基于深度和图像数据的多模态物体检测用于制造零件",
      "authors": [
        "Nazanin Mahjourian",
        "Vinh Nguyen"
      ],
      "abstract": "Manufacturing requires reliable object detection methods for precise picking\nand handling of diverse types of manufacturing parts and components.\nTraditional object detection methods utilize either only 2D images from cameras\nor 3D data from lidars or similar 3D sensors. However, each of these sensors\nhave weaknesses and limitations. Cameras do not have depth perception and 3D\nsensors typically do not carry color information. These weaknesses can\nundermine the reliability and robustness of industrial manufacturing systems.\nTo address these challenges, this work proposes a multi-sensor system combining\nan red-green-blue (RGB) camera and a 3D point cloud sensor. The two sensors are\ncalibrated for precise alignment of the multimodal data captured from the two\nhardware devices. A novel multimodal object detection method is developed to\nprocess both RGB and depth data. This object detector is based on the Faster\nR-CNN baseline that was originally designed to process only camera images. The\nresults show that the multimodal model significantly outperforms the depth-only\nand RGB-only baselines on established object detection metrics. More\nspecifically, the multimodal model improves mAP by 13% and raises Mean\nPrecision by 11.8% in comparison to the RGB-only baseline. Compared to the\ndepth-only baseline, it improves mAP by 78% and raises Mean Precision by 57%.\nHence, this method facilitates more reliable and robust object detection in\nservice to smart manufacturing applications.",
      "tldr_zh": "本文针对制造零件检测的挑战，提出了一种多模态对象检测系统，结合RGB相机和3D点云传感器，以克服传统方法（如仅使用2D图像或3D数据）的局限性，例如相机缺少深度感知和3D传感器缺少颜色信息。该系统通过传感器校准和基于Faster R-CNN的创新方法，同时处理RGB和深度数据，实现更精确的对象检测。实验结果显示，多模态模型在mAP上比RGB-only基线提高了13%、Mean Precision提高了11.8%；与depth-only基线相比，mAP提升了78%、Mean Precision提升了57%。这种方法显著提升了智能制造应用中的检测可靠性和稳健性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.09062v2",
      "published_date": "2024-11-13 22:43:15 UTC",
      "updated_date": "2025-03-27 19:10:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:02:20.068192"
    },
    {
      "arxiv_id": "2411.09055v1",
      "title": "SAFELOC: Overcoming Data Poisoning Attacks in Heterogeneous Federated Machine Learning for Indoor Localization",
      "title_zh": "翻译失败",
      "authors": [
        "Akhil Singampalli",
        "Danish Gufran",
        "Sudeep Pasricha"
      ],
      "abstract": "Machine learning (ML) based indoor localization solutions are critical for\nmany emerging applications, yet their efficacy is often compromised by\nhardware/software variations across mobile devices (i.e., device heterogeneity)\nand the threat of ML data poisoning attacks. Conventional methods aimed at\ncountering these challenges show limited resilience to the uncertainties\ncreated by these phenomena. In response, in this paper, we introduce SAFELOC, a\nnovel framework that not only minimizes localization errors under these\nchallenging conditions but also ensures model compactness for efficient mobile\ndevice deployment. Our framework targets a distributed and co-operative\nlearning environment that uses federated learning (FL) to preserve user data\nprivacy and assumes heterogeneous mobile devices carried by users (just like in\nmost real-world scenarios). Within this heterogeneous FL context, SAFELOC\nintroduces a novel fused neural network architecture that performs data\npoisoning detection and localization, with a low model footprint. Additionally,\na dynamic saliency map-based aggregation strategy is designed to adapt based on\nthe severity of the detected data poisoning scenario. Experimental evaluations\ndemonstrate that SAFELOC achieves improvements of up to 5.9x in mean\nlocalization error, 7.8x in worst-case localization error, and a 2.1x reduction\nin model inference latency compared to state-of-the-art indoor localization\nframeworks, across diverse building floorplans, mobile devices, and ML data\npoisoning attack scenarios.",
      "tldr_zh": "该研究提出 SAFELOC 框架，旨在解决室内定位系统中设备异构性和数据中毒攻击带来的挑战，通过异构联邦学习（Federated Learning, FL）环境实现用户数据隐私保护和模型优化。SAFELOC 采用融合神经网络架构进行数据中毒检测和定位，同时引入动态显著性图（saliency map）-基于聚合策略，以适应不同攻击严重程度，并保持模型紧凑以提升移动设备部署效率。实验结果显示，与现有框架相比，SAFELOC 改善了 5.9 倍的均定位错误、7.8 倍的最坏情况定位错误，并减少了 2.1 倍的模型推理延迟，在多种建筑布局、设备和攻击场景下表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.09055v1",
      "published_date": "2024-11-13 22:28:05 UTC",
      "updated_date": "2024-11-13 22:28:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:02:29.991866"
    },
    {
      "arxiv_id": "2411.09050v1",
      "title": "The Systems Engineering Approach in Times of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Christian Cabrera",
        "Viviana Bastidas",
        "Jennifer Schooling",
        "Neil D. Lawrence"
      ],
      "abstract": "Using Large Language Models (LLMs) to address critical societal problems\nrequires adopting this novel technology into socio-technical systems. However,\nthe complexity of such systems and the nature of LLMs challenge such a vision.\nIt is unlikely that the solution to such challenges will come from the\nArtificial Intelligence (AI) community itself. Instead, the Systems Engineering\napproach is better equipped to facilitate the adoption of LLMs by prioritising\nthe problems and their context before any other aspects. This paper introduces\nthe challenges LLMs generate and surveys systems research efforts for\nengineering AI-based systems. We reveal how the systems engineering principles\nhave supported addressing similar issues to the ones LLMs pose and discuss our\nfindings to provide future directions for adopting LLMs.",
      "tldr_zh": "这篇论文讨论了在 Large Language Models (LLMs) 时代，使用 Systems Engineering 方法来整合这些模型到社会技术系统中，以解决关键社会问题的挑战。作者强调，LLMs 的复杂性和独特特性使得单纯依赖 Artificial Intelligence (AI) 社区难以应对，因此优先考虑问题及其上下文是关键。论文通过调查工程 AI 基于系统的研究努力，揭示了 Systems Engineering 原则如何有效处理类似问题，并为未来 LLMs 的采用提供指导方向。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "This paper has been accepted for the upcoming 58th Hawaii\n  International Conference on System Sciences (HICSS-58)",
      "pdf_url": "http://arxiv.org/pdf/2411.09050v1",
      "published_date": "2024-11-13 22:10:07 UTC",
      "updated_date": "2024-11-13 22:10:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:02:43.560863"
    },
    {
      "arxiv_id": "2411.08992v2",
      "title": "IDCIA: Immunocytochemistry Dataset for Cellular Image Analysis",
      "title_zh": "IDCIA：用于细胞图像分析的免疫",
      "authors": [
        "Abdurahman Ali Mohammed",
        "Catherine Fonder",
        "Donald S. Sakaguchi",
        "Wallapak Tavanapong",
        "Surya K. Mallapragada",
        "Azeez Idris"
      ],
      "abstract": "We present a new annotated microscopic cellular image dataset to improve the\neffectiveness of machine learning methods for cellular image analysis. Cell\ncounting is an important step in cell analysis. Typically, domain experts\nmanually count cells in a microscopic image. Automated cell counting can\npotentially eliminate this tedious, time-consuming process. However, a good,\nlabeled dataset is required for training an accurate machine learning model.\nOur dataset includes microscopic images of cells, and for each image, the cell\ncount and the location of individual cells. The data were collected as part of\nan ongoing study investigating the potential of electrical stimulation to\nmodulate stem cell differentiation and possible applications for neural repair.\nCompared to existing publicly available datasets, our dataset has more images\nof cells stained with more variety of antibodies (protein components of immune\nresponses against invaders) typically used for cell analysis. The experimental\nresults on this dataset indicate that none of the five existing models under\nthis study are able to achieve sufficiently accurate count to replace the\nmanual methods. The dataset is available at\nhttps://figshare.com/articles/dataset/Dataset/21970604.",
      "tldr_zh": "本文介绍了IDCIA数据集，这是一个新的标注微观细胞图像数据集，旨在提升机器学习在细胞图像分析中的有效性。该数据集包含细胞计数、单个细胞位置的信息，并包括更多抗体染色类型，用于研究电刺激对干细胞分化的影响。相比现有公开数据集，IDCIA提供了更多图像和多样性，以支持更准确的自动化细胞计数。实验结果显示，五种现有模型的计数准确性不足，无法取代手动方法，该数据集可公开获取于https://figshare.com/articles/dataset/Dataset/21970604。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08992v2",
      "published_date": "2024-11-13 19:33:08 UTC",
      "updated_date": "2024-11-19 14:51:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:02:54.267623"
    },
    {
      "arxiv_id": "2411.08981v1",
      "title": "Reliability, Resilience and Human Factors Engineering for Trustworthy AI Systems",
      "title_zh": "用于可信赖AI系统的可靠性、韧性和人因工程",
      "authors": [
        "Saurabh Mishra",
        "Anand Rao",
        "Ramayya Krishnan",
        "Bilal Ayyub",
        "Amin Aria",
        "Enrico Zio"
      ],
      "abstract": "As AI systems become integral to critical operations across industries and\nservices, ensuring their reliability and safety is essential. We offer a\nframework that integrates established reliability and resilience engineering\nprinciples into AI systems. By applying traditional metrics such as failure\nrate and Mean Time Between Failures (MTBF) along with resilience engineering\nand human reliability analysis, we propose an integrate framework to manage AI\nsystem performance, and prevent or efficiently recover from failures. Our work\nadapts classical engineering methods to AI systems and outlines a research\nagenda for future technical studies. We apply our framework to a real-world AI\nsystem, using system status data from platforms such as openAI, to demonstrate\nits practical applicability. This framework aligns with emerging global\nstandards and regulatory frameworks, providing a methodology to enhance the\ntrustworthiness of AI systems. Our aim is to guide policy, regulation, and the\ndevelopment of reliable, safe, and adaptable AI technologies capable of\nconsistent performance in real-world environments.",
      "tldr_zh": "本研究提出一个整合框架，将可靠性工程(Resilience Engineering)、韧性工程和人类因素工程(Human Factors Engineering)应用于AI系统，以提升其可靠性、安全性和可信任性。该框架利用传统指标如故障率和Mean Time Between Failures (MTBF)，结合人类可靠性分析，管理AI性能、预防故障并实现快速恢复。研究者通过应用该框架到真实AI系统（如openAI平台）进行验证，证明其实际可行性，并为未来技术研究、政策制定和全球标准（如新兴监管框架）提供指导，最终推动开发可靠、可适应AI技术。",
      "categories": [
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08981v1",
      "published_date": "2024-11-13 19:16:44 UTC",
      "updated_date": "2024-11-13 19:16:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:03:05.869725"
    },
    {
      "arxiv_id": "2411.08979v1",
      "title": "CoCoP: Enhancing Text Classification with LLM through Code Completion Prompt",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammad Mahdi Mohajeri",
        "Mohammad Javad Dousti",
        "Majid Nili Ahmadabadi"
      ],
      "abstract": "Text classification is a fundamental task in natural language processing\n(NLP), and large language models (LLMs) have demonstrated their capability to\nperform this task across various domains. However, the performance of LLMs\nheavily depends on the quality of their input prompts. Recent studies have also\nshown that LLMs exhibit remarkable results in code-related tasks. To leverage\nthe capabilities of LLMs in text classification, we propose the Code Completion\nPrompt (CoCoP) method, which transforms the text classification problem into a\ncode completion task. CoCoP significantly improves text classification\nperformance across diverse datasets by utilizing LLMs' code-completion\ncapability. For instance, CoCoP enhances the accuracy of the SST2 dataset by\nmore than 20%. Moreover, when CoCoP integrated with LLMs specifically designed\nfor code-related tasks (code models), such as CodeLLaMA, this method\ndemonstrates better or comparable performance to few-shot learning techniques\nwhile using only one-tenth of the model size. The source code of our proposed\nmethod will be available to the public upon the acceptance of the paper.",
      "tldr_zh": "该研究提出CoCoP方法，通过将文本分类任务转化为代码补全任务，利用LLM的代码处理能力来提升分类性能。CoCoP在多种数据集上显著提高了准确率，例如在SST2数据集上提升超过20%。此外，当与专为代码任务设计的LLM（如CodeLLaMA）结合时，CoCoP仅使用原模型大小的十分之一，便实现了与少样本学习相当的性能，并计划公开源代码以促进进一步应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08979v1",
      "published_date": "2024-11-13 19:12:02 UTC",
      "updated_date": "2024-11-13 19:12:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:03:18.024895"
    },
    {
      "arxiv_id": "2411.08975v1",
      "title": "Fluoroformer: Scaling multiple instance learning to multiplexed images via attention-based channel fusion",
      "title_zh": "翻译失败",
      "authors": [
        "Marc Harary",
        "Eliezer M. Van Allen",
        "William Lotter"
      ],
      "abstract": "Though multiple instance learning (MIL) has been a foundational strategy in\ncomputational pathology for processing whole slide images (WSIs), current\napproaches are designed for traditional hematoxylin and eosin (H&E) slides\nrather than emerging multiplexed technologies. Here, we present an MIL\nstrategy, the Fluoroformer module, that is specifically tailored to multiplexed\nWSIs by leveraging scaled dot-product attention (SDPA) to interpretably fuse\ninformation across disparate channels. On a cohort of 434 non-small cell lung\ncancer (NSCLC) samples, we show that the Fluoroformer both obtains strong\nprognostic performance and recapitulates immuno-oncological hallmarks of NSCLC.\nOur technique thereby provides a path for adapting state-of-the-art AI\ntechniques to emerging spatial biology assays.",
      "tldr_zh": "这篇论文引入了 Fluoroformer 模块，一种针对多重染色全滑玻图像 (WSIs) 的 multiple instance learning (MIL) 策略，通过 scaled dot-product attention (SDPA) 来可解释地融合不同通道信息，以适应新兴的多重染色技术。实验在 434 个 non-small cell lung cancer (NSCLC) 样本上进行，Fluoroformer 展示了出色的预后性能，并成功再现了 NSCLC 的免疫肿瘤学特征。该方法为将最先进的 AI 技术应用于新兴空间生物学检测提供了重要路径。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "Findings paper presented at Machine Learning for Health (ML4H)\n  symposium 2024, December 15-16, 2024, Vancouver, Canada, 14 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.08975v1",
      "published_date": "2024-11-13 19:06:57 UTC",
      "updated_date": "2024-11-13 19:06:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:03:30.633719"
    },
    {
      "arxiv_id": "2411.08954v2",
      "title": "Inconsistencies In Consistency Models: Better ODE Solving Does Not Imply Better Samples",
      "title_zh": "翻译失败",
      "authors": [
        "Noël Vouitsis",
        "Rasa Hosseinzadeh",
        "Brendan Leigh Ross",
        "Valentin Villecroze",
        "Satya Krishna Gorti",
        "Jesse C. Cresswell",
        "Gabriel Loaiza-Ganem"
      ],
      "abstract": "Although diffusion models can generate remarkably high-quality samples, they\nare intrinsically bottlenecked by their expensive iterative sampling procedure.\nConsistency models (CMs) have recently emerged as a promising diffusion model\ndistillation method, reducing the cost of sampling by generating high-fidelity\nsamples in just a few iterations. Consistency model distillation aims to solve\nthe probability flow ordinary differential equation (ODE) defined by an\nexisting diffusion model. CMs are not directly trained to minimize error\nagainst an ODE solver, rather they use a more computationally tractable\nobjective. As a way to study how effectively CMs solve the probability flow\nODE, and the effect that any induced error has on the quality of generated\nsamples, we introduce Direct CMs, which \\textit{directly} minimize this error.\nIntriguingly, we find that Direct CMs reduce the ODE solving error compared to\nCMs but also result in significantly worse sample quality, calling into\nquestion why exactly CMs work well in the first place. Full code is available\nat: https://github.com/layer6ai-labs/direct-cms.",
      "tldr_zh": "该论文探讨了Consistency models (CMs) 在扩散模型（diffusion models）中的局限性，指出尽管CMs 通过间接目标训练能以少量迭代生成高质量样本，但其并非直接优化概率流普通微分方程（ODE）的求解错误。研究者引入Direct CMs 方法，直接最小化ODE求解错误，以检验CMs 的有效性。结果显示，Direct CMs 降低了ODE求解错误，却导致样本质量显著下降，这揭示了更好的ODE求解并不必然带来更好的生成样本，并为理解CMs的工作机制提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024 ATTRIB Workshop",
      "pdf_url": "http://arxiv.org/pdf/2411.08954v2",
      "published_date": "2024-11-13 19:00:02 UTC",
      "updated_date": "2024-11-15 16:06:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:03:42.312216"
    },
    {
      "arxiv_id": "2411.08879v1",
      "title": "4D Gaussian Splatting in the Wild with Uncertainty-Aware Regularization",
      "title_zh": "翻译失败",
      "authors": [
        "Mijeong Kim",
        "Jongwoo Lim",
        "Bohyung Han"
      ],
      "abstract": "Novel view synthesis of dynamic scenes is becoming important in various\napplications, including augmented and virtual reality. We propose a novel 4D\nGaussian Splatting (4DGS) algorithm for dynamic scenes from casually recorded\nmonocular videos. To overcome the overfitting problem of existing work for\nthese real-world videos, we introduce an uncertainty-aware regularization that\nidentifies uncertain regions with few observations and selectively imposes\nadditional priors based on diffusion models and depth smoothness on such\nregions. This approach improves both the performance of novel view synthesis\nand the quality of training image reconstruction. We also identify the\ninitialization problem of 4DGS in fast-moving dynamic regions, where the\nStructure from Motion (SfM) algorithm fails to provide reliable 3D landmarks.\nTo initialize Gaussian primitives in such regions, we present a dynamic region\ndensification method using the estimated depth maps and scene flow. Our\nexperiments show that the proposed method improves the performance of 4DGS\nreconstruction from a video captured by a handheld monocular camera and also\nexhibits promising results in few-shot static scene reconstruction.",
      "tldr_zh": "本研究提出了一种新的4D Gaussian Splatting (4DGS)算法，用于从随意录制的单目视频中合成动态场景的新视角，以应用于增强现实和虚拟现实领域。为了解决现有方法在真实视频中的过拟合问题，该算法引入了uncertainty-aware regularization，通过识别不确定区域（观察较少的部分）并应用基于扩散模型和深度平滑的额外先验，从而提升新视角合成性能和训练图像重建质量。同时，为处理4DGS在快速移动动态区域的初始化问题（如Structure from Motion (SfM)算法失败时），研究者开发了动态区域稠密化方法，利用估计的深度图和场景流来初始化Gaussian primitives。实验结果显示，该方法显著改善了从手持单目相机捕获视频的4DGS重建效果，并在少样本静态场景重建中表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.08879v1",
      "published_date": "2024-11-13 18:56:39 UTC",
      "updated_date": "2024-11-13 18:56:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:03:56.411740"
    },
    {
      "arxiv_id": "2411.08878v1",
      "title": "A Short Note on Evaluating RepNet for Temporal Repetition Counting in Videos",
      "title_zh": "翻译失败",
      "authors": [
        "Debidatta Dwibedi",
        "Yusuf Aytar",
        "Jonathan Tompson",
        "Pierre Sermanet",
        "Andrew Zisserman"
      ],
      "abstract": "We discuss some consistent issues on how RepNet has been evaluated in various\npapers. As a way to mitigate these issues, we report RepNet performance results\non different datasets, and release evaluation code and the RepNet checkpoint to\nobtain these results. Code URL:\nhttps://github.com/google-research/google-research/blob/master/repnet/",
      "tldr_zh": "这篇论文讨论了在各种研究中评估RepNet（用于视频中时间重复计数）的常见问题，以提高评估的一致性和可靠性。作者报告了RepNet在不同数据集上的性能结果，并发布了评估代码和RepNet检查点，以便其他研究者复现这些结果。总体而言，此工作有助于标准化RepNet的评估流程，促进视频重复计数领域的可重复性研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08878v1",
      "published_date": "2024-11-13 18:55:10 UTC",
      "updated_date": "2024-11-13 18:55:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:04:05.371447"
    },
    {
      "arxiv_id": "2411.08875v1",
      "title": "Causal Explanations for Image Classifiers",
      "title_zh": "图像分类器的因果解释",
      "authors": [
        "Hana Chockler",
        "David A. Kelly",
        "Daniel Kroening",
        "Youcheng Sun"
      ],
      "abstract": "Existing algorithms for explaining the output of image classifiers use\ndifferent definitions of explanations and a variety of techniques to extract\nthem. However, none of the existing tools use a principled approach based on\nformal definitions of causes and explanations for the explanation extraction.\nIn this paper we present a novel black-box approach to computing explanations\ngrounded in the theory of actual causality. We prove relevant theoretical\nresults and present an algorithm for computing approximate explanations based\non these definitions. We prove termination of our algorithm and discuss its\ncomplexity and the amount of approximation compared to the precise definition.\nWe implemented the framework in a tool rex and we present experimental results\nand a comparison with state-of-the-art tools. We demonstrate that rex is the\nmost efficient tool and produces the smallest explanations, in addition to\noutperforming other black-box tools on standard quality measures.",
      "tldr_zh": "这篇论文提出了一种基于实际因果理论（actual causality）的黑-box 方法，用于解释图像分类器的输出，填补了现有算法缺乏正式定义的空白。作者开发了一个算法来计算近似解释，并证明了其终止性、复杂性和近似精度。实验结果显示，该方法实现的工具 rex 比现有工具更高效，生成的最小解释，并在标准质量指标上优于其他 black-box 工具。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08875v1",
      "published_date": "2024-11-13 18:52:42 UTC",
      "updated_date": "2024-11-13 18:52:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:04:17.932250"
    },
    {
      "arxiv_id": "2412.12101v1",
      "title": "InterPLM: Discovering Interpretable Features in Protein Language Models via Sparse Autoencoders",
      "title_zh": "InterPLM：通过稀疏自动编码器在蛋白质语言模型中发现可解释特征",
      "authors": [
        "Elana Simon",
        "James Zou"
      ],
      "abstract": "Protein language models (PLMs) have demonstrated remarkable success in\nprotein modeling and design, yet their internal mechanisms for predicting\nstructure and function remain poorly understood. Here we present a systematic\napproach to extract and analyze interpretable features from PLMs using sparse\nautoencoders (SAEs). By training SAEs on embeddings from the PLM ESM-2, we\nidentify up to 2,548 human-interpretable latent features per layer that\nstrongly correlate with up to 143 known biological concepts such as binding\nsites, structural motifs, and functional domains. In contrast, examining\nindividual neurons in ESM-2 reveals up to 46 neurons per layer with clear\nconceptual alignment across 15 known concepts, suggesting that PLMs represent\nmost concepts in superposition. Beyond capturing known annotations, we show\nthat ESM-2 learns coherent concepts that do not map onto existing annotations\nand propose a pipeline using language models to automatically interpret novel\nlatent features learned by the SAEs. As practical applications, we demonstrate\nhow these latent features can fill in missing annotations in protein databases\nand enable targeted steering of protein sequence generation. Our results\ndemonstrate that PLMs encode rich, interpretable representations of protein\nbiology and we propose a systematic framework to extract and analyze these\nlatent features. In the process, we recover both known biology and potentially\nnew protein motifs. As community resources, we introduce InterPLM\n(interPLM.ai), an interactive visualization platform for exploring and\nanalyzing learned PLM features, and release code for training and analysis at\ngithub.com/ElanaPearl/interPLM.",
      "tldr_zh": "本研究提出InterPLM框架，使用Sparse Autoencoders (SAEs)从Protein Language Models (PLMs)如ESM-2的嵌入中提取可解释特征，旨在揭示PLMs在预测蛋白质结构和功能时的内部机制。结果显示，每个层可识别多达2,548个与已知生物概念（如binding sites、structural motifs和functional domains）高度相关的潜在特征，而单个神经元仅显示少量概念叠加现象。作者进一步开发了自动解释新特征的管道，并展示了实际应用，如填充蛋白质数据库的缺失注释和针对性引导蛋白序列生成，同时提供InterPLM交互平台和开源代码作为社区资源。",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.LG",
        "q-bio.QM"
      ],
      "primary_category": "q-bio.BM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12101v1",
      "published_date": "2024-11-13 18:51:21 UTC",
      "updated_date": "2024-11-13 18:51:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:04:31.073859"
    },
    {
      "arxiv_id": "2411.08870v2",
      "title": "The Limited Impact of Medical Adaptation of Large Language and Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel P. Jeong",
        "Pranav Mani",
        "Saurabh Garg",
        "Zachary C. Lipton",
        "Michael Oberst"
      ],
      "abstract": "Several recent works seek to adapt general-purpose large language models\n(LLMs) and vision-language models (VLMs) for medical applications through\ncontinued pretraining on publicly available biomedical corpora. These works\ntypically claim that such domain-adaptive pretraining improves performance on\nvarious downstream medical tasks, such as answering medical exam questions. In\nthis paper, we compare ten \"medical\" LLMs and two VLMs against their\ncorresponding base models, arriving at a different conclusion: all medical VLMs\nand nearly all medical LLMs fail to consistently improve over their base models\nin the zero-/few-shot prompting and supervised fine-tuning regimes for medical\nquestion answering (QA). For instance, on clinical-note-based QA tasks in the\n3-shot setting, medical LLMs outperform their base models in only 26.7% of\ncases, reach a (statistical) tie in 16.7% of cases, and perform significantly\nworse in the remaining 56.7% of cases. Our conclusions are based on (i)\ncomparing each medical model directly against its base model; (ii) optimizing\nthe prompts for each model separately in zero-/few-shot prompting; and (iii)\naccounting for statistical uncertainty in comparisons. Our findings suggest\nthat state-of-the-art general-domain models may already exhibit strong medical\nknowledge and reasoning capabilities, and offer recommendations to strengthen\nthe conclusions of future studies.",
      "tldr_zh": "这篇论文评估了将大型语言模型（LLMs）和视觉语言模型（VLMs）适应医疗领域的效果，通过比较十个“医疗”LLMs和两个VLMs与其基础模型在医疗问答（QA）任务中的表现。研究发现，在零/少样本提示和监督微调设置下，所有医疗VLMs和几乎所有医疗LLMs未能一致地改善性能，例如在3-shot临床笔记QA任务中，医疗LLMs仅在26.7%的情况下优于基础模型，而在56.7%的情况下表现更差。作者强调，通用域模型可能已具备强大的医疗知识和推理能力，并建议未来研究通过优化提示和考虑统计不确定性来加强结论的可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Extended version of EMNLP 2024 paper arXiv:2411.04118. Includes\n  additional results on clinical note QA tasks and supervised fine-tuning\n  evaluations",
      "pdf_url": "http://arxiv.org/pdf/2411.08870v2",
      "published_date": "2024-11-13 18:50:13 UTC",
      "updated_date": "2025-02-28 07:34:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:04:42.624232"
    },
    {
      "arxiv_id": "2411.08861v1",
      "title": "Interaction Testing in Variation Analysis",
      "title_zh": "变异分析中的交互测试",
      "authors": [
        "Drago Plecko"
      ],
      "abstract": "Relationships of cause and effect are of prime importance for explaining\nscientific phenomena. Often, rather than just understanding the effects of\ncauses, researchers also wish to understand how a cause $X$ affects an outcome\n$Y$ mechanistically -- i.e., what are the causal pathways that are activated\nbetween $X$ and $Y$. For analyzing such questions, a range of methods has been\ndeveloped over decades under the rubric of causal mediation analysis.\nTraditional mediation analysis focuses on decomposing the average treatment\neffect (ATE) into direct and indirect effects, and therefore focuses on the ATE\nas the central quantity. This corresponds to providing explanations for\nassociations in the interventional regime, such as when the treatment $X$ is\nrandomized. Commonly, however, it is of interest to explain associations in the\nobservational regime, and not just in the interventional regime. In this paper,\nwe introduce \\text{variation analysis}, an extension of mediation analysis that\nfocuses on the total variation (TV) measure between $X$ and $Y$, written as\n$\\mathrm{E}[Y \\mid X=x_1] - \\mathrm{E}[Y \\mid X=x_0]$. The TV measure\nencompasses both causal and confounded effects, as opposed to the ATE which\nonly encompasses causal (direct and mediated) variations. In this way, the TV\nmeasure is suitable for providing explanations in the natural regime and\nanswering questions such as ``why is $X$ associated with $Y$?''. Our focus is\non decomposing the TV measure, in a way that explicitly includes direct,\nindirect, and confounded variations. Furthermore, we also decompose the TV\nmeasure to include interaction terms between these different pathways.\nSubsequently, interaction testing is introduced, involving hypothesis tests to\ndetermine if interaction terms are significantly different from zero. If\ninteractions are not significant, more parsimonious decompositions of the TV\nmeasure can be used.",
      "tldr_zh": "本文扩展了causal mediation analysis，引入variation analysis方法，聚焦于总变异(TV)度量（即E[Y | X=x1] - E[Y | X=x0]），以解释观察性制度中的X与Y关联，包括因果、混杂效应，而非仅限于average treatment effect (ATE)。该方法将TV分解为直接、间接和混杂变异，并加入这些路径间的交互项，提供更全面的机制性分析。作者提出interaction testing，通过假设检验确定交互项是否显著，从而允许使用更简化的分解模型。",
      "categories": [
        "stat.ME",
        "cs.AI",
        "cs.LG",
        "math.ST",
        "stat.TH"
      ],
      "primary_category": "stat.ME",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08861v1",
      "published_date": "2024-11-13 18:42:34 UTC",
      "updated_date": "2024-11-13 18:42:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:04:54.751429"
    },
    {
      "arxiv_id": "2411.08843v1",
      "title": "Data-driven Surface Solar Irradiance Estimation using Neural Operators at Global Scale",
      "title_zh": "翻译失败",
      "authors": [
        "Alberto Carpentieri",
        "Jussi Leinonen",
        "Jeff Adie",
        "Boris Bonev",
        "Doris Folini",
        "Farah Hariri"
      ],
      "abstract": "Accurate surface solar irradiance (SSI) forecasting is essential for\noptimizing renewable energy systems, particularly in the context of long-term\nenergy planning on a global scale. This paper presents a pioneering approach to\nsolar radiation forecasting that leverages recent advancements in numerical\nweather prediction (NWP) and data-driven machine learning weather models. These\nadvances facilitate long, stable rollouts and enable large ensemble forecasts,\nenhancing the reliability of predictions. Our flexible model utilizes variables\nforecast by these NWP and AI weather models to estimate 6-hourly SSI at global\nscale. Developed using NVIDIA Modulus, our model represents the first adaptive\nglobal framework capable of providing long-term SSI forecasts. Furthermore, it\ncan be fine-tuned using satellite data, which significantly enhances its\nperformance in the fine-tuned regions, while maintaining accuracy elsewhere.\nThe improved accuracy of these forecasts has substantial implications for the\nintegration of solar energy into power grids, enabling more efficient energy\nmanagement and contributing to the global transition to renewable energy\nsources.",
      "tldr_zh": "这篇论文提出了一种数据驱动的方法，使用 Neural Operators 基于数值天气预报 (NWP) 和 AI 天气模型的数据，估计全球规模的表面太阳辐照度 (SSI)，以支持长期能源规划。该模型由 NVIDIA Modulus 开发，是首个自适应全球框架，能够提供稳定的长期预测和大型集合预报，并通过卫星数据微调提升特定区域的性能，同时保持整体准确性。结果表明，该方法显著提高了 SSI 预测准确性，促进太阳能与电网的更高效整合，并加速全球向可再生能源的过渡。",
      "categories": [
        "physics.ao-ph",
        "cs.AI"
      ],
      "primary_category": "physics.ao-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08843v1",
      "published_date": "2024-11-13 18:21:56 UTC",
      "updated_date": "2024-11-13 18:21:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:05:06.810867"
    },
    {
      "arxiv_id": "2411.08842v1",
      "title": "AstroM$^3$: A self-supervised multimodal model for astronomy",
      "title_zh": "翻译失败",
      "authors": [
        "Mariia Rizhko",
        "Joshua S. Bloom"
      ],
      "abstract": "While machine-learned models are now routinely employed to facilitate\nastronomical inquiry, model inputs tend to be limited to a primary data source\n(namely images or time series) and, in the more advanced approaches, some\nmetadata. Yet with the growing use of wide-field, multiplexed observational\nresources, individual sources of interest often have a broad range of\nobservational modes available. Here we construct an astronomical multimodal\ndataset and propose AstroM$^3$, a self-supervised pre-training approach that\nenables a model to learn from multiple modalities simultaneously. Specifically,\nwe extend the CLIP (Contrastive Language-Image Pretraining) model to a trimodal\nsetting, allowing the integration of time-series photometry data, spectra, and\nastrophysical metadata. In a fine-tuning supervised setting, our results\ndemonstrate that CLIP pre-training improves classification performance for\ntime-series photometry, where accuracy increases from 84.6% to 91.5%.\nFurthermore, CLIP boosts classification accuracy by up to 12.6% when the\navailability of labeled data is limited, showing the effectiveness of\nleveraging larger corpora of unlabeled data. In addition to fine-tuned\nclassification, we can use the trained model in other downstream tasks that are\nnot explicitly contemplated during the construction of the self-supervised\nmodel. In particular we show the efficacy of using the learned embeddings for\nmisclassifications identification, similarity search, and anomaly detection.\nOne surprising highlight is the \"rediscovery\" of Mira subtypes and two\nRotational variable subclasses using manifold learning and dimension reduction\nalgorithm. To our knowledge this is the first construction of an $n>2$ mode\nmodel in astronomy. Extensions to $n>3$ modes is naturally anticipated with\nthis approach.",
      "tldr_zh": "本研究提出 AstroM³，一个自监督的多模态模型，用于天文学领域，旨在整合时间序列光度数据、光谱和天文元数据，以充分利用多种观测模式。作者构建了一个天文多模态数据集，并扩展 CLIP（Contrastive Language-Image Pretraining）模型到三模态设置，实现多模态数据的联合学习。在微调监督任务中，AstroM³ 通过 CLIP 预训练将时间序列光度数据的分类准确率从 84.6% 提高到 91.5%，并在标注数据有限时提升高达 12.6%。此外，该模型支持下游任务如误分类识别、相似性搜索和异常检测，并意外“重新发现”了 Mira 子类型和两种旋转变量子类，这标志着天文学中首个 n>2 模态模型的创新。",
      "categories": [
        "astro-ph.IM",
        "cs.AI"
      ],
      "primary_category": "astro-ph.IM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08842v1",
      "published_date": "2024-11-13 18:20:29 UTC",
      "updated_date": "2024-11-13 18:20:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:05:19.123994"
    },
    {
      "arxiv_id": "2411.08832v2",
      "title": "Offline Adaptation of Quadruped Locomotion using Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Reece O'Mahoney",
        "Alexander L. Mitchell",
        "Wanming Yu",
        "Ingmar Posner",
        "Ioannis Havoutis"
      ],
      "abstract": "We present a diffusion-based approach to quadrupedal locomotion that\nsimultaneously addresses the limitations of learning and interpolating between\nmultiple skills and of (modes) offline adapting to new locomotion behaviours\nafter training. This is the first framework to apply classifier-free guided\ndiffusion to quadruped locomotion and demonstrate its efficacy by extracting\ngoal-conditioned behaviour from an originally unlabelled dataset. We show that\nthese capabilities are compatible with a multi-skill policy and can be applied\nwith little modification and minimal compute overhead, i.e., running entirely\non the robots onboard CPU. We verify the validity of our approach with hardware\nexperiments on the ANYmal quadruped platform.",
      "tldr_zh": "本研究提出了一种基于 diffusion models 的四足机器人运动方法，能够同时解决学习和插值多个技能的限制，以及训练后离线适应新行为的问题。该方法首次将 classifier-free guided diffusion 应用于 quadruped locomotion，从原始无标签数据集提取 goal-conditioned behaviour，并与多技能策略兼容，仅需微小修改和机器人 onboard CPU 的计算开销。硬件实验在 ANYmal 四足机器人平台上验证了该方法的有效性，展示了其在实际应用中的潜力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08832v2",
      "published_date": "2024-11-13 18:12:15 UTC",
      "updated_date": "2025-03-10 07:30:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:05:29.939806"
    },
    {
      "arxiv_id": "2411.08814v1",
      "title": "Process-aware Human Activity Recognition",
      "title_zh": "过程感知的人类活动识别",
      "authors": [
        "Jiawei Zheng",
        "Petros Papapanagiotou",
        "Jacques D. Fleuriot",
        "Jane Hillston"
      ],
      "abstract": "Humans naturally follow distinct patterns when conducting their daily\nactivities, which are driven by established practices and processes, such as\nproduction workflows, social norms and daily routines. Human activity\nrecognition (HAR) algorithms usually use neural networks or machine learning\ntechniques to analyse inherent relationships within the data. However, these\napproaches often overlook the contextual information in which the data are\ngenerated, potentially limiting their effectiveness. We propose a novel\napproach that incorporates process information from context to enhance the HAR\nperformance. Specifically, we align probabilistic events generated by machine\nlearning models with process models derived from contextual information. This\nalignment adaptively weighs these two sources of information to optimise HAR\naccuracy. Our experiments demonstrate that our approach achieves better\naccuracy and Macro F1-score compared to baseline models.",
      "tldr_zh": "人类日常活动通常遵循特定的模式，如生产流程、社会规范和日常习惯，但现有的 Human Activity Recognition (HAR) 算法往往忽略数据生成的环境上下文，导致性能受限。  \n本研究提出了一种新方法，通过将机器学习模型生成的概率事件与从上下文派生的过程模型对齐，并自适应权衡这两种信息来源，以优化 HAR 的准确性。  \n实验结果表明，该方法相较于基线模型显著提高了准确率和 Macro F1-score。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08814v1",
      "published_date": "2024-11-13 17:53:23 UTC",
      "updated_date": "2024-11-13 17:53:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:05:43.318708"
    },
    {
      "arxiv_id": "2411.08813v1",
      "title": "Rethinking CyberSecEval: An LLM-Aided Approach to Evaluation Critique",
      "title_zh": "翻译失败",
      "authors": [
        "Suhas Hariharan",
        "Zainab Ali Majid",
        "Jaime Raldua Veuthey",
        "Jacob Haimes"
      ],
      "abstract": "A key development in the cybersecurity evaluations space is the work carried\nout by Meta, through their CyberSecEval approach. While this work is\nundoubtedly a useful contribution to a nascent field, there are notable\nfeatures that limit its utility. Key drawbacks focus on the insecure code\ndetection part of Meta's methodology. We explore these limitations, and use our\nexploration as a test case for LLM-assisted benchmark analysis.",
      "tldr_zh": "这篇论文重新审视了Meta的CyberSecEval方法，指出其在网络安全评估中，尤其是不安全代码检测部分的显著局限性。作者采用LLM（Large Language Models）辅助的基准分析方法，作为测试案例来探索这些问题。该方法展示了LLM在提升评估批评效率方面的潜力，为未来网络安全基准设计提供了改进方向。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "NeurIPS 2024, 2 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.08813v1",
      "published_date": "2024-11-13 17:51:57 UTC",
      "updated_date": "2024-11-13 17:51:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:05:53.848565"
    },
    {
      "arxiv_id": "2411.08794v1",
      "title": "Evaluating World Models with LLM for Decision Making",
      "title_zh": "使用 LLM 评估世界模型以进行决策",
      "authors": [
        "Chang Yang",
        "Xinrun Wang",
        "Junzhe Jiang",
        "Qinggang Zhang",
        "Xiao Huang"
      ],
      "abstract": "World model emerges as a key module in decision making, where MuZero and\nDreamer achieve remarkable successes in complex tasks. Recent work leverages\nLarge Language Models (LLMs) as general world simulators to simulate the\ndynamics of the world due to their generalizability. LLMs also serve as the\nworld model for deliberative reasoning in Reasoning via Planning (RAP) and Tree\nof Thought (ToT). However, the world models are either evaluated as a general\nworld simulator, or as a functional module of the agent, i.e., predicting the\ntransitions to assist the planning. In this work, we propose a comprehensive\nevaluation of the world models with LLMs from the decision making perspective.\nSpecifically, we leverage the 31 diverse environments from (Wang et al.,\n2023;2024) and curate the rule-based policy of each environment for the diverse\nevaluation. Then, we design three main tasks, i.e., policy verification, action\nproposal, and policy planning, where the world models can be used for decision\nmaking solely. Finally, we conduct the comprehensive evaluation of the advanced\nLLMs, i.e., GPT-4o and GPT-4o-mini, on the environments for the three main\ntasks under various settings. The key observations include: i) GPT-4o\nsignificantly outperforms GPT-4o-mini on the three main tasks, especially for\nthe tasks which require the domain knowledge, ii) the performance of the world\nmodel with LLM will be decreased for long-term decision-making tasks, and iii)\nthe combination of different functionalities of the world model will brings\nadditional unstabilities of the performance.",
      "tldr_zh": "这篇论文评估了大型语言模型 (LLMs) 作为世界模型在决策中的性能，针对现有方法的局限性，提出从决策视角进行全面评估。研究者使用 31 个多样环境并设计了三个主要任务：政策验证 (policy verification)、行动提案 (action proposal) 和政策规划 (policy planning)，这些任务仅依赖世界模型进行决策。实验结果显示，GPT-4o 显著优于 GPT-4o-mini 尤其在需要领域知识的任务中，但 LLM 世界模型在长期决策任务上性能下降，且结合不同功能可能导致额外的不稳定性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08794v1",
      "published_date": "2024-11-13 17:19:32 UTC",
      "updated_date": "2024-11-13 17:19:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:06:07.191844"
    },
    {
      "arxiv_id": "2411.08790v1",
      "title": "Can sparse autoencoders be used to decompose and interpret steering vectors?",
      "title_zh": "翻译失败",
      "authors": [
        "Harry Mayne",
        "Yushi Yang",
        "Adam Mahdi"
      ],
      "abstract": "Steering vectors are a promising approach to control the behaviour of large\nlanguage models. However, their underlying mechanisms remain poorly understood.\nWhile sparse autoencoders (SAEs) may offer a potential method to interpret\nsteering vectors, recent findings show that SAE-reconstructed vectors often\nlack the steering properties of the original vectors. This paper investigates\nwhy directly applying SAEs to steering vectors yields misleading\ndecompositions, identifying two reasons: (1) steering vectors fall outside the\ninput distribution for which SAEs are designed, and (2) steering vectors can\nhave meaningful negative projections in feature directions, which SAEs are not\ndesigned to accommodate. These limitations hinder the direct use of SAEs for\ninterpreting steering vectors.",
      "tldr_zh": "本论文探讨了是否可以使用 sparse autoencoders (SAEs) 来分解和解释 steering vectors，以更好地理解大型语言模型的行为控制机制。研究发现，直接应用 SAEs 会导致误导性分解，主要原因包括：(1) steering vectors 超出 SAEs 设计的输入分布范围，以及(2) SAEs 无法处理 steering vectors 在特征方向上的有意义负投影。这些发现揭示了 SAEs 在此领域的局限性，并为改进解释方法提供了潜在方向。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08790v1",
      "published_date": "2024-11-13 17:16:48 UTC",
      "updated_date": "2024-11-13 17:16:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:06:18.649714"
    },
    {
      "arxiv_id": "2411.08785v1",
      "title": "Zero-shot Cross-lingual Transfer Learning with Multiple Source and Target Languages for Information Extraction: Language Selection and Adversarial Training",
      "title_zh": "翻译失败",
      "authors": [
        "Nghia Trung Ngo",
        "Thien Huu Nguyen"
      ],
      "abstract": "The majority of previous researches addressing multi-lingual IE are limited\nto zero-shot cross-lingual single-transfer (one-to-one) setting, with\nhigh-resource languages predominantly as source training data. As a result,\nthese works provide little understanding and benefit for the realistic goal of\ndeveloping a multi-lingual IE system that can generalize to as many languages\nas possible. Our study aims to fill this gap by providing a detailed analysis\non Cross-Lingual Multi-Transferability (many-to-many transfer learning), for\nthe recent IE corpora that cover a diverse set of languages. Specifically, we\nfirst determine the correlation between single-transfer performance and a wide\nrange of linguistic-based distances. From the obtained insights, a combined\nlanguage distance metric can be developed that is not only highly correlated\nbut also robust across different tasks and model scales. Next, we investigate\nthe more general zero-shot multi-lingual transfer settings where multiple\nlanguages are involved in the training and evaluation processes. Language\nclustering based on the newly defined distance can provide directions for\nachieving the optimal cost-performance trade-off in data (languages) selection\nproblem. Finally, a relational-transfer setting is proposed to further\nincorporate multi-lingual unlabeled data based on adversarial training using\nthe relation induced from the above linguistic distance.",
      "tldr_zh": "本研究探讨了零-shot cross-lingual transfer learning在信息提取（Information Extraction）中的应用，针对多源和多目标语言的Cross-Lingual Multi-Transferability（多对多转移学习）进行详细分析，以解决现有方法对更多语言泛化能力不足的问题。首先，通过分析single-transfer性能与多种语言距离的相关性，开发了一个鲁棒的组合语言距离指标，该指标适用于不同任务和模型规模。其次，基于这一距离进行语言聚类，帮助优化语言选择，实现数据选择的成本-性能权衡。最后，提出relational-transfer设置，利用adversarial training整合多语言无标签数据，进一步提升多语言IE系统的泛化性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08785v1",
      "published_date": "2024-11-13 17:13:25 UTC",
      "updated_date": "2024-11-13 17:13:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:06:30.905870"
    },
    {
      "arxiv_id": "2411.08768v1",
      "title": "Sharingan: Extract User Action Sequence from Desktop Recordings",
      "title_zh": "Sharingan：从桌面记录中提取用户动作序列",
      "authors": [
        "Yanting Chen",
        "Yi Ren",
        "Xiaoting Qin",
        "Jue Zhang",
        "Kehong Yuan",
        "Lu Han",
        "Qingwei Lin",
        "Dongmei Zhang",
        "Saravan Rajmohan",
        "Qi Zhang"
      ],
      "abstract": "Video recordings of user activities, particularly desktop recordings, offer a\nrich source of data for understanding user behaviors and automating processes.\nHowever, despite advancements in Vision-Language Models (VLMs) and their\nincreasing use in video analysis, extracting user actions from desktop\nrecordings remains an underexplored area. This paper addresses this gap by\nproposing two novel VLM-based methods for user action extraction: the Direct\nFrame-Based Approach (DF), which inputs sampled frames directly into VLMs, and\nthe Differential Frame-Based Approach (DiffF), which incorporates explicit\nframe differences detected via computer vision techniques. We evaluate these\nmethods using a basic self-curated dataset and an advanced benchmark adapted\nfrom prior work. Our results show that the DF approach achieves an accuracy of\n70% to 80% in identifying user actions, with the extracted action sequences\nbeing re-playable though Robotic Process Automation. We find that while VLMs\nshow potential, incorporating explicit UI changes can degrade performance,\nmaking the DF approach more reliable. This work represents the first\napplication of VLMs for extracting user action sequences from desktop\nrecordings, contributing new methods, benchmarks, and insights for future\nresearch.",
      "tldr_zh": "本研究提出Sharingan框架，利用Vision-Language Models (VLMs)从桌面录像中提取用户动作序列，填补了这一领域的空白。框架包括两种方法：Direct Frame-Based Approach (DF)，直接输入采样帧到VLMs进行分析；以及Differential Frame-Based Approach (DiffF)，结合计算机视觉技术检测帧差异。实验结果显示，DF方法在识别用户动作时准确率达70%至80%，提取的序列可用于Robotic Process Automation (RPA)，而加入显式UI变化可能降低性能，使DF更可靠。该工作首次将VLMs应用于桌面录像动作提取，提供新方法、基准和未来研究见解。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08768v1",
      "published_date": "2024-11-13 16:53:29 UTC",
      "updated_date": "2024-11-13 16:53:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:06:41.949901"
    },
    {
      "arxiv_id": "2411.08767v2",
      "title": "SANDWICH: Towards an Offline, Differentiable, Fully-Trainable Wireless Neural Ray-Tracing Surrogate",
      "title_zh": "翻译失败",
      "authors": [
        "Yifei Jin",
        "Ali Maatouk",
        "Sarunas Girdzijauskas",
        "Shugong Xu",
        "Leandros Tassiulas",
        "Rex Ying"
      ],
      "abstract": "Wireless ray-tracing (RT) is emerging as a key tool for three-dimensional\n(3D) wireless channel modeling, driven by advances in graphical rendering.\nCurrent approaches struggle to accurately model beyond 5G (B5G) network\nsignaling, which often operates at higher frequencies and is more susceptible\nto environmental conditions and changes. Existing online learning solutions\nrequire real-time environmental supervision during training, which is both\ncostly and incompatible with GPU-based processing. In response, we propose a\nnovel approach that redefines ray trajectory generation as a sequential\ndecision-making problem, leveraging generative models to jointly learn the\noptical, physical, and signal properties within each designated environment.\nOur work introduces the Scene-Aware Neural Decision Wireless Channel Raytracing\nHierarchy (SANDWICH), an innovative offline, fully differentiable approach that\ncan be trained entirely on GPUs. SANDWICH offers superior performance compared\nto existing online learning methods, outperforms the baseline by 4e^-2 radian\nin RT accuracy, and only fades 0.5 dB away from toplined channel gain\nestimation.",
      "tldr_zh": "该论文针对无线射线追踪(RT) 在B5G网络建模中的准确性问题，提出了一种创新框架SANDWICH，将射线轨迹生成视为顺序决策问题，并利用生成模型联合学习光学、物理和信号属性。SANDWICH采用离线、全微分和完全可训练的离线方法，可在GPU上进行训练，从而避免了现有在线学习方案的实时环境监督需求。实验结果显示，SANDWICH比基线方法在RT准确性上提高了4e^-2弧度，并在通道增益估计上仅比顶级方法低0.5 dB，提供了一种高效的无线通道建模解决方案。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "Accepted in ICMLCN 2025",
      "pdf_url": "http://arxiv.org/pdf/2411.08767v2",
      "published_date": "2024-11-13 16:53:14 UTC",
      "updated_date": "2025-02-20 21:46:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:06:55.013026"
    },
    {
      "arxiv_id": "2411.08764v1",
      "title": "Flow reconstruction in time-varying geometries using graph neural networks",
      "title_zh": "翻译失败",
      "authors": [
        "Bogdan A. Danciu",
        "Vito A. Pagone",
        "Benjamin Böhm",
        "Marius Schmidt",
        "Christos E. Frouzakis"
      ],
      "abstract": "The paper presents a Graph Attention Convolutional Network (GACN) for flow\nreconstruction from very sparse data in time-varying geometries. The model\nincorporates a feature propagation algorithm as a preprocessing step to handle\nextremely sparse inputs, leveraging information from neighboring nodes to\ninitialize missing features. In addition, a binary indicator is introduced as a\nvalidity mask to distinguish between the original and propagated data points,\nenabling more effective learning from sparse inputs. Trained on a unique data\nset of Direct Numerical Simulations (DNS) of a motored engine at a technically\nrelevant operating condition, the GACN shows robust performance across\ndifferent resolutions and domain sizes and can effectively handle unstructured\ndata and variable input sizes. The model is tested on previously unseen DNS\ndata as well as on an experimental data set from Particle Image Velocimetry\n(PIV) measurements that were not considered during training. A comparative\nanalysis shows that the GACN consistently outperforms both a conventional\nConvolutional Neural Network (CNN) and cubic interpolation methods on the DNS\nand PIV test sets by achieving lower reconstruction errors and better capturing\nfine-scale turbulent structures. In particular, the GACN effectively\nreconstructs flow fields from domains up to 14 times larger than those observed\nduring training, with the performance advantage increasing for larger domains.",
      "tldr_zh": "本文提出了一种 Graph Attention Convolutional Network (GACN) 用于在时间变化几何中从极度稀疏数据重建流动，结合特征传播算法和二进制有效性掩码来初始化缺失特征并提升学习效率。GACN 在 Direct Numerical Simulations (DNS) 数据集上训练，展现出在不同分辨率和域大小上的稳健性能，并能处理非结构化数据。相比传统 Convolutional Neural Network (CNN) 和立方插值方法，GACN 在 DNS 和 Particle Image Velocimetry (PIV) 测试集上实现了更低的重建错误和更精确的细尺度湍流结构捕捉，尤其能重建训练域大14倍的流动场。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.flu-dyn"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08764v1",
      "published_date": "2024-11-13 16:49:56 UTC",
      "updated_date": "2024-11-13 16:49:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:07:07.729083"
    },
    {
      "arxiv_id": "2411.08745v3",
      "title": "Separating Tongue from Thought: Activation Patching Reveals Language-Agnostic Concept Representations in Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Clément Dumas",
        "Chris Wendler",
        "Veniamin Veselovsky",
        "Giovanni Monea",
        "Robert West"
      ],
      "abstract": "A central question in multilingual language modeling is whether large\nlanguage models (LLMs) develop a universal concept representation, disentangled\nfrom specific languages. In this paper, we address this question by analyzing\nlatent representations (latents) during a word translation task in\ntransformer-based LLMs. We strategically extract latents from a source\ntranslation prompt and insert them into the forward pass on a target\ntranslation prompt. By doing so, we find that the output language is encoded in\nthe latent at an earlier layer than the concept to be translated. Building on\nthis insight, we conduct two key experiments. First, we demonstrate that we can\nchange the concept without changing the language and vice versa through\nactivation patching alone. Second, we show that patching with the mean over\nlatents across different languages does not impair and instead improves the\nmodels' performance in translating the concept. Our results provide evidence\nfor the existence of language-agnostic concept representations within the\ninvestigated models.",
      "tldr_zh": "本文研究大型语言模型（LLMs）是否开发了与特定语言分离的通用概念表示，通过激活 patching 技术分析 Transformer 模型中的潜在表示（latents）。研究发现，在单词翻译任务中，输出语言在较早层编码，而概念在较晚层编码，从而允许通过激活 patching 单独改变概念或语言。实验进一步显示，使用不同语言 latents 的均值进行 patching，不仅不影响性能，反而提升了模型的翻译准确性，为 Transformers 中存在 language-agnostic concept representations 提供了有力证据。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages, 14 figures, previous version published under the title \"How\n  Do Llamas Process Multilingual Text? A Latent Exploration through Activation\n  Patching\" at the ICML 2024 mechanistic interpretability workshop at\n  https://openreview.net/forum?id=0ku2hIm4BS",
      "pdf_url": "http://arxiv.org/pdf/2411.08745v3",
      "published_date": "2024-11-13 16:26:19 UTC",
      "updated_date": "2025-01-09 21:53:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:07:18.812144"
    },
    {
      "arxiv_id": "2411.08728v1",
      "title": "Polymetis:Large Language Modeling for Multiple Material Domains",
      "title_zh": "翻译失败",
      "authors": [
        "Chao Huang",
        "Huichen Xiao",
        "Chen Chen",
        "Chunyan Chen",
        "Yi Zhao",
        "Shiyu Du",
        "Yiming Zhang",
        "He Sha",
        "Ruixin Gu"
      ],
      "abstract": "As the application of large language models in various fields continues to\nexpand, materials science also ushers in opportunities for AI-driven\ninnovation. The traditional way of relying on manual search for materials\nscience-related information is now using artificial intelligence technology as\nan auxiliary tool to improve the efficiency of materials science research. To\naccelerate researchers' knowledge acquisition and intelligent decision-making\nsupport in materials science research, this paper proposes a large language\nmodel Polymetis model for a variety of materials fields, aiming to provide\nhighly professional knowledge answers in the field of materials, covering\nenergy materials, functional materials, alloy materials, physical chemistry,\nbiology, and other material directions. The model uses a dataset of about 2\nmillion material knowledge instructions, and in the process of building the\ndataset, we developed the Intelligent Extraction Large Model (IELM), which is\nspecially used to extract and form structured knowledge from scientific texts,\navoiding a large number of costs that need to be manually annotated, and\nimproving efficiency. We inject this data into the GLM4-9B model for learning\nto enhance its inference capabilities in a variety of material domains. In\naddition, we have introduced enhanced prompt strategies to ensure that the\nanswers to the model are more organized and comprehensive, providing efficient\nand comprehensive intelligent support for the diverse needs of materials\nscience exploration, and promoting the development of material science.",
      "tldr_zh": "本研究提出Polymetis模型，这是一个针对多种材料领域的Large Language Model，旨在加速材料科学研究的知识获取和智能决策支持，覆盖能量材料、功能材料、合金材料、物理化学和生物等领域。研究团队构建了约200万条材料知识指令数据集，并开发了Intelligent Extraction Large Model (IELM)来从科学文本中自动提取和结构化知识，从而减少手动标注成本并提高效率。将该数据集注入GLM4-9B模型进行训练，并引入增强提示策略，以提升模型在材料领域的推理能力和答案的组织性。总体上，Polymetis为材料科学探索提供高效、全面的智能支持，促进该领域的创新发展。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08728v1",
      "published_date": "2024-11-13 16:10:14 UTC",
      "updated_date": "2024-11-13 16:10:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:07:30.146158"
    },
    {
      "arxiv_id": "2411.08706v1",
      "title": "Searching Latent Program Spaces",
      "title_zh": "搜索潜在程序空间",
      "authors": [
        "Clément Bonnet",
        "Matthew V Macfarlane"
      ],
      "abstract": "Program synthesis methods aim to automatically generate programs restricted\nto a language that can explain a given specification of input-output pairs.\nWhile purely symbolic approaches suffer from a combinatorial search space,\nrecent methods leverage neural networks to learn distributions over program\nstructures to narrow this search space significantly, enabling more efficient\nsearch. However, for challenging problems, it remains difficult to train models\nto perform program synthesis in one shot, making test-time search essential.\nMost neural methods lack structured search mechanisms during inference, relying\ninstead on stochastic sampling or gradient updates, which can be inefficient.\nIn this work, we propose the Latent Program Network (LPN), a general algorithm\nfor program induction that learns a distribution over latent programs in a\ncontinuous space, enabling efficient search and test-time adaptation. We\nexplore how to train these networks to optimize for test-time computation and\ndemonstrate the use of gradient-based search both during training and at test\ntime. We evaluate LPN on ARC-AGI, a program synthesis benchmark that evaluates\nperformance by generalizing programs to new inputs rather than explaining the\nunderlying specification. We show that LPN can generalize beyond its training\ndistribution and adapt to unseen tasks by utilizing test-time computation,\noutperforming algorithms without test-time adaptation mechanisms.",
      "tldr_zh": "这篇论文针对程序合成（Program Synthesis）中的组合搜索空间问题，提出了一种通用的算法——Latent Program Network (LPN)，它在连续空间中学习潜在程序的分布，以实现高效搜索和测试时适应。LPN 通过梯度-based search 机制优化训练过程，并允许在测试时进行计算调整，从而解决神经方法依赖随机采样或梯度更新的效率不足。实验结果显示，在 ARC-AGI 基准上，LPN 能够超越训练分布进行泛化，并在新输入和未见任务上表现出色，优于缺乏测试时适应机制的算法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Code available at https://github.com/clement-bonnet/lpn",
      "pdf_url": "http://arxiv.org/pdf/2411.08706v1",
      "published_date": "2024-11-13 15:50:32 UTC",
      "updated_date": "2024-11-13 15:50:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:07:43.169694"
    },
    {
      "arxiv_id": "2411.08703v1",
      "title": "MVKTrans: Multi-View Knowledge Transfer for Robust Multiomics Classification",
      "title_zh": "MVKTrans：多视图知识转移用于鲁棒的多组学分类",
      "authors": [
        "Shan Cong",
        "Zhiling Sang",
        "Hongwei Liu",
        "Haoran Luo",
        "Xin Wang",
        "Hong Liang",
        "Jie Hao",
        "Xiaohui Yao"
      ],
      "abstract": "The distinct characteristics of multiomics data, including complex\ninteractions within and across biological layers and disease heterogeneity\n(e.g., heterogeneity in etiology and clinical symptoms), drive us to develop\nnovel designs to address unique challenges in multiomics prediction. In this\npaper, we propose the multi-view knowledge transfer learning (MVKTrans)\nframework, which transfers intra- and inter-omics knowledge in an adaptive\nmanner by reviewing data heterogeneity and suppressing bias transfer, thereby\nenhancing classification performance. Specifically, we design a graph\ncontrastive module that is trained on unlabeled data to effectively learn and\ntransfer the underlying intra-omics patterns to the supervised task. This\nunsupervised pretraining promotes learning general and unbiased representations\nfor each modality, regardless of the downstream tasks. In light of the varying\ndiscriminative capacities of modalities across different diseases and/or\nsamples, we introduce an adaptive and bi-directional cross-omics distillation\nmodule. This module automatically identifies richer modalities and facilitates\ndynamic knowledge transfer from more informative to less informative omics,\nthereby enabling a more robust and generalized integration. Extensive\nexperiments on four real biomedical datasets demonstrate the superior\nperformance and robustness of MVKTrans compared to the state-of-the-art. Code\nand data are available at https://github.com/Yaolab-fantastic/MVKTrans.",
      "tldr_zh": "本研究提出 MVKTrans 框架，即多视图知识转移学习，用于处理多组学数据的复杂交互和异质性，从而提升分类性能。该框架包括一个图对比模块（graph contrastive module），通过无监督预训练学习和转移内部组学模式，生成通用的无偏表示；此外，还引入自适应双向跨组学蒸馏模块（adaptive and bi-directional cross-omics distillation module），动态识别并从更丰富的组学模态向较弱模态转移知识，以实现更稳健的集成。在四个真实生物医学数据集上的广泛实验表明，MVKTrans 比现有最先进方法表现出色，并提供开源代码和数据以支持进一步研究。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08703v1",
      "published_date": "2024-11-13 15:45:46 UTC",
      "updated_date": "2024-11-13 15:45:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:07:53.575798"
    },
    {
      "arxiv_id": "2411.08701v1",
      "title": "TRACE: Transformer-based Risk Assessment for Clinical Evaluation",
      "title_zh": "TRACE：基于Transformer的临床风险评估",
      "authors": [
        "Dionysis Christopoulos",
        "Sotiris Spanos",
        "Valsamis Ntouskos",
        "Konstantinos Karantzalos"
      ],
      "abstract": "We present TRACE (Transformer-based Risk Assessment for Clinical Evaluation),\na novel method for clinical risk assessment based on clinical data, leveraging\nthe self-attention mechanism for enhanced feature interaction and result\ninterpretation. Our approach is able to handle different data modalities,\nincluding continuous, categorical and multiple-choice (checkbox) attributes.\nThe proposed architecture features a shared representation of the clinical data\nobtained by integrating specialized embeddings of each data modality, enabling\nthe detection of high-risk individuals using Transformer encoder layers. To\nassess the effectiveness of the proposed method, a strong baseline based on\nnon-negative multi-layer perceptrons (MLPs) is introduced. The proposed method\noutperforms various baselines widely used in the domain of clinical risk\nassessment, while effectively handling missing values. In terms of\nexplainability, our Transformer-based method offers easily interpretable\nresults via attention weights, further enhancing the clinicians'\ndecision-making process.",
      "tldr_zh": "本研究提出TRACE，一种基于Transformer的自注意力机制的临床风险评估方法，用于处理临床数据的风险预测。该方法支持多种数据模态，包括连续、分类和多选属性，通过整合专用嵌入形成共享表示，并利用Transformer编码器层检测高风险个体。与基于非负多层感知器（MLPs）的基线相比，TRACE在性能上优于现有方法，并能有效处理缺失值。在可解释性方面，该框架通过注意力权重提供易解读的结果，提升临床决策过程。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08701v1",
      "published_date": "2024-11-13 15:42:28 UTC",
      "updated_date": "2024-11-13 15:42:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:08:05.523332"
    },
    {
      "arxiv_id": "2411.08700v1",
      "title": "Rethinking negative sampling in content-based news recommendation",
      "title_zh": "重新思考基于内容的新闻推荐中的负采样",
      "authors": [
        "Miguel Ângelo Rebelo",
        "João Vinagre",
        "Ivo Pereira",
        "Álvaro Figueira"
      ],
      "abstract": "News recommender systems are hindered by the brief lifespan of articles, as\nthey undergo rapid relevance decay. Recent studies have demonstrated the\npotential of content-based neural techniques in tackling this problem. However,\nthese models often involve complex neural architectures and often lack\nconsideration for negative examples. In this study, we posit that the careful\nsampling of negative examples has a big impact on the model's outcome. We\ndevise a negative sampling technique that not only improves the accuracy of the\nmodel but also facilitates the decentralization of the recommendation system.\nThe experimental results obtained using the MIND dataset demonstrate that the\naccuracy of the method under consideration can compete with that of\nState-of-the-Art models. The utilization of the sampling technique is essential\nin reducing model complexity and accelerating the training process, while\nmaintaining a high level of accuracy. Finally, we discuss how decentralized\nmodels can help improve privacy and scalability.",
      "tldr_zh": "本文重新审视了内容-based 新闻推荐中的 negative sampling 问题，认为仔细选择负面样本能显著提升模型性能。研究提出了一种新的 negative sampling 技术，不仅提高了准确性，还促进了推荐系统的去中心化，从而减少模型复杂性和加速训练过程。在 MIND 数据集的实验中，该方法准确性可与 State-of-the-Art 模型竞争，并通过去中心化改善了隐私和可扩展性。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08700v1",
      "published_date": "2024-11-13 15:42:13 UTC",
      "updated_date": "2024-11-13 15:42:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:08:18.474804"
    },
    {
      "arxiv_id": "2411.08696v1",
      "title": "Scholarly Wikidata: Population and Exploration of Conference Data in Wikidata using LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Nandana Mihindukulasooriya",
        "Sanju Tiwari",
        "Daniil Dobriy",
        "Finn Årup Nielsen",
        "Tek Raj Chhetri",
        "Axel Polleres"
      ],
      "abstract": "Several initiatives have been undertaken to conceptually model the domain of\nscholarly data using ontologies and to create respective Knowledge Graphs. Yet,\nthe full potential seems unleashed, as automated means for automatic population\nof said ontologies are lacking, and respective initiatives from the Semantic\nWeb community are not necessarily connected: we propose to make scholarly data\nmore sustainably accessible by leveraging Wikidata's infrastructure and\nautomating its population in a sustainable manner through LLMs by tapping into\nunstructured sources like conference Web sites and proceedings texts as well as\nalready existing structured conference datasets. While an initial analysis\nshows that Semantic Web conferences are only minimally represented in Wikidata,\nwe argue that our methodology can help to populate, evolve and maintain\nscholarly data as a community within Wikidata. Our main contributions include\n(a) an analysis of ontologies for representing scholarly data to identify gaps\nand relevant entities/properties in Wikidata, (b) semi-automated extraction --\nrequiring (minimal) manual validation -- of conference metadata (e.g.,\nacceptance rates, organizer roles, programme committee members, best paper\nawards, keynotes, and sponsors) from websites and proceedings texts using LLMs.\nFinally, we discuss (c) extensions to visualization tools in the Wikidata\ncontext for data exploration of the generated scholarly data. Our study focuses\non data from 105 Semantic Web-related conferences and extends/adds more than\n6000 entities in Wikidata. It is important to note that the method can be more\ngenerally applicable beyond Semantic Web-related conferences for enhancing\nWikidata's utility as a comprehensive scholarly resource.\n  Source Repository: https://github.com/scholarly-wikidata/\n  DOI: https://doi.org/10.5281/zenodo.10989709\n  License: Creative Commons CC0 (Data), MIT (Code)",
      "tldr_zh": "该论文提出利用大型语言模型（LLMs）自动填充和探索 Wikidata 中的会议数据，以解决学术数据本体和知识图谱（Knowledge Graphs）填充不足的问题。研究通过分析现有本体，识别 Wikidata 的空白，并从非结构化来源（如会议网站和论文文本）半自动化提取元数据，包括接受率、组织者角色和程序委员会成员等，需最小手动验证。最终，在 105 个语义网相关会议上添加了超过 6000 个实体，并扩展了 Wikidata 的可视化工具，支持数据探索，该方法可推广到更广泛的学术资源领域。",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.DL",
      "comment": "17 pages, accepted at EKAW-24",
      "pdf_url": "http://arxiv.org/pdf/2411.08696v1",
      "published_date": "2024-11-13 15:34:52 UTC",
      "updated_date": "2024-11-13 15:34:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:08:31.432907"
    },
    {
      "arxiv_id": "2411.08684v1",
      "title": "Analogical Reasoning Within a Conceptual Hyperspace",
      "title_zh": "在概念超空间中的类比",
      "authors": [
        "Howard Goldowsky",
        "Vasanth Sarathy"
      ],
      "abstract": "We propose an approach to analogical inference that marries the\nneuro-symbolic computational power of complex-sampled hyperdimensional\ncomputing (HDC) with Conceptual Spaces Theory (CST), a promising theory of\nsemantic meaning. CST sketches, at an abstract level, approaches to analogical\ninference that go beyond the standard predicate-based structure mapping\ntheories. But it does not describe how such an approach can be operationalized.\nWe propose a concrete HDC-based architecture that computes several types of\nanalogy classified by CST. We present preliminary proof-of-concept experimental\nresults within a toy domain and describe how it can perform category-based and\nproperty-based analogical reasoning.",
      "tldr_zh": "这篇论文提出了一种将复杂采样超维度计算(HDC)与概念空间理论(CST)相结合的方法，用于类比推理，超越了标准的谓词结构映射理论。作者设计了一个基于 HDC 的具体架构，能够计算 CST 分类的多种类比类型，并在玩具领域进行初步概念验证实验。实验结果展示了该框架在进行 category-based 和 property-based  analogical reasoning 方面的潜力，为语义意义建模提供了新途径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Analogy-angle workshop full paper at IJCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.08684v1",
      "published_date": "2024-11-13 15:20:14 UTC",
      "updated_date": "2024-11-13 15:20:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:08:42.022276"
    },
    {
      "arxiv_id": "2411.08666v2",
      "title": "A Survey on Vision Autoregressive Model",
      "title_zh": "视觉自回归模型的综述",
      "authors": [
        "Kai Jiang",
        "Jiaxing Huang"
      ],
      "abstract": "Autoregressive models have demonstrated great performance in natural language\nprocessing (NLP) with impressive scalability, adaptability and\ngeneralizability. Inspired by their notable success in NLP field,\nautoregressive models have been intensively investigated recently for computer\nvision, which perform next-token predictions by representing visual data as\nvisual tokens and enables autoregressive modelling for a wide range of vision\ntasks, ranging from visual generation and visual understanding to the very\nrecent multimodal generation that unifies visual generation and understanding\nwith a single autoregressive model. This paper provides a systematic review of\nvision autoregressive models, including the development of a taxonomy of\nexisting methods and highlighting their major contributions, strengths, and\nlimitations, covering various vision tasks such as image generation, video\ngeneration, image editing, motion generation, medical image analysis, 3D\ngeneration, robotic manipulation, unified multimodal generation, etc. Besides,\nwe investigate and analyze the latest advancements in autoregressive models,\nincluding thorough benchmarking and discussion of existing methods across\nvarious evaluation datasets. Finally, we outline key challenges and promising\ndirections for future research, offering a roadmap to guide further\nadvancements in vision autoregressive models.",
      "tldr_zh": "这篇论文对视觉自回归模型进行了系统调查，强调这些模型受NLP（Natural Language Processing）领域成功启发，将视觉数据表示为visual tokens，实现从图像生成到多模态生成的各种任务，包括图像生成、视频生成、图像编辑和统一multimodal generation等。论文构建了一个现有方法的分类框架，分析了它们的贡献、优势（如可扩展性和泛化性）和局限性，并通过基准测试评估了最新进展。最终，它指出了关键挑战，如模型的适应性和效率问题，并为未来研究提供了路线图。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "This work will be integrated into another project",
      "pdf_url": "http://arxiv.org/pdf/2411.08666v2",
      "published_date": "2024-11-13 14:59:41 UTC",
      "updated_date": "2024-11-16 11:17:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:08:54.331987"
    },
    {
      "arxiv_id": "2411.17708v1",
      "title": "Towards Efficient Neurally-Guided Program Induction for ARC-AGI",
      "title_zh": "翻译失败",
      "authors": [
        "Simon Ouellette"
      ],
      "abstract": "ARC-AGI is an open-world problem domain in which the ability to generalize\nout-of-distribution is a crucial quality. Under the program induction paradigm,\nwe present a series of experiments that reveal the efficiency and\ngeneralization characteristics of various neurally-guided program induction\napproaches. The three paradigms we consider are Learning the grid space,\nLearning the program space, and Learning the transform space. We implement and\nexperiment thoroughly on the first two, and retain the second one for ARC-AGI\nsubmission. After identifying the strengths and weaknesses of both of these\napproaches, we suggest the third as a potential solution, and run preliminary\nexperiments.",
      "tldr_zh": "本研究针对 ARC-AGI 的开放世界问题，探索高效的神经引导程序归纳（program induction），以提升 out-of-distribution generalization 能力。论文通过实验比较三种范式：Learning the grid space、Learning the program space 和 Learning the transform space，实现了前两种并选择后者用于 ARC-AGI 提交。结果显示，Learning the grid space 和 Learning the program space 各有优势和劣势，前者更适合某些场景，而后者在泛化方面表现突出。作者建议 Learning the transform space 作为潜在解决方案，并进行了初步实验，以推动更高效的程序归纳方法。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17708v1",
      "published_date": "2024-11-13 14:44:03 UTC",
      "updated_date": "2024-11-13 14:44:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:09:07.166481"
    },
    {
      "arxiv_id": "2411.08651v1",
      "title": "Estimating unknown parameters in differential equations with a reinforcement learning based PSO method",
      "title_zh": "使用基于强化学习的 PSO 方法估计微分方程中的未知参数",
      "authors": [
        "Wenkui Sun",
        "Xiaoya Fan",
        "Lijuan Jia",
        "Tinyi Chu",
        "Shing-Tung Yau",
        "Rongling Wu",
        "Zhong Wang"
      ],
      "abstract": "Differential equations offer a foundational yet powerful framework for\nmodeling interactions within complex dynamic systems and are widely applied\nacross numerous scientific fields. One common challenge in this area is\nestimating the unknown parameters of these dynamic relationships. However,\ntraditional numerical optimization methods rely on the selection of initial\nparameter values, making them prone to local optima. Meanwhile, deep learning\nand Bayesian methods require training models on specific differential\nequations, resulting in poor versatility. This paper reformulates the parameter\nestimation problem of differential equations as an optimization problem by\nintroducing the concept of particles from the particle swarm optimization\nalgorithm. Building on reinforcement learning-based particle swarm optimization\n(RLLPSO), this paper proposes a novel method, DERLPSO, for estimating unknown\nparameters of differential equations. We compared its performance on three\ntypical ordinary differential equations with the state-of-the-art methods,\nincluding the RLLPSO algorithm, traditional numerical methods, deep learning\napproaches, and Bayesian methods. The experimental results demonstrate that our\nDERLPSO consistently outperforms other methods in terms of performance,\nachieving an average Mean Square Error of 1.13e-05, which reduces the error by\napproximately 4 orders of magnitude compared to other methods. Apart from\nordinary differential equations, our DERLPSO also show great promise for\nestimating unknown parameters of partial differential equations. The DERLPSO\nmethod proposed in this paper has high accuracy, is independent of initial\nparameter values, and possesses strong versatility and stability. This work\nprovides new insights into unknown parameter estimation for differential\nequations.",
      "tldr_zh": "本文提出了一种基于强化学习的粒子群优化方法DERLPSO，用于估计微分方程的未知参数，从而解决传统数值方法易陷局部最优和深度学习方法通用性差的问题。该方法将参数估计问题转化为优化问题，并通过实验在三个典型ordinary differential equations上与RLLPSO、传统方法、deep learning和Bayesian方法比较，实现了平均Mean Square Error仅为1.13e-05，比其他方法降低了约4个数量级。DERLPSO具有高准确性、独立于初始参数值以及强通用性和稳定性，并显示出在partial differential equations上的潜力，为微分方程未知参数估计提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08651v1",
      "published_date": "2024-11-13 14:40:51 UTC",
      "updated_date": "2024-11-13 14:40:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:09:19.729504"
    },
    {
      "arxiv_id": "2411.08645v1",
      "title": "A System Level Performance Evaluation for Superconducting Digital Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Joyjit Kundu",
        "Debjyoti Bhattacharjee",
        "Nathan Josephsen",
        "Ankit Pokhrel",
        "Udara De Silva",
        "Wenzhe Guo",
        "Steven Van Winckel",
        "Steven Brebels",
        "Manu Perumkunnil",
        "Quentin Herr",
        "Anna Herr"
      ],
      "abstract": "Superconducting Digital (SCD) technology offers significant potential for\nenhancing the performance of next generation large scale compute workloads. By\nleveraging advanced lithography and a 300 mm platform, SCD devices can reduce\nenergy consumption and boost computational power. This paper presents a\ncross-layer modeling approach to evaluate the system-level performance benefits\nof SCD architectures for Large Language Model (LLM) training and inference. Our\nfindings, based on experimental data and Pulse Conserving Logic (PCL) design\nprinciples, demonstrate substantial performance gain in both training and\ninference. We are, thus, able to convincingly show that the SCD technology can\naddress memory and interconnect limitations of present day solutions for\nnext-generation compute systems.",
      "tldr_zh": "本论文评估了Superconducting Digital (SCD) 技术在下一代大规模计算工作负载中的性能潜力，通过先进光刻和300 mm平台实现能源消耗降低和计算能力提升。研究采用跨层建模方法，结合实验数据和Pulse Conserving Logic (PCL) 设计原则，评估SCD架构在Large Language Model (LLM) 训练和推理中的系统级益处。结果显示，SCD技术显著提高了训练和推理性能，并有效解决了当前解决方案的内存和互连限制，为下一代计算系统提供了可行路径。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.AR",
      "comment": "8 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.08645v1",
      "published_date": "2024-11-13 14:36:12 UTC",
      "updated_date": "2024-11-13 14:36:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:09:29.850948"
    },
    {
      "arxiv_id": "2411.08642v1",
      "title": "Towards More Accurate Fake Detection on Images Generated from Advanced Generative and Neural Rendering Models",
      "title_zh": "翻译失败",
      "authors": [
        "Chengdong Dong",
        "Vijayakumar Bhagavatula",
        "Zhenyu Zhou",
        "Ajay Kumar"
      ],
      "abstract": "The remarkable progress in neural-network-driven visual data generation,\nespecially with neural rendering techniques like Neural Radiance Fields and 3D\nGaussian splatting, offers a powerful alternative to GANs and diffusion models.\nThese methods can produce high-fidelity images and lifelike avatars,\nhighlighting the need for robust detection methods. In response, an\nunsupervised training technique is proposed that enables the model to extract\ncomprehensive features from the Fourier spectrum magnitude, thereby overcoming\nthe challenges of reconstructing the spectrum due to its centrosymmetric\nproperties. By leveraging the spectral domain and dynamically combining it with\nspatial domain information, we create a robust multimodal detector that\ndemonstrates superior generalization capabilities in identifying challenging\nsynthetic images generated by the latest image synthesis techniques. To address\nthe absence of a 3D neural rendering-based fake image database, we develop a\ncomprehensive database that includes images generated by diverse neural\nrendering techniques, providing a robust foundation for evaluating and\nadvancing detection methods.",
      "tldr_zh": "该研究针对神经渲染技术（如Neural Radiance Fields和3D Gaussian splatting）生成的高保真图像，提出了一种更准确的假图像检测方法，以应对GANs和扩散模型的挑战。论文引入无监督训练技术，从Fourier spectrum magnitude提取全面特征，并结合光谱域和空间域信息，构建了一个鲁棒的多模态检测器，提升了在识别最新合成图像时的泛化能力。为解决缺乏相关数据库的问题，研究团队开发了一个包含多种神经渲染技术生成图像的综合数据库，作为评估和改进检测方法的坚实基础。实验结果显示，该检测器在处理复杂合成图像时表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages, 8 Figures",
      "pdf_url": "http://arxiv.org/pdf/2411.08642v1",
      "published_date": "2024-11-13 14:32:28 UTC",
      "updated_date": "2024-11-13 14:32:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:09:42.738292"
    },
    {
      "arxiv_id": "2411.08641v1",
      "title": "DipMe: Haptic Recognition of Granular Media for Tangible Interactive Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Xinkai Wang",
        "Shuo Zhang",
        "Ziyi Zhao",
        "Lifeng Zhu",
        "Aiguo Song"
      ],
      "abstract": "While tangible user interface has shown its power in naturally interacting\nwith rigid or soft objects, users cannot conveniently use different types of\ngranular materials as the interaction media. We introduce DipMe as a smart\ndevice to recognize the types of granular media in real time, which can be used\nto connect the granular materials in the physical world with various virtual\ncontent. Other than vision-based solutions, we propose a dip operation of our\ndevice and exploit the haptic signals to recognize different types of granular\nmaterials. With modern machine learning tools, we find the haptic signals from\ndifferent granular media are distinguishable by DipMe. With the online granular\nobject recognition, we build several tangible interactive applications,\ndemonstrating the effects of DipMe in perceiving granular materials and its\npotential in developing a tangible user interface with granular objects as the\nnew media.",
      "tldr_zh": "本文提出DipMe，一种智能设备，用于实时识别颗粒介质(granular media)的类型，以增强有形用户界面(tangible user interface)中的交互体验。不同于基于视觉的解决方案，DipMe通过浸入操作(dip operation)捕获触觉信号(haptic signals)，并运用现代机器学习工具证明不同颗粒介质的信号是可区分的。最终，研究构建了几个有形交互应用，展示了DipMe在感知颗粒材料方面的效果及其在开发新型交互媒体的潜力。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "17 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.08641v1",
      "published_date": "2024-11-13 14:32:10 UTC",
      "updated_date": "2024-11-13 14:32:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:09:54.385563"
    },
    {
      "arxiv_id": "2411.08622v1",
      "title": "Precision-Focused Reinforcement Learning Model for Robotic Object Pushing",
      "title_zh": "翻译失败",
      "authors": [
        "Lara Bergmann",
        "David Leins",
        "Robert Haschke",
        "Klaus Neumann"
      ],
      "abstract": "Non-prehensile manipulation, such as pushing objects to a desired target\nposition, is an important skill for robots to assist humans in everyday\nsituations. However, the task is challenging due to the large variety of\nobjects with different and sometimes unknown physical properties, such as\nshape, size, mass, and friction. This can lead to the object overshooting its\ntarget position, requiring fast corrective movements of the robot around the\nobject, especially in cases where objects need to be precisely pushed. In this\npaper, we improve the state-of-the-art by introducing a new memory-based\nvision-proprioception RL model to push objects more precisely to target\npositions using fewer corrective movements.",
      "tldr_zh": "该研究针对机器人非抓取操作（如推动物体到目标位置）的精确性挑战，强调了物体多样性（如形状、大小、质量和摩擦等未知物理属性）可能导致物体超射和需要频繁校正动作的问题。论文提出一个新的基于记忆的 vision-proprioception reinforcement learning (RL) 模型，通过整合视觉和本体感觉数据来提升推动任务的精确性。实验结果显示，该模型显著减少了校正动作，从而改进了现有状态-of-the-art技术，为机器人辅助日常任务提供了更可靠的解决方案。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08622v1",
      "published_date": "2024-11-13 14:08:58 UTC",
      "updated_date": "2024-11-13 14:08:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:10:06.145057"
    },
    {
      "arxiv_id": "2411.08605v1",
      "title": "Lo-MARVE: A Low Cost Autonomous Underwater Vehicle for Marine Exploration",
      "title_zh": "翻译失败",
      "authors": [
        "Karl Mason",
        "Daniel Kelly"
      ],
      "abstract": "This paper presents Low-cost Marine Autonomous Robotic Vehicle Explorer\n(Lo-MARVE), a novel autonomous underwater vehicle (AUV) designed to provide a\nlow cost solution for underwater exploration and environmental monitoring in\nshallow water environments. Lo-MARVE offers a cost-effective alternative to\nexisting AUVs, featuring a modular design, low-cost sensors, and wireless\ncommunication capabilities. The total cost of Lo-MARVE is approximately EUR\n500. Lo-MARVE is developed using the Raspberry Pi 4B microprocessor, with\ncontrol software written in Python. The proposed AUV was validated through\nfield testing outside of a laboratory setting, in the freshwater environment of\nthe River Corrib in Galway, Ireland. This demonstrates its ability to navigate\nautonomously, collect data, and communicate effectively outside of a controlled\nlaboratory setting. The successful deployment of Lo-MARVE in a real-world\nenvironment validates its proof of concept.",
      "tldr_zh": "本文介绍了Lo-MARVE，一种低成本自主水下车辆(AUV)，旨在为浅水环境提供经济实惠的水下探索和环境监测解决方案。Lo-MARVE采用模块化设计、低成本传感器和无线通信技术，总成本约500欧元，并使用Raspberry Pi 4B微处理器及Python编写控制软件。该系统已在爱尔兰River Corrib河的实地测试中成功验证，能够自主导航、收集数据并有效通信，证明了其实际可行性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "This paper was presented at the 12th International Conference on\n  Control, Mechatronics and Automation (ICCMA 2024), held in London, UK, from\n  November 11-13, 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.08605v1",
      "published_date": "2024-11-13 13:45:54 UTC",
      "updated_date": "2024-11-13 13:45:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:10:18.002973"
    },
    {
      "arxiv_id": "2411.08599v3",
      "title": "A Preview of XiYan-SQL: A Multi-Generator Ensemble Framework for Text-to-SQL",
      "title_zh": "翻译失败",
      "authors": [
        "Yingqi Gao",
        "Yifu Liu",
        "Xiaoxia Li",
        "Xiaorong Shi",
        "Yin Zhu",
        "Yiming Wang",
        "Shiqi Li",
        "Wei Li",
        "Yuntao Hong",
        "Zhiling Luo",
        "Jinyang Gao",
        "Liyu Mou",
        "Yu Li"
      ],
      "abstract": "To tackle the challenges of large language model performance in natural\nlanguage to SQL tasks, we introduce XiYan-SQL, an innovative framework that\nemploys a multi-generator ensemble strategy to improve candidate generation. We\nintroduce M-Schema, a semi-structured schema representation method designed to\nenhance the understanding of database structures. To enhance the quality and\ndiversity of generated candidate SQL queries, XiYan-SQL integrates the\nsignificant potential of in-context learning (ICL) with the precise control of\nsupervised fine-tuning. On one hand, we propose a series of training strategies\nto fine-tune models to generate high-quality candidates with diverse\npreferences. On the other hand, we implement the ICL approach with an example\nselection method based on named entity recognition to prevent overemphasis on\nentities. The refiner optimizes each candidate by correcting logical or\nsyntactical errors. To address the challenge of identifying the best candidate,\nwe fine-tune a selection model to distinguish nuances of candidate SQL queries.\nThe experimental results on multiple dialect datasets demonstrate the\nrobustness of XiYan-SQL in addressing challenges across different scenarios.\nOverall, our proposed XiYan-SQL achieves the state-of-the-art execution\naccuracy of 75.63% on Bird benchmark, 89.65% on the Spider test set, 69.86% on\nSQL-Eval, 41.20% on NL2GQL. The proposed framework not only enhances the\nquality and diversity of SQL queries but also outperforms previous methods.",
      "tldr_zh": "本文介绍了 XiYan-SQL，一种多生成器集成框架，旨在提升大语言模型在文本到 SQL 任务中的性能，通过引入 M-Schema 的半结构化模式表示方法来增强数据库结构的理解。框架结合 in-context learning (ICL) 和监督微调策略，生成高质量、多样化的 SQL 候选查询，并使用精炼器纠正错误以及微调的选择模型来优化和选择最佳候选。实验结果显示，XiYan-SQL 在 Bird benchmark 上达到 75.63% 执行准确率，在 Spider 测试集上达 89.65%，在其他数据集如 SQL-Eval 和 NL2GQL 上也表现出色，超越了现有方法。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.DB",
        "cs.LG",
        "I.2; H.2"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08599v3",
      "published_date": "2024-11-13 13:30:21 UTC",
      "updated_date": "2025-02-10 10:28:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:10:31.060827"
    },
    {
      "arxiv_id": "2411.08587v1",
      "title": "DeepUQ: Assessing the Aleatoric Uncertainties from two Deep Learning Methods",
      "title_zh": "DeepUQ：评估两种深度学习方法的随机不确定性",
      "authors": [
        "Rebecca Nevin",
        "Aleksandra Ćiprijanović",
        "Brian D. Nord"
      ],
      "abstract": "Assessing the quality of aleatoric uncertainty estimates from uncertainty\nquantification (UQ) deep learning methods is important in scientific contexts,\nwhere uncertainty is physically meaningful and important to characterize and\ninterpret exactly. We systematically compare aleatoric uncertainty measured by\ntwo UQ techniques, Deep Ensembles (DE) and Deep Evidential Regression (DER).\nOur method focuses on both zero-dimensional (0D) and two-dimensional (2D) data,\nto explore how the UQ methods function for different data dimensionalities. We\ninvestigate uncertainty injected on the input and output variables and include\na method to propagate uncertainty in the case of input uncertainty so that we\ncan compare the predicted aleatoric uncertainty to the known values. We\nexperiment with three levels of noise. The aleatoric uncertainty predicted\nacross all models and experiments scales with the injected noise level.\nHowever, the predicted uncertainty is miscalibrated to $\\rm{std}(\\sigma_{\\rm\nal})$ with the true uncertainty for half of the DE experiments and almost all\nof the DER experiments. The predicted uncertainty is the least accurate for\nboth UQ methods for the 2D input uncertainty experiment and the high-noise\nlevel. While these results do not apply to more complex data, they highlight\nthat further research on post-facto calibration for these methods would be\nbeneficial, particularly for high-noise and high-dimensional settings.",
      "tldr_zh": "本文评估了两种深度学习不确定性量化（UQ）方法——Deep Ensembles (DE) 和 Deep Evidential Regression (DER)——对 aleatoric 不确定性的估计质量，特别是在科学背景下的0D和2D数据场景。研究通过注入三种噪声水平并传播输入不确定性，系统比较了预测不确定性与真实值的匹配度。结果显示，预测的不确定性随噪声增加，但DE的一半实验和DER的几乎所有实验均存在低估问题，尤其在高噪声和2D输入设置下；这突显了进一步开展后验校准研究的必要性，以提升这些方法在高维和高噪声环境中的可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to the Machine Learning for Physical Sciences workshop at\n  NeurIPS 2024; 11 pages, 2 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2411.08587v1",
      "published_date": "2024-11-13 13:11:49 UTC",
      "updated_date": "2024-11-13 13:11:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:10:42.868278"
    },
    {
      "arxiv_id": "2411.08586v2",
      "title": "Optimizing Automatic Summarization of Long Clinical Records Using Dynamic Context Extension:Testing and Evaluation of the NBCE Method",
      "title_zh": "翻译失败",
      "authors": [
        "Guoqing Zhang",
        "Keita Fukuyama",
        "Kazumasa Kishimoto",
        "Tomohiro Kuroda"
      ],
      "abstract": "Summarizing patient clinical notes is vital for reducing documentation\nburdens. Current manual summarization makes medical staff struggle. We propose\nan automatic method using LLMs, but long inputs cause LLMs to lose context,\nreducing output quality especially in small size model. We used a 7B model,\nopen-calm-7b, enhanced with Native Bayes Context Extend and a redesigned\ndecoding mechanism to reference one sentence at a time, keeping inputs within\ncontext windows, 2048 tokens. Our improved model achieved near parity with\nGoogle's over 175B Gemini on ROUGE-L metrics with 200 samples, indicating\nstrong performance using less resources, enhancing automated EMR summarization\nfeasibility.",
      "tldr_zh": "本文针对临床笔记的手动总结负担过重问题，提出了一种优化自动总结方法，使用 Large Language Models (LLMs) 结合 Native Bayes Context Extend (NBCE) 和重新设计的解码机制，来处理长输入导致的上下文丢失问题。研究在 7B 模型 open-calm-7b 上实施，通过一次引用一个句子保持输入在 2048 tokens 以内。实验结果显示，该方法在 200 个样本上的 ROUGE-L 指标上与 Google 的 175B Gemini 模型性能几乎相当，但资源消耗更低，从而提高了电子医疗记录 (EMR) 自动总结的可行性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08586v2",
      "published_date": "2024-11-13 13:09:14 UTC",
      "updated_date": "2024-11-14 14:07:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:10:55.245611"
    },
    {
      "arxiv_id": "2411.08583v1",
      "title": "An Empirical Examination of the Evaluative AI Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Jaroslaw Kornowicz"
      ],
      "abstract": "This study empirically examines the \"Evaluative AI\" framework, which aims to\nenhance the decision-making process for AI users by transitioning from a\nrecommendation-based approach to a hypothesis-driven one. Rather than offering\ndirect recommendations, this framework presents users pro and con evidence for\nhypotheses to support more informed decisions. However, findings from the\ncurrent behavioral experiment reveal no significant improvement in\ndecision-making performance and limited user engagement with the evidence\nprovided, resulting in cognitive processes similar to those observed in\ntraditional AI systems. Despite these results, the framework still holds\npromise for further exploration in future research.",
      "tldr_zh": "本研究实证考察了 Evaluative AI 框架，该框架旨在通过从推荐-based 转向 hypothesis-driven 的方法，提升 AI 用户决策过程，具体方式是呈现支持和反对假设的证据以辅助更明智的决策。行为实验结果显示，该框架并未显著改善决策表现，且用户对证据的参与有限，导致认知过程与传统 AI 系统相似。尽管如此，研究认为 Evaluative AI 框架仍有潜力，值得未来进一步探索。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08583v1",
      "published_date": "2024-11-13 13:03:49 UTC",
      "updated_date": "2024-11-13 13:03:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:11:05.444053"
    },
    {
      "arxiv_id": "2411.08582v1",
      "title": "Intelligent Algorithms For Signature Diagnostics Of Three-Phase Motors",
      "title_zh": "用于三相电机签名诊断的智能算法",
      "authors": [
        "Stepan Svirin",
        "Artem Ryzhikov",
        "Saraa Ali",
        "Denis Derkach"
      ],
      "abstract": "The application of machine learning (ML) algorithms in the intelligent\ndiagnosis of three-phase engines has the potential to significantly enhance\ndiagnostic performance and accuracy. Traditional methods largely rely on\nsignature analysis, which, despite being a standard practice, can benefit from\nthe integration of advanced ML techniques. In our study, we innovate by\ncombining state of the art algorithms with a novel unsupervised anomaly\ngeneration methodology that takes into account physics model of the engine.\nThis hybrid approach leverages the strengths of both supervised ML and\nunsupervised signature analysis, achieving superior diagnostic accuracy and\nreliability along with a wide industrial application. Our experimental results\ndemonstrate that this method significantly outperforms existing ML and non-ML\nstate-of-the-art approaches while retaining the practical advantages of an\nunsupervised methodology. The findings highlight the potential of our approach\nto significantly contribute to the field of engine diagnostics, offering a\nrobust and efficient solution for real-world applications.",
      "tldr_zh": "这篇论文提出了一种智能算法，用于三相电机的签名诊断，通过结合先进的机器学习(ML)算法和一种新型的无监督异常生成方法，该方法考虑了电机的physics model，以提升诊断性能和准确性。该混合方法融合了监督ML和无监督签名分析的优势，实现更高的诊断可靠性和广泛工业应用。实验结果表明，该方法显著优于现有ML和非ML基准，同时保留了无监督方法的实用性，为发动机诊断领域提供了稳健、高效的解决方案。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08582v1",
      "published_date": "2024-11-13 13:01:44 UTC",
      "updated_date": "2024-11-13 13:01:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:11:18.137751"
    },
    {
      "arxiv_id": "2411.08563v1",
      "title": "Leveraging LLMs for Predictive Insights in Food Policy and Behavioral Interventions",
      "title_zh": "翻译失败",
      "authors": [
        "Micha Kaiser",
        "Paul Lohmann",
        "Peter Ochieng",
        "Billy Shi",
        "Cass R. Sunstein",
        "Lucia A. Reisch"
      ],
      "abstract": "Food consumption and production contribute significantly to global greenhouse\ngas emissions, making them crucial entry points for mitigating climate change\nand maintaining a liveable planet. Over the past two decades, food policy\ninitiatives have explored interventions to reshape production and consumption\npatterns, focusing on reducing food waste and curbing ruminant meat\nconsumption. While the evidence of \"what works\" improves, evaluating which\npolicies are appropriate and effective in specific contexts remains difficult\ndue to external validity challenges. This paper demonstrates that a fine-tuned\nlarge language model (LLM) can accurately predict the direction of outcomes in\napproximately 80\\% of empirical studies measuring dietary-based impacts (e.g.\nfood choices, sales, waste) resulting from behavioral interventions and\npolicies. Approximately 75 prompts were required to achieve optimal results,\nwith performance showing signs of catastrophic loss beyond this point. Our\nfindings indicate that greater input detail enhances predictive accuracy,\nalthough the model still faces challenges with unseen studies, underscoring the\nimportance of a representative training sample. As LLMs continue to improve and\ndiversify, they hold promise for advancing data-driven, evidence-based\npolicymaking.",
      "tldr_zh": "这篇论文探讨了利用微调的大型语言模型（LLM）来预测食物政策和行为干预的效果，旨在解决评估干预（如减少食物浪费和反刍动物肉类消费）在不同情境中的外部有效性挑战。研究发现，通过约75个优化提示，LLM能够准确预测约80%的经验研究中干预对饮食影响（如食物选择、销售和浪费）的结果，而增加输入细节进一步提升了预测准确性。论文强调，尽管LLM在处理未见过的研究时存在局限，但其潜力有助于推进数据驱动的证据型政策制定。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08563v1",
      "published_date": "2024-11-13 12:21:13 UTC",
      "updated_date": "2024-11-13 12:21:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:11:30.389222"
    },
    {
      "arxiv_id": "2411.08562v1",
      "title": "Neural Corrective Machine Unranking",
      "title_zh": "翻译失败",
      "authors": [
        "Jingrui Hou",
        "Axel Finke",
        "Georgina Cosma"
      ],
      "abstract": "Machine unlearning in neural information retrieval (IR) systems requires\nremoving specific data whilst maintaining model performance. Applying existing\nmachine unlearning methods to IR may compromise retrieval effectiveness or\ninadvertently expose unlearning actions due to the removal of particular items\nfrom the retrieved results presented to users. We formalise corrective\nunranking, which extends machine unlearning in (neural) IR context by\nintegrating substitute documents to preserve ranking integrity, and propose a\nnovel teacher-student framework, Corrective unRanking Distillation (CuRD), for\nthis task. CuRD (1) facilitates forgetting by adjusting the (trained) neural IR\nmodel such that its output relevance scores of to-be-forgotten samples mimic\nthose of low-ranking, non-retrievable samples; (2) enables correction by\nfine-tuning the relevance scores for the substitute samples to match those of\ncorresponding to-be-forgotten samples closely; (3) seeks to preserve\nperformance on samples that are not targeted for forgetting. We evaluate CuRD\non four neural IR models (BERTcat, BERTdot, ColBERT, PARADE) using MS MARCO and\nTREC CAR datasets. Experiments with forget set sizes from 1 % and 20 % of the\ntraining dataset demonstrate that CuRD outperforms seven state-of-the-art\nbaselines in terms of forgetting and correction while maintaining model\nretention and generalisation capabilities.",
      "tldr_zh": "本研究针对神经信息检索（neural information retrieval）中的机器遗忘（machine unlearning）问题，提出了一种 corrective unranking 方法，通过引入替代文档（substitute documents）来移除特定数据，同时保持排名完整性。研究开发了 Corrective unRanking Distillation (CuRD) 框架，这是一个 teacher-student 框架，能够调整模型输出，使要遗忘样本的分数模拟低排名样本，并微调替代样本的分数，同时保留非目标样本的性能。实验在 BERTcat、BERTdot、ColBERT 和 PARADE 等四种神经 IR 模型上，使用 MS MARCO 和 TREC CAR 数据集进行测试，结果显示 CuRD 在遗忘集大小为 1% 到 20% 的场景下，优于七个基线模型，在遗忘、修正和性能保持方面表现出色。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "submitted to Information Sciences",
      "pdf_url": "http://arxiv.org/pdf/2411.08562v1",
      "published_date": "2024-11-13 12:19:46 UTC",
      "updated_date": "2024-11-13 12:19:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:11:42.709769"
    },
    {
      "arxiv_id": "2411.08561v5",
      "title": "LogLLM: Log-based Anomaly Detection Using Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Guan",
        "Jian Cao",
        "Shiyou Qian",
        "Jianqi Gao",
        "Chun Ouyang"
      ],
      "abstract": "Software systems often record important runtime information in logs to help\nwith troubleshooting. Log-based anomaly detection has become a key research\narea that aims to identify system issues through log data, ultimately enhancing\nthe reliability of software systems. Traditional deep learning methods often\nstruggle to capture the semantic information embedded in log data, which is\ntypically organized in natural language. In this paper, we propose LogLLM, a\nlog-based anomaly detection framework that leverages large language models\n(LLMs). LogLLM employs BERT for extracting semantic vectors from log messages,\nwhile utilizing Llama, a transformer decoder-based model, for classifying log\nsequences. Additionally, we introduce a projector to align the vector\nrepresentation spaces of BERT and Llama, ensuring a cohesive understanding of\nlog semantics. Unlike conventional methods that require log parsers to extract\ntemplates, LogLLM preprocesses log messages with regular expressions,\nstreamlining the entire process. Our framework is trained through a novel\nthree-stage procedure designed to enhance performance and adaptability.\nExperimental results across four public datasets demonstrate that LogLLM\noutperforms state-of-the-art methods. Even when handling unstable logs, it\neffectively captures the semantic meaning of log messages and detects anomalies\naccurately.",
      "tldr_zh": "本文提出 LogLLM，一种基于大型语言模型(LLMs)的日志异常检测框架，旨在解决传统深度学习方法在捕捉日志语义信息方面的不足。框架使用 BERT 提取日志消息的语义向量，并结合 Llama 进行日志序列分类，同时引入 projector 来对齐两个模型的向量表示空间，以确保语义一致性。LogLLM 通过正则表达式预处理日志，避免了传统日志解析器的复杂性，并采用三阶段训练过程提升适应性和性能。在四个公共数据集上的实验结果显示，该框架优于现有最先进方法，即使处理不稳定日志也能准确捕捉语义并检测异常。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08561v5",
      "published_date": "2024-11-13 12:18:00 UTC",
      "updated_date": "2025-04-14 02:52:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:11:55.204216"
    },
    {
      "arxiv_id": "2411.08553v1",
      "title": "CorrSynth -- A Correlated Sampling Method for Diverse Dataset Generation from LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Suhas S Kowshik",
        "Abhishek Divekar",
        "Vijit Malik"
      ],
      "abstract": "Large language models (LLMs) have demonstrated remarkable performance in\ndiverse tasks using zero-shot and few-shot prompting. Even though their\ncapabilities of data synthesis have been studied well in recent years, the\ngenerated data suffers from a lack of diversity, less adherence to the prompt,\nand potential biases that creep into the data from the generator model. In this\nwork, we tackle the challenge of generating datasets with high diversity, upon\nwhich a student model is trained for downstream tasks. Taking the route of\ndecoding-time guidance-based approaches, we propose CorrSynth, which generates\ndata that is more diverse and faithful to the input prompt using a correlated\nsampling strategy. Further, our method overcomes the complexity drawbacks of\nsome other guidance-based techniques like classifier-based guidance. With\nextensive experiments, we show the effectiveness of our approach and\nsubstantiate our claims. In particular, we perform intrinsic evaluation to show\nthe improvements in diversity. Our experiments show that CorrSynth improves\nboth student metrics and intrinsic metrics upon competitive baselines across\nfour datasets, showing the innate advantage of our method.",
      "tldr_zh": "本文提出 CorrSynth，一种基于关联采样（correlated sampling）的解码时指导方法，用于从 LLMs 生成更具多样性和忠实于输入提示的数据集，从而解决现有合成数据缺乏多样性、偏差和不精确的问题。该方法避免了其他指导技术如分类器指导的复杂性，通过优化采样策略提升数据生成质量。实验结果显示，CorrSynth 在四个数据集上显著提高了内在多样性指标和学生模型的性能指标，优于竞争基线。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Published as a main conference paper at EMNLP 2024; First two authors\n  contributed equally",
      "pdf_url": "http://arxiv.org/pdf/2411.08553v1",
      "published_date": "2024-11-13 12:09:23 UTC",
      "updated_date": "2024-11-13 12:09:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:12:06.111791"
    },
    {
      "arxiv_id": "2411.08552v1",
      "title": "Leveraging Pre-Trained Neural Networks to Enhance Machine Learning with Variational Quantum Circuits",
      "title_zh": "翻译失败",
      "authors": [
        "Jun Qi",
        "Chao-Han Yang",
        "Samuel Yen-Chi Chen",
        "Pin-Yu Chen",
        "Hector Zenil",
        "Jesper Tegner"
      ],
      "abstract": "Quantum Machine Learning (QML) offers tremendous potential but is currently\nlimited by the availability of qubits. We introduce an innovative approach that\nutilizes pre-trained neural networks to enhance Variational Quantum Circuits\n(VQC). This technique effectively separates approximation error from qubit\ncount and removes the need for restrictive conditions, making QML more viable\nfor real-world applications. Our method significantly improves parameter\noptimization for VQC while delivering notable gains in representation and\ngeneralization capabilities, as evidenced by rigorous theoretical analysis and\nextensive empirical testing on quantum dot classification tasks. Moreover, our\nresults extend to applications such as human genome analysis, demonstrating the\nbroad applicability of our approach. By addressing the constraints of current\nquantum hardware, our work paves the way for a new era of advanced QML\napplications, unlocking the full potential of quantum computing in fields such\nas machine learning, materials science, medicine, mimetics, and various\ninterdisciplinary areas.",
      "tldr_zh": "本研究提出了一种创新方法，利用预训练神经网络（pre-trained neural networks）来增强变分量子电路（VQC），以克服量子机器学习（QML）中量子比特数量的限制。该方法通过分离近似误差并消除严格条件，提高了VQC的参数优化、表示能力和泛化性能。实验结果显示，在量子点分类任务上取得了显著提升，并成功扩展到人类基因组分析等应用，从而为QML在机器学习、材料科学、医学等领域铺平道路，释放量子计算的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "quant-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "In submission",
      "pdf_url": "http://arxiv.org/pdf/2411.08552v1",
      "published_date": "2024-11-13 12:03:39 UTC",
      "updated_date": "2024-11-13 12:03:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:12:17.833840"
    },
    {
      "arxiv_id": "2411.08544v1",
      "title": "Deeper Insights into Learning Performance of Stochastic Configuration Networks",
      "title_zh": "对随机配置网络学习性能的更深入洞察",
      "authors": [
        "Xiufeng Yan",
        "Dianhui Wang"
      ],
      "abstract": "Stochastic Configuration Networks (SCNs) are a class of randomized neural\nnetworks that integrate randomized algorithms within an incremental learning\nframework. A defining feature of SCNs is the supervisory mechanism, which\nadaptively adjusts the distribution to generate effective random basis\nfunctions, thereby enabling error-free learning. In this paper, we present a\ncomprehensive analysis of the impact of the supervisory mechanism on the\nlearning performance of SCNs. Our findings reveal that the current SCN\nframework evaluates the effectiveness of each random basis function in reducing\nresidual errors using a lower bound on its error reduction potential, which\nconstrains SCNs' overall learning efficiency. Specifically, SCNs may fail to\nconsistently select the most effective random candidate as the new basis\nfunction during each training iteration. To overcome this problem, we propose a\nnovel method for evaluating the hidden layer's output matrix, supported by a\nnew supervisory mechanism that accurately assesses the error reduction\npotential of random basis functions without requiring the computation of the\nMoore-Penrose inverse of the output matrix. This approach enhances the\nselection of basis functions, reducing computational complexity and improving\nthe overall scalability and learning capabilities of SCNs. We introduce a\nRecursive Moore-Penrose Inverse-SCN (RMPI-SCN) training scheme based on the new\nsupervisory mechanism and demonstrate its effectiveness through simulations\nover some benchmark datasets. Experiments show that RMPI-SCN outperforms the\nconventional SCN in terms of learning capability, underscoring its potential to\nadvance the SCN framework for large-scale data modeling applications.",
      "tldr_zh": "该论文深入分析了Stochastic Configuration Networks (SCNs)的学习性能，揭示其监督机制（supervisory mechanism）使用误差减少的下界评估随机基函数，可能导致无法选择最有效的基函数，从而限制整体学习效率。研究者提出了一种新方法，通过评估隐藏层输出矩阵的创新监督机制，准确评估基函数的误差减少潜力，而无需计算Moore-Penrose逆，这降低了计算复杂性和提高了SCNs的可扩展性。为此，他们开发了Recursive Moore-Penrose Inverse-SCN (RMPI-SCN)训练方案，并通过基准数据集的模拟实验证明，RMPI-SCN在学习能力上显著优于传统SCNs，适用于大规模数据建模应用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08544v1",
      "published_date": "2024-11-13 11:45:39 UTC",
      "updated_date": "2024-11-13 11:45:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:12:32.090076"
    },
    {
      "arxiv_id": "2411.08537v1",
      "title": "MLV$^2$-Net: Rater-Based Majority-Label Voting for Consistent Meningeal Lymphatic Vessel Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Fabian Bongratz",
        "Markus Karmann",
        "Adrian Holz",
        "Moritz Bonhoeffer",
        "Viktor Neumaier",
        "Sarah Deli",
        "Benita Schmitz-Koep",
        "Claus Zimmer",
        "Christian Sorg",
        "Melissa Thalhammer",
        "Dennis M Hedderich",
        "Christian Wachinger"
      ],
      "abstract": "Meningeal lymphatic vessels (MLVs) are responsible for the drainage of waste\nproducts from the human brain. An impairment in their functionality has been\nassociated with aging as well as brain disorders like multiple sclerosis and\nAlzheimer's disease. However, MLVs have only recently been described for the\nfirst time in magnetic resonance imaging (MRI), and their ramified structure\nrenders manual segmentation particularly difficult. Further, as there is no\nconsistent notion of their appearance, human-annotated MLV structures contain a\nhigh inter-rater variability that most automatic segmentation methods cannot\ntake into account. In this work, we propose a new rater-aware training scheme\nfor the popular nnU-Net model, and we explore rater-based ensembling strategies\nfor accurate and consistent segmentation of MLVs. This enables us to boost\nnnU-Net's performance while obtaining explicit predictions in different\nannotation styles and a rater-based uncertainty estimation. Our final model,\nMLV$^2$-Net, achieves a Dice similarity coefficient of 0.806 with respect to\nthe human reference standard. The model further matches the human inter-rater\nreliability and replicates age-related associations with MLV volume.",
      "tldr_zh": "本研究针对脑膜淋巴血管 (MLVs) 的分割难题提出 MLV$^2$-Net 模型，该模型基于标注者 (rater) 的多数标签投票 (majority-label voting) 策略，改进 nnU-Net 的训练方案，以处理标注者间的高变异性和结构复杂性。方法通过 rater-aware 训练和集成策略，实现不同标注风格的预测以及不确定性估计，从而提升分割的一致性和准确性。实验结果显示，MLV$^2$-Net 达到了 0.806 的 Dice similarity coefficient，与人类标注者可靠性相当，并成功复制了 MLVs 体积与年龄相关的关联。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "ML4H 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.08537v1",
      "published_date": "2024-11-13 11:35:39 UTC",
      "updated_date": "2024-11-13 11:35:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:12:42.648983"
    },
    {
      "arxiv_id": "2411.08533v2",
      "title": "ACROSS: A Deformation-Based Cross-Modal Representation for Robotic Tactile Perception",
      "title_zh": "ACROSS：一种基于变形的跨模态表示用于机器人触觉感知",
      "authors": [
        "Wadhah Zai El Amri",
        "Malte Kuhlmann",
        "Nicolás Navarro-Guerrero"
      ],
      "abstract": "Tactile perception is essential for human interaction with the environment\nand is becoming increasingly crucial in robotics. Tactile sensors like the\nBioTac mimic human fingertips and provide detailed interaction data. Despite\nits utility in applications like slip detection and object identification, this\nsensor is now deprecated, making many valuable datasets obsolete. However,\nrecreating similar datasets with newer sensor technologies is both tedious and\ntime-consuming. Therefore, adapting these existing datasets for use with new\nsetups and modalities is crucial. In response, we introduce ACROSS, a novel\nframework for translating data between tactile sensors by exploiting sensor\ndeformation information. We demonstrate the approach by translating BioTac\nsignals into the DIGIT sensor. Our framework consists of first converting the\ninput signals into 3D deformation meshes. We then transition from the 3D\ndeformation mesh of one sensor to the mesh of another, and finally convert the\ngenerated 3D deformation mesh into the corresponding output space. We\ndemonstrate our approach to the most challenging problem of going from a\nlow-dimensional tactile representation to a high-dimensional one. In\nparticular, we transfer the tactile signals of a BioTac sensor to DIGIT tactile\nimages. Our approach enables the continued use of valuable datasets and data\nexchange between groups with different setups.",
      "tldr_zh": "该研究提出ACROSS框架，利用传感器变形信息，实现机器人触觉感知中的跨模态数据转换，以解决BioTac传感器弃用导致数据集过时的问题。方法包括将输入信号（如BioTac的低维信号）转换为3D变形网格，然后将网格从一个传感器转移到另一个（如DIGIT传感器），并最终转换为相应的高维输出空间。实验证明，该框架成功将BioTac信号转换为DIGIT触觉图像，从而使现有数据集得以继续使用，并促进不同实验设置之间的数据交换。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted to 2025 IEEE Conference on Robotics and Automation (ICRA\n  2025). arXiv admin note: text overlap with arXiv:2410.14310",
      "pdf_url": "http://arxiv.org/pdf/2411.08533v2",
      "published_date": "2024-11-13 11:29:14 UTC",
      "updated_date": "2025-02-19 17:08:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:12:54.343299"
    },
    {
      "arxiv_id": "2411.08526v2",
      "title": "Gendered Words and Grant Rates: A Textual Analysis of Disparate Outcomes in the Patent System",
      "title_zh": "性别化词汇与授予率：专利系统中不同结果的文本分析",
      "authors": [
        "Deborah Gerhardt",
        "Miriam Marcowitz-Bitton",
        "W. Michael Schuster",
        "Avshalom Elmalech",
        "Omri Suissa",
        "Moshe Mash"
      ],
      "abstract": "Text is a vehicle to convey information that reflects the writer's linguistic\nstyle and communicative patterns. By studying these attributes, we can discover\nlatent insights about the author and their underlying message. This article\nuses such an approach to better understand patent applications and their\ninventors. While prior research focuses on patent metadata, we employ machine\nlearning and natural language processing to extract hidden information from the\nwords in patent applications. Through these methods, we find that inventor\ngender can often be identified from textual attributes - even without knowing\nthe inventor's name. This ability to discern gender through text suggests that\nanonymized patent examination - often proposed as a solution to mitigate\ndisparities in patent grant rates - may not fully address gendered outcomes in\nsecuring a patent. Our study also investigates whether objective features of a\npatent application can predict if it will be granted. Using a classifier\nalgorithm, we correctly predicted whether a patent was granted over 60% of the\ntime. Further analysis emphasized that writing style - like vocabulary and\nsentence complexity - disproportionately influenced grant predictions relative\nto other attributes such as inventor gender and subject matter keywords.\nLastly, we examine whether women disproportionately invent in technological\nareas with higher rejection rates. Using a clustering algorithm, applications\nwere allocated into groups with related subject matter. We found that 85% of\nfemale-dominated clusters have abnormally high rejection rates, compared to\nonly 45% for male-dominated groupings. These findings highlight complex\ninteractions between textual choices, gender, and success in securing a patent.\nThey also raise questions about whether current proposals will be sufficient to\nachieve gender equity and efficiency in the patent system.",
      "tldr_zh": "本研究通过机器学习和 natural language processing 分析专利申请文本，揭示了性别因素对专利授予率的影响。研究发现，文本属性（如词汇和句子复杂度）可用于识别发明人性别，即使匿名化处理也难以消除性别偏见；使用 classifier algorithm 预测专利是否被授予，准确率超过60%，其中写作风格的影响远大于发明人性别或主题关键词。进一步分析显示，女性主导的技术领域集群有85%的异常高拒绝率，相比男性主导集群的45%，这突出了文本选择、性别和专利成功之间的复杂互动，并质疑现有措施能否实现性别公平。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08526v2",
      "published_date": "2024-11-13 11:20:09 UTC",
      "updated_date": "2024-12-18 17:24:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:13:06.400608"
    },
    {
      "arxiv_id": "2411.08521v3",
      "title": "SAD-TIME: a Spatiotemporal-fused network for depression detection with Automated multi-scale Depth-wise and TIME-interval-related common feature extractor",
      "title_zh": "翻译失败",
      "authors": [
        "Han-Guang Wang",
        "Hui-Rang Hou",
        "Li-Cheng Jin",
        "Chen-Yang Xu",
        "Zhong-Yi Zhang",
        "Qing-Hao Meng"
      ],
      "abstract": "Background and Objective: Depression is a severe mental disorder, and\naccurate diagnosis is pivotal to the cure and rehabilitation of people with\ndepression. However, the current questionnaire-based diagnostic methods could\nbring subjective biases and may be denied by subjects. In search of a more\nobjective means of diagnosis, researchers have begun to experiment with deep\nlearning-based methods for identifying depressive disorders in recent years.\nMethods: In this study, a novel Spatiotemporal-fused network with Automated\nmulti-scale Depth-wise and TIME-interval-related common feature extractor\n(SAD-TIME) is proposed. SAD-TIME incorporates an automated nodes' common\nfeatures extractor (CFE), a spatial sector (SpS), a modified temporal sector\n(TeS), and a domain adversarial learner (DAL). The CFE includes a multi-scale\ndepth-wise 1D-convolutional neural network and a time-interval embedding\ngenerator, where the unique information of each channel is preserved. The SpS\nfuses the functional connectivity with the distance-based connectivity\ncontaining spatial position of EEG electrodes. A multi-head-attention graph\nconvolutional network is also applied in the SpS to fuse the features from\ndifferent EEG channels. The TeS is based on long short-term memory and graph\ntransformer networks, where the temporal information of different time-windows\nis fused. Moreover, the DAL is used after the SpS to obtain the\ndomain-invariant feature. Results: Experimental results under tenfold\ncross-validation show that the proposed SAD-TIME method achieves 92.00% and\n94.00% depression classification accuracies on two datasets, respectively, in\ncross-subject mode. Conclusion: SAD-TIME is a robust depression detection\nmodel, where the automatedly-generated features, the SpS and the TeS assist the\nclassification performance with the fusion of the innate spatiotemporal\ninformation in the EEG signals.",
      "tldr_zh": "本文提出了一种名为 SAD-TIME 的时空融合网络，用于通过 EEG 信号实现抑郁症检测，以克服传统问卷方法的主观偏差。该网络包括自动多尺度深度-wise 1D-卷积神经网络和时间间隔嵌入的共同特征提取器 (CFE)、融合功能和距离连接的空间扇区 (SpS) 以及基于 LSTM 和图变换器的时间扇区 (TeS)，并通过领域对抗学习器 (DAL) 提取领域不变特征。实验在两个数据集上进行十折交叉验证，分别获得 92.00% 和 94.00% 的跨主体分类准确率。总体而言，SAD-TIME 通过自动生成特征和时空信息融合，提升了抑郁检测的鲁棒性和性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "21pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.08521v3",
      "published_date": "2024-11-13 11:08:28 UTC",
      "updated_date": "2024-12-28 09:10:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:13:19.733831"
    },
    {
      "arxiv_id": "2411.08514v1",
      "title": "Explainers' Mental Representations of Explainees' Needs in Everyday Explanations",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Erol Schaffer",
        "Lutz Terfloth",
        "Carsten Schulte",
        "Heike M. Buhl"
      ],
      "abstract": "In explanations, explainers have mental representations of explainees'\ndeveloping knowledge and shifting interests regarding the explanandum. These\nmental representations are dynamic in nature and develop over time, thereby\nenabling explainers to react to explainees' needs by adapting and customizing\nthe explanation. XAI should be able to react to explainees' needs in a similar\nmanner. Therefore, a component that incorporates aspects of explainers' mental\nrepresentations of explainees is required. In this study, we took first steps\nby investigating explainers' mental representations in everyday explanations of\ntechnological artifacts. According to the dual nature theory, technological\nartifacts require explanations with two distinct perspectives, namely\nobservable and measurable features addressing \"Architecture\" or interpretable\naspects addressing \"Relevance\". We conducted extended semi structured pre-,\npost- and video recall-interviews with explainers (N=9) in the context of an\nexplanation. The transcribed interviews were analyzed utilizing qualitative\ncontent analysis. The explainers' answers regarding the explainees' knowledge\nand interests with regard to the technological artifact emphasized the\nvagueness of early assumptions of explainers toward strong beliefs in the\ncourse of explanations. The assumed knowledge of explainees in the beginning is\ncentered around Architecture and develops toward knowledge with regard to both\nArchitecture and Relevance. In contrast, explainers assumed higher interests in\nRelevance in the beginning to interests regarding both Architecture and\nRelevance in the further course of explanations. Further, explainers often\nfinished the explanation despite their perception that explainees still had\ngaps in knowledge. These findings are transferred into practical implications\nrelevant for user models for adaptive explainable systems.",
      "tldr_zh": "这篇论文探讨了解释者在日常解释中对被解释者知识和兴趣的动态心理表征（mental representations），以帮助适应和定制解释，并为XAI（可解释人工智能）系统提供类似响应机制。研究聚焦于技术人工制品的解释，根据dual nature theory，涉及Architecture（可观察特征）和Relevance（可解释方面）两个视角。作者通过对9位解释者的半结构化访谈（包括pre-、post-和video recall-interviews）和定性内容分析，发现解释者对被解释者知识的假设从模糊且偏向Architecture逐步扩展到Architecture和Relevance，而兴趣则从Relevance起始逐渐涵盖两者。此外，尽管感知被解释者仍有知识缺口，解释者往往提前结束解释，这些发现为设计适应性可解释系统的用户模型提供了实用启示。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08514v1",
      "published_date": "2024-11-13 10:53:07 UTC",
      "updated_date": "2024-11-13 10:53:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:13:31.807388"
    },
    {
      "arxiv_id": "2411.08506v2",
      "title": "Towards Operationalizing Right to Data Protection",
      "title_zh": "翻译失败",
      "authors": [
        "Abhinav Java",
        "Simra Shahid",
        "Chirag Agarwal"
      ],
      "abstract": "The widespread practice of indiscriminate data scraping to fine-tune language\nmodels (LMs) raises significant legal and ethical concerns, particularly\nregarding compliance with data protection laws such as the General Data\nProtection Regulation (GDPR). This practice often results in the unauthorized\nuse of personal information, prompting growing debate within the academic and\nregulatory communities. Recent works have introduced the concept of generating\nunlearnable datasets (by adding imperceptible noise to the clean data), such\nthat the underlying model achieves lower loss during training but fails to\ngeneralize to the unseen test setting. Though somewhat effective, these\napproaches are predominantly designed for images and are limited by several\npractical constraints like requiring knowledge of the target model. To this\nend, we introduce RegText, a framework that injects imperceptible spurious\ncorrelations into natural language datasets, effectively rendering them\nunlearnable without affecting semantic content. We demonstrate RegText's\nutility through rigorous empirical analysis of small and large LMs. Notably,\nRegText can restrict newer models like GPT-4o and Llama from learning on our\ngenerated data, resulting in a drop in their test accuracy compared to their\nzero-shot performance and paving the way for generating unlearnable text to\nprotect public data.",
      "tldr_zh": "这篇论文针对数据抓取用于微调语言模型（LMs）所引发的法律和伦理问题，特别是与 General Data Protection Regulation (GDPR) 的合规性，提出 RegText 框架。RegText 通过在自然语言数据集注入 imperceptible spurious correlations 的方式，使数据变得 unlearnable，同时不影响其语义内容，从而防止模型有效学习。实验结果显示，该框架能显著降低小型和大型 LMs（如 GPT-4o 和 Llama）的测试准确率，与零样本性能相比下降明显，为操作化数据保护权提供了一种可行的保护公共数据的策略。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "First two authors contributed equally to this work",
      "pdf_url": "http://arxiv.org/pdf/2411.08506v2",
      "published_date": "2024-11-13 10:43:31 UTC",
      "updated_date": "2024-11-16 09:36:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:13:43.010168"
    },
    {
      "arxiv_id": "2411.08504v2",
      "title": "Towards Objective and Unbiased Decision Assessments with LLM-Enhanced Hierarchical Attention Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Junhua Liu",
        "Kwan Hui Lim",
        "Roy Ka-Wei Lee"
      ],
      "abstract": "How objective and unbiased are we while making decisions? This work\ninvestigates cognitive bias identification in high-stake decision making\nprocess by human experts, questioning its effectiveness in real-world settings,\nsuch as candidates assessments for university admission. We begin with a\nstatistical analysis assessing correlations among different decision points\namong in the current process, which discovers discrepancies that imply\ncognitive bias and inconsistency in decisions. This motivates our exploration\nof bias-aware AI-augmented workflow that surpass human judgment. We propose\nBGM-HAN, an enhanced Hierarchical Attention Network with Byte-Pair Encoding,\nGated Residual Connections and Multi-Head Attention. Using it as a backbone\nmodel, we further propose a Shortlist-Analyse-Recommend (SAR) agentic workflow,\nwhich simulate real-world decision-making. In our experiments, both the\nproposed model and the agentic workflow significantly improves on both human\njudgment and alternative models, validated with real-world data.",
      "tldr_zh": "这篇论文探讨了人类在高风险决策（如大学录取）中的认知偏差，通过统计分析揭示决策点之间的不一致性，质疑其在真实场景中的有效性。为解决这一问题，作者提出 BGM-HAN，一种增强的 Hierarchical Attention Network，结合 Byte-Pair Encoding、Gated Residual Connections 和 Multi-Head Attention，并开发了 Shortlist-Analyse-Recommend (SAR) 代理工作流来模拟并优化决策过程。实验结果显示，该模型和工作流在真实数据上显著优于人类判断和其它基准模型，推动了更客观和无偏见的决策评估。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Source code is available at: https://github.com/junhua/bgm-han",
      "pdf_url": "http://arxiv.org/pdf/2411.08504v2",
      "published_date": "2024-11-13 10:42:11 UTC",
      "updated_date": "2024-11-14 05:51:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:13:55.028191"
    },
    {
      "arxiv_id": "2411.08478v1",
      "title": "Learning Model Agnostic Explanations via Constraint Programming",
      "title_zh": "翻译失败",
      "authors": [
        "Frederic Koriche",
        "Jean-Marie Lagniez",
        "Stefan Mengel",
        "Chi Tran"
      ],
      "abstract": "Interpretable Machine Learning faces a recurring challenge of explaining the\npredictions made by opaque classifiers such as ensemble models, kernel methods,\nor neural networks in terms that are understandable to humans. When the model\nis viewed as a black box, the objective is to identify a small set of features\nthat jointly determine the black box response with minimal error. However,\nfinding such model-agnostic explanations is computationally demanding, as the\nproblem is intractable even for binary classifiers. In this paper, the task is\nframed as a Constraint Optimization Problem, where the constraint solver seeks\nan explanation of minimum error and bounded size for an input data instance and\na set of samples generated by the black box. From a theoretical perspective,\nthis constraint programming approach offers PAC-style guarantees for the output\nexplanation. We evaluate the approach empirically on various datasets and show\nthat it statistically outperforms the state-of-the-art heuristic Anchors\nmethod.",
      "tldr_zh": "本文提出了一种通过约束编程(Constraint Programming)学习模型无关解释的方法，将解释黑盒分类器（如集成模型、核方法或神经网络）预测的任务框架化为约束优化问题(Constraint Optimization Problem)，旨在找到最小错误和有限大小的特征集来精确解释模型响应。该方法从理论上提供PAC-style guarantees，确保解释的可靠性。在各种数据集上的实验表明，该方法统计上优于现有启发式方法Anchors，提供更有效的模型解释。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08478v1",
      "published_date": "2024-11-13 09:55:59 UTC",
      "updated_date": "2024-11-13 09:55:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:14:06.092913"
    },
    {
      "arxiv_id": "2411.08469v2",
      "title": "Building Trustworthy AI: Transparent AI Systems via Large Language Models, Ontologies, and Logical Reasoning (TranspNet)",
      "title_zh": "构建可信赖的 AI：通过大型语言模型、本体和逻辑推理实现透明 AI 系统 (TranspNet)",
      "authors": [
        "Fadi Al Machot",
        "Martin Thomas Horsch",
        "Habib Ullah"
      ],
      "abstract": "Growing concerns over the lack of transparency in AI, particularly in\nhigh-stakes fields like healthcare and finance, drive the need for explainable\nand trustworthy systems. While Large Language Models (LLMs) perform\nexceptionally well in generating accurate outputs, their \"black box\" nature\nposes significant challenges to transparency and trust. To address this, the\npaper proposes the TranspNet pipeline, which integrates symbolic AI with LLMs.\nBy leveraging domain expert knowledge, retrieval-augmented generation (RAG),\nand formal reasoning frameworks like Answer Set Programming (ASP), TranspNet\nenhances LLM outputs with structured reasoning and verification.This approach\nstrives to help AI systems deliver results that are as accurate, explainable,\nand trustworthy as possible, aligning with regulatory expectations for\ntransparency and accountability. TranspNet provides a solution for developing\nAI systems that are reliable and interpretable, making it suitable for\nreal-world applications where trust is critical.",
      "tldr_zh": "该论文针对 AI 系统的透明性问题，特别是 Large Language Models (LLMs) 的黑箱性质在医疗和金融等高风险领域带来的信任挑战，提出 TranspNet 管道作为解决方案。TranspNet 通过整合 LLMs 与符号 AI，包括利用领域专家知识、Retrieval-Augmented Generation (RAG) 和 Answer Set Programming (ASP) 等正式推理框架，来增强输出结果的结构化推理和验证。该框架显著提高了 AI 的准确性、可解释性和可信任度，符合监管要求，并适用于需要高可靠性真实世界应用。",
      "categories": [
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08469v2",
      "published_date": "2024-11-13 09:40:37 UTC",
      "updated_date": "2024-12-18 14:45:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:14:18.630887"
    },
    {
      "arxiv_id": "2411.08464v1",
      "title": "Crystal Structure Generation Based On Material Properties",
      "title_zh": "基于材料属性的晶体结构生成",
      "authors": [
        "Chao Huang",
        "JiaHui Chen",
        "HongRui Liang",
        "ChunYan Chen",
        "Chen Chen"
      ],
      "abstract": "The discovery of new materials is very important to the field of materials\nscience. When researchers explore new materials, they often have expected\nperformance requirements for their crystal structure. In recent years,\ndata-driven methods have made great progress in the direction plane of crystal\nstructure generation, but there is still a lack of methods that can effectively\nmap material properties to crystal structure. In this paper, we propose a\nCrystal DiT model to generate the crystal structure from the expected material\nproperties by embedding the material properties and combining the symmetry\ninformation predicted by the large language model. Experimental verification\nshows that our proposed method has good performance.",
      "tldr_zh": "该研究针对材料科学中基于预期性能生成晶体结构的需求，提出了一种Crystal DiT模型，以解决现有数据驱动方法在将材料属性映射到晶体结构方面的不足。该模型通过嵌入材料属性并结合large language model预测的对称性信息，实现从预期性能到晶体结构的有效生成。实验验证表明，该方法表现出良好的性能，有助于加速新材料发现过程。",
      "categories": [
        "cs.AI",
        "cond-mat.mtrl-sci"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08464v1",
      "published_date": "2024-11-13 09:36:50 UTC",
      "updated_date": "2024-11-13 09:36:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:14:29.561090"
    },
    {
      "arxiv_id": "2411.08463v2",
      "title": "Symbolic-AI-Fusion Deep Learning (SAIF-DL): Encoding Knowledge into Training with Answer Set Programming Loss Penalties by a Novel Loss Function Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Fadi Al Machot",
        "Martin Thomas Horsch",
        "Habib Ullah"
      ],
      "abstract": "This paper presents a hybrid methodology that enhances the training process\nof deep learning (DL) models by embedding domain expert knowledge using\nontologies and answer set programming (ASP). By integrating these symbolic AI\nmethods, we encode domain-specific constraints, rules, and logical reasoning\ndirectly into the model's learning process, thereby improving both performance\nand trustworthiness. The proposed approach is flexible and applicable to both\nregression and classification tasks, demonstrating generalizability across\nvarious fields such as healthcare, autonomous systems, engineering, and battery\nmanufacturing applications. Unlike other state-of-the-art methods, the strength\nof our approach lies in its scalability across different domains. The design\nallows for the automation of the loss function by simply updating the ASP\nrules, making the system highly scalable and user-friendly. This facilitates\nseamless adaptation to new domains without significant redesign, offering a\npractical solution for integrating expert knowledge into DL models in\nindustrial settings such as battery manufacturing.",
      "tldr_zh": "本文提出了一种名为 Symbolic-AI-Fusion Deep Learning (SAIF-DL) 的混合方法，通过使用本体论和 Answer Set Programming (ASP) 将领域专家知识嵌入深度学习 (DL) 模型的训练过程，从而编码特定约束、规则和逻辑推理，以提升模型的性能和可信度。该方法适用于回归和分类任务，并在医疗、自治系统、工程以及电池制造等领域展示出良好的通用性和可扩展性。不同于其他方法，SAIF-DL 通过简单更新 ASP 规则即可自动化损失函数的设计，实现无缝适应新领域，而无需重大重构。实验结果表明，该方法在工业应用中提供了一个实用且高效的解决方案。",
      "categories": [
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08463v2",
      "published_date": "2024-11-13 09:33:33 UTC",
      "updated_date": "2024-12-18 14:55:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:14:43.506288"
    },
    {
      "arxiv_id": "2411.08460v2",
      "title": "Trap-MID: Trapdoor-based Defense against Model Inversion Attacks",
      "title_zh": "Trap-MID：基于陷门的模型反演攻击防御",
      "authors": [
        "Zhen-Ting Liu",
        "Shang-Tse Chen"
      ],
      "abstract": "Model Inversion (MI) attacks pose a significant threat to the privacy of Deep\nNeural Networks by recovering training data distribution from well-trained\nmodels. While existing defenses often rely on regularization techniques to\nreduce information leakage, they remain vulnerable to recent attacks. In this\npaper, we propose the Trapdoor-based Model Inversion Defense (Trap-MID) to\nmislead MI attacks. A trapdoor is integrated into the model to predict a\nspecific label when the input is injected with the corresponding trigger.\nConsequently, this trapdoor information serves as the \"shortcut\" for MI\nattacks, leading them to extract trapdoor triggers rather than private data. We\nprovide theoretical insights into the impacts of trapdoor's effectiveness and\nnaturalness on deceiving MI attacks. In addition, empirical experiments\ndemonstrate the state-of-the-art defense performance of Trap-MID against\nvarious MI attacks without the requirements for extra data or large\ncomputational overhead. Our source code is publicly available at\nhttps://github.com/ntuaislab/Trap-MID.",
      "tldr_zh": "本研究针对模型反转(Model Inversion, MI)攻击对深度神经网络隐私的威胁，提出了一种基于陷阱门(trapdoor)的防御方法Trap-MID。该方法通过在模型中集成陷阱门，当输入注入特定触发器时，使模型预测特定标签，从而误导MI攻击提取陷阱触发器而非私有数据。论文提供了陷阱门有效性和自然性的理论分析，并通过实验证明Trap-MID在各种MI攻击中表现出最先进的防御性能，无需额外数据或大量计算开销。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted by Neural Information Processing Systems (NeurIPS) 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.08460v2",
      "published_date": "2024-11-13 09:31:06 UTC",
      "updated_date": "2024-11-25 12:10:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:14:54.138028"
    },
    {
      "arxiv_id": "2411.08933v2",
      "title": "Confidence-aware Denoised Fine-tuning of Off-the-shelf Models for Certified Robustness",
      "title_zh": "翻译失败",
      "authors": [
        "Suhyeok Jang",
        "Seojin Kim",
        "Jinwoo Shin",
        "Jongheon Jeong"
      ],
      "abstract": "The remarkable advances in deep learning have led to the emergence of many\noff-the-shelf classifiers, e.g., large pre-trained models. However, since they\nare typically trained on clean data, they remain vulnerable to adversarial\nattacks. Despite this vulnerability, their superior performance and\ntransferability make off-the-shelf classifiers still valuable in practice,\ndemanding further work to provide adversarial robustness for them in a post-hoc\nmanner. A recently proposed method, denoised smoothing, leverages a denoiser\nmodel in front of the classifier to obtain provable robustness without\nadditional training. However, the denoiser often creates hallucination, i.e.,\nimages that have lost the semantics of their originally assigned class, leading\nto a drop in robustness. Furthermore, its noise-and-denoise procedure\nintroduces a significant distribution shift from the original distribution,\ncausing the denoised smoothing framework to achieve sub-optimal robustness. In\nthis paper, we introduce Fine-Tuning with Confidence-Aware Denoised Image\nSelection (FT-CADIS), a novel fine-tuning scheme to enhance the certified\nrobustness of off-the-shelf classifiers. FT-CADIS is inspired by the\nobservation that the confidence of off-the-shelf classifiers can effectively\nidentify hallucinated images during denoised smoothing. Based on this, we\ndevelop a confidence-aware training objective to handle such hallucinated\nimages and improve the stability of fine-tuning from denoised images. In this\nway, the classifier can be fine-tuned using only images that are beneficial for\nadversarial robustness. We also find that such a fine-tuning can be done by\nupdating a small fraction of parameters of the classifier. Extensive\nexperiments demonstrate that FT-CADIS has established the state-of-the-art\ncertified robustness among denoised smoothing methods across all\n$\\ell_2$-adversary radius in various benchmarks.",
      "tldr_zh": "该研究针对现成分类器（如大型预训练模型）在对抗攻击下的脆弱性，提出了一种新的微调方案：Confidence-aware Denoised Fine-tuning of Off-the-shelf Models for Certified Robustness。方法名为 FT-CADIS，它利用分类器的置信度来识别 denoised smoothing 中的 hallucination 图像，并设计一个基于置信度的训练目标，仅使用有益图像进行微调，同时仅更新分类器的一小部分参数，以缓解分布偏移问题。实验结果显示，FT-CADIS 在各种基准上实现了 denoised smoothing 方法的最先进 certified robustness，在所有 ℓ2-adversary radius 下均显著提升鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "26 pages; TMLR 2024; Code is available at\n  https://github.com/suhyeok24/FT-CADIS",
      "pdf_url": "http://arxiv.org/pdf/2411.08933v2",
      "published_date": "2024-11-13 09:13:20 UTC",
      "updated_date": "2024-11-15 06:13:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:15:06.375560"
    },
    {
      "arxiv_id": "2411.08447v1",
      "title": "Learning Dynamic Cognitive Map with Autonomous Navigation",
      "title_zh": "学习动态认知地图与自主导航",
      "authors": [
        "Daria de Tinguy",
        "Tim Verbelen",
        "Bart Dhoedt"
      ],
      "abstract": "Inspired by animal navigation strategies, we introduce a novel computational\nmodel to navigate and map a space rooted in biologically inspired principles.\nAnimals exhibit extraordinary navigation prowess, harnessing memory,\nimagination, and strategic decision-making to traverse complex and aliased\nenvironments adeptly. Our model aims to replicate these capabilities by\nincorporating a dynamically expanding cognitive map over predicted poses within\nan Active Inference framework, enhancing our agent's generative model\nplasticity to novelty and environmental changes. Through structure learning and\nactive inference navigation, our model demonstrates efficient exploration and\nexploitation, dynamically expanding its model capacity in response to\nanticipated novel un-visited locations and updating the map given new evidence\ncontradicting previous beliefs. Comparative analyses in mini-grid environments\nwith the Clone-Structured Cognitive Graph model (CSCG), which shares similar\nobjectives, highlight our model's ability to rapidly learn environmental\nstructures within a single episode, with minimal navigation overlap. Our model\nachieves this without prior knowledge of observation and world dimensions,\nunderscoring its robustness and efficacy in navigating intricate environments.",
      "tldr_zh": "该研究受动物导航策略启发，提出了一种新型计算模型，用于实现自主导航和空间映射，通过动态扩展的 cognitive map 和 Active Inference 框架来模仿动物的记忆、想象力和决策能力。该模型通过结构学习和主动推理，允许代理高效探索和利用环境，能够根据预期的未知区域动态扩展模型容量，并在新证据下更新认知地图。与 CSCG 模型相比，实验在 mini-grid 环境中显示，该模型能在单次回合内快速学习环境结构，减少导航重叠，且无需事先知道观察和世界维度，展示了其鲁棒性和高效性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "under submission at Frontiers Computer Neuroscience",
      "pdf_url": "http://arxiv.org/pdf/2411.08447v1",
      "published_date": "2024-11-13 08:59:53 UTC",
      "updated_date": "2024-11-13 08:59:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:17:17.989013"
    },
    {
      "arxiv_id": "2411.08438v1",
      "title": "Towards Optimizing a Retrieval Augmented Generation using Large Language Model on Academic Data",
      "title_zh": "翻译失败",
      "authors": [
        "Anum Afzal",
        "Juraj Vladika",
        "Gentrit Fazlija",
        "Andrei Staradubets",
        "Florian Matthes"
      ],
      "abstract": "Given the growing trend of many organizations integrating Retrieval Augmented\nGeneration (RAG) into their operations, we assess RAG on domain-specific data\nand test state-of-the-art models across various optimization techniques. We\nincorporate four optimizations; Multi-Query, Child-Parent-Retriever, Ensemble\nRetriever, and In-Context-Learning, to enhance the functionality and\nperformance in the academic domain. We focus on data retrieval, specifically\ntargeting various study programs at a large technical university. We\nadditionally introduce a novel evaluation approach, the RAG Confusion Matrix\ndesigned to assess the effectiveness of various configurations within the RAG\nframework. By exploring the integration of both open-source (e.g., Llama2,\nMistral) and closed-source (GPT-3.5 and GPT-4) Large Language Models, we offer\nvaluable insights into the application and optimization of RAG frameworks in\ndomain-specific contexts. Our experiments show a significant performance\nincrease when including multi-query in the retrieval phase.",
      "tldr_zh": "本文评估了 Retrieval Augmented Generation (RAG) 在学术领域数据的优化应用，测试了 Multi-Query、Child-Parent-Retriever、Ensemble Retriever 和 In-Context-Learning 等四种优化技术，以提升数据检索性能。研究焦点针对大型技术大学的学习项目，并引入了新型评估方法 RAG Confusion Matrix 来评估不同 RAG 配置的有效性。通过整合开源模型（如 Llama2 和 Mistral）和闭源模型（如 GPT-3.5 和 GPT-4），实验发现，在检索阶段加入 Multi-Query 显著提高了整体性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08438v1",
      "published_date": "2024-11-13 08:43:37 UTC",
      "updated_date": "2024-11-13 08:43:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:15:31.397660"
    },
    {
      "arxiv_id": "2411.08433v1",
      "title": "3D Multi-Object Tracking with Semi-Supervised GRU-Kalman Filter",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoxiang Wang",
        "Jiaxin Liu",
        "Miaojie Feng",
        "Zhaoxing Zhang",
        "Xin Yang"
      ],
      "abstract": "3D Multi-Object Tracking (MOT), a fundamental component of environmental\nperception, is essential for intelligent systems like autonomous driving and\nrobotic sensing. Although Tracking-by-Detection frameworks have demonstrated\nexcellent performance in recent years, their application in real-world\nscenarios faces significant challenges. Object movement in complex environments\nis often highly nonlinear, while existing methods typically rely on linear\napproximations of motion. Furthermore, system noise is frequently modeled as a\nGaussian distribution, which fails to capture the true complexity of the noise\ndynamics. These oversimplified modeling assumptions can lead to significant\nreductions in tracking precision. To address this, we propose a GRU-based MOT\nmethod, which introduces a learnable Kalman filter into the motion module. This\napproach is able to learn object motion characteristics through data-driven\nlearning, thereby avoiding the need for manual model design and model error. At\nthe same time, to avoid abnormal supervision caused by the wrong association\nbetween annotations and trajectories, we design a semi-supervised learning\nstrategy to accelerate the convergence speed and improve the robustness of the\nmodel. Evaluation experiment on the nuScenes and Argoverse2 datasets\ndemonstrates that our system exhibits superior performance and significant\npotential compared to traditional TBD methods.",
      "tldr_zh": "本研究针对3D Multi-Object Tracking (MOT)中的非线性运动和噪声建模问题，提出了一种基于Semi-Supervised GRU-Kalman Filter的方法，以提升自动驾驶和机器人感知系统的跟踪精度。该方法将可学习的Kalman Filter融入GRU框架，通过数据驱动学习物体运动特性，避免了传统手动模型设计的误差，同时采用半监督学习策略来减少标注与轨迹关联的异常，提高模型的收敛速度和鲁棒性。在nuScenes和Argoverse2数据集上的实验表明，该系统相较于传统Tracking-by-Detection (TBD)方法表现出显著优势，展示了其在复杂环境中的潜力。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08433v1",
      "published_date": "2024-11-13 08:34:07 UTC",
      "updated_date": "2024-11-13 08:34:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:15:41.840643"
    },
    {
      "arxiv_id": "2411.08432v1",
      "title": "One STEP at a time: Language Agents are Stepwise Planners",
      "title_zh": "翻译失败",
      "authors": [
        "Minh Nguyen",
        "Ehsan Shareghi"
      ],
      "abstract": "Language agents have shown promising adaptability in dynamic environments to\nperform complex tasks. However, despite the versatile knowledge embedded in\nlarge language models, these agents still fall short when it comes to tasks\nthat require planning. We introduce STEP, a novel framework designed to\nefficiently learn from previous experiences to enhance the planning\ncapabilities of language agents in future steps. Concretely, STEP functions\nthrough four interconnected components. First, the Planner takes on the task,\nbreaks it down into subtasks and provides relevant insights. Then the Executor\ngenerates action candidates, while the Evaluator ensures the actions align with\nlearned rules from previous experiences. Lastly, Memory stores experiences to\ninform future decisions. In the ScienceWorld benchmark, our results show that\nSTEP consistently outperforms state-of-the-art models, achieving an overall\nscore of 67.4 and successfully completing 12 out of 18 tasks. These findings\nhighlight STEP's potential as a framework for enhancing planning capabilities\nin language agents, paving the way for more sophisticated task-solving in\ndynamic environments.",
      "tldr_zh": "语言代理在动态环境中表现出色，但其规划能力仍存在不足，本文引入 STEP 框架，通过从以往经验中学习来提升代理的规划功能。STEP 由四个组件组成：Planner 负责分解任务并提供见解、Executor 生成行动候选、Evaluator 确保行动符合学得规则，以及 Memory 存储经验以指导未来决策。在 ScienceWorld 基准测试中，STEP 超过了最先进模型，取得总体得分 67.4 并成功完成 18 个任务中的 12 个，展示了其在增强语言代理规划方面的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08432v1",
      "published_date": "2024-11-13 08:32:42 UTC",
      "updated_date": "2024-11-13 08:32:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:15:54.342181"
    },
    {
      "arxiv_id": "2411.08424v1",
      "title": "A Heterogeneous Graph Neural Network Fusing Functional and Structural Connectivity for MCI Diagnosis",
      "title_zh": "融合功能和结构连接的异构图神经网络用于 MCI 诊断",
      "authors": [
        "Feiyu Yin",
        "Yu Lei",
        "Siyuan Dai",
        "Wenwen Zeng",
        "Guoqing Wu",
        "Liang Zhan",
        "Jinhua Yu"
      ],
      "abstract": "Brain connectivity alternations associated with brain disorders have been\nwidely reported in resting-state functional imaging (rs-fMRI) and diffusion\ntensor imaging (DTI). While many dual-modal fusion methods based on graph\nneural networks (GNNs) have been proposed, they generally follow homogenous\nfusion ways ignoring rich heterogeneity of dual-modal information. To address\nthis issue, we propose a novel method that integrates functional and structural\nconnectivity based on heterogeneous graph neural networks (HGNNs) to better\nleverage the rich heterogeneity in dual-modal images. We firstly use blood\noxygen level dependency and whiter matter structure information provided by\nrs-fMRI and DTI to establish homo-meta-path, capturing node relationships\nwithin the same modality. At the same time, we propose to establish\nhetero-meta-path based on structure-function coupling and brain community\nsearching to capture relations among cross-modal nodes. Secondly, we further\nintroduce a heterogeneous graph pooling strategy that automatically balances\nhomo- and hetero-meta-path, effectively leveraging heterogeneous information\nand preventing feature confusion after pooling. Thirdly, based on the\nflexibility of heterogeneous graphs, we propose a heterogeneous graph data\naugmentation approach that can conveniently address the sample imbalance issue\ncommonly seen in clinical diagnosis. We evaluate our method on ADNI-3 dataset\nfor mild cognitive impairment (MCI) diagnosis. Experimental results indicate\nthe proposed method is effective and superior to other algorithms, with a mean\nclassification accuracy of 93.3%.",
      "tldr_zh": "本研究提出了一种基于异构图神经网络(HGNNs)的创新方法，用于融合rs-fMRI的功能连接和DTI的结构连接，以诊断轻度认知障碍(MCI)。该方法首先建立homo-meta-path和hetero-meta-path，分别捕捉同模态和跨模态节点关系，并引入异构图池化策略来平衡信息，同时通过异构图数据增强处理样本不平衡问题。实验在ADNI-3数据集上进行，结果显示该方法分类准确率达到93.3%，优于其他算法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08424v1",
      "published_date": "2024-11-13 08:17:52 UTC",
      "updated_date": "2024-11-13 08:17:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:16:06.874541"
    },
    {
      "arxiv_id": "2411.08418v1",
      "title": "Enhanced Classroom Dialogue Sequences Analysis with a Hybrid AI Agent: Merging Expert Rule-Base with Large Language Models",
      "title_zh": "使用混合 AI 代理增强课堂对话序列分析：合并专家规则库与大语言模型",
      "authors": [
        "Yun Long",
        "Yu Zhang"
      ],
      "abstract": "Classroom dialogue plays a crucial role in fostering student engagement and\ndeeper learning. However, analysing dialogue sequences has traditionally relied\non either theoretical frameworks or empirical descriptions of practice, with\nlimited integration between the two. This study addresses this gap by\ndeveloping a comprehensive rule base of dialogue sequences and an Artificial\nIntelligence (AI) agent that combines expert-informed rule-based systems with a\nlarge language model (LLM). The agent applies expert knowledge while adapting\nto the complexities of natural language, enabling accurate and flexible\ncategorisation of classroom dialogue sequences. By synthesising findings from\nover 30 studies, we established a comprehensive framework for dialogue\nanalysis. The agent was validated against human expert coding, achieving high\nlevels of precision and reliability. The results demonstrate that the agent\nprovides theory-grounded and adaptive functions, tremendously enhancing the\nefficiency and scalability of classroom dialogue analysis, offering significant\npotential in improving classroom teaching practices and supporting teacher\nprofessional development.",
      "tldr_zh": "本文提出了一种混合 AI 代理，用于增强课堂对话序列分析，该代理将专家规则库 (expert rule-base) 与大型语言模型 (LLM) 相结合，解决传统分析中理论与经验整合不足的问题。通过综合 30 多个研究的发现，建立了一个全面的对话分析框架，实现对自然语言的准确分类和适应。实验验证显示，该代理在精度和可靠性上与人类专家编码相当，大大提高了分析效率和可扩展性，并为改善课堂教学实践和支持教师专业发展提供了重要潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08418v1",
      "published_date": "2024-11-13 08:13:41 UTC",
      "updated_date": "2024-11-13 08:13:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:16:18.618170"
    },
    {
      "arxiv_id": "2411.08414v1",
      "title": "Material Property Prediction with Element Attribute Knowledge Graphs and Multimodal Representation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Chao Huang",
        "Chunyan Chen",
        "Ling Shi",
        "Chen Chen"
      ],
      "abstract": "Machine learning has become a crucial tool for predicting the properties of\ncrystalline materials. However, existing methods primarily represent material\ninformation by constructing multi-edge graphs of crystal structures, often\noverlooking the chemical and physical properties of elements (such as atomic\nradius, electronegativity, melting point, and ionization energy), which have a\nsignificant impact on material performance. To address this limitation, we\nfirst constructed an element property knowledge graph and utilized an embedding\nmodel to encode the element attributes within the knowledge graph. Furthermore,\nwe propose a multimodal fusion framework, ESNet, which integrates element\nproperty features with crystal structure features to generate joint multimodal\nrepresentations. This provides a more comprehensive perspective for predicting\nthe performance of crystalline materials, enabling the model to consider both\nmicrostructural composition and chemical characteristics of the materials. We\nconducted experiments on the Materials Project benchmark dataset, which showed\nleading performance in the bandgap prediction task and achieved results on a\npar with existing benchmarks in the formation energy prediction task.",
      "tldr_zh": "本文研究了利用元素属性知识图和多模态表示学习来预测材料性能的问题，解决了现有方法忽略元素化学和物理属性（如原子半径、电负性、熔点和ionization energy）的局限性。作者首先构建了element property knowledge graph，并使用embedding model对其进行编码，然后提出ESNet框架，通过multimodal fusion整合元素属性特征与晶体结构特征，生成更全面的材料表示。实验结果显示，在Materials Project基准数据集上，ESNet在bandgap prediction任务中表现出色，并在formation energy prediction任务中达到与现有基准相当的水平。",
      "categories": [
        "cs.LG",
        "cond-mat.mtrl-sci",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08414v1",
      "published_date": "2024-11-13 08:07:21 UTC",
      "updated_date": "2024-11-13 08:07:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:16:30.426754"
    },
    {
      "arxiv_id": "2411.10480v1",
      "title": "Hateful Meme Detection through Context-Sensitive Prompting and Fine-Grained Labeling",
      "title_zh": "翻译失败",
      "authors": [
        "Rongxin Ouyang",
        "Kokil Jaidka",
        "Subhayan Mukerjee",
        "Guangyu Cui"
      ],
      "abstract": "The prevalence of multi-modal content on social media complicates automated\nmoderation strategies. This calls for an enhancement in multi-modal\nclassification and a deeper understanding of understated meanings in images and\nmemes. Although previous efforts have aimed at improving model performance\nthrough fine-tuning, few have explored an end-to-end optimization pipeline that\naccounts for modalities, prompting, labeling, and fine-tuning. In this study,\nwe propose an end-to-end conceptual framework for model optimization in complex\ntasks. Experiments support the efficacy of this traditional yet novel\nframework, achieving the highest accuracy and AUROC. Ablation experiments\ndemonstrate that isolated optimizations are not ineffective on their own.",
      "tldr_zh": "这篇论文针对社交媒体上多模态内容的仇恨模因检测（Hateful Meme Detection），提出一个端到端的概念框架，结合上下文敏感提示（Context-Sensitive Prompting）和细粒度标签（Fine-Grained Labeling），以提升对图像和模因中隐含含义的理解。框架优化了模态处理、提示、标签和微调等环节，通过实验验证在复杂任务中实现了最高的准确率和 AUROC。消融实验进一步证明，孤立的优化策略无法单独生效，强调了整体管道的必要性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.MM",
        "68T45, 68T50, 68T07",
        "I.2.10; I.2.7; I.2.6"
      ],
      "primary_category": "cs.CV",
      "comment": "AAAI-25 Student Abstract, Oral Presentation",
      "pdf_url": "http://arxiv.org/pdf/2411.10480v1",
      "published_date": "2024-11-13 08:05:41 UTC",
      "updated_date": "2024-11-13 08:05:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:16:42.498684"
    },
    {
      "arxiv_id": "2411.08409v1",
      "title": "DiVR: incorporating context from diverse VR scenes for human trajectory prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Franz Franco Gallo",
        "Hui-Yin Wu",
        "Lucile Sassatelli"
      ],
      "abstract": "Virtual environments provide a rich and controlled setting for collecting\ndetailed data on human behavior, offering unique opportunities for predicting\nhuman trajectories in dynamic scenes. However, most existing approaches have\noverlooked the potential of these environments, focusing instead on static\ncontexts without considering userspecific factors. Employing the CREATTIVE3D\ndataset, our work models trajectories recorded in virtual reality (VR) scenes\nfor diverse situations including road-crossing tasks with user interactions and\nsimulated visual impairments. We propose Diverse Context VR Human Motion\nPrediction (DiVR), a cross-modal transformer based on the Perceiver\narchitecture that integrates both static and dynamic scene context using a\nheterogeneous graph convolution network. We conduct extensive experiments\ncomparing DiVR against existing architectures including MLP, LSTM, and\ntransformers with gaze and point cloud context. Additionally, we also stress\ntest our model's generalizability across different users, tasks, and scenes.\nResults show that DiVR achieves higher accuracy and adaptability compared to\nother models and to static graphs. This work highlights the advantages of using\nVR datasets for context-aware human trajectory modeling, with potential\napplications in enhancing user experiences in the metaverse. Our source code is\npublicly available at https://gitlab.inria.fr/ffrancog/creattive3d-divr-model.",
      "tldr_zh": "本研究针对人类轨迹预测问题，利用虚拟现实(VR)环境中的丰富数据，提出DiVR模型，以解决现有方法忽略用户特定因素和动态上下文的局限。DiVR基于Perceiver架构的跨模态transformer，整合静态和动态场景上下文，通过异构图卷积网络(heterogeneous graph convolution network)处理CREATTIVE3D数据集中的多样场景，如道路穿越任务和模拟视觉障碍。实验结果显示，DiVR在与MLP、LSTM和transformer等基线模型的比较中，实现了更高的准确性和适应性，并在不同用户、任务和场景中表现出色。该框架突显了VR数据集在上下文感知轨迹建模中的优势，有望应用于元宇宙的用户体验增强。",
      "categories": [
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08409v1",
      "published_date": "2024-11-13 07:55:41 UTC",
      "updated_date": "2024-11-13 07:55:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:17:40.497955"
    },
    {
      "arxiv_id": "2411.08400v1",
      "title": "BAMAX: Backtrack Assisted Multi-Agent Exploration using Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Geetansh Kalra",
        "Amit Patel",
        "Atul Chaudhari",
        "Divye Singh"
      ],
      "abstract": "Autonomous robots collaboratively exploring an unknown environment is still\nan open problem. The problem has its roots in coordination among non-stationary\nagents, each with only a partial view of information. The problem is compounded\nwhen the multiple robots must completely explore the environment. In this\npaper, we introduce Backtrack Assisted Multi-Agent Exploration using\nReinforcement Learning (BAMAX), a method for collaborative exploration in\nmulti-agent systems which attempts to explore an entire virtual environment. As\nin the name, BAMAX leverages backtrack assistance to enhance the performance of\nagents in exploration tasks. To evaluate BAMAX against traditional approaches,\nwe present the results of experiments conducted across multiple hexagonal\nshaped grids sizes, ranging from 10x10 to 60x60. The results demonstrate that\nBAMAX outperforms other methods in terms of faster coverage and less\nbacktracking across these environments.",
      "tldr_zh": "该研究提出了一种名为 BAMAX 的方法，利用强化学习（Reinforcement Learning）辅助多智能体协作探索未知环境，解决代理间协调和部分信息限制的问题。BAMAX 通过回溯辅助（Backtrack Assisted）机制提升探索效率，确保全面覆盖环境。实验结果显示，在从 10x10 到 60x60 的六角形网格环境中，BAMAX 比传统方法实现了更快覆盖和更少的回溯操作。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08400v1",
      "published_date": "2024-11-13 07:38:24 UTC",
      "updated_date": "2024-11-13 07:38:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:17:50.818897"
    },
    {
      "arxiv_id": "2411.08392v1",
      "title": "RLInspect: An Interactive Visual Approach to Assess Reinforcement Learning Algorithm",
      "title_zh": "翻译失败",
      "authors": [
        "Geetansh Kalra",
        "Divye Singh",
        "Justin Jose"
      ],
      "abstract": "Reinforcement Learning (RL) is a rapidly growing area of machine learning\nthat finds its application in a broad range of domains, from finance and\nhealthcare to robotics and gaming. Compared to other machine learning\ntechniques, RL agents learn from their own experiences using trial and error,\nand improve their performance over time. However, assessing RL models can be\nchallenging, which makes it difficult to interpret their behaviour. While\nreward is a widely used metric to evaluate RL models, it may not always provide\nan accurate measure of training performance. In some cases, the reward may seem\nincreasing while the model's performance is actually decreasing, leading to\nmisleading conclusions about the effectiveness of the training. To overcome\nthis limitation, we have developed RLInspect - an interactive visual analytic\ntool, that takes into account different components of the RL model - state,\naction, agent architecture and reward, and provides a more comprehensive view\nof the RL training. By using RLInspect, users can gain insights into the\nmodel's behaviour, identify issues during training, and potentially correct\nthem effectively, leading to a more robust and reliable RL system.",
      "tldr_zh": "强化学习 (RL) 在评估模型时面临挑战，因为奖励指标可能误导性强，导致性能下降时奖励却在增加。论文提出 RLInspect，一种交互式可视化分析工具，该工具整合状态、动作、代理架构和奖励等组件，提供对 RL 训练过程的全面视图。通过 RLInspect，用户可以深入洞察模型行为、及时识别训练问题并进行有效修正，从而构建更可靠的 RL 系统。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08392v1",
      "published_date": "2024-11-13 07:24:14 UTC",
      "updated_date": "2024-11-13 07:24:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:18:03.060258"
    },
    {
      "arxiv_id": "2411.08378v1",
      "title": "Physics Informed Distillation for Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Joshua Tian Jin Tee",
        "Kang Zhang",
        "Hee Suk Yoon",
        "Dhananjaya Nagaraja Gowda",
        "Chanwoo Kim",
        "Chang D. Yoo"
      ],
      "abstract": "Diffusion models have recently emerged as a potent tool in generative\nmodeling. However, their inherent iterative nature often results in sluggish\nimage generation due to the requirement for multiple model evaluations. Recent\nprogress has unveiled the intrinsic link between diffusion models and\nProbability Flow Ordinary Differential Equations (ODEs), thus enabling us to\nconceptualize diffusion models as ODE systems. Simultaneously, Physics Informed\nNeural Networks (PINNs) have substantiated their effectiveness in solving\nintricate differential equations through implicit modeling of their solutions.\nBuilding upon these foundational insights, we introduce Physics Informed\nDistillation (PID), which employs a student model to represent the solution of\nthe ODE system corresponding to the teacher diffusion model, akin to the\nprinciples employed in PINNs. Through experiments on CIFAR 10 and ImageNet\n64x64, we observe that PID achieves performance comparable to recent\ndistillation methods. Notably, it demonstrates predictable trends concerning\nmethod-specific hyperparameters and eliminates the need for synthetic dataset\ngeneration during the distillation process. Both of which contribute to its\neasy-to-use nature as a distillation approach for Diffusion Models. Our code\nand pre-trained checkpoint are publicly available at:\nhttps://github.com/pantheon5100/pid_diffusion.git.",
      "tldr_zh": "本研究针对 Diffusion models 在生成建模中的生成速度慢问题，提出 Physics Informed Distillation (PID) 方法，将 Diffusion models 视为 Probability Flow Ordinary Differential Equations (ODEs) 系统，并使用学生模型模拟其解，借鉴 Physics Informed Neural Networks (PINNs) 的原理进行知识蒸馏。PID 在 CIFAR 10 和 ImageNet 64x64 数据集上实验显示，其性能与现有蒸馏方法相当，同时展现出可预测的超参数趋势。相比传统方法，PID 无需生成合成数据集，显著提高了易用性，为高效的 Diffusion models 优化提供了实用途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08378v1",
      "published_date": "2024-11-13 07:03:47 UTC",
      "updated_date": "2024-11-13 07:03:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:18:15.546106"
    },
    {
      "arxiv_id": "2411.08375v1",
      "title": "Developing an Effective Training Dataset to Enhance the Performance of AI-based Speaker Separation Systems",
      "title_zh": "开发有效的训练数据集以提升基于AI的说话人分离系统的性能",
      "authors": [
        "Rawad Melhem",
        "Assef Jafar",
        "Oumayma Al Dakkak"
      ],
      "abstract": "This paper addresses the challenge of speaker separation, which remains an\nactive research topic despite the promising results achieved in recent years.\nThese results, however, often degrade in real recording conditions due to the\npresence of noise, echo, and other interferences. This is because neural models\nare typically trained on synthetic datasets consisting of mixed audio signals\nand their corresponding ground truths, which are generated using computer\nsoftware and do not fully represent the complexities of real-world recording\nscenarios. The lack of realistic training sets for speaker separation remains a\nmajor hurdle, as obtaining individual sounds from mixed audio signals is a\nnontrivial task. To address this issue, we propose a novel method for\nconstructing a realistic training set that includes mixture signals and\ncorresponding ground truths for each speaker. We evaluate this dataset on a\ndeep learning model and compare it to a synthetic dataset. We got a 1.65 dB\nimprovement in Scale Invariant Signal to Distortion Ratio (SI-SDR) for speaker\nseparation accuracy in realistic mixing. Our findings highlight the potential\nof realistic training sets for enhancing the performance of speaker separation\nmodels in real-world scenarios.",
      "tldr_zh": "本文针对 AI 基于的说话者分离（speaker separation）系统在真实录音条件下因噪声和干扰而性能下降的问题，提出了一种构建现实训练数据集的新方法。该方法通过生成包括混合信号和每个说话者的对应 ground truths 的数据集，模拟真实世界场景的复杂性。在深度学习模型上的实验显示，与合成数据集相比，使用新数据集的 SI-SDR 提高了 1.65 dB。研究结果强调了现实训练集在提升说话者分离模型真实场景性能方面的潜力。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "in Arabic language",
      "pdf_url": "http://arxiv.org/pdf/2411.08375v1",
      "published_date": "2024-11-13 06:55:18 UTC",
      "updated_date": "2024-11-13 06:55:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:18:27.972600"
    },
    {
      "arxiv_id": "2411.08370v1",
      "title": "A Fuzzy Reinforcement LSTM-based Long-term Prediction Model for Fault Conditions in Nuclear Power Plants",
      "title_zh": "基于模糊强化 LSTM 的核电站故障条件长期预测模型",
      "authors": [
        "Siwei Li",
        "Jiayan Fang",
        "Yichun Wua",
        "Wei Wang",
        "Chengxin Li",
        "Jiangwen Chen"
      ],
      "abstract": "Early fault detection and timely maintenance scheduling can significantly\nmitigate operational risks in NPPs and enhance the reliability of operator\ndecision-making. Therefore, it is necessary to develop an efficient Prognostics\nand Health Management (PHM) multi-step prediction model for predicting of\nsystem health status and prompt execution of maintenance operations. In this\nstudy, we propose a novel predictive model that integrates reinforcement\nlearning with Long Short-Term Memory (LSTM) neural networks and the Expert\nFuzzy Evaluation Method. The model is validated using parameter data for 20\ndifferent breach sizes in the Main Steam Line Break (MSLB) accident condition\nof the CPR1000 pressurized water reactor simulation model and it demonstrates a\nremarkable capability in accurately forecasting NPP parameter changes up to 128\nsteps ahead (with a time interval of 10 seconds per step, i.e., 1280 seconds),\nthereby satisfying the temporal advance requirement for fault prognostics in\nNPPs. Furthermore, this method provides an effective reference solution for PHM\napplications such as anomaly detection and remaining useful life prediction.",
      "tldr_zh": "这篇论文提出了一种结合强化学习(Reinforcement Learning)、LSTM 神经网络和专家模糊评估方法(Expert Fuzzy Evaluation Method)的长期预测模型，用于核电站(NPPs)的故障条件预测，以提升早期故障检测和维护调度。模型通过对 CPR1000 压水反应堆的 Main Steam Line Break (MSLB) 事故数据进行验证，能够准确预测参数变化长达 128 步（每步 10 秒，共 1280 秒），满足故障预知的时效要求。实验结果表明，该方法显著提高了 Prognostics and Health Management (PHM) 的可靠性，并为异常检测和剩余寿命预测等应用提供了有效的参考方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08370v1",
      "published_date": "2024-11-13 06:40:17 UTC",
      "updated_date": "2024-11-13 06:40:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:18:40.081894"
    },
    {
      "arxiv_id": "2411.08367v1",
      "title": "Surprisingly Popular Voting for Concentric Rank-Order Models",
      "title_zh": "翻译失败",
      "authors": [
        "Hadi Hosseini",
        "Debmalya Mandal",
        "Amrit Puhan"
      ],
      "abstract": "An important problem on social information sites is the recovery of ground\ntruth from individual reports when the experts are in the minority. The wisdom\nof the crowd, i.e. the collective opinion of a group of individuals fails in\nsuch a scenario. However, the surprisingly popular (SP)\nalgorithm~\\cite{prelec2017solution} can recover the ground truth even when the\nexperts are in the minority, by asking the individuals to report additional\nprediction reports--their beliefs about the reports of others. Several recent\nworks have extended the surprisingly popular algorithm to an equivalent voting\nrule (SP-voting) to recover the ground truth ranking over a set of $m$\nalternatives. However, we are yet to fully understand when SP-voting can\nrecover the ground truth ranking, and if so, how many samples (votes and\npredictions) it needs. We answer this question by proposing two rank-order\nmodels and analyzing the sample complexity of SP-voting under these models. In\nparticular, we propose concentric mixtures of Mallows and Plackett-Luce models\nwith $G (\\ge 2)$ groups. Our models generalize previously proposed concentric\nmixtures of Mallows models with $2$ groups, and we highlight the importance of\n$G > 2$ groups by identifying three distinct groups (expert, intermediate, and\nnon-expert) from existing datasets. Next, we provide conditions on the\nparameters of the underlying models so that SP-voting can recover ground-truth\nrankings with high probability, and also derive sample complexities under the\nsame. We complement the theoretical results by evaluating SP-voting on\nsimulated and real datasets.",
      "tldr_zh": "该研究探讨了在社会信息平台上，当专家处于少数时，从个体报告中恢复真实排序的问题，Surprisingly Popular (SP) 算法通过让个体预测他人报告来解决这一挑战。作者提出两种新的 rank-order 模型，即具有 G (≥2) 组的 concentric mixtures of Mallows 和 Plackett-Luce 模型，这些模型扩展了之前的框架，并通过实际数据集识别出专家、中间和非专家等多个组别。研究分析了 SP-voting 在这些模型下的样本复杂度，提供条件以高概率恢复真实排名，并通过模拟和真实数据集的实验验证其有效性。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08367v1",
      "published_date": "2024-11-13 06:32:17 UTC",
      "updated_date": "2024-11-13 06:32:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:18:51.850761"
    },
    {
      "arxiv_id": "2411.08347v1",
      "title": "A Chinese Multi-label Affective Computing Dataset Based on Social Media Network Users",
      "title_zh": "基于社交媒体网络用户的中文多标签情感计算数据集",
      "authors": [
        "Jingyi Zhou",
        "Senlin Luo",
        "Haofan Chen"
      ],
      "abstract": "Emotion and personality are central elements in understanding human\npsychological states. Emotions reflect an individual subjective experiences,\nwhile personality reveals relatively stable behavioral and cognitive patterns.\nExisting affective computing datasets often annotate emotion and personality\ntraits separately, lacking fine-grained labeling of micro-emotions and emotion\nintensity in both single-label and multi-label classifications. Chinese emotion\ndatasets are extremely scarce, and datasets capturing Chinese user personality\ntraits are even more limited. To address these gaps, this study collected data\nfrom the major social media platform Weibo, screening 11,338 valid users from\nover 50,000 individuals with diverse MBTI personality labels and acquiring\n566,900 posts along with the user MBTI personality tags. Using the EQN method,\nwe compiled a multi-label Chinese affective computing dataset that integrates\nthe same user's personality traits with six emotions and micro-emotions, each\nannotated with intensity levels. Validation results across multiple NLP\nclassification models demonstrate the dataset strong utility. This dataset is\ndesigned to advance machine recognition of complex human emotions and provide\ndata support for research in psychology, education, marketing, finance, and\npolitics.",
      "tldr_zh": "本研究针对现有情感计算数据集的不足（如缺乏细粒度微情感和强度标注，以及中文数据集的稀缺），构建了一个基于微博的多标签中文情感计算数据集。研究从超过50,000个用户中筛选出11,338个有效用户，收集了566,900个帖子及其MBTI个性标签，并使用EQN方法整合了用户的个性特征、六种情感和微情感，每个标注了强度级别。实验验证显示，该数据集在多个NLP分类模型上表现出色，可支持心理学、教育、营销、金融和政治等领域的研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08347v1",
      "published_date": "2024-11-13 05:38:55 UTC",
      "updated_date": "2024-11-13 05:38:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:19:04.093783"
    },
    {
      "arxiv_id": "2411.08341v1",
      "title": "Generative AI for Data Augmentation in Wireless Networks: Analysis, Applications, and Case Study",
      "title_zh": "生成式人工智能在无线网络中的数据增强：分析、应用和案例研究",
      "authors": [
        "Jinbo Wen",
        "Jiawen Kang",
        "Dusit Niyato",
        "Yang Zhang",
        "Jiacheng Wang",
        "Biplab Sikdar",
        "Ping Zhang"
      ],
      "abstract": "Data augmentation is a powerful technique to mitigate data scarcity. However,\nowing to fundamental differences in wireless data structures, traditional data\naugmentation techniques may not be suitable for wireless data. Fortunately,\nGenerative Artificial Intelligence (GenAI) can be an effective alternative to\nwireless data augmentation due to its excellent data generation capability.\nThis article systemically explores the potential and effectiveness of\nGenAI-driven data augmentation in wireless networks. We first briefly review\ndata augmentation techniques, discuss their limitations in wireless networks,\nand introduce generative data augmentation, including reviewing GenAI models\nand their applications in data augmentation. We then explore the application\nprospects of GenAI-driven data augmentation in wireless networks from the\nphysical, network, and application layers, which provides a GenAI-driven data\naugmentation architecture for each application. Subsequently, we propose a\ngeneral generative diffusion model-based data augmentation framework for Wi-Fi\ngesture recognition, which uses transformer-based diffusion models to generate\nhigh-quality channel state information data. Furthermore, we develop residual\nneural network models for Wi-Fi gesture recognition to evaluate the role of\naugmented data and conduct a case study based on a real dataset. Simulation\nresults demonstrate the effectiveness of the proposed framework. Finally, we\ndiscuss research directions for generative data augmentation.",
      "tldr_zh": "这篇论文探讨了Generative AI (GenAI) 在无线网络数据增强中的潜力，以解决传统数据增强技术因无线数据结构独特而导致的局限性。作者系统回顾了数据增强方法，引入GenAI模型及其在无线网络物理、网络和应用层的应用前景，并提出一个基于生成扩散模型的框架，用于Wi-Fi gesture recognition 生成高质量的信道状态信息数据。通过残差神经网络模型的案例研究，实验结果显示该框架提升了识别准确率，并证明了其有效性。最后，论文讨论了生成式数据增强的未来研究方向。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08341v1",
      "published_date": "2024-11-13 05:15:25 UTC",
      "updated_date": "2024-11-13 05:15:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:19:16.487884"
    },
    {
      "arxiv_id": "2411.08335v1",
      "title": "DEEGITS: Deep Learning based Framework for Measuring Heterogenous Traffic State in Challenging Traffic Scenarios",
      "title_zh": "翻译失败",
      "authors": [
        "Muttahirul Islam",
        "Nazmul Haque",
        "Md. Hadiuzzaman"
      ],
      "abstract": "This paper presents DEEGITS (Deep Learning Based Heterogeneous Traffic State\nMeasurement), a comprehensive framework that leverages state-of-the-art\nconvolutional neural network (CNN) techniques to accurately and rapidly detect\nvehicles and pedestrians, as well as to measure traffic states in challenging\nscenarios (i.e., congestion, occlusion). In this study, we enhance the training\ndataset through data fusion, enabling simultaneous detection of vehicles and\npedestrians. Image preprocessing and augmentation are subsequently performed to\nimprove the quality and quantity of the dataset. Transfer learning is applied\non the YOLOv8 pretrained model to increase the model's capability to identify a\ndiverse array of vehicles. Optimal hyperparameters are obtained using the Grid\nSearch algorithm, with the Stochastic Gradient Descent (SGD) optimizer\noutperforming other optimizers under these settings. Extensive experimentation\nand evaluation demonstrate substantial accuracy within the detection framework,\nwith the model achieving 0.794 mAP@0.5 on the validation set and 0.786 mAP@0.5\non the test set, surpassing previous benchmarks on similar datasets. The\nDeepSORT multi-object tracking algorithm is incorporated to track detected\nvehicles and pedestrians in this study. Finally, the framework is tested to\nmeasure heterogeneous traffic states in mixed traffic conditions. Two locations\nwith differing traffic compositions and congestion levels are selected: one\nmotorized-dominant location with moderate density and one\nnon-motorized-dominant location with higher density. Errors are statistically\ninsignificant for both cases, showing correlations from 0.99 to 0.88 and 0.91\nto 0.97 for heterogeneous traffic flow and speed measurements, respectively.",
      "tldr_zh": "这篇论文介绍了 DEEGITS 框架，这是一个基于深度学习的系统，利用先进的 CNN 技术来准确检测车辆和行人，并测量异构交通状态，尤其在拥堵和遮挡等挑战场景中。框架通过数据融合增强训练数据集、图像预处理和增强、YOLOv8 的迁移学习、Grid Search 优化超参数以及 SGD 优化器来提升检测能力，并整合 DeepSORT 算法进行多对象跟踪。实验结果显示，模型在验证集和测试集上分别达到 0.794 mAP@0.5 和 0.786 mAP@0.5 的准确率，并在实际混合交通条件下表现出色，相关性高达 0.99 到 0.88，为异构交通状态测量提供了可靠的基准。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Submitted for presentation at the 103 rd Annual Meeting of\n  Transportation Research Board and publication in Transportation Research\n  Record: Journal of Transportation Research Board",
      "pdf_url": "http://arxiv.org/pdf/2411.08335v1",
      "published_date": "2024-11-13 04:49:32 UTC",
      "updated_date": "2024-11-13 04:49:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:19:29.202799"
    },
    {
      "arxiv_id": "2411.08334v2",
      "title": "MIRe: Enhancing Multimodal Queries Representation via Fusion-Free Modality Interaction for Multimodal Retrieval",
      "title_zh": "MIRe：通过无融合多模态交互增强多模态查询表示用于多模态检索",
      "authors": [
        "Yeong-Joon Ju",
        "Ho-Joong Kim",
        "Seong-Whan Lee"
      ],
      "abstract": "Recent multimodal retrieval methods have endowed text-based retrievers with\nmultimodal capabilities by utilizing pre-training strategies for visual-text\nalignment. They often directly fuse the two modalities for cross-reference\nduring the alignment to understand multimodal queries. However, existing\nmethods often overlook crucial visual information due to a text-dominant issue,\nwhich overly depends on text-driven signals. In this paper, we introduce MIRe,\na retrieval framework that achieves modality interaction without fusing textual\nfeatures during the alignment. Our method allows the textual query to attend to\nvisual embeddings while not feeding text-driven signals back into the visual\nrepresentations. Additionally, we construct a pre-training dataset for\nmultimodal query retrieval by transforming concise question-answer pairs into\nextended passages. Our experiments demonstrate that our pre-training strategy\nsignificantly enhances the understanding of multimodal queries, resulting in\nstrong performance across four multimodal retrieval benchmarks under zero-shot\nsettings. Our code is publicly available: https://github.com/yeongjoonJu/MIRe.",
      "tldr_zh": "本文提出 MIRe 框架，用于提升多模态检索中的查询表示，通过 Fusion-Free Modality Interaction 实现模态交互，避免直接融合文本特征导致的文本主导问题，从而更好地保留视觉信息。MIRe 允许文本查询关注视觉嵌入，而不将文本信号反馈到视觉表示中，同时构建了一个预训练数据集，将简洁的问答对转化为扩展段落，以增强多模态查询理解。实验结果显示，该方法在零样本设置下，在四个多模态检索基准上显著提升性能，证明了其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.IR",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "preprint",
      "pdf_url": "http://arxiv.org/pdf/2411.08334v2",
      "published_date": "2024-11-13 04:32:58 UTC",
      "updated_date": "2025-02-17 01:49:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:19:39.441092"
    },
    {
      "arxiv_id": "2411.08324v1",
      "title": "Are LLMs Prescient? A Continuous Evaluation using Daily News as the Oracle",
      "title_zh": "翻译失败",
      "authors": [
        "Hui Dai",
        "Ryan Teehan",
        "Mengye Ren"
      ],
      "abstract": "Many existing evaluation benchmarks for Large Language Models (LLMs) quickly\nbecome outdated due to the emergence of new models and training data. These\nbenchmarks also fall short in assessing how LLM performance changes over time,\nas they consist of static questions without a temporal dimension. To address\nthese limitations, we propose using future event prediction as a continuous\nevaluation method to assess LLMs' temporal generalization and forecasting\nabilities. Our benchmark, Daily Oracle, automatically generates question-answer\n(QA) pairs from daily news, challenging LLMs to predict \"future\" event\noutcomes. Our findings reveal that as pre-training data becomes outdated, LLM\nperformance degrades over time. While Retrieval Augmented Generation (RAG) has\nthe potential to enhance prediction accuracy, the performance degradation\npattern persists, highlighting the need for continuous model updates.",
      "tldr_zh": "这篇论文探讨了大型语言模型（LLMs）的预测能力，提出使用未来事件预测作为一种连续评估方法，以克服现有静态基准的局限性。研究者开发了Daily Oracle基准，通过从每日新闻自动生成QA对，让LLMs预测“未来”事件结果，从而评估其时间泛化能力和预测性能。实验发现，随着预训练数据的过时，LLMs的性能会逐渐下降；虽然Retrieval Augmented Generation（RAG）能部分提升准确性，但下降趋势持续存在，突显出模型需要定期更新的必要性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08324v1",
      "published_date": "2024-11-13 04:20:20 UTC",
      "updated_date": "2024-11-13 04:20:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:19:51.383082"
    },
    {
      "arxiv_id": "2411.08320v1",
      "title": "Responsible AI in Construction Safety: Systematic Evaluation of Large Language Models and Prompt Engineering",
      "title_zh": "建筑安全中的负责任 AI：大型语言模型和提示工程的系统评估",
      "authors": [
        "Farouq Sammour",
        "Jia Xu",
        "Xi Wang",
        "Mo Hu",
        "Zhenyu Zhang"
      ],
      "abstract": "Construction remains one of the most hazardous sectors. Recent advancements\nin AI, particularly Large Language Models (LLMs), offer promising opportunities\nfor enhancing workplace safety. However, responsible integration of LLMs\nrequires systematic evaluation, as deploying them without understanding their\ncapabilities and limitations risks generating inaccurate information, fostering\nmisplaced confidence, and compromising worker safety. This study evaluates the\nperformance of two widely used LLMs, GPT-3.5 and GPT-4o, across three\nstandardized exams administered by the Board of Certified Safety Professionals\n(BCSP). Using 385 questions spanning seven safety knowledge areas, the study\nanalyzes the models' accuracy, consistency, and reliability. Results show that\nboth models consistently exceed the BCSP benchmark, with GPT-4o achieving an\naccuracy rate of 84.6% and GPT-3.5 reaching 73.8%. Both models demonstrate\nstrengths in safety management systems and hazard identification and control,\nbut exhibit weaknesses in science, mathematics, emergency response, and fire\nprevention. An error analysis identifies four primary limitations affecting LLM\nperformance: lack of knowledge, reasoning flaws, memory issues, and calculation\nerrors. Our study also highlights the impact of prompt engineering strategies,\nwith variations in accuracy reaching 13.5% for GPT-3.5 and 7.9% for GPT-4o.\nHowever, no single prompt configuration proves universally effective. This\nresearch advances knowledge in three ways: by identifying areas where LLMs can\nsupport safety practices and where human oversight remains essential, by\noffering practical insights into improving LLM implementation through prompt\nengineering, and by providing evidence-based direction for future research and\ndevelopment. These contributions support the responsible integration of AI in\nconstruction safety management toward achieving zero injuries.",
      "tldr_zh": "这篇论文系统评估了 Large Language Models (LLMs) 如 GPT-3.5 和 GPT-4o 在建筑安全领域的性能，使用 Board of Certified Safety Professionals (BCSP) 的 385 个考试问题，覆盖七个安全知识领域。结果显示，GPT-4o 准确率达 84.6%，GPT-3.5 为 73.8%，两者在安全管理系统和风险识别与控制方面表现出色，但存在科学、数学、紧急响应和防火的弱点，主要受知识缺失、推理错误、记忆问题和计算错误影响。研究还探讨了 Prompt Engineering 的作用，发现其可使准确率变化高达 13.5%（GPT-3.5）和 7.9%（GPT-4o），并为负责任 AI 在建筑安全中的整合提供指导，包括识别 LLMs 支持的领域和需要人类监督的方面，以推动零伤亡目标。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "29 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.08320v1",
      "published_date": "2024-11-13 04:06:09 UTC",
      "updated_date": "2024-11-13 04:06:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:20:05.216907"
    },
    {
      "arxiv_id": "2411.08932v3",
      "title": "PyGen: A Collaborative Human-AI Approach to Python Package Creation",
      "title_zh": "PyGen：一种协作式人类-AI 方法用于 Python 包创建",
      "authors": [
        "Saikat Barua",
        "Mostafizur Rahman",
        "Md Jafor Sadek",
        "Rafiul Islam",
        "Shehenaz Khaled",
        "Md. Shohrab Hossain"
      ],
      "abstract": "The principles of automation and innovation serve as foundational elements\nfor advancement in contemporary science and technology. Here, we introduce\nPygen, an automation platform designed to empower researchers, technologists,\nand hobbyists to bring abstract ideas to life as core, usable software tools\nwritten in Python. Pygen leverages the immense power of autoregressive large\nlanguage models to augment human creativity during the ideation, iteration, and\ninnovation process. By combining state-of-the-art language models with\nopen-source code generation technologies, Pygen has significantly reduced the\nmanual overhead of tool development. From a user prompt, Pygen automatically\ngenerates Python packages for a complete workflow from concept to package\ngeneration and documentation. The findings of our work show that Pygen\nconsiderably enhances the researcher's productivity by enabling the creation of\nresilient, modular, and well-documented packages for various specialized\npurposes. We employ a prompt enhancement approach to distill the user's package\ndescription into increasingly specific and actionable. While being inherently\nan open-ended task, we have evaluated the generated packages and the\ndocumentation using Human Evaluation, LLM-based evaluation, and CodeBLEU, with\ndetailed results in the results section. Furthermore, we documented our\nresults, analyzed the limitations, and suggested strategies to alleviate them.\nPygen is our vision of ethical automation, a framework that promotes\ninclusivity, accessibility, and collaborative development. This project marks\nthe beginning of a large-scale effort towards creating tools where intelligent\nagents collaborate with humans to improve scientific and technological\ndevelopment substantially.\n  Our code and generated examples are open-sourced at\n[https://github.com/GitsSaikat/Pygen]",
      "tldr_zh": "本文介绍了 PyGen，一种基于人类-AI 协作的自动化平台，利用 autoregressive large language models 和 open-source code generation 技术，帮助用户从抽象想法快速生成完整的 Python 包，包括代码和文档。PyGen 通过 prompt enhancement 方法，将用户描述转化为更具体、可操作的指令，从而显著减少手动开发工作量，并提升研究者的生产力。实验评估采用 Human Evaluation、LLM-based evaluation 和 CodeBLEU，结果显示生成的包在模块化和可靠性方面表现出色。该平台强调 ethical automation，促进 inclusivity、accessibility 和协作发展，并已开源在 GitHub。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "33 pages, 13 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.08932v3",
      "published_date": "2024-11-13 03:16:18 UTC",
      "updated_date": "2025-03-11 09:05:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:20:15.429988"
    },
    {
      "arxiv_id": "2411.08307v2",
      "title": "PerceiverS: A Multi-Scale Perceiver with Effective Segmentation for Long-Term Expressive Symbolic Music Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Yungang Yi",
        "Weihua Li",
        "Matthew Kuo",
        "Quan Bai"
      ],
      "abstract": "AI-based music generation has progressed significantly in recent years.\nHowever, creating symbolic music that is both long-structured and expressive\nremains a considerable challenge. In this paper, we propose PerceiverS\n(Segmentation and Scale), a novel architecture designed to address this issue\nby leveraging both Effective Segmentation and Multi-Scale attention mechanisms.\nOur approach enhances symbolic music generation by simultaneously learning\nlong-term structural dependencies and short-term expressive details. By\ncombining cross-attention and self-attention in a Multi-Scale setting,\nPerceiverS captures long-range musical structure while preserving musical\ndiversity. The proposed model has been evaluated using the Maestro dataset and\nhas demonstrated improvements in generating music of conventional length with\nexpressive nuances. The project demos and the generated music samples can be\naccessed through the link: https://perceivers.github.io",
      "tldr_zh": "本论文提出 PerceiverS，一种新型架构，结合 Effective Segmentation 和 Multi-Scale 注意力机制，旨在解决生成长结构和富有表现力的符号音乐的挑战。\nPerceiverS 通过交叉注意力(cross-attention)和自注意力(self-attention)在 Multi-Scale 设置中，同时学习长范围音乐结构依赖和短结构表达细节，从而提升音乐的多样性和整体质量。\n在 Maestro 数据集上的实验表明，该模型在生成常规长度音乐时表现出显著改进，增加了表现力细微之处，并提供了项目演示和音乐样本链接。",
      "categories": [
        "cs.AI",
        "cs.MM",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08307v2",
      "published_date": "2024-11-13 03:14:10 UTC",
      "updated_date": "2024-12-04 22:02:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:20:28.259548"
    },
    {
      "arxiv_id": "2411.17707v1",
      "title": "A Composite Fault Diagnosis Model for NPPs Based on Bayesian-EfficientNet Module",
      "title_zh": "翻译失败",
      "authors": [
        "Siwei Li",
        "Jiangwen Chen",
        "Hua Lin",
        "Wei Wang"
      ],
      "abstract": "This article focuses on the faults of important mechanical components such as\npumps, valves, and pipelines in the reactor coolant system, main steam system,\ncondensate system, and main feedwater system of nuclear power plants (NPPs). It\nproposes a composite multi-fault diagnosis model based on Bayesian algorithm\nand EfficientNet large model using data-driven deep learning fault diagnosis\ntechnology. The aim is to evaluate the effectiveness of automatic deep\nlearning-based large model technology through transfer learning in nuclear\npower plant scenarios.",
      "tldr_zh": "这篇论文针对核电站（NPPs）中反应堆冷却系统、主蒸汽系统、凝结水系统和主给水系统的关键机械部件（如泵、阀门和管道）的故障，提出了一种基于 Bayesian 算法和 EfficientNet 大模型的复合多故障诊断模型。模型采用数据驱动的深度学习技术，通过迁移学习来实现故障诊断的自动化。研究旨在评估这种大模型技术在核电站场景中的有效性，为改进核电站的安全性和维护提供新方法。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17707v1",
      "published_date": "2024-11-13 02:53:21 UTC",
      "updated_date": "2024-11-13 02:53:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:20:39.979185"
    },
    {
      "arxiv_id": "2411.08302v1",
      "title": "R3HF: Reward Redistribution for Enhancing Reinforcement Learning from Human Feedback",
      "title_zh": "R3HF：奖励重分配用于增强基于",
      "authors": [
        "Jiahui Li",
        "Tai-wei Chang",
        "Fengda Zhang",
        "Kun Kuang",
        "Long Chen"
      ],
      "abstract": "Reinforcement learning from human feedback (RLHF) provides a paradigm for\naligning large language models (LLMs) with human preferences. This involves the\ninitial training of a reward model based on pairwise human feedback. The reward\nmodel is subsequently utilized in reinforcement learning to assess the scores\nof each generated sentence as a whole, further guiding the optimization of\nLLMs. However, current approaches have a significant shortcoming: \\emph{They\nallocate a single, sparse, and delayed reward to an entire sequence of output}.\nThis may overlook some significant individual contributions of each token\ntowards the desired outcome. To overcome this limitation, our paper proposes a\nnovel reward redistribution method called R3HF, which facilitates a more\nfine-grained, token-level reward allocation. Specifically, our method treats\nthe reward prediction task of the reward model as a regression problem. As a\nresult, the redistributed rewards are computed by evaluating the specific\ncontribution of each token to the reward model's output. This detailed approach\nimproves the model's understanding of language nuances, leading to more precise\nenhancements in its performance. Our method is crafted to integrate seamlessly\nwith most current techniques while incurring minimal computational costs.\nThrough comprehensive experiments across diverse datasets and tasks, we have\nverified the effectiveness and superiority of our approach.",
      "tldr_zh": "该论文针对强化学习从人类反馈（Reinforcement Learning from Human Feedback, RLHF）中存在的不足，即现有方法仅为整个输出序列分配单一、稀疏的奖励，从而忽略了每个 token 的贡献，提出了一种新型方法 R3HF。R3HF 通过将奖励模型的预测视为回归问题，重新分配奖励到 token 级别，评估每个 token 对最终奖励的特定贡献，从而实现更细粒度的语言理解和模型优化。该方法易于与现有技术无缝集成，且计算开销最小；在多种数据集和任务上的实验验证了 R3HF 的有效性和性能优势。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08302v1",
      "published_date": "2024-11-13 02:45:21 UTC",
      "updated_date": "2024-11-13 02:45:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:20:50.921912"
    },
    {
      "arxiv_id": "2411.08299v3",
      "title": "DNN Task Assignment in UAV Networks: A Generative AI Enhanced Multi-Agent Reinforcement Learning Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Xin Tang",
        "Qian Chen",
        "Wenjie Weng",
        "Binhan Liao",
        "Jiacheng Wang",
        "Xianbin Cao",
        "Xiaohuan Li"
      ],
      "abstract": "Unmanned Aerial Vehicles (UAVs) possess high mobility and flexible deployment\ncapabilities, prompting the development of UAVs for various application\nscenarios within the Internet of Things (IoT). The unique capabilities of UAVs\ngive rise to increasingly critical and complex tasks in uncertain and\npotentially harsh environments. The substantial amount of data generated from\nthese applications necessitates processing and analysis through deep neural\nnetworks (DNNs). However, UAVs encounter challenges due to their limited\ncomputing resources when managing DNN models. This paper presents a joint\napproach that combines multiple-agent reinforcement learning (MARL) and\ngenerative diffusion models (GDM) for assigning DNN tasks to a UAV swarm, aimed\nat reducing latency from task capture to result output. To address these\nchallenges, we first consider the task size of the target area to be inspected\nand the shortest flying path as optimization constraints, employing a greedy\nalgorithm to resolve the subproblem with a focus on minimizing the UAV's flying\npath and the overall system cost. In the second stage, we introduce a novel DNN\ntask assignment algorithm, termed GDM-MADDPG, which utilizes the reverse\ndenoising process of GDM to replace the actor network in multi-agent deep\ndeterministic policy gradient (MADDPG). This approach generates specific DNN\ntask assignment actions based on agents' observations in a dynamic environment.\nSimulation results indicate that our algorithm performs favorably compared to\nbenchmarks in terms of path planning, Age of Information (AoI), energy\nconsumption, and task load balancing.",
      "tldr_zh": "该论文针对无人驾驶飞行器（UAVs）在物联网（IoT）应用中处理深度神经网络（DNNs）任务时面临的计算资源限制和环境不确定性问题，提出了一种结合多智能体强化学习（MARL）和生成扩散模型（GDM）的联合方法，以优化DNN任务分配并降低延迟。  \n首先，该方法使用贪婪算法作为第一阶段，考虑任务大小和最短飞行路径作为约束， minimizes UAV群的飞行路径和系统成本；其次，引入GDM-MADDPG算法，通过GDM的反向去噪过程替换MADDPG中的actor网络，生成动态环境下的具体任务分配动作。  \n模拟结果表明，该算法在路径规划、Age of Information (AoI)、能量消耗和任务负载平衡方面均优于基准模型，为高效的UAV网络任务管理提供了新途径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08299v3",
      "published_date": "2024-11-13 02:41:02 UTC",
      "updated_date": "2024-12-13 05:48:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:21:04.738939"
    },
    {
      "arxiv_id": "2411.08297v2",
      "title": "TowerDebias: A Novel Unfairness Removal Method Based on the Tower Property",
      "title_zh": "TowerDebias：一种基于 Tower Property 的新颖不公平去除方法",
      "authors": [
        "Norman Matloff",
        "Aditya Mittal"
      ],
      "abstract": "Decision-making processes have increasingly come to rely on sophisticated\nmachine learning tools, raising critical concerns about the fairness of their\npredictions with respect to sensitive groups. The widespread adoption of\ncommercial \"black-box\" models necessitates careful consideration of their legal\nand ethical implications for consumers. When users interact with such black-box\nmodels, a key challenge arises: how can the influence of sensitive attributes,\nsuch as race or gender, be mitigated or removed from its predictions? We\npropose towerDebias (tDB), a novel post-processing method designed to reduce\nthe influence of sensitive attributes in predictions made by black-box models.\nOur tDB approach leverages the Tower Property from probability theory to\nimprove prediction fairness without requiring retraining of the original model.\nThis method is highly versatile, as it requires no prior knowledge of the\noriginal algorithm's internal structure and is adaptable to a diverse range of\napplications. We present a formal fairness improvement theorem for tDB and\nshowcase its effectiveness in both regression and classification tasks using\nmultiple real-world datasets.",
      "tldr_zh": "这篇论文针对机器学习决策中的公平性问题，提出了一种新后处理方法 towerDebias (tDB)，旨在减少黑-box模型对敏感属性（如种族或性别）的偏见影响。tDB 利用概率理论中的 Tower Property 来改进预测公平性，而无需重新训练原模型或了解其内部结构。作者提供了正式的公平性改进定理，并在回归和分类任务的真实数据集上验证了 tDB 的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.PR",
        "stat.AP",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Completed preprint version. To be submitted for review",
      "pdf_url": "http://arxiv.org/pdf/2411.08297v2",
      "published_date": "2024-11-13 02:32:38 UTC",
      "updated_date": "2025-04-02 19:30:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:21:15.314273"
    },
    {
      "arxiv_id": "2411.08290v1",
      "title": "RESOLVE: Relational Reasoning with Symbolic and Object-Level Features Using Vector Symbolic Processing",
      "title_zh": "RESOLVE：使用向量符号处理进行符号和对象级特征的关系推理",
      "authors": [
        "Mohamed Mejri",
        "Chandramouli Amarnath",
        "Abhijit Chatterjee"
      ],
      "abstract": "Modern transformer-based encoder-decoder architectures struggle with\nreasoning tasks due to their inability to effectively extract relational\ninformation between input objects (data/tokens). Recent work introduced the\nAbstractor module, embedded between transformer layers, to address this gap.\nHowever, the Abstractor layer while excelling at capturing relational\ninformation (pure relational reasoning), faces challenges in tasks that require\nboth object and relational-level reasoning (partial relational reasoning). To\naddress this, we propose RESOLVE, a neuro-vector symbolic architecture that\ncombines object-level features with relational representations in\nhigh-dimensional spaces, using fast and efficient operations such as bundling\n(summation) and binding (Hadamard product) allowing both object-level features\nand relational representations to coexist within the same structure without\ninterfering with one another. RESOLVE is driven by a novel attention mechanism\nthat operates in a bipolar high dimensional space, allowing fast attention\nscore computation compared to the state-of-the-art. By leveraging this design,\nthe model achieves both low compute latency and memory efficiency. RESOLVE also\noffers better generalizability while achieving higher accuracy in purely\nrelational reasoning tasks such as sorting as well as partial relational\nreasoning tasks such as math problem-solving compared to state-of-the-art\nmethods.",
      "tldr_zh": "本文提出RESOLVE，一种神经-向量符号架构（neuro-vector symbolic architecture），旨在解决Transformer模型在关系推理任务中的局限性，通过结合对象级特征和关系表示，使用捆绑（bundling，如求和）和绑定（binding，如Hadamard product）操作来实现高效融合。RESOLVE引入了一种在双极高维空间中操作的新型注意机制，显著降低计算延迟和内存消耗。相比现有方法，该架构在纯关系推理任务（如排序）和部分关系推理任务（如数学问题求解）上实现了更高的准确率和泛化性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08290v1",
      "published_date": "2024-11-13 02:17:03 UTC",
      "updated_date": "2024-11-13 02:17:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:21:28.864163"
    },
    {
      "arxiv_id": "2411.08286v1",
      "title": "Hashing for Protein Structure Similarity Search",
      "title_zh": "翻译失败",
      "authors": [
        "Jin Han",
        "Wu-Jun Li"
      ],
      "abstract": "Protein structure similarity search (PSSS), which tries to search proteins\nwith similar structures, plays a crucial role across diverse domains from drug\ndesign to protein function prediction and molecular evolution. Traditional\nalignment-based PSSS methods, which directly calculate alignment on the protein\nstructures, are highly time-consuming with high memory cost. Recently,\nalignment-free methods, which represent protein structures as fixed-length\nreal-valued vectors, are proposed for PSSS. Although these methods have lower\ntime and memory cost than alignment-based methods, their time and memory cost\nis still too high for large-scale PSSS, and their accuracy is unsatisfactory.\nIn this paper, we propose a novel method, called\n$\\underline{\\text{p}}$r$\\underline{\\text{o}}$tein\n$\\underline{\\text{s}}$tructure $\\underline{\\text{h}}$ashing (POSH), for PSSS.\nPOSH learns a binary vector representation for each protein structure, which\ncan dramatically reduce the time and memory cost for PSSS compared with\nreal-valued vector representation based methods. Furthermore, in POSH we also\npropose expressive hand-crafted features and a structure encoder to well model\nboth node and edge interactions in proteins. Experimental results on real\ndatasets show that POSH can outperform other methods to achieve\nstate-of-the-art accuracy. Furthermore, POSH achieves a memory saving of more\nthan six times and speed improvement of more than four times, compared with\nother methods.",
      "tldr_zh": "本论文针对蛋白质结构相似性搜索（PSSS），提出了一种新型方法POSH（Protein Structure Hashing），旨在解决传统对齐方法计算密集和高内存消耗问题，以及现有非对齐方法效率和准确率不足的挑战。POSH通过学习蛋白质结构的二进制向量表示，结合手工艺特征和结构编码器来有效建模节点和边交互，从而显著降低搜索时间和内存成本。实验结果显示，POSH在真实数据集上实现了最先进的准确率，同时比其他方法节省内存超过六倍和提升速度超过四倍。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08286v1",
      "published_date": "2024-11-13 02:02:52 UTC",
      "updated_date": "2024-11-13 02:02:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:21:39.195821"
    },
    {
      "arxiv_id": "2411.08278v2",
      "title": "Knowledge Bases in Support of Large Language Models for Processing Web News",
      "title_zh": "翻译失败",
      "authors": [
        "Yihe Zhang",
        "Nabin Pakka",
        "Nian-Feng Tzeng"
      ],
      "abstract": "Large Language Models (LLMs) have received considerable interest in wide\napplications lately. During pre-training via massive datasets, such a model\nimplicitly memorizes the factual knowledge of trained datasets in its hidden\nparameters. However, knowledge held implicitly in parameters often makes its\nuse by downstream applications ineffective due to the lack of common-sense\nreasoning. In this article, we introduce a general framework that permits to\nbuild knowledge bases with an aid of LLMs, tailored for processing Web news.\nThe framework applies a rule-based News Information Extractor (NewsIE) to news\nitems for extracting their relational tuples, referred to as knowledge bases,\nwhich are then graph-convoluted with the implicit knowledge facts of news items\nobtained by LLMs, for their classification. It involves two lightweight\ncomponents: 1) NewsIE: for extracting the structural information of every news\nitem, in the form of relational tuples; 2) BERTGraph: for graph convoluting the\nimplicit knowledge facts with relational tuples extracted by NewsIE. We have\nevaluated our framework under different news-related datasets for news category\nclassification, with promising experimental results.",
      "tldr_zh": "该研究探讨了大型语言模型(LLMs)在处理网络新闻时的局限性，特别是隐含知识缺乏常识推理的问题。为此，提出一个通用框架，利用LLMs辅助构建知识库。该框架包括两个关键组件：基于规则的NewsIE，用于从新闻项目中提取关系元组；以及BERTGraph，用于将这些元组与LLMs的隐含知识事实进行图卷积，从而提升新闻分类任务。通过在不同新闻数据集上的实验，该框架在新闻类别分类方面取得了有前景的结果。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.08278v2",
      "published_date": "2024-11-13 01:33:05 UTC",
      "updated_date": "2024-11-14 15:49:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:21:51.063910"
    },
    {
      "arxiv_id": "2411.08257v1",
      "title": "GPTree: Towards Explainable Decision-Making via LLM-powered Decision Trees",
      "title_zh": "翻译失败",
      "authors": [
        "Sichao Xiong",
        "Yigit Ihlamur",
        "Fuat Alican",
        "Aaron Ontoyin Yin"
      ],
      "abstract": "Traditional decision tree algorithms are explainable but struggle with\nnon-linear, high-dimensional data, limiting its applicability in complex\ndecision-making. Neural networks excel at capturing complex patterns but\nsacrifice explainability in the process. In this work, we present GPTree, a\nnovel framework combining explainability of decision trees with the advanced\nreasoning capabilities of LLMs. GPTree eliminates the need for feature\nengineering and prompt chaining, requiring only a task-specific prompt and\nleveraging a tree-based structure to dynamically split samples. We also\nintroduce an expert-in-the-loop feedback mechanism to further enhance\nperformance by enabling human intervention to refine and rebuild decision\npaths, emphasizing the harmony between human expertise and machine\nintelligence. Our decision tree achieved a 7.8% precision rate for identifying\n\"unicorn\" startups at the inception stage of a startup, surpassing gpt-4o with\nfew-shot learning as well as the best human decision-makers (3.1% to 5.6%).",
      "tldr_zh": "本文提出 GPTree 框架，将决策树的解释性与大型语言模型(LLMs)的先进推理能力相结合，以解决传统决策树在处理非线性高维数据时的局限性，同时避免神经网络的解释性缺失。GPTree 通过任务特定提示和动态树状结构分割样本，消除特征工程和提示链的需求，并引入专家反馈机制允许人类干预优化决策路径。在实验中，GPTree 在识别“独角兽”初创企业的任务上实现了 7.8% 的精度，超越了 GPT-4o 和最佳人类决策者（3.1% 到 5.6%）。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08257v1",
      "published_date": "2024-11-13 00:14:09 UTC",
      "updated_date": "2024-11-13 00:14:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:22:03.625826"
    },
    {
      "arxiv_id": "2411.08254v1",
      "title": "VALTEST: Automated Validation of Language Model Generated Test Cases",
      "title_zh": "VALTEST：语言模型生成测试用例的自动验证",
      "authors": [
        "Hamed Taherkhani",
        "Hadi Hemmati"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated significant potential in\nautomating software testing, specifically in generating unit test cases.\nHowever, the validation of LLM-generated test cases remains a challenge,\nparticularly when the ground truth is unavailable. This paper introduces\nVALTEST, a novel framework designed to automatically validate test cases\ngenerated by LLMs by leveraging token probabilities. We evaluate VALTEST using\nnine test suites generated from three datasets (HumanEval, MBPP, and LeetCode)\nacross three LLMs (GPT-4o, GPT-3.5-turbo, and LLama3.1 8b). By extracting\nstatistical features from token probabilities, we train a machine learning\nmodel to predict test case validity. VALTEST increases the validity rate of\ntest cases by 6.2% to 24%, depending on the dataset and LLM. Our results\nsuggest that token probabilities are reliable indicators for distinguishing\nbetween valid and invalid test cases, which provides a robust solution for\nimproving the correctness of LLM-generated test cases in software testing. In\naddition, we found that replacing the identified invalid test cases by VALTEST,\nusing a Chain-of-Thought prompting results in a more effective test suite while\nkeeping the high validity rates.",
      "tldr_zh": "本研究提出VALTEST框架，用于自动验证Large Language Models (LLMs) 生成的测试用例，通过利用token probabilities来解决缺乏ground truth的挑战。VALTEST从HumanEval、MBPP和LeetCode三个数据集上生成的九个测试套件中提取token probabilities的统计特征，并训练机器学习模型预测测试用例的有效性。实验结果显示，VALTEST将测试用例的有效率提高6.2%至24%，证明token probabilities是区分有效与无效测试用例的可靠指标；此外，使用Chain-of-Thought提示替换无效用例，能进一步提升测试套件的整体效能。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08254v1",
      "published_date": "2024-11-13 00:07:32 UTC",
      "updated_date": "2024-11-13 00:07:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:22:15.917077"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 103,
  "processed_papers_count": 103,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-21T00:22:34.649604"
}