[
  {
    "arxiv_id": "2508.16609v1",
    "title": "Social Identity in Human-Agent Interaction: A Primer",
    "authors": [
      "Katie Seaborn"
    ],
    "abstract": "Social identity theory (SIT) and social categorization theory (SCT) are two facets of the social identity approach (SIA) to understanding social phenomena. SIT and SCT are models that describe and explain how people interact with one another socially, connecting the individual to the group through an understanding of underlying psychological mechanisms and intergroup behaviour. SIT, originally developed in the 1970s, and SCT, a later, more general offshoot, have been broadly applied to a range of social phenomena among people. The rise of increasingly social machines embedded in daily life has spurned efforts on understanding whether and how artificial agents can and do participate in SIA activities. As agents like social robots and chatbots powered by sophisticated large language models (LLMs) advance, understanding the real and potential roles of these technologies as social entities is crucial. Here, I provide a primer on SIA and extrapolate, through case studies and imagined examples, how SIT and SCT can apply to artificial social agents. I emphasize that not all human models and sub-theories will apply. I further argue that, given the emerging competence of these machines and our tendency to be taken in by them, we experts may need to don the hat of the uncanny killjoy, for our own good.",
    "categories": [
      "physics.soc-ph",
      "cs.AI",
      "cs.CY",
      "cs.HC",
      "cs.RO"
    ],
    "primary_category": "physics.soc-ph",
    "comment": "28 pages",
    "pdf_url": "https://arxiv.org/pdf/2508.16609v1",
    "published_date": "2025-08-12 23:48:59 UTC",
    "updated_date": "2025-08-12 23:48:59 UTC"
  },
  {
    "arxiv_id": "2508.09385v1",
    "title": "Understanding Dementia Speech Alignment with Diffusion-Based Image Generation",
    "authors": [
      "Mansi",
      "Anastasios Lepipas",
      "Dominika Woszczyk",
      "Yiying Guan",
      "Soteris Demetriou"
    ],
    "abstract": "Text-to-image models generate highly realistic images based on natural language descriptions and millions of users use them to create and share images online. While it is expected that such models can align input text and generated image in the same latent space little has been done to understand whether this alignment is possible between pathological speech and generated images. In this work, we examine the ability of such models to align dementia-related speech information with the generated images and develop methods to explain this alignment. Surprisingly, we found that dementia detection is possible from generated images alone achieving 75% accuracy on the ADReSS dataset. We then leverage explainability methods to show which parts of the language contribute to the detection.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Paper accepted at Interspeech 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.09385v1",
    "published_date": "2025-08-12 23:00:36 UTC",
    "updated_date": "2025-08-12 23:00:36 UTC"
  },
  {
    "arxiv_id": "2508.13180v1",
    "title": "Search-Time Data Contamination",
    "authors": [
      "Ziwen Han",
      "Meher Mankikar",
      "Julian Michael",
      "Zifan Wang"
    ],
    "abstract": "Data contamination refers to the leakage of evaluation data into model training data, resulting in overfitting to supposedly held-out test sets and compromising test validity. We identify an analogous issue, search-time contamination (STC), in evaluating search-based LLM agents which use tools to gather information from online sources when answering user queries. STC occurs when the retrieval step surfaces a source containing the test question (or a near-duplicate) alongside its answer, enabling agents to copy rather than genuinely infer or reason, undermining benchmark integrity. We find that HuggingFace, an online platform hosting evaluation datasets, appears among retrieved sources in search based agent logs. Consequently, agents often explicitly acknowledge discovering question answer pairs from HuggingFace within their reasoning chains. On three commonly used capability benchmarks: Humanity's Last Exam (HLE), SimpleQA, and GPQA, we demonstrate that for approximately 3% of questions, search-based agents directly find the datasets with ground truth labels on HuggingFace. When millions of evaluation queries target the same benchmark, even small, repeated leaks can accelerate the benchmark's obsolescence, shortening its intended lifecycle. After HuggingFace is blocked, we observe a drop in accuracy on the contaminated subset of approximately 15%. We further show through ablation experiments that publicly accessible evaluation datasets on HuggingFace may not be the sole source of STC. To this end, we conclude by proposing best practices for benchmark design and result reporting to address this novel form of leakage and ensure trustworthy evaluation of search-based LLM agents. To facilitate the auditing of evaluation results, we also publicly release the complete logs from our experiments.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.13180v1",
    "published_date": "2025-08-12 22:52:21 UTC",
    "updated_date": "2025-08-12 22:52:21 UTC"
  },
  {
    "arxiv_id": "2508.09383v1",
    "title": "X-UniMotion: Animating Human Images with Expressive, Unified and Identity-Agnostic Motion Latents",
    "authors": [
      "Guoxian Song",
      "Hongyi Xu",
      "Xiaochen Zhao",
      "You Xie",
      "Tianpei Gu",
      "Zenan Li",
      "Chenxu Zhang",
      "Linjie Luo"
    ],
    "abstract": "We present X-UniMotion, a unified and expressive implicit latent representation for whole-body human motion, encompassing facial expressions, body poses, and hand gestures. Unlike prior motion transfer methods that rely on explicit skeletal poses and heuristic cross-identity adjustments, our approach encodes multi-granular motion directly from a single image into a compact set of four disentangled latent tokens -- one for facial expression, one for body pose, and one for each hand. These motion latents are both highly expressive and identity-agnostic, enabling high-fidelity, detailed cross-identity motion transfer across subjects with diverse identities, poses, and spatial configurations. To achieve this, we introduce a self-supervised, end-to-end framework that jointly learns the motion encoder and latent representation alongside a DiT-based video generative model, trained on large-scale, diverse human motion datasets. Motion-identity disentanglement is enforced via 2D spatial and color augmentations, as well as synthetic 3D renderings of cross-identity subject pairs under shared poses. Furthermore, we guide motion token learning with auxiliary decoders that promote fine-grained, semantically aligned, and depth-aware motion embeddings. Extensive experiments show that X-UniMotion outperforms state-of-the-art methods, producing highly expressive animations with superior motion fidelity and identity preservation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.09383v1",
    "published_date": "2025-08-12 22:47:20 UTC",
    "updated_date": "2025-08-12 22:47:20 UTC"
  },
  {
    "arxiv_id": "2508.09381v1",
    "title": "What Can We Learn from Inter-Annotator Variability in Skin Lesion Segmentation?",
    "authors": [
      "Kumar Abhishek",
      "Jeremy Kawahara",
      "Ghassan Hamarneh"
    ],
    "abstract": "Medical image segmentation exhibits intra- and inter-annotator variability due to ambiguous object boundaries, annotator preferences, expertise, and tools, among other factors. Lesions with ambiguous boundaries, e.g., spiculated or infiltrative nodules, or irregular borders per the ABCD rule, are particularly prone to disagreement and are often associated with malignancy. In this work, we curate IMA++, the largest multi-annotator skin lesion segmentation dataset, on which we conduct an in-depth study of variability due to annotator, malignancy, tool, and skill factors. We find a statistically significant (p<0.001) association between inter-annotator agreement (IAA), measured using Dice, and the malignancy of skin lesions. We further show that IAA can be accurately predicted directly from dermoscopic images, achieving a mean absolute error of 0.108. Finally, we leverage this association by utilizing IAA as a \"soft\" clinical feature within a multi-task learning objective, yielding a 4.2% improvement in balanced accuracy averaged across multiple model architectures and across IMA++ and four public dermoscopic datasets. The code is available at https://github.com/sfu-mial/skin-IAV.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Medical Image Computing and Computer-Assisted Intervention (MICCAI) ISIC Skin Image Analysis Workshop (MICCAI ISIC) 2025; 12 pages, 4 tables, 3 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.09381v1",
    "published_date": "2025-08-12 22:37:56 UTC",
    "updated_date": "2025-08-12 22:37:56 UTC"
  },
  {
    "arxiv_id": "2508.09378v1",
    "title": "APIO: Automatic Prompt Induction and Optimization for Grammatical Error Correction and Text Simplification",
    "authors": [
      "Artem Chernodub",
      "Aman Saini",
      "Yejin Huh",
      "Vivek Kulkarni",
      "Vipul Raheja"
    ],
    "abstract": "Recent advancements in large language models (LLMs) have enabled a wide range of natural language processing (NLP) tasks to be performed through simple prompt-based interactions. Consequently, several approaches have been proposed to engineer prompts that most effectively enable LLMs to perform a given task (e.g., chain-of-thought prompting). In settings with a well-defined metric to optimize model performance, automatic prompt optimization (APO) methods have been developed to refine a seed prompt. Advancing this line of research, we propose APIO, a simple but effective prompt induction and optimization approach for the tasks of Grammatical Error Correction (GEC) and Text Simplification, without relying on manually specified seed prompts. APIO achieves a new state-of-the-art performance for purely LLM-based prompting methods on these tasks. We make our data, code, prompts, and outputs publicly available.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted for publication at Recent Advances in Natural Language Processing conference (RANLP 2025)",
    "pdf_url": "https://arxiv.org/pdf/2508.09378v1",
    "published_date": "2025-08-12 22:26:32 UTC",
    "updated_date": "2025-08-12 22:26:32 UTC"
  },
  {
    "arxiv_id": "2508.09372v1",
    "title": "A Signer-Invariant Conformer and Multi-Scale Fusion Transformer for Continuous Sign Language Recognition",
    "authors": [
      "Md Rezwanul Haque",
      "Md. Milon Islam",
      "S M Taslim Uddin Raju",
      "Fakhri Karray"
    ],
    "abstract": "Continuous Sign Language Recognition (CSLR) faces multiple challenges, including significant inter-signer variability and poor generalization to novel sentence structures. Traditional solutions frequently fail to handle these issues efficiently. For overcoming these constraints, we propose a dual-architecture framework. For the Signer-Independent (SI) challenge, we propose a Signer-Invariant Conformer that combines convolutions with multi-head self-attention to learn robust, signer-agnostic representations from pose-based skeletal keypoints. For the Unseen-Sentences (US) task, we designed a Multi-Scale Fusion Transformer with a novel dual-path temporal encoder that captures both fine-grained posture dynamics, enabling the model's ability to comprehend novel grammatical compositions. Experiments on the challenging Isharah-1000 dataset establish a new standard for both CSLR benchmarks. The proposed conformer architecture achieves a Word Error Rate (WER) of 13.07% on the SI challenge, a reduction of 13.53% from the state-of-the-art. On the US task, the transformer model scores a WER of 47.78%, surpassing previous work. In the SignEval 2025 CSLR challenge, our team placed 2nd in the US task and 4th in the SI task, demonstrating the performance of these models. The findings validate our key hypothesis: that developing task-specific networks designed for the particular challenges of CSLR leads to considerable performance improvements and establishes a new baseline for further research. The source code is available at: https://github.com/rezwanh001/MSLR-Pose86K-CSLR-Isharah.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted for the IEEE/CVF International Conference on Computer Vision (ICCV), Honolulu, Hawaii, USA. 1st MSLR Workshop 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.09372v1",
    "published_date": "2025-08-12 21:59:53 UTC",
    "updated_date": "2025-08-12 21:59:53 UTC"
  },
  {
    "arxiv_id": "2508.09362v1",
    "title": "FusionEnsemble-Net: An Attention-Based Ensemble of Spatiotemporal Networks for Multimodal Sign Language Recognition",
    "authors": [
      "Md. Milon Islam",
      "Md Rezwanul Haque",
      "S M Taslim Uddin Raju",
      "Fakhri Karray"
    ],
    "abstract": "Accurate recognition of sign language in healthcare communication poses a significant challenge, requiring frameworks that can accurately interpret complex multimodal gestures. To deal with this, we propose FusionEnsemble-Net, a novel attention-based ensemble of spatiotemporal networks that dynamically fuses visual and motion data to enhance recognition accuracy. The proposed approach processes RGB video and range Doppler map radar modalities synchronously through four different spatiotemporal networks. For each network, features from both modalities are continuously fused using an attention-based fusion module before being fed into an ensemble of classifiers. Finally, the outputs of these four different fused channels are combined in an ensemble classification head, thereby enhancing the model's robustness. Experiments demonstrate that FusionEnsemble-Net outperforms state-of-the-art approaches with a test accuracy of 99.44% on the large-scale MultiMeDaLIS dataset for Italian Sign Language. Our findings indicate that an ensemble of diverse spatiotemporal networks, unified by attention-based fusion, yields a robust and accurate framework for complex, multimodal isolated gesture recognition tasks. The source code is available at: https://github.com/rezwanh001/Multimodal-Isolated-Italian-Sign-Language-Recognition.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted for the IEEE/CVF International Conference on Computer Vision (ICCV), Honolulu, Hawaii, USA. 1st MSLR Workshop 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.09362v1",
    "published_date": "2025-08-12 21:44:23 UTC",
    "updated_date": "2025-08-12 21:44:23 UTC"
  },
  {
    "arxiv_id": "2508.10057v1",
    "title": "Large Language Models Show Signs of Alignment with Human Neurocognition During Abstract Reasoning",
    "authors": [
      "Christopher Pinier",
      "Sonia Acuña Vargas",
      "Mariia Steeghs-Turchina",
      "Dora Matzke",
      "Claire E. Stevenson",
      "Michael D. Nunez"
    ],
    "abstract": "This study investigates whether large language models (LLMs) mirror human neurocognition during abstract reasoning. We compared the performance and neural representations of human participants with those of eight open-source LLMs on an abstract-pattern-completion task. We leveraged pattern type differences in task performance and in fixation-related potentials (FRPs) as recorded by electroencephalography (EEG) during the task. Our findings indicate that only the largest tested LLMs (~70 billion parameters) achieve human-comparable accuracy, with Qwen-2.5-72B and DeepSeek-R1-70B also showing similarities with the human pattern-specific difficulty profile. Critically, every LLM tested forms representations that distinctly cluster the abstract pattern categories within their intermediate layers, although the strength of this clustering scales with their performance on the task. Moderate positive correlations were observed between the representational geometries of task-optimal LLM layers and human frontal FRPs. These results consistently diverged from comparisons with other EEG measures (response-locked ERPs and resting EEG), suggesting a potential shared representational space for abstract patterns. This indicates that LLMs might mirror human brain mechanisms in abstract reasoning, offering preliminary evidence of shared principles between biological and artificial intelligence.",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "q-bio.NC",
    "comment": "Presented at the 8th Annual Conference on Cognitive Computational Neuroscience (August 12-15, 2025; Amsterdam, The Netherlands); 20 pages, 11 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.10057v1",
    "published_date": "2025-08-12 21:38:46 UTC",
    "updated_date": "2025-08-12 21:38:46 UTC"
  },
  {
    "arxiv_id": "2508.09349v1",
    "title": "The Human-AI Hybrid Delphi Model: A Structured Framework for Context-Rich, Expert Consensus in Complex Domains",
    "authors": [
      "Cathy Speed",
      "Ahmed A. Metwally"
    ],
    "abstract": "Expert consensus plays a critical role in domains where evidence is complex, conflicting, or insufficient for direct prescription. Traditional methods, such as Delphi studies, consensus conferences, and systematic guideline synthesis, offer structure but face limitations including high panel burden, interpretive oversimplification, and suppression of conditional nuance. These challenges are now exacerbated by information overload, fragmentation of the evidence base, and increasing reliance on publicly available sources that lack expert filtering. This study introduces and evaluates a Human-AI Hybrid Delphi (HAH-Delphi) framework designed to augment expert consensus development by integrating a generative AI model (Gemini 2.5 Pro), small panels of senior human experts, and structured facilitation. The HAH-Delphi was tested in three phases: retrospective replication, prospective comparison, and applied deployment in two applied domains (endurance training and resistance and mixed cardio/strength training). The AI replicated 95% of published expert consensus conclusions in Phase I and showed 95% directional agreement with senior human experts in Phase II, though it lacked experiential and pragmatic nuance. In Phase III, compact panels of six senior experts achieved >90% consensus coverage and reached thematic saturation before the final participant. The AI provided consistent, literature-grounded scaffolding that supported divergence resolution and accelerated saturation. The HAH-Delphi framework offers a flexible, scalable approach for generating high-quality, context-sensitive consensus. Its successful application across health, coaching, and performance science confirms its methodological robustness and supports its use as a foundation for generating conditional, personalised guidance and published consensus frameworks at scale.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.09349v1",
    "published_date": "2025-08-12 21:24:19 UTC",
    "updated_date": "2025-08-12 21:24:19 UTC"
  },
  {
    "arxiv_id": "2508.09340v1",
    "title": "Collective dynamics of strategic classification",
    "authors": [
      "Marta C. Couto",
      "Flavia Barsotti",
      "Fernando P. Santos"
    ],
    "abstract": "Classification algorithms based on Artificial Intelligence (AI) are nowadays applied in high-stakes decisions in finance, healthcare, criminal justice, or education. Individuals can strategically adapt to the information gathered about classifiers, which in turn may require algorithms to be re-trained. Which collective dynamics will result from users' adaptation and algorithms' retraining? We apply evolutionary game theory to address this question. Our framework provides a mathematically rigorous way of treating the problem of feedback loops between collectives of users and institutions, allowing to test interventions to mitigate the adverse effects of strategic adaptation. As a case study, we consider institutions deploying algorithms for credit lending. We consider several scenarios, each representing different interaction paradigms. When algorithms are not robust against strategic manipulation, we are able to capture previous challenges discussed in the strategic classification literature, whereby users either pay excessive costs to meet the institutions' expectations (leading to high social costs) or game the algorithm (e.g., provide fake information). From this baseline setting, we test the role of improving gaming detection and providing algorithmic recourse. We show that increased detection capabilities reduce social costs and could lead to users' improvement; when perfect classifiers are not feasible (likely to occur in practice), algorithmic recourse can steer the dynamics towards high users' improvement rates. The speed at which the institutions re-adapt to the user's population plays a role in the final outcome. Finally, we explore a scenario where strict institutions provide actionable recourse to their unsuccessful users and observe cycling dynamics so far unnoticed in the literature.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "econ.TH"
    ],
    "primary_category": "cs.GT",
    "comment": "34 pages",
    "pdf_url": "https://arxiv.org/pdf/2508.09340v1",
    "published_date": "2025-08-12 20:57:17 UTC",
    "updated_date": "2025-08-12 20:57:17 UTC"
  },
  {
    "arxiv_id": "2508.09334v1",
    "title": "RicciFlowRec: A Geometric Root Cause Recommender Using Ricci Curvature on Financial Graphs",
    "authors": [
      "Zhongtian Sun",
      "Anoushka Harit"
    ],
    "abstract": "We propose RicciFlowRec, a geometric recommendation framework that performs root cause attribution via Ricci curvature and flow on dynamic financial graphs. By modelling evolving interactions among stocks, macroeconomic indicators, and news, we quantify local stress using discrete Ricci curvature and trace shock propagation via Ricci flow. Curvature gradients reveal causal substructures, informing a structural risk-aware ranking function. Preliminary results on S\\&P~500 data with FinBERT-based sentiment show improved robustness and interpretability under synthetic perturbations. This ongoing work supports curvature-based attribution and early-stage risk-aware ranking, with plans for portfolio optimization and return forecasting. To our knowledge, RicciFlowRec is the first recommender to apply geometric flow-based reasoning in financial decision support.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at ACM RecSys 2025 (Late Breaking Results Track)",
    "pdf_url": "https://arxiv.org/pdf/2508.09334v1",
    "published_date": "2025-08-12 20:45:02 UTC",
    "updated_date": "2025-08-12 20:45:02 UTC"
  },
  {
    "arxiv_id": "2508.21076v1",
    "title": "Pep2Prob Benchmark: Predicting Fragment Ion Probability for MS$^2$-based Proteomics",
    "authors": [
      "Hao Xu",
      "Zhichao Wang",
      "Shengqi Sang",
      "Pisit Wajanasara",
      "Nuno Bandeira"
    ],
    "abstract": "Proteins perform nearly all cellular functions and constitute most drug targets, making their analysis fundamental to understanding human biology in health and disease. Tandem mass spectrometry (MS$^2$) is the major analytical technique in proteomics that identifies peptides by ionizing them, fragmenting them, and using the resulting mass spectra to identify and quantify proteins in biological samples. In MS$^2$ analysis, peptide fragment ion probability prediction plays a critical role, enhancing the accuracy of peptide identification from mass spectra as a complement to the intensity information. Current approaches rely on global statistics of fragmentation, which assumes that a fragment's probability is uniform across all peptides. Nevertheless, this assumption is oversimplified from a biochemical principle point of view and limits accurate prediction. To address this gap, we present Pep2Prob, the first comprehensive dataset and benchmark designed for peptide-specific fragment ion probability prediction. The proposed dataset contains fragment ion probability statistics for 608,780 unique precursors (each precursor is a pair of peptide sequence and charge state), summarized from more than 183 million high-quality, high-resolution, HCD MS$^2$ spectra with validated peptide assignments and fragmentation annotations. We establish baseline performance using simple statistical rules and learning-based methods, and find that models leveraging peptide-specific information significantly outperform previous methods using only global fragmentation statistics. Furthermore, performance across benchmark models with increasing capacities suggests that the peptide-fragmentation relationship exhibits complex nonlinearities requiring sophisticated machine learning approaches.",
    "categories": [
      "q-bio.BM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.BM",
    "comment": "Dataset is available at HuggingFace: https://huggingface.co/datasets/bandeiralab/Pep2Prob",
    "pdf_url": "https://arxiv.org/pdf/2508.21076v1",
    "published_date": "2025-08-12 20:39:50 UTC",
    "updated_date": "2025-08-12 20:39:50 UTC"
  },
  {
    "arxiv_id": "2508.09330v2",
    "title": "Synaptic Pruning: A Biological Inspiration for Deep Learning Regularization",
    "authors": [
      "Gideon Vos",
      "Liza van Eijk",
      "Zoltan Sarnyai",
      "Mostafa Rahimi Azghadi"
    ],
    "abstract": "Synaptic pruning in biological brains removes weak connections to improve efficiency. In contrast, dropout regularization in artificial neural networks randomly deactivates neurons without considering activity-dependent pruning. We propose a magnitude-based synaptic pruning method that better reflects biology by progressively removing low-importance connections during training. Integrated directly into the training loop as a dropout replacement, our approach computes weight importance from absolute magnitudes across layers and applies a cubic schedule to gradually increase global sparsity. At fixed intervals, pruning masks permanently remove low-importance weights while maintaining gradient flow for active ones, eliminating the need for separate pruning and fine-tuning phases. Experiments on multiple time series forecasting models including RNN, LSTM, and Patch Time Series Transformer across four datasets show consistent gains. Our method ranked best overall, with statistically significant improvements confirmed by Friedman tests (p < 0.01). In financial forecasting, it reduced Mean Absolute Error by up to 20% over models with no or standard dropout, and up to 52% in select transformer models. This dynamic pruning mechanism advances regularization by coupling weight elimination with progressive sparsification, offering easy integration into diverse architectures. Its strong performance, especially in financial time series forecasting, highlights its potential as a practical alternative to conventional dropout techniques.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "24 pages, 7 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.09330v2",
    "published_date": "2025-08-12 20:36:00 UTC",
    "updated_date": "2025-10-05 07:16:18 UTC"
  },
  {
    "arxiv_id": "2508.09325v3",
    "title": "SegDAC: Improving Visual Reinforcement Learning by Extracting Dynamic Object-Centric Representations from Pretrained Vision Models",
    "authors": [
      "Alexandre Brown",
      "Glen Berseth"
    ],
    "abstract": "Visual reinforcement learning (RL) is challenging due to the need to extract useful representations from high-dimensional inputs while learning effective control from sparse and noisy rewards. Although large perception models exist, integrating them effectively into RL for visual generalization and improved sample efficiency remains difficult. We propose SegDAC, a Segmentation-Driven Actor-Critic method. SegDAC uses Segment Anything (SAM) for object-centric decomposition and YOLO-World to ground the image segmentation process via text inputs. It includes a novel transformer-based architecture that supports a dynamic number of segments at each time step and effectively learns which segments to focus on using online RL, without using human labels. By evaluating SegDAC over a challenging visual generalization benchmark using Maniskill3, which covers diverse manipulation tasks under strong visual perturbations, we demonstrate that SegDAC achieves significantly better visual generalization, doubling prior performance on the hardest setting and matching or surpassing prior methods in sample efficiency across all evaluated tasks. Project Page: https://segdac.github.io/",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.09325v3",
    "published_date": "2025-08-12 20:16:54 UTC",
    "updated_date": "2026-01-12 13:21:57 UTC"
  },
  {
    "arxiv_id": "2508.09324v1",
    "title": "TEN: Table Explicitization, Neurosymbolically",
    "authors": [
      "Nikita Mehrotra",
      "Aayush Kumar",
      "Sumit Gulwani",
      "Arjun Radhakrishna",
      "Ashish Tiwari"
    ],
    "abstract": "We present a neurosymbolic approach, TEN, for extracting tabular data from semistructured input text. This task is particularly challenging for text input that does not use special delimiters consistently to separate columns and rows. Purely neural approaches perform poorly due to hallucinations and their inability to enforce hard constraints. TEN uses Structural Decomposition prompting - a specialized chain-of-thought prompting approach - on a large language model (LLM) to generate an initial table, and thereafter uses a symbolic checker to evaluate not only the well-formedness of that table, but also detect cases of hallucinations or forgetting. The output of the symbolic checker is processed by a critique-LLM to generate guidance for fixing the table, which is presented to the original LLM in a self-debug loop. Our extensive experiments demonstrate that TEN significantly outperforms purely neural baselines across multiple datasets and metrics, achieving significantly higher exact match accuracy and substantially reduced hallucination rates. A 21-participant user study further confirms that TEN's tables are rated significantly more accurate (mean score: 5.0 vs 4.3; p = 0.021), and are consistently preferred for ease of verification and correction, with participants favoring our method in over 60% of the cases.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.09324v1",
    "published_date": "2025-08-12 20:16:41 UTC",
    "updated_date": "2025-08-12 20:16:41 UTC"
  },
  {
    "arxiv_id": "2508.09323v2",
    "title": "Leveraging Large Language Models for Rare Disease Named Entity Recognition",
    "authors": [
      "Nan Miles Xi",
      "Yu Deng",
      "Lin Wang"
    ],
    "abstract": "Named Entity Recognition (NER) in the rare disease domain poses unique challenges due to limited labeled data, semantic ambiguity between entity types, and long-tail distributions. In this study, we evaluate the capabilities of GPT-4o for rare disease NER under low-resource settings, using a range of prompt-based strategies including zero-shot prompting, few-shot in-context learning, retrieval-augmented generation (RAG), and task-level fine-tuning. We design a structured prompting framework that encodes domain-specific knowledge and disambiguation rules for four entity types. We further introduce two semantically guided few-shot example selection methods to improve in-context performance while reducing labeling effort. Experiments on the RareDis Corpus show that GPT-4o achieves competitive or superior performance compared to BioClinicalBERT, with task-level fine-tuning yielding the strongest performance among the evaluated approaches and improving upon the previously reported BioClinicalBERT baseline. Cost-performance analysis reveals that few-shot prompting delivers high returns at low token budgets. RAG provides limited overall gains but can improve recall for challenging entity types, especially signs and symptoms. An error taxonomy highlights common failure modes such as boundary drift and type confusion, suggesting opportunities for post-processing and hybrid refinement. Our results demonstrate that prompt-optimized LLMs can serve as effective, scalable alternatives to traditional supervised models in biomedical NER, particularly in rare disease applications where annotated data is scarce.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.09323v2",
    "published_date": "2025-08-12 20:16:31 UTC",
    "updated_date": "2025-12-29 16:39:56 UTC"
  },
  {
    "arxiv_id": "2508.09320v2",
    "title": "Exact Verification of Graph Neural Networks with Incremental Constraint Solving",
    "authors": [
      "Minghao Liu",
      "Chia-Hsuan Lu",
      "Marta Kwiatkowska"
    ],
    "abstract": "Graph neural networks (GNNs) are increasingly employed in high-stakes applications, such as fraud detection or healthcare, but are susceptible to adversarial attacks. A number of techniques have been proposed to provide adversarial robustness guarantees, but support for commonly used aggregation functions in message-passing GNNs is lacking. In this paper, we develop an exact (sound and complete) verification method for GNNs to compute guarantees against attribute and structural perturbations that involve edge addition or deletion, subject to budget constraints. Our method employs constraint solving with bound tightening, and iteratively solves a sequence of relaxed constraint satisfaction problems while relying on incremental solving capabilities of solvers to improve efficiency. We implement GNNev, a versatile exact verifier for message-passing neural networks, which supports three aggregation functions, sum, max and mean, with the latter two considered here for the first time. Extensive experimental evaluation of GNNev on real-world fraud datasets (Amazon and Yelp) and biochemical datasets (MUTAG and ENZYMES) demonstrates its usability and effectiveness, as well as superior performance for node classification and competitiveness on graph classification compared to existing exact verification tools on sum-aggregated GNNs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.09320v2",
    "published_date": "2025-08-12 20:10:31 UTC",
    "updated_date": "2025-12-17 14:35:40 UTC"
  },
  {
    "arxiv_id": "2508.09318v1",
    "title": "TPTP World Infrastructure for Non-classical Logics",
    "authors": [
      "Alexander Steen",
      "Geoff Sutcliffe"
    ],
    "abstract": "The TPTP World is the well established infrastructure that supports research, development, and deployment of Automated Theorem Proving (ATP) systems. The TPTP World supports a range of classical logics, and since release v9.0.0 has supported non-classical logics. This paper provides a self-contained comprehensive overview of the TPTP World infrastructure for ATP in non-classical logics: the non-classical language extension, problems and solutions, and tool support. A detailed description of use of the infrastructure for quantified normal multi-modal logic is given.",
    "categories": [
      "cs.LO",
      "cs.AI"
    ],
    "primary_category": "cs.LO",
    "comment": "35 pages",
    "pdf_url": "https://arxiv.org/pdf/2508.09318v1",
    "published_date": "2025-08-12 20:05:52 UTC",
    "updated_date": "2025-08-12 20:05:52 UTC"
  },
  {
    "arxiv_id": "2508.11697v1",
    "title": "Separating Knowledge and Perception with Procedural Data",
    "authors": [
      "Adrián Rodríguez-Muñoz",
      "Manel Baradad",
      "Phillip Isola",
      "Antonio Torralba"
    ],
    "abstract": "We train representation models with procedural data only, and apply them on visual similarity, classification, and semantic segmentation tasks without further training by using visual memory -- an explicit database of reference image embeddings. Unlike prior work on visual memory, our approach achieves full compartmentalization with respect to all real-world images while retaining strong performance. Compared to a model trained on Places, our procedural model performs within $1\\%$ on NIGHTS visual similarity, outperforms by $8\\%$ and $15\\%$ on CUB200 and Flowers102 fine-grained classification, and is within $10\\%$ on ImageNet-1K classification. It also demonstrates strong zero-shot segmentation, achieving an $R^2$ on COCO within $10\\%$ of the models trained on real data. Finally, we analyze procedural versus real data models, showing that parts of the same object have dissimilar representations in procedural models, resulting in incorrect searches in memory and explaining the remaining performance gap.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "17 pages, 18 figures, 3 tables, to be published in ICML 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.11697v1",
    "published_date": "2025-08-12 19:48:35 UTC",
    "updated_date": "2025-08-12 19:48:35 UTC"
  },
  {
    "arxiv_id": "2508.09303v1",
    "title": "ParallelSearch: Train your LLMs to Decompose Query and Search Sub-queries in Parallel with Reinforcement Learning",
    "authors": [
      "Shu Zhao",
      "Tan Yu",
      "Anbang Xu",
      "Japinder Singh",
      "Aaditya Shukla",
      "Rama Akkiraju"
    ],
    "abstract": "Reasoning-augmented search agents such as Search-R1, trained via reinforcement learning with verifiable rewards (RLVR), demonstrate remarkable capabilities in multi-step information retrieval from external knowledge sources. These agents address the limitations of their parametric memory by dynamically gathering relevant facts to address complex reasoning tasks. However, existing approaches suffer from a fundamental architectural limitation: they process search queries strictly sequentially, even when handling inherently parallelizable and logically independent comparisons. This sequential bottleneck significantly constrains computational efficiency, particularly for queries that require multiple entity comparisons. To address this critical limitation, we propose ParallelSearch, a novel reinforcement learning framework that empowers large language models (LLMs) to recognize parallelizable query structures and execute multiple search operations concurrently. Our approach introduces dedicated reward functions that incentivize the identification of independent query components while preserving answer accuracy through jointly considering correctness, query decomposition quality, and parallel execution benefits. Comprehensive experiments demonstrate that ParallelSearch outperforms state-of-the-art baselines by an average performance gain of 2.9% across seven question-answering benchmarks. Notably, on parallelizable questions, our method achieves a 12.7% performance improvement while requiring only 69.6% of the LLM calls compared to sequential approaches.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.09303v1",
    "published_date": "2025-08-12 19:38:21 UTC",
    "updated_date": "2025-08-12 19:38:21 UTC"
  },
  {
    "arxiv_id": "2508.09299v2",
    "title": "Decentralized Weather Forecasting via Distributed Machine Learning and Blockchain-Based Model Validation",
    "authors": [
      "Rilwan Umar",
      "Aydin Abadi",
      "Basil Aldali",
      "Benito Vincent",
      "Elliot A. J. Hurley",
      "Hotoon Aljazaeri",
      "Jamie Hedley-Cook",
      "Jamie-Lee Bell",
      "Lambert Uwuigbusun",
      "Mujeeb Ahmed",
      "Shishir Nagaraja",
      "Suleiman Sabo",
      "Weaam Alrbeiqi"
    ],
    "abstract": "Weather forecasting plays a vital role in disaster preparedness, agriculture, and resource management, yet current centralized forecasting systems are increasingly strained by security vulnerabilities, limited scalability, and susceptibility to single points of failure. To address these challenges, we propose a decentralized weather forecasting framework that integrates Federated Learning (FL) with blockchain technology. FL enables collaborative model training without exposing sensitive local data; this approach enhances privacy and reduces data transfer overhead. Meanwhile, the Ethereum blockchain ensures transparent and dependable verification of model updates. To further enhance the system's security, we introduce a reputation-based voting mechanism that assesses the trustworthiness of submitted models while utilizing the Interplanetary File System (IPFS) for efficient off-chain storage. Experimental results demonstrate that our approach not only improves forecasting accuracy but also enhances system resilience and scalability, making it a viable candidate for deployment in real-world, security-critical environments.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.09299v2",
    "published_date": "2025-08-12 19:25:34 UTC",
    "updated_date": "2025-08-14 07:18:06 UTC"
  },
  {
    "arxiv_id": "2508.09297v3",
    "title": "Biased AI improves human decision-making but reduces trust",
    "authors": [
      "Shiyang Lai",
      "Junsol Kim",
      "Nadav Kunievsky",
      "Yujin Potter",
      "James Evans"
    ],
    "abstract": "Current AI systems minimize risk by enforcing ideological neutrality, yet this may introduce automation bias by suppressing cognitive engagement in human decision-making. We conducted randomized trials with 2,500 participants to test whether culturally biased AI enhances human decision-making. Participants interacted with politically diverse GPT-4o variants on information evaluation tasks. Partisan AI assistants enhanced human performance, increased engagement, and reduced evaluative bias compared to non-biased counterparts, with amplified benefits when participants encountered opposing views. These gains carried a trust penalty: participants underappreciated biased AI and overcredited neutral systems. Exposing participants to two AIs whose biases flanked human perspectives closed the perception-performance gap. These findings complicate conventional wisdom about AI neutrality, suggesting that strategic integration of diverse cultural biases may foster improved and resilient human decision-making.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.09297v3",
    "published_date": "2025-08-12 19:20:43 UTC",
    "updated_date": "2025-08-19 22:58:06 UTC"
  },
  {
    "arxiv_id": "2508.09294v1",
    "title": "Fake-Mamba: Real-Time Speech Deepfake Detection Using Bidirectional Mamba as Self-Attention's Alternative",
    "authors": [
      "Xi Xuan",
      "Zimo Zhu",
      "Wenxin Zhang",
      "Yi-Cheng Lin",
      "Tomi Kinnunen"
    ],
    "abstract": "Advances in speech synthesis intensify security threats, motivating real-time deepfake detection research. We investigate whether bidirectional Mamba can serve as a competitive alternative to Self-Attention in detecting synthetic speech. Our solution, Fake-Mamba, integrates an XLSR front-end with bidirectional Mamba to capture both local and global artifacts. Our core innovation introduces three efficient encoders: TransBiMamba, ConBiMamba, and PN-BiMamba. Leveraging XLSR's rich linguistic representations, PN-BiMamba can effectively capture the subtle cues of synthetic speech. Evaluated on ASVspoof 21 LA, 21 DF, and In-The-Wild benchmarks, Fake-Mamba achieves 0.97%, 1.74%, and 5.85% EER, respectively, representing substantial relative gains over SOTA models XLSR-Conformer and XLSR-Mamba. The framework maintains real-time inference across utterance lengths, demonstrating strong generalization and practical viability. The code is available at https://github.com/xuanxixi/Fake-Mamba.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "eess.SY"
    ],
    "primary_category": "eess.AS",
    "comment": "Accepted at IEEE ASRU 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.09294v1",
    "published_date": "2025-08-12 19:15:13 UTC",
    "updated_date": "2025-08-12 19:15:13 UTC"
  },
  {
    "arxiv_id": "2508.09293v1",
    "title": "Ethical Medical Image Synthesis",
    "authors": [
      "Weina Jin",
      "Ashish Sinha",
      "Kumar Abhishek",
      "Ghassan Hamarneh"
    ],
    "abstract": "The task of ethical Medical Image Synthesis (MISyn) is to ensure that the MISyn techniques are researched and developed ethically throughout their entire lifecycle, which is essential to prevent the negative impacts of MISyn. To address the ever-increasing needs and requirements for ethical practice of MISyn research and development, we first conduct a theoretical analysis that identifies the key properties of ethical MISyn and intrinsic limits of MISyn. We identify that synthetic images lack inherent grounding in real medical phenomena, cannot fully represent the training medical images, and inevitably introduce new distribution shifts and biases.\n  Ethical risks can arise from not acknowledging the intrinsic limits and weaknesses of synthetic images compared to medical images, with the extreme form manifested as misinformation of MISyn that substitutes synthetic images for medical images without acknowledgment. The resulting ethical harms include eroding trust in the medical imaging dataset environment and causing algorithmic discrimination towards stakeholders and the public.\n  To facilitate collective efforts towards ethical MISyn within and outside the medical image analysis community, we then propose practical supports for ethical practice in MISyn based on the theoretical analysis, including ethical practice recommendations that adapt the existing technical standards, problem formulation, design, and evaluation practice of MISyn to the ethical challenges; and oversight recommendations to facilitate checks and balances from stakeholders and the public. We also present two case studies that demonstrate how to apply the ethical practice recommendations in practice, and identify gaps between existing practice and the ethical practice recommendations.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.09293v1",
    "published_date": "2025-08-12 19:14:37 UTC",
    "updated_date": "2025-08-12 19:14:37 UTC"
  },
  {
    "arxiv_id": "2508.09292v1",
    "title": "The Othello AI Arena: Evaluating Intelligent Systems Through Limited-Time Adaptation to Unseen Boards",
    "authors": [
      "Sundong Kim"
    ],
    "abstract": "The ability to rapidly adapt to novel and unforeseen environmental changes is a cornerstone of artificial general intelligence (AGI), yet it remains a critical blind spot in most existing AI benchmarks. Traditional evaluation largely focuses on optimizing performance within fixed environments, failing to assess systems' flexibility and generalization capabilities when faced with even subtle rule or structural modifications. Addressing this gap, I introduce the Othello AI Arena, a novel benchmark framework designed to evaluate intelligent systems based on their capacity for limited-time adaptation to unseen environments. Our platform poses a meta-learning challenge: participants must develop systems that can analyze the specific configuration and rules of a novel Othello board within a strict time limit (60 seconds) and generate a tailored, high-performing strategy for that unique environment. With this, evaluation of the meta-level intelligence can be separated from the task-level strategy performance. The Arena features a diverse set of game stages, including public stages for development and private stages with structural and rule variations designed to test genuine adaptive and generalization capabilities. Implemented as an accessible web-based platform, the Arena provides real-time visualization, automated evaluation using multi-dimensional metrics, and comprehensive logging for post-hoc analysis. Initial observations from pilot tests and preliminary student engagements highlight fascinating patterns in adaptation approaches, ranging from rapid parameter tuning to rudimentary environmental model learning through simulation. The Othello AI Arena offers a unique educational tool and a valuable research benchmark for fostering and evaluating the crucial skill of rapid, intelligent adaptation in AI systems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.09292v1",
    "published_date": "2025-08-12 19:10:58 UTC",
    "updated_date": "2025-08-12 19:10:58 UTC"
  },
  {
    "arxiv_id": "2508.09288v2",
    "title": "Can AI Keep a Secret? Contextual Integrity Verification: A Provable Security Architecture for LLMs",
    "authors": [
      "Aayush Gupta"
    ],
    "abstract": "Large language models (LLMs) remain acutely vulnerable to prompt injection and related jailbreak attacks; heuristic guardrails (rules, filters, LLM judges) are routinely bypassed. We present Contextual Integrity Verification (CIV), an inference-time security architecture that attaches cryptographically signed provenance labels to every token and enforces a source-trust lattice inside the transformer via a pre-softmax hard attention mask (with optional FFN/residual gating). CIV provides deterministic, per-token non-interference guarantees on frozen models: lower-trust tokens cannot influence higher-trust representations. On benchmarks derived from recent taxonomies of prompt-injection vectors (Elite-Attack + SoK-246), CIV attains 0% attack success rate under the stated threat model while preserving 93.1% token-level similarity and showing no degradation in model perplexity on benign tasks; we note a latency overhead attributable to a non-optimized data path. Because CIV is a lightweight patch -- no fine-tuning required -- we demonstrate drop-in protection for Llama-3-8B and Mistral-7B. We release a reference implementation, an automated certification harness, and the Elite-Attack corpus to support reproducible research.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "2 figures, 3 tables; code and certification harness: https://github.com/ayushgupta4897/Contextual-Integrity-Verification ; Elite-Attack dataset: https://huggingface.co/datasets/zyushg/elite-attack",
    "pdf_url": "https://arxiv.org/pdf/2508.09288v2",
    "published_date": "2025-08-12 18:47:30 UTC",
    "updated_date": "2025-08-18 18:20:18 UTC"
  },
  {
    "arxiv_id": "2508.09277v1",
    "title": "Value Function Initialization for Knowledge Transfer and Jump-start in Deep Reinforcement Learning",
    "authors": [
      "Soumia Mehimeh"
    ],
    "abstract": "Value function initialization (VFI) is an effective way to achieve a jumpstart in reinforcement learning (RL) by leveraging value estimates from prior tasks. While this approach is well established in tabular settings, extending it to deep reinforcement learning (DRL) poses challenges due to the continuous nature of the state-action space, the noisy approximations of neural networks, and the impracticality of storing all past models for reuse. In this work, we address these challenges and introduce DQInit, a method that adapts value function initialization to DRL. DQInit reuses compact tabular Q-values extracted from previously solved tasks as a transferable knowledge base. It employs a knownness-based mechanism to softly integrate these transferred values into underexplored regions and gradually shift toward the agent's learned estimates, avoiding the limitations of fixed time decay. Our approach offers a novel perspective on knowledge transfer in DRL by relying solely on value estimates rather than policies or demonstrations, effectively combining the strengths of jumpstart RL and policy distillation while mitigating their drawbacks. Experiments across multiple continuous control tasks demonstrate that DQInit consistently improves early learning efficiency, stability, and overall performance compared to standard initialization and existing transfer techniques.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.09277v1",
    "published_date": "2025-08-12 18:32:08 UTC",
    "updated_date": "2025-08-12 18:32:08 UTC"
  },
  {
    "arxiv_id": "2508.11695v1",
    "title": "RefAdGen: High-Fidelity Advertising Image Generation",
    "authors": [
      "Yiyun Chen",
      "Weikai Yang"
    ],
    "abstract": "The rapid advancement of Artificial Intelligence Generated Content (AIGC) techniques has unlocked opportunities in generating diverse and compelling advertising images based on referenced product images and textual scene descriptions. This capability substantially reduces human labor and production costs in traditional marketing workflows. However, existing AIGC techniques either demand extensive fine-tuning for each referenced image to achieve high fidelity, or they struggle to maintain fidelity across diverse products, making them impractical for e-commerce and marketing industries. To tackle this limitation, we first construct AdProd-100K, a large-scale advertising image generation dataset. A key innovation in its construction is our dual data augmentation strategy, which fosters robust, 3D-aware representations crucial for realistic and high-fidelity image synthesis. Leveraging this dataset, we propose RefAdGen, a generation framework that achieves high fidelity through a decoupled design. The framework enforces precise spatial control by injecting a product mask at the U-Net input, and employs an efficient Attention Fusion Module (AFM) to integrate product features. This design effectively resolves the fidelity-efficiency dilemma present in existing methods. Extensive experiments demonstrate that RefAdGen achieves state-of-the-art performance, showcasing robust generalization by maintaining high fidelity and remarkable visual results for both unseen products and challenging real-world, in-the-wild images. This offers a scalable and cost-effective alternative to traditional workflows. Code and datasets are publicly available at https://github.com/Anonymous-Name-139/RefAdgen.",
    "categories": [
      "cs.GR",
      "cs.AI"
    ],
    "primary_category": "cs.GR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.11695v1",
    "published_date": "2025-08-12 18:25:31 UTC",
    "updated_date": "2025-08-12 18:25:31 UTC"
  },
  {
    "arxiv_id": "2508.09264v1",
    "title": "Detection of Odor Presence via Deep Neural Networks",
    "authors": [
      "Matin Hassanloo",
      "Ali Zareh",
      "Mehmet Kemal Özdemir"
    ],
    "abstract": "Odor detection underpins food safety, environmental monitoring, medical diagnostics, and many more fields. The current artificial sensors developed for odor detection struggle with complex mixtures while non-invasive recordings lack reliable single-trial fidelity. To develop a general system for odor detection, in this study we present a preliminary work where we aim to test two hypotheses: (i) that spectral features of local field potentials (LFPs) are sufficient for robust single-trial odor detection and (ii) that signals from the olfactory bulb alone are adequate. To test two hypotheses, we propose an ensemble of complementary one-dimensional convolutional networks (ResCNN and AttentionCNN) that decodes the presence of odor from multichannel olfactory bulb LFPs. Tested on 2,349 trials from seven awake mice, our final ensemble model supports both hypotheses, achieving a mean accuracy of 86.6%, an F1-score of 81.0%, and an AUC of 0.9247, substantially outperforming previous benchmarks. In addition, the t-SNE visualization confirms that our framework captures biologically significant signatures. These findings establish the feasibility of robust single-trial detection of the presence of odor from extracellular LFPs, as well as demonstrate the potential of deep learning models to provide a deeper understanding of olfactory representations.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.09264v1",
    "published_date": "2025-08-12 18:14:24 UTC",
    "updated_date": "2025-08-12 18:14:24 UTC"
  },
  {
    "arxiv_id": "2508.09138v3",
    "title": "Time Is a Feature: Exploiting Temporal Dynamics in Diffusion Language Models",
    "authors": [
      "Wen Wang",
      "Bozhen Fang",
      "Chenchen Jing",
      "Yongliang Shen",
      "Yangyi Shen",
      "Qiuyu Wang",
      "Hao Ouyang",
      "Hao Chen",
      "Chunhua Shen"
    ],
    "abstract": "Diffusion large language models (dLLMs) generate text through iterative denoising, yet current decoding strategies discard rich intermediate predictions in favor of the final output. Our work here reveals a critical phenomenon, temporal oscillation, where correct answers often emerge in the middle process, but are overwritten in later denoising steps. To address this issue, we introduce two complementary methods that exploit temporal consistency: 1) Temporal Self-Consistency Voting, a training-free, test-time decoding strategy that aggregates predictions across denoising steps to select the most consistent output; and 2) a post-training method termed Temporal Consistency Reinforcement, which uses Temporal Semantic Entropy (TSE), a measure of semantic stability across intermediate predictions, as a reward signal to encourage stable generations. Empirical results across multiple benchmarks demonstrate the effectiveness of our approach. Using the negative TSE reward alone, we observe a remarkable average improvement of 24.7% on the Countdown dataset over an existing dLLM. Combined with the accuracy reward, we achieve absolute gains of 2.0% on GSM8K, 4.3% on MATH500, 6.6% on SVAMP, and 25.3% on Countdown, respectively. Our findings underscore the untapped potential of temporal dynamics in dLLMs and offer two simple yet effective tools to harness them.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Project webpage: https://aim-uofa.github.io/dLLM-MidTruth",
    "pdf_url": "https://arxiv.org/pdf/2508.09138v3",
    "published_date": "2025-08-12 17:59:57 UTC",
    "updated_date": "2025-10-06 14:46:22 UTC"
  },
  {
    "arxiv_id": "2508.09131v2",
    "title": "Training-Free Text-Guided Color Editing with Multi-Modal Diffusion Transformer",
    "authors": [
      "Zixin Yin",
      "Xili Dai",
      "Ling-Hao Chen",
      "Deyu Zhou",
      "Jianan Wang",
      "Duomin Wang",
      "Gang Yu",
      "Lionel M. Ni",
      "Lei Zhang",
      "Heung-Yeung Shum"
    ],
    "abstract": "Text-guided color editing in images and videos is a fundamental yet unsolved problem, requiring fine-grained manipulation of color attributes, including albedo, light source color, and ambient lighting, while preserving physical consistency in geometry, material properties, and light-matter interactions. Existing training-free methods offer broad applicability across editing tasks but struggle with precise color control and often introduce visual inconsistency in both edited and non-edited regions. In this work, we present ColorCtrl, a training-free color editing method that leverages the attention mechanisms of modern Multi-Modal Diffusion Transformers (MM-DiT). By disentangling structure and color through targeted manipulation of attention maps and value tokens, our method enables accurate and consistent color editing, along with word-level control of attribute intensity. Our method modifies only the intended regions specified by the prompt, leaving unrelated areas untouched. Extensive experiments on both SD3 and FLUX.1-dev demonstrate that ColorCtrl outperforms existing training-free approaches and achieves state-of-the-art performances in both edit quality and consistency. Furthermore, our method surpasses strong commercial models such as FLUX.1 Kontext Max and GPT-4o Image Generation in terms of consistency. When extended to video models like CogVideoX, our approach exhibits greater advantages, particularly in maintaining temporal coherence and editing stability. Finally, our method also generalizes to instruction-based editing diffusion models such as Step1X-Edit and FLUX.1 Kontext dev, further demonstrating its versatility.",
    "categories": [
      "cs.GR",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.GR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.09131v2",
    "published_date": "2025-08-12 17:57:04 UTC",
    "updated_date": "2025-08-13 01:20:54 UTC"
  },
  {
    "arxiv_id": "2508.09129v1",
    "title": "BrowseMaster: Towards Scalable Web Browsing via Tool-Augmented Programmatic Agent Pair",
    "authors": [
      "Xianghe Pang",
      "Shuo Tang",
      "Rui Ye",
      "Yuwen Du",
      "Yaxin Du",
      "Siheng Chen"
    ],
    "abstract": "Effective information seeking in the vast and ever-growing digital landscape requires balancing expansive search with strategic reasoning. Current large language model (LLM)-based agents struggle to achieve this balance due to limitations in search breadth and reasoning depth, where slow, serial querying restricts coverage of relevant sources and noisy raw inputs disrupt the continuity of multi-step reasoning. To address these challenges, we propose BrowseMaster, a scalable framework built around a programmatically augmented planner-executor agent pair. The planner formulates and adapts search strategies based on task constraints, while the executor conducts efficient, targeted retrieval to supply the planner with concise, relevant evidence. This division of labor preserves coherent, long-horizon reasoning while sustaining broad and systematic exploration, overcoming the trade-off that limits existing agents. Extensive experiments on challenging English and Chinese benchmarks show that BrowseMaster consistently outperforms open-source and proprietary baselines, achieving scores of 30.0 on BrowseComp-en and 46.5 on BrowseComp-zh, which demonstrates its strong capability in complex, reasoning-heavy information-seeking tasks at scale.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.09129v1",
    "published_date": "2025-08-12 17:56:25 UTC",
    "updated_date": "2025-08-12 17:56:25 UTC"
  },
  {
    "arxiv_id": "2508.09123v3",
    "title": "OpenCUA: Open Foundations for Computer-Use Agents",
    "authors": [
      "Xinyuan Wang",
      "Bowen Wang",
      "Dunjie Lu",
      "Junlin Yang",
      "Tianbao Xie",
      "Junli Wang",
      "Jiaqi Deng",
      "Xiaole Guo",
      "Yiheng Xu",
      "Chen Henry Wu",
      "Zhennan Shen",
      "Zhuokai Li",
      "Ryan Li",
      "Xiaochuan Li",
      "Junda Chen",
      "Boyuan Zheng",
      "Peihang Li",
      "Fangyu Lei",
      "Ruisheng Cao",
      "Yeqiao Fu",
      "Dongchan Shin",
      "Martin Shin",
      "Jiarui Hu",
      "Yuyan Wang",
      "Jixuan Chen",
      "Yuxiao Ye",
      "Danyang Zhang",
      "Dikang Du",
      "Hao Hu",
      "Huarong Chen",
      "Zaida Zhou",
      "Haotian Yao",
      "Ziwei Chen",
      "Qizheng Gu",
      "Yipu Wang",
      "Heng Wang",
      "Diyi Yang",
      "Victor Zhong",
      "Flood Sung",
      "Y. Charles",
      "Zhilin Yang",
      "Tao Yu"
    ],
    "abstract": "Vision-language models have demonstrated impressive capabilities as computer-use agents (CUAs) capable of automating diverse computer tasks. As their commercial potential grows, critical details of the most capable CUA systems remain closed. As these agents will increasingly mediate digital interactions and execute consequential decisions on our behalf, the research community needs access to open CUA frameworks to study their capabilities, limitations, and risks. To bridge this gap, we propose OpenCUA, a comprehensive open-source framework for scaling CUA data and foundation models. Our framework consists of: (1) an annotation infrastructure that seamlessly captures human computer-use demonstrations; (2) AgentNet, the first large-scale computer-use task dataset spanning 3 operating systems and 200+ applications and websites; (3) a scalable pipeline that transforms demonstrations into state-action pairs with reflective long Chain-of-Thought reasoning that sustain robust performance gains as data scales. Our end-to-end agent models demonstrate strong performance across CUA benchmarks. In particular, OpenCUA-72B achieves an average success rate of 45.0% on OSWorld-Verified, establishing a new state-of-the-art (SOTA) among open-source models. Further analysis confirms that our approach generalizes well across domains and benefits significantly from increased test-time computation. We release our annotation tool, datasets, code, and models to build open foundations for further CUA research.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "Updata author list, modify first page format, correct typos",
    "pdf_url": "https://arxiv.org/pdf/2508.09123v3",
    "published_date": "2025-08-12 17:52:32 UTC",
    "updated_date": "2025-10-04 17:38:02 UTC"
  },
  {
    "arxiv_id": "2508.13179v1",
    "title": "Toward an African Agenda for AI Safety",
    "authors": [
      "Samuel T. Segun",
      "Rachel Adams",
      "Ana Florido",
      "Scott Timcke",
      "Jonathan Shock",
      "Leah Junck",
      "Fola Adeleke",
      "Nicolas Grossman",
      "Ayantola Alayande",
      "Jerry John Kponyo",
      "Matthew Smith",
      "Dickson Marfo Fosu",
      "Prince Dawson Tetteh",
      "Juliet Arthur",
      "Stephanie Kasaon",
      "Odilile Ayodele",
      "Laetitia Badolo",
      "Paul Plantinga",
      "Michael Gastrow",
      "Sumaya Nur Adan",
      "Joanna Wiaterek",
      "Cecil Abungu",
      "Kojo Apeagyei",
      "Luise Eder",
      "Tegawende Bissyande"
    ],
    "abstract": "This paper maps Africa's distinctive AI risk profile, from deepfake fuelled electoral interference and data colonial dependency to compute scarcity, labour disruption and disproportionate exposure to climate driven environmental costs. While major benefits are promised to accrue, the availability, development and adoption of AI also mean that African people and countries face particular AI safety risks, from large scale labour market disruptions to the nefarious use of AI to manipulate public opinion. To date, African perspectives have not been meaningfully integrated into global debates and processes regarding AI safety, leaving African stakeholders with limited influence over the emerging global AI safety governance agenda. While there are Computer Incident Response Teams on the continent, none hosts a dedicated AI Safety Institute or office. We propose a five-point action plan centred on (i) a policy approach that foregrounds the protection of the human rights of those most vulnerable to experiencing the harmful socio-economic effects of AI; (ii) the establishment of an African AI Safety Institute; (iii) promote public AI literacy and awareness; (iv) development of early warning system with inclusive benchmark suites for 25+ African languages; and (v) an annual AU-level AI Safety & Security Forum.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "28 pages, 2 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.13179v1",
    "published_date": "2025-08-12 17:42:09 UTC",
    "updated_date": "2025-08-12 17:42:09 UTC"
  },
  {
    "arxiv_id": "2508.09105v2",
    "title": "SMA: Who Said That? Auditing Membership Leakage in Semi-Black-box RAG Controlling",
    "authors": [
      "Shixuan Sun",
      "Siyuan Liang",
      "Ruoyu Chen",
      "Jianjie Huang",
      "Jingzhi Li",
      "Xiaochun Cao"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) and its Multimodal Retrieval-Augmented Generation (MRAG) significantly improve the knowledge coverage and contextual understanding of Large Language Models (LLMs) by introducing external knowledge sources. However, retrieval and multimodal fusion obscure content provenance, rendering existing membership inference methods unable to reliably attribute generated outputs to pre-training, external retrieval, or user input, thus undermining privacy leakage accountability\n  To address these challenges, we propose the first Source-aware Membership Audit (SMA) that enables fine-grained source attribution of generated content in a semi-black-box setting with retrieval control capabilities. To address the environmental constraints of semi-black-box auditing, we further design an attribution estimation mechanism based on zero-order optimization, which robustly approximates the true influence of input tokens on the output through large-scale perturbation sampling and ridge regression modeling. In addition, SMA introduces a cross-modal attribution technique that projects image inputs into textual descriptions via MLLMs, enabling token-level attribution in the text modality, which for the first time facilitates membership inference on image retrieval traces in MRAG systems. This work shifts the focus of membership inference from 'whether the data has been memorized' to 'where the content is sourced from', offering a novel perspective for auditing data provenance in complex generative systems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.09105v2",
    "published_date": "2025-08-12 17:32:24 UTC",
    "updated_date": "2025-08-13 11:05:22 UTC"
  },
  {
    "arxiv_id": "2508.09100v1",
    "title": "Towards Universal Neural Inference",
    "authors": [
      "Shreyas Bhat Brahmavar",
      "Yang Li",
      "Junier Oliva"
    ],
    "abstract": "Real-world data often appears in diverse, disjoint forms -- with varying schemas, inconsistent semantics, and no fixed feature ordering -- making it challenging to build general-purpose models that can leverage information across datasets. We introduce ASPIRE, Arbitrary Set-based Permutation-Invariant Reasoning Engine, a Universal Neural Inference model for semantic reasoning and prediction over heterogeneous structured data. ASPIRE combines a permutation-invariant, set-based Transformer with a semantic grounding module that incorporates natural language descriptions, dataset metadata, and in-context examples to learn cross-dataset feature dependencies. This architecture allows ASPIRE to ingest arbitrary sets of feature--value pairs and support examples, align semantics across disjoint tables, and make predictions for any specified target. Once trained, ASPIRE generalizes to new inference tasks without additional tuning. In addition to delivering strong results across diverse benchmarks, ASPIRE naturally supports cost-aware active feature acquisition in an open-world setting, selecting informative features under test-time budget constraints for an arbitrary unseen dataset. These capabilities position ASPIRE as a step toward truly universal, semantics-aware inference over structured data.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.09100v1",
    "published_date": "2025-08-12 17:26:48 UTC",
    "updated_date": "2025-08-12 17:26:48 UTC"
  },
  {
    "arxiv_id": "2508.09090v2",
    "title": "SPARC: Soft Probabilistic Adaptive multi-interest Retrieval Model via Codebooks for recommender system",
    "authors": [
      "Jialiang Shi",
      "Yaguang Dou",
      "Tian Qi"
    ],
    "abstract": "Modeling multi-interests has arisen as a core problem in real-world RS. Current multi-interest retrieval methods pose three major challenges: 1) Interests, typically extracted from predefined external knowledge, are invariant. Failed to dynamically evolve with users' real-time consumption preferences. 2) Online inference typically employs an over-exploited strategy, mainly matching users' existing interests, lacking proactive exploration and discovery of novel and long-tail interests. To address these challenges, we propose a novel retrieval framework named SPARC(Soft Probabilistic Adaptive Retrieval Model via Codebooks). Our contribution is two folds. First, the framework utilizes Residual Quantized Variational Autoencoder (RQ-VAE) to construct a discretized interest space. It achieves joint training of the RQ-VAE with the industrial large scale recommendation model, mining behavior-aware interests that can perceive user feedback and evolve dynamically. Secondly, a probabilistic interest module that predicts the probability distribution over the entire dynamic and discrete interest space. This facilitates an efficient \"soft-search\" strategy during online inference, revolutionizing the retrieval paradigm from \"passive matching\" to \"proactive exploration\" and thereby effectively promoting interest discovery. Online A/B tests on an industrial platform with tens of millions daily active users, have achieved substantial gains in business metrics: +0.9% increase in user view duration, +0.4% increase in user page views (PV), and a +22.7% improvement in PV500(new content reaching 500 PVs in 24 hours). Offline evaluations are conducted on open-source Amazon Product datasets. Metrics, such as Recall@K and Normalized Discounted Cumulative Gain@K(NDCG@K), also showed consistent improvement. Both online and offline experiments validate the efficacy and practical value of the proposed method.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "8 pages",
    "pdf_url": "https://arxiv.org/pdf/2508.09090v2",
    "published_date": "2025-08-12 17:16:37 UTC",
    "updated_date": "2025-08-13 01:51:32 UTC"
  },
  {
    "arxiv_id": "2508.09085v1",
    "title": "Dynamic Uncertainty-aware Multimodal Fusion for Outdoor Health Monitoring",
    "authors": [
      "Zihan Fang",
      "Zheng Lin",
      "Senkang Hu",
      "Yihang Tao",
      "Yiqin Deng",
      "Xianhao Chen",
      "Yuguang Fang"
    ],
    "abstract": "Outdoor health monitoring is essential to detect early abnormal health status for safeguarding human health and safety. Conventional outdoor monitoring relies on static multimodal deep learning frameworks, which requires extensive data training from scratch and fails to capture subtle health status changes. Multimodal large language models (MLLMs) emerge as a promising alternative, utilizing only small datasets to fine-tune pre-trained information-rich models for enabling powerful health status monitoring. Unfortunately, MLLM-based outdoor health monitoring also faces significant challenges: I) sensor data contains input noise stemming from sensor data acquisition and fluctuation noise caused by sudden changes in physiological signals due to dynamic outdoor environments, thus degrading the training performance; ii) current transformer based MLLMs struggle to achieve robust multimodal fusion, as they lack a design for fusing the noisy modality; iii) modalities with varying noise levels hinder accurate recovery of missing data from fluctuating distributions. To combat these challenges, we propose an uncertainty-aware multimodal fusion framework, named DUAL-Health, for outdoor health monitoring in dynamic and noisy environments. First, to assess the impact of noise, we accurately quantify modality uncertainty caused by input and fluctuation noise with current and temporal features. Second, to empower efficient muitimodal fusion with low-quality modalities,we customize the fusion weight for each modality based on quantified and calibrated uncertainty. Third, to enhance data recovery from fluctuating noisy modalities, we align modality distributions within a common semantic space. Extensive experiments demonstrate that our DUAL-Health outperforms state-of-the-art baselines in detection accuracy and robustness.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NI",
    "comment": "14 pages, 10 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.09085v1",
    "published_date": "2025-08-12 17:07:27 UTC",
    "updated_date": "2025-08-12 17:07:27 UTC"
  },
  {
    "arxiv_id": "2508.09054v1",
    "title": "CVCM Track Circuits Pre-emptive Failure Diagnostics for Predictive Maintenance Using Deep Neural Networks",
    "authors": [
      "Debdeep Mukherjee",
      "Eduardo Di Santi",
      "Clément Lefebvre",
      "Nenad Mijatovic",
      "Victor Martin",
      "Thierry Josse",
      "Jonathan Brown",
      "Kenza Saiah"
    ],
    "abstract": "Track circuits are critical for railway operations, acting as the main signalling sub-system to locate trains. Continuous Variable Current Modulation (CVCM) is one such technology. Like any field-deployed, safety-critical asset, it can fail, triggering cascading disruptions. Many failures originate as subtle anomalies that evolve over time, often not visually apparent in monitored signals. Conventional approaches, which rely on clear signal changes, struggle to detect them early. Early identification of failure types is essential to improve maintenance planning, minimising downtime and revenue loss. Leveraging deep neural networks, we propose a predictive maintenance framework that classifies anomalies well before they escalate into failures. Validated on 10 CVCM failure cases across different installations, the method is ISO-17359 compliant and outperforms conventional techniques, achieving 99.31% overall accuracy with detection within 1% of anomaly onset. Through conformal prediction, we provide uncertainty estimates, reaching 99% confidence with consistent coverage across classes. Given CVCMs global deployment, the approach is scalable and adaptable to other track circuits and railway systems, enhancing operational reliability.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.AI",
    "comment": "Peer-reviewed conference paper. Presented at ICROMA 2025 (International Conference on Railway Operations Modelling and Analysis), Dresden, Germany. https://tu-dresden.de/raildresden2025 8 pages, 6 figures, 1 table",
    "pdf_url": "https://arxiv.org/pdf/2508.09054v1",
    "published_date": "2025-08-12 16:13:51 UTC",
    "updated_date": "2025-08-12 16:13:51 UTC"
  },
  {
    "arxiv_id": "2508.16607v2",
    "title": "\"Accessibility people, you go work on that thing of yours over there\": Addressing Disability Inclusion in AI Product Organizations",
    "authors": [
      "Sanika Moharana",
      "Cynthia L. Bennett",
      "Erin Buehler",
      "Michael Madaio",
      "Vinita Tibdewal",
      "Shaun K. Kane"
    ],
    "abstract": "The rapid emergence of generative AI has changed the way that technology is designed, constructed, maintained, and evaluated. Decisions made when creating AI-powered systems may impact some users disproportionately, such as people with disabilities. In this paper, we report on an interview study with 25 AI practitioners across multiple roles (engineering, research, UX, and responsible AI) about how their work processes and artifacts may impact end users with disabilities. We found that practitioners experienced friction when triaging problems at the intersection of responsible AI and accessibility practices, navigated contradictions between accessibility and responsible AI guidelines, identified gaps in data about users with disabilities, and gathered support for addressing the needs of disabled stakeholders by leveraging informal volunteer and community groups within their company. Based on these findings, we offer suggestions for new resources and process changes to better support people with disabilities as end users of AI.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.16607v2",
    "published_date": "2025-08-12 16:08:42 UTC",
    "updated_date": "2025-11-05 16:58:10 UTC"
  },
  {
    "arxiv_id": "2508.09242v1",
    "title": "Cross-BCI, A Cross-BCI-Paradigm Classifica-tion Model Towards Universal BCI Applications",
    "authors": [
      "Gaojie Zhou",
      "Junhua Li"
    ],
    "abstract": "Classification models used in brain-computer interface (BCI) are usually designed for a single BCI paradigm. This requires the redevelopment of the model when applying it to a new BCI paradigm, resulting in repeated costs and effort. Moreover, less complex deep learning models are desired for practical usage, as well as for deployment on portable devices. In or-der to fill the above gaps, we, in this study, proposed a light-weight and unified decoding model for cross-BCI-paradigm classification. The proposed model starts with a tempo-spatial convolution. It is followed by a multi-scale local feature selec-tion module, aiming to extract local features shared across BCI paradigms and generate weighted features. Finally, a mul-ti-dimensional global feature extraction module is designed, in which multi-dimensional global features are extracted from the weighted features and fused with the weighted features to form high-level feature representations associated with BCI para-digms. The results, evaluated on a mixture of three classical BCI paradigms (i.e., MI, SSVEP, and P300), demon-strate that the proposed model achieves 88.39%, 82.36%, 80.01%, and 0.8092 for accuracy, macro-precision, mac-ro-recall, and macro-F1-score, respectively, significantly out-performing the compared models. This study pro-vides a feasible solution for cross-BCI-paradigm classifica-tion. It lays a technological foundation for de-veloping a new generation of unified decoding systems, paving the way for low-cost and universal practical applications.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.09242v1",
    "published_date": "2025-08-12 16:04:50 UTC",
    "updated_date": "2025-08-12 16:04:50 UTC"
  },
  {
    "arxiv_id": "2508.09036v1",
    "title": "Can We Trust AI to Govern AI? Benchmarking LLM Performance on Privacy and AI Governance Exams",
    "authors": [
      "Zane Witherspoon",
      "Thet Mon Aye",
      "YingYing Hao"
    ],
    "abstract": "The rapid emergence of large language models (LLMs) has raised urgent questions across the modern workforce about this new technology's strengths, weaknesses, and capabilities. For privacy professionals, the question is whether these AI systems can provide reliable support on regulatory compliance, privacy program management, and AI governance. In this study, we evaluate ten leading open and closed LLMs, including models from OpenAI, Anthropic, Google DeepMind, Meta, and DeepSeek, by benchmarking their performance on industry-standard certification exams: CIPP/US, CIPM, CIPT, and AIGP from the International Association of Privacy Professionals (IAPP). Each model was tested using official sample exams in a closed-book setting and compared to IAPP's passing thresholds. Our findings show that several frontier models such as Gemini 2.5 Pro and OpenAI's GPT-5 consistently achieve scores exceeding the standards for professional human certification - demonstrating substantial expertise in privacy law, technical controls, and AI governance. The results highlight both the strengths and domain-specific gaps of current LLMs and offer practical insights for privacy officers, compliance leads, and technologists assessing the readiness of AI tools for high-stakes data governance roles. This paper provides an overview for professionals navigating the intersection of AI advancement and regulatory risk and establishes a machine benchmark based on human-centric evaluations.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.09036v1",
    "published_date": "2025-08-12 15:57:22 UTC",
    "updated_date": "2025-08-12 15:57:22 UTC"
  },
  {
    "arxiv_id": "2508.09032v1",
    "title": "Spatial Traces: Enhancing VLA Models with Spatial-Temporal Understanding",
    "authors": [
      "Maxim A. Patratskiy",
      "Alexey K. Kovalev",
      "Aleksandr I. Panov"
    ],
    "abstract": "Vision-Language-Action models have demonstrated remarkable capabilities in predicting agent movements within virtual environments and real-world scenarios based on visual observations and textual instructions. Although recent research has focused on enhancing spatial and temporal understanding independently, this paper presents a novel approach that integrates both aspects through visual prompting. We introduce a method that projects visual traces of key points from observations onto depth maps, enabling models to capture both spatial and temporal information simultaneously. The experiments in SimplerEnv show that the mean number of tasks successfully solved increased for 4% compared to SpatialVLA and 19% compared to TraceVLA. Furthermore, we show that this enhancement can be achieved with minimal training data, making it particularly valuable for real-world applications where data collection is challenging. The project page is available at https://ampiromax.github.io/ST-VLA.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.09032v1",
    "published_date": "2025-08-12 15:53:45 UTC",
    "updated_date": "2025-08-12 15:53:45 UTC"
  },
  {
    "arxiv_id": "2508.10052v1",
    "title": "NetMoniAI: An Agentic AI Framework for Network Security & Monitoring",
    "authors": [
      "Pallavi Zambare",
      "Venkata Nikhil Thanikella",
      "Nikhil Padmanabh Kottur",
      "Sree Akhil Akula",
      "Ying Liu"
    ],
    "abstract": "In this paper, we present NetMoniAI, an agentic AI framework for automatic network monitoring and security that integrates decentralized analysis with lightweight centralized coordination. The framework consists of two layers: autonomous micro-agents at each node perform local traffic analysis and anomaly detection. A central controller then aggregates insights across nodes to detect coordinated attacks and maintain system-wide situational awareness. We evaluated NetMoniAI on a local micro-testbed and through NS-3 simulations. Results confirm that the two-tier agentic-AI design scales under resource constraints, reduces redundancy, and improves response time without compromising accuracy. To facilitate broader adoption and reproducibility, the complete framework is available as open source. This enables researchers and practitioners to replicate, validate, and extend it across diverse network environments and threat scenarios. Github link: https://github.com/pzambare3/NetMoniAI",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted in IEEE 3rd International Conference on Artificial Intelligence, Blockchain, and Internet of Things (AIBThings 2025)",
    "pdf_url": "https://arxiv.org/pdf/2508.10052v1",
    "published_date": "2025-08-12 15:48:53 UTC",
    "updated_date": "2025-08-12 15:48:53 UTC"
  },
  {
    "arxiv_id": "2508.09027v1",
    "title": "A First Look at Predictability and Explainability of Pre-request Passenger Waiting Time in Ridesharing Systems",
    "authors": [
      "Jie Wang",
      "Guang Wang"
    ],
    "abstract": "Passenger waiting time prediction plays a critical role in enhancing both ridesharing user experience and platform efficiency. While most existing research focuses on post-request waiting time prediction with knowing the matched driver information, pre-request waiting time prediction (i.e., before submitting a ride request and without matching a driver) is also important, as it enables passengers to plan their trips more effectively and enhance the experience of both passengers and drivers. However, it has not been fully studied by existing works. In this paper, we take the first step toward understanding the predictability and explainability of pre-request passenger waiting time in ridesharing systems. Particularly, we conduct an in-depth data-driven study to investigate the impact of demand&supply dynamics on passenger waiting time. Based on this analysis and feature engineering, we propose FiXGBoost, a novel feature interaction-based XGBoost model designed to predict waiting time without knowing the assigned driver information. We further perform an importance analysis to quantify the contribution of each factor. Experiments on a large-scale real-world ridesharing dataset including over 30 million trip records show that our FiXGBoost can achieve a good performance for pre-request passenger waiting time prediction with high explainability.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.09027v1",
    "published_date": "2025-08-12 15:42:14 UTC",
    "updated_date": "2025-08-12 15:42:14 UTC"
  },
  {
    "arxiv_id": "2508.09023v2",
    "title": "E3-Rewrite: Learning to Rewrite SQL for Executability, Equivalence,and Efficiency",
    "authors": [
      "Dongjie Xu",
      "Yue Cui",
      "Weijie Shi",
      "Qingzhi Ma",
      "Hanghui Guo",
      "Jiaming Li",
      "Yao Zhao",
      "Ruiyuan Zhang",
      "Shimin Di",
      "Jia Zhu",
      "Kai Zheng",
      "Jiajie Xu"
    ],
    "abstract": "SQL query rewriting aims to reformulate a query into a more efficient form while preserving equivalence. Most existing methods rely on predefined rewrite rules. However, such rule-based approaches face fundamental limitations: (1) fixed rule sets generalize poorly to novel query patterns and struggle with complex queries; (2) a wide range of effective rewriting strategies cannot be fully captured by declarative rules. To overcome these issues, we propose using large language models (LLMs) to generate rewrites. LLMs can capture complex strategies, such as evaluation reordering and CTE rewriting. Despite this potential, directly applying LLMs often results in performance regressions or non-equivalent rewrites due to a lack of execution awareness and semantic grounding. To address these challenges, We present E3-Rewrite, an LLM-based SQL rewriting framework that produces executable, equivalent, and efficient queries. It integrates two core components: a context construction module and a reinforcement learning framework. First, the context module leverages execution plans and retrieved demonstrations to build bottleneck-aware prompts that guide inference-time rewriting. Second, we design a reward function targeting executability, equivalence, and efficiency, evaluated via syntax checks, equivalence verification, and cost estimation. Third, to ensure stable multi-objective learning, we adopt a staged curriculum that first emphasizes executability and equivalence, then gradually incorporates efficiency. Across multiple SQL benchmarks, our experiments demonstrate that E3-Rewrite can shorten query execution time by as much as 25.6% relative to leading baselines, while also producing up to 24.4% more rewrites that meet strict equivalence criteria. These gains extend to challenging query patterns that prior approaches could not effectively optimize.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.09023v2",
    "published_date": "2025-08-12 15:38:10 UTC",
    "updated_date": "2025-08-15 03:52:09 UTC"
  },
  {
    "arxiv_id": "2508.09022v3",
    "title": "Leveraging Unlabeled Data from Unknown Sources via Dual-Path Guidance for Deepfake Face Detection",
    "authors": [
      "Zhiqiang Yang",
      "Renshuai Tao",
      "Chunjie Zhang",
      "guodong yang",
      "Xiaolong Zheng",
      "Yao Zhao"
    ],
    "abstract": "Existing deepfake detection methods heavily rely on static labeled datasets. However, with the proliferation of generative models, real-world scenarios are flooded with massive amounts of unlabeled fake face data from unknown sources. This presents a critical dilemma: detectors relying solely on existing data face generalization failure, while manual labeling for this new stream is infeasible due to the high realism of fakes. A more fundamental challenge is that, unlike typical unsupervised learning tasks where categories are clearly defined, real and fake faces share the same semantics, which leads to a decline in the performance of traditional unsupervised strategies. Therefore, there is an urgent need for a new paradigm designed specifically for this scenario to effectively utilize these unlabeled data. Accordingly, this paper proposes a dual-path guided network (DPGNet) to address two key challenges: (1) bridging the domain differences between faces generated by different generative models; and (2) utilizing unlabeled image samples. The method comprises two core modules: text-guided cross-domain alignment, which uses learnable cues to unify visual and textual embeddings into a domain-invariant feature space; and curriculum-driven pseudo-label generation, which dynamically utilizes unlabeled samples. Extensive experiments on multiple mainstream datasets show that DPGNet significantly outperforms existing techniques,, highlighting its effectiveness in addressing the challenges posed by the deepfakes using unlabeled data.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "11pages,4figures",
    "pdf_url": "https://arxiv.org/pdf/2508.09022v3",
    "published_date": "2025-08-12 15:37:17 UTC",
    "updated_date": "2025-11-25 09:30:41 UTC"
  },
  {
    "arxiv_id": "2508.09021v1",
    "title": "Attacks and Defenses Against LLM Fingerprinting",
    "authors": [
      "Kevin Kurian",
      "Ethan Holland",
      "Sean Oesch"
    ],
    "abstract": "As large language models are increasingly deployed in sensitive environments, fingerprinting attacks pose significant privacy and security risks. We present a study of LLM fingerprinting from both offensive and defensive perspectives. Our attack methodology uses reinforcement learning to automatically optimize query selection, achieving better fingerprinting accuracy with only 3 queries compared to randomly selecting 3 queries from the same pool. Our defensive approach employs semantic-preserving output filtering through a secondary LLM to obfuscate model identity while maintaining semantic integrity. The defensive method reduces fingerprinting accuracy across tested models while preserving output quality. These contributions show the potential to improve fingerprinting tools capabilities while providing practical mitigation strategies against fingerprinting attacks.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.09021v1",
    "published_date": "2025-08-12 15:36:36 UTC",
    "updated_date": "2025-08-12 15:36:36 UTC"
  },
  {
    "arxiv_id": "2508.09019v1",
    "title": "Activation Steering for Bias Mitigation: An Interpretable Approach to Safer LLMs",
    "authors": [
      "Shivam Dubey"
    ],
    "abstract": "As large language models (LLMs) become more integrated into societal systems, the risk of them perpetuating and amplifying harmful biases becomes a critical safety concern. Traditional methods for mitigating bias often rely on data filtering or post-hoc output moderation, which treat the model as an opaque black box. In this work, we introduce a complete, end-to-end system that uses techniques from mechanistic interpretability to both identify and actively mitigate bias directly within a model's internal workings. Our method involves two primary stages. First, we train linear \"probes\" on the internal activations of a model to detect the latent representations of various biases (e.g., gender, race, age). Our experiments on \\texttt{gpt2-large} demonstrate that these probes can identify biased content with near-perfect accuracy, revealing that bias representations become most salient in the model's later layers. Second, we leverage these findings to compute \"steering vectors\" by contrasting the model's activation patterns for biased and neutral statements. By adding these vectors during inference, we can actively steer the model's generative process away from producing harmful, stereotypical, or biased content in real-time. We demonstrate the efficacy of this activation steering technique, showing that it successfully alters biased completions toward more neutral alternatives. We present our work as a robust and reproducible system that offers a more direct and interpretable approach to building safer and more accountable LLMs.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.09019v1",
    "published_date": "2025-08-12 15:34:18 UTC",
    "updated_date": "2025-08-12 15:34:18 UTC"
  },
  {
    "arxiv_id": "2508.09012v1",
    "title": "LyS at SemEval 2025 Task 8: Zero-Shot Code Generation for Tabular QA",
    "authors": [
      "Adrián Gude",
      "Roi Santos-Ríos",
      "Francisco Prado-Valiño",
      "Ana Ezquerro",
      "Jesús Vilares"
    ],
    "abstract": "This paper describes our participation in SemEval 2025 Task 8, focused on Tabular Question Answering. We developed a zero-shot pipeline that leverages an Large Language Model to generate functional code capable of extracting the relevant information from tabular data based on an input question. Our approach consists of a modular pipeline where the main code generator module is supported by additional components that identify the most relevant columns and analyze their data types to improve extraction accuracy. In the event that the generated code fails, an iterative refinement process is triggered, incorporating the error feedback into a new generation prompt to enhance robustness. Our results show that zero-shot code generation is a valid approach for Tabular QA, achieving rank 33 of 53 in the test phase despite the lack of task-specific fine-tuning.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to SemEval 2025. Camera-ready version",
    "pdf_url": "https://arxiv.org/pdf/2508.09012v1",
    "published_date": "2025-08-12 15:25:31 UTC",
    "updated_date": "2025-08-12 15:25:31 UTC"
  },
  {
    "arxiv_id": "2508.09001v1",
    "title": "Retrospective Sparse Attention for Efficient Long-Context Generation",
    "authors": [
      "Seonghwan Choi",
      "Beomseok Kang",
      "Dongwon Jo",
      "Jae-Joon Kim"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly deployed in long-context tasks such as reasoning, code generation, and multi-turn dialogue. However, inference over extended contexts is bottlenecked by the Key-Value (KV) cache, whose memory footprint grows linearly with sequence length and dominates latency at each decoding step. While recent KV cache compression methods identify and load important tokens, they focus predominantly on input contexts and fail to address the cumulative attention errors that arise during long decoding. In this paper, we introduce RetroAttention, a novel KV cache update technique that retrospectively revises past attention outputs using newly arrived KV entries from subsequent decoding steps. By maintaining a lightweight output cache, RetroAttention enables past queries to efficiently access more relevant context, while incurring minimal latency overhead. This breaks the fixed-attention-output paradigm and allows continual correction of prior approximations. Extensive experiments on long-generation benchmarks show that RetroAttention consistently outperforms state-of-the-art (SOTA) KV compression methods, increasing effective KV exposure by up to 1.6$\\times$ and accuracy by up to 21.9\\%.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.09001v1",
    "published_date": "2025-08-12 15:11:47 UTC",
    "updated_date": "2025-08-12 15:11:47 UTC"
  },
  {
    "arxiv_id": "2508.08997v2",
    "title": "Intrinsic Memory Agents: Heterogeneous Multi-Agent LLM Systems through Structured Contextual Memory",
    "authors": [
      "Sizhe Yuen",
      "Francisco Gomez Medina",
      "Ting Su",
      "Yali Du",
      "Adam J. Sobey"
    ],
    "abstract": "Multi-agent systems built on Large Language Models (LLMs) show exceptional promise for complex collaborative problem-solving, yet they face fundamental challenges stemming from context window limitations that impair memory consistency, role adherence, and procedural integrity. This paper introduces Intrinsic Memory Agents, a novel framework that addresses these limitations through agent-specific memories that evolve intrinsically with agent outputs. Specifically, our method maintains role-aligned memory that preserves specialized perspectives while focusing on task-relevant information. Our approach utilises a generic memory template applicable to new problems without the need to hand-craft specific memory prompts. We benchmark our approach on the PDDL, FEVER, and ALFWorld datasets, comparing its performance to existing state-of-the-art multi-agentic memory approaches and showing state-of-the-art or comparable performance across all three, with the highest consistency. An additional evaluation is performed on a complex data pipeline design task, and we demonstrate that our approach produces higher quality designs across 5 metrics: scalability, reliability, usability, cost-effectiveness, and documentation, plus additional qualitative evidence of the improvements. Our findings suggest that addressing memory limitations through intrinsic approaches can improve the capabilities of multi-agent LLM systems on structured planning tasks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.08997v2",
    "published_date": "2025-08-12 15:05:00 UTC",
    "updated_date": "2026-01-12 11:46:09 UTC"
  },
  {
    "arxiv_id": "2508.09240v1",
    "title": "NEFMind: Parameter-Efficient Fine-Tuning of Open-Source LLMs for Telecom APIs Automation",
    "authors": [
      "Zainab Khan",
      "Ahmed Hussain",
      "Mukesh Thakur",
      "Arto Hellas",
      "Panos Papadimitratos"
    ],
    "abstract": "The use of Service-Based Architecture in modern telecommunications has exponentially increased Network Functions (NFs) and Application Programming Interfaces (APIs), creating substantial operational complexities in service discovery and management. We introduce \\textit{NEFMind}, a framework leveraging parameter-efficient fine-tuning of open-source Large Language Models (LLMs) to address these challenges. It integrates three core components: synthetic dataset generation from Network Exposure Function (NEF) API specifications, model optimization through Quantized-Low-Rank Adaptation, and performance evaluation via GPT-4 Ref Score and BertScore metrics. Targeting 5G Service-Based Architecture APIs, our approach achieves 85% reduction in communication overhead compared to manual discovery methods. Experimental validation using the open-source Phi-2 model demonstrates exceptional API call identification performance at 98-100% accuracy. The fine-tuned Phi-2 model delivers performance comparable to significantly larger models like GPT-4 while maintaining computational efficiency for telecommunications infrastructure deployment. These findings validate domain-specific, parameter-efficient LLM strategies for managing complex API ecosystems in next-generation telecommunications networks.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.NI",
    "comment": "6 pages",
    "pdf_url": "https://arxiv.org/pdf/2508.09240v1",
    "published_date": "2025-08-12 15:03:22 UTC",
    "updated_date": "2025-08-12 15:03:22 UTC"
  },
  {
    "arxiv_id": "2508.08992v1",
    "title": "Prospect Theory Fails for LLMs: Revealing Instability of Decision-Making under Epistemic Uncertainty",
    "authors": [
      "Rui Wang",
      "Qihan Lin",
      "Jiayu Liu",
      "Qing Zong",
      "Tianshi Zheng",
      "Weiqi Wang",
      "Yangqiu Song"
    ],
    "abstract": "Prospect Theory (PT) models human decision-making under uncertainty, while epistemic markers (e.g., maybe) serve to express uncertainty in language. However, it remains largely unexplored whether Prospect Theory applies to contemporary Large Language Models and whether epistemic markers, which express human uncertainty, affect their decision-making behaviour. To address these research gaps, we design a three-stage experiment based on economic questionnaires. We propose a more general and precise evaluation framework to model LLMs' decision-making behaviour under PT, introducing uncertainty through the empirical probability values associated with commonly used epistemic markers in comparable contexts. We then incorporate epistemic markers into the evaluation framework based on their corresponding probability values to examine their influence on LLM decision-making behaviours. Our findings suggest that modelling LLMs' decision-making with PT is not consistently reliable, particularly when uncertainty is expressed in diverse linguistic forms. Our code is released in https://github.com/HKUST-KnowComp/MarPT.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.08992v1",
    "published_date": "2025-08-12 15:02:16 UTC",
    "updated_date": "2025-08-12 15:02:16 UTC"
  },
  {
    "arxiv_id": "2508.14077v1",
    "title": "Label Smoothing is a Pragmatic Information Bottleneck",
    "authors": [
      "Sota Kudo"
    ],
    "abstract": "This study revisits label smoothing via a form of information bottleneck. Under the assumption of sufficient model flexibility and no conflicting labels for the same input, we theoretically and experimentally demonstrate that the model output obtained through label smoothing explores the optimal solution of the information bottleneck. Based on this, label smoothing can be interpreted as a practical approach to the information bottleneck, enabling simple implementation. As an information bottleneck method, we experimentally show that label smoothing also exhibits the property of being insensitive to factors that do not contain information about the target, or to factors that provide no additional information about it when conditioned on another variable.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "18 pages, 8 figures, published in Transactions on Machine Learning Research (TMLR), 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.14077v1",
    "published_date": "2025-08-12 14:50:23 UTC",
    "updated_date": "2025-08-12 14:50:23 UTC"
  },
  {
    "arxiv_id": "2508.08983v1",
    "title": "Rational Inverse Reasoning",
    "authors": [
      "Ben Zandonati",
      "Tomás Lozano-Pérez",
      "Leslie Pack Kaelbling"
    ],
    "abstract": "Humans can observe a single, imperfect demonstration and immediately generalize to very different problem settings. Robots, in contrast, often require hundreds of examples and still struggle to generalize beyond the training conditions. We argue that this limitation arises from the inability to recover the latent explanations that underpin intelligent behavior, and that these explanations can take the form of structured programs consisting of high-level goals, sub-task decomposition, and execution constraints. In this work, we introduce Rational Inverse Reasoning (RIR), a framework for inferring these latent programs through a hierarchical generative model of behavior. RIR frames few-shot imitation as Bayesian program induction: a vision-language model iteratively proposes structured symbolic task hypotheses, while a planner-in-the-loop inference scheme scores each by the likelihood of the observed demonstration under that hypothesis. This loop yields a posterior over concise, executable programs. We evaluate RIR on a suite of continuous manipulation tasks designed to test one-shot and few-shot generalization across variations in object pose, count, geometry, and layout. With as little as one demonstration, RIR infers the intended task structure and generalizes to novel settings, outperforming state-of-the-art vision-language model baselines.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.08983v1",
    "published_date": "2025-08-12 14:49:44 UTC",
    "updated_date": "2025-08-12 14:49:44 UTC"
  },
  {
    "arxiv_id": "2508.08982v1",
    "title": "Unsupervised Skill Discovery as Exploration for Learning Agile Locomotion",
    "authors": [
      "Seungeun Rho",
      "Kartik Garg",
      "Morgan Byrd",
      "Sehoon Ha"
    ],
    "abstract": "Exploration is crucial for enabling legged robots to learn agile locomotion behaviors that can overcome diverse obstacles. However, such exploration is inherently challenging, and we often rely on extensive reward engineering, expert demonstrations, or curriculum learning - all of which limit generalizability. In this work, we propose Skill Discovery as Exploration (SDAX), a novel learning framework that significantly reduces human engineering effort. SDAX leverages unsupervised skill discovery to autonomously acquire a diverse repertoire of skills for overcoming obstacles. To dynamically regulate the level of exploration during training, SDAX employs a bi-level optimization process that autonomously adjusts the degree of exploration. We demonstrate that SDAX enables quadrupedal robots to acquire highly agile behaviors including crawling, climbing, leaping, and executing complex maneuvers such as jumping off vertical walls. Finally, we deploy the learned policy on real hardware, validating its successful transfer to the real world.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Conference on Robot Learning 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.08982v1",
    "published_date": "2025-08-12 14:49:25 UTC",
    "updated_date": "2025-08-12 14:49:25 UTC"
  },
  {
    "arxiv_id": "2508.08976v1",
    "title": "Urban-STA4CLC: Urban Theory-Informed Spatio-Temporal Attention Model for Predicting Post-Disaster Commercial Land Use Change",
    "authors": [
      "Ziyi Guo",
      "Yan Wang"
    ],
    "abstract": "Natural disasters such as hurricanes and wildfires increasingly introduce unusual disturbance on economic activities, which are especially likely to reshape commercial land use pattern given their sensitive to customer visitation. However, current modeling approaches are limited in capturing such complex interplay between human activities and commercial land use change under and following disturbances. Such interactions have been more effectively captured in current resilient urban planning theories. This study designs and calibrates a Urban Theory-Informed Spatio-Temporal Attention Model for Predicting Post-Disaster Commercial Land Use Change (Urban-STA4CLC) to predict both the yearly decline and expansion of commercial land use at census block level under cumulative impact of disasters on human activities over two years. Guided by urban theories, Urban-STA4CLC integrates both spatial and temporal attention mechanisms with three theory-informed modules. Resilience theory guides a disaster-aware temporal attention module that captures visitation dynamics. Spatial economic theory informs a multi-relational spatial attention module for inter-block representation. Diffusion theory contributes a regularization term that constrains land use transitions. The model performs significantly better than non-theoretical baselines in predicting commercial land use change under the scenario of recurrent hurricanes, with around 19% improvement in F1 score (0.8763). The effectiveness of the theory-guided modules was further validated through ablation studies. The research demonstrates that embedding urban theory into commercial land use modeling models may substantially enhance the capacity to capture its gains and losses. These advances in commercial land use modeling contribute to land use research that accounts for cumulative impacts of recurrent disasters and shifts in economic activity patterns.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.08976v1",
    "published_date": "2025-08-12 14:39:42 UTC",
    "updated_date": "2025-08-12 14:39:42 UTC"
  },
  {
    "arxiv_id": "2508.11693v1",
    "title": "Track Component Failure Detection Using Data Analytics over existing STDS Track Circuit data",
    "authors": [
      "Francisco López",
      "Eduardo Di Santi",
      "Clément Lefebvre",
      "Nenad Mijatovic",
      "Michele Pugnaloni",
      "Victor Martín",
      "Kenza Saiah"
    ],
    "abstract": "Track Circuits (TC) are the main signalling devices used to detect the presence of a train on a rail track. It has been used since the 19th century and nowadays there are many types depending on the technology. As a general classification, Track Circuits can be divided into 2 main groups, DC (Direct Current) and AC (Alternating Current) circuits. This work is focused on a particular AC track circuit, called \"Smart Train Detection System\" (STDS), designed with both high and low-frequency bands. This approach uses STDS current data applied to an SVM (support vector machine) classifier as a type of failure identifier. The main purpose of this work consists on determine automatically which is the component of the track that is failing to improve the maintenance action. Model was trained to classify 15 different failures that belong to 3 more general categories. The method was tested with field data from 10 different track circuits and validated by the STDS track circuit expert and maintainers. All use cases were correctly classified by the method.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "eess.SP",
    "comment": "Peer-reviewed conference paper. Presented at ICROMA 2025 (International Conference on Railway Operations Modelling and Analysis), Dresden, Germany",
    "pdf_url": "https://arxiv.org/pdf/2508.11693v1",
    "published_date": "2025-08-12 14:35:18 UTC",
    "updated_date": "2025-08-12 14:35:18 UTC"
  },
  {
    "arxiv_id": "2508.08967v2",
    "title": "Revealing the Role of Audio Channels in ASR Performance Degradation",
    "authors": [
      "Kuan-Tang Huang",
      "Li-Wei Chen",
      "Hung-Shin Lee",
      "Berlin Chen",
      "Hsin-Min Wang"
    ],
    "abstract": "Pre-trained automatic speech recognition (ASR) models have demonstrated strong performance on a variety of tasks. However, their performance can degrade substantially when the input audio comes from different recording channels. While previous studies have demonstrated this phenomenon, it is often attributed to the mismatch between training and testing corpora. This study argues that variations in speech characteristics caused by different recording channels can fundamentally harm ASR performance. To address this limitation, we propose a normalization technique designed to mitigate the impact of channel variation by aligning internal feature representations in the ASR model with those derived from a clean reference channel. This approach significantly improves ASR performance on previously unseen channels and languages, highlighting its ability to generalize across channel and language differences.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted to IEEE ASRU 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.08967v2",
    "published_date": "2025-08-12 14:32:48 UTC",
    "updated_date": "2025-08-22 04:10:08 UTC"
  },
  {
    "arxiv_id": "2508.14076v1",
    "title": "PersRM-R1: Enhance Personalized Reward Modeling with Reinforcement Learning",
    "authors": [
      "Mengdi Li",
      "Guanqiao Chen",
      "Xufeng Zhao",
      "Haochen Wen",
      "Shu Yang",
      "Di Wang"
    ],
    "abstract": "Reward models (RMs), which are central to existing post-training methods, aim to align LLM outputs with human values by providing feedback signals during fine-tuning. However, existing RMs struggle to capture nuanced, user-specific preferences, especially under limited data and across diverse domains. Thus, we introduce PersRM-R1, the first reasoning-based reward modeling framework specifically designed to identify and represent personal factors from only one or a few personal exemplars. To address challenges including limited data availability and the requirement for robust generalization, our approach combines synthetic data generation with a two-stage training pipeline consisting of supervised fine-tuning followed by reinforcement fine-tuning. Experimental results demonstrate that PersRM-R1 outperforms existing models of similar size and matches the performance of much larger models in both accuracy and generalizability, paving the way for more effective personalized LLMs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.14076v1",
    "published_date": "2025-08-12 14:25:58 UTC",
    "updated_date": "2025-08-12 14:25:58 UTC"
  },
  {
    "arxiv_id": "2508.09765v1",
    "title": "Enhance the machine learning algorithm performance in phishing detection with keyword features",
    "authors": [
      "Zijiang Yang"
    ],
    "abstract": "Recently, we can observe a significant increase of the phishing attacks in the Internet. In a typical phishing attack, the attacker sets up a malicious website that looks similar to the legitimate website in order to obtain the end-users' information. This may cause the leakage of the sensitive information and the financial loss for the end-users. To avoid such attacks, the early detection of these websites' URLs is vital and necessary. Previous researchers have proposed many machine learning algorithms to distinguish the phishing URLs from the legitimate ones. In this paper, we would like to enhance these machine learning algorithms from the perspective of feature selection. We propose a novel method to incorporate the keyword features with the traditional features. This method is applied on multiple traditional machine learning algorithms and the experimental results have shown this method is useful and effective. On average, this method can reduce the classification error by 30% for the large dataset. Moreover, its enhancement is more significant for the small dataset. In addition, this method extracts the information from the URL and does not rely on the additional information provided by the third-part service. The best result for the machine learning algorithm using our proposed method has achieved the accuracy of 99.68%.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.09765v1",
    "published_date": "2025-08-12 14:16:11 UTC",
    "updated_date": "2025-08-12 14:16:11 UTC"
  },
  {
    "arxiv_id": "2508.08957v1",
    "title": "QAMRO: Quality-aware Adaptive Margin Ranking Optimization for Human-aligned Assessment of Audio Generation Systems",
    "authors": [
      "Chien-Chun Wang",
      "Kuan-Tang Huang",
      "Cheng-Yeh Yang",
      "Hung-Shin Lee",
      "Hsin-Min Wang",
      "Berlin Chen"
    ],
    "abstract": "Evaluating audio generation systems, including text-to-music (TTM), text-to-speech (TTS), and text-to-audio (TTA), remains challenging due to the subjective and multi-dimensional nature of human perception. Existing methods treat mean opinion score (MOS) prediction as a regression problem, but standard regression losses overlook the relativity of perceptual judgments. To address this limitation, we introduce QAMRO, a novel Quality-aware Adaptive Margin Ranking Optimization framework that seamlessly integrates regression objectives from different perspectives, aiming to highlight perceptual differences and prioritize accurate ratings. Our framework leverages pre-trained audio-text models such as CLAP and Audiobox-Aesthetics, and is trained exclusively on the official AudioMOS Challenge 2025 dataset. It demonstrates superior alignment with human evaluations across all dimensions, significantly outperforming robust baseline models.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted to IEEE ASRU 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.08957v1",
    "published_date": "2025-08-12 14:14:04 UTC",
    "updated_date": "2025-08-12 14:14:04 UTC"
  },
  {
    "arxiv_id": "2509.05298v1",
    "title": "Livia: An Emotion-Aware AR Companion Powered by Modular AI Agents and Progressive Memory Compression",
    "authors": [
      "Rui Xi",
      "Xianghan Wang"
    ],
    "abstract": "Loneliness and social isolation pose significant emotional and health challenges, prompting the development of technology-based solutions for companionship and emotional support. This paper introduces Livia, an emotion-aware augmented reality (AR) companion app designed to provide personalized emotional support by combining modular artificial intelligence (AI) agents, multimodal affective computing, progressive memory compression, and AR driven embodied interaction. Livia employs a modular AI architecture with specialized agents responsible for emotion analysis, dialogue generation, memory management, and behavioral orchestration, ensuring robust and adaptive interactions. Two novel algorithms-Temporal Binary Compression (TBC) and Dynamic Importance Memory Filter (DIMF)-effectively manage and prioritize long-term memory, significantly reducing storage requirements while retaining critical context. Our multimodal emotion detection approach achieves high accuracy, enhancing proactive and empathetic engagement. User evaluations demonstrated increased emotional bonds, improved satisfaction, and statistically significant reductions in loneliness. Users particularly valued Livia's adaptive personality evolution and realistic AR embodiment. Future research directions include expanding gesture and tactile interactions, supporting multi-user experiences, and exploring customized hardware implementations.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted to the Proceedings of the 2025 International Conference on Artificial Intelligence and Virtual Reality (AIVR 2025). \\c{opyright} 2025 Springer. This is the author-accepted manuscript. Rui Xi and Xianghan Wang contributed equally to this work. The final version will be available via SpringerLink",
    "pdf_url": "https://arxiv.org/pdf/2509.05298v1",
    "published_date": "2025-08-12 14:07:22 UTC",
    "updated_date": "2025-08-12 14:07:22 UTC"
  },
  {
    "arxiv_id": "2508.08947v2",
    "title": "Generalising Traffic Forecasting to Regions without Traffic Observations",
    "authors": [
      "Xinyu Su",
      "Majid Sarvi",
      "Feng Liu",
      "Egemen Tanin",
      "Jianzhong Qi"
    ],
    "abstract": "Traffic forecasting is essential for intelligent transportation systems. Accurate forecasting relies on continuous observations collected by traffic sensors. However, due to high deployment and maintenance costs, not all regions are equipped with such sensors. This paper aims to forecast for regions without traffic sensors, where the lack of historical traffic observations challenges the generalisability of existing models. We propose a model named GenCast, the core idea of which is to exploit external knowledge to compensate for the missing observations and to enhance generalisation. We integrate physics-informed neural networks into GenCast, enabling physical principles to regularise the learning process. We introduce an external signal learning module to explore correlations between traffic states and external signals such as weather conditions, further improving model generalisability. Additionally, we design a spatial grouping module to filter localised features that hinder model generalisability. Extensive experiments show that GenCast consistently reduces forecasting errors on multiple real-world datasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by AAAI 2026",
    "pdf_url": "https://arxiv.org/pdf/2508.08947v2",
    "published_date": "2025-08-12 14:00:12 UTC",
    "updated_date": "2025-12-30 09:59:42 UTC"
  },
  {
    "arxiv_id": "2508.08940v1",
    "title": "Train Long, Think Short: Curriculum Learning for Efficient Reasoning",
    "authors": [
      "Hasan Abed Al Kader Hammoud",
      "Kumail Alhamoud",
      "Abed Hammoud",
      "Elie Bou-Zeid",
      "Marzyeh Ghassemi",
      "Bernard Ghanem"
    ],
    "abstract": "Recent work on enhancing the reasoning abilities of large language models (LLMs) has introduced explicit length control as a means of constraining computational cost while preserving accuracy. However, existing approaches rely on fixed-length training budgets, which do not take advantage of the natural progression from exploration to compression during learning. In this work, we propose a curriculum learning strategy for length-controlled reasoning using Group Relative Policy Optimization (GRPO). Our method starts with generous token budgets and gradually tightens them over training, encouraging models to first discover effective solution strategies and then distill them into more concise reasoning traces. We augment GRPO with a reward function that balances three signals: task correctness (via verifier feedback), length efficiency, and formatting adherence (via structural tags). Experiments on GSM8K, MATH500, SVAMP, College Math, and GSM+ demonstrate that curriculum-based training consistently outperforms fixed-budget baselines at the same final budget, achieving higher accuracy and significantly improved token efficiency. We further ablate the impact of reward weighting and decay schedule design, showing that progressive constraint serves as a powerful inductive bias for training efficient reasoning models. Our code and checkpoints are released at: https://github.com/hammoudhasan/curriculum_grpo.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Under Review",
    "pdf_url": "https://arxiv.org/pdf/2508.08940v1",
    "published_date": "2025-08-12 13:48:03 UTC",
    "updated_date": "2025-08-12 13:48:03 UTC"
  },
  {
    "arxiv_id": "2508.08926v1",
    "title": "Safe Semantics, Unsafe Interpretations: Tackling Implicit Reasoning Safety in Large Vision-Language Models",
    "authors": [
      "Wei Cai",
      "Jian Zhao",
      "Yuchu Jiang",
      "Tianle Zhang",
      "Xuelong Li"
    ],
    "abstract": "Large Vision-Language Models face growing safety challenges with multimodal inputs. This paper introduces the concept of Implicit Reasoning Safety, a vulnerability in LVLMs. Benign combined inputs trigger unsafe LVLM outputs due to flawed or hidden reasoning. To showcase this, we developed Safe Semantics, Unsafe Interpretations, the first dataset for this critical issue. Our demonstrations show that even simple In-Context Learning with SSUI significantly mitigates these implicit multimodal threats, underscoring the urgent need to improve cross-modal implicit reasoning.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.08926v1",
    "published_date": "2025-08-12 13:26:06 UTC",
    "updated_date": "2025-08-12 13:26:06 UTC"
  },
  {
    "arxiv_id": "2508.08924v1",
    "title": "EGGCodec: A Robust Neural Encodec Framework for EGG Reconstruction and F0 Extraction",
    "authors": [
      "Rui Feng",
      "Yuang Chen",
      "Yu Hu",
      "Jun Du",
      "Jiahong Yuan"
    ],
    "abstract": "This letter introduces EGGCodec, a robust neural Encodec framework engineered for electroglottography (EGG) signal reconstruction and F0 extraction. We propose a multi-scale frequency-domain loss function to capture the nuanced relationship between original and reconstructed EGG signals, complemented by a time-domain correlation loss to improve generalization and accuracy. Unlike conventional Encodec models that extract F0 directly from features, EGGCodec leverages reconstructed EGG signals, which more closely correspond to F0. By removing the conventional GAN discriminator, we streamline EGGCodec's training process without compromising efficiency, incurring only negligible performance degradation. Trained on a widely used EGG-inclusive dataset, extensive evaluations demonstrate that EGGCodec outperforms state-of-the-art F0 extraction schemes, reducing mean absolute error (MAE) from 14.14 Hz to 13.69 Hz, and improving voicing decision error (VDE) by 38.2\\%. Moreover, extensive ablation experiments validate the contribution of each component of EGGCodec.",
    "categories": [
      "eess.AS",
      "cs.AI"
    ],
    "primary_category": "eess.AS",
    "comment": "5 pages, 5 figures, to be appeared in IEEE Signal Processing Letters",
    "pdf_url": "https://arxiv.org/pdf/2508.08924v1",
    "published_date": "2025-08-12 13:20:25 UTC",
    "updated_date": "2025-08-12 13:20:25 UTC"
  },
  {
    "arxiv_id": "2508.08923v1",
    "title": "Shape Completion and Real-Time Visualization in Robotic Ultrasound Spine Acquisitions",
    "authors": [
      "Miruna-Alexandra Gafencu",
      "Reem Shaban",
      "Yordanka Velikova",
      "Mohammad Farid Azampour",
      "Nassir Navab"
    ],
    "abstract": "Ultrasound (US) imaging is increasingly used in spinal procedures due to its real-time, radiation-free capabilities; however, its effectiveness is hindered by shadowing artifacts that obscure deeper tissue structures. Traditional approaches, such as CT-to-US registration, incorporate anatomical information from preoperative CT scans to guide interventions, but they are limited by complex registration requirements, differences in spine curvature, and the need for recent CT imaging. Recent shape completion methods can offer an alternative by reconstructing spinal structures in US data, while being pretrained on large set of publicly available CT scans. However, these approaches are typically offline and have limited reproducibility. In this work, we introduce a novel integrated system that combines robotic ultrasound with real-time shape completion to enhance spinal visualization. Our robotic platform autonomously acquires US sweeps of the lumbar spine, extracts vertebral surfaces from ultrasound, and reconstructs the complete anatomy using a deep learning-based shape completion network. This framework provides interactive, real-time visualization with the capability to autonomously repeat scans and can enable navigation to target locations. This can contribute to better consistency, reproducibility, and understanding of the underlying anatomy. We validate our approach through quantitative experiments assessing shape completion accuracy and evaluations of multiple spine acquisition protocols on a phantom setup. Additionally, we present qualitative results of the visualization on a volunteer scan.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.08923v1",
    "published_date": "2025-08-12 13:19:37 UTC",
    "updated_date": "2025-08-12 13:19:37 UTC"
  },
  {
    "arxiv_id": "2508.11692v1",
    "title": "Scalable, Technology-Agnostic Diagnosis and Predictive Maintenance for Point Machine using Deep Learning",
    "authors": [
      "Eduardo Di Santi",
      "Ruixiang Ci",
      "Clément Lefebvre",
      "Nenad Mijatovic",
      "Michele Pugnaloni",
      "Jonathan Brown",
      "Victor Martín",
      "Kenza Saiah"
    ],
    "abstract": "The Point Machine (PM) is a critical piece of railway equipment that switches train routes by diverting tracks through a switchblade. As with any critical safety equipment, a failure will halt operations leading to service disruptions; therefore, pre-emptive maintenance may avoid unnecessary interruptions by detecting anomalies before they become failures. Previous work relies on several inputs and crafting custom features by segmenting the signal. This not only adds additional requirements for data collection and processing, but it is also specific to the PM technology, the installed locations and operational conditions limiting scalability. Based on the available maintenance records, the main failure causes for PM are obstacles, friction, power source issues and misalignment. Those failures affect the energy consumption pattern of PMs, altering the usual (or healthy) shape of the power signal during the PM movement. In contrast to the current state-of-the-art, our method requires only one input. We apply a deep learning model to the power signal pattern to classify if the PM is nominal or associated with any failure type, achieving >99.99\\% precision, <0.01\\% false positives and negligible false negatives. Our methodology is generic and technology-agnostic, proven to be scalable on several electromechanical PM types deployed in both real-world and test bench environments. Finally, by using conformal prediction the maintainer gets a clear indication of the certainty of the system outputs, adding a confidence layer to operations and making the method compliant with the ISO-17359 standard.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "Peer-reviewed conference paper. Presented at ICROMA 2025, Dresden, Germany. Conference: https://tu-dresden.de/raildresden2025. Book of abstracts: https://tu-dresden.de/raildresden2025/BoA.pdf. 8 pages, 6 figures, 1 table",
    "pdf_url": "https://arxiv.org/pdf/2508.11692v1",
    "published_date": "2025-08-12 13:15:56 UTC",
    "updated_date": "2025-08-12 13:15:56 UTC"
  },
  {
    "arxiv_id": "2508.09239v1",
    "title": "Gradient-Direction-Aware Density Control for 3D Gaussian Splatting",
    "authors": [
      "Zheng Zhou",
      "Yu-Jie Xiong",
      "Chun-Ming Xia",
      "Jia-Chen Zhang",
      "Hong-Jian Zhan"
    ],
    "abstract": "The emergence of 3D Gaussian Splatting (3DGS) has significantly advanced novel view synthesis through explicit scene representation, enabling real-time photorealistic rendering. However, existing approaches manifest two critical limitations in complex scenarios: (1) Over-reconstruction occurs when persistent large Gaussians cannot meet adaptive splitting thresholds during density control. This is exacerbated by conflicting gradient directions that prevent effective splitting of these Gaussians; (2) Over-densification of Gaussians occurs in regions with aligned gradient aggregation, leading to redundant component proliferation. This redundancy significantly increases memory overhead due to unnecessary data retention. We present Gradient-Direction-Aware Gaussian Splatting (GDAGS), a gradient-direction-aware adaptive density control framework to address these challenges. Our key innovations: the gradient coherence ratio (GCR), computed through normalized gradient vector norms, which explicitly discriminates Gaussians with concordant versus conflicting gradient directions; and a nonlinear dynamic weighting mechanism leverages the GCR to enable gradient-direction-aware density control. Specifically, GDAGS prioritizes conflicting-gradient Gaussians during splitting operations to enhance geometric details while suppressing redundant concordant-direction Gaussians. Conversely, in cloning processes, GDAGS promotes concordant-direction Gaussian densification for structural completion while preventing conflicting-direction Gaussian overpopulation. Comprehensive evaluations across diverse real-world benchmarks demonstrate that GDAGS achieves superior rendering quality while effectively mitigating over-reconstruction, suppressing over-densification, and constructing compact scene representations with 50\\% reduced memory consumption through optimized Gaussians utilization.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.09239v1",
    "published_date": "2025-08-12 13:12:54 UTC",
    "updated_date": "2025-08-12 13:12:54 UTC"
  },
  {
    "arxiv_id": "2508.16606v1",
    "title": "Multimodal Appearance based Gaze-Controlled Virtual Keyboard with Synchronous Asynchronous Interaction for Low-Resource Settings",
    "authors": [
      "Yogesh Kumar Meena",
      "Manish Salvi"
    ],
    "abstract": "Over the past decade, the demand for communication devices has increased among individuals with mobility and speech impairments. Eye-gaze tracking has emerged as a promising solution for hands-free communication; however, traditional appearance-based interfaces often face challenges such as accuracy issues, involuntary eye movements, and difficulties with extensive command sets. This work presents a multimodal appearance-based gaze-controlled virtual keyboard that utilises deep learning in conjunction with standard camera hardware, incorporating both synchronous and asynchronous modes for command selection. The virtual keyboard application supports menu-based selection with nine commands, enabling users to spell and type up to 56 English characters, including uppercase and lowercase letters, punctuation, and a delete function for corrections. The proposed system was evaluated with twenty able-bodied participants who completed specially designed typing tasks using three input modalities: (i) a mouse, (ii) an eye-tracker, and (iii) an unmodified webcam. Typing performance was measured in terms of speed and information transfer rate (ITR) at both command and letter levels. Average typing speeds were 18.3+-5.31 letters/min (mouse), 12.60+-2.99letters/min (eye-tracker, synchronous), 10.94 +- 1.89 letters/min (webcam, synchronous), 11.15 +- 2.90 letters/min (eye-tracker, asynchronous), and 7.86 +- 1.69 letters/min (webcam, asynchronous). ITRs were approximately 80.29 +- 15.72 bits/min (command level) and 63.56 +- 11 bits/min (letter level) with webcam in synchronous mode. The system demonstrated good usability and low workload with webcam input, highlighting its user-centred design and promise as an accessible communication tool in low-resource settings.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.16606v1",
    "published_date": "2025-08-12 13:08:54 UTC",
    "updated_date": "2025-08-12 13:08:54 UTC"
  },
  {
    "arxiv_id": "2508.08912v1",
    "title": "Munsit at NADI 2025 Shared Task 2: Pushing the Boundaries of Multidialectal Arabic ASR with Weakly Supervised Pretraining and Continual Supervised Fine-tuning",
    "authors": [
      "Mahmoud Salhab",
      "Shameed Sait",
      "Mohammad Abusheikh",
      "Hasan Abusheikh"
    ],
    "abstract": "Automatic speech recognition (ASR) plays a vital role in enabling natural human-machine interaction across applications such as virtual assistants, industrial automation, customer support, and real-time transcription. However, developing accurate ASR systems for low-resource languages like Arabic remains a significant challenge due to limited labeled data and the linguistic complexity introduced by diverse dialects. In this work, we present a scalable training pipeline that combines weakly supervised learning with supervised fine-tuning to develop a robust Arabic ASR model. In the first stage, we pretrain the model on 15,000 hours of weakly labeled speech covering both Modern Standard Arabic (MSA) and various Dialectal Arabic (DA) variants. In the subsequent stage, we perform continual supervised fine-tuning using a mixture of filtered weakly labeled data and a small, high-quality annotated dataset. Our approach achieves state-of-the-art results, ranking first in the multi-dialectal Arabic ASR challenge. These findings highlight the effectiveness of weak supervision paired with fine-tuning in overcoming data scarcity and delivering high-quality ASR for low-resource, dialect-rich languages.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.08912v1",
    "published_date": "2025-08-12 13:02:22 UTC",
    "updated_date": "2025-08-12 13:02:22 UTC"
  },
  {
    "arxiv_id": "2508.08909v2",
    "title": "Compass-Thinker-7B Technical Report",
    "authors": [
      "Anxiang Zeng",
      "Haibo Zhang",
      "Kaixiang Mo",
      "Long Zhang",
      "Shuman Liu",
      "Yanhui Huang",
      "Yawen Liu",
      "Yuepeng Sheng",
      "Yuwei Huang"
    ],
    "abstract": "Recent R1-Zero-like research further demonstrates that reasoning extension has given large language models (LLMs) unprecedented reasoning capabilities, and Reinforcement Learning is the core technology to elicit its complex reasoning. However, conducting RL experiments directly on hyperscale models involves high computational costs and resource demands, posing significant risks. We propose the Compass-Thinker-7B model, which aims to explore the potential of Reinforcement Learning with less computational resources and costs, and provides insights for further research into RL recipes for larger models. Compass-Thinker-7B is trained from an open source model through a specially designed Reinforcement Learning Pipeline. We curate a dataset of 30k verifiable mathematics problems for the Reinforcement Learning Pipeline. By configuring data and training settings with different difficulty distributions for different stages, the potential of the model is gradually released and the training efficiency is improved. Extensive evaluations show that Compass-Thinker-7B possesses exceptional reasoning potential, and achieves superior performance on mathematics compared to the same-sized RL model. Especially in the challenging AIME2024 evaluation, Compass-Thinker-7B achieves 40% accuracy.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.08909v2",
    "published_date": "2025-08-12 12:58:12 UTC",
    "updated_date": "2025-08-14 07:12:38 UTC"
  },
  {
    "arxiv_id": "2508.14908v1",
    "title": "A Chinese Heart Failure Status Speech Database with Universal and Personalised Classification",
    "authors": [
      "Yue Pan",
      "Liwei Liu",
      "Changxin Li",
      "Xinyao Wang",
      "Yili Xia",
      "Hanyue Zhang",
      "Ming Chu"
    ],
    "abstract": "Speech is a cost-effective and non-intrusive data source for identifying acute and chronic heart failure (HF). However, there is a lack of research on whether Chinese syllables contain HF-related information, as observed in other well-studied languages. This study presents the first Chinese speech database of HF patients, featuring paired recordings taken before and after hospitalisation. The findings confirm the effectiveness of the Chinese language in HF detection using both standard 'patient-wise' and personalised 'pair-wise' classification approaches, with the latter serving as an ideal speaker-decoupled baseline for future research. Statistical tests and classification results highlight individual differences as key contributors to inaccuracy. Additionally, an adaptive frequency filter (AFF) is proposed for frequency importance analysis. The data and demonstrations are published at https://github.com/panyue1998/Voice_HF.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.14908v1",
    "published_date": "2025-08-12 12:52:16 UTC",
    "updated_date": "2025-08-12 12:52:16 UTC"
  },
  {
    "arxiv_id": "2508.08895v2",
    "title": "ASPD: Unlocking Adaptive Serial-Parallel Decoding by Exploring Intrinsic Parallelism in LLMs",
    "authors": [
      "Keyu Chen",
      "Zhifeng Shen",
      "Daohai Yu",
      "Haoqian Wu",
      "Wei Wen",
      "Jianfeng He",
      "Ruizhi Qiao",
      "Xing Sun"
    ],
    "abstract": "The increasing scale and complexity of large language models (LLMs) pose significant inference latency challenges, primarily due to their autoregressive decoding paradigm characterized by the sequential nature of next-token prediction. By re-examining the outputs of autoregressive models, we observed that some segments exhibit parallelizable structures, which we term intrinsic parallelism. Decoding each parallelizable branch simultaneously (i.e. parallel decoding) can significantly improve the overall inference speed of LLMs. In this paper, we propose an Adaptive Serial-Parallel Decoding (ASPD), which addresses two core challenges: automated construction of parallelizable data and efficient parallel decoding mechanism. More specifically, we introduce a non-invasive pipeline that automatically extracts and validates parallelizable structures from the responses of autoregressive models. To empower efficient adaptive serial-parallel decoding, we implement a Hybrid Decoding Engine which enables seamless transitions between serial and parallel decoding modes while maintaining a reusable KV cache, maximizing computational efficiency. Extensive evaluations across General Tasks, Retrieval-Augmented Generation, Mathematical Reasoning, demonstrate that ASPD achieves unprecedented performance in both effectiveness and efficiency. Notably, on Vicuna Bench, our method achieves up to 3.19x speedup (1.85x on average) while maintaining response quality within 1% difference compared to autoregressive models, realizing significant acceleration without compromising generation quality. Our framework sets a groundbreaking benchmark for efficient LLM parallel inference, paving the way for its deployment in latency-sensitive applications such as AI-powered customer service bots and answer retrieval engines.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "20 pages, 9 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.08895v2",
    "published_date": "2025-08-12 12:35:55 UTC",
    "updated_date": "2025-08-14 09:04:56 UTC"
  },
  {
    "arxiv_id": "2508.08883v1",
    "title": "Position: Causal Machine Learning Requires Rigorous Synthetic Experiments for Broader Adoption",
    "authors": [
      "Audrey Poinsot",
      "Panayiotis Panayiotou",
      "Alessandro Leite",
      "Nicolas Chesneau",
      "Özgür Şimşek",
      "Marc Schoenauer"
    ],
    "abstract": "Causal machine learning has the potential to revolutionize decision-making by combining the predictive power of machine learning algorithms with the theory of causal inference. However, these methods remain underutilized by the broader machine learning community, in part because current empirical evaluations do not permit assessment of their reliability and robustness, undermining their practical utility. Specifically, one of the principal criticisms made by the community is the extensive use of synthetic experiments. We argue, on the contrary, that synthetic experiments are essential and necessary to precisely assess and understand the capabilities of causal machine learning methods. To substantiate our position, we critically review the current evaluation practices, spotlight their shortcomings, and propose a set of principles for conducting rigorous empirical analyses with synthetic data. Adopting the proposed principles will enable comprehensive evaluations that build trust in causal machine learning methods, driving their broader adoption and impactful real-world use.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ME",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at ICML 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.08883v1",
    "published_date": "2025-08-12 12:13:13 UTC",
    "updated_date": "2025-08-12 12:13:13 UTC"
  },
  {
    "arxiv_id": "2508.08882v4",
    "title": "Reducing Cognitive Overhead in Tool Use via Multi-Small-Agent Reinforcement Learning",
    "authors": [
      "Dayu Wang",
      "Jiaye Yang",
      "Weikang Li",
      "Jiahui Liang",
      "Yang Li"
    ],
    "abstract": "Recent advances in multi-agent systems highlight the potential of specialized small agents that collaborate via division of labor. Existing tool-integrated reasoning systems, however, often follow a single-agent paradigm in which one large model interleaves long-horizon reasoning with precise tool operations, leading to cognitive-load interference and unstable coordination. We present MSARL, a Multi-Small-Agent Reinforcement Learning framework that explicitly decouples reasoning from tool use. In MSARL, a Reasoning Agent decomposes problems and plans tool invocations, while multiple Tool Agents specialize in specific external tools, each trained via a combination of imitation learning and reinforcement learning with role-specific rewards. On mathematical problem solving with code execution, MSARL significantly improves reasoning stability and final-answer accuracy over single-agent baselines. Moreover, the architecture generalizes to diverse tool-use tasks, demonstrating that cognitive-role decoupling with small agents is a scalable blueprint for multi-agent AI design.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.08882v4",
    "published_date": "2025-08-12 12:10:53 UTC",
    "updated_date": "2025-10-11 08:24:16 UTC"
  },
  {
    "arxiv_id": "2508.08879v2",
    "title": "Entangled in Representations: Mechanistic Investigation of Cultural Biases in Large Language Models",
    "authors": [
      "Haeun Yu",
      "Seogyeong Jeong",
      "Siddhesh Pawar",
      "Jisu Shin",
      "Jiho Jin",
      "Junho Myung",
      "Alice Oh",
      "Isabelle Augenstein"
    ],
    "abstract": "The growing deployment of large language models (LLMs) across diverse cultural contexts necessitates a deeper understanding of LLMs' representations of different cultures. Prior work has focused on evaluating the cultural awareness of LLMs by only examining the text they generate. This approach overlooks the internal sources of cultural misrepresentation within the models themselves. To bridge this gap, we propose Culturescope, the first mechanistic interpretability-based method that probes the internal representations of different cultural knowledge in LLMs. We also introduce a cultural flattening score as a measure of the intrinsic cultural biases of the decoded knowledge from Culturescope. Additionally, we study how LLMs internalize cultural biases, which allows us to trace how cultural biases such as Western-dominance bias and cultural flattening emerge within LLMs. We find that low-resource cultures are less susceptible to cultural biases, likely due to the model's limited parametric knowledge. Our work provides a foundation for future research on mitigating cultural biases and enhancing LLMs' cultural understanding.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "16 pages, 7 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.08879v2",
    "published_date": "2025-08-12 12:05:32 UTC",
    "updated_date": "2026-01-16 14:21:35 UTC"
  },
  {
    "arxiv_id": "2508.08875v2",
    "title": "Oblivionis: A Lightweight Learning and Unlearning Framework for Federated Large Language Models",
    "authors": [
      "Fuyao Zhang",
      "Xinyu Yan",
      "Tiantong Wu",
      "Wenjie Li",
      "Tianxiang Chen",
      "Yang Cao",
      "Ran Yan",
      "Longtao Huang",
      "Wei Yang Bryan Lim",
      "Qiang Yang"
    ],
    "abstract": "Large Language Models (LLMs) increasingly leverage Federated Learning (FL) to utilize private, task-specific datasets for fine-tuning while preserving data privacy. However, while federated LLM frameworks effectively enable collaborative training without raw data sharing, they critically lack built-in mechanisms for regulatory compliance like GDPR's right to be forgotten. Integrating private data heightens concerns over data quality and long-term governance, yet existing distributed training frameworks offer no principled way to selectively remove specific client contributions post-training. Due to distributed data silos, stringent privacy constraints, and the intricacies of interdependent model aggregation, federated LLM unlearning is significantly more complex than centralized LLM unlearning. To address this gap, we introduce Oblivionis, a lightweight learning and unlearning framework that enables clients to selectively remove specific private data during federated LLM training, enhancing trustworthiness and regulatory compliance. By unifying FL and unlearning as a dual optimization objective, we incorporate 6 FL and 5 unlearning algorithms for comprehensive evaluation and comparative analysis, establishing a robust pipeline for federated LLM unlearning. Extensive experiments demonstrate that Oblivionis outperforms local training, achieving a robust balance between forgetting efficacy and model utility, with cross-algorithm comparisons providing clear directions for future LLM development.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.08875v2",
    "published_date": "2025-08-12 12:02:53 UTC",
    "updated_date": "2025-11-08 06:01:37 UTC"
  },
  {
    "arxiv_id": "2508.20103v1",
    "title": "Deep Reinforcement Learning for Optimal Asset Allocation Using DDPG with TiDE",
    "authors": [
      "Rongwei Liu",
      "Jin Zheng",
      "John Cartlidge"
    ],
    "abstract": "The optimal asset allocation between risky and risk-free assets is a persistent challenge due to the inherent volatility in financial markets. Conventional methods rely on strict distributional assumptions or non-additive reward ratios, which limit their robustness and applicability to investment goals. To overcome these constraints, this study formulates the optimal two-asset allocation problem as a sequential decision-making task within a Markov Decision Process (MDP). This framework enables the application of reinforcement learning (RL) mechanisms to develop dynamic policies based on simulated financial scenarios, regardless of prerequisites. We use the Kelly criterion to balance immediate reward signals against long-term investment objectives, and we take the novel step of integrating the Time-series Dense Encoder (TiDE) into the Deep Deterministic Policy Gradient (DDPG) RL framework for continuous decision-making. We compare DDPG-TiDE with a simple discrete-action Q-learning RL framework and a passive buy-and-hold investment strategy. Empirical results show that DDPG-TiDE outperforms Q-learning and generates higher risk adjusted returns than buy-and-hold. These findings suggest that tackling the optimal asset allocation problem by integrating TiDE within a DDPG reinforcement learning framework is a fruitful avenue for further exploration.",
    "categories": [
      "q-fin.PM",
      "cs.AI",
      "cs.LG",
      "q-fin.RM"
    ],
    "primary_category": "q-fin.PM",
    "comment": "10 pages, 3 figures, authors accepted manuscript, to appear in 24th International Conference on Modelling and Applied Simulation (MAS), Sep. 2025, Fes, Morocco",
    "pdf_url": "https://arxiv.org/pdf/2508.20103v1",
    "published_date": "2025-08-12 11:59:55 UTC",
    "updated_date": "2025-08-12 11:59:55 UTC"
  },
  {
    "arxiv_id": "2508.15791v1",
    "title": "InteChar: A Unified Oracle Bone Character List for Ancient Chinese Language Modeling",
    "authors": [
      "Xiaolei Diao",
      "Zhihan Zhou",
      "Lida Shi",
      "Ting Wang",
      "Ruihua Qi",
      "Hao Xu",
      "Daqian Shi"
    ],
    "abstract": "Constructing historical language models (LMs) plays a crucial role in aiding archaeological provenance studies and understanding ancient cultures. However, existing resources present major challenges for training effective LMs on historical texts. First, the scarcity of historical language samples renders unsupervised learning approaches based on large text corpora highly inefficient, hindering effective pre-training. Moreover, due to the considerable temporal gap and complex evolution of ancient scripts, the absence of comprehensive character encoding schemes limits the digitization and computational processing of ancient texts, particularly in early Chinese writing. To address these challenges, we introduce InteChar, a unified and extensible character list that integrates unencoded oracle bone characters with traditional and modern Chinese. InteChar enables consistent digitization and representation of historical texts, providing a foundation for robust modeling of ancient scripts. To evaluate the effectiveness of InteChar, we construct the Oracle Corpus Set (OracleCS), an ancient Chinese corpus that combines expert-annotated samples with LLM-assisted data augmentation, centered on Chinese oracle bone inscriptions. Extensive experiments show that models trained with InteChar on OracleCS achieve substantial improvements across various historical language understanding tasks, confirming the effectiveness of our approach and establishing a solid foundation for future research in ancient Chinese NLP.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.15791v1",
    "published_date": "2025-08-12 11:53:57 UTC",
    "updated_date": "2025-08-12 11:53:57 UTC"
  },
  {
    "arxiv_id": "2508.10050v1",
    "title": "Legal Zero-Days: A Novel Risk Vector for Advanced AI Systems",
    "authors": [
      "Greg Sadler",
      "Nathan Sherburn"
    ],
    "abstract": "We introduce the concept of \"Legal Zero-Days\" as a novel risk vector for advanced AI systems. Legal Zero-Days are previously undiscovered vulnerabilities in legal frameworks that, when exploited, can cause immediate and significant societal disruption without requiring litigation or other processes before impact. We present a risk model for identifying and evaluating these vulnerabilities, demonstrating their potential to bypass safeguards or impede government responses to AI incidents. Using the 2017 Australian dual citizenship crisis as a case study, we illustrate how seemingly minor legal oversights can lead to large-scale governance disruption. We develop a methodology for creating \"legal puzzles\" as evaluation instruments for assessing AI systems' capabilities to discover such vulnerabilities. Our findings suggest that while current AI models may not reliably find impactful Legal Zero-Days, future systems may develop this capability, presenting both risks and opportunities for improving legal robustness. This work contributes to the broader effort to identify and mitigate previously unrecognized risks from frontier AI systems.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "10 pages, 1 table, 1 figure. Introduces Legal Zero-Days as a novel AI risk vector and provides evaluation framework for measuring AI systems' ability to discover legal vulnerabilities",
    "pdf_url": "https://arxiv.org/pdf/2508.10050v1",
    "published_date": "2025-08-12 11:43:00 UTC",
    "updated_date": "2025-08-12 11:43:00 UTC"
  },
  {
    "arxiv_id": "2508.13178v1",
    "title": "The Interpretability Analysis of the Model Can Bring Improvements to the Text-to-SQL Task",
    "authors": [
      "Cong Zhang"
    ],
    "abstract": "To elevate the foundational capabilities and generalization prowess of the text-to-SQL model in real-world applications, we integrate model interpretability analysis with execution-guided strategy for semantic parsing of WHERE clauses in SQL queries. Furthermore, we augment this approach with filtering adjustments, logical correlation refinements, and model fusion, culminating in the design of the CESQL model that facilitates conditional enhancement. Our model excels on the WikiSQL dataset, which is emblematic of single-table database query tasks, markedly boosting the accuracy of prediction outcomes. When predicting conditional values in WHERE clauses, we have not only minimized our dependence on data within the condition columns of tables but also circumvented the impact of manually labeled training data. Our hope is that this endeavor to enhance accuracy in processing basic database queries will offer fresh perspectives for research into handling complex queries and scenarios featuring irregular data in real-world database environments.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.DB"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.13178v1",
    "published_date": "2025-08-12 11:24:16 UTC",
    "updated_date": "2025-08-12 11:24:16 UTC"
  },
  {
    "arxiv_id": "2508.08855v2",
    "title": "BiasGym: Fantastic LLM Biases and How to Find (and Remove) Them",
    "authors": [
      "Sekh Mainul Islam",
      "Nadav Borenstein",
      "Siddhesh Milind Pawar",
      "Haeun Yu",
      "Arnav Arora",
      "Isabelle Augenstein"
    ],
    "abstract": "Understanding biases and stereotypes encoded in the weights of Large Language Models (LLMs) is crucial for developing effective mitigation strategies. Biased behaviour is often subtle and non-trivial to isolate, even when deliberately elicited, making systematic analysis and debiasing particularly challenging. To address this, we introduce BiasGym, a simple, cost-effective, and generalizable framework for reliably injecting, analyzing, and mitigating conceptual associations within LLMs. BiasGym consists of two components: BiasInject, which injects specific biases into the model via token-based fine-tuning while keeping the model frozen, and BiasScope, which leverages these injected signals to identify and steer the components responsible for biased behavior. Our method enables consistent bias elicitation for mechanistic analysis, supports targeted debiasing without degrading performance on downstream tasks, and generalizes to biases unseen during token-based fine-tuning. We demonstrate the effectiveness of BiasGym in reducing real-world stereotypes (e.g., people from Italy being `reckless drivers') and in probing fictional associations (e.g., people from a fictional country having `blue skin'), showing its utility for both safety interventions and interpretability research.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Under review",
    "pdf_url": "https://arxiv.org/pdf/2508.08855v2",
    "published_date": "2025-08-12 11:23:44 UTC",
    "updated_date": "2025-08-14 17:57:53 UTC"
  },
  {
    "arxiv_id": "2508.14075v2",
    "title": "Explainable Graph Spectral Clustering For GloVe-like Text Embeddings",
    "authors": [
      "Mieczysław A. Kłopotek",
      "Sławomir T. Wierzchoń",
      "Bartłomiej Starosta",
      "Piotr Borkowski",
      "Dariusz Czerski",
      "Eryk Laskowski"
    ],
    "abstract": "In a previous paper, we proposed an introduction to the explainability of Graph Spectral Clustering results for textual documents, given that document similarity is computed as cosine similarity in term vector space.\n  In this paper, we generalize this idea by considering other embeddings of documents, in particular, based on the GloVe embedding idea.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "47 pages, 19 tables, 11 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.14075v2",
    "published_date": "2025-08-12 11:20:27 UTC",
    "updated_date": "2025-12-22 06:08:18 UTC"
  },
  {
    "arxiv_id": "2508.08846v3",
    "title": "Steering Towards Fairness: Mitigating Political Bias in LLMs",
    "authors": [
      "Afrozah Nadeem",
      "Mark Dras",
      "Usman Naseem"
    ],
    "abstract": "Recent advancements in large language models (LLMs) have enabled their widespread use across diverse real-world applications. However, concerns remain about their tendency to encode and reproduce ideological biases along political and economic dimensions. In this paper, we employ a framework for probing and mitigating such biases in decoder-based LLMs through analysis of internal model representations. Grounded in the Political Compass Test (PCT), this method uses contrastive pairs to extract and compare hidden layer activations from models like Mistral and DeepSeek. We introduce a comprehensive activation extraction pipeline capable of layer-wise analysis across multiple ideological axes, revealing meaningful disparities linked to political framing. Our results show that decoder LLMs systematically encode representational bias across layers, which can be leveraged for effective steering vector-based mitigation. This work provides new insights into how political bias is encoded in LLMs and offers a principled approach to debiasing beyond surface-level output interventions.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at CASE@RANLP2025",
    "pdf_url": "https://arxiv.org/pdf/2508.08846v3",
    "published_date": "2025-08-12 11:09:03 UTC",
    "updated_date": "2025-09-20 07:24:55 UTC"
  },
  {
    "arxiv_id": "2508.08837v2",
    "title": "The Roots of International Perceptions: Simulating US Attitude Changes Towards China with LLM Agents",
    "authors": [
      "Nicholas Sukiennik",
      "Yichuan Xu",
      "Yuqing Kan",
      "Jinghua Piao",
      "Yuwei Yan",
      "Chen Gao",
      "Yong Li"
    ],
    "abstract": "The rise of LLMs poses new possibilities in modeling opinion evolution, a long-standing task in simulation, by leveraging advanced reasoning abilities to recreate complex, large-scale human cognitive trends. While most prior works focus on opinion evolution surrounding specific isolated events or the views within a country, ours is the first to model the large-scale attitude evolution of a population representing an entire country towards another -- US citizens' perspectives towards China. To tackle the challenges of this broad scenario, we propose a framework that integrates media data collection, user profile creation, and cognitive architecture for opinion updates to successfully reproduce the real trend of US attitudes towards China over a 20-year period from 2005 to today. We also leverage LLMs' capabilities to introduce debiased media exposure, extracting neutral events from typically subjective news contents, to uncover the roots of polarized opinion formation, as well as a devils advocate agent to help explain the rare reversal from negative to positive attitudes towards China, corresponding with changes in the way Americans obtain information about the country. The simulation results, beyond validating our framework architecture, also reveal the impact of biased framing and selection bias in shaping attitudes. Overall, our work contributes to a new paradigm for LLM-based modeling of cognitive behaviors in a large-scale, long-term, cross-border social context, providing insights into the formation of international biases and offering valuable implications for media consumers to better understand the factors shaping their perspectives, and ultimately contributing to the larger social need for bias reduction and cross-cultural tolerance.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI",
    "comment": "Submitted to AAAI Social Impact 2026",
    "pdf_url": "https://arxiv.org/pdf/2508.08837v2",
    "published_date": "2025-08-12 10:54:08 UTC",
    "updated_date": "2025-08-15 10:48:46 UTC"
  },
  {
    "arxiv_id": "2508.08836v1",
    "title": "EditMF: Drawing an Invisible Fingerprint for Your Large Language Models",
    "authors": [
      "Jiaxuan Wu",
      "Yinghan Zhou",
      "Wanli Peng",
      "Yiming Xue",
      "Juan Wen",
      "Ping Zhong"
    ],
    "abstract": "Training large language models (LLMs) is resource-intensive and expensive, making protecting intellectual property (IP) for LLMs crucial. Recently, embedding fingerprints into LLMs has emerged as a prevalent method for establishing model ownership. However, existing back-door-based methods suffer from limited stealth and efficiency. To simultaneously address these issues, we propose EditMF, a training-free fingerprinting paradigm that achieves highly imperceptible fingerprint embedding with minimal computational overhead. Ownership bits are mapped to compact, semantically coherent triples drawn from an encrypted artificial knowledge base (e.g., virtual author-novel-protagonist facts). Causal tracing localizes the minimal set of layers influencing each triple, and a zero-space update injects the fingerprint without perturbing unrelated knowledge. Verification requires only a single black-box query and succeeds when the model returns the exact pre-embedded protagonist. Empirical results on LLaMA and Qwen families show that EditMF combines high imperceptibility with negligible model's performance loss, while delivering robustness far beyond LoRA-based fingerprinting and approaching that of SFT embeddings. Extensive experiments demonstrate that EditMF is an effective and low-overhead solution for secure LLM ownership verification.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "8 pages, 2 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.08836v1",
    "published_date": "2025-08-12 10:52:48 UTC",
    "updated_date": "2025-08-12 10:52:48 UTC"
  },
  {
    "arxiv_id": "2508.08833v3",
    "title": "An Investigation of Robustness of LLMs in Mathematical Reasoning: Benchmarking with Mathematically-Equivalent Transformation of Advanced Mathematical Problems",
    "authors": [
      "Yuren Hao",
      "Xiang Wan",
      "ChengXiang Zhai"
    ],
    "abstract": "In this paper, we introduce a systematic framework beyond conventional method to assess LLMs' mathematical-reasoning robustness by stress-testing them on advanced math problems that are mathematically equivalent but with linguistic and parametric variation. These transformations allow us to measure the sensitivity of LLMs to non-mathematical perturbations, thereby enabling a more accurate evaluation of their mathematical reasoning capabilities. Using this new evaluation methodology, we created PutnamGAP, a new benchmark dataset with multiple mathematically-equivalent variations of competition-level math problems. With the new dataset, we evaluate multiple families of representative LLMs and examine their robustness. Across 18 commercial and open-source models we observe sharp performance degradation on the variants. OpenAI's flagship reasoning model, O3, scores 51.5% on the originals but drops by 4.7 percentage points on surface-renaming variants, and by 12.9 percentage points on parametric variants, while smaller models fare far worse. Overall, the results show that the proposed new evaluation methodology is effective for deepening our understanding of the robustness of LLMs and generating new insights for further improving their mathematical reasoning capabilities.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "34 pages, 9 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.08833v3",
    "published_date": "2025-08-12 10:40:33 UTC",
    "updated_date": "2025-12-04 08:10:06 UTC"
  },
  {
    "arxiv_id": "2508.08830v1",
    "title": "Silicon Minds versus Human Hearts: The Wisdom of Crowds Beats the Wisdom of AI in Emotion Recognition",
    "authors": [
      "Mustafa Akben",
      "Vinayaka Gude",
      "Haya Ajjan"
    ],
    "abstract": "The ability to discern subtle emotional cues is fundamental to human social intelligence. As artificial intelligence (AI) becomes increasingly common, AI's ability to recognize and respond to human emotions is crucial for effective human-AI interactions. In particular, whether such systems can match or surpass human experts remains to be seen. However, the emotional intelligence of AI, particularly multimodal large language models (MLLMs), remains largely unexplored. This study evaluates the emotion recognition abilities of MLLMs using the Reading the Mind in the Eyes Test (RMET) and its multiracial counterpart (MRMET), and compares their performance against human participants. Results show that, on average, MLLMs outperform humans in accurately identifying emotions across both tests. This trend persists even when comparing performance across low, medium, and expert-level performing groups. Yet when we aggregate independent human decisions to simulate collective intelligence, human groups significantly surpass the performance of aggregated MLLM predictions, highlighting the wisdom of the crowd. Moreover, a collaborative approach (augmented intelligence) that combines human and MLLM predictions achieves greater accuracy than either humans or MLLMs alone. These results suggest that while MLLMs exhibit strong emotion recognition at the individual level, the collective intelligence of humans and the synergistic potential of human-AI collaboration offer the most promising path toward effective emotional AI. We discuss the implications of these findings for the development of emotionally intelligent AI systems and future research directions.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.08830v1",
    "published_date": "2025-08-12 10:37:37 UTC",
    "updated_date": "2025-08-12 10:37:37 UTC"
  },
  {
    "arxiv_id": "2508.08826v3",
    "title": "Geometry-Aware Global Feature Aggregation for Real-Time Indirect Illumination",
    "authors": [
      "Meng Gai",
      "Guoping Wang",
      "Sheng Li"
    ],
    "abstract": "Real-time rendering with global illumination is crucial to afford the user realistic experience in virtual environments. We present a learning-based estimator to predict diffuse indirect illumination in screen space, which then is combined with direct illumination to synthesize globally-illuminated high dynamic range (HDR) results. Our approach tackles the challenges of capturing long-range/long-distance indirect illumination when employing neural networks and is generalized to handle complex lighting and scenarios.\n  From the neural network thinking of the solver to the rendering equation, we present a novel network architecture to predict indirect illumination. Our network is equipped with a modified attention mechanism that aggregates global information guided by spacial geometry features, as well as a monochromatic design that encodes each color channel individually.\n  We conducted extensive evaluations, and the experimental results demonstrate our superiority over previous learning-based techniques. Our approach excels at handling complex lighting such as varying-colored lighting and environment lighting. It can successfully capture distant indirect illumination and simulates the interreflections between textured surfaces well (i.e., color bleeding effects); it can also effectively handle new scenes that are not present in the training dataset.",
    "categories": [
      "cs.GR",
      "cs.AI"
    ],
    "primary_category": "cs.GR",
    "comment": "10 pages",
    "pdf_url": "https://arxiv.org/pdf/2508.08826v3",
    "published_date": "2025-08-12 10:36:03 UTC",
    "updated_date": "2025-11-05 15:51:33 UTC"
  },
  {
    "arxiv_id": "2508.08825v1",
    "title": "Wavelet Mixture of Experts for Time Series Forecasting",
    "authors": [
      "Zheng Zhou",
      "Yu-Jie Xiong",
      "Jia-Chen Zhang",
      "Chun-Ming Xia",
      "Xi-Jiong Xie"
    ],
    "abstract": "The field of time series forecasting is rapidly advancing, with recent large-scale Transformers and lightweight Multilayer Perceptron (MLP) models showing strong predictive performance. However, conventional Transformer models are often hindered by their large number of parameters and their limited ability to capture non-stationary features in data through smoothing. Similarly, MLP models struggle to manage multi-channel dependencies effectively. To address these limitations, we propose a novel, lightweight time series prediction model, WaveTS-B. This model combines wavelet transforms with MLP to capture both periodic and non-stationary characteristics of data in the wavelet domain. Building on this foundation, we propose a channel clustering strategy that incorporates a Mixture of Experts (MoE) framework, utilizing a gating mechanism and expert network to handle multi-channel dependencies efficiently. We propose WaveTS-M, an advanced model tailored for multi-channel time series prediction. Empirical evaluation across eight real-world time series datasets demonstrates that our WaveTS series models achieve state-of-the-art (SOTA) performance with significantly fewer parameters. Notably, WaveTS-M shows substantial improvements on multi-channel datasets, highlighting its effectiveness.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.08825v1",
    "published_date": "2025-08-12 10:32:51 UTC",
    "updated_date": "2025-08-12 10:32:51 UTC"
  },
  {
    "arxiv_id": "2508.08822v1",
    "title": "OISMA: On-the-fly In-memory Stochastic Multiplication Architecture for Matrix-Multiplication Workloads",
    "authors": [
      "Shady Agwa",
      "Yihan Pan",
      "Georgios Papandroulidakis",
      "Themis Prodromakis"
    ],
    "abstract": "Artificial Intelligence models are currently driven by a significant up-scaling of their complexity, with massive matrix multiplication workloads representing the major computational bottleneck. In-memory computing architectures are proposed to avoid the Von Neumann bottleneck. However, both digital/binary-based and analogue in-memory computing architectures suffer from various limitations, which significantly degrade the performance and energy efficiency gains. This work proposes OISMA, a novel in-memory computing architecture that utilizes the computational simplicity of a quasi-stochastic computing domain (Bent-Pyramid system), while keeping the same efficiency, scalability, and productivity of digital memories. OISMA converts normal memory read operations into in-situ stochastic multiplication operations with a negligible cost. An accumulation periphery then accumulates the output multiplication bitstreams, achieving the matrix multiplication functionality. Extensive matrix multiplication benchmarking was conducted to analyze the accuracy of the Bent-Pyramid system, using matrix dimensions ranging from 4x4 to 512x512. The accuracy results show a significant decrease in the average relative Frobenius error, from 9.42% (for 4x4) to 1.81% (for 512x512), compared to 64-bit double precision floating-point format. A 1T1R OISMA array of 4 KB capacity was implemented using a commercial 180nm technology node and in-house RRAM technology. At 50 MHz, OISMA achieves 0.891 TOPS/W and 3.98 GOPS/mm2 for energy and area efficiency, respectively, occupying an effective computing area of 0.804241 mm2. Scaling OISMA from 180nm to 22nm technology shows a significant improvement of two orders of magnitude in energy efficiency and one order of magnitude in area efficiency, compared to dense matrix multiplication in-memory computing architectures.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.ET",
      "cs.PF"
    ],
    "primary_category": "cs.AR",
    "comment": "12 pages, 13 figures. This work has been submitted to the IEEE for possible publication",
    "pdf_url": "https://arxiv.org/pdf/2508.08822v1",
    "published_date": "2025-08-12 10:24:33 UTC",
    "updated_date": "2025-08-12 10:24:33 UTC"
  },
  {
    "arxiv_id": "2508.08816v1",
    "title": "Efficient Agent: Optimizing Planning Capability for Multimodal Retrieval Augmented Generation",
    "authors": [
      "Yuechen Wang",
      "Yuming Qiao",
      "Dan Meng",
      "Jun Yang",
      "Haonan Lu",
      "Zhenyu Yang",
      "Xudong Zhang"
    ],
    "abstract": "Multimodal Retrieval-Augmented Generation (mRAG) has emerged as a promising solution to address the temporal limitations of Multimodal Large Language Models (MLLMs) in real-world scenarios like news analysis and trending topics. However, existing approaches often suffer from rigid retrieval strategies and under-utilization of visual information. To bridge this gap, we propose E-Agent, an agent framework featuring two key innovations: a mRAG planner trained to dynamically orchestrate multimodal tools based on contextual reasoning, and a task executor employing tool-aware execution sequencing to implement optimized mRAG workflows. E-Agent adopts a one-time mRAG planning strategy that enables efficient information retrieval while minimizing redundant tool invocations. To rigorously assess the planning capabilities of mRAG systems, we introduce the Real-World mRAG Planning (RemPlan) benchmark. This novel benchmark contains both retrieval-dependent and retrieval-independent question types, systematically annotated with essential retrieval tools required for each instance. The benchmark's explicit mRAG planning annotations and diverse question design enhance its practical relevance by simulating real-world scenarios requiring dynamic mRAG decisions. Experiments across RemPlan and three established benchmarks demonstrate E-Agent's superiority: 13% accuracy gain over state-of-the-art mRAG methods while reducing redundant searches by 37%.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.08816v1",
    "published_date": "2025-08-12 10:17:12 UTC",
    "updated_date": "2025-08-12 10:17:12 UTC"
  },
  {
    "arxiv_id": "2508.08815v1",
    "title": "GRainsaCK: a Comprehensive Software Library for Benchmarking Explanations of Link Prediction Tasks on Knowledge Graphs",
    "authors": [
      "Roberto Barile",
      "Claudia d'Amato",
      "Nicola Fanizzi"
    ],
    "abstract": "Since Knowledge Graphs are often incomplete, link prediction methods are adopted for predicting missing facts. Scalable embedding based solutions are mostly adopted for this purpose, however, they lack comprehensibility, which may be crucial in several domains. Explanation methods tackle this issue by identifying supporting knowledge explaining the predicted facts. Regretfully, evaluating/comparing quantitatively the resulting explanations is challenging as there is no standard evaluation protocol and overall benchmarking resource. We fill this important gap by proposing GRainsaCK, a reusable software resource that fully streamlines all the tasks involved in benchmarking explanations, i.e., from model training to evaluation of explanations along the same evaluation protocol. Moreover, GRainsaCK furthers modularity/extensibility by implementing the main components as functions that can be easily replaced. Finally, fostering its reuse, we provide extensive documentation including a tutorial.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.08815v1",
    "published_date": "2025-08-12 10:15:58 UTC",
    "updated_date": "2025-08-12 10:15:58 UTC"
  },
  {
    "arxiv_id": "2508.08814v2",
    "title": "TempOpt -- Unsupervised Alarm Relation Learning for Telecommunication Networks",
    "authors": [
      "Sathiyanaryanan Sampath",
      "Pratyush Uppuluri",
      "Thirumaran Ekambaram"
    ],
    "abstract": "In a telecommunications network, fault alarms generated by network nodes are monitored in a Network Operations Centre (NOC) to ensure network availability and continuous network operations. The monitoring process comprises of tasks such as active alarms analysis, root alarm identification, and resolution of the underlying problem. Each network node potentially can generate alarms of different types, while nodes can be from multiple vendors, a network can have hundreds of nodes thus resulting in an enormous volume of alarms at any time. Since network nodes are inter-connected, a single fault in the network would trigger multiple sequences of alarms across a variety of nodes and from a monitoring point of view, it is a challenging task for a NOC engineer to be aware of relations between the various alarms, when trying to identify, for example, a root alarm on which an action needs to be taken. To effectively identify root alarms, it is essential to learn relation among the alarms for accurate and faster resolution. In this work we propose a novel unsupervised alarm relation learning technique Temporal Optimization (TempOpt) that is practical and overcomes the limitations of an existing class of alarm relational learning method-temporal dependency methods. Experiments have been carried on real-world network datasets, that demonstrate the improved quality of alarm relations learned by TempOpt as compared to temporal dependency method.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "6 pages, 9 figures. IEEE 21st India Council International Conference (INDICON), 2024",
    "pdf_url": "https://arxiv.org/pdf/2508.08814v2",
    "published_date": "2025-08-12 10:15:48 UTC",
    "updated_date": "2025-08-13 07:28:25 UTC"
  },
  {
    "arxiv_id": "2508.08810v1",
    "title": "Not in My Backyard! Temporal Voting Over Public Chores",
    "authors": [
      "Edith Elkind",
      "Tzeh Yuan Neoh",
      "Nicholas Teh"
    ],
    "abstract": "We study a temporal voting model where voters have dynamic preferences over a set of public chores -- projects that benefit society, but impose individual costs on those affected by their implementation. We investigate the computational complexity of optimizing utilitarian and egalitarian welfare. Our results show that while optimizing the former is computationally straightforward, minimizing the latter is computationally intractable, even in very restricted cases. Nevertheless, we identify several settings where this problem can be solved efficiently, either exactly or by an approximation algorithm. We also examine the effects of enforcing temporal fairness and its impact on social welfare, and analyze the competitive ratio of online algorithms. We then explore the strategic behavior of agents, providing insights into potential malfeasance in such decision-making environments. Finally, we discuss a range of fairness measures and their suitability for our setting.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.MA",
      "econ.TH"
    ],
    "primary_category": "cs.GT",
    "comment": "Appears in the 34th International Joint Conference on Artificial Intelligence (IJCAI), 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.08810v1",
    "published_date": "2025-08-12 10:06:56 UTC",
    "updated_date": "2025-08-12 10:06:56 UTC"
  },
  {
    "arxiv_id": "2508.08805v1",
    "title": "Opening Musical Creativity? Embedded Ideologies in Generative-AI Music Systems",
    "authors": [
      "Liam Pram",
      "Fabio Morreale"
    ],
    "abstract": "AI systems for music generation are increasingly common and easy to use, granting people without any musical background the ability to create music. Because of this, generative-AI has been marketed and celebrated as a means of democratizing music making. However, inclusivity often functions as marketable rhetoric rather than a genuine guiding principle in these industry settings. In this paper, we look at four generative-AI music making systems available to the public as of mid-2025 (AIVA, Stable Audio, Suno, and Udio) and track how they are rhetoricized by their developers, and received by users. Our aim is to investigate ideologies that are driving the early-stage development and adoption of generative-AI in music making, with a particular focus on democratization. A combination of autoethnography and digital ethnography is used to examine patterns and incongruities in rhetoric when positioned against product functionality. The results are then collated to develop a nuanced, contextual discussion. The shared ideology we map between producers and consumers is individualist, globalist, techno-liberal, and ethically evasive. It is a 'total ideology' which obfuscates individual responsibility, and through which the nature of music and musical practice is transfigured to suit generative outcomes.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.SD",
    "comment": "Extended version of the presentation at The First International Conference in AI Music Studies 2024",
    "pdf_url": "https://arxiv.org/pdf/2508.08805v1",
    "published_date": "2025-08-12 09:59:07 UTC",
    "updated_date": "2025-08-12 09:59:07 UTC"
  },
  {
    "arxiv_id": "2508.08804v1",
    "title": "TechOps: Technical Documentation Templates for the AI Act",
    "authors": [
      "Laura Lucaj",
      "Alex Loosley",
      "Hakan Jonsson",
      "Urs Gasser",
      "Patrick van der Smagt"
    ],
    "abstract": "Operationalizing the EU AI Act requires clear technical documentation to ensure AI systems are transparent, traceable, and accountable. Existing documentation templates for AI systems do not fully cover the entire AI lifecycle while meeting the technical documentation requirements of the AI Act.\n  This paper addresses those shortcomings by introducing open-source templates and examples for documenting data, models, and applications to provide sufficient documentation for certifying compliance with the AI Act. These templates track the system status over the entire AI lifecycle, ensuring traceability, reproducibility, and compliance with the AI Act. They also promote discoverability and collaboration, reduce risks, and align with best practices in AI documentation and governance.\n  The templates are evaluated and refined based on user feedback to enable insights into their usability and implementability. We then validate the approach on real-world scenarios, providing examples that further guide their implementation: the data template is followed to document a skin tones dataset created to support fairness evaluations of downstream computer vision models and human-centric applications; the model template is followed to document a neural network for segmenting human silhouettes in photos. The application template is tested on a system deployed for construction site safety using real-time video analytics and sensor data. Our results show that TechOps can serve as a practical tool to enable oversight for regulatory compliance and responsible AI development.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.08804v1",
    "published_date": "2025-08-12 09:58:33 UTC",
    "updated_date": "2025-08-12 09:58:33 UTC"
  },
  {
    "arxiv_id": "2508.11691v1",
    "title": "Towards Generalizable Learning Models for EEG-Based Identification of Pain Perception",
    "authors": [
      "Mathis Rezzouk",
      "Fabrice Gagnon",
      "Alyson Champagne",
      "Mathieu Roy",
      "Philippe Albouy",
      "Michel-Pierre Coll",
      "Cem Subakan"
    ],
    "abstract": "EEG-based analysis of pain perception, enhanced by machine learning, reveals how the brain encodes pain by identifying neural patterns evoked by noxious stimulation. However, a major challenge that remains is the generalization of machine learning models across individuals, given the high cross-participant variability inherent to EEG signals and the limited focus on direct pain perception identification in current research. In this study, we systematically evaluate the performance of cross-participant generalization of a wide range of models, including traditional classifiers and deep neural classifiers for identifying the sensory modality of thermal pain and aversive auditory stimulation from EEG recordings. Using a novel dataset of EEG recordings from 108 participants, we benchmark model performance under both within- and cross-participant evaluation settings. Our findings show that traditional models suffered the largest drop from within- to cross-participant performance, while deep learning models proved more resilient, underscoring their potential for subject-invariant EEG decoding. Even though performance variability remained high, the strong results of the graph-based model highlight its potential to capture subject-invariant structure in EEG signals. On the other hand, we also share the preprocessed dataset used in this study, providing a standardized benchmark for evaluating future algorithms under the same generalization constraints.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "6 pages, 2 figures, 2 tables, MLSP IEEE conference",
    "pdf_url": "https://arxiv.org/pdf/2508.11691v1",
    "published_date": "2025-08-12 09:57:32 UTC",
    "updated_date": "2025-08-12 09:57:32 UTC"
  },
  {
    "arxiv_id": "2508.08795v1",
    "title": "A Dual-Axis Taxonomy of Knowledge Editing for LLMs: From Mechanisms to Functions",
    "authors": [
      "Amir Mohammad Salehoof",
      "Ali Ramezani",
      "Yadollah Yaghoobzadeh",
      "Majid Nili Ahmadabadi"
    ],
    "abstract": "Large language models (LLMs) acquire vast knowledge from large text corpora, but this information can become outdated or inaccurate. Since retraining is computationally expensive, knowledge editing offers an efficient alternative -- modifying internal knowledge without full retraining. These methods aim to update facts precisely while preserving the model's overall capabilities. While existing surveys focus on the mechanism of editing (e.g., parameter changes vs. external memory), they often overlook the function of the knowledge being edited. This survey introduces a novel, complementary function-based taxonomy to provide a more holistic view. We examine how different mechanisms apply to various knowledge types -- factual, temporal, conceptual, commonsense, and social -- highlighting how editing effectiveness depends on the nature of the target knowledge. By organizing our review along these two axes, we map the current landscape, outline the strengths and limitations of existing methods, define the problem formally, survey evaluation tasks and datasets, and conclude with open challenges and future directions.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "13 pages, 1 figure",
    "pdf_url": "https://arxiv.org/pdf/2508.08795v1",
    "published_date": "2025-08-12 09:51:39 UTC",
    "updated_date": "2025-08-12 09:51:39 UTC"
  },
  {
    "arxiv_id": "2508.08791v2",
    "title": "Feedback-Driven Tool-Use Improvements in Large Language Models via Automated Build Environments",
    "authors": [
      "Junjie Ye",
      "Changhao Jiang",
      "Zhengyin Du",
      "Yufei Xu",
      "Xuesong Yao",
      "Zhiheng Xi",
      "Xiaoran Fan",
      "Qi Zhang",
      "Tao Gui",
      "Xuanjing Huang",
      "Jiecao Chen"
    ],
    "abstract": "Effective tool use is essential for large language models (LLMs) to interact meaningfully with their environment. However, progress is limited by the lack of efficient reinforcement learning (RL) frameworks specifically designed for tool use, due to challenges in constructing stable training environments and designing verifiable reward mechanisms. To address this, we propose an automated environment construction pipeline, incorporating scenario decomposition, document generation, function integration, complexity scaling, and localized deployment. This enables the creation of high-quality training environments that provide detailed and measurable feedback without relying on external tools. Additionally, we introduce a verifiable reward mechanism that evaluates both the precision of tool use and the completeness of task execution. When combined with trajectory data collected from the constructed environments, this mechanism integrates seamlessly with standard RL algorithms to facilitate feedback-driven model training. Experiments on LLMs of varying scales demonstrate that our approach significantly enhances the models' tool-use performance without degrading their general capabilities, regardless of inference modes or training algorithms. Our analysis suggests that these gains result from improved context understanding and reasoning, driven by updates to the lower-layer MLP parameters in models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.08791v2",
    "published_date": "2025-08-12 09:45:19 UTC",
    "updated_date": "2025-09-12 02:57:21 UTC"
  },
  {
    "arxiv_id": "2508.08790v1",
    "title": "ReQuestNet: A Foundational Learning model for Channel Estimation",
    "authors": [
      "Kumar Pratik",
      "Pouriya Sadeghi",
      "Gabriele Cesa",
      "Sanaz Barghi",
      "Joseph B. Soriaga",
      "Yuanning Yu",
      "Supratik Bhattacharjee",
      "Arash Behboodi"
    ],
    "abstract": "In this paper, we present a novel neural architecture for channel estimation (CE) in 5G and beyond, the Recurrent Equivariant UERS Estimation Network (ReQuestNet). It incorporates several practical considerations in wireless communication systems, such as ability to handle variable number of resource block (RB), dynamic number of transmit layers, physical resource block groups (PRGs) bundling size (BS), demodulation reference signal (DMRS) patterns with a single unified model, thereby, drastically simplifying the CE pipeline. Besides it addresses several limitations of the legacy linear MMSE solutions, for example, by being independent of other reference signals and particularly by jointly processing MIMO layers and differently precoded channels with unknown precoding at the receiver. ReQuestNet comprises of two sub-units, CoarseNet followed by RefinementNet. CoarseNet performs per PRG, per transmit-receive (Tx-Rx) stream channel estimation, while RefinementNet refines the CoarseNet channel estimate by incorporating correlations across differently precoded PRGs, and correlation across multiple input multiple output (MIMO) channel spatial dimensions (cross-MIMO). Simulation results demonstrate that ReQuestNet significantly outperforms genie minimum mean squared error (MMSE) CE across a wide range of channel conditions, delay-Doppler profiles, achieving up to 10dB gain at high SNRs. Notably, ReQuestNet generalizes effectively to unseen channel profiles, efficiently exploiting inter-PRG and cross-MIMO correlations under dynamic PRG BS and varying transmit layer allocations.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "eess.SP",
    "comment": "Accepted at IEEE Globecom 2025. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works",
    "pdf_url": "https://arxiv.org/pdf/2508.08790v1",
    "published_date": "2025-08-12 09:44:47 UTC",
    "updated_date": "2025-08-12 09:44:47 UTC"
  },
  {
    "arxiv_id": "2508.13177v1",
    "title": "A Hardware-oriented Approach for Efficient Active Inference Computation and Deployment",
    "authors": [
      "Nikola Pižurica",
      "Nikola Milović",
      "Igor Jovančević",
      "Conor Heins",
      "Miguel de Prado"
    ],
    "abstract": "Active Inference (AIF) offers a robust framework for decision-making, yet its computational and memory demands pose challenges for deployment, especially in resource-constrained environments. This work presents a methodology that facilitates AIF's deployment by integrating pymdp's flexibility and efficiency with a unified, sparse, computational graph tailored for hardware-efficient execution. Our approach reduces latency by over 2x and memory by up to 35%, advancing the deployment of efficient AIF agents for real-time and embedded applications.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.13177v1",
    "published_date": "2025-08-12 09:39:46 UTC",
    "updated_date": "2025-08-12 09:39:46 UTC"
  },
  {
    "arxiv_id": "2508.08777v1",
    "title": "Evaluating Podcast Recommendations with Profile-Aware LLM-as-a-Judge",
    "authors": [
      "Francesco Fabbri",
      "Gustavo Penha",
      "Edoardo D'Amico",
      "Alice Wang",
      "Marco De Nadai",
      "Jackie Doremus",
      "Paul Gigioli",
      "Andreas Damianou",
      "Oskar Stal",
      "Mounia Lalmas"
    ],
    "abstract": "Evaluating personalized recommendations remains a central challenge, especially in long-form audio domains like podcasts, where traditional offline metrics suffer from exposure bias and online methods such as A/B testing are costly and operationally constrained. In this paper, we propose a novel framework that leverages Large Language Models (LLMs) as offline judges to assess the quality of podcast recommendations in a scalable and interpretable manner. Our two-stage profile-aware approach first constructs natural-language user profiles distilled from 90 days of listening history. These profiles summarize both topical interests and behavioral patterns, serving as compact, interpretable representations of user preferences. Rather than prompting the LLM with raw data, we use these profiles to provide high-level, semantically rich context-enabling the LLM to reason more effectively about alignment between a user's interests and recommended episodes. This reduces input complexity and improves interpretability. The LLM is then prompted to deliver fine-grained pointwise and pairwise judgments based on the profile-episode match. In a controlled study with 47 participants, our profile-aware judge matched human judgments with high fidelity and outperformed or matched a variant using raw listening histories. The framework enables efficient, profile-aware evaluation for iterative testing and model selection in recommender systems.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted at RecSys '25",
    "pdf_url": "https://arxiv.org/pdf/2508.08777v1",
    "published_date": "2025-08-12 09:23:35 UTC",
    "updated_date": "2025-08-12 09:23:35 UTC"
  },
  {
    "arxiv_id": "2508.08774v1",
    "title": "Designing Memory-Augmented AR Agents for Spatiotemporal Reasoning in Personalized Task Assistance",
    "authors": [
      "Dongwook Choi",
      "Taeyoon Kwon",
      "Dongil Yang",
      "Hyojun Kim",
      "Jinyoung Yeo"
    ],
    "abstract": "Augmented Reality (AR) systems are increasingly integrating foundation models, such as Multimodal Large Language Models (MLLMs), to provide more context-aware and adaptive user experiences. This integration has led to the development of AR agents to support intelligent, goal-directed interactions in real-world environments. While current AR agents effectively support immediate tasks, they struggle with complex multi-step scenarios that require understanding and leveraging user's long-term experiences and preferences. This limitation stems from their inability to capture, retain, and reason over historical user interactions in spatiotemporal contexts. To address these challenges, we propose a conceptual framework for memory-augmented AR agents that can provide personalized task assistance by learning from and adapting to user-specific experiences over time. Our framework consists of four interconnected modules: (1) Perception Module for multimodal sensor processing, (2) Memory Module for persistent spatiotemporal experience storage, (3) Spatiotemporal Reasoning Module for synthesizing past and present contexts, and (4) Actuator Module for effective AR communication. We further present an implementation roadmap, a future evaluation strategy, a potential target application and use cases to demonstrate the practical applicability of our framework across diverse domains. We aim for this work to motivate future research toward developing more intelligent AR systems that can effectively bridge user's interaction history with adaptive, context-aware task assistance.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "7 pages, 2 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.08774v1",
    "published_date": "2025-08-12 09:20:20 UTC",
    "updated_date": "2025-08-12 09:20:20 UTC"
  },
  {
    "arxiv_id": "2508.08765v2",
    "title": "Bridging the Gap: A Framework for Real-World Video Deepfake Detection via Social Network Compression Emulation",
    "authors": [
      "Andrea Montibeller",
      "Dasara Shullani",
      "Daniele Baracchi",
      "Alessandro Piva",
      "Giulia Boato"
    ],
    "abstract": "The growing presence of AI-generated videos on social networks poses new challenges for deepfake detection, as detectors trained under controlled conditions often fail to generalize to real-world scenarios. A key factor behind this gap is the aggressive, proprietary compression applied by platforms like YouTube and Facebook, which launder low-level forensic cues. However, replicating these transformations at scale is difficult due to API limitations and data-sharing constraints. For these reasons, we propose a first framework that emulates the video sharing pipelines of social networks by estimating compression and resizing parameters from a small set of uploaded videos. These parameters enable a local emulator capable of reproducing platform-specific artifacts on large datasets without direct API access. Experiments on FaceForensics++ videos shared via social networks demonstrate that our emulated data closely matches the degradation patterns of real uploads. Furthermore, detectors fine-tuned on emulated videos achieve comparable performance to those trained on actual shared media. Our approach offers a scalable and practical solution for bridging the gap between lab-based training and real-world deployment of deepfake detectors, particularly in the underexplored domain of compressed video content.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.08765v2",
    "published_date": "2025-08-12 09:11:31 UTC",
    "updated_date": "2025-09-12 17:29:48 UTC"
  },
  {
    "arxiv_id": "2508.08761v1",
    "title": "DevNous: An LLM-Based Multi-Agent System for Grounding IT Project Management in Unstructured Conversation",
    "authors": [
      "Stavros Doropoulos",
      "Stavros Vologiannidis",
      "Ioannis Magnisalis"
    ],
    "abstract": "The manual translation of unstructured team dialogue into the structured artifacts required for Information Technology (IT) project governance is a critical bottleneck in modern information systems management. We introduce DevNous, a Large Language Model-based (LLM) multi-agent expert system, to automate this unstructured-to-structured translation process. DevNous integrates directly into team chat environments, identifying actionable intents from informal dialogue and managing stateful, multi-turn workflows for core administrative tasks like automated task formalization and progress summary synthesis. To quantitatively evaluate the system, we introduce a new benchmark of 160 realistic, interactive conversational turns. The dataset was manually annotated with a multi-label ground truth and is publicly available. On this benchmark, DevNous achieves an exact match turn accuracy of 81.3\\% and a multiset F1-Score of 0.845, providing strong evidence for its viability. The primary contributions of this work are twofold: (1) a validated architectural pattern for developing ambient administrative agents, and (2) the introduction of the first robust empirical baseline and public benchmark dataset for this challenging problem domain.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.08761v1",
    "published_date": "2025-08-12 09:08:29 UTC",
    "updated_date": "2025-08-12 09:08:29 UTC"
  },
  {
    "arxiv_id": "2508.08748v1",
    "title": "Visual Prompting for Robotic Manipulation with Annotation-Guided Pick-and-Place Using ACT",
    "authors": [
      "Muhammad A. Muttaqien",
      "Tomohiro Motoda",
      "Ryo Hanai",
      "Yukiyasu Domae"
    ],
    "abstract": "Robotic pick-and-place tasks in convenience stores pose challenges due to dense object arrangements, occlusions, and variations in object properties such as color, shape, size, and texture. These factors complicate trajectory planning and grasping. This paper introduces a perception-action pipeline leveraging annotation-guided visual prompting, where bounding box annotations identify both pickable objects and placement locations, providing structured spatial guidance. Instead of traditional step-by-step planning, we employ Action Chunking with Transformers (ACT) as an imitation learning algorithm, enabling the robotic arm to predict chunked action sequences from human demonstrations. This facilitates smooth, adaptive, and data-driven pick-and-place operations. We evaluate our system based on success rate and visual analysis of grasping behavior, demonstrating improved grasp accuracy and adaptability in retail environments.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.08748v1",
    "published_date": "2025-08-12 08:45:09 UTC",
    "updated_date": "2025-08-12 08:45:09 UTC"
  },
  {
    "arxiv_id": "2508.14074v1",
    "title": "GEPD:GAN-Enhanced Generalizable Model for EEG-Based Detection of Parkinson's Disease",
    "authors": [
      "Qian Zhang",
      "Ruilin Zhang",
      "Biaokai Zhu",
      "Xun Han",
      "Jun Xiao",
      "Yifan Liu",
      "Zhe Wang"
    ],
    "abstract": "Electroencephalography has been established as an effective method for detecting Parkinson's disease, typically diagnosed early.Current Parkinson's disease detection methods have shown significant success within individual datasets, however, the variability in detection methods across different EEG datasets and the small size of each dataset pose challenges for training a generalizable model for cross-dataset scenarios. To address these issues, this paper proposes a GAN-enhanced generalizable model, named GEPD, specifically for EEG-based cross-dataset classification of Parkinson's disease.First, we design a generative network that creates fusion EEG data by controlling the distribution similarity between generated data and real data.In addition, an EEG signal quality assessment model is designed to ensure the quality of generated data great.Second, we design a classification network that utilizes a combination of multiple convolutional neural networks to effectively capture the time-frequency characteristics of EEG signals, while maintaining a generalizable structure and ensuring easy convergence.This work is dedicated to utilizing intelligent methods to study pathological manifestations, aiming to facilitate the diagnosis and monitoring of neurological diseases.The evaluation results demonstrate that our model performs comparably to state-of-the-art models in cross-dataset settings, achieving an accuracy of 84.3% and an F1-score of 84.0%, showcasing the generalizability of the proposed model.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by International Conference on Intelligent Computing(ICIC 2025)",
    "pdf_url": "https://arxiv.org/pdf/2508.14074v1",
    "published_date": "2025-08-12 08:37:14 UTC",
    "updated_date": "2025-08-12 08:37:14 UTC"
  },
  {
    "arxiv_id": "2508.08742v2",
    "title": "SciRerankBench: Benchmarking Rerankers Towards Scientific Retrieval-Augmented Generated LLMs",
    "authors": [
      "Haotian Chen",
      "Qingqing Long",
      "Meng Xiao",
      "Xiao Luo",
      "Wei Ju",
      "Chengrui Wang",
      "Xuezhi Wang",
      "Yuanchun Zhou",
      "Hengshu Zhu"
    ],
    "abstract": "Scientific literature question answering is a pivotal step towards new scientific discoveries. Recently, \\textit{two-stage} retrieval-augmented generated large language models (RAG-LLMs) have shown impressive advancements in this domain. Such a two-stage framework, especially the second stage (reranker), is particularly essential in the scientific domain, where subtle differences in terminology may have a greatly negative impact on the final factual-oriented or knowledge-intensive answers. Despite this significant progress, the potential and limitations of these works remain unexplored. In this work, we present a Scientific Rerank-oriented RAG Benchmark (SciRerankBench), for evaluating rerankers within RAG-LLMs systems, spanning five scientific subjects. To rigorously assess the reranker performance in terms of noise resilience, relevance disambiguation, and factual consistency, we develop three types of question-context-answer (Q-C-A) pairs, i.e., Noisy Contexts (NC), Semantically Similar but Logically Irrelevant Contexts (SSLI), and Counterfactual Contexts (CC). Through systematic evaluation of 13 widely used rerankers on five families of LLMs, we provide detailed insights into their relative strengths and limitations. To the best of our knowledge, SciRerankBench is the first benchmark specifically developed to evaluate rerankers within RAG-LLMs, which provides valuable observations and guidance for their future development.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.08742v2",
    "published_date": "2025-08-12 08:36:23 UTC",
    "updated_date": "2025-09-24 07:37:00 UTC"
  },
  {
    "arxiv_id": "2508.09232v2",
    "title": "PETLP: A Privacy-by-Design Pipeline for Social Media Data in AI Research",
    "authors": [
      "Nick Oh",
      "Giorgos D. Vrakas",
      "Siân J. M. Brooke",
      "Sasha Morinière",
      "Toju Duke"
    ],
    "abstract": "Social media data presents AI researchers with overlapping obligations under the GDPR, copyright law, and platform terms -- yet existing frameworks fail to integrate these regulatory domains, leaving researchers without unified guidance. We introduce PETLP (Privacy-by-design Extract, Transform, Load, and Present), a compliance framework that embeds legal safeguards directly into extended ETL pipelines. Central to PETLP is treating Data Protection Impact Assessments as living documents that evolve from pre-registration through dissemination. Through systematic Reddit analysis, we demonstrate how extraction rights fundamentally differ between qualifying research organisations (who can invoke DSM Article 3 to override platform restrictions) and commercial entities (bound by terms of service), whilst GDPR obligations apply universally. We demonstrate why true anonymisation remains unachievable for social media data and expose the legal gap between permitted dataset creation and uncertain model distribution. By structuring compliance decisions into practical workflows and simplifying institutional data management plans, PETLP enables researchers to navigate regulatory complexity with confidence, bridging the gap between legal requirements and research practice.",
    "categories": [
      "cs.MM",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.MM",
    "comment": "Extended version of paper to appear in the 8th AAAI/ACM Conference on AI, Ethics, and Society (AIES 2025)",
    "pdf_url": "https://arxiv.org/pdf/2508.09232v2",
    "published_date": "2025-08-12 08:33:40 UTC",
    "updated_date": "2025-10-16 07:38:09 UTC"
  },
  {
    "arxiv_id": "2509.09681v2",
    "title": "DB3 Team's Solution For Meta KDD Cup' 25",
    "authors": [
      "Yikuan Xia",
      "Jiazun Chen",
      "Yirui Zhan",
      "Suifeng Zhao",
      "Weipeng Jiang",
      "Chaorui Zhang",
      "Wei Han",
      "Bo Bai",
      "Jun Gao"
    ],
    "abstract": "This paper presents the db3 team's winning solution for the Meta CRAG-MM Challenge 2025 at KDD Cup'25. Addressing the challenge's unique multi-modal, multi-turn question answering benchmark (CRAG-MM), we developed a comprehensive framework that integrates tailored retrieval pipelines for different tasks with a unified LLM-tuning approach for hallucination control. Our solution features (1) domain-specific retrieval pipelines handling image-indexed knowledge graphs, web sources, and multi-turn conversations; and (2) advanced refusal training using SFT, DPO, and RL. The system achieved 2nd place in Task 1, 2nd place in Task 2, and 1st place in Task 3, securing the grand prize for excellence in ego-centric queries through superior handling of first-person perspective challenges.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.09681v2",
    "published_date": "2025-08-12 08:27:53 UTC",
    "updated_date": "2026-01-12 05:54:12 UTC"
  },
  {
    "arxiv_id": "2508.14073v2",
    "title": "MCLPD:Multi-view Contrastive Learning for EEG-based PD Detection Across Datasets",
    "authors": [
      "Qian Zhang",
      "Ruilin Zhang",
      "Jun Xiao",
      "Yifan Liu",
      "Zhe Wang"
    ],
    "abstract": "Electroencephalography has been validated as an effective technique for detecting Parkinson's disease,particularly in its early stages.However,the high cost of EEG data annotation often results in limited dataset size and considerable discrepancies across datasets,including differences in acquisition protocols and subject demographics,significantly hinder the robustness and generalizability of models in cross-dataset detection scenarios.To address such challenges,this paper proposes a semi-supervised learning framework named MCLPD,which integrates multi-view contrastive pre-training with lightweight supervised fine-tuning to enhance cross-dataset PD detection performance.During pre-training,MCLPD uses self-supervised learning on the unlabeled UNM dataset.To build contrastive pairs,it applies dual augmentations in both time and frequency domains,which enrich the data and naturally fuse time-frequency information.In the fine-tuning phase,only a small proportion of labeled data from another two datasets (UI and UC)is used for supervised optimization.Experimental results show that MCLPD achieves F1 scores of 0.91 on UI and 0.81 on UC using only 1%of labeled data,which further improve to 0.97 and 0.87,respectively,when 5%of labeled data is used.Compared to existing methods,MCLPD substantially improves cross-dataset generalization while reducing the dependency on labeled data,demonstrating the effectiveness of the proposed framework.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Acccepted by European Conference on Artificial Intelligence(ECAI 2025)",
    "pdf_url": "https://arxiv.org/pdf/2508.14073v2",
    "published_date": "2025-08-12 08:19:27 UTC",
    "updated_date": "2025-08-21 07:34:07 UTC"
  },
  {
    "arxiv_id": "2508.09231v1",
    "title": "Beyond Technocratic XAI: The Who, What & How in Explanation Design",
    "authors": [
      "Ruchira Dhar",
      "Stephanie Brandl",
      "Ninell Oldenburg",
      "Anders Søgaard"
    ],
    "abstract": "The field of Explainable AI (XAI) offers a wide range of techniques for making complex models interpretable. Yet, in practice, generating meaningful explanations is a context-dependent task that requires intentional design choices to ensure accessibility and transparency. This paper reframes explanation as a situated design process -- an approach particularly relevant for practitioners involved in building and deploying explainable systems. Drawing on prior research and principles from design thinking, we propose a three-part framework for explanation design in XAI: asking Who needs the explanation, What they need explained, and How that explanation should be delivered. We also emphasize the need for ethical considerations, including risks of epistemic inequality, reinforcing social inequities, and obscuring accountability and governance. By treating explanation as a sociotechnical design process, this framework encourages a context-aware approach to XAI that supports effective communication and the development of ethically responsible explanations.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "Accepted to AI, Ethics & Society Conference (AIES) Proceedings 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.09231v1",
    "published_date": "2025-08-12 08:17:26 UTC",
    "updated_date": "2025-08-12 08:17:26 UTC"
  },
  {
    "arxiv_id": "2508.08726v1",
    "title": "Simulating Generative Social Agents via Theory-Informed Workflow Design",
    "authors": [
      "Yuwei Yan",
      "Jinghua Piao",
      "Xiaochong Lan",
      "Chenyang Shao",
      "Pan Hui",
      "Yong Li"
    ],
    "abstract": "Recent advances in large language models have demonstrated strong reasoning and role-playing capabilities, opening new opportunities for agent-based social simulations. However, most existing agents' implementations are scenario-tailored, without a unified framework to guide the design. This lack of a general social agent limits their ability to generalize across different social contexts and to produce consistent, realistic behaviors. To address this challenge, we propose a theory-informed framework that provides a systematic design process for LLM-based social agents. Our framework is grounded in principles from Social Cognition Theory and introduces three key modules: motivation, action planning, and learning. These modules jointly enable agents to reason about their goals, plan coherent actions, and adapt their behavior over time, leading to more flexible and contextually appropriate responses. Comprehensive experiments demonstrate that our theory-driven agents reproduce realistic human behavior patterns under complex conditions, achieving up to 75% lower deviation from real-world behavioral data across multiple fidelity metrics compared to classical generative baselines. Ablation studies further show that removing motivation, planning, or learning modules increases errors by 1.5 to 3.2 times, confirming their distinct and essential contributions to generating realistic and coherent social behaviors.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.08726v1",
    "published_date": "2025-08-12 08:14:48 UTC",
    "updated_date": "2025-08-12 08:14:48 UTC"
  },
  {
    "arxiv_id": "2508.08719v2",
    "title": "IROTE: Human-like Traits Elicitation of Large Language Model via In-Context Self-Reflective Optimization",
    "authors": [
      "Yuzhuo Bai",
      "Shitong Duan",
      "Muhua Huang",
      "Jing Yao",
      "Zhenghao Liu",
      "Peng Zhang",
      "Tun Lu",
      "Xiaoyuan Yi",
      "Maosong Sun",
      "Xing Xie"
    ],
    "abstract": "Trained on various human-authored corpora, Large Language Models (LLMs) have demonstrated a certain capability of reflecting specific human-like traits (e.g., personality or values) by prompting, benefiting applications like personalized LLMs and social simulations. However, existing methods suffer from the superficial elicitation problem: LLMs can only be steered to mimic shallow and unstable stylistic patterns, failing to embody the desired traits precisely and consistently across diverse tasks like humans. To address this challenge, we propose IROTE, a novel in-context method for stable and transferable trait elicitation. Drawing on psychological theories suggesting that traits are formed through identity-related reflection, our method automatically generates and optimizes a textual self-reflection within prompts, which comprises self-perceived experience, to stimulate LLMs' trait-driven behavior. The optimization is performed by iteratively maximizing an information-theoretic objective that enhances the connections between LLMs' behavior and the target trait, while reducing noisy redundancy in reflection without any fine-tuning, leading to evocative and compact trait reflection. Extensive experiments across three human trait systems manifest that one single IROTE-generated self-reflection can induce LLMs' stable impersonation of the target trait across diverse downstream tasks beyond simple questionnaire answering, consistently outperforming existing strong baselines.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "This paper is accepted by AAAI 2026",
    "pdf_url": "https://arxiv.org/pdf/2508.08719v2",
    "published_date": "2025-08-12 08:04:28 UTC",
    "updated_date": "2025-11-27 12:38:51 UTC"
  },
  {
    "arxiv_id": "2508.08718v1",
    "title": "Generative Modeling for Robust Deep Reinforcement Learning on the Traveling Salesman Problem",
    "authors": [
      "Michael Li",
      "Eric Bae",
      "Christopher Haberland",
      "Natasha Jaques"
    ],
    "abstract": "The Traveling Salesman Problem (TSP) is a classic NP-hard combinatorial optimization task with numerous practical applications. Classic heuristic solvers can attain near-optimal performance for small problem instances, but become computationally intractable for larger problems. Real-world logistics problems such as dynamically re-routing last-mile deliveries demand a solver with fast inference time, which has led researchers to investigate specialized neural network solvers. However, neural networks struggle to generalize beyond the synthetic data they were trained on. In particular, we show that there exist TSP distributions that are realistic in practice, which also consistently lead to poor worst-case performance for existing neural approaches. To address this issue of distribution robustness, we present Combinatorial Optimization with Generative Sampling (COGS), where training data is sampled from a generative TSP model. We show that COGS provides better data coverage and interpolation in the space of TSP training distributions. We also present TSPLib50, a dataset of realistically distributed TSP samples, which tests real-world generalization ability without conflating this issue with instance size. We evaluate our method on various synthetic datasets as well as TSPLib50, and compare to state-of-the-art neural baselines. We demonstrate that COGS improves distribution robustness, with most performance gains coming from worst-case scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 8 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.08718v1",
    "published_date": "2025-08-12 08:04:16 UTC",
    "updated_date": "2025-08-12 08:04:16 UTC"
  },
  {
    "arxiv_id": "2508.08715v3",
    "title": "MultiGen: Child-Friendly Multilingual Speech Generator with LLMs",
    "authors": [
      "Xiaoxue Gao",
      "Huayun Zhang",
      "Nancy F. Chen"
    ],
    "abstract": "Generative speech models have demonstrated significant potential in improving human-machine interactions, offering valuable real-world applications such as language learning for children. However, achieving high-quality, child-friendly speech generation remains challenging, particularly for low-resource languages across diverse languages and cultural contexts. In this paper, we propose MultiGen, a multilingual speech generation model with child-friendly interaction, leveraging LLM architecture for speech generation tailored for low-resource languages. We propose to integrate age-appropriate multilingual speech generation using LLM architectures, which can be used to facilitate young children's communication with AI systems through culturally relevant context in three low-resource languages: Singaporean accent Mandarin, Malay, and Tamil. Experimental results from both objective metrics and subjective evaluations demonstrate the superior performance of the proposed MultiGen compared to baseline methods.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL",
      "eess.SP"
    ],
    "primary_category": "eess.AS",
    "comment": "5 pages",
    "pdf_url": "https://arxiv.org/pdf/2508.08715v3",
    "published_date": "2025-08-12 07:58:48 UTC",
    "updated_date": "2025-09-04 07:56:00 UTC"
  },
  {
    "arxiv_id": "2508.08712v3",
    "title": "A Survey on Parallel Text Generation: From Parallel Decoding to Diffusion Language Models",
    "authors": [
      "Lingzhe Zhang",
      "Liancheng Fang",
      "Chiming Duan",
      "Minghua He",
      "Leyi Pan",
      "Pei Xiao",
      "Shiyu Huang",
      "Yunpeng Zhai",
      "Xuming Hu",
      "Philip S. Yu",
      "Aiwei Liu"
    ],
    "abstract": "As text generation has become a core capability of modern Large Language Models (LLMs), it underpins a wide range of downstream applications. However, most existing LLMs rely on autoregressive (AR) generation, producing one token at a time based on previously generated context-resulting in limited generation speed due to the inherently sequential nature of the process. To address this challenge, an increasing number of researchers have begun exploring parallel text generation-a broad class of techniques aimed at breaking the token-by-token generation bottleneck and improving inference efficiency. Despite growing interest, there remains a lack of comprehensive analysis on what specific techniques constitute parallel text generation and how they improve inference performance. To bridge this gap, we present a systematic survey of parallel text generation methods. We categorize existing approaches into AR-based and Non-AR-based paradigms, and provide a detailed examination of the core techniques within each category. Following this taxonomy, we assess their theoretical trade-offs in terms of speed, quality, and efficiency, and examine their potential for combination and comparison with alternative acceleration strategies. Finally, based on our findings, we highlight recent advancements, identify open challenges, and outline promising directions for future research in parallel text generation. We have also created a GitHub repository for indexing relevant papers and open resources available at https://github.com/zhanglingzhe0820/Awesome-Parallel-Text-Generation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.08712v3",
    "published_date": "2025-08-12 07:56:04 UTC",
    "updated_date": "2025-08-27 03:08:49 UTC"
  },
  {
    "arxiv_id": "2508.09230v1",
    "title": "Cowpox: Towards the Immunity of VLM-based Multi-Agent Systems",
    "authors": [
      "Yutong Wu",
      "Jie Zhang",
      "Yiming Li",
      "Chao Zhang",
      "Qing Guo",
      "Nils Lukas",
      "Tianwei Zhang"
    ],
    "abstract": "Vision Language Model (VLM)-based agents are stateful, autonomous entities capable of perceiving and interacting with their environments through vision and language. Multi-agent systems comprise specialized agents who collaborate to solve a (complex) task. A core security property is robustness, stating that the system should maintain its integrity under adversarial attacks. However, the design of existing multi-agent systems lacks the robustness consideration, as a successful exploit against one agent can spread and infect other agents to undermine the entire system's assurance. To address this, we propose a new defense approach, Cowpox, to provably enhance the robustness of multi-agent systems. It incorporates a distributed mechanism, which improves the recovery rate of agents by limiting the expected number of infections to other agents. The core idea is to generate and distribute a special cure sample that immunizes an agent against the attack before exposure and helps recover the already infected agents. We demonstrate the effectiveness of Cowpox empirically and provide theoretical robustness guarantees.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.09230v1",
    "published_date": "2025-08-12 07:48:51 UTC",
    "updated_date": "2025-08-12 07:48:51 UTC"
  },
  {
    "arxiv_id": "2508.08701v2",
    "title": "SafeFix: Targeted Model Repair via Controlled Image Generation",
    "authors": [
      "Ouyang Xu",
      "Baoming Zhang",
      "Ruiyu Mao",
      "Yunhui Guo"
    ],
    "abstract": "Deep learning models for visual recognition often exhibit systematic errors due to underrepresented semantic subpopulations. Although existing debugging frameworks can pinpoint these failures by identifying key failure attributes, repairing the model effectively remains difficult. Current solutions often rely on manually designed prompts to generate synthetic training images -- an approach prone to distribution shift and semantic errors. To overcome these challenges, we introduce a model repair module that builds on an interpretable failure attribution pipeline. Our approach uses a conditional text-to-image model to generate semantically faithful and targeted images for failure cases. To preserve the quality and relevance of the generated samples, we further employ a large vision-language model (LVLM) to filter the outputs, enforcing alignment with the original data distribution and maintaining semantic consistency. By retraining vision models with this rare-case-augmented synthetic dataset, we significantly reduce errors associated with rare cases. Our experiments demonstrate that this targeted repair strategy improves model robustness without introducing new bugs. Code is available at https://github.com/oxu2/SafeFix",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.08701v2",
    "published_date": "2025-08-12 07:45:25 UTC",
    "updated_date": "2025-11-24 19:26:12 UTC"
  },
  {
    "arxiv_id": "2508.14906v1",
    "title": "Collaborative Filtering using Variational Quantum Hopfield Associative Memory",
    "authors": [
      "Amir Kermanshahani",
      "Ebrahim Ardeshir-Larijani",
      "Rakesh Saini",
      "Saif Al-Kuwari"
    ],
    "abstract": "Quantum computing, with its ability to do exponentially faster computation compared to classical systems, has found novel applications in various fields such as machine learning and recommendation systems. Quantum Machine Learning (QML), which integrates quantum computing with machine learning techniques, presents powerful new tools for data processing and pattern recognition. This paper proposes a hybrid recommendation system that combines Quantum Hopfield Associative Memory (QHAM) with deep neural networks to improve the extraction and classification on the MovieLens 1M dataset. User archetypes are clustered into multiple unique groups using the K-Means algorithm and converted into polar patterns through the encoder's activation function. These polar patterns are then integrated into the variational QHAM-based hybrid recommendation model. The system was trained using the MSE loss over 35 epochs in an ideal environment, achieving an ROC value of 0.9795, an accuracy of 0.8841, and an F-1 Score of 0.8786. Trained with the same number of epochs in a noisy environment using a custom Qiskit AER noise model incorporating bit-flip and readout errors with the same probabilities as in real quantum hardware, it achieves an ROC of 0.9177, an accuracy of 0.8013, and an F-1 Score equal to 0.7866, demonstrating consistent performance.\n  Additionally, we were able to optimize the qubit overhead present in previous QHAM architectures by efficiently updating only one random targeted qubit. This research presents a novel framework that combines variational quantum computing with deep learning, capable of dealing with real-world datasets with comparable performance compared to purely classical counterparts. Additionally, the model can perform similarly well in noisy configurations, showcasing a steady performance and proposing a promising direction for future usage in recommendation systems.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.ET",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.14906v1",
    "published_date": "2025-08-12 07:33:11 UTC",
    "updated_date": "2025-08-12 07:33:11 UTC"
  },
  {
    "arxiv_id": "2508.08688v1",
    "title": "STELAR-VISION: Self-Topology-Aware Efficient Learning for Aligned Reasoning in Vision",
    "authors": [
      "Chen Li",
      "Han Zhang",
      "Zhantao Yang",
      "Fangyi Chen",
      "Zihan Wang",
      "Anudeepsekhar Bolimera",
      "Marios Savvides"
    ],
    "abstract": "Vision-language models (VLMs) have made significant strides in reasoning, yet they often struggle with complex multimodal tasks and tend to generate overly verbose outputs. A key limitation is their reliance on chain-of-thought (CoT) reasoning, despite many tasks benefiting from alternative topologies like trees or graphs. To address this, we introduce STELAR-Vision, a training framework for topology-aware reasoning. At its core is TopoAug, a synthetic data pipeline that enriches training with diverse topological structures. Using supervised fine-tuning and reinforcement learning, we post-train Qwen2VL models with both accuracy and efficiency in mind. Additionally, we propose Frugal Learning, which reduces output length with minimal accuracy loss. On MATH-V and VLM-S2H, STELAR-Vision improves accuracy by 9.7% over its base model and surpasses the larger Qwen2VL-72B-Instruct by 7.3%. On five out-of-distribution benchmarks, it outperforms Phi-4-Multimodal-Instruct by up to 28.4% and LLaMA-3.2-11B-Vision-Instruct by up to 13.2%, demonstrating strong generalization. Compared to Chain-Only training, our approach achieves 4.3% higher overall accuracy on in-distribution datasets and consistently outperforms across all OOD benchmarks. We have released datasets, and code will be available.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.08688v1",
    "published_date": "2025-08-12 07:27:50 UTC",
    "updated_date": "2025-08-12 07:27:50 UTC"
  },
  {
    "arxiv_id": "2508.09229v1",
    "title": "Cluster Topology-Driven Placement of Experts Reduces Network Traffic in MoE Inference",
    "authors": [
      "Danil Sivtsov",
      "Aleksandr Katrutsa",
      "Ivan Oseledets"
    ],
    "abstract": "Efficient deployment of a pre-trained LLM to a cluster with multiple servers is a critical step for providing fast responses to users' queries. The recent success of Mixture-of-Experts (MoE) LLMs raises the question of how to deploy them efficiently, considering their underlying structure. During the inference in MoE LLMs, only a small part of the experts is selected to process a given token. Moreover, in practice, the experts' load is highly imbalanced. For efficient deployment, one has to distribute the model across a large number of servers using a model placement algorithm. Thus, to improve cluster utilization, the model placement algorithm has to take into account the network topology. This work focuses on the efficient topology-aware placement of the pre-trained MoE LLMs in the inference stage. We propose an integer linear program (ILP) that determines the optimal placement of experts, minimizing the expected number of transmissions. Due to the internal structure, this optimization problem can be solved with a standard ILP solver. We demonstrate that ILP-based placement strategy yields lower network traffic than competitors for small-scale (DeepSeekMoE~16B) and large-scale (DeepSeek-R1~671B) models.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.09229v1",
    "published_date": "2025-08-12 07:08:48 UTC",
    "updated_date": "2025-08-12 07:08:48 UTC"
  },
  {
    "arxiv_id": "2508.08679v2",
    "title": "MMIF-AMIN: Adaptive Loss-Driven Multi-Scale Invertible Dense Network for Multimodal Medical Image Fusion",
    "authors": [
      "Tao Luo",
      "Weihua Xu"
    ],
    "abstract": "Multimodal medical image fusion (MMIF) aims to integrate images from different modalities to produce a comprehensive image that enhances medical diagnosis by accurately depicting organ structures, tissue textures, and metabolic information. Capturing both the unique and complementary information across multiple modalities simultaneously is a key research challenge in MMIF. To address this challenge, this paper proposes a novel image fusion method, MMIF-AMIN, which features a new architecture that can effectively extract these unique and complementary features. Specifically, an Invertible Dense Network (IDN) is employed for lossless feature extraction from individual modalities. To extract complementary information between modalities, a Multi-scale Complementary Feature Extraction Module (MCFEM) is designed, which incorporates a hybrid attention mechanism, convolutional layers of varying sizes, and Transformers. An adaptive loss function is introduced to guide model learning, addressing the limitations of traditional manually-designed loss functions and enhancing the depth of data mining. Extensive experiments demonstrate that MMIF-AMIN outperforms nine state-of-the-art MMIF methods, delivering superior results in both quantitative and qualitative analyses. Ablation experiments confirm the effectiveness of each component of the proposed method. Additionally, extending MMIF-AMIN to other image fusion tasks also achieves promising performance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "This manuscript is withdrawn to allow for substantial expansion and restructuring. Based on recent research progress, we plan to add Generalization experiment and reorganize the manuscript structure to improve readability and logical flow. Thank you for your understanding and support",
    "pdf_url": "https://arxiv.org/pdf/2508.08679v2",
    "published_date": "2025-08-12 06:55:38 UTC",
    "updated_date": "2025-12-01 09:05:21 UTC"
  },
  {
    "arxiv_id": "2508.10047v1",
    "title": "A Survey of Optimization Modeling Meets LLMs: Progress and Future Directions",
    "authors": [
      "Ziyang Xiao",
      "Jingrong Xie",
      "Lilin Xu",
      "Shisi Guan",
      "Jingyan Zhu",
      "Xiongwei Han",
      "Xiaojin Fu",
      "WingYin Yu",
      "Han Wu",
      "Wei Shi",
      "Qingcan Kang",
      "Jiahui Duan",
      "Tao Zhong",
      "Mingxuan Yuan",
      "Jia Zeng",
      "Yuan Wang",
      "Gang Chen",
      "Dongxiang Zhang"
    ],
    "abstract": "By virtue of its great utility in solving real-world problems, optimization modeling has been widely employed for optimal decision-making across various sectors, but it requires substantial expertise from operations research professionals. With the advent of large language models (LLMs), new opportunities have emerged to automate the procedure of mathematical modeling. This survey presents a comprehensive and timely review of recent advancements that cover the entire technical stack, including data synthesis and fine-tuning for the base model, inference frameworks, benchmark datasets, and performance evaluation. In addition, we conducted an in-depth analysis on the quality of benchmark datasets, which was found to have a surprisingly high error rate. We cleaned the datasets and constructed a new leaderboard with fair performance evaluation in terms of base LLM model and datasets. We also build an online portal that integrates resources of cleaned datasets, code and paper repository to benefit the community. Finally, we identify limitations in current methodologies and outline future research opportunities.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.10047v1",
    "published_date": "2025-08-12 06:55:33 UTC",
    "updated_date": "2025-08-12 06:55:33 UTC"
  },
  {
    "arxiv_id": "2508.09227v1",
    "title": "GSMT: Graph Fusion and Spatiotemporal TaskCorrection for Multi-Bus Trajectory Prediction",
    "authors": [
      "Fan Ding",
      "Hwa Hui Tew",
      "Junn Yong Loo",
      "Susilawati",
      "LiTong Liu",
      "Fang Yu Leong",
      "Xuewen Luo",
      "Kar Keong Chin",
      "Jia Jun Gan"
    ],
    "abstract": "Accurate trajectory prediction for buses is crucial in intelligent transportation systems, particularly within urban environments. In developing regions where access to multimodal data is limited, relying solely on onboard GPS data remains indispensable despite inherent challenges. To address this problem, we propose GSMT, a hybrid model that integrates a Graph Attention Network (GAT) with a sequence-to-sequence Recurrent Neural Network (RNN), and incorporates a task corrector capable of extracting complex behavioral patterns from large-scale trajectory data. The task corrector clusters historical trajectories to identify distinct motion patterns and fine-tunes the predictions generated by the GAT and RNN. Specifically, GSMT fuses dynamic bus information and static station information through embedded hybrid networks to perform trajectory prediction, and applies the task corrector for secondary refinement after the initial predictions are generated. This two-stage approach enables multi-node trajectory prediction among buses operating in dense urban traffic environments under complex conditions. Experiments conducted on a real-world dataset from Kuala Lumpur, Malaysia, demonstrate that our method significantly outperforms existing approaches, achieving superior performance in both short-term and long-term trajectory prediction tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.LG",
    "comment": "This paper has been accepted by ITSC 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.09227v1",
    "published_date": "2025-08-12 06:54:26 UTC",
    "updated_date": "2025-08-12 06:54:26 UTC"
  },
  {
    "arxiv_id": "2508.10046v1",
    "title": "SABIA: An AI-Powered Tool for Detecting Opioid-Related Behaviors on Social Media",
    "authors": [
      "Muhammad Ahmad",
      "Fida Ullah",
      "Muhammad Usman",
      "Ildar Batyrshin",
      "Grigori Sidorov"
    ],
    "abstract": "Social media platforms have become valuable tools for understanding public health challenges by offering insights into patient behaviors, medication use, and mental health issues. However, analyzing such data remains difficult due to the prevalence of informal language, slang, and coded communication, which can obscure the detection of opioid misuse. This study addresses the issue of opioid-related user behavior on social media, including informal expressions, slang terms, and misspelled or coded language. We analyzed the existing Bidirectional Encoder Representations from Transformers (BERT) technique and developed a BERT-BiLSTM-3CNN hybrid deep learning model, named SABIA, to create a single-task classifier that effectively captures the features of the target dataset. The SABIA model demonstrated strong capabilities in capturing semantics and contextual information. The proposed approach includes: (1) data preprocessing, (2) data representation using the SABIA model, (3) a fine-tuning phase, and (4) classification of user behavior into five categories. A new dataset was constructed from Reddit posts, identifying opioid user behaviors across five classes: Dealers, Active Opioid Users, Recovered Users, Prescription Users, and Non-Users, supported by detailed annotation guidelines. Experiments were conducted using supervised learning. Results show that SABIA achieved benchmark performance, outperforming the baseline (Logistic Regression, LR = 0.86) and improving accuracy by 9.30%. Comparisons with seven previous studies confirmed its effectiveness and robustness. This study demonstrates the potential of hybrid deep learning models for detecting complex opioid-related behaviors on social media, supporting public health monitoring and intervention efforts.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.10046v1",
    "published_date": "2025-08-12 06:52:41 UTC",
    "updated_date": "2025-08-12 06:52:41 UTC"
  },
  {
    "arxiv_id": "2508.16603v1",
    "title": "GreenTEA: Gradient Descent with Topic-modeling and Evolutionary Auto-prompting",
    "authors": [
      "Zheng Dong",
      "Luming Shang",
      "Gabriela Olinto"
    ],
    "abstract": "High-quality prompts are crucial for Large Language Models (LLMs) to achieve exceptional performance. However, manually crafting effective prompts is labor-intensive and demands significant domain expertise, limiting its scalability. Existing automatic prompt optimization methods either extensively explore new prompt candidates, incurring high computational costs due to inefficient searches within a large solution space, or overly exploit feedback on existing prompts, risking suboptimal optimization because of the complex prompt landscape. To address these challenges, we introduce GreenTEA, an agentic LLM workflow for automatic prompt optimization that balances candidate exploration and knowledge exploitation. It leverages a collaborative team of agents to iteratively refine prompts based on feedback from error samples. An analyzing agent identifies common error patterns resulting from the current prompt via topic modeling, and a generation agent revises the prompt to directly address these key deficiencies. This refinement process is guided by a genetic algorithm framework, which simulates natural selection by evolving candidate prompts through operations such as crossover and mutation to progressively optimize model performance. Extensive numerical experiments conducted on public benchmark datasets suggest the superior performance of GreenTEA against human-engineered prompts and existing state-of-the-arts for automatic prompt optimization, covering logical and quantitative reasoning, commonsense, and ethical decision-making.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.16603v1",
    "published_date": "2025-08-12 06:48:30 UTC",
    "updated_date": "2025-08-12 06:48:30 UTC"
  },
  {
    "arxiv_id": "2508.09225v1",
    "title": "AMRG: Extend Vision Language Models for Automatic Mammography Report Generation",
    "authors": [
      "Nak-Jun Sung",
      "Donghyun Lee",
      "Bo Hwa Choi",
      "Chae Jung Park"
    ],
    "abstract": "Mammography report generation is a critical yet underexplored task in medical AI, characterized by challenges such as multiview image reasoning, high-resolution visual cues, and unstructured radiologic language. In this work, we introduce AMRG (Automatic Mammography Report Generation), the first end-to-end framework for generating narrative mammography reports using large vision-language models (VLMs). Building upon MedGemma-4B-it-a domain-specialized, instruction-tuned VLM-we employ a parameter-efficient fine-tuning (PEFT) strategy via Low-Rank Adaptation (LoRA), enabling lightweight adaptation with minimal computational overhead. We train and evaluate AMRG on DMID, a publicly available dataset of paired high-resolution mammograms and diagnostic reports. This work establishes the first reproducible benchmark for mammography report generation, addressing a longstanding gap in multimodal clinical AI. We systematically explore LoRA hyperparameter configurations and conduct comparative experiments across multiple VLM backbones, including both domain-specific and general-purpose models under a unified tuning protocol. Our framework demonstrates strong performance across both language generation and clinical metrics, achieving a ROUGE-L score of 0.5691, METEOR of 0.6152, CIDEr of 0.5818, and BI-RADS accuracy of 0.5582. Qualitative analysis further highlights improved diagnostic consistency and reduced hallucinations. AMRG offers a scalable and adaptable foundation for radiology report generation and paves the way for future research in multimodal medical AI.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.09225v1",
    "published_date": "2025-08-12 06:37:41 UTC",
    "updated_date": "2025-08-12 06:37:41 UTC"
  },
  {
    "arxiv_id": "2508.08672v2",
    "title": "Imposing AI: Deceptive design patterns against sustainability",
    "authors": [
      "Anaëlle Beignon",
      "Thomas Thibault",
      "Nolwenn Maudet"
    ],
    "abstract": "Generative AI is being massively deployed in digital services, at a scale that will result in significant environmental harm. We document how tech companies are transforming established user interfaces to impose AI use and show how and to what extent these strategies fit within established deceptive pattern categories. We identify two main design strategies that are implemented to impose AI use in both personal and professional contexts: imposing AI features in interfaces at the expense of existing non-AI features and promoting narratives about AI that make it harder to resist using it. We discuss opportunities for regulating the imposed adoption of AI features, which would inevitably lead to negative environmental effects.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.08672v2",
    "published_date": "2025-08-12 06:37:39 UTC",
    "updated_date": "2025-09-12 13:49:51 UTC"
  },
  {
    "arxiv_id": "2508.08665v2",
    "title": "Aryabhata: An exam-focused language model for JEE Math",
    "authors": [
      "Ritvik Rastogi",
      "Sachin Dharashivkar",
      "Sandeep Varma"
    ],
    "abstract": "We present Aryabhata 1.0, a compact 7B parameter math reasoning model optimized for the Indian academic exam, the Joint Entrance Examination (JEE). Despite rapid progress in large language models (LLMs), current models often remain unsuitable for educational use. Aryabhata 1.0 is built by merging strong open-weight reasoning models, followed by supervised fine-tuning (SFT) with curriculum learning on verified chain-of-thought (CoT) traces curated through best-of-$n$ rejection sampling. To further boost performance, we apply reinforcement learning with verifiable rewards (RLVR) using A2C objective with group-relative advantage estimation along with novel exploration strategies such as Adaptive Group Resizing and Temperature Scaling. Evaluated on both in-distribution (JEE Main 2025) and out-of-distribution (MATH, GSM8K) benchmarks, Aryabhata outperforms existing models in accuracy and efficiency, while offering pedagogically useful step-by-step reasoning. We release Aryabhata as a foundation model to advance exam-centric, open-source small language models. This marks our first open release for community feedback (https://huggingface.co/PhysicsWallahAI/Aryabhata-1.0); PW is actively training future models to further improve learning outcomes for students.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.08665v2",
    "published_date": "2025-08-12 06:20:07 UTC",
    "updated_date": "2025-08-13 05:34:21 UTC"
  },
  {
    "arxiv_id": "2508.08661v1",
    "title": "Hallucinations in Code Change to Natural Language Generation: Prevalence and Evaluation of Detection Metrics",
    "authors": [
      "Chunhua Liu",
      "Hong Yi Lin",
      "Patanamon Thongtanunam"
    ],
    "abstract": "Language models have shown strong capabilities across a wide range of tasks in software engineering, such as code generation, yet they suffer from hallucinations. While hallucinations have been studied independently in natural language and code generation, their occurrence in tasks involving code changes which have a structurally complex and context-dependent format of code remains largely unexplored. This paper presents the first comprehensive analysis of hallucinations in two critical tasks involving code change to natural language generation: commit message generation and code review comment generation. We quantify the prevalence of hallucinations in recent language models and explore a range of metric-based approaches to automatically detect them. Our findings reveal that approximately 50\\% of generated code reviews and 20\\% of generated commit messages contain hallucinations. Whilst commonly used metrics are weak detectors on their own, combining multiple metrics substantially improves performance. Notably, model confidence and feature attribution metrics effectively contribute to hallucination detection, showing promise for inference-time detection.\\footnote{All code and data will be released upon acceptance.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "8 main pages, 5 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.08661v1",
    "published_date": "2025-08-12 05:59:33 UTC",
    "updated_date": "2025-08-12 05:59:33 UTC"
  },
  {
    "arxiv_id": "2508.08659v1",
    "title": "Hybrid Node-Destroyer Model with Large Neighborhood Search for Solving the Capacitated Vehicle Routing Problem",
    "authors": [
      "Bachtiar Herdianto",
      "Romain Billot",
      "Flavien Lucas",
      "Marc Sevaux",
      "Daniele Vigo"
    ],
    "abstract": "In this research, we propose an iterative learning hybrid optimization solver developed to strengthen the performance of metaheuristic algorithms in solving the Capacitated Vehicle Routing Problem (CVRP). The iterative hybrid mechanism integrates the proposed Node-Destroyer Model, a machine learning hybrid model that utilized Graph Neural Networks (GNNs) such identifies and selects customer nodes to guide the Large Neighborhood Search (LNS) operator within the metaheuristic optimization frameworks. This model leverages the structural properties of the problem and solution that can be represented as a graph, to guide strategic selections concerning node removal. The proposed approach reduces operational complexity and scales down the search space involved in the optimization process. The hybrid approach is applied specifically to the CVRP and does not require retraining across problem instances of different sizes. The proposed hybrid mechanism is able to improve the performance of baseline metaheuristic algorithms. Our approach not only enhances the solution quality for standard CVRP benchmarks but also proves scalability on very large-scale instances with up to 30,000 customer nodes. Experimental evaluations on benchmark datasets show that the proposed hybrid mechanism is capable of improving different baseline algorithms, achieving better quality of solutions under similar settings.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "19 pages, 10 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.08659v1",
    "published_date": "2025-08-12 05:56:13 UTC",
    "updated_date": "2025-08-12 05:56:13 UTC"
  },
  {
    "arxiv_id": "2508.11690v1",
    "title": "Real Time Child Abduction And Detection System",
    "authors": [
      "Tadisetty Sai Yashwanth",
      "Yangalasetty Sruthi Royal",
      "Vankayala Rajeshwari Shreya",
      "Mayank Kashyap",
      "Divyaprabha K N"
    ],
    "abstract": "Child safety continues to be a paramount concern worldwide, with child abduction posing significant threats to communities. This paper presents the development of an edge-based child abduction detection and alert system utilizing a multi-agent framework where each agent incorporates Vision-Language Models (VLMs) deployed on a Raspberry Pi. Leveraging the advanced capabilities of VLMs within individual agents of a multi-agent team, our system is trained to accurately detect and interpret complex interactions involving children in various environments in real-time. The multi-agent system is deployed on a Raspberry Pi connected to a webcam, forming an edge device capable of processing video feeds, thereby reducing latency and enhancing privacy. An integrated alert system utilizes the Twilio API to send immediate SMS and WhatsApp notifications, including calls and messages, when a potential child abduction event is detected. Experimental results demonstrate that the system achieves high accuracy in detecting potential abduction scenarios, with near real-time performance suitable for practical deployment. The multi-agent architecture enhances the system's ability to process complex situational data, improving detection capabilities over traditional single-model approaches. The edge deployment ensures scalability and cost-effectiveness, making it accessible for widespread use. The proposed system offers a proactive solution to enhance child safety through continuous monitoring and rapid alerting, contributing a valuable tool in efforts to prevent child abductions.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.11690v1",
    "published_date": "2025-08-12 05:56:05 UTC",
    "updated_date": "2025-08-12 05:56:05 UTC"
  },
  {
    "arxiv_id": "2508.08657v1",
    "title": "$\\text{M}^{2}$LLM: Multi-view Molecular Representation Learning with Large Language Models",
    "authors": [
      "Jiaxin Ju",
      "Yizhen Zheng",
      "Huan Yee Koh",
      "Can Wang",
      "Shirui Pan"
    ],
    "abstract": "Accurate molecular property prediction is a critical challenge with wide-ranging applications in chemistry, materials science, and drug discovery. Molecular representation methods, including fingerprints and graph neural networks (GNNs), achieve state-of-the-art results by effectively deriving features from molecular structures. However, these methods often overlook decades of accumulated semantic and contextual knowledge. Recent advancements in large language models (LLMs) demonstrate remarkable reasoning abilities and prior knowledge across scientific domains, leading us to hypothesize that LLMs can generate rich molecular representations when guided to reason in multiple perspectives. To address these gaps, we propose $\\text{M}^{2}$LLM, a multi-view framework that integrates three perspectives: the molecular structure view, the molecular task view, and the molecular rules view. These views are fused dynamically to adapt to task requirements, and experiments demonstrate that $\\text{M}^{2}$LLM achieves state-of-the-art performance on multiple benchmarks across classification and regression tasks. Moreover, we demonstrate that representation derived from LLM achieves exceptional performance by leveraging two core functionalities: the generation of molecular embeddings through their encoding capabilities and the curation of molecular features through advanced reasoning processes.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "IJCAI 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.08657v1",
    "published_date": "2025-08-12 05:46:47 UTC",
    "updated_date": "2025-08-12 05:46:47 UTC"
  },
  {
    "arxiv_id": "2508.08653v1",
    "title": "LLM driven Text-to-Table Generation through Sub-Tasks Guidance and Iterative Refinement",
    "authors": [
      "Rajmohan C",
      "Sarthak Harne",
      "Arvind Agarwal"
    ],
    "abstract": "Transforming unstructured text into structured data is a complex task, requiring semantic understanding, reasoning, and structural comprehension. While Large Language Models (LLMs) offer potential, they often struggle with handling ambiguous or domain-specific data, maintaining table structure, managing long inputs, and addressing numerical reasoning. This paper proposes an efficient system for LLM-driven text-to-table generation that leverages novel prompting techniques. Specifically, the system incorporates two key strategies: breaking down the text-to-table task into manageable, guided sub-tasks and refining the generated tables through iterative self-feedback. We show that this custom task decomposition allows the model to address the problem in a stepwise manner and improves the quality of the generated table. Furthermore, we discuss the benefits and potential risks associated with iterative self-feedback on the generated tables while highlighting the trade-offs between enhanced performance and computational cost. Our methods achieve strong results compared to baselines on two complex text-to-table generation datasets available in the public domain.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.08653v1",
    "published_date": "2025-08-12 05:37:12 UTC",
    "updated_date": "2025-08-12 05:37:12 UTC"
  },
  {
    "arxiv_id": "2508.08652v1",
    "title": "Prompt-and-Check: Using Large Language Models to Evaluate Communication Protocol Compliance in Simulation-Based Training",
    "authors": [
      "Vishakha Lall",
      "Yisi Liu"
    ],
    "abstract": "Accurate evaluation of procedural communication compliance is essential in simulation-based training, particularly in safety-critical domains where adherence to compliance checklists reflects operational competence. This paper explores a lightweight, deployable approach using prompt-based inference with open-source large language models (LLMs) that can run efficiently on consumer-grade GPUs. We present Prompt-and-Check, a method that uses context-rich prompts to evaluate whether each checklist item in a protocol has been fulfilled, solely based on transcribed verbal exchanges. We perform a case study in the maritime domain with participants performing an identical simulation task, and experiment with models such as LLama 2 7B, LLaMA 3 8B and Mistral 7B, running locally on an RTX 4070 GPU. For each checklist item, a prompt incorporating relevant transcript excerpts is fed into the model, which outputs a compliance judgment. We assess model outputs against expert-annotated ground truth using classification accuracy and agreement scores. Our findings demonstrate that prompting enables effective context-aware reasoning without task-specific training. This study highlights the practical utility of LLMs in augmenting debriefing, performance feedback, and automated assessment in training environments.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.08652v1",
    "published_date": "2025-08-12 05:35:57 UTC",
    "updated_date": "2025-08-12 05:35:57 UTC"
  },
  {
    "arxiv_id": "2508.14071v1",
    "title": "Edge-Selector Model Applied for Local Search Neighborhood for Solving Vehicle Routing Problems",
    "authors": [
      "Bachtiar Herdianto",
      "Romain Billot",
      "Flavien Lucas",
      "Marc Sevaux",
      "Daniele Vigo"
    ],
    "abstract": "This research proposes a hybrid Machine Learning and metaheuristic mechanism that is designed to solve Vehicle Routing Problems (VRPs). The main of our method is an edge solution selector model, which classifies solution edges to identify prohibited moves during the local search, hence guiding the search process within metaheuristic baselines. Two learning-based mechanisms are used to develop the edge selector: a simple tabular binary classifier and a Graph Neural Network (GNN). The tabular classifier employs Gradient Boosting Trees and Feedforward Neural Network as the baseline algorithms. Adjustments to the decision threshold are also applied to handle the class imbalance in the problem instance. An alternative mechanism employs the GNN to utilize graph structure for direct solution edge prediction, with the objective of guiding local search by predicting prohibited moves. These hybrid mechanisms are then applied in state-fo-the-art metaheuristic baselines. Our method demonstrates both scalability and generalizability, achieving performance improvements across different baseline metaheuristics, various problem sizes and variants, including the Capacitated Vehicle Routing Problem (CVRP) and CVRP with Time Windows (CVRPTW). Experimental evaluations on benchmark datasets up to 30,000 customer nodes, supported by pair-wise statistical analysis, verify the observed improvements.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "29 pages, 12 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.14071v1",
    "published_date": "2025-08-12 05:28:26 UTC",
    "updated_date": "2025-08-12 05:28:26 UTC"
  },
  {
    "arxiv_id": "2508.08646v1",
    "title": "P-CAFE: Personalized Cost-Aware Incremental Feature Selection For Electronic Health Records",
    "authors": [
      "Naama Kashani",
      "Mira Cohen",
      "Uri Shaham"
    ],
    "abstract": "Electronic Health Records (EHR) have revolutionized healthcare by digitizing patient data, improving accessibility, and streamlining clinical workflows. However, extracting meaningful insights from these complex and multimodal datasets remains a significant challenge for researchers. Traditional feature selection methods often struggle with the inherent sparsity and heterogeneity of EHR data, especially when accounting for patient-specific variations and feature costs in clinical applications. To address these challenges, we propose a novel personalized, online and cost-aware feature selection framework tailored specifically for EHR datasets. The features are aquired in an online fashion for individual patients, incorporating budgetary constraints and feature variability costs. The framework is designed to effectively manage sparse and multimodal data, ensuring robust and scalable performance in diverse healthcare contexts. A primary application of our proposed method is to support physicians' decision making in patient screening scenarios. By guiding physicians toward incremental acquisition of the most informative features within budget constraints, our approach aims to increase diagnostic confidence while optimizing resource utilization.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "17 pages, 5 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.08646v1",
    "published_date": "2025-08-12 05:23:46 UTC",
    "updated_date": "2025-08-12 05:23:46 UTC"
  },
  {
    "arxiv_id": "2508.08641v1",
    "title": "MiGrATe: Mixed-Policy GRPO for Adaptation at Test-Time",
    "authors": [
      "Peter Phan",
      "Dhruv Agarwal",
      "Kavitha Srinivas",
      "Horst Samulowitz",
      "Pavan Kapanipathi",
      "Andrew McCallum"
    ],
    "abstract": "Large language models (LLMs) are increasingly being applied to black-box optimization tasks, from program synthesis to molecule design. Prior work typically leverages in-context learning to iteratively guide the model towards better solutions. Such methods, however, often struggle to balance exploration of new solution spaces with exploitation of high-reward ones. Recently, test-time training (TTT) with synthetic data has shown promise in improving solution quality. However, the need for hand-crafted training data tailored to each task limits feasibility and scalability across domains. To address this problem, we introduce MiGrATe-a method for online TTT that uses GRPO as a search algorithm to adapt LLMs at inference without requiring external training data. MiGrATe operates via a mixed-policy group construction procedure that combines on-policy sampling with two off-policy data selection techniques: greedy sampling, which selects top-performing past completions, and neighborhood sampling (NS), which generates completions structurally similar to high-reward ones. Together, these components bias the policy gradient towards exploitation of promising regions in solution space, while preserving exploration through on-policy sampling. We evaluate MiGrATe on three challenging domains-word search, molecule optimization, and hypothesis+program induction on the Abstraction and Reasoning Corpus (ARC)-and find that it consistently outperforms both inference-only and TTT baselines, demonstrating the potential of online TTT as a solution for complex search tasks without external supervision.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.08641v1",
    "published_date": "2025-08-12 05:08:21 UTC",
    "updated_date": "2025-08-12 05:08:21 UTC"
  },
  {
    "arxiv_id": "2508.08633v1",
    "title": "Diminution: On Reducing the Size of Grounding ASP Programs",
    "authors": [
      "HuanYu Yang",
      "Fengming Zhu",
      "YangFan Wu",
      "Jianmin Ji"
    ],
    "abstract": "Answer Set Programming (ASP) is often hindered by the grounding bottleneck: large Herbrand universes generate ground programs so large that solving becomes difficult. Many methods employ ad-hoc heuristics to improve grounding performance, motivating the need for a more formal and generalizable strategy. We introduce the notion of diminution, defined as a selected subset of the Herbrand universe used to generate a reduced ground program before solving. We give a formal definition of diminution, analyze its key properties, and study the complexity of identifying it. We use a specific encoding that enables off-the-shelf ASP solver to evaluate candidate subsets. Our approach integrates seamlessly with existing grounders via domain predicates. In extensive experiments on five benchmarks, applying diminutions selected by our strategy yields significant performance improvements, reducing grounding time by up to 70% on average and decreasing the size of grounding files by up to 85%. These results demonstrate that leveraging diminutions constitutes a robust and general-purpose approach for alleviating the grounding bottleneck in ASP.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.08633v1",
    "published_date": "2025-08-12 04:52:19 UTC",
    "updated_date": "2025-08-12 04:52:19 UTC"
  },
  {
    "arxiv_id": "2508.08632v1",
    "title": "AgriGPT: a Large Language Model Ecosystem for Agriculture",
    "authors": [
      "Bo Yang",
      "Yu Zhang",
      "Lanfei Feng",
      "Yunkui Chen",
      "Jianyu Zhang",
      "Xiao Xu",
      "Nueraili Aierken",
      "Yurui Li",
      "Yuxuan Chen",
      "Guijun Yang",
      "Yong He",
      "Runhe Huang",
      "Shijian Li"
    ],
    "abstract": "Despite the rapid progress of Large Language Models (LLMs), their application in agriculture remains limited due to the lack of domain-specific models, curated datasets, and robust evaluation frameworks. To address these challenges, we propose AgriGPT, a domain-specialized LLM ecosystem for agricultural usage. At its core, we design a multi-agent scalable data engine that systematically compiles credible data sources into Agri-342K, a high-quality, standardized question-answer (QA) dataset. Trained on this dataset, AgriGPT supports a broad range of agricultural stakeholders, from practitioners to policy-makers. To enhance factual grounding, we employ Tri-RAG, a three-channel Retrieval-Augmented Generation framework combining dense retrieval, sparse retrieval, and multi-hop knowledge graph reasoning, thereby improving the LLM's reasoning reliability. For comprehensive evaluation, we introduce AgriBench-13K, a benchmark suite comprising 13 tasks with varying types and complexities. Experiments demonstrate that AgriGPT significantly outperforms general-purpose LLMs on both domain adaptation and reasoning. Beyond the model itself, AgriGPT represents a modular and extensible LLM ecosystem for agriculture, comprising structured data construction, retrieval-enhanced generation, and domain-specific evaluation. This work provides a generalizable framework for developing scientific and industry-specialized LLMs. All models, datasets, and code will be released to empower agricultural communities, especially in underserved regions, and to promote open, impactful research.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.08632v1",
    "published_date": "2025-08-12 04:51:08 UTC",
    "updated_date": "2025-08-12 04:51:08 UTC"
  },
  {
    "arxiv_id": "2508.08629v1",
    "title": "Securing Educational LLMs: A Generalised Taxonomy of Attacks on LLMs and DREAD Risk Assessment",
    "authors": [
      "Farzana Zahid",
      "Anjalika Sewwandi",
      "Lee Brandon",
      "Vimal Kumar",
      "Roopak Sinha"
    ],
    "abstract": "Due to perceptions of efficiency and significant productivity gains, various organisations, including in education, are adopting Large Language Models (LLMs) into their workflows. Educator-facing, learner-facing, and institution-facing LLMs, collectively, Educational Large Language Models (eLLMs), complement and enhance the effectiveness of teaching, learning, and academic operations. However, their integration into an educational setting raises significant cybersecurity concerns. A comprehensive landscape of contemporary attacks on LLMs and their impact on the educational environment is missing. This study presents a generalised taxonomy of fifty attacks on LLMs, which are categorized as attacks targeting either models or their infrastructure. The severity of these attacks is evaluated in the educational sector using the DREAD risk assessment framework. Our risk assessment indicates that token smuggling, adversarial prompts, direct injection, and multi-step jailbreak are critical attacks on eLLMs. The proposed taxonomy, its application in the educational environment, and our risk assessment will help academic and industrial practitioners to build resilient solutions that protect learners and institutions.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.08629v1",
    "published_date": "2025-08-12 04:34:12 UTC",
    "updated_date": "2025-08-12 04:34:12 UTC"
  },
  {
    "arxiv_id": "2508.08627v1",
    "title": "QoE-Aware Service Provision for Mobile AR Rendering: An Agent-Driven Approach",
    "authors": [
      "Conghao Zhou",
      "Lulu Sun",
      "Xiucheng Wang",
      "Peng Yang",
      "Feng Lyu",
      "Sihan Lu",
      "Xuemin Shen"
    ],
    "abstract": "Mobile augmented reality (MAR) is envisioned as a key immersive application in 6G, enabling virtual content rendering aligned with the physical environment through device pose estimation. In this paper, we propose a novel agent-driven communication service provisioning approach for edge-assisted MAR, aiming to reduce communication overhead between MAR devices and the edge server while ensuring the quality of experience (QoE). First, to address the inaccessibility of MAR application-specific information to the network controller, we establish a digital agent powered by large language models (LLMs) on behalf of the MAR service provider, bridging the data and function gap between the MAR service and network domains. Second, to cope with the user-dependent and dynamic nature of data traffic patterns for individual devices, we develop a user-level QoE modeling method that captures the relationship between communication resource demands and perceived user QoE, enabling personalized, agent-driven communication resource management. Trace-driven simulation results demonstrate that the proposed approach outperforms conventional LLM-based QoE-aware service provisioning methods in both user-level QoE modeling accuracy and communication resource efficiency.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.08627v1",
    "published_date": "2025-08-12 04:32:04 UTC",
    "updated_date": "2025-08-12 04:32:04 UTC"
  },
  {
    "arxiv_id": "2508.15790v1",
    "title": "KG-o1: Enhancing Multi-hop Question Answering in Large Language Models via Knowledge Graph Integration",
    "authors": [
      "Nan Wang",
      "Yongqi Fan",
      "yansha zhu",
      "ZongYu Wang",
      "Xuezhi Cao",
      "Xinyan He",
      "Haiyun Jiang",
      "Tong Ruan",
      "Jingping Liu"
    ],
    "abstract": "Large Language Models (LLMs) face challenges in knowledge-intensive reasoning tasks like classic multi-hop question and answering, which involves reasoning across multiple facts. This difficulty arises because the chain of thoughts (CoTs) generated by LLMs in such tasks often deviate from real or a priori reasoning paths. In contrast, knowledge graphs (KGs) explicitly represent the logical connections between facts through entities and relationships. This reflects a significant gap. Meanwhile, large reasoning models (LRMs), such as o1, have demonstrated that long-step reasoning significantly enhances the performance of LLMs. Building on these insights, we propose KG-o1, a four-stage approach that integrates KGs to enhance the multi-hop reasoning abilities of LLMs. We first filter out initial entities and generate complex subgraphs. Secondly, we construct logical paths for subgraphs and then use knowledge graphs to build a dataset with a complex and extended brainstorming process, which trains LLMs to imitate long-term reasoning. Finally, we employ rejection sampling to generate a self-improving corpus for direct preference optimization (DPO), further refining the LLMs reasoning abilities. We conducted experiments on two simple and two complex datasets. The results show that KG-o1 models exhibit superior performance across all tasks compared to existing LRMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.15790v1",
    "published_date": "2025-08-12 04:29:10 UTC",
    "updated_date": "2025-08-12 04:29:10 UTC"
  },
  {
    "arxiv_id": "2508.08615v2",
    "title": "UGM2N: An Unsupervised and Generalizable Mesh Movement Network via M-Uniform Loss",
    "authors": [
      "Zhichao Wang",
      "Xinhai Chen",
      "Qinglin Wang",
      "Xiang Gao",
      "Qingyang Zhang",
      "Menghan Jia",
      "Xiang Zhang",
      "Jie Liu"
    ],
    "abstract": "Partial differential equations (PDEs) form the mathematical foundation for modeling physical systems in science and engineering, where numerical solutions demand rigorous accuracy-efficiency tradeoffs. Mesh movement techniques address this challenge by dynamically relocating mesh nodes to rapidly-varying regions, enhancing both simulation accuracy and computational efficiency. However, traditional approaches suffer from high computational complexity and geometric inflexibility, limiting their applicability, and existing supervised learning-based approaches face challenges in zero-shot generalization across diverse PDEs and mesh topologies.In this paper, we present an Unsupervised and Generalizable Mesh Movement Network (UGM2N). We first introduce unsupervised mesh adaptation through localized geometric feature learning, eliminating the dependency on pre-adapted meshes. We then develop a physics-constrained loss function, M-Uniform loss, that enforces mesh equidistribution at the nodal level.Experimental results demonstrate that the proposed network exhibits equation-agnostic generalization and geometric independence in efficient mesh adaptation. It demonstrates consistent superiority over existing methods, including robust performance across diverse PDEs and mesh geometries, scalability to multi-scale resolutions and guaranteed error reduction without mesh tangling.",
    "categories": [
      "cs.AI",
      "math.NA"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted as a Poster at NeurIPS 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.08615v2",
    "published_date": "2025-08-12 03:56:45 UTC",
    "updated_date": "2025-10-29 08:36:55 UTC"
  },
  {
    "arxiv_id": "2508.14070v2",
    "title": "Special-Character Adversarial Attacks on Open-Source Language Model",
    "authors": [
      "Ephraiem Sarabamoun"
    ],
    "abstract": "Large language models (LLMs) have achieved remarkable performance across diverse natural language processing tasks, yet their vulnerability to character-level adversarial manipulations presents significant security challenges for real-world deployments. This paper presents a study of different special character attacks including unicode, homoglyph, structural, and textual encoding attacks aimed at bypassing safety mechanisms. We evaluate seven prominent open-source models ranging from 3.8B to 32B parameters on 4,000+ attack attempts. These experiments reveal critical vulnerabilities across all model sizes, exposing failure modes that include successful jailbreaks, incoherent outputs, and unrelated hallucinations.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.14070v2",
    "published_date": "2025-08-12 03:42:59 UTC",
    "updated_date": "2025-11-25 23:27:47 UTC"
  },
  {
    "arxiv_id": "2508.08604v3",
    "title": "Transferable Model-agnostic Vision-Language Model Adaptation for Efficient Weak-to-Strong Generalization",
    "authors": [
      "Jihwan Park",
      "Taehoon Song",
      "Sanghyeok Lee",
      "Miso Choi",
      "Hyunwoo J. Kim"
    ],
    "abstract": "Vision-Language Models (VLMs) have been widely used in various visual recognition tasks due to their remarkable generalization capabilities. As these models grow in size and complexity, fine-tuning becomes costly, emphasizing the need to reuse adaptation knowledge from 'weaker' models to efficiently enhance 'stronger' ones. However, existing adaptation transfer methods exhibit limited transferability across models due to their model-specific design and high computational demands. To tackle this, we propose Transferable Model-agnostic adapter (TransMiter), a light-weight adapter that improves vision-language models 'without backpropagation'. TransMiter captures the knowledge gap between pre-trained and fine-tuned VLMs, in an 'unsupervised' manner. Once trained, this knowledge can be seamlessly transferred across different models without the need for backpropagation. Moreover, TransMiter consists of only a few layers, inducing a negligible additional inference cost. Notably, supplementing the process with a few labeled data further yields additional performance gain, often surpassing a fine-tuned stronger model, with a marginal training cost. Experimental results and analyses demonstrate that TransMiter effectively and efficiently transfers adaptation knowledge while preserving generalization abilities across VLMs of different sizes and architectures in visual recognition tasks.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "AAAI2026 Oral (camera ready version)",
    "pdf_url": "https://arxiv.org/pdf/2508.08604v3",
    "published_date": "2025-08-12 03:37:16 UTC",
    "updated_date": "2026-01-17 15:36:14 UTC"
  },
  {
    "arxiv_id": "2508.08601v3",
    "title": "Yan: Foundational Interactive Video Generation",
    "authors": [
      "Deheng Ye",
      "Fangyun Zhou",
      "Jiacheng Lv",
      "Jianqi Ma",
      "Jun Zhang",
      "Junyan Lv",
      "Junyou Li",
      "Minwen Deng",
      "Mingyu Yang",
      "Qiang Fu",
      "Wei Yang",
      "Wenkai Lv",
      "Yangbin Yu",
      "Yewen Wang",
      "Yonghang Guan",
      "Zhihao Hu",
      "Zhongbin Fang",
      "Zhongqian Sun"
    ],
    "abstract": "We present Yan, a foundational framework for interactive video generation, covering the entire pipeline from simulation and generation to editing. Specifically, Yan comprises three core modules. AAA-level Simulation: We design a highly-compressed, low-latency 3D-VAE coupled with a KV-cache-based shift-window denoising inference process, achieving real-time 1080P/60FPS interactive simulation. Multi-Modal Generation: We introduce a hierarchical autoregressive caption method that injects game-specific knowledge into open-domain multi-modal video diffusion models (VDMs), then transforming the VDM into a frame-wise, action-controllable, real-time infinite interactive video generator. Notably, when the textual and visual prompts are sourced from different domains, the model demonstrates strong generalization, allowing it to blend and compose the style and mechanics across domains flexibly according to user prompts. Multi-Granularity Editing: We propose a hybrid model that explicitly disentangles interactive mechanics simulation from visual rendering, enabling multi-granularity video content editing during interaction through text. Collectively, Yan offers an integration of these modules, pushing interactive video generation beyond isolated capabilities toward a comprehensive AI-driven interactive creation paradigm, paving the way for the next generation of creative tools, media, and entertainment. The project page is: https://greatx3.github.io/Yan/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.08601v3",
    "published_date": "2025-08-12 03:34:21 UTC",
    "updated_date": "2025-08-14 10:26:51 UTC"
  },
  {
    "arxiv_id": "2508.08593v1",
    "title": "Generative AI for Critical Infrastructure in Smart Grids: A Unified Framework for Synthetic Data Generation and Anomaly Detection",
    "authors": [
      "Aydin Zaboli",
      "Junho Hong"
    ],
    "abstract": "In digital substations, security events pose significant challenges to the sustained operation of power systems. To mitigate these challenges, the implementation of robust defense strategies is critically important. A thorough process of anomaly identification and detection in information and communication technology (ICT) frameworks is crucial to ensure secure and reliable communication and coordination between interconnected devices within digital substations. Hence, this paper addresses the critical cybersecurity challenges confronting IEC61850-based digital substations within modern smart grids, where the integration of advanced communication protocols, e.g., generic object-oriented substation event (GOOSE), has enhanced energy management and introduced significant vulnerabilities to cyberattacks. Focusing on the limitations of traditional anomaly detection systems (ADSs) in detecting threats, this research proposes a transformative approach by leveraging generative AI (GenAI) to develop robust ADSs. The primary contributions include the suggested advanced adversarial traffic mutation (AATM) technique to generate synthesized and balanced datasets for GOOSE messages, ensuring protocol compliance and enabling realistic zero-day attack pattern creation to address data scarcity. Then, the implementation of GenAI-based ADSs incorporating the task-oriented dialogue (ToD) processes has been explored for improved detection of attack patterns. Finally, a comparison of the GenAI-based ADS with machine learning (ML)-based ADSs has been implemented to showcase the outperformance of the GenAI-based frameworks considering the AATM-generated GOOSE datasets and standard/advanced performance evaluation metrics.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "28 pages, 12 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.08593v1",
    "published_date": "2025-08-12 03:18:05 UTC",
    "updated_date": "2025-08-12 03:18:05 UTC"
  },
  {
    "arxiv_id": "2508.08591v1",
    "title": "DepressLLM: Interpretable domain-adapted language model for depression detection from real-world narratives",
    "authors": [
      "Sehwan Moon",
      "Aram Lee",
      "Jeong Eun Kim",
      "Hee-Ju Kang",
      "Il-Seon Shin",
      "Sung-Wan Kim",
      "Jae-Min Kim",
      "Min Jhon",
      "Ju-Wan Kim"
    ],
    "abstract": "Advances in large language models (LLMs) have enabled a wide range of applications. However, depression prediction is hindered by the lack of large-scale, high-quality, and rigorously annotated datasets. This study introduces DepressLLM, trained and evaluated on a novel corpus of 3,699 autobiographical narratives reflecting both happiness and distress. DepressLLM provides interpretable depression predictions and, via its Score-guided Token Probability Summation (SToPS) module, delivers both improved classification performance and reliable confidence estimates, achieving an AUC of 0.789, which rises to 0.904 on samples with confidence $\\geq$ 0.95. To validate its robustness to heterogeneous data, we evaluated DepressLLM on in-house datasets, including an Ecological Momentary Assessment (EMA) corpus of daily stress and mood recordings, and on public clinical interview data. Finally, a psychiatric review of high-confidence misclassifications highlighted key model and data limitations that suggest directions for future refinements. These findings demonstrate that interpretable AI can enable earlier diagnosis of depression and underscore the promise of medical AI in psychiatry.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.08591v1",
    "published_date": "2025-08-12 03:12:55 UTC",
    "updated_date": "2025-08-12 03:12:55 UTC"
  },
  {
    "arxiv_id": "2508.10044v2",
    "title": "Large Language Models for Power System Security: A Novel Multi-Modal Approach for Anomaly Detection in Energy Management Systems",
    "authors": [
      "Aydin Zaboli",
      "Junho Hong",
      "Alexandru Stefanov",
      "Chen-Ching Liu",
      "Chul-Sang Hwang"
    ],
    "abstract": "This paper elaborates on an extensive security framework specifically designed for energy management systems (EMSs), which effectively tackles the dynamic environment of cybersecurity vulnerabilities and/or system problems (SPs), accomplished through the incorporation of novel methodologies. A comprehensive multi-point attack/error model is initially proposed to systematically identify vulnerabilities throughout the entire EMS data processing pipeline, including post state estimation (SE) stealth attacks, EMS database manipulation, and human-machine interface (HMI) display corruption according to the real-time database (RTDB) storage. This framework acknowledges the interconnected nature of modern attack vectors, which utilize various phases of supervisory control and data acquisition (SCADA) data flow. Then, generative AI (GenAI)-based anomaly detection systems (ADSs) for EMSs are proposed for the first time in the power system domain to handle the scenarios. Further, a set-of-mark generative intelligence (SoM-GI) framework, which leverages multimodal analysis by integrating visual markers with rules considering the GenAI capabilities, is suggested to overcome inherent spatial reasoning limitations. The SoM-GI methodology employs systematic visual indicators to enable accurate interpretation of segmented HMI displays and detect visual anomalies that numerical methods fail to identify. Validation on the IEEE 14-Bus system shows the framework's effectiveness across scenarios, while visual analysis identifies inconsistencies. This integrated approach combines numerical analysis with visual pattern recognition and linguistic rules to protect against cyber threats and system errors.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "10 Figures; 6 Tables; Accepted, IEEE ACCESS 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.10044v2",
    "published_date": "2025-08-12 03:10:22 UTC",
    "updated_date": "2025-11-29 20:47:24 UTC"
  },
  {
    "arxiv_id": "2508.20102v1",
    "title": "A Hierarchical Signal Coordination and Control System Using a Hybrid Model-based and Reinforcement Learning Approach",
    "authors": [
      "Xianyue Peng",
      "Shenyang Chen",
      "H. Michael Zhang"
    ],
    "abstract": "Signal control in urban corridors faces the dual challenge of maintaining arterial traffic progression while adapting to demand variations at local intersections. We propose a hierarchical traffic signal coordination and control scheme that integrates model-based optimization with reinforcement learning. The system consists of: (i) a High-Level Coordinator (HLC) that selects coordination strategies based on observed and predicted demand; (ii) a Corridor Coordinator that derives phase constraints from the selected strategy-either Max-Flow Coordination (MFC) or Green-Wave Coordination (GWC); and (iii) Hybrid Signal Agents (HSAs) that determine signal phases via reinforcement learning with action masking to enforce feasibility. Hierarchical reinforcement learning with Proximal Policy Optimization (PPO) is used to train HSA and HLC policies. At the lower level, three HSA policies-MFC-aware, GWC-aware, and pure agent control (PAC) are trained in conjunction with their respective coordination strategies. At the higher level, the HLC is trained to dynamically switch strategies using a multi-objective reward balancing corridor-level and network-wide performance. The proposed scheme was developed and evaluated on a SUMO-RLlib platform. Case results show that hybrid MFC maximizes throughput under heavy demand; hybrid GWC consistently minimizes arterial stops and maintains progression across diverse traffic conditions but can reduce network-wide efficiency; and PAC improves network-wide travel time in moderate demand but is less effective under heavy demand. The hierarchical design enables adaptive strategy selection, achieving robust performance across all demand levels.",
    "categories": [
      "eess.SY",
      "cs.AI"
    ],
    "primary_category": "eess.SY",
    "comment": "28 pages, 7 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.20102v1",
    "published_date": "2025-08-12 03:10:06 UTC",
    "updated_date": "2025-08-12 03:10:06 UTC"
  },
  {
    "arxiv_id": "2508.14905v1",
    "title": "Privacy Preserving Inference of Personalized Content for Out of Matrix Users",
    "authors": [
      "Michael Sun",
      "Tai Vu",
      "Andrew Wang"
    ],
    "abstract": "Recommender systems for niche and dynamic communities face persistent challenges from data sparsity, cold start users and items, and privacy constraints. Traditional collaborative filtering and content-based approaches underperform in these settings, either requiring invasive user data or failing when preference histories are absent. We present DeepNaniNet, a deep neural recommendation framework that addresses these challenges through an inductive graph-based architecture combining user-item interactions, item-item relations, and rich textual review embeddings derived from BERT. Our design enables cold start recommendations without profile mining, using a novel \"content basket\" user representation and an autoencoder-based generalization strategy for unseen users. We introduce AnimeULike, a new dataset of 10,000 anime titles and 13,000 users, to evaluate performance in realistic scenarios with high proportions of guest or low-activity users. DeepNaniNet achieves state-of-the-art cold start results on the CiteULike benchmark, matches DropoutNet in user recall without performance degradation for out-of-matrix users, and outperforms Weighted Matrix Factorization (WMF) and DropoutNet on AnimeULike warm start by up to 7x and 1.5x in Recall@100, respectively. Our findings demonstrate that DeepNaniNet delivers high-quality, privacy-preserving recommendations in data-sparse, cold start-heavy environments while effectively integrating heterogeneous content sources.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.14905v1",
    "published_date": "2025-08-12 02:55:29 UTC",
    "updated_date": "2025-08-12 02:55:29 UTC"
  },
  {
    "arxiv_id": "2508.08583v1",
    "title": "AI Security Map: Holistic Organization of AI Security Technologies and Impacts on Stakeholders",
    "authors": [
      "Hiroya Kato",
      "Kentaro Kita",
      "Kento Hasegawa",
      "Seira Hidano"
    ],
    "abstract": "As the social implementation of AI has been steadily progressing, research and development related to AI security has also been increasing. However, existing studies have been limited to organizing related techniques, attacks, defenses, and risks in terms of specific domains or AI elements. Thus, it extremely difficult to understand the relationships among them and how negative impacts on stakeholders are brought about. In this paper, we argue that the knowledge, technologies, and social impacts related to AI security should be holistically organized to help understand relationships among them. To this end, we first develop an AI security map that holistically organizes interrelationships among elements related to AI security as well as negative impacts on information systems and stakeholders. This map consists of the two aspects, namely the information system aspect (ISA) and the external influence aspect (EIA). The elements that AI should fulfill within information systems are classified under the ISA. The EIA includes elements that affect stakeholders as a result of AI being attacked or misused. For each element, corresponding negative impacts are identified. By referring to the AI security map, one can understand the potential negative impacts, along with their causes and countermeasures. Additionally, our map helps clarify how the negative impacts on AI-based systems relate to those on stakeholders. We show some findings newly obtained by referring to our map. We also provide several recommendations and open problems to guide future AI security communities.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.08583v1",
    "published_date": "2025-08-12 02:41:20 UTC",
    "updated_date": "2025-08-12 02:41:20 UTC"
  },
  {
    "arxiv_id": "2508.14904v3",
    "title": "Efficient Switchable Safety Control in LLMs via Magic-Token-Guided Co-Training",
    "authors": [
      "Jianfeng Si",
      "Lin Sun",
      "Zhewen Tan",
      "Xiangzheng Zhang"
    ],
    "abstract": "Current methods for content safety in Large Language Models (LLMs), such as Supervised Fine-Tuning (SFT) and Reinforcement Learning from Human Feedback (RLHF), often rely on multi-stage training pipelines and lack fine-grained, post-deployment controllability. To address these limitations, we propose a unified co-training framework that efficiently integrates multiple safety behaviors: positive (lawful/prosocial), negative (unfiltered/risk-prone) and rejective (refusal-oriented/conservative) within a single SFT stage. Notably, each behavior is dynamically activated via a simple system-level instruction, or magic token, enabling stealthy and efficient behavioral switching at inference time. This flexibility supports diverse deployment scenarios, such as positive for safe user interaction, negative for internal red-teaming, and rejective for context-aware refusals triggered by upstream moderation signals. This co-training strategy induces a distinct Safety Alignment Margin in the output space, characterized by well-separated response distributions corresponding to each safety mode. The existence of this margin provides empirical evidence for the model's safety robustness and enables unprecedented fine-grained control. Experiments show that our method matches the safety alignment quality of SFT+DPO, with our 8B model notably surpassing DeepSeek-R1 (671B) in safety performance, while significantly reducing both training complexity and deployment costs. This work presents a scalable, efficient, and highly controllable solution for LLM content safety.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "15 pages,3 figures,5 tables",
    "pdf_url": "https://arxiv.org/pdf/2508.14904v3",
    "published_date": "2025-08-12 02:39:33 UTC",
    "updated_date": "2026-01-20 13:15:53 UTC"
  },
  {
    "arxiv_id": "2508.08573v2",
    "title": "Who Pays the RENT? Implications of Spatial Inequality for Prediction-Based Allocation Policies",
    "authors": [
      "Tasfia Mashiat",
      "Patrick J. Fowler",
      "Sanmay Das"
    ],
    "abstract": "AI-powered scarce resource allocation policies rely on predictions to target either specific individuals (e.g., high-risk) or settings (e.g., neighborhoods). Recent research on individual-level targeting demonstrates conflicting results; some models show that targeting is not useful when inequality is high, while other work demonstrates potential benefits. To study and reconcile this apparent discrepancy, we develop a stylized framework based on the Mallows model to understand how the spatial distribution of inequality affects the effectiveness of door-to-door outreach policies. We introduce the RENT (Relative Efficiency of Non-Targeting) metric, which we use to assess the effectiveness of targeting approaches compared with neighborhood-based approaches in preventing tenant eviction when high-risk households are more versus less spatially concentrated. We then calibrate the model parameters to eviction court records collected in a medium-sized city in the USA. Results demonstrate considerable gains in the number of high-risk households canvassed through individually targeted policies, even in a highly segregated metro area with concentrated risks of eviction. We conclude that apparent discrepancies in the prior literature can be reconciled by considering 1) the source of deployment costs and 2) the observed versus modeled concentrations of risk. Our results inform the deployment of AI-based solutions in social service provision that account for particular applications and geographies.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "This work has been accepted for publication as a full paper at the AAAI/ACM Conference on AI, Ethics, and Society (AIES 2025)",
    "pdf_url": "https://arxiv.org/pdf/2508.08573v2",
    "published_date": "2025-08-12 02:16:50 UTC",
    "updated_date": "2025-08-17 03:49:32 UTC"
  },
  {
    "arxiv_id": "2508.08570v1",
    "title": "Superclass-Guided Representation Disentanglement for Spurious Correlation Mitigation",
    "authors": [
      "Chenruo Liu",
      "Hongjun Liu",
      "Zeyu Lai",
      "Yiqiu Shen",
      "Chen Zhao",
      "Qi Lei"
    ],
    "abstract": "To enhance group robustness to spurious correlations, prior work often relies on auxiliary annotations for groups or spurious features and assumes identical sets of groups across source and target domains. These two requirements are both unnatural and impractical in real-world settings. To overcome these limitations, we propose a method that leverages the semantic structure inherent in class labels--specifically, superclass information--to naturally reduce reliance on spurious features. Our model employs gradient-based attention guided by a pre-trained vision-language model to disentangle superclass-relevant and irrelevant features. Then, by promoting the use of all superclass-relevant features for prediction, our approach achieves robustness to more complex spurious correlations without the need to annotate any source samples. Experiments across diverse datasets demonstrate that our method significantly outperforms baselines in domain generalization tasks, with clear improvements in both quantitative metrics and qualitative visualizations.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.08570v1",
    "published_date": "2025-08-12 02:16:04 UTC",
    "updated_date": "2025-08-12 02:16:04 UTC"
  },
  {
    "arxiv_id": "2508.08551v2",
    "title": "UQGNN: Uncertainty Quantification of Graph Neural Networks for Multivariate Spatiotemporal Prediction",
    "authors": [
      "Dahai Yu",
      "Dingyi Zhuang",
      "Lin Jiang",
      "Rongchao Xu",
      "Xinyue Ye",
      "Yuheng Bu",
      "Shenhao Wang",
      "Guang Wang"
    ],
    "abstract": "Spatiotemporal prediction plays a critical role in numerous real-world applications such as urban planning, transportation optimization, disaster response, and pandemic control. In recent years, researchers have made significant progress by developing advanced deep learning models for spatiotemporal prediction. However, most existing models are deterministic, i.e., predicting only the expected mean values without quantifying uncertainty, leading to potentially unreliable and inaccurate outcomes. While recent studies have introduced probabilistic models to quantify uncertainty, they typically focus on a single phenomenon (e.g., taxi, bike, crime, or traffic crashes), thereby neglecting the inherent correlations among heterogeneous urban phenomena. To address the research gap, we propose a novel Graph Neural Network with Uncertainty Quantification, termed UQGNN for multivariate spatiotemporal prediction. UQGNN introduces two key innovations: (i) an Interaction-aware Spatiotemporal Embedding Module that integrates a multivariate diffusion graph convolutional network and an interaction-aware temporal convolutional network to effectively capture complex spatial and temporal interaction patterns, and (ii) a multivariate probabilistic prediction module designed to estimate both expected mean values and associated uncertainties. Extensive experiments on four real-world multivariate spatiotemporal datasets from Shenzhen, New York City, and Chicago demonstrate that UQGNN consistently outperforms state-of-the-art baselines in both prediction accuracy and uncertainty quantification. For example, on the Shenzhen dataset, UQGNN achieves a 5% improvement in both prediction accuracy and uncertainty quantification.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 7 figures, SIGSPATIAL 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.08551v2",
    "published_date": "2025-08-12 01:40:05 UTC",
    "updated_date": "2025-08-31 14:18:22 UTC"
  },
  {
    "arxiv_id": "2508.19254v1",
    "title": "Real-Time Intuitive AI Drawing System for Collaboration: Enhancing Human Creativity through Formal and Contextual Intent Integration",
    "authors": [
      "Jookyung Song",
      "Mookyoung Kang",
      "Nojun Kwak"
    ],
    "abstract": "This paper presents a real-time generative drawing system that interprets and integrates both formal intent - the structural, compositional, and stylistic attributes of a sketch - and contextual intent - the semantic and thematic meaning inferred from its visual content - into a unified transformation process. Unlike conventional text-prompt-based generative systems, which primarily capture high-level contextual descriptions, our approach simultaneously analyzes ground-level intuitive geometric features such as line trajectories, proportions, and spatial arrangement, and high-level semantic cues extracted via vision-language models. These dual intent signals are jointly conditioned in a multi-stage generation pipeline that combines contour-preserving structural control with style- and content-aware image synthesis. Implemented with a touchscreen-based interface and distributed inference architecture, the system achieves low-latency, two-stage transformation while supporting multi-user collaboration on shared canvases. The resulting platform enables participants, regardless of artistic expertise, to engage in synchronous, co-authored visual creation, redefining human-AI interaction as a process of co-creation and mutual enhancement.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CV",
    "comment": "6 pages, 4 figures, NeurIPS Creative AI Track 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.19254v1",
    "published_date": "2025-08-12 01:34:23 UTC",
    "updated_date": "2025-08-12 01:34:23 UTC"
  },
  {
    "arxiv_id": "2508.08545v1",
    "title": "OmniLLP: Enhancing LLM-based Log Level Prediction with Context-Aware Retrieval",
    "authors": [
      "Youssef Esseddiq Ouatiti",
      "Mohammed Sayagh",
      "Bram Adams",
      "Ahmed E. Hassan"
    ],
    "abstract": "Developers insert logging statements in source code to capture relevant runtime information essential for maintenance and debugging activities. Log level choice is an integral, yet tricky part of the logging activity as it controls log verbosity and therefore influences systems' observability and performance. Recent advances in ML-based log level prediction have leveraged large language models (LLMs) to propose log level predictors (LLPs) that demonstrated promising performance improvements (AUC between 0.64 and 0.8). Nevertheless, current LLM-based LLPs rely on randomly selected in-context examples, overlooking the structure and the diverse logging practices within modern software projects. In this paper, we propose OmniLLP, a novel LLP enhancement framework that clusters source files based on (1) semantic similarity reflecting the code's functional purpose, and (2) developer ownership cohesion. By retrieving in-context learning examples exclusively from these semantic and ownership aware clusters, we aim to provide more coherent prompts to LLPs leveraging LLMs, thereby improving their predictive accuracy. Our results show that both semantic and ownership-aware clusterings statistically significantly improve the accuracy (by up to 8\\% AUC) of the evaluated LLM-based LLPs compared to random predictors (i.e., leveraging randomly selected in-context examples from the whole project). Additionally, our approach that combines the semantic and ownership signal for in-context prediction achieves an impressive 0.88 to 0.96 AUC across our evaluated projects. Our findings highlight the value of integrating software engineering-specific context, such as code semantic and developer ownership signals into LLM-LLPs, offering developers a more accurate, contextually-aware approach to logging and therefore, enhancing system maintainability and observability.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.08545v1",
    "published_date": "2025-08-12 01:18:56 UTC",
    "updated_date": "2025-08-12 01:18:56 UTC"
  },
  {
    "arxiv_id": "2508.08544v1",
    "title": "AI Agents and the Law",
    "authors": [
      "Mark O. Riedl",
      "Deven R. Desai"
    ],
    "abstract": "As AI becomes more \"agentic,\" it faces technical and socio-legal issues it must address if it is to fulfill its promise of increased economic productivity and efficiency. This paper uses technical and legal perspectives to explain how things change when AI systems start being able to directly execute tasks on behalf of a user. We show how technical conceptions of agents track some, but not all, socio-legal conceptions of agency. That is, both computer science and the law recognize the problems of under-specification for an agent, and both disciplines have robust conceptions of how to address ensuring an agent does what the programmer, or in the law, the principal desires and no more. However, to date, computer science has under-theorized issues related to questions of loyalty and to third parties that interact with an agent, both of which are central parts of the law of agency. First, we examine the correlations between implied authority in agency law and the principle of value-alignment in AI, wherein AI systems must operate under imperfect objective specification. Second, we reveal gaps in the current computer science view of agents pertaining to the legal concepts of disclosure and loyalty, and how failure to account for them can result in unintended effects in AI ecommerce agents. In surfacing these gaps, we show a path forward for responsible AI agent development and deployment.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "2025 AAAI Conference on AI, Ethics, and Society",
    "pdf_url": "https://arxiv.org/pdf/2508.08544v1",
    "published_date": "2025-08-12 01:18:48 UTC",
    "updated_date": "2025-08-12 01:18:48 UTC"
  },
  {
    "arxiv_id": "2508.08543v3",
    "title": "M3-Net: A Cost-Effective Graph-Free MLP-Based Model for Traffic Prediction",
    "authors": [
      "Guangyin Jin",
      "Sicong Lai",
      "Xiaoshuai Hao",
      "Mingtao Zhang",
      "Jinlei Zhang"
    ],
    "abstract": "Achieving accurate traffic prediction is a fundamental but crucial task in the development of current intelligent transportation systems.Most of the mainstream methods that have made breakthroughs in traffic prediction rely on spatio-temporal graph neural networks, spatio-temporal attention mechanisms, etc. The main challenges of the existing deep learning approaches are that they either depend on a complete traffic network structure or require intricate model designs to capture complex spatio-temporal dependencies. These limitations pose significant challenges for the efficient deployment and operation of deep learning models on large-scale datasets. To address these challenges, we propose a cost-effective graph-free Multilayer Perceptron (MLP) based model M3-Net for traffic prediction. Our proposed model not only employs time series and spatio-temporal embeddings for efficient feature processing but also first introduces a novel MLP-Mixer architecture with a mixture of experts (MoE) mechanism. Extensive experiments conducted on multiple real datasets demonstrate the superiority of the proposed model in terms of prediction performance and lightweight deployment.Our code is available at https://github.com/jinguangyin/M3_NET",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.08543v3",
    "published_date": "2025-08-12 01:11:46 UTC",
    "updated_date": "2025-11-12 04:18:22 UTC"
  },
  {
    "arxiv_id": "2508.08535v2",
    "title": "LLM-Driven Adaptive 6G-Ready Wireless Body Area Networks: Survey and Framework",
    "authors": [
      "Mohammad Jalili Torkamani",
      "Negin Mahmoudi",
      "Kiana Kiashemshaki"
    ],
    "abstract": "Wireless Body Area Networks (WBANs) enable continuous monitoring of physiological signals for applications ranging from chronic disease management to emergency response. Recent advances in 6G communications, post-quantum cryptography, and energy harvesting have the potential to enhance WBAN performance. However, integrating these technologies into a unified, adaptive system remains a challenge. This paper surveys some of the most well-known Wireless Body Area Network (WBAN) architectures, routing strategies, and security mechanisms, identifying key gaps in adaptability, energy efficiency, and quantum-resistant security. We propose a novel Large Language Model-driven adaptive WBAN framework in which a Large Language Model acts as a cognitive control plane, coordinating routing, physical layer selection, micro-energy harvesting, and post-quantum security in real time. Our review highlights the limitations of current heuristic-based designs and outlines a research agenda for resource-constrained, 6G-ready medical systems. This approach aims to enable ultra-reliable, secure, and self-optimizing WBANs for next-generation mobile health applications.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "7 pages",
    "pdf_url": "https://arxiv.org/pdf/2508.08535v2",
    "published_date": "2025-08-12 00:25:41 UTC",
    "updated_date": "2025-08-14 02:38:22 UTC"
  },
  {
    "arxiv_id": "2508.09224v1",
    "title": "From Hard Refusals to Safe-Completions: Toward Output-Centric Safety Training",
    "authors": [
      "Yuan Yuan",
      "Tina Sriskandarajah",
      "Anna-Luisa Brakman",
      "Alec Helyar",
      "Alex Beutel",
      "Andrea Vallone",
      "Saachi Jain"
    ],
    "abstract": "Large Language Models used in ChatGPT have traditionally been trained to learn a refusal boundary: depending on the user's intent, the model is taught to either fully comply or outright refuse. While this is a strong mitigation for explicitly malicious prompts, focusing safety training on refusals can lead to brittleness for prompts with obscured user intent. Binary refusal boundaries are especially ill-suited for dual-use cases (such as biology or cybersecurity), where a user request can be answered safely at a high level, but in some cases can lead to malicious uplift if sufficiently detailed or actionable. As an alternative, we propose safe-completions: a safety-training approach that centers on the safety of the assistant's output, rather than a binary classification of the user's intent. Safe-completions seek to maximize helpfulness within the safety policy's constraints. We incorporated this approach into GPT-5 and find that across both production comparisons and internally controlled experiments, safe-completion training improves safety (especially on dual-use prompts), reduces the severity of residual safety failures, and substantially increases model helpfulness.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.09224v1",
    "published_date": "2025-08-12 00:18:23 UTC",
    "updated_date": "2025-08-12 00:18:23 UTC"
  },
  {
    "arxiv_id": "2508.10043v1",
    "title": "Securing Agentic AI: Threat Modeling and Risk Analysis for Network Monitoring Agentic AI System",
    "authors": [
      "Pallavi Zambare",
      "Venkata Nikhil Thanikella",
      "Ying Liu"
    ],
    "abstract": "When combining Large Language Models (LLMs) with autonomous agents, used in network monitoring and decision-making systems, this will create serious security issues. In this research, the MAESTRO framework consisting of the seven layers threat modeling architecture in the system was used to expose, evaluate, and eliminate vulnerabilities of agentic AI. The prototype agent system was constructed and implemented, using Python, LangChain, and telemetry in WebSockets, and deployed with inference, memory, parameter tuning, and anomaly detection modules. Two practical threat cases were confirmed as follows: (i) resource denial of service by traffic replay denial-of-service, and (ii) memory poisoning by tampering with the historical log file maintained by the agent. These situations resulted in measurable levels of performance degradation, i.e. telemetry updates were delayed, and computational loads were increased, as a result of poor system adaptations. It was suggested to use a multilayered defense-in-depth approach with memory isolation, validation of planners and anomaly response systems in real-time. These findings verify that MAESTRO is viable in operational threat mapping, prospective risk scoring, and the basis of the resilient system design. The authors bring attention to the importance of the enforcement of memory integrity, paying attention to the adaptation logic monitoring, and cross-layer communication protection that guarantee the agentic AI reliability in adversarial settings.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Submitted and under review in IEEE Transactions on Privacy",
    "pdf_url": "https://arxiv.org/pdf/2508.10043v1",
    "published_date": "2025-08-12 00:14:12 UTC",
    "updated_date": "2025-08-12 00:14:12 UTC"
  }
]