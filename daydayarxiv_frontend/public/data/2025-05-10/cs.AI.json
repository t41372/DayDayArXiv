{
  "date": "2025-05-10",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-05-10 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 更新了 45 篇论文，主要聚焦 AI 在多模态生成、强化学习、机器人控制和医疗应用等领域的创新进展，其中 Thomas L. Griffiths 关于从大型语言模型嵌入中恢复事件概率的论文，以及 Gabriel Peyré 的优化传输理论研究，令人印象深刻；此外，多篇机器人和医疗 AI 论文强调实际应用和可解释性，展示了 AI 向现实场景转化的潜力。\n\n下面，我将挑选重点论文进行简要讨论，先优先聊那些创新性强、可能引发话题的文章（如有著名学者或实际影响的），并将相关主题归类快速概述。其他较基础或理论性较弱的论文（如一些纯数学模型或重复性工作），我将简略掠过。\n\n### 多模态生成与模型鲁棒性\n- **Multi-modal Synthetic Data Training and Model Collapse: Insights from VLMs and Diffusion Models（多模态合成数据训练与模型崩溃：从视觉语言模型和扩散模型的洞见）**  \n  这篇论文探讨了在多模态系统中（如视觉语言模型和扩散模型）使用合成数据训练时可能发生的模型崩溃问题。核心贡献是通过实验发现模型崩溃在多模态场景下表现出独特特征（如更好的视觉语言对齐），并提出方法（如增加解码预算和模型多样性）来缓解崩溃，为自提升多代理 AI 系统提供实用指导。令人印象深刻的是，它扩展了单模态研究的边界，作者包括 Mohammad Rostami 和 Jesse Thomason 等知名学者。\n\n- **Symbolic Rule Extraction from Attention-Guided Sparse Representations in Vision Transformers（从注意力引导的稀疏表示中提取符号规则的 Vision Transformers）**  \n  作者 Parth Padalkar 和 Gopal Gupta 提出了一种框架，使用稀疏自动编码器在 Vision Transformers 中提取符号规则。关键发现是，该方法提高了分类准确性（比标准 ViT 高 5.14%），并生成可执行的逻辑程序，提升了 AI 的可解释性和验证性。这篇论文在神经符号 AI 领域有话题潜力。\n\n- **Recovering Event Probabilities from Large Language Model Embeddings via Axiomatic Constraints（通过公理约束从大型语言模型嵌入中恢复事件概率）**  \n  Thomas L. Griffiths 等学者的工作聚焦于修复大型语言模型的概率不一致问题。贡献包括使用变分自动编码器强制公理约束，实验显示恢复的概率更符合真实分布。该论文为不确定性决策提供理论洞见，具有广泛影响。\n\n### 机器人与轨迹预测\n- **TPK: Trustworthy Trajectory Prediction Integrating Prior Knowledge For Interpretability and Kinematic Feasibility（TPK：整合先验知识的可靠轨迹预测，用于可解释性和运动学可行性）**  \n  这篇论文（作者包括 J. Marius Zöllner）针对自动驾驶提出了一种方法，结合车辆、行人和骑行者的交互和运动学模型。核心发现是提高了轨迹预测的可解释性和物理可行性，在 Argoverse 2 数据集上表现优于基准模型。该工作已被 IV 2025 会议接受，强调实际应用价值。\n\n- **Boundary-Guided Trajectory Prediction for Road Aware and Physically Feasible Autonomous Driving（边界引导的轨迹预测，用于道路感知和物理可行自动驾驶）**  \n  作者 Ahmed Abouelazm 等构建了一个框架，通过边界引导和加速度预测确保轨迹的道路适应性和可行性。发现显示，在 Argoverse-2 数据集上，该方法减少了不可行轨迹，并提升了鲁棒性。该论文也来自 IV 2025，相关主题与上一篇相近，展示了自动驾驶领域的进展。\n\n- **JAEGER: Dual-Level Humanoid Whole-Body Controller（JAEGER：双层人形机器人全身控制器）**  \n  作者 Ziluo Ding 等提出了一种双层控制器，分离上、下身控制以提高鲁棒性和适应性。贡献包括支持速度和关节角度跟踪，并在模拟和真实环境中超越现有方法。该论文在机器人控制领域有创新性。\n\n### 强化学习与决策优化\n- **Value Iteration with Guessing for Markov Chains and Markov Decision Processes（Markov 链和 Markov 决策过程的猜测值迭代）**  \n  Krishnendu Chatterjee 等学者的工作引入了基于猜测的值迭代算法。核心发现是，通过预处理，实现子指数级 Bellman 更新，显著提高了计算效率。该论文来自 TACAS 2025，理论贡献强，对规划问题有实际启发。\n\n- **Bi-level Mean Field: Dynamic Grouping for Large-Scale MARL（双层均值场：用于大规模多代理强化学习的动态分组）**  \n  作者 Yuxuan Zheng 等提出 BMF 方法，通过变分自动编码器实现动态代理分组，缓解大规模 MARL 中的维数灾难。实验显示性能优于最先进方法，适合复杂多代理场景。\n\n- **Model Steering: Learning with a Reference Model Improves Generalization Bounds and Scaling Laws（模型引导：使用参考模型改善泛化边界和缩放定律）**  \n  Tianbao Yang 等的工作形式化了模型引导范式，通过分布鲁棒优化提升数据效率。贡献包括理论证明和实验验证（如在 CLIP 上改进缩放定律），为 AI 训练提供新视角。\n\n### 医疗 AI 与可解释性\n- **Deeply Explainable Artificial Neural Network（深度可解释人工神经网络）**  \n  作者 David Zucker 设计了 DxANN 架构，将可解释性嵌入训练过程。关键发现是，它在医疗图像任务中提供实时解释，避免了后处理方法的开销，提升了 AI 在关键领域的可信度。\n\n- **Integrating Explainable AI in Medical Devices: Technical, Clinical and Regulatory Insights and Recommendations（将可解释 AI 整合到医疗设备中：技术、临床和监管洞见及建议）**  \n  这篇论文由 Allan Tucker 等专家合作，提供框架以确保 AI 设备符合 EU AI Act。贡献包括建议和实验，强调可解释 AI 在医疗中的安全性和可持续性，具有政策影响。\n\n其他论文，如那些聚焦基础理论（如 Optimal Transport for Machine Learners）或特定应用（如 Underwater object detection），我将快速掠过：它们提供了技术细节，但影响力较小。例如，**Optimal Transport for Machine Learners（机器学习中的最优传输）** 由 Gabriel Peyré 概述了优化传输在 AI 中的应用，适合理论研究者。\n\n总之，今天的论文突显 AI 向实用性和可解释性转型，值得关注领域包括多模态鲁棒性和医疗应用。如果你对特定主题感兴趣，建议查看这些论文的摘要以获取更多细节。明天的快报见！",
  "papers": [
    {
      "arxiv_id": "2505.08803v1",
      "title": "Multi-modal Synthetic Data Training and Model Collapse: Insights from VLMs and Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zizhao Hu",
        "Mohammad Rostami",
        "Jesse Thomason"
      ],
      "abstract": "Recent research has highlighted the risk of generative model collapse, where\nperformance progressively degrades when continually trained on self-generated\ndata. However, existing exploration on model collapse is limited to single,\nunimodal models, limiting our understanding in more realistic scenarios, such\nas diverse multi-modal AI agents interacting autonomously through synthetic\ndata and continually evolving. We expand the synthetic data training and model\ncollapse study to multi-modal vision-language generative systems, such as\nvision-language models (VLMs) and text-to-image diffusion models, as well as\nrecursive generate-train loops with multiple models. We find that model\ncollapse, previously observed in single-modality generative models, exhibits\ndistinct characteristics in the multi-modal context, such as improved\nvision-language alignment and increased variance in VLM image-captioning task.\nAdditionally, we find that general approaches such as increased decoding\nbudgets, greater model diversity, and relabeling with frozen models can\neffectively mitigate model collapse. Our findings provide initial insights and\npractical guidelines for reducing the risk of model collapse in self-improving\nmulti-agent AI systems and curating robust multi-modal synthetic datasets.",
      "tldr_zh": "本文研究扩展了模型崩溃（Model Collapse）的探索，聚焦于多模态生成系统，如视觉语言模型（VLMs）和文本到图像扩散模型（Diffusion Models），以及多个模型的递归生成-训练循环。研究发现，在多模态环境中，模型崩溃表现出独特特征，包括改进的视觉语言对齐和VLMs图像标题任务中的变异性增加。作者提出有效缓解策略，如增加解码预算、提升模型多样性和使用冻结模型重新标记。这些发现为减少自提升多代理AI系统中的模型崩溃风险，并构建稳健的多模态合成数据集提供了实用指导。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08803v1",
      "published_date": "2025-05-10 22:42:29 UTC",
      "updated_date": "2025-05-10 22:42:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:30:37.390026"
    },
    {
      "arxiv_id": "2505.06769v1",
      "title": "Value Iteration with Guessing for Markov Chains and Markov Decision Processes",
      "title_zh": "翻译失败",
      "authors": [
        "Krishnendu Chatterjee",
        "Mahdi JafariRaviz",
        "Raimundo Saona",
        "Jakub Svoboda"
      ],
      "abstract": "Two standard models for probabilistic systems are Markov chains (MCs) and\nMarkov decision processes (MDPs). Classic objectives for such probabilistic\nmodels for control and planning problems are reachability and stochastic\nshortest path. The widely studied algorithmic approach for these problems is\nthe Value Iteration (VI) algorithm which iteratively applies local updates\ncalled Bellman updates. There are many practical approaches for VI in the\nliterature but they all require exponentially many Bellman updates for MCs in\nthe worst case. A preprocessing step is an algorithm that is discrete,\ngraph-theoretical, and requires linear space. An important open question is\nwhether, after a polynomial-time preprocessing, VI can be achieved with\nsub-exponentially many Bellman updates. In this work, we present a new approach\nfor VI based on guessing values. Our theoretical contributions are twofold.\nFirst, for MCs, we present an almost-linear-time preprocessing algorithm after\nwhich, along with guessing values, VI requires only subexponentially many\nBellman updates. Second, we present an improved analysis of the speed of\nconvergence of VI for MDPs. Finally, we present a practical algorithm for MDPs\nbased on our new approach. Experimental results show that our approach provides\na considerable improvement over existing VI-based approaches on several\nbenchmark examples from the literature.",
      "tldr_zh": "这篇论文针对Markov chains (MCs) 和Markov decision processes (MDPs) 的经典问题，如reachability 和stochastic shortest path，提出了一种基于guessing values 的Value Iteration (VI) 新方法，以减少所需的Bellman updates。论文的主要贡献包括：为MCs 设计了一个几乎线性时间的预处理算法，结合guessing values 使VI 只需次指数级的更新；并对MDPs 的VI 收敛速度进行了改进分析，同时开发了一个实用算法。实验结果显示，该方法在多个基准示例上显著优于现有VI 算法，提供更高效的解决方案。",
      "categories": [
        "cs.AI",
        "cs.CC"
      ],
      "primary_category": "cs.AI",
      "comment": "Appeared in the 31st International Conference on Tools and Algorithms\n  for the Construction and Analysis of Systems (TACAS 2025)",
      "pdf_url": "http://arxiv.org/pdf/2505.06769v1",
      "published_date": "2025-05-10 22:24:49 UTC",
      "updated_date": "2025-05-10 22:24:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:30:50.866127"
    },
    {
      "arxiv_id": "2505.06745v1",
      "title": "Symbolic Rule Extraction from Attention-Guided Sparse Representations in Vision Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Parth Padalkar",
        "Gopal Gupta"
      ],
      "abstract": "Recent neuro-symbolic approaches have successfully extracted symbolic\nrule-sets from CNN-based models to enhance interpretability. However, applying\nsimilar techniques to Vision Transformers (ViTs) remains challenging due to\ntheir lack of modular concept detectors and reliance on global self-attention\nmechanisms. We propose a framework for symbolic rule extraction from ViTs by\nintroducing a sparse concept layer inspired by Sparse Autoencoders (SAEs). This\nlinear layer operates on attention-weighted patch representations and learns a\ndisentangled, binarized representation in which individual neurons activate for\nhigh-level visual concepts. To encourage interpretability, we apply a\ncombination of L1 sparsity, entropy minimization, and supervised contrastive\nloss. These binarized concept activations are used as input to the FOLD-SE-M\nalgorithm, which generates a rule-set in the form of logic programs. Our method\nachieves a 5.14% better classification accuracy than the standard ViT while\nenabling symbolic reasoning. Crucially, the extracted rule-set is not merely\npost-hoc but acts as a logic-based decision layer that operates directly on the\nsparse concept representations. The resulting programs are concise and\nsemantically meaningful. This work is the first to extract executable logic\nprograms from ViTs using sparse symbolic representations. It bridges the gap\nbetween transformer-based vision models and symbolic logic programming,\nproviding a step forward in interpretable and verifiable neuro-symbolic AI.",
      "tldr_zh": "本研究提出了一种从 Vision Transformers (ViTs) 中提取符号规则的框架，以提升模型的可解释性。该框架引入受 Sparse Autoencoders (SAEs) 启发的稀疏概念层，作用于注意力加权的 patch 表示，通过 L1 稀疏性、熵最小化和监督对比损失学习解耦的二值化概念激活。提取的规则集由 FOLD-SE-M 算法生成，作为逻辑-based 决策层直接应用于稀疏表示，实现比标准 ViT 高 5.14% 的分类准确率，并支持符号推理。该方法首次桥接了 transformer-based 视觉模型与符号逻辑编程的差距，促进可解释和可验证的神经符号 AI。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06745v1",
      "published_date": "2025-05-10 19:45:15 UTC",
      "updated_date": "2025-05-10 19:45:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:31:02.638384"
    },
    {
      "arxiv_id": "2505.06743v1",
      "title": "TPK: Trustworthy Trajectory Prediction Integrating Prior Knowledge For Interpretability and Kinematic Feasibility",
      "title_zh": "TPK: 整合先验",
      "authors": [
        "Marius Baden",
        "Ahmed Abouelazm",
        "Christian Hubschneider",
        "Yin Wu",
        "Daniel Slieter",
        "J. Marius Zöllner"
      ],
      "abstract": "Trajectory prediction is crucial for autonomous driving, enabling vehicles to\nnavigate safely by anticipating the movements of surrounding road users.\nHowever, current deep learning models often lack trustworthiness as their\npredictions can be physically infeasible and illogical to humans. To make\npredictions more trustworthy, recent research has incorporated prior knowledge,\nlike the social force model for modeling interactions and kinematic models for\nphysical realism. However, these approaches focus on priors that suit either\nvehicles or pedestrians and do not generalize to traffic with mixed agent\nclasses. We propose incorporating interaction and kinematic priors of all agent\nclasses--vehicles, pedestrians, and cyclists with class-specific interaction\nlayers to capture agent behavioral differences. To improve the interpretability\nof the agent interactions, we introduce DG-SFM, a rule-based interaction\nimportance score that guides the interaction layer. To ensure physically\nfeasible predictions, we proposed suitable kinematic models for all agent\nclasses with a novel pedestrian kinematic model. We benchmark our approach on\nthe Argoverse 2 dataset, using the state-of-the-art transformer HPTR as our\nbaseline. Experiments demonstrate that our method improves interaction\ninterpretability, revealing a correlation between incorrect predictions and\ndivergence from our interaction prior. Even though incorporating the kinematic\nmodels causes a slight decrease in accuracy, they eliminate infeasible\ntrajectories found in the dataset and the baseline model. Thus, our approach\nfosters trust in trajectory prediction as its interaction reasoning is\ninterpretable, and its predictions adhere to physics.",
      "tldr_zh": "本文提出 TPK 方法，通过整合先验知识（Prior Knowledge）来提升轨迹预测（Trajectory Prediction）的可解释性（Interpretability）和运动学可行性（Kinematic Feasibility）。该方法为 vehicles、pedestrians 和 cyclists 等不同代理类设计类特定交互层，并引入 DG-SFM 规则-based 交互重要性评分，以更好地捕捉代理行为差异。实验在 Argoverse 2 数据集上以 HPTR 为基线，显示交互可解释性显著改善，虽然准确性略微下降，但成功消除了不可行轨迹，从而增强了预测的可靠性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted in the 36th IEEE Intelligent Vehicles Symposium (IV 2025)\n  for oral presentation",
      "pdf_url": "http://arxiv.org/pdf/2505.06743v1",
      "published_date": "2025-05-10 19:29:32 UTC",
      "updated_date": "2025-05-10 19:29:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:31:14.304541"
    },
    {
      "arxiv_id": "2505.06740v1",
      "title": "Boundary-Guided Trajectory Prediction for Road Aware and Physically Feasible Autonomous Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmed Abouelazm",
        "Mianzhi Liu",
        "Christian Hubschneider",
        "Yin Wu",
        "Daniel Slieter",
        "J. Marius Zöllner"
      ],
      "abstract": "Accurate prediction of surrounding road users' trajectories is essential for\nsafe and efficient autonomous driving. While deep learning models have improved\nperformance, challenges remain in preventing off-road predictions and ensuring\nkinematic feasibility. Existing methods incorporate road-awareness modules and\nenforce kinematic constraints but lack plausibility guarantees and often\nintroduce trade-offs in complexity and flexibility. This paper proposes a novel\nframework that formulates trajectory prediction as a constrained regression\nguided by permissible driving directions and their boundaries. Using the\nagent's current state and an HD map, our approach defines the valid boundaries\nand ensures on-road predictions by training the network to learn superimposed\npaths between left and right boundary polylines. To guarantee feasibility, the\nmodel predicts acceleration profiles that determine the vehicle's travel\ndistance along these paths while adhering to kinematic constraints. We evaluate\nour approach on the Argoverse-2 dataset against the HPTR baseline. Our approach\nshows a slight decrease in benchmark metrics compared to HPTR but notably\nimproves final displacement error and eliminates infeasible trajectories.\nMoreover, the proposed approach has superior generalization to less prevalent\nmaneuvers and unseen out-of-distribution scenarios, reducing the off-road rate\nunder adversarial attacks from 66\\% to just 1\\%. These results highlight the\neffectiveness of our approach in generating feasible and robust predictions.",
      "tldr_zh": "本论文提出一个边界引导的轨迹预测框架，用于实现道路感知和物理可行的自动驾驶，该框架将预测表述为受可允许驾驶方向和边界约束的回归任务。方法利用代理的当前状态和 HD map 定义有效边界，通过训练网络学习左、右边界折线之间的叠加路径，并预测加速度配置文件以确保 kinematic constraints 和 on-road 预测。实验结果显示，在 Argoverse-2 数据集上，该方法与 HPTR 基线相比虽基准指标略有下降，但显著改善了最终位移错误、消除了不可行轨迹，并提升了泛化能力，将 off-road rate 在对抗攻击下从 66% 降至 1%。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted in the 36th IEEE Intelligent Vehicles Symposium (IV 2025)",
      "pdf_url": "http://arxiv.org/pdf/2505.06740v1",
      "published_date": "2025-05-10 19:21:00 UTC",
      "updated_date": "2025-05-10 19:21:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:31:27.503083"
    },
    {
      "arxiv_id": "2505.06737v1",
      "title": "Balancing Progress and Safety: A Novel Risk-Aware Objective for RL in Autonomous Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmed Abouelazm",
        "Jonas Michel",
        "Helen Gremmelmaier",
        "Tim Joseph",
        "Philip Schörner",
        "J. Marius Zöllner"
      ],
      "abstract": "Reinforcement Learning (RL) is a promising approach for achieving autonomous\ndriving due to robust decision-making capabilities. RL learns a driving policy\nthrough trial and error in traffic scenarios, guided by a reward function that\ncombines the driving objectives. The design of such reward function has\nreceived insufficient attention, yielding ill-defined rewards with various\npitfalls. Safety, in particular, has long been regarded only as a penalty for\ncollisions. This leaves the risks associated with actions leading up to a\ncollision unaddressed, limiting the applicability of RL in real-world\nscenarios. To address these shortcomings, our work focuses on enhancing the\nreward formulation by defining a set of driving objectives and structuring them\nhierarchically. Furthermore, we discuss the formulation of these objectives in\na normalized manner to transparently determine their contribution to the\noverall reward. Additionally, we introduce a novel risk-aware objective for\nvarious driving interactions based on a two-dimensional ellipsoid function and\nan extension of Responsibility-Sensitive Safety (RSS) concepts. We evaluate the\nefficacy of our proposed reward in unsignalized intersection scenarios with\nvarying traffic densities. The approach decreases collision rates by 21\\% on\naverage compared to baseline rewards and consistently surpasses them in route\nprogress and cumulative reward, demonstrating its capability to promote safer\ndriving behaviors while maintaining high-performance levels.",
      "tldr_zh": "本研究针对强化学习（RL）在自动驾驶中的奖励函数设计不足问题，提出一个新颖的风险感知目标，以平衡驾驶进度和安全需求。该方法通过定义一组层次化驾驶目标并标准化它们，确保各目标对整体奖励的贡献透明，同时引入基于二维椭球函数和 Responsibility-Sensitive Safety (RSS) 概念的风险感知目标。实验在无信号灯交叉路口场景中评估，结果显示该方法平均减少21%的碰撞率，同时在路线进展和累积奖励方面均优于基线模型，展示了其在提升安全性的同时维持高性能的能力。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted in the 36th IEEE Intelligent vehicles Symposium (IV 2025)",
      "pdf_url": "http://arxiv.org/pdf/2505.06737v1",
      "published_date": "2025-05-10 19:05:03 UTC",
      "updated_date": "2025-05-10 19:05:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:31:37.545934"
    },
    {
      "arxiv_id": "2505.07883v1",
      "title": "Recovering Event Probabilities from Large Language Model Embeddings via Axiomatic Constraints",
      "title_zh": "通过公理约束从大语言模型嵌入中恢复事件概率",
      "authors": [
        "Jian-Qiao Zhu",
        "Haijiang Yan",
        "Thomas L. Griffiths"
      ],
      "abstract": "Rational decision-making under uncertainty requires coherent degrees of\nbelief in events. However, event probabilities generated by Large Language\nModels (LLMs) have been shown to exhibit incoherence, violating the axioms of\nprobability theory. This raises the question of whether coherent event\nprobabilities can be recovered from the embeddings used by the models. If so,\nthose derived probabilities could be used as more accurate estimates in events\ninvolving uncertainty. To explore this question, we propose enforcing axiomatic\nconstraints, such as the additive rule of probability theory, in the latent\nspace learned by an extended variational autoencoder (VAE) applied to LLM\nembeddings. This approach enables event probabilities to naturally emerge in\nthe latent space as the VAE learns to both reconstruct the original embeddings\nand predict the embeddings of semantically related events. We evaluate our\nmethod on complementary events (i.e., event A and its complement, event not-A),\nwhere the true probabilities of the two events must sum to 1. Experiment\nresults on open-weight language models demonstrate that probabilities recovered\nfrom embeddings exhibit greater coherence than those directly reported by the\ncorresponding models and align closely with the true probabilities.",
      "tldr_zh": "该研究探讨了从大型语言模型(LLMs)嵌入中恢复一致事件概率的问题，以解决LLMs直接生成概率时违反概率理论公理的不连贯性。研究提出一种方法，使用扩展的变分自编码器(VAE)在潜在空间中强制执行公理约束，如概率加法规则，从而使事件概率在重建原始嵌入和预测语义相关事件的过程中自然浮现。在针对互补事件的实验中，结果显示从嵌入恢复的概率比LLMs直接报告的更具连贯性，并更接近真实概率，为理性决策中的不确定性建模提供了更准确的估计。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07883v1",
      "published_date": "2025-05-10 19:04:56 UTC",
      "updated_date": "2025-05-10 19:04:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:31:49.628968"
    },
    {
      "arxiv_id": "2505.06731v1",
      "title": "Deeply Explainable Artificial Neural Network",
      "title_zh": "翻译失败",
      "authors": [
        "David Zucker"
      ],
      "abstract": "While deep learning models have demonstrated remarkable success in numerous\ndomains, their black-box nature remains a significant limitation, especially in\ncritical fields such as medical image analysis and inference. Existing\nexplainability methods, such as SHAP, LIME, and Grad-CAM, are typically applied\npost hoc, adding computational overhead and sometimes producing inconsistent or\nambiguous results. In this paper, we present the Deeply Explainable Artificial\nNeural Network (DxANN), a novel deep learning architecture that embeds\nexplainability ante hoc, directly into the training process. Unlike\nconventional models that require external interpretation methods, DxANN is\ndesigned to produce per-sample, per-feature explanations as part of the forward\npass. Built on a flow-based framework, it enables both accurate predictions and\ntransparent decision-making, and is particularly well-suited for image-based\ntasks. While our focus is on medical imaging, the DxANN architecture is readily\nadaptable to other data modalities, including tabular and sequential data.\nDxANN marks a step forward toward intrinsically interpretable deep learning,\noffering a practical solution for applications where trust and accountability\nare essential.",
      "tldr_zh": "本研究针对深度学习模型的黑箱性质问题，特别是在医疗图像分析等领域，提出了一种名为 Deeply Explainable Artificial Neural Network (DxANN) 的新型架构，将解释性 ante hoc 嵌入训练过程，从而避免了传统后验方法如 SHAP、LIME 和 Grad-CAM 的计算开销和不一致性。DxANN 基于流式框架，在正向传播中直接生成每个样本和每个特征的解释，确保预测准确性和决策透明度。适用于图像任务，尤其是医疗成像领域，并可扩展到表格或序列数据类型，为可信赖的深度学习应用提供了实用解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06731v1",
      "published_date": "2025-05-10 18:45:38 UTC",
      "updated_date": "2025-05-10 18:45:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:32:01.077390"
    },
    {
      "arxiv_id": "2505.06706v2",
      "title": "Bi-level Mean Field: Dynamic Grouping for Large-Scale MARL",
      "title_zh": "双层平均场：大规模 MARL 的动态分组",
      "authors": [
        "Yuxuan Zheng",
        "Yihe Zhou",
        "Feiyang Xu",
        "Mingli Song",
        "Shunyu Liu"
      ],
      "abstract": "Large-scale Multi-Agent Reinforcement Learning (MARL) often suffers from the\ncurse of dimensionality, as the exponential growth in agent interactions\nsignificantly increases computational complexity and impedes learning\nefficiency. To mitigate this, existing efforts that rely on Mean Field (MF)\nsimplify the interaction landscape by approximating neighboring agents as a\nsingle mean agent, thus reducing overall complexity to pairwise interactions.\nHowever, these MF methods inevitably fail to account for individual\ndifferences, leading to aggregation noise caused by inaccurate iterative\nupdates during MF learning. In this paper, we propose a Bi-level Mean Field\n(BMF) method to capture agent diversity with dynamic grouping in large-scale\nMARL, which can alleviate aggregation noise via bi-level interaction.\nSpecifically, BMF introduces a dynamic group assignment module, which employs a\nVariational AutoEncoder (VAE) to learn the representations of agents,\nfacilitating their dynamic grouping over time. Furthermore, we propose a\nbi-level interaction module to model both inter- and intra-group interactions\nfor effective neighboring aggregation. Experiments across various tasks\ndemonstrate that the proposed BMF yields results superior to the\nstate-of-the-art methods.",
      "tldr_zh": "该研究针对大型多智能体强化学习（MARL）中的维数灾难问题，提出Bi-level Mean Field (BMF) 方法，通过动态分组捕获代理多样性，从而缓解传统Mean Field (MF) 方法因忽略个体差异而导致的聚合噪声。BMF 包括一个动态分组模块，使用Variational AutoEncoder (VAE) 学习代理表示并实现随时间分组，以及一个双层互动模块，分别处理组内和组间互动以优化邻近代理聚合。实验结果显示，在多种任务中，BMF 比现有最先进方法表现出色，提升了学习效率和性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06706v2",
      "published_date": "2025-05-10 17:04:33 UTC",
      "updated_date": "2025-05-20 07:29:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:32:14.056083"
    },
    {
      "arxiv_id": "2505.06699v3",
      "title": "Model Steering: Learning with a Reference Model Improves Generalization Bounds and Scaling Laws",
      "title_zh": "模型引导：使用参考模型",
      "authors": [
        "Xiyuan Wei",
        "Ming Lin",
        "Fanjiang Ye",
        "Fengguang Song",
        "Liangliang Cao",
        "My T. Thai",
        "Tianbao Yang"
      ],
      "abstract": "This paper formalizes an emerging learning paradigm that uses a trained model\nas a reference to guide and enhance the training of a target model through\nstrategic data selection or weighting, named $\\textbf{model steering}$. While\nad-hoc methods have been used in various contexts, including the training of\nlarge foundation models, its underlying principles remain insufficiently\nunderstood, leading to sub-optimal performance. In this work, we propose a\ntheory-driven framework for model steering called $\\textbf{DRRho risk\nminimization}$, which is rooted in Distributionally Robust Optimization (DRO).\nThrough a generalization analysis, we provide theoretical insights into why\nthis approach improves generalization and data efficiency compared to training\nwithout a reference model. To the best of our knowledge, this is the first time\nsuch theoretical insights are provided for the new learning paradigm, which\nsignificantly enhance our understanding and practice of model steering.\nBuilding on these insights and the connection between contrastive learning and\nDRO, we introduce a novel method for Contrastive Language-Image Pretraining\n(CLIP) with a reference model, termed DRRho-CLIP. Extensive experiments\nvalidate the theoretical insights, reveal a superior scaling law compared to\nCLIP without a reference model, and demonstrate its strength over existing\nheuristic approaches.",
      "tldr_zh": "这篇论文形式化了 model steering 学习范式，使用一个训练好的参考模型通过战略数据选择或加权来指导目标模型的训练，从而提升其性能。作者提出基于 Distributionally Robust Optimization (DRO) 的 DRRho risk minimization 框架，并通过泛化分析提供了理论见解，证明这种方法能改善泛化边界、数据效率和 scaling laws。基于这些见解，他们开发了 DRRho-CLIP 方法，用于 Contrastive Language-Image Pretraining (CLIP)，实验结果显示其比传统 CLIP 具有更好的 scaling laws 和优越性能，优于现有的启发式方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.06699v3",
      "published_date": "2025-05-10 16:55:03 UTC",
      "updated_date": "2025-05-17 02:26:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:32:25.848853"
    },
    {
      "arxiv_id": "2505.06694v1",
      "title": "Underwater object detection in sonar imagery with detection transformer and Zero-shot neural architecture search",
      "title_zh": "翻译失败",
      "authors": [
        "XiaoTong Gu",
        "Shengyu Tang",
        "Yiming Cao",
        "Changdong Yu"
      ],
      "abstract": "Underwater object detection using sonar imagery has become a critical and\nrapidly evolving research domain within marine technology. However, sonar\nimages are characterized by lower resolution and sparser features compared to\noptical images, which seriously degrades the performance of object detection.To\naddress these challenges, we specifically propose a Detection Transformer\n(DETR) architecture optimized with a Neural Architecture Search (NAS) approach\ncalled NAS-DETR for object detection in sonar images. First, an improved\nZero-shot Neural Architecture Search (NAS) method based on the maximum entropy\nprinciple is proposed to identify a real-time, high-representational-capacity\nCNN-Transformer backbone for sonar image detection. This method enables the\nefficient discovery of high-performance network architectures with low\ncomputational and time overhead. Subsequently, the backbone is combined with a\nFeature Pyramid Network (FPN) and a deformable attention-based Transformer\ndecoder to construct a complete network architecture. This architecture\nintegrates various advanced components and training schemes to enhance overall\nperformance. Extensive experiments demonstrate that this architecture achieves\nstate-of-the-art performance on two Representative datasets, while maintaining\nminimal overhead in real-time efficiency and computational complexity.\nFurthermore, correlation analysis between the key parameters and differential\nentropy-based fitness function is performed to enhance the interpretability of\nthe proposed framework. To the best of our knowledge, this is the first work in\nthe field of sonar object detection to integrate the DETR architecture with a\nNAS search mechanism.",
      "tldr_zh": "该研究针对声呐图像中物体检测的挑战，如分辨率低和特征稀疏，提出了一种名为 NAS-DETR 的框架，将 Detection Transformer (DETR) 架构与 Zero-shot Neural Architecture Search (NAS) 相结合。改进的 Zero-shot NAS 方法基于最大熵原则，高效搜索出实时、高表示能力的 CNN-Transformer 骨干网，并与 Feature Pyramid Network (FPN) 和 deformable attention-based Transformer decoder 整合，以提升检测性能。实验结果显示，该框架在两个代表性数据集上达到 state-of-the-art 水平，同时保持低计算复杂度和实时效率，并通过关键参数与差分熵-based 适应性函数的相关分析增强了框架的可解释性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06694v1",
      "published_date": "2025-05-10 16:41:09 UTC",
      "updated_date": "2025-05-10 16:41:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:32:38.450156"
    },
    {
      "arxiv_id": "2505.06684v1",
      "title": "FNBench: Benchmarking Robust Federated Learning against Noisy Labels",
      "title_zh": "翻译失败",
      "authors": [
        "Xuefeng Jiang",
        "Jia Li",
        "Nannan Wu",
        "Zhiyuan Wu",
        "Xujing Li",
        "Sheng Sun",
        "Gang Xu",
        "Yuwei Wang",
        "Qi Li",
        "Min Liu"
      ],
      "abstract": "Robustness to label noise within data is a significant challenge in federated\nlearning (FL). From the data-centric perspective, the data quality of\ndistributed datasets can not be guaranteed since annotations of different\nclients contain complicated label noise of varying degrees, which causes the\nperformance degradation. There have been some early attempts to tackle noisy\nlabels in FL. However, there exists a lack of benchmark studies on\ncomprehensively evaluating their practical performance under unified settings.\nTo this end, we propose the first benchmark study FNBench to provide an\nexperimental investigation which considers three diverse label noise patterns\ncovering synthetic label noise, imperfect human-annotation errors and\nsystematic errors. Our evaluation incorporates eighteen state-of-the-art\nmethods over five image recognition datasets and one text classification\ndataset. Meanwhile, we provide observations to understand why noisy labels\nimpair FL, and additionally exploit a representation-aware regularization\nmethod to enhance the robustness of existing methods against noisy labels based\non our observations. Finally, we discuss the limitations of this work and\npropose three-fold future directions. To facilitate related communities, our\nsource code is open-sourced at https://github.com/Sprinter1999/FNBench.",
      "tldr_zh": "该研究提出了FNBench，这是一个针对联邦学习（Federated Learning）中标签噪声的首个基准框架，用于评估现有方法的鲁棒性。FNBench考虑了三种标签噪声模式，包括合成标签噪声、人类标注错误和系统性错误，并在五种图像识别数据集和一种文本分类数据集上测试了18种最先进方法。实验观察揭示了噪声标签如何损害FL性能，并引入了一种基于表示感知正则化（representation-aware regularization）的改进方法，以提升现有方法的鲁棒性；此外，论文讨论了局限性和未来方向，并开源了代码。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Submitted to IEEE TDSC, currently under major revision",
      "pdf_url": "http://arxiv.org/pdf/2505.06684v1",
      "published_date": "2025-05-10 16:14:52 UTC",
      "updated_date": "2025-05-10 16:14:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:32:49.092952"
    },
    {
      "arxiv_id": "2505.07882v1",
      "title": "Enhancing Trust Management System for Connected Autonomous Vehicles Using Machine Learning Methods: A Survey",
      "title_zh": "使用机器学习",
      "authors": [
        "Qian Xu",
        "Lei Zhang",
        "Yixiao Liu"
      ],
      "abstract": "Connected Autonomous Vehicles (CAVs) operate in dynamic, open, and\nmulti-domain networks, rendering them vulnerable to various threats. Trust\nManagement Systems (TMS) systematically organize essential steps in the trust\nmechanism, identifying malicious nodes against internal threats and external\nthreats, as well as ensuring reliable decision-making for more cooperative\ntasks. Recent advances in machine learning (ML) offer significant potential to\nenhance TMS, especially for the strict requirements of CAVs, such as CAV nodes\nmoving at varying speeds, and opportunistic and intermittent network behavior.\nThose features distinguish ML-based TMS from social networks, static IoT, and\nSocial IoT. This survey proposes a novel three-layer ML-based TMS framework for\nCAVs in the vehicle-road-cloud integration system, i.e., trust data layer,\ntrust calculation layer and trust incentive layer. A six-dimensional taxonomy\nof objectives is proposed. Furthermore, the principles of ML methods for each\nmodule in each layer are analyzed. Then, recent studies are categorized based\non traffic scenarios that are against the proposed objectives. Finally, future\ndirections are suggested, addressing the open issues and meeting the research\ntrend. We maintain an active repository that contains up-to-date literature and\nopen-source projects at\nhttps://github.com/octoberzzzzz/ML-based-TMS-CAV-Survey.",
      "tldr_zh": "这篇调查论文探讨了使用 Machine Learning (ML) 方法增强 Connected Autonomous Vehicles (CAVs) 的 Trust Management Systems (TMS)，以应对动态网络中的内部和外部威胁，并确保可靠决策。论文提出一个三层 ML-based TMS 框架，包括 trust data layer、trust calculation layer 和 trust incentive layer，以及一个六维目标分类法，用于分析 ML 方法在各层中的应用和针对不同交通场景的研究。最终，论文总结了最近的研究进展，并建议未来方向，如解决开放问题和跟进研究趋势，同时提供了一个活跃的开源仓库。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "31 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.07882v1",
      "published_date": "2025-05-10 16:13:36 UTC",
      "updated_date": "2025-05-10 16:13:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:33:01.557181"
    },
    {
      "arxiv_id": "2505.06682v1",
      "title": "A Short Overview of Multi-Modal Wi-Fi Sensing",
      "title_zh": "多模态 Wi-Fi 感知的简要概述",
      "authors": [
        "Zijian Zhao"
      ],
      "abstract": "Wi-Fi sensing has emerged as a significant technology in wireless sensing and\nIntegrated Sensing and Communication (ISAC), offering benefits such as low\ncost, high penetration, and enhanced privacy. Currently, it is widely utilized\nin various applications, including action recognition, human localization, and\ncrowd counting. However, Wi-Fi sensing also faces challenges, such as low\nrobustness and difficulties in data collection. Recently, there has been an\nincreasing focus on multi-modal Wi-Fi sensing, where other modalities can act\nas teachers, providing ground truth or robust features for Wi-Fi sensing models\nto learn from, or can be directly fused with Wi-Fi for enhanced sensing\ncapabilities. Although these methods have demonstrated promising results and\nsubstantial value in practical applications, there is a lack of comprehensive\nsurveys reviewing them. To address this gap, this paper reviews the multi-modal\nWi-Fi sensing literature \\textbf{from the past 24 months} and highlights the\ncurrent limitations, challenges and future directions in this field.",
      "tldr_zh": "Wi-Fi sensing 是一种低成本、高渗透且增强隐私的无线感知技术，广泛应用于动作识别、人定位和人群计数，但面临低鲁棒性和数据收集困难的挑战。近年来，多模态 Wi-Fi sensing 备受关注，通过其他模态作为教师提供 ground truth 或鲁棒特征，或直接与 Wi-Fi 融合，以提升感知能力并在实际应用中展现出有前景的结果。本文对过去 24 个月的多模态 Wi-Fi sensing 文献进行全面回顾，突出了当前限制、挑战，并探讨了未来方向，如进一步提高鲁棒性和集成 ISAC 系统。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06682v1",
      "published_date": "2025-05-10 16:12:56 UTC",
      "updated_date": "2025-05-10 16:12:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:33:13.471154"
    },
    {
      "arxiv_id": "2505.06680v1",
      "title": "A Survey on Data-Driven Modeling of Human Drivers' Lane-Changing Decisions",
      "title_zh": "翻译失败",
      "authors": [
        "Linxuan Huang",
        "Dong-Fan Xie",
        "Li Li",
        "Zhengbing He"
      ],
      "abstract": "Lane-changing (LC) behavior, a critical yet complex driving maneuver,\nsignificantly influences driving safety and traffic dynamics. Traditional\nanalytical LC decision (LCD) models, while effective in specific environments,\noften oversimplify behavioral heterogeneity and complex interactions, limiting\ntheir capacity to capture real LCD. Data-driven approaches address these gaps\nby leveraging rich empirical data and machine learning to decode latent\ndecision-making patterns, enabling adaptive LCD modeling in dynamic\nenvironments. In light of the rapid development of artificial intelligence and\nthe demand for data-driven models oriented towards connected vehicles and\nautonomous vehicles, this paper presents a comprehensive survey of data-driven\nLCD models, with a particular focus on human drivers LC decision-making. It\nsystematically reviews the modeling framework, covering data sources and\npreprocessing, model inputs and outputs, objectives, structures, and validation\nmethods. This survey further discusses the opportunities and challenges faced\nby data-driven LCD models, including driving safety, uncertainty, as well as\nthe integration and improvement of technical frameworks.",
      "tldr_zh": "这篇论文对数据驱动的人类驾驶员车道变更（Lane-Changing Decisions）决策建模进行了全面调查，强调了这些方法相对于传统分析模型的优势，能够更好地捕捉行为异质性和复杂互动。调查系统回顾了建模框架，包括数据来源和预处理、模型输入输出、目标、结构以及验证方法。论文进一步讨论了数据驱动模型在驾驶安全、不确定性以及与连接车辆和自动驾驶车辆整合方面的机遇和挑战。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.LG",
        "cs.SY",
        "eess.SY",
        "physics.soc-ph"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06680v1",
      "published_date": "2025-05-10 16:09:03 UTC",
      "updated_date": "2025-05-10 16:09:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:33:24.863168"
    },
    {
      "arxiv_id": "2505.07879v1",
      "title": "OMGM: Orchestrate Multiple Granularities and Modalities for Efficient Multimodal Retrieval",
      "title_zh": "OMGM: 协调多个粒度和模态以实现高效多模态检索",
      "authors": [
        "Wei Yang",
        "Jingjing Fu",
        "Rui Wang",
        "Jinyu Wang",
        "Lei Song",
        "Jiang Bian"
      ],
      "abstract": "Vision-language retrieval-augmented generation (RAG) has become an effective\napproach for tackling Knowledge-Based Visual Question Answering (KB-VQA), which\nrequires external knowledge beyond the visual content presented in images. The\neffectiveness of Vision-language RAG systems hinges on multimodal retrieval,\nwhich is inherently challenging due to the diverse modalities and knowledge\ngranularities in both queries and knowledge bases. Existing methods have not\nfully tapped into the potential interplay between these elements. We propose a\nmultimodal RAG system featuring a coarse-to-fine, multi-step retrieval that\nharmonizes multiple granularities and modalities to enhance efficacy. Our\nsystem begins with a broad initial search aligning knowledge granularity for\ncross-modal retrieval, followed by a multimodal fusion reranking to capture the\nnuanced multimodal information for top entity selection. A text reranker then\nfilters out the most relevant fine-grained section for augmented generation.\nExtensive experiments on the InfoSeek and Encyclopedic-VQA benchmarks show our\nmethod achieves state-of-the-art retrieval performance and highly competitive\nanswering results, underscoring its effectiveness in advancing KB-VQA systems.",
      "tldr_zh": "本研究提出 OMGM 系统，用于优化多模态检索，通过协调多个 granularities 和 modalities 来提升视觉语言检索增强生成 (RAG) 在基于知识的视觉问答 (KB-VQA) 中的效能。系统采用粗到细的多步检索流程，包括初始宽泛搜索对齐知识粒度、跨模态检索，多模态融合 reranking 选择顶级实体，以及文本 reranking 筛选最相关细粒度部分。实验结果显示，在 InfoSeek 和 Encyclopedic-VQA 基准上，OMGM 实现了 state-of-the-art 的检索性能，并取得了高度竞争的回答效果。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.IR",
      "comment": "19 pages, 6 figures, 17 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.07879v1",
      "published_date": "2025-05-10 14:24:41 UTC",
      "updated_date": "2025-05-10 14:24:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:33:37.680060"
    },
    {
      "arxiv_id": "2505.06652v1",
      "title": "Enfoque Odychess: Un método dialéctico, constructivista y adaptativo para la enseñanza del ajedrez con inteligencias artificiales generativas",
      "title_zh": "翻译失败",
      "authors": [
        "Ernesto Giralt Hernandez",
        "Lazaro Antonio Bueno Perez"
      ],
      "abstract": "Chess teaching has evolved through different approaches, however, traditional\nmethodologies, often based on memorization, contrast with the new possibilities\noffered by generative artificial intelligence, a technology still little\nexplored in this field. This study seeks to empirically validate the\neffectiveness of the Odychess Approach in improving chess knowledge, strategic\nunderstanding, and metacognitive skills in students. A quasi-experimental study\nwas conducted with a pre-test/post-test design and a control group (N=60). The\nexperimental intervention implemented the Odychess Approach, incorporating a\nLlama 3.3 language model that was specifically adapted using\nParameter-Efficient Fine-Tuning (PEFT) techniques to act as a Socratic chess\ntutor. Quantitative assessment instruments were used to measure chess\nknowledge, strategic understanding, and metacognitive skills before and after\nthe intervention. The results of the quasi-experimental study showed\nsignificant improvements in the experimental group compared to the control\ngroup in the three variables analyzed: chess knowledge, strategic\nunderstanding, and metacognitive skills. The complementary qualitative analysis\nrevealed greater analytical depth, more developed dialectical reasoning, and\nincreased intrinsic motivation in students who participated in the Odychess\nmethod-based intervention. The Odychess Approach represents an effective\npedagogical methodology for teaching chess, demonstrating the potential of the\nsynergistic integration of constructivist and dialectical principles with\ngenerative artificial intelligence. The implications of this work are relevant\nfor educators and institutions interested in adopting innovative pedagogical\ntechnologies and for researchers in the field of AI applied to education,\nhighlighting the transferability of the language model adaptation methodology\nto other educational domains.",
      "tldr_zh": "这篇论文提出Odychess Approach，一种结合辩证法(dialectical)、建构主义(constructivist)和适应性(adaptive)的教学方法，利用生成式人工智能教学国际象棋。研究采用准实验设计（包括预测试/后测试和对照组，N=60），通过对Llama 3.3语言模型进行Parameter-Efficient Fine-Tuning (PEFT)微调，使其充当Socratic chess tutor，显著提升学生的国际象棋知识、战略理解和元认知技能。结果显示实验组在定量和定性评估中表现出更强的分析深度、辩证推理和内在动机，该方法证明了AI在教育领域的潜力，并为其他领域的语言模型适配提供可转移性参考。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "Full article in Spanish",
      "pdf_url": "http://arxiv.org/pdf/2505.06652v1",
      "published_date": "2025-05-10 13:58:47 UTC",
      "updated_date": "2025-05-10 13:58:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:33:51.730328"
    },
    {
      "arxiv_id": "2505.06651v1",
      "title": "Dyn-D$^2$P: Dynamic Differentially Private Decentralized Learning with Provable Utility Guarantee",
      "title_zh": "翻译失败",
      "authors": [
        "Zehan Zhu",
        "Yan Huang",
        "Xin Wang",
        "Shouling Ji",
        "Jinming Xu"
      ],
      "abstract": "Most existing decentralized learning methods with differential privacy (DP)\nguarantee rely on constant gradient clipping bounds and fixed-level DP Gaussian\nnoises for each node throughout the training process, leading to a significant\naccuracy degradation compared to non-private counterparts. In this paper, we\npropose a new Dynamic Differentially Private Decentralized learning approach\n(termed Dyn-D$^2$P) tailored for general time-varying directed networks.\nLeveraging the Gaussian DP (GDP) framework for privacy accounting, Dyn-D$^2$P\ndynamically adjusts gradient clipping bounds and noise levels based on gradient\nconvergence. This proposed dynamic noise strategy enables us to enhance model\naccuracy while preserving the total privacy budget. Extensive experiments on\nbenchmark datasets demonstrate the superiority of Dyn-D$^2$P over its\ncounterparts employing fixed-level noises, especially under strong privacy\nguarantees. Furthermore, we provide a provable utility bound for Dyn-D$^2$P\nthat establishes an explicit dependency on network-related parameters, with a\nscaling factor of $1/\\sqrt{n}$ in terms of the number of nodes $n$ up to a bias\nerror term induced by gradient clipping. To our knowledge, this is the first\nmodel utility analysis for differentially private decentralized non-convex\noptimization with dynamic gradient clipping bounds and noise levels.",
      "tldr_zh": "本论文提出了一种名为 Dyn-D²P 的动态差分隐私 (DP) 去中心化学习方法，针对时间变化的定向网络，动态调整梯度裁剪边界和噪声水平，以缓解传统固定噪声策略导致的准确性下降问题。Dyn-D²P 利用 Gaussian DP (GDP) 框架基于梯度收敛进行隐私预算优化，从而提升模型性能，同时保持强隐私保证。在基准数据集上的实验显示，该方法显著优于固定噪声竞争者，尤其在高隐私设置下；此外，论文提供了可证明的效用边界，显示了与网络参数（如节点数 n 的 1/√n 缩放因子）的显式依赖关系，这是首个针对动态梯度裁剪和噪声的差分隐私去中心化非凸优化效用分析。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper has been accepted by the 34th International Joint\n  Conference on Artificial Intelligence(IJCAI 2025)",
      "pdf_url": "http://arxiv.org/pdf/2505.06651v1",
      "published_date": "2025-05-10 13:57:57 UTC",
      "updated_date": "2025-05-10 13:57:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:34:05.409131"
    },
    {
      "arxiv_id": "2505.06637v1",
      "title": "Exploring Multimodal Foundation AI and Expert-in-the-Loop for Sustainable Management of Wild Salmon Fisheries in Indigenous Rivers",
      "title_zh": "翻译失败",
      "authors": [
        "Chi Xu",
        "Yili Jin",
        "Sami Ma",
        "Rongsheng Qian",
        "Hao Fang",
        "Jiangchuan Liu",
        "Xue Liu",
        "Edith C. H. Ngai",
        "William I. Atlas",
        "Katrina M. Connors",
        "Mark A. Spoljaric"
      ],
      "abstract": "Wild salmon are essential to the ecological, economic, and cultural\nsustainability of the North Pacific Rim. Yet climate variability, habitat loss,\nand data limitations in remote ecosystems that lack basic infrastructure\nsupport pose significant challenges to effective fisheries management. This\nproject explores the integration of multimodal foundation AI and\nexpert-in-the-loop frameworks to enhance wild salmon monitoring and sustainable\nfisheries management in Indigenous rivers across Pacific Northwest. By\nleveraging video and sonar-based monitoring, we develop AI-powered tools for\nautomated species identification, counting, and length measurement, reducing\nmanual effort, expediting delivery of results, and improving decision-making\naccuracy. Expert validation and active learning frameworks ensure ecological\nrelevance while reducing annotation burdens. To address unique technical and\nsocietal challenges, we bring together a cross-domain, interdisciplinary team\nof university researchers, fisheries biologists, Indigenous stewardship\npractitioners, government agencies, and conservation organizations. Through\nthese collaborations, our research fosters ethical AI co-development, open data\nsharing, and culturally informed fisheries management.",
      "tldr_zh": "这篇论文探讨了如何通过多模态基础 AI 和专家-in-the-loop 框架来提升北太平洋原住民河流中野鲑鱼渔业的可持续管理，以应对气候变异、栖息地丧失和数据限制等挑战。研究利用视频和声呐监测开发 AI 工具，实现自动物种识别、计数和长度测量，从而减少手动工作、加快结果交付并提高决策准确性。专家验证与主动学习框架确保生态相关性和降低标注负担，同时通过跨领域团队合作，包括大学研究员、渔业生物学家和原住民实践者，促进道德 AI 共同开发、开放数据共享以及文化相关的渔业管理。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, accepted by IJCAI 2025, AI and Social Good Track",
      "pdf_url": "http://arxiv.org/pdf/2505.06637v1",
      "published_date": "2025-05-10 13:03:06 UTC",
      "updated_date": "2025-05-10 13:03:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:34:14.149808"
    },
    {
      "arxiv_id": "2505.06632v1",
      "title": "AI-Powered Anomaly Detection with Blockchain for Real-Time Security and Reliability in Autonomous Vehicles",
      "title_zh": "翻译失败",
      "authors": [
        "Rathin Chandra Shit",
        "Sharmila Subudhi"
      ],
      "abstract": "Autonomous Vehicles (AV) proliferation brings important and pressing security\nand reliability issues that must be dealt with to guarantee public safety and\nhelp their widespread adoption. The contribution of the proposed research is\ntowards achieving more secure, reliable, and trustworthy autonomous\ntransportation system by providing more capabilities for anomaly detection,\ndata provenance, and real-time response in safety critical AV deployments. In\nthis research, we develop a new framework that combines the power of Artificial\nIntelligence (AI) for real-time anomaly detection with blockchain technology to\ndetect and prevent any malicious activity including sensor failures in AVs.\nThrough Long Short-Term Memory (LSTM) networks, our approach continually\nmonitors associated multi-sensor data streams to detect anomalous patterns that\nmay represent cyberattacks as well as hardware malfunctions. Further, this\nframework employs a decentralized platform for securely storing sensor data and\nanomaly alerts in a blockchain ledger for data incorruptibility and\nauthenticity, while offering transparent forensic features. Moreover, immediate\nautomated response mechanisms are deployed using smart contracts when anomalies\nare found. This makes the AV system more resilient to attacks from both\ncyberspace and hardware component failure. Besides, we identify potential\nchallenges of scalability in handling high frequency sensor data, computational\nconstraint in resource constrained environment, and of distributed data storage\nin terms of privacy.",
      "tldr_zh": "这篇论文提出了一种结合人工智能(AI)和区块链技术的框架，用于实时检测自动驾驶车辆(AVs)的异常，提高其安全性和可靠性。该框架利用Long Short-Term Memory (LSTM)网络持续监控多传感器数据流，以识别潜在的网络攻击或硬件故障；同时，区块链用于安全存储数据和警报，确保数据完整性和可追踪性，并通过智能合约实现即时自动响应。实验结果表明，该系统增强了AVs对威胁的弹性，但也指出了可扩展性、计算资源限制和隐私保护等挑战。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Scheduled for presentation at an upcoming conference",
      "pdf_url": "http://arxiv.org/pdf/2505.06632v1",
      "published_date": "2025-05-10 12:53:28 UTC",
      "updated_date": "2025-05-10 12:53:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:34:25.014912"
    },
    {
      "arxiv_id": "2505.06630v1",
      "title": "Dynamic Domain Information Modulation Algorithm for Multi-domain Sentiment Analysis",
      "title_zh": "多领域情感分析的动态领域信息调制算法",
      "authors": [
        "Chunyi Yue",
        "Ang Li"
      ],
      "abstract": "Multi-domain sentiment classification aims to mitigate poor performance\nmodels due to the scarcity of labeled data in a single domain, by utilizing\ndata labeled from various domains. A series of models that jointly train domain\nclassifiers and sentiment classifiers have demonstrated their advantages,\nbecause domain classification helps generate necessary information for\nsentiment classification. Intuitively, the importance of sentiment\nclassification tasks is the same in all domains for multi-domain sentiment\nclassification; but domain classification tasks are different because the\nimpact of domain information on sentiment classification varies across\ndifferent fields; this can be controlled through adjustable weights or hyper\nparameters. However, as the number of domains increases, existing\nhyperparameter optimization algorithms may face the following challenges: (1)\ntremendous demand for computing resources, (2) convergence problems, and (3)\nhigh algorithm complexity. To efficiently generate the domain information\nrequired for sentiment classification in each domain, we propose a dynamic\ninformation modulation algorithm. Specifically, the model training process is\ndivided into two stages. In the first stage, a shared hyperparameter, which\nwould control the proportion of domain classification tasks across all fields,\nis determined. In the second stage, we introduce a novel domain-aware\nmodulation algorithm to adjust the domain information contained in the input\ntext, which is then calculated based on a gradient-based and loss-based method.\nIn summary, experimental results on a public sentiment analysis dataset\ncontaining 16 domains prove the superiority of the proposed method.",
      "tldr_zh": "这篇论文针对多域情感分析提出了Dynamic Domain Information Modulation Algorithm，以解决现有超参数优化算法在处理多个域时面临的计算资源需求大、收敛问题和高复杂度等问题。方法将训练过程分为两个阶段：第一阶段确定一个共享超参数来控制所有域的域分类任务比例；第二阶段引入基于梯度和损失的域感知调制算法，动态调整输入文本中的域信息以支持情感分类。实验结果在包含16个域的公共数据集上证明了该方法的优越性，显著提升了多域情感分类的性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages, 5 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.06630v1",
      "published_date": "2025-05-10 12:36:00 UTC",
      "updated_date": "2025-05-10 12:36:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:34:38.029273"
    },
    {
      "arxiv_id": "2505.07877v1",
      "title": "Efficient Telecom Specific LLM: TSLAM-Mini with QLoRA and Digital Twin Data",
      "title_zh": "翻译失败",
      "authors": [
        "Vignesh Ethiraj",
        "Divya Vijay",
        "Sidhanth Menon",
        "Heblin Berscilla"
      ],
      "abstract": "General-purpose large language models (LLMs), despite their broad\ncapabilities accrued from open-world data, frequently exhibit suboptimal\nperformance when confronted with the nuanced and specialized demands inherent\nin real-time telecommunications applications. This investigation addresses this\ncritical limitation through the meticulous fine-tuning of TSLAM-Mini developed\nby NetoAI, a compact (3.8-billion parameter) causal language model\narchitecturally derived from Phi-4 Mini Instruct 4B. The fine-tuning regimen\nleverages a bespoke dataset comprising 100,000 samples, strategically\nengineered to address 20 pivotal telecommunications use-cases, encompassing\ndomains such as Network Fundamentals, IP Routing, MPLS, Network Security,\nAutomation, OSS/BSS, RAN, Mobile Core, Satellite Communications, and Ethical\nAI. This dataset was curated utilizing NetoAI's DigiTwin platform, enriched\nwith granular insights from venerated network Subject Matter Experts (SMEs) and\nauthoritative RFC documents, thereby capturing high-fidelity representations of\nreal-world network dynamics through simulations inspired by digital twin\nparadigms. Employing Quantized Low-Rank Adaptation (QLoRA), a state-of-the-art\nParameter Efficient Fine-Tuning (PEFT) technique, we achieved substantial\ntraining efficiency and enabled prospective deployment on resource-constrained\nhardware. A novel evaluation framework, predicated on a high-capacity LLM\n(Qwen3-235B-A22B) functioning as an automated adjudicator, was instituted to\nrigorously assess instruction-following fidelity and response quality across\nthe specified telecom use-cases. Empirical results unequivocally demonstrate\nTSLAM-Mini's superior aptitude in telecom-centric applications, underscoring\nthe profound efficacy of domain-specific datasets and PEFT methodologies for\nadvancing intelligent network management.",
      "tldr_zh": "这篇论文针对通用大型语言模型(LLMs)在电信应用中的表现不足，提出通过微调TSLAM-Mini（一个基于Phi-4 Mini Instruct 4B的3.8亿参数紧凑模型）来提升其在实时电信场景中的性能。研究团队构建了一个自定义数据集，包含10万样本，覆盖20个关键电信用例（如Network Fundamentals、IP Routing和Network Security），该数据集利用NetoAI的DigiTwin平台结合专家知识和RFC文档，通过数字孪生模拟获取真实网络动态。采用QLoRA（Quantized Low-Rank Adaptation）作为参数高效微调技术，提高训练效率并支持资源受限硬件部署；实验评估使用Qwen3-235B-A22B作为自动评判器，结果显示TSLAM-Mini在电信应用中显著优于基线模型，证明了领域特定数据集和PEFT方法在智能网络管理中的巨大潜力。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "68T50",
        "I.2.7; I.2.6; C.2.3"
      ],
      "primary_category": "cs.NI",
      "comment": "Introducing TSLAM-Mini, a specialized language model for\n  telecommunications, demonstrating the efficacy of QLoRA fine-tuning and\n  digital twin-synthesized data for enhanced network intelligence. Model\n  available on: https://huggingface.co/NetoAISolutions/TSLAM-Mini-2B",
      "pdf_url": "http://arxiv.org/pdf/2505.07877v1",
      "published_date": "2025-05-10 12:28:47 UTC",
      "updated_date": "2025-05-10 12:28:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:34:51.355960"
    },
    {
      "arxiv_id": "2505.06625v1",
      "title": "CaMDN: Enhancing Cache Efficiency for Multi-tenant DNNs on Integrated NPUs",
      "title_zh": "翻译失败",
      "authors": [
        "Tianhao Cai",
        "Liang Wang",
        "Limin Xiao",
        "Meng Han",
        "Zeyu Wang",
        "Lin Sun",
        "Xiaojian Liao"
      ],
      "abstract": "With the rapid development of DNN applications, multi-tenant execution, where\nmultiple DNNs are co-located on a single SoC, is becoming a prevailing trend.\nAlthough many methods are proposed in prior works to improve multi-tenant\nperformance, the impact of shared cache is not well studied. This paper\nproposes CaMDN, an architecture-scheduling co-design to enhance cache\nefficiency for multi-tenant DNNs on integrated NPUs. Specifically, a\nlightweight architecture is proposed to support model-exclusive, NPU-controlled\nregions inside shared cache to eliminate unexpected cache contention. Moreover,\na cache scheduling method is proposed to improve shared cache utilization. In\nparticular, it includes a cache-aware mapping method for adaptability to the\nvarying available cache capacity and a dynamic allocation algorithm to adjust\nthe usage among co-located DNNs at runtime. Compared to prior works, CaMDN\nreduces the memory access by 33.4% on average and achieves a model speedup of\nup to 2.56$\\times$ (1.88$\\times$ on average).",
      "tldr_zh": "本文提出CaMDN，一种架构-调度联合设计，旨在提升集成NPUs上多租户DNNs的缓存效率，以解决共享缓存竞争问题。CaMDN包括一个轻量级架构，支持模型独占的NPU控制缓存区域来消除意外竞争，以及一个缓存调度方法，结合缓存感知映射和动态分配算法，以适应可变缓存容量并在运行时优化资源分配。实验结果显示，CaMDN平均减少33.4%的内存访问，并实现高达2.56倍的模型加速（平均1.88倍），显著提高了多租户DNNs的性能。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.OS"
      ],
      "primary_category": "cs.AR",
      "comment": "7 pages, 9 figures. This paper has been accepted to the 2025 Design\n  Automation Conference (DAC)",
      "pdf_url": "http://arxiv.org/pdf/2505.06625v1",
      "published_date": "2025-05-10 12:16:50 UTC",
      "updated_date": "2025-05-10 12:16:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:35:02.152411"
    },
    {
      "arxiv_id": "2505.06620v1",
      "title": "Integrating Explainable AI in Medical Devices: Technical, Clinical and Regulatory Insights and Recommendations",
      "title_zh": "在医疗器械中整合可解释人工智能：技术、临床",
      "authors": [
        "Dima Alattal",
        "Asal Khoshravan Azar",
        "Puja Myles",
        "Richard Branson",
        "Hatim Abdulhussein",
        "Allan Tucker"
      ],
      "abstract": "There is a growing demand for the use of Artificial Intelligence (AI) and\nMachine Learning (ML) in healthcare, particularly as clinical decision support\nsystems to assist medical professionals. However, the complexity of many of\nthese models, often referred to as black box models, raises concerns about\ntheir safe integration into clinical settings as it is difficult to understand\nhow they arrived at their predictions. This paper discusses insights and\nrecommendations derived from an expert working group convened by the UK\nMedicine and Healthcare products Regulatory Agency (MHRA). The group consisted\nof healthcare professionals, regulators, and data scientists, with a primary\nfocus on evaluating the outputs from different AI algorithms in clinical\ndecision-making contexts. Additionally, the group evaluated findings from a\npilot study investigating clinicians' behaviour and interaction with AI methods\nduring clinical diagnosis. Incorporating AI methods is crucial for ensuring the\nsafety and trustworthiness of medical AI devices in clinical settings. Adequate\ntraining for stakeholders is essential to address potential issues, and further\ninsights and recommendations for safely adopting AI systems in healthcare\nsettings are provided.",
      "tldr_zh": "这篇论文探讨了在医疗设备中整合Explainable AI的可行性，针对AI和ML作为临床决策支持系统的应用，强调了黑盒模型的复杂性可能导致的安全风险和理解难题。论文基于一个由医疗专业人士、监管者和数据科学家组成的工作组的讨论，评估了AI算法在临床决策中的输出，并通过一个试点研究分析了临床医生与AI互动的行为模式。最终，该研究提供了技术、临床和监管方面的见解与推荐，包括加强利益相关者培训和确保医疗AI设备的安全性，以促进AI在医疗环境中的可靠采用。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "H.5.2"
      ],
      "primary_category": "cs.HC",
      "comment": "47 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.06620v1",
      "published_date": "2025-05-10 12:09:19 UTC",
      "updated_date": "2025-05-10 12:09:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:35:12.856049"
    },
    {
      "arxiv_id": "2505.06612v1",
      "title": "Burger: Robust Graph Denoising-augmentation Fusion and Multi-semantic Modeling in Social Recommendation",
      "title_zh": "Burger：社交推荐中的鲁棒图去噪-增强融合和多语义建模",
      "authors": [
        "Yuqin Lan"
      ],
      "abstract": "In the era of rapid development of social media, social recommendation\nsystems as hybrid recommendation systems have been widely applied. Existing\nmethods capture interest similarity between users to filter out\ninterest-irrelevant relations in social networks that inevitably decrease\nrecommendation accuracy, however, limited research has a focus on the mutual\ninfluence of semantic information between the social network and the user-item\ninteraction network for further improving social recommendation. To address\nthese issues, we introduce a social \\underline{r}ecommendation model with\nro\\underline{bu}st g\\underline{r}aph denoisin\\underline{g}-augmentation fusion\nand multi-s\\underline{e}mantic Modeling(Burger). Specifically, we firstly\npropose to construct a social tensor in order to smooth the training process of\nthe model. Then, a graph convolutional network and a tensor convolutional\nnetwork are employed to capture user's item preference and social preference,\nrespectively. Considering the different semantic information in the user-item\ninteraction network and the social network, a bi-semantic coordination loss is\nproposed to model the mutual influence of semantic information. To alleviate\nthe interference of interest-irrelevant relations on multi-semantic modeling,\nwe further use Bayesian posterior probability to mine potential social\nrelations to replace social noise. Finally, the sliding window mechanism is\nutilized to update the social tensor as the input for the next iteration.\nExtensive experiments on three real datasets show Burger has a superior\nperformance compared with the state-of-the-art models.",
      "tldr_zh": "该研究提出了一种社交推荐模型 Burger，通过鲁棒的图 denoising-augmentation 融合和多语义建模，解决现有方法忽略社交网络与用户-物品交互网络语义信息相互影响的问题。具体来说，模型构建社交张量来平滑训练过程，使用 graph convolutional network 和 tensor convolutional network 分别捕获用户的物品偏好和社会偏好，并引入 bi-semantic coordination loss 来建模语义相互影响，同时利用 Bayesian posterior probability 挖掘潜在社交关系以减少噪声干扰。实验在三个真实数据集上表明，Burger 比最先进模型表现出色，显著提升了推荐准确性。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.IR",
        "F.2.2; I.2.7"
      ],
      "primary_category": "cs.SI",
      "comment": "10 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.06612v1",
      "published_date": "2025-05-10 11:51:22 UTC",
      "updated_date": "2025-05-10 11:51:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:35:25.198056"
    },
    {
      "arxiv_id": "2505.06595v1",
      "title": "Feature Representation Transferring to Lightweight Models via Perception Coherence",
      "title_zh": "翻译失败",
      "authors": [
        "Hai-Vy Nguyen",
        "Fabrice Gamboa",
        "Sixin Zhang",
        "Reda Chhaibi",
        "Serge Gratton",
        "Thierry Giaccone"
      ],
      "abstract": "In this paper, we propose a method for transferring feature representation to\nlightweight student models from larger teacher models. We mathematically define\na new notion called \\textit{perception coherence}. Based on this notion, we\npropose a loss function, which takes into account the dissimilarities between\ndata points in feature space through their ranking. At a high level, by\nminimizing this loss function, the student model learns to mimic how the\nteacher model \\textit{perceives} inputs. More precisely, our method is\nmotivated by the fact that the representational capacity of the student model\nis weaker than the teacher model. Hence, we aim to develop a new method\nallowing for a better relaxation. This means that, the student model does not\nneed to preserve the absolute geometry of the teacher one, while preserving\nglobal coherence through dissimilarity ranking. Our theoretical insights\nprovide a probabilistic perspective on the process of feature representation\ntransfer. Our experiments results show that our method outperforms or achieves\non-par performance compared to strong baseline methods for representation\ntransferring.",
      "tldr_zh": "本研究提出了一种通过“perception coherence”概念将特征表示从大型教师模型转移到轻量级学生模型的方法。具体而言，该方法定义了“perception coherence”作为数据点在特征空间中差异排名的度量，并基于此设计了一个损失函数，使学生模型学习模仿教师模型对输入的感知，而非精确复制其几何结构。实验结果表明，该方法在特征表示转移任务上优于或达到与强基线方法相当的性能，为处理学生模型表示能力限制提供了更宽松且有效的理论框架。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "math.PR"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06595v1",
      "published_date": "2025-05-10 10:55:06 UTC",
      "updated_date": "2025-05-10 10:55:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:35:36.731338"
    },
    {
      "arxiv_id": "2505.06589v1",
      "title": "Optimal Transport for Machine Learners",
      "title_zh": "翻译失败",
      "authors": [
        "Gabriel Peyré"
      ],
      "abstract": "Optimal Transport is a foundational mathematical theory that connects\noptimization, partial differential equations, and probability. It offers a\npowerful framework for comparing probability distributions and has recently\nbecome an important tool in machine learning, especially for designing and\nevaluating generative models. These course notes cover the fundamental\nmathematical aspects of OT, including the Monge and Kantorovich formulations,\nBrenier's theorem, the dual and dynamic formulations, the Bures metric on\nGaussian distributions, and gradient flows. It also introduces numerical\nmethods such as linear programming, semi-discrete solvers, and entropic\nregularization. Applications in machine learning include topics like training\nneural networks via gradient flows, token dynamics in transformers, and the\nstructure of GANs and diffusion models. These notes focus primarily on\nmathematical content rather than deep learning techniques.",
      "tldr_zh": "本课程笔记介绍了 Optimal Transport (OT) 作为一种连接优化、偏微分方程和概率的数学理论，并强调其在机器学习中的作用，特别是用于比较概率分布和评估生成模型。笔记涵盖了核心数学方面，包括 Monge 和 Kantorovich 公式、Brenier's theorem、dual and dynamic formulations、Bures metric on Gaussian distributions 以及 gradient flows。还讨论了数值方法如 linear programming、semi-discrete solvers 和 entropic regularization，并应用于机器学习领域，如通过 gradient flows 训练神经网络、token dynamics in transformers 以及 GANs 和 diffusion models 的结构设计。重点在于数学内容而非深度学习技巧。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "stat.ML",
      "comment": "arXiv admin note: text overlap with arXiv:1803.00567",
      "pdf_url": "http://arxiv.org/pdf/2505.06589v1",
      "published_date": "2025-05-10 10:35:03 UTC",
      "updated_date": "2025-05-10 10:35:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:35:49.430053"
    },
    {
      "arxiv_id": "2505.06584v1",
      "title": "JAEGER: Dual-Level Humanoid Whole-Body Controller",
      "title_zh": "JAEGER: 双层级人形机器人全身控制器",
      "authors": [
        "Ziluo Ding",
        "Haobin Jiang",
        "Yuxuan Wang",
        "Zhenguo Sun",
        "Yu Zhang",
        "Xiaojie Niu",
        "Ming Yang",
        "Weishuai Zeng",
        "Xinrun Xu",
        "Zongqing Lu"
      ],
      "abstract": "This paper presents JAEGER, a dual-level whole-body controller for humanoid\nrobots that addresses the challenges of training a more robust and versatile\npolicy. Unlike traditional single-controller approaches, JAEGER separates the\ncontrol of the upper and lower bodies into two independent controllers, so that\nthey can better focus on their distinct tasks. This separation alleviates the\ndimensionality curse and improves fault tolerance. JAEGER supports both root\nvelocity tracking (coarse-grained control) and local joint angle tracking\n(fine-grained control), enabling versatile and stable movements. To train the\ncontroller, we utilize a human motion dataset (AMASS), retargeting human poses\nto humanoid poses through an efficient retargeting network, and employ a\ncurriculum learning approach. This method performs supervised learning for\ninitialization, followed by reinforcement learning for further exploration. We\nconduct our experiments on two humanoid platforms and demonstrate the\nsuperiority of our approach against state-of-the-art methods in both simulation\nand real environments.",
      "tldr_zh": "本论文提出JAEGER，一种双层全身体控制器，用于提升人形机器人的鲁棒性和多功能性。该控制器将上半身和下半身的控制分开独立处理，缓解维度诅咒并提高容错性，同时支持根速度跟踪（粗粒度控制）和局部关节角度跟踪（细粒度控制），实现稳定运动。训练过程利用AMASS人类运动数据集进行姿势重定向，并采用课程学习方法，先通过监督学习初始化，再用reinforcement learning探索优化；在两个人形机器人平台上的实验显示，JAEGER在模拟和真实环境中优于现有方法。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "15 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.06584v1",
      "published_date": "2025-05-10 10:10:19 UTC",
      "updated_date": "2025-05-10 10:10:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:36:00.728042"
    },
    {
      "arxiv_id": "2505.06580v1",
      "title": "TAROT: Towards Essentially Domain-Invariant Robustness with Theoretical Justification",
      "title_zh": "翻译失败",
      "authors": [
        "Dongyoon Yang",
        "Jihu Lee",
        "Yongdai Kim"
      ],
      "abstract": "Robust domain adaptation against adversarial attacks is a critical research\narea that aims to develop models capable of maintaining consistent performance\nacross diverse and challenging domains. In this paper, we derive a new\ngeneralization bound for robust risk on the target domain using a novel\ndivergence measure specifically designed for robust domain adaptation. Building\nupon this, we propose a new algorithm named TAROT, which is designed to enhance\nboth domain adaptability and robustness. Through extensive experiments, TAROT\nnot only surpasses state-of-the-art methods in accuracy and robustness but also\nsignificantly enhances domain generalization and scalability by effectively\nlearning domain-invariant features. In particular, TAROT achieves superior\nperformance on the challenging DomainNet dataset, demonstrating its ability to\nlearn domain-invariant representations that generalize well across different\ndomains, including unseen ones. These results highlight the broader\napplicability of our approach in real-world domain adaptation scenarios.",
      "tldr_zh": "该论文针对鲁棒域适应（robust domain adaptation）问题，提出了一种新算法 TAROT，以提升模型在不同域中的鲁棒性和泛化能力，并通过一个新型散度测量（divergence measure）推导了目标域鲁棒风险的泛化边界。TAROT 旨在学习域不变特征（domain-invariant features），从而增强域适应性和可扩展性。实验结果显示，该算法在准确性和鲁棒性上超越了现有方法，尤其在 DomainNet 数据集上表现出色，能够有效处理不同和未见域。总体而言，这为真实世界域适应场景提供了更可靠的理论基础和实际应用。",
      "categories": [
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted in CVPR 2025 (19 pages, 7 figures)",
      "pdf_url": "http://arxiv.org/pdf/2505.06580v1",
      "published_date": "2025-05-10 09:43:04 UTC",
      "updated_date": "2025-05-10 09:43:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:36:12.522135"
    },
    {
      "arxiv_id": "2505.06576v2",
      "title": "Two-Stage Random Alternation Framework for One-Shot Pansharpening",
      "title_zh": "翻译失败",
      "authors": [
        "Haorui Chen",
        "Zeyu Ren",
        "Jiaxuan Ren",
        "Ran Ran",
        "Jinliang Shao",
        "Jie Huang",
        "Liangjian Deng"
      ],
      "abstract": "Deep learning has substantially advanced pansharpening, achieving impressive\nfusion quality. However, a prevalent limitation is that conventional deep\nlearning models, which typically rely on training datasets, often exhibit\nsuboptimal generalization to unseen real-world image pairs. This restricts\ntheir practical utility when faced with real-world scenarios not included in\nthe training datasets. To overcome this, we introduce a two-stage random\nalternating framework (TRA-PAN) that performs instance-specific optimization\nfor any given Multispectral(MS)/Panchromatic(PAN) pair, ensuring robust and\nhigh-quality fusion. TRA-PAN effectively integrates strong supervision\nconstraints from reduced-resolution images with the physical characteristics of\nthe full-resolution images. The first stage introduces a pre-training\nprocedure, which includes Degradation-Aware Modeling (DAM) to capture spectral\ndegradation mappings, alongside a warm-up procedure designed to reduce training\ntime and mitigate the adverse effects of reduced-resolution data. The second\nstage employs Random Alternation Optimization (RAO), randomly alternating\nbetween reduced- and full-resolution images to refine the fusion model\nprogressively. This adaptive, per-instance optimization strategy, operating in\na one-shot manner for each MS/PAN pair, yields superior high-resolution\nmultispectral images. Experimental results demonstrate that TRA-PAN outperforms\nstate-of-the-art (SOTA) methods in quantitative metrics and visual quality in\nreal-world scenarios, underscoring its enhanced practical applicability and\nrobustness.",
      "tldr_zh": "本文提出了一种两阶段随机交替框架（TRA-PAN），用于一-shot pansharpening，以解决深度学习模型在真实场景中泛化性差的问题。该框架通过第一阶段的Degradation-Aware Modeling (DAM)和warm-up过程捕捉光谱退化映射，并减少训练时间；第二阶段则采用Random Alternation Optimization (RAO)，在低分辨率和全分辨率MS/PAN图像间随机切换进行实例特定优化。实验结果显示，TRA-PAN在定量指标和视觉质量上优于现有SOTA方法，显著提升了实际应用的鲁棒性和实用性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06576v2",
      "published_date": "2025-05-10 09:26:22 UTC",
      "updated_date": "2025-05-16 10:39:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:36:26.039090"
    },
    {
      "arxiv_id": "2505.06569v2",
      "title": "MacRAG: Compress, Slice, and Scale-up for Multi-Scale Adaptive Context RAG",
      "title_zh": "翻译失败",
      "authors": [
        "Woosang Lim",
        "Zekun Li",
        "Gyuwan Kim",
        "Sungyoung Ji",
        "HyeonJung Kim",
        "Kyuri Choi",
        "Jin Hyuk Lim",
        "Kyungpyo Park",
        "William Yang Wang"
      ],
      "abstract": "Long-context large language models (LC LLMs) combined with\nretrieval-augmented generation (RAG) hold strong potential for complex\nmulti-hop and large-document tasks. However, existing RAG systems often suffer\nfrom imprecise retrieval, incomplete context coverage under constrained\nwindows, and fragmented information from suboptimal context construction. We\nintroduce Multi-scale Adaptive Context RAG (MacRAG), a hierarchical RAG\nframework that compresses and partitions documents into coarse-to-fine\ngranularities, then adaptively merges relevant contexts through real-time\nchunk- and document-level expansions. By initiating with finest-level retrieval\nand progressively incorporating broader, higher-level context, MacRAG\nconstructs effective query-specific long contexts, optimizing both precision\nand coverage. Evaluations on challenging LongBench expansions of HotpotQA,\n2WikiMultihopQA, and Musique confirm MacRAG consistently surpasses baseline RAG\npipelines in single- and multi-step generation using Llama-3.1-8B,\nGemini-1.5-pro, and GPT-4o. Our results establish MacRAG as an efficient,\nscalable solution for real-world long-context, multi-hop reasoning. Our code is\navailable at https://github.com/Leezekun/MacRAG.",
      "tldr_zh": "本文提出 MacRAG，一种多尺度适应性上下文 RAG 框架，通过压缩文档、划分成粗到细的粒度，并通过实时 chunk- 和 document-level 扩展来适应性地合并相关上下文，从而优化检索精度和覆盖率。MacRAG 从最细粒度检索开始，逐步整合更广的上下文，构建有效的查询特定长上下文，以提升多跳推理任务的性能。在 LongBench 扩展的 HotpotQA、2WikiMultihopQA 和 Musique 基准测试中，该框架使用 Llama-3.1-8B、Gemini-1.5-pro 和 GPT-4o 模型，显著超越基线 RAG 系统，为真实世界的长-context 多跳推理提供高效、可扩展的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06569v2",
      "published_date": "2025-05-10 08:50:44 UTC",
      "updated_date": "2025-05-20 20:24:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:36:38.139870"
    },
    {
      "arxiv_id": "2505.06561v1",
      "title": "Quadrupedal Robot Skateboard Mounting via Reverse Curriculum Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Danil Belov",
        "Artem Erkhov",
        "Elizaveta Pestova",
        "Ilya Osokin",
        "Dzmitry Tsetserukou",
        "Pavel Osinenko"
      ],
      "abstract": "The aim of this work is to enable quadrupedal robots to mount skateboards\nusing Reverse Curriculum Reinforcement Learning. Although prior work has\ndemonstrated skateboarding for quadrupeds that are already positioned on the\nboard, the initial mounting phase still poses a significant challenge. A\ngoal-oriented methodology was adopted, beginning with the terminal phases of\nthe task and progressively increasing the complexity of the problem definition\nto approximate the desired objective. The learning process was initiated with\nthe skateboard rigidly fixed within the global coordinate frame and the robot\npositioned directly above it. Through gradual relaxation of these initial\nconditions, the learned policy demonstrated robustness to variations in\nskateboard position and orientation, ultimately exhibiting a successful\ntransfer to scenarios involving a mobile skateboard. The code, trained models,\nand reproducible examples are available at the following link:\nhttps://github.com/dancher00/quadruped-skateboard-mounting",
      "tldr_zh": "这篇论文提出了一种使用Reverse Curriculum Reinforcement Learning的方法，让四足机器人能够成功上滑板，解决初始定位的挑战。方法采用目标导向策略，从任务的末端阶段开始训练，例如先将滑板固定并将机器人置于其上方，然后逐步放松条件以增加复杂度，使策略对滑板位置和方向变化具有鲁棒性。实验结果显示，该策略成功转移到移动滑板场景，并提供了开源代码（https://github.com/dancher00/quadruped-skateboard-mounting），为机器人学习复杂任务提供了新途径。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06561v1",
      "published_date": "2025-05-10 08:17:15 UTC",
      "updated_date": "2025-05-10 08:17:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:36:48.958943"
    },
    {
      "arxiv_id": "2505.07875v1",
      "title": "Getting Ready for the EU AI Act in Healthcare. A call for Sustainable AI Development and Deployment",
      "title_zh": "翻译失败",
      "authors": [
        "John Brandt Brodersen",
        "Ilaria Amelia Caggiano",
        "Pedro Kringen",
        "Vince Istvan Madai",
        "Walter Osika",
        "Giovanni Sartor",
        "Ellen Svensson",
        "Magnus Westerlund",
        "Roberto V. Zicari"
      ],
      "abstract": "Assessments of trustworthiness have become a cornerstone of responsible AI\ndevelopment. Especially in high-stakes fields like healthcare, aligning\ntechnical, evidence-based, and ethical practices with forthcoming legal\nrequirements is increasingly urgent. We argue that developers and deployers of\nAI systems for the medical domain should be proactive and take steps to\nprogressively ensure that such systems, both those currently in use and those\nbeing developed or planned, respect the requirements of the AI Act, which has\ncome into force in August 2024. This is necessary if full and effective\ncompliance is to be ensured when the most relevant provisions of the Act become\neffective (August 2026). The engagement with the AI Act cannot be viewed as a\nformalistic exercise. Compliance with the AI Act needs to be carried out\nthrough the proactive commitment to the ethical principles of trustworthy AI.\nThese principles provide the background for the Act, which mentions them\nseveral times and connects them to the protection of public interest. They can\nbe used to interpret and apply the Act's provisions and to identify good\npractices, increasing the validity and sustainability of AI systems over time.",
      "tldr_zh": "该论文呼吁医疗领域的AI开发者和部署者主动准备欧盟AI Act（EU AI Act），以确保AI系统符合即将于2026年生效的关键规定，从而实现负责任的AI发展。作者强调，将技术评估、证据基础和伦理实践与法律要求相结合，是构建可信赖AI（trustworthy AI）的关键，而不仅仅是形式化合规。论文指出，通过遵守AI Act中提到的伦理原则，可以提升AI系统的长期有效性和可持续性，尤其在高风险医疗环境中。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "K.4.1; K.5.2"
      ],
      "primary_category": "cs.CY",
      "comment": "8 pages, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2505.07875v1",
      "published_date": "2025-05-10 07:46:54 UTC",
      "updated_date": "2025-05-10 07:46:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:36:59.892046"
    },
    {
      "arxiv_id": "2505.06542v1",
      "title": "dcFCI: Robust Causal Discovery Under Latent Confounding, Unfaithfulness, and Mixed Data",
      "title_zh": "翻译失败",
      "authors": [
        "Adèle H. Ribeiro",
        "Dominik Heider"
      ],
      "abstract": "Causal discovery is central to inferring causal relationships from\nobservational data. In the presence of latent confounding, algorithms such as\nFast Causal Inference (FCI) learn a Partial Ancestral Graph (PAG) representing\nthe true model's Markov Equivalence Class. However, their correctness\ncritically depends on empirical faithfulness, the assumption that observed\n(in)dependencies perfectly reflect those of the underlying causal model, which\noften fails in practice due to limited sample sizes. To address this, we\nintroduce the first nonparametric score to assess a PAG's compatibility with\nobserved data, even with mixed variable types. This score is both necessary and\nsufficient to characterize structural uncertainty and distinguish between\ndistinct PAGs. We then propose data-compatible FCI (dcFCI), the first hybrid\ncausal discovery algorithm to jointly address latent confounding, empirical\nunfaithfulness, and mixed data types. dcFCI integrates our score into an\n(Anytime)FCI-guided search that systematically explores, ranks, and validates\ncandidate PAGs. Experiments on synthetic and real-world scenarios demonstrate\nthat dcFCI significantly outperforms state-of-the-art methods, often recovering\nthe true PAG even in small and heterogeneous datasets. Examining top-ranked\nPAGs further provides valuable insights into structural uncertainty, supporting\nmore robust and informed causal reasoning and decision-making.",
      "tldr_zh": "本文提出dcFCI算法，用于在潜在混杂(latent confounding)、经验不忠实(unfaithfulness)和混合数据(mixed data)条件下进行鲁棒的因果发现。dcFCI引入一个新的非参数评分方法，来评估Partial Ancestral Graph (PAG)与观察数据的兼容性，并将其整合到基于Fast Causal Inference (FCI)的搜索框架中，以系统探索、排名和验证候选PAG。实验结果显示，dcFCI在合成和真实场景中显著优于现有方法，即使在小样本和异质数据集上也能恢复真实PAG，并通过分析排名最高的PAG提供宝贵的结构不确定性洞见，支持更稳健的因果推理。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "31 pages. This work has been submitted to the IEEE for possible\n  publication",
      "pdf_url": "http://arxiv.org/pdf/2505.06542v1",
      "published_date": "2025-05-10 07:05:19 UTC",
      "updated_date": "2025-05-10 07:05:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:37:14.488502"
    },
    {
      "arxiv_id": "2505.06537v1",
      "title": "ProFashion: Prototype-guided Fashion Video Generation with Multiple Reference Images",
      "title_zh": "翻译失败",
      "authors": [
        "Xianghao Kong",
        "Qiaosong Qi",
        "Yuanbin Wang",
        "Anyi Rao",
        "Biaolong Chen",
        "Aixi Zhang",
        "Si Liu",
        "Hao Jiang"
      ],
      "abstract": "Fashion video generation aims to synthesize temporally consistent videos from\nreference images of a designated character. Despite significant progress,\nexisting diffusion-based methods only support a single reference image as\ninput, severely limiting their capability to generate view-consistent fashion\nvideos, especially when there are different patterns on the clothes from\ndifferent perspectives. Moreover, the widely adopted motion module does not\nsufficiently model human body movement, leading to sub-optimal spatiotemporal\nconsistency. To address these issues, we propose ProFashion, a fashion video\ngeneration framework leveraging multiple reference images to achieve improved\nview consistency and temporal coherency. To effectively leverage features from\nmultiple reference images while maintaining a reasonable computational cost, we\ndevise a Pose-aware Prototype Aggregator, which selects and aggregates global\nand fine-grained reference features according to pose information to form\nframe-wise prototypes, which serve as guidance in the denoising process. To\nfurther enhance motion consistency, we introduce a Flow-enhanced Prototype\nInstantiator, which exploits the human keypoint motion flow to guide an extra\nspatiotemporal attention process in the denoiser. To demonstrate the\neffectiveness of ProFashion, we extensively evaluate our method on the\nMRFashion-7K dataset we collected from the Internet. ProFashion also\noutperforms previous methods on the UBC Fashion dataset.",
      "tldr_zh": "该研究提出ProFashion框架，用于基于多个参考图像生成时尚视频，以提升视图一致性和时间连贯性。框架包括Pose-aware Prototype Aggregator模块，该模块根据姿势信息选择并聚合全局和细粒度参考特征，形成帧级原型，用于指导去噪过程；以及Flow-enhanced Prototype Instantiator模块，利用人体关键点运动流增强时空注意过程，以改善运动一致性。实验在自收集的MRFashion-7K数据集和UBC Fashion数据集上显示，ProFashion优于现有diffusion-based方法，在处理不同视角服装图案时表现出显著优势。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06537v1",
      "published_date": "2025-05-10 06:59:24 UTC",
      "updated_date": "2025-05-10 06:59:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:37:25.333418"
    },
    {
      "arxiv_id": "2505.06536v1",
      "title": "TACFN: Transformer-based Adaptive Cross-modal Fusion Network for Multimodal Emotion Recognition",
      "title_zh": "TACFN：基于 Transformer 的自适应跨模态融合网络用于多模态情感识别",
      "authors": [
        "Feng Liu",
        "Ziwang Fu",
        "Yunlong Wang",
        "Qijian Zheng"
      ],
      "abstract": "The fusion technique is the key to the multimodal emotion recognition task.\nRecently, cross-modal attention-based fusion methods have demonstrated high\nperformance and strong robustness. However, cross-modal attention suffers from\nredundant features and does not capture complementary features well. We find\nthat it is not necessary to use the entire information of one modality to\nreinforce the other during cross-modal interaction, and the features that can\nreinforce a modality may contain only a part of it. To this end, we design an\ninnovative Transformer-based Adaptive Cross-modal Fusion Network (TACFN).\nSpecifically, for the redundant features, we make one modality perform\nintra-modal feature selection through a self-attention mechanism, so that the\nselected features can adaptively and efficiently interact with another\nmodality. To better capture the complementary information between the\nmodalities, we obtain the fused weight vector by splicing and use the weight\nvector to achieve feature reinforcement of the modalities. We apply TCAFN to\nthe RAVDESS and IEMOCAP datasets. For fair comparison, we use the same unimodal\nrepresentations to validate the effectiveness of the proposed fusion method.\nThe experimental results show that TACFN brings a significant performance\nimprovement compared to other methods and reaches the state-of-the-art. All\ncode and models could be accessed from https://github.com/shuzihuaiyu/TACFN.",
      "tldr_zh": "该研究针对多模态情感识别中的融合技术问题，提出了基于 Transformer's Adaptive Cross-modal Fusion Network (TACFN)，通过自注意力机制进行模态内特征选择，以减少冗余特征并实现高效的跨模态交互。\nTACFN 进一步通过拼接获得融合权重向量，用于强化模态间的互补信息捕获。\n在 RAVDESS 和 IEMOCAP 数据集上的实验表明，该方法在相同的单模态表示下，比其他方法显著提升性能，达到了 state-of-the-art 水平。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "arXiv admin note: text overlap with arXiv:2111.02172",
      "pdf_url": "http://arxiv.org/pdf/2505.06536v1",
      "published_date": "2025-05-10 06:57:58 UTC",
      "updated_date": "2025-05-10 06:57:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:37:37.829822"
    },
    {
      "arxiv_id": "2505.06535v1",
      "title": "Online Feedback Efficient Active Target Discovery in Partially Observable Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Anindya Sarkar",
        "Binglin Ji",
        "Yevgeniy Vorobeychik"
      ],
      "abstract": "In various scientific and engineering domains, where data acquisition is\ncostly, such as in medical imaging, environmental monitoring, or remote\nsensing, strategic sampling from unobserved regions, guided by prior\nobservations, is essential to maximize target discovery within a limited\nsampling budget. In this work, we introduce Diffusion-guided Active Target\nDiscovery (DiffATD), a novel method that leverages diffusion dynamics for\nactive target discovery. DiffATD maintains a belief distribution over each\nunobserved state in the environment, using this distribution to dynamically\nbalance exploration-exploitation. Exploration reduces uncertainty by sampling\nregions with the highest expected entropy, while exploitation targets areas\nwith the highest likelihood of discovering the target, indicated by the belief\ndistribution and an incrementally trained reward model designed to learn the\ncharacteristics of the target. DiffATD enables efficient target discovery in a\npartially observable environment within a fixed sampling budget, all without\nrelying on any prior supervised training. Furthermore, DiffATD offers\ninterpretability, unlike existing black-box policies that require extensive\nsupervised training. Through extensive experiments and ablation studies across\ndiverse domains, including medical imaging and remote sensing, we show that\nDiffATD performs significantly better than baselines and competitively with\nsupervised methods that operate under full environmental observability.",
      "tldr_zh": "该研究针对数据采集成本高的领域（如医疗成像和遥感），提出了一种名为DiffATD的创新方法，用于在部分可观察环境中进行在线反馈高效的主动目标发现。DiffATD利用扩散动态维护未观察状态的信念分布，动态平衡exploration-exploitation策略，其中exploration通过采样高预期熵区域减少不确定性，exploitation则针对信念分布和增量训练的奖励模型来定位高可能性目标区域。该方法无需先验监督训练，提供可解释性，并在各种实验中表现出色，比基线方法显著提升性能，甚至与完全可观察的监督方法竞争。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.AI",
      "comment": "30 pages, 28 figures, Pre-print",
      "pdf_url": "http://arxiv.org/pdf/2505.06535v1",
      "published_date": "2025-05-10 06:50:01 UTC",
      "updated_date": "2025-05-10 06:50:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:37:49.045095"
    },
    {
      "arxiv_id": "2505.06527v1",
      "title": "Improving Generalization of Medical Image Registration Foundation Model",
      "title_zh": "提升医学图像配准基础模型的泛化能力",
      "authors": [
        "Jing Hu",
        "Kaiwei Yu",
        "Hongjiang Xian",
        "Shu Hu",
        "Xin Wang"
      ],
      "abstract": "Deformable registration is a fundamental task in medical image processing,\naiming to achieve precise alignment by establishing nonlinear correspondences\nbetween images. Traditional methods offer good adaptability and\ninterpretability but are limited by computational efficiency. Although deep\nlearning approaches have significantly improved registration speed and\naccuracy, they often lack flexibility and generalizability across different\ndatasets and tasks. In recent years, foundation models have emerged as a\npromising direction, leveraging large and diverse datasets to learn universal\nfeatures and transformation patterns for image registration, thus demonstrating\nstrong cross-task transferability. However, these models still face challenges\nin generalization and robustness when encountering novel anatomical structures,\nvarying imaging conditions, or unseen modalities. To address these limitations,\nthis paper incorporates Sharpness-Aware Minimization (SAM) into foundation\nmodels to enhance their generalization and robustness in medical image\nregistration. By optimizing the flatness of the loss landscape, SAM improves\nmodel stability across diverse data distributions and strengthens its ability\nto handle complex clinical scenarios. Experimental results show that foundation\nmodels integrated with SAM achieve significant improvements in cross-dataset\nregistration performance, offering new insights for the advancement of medical\nimage registration technology. Our code is available at\nhttps://github.com/Promise13/fm_sam}{https://github.com/Promise13/fm\\_sam.",
      "tldr_zh": "这篇论文针对医疗图像注册（Deformable registration）的基础模型（Foundation models）在不同数据集和任务中的泛化性和鲁棒性不足问题，提出将Sharpness-Aware Minimization (SAM)整合到模型中，以优化损失景观的平坦度并提升模型稳定性。SAM方法通过处理新解剖结构、成像条件和未见模态等挑战，帮助模型更好地适应复杂临床场景。实验结果显示，整合SAM后的基础模型在跨数据集注册性能上实现了显著改善，为医疗图像处理技术提供了新颖见解。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "IJCNN",
      "pdf_url": "http://arxiv.org/pdf/2505.06527v1",
      "published_date": "2025-05-10 06:14:09 UTC",
      "updated_date": "2025-05-10 06:14:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:38:01.760056"
    },
    {
      "arxiv_id": "2505.06520v2",
      "title": "PRUNE: A Patching Based Repair Framework for Certifiable Unlearning of Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Xuran Li",
        "Jingyi Wang",
        "Xiaohan Yuan",
        "Peixin Zhang",
        "Zhan Qin",
        "Zhibo Wang",
        "Kui Ren"
      ],
      "abstract": "It is often desirable to remove (a.k.a. unlearn) a specific part of the\ntraining data from a trained neural network model. A typical application\nscenario is to protect the data holder's right to be forgotten, which has been\npromoted by many recent regulation rules. Existing unlearning methods involve\ntraining alternative models with remaining data, which may be costly and\nchallenging to verify from the data holder or a thirdparty auditor's\nperspective. In this work, we provide a new angle and propose a novel\nunlearning approach by imposing carefully crafted \"patch\" on the original\nneural network to achieve targeted \"forgetting\" of the requested data to\ndelete. Specifically, inspired by the research line of neural network repair,\nwe propose to strategically seek a lightweight minimum \"patch\" for unlearning a\ngiven data point with certifiable guarantee. Furthermore, to unlearn a\nconsiderable amount of data points (or an entire class), we propose to\niteratively select a small subset of representative data points to unlearn,\nwhich achieves the effect of unlearning the whole set. Extensive experiments on\nmultiple categorical datasets demonstrates our approach's effectiveness,\nachieving measurable unlearning while preserving the model's performance and\nbeing competitive in efficiency and memory consumption compared to various\nbaseline methods.",
      "tldr_zh": "该论文提出PRUNE框架，这是一种基于修补的修复方法，用于实现神经网络的可证实unlearning，即通过在原模型上施加精心设计的轻量级“patch”来针对性地遗忘指定训练数据点。方法受神经网络修复研究启发，确保unlearning过程具有可证实的保证，并通过迭代选择小部分代表性数据点来扩展处理大量数据或整个类别。实验在多个分类数据集上验证了PRUNE的有效性，它实现了可衡量的遗忘效果，同时保持模型性能，并在效率和内存消耗上与基线方法具有竞争力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06520v2",
      "published_date": "2025-05-10 05:35:08 UTC",
      "updated_date": "2025-05-21 14:04:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:38:13.580464"
    },
    {
      "arxiv_id": "2505.06518v1",
      "title": "A Point-Based Algorithm for Distributional Reinforcement Learning in Partially Observable Domains",
      "title_zh": "一种基于点的算法，用于部分可观测域中的分布强化学习",
      "authors": [
        "Larry Preuett III"
      ],
      "abstract": "In many real-world planning tasks, agents must tackle uncertainty about the\nenvironment's state and variability in the outcomes of any chosen policy. We\naddress both forms of uncertainty as a first step toward safer algorithms in\npartially observable settings. Specifically, we extend Distributional\nReinforcement Learning (DistRL)-which models the entire return distribution for\nfully observable domains-to Partially Observable Markov Decision Processes\n(POMDPs), allowing an agent to learn the distribution of returns for each\nconditional plan. Concretely, we introduce new distributional Bellman operators\nfor partial observability and prove their convergence under the supremum\np-Wasserstein metric. We also propose a finite representation of these return\ndistributions via psi-vectors, generalizing the classical alpha-vectors in\nPOMDP solvers. Building on this, we develop Distributional Point-Based Value\nIteration (DPBVI), which integrates psi-vectors into a standard point-based\nbackup procedure-bridging DistRL and POMDP planning. By tracking return\ndistributions, DPBVI naturally enables risk-sensitive control in domains where\nrare, high-impact events must be carefully managed. We provide source code to\nfoster further research in robust decision-making under partial observability.",
      "tldr_zh": "本论文扩展了 Distributional Reinforcement Learning (DistRL) 到 Partially Observable Markov Decision Processes (POMDPs)，以处理真实世界规划任务中的环境状态不确定性和策略结果可变性。研究引入新的分布 Bellman operators，并证明其在 supremum p-Wasserstein metric 下的收敛性，同时提出 psi-vectors 作为返回分布的有限表示，类似于传统 POMDP 中的 alpha-vectors。基于此，开发了 Distributional Point-Based Value Iteration (DPBVI) 算法，将 psi-vectors 整合到点-based 备份程序中，实现风险敏感控制，尤其适用于管理稀有高影响事件的场景，并提供源代码以促进相关研究。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06518v1",
      "published_date": "2025-05-10 05:19:32 UTC",
      "updated_date": "2025-05-10 05:19:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:38:26.183141"
    },
    {
      "arxiv_id": "2505.06507v1",
      "title": "Text-to-CadQuery: A New Paradigm for CAD Generation with Scalable Large Model Capabilities",
      "title_zh": "翻译失败",
      "authors": [
        "Haoyang Xie",
        "Feng Ju"
      ],
      "abstract": "Computer-aided design (CAD) is fundamental to modern engineering and\nmanufacturing, but creating CAD models still requires expert knowledge and\nspecialized software. Recent advances in large language models (LLMs) open up\nthe possibility of generative CAD, where natural language is directly\ntranslated into parametric 3D models. However, most existing methods generate\ntask-specific command sequences that pretrained models cannot directly handle.\nThese sequences must be converted into CAD representations such as CAD vectors\nbefore a 3D model can be produced, which requires training models from scratch\nand adds unnecessary complexity. To tackle this issue, we propose generating\nCadQuery code directly from text, leveraging the strengths of pretrained LLMs\nto produce 3D models without intermediate representations, using this\nPython-based scripting language. Since LLMs already excel at Python generation\nand spatial reasoning, fine-tuning them on Text-to-CadQuery data proves highly\neffective. Given that these capabilities typically improve with scale, we\nhypothesize that larger models will perform better after fine-tuning. To enable\nthis, we augment the Text2CAD dataset with 170,000 CadQuery annotations. We\nfine-tune six open-source LLMs of varying sizes and observe consistent\nimprovements. Our best model achieves a top-1 exact match of 69.3%, up from\n58.8%, and reduces Chamfer Distance by 48.6%. Project page:\nhttps://github.com/Text-to-CadQuery/Text-to-CadQuery.",
      "tldr_zh": "该论文提出了一种名为 Text-to-CadQuery 的新范式，利用大型语言模型 (LLMs) 通过自然语言直接生成 CadQuery 代码，从而简化计算机辅助设计 (CAD) 模型的创建过程，避免了传统方法中的中间表示复杂性。研究者通过扩充 Text2CAD 数据集（添加17万条 CadQuery 注释）并微调六种不同规模的开源 LLMs，充分利用这些模型在 Python 生成和空间推理方面的优势，假设更大模型在微调后表现更好。实验结果显示，最佳模型的 top-1 精确匹配率从58.8% 提高到69.3%，Chamfer Distance 减少48.6%，证明了这一方法的有效性和可扩展性。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06507v1",
      "published_date": "2025-05-10 04:47:08 UTC",
      "updated_date": "2025-05-10 04:47:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:38:39.382995"
    },
    {
      "arxiv_id": "2505.06505v1",
      "title": "On Definite Iterated Belief Revision with Belief Algebras",
      "title_zh": "翻译失败",
      "authors": [
        "Hua Meng",
        "Zhiguo Long",
        "Michael Sioutis",
        "Zhengchun Zhou"
      ],
      "abstract": "Traditional logic-based belief revision research focuses on designing rules\nto constrain the behavior of revision operators. Frameworks have been proposed\nto characterize iterated revision rules, but they are often too loose, leading\nto multiple revision operators that all satisfy the rules under the same belief\ncondition. In many practical applications, such as safety critical ones, it is\nimportant to specify a definite revision operator to enable agents to\niteratively revise their beliefs in a deterministic way. In this paper, we\npropose a novel framework for iterated belief revision by characterizing belief\ninformation through preference relations. Semantically, both beliefs and new\nevidence are represented as belief algebras, which provide a rich and\nexpressive foundation for belief revision. Building on traditional revision\nrules, we introduce additional postulates for revision with belief algebra,\nincluding an upper-bound constraint on the outcomes of revision. We prove that\nthe revision result is uniquely determined given the current belief state and\nnew evidence. Furthermore, to make the framework more useful in practice, we\ndevelop a particular algorithm for performing the proposed revision process. We\nargue that this approach may offer a more predictable and principled method for\nbelief revision, making it suitable for real-world applications.",
      "tldr_zh": "本研究针对传统信念修正框架的宽松性问题，提出了一种基于偏好关系和belief algebras的确定性迭代信念修正框架，以确保修正操作符在安全关键应用中实现可预测的确定性行为。论文将信念和新证据语义上表示为belief algebras，并引入额外假设（如修正结果的上限约束），证明给定当前信念状态和新证据，修正结果是唯一的。此外，该框架开发了一个具体算法来执行修正过程，提供一种更原则性和实用的方法，适用于实际场景。",
      "categories": [
        "cs.AI",
        "I.2.4"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages. Extended version of an accepted IJCAI 2025 paper",
      "pdf_url": "http://arxiv.org/pdf/2505.06505v1",
      "published_date": "2025-05-10 04:34:43 UTC",
      "updated_date": "2025-05-10 04:34:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:38:49.826125"
    },
    {
      "arxiv_id": "2505.06503v1",
      "title": "Attention Mechanisms in Dynamical Systems: A Case Study with Predator-Prey Models",
      "title_zh": "翻译失败",
      "authors": [
        "David Balaban"
      ],
      "abstract": "Attention mechanisms are widely used in artificial intelligence to enhance\nperformance and interpretability. In this paper, we investigate their utility\nin modeling classical dynamical systems -- specifically, a noisy predator-prey\n(Lotka-Volterra) system. We train a simple linear attention model on perturbed\ntime-series data to reconstruct system trajectories. Remarkably, the learned\nattention weights align with the geometric structure of the Lyapunov function:\nhigh attention corresponds to flat regions (where perturbations have small\neffect), and low attention aligns with steep regions (where perturbations have\nlarge effect). We further demonstrate that attention-based weighting can serve\nas a proxy for sensitivity analysis, capturing key phase-space properties\nwithout explicit knowledge of the system equations. These results suggest a\nnovel use of AI-derived attention for interpretable, data-driven analysis and\ncontrol of nonlinear systems. For example our framework could support future\nwork in biological modeling of circadian rhythms, and interpretable machine\nlearning for dynamical environments.",
      "tldr_zh": "本研究探讨了attention mechanisms在经典动力系统中的应用，以嘈杂的捕食者-猎物(Lotka-Volterra)模型为例，通过训练一个简单的线性attention模型来重建扰动的时间序列数据。结果显示，学到的attention权重与Lyapunov函数的几何结构高度一致：高attention对应扰动影响小的平坦区域，而低attention对应影响大的陡峭区域。进一步发现，attention机制可作为敏感性分析的代理，捕捉相空间的关键属性，从而实现可解释的数据驱动分析和控制非线性系统，并为生物建模（如昼夜节律）和可解释机器学习提供新框架。",
      "categories": [
        "math.DS",
        "cs.AI",
        "es: 92B05 (Primary), 34C60, 37N25, 68T07, 93B30 (Secondary)"
      ],
      "primary_category": "math.DS",
      "comment": "5 figures, 12 pages, python code included",
      "pdf_url": "http://arxiv.org/pdf/2505.06503v1",
      "published_date": "2025-05-10 04:14:28 UTC",
      "updated_date": "2025-05-10 04:14:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:39:02.680224"
    },
    {
      "arxiv_id": "2505.06496v1",
      "title": "xGen-small Technical Report",
      "title_zh": "xGen-small 技术报告",
      "authors": [
        "Erik Nijkamp",
        "Bo Pang",
        "Egor Pakhomov",
        "Akash Gokul",
        "Jin Qu",
        "Silvio Savarese",
        "Yingbo Zhou",
        "Caiming Xiong"
      ],
      "abstract": "We introduce xGen-small, a family of 4B and 9B Transformer decoder models\noptimized for long-context applications. Our vertically integrated pipeline\nunites domain-balanced, frequency-aware data curation; multi-stage pre-training\nwith quality annealing and length extension to 128k tokens; and targeted\npost-training via supervised fine-tuning, preference learning, and online\nreinforcement learning. xGen-small delivers strong performance across various\ntasks, especially in math and coding domains, while excelling at long context\nbenchmarks.",
      "tldr_zh": "我们介绍了 xGen-small，一系列 4B 和 9B 的 Transformer decoder 模型，针对长上下文应用进行了优化。模型采用垂直整合的管道，包括领域平衡、频率感知的数据整理；多阶段预训练（如质量退火和长度扩展到 128k tokens）；以及针对性的后训练方法，包括监督微调、偏好学习和在线强化学习。实验结果显示，xGen-small 在数学和编码任务上表现出色，并在长上下文基准上表现出色整体性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06496v1",
      "published_date": "2025-05-10 02:54:16 UTC",
      "updated_date": "2025-05-10 02:54:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:39:13.771054"
    },
    {
      "arxiv_id": "2505.06493v1",
      "title": "System Prompt Poisoning: Persistent Attacks on Large Language Models Beyond User Injection",
      "title_zh": "系统提示投毒：超越用户注入的针对大型语言模型的持续攻击",
      "authors": [
        "Jiawei Guo",
        "Haipeng Cai"
      ],
      "abstract": "Large language models (LLMs) have gained widespread adoption across diverse\napplications due to their impressive generative capabilities. Their\nplug-and-play nature enables both developers and end users to interact with\nthese models through simple prompts. However, as LLMs become more integrated\ninto various systems in diverse domains, concerns around their security are\ngrowing. Existing studies mainly focus on threats arising from user prompts\n(e.g. prompt injection attack) and model output (e.g. model inversion attack),\nwhile the security of system prompts remains largely overlooked. This work\nbridges the critical gap. We introduce system prompt poisoning, a new attack\nvector against LLMs that, unlike traditional user prompt injection, poisons\nsystem prompts hence persistently impacts all subsequent user interactions and\nmodel responses. We systematically investigate four practical attack strategies\nin various poisoning scenarios. Through demonstration on both generative and\nreasoning LLMs, we show that system prompt poisoning is highly feasible without\nrequiring jailbreak techniques, and effective across a wide range of tasks,\nincluding those in mathematics, coding, logical reasoning, and natural language\nprocessing. Importantly, our findings reveal that the attack remains effective\neven when user prompts employ advanced prompting techniques like\nchain-of-thought (CoT). We also show that such techniques, including CoT and\nretrieval-augmentation-generation (RAG), which are proven to be effective for\nimproving LLM performance in a wide range of tasks, are significantly weakened\nin their effectiveness by system prompt poisoning.",
      "tldr_zh": "本研究引入了“system prompt poisoning”作为一种新型攻击向量，针对大型语言模型（LLMs）的系统提示进行持久性投毒，从而影响所有后续用户互动，而非仅限于用户提示注入。研究者系统调查了四种实际攻击策略，并在生成和推理LLMs上进行实验，证明这种攻击在数学、编码、逻辑推理和自然语言处理等任务中高度可行，且无需越狱技术。结果显示，即使采用chain-of-thought (CoT) 等高级提示技术，攻击仍保持有效性，并显著削弱了CoT和retrieval-augmentation-generation (RAG)等方法的性能防护能力。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06493v1",
      "published_date": "2025-05-10 02:31:26 UTC",
      "updated_date": "2025-05-10 02:31:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:39:25.312203"
    },
    {
      "arxiv_id": "2505.06492v1",
      "title": "SmartPilot: A Multiagent CoPilot for Adaptive and Intelligent Manufacturing",
      "title_zh": "翻译失败",
      "authors": [
        "Chathurangi Shyalika",
        "Renjith Prasad",
        "Alaa Al Ghazo",
        "Darssan Eswaramoorthi",
        "Harleen Kaur",
        "Sara Shree Muthuselvam",
        "Amit Sheth"
      ],
      "abstract": "In the dynamic landscape of Industry 4.0, achieving efficiency, precision,\nand adaptability is essential to optimize manufacturing operations. Industries\nsuffer due to supply chain disruptions caused by anomalies, which are being\ndetected by current AI models but leaving domain experts uncertain without\ndeeper insights into these anomalies. Additionally, operational inefficiencies\npersist due to inaccurate production forecasts and the limited effectiveness of\ntraditional AI models for processing complex sensor data. Despite these\nadvancements, existing systems lack the seamless integration of these\ncapabilities needed to create a truly unified solution for enhancing production\nand decision-making. We propose SmartPilot, a neurosymbolic, multiagent CoPilot\ndesigned for advanced reasoning and contextual decision-making to address these\nchallenges. SmartPilot processes multimodal sensor data and is compact to\ndeploy on edge devices. It focuses on three key tasks: anomaly prediction,\nproduction forecasting, and domain-specific question answering. By bridging the\ngap between AI capabilities and real-world industrial needs, SmartPilot\nempowers industries with intelligent decision-making and drives transformative\ninnovation in manufacturing. The demonstration video, datasets, and\nsupplementary materials are available at\nhttps://github.com/ChathurangiShyalika/SmartPilot.",
      "tldr_zh": "在 Industry 4.0 的动态环境中，制造行业面临供应链异常检测缺乏洞见、生产预测不准确以及传统 AI 处理复杂传感器数据效率低的问题。为解决这些挑战，我们提出 SmartPilot，一种神经符号多智能体 CoPilot，具备高级推理和情境决策能力，能够处理多模态传感器数据并部署在边缘设备。SmartPilot 专注于三个关键任务：anomaly prediction、生产预测和领域特定问答，从而桥接 AI 与实际工业需求，提升决策效率并推动制造创新。实验资源如演示视频和数据集可从 GitHub 获取。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 8 figures, 4 tables, IEEE Conference on Artificial\n  Intelligence (IEEE CAI) 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.06492v1",
      "published_date": "2025-05-10 02:20:49 UTC",
      "updated_date": "2025-05-10 02:20:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:39:37.660101"
    },
    {
      "arxiv_id": "2505.06482v2",
      "title": "Video-Enhanced Offline Reinforcement Learning: A Model-Based Approach",
      "title_zh": "视频增强离线强化学习：基于模型",
      "authors": [
        "Minting Pan",
        "Yitao Zheng",
        "Jiajian Li",
        "Yunbo Wang",
        "Xiaokang Yang"
      ],
      "abstract": "Offline reinforcement learning (RL) enables policy optimization using static\ndatasets, avoiding the risks and costs of extensive real-world exploration.\nHowever, it struggles with suboptimal offline behaviors and inaccurate value\nestimation due to the lack of environmental interaction. We present\nVideo-Enhanced Offline RL (VeoRL), a model-based method that constructs an\ninteractive world model from diverse, unlabeled video data readily available\nonline. Leveraging model-based behavior guidance, our approach transfers\ncommonsense knowledge of control policy and physical dynamics from natural\nvideos to the RL agent within the target domain. VeoRL achieves substantial\nperformance gains (over 100% in some cases) across visual control tasks in\nrobotic manipulation, autonomous driving, and open-world video games.",
      "tldr_zh": "本文提出 Video-Enhanced Offline Reinforcement Learning (VeoRL)，一种基于模型的方法，用于解决离线强化学习(Offline RL)中子优行为和价值估计不准确的问题，通过从在线多样无标签视频数据构建交互式世界模型。VeoRL 利用模型-based 行为指导，将自然视频中的常识知识（如控制策略和物理动态）转移到目标领域的 RL 代理。实验结果显示，在机器人操作、自动驾驶和开放世界视频游戏等视觉控制任务中，VeoRL 实现了显著性能提升，某些场景超过 100%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06482v2",
      "published_date": "2025-05-10 00:54:12 UTC",
      "updated_date": "2025-05-17 09:20:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:39:48.970997"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 47,
  "processed_papers_count": 47,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-24T21:40:08.701922"
}