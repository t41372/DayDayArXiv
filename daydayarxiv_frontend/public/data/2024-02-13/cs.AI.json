{
  "date": "2024-02-13",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-02-13 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文聚焦于 AI 和机器学习的创新应用，包括大型语言模型（LLMs）在写作、医疗诊断和推荐系统中的潜力，AI 模型的泛化与鲁棒性挑战，以及强化学习在机器人和决策优化中的进展；令人印象深刻的文章包括基于 LLM 的医疗诊断优化和 AI 公平性研究，而知名学者如 Marc G. Bellemare 和 Dieter Fox 的参与进一步提升了学术影响力。\n\n### 重点论文讨论\n我们挑选了今天几篇最具话题度和影响力的论文，先从 LLM 应用和 AI 泛化入手，再扩展到医疗和机器人领域。其他论文如纯理论模型或小众主题（如特定算法优化），我们快速掠过，仅提及核心点。\n\n1. **GhostWriter: Augmenting Collaborative Human-AI Writing Experiences Through Personalization and Agency**  \n   这篇论文探讨了 LLM 在写作辅助中的个性化控制。贡献在于引入 GhostWriter 系统，利用 LLM 学习用户写作风格，提供多方式输出控制，并通过 18 名参与者的实验证明了其在编辑和创意任务中的有效性，强调了 AI 在提升用户代理力的潜力。\n\n2. **Hybrid Inverse Reinforcement Learning**  \n   作者包括知名学者 J. Andrew Bagnell。论文提出混合逆强化学习方法，减少不必要的探索以提高样本效率。关键发现是通过专家数据聚焦学习，显著提升了连续控制任务的性能，相比标准逆强化学习减少了交互次数，提供更强的鲁棒性保证。\n\n3. **An Embarrassingly Simple Approach for LLM with Strong ASR Capacity**  \n   论文简化了 LLM 在自动语音识别（ASR）中的设计，仅训练线性投影器就实现了高性能。贡献包括构建 SLAM-ASR 系统，在 LibriSpeech 数据集上超越现有 LLM 模型，甚至在跨模态任务中表现出色，展示了 LLM 在语音领域的泛化潜力。\n\n4. **Combining Insights From Multiple Large Language Models Improves Diagnostic Accuracy**  \n   作者团队包括多名 AI 医疗专家。论文使用集体智能方法聚合多个 LLM（如 GPT-4 和 PaLM 2）的诊断结果，显著提高了临床案例的准确率（从 59% 到 75%），为 LLM 在医疗决策支持中的应用提供了新路径，避免了对单一模型的依赖。\n\n5. **eCeLLM: Generalizing Large Language Models for E-commerce from Large-scale, High-quality Instruction Data**  \n   论文由 Huan Sun 和 Xia Ning 等学者主导，构建了 eCeLLM 模型和 ECInstruct 数据集。关键发现是，通过指令微调，eCeLLM 在电商任务中超越 GPT-4 和任务特定模型，尤其在泛化到新产品和指令时表现出色，促进了 LLM 在商业领域的实际应用。\n\n6. **ChatGPT vs LLaMA: Impact, Reliability, and Challenges in Stack Overflow Discussions**  \n   这篇快速讨论了 LLM 在开发者社区中的影响。贡献在于实验比较 ChatGPT 和 LLaMA 在代码问题上的表现，发现它们虽挑战人类专家但在某些领域表现不佳，并分析了用户参与度和潜在风险，强调了 LLM 可靠性的改进需求。\n\n7. **Mitigating Object Hallucination in Large Vision-Language Models via Classifier-Free Guidance**  \n   论文提出 MARINE 框架，使用分类器无指导方法减少视觉语言模型中的物体幻觉。发现通过整合开源视觉模型，显著提升了生成精度，并在无训练数据场景下超越基线，适用于高风险应用如医疗图像分析。\n\n8. **IM-3D: Iterative Multiview Diffusion and Reconstruction for High-Quality 3D Generation**  \n   作者包括 Andrea Vedaldi 和 Oran Gafni。论文创新性地结合扩散模型和 3D 重建，减少了生成计算量并提升质量。关键发现是 IM-3D 在文本到 3D 生成中表现出色，减少了伪影，提供更高效的 3D 资产生成方法。\n\n### 其他快速掠过\n今天还有一些论文涉及强化学习（如在农业或机器人路径规划中的应用）和 AI 泛化（如 OOD 泛化分析），但它们相对小众或重复现有工作，因此仅简要提及：例如，\"Intelligent Agricultural Management Considering N$_2$O Emission and Climate Variability with Uncertainties\" 使用强化学习优化农业决策，考虑不确定性；\"Epistemic Exploration for Generalizable Planning and Learning in Non-Stationary Settings\" 探讨了 AI 在动态环境中的探索策略。这些论文的核心在于提升模型鲁棒性，但影响力不如上述重点文章。\n\n总之，今天的 arXiv 论文突显了 AI 模型在实际应用中的潜力与挑战，LLM 的创新应用和泛化问题值得持续关注。如果你对特定领域感兴趣，建议优先查看这些论文！",
  "papers": [
    {
      "arxiv_id": "2402.08855v2",
      "title": "GhostWriter: Augmenting Collaborative Human-AI Writing Experiences Through Personalization and Agency",
      "title_zh": "翻译失败",
      "authors": [
        "Catherine Yeh",
        "Gonzalo Ramos",
        "Rachel Ng",
        "Andy Huntington",
        "Richard Banks"
      ],
      "abstract": "Writing is a well-established practice to support ideation and creativity.\nWhile Large Language Models (LLMs) have become ubiquitous in providing\ndifferent kinds of writing assistance to different writers, LLM-powered writing\nsystems often fall short in capturing the nuanced personalization and control\nnecessary for effective support and creative exploration. To address these\nchallenges, we introduce GhostWriter, an AI-enhanced writing design probe that\nenables users to exercise enhanced agency and personalization. GhostWriter\nleverages LLMs to implicitly learn the user's intended writing style for\nseamless personalization, while exposing explicit teaching moments for style\nrefinement and reflection. We study 18 participants who use GhostWriter for\nediting and creative tasks, observing that it helps users craft personalized\ntext and empowers them by providing multiple ways to steer system output. Based\non this study, we present insights on people's relationships with AI-assisted\nwriting and offer design recommendations to promote user agency in similar\nco-creative systems.",
      "tldr_zh": "该研究介绍了 GhostWriter，一种增强人类-AI 协作写作系统的设计探针，旨在通过个性化学习和用户代理解决大语言模型 (LLMs) 在写作辅助中的不足。GhostWriter 利用 LLMs 隐式学习用户的写作风格，实现无缝个性化，同时提供显式教学机制来精炼风格并促进反思。在一项涉及 18 名参与者的研究中，该系统帮助用户创建个性化文本，并通过多种方式引导输出，揭示了人与 AI 辅助写作的关系，并提出设计推荐以提升类似合作系统中的用户代理。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "23 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.08855v2",
      "published_date": "2024-02-13 23:48:59 UTC",
      "updated_date": "2025-03-23 19:08:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:44:15.331853"
    },
    {
      "arxiv_id": "2402.08848v2",
      "title": "Hybrid Inverse Reinforcement Learning",
      "title_zh": "混合逆强化学习",
      "authors": [
        "Juntao Ren",
        "Gokul Swamy",
        "Zhiwei Steven Wu",
        "J. Andrew Bagnell",
        "Sanjiban Choudhury"
      ],
      "abstract": "The inverse reinforcement learning approach to imitation learning is a\ndouble-edged sword. On the one hand, it can enable learning from a smaller\nnumber of expert demonstrations with more robustness to error compounding than\nbehavioral cloning approaches. On the other hand, it requires that the learner\nrepeatedly solve a computationally expensive reinforcement learning (RL)\nproblem. Often, much of this computation is wasted searching over policies very\ndissimilar to the expert's. In this work, we propose using hybrid RL --\ntraining on a mixture of online and expert data -- to curtail unnecessary\nexploration. Intuitively, the expert data focuses the learner on good states\nduring training, which reduces the amount of exploration required to compute a\nstrong policy. Notably, such an approach doesn't need the ability to reset the\nlearner to arbitrary states in the environment, a requirement of prior work in\nefficient inverse RL. More formally, we derive a reduction from inverse RL to\nexpert-competitive RL (rather than globally optimal RL) that allows us to\ndramatically reduce interaction during the inner policy search loop while\nmaintaining the benefits of the IRL approach. This allows us to derive both\nmodel-free and model-based hybrid inverse RL algorithms with strong policy\nperformance guarantees. Empirically, we find that our approaches are\nsignificantly more sample efficient than standard inverse RL and several other\nbaselines on a suite of continuous control tasks.",
      "tldr_zh": "本论文提出了一种Hybrid Inverse Reinforcement Learning方法，以解决传统逆强化学习（Inverse RL）在模仿学习中的计算浪费问题。该方法通过在在线数据和专家数据混合训练来减少不必要的探索，从而聚焦于良好状态并提高样本效率。与以往方法不同，它无需重置学习者到任意环境状态，而是将Inverse RL归约到专家竞争RL（expert-competitive RL），并开发了无模型和有模型的混合算法，提供强有力的策略性能保证。实验结果显示，该方法在连续控制任务上显著优于标准Inverse RL和其他基线，实现了更高的样本效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08848v2",
      "published_date": "2024-02-13 23:29:09 UTC",
      "updated_date": "2024-06-05 00:17:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:44:27.284743"
    },
    {
      "arxiv_id": "2402.08846v1",
      "title": "An Embarrassingly Simple Approach for LLM with Strong ASR Capacity",
      "title_zh": "一种尴尬",
      "authors": [
        "Ziyang Ma",
        "Guanrou Yang",
        "Yifan Yang",
        "Zhifu Gao",
        "Jiaming Wang",
        "Zhihao Du",
        "Fan Yu",
        "Qian Chen",
        "Siqi Zheng",
        "Shiliang Zhang",
        "Xie Chen"
      ],
      "abstract": "In this paper, we focus on solving one of the most important tasks in the\nfield of speech processing, i.e., automatic speech recognition (ASR), with\nspeech foundation encoders and large language models (LLM). Recent works have\ncomplex designs such as compressing the output temporally for the speech\nencoder, tackling modal alignment for the projector, and utilizing\nparameter-efficient fine-tuning for the LLM. We found that delicate designs are\nnot necessary, while an embarrassingly simple composition of off-the-shelf\nspeech encoder, LLM, and the only trainable linear projector is competent for\nthe ASR task. To be more specific, we benchmark and explore various\ncombinations of LLMs and speech encoders, leading to the optimal LLM-based ASR\nsystem, which we call SLAM-ASR. The proposed SLAM-ASR provides a clean setup\nand little task-specific design, where only the linear projector is trained. To\nthe best of our knowledge, SLAM-ASR achieves the best performance on the\nLibrispeech benchmark among LLM-based ASR models and even outperforms the\nlatest LLM-based audio-universal model trained on massive pair data. Finally,\nwe explore the capability emergence of LLM-based ASR in the process of modal\nalignment. We hope that our study can facilitate the research on extending LLM\nwith cross-modality capacity and shed light on the LLM-based ASR community.",
      "tldr_zh": "本研究提出了一种简单的方法，利用现成的语音编码器和大型语言模型（LLM）来构建高效的自动语音识别（ASR）系统，核心是仅训练一个线性投影器（linear projector），而非复杂的模块设计。该方法命名为 SLAM-ASR，通过基准测试探索不同 LLM 和语音编码器的组合，在 LibriSpeech 数据集上实现了最佳性能，甚至超过了基于海量数据的音频通用模型。实验结果展示了模态对齐（modal alignment）过程中 LLM 能力的涌现（capability emergence），为扩展 LLM 的跨模态能力提供了新见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.MM",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "Working in progress and will open-source soon",
      "pdf_url": "http://arxiv.org/pdf/2402.08846v1",
      "published_date": "2024-02-13 23:25:04 UTC",
      "updated_date": "2024-02-13 23:25:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:44:39.359876"
    },
    {
      "arxiv_id": "2402.08832v1",
      "title": "Intelligent Agricultural Management Considering N$_2$O Emission and Climate Variability with Uncertainties",
      "title_zh": "翻译失败",
      "authors": [
        "Zhaoan Wang",
        "Shaoping Xiao",
        "Jun Wang",
        "Ashwin Parab",
        "Shivam Patel"
      ],
      "abstract": "This study examines how artificial intelligence (AI), especially\nReinforcement Learning (RL), can be used in farming to boost crop yields,\nfine-tune nitrogen use and watering, and reduce nitrate runoff and greenhouse\ngases, focusing on Nitrous Oxide (N$_2$O) emissions from soil. Facing climate\nchange and limited agricultural knowledge, we use Partially Observable Markov\nDecision Processes (POMDPs) with a crop simulator to model AI agents'\ninteractions with farming environments. We apply deep Q-learning with Recurrent\nNeural Network (RNN)-based Q networks for training agents on optimal actions.\nAlso, we develop Machine Learning (ML) models to predict N$_2$O emissions,\nintegrating these predictions into the simulator. Our research tackles\nuncertainties in N$_2$O emission estimates with a probabilistic ML approach and\nclimate variability through a stochastic weather model, offering a range of\nemission outcomes to improve forecast reliability and decision-making. By\nincorporating climate change effects, we enhance agents' climate adaptability,\naiming for resilient agricultural practices. Results show these agents can\nalign crop productivity with environmental concerns by penalizing N$_2$O\nemissions, adapting effectively to climate shifts like warmer temperatures and\nless rain. This strategy improves farm management under climate change,\nhighlighting AI's role in sustainable agriculture.",
      "tldr_zh": "本研究探讨了使用人工智能（AI），特别是 Reinforcement Learning (RL)，来优化农业管理，提高作物产量、优化氮肥和灌溉，同时减少硝酸盐径流和 Nitrous Oxide (N$_2$O) 等温室气体排放。研究采用 Partially Observable Markov Decision Processes (POMDPs) 和作物模拟器来模拟 AI 代理与环境的交互，并通过 deep Q-learning 与 Recurrent Neural Network (RNN)-based Q 网络训练代理。Machine Learning (ML) 模型被开发用于预测 N$_2$O 排放，并通过 probabilistic ML 方法处理排放不确定性，以及 stochastic weather 模型应对气候变异性，以提升决策可靠性。结果显示，该方法使代理能够平衡作物生产力和环境影响，通过惩罚 N$_2$O 排放并适应气候变化（如更温暖的温度和更少降雨），从而推动可持续农业实践。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08832v1",
      "published_date": "2024-02-13 22:29:40 UTC",
      "updated_date": "2024-02-13 22:29:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:44:53.301025"
    },
    {
      "arxiv_id": "2402.08831v2",
      "title": "eCeLLM: Generalizing Large Language Models for E-commerce from Large-scale, High-quality Instruction Data",
      "title_zh": "翻译失败",
      "authors": [
        "Bo Peng",
        "Xinyi Ling",
        "Ziru Chen",
        "Huan Sun",
        "Xia Ning"
      ],
      "abstract": "With tremendous efforts on developing effective e-commerce models,\nconventional e-commerce models show limited success in generalist e-commerce\nmodeling, and suffer from unsatisfactory performance on new users and new\nproducts - a typical out-of-domain generalization challenge. Meanwhile, large\nlanguage models (LLMs) demonstrate outstanding performance in generalist\nmodeling and out-of-domain generalizability in many fields. Toward fully\nunleashing their power for e-commerce, in this paper, we construct ECInstruct,\nthe first open-sourced, large-scale, and high-quality benchmark instruction\ndataset for e-commerce. Leveraging ECInstruct, we develop eCeLLM, a series of\ne-commerce LLMs, by instruction-tuning general-purpose LLMs. Our comprehensive\nexperiments and evaluation demonstrate that eCeLLM models substantially\noutperform baseline models, including the most advanced GPT-4, and the\nstate-of-the-art task-specific models in in-domain evaluation. Moreover, eCeLLM\nexhibits excellent generalizability to out-of-domain settings, including unseen\nproducts and unseen instructions, highlighting its superiority as a generalist\ne-commerce model. Both the ECInstruct dataset and the eCeLLM models show great\npotential in empowering versatile and effective LLMs for e-commerce. ECInstruct\nand eCeLLM models are publicly accessible through\nhttps://ninglab.github.io/eCeLLM.",
      "tldr_zh": "该论文针对电商领域的泛化挑战，构建了首个开源的大型、高质量指令数据集ECInstruct，以提升Large Language Models (LLMs)在电商建模中的性能。作者通过instruction-tuning对一般用途LLMs进行微调，开发了eCeLLM系列模型，这些模型在领域内评估中大幅超越基线模型，包括GPT-4和最先进的任务特定模型。实验结果显示，eCeLLM在out-of-domain场景（如未见产品和指令）中表现出色，证明其作为通用电商模型的优越性，并通过公开资源推动电商LLMs的应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "ICML 2024; Bo Peng and Xinyi Ling contributed equally to this paper",
      "pdf_url": "http://arxiv.org/pdf/2402.08831v2",
      "published_date": "2024-02-13 22:26:24 UTC",
      "updated_date": "2024-08-03 23:29:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:45:04.520146"
    },
    {
      "arxiv_id": "2402.08812v3",
      "title": "Intelligent Canvas: Enabling Design-Like Exploratory Visual Data Analysis with Generative AI through Rapid Prototyping, Iteration and Curation",
      "title_zh": "翻译失败",
      "authors": [
        "Zijian Ding",
        "Joel Chan"
      ],
      "abstract": "Complex data analysis inherently seeks unexpected insights through\nexploratory visual analysis methods, transcending logical, step-by-step\nprocessing. However, existing interfaces such as notebooks and dashboards have\nlimitations in exploration and comparison for visual data analysis. Addressing\nthese limitations, we introduce a \"design-like\" intelligent canvas environment\nintegrating generative AI into data analysis, offering rapid prototyping,\niteration, and comparative visualization management. Our dual contributions\ninclude the integration of generative AI components into a canvas interface,\nand empirical findings from a user study (N=10) evaluating the effectiveness of\nthe canvas interface.",
      "tldr_zh": "本研究针对现有数据分析界面（如笔记本和仪表板）在探索性视觉数据分析（exploratory visual data analysis）中的局限性，提出Intelligent Canvas——一个整合生成AI（generative AI）的“设计-like”环境，支持快速原型设计（rapid prototyping）、迭代（iteration）和比较可视化管理（curation）。该系统的主要贡献包括将生成AI组件嵌入画布界面，以及通过用户研究（N=10）获得的实证发现，证明了其在提升数据探索效率方面的有效性。整体设计旨在超越传统的步步逻辑处理，促进意外洞见的发现。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08812v3",
      "published_date": "2024-02-13 21:33:12 UTC",
      "updated_date": "2024-03-21 16:44:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:45:15.679661"
    },
    {
      "arxiv_id": "2402.08806v1",
      "title": "Combining Insights From Multiple Large Language Models Improves Diagnostic Accuracy",
      "title_zh": "结合多个大型语言模型的洞见以提高诊断准确性",
      "authors": [
        "Gioele Barabucci",
        "Victor Shia",
        "Eugene Chu",
        "Benjamin Harack",
        "Nathan Fu"
      ],
      "abstract": "Background: Large language models (LLMs) such as OpenAI's GPT-4 or Google's\nPaLM 2 are proposed as viable diagnostic support tools or even spoken of as\nreplacements for \"curbside consults\". However, even LLMs specifically trained\non medical topics may lack sufficient diagnostic accuracy for real-life\napplications.\n  Methods: Using collective intelligence methods and a dataset of 200 clinical\nvignettes of real-life cases, we assessed and compared the accuracy of\ndifferential diagnoses obtained by asking individual commercial LLMs (OpenAI\nGPT-4, Google PaLM 2, Cohere Command, Meta Llama 2) against the accuracy of\ndifferential diagnoses synthesized by aggregating responses from combinations\nof the same LLMs.\n  Results: We find that aggregating responses from multiple, various LLMs leads\nto more accurate differential diagnoses (average accuracy for 3 LLMs:\n$75.3\\%\\pm 1.6pp$) compared to the differential diagnoses produced by single\nLLMs (average accuracy for single LLMs: $59.0\\%\\pm 6.1pp$).\n  Discussion: The use of collective intelligence methods to synthesize\ndifferential diagnoses combining the responses of different LLMs achieves two\nof the necessary steps towards advancing acceptance of LLMs as a diagnostic\nsupport tool: (1) demonstrate high diagnostic accuracy and (2) eliminate\ndependence on a single commercial vendor.",
      "tldr_zh": "这篇论文探讨了通过结合多个大型语言模型 (LLMs) 的见解来提升诊断准确性的方法，针对现有 LLMs（如 GPT-4 和 PaLM 2）在医疗诊断中的局限性。研究采用集体智能方法，对 200 个真实临床病例进行评估，比较单个 LLMs 的诊断准确率与聚合多个 LLMs 响应后的准确率。结果显示，聚合三个 LLMs 的响应，平均准确率达到 75.3% ± 1.6pp，显著高于单个 LLMs 的 59.0% ± 6.1pp。这种方法不仅提高了诊断精度，还减少了对单一商业供应商的依赖，促进 LLMs 作为可靠诊断支持工具的应用。",
      "categories": [
        "cs.AI",
        "I.2.1; J.3"
      ],
      "primary_category": "cs.AI",
      "comment": "5 pages, 2 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2402.08806v1",
      "published_date": "2024-02-13 21:24:21 UTC",
      "updated_date": "2024-02-13 21:24:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:45:29.092555"
    },
    {
      "arxiv_id": "2402.08801v1",
      "title": "ChatGPT vs LLaMA: Impact, Reliability, and Challenges in Stack Overflow Discussions",
      "title_zh": "ChatGPT 与 LLaMA：在 Stack Overflow 讨论中的影响、可靠性和挑战",
      "authors": [
        "Leuson Da Silva",
        "Jordan Samhi",
        "Foutse Khomh"
      ],
      "abstract": "Since its release in November 2022, ChatGPT has shaken up Stack Overflow, the\npremier platform for developers' queries on programming and software\ndevelopment. Demonstrating an ability to generate instant, human-like responses\nto technical questions, ChatGPT has ignited debates within the developer\ncommunity about the evolving role of human-driven platforms in the age of\ngenerative AI. Two months after ChatGPT's release, Meta released its answer\nwith its own Large Language Model (LLM) called LLaMA: the race was on. We\nconducted an empirical study analyzing questions from Stack Overflow and using\nthese LLMs to address them. This way, we aim to (ii) measure user engagement\nevolution with Stack Overflow over time; (ii) quantify the reliability of LLMs'\nanswers and their potential to replace Stack Overflow in the long term; (iii)\nidentify and understand why LLMs fails; and (iv) compare LLMs together. Our\nempirical results are unequivocal: ChatGPT and LLaMA challenge human expertise,\nyet do not outperform it for some domains, while a significant decline in user\nposting activity has been observed. Furthermore, we also discuss the impact of\nour findings regarding the usage and development of new LLMs.",
      "tldr_zh": "这篇论文比较了ChatGPT和LLaMA在Stack Overflow讨论中的影响、可靠性和挑战，通过实证研究分析开发者查询的互动变化。研究方法包括使用这些Large Language Models (LLMs)生成答案，以量化其可靠性、潜在取代Stack Overflow的可能性，并识别LLMs失败的原因，如在某些领域无法超越人类专业知识。结果显示，ChatGPT和LLaMA虽挑战了人类专家，但整体表现不如人类，且Stack Overflow的用户发布活动显著下降。最后，论文讨论了这些发现对LLM使用和未来发展的启示。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "36 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.08801v1",
      "published_date": "2024-02-13 21:15:33 UTC",
      "updated_date": "2024-02-13 21:15:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:45:40.183664"
    },
    {
      "arxiv_id": "2402.08789v1",
      "title": "Leveraging cough sounds to optimize chest x-ray usage in low-resource settings",
      "title_zh": "翻译失败",
      "authors": [
        "Alexander Philip",
        "Sanya Chawla",
        "Lola Jover",
        "George P. Kafentzis",
        "Joe Brew",
        "Vishakh Saraf",
        "Shibu Vijayan",
        "Peter Small",
        "Carlos Chaccour"
      ],
      "abstract": "Chest X-ray is a commonly used tool during triage, diagnosis and management\nof respiratory diseases. In resource-constricted settings, optimizing this\nresource can lead to valuable cost savings for the health care system and the\npatients as well as to and improvement in consult time. We used\nprospectively-collected data from 137 patients referred for chest X-ray at the\nChristian Medical Center and Hospital (CMCH) in Purnia, Bihar, India. Each\npatient provided at least five coughs while awaiting radiography. Collected\ncough sounds were analyzed using acoustic AI methods. Cross-validation was done\non temporal and spectral features on the cough sounds of each patient. Features\nwere summarized using standard statistical approaches. Three models were\ndeveloped, tested and compared in their capacity to predict an abnormal result\nin the chest X-ray. All three methods yielded models that could discriminate to\nsome extent between normal and abnormal with the logistic regression performing\nbest with an area under the receiver operating characteristic curves ranging\nfrom 0.7 to 0.78. Despite limitations and its relatively small sample size,\nthis study shows that AI-enabled algorithms can use cough sounds to predict\nwhich individuals presenting for chest radiographic examination will have a\nnormal or abnormal results. These results call for expanding this research\ngiven the potential optimization of limited health care resources in low- and\nmiddle-income countries.",
      "tldr_zh": "本研究旨在通过分析咳嗽声音来优化资源有限环境下的 chest X-ray 使用，以降低医疗成本并缩短咨询时间。研究者收集了137名患者在等待X光检查时的咳嗽数据，使用声学AI方法提取时间和频谱特征，并开发了三种模型，包括logistic regression模型，该模型在预测X光异常结果时表现最佳，AUC值为0.7-0.78。尽管样本量较小，结果表明AI算法能有效区分正常和异常X光结果，为低中收入国家医疗资源优化提供了潜在解决方案。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.LG",
        "q-bio.QM"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08789v1",
      "published_date": "2024-02-13 20:54:55 UTC",
      "updated_date": "2024-02-13 20:54:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:45:52.379645"
    },
    {
      "arxiv_id": "2402.08780v1",
      "title": "Enhanced Deep Q-Learning for 2D Self-Driving Cars: Implementation and Evaluation on a Custom Track Environment",
      "title_zh": "增强深度 Q",
      "authors": [
        "Sagar Pathak",
        "Bidhya Shrestha",
        "Kritish Pahi"
      ],
      "abstract": "This research project presents the implementation of a Deep Q-Learning\nNetwork (DQN) for a self-driving car on a 2-dimensional (2D) custom track, with\nthe objective of enhancing the DQN network's performance. It encompasses the\ndevelopment of a custom driving environment using Pygame on a track surrounding\nthe University of Memphis map, as well as the design and implementation of the\nDQN model. The algorithm utilizes data from 7 sensors installed in the car,\nwhich measure the distance between the car and the track. These sensors are\npositioned in front of the vehicle, spaced 20 degrees apart, enabling them to\nsense a wide area ahead. We successfully implemented the DQN and also a\nmodified version of the DQN with a priority-based action selection mechanism,\nwhich we refer to as modified DQN. The model was trained over 1000 episodes,\nand the average reward received by the agent was found to be around 40, which\nis approximately 60% higher than the original DQN and around 50% higher than\nthe vanilla neural network.",
      "tldr_zh": "这篇论文实现了Enhanced Deep Q-Learning (DQN) 用于2D自驾车，旨在提升其性能，通过Pygame开发了一个自定义轨道环境模拟University of Memphis地图，并利用7个传感器（每20度间隔）测量车与轨道的距离。论文设计了标准DQN和一个modified DQN，采用了优先级-based行动选择机制。训练1000个episode后，modified DQN的平均奖励达到约40，比原DQN提高了60%，比vanilla神经网络提高了50%。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.08780v1",
      "published_date": "2024-02-13 20:29:36 UTC",
      "updated_date": "2024-02-13 20:29:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:46:03.840823"
    },
    {
      "arxiv_id": "2402.08777v3",
      "title": "DNABERT-S: Pioneering Species Differentiation with Species-Aware DNA Embeddings",
      "title_zh": "翻译失败",
      "authors": [
        "Zhihan Zhou",
        "Weimin Wu",
        "Harrison Ho",
        "Jiayi Wang",
        "Lizhen Shi",
        "Ramana V Davuluri",
        "Zhong Wang",
        "Han Liu"
      ],
      "abstract": "We introduce DNABERT-S, a tailored genome model that develops species-aware\nembeddings to naturally cluster and segregate DNA sequences of different\nspecies in the embedding space. Differentiating species from genomic sequences\n(i.e., DNA and RNA) is vital yet challenging, since many real-world species\nremain uncharacterized, lacking known genomes for reference. Embedding-based\nmethods are therefore used to differentiate species in an unsupervised manner.\nDNABERT-S builds upon a pre-trained genome foundation model named DNABERT-2. To\nencourage effective embeddings to error-prone long-read DNA sequences, we\nintroduce Manifold Instance Mixup (MI-Mix), a contrastive objective that mixes\nthe hidden representations of DNA sequences at randomly selected layers and\ntrains the model to recognize and differentiate these mixed proportions at the\noutput layer. We further enhance it with the proposed Curriculum Contrastive\nLearning (C$^2$LR) strategy. Empirical results on 23 diverse datasets show\nDNABERT-S's effectiveness, especially in realistic label-scarce scenarios. For\nexample, it identifies twice more species from a mixture of unlabeled genomic\nsequences, doubles the Adjusted Rand Index (ARI) in species clustering, and\noutperforms the top baseline's performance in 10-shot species classification\nwith just a 2-shot training. Model, codes, and data are publicly available at\n\\url{https://github.com/MAGICS-LAB/DNABERT_S}.",
      "tldr_zh": "该研究引入了DNABERT-S，一种定制的基因组模型，通过开发物种感知嵌入(species-aware embeddings)，实现DNA序列在嵌入空间中的自然聚类和分离，从而在无监督方式下区分不同物种。模型基于预训练的DNABERT-2，引入Manifold Instance Mixup (MI-Mix)对比目标和Curriculum Contrastive Learning (C²LR)策略，分别通过混合隐藏表示和逐步强化学习来提升对长读DNA序列的鲁棒性。在23个多样数据集上的实验显示，DNABERT-S在标签稀缺场景中表现出色，例如从未标记序列中识别出两倍多的物种，将Adjusted Rand Index (ARI)在物种聚类中提高一倍，并在2-shot训练下超越基线在10-shot分类的性能。",
      "categories": [
        "q-bio.GN",
        "cs.AI",
        "cs.CE",
        "cs.CL"
      ],
      "primary_category": "q-bio.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08777v3",
      "published_date": "2024-02-13 20:21:29 UTC",
      "updated_date": "2024-10-22 04:14:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:46:18.078716"
    },
    {
      "arxiv_id": "2402.10962v4",
      "title": "Measuring and Controlling Instruction (In)Stability in Language Model Dialogs",
      "title_zh": "翻译失败",
      "authors": [
        "Kenneth Li",
        "Tianle Liu",
        "Naomi Bashkansky",
        "David Bau",
        "Fernanda Viégas",
        "Hanspeter Pfister",
        "Martin Wattenberg"
      ],
      "abstract": "System-prompting is a standard tool for customizing language-model chatbots,\nenabling them to follow a specific instruction. An implicit assumption in the\nuse of system prompts is that they will be stable, so the chatbot will continue\nto generate text according to the stipulated instructions for the duration of a\nconversation. We propose a quantitative benchmark to test this assumption,\nevaluating instruction stability via self-chats between two instructed\nchatbots. Testing popular models like LLaMA2-chat-70B and GPT-3.5, we reveal a\nsignificant instruction drift within eight rounds of conversations. An\nempirical and theoretical analysis of this phenomenon suggests the transformer\nattention mechanism plays a role, due to attention decay over long exchanges.\nTo combat attention decay and instruction drift, we propose a lightweight\nmethod called split-softmax, which compares favorably against two strong\nbaselines.",
      "tldr_zh": "本研究评估了语言模型对话中指令稳定性的问题，提出一个量化基准，通过两个受指令的聊天机器人（self-chats）进行测试。实验发现，模型如 LLaMA2-chat-70B 和 GPT-3.5 在8轮对话内即出现显著的指令漂移（instruction drift），这归因于 transformer attention mechanism 的注意力衰减（attention decay）。为应对这一问题，论文引入了轻量级方法 split-softmax，并证明其比现有基线更有效。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "COLM 2024; Code and data: https://github.com/likenneth/persona_drift",
      "pdf_url": "http://arxiv.org/pdf/2402.10962v4",
      "published_date": "2024-02-13 20:10:29 UTC",
      "updated_date": "2024-07-25 18:58:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:46:28.553609"
    },
    {
      "arxiv_id": "2402.08772v3",
      "title": "Optimal Task Assignment and Path Planning using Conflict-Based Search with Precedence and Temporal Constraints",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Quan Chong",
        "Jiaoyang Li",
        "Katia Sycara"
      ],
      "abstract": "The Multi-Agent Path Finding (MAPF) problem entails finding collision-free\npaths for a set of agents, guiding them from their start to goal locations.\nHowever, MAPF does not account for several practical task-related constraints.\nFor example, agents may need to perform actions at goal locations with specific\nexecution times, adhering to predetermined orders and timeframes. Moreover,\ngoal assignments may not be predefined for agents, and the optimization\nobjective may lack an explicit definition. To incorporate task assignment, path\nplanning, and a user-defined objective into a coherent framework, this paper\nexamines the Task Assignment and Path Finding with Precedence and Temporal\nConstraints (TAPF-PTC) problem. We augment Conflict-Based Search (CBS) to\nsimultaneously generate task assignments and collision-free paths that adhere\nto precedence and temporal constraints, maximizing an objective quantified by\nthe return from a user-defined reward function in reinforcement learning (RL).\nExperimentally, we demonstrate that our algorithm, CBS-TA-PTC, can solve highly\nchallenging bomb-defusing tasks with precedence and temporal constraints\nefficiently relative to MARL and adapted Target Assignment and Path Finding\n(TAPF) methods.",
      "tldr_zh": "本论文研究了Task Assignment and Path Finding with Precedence and Temporal Constraints (TAPF-PTC)问题，这是一种扩展Multi-Agent Path Finding (MAPF)的框架，用于处理代理间的冲突、任务分配、路径规划以及先决和时间约束。作者改进了Conflict-Based Search (CBS)算法，开发出CBS-TA-PTC方法，能够同时生成任务分配和无冲突路径，同时最大化基于强化学习 (RL) 的用户定义奖励函数。实验结果显示，该算法在复杂炸弹拆除任务中比Multi-Agent Reinforcement Learning (MARL)和适应后的TAPF方法更高效，证明了其在实际应用中的优越性。",
      "categories": [
        "cs.AI",
        "cs.MA",
        "I.2.11"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08772v3",
      "published_date": "2024-02-13 20:07:58 UTC",
      "updated_date": "2024-04-22 00:46:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:46:40.322137"
    },
    {
      "arxiv_id": "2402.08761v1",
      "title": "JAMDEC: Unsupervised Authorship Obfuscation using Constrained Decoding over Small Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jillian Fisher",
        "Ximing Lu",
        "Jaehun Jung",
        "Liwei Jiang",
        "Zaid Harchaoui",
        "Yejin Choi"
      ],
      "abstract": "The permanence of online content combined with the enhanced authorship\nidentification techniques calls for stronger computational methods to protect\nthe identity and privacy of online authorship when needed, e.g., blind reviews\nfor scientific papers, anonymous online reviews, or anonymous interactions in\nthe mental health forums. In this paper, we propose an unsupervised\ninference-time approach to authorship obfuscation to address the unique\nchallenges of authorship obfuscation: lack of supervision data for diverse\nauthorship and domains, and the need for a sufficient level of revision beyond\nsimple paraphrasing to obfuscate the authorship, all the while preserving the\noriginal content and fluency.\n  We introduce JAMDEC, a user-controlled, inference-time algorithm for\nauthorship obfuscation that can be in principle applied to any text and\nauthorship. Our approach builds on small language models such as GPT2-XL in\norder to help avoid disclosing the original content to proprietary LLM's APIs,\nwhile also reducing the performance gap between small and large language models\nvia algorithmic enhancement. The key idea behind our approach is to boost the\ncreative power of smaller language models through constrained decoding, while\nalso allowing for user-specified controls and flexibility. Experimental results\ndemonstrate that our approach based on GPT2-XL outperforms previous\nstate-of-the-art methods based on comparably small models, while performing\ncompetitively against GPT3.5 175B, a propriety model that is two orders of\nmagnitudes larger.",
      "tldr_zh": "这篇论文提出了一种无监督的 authorship obfuscation 方法，名为 JAMDEC，利用 constrained decoding 在小语言模型（如 GPT2-XL）上进行，以保护在线内容的作者隐私，同时处理监督数据缺乏、多领域多样性和内容流畅性挑战。关键创新在于通过用户控制的推理时算法增强小模型的创造力，避免依赖大型专有模型API，并允许灵活的文本修改。实验结果显示，JAMDEC 基于 GPT2-XL 的表现优于现有小模型方法，并与 GPT3.5 175B 大模型竞争。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Code is available at https://github.com/jfisher52/JAMDecoding",
      "pdf_url": "http://arxiv.org/pdf/2402.08761v1",
      "published_date": "2024-02-13 19:54:29 UTC",
      "updated_date": "2024-02-13 19:54:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:46:52.283854"
    },
    {
      "arxiv_id": "2402.08755v1",
      "title": "LLM-driven Imitation of Subrational Behavior : Illusion or Reality?",
      "title_zh": "LLM驱动的次理性行为模仿：幻觉还是现实？",
      "authors": [
        "Andrea Coletta",
        "Kshama Dwarakanath",
        "Penghang Liu",
        "Svitlana Vyetrenko",
        "Tucker Balch"
      ],
      "abstract": "Modeling subrational agents, such as humans or economic households, is\ninherently challenging due to the difficulty in calibrating reinforcement\nlearning models or collecting data that involves human subjects. Existing work\nhighlights the ability of Large Language Models (LLMs) to address complex\nreasoning tasks and mimic human communication, while simulation using LLMs as\nagents shows emergent social behaviors, potentially improving our comprehension\nof human conduct. In this paper, we propose to investigate the use of LLMs to\ngenerate synthetic human demonstrations, which are then used to learn\nsubrational agent policies though Imitation Learning. We make an assumption\nthat LLMs can be used as implicit computational models of humans, and propose a\nframework to use synthetic demonstrations derived from LLMs to model\nsubrational behaviors that are characteristic of humans (e.g., myopic behavior\nor preference for risk aversion). We experimentally evaluate the ability of our\nframework to model sub-rationality through four simple scenarios, including the\nwell-researched ultimatum game and marshmallow experiment. To gain confidence\nin our framework, we are able to replicate well-established findings from prior\nhuman studies associated with the above scenarios. We conclude by discussing\nthe potential benefits, challenges and limitations of our framework.",
      "tldr_zh": "本研究探讨了使用大型语言模型 (LLMs) 是否能有效模拟亚理性行为（如人类短视或风险厌恶），通过生成合成人类演示来训练亚理性代理策略。论文提出一个框架，利用 LLMs 作为隐式人类计算模型，结合 Imitation Learning 来学习这些行为，并在四个简单场景（如最后通牒游戏和棉花糖实验）中进行实验验证。结果显示，该框架成功复制了先前人类研究的经典发现，提高了对亚理性行为的理解。最终，研究讨论了这一方法的潜在益处、挑战和局限性，包括其是否真正反映现实而非幻觉。",
      "categories": [
        "cs.AI",
        "econ.GN",
        "q-fin.EC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08755v1",
      "published_date": "2024-02-13 19:46:39 UTC",
      "updated_date": "2024-02-13 19:46:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:47:04.328985"
    },
    {
      "arxiv_id": "2402.08682v1",
      "title": "IM-3D: Iterative Multiview Diffusion and Reconstruction for High-Quality 3D Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Luke Melas-Kyriazi",
        "Iro Laina",
        "Christian Rupprecht",
        "Natalia Neverova",
        "Andrea Vedaldi",
        "Oran Gafni",
        "Filippos Kokkinos"
      ],
      "abstract": "Most text-to-3D generators build upon off-the-shelf text-to-image models\ntrained on billions of images. They use variants of Score Distillation Sampling\n(SDS), which is slow, somewhat unstable, and prone to artifacts. A mitigation\nis to fine-tune the 2D generator to be multi-view aware, which can help\ndistillation or can be combined with reconstruction networks to output 3D\nobjects directly. In this paper, we further explore the design space of\ntext-to-3D models. We significantly improve multi-view generation by\nconsidering video instead of image generators. Combined with a 3D\nreconstruction algorithm which, by using Gaussian splatting, can optimize a\nrobust image-based loss, we directly produce high-quality 3D outputs from the\ngenerated views. Our new method, IM-3D, reduces the number of evaluations of\nthe 2D generator network 10-100x, resulting in a much more efficient pipeline,\nbetter quality, fewer geometric inconsistencies, and higher yield of usable 3D\nassets.",
      "tldr_zh": "本文提出 IM-3D，一种迭代多视图扩散和重建方法，用于实现高质量文本到3D 生成。不同于传统基于 Score Distillation Sampling (SDS) 的生成器，该方法利用视频生成器代替图像生成器，显著提升多视图生成质量，并结合 Gaussian splatting 优化算法，直接从生成的视图中重建3D 对象。结果显示，IM-3D 将2D 生成器网络评估次数减少10-100倍，提高了管道效率、输出质量、几何一致性，并提升了可用3D 资产的产出率。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08682v1",
      "published_date": "2024-02-13 18:59:51 UTC",
      "updated_date": "2024-02-13 18:59:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:47:16.799189"
    },
    {
      "arxiv_id": "2402.08680v1",
      "title": "Mitigating Object Hallucination in Large Vision-Language Models via Classifier-Free Guidance",
      "title_zh": "翻译失败",
      "authors": [
        "Linxi Zhao",
        "Yihe Deng",
        "Weitong Zhang",
        "Quanquan Gu"
      ],
      "abstract": "The advancement of Large Vision-Language Models (LVLMs) has increasingly\nhighlighted the critical issue of their tendency to hallucinate non-existing\nobjects in the images. To address this issue, previous works focused on using\nspecially curated datasets or powerful LLMs (e.g., GPT-3.5) to rectify the\noutputs of LVLMs. However, these approaches require either expensive\ntraining/fine-tuning or API access to advanced LLMs to correct the model's\noutput post-generation. In this paper, we tackle this challenge by introducing\na framework called Mitigating hallucinAtion via classifieR-Free guIdaNcE\n(MARINE), which is both training-free and API-free, and can effectively and\nefficiently reduce object hallucinations during the generation process.\nSpecifically, MARINE enriches the visual context of LVLMs by integrating\nexisting open-source vision models, and employs classifier-free guidance to\nincorporate the additional object grounding features to improve the precision\nof LVLMs' generations. Through comprehensive evaluations across $6$ popular\nLVLMs with diverse evaluation metrics, we demonstrate the effectiveness of\nMARINE, which even outperforms existing fine-tuning-based methods. Remarkably,\nit not only reduces hallucinations but also improves the detailedness of LVLMs'\ngenerations, as assessed by GPT-4V.",
      "tldr_zh": "本论文提出 MARINE 框架，用于缓解 Large Vision-Language Models (LVLMs) 在图像中生成不存在对象的幻觉问题，该框架无需训练或外部 API 访问。MARINE 通过整合开源视觉模型来丰富视觉上下文，并采用 classifier-free guidance 技术整合对象 grounding 特征，从而在生成过程中提升 LVLMs 的精确性。实验在 6 个流行 LVLMs 上进行评估，结果显示 MARINE 优于现有微调方法，不仅显著减少幻觉，还提高了生成的详细性，如由 GPT-4V 评估确认。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "27 pages, 20 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2402.08680v1",
      "published_date": "2024-02-13 18:59:05 UTC",
      "updated_date": "2024-02-13 18:59:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:47:29.762955"
    },
    {
      "arxiv_id": "2402.08679v2",
      "title": "COLD-Attack: Jailbreaking LLMs with Stealthiness and Controllability",
      "title_zh": "COLD-Attack：利用隐秘性和可控性",
      "authors": [
        "Xingang Guo",
        "Fangxu Yu",
        "Huan Zhang",
        "Lianhui Qin",
        "Bin Hu"
      ],
      "abstract": "Jailbreaks on large language models (LLMs) have recently received increasing\nattention. For a comprehensive assessment of LLM safety, it is essential to\nconsider jailbreaks with diverse attributes, such as contextual coherence and\nsentiment/stylistic variations, and hence it is beneficial to study\ncontrollable jailbreaking, i.e. how to enforce control on LLM attacks. In this\npaper, we formally formulate the controllable attack generation problem, and\nbuild a novel connection between this problem and controllable text generation,\na well-explored topic of natural language processing. Based on this connection,\nwe adapt the Energy-based Constrained Decoding with Langevin Dynamics (COLD), a\nstate-of-the-art, highly efficient algorithm in controllable text generation,\nand introduce the COLD-Attack framework which unifies and automates the search\nof adversarial LLM attacks under a variety of control requirements such as\nfluency, stealthiness, sentiment, and left-right-coherence. The controllability\nenabled by COLD-Attack leads to diverse new jailbreak scenarios which not only\ncover the standard setting of generating fluent (suffix) attack with\ncontinuation constraint, but also allow us to address new controllable attack\nsettings such as revising a user query adversarially with paraphrasing\nconstraint, and inserting stealthy attacks in context with position constraint.\nOur extensive experiments on various LLMs (Llama-2, Mistral, Vicuna, Guanaco,\nGPT-3.5, and GPT-4) show COLD-Attack's broad applicability, strong\ncontrollability, high success rate, and attack transferability. Our code is\navailable at https://github.com/Yu-Fangxu/COLD-Attack.",
      "tldr_zh": "该研究正式定义了可控大型语言模型(LLMs)越狱攻击问题，并提出COLD-Attack框架，通过适应Energy-based Constrained Decoding with Langevin Dynamics (COLD)算法，实现对攻击的隐蔽性和可控性控制，如流畅性、情感和上下文连贯性。COLD-Attack统一自动化搜索对抗性攻击，支持多样场景，包括生成流畅后缀攻击、修改用户查询和插入位置约束的隐蔽攻击。实验在Llama-2、Mistral、Vicuna等各种LLMs上显示，该框架具有高成功率、强可控性和攻击转移能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.08679v2",
      "published_date": "2024-02-13 18:58:48 UTC",
      "updated_date": "2024-06-07 00:13:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:47:40.849042"
    },
    {
      "arxiv_id": "2402.08714v2",
      "title": "PRDP: Proximal Reward Difference Prediction for Large-Scale Reward Finetuning of Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Fei Deng",
        "Qifei Wang",
        "Wei Wei",
        "Matthias Grundmann",
        "Tingbo Hou"
      ],
      "abstract": "Reward finetuning has emerged as a promising approach to aligning foundation\nmodels with downstream objectives. Remarkable success has been achieved in the\nlanguage domain by using reinforcement learning (RL) to maximize rewards that\nreflect human preference. However, in the vision domain, existing RL-based\nreward finetuning methods are limited by their instability in large-scale\ntraining, rendering them incapable of generalizing to complex, unseen prompts.\nIn this paper, we propose Proximal Reward Difference Prediction (PRDP),\nenabling stable black-box reward finetuning for diffusion models for the first\ntime on large-scale prompt datasets with over 100K prompts. Our key innovation\nis the Reward Difference Prediction (RDP) objective that has the same optimal\nsolution as the RL objective while enjoying better training stability.\nSpecifically, the RDP objective is a supervised regression objective that tasks\nthe diffusion model with predicting the reward difference of generated image\npairs from their denoising trajectories. We theoretically prove that the\ndiffusion model that obtains perfect reward difference prediction is exactly\nthe maximizer of the RL objective. We further develop an online algorithm with\nproximal updates to stably optimize the RDP objective. In experiments, we\ndemonstrate that PRDP can match the reward maximization ability of\nwell-established RL-based methods in small-scale training. Furthermore, through\nlarge-scale training on text prompts from the Human Preference Dataset v2 and\nthe Pick-a-Pic v1 dataset, PRDP achieves superior generation quality on a\ndiverse set of complex, unseen prompts whereas RL-based methods completely\nfail.",
      "tldr_zh": "本文提出 PRDP 方法，用于大规模奖励微调扩散模型，解决现有基于强化学习 (RL) 的方法在视觉领域训练不稳定的问题。PRDP 的核心创新是 Reward Difference Prediction (RDP) 目标，这是一个监督回归任务，让扩散模型预测生成图像对的奖励差异，并理论证明其与 RL 目标具有相同的最优解，同时通过近端更新实现稳定优化。实验结果显示，PRDP 在小规模训练中与 RL 方法在奖励最大化能力相当，而在大规模数据集（如 Human Preference Dataset v2 和 Pick-a-Pic v1）上，PRDP 显著提升了复杂未见提示的生成质量，而 RL 方法则完全失败。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "CVPR 2024. Project page: https://fdeng18.github.io/prdp",
      "pdf_url": "http://arxiv.org/pdf/2402.08714v2",
      "published_date": "2024-02-13 18:58:16 UTC",
      "updated_date": "2024-03-27 21:37:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:47:53.916768"
    },
    {
      "arxiv_id": "2402.08672v2",
      "title": "Model Assessment and Selection under Temporal Distribution Shift",
      "title_zh": "时间",
      "authors": [
        "Elise Han",
        "Chengpiao Huang",
        "Kaizheng Wang"
      ],
      "abstract": "We investigate model assessment and selection in a changing environment, by\nsynthesizing datasets from both the current time period and historical epochs.\nTo tackle unknown and potentially arbitrary temporal distribution shift, we\ndevelop an adaptive rolling window approach to estimate the generalization\nerror of a given model. This strategy also facilitates the comparison between\nany two candidate models by estimating the difference of their generalization\nerrors. We further integrate pairwise comparisons into a single-elimination\ntournament, achieving near-optimal model selection from a collection of\ncandidates. Theoretical analyses and numerical experiments demonstrate the\nadaptivity of our proposed methods to the non-stationarity in data.",
      "tldr_zh": "本文研究了在时间分布偏移(temporal distribution shift)下进行模型评估和选择，通过合成当前和历史数据集来应对未知的分布变化。作者提出了一种自适应滚动窗口方法(adaptive rolling window approach)，用于估计模型的泛化错误(generalization error)，并通过成对比较和单淘汰锦标赛(single-elimination tournament)从候选模型中选择近优方案。理论分析和数值实验证明，该方法对数据中的非平稳性(non-stationarity)具有良好的适应性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME",
        "62G05 (Primary), 62J02 (Secondary)"
      ],
      "primary_category": "cs.LG",
      "comment": "26 pages, 6 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2402.08672v2",
      "published_date": "2024-02-13 18:54:08 UTC",
      "updated_date": "2024-06-03 22:30:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:48:04.709675"
    },
    {
      "arxiv_id": "2402.08671v3",
      "title": "Are Semi-Dense Detector-Free Methods Good at Matching Local Features?",
      "title_zh": "翻译失败",
      "authors": [
        "Matthieu Vilain",
        "Rémi Giraud",
        "Hugo Germain",
        "Guillaume Bourmaud"
      ],
      "abstract": "Semi-dense detector-free approaches (SDF), such as LoFTR, are currently among\nthe most popular image matching methods. While SDF methods are trained to\nestablish correspondences between two images, their performances are almost\nexclusively evaluated using relative pose estimation metrics. Thus, the link\nbetween their ability to establish correspondences and the quality of the\nresulting estimated pose has thus far received little attention. This paper is\na first attempt to study this link. We start with proposing a novel structured\nattention-based image matching architecture (SAM). It allows us to show a\ncounter-intuitive result on two datasets (MegaDepth and HPatches): on the one\nhand SAM either outperforms or is on par with SDF methods in terms of\npose/homography estimation metrics, but on the other hand SDF approaches are\nsignificantly better than SAM in terms of matching accuracy. We then propose to\nlimit the computation of the matching accuracy to textured regions, and show\nthat in this case SAM often surpasses SDF methods. Our findings highlight a\nstrong correlation between the ability to establish accurate correspondences in\ntextured regions and the accuracy of the resulting estimated pose/homography.\nOur code will be made available.",
      "tldr_zh": "本文研究了 Semi-Dense Detector-Free (SDF) 方法（如 LoFTR）在图像匹配中的性能，特别探讨了建立对应点的能力与位姿估计质量之间的关系。作者提出了一种新型基于 Structured Attention-based (SAM) 的图像匹配架构，并在 MegaDepth 和 HPatches 数据集上进行评估，结果显示 SAM 在位姿/单应性估计指标上要么优于要么与 SDF 方法相当，但 SDF 在整体匹配准确性上表现更好。进一步分析发现，如果仅在纹理区域计算匹配准确性，SAM 往往超越 SDF 方法。研究强调了纹理区域对应点准确性与位姿/单应性估计精确性之间的强相关性，并计划公开代码。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08671v3",
      "published_date": "2024-02-13 18:53:13 UTC",
      "updated_date": "2024-06-01 11:34:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:48:18.700158"
    },
    {
      "arxiv_id": "2402.08670v1",
      "title": "Rec-GPT4V: Multimodal Recommendation with Large Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yuqing Liu",
        "Yu Wang",
        "Lichao Sun",
        "Philip S. Yu"
      ],
      "abstract": "The development of large vision-language models (LVLMs) offers the potential\nto address challenges faced by traditional multimodal recommendations thanks to\ntheir proficient understanding of static images and textual dynamics. However,\nthe application of LVLMs in this field is still limited due to the following\ncomplexities: First, LVLMs lack user preference knowledge as they are trained\nfrom vast general datasets. Second, LVLMs suffer setbacks in addressing\nmultiple image dynamics in scenarios involving discrete, noisy, and redundant\nimage sequences. To overcome these issues, we propose the novel reasoning\nscheme named Rec-GPT4V: Visual-Summary Thought (VST) of leveraging large\nvision-language models for multimodal recommendation. We utilize user history\nas in-context user preferences to address the first challenge. Next, we prompt\nLVLMs to generate item image summaries and utilize image comprehension in\nnatural language space combined with item titles to query the user preferences\nover candidate items. We conduct comprehensive experiments across four datasets\nwith three LVLMs: GPT4-V, LLaVa-7b, and LLaVa-13b. The numerical results\nindicate the efficacy of VST.",
      "tldr_zh": "该研究提出了一种名为 Rec-GPT4V 的新推理方案（Visual-Summary Thought, VST），利用大型视觉语言模型 (LVLMs) 提升多模态推荐系统的性能，解决 LVLMs 缺乏用户偏好知识和处理图像序列动态（如离散、嘈杂或冗余）的问题。方法包括使用用户历史作为 in-context 用户偏好，提示 LVLMs 生成物品图像摘要，并结合自然语言空间的图像理解与物品标题来查询候选物品的偏好匹配。实验在四个数据集上使用 GPT4-V、LLaVa-7b 和 LLaVa-13b 等模型进行测试，结果表明 VST 方案有效，提高了推荐的准确性和实用性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "under review",
      "pdf_url": "http://arxiv.org/pdf/2402.08670v1",
      "published_date": "2024-02-13 18:51:18 UTC",
      "updated_date": "2024-02-13 18:51:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:48:29.483733"
    },
    {
      "arxiv_id": "2402.08658v3",
      "title": "The Last JITAI? Exploring Large Language Models for Issuing Just-in-Time Adaptive Interventions: Fostering Physical Activity in a Conceptual Cardiac Rehabilitation Setting",
      "title_zh": "翻译失败",
      "authors": [
        "David Haag",
        "Devender Kumar",
        "Sebastian Gruber",
        "Dominik Hofer",
        "Mahdi Sareban",
        "Gunnar Treff",
        "Josef Niebauer",
        "Christopher Bull",
        "Albrecht Schmidt",
        "Jan David Smeddinck"
      ],
      "abstract": "We evaluated the viability of using Large Language Models (LLMs) to trigger\nand personalize content in Just-in-Time Adaptive Interventions (JITAIs) in\ndigital health. As an interaction pattern representative of context-aware\ncomputing, JITAIs are being explored for their potential to support sustainable\nbehavior change, adapting interventions to an individual's current context and\nneeds. Challenging traditional JITAI implementation models, which face severe\nscalability and flexibility limitations, we tested GPT-4 for suggesting JITAIs\nin the use case of heart-healthy activity in cardiac rehabilitation. Using\nthree personas representing patients affected by CVD with varying severeness\nand five context sets per persona, we generated 450 JITAI decisions and\nmessages. These were systematically evaluated against those created by 10\nlaypersons (LayPs) and 10 healthcare professionals (HCPs). GPT-4-generated\nJITAIs surpassed human-generated intervention suggestions, outperforming both\nLayPs and HCPs across all metrics (i.e., appropriateness, engagement,\neffectiveness, and professionalism). These results highlight the potential of\nLLMs to enhance JITAI implementations in personalized health interventions,\ndemonstrating how generative AI could revolutionize context-aware computing.",
      "tldr_zh": "本研究评估了使用大型语言模型 (LLMs) 来触发和个性化 Just-in-Time Adaptive Interventions (JITAIs) 的可行性，旨在通过上下文感知计算支持心脏康复患者的身体活动行为改变。研究者使用 GPT-4 生成450个 JITAI 决策和消息，基于三个心脏疾病患者角色和每个角色的五个上下文集，并与10名普通人 (LayPs) 和10名医疗专业人士 (HCPs) 的建议进行比较。结果显示，GPT-4 生成的 JITAIs 在适当性、吸引力、有效性和专业性等指标上均优于人类建议，突显了 LLMs 在个性化健康干预中的潜力，并可能革新传统 JITAI 实施的局限性。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "J.3"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08658v3",
      "published_date": "2024-02-13 18:39:36 UTC",
      "updated_date": "2025-02-26 08:57:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:48:42.377709"
    },
    {
      "arxiv_id": "2402.08653v4",
      "title": "SAGMAN: Stability Analysis of Graph Neural Networks on the Manifolds",
      "title_zh": "SAGMAN：图神经网络在流形上的稳定性分析",
      "authors": [
        "Wuxinlin Cheng",
        "Chenhui Deng",
        "Ali Aghdaei",
        "Zhiru Zhang",
        "Zhuo Feng"
      ],
      "abstract": "Modern graph neural networks (GNNs) can be sensitive to changes in the input\ngraph structure and node features, potentially resulting in unpredictable\nbehavior and degraded performance. In this work, we introduce a spectral\nframework known as SAGMAN for examining the stability of GNNs. This framework\nassesses the distance distortions that arise from the nonlinear mappings of\nGNNs between the input and output manifolds: when two nearby nodes on the input\nmanifold are mapped (through a GNN model) to two distant ones on the output\nmanifold, it implies a large distance distortion and thus a poor GNN stability.\nWe propose a distance-preserving graph dimension reduction (GDR) approach that\nutilizes spectral graph embedding and probabilistic graphical models (PGMs) to\ncreate low-dimensional input/output graph-based manifolds for meaningful\nstability analysis. Our empirical evaluations show that SAGMAN effectively\nassesses the stability of each node when subjected to various edge or feature\nperturbations, offering a scalable approach for evaluating the stability of\nGNNs, extending to applications within recommendation systems. Furthermore, we\nillustrate its utility in downstream tasks, notably in enhancing GNN stability\nand facilitating adversarial targeted attacks.",
      "tldr_zh": "本研究引入了SAGMAN框架，用于分析Graph Neural Networks (GNNs)在流形上的稳定性，针对GNNs对输入图结构和节点特征变化的敏感性问题。SAGMAN通过评估GNNs非线性映射导致的输入和输出流形距离扭曲来衡量稳定性，并提出了一种基于谱图嵌入和Probabilistic Graphical Models (PGMs)的Graph Dimension Reduction (GDR)方法，以创建低维流形进行分析。实证评估表明，该框架能有效评估节点在边或特征扰动下的稳定性，提供可扩展的评估工具，并应用于推荐系统、增强GNN稳定性以及对抗性目标攻击等下游任务。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08653v4",
      "published_date": "2024-02-13 18:33:45 UTC",
      "updated_date": "2024-10-09 16:51:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:48:54.343235"
    },
    {
      "arxiv_id": "2402.08648v1",
      "title": "Generating Universal Adversarial Perturbations for Quantum Classifiers",
      "title_zh": "为量子分类器生成通用对抗扰动",
      "authors": [
        "Gautham Anil",
        "Vishnu Vinod",
        "Apurva Narayan"
      ],
      "abstract": "Quantum Machine Learning (QML) has emerged as a promising field of research,\naiming to leverage the capabilities of quantum computing to enhance existing\nmachine learning methodologies. Recent studies have revealed that, like their\nclassical counterparts, QML models based on Parametrized Quantum Circuits\n(PQCs) are also vulnerable to adversarial attacks. Moreover, the existence of\nUniversal Adversarial Perturbations (UAPs) in the quantum domain has been\ndemonstrated theoretically in the context of quantum classifiers. In this work,\nwe introduce QuGAP: a novel framework for generating UAPs for quantum\nclassifiers. We conceptualize the notion of additive UAPs for PQC-based\nclassifiers and theoretically demonstrate their existence. We then utilize\ngenerative models (QuGAP-A) to craft additive UAPs and experimentally show that\nquantum classifiers are susceptible to such attacks. Moreover, we formulate a\nnew method for generating unitary UAPs (QuGAP-U) using quantum generative\nmodels and a novel loss function based on fidelity constraints. We evaluate the\nperformance of the proposed framework and show that our method achieves\nstate-of-the-art misclassification rates, while maintaining high fidelity\nbetween legitimate and adversarial samples.",
      "tldr_zh": "这篇论文探讨了量子机器学习 (QML) 中的安全问题，证明了基于参数化量子电路 (PQCs) 的量子分类器易受通用对抗扰动 (UAPs) 攻击。作者引入了 QuGAP 框架，包括 QuGAP-A 方法利用生成模型创建添加性 UAPs，以及 QuGAP-U 方法使用量子生成模型和基于保真度约束的损失函数生成单体 UAPs。实验结果显示，该框架实现了最先进的误分类率，同时保持合法和对抗样本之间的高 fidelity，为提升 QML 模型的鲁棒性提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at AAAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.08648v1",
      "published_date": "2024-02-13 18:27:53 UTC",
      "updated_date": "2024-02-13 18:27:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:49:06.253960"
    },
    {
      "arxiv_id": "2402.08646v1",
      "title": "Inference of Abstraction for a Unified Account of Symbolic Reasoning from Data",
      "title_zh": "翻译失败",
      "authors": [
        "Hiroyuki Kido"
      ],
      "abstract": "Inspired by empirical work in neuroscience for Bayesian approaches to brain\nfunction, we give a unified probabilistic account of various types of symbolic\nreasoning from data. We characterise them in terms of formal logic using the\nclassical consequence relation, an empirical consequence relation, maximal\nconsistent sets, maximal possible sets and maximum likelihood estimation. The\ntheory gives new insights into reasoning towards human-like machine\nintelligence.",
      "tldr_zh": "本论文提出一个统一的概率框架，用于从数据中推断抽象，从而解释各种类型的符号推理（symbolic reasoning），其灵感来源于神经科学（neuroscience）和贝叶斯方法（Bayesian approaches）。该框架通过形式逻辑（formal logic）的工具，如经典推论关系（classical consequence relation）、经验推论关系（empirical consequence relation）、最大一致集（maximal consistent sets）、最大可能集（maximal possible sets）和最大似然估计（maximum likelihood estimation）来表征这些推理过程。最终，该理论为实现类似人类的机器智能（human-like machine intelligence）提供了新的见解和潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08646v1",
      "published_date": "2024-02-13 18:24:23 UTC",
      "updated_date": "2024-02-13 18:24:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:49:17.783910"
    },
    {
      "arxiv_id": "2402.08644v4",
      "title": "Tandem Transformers for Inference Efficient LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Aishwarya P S",
        "Pranav Ajit Nair",
        "Yashas Samaga",
        "Toby Boyd",
        "Sanjiv Kumar",
        "Prateek Jain",
        "Praneeth Netrapalli"
      ],
      "abstract": "The autoregressive nature of conventional large language models (LLMs)\ninherently limits inference speed, as tokens are generated sequentially. While\nspeculative and parallel decoding techniques attempt to mitigate this, they\nface limitations: either relying on less accurate smaller models for generation\nor failing to fully leverage the base LLM's representations.\n  We introduce a novel architecture, Tandem transformers, to address these\nissues. This architecture uniquely combines (1) a small autoregressive model\nand (2) a large model operating in block mode (processing multiple tokens\nsimultaneously). The small model's predictive accuracy is substantially\nenhanced by granting it attention to the large model's richer representations.\nOn the PaLM2 pretraining dataset, a tandem of PaLM2-Bison and PaLM2-Gecko\ndemonstrates a 3.3% improvement in next-token prediction accuracy over a\nstandalone PaLM2-Gecko, offering a 1.16x speedup compared to a PaLM2-Otter\nmodel with comparable downstream performance. We further incorporate the tandem\nmodel within the speculative decoding (SPEED) framework where the large model\nvalidates tokens from the small model. This ensures that the Tandem of\nPaLM2-Bison and PaLM2-Gecko achieves substantial speedup (around 1.14x faster\nthan using vanilla PaLM2-Gecko in SPEED) while maintaining identical downstream\ntask accuracy.",
      "tldr_zh": "该论文提出Tandem Transformers架构，以提升大型语言模型(LLMs)的推理效率。该架构结合了一个小型自回归模型和一个大型模型（以块模式处理多个tokens），通过让小型模型访问大型模型的丰富表示来显著提高预测准确性。在PaLM2预训练数据集上，PaLM2-Bison和PaLM2-Gecko的Tandem组合比独立PaLM2-Gecko在下一个token预测准确率提升3.3%，并实现1.16x加速。随后，将其整合到speculative decoding框架(SPEED)中，进一步获得1.14x速度提升，同时保持下游任务准确性不变。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08644v4",
      "published_date": "2024-02-13 18:24:08 UTC",
      "updated_date": "2024-10-20 15:34:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:49:30.178183"
    },
    {
      "arxiv_id": "2402.08640v3",
      "title": "Forecasting high-impact research topics via machine learning on evolving knowledge graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Xuemei Gu",
        "Mario Krenn"
      ],
      "abstract": "The exponential growth in scientific publications poses a severe challenge\nfor human researchers. It forces attention to more narrow sub-fields, which\nmakes it challenging to discover new impactful research ideas and\ncollaborations outside one's own field. While there are ways to predict a\nscientific paper's future citation counts, they need the research to be\nfinished and the paper written, usually assessing impact long after the idea\nwas conceived. Here we show how to predict the impact of onsets of ideas that\nhave never been published by researchers. For that, we developed a large\nevolving knowledge graph built from more than 21 million scientific papers. It\ncombines a semantic network created from the content of the papers and an\nimpact network created from the historic citations of papers. Using machine\nlearning, we can predict the dynamic of the evolving network into the future\nwith high accuracy (AUC values beyond 0.9 for most experiments), and thereby\nthe impact of new research directions. We envision that the ability to predict\nthe impact of new ideas will be a crucial component of future artificial muses\nthat can inspire new impactful and interesting scientific ideas.",
      "tldr_zh": "该研究针对科学出版物指数级增长导致的研究者视野狭窄问题，提出了一种预测未发表新想法影响的方法。研究构建了一个由超过2100万篇论文形成的演化知识图谱，包括语义网络（基于论文内容）和影响网络（基于历史引用）。通过machine learning模型预测知识图谱的未来动态，实现了高准确率（AUC值超过0.9），从而评估新研究方向的潜在影响。该方法有望成为未来人工智能缪斯的关键组件，帮助激发高影响力科学想法。",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DL",
      "comment": "13 pages, 12 figures, Comments welcome!",
      "pdf_url": "http://arxiv.org/pdf/2402.08640v3",
      "published_date": "2024-02-13 18:09:38 UTC",
      "updated_date": "2025-01-07 21:19:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:49:41.854900"
    },
    {
      "arxiv_id": "2402.08631v2",
      "title": "Knowledge Editing on Black-box Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoshuai Song",
        "Zhengyang Wang",
        "Keqing He",
        "Guanting Dong",
        "Yutao Mou",
        "Jinxu Zhao",
        "Weiran Xu"
      ],
      "abstract": "Knowledge editing (KE) aims to efficiently and precisely modify the behavior\nof large language models (LLMs) to update specific knowledge without negatively\ninfluencing other knowledge. Current research primarily focuses on white-box\nLLMs editing, overlooking an important scenario: black-box LLMs editing, where\nLLMs are accessed through interfaces and only textual output is available. In\nthis paper, we first officially introduce KE on black-box LLMs and then propose\na comprehensive evaluation framework to overcome the limitations of existing\nevaluations that are not applicable to black-box LLMs editing and lack\ncomprehensiveness. To tackle privacy leaks of editing data and style\nover-editing in current methods, we introduce a novel postEdit framework,\nresolving privacy concerns through downstream post-processing and maintaining\ntextual style consistency via fine-grained editing to original responses.\nExperiments and analysis on two benchmarks demonstrate that postEdit\noutperforms all baselines and achieves strong generalization, especially with\nhuge improvements on style retention (average $+20.82\\%\\uparrow$).",
      "tldr_zh": "该论文正式引入了针对黑-box Large Language Models (LLMs) 的 Knowledge Editing (KE) 问题，旨在高效精确地更新特定知识而不影响其他知识，同时解决当前研究忽略的黑盒场景（仅通过接口访问文本输出）。作者提出一个全面的评估框架，以弥补现有方法在适用性和全面性上的不足，并开发了 postEdit 框架，通过下游后处理避免编辑数据的隐私泄露，并利用细粒度编辑维持文本风格一致性。实验在两个基准上显示，postEdit 优于所有基线模型，尤其在风格保留方面平均提升 20.82%，并展现出强大的泛化能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2402.08631v2",
      "published_date": "2024-02-13 17:59:34 UTC",
      "updated_date": "2024-02-17 16:06:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:49:53.588054"
    },
    {
      "arxiv_id": "2402.08609v3",
      "title": "Mixtures of Experts Unlock Parameter Scaling for Deep RL",
      "title_zh": "翻译失败",
      "authors": [
        "Johan Obando-Ceron",
        "Ghada Sokar",
        "Timon Willi",
        "Clare Lyle",
        "Jesse Farebrother",
        "Jakob Foerster",
        "Gintare Karolina Dziugaite",
        "Doina Precup",
        "Pablo Samuel Castro"
      ],
      "abstract": "The recent rapid progress in (self) supervised learning models is in large\npart predicted by empirical scaling laws: a model's performance scales\nproportionally to its size. Analogous scaling laws remain elusive for\nreinforcement learning domains, however, where increasing the parameter count\nof a model often hurts its final performance. In this paper, we demonstrate\nthat incorporating Mixture-of-Expert (MoE) modules, and in particular Soft MoEs\n(Puigcerver et al., 2023), into value-based networks results in more\nparameter-scalable models, evidenced by substantial performance increases\nacross a variety of training regimes and model sizes. This work thus provides\nstrong empirical evidence towards developing scaling laws for reinforcement\nlearning.",
      "tldr_zh": "本文发现，强化学习（RL）领域缺乏类似于监督学习的参数缩放定律，因为增加模型参数通常会降低最终性能。研究者通过在价值-based 网络中整合 Mixture-of-Expert (MoE) 模块，特别是 Soft MoEs (Puigcerver et al., 2023)，实现了更具可缩放性的模型设计。实验结果显示，这种方法在多种训练制度和模型规模下显著提升了性能，为建立 RL 的缩放定律提供了强有力的经验证据。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08609v3",
      "published_date": "2024-02-13 17:18:56 UTC",
      "updated_date": "2024-06-26 16:50:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:50:04.987859"
    },
    {
      "arxiv_id": "2402.08703v2",
      "title": "A Survey of Generative AI for de novo Drug Design: New Frontiers in Molecule and Protein Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Xiangru Tang",
        "Howard Dai",
        "Elizabeth Knight",
        "Fang Wu",
        "Yunyang Li",
        "Tianxiao Li",
        "Mark Gerstein"
      ],
      "abstract": "Artificial intelligence (AI)-driven methods can vastly improve the\nhistorically costly drug design process, with various generative models already\nin widespread use. Generative models for de novo drug design, in particular,\nfocus on the creation of novel biological compounds entirely from scratch,\nrepresenting a promising future direction. Rapid development in the field,\ncombined with the inherent complexity of the drug design process, creates a\ndifficult landscape for new researchers to enter. In this survey, we organize\nde novo drug design into two overarching themes: small molecule and protein\ngeneration. Within each theme, we identify a variety of subtasks and\napplications, highlighting important datasets, benchmarks, and model\narchitectures and comparing the performance of top models. We take a broad\napproach to AI-driven drug design, allowing for both micro-level comparisons of\nvarious methods within each subtask and macro-level observations across\ndifferent fields. We discuss parallel challenges and approaches between the two\napplications and highlight future directions for AI-driven de novo drug design\nas a whole. An organized repository of all covered sources is available at\nhttps://github.com/gersteinlab/GenAI4Drug.",
      "tldr_zh": "这篇调查论文综述了生成式 AI 在 de novo 药物设计中的应用，聚焦于从零开始创建新生物化合物的分子和蛋白质生成两大主题。论文组织了相关子任务、重要数据集、基准测试和模型架构，并对顶级模型的表现进行了微观和宏观比较，揭示了这两个领域的平行挑战和方法。最终，它突出了 AI 驱动药物设计的未来方向，并提供了一个资源存储库（https://github.com/gersteinlab/GenAI4Drug），以便研究者快速进入该领域。",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.BM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08703v2",
      "published_date": "2024-02-13 16:56:31 UTC",
      "updated_date": "2024-06-26 11:03:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:50:17.089157"
    },
    {
      "arxiv_id": "2402.08593v2",
      "title": "Graph Feature Preprocessor: Real-time Subgraph-based Feature Extraction for Financial Crime Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Jovan Blanuša",
        "Maximo Cravero Baraja",
        "Andreea Anghel",
        "Luc von Niederhäusern",
        "Erik Altman",
        "Haris Pozidis",
        "Kubilay Atasu"
      ],
      "abstract": "In this paper, we present \"Graph Feature Preprocessor\", a software library\nfor detecting typical money laundering patterns in financial transaction graphs\nin real time. These patterns are used to produce a rich set of transaction\nfeatures for downstream machine learning training and inference tasks such as\ndetection of fraudulent financial transactions. We show that our enriched\ntransaction features dramatically improve the prediction accuracy of\ngradient-boosting-based machine learning models. Our library exploits multicore\nparallelism, maintains a dynamic in-memory graph, and efficiently mines\nsubgraph patterns in the incoming transaction stream, which enables it to be\noperated in a streaming manner. Our solution, which combines our Graph Feature\nPreprocessor and gradient-boosting-based machine learning models, can detect\nillicit transactions with higher minority-class F1 scores than standard graph\nneural networks in anti-money laundering and phishing datasets. In addition,\nthe end-to-end throughput rate of our solution executed on a multicore CPU\noutperforms the graph neural network baselines executed on a powerful V100 GPU.\nOverall, the combination of high accuracy, a high throughput rate, and low\nlatency of our solution demonstrates the practical value of our library in\nreal-world applications.",
      "tldr_zh": "本研究引入了 Graph Feature Preprocessor，这是一个实时子图-based特征提取软件库，用于检测金融交易图中的典型洗钱模式，并生成丰富的交易特征以支持下游机器学习任务，如欺诈交易检测。库通过利用多核并行处理、动态内存图和高效子图模式挖掘，实现流式处理，并与梯度-boosting机器学习模型结合，显著提升了预测准确性。实验结果显示，该解决方案在反洗钱和网络钓鱼数据集上，比标准Graph Neural Networks实现了更高的少数类F1分数，同时在多核CPU上的端到端吞吐率超过了在V100 GPU上运行的基线模型，证明了其在实际金融犯罪检测中的高实用价值。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ACM ICAIF'24, extended version",
      "pdf_url": "http://arxiv.org/pdf/2402.08593v2",
      "published_date": "2024-02-13 16:53:48 UTC",
      "updated_date": "2024-10-03 09:38:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:50:30.471077"
    },
    {
      "arxiv_id": "2402.08702v4",
      "title": "PRompt Optimization in Multi-Step Tasks (PROMST): Integrating Human Feedback and Heuristic-based Sampling",
      "title_zh": "翻译失败",
      "authors": [
        "Yongchao Chen",
        "Jacob Arkin",
        "Yilun Hao",
        "Yang Zhang",
        "Nicholas Roy",
        "Chuchu Fan"
      ],
      "abstract": "Prompt optimization aims to find the best prompt to a large language model\n(LLM) for a given task. LLMs have been successfully used to help find and\nimprove prompt candidates for single-step tasks. However, realistic tasks for\nagents are multi-step and introduce new challenges: (1) Prompt content is\nlikely to be more extensive and complex, making it more difficult for LLMs to\nanalyze errors, (2) the impact of an individual step is difficult to evaluate,\nand (3) different people may have varied preferences about task execution.\nWhile humans struggle to optimize prompts, they are good at providing feedback\nabout LLM outputs; we therefore introduce a new LLM-driven discrete prompt\noptimization framework PRompt Optimization in Multi-Step Tasks (PROMST) that\nincorporates human-designed feedback rules to automatically offer direct\nsuggestions for improvement. We also use an extra learned heuristic model that\npredicts prompt performance to efficiently sample from prompt candidates. This\napproach significantly outperforms both human-engineered prompts and several\nother prompt optimization methods across 11 representative multi-step tasks (an\naverage 10.6\\%-29.3\\% improvement to current best methods on five LLMs\nrespectively). We believe our work can serve as a benchmark for automatic\nprompt optimization for LLM-driven multi-step tasks. Datasets and Codes are\navailable at https://github.com/yongchao98/PROMST. Project Page is available at\nhttps://yongchao98.github.io/MIT-REALM-PROMST.",
      "tldr_zh": "本文提出PROMST框架，用于优化大型语言模型(LLMs)提示在多步任务中的性能，解决提示内容复杂、步骤影响评估困难以及用户偏好差异等挑战。PROMST整合人类反馈(human feedback)规则来自动生成改进建议，并使用一个学习启发式模型(heuristic-based sampling)预测提示性能以高效采样候选提示。该方法在11个代表性多步任务上显著优于现有优化技术，平均提升10.6%至29.3%的性能，为LLM驱动多步任务的自动提示优化( Prompt optimization)提供了新基准。数据集和代码已在GitHub上公开。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.RO"
      ],
      "primary_category": "cs.CL",
      "comment": "62 pages, 14 figures, Published in EMNLP 2024 Main",
      "pdf_url": "http://arxiv.org/pdf/2402.08702v4",
      "published_date": "2024-02-13 16:38:01 UTC",
      "updated_date": "2024-10-03 16:11:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:50:42.900687"
    },
    {
      "arxiv_id": "2402.08582v2",
      "title": "FESS Loss: Feature-Enhanced Spatial Segmentation Loss for Optimizing Medical Image Analysis",
      "title_zh": "FESS Loss：特征增强的空间分割损失函数，用于优化医学图像分析",
      "authors": [
        "Charulkumar Chodvadiya",
        "Navyansh Mahla",
        "Kinshuk Gaurav Singh",
        "Kshitij Sharad Jadhav"
      ],
      "abstract": "Medical image segmentation is a critical process in the field of medical\nimaging, playing a pivotal role in diagnosis, treatment, and research. It\ninvolves partitioning of an image into multiple regions, representing distinct\nanatomical or pathological structures. Conventional methods often grapple with\nthe challenge of balancing spatial precision and comprehensive feature\nrepresentation due to their reliance on traditional loss functions. To overcome\nthis, we propose Feature-Enhanced Spatial Segmentation Loss (FESS Loss), that\nintegrates the benefits of contrastive learning (which extracts intricate\nfeatures, particularly in the nuanced domain of medical imaging) with the\nspatial accuracy inherent in the Dice loss. The objective is to augment both\nspatial precision and feature-based representation in the segmentation of\nmedical images. FESS Loss signifies a notable advancement, offering a more\naccurate and refined segmentation process, ultimately contributing to\nheightened precision in the analysis of medical images. Further, FESS loss\ndemonstrates superior performance in limited annotated data availability\nscenarios often present in the medical domain.",
      "tldr_zh": "本研究针对医疗图像分割中传统方法在空间精度和特征表示平衡上的挑战，提出了一种新型损失函数FESS Loss（Feature-Enhanced Spatial Segmentation Loss）。FESS Loss将对比学习（contrastive learning）的特征提取能力与Dice loss的空间精度相结合，提升了医疗图像的分割准确性和精细度。实验结果显示，该方法在数据标注有限的场景下表现出色，有助于提高诊断和治疗的整体精度。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "5 Pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.08582v2",
      "published_date": "2024-02-13 16:36:21 UTC",
      "updated_date": "2024-02-26 14:15:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:50:52.762539"
    },
    {
      "arxiv_id": "2402.08578v1",
      "title": "FedLPS: Heterogeneous Federated Learning for Multiple Tasks with Local Parameter Sharing",
      "title_zh": "翻译失败",
      "authors": [
        "Yongzhe Jia",
        "Xuyun Zhang",
        "Amin Beheshti",
        "Wanchun Dou"
      ],
      "abstract": "Federated Learning (FL) has emerged as a promising solution in Edge Computing\n(EC) environments to process the proliferation of data generated by edge\ndevices. By collaboratively optimizing the global machine learning models on\ndistributed edge devices, FL circumvents the need for transmitting raw data and\nenhances user privacy. Despite practical successes, FL still confronts\nsignificant challenges including constrained edge device resources, multiple\ntasks deployment, and data heterogeneity. However, existing studies focus on\nmitigating the FL training costs of each single task whereas neglecting the\nresource consumption across multiple tasks in heterogeneous FL scenarios. In\nthis paper, we propose Heterogeneous Federated Learning with Local Parameter\nSharing (FedLPS) to fill this gap. FedLPS leverages principles from transfer\nlearning to facilitate the deployment of multiple tasks on a single device by\ndividing the local model into a shareable encoder and task-specific encoders.\nTo further reduce resource consumption, a channel-wise model pruning algorithm\nthat shrinks the footprint of local models while accounting for both data and\nsystem heterogeneity is employed in FedLPS. Additionally, a novel heterogeneous\nmodel aggregation algorithm is proposed to aggregate the heterogeneous\npredictors in FedLPS. We implemented the proposed FedLPS on a real FL platform\nand compared it with state-of-the-art (SOTA) FL frameworks. The experimental\nresults on five popular datasets and two modern DNN models illustrate that the\nproposed FedLPS significantly outperforms the SOTA FL frameworks by up to 4.88%\nand reduces the computational resource consumption by 21.3%. Our code is\navailable at:https://github.com/jyzgh/FedLPS.",
      "tldr_zh": "本研究提出FedLPS，一种异质联邦学习(Heterogeneous Federated Learning)框架，旨在通过本地参数共享(Local Parameter Sharing)处理边缘计算(Edge Computing)环境中多任务部署和数据异质性的挑战。FedLPS将本地模型分为可共享的编码器和任务特定编码器，并结合通道级模型剪枝算法和新型异质模型聚合算法，以减少资源消耗并提升训练效率。在五个流行数据集和两个现代DNN模型上的实验表明，FedLPS相较于现有SOTA联邦学习框架，准确率提升高达4.88%，并降低21.3%的计算资源消耗。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by AAAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.08578v1",
      "published_date": "2024-02-13 16:30:30 UTC",
      "updated_date": "2024-02-13 16:30:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:51:06.584994"
    },
    {
      "arxiv_id": "2402.08570v1",
      "title": "Online Foundation Model Selection in Robotics",
      "title_zh": "机器人学中的在线基础模型选择",
      "authors": [
        "Po-han Li",
        "Oyku Selin Toprak",
        "Aditya Narayanan",
        "Ufuk Topcu",
        "Sandeep Chinchali"
      ],
      "abstract": "Foundation models have recently expanded into robotics after excelling in\ncomputer vision and natural language processing. The models are accessible in\ntwo ways: open-source or paid, closed-source options. Users with access to both\nface a problem when deciding between effective yet costly closed-source models\nand free but less powerful open-source alternatives. We call it the model\nselection problem. Existing supervised-learning methods are impractical due to\nthe high cost of collecting extensive training data from closed-source models.\nHence, we focus on the online learning setting where algorithms learn while\ncollecting data, eliminating the need for large pre-collected datasets. We thus\nformulate a user-centric online model selection problem and propose a novel\nsolution that combines an open-source encoder to output context and an online\nlearning algorithm that processes this context. The encoder distills vast data\ndistributions into low-dimensional features, i.e., the context, without\nadditional training. The online learning algorithm aims to maximize a composite\nreward that includes model performance, execution time, and costs based on the\ncontext extracted from the data. It results in an improved trade-off between\nselecting open-source and closed-source models compared to non-contextual\nmethods, as validated by our theoretical analysis. Experiments across\nlanguage-based robotic tasks such as Waymo Open Dataset, ALFRED, and Open\nX-Embodiment demonstrate real-world applications of the solution. The results\nshow that the solution significantly improves the task success rate by up to\n14%.",
      "tldr_zh": "本研究解决了机器人领域的基础模型（Foundation models）选择问题，即如何在免费但性能较弱的开源模型和有效但成本较高的闭源模型之间权衡。论文提出了一种在线学习（online learning）框架，使用开源编码器提取数据上下文，然后通过在线算法最大化综合奖励，包括模型性能、执行时间和成本，从而避免了大量预先收集训练数据的需求。理论分析证明了该方法相对于非上下文方法在模型选择权衡上的改进，并在Waymo Open Dataset、ALFRED和Open X-Embodiment等语言-based机器人任务中实验验证，任务成功率最高提升14%。这项工作为用户提供了一个实用、可扩展的模型选择策略，提升了机器人应用的效率和经济性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08570v1",
      "published_date": "2024-02-13 16:14:32 UTC",
      "updated_date": "2024-02-13 16:14:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:51:18.440213"
    },
    {
      "arxiv_id": "2402.08565v2",
      "title": "Artificial Intelligence for Literature Reviews: Opportunities and Challenges",
      "title_zh": "翻译失败",
      "authors": [
        "Francisco Bolanos",
        "Angelo Salatino",
        "Francesco Osborne",
        "Enrico Motta"
      ],
      "abstract": "This manuscript presents a comprehensive review of the use of Artificial\nIntelligence (AI) in Systematic Literature Reviews (SLRs). A SLR is a rigorous\nand organised methodology that assesses and integrates previous research on a\ngiven topic. Numerous tools have been developed to assist and partially\nautomate the SLR process. The increasing role of AI in this field shows great\npotential in providing more effective support for researchers, moving towards\nthe semi-automatic creation of literature reviews. Our study focuses on how AI\ntechniques are applied in the semi-automation of SLRs, specifically in the\nscreening and extraction phases. We examine 21 leading SLR tools using a\nframework that combines 23 traditional features with 11 AI features. We also\nanalyse 11 recent tools that leverage large language models for searching the\nliterature and assisting academic writing. Finally, the paper discusses current\ntrends in the field, outlines key research challenges, and suggests directions\nfor future research.",
      "tldr_zh": "这篇论文对Artificial Intelligence (AI)在Systematic Literature Reviews (SLRs)中的应用进行了全面综述，强调AI如何辅助文献筛选和提取阶段，实现半自动化过程。研究者评估了21个领先的SLR工具，使用一个结合23个传统特征和11个AI特征的框架，并分析了11个基于large language models的工具，以探讨AI在学术写作和文献搜索中的作用。论文总结了当前趋势、关键挑战，如工具的准确性和可解释性，并为未来研究方向提出建议。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "Updated with the reviewers comments. This version is now accepted at\n  the Artificial Intelligence Review journal",
      "pdf_url": "http://arxiv.org/pdf/2402.08565v2",
      "published_date": "2024-02-13 16:05:51 UTC",
      "updated_date": "2024-08-06 15:40:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:51:29.672823"
    },
    {
      "arxiv_id": "2402.08562v1",
      "title": "Higher Layers Need More LoRA Experts",
      "title_zh": "翻译失败",
      "authors": [
        "Chongyang Gao",
        "Kezhen Chen",
        "Jinmeng Rao",
        "Baochen Sun",
        "Ruibo Liu",
        "Daiyi Peng",
        "Yawen Zhang",
        "Xiaoyuan Guo",
        "Jie Yang",
        "VS Subrahmanian"
      ],
      "abstract": "Parameter-efficient tuning (PEFT) techniques like low-rank adaptation (LoRA)\noffer training efficiency on Large Language Models, but their impact on model\nperformance remains limited. Recent efforts integrate LoRA and\nMixture-of-Experts (MoE) to improve the performance of PEFT methods. Despite\npromising results, research on improving the efficiency of LoRA with MoE is\nstill in its early stages. Recent studies have shown that experts in the MoE\narchitecture have different strengths and also exhibit some redundancy. Does\nthis statement also apply to parameter-efficient MoE? In this paper, we\nintroduce a novel parameter-efficient MoE method,\n\\textit{\\textbf{M}oE-L\\textbf{o}RA with \\textbf{L}ayer-wise Expert\n\\textbf{A}llocation (MoLA)} for Transformer-based models, where each model\nlayer has the flexibility to employ a varying number of LoRA experts. We\ninvestigate several architectures with varying layer-wise expert\nconfigurations. Experiments on six well-known NLP and commonsense QA benchmarks\ndemonstrate that MoLA achieves equal or superior performance compared to all\nbaselines. We find that allocating more LoRA experts to higher layers further\nenhances the effectiveness of models with a certain number of experts in total.\nWith much fewer parameters, this allocation strategy outperforms the setting\nwith the same number of experts in every layer. This work can be widely used as\na plug-and-play parameter-efficient tuning approach for various applications.\nThe code is available at https://github.com/GCYZSL/MoLA.",
      "tldr_zh": "本文提出了一种新型参数高效微调（PEFT）方法MoLA（MoE-LoRA with Layer-wise Expert Allocation），它将Low-Rank Adaptation (LoRA) 与Mixture-of-Experts (MoE) 结合，允许Transformer模型的每个层灵活分配不同数量的LoRA experts，以优化模型性能。实验在六个NLP和常识QA基准上显示，MoLA比基线方法表现出色，尤其是在总experts数量固定时，向高层分配更多experts能进一步提升效果，并使用更少的参数。总体而言，这一策略证明了高层需要更多LoRA experts，并可作为即插即用的PEFT方法应用于各种场景。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "The code is available at https://github.com/GCYZSL/MoLA",
      "pdf_url": "http://arxiv.org/pdf/2402.08562v1",
      "published_date": "2024-02-13 16:04:21 UTC",
      "updated_date": "2024-02-13 16:04:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:51:42.019993"
    },
    {
      "arxiv_id": "2402.08547v2",
      "title": "Dueling Over Dessert, Mastering the Art of Repeated Cake Cutting",
      "title_zh": "甜点之争：掌握重复切割蛋糕的艺术",
      "authors": [
        "Simina Brânzei",
        "MohammadTaghi Hajiaghayi",
        "Reed Phillips",
        "Suho Shin",
        "Kun Wang"
      ],
      "abstract": "We consider the setting of repeated fair division between two players,\ndenoted Alice and Bob, with private valuations over a cake. In each round, a\nnew cake arrives, which is identical to the ones in previous rounds. Alice cuts\nthe cake at a point of her choice, while Bob chooses the left piece or the\nright piece, leaving the remainder for Alice. We consider two versions:\nsequential, where Bob observes Alice's cut point before choosing left/right,\nand simultaneous, where he only observes her cut point after making his choice.\nThe simultaneous version was first considered by Aumann and Maschler (1995).\n  We observe that if Bob is almost myopic and chooses his favorite piece too\noften, then he can be systematically exploited by Alice through a strategy akin\nto a binary search. This strategy allows Alice to approximate Bob's preferences\nwith increasing precision, thereby securing a disproportionate share of the\nresource over time.\n  We analyze the limits of how much a player can exploit the other one and show\nthat fair utility profiles are in fact achievable. Specifically, the players\ncan enforce the equitable utility profile of $(1/2, 1/2)$ in the limit on every\ntrajectory of play, by keeping the other player's utility to approximately\n$1/2$ on average while guaranteeing they themselves get at least approximately\n$1/2$ on average. We show this theorem using a connection with Blackwell\napproachability.\n  Finally, we analyze a natural dynamic known as fictitious play, where players\nbest respond to the empirical distribution of the other player. We show that\nfictitious play converges to the equitable utility profile of $(1/2, 1/2)$ at a\nrate of $O(1/\\sqrt{T})$.",
      "tldr_zh": "这篇论文探讨了两个玩家（Alice 和 Bob）在重复公平分配蛋糕的场景中，Alice 切割蛋糕而 Bob 选择片段的策略，涉及顺序和同时版本。论文发现，如果 Bob 过于短视偏好当前片段，Alice 可以通过类似二分搜索的策略逐步推断 Bob 的偏好，从而长期获得更多份额。研究证明，通过 Blackwellell approachability，玩家能强制实现公平效用分布（1/2, 1/2），即在长期平均上确保双方各得约一半；此外，虚构游戏（fictitious play）会以 O(1/√T) 的速度收敛到这一均衡点。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "econ.TH"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08547v2",
      "published_date": "2024-02-13 15:53:09 UTC",
      "updated_date": "2024-02-18 22:33:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:51:55.155407"
    },
    {
      "arxiv_id": "2402.08530v2",
      "title": "A Distributional Analogue to the Successor Representation",
      "title_zh": "翻译失败",
      "authors": [
        "Harley Wiltzer",
        "Jesse Farebrother",
        "Arthur Gretton",
        "Yunhao Tang",
        "André Barreto",
        "Will Dabney",
        "Marc G. Bellemare",
        "Mark Rowland"
      ],
      "abstract": "This paper contributes a new approach for distributional reinforcement\nlearning which elucidates a clean separation of transition structure and reward\nin the learning process. Analogous to how the successor representation (SR)\ndescribes the expected consequences of behaving according to a given policy,\nour distributional successor measure (SM) describes the distributional\nconsequences of this behaviour. We formulate the distributional SM as a\ndistribution over distributions and provide theory connecting it with\ndistributional and model-based reinforcement learning. Moreover, we propose an\nalgorithm that learns the distributional SM from data by minimizing a two-level\nmaximum mean discrepancy. Key to our method are a number of algorithmic\ntechniques that are independently valuable for learning generative models of\nstate. As an illustration of the usefulness of the distributional SM, we show\nthat it enables zero-shot risk-sensitive policy evaluation in a way that was\nnot previously possible.",
      "tldr_zh": "这篇论文提出了一种新的分布强化学习方法，即分布后继度量 (Distributional Successor Measure, SM)，作为 Successor Representation (SR) 的类比形式，用于清晰分离强化学习中的过渡结构和奖励。SM 被表述为一个分布上的分布，并提供了理论联系，将其与分布强化学习和基于模型的强化学习相结合。作者设计了一种算法，通过最小化两级最大均差 (maximum mean discrepancy) 从数据中学习 SM，并引入了一些独立有价值的技巧来学习状态的生成模型。作为关键应用，该方法实现了零样本风险敏感策略评估，这在之前无法实现，从而提升了强化学习的实用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to ICML 2024. First two authors contributed equally",
      "pdf_url": "http://arxiv.org/pdf/2402.08530v2",
      "published_date": "2024-02-13 15:35:24 UTC",
      "updated_date": "2024-05-24 16:29:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:52:06.242900"
    },
    {
      "arxiv_id": "2402.08514v2",
      "title": "Counterfactual Influence in Markov Decision Processes",
      "title_zh": "马尔可夫决策过程中的反事实影响",
      "authors": [
        "Milad Kazemi",
        "Jessica Lally",
        "Ekaterina Tishchenko",
        "Hana Chockler",
        "Nicola Paoletti"
      ],
      "abstract": "Our work addresses a fundamental problem in the context of counterfactual\ninference for Markov Decision Processes (MDPs). Given an MDP path $\\tau$, this\nkind of inference allows us to derive counterfactual paths $\\tau'$ describing\nwhat-if versions of $\\tau$ obtained under different action sequences than those\nobserved in $\\tau$. However, as the counterfactual states and actions deviate\nfrom the observed ones over time, the observation $\\tau$ may no longer\ninfluence the counterfactual world, meaning that the analysis is no longer\ntailored to the individual observation, resulting in interventional outcomes\nrather than counterfactual ones. Even though this issue specifically affects\nthe popular Gumbel-max structural causal model used for MDP counterfactuals, it\nhas remained overlooked until now. In this work, we introduce a formal\ncharacterisation of influence based on comparing counterfactual and\ninterventional distributions. We devise an algorithm to construct\ncounterfactual models that automatically satisfy influence constraints.\nLeveraging such models, we derive counterfactual policies that are not just\noptimal for a given reward structure but also remain tailored to the observed\npath. Even though there is an unavoidable trade-off between policy optimality\nand strength of influence constraints, our experiments demonstrate that it is\npossible to derive (near-)optimal policies while remaining under the influence\nof the observation.",
      "tldr_zh": "本文研究了Markov Decision Processes (MDPs)中的反事实推理问题，特别针对Gumbel-max结构因果模型中，当反事实路径偏离观察路径时，观察的影响可能缺失，导致结果转为干预性而非反事实性。作者引入了基于比较反事实分布和干预分布的正式影响表征，并开发了算法来构建满足影响约束的反事实模型，从而推导出既针对给定奖励结构最优又针对特定观察路径量身定制的反事实策略。尽管策略最优性和影响约束之间存在权衡，实验结果显示，可以实现（近似）最优策略，同时保持对观察路径的影响。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.08514v2",
      "published_date": "2024-02-13 15:10:30 UTC",
      "updated_date": "2025-03-27 13:59:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:52:20.521863"
    },
    {
      "arxiv_id": "2402.08511v1",
      "title": "Amplifying Exploration in Monte-Carlo Tree Search by Focusing on the Unknown",
      "title_zh": "通过聚焦未知来增强蒙特卡洛树搜索的探索",
      "authors": [
        "Cedric Derstroff",
        "Jannis Brugger",
        "Jannis Blüml",
        "Mira Mezini",
        "Stefan Kramer",
        "Kristian Kersting"
      ],
      "abstract": "Monte-Carlo tree search (MCTS) is an effective anytime algorithm with a vast\namount of applications. It strategically allocates computational resources to\nfocus on promising segments of the search tree, making it a very attractive\nsearch algorithm in large search spaces. However, it often expends its limited\nresources on reevaluating previously explored regions when they remain the most\npromising path. Our proposed methodology, denoted as AmEx-MCTS, solves this\nproblem by introducing a novel MCTS formulation. Central to AmEx-MCTS is the\ndecoupling of value updates, visit count updates, and the selected path during\nthe tree search, thereby enabling the exclusion of already explored subtrees or\nleaves. This segregation preserves the utility of visit counts for both\nexploration-exploitation balancing and quality metrics within MCTS. The\nresultant augmentation facilitates in a considerably broader search using\nidentical computational resources, preserving the essential characteristics of\nMCTS. The expanded coverage not only yields more precise estimations but also\nproves instrumental in larger and more complex problems. Our empirical\nevaluation demonstrates the superior performance of AmEx-MCTS, surpassing\nclassical MCTS and related approaches by a substantial margin.",
      "tldr_zh": "该研究针对Monte-Carlo Tree Search (MCTS)算法在资源分配上过度关注已探索区域的问题，提出了一种新方法AmEx-MCTS，通过解耦value updates、visit count updates和selected path，实现了对已探索子树或叶子的排除，从而放大探索范围。AmEx-MCTS保留了MCTS的核心特性，如探索-利用平衡，同时使用相同计算资源实现更广泛的搜索和更精确的估计。实验结果显示，AmEx-MCTS在更大、更复杂的问题上显著优于经典MCTS和相关方法，提供更高效的性能提升。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.08511v1",
      "published_date": "2024-02-13 15:05:54 UTC",
      "updated_date": "2024-02-13 15:05:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:52:30.431052"
    },
    {
      "arxiv_id": "2402.08509v1",
      "title": "From Shapes to Shapes: Inferring SHACL Shapes for Results of SPARQL CONSTRUCT Queries (Extended Version)",
      "title_zh": "从形状到形状：推断 SPARQL CONSTRUCT 查询结果的 SHACL 形状（扩展版本）",
      "authors": [
        "Philipp Seifer",
        "Daniel Hernández",
        "Ralf Lämmel",
        "Steffen Staab"
      ],
      "abstract": "SPARQL CONSTRUCT queries allow for the specification of data processing\npipelines that transform given input graphs into new output graphs. It is now\ncommon to constrain graphs through SHACL shapes allowing users to understand\nwhich data they can expect and which not. However, it becomes challenging to\nunderstand what graph data can be expected at the end of a data processing\npipeline without knowing the particular input data: Shape constraints on the\ninput graph may affect the output graph, but may no longer apply literally, and\nnew shapes may be imposed by the query template. In this paper, we study the\nderivation of shape constraints that hold on all possible output graphs of a\ngiven SPARQL CONSTRUCT query. We assume that the SPARQL CONSTRUCT query is\nfixed, e.g., being part of a program, whereas the input graphs adhere to input\nshape constraints but may otherwise vary over time and, thus, are mostly\nunknown. We study a fragment of SPARQL CONSTRUCT queries (SCCQ) and a fragment\nof SHACL (Simple SHACL). We formally define the problem of deriving the most\nrestrictive set of Simple SHACL shapes that constrain the results from\nevaluating a SCCQ over any input graph restricted by a given set of Simple\nSHACL shapes. We propose and implement an algorithm that statically analyses\ninput SHACL shapes and CONSTRUCT queries and prove its soundness and\ncomplexity.",
      "tldr_zh": "本论文探讨了从 SPARQL CONSTRUCT 查询的结果中推断 SHACL shapes 的问题，旨在解决数据处理管道输出图形约束的挑战，因为输入图形虽受输入 SHACL shapes 限制，但可能变化。研究聚焦于 SPARQL CONSTRUCT 查询的子集 (SCCQ) 和 SHACL 的子集 (Simple SHACL)，并正式定义了推断最严格的 Simple SHACL shapes 以约束所有可能输出图形的方法。作者提出并实现了一个静态分析算法，通过分析输入 SHACL shapes 和 CONSTRUCT 查询，来自动推断输出 shapes，并证明了该算法的正确性和计算复杂度。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.DB",
      "comment": "19 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.08509v1",
      "published_date": "2024-02-13 15:04:11 UTC",
      "updated_date": "2024-02-13 15:04:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:52:43.568337"
    },
    {
      "arxiv_id": "2402.08496v3",
      "title": "A Systematic Review of Data-to-Text NLG",
      "title_zh": "翻译失败",
      "authors": [
        "Chinonso Cynthia Osuji",
        "Thiago Castro Ferreira",
        "Brian Davis"
      ],
      "abstract": "This systematic review undertakes a comprehensive analysis of current\nresearch on data-to-text generation, identifying gaps, challenges, and future\ndirections within the field. Relevant literature in this field on datasets,\nevaluation metrics, application areas, multilingualism, language models, and\nhallucination mitigation methods is reviewed. Various methods for producing\nhigh-quality text are explored, addressing the challenge of hallucinations in\ndata-to-text generation. These methods include re-ranking, traditional and\nneural pipeline architecture, planning architectures, data cleaning, controlled\ngeneration, and modification of models and training techniques. Their\neffectiveness and limitations are assessed, highlighting the need for\nuniversally applicable strategies to mitigate hallucinations. The review also\nexamines the usage, popularity, and impact of datasets, alongside evaluation\nmetrics, with an emphasis on both automatic and human assessment. Additionally,\nthe evolution of data-to-text models, particularly the widespread adoption of\ntransformer models, is discussed. Despite advancements in text quality, the\nreview emphasizes the importance of research in low-resourced languages and the\nengineering of datasets in these languages to promote inclusivity. Finally,\nseveral application domains of data-to-text are highlighted, emphasizing their\nrelevance in such domains. Overall, this review serves as a guiding framework\nfor fostering innovation and advancing data-to-text generation.",
      "tldr_zh": "这篇系统综述对数据到文本生成（Data-to-Text NLG）领域进行了全面分析，识别了当前研究的差距、挑战和未来方向，包括数据集、评估指标、应用领域、多语言性和语言模型的演变。综述探讨了多种缓解幻觉（hallucinations）的方法，如再排名（re-ranking）、传统和神经管道架构、规划架构、数据清洗以及模型和训练技术的修改，并评估了这些方法的有效性和局限性。结果强调了transformer模型的广泛采用提高了文本质量，但仍需开发通用的幻觉缓解策略，并加强低资源语言的研究和数据集工程。该综述突出了数据到文本在各种应用领域的相关性，并为推动该领域的创新提供了指导框架。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08496v3",
      "published_date": "2024-02-13 14:51:45 UTC",
      "updated_date": "2024-02-27 00:05:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:52:56.269985"
    },
    {
      "arxiv_id": "2402.08492v1",
      "title": "The Application of ChatGPT in Responding to Questions Related to the Boston Bowel Preparation Scale",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoqiang Liu",
        "Yubin Wang",
        "Zicheng Huang",
        "Boming Xu",
        "Yilin Zeng",
        "Xinqi Chen",
        "Zilong Wang",
        "Enning Yang",
        "Xiaoxuan Lei",
        "Yisen Huang",
        "Xiaobo Liu"
      ],
      "abstract": "Background: Colonoscopy, a crucial diagnostic tool in gastroenterology,\ndepends heavily on superior bowel preparation. ChatGPT, a large language model\nwith emergent intelligence which also exhibits potential in medical\napplications. This study aims to assess the accuracy and consistency of ChatGPT\nin using the Boston Bowel Preparation Scale (BBPS) for colonoscopy assessment.\nMethods: We retrospectively collected 233 colonoscopy images from 2020 to 2023.\nThese images were evaluated using the BBPS by 3 senior endoscopists and 3\nnovice endoscopists. Additionally, ChatGPT also assessed these images, having\nbeen divided into three groups and undergone specific Fine-tuning. Consistency\nwas evaluated through two rounds of testing. Results: In the initial round,\nChatGPT's accuracy varied between 48.93% and 62.66%, trailing the endoscopists'\naccuracy of 76.68% to 77.83%. Kappa values for ChatGPT was between 0.52 and\n0.53, compared to 0.75 to 0.87 for the endoscopists. Conclusion: While ChatGPT\nshows promise in bowel preparation scoring, it currently does not match the\naccuracy and consistency of experienced endoscopists. Future research should\nfocus on in-depth Fine-tuning.",
      "tldr_zh": "本研究评估了ChatGPT在应用Boston Bowel Preparation Scale (BBPS)评估结肠镜图像时的准确性和一致性，旨在探讨其在肠道准备评分中的潜力。方法包括回顾性收集233张2010-2023年的结肠镜图像，由3名资深内镜医师和3名novice内镜医师进行评估，同时ChatGPT经过特定Fine-tuning后也参与评估，并进行了两轮测试。结果显示，ChatGPT的准确率在48.93%至62.66%之间，Kappa值在0.52至0.53，而内镜医师的准确率达76.68%至77.83%，Kappa值在0.75至0.87。结论是ChatGPT虽有前景，但目前无法匹敌经验丰富的内镜医师，未来需加强Fine-tuning。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08492v1",
      "published_date": "2024-02-13 14:38:12 UTC",
      "updated_date": "2024-02-13 14:38:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:53:09.003657"
    },
    {
      "arxiv_id": "2402.08491v3",
      "title": "Deep Reinforcement Learning for Controlled Traversing of the Attractor Landscape of Boolean Models in the Context of Cellular Reprogramming",
      "title_zh": "翻译失败",
      "authors": [
        "Andrzej Mizera",
        "Jakub Zarzycki"
      ],
      "abstract": "Cellular reprogramming can be used for both the prevention and cure of\ndifferent diseases. However, the efficiency of discovering reprogramming\nstrategies with classical wet-lab experiments is hindered by lengthy time\ncommitments and high costs. In this study, we develop a novel computational\nframework based on deep reinforcement learning that facilitates the\nidentification of reprogramming strategies. For this aim, we formulate a\ncontrol problem in the context of cellular reprogramming for the frameworks of\nBNs and PBNs under the asynchronous update mode. Furthermore, we introduce the\nnotion of a pseudo-attractor and a procedure for identification of\npseudo-attractor state during training. Finally, we devise a computational\nframework for solving the control problem, which we test on a number of\ndifferent models.",
      "tldr_zh": "本研究针对细胞重编程（cellular reprogramming）的效率问题，提出了一种基于深度强化学习（deep reinforcement learning）的计算框架，以加速发现重编程策略。该框架将细胞重编程建模为布尔网络（BNs）和概率布尔网络（PBNs）在异步更新模式下的控制问题，并引入伪吸引子（pseudo-attractor）概念及其识别程序，以优化吸引子景观（attractor landscape）的遍历过程。通过在多个模型上测试，该框架证明了其在高效识别重编程策略方面的潜力，为减少实验时间和成本提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.MN",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08491v3",
      "published_date": "2024-02-13 14:36:46 UTC",
      "updated_date": "2025-03-03 12:22:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:53:18.909833"
    },
    {
      "arxiv_id": "2402.08473v1",
      "title": "Intriguing Differences Between Zero-Shot and Systematic Evaluations of Vision-Language Transformer Models",
      "title_zh": "翻译失败",
      "authors": [
        "Shaeke Salman",
        "Md Montasir Bin Shams",
        "Xiuwen Liu",
        "Lingjiong Zhu"
      ],
      "abstract": "Transformer-based models have dominated natural language processing and other\nareas in the last few years due to their superior (zero-shot) performance on\nbenchmark datasets. However, these models are poorly understood due to their\ncomplexity and size. While probing-based methods are widely used to understand\nspecific properties, the structures of the representation space are not\nsystematically characterized; consequently, it is unclear how such models\ngeneralize and overgeneralize to new inputs beyond datasets. In this paper,\nbased on a new gradient descent optimization method, we are able to explore the\nembedding space of a commonly used vision-language model. Using the Imagenette\ndataset, we show that while the model achieves over 99\\% zero-shot\nclassification performance, it fails systematic evaluations completely. Using a\nlinear approximation, we provide a framework to explain the striking\ndifferences. We have also obtained similar results using a different model to\nsupport that our results are applicable to other transformer models with\ncontinuous inputs. We also propose a robust way to detect the modified images.",
      "tldr_zh": "这篇论文探讨了视觉语言 Transformer 模型在零样本(zero-shot)评估和系统评估(systematic evaluations)之间存在的显著差异，尽管这些模型在基准数据集上表现出色，但其泛化能力存在问题。研究者使用一种新的梯度下降优化方法探索模型的嵌入空间，并在 Imagenette 数据集上发现，模型零样本分类准确率超过99%，却在系统评估中完全失败。通过线性近似框架，他们解释了这些差异，并证明结果适用于其他 Transformer 模型。最后，论文提出了一种鲁棒方法来检测修改图像，从而提升模型的可信度。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "30 pages, 30 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.08473v1",
      "published_date": "2024-02-13 14:07:49 UTC",
      "updated_date": "2024-02-13 14:07:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:53:30.865731"
    },
    {
      "arxiv_id": "2402.08472v1",
      "title": "Large Language Models for the Automated Analysis of Optimization Algorithms",
      "title_zh": "大型语言模型用于优化算法的自动化分析",
      "authors": [
        "Camilo Chacón Sartori",
        "Christian Blum",
        "Gabriela Ochoa"
      ],
      "abstract": "The ability of Large Language Models (LLMs) to generate high-quality text and\ncode has fuelled their rise in popularity. In this paper, we aim to demonstrate\nthe potential of LLMs within the realm of optimization algorithms by\nintegrating them into STNWeb. This is a web-based tool for the generation of\nSearch Trajectory Networks (STNs), which are visualizations of optimization\nalgorithm behavior. Although visualizations produced by STNWeb can be very\ninformative for algorithm designers, they often require a certain level of\nprior knowledge to be interpreted. In an attempt to bridge this knowledge gap,\nwe have incorporated LLMs, specifically GPT-4, into STNWeb to produce extensive\nwritten reports, complemented by automatically generated plots, thereby\nenhancing the user experience and reducing the barriers to the adoption of this\ntool by the research community. Moreover, our approach can be expanded to other\ntools from the optimization community, showcasing the versatility and potential\nof LLMs in this field.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 在优化算法分析中的潜力，通过将其整合到 STNWeb 工具中，以生成 Search Trajectory Networks (STNs) 的可视化报告。STNWeb 的原有可视化需依赖用户先验知识，而加入 GPT-4 后，可自动创建详细的书面报告和图表，降低了门槛并提升了用户体验。该方法不仅展示了 LLMs 的多功能性，还可扩展至优化领域的其他工具。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Submitted to the GECCO 2024 conference",
      "pdf_url": "http://arxiv.org/pdf/2402.08472v1",
      "published_date": "2024-02-13 14:05:02 UTC",
      "updated_date": "2024-02-13 14:05:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:53:43.488024"
    },
    {
      "arxiv_id": "2402.08470v1",
      "title": "Parallel-friendly Spatio-Temporal Graph Learning for Photovoltaic Degradation Analysis at Scale",
      "title_zh": "翻译失败",
      "authors": [
        "Yangxin Fan",
        "Raymond Wieser",
        "Laura Bruckman",
        "Roger French",
        "Yinghui Wu"
      ],
      "abstract": "We propose a novel Spatio-Temporal Graph Neural Network empowered trend\nanalysis approach (ST-GTrend) to perform fleet-level performance degradation\nanalysis for Photovoltaic (PV) power networks. PV power stations have become an\nintegral component to the global sustainable energy production landscape.\nAccurately estimating the performance of PV systems is critical to their\nfeasibility as a power generation technology and as a financial asset. One of\nthe most challenging problems in assessing the Levelized Cost of Energy (LCOE)\nof a PV system is to understand and estimate the long-term Performance Loss\nRate (PLR) for large fleets of PV inverters. ST-GTrend integrates\nspatio-temporal coherence and graph attention to separate PLR as a long-term\n\"aging\" trend from multiple fluctuation terms in the PV input data. To cope\nwith diverse degradation patterns in timeseries, ST-GTrend adopts a paralleled\ngraph autoencoder array to extract aging and fluctuation terms simultaneously.\nST-GTrend imposes flatness and smoothness regularization to ensure the\ndisentanglement between aging and fluctuation. To scale the analysis to large\nPV systems, we also introduce Para-GTrend, a parallel algorithm to accelerate\nthe training and inference of ST-GTrend. We have evaluated ST-GTrend on three\nlarge-scale PV datasets, spanning a time period of 10 years. Our results show\nthat ST-GTrend reduces Mean Absolute Percent Error (MAPE) and Euclidean\nDistances by 34.74% and 33.66% compared to the SOTA methods. Our results\ndemonstrate that Para-GTrend can speed up ST-GTrend by up to 7.92 times. We\nfurther verify the generality and effectiveness of ST-GTrend for trend analysis\nusing financial and economic datasets.",
      "tldr_zh": "本研究提出了一种新型时空图神经网络方法ST-GTrend，用于大规模光伏（PV）电力网络的性能退化分析。该方法整合时空一致性和图注意力机制，将长期性能损失率（PLR）作为“老化”趋势与波动项分离，并采用并行图自编码器数组同时提取这些项，同时通过平坦性和平滑性正则化确保趋势的解耦。针对大型PV系统，引入了Para-GTrend算法来加速训练和推理。在三个10年跨度的PV数据集上，ST-GTrend相比现有最先进方法降低了34.74%的平均绝对百分比误差（MAPE）和33.66%的欧氏距离，并证明其在金融和经济数据集上的通用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08470v1",
      "published_date": "2024-02-13 14:00:59 UTC",
      "updated_date": "2024-02-13 14:00:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:53:55.230868"
    },
    {
      "arxiv_id": "2402.08466v2",
      "title": "Taking Training Seriously: Human Guidance and Management-Based Regulation of Artificial Intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Cary Coglianese",
        "Colton R. Crum"
      ],
      "abstract": "Fervent calls for more robust governance of the harms associated with\nartificial intelligence (AI) are leading to the adoption around the world of\nwhat regulatory scholars have called a management-based approach to regulation.\nRecent initiatives in the United States and Europe, as well as the adoption of\nmajor self-regulatory standards by the International Organization for\nStandardization, share in common a core management-based paradigm. These\nmanagement-based initiatives seek to motivate an increase in human oversight of\nhow AI tools are trained and developed. Refinements and systematization of\nhuman-guided training techniques will thus be needed to fit within this\nemerging era of management-based regulatory paradigm. If taken seriously,\nhuman-guided training can alleviate some of the technical and ethical pressures\non AI, boosting AI performance with human intuition as well as better\naddressing the needs for fairness and effective explainability. In this paper,\nwe discuss the connection between the emerging management-based regulatory\nframeworks governing AI and the need for human oversight during training. We\nbroadly cover some of the technical components involved in human-guided\ntraining and then argue that the kinds of high-stakes use cases for AI that\nappear of most concern to regulators should lean more on human-guided training\nthan on data-only training. We hope to foster a discussion between legal\nscholars and computer scientists involving how to govern a domain of technology\nthat is vast, heterogenous, and dynamic in its applications and risks.",
      "tldr_zh": "该论文探讨了管理型监管（management-based regulation）框架在治理人工智能（AI）风险中的作用，强调通过增加人类监督来提升AI工具的训练和开发过程。作者分析了人类指导训练（human-guided training）的技术组件，认为这种方法能缓解AI的技术和伦理压力，提高性能、公平性和可解释性。论文建议，高风险AI应用应优先采用人类指导训练而非仅依赖数据训练，以促进法律学者和计算机科学家之间的跨学科讨论。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2402.08466v2",
      "published_date": "2024-02-13 13:48:54 UTC",
      "updated_date": "2024-06-27 02:45:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:54:07.297234"
    },
    {
      "arxiv_id": "2402.08430v1",
      "title": "Analyzing Prompt Influence on Automated Method Generation: An Empirical Study with Copilot",
      "title_zh": "翻译失败",
      "authors": [
        "Ionut Daniel Fagadau",
        "Leonardo Mariani",
        "Daniela Micucci",
        "Oliviero Riganelli"
      ],
      "abstract": "Generative AI is changing the way developers interact with software systems,\nproviding services that can produce and deliver new content, crafted to satisfy\nthe actual needs of developers. For instance, developers can ask for new code\ndirectly from within their IDEs by writing natural language prompts, and\nintegrated services based on generative AI, such as Copilot, immediately\nrespond to prompts by providing ready-to-use code snippets. Formulating the\nprompt appropriately, and incorporating the useful information while avoiding\nany information overload, can be an important factor in obtaining the right\npiece of code. The task of designing good prompts is known as prompt\nengineering. In this paper, we systematically investigate the influence of\neight prompt features on the style and the content of prompts, on the level of\ncorrectness, complexity, size, and similarity to the developers' code of the\ngenerated code. We specifically consider the task of using Copilot with 124,800\nprompts obtained by systematically combining the eight considered prompt\nfeatures to generate the implementation of 200 Java methods. Results show how\nsome prompt features, such as the presence of examples and the summary of the\npurpose of the method, can significantly influence the quality of the result.",
      "tldr_zh": "这篇论文通过实证研究分析了提示特征对使用 Copilot 自动生成代码的影响，聚焦于八个提示特征（如示例和方法目的总结）对代码的正确性、复杂性、大小和相似度的影响。研究者系统地组合这些特征，生成124,800个提示来实现200个Java方法。结果表明，包含示例和方法总结的提示特征能显著提升生成代码的质量，为prompt engineering提供重要见解。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08430v1",
      "published_date": "2024-02-13 12:58:53 UTC",
      "updated_date": "2024-02-13 12:58:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:54:20.294951"
    },
    {
      "arxiv_id": "2402.08423v1",
      "title": "Vehicle Behavior Prediction by Episodic-Memory Implanted NDT",
      "title_zh": "翻译失败",
      "authors": [
        "Peining Shen",
        "Jianwu Fang",
        "Hongkai Yu",
        "Jianru Xue"
      ],
      "abstract": "In autonomous driving, predicting the behavior (turning left, stopping, etc.)\nof target vehicles is crucial for the self-driving vehicle to make safe\ndecisions and avoid accidents. Existing deep learning-based methods have shown\nexcellent and accurate performance, but the black-box nature makes it\nuntrustworthy to apply them in practical use. In this work, we explore the\ninterpretability of behavior prediction of target vehicles by an Episodic\nMemory implanted Neural Decision Tree (abbrev. eMem-NDT). The structure of\neMem-NDT is constructed by hierarchically clustering the text embedding of\nvehicle behavior descriptions. eMem-NDT is a neural-backed part of a\npre-trained deep learning model by changing the soft-max layer of the deep\nmodel to eMem-NDT, for grouping and aligning the memory prototypes of the\nhistorical vehicle behavior features in training data on a neural decision\ntree. Each leaf node of eMem-NDT is modeled by a neural network for aligning\nthe behavior memory prototypes. By eMem-NDT, we infer each instance in behavior\nprediction of vehicles by bottom-up Memory Prototype Matching (MPM) (searching\nthe appropriate leaf node and the links to the root node) and top-down Leaf\nLink Aggregation (LLA) (obtaining the probability of future behaviors of\nvehicles for certain instances). We validate eMem-NDT on BLVD and LOKI\ndatasets, and the results show that our model can obtain a superior performance\nto other methods with clear explainability. The code is available at\nhttps://github.com/JWFangit/eMem-NDT.",
      "tldr_zh": "本研究针对自动驾驶中目标车辆行为预测（如左转或停车）的黑盒问题，提出了一种 Episodic-Memory implanted Neural Decision Tree (eMem-NDT) 模型，以提升预测的可解释性。eMem-NDT 通过对车辆行为描述的文本嵌入进行层次聚类构建结构，并将预训练深度学习模型的 softmax 层替换为 eMem-NDT，利用 Memory Prototype Matching (MPM) 和 Leaf Link Aggregation (LLA) 进行自下而上的记忆原型匹配和自上而下的行为概率聚合。实验在 BLVD 和 LOKI 数据集上验证，eMem-NDT 模型在准确性上优于现有方法，同时提供清晰的可解释路径，代码已在 GitHub 开源。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by ICRA2024",
      "pdf_url": "http://arxiv.org/pdf/2402.08423v1",
      "published_date": "2024-02-13 12:50:04 UTC",
      "updated_date": "2024-02-13 12:50:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:54:31.855683"
    },
    {
      "arxiv_id": "2402.08409v1",
      "title": "Transferring Ultrahigh-Field Representations for Intensity-Guided Brain Segmentation of Low-Field Magnetic Resonance Imaging",
      "title_zh": "翻译失败",
      "authors": [
        "Kwanseok Oh",
        "Jieun Lee",
        "Da-Woon Heo",
        "Dinggang Shen",
        "Heung-Il Suk"
      ],
      "abstract": "Ultrahigh-field (UHF) magnetic resonance imaging (MRI), i.e., 7T MRI,\nprovides superior anatomical details of internal brain structures owing to its\nenhanced signal-to-noise ratio and susceptibility-induced contrast. However,\nthe widespread use of 7T MRI is limited by its high cost and lower\naccessibility compared to low-field (LF) MRI. This study proposes a\ndeep-learning framework that systematically fuses the input LF magnetic\nresonance feature representations with the inferred 7T-like feature\nrepresentations for brain image segmentation tasks in a 7T-absent environment.\nSpecifically, our adaptive fusion module aggregates 7T-like features derived\nfrom the LF image by a pre-trained network and then refines them to be\neffectively assimilable UHF guidance into LF image features. Using\nintensity-guided features obtained from such aggregation and assimilation,\nsegmentation models can recognize subtle structural representations that are\nusually difficult to recognize when relying only on LF features. Beyond such\nadvantages, this strategy can seamlessly be utilized by modulating the contrast\nof LF features in alignment with UHF guidance, even when employing arbitrary\nsegmentation models. Exhaustive experiments demonstrated that the proposed\nmethod significantly outperformed all baseline models on both brain tissue and\nwhole-brain segmentation tasks; further, it exhibited remarkable adaptability\nand scalability by successfully integrating diverse segmentation models and\ntasks. These improvements were not only quantifiable but also visible in the\nsuperlative visual quality of segmentation masks.",
      "tldr_zh": "这篇论文提出了一种深度学习框架，用于在低场 (LF) MRI 环境中，通过转移超高场 (UHF) 特征来指导脑部图像分割，从而克服 LF MRI 在识别微妙结构方面的局限性。具体而言，该框架利用预训练网络从 LF 图像中推断出 7T-like 特征，并通过自适应融合模块 (adaptive fusion module) 聚合并精炼这些特征，以调整 LF 特征的对比度并增强结构表示。实验结果显示，该方法在脑组织和全脑分割任务上显著优于基线模型，并展示了出色的适应性、可扩展性和视觉质量。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "32 pages, 9 figures, and 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2402.08409v1",
      "published_date": "2024-02-13 12:21:06 UTC",
      "updated_date": "2024-02-13 12:21:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:54:46.099283"
    },
    {
      "arxiv_id": "2402.08401v1",
      "title": "LOSS-GAT: Label Propagation and One-Class Semi-Supervised Graph Attention Network for Fake News Detection",
      "title_zh": "LOSS-GAT：标签传播和一类半监督图注意力网络用于假新闻检测",
      "authors": [
        "Batool Lakzaei",
        "Mostafa Haghir Chehreghani",
        "Alireza Bagheri"
      ],
      "abstract": "In the era of widespread social networks, the rapid dissemination of fake\nnews has emerged as a significant threat, inflicting detrimental consequences\nacross various dimensions of people's lives. Machine learning and deep learning\napproaches have been extensively employed for identifying fake news. However, a\nsignificant challenge in identifying fake news is the limited availability of\nlabeled news datasets. Therefore, the One-Class Learning (OCL) approach,\nutilizing only a small set of labeled data from the interest class, can be a\nsuitable approach to address this challenge. On the other hand, representing\ndata as a graph enables access to diverse content and structural information,\nand label propagation methods on graphs can be effective in predicting node\nlabels. In this paper, we adopt a graph-based model for data representation and\nintroduce a semi-supervised and one-class approach for fake news detection,\ncalled LOSS-GAT. Initially, we employ a two-step label propagation algorithm,\nutilizing Graph Neural Networks (GNNs) as an initial classifier to categorize\nnews into two groups: interest (fake) and non-interest (real). Subsequently, we\nenhance the graph structure using structural augmentation techniques.\nUltimately, we predict the final labels for all unlabeled data using a GNN that\ninduces randomness within the local neighborhood of nodes through the\naggregation function. We evaluate our proposed method on five common datasets\nand compare the results against a set of baseline models, including both OCL\nand binary labeled models. The results demonstrate that LOSS-GAT achieves a\nnotable improvement, surpassing 10%, with the advantage of utilizing only a\nlimited set of labeled fake news. Noteworthy, LOSS-GAT even outperforms binary\nlabeled models.",
      "tldr_zh": "本研究针对社交网络上假新闻检测的标签数据不足问题，提出了一种名为 LOSS-GAT 的半监督 One-Class 学习框架，结合标签传播算法和 Graph Attention Network (GAT)。该方法首先使用 Graph Neural Networks (GNNs) 作为初始分类器，将新闻分为假新闻（兴趣类）和真实新闻，随后通过结构增强技术和随机聚合函数在图结构上预测最终标签。实验结果显示，LOSS-GAT 在五个常见数据集上比基线模型（包括 One-Class 和二元标签模型）提高了超过 10% 的性能，即使仅使用少量标签数据，也超过了传统二元标签模型的表现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08401v1",
      "published_date": "2024-02-13 12:02:37 UTC",
      "updated_date": "2024-02-13 12:02:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:54:57.345495"
    },
    {
      "arxiv_id": "2402.08384v2",
      "title": "Selective Learning: Towards Robust Calibration with Dynamic Regularization",
      "title_zh": "翻译失败",
      "authors": [
        "Zongbo Han",
        "Yifeng Yang",
        "Changqing Zhang",
        "Linjun Zhang",
        "Joey Tianyi Zhou",
        "Qinghua Hu"
      ],
      "abstract": "Miscalibration in deep learning refers to there is a discrepancy between the\npredicted confidence and performance. This problem usually arises due to the\noverfitting problem, which is characterized by learning everything presented in\nthe training set, resulting in overconfident predictions during testing.\nExisting methods typically address overfitting and mitigate the miscalibration\nby adding a maximum-entropy regularizer to the objective function. The\nobjective can be understood as seeking a model that fits the ground-truth\nlabels by increasing the confidence while also maximizing the entropy of\npredicted probabilities by decreasing the confidence. However, previous methods\nlack clear guidance on confidence adjustment, leading to conflicting objectives\n(increasing but also decreasing confidence). Therefore, we introduce a method\ncalled Dynamic Regularization (DReg), which aims to learn what should be\nlearned during training thereby circumventing the confidence adjusting\ntrade-off. At a high level, DReg aims to obtain a more reliable model capable\nof acknowledging what it knows and does not know. Specifically, DReg\neffectively fits the labels for in-distribution samples (samples that should be\nlearned) while applying regularization dynamically to samples beyond model\ncapabilities (e.g., outliers), thereby obtaining a robust calibrated model\nespecially on the samples beyond model capabilities. Both theoretical and\nempirical analyses sufficiently demonstrate the superiority of DReg compared\nwith previous methods.",
      "tldr_zh": "该论文针对深度学习中的miscalibration问题（预测置信度与实际性能不一致），指出现有方法通过添加maximum-entropy regularizer来缓解overfitting，但会导致置信度调整的冲突。作者提出Dynamic Regularization (DReg)方法，通过动态正则化选择性地学习分布内样本的标签，而对超出模型能力的样本（如异常值）施加正则化，从而避免置信度权衡并获得更鲁棒的校准模型。理论和实证分析显示，DReg在处理未知样本方面优于现有方法，提升了模型的可靠性和泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08384v2",
      "published_date": "2024-02-13 11:25:20 UTC",
      "updated_date": "2024-07-14 09:12:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:55:07.512673"
    },
    {
      "arxiv_id": "2402.08383v1",
      "title": "Uncertainty Quantification for Forward and Inverse Problems of PDEs via Latent Global Evolution",
      "title_zh": "通过潜在全局演化实现偏微分方程正问题和逆问题的不确定性量化",
      "authors": [
        "Tailin Wu",
        "Willie Neiswanger",
        "Hongtao Zheng",
        "Stefano Ermon",
        "Jure Leskovec"
      ],
      "abstract": "Deep learning-based surrogate models have demonstrated remarkable advantages\nover classical solvers in terms of speed, often achieving speedups of 10 to\n1000 times over traditional partial differential equation (PDE) solvers.\nHowever, a significant challenge hindering their widespread adoption in both\nscientific and industrial domains is the lack of understanding about their\nprediction uncertainties, particularly in scenarios that involve critical\ndecision making. To address this limitation, we propose a method that\nintegrates efficient and precise uncertainty quantification into a deep\nlearning-based surrogate model. Our method, termed Latent Evolution of PDEs\nwith Uncertainty Quantification (LE-PDE-UQ), endows deep learning-based\nsurrogate models with robust and efficient uncertainty quantification\ncapabilities for both forward and inverse problems. LE-PDE-UQ leverages latent\nvectors within a latent space to evolve both the system's state and its\ncorresponding uncertainty estimation. The latent vectors are decoded to provide\npredictions for the system's state as well as estimates of its uncertainty. In\nextensive experiments, we demonstrate the accurate uncertainty quantification\nperformance of our approach, surpassing that of strong baselines including deep\nensembles, Bayesian neural network layers, and dropout. Our method excels at\npropagating uncertainty over extended auto-regressive rollouts, making it\nsuitable for scenarios involving long-term predictions. Our code is available\nat: https://github.com/AI4Science-WestlakeU/le-pde-uq.",
      "tldr_zh": "本研究针对深度学习代理模型在求解偏微分方程 (PDEs) 时速度优势显著（可达10-1000倍加速），但不确定性量化 (Uncertainty Quantification) 不足的问题，提出了一种新方法 Latent Evolution of PDEs with Uncertainty Quantification (LE-PDE-UQ)。该方法利用潜在空间的潜在向量来演化系统状态及其不确定性估计，从而为PDEs的正向和逆向问题提供高效、精确的不确定性量化。实验结果显示，LE-PDE-UQ 优于基线模型（如 deep ensembles、Bayesian neural network layers 和 dropout），在长期自回归预测中表现出色，并支持不确定性的准确传播。研究代码已在 GitHub 上公开。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by AAAI 2024 (Oral)",
      "pdf_url": "http://arxiv.org/pdf/2402.08383v1",
      "published_date": "2024-02-13 11:22:59 UTC",
      "updated_date": "2024-02-13 11:22:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:55:19.676268"
    },
    {
      "arxiv_id": "2402.08373v1",
      "title": "Time-Series Classification for Dynamic Strategies in Multi-Step Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Riku Green",
        "Grant Stevens",
        "Telmo de Menezes e Silva Filho",
        "Zahraa Abdallah"
      ],
      "abstract": "Multi-step forecasting (MSF) in time-series, the ability to make predictions\nmultiple time steps into the future, is fundamental to almost all temporal\ndomains. To make such forecasts, one must assume the recursive complexity of\nthe temporal dynamics. Such assumptions are referred to as the forecasting\nstrategy used to train a predictive model. Previous work shows that it is not\nclear which forecasting strategy is optimal a priori to evaluating on unseen\ndata. Furthermore, current approaches to MSF use a single (fixed) forecasting\nstrategy.\n  In this paper, we characterise the instance-level variance of optimal\nforecasting strategies and propose Dynamic Strategies (DyStrat) for MSF. We\nexperiment using 10 datasets from different scales, domains, and lengths of\nmulti-step horizons. When using a random-forest-based classifier, DyStrat\noutperforms the best fixed strategy, which is not knowable a priori, 94% of the\ntime, with an average reduction in mean-squared error of 11%. Our approach\ntypically triples the top-1 accuracy compared to current approaches. Notably,\nwe show DyStrat generalises well for any MSF task.",
      "tldr_zh": "本研究探讨多步时间序列预测（Multi-step forecasting, MSF）的预测策略问题，指出现有方法使用单一固定策略，但最优策略在事前难以确定。作者提出Dynamic Strategies (DyStrat)方法，通过分类器（如随机森林）动态选择实例级最优策略，以处理时间序列的递归复杂性。在10个不同规模、领域和预测地平线的数据集实验中，DyStrat在94%的情况下优于最佳固定策略，平均减少11%的均方误差（mean-squared error），并将top-1 accuracy提高三倍，同时显示出对任何MSF任务的良好泛化性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08373v1",
      "published_date": "2024-02-13 11:10:14 UTC",
      "updated_date": "2024-02-13 11:10:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:55:32.289806"
    },
    {
      "arxiv_id": "2402.08369v1",
      "title": "One-shot Imitation in a Non-Stationary Environment via Multi-Modal Skill",
      "title_zh": "翻译失败",
      "authors": [
        "Sangwoo Shin",
        "Daehee Lee",
        "Minjong Yoo",
        "Woo Kyung Kim",
        "Honguk Woo"
      ],
      "abstract": "One-shot imitation is to learn a new task from a single demonstration, yet it\nis a challenging problem to adopt it for complex tasks with the high domain\ndiversity inherent in a non-stationary environment. To tackle the problem, we\nexplore the compositionality of complex tasks, and present a novel skill-based\nimitation learning framework enabling one-shot imitation and zero-shot\nadaptation; from a single demonstration for a complex unseen task, a semantic\nskill sequence is inferred and then each skill in the sequence is converted\ninto an action sequence optimized for environmental hidden dynamics that can\nvary over time. Specifically, we leverage a vision-language model to learn a\nsemantic skill set from offline video datasets, where each skill is represented\non the vision-language embedding space, and adapt meta-learning with dynamics\ninference to enable zero-shot skill adaptation. We evaluate our framework with\nvarious one-shot imitation scenarios for extended multi-stage Meta-world tasks,\nshowing its superiority in learning complex tasks, generalizing to dynamics\nchanges, and extending to different demonstration conditions and modalities,\ncompared to other baselines.",
      "tldr_zh": "该研究针对非平稳环境中的复杂任务，提出了一种基于多模态技能的技能型模仿学习框架，支持一次性模仿（one-shot imitation）和零次适应（zero-shot adaptation）。框架从单个演示中推断语义技能序列（semantic skill sequence），并将每个技能转换为针对环境隐藏动态优化的动作序列（action sequence）。具体方法利用视觉语言模型（vision-language model）从离线视频数据集学习技能表示，并结合元学习（meta-learning）和动态推断（dynamics inference）实现技能适应。实验结果显示，该框架在扩展的多阶段 Meta-world 任务中表现出色，优于基线模型，能够更好地学习复杂任务、泛化动态变化，并适应不同演示条件和模态。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "ICML-2023 Camera Ready Version",
      "pdf_url": "http://arxiv.org/pdf/2402.08369v1",
      "published_date": "2024-02-13 11:01:52 UTC",
      "updated_date": "2024-02-13 11:01:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:55:44.646930"
    },
    {
      "arxiv_id": "2402.08349v3",
      "title": "Evaluating the Data Model Robustness of Text-to-SQL Systems Based on Real User Queries",
      "title_zh": "基于真实用户查询评估 Text-to-SQL 系统的数据模型鲁棒性",
      "authors": [
        "Jonathan Fürst",
        "Catherine Kosten",
        "Farhad Nooralahzadeh",
        "Yi Zhang",
        "Kurt Stockinger"
      ],
      "abstract": "Text-to-SQL systems (also known as NL-to-SQL systems) have become an\nincreasingly popular solution for bridging the gap between user capabilities\nand SQL-based data access. These systems translate user requests in natural\nlanguage to valid SQL statements for a specific database. Recent Text-to-SQL\nsystems have benefited from the rapid improvement of transformer-based language\nmodels. However, while Text-to-SQL systems that incorporate such models\ncontinuously reach new high scores on -- often synthetic -- benchmark datasets,\na systematic exploration of their robustness towards different data models in a\nreal-world, realistic scenario is notably missing. This paper provides the\nfirst in-depth evaluation of the data model robustness of Text-to-SQL systems\nin practice based on a multi-year international project focused on Text-to-SQL\ninterfaces. Our evaluation is based on a real-world deployment of FootballDB, a\nsystem that was deployed over a 9 month period in the context of the FIFA World\nCup 2022, during which about 6K natural language questions were asked and\nexecuted. All of our data is based on real user questions that were asked live\nto the system. We manually labeled and translated a subset of these questions\nfor three different data models. For each data model, we explore the\nperformance of representative Text-to-SQL systems and language models. We\nfurther quantify the impact of training data size, pre-, and post-processing\nsteps as well as language model inference time. Our comprehensive evaluation\nsheds light on the design choices of real-world Text-to-SQL systems and their\nimpact on moving from research prototypes to real deployments. Last, we provide\na new benchmark dataset to the community, which is the first to enable the\nevaluation of different data models for the same dataset and is substantially\nmore challenging than most previous datasets in terms of query complexity.",
      "tldr_zh": "本论文评估了 Text-to-SQL 系统的鲁棒性，聚焦于不同数据模型在真实用户查询场景下的表现，填补了现有研究在实际部署方面的空白。通过分析 FIFA World Cup 2022 期间 FootballDB 系统收集的约 6K 真实自然语言查询，研究者手动标记并翻译了查询子集，并测试了多种 Text-to-SQL 系统和 transformer-based 语言模型的性能，包括训练数据大小、前后处理步骤和推理时间的影响。结果显示，系统设计选择显著影响从研究原型到实际部署的过渡，并贡献了一个新基准数据集，该数据集支持同一数据集的多数据模型评估，且查询复杂度远高于现有基准。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08349v3",
      "published_date": "2024-02-13 10:28:57 UTC",
      "updated_date": "2024-11-29 14:44:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:55:57.174017"
    },
    {
      "arxiv_id": "2402.08341v2",
      "title": "Eliciting Personality Traits in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Airlie Hilliard",
        "Cristian Munoz",
        "Zekun Wu",
        "Adriano Soares Koshiyama"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly being utilized by both\ncandidates and employers in the recruitment context. However, with this comes\nnumerous ethical concerns, particularly related to the lack of transparency in\nthese \"black-box\" models. Although previous studies have sought to increase the\ntransparency of these models by investigating the personality traits of LLMs,\nmany of the previous studies have provided them with personality assessments to\ncomplete. On the other hand, this study seeks to obtain a better understanding\nof such models by examining their output variations based on different input\nprompts. Specifically, we use a novel elicitation approach using prompts\nderived from common interview questions, as well as prompts designed to elicit\nparticular Big Five personality traits to examine whether the models were\nsusceptible to trait-activation like humans are, to measure their personality\nbased on the language used in their outputs. To do so, we repeatedly prompted\nmultiple LMs with different parameter sizes, including Llama-2, Falcon,\nMistral, Bloom, GPT, OPT, and XLNet (base and fine tuned versions) and examined\ntheir personality using classifiers trained on the myPersonality dataset. Our\nresults reveal that, generally, all LLMs demonstrate high openness and low\nextraversion. However, whereas LMs with fewer parameters exhibit similar\nbehaviour in personality traits, newer and LMs with more parameters exhibit a\nbroader range of personality traits, with increased agreeableness, emotional\nstability, and openness. Furthermore, a greater number of parameters is\npositively associated with openness and conscientiousness. Moreover, fine-tuned\nmodels exhibit minor modulations in their personality traits, contingent on the\ndataset. Implications and directions for future research are discussed.",
      "tldr_zh": "本研究探讨了如何通过提示激发Large Language Models (LLMs)的个性特质，以提升模型透明度。研究采用一种新颖方法，使用基于常见面试问题和Big Five个性特质的提示，对多种LLMs（如Llama-2、Falcon、Mistral等基础和微调版本）进行重复测试，并通过基于myPersonality数据集训练的分类器分析输出语言。结果显示，所有LLMs普遍表现出高开放性和低外向性，而参数较大的模型显示更广泛的特质，包括更高的宜人性、情感稳定性和开放性，且参数数量与开放性和尽责性正相关。总之，此研究揭示了LLMs个性特质的模式，为提升模型伦理应用和未来研究提供重要启示。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Manuscript submitted to ACM Facct. Authors One and Two contributed\n  equally to this work",
      "pdf_url": "http://arxiv.org/pdf/2402.08341v2",
      "published_date": "2024-02-13 10:09:00 UTC",
      "updated_date": "2024-02-15 09:12:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:56:08.437949"
    },
    {
      "arxiv_id": "2402.08324v1",
      "title": "Uncertainty Quantification via Stable Distribution Propagation",
      "title_zh": "翻译失败",
      "authors": [
        "Felix Petersen",
        "Aashwin Mishra",
        "Hilde Kuehne",
        "Christian Borgelt",
        "Oliver Deussen",
        "Mikhail Yurochkin"
      ],
      "abstract": "We propose a new approach for propagating stable probability distributions\nthrough neural networks. Our method is based on local linearization, which we\nshow to be an optimal approximation in terms of total variation distance for\nthe ReLU non-linearity. This allows propagating Gaussian and Cauchy input\nuncertainties through neural networks to quantify their output uncertainties.\nTo demonstrate the utility of propagating distributions, we apply the proposed\nmethod to predicting calibrated confidence intervals and selective prediction\non out-of-distribution data. The results demonstrate a broad applicability of\npropagating distributions and show the advantages of our method over other\napproaches such as moment matching.",
      "tldr_zh": "本研究提出了一种通过神经网络传播稳定概率分布的新方法，基于局部线性化(local linearization)，并证明其在ReLU非线性上的总变差距离(total variation distance)是最优近似，从而允许传播Gaussian和Cauchy输入不确定性以量化输出不确定性。该方法应用于预测校准的置信区间和选择性预测，尤其在分布外数据上，展示了其实际效用。与其他方法如moment matching相比，实验结果表明该方法具有更广泛的适用性和显著优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at ICLR 2024, Code @\n  https://github.com/Felix-Petersen/distprop",
      "pdf_url": "http://arxiv.org/pdf/2402.08324v1",
      "published_date": "2024-02-13 09:40:19 UTC",
      "updated_date": "2024-02-13 09:40:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:56:21.307629"
    },
    {
      "arxiv_id": "2402.08323v1",
      "title": "Mapping the Ethics of Generative AI: A Comprehensive Scoping Review",
      "title_zh": "生成式人工智能的伦理映射：全面的范围界定回顾",
      "authors": [
        "Thilo Hagendorff"
      ],
      "abstract": "The advent of generative artificial intelligence and the widespread adoption\nof it in society engendered intensive debates about its ethical implications\nand risks. These risks often differ from those associated with traditional\ndiscriminative machine learning. To synthesize the recent discourse and map its\nnormative concepts, we conducted a scoping review on the ethics of generative\nartificial intelligence, including especially large language models and\ntext-to-image models. Our analysis provides a taxonomy of 378 normative issues\nin 19 topic areas and ranks them according to their prevalence in the\nliterature. The study offers a comprehensive overview for scholars,\npractitioners, or policymakers, condensing the ethical debates surrounding\nfairness, safety, harmful content, hallucinations, privacy, interaction risks,\nsecurity, alignment, societal impacts, and others. We discuss the results,\nevaluate imbalances in the literature, and explore unsubstantiated risk\nscenarios.",
      "tldr_zh": "本研究通过进行一个全面的 scoping review，综合分析了 generative AI 的伦理讨论，特别是大型语言模型和文本到图像模型，识别出 378 个规范性问题并将其分类为 19 个主题领域。研究构建了一个 taxonomy 来排名这些问题的流行度，涵盖公平性、safety、harmful content、hallucinations、privacy、interaction risks、security、alignment、社会影响等关键议题。结果显示文献中存在不平衡，并探讨了未证实的风险场景，为学者、从业者和政策制定者提供了一个简明概述，以指导 generative AI 的伦理治理。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08323v1",
      "published_date": "2024-02-13 09:38:17 UTC",
      "updated_date": "2024-02-13 09:38:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:56:32.191164"
    },
    {
      "arxiv_id": "2402.15898v6",
      "title": "Transductive Active Learning: Theory and Applications",
      "title_zh": "传递式主动学习：理论与应用",
      "authors": [
        "Jonas Hübotter",
        "Bhavya Sukhija",
        "Lenart Treven",
        "Yarden As",
        "Andreas Krause"
      ],
      "abstract": "We study a generalization of classical active learning to real-world settings\nwith concrete prediction targets where sampling is restricted to an accessible\nregion of the domain, while prediction targets may lie outside this region. We\nanalyze a family of decision rules that sample adaptively to minimize\nuncertainty about prediction targets. We are the first to show, under general\nregularity assumptions, that such decision rules converge uniformly to the\nsmallest possible uncertainty obtainable from the accessible data. We\ndemonstrate their strong sample efficiency in two key applications: active\nfine-tuning of large neural networks and safe Bayesian optimization, where they\nachieve state-of-the-art performance.",
      "tldr_zh": "本研究扩展了经典主动学习（Active Learning），提出一种传递式（Transductive）框架，适用于真实世界场景，其中采样仅限于可访问领域，而预测目标可能超出该范围。该框架分析了自适应决策规则，通过最小化对预测目标的不确定性来采样，并在一般正则性假设下首次证明这些规则能均匀收敛到从可访问数据中获得的最小不确定性。在主动微调大型神经网络和安全贝叶斯优化（Bayesian Optimization）等关键应用中，该方法展示了强大的样本效率，并达到了最先进性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "accepted in NeurIPS 2024. arXiv admin note: text overlap with\n  arXiv:2402.15441",
      "pdf_url": "http://arxiv.org/pdf/2402.15898v6",
      "published_date": "2024-02-13 09:22:45 UTC",
      "updated_date": "2025-02-08 19:30:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:56:44.663539"
    },
    {
      "arxiv_id": "2402.15441v4",
      "title": "Active Few-Shot Fine-Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Jonas Hübotter",
        "Bhavya Sukhija",
        "Lenart Treven",
        "Yarden As",
        "Andreas Krause"
      ],
      "abstract": "We study the question: How can we select the right data for fine-tuning to a\nspecific task? We call this data selection problem active fine-tuning and show\nthat it is an instance of transductive active learning, a novel generalization\nof classical active learning. We propose ITL, short for information-based\ntransductive learning, an approach which samples adaptively to maximize\ninformation gained about the specified task. We are the first to show, under\ngeneral regularity assumptions, that such decision rules converge uniformly to\nthe smallest possible uncertainty obtainable from the accessible data. We apply\nITL to the few-shot fine-tuning of large neural networks and show that\nfine-tuning with ITL learns the task with significantly fewer examples than the\nstate-of-the-art.",
      "tldr_zh": "本文研究了如何选择合适的数据进行特定任务的少样本微调（Active Few-Shot Fine-Tuning），将其视为 transductive active learning 的一个新实例。作者提出 ITL（information-based transductive learning）方法，通过自适应采样最大化任务相关信息，并在一般正则性假设下证明其能均匀收敛到从可访问数据中获得的最小不确定性。实验结果显示，ITL 在微调大型神经网络时，比最先进方法使用显著更少的样本就实现了任务学习。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.15441v4",
      "published_date": "2024-02-13 09:19:05 UTC",
      "updated_date": "2024-06-21 08:48:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:56:56.908339"
    },
    {
      "arxiv_id": "2402.08310v1",
      "title": "One-to-many Reconstruction of 3D Geometry of cultural Artifacts using a synthetically trained Generative Model",
      "title_zh": "翻译失败",
      "authors": [
        "Thomas Pöllabauer",
        "Julius Kühn",
        "Jiayi Li",
        "Arjan Kuijper"
      ],
      "abstract": "Estimating the 3D shape of an object using a single image is a difficult\nproblem. Modern approaches achieve good results for general objects, based on\nreal photographs, but worse results on less expressive representations such as\nhistoric sketches. Our automated approach generates a variety of detailed 3D\nrepresentation from a single sketch, depicting a medieval statue, and can be\nguided by multi-modal inputs, such as text prompts. It relies solely on\nsynthetic data for training, making it adoptable even in cases of only small\nnumbers of training examples. Our solution allows domain experts such as a\ncurators to interactively reconstruct potential appearances of lost artifacts.",
      "tldr_zh": "该研究提出了一种从单张图像（如历史草图）重建文化文物3D Geometry的方法，使用合成数据训练的Generative Model，能够生成多种详细的3D表示，例如中世纪雕像。方法支持多模态输入（如文本提示）引导重建，并仅依赖synthetic data训练，即使训练样本少也能适用。该框架允许领域专家如策展人进行交互式重建，潜在应用于恢复丢失文物外观，并提升了传统方法在历史草图上的表现。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08310v1",
      "published_date": "2024-02-13 09:13:30 UTC",
      "updated_date": "2024-02-13 09:13:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:57:08.102709"
    },
    {
      "arxiv_id": "2402.08303v4",
      "title": "ChatCell: Facilitating Single-Cell Analysis with Natural Language",
      "title_zh": "ChatCell：通过自然语言促进单细胞分析",
      "authors": [
        "Yin Fang",
        "Kangwei Liu",
        "Ningyu Zhang",
        "Xinle Deng",
        "Penghui Yang",
        "Zhuo Chen",
        "Xiangru Tang",
        "Mark Gerstein",
        "Xiaohui Fan",
        "Huajun Chen"
      ],
      "abstract": "As Large Language Models (LLMs) rapidly evolve, their influence in science is\nbecoming increasingly prominent. The emerging capabilities of LLMs in task\ngeneralization and free-form dialogue can significantly advance fields like\nchemistry and biology. However, the field of single-cell biology, which forms\nthe foundational building blocks of living organisms, still faces several\nchallenges. High knowledge barriers and limited scalability in current methods\nrestrict the full exploitation of LLMs in mastering single-cell data, impeding\ndirect accessibility and rapid iteration. To this end, we introduce ChatCell,\nwhich signifies a paradigm shift by facilitating single-cell analysis with\nnatural language. Leveraging vocabulary adaptation and unified sequence\ngeneration, ChatCell has acquired profound expertise in single-cell biology and\nthe capability to accommodate a diverse range of analysis tasks. Extensive\nexperiments further demonstrate ChatCell's robust performance and potential to\ndeepen single-cell insights, paving the way for more accessible and intuitive\nexploration in this pivotal field. Our project homepage is available at\nhttps://zjunlp.github.io/project/ChatCell.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）在单细胞生物学中的应用，指出现有方法面临高知识壁垒和可扩展性问题，从而限制了LLMs的潜力。为解决这些挑战，研究团队引入了ChatCell框架，通过词汇适应和统一序列生成，使其具备单细胞生物学的专业知识，并支持多种分析任务的自然语言交互。实验结果显示，ChatCell表现出色，能够深化单细胞洞察，并为该领域提供更易访问和直观的探索方式。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CE",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "I have decided to temporarily withdraw this draft as I am in the\n  process of making further revisions to improve its content. Code:\n  https://github.com/zjunlp/ChatCell Dataset:\n  https://huggingface.co/datasets/zjunlp/ChatCell-Instructions Demo:\n  https://chat.openai.com/g/g-vUwj222gQ-chatcell",
      "pdf_url": "http://arxiv.org/pdf/2402.08303v4",
      "published_date": "2024-02-13 09:06:14 UTC",
      "updated_date": "2024-02-20 02:26:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:57:20.756467"
    },
    {
      "arxiv_id": "2402.08298v1",
      "title": "Time to Stop and Think: What kind of research do we want to do?",
      "title_zh": "是时候停下来思考：我们要做什么样的研究？",
      "authors": [
        "Josu Ceberio",
        "Borja Calvo"
      ],
      "abstract": "Experimentation is an intrinsic part of research in artificial intelligence\nsince it allows for collecting quantitative observations, validating\nhypotheses, and providing evidence for their reformulation. For that reason,\nexperimentation must be coherent with the purposes of the research, properly\naddressing the relevant questions in each case. Unfortunately, the literature\nis full of works whose experimentation is neither rigorous nor convincing,\noftentimes designed to support prior beliefs rather than answering the relevant\nresearch questions.\n  In this paper, we focus on the field of metaheuristic optimization, since it\nis our main field of work, and it is where we have observed the misconduct that\nhas motivated this letter. Even if we limit the focus of this manuscript to the\nexperimental part of the research, our main goal is to sew the seed of sincere\ncritical assessment of our work, sparking a reflection process both at the\nindividual and the community level. Such a reflection process is too complex\nand extensive to be tackled as a whole. Therefore, to bring our feet to the\nground, we will include in this document our reflections about the role of\nexperimentation in our work, discussing topics such as the use of benchmark\ninstances vs instance generators, or the statistical assessment of empirical\nresults. That is, all the statements included in this document are personal\nviews and opinions, which can be shared by others or not. Certainly, having\ndifferent points of view is the basis to establish a good discussion process.",
      "tldr_zh": "这篇论文呼吁人工智能研究领域，尤其是元启发式优化（metaheuristic optimization），对实验设计进行深刻反思，因为许多研究实验缺乏严谨性和说服力，往往服务于预设信念而非实际问题。作者强调，实验应与研究目标一致，通过定量观察、假设验证和证据支持来推动科学进展。论文分享个人观点，包括基准实例（benchmark instances）与实例生成器（instance generators）的使用，以及统计评估的必要性，旨在激发个体和社区层面的批判性讨论，以提升研究质量。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08298v1",
      "published_date": "2024-02-13 08:53:57 UTC",
      "updated_date": "2024-02-13 08:53:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:57:31.544833"
    },
    {
      "arxiv_id": "2402.08290v3",
      "title": "The Effect of Data Poisoning on Counterfactual Explanations",
      "title_zh": "数据投毒对反事实解释的影响",
      "authors": [
        "André Artelt",
        "Shubham Sharma",
        "Freddy Lecué",
        "Barbara Hammer"
      ],
      "abstract": "Counterfactual explanations provide a popular method for analyzing the\npredictions of black-box systems, and they can offer the opportunity for\ncomputational recourse by suggesting actionable changes on how to change the\ninput to obtain a different (i.e.\\ more favorable) system output. However,\nrecent work highlighted their vulnerability to different types of\nmanipulations.\n  This work studies the vulnerability of counterfactual explanations to data\npoisoning. We formally introduce and investigate data poisoning in the context\nof counterfactual explanations for increasing the cost of recourse on three\ndifferent levels: locally for a single instance, or a sub-group of instances,\nor globally for all instances. In this context, we characterize and prove the\ncorrectness of several different data poisonings. We also empirically\ndemonstrate that state-of-the-art counterfactual generation methods and\ntoolboxes are vulnerable to such data poisoning.",
      "tldr_zh": "本研究探讨了数据投毒（data poisoning）对反事实解释（counterfactual explanations）的负面影响，这些解释常用于分析黑盒系统预测并提供计算补救建议，如通过改变输入获得更理想的输出。论文正式引入数据投毒机制，针对单个实例、子组实例或全局所有实例来增加补救成本（recourse），并证明了多种投毒方法的特性及其正确性。通过实验验证，结果显示现有反事实生成方法和工具箱对这种数据投毒高度脆弱。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08290v3",
      "published_date": "2024-02-13 08:41:32 UTC",
      "updated_date": "2024-05-21 11:37:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:57:45.663687"
    },
    {
      "arxiv_id": "2402.08284v1",
      "title": "A Logical Approach to Criminal Case Investigation",
      "title_zh": "逻辑方法在刑事案件调查中的应用",
      "authors": [
        "Takanori Ugai",
        "Yusuke Koyanagi",
        "Fumihito Nishino"
      ],
      "abstract": "XAI (eXplanable AI) techniques that have the property of explaining the\nreasons for their conclusions, i.e. explainability or interpretability, are\nattracting attention. XAI is expected to be used in the development of forensic\nscience and the justice system. In today's forensic and criminal investigation\nenvironment, experts face many challenges due to large amounts of data, small\npieces of evidence in a chaotic and complex environment, traditional laboratory\nstructures and sometimes inadequate knowledge. All these can lead to failed\ninvestigations and miscarriages of justice. In this paper, we describe the\napplication of one logical approach to crime scene investigation. The subject\nof the application is ``The Adventure of the Speckled Band'' from the Sherlock\nHolmes short stories. The applied data is the knowledge graph created for the\nKnowledge Graph Reasoning Challenge. We tried to find the murderer by inferring\neach person with the motive, opportunity, and method. We created an ontology of\nmotives and methods of murder from dictionaries and dictionaries, added it to\nthe knowledge graph of ``The Adventure of the Speckled Band'', and applied\nscripts to determine motives, opportunities, and methods.",
      "tldr_zh": "本研究探讨了 XAI (eXplainable AI) 在刑事调查中的应用，旨在通过逻辑方法解决专家面临的挑战，如海量数据、证据碎片和复杂环境，以避免调查失败和司法错误。作者以 Sherlock Holmes 短篇故事“The Adventure of the Speckled Band”为基础，构建了一个知识图谱，并添加了关于谋杀动机的本体（ontology）。通过推理每个嫌疑人的动机、机会和手段，该方法成功演示了如何识别潜在凶手，为 forensic science 和司法系统的发展提供了可解释的逻辑框架。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.08284v1",
      "published_date": "2024-02-13 08:24:32 UTC",
      "updated_date": "2024-02-13 08:24:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:57:56.355293"
    },
    {
      "arxiv_id": "2402.08280v2",
      "title": "Pix2Code: Learning to Compose Neural Visual Concepts as Programs",
      "title_zh": "翻译失败",
      "authors": [
        "Antonia Wüst",
        "Wolfgang Stammer",
        "Quentin Delfosse",
        "Devendra Singh Dhami",
        "Kristian Kersting"
      ],
      "abstract": "The challenge in learning abstract concepts from images in an unsupervised\nfashion lies in the required integration of visual perception and generalizable\nrelational reasoning. Moreover, the unsupervised nature of this task makes it\nnecessary for human users to be able to understand a model's learnt concepts\nand potentially revise false behaviours. To tackle both the generalizability\nand interpretability constraints of visual concept learning, we propose\nPix2Code, a framework that extends program synthesis to visual relational\nreasoning by utilizing the abilities of both explicit, compositional symbolic\nand implicit neural representations. This is achieved by retrieving object\nrepresentations from images and synthesizing relational concepts as\nlambda-calculus programs. We evaluate the diverse properties of Pix2Code on the\nchallenging reasoning domains, Kandinsky Patterns and CURI, thereby testing its\nability to identify compositional visual concepts that generalize to novel data\nand concept configurations. Particularly, in stark contrast to neural\napproaches, we show that Pix2Code's representations remain human interpretable\nand can be easily revised for improved performance.",
      "tldr_zh": "本研究提出 Pix2Code 框架，旨在解决无监督从图像中学习抽象概念的挑战，通过整合视觉感知和关系推理，同时确保模型的可解释性和可修订性。Pix2Code 结合程序合成（program synthesis）和神经表示，从图像中检索对象表示，并将关系概念合成为 lambda-calculus 程序，从而实现概念的组成性和泛化。实验在 Kandinsky Patterns 和 CURI 数据集上显示，该框架能识别可泛化的视觉概念，与神经方法相比，其表示更易于人类理解和修改，以提升性能。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08280v2",
      "published_date": "2024-02-13 08:14:10 UTC",
      "updated_date": "2024-07-06 15:07:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:58:09.454606"
    },
    {
      "arxiv_id": "2402.08269v1",
      "title": "Geometry-induced Implicit Regularization in Deep ReLU Neural Networks",
      "title_zh": "深度 ReLU 神经网络中的几何诱导隐式正则化",
      "authors": [
        "Joachim Bona-Pellissier",
        "Fran çois Malgouyres",
        "Fran çois Bachoc"
      ],
      "abstract": "It is well known that neural networks with many more parameters than training\nexamples do not overfit. Implicit regularization phenomena, which are still not\nwell understood, occur during optimization and 'good' networks are favored.\nThus the number of parameters is not an adequate measure of complexity if we do\nnot consider all possible networks but only the 'good' ones. To better\nunderstand which networks are favored during optimization, we study the\ngeometry of the output set as parameters vary. When the inputs are fixed, we\nprove that the dimension of this set changes and that the local dimension,\ncalled batch functional dimension, is almost surely determined by the\nactivation patterns in the hidden layers. We prove that the batch functional\ndimension is invariant to the symmetries of the network parameterization:\nneuron permutations and positive rescalings. Empirically, we establish that the\nbatch functional dimension decreases during optimization. As a consequence,\noptimization leads to parameters with low batch functional dimensions. We call\nthis phenomenon geometry-induced implicit regularization.The batch functional\ndimension depends on both the network parameters and inputs. To understand the\nimpact of the inputs, we study, for fixed parameters, the largest attainable\nbatch functional dimension when the inputs vary. We prove that this quantity,\ncalled computable full functional dimension, is also invariant to the\nsymmetries of the network's parameterization, and is determined by the\nachievable activation patterns. We also provide a sampling theorem, showing a\nfast convergence of the estimation of the computable full functional dimension\nfor a random input of increasing size. Empirically we find that the computable\nfull functional dimension remains close to the number of parameters, which is\nrelated to the notion of local identifiability. This differs from the observed\nvalues for the batch functional dimension computed on training inputs and test\ninputs. The latter are influenced by geometry-induced implicit regularization.",
      "tldr_zh": "这篇论文探讨了Deep ReLU Neural Networks中几何诱导的隐式正则化(implicit regularization)现象，解释了为什么参数远多于训练样本的网络不会过拟合。作者通过分析输出集的几何形状，引入了批处理功能维度(batch functional dimension)，证明该维度由隐藏层的激活模式决定，并对网络参数的对称性（如神经元排列和正缩放）保持不变。实验发现，在优化过程中，batch functional dimension 逐渐下降，这体现了几何诱导的隐式正则化。论文还定义了可计算全功能维度(computable full functional dimension)，证明它受输入影响并接近参数数量，并提供采样定理来快速估计该维度。该研究深化了对神经网络优化行为的理解，为评估网络复杂性提供了新工具。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.NE",
        "math.OC",
        "math.ST",
        "stat.TH"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08269v1",
      "published_date": "2024-02-13 07:49:57 UTC",
      "updated_date": "2024-02-13 07:49:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:58:23.364627"
    },
    {
      "arxiv_id": "2402.08267v2",
      "title": "Improving Image Coding for Machines through Optimizing Encoder via Auxiliary Loss",
      "title_zh": "通过辅助损失优化编码器以改善针对机器的图像编码",
      "authors": [
        "Kei Iino",
        "Shunsuke Akamatsu",
        "Hiroshi Watanabe",
        "Shohei Enomoto",
        "Akira Sakamoto",
        "Takeharu Eda"
      ],
      "abstract": "Image coding for machines (ICM) aims to compress images for machine analysis\nusing recognition models rather than human vision. Hence, in ICM, it is\nimportant for the encoder to recognize and compress the information necessary\nfor the machine recognition task. There are two main approaches in learned ICM;\noptimization of the compression model based on task loss, and Region of\nInterest (ROI) based bit allocation. These approaches provide the encoder with\nthe recognition capability. However, optimization with task loss becomes\ndifficult when the recognition model is deep, and ROI-based methods often\ninvolve extra overhead during evaluation. In this study, we propose a novel\ntraining method for learned ICM models that applies auxiliary loss to the\nencoder to improve its recognition capability and rate-distortion performance.\nOur method achieves Bjontegaard Delta rate improvements of 27.7% and 20.3% in\nobject detection and semantic segmentation tasks, compared to the conventional\ntraining method.\n  \\c{opyright} 2024 IEEE. Personal use of this material is permitted.\nPermission from IEEE must be obtained for all other uses, in any current or\nfuture media, including reprinting/republishing this material for advertising\nor promotional purposes, creating new collective works, for resale or\nredistribution to servers or lists, or reuse of any copyrighted component of\nthis work in other works.",
      "tldr_zh": "本论文针对 Image Coding for Machines (ICM) 的问题，提出了一种新训练方法，通过在编码器上应用 auxiliary loss 来提升其识别能力和率-失真性能，从而更好地压缩机器分析所需的信息。相比传统基于任务损失优化或 Region of Interest (ROI) 位分配的方法，该方法避免了深度模型优化难度和评估开销。实验结果显示，在物体检测和语义分割任务上，Bjontegaard Delta rate 分别改善了 27.7% 和 20.3%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at ICIP 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.08267v2",
      "published_date": "2024-02-13 07:45:25 UTC",
      "updated_date": "2024-09-28 14:05:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:58:35.194050"
    },
    {
      "arxiv_id": "2402.08256v1",
      "title": "Modeling Balanced Explicit and Implicit Relations with Contrastive Learning for Knowledge Concept Recommendation in MOOCs",
      "title_zh": "基于对比学习的平衡显式和隐式关系建模，用于 MOOCs 中的知识概念推荐",
      "authors": [
        "Hengnian Gu",
        "Zhiyi Duan",
        "Pan Xie",
        "Dongdai Zhou"
      ],
      "abstract": "The knowledge concept recommendation in Massive Open Online Courses (MOOCs)\nis a significant issue that has garnered widespread attention. Existing methods\nprimarily rely on the explicit relations between users and knowledge concepts\non the MOOC platforms for recommendation. However, there are numerous implicit\nrelations (e.g., shared interests or same knowledge levels between users)\ngenerated within the users' learning activities on the MOOC platforms. Existing\nmethods fail to consider these implicit relations, and these relations\nthemselves are difficult to learn and represent, causing poor performance in\nknowledge concept recommendation and an inability to meet users' personalized\nneeds. To address this issue, we propose a novel framework based on contrastive\nlearning, which can represent and balance the explicit and implicit relations\nfor knowledge concept recommendation in MOOCs (CL-KCRec). Specifically, we\nfirst construct a MOOCs heterogeneous information network (HIN) by modeling the\ndata from the MOOC platforms. Then, we utilize a relation-updated graph\nconvolutional network and stacked multi-channel graph neural network to\nrepresent the explicit and implicit relations in the HIN, respectively.\nConsidering that the quantity of explicit relations is relatively fewer\ncompared to implicit relations in MOOCs, we propose a contrastive learning with\nprototypical graph to enhance the representations of both relations to capture\ntheir fruitful inherent relational knowledge, which can guide the propagation\nof students' preferences within the HIN. Based on these enhanced\nrepresentations, to ensure the balanced contribution of both towards the final\nrecommendation, we propose a dual-head attention mechanism for balanced fusion.\nExperimental results demonstrate that CL-KCRec outperforms several\nstate-of-the-art baselines on real-world datasets in terms of HR, NDCG and MRR.",
      "tldr_zh": "本研究针对 MOOCs 中的知识概念推荐问题，指出现有方法仅依赖 explicit relations 而忽略 implicit relations（如用户共享兴趣），导致推荐效果不佳。作者提出 CL-KCRec 框架，通过构建 MOOCs heterogeneous information network (HIN)，并分别使用 relation-updated graph convolutional network 和 stacked multi-channel graph neural network 来表示 explicit 和 implicit relations。框架进一步采用 contrastive learning with prototypical graph 增强关系的表示，并通过 dual-head attention mechanism 实现平衡融合，以捕捉用户偏好并指导推荐。实验结果表明，CL-KCRec 在真实数据集上，在 HR、NDCG 和 MRR 指标上优于现有基线方法。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted to WWW 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.08256v1",
      "published_date": "2024-02-13 07:12:44 UTC",
      "updated_date": "2024-02-13 07:12:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:58:47.197850"
    },
    {
      "arxiv_id": "2402.08255v1",
      "title": "Distal Interference: Exploring the Limits of Model-Based Continual Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Heinrich van Deventer",
        "Anna Sergeevna Bosman"
      ],
      "abstract": "Continual learning is the sequential learning of different tasks by a machine\nlearning model. Continual learning is known to be hindered by catastrophic\ninterference or forgetting, i.e. rapid unlearning of earlier learned tasks when\nnew tasks are learned. Despite their practical success, artificial neural\nnetworks (ANNs) are prone to catastrophic interference. This study analyses how\ngradient descent and overlapping representations between distant input points\nlead to distal interference and catastrophic interference. Distal interference\nrefers to the phenomenon where training a model on a subset of the domain leads\nto non-local changes on other subsets of the domain. This study shows that\nuniformly trainable models without distal interference must be exponentially\nlarge. A novel antisymmetric bounded exponential layer B-spline ANN\narchitecture named ABEL-Spline is proposed that can approximate any continuous\nfunction, is uniformly trainable, has polynomial computational complexity, and\nprovides some guarantees for distal interference. Experiments are presented to\ndemonstrate the theoretical properties of ABEL-Splines. ABEL-Splines are also\nevaluated on benchmark regression problems. It is concluded that the weaker\ndistal interference guarantees in ABEL-Splines are insufficient for model-only\ncontinual learning. It is conjectured that continual learning with polynomial\ncomplexity models requires augmentation of the training data or algorithm.",
      "tldr_zh": "本研究探讨了基于模型的持续学习（continual learning）中的远端干扰（distal interference），即在域的一个子集上训练模型会导致其他子集的非局部变化，从而加剧灾难性干扰（catastrophic interference）。作者分析了梯度下降（gradient descent）和重叠表示如何引发这一问题，并证明了无远端干扰的模型必须指数级庞大。论文提出了一种新型反-symmetric 边界指数层 B-spline 神经网络架构 ABEL-Spline，能逼近任意连续函数、具有多项式计算复杂性，并提供部分远端干扰保证；实验验证了其理论属性，但结论指出该架构不足以支持纯模型持续学习，并推测需要增强训练数据或算法才能实现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE",
        "68T07",
        "I.5.1"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08255v1",
      "published_date": "2024-02-13 07:07:37 UTC",
      "updated_date": "2024-02-13 07:07:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:58:58.330157"
    },
    {
      "arxiv_id": "2402.08250v1",
      "title": "A survey of recent methods for addressing AI fairness and bias in biomedicine",
      "title_zh": "翻译失败",
      "authors": [
        "Yifan Yang",
        "Mingquan Lin",
        "Han Zhao",
        "Yifan Peng",
        "Furong Huang",
        "Zhiyong Lu"
      ],
      "abstract": "Artificial intelligence (AI) systems have the potential to revolutionize\nclinical practices, including improving diagnostic accuracy and surgical\ndecision-making, while also reducing costs and manpower. However, it is\nimportant to recognize that these systems may perpetuate social inequities or\ndemonstrate biases, such as those based on race or gender. Such biases can\noccur before, during, or after the development of AI models, making it critical\nto understand and address potential biases to enable the accurate and reliable\napplication of AI models in clinical settings. To mitigate bias concerns during\nmodel development, we surveyed recent publications on different debiasing\nmethods in the fields of biomedical natural language processing (NLP) or\ncomputer vision (CV). Then we discussed the methods that have been applied in\nthe biomedical domain to address bias. We performed our literature search on\nPubMed, ACM digital library, and IEEE Xplore of relevant articles published\nbetween January 2018 and December 2023 using multiple combinations of keywords.\nWe then filtered the result of 10,041 articles automatically with loose\nconstraints, and manually inspected the abstracts of the remaining 890 articles\nto identify the 55 articles included in this review. Additional articles in the\nreferences are also included in this review. We discuss each method and compare\nits strengths and weaknesses. Finally, we review other potential methods from\nthe general domain that could be applied to biomedicine to address bias and\nimprove fairness.The bias of AIs in biomedicine can originate from multiple\nsources. Existing debiasing methods that focus on algorithms can be categorized\ninto distributional or algorithmic.",
      "tldr_zh": "本论文对2018年至2023年间AI在生物医学领域中的公平性和偏见问题进行了全面调查，强调AI系统可能在诊断和决策中强化种族或性别等社会不公。研究者通过在PubMed、ACM数字图书馆和IEEE Xplore上搜索关键词，筛选出55篇相关文章，聚焦于生物医学自然语言处理(NLP)和计算机视觉(CV)中的debiasing方法。论文将这些方法分类为distributional或algorithmic类型，并比较了每种方法的优势和劣势，以帮助缓解偏见。最终，论文还探讨了从一般领域借鉴的其他潜在方法，以提升AI在生物医学中的公平性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08250v1",
      "published_date": "2024-02-13 06:38:46 UTC",
      "updated_date": "2024-02-13 06:38:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:59:10.316963"
    },
    {
      "arxiv_id": "2402.08246v1",
      "title": "Ant Colony Optimization for Cooperative Inspection Path Planning Using Multiple Unmanned Aerial Vehicles",
      "title_zh": "蚁群优化用于多无人驾驶航空器的合作检查路径规划",
      "authors": [
        "Duy Nam Bui",
        "Thuy Ngan Duong",
        "Manh Duong Phung"
      ],
      "abstract": "This paper presents a new swarm intelligence-based approach to deal with the\ncooperative path planning problem of unmanned aerial vehicles (UAVs), which is\nessential for the automatic inspection of infrastructure. The approach uses a\n3D model of the structure to generate viewpoints for the UAVs. The calculation\nof the viewpoints considers the constraints related to the UAV formation model,\ncamera parameters, and requirements for data post-processing. The viewpoints\nare then used as input to formulate the path planning as an extended traveling\nsalesman problem and the definition of a new cost function. Ant colony\noptimization is finally used to solve the problem to yield optimal inspection\npaths. Experiments with 3D models of real structures have been conducted to\nevaluate the performance of the proposed approach. The results show that our\nsystem is not only capable of generating feasible inspection paths for UAVs but\nalso reducing the path length by 29.47\\% for complex structures when compared\nwith another heuristic approach. The source code of the algorithm can be found\nat https://github.com/duynamrcv/aco_3d_ipp.",
      "tldr_zh": "这篇论文提出了一种基于 Ant Colony Optimization 的群智能方法，用于多 Unmanned Aerial Vehicles (UAVs) 的合作路径规划，以实现基础设施的自动检查。方法首先利用结构的三维模型生成 UAV 视点，考虑 UAV 编队模型、相机参数和数据后处理要求，然后将路径规划表述为扩展的 Traveling Salesman Problem 并定义新的成本函数。最终，通过 Ant Colony Optimization 算法求解，生成最优检查路径。实验结果显示，该方法在真实结构的 3D 模型上不仅能产生可行路径，还将复杂结构的路径长度比其他启发式方法减少 29.47%。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "Published in: 2024 IEEE/SICE International Symposium on System\n  Integration (SII)",
      "pdf_url": "http://arxiv.org/pdf/2402.08246v1",
      "published_date": "2024-02-13 06:20:37 UTC",
      "updated_date": "2024-02-13 06:20:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:59:23.200823"
    },
    {
      "arxiv_id": "2402.08242v1",
      "title": "Towards Equitable Agile Research and Development of AI and Robotics",
      "title_zh": "迈向人工智能和机器人技术的公平敏捷研究与开发",
      "authors": [
        "Andrew Hundt",
        "Julia Schuller",
        "Severin Kacianka"
      ],
      "abstract": "Machine Learning (ML) and 'Artificial Intelligence' ('AI') methods tend to\nreplicate and amplify existing biases and prejudices, as do Robots with AI. For\nexample, robots with facial recognition have failed to identify Black Women as\nhuman, while others have categorized people, such as Black Men, as criminals\nbased on appearance alone. A 'culture of modularity' means harms are perceived\nas 'out of scope', or someone else's responsibility, throughout employment\npositions in the 'AI supply chain'. Incidents are routine enough\n(incidentdatabase.ai lists over 2000 examples) to indicate that few\norganizations are capable of completely respecting peoples' rights; meeting\nclaimed equity, diversity, and inclusion (EDI or DEI) goals; or recognizing and\nthen addressing such failures in their organizations and artifacts. We propose\na framework for adapting widely practiced Research and Development (R&D)\nproject management methodologies to build organizational equity capabilities\nand better integrate known evidence-based best practices. We describe how\nproject teams can organize and operationalize the most promising practices,\nskill sets, organizational cultures, and methods to detect and address\nrights-based fairness, equity, accountability, and ethical problems as early as\npossible when they are often less harmful and easier to mitigate; then monitor\nfor unforeseen incidents to adaptively and constructively address them. Our\nprimary example adapts an Agile development process based on Scrum, one of the\nmost widely adopted approaches to organizing R&D teams. We also discuss\nlimitations of our proposed framework and future research directions.",
      "tldr_zh": "该论文讨论了AI和机器人在开发过程中如何放大现有偏见，例如面部识别系统未能识别黑人女性或错误地将黑人男性归类为罪犯，导致权益问题被视为“文化模块化”的责任分散现象。作者提出一个框架，适应Agile开发（如Scrum）等R&D项目管理方法，旨在构建组织公平能力，通过整合证据-based最佳实践来及早检测和解决公平、问责和伦理问题。实验和讨论显示，该框架可减少早期危害并监控意外事件，但也存在局限性，需要进一步研究。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.LG",
        "cs.RO",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "15 pages (32 with refs + appendix), 2 figures, 1 table (7 with\n  appendix), incorporates changes based on WeRobot 2023 Draft feedback",
      "pdf_url": "http://arxiv.org/pdf/2402.08242v1",
      "published_date": "2024-02-13 06:13:17 UTC",
      "updated_date": "2024-02-13 06:13:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:59:35.629157"
    },
    {
      "arxiv_id": "2402.08236v1",
      "title": "BERT4FCA: A Method for Bipartite Link Prediction using Formal Concept Analysis and BERT",
      "title_zh": "翻译失败",
      "authors": [
        "Siqi Peng",
        "Hongyuan Yang",
        "Akihiro Yamamoto"
      ],
      "abstract": "We propose BERT4FCA, a novel method for link prediction in bipartite\nnetworks, using formal concept analysis (FCA) and BERT. Link prediction in\nbipartite networks is an important task that can solve various practical\nproblems like friend recommendation in social networks and co-authorship\nprediction in author-paper networks. Recent research has found that in\nbipartite networks, maximal bi-cliques provide important information for link\nprediction, and they can be extracted by FCA. Some FCA-based bipartite link\nprediction methods have achieved good performance. However, we figured out that\ntheir performance could be further improved because these methods did not fully\ncapture the rich information of the extracted maximal bi-cliques. To address\nthis limitation, we propose an approach using BERT, which can learn more\ninformation from the maximal bi-cliques extracted by FCA and use them to make\nlink prediction. We conduct experiments on three real-world bipartite networks\nand demonstrate that our method outperforms previous FCA-based methods, and\nsome classic methods such as matrix-factorization and node2vec.",
      "tldr_zh": "本论文提出BERT4FCA，一种结合Formal Concept Analysis (FCA)和BERT的创新方法，用于二分网络的链接预测任务，该方法可应用于社交网络的朋友推荐或作者-论文网络的合著预测。BERT4FCA首先通过FCA提取最大二分团（maximal bi-cliques），然后利用BERT从这些团中学习更丰富的特征信息，从而提升预测准确性。实验结果显示，该方法在三个真实世界二分网络上优于现有FCA-based方法以及经典算法如matrix-factorization和node2vec，证明了其有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "23 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.08236v1",
      "published_date": "2024-02-13 06:02:05 UTC",
      "updated_date": "2024-02-13 06:02:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:59:46.000972"
    },
    {
      "arxiv_id": "2402.08228v2",
      "title": "Investigating Out-of-Distribution Generalization of GNNs: An Architecture Perspective",
      "title_zh": "图神经网络的分布外泛化研究：从架构视角",
      "authors": [
        "Kai Guo",
        "Hongzhi Wen",
        "Wei Jin",
        "Yaming Guo",
        "Jiliang Tang",
        "Yi Chang"
      ],
      "abstract": "Graph neural networks (GNNs) have exhibited remarkable performance under the\nassumption that test data comes from the same distribution of training data.\nHowever, in real-world scenarios, this assumption may not always be valid.\nConsequently, there is a growing focus on exploring the Out-of-Distribution\n(OOD) problem in the context of graphs. Most existing efforts have primarily\nconcentrated on improving graph OOD generalization from two\n\\textbf{model-agnostic} perspectives: data-driven methods and strategy-based\nlearning. However, there has been limited attention dedicated to investigating\nthe impact of well-known \\textbf{GNN model architectures} on graph OOD\ngeneralization, which is orthogonal to existing research. In this work, we\nprovide the first comprehensive investigation of OOD generalization on graphs\nfrom an architecture perspective, by examining the common building blocks of\nmodern GNNs. Through extensive experiments, we reveal that both the graph\nself-attention mechanism and the decoupled architecture contribute positively\nto graph OOD generalization. In contrast, we observe that the linear\nclassification layer tends to compromise graph OOD generalization capability.\nFurthermore, we provide in-depth theoretical insights and discussions to\nunderpin these discoveries. These insights have empowered us to develop a novel\nGNN backbone model, DGAT, designed to harness the robust properties of both\ngraph self-attention mechanism and the decoupled architecture. Extensive\nexperimental results demonstrate the effectiveness of our model under graph\nOOD, exhibiting substantial and consistent enhancements across various training\nstrategies.",
      "tldr_zh": "这篇论文从架构视角探讨了图神经网络(GNNs)的Out-of-Distribution (OOD) 泛化问题，首次系统调查了常见GNN构建块的影响，包括图自注意力机制、解耦架构和线性分类层。\n实验发现，图自注意力机制和解耦架构有助于提升GNNs的OOD泛化能力，而线性分类层则会损害这一性能。\n基于这些理论洞见，研究开发了新型GNN模型DGAT，利用图自注意力机制和解耦架构的优势，在各种训练策略下实现了显著的性能提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08228v2",
      "published_date": "2024-02-13 05:38:45 UTC",
      "updated_date": "2024-02-14 16:26:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:59:59.210973"
    },
    {
      "arxiv_id": "2402.08219v2",
      "title": "BBox-Adapter: Lightweight Adapting for Black-Box Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Haotian Sun",
        "Yuchen Zhuang",
        "Wei Wei",
        "Chao Zhang",
        "Bo Dai"
      ],
      "abstract": "Adapting state-of-the-art Large Language Models (LLMs) like GPT-4 and Gemini\nfor specific tasks is challenging. Due to the opacity in their parameters,\nembeddings, and even output probabilities, existing fine-tuning adaptation\nmethods are inapplicable. Consequently, adapting these black-box LLMs is only\npossible through their API services, raising concerns about transparency,\nprivacy, and cost. To address these challenges, we introduce BBox-Adapter, a\nnovel lightweight adapter for black-box LLMs. BBox-Adapter distinguishes target\nand source domain data by treating target data as positive and source data as\nnegative. It employs a ranking-based Noise Contrastive Estimation (NCE) loss to\npromote the likelihood of target domain data while penalizing that of the\nsource domain. Furthermore, it features an online adaptation mechanism, which\nincorporates real-time positive data sampling from ground-truth, human, or AI\nfeedback, coupled with negative data from previous adaptations. Extensive\nexperiments demonstrate BBox-Adapter's effectiveness and cost efficiency. It\nimproves model performance by up to 6.77% across diverse tasks and domains,\nwhile reducing training and inference costs by 31.30x and 1.84x, respectively.",
      "tldr_zh": "该论文提出BBox-Adapter，一种轻量级适配器，用于适应黑箱Large Language Models (LLMs)，如GPT-4和Gemini，解决参数不透明导致的透明度、隐私和成本问题。BBox-Adapter通过将目标域数据视为正样本、源域数据视为负样本，并采用基于排名的Noise Contrastive Estimation (NCE)损失函数，来提升目标域数据的可能性同时惩罚源域数据；此外，它还包括在线适应机制，利用实时正样本（如ground-truth、人类或AI反馈）和负样本进行优化。实验结果显示，该适配器在多种任务和领域中将模型性能提升高达6.77%，并分别将训练和推理成本降低31.30倍和1.84倍。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "25 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.08219v2",
      "published_date": "2024-02-13 05:15:46 UTC",
      "updated_date": "2024-05-28 17:04:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:00:09.874049"
    },
    {
      "arxiv_id": "2402.08211v1",
      "title": "Transformer Mechanisms Mimic Frontostriatal Gating Operations When Trained on Human Working Memory Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Aaron Traylor",
        "Jack Merullo",
        "Michael J. Frank",
        "Ellie Pavlick"
      ],
      "abstract": "Models based on the Transformer neural network architecture have seen success\non a wide variety of tasks that appear to require complex \"cognitive branching\"\n-- or the ability to maintain pursuit of one goal while accomplishing others.\nIn cognitive neuroscience, success on such tasks is thought to rely on\nsophisticated frontostriatal mechanisms for selective \\textit{gating}, which\nenable role-addressable updating -- and later readout -- of information to and\nfrom distinct \"addresses\" of memory, in the form of clusters of neurons.\nHowever, Transformer models have no such mechanisms intentionally built-in. It\nis thus an open question how Transformers solve such tasks, and whether the\nmechanisms that emerge to help them to do so bear any resemblance to the gating\nmechanisms in the human brain. In this work, we analyze the mechanisms that\nemerge within a vanilla attention-only Transformer trained on a simple sequence\nmodeling task inspired by a task explicitly designed to study working memory\ngating in computational cognitive neuroscience. We find that, as a result of\ntraining, the self-attention mechanism within the Transformer specializes in a\nway that mirrors the input and output gating mechanisms which were explicitly\nincorporated into earlier, more biologically-inspired architectures. These\nresults suggest opportunities for future research on computational similarities\nbetween modern AI architectures and models of the human brain.",
      "tldr_zh": "这篇论文探讨了Transformer模型在训练于人类工作记忆任务时，其内部机制如何模仿大脑的前扣带-纹状体（frontostriatal gating）操作，以实现选择性信息更新和读取。研究方法包括训练一个vanilla attention-only Transformer于一个受工作记忆任务启发的序列建模任务，并分析其self-attention机制。结果显示，Transformer的自注意力机制在训练后专门化，类似于早期生物启发架构中的输入和输出gating机制，这为探索AI架构与人类大脑计算相似性的未来研究提供了新机遇。",
      "categories": [
        "cs.AI",
        "I.2.6"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.08211v1",
      "published_date": "2024-02-13 04:28:43 UTC",
      "updated_date": "2024-02-13 04:28:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:00:23.178591"
    },
    {
      "arxiv_id": "2402.08209v1",
      "title": "Thresholding Data Shapley for Data Cleansing Using Multi-Armed Bandits",
      "title_zh": "翻译失败",
      "authors": [
        "Hiroyuki Namba",
        "Shota Horiguchi",
        "Masaki Hamamoto",
        "Masashi Egi"
      ],
      "abstract": "Data cleansing aims to improve model performance by removing a set of harmful\ninstances from the training dataset. Data Shapley is a common theoretically\nguaranteed method to evaluate the contribution of each instance to model\nperformance; however, it requires training on all subsets of the training data,\nwhich is computationally expensive. In this paper, we propose an\niterativemethod to fast identify a subset of instances with low data Shapley\nvalues by using the thresholding bandit algorithm. We provide a theoretical\nguarantee that the proposed method can accurately select harmful instances if a\nsufficiently large number of iterations is conducted. Empirical evaluation\nusing various models and datasets demonstrated that the proposed method\nefficiently improved the computational speed while maintaining the model\nperformance.",
      "tldr_zh": "这篇论文针对数据清洗问题，提出了一种使用 Multi-Armed Bandits 的阈值化方法，来快速识别 Data Shapley 值低的 harmful instances，从而避免了传统 Data Shapley 方法需训练所有训练数据子集的计算开销。方法采用迭代过程，通过 thresholding bandit 算法高效筛选有害实例。论文提供了理论保证，即在迭代次数足够时，该方法能准确选择有害实例。实证评估在多种模型和数据集上表明，该方法显著提高了计算速度，同时保持了模型性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08209v1",
      "published_date": "2024-02-13 04:17:48 UTC",
      "updated_date": "2024-02-13 04:17:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:00:34.470221"
    },
    {
      "arxiv_id": "2402.08208v2",
      "title": "Inherent Diverse Redundant Safety Mechanisms for AI-based Software Elements in Automotive Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Mandar Pitale",
        "Alireza Abbaspour",
        "Devesh Upadhyay"
      ],
      "abstract": "This paper explores the role and challenges of Artificial Intelligence (AI)\nalgorithms, specifically AI-based software elements, in autonomous driving\nsystems. These AI systems are fundamental in executing real-time critical\nfunctions in complex and high-dimensional environments. They handle vital tasks\nlike multi-modal perception, cognition, and decision-making tasks such as\nmotion planning, lane keeping, and emergency braking. A primary concern relates\nto the ability (and necessity) of AI models to generalize beyond their initial\ntraining data. This generalization issue becomes evident in real-time\nscenarios, where models frequently encounter inputs not represented in their\ntraining or validation data. In such cases, AI systems must still function\neffectively despite facing distributional or domain shifts. This paper\ninvestigates the risk associated with overconfident AI models in\nsafety-critical applications like autonomous driving. To mitigate these risks,\nmethods for training AI models that help maintain performance without\noverconfidence are proposed. This involves implementing certainty reporting\narchitectures and ensuring diverse training data. While various\ndistribution-based methods exist to provide safety mechanisms for AI models,\nthere is a noted lack of systematic assessment of these methods, especially in\nthe context of safety-critical automotive applications. Many methods in the\nliterature do not adapt well to the quick response times required in\nsafety-critical edge applications. This paper reviews these methods, discusses\ntheir suitability for safety-critical applications, and highlights their\nstrengths and limitations. The paper also proposes potential improvements to\nenhance the safety and reliability of AI algorithms in autonomous vehicles in\nthe context of rapid and accurate decision-making processes.",
      "tldr_zh": "这篇论文探讨了AI算法在自动驾驶系统中的角色与挑战，重点关注AI-based software elements在处理实时关键任务（如多模态感知、决策和运动规划）时的泛化问题和过自信风险。这些问题在面对训练数据外的输入时可能导致性能下降，因此论文提出训练方法，包括certainty reporting architectures和diverse training data，以提升AI模型的可靠性和安全性。最后，论文审查现有分布-based方法，评估其在安全关键汽车应用的适用性，并建议改进来支持快速决策过程。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "This article is accepted for the SAE WCX 2024 conference proceedings",
      "pdf_url": "http://arxiv.org/pdf/2402.08208v2",
      "published_date": "2024-02-13 04:15:26 UTC",
      "updated_date": "2024-02-29 18:18:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:00:46.106568"
    },
    {
      "arxiv_id": "2402.08198v1",
      "title": "PSC-CPI: Multi-Scale Protein Sequence-Structure Contrasting for Efficient and Generalizable Compound-Protein Interaction Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Lirong Wu",
        "Yufei Huang",
        "Cheng Tan",
        "Zhangyang Gao",
        "Bozhen Hu",
        "Haitao Lin",
        "Zicheng Liu",
        "Stan Z. Li"
      ],
      "abstract": "Compound-Protein Interaction (CPI) prediction aims to predict the pattern and\nstrength of compound-protein interactions for rational drug discovery. Existing\ndeep learning-based methods utilize only the single modality of protein\nsequences or structures and lack the co-modeling of the joint distribution of\nthe two modalities, which may lead to significant performance drops in complex\nreal-world scenarios due to various factors, e.g., modality missing and domain\nshifting. More importantly, these methods only model protein sequences and\nstructures at a single fixed scale, neglecting more fine-grained multi-scale\ninformation, such as those embedded in key protein fragments. In this paper, we\npropose a novel multi-scale Protein Sequence-structure Contrasting framework\nfor CPI prediction (PSC-CPI), which captures the dependencies between protein\nsequences and structures through both intra-modality and cross-modality\ncontrasting. We further apply length-variable protein augmentation to allow\ncontrasting to be performed at different scales, from the amino acid level to\nthe sequence level. Finally, in order to more fairly evaluate the model\ngeneralizability, we split the test data into four settings based on whether\ncompounds and proteins have been observed during the training stage. Extensive\nexperiments have shown that PSC-CPI generalizes well in all four settings,\nparticularly in the more challenging ``Unseen-Both\" setting, where neither\ncompounds nor proteins have been observed during training. Furthermore, even\nwhen encountering a situation of modality missing, i.e., inference with only\nsingle-modality protein data, PSC-CPI still exhibits comparable or even better\nperformance than previous approaches.",
      "tldr_zh": "该论文提出 PSC-CPI，一种多尺度蛋白序列-结构对比框架，用于高效且泛化性强的 Compound-Protein Interaction (CPI) 预测，以解决现有方法仅使用单一模态（如序列或结构）导致的性能下降问题。PSC-CPI 通过 intra-modality 和 cross-modality contrasting 捕获序列与结构之间的依赖，并利用 length-variable protein augmentation 在不同尺度（如氨基酸级别到序列级别）进行建模。实验结果显示，该框架在四种测试设置中均表现出色，尤其在更具挑战性的 \"Unseen-Both\" 场景（训练中未见过化合物和蛋白）中泛化良好；即使在模态缺失（如仅用单一模态数据）的情况下，PSC-CPI 的性能仍优于或相当于是前人方法。",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.BM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08198v1",
      "published_date": "2024-02-13 03:51:10 UTC",
      "updated_date": "2024-02-13 03:51:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:00:59.094846"
    },
    {
      "arxiv_id": "2402.08191v2",
      "title": "THE COLOSSEUM: A Benchmark for Evaluating Generalization for Robotic Manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Wilbert Pumacay",
        "Ishika Singh",
        "Jiafei Duan",
        "Ranjay Krishna",
        "Jesse Thomason",
        "Dieter Fox"
      ],
      "abstract": "To realize effective large-scale, real-world robotic applications, we must\nevaluate how well our robot policies adapt to changes in environmental\nconditions. Unfortunately, a majority of studies evaluate robot performance in\nenvironments closely resembling or even identical to the training setup. We\npresent THE COLOSSEUM, a novel simulation benchmark, with 20 diverse\nmanipulation tasks, that enables systematical evaluation of models across 14\naxes of environmental perturbations. These perturbations include changes in\ncolor, texture, and size of objects, table-tops, and backgrounds; we also vary\nlighting, distractors, physical properties perturbations and camera pose. Using\nTHE COLOSSEUM, we compare 5 state-of-the-art manipulation models to reveal that\ntheir success rate degrades between 30-50% across these perturbation factors.\nWhen multiple perturbations are applied in unison, the success rate degrades\n$\\geq$75%. We identify that changing the number of distractor objects, target\nobject color, or lighting conditions are the perturbations that reduce model\nperformance the most. To verify the ecological validity of our results, we show\nthat our results in simulation are correlated ($\\bar{R}^2 = 0.614$) to similar\nperturbations in real-world experiments. We open source code for others to use\nTHE COLOSSEUM, and also release code to 3D print the objects used to replicate\nthe real-world perturbations. Ultimately, we hope that THE COLOSSEUM will serve\nas a benchmark to identify modeling decisions that systematically improve\ngeneralization for manipulation. See https://robot-colosseum.github.io/ for\nmore details.",
      "tldr_zh": "该研究引入了THE COLOSSEUM基准，一个模拟环境，用于系统评估机器人操作模型在环境扰动下的泛化能力，包括20个多样化操作任务和14个扰动轴，如对象颜色、纹理、大小、灯光、干扰物和相机姿势变化。实验比较了5个最先进模型，发现这些模型在单一扰动下成功率下降30-50%，而多重扰动时下降≥75%，其中干扰物数量、目标对象颜色和灯光条件对性能影响最大。论文验证了模拟结果与真实世界实验的相关性（平均R²=0.614），并开源代码和3D打印资源，以促进未来机器人操作泛化的建模改进。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "RSS 2024. 33 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.08191v2",
      "published_date": "2024-02-13 03:25:33 UTC",
      "updated_date": "2024-05-28 00:37:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:01:11.075933"
    },
    {
      "arxiv_id": "2402.08185v1",
      "title": "Advancing Data-driven Weather Forecasting: Time-Sliding Data Augmentation of ERA5",
      "title_zh": "翻译失败",
      "authors": [
        "Minjong Cheon",
        "Daehyun Kang",
        "Yo-Hwan Choi",
        "Seon-Yu Kang"
      ],
      "abstract": "Modern deep learning techniques, which mimic traditional numerical weather\nprediction (NWP) models and are derived from global atmospheric reanalysis\ndata, have caused a significant revolution within a few years. In this new\nparadigm, our research introduces a novel strategy that deviates from the\ncommon dependence on high-resolution data, which is often constrained by\ncomputational resources, and instead utilizes low-resolution data (2.5 degrees)\nfor global weather prediction and climate data analysis. Our main focus is\nevaluating data-driven weather prediction (DDWP) frameworks, specifically\naddressing sample size adequacy, structural improvements to the model, and the\nability of climate data to represent current climatic trends. By using the\nAdaptive Fourier Neural Operator (AFNO) model via FourCastNet and a proposed\ntime-sliding method to inflate the dataset of the ECMWF Reanalysis v5 (ERA5),\nthis paper improves on conventional approaches by adding more variables and a\nnovel approach to data augmentation and processing. Our findings reveal that\ndespite the lower resolution, the proposed approach demonstrates considerable\naccuracy in predicting atmospheric conditions, effectively rivaling\nhigher-resolution models. Furthermore, the study confirms the model's\nproficiency in reflecting current climate trends and its potential in\npredicting future climatic events, underscoring its utility in climate change\nstrategies. This research marks a pivotal step in the realm of meteorological\nforecasting, showcasing the feasibility of lower-resolution data in producing\nreliable predictions and opening avenues for more accessible and inclusive\nclimate modeling. The insights gleaned from this study not only contribute to\nthe advancement of climate science but also lay the groundwork for future\ninnovations in the field.",
      "tldr_zh": "本研究提出了一种创新策略，使用低分辨率数据（2.5 度）进行全球天气预测和气候数据分析，以减少对高分辨率数据的依赖。该方法基于 Adaptive Fourier Neural Operator (AFNO) 模型和 FourCastNet 框架，通过 time-sliding 数据增强技术扩展 ECMWF Reanalysis v5 (ERA5) 数据集，并添加更多变量来提升数据驱动天气预测 (DDWP) 的样本大小和模型结构。实验结果显示，尽管分辨率较低，该方法在预测大气条件方面表现出色，与高分辨率模型相当，并能准确反映当前气候趋势及预测未来气候事件。该研究为气象预报领域开辟新路径，证明低分辨率数据可实现可靠预测，促进更具包容性的气候建模和变化策略。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "physics.ao-ph"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08185v1",
      "published_date": "2024-02-13 03:01:22 UTC",
      "updated_date": "2024-02-13 03:01:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:01:23.077779"
    },
    {
      "arxiv_id": "2402.08184v1",
      "title": "Enabling Multi-Agent Transfer Reinforcement Learning via Scenario Independent Representation",
      "title_zh": "翻译失败",
      "authors": [
        "Ayesha Siddika Nipu",
        "Siming Liu",
        "Anthony Harris"
      ],
      "abstract": "Multi-Agent Reinforcement Learning (MARL) algorithms are widely adopted in\ntackling complex tasks that require collaboration and competition among agents\nin dynamic Multi-Agent Systems (MAS). However, learning such tasks from scratch\nis arduous and may not always be feasible, particularly for MASs with a large\nnumber of interactive agents due to the extensive sample complexity. Therefore,\nreusing knowledge gained from past experiences or other agents could\nefficiently accelerate the learning process and upscale MARL algorithms. In\nthis study, we introduce a novel framework that enables transfer learning for\nMARL through unifying various state spaces into fixed-size inputs that allow\none unified deep-learning policy viable in different scenarios within a MAS. We\nevaluated our approach in a range of scenarios within the StarCraft Multi-Agent\nChallenge (SMAC) environment, and the findings show significant enhancements in\nmulti-agent learning performance using maneuvering skills learned from other\nscenarios compared to agents learning from scratch. Furthermore, we adopted\nCurriculum Transfer Learning (CTL), enabling our deep learning policy to\nprogressively acquire knowledge and skills across pre-designed homogeneous\nlearning scenarios organized by difficulty levels. This process promotes inter-\nand intra-agent knowledge transfer, leading to high multi-agent learning\nperformance in more complicated heterogeneous scenarios.",
      "tldr_zh": "本文提出了一种新框架，通过 Scenario Independent Representation 将各种状态空间统一为固定大小的输入，实现 Multi-Agent Reinforcement Learning (MARL) 的转移学习，从而高效重用知识加速多智能体系统中的协作和竞争任务。实验在 StarCraft Multi-Agent Challenge (SMAC) 环境中进行，结果显示，该方法显著提升了学习性能，使用其他场景学到的机动技能比从零开始学习提高了效果。此外，结合 Curriculum Transfer Learning (CTL)，框架允许策略逐步在按难度组织的同质场景中获取知识，并推广到复杂异质场景，促进智能体间和内部知识转移。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "2023 IEEE Conference on Games (CoG)",
      "pdf_url": "http://arxiv.org/pdf/2402.08184v1",
      "published_date": "2024-02-13 02:48:18 UTC",
      "updated_date": "2024-02-13 02:48:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:01:34.772290"
    },
    {
      "arxiv_id": "2402.08178v1",
      "title": "LoTa-Bench: Benchmarking Language-oriented Task Planners for Embodied Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Jae-Woo Choi",
        "Youngwoo Yoon",
        "Hyobin Ong",
        "Jaehong Kim",
        "Minsu Jang"
      ],
      "abstract": "Large language models (LLMs) have recently received considerable attention as\nalternative solutions for task planning. However, comparing the performance of\nlanguage-oriented task planners becomes difficult, and there exists a dearth of\ndetailed exploration regarding the effects of various factors such as\npre-trained model selection and prompt construction. To address this, we\npropose a benchmark system for automatically quantifying performance of task\nplanning for home-service embodied agents. Task planners are tested on two\npairs of datasets and simulators: 1) ALFRED and AI2-THOR, 2) an extension of\nWatch-And-Help and VirtualHome. Using the proposed benchmark system, we perform\nextensive experiments with LLMs and prompts, and explore several enhancements\nof the baseline planner. We expect that the proposed benchmark tool would\naccelerate the development of language-oriented task planners.",
      "tldr_zh": "该论文提出LoTa-Bench基准系统，用于评估语言导向任务规划器在家居服务化身代理中的性能，解决比较LLMs（Large Language Models）规划器难度大以及对因素如预训练模型选择和提示构建缺乏探索的问题。基准系统在ALFRED与AI2-THOR，以及Watch-And-Help扩展与VirtualHome两个数据集和模拟器对上进行自动量化测试，通过广泛实验探索LLMs的优化和基线规划器的增强。研究结果表明，该工具有望加速语言导向任务规划器的开发和改进。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "ICLR 2024. Code: https://github.com/lbaa2022/LLMTaskPlanning",
      "pdf_url": "http://arxiv.org/pdf/2402.08178v1",
      "published_date": "2024-02-13 02:28:57 UTC",
      "updated_date": "2024-02-13 02:28:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:01:47.470529"
    },
    {
      "arxiv_id": "2402.08174v2",
      "title": "Hierarchical Position Embedding of Graphs with Landmarks and Clustering for Link Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Minsang Kim",
        "Seungjun Baek"
      ],
      "abstract": "Learning positional information of nodes in a graph is important for link\nprediction tasks. We propose a representation of positional information using\nrepresentative nodes called landmarks. A small number of nodes with high degree\ncentrality are selected as landmarks, which serve as reference points for the\nnodes' positions. We justify this selection strategy for well-known random\ngraph models and derive closed-form bounds on the average path lengths\ninvolving landmarks. In a model for power-law graphs, we prove that landmarks\nprovide asymptotically exact information on inter-node distances. We apply\ntheoretical insights to practical networks and propose Hierarchical Position\nembedding with Landmarks and Clustering (HPLC). HPLC combines landmark\nselection and graph clustering, where the graph is partitioned into densely\nconnected clusters in which nodes with the highest degree are selected as\nlandmarks. HPLC leverages the positional information of nodes based on\nlandmarks at various levels of hierarchy such as nodes' distances to landmarks,\ninter-landmark distances and hierarchical grouping of clusters. Experiments\nshow that HPLC achieves state-of-the-art performances of link prediction on\nvarious datasets in terms of HIT@K, MRR, and AUC. The code is available at\n\\url{https://github.com/kmswin1/HPLC}.",
      "tldr_zh": "该论文提出了一种名为HPLC（Hierarchical Position Embedding with Landmarks and Clustering）的图位置嵌入方法，用于提升link prediction任务的性能，通过选择高degree centrality的节点作为landmarks，并结合图聚类构建多层次位置信息，如节点到landmarks的距离和层次聚类。理论分析证明了landmarks在随机图模型和幂律图中能提供渐近精确的节点间距离边界。实验结果显示，HPLC在各种数据集上实现了state-of-the-art性能，包括HIT@K、MRR和AUC指标的显著提升。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "The International World Wide Web Conference (WWW) 2024, Accepted\n  paper",
      "pdf_url": "http://arxiv.org/pdf/2402.08174v2",
      "published_date": "2024-02-13 02:13:12 UTC",
      "updated_date": "2024-04-19 10:23:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:01:59.784402"
    },
    {
      "arxiv_id": "2402.08170v3",
      "title": "LLaGA: Large Language and Graph Assistant",
      "title_zh": "翻译失败",
      "authors": [
        "Runjin Chen",
        "Tong Zhao",
        "Ajay Jaiswal",
        "Neil Shah",
        "Zhangyang Wang"
      ],
      "abstract": "Graph Neural Networks (GNNs) have empowered the advance in graph-structured\ndata analysis. Recently, the rise of Large Language Models (LLMs) like GPT-4\nhas heralded a new era in deep learning. However, their application to graph\ndata poses distinct challenges due to the inherent difficulty of translating\ngraph structures to language. To this end, we introduce the Large Language and\nGraph Assistant (LLaGA), an innovative model that effectively integrates LLM\ncapabilities to handle the complexities of graph-structured data. LLaGA retains\nthe general-purpose nature of LLMs while adapting graph data into a format\ncompatible with LLM input. LLaGA achieves this by reorganizing graph nodes to\nstructure-aware sequences and then mapping these into the token embedding space\nthrough a versatile projector. LLaGA excels in versatility, generalizability\nand interpretability, allowing it to perform consistently well across different\ndatasets and tasks, extend its ability to unseen datasets or tasks, and provide\nexplanations for graphs. Our extensive experiments across popular graph\nbenchmarks show that LLaGA delivers outstanding performance across four\ndatasets and three tasks using one single model, surpassing state-of-the-art\ngraph models in both supervised and zero-shot scenarios. Our code is available\nat \\url{https://github.com/VITA-Group/LLaGA}.",
      "tldr_zh": "这篇论文提出了 LLaGA，一种创新模型，将 Large Language Models (LLMs) 与图结构数据处理相结合，旨在解决将 LLMs 应用于图数据时面临的翻译挑战。LLaGA 通过将图节点重组为结构感知序列，并使用一个多功能投影器映射到 token 嵌入空间，从而保留了 LLMs 的通用性，同时提升了在图任务中的多功能性、泛化性和可解释性。实验结果显示，LLaGA 在四个数据集和三个任务上表现出色，超越了最先进的 Graph Neural Networks (GNNs) 模型，在监督和零射击场景中均有显著性能提升。模型代码已在 GitHub 上公开。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08170v3",
      "published_date": "2024-02-13 02:03:26 UTC",
      "updated_date": "2024-04-11 05:01:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:02:10.677508"
    },
    {
      "arxiv_id": "2402.08164v2",
      "title": "On Limitations of the Transformer Architecture",
      "title_zh": "翻译失败",
      "authors": [
        "Binghui Peng",
        "Srini Narayanan",
        "Christos Papadimitriou"
      ],
      "abstract": "What are the root causes of hallucinations in large language models (LLMs)?\nWe use Communication Complexity to prove that the Transformer layer is\nincapable of composing functions (e.g., identify a grandparent of a person in a\ngenealogy) if the domains of the functions are large enough; we show through\nexamples that this inability is already empirically present when the domains\nare quite small. We also point out that several mathematical tasks that are at\nthe core of the so-called compositional tasks thought to be hard for LLMs are\nunlikely to be solvable by Transformers, for large enough instances and\nassuming that certain well accepted conjectures in the field of Computational\nComplexity are true.",
      "tldr_zh": "本论文探讨了Transformer架构在大型语言模型(LLMs)中产生幻觉的根本原因，通过Communication Complexity理论证明，Transformer层无法有效组合函数（如识别祖先关系），尤其当函数域足够大时；即使在较小域中，这种问题已在实验示例中显现。研究进一步指出，许多核心的组合任务（如某些数学问题）可能无法由Transformer解决，前提是某些计算复杂性猜想成立。这些发现强调了Transformer架构的局限性，并为未来模型设计提供了重要启示。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08164v2",
      "published_date": "2024-02-13 01:52:15 UTC",
      "updated_date": "2024-02-26 22:12:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:02:21.845018"
    },
    {
      "arxiv_id": "2402.08156v7",
      "title": "Differentially Private Distributed Inference",
      "title_zh": "差分隐私分布式推理",
      "authors": [
        "Marios Papachristou",
        "M. Amin Rahimian"
      ],
      "abstract": "How can agents exchange information to learn while protecting privacy?\nHealthcare centers collaborating on clinical trials must balance knowledge\nsharing with safeguarding sensitive patient data. We address this challenge by\nusing differential privacy (DP) to control information leakage. Agents update\nbelief statistics via log-linear rules, and DP noise provides plausible\ndeniability and rigorous performance guarantees. We study two settings:\ndistributed maximum likelihood estimation (MLE) with a finite set of private\nsignals and online learning from an intermittent signal stream. Noisy\naggregation introduces trade-offs between rejecting low-quality states and\naccepting high-quality ones. The MLE setting naturally applies to hypothesis\ntesting with formal statistical guarantees. Through simulations, we demonstrate\ndifferentially private, distributed survival analysis on real-world clinical\ntrial data, evaluating treatment efficacy and the impact of biomedical indices\non patient survival. Our methods enable privacy-preserving inference with\ngreater efficiency and lower error rates than homomorphic encryption and\nfirst-order DP optimization approaches.",
      "tldr_zh": "本研究探讨了代理在保护隐私的同时交换信息进行学习的机制，特别针对医疗中心在临床试验中共享知识却需防范敏感患者数据泄露的问题。作者采用差分隐私(DP)技术，通过log-linear规则更新信念统计并添加DP噪声，以提供plausible deniability和性能保证，并在分布式最大似然估计(MLE)以及在线学习从间歇性信号流中两个设置下进行了分析。实验结果显示，该方法在真实临床试验数据上的分布式生存分析中，实现了高效的隐私保护推理，比同态加密和一阶DP优化方法具有更低的错误率，并为假设测试提供了正式的统计保证。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.MA",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08156v7",
      "published_date": "2024-02-13 01:38:01 UTC",
      "updated_date": "2025-03-18 03:46:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:02:36.785817"
    },
    {
      "arxiv_id": "2402.08155v1",
      "title": "CMA-R:Causal Mediation Analysis for Explaining Rumour Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Lin Tian",
        "Xiuzhen Zhang",
        "Jey Han Lau"
      ],
      "abstract": "We apply causal mediation analysis to explain the decision-making process of\nneural models for rumour detection on Twitter. Interventions at the input and\nnetwork level reveal the causal impacts of tweets and words in the model\noutput. We find that our approach CMA-R -- Causal Mediation Analysis for Rumour\ndetection -- identifies salient tweets that explain model predictions and show\nstrong agreement with human judgements for critical tweets determining the\ntruthfulness of stories. CMA-R can further highlight causally impactful words\nin the salient tweets, providing another layer of interpretability and\ntransparency into these blackbox rumour detection systems. Code is available\nat: https://github.com/ltian678/cma-r.",
      "tldr_zh": "本研究提出 CMA-R 方法，利用因果中介分析（Causal Mediation Analysis）来解释神经模型在 Twitter 谣言检测中的决策过程。通过对输入（如推文和单词）和网络层面的干预，CMA-R 揭示了这些元素对模型输出的因果影响。实验结果显示，该方法能准确识别出关键推文，这些推文与人类判断高度一致，并进一步突出这些推文中具有因果影响的单词，从而提升谣言检测系统的可解释性和透明度。代码已在 GitHub 上公开。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 7 figures, Accepted by EACL 2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2402.08155v1",
      "published_date": "2024-02-13 01:31:08 UTC",
      "updated_date": "2024-02-13 01:31:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:02:47.173503"
    },
    {
      "arxiv_id": "2402.08151v2",
      "title": "Gradient-flow adaptive importance sampling for Bayesian leave one out cross-validation with application to sigmoidal classification models",
      "title_zh": "翻译失败",
      "authors": [
        "Joshua C Chang",
        "Xiangting Li",
        "Shixin Xu",
        "Hao-Ren Yao",
        "Julia Porcino",
        "Carson Chow"
      ],
      "abstract": "We introduce gradient-flow-guided adaptive importance sampling (IS)\ntransformations for stabilizing Monte-Carlo approximations of leave-one-out\n(LOO) cross-validated predictions for Bayesian models. After defining two\nvariational problems, we derive corresponding simple nonlinear transformations\nthat utilize gradient information to shift a model's pre-trained full-data\nposterior closer to the target LOO posterior predictive distributions. In doing\nso, the transformations stabilize importance weights. The resulting Monte Carlo\nintegrals depend on Jacobian determinants with respect to the model Hessian. We\nderive closed-form exact formulae for these Jacobian determinants in the cases\nof logistic regression and shallow ReLU-activated artificial neural networks,\nand provide a simple approximation that sidesteps the need to compute full\nHessian matrices and their spectra. We test the methodology on an $n\\ll p$\ndataset that is known to produce unstable LOO IS weights.",
      "tldr_zh": "本文提出了一种基于梯度流（gradient-flow）的适应性重要性采样（adaptive importance sampling）方法，用于稳定贝叶斯模型的留一交叉验证（leave one out cross-validation, LOO）的 Monte-Carlo 近似。通过定义两个变分问题，该方法导出非线性变换，利用梯度信息将模型的全数据后验分布移向目标 LOO 后验预测分布，从而稳定重要性权重。针对 logistic 回归和浅层 ReLU-activated artificial neural networks，论文导出了 Jacobian determinants 的封闭形式公式，并提供简单近似以避免计算完整 Hessian 矩阵。在 n ≪ p 数据集上测试，该方法有效解决了不稳定的 LOO IS 权重问题。",
      "categories": [
        "stat.ME",
        "cs.AI",
        "cs.LG",
        "math.SP",
        "math.ST",
        "stat.TH"
      ],
      "primary_category": "stat.ME",
      "comment": "Submitted",
      "pdf_url": "http://arxiv.org/pdf/2402.08151v2",
      "published_date": "2024-02-13 01:03:39 UTC",
      "updated_date": "2024-10-20 22:42:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:03:01.022773"
    },
    {
      "arxiv_id": "2402.08147v2",
      "title": "VerMCTS: Synthesizing Multi-Step Programs using a Verifier, a Large Language Model, and Tree Search",
      "title_zh": "翻译失败",
      "authors": [
        "David Brandfonbrener",
        "Simon Henniger",
        "Sibi Raja",
        "Tarun Prasad",
        "Chloe Loughridge",
        "Federico Cassano",
        "Sabrina Ruixin Hu",
        "Jianang Yang",
        "William E. Byrd",
        "Robert Zinkov",
        "Nada Amin"
      ],
      "abstract": "Large Language Models (LLMs) can generate useful code, but often the code\nthey generate cannot be trusted to be sound. In this paper, we present VerMCTS,\nan approach to begin to resolve this issue by generating verified programs in\nDafny and Coq. VerMCTS uses a logical verifier in concert with an LLM to guide\na modified Monte Carlo Tree Search (MCTS). This approach leverages the verifier\nto gain intermediate feedback inside the search algorithm by checking partial\nprograms at each step to estimate an upper bound on the value function. To\nmeasure the performance of VerMCTS, we develop a new suite of multi-step\nverified programming problems in Dafny and Coq. In terms of pass@T, a new\nmetric which computes the pass rate given a budget of T tokens sampled from the\nLLM, VerMCTS leads to more than a 30% absolute increase in average pass@5000\nacross the suite over repeated sampling from the base language model. Our code\nand benchmarks are available at\nhttps://github.com/namin/llm-verified-with-monte-carlo-tree-search .",
      "tldr_zh": "本论文提出 VerMCTS，一种结合验证器、Large Language Models (LLMs) 和修改后的 Monte Carlo Tree Search (MCTS) 的方法，用于合成多步验证程序，如在 Dafny 和 Coq 中的应用。该方法通过在搜索过程中对部分程序进行逻辑验证，获得中间反馈以估计价值函数的上界，从而提升程序生成的可靠性和准确性。为评估性能，论文开发了新的多步验证编程问题基准，结果显示 VerMCTS 在 pass@5000 指标上比基础语言模型平均提高了超过 30%。代码和基准可从指定 GitHub 仓库获取。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG",
        "cs.LO",
        "cs.PL"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08147v2",
      "published_date": "2024-02-13 00:55:14 UTC",
      "updated_date": "2024-05-24 14:51:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:03:12.358842"
    },
    {
      "arxiv_id": "2402.08145v2",
      "title": "Epistemic Exploration for Generalizable Planning and Learning in Non-Stationary Settings",
      "title_zh": "翻译失败",
      "authors": [
        "Rushang Karia",
        "Pulkit Verma",
        "Alberto Speranzon",
        "Siddharth Srivastava"
      ],
      "abstract": "This paper introduces a new approach for continual planning and model\nlearning in relational, non-stationary stochastic environments. Such\ncapabilities are essential for the deployment of sequential decision-making\nsystems in the uncertain and constantly evolving real world. Working in such\npractical settings with unknown (and non-stationary) transition systems and\nchanging tasks, the proposed framework models gaps in the agent's current state\nof knowledge and uses them to conduct focused, investigative explorations. Data\ncollected using these explorations is used for learning generalizable\nprobabilistic models for solving the current task despite continual changes in\nthe environment dynamics. Empirical evaluations on several non-stationary\nbenchmark domains show that this approach significantly outperforms planning\nand RL baselines in terms of sample complexity. Theoretical results show that\nthe system exhibits desirable convergence properties when stationarity holds.",
      "tldr_zh": "这篇论文提出了一种Epistemic Exploration框架，用于在non-stationary stochastic environments中进行持续规划和模型学习，以适应不确定且不断变化的真实世界任务。该框架通过识别代理知识空白进行有针对性的探索性调查，并利用收集的数据学习可泛化的probabilistic models，从而在环境动态变化的情况下有效解决当前任务。实证评估在多个non-stationary基准域上显示，该方法在sample complexity方面显著优于规划和RL baselines；理论分析表明，当环境平稳时，系统具备理想的收敛特性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "To appear at ICAPS-24",
      "pdf_url": "http://arxiv.org/pdf/2402.08145v2",
      "published_date": "2024-02-13 00:50:06 UTC",
      "updated_date": "2024-06-07 01:21:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:03:23.893088"
    },
    {
      "arxiv_id": "2402.08144v2",
      "title": "Average-Case Analysis of Iterative Voting",
      "title_zh": "翻译失败",
      "authors": [
        "Joshua Kavner",
        "Lirong Xia"
      ],
      "abstract": "Iterative voting is a natural model of repeated strategic decision-making in\nsocial choice when agents have the opportunity to update their votes prior to\nfinalizing the group decision. Prior work has analyzed the efficacy of\niterative plurality on the welfare of the chosen outcome at equilibrium,\nrelative to the truthful vote profile, via an adaptation of the price of\nanarchy. However, prior analyses have only studied the worst- and average-case\nperformances when agents' preferences are distributed by the impartial culture.\nThis work extends average-case analysis to a wider class of distributions and\ndistinguishes when iterative plurality improves or degrades asymptotic welfare.",
      "tldr_zh": "该论文分析了迭代投票（iterative voting）模型，该模型允许代理人在社会选择中多次更新投票以优化最终群体决策。作者扩展了先前基于无政府价格（price of anarchy）适配的平均情况分析，从仅限于公正文化（impartial culture）的分布扩展到更广泛的偏好分布。研究结果显示，迭代多数投票在不同分布下可能改善或降低渐近福利，从而为评估其对社会福利的影响提供了更全面的洞见。",
      "categories": [
        "cs.GT",
        "cs.AI"
      ],
      "primary_category": "cs.GT",
      "comment": "75 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.08144v2",
      "published_date": "2024-02-13 00:46:46 UTC",
      "updated_date": "2024-03-06 00:15:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:03:34.341310"
    },
    {
      "arxiv_id": "2402.08143v1",
      "title": "Artificial intelligence and the transformation of higher education institutions",
      "title_zh": "人工智能与高等教育机构的转型",
      "authors": [
        "Evangelos Katsamakas",
        "Oleg V. Pavlov",
        "Ryan Saklad"
      ],
      "abstract": "Artificial intelligence (AI) advances and the rapid adoption of generative AI\ntools like ChatGPT present new opportunities and challenges for higher\neducation. While substantial literature discusses AI in higher education, there\nis a lack of a systemic approach that captures a holistic view of the AI\ntransformation of higher education institutions (HEIs). To fill this gap, this\narticle, taking a complex systems approach, develops a causal loop diagram\n(CLD) to map the causal feedback mechanisms of AI transformation in a typical\nHEI. Our model accounts for the forces that drive the AI transformation and the\nconsequences of the AI transformation on value creation in a typical HEI. The\narticle identifies and analyzes several reinforcing and balancing feedback\nloops, showing how, motivated by AI technology advances, the HEI invests in AI\nto improve student learning, research, and administration. The HEI must take\nmeasures to deal with academic integrity problems and adapt to changes in\navailable jobs due to AI, emphasizing AI-complementary skills for its students.\nHowever, HEIs face a competitive threat and several policy traps that may lead\nto decline. HEI leaders need to become systems thinkers to manage the\ncomplexity of the AI transformation and benefit from the AI feedback loops\nwhile avoiding the associated pitfalls. We also discuss long-term scenarios,\nthe notion of HEIs influencing the direction of AI, and directions for future\nresearch on AI transformation.",
      "tldr_zh": "这篇论文探讨了人工智能（AI）对高等教育机构（HEIs）的转变，强调AI的进步（如ChatGPT）带来的机遇和挑战。作者采用复杂系统方法，构建了一个因果循环图（CLD）来系统映射AI转变的反馈机制，包括驱动因素及其对学生学习、研究和管理价值的影响。论文识别了强化和平衡反馈循环，指出HEIs需投资AI以提升教育质量，同时应对学术诚信问题、就业变化和竞争威胁，并建议领导者通过系统思考避免政策陷阱。最终，该研究讨论了长期场景、HEIs影响AI方向的潜力，以及未来研究的导向。",
      "categories": [
        "econ.GN",
        "cs.AI",
        "cs.CY",
        "q-fin.EC"
      ],
      "primary_category": "econ.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08143v1",
      "published_date": "2024-02-13 00:36:10 UTC",
      "updated_date": "2024-02-13 00:36:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:03:47.023593"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 98,
  "processed_papers_count": 98,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-17T06:04:06.587745"
}