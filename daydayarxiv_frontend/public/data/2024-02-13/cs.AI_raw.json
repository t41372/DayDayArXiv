[
  {
    "arxiv_id": "2402.08855v2",
    "title": "GhostWriter: Augmenting Collaborative Human-AI Writing Experiences Through Personalization and Agency",
    "authors": [
      "Catherine Yeh",
      "Gonzalo Ramos",
      "Rachel Ng",
      "Andy Huntington",
      "Richard Banks"
    ],
    "abstract": "Writing is a well-established practice to support ideation and creativity.\nWhile Large Language Models (LLMs) have become ubiquitous in providing\ndifferent kinds of writing assistance to different writers, LLM-powered writing\nsystems often fall short in capturing the nuanced personalization and control\nnecessary for effective support and creative exploration. To address these\nchallenges, we introduce GhostWriter, an AI-enhanced writing design probe that\nenables users to exercise enhanced agency and personalization. GhostWriter\nleverages LLMs to implicitly learn the user's intended writing style for\nseamless personalization, while exposing explicit teaching moments for style\nrefinement and reflection. We study 18 participants who use GhostWriter for\nediting and creative tasks, observing that it helps users craft personalized\ntext and empowers them by providing multiple ways to steer system output. Based\non this study, we present insights on people's relationships with AI-assisted\nwriting and offer design recommendations to promote user agency in similar\nco-creative systems.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "23 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.08855v2",
    "published_date": "2024-02-13 23:48:59 UTC",
    "updated_date": "2025-03-23 19:08:00 UTC"
  },
  {
    "arxiv_id": "2402.08848v2",
    "title": "Hybrid Inverse Reinforcement Learning",
    "authors": [
      "Juntao Ren",
      "Gokul Swamy",
      "Zhiwei Steven Wu",
      "J. Andrew Bagnell",
      "Sanjiban Choudhury"
    ],
    "abstract": "The inverse reinforcement learning approach to imitation learning is a\ndouble-edged sword. On the one hand, it can enable learning from a smaller\nnumber of expert demonstrations with more robustness to error compounding than\nbehavioral cloning approaches. On the other hand, it requires that the learner\nrepeatedly solve a computationally expensive reinforcement learning (RL)\nproblem. Often, much of this computation is wasted searching over policies very\ndissimilar to the expert's. In this work, we propose using hybrid RL --\ntraining on a mixture of online and expert data -- to curtail unnecessary\nexploration. Intuitively, the expert data focuses the learner on good states\nduring training, which reduces the amount of exploration required to compute a\nstrong policy. Notably, such an approach doesn't need the ability to reset the\nlearner to arbitrary states in the environment, a requirement of prior work in\nefficient inverse RL. More formally, we derive a reduction from inverse RL to\nexpert-competitive RL (rather than globally optimal RL) that allows us to\ndramatically reduce interaction during the inner policy search loop while\nmaintaining the benefits of the IRL approach. This allows us to derive both\nmodel-free and model-based hybrid inverse RL algorithms with strong policy\nperformance guarantees. Empirically, we find that our approaches are\nsignificantly more sample efficient than standard inverse RL and several other\nbaselines on a suite of continuous control tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.08848v2",
    "published_date": "2024-02-13 23:29:09 UTC",
    "updated_date": "2024-06-05 00:17:20 UTC"
  },
  {
    "arxiv_id": "2402.08846v1",
    "title": "An Embarrassingly Simple Approach for LLM with Strong ASR Capacity",
    "authors": [
      "Ziyang Ma",
      "Guanrou Yang",
      "Yifan Yang",
      "Zhifu Gao",
      "Jiaming Wang",
      "Zhihao Du",
      "Fan Yu",
      "Qian Chen",
      "Siqi Zheng",
      "Shiliang Zhang",
      "Xie Chen"
    ],
    "abstract": "In this paper, we focus on solving one of the most important tasks in the\nfield of speech processing, i.e., automatic speech recognition (ASR), with\nspeech foundation encoders and large language models (LLM). Recent works have\ncomplex designs such as compressing the output temporally for the speech\nencoder, tackling modal alignment for the projector, and utilizing\nparameter-efficient fine-tuning for the LLM. We found that delicate designs are\nnot necessary, while an embarrassingly simple composition of off-the-shelf\nspeech encoder, LLM, and the only trainable linear projector is competent for\nthe ASR task. To be more specific, we benchmark and explore various\ncombinations of LLMs and speech encoders, leading to the optimal LLM-based ASR\nsystem, which we call SLAM-ASR. The proposed SLAM-ASR provides a clean setup\nand little task-specific design, where only the linear projector is trained. To\nthe best of our knowledge, SLAM-ASR achieves the best performance on the\nLibrispeech benchmark among LLM-based ASR models and even outperforms the\nlatest LLM-based audio-universal model trained on massive pair data. Finally,\nwe explore the capability emergence of LLM-based ASR in the process of modal\nalignment. We hope that our study can facilitate the research on extending LLM\nwith cross-modality capacity and shed light on the LLM-based ASR community.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.MM",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "Working in progress and will open-source soon",
    "pdf_url": "http://arxiv.org/pdf/2402.08846v1",
    "published_date": "2024-02-13 23:25:04 UTC",
    "updated_date": "2024-02-13 23:25:04 UTC"
  },
  {
    "arxiv_id": "2402.08832v1",
    "title": "Intelligent Agricultural Management Considering N$_2$O Emission and Climate Variability with Uncertainties",
    "authors": [
      "Zhaoan Wang",
      "Shaoping Xiao",
      "Jun Wang",
      "Ashwin Parab",
      "Shivam Patel"
    ],
    "abstract": "This study examines how artificial intelligence (AI), especially\nReinforcement Learning (RL), can be used in farming to boost crop yields,\nfine-tune nitrogen use and watering, and reduce nitrate runoff and greenhouse\ngases, focusing on Nitrous Oxide (N$_2$O) emissions from soil. Facing climate\nchange and limited agricultural knowledge, we use Partially Observable Markov\nDecision Processes (POMDPs) with a crop simulator to model AI agents'\ninteractions with farming environments. We apply deep Q-learning with Recurrent\nNeural Network (RNN)-based Q networks for training agents on optimal actions.\nAlso, we develop Machine Learning (ML) models to predict N$_2$O emissions,\nintegrating these predictions into the simulator. Our research tackles\nuncertainties in N$_2$O emission estimates with a probabilistic ML approach and\nclimate variability through a stochastic weather model, offering a range of\nemission outcomes to improve forecast reliability and decision-making. By\nincorporating climate change effects, we enhance agents' climate adaptability,\naiming for resilient agricultural practices. Results show these agents can\nalign crop productivity with environmental concerns by penalizing N$_2$O\nemissions, adapting effectively to climate shifts like warmer temperatures and\nless rain. This strategy improves farm management under climate change,\nhighlighting AI's role in sustainable agriculture.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.08832v1",
    "published_date": "2024-02-13 22:29:40 UTC",
    "updated_date": "2024-02-13 22:29:40 UTC"
  },
  {
    "arxiv_id": "2402.08831v2",
    "title": "eCeLLM: Generalizing Large Language Models for E-commerce from Large-scale, High-quality Instruction Data",
    "authors": [
      "Bo Peng",
      "Xinyi Ling",
      "Ziru Chen",
      "Huan Sun",
      "Xia Ning"
    ],
    "abstract": "With tremendous efforts on developing effective e-commerce models,\nconventional e-commerce models show limited success in generalist e-commerce\nmodeling, and suffer from unsatisfactory performance on new users and new\nproducts - a typical out-of-domain generalization challenge. Meanwhile, large\nlanguage models (LLMs) demonstrate outstanding performance in generalist\nmodeling and out-of-domain generalizability in many fields. Toward fully\nunleashing their power for e-commerce, in this paper, we construct ECInstruct,\nthe first open-sourced, large-scale, and high-quality benchmark instruction\ndataset for e-commerce. Leveraging ECInstruct, we develop eCeLLM, a series of\ne-commerce LLMs, by instruction-tuning general-purpose LLMs. Our comprehensive\nexperiments and evaluation demonstrate that eCeLLM models substantially\noutperform baseline models, including the most advanced GPT-4, and the\nstate-of-the-art task-specific models in in-domain evaluation. Moreover, eCeLLM\nexhibits excellent generalizability to out-of-domain settings, including unseen\nproducts and unseen instructions, highlighting its superiority as a generalist\ne-commerce model. Both the ECInstruct dataset and the eCeLLM models show great\npotential in empowering versatile and effective LLMs for e-commerce. ECInstruct\nand eCeLLM models are publicly accessible through\nhttps://ninglab.github.io/eCeLLM.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "ICML 2024; Bo Peng and Xinyi Ling contributed equally to this paper",
    "pdf_url": "http://arxiv.org/pdf/2402.08831v2",
    "published_date": "2024-02-13 22:26:24 UTC",
    "updated_date": "2024-08-03 23:29:26 UTC"
  },
  {
    "arxiv_id": "2402.08812v3",
    "title": "Intelligent Canvas: Enabling Design-Like Exploratory Visual Data Analysis with Generative AI through Rapid Prototyping, Iteration and Curation",
    "authors": [
      "Zijian Ding",
      "Joel Chan"
    ],
    "abstract": "Complex data analysis inherently seeks unexpected insights through\nexploratory visual analysis methods, transcending logical, step-by-step\nprocessing. However, existing interfaces such as notebooks and dashboards have\nlimitations in exploration and comparison for visual data analysis. Addressing\nthese limitations, we introduce a \"design-like\" intelligent canvas environment\nintegrating generative AI into data analysis, offering rapid prototyping,\niteration, and comparative visualization management. Our dual contributions\ninclude the integration of generative AI components into a canvas interface,\nand empirical findings from a user study (N=10) evaluating the effectiveness of\nthe canvas interface.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.08812v3",
    "published_date": "2024-02-13 21:33:12 UTC",
    "updated_date": "2024-03-21 16:44:41 UTC"
  },
  {
    "arxiv_id": "2402.08806v1",
    "title": "Combining Insights From Multiple Large Language Models Improves Diagnostic Accuracy",
    "authors": [
      "Gioele Barabucci",
      "Victor Shia",
      "Eugene Chu",
      "Benjamin Harack",
      "Nathan Fu"
    ],
    "abstract": "Background: Large language models (LLMs) such as OpenAI's GPT-4 or Google's\nPaLM 2 are proposed as viable diagnostic support tools or even spoken of as\nreplacements for \"curbside consults\". However, even LLMs specifically trained\non medical topics may lack sufficient diagnostic accuracy for real-life\napplications.\n  Methods: Using collective intelligence methods and a dataset of 200 clinical\nvignettes of real-life cases, we assessed and compared the accuracy of\ndifferential diagnoses obtained by asking individual commercial LLMs (OpenAI\nGPT-4, Google PaLM 2, Cohere Command, Meta Llama 2) against the accuracy of\ndifferential diagnoses synthesized by aggregating responses from combinations\nof the same LLMs.\n  Results: We find that aggregating responses from multiple, various LLMs leads\nto more accurate differential diagnoses (average accuracy for 3 LLMs:\n$75.3\\%\\pm 1.6pp$) compared to the differential diagnoses produced by single\nLLMs (average accuracy for single LLMs: $59.0\\%\\pm 6.1pp$).\n  Discussion: The use of collective intelligence methods to synthesize\ndifferential diagnoses combining the responses of different LLMs achieves two\nof the necessary steps towards advancing acceptance of LLMs as a diagnostic\nsupport tool: (1) demonstrate high diagnostic accuracy and (2) eliminate\ndependence on a single commercial vendor.",
    "categories": [
      "cs.AI",
      "I.2.1; J.3"
    ],
    "primary_category": "cs.AI",
    "comment": "5 pages, 2 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2402.08806v1",
    "published_date": "2024-02-13 21:24:21 UTC",
    "updated_date": "2024-02-13 21:24:21 UTC"
  },
  {
    "arxiv_id": "2402.08801v1",
    "title": "ChatGPT vs LLaMA: Impact, Reliability, and Challenges in Stack Overflow Discussions",
    "authors": [
      "Leuson Da Silva",
      "Jordan Samhi",
      "Foutse Khomh"
    ],
    "abstract": "Since its release in November 2022, ChatGPT has shaken up Stack Overflow, the\npremier platform for developers' queries on programming and software\ndevelopment. Demonstrating an ability to generate instant, human-like responses\nto technical questions, ChatGPT has ignited debates within the developer\ncommunity about the evolving role of human-driven platforms in the age of\ngenerative AI. Two months after ChatGPT's release, Meta released its answer\nwith its own Large Language Model (LLM) called LLaMA: the race was on. We\nconducted an empirical study analyzing questions from Stack Overflow and using\nthese LLMs to address them. This way, we aim to (ii) measure user engagement\nevolution with Stack Overflow over time; (ii) quantify the reliability of LLMs'\nanswers and their potential to replace Stack Overflow in the long term; (iii)\nidentify and understand why LLMs fails; and (iv) compare LLMs together. Our\nempirical results are unequivocal: ChatGPT and LLaMA challenge human expertise,\nyet do not outperform it for some domains, while a significant decline in user\nposting activity has been observed. Furthermore, we also discuss the impact of\nour findings regarding the usage and development of new LLMs.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "36 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.08801v1",
    "published_date": "2024-02-13 21:15:33 UTC",
    "updated_date": "2024-02-13 21:15:33 UTC"
  },
  {
    "arxiv_id": "2402.08789v1",
    "title": "Leveraging cough sounds to optimize chest x-ray usage in low-resource settings",
    "authors": [
      "Alexander Philip",
      "Sanya Chawla",
      "Lola Jover",
      "George P. Kafentzis",
      "Joe Brew",
      "Vishakh Saraf",
      "Shibu Vijayan",
      "Peter Small",
      "Carlos Chaccour"
    ],
    "abstract": "Chest X-ray is a commonly used tool during triage, diagnosis and management\nof respiratory diseases. In resource-constricted settings, optimizing this\nresource can lead to valuable cost savings for the health care system and the\npatients as well as to and improvement in consult time. We used\nprospectively-collected data from 137 patients referred for chest X-ray at the\nChristian Medical Center and Hospital (CMCH) in Purnia, Bihar, India. Each\npatient provided at least five coughs while awaiting radiography. Collected\ncough sounds were analyzed using acoustic AI methods. Cross-validation was done\non temporal and spectral features on the cough sounds of each patient. Features\nwere summarized using standard statistical approaches. Three models were\ndeveloped, tested and compared in their capacity to predict an abnormal result\nin the chest X-ray. All three methods yielded models that could discriminate to\nsome extent between normal and abnormal with the logistic regression performing\nbest with an area under the receiver operating characteristic curves ranging\nfrom 0.7 to 0.78. Despite limitations and its relatively small sample size,\nthis study shows that AI-enabled algorithms can use cough sounds to predict\nwhich individuals presenting for chest radiographic examination will have a\nnormal or abnormal results. These results call for expanding this research\ngiven the potential optimization of limited health care resources in low- and\nmiddle-income countries.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.LG",
      "q-bio.QM"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.08789v1",
    "published_date": "2024-02-13 20:54:55 UTC",
    "updated_date": "2024-02-13 20:54:55 UTC"
  },
  {
    "arxiv_id": "2402.08780v1",
    "title": "Enhanced Deep Q-Learning for 2D Self-Driving Cars: Implementation and Evaluation on a Custom Track Environment",
    "authors": [
      "Sagar Pathak",
      "Bidhya Shrestha",
      "Kritish Pahi"
    ],
    "abstract": "This research project presents the implementation of a Deep Q-Learning\nNetwork (DQN) for a self-driving car on a 2-dimensional (2D) custom track, with\nthe objective of enhancing the DQN network's performance. It encompasses the\ndevelopment of a custom driving environment using Pygame on a track surrounding\nthe University of Memphis map, as well as the design and implementation of the\nDQN model. The algorithm utilizes data from 7 sensors installed in the car,\nwhich measure the distance between the car and the track. These sensors are\npositioned in front of the vehicle, spaced 20 degrees apart, enabling them to\nsense a wide area ahead. We successfully implemented the DQN and also a\nmodified version of the DQN with a priority-based action selection mechanism,\nwhich we refer to as modified DQN. The model was trained over 1000 episodes,\nand the average reward received by the agent was found to be around 40, which\nis approximately 60% higher than the original DQN and around 50% higher than\nthe vanilla neural network.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.08780v1",
    "published_date": "2024-02-13 20:29:36 UTC",
    "updated_date": "2024-02-13 20:29:36 UTC"
  },
  {
    "arxiv_id": "2402.08777v3",
    "title": "DNABERT-S: Pioneering Species Differentiation with Species-Aware DNA Embeddings",
    "authors": [
      "Zhihan Zhou",
      "Weimin Wu",
      "Harrison Ho",
      "Jiayi Wang",
      "Lizhen Shi",
      "Ramana V Davuluri",
      "Zhong Wang",
      "Han Liu"
    ],
    "abstract": "We introduce DNABERT-S, a tailored genome model that develops species-aware\nembeddings to naturally cluster and segregate DNA sequences of different\nspecies in the embedding space. Differentiating species from genomic sequences\n(i.e., DNA and RNA) is vital yet challenging, since many real-world species\nremain uncharacterized, lacking known genomes for reference. Embedding-based\nmethods are therefore used to differentiate species in an unsupervised manner.\nDNABERT-S builds upon a pre-trained genome foundation model named DNABERT-2. To\nencourage effective embeddings to error-prone long-read DNA sequences, we\nintroduce Manifold Instance Mixup (MI-Mix), a contrastive objective that mixes\nthe hidden representations of DNA sequences at randomly selected layers and\ntrains the model to recognize and differentiate these mixed proportions at the\noutput layer. We further enhance it with the proposed Curriculum Contrastive\nLearning (C$^2$LR) strategy. Empirical results on 23 diverse datasets show\nDNABERT-S's effectiveness, especially in realistic label-scarce scenarios. For\nexample, it identifies twice more species from a mixture of unlabeled genomic\nsequences, doubles the Adjusted Rand Index (ARI) in species clustering, and\noutperforms the top baseline's performance in 10-shot species classification\nwith just a 2-shot training. Model, codes, and data are publicly available at\n\\url{https://github.com/MAGICS-LAB/DNABERT_S}.",
    "categories": [
      "q-bio.GN",
      "cs.AI",
      "cs.CE",
      "cs.CL"
    ],
    "primary_category": "q-bio.GN",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.08777v3",
    "published_date": "2024-02-13 20:21:29 UTC",
    "updated_date": "2024-10-22 04:14:08 UTC"
  },
  {
    "arxiv_id": "2402.10962v4",
    "title": "Measuring and Controlling Instruction (In)Stability in Language Model Dialogs",
    "authors": [
      "Kenneth Li",
      "Tianle Liu",
      "Naomi Bashkansky",
      "David Bau",
      "Fernanda Viégas",
      "Hanspeter Pfister",
      "Martin Wattenberg"
    ],
    "abstract": "System-prompting is a standard tool for customizing language-model chatbots,\nenabling them to follow a specific instruction. An implicit assumption in the\nuse of system prompts is that they will be stable, so the chatbot will continue\nto generate text according to the stipulated instructions for the duration of a\nconversation. We propose a quantitative benchmark to test this assumption,\nevaluating instruction stability via self-chats between two instructed\nchatbots. Testing popular models like LLaMA2-chat-70B and GPT-3.5, we reveal a\nsignificant instruction drift within eight rounds of conversations. An\nempirical and theoretical analysis of this phenomenon suggests the transformer\nattention mechanism plays a role, due to attention decay over long exchanges.\nTo combat attention decay and instruction drift, we propose a lightweight\nmethod called split-softmax, which compares favorably against two strong\nbaselines.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "COLM 2024; Code and data: https://github.com/likenneth/persona_drift",
    "pdf_url": "http://arxiv.org/pdf/2402.10962v4",
    "published_date": "2024-02-13 20:10:29 UTC",
    "updated_date": "2024-07-25 18:58:51 UTC"
  },
  {
    "arxiv_id": "2402.08772v3",
    "title": "Optimal Task Assignment and Path Planning using Conflict-Based Search with Precedence and Temporal Constraints",
    "authors": [
      "Yu Quan Chong",
      "Jiaoyang Li",
      "Katia Sycara"
    ],
    "abstract": "The Multi-Agent Path Finding (MAPF) problem entails finding collision-free\npaths for a set of agents, guiding them from their start to goal locations.\nHowever, MAPF does not account for several practical task-related constraints.\nFor example, agents may need to perform actions at goal locations with specific\nexecution times, adhering to predetermined orders and timeframes. Moreover,\ngoal assignments may not be predefined for agents, and the optimization\nobjective may lack an explicit definition. To incorporate task assignment, path\nplanning, and a user-defined objective into a coherent framework, this paper\nexamines the Task Assignment and Path Finding with Precedence and Temporal\nConstraints (TAPF-PTC) problem. We augment Conflict-Based Search (CBS) to\nsimultaneously generate task assignments and collision-free paths that adhere\nto precedence and temporal constraints, maximizing an objective quantified by\nthe return from a user-defined reward function in reinforcement learning (RL).\nExperimentally, we demonstrate that our algorithm, CBS-TA-PTC, can solve highly\nchallenging bomb-defusing tasks with precedence and temporal constraints\nefficiently relative to MARL and adapted Target Assignment and Path Finding\n(TAPF) methods.",
    "categories": [
      "cs.AI",
      "cs.MA",
      "I.2.11"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.08772v3",
    "published_date": "2024-02-13 20:07:58 UTC",
    "updated_date": "2024-04-22 00:46:34 UTC"
  },
  {
    "arxiv_id": "2402.08761v1",
    "title": "JAMDEC: Unsupervised Authorship Obfuscation using Constrained Decoding over Small Language Models",
    "authors": [
      "Jillian Fisher",
      "Ximing Lu",
      "Jaehun Jung",
      "Liwei Jiang",
      "Zaid Harchaoui",
      "Yejin Choi"
    ],
    "abstract": "The permanence of online content combined with the enhanced authorship\nidentification techniques calls for stronger computational methods to protect\nthe identity and privacy of online authorship when needed, e.g., blind reviews\nfor scientific papers, anonymous online reviews, or anonymous interactions in\nthe mental health forums. In this paper, we propose an unsupervised\ninference-time approach to authorship obfuscation to address the unique\nchallenges of authorship obfuscation: lack of supervision data for diverse\nauthorship and domains, and the need for a sufficient level of revision beyond\nsimple paraphrasing to obfuscate the authorship, all the while preserving the\noriginal content and fluency.\n  We introduce JAMDEC, a user-controlled, inference-time algorithm for\nauthorship obfuscation that can be in principle applied to any text and\nauthorship. Our approach builds on small language models such as GPT2-XL in\norder to help avoid disclosing the original content to proprietary LLM's APIs,\nwhile also reducing the performance gap between small and large language models\nvia algorithmic enhancement. The key idea behind our approach is to boost the\ncreative power of smaller language models through constrained decoding, while\nalso allowing for user-specified controls and flexibility. Experimental results\ndemonstrate that our approach based on GPT2-XL outperforms previous\nstate-of-the-art methods based on comparably small models, while performing\ncompetitively against GPT3.5 175B, a propriety model that is two orders of\nmagnitudes larger.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Code is available at https://github.com/jfisher52/JAMDecoding",
    "pdf_url": "http://arxiv.org/pdf/2402.08761v1",
    "published_date": "2024-02-13 19:54:29 UTC",
    "updated_date": "2024-02-13 19:54:29 UTC"
  },
  {
    "arxiv_id": "2402.08755v1",
    "title": "LLM-driven Imitation of Subrational Behavior : Illusion or Reality?",
    "authors": [
      "Andrea Coletta",
      "Kshama Dwarakanath",
      "Penghang Liu",
      "Svitlana Vyetrenko",
      "Tucker Balch"
    ],
    "abstract": "Modeling subrational agents, such as humans or economic households, is\ninherently challenging due to the difficulty in calibrating reinforcement\nlearning models or collecting data that involves human subjects. Existing work\nhighlights the ability of Large Language Models (LLMs) to address complex\nreasoning tasks and mimic human communication, while simulation using LLMs as\nagents shows emergent social behaviors, potentially improving our comprehension\nof human conduct. In this paper, we propose to investigate the use of LLMs to\ngenerate synthetic human demonstrations, which are then used to learn\nsubrational agent policies though Imitation Learning. We make an assumption\nthat LLMs can be used as implicit computational models of humans, and propose a\nframework to use synthetic demonstrations derived from LLMs to model\nsubrational behaviors that are characteristic of humans (e.g., myopic behavior\nor preference for risk aversion). We experimentally evaluate the ability of our\nframework to model sub-rationality through four simple scenarios, including the\nwell-researched ultimatum game and marshmallow experiment. To gain confidence\nin our framework, we are able to replicate well-established findings from prior\nhuman studies associated with the above scenarios. We conclude by discussing\nthe potential benefits, challenges and limitations of our framework.",
    "categories": [
      "cs.AI",
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.08755v1",
    "published_date": "2024-02-13 19:46:39 UTC",
    "updated_date": "2024-02-13 19:46:39 UTC"
  },
  {
    "arxiv_id": "2402.08682v1",
    "title": "IM-3D: Iterative Multiview Diffusion and Reconstruction for High-Quality 3D Generation",
    "authors": [
      "Luke Melas-Kyriazi",
      "Iro Laina",
      "Christian Rupprecht",
      "Natalia Neverova",
      "Andrea Vedaldi",
      "Oran Gafni",
      "Filippos Kokkinos"
    ],
    "abstract": "Most text-to-3D generators build upon off-the-shelf text-to-image models\ntrained on billions of images. They use variants of Score Distillation Sampling\n(SDS), which is slow, somewhat unstable, and prone to artifacts. A mitigation\nis to fine-tune the 2D generator to be multi-view aware, which can help\ndistillation or can be combined with reconstruction networks to output 3D\nobjects directly. In this paper, we further explore the design space of\ntext-to-3D models. We significantly improve multi-view generation by\nconsidering video instead of image generators. Combined with a 3D\nreconstruction algorithm which, by using Gaussian splatting, can optimize a\nrobust image-based loss, we directly produce high-quality 3D outputs from the\ngenerated views. Our new method, IM-3D, reduces the number of evaluations of\nthe 2D generator network 10-100x, resulting in a much more efficient pipeline,\nbetter quality, fewer geometric inconsistencies, and higher yield of usable 3D\nassets.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.08682v1",
    "published_date": "2024-02-13 18:59:51 UTC",
    "updated_date": "2024-02-13 18:59:51 UTC"
  },
  {
    "arxiv_id": "2402.08680v1",
    "title": "Mitigating Object Hallucination in Large Vision-Language Models via Classifier-Free Guidance",
    "authors": [
      "Linxi Zhao",
      "Yihe Deng",
      "Weitong Zhang",
      "Quanquan Gu"
    ],
    "abstract": "The advancement of Large Vision-Language Models (LVLMs) has increasingly\nhighlighted the critical issue of their tendency to hallucinate non-existing\nobjects in the images. To address this issue, previous works focused on using\nspecially curated datasets or powerful LLMs (e.g., GPT-3.5) to rectify the\noutputs of LVLMs. However, these approaches require either expensive\ntraining/fine-tuning or API access to advanced LLMs to correct the model's\noutput post-generation. In this paper, we tackle this challenge by introducing\na framework called Mitigating hallucinAtion via classifieR-Free guIdaNcE\n(MARINE), which is both training-free and API-free, and can effectively and\nefficiently reduce object hallucinations during the generation process.\nSpecifically, MARINE enriches the visual context of LVLMs by integrating\nexisting open-source vision models, and employs classifier-free guidance to\nincorporate the additional object grounding features to improve the precision\nof LVLMs' generations. Through comprehensive evaluations across $6$ popular\nLVLMs with diverse evaluation metrics, we demonstrate the effectiveness of\nMARINE, which even outperforms existing fine-tuning-based methods. Remarkably,\nit not only reduces hallucinations but also improves the detailedness of LVLMs'\ngenerations, as assessed by GPT-4V.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "27 pages, 20 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2402.08680v1",
    "published_date": "2024-02-13 18:59:05 UTC",
    "updated_date": "2024-02-13 18:59:05 UTC"
  },
  {
    "arxiv_id": "2402.08679v2",
    "title": "COLD-Attack: Jailbreaking LLMs with Stealthiness and Controllability",
    "authors": [
      "Xingang Guo",
      "Fangxu Yu",
      "Huan Zhang",
      "Lianhui Qin",
      "Bin Hu"
    ],
    "abstract": "Jailbreaks on large language models (LLMs) have recently received increasing\nattention. For a comprehensive assessment of LLM safety, it is essential to\nconsider jailbreaks with diverse attributes, such as contextual coherence and\nsentiment/stylistic variations, and hence it is beneficial to study\ncontrollable jailbreaking, i.e. how to enforce control on LLM attacks. In this\npaper, we formally formulate the controllable attack generation problem, and\nbuild a novel connection between this problem and controllable text generation,\na well-explored topic of natural language processing. Based on this connection,\nwe adapt the Energy-based Constrained Decoding with Langevin Dynamics (COLD), a\nstate-of-the-art, highly efficient algorithm in controllable text generation,\nand introduce the COLD-Attack framework which unifies and automates the search\nof adversarial LLM attacks under a variety of control requirements such as\nfluency, stealthiness, sentiment, and left-right-coherence. The controllability\nenabled by COLD-Attack leads to diverse new jailbreak scenarios which not only\ncover the standard setting of generating fluent (suffix) attack with\ncontinuation constraint, but also allow us to address new controllable attack\nsettings such as revising a user query adversarially with paraphrasing\nconstraint, and inserting stealthy attacks in context with position constraint.\nOur extensive experiments on various LLMs (Llama-2, Mistral, Vicuna, Guanaco,\nGPT-3.5, and GPT-4) show COLD-Attack's broad applicability, strong\ncontrollability, high success rate, and attack transferability. Our code is\navailable at https://github.com/Yu-Fangxu/COLD-Attack.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.08679v2",
    "published_date": "2024-02-13 18:58:48 UTC",
    "updated_date": "2024-06-07 00:13:08 UTC"
  },
  {
    "arxiv_id": "2402.08714v2",
    "title": "PRDP: Proximal Reward Difference Prediction for Large-Scale Reward Finetuning of Diffusion Models",
    "authors": [
      "Fei Deng",
      "Qifei Wang",
      "Wei Wei",
      "Matthias Grundmann",
      "Tingbo Hou"
    ],
    "abstract": "Reward finetuning has emerged as a promising approach to aligning foundation\nmodels with downstream objectives. Remarkable success has been achieved in the\nlanguage domain by using reinforcement learning (RL) to maximize rewards that\nreflect human preference. However, in the vision domain, existing RL-based\nreward finetuning methods are limited by their instability in large-scale\ntraining, rendering them incapable of generalizing to complex, unseen prompts.\nIn this paper, we propose Proximal Reward Difference Prediction (PRDP),\nenabling stable black-box reward finetuning for diffusion models for the first\ntime on large-scale prompt datasets with over 100K prompts. Our key innovation\nis the Reward Difference Prediction (RDP) objective that has the same optimal\nsolution as the RL objective while enjoying better training stability.\nSpecifically, the RDP objective is a supervised regression objective that tasks\nthe diffusion model with predicting the reward difference of generated image\npairs from their denoising trajectories. We theoretically prove that the\ndiffusion model that obtains perfect reward difference prediction is exactly\nthe maximizer of the RL objective. We further develop an online algorithm with\nproximal updates to stably optimize the RDP objective. In experiments, we\ndemonstrate that PRDP can match the reward maximization ability of\nwell-established RL-based methods in small-scale training. Furthermore, through\nlarge-scale training on text prompts from the Human Preference Dataset v2 and\nthe Pick-a-Pic v1 dataset, PRDP achieves superior generation quality on a\ndiverse set of complex, unseen prompts whereas RL-based methods completely\nfail.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "CVPR 2024. Project page: https://fdeng18.github.io/prdp",
    "pdf_url": "http://arxiv.org/pdf/2402.08714v2",
    "published_date": "2024-02-13 18:58:16 UTC",
    "updated_date": "2024-03-27 21:37:39 UTC"
  },
  {
    "arxiv_id": "2402.08672v2",
    "title": "Model Assessment and Selection under Temporal Distribution Shift",
    "authors": [
      "Elise Han",
      "Chengpiao Huang",
      "Kaizheng Wang"
    ],
    "abstract": "We investigate model assessment and selection in a changing environment, by\nsynthesizing datasets from both the current time period and historical epochs.\nTo tackle unknown and potentially arbitrary temporal distribution shift, we\ndevelop an adaptive rolling window approach to estimate the generalization\nerror of a given model. This strategy also facilitates the comparison between\nany two candidate models by estimating the difference of their generalization\nerrors. We further integrate pairwise comparisons into a single-elimination\ntournament, achieving near-optimal model selection from a collection of\ncandidates. Theoretical analyses and numerical experiments demonstrate the\nadaptivity of our proposed methods to the non-stationarity in data.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ME",
      "62G05 (Primary), 62J02 (Secondary)"
    ],
    "primary_category": "cs.LG",
    "comment": "26 pages, 6 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2402.08672v2",
    "published_date": "2024-02-13 18:54:08 UTC",
    "updated_date": "2024-06-03 22:30:38 UTC"
  },
  {
    "arxiv_id": "2402.08671v3",
    "title": "Are Semi-Dense Detector-Free Methods Good at Matching Local Features?",
    "authors": [
      "Matthieu Vilain",
      "Rémi Giraud",
      "Hugo Germain",
      "Guillaume Bourmaud"
    ],
    "abstract": "Semi-dense detector-free approaches (SDF), such as LoFTR, are currently among\nthe most popular image matching methods. While SDF methods are trained to\nestablish correspondences between two images, their performances are almost\nexclusively evaluated using relative pose estimation metrics. Thus, the link\nbetween their ability to establish correspondences and the quality of the\nresulting estimated pose has thus far received little attention. This paper is\na first attempt to study this link. We start with proposing a novel structured\nattention-based image matching architecture (SAM). It allows us to show a\ncounter-intuitive result on two datasets (MegaDepth and HPatches): on the one\nhand SAM either outperforms or is on par with SDF methods in terms of\npose/homography estimation metrics, but on the other hand SDF approaches are\nsignificantly better than SAM in terms of matching accuracy. We then propose to\nlimit the computation of the matching accuracy to textured regions, and show\nthat in this case SAM often surpasses SDF methods. Our findings highlight a\nstrong correlation between the ability to establish accurate correspondences in\ntextured regions and the accuracy of the resulting estimated pose/homography.\nOur code will be made available.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.08671v3",
    "published_date": "2024-02-13 18:53:13 UTC",
    "updated_date": "2024-06-01 11:34:13 UTC"
  },
  {
    "arxiv_id": "2402.08670v1",
    "title": "Rec-GPT4V: Multimodal Recommendation with Large Vision-Language Models",
    "authors": [
      "Yuqing Liu",
      "Yu Wang",
      "Lichao Sun",
      "Philip S. Yu"
    ],
    "abstract": "The development of large vision-language models (LVLMs) offers the potential\nto address challenges faced by traditional multimodal recommendations thanks to\ntheir proficient understanding of static images and textual dynamics. However,\nthe application of LVLMs in this field is still limited due to the following\ncomplexities: First, LVLMs lack user preference knowledge as they are trained\nfrom vast general datasets. Second, LVLMs suffer setbacks in addressing\nmultiple image dynamics in scenarios involving discrete, noisy, and redundant\nimage sequences. To overcome these issues, we propose the novel reasoning\nscheme named Rec-GPT4V: Visual-Summary Thought (VST) of leveraging large\nvision-language models for multimodal recommendation. We utilize user history\nas in-context user preferences to address the first challenge. Next, we prompt\nLVLMs to generate item image summaries and utilize image comprehension in\nnatural language space combined with item titles to query the user preferences\nover candidate items. We conduct comprehensive experiments across four datasets\nwith three LVLMs: GPT4-V, LLaVa-7b, and LLaVa-13b. The numerical results\nindicate the efficacy of VST.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "under review",
    "pdf_url": "http://arxiv.org/pdf/2402.08670v1",
    "published_date": "2024-02-13 18:51:18 UTC",
    "updated_date": "2024-02-13 18:51:18 UTC"
  },
  {
    "arxiv_id": "2402.08658v3",
    "title": "The Last JITAI? Exploring Large Language Models for Issuing Just-in-Time Adaptive Interventions: Fostering Physical Activity in a Conceptual Cardiac Rehabilitation Setting",
    "authors": [
      "David Haag",
      "Devender Kumar",
      "Sebastian Gruber",
      "Dominik Hofer",
      "Mahdi Sareban",
      "Gunnar Treff",
      "Josef Niebauer",
      "Christopher Bull",
      "Albrecht Schmidt",
      "Jan David Smeddinck"
    ],
    "abstract": "We evaluated the viability of using Large Language Models (LLMs) to trigger\nand personalize content in Just-in-Time Adaptive Interventions (JITAIs) in\ndigital health. As an interaction pattern representative of context-aware\ncomputing, JITAIs are being explored for their potential to support sustainable\nbehavior change, adapting interventions to an individual's current context and\nneeds. Challenging traditional JITAI implementation models, which face severe\nscalability and flexibility limitations, we tested GPT-4 for suggesting JITAIs\nin the use case of heart-healthy activity in cardiac rehabilitation. Using\nthree personas representing patients affected by CVD with varying severeness\nand five context sets per persona, we generated 450 JITAI decisions and\nmessages. These were systematically evaluated against those created by 10\nlaypersons (LayPs) and 10 healthcare professionals (HCPs). GPT-4-generated\nJITAIs surpassed human-generated intervention suggestions, outperforming both\nLayPs and HCPs across all metrics (i.e., appropriateness, engagement,\neffectiveness, and professionalism). These results highlight the potential of\nLLMs to enhance JITAI implementations in personalized health interventions,\ndemonstrating how generative AI could revolutionize context-aware computing.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "J.3"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.08658v3",
    "published_date": "2024-02-13 18:39:36 UTC",
    "updated_date": "2025-02-26 08:57:38 UTC"
  },
  {
    "arxiv_id": "2402.08653v4",
    "title": "SAGMAN: Stability Analysis of Graph Neural Networks on the Manifolds",
    "authors": [
      "Wuxinlin Cheng",
      "Chenhui Deng",
      "Ali Aghdaei",
      "Zhiru Zhang",
      "Zhuo Feng"
    ],
    "abstract": "Modern graph neural networks (GNNs) can be sensitive to changes in the input\ngraph structure and node features, potentially resulting in unpredictable\nbehavior and degraded performance. In this work, we introduce a spectral\nframework known as SAGMAN for examining the stability of GNNs. This framework\nassesses the distance distortions that arise from the nonlinear mappings of\nGNNs between the input and output manifolds: when two nearby nodes on the input\nmanifold are mapped (through a GNN model) to two distant ones on the output\nmanifold, it implies a large distance distortion and thus a poor GNN stability.\nWe propose a distance-preserving graph dimension reduction (GDR) approach that\nutilizes spectral graph embedding and probabilistic graphical models (PGMs) to\ncreate low-dimensional input/output graph-based manifolds for meaningful\nstability analysis. Our empirical evaluations show that SAGMAN effectively\nassesses the stability of each node when subjected to various edge or feature\nperturbations, offering a scalable approach for evaluating the stability of\nGNNs, extending to applications within recommendation systems. Furthermore, we\nillustrate its utility in downstream tasks, notably in enhancing GNN stability\nand facilitating adversarial targeted attacks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.08653v4",
    "published_date": "2024-02-13 18:33:45 UTC",
    "updated_date": "2024-10-09 16:51:02 UTC"
  },
  {
    "arxiv_id": "2402.08648v1",
    "title": "Generating Universal Adversarial Perturbations for Quantum Classifiers",
    "authors": [
      "Gautham Anil",
      "Vishnu Vinod",
      "Apurva Narayan"
    ],
    "abstract": "Quantum Machine Learning (QML) has emerged as a promising field of research,\naiming to leverage the capabilities of quantum computing to enhance existing\nmachine learning methodologies. Recent studies have revealed that, like their\nclassical counterparts, QML models based on Parametrized Quantum Circuits\n(PQCs) are also vulnerable to adversarial attacks. Moreover, the existence of\nUniversal Adversarial Perturbations (UAPs) in the quantum domain has been\ndemonstrated theoretically in the context of quantum classifiers. In this work,\nwe introduce QuGAP: a novel framework for generating UAPs for quantum\nclassifiers. We conceptualize the notion of additive UAPs for PQC-based\nclassifiers and theoretically demonstrate their existence. We then utilize\ngenerative models (QuGAP-A) to craft additive UAPs and experimentally show that\nquantum classifiers are susceptible to such attacks. Moreover, we formulate a\nnew method for generating unitary UAPs (QuGAP-U) using quantum generative\nmodels and a novel loss function based on fidelity constraints. We evaluate the\nperformance of the proposed framework and show that our method achieves\nstate-of-the-art misclassification rates, while maintaining high fidelity\nbetween legitimate and adversarial samples.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at AAAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.08648v1",
    "published_date": "2024-02-13 18:27:53 UTC",
    "updated_date": "2024-02-13 18:27:53 UTC"
  },
  {
    "arxiv_id": "2402.08646v1",
    "title": "Inference of Abstraction for a Unified Account of Symbolic Reasoning from Data",
    "authors": [
      "Hiroyuki Kido"
    ],
    "abstract": "Inspired by empirical work in neuroscience for Bayesian approaches to brain\nfunction, we give a unified probabilistic account of various types of symbolic\nreasoning from data. We characterise them in terms of formal logic using the\nclassical consequence relation, an empirical consequence relation, maximal\nconsistent sets, maximal possible sets and maximum likelihood estimation. The\ntheory gives new insights into reasoning towards human-like machine\nintelligence.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.08646v1",
    "published_date": "2024-02-13 18:24:23 UTC",
    "updated_date": "2024-02-13 18:24:23 UTC"
  },
  {
    "arxiv_id": "2402.08644v4",
    "title": "Tandem Transformers for Inference Efficient LLMs",
    "authors": [
      "Aishwarya P S",
      "Pranav Ajit Nair",
      "Yashas Samaga",
      "Toby Boyd",
      "Sanjiv Kumar",
      "Prateek Jain",
      "Praneeth Netrapalli"
    ],
    "abstract": "The autoregressive nature of conventional large language models (LLMs)\ninherently limits inference speed, as tokens are generated sequentially. While\nspeculative and parallel decoding techniques attempt to mitigate this, they\nface limitations: either relying on less accurate smaller models for generation\nor failing to fully leverage the base LLM's representations.\n  We introduce a novel architecture, Tandem transformers, to address these\nissues. This architecture uniquely combines (1) a small autoregressive model\nand (2) a large model operating in block mode (processing multiple tokens\nsimultaneously). The small model's predictive accuracy is substantially\nenhanced by granting it attention to the large model's richer representations.\nOn the PaLM2 pretraining dataset, a tandem of PaLM2-Bison and PaLM2-Gecko\ndemonstrates a 3.3% improvement in next-token prediction accuracy over a\nstandalone PaLM2-Gecko, offering a 1.16x speedup compared to a PaLM2-Otter\nmodel with comparable downstream performance. We further incorporate the tandem\nmodel within the speculative decoding (SPEED) framework where the large model\nvalidates tokens from the small model. This ensures that the Tandem of\nPaLM2-Bison and PaLM2-Gecko achieves substantial speedup (around 1.14x faster\nthan using vanilla PaLM2-Gecko in SPEED) while maintaining identical downstream\ntask accuracy.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.08644v4",
    "published_date": "2024-02-13 18:24:08 UTC",
    "updated_date": "2024-10-20 15:34:16 UTC"
  },
  {
    "arxiv_id": "2402.08640v3",
    "title": "Forecasting high-impact research topics via machine learning on evolving knowledge graphs",
    "authors": [
      "Xuemei Gu",
      "Mario Krenn"
    ],
    "abstract": "The exponential growth in scientific publications poses a severe challenge\nfor human researchers. It forces attention to more narrow sub-fields, which\nmakes it challenging to discover new impactful research ideas and\ncollaborations outside one's own field. While there are ways to predict a\nscientific paper's future citation counts, they need the research to be\nfinished and the paper written, usually assessing impact long after the idea\nwas conceived. Here we show how to predict the impact of onsets of ideas that\nhave never been published by researchers. For that, we developed a large\nevolving knowledge graph built from more than 21 million scientific papers. It\ncombines a semantic network created from the content of the papers and an\nimpact network created from the historic citations of papers. Using machine\nlearning, we can predict the dynamic of the evolving network into the future\nwith high accuracy (AUC values beyond 0.9 for most experiments), and thereby\nthe impact of new research directions. We envision that the ability to predict\nthe impact of new ideas will be a crucial component of future artificial muses\nthat can inspire new impactful and interesting scientific ideas.",
    "categories": [
      "cs.DL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DL",
    "comment": "13 pages, 12 figures, Comments welcome!",
    "pdf_url": "http://arxiv.org/pdf/2402.08640v3",
    "published_date": "2024-02-13 18:09:38 UTC",
    "updated_date": "2025-01-07 21:19:30 UTC"
  },
  {
    "arxiv_id": "2402.08631v2",
    "title": "Knowledge Editing on Black-box Large Language Models",
    "authors": [
      "Xiaoshuai Song",
      "Zhengyang Wang",
      "Keqing He",
      "Guanting Dong",
      "Yutao Mou",
      "Jinxu Zhao",
      "Weiran Xu"
    ],
    "abstract": "Knowledge editing (KE) aims to efficiently and precisely modify the behavior\nof large language models (LLMs) to update specific knowledge without negatively\ninfluencing other knowledge. Current research primarily focuses on white-box\nLLMs editing, overlooking an important scenario: black-box LLMs editing, where\nLLMs are accessed through interfaces and only textual output is available. In\nthis paper, we first officially introduce KE on black-box LLMs and then propose\na comprehensive evaluation framework to overcome the limitations of existing\nevaluations that are not applicable to black-box LLMs editing and lack\ncomprehensiveness. To tackle privacy leaks of editing data and style\nover-editing in current methods, we introduce a novel postEdit framework,\nresolving privacy concerns through downstream post-processing and maintaining\ntextual style consistency via fine-grained editing to original responses.\nExperiments and analysis on two benchmarks demonstrate that postEdit\noutperforms all baselines and achieves strong generalization, especially with\nhuge improvements on style retention (average $+20.82\\%\\uparrow$).",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Work in progress",
    "pdf_url": "http://arxiv.org/pdf/2402.08631v2",
    "published_date": "2024-02-13 17:59:34 UTC",
    "updated_date": "2024-02-17 16:06:10 UTC"
  },
  {
    "arxiv_id": "2402.08609v3",
    "title": "Mixtures of Experts Unlock Parameter Scaling for Deep RL",
    "authors": [
      "Johan Obando-Ceron",
      "Ghada Sokar",
      "Timon Willi",
      "Clare Lyle",
      "Jesse Farebrother",
      "Jakob Foerster",
      "Gintare Karolina Dziugaite",
      "Doina Precup",
      "Pablo Samuel Castro"
    ],
    "abstract": "The recent rapid progress in (self) supervised learning models is in large\npart predicted by empirical scaling laws: a model's performance scales\nproportionally to its size. Analogous scaling laws remain elusive for\nreinforcement learning domains, however, where increasing the parameter count\nof a model often hurts its final performance. In this paper, we demonstrate\nthat incorporating Mixture-of-Expert (MoE) modules, and in particular Soft MoEs\n(Puigcerver et al., 2023), into value-based networks results in more\nparameter-scalable models, evidenced by substantial performance increases\nacross a variety of training regimes and model sizes. This work thus provides\nstrong empirical evidence towards developing scaling laws for reinforcement\nlearning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.08609v3",
    "published_date": "2024-02-13 17:18:56 UTC",
    "updated_date": "2024-06-26 16:50:01 UTC"
  },
  {
    "arxiv_id": "2402.08703v2",
    "title": "A Survey of Generative AI for de novo Drug Design: New Frontiers in Molecule and Protein Generation",
    "authors": [
      "Xiangru Tang",
      "Howard Dai",
      "Elizabeth Knight",
      "Fang Wu",
      "Yunyang Li",
      "Tianxiao Li",
      "Mark Gerstein"
    ],
    "abstract": "Artificial intelligence (AI)-driven methods can vastly improve the\nhistorically costly drug design process, with various generative models already\nin widespread use. Generative models for de novo drug design, in particular,\nfocus on the creation of novel biological compounds entirely from scratch,\nrepresenting a promising future direction. Rapid development in the field,\ncombined with the inherent complexity of the drug design process, creates a\ndifficult landscape for new researchers to enter. In this survey, we organize\nde novo drug design into two overarching themes: small molecule and protein\ngeneration. Within each theme, we identify a variety of subtasks and\napplications, highlighting important datasets, benchmarks, and model\narchitectures and comparing the performance of top models. We take a broad\napproach to AI-driven drug design, allowing for both micro-level comparisons of\nvarious methods within each subtask and macro-level observations across\ndifferent fields. We discuss parallel challenges and approaches between the two\napplications and highlight future directions for AI-driven de novo drug design\nas a whole. An organized repository of all covered sources is available at\nhttps://github.com/gersteinlab/GenAI4Drug.",
    "categories": [
      "q-bio.BM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.BM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.08703v2",
    "published_date": "2024-02-13 16:56:31 UTC",
    "updated_date": "2024-06-26 11:03:21 UTC"
  },
  {
    "arxiv_id": "2402.08593v2",
    "title": "Graph Feature Preprocessor: Real-time Subgraph-based Feature Extraction for Financial Crime Detection",
    "authors": [
      "Jovan Blanuša",
      "Maximo Cravero Baraja",
      "Andreea Anghel",
      "Luc von Niederhäusern",
      "Erik Altman",
      "Haris Pozidis",
      "Kubilay Atasu"
    ],
    "abstract": "In this paper, we present \"Graph Feature Preprocessor\", a software library\nfor detecting typical money laundering patterns in financial transaction graphs\nin real time. These patterns are used to produce a rich set of transaction\nfeatures for downstream machine learning training and inference tasks such as\ndetection of fraudulent financial transactions. We show that our enriched\ntransaction features dramatically improve the prediction accuracy of\ngradient-boosting-based machine learning models. Our library exploits multicore\nparallelism, maintains a dynamic in-memory graph, and efficiently mines\nsubgraph patterns in the incoming transaction stream, which enables it to be\noperated in a streaming manner. Our solution, which combines our Graph Feature\nPreprocessor and gradient-boosting-based machine learning models, can detect\nillicit transactions with higher minority-class F1 scores than standard graph\nneural networks in anti-money laundering and phishing datasets. In addition,\nthe end-to-end throughput rate of our solution executed on a multicore CPU\noutperforms the graph neural network baselines executed on a powerful V100 GPU.\nOverall, the combination of high accuracy, a high throughput rate, and low\nlatency of our solution demonstrates the practical value of our library in\nreal-world applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ACM ICAIF'24, extended version",
    "pdf_url": "http://arxiv.org/pdf/2402.08593v2",
    "published_date": "2024-02-13 16:53:48 UTC",
    "updated_date": "2024-10-03 09:38:16 UTC"
  },
  {
    "arxiv_id": "2402.08702v4",
    "title": "PRompt Optimization in Multi-Step Tasks (PROMST): Integrating Human Feedback and Heuristic-based Sampling",
    "authors": [
      "Yongchao Chen",
      "Jacob Arkin",
      "Yilun Hao",
      "Yang Zhang",
      "Nicholas Roy",
      "Chuchu Fan"
    ],
    "abstract": "Prompt optimization aims to find the best prompt to a large language model\n(LLM) for a given task. LLMs have been successfully used to help find and\nimprove prompt candidates for single-step tasks. However, realistic tasks for\nagents are multi-step and introduce new challenges: (1) Prompt content is\nlikely to be more extensive and complex, making it more difficult for LLMs to\nanalyze errors, (2) the impact of an individual step is difficult to evaluate,\nand (3) different people may have varied preferences about task execution.\nWhile humans struggle to optimize prompts, they are good at providing feedback\nabout LLM outputs; we therefore introduce a new LLM-driven discrete prompt\noptimization framework PRompt Optimization in Multi-Step Tasks (PROMST) that\nincorporates human-designed feedback rules to automatically offer direct\nsuggestions for improvement. We also use an extra learned heuristic model that\npredicts prompt performance to efficiently sample from prompt candidates. This\napproach significantly outperforms both human-engineered prompts and several\nother prompt optimization methods across 11 representative multi-step tasks (an\naverage 10.6\\%-29.3\\% improvement to current best methods on five LLMs\nrespectively). We believe our work can serve as a benchmark for automatic\nprompt optimization for LLM-driven multi-step tasks. Datasets and Codes are\navailable at https://github.com/yongchao98/PROMST. Project Page is available at\nhttps://yongchao98.github.io/MIT-REALM-PROMST.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "cs.RO"
    ],
    "primary_category": "cs.CL",
    "comment": "62 pages, 14 figures, Published in EMNLP 2024 Main",
    "pdf_url": "http://arxiv.org/pdf/2402.08702v4",
    "published_date": "2024-02-13 16:38:01 UTC",
    "updated_date": "2024-10-03 16:11:43 UTC"
  },
  {
    "arxiv_id": "2402.08582v2",
    "title": "FESS Loss: Feature-Enhanced Spatial Segmentation Loss for Optimizing Medical Image Analysis",
    "authors": [
      "Charulkumar Chodvadiya",
      "Navyansh Mahla",
      "Kinshuk Gaurav Singh",
      "Kshitij Sharad Jadhav"
    ],
    "abstract": "Medical image segmentation is a critical process in the field of medical\nimaging, playing a pivotal role in diagnosis, treatment, and research. It\ninvolves partitioning of an image into multiple regions, representing distinct\nanatomical or pathological structures. Conventional methods often grapple with\nthe challenge of balancing spatial precision and comprehensive feature\nrepresentation due to their reliance on traditional loss functions. To overcome\nthis, we propose Feature-Enhanced Spatial Segmentation Loss (FESS Loss), that\nintegrates the benefits of contrastive learning (which extracts intricate\nfeatures, particularly in the nuanced domain of medical imaging) with the\nspatial accuracy inherent in the Dice loss. The objective is to augment both\nspatial precision and feature-based representation in the segmentation of\nmedical images. FESS Loss signifies a notable advancement, offering a more\naccurate and refined segmentation process, ultimately contributing to\nheightened precision in the analysis of medical images. Further, FESS loss\ndemonstrates superior performance in limited annotated data availability\nscenarios often present in the medical domain.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "5 Pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.08582v2",
    "published_date": "2024-02-13 16:36:21 UTC",
    "updated_date": "2024-02-26 14:15:50 UTC"
  },
  {
    "arxiv_id": "2402.08578v1",
    "title": "FedLPS: Heterogeneous Federated Learning for Multiple Tasks with Local Parameter Sharing",
    "authors": [
      "Yongzhe Jia",
      "Xuyun Zhang",
      "Amin Beheshti",
      "Wanchun Dou"
    ],
    "abstract": "Federated Learning (FL) has emerged as a promising solution in Edge Computing\n(EC) environments to process the proliferation of data generated by edge\ndevices. By collaboratively optimizing the global machine learning models on\ndistributed edge devices, FL circumvents the need for transmitting raw data and\nenhances user privacy. Despite practical successes, FL still confronts\nsignificant challenges including constrained edge device resources, multiple\ntasks deployment, and data heterogeneity. However, existing studies focus on\nmitigating the FL training costs of each single task whereas neglecting the\nresource consumption across multiple tasks in heterogeneous FL scenarios. In\nthis paper, we propose Heterogeneous Federated Learning with Local Parameter\nSharing (FedLPS) to fill this gap. FedLPS leverages principles from transfer\nlearning to facilitate the deployment of multiple tasks on a single device by\ndividing the local model into a shareable encoder and task-specific encoders.\nTo further reduce resource consumption, a channel-wise model pruning algorithm\nthat shrinks the footprint of local models while accounting for both data and\nsystem heterogeneity is employed in FedLPS. Additionally, a novel heterogeneous\nmodel aggregation algorithm is proposed to aggregate the heterogeneous\npredictors in FedLPS. We implemented the proposed FedLPS on a real FL platform\nand compared it with state-of-the-art (SOTA) FL frameworks. The experimental\nresults on five popular datasets and two modern DNN models illustrate that the\nproposed FedLPS significantly outperforms the SOTA FL frameworks by up to 4.88%\nand reduces the computational resource consumption by 21.3%. Our code is\navailable at:https://github.com/jyzgh/FedLPS.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by AAAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.08578v1",
    "published_date": "2024-02-13 16:30:30 UTC",
    "updated_date": "2024-02-13 16:30:30 UTC"
  },
  {
    "arxiv_id": "2402.08570v1",
    "title": "Online Foundation Model Selection in Robotics",
    "authors": [
      "Po-han Li",
      "Oyku Selin Toprak",
      "Aditya Narayanan",
      "Ufuk Topcu",
      "Sandeep Chinchali"
    ],
    "abstract": "Foundation models have recently expanded into robotics after excelling in\ncomputer vision and natural language processing. The models are accessible in\ntwo ways: open-source or paid, closed-source options. Users with access to both\nface a problem when deciding between effective yet costly closed-source models\nand free but less powerful open-source alternatives. We call it the model\nselection problem. Existing supervised-learning methods are impractical due to\nthe high cost of collecting extensive training data from closed-source models.\nHence, we focus on the online learning setting where algorithms learn while\ncollecting data, eliminating the need for large pre-collected datasets. We thus\nformulate a user-centric online model selection problem and propose a novel\nsolution that combines an open-source encoder to output context and an online\nlearning algorithm that processes this context. The encoder distills vast data\ndistributions into low-dimensional features, i.e., the context, without\nadditional training. The online learning algorithm aims to maximize a composite\nreward that includes model performance, execution time, and costs based on the\ncontext extracted from the data. It results in an improved trade-off between\nselecting open-source and closed-source models compared to non-contextual\nmethods, as validated by our theoretical analysis. Experiments across\nlanguage-based robotic tasks such as Waymo Open Dataset, ALFRED, and Open\nX-Embodiment demonstrate real-world applications of the solution. The results\nshow that the solution significantly improves the task success rate by up to\n14%.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.08570v1",
    "published_date": "2024-02-13 16:14:32 UTC",
    "updated_date": "2024-02-13 16:14:32 UTC"
  },
  {
    "arxiv_id": "2402.08565v2",
    "title": "Artificial Intelligence for Literature Reviews: Opportunities and Challenges",
    "authors": [
      "Francisco Bolanos",
      "Angelo Salatino",
      "Francesco Osborne",
      "Enrico Motta"
    ],
    "abstract": "This manuscript presents a comprehensive review of the use of Artificial\nIntelligence (AI) in Systematic Literature Reviews (SLRs). A SLR is a rigorous\nand organised methodology that assesses and integrates previous research on a\ngiven topic. Numerous tools have been developed to assist and partially\nautomate the SLR process. The increasing role of AI in this field shows great\npotential in providing more effective support for researchers, moving towards\nthe semi-automatic creation of literature reviews. Our study focuses on how AI\ntechniques are applied in the semi-automation of SLRs, specifically in the\nscreening and extraction phases. We examine 21 leading SLR tools using a\nframework that combines 23 traditional features with 11 AI features. We also\nanalyse 11 recent tools that leverage large language models for searching the\nliterature and assisting academic writing. Finally, the paper discusses current\ntrends in the field, outlines key research challenges, and suggests directions\nfor future research.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "comment": "Updated with the reviewers comments. This version is now accepted at\n  the Artificial Intelligence Review journal",
    "pdf_url": "http://arxiv.org/pdf/2402.08565v2",
    "published_date": "2024-02-13 16:05:51 UTC",
    "updated_date": "2024-08-06 15:40:04 UTC"
  },
  {
    "arxiv_id": "2402.08562v1",
    "title": "Higher Layers Need More LoRA Experts",
    "authors": [
      "Chongyang Gao",
      "Kezhen Chen",
      "Jinmeng Rao",
      "Baochen Sun",
      "Ruibo Liu",
      "Daiyi Peng",
      "Yawen Zhang",
      "Xiaoyuan Guo",
      "Jie Yang",
      "VS Subrahmanian"
    ],
    "abstract": "Parameter-efficient tuning (PEFT) techniques like low-rank adaptation (LoRA)\noffer training efficiency on Large Language Models, but their impact on model\nperformance remains limited. Recent efforts integrate LoRA and\nMixture-of-Experts (MoE) to improve the performance of PEFT methods. Despite\npromising results, research on improving the efficiency of LoRA with MoE is\nstill in its early stages. Recent studies have shown that experts in the MoE\narchitecture have different strengths and also exhibit some redundancy. Does\nthis statement also apply to parameter-efficient MoE? In this paper, we\nintroduce a novel parameter-efficient MoE method,\n\\textit{\\textbf{M}oE-L\\textbf{o}RA with \\textbf{L}ayer-wise Expert\n\\textbf{A}llocation (MoLA)} for Transformer-based models, where each model\nlayer has the flexibility to employ a varying number of LoRA experts. We\ninvestigate several architectures with varying layer-wise expert\nconfigurations. Experiments on six well-known NLP and commonsense QA benchmarks\ndemonstrate that MoLA achieves equal or superior performance compared to all\nbaselines. We find that allocating more LoRA experts to higher layers further\nenhances the effectiveness of models with a certain number of experts in total.\nWith much fewer parameters, this allocation strategy outperforms the setting\nwith the same number of experts in every layer. This work can be widely used as\na plug-and-play parameter-efficient tuning approach for various applications.\nThe code is available at https://github.com/GCYZSL/MoLA.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "The code is available at https://github.com/GCYZSL/MoLA",
    "pdf_url": "http://arxiv.org/pdf/2402.08562v1",
    "published_date": "2024-02-13 16:04:21 UTC",
    "updated_date": "2024-02-13 16:04:21 UTC"
  },
  {
    "arxiv_id": "2402.08547v2",
    "title": "Dueling Over Dessert, Mastering the Art of Repeated Cake Cutting",
    "authors": [
      "Simina Brânzei",
      "MohammadTaghi Hajiaghayi",
      "Reed Phillips",
      "Suho Shin",
      "Kun Wang"
    ],
    "abstract": "We consider the setting of repeated fair division between two players,\ndenoted Alice and Bob, with private valuations over a cake. In each round, a\nnew cake arrives, which is identical to the ones in previous rounds. Alice cuts\nthe cake at a point of her choice, while Bob chooses the left piece or the\nright piece, leaving the remainder for Alice. We consider two versions:\nsequential, where Bob observes Alice's cut point before choosing left/right,\nand simultaneous, where he only observes her cut point after making his choice.\nThe simultaneous version was first considered by Aumann and Maschler (1995).\n  We observe that if Bob is almost myopic and chooses his favorite piece too\noften, then he can be systematically exploited by Alice through a strategy akin\nto a binary search. This strategy allows Alice to approximate Bob's preferences\nwith increasing precision, thereby securing a disproportionate share of the\nresource over time.\n  We analyze the limits of how much a player can exploit the other one and show\nthat fair utility profiles are in fact achievable. Specifically, the players\ncan enforce the equitable utility profile of $(1/2, 1/2)$ in the limit on every\ntrajectory of play, by keeping the other player's utility to approximately\n$1/2$ on average while guaranteeing they themselves get at least approximately\n$1/2$ on average. We show this theorem using a connection with Blackwell\napproachability.\n  Finally, we analyze a natural dynamic known as fictitious play, where players\nbest respond to the empirical distribution of the other player. We show that\nfictitious play converges to the equitable utility profile of $(1/2, 1/2)$ at a\nrate of $O(1/\\sqrt{T})$.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "econ.TH"
    ],
    "primary_category": "cs.GT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.08547v2",
    "published_date": "2024-02-13 15:53:09 UTC",
    "updated_date": "2024-02-18 22:33:10 UTC"
  },
  {
    "arxiv_id": "2402.08530v2",
    "title": "A Distributional Analogue to the Successor Representation",
    "authors": [
      "Harley Wiltzer",
      "Jesse Farebrother",
      "Arthur Gretton",
      "Yunhao Tang",
      "André Barreto",
      "Will Dabney",
      "Marc G. Bellemare",
      "Mark Rowland"
    ],
    "abstract": "This paper contributes a new approach for distributional reinforcement\nlearning which elucidates a clean separation of transition structure and reward\nin the learning process. Analogous to how the successor representation (SR)\ndescribes the expected consequences of behaving according to a given policy,\nour distributional successor measure (SM) describes the distributional\nconsequences of this behaviour. We formulate the distributional SM as a\ndistribution over distributions and provide theory connecting it with\ndistributional and model-based reinforcement learning. Moreover, we propose an\nalgorithm that learns the distributional SM from data by minimizing a two-level\nmaximum mean discrepancy. Key to our method are a number of algorithmic\ntechniques that are independently valuable for learning generative models of\nstate. As an illustration of the usefulness of the distributional SM, we show\nthat it enables zero-shot risk-sensitive policy evaluation in a way that was\nnot previously possible.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to ICML 2024. First two authors contributed equally",
    "pdf_url": "http://arxiv.org/pdf/2402.08530v2",
    "published_date": "2024-02-13 15:35:24 UTC",
    "updated_date": "2024-05-24 16:29:32 UTC"
  },
  {
    "arxiv_id": "2402.08514v2",
    "title": "Counterfactual Influence in Markov Decision Processes",
    "authors": [
      "Milad Kazemi",
      "Jessica Lally",
      "Ekaterina Tishchenko",
      "Hana Chockler",
      "Nicola Paoletti"
    ],
    "abstract": "Our work addresses a fundamental problem in the context of counterfactual\ninference for Markov Decision Processes (MDPs). Given an MDP path $\\tau$, this\nkind of inference allows us to derive counterfactual paths $\\tau'$ describing\nwhat-if versions of $\\tau$ obtained under different action sequences than those\nobserved in $\\tau$. However, as the counterfactual states and actions deviate\nfrom the observed ones over time, the observation $\\tau$ may no longer\ninfluence the counterfactual world, meaning that the analysis is no longer\ntailored to the individual observation, resulting in interventional outcomes\nrather than counterfactual ones. Even though this issue specifically affects\nthe popular Gumbel-max structural causal model used for MDP counterfactuals, it\nhas remained overlooked until now. In this work, we introduce a formal\ncharacterisation of influence based on comparing counterfactual and\ninterventional distributions. We devise an algorithm to construct\ncounterfactual models that automatically satisfy influence constraints.\nLeveraging such models, we derive counterfactual policies that are not just\noptimal for a given reward structure but also remain tailored to the observed\npath. Even though there is an unavoidable trade-off between policy optimality\nand strength of influence constraints, our experiments demonstrate that it is\npossible to derive (near-)optimal policies while remaining under the influence\nof the observation.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "12 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.08514v2",
    "published_date": "2024-02-13 15:10:30 UTC",
    "updated_date": "2025-03-27 13:59:05 UTC"
  },
  {
    "arxiv_id": "2402.08511v1",
    "title": "Amplifying Exploration in Monte-Carlo Tree Search by Focusing on the Unknown",
    "authors": [
      "Cedric Derstroff",
      "Jannis Brugger",
      "Jannis Blüml",
      "Mira Mezini",
      "Stefan Kramer",
      "Kristian Kersting"
    ],
    "abstract": "Monte-Carlo tree search (MCTS) is an effective anytime algorithm with a vast\namount of applications. It strategically allocates computational resources to\nfocus on promising segments of the search tree, making it a very attractive\nsearch algorithm in large search spaces. However, it often expends its limited\nresources on reevaluating previously explored regions when they remain the most\npromising path. Our proposed methodology, denoted as AmEx-MCTS, solves this\nproblem by introducing a novel MCTS formulation. Central to AmEx-MCTS is the\ndecoupling of value updates, visit count updates, and the selected path during\nthe tree search, thereby enabling the exclusion of already explored subtrees or\nleaves. This segregation preserves the utility of visit counts for both\nexploration-exploitation balancing and quality metrics within MCTS. The\nresultant augmentation facilitates in a considerably broader search using\nidentical computational resources, preserving the essential characteristics of\nMCTS. The expanded coverage not only yields more precise estimations but also\nproves instrumental in larger and more complex problems. Our empirical\nevaluation demonstrates the superior performance of AmEx-MCTS, surpassing\nclassical MCTS and related approaches by a substantial margin.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.08511v1",
    "published_date": "2024-02-13 15:05:54 UTC",
    "updated_date": "2024-02-13 15:05:54 UTC"
  },
  {
    "arxiv_id": "2402.08509v1",
    "title": "From Shapes to Shapes: Inferring SHACL Shapes for Results of SPARQL CONSTRUCT Queries (Extended Version)",
    "authors": [
      "Philipp Seifer",
      "Daniel Hernández",
      "Ralf Lämmel",
      "Steffen Staab"
    ],
    "abstract": "SPARQL CONSTRUCT queries allow for the specification of data processing\npipelines that transform given input graphs into new output graphs. It is now\ncommon to constrain graphs through SHACL shapes allowing users to understand\nwhich data they can expect and which not. However, it becomes challenging to\nunderstand what graph data can be expected at the end of a data processing\npipeline without knowing the particular input data: Shape constraints on the\ninput graph may affect the output graph, but may no longer apply literally, and\nnew shapes may be imposed by the query template. In this paper, we study the\nderivation of shape constraints that hold on all possible output graphs of a\ngiven SPARQL CONSTRUCT query. We assume that the SPARQL CONSTRUCT query is\nfixed, e.g., being part of a program, whereas the input graphs adhere to input\nshape constraints but may otherwise vary over time and, thus, are mostly\nunknown. We study a fragment of SPARQL CONSTRUCT queries (SCCQ) and a fragment\nof SHACL (Simple SHACL). We formally define the problem of deriving the most\nrestrictive set of Simple SHACL shapes that constrain the results from\nevaluating a SCCQ over any input graph restricted by a given set of Simple\nSHACL shapes. We propose and implement an algorithm that statically analyses\ninput SHACL shapes and CONSTRUCT queries and prove its soundness and\ncomplexity.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.DB",
    "comment": "19 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.08509v1",
    "published_date": "2024-02-13 15:04:11 UTC",
    "updated_date": "2024-02-13 15:04:11 UTC"
  },
  {
    "arxiv_id": "2402.08496v3",
    "title": "A Systematic Review of Data-to-Text NLG",
    "authors": [
      "Chinonso Cynthia Osuji",
      "Thiago Castro Ferreira",
      "Brian Davis"
    ],
    "abstract": "This systematic review undertakes a comprehensive analysis of current\nresearch on data-to-text generation, identifying gaps, challenges, and future\ndirections within the field. Relevant literature in this field on datasets,\nevaluation metrics, application areas, multilingualism, language models, and\nhallucination mitigation methods is reviewed. Various methods for producing\nhigh-quality text are explored, addressing the challenge of hallucinations in\ndata-to-text generation. These methods include re-ranking, traditional and\nneural pipeline architecture, planning architectures, data cleaning, controlled\ngeneration, and modification of models and training techniques. Their\neffectiveness and limitations are assessed, highlighting the need for\nuniversally applicable strategies to mitigate hallucinations. The review also\nexamines the usage, popularity, and impact of datasets, alongside evaluation\nmetrics, with an emphasis on both automatic and human assessment. Additionally,\nthe evolution of data-to-text models, particularly the widespread adoption of\ntransformer models, is discussed. Despite advancements in text quality, the\nreview emphasizes the importance of research in low-resourced languages and the\nengineering of datasets in these languages to promote inclusivity. Finally,\nseveral application domains of data-to-text are highlighted, emphasizing their\nrelevance in such domains. Overall, this review serves as a guiding framework\nfor fostering innovation and advancing data-to-text generation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.08496v3",
    "published_date": "2024-02-13 14:51:45 UTC",
    "updated_date": "2024-02-27 00:05:28 UTC"
  },
  {
    "arxiv_id": "2402.08492v1",
    "title": "The Application of ChatGPT in Responding to Questions Related to the Boston Bowel Preparation Scale",
    "authors": [
      "Xiaoqiang Liu",
      "Yubin Wang",
      "Zicheng Huang",
      "Boming Xu",
      "Yilin Zeng",
      "Xinqi Chen",
      "Zilong Wang",
      "Enning Yang",
      "Xiaoxuan Lei",
      "Yisen Huang",
      "Xiaobo Liu"
    ],
    "abstract": "Background: Colonoscopy, a crucial diagnostic tool in gastroenterology,\ndepends heavily on superior bowel preparation. ChatGPT, a large language model\nwith emergent intelligence which also exhibits potential in medical\napplications. This study aims to assess the accuracy and consistency of ChatGPT\nin using the Boston Bowel Preparation Scale (BBPS) for colonoscopy assessment.\nMethods: We retrospectively collected 233 colonoscopy images from 2020 to 2023.\nThese images were evaluated using the BBPS by 3 senior endoscopists and 3\nnovice endoscopists. Additionally, ChatGPT also assessed these images, having\nbeen divided into three groups and undergone specific Fine-tuning. Consistency\nwas evaluated through two rounds of testing. Results: In the initial round,\nChatGPT's accuracy varied between 48.93% and 62.66%, trailing the endoscopists'\naccuracy of 76.68% to 77.83%. Kappa values for ChatGPT was between 0.52 and\n0.53, compared to 0.75 to 0.87 for the endoscopists. Conclusion: While ChatGPT\nshows promise in bowel preparation scoring, it currently does not match the\naccuracy and consistency of experienced endoscopists. Future research should\nfocus on in-depth Fine-tuning.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.08492v1",
    "published_date": "2024-02-13 14:38:12 UTC",
    "updated_date": "2024-02-13 14:38:12 UTC"
  },
  {
    "arxiv_id": "2402.08491v3",
    "title": "Deep Reinforcement Learning for Controlled Traversing of the Attractor Landscape of Boolean Models in the Context of Cellular Reprogramming",
    "authors": [
      "Andrzej Mizera",
      "Jakub Zarzycki"
    ],
    "abstract": "Cellular reprogramming can be used for both the prevention and cure of\ndifferent diseases. However, the efficiency of discovering reprogramming\nstrategies with classical wet-lab experiments is hindered by lengthy time\ncommitments and high costs. In this study, we develop a novel computational\nframework based on deep reinforcement learning that facilitates the\nidentification of reprogramming strategies. For this aim, we formulate a\ncontrol problem in the context of cellular reprogramming for the frameworks of\nBNs and PBNs under the asynchronous update mode. Furthermore, we introduce the\nnotion of a pseudo-attractor and a procedure for identification of\npseudo-attractor state during training. Finally, we devise a computational\nframework for solving the control problem, which we test on a number of\ndifferent models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.MN",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.08491v3",
    "published_date": "2024-02-13 14:36:46 UTC",
    "updated_date": "2025-03-03 12:22:02 UTC"
  },
  {
    "arxiv_id": "2402.08473v1",
    "title": "Intriguing Differences Between Zero-Shot and Systematic Evaluations of Vision-Language Transformer Models",
    "authors": [
      "Shaeke Salman",
      "Md Montasir Bin Shams",
      "Xiuwen Liu",
      "Lingjiong Zhu"
    ],
    "abstract": "Transformer-based models have dominated natural language processing and other\nareas in the last few years due to their superior (zero-shot) performance on\nbenchmark datasets. However, these models are poorly understood due to their\ncomplexity and size. While probing-based methods are widely used to understand\nspecific properties, the structures of the representation space are not\nsystematically characterized; consequently, it is unclear how such models\ngeneralize and overgeneralize to new inputs beyond datasets. In this paper,\nbased on a new gradient descent optimization method, we are able to explore the\nembedding space of a commonly used vision-language model. Using the Imagenette\ndataset, we show that while the model achieves over 99\\% zero-shot\nclassification performance, it fails systematic evaluations completely. Using a\nlinear approximation, we provide a framework to explain the striking\ndifferences. We have also obtained similar results using a different model to\nsupport that our results are applicable to other transformer models with\ncontinuous inputs. We also propose a robust way to detect the modified images.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "30 pages, 30 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.08473v1",
    "published_date": "2024-02-13 14:07:49 UTC",
    "updated_date": "2024-02-13 14:07:49 UTC"
  },
  {
    "arxiv_id": "2402.08472v1",
    "title": "Large Language Models for the Automated Analysis of Optimization Algorithms",
    "authors": [
      "Camilo Chacón Sartori",
      "Christian Blum",
      "Gabriela Ochoa"
    ],
    "abstract": "The ability of Large Language Models (LLMs) to generate high-quality text and\ncode has fuelled their rise in popularity. In this paper, we aim to demonstrate\nthe potential of LLMs within the realm of optimization algorithms by\nintegrating them into STNWeb. This is a web-based tool for the generation of\nSearch Trajectory Networks (STNs), which are visualizations of optimization\nalgorithm behavior. Although visualizations produced by STNWeb can be very\ninformative for algorithm designers, they often require a certain level of\nprior knowledge to be interpreted. In an attempt to bridge this knowledge gap,\nwe have incorporated LLMs, specifically GPT-4, into STNWeb to produce extensive\nwritten reports, complemented by automatically generated plots, thereby\nenhancing the user experience and reducing the barriers to the adoption of this\ntool by the research community. Moreover, our approach can be expanded to other\ntools from the optimization community, showcasing the versatility and potential\nof LLMs in this field.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Submitted to the GECCO 2024 conference",
    "pdf_url": "http://arxiv.org/pdf/2402.08472v1",
    "published_date": "2024-02-13 14:05:02 UTC",
    "updated_date": "2024-02-13 14:05:02 UTC"
  },
  {
    "arxiv_id": "2402.08470v1",
    "title": "Parallel-friendly Spatio-Temporal Graph Learning for Photovoltaic Degradation Analysis at Scale",
    "authors": [
      "Yangxin Fan",
      "Raymond Wieser",
      "Laura Bruckman",
      "Roger French",
      "Yinghui Wu"
    ],
    "abstract": "We propose a novel Spatio-Temporal Graph Neural Network empowered trend\nanalysis approach (ST-GTrend) to perform fleet-level performance degradation\nanalysis for Photovoltaic (PV) power networks. PV power stations have become an\nintegral component to the global sustainable energy production landscape.\nAccurately estimating the performance of PV systems is critical to their\nfeasibility as a power generation technology and as a financial asset. One of\nthe most challenging problems in assessing the Levelized Cost of Energy (LCOE)\nof a PV system is to understand and estimate the long-term Performance Loss\nRate (PLR) for large fleets of PV inverters. ST-GTrend integrates\nspatio-temporal coherence and graph attention to separate PLR as a long-term\n\"aging\" trend from multiple fluctuation terms in the PV input data. To cope\nwith diverse degradation patterns in timeseries, ST-GTrend adopts a paralleled\ngraph autoencoder array to extract aging and fluctuation terms simultaneously.\nST-GTrend imposes flatness and smoothness regularization to ensure the\ndisentanglement between aging and fluctuation. To scale the analysis to large\nPV systems, we also introduce Para-GTrend, a parallel algorithm to accelerate\nthe training and inference of ST-GTrend. We have evaluated ST-GTrend on three\nlarge-scale PV datasets, spanning a time period of 10 years. Our results show\nthat ST-GTrend reduces Mean Absolute Percent Error (MAPE) and Euclidean\nDistances by 34.74% and 33.66% compared to the SOTA methods. Our results\ndemonstrate that Para-GTrend can speed up ST-GTrend by up to 7.92 times. We\nfurther verify the generality and effectiveness of ST-GTrend for trend analysis\nusing financial and economic datasets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.08470v1",
    "published_date": "2024-02-13 14:00:59 UTC",
    "updated_date": "2024-02-13 14:00:59 UTC"
  },
  {
    "arxiv_id": "2402.08466v2",
    "title": "Taking Training Seriously: Human Guidance and Management-Based Regulation of Artificial Intelligence",
    "authors": [
      "Cary Coglianese",
      "Colton R. Crum"
    ],
    "abstract": "Fervent calls for more robust governance of the harms associated with\nartificial intelligence (AI) are leading to the adoption around the world of\nwhat regulatory scholars have called a management-based approach to regulation.\nRecent initiatives in the United States and Europe, as well as the adoption of\nmajor self-regulatory standards by the International Organization for\nStandardization, share in common a core management-based paradigm. These\nmanagement-based initiatives seek to motivate an increase in human oversight of\nhow AI tools are trained and developed. Refinements and systematization of\nhuman-guided training techniques will thus be needed to fit within this\nemerging era of management-based regulatory paradigm. If taken seriously,\nhuman-guided training can alleviate some of the technical and ethical pressures\non AI, boosting AI performance with human intuition as well as better\naddressing the needs for fairness and effective explainability. In this paper,\nwe discuss the connection between the emerging management-based regulatory\nframeworks governing AI and the need for human oversight during training. We\nbroadly cover some of the technical components involved in human-guided\ntraining and then argue that the kinds of high-stakes use cases for AI that\nappear of most concern to regulators should lean more on human-guided training\nthan on data-only training. We hope to foster a discussion between legal\nscholars and computer scientists involving how to govern a domain of technology\nthat is vast, heterogenous, and dynamic in its applications and risks.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2402.08466v2",
    "published_date": "2024-02-13 13:48:54 UTC",
    "updated_date": "2024-06-27 02:45:49 UTC"
  },
  {
    "arxiv_id": "2402.08430v1",
    "title": "Analyzing Prompt Influence on Automated Method Generation: An Empirical Study with Copilot",
    "authors": [
      "Ionut Daniel Fagadau",
      "Leonardo Mariani",
      "Daniela Micucci",
      "Oliviero Riganelli"
    ],
    "abstract": "Generative AI is changing the way developers interact with software systems,\nproviding services that can produce and deliver new content, crafted to satisfy\nthe actual needs of developers. For instance, developers can ask for new code\ndirectly from within their IDEs by writing natural language prompts, and\nintegrated services based on generative AI, such as Copilot, immediately\nrespond to prompts by providing ready-to-use code snippets. Formulating the\nprompt appropriately, and incorporating the useful information while avoiding\nany information overload, can be an important factor in obtaining the right\npiece of code. The task of designing good prompts is known as prompt\nengineering. In this paper, we systematically investigate the influence of\neight prompt features on the style and the content of prompts, on the level of\ncorrectness, complexity, size, and similarity to the developers' code of the\ngenerated code. We specifically consider the task of using Copilot with 124,800\nprompts obtained by systematically combining the eight considered prompt\nfeatures to generate the implementation of 200 Java methods. Results show how\nsome prompt features, such as the presence of examples and the summary of the\npurpose of the method, can significantly influence the quality of the result.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.08430v1",
    "published_date": "2024-02-13 12:58:53 UTC",
    "updated_date": "2024-02-13 12:58:53 UTC"
  },
  {
    "arxiv_id": "2402.08423v1",
    "title": "Vehicle Behavior Prediction by Episodic-Memory Implanted NDT",
    "authors": [
      "Peining Shen",
      "Jianwu Fang",
      "Hongkai Yu",
      "Jianru Xue"
    ],
    "abstract": "In autonomous driving, predicting the behavior (turning left, stopping, etc.)\nof target vehicles is crucial for the self-driving vehicle to make safe\ndecisions and avoid accidents. Existing deep learning-based methods have shown\nexcellent and accurate performance, but the black-box nature makes it\nuntrustworthy to apply them in practical use. In this work, we explore the\ninterpretability of behavior prediction of target vehicles by an Episodic\nMemory implanted Neural Decision Tree (abbrev. eMem-NDT). The structure of\neMem-NDT is constructed by hierarchically clustering the text embedding of\nvehicle behavior descriptions. eMem-NDT is a neural-backed part of a\npre-trained deep learning model by changing the soft-max layer of the deep\nmodel to eMem-NDT, for grouping and aligning the memory prototypes of the\nhistorical vehicle behavior features in training data on a neural decision\ntree. Each leaf node of eMem-NDT is modeled by a neural network for aligning\nthe behavior memory prototypes. By eMem-NDT, we infer each instance in behavior\nprediction of vehicles by bottom-up Memory Prototype Matching (MPM) (searching\nthe appropriate leaf node and the links to the root node) and top-down Leaf\nLink Aggregation (LLA) (obtaining the probability of future behaviors of\nvehicles for certain instances). We validate eMem-NDT on BLVD and LOKI\ndatasets, and the results show that our model can obtain a superior performance\nto other methods with clear explainability. The code is available at\nhttps://github.com/JWFangit/eMem-NDT.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by ICRA2024",
    "pdf_url": "http://arxiv.org/pdf/2402.08423v1",
    "published_date": "2024-02-13 12:50:04 UTC",
    "updated_date": "2024-02-13 12:50:04 UTC"
  },
  {
    "arxiv_id": "2402.08409v1",
    "title": "Transferring Ultrahigh-Field Representations for Intensity-Guided Brain Segmentation of Low-Field Magnetic Resonance Imaging",
    "authors": [
      "Kwanseok Oh",
      "Jieun Lee",
      "Da-Woon Heo",
      "Dinggang Shen",
      "Heung-Il Suk"
    ],
    "abstract": "Ultrahigh-field (UHF) magnetic resonance imaging (MRI), i.e., 7T MRI,\nprovides superior anatomical details of internal brain structures owing to its\nenhanced signal-to-noise ratio and susceptibility-induced contrast. However,\nthe widespread use of 7T MRI is limited by its high cost and lower\naccessibility compared to low-field (LF) MRI. This study proposes a\ndeep-learning framework that systematically fuses the input LF magnetic\nresonance feature representations with the inferred 7T-like feature\nrepresentations for brain image segmentation tasks in a 7T-absent environment.\nSpecifically, our adaptive fusion module aggregates 7T-like features derived\nfrom the LF image by a pre-trained network and then refines them to be\neffectively assimilable UHF guidance into LF image features. Using\nintensity-guided features obtained from such aggregation and assimilation,\nsegmentation models can recognize subtle structural representations that are\nusually difficult to recognize when relying only on LF features. Beyond such\nadvantages, this strategy can seamlessly be utilized by modulating the contrast\nof LF features in alignment with UHF guidance, even when employing arbitrary\nsegmentation models. Exhaustive experiments demonstrated that the proposed\nmethod significantly outperformed all baseline models on both brain tissue and\nwhole-brain segmentation tasks; further, it exhibited remarkable adaptability\nand scalability by successfully integrating diverse segmentation models and\ntasks. These improvements were not only quantifiable but also visible in the\nsuperlative visual quality of segmentation masks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "32 pages, 9 figures, and 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2402.08409v1",
    "published_date": "2024-02-13 12:21:06 UTC",
    "updated_date": "2024-02-13 12:21:06 UTC"
  },
  {
    "arxiv_id": "2402.08401v1",
    "title": "LOSS-GAT: Label Propagation and One-Class Semi-Supervised Graph Attention Network for Fake News Detection",
    "authors": [
      "Batool Lakzaei",
      "Mostafa Haghir Chehreghani",
      "Alireza Bagheri"
    ],
    "abstract": "In the era of widespread social networks, the rapid dissemination of fake\nnews has emerged as a significant threat, inflicting detrimental consequences\nacross various dimensions of people's lives. Machine learning and deep learning\napproaches have been extensively employed for identifying fake news. However, a\nsignificant challenge in identifying fake news is the limited availability of\nlabeled news datasets. Therefore, the One-Class Learning (OCL) approach,\nutilizing only a small set of labeled data from the interest class, can be a\nsuitable approach to address this challenge. On the other hand, representing\ndata as a graph enables access to diverse content and structural information,\nand label propagation methods on graphs can be effective in predicting node\nlabels. In this paper, we adopt a graph-based model for data representation and\nintroduce a semi-supervised and one-class approach for fake news detection,\ncalled LOSS-GAT. Initially, we employ a two-step label propagation algorithm,\nutilizing Graph Neural Networks (GNNs) as an initial classifier to categorize\nnews into two groups: interest (fake) and non-interest (real). Subsequently, we\nenhance the graph structure using structural augmentation techniques.\nUltimately, we predict the final labels for all unlabeled data using a GNN that\ninduces randomness within the local neighborhood of nodes through the\naggregation function. We evaluate our proposed method on five common datasets\nand compare the results against a set of baseline models, including both OCL\nand binary labeled models. The results demonstrate that LOSS-GAT achieves a\nnotable improvement, surpassing 10%, with the advantage of utilizing only a\nlimited set of labeled fake news. Noteworthy, LOSS-GAT even outperforms binary\nlabeled models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.08401v1",
    "published_date": "2024-02-13 12:02:37 UTC",
    "updated_date": "2024-02-13 12:02:37 UTC"
  },
  {
    "arxiv_id": "2402.08384v2",
    "title": "Selective Learning: Towards Robust Calibration with Dynamic Regularization",
    "authors": [
      "Zongbo Han",
      "Yifeng Yang",
      "Changqing Zhang",
      "Linjun Zhang",
      "Joey Tianyi Zhou",
      "Qinghua Hu"
    ],
    "abstract": "Miscalibration in deep learning refers to there is a discrepancy between the\npredicted confidence and performance. This problem usually arises due to the\noverfitting problem, which is characterized by learning everything presented in\nthe training set, resulting in overconfident predictions during testing.\nExisting methods typically address overfitting and mitigate the miscalibration\nby adding a maximum-entropy regularizer to the objective function. The\nobjective can be understood as seeking a model that fits the ground-truth\nlabels by increasing the confidence while also maximizing the entropy of\npredicted probabilities by decreasing the confidence. However, previous methods\nlack clear guidance on confidence adjustment, leading to conflicting objectives\n(increasing but also decreasing confidence). Therefore, we introduce a method\ncalled Dynamic Regularization (DReg), which aims to learn what should be\nlearned during training thereby circumventing the confidence adjusting\ntrade-off. At a high level, DReg aims to obtain a more reliable model capable\nof acknowledging what it knows and does not know. Specifically, DReg\neffectively fits the labels for in-distribution samples (samples that should be\nlearned) while applying regularization dynamically to samples beyond model\ncapabilities (e.g., outliers), thereby obtaining a robust calibrated model\nespecially on the samples beyond model capabilities. Both theoretical and\nempirical analyses sufficiently demonstrate the superiority of DReg compared\nwith previous methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.08384v2",
    "published_date": "2024-02-13 11:25:20 UTC",
    "updated_date": "2024-07-14 09:12:25 UTC"
  },
  {
    "arxiv_id": "2402.08383v1",
    "title": "Uncertainty Quantification for Forward and Inverse Problems of PDEs via Latent Global Evolution",
    "authors": [
      "Tailin Wu",
      "Willie Neiswanger",
      "Hongtao Zheng",
      "Stefano Ermon",
      "Jure Leskovec"
    ],
    "abstract": "Deep learning-based surrogate models have demonstrated remarkable advantages\nover classical solvers in terms of speed, often achieving speedups of 10 to\n1000 times over traditional partial differential equation (PDE) solvers.\nHowever, a significant challenge hindering their widespread adoption in both\nscientific and industrial domains is the lack of understanding about their\nprediction uncertainties, particularly in scenarios that involve critical\ndecision making. To address this limitation, we propose a method that\nintegrates efficient and precise uncertainty quantification into a deep\nlearning-based surrogate model. Our method, termed Latent Evolution of PDEs\nwith Uncertainty Quantification (LE-PDE-UQ), endows deep learning-based\nsurrogate models with robust and efficient uncertainty quantification\ncapabilities for both forward and inverse problems. LE-PDE-UQ leverages latent\nvectors within a latent space to evolve both the system's state and its\ncorresponding uncertainty estimation. The latent vectors are decoded to provide\npredictions for the system's state as well as estimates of its uncertainty. In\nextensive experiments, we demonstrate the accurate uncertainty quantification\nperformance of our approach, surpassing that of strong baselines including deep\nensembles, Bayesian neural network layers, and dropout. Our method excels at\npropagating uncertainty over extended auto-regressive rollouts, making it\nsuitable for scenarios involving long-term predictions. Our code is available\nat: https://github.com/AI4Science-WestlakeU/le-pde-uq.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by AAAI 2024 (Oral)",
    "pdf_url": "http://arxiv.org/pdf/2402.08383v1",
    "published_date": "2024-02-13 11:22:59 UTC",
    "updated_date": "2024-02-13 11:22:59 UTC"
  },
  {
    "arxiv_id": "2402.08373v1",
    "title": "Time-Series Classification for Dynamic Strategies in Multi-Step Forecasting",
    "authors": [
      "Riku Green",
      "Grant Stevens",
      "Telmo de Menezes e Silva Filho",
      "Zahraa Abdallah"
    ],
    "abstract": "Multi-step forecasting (MSF) in time-series, the ability to make predictions\nmultiple time steps into the future, is fundamental to almost all temporal\ndomains. To make such forecasts, one must assume the recursive complexity of\nthe temporal dynamics. Such assumptions are referred to as the forecasting\nstrategy used to train a predictive model. Previous work shows that it is not\nclear which forecasting strategy is optimal a priori to evaluating on unseen\ndata. Furthermore, current approaches to MSF use a single (fixed) forecasting\nstrategy.\n  In this paper, we characterise the instance-level variance of optimal\nforecasting strategies and propose Dynamic Strategies (DyStrat) for MSF. We\nexperiment using 10 datasets from different scales, domains, and lengths of\nmulti-step horizons. When using a random-forest-based classifier, DyStrat\noutperforms the best fixed strategy, which is not knowable a priori, 94% of the\ntime, with an average reduction in mean-squared error of 11%. Our approach\ntypically triples the top-1 accuracy compared to current approaches. Notably,\nwe show DyStrat generalises well for any MSF task.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.08373v1",
    "published_date": "2024-02-13 11:10:14 UTC",
    "updated_date": "2024-02-13 11:10:14 UTC"
  },
  {
    "arxiv_id": "2402.08369v1",
    "title": "One-shot Imitation in a Non-Stationary Environment via Multi-Modal Skill",
    "authors": [
      "Sangwoo Shin",
      "Daehee Lee",
      "Minjong Yoo",
      "Woo Kyung Kim",
      "Honguk Woo"
    ],
    "abstract": "One-shot imitation is to learn a new task from a single demonstration, yet it\nis a challenging problem to adopt it for complex tasks with the high domain\ndiversity inherent in a non-stationary environment. To tackle the problem, we\nexplore the compositionality of complex tasks, and present a novel skill-based\nimitation learning framework enabling one-shot imitation and zero-shot\nadaptation; from a single demonstration for a complex unseen task, a semantic\nskill sequence is inferred and then each skill in the sequence is converted\ninto an action sequence optimized for environmental hidden dynamics that can\nvary over time. Specifically, we leverage a vision-language model to learn a\nsemantic skill set from offline video datasets, where each skill is represented\non the vision-language embedding space, and adapt meta-learning with dynamics\ninference to enable zero-shot skill adaptation. We evaluate our framework with\nvarious one-shot imitation scenarios for extended multi-stage Meta-world tasks,\nshowing its superiority in learning complex tasks, generalizing to dynamics\nchanges, and extending to different demonstration conditions and modalities,\ncompared to other baselines.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "ICML-2023 Camera Ready Version",
    "pdf_url": "http://arxiv.org/pdf/2402.08369v1",
    "published_date": "2024-02-13 11:01:52 UTC",
    "updated_date": "2024-02-13 11:01:52 UTC"
  },
  {
    "arxiv_id": "2402.08349v3",
    "title": "Evaluating the Data Model Robustness of Text-to-SQL Systems Based on Real User Queries",
    "authors": [
      "Jonathan Fürst",
      "Catherine Kosten",
      "Farhad Nooralahzadeh",
      "Yi Zhang",
      "Kurt Stockinger"
    ],
    "abstract": "Text-to-SQL systems (also known as NL-to-SQL systems) have become an\nincreasingly popular solution for bridging the gap between user capabilities\nand SQL-based data access. These systems translate user requests in natural\nlanguage to valid SQL statements for a specific database. Recent Text-to-SQL\nsystems have benefited from the rapid improvement of transformer-based language\nmodels. However, while Text-to-SQL systems that incorporate such models\ncontinuously reach new high scores on -- often synthetic -- benchmark datasets,\na systematic exploration of their robustness towards different data models in a\nreal-world, realistic scenario is notably missing. This paper provides the\nfirst in-depth evaluation of the data model robustness of Text-to-SQL systems\nin practice based on a multi-year international project focused on Text-to-SQL\ninterfaces. Our evaluation is based on a real-world deployment of FootballDB, a\nsystem that was deployed over a 9 month period in the context of the FIFA World\nCup 2022, during which about 6K natural language questions were asked and\nexecuted. All of our data is based on real user questions that were asked live\nto the system. We manually labeled and translated a subset of these questions\nfor three different data models. For each data model, we explore the\nperformance of representative Text-to-SQL systems and language models. We\nfurther quantify the impact of training data size, pre-, and post-processing\nsteps as well as language model inference time. Our comprehensive evaluation\nsheds light on the design choices of real-world Text-to-SQL systems and their\nimpact on moving from research prototypes to real deployments. Last, we provide\na new benchmark dataset to the community, which is the first to enable the\nevaluation of different data models for the same dataset and is substantially\nmore challenging than most previous datasets in terms of query complexity.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.08349v3",
    "published_date": "2024-02-13 10:28:57 UTC",
    "updated_date": "2024-11-29 14:44:27 UTC"
  },
  {
    "arxiv_id": "2402.08341v2",
    "title": "Eliciting Personality Traits in Large Language Models",
    "authors": [
      "Airlie Hilliard",
      "Cristian Munoz",
      "Zekun Wu",
      "Adriano Soares Koshiyama"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly being utilized by both\ncandidates and employers in the recruitment context. However, with this comes\nnumerous ethical concerns, particularly related to the lack of transparency in\nthese \"black-box\" models. Although previous studies have sought to increase the\ntransparency of these models by investigating the personality traits of LLMs,\nmany of the previous studies have provided them with personality assessments to\ncomplete. On the other hand, this study seeks to obtain a better understanding\nof such models by examining their output variations based on different input\nprompts. Specifically, we use a novel elicitation approach using prompts\nderived from common interview questions, as well as prompts designed to elicit\nparticular Big Five personality traits to examine whether the models were\nsusceptible to trait-activation like humans are, to measure their personality\nbased on the language used in their outputs. To do so, we repeatedly prompted\nmultiple LMs with different parameter sizes, including Llama-2, Falcon,\nMistral, Bloom, GPT, OPT, and XLNet (base and fine tuned versions) and examined\ntheir personality using classifiers trained on the myPersonality dataset. Our\nresults reveal that, generally, all LLMs demonstrate high openness and low\nextraversion. However, whereas LMs with fewer parameters exhibit similar\nbehaviour in personality traits, newer and LMs with more parameters exhibit a\nbroader range of personality traits, with increased agreeableness, emotional\nstability, and openness. Furthermore, a greater number of parameters is\npositively associated with openness and conscientiousness. Moreover, fine-tuned\nmodels exhibit minor modulations in their personality traits, contingent on the\ndataset. Implications and directions for future research are discussed.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Manuscript submitted to ACM Facct. Authors One and Two contributed\n  equally to this work",
    "pdf_url": "http://arxiv.org/pdf/2402.08341v2",
    "published_date": "2024-02-13 10:09:00 UTC",
    "updated_date": "2024-02-15 09:12:40 UTC"
  },
  {
    "arxiv_id": "2402.08324v1",
    "title": "Uncertainty Quantification via Stable Distribution Propagation",
    "authors": [
      "Felix Petersen",
      "Aashwin Mishra",
      "Hilde Kuehne",
      "Christian Borgelt",
      "Oliver Deussen",
      "Mikhail Yurochkin"
    ],
    "abstract": "We propose a new approach for propagating stable probability distributions\nthrough neural networks. Our method is based on local linearization, which we\nshow to be an optimal approximation in terms of total variation distance for\nthe ReLU non-linearity. This allows propagating Gaussian and Cauchy input\nuncertainties through neural networks to quantify their output uncertainties.\nTo demonstrate the utility of propagating distributions, we apply the proposed\nmethod to predicting calibrated confidence intervals and selective prediction\non out-of-distribution data. The results demonstrate a broad applicability of\npropagating distributions and show the advantages of our method over other\napproaches such as moment matching.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Published at ICLR 2024, Code @\n  https://github.com/Felix-Petersen/distprop",
    "pdf_url": "http://arxiv.org/pdf/2402.08324v1",
    "published_date": "2024-02-13 09:40:19 UTC",
    "updated_date": "2024-02-13 09:40:19 UTC"
  },
  {
    "arxiv_id": "2402.08323v1",
    "title": "Mapping the Ethics of Generative AI: A Comprehensive Scoping Review",
    "authors": [
      "Thilo Hagendorff"
    ],
    "abstract": "The advent of generative artificial intelligence and the widespread adoption\nof it in society engendered intensive debates about its ethical implications\nand risks. These risks often differ from those associated with traditional\ndiscriminative machine learning. To synthesize the recent discourse and map its\nnormative concepts, we conducted a scoping review on the ethics of generative\nartificial intelligence, including especially large language models and\ntext-to-image models. Our analysis provides a taxonomy of 378 normative issues\nin 19 topic areas and ranks them according to their prevalence in the\nliterature. The study offers a comprehensive overview for scholars,\npractitioners, or policymakers, condensing the ethical debates surrounding\nfairness, safety, harmful content, hallucinations, privacy, interaction risks,\nsecurity, alignment, societal impacts, and others. We discuss the results,\nevaluate imbalances in the literature, and explore unsubstantiated risk\nscenarios.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.08323v1",
    "published_date": "2024-02-13 09:38:17 UTC",
    "updated_date": "2024-02-13 09:38:17 UTC"
  },
  {
    "arxiv_id": "2402.15898v6",
    "title": "Transductive Active Learning: Theory and Applications",
    "authors": [
      "Jonas Hübotter",
      "Bhavya Sukhija",
      "Lenart Treven",
      "Yarden As",
      "Andreas Krause"
    ],
    "abstract": "We study a generalization of classical active learning to real-world settings\nwith concrete prediction targets where sampling is restricted to an accessible\nregion of the domain, while prediction targets may lie outside this region. We\nanalyze a family of decision rules that sample adaptively to minimize\nuncertainty about prediction targets. We are the first to show, under general\nregularity assumptions, that such decision rules converge uniformly to the\nsmallest possible uncertainty obtainable from the accessible data. We\ndemonstrate their strong sample efficiency in two key applications: active\nfine-tuning of large neural networks and safe Bayesian optimization, where they\nachieve state-of-the-art performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "accepted in NeurIPS 2024. arXiv admin note: text overlap with\n  arXiv:2402.15441",
    "pdf_url": "http://arxiv.org/pdf/2402.15898v6",
    "published_date": "2024-02-13 09:22:45 UTC",
    "updated_date": "2025-02-08 19:30:33 UTC"
  },
  {
    "arxiv_id": "2402.15441v4",
    "title": "Active Few-Shot Fine-Tuning",
    "authors": [
      "Jonas Hübotter",
      "Bhavya Sukhija",
      "Lenart Treven",
      "Yarden As",
      "Andreas Krause"
    ],
    "abstract": "We study the question: How can we select the right data for fine-tuning to a\nspecific task? We call this data selection problem active fine-tuning and show\nthat it is an instance of transductive active learning, a novel generalization\nof classical active learning. We propose ITL, short for information-based\ntransductive learning, an approach which samples adaptively to maximize\ninformation gained about the specified task. We are the first to show, under\ngeneral regularity assumptions, that such decision rules converge uniformly to\nthe smallest possible uncertainty obtainable from the accessible data. We apply\nITL to the few-shot fine-tuning of large neural networks and show that\nfine-tuning with ITL learns the task with significantly fewer examples than the\nstate-of-the-art.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.15441v4",
    "published_date": "2024-02-13 09:19:05 UTC",
    "updated_date": "2024-06-21 08:48:18 UTC"
  },
  {
    "arxiv_id": "2402.08310v1",
    "title": "One-to-many Reconstruction of 3D Geometry of cultural Artifacts using a synthetically trained Generative Model",
    "authors": [
      "Thomas Pöllabauer",
      "Julius Kühn",
      "Jiayi Li",
      "Arjan Kuijper"
    ],
    "abstract": "Estimating the 3D shape of an object using a single image is a difficult\nproblem. Modern approaches achieve good results for general objects, based on\nreal photographs, but worse results on less expressive representations such as\nhistoric sketches. Our automated approach generates a variety of detailed 3D\nrepresentation from a single sketch, depicting a medieval statue, and can be\nguided by multi-modal inputs, such as text prompts. It relies solely on\nsynthetic data for training, making it adoptable even in cases of only small\nnumbers of training examples. Our solution allows domain experts such as a\ncurators to interactively reconstruct potential appearances of lost artifacts.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.08310v1",
    "published_date": "2024-02-13 09:13:30 UTC",
    "updated_date": "2024-02-13 09:13:30 UTC"
  },
  {
    "arxiv_id": "2402.08303v4",
    "title": "ChatCell: Facilitating Single-Cell Analysis with Natural Language",
    "authors": [
      "Yin Fang",
      "Kangwei Liu",
      "Ningyu Zhang",
      "Xinle Deng",
      "Penghui Yang",
      "Zhuo Chen",
      "Xiangru Tang",
      "Mark Gerstein",
      "Xiaohui Fan",
      "Huajun Chen"
    ],
    "abstract": "As Large Language Models (LLMs) rapidly evolve, their influence in science is\nbecoming increasingly prominent. The emerging capabilities of LLMs in task\ngeneralization and free-form dialogue can significantly advance fields like\nchemistry and biology. However, the field of single-cell biology, which forms\nthe foundational building blocks of living organisms, still faces several\nchallenges. High knowledge barriers and limited scalability in current methods\nrestrict the full exploitation of LLMs in mastering single-cell data, impeding\ndirect accessibility and rapid iteration. To this end, we introduce ChatCell,\nwhich signifies a paradigm shift by facilitating single-cell analysis with\nnatural language. Leveraging vocabulary adaptation and unified sequence\ngeneration, ChatCell has acquired profound expertise in single-cell biology and\nthe capability to accommodate a diverse range of analysis tasks. Extensive\nexperiments further demonstrate ChatCell's robust performance and potential to\ndeepen single-cell insights, paving the way for more accessible and intuitive\nexploration in this pivotal field. Our project homepage is available at\nhttps://zjunlp.github.io/project/ChatCell.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CE",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "I have decided to temporarily withdraw this draft as I am in the\n  process of making further revisions to improve its content. Code:\n  https://github.com/zjunlp/ChatCell Dataset:\n  https://huggingface.co/datasets/zjunlp/ChatCell-Instructions Demo:\n  https://chat.openai.com/g/g-vUwj222gQ-chatcell",
    "pdf_url": "http://arxiv.org/pdf/2402.08303v4",
    "published_date": "2024-02-13 09:06:14 UTC",
    "updated_date": "2024-02-20 02:26:39 UTC"
  },
  {
    "arxiv_id": "2402.08298v1",
    "title": "Time to Stop and Think: What kind of research do we want to do?",
    "authors": [
      "Josu Ceberio",
      "Borja Calvo"
    ],
    "abstract": "Experimentation is an intrinsic part of research in artificial intelligence\nsince it allows for collecting quantitative observations, validating\nhypotheses, and providing evidence for their reformulation. For that reason,\nexperimentation must be coherent with the purposes of the research, properly\naddressing the relevant questions in each case. Unfortunately, the literature\nis full of works whose experimentation is neither rigorous nor convincing,\noftentimes designed to support prior beliefs rather than answering the relevant\nresearch questions.\n  In this paper, we focus on the field of metaheuristic optimization, since it\nis our main field of work, and it is where we have observed the misconduct that\nhas motivated this letter. Even if we limit the focus of this manuscript to the\nexperimental part of the research, our main goal is to sew the seed of sincere\ncritical assessment of our work, sparking a reflection process both at the\nindividual and the community level. Such a reflection process is too complex\nand extensive to be tackled as a whole. Therefore, to bring our feet to the\nground, we will include in this document our reflections about the role of\nexperimentation in our work, discussing topics such as the use of benchmark\ninstances vs instance generators, or the statistical assessment of empirical\nresults. That is, all the statements included in this document are personal\nviews and opinions, which can be shared by others or not. Certainly, having\ndifferent points of view is the basis to establish a good discussion process.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.08298v1",
    "published_date": "2024-02-13 08:53:57 UTC",
    "updated_date": "2024-02-13 08:53:57 UTC"
  },
  {
    "arxiv_id": "2402.08290v3",
    "title": "The Effect of Data Poisoning on Counterfactual Explanations",
    "authors": [
      "André Artelt",
      "Shubham Sharma",
      "Freddy Lecué",
      "Barbara Hammer"
    ],
    "abstract": "Counterfactual explanations provide a popular method for analyzing the\npredictions of black-box systems, and they can offer the opportunity for\ncomputational recourse by suggesting actionable changes on how to change the\ninput to obtain a different (i.e.\\ more favorable) system output. However,\nrecent work highlighted their vulnerability to different types of\nmanipulations.\n  This work studies the vulnerability of counterfactual explanations to data\npoisoning. We formally introduce and investigate data poisoning in the context\nof counterfactual explanations for increasing the cost of recourse on three\ndifferent levels: locally for a single instance, or a sub-group of instances,\nor globally for all instances. In this context, we characterize and prove the\ncorrectness of several different data poisonings. We also empirically\ndemonstrate that state-of-the-art counterfactual generation methods and\ntoolboxes are vulnerable to such data poisoning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.08290v3",
    "published_date": "2024-02-13 08:41:32 UTC",
    "updated_date": "2024-05-21 11:37:52 UTC"
  },
  {
    "arxiv_id": "2402.08284v1",
    "title": "A Logical Approach to Criminal Case Investigation",
    "authors": [
      "Takanori Ugai",
      "Yusuke Koyanagi",
      "Fumihito Nishino"
    ],
    "abstract": "XAI (eXplanable AI) techniques that have the property of explaining the\nreasons for their conclusions, i.e. explainability or interpretability, are\nattracting attention. XAI is expected to be used in the development of forensic\nscience and the justice system. In today's forensic and criminal investigation\nenvironment, experts face many challenges due to large amounts of data, small\npieces of evidence in a chaotic and complex environment, traditional laboratory\nstructures and sometimes inadequate knowledge. All these can lead to failed\ninvestigations and miscarriages of justice. In this paper, we describe the\napplication of one logical approach to crime scene investigation. The subject\nof the application is ``The Adventure of the Speckled Band'' from the Sherlock\nHolmes short stories. The applied data is the knowledge graph created for the\nKnowledge Graph Reasoning Challenge. We tried to find the murderer by inferring\neach person with the motive, opportunity, and method. We created an ontology of\nmotives and methods of murder from dictionaries and dictionaries, added it to\nthe knowledge graph of ``The Adventure of the Speckled Band'', and applied\nscripts to determine motives, opportunities, and methods.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "11 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.08284v1",
    "published_date": "2024-02-13 08:24:32 UTC",
    "updated_date": "2024-02-13 08:24:32 UTC"
  },
  {
    "arxiv_id": "2402.08280v2",
    "title": "Pix2Code: Learning to Compose Neural Visual Concepts as Programs",
    "authors": [
      "Antonia Wüst",
      "Wolfgang Stammer",
      "Quentin Delfosse",
      "Devendra Singh Dhami",
      "Kristian Kersting"
    ],
    "abstract": "The challenge in learning abstract concepts from images in an unsupervised\nfashion lies in the required integration of visual perception and generalizable\nrelational reasoning. Moreover, the unsupervised nature of this task makes it\nnecessary for human users to be able to understand a model's learnt concepts\nand potentially revise false behaviours. To tackle both the generalizability\nand interpretability constraints of visual concept learning, we propose\nPix2Code, a framework that extends program synthesis to visual relational\nreasoning by utilizing the abilities of both explicit, compositional symbolic\nand implicit neural representations. This is achieved by retrieving object\nrepresentations from images and synthesizing relational concepts as\nlambda-calculus programs. We evaluate the diverse properties of Pix2Code on the\nchallenging reasoning domains, Kandinsky Patterns and CURI, thereby testing its\nability to identify compositional visual concepts that generalize to novel data\nand concept configurations. Particularly, in stark contrast to neural\napproaches, we show that Pix2Code's representations remain human interpretable\nand can be easily revised for improved performance.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.08280v2",
    "published_date": "2024-02-13 08:14:10 UTC",
    "updated_date": "2024-07-06 15:07:57 UTC"
  },
  {
    "arxiv_id": "2402.08269v1",
    "title": "Geometry-induced Implicit Regularization in Deep ReLU Neural Networks",
    "authors": [
      "Joachim Bona-Pellissier",
      "Fran çois Malgouyres",
      "Fran çois Bachoc"
    ],
    "abstract": "It is well known that neural networks with many more parameters than training\nexamples do not overfit. Implicit regularization phenomena, which are still not\nwell understood, occur during optimization and 'good' networks are favored.\nThus the number of parameters is not an adequate measure of complexity if we do\nnot consider all possible networks but only the 'good' ones. To better\nunderstand which networks are favored during optimization, we study the\ngeometry of the output set as parameters vary. When the inputs are fixed, we\nprove that the dimension of this set changes and that the local dimension,\ncalled batch functional dimension, is almost surely determined by the\nactivation patterns in the hidden layers. We prove that the batch functional\ndimension is invariant to the symmetries of the network parameterization:\nneuron permutations and positive rescalings. Empirically, we establish that the\nbatch functional dimension decreases during optimization. As a consequence,\noptimization leads to parameters with low batch functional dimensions. We call\nthis phenomenon geometry-induced implicit regularization.The batch functional\ndimension depends on both the network parameters and inputs. To understand the\nimpact of the inputs, we study, for fixed parameters, the largest attainable\nbatch functional dimension when the inputs vary. We prove that this quantity,\ncalled computable full functional dimension, is also invariant to the\nsymmetries of the network's parameterization, and is determined by the\nachievable activation patterns. We also provide a sampling theorem, showing a\nfast convergence of the estimation of the computable full functional dimension\nfor a random input of increasing size. Empirically we find that the computable\nfull functional dimension remains close to the number of parameters, which is\nrelated to the notion of local identifiability. This differs from the observed\nvalues for the batch functional dimension computed on training inputs and test\ninputs. The latter are influenced by geometry-induced implicit regularization.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.NE",
      "math.OC",
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.08269v1",
    "published_date": "2024-02-13 07:49:57 UTC",
    "updated_date": "2024-02-13 07:49:57 UTC"
  },
  {
    "arxiv_id": "2402.08267v2",
    "title": "Improving Image Coding for Machines through Optimizing Encoder via Auxiliary Loss",
    "authors": [
      "Kei Iino",
      "Shunsuke Akamatsu",
      "Hiroshi Watanabe",
      "Shohei Enomoto",
      "Akira Sakamoto",
      "Takeharu Eda"
    ],
    "abstract": "Image coding for machines (ICM) aims to compress images for machine analysis\nusing recognition models rather than human vision. Hence, in ICM, it is\nimportant for the encoder to recognize and compress the information necessary\nfor the machine recognition task. There are two main approaches in learned ICM;\noptimization of the compression model based on task loss, and Region of\nInterest (ROI) based bit allocation. These approaches provide the encoder with\nthe recognition capability. However, optimization with task loss becomes\ndifficult when the recognition model is deep, and ROI-based methods often\ninvolve extra overhead during evaluation. In this study, we propose a novel\ntraining method for learned ICM models that applies auxiliary loss to the\nencoder to improve its recognition capability and rate-distortion performance.\nOur method achieves Bjontegaard Delta rate improvements of 27.7% and 20.3% in\nobject detection and semantic segmentation tasks, compared to the conventional\ntraining method.\n  \\c{opyright} 2024 IEEE. Personal use of this material is permitted.\nPermission from IEEE must be obtained for all other uses, in any current or\nfuture media, including reprinting/republishing this material for advertising\nor promotional purposes, creating new collective works, for resale or\nredistribution to servers or lists, or reuse of any copyrighted component of\nthis work in other works.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at ICIP 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.08267v2",
    "published_date": "2024-02-13 07:45:25 UTC",
    "updated_date": "2024-09-28 14:05:27 UTC"
  },
  {
    "arxiv_id": "2402.08256v1",
    "title": "Modeling Balanced Explicit and Implicit Relations with Contrastive Learning for Knowledge Concept Recommendation in MOOCs",
    "authors": [
      "Hengnian Gu",
      "Zhiyi Duan",
      "Pan Xie",
      "Dongdai Zhou"
    ],
    "abstract": "The knowledge concept recommendation in Massive Open Online Courses (MOOCs)\nis a significant issue that has garnered widespread attention. Existing methods\nprimarily rely on the explicit relations between users and knowledge concepts\non the MOOC platforms for recommendation. However, there are numerous implicit\nrelations (e.g., shared interests or same knowledge levels between users)\ngenerated within the users' learning activities on the MOOC platforms. Existing\nmethods fail to consider these implicit relations, and these relations\nthemselves are difficult to learn and represent, causing poor performance in\nknowledge concept recommendation and an inability to meet users' personalized\nneeds. To address this issue, we propose a novel framework based on contrastive\nlearning, which can represent and balance the explicit and implicit relations\nfor knowledge concept recommendation in MOOCs (CL-KCRec). Specifically, we\nfirst construct a MOOCs heterogeneous information network (HIN) by modeling the\ndata from the MOOC platforms. Then, we utilize a relation-updated graph\nconvolutional network and stacked multi-channel graph neural network to\nrepresent the explicit and implicit relations in the HIN, respectively.\nConsidering that the quantity of explicit relations is relatively fewer\ncompared to implicit relations in MOOCs, we propose a contrastive learning with\nprototypical graph to enhance the representations of both relations to capture\ntheir fruitful inherent relational knowledge, which can guide the propagation\nof students' preferences within the HIN. Based on these enhanced\nrepresentations, to ensure the balanced contribution of both towards the final\nrecommendation, we propose a dual-head attention mechanism for balanced fusion.\nExperimental results demonstrate that CL-KCRec outperforms several\nstate-of-the-art baselines on real-world datasets in terms of HR, NDCG and MRR.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted to WWW 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.08256v1",
    "published_date": "2024-02-13 07:12:44 UTC",
    "updated_date": "2024-02-13 07:12:44 UTC"
  },
  {
    "arxiv_id": "2402.08255v1",
    "title": "Distal Interference: Exploring the Limits of Model-Based Continual Learning",
    "authors": [
      "Heinrich van Deventer",
      "Anna Sergeevna Bosman"
    ],
    "abstract": "Continual learning is the sequential learning of different tasks by a machine\nlearning model. Continual learning is known to be hindered by catastrophic\ninterference or forgetting, i.e. rapid unlearning of earlier learned tasks when\nnew tasks are learned. Despite their practical success, artificial neural\nnetworks (ANNs) are prone to catastrophic interference. This study analyses how\ngradient descent and overlapping representations between distant input points\nlead to distal interference and catastrophic interference. Distal interference\nrefers to the phenomenon where training a model on a subset of the domain leads\nto non-local changes on other subsets of the domain. This study shows that\nuniformly trainable models without distal interference must be exponentially\nlarge. A novel antisymmetric bounded exponential layer B-spline ANN\narchitecture named ABEL-Spline is proposed that can approximate any continuous\nfunction, is uniformly trainable, has polynomial computational complexity, and\nprovides some guarantees for distal interference. Experiments are presented to\ndemonstrate the theoretical properties of ABEL-Splines. ABEL-Splines are also\nevaluated on benchmark regression problems. It is concluded that the weaker\ndistal interference guarantees in ABEL-Splines are insufficient for model-only\ncontinual learning. It is conjectured that continual learning with polynomial\ncomplexity models requires augmentation of the training data or algorithm.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE",
      "68T07",
      "I.5.1"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.08255v1",
    "published_date": "2024-02-13 07:07:37 UTC",
    "updated_date": "2024-02-13 07:07:37 UTC"
  },
  {
    "arxiv_id": "2402.08250v1",
    "title": "A survey of recent methods for addressing AI fairness and bias in biomedicine",
    "authors": [
      "Yifan Yang",
      "Mingquan Lin",
      "Han Zhao",
      "Yifan Peng",
      "Furong Huang",
      "Zhiyong Lu"
    ],
    "abstract": "Artificial intelligence (AI) systems have the potential to revolutionize\nclinical practices, including improving diagnostic accuracy and surgical\ndecision-making, while also reducing costs and manpower. However, it is\nimportant to recognize that these systems may perpetuate social inequities or\ndemonstrate biases, such as those based on race or gender. Such biases can\noccur before, during, or after the development of AI models, making it critical\nto understand and address potential biases to enable the accurate and reliable\napplication of AI models in clinical settings. To mitigate bias concerns during\nmodel development, we surveyed recent publications on different debiasing\nmethods in the fields of biomedical natural language processing (NLP) or\ncomputer vision (CV). Then we discussed the methods that have been applied in\nthe biomedical domain to address bias. We performed our literature search on\nPubMed, ACM digital library, and IEEE Xplore of relevant articles published\nbetween January 2018 and December 2023 using multiple combinations of keywords.\nWe then filtered the result of 10,041 articles automatically with loose\nconstraints, and manually inspected the abstracts of the remaining 890 articles\nto identify the 55 articles included in this review. Additional articles in the\nreferences are also included in this review. We discuss each method and compare\nits strengths and weaknesses. Finally, we review other potential methods from\nthe general domain that could be applied to biomedicine to address bias and\nimprove fairness.The bias of AIs in biomedicine can originate from multiple\nsources. Existing debiasing methods that focus on algorithms can be categorized\ninto distributional or algorithmic.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.08250v1",
    "published_date": "2024-02-13 06:38:46 UTC",
    "updated_date": "2024-02-13 06:38:46 UTC"
  },
  {
    "arxiv_id": "2402.08246v1",
    "title": "Ant Colony Optimization for Cooperative Inspection Path Planning Using Multiple Unmanned Aerial Vehicles",
    "authors": [
      "Duy Nam Bui",
      "Thuy Ngan Duong",
      "Manh Duong Phung"
    ],
    "abstract": "This paper presents a new swarm intelligence-based approach to deal with the\ncooperative path planning problem of unmanned aerial vehicles (UAVs), which is\nessential for the automatic inspection of infrastructure. The approach uses a\n3D model of the structure to generate viewpoints for the UAVs. The calculation\nof the viewpoints considers the constraints related to the UAV formation model,\ncamera parameters, and requirements for data post-processing. The viewpoints\nare then used as input to formulate the path planning as an extended traveling\nsalesman problem and the definition of a new cost function. Ant colony\noptimization is finally used to solve the problem to yield optimal inspection\npaths. Experiments with 3D models of real structures have been conducted to\nevaluate the performance of the proposed approach. The results show that our\nsystem is not only capable of generating feasible inspection paths for UAVs but\nalso reducing the path length by 29.47\\% for complex structures when compared\nwith another heuristic approach. The source code of the algorithm can be found\nat https://github.com/duynamrcv/aco_3d_ipp.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "Published in: 2024 IEEE/SICE International Symposium on System\n  Integration (SII)",
    "pdf_url": "http://arxiv.org/pdf/2402.08246v1",
    "published_date": "2024-02-13 06:20:37 UTC",
    "updated_date": "2024-02-13 06:20:37 UTC"
  },
  {
    "arxiv_id": "2402.08242v1",
    "title": "Towards Equitable Agile Research and Development of AI and Robotics",
    "authors": [
      "Andrew Hundt",
      "Julia Schuller",
      "Severin Kacianka"
    ],
    "abstract": "Machine Learning (ML) and 'Artificial Intelligence' ('AI') methods tend to\nreplicate and amplify existing biases and prejudices, as do Robots with AI. For\nexample, robots with facial recognition have failed to identify Black Women as\nhuman, while others have categorized people, such as Black Men, as criminals\nbased on appearance alone. A 'culture of modularity' means harms are perceived\nas 'out of scope', or someone else's responsibility, throughout employment\npositions in the 'AI supply chain'. Incidents are routine enough\n(incidentdatabase.ai lists over 2000 examples) to indicate that few\norganizations are capable of completely respecting peoples' rights; meeting\nclaimed equity, diversity, and inclusion (EDI or DEI) goals; or recognizing and\nthen addressing such failures in their organizations and artifacts. We propose\na framework for adapting widely practiced Research and Development (R&D)\nproject management methodologies to build organizational equity capabilities\nand better integrate known evidence-based best practices. We describe how\nproject teams can organize and operationalize the most promising practices,\nskill sets, organizational cultures, and methods to detect and address\nrights-based fairness, equity, accountability, and ethical problems as early as\npossible when they are often less harmful and easier to mitigate; then monitor\nfor unforeseen incidents to adaptively and constructively address them. Our\nprimary example adapts an Agile development process based on Scrum, one of the\nmost widely adopted approaches to organizing R&D teams. We also discuss\nlimitations of our proposed framework and future research directions.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.LG",
      "cs.RO",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "15 pages (32 with refs + appendix), 2 figures, 1 table (7 with\n  appendix), incorporates changes based on WeRobot 2023 Draft feedback",
    "pdf_url": "http://arxiv.org/pdf/2402.08242v1",
    "published_date": "2024-02-13 06:13:17 UTC",
    "updated_date": "2024-02-13 06:13:17 UTC"
  },
  {
    "arxiv_id": "2402.08236v1",
    "title": "BERT4FCA: A Method for Bipartite Link Prediction using Formal Concept Analysis and BERT",
    "authors": [
      "Siqi Peng",
      "Hongyuan Yang",
      "Akihiro Yamamoto"
    ],
    "abstract": "We propose BERT4FCA, a novel method for link prediction in bipartite\nnetworks, using formal concept analysis (FCA) and BERT. Link prediction in\nbipartite networks is an important task that can solve various practical\nproblems like friend recommendation in social networks and co-authorship\nprediction in author-paper networks. Recent research has found that in\nbipartite networks, maximal bi-cliques provide important information for link\nprediction, and they can be extracted by FCA. Some FCA-based bipartite link\nprediction methods have achieved good performance. However, we figured out that\ntheir performance could be further improved because these methods did not fully\ncapture the rich information of the extracted maximal bi-cliques. To address\nthis limitation, we propose an approach using BERT, which can learn more\ninformation from the maximal bi-cliques extracted by FCA and use them to make\nlink prediction. We conduct experiments on three real-world bipartite networks\nand demonstrate that our method outperforms previous FCA-based methods, and\nsome classic methods such as matrix-factorization and node2vec.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "23 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.08236v1",
    "published_date": "2024-02-13 06:02:05 UTC",
    "updated_date": "2024-02-13 06:02:05 UTC"
  },
  {
    "arxiv_id": "2402.08228v2",
    "title": "Investigating Out-of-Distribution Generalization of GNNs: An Architecture Perspective",
    "authors": [
      "Kai Guo",
      "Hongzhi Wen",
      "Wei Jin",
      "Yaming Guo",
      "Jiliang Tang",
      "Yi Chang"
    ],
    "abstract": "Graph neural networks (GNNs) have exhibited remarkable performance under the\nassumption that test data comes from the same distribution of training data.\nHowever, in real-world scenarios, this assumption may not always be valid.\nConsequently, there is a growing focus on exploring the Out-of-Distribution\n(OOD) problem in the context of graphs. Most existing efforts have primarily\nconcentrated on improving graph OOD generalization from two\n\\textbf{model-agnostic} perspectives: data-driven methods and strategy-based\nlearning. However, there has been limited attention dedicated to investigating\nthe impact of well-known \\textbf{GNN model architectures} on graph OOD\ngeneralization, which is orthogonal to existing research. In this work, we\nprovide the first comprehensive investigation of OOD generalization on graphs\nfrom an architecture perspective, by examining the common building blocks of\nmodern GNNs. Through extensive experiments, we reveal that both the graph\nself-attention mechanism and the decoupled architecture contribute positively\nto graph OOD generalization. In contrast, we observe that the linear\nclassification layer tends to compromise graph OOD generalization capability.\nFurthermore, we provide in-depth theoretical insights and discussions to\nunderpin these discoveries. These insights have empowered us to develop a novel\nGNN backbone model, DGAT, designed to harness the robust properties of both\ngraph self-attention mechanism and the decoupled architecture. Extensive\nexperimental results demonstrate the effectiveness of our model under graph\nOOD, exhibiting substantial and consistent enhancements across various training\nstrategies.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.08228v2",
    "published_date": "2024-02-13 05:38:45 UTC",
    "updated_date": "2024-02-14 16:26:09 UTC"
  },
  {
    "arxiv_id": "2402.08219v2",
    "title": "BBox-Adapter: Lightweight Adapting for Black-Box Large Language Models",
    "authors": [
      "Haotian Sun",
      "Yuchen Zhuang",
      "Wei Wei",
      "Chao Zhang",
      "Bo Dai"
    ],
    "abstract": "Adapting state-of-the-art Large Language Models (LLMs) like GPT-4 and Gemini\nfor specific tasks is challenging. Due to the opacity in their parameters,\nembeddings, and even output probabilities, existing fine-tuning adaptation\nmethods are inapplicable. Consequently, adapting these black-box LLMs is only\npossible through their API services, raising concerns about transparency,\nprivacy, and cost. To address these challenges, we introduce BBox-Adapter, a\nnovel lightweight adapter for black-box LLMs. BBox-Adapter distinguishes target\nand source domain data by treating target data as positive and source data as\nnegative. It employs a ranking-based Noise Contrastive Estimation (NCE) loss to\npromote the likelihood of target domain data while penalizing that of the\nsource domain. Furthermore, it features an online adaptation mechanism, which\nincorporates real-time positive data sampling from ground-truth, human, or AI\nfeedback, coupled with negative data from previous adaptations. Extensive\nexperiments demonstrate BBox-Adapter's effectiveness and cost efficiency. It\nimproves model performance by up to 6.77% across diverse tasks and domains,\nwhile reducing training and inference costs by 31.30x and 1.84x, respectively.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "25 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.08219v2",
    "published_date": "2024-02-13 05:15:46 UTC",
    "updated_date": "2024-05-28 17:04:45 UTC"
  },
  {
    "arxiv_id": "2402.08211v1",
    "title": "Transformer Mechanisms Mimic Frontostriatal Gating Operations When Trained on Human Working Memory Tasks",
    "authors": [
      "Aaron Traylor",
      "Jack Merullo",
      "Michael J. Frank",
      "Ellie Pavlick"
    ],
    "abstract": "Models based on the Transformer neural network architecture have seen success\non a wide variety of tasks that appear to require complex \"cognitive branching\"\n-- or the ability to maintain pursuit of one goal while accomplishing others.\nIn cognitive neuroscience, success on such tasks is thought to rely on\nsophisticated frontostriatal mechanisms for selective \\textit{gating}, which\nenable role-addressable updating -- and later readout -- of information to and\nfrom distinct \"addresses\" of memory, in the form of clusters of neurons.\nHowever, Transformer models have no such mechanisms intentionally built-in. It\nis thus an open question how Transformers solve such tasks, and whether the\nmechanisms that emerge to help them to do so bear any resemblance to the gating\nmechanisms in the human brain. In this work, we analyze the mechanisms that\nemerge within a vanilla attention-only Transformer trained on a simple sequence\nmodeling task inspired by a task explicitly designed to study working memory\ngating in computational cognitive neuroscience. We find that, as a result of\ntraining, the self-attention mechanism within the Transformer specializes in a\nway that mirrors the input and output gating mechanisms which were explicitly\nincorporated into earlier, more biologically-inspired architectures. These\nresults suggest opportunities for future research on computational similarities\nbetween modern AI architectures and models of the human brain.",
    "categories": [
      "cs.AI",
      "I.2.6"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.08211v1",
    "published_date": "2024-02-13 04:28:43 UTC",
    "updated_date": "2024-02-13 04:28:43 UTC"
  },
  {
    "arxiv_id": "2402.08209v1",
    "title": "Thresholding Data Shapley for Data Cleansing Using Multi-Armed Bandits",
    "authors": [
      "Hiroyuki Namba",
      "Shota Horiguchi",
      "Masaki Hamamoto",
      "Masashi Egi"
    ],
    "abstract": "Data cleansing aims to improve model performance by removing a set of harmful\ninstances from the training dataset. Data Shapley is a common theoretically\nguaranteed method to evaluate the contribution of each instance to model\nperformance; however, it requires training on all subsets of the training data,\nwhich is computationally expensive. In this paper, we propose an\niterativemethod to fast identify a subset of instances with low data Shapley\nvalues by using the thresholding bandit algorithm. We provide a theoretical\nguarantee that the proposed method can accurately select harmful instances if a\nsufficiently large number of iterations is conducted. Empirical evaluation\nusing various models and datasets demonstrated that the proposed method\nefficiently improved the computational speed while maintaining the model\nperformance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.08209v1",
    "published_date": "2024-02-13 04:17:48 UTC",
    "updated_date": "2024-02-13 04:17:48 UTC"
  },
  {
    "arxiv_id": "2402.08208v2",
    "title": "Inherent Diverse Redundant Safety Mechanisms for AI-based Software Elements in Automotive Applications",
    "authors": [
      "Mandar Pitale",
      "Alireza Abbaspour",
      "Devesh Upadhyay"
    ],
    "abstract": "This paper explores the role and challenges of Artificial Intelligence (AI)\nalgorithms, specifically AI-based software elements, in autonomous driving\nsystems. These AI systems are fundamental in executing real-time critical\nfunctions in complex and high-dimensional environments. They handle vital tasks\nlike multi-modal perception, cognition, and decision-making tasks such as\nmotion planning, lane keeping, and emergency braking. A primary concern relates\nto the ability (and necessity) of AI models to generalize beyond their initial\ntraining data. This generalization issue becomes evident in real-time\nscenarios, where models frequently encounter inputs not represented in their\ntraining or validation data. In such cases, AI systems must still function\neffectively despite facing distributional or domain shifts. This paper\ninvestigates the risk associated with overconfident AI models in\nsafety-critical applications like autonomous driving. To mitigate these risks,\nmethods for training AI models that help maintain performance without\noverconfidence are proposed. This involves implementing certainty reporting\narchitectures and ensuring diverse training data. While various\ndistribution-based methods exist to provide safety mechanisms for AI models,\nthere is a noted lack of systematic assessment of these methods, especially in\nthe context of safety-critical automotive applications. Many methods in the\nliterature do not adapt well to the quick response times required in\nsafety-critical edge applications. This paper reviews these methods, discusses\ntheir suitability for safety-critical applications, and highlights their\nstrengths and limitations. The paper also proposes potential improvements to\nenhance the safety and reliability of AI algorithms in autonomous vehicles in\nthe context of rapid and accurate decision-making processes.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "This article is accepted for the SAE WCX 2024 conference proceedings",
    "pdf_url": "http://arxiv.org/pdf/2402.08208v2",
    "published_date": "2024-02-13 04:15:26 UTC",
    "updated_date": "2024-02-29 18:18:04 UTC"
  },
  {
    "arxiv_id": "2402.08198v1",
    "title": "PSC-CPI: Multi-Scale Protein Sequence-Structure Contrasting for Efficient and Generalizable Compound-Protein Interaction Prediction",
    "authors": [
      "Lirong Wu",
      "Yufei Huang",
      "Cheng Tan",
      "Zhangyang Gao",
      "Bozhen Hu",
      "Haitao Lin",
      "Zicheng Liu",
      "Stan Z. Li"
    ],
    "abstract": "Compound-Protein Interaction (CPI) prediction aims to predict the pattern and\nstrength of compound-protein interactions for rational drug discovery. Existing\ndeep learning-based methods utilize only the single modality of protein\nsequences or structures and lack the co-modeling of the joint distribution of\nthe two modalities, which may lead to significant performance drops in complex\nreal-world scenarios due to various factors, e.g., modality missing and domain\nshifting. More importantly, these methods only model protein sequences and\nstructures at a single fixed scale, neglecting more fine-grained multi-scale\ninformation, such as those embedded in key protein fragments. In this paper, we\npropose a novel multi-scale Protein Sequence-structure Contrasting framework\nfor CPI prediction (PSC-CPI), which captures the dependencies between protein\nsequences and structures through both intra-modality and cross-modality\ncontrasting. We further apply length-variable protein augmentation to allow\ncontrasting to be performed at different scales, from the amino acid level to\nthe sequence level. Finally, in order to more fairly evaluate the model\ngeneralizability, we split the test data into four settings based on whether\ncompounds and proteins have been observed during the training stage. Extensive\nexperiments have shown that PSC-CPI generalizes well in all four settings,\nparticularly in the more challenging ``Unseen-Both\" setting, where neither\ncompounds nor proteins have been observed during training. Furthermore, even\nwhen encountering a situation of modality missing, i.e., inference with only\nsingle-modality protein data, PSC-CPI still exhibits comparable or even better\nperformance than previous approaches.",
    "categories": [
      "q-bio.BM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.BM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.08198v1",
    "published_date": "2024-02-13 03:51:10 UTC",
    "updated_date": "2024-02-13 03:51:10 UTC"
  },
  {
    "arxiv_id": "2402.08191v2",
    "title": "THE COLOSSEUM: A Benchmark for Evaluating Generalization for Robotic Manipulation",
    "authors": [
      "Wilbert Pumacay",
      "Ishika Singh",
      "Jiafei Duan",
      "Ranjay Krishna",
      "Jesse Thomason",
      "Dieter Fox"
    ],
    "abstract": "To realize effective large-scale, real-world robotic applications, we must\nevaluate how well our robot policies adapt to changes in environmental\nconditions. Unfortunately, a majority of studies evaluate robot performance in\nenvironments closely resembling or even identical to the training setup. We\npresent THE COLOSSEUM, a novel simulation benchmark, with 20 diverse\nmanipulation tasks, that enables systematical evaluation of models across 14\naxes of environmental perturbations. These perturbations include changes in\ncolor, texture, and size of objects, table-tops, and backgrounds; we also vary\nlighting, distractors, physical properties perturbations and camera pose. Using\nTHE COLOSSEUM, we compare 5 state-of-the-art manipulation models to reveal that\ntheir success rate degrades between 30-50% across these perturbation factors.\nWhen multiple perturbations are applied in unison, the success rate degrades\n$\\geq$75%. We identify that changing the number of distractor objects, target\nobject color, or lighting conditions are the perturbations that reduce model\nperformance the most. To verify the ecological validity of our results, we show\nthat our results in simulation are correlated ($\\bar{R}^2 = 0.614$) to similar\nperturbations in real-world experiments. We open source code for others to use\nTHE COLOSSEUM, and also release code to 3D print the objects used to replicate\nthe real-world perturbations. Ultimately, we hope that THE COLOSSEUM will serve\nas a benchmark to identify modeling decisions that systematically improve\ngeneralization for manipulation. See https://robot-colosseum.github.io/ for\nmore details.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "RSS 2024. 33 pages",
    "pdf_url": "http://arxiv.org/pdf/2402.08191v2",
    "published_date": "2024-02-13 03:25:33 UTC",
    "updated_date": "2024-05-28 00:37:02 UTC"
  },
  {
    "arxiv_id": "2402.08185v1",
    "title": "Advancing Data-driven Weather Forecasting: Time-Sliding Data Augmentation of ERA5",
    "authors": [
      "Minjong Cheon",
      "Daehyun Kang",
      "Yo-Hwan Choi",
      "Seon-Yu Kang"
    ],
    "abstract": "Modern deep learning techniques, which mimic traditional numerical weather\nprediction (NWP) models and are derived from global atmospheric reanalysis\ndata, have caused a significant revolution within a few years. In this new\nparadigm, our research introduces a novel strategy that deviates from the\ncommon dependence on high-resolution data, which is often constrained by\ncomputational resources, and instead utilizes low-resolution data (2.5 degrees)\nfor global weather prediction and climate data analysis. Our main focus is\nevaluating data-driven weather prediction (DDWP) frameworks, specifically\naddressing sample size adequacy, structural improvements to the model, and the\nability of climate data to represent current climatic trends. By using the\nAdaptive Fourier Neural Operator (AFNO) model via FourCastNet and a proposed\ntime-sliding method to inflate the dataset of the ECMWF Reanalysis v5 (ERA5),\nthis paper improves on conventional approaches by adding more variables and a\nnovel approach to data augmentation and processing. Our findings reveal that\ndespite the lower resolution, the proposed approach demonstrates considerable\naccuracy in predicting atmospheric conditions, effectively rivaling\nhigher-resolution models. Furthermore, the study confirms the model's\nproficiency in reflecting current climate trends and its potential in\npredicting future climatic events, underscoring its utility in climate change\nstrategies. This research marks a pivotal step in the realm of meteorological\nforecasting, showcasing the feasibility of lower-resolution data in producing\nreliable predictions and opening avenues for more accessible and inclusive\nclimate modeling. The insights gleaned from this study not only contribute to\nthe advancement of climate science but also lay the groundwork for future\ninnovations in the field.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "physics.ao-ph"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.08185v1",
    "published_date": "2024-02-13 03:01:22 UTC",
    "updated_date": "2024-02-13 03:01:22 UTC"
  },
  {
    "arxiv_id": "2402.08184v1",
    "title": "Enabling Multi-Agent Transfer Reinforcement Learning via Scenario Independent Representation",
    "authors": [
      "Ayesha Siddika Nipu",
      "Siming Liu",
      "Anthony Harris"
    ],
    "abstract": "Multi-Agent Reinforcement Learning (MARL) algorithms are widely adopted in\ntackling complex tasks that require collaboration and competition among agents\nin dynamic Multi-Agent Systems (MAS). However, learning such tasks from scratch\nis arduous and may not always be feasible, particularly for MASs with a large\nnumber of interactive agents due to the extensive sample complexity. Therefore,\nreusing knowledge gained from past experiences or other agents could\nefficiently accelerate the learning process and upscale MARL algorithms. In\nthis study, we introduce a novel framework that enables transfer learning for\nMARL through unifying various state spaces into fixed-size inputs that allow\none unified deep-learning policy viable in different scenarios within a MAS. We\nevaluated our approach in a range of scenarios within the StarCraft Multi-Agent\nChallenge (SMAC) environment, and the findings show significant enhancements in\nmulti-agent learning performance using maneuvering skills learned from other\nscenarios compared to agents learning from scratch. Furthermore, we adopted\nCurriculum Transfer Learning (CTL), enabling our deep learning policy to\nprogressively acquire knowledge and skills across pre-designed homogeneous\nlearning scenarios organized by difficulty levels. This process promotes inter-\nand intra-agent knowledge transfer, leading to high multi-agent learning\nperformance in more complicated heterogeneous scenarios.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "2023 IEEE Conference on Games (CoG)",
    "pdf_url": "http://arxiv.org/pdf/2402.08184v1",
    "published_date": "2024-02-13 02:48:18 UTC",
    "updated_date": "2024-02-13 02:48:18 UTC"
  },
  {
    "arxiv_id": "2402.08178v1",
    "title": "LoTa-Bench: Benchmarking Language-oriented Task Planners for Embodied Agents",
    "authors": [
      "Jae-Woo Choi",
      "Youngwoo Yoon",
      "Hyobin Ong",
      "Jaehong Kim",
      "Minsu Jang"
    ],
    "abstract": "Large language models (LLMs) have recently received considerable attention as\nalternative solutions for task planning. However, comparing the performance of\nlanguage-oriented task planners becomes difficult, and there exists a dearth of\ndetailed exploration regarding the effects of various factors such as\npre-trained model selection and prompt construction. To address this, we\npropose a benchmark system for automatically quantifying performance of task\nplanning for home-service embodied agents. Task planners are tested on two\npairs of datasets and simulators: 1) ALFRED and AI2-THOR, 2) an extension of\nWatch-And-Help and VirtualHome. Using the proposed benchmark system, we perform\nextensive experiments with LLMs and prompts, and explore several enhancements\nof the baseline planner. We expect that the proposed benchmark tool would\naccelerate the development of language-oriented task planners.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "ICLR 2024. Code: https://github.com/lbaa2022/LLMTaskPlanning",
    "pdf_url": "http://arxiv.org/pdf/2402.08178v1",
    "published_date": "2024-02-13 02:28:57 UTC",
    "updated_date": "2024-02-13 02:28:57 UTC"
  },
  {
    "arxiv_id": "2402.08174v2",
    "title": "Hierarchical Position Embedding of Graphs with Landmarks and Clustering for Link Prediction",
    "authors": [
      "Minsang Kim",
      "Seungjun Baek"
    ],
    "abstract": "Learning positional information of nodes in a graph is important for link\nprediction tasks. We propose a representation of positional information using\nrepresentative nodes called landmarks. A small number of nodes with high degree\ncentrality are selected as landmarks, which serve as reference points for the\nnodes' positions. We justify this selection strategy for well-known random\ngraph models and derive closed-form bounds on the average path lengths\ninvolving landmarks. In a model for power-law graphs, we prove that landmarks\nprovide asymptotically exact information on inter-node distances. We apply\ntheoretical insights to practical networks and propose Hierarchical Position\nembedding with Landmarks and Clustering (HPLC). HPLC combines landmark\nselection and graph clustering, where the graph is partitioned into densely\nconnected clusters in which nodes with the highest degree are selected as\nlandmarks. HPLC leverages the positional information of nodes based on\nlandmarks at various levels of hierarchy such as nodes' distances to landmarks,\ninter-landmark distances and hierarchical grouping of clusters. Experiments\nshow that HPLC achieves state-of-the-art performances of link prediction on\nvarious datasets in terms of HIT@K, MRR, and AUC. The code is available at\n\\url{https://github.com/kmswin1/HPLC}.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "The International World Wide Web Conference (WWW) 2024, Accepted\n  paper",
    "pdf_url": "http://arxiv.org/pdf/2402.08174v2",
    "published_date": "2024-02-13 02:13:12 UTC",
    "updated_date": "2024-04-19 10:23:56 UTC"
  },
  {
    "arxiv_id": "2402.08170v3",
    "title": "LLaGA: Large Language and Graph Assistant",
    "authors": [
      "Runjin Chen",
      "Tong Zhao",
      "Ajay Jaiswal",
      "Neil Shah",
      "Zhangyang Wang"
    ],
    "abstract": "Graph Neural Networks (GNNs) have empowered the advance in graph-structured\ndata analysis. Recently, the rise of Large Language Models (LLMs) like GPT-4\nhas heralded a new era in deep learning. However, their application to graph\ndata poses distinct challenges due to the inherent difficulty of translating\ngraph structures to language. To this end, we introduce the Large Language and\nGraph Assistant (LLaGA), an innovative model that effectively integrates LLM\ncapabilities to handle the complexities of graph-structured data. LLaGA retains\nthe general-purpose nature of LLMs while adapting graph data into a format\ncompatible with LLM input. LLaGA achieves this by reorganizing graph nodes to\nstructure-aware sequences and then mapping these into the token embedding space\nthrough a versatile projector. LLaGA excels in versatility, generalizability\nand interpretability, allowing it to perform consistently well across different\ndatasets and tasks, extend its ability to unseen datasets or tasks, and provide\nexplanations for graphs. Our extensive experiments across popular graph\nbenchmarks show that LLaGA delivers outstanding performance across four\ndatasets and three tasks using one single model, surpassing state-of-the-art\ngraph models in both supervised and zero-shot scenarios. Our code is available\nat \\url{https://github.com/VITA-Group/LLaGA}.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.08170v3",
    "published_date": "2024-02-13 02:03:26 UTC",
    "updated_date": "2024-04-11 05:01:12 UTC"
  },
  {
    "arxiv_id": "2402.08164v2",
    "title": "On Limitations of the Transformer Architecture",
    "authors": [
      "Binghui Peng",
      "Srini Narayanan",
      "Christos Papadimitriou"
    ],
    "abstract": "What are the root causes of hallucinations in large language models (LLMs)?\nWe use Communication Complexity to prove that the Transformer layer is\nincapable of composing functions (e.g., identify a grandparent of a person in a\ngenealogy) if the domains of the functions are large enough; we show through\nexamples that this inability is already empirically present when the domains\nare quite small. We also point out that several mathematical tasks that are at\nthe core of the so-called compositional tasks thought to be hard for LLMs are\nunlikely to be solvable by Transformers, for large enough instances and\nassuming that certain well accepted conjectures in the field of Computational\nComplexity are true.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.08164v2",
    "published_date": "2024-02-13 01:52:15 UTC",
    "updated_date": "2024-02-26 22:12:37 UTC"
  },
  {
    "arxiv_id": "2402.08156v7",
    "title": "Differentially Private Distributed Inference",
    "authors": [
      "Marios Papachristou",
      "M. Amin Rahimian"
    ],
    "abstract": "How can agents exchange information to learn while protecting privacy?\nHealthcare centers collaborating on clinical trials must balance knowledge\nsharing with safeguarding sensitive patient data. We address this challenge by\nusing differential privacy (DP) to control information leakage. Agents update\nbelief statistics via log-linear rules, and DP noise provides plausible\ndeniability and rigorous performance guarantees. We study two settings:\ndistributed maximum likelihood estimation (MLE) with a finite set of private\nsignals and online learning from an intermittent signal stream. Noisy\naggregation introduces trade-offs between rejecting low-quality states and\naccepting high-quality ones. The MLE setting naturally applies to hypothesis\ntesting with formal statistical guarantees. Through simulations, we demonstrate\ndifferentially private, distributed survival analysis on real-world clinical\ntrial data, evaluating treatment efficacy and the impact of biomedical indices\non patient survival. Our methods enable privacy-preserving inference with\ngreater efficiency and lower error rates than homomorphic encryption and\nfirst-order DP optimization approaches.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.MA",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.08156v7",
    "published_date": "2024-02-13 01:38:01 UTC",
    "updated_date": "2025-03-18 03:46:15 UTC"
  },
  {
    "arxiv_id": "2402.08155v1",
    "title": "CMA-R:Causal Mediation Analysis for Explaining Rumour Detection",
    "authors": [
      "Lin Tian",
      "Xiuzhen Zhang",
      "Jey Han Lau"
    ],
    "abstract": "We apply causal mediation analysis to explain the decision-making process of\nneural models for rumour detection on Twitter. Interventions at the input and\nnetwork level reveal the causal impacts of tweets and words in the model\noutput. We find that our approach CMA-R -- Causal Mediation Analysis for Rumour\ndetection -- identifies salient tweets that explain model predictions and show\nstrong agreement with human judgements for critical tweets determining the\ntruthfulness of stories. CMA-R can further highlight causally impactful words\nin the salient tweets, providing another layer of interpretability and\ntransparency into these blackbox rumour detection systems. Code is available\nat: https://github.com/ltian678/cma-r.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages, 7 figures, Accepted by EACL 2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2402.08155v1",
    "published_date": "2024-02-13 01:31:08 UTC",
    "updated_date": "2024-02-13 01:31:08 UTC"
  },
  {
    "arxiv_id": "2402.08151v2",
    "title": "Gradient-flow adaptive importance sampling for Bayesian leave one out cross-validation with application to sigmoidal classification models",
    "authors": [
      "Joshua C Chang",
      "Xiangting Li",
      "Shixin Xu",
      "Hao-Ren Yao",
      "Julia Porcino",
      "Carson Chow"
    ],
    "abstract": "We introduce gradient-flow-guided adaptive importance sampling (IS)\ntransformations for stabilizing Monte-Carlo approximations of leave-one-out\n(LOO) cross-validated predictions for Bayesian models. After defining two\nvariational problems, we derive corresponding simple nonlinear transformations\nthat utilize gradient information to shift a model's pre-trained full-data\nposterior closer to the target LOO posterior predictive distributions. In doing\nso, the transformations stabilize importance weights. The resulting Monte Carlo\nintegrals depend on Jacobian determinants with respect to the model Hessian. We\nderive closed-form exact formulae for these Jacobian determinants in the cases\nof logistic regression and shallow ReLU-activated artificial neural networks,\nand provide a simple approximation that sidesteps the need to compute full\nHessian matrices and their spectra. We test the methodology on an $n\\ll p$\ndataset that is known to produce unstable LOO IS weights.",
    "categories": [
      "stat.ME",
      "cs.AI",
      "cs.LG",
      "math.SP",
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "stat.ME",
    "comment": "Submitted",
    "pdf_url": "http://arxiv.org/pdf/2402.08151v2",
    "published_date": "2024-02-13 01:03:39 UTC",
    "updated_date": "2024-10-20 22:42:57 UTC"
  },
  {
    "arxiv_id": "2402.08147v2",
    "title": "VerMCTS: Synthesizing Multi-Step Programs using a Verifier, a Large Language Model, and Tree Search",
    "authors": [
      "David Brandfonbrener",
      "Simon Henniger",
      "Sibi Raja",
      "Tarun Prasad",
      "Chloe Loughridge",
      "Federico Cassano",
      "Sabrina Ruixin Hu",
      "Jianang Yang",
      "William E. Byrd",
      "Robert Zinkov",
      "Nada Amin"
    ],
    "abstract": "Large Language Models (LLMs) can generate useful code, but often the code\nthey generate cannot be trusted to be sound. In this paper, we present VerMCTS,\nan approach to begin to resolve this issue by generating verified programs in\nDafny and Coq. VerMCTS uses a logical verifier in concert with an LLM to guide\na modified Monte Carlo Tree Search (MCTS). This approach leverages the verifier\nto gain intermediate feedback inside the search algorithm by checking partial\nprograms at each step to estimate an upper bound on the value function. To\nmeasure the performance of VerMCTS, we develop a new suite of multi-step\nverified programming problems in Dafny and Coq. In terms of pass@T, a new\nmetric which computes the pass rate given a budget of T tokens sampled from the\nLLM, VerMCTS leads to more than a 30% absolute increase in average pass@5000\nacross the suite over repeated sampling from the base language model. Our code\nand benchmarks are available at\nhttps://github.com/namin/llm-verified-with-monte-carlo-tree-search .",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG",
      "cs.LO",
      "cs.PL"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.08147v2",
    "published_date": "2024-02-13 00:55:14 UTC",
    "updated_date": "2024-05-24 14:51:14 UTC"
  },
  {
    "arxiv_id": "2402.08145v2",
    "title": "Epistemic Exploration for Generalizable Planning and Learning in Non-Stationary Settings",
    "authors": [
      "Rushang Karia",
      "Pulkit Verma",
      "Alberto Speranzon",
      "Siddharth Srivastava"
    ],
    "abstract": "This paper introduces a new approach for continual planning and model\nlearning in relational, non-stationary stochastic environments. Such\ncapabilities are essential for the deployment of sequential decision-making\nsystems in the uncertain and constantly evolving real world. Working in such\npractical settings with unknown (and non-stationary) transition systems and\nchanging tasks, the proposed framework models gaps in the agent's current state\nof knowledge and uses them to conduct focused, investigative explorations. Data\ncollected using these explorations is used for learning generalizable\nprobabilistic models for solving the current task despite continual changes in\nthe environment dynamics. Empirical evaluations on several non-stationary\nbenchmark domains show that this approach significantly outperforms planning\nand RL baselines in terms of sample complexity. Theoretical results show that\nthe system exhibits desirable convergence properties when stationarity holds.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "To appear at ICAPS-24",
    "pdf_url": "http://arxiv.org/pdf/2402.08145v2",
    "published_date": "2024-02-13 00:50:06 UTC",
    "updated_date": "2024-06-07 01:21:18 UTC"
  },
  {
    "arxiv_id": "2402.08144v2",
    "title": "Average-Case Analysis of Iterative Voting",
    "authors": [
      "Joshua Kavner",
      "Lirong Xia"
    ],
    "abstract": "Iterative voting is a natural model of repeated strategic decision-making in\nsocial choice when agents have the opportunity to update their votes prior to\nfinalizing the group decision. Prior work has analyzed the efficacy of\niterative plurality on the welfare of the chosen outcome at equilibrium,\nrelative to the truthful vote profile, via an adaptation of the price of\nanarchy. However, prior analyses have only studied the worst- and average-case\nperformances when agents' preferences are distributed by the impartial culture.\nThis work extends average-case analysis to a wider class of distributions and\ndistinguishes when iterative plurality improves or degrades asymptotic welfare.",
    "categories": [
      "cs.GT",
      "cs.AI"
    ],
    "primary_category": "cs.GT",
    "comment": "75 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.08144v2",
    "published_date": "2024-02-13 00:46:46 UTC",
    "updated_date": "2024-03-06 00:15:56 UTC"
  },
  {
    "arxiv_id": "2402.08143v1",
    "title": "Artificial intelligence and the transformation of higher education institutions",
    "authors": [
      "Evangelos Katsamakas",
      "Oleg V. Pavlov",
      "Ryan Saklad"
    ],
    "abstract": "Artificial intelligence (AI) advances and the rapid adoption of generative AI\ntools like ChatGPT present new opportunities and challenges for higher\neducation. While substantial literature discusses AI in higher education, there\nis a lack of a systemic approach that captures a holistic view of the AI\ntransformation of higher education institutions (HEIs). To fill this gap, this\narticle, taking a complex systems approach, develops a causal loop diagram\n(CLD) to map the causal feedback mechanisms of AI transformation in a typical\nHEI. Our model accounts for the forces that drive the AI transformation and the\nconsequences of the AI transformation on value creation in a typical HEI. The\narticle identifies and analyzes several reinforcing and balancing feedback\nloops, showing how, motivated by AI technology advances, the HEI invests in AI\nto improve student learning, research, and administration. The HEI must take\nmeasures to deal with academic integrity problems and adapt to changes in\navailable jobs due to AI, emphasizing AI-complementary skills for its students.\nHowever, HEIs face a competitive threat and several policy traps that may lead\nto decline. HEI leaders need to become systems thinkers to manage the\ncomplexity of the AI transformation and benefit from the AI feedback loops\nwhile avoiding the associated pitfalls. We also discuss long-term scenarios,\nthe notion of HEIs influencing the direction of AI, and directions for future\nresearch on AI transformation.",
    "categories": [
      "econ.GN",
      "cs.AI",
      "cs.CY",
      "q-fin.EC"
    ],
    "primary_category": "econ.GN",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.08143v1",
    "published_date": "2024-02-13 00:36:10 UTC",
    "updated_date": "2024-02-13 00:36:10 UTC"
  }
]