{
  "date": "2025-04-30",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-04-30 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 101 篇论文，主要聚焦 AI 推理、多模态模型（如 LLM 和视觉处理）、机器人应用以及医疗 AI 等前沿领域，其中 DeepSeek-Prover-V2 等论文在数学推理和 LLM 优化上令人印象深刻，作者团队包括知名学者如 Daya Guo 和 Wojciech Matusik，展示了高效算法和实际应用潜力。\n\n下面，我挑选并简要讨论了今天更新的论文，先优先聊那些重要、话题度高或有影响力的文章（如 AI 推理、机器人和医疗领域），并将相关主题归类。其他较次要的论文（如纯技术优化或较窄领域）将快速掠过，只列出标题和核心要点，以控制篇幅。\n\n### AI 推理和 LLM 相关（重点领域，讨论较多）\n- **DeepSeek-Prover-V2: Advancing Formal Mathematical Reasoning via Reinforcement Learning for Subgoal Decomposition**（中文：DeepSeek-Prover-V2：通过强化学习子目标分解提升形式数学推理）  \n  这篇论文由 Daya Guo 等知名学者主导，使用强化学习优化子目标分解，实现 88.9% 的 MiniF2F 测试通过率，并在 PutnamBench 和 AIME 问题上表现出色，主要贡献是结合非正式和形式数学推理，显著提升大语言模型在复杂证明任务中的性能。\n\n- **Phi-4-reasoning Technical Report**（中文：Phi-4-reasoning 技术报告）  \n  作者团队包括 Ahmed Awadallah 和 Besmira Nushi，提出一个 14B 参数的推理模型，通过监督微调和强化学习，显著提升数学和科学推理性能，超过同规模开源模型；关键发现是数据精炼和 RL 可减少推理冗余。\n\n- **ShorterBetter: Guiding Reasoning Models to Find Optimal Inference Length for Efficient Reasoning**（中文：ShorterBetter：指导推理模型找到最优推理长度以提升效率）  \n  这篇论文优化 LLM 推理长度，使用强化学习减少输出冗余，实现 50%-80% 的长度减少，同时保持准确性；主要贡献是引入动态奖励信号，帮助模型避免过度推理。\n\n- **WebThinker: Empowering Large Reasoning Models with Deep Research Capability**（中文：WebThinker：赋予大型推理模型深度研究能力）  \n  论文提出一个自主搜索和推理框架，使用 RAG 和 RL 优化，提升模型在知识密集任务中的表现；关键发现是模型能实时搜索网页并生成报告，显著超越现有方法。\n\n- **Ada-R1: Hybrid-CoT via Bi-Level Adaptive Reasoning Optimization**（中文：Ada-R1：通过双层自适应推理优化实现的混合思维链）  \n  这篇快速讨论，引入双层优化策略融合长短思维链，提升 LLM 效率；主要贡献是减少推理冗余，适用于复杂任务。\n\n其他 LLM 相关论文如 **Multi-Goal Dexterous Hand Manipulation using Probabilistic Model-based Reinforcement Learning** 和 **Memorization and Knowledge Injection in Gated LLMs**，快速掠过：前者优化机器人手部操作，后者探讨记忆注入，仅在特定场景提升性能。\n\n### 机器人和视觉应用（高话题度，简要扩展）\n- **CoordField: Coordination Field for Agentic UAV Task Allocation In Low-altitude Urban Scenarios**（中文：CoordField：用于低空城市场景的代理 UAV 任务分配协调场）  \n  论文提出一个基于大型语言模型的 UAV 协调框架，使用协调场机制实现动态任务分配；主要发现是系统在复杂环境中提升任务覆盖和响应时间，适合城市探索应用。\n\n- **SimPRIVE: a Simulation framework for Physical Robot Interaction with Virtual Environments**（中文：SimPRIVE：物理机器人与虚拟环境交互的模拟框架）  \n  这篇设计一个机器人模拟系统，支持物理-虚拟交互；关键贡献是提升路径规划效率，实验验证了在动态环境中的鲁棒性。\n\n- **DGFNet: End-to-End Audio-Visual Source Separation Based on Dynamic Gating Fusion**（中文：DGFNet：基于动态门控融合的端到端音频-视觉源分离）  \n  快速讨论：使用门控机制融合模态，提升分离性能；主要发现是音频-视觉协作在多媒体应用中的潜力。\n\n其他机器人论文如 **Efficient Quantum-Safe Homomorphic Encryption for Quantum Computer Programs**，快速掠过：提出量子安全加密框架，仅适用于特定计算场景。\n\n### 医疗和生物 AI（实际影响大，突出关键）\n- **Attention-enabled Explainable AI for Bladder Cancer Recurrence Prediction**（中文：注意力机制支持的可解释 AI 用于膀胱癌复发预测）  \n  论文使用注意力机制和嵌入建模，预测非肌肉浸润性膀胱癌复发，准确率达 70%；主要贡献是提供患者级解释，识别新风险因素如手术时长。\n\n- **xEEGNet: Towards Explainable AI in EEG Dementia Classification**（中文：xEEGNet：面向 EEG 痴呆分类的可解释 AI）  \n  这篇设计一个可解释 EEG 网络，减少参数并提升准确性；关键发现是模型能解释脑波模式，支持痴呆诊断。\n\n- **ArrhythmiaVision: Resource-Conscious Deep Learning Models with Visual Explanations for ECG Arrhythmia Classification**（中文：ArrhythmiaVision：资源感知的深度学习模型用于 ECG 心律失常分类）  \n  快速讨论：提出轻量模型识别心律失常，准确率达 99%，并提供视觉解释；主要贡献是适用于边缘设备。\n\n其他医疗论文如 **RAIL in the Wild: Operationalizing Responsible AI Evaluation Using Anthropic's Value Dataset**，快速掠过：使用 RAIL 框架评估 LLM 伦理行为，仅在 AI 治理中提供见解。\n\n### 其他领域（快速掠过，列出要点）\n- **Empirical Evaluation of Progressive Coding for Sparse Autoencoders**（中文：稀疏自动编码器的渐进编码实证评估）  \n  比较编码方法，提升模型效率；主要发现是权衡损失和可解释性。\n  \n- **GEOM-Drugs Revisited: Toward More Chemically Accurate Benchmarks for 3D Molecule Generation**（中文：GEOM-Drugs  revisited：针对 3D 分子生成的更精确基准）  \n  优化分子生成基准；关键贡献是修复评估错误，提升化学准确性。\n  \n- **Detecting and Mitigating Hateful Content in Multimodal Memes with Vision-Language Models**（中文：使用视觉-语言模型检测和缓解多模态模因中的仇恨内容）  \n  提出框架检测仇恨模因；主要发现是 VLMs 在内容缓解中的有效性。\n  \n其余论文如量子计算、公平性或加密主题（如 **Quantum-Safe Homomorphic Encryption** 和 **Fairness in Graph Learning**），篇幅有限，仅提核心：前者提升量子程序安全性，后者探讨图学习公平性，但影响较小，不做深入讨论。\n\n总之，今天的论文突出了 AI 推理和多模态融合的创新潜力，DeepSeek-Prover-V2 等工作可能推动数学和机器人领域进展。读者可关注这些高影响力文章，以探索实际应用。明天见！",
  "papers": [
    {
      "arxiv_id": "2505.00222v1",
      "title": "AI-Enhanced Automatic Design of Efficient Underwater Gliders",
      "title_zh": "翻译失败",
      "authors": [
        "Peter Yichen Chen",
        "Pingchuan Ma",
        "Niklas Hagemann",
        "John Romanishin",
        "Wei Wang",
        "Daniela Rus",
        "Wojciech Matusik"
      ],
      "abstract": "The development of novel autonomous underwater gliders has been hindered by\nlimited shape diversity, primarily due to the reliance on traditional design\ntools that depend heavily on manual trial and error. Building an automated\ndesign framework is challenging due to the complexities of representing glider\nshapes and the high computational costs associated with modeling complex\nsolid-fluid interactions. In this work, we introduce an AI-enhanced automated\ncomputational framework designed to overcome these limitations by enabling the\ncreation of underwater robots with non-trivial hull shapes. Our approach\ninvolves an algorithm that co-optimizes both shape and control signals,\nutilizing a reduced-order geometry representation and a differentiable\nneural-network-based fluid surrogate model. This end-to-end design workflow\nfacilitates rapid iteration and evaluation of hydrodynamic performance, leading\nto the discovery of optimal and complex hull shapes across various control\nsettings. We validate our method through wind tunnel experiments and swimming\npool gliding tests, demonstrating that our computationally designed gliders\nsurpass manually designed counterparts in terms of energy efficiency. By\naddressing challenges in efficient shape representation and neural fluid\nsurrogate models, our work paves the way for the development of highly\nefficient underwater gliders, with implications for long-range ocean\nexploration and environmental monitoring.",
      "tldr_zh": "这篇论文提出了一种AI增强的自动计算框架，用于设计高效水下滑翔机，以克服传统手动试错方法导致的形状多样性不足问题。该框架通过一个同时优化形状和控制信号的算法，结合简化几何表示和可微神经网络流体代理模型，实现端到端的快速迭代和流体动力性能评估。实验验证，包括风洞测试和游泳池滑行测试，表明AI设计的水下滑翔机在能量效率上优于手动设计版本，为远距离海洋探索和环境监测提供了新机遇。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.GR",
        "cs.LG",
        "physics.comp-ph"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00222v1",
      "published_date": "2025-04-30 23:55:44 UTC",
      "updated_date": "2025-04-30 23:55:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:07:11.618734"
    },
    {
      "arxiv_id": "2505.00216v1",
      "title": "Online Federation For Mixtures of Proprietary Agents with Black-Box Encoders",
      "title_zh": "翻译失败",
      "authors": [
        "Xuwei Yang",
        "Fatemeh Tavakoli",
        "David B. Emerson",
        "Anastasis Kratsios"
      ],
      "abstract": "Most industry-standard generative AIs and feature encoders are proprietary,\noffering only black-box access: their outputs are observable, but their\ninternal parameters and architectures remain hidden from the end-user. This\nblack-box access is especially limiting when constructing mixture-of-expert\ntype ensemble models since the user cannot optimize each proprietary AI's\ninternal parameters. Our problem naturally lends itself to a non-competitive\ngame-theoretic lens where each proprietary AI (agent) is inherently competing\nagainst the other AI agents, with this competition arising naturally due to\ntheir obliviousness of the AI's to their internal structure. In contrast, the\nuser acts as a central planner trying to synchronize the ensemble of competing\nAIs.\n  We show the existence of the unique Nash equilibrium in the online setting,\nwhich we even compute in closed-form by eliciting a feedback mechanism between\nany given time series and the sequence generated by each (proprietary) AI\nagent. Our solution is implemented as a decentralized, federated-learning\nalgorithm in which each agent optimizes their structure locally on their\nmachine without ever releasing any internal structure to the others. We obtain\nrefined expressions for pre-trained models such as transformers, random feature\nmodels, and echo-state networks. Our ``proprietary federated learning''\nalgorithm is implemented on a range of real-world and synthetic time-series\nbenchmarks. It achieves orders-of-magnitude improvements in predictive accuracy\nover natural benchmarks, of which there are surprisingly few due to this\nnatural problem still being largely unexplored.",
      "tldr_zh": "该论文探讨了处理专有黑-box 编码器的混合代理（mixtures of proprietary agents）问题，提出了一种在线联邦学习（online federation）框架，将其视为非竞争博弈论场景，其中用户作为中央规划者协调竞争代理。核心方法包括证明在线设置中唯一 Nash equilibrium 的存在，并通过反馈机制计算闭合形式解决方案，实现去中心化算法，让每个代理在本地优化结构而不共享内部参数。实验在真实和合成时间序列基准上验证了该算法，对预训练模型如 transformers 和 random feature models 取得了数个数量级的预测准确率提升，为黑-box AI 集成提供了新范式。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.GT",
        "68T05, 68T07, 91A80",
        "I.2.1; I.2.11; G.1.6"
      ],
      "primary_category": "cs.LG",
      "comment": "47 pages, 16 figures, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.00216v1",
      "published_date": "2025-04-30 23:19:37 UTC",
      "updated_date": "2025-04-30 23:19:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:07:22.601062"
    },
    {
      "arxiv_id": "2505.00749v1",
      "title": "The Coral Protocol: Open Infrastructure Connecting The Internet of Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Roman J. Georgio",
        "Caelum Forder",
        "Suman Deb",
        "Peter Carroll",
        "Önder Gürcan"
      ],
      "abstract": "The Coral Protocol is an open and decentralized collaboration infrastructure\nthat enables communication, coordination, trust and payments for The Internet\nof Agents. It addresses the growing need for interoperability in a world where\norganizations are deploying multiple specialized AI agents that must work\ntogether across domains and vendors. As a foundational platform for multi-agent\nAI ecosystems, Coral establishes a common language and coordination framework\nallowing any agent to participate in complex workflows with others. Its design\nemphasizes broad compatibility, security, and vendor neutrality, ensuring that\nagent interactions are efficient and trustworthy. In particular, Coral\nintroduces standardized messaging formats for agent communication, a modular\ncoordination mechanism for orchestrating multi-agent tasks, and secure team\nformation capabilities for dynamically assembling trusted groups of agents.\nTogether, these innovations position Coral Protocol as a cornerstone of the\nemerging \"Internet of Agents,\" unlocking new levels of automation, collective\nintelligence, and business value through open agent collaboration.",
      "tldr_zh": "本文提出 Coral Protocol，这是一个开放、去中心化的基础设施，旨在连接 Internet of Agents 并支持 AI agents 的通信、协调、信任和支付，以解决多代理系统在跨领域和供应商协作中的互操作性挑战。协议引入标准化消息格式、模块化协调机制以及安全的团队形成能力，作为多代理 AI 生态系统的通用框架，促进复杂工作流的执行。总体上，Coral Protocol 通过强调兼容性、安全性和中立性，解锁了更高的自动化、集体智能和商业价值潜力。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "31 pages, 3 figures, Whitepaper",
      "pdf_url": "http://arxiv.org/pdf/2505.00749v1",
      "published_date": "2025-04-30 22:17:13 UTC",
      "updated_date": "2025-04-30 22:17:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:07:33.894735"
    },
    {
      "arxiv_id": "2505.00204v1",
      "title": "RAIL in the Wild: Operationalizing Responsible AI Evaluation Using Anthropic's Value Dataset",
      "title_zh": "RAIL in the Wild",
      "authors": [
        "Sumit Verma",
        "Pritam Prasun",
        "Arpit Jaiswal",
        "Pritish Kumar"
      ],
      "abstract": "As AI systems become embedded in real-world applications, ensuring they meet\nethical standards is crucial. While existing AI ethics frameworks emphasize\nfairness, transparency, and accountability, they often lack actionable\nevaluation methods. This paper introduces a systematic approach using the\nResponsible AI Labs (RAIL) framework, which includes eight measurable\ndimensions to assess the normative behavior of large language models (LLMs). We\napply this framework to Anthropic's \"Values in the Wild\" dataset, containing\nover 308,000 anonymized conversations with Claude and more than 3,000 annotated\nvalue expressions. Our study maps these values to RAIL dimensions, computes\nsynthetic scores, and provides insights into the ethical behavior of LLMs in\nreal-world use.",
      "tldr_zh": "这篇论文介绍了 Responsible AI Labs (RAIL) 框架的系统性应用，用于评估大型语言模型 (LLMs) 的伦理行为。RAIL 框架包括八个可衡量的维度，旨在解决现有 AI 伦理框架中缺乏可操作评估方法的不足。研究者将该框架应用到 Anthropic 的 \"Values in the Wild\" 数据集（包含超过 30.8 万条匿名对话和 3,000 多个标注的价值表达），通过映射这些价值到 RAIL 维度并计算合成分数，提供 LLMs 在现实世界应用中的伦理行为洞见。总的来说，此方法为 AI 系统的公平性、透明度和责任性评估提供了可行的工具。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00204v1",
      "published_date": "2025-04-30 22:03:26 UTC",
      "updated_date": "2025-04-30 22:03:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:07:46.123051"
    },
    {
      "arxiv_id": "2505.00190v1",
      "title": "Empirical Evaluation of Progressive Coding for Sparse Autoencoders",
      "title_zh": "稀疏自编码器的渐进编码实证评估",
      "authors": [
        "Hans Peter",
        "Anders Søgaard"
      ],
      "abstract": "Sparse autoencoders (SAEs)\n\\citep{bricken2023monosemanticity,gao2024scalingevaluatingsparseautoencoders}\nrely on dictionary learning to extract interpretable features from neural\nnetworks at scale in an unsupervised manner, with applications to\nrepresentation engineering and information retrieval. SAEs are, however,\ncomputationally expensive \\citep{lieberum2024gemmascopeopensparse}, especially\nwhen multiple SAEs of different sizes are needed. We show that dictionary\nimportance in vanilla SAEs follows a power law. We compare progressive coding\nbased on subset pruning of SAEs -- to jointly training nested SAEs, or\nso-called {\\em Matryoshka} SAEs\n\\citep{bussmann2024learning,nabeshima2024Matryoshka} -- on a language modeling\ntask. We show Matryoshka SAEs exhibit lower reconstruction loss and recaptured\nlanguage modeling loss, as well as higher representational similarity. Pruned\nvanilla SAEs are more interpretable, however. We discuss the origins and\nimplications of this trade-off.",
      "tldr_zh": "这篇论文实证评估了渐进式编码(Progressive Coding)在稀疏自编码器(Sparse Autoencoders, SAEs)中的应用，旨在解决SAEs在提取神经网络可解释特征时面临的计算开销问题。研究者比较了基于子集修剪的渐进式编码方法与联合训练的嵌套SAEs（即Matryoshka SAEs），发现Matryoshka SAEs在重构损失、语言建模损失和表示相似性方面表现出色。另一方面，修剪的vanilla SAEs更具可解释性，论文讨论了这一性能与可解释性之间的权衡及其含义。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00190v1",
      "published_date": "2025-04-30 21:08:32 UTC",
      "updated_date": "2025-04-30 21:08:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:07:58.534436"
    },
    {
      "arxiv_id": "2505.00186v1",
      "title": "Neuroevolution of Self-Attention Over Proto-Objects",
      "title_zh": "神经进化：自注意力在原型对象上的演化",
      "authors": [
        "Rafael C. Pinto",
        "Anderson R. Tavares"
      ],
      "abstract": "Proto-objects - image regions that share common visual properties - offer a\npromising alternative to traditional attention mechanisms based on\nrectangular-shaped image patches in neural networks. Although previous work\ndemonstrated that evolving a patch-based hard-attention module alongside a\ncontroller network could achieve state-of-the-art performance in visual\nreinforcement learning tasks, our approach leverages image segmentation to work\nwith higher-level features. By operating on proto-objects rather than fixed\npatches, we significantly reduce the representational complexity: each image\ndecomposes into fewer proto-objects than regular patches, and each proto-object\ncan be efficiently encoded as a compact feature vector. This enables a\nsubstantially smaller self-attention module that processes richer semantic\ninformation. Our experiments demonstrate that this proto-object-based approach\nmatches or exceeds the state-of-the-art performance of patch-based\nimplementations with 62% less parameters and 2.6 times less training time.",
      "tldr_zh": "这篇论文探讨了基于 proto-objects（图像中共享视觉属性的区域）的 self-attention 机制，通过 neuroevolution 优化来提升视觉强化学习任务的性能。不同于传统依赖矩形图像补丁的注意力方法，该方法利用图像分割提取 proto-objects，从而显著降低表示复杂性，每个图像分解为更少的 proto-objects，并以紧凑特征向量编码。实验结果表明，这种方法在性能上匹配或超过基于补丁的基准模型，同时参数减少 62%，训练时间缩短 2.6 倍。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.NE",
      "comment": "9 pages, 16 figures, GECCO",
      "pdf_url": "http://arxiv.org/pdf/2505.00186v1",
      "published_date": "2025-04-30 21:01:20 UTC",
      "updated_date": "2025-04-30 21:01:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:08:10.195691"
    },
    {
      "arxiv_id": "2505.00174v2",
      "title": "Real-World Gaps in AI Governance Research",
      "title_zh": "翻译失败",
      "authors": [
        "Ilan Strauss",
        "Isobel Moure",
        "Tim O'Reilly",
        "Sruly Rosenblat"
      ],
      "abstract": "Drawing on 1,178 safety and reliability papers from 9,439 generative AI\npapers (January 2020 - March 2025), we compare research outputs of leading AI\ncompanies (Anthropic, Google DeepMind, Meta, Microsoft, and OpenAI) and AI\nuniversities (CMU, MIT, NYU, Stanford, UC Berkeley, and University of\nWashington). We find that corporate AI research increasingly concentrates on\npre-deployment areas -- model alignment and testing & evaluation -- while\nattention to deployment-stage issues such as model bias has waned. Significant\nresearch gaps exist in high-risk deployment domains, including healthcare,\nfinance, misinformation, persuasive and addictive features, hallucinations, and\ncopyright. Without improved observability into deployed AI, growing corporate\nconcentration could deepen knowledge deficits. We recommend expanding external\nresearcher access to deployment data and systematic observability of in-market\nAI behaviors.",
      "tldr_zh": "本研究分析了2020年1月至2025年3月的9,439篇生成AI论文，其中1,178篇涉及安全和可靠性，比较了领先AI公司（Anthropic、Google DeepMind、Meta、Microsoft和OpenAI）和AI大学（CMU、MIT、NYU、Stanford、UC Berkeley和University of Washington）的输出。结果显示，公司研究越来越集中在模型对齐和testing & evaluation等部署前领域，而对部署阶段问题如model bias的关注有所减弱。高风险领域包括healthcare、finance、misinformation、persuasive and addictive features、hallucinations和copyright等方面存在显著研究空白。作者推荐扩大外部研究者对部署数据的访问，并加强系统性observability，以缓解公司集中度带来的知识缺口。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Corrected a previous error: replaced 'underrepresented in Academic AI\n  research' with the intended phrase 'underrepresented in Corporate AI\n  research'",
      "pdf_url": "http://arxiv.org/pdf/2505.00174v2",
      "published_date": "2025-04-30 20:44:42 UTC",
      "updated_date": "2025-05-05 21:12:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:08:22.781872"
    },
    {
      "arxiv_id": "2505.00173v1",
      "title": "First Order Logic with Fuzzy Semantics for Describing and Recognizing Nerves in Medical Images",
      "title_zh": "翻译失败",
      "authors": [
        "Isabelle Bloch",
        "Enzo Bonnot",
        "Pietro Gori",
        "Giammarco La Barbera",
        "Sabine Sarnacki"
      ],
      "abstract": "This article deals with the description and recognition of fiber bundles, in\nparticular nerves, in medical images, based on the anatomical description of\nthe fiber trajectories. To this end, we propose a logical formalization of this\nanatomical knowledge. The intrinsically imprecise description of nerves, as\nfound in anatomical textbooks, leads us to propose fuzzy semantics combined\nwith first-order logic. We define a language representing spatial entities,\nrelations between these entities and quantifiers. A formula in this language is\nthen a formalization of the natural language description. The semantics are\ngiven by fuzzy representations in a concrete domain and satisfaction degrees of\nrelations. Based on this formalization, a spatial reasoning algorithm is\nproposed for segmentation and recognition of nerves from anatomical and\ndiffusion magnetic resonance images, which is illustrated on pelvic nerves in\npediatric imaging, enabling surgeons to plan surgery.",
      "tldr_zh": "本研究提出了一种基于一阶逻辑（First Order Logic）结合模糊语义（Fuzzy Semantics）的框架，用于描述和识别医疗图像中的纤维束，特别是神经。该方法形式化了神经的解剖知识，通过定义一种语言来表示空间实体、实体间关系和量词，并使用模糊表示和关系的满足度来处理描述的不精确性。基于此，研究开发了一个空间推理算法，能够从解剖和扩散磁共振图像中分割和识别神经，如儿科成像中的盆腔神经，从而辅助外科医生进行手术规划。实验结果证明了该框架的有效性，为医疗图像分析提供了更精确的工具。",
      "categories": [
        "cs.AI",
        "cs.LO",
        "math.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted for presentation at the FUZZ-IEEE 2025 conference",
      "pdf_url": "http://arxiv.org/pdf/2505.00173v1",
      "published_date": "2025-04-30 20:41:04 UTC",
      "updated_date": "2025-04-30 20:41:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:08:33.391889"
    },
    {
      "arxiv_id": "2505.00171v1",
      "title": "Attention-enabled Explainable AI for Bladder Cancer Recurrence Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Saram Abbas",
        "Naeem Soomro",
        "Rishad Shafik",
        "Rakesh Heer",
        "Kabita Adhikari"
      ],
      "abstract": "Non-muscle-invasive bladder cancer (NMIBC) is a relentless challenge in\noncology, with recurrence rates soaring as high as 70-80%. Each recurrence\ntriggers a cascade of invasive procedures, lifelong surveillance, and\nescalating healthcare costs - affecting 460,000 individuals worldwide. However,\nexisting clinical prediction tools remain fundamentally flawed, often\noverestimating recurrence risk and failing to provide personalized insights for\npatient management. In this work, we propose an interpretable deep learning\nframework that integrates vector embeddings and attention mechanisms to improve\nNMIBC recurrence prediction performance. We incorporate vector embeddings for\ncategorical variables such as smoking status and intravesical treatments,\nallowing the model to capture complex relationships between patient attributes\nand recurrence risk. These embeddings provide a richer representation of the\ndata, enabling improved feature interactions and enhancing prediction\nperformance. Our approach not only enhances performance but also provides\nclinicians with patient-specific insights by highlighting the most influential\nfeatures contributing to recurrence risk for each patient. Our model achieves\naccuracy of 70% with tabular data, outperforming conventional statistical\nmethods while providing clinician-friendly patient-level explanations through\nfeature attention. Unlike previous studies, our approach identifies new\nimportant factors influencing recurrence, such as surgical duration and\nhospital stay, which had not been considered in existing NMIBC prediction\nmodels.",
      "tldr_zh": "本研究针对非肌层浸润性膀胱癌 (NMIBC) 的高复发率（高达70-80%），提出了一种可解释的深度学习框架，利用注意力机制 (attention mechanisms) 和向量嵌入 (vector embeddings) 来提升复发风险预测的准确性和个性化见解。框架通过处理分类变量（如吸烟状态和膀胱内治疗），捕捉患者属性与风险之间的复杂关系，并为临床医生提供患者级解释，突出关键影响因素。实验结果显示，该模型在表格数据上达到70%的准确率，优于传统统计方法，并首次识别出手术持续时间和住院时间等新影响因素，为NMIBC患者管理提供更可靠的工具。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages, 5 figures, Accepted to be presented at the 47th Annual\n  International Conference of the IEEE Engineering in Medicine and Biology\n  Society (EMBC 2025)",
      "pdf_url": "http://arxiv.org/pdf/2505.00171v1",
      "published_date": "2025-04-30 20:39:33 UTC",
      "updated_date": "2025-04-30 20:39:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:08:47.852002"
    },
    {
      "arxiv_id": "2505.00169v2",
      "title": "GEOM-Drugs Revisited: Toward More Chemically Accurate Benchmarks for 3D Molecule Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Filipp Nikitin",
        "Ian Dunn",
        "David Ryan Koes",
        "Olexandr Isayev"
      ],
      "abstract": "Deep generative models have shown significant promise in generating valid 3D\nmolecular structures, with the GEOM-Drugs dataset serving as a key benchmark.\nHowever, current evaluation protocols suffer from critical flaws, including\nincorrect valency definitions, bugs in bond order calculations, and reliance on\nforce fields inconsistent with the reference data. In this work, we revisit\nGEOM-Drugs and propose a corrected evaluation framework: we identify and fix\nissues in data preprocessing, construct chemically accurate valency tables, and\nintroduce a GFN2-xTB-based geometry and energy benchmark. We retrain and\nre-evaluate several leading models under this framework, providing updated\nperformance metrics and practical recommendations for future benchmarking. Our\nresults underscore the need for chemically rigorous evaluation practices in 3D\nmolecular generation. Our recommended evaluation methods and GEOM-Drugs\nprocessing scripts are available at\nhttps://github.com/isayevlab/geom-drugs-3dgen-evaluation.",
      "tldr_zh": "本文重新审视 GEOM-Drugs 数据集，指出其作为 3D 分子生成基准时存在的关键问题，包括 valency 定义错误、bond order 计算 bug 以及与参考数据不一致的 force fields。研究者提出一个修正的评估框架，通过修复数据预处理问题、构建准确的 valency 表，并引入基于 GFN2-xTB 的几何和能量基准，来提升化学准确性。他们重新训练和评估了几种领先模型，提供更新的性能指标，并强调了在 3D 分子生成中采用严格化学评估实践的必要性；相关方法和脚本可从 https://github.com/isayevlab/geom-drugs-3dgen-evaluation 获取。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00169v2",
      "published_date": "2025-04-30 20:29:22 UTC",
      "updated_date": "2025-05-16 03:27:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:08:58.521365"
    },
    {
      "arxiv_id": "2505.00150v1",
      "title": "Detecting and Mitigating Hateful Content in Multimodal Memes with Vision-Language Models",
      "title_zh": "使用视觉语言模型检测和缓解多模态模因中的仇恨内容",
      "authors": [
        "Minh-Hao Van",
        "Xintao Wu"
      ],
      "abstract": "The rapid evolution of social media has provided enhanced communication\nchannels for individuals to create online content, enabling them to express\ntheir thoughts and opinions. Multimodal memes, often utilized for playful or\nhumorous expressions with visual and textual elements, are sometimes misused to\ndisseminate hate speech against individuals or groups. While the detection of\nhateful memes is well-researched, developing effective methods to transform\nhateful content in memes remains a significant challenge. Leveraging the\npowerful generation and reasoning capabilities of Vision-Language Models\n(VLMs), we address the tasks of detecting and mitigating hateful content. This\npaper presents two key contributions: first, a definition-guided prompting\ntechnique for detecting hateful memes, and second, a unified framework for\nmitigating hateful content in memes, named UnHateMeme, which works by replacing\nhateful textual and/or visual components. With our definition-guided prompts,\nVLMs achieve impressive performance on hateful memes detection task.\nFurthermore, our UnHateMeme framework, integrated with VLMs, demonstrates a\nstrong capability to convert hateful memes into non-hateful forms that meet\nhuman-level criteria for hate speech and maintain multimodal coherence between\nimage and text. Through empirical experiments, we show the effectiveness of\nstate-of-the-art pretrained VLMs such as LLaVA, Gemini and GPT-4o on the\nproposed tasks, providing a comprehensive analysis of their respective\nstrengths and limitations for these tasks. This paper aims to shed light on\nimportant applications of VLMs for ensuring safe and respectful online\nenvironments.",
      "tldr_zh": "本文利用 Vision-Language Models (VLMs) 检测和缓解多模态模因中的仇恨内容，解决现有方法在转化仇恨元素方面的挑战。论文的主要贡献包括：提出 definition-guided prompting 技术，以提高仇恨模因的检测准确性；以及开发 UnHateMeme 框架，通过替换仇恨的文本和/或视觉组件，将模因转化为非仇恨形式，同时保持多模态一致性。实验结果显示，VLMs 如 LLaVA、Gemini 和 GPT-4o 在这些任务上表现出色，显著提升了性能，并分析了它们的优势和局限性。该研究为构建安全、尊重的在线环境提供了重要见解。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00150v1",
      "published_date": "2025-04-30 19:48:12 UTC",
      "updated_date": "2025-04-30 19:48:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:09:10.987053"
    },
    {
      "arxiv_id": "2505.03788v1",
      "title": "Calibrating Uncertainty Quantification of Multi-Modal LLMs using Grounding",
      "title_zh": "基于 Grounding 校",
      "authors": [
        "Trilok Padhi",
        "Ramneet Kaur",
        "Adam D. Cobb",
        "Manoj Acharya",
        "Anirban Roy",
        "Colin Samplawski",
        "Brian Matejek",
        "Alexander M. Berenbeim",
        "Nathaniel D. Bastian",
        "Susmit Jha"
      ],
      "abstract": "We introduce a novel approach for calibrating uncertainty quantification (UQ)\ntailored for multi-modal large language models (LLMs). Existing\nstate-of-the-art UQ methods rely on consistency among multiple responses\ngenerated by the LLM on an input query under diverse settings. However, these\napproaches often report higher confidence in scenarios where the LLM is\nconsistently incorrect. This leads to a poorly calibrated confidence with\nrespect to accuracy. To address this, we leverage cross-modal consistency in\naddition to self-consistency to improve the calibration of the multi-modal\nmodels. Specifically, we ground the textual responses to the visual inputs. The\nconfidence from the grounding model is used to calibrate the overall\nconfidence. Given that using a grounding model adds its own uncertainty in the\npipeline, we apply temperature scaling - a widely accepted parametric\ncalibration technique - to calibrate the grounding model's confidence in the\naccuracy of generated responses. We evaluate the proposed approach across\nmultiple multi-modal tasks, such as medical question answering (Slake) and\nvisual question answering (VQAv2), considering multi-modal models such as\nLLaVA-Med and LLaVA. The experiments demonstrate that the proposed framework\nachieves significantly improved calibration on both tasks.",
      "tldr_zh": "本研究提出了一种新型方法，用于校准多模态大语言模型（Multi-Modal LLMs）的不确定性量化（UQ），通过引入grounding来整合跨模态一致性，解决现有方法在模型错误时仍高估置信度的缺陷。该方法将文本响应grounding到视觉输入，利用grounding模型的置信度校准整体置信度，并应用temperature scaling来进一步校准grounding模型的不确定性。在Slake（医疗问答）和VQAv2（视觉问答）等任务上，使用LLaVA-Med和LLaVA模型的实验表明，该框架显著提高了校准性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03788v1",
      "published_date": "2025-04-30 19:19:21 UTC",
      "updated_date": "2025-04-30 19:19:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:09:22.869682"
    },
    {
      "arxiv_id": "2505.00136v1",
      "title": "GPRat: Gaussian Process Regression with Asynchronous Tasks",
      "title_zh": "GPRat：高斯过程回归与异步任务",
      "authors": [
        "Maksim Helmann",
        "Alexander Strack",
        "Dirk Pflüger"
      ],
      "abstract": "Python is the de-facto language for software development in artificial\nintelligence (AI). Commonly used libraries, such as PyTorch and TensorFlow,\nrely on parallelization built into their BLAS backends to achieve speedup on\nCPUs. However, only applying parallelization in a low-level backend can lead to\nperformance and scaling degradation. In this work, we present a novel way of\nbinding task-based C++ code built on the asynchronous runtime model HPX to a\nhigh-level Python API using pybind11. We develop a parallel Gaussian process\n(GP) li- brary as an application. The resulting Python library GPRat combines\nthe ease of use of commonly available GP libraries with the performance and\nscalability of asynchronous runtime systems. We evaluate the per- formance on a\nmass-spring-damper system, a standard benchmark from control theory, for\nvarying numbers of regressors (features). The results show almost no binding\noverhead when binding the asynchronous HPX code using pybind11. Compared to\nGPyTorch and GPflow, GPRat shows superior scaling on up to 64 cores on an AMD\nEPYC 7742 CPU for train- ing. Furthermore, our library achieves a prediction\nspeedup of 7.63 over GPyTorch and 25.25 over GPflow. If we increase the number\nof features from eight to 128, we observe speedups of 29.62 and 21.19,\nrespectively. These results showcase the potential of using asynchronous tasks\nwithin Python-based AI applications.",
      "tldr_zh": "这篇论文介绍了 GPRat，一种基于异步任务的 Gaussian Process Regression 库，通过 pybind11 将基于异步运行时模型 HPX 的 C++ 代码绑定到 Python API，以提升 AI 软件的性能和可扩展性。GPRat 结合了现有 GP 库的易用性与异步系统的优势，在一个质量-弹簧-阻尼器系统基准测试中，显示出几乎无绑定开销，并在多达 64 核的 AMD EPYC 7742 CPU 上实现优越的训练扩展性。实验结果表明，GPRat 的预测速度比 GPyTorch 快 7.63 倍，比 GPflow 快 25.25 倍，且当特征数从 8 增加到 128 时，速度优势进一步扩大至 29.62 倍和 21.19 倍。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.00136v1",
      "published_date": "2025-04-30 19:08:51 UTC",
      "updated_date": "2025-04-30 19:08:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:09:35.558845"
    },
    {
      "arxiv_id": "2505.00127v1",
      "title": "Between Underthinking and Overthinking: An Empirical Study of Reasoning Length and correctness in LLMs",
      "title_zh": "欠思考与过度思考之间：大语言模型中推理长度与正确性的实证研究",
      "authors": [
        "Jinyan Su",
        "Jennifer Healey",
        "Preslav Nakov",
        "Claire Cardie"
      ],
      "abstract": "Large language models (LLMs) are increasingly optimized for long reasoning,\nunder the assumption that more reasoning leads to better performance. However,\nemerging evidence suggests that longer responses can sometimes degrade accuracy\nrather than improve it. In this paper, we conduct a systematic empirical study\nof the relationship between reasoning length and answer correctness. We find\nthat LLMs tend to overthink simple problems, generating unnecessarily long\noutputs, and underthink harder ones, failing to extend their reasoning when it\nis most needed. This indicates that models might misjudge problem difficulty\nand fail to calibrate their response length appropriately. Furthermore, we\ninvestigate the effects of length reduction with a preference optimization\nalgorithm when simply preferring the shorter responses regardless of answer\ncorrectness. Experiments show that the generation length can be significantly\nreduced while maintaining acceptable accuracy. Our findings highlight\ngeneration length as a meaningful signal for reasoning behavior and motivate\nfurther exploration into LLMs' self-awareness in reasoning length adaptation.",
      "tldr_zh": "本研究通过实证分析探讨了LLMs中推理长度与答案正确性的关系，发现LLMs在简单问题上倾向于过度思考（overthinking），生成过长的输出，而在困难问题上则不足思考（underthinking），未能适时扩展推理，导致准确性下降。研究表明，模型可能误判问题难度，无法有效校准响应长度。为此，作者使用偏好优化算法优先较短响应，结果显示生成长度可显著减少，同时保持可接受的准确性。这些发现将生成长度视为LLMs推理行为的有效信号，并鼓励进一步探索模型在推理长度适应方面的自我意识。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00127v1",
      "published_date": "2025-04-30 18:48:06 UTC",
      "updated_date": "2025-04-30 18:48:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:09:46.704895"
    },
    {
      "arxiv_id": "2505.00114v1",
      "title": "Fine-Tuning LLMs for Low-Resource Dialect Translation: The Case of Lebanese",
      "title_zh": "翻译失败",
      "authors": [
        "Silvana Yakhni",
        "Ali Chehab"
      ],
      "abstract": "This paper examines the effectiveness of Large Language Models (LLMs) in\ntranslating the low-resource Lebanese dialect, focusing on the impact of\nculturally authentic data versus larger translated datasets. We compare three\nfine-tuning approaches: Basic, contrastive, and grammar-hint tuning, using\nopen-source Aya23 models. Experiments reveal that models fine-tuned on a\nsmaller but culturally aware Lebanese dataset (LW) consistently outperform\nthose trained on larger, non-native data. The best results were achieved\nthrough contrastive fine-tuning paired with contrastive prompting, which\nindicates the benefits of exposing translation models to bad examples. In\naddition, to ensure authentic evaluation, we introduce LebEval, a new benchmark\nderived from native Lebanese content, and compare it to the existing FLoRes\nbenchmark. Our findings challenge the \"More Data is Better\" paradigm and\nemphasize the crucial role of cultural authenticity in dialectal translation.\nWe made our datasets and code available on Github.",
      "tldr_zh": "本研究探讨了微调大型语言模型（LLMs）以翻译低资源方言（如黎巴嫩方言）的有效性，比较了文化真实数据与更大翻译数据集的影响。研究者评估了三种微调方法：Basic Tuning、Contrastive Tuning 和 Grammar-Hint Tuning，使用开源 Aya23 模型，结果显示，使用较小但文化相关的黎巴嫩数据集（LW）微调的模型在性能上优于那些基于更大非本土数据集的模型。最佳效果来自 Contrastive Fine-Tuning 结合 Contrastive Prompting，这突显了暴露模型于不良示例的益处。研究还引入了新的基准 LebEval，由本土黎巴嫩内容衍生而来，并与现有 FLoRes 基准比较，挑战了“更多数据更好”的理念，并强调文化真实性在方言翻译中的关键作用。数据集和代码已在 Github 上公开。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00114v1",
      "published_date": "2025-04-30 18:33:53 UTC",
      "updated_date": "2025-04-30 18:33:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:10:00.557141"
    },
    {
      "arxiv_id": "2505.03787v1",
      "title": "ArrhythmiaVision: Resource-Conscious Deep Learning Models with Visual Explanations for ECG Arrhythmia Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Zuraiz Baig",
        "Sidra Nasir",
        "Rizwan Ahmed Khan",
        "Muhammad Zeeshan Ul Haque"
      ],
      "abstract": "Cardiac arrhythmias are a leading cause of life-threatening cardiac events,\nhighlighting the urgent need for accurate and timely detection.\nElectrocardiography (ECG) remains the clinical gold standard for arrhythmia\ndiagnosis; however, manual interpretation is time-consuming, dependent on\nclinical expertise, and prone to human error. Although deep learning has\nadvanced automated ECG analysis, many existing models abstract away the\nsignal's intrinsic temporal and morphological features, lack interpretability,\nand are computationally intensive-hindering their deployment on\nresource-constrained platforms. In this work, we propose two novel lightweight\n1D convolutional neural networks, ArrhythmiNet V1 and V2, optimized for\nefficient, real-time arrhythmia classification on edge devices. Inspired by\nMobileNet's depthwise separable convolutional design, these models maintain\nmemory footprints of just 302.18 KB and 157.76 KB, respectively, while\nachieving classification accuracies of 0.99 (V1) and 0.98 (V2) on the MIT-BIH\nArrhythmia Dataset across five classes: Normal Sinus Rhythm, Left Bundle Branch\nBlock, Right Bundle Branch Block, Atrial Premature Contraction, and Premature\nVentricular Contraction. In order to ensure clinical transparency and\nrelevance, we integrate Shapley Additive Explanations and Gradient-weighted\nClass Activation Mapping, enabling both local and global interpretability.\nThese techniques highlight physiologically meaningful patterns such as the QRS\ncomplex and T-wave that contribute to the model's predictions. We also discuss\nperformance-efficiency trade-offs and address current limitations related to\ndataset diversity and generalizability. Overall, our findings demonstrate the\nfeasibility of combining interpretability, predictive accuracy, and\ncomputational efficiency in practical, wearable, and embedded ECG monitoring\nsystems.",
      "tldr_zh": "这篇论文针对心律失常检测的挑战，提出两个轻量级1D卷积神经网络ArrhythmiNet V1和V2，优化用于边缘设备的实时ECG分类，受MobileNet设计启发，确保内存占用仅为302.18 KB和157.76 KB。模型在MIT-BIH Arrhythmia Dataset上实现了0.99（V1）和0.98（V2）的准确率，成功分类五类心律失常，包括Normal Sinus Rhythm和Premature Ventricular Contraction。论文整合Shapley Additive Explanations和Gradient-weighted Class Activation Mapping，提供视觉解释，突出生理模式如QRS复合波和T波，提升了临床透明度和可解释性。总体上，这展示了在可穿戴ECG系统中结合高准确率、计算效率和解释性的可行性，同时讨论了数据集多样性与泛化性的限制。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages and 08 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.03787v1",
      "published_date": "2025-04-30 18:22:45 UTC",
      "updated_date": "2025-04-30 18:22:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:10:12.490358"
    },
    {
      "arxiv_id": "2505.00100v1",
      "title": "Evaluating the AI-Lab Intervention: Impact on Student Perception and Use of Generative AI in Early Undergraduate Computer Science Courses",
      "title_zh": "翻译失败",
      "authors": [
        "Ethan Dickey",
        "Andres Bejarano",
        "Rhianna Kuperus",
        "Bárbara Fagundes"
      ],
      "abstract": "Generative AI (GenAI) is rapidly entering computer science education, yet its\neffects on student learning, skill development, and perceptions remain\nunderexplored. Concerns about overreliance coexist with a gap in research on\nstructured scaffolding to guide tool use in formal courses. This study examines\nthe impact of a dedicated \"AI-Lab\" intervention -- emphasizing guided\nscaffolding and mindful engagement -- on undergraduate students in Data\nStructures and Algorithms, Competitive Programming, and first-year engineering\ncourses at Purdue University.\n  Over three semesters, we integrated AI-Lab modules into four mandatory and\nelective courses, yielding 831 matched pre- and post-intervention survey\nresponses, alongside focus group discussions. Employing a mixed-methods\napproach, we analyzed quantitative shifts in usage patterns and attitudes as\nwell as qualitative narratives of student experiences.\n  While the overall frequency of GenAI usage for homework or programming\nprojects remained largely stable, we observed large effect sizes in comfort and\nopenness across conceptual, debugging, and homework problems. Notably, usage\npatterns for debugging also shifted statistically significantly, reflecting\nstudents' more mindful and deliberate approach. Focus group discussions\ncorroborated these results, suggesting that the intervention \"bridged the gap\"\nbetween naive GenAI usage and more nuanced, reflective integration of AI tools\ninto coursework, ultimately heightening students' awareness of their own skill\ndevelopment.\n  These findings suggest that structured, scaffolded interventions can enable\nstudents to harness GenAI's benefits without undermining essential\ncompetencies. We offer evidence-based recommendations for educators seeking to\nintegrate GenAI responsibly into computing curricula and identify avenues for\nfuture research on GenAI-supported pedagogy.",
      "tldr_zh": "这篇论文评估了在普渡大学本科计算机科学课程中引入“AI-Lab”干预措施对学生对Generative AI (GenAI)感知和使用的影响，该干预强调指导性支架和有意识参与，针对数据结构、算法和工程课程。研究通过三个学期的混合方法分析，包括831份匹配的预后调查和焦点小组讨论，发现尽管GenAI在作业中的整体使用频率稳定，但学生的舒适度、开放度和调试使用模式均有显著改善，促使更注重反思性整合。最终，论文证明结构化的干预能让学生有效利用GenAI的好处而不损害核心技能，并为教育者提供基于证据的整合推荐和未来研究方向。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.ET",
        "K.3"
      ],
      "primary_category": "cs.CY",
      "comment": "18 pages, 5 figures, 17 tables, submitted for publication",
      "pdf_url": "http://arxiv.org/pdf/2505.00100v1",
      "published_date": "2025-04-30 18:12:42 UTC",
      "updated_date": "2025-04-30 18:12:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:10:23.458239"
    },
    {
      "arxiv_id": "2505.00091v2",
      "title": "CoordField: Coordination Field for Agentic UAV Task Allocation In Low-altitude Urban Scenarios",
      "title_zh": "翻译失败",
      "authors": [
        "Tengchao Zhang",
        "Yonglin Tian",
        "Fei Lin",
        "Jun Huang",
        "Patrik P. Süli",
        "Rui Qin",
        "Fei-Yue Wang"
      ],
      "abstract": "With the increasing demand for heterogeneous Unmanned Aerial Vehicle (UAV)\nswarms to perform complex tasks in urban environments, system design now faces\nmajor challenges, including efficient semantic understanding, flexible task\nplanning, and the ability to dynamically adjust coordination strategies in\nresponse to evolving environmental conditions and continuously changing task\nrequirements. To address the limitations of existing approaches, this paper\nproposes coordination field agentic system for coordinating heterogeneous UAV\nswarms in complex urban scenarios. In this system, large language models (LLMs)\nis responsible for interpreting high-level human instructions and converting\nthem into executable commands for the UAV swarms, such as patrol and target\ntracking. Subsequently, a Coordination field mechanism is proposed to guide UAV\nmotion and task selection, enabling decentralized and adaptive allocation of\nemergent tasks. A total of 50 rounds of comparative testing were conducted\nacross different models in a 2D simulation space to evaluate their performance.\nExperimental results demonstrate that the proposed system achieves superior\nperformance in terms of task coverage, response time, and adaptability to\ndynamic changes.",
      "tldr_zh": "这篇论文针对异构 Unmanned Aerial Vehicle (UAV) 群在城市环境中执行复杂任务的挑战，提出了 Coordination Field 代理系统，以实现高效语义理解、灵活任务规划和动态协调策略。该系统利用 large language models (LLMs) 来解释高层人类指令并转换为可执行命令，如巡逻和目标跟踪，同时通过 Coordination Field 机制引导 UAV 的运动和任务选择，实现去中心化和自适应分配。在 2D 模拟实验中，该系统在 50 轮测试中表现出色，任务覆盖率、响应时间和对动态变化的适应性均优于基线模型。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Submitted ITSC 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.00091v2",
      "published_date": "2025-04-30 18:02:45 UTC",
      "updated_date": "2025-05-03 16:45:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:10:34.349419"
    },
    {
      "arxiv_id": "2504.21851v1",
      "title": "TRUST: An LLM-Based Dialogue System for Trauma Understanding and Structured Assessments",
      "title_zh": "TRUST：一种基于LLM的对话系统，用于创伤理解和结构化评估",
      "authors": [
        "Sichang Tu",
        "Abigail Powers",
        "Stephen Doogan",
        "Jinho D. Choi"
      ],
      "abstract": "Objectives: While Large Language Models (LLMs) have been widely used to\nassist clinicians and support patients, no existing work has explored dialogue\nsystems for standard diagnostic interviews and assessments. This study aims to\nbridge the gap in mental healthcare accessibility by developing an LLM-powered\ndialogue system that replicates clinician behavior. Materials and Methods: We\nintroduce TRUST, a framework of cooperative LLM modules capable of conducting\nformal diagnostic interviews and assessments for Post-Traumatic Stress Disorder\n(PTSD). To guide the generation of appropriate clinical responses, we propose a\nDialogue Acts schema specifically designed for clinical interviews.\nAdditionally, we develop a patient simulation approach based on real-life\ninterview transcripts to replace time-consuming and costly manual testing by\nclinicians. Results: A comprehensive set of evaluation metrics is designed to\nassess the dialogue system from both the agent and patient simulation\nperspectives. Expert evaluations by conversation and clinical specialists show\nthat TRUST performs comparably to real-life clinical interviews. Discussion:\nOur system performs at the level of average clinicians, with room for future\nenhancements in communication styles and response appropriateness. Conclusions:\nOur TRUST framework shows its potential to facilitate mental healthcare\navailability.",
      "tldr_zh": "本研究开发了TRUST框架，这是一个基于Large Language Models (LLMs)的对话系统，旨在通过模拟临床行为进行创伤后应激障碍(PTSD)的正式诊断访谈和评估，从而提升心理保健的可及性。方法包括提出一个专门的Dialogue Acts schema来指导临床响应生成，并采用基于真实访谈记录的患者模拟方法，以替代耗时的手动测试。结果显示，通过全面评估指标和专家评估，TRUST的表现与真实临床访谈相当，达到平均临床医生的水平，并展示了其在未来改进通信风格后进一步促进心理保健可用性的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "5 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.21851v1",
      "published_date": "2025-04-30 17:58:06 UTC",
      "updated_date": "2025-04-30 17:58:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:10:46.500171"
    },
    {
      "arxiv_id": "2504.21849v1",
      "title": "Public Opinion and The Rise of Digital Minds: Perceived Risk, Trust, and Regulation Support",
      "title_zh": "翻译失败",
      "authors": [
        "Justin B. Bullock",
        "Janet V. T. Pauketat",
        "Hsini Huang",
        "Yi-Fan Wang",
        "Jacy Reese Anthis"
      ],
      "abstract": "Governance institutions must respond to societal risks, including those posed\nby generative AI. This study empirically examines how public trust in\ninstitutions and AI technologies, along with perceived risks, shape preferences\nfor AI regulation. Using the nationally representative 2023 Artificial\nIntelligence, Morality, and Sentience (AIMS) survey, we assess trust in\ngovernment, AI companies, and AI technologies, as well as public support for\nregulatory measures such as slowing AI development or outright bans on advanced\nAI. Our findings reveal broad public support for AI regulation, with risk\nperception playing a significant role in shaping policy preferences.\nIndividuals with higher trust in government favor regulation, while those with\ngreater trust in AI companies and AI technologies are less inclined to support\nrestrictions. Trust in government and perceived risks significantly predict\npreferences for both soft (e.g., slowing development) and strong (e.g., banning\nAI systems) regulatory interventions. These results highlight the importance of\npublic opinion in AI governance. As AI capabilities advance, effective\nregulation will require balancing public concerns about risks with trust in\ninstitutions. This study provides a foundational empirical baseline for\npolicymakers navigating AI governance and underscores the need for further\nresearch into public trust, risk perception, and regulatory strategies in the\nevolving AI landscape.",
      "tldr_zh": "这项研究使用2023年Artificial Intelligence, Morality, and Sentience (AIMS)调查数据，探讨了公众对AI技术的perceived risk和trust如何影响对AI监管的支持，包括信任政府、AI公司和AI技术。结果显示，公众广泛支持AI监管，风险感知是主要驱动因素，而对政府的trust会增加对监管的偏好，对AI公司和技术的trust则会减少支持。研究发现，trust in government和perceived risks显著预测软性（如放缓AI发展）和硬性（如禁止AI系统）监管干预，并强调公众意见在AI governance中的重要性，为政策制定提供实证基础，并呼吁进一步研究以平衡风险与信任。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "31 pages, 1 figure, 5 tables, accepted to Public Performance and\n  Management Review",
      "pdf_url": "http://arxiv.org/pdf/2504.21849v1",
      "published_date": "2025-04-30 17:56:23 UTC",
      "updated_date": "2025-04-30 17:56:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:10:57.787104"
    },
    {
      "arxiv_id": "2504.21848v1",
      "title": "Characterizing AI Agents for Alignment and Governance",
      "title_zh": "翻译失败",
      "authors": [
        "Atoosa Kasirzadeh",
        "Iason Gabriel"
      ],
      "abstract": "The creation of effective governance mechanisms for AI agents requires a\ndeeper understanding of their core properties and how these properties relate\nto questions surrounding the deployment and operation of agents in the world.\nThis paper provides a characterization of AI agents that focuses on four\ndimensions: autonomy, efficacy, goal complexity, and generality. We propose\ndifferent gradations for each dimension, and argue that each dimension raises\nunique questions about the design, operation, and governance of these systems.\nMoreover, we draw upon this framework to construct \"agentic profiles\" for\ndifferent kinds of AI agents. These profiles help to illuminate cross-cutting\ntechnical and non-technical governance challenges posed by different classes of\nAI agents, ranging from narrow task-specific assistants to highly autonomous\ngeneral-purpose systems. By mapping out key axes of variation and continuity,\nthis framework provides developers, policymakers, and members of the public\nwith the opportunity to develop governance approaches that better align with\ncollective societal goals.",
      "tldr_zh": "本论文针对AI代理的部署和治理问题，提出了一种基于四个核心维度（autonomy、efficacy、goal complexity 和 generality）的特征化框架，以加深对AI代理属性的理解。这些维度各有不同渐变（gradations），并引发了AI系统设计、操作和治理的独特挑战。论文通过构建“agentic profiles”，分析从狭窄任务助手到高度自治系统的各种AI代理类别，从而揭示跨领域的技术与非技术治理难题，并为开发者、政策制定者和公众提供工具，以制定更符合社会目标的治理策略。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21848v1",
      "published_date": "2025-04-30 17:55:48 UTC",
      "updated_date": "2025-04-30 17:55:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:11:08.949002"
    },
    {
      "arxiv_id": "2504.21846v1",
      "title": "Active Light Modulation to Counter Manipulation of Speech Visual Content",
      "title_zh": "主动光调制以对抗语音视觉内容的操控",
      "authors": [
        "Hadleigh Schwartz",
        "Xiaofeng Yan",
        "Charles J. Carver",
        "Xia Zhou"
      ],
      "abstract": "High-profile speech videos are prime targets for falsification, owing to\ntheir accessibility and influence. This work proposes Spotlight, a low-overhead\nand unobtrusive system for protecting live speech videos from visual\nfalsification of speaker identity and lip and facial motion. Unlike predominant\nfalsification detection methods operating in the digital domain, Spotlight\ncreates dynamic physical signatures at the event site and embeds them into all\nvideo recordings via imperceptible modulated light. These physical signatures\nencode semantically-meaningful features unique to the speech event, including\nthe speaker's identity and facial motion, and are cryptographically-secured to\nprevent spoofing. The signatures can be extracted from any video downstream and\nvalidated against the portrayed speech content to check its integrity. Key\nelements of Spotlight include (1) a framework for generating extremely compact\n(i.e., 150-bit), pose-invariant speech video features, based on\nlocality-sensitive hashing; and (2) an optical modulation scheme that embeds\n>200 bps into video while remaining imperceptible both in video and live.\nPrototype experiments on extensive video datasets show Spotlight achieves AUCs\n$\\geq$ 0.99 and an overall true positive rate of 100% in detecting falsified\nvideos. Further, Spotlight is highly robust across recording conditions, video\npost-processing techniques, and white-box adversarial attacks on its video\nfeature extraction methodologies.",
      "tldr_zh": "该研究提出Spotlight系统，一种低开销、非 intrusive的方法，用于保护实时演讲视频免受说话者身份、唇部和面部动作的视觉篡改。Spotlight通过在现场创建动态物理签名，并利用imperceptible调制光将这些签名嵌入视频中，这些签名编码了说话者身份和面部动作的语义特征，并通过加密技术防止欺骗。关键创新包括基于locality-sensitive hashing的框架生成紧凑（150-bit）的姿态不变视频特征，以及一种光学调制方案将超过200 bps的信息嵌入视频而不被察觉。实验结果显示，Spotlight在广泛视频数据集上实现了AUC ≥ 0.99和100%的真正率检测假冒视频，并对各种录制条件、视频后处理和白盒对抗攻击表现出高度鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21846v1",
      "published_date": "2025-04-30 17:55:24 UTC",
      "updated_date": "2025-04-30 17:55:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:11:23.068357"
    },
    {
      "arxiv_id": "2504.21831v1",
      "title": "Early Exit and Multi Stage Knowledge Distillation in VLMs for Video Summarization",
      "title_zh": "翻译失败",
      "authors": [
        "Anas Anwarul Haq Khan",
        "Utkarsh Verma",
        "Prateek Chanda",
        "Ganesh Ramakrishnan"
      ],
      "abstract": "We introduce DEEVISum (Distilled Early Exit Vision language model for\nSummarization), a lightweight, efficient, and scalable vision language model\ndesigned for segment wise video summarization. Leveraging multi modal prompts\nthat combine textual and audio derived signals, DEEVISum incorporates Multi\nStage Knowledge Distillation (MSKD) and Early Exit (EE) to strike a balance\nbetween performance and efficiency. MSKD offers a 1.33% absolute F1 improvement\nover baseline distillation (0.5%), while EE reduces inference time by\napproximately 21% with a 1.3 point drop in F1. Evaluated on the TVSum dataset,\nour best model PaLI Gemma2 3B + MSKD achieves an F1 score of 61.1, competing\nthe performance of significantly larger models, all while maintaining a lower\ncomputational footprint. We publicly release our code and processed dataset to\nsupport further research.",
      "tldr_zh": "本研究提出 DEEVISum，一种轻量级、高效的视觉语言模型（VLMs），用于视频分段摘要，通过整合多模态提示（结合文本和音频信号）来提升性能。模型采用 Multi Stage Knowledge Distillation (MSKD) 和 Early Exit (EE) 机制，其中 MSKD 比基线蒸馏方法提高了 1.33% 的 F1 分数，而 EE 减少了约 21% 的推理时间，仅以 1.3 点的 F1 分数为代价。在 TVSum 数据集上，PaLI Gemma2 3B + MSKD 模型达到了 61.1 的 F1 分数，与更大模型相当，同时保持较低的计算开销。该研究还公开了代码和处理后的数据集，以支持进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21831v1",
      "published_date": "2025-04-30 17:37:55 UTC",
      "updated_date": "2025-04-30 17:37:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:11:34.534495"
    },
    {
      "arxiv_id": "2504.21801v1",
      "title": "DeepSeek-Prover-V2: Advancing Formal Mathematical Reasoning via Reinforcement Learning for Subgoal Decomposition",
      "title_zh": "翻译失败",
      "authors": [
        "Z. Z. Ren",
        "Zhihong Shao",
        "Junxiao Song",
        "Huajian Xin",
        "Haocheng Wang",
        "Wanjia Zhao",
        "Liyue Zhang",
        "Zhe Fu",
        "Qihao Zhu",
        "Dejian Yang",
        "Z. F. Wu",
        "Zhibin Gou",
        "Shirong Ma",
        "Hongxuan Tang",
        "Yuxuan Liu",
        "Wenjun Gao",
        "Daya Guo",
        "Chong Ruan"
      ],
      "abstract": "We introduce DeepSeek-Prover-V2, an open-source large language model designed\nfor formal theorem proving in Lean 4, with initialization data collected\nthrough a recursive theorem proving pipeline powered by DeepSeek-V3. The\ncold-start training procedure begins by prompting DeepSeek-V3 to decompose\ncomplex problems into a series of subgoals. The proofs of resolved subgoals are\nsynthesized into a chain-of-thought process, combined with DeepSeek-V3's\nstep-by-step reasoning, to create an initial cold start for reinforcement\nlearning. This process enables us to integrate both informal and formal\nmathematical reasoning into a unified model. The resulting model,\nDeepSeek-Prover-V2-671B, achieves state-of-the-art performance in neural\ntheorem proving, reaching 88.9% pass ratio on the MiniF2F-test and solving 49\nout of 658 problems from PutnamBench. In addition to standard benchmarks, we\nintroduce ProverBench, a collection of 325 formalized problems, to enrich our\nevaluation, including 15 selected problems from the recent AIME competitions\n(years 24-25). Further evaluation on these 15 AIME problems shows that the\nmodel successfully solves 6 of them. In comparison, DeepSeek-V3 solves 8 of\nthese problems using majority voting, highlighting that the gap between formal\nand informal mathematical reasoning in large language models is substantially\nnarrowing.",
      "tldr_zh": "本研究引入 DeepSeek-Prover-V2，一种开源的大型语言模型，旨在通过强化学习和子目标分解提升 Lean 4 中的正式定理证明能力。模型采用冷启动训练流程，利用 DeepSeek-V3 分解复杂问题为子目标，并将证明合成链式思维过程，融合非正式和正式数学推理。实验结果显示，DeepSeek-Prover-V2-671B 在 MiniF2F-test 上达到 88.9% 的通过率，并解决了 PutnamBench 中的 49 个问题；此外，在新基准 ProverBench 和 AIME 问题上，该模型成功解决 6 个 AIME 问题，显著缩小了大型语言模型中正式与非正式推理的差距。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21801v1",
      "published_date": "2025-04-30 16:57:48 UTC",
      "updated_date": "2025-04-30 16:57:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:11:47.716022"
    },
    {
      "arxiv_id": "2504.21800v3",
      "title": "How Real Are Synthetic Therapy Conversations? Evaluating Fidelity in Prolonged Exposure Dialogues",
      "title_zh": "翻译失败",
      "authors": [
        "Suhas BN",
        "Dominik Mattioli",
        "Saeed Abdullah",
        "Rosa I. Arriaga",
        "Chris W. Wiese",
        "Andrew M. Sherrill"
      ],
      "abstract": "The growing adoption of synthetic data in healthcare is driven by privacy\nconcerns, limited access to real-world data, and the high cost of annotation.\nThis work explores the use of synthetic Prolonged Exposure (PE) therapeutic\nconversations for Post-Traumatic Stress Disorder (PTSD) as a scalable\nalternative for training and evaluating clinical models. We systematically\ncompare real and synthetic dialogues using linguistic, structural, and\nprotocol-specific metrics, including turn-taking patterns and treatment\nfidelity. We also introduce and evaluate PE-specific metrics derived from\nlinguistic analysis and semantic modeling, offering a novel framework for\nassessing clinical fidelity beyond surface fluency. Our findings show that\nalthough synthetic data holds promise for mitigating data scarcity and\nprotecting patient privacy, it can struggle to capture the subtle dynamics of\ntherapeutic interactions. Synthetic therapy dialogues closely match structural\nfeatures of real-world conversations (e.g., speaker switch ratio: 0.98 vs.\n0.99); however, they may not adequately reflect key fidelity markers (e.g.,\ndistress monitoring). We highlight gaps in existing evaluation frameworks and\nadvocate for fidelity-aware metrics that go beyond surface fluency to uncover\nclinically significant failures. Our findings clarify where synthetic data can\neffectively complement real-world datasets -- and where critical limitations\nremain.",
      "tldr_zh": "这篇论文评估了合成数据在生成Prolonged Exposure (PE)治疗对话中的真实性，作为训练和评估PTSD临床模型的可扩展替代方案。作者通过语言、结构和协议特定指标（如轮流模式和treatment fidelity）系统比较真实和合成对话，并引入基于语言分析和语义建模的PE-specific metrics，提供了一个新的评估框架。结果显示，合成数据在结构特征上（如说话者切换比率：0.98 vs. 0.99）与真实对话高度相似，但难以捕捉治疗互动的细微动态（如distress monitoring）。论文强调合成数据可缓解数据稀缺性和保护患者隐私，但呼吁开发更全面的fidelity-aware metrics，以揭示临床上的关键缺陷。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.HC",
        "68T50",
        "I.2.7; H.3.1"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.21800v3",
      "published_date": "2025-04-30 16:56:56 UTC",
      "updated_date": "2025-05-21 20:26:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:12:00.315356"
    },
    {
      "arxiv_id": "2504.21798v2",
      "title": "SWE-smith: Scaling Data for Software Engineering Agents",
      "title_zh": "翻译失败",
      "authors": [
        "John Yang",
        "Kilian Leret",
        "Carlos E. Jimenez",
        "Alexander Wettig",
        "Kabir Khandpur",
        "Yanzhe Zhang",
        "Binyuan Hui",
        "Ofir Press",
        "Ludwig Schmidt",
        "Diyi Yang"
      ],
      "abstract": "Despite recent progress in Language Models (LMs) for software engineering,\ncollecting training data remains a significant pain point. Existing datasets\nare small, with at most 1,000s of training instances from 11 or fewer GitHub\nrepositories. The procedures to curate such datasets are often complex,\nnecessitating hundreds of hours of human labor; companion execution\nenvironments also take up several terabytes of storage, severely limiting their\nscalability and usability. To address this pain point, we introduce SWE-smith,\na novel pipeline for generating software engineering training data at scale.\nGiven any Python codebase, SWE-smith constructs a corresponding execution\nenvironment, then automatically synthesizes 100s to 1,000s of task instances\nthat break existing test(s) in the codebase. Using SWE-smith, we create a\ndataset of 50k instances sourced from 128 GitHub repositories, an order of\nmagnitude larger than all previous works. We train SWE-agent-LM-32B, achieving\n40.2% Pass@1 resolve rate on the SWE-bench Verified benchmark, state of the art\namong open source models. We open source SWE-smith (collection procedure, task\ninstances, trajectories, models) to lower the barrier of entry for research in\nLM systems for automated software engineering. All assets available at\nhttps://swesmith.com.",
      "tldr_zh": "该研究解决了软件工程领域 Language Models (LMs) 训练数据规模小和收集复杂的问题，引入了 SWE-smith 管道：它针对任何 Python 代码库自动构建执行环境，并合成数百到数千个破坏现有测试的任务实例。利用 SWE-smith，他们创建了一个规模达 50k 实例的数据集，源自 128 个 GitHub 仓库，比现有数据集大一个数量级。基于此数据集训练的 SWE-agent-LM-32B 模型，在 SWE-bench Verified 基准上实现了 40.2% Pass@1 解决率，领先开源模型。该框架及其资产已开源，以降低自动化软件工程研究门槛。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "All assets available at https://swesmith.com",
      "pdf_url": "http://arxiv.org/pdf/2504.21798v2",
      "published_date": "2025-04-30 16:56:06 UTC",
      "updated_date": "2025-05-21 17:21:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:12:12.004164"
    },
    {
      "arxiv_id": "2504.21776v1",
      "title": "WebThinker: Empowering Large Reasoning Models with Deep Research Capability",
      "title_zh": "WebThinker：为大型推理模型赋予深度研究能力",
      "authors": [
        "Xiaoxi Li",
        "Jiajie Jin",
        "Guanting Dong",
        "Hongjin Qian",
        "Yutao Zhu",
        "Yongkang Wu",
        "Ji-Rong Wen",
        "Zhicheng Dou"
      ],
      "abstract": "Large reasoning models (LRMs), such as OpenAI-o1 and DeepSeek-R1, demonstrate\nimpressive long-horizon reasoning capabilities. However, their reliance on\nstatic internal knowledge limits their performance on complex,\nknowledge-intensive tasks and hinders their ability to produce comprehensive\nresearch reports requiring synthesis of diverse web information. To address\nthis, we propose \\textbf{WebThinker}, a deep research agent that empowers LRMs\nto autonomously search the web, navigate web pages, and draft research reports\nduring the reasoning process. WebThinker integrates a \\textbf{Deep Web\nExplorer} module, enabling LRMs to dynamically search, navigate, and extract\ninformation from the web when encountering knowledge gaps. It also employs an\n\\textbf{Autonomous Think-Search-and-Draft strategy}, allowing the model to\nseamlessly interleave reasoning, information gathering, and report writing in\nreal time. To further enhance research tool utilization, we introduce an\n\\textbf{RL-based training strategy} via iterative online Direct Preference\nOptimization (DPO). Extensive experiments on complex reasoning benchmarks\n(GPQA, GAIA, WebWalkerQA, HLE) and scientific report generation tasks (Glaive)\ndemonstrate that WebThinker significantly outperforms existing methods and\nstrong proprietary systems. Our approach enhances LRM reliability and\napplicability in complex scenarios, paving the way for more capable and\nversatile deep research systems. The code is available at\nhttps://github.com/RUC-NLPIR/WebThinker.",
      "tldr_zh": "本研究提出 WebThinker，一种深度研究代理，用于增强 Large Reasoning Models (LRMs) 如 OpenAI-o1 的能力，解决其依赖静态知识的局限性，从而更好地处理复杂知识密集型任务和生成综合研究报告。WebThinker 整合了 Deep Web Explorer 模块以动态搜索、导航和提取网络信息，以及 Autonomous Think-Search-and-Draft strategy 来实时交替进行推理、信息收集和报告撰写；同时采用 RL-based training strategy via Direct Preference Optimization (DPO) 来优化工具利用。实验结果显示，在 GPQA、GAIA、WebWalkerQA、HLE 和 Glaive 等基准上，WebThinker 显著优于现有方法和专有系统，提升了 LRM 在复杂场景中的可靠性和适用性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21776v1",
      "published_date": "2025-04-30 16:25:25 UTC",
      "updated_date": "2025-04-30 16:25:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:12:23.660141"
    },
    {
      "arxiv_id": "2504.21775v1",
      "title": "Learning Heterogeneous Performance-Fairness Trade-offs in Federated Learning",
      "title_zh": "在联邦学习中学习异质性能-公平性权衡",
      "authors": [
        "Rongguang Ye",
        "Ming Tang"
      ],
      "abstract": "Recent methods leverage a hypernet to handle the performance-fairness\ntrade-offs in federated learning. This hypernet maps the clients' preferences\nbetween model performance and fairness to preference-specifc models on the\ntrade-off curve, known as local Pareto front. However, existing methods\ntypically adopt a uniform preference sampling distribution to train the\nhypernet across clients, neglecting the inherent heterogeneity of their local\nPareto fronts. Meanwhile, from the perspective of generalization, they do not\nconsider the gap between local and global Pareto fronts on the global dataset.\nTo address these limitations, we propose HetPFL to effectively learn both local\nand global Pareto fronts. HetPFL comprises Preference Sampling Adaptation (PSA)\nand Preference-aware Hypernet Fusion (PHF). PSA adaptively determines the\noptimal preference sampling distribution for each client to accommodate\nheterogeneous local Pareto fronts. While PHF performs preference-aware fusion\nof clients' hypernets to ensure the performance of the global Pareto front. We\nprove that HetPFL converges linearly with respect to the number of rounds,\nunder weaker assumptions than existing methods. Extensive experiments on four\ndatasets show that HetPFL significantly outperforms seven baselines in terms of\nthe quality of learned local and global Pareto fronts.",
      "tldr_zh": "该论文提出了一种名为 HetPFL 的方法，用于处理联邦学习(Federated Learning)中异质性的性能-公平性权衡问题。HetPFL 通过 Preference Sampling Adaptation (PSA) 模块适应性地为每个客户端优化偏好采样分布，以应对本地 Pareto 前沿的差异；同时，通过 Preference-aware Hypernet Fusion (PHF) 模块融合客户端的 hypernet，确保全局 Pareto 前沿的性能。实验结果显示，HetPFL 在四个数据集上显著优于七个基线模型，并在收敛性证明中显示出线性收敛优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by IJCAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.21775v1",
      "published_date": "2025-04-30 16:25:02 UTC",
      "updated_date": "2025-04-30 16:25:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:12:34.274363"
    },
    {
      "arxiv_id": "2504.21774v1",
      "title": "Is Intermediate Fusion All You Need for UAV-based Collaborative Perception?",
      "title_zh": "翻译失败",
      "authors": [
        "Jiuwu Hao",
        "Liguo Sun",
        "Yuting Wan",
        "Yueyang Wu",
        "Ti Xiang",
        "Haolin Song",
        "Pin Lv"
      ],
      "abstract": "Collaborative perception enhances environmental awareness through inter-agent\ncommunication and is regarded as a promising solution to intelligent\ntransportation systems. However, existing collaborative methods for Unmanned\nAerial Vehicles (UAVs) overlook the unique characteristics of the UAV\nperspective, resulting in substantial communication overhead. To address this\nissue, we propose a novel communication-efficient collaborative perception\nframework based on late-intermediate fusion, dubbed LIF. The core concept is to\nexchange informative and compact detection results and shift the fusion stage\nto the feature representation level. In particular, we leverage vision-guided\npositional embedding (VPE) and box-based virtual augmented feature (BoBEV) to\neffectively integrate complementary information from various agents.\nAdditionally, we innovatively introduce an uncertainty-driven communication\nmechanism that uses uncertainty evaluation to select high-quality and reliable\nshared areas. Experimental results demonstrate that our LIF achieves superior\nperformance with minimal communication bandwidth, proving its effectiveness and\npracticality. Code and models are available at https://github.com/uestchjw/LIF.",
      "tldr_zh": "本研究质疑了在无人机（UAV）协作感知中是否仅需中间融合，针对现有方法忽略UAV视角特性导致通信开销大的问题，提出了一种通信高效的LIF（Late-Intermediate Fusion）框架。该框架通过交换信息量大且紧凑的检测结果，将融合阶段移至特征表示级别，并利用vision-guided positional embedding (VPE) 和 box-based virtual augmented feature (BoBEV) 有效整合不同代理的互补信息。同时，引入uncertainty-driven communication机制，通过不确定性评估选择高质量的共享区域。实验结果表明，LIF在最小通信带宽下实现了优越性能，证明了其有效性和实用性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21774v1",
      "published_date": "2025-04-30 16:22:14 UTC",
      "updated_date": "2025-04-30 16:22:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:12:46.594892"
    },
    {
      "arxiv_id": "2504.21773v1",
      "title": "MAC-Tuning: LLM Multi-Compositional Problem Reasoning with Enhanced Knowledge Boundary Awareness",
      "title_zh": "翻译失败",
      "authors": [
        "Junsheng Huang",
        "Zhitao He",
        "Sandeep Polisetty",
        "Qingyun Wang",
        "May Fung"
      ],
      "abstract": "With the widespread application of large language models (LLMs), the issue of\ngenerating non-existing facts, known as hallucination, has garnered increasing\nattention. Previous research in enhancing LLM confidence estimation mainly\nfocuses on the single problem setting. However, LLM awareness of its internal\nparameterized knowledge boundary under the more challenging multi-problem\nsetting, which requires answering multiple problems accurately simultaneously,\nremains underexplored. To bridge this gap, we introduce a novel method,\nMultiple Answers and Confidence Stepwise Tuning (MAC-Tuning), that separates\nthe learning of answer prediction and confidence estimation during fine-tuning\non instruction data. Extensive experiments demonstrate that our method\noutperforms baselines by up to 25% in average precision.",
      "tldr_zh": "该研究针对大型语言模型(LLMs)在多问题设置下生成的幻觉(hallucination)问题，提出了一种新方法MAC-Tuning，以提升模型对内部参数化知识边界(knowledge boundary awareness)的意识。MAC-Tuning通过在指令数据微调过程中分离答案预测和置信度估计(confidence estimation)的学习步骤，实现更准确的多组合问题推理(multi-compositional problem reasoning)。实验结果显示，该方法在平均精度上比基线模型提高了25%，为LLMs在复杂任务中的可靠应用提供了重要改进。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21773v1",
      "published_date": "2025-04-30 16:17:53 UTC",
      "updated_date": "2025-04-30 16:17:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:12:57.701520"
    },
    {
      "arxiv_id": "2504.21772v2",
      "title": "Solving Copyright Infringement on Short Video Platforms: Novel Datasets and an Audio Restoration Deep Learning Pipeline",
      "title_zh": "翻译失败",
      "authors": [
        "Minwoo Oh",
        "Minsu Park",
        "Eunil Park"
      ],
      "abstract": "Short video platforms like YouTube Shorts and TikTok face significant\ncopyright compliance challenges, as infringers frequently embed arbitrary\nbackground music (BGM) to obscure original soundtracks (OST) and evade content\noriginality detection. To tackle this issue, we propose a novel pipeline that\nintegrates Music Source Separation (MSS) and cross-modal video-music retrieval\n(CMVMR). Our approach effectively separates arbitrary BGM from the original\nOST, enabling the restoration of authentic video audio tracks. To support this\nwork, we introduce two domain-specific datasets: OASD-20K for audio separation\nand OSVAR-160 for pipeline evaluation. OASD-20K contains 20,000 audio clips\nfeaturing mixed BGM and OST pairs, while OSVAR160 is a unique benchmark dataset\ncomprising 1,121 video and mixed-audio pairs, specifically designed for short\nvideo restoration tasks. Experimental results demonstrate that our pipeline not\nonly removes arbitrary BGM with high accuracy but also restores OSTs, ensuring\ncontent integrity. This approach provides an ethical and scalable solution to\ncopyright challenges in user-generated content on short video platforms.",
      "tldr_zh": "这篇论文针对短视频平台（如YouTube Shorts和TikTok）上的版权侵权问题，提出了一种新型深度学习管道，整合Music Source Separation (MSS)和cross-modal video-music retrieval (CMVMR)，用于有效分离任意背景音乐(BGM)并恢复原声轨(OST)。为了支持这一工作，研究者引入了两个专用数据集：OASD-20K 包含20,000个混合音频片段，用于音频分离训练，以及OSVAR-160 包含1,121个视频和混合音频对，用于管道整体评估。实验结果表明，该管道能高精度移除BGM并恢复音频完整性，从而提供一个道德且可扩展的解决方案，增强短视频平台的版权合规性。",
      "categories": [
        "cs.MM",
        "cs.AI"
      ],
      "primary_category": "cs.MM",
      "comment": "will be presented in IJCAI 2025, 9 pages, 4 tables, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.21772v2",
      "published_date": "2025-04-30 16:17:05 UTC",
      "updated_date": "2025-05-03 12:54:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:13:10.488294"
    },
    {
      "arxiv_id": "2504.21731v1",
      "title": "Adaptive 3D UI Placement in Mixed Reality Using Deep Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Feiyu Lu",
        "Mengyu Chen",
        "Hsiang Hsu",
        "Pranav Deshpande",
        "Cheng Yao Wang",
        "Blair MacIntyre"
      ],
      "abstract": "Mixed Reality (MR) could assist users' tasks by continuously integrating\nvirtual content with their view of the physical environment. However, where and\nhow to place these content to best support the users has been a challenging\nproblem due to the dynamic nature of MR experiences. In contrast to prior work\nthat investigates optimization-based methods, we are exploring how\nreinforcement learning (RL) could assist with continuous 3D content placement\nthat is aware of users' poses and their surrounding environments. Through an\ninitial exploration and preliminary evaluation, our results demonstrate the\npotential of RL to position content that maximizes the reward for users on the\ngo. We further identify future directions for research that could harness the\npower of RL for personalized and optimized UI and content placement in MR.",
      "tldr_zh": "本研究探讨了在 Mixed Reality (MR) 中使用 Deep Reinforcement Learning (RL) 实现自适应 3D UI 放置的问题，以应对虚拟内容与物理环境的动态整合挑战。不同于以往的优化方法，该方法通过 RL 算法实时考虑用户的姿势和周围环境，从而优化 UI 位置以最大化用户奖励。初步探索和评估结果表明，RL 能有效提升内容放置的适应性，并为未来的个性化 UI 优化研究提供方向。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.HC",
      "comment": "In Extended Abstracts of the CHI Conference on Human Factors in\n  Computing Systems (CHI EA '24)",
      "pdf_url": "http://arxiv.org/pdf/2504.21731v1",
      "published_date": "2025-04-30 15:21:36 UTC",
      "updated_date": "2025-04-30 15:21:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:13:21.800901"
    },
    {
      "arxiv_id": "2504.21730v1",
      "title": "Cert-SSB: Toward Certified Sample-Specific Backdoor Defense",
      "title_zh": "翻译失败",
      "authors": [
        "Ting Qiao",
        "Yingjia Wang",
        "Xing Liu",
        "Sixing Wu",
        "Jianbing Li",
        "Yiming Li"
      ],
      "abstract": "Deep neural networks (DNNs) are vulnerable to backdoor attacks, where an\nattacker manipulates a small portion of the training data to implant hidden\nbackdoors into the model. The compromised model behaves normally on clean\nsamples but misclassifies backdoored samples into the attacker-specified target\nclass, posing a significant threat to real-world DNN applications. Currently,\nseveral empirical defense methods have been proposed to mitigate backdoor\nattacks, but they are often bypassed by more advanced backdoor techniques. In\ncontrast, certified defenses based on randomized smoothing have shown promise\nby adding random noise to training and testing samples to counteract backdoor\nattacks. In this paper, we reveal that existing randomized smoothing defenses\nimplicitly assume that all samples are equidistant from the decision boundary.\nHowever, it may not hold in practice, leading to suboptimal certification\nperformance. To address this issue, we propose a sample-specific certified\nbackdoor defense method, termed Cert-SSB. Cert-SSB first employs stochastic\ngradient ascent to optimize the noise magnitude for each sample, ensuring a\nsample-specific noise level that is then applied to multiple poisoned training\nsets to retrain several smoothed models. After that, Cert-SSB aggregates the\npredictions of multiple smoothed models to generate the final robust\nprediction. In particular, in this case, existing certification methods become\ninapplicable since the optimized noise varies across different samples. To\nconquer this challenge, we introduce a storage-update-based certification\nmethod, which dynamically adjusts each sample's certification region to improve\ncertification performance. We conduct extensive experiments on multiple\nbenchmark datasets, demonstrating the effectiveness of our proposed method. Our\ncode is available at https://github.com/NcepuQiaoTing/Cert-SSB.",
      "tldr_zh": "该论文针对深度神经网络 (DNNs) 的后门攻击问题，提出了一种样本特定的认证防御方法 Cert-SSB，以解决现有随机平滑防御假设所有样本等距决策边界的不合理性。Cert-SSB 通过随机梯度上升优化每个样本的噪声幅度，并将其应用于多个中毒训练集来重新训练平滑模型，随后聚合这些模型的预测以生成鲁棒输出。同时，引入基于存储更新的认证方法，动态调整样本的认证区域，以适应样本特定的噪声水平。实验在多个基准数据集上证明，该方法显著提高了后门防御的认证性能。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "15 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.21730v1",
      "published_date": "2025-04-30 15:21:25 UTC",
      "updated_date": "2025-04-30 15:21:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:13:35.890183"
    },
    {
      "arxiv_id": "2504.21719v1",
      "title": "Sionna RT: Technical Report",
      "title_zh": "Sionna RT: 技术报告",
      "authors": [
        "Fayçal Aït Aoudia",
        "Jakob Hoydis",
        "Merlin Nimier-David",
        "Sebastian Cammerer",
        "Alexander Keller"
      ],
      "abstract": "Sionna is an open-source, GPU-accelerated library that, as of version 0.14,\nincorporates a ray tracer for simulating radio wave propagation. A unique\nfeature of Sionna RT is differentiability, enabling the calculation of\ngradients for the channel impulse responses (CIRs), radio maps, and other\nrelated metrics with respect to system and environmental parameters, such as\nmaterial properties, antenna patterns, and array geometries. The release of\nSionna 1.0 provides a complete overhaul of the ray tracer, significantly\nimproving its speed, memory efficiency, and extensibility. This document\ndetails the algorithms employed by Sionna RT to simulate radio wave propagation\nefficiently, while also addressing their current limitations. Given that the\ncomputation of CIRs and radio maps requires distinct algorithms, these are\ndetailed in separate sections. For CIRs, Sionna RT integrates shooting and\nbouncing of rays (SBR) with the image method and uses a hashing-based mechanism\nto efficiently eliminate duplicate paths. Radio maps are computed using a\npurely SBR-based approach.",
      "tldr_zh": "Sionna RT 是一个开源的 GPU-accelerated 库，用于模拟无线电波传播，其独特功能是可微性(differentiability)，允许计算通道脉冲响应(CIRs)、无线电地图和其他指标相对于系统和环境参数（如材料属性、天线图案和阵列几何）的梯度。新版本 1.0 对射线追踪器进行了全面重构，提高了速度、内存效率和可扩展性。该库采用射线发射和弹跳(SBR)结合图像方法来计算 CIRs，并使用基于散列的机制高效消除重复路径，而无线电地图则通过纯 SBR 方法生成。文档详细了这些算法及其当前局限性，为无线电传播模拟提供了高效工具。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "eess.SP",
        "math.IT"
      ],
      "primary_category": "cs.IT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21719v1",
      "published_date": "2025-04-30 15:05:20 UTC",
      "updated_date": "2025-04-30 15:05:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:13:47.888239"
    },
    {
      "arxiv_id": "2504.21716v1",
      "title": "LLM-Empowered Embodied Agent for Memory-Augmented Task Planning in Household Robotics",
      "title_zh": "翻译失败",
      "authors": [
        "Marc Glocker",
        "Peter Hönig",
        "Matthias Hirschmanner",
        "Markus Vincze"
      ],
      "abstract": "We present an embodied robotic system with an LLM-driven agent-orchestration\narchitecture for autonomous household object management. The system integrates\nmemory-augmented task planning, enabling robots to execute high-level user\ncommands while tracking past actions. It employs three specialized agents: a\nrouting agent, a task planning agent, and a knowledge base agent, each powered\nby task-specific LLMs. By leveraging in-context learning, our system avoids the\nneed for explicit model training. RAG enables the system to retrieve context\nfrom past interactions, enhancing long-term object tracking. A combination of\nGrounded SAM and LLaMa3.2-Vision provides robust object detection, facilitating\nsemantic scene understanding for task planning. Evaluation across three\nhousehold scenarios demonstrates high task planning accuracy and an improvement\nin memory recall due to RAG. Specifically, Qwen2.5 yields best performance for\nspecialized agents, while LLaMA3.1 excels in routing tasks. The source code is\navailable at: https://github.com/marc1198/chat-hsr.",
      "tldr_zh": "本研究提出了一种基于LLM驱动的具身代理系统，用于家庭机器人的记忆增强任务规划。该系统整合了记忆机制和任务规划功能，通过三个专门代理（routing agent、task planning agent 和 knowledge base agent）来执行高层用户命令并跟踪过去行动，利用in-context learning和RAG技术避免显式模型训练，并结合Grounded SAM和LLaMa3.2-Vision实现鲁棒的对象检测和语义场景理解。在三个家庭场景的评估中，该系统展示了高任务规划准确性，RAG显著提升了记忆召回性能，其中Qwen2.5在专门代理中表现最佳，而LLaMA3.1在路由任务中领先。开源代码可从指定仓库获取。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted at Austrian Robotics Workshop 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.21716v1",
      "published_date": "2025-04-30 15:00:20 UTC",
      "updated_date": "2025-04-30 15:00:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:13:58.245205"
    },
    {
      "arxiv_id": "2504.21707v1",
      "title": "Recursive KL Divergence Optimization: A Dynamic Framework for Representation Learning",
      "title_zh": "递归 KL 散度优化：一种用于表示学习的动态框架",
      "authors": [
        "Anthony D Martin"
      ],
      "abstract": "We propose a generalization of modern representation learning objectives by\nreframing them as recursive divergence alignment processes over localized\nconditional distributions While recent frameworks like Information Contrastive\nLearning I-Con unify multiple learning paradigms through KL divergence between\nfixed neighborhood conditionals we argue this view underplays a crucial\nrecursive structure inherent in the learning process. We introduce Recursive KL\nDivergence Optimization RKDO a dynamic formalism where representation learning\nis framed as the evolution of KL divergences across data neighborhoods. This\nformulation captures contrastive clustering and dimensionality reduction\nmethods as static slices while offering a new path to model stability and local\nadaptation. Our experiments demonstrate that RKDO offers dual efficiency\nadvantages approximately 30 percent lower loss values compared to static\napproaches across three different datasets and 60 to 80 percent reduction in\ncomputational resources needed to achieve comparable results. This suggests\nthat RKDOs recursive updating mechanism provides a fundamentally more efficient\noptimization landscape for representation learning with significant\nimplications for resource constrained applications.",
      "tldr_zh": "本研究提出Recursive KL Divergence Optimization (RKDO)，一种动态框架，将现代表示学习目标泛化为在局部条件分布上递归的散度对齐过程，以克服现有框架如Information Contrastive Learning (I-Con)忽略学习过程中的递归结构问题。RKDO将表示学习视为数据邻域中KL散度的演化，从而捕捉对比学习、聚类和降维方法作为静态切片，同时提升模型稳定性和局部适应性。实验结果显示，RKDO在三个数据集上比静态方法降低约30%的损失值，并减少60-80%的计算资源，展示了其在资源受限应用中的高效优化潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.IT",
        "cs.NE",
        "math.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21707v1",
      "published_date": "2025-04-30 14:51:27 UTC",
      "updated_date": "2025-04-30 14:51:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:14:10.709887"
    },
    {
      "arxiv_id": "2504.21706v2",
      "title": "Vision Transformers in Precision Agriculture: A Comprehensive Survey",
      "title_zh": "视觉Transformer在精准农业中的全面综述",
      "authors": [
        "Saber Mehdipour",
        "Seyed Abolghasem Mirroshandel",
        "Seyed Amirhossein Tabatabaei"
      ],
      "abstract": "Detecting plant diseases is a crucial aspect of modern agriculture, as it\nplays a key role in maintaining crop health and increasing overall yield.\nTraditional approaches, though still valuable, often rely on manual inspection\nor conventional machine learning techniques, both of which face limitations in\nscalability and accuracy. Recently, Vision Transformers (ViTs) have emerged as\na promising alternative, offering advantages such as improved handling of\nlong-range dependencies and better scalability for visual tasks. This review\nexplores the application of ViTs in precision agriculture, covering a range of\ntasks. We begin by introducing the foundational architecture of ViTs and\ndiscussing their transition from Natural Language Processing (NLP) to Computer\nVision. The discussion includes the concept of inductive bias in traditional\nmodels like Convolutional Neural Networks (CNNs), and how ViTs mitigate these\nbiases. We provide a comprehensive review of recent literature, focusing on key\nmethodologies, datasets, and performance metrics. This study also includes a\ncomparative analysis of CNNs and ViTs, along with a review of hybrid models and\nperformance enhancements. Technical challenges such as data requirements,\ncomputational demands, and model interpretability are addressed, along with\npotential solutions. Finally, we outline future research directions and\ntechnological advancements that could further support the integration of ViTs\nin real-world agricultural settings. Our goal with this study is to offer\npractitioners and researchers a deeper understanding of how ViTs are poised to\ntransform smart and precision agriculture.",
      "tldr_zh": "这篇论文对 Vision Transformers (ViTs) 在精准农业中的应用进行了全面调查，强调了 ViTs 在处理植物疾病检测等任务时的优势，如改善长距离依赖和可扩展性。论文介绍了 ViTs 的基础架构及其从 Natural Language Processing (NLP) 到 Computer Vision 的演变，并与 Convolutional Neural Networks (CNNs) 进行了比较，包括混合模型和性能提升。研究回顾了相关文献、数据集、性能指标，并讨论了技术挑战，如数据需求、计算需求和模型可解释性。最终，论文指出了未来研究方向，以推动 ViTs 在真实农业环境中的整合，从而提升智能和精准农业。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21706v2",
      "published_date": "2025-04-30 14:50:02 UTC",
      "updated_date": "2025-05-19 14:20:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:14:22.210953"
    },
    {
      "arxiv_id": "2504.21700v1",
      "title": "XBreaking: Explainable Artificial Intelligence for Jailbreaking LLMs",
      "title_zh": "XBreaking：用于越狱 LLMs 的",
      "authors": [
        "Marco Arazzi",
        "Vignesh Kumar Kembu",
        "Antonino Nocera",
        "Vinod P"
      ],
      "abstract": "Large Language Models are fundamental actors in the modern IT landscape\ndominated by AI solutions. However, security threats associated with them might\nprevent their reliable adoption in critical application scenarios such as\ngovernment organizations and medical institutions. For this reason, commercial\nLLMs typically undergo a sophisticated censoring mechanism to eliminate any\nharmful output they could possibly produce. In response to this, LLM\nJailbreaking is a significant threat to such protections, and many previous\napproaches have already demonstrated its effectiveness across diverse domains.\nExisting jailbreak proposals mostly adopt a generate-and-test strategy to craft\nmalicious input. To improve the comprehension of censoring mechanisms and\ndesign a targeted jailbreak attack, we propose an Explainable-AI solution that\ncomparatively analyzes the behavior of censored and uncensored models to derive\nunique exploitable alignment patterns. Then, we propose XBreaking, a novel\njailbreak attack that exploits these unique patterns to break the security\nconstraints of LLMs by targeted noise injection. Our thorough experimental\ncampaign returns important insights about the censoring mechanisms and\ndemonstrates the effectiveness and performance of our attack.",
      "tldr_zh": "本研究针对大型语言模型（LLMs）的安全威胁，探讨了审查机制如何防止有害输出，但现有 LLM Jailbreaking 攻击仍能有效绕过这些保护。论文提出一种 Explainable-AI 解决方案，通过比较审查和非审查模型的行为，识别出可利用的 alignment patterns。基于此，作者开发了 XBreaking 攻击，该方法通过针对性噪声注入来打破 LLMs 的安全约束。实验结果证明了该攻击的有效性和性能，并提供了审查机制的重要洞见。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21700v1",
      "published_date": "2025-04-30 14:44:24 UTC",
      "updated_date": "2025-04-30 14:44:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:14:34.642091"
    },
    {
      "arxiv_id": "2505.00060v1",
      "title": "Fact-Consistency Evaluation of Text-to-SQL Generation for Business Intelligence Using Exaone 3.5",
      "title_zh": "翻译失败",
      "authors": [
        "Jeho Choi"
      ],
      "abstract": "Large Language Models (LLMs) have shown promise in enabling natural language\ninterfaces for structured data querying through text-to-SQL generation.\nHowever, their application in real-world Business Intelligence (BI) contexts\nremains limited due to semantic hallucinations, structural errors, and a lack\nof domain-specific evaluation frameworks. In this study, we propose a\nFact-Consistency Evaluation Framework for assessing the semantic accuracy of\nLLM-generated SQL outputs using Exaone 3.5--an instruction-tuned, bilingual LLM\noptimized for enterprise tasks. We construct a domain-specific benchmark\ncomprising 219 natural language business questions across five SQL complexity\nlevels, derived from actual sales data in LG Electronics' internal BigQuery\nenvironment. Each question is paired with a gold-standard SQL query and a\nvalidated ground-truth answer. We evaluate model performance using answer\naccuracy, execution success rate, semantic error rate, and non-response rate.\nExperimental results show that while Exaone 3.5 performs well on simple\naggregation tasks (93% accuracy in L1), it exhibits substantial degradation in\narithmetic reasoning (4% accuracy in H1) and grouped ranking tasks (31% in H4),\nwith semantic errors and non-responses concentrated in complex cases.\nQualitative error analysis further identifies common failure types such as\nmisapplied arithmetic logic, incomplete filtering, and incorrect grouping\noperations. Our findings highlight the current limitations of LLMs in\nbusiness-critical environments and underscore the need for fact-consistency\nvalidation layers and hybrid reasoning approaches. This work contributes a\nreproducible benchmark and evaluation methodology for advancing reliable\nnatural language interfaces to structured enterprise data systems.",
      "tldr_zh": "本研究提出了一种事实一致性评估框架，使用 Exaone 3.5（一个指令调整的双语 LLM）来评估大型语言模型 (LLMs) 在商业智能 (BI) 环境中的 Text-to-SQL 生成性能，针对语义幻觉和结构错误等问题。研究构建了一个包含 219 个自然语言商业问题的领域特定基准数据集，涵盖五种 SQL 复杂程度，并使用答案准确率、执行成功率、语义错误率和非响应率等指标进行评估。结果显示，Exaone 3.5 在简单聚合任务 (L1) 上准确率达 93%，但在算术推理 (H1) 和分组排名 (H4) 等复杂任务上准确率显著下降（分别为 4% 和 31%），常见错误包括误应用算术逻辑、不完整过滤和错误分组。该工作突出了 LLMs 在商业关键环境中的局限性，并提供了一个可重现的基准和评估方法，呼吁引入事实一致性验证层和混合推理方法以提升可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2505.00060v1",
      "published_date": "2025-04-30 14:42:18 UTC",
      "updated_date": "2025-04-30 14:42:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:14:49.227743"
    },
    {
      "arxiv_id": "2504.21695v1",
      "title": "Self-Supervised Monocular Visual Drone Model Identification through Improved Occlusion Handling",
      "title_zh": "翻译失败",
      "authors": [
        "Stavrow A. Bahnam",
        "Christophe De Wagter",
        "Guido C. H. E. de Croon"
      ],
      "abstract": "Ego-motion estimation is vital for drones when flying in GPS-denied\nenvironments. Vision-based methods struggle when flight speed increases and\nclose-by objects lead to difficult visual conditions with considerable motion\nblur and large occlusions. To tackle this, vision is typically complemented by\nstate estimation filters that combine a drone model with inertial measurements.\nHowever, these drone models are currently learned in a supervised manner with\nground-truth data from external motion capture systems, limiting scalability to\ndifferent environments and drones. In this work, we propose a self-supervised\nlearning scheme to train a neural-network-based drone model using only onboard\nmonocular video and flight controller data (IMU and motor feedback). We achieve\nthis by first training a self-supervised relative pose estimation model, which\nthen serves as a teacher for the drone model. To allow this to work at high\nspeed close to obstacles, we propose an improved occlusion handling method for\ntraining self-supervised pose estimation models. Due to this method, the root\nmean squared error of resulting odometry estimates is reduced by an average of\n15%. Moreover, the student neural drone model can be successfully obtained from\nthe onboard data. It even becomes more accurate at higher speeds compared to\nits teacher, the self-supervised vision-based model. We demonstrate the value\nof the neural drone model by integrating it into a traditional filter-based VIO\nsystem (ROVIO), resulting in superior odometry accuracy on aggressive 3D racing\ntrajectories near obstacles. Self-supervised learning of ego-motion estimation\nrepresents a significant step toward bridging the gap between flying in\ncontrolled, expensive lab environments and real-world drone applications. The\nfusion of vision and drone models will enable higher-speed flight and improve\nstate estimation, on any drone in any environment.",
      "tldr_zh": "这篇论文提出了一种自监督学习方案，用于训练基于神经网络的无人机模型，仅利用机载单目视频和飞行控制器数据（IMU 和电机反馈），以解决高速度飞行中遮挡和运动模糊问题。作者引入改进的遮挡处理方法，训练自监督相对位姿估计模型作为教师模型，成功将根均方误差平均降低15%。随后，学生神经无人机模型在高速度条件下比教师模型更准确，并通过集成到传统 VIO 系统（ROVIO）中，提升了在侵略性 3D 赛车轨迹上的测距精度。这种方法标志着无人机 ego-motion estimation 向真实世界应用的重大进步，促进了在任何环境下的高速度飞行。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21695v1",
      "published_date": "2025-04-30 14:38:01 UTC",
      "updated_date": "2025-04-30 14:38:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:14:59.789954"
    },
    {
      "arxiv_id": "2504.21694v1",
      "title": "Automatic Mapping of AutomationML Files to Ontologies for Graph Queries and Validation",
      "title_zh": "用于图查询和验证的 AutomationML 文件到本体的自动映射",
      "authors": [
        "Tom Westermann",
        "Malte Ramonat",
        "Johannes Hujer",
        "Felix Gehlhoff",
        "Alexander Fay"
      ],
      "abstract": "AutomationML has seen widespread adoption as an open data exchange format in\nthe automation domain. It is an open and vendor neutral standard based on the\nextensible markup language XML. However, AutomationML extends XML with\nadditional semantics, that limit the applicability of common XML-tools for\napplications like querying or data validation. This article provides\npractitioners with 1) an up-to-date ontology of the concepts in the\nAutomationML-standard, as well as 2) a declarative mapping to automatically\ntransform any AutomationML model into RDF triples. Together, these artifacts\nallow practitioners an easy integration of AutomationML information into\nindustrial knowledge graphs. A study on examples from the automation domain\nconcludes that transforming AutomationML to OWL opens up new powerful ways for\nquerying and validation that are impossible without transformation.",
      "tldr_zh": "这篇论文针对AutomationML作为自动化领域基于XML的开放数据交换格式的问题，指出其额外语义限制了常见XML工具在查询和数据验证中的应用。论文的主要贡献包括：1) 提供AutomationML标准的最新ontology，以及2) 一个declarative mapping，用于自动将AutomationML模型转换为RDF triples，从而便于将其集成到工业knowledge graphs中。通过自动化领域的案例研究，研究发现，将AutomationML转换为OWL后，能够实现以前不可能的强大查询和验证功能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21694v1",
      "published_date": "2025-04-30 14:34:56 UTC",
      "updated_date": "2025-04-30 14:34:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:15:11.590210"
    },
    {
      "arxiv_id": "2504.21692v1",
      "title": "Enhancing Self-Supervised Fine-Grained Video Object Tracking with Dynamic Memory Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Zihan Zhou",
        "Changrui Dai",
        "Aibo Song",
        "Xiaolin Fang"
      ],
      "abstract": "Successful video analysis relies on accurate recognition of pixels across\nframes, and frame reconstruction methods based on video correspondence learning\nare popular due to their efficiency. Existing frame reconstruction methods,\nwhile efficient, neglect the value of direct involvement of multiple reference\nframes for reconstruction and decision-making aspects, especially in complex\nsituations such as occlusion or fast movement. In this paper, we introduce a\nDynamic Memory Prediction (DMP) framework that innovatively utilizes multiple\nreference frames to concisely and directly enhance frame reconstruction. Its\ncore component is a Reference Frame Memory Engine that dynamically selects\nframes based on object pixel features to improve tracking accuracy. In\naddition, a Bidirectional Target Prediction Network is built to utilize\nmultiple reference frames to improve the robustness of the model. Through\nexperiments, our algorithm outperforms the state-of-the-art self-supervised\ntechniques on two fine-grained video object tracking tasks: object segmentation\nand keypoint tracking.",
      "tldr_zh": "本研究提出Dynamic Memory Prediction (DMP)框架，以提升自监督细粒度视频对象跟踪的性能，特别针对现有帧重建方法在遮挡或快速移动等复杂场景中忽略多参考帧参与的问题。DMP的核心组件包括Reference Frame Memory Engine，该引擎基于对象像素特征动态选择参考帧，以提高跟踪准确性；此外，还构建了Bidirectional Target Prediction Network，利用多个参考帧增强模型的鲁棒性。通过实验，该算法在对象分割和关键点跟踪两个任务上，超过了最先进的自监督技术，展示了显著的性能提升。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21692v1",
      "published_date": "2025-04-30 14:29:04 UTC",
      "updated_date": "2025-04-30 14:29:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:15:22.504394"
    },
    {
      "arxiv_id": "2504.21685v1",
      "title": "Enhancing Health Mention Classification Performance: A Study on Advancements in Parameter Efficient Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Reem Abdel-Salam",
        "Mary Adewunmi"
      ],
      "abstract": "Health Mention Classification (HMC) plays a critical role in leveraging\nsocial media posts for real-time tracking and public health monitoring.\nNevertheless, the process of HMC presents significant challenges due to its\nintricate nature, primarily stemming from the contextual aspects of health\nmentions, such as figurative language and descriptive terminology, rather than\nexplicitly reflecting a personal ailment. To address this problem, we argue\nthat clearer mentions can be achieved through conventional fine-tuning with\nenhanced parameters of biomedical natural language methods (NLP). In this\nstudy, we explore different techniques such as the utilisation of\npart-of-speech (POS) tagger information, improving on PEFT techniques, and\ndifferent combinations thereof. Extensive experiments are conducted on three\nwidely used datasets: RHDM, PHM, and Illness. The results incorporated POS\ntagger information, and leveraging PEFT techniques significantly improves\nperformance in terms of F1-score compared to state-of-the-art methods across\nall three datasets by utilising smaller models and efficient training.\nFurthermore, the findings highlight the effectiveness of incorporating POS\ntagger information and leveraging PEFT techniques for HMC. In conclusion, the\nproposed methodology presents a potentially effective approach to accurately\nclassifying health mentions in social media posts while optimising the model\nsize and training efficiency.",
      "tldr_zh": "这篇论文探讨了如何提升 Health Mention Classification (HMC) 的性能，针对社交媒体帖子中健康提及的上下文挑战，如比喻语言和描述性术语。研究方法包括整合 part-of-speech (POS) tagger 信息、改进 Parameter Efficient Fine-Tuning (PEFT) 技术，以及它们的组合，以进行更有效的生物医学 NLP 微调。在 RHDM、PHM 和 Illness 数据集上的广泛实验显示，这种方法显著提高了 F1-score，比现有最先进方法表现更好，同时使用更小的模型和更高效的训练。总体而言，该方法为准确分类社交媒体健康提及提供了优化模型大小和训练效率的潜在解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.21685v1",
      "published_date": "2025-04-30 14:21:54 UTC",
      "updated_date": "2025-04-30 14:21:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:15:37.005821"
    },
    {
      "arxiv_id": "2504.21683v1",
      "title": "Extension-ranking Semantics for Abstract Argumentation Preprint",
      "title_zh": "翻译失败",
      "authors": [
        "Kenneth Skiba",
        "Tjitze Rienstra",
        "Matthias Thimm",
        "Jesse Heyninck",
        "Gabriele Kern-Isberner"
      ],
      "abstract": "In this paper, we present a general framework for ranking sets of arguments\nin abstract argumentation based on their plausibility of acceptance. We present\na generalisation of Dung's extension semantics as extension-ranking semantics,\nwhich induce a preorder over the power set of all arguments, allowing us to\nstate that one set is \"closer\" to being acceptable than another. To evaluate\nthe extension-ranking semantics, we introduce a number of principles that a\nwell-behaved extension-ranking semantics should satisfy. We consider several\nsimple base relations, each of which models a single central aspect of\nargumentative reasoning. The combination of these base relations provides us\nwith a family of extension-ranking semantics. We also adapt a number of\napproaches from the literature for ranking extensions to be usable in the\ncontext of extension-ranking semantics, and evaluate their behaviour.",
      "tldr_zh": "本论文提出了一种extension-ranking semantics框架，用于基于接受可能性对抽象论证（abstract argumentation）中的论点集合进行排名。该框架将Dung's extension semantics泛化为extension-ranking semantics，在所有论点的幂集上诱导偏序，从而允许比较一个集合比另一个更接近可接受状态。为评估该语义，论文引入了若干原则，并通过组合简单基关系（每个建模论证推理的核心方面）构建了一系列extension-ranking semantics，同时适应文献中的扩展排名方法并评估其行为。总的来说，此框架为论证系统的排序提供了更精细的工具，提升了论证推理的系统性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21683v1",
      "published_date": "2025-04-30 14:19:42 UTC",
      "updated_date": "2025-04-30 14:19:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:15:48.079215"
    },
    {
      "arxiv_id": "2504.21659v2",
      "title": "Ada-R1: Hybrid-CoT via Bi-Level Adaptive Reasoning Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Haotian Luo",
        "Haiying He",
        "Yibo Wang",
        "Jinluan Yang",
        "Rui Liu",
        "Naiqiang Tan",
        "Xiaochun Cao",
        "Dacheng Tao",
        "Li Shen"
      ],
      "abstract": "Recently, long-thought reasoning models achieve strong performance on complex\nreasoning tasks, but often incur substantial inference overhead, making\nefficiency a critical concern. Our empirical analysis reveals that the benefit\nof using Long-CoT varies across problems: while some problems require elaborate\nreasoning, others show no improvement, or even degraded accuracy. This\nmotivates adaptive reasoning strategies that tailor reasoning depth to the\ninput. However, prior work primarily reduces redundancy within long reasoning\npaths, limiting exploration of more efficient strategies beyond the Long-CoT\nparadigm. To address this, we propose a novel two-stage framework for adaptive\nand efficient reasoning. First, we construct a hybrid reasoning model by\nmerging long and short CoT models to enable diverse reasoning styles. Second,\nwe apply bi-level preference training to guide the model to select suitable\nreasoning styles (group-level), and prefer concise and correct reasoning within\neach style group (instance-level). Experiments demonstrate that our method\n(Ada-R1) significantly reduces inference costs compared to other baseline\napproaches, while maintaining performance. Notably, on five mathematical\ndatasets, the average length of reasoning is reduced by more than 50%,\nhighlighting the potential of adaptive strategies to optimize reasoning\nefficiency in large language models. Our code is coming soon at\nhttps://github.com/StarDewXXX/AdaR1",
      "tldr_zh": "该研究针对长链式思维推理（Long-CoT）模型在复杂任务上的高推理开销问题，提出Ada-R1框架，通过构建混合CoT模型（合并长短CoT以支持多样推理风格）来实现自适应优化。框架采用双层偏好训练（bi-level preference training），在组级选择合适的推理风格，并在实例级优先简洁正确的推理路径，从而根据输入问题动态调整推理深度。实验结果显示，Ada-R1在五个数学数据集上将推理平均长度减少超过50%，显著降低推理成本，同时维持性能水平，为高效的大型语言模型推理策略提供了新途径。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21659v2",
      "published_date": "2025-04-30 14:01:45 UTC",
      "updated_date": "2025-05-21 11:59:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:16:00.528378"
    },
    {
      "arxiv_id": "2504.21643v1",
      "title": "Designing Control Barrier Function via Probabilistic Enumeration for Safe Reinforcement Learning Navigation",
      "title_zh": "翻译失败",
      "authors": [
        "Luca Marzari",
        "Francesco Trotti",
        "Enrico Marchesini",
        "Alessandro Farinelli"
      ],
      "abstract": "Achieving safe autonomous navigation systems is critical for deploying robots\nin dynamic and uncertain real-world environments. In this paper, we propose a\nhierarchical control framework leveraging neural network verification\ntechniques to design control barrier functions (CBFs) and policy correction\nmechanisms that ensure safe reinforcement learning navigation policies. Our\napproach relies on probabilistic enumeration to identify unsafe regions of\noperation, which are then used to construct a safe CBF-based control layer\napplicable to arbitrary policies. We validate our framework both in simulation\nand on a real robot, using a standard mobile robot benchmark and a highly\ndynamic aquatic environmental monitoring task. These experiments demonstrate\nthe ability of the proposed solution to correct unsafe actions while preserving\nefficient navigation behavior. Our results show the promise of developing\nhierarchical verification-based systems to enable safe and robust navigation\nbehaviors in complex scenarios.",
      "tldr_zh": "本研究提出了一种分层控制框架，通过神经网络验证技术设计 Control Barrier Function (CBFs) 和策略修正机制，以确保强化学习导航策略的安全性。该方法利用 Probabilistic Enumeration 识别操作中的不安全区域，并构建基于 CBF 的安全控制层，适用于任意策略。在模拟和真实机器人实验中，包括标准移动机器人基准和动态水生环境监测任务，该框架成功修正了不安全动作，同时维持了高效导航行为。这些结果证明了基于分层验证系统的潜力，可实现复杂场景中的鲁棒安全导航。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21643v1",
      "published_date": "2025-04-30 13:47:25 UTC",
      "updated_date": "2025-04-30 13:47:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:16:10.202291"
    },
    {
      "arxiv_id": "2504.21635v1",
      "title": "Sadeed: Advancing Arabic Diacritization Through Small Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Zeina Aldallal",
        "Sara Chrouf",
        "Khalil Hennara",
        "Mohamed Motaism Hamed",
        "Muhammad Hreden",
        "Safwan AlModhayan"
      ],
      "abstract": "Arabic text diacritization remains a persistent challenge in natural language\nprocessing due to the language's morphological richness. In this paper, we\nintroduce Sadeed, a novel approach based on a fine-tuned decoder-only language\nmodel adapted from Kuwain 1.5B Hennara et al. [2025], a compact model\noriginally trained on diverse Arabic corpora. Sadeed is fine-tuned on carefully\ncurated, high-quality diacritized datasets, constructed through a rigorous\ndata-cleaning and normalization pipeline. Despite utilizing modest\ncomputational resources, Sadeed achieves competitive results compared to\nproprietary large language models and outperforms traditional models trained on\nsimilar domains. Additionally, we highlight key limitations in current\nbenchmarking practices for Arabic diacritization. To address these issues, we\nintroduce SadeedDiac-25, a new benchmark designed to enable fairer and more\ncomprehensive evaluation across diverse text genres and complexity levels.\nTogether, Sadeed and SadeedDiac-25 provide a robust foundation for advancing\nArabic NLP applications, including machine translation, text-to-speech, and\nlanguage learning tools.",
      "tldr_zh": "本研究针对阿拉伯语的形态丰富性带来的 diacritization 挑战，引入了 Sadeed，这是一种基于小语言模型（fine-tuned from Kuwain 1.5B）的解码器-only 方法，通过严格的数据清洗和归一化数据集进行微调。Sadeed 尽管使用 modest computational resources，仍实现了与 proprietary large language models 相当的性能，并优于传统模型。论文还指出了当前 benchmarking practices 的局限性，并提出新基准 SadeedDiac-25，以支持更公平、全面的评估，从而为 Arabic NLP 应用（如 machine translation、text-to-speech 和 language learning tools）提供坚实基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21635v1",
      "published_date": "2025-04-30 13:37:24 UTC",
      "updated_date": "2025-04-30 13:37:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:16:23.936480"
    },
    {
      "arxiv_id": "2504.21634v1",
      "title": "Quantitative Auditing of AI Fairness with Differentially Private Synthetic Data",
      "title_zh": "利用差分隐私合成数据进行 AI 公平性定量审计",
      "authors": [
        "Chih-Cheng Rex Yuan",
        "Bow-Yaw Wang"
      ],
      "abstract": "Fairness auditing of AI systems can identify and quantify biases. However,\ntraditional auditing using real-world data raises security and privacy\nconcerns. It exposes auditors to security risks as they become custodians of\nsensitive information and targets for cyberattacks. Privacy risks arise even\nwithout direct breaches, as data analyses can inadvertently expose confidential\ninformation. To address these, we propose a framework that leverages\ndifferentially private synthetic data to audit the fairness of AI systems. By\napplying privacy-preserving mechanisms, it generates synthetic data that\nmirrors the statistical properties of the original dataset while ensuring\nprivacy. This method balances the goal of rigorous fairness auditing and the\nneed for strong privacy protections. Through experiments on real datasets like\nAdult, COMPAS, and Diabetes, we compare fairness metrics of synthetic and real\ndata. By analyzing the alignment and discrepancies between these metrics, we\nassess the capacity of synthetic data to preserve the fairness properties of\nreal data. Our results demonstrate the framework's ability to enable meaningful\nfairness evaluations while safeguarding sensitive information, proving its\napplicability across critical and sensitive domains.",
      "tldr_zh": "该研究提出一个框架，使用 Differentially Private 合成数据来审计 AI 系统的公平性，以解决传统方法带来的安全和隐私风险。该框架通过差分隐私机制生成模拟原始数据集统计属性的合成数据，确保审计过程保护敏感信息，同时保持公平性评估的可靠性。在 Adult、COMPAS 和 Diabetes 等真实数据集上的实验中，合成数据的公平性指标与真实数据高度一致，证明该方法能实现有效的公平审计并适用于关键领域。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21634v1",
      "published_date": "2025-04-30 13:36:27 UTC",
      "updated_date": "2025-04-30 13:36:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:16:35.465779"
    },
    {
      "arxiv_id": "2504.21605v1",
      "title": "RDF-Based Structured Quality Assessment Representation of Multilingual LLM Evaluations",
      "title_zh": "翻译失败",
      "authors": [
        "Jonas Gwozdz",
        "Andreas Both"
      ],
      "abstract": "Large Language Models (LLMs) increasingly serve as knowledge interfaces, yet\nsystematically assessing their reliability with conflicting information remains\ndifficult. We propose an RDF-based framework to assess multilingual LLM\nquality, focusing on knowledge conflicts. Our approach captures model responses\nacross four distinct context conditions (complete, incomplete, conflicting, and\nno-context information) in German and English. This structured representation\nenables the comprehensive analysis of knowledge leakage-where models favor\ntraining data over provided context-error detection, and multilingual\nconsistency. We demonstrate the framework through a fire safety domain\nexperiment, revealing critical patterns in context prioritization and\nlanguage-specific performance, and demonstrating that our vocabulary was\nsufficient to express every assessment facet encountered in the 28-question\nstudy.",
      "tldr_zh": "该论文提出了一种基于 RDF 的结构化框架，用于评估多语言大型语言模型（LLMs）的质量，特别关注知识冲突问题。该框架通过捕获模型在四种上下文条件（完整、Incomplete、Conflicting 和 No-Context）下的响应，并在德语和英语中进行测试，实现对知识泄露（Knowledge Leakage）、错误检测和多语言一致性的全面分析。实验以火灾安全领域为例，揭示了模型在上下文优先级和语言特定性能方面的关键模式，并证明了所用词汇能够充分表达评估的所有方面。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21605v1",
      "published_date": "2025-04-30 13:06:40 UTC",
      "updated_date": "2025-04-30 13:06:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:16:47.649043"
    },
    {
      "arxiv_id": "2505.03780v2",
      "title": "GPU Performance Portability needs Autotuning",
      "title_zh": "翻译失败",
      "authors": [
        "Burkhard Ringlein",
        "Thomas Parnell",
        "Radu Stoica"
      ],
      "abstract": "As LLMs grow in complexity, achieving state-of-the-art performance requires\ntight co-design across algorithms, software, and hardware. Today's reliance on\na single dominant platform limits portability, creates vendor lock-in, and\nraises barriers for new AI hardware. In this work, we make the case for\ncombining just-in-time (JIT) compilation with kernel parameter autotuning to\nenable portable LLM inference with state-of-the-art performance without code\nchanges. Focusing on flash attention -- a widespread performance critical LLM\nkernel -- we demonstrate that this approach explores up to 15x more kernel\nparameter configurations, produces significantly more diverse code across\nmultiple dimensions, and even outperforms vendor-optimized implementations by\nup to 230%, all while reducing kernel code size by 70x and eliminating manual\ncode optimizations. Our results highlight autotuning as a promising path to\nunlocking model portability across GPU vendors.",
      "tldr_zh": "该论文强调，随着大型语言模型（LLMs）的复杂性增加，实现最先进性能需要算法、软件和硬件的紧密协同设计，但当前依赖单一平台的做法导致了可移植性问题、供应商锁定和新硬件障碍。作者主张通过结合即时编译（JIT）和内核参数自动调整（autotuning），实现无需代码修改的、可移植的 LLM 推理。针对 flash attention 内核，实验显示这种方法探索了多达 15 倍的配置选项，产生更多样化的代码，并比供应商优化实现高出 230% 的性能，同时将内核代码大小减少 70 倍。结果表明，autotuning 是提升 GPU 供应商间模型可移植性的关键路径。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.AR",
      "comment": "typos, fix grammatical mistakes",
      "pdf_url": "http://arxiv.org/pdf/2505.03780v2",
      "published_date": "2025-04-30 12:57:21 UTC",
      "updated_date": "2025-05-15 14:26:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:17:00.342531"
    },
    {
      "arxiv_id": "2504.21596v1",
      "title": "Leveraging Pre-trained Large Language Models with Refined Prompting for Online Task and Motion Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Huihui Guo",
        "Huilong Pi",
        "Yunchuan Qin",
        "Zhuo Tang",
        "Kenli Li"
      ],
      "abstract": "With the rapid advancement of artificial intelligence, there is an increasing\ndemand for intelligent robots capable of assisting humans in daily tasks and\nperforming complex operations. Such robots not only require task planning\ncapabilities but must also execute tasks with stability and robustness. In this\npaper, we present a closed-loop task planning and acting system, LLM-PAS, which\nis assisted by a pre-trained Large Language Model (LLM). While LLM-PAS plans\nlong-horizon tasks in a manner similar to traditional task and motion planners,\nit also emphasizes the execution phase of the task. By transferring part of the\nconstraint-checking process from the planning phase to the execution phase,\nLLM-PAS enables exploration of the constraint space and delivers more accurate\nfeedback on environmental anomalies during execution. The reasoning\ncapabilities of the LLM allow it to handle anomalies that cannot be addressed\nby the robust executor. To further enhance the system's ability to assist the\nplanner during replanning, we propose the First Look Prompting (FLP) method,\nwhich induces LLM to generate effective PDDL goals. Through comparative\nprompting experiments and systematic experiments, we demonstrate the\neffectiveness and robustness of LLM-PAS in handling anomalous conditions during\ntask execution.",
      "tldr_zh": "本研究提出了一种闭环任务规划和执行系统LLM-PAS，利用预训练Large Language Models (LLM)来辅助在线任务和运动规划，从而提升机器人在处理复杂任务时的稳定性和鲁棒性。该系统将部分约束检查从规划阶段转移到执行阶段，允许探索约束空间并提供更准确的环境异常反馈，同时通过LLM的推理能力处理无法由执行器解决的异常。为优化规划，引入First Look Prompting (FLP)方法，帮助LLM生成有效的PDDL目标。实验结果显示，LLM-PAS在处理任务执行中的异常时表现出色，具有较高的有效性和鲁棒性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21596v1",
      "published_date": "2025-04-30 12:53:53 UTC",
      "updated_date": "2025-04-30 12:53:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:17:12.302104"
    },
    {
      "arxiv_id": "2504.21589v1",
      "title": "DNB-AI-Project at SemEval-2025 Task 5: An LLM-Ensemble Approach for Automated Subject Indexing",
      "title_zh": "翻译失败",
      "authors": [
        "Lisa Kluge",
        "Maximilian Kähler"
      ],
      "abstract": "This paper presents our system developed for the SemEval-2025 Task 5:\nLLMs4Subjects: LLM-based Automated Subject Tagging for a National Technical\nLibrary's Open-Access Catalog. Our system relies on prompting a selection of\nLLMs with varying examples of intellectually annotated records and asking the\nLLMs to similarly suggest keywords for new records. This few-shot prompting\ntechnique is combined with a series of post-processing steps that map the\ngenerated keywords to the target vocabulary, aggregate the resulting subject\nterms to an ensemble vote and, finally, rank them as to their relevance to the\nrecord. Our system is fourth in the quantitative ranking in the all-subjects\ntrack, but achieves the best result in the qualitative ranking conducted by\nsubject indexing experts.",
      "tldr_zh": "这篇论文介绍了 DNB-AI-Project 系统，针对 SemEval-2025 Task 5（LLMs4Subjects），提出了一种基于 LLM-Ensemble 的方法，用于国家技术图书馆开放目录的自动主题标记。系统采用 few-shot prompting 技术，让多个 LLM 通过示例记录生成关键词，并结合后处理步骤（如映射到目标词汇、聚合 ensemble vote 和排名）来优化输出。在实验中，该系统在 all-subjects 轨道中排名第四，但在专家进行的定性评估中取得了最佳结果。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DL",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages, 4 figures, submitted to SemEval-2025 workshop Task 5:\n  LLMs4Subjects",
      "pdf_url": "http://arxiv.org/pdf/2504.21589v1",
      "published_date": "2025-04-30 12:47:09 UTC",
      "updated_date": "2025-04-30 12:47:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:17:23.947046"
    },
    {
      "arxiv_id": "2504.21586v1",
      "title": "One Net to Rule Them All: Domain Randomization in Quadcopter Racing Across Different Platforms",
      "title_zh": "翻译失败",
      "authors": [
        "Robin Ferede",
        "Till Blaha",
        "Erin Lucassen",
        "Christophe De Wagter",
        "Guido C. H. E. de Croon"
      ],
      "abstract": "In high-speed quadcopter racing, finding a single controller that works well\nacross different platforms remains challenging. This work presents the first\nneural network controller for drone racing that generalizes across physically\ndistinct quadcopters. We demonstrate that a single network, trained with domain\nrandomization, can robustly control various types of quadcopters. The network\nrelies solely on the current state to directly compute motor commands. The\neffectiveness of this generalized controller is validated through real-world\ntests on two substantially different crafts (3-inch and 5-inch race\nquadcopters). We further compare the performance of this generalized controller\nwith controllers specifically trained for the 3-inch and 5-inch drone, using\ntheir identified model parameters with varying levels of domain randomization\n(0%, 10%, 20%, 30%). While the generalized controller shows slightly slower\nspeeds compared to the fine-tuned models, it excels in adaptability across\ndifferent platforms. Our results show that no randomization fails sim-to-real\ntransfer while increasing randomization improves robustness but reduces speed.\nDespite this trade-off, our findings highlight the potential of domain\nrandomization for generalizing controllers, paving the way for universal AI\ncontrollers that can adapt to any platform.",
      "tldr_zh": "本文提出一个通过领域随机化（domain randomization）训练的神经网络控制器，用于高速度四旋翼无人机（quadcopters）竞赛，能够在物理上不同的平台上实现泛化。控制器仅基于当前状态直接计算电机命令，并在真实测试中验证了其在3英寸和5英寸无人机上的鲁棒性能。与针对特定无人机的控制器相比，该泛化控制器虽速度稍慢，但表现出更强的适应性。研究结果表明，增加随机化水平能提升鲁棒性并改善模拟到真实（sim-to-real）转移，但会带来速度权衡，为开发通用AI控制器铺平道路。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21586v1",
      "published_date": "2025-04-30 12:44:41 UTC",
      "updated_date": "2025-04-30 12:44:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:17:37.437263"
    },
    {
      "arxiv_id": "2504.21585v1",
      "title": "Multi-Goal Dexterous Hand Manipulation using Probabilistic Model-based Reinforcement Learning",
      "title_zh": "使用基于概率模型的强化学习进行多目标灵巧手操控",
      "authors": [
        "Yingzhuo Jiang",
        "Wenjun Huang",
        "Rongdun Lin",
        "Chenyang Miao",
        "Tianfu Sun",
        "Yunduan Cui"
      ],
      "abstract": "This paper tackles the challenge of learning multi-goal dexterous hand\nmanipulation tasks using model-based Reinforcement Learning. We propose\nGoal-Conditioned Probabilistic Model Predictive Control (GC-PMPC) by designing\nprobabilistic neural network ensembles to describe the high-dimensional\ndexterous hand dynamics and introducing an asynchronous MPC policy to meet the\ncontrol frequency requirements in real-world dexterous hand systems. Extensive\nevaluations on four simulated Shadow Hand manipulation scenarios with randomly\ngenerated goals demonstrate GC-PMPC's superior performance over\nstate-of-the-art baselines. It successfully drives a cable-driven Dexterous\nhand, DexHand 021 with 12 Active DOFs and 5 tactile sensors, to learn\nmanipulating a cubic die to three goal poses within approximately 80 minutes of\ninteractions, demonstrating exceptional learning efficiency and control\nperformance on a cost-effective dexterous hand platform.",
      "tldr_zh": "本文提出了一种基于概率模型的强化学习方法，即Goal-Conditioned Probabilistic Model Predictive Control (GC-PMPC)，用于解决多目标灵巧手操作任务。该方法通过概率神经网络集成描述高维灵巧手动态，并引入异步MPC策略以满足实时控制需求。在四个模拟Shadow Hand场景中，GC-PMPC比最先进基线表现出色，并在真实硬件上成功驱动DexHand 021（12个主动自由度、5个触觉传感器）在约80分钟内完成立方体操作目标，展示了高效的学习和控制性能。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21585v1",
      "published_date": "2025-04-30 12:44:38 UTC",
      "updated_date": "2025-04-30 12:44:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:17:48.218455"
    },
    {
      "arxiv_id": "2504.21582v2",
      "title": "MF-LLM: Simulating Population Decision Dynamics via a Mean-Field Large Language Model Framework",
      "title_zh": "MF-LLM",
      "authors": [
        "Qirui Mi",
        "Mengyue Yang",
        "Xiangning Yu",
        "Zhiyu Zhao",
        "Cheng Deng",
        "Bo An",
        "Haifeng Zhang",
        "Xu Chen",
        "Jun Wang"
      ],
      "abstract": "Simulating collective decision-making involves more than aggregating\nindividual behaviors; it emerges from dynamic interactions among individuals.\nWhile large language models (LLMs) offer strong potential for social\nsimulation, achieving quantitative alignment with real-world data remains a key\nchallenge. To bridge this gap, we propose the Mean-Field LLM (MF-LLM)\nframework, the first to incorporate mean field theory into LLM-based social\nsimulation. MF-LLM models bidirectional interactions between individuals and\nthe population through an iterative process, generating population signals to\nguide individual decisions, which in turn update the signals. This interplay\nproduces coherent trajectories of collective behavior. To improve alignment\nwith real-world data, we introduce IB-Tune, a novel fine-tuning method inspired\nby the Information Bottleneck principle, which retains population signals most\npredictive of future actions while filtering redundant history. Evaluated on a\nreal-world social dataset, MF-LLM reduces KL divergence to human population\ndistributions by 47\\% compared to non-mean-field baselines, enabling accurate\ntrend forecasting and effective intervention planning. Generalizing across 7\ndomains and 4 LLM backbones, MF-LLM provides a scalable, high-fidelity\nfoundation for social simulation.",
      "tldr_zh": "该研究提出 MF-LLM 框架，这是首个将 mean field theory 整合到大型语言模型(LLMs)基于的社会模拟中的方法，用于模拟群体决策动态。框架通过迭代过程处理个体与群体的双向互动，生成群体信号指导个体决策，并反向更新信号，以产生更连贯的集体行为。为提升与真实数据的对齐，引入 IB-Tune 微调方法，该方法基于信息瓶颈原则保留最预测性的信号。实验在真实社会数据集上显示，MF-LLM 比基线模型降低了 47% 的 KL divergence，并在 7 个领域和 4 个 LLM 骨干上实现可扩展和高保真度的趋势预测及干预规划。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "29 pages, 8 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.21582v2",
      "published_date": "2025-04-30 12:41:51 UTC",
      "updated_date": "2025-05-19 13:12:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:18:02.143389"
    },
    {
      "arxiv_id": "2505.07831v1",
      "title": "Polysemy of Synthetic Neurons Towards a New Type of Explanatory Categorical Vector Spaces",
      "title_zh": "合成神经元的多义性朝向一种新的解释性",
      "authors": [
        "Michael Pichat",
        "William Pogrund",
        "Paloma Pichat",
        "Judicael Poumay",
        "Armanouche Gasparian",
        "Samuel Demarchi",
        "Martin Corbet",
        "Alois Georgeon",
        "Michael Veillet-Guillem"
      ],
      "abstract": "The polysemantic nature of synthetic neurons in artificial intelligence\nlanguage models is currently understood as the result of a necessary\nsuperposition of distributed features within the latent space. We propose an\nalternative approach, geometrically defining a neuron in layer n as a\ncategorical vector space with a non-orthogonal basis, composed of categorical\nsub-dimensions extracted from preceding neurons in layer n-1. This categorical\nvector space is structured by the activation space of each neuron and enables,\nvia an intra-neuronal attention process, the identification and utilization of\na critical categorical zone for the efficiency of the language model - more\nhomogeneous and located at the intersection of these different categorical\nsub-dimensions.",
      "tldr_zh": "这篇论文探讨了人工智能语言模型中合成神经元（synthetic neurons）的多义性（polysemy），挑战了现有观点，将其视为潜在空间中分布式特征的叠加。作者提出一种新方法，将层 n 的神经元几何定义为一个带有非正交基的分类向量空间（categorical vector space），其基础由层 n-1 的神经元提取的分类子维度组成。该框架通过内部神经元注意力（intra-neuronal attention）过程，识别出一个关键的分类区域（critical categorical zone），该区域更均匀并位于不同子维度的交汇处，从而提升语言模型的效率和解释性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07831v1",
      "published_date": "2025-04-30 12:33:28 UTC",
      "updated_date": "2025-04-30 12:33:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:18:12.454831"
    },
    {
      "arxiv_id": "2504.21568v1",
      "title": "A Study on Group Decision Making Problem Based on Fuzzy Reasoning and Bayesian Networks",
      "title_zh": "基于模糊推理和贝叶斯网络的群决策问题研究",
      "authors": [
        "Shui-jin Rong",
        "Wei Guo",
        "Da-qing Zhang"
      ],
      "abstract": "Aiming at the group decision - making problem with multi - objective\nattributes, this study proposes a group decision - making system that\nintegrates fuzzy inference and Bayesian network. A fuzzy rule base is\nconstructed by combining threshold values, membership functions, expert\nexperience, and domain knowledge to address quantitative challenges such as\nscale differences and expert linguistic variables. A hierarchical Bayesian\nnetwork is designed, featuring a directed acyclic graph with nodes selected by\nexperts, and maximum likelihood estimation is used to dynamically optimize the\nconditional probability table, modeling the nonlinear correlations among\nmultidimensional indices for posterior probability aggregation. In a\ncomprehensive student evaluation case, this method is compared with the\ntraditional weighted scoring approach. The results indicate that the proposed\nmethod demonstrates effectiveness in both rule criterion construction and\nranking consistency, with a classification accuracy of 86.0% and an F1 value\nimprovement of 53.4% over the traditional method. Additionally, computational\nexperiments on real - world datasets across various group decision scenarios\nassess the method's performance and robustness, providing evidence of its\nreliability in diverse contexts.",
      "tldr_zh": "这篇论文研究了基于模糊推理和Bayesian networks的多目标属性群决策问题，提出了一种整合模糊推理和分层Bayesian network的决策系统。系统通过构建模糊规则库（结合阈值、membership functions、专家经验和领域知识）来处理量化挑战，如规模差异和专家语言变量，并使用最大似然估计动态优化条件概率表，以模型多维指标之间的非线性相关性和后验概率聚合。在学生评价案例中，该方法与传统加权评分方法相比，展示了在规则标准构建和排名一致性上的有效性，分类准确率达86.0%，F1值提高了53.4%；此外，在真实世界数据集上的实验验证了其性能和鲁棒性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21568v1",
      "published_date": "2025-04-30 12:14:48 UTC",
      "updated_date": "2025-04-30 12:14:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:18:25.197358"
    },
    {
      "arxiv_id": "2504.21565v1",
      "title": "Towards proactive self-adaptive AI for non-stationary environments with dataset shifts",
      "title_zh": "针对具有数据集偏移的非平稳环境的主动自适应 AI",
      "authors": [
        "David Fernández Narro",
        "Pablo Ferri",
        "Juan M. García-Gómez",
        "Carlos Sáez"
      ],
      "abstract": "Artificial Intelligence (AI) models deployed in production frequently face\nchallenges in maintaining their performance in non-stationary environments.\nThis issue is particularly noticeable in medical settings, where temporal\ndataset shifts often occur. These shifts arise when the distributions of\ntraining data differ from those of the data encountered during deployment over\ntime. Further, new labeled data to continuously retrain AI is not typically\navailable in a timely manner due to data access limitations. To address these\nchallenges, we propose a proactive self-adaptive AI approach, or pro-adaptive,\nwhere we model the temporal trajectory of AI parameters, allowing us to\nshort-term forecast parameter values. To this end, we use polynomial spline\nbases, within an extensible Functional Data Analysis framework. We validate our\nmethodology with a logistic regression model addressing prior probability\nshift, covariate shift, and concept shift. This validation is conducted on both\na controlled simulated dataset and a publicly available real-world COVID-19\ndataset from Mexico, with various shifts occurring between 2020 and 2024. Our\nresults indicate that this approach enhances the performance of AI against\nshifts compared to baseline stable models trained at different time distances\nfrom the present, without requiring updated training data. This work lays the\nfoundation for pro-adaptive AI research against dynamic, non-stationary\nenvironments, being compatible with data protection, in resilient AI production\nenvironments for health.",
      "tldr_zh": "本研究针对AI模型在非平稳环境（如医疗领域）中面临的性能挑战，特别是在temporal dataset shifts（如prior probability shift、covariate shift和concept shift）下，提出一种proactive self-adaptive AI（pro-adaptive）方法，以应对训练数据分布变化和新标签数据获取困难的问题。  \n该方法通过建模AI参数的temporal trajectory，利用polynomial spline bases和Functional Data Analysis框架，进行短期参数预测，从而实现模型的自适应调整，而无需实时更新训练数据。  \n在控制模拟数据集和真实COVID-19数据集（覆盖2020-2024年间各种偏移）上验证，pro-adaptive方法相较于基线稳定模型，显著提升了AI的性能。  \n这项工作为在动态、非平稳环境中构建resilient AI奠定了基础，同时兼容数据保护要求。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.8"
      ],
      "primary_category": "cs.LG",
      "comment": "6 pages, 4 figures, conference paper",
      "pdf_url": "http://arxiv.org/pdf/2504.21565v1",
      "published_date": "2025-04-30 12:09:59 UTC",
      "updated_date": "2025-04-30 12:09:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:18:36.102830"
    },
    {
      "arxiv_id": "2504.21562v1",
      "title": "eNCApsulate: NCA for Precision Diagnosis on Capsule Endoscopes",
      "title_zh": "eNCApsulate：NCA 用于胶囊内镜的精确诊断",
      "authors": [
        "Henry John Krumb",
        "Anirban Mukhopadhyay"
      ],
      "abstract": "Wireless Capsule Endoscopy is a non-invasive imaging method for the entire\ngastrointestinal tract, and is a pain-free alternative to traditional\nendoscopy. It generates extensive video data that requires significant review\ntime, and localizing the capsule after ingestion is a challenge. Techniques\nlike bleeding detection and depth estimation can help with localization of\npathologies, but deep learning models are typically too large to run directly\non the capsule. Neural Cellular Automata (NCA) for bleeding segmentation and\ndepth estimation are trained on capsule endoscopic images. For monocular depth\nestimation, we distill a large foundation model into the lean NCA architecture,\nby treating the outputs of the foundation model as pseudo ground truth. We then\nport the trained NCA to the ESP32 microcontroller, enabling efficient image\nprocessing on hardware as small as a camera capsule. NCA are more accurate\n(Dice) than other portable segmentation models, while requiring more than 100x\nfewer parameters stored in memory than other small-scale models. The visual\nresults of NCA depth estimation look convincing, and in some cases beat the\nrealism and detail of the pseudo ground truth. Runtime optimizations on the\nESP32-S3 accelerate the average inference speed significantly, by more than\nfactor 3. With several algorithmic adjustments and distillation, it is possible\nto eNCApsulate NCA models into microcontrollers that fit into wireless capsule\nendoscopes. This is the first work that enables reliable bleeding segmentation\nand depth estimation on a miniaturized device, paving the way for precise\ndiagnosis combined with visual odometry as a means of precise localization of\nthe capsule -- on the capsule.",
      "tldr_zh": "该研究提出 eNCApsulate 框架，利用 Neural Cellular Automata (NCA) 进行胶囊内镜的出血分割和单目深度估计，以解决无线胶囊内镜数据审查时间长和定位挑战的问题。通过知识蒸馏，将大型基础模型提炼到 NCA 架构中，并移植到 ESP32 微控制器上，实现高效的设备端图像处理。实验显示，NCA 在 Dice 准确性上优于其他便携模型，且参数量减少 100 倍以上，推理速度在 ESP32-S3 上提升 3 倍；这标志着首次在微型设备上实现可靠的出血检测和深度估计，为精确诊断和胶囊定位铺平道路。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21562v1",
      "published_date": "2025-04-30 12:06:56 UTC",
      "updated_date": "2025-04-30 12:06:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:18:48.801109"
    },
    {
      "arxiv_id": "2504.21559v1",
      "title": "Black-Box Visual Prompt Engineering for Mitigating Object Hallucination in Large Vision Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Sangmin Woo",
        "Kang Zhou",
        "Yun Zhou",
        "Shuai Wang",
        "Sheng Guan",
        "Haibo Ding",
        "Lin Lee Cheong"
      ],
      "abstract": "Large Vision Language Models (LVLMs) often suffer from object hallucination,\nwhich undermines their reliability. Surprisingly, we find that simple\nobject-based visual prompting -- overlaying visual cues (e.g., bounding box,\ncircle) on images -- can significantly mitigate such hallucination; however,\ndifferent visual prompts (VPs) vary in effectiveness. To address this, we\npropose Black-Box Visual Prompt Engineering (BBVPE), a framework to identify\noptimal VPs that enhance LVLM responses without needing access to model\ninternals. Our approach employs a pool of candidate VPs and trains a router\nmodel to dynamically select the most effective VP for a given input image. This\nblack-box approach is model-agnostic, making it applicable to both open-source\nand proprietary LVLMs. Evaluations on benchmarks such as POPE and CHAIR\ndemonstrate that BBVPE effectively reduces object hallucination.",
      "tldr_zh": "大型视觉语言模型(LVLMs)经常出现对象 hallucination 问题，导致可靠性下降。论文提出 Black-Box Visual Prompt Engineering (BBVPE) 框架，使用一组候选视觉提示(VPs)并训练路由器模型来动态选择最有效的 VP，从而缓解幻觉而不需访问模型内部。该方法是模型无关的，可应用于开源和专有 LVLMs。在 POPE 和 CHAIR 等基准测试中，BBVPE 有效减少了对象 hallucination。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.21559v1",
      "published_date": "2025-04-30 11:58:30 UTC",
      "updated_date": "2025-04-30 11:58:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:19:00.949183"
    },
    {
      "arxiv_id": "2504.21545v1",
      "title": "Meta knowledge assisted Evolutionary Neural Architecture Search",
      "title_zh": "元知识辅助的进化神经架构搜索",
      "authors": [
        "Yangyang Li",
        "Guanlong Liu",
        "Ronghua Shang",
        "Licheng Jiao"
      ],
      "abstract": "Evolutionary computation (EC)-based neural architecture search (NAS) has\nachieved remarkable performance in the automatic design of neural\narchitectures. However, the high computational cost associated with evaluating\nsearched architectures poses a challenge for these methods, and a fixed form of\nlearning rate (LR) schedule means greater information loss on diverse searched\narchitectures. This paper introduces an efficient EC-based NAS method to solve\nthese problems via an innovative meta-learning framework. Specifically, a\nmeta-learning-rate (Meta-LR) scheme is used through pretraining to obtain a\nsuitable LR schedule, which guides the training process with lower information\nloss when evaluating each individual. An adaptive surrogate model is designed\nthrough an adaptive threshold to select the potential architectures in a few\nepochs and then evaluate the potential architectures with complete epochs.\nAdditionally, a periodic mutation operator is proposed to increase the\ndiversity of the population, which enhances the generalizability and\nrobustness. Experiments on CIFAR-10, CIFAR-100, and ImageNet1K datasets\ndemonstrate that the proposed method achieves high performance comparable to\nthat of many state-of-the-art peer methods, with lower computational cost and\ngreater robustness.",
      "tldr_zh": "这篇论文提出了一种基于元知识辅助的进化神经架构搜索（Evolutionary Neural Architecture Search, EC-based NAS）方法，通过创新的元学习框架解决高计算成本和固定学习率（LR）调度导致的信息损失问题。方法包括Meta-LR方案，通过预训练获取合适的LR调度以减少评估时的信息损失；自适应代理模型，使用自适应阈值在少量epochs中筛选潜在架构，并用完整epochs进行评估；以及周期性变异操作符，以增加种群多样性并提升泛化性和鲁棒性。在CIFAR-10、CIFAR-100和ImageNet1K数据集上的实验显示，该方法实现了与最先进方法相当的高性能，同时显著降低了计算成本并增强了鲁棒性。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21545v1",
      "published_date": "2025-04-30 11:43:07 UTC",
      "updated_date": "2025-04-30 11:43:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:19:14.210176"
    },
    {
      "arxiv_id": "2505.15821v1",
      "title": "A Novel Compound AI Model for 6G Networks in 3D Continuum",
      "title_zh": "翻译失败",
      "authors": [
        "Milos Gravara",
        "Andrija Stanisic",
        "Stefan Nastic"
      ],
      "abstract": "The 3D continuum presents a complex environment that spans the terrestrial,\naerial and space domains, with 6Gnetworks serving as a key enabling technology.\nCurrent AI approaches for network management rely on monolithic models that\nfail to capture cross-domain interactions, lack adaptability,and demand\nprohibitive computational resources. This paper presents a formal model of\nCompound AI systems, introducing a novel tripartite framework that decomposes\ncomplex tasks into specialized, interoperable modules. The proposed modular\narchitecture provides essential capabilities to address the unique challenges\nof 6G networks in the 3D continuum, where heterogeneous components require\ncoordinated, yet distributed, intelligence. This approach introduces a\nfundamental trade-off between model and system performance, which must be\ncarefully addressed. Furthermore, we identify key challenges faced by Compound\nAI systems within 6G networks operating in the 3D continuum, including\ncross-domain resource orchestration, adaptation to dynamic topologies, and the\nmaintenance of consistent AI service quality across heterogeneous environments.",
      "tldr_zh": "本研究针对6G网络在3D Continuum（包括陆地、空中和空间域）的复杂环境，提出了一种新型Compound AI模型，以解决现有monolithic models在网络管理中捕捉跨域交互不足、适应性差和高计算资源需求的问题。该模型引入一个tripartite framework，将复杂任务分解为专业化、可互操作的模块，实现协调分布式智能，并处理异构组件的挑战。同时，论文探讨了模型与系统性能之间的基本trade-off，并识别关键挑战，如跨域资源orchestration、适应动态topologies以及维护一致的AI服务质量。总的来说，这一框架为6G网络的管理提供了更高效、可扩展的解决方案。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "I.2.11; C.2.3; C.2.4"
      ],
      "primary_category": "cs.NI",
      "comment": "4 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.15821v1",
      "published_date": "2025-04-30 11:28:33 UTC",
      "updated_date": "2025-04-30 11:28:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:19:25.028196"
    },
    {
      "arxiv_id": "2504.21491v1",
      "title": "ClassWise-CRF: Category-Specific Fusion for Enhanced Semantic Segmentation of Remote Sensing Imagery",
      "title_zh": "翻译失败",
      "authors": [
        "Qinfeng Zhu",
        "Yunxi Jiang",
        "Lei Fan"
      ],
      "abstract": "We propose a result-level category-specific fusion architecture called\nClassWise-CRF. This architecture employs a two-stage process: first, it selects\nexpert networks that perform well in specific categories from a pool of\ncandidate networks using a greedy algorithm; second, it integrates the\nsegmentation predictions of these selected networks by adaptively weighting\ntheir contributions based on their segmentation performance in each category.\nInspired by Conditional Random Field (CRF), the ClassWise-CRF architecture\ntreats the segmentation predictions from multiple networks as confidence vector\nfields. It leverages segmentation metrics (such as Intersection over Union)\nfrom the validation set as priors and employs an exponential weighting strategy\nto fuse the category-specific confidence scores predicted by each network. This\nfusion method dynamically adjusts the weights of each network for different\ncategories, achieving category-specific optimization. Building on this, the\narchitecture further optimizes the fused results using unary and pairwise\npotentials in CRF to ensure spatial consistency and boundary accuracy. To\nvalidate the effectiveness of ClassWise-CRF, we conducted experiments on two\nremote sensing datasets, LoveDA and Vaihingen, using eight classic and advanced\nsemantic segmentation networks. The results show that the ClassWise-CRF\narchitecture significantly improves segmentation performance: on the LoveDA\ndataset, the mean Intersection over Union (mIoU) metric increased by 1.00% on\nthe validation set and by 0.68% on the test set; on the Vaihingen dataset, the\nmIoU improved by 0.87% on the validation set and by 0.91% on the test set.\nThese results fully demonstrate the effectiveness and generality of the\nClassWise-CRF architecture in semantic segmentation of remote sensing images.\nThe full code is available at https://github.com/zhuqinfeng1999/ClassWise-CRF.",
      "tldr_zh": "我们提出了 ClassWise-CRF，一种结果级别的类别特定融合架构，用于提升遥感图像语义分割的性能。该架构采用两阶段过程：首先使用贪婪算法从候选网络中选择在特定类别表现优秀的专家网络；其次，通过指数加权策略基于每个类别的分割指标（如 IoU）融合预测，并结合 Conditional Random Field (CRF) 的一元和二元势优化空间一致性和边界准确性。在 LoveDA 和 Vaihingen 数据集上的实验中，ClassWise-CRF 显著提高了 mean Intersection over Union (mIoU)，例如 LoveDA 验证集提升 1.00%、测试集提升 0.68%，证明了其有效性和泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21491v1",
      "published_date": "2025-04-30 10:19:21 UTC",
      "updated_date": "2025-04-30 10:19:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:19:38.214067"
    },
    {
      "arxiv_id": "2504.21489v2",
      "title": "TRIED: Truly Innovative and Effective AI Detection Benchmark, developed by WITNESS",
      "title_zh": "TRIED：真正创新且有效的 AI 检测基准，由 WITNESS 开发",
      "authors": [
        "Shirin Anlen",
        "Zuzanna Wojciak"
      ],
      "abstract": "The proliferation of generative AI and deceptive synthetic media threatens\nthe global information ecosystem, especially across the Global Majority. This\nreport from WITNESS highlights the limitations of current AI detection tools,\nwhich often underperform in real-world scenarios due to challenges related to\nexplainability, fairness, accessibility, and contextual relevance. In response,\nWITNESS introduces the Truly Innovative and Effective AI Detection (TRIED)\nBenchmark, a new framework for evaluating detection tools based on their\nreal-world impact and capacity for innovation. Drawing on frontline\nexperiences, deceptive AI cases, and global consultations, the report outlines\nhow detection tools must evolve to become truly innovative and relevant by\nmeeting diverse linguistic, cultural, and technological contexts. It offers\npractical guidance for developers, policy actors, and standards bodies to\ndesign accountable, transparent, and user-centered detection solutions, and\nincorporate sociotechnical considerations into future AI standards, procedures\nand evaluation frameworks. By adopting the TRIED Benchmark, stakeholders can\ndrive innovation, safeguard public trust, strengthen AI literacy, and\ncontribute to a more resilient global information credibility.",
      "tldr_zh": "本报告由 WITNESS 发布，强调生成式 AI 和合成媒体的扩散对全球信息生态，尤其是全球多数国家的威胁，并指出现有 AI 检测工具在可解释性、公平性、可访问性和上下文相关性方面表现不佳。WITNESS 引入了 Truly Innovative and Effective AI Detection (TRIED) Benchmark，这是一个创新评估框架，旨在评估检测工具的真实影响和创新潜力，通过整合前线经验、欺骗性 AI 案例及全球咨询来适应多样化的语言、文化和技术环境。该基准提供实用指导，帮助开发者、政策制定者和标准机构设计负责任、透明的用户中心解决方案，并将社会技术考虑纳入 AI 标准，从而推动创新、维护公众信任、加强 AI 素养，并提升全球信息可信度。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "33 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.21489v2",
      "published_date": "2025-04-30 10:18:19 UTC",
      "updated_date": "2025-05-01 13:38:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:19:49.646986"
    },
    {
      "arxiv_id": "2504.21480v1",
      "title": "A Comprehensive Study of Exploitable Patterns in Smart Contracts: From Vulnerability to Defense",
      "title_zh": "智能合约中可利用模式的全面研究：从漏洞到防御",
      "authors": [
        "Yuchen Ding",
        "Hongli Peng",
        "Xiaoqi Li"
      ],
      "abstract": "With the rapid advancement of blockchain technology, smart contracts have\nenabled the implementation of increasingly complex functionalities. However,\nensuring the security of smart contracts remains a persistent challenge across\nthe stages of development, compilation, and execution. Vulnerabilities within\nsmart contracts not only undermine the security of individual applications but\nalso pose significant risks to the broader blockchain ecosystem, as\ndemonstrated by the growing frequency of attacks since 2016, resulting in\nsubstantial financial losses. This paper provides a comprehensive analysis of\nkey security risks in Ethereum smart contracts, specifically those written in\nSolidity and executed on the Ethereum Virtual Machine (EVM). We focus on two\nprevalent and critical vulnerability types (reentrancy and integer overflow) by\nexamining their underlying mechanisms, replicating attack scenarios, and\nassessing effective countermeasures.",
      "tldr_zh": "这篇论文对区块链智能合约的安全风险进行全面研究，强调了从开发到执行阶段的潜在漏洞如何威胁单个应用和整个生态系统，特别是自2016年以来导致的频繁攻击和财务损失。研究重点分析了Ethereum智能合约（使用Solidity编写并在EVM上执行）中的两种关键漏洞：reentrancy和integer overflow，通过探讨其底层机制、模拟攻击场景，并评估有效防御策略。总体而言，该工作为提升智能合约的安全性提供了宝贵的见解和防范措施。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21480v1",
      "published_date": "2025-04-30 10:00:36 UTC",
      "updated_date": "2025-04-30 10:00:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:20:00.647240"
    },
    {
      "arxiv_id": "2504.21476v2",
      "title": "GarmentDiffusion: 3D Garment Sewing Pattern Generation with Multimodal Diffusion Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyu Li",
        "Qi Yao",
        "Yuanda Wang"
      ],
      "abstract": "Garment sewing patterns are fundamental design elements that bridge the gap\nbetween design concepts and practical manufacturing. The generative modeling of\nsewing patterns is crucial for creating diversified garments. However, existing\napproaches are limited either by reliance on a single input modality or by\nsuboptimal generation efficiency. In this work, we present GarmentDiffusion, a\nnew generative model capable of producing centimeter-precise, vectorized 3D\nsewing patterns from multimodal inputs (text, image, and incomplete sewing\npattern). Our method efficiently encodes 3D sewing pattern parameters into\ncompact edge token representations, achieving a sequence length that is 10\ntimes shorter than that of the autoregressive SewingGPT in DressCode. By\nemploying a diffusion transformer, we simultaneously denoise all edge tokens\nalong the temporal axis, while maintaining a constant number of denoising steps\nregardless of dataset-specific edge and panel statistics. With all combination\nof designs of our model, the sewing pattern generation speed is accelerated by\n100 times compared to SewingGPT. We achieve new state-of-the-art results on\nDressCodeData, as well as on the largest sewing pattern dataset, namely\nGarmentCodeData. The project website is available at\nhttps://shenfu-research.github.io/Garment-Diffusion/.",
      "tldr_zh": "本文提出 GarmentDiffusion 模型，用于从多模态输入（如文本、图像和不完整的缝纫图案）生成厘米级精确的向量化 3D 缝纫图案，解决了现有方法的单一模式依赖和生成效率问题。该模型通过高效编码 3D 缝纫图案参数为紧凑的边沿标记表示，并采用 Diffusion Transformers 同时去噪所有标记，保持恒定去噪步骤，从而将生成速度比 SewingGPT 加快 100 倍。在 DressCodeData 和 GarmentCodeData 数据集上，GarmentDiffusion 达到了新的最先进结果。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "The 34th International Joint Conference on Artificial Intelligence\n  (IJCAI 2025)",
      "pdf_url": "http://arxiv.org/pdf/2504.21476v2",
      "published_date": "2025-04-30 09:56:59 UTC",
      "updated_date": "2025-05-10 13:14:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:20:13.679318"
    },
    {
      "arxiv_id": "2504.21475v1",
      "title": "Advancing Arabic Reverse Dictionary Systems: A Transformer-Based Approach with Dataset Construction Guidelines",
      "title_zh": "翻译失败",
      "authors": [
        "Serry Sibaee",
        "Samar Ahmed",
        "Abdullah Al Harbi",
        "Omer Nacar",
        "Adel Ammar",
        "Yasser Habashi",
        "Wadii Boulila"
      ],
      "abstract": "This study addresses the critical gap in Arabic natural language processing\nby developing an effective Arabic Reverse Dictionary (RD) system that enables\nusers to find words based on their descriptions or meanings. We present a novel\ntransformer-based approach with a semi-encoder neural network architecture\nfeaturing geometrically decreasing layers that achieves state-of-the-art\nresults for Arabic RD tasks. Our methodology incorporates a comprehensive\ndataset construction process and establishes formal quality standards for\nArabic lexicographic definitions. Experiments with various pre-trained models\ndemonstrate that Arabic-specific models significantly outperform general\nmultilingual embeddings, with ARBERTv2 achieving the best ranking score\n(0.0644). Additionally, we provide a formal abstraction of the reverse\ndictionary task that enhances theoretical understanding and develop a modular,\nextensible Python library (RDTL) with configurable training pipelines. Our\nanalysis of dataset quality reveals important insights for improving Arabic\ndefinition construction, leading to eight specific standards for building\nhigh-quality reverse dictionary resources. This work contributes significantly\nto Arabic computational linguistics and provides valuable tools for language\nlearning, academic writing, and professional communication in Arabic.",
      "tldr_zh": "本研究针对阿拉伯语自然语言处理中的空白，开发了一个基于 Transformer 的反向字典 (Reverse Dictionary) 系统，使用半编码器神经网络架构（层数几何递减），实现了阿拉伯语 RD 任务的 state-of-the-art 结果，并提供了全面的数据集构建过程和质量标准。实验显示，阿拉伯语特定模型如 ARBERTv2 显著优于多语言嵌入，其排名分数达到 0.0644。研究还建立了反向字典任务的正式抽象、一个模块化 Python 库 (RDTL) 用于可配置训练，以及八个具体标准来提升阿拉伯语定义质量，为阿拉伯语计算语言学贡献工具和见解，支持语言学习、学术写作和专业交流。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21475v1",
      "published_date": "2025-04-30 09:56:36 UTC",
      "updated_date": "2025-04-30 09:56:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:20:25.551113"
    },
    {
      "arxiv_id": "2504.21474v1",
      "title": "Homa at SemEval-2025 Task 5: Aligning Librarian Records with OntoAligner for Subject Tagging",
      "title_zh": "翻译失败",
      "authors": [
        "Hadi Bayrami Asl Tekanlou",
        "Jafar Razmara",
        "Mahsa Sanaei",
        "Mostafa Rahgouy",
        "Hamed Babaei Giglou"
      ],
      "abstract": "This paper presents our system, Homa, for SemEval-2025 Task 5: Subject\nTagging, which focuses on automatically assigning subject labels to technical\nrecords from TIBKAT using the Gemeinsame Normdatei (GND) taxonomy. We leverage\nOntoAligner, a modular ontology alignment toolkit, to address this task by\nintegrating retrieval-augmented generation (RAG) techniques. Our approach\nformulates the subject tagging problem as an alignment task, where records are\nmatched to GND categories based on semantic similarity. We evaluate\nOntoAligner's adaptability for subject indexing and analyze its effectiveness\nin handling multilingual records. Experimental results demonstrate the\nstrengths and limitations of this method, highlighting the potential of\nalignment techniques for improving subject tagging in digital libraries.",
      "tldr_zh": "这篇论文介绍了Homa系统，针对SemEval-2025 Task 5，使用OntoAligner工具为TIBKAT的技术记录自动分配主题标签，基于Gemeinsame Normdatei (GND) taxonomy。方法将主题标记问题转化为本体对齐任务，结合检索增强生成(RAG)技术，通过语义相似性匹配记录到相关类别，并评估其处理多语言记录的适应性。实验结果展示了该方法的优势和局限性，突出了本体对齐技术在提升数字图书馆主题标记方面的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "7 pages, 4 figures, accepted to the LLMs4Subjects shared task at\n  SemEval2025",
      "pdf_url": "http://arxiv.org/pdf/2504.21474v1",
      "published_date": "2025-04-30 09:52:51 UTC",
      "updated_date": "2025-04-30 09:52:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:20:36.772131"
    },
    {
      "arxiv_id": "2504.21457v1",
      "title": "xEEGNet: Towards Explainable AI in EEG Dementia Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Andrea Zanola",
        "Louis Fabrice Tshimanga",
        "Federico Del Pup",
        "Marco Baiesi",
        "Manfredo Atzori"
      ],
      "abstract": "This work presents xEEGNet, a novel, compact, and explainable neural network\nfor EEG data analysis. It is fully interpretable and reduces overfitting\nthrough major parameter reduction. As an applicative use case, we focused on\nclassifying common dementia conditions, Alzheimer's and frontotemporal\ndementia, versus controls. xEEGNet is broadly applicable to other neurological\nconditions involving spectral alterations. We initially used ShallowNet, a\nsimple and popular model from the EEGNet-family. Its structure was analyzed and\ngradually modified to move from a \"black box\" to a more transparent model,\nwithout compromising performance. The learned kernels and weights were examined\nfrom a clinical standpoint to assess medical relevance. Model variants,\nincluding ShallowNet and the final xEEGNet, were evaluated using robust\nNested-Leave-N-Subjects-Out cross-validation for unbiased performance\nestimates. Variability across data splits was explained using embedded EEG\nrepresentations, grouped by class and set, with pairwise separability to\nquantify group distinction. Overfitting was assessed through\ntraining-validation loss correlation and training speed. xEEGNet uses only 168\nparameters, 200 times fewer than ShallowNet, yet retains interpretability,\nresists overfitting, achieves comparable median performance (-1.5%), and\nreduces variability across splits. This variability is explained by embedded\nEEG representations: higher accuracy correlates with greater separation between\ntest set controls and Alzheimer's cases, without significant influence from\ntraining data. xEEGNet's ability to filter specific EEG bands, learn\nband-specific topographies, and use relevant spectral features demonstrates its\ninterpretability. While large deep learning models are often prioritized for\nperformance, this study shows smaller architectures like xEEGNet can be equally\neffective in EEG pathology classification.",
      "tldr_zh": "本研究提出 xEEGNet，一种紧凑且完全可解释的神经网络，用于 EEG 数据分析，旨在减少过拟合并提升模型透明度。基于 ShallowNet 的结构，研究团队逐步修改模型参数和架构，并通过嵌套的 Leave-N-Subjects-Out 交叉验证评估其在痴呆症（如 Alzheimer's 和 frontotemporal dementia）分类中的性能。结果显示，xEEGNet 仅使用 168 个参数，比 ShallowNet 少 200 倍，同时保持相近的中位数性能（下降 1.5%）并显著降低变异性，其可解释性体现在过滤特定 EEG 频带和学习相关光谱特征上。该工作证明了小型架构在 EEG 病理分类中的有效性，强调了可解释 AI 在神经学应用中的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21457v1",
      "published_date": "2025-04-30 09:24:50 UTC",
      "updated_date": "2025-04-30 09:24:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:20:50.308234"
    },
    {
      "arxiv_id": "2504.21454v1",
      "title": "SimPRIVE: a Simulation framework for Physical Robot Interaction with Virtual Environments",
      "title_zh": "SimPRIVE：物理机器人与虚拟环境交互的模拟框架",
      "authors": [
        "Federico Nesti",
        "Gianluca D'Amico",
        "Mauro Marinoni",
        "Giorgio Buttazzo"
      ],
      "abstract": "The use of machine learning in cyber-physical systems has attracted the\ninterest of both industry and academia. However, no general solution has yet\nbeen found against the unpredictable behavior of neural networks and\nreinforcement learning agents. Nevertheless, the improvements of\nphoto-realistic simulators have paved the way towards extensive testing of\ncomplex algorithms in different virtual scenarios, which would be expensive and\ndangerous to implement in the real world.\n  This paper presents SimPRIVE, a simulation framework for physical robot\ninteraction with virtual environments, which operates as a vehicle-in-the-loop\nplatform, rendering a virtual world while operating the vehicle in the real\nworld.\n  Using SimPRIVE, any physical mobile robot running on ROS 2 can easily be\nconfigured to move its digital twin in a virtual world built with the Unreal\nEngine 5 graphic engine, which can be populated with objects, people, or other\nvehicles with programmable behavior.\n  SimPRIVE has been designed to accommodate custom or pre-built virtual worlds\nwhile being light-weight to contain execution times and allow fast rendering.\nIts main advantage lies in the possibility of testing complex algorithms on the\nfull software and hardware stack while minimizing the risks and costs of a test\ncampaign. The framework has been validated by testing a reinforcement learning\nagent trained for obstacle avoidance on an AgileX Scout Mini rover that\nnavigates a virtual office environment where everyday objects and people are\nplaced as obstacles. The physical rover moves with no collision in an indoor\nlimited space, thanks to a LiDAR-based heuristic.",
      "tldr_zh": "该论文提出SimPRIVE框架，这是一个用于物理机器人与虚拟环境交互的模拟平台，旨在通过vehicle-in-the-loop机制在真实世界操作机器人，同时渲染基于Unreal Engine 5的虚拟世界。框架支持ROS 2上的移动机器人，实现轻量级自定义虚拟场景测试，减少算法开发的风险和成本。实验验证显示，SimPRIVE成功训练并测试了一个reinforcement learning代理，用于AgileX Scout Mini漫游者在虚拟办公室环境中避开障碍，同时借助LiDAR-based启发式方法确保物理机器人安全移动。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Submitted to IEEE ITSC 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.21454v1",
      "published_date": "2025-04-30 09:22:55 UTC",
      "updated_date": "2025-04-30 09:22:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:21:00.406303"
    },
    {
      "arxiv_id": "2505.01453v1",
      "title": "Safe and Efficient CAV Lane Changing using Decentralised Safety Shields",
      "title_zh": "安全高效的 CAV 换道使用去中心化安全屏蔽",
      "authors": [
        "Bharathkumar Hegde",
        "Melanie Bouroche"
      ],
      "abstract": "Lane changing is a complex decision-making problem for Connected and\nAutonomous Vehicles (CAVs) as it requires balancing traffic efficiency with\nsafety. Although traffic efficiency can be improved by using vehicular\ncommunication for training lane change controllers using Multi-Agent\nReinforcement Learning (MARL), ensuring safety is difficult. To address this\nissue, we propose a decentralised Hybrid Safety Shield (HSS) that combines\noptimisation and a rule-based approach to guarantee safety. Our method applies\ncontrol barrier functions to constrain longitudinal and lateral control inputs\nof a CAV to ensure safe manoeuvres. Additionally, we present an architecture to\nintegrate HSS with MARL, called MARL-HSS, to improve traffic efficiency while\nensuring safety. We evaluate MARL-HSS using a gym-like environment that\nsimulates an on-ramp merging scenario with two levels of traffic densities,\nsuch as light and moderate densities. The results show that HSS provides a\nsafety guarantee by strictly enforcing a dynamic safety constraint defined on a\ntime headway, even in moderate traffic density that offers challenging lane\nchange scenarios. Moreover, the proposed method learns stable policies compared\nto the baseline, a state-of-the-art MARL lane change controller without a\nsafety shield. Further policy evaluation shows that our method achieves a\nbalance between safety and traffic efficiency with zero crashes and comparable\naverage speeds in light and moderate traffic densities.",
      "tldr_zh": "该论文探讨了自动驾驶车辆（CAV）换道决策的问题，强调需要在交通效率和安全之间实现平衡。作者提出了一种去中心化的混合安全屏蔽（Hybrid Safety Shield，HSS），结合优化方法和基于规则的控制屏障函数（control barrier functions）来约束车辆的纵向和横向控制输入，确保安全操作。随后，他们开发了MARL-HSS架构，将HSS与多智能体强化学习（MARL）集成，以提升交通效率。实验结果显示，在模拟的轻度和中度交通密度场景中，MARL-HSS实现了零碰撞、策略稳定性提升，并保持了与基线相当的平均速度，从而在安全和效率间取得了平衡。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.RO",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.MA",
      "comment": "Accepted in IEEE IV 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.01453v1",
      "published_date": "2025-04-30 09:11:09 UTC",
      "updated_date": "2025-04-30 09:11:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:21:12.678820"
    },
    {
      "arxiv_id": "2504.21447v1",
      "title": "Rethinking Visual Layer Selection in Multimodal LLMs",
      "title_zh": "重新思考多模态大语言模型中的视觉层选择",
      "authors": [
        "Haoran Chen",
        "Junyan Lin",
        "Xinhao Chen",
        "Yue Fan",
        "Xin Jin",
        "Hui Su",
        "Jianfeng Dong",
        "Jinlan Fu",
        "Xiaoyu Shen"
      ],
      "abstract": "Multimodal large language models (MLLMs) have achieved impressive performance\nacross a wide range of tasks, typically using CLIP-ViT as their visual encoder\ndue to its strong text-image alignment capabilities. While prior studies\nsuggest that different CLIP-ViT layers capture different types of information,\nwith shallower layers focusing on fine visual details and deeper layers\naligning more closely with textual semantics, most MLLMs still select visual\nfeatures based on empirical heuristics rather than systematic analysis. In this\nwork, we propose a Layer-wise Representation Similarity approach to group\nCLIP-ViT layers with similar behaviors into {shallow, middle, and deep}\ncategories and assess their impact on MLLM performance. Building on this\nfoundation, we revisit the visual layer selection problem in MLLMs at scale,\ntraining LLaVA-style models ranging from 1.4B to 7B parameters. Through\nextensive experiments across 10 datasets and 4 tasks, we find that: (1) deep\nlayers are essential for OCR tasks; (2) shallow and middle layers substantially\noutperform deep layers on reasoning tasks involving counting, positioning, and\nobject localization; (3) a lightweight fusion of features across shallow,\nmiddle, and deep layers consistently outperforms specialized fusion baselines\nand single-layer selections, achieving gains on 9 out of 10 datasets. Our work\noffers the first principled study of visual layer selection in MLLMs, laying\nthe groundwork for deeper investigations into visual representation learning\nfor MLLMs.",
      "tldr_zh": "本研究重新审视 Multimodal LLMs 中的视觉层选择问题，提出 Layer-wise Representation Similarity 方法，将 CLIP-ViT 层分组为浅层、中层和深层，并评估其对模型性能的影响。通过训练 1.4B 到 7B 参数的 LLaVA-style 模型，并在 10 个数据集和 4 个任务上进行实验，发现深层在 OCR 任务中至关重要，而浅层和中层在涉及计数、定位和对象定位的推理任务中表现更优。最终，轻量级融合浅层、中层和深层特征的策略 consistently 优于单一层选择，在 9 个数据集上取得提升，为 Multimodal LLMs 的视觉表示学习提供系统性基础。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 4 figures, submitted to ICCV 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.21447v1",
      "published_date": "2025-04-30 09:07:10 UTC",
      "updated_date": "2025-04-30 09:07:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:21:26.667433"
    },
    {
      "arxiv_id": "2504.21435v3",
      "title": "SeriesBench: A Benchmark for Narrative-Driven Drama Series Understanding",
      "title_zh": "SeriesBench: 叙事驱动戏剧系列理解基准",
      "authors": [
        "Chenkai Zhang",
        "Yiming Lei",
        "Zeming Liu",
        "Haitao Leng",
        "Shaoguo Liu",
        "Tingting Gao",
        "Qingjie Liu",
        "Yunhong Wang"
      ],
      "abstract": "With the rapid development of Multi-modal Large Language Models (MLLMs), an\nincreasing number of benchmarks have been established to evaluate the video\nunderstanding capabilities of these models. However, these benchmarks focus on\nstandalone videos and mainly assess \"visual elements\" like human actions and\nobject states. In reality, contemporary videos often encompass complex and\ncontinuous narratives, typically presented as a series. To address this\nchallenge, we propose SeriesBench, a benchmark consisting of 105 carefully\ncurated narrative-driven series, covering 28 specialized tasks that require\ndeep narrative understanding. Specifically, we first select a diverse set of\ndrama series spanning various genres. Then, we introduce a novel long-span\nnarrative annotation method, combined with a full-information transformation\napproach to convert manual annotations into diverse task formats. To further\nenhance model capacity for detailed analysis of plot structures and character\nrelationships within series, we propose a novel narrative reasoning framework,\nPC-DCoT. Extensive results on SeriesBench indicate that existing MLLMs still\nface significant challenges in understanding narrative-driven series, while\nPC-DCoT enables these MLLMs to achieve performance improvements. Overall, our\nSeriesBench and PC-DCoT highlight the critical necessity of advancing model\ncapabilities to understand narrative-driven series, guiding the future\ndevelopment of MLLMs. SeriesBench is publicly available at\nhttps://github.com/zackhxn/SeriesBench-CVPR2025.",
      "tldr_zh": "该研究提出 SeriesBench，一个由 105 个叙事驱动戏剧系列组成的基准，旨在评估多模态大语言模型（MLLMs）在处理复杂连续叙事方面的能力，覆盖 28 个需要深度叙事理解的任务。SeriesBench 通过选择多样化剧集、引入长跨度叙事注释方法和全信息转换技术，将手动注释转化为多种任务格式，以弥补现有基准对独立视频和视觉元素的局限。研究同时开发了新的叙事推理框架 PC-DCoT，帮助 MLLMs 更好地分析情节结构和人物关系。实验结果显示，现有的 MLLMs 在 SeriesBench 上表现欠佳，但 PC-DCoT 显著提升了模型性能，强调了未来 MLLMs 发展中理解叙事系列的必要性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "29 pages, 15 figures, CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.21435v3",
      "published_date": "2025-04-30 08:48:21 UTC",
      "updated_date": "2025-05-13 08:06:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:21:37.745365"
    },
    {
      "arxiv_id": "2504.21433v1",
      "title": "NGENT: Next-Generation AI Agents Must Integrate Multi-Domain Abilities to Achieve Artificial General Intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Zhicong Li",
        "Hangyu Mao",
        "Jiangjin Yin",
        "Mingzhe Xing",
        "Zhiwei Xu",
        "Yuanxing Zhang",
        "Yang Xiao"
      ],
      "abstract": "This paper argues that the next generation of AI agent (NGENT) should\nintegrate across-domain abilities to advance toward Artificial General\nIntelligence (AGI). Although current AI agents are effective in specialized\ntasks such as robotics, role-playing, and tool-using, they remain confined to\nnarrow domains. We propose that future AI agents should synthesize the\nstrengths of these specialized systems into a unified framework capable of\noperating across text, vision, robotics, reinforcement learning, emotional\nintelligence, and beyond. This integration is not only feasible but also\nessential for achieving the versatility and adaptability that characterize\nhuman intelligence. The convergence of technologies across AI domains, coupled\nwith increasing user demand for cross-domain capabilities, suggests that such\nintegration is within reach. Ultimately, the development of these versatile\nagents is a critical step toward realizing AGI. This paper explores the\nrationale for this shift, potential pathways for achieving it.",
      "tldr_zh": "本论文提出，下一代 AI 代理（NGENT）必须整合多域能力，包括文本、视觉、机器人、强化学习和情感智能等领域，以推进 Artificial General Intelligence (AGI) 的发展。当前 AI 代理虽在特定任务如机器人操作、角色扮演和工具使用上表现出色，但仍局限于狭窄领域，无法实现人类的通用性和适应性。该整合框架将现有专业系统的优势合成一个统一系统，不仅可行，还能满足技术融合和用户需求的推动，最终为实现 AGI 提供关键路径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21433v1",
      "published_date": "2025-04-30 08:46:14 UTC",
      "updated_date": "2025-04-30 08:46:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:21:48.642437"
    },
    {
      "arxiv_id": "2504.21428v1",
      "title": "UAV Marketplace Simulation Tool for BVLOS Operations",
      "title_zh": "翻译失败",
      "authors": [
        "Kıvanç Şerefoğlu",
        "Önder Gürcan",
        "Reyhan Aydoğan"
      ],
      "abstract": "We present a simulation tool for evaluating team formation in autonomous\nmulti-UAV (Unmanned Aerial Vehicle) missions that operate Beyond Visual Line of\nSight (BVLOS). The tool models UAV collaboration and mission execution in\ndynamic and adversarial conditions, where Byzantine UAVs attempt to disrupt\noperations. Our tool allows researchers to integrate and compare various team\nformation strategies in a controlled environment with configurable mission\nparameters and adversarial behaviors. The log of each simulation run is stored\nin a structured way along with performance metrics so that statistical analysis\ncould be done straightforwardly. The tool is versatile for testing and\nimproving UAV coordination strategies in real-world applications.",
      "tldr_zh": "本研究提出一个名为UAV Marketplace的模拟工具，用于评估在Beyond Visual Line of Sight (BVLOS)操作中的自主多-UAV任务团队形成。该工具模拟UAV协作和任务执行，处理动态和对抗环境，包括Byzantine UAVs的干扰，并允许研究人员整合并比较各种团队形成策略。用户可以通过可配置的使命参数和对抗行为进行测试，每个模拟运行的日志以结构化方式存储，并附带性能指标，便于统计分析。该工具适用于改进UAV协调策略在真实世界应用中的效果。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.RO",
      "comment": "3 pages, 2 figures, the 24th International Conference on Autonomous\n  Agents and Multiagent Systems (AAMAS 2025)",
      "pdf_url": "http://arxiv.org/pdf/2504.21428v1",
      "published_date": "2025-04-30 08:36:22 UTC",
      "updated_date": "2025-04-30 08:36:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:22:00.299993"
    },
    {
      "arxiv_id": "2504.21427v1",
      "title": "MPEC: Manifold-Preserved EEG Classification via an Ensemble of Clustering-Based Classifiers",
      "title_zh": "翻译失败",
      "authors": [
        "Shermin Shahbazi",
        "Mohammad-Reza Nasiri",
        "Majid Ramezani"
      ],
      "abstract": "Accurate classification of EEG signals is crucial for brain-computer\ninterfaces (BCIs) and neuroprosthetic applications, yet many existing methods\nfail to account for the non-Euclidean, manifold structure of EEG data,\nresulting in suboptimal performance. Preserving this manifold information is\nessential to capture the true geometry of EEG signals, but traditional\nclassification techniques largely overlook this need. To this end, we propose\nMPEC (Manifold-Preserved EEG Classification via an Ensemble of Clustering-Based\nClassifiers), that introduces two key innovations: (1) a feature engineering\nphase that combines covariance matrices and Radial Basis Function (RBF) kernels\nto capture both linear and non-linear relationships among EEG channels, and (2)\na clustering phase that employs a modified K-means algorithm tailored for the\nRiemannian manifold space, ensuring local geometric sensitivity. Ensembling\nmultiple clustering-based classifiers, MPEC achieves superior results,\nvalidated by significant improvements on the BCI Competition IV dataset 2a.",
      "tldr_zh": "本文提出 MPEC 方法，用于改进 EEG 信号分类问题，该方法强调保留 EEG 数据的流形结构，以解决传统分类技术忽略非欧空间几何的不足。MPEC 包括两个关键创新：（1）特征工程阶段结合 covariance matrices 和 RBF kernels，捕获 EEG 通道的线性与非线性关系；（2）聚类阶段采用修改后的 K-means 算法，适应 Riemannian manifold 空间，确保局部几何敏感性，并通过集成多个基于聚类的分类器提升整体性能。在 BCI Competition IV dataset 2a 上，MPEC 实现了显著的分类准确率改进。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages ,3 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.21427v1",
      "published_date": "2025-04-30 08:34:15 UTC",
      "updated_date": "2025-04-30 08:34:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:22:13.125851"
    },
    {
      "arxiv_id": "2504.21415v2",
      "title": "Optimizing Mouse Dynamics for User Authentication by Machine Learning: Addressing Data Sufficiency, Accuracy-Practicality Trade-off, and Model Performance Challenges",
      "title_zh": "翻译失败",
      "authors": [
        "Yi Wang",
        "Chengyv Wu",
        "Yang Liao",
        "Maowei You"
      ],
      "abstract": "User authentication is essential to ensure secure access to computer systems,\nyet traditional methods face limitations in usability, cost, and security.\nMouse dynamics authentication, based on the analysis of users' natural\ninteraction behaviors with mouse devices, offers a cost-effective,\nnon-intrusive, and adaptable solution. However, challenges remain in\ndetermining the optimal data volume, balancing accuracy and practicality, and\neffectively capturing temporal behavioral patterns. In this study, we propose a\nstatistical method using Gaussian kernel density estimate (KDE) and\nKullback-Leibler (KL) divergence to estimate the sufficient data volume for\ntraining authentication models. We introduce the Mouse Authentication Unit\n(MAU), leveraging Approximate Entropy (ApEn) to optimize segment length for\nefficient and accurate behavioral representation. Furthermore, we design the\nLocal-Time Mouse Authentication (LT-AMouse) framework, integrating 1D-ResNet\nfor local feature extraction and GRU for modeling long-term temporal\ndependencies. Taking the Balabit and DFL datasets as examples, we significantly\nreduced the data scale, particularly by a factor of 10 for the DFL dataset,\ngreatly alleviating the training burden. Additionally, we determined the\noptimal input recognition unit length for the user authentication system on\ndifferent datasets based on the slope of Approximate Entropy. Training with\nimbalanced samples, our model achieved a successful defense AUC 98.52% for\nblind attack on the DFL dataset and 94.65% on the Balabit dataset, surpassing\nthe current sota performance.",
      "tldr_zh": "本研究针对用户认证的挑战，提出使用机器学习优化鼠标动态行为的方法，解决数据充足性、准确性与实用性权衡以及模型性能问题。论文引入基于 Gaussian kernel density estimate (KDE) 和 Kullback-Leibler (KL) divergence 的统计方法来估计训练所需数据量，开发了 Mouse Authentication Unit (MAU) 以 Approximate Entropy (ApEn) 优化行为段长度，并设计了 Local-Time Mouse Authentication (LT-AMouse) 框架，结合 1D-ResNet 提取局部特征和 GRU 建模长期时间依赖。实验在 Balabit 和 DFL 数据集上显著减少数据规模（如 DFL 数据集减少10倍），并在不平衡样本训练下实现98.52% 和94.65% 的 AUC 性能，超越现有最先进水平。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "13pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.21415v2",
      "published_date": "2025-04-30 08:16:52 UTC",
      "updated_date": "2025-05-11 05:42:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:22:27.217945"
    },
    {
      "arxiv_id": "2504.21411v1",
      "title": "Galvatron: An Automatic Distributed System for Efficient Foundation Model Training",
      "title_zh": "Galvatron：用于高效基础模型训练的自动分布式系统",
      "authors": [
        "Xinyi Liu",
        "Yujie Wang",
        "Shenhan Zhu",
        "Fangcheng Fu",
        "Qingshuo Liu",
        "Guangming Lin",
        "Bin Cui"
      ],
      "abstract": "Galvatron is a distributed system for efficiently training large-scale\nFoundation Models. It overcomes the complexities of selecting optimal\nparallelism strategies by automatically identifying the most efficient hybrid\nstrategy, incorporating data, tensor, pipeline, sharded data, and sequence\nparallelism, along with recomputation. The system's architecture includes a\nprofiler for hardware and model analysis, a search engine for strategy\noptimization using decision trees and dynamic programming, and a runtime for\nexecuting these strategies efficiently. Benchmarking on various clusters\ndemonstrates Galvatron's superior throughput compared to existing frameworks.\nThis open-source system offers user-friendly interfaces and comprehensive\ndocumentation, making complex distributed training accessible and efficient.\nThe source code of Galvatron is available at\nhttps://github.com/PKU-DAIR/Hetu-Galvatron.",
      "tldr_zh": "Galvatron 是一个自动分布式系统，旨在高效训练大型 Foundation Models，通过自动识别最优混合并行策略，包括 data parallelism、tensor parallelism、pipeline parallelism、sharded data parallelism 和 sequence parallelism，以及 recomputation 来简化复杂训练过程。系统架构包括 profiler 用于硬件和模型分析、search engine 利用决策树和动态规划优化策略，以及 runtime 确保高效执行。基准测试在各种集群上显示，Galvatron 的吞吐量优于现有框架。该系统开源，提供用户友好的接口和全面文档，源码可在 https://github.com/PKU-DAIR/Hetu-Galvatron 获取。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21411v1",
      "published_date": "2025-04-30 08:11:45 UTC",
      "updated_date": "2025-04-30 08:11:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:22:37.214937"
    },
    {
      "arxiv_id": "2504.21383v1",
      "title": "FAST-Q: Fast-track Exploration with Adversarially Balanced State Representations for Counterfactual Action Estimation in Offline Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Pulkit Agrawal",
        "Rukma Talwadker",
        "Aditya Pareek",
        "Tridib Mukherjee"
      ],
      "abstract": "Recent advancements in state-of-the-art (SOTA) offline reinforcement learning\n(RL) have primarily focused on addressing function approximation errors, which\ncontribute to the overestimation of Q-values for out-of-distribution actions, a\nchallenge that static datasets exacerbate. However, high stakes applications\nsuch as recommendation systems in online gaming, introduce further complexities\ndue to player's psychology (intent) driven by gameplay experiences and the\ninherent volatility on the platform. These factors create highly sparse,\npartially overlapping state spaces across policies, further influenced by the\nexperiment path selection logic which biases state spaces towards specific\npolicies. Current SOTA methods constrain learning from such offline data by\nclipping known counterfactual actions as out-of-distribution due to poor\ngeneralization across unobserved states. Further aggravating conservative\nQ-learning and necessitating more online exploration. FAST-Q introduces a novel\napproach that (1) leverages Gradient Reversal Learning to construct balanced\nstate representations, regularizing the policy-specific bias between the\nplayer's state and action thereby enabling counterfactual estimation; (2)\nsupports offline counterfactual exploration in parallel with static data\nexploitation; and (3) proposes a Q-value decomposition strategy for\nmulti-objective optimization, facilitating explainable recommendations over\nshort and long-term objectives. These innovations demonstrate superiority of\nFAST-Q over prior SOTA approaches and demonstrates at least 0.15 percent\nincrease in player returns, 2 percent improvement in lifetime value (LTV), 0.4\npercent enhancement in the recommendation driven engagement, 2 percent\nimprovement in the player's platform dwell time and an impressive 10 percent\nreduction in the costs associated with the recommendation, on our volatile\ngaming platform.",
      "tldr_zh": "该论文针对离线强化学习（Offline Reinforcement Learning）中的Q值过估计问题和状态空间偏差，提出了一种名为FAST-Q的框架，以优化高风险应用如在线游戏推荐系统。FAST-Q的核心方法包括：(1)利用Gradient Reversal Learning构建平衡的状态表示，减少政策特定偏差并支持反事实行动估计；(2)实现离线反事实探索与静态数据利用的并行机制；(3)引入Q-value decomposition策略进行多目标优化，提供可解释的推荐决策。实验结果显示，在游戏平台上，FAST-Q实现了玩家回报提升0.15%、终身价值(LTV)提升2%、推荐驱动参与度提升0.4%、平台停留时间提升2%，并将推荐成本降低10%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21383v1",
      "published_date": "2025-04-30 07:32:40 UTC",
      "updated_date": "2025-04-30 07:32:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:22:48.639385"
    },
    {
      "arxiv_id": "2505.00050v1",
      "title": "Emotional Analysis of Fashion Trends Using Social Media and AI: Sentiment Analysis on Twitter for Fashion Trend Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Aayam Bansal",
        "Agneya Tharun"
      ],
      "abstract": "This study explores the intersection of fashion trends and social media\nsentiment through computational analysis of Twitter data using the T4SA\n(Twitter for Sentiment Analysis) dataset. By applying natural language\nprocessing and machine learning techniques, we examine how sentiment patterns\nin fashion-related social media conversations can serve as predictors for\nemerging fashion trends. Our analysis involves the identification and\ncategorization of fashion-related content, sentiment classification with\nimproved normalization techniques, time series decomposition, statistically\nvalidated causal relationship modeling, cross-platform sentiment comparison,\nand brand-specific sentiment analysis. Results indicate correlations between\nsentiment patterns and fashion theme popularity, with accessories and\nstreetwear themes showing statistically significant rising trends. The Granger\ncausality analysis establishes sustainability and streetwear as primary trend\ndrivers, showing bidirectional relationships with several other themes. The\nfindings demonstrate that social media sentiment analysis can serve as an\neffective early indicator of fashion trend trajectories when proper statistical\nvalidation is applied. Our improved predictive model achieved 78.35% balanced\naccuracy in sentiment classification, establishing a reliable foundation for\ntrend prediction across positive, neutral, and negative sentiment categories.",
      "tldr_zh": "本研究利用 Twitter 数据和 T4SA 数据集，通过自然语言 processing 和 machine learning 技术分析社交媒体中的情感模式，以预测时尚趋势。研究涉及情感分类、时间序列分解、Granger causality 建模以及跨平台和品牌特定分析，结果显示情感模式与时尚主题流行高度相关，其中 accessories 和 streetwear 主题呈现显著上升趋势。Granger 因果分析确认 sustainability 和 streetwear 是主要趋势驱动因素，且改进的预测模型在情感分类中达到 78.35% 的 balanced accuracy，为社交媒体情感分析作为时尚趋势早期指标提供了可靠基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "13 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.00050v1",
      "published_date": "2025-04-30 07:27:06 UTC",
      "updated_date": "2025-04-30 07:27:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:23:01.594074"
    },
    {
      "arxiv_id": "2504.21372v1",
      "title": "Retrieval-Enhanced Few-Shot Prompting for Speech Event Extraction",
      "title_zh": "翻译失败",
      "authors": [
        "Máté Gedeon"
      ],
      "abstract": "Speech Event Extraction (SpeechEE) is a challenging task that lies at the\nintersection of Automatic Speech Recognition (ASR) and Natural Language\nProcessing (NLP), requiring the identification of structured event information\nfrom spoken language. In this work, we present a modular, pipeline-based\nSpeechEE framework that integrates high-performance ASR with semantic\nsearch-enhanced prompting of Large Language Models (LLMs). Our system first\nclassifies speech segments likely to contain events using a hybrid filtering\nmechanism including rule-based, BERT-based, and LLM-based models. It then\nemploys few-shot LLM prompting, dynamically enriched via semantic similarity\nretrieval, to identify event triggers and extract corresponding arguments. We\nevaluate the pipeline using multiple LLMs (Llama3-8B, GPT-4o-mini, and o1-mini)\nhighlighting significant performance gains with o1-mini, which achieves 63.3%\nF1 on trigger classification and 27.8% F1 on argument classification,\noutperforming prior benchmarks. Our results demonstrate that pipeline\napproaches, when empowered by retrieval-augmented LLMs, can rival or exceed\nend-to-end systems while maintaining interpretability and modularity. This work\nprovides practical insights into LLM-driven event extraction and opens pathways\nfor future hybrid models combining textual and acoustic features.",
      "tldr_zh": "本研究针对Speech Event Extraction (SpeechEE)任务，提出了一种模块化的管道框架，将高性能Automatic Speech Recognition (ASR)与语义搜索增强的Large Language Models (LLMs)提示相结合，从口语中提取结构化事件信息。框架首先使用混合过滤机制（包括基于规则、BERT和LLM的模型）分类可能包含事件的语音段，然后通过few-shot LLM prompting和动态语义相似性检索来识别事件触发器并提取相应参数。实验评估显示，使用o1-mini模型，该框架在触发分类上达到63.3% F1分数，在参数分类上达到27.8% F1，分数均优于现有基准。结果证明，这种检索增强的管道方法能与端到端系统媲美或超越，同时提升了系统的可解释性和模块化，为未来结合文本和声学特征的混合模型提供了新路径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21372v1",
      "published_date": "2025-04-30 07:10:10 UTC",
      "updated_date": "2025-04-30 07:10:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:23:14.557470"
    },
    {
      "arxiv_id": "2504.21370v2",
      "title": "ShorterBetter: Guiding Reasoning Models to Find Optimal Inference Length for Efficient Reasoning",
      "title_zh": "ShorterBetter：引导推理模型寻找最优推理长度以实现高效推理",
      "authors": [
        "Jingyang Yi",
        "Jiazheng Wang",
        "Sida Li"
      ],
      "abstract": "Recent models such as OpenAI o1 and DeepSeek-R1 have demonstrated strong\nperformance on reasoning-intensive tasks by generating extended\nChain-of-Thought (CoT) traces. While longer reasoning helps with thorough\nexploration of solution paths for complex problems, it also often leads to\ninefficient and redundant outputs--a phenomenon commonly described as\noverthinking. In this paper, we propose ShorterBetter, a simple yet effective\nreinforcement learning method that enables reasoning models to learn their own\noptimal CoT lengths without manual supervision. We define the Sample Optimal\nLength (SOL) as the length of the shortest correct response among multiple\ngenerations, which serves as a dynamic reward signal to guide the model toward\nefficient reasoning. Applied to DeepSeek-Distill-Qwen-1.5B/7B as base models,\nShorterBetter achieves 50%-80% reduction in output lengths in both in-domain\nand out-of-domain reasoning tasks while maintaining accuracy. Our reasoning\ntrace analysis shows that ShorterBetter refines the structure of the reasoning\ntraces by reducing unnecessary repetition, excessive self-verification, and\nover-exploration of alternatives.",
      "tldr_zh": "该论文提出 ShorterBetter，一种简单有效的强化学习方法，帮助推理模型（如基于 Chain-of-Thought (CoT) 的模型）自动学习最佳推理长度，避免 overthinking 导致的效率低下和冗余输出。方法通过定义 Sample Optimal Length (SOL) 作为动态奖励信号，即多个生成中最短的正确响应，来指导模型优化推理过程。实验结果显示，在 DeepSeek-Distill-Qwen-1.5B/7B 等基模型上，ShorterBetter 在领域内和领域外任务中将输出长度减少 50%-80%，同时保持准确性，并通过减少不必要的重复和过度探索来改进推理追踪结构。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Training script, model weights and analysis pipelines will be\n  released soon",
      "pdf_url": "http://arxiv.org/pdf/2504.21370v2",
      "published_date": "2025-04-30 07:04:19 UTC",
      "updated_date": "2025-05-16 20:59:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:23:25.988415"
    },
    {
      "arxiv_id": "2504.21368v1",
      "title": "Revisiting Diffusion Autoencoder Training for Image Reconstruction Quality",
      "title_zh": "重访扩散自编码器训练以提升图像重建质量",
      "authors": [
        "Pramook Khungurn",
        "Sukit Seripanitkarn",
        "Phonphrm Thawatdamrongkit",
        "Supasorn Suwajanakorn"
      ],
      "abstract": "Diffusion autoencoders (DAEs) are typically formulated as a noise prediction\nmodel and trained with a linear-$\\beta$ noise schedule that spends much of its\nsampling steps at high noise levels. Because high noise levels are associated\nwith recovering large-scale image structures and low noise levels with\nrecovering details, this configuration can result in low-quality and blurry\nimages. However, it should be possible to improve details while spending fewer\nsteps recovering structures because the latent code should already contain\nstructural information. Based on this insight, we propose a new DAE training\nmethod that improves the quality of reconstructed images. We divide training\ninto two phases. In the first phase, the DAE is trained as a vanilla\nautoencoder by always setting the noise level to the highest, forcing the\nencoder and decoder to populate the latent code with structural information. In\nthe second phase, we incorporate a noise schedule that spends more time in the\nlow-noise region, allowing the DAE to learn how to perfect the details. Our\nmethod results in images that have accurate high-level structures and low-level\ndetails while still preserving useful properties of the latent codes.",
      "tldr_zh": "本研究重新审视了Diffusion Autoencoders (DAEs)的训练方法，以提升图像重建质量。传统DAEs使用线性-β噪声调度，大部分步骤在高噪声水平，导致图像模糊和细节缺失；作者提出一种两阶段训练方法，第一阶段在最高噪声水平训练DAEs作为普通自编码器，确保潜在代码包含结构信息，第二阶段引入噪声调度，在低噪声区域花费更多时间来完善细节。新方法生成的图像兼具准确的高级结构和低级细节，同时保留了潜在代码的有用属性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "AI for Content Creation (AI4CC) Workshop at CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.21368v1",
      "published_date": "2025-04-30 07:00:33 UTC",
      "updated_date": "2025-04-30 07:00:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:23:37.236841"
    },
    {
      "arxiv_id": "2504.21366v1",
      "title": "DGFNet: End-to-End Audio-Visual Source Separation Based on Dynamic Gating Fusion",
      "title_zh": "DGFNet：基于动态门控融合的端到端音频",
      "authors": [
        "Yinfeng Yu",
        "Shiyu Sun"
      ],
      "abstract": "Current Audio-Visual Source Separation methods primarily adopt two design\nstrategies. The first strategy involves fusing audio and visual features at the\nbottleneck layer of the encoder, followed by processing the fused features\nthrough the decoder. However, when there is a significant disparity between the\ntwo modalities, this approach may lead to the loss of critical information. The\nsecond strategy avoids direct fusion and instead relies on the decoder to\nhandle the interaction between audio and visual features. Nonetheless, if the\nencoder fails to integrate information across modalities adequately, the\ndecoder may be unable to effectively capture the complex relationships between\nthem. To address these issues, this paper proposes a dynamic fusion method\nbased on a gating mechanism that dynamically adjusts the modality fusion\ndegree. This approach mitigates the limitations of solely relying on the\ndecoder and facilitates efficient collaboration between audio and visual\nfeatures. Additionally, an audio attention module is introduced to enhance the\nexpressive capacity of audio features, thereby further improving model\nperformance. Experimental results demonstrate that our method achieves\nsignificant performance improvements on two benchmark datasets, validating its\neffectiveness and advantages in Audio-Visual Source Separation tasks.",
      "tldr_zh": "本论文针对现有的Audio-Visual Source Separation方法存在的局限性，提出了一种端到端框架DGFNet，该框架基于Dynamic Gating Fusion动态门控机制，动态调整音频和视觉特征的融合程度，以促进模态间的有效协作，并引入audio attention module来增强音频特征的表达能力。相比传统策略，该方法避免了关键信息丢失和模态交互不足的问题。实验结果显示，在两个基准数据集上，DGFNet实现了显著的性能提升，验证了其在Audio-Visual Source Separation任务中的有效性和优势。",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "comment": "Main paper (9 pages). Accepted for publication by ICMR(International\n  Conference on Multimedia Retrieval) 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.21366v1",
      "published_date": "2025-04-30 06:55:24 UTC",
      "updated_date": "2025-04-30 06:55:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:23:49.441505"
    },
    {
      "arxiv_id": "2504.21358v1",
      "title": "A comparative study of deep learning and ensemble learning to extend the horizon of traffic forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Xiao Zheng",
        "Saeed Asadi Bagloee",
        "Majid Sarvi"
      ],
      "abstract": "Traffic forecasting is vital for Intelligent Transportation Systems, for\nwhich Machine Learning (ML) methods have been extensively explored to develop\ndata-driven Artificial Intelligence (AI) solutions. Recent research focuses on\nmodelling spatial-temporal correlations for short-term traffic prediction,\nleaving the favourable long-term forecasting a challenging and open issue. This\npaper presents a comparative study on large-scale real-world signalized\narterials and freeway traffic flow datasets, aiming to evaluate promising ML\nmethods in the context of large forecasting horizons up to 30 days. Focusing on\nmodelling capacity for temporal dynamics, we develop one ensemble ML method,\neXtreme Gradient Boosting (XGBoost), and a range of Deep Learning (DL) methods,\nincluding Recurrent Neural Network (RNN)-based methods and the state-of-the-art\nTransformer-based method. Time embedding is leveraged to enhance their\nunderstanding of seasonality and event factors. Experimental results highlight\nthat while the attention mechanism/Transformer framework is effective for\ncapturing long-range dependencies in sequential data, as the forecasting\nhorizon extends, the key to effective traffic forecasting gradually shifts from\ntemporal dependency capturing to periodicity modelling. Time embedding is\nparticularly effective in this context, helping naive RNN outperform Informer\nby 31.1% for 30-day-ahead forecasting. Meanwhile, as an efficient and robust\nmodel, XGBoost, while learning solely from time features, performs\ncompetitively with DL methods. Moreover, we investigate the impacts of various\nfactors like input sequence length, holiday traffic, data granularity, and\ntraining data size. The findings offer valuable insights and serve as a\nreference for future long-term traffic forecasting research and the improvement\nof AI's corresponding learning capabilities.",
      "tldr_zh": "本研究比较了深度学习(DL)和集成学习方法在长期交通预测（长达30天）中的表现，针对大规模真实交通数据集评估了这些方法的建模能力。研究开发了XGBoost（集成学习）以及多种DL方法，包括基于Recurrent Neural Network (RNN)的模型和Transformer-based模型，并通过时间嵌入技术增强对季节性和事件因素的理解。实验结果显示，随着预测期限延长，捕捉周期性变得比时间依赖更关键，时间嵌入使简单RNN在30天预测中比Informer提升31.1%；同时，XGBoost仅基于时间特征就与DL方法表现出色。研究还探讨了输入序列长度、假期交通、数据粒度和训练数据大小等因素的影响，为未来长期交通预测研究提供宝贵见解和参考。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "32 pages, 16 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.21358v1",
      "published_date": "2025-04-30 06:31:21 UTC",
      "updated_date": "2025-04-30 06:31:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:24:01.322437"
    },
    {
      "arxiv_id": "2504.21356v2",
      "title": "Nexus-Gen: A Unified Model for Image Understanding, Generation, and Editing",
      "title_zh": "Nexus-Gen：图像理解、生成和编辑的统一模型",
      "authors": [
        "Hong Zhang",
        "Zhongjie Duan",
        "Xingjun Wang",
        "Yuze Zhao",
        "Weiyi Lu",
        "Zhipeng Di",
        "Yixuan Xu",
        "Yingda Chen",
        "Yu Zhang"
      ],
      "abstract": "Unified multimodal large language models (MLLMs) aim to integrate multimodal\nunderstanding and generation abilities through a single framework. Despite\ntheir versatility, existing open-source unified models exhibit performance gaps\nagainst domain-specific architectures. To bridge this gap, we present\nNexus-Gen, a unified model that synergizes the language reasoning capabilities\nof LLMs with the image synthesis power of diffusion models. To align the\nembedding space of the LLM and diffusion model, we conduct a dual-phase\nalignment training process. (1) The autoregressive LLM learns to predict image\nembeddings conditioned on multimodal inputs, while (2) the vision decoder is\ntrained to reconstruct high-fidelity images from these embeddings. During\ntraining the LLM, we identified a critical discrepancy between the\nautoregressive paradigm's training and inference phases, where error\naccumulation in continuous embedding space severely degrades generation\nquality. To avoid this issue, we introduce a prefilled autoregression strategy\nthat prefills input sequence with position-embedded special tokens instead of\ncontinuous embeddings. Through dual-phase training, Nexus-Gen has developed the\nintegrated capability to comprehensively address the image understanding,\ngeneration and editing tasks. All models, datasets, and codes are published at\nhttps://github.com/modelscope/Nexus-Gen.git to facilitate further advancements\nacross the field.",
      "tldr_zh": "该研究提出Nexus-Gen，一种统一的模型，将LLMs的语言推理能力和diffusion models的图像合成能力相结合，用于图像理解、生成和编辑任务。模型通过双阶段对齐训练过程实现嵌入空间的统一：首先，autoregressive LLM学习基于多模态输入预测图像嵌入；其次，视觉解码器训练重建高保真图像，同时引入预填充autoregression策略来避免训练和推理阶段的错误积累。实验结果显示，Nexus-Gen有效桥接了现有统一模型与领域特定架构的性能差距，所有模型、数据集和代码已开源以促进进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21356v2",
      "published_date": "2025-04-30 06:30:48 UTC",
      "updated_date": "2025-05-08 08:58:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:24:14.081161"
    },
    {
      "arxiv_id": "2504.21347v1",
      "title": "IRL Dittos: Embodied Multimodal AI Agent Interactions in Open Spaces",
      "title_zh": "翻译失败",
      "authors": [
        "Seonghee Lee",
        "Denae Ford",
        "John Tang",
        "Sasa Junuzovic",
        "Asta Roseway",
        "Ed Cutrell",
        "Kori Inkpen"
      ],
      "abstract": "We introduce the In Real Life (IRL) Ditto, an AI-driven embodied agent\ndesigned to represent remote colleagues in shared office spaces, creating\nopportunities for real-time exchanges even in their absence. IRL Ditto offers a\nunique hybrid experience by allowing in-person colleagues to encounter a\ndigital version of their remote teammates, initiating greetings, updates, or\nsmall talk as they might in person. Our research question examines: How can the\nIRL Ditto influence interactions and relationships among colleagues in a shared\noffice space? Through a four-day study, we assessed IRL Ditto's ability to\nstrengthen social ties by simulating presence and enabling meaningful\ninteractions across different levels of social familiarity. We find that\nenhancing social relationships depended deeply on the foundation of the\nrelationship participants had with the source of the IRL Ditto. This study\nprovides insights into the role of embodied agents in enriching workplace\ndynamics for distributed teams.",
      "tldr_zh": "本研究引入了 IRL Dittos，这是一种实体多模态 AI 代理，旨在在共享办公室空间中代表远程同事，实现实时互动，如问候、更新或闲聊，从而增强团队协作。研究通过为期四天的实验评估了 IRL Dittos 如何通过模拟存在和促进有意义互动来影响同事关系，结果显示其对社会联系的强化高度依赖于参与者与代理来源的原有关系基础。该工作为分布式团队提供宝贵见解，展示了实体代理在丰富工作场所动态方面的潜力。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "H.5.2; I.2.9"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.21347v1",
      "published_date": "2025-04-30 06:16:32 UTC",
      "updated_date": "2025-04-30 06:16:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:24:25.022920"
    },
    {
      "arxiv_id": "2504.21344v1",
      "title": "Vision-Language Model-Based Semantic-Guided Imaging Biomarker for Early Lung Cancer Detection",
      "title_zh": "基于视觉-语言模型的语义引导影像学生物标志物用于早期肺癌检测",
      "authors": [
        "Luoting Zhuang",
        "Seyed Mohammad Hossein Tabatabaei",
        "Ramin Salehi-Rad",
        "Linh M. Tran",
        "Denise R. Aberle",
        "Ashley E. Prosper",
        "William Hsu"
      ],
      "abstract": "Objective: A number of machine learning models have utilized semantic\nfeatures, deep features, or both to assess lung nodule malignancy. However,\ntheir reliance on manual annotation during inference, limited interpretability,\nand sensitivity to imaging variations hinder their application in real-world\nclinical settings. Thus, this research aims to integrate semantic features\nderived from radiologists' assessments of nodules, allowing the model to learn\nclinically relevant, robust, and explainable features for predicting lung\ncancer. Methods: We obtained 938 low-dose CT scans from the National Lung\nScreening Trial with 1,246 nodules and semantic features. The Lung Image\nDatabase Consortium dataset contains 1,018 CT scans, with 2,625 lesions\nannotated for nodule characteristics. Three external datasets were obtained\nfrom UCLA Health, the LUNGx Challenge, and the Duke Lung Cancer Screening. We\nfinetuned a pretrained Contrastive Language-Image Pretraining model with a\nparameter-efficient fine-tuning approach to align imaging and semantic features\nand predict the one-year lung cancer diagnosis. Results: We evaluated the\nperformance of the one-year diagnosis of lung cancer with AUROC and AUPRC and\ncompared it to three state-of-the-art models. Our model demonstrated an AUROC\nof 0.90 and AUPRC of 0.78, outperforming baseline state-of-the-art models on\nexternal datasets. Using CLIP, we also obtained predictions on semantic\nfeatures, such as nodule margin (AUROC: 0.81), nodule consistency (0.81), and\npleural attachment (0.84), that can be used to explain model predictions.\nConclusion: Our approach accurately classifies lung nodules as benign or\nmalignant, providing explainable outputs, aiding clinicians in comprehending\nthe underlying meaning of model predictions. This approach also prevents the\nmodel from learning shortcuts and generalizes across clinical settings.",
      "tldr_zh": "本研究旨在通过整合放射科医生的语义特征，开发一种基于 Vision-Language Model（如 Contrastive Language-Image Pretraining (CLIP)）的语义引导成像生物标记物，用于早期肺癌检测，从而解决传统模型在可解释性和鲁棒性方面的局限。方法包括微调预训练的 CLIP 模型，使用参数高效微调技术，对齐图像和语义特征，并基于多个数据集（如 National Lung Screening Trial 和外部数据集）预测一年的肺癌诊断。结果显示，该模型在外部数据集上达到 AUROC 0.90 和 AUPRC 0.78，优于现有 state-of-the-art 模型，并在语义特征预测（如 nodule margin AUROC 0.81）上表现出色，提供可解释输出。总之，此方法可帮助临床医生理解模型预测、防止学习捷径，并实现跨临床环境的泛化。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21344v1",
      "published_date": "2025-04-30 06:11:34 UTC",
      "updated_date": "2025-04-30 06:11:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:24:38.492109"
    },
    {
      "arxiv_id": "2504.21326v1",
      "title": "Q-function Decomposition with Intervention Semantics with Factored Action Spaces",
      "title_zh": "翻译失败",
      "authors": [
        "Junkyu Lee",
        "Tian Gao",
        "Elliot Nelson",
        "Miao Liu",
        "Debarun Bhattacharjya",
        "Songtao Lu"
      ],
      "abstract": "Many practical reinforcement learning environments have a discrete factored\naction space that induces a large combinatorial set of actions, thereby posing\nsignificant challenges. Existing approaches leverage the regular structure of\nthe action space and resort to a linear decomposition of Q-functions, which\navoids enumerating all combinations of factored actions. In this paper, we\nconsider Q-functions defined over a lower dimensional projected subspace of the\noriginal action space, and study the condition for the unbiasedness of\ndecomposed Q-functions using causal effect estimation from the no unobserved\nconfounder setting in causal statistics. This leads to a general scheme which\nwe call action decomposed reinforcement learning that uses the projected\nQ-functions to approximate the Q-function in standard model-free reinforcement\nlearning algorithms. The proposed approach is shown to improve sample\ncomplexity in a model-based reinforcement learning setting. We demonstrate\nimprovements in sample efficiency compared to state-of-the-art baselines in\nonline continuous control environments and a real-world offline sepsis\ntreatment environment.",
      "tldr_zh": "该论文针对强化学习环境中离散的因子化动作空间（factored action spaces）导致的动作组合爆炸问题，提出了一种Q-function分解方法，利用干预语义（Intervention Semantics）来确保分解Q函数的无偏性。方法基于因果统计中的无隐藏混淆变量假设，将Q函数定义在原始动作空间的低维投影子空间上，并开发了action decomposed reinforcement learning框架，以近似标准无模型强化学习算法中的Q函数。实验结果显示，该方法在基于模型的强化学习中提高了样本复杂度，并在在线连续控制环境以及真实世界的离线败血症治疗环境中，比现有基线显著提升了样本效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "AISTATS 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.21326v1",
      "published_date": "2025-04-30 05:26:51 UTC",
      "updated_date": "2025-04-30 05:26:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:24:48.780800"
    },
    {
      "arxiv_id": "2504.21323v1",
      "title": "How to Backdoor the Knowledge Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Chen Wu",
        "Qian Ma",
        "Prasenjit Mitra",
        "Sencun Zhu"
      ],
      "abstract": "Knowledge distillation has become a cornerstone in modern machine learning\nsystems, celebrated for its ability to transfer knowledge from a large, complex\nteacher model to a more efficient student model. Traditionally, this process is\nregarded as secure, assuming the teacher model is clean. This belief stems from\nconventional backdoor attacks relying on poisoned training data with backdoor\ntriggers and attacker-chosen labels, which are not involved in the distillation\nprocess. Instead, knowledge distillation uses the outputs of a clean teacher\nmodel to guide the student model, inherently preventing recognition or response\nto backdoor triggers as intended by an attacker. In this paper, we challenge\nthis assumption by introducing a novel attack methodology that strategically\npoisons the distillation dataset with adversarial examples embedded with\nbackdoor triggers. This technique allows for the stealthy compromise of the\nstudent model while maintaining the integrity of the teacher model. Our\ninnovative approach represents the first successful exploitation of\nvulnerabilities within the knowledge distillation process using clean teacher\nmodels. Through extensive experiments conducted across various datasets and\nattack settings, we demonstrate the robustness, stealthiness, and effectiveness\nof our method. Our findings reveal previously unrecognized vulnerabilities and\npave the way for future research aimed at securing knowledge distillation\nprocesses against backdoor attacks.",
      "tldr_zh": "这篇论文挑战了知识蒸馏（knowledge distillation）的传统安全假设，即如果教师模型是干净的，学生模型就不会受到后门攻击（backdoor attacks）。作者提出了一种新颖的攻击方法，通过在蒸馏数据集上添加带有后门触发器的对抗样本（adversarial examples），实现对学生模型的隐秘破坏，同时保持教师模型的完整性。实验在多种数据集和攻击设置下证明了该方法的鲁棒性、隐蔽性和有效性，首次展示了知识蒸馏过程的潜在漏洞。该研究为未来增强知识蒸馏的安全性提供了重要启示。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21323v1",
      "published_date": "2025-04-30 05:19:23 UTC",
      "updated_date": "2025-04-30 05:19:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:25:00.658947"
    },
    {
      "arxiv_id": "2504.21318v1",
      "title": "Phi-4-reasoning Technical Report",
      "title_zh": "Phi-4-reasoning 技术报告",
      "authors": [
        "Marah Abdin",
        "Sahaj Agarwal",
        "Ahmed Awadallah",
        "Vidhisha Balachandran",
        "Harkirat Behl",
        "Lingjiao Chen",
        "Gustavo de Rosa",
        "Suriya Gunasekar",
        "Mojan Javaheripi",
        "Neel Joshi",
        "Piero Kauffmann",
        "Yash Lara",
        "Caio César Teodoro Mendes",
        "Arindam Mitra",
        "Besmira Nushi",
        "Dimitris Papailiopoulos",
        "Olli Saarikivi",
        "Shital Shah",
        "Vaishnavi Shrivastava",
        "Vibhav Vineet",
        "Yue Wu",
        "Safoora Yousefi",
        "Guoqing Zheng"
      ],
      "abstract": "We introduce Phi-4-reasoning, a 14-billion parameter reasoning model that\nachieves strong performance on complex reasoning tasks. Trained via supervised\nfine-tuning of Phi-4 on carefully curated set of \"teachable\" prompts-selected\nfor the right level of complexity and diversity-and reasoning demonstrations\ngenerated using o3-mini, Phi-4-reasoning generates detailed reasoning chains\nthat effectively leverage inference-time compute. We further develop\nPhi-4-reasoning-plus, a variant enhanced through a short phase of outcome-based\nreinforcement learning that offers higher performance by generating longer\nreasoning traces. Across a wide range of reasoning tasks, both models\noutperform significantly larger open-weight models such as\nDeepSeek-R1-Distill-Llama-70B model and approach the performance levels of full\nDeepSeek-R1 model. Our comprehensive evaluations span benchmarks in math and\nscientific reasoning, coding, algorithmic problem solving, planning, and\nspatial understanding. Interestingly, we observe a non-trivial transfer of\nimprovements to general-purpose benchmarks as well. In this report, we provide\ninsights into our training data, our training methodologies, and our\nevaluations. We show that the benefit of careful data curation for supervised\nfine-tuning (SFT) extends to reasoning language models, and can be further\namplified by reinforcement learning (RL). Finally, our evaluation points to\nopportunities for improving how we assess the performance and robustness of\nreasoning models.",
      "tldr_zh": "我们引入了 Phi-4-reasoning，这是一个 14 亿参数的推理模型，通过对 Phi-4 进行 supervised fine-tuning 和使用精心策划的 \"teachable\" 提示及 o3-mini 生成的演示，实现了在复杂推理任务上生成详细推理链的能力。模型的增强版 Phi-4-reasoning-plus 通过 outcome-based reinforcement learning 进一步提升性能，生成更长的推理痕迹。在数学、科学推理、编码、算法问题解决、规划和空间理解等基准上，这两个模型超过了更大的开源模型如 DeepSeek-R1-Distill-Llama-70B，并接近 DeepSeek-R1 的水平，同时观察到改进在一般基准上也有显著转移。研究强调了数据策划在 supervised fine-tuning 中的益处，以及 reinforcement learning 的放大作用，并指出未来评估推理模型性能和鲁棒性的改进机会。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21318v1",
      "published_date": "2025-04-30 05:05:09 UTC",
      "updated_date": "2025-04-30 05:05:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:25:14.606978"
    },
    {
      "arxiv_id": "2504.21297v1",
      "title": "Participatory AI, Public Sector AI, Differential Privacy, Conversational Interfaces, Explainable AI, Citizen Engagement in AI",
      "title_zh": "参与式 AI、公共部门 AI、差分隐私、对话接口、可解释 AI、公民参与 AI",
      "authors": [
        "Wenjun Yang",
        "Eyhab Al-Masri"
      ],
      "abstract": "This paper introduces a conversational interface system that enables\nparticipatory design of differentially private AI systems in public sector\napplications. Addressing the challenge of balancing mathematical privacy\nguarantees with democratic accountability, we propose three key contributions:\n(1) an adaptive $\\epsilon$-selection protocol leveraging TOPSIS multi-criteria\ndecision analysis to align citizen preferences with differential privacy (DP)\nparameters, (2) an explainable noise-injection framework featuring real-time\nMean Absolute Error (MAE) visualizations and GPT-4-powered impact analysis, and\n(3) an integrated legal-compliance mechanism that dynamically modulates privacy\nbudgets based on evolving regulatory constraints. Our results advance\nparticipatory AI practices by demonstrating how conversational interfaces can\nenhance public engagement in algorithmic privacy mechanisms, ensuring that\nprivacy-preserving AI in public sector governance remains both mathematically\nrobust and democratically accountable.",
      "tldr_zh": "这篇论文提出了一种对话接口系统，用于在公有部门应用中实现参与式设计差分隐私 (Differential Privacy) AI 系统，以平衡数学隐私保证与民主问责制。关键贡献包括：(1) 自适应 ε-选择协议，利用 TOPSIS 多标准决策分析来匹配公民偏好与 DP 参数；(2) 可解释噪声注入框架，提供实时 Mean Absolute Error (MAE) 可视化和 GPT-4 驱动的影响分析；以及 (3) 一个集成的法律合规机制，根据监管变化动态调整隐私预算。结果表明，该系统通过提升公众参与，推进了参与式 AI 实践，确保公有部门 AI 治理在数学上稳健且民主问责。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "cs.CY",
        "cs.ET",
        "math.IT"
      ],
      "primary_category": "cs.IT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21297v1",
      "published_date": "2025-04-30 04:10:50 UTC",
      "updated_date": "2025-04-30 04:10:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:25:27.762040"
    },
    {
      "arxiv_id": "2504.21296v1",
      "title": "Fairness in Graph Learning Augmented with Machine Learning: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Renqiang Luo",
        "Ziqi Xu",
        "Xikun Zhang",
        "Qing Qing",
        "Huafei Huang",
        "Enyan Dai",
        "Zhe Wang",
        "Bo Yang"
      ],
      "abstract": "Augmenting specialised machine learning techniques into traditional graph\nlearning models has achieved notable success across various domains, including\nfederated graph learning, dynamic graph learning, and graph transformers.\nHowever, the intricate mechanisms of these specialised techniques introduce\nsignificant challenges in maintaining model fairness, potentially resulting in\ndiscriminatory outcomes in high-stakes applications such as recommendation\nsystems, disaster response, criminal justice, and loan approval. This paper\nsystematically examines the unique fairness challenges posed by Graph Learning\naugmented with Machine Learning (GL-ML). It highlights the complex interplay\nbetween graph learning mechanisms and machine learning techniques, emphasising\nhow the augmentation of machine learning both enhances and complicates\nfairness. Additionally, we explore four critical techniques frequently employed\nto improve fairness in GL-ML methods. By thoroughly investigating the root\ncauses and broader implications of fairness challenges in this rapidly evolving\nfield, this work establishes a robust foundation for future research and\ninnovation in GL-ML fairness.",
      "tldr_zh": "这篇调查论文审视了在Graph Learning中增强Machine Learning (GL-ML) 所带来的公平性挑战，这些挑战源于机器学习技术的整合，可能导致高风险应用（如推荐系统、刑事司法和贷款审批）中的歧视性结果。论文强调了图学习机制与机器学习互动的复杂性，既提升了模型性能又加剧了公平问题，并探讨了四种关键技术来改善GL-ML的公平性。通过分析这些挑战的根本原因和广泛影响，该工作为未来Graph Learning领域的研究和创新奠定了坚实基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21296v1",
      "published_date": "2025-04-30 04:02:23 UTC",
      "updated_date": "2025-04-30 04:02:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:25:37.849353"
    },
    {
      "arxiv_id": "2504.21289v1",
      "title": "Orthogonal Factor-Based Biclustering Algorithm (BCBOF) for High-Dimensional Data and Its Application in Stock Trend Prediction",
      "title_zh": "基于正交因子双聚类",
      "authors": [
        "Yan Huang",
        "Da-Qing Zhang"
      ],
      "abstract": "Biclustering is an effective technique in data mining and pattern\nrecognition. Biclustering algorithms based on traditional clustering face two\nfundamental limitations when processing high-dimensional data: (1) The distance\nconcentration phenomenon in high-dimensional spaces leads to data sparsity,\nrendering similarity measures ineffective; (2) Mainstream linear dimensionality\nreduction methods disrupt critical local structural patterns. To apply\nbiclustering to high-dimensional datasets, we propose an orthogonal\nfactor-based biclustering algorithm (BCBOF). First, we constructed orthogonal\nfactors in the vector space of the high-dimensional dataset. Then, we performed\nclustering using the coordinates of the original data in the orthogonal\nsubspace as clustering targets. Finally, we obtained biclustering results of\nthe original dataset. Since dimensionality reduction was applied before\nclustering, the proposed algorithm effectively mitigated the data sparsity\nproblem caused by high dimensionality. Additionally, we applied this\nbiclustering algorithm to stock technical indicator combinations and stock\nprice trend prediction. Biclustering results were transformed into fuzzy rules,\nand we incorporated profit-preserving and stop-loss rules into the rule set,\nultimately forming a fuzzy inference system for stock price trend predictions\nand trading signals. To evaluate the performance of BCBOF, we compared it with\nexisting biclustering methods using multiple evaluation metrics. The results\nshowed that our algorithm outperformed other biclustering techniques. To\nvalidate the effectiveness of the fuzzy inference system, we conducted virtual\ntrading experiments using historical data from 10 A-share stocks. The\nexperimental results showed that the generated trading strategies yielded\nhigher returns for investors.",
      "tldr_zh": "该论文提出了一种基于正交因子（orthogonal factors）的双聚类算法（BCBOF），旨在解决传统聚类在高维数据中面临的距离集中现象（distance concentration phenomenon）和线性降维破坏局部结构的问题。通过在高维数据集的向量空间中构建正交因子，并使用原数据在正交子空间的坐标进行聚类，算法有效缓解了数据稀疏问题并获得准确的双聚类结果。研究将BCBOF应用于股票技术指标组合和价格趋势预测，将聚类结果转化为模糊规则（fuzzy rules），并结合保利和止损规则形成模糊推理系统（fuzzy inference system）。实验结果显示，BCBOF在多个评价指标上优于现有方法，并在10支A股股票的虚拟交易中产生了更高的投资回报。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21289v1",
      "published_date": "2025-04-30 03:49:08 UTC",
      "updated_date": "2025-04-30 03:49:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:25:51.160366"
    },
    {
      "arxiv_id": "2504.21277v2",
      "title": "Reinforced MLLM: A Survey on RL-Based Reasoning in Multimodal Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Guanghao Zhou",
        "Panjia Qiu",
        "Cen Chen",
        "Jie Wang",
        "Zheming Yang",
        "Jian Xu",
        "Minghui Qiu"
      ],
      "abstract": "The application of reinforcement learning (RL) to enhance the reasoning\ncapabilities of Multimodal Large Language Models (MLLMs) constitutes a rapidly\nadvancing research area. While MLLMs extend Large Language Models (LLMs) to\nhandle diverse modalities such as vision, audio, and video, enabling robust\nreasoning across multimodal inputs remains challenging. This paper provides a\nsystematic review of recent advances in RL-based reasoning for MLLMs, covering\nkey algorithmic designs, reward mechanism innovations, and practical\napplications. We highlight two main RL paradigms, value-model-free and\nvalue-model-based methods, and analyze how RL enhances reasoning abilities by\noptimizing reasoning trajectories and aligning multimodal information.\nAdditionally, we provide an extensive overview of benchmark datasets,\nevaluation protocols, and current limitations, and propose future research\ndirections to address challenges such as sparse rewards, inefficient\ncross-modal reasoning, and real-world deployment constraints. Our goal is to\nprovide a comprehensive and structured guide to RL-based multimodal reasoning.",
      "tldr_zh": "这篇论文对强化学习(RL)用于提升多模态大语言模型(MLLMs)的推理能力进行了系统综述，涵盖了关键算法设计、奖励机制创新以及实际应用。论文分析了两种主要RL范式——价值模型无关和价值模型相关方法，以及RL如何优化推理轨迹和对齐多模态信息，从而增强MLLMs在处理视觉、音频和视频等模态时的鲁棒性。最终，它概述了基准数据集、评估协议、当前挑战（如稀疏奖励和跨模态推理效率问题），并提出未来研究方向以推动RL在真实世界部署中的应用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21277v2",
      "published_date": "2025-04-30 03:14:28 UTC",
      "updated_date": "2025-05-21 06:08:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:26:02.588217"
    },
    {
      "arxiv_id": "2504.21276v1",
      "title": "Assessing LLM code generation quality through path planning tasks",
      "title_zh": "通过路径规划任务评估 LLM 代码生成质量",
      "authors": [
        "Wanyi Chen",
        "Meng-Wen Su",
        "Mary L. Cummings"
      ],
      "abstract": "As LLM-generated code grows in popularity, more evaluation is needed to\nassess the risks of using such tools, especially for safety-critical\napplications such as path planning. Existing coding benchmarks are insufficient\nas they do not reflect the context and complexity of safety-critical\napplications. To this end, we assessed six LLMs' abilities to generate the code\nfor three different path-planning algorithms and tested them on three maps of\nvarious difficulties. Our results suggest that LLM-generated code presents\nserious hazards for path planning applications and should not be applied in\nsafety-critical contexts without rigorous testing.",
      "tldr_zh": "本研究评估了大型语言模型（LLMs）生成代码的质量，特别针对安全关键应用如路径规划任务，强调现有代码基准的不足。研究者测试了六个LLMs生成的三种路径规划算法代码，并在三种不同难度的地图上进行验证。结果显示，LLM生成的代码存在严重风险，可能导致安全问题，因此在安全关键环境中使用时需进行严格测试。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21276v1",
      "published_date": "2025-04-30 03:11:54 UTC",
      "updated_date": "2025-04-30 03:11:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:26:11.837456"
    },
    {
      "arxiv_id": "2505.00742v1",
      "title": "Zoomer: Adaptive Image Focus Optimization for Black-box MLLM",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaxu Qian",
        "Chendong Wang",
        "Yifan Yang",
        "Chaoyun Zhang",
        "Huiqiang Jiang",
        "Xufang Luo",
        "Yu Kang",
        "Qingwei Lin",
        "Anlan Zhang",
        "Shiqi Jiang",
        "Ting Cao",
        "Tianjun Mao",
        "Suman Banerjee",
        "Guyue Liu",
        "Saravan Rajmohan",
        "Dongmei Zhang",
        "Yuqing Yang",
        "Qi Zhang",
        "Lili Qiu"
      ],
      "abstract": "Recent advancements in multimodal large language models (MLLMs) have\nbroadened the scope of vision-language tasks, excelling in applications like\nimage captioning and interactive question-answering. However, these models\nstruggle with accurately processing visual data, particularly in tasks\nrequiring precise object recognition and fine visual details. Stringent token\nlimits often result in the omission of critical information, hampering\nperformance. To address these limitations, we introduce \\SysName, a novel\nvisual prompting mechanism designed to enhance MLLM performance while\npreserving essential visual details within token limits. \\SysName features\nthree key innovations: a prompt-aware strategy that dynamically highlights\nrelevant image regions, a spatial-preserving orchestration schema that\nmaintains object integrity, and a budget-aware prompting method that balances\nglobal context with crucial visual details. Comprehensive evaluations across\nmultiple datasets demonstrate that \\SysName consistently outperforms baseline\nmethods, achieving up to a $26.9\\%$ improvement in accuracy while significantly\nreducing token consumption.",
      "tldr_zh": "该研究针对多模态大语言模型 (MLLMs) 在处理精确对象识别和细致视觉细节时面临的挑战（如 token 限制导致信息缺失），提出了一种新型视觉提示机制 Zoomer。Zoomer 包括三个关键创新：prompt-aware strategy 用于动态突出相关图像区域、spatial-preserving orchestration schema 用于维护对象完整性，以及 budget-aware prompting method 用于平衡全局上下文和关键细节。在多个数据集上的全面评估中，Zoomer 比基线方法提升准确率高达 26.9%，同时显著减少 token 消耗，从而提升了 MLLMs 的整体性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00742v1",
      "published_date": "2025-04-30 02:51:10 UTC",
      "updated_date": "2025-04-30 02:51:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:26:25.351404"
    },
    {
      "arxiv_id": "2504.21261v1",
      "title": "Multi-Domain Causal Discovery in Bijective Causal Models",
      "title_zh": "在双射因果模型中的多域因果发现",
      "authors": [
        "Kasra Jalaldoust",
        "Saber Salehkaleybar",
        "Negar Kiyavash"
      ],
      "abstract": "We consider the problem of causal discovery (a.k.a., causal structure\nlearning) in a multi-domain setting. We assume that the causal functions are\ninvariant across the domains, while the distribution of the exogenous noise may\nvary. Under causal sufficiency (i.e., no confounders exist), we show that the\ncausal diagram can be discovered under less restrictive functional assumptions\ncompared to previous work. What enables causal discovery in this setting is\nbijective generation mechanisms (BGM), which ensures that the functional\nrelation between the exogenous noise $E$ and the endogenous variable $Y$ is\nbijective and differentiable in both directions at every level of the cause\nvariable $X = x$. BGM generalizes a variety of models including additive noise\nmodel, LiNGAM, post-nonlinear model, and location-scale noise model. Further,\nwe derive a statistical test to find the parents set of the target variable.\nExperiments on various synthetic and real-world datasets validate our\ntheoretical findings.",
      "tldr_zh": "本研究探讨了多域设置下的因果发现（causal discovery），假设因果函数在不同域间不变，而外生噪声（exogenous noise）的分布可能变化。在因果充分性（causal sufficiency）条件下，通过引入双射生成机制（bijective generation mechanisms, BGM），该机制确保外生噪声 E 和内生变量 Y 之间的函数关系在每个因变量 X = x 水平上是双射且可微，从而在更宽松的函数假设下发现因果图。BGM 泛化了多种模型，包括 additive noise model、LiNGAM、post-nonlinear model 和 location-scale noise model，并推导了一个统计测试来识别目标变量的父集（parents set）。实验在各种合成和真实数据集上验证了这些理论发现，证明了方法的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "comment": "Proceedings of Causal Learning and Reasoning (CLeaR) 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.21261v1",
      "published_date": "2025-04-30 02:30:10 UTC",
      "updated_date": "2025-04-30 02:30:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:26:38.203170"
    },
    {
      "arxiv_id": "2505.00737v1",
      "title": "A Survey on 3D Reconstruction Techniques in Plant Phenotyping: From Classical Methods to Neural Radiance Fields (NeRF), 3D Gaussian Splatting (3DGS), and Beyond",
      "title_zh": "翻译失败",
      "authors": [
        "Jiajia Li",
        "Xinda Qi",
        "Seyed Hamidreza Nabaei",
        "Meiqi Liu",
        "Dong Chen",
        "Xin Zhang",
        "Xunyuan Yin",
        "Zhaojian Li"
      ],
      "abstract": "Plant phenotyping plays a pivotal role in understanding plant traits and\ntheir interactions with the environment, making it crucial for advancing\nprecision agriculture and crop improvement. 3D reconstruction technologies have\nemerged as powerful tools for capturing detailed plant morphology and\nstructure, offering significant potential for accurate and automated\nphenotyping. This paper provides a comprehensive review of the 3D\nreconstruction techniques for plant phenotyping, covering classical\nreconstruction methods, emerging Neural Radiance Fields (NeRF), and the novel\n3D Gaussian Splatting (3DGS) approach. Classical methods, which often rely on\nhigh-resolution sensors, are widely adopted due to their simplicity and\nflexibility in representing plant structures. However, they face challenges\nsuch as data density, noise, and scalability. NeRF, a recent advancement,\nenables high-quality, photorealistic 3D reconstructions from sparse viewpoints,\nbut its computational cost and applicability in outdoor environments remain\nareas of active research. The emerging 3DGS technique introduces a new paradigm\nin reconstructing plant structures by representing geometry through Gaussian\nprimitives, offering potential benefits in both efficiency and scalability. We\nreview the methodologies, applications, and performance of these approaches in\nplant phenotyping and discuss their respective strengths, limitations, and\nfuture prospects (https://github.com/JiajiaLi04/3D-Reconstruction-Plants).\nThrough this review, we aim to provide insights into how these diverse 3D\nreconstruction techniques can be effectively leveraged for automated and\nhigh-throughput plant phenotyping, contributing to the next generation of\nagricultural technology.",
      "tldr_zh": "这篇论文对植物表型学中的 3D 重建技术进行了全面综述，从经典方法到新兴的 Neural Radiance Fields (NeRF) 和 3D Gaussian Splatting (3DGS)，探讨其在精确捕获植物形态方面的应用。经典方法依赖高分辨率传感器，具有简单性和灵活性，但面临数据密度、噪声和可扩展性挑战；NeRF 能从稀疏视角生成高质量光照真实重建，但计算成本高且户外适用性需进一步研究。3DGS 通过高斯原语表示几何，提供更高的效率和可扩展性，适合大规模植物表型学任务；总体上，论文分析了这些技术的优势、局限性及未来潜力，以推动自动化高通量农业技术的发展。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "17 pages, 7 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.00737v1",
      "published_date": "2025-04-30 02:04:23 UTC",
      "updated_date": "2025-04-30 02:04:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:26:52.017215"
    },
    {
      "arxiv_id": "2504.21239v1",
      "title": "Memorization and Knowledge Injection in Gated LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Xu Pan",
        "Ely Hahami",
        "Zechen Zhang",
        "Haim Sompolinsky"
      ],
      "abstract": "Large Language Models (LLMs) currently struggle to sequentially add new\nmemories and integrate new knowledge. These limitations contrast with the human\nability to continuously learn from new experiences and acquire knowledge\nthroughout life. Most existing approaches add memories either through large\ncontext windows or external memory buffers (e.g., Retrieval-Augmented\nGeneration), and studies on knowledge injection rarely test scenarios\nresembling everyday life events. In this work, we introduce a continual\nlearning framework, Memory Embedded in Gated LLMs (MEGa), which injects event\nmemories directly into the weights of LLMs. Each memory is stored in a\ndedicated set of gated low-rank weights. During inference, a gating mechanism\nactivates relevant memory weights by matching query embeddings to stored memory\nembeddings. This enables the model to both recall entire memories and answer\nrelated questions. On two datasets - fictional characters and Wikipedia events\n- MEGa outperforms baseline approaches in mitigating catastrophic forgetting.\nOur model draws inspiration from the complementary memory system of the human\nbrain.",
      "tldr_zh": "本研究探讨了大型语言模型(LLMs)在记忆存储和知识注入方面的局限性，特别是难以顺序添加新记忆并避免灾难性遗忘(unlike human learning)。为了解决这一问题，作者提出了一种持续学习框架Memory Embedded in Gated LLMs (MEGa)，通过将事件记忆直接注入LLMs的门控低秩权重中，并使用门控机制匹配查询嵌入以激活相关记忆，从而实现记忆回忆和相关问题回答。实验结果显示，在虚构人物和Wikipedia事件数据集上，MEGa比基线方法（如Retrieval-Augmented Generation）更有效地缓解了灾难性遗忘，并从人类大脑的互补记忆系统中汲取灵感。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21239v1",
      "published_date": "2025-04-30 00:28:32 UTC",
      "updated_date": "2025-04-30 00:28:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:27:01.663179"
    },
    {
      "arxiv_id": "2504.21235v1",
      "title": "Efficient Quantum-Safe Homomorphic Encryption for Quantum Computer Programs",
      "title_zh": "翻译失败",
      "authors": [
        "Ben Goertzel"
      ],
      "abstract": "We present a lattice-based scheme for homomorphic evaluation of quantum\nprograms and proofs that remains secure against quantum adversaries. Classical\nhomomorphic encryption is lifted to the quantum setting by replacing\ncomposite-order groups with Module Learning-With-Errors (MLWE) lattices and by\ngeneralizing polynomial functors to bounded natural super functors (BNSFs). A\nsecret depolarizing BNSF mask hides amplitudes, while each quantum state is\nstored as an MLWE ciphertext pair. We formalize security with the qIND-CPA game\nthat allows coherent access to the encryption oracle and give a four-hybrid\nreduction to decisional MLWE.\n  The design also covers practical issues usually left open. A typed QC-bridge\nkeeps classical bits produced by measurements encrypted yet still usable as\ncontrols, with weak-measurement semantics for expectation-value workloads.\nEncrypted Pauli twirls add circuit privacy. If a fixed knowledge base is\nneeded, its axioms are shipped as MLWE \"capsules\"; the evaluator can use them\nbut cannot read them. A rho-calculus driver schedules encrypted tasks across\nseveral QPUs and records an auditable trace on an RChain-style ledger.\n  Performance analysis shows that the extra lattice arithmetic fits inside\ntoday's QPU idle windows: a 100-qubit, depth-10^3 teleportation-based proof\nruns in about 10 ms, the public key (seed only) is 32 bytes, and even a\nCCA-level key stays below 300 kB. A photonic Dirac-3 prototype that executes\nhomomorphic teleportation plus knowledge-base-relative amplitude checks appears\nfeasible with current hardware. These results indicate that fully homomorphic,\nknowledge-base-aware quantum reasoning is compatible with near-term quantum\nclouds and standard post-quantum security assumptions.",
      "tldr_zh": "该论文提出了一种高效的量子安全同态加密方案，用于量子计算机程序的评估，该方案基于格结构（lattice-based），通过将 Module Learning-With-Errors (MLWE) 格子取代复合阶群，并将多项式函子推广到 bounded natural super functors (BNSFs)，以抵抗量子对手。安全模型采用 qIND-CPA 游戏形式化，并通过四混合归约证明其基于 decisional MLWE 的安全性；同时，该设计处理实际问题，如使用 typed QC-bridge 管理加密的经典位和弱测量语义，以及 Encrypted Pauli twirls 增强电路隐私。实验结果显示，该方案在性能上高效，例如一个 100-qubit、深度-10^3 的传送证明仅需约 10 ms，公钥种子仅 32 字节，且与当前量子硬件兼容，支持近期的量子云和后量子安全假设。",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21235v1",
      "published_date": "2025-04-30 00:08:43 UTC",
      "updated_date": "2025-04-30 00:08:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:27:14.294332"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 101,
  "processed_papers_count": 101,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-24T18:27:37.844628"
}