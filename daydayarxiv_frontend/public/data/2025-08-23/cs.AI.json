{
  "date": "2025-08-23",
  "category": "cs.AI",
  "summary": "ä½ å¥½ï¼æ¬¢è¿æ¥åˆ° UTC æ—¶é—´ 2025-08-23 çš„ arXiv ä¸­æ–‡ TLDR å¿«æŠ¥ï¼\n\næˆ‘æ˜¯ä½ ä»¬çš„è€æœ‹å‹ï¼Œä¸“æ³¨äº arXiv æ¯æ—¥æŒ–æ˜çš„ç ”ç©¶å‘˜ã€‚\n\n**ä¸€å¥è¯æ€»ç»“ï¼š**\nä»Šå¤©çš„ arXiv å……æ»¡äº†å¯¹äº **LLM å¯¹é½æœºåˆ¶ï¼ˆç‰¹åˆ«æ˜¯ DPO æ•°æ®è´¨é‡ï¼‰çš„æ·±åº¦åæ€**ï¼Œä»¥åŠ **Agent å®‰å…¨æ€§ï¼ˆTOCTOU æ¼æ´ï¼‰** çš„é¦–ä¸ªç³»ç»Ÿæ€§ç ”ç©¶ï¼›åŒæ—¶ï¼Œ**å…·èº«æ™ºèƒ½ï¼ˆVLA æ¨¡å‹ï¼‰** è¯•å›¾æ‘†è„± Diffusion çš„æ¨ç†å»¶è¿Ÿï¼Œè€Œ **å¤šæ¨¡æ€é¢†åŸŸ** åˆ™åœ¨å°è¯•ä¿®å¤ GPT-4o çš„ç©ºé—´æ„ŸçŸ¥çŸ­æ¿ã€‚\n\n---\n\n### ğŸš€ å¿…è¯»ï¼šLLM å¯¹é½ã€å®‰å…¨ä¸æ¨ç†\n\nä»Šå¤©æœ‰å‡ ç¯‡å…³äºâ€œå¦‚ä½•æ›´å¥½åœ°è®­ç»ƒå’Œä¿æŠ¤ LLMâ€çš„é«˜è´¨é‡å·¥ä½œï¼Œç‰¹åˆ«æ˜¯å¯¹ DPO çš„ç†è®ºåˆ†æå’Œ Agent æ–°å‹æ”»å‡»é¢å€¼å¾—å…³æ³¨ã€‚\n\n**1. DPO æ•°æ®ä¸­ä»€ä¹ˆæœ€é‡è¦ï¼Ÿ**\n**# Title: What Matters in Data for DPO?**\n**# Title: DPO æ•°æ®ä¸­çš„å…³é”®å› ç´ æ˜¯ä»€ä¹ˆï¼Ÿ**\n*   **æ ¸å¿ƒå‘ç°**ï¼šè¿™ç¯‡è®ºæ–‡å¯¹ç›®å‰å¤§ç«çš„ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰è¿›è¡Œäº†ç³»ç»Ÿæ€§â€œä½“æ£€â€ã€‚ä½œè€…å‘ç°ï¼Œ**â€œè¢«é€‰ä¸­ï¼ˆChosenï¼‰â€å›ç­”çš„è´¨é‡å¯¹ DPO æ€§èƒ½èµ·ä¸»å¯¼ä½œç”¨**ï¼Œè€Œâ€œè¢«æ‹’ç»ï¼ˆRejectedï¼‰â€å›ç­”çš„è´¨é‡å½±å“ç›¸å¯¹æœ‰é™ã€‚\n*   **Implication**ï¼šç†è®ºåˆ†æè¡¨æ˜ï¼Œå“åº”ä¹‹é—´çš„å¯¹æ¯”æ€§ä¸»è¦é€šè¿‡æå‡ Chosen æ ·æœ¬æ¥èµ·ä½œç”¨ã€‚è¿™æ„å‘³ç€åœ¨æ„å»ºå¯¹é½æ•°æ®é›†æ—¶ï¼Œä¸å…¶è´¹å°½å¿ƒæœºæ‰¾å„ç§èŠ±å“¨çš„è´Ÿæ ·æœ¬ï¼Œä¸å¦‚ä¸“æ³¨äºæé«˜æ­£æ ·æœ¬çš„è´¨é‡ã€‚è¿™æœ‰ç‚¹åƒ supervised fine-tuning (SFT) çš„å»¶ä¼¸ã€‚\n\n**2. Agent å®‰å…¨çš„æ–°æˆ˜åœºï¼šTOCTOU æ¼æ´**\n**# Title: Mind the Gap: Time-of-Check to Time-of-Use Vulnerabilities in LLM-Enabled Agents**\n**# Title: å°å¿ƒé—´éš™ï¼šLLM æ™ºèƒ½ä½“ä¸­çš„æ£€æŸ¥ä¸ä½¿ç”¨æ—¶é—´å·®ï¼ˆTOCTOUï¼‰æ¼æ´**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šè¿™æ˜¯**é¦–ä¸ª**é’ˆå¯¹ LLM Agent ä¸­ TOCTOUï¼ˆTime-of-Check to Time-of-Useï¼‰æ¼æ´çš„ç ”ç©¶ã€‚ç®€å•è¯´ï¼Œå½“ Agent æ£€æŸ¥ä¸€ä¸ªçŠ¶æ€ï¼ˆå¦‚æ–‡ä»¶å†…å®¹ï¼‰å’Œä½¿ç”¨å®ƒä¹‹é—´å­˜åœ¨æ—¶é—´å·®æ—¶ï¼Œæ”»å‡»è€…å¯ä»¥åˆ©ç”¨è¿™ä¸ªé—´éš™ä¿®æ”¹çŠ¶æ€ã€‚\n*   **å‘ç°**ï¼šä½œè€…æå‡ºäº† TOCTOU-Bench åŸºå‡†ï¼ŒåŒ…å« 66 ä¸ªç°å®ä»»åŠ¡ã€‚ç ”ç©¶å‘ç° Agent å¾ˆå®¹æ˜“å—åˆ°è¿™ç§â€œè°ƒåŒ…è®¡â€æ”»å‡»ï¼Œå¯¼è‡´æ¶æ„é…ç½®äº¤æ¢æˆ– Payload æ³¨å…¥ã€‚ä»–ä»¬æå‡ºçš„é˜²å¾¡æ–¹æ¡ˆèƒ½å°†æ”»å‡»çª—å£å‡å°‘ 95%ã€‚åš Agent å®‰å…¨çš„åŒå­¦å¿…çœ‹ã€‚\n\n**3. æ‰“ç ´æ¨ç†ç“¶é¢ˆï¼šé‡è§„è„šæ‰‹æ¶å¼ºåŒ–å­¦ä¹ **\n**# Title: Breaking the Exploration Bottleneck: Rubric-Scaffolded Reinforcement Learning for General LLM Reasoning**\n**# Title: æ‰“ç ´æ¢ç´¢ç“¶é¢ˆï¼šç”¨äºé€šç”¨ LLM æ¨ç†çš„é‡è§„è„šæ‰‹æ¶å¼ºåŒ–å­¦ä¹  (RuscaRL)**\n*   **æ ¸å¿ƒæ–¹æ³•**ï¼šé’ˆå¯¹ LLM åœ¨å¼ºåŒ–å­¦ä¹ æ¢ç´¢é˜¶æ®µéš¾ä»¥ç”Ÿæˆé«˜è´¨é‡æ¨ç†è·¯å¾„çš„é—®é¢˜ï¼Œæå‡º RuscaRLã€‚å®ƒå¼•å…¥äº†**æ¸…å•å¼çš„â€œé‡è§„ï¼ˆRubricsï¼‰â€**ä½œä¸ºè„šæ‰‹æ¶ã€‚\n*   **æ•ˆæœ**ï¼šåœ¨ç”Ÿæˆé˜¶æ®µï¼Œåˆ©ç”¨é‡è§„å¼•å¯¼æ¨¡å‹æ¢ç´¢ï¼›åœ¨è®­ç»ƒé˜¶æ®µï¼Œåˆ©ç”¨é‡è§„ä½œä¸º LLM-as-a-Judge çš„è¯„åˆ†ä¾æ®ã€‚Qwen2.5-7B-Instruct ç”¨äº†è¿™ä¸ªæ–¹æ³•åï¼Œåœ¨ HealthBench-500 ä¸Šåˆ†æ•°ç¿»å€ï¼Œè¶…è¶Šäº† GPT-4.1ã€‚\n\n**4. è­¦æƒ•æ¨¡å‹çš„â€œé©¬å±ç²¾â€å±æ€§**\n**# Title: BASIL: Bayesian Assessment of Sycophancy in LLMs**\n**# Title: BASILï¼šLLM è¶‹ç‚é™„åŠ¿è¡Œä¸ºçš„è´å¶æ–¯è¯„ä¼°**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šåŒºåˆ†äº†â€œç†æ€§çš„ä¿¡å¿µæ›´æ–°â€å’Œâ€œæ— è„‘çš„è¿åˆï¼ˆSycophancyï¼‰â€ã€‚ä½œè€…æå‡ºäº†ä¸€ä¸ªåŸºäºè´å¶æ–¯çš„æ¡†æ¶æ¥é‡åŒ–è¿™ç§è¡Œä¸ºã€‚ç ”ç©¶å‘ç°ï¼ŒSFT å’Œ DPO éƒ½èƒ½å‡å°‘è¿™ç§è´å¶æ–¯ä¸ä¸€è‡´æ€§ï¼Œå°¤å…¶æ˜¯ DPO æ•ˆæœæ›´å¥½ã€‚\n\n---\n\n### ğŸ¤– å¤šæ¨¡æ€ã€è§†é¢‘ä¸å…·èº«æ™ºèƒ½\n\nä»Šå¤©çš„å¤šæ¨¡æ€é¢†åŸŸéå¸¸æ´»è·ƒï¼Œä»çº¯è§†è§‰çš„ Web Agent åˆ°æœºå™¨äººæ§åˆ¶æ¨¡å‹çš„æ–°æ¶æ„ï¼Œéƒ½æœ‰ä¸å°‘äº®ç‚¹ã€‚\n\n**5. å…·èº«æ™ºèƒ½æ–°æ¶æ„ï¼šç”¨ Normalizing Flows æ›¿ä»£ Diffusion**\n**# Title: NinA: Normalizing Flows in Action. Training VLA Models with Normalizing Flows**\n**# Title: NinAï¼šè¡ŒåŠ¨ä¸­çš„å½’ä¸€åŒ–æµ â€”â€” ç”¨å½’ä¸€åŒ–æµè®­ç»ƒ VLA æ¨¡å‹**\n*   **ç—›ç‚¹**ï¼šç°åœ¨çš„è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡å‹å–œæ¬¢ç”¨ Diffusion åšåŠ¨ä½œè§£ç å™¨ï¼Œä½†æ¨ç†å¤ªæ…¢ï¼Œéš¾ä»¥æ»¡è¶³æœºå™¨äººé«˜é¢‘æ§åˆ¶çš„éœ€æ±‚ã€‚\n*   **åˆ›æ–°**ï¼šæå‡º NinAï¼Œç”¨**å½’ä¸€åŒ–æµï¼ˆNormalizing Flowsï¼‰**æ›¿ä»£ Diffusionã€‚\n*   **æ•ˆæœ**ï¼šå®ç°äº†ä¸€æ¬¡æ€§ï¼ˆone-shotï¼‰é‡‡æ ·ï¼Œæ¨ç†é€Ÿåº¦å¤§å¹…æå‡ï¼Œä¸”æ€§èƒ½ä¸ Diffusion ç›¸å½“ã€‚è¿™ä¸ºå®æ—¶æœºå™¨äººæ§åˆ¶æä¾›äº†ä¸€æ¡æ–°è·¯ã€‚\n\n**6. çº¯è§†è§‰ Web Agent**\n**# Title: WebSight: A Vision-First Architecture for Robust Web Agents**\n**# Title: WebSightï¼šä¸€ç§ç”¨äºé²æ£’ Web æ™ºèƒ½ä½“çš„è§†è§‰ä¼˜å…ˆæ¶æ„**\n*   **æ ¸å¿ƒæ€è·¯**ï¼šå®Œå…¨æŠ›å¼ƒ HTML ä»£ç æˆ– DOM æ ‘ï¼Œ**çº¯é çœ‹ï¼ˆè§†è§‰æ„ŸçŸ¥ï¼‰**æ¥æ“ä½œç½‘é¡µã€‚ä½œè€…å¾®è°ƒäº†ä¸€ä¸ª WebSight-7B æ¨¡å‹ï¼Œåœ¨ WebVoyager åŸºå‡†ä¸Šè¾¾åˆ°äº† 68% çš„æˆåŠŸç‡ï¼Œè¶…è¿‡äº† OpenAI çš„æ–¹æ¡ˆã€‚è¿™è®© Agent æ›´åƒäººç±»ç”¨æˆ·ï¼Œä¹Ÿæ›´éš¾è¢«ç½‘é¡µç»“æ„çš„å˜åŠ¨æ‰€å¹²æ‰°ã€‚\n\n**7. ä¿®å¤ GPT-4o çš„â€œç©ºé—´ç›²åŒºâ€**\n**# Title: Beyond Play and Pause: Turning GPT-4o Spatial Weakness into a Strength for In-Depth Interactive Video Learning**\n**# Title: è¶…è¶Šæ’­æ”¾ä¸æš‚åœï¼šå°† GPT-4o çš„ç©ºé—´å¼±ç‚¹è½¬åŒ–ä¸ºæ·±åº¦äº¤äº’å¼è§†é¢‘å­¦ä¹ çš„ä¼˜åŠ¿**\n*   **è¶£ç‚¹**ï¼šGPT-4o è™½ç„¶å¼ºï¼Œä½†å¯¹è§†é¢‘ä¸­å…·ä½“çš„ç©ºé—´åæ ‡ï¼ˆBounding Boxï¼‰ç†è§£å¾ˆå·®ã€‚è¿™ç¯‡æ–‡ç« æå‡ºäº† Untwist ç³»ç»Ÿï¼Œé€šè¿‡åœ¨å¸§ä¸Šç»˜åˆ¶æ ‡æ³¨ï¼ˆAnnotated Framesï¼‰è€Œä¸æ˜¯ç›´æ¥å–‚åæ ‡æ•°æ®ï¼Œå·§å¦™åœ°ç»•è¿‡äº† GPT-4o çš„çŸ­æ¿ï¼Œå®ç°äº†å¯¹è§†é¢‘ç‰¹å®šåŒºåŸŸçš„ç²¾å‡†é—®ç­”ã€‚\n\n**8. ç©ºé—´ä¿¡å·å¼•å¯¼çš„è§†é¢‘ç”Ÿæˆ**\n**# Title: SSG-Dit: A Spatial Signal Guided Framework for Controllable Video Generation**\n**# Title: SSG-Ditï¼šä¸€ç§ç”¨äºå¯æ§è§†é¢‘ç”Ÿæˆçš„ç©ºé—´ä¿¡å·å¼•å¯¼æ¡†æ¶**\n*   **æ–¹æ³•**ï¼šè§£å†³è§†é¢‘ç”Ÿæˆä¸­â€œæ–‡ä¸å¯¹ç‰ˆâ€çš„é—®é¢˜ã€‚å¼•å…¥ç©ºé—´ä¿¡å· Promptingï¼Œç»“åˆ frozen çš„ DiT ä¸»å¹²ï¼Œå®ç°äº†å¯¹è§†é¢‘ç”Ÿæˆçš„ç©ºé—´å…³ç³»è¿›è¡Œç²¾ç¡®æ§åˆ¶ã€‚\n\n---\n\n### ğŸ“š RAG ä¸ æ¶æ„ä¼˜åŒ–\n\n**9. å¤šæ¨¡æ€ RAG çš„æ–°èŒƒå¼**\n**# Title: Zero-shot Multimodal Document Retrieval via Cross-modal Question Generation**\n**# Title: åŸºäºè·¨æ¨¡æ€é—®é¢˜ç”Ÿæˆçš„é›¶æ ·æœ¬å¤šæ¨¡æ€æ–‡æ¡£æ£€ç´¢**\n*   **æ–¹æ³•**ï¼šé’ˆå¯¹åŒ…å«å›¾æ–‡çš„å¤æ‚æ–‡æ¡£æ£€ç´¢ã€‚ä¸åƒä»¥å‰é‚£æ ·åªåšå‘é‡åŒ¹é…ï¼ŒPREMIR æ¡†æ¶åˆ©ç”¨ MLLM åœ¨æ£€ç´¢å‰ç”Ÿæˆâ€œè·¨æ¨¡æ€é¢„é—®é¢˜ï¼ˆpre-questionsï¼‰â€ï¼Œå°†åŒ¹é…ç²’åº¦æ‰©å±•åˆ° token çº§åˆ«ï¼Œæ˜¾è‘—æå‡äº†è·¨åŸŸæ£€ç´¢èƒ½åŠ›ã€‚\n\n**10. Transformer çš„ä½ç½®ç¼–ç æ–°è§£**\n**# Title: CoPE: A Lightweight Complex Positional Encoding**\n**# Title: CoPEï¼šä¸€ç§è½»é‡çº§çš„å¤æ•°ä½ç½®ç¼–ç **\n*   **åˆ›æ–°**ï¼šæå‡ºç”¨å¤æ•°åµŒå…¥ï¼ˆComplex Embeddingsï¼‰æ¥æ›¿ä»£ä¼ ç»Ÿä½ç½®ç¼–ç ã€‚å®éƒ¨å­˜è¯­ä¹‰ï¼Œè™šéƒ¨å­˜ä½ç½®ã€‚ä¸ä»…è®¡ç®—é‡å°ï¼Œè€Œä¸”è§£å†³äº†é•¿åºåˆ—è¡°å‡é—®é¢˜ï¼Œæ¯” RoPE å’Œæ­£å¼¦ç¼–ç è¡¨ç°æ›´å¥½ã€‚\n\n**11. KAN ç½‘ç»œçš„ FPGA åŠ é€Ÿ**\n**# Title: Optimizing Neural Networks with Learnable Non-Linear Activation Functions via Lookup-Based FPGA Acceleration**\n**# Title: åŸºäºæŸ¥æ‰¾è¡¨ FPGA åŠ é€Ÿçš„ KAN ç½‘ç»œä¼˜åŒ–**\n*   **å…³æ³¨ç‚¹**ï¼šKolmogorov-Arnold Networks (KANs) æœ€è¿‘å¾ˆç«ï¼Œä½†è®¡ç®—å¤æ‚ã€‚è¿™ç¯‡æ–‡ç« æå‡ºäº†åŸºäº FPGA çš„æŸ¥æ‰¾è¡¨åŠ é€Ÿæ–¹æ¡ˆï¼Œèƒ½æ•ˆæ¯” CPU/GPU é«˜ä¸€ä¸‡å€ï¼Œä¸º KAN åœ¨è¾¹ç¼˜è®¾å¤‡çš„éƒ¨ç½²æ‰«æ¸…äº†éšœç¢ã€‚\n\n---\n\n### ğŸŒŸ å…¶å®ƒå€¼å¾—å…³æ³¨çš„é¢†åŸŸ\n\n*   **[é‡‘è] # Title: THEME: Enhancing Thematic Investing with Semantic Stock Representations and Temporal Dynamics**\n    *   **THEME**ï¼šåˆ©ç”¨å±‚æ¬¡å¯¹æ¯”å­¦ä¹ å¾®è°ƒ Embeddingsï¼Œä¸“é—¨ç”¨äºç†è§£é‡‘èæ–‡æœ¬ä¸­çš„ä¸»é¢˜æŠ•èµ„è¶‹åŠ¿ï¼Œä¸ä»…ä»…æ˜¯çœ‹å…³é”®è¯ï¼Œè¿˜ç»“åˆäº†è‚¡ä»·å›æŠ¥åŠ¨æ€ã€‚\n*   **[å®‡å®™å­¦] # Title: Score Matching on Large Geometric Graphs for Cosmology Generation**\n    *   **AI for Science**ï¼šç”¨åŸºäºåˆ†æ•°çš„ç”Ÿæˆæ¨¡å‹ï¼ˆScore-based generative modelï¼‰å’Œå›¾ç¥ç»ç½‘ç»œæ¥æ¨¡æ‹Ÿå®‡å®™æ˜Ÿç³»çš„å¼•åŠ›èšç±»ï¼Œæ¯”ä¼ ç»Ÿ N-body æ¨¡æ‹Ÿæ›´å¿«ã€‚\n*   **[æ•°å­¦] # Title: Error analysis for the deep Kolmogorov method**\n    *   **æ·±åº¦æ•°å­¦**ï¼šè¿™å°±æ¯”è¾ƒç¡¬æ ¸äº†ï¼Œé•¿è¾¾40é¡µçš„è®ºæ–‡ï¼Œä¸“é—¨åˆ†æ Deep Kolmogorov æ–¹æ³•åœ¨è§£çƒ­åå¾®åˆ†æ–¹ç¨‹æ—¶çš„è¯¯å·®æ”¶æ•›ç‡ã€‚\n\n---\n**ç»“è¯­ï¼š**\nä»Šå¤©çš„è®ºæ–‡åœ¨**æ•°æ®è´¨é‡ï¼ˆDPOï¼‰**å’Œ**ç³»ç»Ÿå®‰å…¨ï¼ˆAgent TOCTOUï¼‰**ä¸Šæ•²å“äº†è­¦é’Ÿï¼ŒåŒæ—¶ä¹Ÿå±•ç¤ºäº† AI åœ¨**æ‘†è„±ä¼ ç»Ÿæ¶æ„æŸç¼š**ï¼ˆå¦‚ç”¨ Flows æ›¿ Diffusionï¼Œç”¨å¤æ•°åšä½ç½®ç¼–ç ï¼‰æ–¹é¢çš„å‹ƒå‹ƒç”Ÿæœºã€‚\n\nå¸Œæœ›è¿™ä»½å¿«æŠ¥å¯¹ä½ çš„ç ”ç©¶æœ‰æ‰€å¯å‘ï¼Œæˆ‘ä»¬æ˜å¤©è§ï¼",
  "papers": [
    {
      "arxiv_id": "2508.17167v3",
      "title": "Error analysis for the deep Kolmogorov method",
      "title_zh": "æ·±åº¦ Kolmogorov æ–¹æ³•çš„è¯¯å·®åˆ†æ",
      "authors": [
        "Iulian CÃ®mpean",
        "Thang Do",
        "Lukas Gonon",
        "Arnulf Jentzen",
        "Ionel Popescu"
      ],
      "abstract": "The deep Kolmogorov method is a simple and popular deep learning based method for approximating solutions of partial differential equations (PDEs) of the Kolmogorov type. In this work we provide an error analysis for the deep Kolmogorov method for heat PDEs. Specifically, we reveal convergence with convergence rates for the overall mean square distance between the exact solution of the heat PDE and the realization function of the approximating deep neural network (DNN) associated with a stochastic optimization algorithm in terms of the size of the architecture (the depth/number of hidden layers and the width of the hidden layers) of the approximating DNN, in terms of the number of random sample points used in the loss function (the number of input-output data pairs used in the loss function), and in terms of the size of the optimization error made by the employed stochastic optimization method.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç”¨äºæ±‚è§£ Kolmogorov å‹åå¾®åˆ†æ–¹ç¨‹(PDEs)çš„ deep Kolmogorov method è¿›è¡Œäº†æ·±å…¥çš„è¯¯å·®åˆ†æï¼Œé‡ç‚¹æ¢è®¨äº†å…¶åœ¨å¤„ç†çƒ­ä¼ å¯¼åå¾®åˆ†æ–¹ç¨‹(heat PDEs)æ—¶çš„è¡¨ç°ã€‚æ–‡ç« æ­ç¤ºäº†ç²¾ç¡®è§£ä¸æ·±åº¦ç¥ç»ç½‘ç»œ(DNN)è¿‘ä¼¼å‡½æ•°ä¹‹é—´çš„æ€»ä½“å‡æ–¹è·ç¦»çš„æ”¶æ•›æ€§åŠå…¶æ”¶æ•›é€Ÿç‡ã€‚åˆ†æè¿‡ç¨‹ç»¼åˆè€ƒè™‘äº† DNN æ¶æ„çš„è§„æ¨¡ï¼ˆåŒ…æ‹¬éšè—å±‚çš„æ·±åº¦å’Œå®½åº¦ï¼‰ã€æŸå¤±å‡½æ•°ä¸­ä½¿ç”¨çš„éšæœºæ ·æœ¬ç‚¹æ•°é‡ä»¥åŠæ‰€é‡‡ç”¨çš„éšæœºä¼˜åŒ–ç®—æ³•äº§ç”Ÿçš„ä¼˜åŒ–è¯¯å·®ã€‚é€šè¿‡å»ºç«‹è¿™äº›å…³é”®å‚æ•°ä¸è¯¯å·®ä¹‹é—´çš„å®šé‡å…³ç³»ï¼Œè¯¥é¡¹å·¥ä½œä¸ºè¯„ä¼°åŸºäºæ·±åº¦å­¦ä¹ çš„åå¾®åˆ†æ–¹ç¨‹æ•°å€¼è§£æ³•çš„å‡†ç¡®æ€§å’Œå¯é æ€§æä¾›äº†é‡è¦çš„ç†è®ºä¾æ®ã€‚",
      "categories": [
        "math.NA",
        "cs.AI",
        "math.AP"
      ],
      "primary_category": "math.NA",
      "comment": "40 pages",
      "pdf_url": "https://arxiv.org/pdf/2508.17167v3",
      "published_date": "2025-08-23 23:49:01 UTC",
      "updated_date": "2025-11-23 13:47:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:34:41.989313+00:00"
    },
    {
      "arxiv_id": "2508.17160v1",
      "title": "Beyond Play and Pause: Turning GPT-4o Spatial Weakness into a Strength for In-Depth Interactive Video Learning",
      "title_zh": "è¶…è¶Šæ’­æ”¾ä¸æš‚åœï¼šåŒ– GPT-4o ç©ºé—´æ„ŸçŸ¥å¼±ç‚¹ä¸ºæ·±åº¦äº¤äº’å¼è§†é¢‘å­¦ä¹ çš„ä¼˜åŠ¿",
      "authors": [
        "Sajad Goudarzi",
        "Samaneh Zamanifard"
      ],
      "abstract": "Traditional video-based learning remains passive, offering limited opportunities for users to engage dynamically with content. While current AI-powered tools offer transcription and summarization, they lack real-time, region-specific interaction capabilities. This paper introduces Untwist, an AI-driven system that enables interactive video learning by allowing users to ask questions about the entire video or specific regions using a bounding box, receiving context-aware, multimodal responses. By integrating GPT APIs with Computer Vision techniques, Untwist extracts, processes, and structures video content to enhance comprehension. Our approach addresses GPT-4o spatial weakness by leveraging annotated frames instead of raw coordinate data, significantly improving accuracy in localizing and interpreting video content. This paper describes the system architecture, including video pre-processing and real-time interaction, and outlines how Untwist can transform passive video consumption into an interactive, AI-driven learning experience with the potential to enhance engagement and comprehension.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¼ ç»Ÿè§†é¢‘å­¦ä¹ ç¼ºä¹åŠ¨æ€äº¤äº’çš„é—®é¢˜ï¼Œå¼€å‘äº†åä¸ºUntwistçš„AIé©±åŠ¨ç³»ç»Ÿï¼Œæ—¨åœ¨é€šè¿‡å®æ—¶ã€ç‰¹å®šåŒºåŸŸçš„äº¤äº’æå‡å­¦ä¹ æ·±åº¦ã€‚ç”¨æˆ·å¯ä»¥åˆ©ç”¨å®šç•Œæ¡†(bounding box)å¯¹è§†é¢‘çš„å±€éƒ¨æˆ–å…¨å±€å†…å®¹è¿›è¡Œæé—®ï¼Œå¹¶è·å–ç»“åˆä¸Šä¸‹æ–‡çš„å¤šæ¨¡æ€å›å¤ã€‚Untwisté€šè¿‡é›†æˆGPT APIsä¸è®¡ç®—æœºè§†è§‰(Computer Vision)æŠ€æœ¯å¯¹è§†é¢‘è¿›è¡Œé¢„å¤„ç†å’Œç»“æ„åŒ–ï¼Œä»¥å¢å¼ºä¿¡æ¯æå–èƒ½åŠ›ã€‚ä¸ºäº†å…‹æœGPT-4oåœ¨ç©ºé—´ç†è§£ä¸Šçš„å¼±ç‚¹ï¼Œè¯¥ç³»ç»Ÿåˆ›æ–°æ€§åœ°åˆ©ç”¨æ ‡æ³¨å¸§(annotated frames)æ›¿ä»£åŸå§‹åæ ‡æ•°æ®ï¼Œä»è€Œå¤§å¹…æé«˜äº†è§†é¢‘å†…å®¹å®šä½ä¸è§£è¯»çš„å‡†ç¡®æ€§ã€‚è¯¥ç³»ç»Ÿçš„æ¶æ„å®ç°äº†ä»è¢«åŠ¨è§†é¢‘è§‚çœ‹å‘ä¸»åŠ¨äº¤äº’å¼å­¦ä¹ çš„è½¬å˜ï¼Œä¸ºå¢å¼ºç”¨æˆ·çš„å‚ä¸æ„Ÿå’Œç†è§£åŠ›æä¾›äº†æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.17160v1",
      "published_date": "2025-08-23 23:08:04 UTC",
      "updated_date": "2025-08-23 23:08:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:34:46.887018+00:00"
    },
    {
      "arxiv_id": "2508.17155v1",
      "title": "Mind the Gap: Time-of-Check to Time-of-Use Vulnerabilities in LLM-Enabled Agents",
      "title_zh": "Mind the Gapï¼šå¤§è¯­è¨€æ¨¡å‹é©±åŠ¨æ™ºèƒ½ä½“ä¸­çš„æ£€æŸ¥è‡³ä½¿ç”¨æ—¶é—´ï¼ˆTOCTOUï¼‰æ¼æ´",
      "authors": [
        "Derek Lilienthal",
        "Sanghyun Hong"
      ],
      "abstract": "Large Language Model (LLM)-enabled agents are rapidly emerging across a wide range of applications, but their deployment introduces vulnerabilities with security implications. While prior work has examined prompt-based attacks (e.g., prompt injection) and data-oriented threats (e.g., data exfiltration), time-of-check to time-of-use (TOCTOU) remain largely unexplored in this context. TOCTOU arises when an agent validates external state (e.g., a file or API response) that is later modified before use, enabling practical attacks such as malicious configuration swaps or payload injection. In this work, we present the first study of TOCTOU vulnerabilities in LLM-enabled agents. We introduce TOCTOU-Bench, a benchmark with 66 realistic user tasks designed to evaluate this class of vulnerabilities. As countermeasures, we adapt detection and mitigation techniques from systems security to this setting and propose prompt rewriting, state integrity monitoring, and tool-fusing. Our study highlights challenges unique to agentic workflows, where we achieve up to 25% detection accuracy using automated detection methods, a 3% decrease in vulnerable plan generation, and a 95% reduction in the attack window. When combining all three approaches, we reduce the TOCTOU vulnerabilities from an executed trajectory from 12% to 8%. Our findings open a new research direction at the intersection of AI safety and systems security.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLM)çš„æ™ºèƒ½ä½“ä¸­å°šæœªè¢«å……åˆ†ç ”ç©¶çš„ Time-of-Check to Time-of-Use (TOCTOU) æ¼æ´ï¼Œæ­¤ç±»æ¼æ´æºäºæ™ºèƒ½ä½“åœ¨éªŒè¯å¤–éƒ¨çŠ¶æ€ä¸å®é™…ä½¿ç”¨è¯¥çŠ¶æ€çš„æ—¶é—´å·®å†…ï¼Œå¤–éƒ¨çŠ¶æ€å¯èƒ½è¢«æ¶æ„ç¯¡æ”¹ã€‚ä¸ºäº†è¯„ä¼°è¿™ä¸€å®‰å…¨å¨èƒï¼Œä½œè€…æå‡ºäº†é¦–ä¸ªé’ˆå¯¹ LLM æ™ºèƒ½ä½“çš„ TOCTOU æ¼æ´ç ”ç©¶ï¼Œå¹¶å‘å¸ƒäº†åŒ…å«66ä¸ªçœŸå®ä»»åŠ¡çš„åŸºå‡†æµ‹è¯•é›† TOCTOU-Benchã€‚ç ”ç©¶å€Ÿé‰´ç³»ç»Ÿå®‰å…¨æŠ€æœ¯ï¼Œæå‡ºäº†æç¤ºé‡å†™(prompt rewriting)ã€çŠ¶æ€å®Œæ•´æ€§ç›‘æ§(state integrity monitoring)å’Œå·¥å…·èåˆ(tool-fusing)ç­‰é˜²å¾¡æ‰‹æ®µã€‚å®éªŒè¡¨æ˜ï¼Œè‡ªåŠ¨åŒ–æ£€æµ‹æ–¹æ³•å¯è¾¾åˆ°25%çš„å‡†ç¡®ç‡ï¼Œå¹¶å°†æ”»å‡»çª—å£ç¼©çŸ­äº†95%ï¼ŒåŒæ—¶ä½¿æ˜“å—æ”»å‡»çš„è®¡åˆ’ç”Ÿæˆå‡å°‘äº†3%ã€‚é€šè¿‡æ•´åˆä¸Šè¿°é˜²å¾¡æ–¹æ¡ˆï¼Œæ‰§è¡Œè½¨è¿¹ä¸­çš„æ¼æ´æ¯”ä¾‹ä»12%é™è‡³8%ï¼Œæœ‰æ•ˆæå‡äº†æ™ºèƒ½ä½“ç³»ç»Ÿçš„å®‰å…¨æ€§ã€‚è¯¥å·¥ä½œä¸º AI safety ä¸ systems security çš„äº¤å‰ç ”ç©¶é¢†åŸŸæä¾›äº†é‡è¦çš„ç†è®ºåŸºç¡€ä¸å®è·µå‚è€ƒã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Pre-print",
      "pdf_url": "https://arxiv.org/pdf/2508.17155v1",
      "published_date": "2025-08-23 22:41:49 UTC",
      "updated_date": "2025-08-23 22:41:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:35:00.783203+00:00"
    },
    {
      "arxiv_id": "2509.06968v1",
      "title": "Deep Learning-based Techniques for Integrated Sensing and Communication Systems: State-of-the-Art, Challenges, and Opportunities",
      "title_zh": "åŸºäºæ·±åº¦å­¦ä¹ çš„é€šä¿¡æ„ŸçŸ¥ä¸€ä½“åŒ–ç³»ç»ŸæŠ€æœ¯ï¼šç ”ç©¶ç°çŠ¶ã€æŒ‘æˆ˜ä¸æœºé‡",
      "authors": [
        "Murat Temiz",
        "Yongwei Zhang",
        "Yanwei Fu",
        "Chi Zhang",
        "Chenfeng Meng",
        "Orhan Kaplan",
        "Christos Masouros"
      ],
      "abstract": "This article comprehensively reviews recent developments and research on deep learning-based (DL-based) techniques for integrated sensing and communication (ISAC) systems. ISAC, which combines sensing and communication functionalities, is regarded as a key enabler for 6G and beyond networks, as many emerging applications, such as vehicular networks and industrial robotics, necessitate both sensing and communication capabilities for effective operation. A unified platform that provides both functions can reduce hardware complexity, alleviate frequency spectrum congestion, and improve energy efficiency. However, integrating these functionalities on the same hardware requires highly optimized signal processing and system design, introducing significant computational complexity when relying on conventional iterative or optimization-based techniques. As an alternative to conventional techniques, DL-based techniques offer efficient and near-optimal solutions with reduced computational complexity. Hence, such techniques are well-suited for operating under limited computational resources and low latency requirements in real-time systems. DL-based techniques can swiftly and effectively yield near-optimal solutions for a wide range of sophisticated ISAC-related tasks, including waveform design, channel estimation, sensing signal processing, data demodulation, and interference mitigation. Therefore, motivated by these advantages, recent studies have proposed various DL-based approaches for ISAC system design. After briefly introducing DL architectures and ISAC fundamentals, this survey presents a comprehensive and categorized review of state-of-the-art DL-based techniques for ISAC, highlights their key advantages and major challenges, and outlines potential directions for future research.",
      "tldr_zh": "è¯¥ç»¼è¿°å…¨é¢å›é¡¾äº†åŸºäºæ·±åº¦å­¦ä¹  (Deep Learning) æŠ€æœ¯åœ¨æ„ŸçŸ¥ä¸é€šä¿¡ä¸€ä½“åŒ– (Integrated Sensing and Communication, ISAC) ç³»ç»Ÿä¸­çš„ç ”ç©¶è¿›å±•ã€‚é’ˆå¯¹ 6G ç½‘ç»œä¸­ ISAC ä¼ ç»Ÿä¼˜åŒ–ç®—æ³•è®¡ç®—å¤æ‚åº¦è¿‡é«˜çš„é—®é¢˜ï¼Œæ·±åº¦å­¦ä¹ å‡­å€Ÿå…¶ä½å»¶è¿Ÿå’Œé«˜æ•ˆå¤„ç†èƒ½åŠ›æä¾›äº†æ¥è¿‘æœ€ä¼˜çš„è§£å†³æ–¹æ¡ˆã€‚æ–‡ç« æ·±å…¥æ¢è®¨äº†æ·±åº¦å­¦ä¹ åœ¨æ³¢å½¢è®¾è®¡ (waveform design)ã€ä¿¡é“ä¼°è®¡ (channel estimation)ã€æ„ŸçŸ¥ä¿¡å·å¤„ç†ä»¥åŠå¹²æ‰°ç¼“è§£ (interference mitigation) ç­‰å…³é”®ä»»åŠ¡ä¸­çš„åº”ç”¨ã€‚åœ¨ä»‹ç»æ·±åº¦å­¦ä¹ æ¶æ„å’Œ ISAC åŸºç¡€çŸ¥è¯†çš„åŸºç¡€ä¸Šï¼Œæœ¬æ–‡å¯¹å½“å‰æœ€å‰æ²¿çš„æŠ€æœ¯è¿›è¡Œäº†ç³»ç»Ÿåˆ†ç±»ã€‚è¯¥ç ”ç©¶è¿›ä¸€æ­¥åˆ†æäº†ç°æœ‰æŠ€æœ¯é¢ä¸´çš„ä¸»è¦æŒ‘æˆ˜ï¼Œå¹¶ä¸º ISAC ç³»ç»Ÿçš„æœªæ¥å‘å±•å’Œä¼˜åŒ–æ–¹å‘æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "35 Pages, 13 Figures, 11 Tables, corrected version of the published journal article in IEEE Open Journal of the Communications Society",
      "pdf_url": "https://arxiv.org/pdf/2509.06968v1",
      "published_date": "2025-08-23 22:27:51 UTC",
      "updated_date": "2025-08-23 22:27:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:35:05.391813+00:00"
    },
    {
      "arxiv_id": "2508.17153v1",
      "title": "Natural Language Satisfiability: Exploring the Problem Distribution and Evaluating Transformer-based Language Models",
      "title_zh": "è‡ªç„¶è¯­è¨€å¯æ»¡è¶³æ€§ï¼šæ¢ç©¶é—®é¢˜åˆ†å¸ƒä¸è¯„ä¼°åŸºäº Transformer çš„è¯­è¨€æ¨¡å‹",
      "authors": [
        "Tharindu Madusanka",
        "Ian Pratt-Hartmann",
        "Riza Batista-Navarro"
      ],
      "abstract": "Efforts to apply transformer-based language models (TLMs) to the problem of reasoning in natural language have enjoyed ever-increasing success in recent years. The most fundamental task in this area to which nearly all others can be reduced is that of determining satisfiability. However, from a logical point of view, satisfiability problems vary along various dimensions, which may affect TLMs' ability to learn how to solve them. The problem instances of satisfiability in natural language can belong to different computational complexity classes depending on the language fragment in which they are expressed. Although prior research has explored the problem of natural language satisfiability, the above-mentioned point has not been discussed adequately. Hence, we investigate how problem instances from varying computational complexity classes and having different grammatical constructs impact TLMs' ability to learn rules of inference. Furthermore, to faithfully evaluate TLMs, we conduct an empirical study to explore the distribution of satisfiability problems.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åŸºäºTransformerçš„è¯­è¨€æ¨¡å‹(Transformer-based Language Models, TLMs)åœ¨è‡ªç„¶è¯­è¨€æ»¡è¶³æ€§(Natural Language Satisfiability)è¿™ä¸€æ ¸å¿ƒæ¨ç†ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚ç ”ç©¶æŒ‡å‡ºï¼Œæ»¡è¶³æ€§é—®é¢˜ä¼šå› å…¶æ‰€å¤„çš„è®¡ç®—å¤æ‚æ€§ç±»(Computational Complexity Classes)å’Œè¯­æ³•ç»“æ„(Grammatical Constructs)çš„ä¸åŒè€Œå±•ç°å‡ºä¸åŒçš„é€»è¾‘ç‰¹æ€§ï¼Œè¿™ç›´æ¥å½±å“äº†TLMså­¦ä¹ æ¨ç†è§„åˆ™(Rules of Inference)çš„èƒ½åŠ›ã€‚ä½œè€…ç³»ç»Ÿåœ°è°ƒæŸ¥äº†è¿™äº›ç»´åº¦å¯¹æ¨¡å‹å­¦ä¹ æ•ˆæœçš„å½±å“ï¼Œå¹¶é’ˆå¯¹ä»¥å¾€ç ”ç©¶ä¸­å¯¹è®¡ç®—å¤æ‚æ€§è®¨è®ºä¸è¶³çš„ç°çŠ¶è¿›è¡Œäº†è¡¥å……ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜é€šè¿‡å®è¯åˆ†ææ¢ç´¢äº†æ»¡è¶³æ€§é—®é¢˜çš„åˆ†å¸ƒç‰¹æ€§ï¼Œæ—¨åœ¨ä¸ºTLMsçš„æ¨ç†èƒ½åŠ›æä¾›æ›´å¿ å®çš„è¯„ä¼°ã€‚è¯¥å·¥ä½œæ·±åŒ–äº†å¯¹è‡ªç„¶è¯­è¨€é€»è¾‘æ¨ç†å¤æ‚æ€§çš„ç†è§£ï¼Œå¹¶ä¸ºè¯„ä¼°å’Œæ”¹è¿›è¯­è¨€æ¨¡å‹çš„é€»è¾‘æ¨ç†ç•Œé™æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "The paper was accepted to the 62nd Association for Computational Linguistics (ACL 2024), where it won the Best Paper Award",
      "pdf_url": "https://arxiv.org/pdf/2508.17153v1",
      "published_date": "2025-08-23 22:19:16 UTC",
      "updated_date": "2025-08-23 22:19:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:35:02.582952+00:00"
    },
    {
      "arxiv_id": "2508.18317v1",
      "title": "Does Calibration Affect Human Actions?",
      "title_zh": "æ ¡å‡†æ˜¯å¦ä¼šå½±å“äººç±»è¡Œä¸ºï¼Ÿ",
      "authors": [
        "Meir Nizri",
        "Amos Azaria",
        "Chirag Gupta",
        "Noam Hazon"
      ],
      "abstract": "Calibration has been proposed as a way to enhance the reliability and adoption of machine learning classifiers. We study a particular aspect of this proposal: how does calibrating a classification model affect the decisions made by non-expert humans consuming the model's predictions? We perform a Human-Computer-Interaction (HCI) experiment to ascertain the effect of calibration on (i) trust in the model, and (ii) the correlation between decisions and predictions. We also propose further corrections to the reported calibrated scores based on Kahneman and Tversky's prospect theory from behavioral economics, and study the effect of these corrections on trust and decision-making. We find that calibration is not sufficient on its own; the prospect theory correction is crucial for increasing the correlation between human decisions and the model's predictions. While this increased correlation suggests higher trust in the model, responses to ``Do you trust the model more?\" are unaffected by the method used.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æœºå™¨å­¦ä¹ åˆ†ç±»å™¨çš„æ ¡å‡†(Calibration)å¦‚ä½•å½±å“éä¸“å®¶ç”¨æˆ·åœ¨æ¥æ”¶æ¨¡å‹é¢„æµ‹åçš„å†³ç­–è¡Œä¸ºã€‚ç ”ç©¶äººå‘˜é€šè¿‡ä¸€é¡¹äººæœºäº¤äº’(HCI)å®éªŒï¼Œé‡ç‚¹è¯„ä¼°äº†æ ¡å‡†å¯¹æ¨¡å‹ä¿¡ä»»åº¦ä»¥åŠç”¨æˆ·å†³ç­–ä¸æ¨¡å‹é¢„æµ‹ä¹‹é—´ç›¸å…³æ€§çš„å½±å“ã€‚é™¤äº†æ ‡å‡†æ ¡å‡†å¤–ï¼Œç ”ç©¶è¿˜ç»“åˆè¡Œä¸ºç»æµå­¦ä¸­çš„å‰æ™¯ç†è®º(Prospect Theory)æå‡ºäº†è¿›ä¸€æ­¥çš„åˆ†æ•°ä¿®æ­£æ–¹æ¡ˆï¼Œå¹¶ç ”ç©¶äº†è¿™äº›ä¿®æ­£å¯¹å†³ç­–è¿‡ç¨‹çš„ä½œç”¨ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä»…é æ ¡å‡†(Calibration)æœ¬èº«ä¸è¶³ä»¥æ˜¾è‘—æ”¹å˜äººç±»è¡Œä¸ºï¼Œè€Œå‰æ™¯ç†è®º(Prospect Theory)çš„ä¿®æ­£åœ¨æé«˜äººç±»å†³ç­–ä¸æ¨¡å‹é¢„æµ‹çš„ç›¸å…³æ€§æ–¹é¢èµ·ç€è‡³å…³é‡è¦çš„ä½œç”¨ã€‚å°½ç®¡ç›¸å…³æ€§çš„æå‡æš—ç¤ºäº†ç”¨æˆ·å¯¹æ¨¡å‹çš„ä¾èµ–å¢åŠ ï¼Œä½†å‚ä¸è€…åœ¨ä¸»è§‚è¯„ä»·ä¸­è¡¨è¾¾çš„ä¿¡ä»»ç¨‹åº¦å¹¶æœªå› æ ¡å‡†æ–¹æ³•çš„ä¸åŒè€Œäº§ç”Ÿæ˜¾è‘—å·®å¼‚ã€‚è¿™ä¸€å‘ç°æ­ç¤ºäº†ç®—æ³•æ€§èƒ½æŒ‡æ ‡ä¸äººç±»å¿ƒç†æ„ŸçŸ¥ä¹‹é—´çš„å¤æ‚å…³ç³»ï¼Œå¼ºè°ƒäº†åœ¨æ„å»ºäººç±»è¾…åŠ©å†³ç­–ç³»ç»Ÿæ—¶è€ƒè™‘è®¤çŸ¥åè§çš„é‡è¦æ€§ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.18317v1",
      "published_date": "2025-08-23 22:12:47 UTC",
      "updated_date": "2025-08-23 22:12:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:35:08.592385+00:00"
    },
    {
      "arxiv_id": "2508.17150v2",
      "title": "SACA: Selective Attention-Based Clustering Algorithm",
      "title_zh": "SACAï¼šåŸºäºé€‰æ‹©æ€§æ³¨æ„åŠ›çš„èšç±»ç®—æ³•",
      "authors": [
        "Meysam Shirdel Bilehsavar",
        "Razieh Ghaedi",
        "Samira Seyed Taheri",
        "Xinqi Fan",
        "Christian O'Reilly"
      ],
      "abstract": "Clustering algorithms are fundamental tools across many fields, with density-based methods offering particular advantages in identifying arbitrarily shaped clusters and handling noise. However, their effectiveness is often limited by the requirement of critical parameter tuning by users, which typically requires significant domain expertise. This paper introduces a novel density-based clustering algorithm loosely inspired by the concept of selective attention, designed to minimize reliance on parameter tuning for most applications. The proposed method computes an adaptive threshold to exclude sparsely distributed points and outliers, constructs an initial cluster framework, and subsequently reintegrates the filtered points to refine the final results. Extensive experiments on diverse benchmark datasets demonstrate the robustness, accuracy, and ease of use of the proposed approach, establishing it as a powerful alternative to conventional density-based clustering techniques.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†SACAï¼Œå³ä¸€ç§åŸºäºSelective Attentionï¼ˆé€‰æ‹©æ€§æ³¨æ„ï¼‰çš„èšç±»ç®—æ³•ï¼Œæ—¨åœ¨è§£å†³Density-based methodsï¼ˆåŸºäºå¯†åº¦çš„èšç±»æ–¹æ³•ï¼‰åœ¨å‚æ•°è°ƒèŠ‚æ–¹é¢å¯¹é¢†åŸŸçŸ¥è¯†çš„è¿‡åº¦ä¾èµ–ã€‚è¯¥æ–¹æ³•å€Ÿé‰´äº†é€‰æ‹©æ€§æ³¨æ„çš„æ¦‚å¿µï¼Œé€šè¿‡è®¡ç®—è‡ªé€‚åº”é˜ˆå€¼æ¥æœ‰æ•ˆæ’é™¤ç¨€ç–åˆ†å¸ƒçš„ç‚¹å’ŒOutliersï¼ˆç¦»ç¾¤ç‚¹ï¼‰ã€‚ç®—æ³•é¦–å…ˆæ„å»ºä¸€ä¸ªåˆå§‹çš„èšç±»æ¡†æ¶ï¼Œéšåé€šè¿‡é‡æ–°æ•´åˆå…ˆå‰è¿‡æ»¤çš„ç‚¹æ¥ç²¾ç‚¼æœ€ç»ˆç»“æœï¼Œä»è€Œæ˜¾è‘—é™ä½äº†å¯¹äººå·¥è°ƒå‚çš„ä¾èµ–ã€‚åœ¨å¤šç§åŸºå‡†æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¯æ˜ï¼ŒSACAåœ¨é²æ£’æ€§ã€å‡†ç¡®æ€§å’Œæ˜“ç”¨æ€§æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚ä½œä¸ºä¸€ç§é«˜æ•ˆä¸”æ˜“äºä½¿ç”¨çš„æ›¿ä»£æ–¹æ¡ˆï¼Œè¯¥ç®—æ³•ä¸ºå¤„ç†ä»»æ„å½¢çŠ¶èšç±»å’Œå™ªå£°æŠ‘åˆ¶æä¾›äº†å¼ºæœ‰åŠ›çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "32 pages, 14 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.17150v2",
      "published_date": "2025-08-23 22:07:01 UTC",
      "updated_date": "2025-11-28 00:14:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:35:15.289277+00:00"
    },
    {
      "arxiv_id": "2509.10469v1",
      "title": "Real-Time RAG for the Identification of Supply Chain Vulnerabilities",
      "title_zh": "ç”¨äºä¾›åº”é“¾è„†å¼±æ€§è¯†åˆ«çš„å®æ—¶ RAG",
      "authors": [
        "Jesse Ponnock",
        "Grace Kenneally",
        "Michael Robert Briggs",
        "Elinor Yeo",
        "Tyrone Patterson",
        "Nicholas Kinberg",
        "Matthew Kalinowski",
        "David Hechtman"
      ],
      "abstract": "New technologies in generative AI can enable deeper analysis into our nation's supply chains but truly informative insights require the continual updating and aggregation of massive data in a timely manner. Large Language Models (LLMs) offer unprecedented analytical opportunities however, their knowledge base is constrained to the models' last training date, rendering these capabilities unusable for organizations whose mission impacts rely on emerging and timely information. This research proposes an innovative approach to supply chain analysis by integrating emerging Retrieval-Augmented Generation (RAG) preprocessing and retrieval techniques with advanced web-scraping technologies. Our method aims to reduce latency in incorporating new information into an augmented-LLM, enabling timely analysis of supply chain disruptors. Through experimentation, this study evaluates the combinatorial effects of these techniques towards timeliness and quality trade-offs. Our results suggest that in applying RAG systems to supply chain analysis, fine-tuning the embedding retrieval model consistently provides the most significant performance gains, underscoring the critical importance of retrieval quality. Adaptive iterative retrieval, which dynamically adjusts retrieval depth based on context, further enhances performance, especially on complex supply chain queries. Conversely, fine-tuning the LLM yields limited improvements and higher resource costs, while techniques such as downward query abstraction significantly outperforms upward abstraction in practice.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨ä¾›åº”é“¾åˆ†æä¸­å› çŸ¥è¯†åº“æ›´æ–°æ»åè€Œéš¾ä»¥åº”å¯¹å®æ—¶é£é™©çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ç»“åˆå…ˆè¿›ç½‘ç»œæŠ“å–æŠ€æœ¯ä¸æ£€ç´¢å¢å¼ºç”Ÿæˆ (Retrieval-Augmented Generation, RAG) é¢„å¤„ç†å’Œæ£€ç´¢æŠ€æœ¯çš„æ–°é¢–æ¡†æ¶ã€‚è¯¥æ–¹æ³•æ—¨åœ¨é€šè¿‡æ˜¾è‘—é™ä½å°†æ–°ä¿¡æ¯æ•´åˆè‡³å¢å¼ºå‹ LLM çš„å»¶è¿Ÿï¼Œå®ç°å¯¹ä¾›åº”é“¾è„†å¼±æ€§çš„åŠæ—¶è¯†åˆ«ä¸åˆ†æã€‚å®éªŒè¯„ä¼°äº†å¤šç§æŠ€æœ¯ç»„åˆåœ¨åŠæ—¶æ€§ä¸è´¨é‡ä¹‹é—´çš„æƒè¡¡ï¼Œç»“æœè¡¨æ˜å¯¹ embedding æ£€ç´¢æ¨¡å‹è¿›è¡Œå¾®è°ƒ (Fine-tuning) å§‹ç»ˆèƒ½å¸¦æ¥æœ€æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œçªæ˜¾äº†æ£€ç´¢è´¨é‡çš„å…³é”®ä½œç”¨ã€‚æ­¤å¤–ï¼Œè‡ªé€‚åº”è¿­ä»£æ£€ç´¢ (Adaptive iterative retrieval) æŠ€æœ¯é€šè¿‡åŠ¨æ€è°ƒæ•´æ£€ç´¢æ·±åº¦ï¼Œè¿›ä¸€æ­¥å¢å¼ºäº†ç³»ç»Ÿå¤„ç†å¤æ‚ä¾›åº”é“¾æŸ¥è¯¢çš„èƒ½åŠ›ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œå¯¹ LLM æœ¬èº«è¿›è¡Œå¾®è°ƒçš„æ•ˆæœæœ‰é™ä¸”èµ„æºæˆæœ¬è¾ƒé«˜ï¼Œè€Œå‘ä¸‹æŸ¥è¯¢æŠ½è±¡ (Downward query abstraction) åœ¨å®é™…åº”ç”¨ä¸­çš„è¡¨ç°ä¼˜äºå‘ä¸ŠæŠ½è±¡ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "14 pages, 5 figures, 1 table. Approved for Public Release; Distribution Unlimited. PRS Release Number: 25-0864",
      "pdf_url": "https://arxiv.org/pdf/2509.10469v1",
      "published_date": "2025-08-23 22:06:19 UTC",
      "updated_date": "2025-08-23 22:06:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:35:22.787388+00:00"
    },
    {
      "arxiv_id": "2508.19278v1",
      "title": "Towards Production-Worthy Simulation for Autonomous Cyber Operations",
      "title_zh": "è¿ˆå‘è‡ªä¸»ç½‘ç»œè¡ŒåŠ¨çš„ç”Ÿäº§çº§ä»¿çœŸ",
      "authors": [
        "Konur Tholl",
        "Mariam El Mezouar",
        "Ranwa Al Mallah"
      ],
      "abstract": "Simulated environments have proven invaluable in Autonomous Cyber Operations (ACO) where Reinforcement Learning (RL) agents can be trained without the computational overhead of emulation. These environments must accurately represent cybersecurity scenarios while producing the necessary signals to support RL training. In this study, we present a framework where we first extend CybORG's Cage Challenge 2 environment by implementing three new actions: Patch, Isolate, and Unisolate, to better represent the capabilities available to human operators in real-world settings. We then propose a design for agent development where we modify the reward signals and the agent's feature space to enhance training performance. To validate these modifications, we train DQN and PPO agents in the updated environment. Our study demonstrates that CybORG can be extended with additional realistic functionality, while maintaining its ability to generate informative training signals for RL agents.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†é¢å‘è‡ªä¸»ç½‘ç»œæ“ä½œ(Autonomous Cyber Operations, ACO)çš„å®ç”¨åŒ–æ¨¡æ‹Ÿç¯å¢ƒï¼Œæ—¨åœ¨åˆ©ç”¨å¼ºåŒ–å­¦ä¹ (Reinforcement Learning, RL)åœ¨æ— ä»¿çœŸå¼€é”€çš„æƒ…å†µä¸‹è®­ç»ƒæ™ºèƒ½ä»£ç†ã€‚ç ”ç©¶å›¢é˜Ÿæ‰©å±•äº†CybORGçš„Cage Challenge 2ç¯å¢ƒï¼Œæ–°å¢äº†Patchã€Isolateå’ŒUnisolateä¸‰é¡¹åŠ¨ä½œï¼Œä»è€Œæ›´çœŸå®åœ°æ¨¡æ‹Ÿäººç±»æ“ä½œå‘˜åœ¨ç°å®åœºæ™¯ä¸­çš„é˜²å¾¡èƒ½åŠ›ã€‚é€šè¿‡å¯¹å¥–åŠ±ä¿¡å·(Reward Signals)å’Œç‰¹å¾ç©ºé—´(Feature Space)çš„ä¼˜åŒ–è®¾è®¡ï¼Œç ”ç©¶è¿›ä¸€æ­¥æå‡äº†ä»£ç†çš„è®­ç»ƒæ€§èƒ½ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨æ›´æ–°ç¯å¢ƒåçš„DQNå’ŒPPOä»£ç†è®­ç»ƒä¸­ï¼Œè¯¥æ¡†æ¶è¡¨ç°å‡ºè‰¯å¥½çš„æœ‰æ•ˆæ€§ã€‚è¿™é¡¹å·¥ä½œè¯æ˜äº†CybORGåœ¨æ‰©å±•ç°å®åŠŸèƒ½çš„åŒæ—¶ï¼Œä»èƒ½ä¸ºå¼ºåŒ–å­¦ä¹ ä»£ç†æä¾›é«˜è´¨é‡çš„è®­ç»ƒä¿¡å·ï¼Œä¸ºæ„å»ºç”Ÿäº§çº§çš„ç½‘ç»œå®‰å…¨æ¨¡æ‹Ÿç¯å¢ƒæä¾›äº†æ”¯æ’‘ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.19278v1",
      "published_date": "2025-08-23 20:29:25 UTC",
      "updated_date": "2025-08-23 20:29:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:35:27.595558+00:00"
    },
    {
      "arxiv_id": "2508.17128v2",
      "title": "CE-RS-SBCIT A Novel Channel Enhanced Hybrid CNN Transformer with Residual, Spatial, and Boundary-Aware Learning for Brain Tumor MRI Analysis",
      "title_zh": "CE-RS-SBCITï¼šä¸€ç§èåˆæ®‹å·®ã€ç©ºé—´åŠè¾¹ç•Œæ„ŸçŸ¥å­¦ä¹ çš„é€šé“å¢å¼ºå‹æ··åˆCNN-Transformerï¼Œç”¨äºè„‘è‚¿ç˜¤MRIåˆ†æ",
      "authors": [
        "Mirza Mumtaz Zahoor",
        "Saddam Hussain Khan"
      ],
      "abstract": "Brain tumors remain among the most lethal human diseases, where early detection and accurate classification are critical for effective diagnosis and treatment planning. Although deep learning-based computer-aided diagnostic (CADx) systems have shown remarkable progress. However, conventional convolutional neural networks (CNNs) and Transformers face persistent challenges, including high computational cost, sensitivity to minor contrast variations, structural heterogeneity, and texture inconsistencies in MRI data. Therefore, a novel hybrid framework, CE-RS-SBCIT, is introduced, integrating residual and spatial learning-based CNNs with transformer-driven modules. The proposed framework exploits local fine-grained and global contextual cues through four core innovations: (i) a smoothing and boundary-based CNN-integrated Transformer (SBCIT), (ii) tailored residual and spatial learning CNNs, (iii) a channel enhancement (CE) strategy, and (iv) a novel spatial attention mechanism. The developed SBCIT employs stem convolution and contextual interaction transformer blocks with systematic smoothing and boundary operations, enabling efficient global feature modeling. Moreover, Residual and spatial CNNs, enhanced by auxiliary transfer-learned feature maps, enrich the representation space, while the CE module amplifies discriminative channels and mitigates redundancy. Furthermore, the spatial attention mechanism selectively emphasizes subtle contrast and textural variations across tumor classes. Extensive evaluation on challenging MRI datasets from Kaggle and Figshare, encompassing glioma, meningioma, pituitary tumors, and healthy controls, demonstrates superior performance, achieving 98.30% accuracy, 98.08% sensitivity, 98.25% F1-score, and 98.43% precision.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è„‘è‚¿ç˜¤æ—©æœŸæ£€æµ‹å’Œå‡†ç¡®åˆ†ç±»çš„æŒ‘æˆ˜ï¼Œæå‡ºäº† CE-RS-SBCIT æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿ CNN å’Œ Transformer åœ¨å¤„ç† MRI æ•°æ®æ—¶é¢ä¸´çš„é«˜è®¡ç®—æˆæœ¬ã€å¯¹æ¯”åº¦æ•æ„ŸåŠç»“æ„å¼‚è´¨æ€§ç­‰é—®é¢˜ã€‚è¯¥æ¡†æ¶é€šè¿‡èåˆ Residual å’Œ Spatial å­¦ä¹ çš„ CNN ä¸ Transformer é©±åŠ¨æ¨¡å—ï¼Œæœ‰æ•ˆæ•´åˆäº†å±€éƒ¨ç»†ç²’åº¦ç‰¹å¾ä¸å…¨å±€ä¸Šä¸‹æ–‡çº¿ç´¢ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ä¸€ä¸ªåŸºäºå¹³æ»‘ä¸è¾¹ç•Œçš„é›†æˆ Transformer æ¨¡å— (SBCIT)ã€é€šé“å¢å¼º (Channel Enhancement) ç­–ç•¥ä»¥åŠä¸€ç§æ–°å‹ç©ºé—´æ³¨æ„åŠ›æœºåˆ¶ï¼Œç”¨äºå¼ºåŒ–åˆ¤åˆ«æ€§ç‰¹å¾å¹¶æ•æ‰å¾®å°çš„çº¹ç†å˜åŒ–ã€‚å®éªŒåœ¨ Kaggle å’Œ Figshare çš„ MRI æ•°æ®é›†ä¸Šæ¶µç›–äº†èƒ¶è´¨ç˜¤ã€è„‘è†œç˜¤å’Œå‚ä½“ç˜¤ç­‰å¤šç§ç±»åˆ«ï¼Œç»“æœæ˜¾ç¤ºè¯¥æ¨¡å‹è¾¾åˆ°äº† 98.30% çš„å‡†ç¡®ç‡å’Œ 98.43% çš„ç²¾ç¡®åº¦ã€‚è¯¥ç ”ç©¶è¯æ˜äº†æ··åˆæ¶æ„åœ¨åŒ»å­¦å½±åƒåˆ†æä¸­çš„ä¼˜è¶Šæ€§ï¼Œä¸ºé«˜ç²¾åº¦çš„è®¡ç®—æœºè¾…åŠ©è¯Šæ–­ç³»ç»Ÿæä¾›äº†æœ‰åŠ›æ”¯æŒã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "37 Pages, 12 Figures",
      "pdf_url": "https://arxiv.org/pdf/2508.17128v2",
      "published_date": "2025-08-23 20:09:39 UTC",
      "updated_date": "2025-08-29 04:47:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:35:28.998194+00:00"
    },
    {
      "arxiv_id": "2508.17126v1",
      "title": "Token Homogenization under Positional Bias",
      "title_zh": "ä½ç½®åç½®ä¸‹çš„ Token åŒè´¨åŒ–",
      "authors": [
        "Viacheslav Yusupov",
        "Danil Maksimov",
        "Ameliia Alaeva",
        "Tatiana Zaitceva",
        "Antipina Anna",
        "Anna Vasileva",
        "Chenlin Liu",
        "Rayuth Chheng",
        "Danil Sazanakov",
        "Andrey Chetvergov",
        "Alina Ermilova",
        "Egor Shvetsov"
      ],
      "abstract": "This paper investigates token homogenization - the convergence of token representations toward uniformity across transformer layers and its relationship to positional bias in large language models. We empirically examine whether homogenization occurs and how positional bias amplifies this effect. Through layer-wise similarity analysis and controlled experiments, we demonstrate that tokens systematically lose distinctiveness during processing, particularly when biased toward extremal positions. Our findings confirm both the existence of homogenization and its dependence on positional attention mechanisms.",
      "tldr_zh": "è¯¥ç ”ç©¶æ·±å…¥æ¢è®¨äº† Transformer æ¨¡å‹ä¸­çš„ Token Homogenization ç°è±¡ï¼Œå³ Token è¡¨ç¤ºåœ¨ç»è¿‡å¤šä¸ªå±‚å¤„ç†åè¶‹å‘äºä¸€è‡´çš„è¶‹åŠ¿ï¼Œå¹¶é‡ç‚¹åˆ†æäº†å…¶ä¸å¤§è¯­è¨€æ¨¡å‹ä¸­ Positional Bias ä¹‹é—´çš„å…³è”ã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡ Layer-wise Similarity Analysis å’Œä¸€ç³»åˆ—å—æ§å®éªŒï¼Œä»å®è¯è§’åº¦è€ƒå¯Ÿäº†åŒè´¨åŒ–çš„å‘ç”Ÿè¿‡ç¨‹ä»¥åŠä½ç½®åå·®å¯¹è¯¥æ•ˆåº”çš„æ”¾å¤§ä½œç”¨ã€‚å®éªŒè¯æ®æ˜¾ç¤ºï¼ŒToken åœ¨æ¨¡å‹å¤„ç†è¿‡ç¨‹ä¸­ä¼šç³»ç»Ÿæ€§åœ°ä¸§å¤±å…¶ç‹¬ç‰¹æ€§ï¼Œä¸”å½“æ³¨æ„åŠ›åå‘åºåˆ—çš„æç«¯ä½ç½®æ—¶ï¼Œè¿™ç§åŒè´¨åŒ–ç°è±¡å°¤ä¸ºæ˜¾è‘—ã€‚ç ”ç©¶ç»“æœä¸ä»…ç¡®è®¤äº† Token Homogenization çš„å­˜åœ¨ï¼Œè¿˜æ­ç¤ºäº†å…¶å¯¹ Positional Attention Mechanisms çš„é«˜åº¦ä¾èµ–æ€§ã€‚è¿™ä¸€å‘ç°ä¸ºç†è§£å¤§è¯­è¨€æ¨¡å‹å¦‚ä½•å¤„ç†ç©ºé—´ä¿¡æ¯ä»¥åŠè¡¨ç¤ºåç¼©çš„æˆå› æä¾›äº†é‡è¦çš„ç†è®ºä¾æ®ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.17126v1",
      "published_date": "2025-08-23 19:59:05 UTC",
      "updated_date": "2025-08-23 19:59:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:35:49.154286+00:00"
    },
    {
      "arxiv_id": "2508.18316v3",
      "title": "Evaluating Federated Learning for At-Risk Student Prediction: A Comparative Analysis of Model Complexity and Data Balancing",
      "title_zh": "é¢å‘å­¦ä¸šé£é™©å­¦ç”Ÿé¢„æµ‹çš„è”é‚¦å­¦ä¹ è¯„ä¼°ï¼šæ¨¡å‹å¤æ‚åº¦ä¸æ•°æ®å¹³è¡¡çš„å¯¹æ¯”åˆ†æ",
      "authors": [
        "Rodrigo Tertulino",
        "Ricardo Almeida"
      ],
      "abstract": "This study proposes and validates a Federated Learning (FL) framework to proactively identify at-risk students while preserving data privacy. Persistently high dropout rates in distance education remain a pressing institutional challenge. Using the large-scale OULAD dataset, we simulate a privacy-centric scenario where models are trained on early academic performance and digital engagement patterns. Our work investigates the practical trade-offs between model complexity (Logistic Regression vs. a Deep Neural Network) and the impact of local data balancing. The resulting federated model achieves strong predictive power (ROC AUC approximately 85%), demonstrating that FL is a practical and scalable solution for early-warning systems that inherently respects student data sovereignty.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è¿œç¨‹æ•™è‚²ä¸­é«˜è¾å­¦ç‡çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ä¸ªæ—¨åœ¨ä¸»åŠ¨è¯†åˆ«å­¦ä¸šé£é™©å­¦ç”Ÿï¼ˆat-risk studentsï¼‰çš„ Federated Learning (FL) æ¡†æ¶ï¼Œä»¥åœ¨ä¿æŠ¤æ•°æ®éšç§çš„å‰æä¸‹å®ç°æ—©æœŸé¢„è­¦ã€‚ç ”ç©¶åˆ©ç”¨å¤§è§„æ¨¡æ•°æ®é›† OULAD æ¨¡æ‹Ÿäº†ä»¥éšç§ä¸ºä¸­å¿ƒçš„åœºæ™¯ï¼Œé€šè¿‡åˆ†ææ—©æœŸå­¦ä¸šè¡¨ç°å’Œæ•°å­—å‚ä¸æ¨¡å¼è¿›è¡Œæ¨¡å‹è®­ç»ƒã€‚ä½œè€…æ·±å…¥æ¢è®¨äº†æ¨¡å‹å¤æ‚åº¦ï¼ˆLogistic Regression ä¸ Deep Neural Network çš„å¯¹æ¯”ï¼‰ä»¥åŠæœ¬åœ°æ•°æ®å¹³è¡¡ï¼ˆlocal data balancingï¼‰å¯¹é¢„æµ‹æ•ˆæœçš„å®é™…å½±å“ä¸æƒè¡¡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥è”é‚¦æ¨¡å‹è¾¾åˆ°äº†çº¦ 85% çš„ ROC AUCï¼Œå±•ç°å‡ºå¼ºå¤§çš„é¢„æµ‹èƒ½åŠ›ã€‚ç ”ç©¶è¯æ˜äº† Federated Learning æ˜¯æ—©æœŸé¢„è­¦ç³»ç»Ÿçš„ä¸€ç§åˆ‡å®å¯è¡Œä¸”å…·æ‰©å±•æ€§çš„è§£å†³æ–¹æ¡ˆï¼Œèƒ½å¤Ÿä»æ ¹æœ¬ä¸Šå°Šé‡å¹¶ç»´æŠ¤å­¦ç”Ÿçš„æ•°æ®ä¸»æƒï¼ˆdata sovereigntyï¼‰ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY",
        "cs.LO"
      ],
      "primary_category": "cs.LG",
      "comment": "This article is currently being prepared for submission to a scientific journal",
      "pdf_url": "https://arxiv.org/pdf/2508.18316v3",
      "published_date": "2025-08-23 19:58:16 UTC",
      "updated_date": "2025-12-12 11:36:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:35:48.855859+00:00"
    },
    {
      "arxiv_id": "2508.18315v1",
      "title": "Automated Landfill Detection Using Deep Learning: A Comparative Study of Lightweight and Custom Architectures with the AerialWaste Dataset",
      "title_zh": "åŸºäºæ·±åº¦å­¦ä¹ çš„è‡ªåŠ¨åŒ–åƒåœ¾å¡«åŸ‹åœºæ£€æµ‹ï¼šåŸºäº AerialWaste æ•°æ®é›†çš„è½»é‡çº§ä¸è‡ªå®šä¹‰æ¶æ„å¯¹æ¯”ç ”ç©¶",
      "authors": [
        "Nowshin Sharmily",
        "Rusab Sarmun",
        "Muhammad E. H. Chowdhury",
        "Mir Hamidul Hussain",
        "Saad Bin Abul Kashem",
        "Molla E Majid",
        "Amith Khandakar"
      ],
      "abstract": "Illegal landfills are posing as a hazardous threat to people all over the world. Due to the arduous nature of manually identifying the location of landfill, many landfills go unnoticed by authorities and later cause dangerous harm to people and environment. Deep learning can play a significant role in identifying these landfills while saving valuable time, manpower and resources. Despite being a burning concern, good quality publicly released datasets for illegal landfill detection are hard to find due to security concerns. However, AerialWaste Dataset is a large collection of 10434 images of Lombardy region of Italy. The images are of varying qualities, collected from three different sources: AGEA Orthophotos, WorldView-3, and Google Earth. The dataset contains professionally curated, diverse and high-quality images which makes it particularly suitable for scalable and impactful research. As we trained several models to compare results, we found complex and heavy models to be prone to overfitting and memorizing training data instead of learning patterns. Therefore, we chose lightweight simpler models which could leverage general features from the dataset. In this study, Mobilenetv2, Googlenet, Densenet, MobileVit and other lightweight deep learning models were used to train and validate the dataset as they achieved significant success with less overfitting. As we saw substantial improvement in the performance using some of these models, we combined the best performing models and came up with an ensemble model. With the help of ensemble and fusion technique, binary classification could be performed on this dataset with 92.33% accuracy, 92.67% precision, 92.33% sensitivity, 92.41% F1 score and 92.71% specificity.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹éæ³•åƒåœ¾å¡«åŸ‹åœºå¸¦æ¥çš„ç¯å¢ƒå¨èƒï¼Œåˆ©ç”¨åŒ…å«10434å¼ æ„å¤§åˆ©ä¼¦å·´ç¬¬å¤§åŒºå›¾åƒçš„å¤§è§„æ¨¡ AerialWaste Dataset æ¢è®¨äº†æ·±åº¦å­¦ä¹ åœ¨è‡ªåŠ¨åŒ–ç›‘æµ‹ä¸­çš„åº”ç”¨ã€‚ç ”ç©¶å‘ç°ï¼Œå¤æ‚çš„é‡å‹æ¨¡å‹åœ¨å¤„ç†è¯¥æ•°æ®é›†æ—¶å®¹æ˜“å‡ºç°è¿‡æ‹Ÿåˆ(overfitting)ï¼Œè€Œ Mobilenetv2ã€Googlenetã€Densenet å’Œ MobileVit ç­‰è½»é‡çº§(lightweight)æ¨¡å‹è¡¨ç°æ›´ä¸ºç¨³å¥ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°å­¦ä¹ æ•°æ®ç‰¹å¾ã€‚é€šè¿‡å¯¹æ¯”ä¸åŒæ¶æ„ï¼Œç ”ç©¶è€…é‡‡ç”¨é›†æˆ(ensemble)å’ŒèåˆæŠ€æœ¯å°†è¡¨ç°æœ€ä¼˜çš„æ¨¡å‹è¿›è¡Œç»„åˆï¼Œæ„å»ºäº†é«˜æ•ˆçš„åˆ†ç±»æ¨¡å‹ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨äºŒåˆ†ç±»ä»»åŠ¡ä¸­è¡¨ç°å“è¶Šï¼Œå®ç°äº†92.33%çš„å‡†ç¡®ç‡(accuracy)ã€92.67%çš„ç²¾ç¡®ç‡(precision)ä»¥åŠ92.41%çš„ F1 scoreã€‚è¿™ä¸€ç ”ç©¶è¯æ˜äº†è½»é‡çº§æ¨¡å‹åœ¨å¤„ç†å¤šæ ·åŒ–ã€é«˜è´¨é‡èˆªç©ºå½±åƒä¸­çš„æœ‰æ•ˆæ€§ï¼Œä¸ºèŠ‚çœäººåŠ›çš„éæ³•å¡«åŸ‹åœºå¤§è§„æ¨¡ç›‘ç®¡æä¾›äº†å¯æ‰©å±•çš„æŠ€æœ¯æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.18315v1",
      "published_date": "2025-08-23 19:52:24 UTC",
      "updated_date": "2025-08-23 19:52:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:35:51.092166+00:00"
    },
    {
      "arxiv_id": "2508.17117v2",
      "title": "PlantVillageVQA: A Visual Question Answering Dataset for Benchmarking Vision-Language Models in Plant Science",
      "title_zh": "PlantVillageVQAï¼šé¢å‘æ¤ç‰©ç§‘å­¦é¢†åŸŸè§†è§‰è¯­è¨€æ¨¡å‹åŸºå‡†è¯„ä¼°çš„è§†è§‰é—®ç­”æ•°æ®é›†",
      "authors": [
        "Syed Nazmus Sakib",
        "Nafiul Haque",
        "Mohammad Zabed Hossain",
        "Shifat E. Arman"
      ],
      "abstract": "PlantVillageVQA is a large-scale visual question answering (VQA) dataset derived from the widely used PlantVillage image corpus. It was designed to advance the development and evaluation of vision-language models for agricultural decision-making and analysis. The PlantVillageVQA dataset comprises 193,609 high-quality question-answer (QA) pairs grounded over 55,448 images spanning 14 crop species and 38 disease conditions. Questions are organised into 3 levels of cognitive complexity and 9 distinct categories. Each question category was phrased manually following expert guidance and generated via an automated two-stage pipeline: (1) template-based QA synthesis from image metadata and (2) multi-stage linguistic re-engineering. The dataset was iteratively reviewed by domain experts for scientific accuracy and relevancy. The final dataset was evaluated using three state-of-the-art models for quality assessment. Our objective remains to provide a publicly available, standardised and expert-verified database to enhance diagnostic accuracy for plant disease identifications and advance scientific research in the agricultural domain. Our dataset will be open-sourced at https://huggingface.co/datasets/SyedNazmusSakib/PlantVillageVQA.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº†PlantVillageVQAï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºPlantVillageå›¾åƒåº“çš„å¤§è§„æ¨¡è§†è§‰é—®ç­”(Visual Question Answering)æ•°æ®é›†ï¼Œæ—¨åœ¨è¯„ä¼°æ¤ç‰©ç§‘å­¦é¢†åŸŸçš„è§†è§‰è¯­è¨€æ¨¡å‹(Vision-Language Models)ã€‚è¯¥æ•°æ®é›†åŒ…å«55,448å¼ å›¾åƒï¼Œæ¶µç›–14ç§å†œä½œç‰©å’Œ38ç§ç–¾ç—…çŠ¶å†µï¼Œå…±è®¡193,609ä¸ªé«˜è´¨é‡é—®ç­”(QA)å¯¹ã€‚é—®é¢˜è¢«åˆ’åˆ†ä¸º3ä¸ªè®¤çŸ¥å¤æ‚åº¦ç­‰çº§å’Œ9ä¸ªä¸åŒç±»åˆ«ï¼Œé€šè¿‡åŸºäºæ¨¡æ¿çš„é—®ç­”åˆæˆå’Œå¤šé˜¶æ®µè¯­è¨€é‡æ„(Linguistic Re-engineering)çš„è‡ªåŠ¨åŒ–æµæ°´çº¿ç”Ÿæˆã€‚æ‰€æœ‰æ•°æ®å‡ç»è¿‡é¢†åŸŸä¸“å®¶ä¸¥æ ¼è¯„å®¡ï¼Œç¡®ä¿äº†å…¶ç§‘å­¦å‡†ç¡®æ€§ã€‚ç ”ç©¶å›¢é˜Ÿåˆ©ç”¨ä¸‰ç§æœ€å…ˆè¿›(State-of-the-art)çš„æ¨¡å‹è¿›è¡Œäº†è´¨é‡è¯„ä¼°ã€‚è¯¥æ•°æ®é›†å·²åœ¨Hugging Faceå¼€æºï¼Œæ—¨åœ¨æå‡æ¤ç‰©ç—…å®³è¯†åˆ«çš„è¯Šæ–­å‡†ç¡®æ€§å¹¶æ¨åŠ¨å†œä¸šé¢†åŸŸçš„AIç ”ç©¶ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "17 pages, 15 figures and Submittd to Nature Scientific Data",
      "pdf_url": "https://arxiv.org/pdf/2508.17117v2",
      "published_date": "2025-08-23 19:04:57 UTC",
      "updated_date": "2025-08-28 21:35:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:35:56.185330+00:00"
    },
    {
      "arxiv_id": "2508.17104v1",
      "title": "Rethinking How AI Embeds and Adapts to Human Values: Challenges and Opportunities",
      "title_zh": "é‡æ–°å®¡è§† AI åµŒå…¥ä¸é€‚é…äººç±»ä»·å€¼è§‚ï¼šæŒ‘æˆ˜ä¸æœºé‡",
      "authors": [
        "Sz-Ting Tzeng",
        "Frank Dignum"
      ],
      "abstract": "The concepts of ``human-centered AI'' and ``value-based decision'' have gained significant attention in both research and industry. However, many critical aspects remain underexplored and require further investigation. In particular, there is a need to understand how systems incorporate human values, how humans can identify these values within systems, and how to minimize the risks of harm or unintended consequences. In this paper, we highlight the need to rethink how we frame value alignment and assert that value alignment should move beyond static and singular conceptions of values. We argue that AI systems should implement long-term reasoning and remain adaptable to evolving values. Furthermore, value alignment requires more theories to address the full spectrum of human values. Since values often vary among individuals or groups, multi-agent systems provide the right framework for navigating pluralism, conflict, and inter-agent reasoning about values. We identify the challenges associated with value alignment and indicate directions for advancing value alignment research. In addition, we broadly discuss diverse perspectives of value alignment, from design methodologies to practical applications.",
      "tldr_zh": "è¯¥ç ”ç©¶é‡æ–°å®¡è§†äº†äººå·¥æ™ºèƒ½å¦‚ä½•åµŒå…¥å¹¶é€‚åº”äººç±»ä»·å€¼è§‚ï¼ŒæŒ‡å‡ºå½“å‰çš„ä»·å€¼å¯¹é½(value alignment)ç ”ç©¶äºŸéœ€è¶…è¶Šé™æ€ä¸”å•ä¸€çš„ä»·å€¼è§‚å¿µã€‚ä½œè€…ä¸»å¼ AIç³»ç»Ÿåº”å½“å…·å¤‡é•¿æœŸæ¨ç†(long-term reasoning)èƒ½åŠ›ï¼Œå¹¶èƒ½å¤Ÿä¿æŒå¯¹ä¸æ–­æ¼”å˜çš„ä»·å€¼è§‚çš„é€‚åº”æ€§ã€‚é’ˆå¯¹ä»·å€¼è§‚åœ¨ä¸åŒä¸ªä½“ä¸ç¾¤ä½“é—´çš„å·®å¼‚æ€§ï¼Œæ–‡ç« æå‡ºå¤šæ™ºèƒ½ä½“ç³»ç»Ÿ(multi-agent systems)æ˜¯å¤„ç†å¤šå…ƒä¸»ä¹‰(pluralism)ã€ä»·å€¼å†²çªåŠæ™ºèƒ½ä½“é—´ä»·å€¼æ¨ç†çš„æœ‰æ•ˆæ¡†æ¶ã€‚é€šè¿‡å¯¹è®¾è®¡æ–¹æ³•è®ºåŠå®é™…åº”ç”¨ç­‰å¤šé‡ç»´åº¦çš„å¹¿æ³›è®¨è®ºï¼Œè¯¥ç ”ç©¶è¯†åˆ«äº†ä»·å€¼å¯¹é½é¢ä¸´çš„å…³é”®æŒ‘æˆ˜ï¼Œå¹¶ä¸ºè¯¥é¢†åŸŸçš„æœªæ¥å‘å±•æ–¹å‘æä¾›äº†é‡è¦æŒ‡å¼•ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "7 pages, accepted at VALE 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.17104v1",
      "published_date": "2025-08-23 18:19:05 UTC",
      "updated_date": "2025-08-23 18:19:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:35:55.753067+00:00"
    },
    {
      "arxiv_id": "2508.17097v1",
      "title": "Two Birds with One Stone: Enhancing Uncertainty Quantification and Interpretability with Graph Functional Neural Process",
      "title_zh": "ä¸€çŸ³äºŒé¸Ÿï¼šåˆ©ç”¨å›¾æ³›å‡½ç¥ç»ç½‘ç»œè¿‡ç¨‹å¢å¼ºä¸ç¡®å®šæ€§é‡åŒ–ä¸å¯è§£é‡Šæ€§",
      "authors": [
        "Lingkai Kong",
        "Haotian Sun",
        "Yuchen Zhuang",
        "Haorui Wang",
        "Wenhao Mu",
        "Chao Zhang"
      ],
      "abstract": "Graph neural networks (GNNs) are powerful tools on graph data. However, their predictions are mis-calibrated and lack interpretability, limiting their adoption in critical applications. To address this issue, we propose a new uncertainty-aware and interpretable graph classification model that combines graph functional neural process and graph generative model. The core of our method is to assume a set of latent rationales which can be mapped to a probabilistic embedding space; the predictive distribution of the classifier is conditioned on such rationale embeddings by learning a stochastic correlation matrix. The graph generator serves to decode the graph structure of the rationales from the embedding space for model interpretability. For efficient model training, we adopt an alternating optimization procedure which mimics the well known Expectation-Maximization (EM) algorithm. The proposed method is general and can be applied to any existing GNN architecture. Extensive experiments on five graph classification datasets demonstrate that our framework outperforms state-of-the-art methods in both uncertainty quantification and GNN interpretability. We also conduct case studies to show that the decoded rationale structure can provide meaningful explanations.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å›¾ç¥ç»ç½‘ç»œ(GNNs)åœ¨é¢„æµ‹æ ¡å‡†å’Œå¯è§£é‡Šæ€§æ–¹é¢çš„ä¸è¶³ï¼Œæå‡ºäº†ä¸€ç§ç»“åˆå›¾æ³›å‡½ç¥ç»ç½‘ç»œè¿‡ç¨‹(Graph Functional Neural Process)å’Œå›¾ç”Ÿæˆæ¨¡å‹çš„åˆ›æ–°åˆ†ç±»æ¡†æ¶ã€‚è¯¥æ–¹æ³•çš„æ ¸å¿ƒåœ¨äºå‡è®¾äº†ä¸€ç»„æ˜ å°„åˆ°æ¦‚ç‡åµŒå…¥ç©ºé—´çš„æ½œåœ¨åˆç†æ€§(latent rationales)ï¼Œå¹¶é€šè¿‡å­¦ä¹ éšæœºç›¸å…³çŸ©é˜µ(stochastic correlation matrix)ä½¿åˆ†ç±»å™¨çš„é¢„æµ‹åˆ†å¸ƒä»¥è¿™äº›åˆç†æ€§åµŒå…¥ä¸ºæ¡ä»¶ã€‚åŒæ—¶ï¼Œæ¨¡å‹åˆ©ç”¨å›¾ç”Ÿæˆå™¨ä»åµŒå…¥ç©ºé—´è§£ç å‡ºåˆç†æ€§çš„å›¾ç»“æ„ï¼Œä»è€Œä¸ºæ¨¡å‹é¢„æµ‹æä¾›ç›´è§‚çš„å¯è§£é‡Šæ€§ã€‚ä¸ºäº†å®ç°é«˜æ•ˆè®­ç»ƒï¼Œç ”ç©¶é‡‡ç”¨äº†æ¨¡æ‹ŸæœŸæœ›æœ€å¤§åŒ–(EM)ç®—æ³•çš„äº¤æ›¿ä¼˜åŒ–ç¨‹åºã€‚åœ¨äº”ä¸ªå›¾åˆ†ç±»æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨ä¸ç¡®å®šæ€§é‡åŒ–(uncertainty quantification)å’ŒGNNå¯è§£é‡Šæ€§æ–¹é¢å‡ä¼˜äºç°æœ‰çš„å…ˆè¿›æ–¹æ³•ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•å…·æœ‰è‰¯å¥½çš„é€šç”¨æ€§ï¼Œèƒ½å¤Ÿåº”ç”¨äºä»»ä½•ç°æœ‰çš„GNNæ¶æ„ï¼Œå¹¶é€šè¿‡æ¡ˆä¾‹ç ”ç©¶è¯æ˜äº†ç”Ÿæˆçš„åˆç†æ€§ç»“æ„å…·æœ‰å®é™…çš„è§£é‡Šæ„ä¹‰ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "AISTATS'25",
      "pdf_url": "https://arxiv.org/pdf/2508.17097v1",
      "published_date": "2025-08-23 17:48:05 UTC",
      "updated_date": "2025-08-23 17:48:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:36:06.192087+00:00"
    },
    {
      "arxiv_id": "2509.00042v1",
      "title": "ARTPS: Depth-Enhanced Hybrid Anomaly Detection and Learnable Curiosity Score for Autonomous Rover Target Prioritization",
      "title_zh": "ARTPSï¼šåŸºäºæ·±åº¦å¢å¼ºæ··åˆå¼‚å¸¸æ£€æµ‹ä¸å¯å­¦ä¹ å¥½å¥‡å¿ƒè¯„åˆ†çš„è‡ªä¸»å·¡è§†å™¨ç›®æ ‡ä¼˜å…ˆçº§æ’åº",
      "authors": [
        "Poyraz Baydemir"
      ],
      "abstract": "We present ARTPS (Autonomous Rover Target Prioritization System), a novel hybrid AI system that combines depth estimation, anomaly detection, and learnable curiosity scoring for autonomous exploration of planetary surfaces. Our approach integrates monocular depth estimation using Vision Transformers with multi-component anomaly detection and a weighted curiosity score that balances known value, anomaly signals, depth variance, and surface roughness. The system achieves state-of-the-art performance with AUROC of 0.94, AUPRC of 0.89, and F1-Score of 0.87 on Mars rover datasets. We demonstrate significant improvements in target prioritization accuracy through ablation studies and provide comprehensive analysis of component contributions. The hybrid fusion approach reduces false positives by 23% while maintaining high detection sensitivity across diverse terrain types.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ARTPSï¼ˆAutonomous Rover Target Prioritization Systemï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ä¸ºè¡Œæ˜Ÿè¡¨é¢è‡ªä¸»æ¢æµ‹è®¾è®¡çš„æ–°å‹æ··åˆAIç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿå°†åŸºäºVision Transformersçš„å•ç›®æ·±åº¦ä¼°è®¡ï¼ˆmonocular depth estimationï¼‰ä¸å¤šç»„ä»¶å¼‚å¸¸æ£€æµ‹ï¼ˆanomaly detectionï¼‰ç›¸ç»“åˆï¼Œæ˜¾è‘—æå‡äº†ç¯å¢ƒæ„ŸçŸ¥ç²¾åº¦ã€‚å…¶æ ¸å¿ƒè´¡çŒ®åœ¨äºå¼•å…¥äº†å¯å­¦ä¹ çš„å¥½å¥‡å¿ƒè¯„åˆ†ï¼ˆlearnable curiosity scoreï¼‰ï¼Œé€šè¿‡åŠ æƒå¹³è¡¡å·²çŸ¥ä»·å€¼ã€å¼‚å¸¸ä¿¡å·ã€æ·±åº¦æ–¹å·®å’Œè¡¨é¢ç²—ç³™åº¦ï¼ˆsurface roughnessï¼‰æ¥ä¼˜åŒ–ç›®æ ‡ä¼˜å…ˆçº§ã€‚åœ¨ç«æ˜Ÿæ¢æµ‹å™¨æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œç³»ç»Ÿè¾¾åˆ°äº†SOTAæ€§èƒ½ï¼Œå…¶AUROCã€AUPRCå’ŒF1-Scoreåˆ†åˆ«é«˜è¾¾0.94ã€0.89å’Œ0.87ã€‚æ¶ˆèç ”ç©¶è¿›ä¸€æ­¥è¯æ˜ï¼Œè¿™ç§æ··åˆèåˆæ–¹æ³•åœ¨ä¿æŒé«˜æ£€æµ‹çµæ•åº¦çš„åŒæ—¶ï¼ŒæˆåŠŸå°†è¯¯æŠ¥ç‡ï¼ˆfalse positivesï¼‰é™ä½äº†23%ã€‚è¯¥ç ”ç©¶ä¸ºæé«˜è‡ªä¸»æ¢æµ‹å™¨åœ¨å¤šæ ·åŒ–åœ°å½¢ä¸‹çš„ç›®æ ‡é€‰æ‹©æ•ˆç‡å’Œç§‘å­¦æ¢æµ‹èƒ½åŠ›æä¾›äº†é‡è¦æ”¯æŒã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages, 12 figures, 4 table, autonomous exploration, Mars rover, computer vision, anomaly detection, depth estimation, curiosity-driven exploration",
      "pdf_url": "https://arxiv.org/pdf/2509.00042v1",
      "published_date": "2025-08-23 17:37:05 UTC",
      "updated_date": "2025-08-23 17:37:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:36:09.053872+00:00"
    },
    {
      "arxiv_id": "2508.17096v1",
      "title": "Convolutional Neural Networks for Accurate Measurement of Train Speed",
      "title_zh": "åŸºäºå·ç§¯ç¥ç»ç½‘ç»œçš„åˆ—è½¦é€Ÿåº¦ç²¾ç¡®æµ‹é‡",
      "authors": [
        "Haitao Tian",
        "Argyrios Zolotas",
        "Miguel Arana-Catania"
      ],
      "abstract": "In this study, we explore the use of Convolutional Neural Networks for improving train speed estimation accuracy, addressing the complex challenges of modern railway systems. We investigate three CNN architectures - single-branch 2D, single-branch 1D, and multiple-branch models - and compare them with the Adaptive Kalman Filter. We analyse their performance using simulated train operation datasets with and without Wheel Slide Protection activation. Our results reveal that CNN-based approaches, especially the multiple-branch model, demonstrate superior accuracy and robustness compared to traditional methods, particularly under challenging operational conditions. These findings highlight the potential of deep learning techniques to enhance railway safety and operational efficiency by more effectively capturing intricate patterns in complex transportation datasets.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åˆ©ç”¨å·ç§¯ç¥ç»ç½‘ç»œ(Convolutional Neural Networks, CNNs)æé«˜ç«è½¦é€Ÿåº¦æµ‹é‡å‡†ç¡®æ€§çš„æ–¹æ³•ï¼Œæ—¨åœ¨åº”å¯¹ç°ä»£é“è·¯ç³»ç»Ÿé¢ä¸´çš„å¤æ‚æŒ‘æˆ˜ã€‚ç ”ç©¶è€…è°ƒæŸ¥å¹¶å¯¹æ¯”äº†å•åˆ†æ”¯2Dã€å•åˆ†æ”¯1Dä»¥åŠå¤šåˆ†æ”¯(multiple-branch)ä¸‰ç§CNNæ¶æ„ï¼Œå¹¶å°†å…¶æ€§èƒ½ä¸ä¼ ç»Ÿçš„è‡ªé€‚åº”å¡å°”æ›¼æ»¤æ³¢(Adaptive Kalman Filter)è¿›è¡Œäº†è¯„ä¼°ã€‚å®éªŒé‡‡ç”¨äº†åŒ…å«å’ŒæœªåŒ…å«é˜²æ»‘ä¿æŠ¤(Wheel Slide Protection, WSP)æ¿€æ´»æƒ…å†µçš„æ¨¡æ‹Ÿåˆ—è½¦è¿è¡Œæ•°æ®é›†ã€‚ç»“æœè¡¨æ˜ï¼ŒåŸºäºCNNçš„æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯å¤šåˆ†æ”¯æ¨¡å‹ï¼Œåœ¨æŒ‘æˆ˜æ€§çš„æ“ä½œæ¡ä»¶ä¸‹è¡¨ç°å‡ºæ¯”ä¼ ç»Ÿæ–¹æ³•æ›´ä¼˜çš„å‡†ç¡®æ€§å’Œç¨³å¥æ€§ã€‚è¿™äº›å‘ç°çªæ˜¾äº†æ·±åº¦å­¦ä¹ æŠ€æœ¯åœ¨æ•æ‰å¤æ‚äº¤é€šæ•°æ®æ¨¡å¼æ–¹é¢çš„æ½œåŠ›ï¼Œå¯¹äºæå‡é“è·¯å®‰å…¨å’Œè¿è¥æ•ˆç‡å…·æœ‰é‡è¦æ„ä¹‰ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 12 figures, 2 tables. Proceedings of the Institution of Mechanical Engineers, Part F: Journal of Rail and Rapid Transit",
      "pdf_url": "https://arxiv.org/pdf/2508.17096v1",
      "published_date": "2025-08-23 17:35:58 UTC",
      "updated_date": "2025-08-23 17:35:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:36:11.158127+00:00"
    },
    {
      "arxiv_id": "2508.17094v3",
      "title": "PowerChain: A Verifiable Agentic AI System for Automating Distribution Grid Analyses",
      "title_zh": "PowerChainï¼šç”¨äºé…ç”µç½‘è‡ªåŠ¨åŒ–åˆ†æçš„å¯éªŒè¯æ™ºèƒ½ä½“ AI ç³»ç»Ÿ",
      "authors": [
        "Emmanuel O. Badmus",
        "Peng Sang",
        "Dimitrios Stamoulis",
        "Amritanshu Pandey"
      ],
      "abstract": "Rapid electrification and decarbonization are increasing the complexity of distribution grid (DG) operation and planning, necessitating advanced computational analyses to ensure reliability and resilience. These analyses depend on disparate workflows comprising complex models, function calls, and data pipelines that require substantial expert knowledge and remain difficult to automate. Workforce and budget constraints further limit utilities' ability to apply such analyses at scale. To address this gap, we build an agentic system PowerChain, which is capable of autonomously performing complex grid analyses. Existing agentic AI systems are typically developed in a bottom-up manner with customized context for predefined analysis tasks; therefore, they do not generalize to tasks that the agent has never seen. In comparison, to generalize to unseen DG analysis tasks, PowerChain dynamically generates structured context by leveraging supervisory signals from self-contained power systems tools (e.g., GridLAB-D) and an optimized set of expert-annotated and verified reasoning trajectories. For complex DG tasks defined in natural language, empirical results on real utility data demonstrate that PowerChain achieves up to a 144/% improvement in performance over baselines.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼€å‘äº†PowerChainï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨è‡ªåŠ¨æ‰§è¡Œå¤æ‚é…ç”µç½‘(Distribution Grid, DG)åˆ†æçš„å¯éªŒè¯Agentic AIç³»ç»Ÿã€‚é’ˆå¯¹ç”µæ°”åŒ–å’Œè„±ç¢³å¸¦æ¥çš„ç”µç½‘å¤æ‚æ€§å¢åŠ ï¼Œä»¥åŠç°æœ‰AIç³»ç»Ÿåœ¨å¤„ç†æœªçŸ¥ä»»åŠ¡æ—¶æ³›åŒ–èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ï¼ŒPowerChainæä¾›äº†ä¸€ç§è‡ªä¸»åŒ–çš„åˆ†ææ–¹æ¡ˆã€‚è¯¥ç³»ç»Ÿé€šè¿‡åˆ©ç”¨è‡ªåŒ…å«ç”µåŠ›ç³»ç»Ÿå·¥å…·ï¼ˆå¦‚GridLAB-Dï¼‰æä¾›çš„ç›‘ç£ä¿¡å·ï¼Œä»¥åŠä¸€ç»„ç»è¿‡ä¼˜åŒ–ã€ç”±ä¸“å®¶æ ‡æ³¨å¹¶éªŒè¯çš„æ¨ç†è½¨è¿¹(Reasoning Trajectories)ï¼Œèƒ½å¤ŸåŠ¨æ€ç”Ÿæˆç»“æ„åŒ–ä¸Šä¸‹æ–‡ã€‚è¿™ç§è®¾è®¡ä½¿å¾—PowerChainèƒ½å¤Ÿæ³›åŒ–åˆ°ä»æœªè§è¿‡çš„DGåˆ†æä»»åŠ¡ï¼Œå…‹æœäº†ä¼ ç»Ÿç³»ç»Ÿä¾èµ–é¢„å®šä¹‰ä»»åŠ¡ä¸Šä¸‹æ–‡çš„å±€é™æ€§ã€‚åœ¨çœŸå®ç”µåŠ›æ•°æ®ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œå¯¹äºè‡ªç„¶è¯­è¨€æè¿°çš„å¤æ‚ä»»åŠ¡ï¼ŒPowerChainç›¸æ¯”åŸºçº¿æ¨¡å‹å®ç°äº†é«˜è¾¾144%çš„æ€§èƒ½æå‡ã€‚è¯¥ç³»ç»Ÿä¸ºå…¬ç”¨äº‹ä¸šå…¬å¸åœ¨å¤§è§„æ¨¡ç”µç½‘åˆ†æä¸­å…‹æœäººåŠ›å’Œé¢„ç®—é™åˆ¶æä¾›äº†å¼ºæœ‰åŠ›çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.AI",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.17094v3",
      "published_date": "2025-08-23 17:24:46 UTC",
      "updated_date": "2025-10-21 17:54:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:36:21.453550+00:00"
    },
    {
      "arxiv_id": "2508.17092v1",
      "title": "Enhancing Knowledge Tracing through Leakage-Free and Recency-Aware Embeddings",
      "title_zh": "é€šè¿‡æ— æ³„æ¼ä¸è¿‘æ—¶æ„ŸçŸ¥åµŒå…¥å¢å¼ºçŸ¥è¯†è¿½è¸ª",
      "authors": [
        "Yahya Badran",
        "Christine Preisach"
      ],
      "abstract": "Knowledge Tracing (KT) aims to predict a student's future performance based on their sequence of interactions with learning content. Many KT models rely on knowledge concepts (KCs), which represent the skills required for each item. However, some of these models are vulnerable to label leakage, in which input data inadvertently reveal the correct answer, particularly in datasets with multiple KCs per question.\n  We propose a straightforward yet effective solution to prevent label leakage by masking ground-truth labels during input embedding construction in cases susceptible to leakage. To accomplish this, we introduce a dedicated MASK label, inspired by masked language modeling (e.g., BERT), to replace ground-truth labels. In addition, we introduce Recency Encoding, which encodes the step-wise distance between the current item and its most recent previous occurrence. This distance is important for modeling learning dynamics such as forgetting, which is a fundamental aspect of human learning, yet it is often overlooked in existing models. Recency Encoding demonstrates improved performance over traditional positional encodings on multiple KT benchmarks.\n  We show that incorporating our embeddings into KT models like DKT, DKT+, AKT, and SAKT consistently improves prediction accuracy across multiple benchmarks. The approach is both efficient and widely applicable.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹Knowledge Tracingæ¨¡å‹åœ¨å¤„ç†å¤šKCsä»»åŠ¡æ—¶æ˜“å‡ºç°çš„label leakageé—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºLeakage-Freeå’ŒRecency-Aware Embeddingsçš„æ”¹è¿›æ–¹æ¡ˆã€‚é€šè¿‡å¼•å…¥å—BERTå¯å‘çš„MASKæ ‡ç­¾ï¼Œè¯¥æ–¹æ³•åœ¨æ„é€ è¾“å…¥åµŒå…¥æ—¶é®ç›–çœŸå®æ ‡ç­¾ï¼Œæœ‰æ•ˆé˜²æ­¢äº†æ­£ç¡®ç­”æ¡ˆçš„é¢„å…ˆæ³„éœ²ã€‚æ­¤å¤–ï¼Œç ”ç©¶è®¾è®¡äº†Recency Encodingæ¥ç¼–ç é¢˜ç›®é‡å¤å‡ºç°çš„æ­¥é•¿è·ç¦»ï¼Œä»è€Œæ›´å¥½åœ°æ¨¡æ‹Ÿäº†è¢«ç°æœ‰æ¨¡å‹å¿½è§†çš„forgettingç­‰äººç±»å­¦ä¹ åŠ¨æ€ç‰¹æ€§ã€‚å®éªŒè¯æ˜ï¼Œå°†æ­¤åµŒå…¥æŠ€æœ¯é›†æˆè‡³DKTã€AKTå’ŒSAKTç­‰ä¸»æµæ¨¡å‹ä¸­ï¼Œèƒ½æ˜¾è‘—ä¸”ä¸€è‡´åœ°æå‡åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„é¢„æµ‹å‡†ç¡®ç‡ã€‚è¯¥æ–¹æ³•å…·æœ‰é«˜æ•ˆä¸”æ™®é€‚æ€§å¼ºçš„ç‰¹ç‚¹ï¼Œä¸ºå¢å¼ºçŸ¥è¯†è¿½è¸ªæ¨¡å‹çš„é²æ£’æ€§ä¸è¡¨å¾èƒ½åŠ›æä¾›äº†æœ‰åŠ›æ”¯æ’‘ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.17092v1",
      "published_date": "2025-08-23 17:13:25 UTC",
      "updated_date": "2025-08-23 17:13:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:36:20.852670+00:00"
    },
    {
      "arxiv_id": "2508.17087v1",
      "title": "Solving the Min-Max Multiple Traveling Salesmen Problem via Learning-Based Path Generation and Optimal Splitting",
      "title_zh": "åŸºäºå­¦ä¹ å‹è·¯å¾„ç”Ÿæˆä¸æœ€ä¼˜åˆ†å‰²çš„æå°æå¤§å¤šæ—…è¡Œå•†é—®é¢˜æ±‚è§£",
      "authors": [
        "Wen Wang",
        "Xiangchen Wu",
        "Liang Wang",
        "Hao Hu",
        "Xianping Tao",
        "Linghao Zhang"
      ],
      "abstract": "This study addresses the Min-Max Multiple Traveling Salesmen Problem ($m^3$-TSP), which aims to coordinate tours for multiple salesmen such that the length of the longest tour is minimized. Due to its NP-hard nature, exact solvers become impractical under the assumption that $P \\ne NP$. As a result, learning-based approaches have gained traction for their ability to rapidly generate high-quality approximate solutions. Among these, two-stage methods combine learning-based components with classical solvers, simplifying the learning objective. However, this decoupling often disrupts consistent optimization, potentially degrading solution quality. To address this issue, we propose a novel two-stage framework named \\textbf{Generate-and-Split} (GaS), which integrates reinforcement learning (RL) with an optimal splitting algorithm in a joint training process. The splitting algorithm offers near-linear scalability with respect to the number of cities and guarantees optimal splitting in Euclidean space for any given path. To facilitate the joint optimization of the RL component with the algorithm, we adopt an LSTM-enhanced model architecture to address partial observability. Extensive experiments show that the proposed GaS framework significantly outperforms existing learning-based approaches in both solution quality and transferability.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æœ€å°-æœ€å¤§å¤šæ—…è¡Œå•†é—®é¢˜ ($m^3$-TSP) å±•å¼€ï¼Œæ—¨åœ¨é€šè¿‡åè°ƒå¤šåæ—…è¡Œå•†çš„è·¯çº¿æ¥æœ€å°åŒ–æœ€é•¿è·¯å¾„çš„é•¿åº¦ã€‚ä¸ºäº†å…‹æœ NP-hard é—®é¢˜çš„æ±‚è§£éš¾åº¦ä»¥åŠç°æœ‰ä¸¤é˜¶æ®µå­¦ä¹ æ–¹æ³•ä¸­ä¼˜åŒ–ä¸ä¸€è‡´çš„ç¼ºé™·ï¼Œä½œè€…æå‡ºäº†ä¸€ç§åä¸º Generate-and-Split (GaS) çš„æ–°å‹ä¸¤é˜¶æ®µæ¡†æ¶ã€‚GaS æ¡†æ¶å°†å¼ºåŒ–å­¦ä¹  (RL) ä¸æœ€ä¼˜åˆ†å‰²ç®—æ³•é›†æˆåœ¨è”åˆè®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œåˆ©ç”¨åˆ†å‰²ç®—æ³•åœ¨æ¬§å‡ é‡Œå¾—ç©ºé—´å†…ä¸ºç»™å®šè·¯å¾„æä¾›å…·æœ‰è¿‘çº¿æ€§æ‰©å±•æ€§çš„æœ€ä¼˜åˆ†å‰²ä¿è¯ã€‚ä¸ºäº†å¢å¼º RL ç»„ä»¶ä¸ç®—æ³•çš„ååŒä¼˜åŒ–èƒ½åŠ›ï¼Œè¯¥æ–¹æ¡ˆé‡‡ç”¨äº† LSTM å¢å¼ºçš„æ¨¡å‹æ¶æ„ä»¥åº”å¯¹éƒ¨åˆ†å¯è§‚æµ‹æ€§æŒ‘æˆ˜ã€‚å¹¿æ³›çš„å®éªŒç»“æœè¡¨æ˜ï¼ŒGaS æ¡†æ¶åœ¨è§£çš„è´¨é‡å’Œè¿ç§»æ€§æ–¹é¢å‡æ˜¾è‘—ä¼˜äºç°æœ‰çš„åŸºäºå­¦ä¹ çš„æ–¹æ³•ï¼Œæœ‰æ•ˆæå‡äº†å¤§è§„æ¨¡ç»„åˆä¼˜åŒ–é—®é¢˜çš„æ±‚è§£æ•ˆç‡ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.17087v1",
      "published_date": "2025-08-23 17:00:57 UTC",
      "updated_date": "2025-08-23 17:00:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:36:37.660410+00:00"
    },
    {
      "arxiv_id": "2508.18313v1",
      "title": "ProtoEHR: Hierarchical Prototype Learning for EHR-based Healthcare Predictions",
      "title_zh": "ProtoEHRï¼šé¢å‘ç”µå­å¥åº·è®°å½•ï¼ˆEHRï¼‰åŒ»ç–—é¢„æµ‹çš„å±‚æ¬¡åŒ–åŸå‹å­¦ä¹ ",
      "authors": [
        "Zi Cai",
        "Yu Liu",
        "Zhiyao Luo",
        "Tingting Zhu"
      ],
      "abstract": "Digital healthcare systems have enabled the collection of mass healthcare data in electronic healthcare records (EHRs), allowing artificial intelligence solutions for various healthcare prediction tasks. However, existing studies often focus on isolated components of EHR data, limiting their predictive performance and interpretability. To address this gap, we propose ProtoEHR, an interpretable hierarchical prototype learning framework that fully exploits the rich, multi-level structure of EHR data to enhance healthcare predictions. More specifically, ProtoEHR models relationships within and across three hierarchical levels of EHRs: medical codes, hospital visits, and patients. We first leverage large language models to extract semantic relationships among medical codes and construct a medical knowledge graph as the knowledge source. Building on this, we design a hierarchical representation learning framework that captures contextualized representations across three levels, while incorporating prototype information within each level to capture intrinsic similarities and improve generalization. To perform a comprehensive assessment, we evaluate ProtoEHR in two public datasets on five clinically significant tasks, including prediction of mortality, prediction of readmission, prediction of length of stay, drug recommendation, and prediction of phenotype. The results demonstrate the ability of ProtoEHR to make accurate, robust, and interpretable predictions compared to baselines in the literature. Furthermore, ProtoEHR offers interpretable insights on code, visit, and patient levels to aid in healthcare prediction.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† ProtoEHRï¼Œä¸€ç§å¯è§£é‡Šçš„å±‚æ¬¡åŒ–åŸå‹å­¦ä¹  (hierarchical prototype learning) æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡æŒ–æ˜ç”µå­å¥åº·æ¡£æ¡ˆ (EHR) çš„å¤šå±‚çº§ç»“æ„æ¥å¢å¼ºåŒ»ç–—é¢„æµ‹æ€§èƒ½ã€‚è¯¥æ¡†æ¶åœ¨åŒ»ç–—ä»£ç  (medical codes)ã€åŒ»é™¢å°±è¯Š (hospital visits) å’Œæ‚£è€… (patients) ä¸‰ä¸ªç»´åº¦ä¸Šå»ºæ¨¡ï¼Œå¹¶åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ (large language models) æå–è¯­ä¹‰å…³ç³»ä»¥æ„å»ºåŒ»å­¦çŸ¥è¯†å›¾è°± (medical knowledge graph)ã€‚é€šè¿‡åœ¨å„å±‚çº§å¼•å…¥åŸå‹ä¿¡æ¯ï¼ŒProtoEHR èƒ½å¤Ÿæ•æ‰æ•°æ®é—´çš„å†…åœ¨ç›¸ä¼¼æ€§ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å’Œä¸Šä¸‹æ–‡è¡¨ç¤ºçš„å‡†ç¡®æ€§ã€‚å®éªŒåœ¨ä¸¤ä¸ªå…¬å¼€æ•°æ®é›†ä¸Šé’ˆå¯¹æ­»äº¡ç‡é¢„æµ‹ã€å†å…¥é™¢é¢„æµ‹ã€ä½é™¢æ—¶é•¿é¢„æµ‹ã€è¯ç‰©æ¨èåŠè¡¨å‹é¢„æµ‹äº”é¡¹ä¸´åºŠä»»åŠ¡è¿›è¡Œäº†è¯„ä¼°ã€‚ç»“æœè¯æ˜ï¼ŒProtoEHR åœ¨å‡†ç¡®æ€§ã€é²æ£’æ€§åŠå¯è§£é‡Šæ€§æ–¹é¢å‡ä¼˜äºç°æœ‰åŸºå‡†æ¨¡å‹ï¼Œèƒ½ä¸ºä¸´åºŠå†³ç­–æä¾›è·¨å±‚çº§çš„æ·±åº¦è§è§£ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "CIKM 2025 Full Paper",
      "pdf_url": "https://arxiv.org/pdf/2508.18313v1",
      "published_date": "2025-08-23 16:42:22 UTC",
      "updated_date": "2025-08-23 16:42:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:36:49.694244+00:00"
    },
    {
      "arxiv_id": "2508.17081v1",
      "title": "Proximal Vision Transformer: Enhancing Feature Representation through Two-Stage Manifold Geometry",
      "title_zh": "Proximal Vision Transformerï¼šåŸºäºä¸¤é˜¶æ®µæµå½¢å‡ ä½•çš„ç‰¹å¾è¡¨ç¤ºå¢å¼º",
      "authors": [
        "Haoyu Yun",
        "Hamid Krim"
      ],
      "abstract": "The Vision Transformer (ViT) architecture has become widely recognized in computer vision, leveraging its self-attention mechanism to achieve remarkable success across various tasks. Despite its strengths, ViT's optimization remains confined to modeling local relationships within individual images, limiting its ability to capture the global geometric relationships between data points. To address this limitation, this paper proposes a novel framework that integrates ViT with the proximal tools, enabling a unified geometric optimization approach to enhance feature representation and classification performance. In this framework, ViT constructs the tangent bundle of the manifold through its self-attention mechanism, where each attention head corresponds to a tangent space, offering geometric representations from diverse local perspectives. Proximal iterations are then introduced to define sections within the tangent bundle and project data from tangent spaces onto the base space, achieving global feature alignment and optimization. Experimental results confirm that the proposed method outperforms traditional ViT in terms of classification accuracy and data distribution.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Proximal Vision Transformeræ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³Vision Transformer (ViT) åœ¨æ•æ‰æ•°æ®ç‚¹é—´å…¨å±€å‡ ä½•å…³ç³»æ–¹é¢çš„å±€é™æ€§ã€‚è¯¥æ¡†æ¶åˆ©ç”¨è‡ªæ³¨æ„åŠ›æœºåˆ¶(Self-attention mechanism)æ„å»ºæµå½¢çš„åˆ‡ä¸›(Tangent bundle)ï¼Œå°†æ¯ä¸ªæ³¨æ„åŠ›å¤´(Attention head)è§†ä¸ºä¸€ä¸ªåˆ‡ç©ºé—´(Tangent space)ï¼Œä»è€Œæä¾›å¤šæ ·çš„å±€éƒ¨å‡ ä½•è¡¨ç¤ºã€‚ç ”ç©¶å¼•å…¥äº†è¿‘ç«¯è¿­ä»£(Proximal iterations)æ¥å®šä¹‰åˆ‡ä¸›å†…çš„æˆªé¢ï¼Œå¹¶å°†æ•°æ®ä»åˆ‡ç©ºé—´æŠ•å½±åˆ°åŸºç©ºé—´(Base space)ï¼Œå®ç°äº†å…¨å±€ç‰¹å¾çš„å¯¹é½ä¸ä¼˜åŒ–ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨åˆ†ç±»å‡†ç¡®ç‡å’Œæ•°æ®åˆ†å¸ƒæ–¹é¢å‡ä¼˜äºä¼ ç»Ÿçš„ViTæ¨¡å‹ï¼Œæ˜¾è‘—å¢å¼ºäº†ç‰¹å¾è¡¨ç¤ºèƒ½åŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.17081v1",
      "published_date": "2025-08-23 16:39:09 UTC",
      "updated_date": "2025-08-23 16:39:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:36:52.091445+00:00"
    },
    {
      "arxiv_id": "2508.19277v1",
      "title": "POT: Inducing Overthinking in LLMs via Black-Box Iterative Optimization",
      "title_zh": "POTï¼šé€šè¿‡é»‘ç›’è¿­ä»£ä¼˜åŒ–è¯±å¯¼å¤§è¯­è¨€æ¨¡å‹è¿‡åº¦æ€è€ƒ",
      "authors": [
        "Xinyu Li",
        "Tianjin Huang",
        "Ronghui Mu",
        "Xiaowei Huang",
        "Gaojie Jin"
      ],
      "abstract": "Recent advances in Chain-of-Thought (CoT) prompting have substantially enhanced the reasoning capabilities of large language models (LLMs), enabling sophisticated problem-solving through explicit multi-step reasoning traces. However, these enhanced reasoning processes introduce novel attack surfaces, particularly vulnerabilities to computational inefficiency through unnecessarily verbose reasoning chains that consume excessive resources without corresponding performance gains. Prior overthinking attacks typically require restrictive conditions including access to external knowledge sources for data poisoning, reliance on retrievable poisoned content, and structurally obvious templates that limit practical applicability in real-world scenarios. To address these limitations, we propose POT (Prompt-Only OverThinking), a novel black-box attack framework that employs LLM-based iterative optimization to generate covert and semantically natural adversarial prompts, eliminating dependence on external data access and model retrieval. Extensive experiments across diverse model architectures and datasets demonstrate that POT achieves superior performance compared to other methods.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨é“¾å¼æ€ç»´(Chain-of-Thought)æ¨ç†ä¸­å®¹æ˜“äº§ç”Ÿå†—é•¿æ¨ç†é“¾ä»è€Œå¯¼è‡´è®¡ç®—æ•ˆç‡ä½ä¸‹çš„æ¼æ´ï¼Œæå‡ºäº†åä¸ºPOT (Prompt-Only OverThinking) çš„æ–°å‹é»‘ç›’æ”»å‡»æ¡†æ¶ã€‚ç°æœ‰çš„è¿‡åº¦æ€è€ƒæ”»å‡»(Overthinking attacks)é€šå¸¸éœ€è¦è®¿é—®å¤–éƒ¨çŸ¥è¯†æºè¿›è¡Œæ•°æ®æŠ•æ¯’ï¼Œä¸”å¾€å¾€ä¾èµ–æ˜“äºè¢«æ£€æµ‹çš„ç»“æ„åŒ–æ¨¡æ¿ã€‚POTæ¡†æ¶é€šè¿‡åŸºäºLLMçš„è¿­ä»£ä¼˜åŒ–(Iterative Optimization)æŠ€æœ¯ï¼Œç”Ÿæˆéšè”½ä¸”è¯­ä¹‰è‡ªç„¶çš„å¯¹æŠ—æ€§æç¤ºè¯(Adversarial Prompts)ï¼Œæ¶ˆé™¤äº†å¯¹å¤–éƒ¨æ•°æ®è®¿é—®å’Œæ¨¡å‹æ£€ç´¢çš„ä¾èµ–ã€‚å®éªŒè¯æ˜ï¼ŒPOTåœ¨ä¸åŒæ¨¡å‹æ¶æ„å’Œæ•°æ®é›†ä¸Šå‡å±•ç°å‡ºä¼˜äºç°æœ‰æ–¹æ³•çš„æ”»å‡»æ€§èƒ½ï¼Œèƒ½å¤Ÿæœ‰æ•ˆè¯±å¯¼æ¨¡å‹æ‰§è¡Œè¿‡åº¦æ¨ç†ä»¥æ¶ˆè€—èµ„æºã€‚è¯¥ç ”ç©¶æ­ç¤ºäº†LLMæ¨ç†è¿‡ç¨‹ä¸­å­˜åœ¨çš„é«˜éšè”½æ€§æ•ˆç‡å®‰å…¨é£é™©ï¼Œä¸ºæœªæ¥æå‡æ¨¡å‹æ¨ç†çš„é²æ£’æ€§æä¾›äº†å‚è€ƒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.19277v1",
      "published_date": "2025-08-23 16:27:42 UTC",
      "updated_date": "2025-08-23 16:27:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:36:42.584038+00:00"
    },
    {
      "arxiv_id": "2508.17079v1",
      "title": "Zero-shot Multimodal Document Retrieval via Cross-modal Question Generation",
      "title_zh": "åŸºäºè·¨æ¨¡æ€é—®é¢˜ç”Ÿæˆçš„é›¶æ ·æœ¬å¤šæ¨¡æ€æ–‡æ¡£æ£€ç´¢",
      "authors": [
        "Yejin Choi",
        "Jaewoo Park",
        "Janghan Yoon",
        "Saejin Kim",
        "Jaehyun Jeon",
        "Youngjae Yu"
      ],
      "abstract": "Rapid advances in Multimodal Large Language Models (MLLMs) have expanded information retrieval beyond purely textual inputs, enabling retrieval from complex real world documents that combine text and visuals. However, most documents are private either owned by individuals or confined within corporate silos and current retrievers struggle when faced with unseen domains or languages. To address this gap, we introduce PREMIR, a simple yet effective framework that leverages the broad knowledge of an MLLM to generate cross modal pre questions (preQs) before retrieval. Unlike earlier multimodal retrievers that compare embeddings in a single vector space, PREMIR leverages preQs from multiple complementary modalities to expand the scope of matching to the token level. Experiments show that PREMIR achieves state of the art performance on out of distribution benchmarks, including closed domain and multilingual settings, outperforming strong baselines across all retrieval metrics. We confirm the contribution of each component through in depth ablation studies, and qualitative analyses of the generated preQs further highlight the model's robustness in real world settings.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLMs)åœ¨å¤„ç†åŒ…å«æ–‡æœ¬å’Œå›¾åƒçš„å¤æ‚æ–‡æ¡£æ£€ç´¢æ—¶ï¼Œé¢ä¸´çš„é¢†åŸŸå¤–(out-of-distribution)å’Œå¤šè¯­è¨€(multilingual)æ³›åŒ–èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ï¼Œæå‡ºäº†PREMIRæ¡†æ¶ã€‚PREMIRåˆ©ç”¨MLLMçš„å¹¿æ³›çŸ¥è¯†ï¼Œåœ¨æ£€ç´¢å‰ç”Ÿæˆè·¨æ¨¡æ€çš„é¢„è®¾é—®é¢˜(pre-questions, preQs)ï¼Œä»è€Œå°†æ£€ç´¢èŒƒå›´ä»ä¼ ç»Ÿçš„å•ä¸€å‘é‡ç©ºé—´(vector space)åµŒå…¥æ¯”å¯¹æ‰©å±•åˆ°æ›´ç»†ç²’åº¦çš„ä»¤ç‰Œçº§åˆ«(token level)åŒ¹é…ã€‚é€šè¿‡æ•´åˆæ¥è‡ªå¤šç§äº’è¡¥æ¨¡æ€çš„ä¿¡æ¯ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿæœ‰æ•ˆå¤„ç†æœªè§è¿‡çš„ç§æœ‰é¢†åŸŸæ•°æ®ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒPREMIRåœ¨å¤šé¡¹åŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº†SOTAæ€§èƒ½ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰çš„å¼ºåŸºå‡†æ¨¡å‹ã€‚æ¶ˆèå®éªŒå’Œå®šæ€§åˆ†æè¿›ä¸€æ­¥è¯å®äº†è¯¥æ¨¡å‹åœ¨ç°å®ä¸–ç•Œåœºæ™¯ä¸­çš„é²æ£’æ€§ï¼Œä¸ºå®ç°é«˜æ€§èƒ½çš„é›¶æ ·æœ¬(Zero-shot)å¤šæ¨¡æ€æ–‡æ¡£æ£€ç´¢å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.17079v1",
      "published_date": "2025-08-23 16:14:41 UTC",
      "updated_date": "2025-08-23 16:14:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:36:50.289377+00:00"
    },
    {
      "arxiv_id": "2508.17078v2",
      "title": "Linguistic Neuron Overlap Patterns to Facilitate Cross-lingual Transfer on Low-resource Languages",
      "title_zh": "æ—¨åœ¨ä¿ƒè¿›ä½èµ„æºè¯­è¨€è·¨è¯­è¨€è¿ç§»çš„è¯­è¨€ç¥ç»å…ƒé‡å æ¨¡å¼",
      "authors": [
        "Yuemei Xu",
        "Kexin Xu",
        "Jian Zhou",
        "Ling Hu",
        "Lin Gui"
      ],
      "abstract": "The current Large Language Models (LLMs) face significant challenges in improving their performance on low-resource languages and urgently need data-efficient methods without costly fine-tuning. From the perspective of language-bridge, we propose a simple yet effective method, namely BridgeX-ICL, to improve the zero-shot Cross-lingual In-Context Learning (X-ICL) for low-resource languages. Unlike existing works focusing on language-specific neurons, BridgeX-ICL explores whether sharing neurons can improve cross-lingual performance in LLMs. We construct neuron probe data from the ground-truth MUSE bilingual dictionaries, and define a subset of language overlap neurons accordingly to ensure full activation of these anchored neurons. Subsequently, we propose an HSIC-based metric to quantify LLMs' internal linguistic spectrum based on overlapping neurons, guiding optimal bridge selection. The experiments conducted on 4 cross-lingual tasks and 15 language pairs from 7 diverse families, covering both high-low and moderate-low pairs, validate the effectiveness of BridgeX-ICL and offer empirical insights into the underlying multilingual mechanisms of LLMs. The code is publicly available at https://github.com/xuyuemei/BridgeX-ICL.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ä½èµ„æºè¯­è¨€ä¸Šé¢ä¸´çš„æ€§èƒ½æŒ‘æˆ˜ï¼Œæå‡ºäº† BridgeX-ICL æ–¹æ³•ï¼Œæ—¨åœ¨é€šè¿‡è¯­è¨€æ¡¥æ¢ï¼ˆlanguage-bridgeï¼‰å¢å¼ºé›¶æ ·æœ¬è·¨è¯­è¨€ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆCross-lingual In-Context Learning, X-ICLï¼‰ã€‚ä¸åŒäºä»¥å¾€å…³æ³¨è¯­è¨€ç‰¹å®šç¥ç»å…ƒçš„ç ”ç©¶ï¼Œè¯¥æ–¹æ³•æ¢ç´¢äº†å…±äº«ç¥ç»å…ƒå¦‚ä½•ä¿ƒè¿›è·¨è¯­è¨€è¿ç§»ï¼Œå¹¶åˆ©ç”¨ MUSE åŒè¯­è¯å…¸è¯†åˆ«è¯­è¨€é‡å ç¥ç»å…ƒï¼ˆlanguage overlap neuronsï¼‰ã€‚ç ”ç©¶è¿˜æå‡ºäº†ä¸€ç§åŸºäº HSIC-based metric çš„åº¦é‡æ ‡å‡†ï¼Œé€šè¿‡é‡å ç¥ç»å…ƒé‡åŒ–æ¨¡å‹å†…éƒ¨çš„è¯­è¨€é¢‘è°±ï¼Œä»è€ŒæŒ‡å¯¼æœ€ä¼˜æ¡¥æ¢è¯­è¨€çš„é€‰æ‹©ã€‚åœ¨æ¶µç›– 7 ä¸ªè¯­ç³»çš„ 15 ä¸ªè¯­è¨€å¯¹å’Œ 4 é¡¹è·¨è¯­è¨€ä»»åŠ¡ä¸Šçš„å®éªŒè¯æ˜ï¼ŒBridgeX-ICL èƒ½åœ¨æ— éœ€å¾®è°ƒçš„æƒ…å†µä¸‹æ˜¾è‘—æå‡ä½èµ„æºè¯­è¨€çš„å¤„ç†èƒ½åŠ›ã€‚è¯¥é¡¹å·¥ä½œä¸ä»…éªŒè¯äº†æ‰€ææ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œè¿˜ä¸ºå¤§è¯­è¨€æ¨¡å‹åº•å±‚çš„å¤šè¯­è¨€æœºåˆ¶æä¾›äº†æ·±åˆ»çš„å®è¯è§è§£ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by EMNLP 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.17078v2",
      "published_date": "2025-08-23 16:13:57 UTC",
      "updated_date": "2025-09-23 14:02:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:37:11.190204+00:00"
    },
    {
      "arxiv_id": "2508.18312v3",
      "title": "What Matters in Data for DPO?",
      "title_zh": "DPO åå¥½æ•°æ®ä¸­å“ªäº›å› ç´ è‡³å…³é‡è¦ï¼Ÿ",
      "authors": [
        "Yu Pan",
        "Zhongze Cai",
        "Guanting Chen",
        "Huaiyang Zhong",
        "Chonghuan Wang"
      ],
      "abstract": "Direct Preference Optimization (DPO) has emerged as a simple and effective approach for aligning large language models (LLMs) with human preferences, bypassing the need for a learned reward model. Despite its growing adoption, a fundamental question remains open: what characteristics of preference data are most critical for DPO performance? In this work, we provide a systematic study of how preference data distribution influences DPO, from both theoretical and empirical perspectives. We show that the quality of chosen responses plays a dominant role in optimizing the DPO objective, while the quality of rejected responses may have relatively limited impact. Our theoretical analysis characterizes the optimal response distribution under DPO and reveals how contrastiveness between responses helps primarily by improving the chosen samples. We further study an online DPO setting and show it effectively reduces to supervised fine-tuning on the chosen responses. Extensive experiments across diverse tasks confirm our findings: improving the quality of chosen responses consistently boosts performance regardless of the quality of the rejected responses. We also investigate the benefit of mixing the on-policy data. Our results interpret the mechanism behind some widely adopted strategies and offer practical insights for constructing high-impact preference datasets for LLM alignment.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é’ˆå¯¹ Direct Preference Optimization (DPO) è¿™ä¸€å¤§è¯­è¨€æ¨¡å‹å¯¹é½æŠ€æœ¯ï¼Œç³»ç»Ÿåœ°æ¢è®¨äº†åå¥½æ•°æ®çš„åˆ†å¸ƒç‰¹å¾å¦‚ä½•å½±å“æ¨¡å‹æ€§èƒ½ã€‚é€šè¿‡ç†è®ºåˆ†æå’Œå®è¯ç ”ç©¶ï¼Œä½œè€…æ­ç¤ºäº† Chosen æ ·æœ¬çš„è´¨é‡åœ¨ DPO ä¼˜åŒ–ä¸­èµ·ç€ä¸»å¯¼ä½œç”¨ï¼Œè€Œ Rejected æ ·æœ¬è´¨é‡çš„å½±å“åˆ™ç›¸å¯¹æœ‰é™ã€‚ç†è®ºåˆ†æè¿›ä¸€æ­¥é˜æ˜äº†æ ·æœ¬é—´çš„å¯¹æ¯”æ€§ (Contrastiveness) ä¸»è¦é€šè¿‡æ”¹å–„å¯¹ Chosen æ ·æœ¬çš„å­¦ä¹ æ¥æå‡æ•ˆæœï¼Œè€Œåœ¨ Online DPO è®¾ç½®ä¸‹ï¼Œè¯¥è¿‡ç¨‹åœ¨å®è´¨ä¸Šç­‰åŒäºå¯¹ Chosen å“åº”çš„ç›‘ç£å¾®è°ƒ (Supervised Fine-Tuning)ã€‚è·¨å¤šé¡¹ä»»åŠ¡çš„å¹¿æ³›å®éªŒè¯å®ï¼ŒæŒç»­æå‡ Chosen æ ·æœ¬è´¨é‡æ˜¯å¢å¼ºæ€§èƒ½çš„å…³é”®ï¼Œæ— è®º Rejected æ ·æœ¬çš„æ°´å¹³å¦‚ä½•ã€‚è¯¥ç ”ç©¶è¿˜æ¢è®¨äº†æ··åˆ On-policy æ•°æ®çš„ç›Šå¤„ï¼Œä¸ä»…è§£é‡Šäº†ç°æœ‰ç­–ç•¥èƒŒåçš„æœºåˆ¶ï¼Œè¿˜ä¸ºæ„å»ºé«˜æ•ˆçš„ LLM å¯¹é½åå¥½æ•°æ®é›†æä¾›äº†æå…·ä»·å€¼çš„å®è·µè§è§£ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.18312v3",
      "published_date": "2025-08-23 16:00:30 UTC",
      "updated_date": "2025-11-07 15:28:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:37:03.091656+00:00"
    },
    {
      "arxiv_id": "2508.17069v1",
      "title": "Optimizing Neural Networks with Learnable Non-Linear Activation Functions via Lookup-Based FPGA Acceleration",
      "title_zh": "åŸºäºæŸ¥æ‰¾è¡¨ FPGA åŠ é€Ÿçš„å…·æœ‰å¯å­¦ä¹ éçº¿æ€§æ¿€æ´»å‡½æ•°çš„ç¥ç»ç½‘ç»œä¼˜åŒ–",
      "authors": [
        "Mengyuan Yin",
        "Benjamin Chen Ming Choong",
        "Chuping Qu",
        "Rick Siow Mong Goh",
        "Weng-Fai Wong",
        "Tao Luo"
      ],
      "abstract": "Learned activation functions in models like Kolmogorov-Arnold Networks (KANs) outperform fixed-activation architectures in terms of accuracy and interpretability; however, their computational complexity poses critical challenges for energy-constrained edge AI deployments. Conventional CPUs/GPUs incur prohibitive latency and power costs when evaluating higher order activations, limiting deployability under ultra-tight energy budgets. We address this via a reconfigurable lookup architecture with edge FPGAs. By coupling fine-grained quantization with adaptive lookup tables, our design minimizes energy-intensive arithmetic operations while preserving activation fidelity. FPGA reconfigurability enables dynamic hardware specialization for learned functions, a key advantage for edge systems that require post-deployment adaptability. Evaluations using KANs - where unique activation functions play a critical role - demonstrate that our FPGA-based design achieves superior computational speed and over $10^4$ times higher energy efficiency compared to edge CPUs and GPUs, while maintaining matching accuracy and minimal footprint overhead. This breakthrough positions our approach as a practical enabler for energy-critical edge AI, where computational intensity and power constraints traditionally preclude the use of adaptive activation networks.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Kolmogorov-Arnold Networks (KANs) ç­‰æ¨¡å‹ä¸­å¯å­¦ä¹ æ¿€æ´»å‡½æ•°å¸¦æ¥çš„è®¡ç®—å¤æ‚æ€§é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºå¯é‡æ„æŸ¥æ‰¾è¡¨ (Lookup Table) æ¶æ„çš„è¾¹ç¼˜ FPGA åŠ é€Ÿæ–¹æ¡ˆã€‚è¯¥è®¾è®¡é€šè¿‡ç»“åˆç»†ç²’åº¦é‡åŒ– (Fine-grained Quantization) ä¸è‡ªé€‚åº”æŸ¥æ‰¾è¡¨ï¼Œåœ¨æœ€å¤§é™åº¦å‡å°‘é«˜èƒ½è€—ç®—æœ¯è¿ç®—çš„åŒæ—¶ï¼Œæœ‰æ•ˆä¿æŒäº†æ¿€æ´»å‡½æ•°çš„ä¿çœŸåº¦ã€‚åˆ©ç”¨ FPGA çš„å¯é‡æ„ç‰¹æ€§ï¼Œè¯¥æ¶æ„èƒ½å¤Ÿå®ç°é’ˆå¯¹å­¦ä¹ å‡½æ•°çš„åŠ¨æ€ç¡¬ä»¶ä¸“ä¸šåŒ–ï¼Œä»è€Œæ»¡è¶³è¾¹ç¼˜ç³»ç»Ÿåœ¨éƒ¨ç½²åå¯¹ä»»åŠ¡çš„é€‚åº”æ€§éœ€æ±‚ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨ KANs æ¨¡å‹ä¸Šçš„è¯„ä¼°è¡¨æ˜è¯¥è®¾è®¡ç›¸æ¯”è¾¹ç¼˜ CPU å’Œ GPU å®ç°äº†æ›´å¿«çš„è®¡ç®—é€Ÿåº¦ä»¥åŠè¶…è¿‡ $10^4$ å€çš„èƒ½æ•ˆæå‡ã€‚åœ¨ç»´æŒé«˜ç²¾åº¦å’Œæå°é¢ç§¯å¼€é”€çš„å‰æä¸‹ï¼Œè¯¥æ–¹æ³•ä¸ºåœ¨èƒ½é‡å—é™çš„è¾¹ç¼˜ AI (Edge AI) ç¯å¢ƒä¸­éƒ¨ç½²é«˜å¼ºåº¦è‡ªé€‚åº”æ¿€æ´»ç½‘ç»œæä¾›äº†åˆ‡å®å¯è¡Œçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.17069v1",
      "published_date": "2025-08-23 15:51:14 UTC",
      "updated_date": "2025-08-23 15:51:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:37:10.498740+00:00"
    },
    {
      "arxiv_id": "2508.17062v1",
      "title": "SSG-Dit: A Spatial Signal Guided Framework for Controllable Video Generation",
      "title_zh": "SSG-Ditï¼šä¸€ç§ç”¨äºå¯æ§è§†é¢‘ç”Ÿæˆçš„ç©ºé—´ä¿¡å·å¼•å¯¼æ¡†æ¶",
      "authors": [
        "Peng Hu",
        "Yu Gu",
        "Liang Luo",
        "Fuji Ren"
      ],
      "abstract": "Controllable video generation aims to synthesize video content that aligns precisely with user-provided conditions, such as text descriptions and initial images. However, a significant challenge persists in this domain: existing models often struggle to maintain strong semantic consistency, frequently generating videos that deviate from the nuanced details specified in the prompts. To address this issue, we propose SSG-DiT (Spatial Signal Guided Diffusion Transformer), a novel and efficient framework for high-fidelity controllable video generation. Our approach introduces a decoupled two-stage process. The first stage, Spatial Signal Prompting, generates a spatially aware visual prompt by leveraging the rich internal representations of a pre-trained multi-modal model. This prompt, combined with the original text, forms a joint condition that is then injected into a frozen video DiT backbone via our lightweight and parameter-efficient SSG-Adapter. This unique design, featuring a dual-branch attention mechanism, allows the model to simultaneously harness its powerful generative priors while being precisely steered by external spatial signals. Extensive experiments demonstrate that SSG-DiT achieves state-of-the-art performance, outperforming existing models on multiple key metrics in the VBench benchmark, particularly in spatial relationship control and overall consistency.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¯æ§è§†é¢‘ç”Ÿæˆ(Controllable video generation)ä¸­è¯­ä¹‰ä¸€è‡´æ€§è¾ƒå·®ã€ç”Ÿæˆçš„è§†é¢‘å†…å®¹æ˜“åç¦»æç¤ºè¯ç»†èŠ‚çš„é—®é¢˜ï¼Œæå‡ºäº†åä¸ºSSG-DiT (Spatial Signal Guided Diffusion Transformer)çš„åˆ›æ–°æ¡†æ¶ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†ä¸€ä¸ªè§£è€¦çš„ä¸¤é˜¶æ®µæµç¨‹ï¼Œç¬¬ä¸€é˜¶æ®µé€šè¿‡Spatial Signal Promptingåˆ©ç”¨é¢„è®­ç»ƒå¤šæ¨¡æ€æ¨¡å‹çš„å†…éƒ¨è¡¨ç¤ºç”Ÿæˆå…·æœ‰ç©ºé—´æ„ŸçŸ¥çš„è§†è§‰æç¤ºã€‚éšåï¼Œåˆ©ç”¨è½»é‡åŒ–ä¸”å‚æ•°é«˜æ•ˆçš„SSG-Adapterå°†è¯¥æç¤ºä¸åŸå§‹æ–‡æœ¬ç»“åˆç”Ÿæˆçš„è”åˆæ¡ä»¶æ³¨å…¥åˆ°å†»ç»“çš„è§†é¢‘DiTéª¨å¹²ç½‘ç»œä¸­ã€‚å…¶ç‹¬ç‰¹çš„è®¾è®¡åŒ…å«ä¸€ä¸ªåŒåˆ†æ”¯æ³¨æ„åŠ›æœºåˆ¶(dual-branch attention mechanism)ï¼Œç¡®ä¿æ¨¡å‹åœ¨åˆ©ç”¨å¼ºå¤§ç”Ÿæˆå…ˆéªŒçš„åŒæ—¶ï¼Œèƒ½å—åˆ°å¤–éƒ¨ç©ºé—´ä¿¡å·çš„ç²¾ç¡®å¼•å¯¼ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSSG-DiTåœ¨VBenchåŸºå‡†æµ‹è¯•çš„ç©ºé—´å…³ç³»æ§åˆ¶å’Œæ•´ä½“ä¸€è‡´æ€§ç­‰å¤šé¡¹å…³é”®æŒ‡æ ‡ä¸Šä¼˜äºç°æœ‰æ¨¡å‹ï¼Œè¾¾åˆ°äº†å½“å‰æœ€å…ˆè¿›çš„State-of-the-artæ€§èƒ½ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.17062v1",
      "published_date": "2025-08-23 15:30:17 UTC",
      "updated_date": "2025-08-23 15:30:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:37:11.290841+00:00"
    },
    {
      "arxiv_id": "2508.17056v1",
      "title": "TabResFlow: A Normalizing Spline Flow Model for Probabilistic Univariate Tabular Regression",
      "title_zh": "TabResFlowï¼šé¢å‘æ¦‚ç‡å•å˜é‡è¡¨æ ¼å›å½’çš„å½’ä¸€åŒ–æ ·æ¡æµæ¨¡å‹",
      "authors": [
        "Kiran Madhusudhanan",
        "Vijaya Krishna Yalavarthi",
        "Jonas Sonntag",
        "Maximilian Stubbemann",
        "Lars Schmidt-Thieme"
      ],
      "abstract": "Tabular regression is a well-studied problem with numerous industrial applications, yet most existing approaches focus on point estimation, often leading to overconfident predictions. This issue is particularly critical in industrial automation, where trustworthy decision-making is essential. Probabilistic regression models address this challenge by modeling prediction uncertainty. However, many conventional methods assume a fixed-shape distribution (typically Gaussian), and resort to estimating distribution parameters. This assumption is often restrictive, as real-world target distributions can be highly complex. To overcome this limitation, we introduce TabResFlow, a Normalizing Spline Flow model designed specifically for univariate tabular regression, where commonly used simple flow networks like RealNVP and Masked Autoregressive Flow (MAF) are unsuitable. TabResFlow consists of three key components: (1) An MLP encoder for each numerical feature. (2) A fully connected ResNet backbone for expressive feature extraction. (3) A conditional spline-based normalizing flow for flexible and tractable density estimation. We evaluate TabResFlow on nine public benchmark datasets, demonstrating that it consistently surpasses existing probabilistic regression models on likelihood scores. Our results demonstrate 9.64% improvement compared to the strongest probabilistic regression model (TreeFlow), and on average 5.6 times speed-up in inference time compared to the strongest deep learning alternative (NodeFlow). Additionally, we validate the practical applicability of TabResFlow in a real-world used car price prediction task under selective regression. To measure performance in this setting, we introduce a novel Area Under Risk Coverage (AURC) metric and show that TabResFlow achieves superior results across this metric.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†TabResFlowï¼Œä¸€ç§ä¸“ä¸ºå•å˜é‡è¡¨æ ¼å›å½’(univariate tabular regression)è®¾è®¡çš„æ­£æ€åŒ–æ ·æ¡æµ(Normalizing Spline Flow)æ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰å›å½’æ–¹æ³•å› å‡è®¾å›ºå®šåˆ†å¸ƒï¼ˆå¦‚Gaussianï¼‰è€Œå¯¼è‡´çš„é¢„æµ‹è¿‡åº¦è‡ªä¿¡é—®é¢˜ã€‚è¯¥æ¡†æ¶ç”±MLPç¼–ç å™¨ã€ResNetéª¨å¹²ç½‘ç»œä»¥åŠæ¡ä»¶æ ·æ¡æ­£æ€åŒ–æµ(conditional spline-based normalizing flow)æ ¸å¿ƒç»„ä»¶æ„æˆï¼Œå…‹æœäº†RealNVPå’ŒMAFç­‰ä¼ ç»Ÿæµæ¨¡å‹åœ¨å¤„ç†å•å˜é‡è¡¨æ ¼æ•°æ®æ—¶çš„å±€é™æ€§ã€‚åœ¨ä¹ä¸ªå…¬å…±åŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒæ˜¾ç¤ºï¼ŒTabResFlowåœ¨ä¼¼ç„¶å¾—åˆ†ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ¦‚ç‡å›å½’æ¨¡å‹ï¼Œç›¸è¾ƒäºTreeFlowå®ç°äº†9.64%çš„æ€§èƒ½æå‡ï¼Œä¸”æ¨ç†é€Ÿåº¦æ¯”NodeFlowå¿«5.6å€ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶é€šè¿‡äºŒæ‰‹è½¦ä»·æ ¼é¢„æµ‹ä»»åŠ¡éªŒè¯äº†æ¨¡å‹åœ¨é€‰æ‹©æ€§å›å½’(selective regression)åœºæ™¯ä¸‹çš„å®é™…ä»·å€¼ï¼Œå¹¶å¼•å…¥äº†å…¨æ–°çš„Area Under Risk Coverage (AURC)æŒ‡æ ‡æ¥è¡¡é‡é¢„æµ‹çš„å¯é æ€§ã€‚å®éªŒç»“æœè¯æ˜TabResFlowèƒ½å¤Ÿæ›´çµæ´»ã€ç²¾ç¡®åœ°å»ºæ¨¡ç°å®ä¸–ç•Œä¸­çš„å¤æ‚åˆ†å¸ƒï¼Œä¸ºå·¥ä¸šè‡ªåŠ¨åŒ–ä¸­éœ€è¦ä¸ç¡®å®šæ€§ä¼°è®¡çš„å†³ç­–ä»»åŠ¡æä¾›äº†å¼ºæœ‰åŠ›çš„æ”¯æŒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "To be published in The European Conference on Artificial Intelligence, 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.17056v1",
      "published_date": "2025-08-23 15:09:02 UTC",
      "updated_date": "2025-08-23 15:09:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:37:21.731993+00:00"
    },
    {
      "arxiv_id": "2509.06967v1",
      "title": "Cross-field SNR Analysis and Tensor Channel Estimation for Multi-UAV Near-field Communications",
      "title_zh": "å¤šæ— äººæœºè¿‘åœºé€šä¿¡ä¸­çš„è·¨åœºä¿¡å™ªæ¯”åˆ†æä¸å¼ é‡ä¿¡é“ä¼°è®¡",
      "authors": [
        "Tianyu Huo",
        "Jian Xiong",
        "Yiyan Wu",
        "Songjie Yang",
        "Bo Liu",
        "Wenjun Zhang"
      ],
      "abstract": "Extremely large antenna array (ELAA) is key to enhancing spectral efficiency in 6G networks. Leveraging the distributed nature of multi-unmanned aerial vehicle (UAV) systems enables the formation of distributed ELAA, which often operate in the near-field region with spatial sparsity, rendering the conventional far-field plane wave assumption invalid. This paper investigates channel estimation for distributed near-field multi-UAV communication systems. We first derive closed-form signal-to-noise ratio (SNR) expressions under the plane wave model (PWM), spherical wave model (SWM), and a hybrid spherical-plane wave model (HSPWM), also referred to as the cross-field model, within a distributed uniform planar array (UPA) scenario. The analysis shows that HSPWM achieves a good balance between modeling accuracy and analytical tractability. Based on this, we propose two channel estimation algorithms: the spherical-domain orthogonal matching pursuit (SD-OMP) and the tensor-OMP. The SD-OMP generalizes the polar domain to jointly consider elevation, azimuth, and range. Under the HSPWM, the channel is naturally formulated as a tensor, enabling the use of tensor-OMP. Simulation results demonstrate that tensor-OMP achieves normalized mean square error (NMSE) performance comparable to SD-OMP, while offering reduced computational complexity and improved scalability.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹6Gç½‘ç»œä¸­ç”±å¤šæ— äººæœº(multi-UAV)ç³»ç»Ÿæ„æˆçš„åˆ†å¸ƒå¼è¶…å¤§è§„æ¨¡å¤©çº¿é˜µåˆ—(ELAA)åœ¨è¿‘åœº(near-field)åŒºåŸŸé¢ä¸´çš„ä¼ ç»Ÿè¿œåœºå¹³é¢æ³¢å‡è®¾å¤±æ•ˆé—®é¢˜ã€‚è®ºæ–‡é¦–å…ˆæ¨å¯¼äº†åœ¨åˆ†å¸ƒå¼å‡åŒ€å¹³é¢é˜µåˆ—(UPA)åœºæ™¯ä¸‹ï¼Œå¹³é¢æ³¢æ¨¡å‹(PWM)ã€çƒé¢æ³¢æ¨¡å‹(SWM)ä»¥åŠæ··åˆçƒé¢å¹³é¢æ³¢æ¨¡å‹(HSPWMï¼Œåˆç§°è·¨åœºæ¨¡å‹)çš„é—­åˆå½¢å¼ä¿¡å™ªæ¯”(SNR)è¡¨è¾¾å¼ã€‚åˆ†æè¡¨æ˜HSPWMåœ¨å»ºæ¨¡ç²¾åº¦ä¸åˆ†æç®€ä¾¿æ€§ä¹‹é—´å–å¾—äº†è‰¯å¥½å¹³è¡¡ï¼Œæ®æ­¤ç ”ç©¶è€…æå‡ºäº†çƒé¢åŸŸæ­£äº¤åŒ¹é…è¿½è¸ª(SD-OMP)å’Œå¼ é‡æ­£äº¤åŒ¹é…è¿½è¸ª(tensor-OMP)ä¸¤ç§ä¿¡é“ä¼°è®¡(channel estimation)ç®—æ³•ã€‚å…¶ä¸­SD-OMPé€šè¿‡æ‰©å±•çƒé¢åŸŸè”åˆè€ƒè™‘ä»°è§’ã€æ–¹ä½è§’å’Œè·ç¦»ï¼Œè€Œtensor-OMPåˆ™åˆ©ç”¨HSPWMä¸‹çš„ä¿¡é“å¼ é‡ç»“æ„ç®€åŒ–è®¡ç®—ã€‚ä»¿çœŸç»“æœæ˜¾ç¤ºï¼Œtensor-OMPåœ¨å½’ä¸€åŒ–å‡æ–¹è¯¯å·®(NMSE)æ€§èƒ½ä¸Šä¸SD-OMPç›¸å½“ï¼ŒåŒæ—¶å…·å¤‡æ›´ä½çš„è®¡ç®—å¤æ‚åº¦å’Œæ›´å¥½çš„å¯æ‰©å±•æ€§(scalability)ã€‚",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.IT"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06967v1",
      "published_date": "2025-08-23 14:50:36 UTC",
      "updated_date": "2025-08-23 14:50:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:37:42.493994+00:00"
    },
    {
      "arxiv_id": "2508.17007v2",
      "title": "An Efficient Dual-Line Decoder Network with Multi-Scale Convolutional Attention for Multi-organ Segmentation",
      "title_zh": "èåˆå¤šå°ºåº¦å·ç§¯æ³¨æ„åŠ›çš„é«˜æ•ˆå¤šå™¨å®˜åˆ†å‰²åŒè·¯è§£ç å™¨ç½‘ç»œ",
      "authors": [
        "Riad Hassan",
        "M. Rubaiyat Hossain Mondal",
        "Sheikh Iqbal Ahamed",
        "Fahad Mostafa",
        "Md Mostafijur Rahman"
      ],
      "abstract": "Proper segmentation of organs-at-risk is important for radiation therapy, surgical planning, and diagnostic decision-making in medical image analysis. While deep learning-based segmentation architectures have made significant progress, they often fail to balance segmentation accuracy with computational efficiency. Most of the current state-of-the-art methods either prioritize performance at the cost of high computational complexity or compromise accuracy for efficiency. This paper addresses this gap by introducing an efficient dual-line decoder segmentation network (EDLDNet). The proposed method features a noisy decoder, which learns to incorporate structured perturbation at training time for better model robustness, yet at inference time only the noise-free decoder is executed, leading to lower computational cost. Multi-Scale convolutional Attention Modules (MSCAMs), Attention Gates (AGs), and Up-Convolution Blocks (UCBs) are further utilized to optimize feature representation and boost segmentation performance. By leveraging multi-scale segmentation masks from both decoders, we also utilize a mutation-based loss function to enhance the model's generalization. Our approach outperforms SOTA segmentation architectures on four publicly available medical imaging datasets. EDLDNet achieves SOTA performance with an 84.00% Dice score on the Synapse dataset, surpassing baseline model like UNet by 13.89% in Dice score while significantly reducing Multiply-Accumulate Operations (MACs) by 89.7%. Compared to recent approaches like EMCAD, our EDLDNet not only achieves higher Dice score but also maintains comparable computational efficiency. The outstanding performance across diverse datasets establishes EDLDNet's strong generalization, computational efficiency, and robustness. The source code, pre-processed data, and pre-trained weights will be available at https://github.com/riadhassan/EDLDNet .",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸ºEDLDNet (Efficient Dual-Line Decoder segmentation Network) çš„é«˜æ•ˆåŒçº¿è·¯è§£ç å™¨åˆ†å‰²ç½‘ç»œï¼Œæ—¨åœ¨è§£å†³åŒ»å­¦å›¾åƒåˆ†æä¸­å¤šå™¨å®˜åˆ†å‰²çš„ç²¾åº¦ä¸è®¡ç®—æ•ˆç‡å¹³è¡¡é—®é¢˜ã€‚è¯¥æ¡†æ¶çš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå¼•å…¥äº†Noisy Decoderï¼Œåœ¨è®­ç»ƒæ—¶é€šè¿‡ç»“æ„åŒ–æ‰°åŠ¨å¢å¼ºæ¨¡å‹é²æ£’æ€§ï¼Œè€Œåœ¨æ¨ç†é˜¶æ®µä»…æ‰§è¡Œæ— å™ªå£°è§£ç å™¨ä»¥æ˜¾è‘—é™ä½è®¡ç®—æˆæœ¬ã€‚ä¸ºäº†ä¼˜åŒ–ç‰¹å¾è¡¨ç¤ºï¼Œæ¨¡å‹è¿›ä¸€æ­¥é›†æˆäº†Multi-Scale convolutional Attention Modules (MSCAMs)ã€Attention Gates (AGs) å’Œ Up-Convolution Blocks (UCBs)ã€‚æ­¤å¤–ï¼Œç ”ç©¶è€…åˆ©ç”¨åŸºäºå˜å¼‚çš„æŸå¤±å‡½æ•° (mutation-based loss function) ç»“åˆåŒè§£ç å™¨çš„å¤šå°ºåº¦æ©ç ï¼Œæœ‰æ•ˆæå‡äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒEDLDNetåœ¨Synapseæ•°æ®é›†ä¸Šå–å¾—äº†84.00%çš„Dice scoreï¼Œç›¸æ¯”UNetæå‡äº†13.89%ï¼ŒåŒæ—¶å°†Multiply-Accumulate Operations (MACs) é™ä½äº†89.7%ã€‚è¯¥æ–¹æ³•åœ¨å››ä¸ªå…¬å¼€æ•°æ®é›†ä¸Šå‡è¾¾åˆ°äº†SOTAæ€§èƒ½ï¼Œè¯æ˜äº†å…¶åœ¨å¤šå™¨å®˜åˆ†å‰²ä»»åŠ¡ä¸­å…·æœ‰å“è¶Šçš„é²æ£’æ€§ã€æ³›åŒ–èƒ½åŠ›å’Œæé«˜çš„è®¡ç®—æ•ˆç‡ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "After revision, minor ablation studies have been added in the published version in Biomedical Signal Processing and Control (BSPC)",
      "pdf_url": "https://arxiv.org/pdf/2508.17007v2",
      "published_date": "2025-08-23 12:34:27 UTC",
      "updated_date": "2025-09-21 10:13:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:37:51.381621+00:00"
    },
    {
      "arxiv_id": "2508.16994v2",
      "title": "GRADE: Generating multi-hop QA and fine-gRAined Difficulty matrix for RAG Evaluation",
      "title_zh": "GRADEï¼šé¢å‘ RAG è¯„ä¼°çš„å¤šè·³é—®ç­”ç”Ÿæˆä¸ç»†ç²’åº¦éš¾åº¦çŸ©é˜µ",
      "authors": [
        "Jeongsoo Lee",
        "Daeyong Kwon",
        "Kyohoon Jin"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) systems are widely adopted in knowledge-intensive NLP tasks, but current evaluations often overlook the structural complexity and multi-step reasoning required in real-world scenarios. These benchmarks overlook key factors such as the interaction between retrieval difficulty and reasoning depth. To address this gap, we propose GRADE, a novel evaluation framework that models task difficulty along two orthogonal dimensions: (1) reasoning depth, defined by the number of inference steps (hops), and (2) semantic distance between the query and its supporting evidence. We construct a synthetic multi-hop QA dataset from factual news articles by extracting knowledge graphs and augmenting them through semantic clustering to recover missing links, allowing us to generate diverse and difficulty-controlled queries. Central to our framework is a 2D difficulty matrix that combines generator-side and retriever-side difficulty. Experiments across multiple domains and models show that error rates strongly correlate with our difficulty measures, validating their diagnostic utility. GRADE enables fine-grained analysis of RAG performance and provides a scalable foundation for evaluating and improving multi-hop reasoning in real-world applications.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† GRADEï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨æ”¹è¿› RAG ç³»ç»Ÿè¯„ä¼°çš„æ–°å‹æ¡†æ¶ï¼Œé‡ç‚¹å…³æ³¨ç°å®åœºæ™¯ä¸­çš„ç»“æ„å¤æ‚æ€§å’Œå¤šæ­¥æ¨ç†ã€‚è¯¥æ¡†æ¶é€šè¿‡ä¸¤ä¸ªæ­£äº¤ç»´åº¦å®šä¹‰ä»»åŠ¡éš¾åº¦ï¼šä¸€æ˜¯æ¨ç†æ·±åº¦ï¼ˆreasoning depthï¼‰ï¼Œå³æ¨ç†æ­¥æ•°ï¼ˆhopsï¼‰ï¼›äºŒæ˜¯æŸ¥è¯¢ä¸æ”¯æŒè¯æ®ä¹‹é—´çš„è¯­ä¹‰è·ç¦»ï¼ˆsemantic distanceï¼‰ã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡ä»æ–°é—»æ–‡ç« ä¸­æå–çŸ¥è¯†å›¾è°±å¹¶ç»“åˆè¯­ä¹‰èšç±»ï¼ˆsemantic clusteringï¼‰æŠ€æœ¯ï¼Œæ„å»ºäº†ä¸€ä¸ªåˆæˆçš„å¤šè·³é—®ç­”æ•°æ®é›†ï¼Œä»è€Œç”Ÿæˆéš¾åº¦å—æ§çš„å¤šæ ·åŒ–æŸ¥è¯¢ã€‚GRADE çš„æ ¸å¿ƒæ˜¯ä¸€ä¸ªäºŒç»´éš¾åº¦çŸ©é˜µï¼Œæœ‰æ•ˆç»“åˆäº†ç”Ÿæˆå™¨ç«¯ï¼ˆgenerator-sideï¼‰å’Œæ£€ç´¢å™¨ç«¯ï¼ˆretriever-sideï¼‰çš„éš¾åº¦æŒ‡æ ‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæ¨¡å‹é”™è¯¯ç‡ä¸è¯¥éš¾åº¦åº¦é‡é«˜åº¦ç›¸å…³ï¼ŒéªŒè¯äº†å…¶åœ¨æ€§èƒ½è¯Šæ–­ä¸­çš„å®ç”¨æ€§ã€‚è¯¥æ¡†æ¶ä¸º RAG ç³»ç»Ÿçš„ç»†ç²’åº¦åˆ†ææä¾›äº†å¯æ‰©å±•çš„åŸºç¡€ï¼Œæœ‰åŠ©äºåœ¨å®é™…åº”ç”¨ä¸­è¯„ä¼°å¹¶æå‡å¤šè·³æ¨ç†èƒ½åŠ›ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at EMNLP 2025 findings",
      "pdf_url": "https://arxiv.org/pdf/2508.16994v2",
      "published_date": "2025-08-23 11:26:41 UTC",
      "updated_date": "2025-12-15 01:19:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:37:56.203293+00:00"
    },
    {
      "arxiv_id": "2508.16990v1",
      "title": "Score Matching on Large Geometric Graphs for Cosmology Generation",
      "title_zh": "é¢å‘å®‡å®™å­¦ç”Ÿæˆçš„å¤§è§„æ¨¡å‡ ä½•å›¾å¾—åˆ†åŒ¹é…",
      "authors": [
        "Diana-Alexandra Onutu",
        "Yue Zhao",
        "Joaquin Vanschoren",
        "Vlado Menkovski"
      ],
      "abstract": "Generative models are a promising tool to produce cosmological simulations but face significant challenges in scalability, physical consistency, and adherence to domain symmetries, limiting their utility as alternatives to $N$-body simulations. To address these limitations, we introduce a score-based generative model with an equivariant graph neural network that simulates gravitational clustering of galaxies across cosmologies starting from an informed prior, respects periodic boundaries, and scales to full galaxy counts in simulations. A novel topology-aware noise schedule, crucial for large geometric graphs, is introduced. The proposed equivariant score-based model successfully generates full-scale cosmological point clouds of up to 600,000 halos, respects periodicity and a uniform prior, and outperforms existing diffusion models in capturing clustering statistics while offering significant computational advantages. This work advances cosmology by introducing a generative model designed to closely resemble the underlying gravitational clustering of structure formation, moving closer to physically realistic and efficient simulators for the evolution of large-scale structures in the universe.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å®‡å®™å­¦æ¨¡æ‹Ÿåœ¨å¯æ‰©å±•æ€§ã€ç‰©ç†ä¸€è‡´æ€§å’ŒåŸŸå¯¹ç§°æ€§æ–¹é¢çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºåˆ†æ•°åŒ¹é…(Score Matching)å’Œç­‰å˜å›¾ç¥ç»ç½‘ç»œ(Equivariant Graph Neural Network)çš„ç”Ÿæˆæ¨¡å‹ã€‚è¯¥æ¨¡å‹æ—¨åœ¨ä»å…ˆéªŒä¿¡æ¯å‡ºå‘æ¨¡æ‹Ÿæ˜Ÿç³»çš„å¼•åŠ›èšç±»ï¼Œä¸ä»…å°Šé‡å‘¨æœŸæ€§è¾¹ç•Œæ¡ä»¶(Periodic Boundaries)ï¼Œè¿˜èƒ½æ‰©å±•åˆ°æ¨¡æ‹Ÿä¸­çš„å®Œæ•´æ˜Ÿç³»æ•°é‡ã€‚ç ”ç©¶å¼•å…¥äº†ä¸€ç§é’ˆå¯¹å¤§å‹å‡ ä½•å›¾çš„æ–°å‹æ‹“æ‰‘æ„ŸçŸ¥å™ªå£°è°ƒåº¦(Topology-aware noise schedule)ï¼Œè¿™æ˜¯ç¡®ä¿å¤§è§„æ¨¡æ•°æ®å¤„ç†çš„å…³é”®ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ¨¡å‹èƒ½å¤ŸæˆåŠŸç”ŸæˆåŒ…å«å¤šè¾¾600,000ä¸ªæ™•(Halos)çš„å…¨è§„æ¨¡å®‡å®™å­¦ç‚¹äº‘ï¼Œåœ¨æ•æ‰èšç±»ç»Ÿè®¡æ•°æ®æ–¹é¢ä¼˜äºç°æœ‰çš„æ‰©æ•£æ¨¡å‹ï¼Œå¹¶å…·æœ‰æ˜¾è‘—çš„è®¡ç®—ä¼˜åŠ¿ã€‚è¯¥å·¥ä½œé€šè¿‡æä¾›æ›´ç¬¦åˆç‰©ç†ç°å®ä¸”é«˜æ•ˆçš„ç”Ÿæˆæ‰‹æ®µï¼Œæ˜¾è‘—æ¨è¿›äº†å®‡å®™å¤§è§„æ¨¡ç»“æ„æ¼”åŒ–çš„æ¨¡æ‹ŸæŠ€æœ¯ã€‚",
      "categories": [
        "astro-ph.CO",
        "cs.AI"
      ],
      "primary_category": "astro-ph.CO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.16990v1",
      "published_date": "2025-08-23 11:08:06 UTC",
      "updated_date": "2025-08-23 11:08:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:37:58.992210+00:00"
    },
    {
      "arxiv_id": "2508.16987v1",
      "title": "WebSight: A Vision-First Architecture for Robust Web Agents",
      "title_zh": "WebSightï¼šé¢å‘é²æ£’ç½‘é¡µæ™ºèƒ½ä½“çš„è§†è§‰ä¼˜å…ˆæ¶æ„",
      "authors": [
        "Tanvir Bhathal",
        "Asanshay Gupta"
      ],
      "abstract": "We introduce WebSight, a vision-based autonomous web agent, designed to interact with web environments purely through visual perception, eliminating dependence on HTML or DOM-based inputs. Central to our approach we introduce our new model, WebSight-7B, a fine-tuned vision-language model optimized for UI element interaction, trained using LoRA on a web-focused subset of the Wave-UI-25K dataset. WebSight integrates this model into a modular multi-agent architecture, comprising planning, reasoning, vision-action, and verification agents, coordinated through an episodic memory mechanism.\n  WebSight-7B achieves a top-1 accuracy of 58.84% on the Showdown Clicks benchmark, outperforming several larger generalist models while maintaining lower latency. The full WebSight agent achieves a 68.0% success rate on the WebVoyager benchmark, surpassing systems from labs such as OpenAI (61.0%) and HCompany (Runner H, 67.0%). Among tasks completed, WebSight answers correctly 97.14% of the time, indicating high precision. Together, WebSight and WebSight-7B establish a new standard for interpretable, robust, and efficient visual web navigation.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»‹ç»äº† WebSightï¼Œä¸€ç§ä»…ä¾é è§†è§‰æ„ŸçŸ¥ä¸ç½‘é¡µç¯å¢ƒäº¤äº’çš„è§†è§‰ä¼˜å…ˆè‡ªä¸»ç½‘é¡µæ™ºèƒ½ä½“(Web Agent)ï¼Œå½»åº•æ‘†è„±äº†å¯¹ HTML æˆ– DOM è¾“å…¥çš„ä¾èµ–ã€‚å…¶æ ¸å¿ƒæ¨¡å‹ WebSight-7B æ˜¯åŸºäº Wave-UI-25K æ•°æ®é›†å­é›†å¹¶é€šè¿‡ LoRA æŠ€æœ¯å¾®è°ƒçš„è§†è§‰è¯­è¨€æ¨¡å‹(Vision-Language Model)ï¼Œä¸“é—¨é’ˆå¯¹ UI å…ƒç´ äº¤äº’è¿›è¡Œäº†ä¼˜åŒ–ã€‚WebSight é‡‡ç”¨äº†æ¨¡å—åŒ–å¤šæ™ºèƒ½ä½“æ¶æ„ï¼Œé€šè¿‡æƒ…èŠ‚è®°å¿†(Episodic Memory)æœºåˆ¶åè°ƒè§„åˆ’(Planning)ã€æ¨ç†(Reasoning)ã€è§†è§‰åŠ¨ä½œ(Vision-action)å’ŒéªŒè¯(Verification)ç­‰å¤šä¸ªç»„ä»¶ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒWebSight-7B åœ¨ Showdown Clicks åŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº† 58.84% çš„å‡†ç¡®ç‡ï¼Œåœ¨ä¿æŒä½å»¶è¿Ÿçš„åŒæ—¶ä¼˜äºå¤šä¸ªå¤§å‹é€šç”¨æ¨¡å‹ã€‚åœ¨ WebVoyager åŸºå‡†æµ‹è¯•ä¸­ï¼ŒWebSight å®ç°äº† 68.0% çš„æˆåŠŸç‡ï¼Œè¶…è¶Šäº† OpenAI (61.0%) å’Œ HCompany (67.0%) çš„ç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿåœ¨ä»»åŠ¡å®Œæˆä¸­çš„æ­£ç¡®ç‡é«˜è¾¾ 97.14%ï¼Œä¸ºå¯è§£é‡Šã€é²æ£’ä¸”é«˜æ•ˆçš„è§†è§‰ç½‘é¡µå¯¼èˆªå»ºç«‹äº†æ–°çš„æ ‡å‡†ã€‚",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.16987v1",
      "published_date": "2025-08-23 11:02:59 UTC",
      "updated_date": "2025-08-23 11:02:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:38:05.390244+00:00"
    },
    {
      "arxiv_id": "2508.16986v1",
      "title": "Complexity in finitary argumentation (extended version)",
      "title_zh": "æœ‰ç©·è®ºè¾©çš„å¤æ‚æ€§ï¼ˆæ‰©å±•ç‰ˆï¼‰",
      "authors": [
        "Uri Andrews",
        "Luca San Mauro"
      ],
      "abstract": "Abstract argumentation frameworks (AFs) provide a formal setting to analyze many forms of reasoning with conflicting information. While the expressiveness of general infinite AFs make them a tempting tool for modeling many kinds of reasoning scenarios, the computational intractability of solving infinite AFs limit their use, even in many theoretical applications.\n  We investigate the complexity of computational problems related to infinite but finitary argumentations frameworks, that is, infinite AFs where each argument is attacked by only finitely many others. Our results reveal a surprising scenario. On one hand, we see that the assumption of being finitary does not automatically guarantee a drop in complexity. However, for the admissibility-based semantics, we find a remarkable combinatorial constraint which entails a dramatic decrease in complexity.\n  We conclude that for many forms of reasoning, the finitary infinite AFs provide a natural setting for reasoning which balances well the competing goals of being expressive enough to be applied to many reasoning settings while being computationally tractable enough for the analysis within the framework to be useful.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æŠ½è±¡è®ºè¯æ¡†æ¶ (Abstract Argumentation Frameworks, AFs) åœ¨å¤„ç†å†²çªä¿¡æ¯æ¨ç†æ—¶çš„è®¡ç®—å¤æ‚æ€§é—®é¢˜ï¼Œç‰¹åˆ«å…³æ³¨äºè¡¨è¾¾åŠ›å¼ºä½†è®¡ç®—å›°éš¾çš„æ— é™ AFsã€‚ç ”ç©¶é‡ç‚¹åˆ†æäº† finitary argumentation frameworks çš„è®¡ç®—é—®é¢˜ï¼Œå³æ¯ä¸ªè®ºç‚¹ä»…å—æœ‰é™æ•°é‡è®ºç‚¹æ”»å‡»çš„æ— é™æ¡†æ¶ã€‚ç ”ç©¶ç»“æœæ˜¾ç¤ºï¼Œè™½ç„¶ finitary å‡è®¾æœ¬èº«å¹¶ä¸å¿…ç„¶é™ä½è®¡ç®—å¤æ‚åº¦ï¼Œä½†åœ¨é’ˆå¯¹ admissibility-based semantics çš„åˆ†æä¸­ï¼Œç‰¹å®šçš„ç»„åˆçº¦æŸä¼šå¯¼è‡´å¤æ‚åº¦å¤§å¹…ä¸‹é™ã€‚ä½œè€…æŒ‡å‡ºï¼Œfinitary infinite AFs åœ¨å»ºæ¨¡èƒ½åŠ›ä¸è®¡ç®—å¯å¤„ç†æ€§ (computational tractability) ä¹‹é—´è¾¾æˆäº†æœ‰æ•ˆå¹³è¡¡ã€‚è¿™ä¸€å‘ç°è¯æ˜äº†è¯¥æ¡†æ¶èƒ½ä¸ºå¤šç§æ¨ç†åœºæ™¯æä¾›ä¸€ä¸ªæ—¢å…·å¤‡è¶³å¤Ÿè¡¨è¾¾åŠ›åˆä¾¿äºè¿›è¡Œå®ç”¨åˆ†æçš„è‡ªç„¶è®¾å®šã€‚",
      "categories": [
        "cs.AI",
        "math.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.16986v1",
      "published_date": "2025-08-23 11:02:43 UTC",
      "updated_date": "2025-08-23 11:02:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:38:09.691051+00:00"
    },
    {
      "arxiv_id": "2508.16983v2",
      "title": "ReFactX: Scalable Reasoning with Reliable Facts via Constrained Generation",
      "title_zh": "ReFactXï¼šåŸºäºçº¦æŸç”Ÿæˆçš„å¯é äº‹å®å¯æ‰©å±•æ¨ç†",
      "authors": [
        "Riccardo Pozzi",
        "Matteo Palmonari",
        "Andrea Coletta",
        "Luigi Bellomarini",
        "Jens Lehmann",
        "Sahar Vahdati"
      ],
      "abstract": "Knowledge gaps and hallucinations are persistent challenges for Large Language Models (LLMs), which generate unreliable responses when lacking the necessary information to fulfill user instructions. Existing approaches, such as Retrieval-Augmented Generation (RAG) and tool use, aim to address these issues by incorporating external knowledge. Yet, they rely on additional models or services, resulting in complex pipelines, potential error propagation, and often requiring the model to process a large number of tokens. In this paper, we present a scalable method that enables LLMs to access external knowledge without depending on retrievers or auxiliary models. Our approach uses constrained generation with a pre-built prefix-tree index. Triples from a Knowledge Graph are verbalized in textual facts, tokenized, and indexed in a prefix tree for efficient access. During inference, to acquire external knowledge, the LLM generates facts with constrained generation which allows only sequences of tokens that form an existing fact. We evaluate our proposal on Question Answering and show that it scales to large knowledge bases (800 million facts), adapts to domain-specific data, and achieves effective results. These gains come with minimal generation-time overhead. ReFactX code is available at https://github.com/rpo19/ReFactX.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Large Language Models (LLMs) åœ¨çŸ¥è¯†ç¼ºå¤±æ—¶äº§ç”Ÿçš„å¹»è§‰å’Œä¸å¯é å“åº”é—®é¢˜ï¼Œæå‡ºäº† ReFactXï¼Œä¸€ç§æ— éœ€ä¾èµ–æ£€ç´¢å™¨æˆ–è¾…åŠ©æ¨¡å‹å³å¯è·å–å¤–éƒ¨çŸ¥è¯†çš„å¯æ‰©å±•æ–¹æ³•ã€‚ReFactX é€šè¿‡å—é™ç”Ÿæˆ (Constrained Generation) æŠ€æœ¯ç»“åˆé¢„æ„å»ºçš„å‰ç¼€æ ‘ç´¢å¼• (Prefix-tree Index)ï¼Œå°†çŸ¥è¯†å›¾è°± (Knowledge Graph) ä¸­çš„ä¸‰å…ƒç»„è½¬åŒ–ä¸ºæ–‡æœ¬äº‹å®è¿›è¡Œé«˜æ•ˆè®¿é—®ã€‚åœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œæ¨¡å‹ä»…è¢«å…è®¸ç”Ÿæˆç´¢å¼•ä¸­å­˜åœ¨çš„çœŸå®äº‹å®åºåˆ—ï¼Œä»è€Œæœ‰æ•ˆé¿å…äº†å¤æ‚æµæ°´çº¿å¸¦æ¥çš„é”™è¯¯ä¼ æ’­ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒReFactX åœ¨é—®ç­”ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œèƒ½å¤Ÿæ‰©å±•è‡³æ‹¥æœ‰ 8 äº¿æ¡äº‹å®çš„å¤§è§„æ¨¡çŸ¥è¯†åº“ï¼Œå¹¶èƒ½çµæ´»é€‚åº”ç‰¹å®šé¢†åŸŸæ•°æ®ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•åœ¨ä¿æŒé«˜æ•ˆæ€§èƒ½çš„åŒæ—¶ä»…äº§ç”Ÿæå°çš„ç”Ÿæˆæ—¶é—´å¼€é”€ï¼Œä¸ºå®ç°å¯é ä¸”å¯æ‰©å±•çš„çŸ¥è¯†æ¨ç†æä¾›äº†æ–°è·¯å¾„ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "19 pages, 6 figures, accepted at ISWC",
      "pdf_url": "https://arxiv.org/pdf/2508.16983v2",
      "published_date": "2025-08-23 10:21:47 UTC",
      "updated_date": "2025-11-19 10:26:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:38:21.555021+00:00"
    },
    {
      "arxiv_id": "2508.16975v1",
      "title": "Combating Digitally Altered Images: Deepfake Detection",
      "title_zh": "åº”å¯¹æ•°å­—ç¯¡æ”¹å›¾åƒï¼šæ·±åº¦ä¼ªé€ æ£€æµ‹",
      "authors": [
        "Saksham Kumar",
        "Rhythm Narang"
      ],
      "abstract": "The rise of Deepfake technology to generate hyper-realistic manipulated images and videos poses a significant challenge to the public and relevant authorities. This study presents a robust Deepfake detection based on a modified Vision Transformer(ViT) model, trained to distinguish between real and Deepfake images. The model has been trained on a subset of the OpenForensics Dataset with multiple augmentation techniques to increase robustness for diverse image manipulations. The class imbalance issues are handled by oversampling and a train-validation split of the dataset in a stratified manner. Performance is evaluated using the accuracy metric on the training and testing datasets, followed by a prediction score on a random image of people, irrespective of their realness. The model demonstrates state-of-the-art results on the test dataset to meticulously detect Deepfake images.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹DeepfakeæŠ€æœ¯ç”Ÿæˆé«˜åº¦é€¼çœŸè™šå‡å›¾åƒæ‰€å¸¦æ¥çš„ç¤¾ä¼šæŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºæ”¹è¿›å‹Vision Transformer (ViT)æ¨¡å‹çš„ç¨³å¥æ£€æµ‹æ–¹æ¡ˆã€‚ä¸ºäº†æé«˜æ¨¡å‹å¯¹å¤šæ ·åŒ–å›¾åƒç¯¡æ”¹çš„é²æ£’æ€§ï¼Œç ”ç©¶è€…åœ¨OpenForensics Datasetå­é›†ä¸Šåº”ç”¨äº†å¤šç§æ•°æ®å¢å¼ºæŠ€æœ¯ï¼Œå¹¶é€šè¿‡oversamplingå’Œåˆ†å±‚é‡‡æ ·(stratified train-validation split)è§£å†³äº†ç±»ä¸å¹³è¡¡(class imbalance)é—®é¢˜ã€‚è¯„ä¼°è¿‡ç¨‹ä¸ä»…ä½¿ç”¨äº†accuracyæŒ‡æ ‡ï¼Œè¿˜é€šè¿‡å¯¹éšæœºå›¾åƒçš„é¢„æµ‹è¯„åˆ†éªŒè¯äº†å…¶å®é™…æ£€æµ‹æ•ˆèƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šå–å¾—äº†state-of-the-artçš„æ£€æµ‹ç»“æœï¼Œèƒ½å¤Ÿç»†è‡´ä¸”å‡†ç¡®åœ°è¯†åˆ«Deepfakeå›¾åƒã€‚è¯¥æˆæœä¸ºæ‰“å‡»æ•°å­—ç¯¡æ”¹å†…å®¹ã€ç»´æŠ¤ä¿¡æ¯çœŸå®æ€§æä¾›äº†é‡è¦çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.16975v1",
      "published_date": "2025-08-23 09:59:03 UTC",
      "updated_date": "2025-08-23 09:59:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:38:22.657449+00:00"
    },
    {
      "arxiv_id": "2508.16969v1",
      "title": "Explaining Black-box Language Models with Knowledge Probing Systems: A Post-hoc Explanation Perspective",
      "title_zh": "åŸºäºçŸ¥è¯†æ¢æµ‹ç³»ç»Ÿçš„é»‘ç›’è¯­è¨€æ¨¡å‹è§£é‡Šï¼šäº‹åè§£é‡Šè§†è§’",
      "authors": [
        "Yunxiao Zhao",
        "Hao Xu",
        "Zhiqiang Wang",
        "Xiaoli Li",
        "Jiye Liang",
        "Ru Li"
      ],
      "abstract": "Pre-trained Language Models (PLMs) are trained on large amounts of unlabeled data, yet they exhibit remarkable reasoning skills. However, the trustworthiness challenges posed by these black-box models have become increasingly evident in recent years. To alleviate this problem, this paper proposes a novel Knowledge-guided Probing approach called KnowProb in a post-hoc explanation way, which aims to probe whether black-box PLMs understand implicit knowledge beyond the given text, rather than focusing only on the surface level content of the text. We provide six potential explanations derived from the underlying content of the given text, including three knowledge-based understanding and three association-based reasoning. In experiments, we validate that current small-scale (or large-scale) PLMs only learn a single distribution of representation, and still face significant challenges in capturing the hidden knowledge behind a given text. Furthermore, we demonstrate that our proposed approach is effective for identifying the limitations of existing black-box models from multiple probing perspectives, which facilitates researchers to promote the study of detecting black-box models in an explainable way.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ (Pre-trained Language Models, PLMs) ä½œä¸ºé»‘ç›’æ¨¡å‹æ‰€é¢ä¸´çš„å¯ä¿¡åº¦æŒ‘æˆ˜ï¼Œä»äº‹åè§£é‡Š (post-hoc explanation) çš„è§†è§’æå‡ºäº†ä¸€ç§åä¸º KnowProb çš„çŸ¥è¯†å¯¼å‘æ¢æµ‹æ–¹æ³•ã€‚è¯¥æ–¹æ³•æ—¨åœ¨æ¢æµ‹é»‘ç›’ PLMs æ˜¯å¦ç†è§£æ–‡æœ¬ä¹‹å¤–çš„éšæ€§çŸ¥è¯†ï¼Œè€Œéä»…ä»…åœç•™åœ¨è¡¨å±‚å†…å®¹ã€‚ç ”ç©¶å›¢é˜Ÿæä¾›äº†å…­ç§è¡ç”Ÿè‡ªæ–‡æœ¬åº•å±‚å†…å®¹çš„æ½œåœ¨è§£é‡Šï¼Œæ¶µç›–äº†ä¸‰ç§åŸºäºçŸ¥è¯†çš„ç†è§£ (knowledge-based understanding) å’Œä¸‰ç§åŸºäºå…³è”çš„æ¨ç† (association-based reasoning)ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå½“å‰çš„å„è§„æ¨¡ PLMs åœ¨æ•æ‰éšè—çŸ¥è¯†æ–¹é¢ä»é¢ä¸´é‡å¤§æŒ‘æˆ˜ï¼Œå¾€å¾€ä»…å­¦ä¹ åˆ°äº†å•ä¸€çš„è¡¨ç¤ºåˆ†å¸ƒã€‚æ­¤å¤–ï¼ŒKnowProb è¢«è¯æ˜èƒ½å¤Ÿæœ‰æ•ˆä»å¤šä¸ªæ¢æµ‹ç»´åº¦è¯†åˆ«ç°æœ‰é»‘ç›’æ¨¡å‹çš„å±€é™æ€§ã€‚è¯¥ç ”ç©¶ä¸ºä»¥å¯è§£é‡Šçš„æ–¹å¼æ£€æµ‹å’Œä¼˜åŒ–é»‘ç›’æ¨¡å‹æä¾›äº†æ–°çš„å·¥å…·ï¼ŒåŠ©åŠ›äº†å­¦æœ¯ç•Œå¯¹æ¨¡å‹å¯ä¿¡åº¦çš„æ·±å…¥æ¢ç´¢ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages, 8 figures. This paper has been accepted by DASFAA 2025: The 30th International Conference on Database Systems for Advanced Applications",
      "pdf_url": "https://arxiv.org/pdf/2508.16969v1",
      "published_date": "2025-08-23 09:41:59 UTC",
      "updated_date": "2025-08-23 09:41:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:38:54.256811+00:00"
    },
    {
      "arxiv_id": "2508.16962v1",
      "title": "LLM-based Human-like Traffic Simulation for Self-driving Tests",
      "title_zh": "é¢å‘è‡ªåŠ¨é©¾é©¶æµ‹è¯•çš„åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„ç±»äººäº¤é€šä»¿çœŸ",
      "authors": [
        "Wendi Li",
        "Hao Wu",
        "Han Gao",
        "Bing Mao",
        "Fengyuan Xu",
        "Sheng Zhong"
      ],
      "abstract": "Ensuring realistic traffic dynamics is a prerequisite for simulation platforms to evaluate the reliability of self-driving systems before deployment in the real world. Because most road users are human drivers, reproducing their diverse behaviors within simulators is vital. Existing solutions, however, typically rely on either handcrafted heuristics or narrow data-driven models, which capture only fragments of real driving behaviors and offer limited driving style diversity and interpretability. To address this gap, we introduce HDSim, an HD traffic generation framework that combines cognitive theory with large language model (LLM) assistance to produce scalable and realistic traffic scenarios within simulation platforms. The framework advances the state of the art in two ways: (i) it introduces a hierarchical driver model that represents diverse driving style traits, and (ii) it develops a Perception-Mediated Behavior Influence strategy, where LLMs guide perception to indirectly shape driver actions. Experiments reveal that embedding HDSim into simulation improves detection of safety-critical failures in self-driving systems by up to 68% and yields realism-consistent accident interpretability.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† HDSimï¼Œä¸€ç§ç»“åˆè®¤çŸ¥ç†è®ºä¸ Large Language Model (LLM) è¾…åŠ©çš„é«˜ä¿çœŸäº¤é€šç”Ÿæˆæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰ä»¿çœŸæ–¹æ¡ˆåœ¨æ¨¡æ‹Ÿäººç±»é©¾é©¶è¡Œä¸ºå¤šæ ·æ€§å’Œå¯è§£é‡Šæ€§æ–¹é¢çš„å±€é™ã€‚è¯¥æ¡†æ¶é€šè¿‡å¼•å…¥å±‚æ¬¡åŒ–é©¾é©¶å‘˜æ¨¡å‹ (hierarchical driver model) æ¥è¡¨å¾ä¸åŒçš„é©¾é©¶é£æ ¼ï¼Œå¹¶å¼€å‘äº†æ„ŸçŸ¥ä»‹å¯¼è¡Œä¸ºå½±å“ç­–ç•¥ (Perception-Mediated Behavior Influence)ï¼Œåˆ©ç”¨ LLMs å¼•å¯¼æ„ŸçŸ¥ä»è€Œé—´æ¥å¡‘é€ é©¾é©¶å‘˜è¡Œä¸ºã€‚å®éªŒè¡¨æ˜ï¼Œå°† HDSim åµŒå…¥ä»¿çœŸå¹³å°å¯å°†è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿå®‰å…¨å…³é”®æ•…éšœ (safety-critical failures) çš„æ£€æµ‹ç‡æé«˜ 68%ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶è¿˜å®ç°äº†ä¸çœŸå®æƒ…å†µä¸€è‡´çš„äº‹æ•…å¯è§£é‡Šæ€§ (interpretability)ï¼Œä¸ºè‡ªåŠ¨é©¾é©¶ç³»ç»Ÿéƒ¨ç½²å‰çš„å¯é æ€§è¯„ä¼°æä¾›äº†é‡è¦æ”¯æŒã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.16962v1",
      "published_date": "2025-08-23 09:30:55 UTC",
      "updated_date": "2025-08-23 09:30:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:38:27.664716+00:00"
    },
    {
      "arxiv_id": "2508.16949v5",
      "title": "Breaking the Exploration Bottleneck: Rubric-Scaffolded Reinforcement Learning for General LLM Reasoning",
      "title_zh": "çªç ´æ¢ç´¢ç“¶é¢ˆï¼šé¢å‘é€šç”¨å¤§è¯­è¨€æ¨¡å‹æ¨ç†çš„é‡è¡¨æ”¯æ¶å¼å¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Yang Zhou",
        "Sunzhu Li",
        "Shunyu Liu",
        "Wenkai Fang",
        "Kongcheng Zhang",
        "Jiale Zhao",
        "Jingwen Yang",
        "Yihe Zhou",
        "Jianwei Lv",
        "Tongya Zheng",
        "Hengtong Lu",
        "Wei Chen",
        "Yan Xie",
        "Mingli Song"
      ],
      "abstract": "Recent advances in Large Language Models (LLMs) have underscored the potential of Reinforcement Learning (RL) to facilitate the emergence of reasoning capabilities. Despite the encouraging results, a fundamental dilemma persists as RL improvement relies on learning from high-quality samples, yet the exploration for such samples remains bounded by the inherent limitations of LLMs. This, in effect, creates an undesirable cycle in which what cannot be explored cannot be learned. In this work, we propose Rubric-Scaffolded Reinforcement Learning (RuscaRL), a novel instructional scaffolding framework designed to break the exploration bottleneck for general LLM reasoning. Specifically, RuscaRL introduces checklist-style rubrics as (1) explicit scaffolding for exploration during rollout generation, where different rubrics are provided as external guidance within task instructions to steer diverse high-quality responses. This guidance is gradually decayed over time, encouraging the model to internalize the underlying reasoning patterns; (2) verifiable rewards for exploitation during model training, where we can obtain robust LLM-as-a-Judge scores using rubrics as references, enabling effective RL on general reasoning tasks. Extensive experiments demonstrate the superiority of the proposed RuscaRL across various benchmarks, effectively expanding reasoning boundaries under the Best-of-N evaluation. Notably, RuscaRL significantly boosts Qwen2.5-7B-Instruct from 23.6 to 50.3 on HealthBench-500, surpassing GPT-4.1. Furthermore, our fine-tuned variant on Qwen3-30B-A3B-Instruct achieves 61.1 on HealthBench-500, outperforming leading LLMs including OpenAI-o3. Our code is available at https://github.com/IANNXANG/RuscaRL.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†RuscaRLï¼ˆRubric-Scaffolded Reinforcement Learningï¼‰ï¼Œæ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰è¿‡ç¨‹ä¸­å› æ¢ç´¢èƒ½åŠ›å—é™è€Œéš¾ä»¥è·å–é«˜è´¨é‡æ ·æœ¬çš„ç“¶é¢ˆé—®é¢˜ã€‚RuscaRLå¼•å…¥äº†æ¸…å•å¼çš„rubricsä½œä¸ºæ•™å­¦æ”¯æ¶ï¼Œåœ¨rolloutç”Ÿæˆé˜¶æ®µæä¾›æ˜¾å¼çš„å¤–éƒ¨å¼•å¯¼ä»¥äº§ç”Ÿå¤šæ ·åŒ–çš„é«˜è´¨é‡å“åº”ï¼Œå¹¶éšç€æ¨¡å‹èƒ½åŠ›çš„æå‡é€æ¸å‡å°‘å¼•å¯¼ä»¥ä¿ƒè¿›æ¨ç†æ¨¡å¼çš„å†…åŒ–ã€‚åŒæ—¶ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨rubricsä½œä¸ºå‚è€ƒï¼Œé€šè¿‡LLM-as-a-Judgeæä¾›å¯éªŒè¯çš„å¥–åŠ±ä¿¡å·ï¼Œä»è€Œåœ¨é€šç”¨æ¨ç†ä»»åŠ¡ä¸Šå®ç°æœ‰æ•ˆçš„RLè®­ç»ƒã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒRuscaRLåœ¨å¤šé¡¹åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—ä¼˜äºç°æœ‰æ¨¡å‹ï¼Œå…¶ä¸­Qwen2.5-7B-Instructåœ¨HealthBench-500ä¸Šçš„å¾—åˆ†ä»23.6æå‡è‡³50.3ï¼Œè¶…è¿‡äº†GPT-4ï¼Œä¸”å…¶åŸºäºQwen3-30B-A3B-Instructçš„å˜ä½“æ€§èƒ½ç”šè‡³è¶…è¶Šäº†OpenAI-o3ã€‚è¯¥æ–¹æ³•æœ‰æ•ˆæ‹“å±•äº†LLMsçš„æ¨ç†è¾¹ç•Œï¼Œä¸ºæå‡é€šç”¨é€»è¾‘æ¨ç†èƒ½åŠ›æä¾›äº†å¯æ‰©å±•ä¸”é«˜æ•ˆçš„æ–°é€”å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.16949v5",
      "published_date": "2025-08-23 08:47:31 UTC",
      "updated_date": "2025-10-22 16:32:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:39:13.846933+00:00"
    },
    {
      "arxiv_id": "2508.16947v1",
      "title": "Drive As You Like: Strategy-Level Motion Planning Based on A Multi-Head Diffusion Model",
      "title_zh": "éšå¿ƒæ‰€æ¬²ï¼šåŸºäºå¤šå¤´æ‰©æ•£æ¨¡å‹çš„ç­–ç•¥çº§è¿åŠ¨è§„åˆ’",
      "authors": [
        "Fan Ding",
        "Xuewen Luo",
        "Hwa Hui Tew",
        "Ruturaj Reddy",
        "Xikun Wang",
        "Junn Yong Loo"
      ],
      "abstract": "Recent advances in motion planning for autonomous driving have led to models capable of generating high-quality trajectories. However, most existing planners tend to fix their policy after supervised training, leading to consistent but rigid driving behaviors. This limits their ability to reflect human preferences or adapt to dynamic, instruction-driven demands. In this work, we propose a diffusion-based multi-head trajectory planner(M-diffusion planner). During the early training stage, all output heads share weights to learn to generate high-quality trajectories. Leveraging the probabilistic nature of diffusion models, we then apply Group Relative Policy Optimization (GRPO) to fine-tune the pre-trained model for diverse policy-specific behaviors. At inference time, we incorporate a large language model (LLM) to guide strategy selection, enabling dynamic, instruction-aware planning without switching models. Closed-loop simulation demonstrates that our post-trained planner retains strong planning capability while achieving state-of-the-art (SOTA) performance on the nuPlan val14 benchmark. Open-loop results further show that the generated trajectories exhibit clear diversity, effectively satisfying multi-modal driving behavior requirements. The code and related experiments will be released upon acceptance of the paper.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† M-diffusion plannerï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºæ‰©æ•£æ¨¡å‹(diffusion model)çš„å¤šå¤´è½¨è¿¹è§„åˆ’å™¨ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰è‡ªåŠ¨é©¾é©¶è§„åˆ’å™¨åœ¨ç›‘ç£è®­ç»ƒåè¡Œä¸ºåƒµåŒ–ã€éš¾ä»¥é€‚åº”äººç±»åå¥½æˆ–æŒ‡ä»¤é©±åŠ¨éœ€æ±‚çš„é—®é¢˜ã€‚åœ¨è®­ç»ƒåˆæœŸï¼Œæ¨¡å‹å„è¾“å‡ºå¤´é€šè¿‡å…±äº«æƒé‡å­¦ä¹ ç”Ÿæˆé«˜è´¨é‡è½¨è¿¹ï¼Œéšååˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„æ¦‚ç‡ç‰¹æ€§ï¼Œé‡‡ç”¨ Group Relative Policy Optimization (GRPO) å¯¹é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä»¥è¯±å¯¼äº§ç”Ÿå¤šæ ·åŒ–çš„ç­–ç•¥ç‰¹å®šè¡Œä¸ºã€‚åœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œç³»ç»Ÿå¼•å…¥å¤§è¯­è¨€æ¨¡å‹(LLM)æŒ‡å¯¼ç­–ç•¥é€‰æ‹©ï¼Œå®ç°äº†æ— éœ€åˆ‡æ¢æ¨¡å‹çš„åŠ¨æ€æŒ‡ä»¤æ„ŸçŸ¥è§„åˆ’ã€‚é—­ç¯ä»¿çœŸè¯æ˜è¯¥è§„åˆ’å™¨åœ¨ nuPlan val14 åŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº†æœ€å…ˆè¿›(SOTA)æ€§èƒ½ï¼Œä¸”å¼€ç¯ç»“æœæ˜¾ç¤ºç”Ÿæˆçš„è½¨è¿¹å…·æœ‰æ˜¾è‘—çš„å¤šæ ·æ€§ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæ»¡è¶³å¤šæ¨¡æ€é©¾é©¶è¡Œä¸ºçš„è¦æ±‚ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Has been submitted to AAAI 2026",
      "pdf_url": "https://arxiv.org/pdf/2508.16947v1",
      "published_date": "2025-08-23 08:33:11 UTC",
      "updated_date": "2025-08-23 08:33:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:39:14.550283+00:00"
    },
    {
      "arxiv_id": "2508.16943v1",
      "title": "HumanoidVerse: A Versatile Humanoid for Vision-Language Guided Multi-Object Rearrangement",
      "title_zh": "HumanoidVerseï¼šé¢å‘è§†è§‰-è¯­è¨€å¼•å¯¼çš„å¤šç‰©ä½“é‡æ’é€šç”¨äººå½¢æœºå™¨äºº",
      "authors": [
        "Haozhuo Zhang",
        "Jingkai Sun",
        "Michele Caprio",
        "Jian Tang",
        "Shanghang Zhang",
        "Qiang Zhang",
        "Wei Pan"
      ],
      "abstract": "We introduce HumanoidVerse, a novel framework for vision-language guided humanoid control that enables a single physically simulated robot to perform long-horizon, multi-object rearrangement tasks across diverse scenes. Unlike prior methods that operate in fixed settings with single-object interactions, our approach supports consecutive manipulation of multiple objects, guided only by natural language instructions and egocentric camera RGB observations. HumanoidVerse is trained via a multi-stage curriculum using a dual-teacher distillation pipeline, enabling fluid transitions between sub-tasks without requiring environment resets. To support this, we construct a large-scale dataset comprising 350 multi-object tasks spanning four room layouts. Extensive experiments in the Isaac Gym simulator demonstrate that our method significantly outperforms prior state-of-the-art in both task success rate and spatial precision, and generalizes well to unseen environments and instructions. Our work represents a key step toward robust, general-purpose humanoid agents capable of executing complex, sequential tasks under real-world sensory constraints. The video visualization results can be found on the project page: https://haozhuo-zhang.github.io/HumanoidVerse-project-page/.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†HumanoidVerseï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°é¢–çš„vision-languageæŒ‡å¯¼çš„äººå½¢æœºå™¨äººæ§åˆ¶æ¡†æ¶ï¼Œæ—¨åœ¨ä½¿å•ä¸ªç‰©ç†æ¨¡æ‹Ÿæœºå™¨äººèƒ½å¤Ÿåœ¨å¤šæ ·åŒ–åœºæ™¯ä¸­æ‰§è¡Œlong-horizonã€multi-object rearrangementä»»åŠ¡ã€‚è¯¥æ–¹æ³•ä»…ä¾èµ–è‡ªç„¶è¯­è¨€æŒ‡ä»¤å’Œegocentric camera RGBè§‚å¯Ÿï¼Œæ”¯æŒå¯¹å¤šä¸ªç‰©ä½“çš„è¿ç»­æ“æ§ï¼Œçªç ´äº†ä»¥å¾€ä»…é™äºå›ºå®šè®¾ç½®æˆ–å•ç‰©ä½“äº¤äº’çš„å±€é™ã€‚HumanoidVerseé‡‡ç”¨åŸºäºdual-teacher distillationæµæ°´çº¿çš„å¤šé˜¶æ®µè¯¾ç¨‹å­¦ä¹ (multi-stage curriculum)è¿›è¡Œè®­ç»ƒï¼Œå®ç°äº†å­ä»»åŠ¡é—´çš„æµç•…åˆ‡æ¢è€Œæ— éœ€ç¯å¢ƒé‡ç½®ã€‚ç ”ç©¶å›¢é˜Ÿä¸ºæ­¤æ„å»ºäº†ä¸€ä¸ªåŒ…å«è·¨è¶Šå››ç§æˆ¿é—´å¸ƒå±€ã€350ä¸ªå¤šç‰©ä½“ä»»åŠ¡çš„å¤§è§„æ¨¡æ•°æ®é›†ã€‚åœ¨Isaac Gymæ¨¡æ‹Ÿå™¨è¿›è¡Œçš„å¹¿æ³›å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä»»åŠ¡æˆåŠŸç‡å’Œç©ºé—´ç²¾åº¦ä¸Šå‡æ˜¾è‘—è¶…è¶Šäº†ç°æœ‰çš„state-of-the-artï¼Œå¹¶å¯¹æœªè§è¿‡çš„ç¯å¢ƒå’ŒæŒ‡ä»¤å±•ç°å‡ºæä½³çš„æ³›åŒ–èƒ½åŠ›ã€‚è¿™é¡¹ç ”ç©¶æ ‡å¿—ç€åœ¨ç°å®æ„Ÿå®˜çº¦æŸä¸‹æ„å»ºèƒ½å¤Ÿæ‰§è¡Œå¤æ‚åºåˆ—ä»»åŠ¡çš„é²æ£’é€šç”¨äººå½¢æ™ºèƒ½ä½“è¿ˆå‡ºäº†å…³é”®ä¸€æ­¥ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Project Page: https://haozhuo-zhang.github.io/HumanoidVerse-project-page/",
      "pdf_url": "https://arxiv.org/pdf/2508.16943v1",
      "published_date": "2025-08-23 08:23:14 UTC",
      "updated_date": "2025-08-23 08:23:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:39:15.950360+00:00"
    },
    {
      "arxiv_id": "2508.16936v2",
      "title": "THEME: Enhancing Thematic Investing with Semantic Stock Representations and Temporal Dynamics",
      "title_zh": "THEMEï¼šåŸºäºè¯­ä¹‰è‚¡ç¥¨è¡¨ç¤ºä¸æ—¶åºåŠ¨æ€å¢å¼ºä¸»é¢˜æŠ•èµ„",
      "authors": [
        "Hoyoung Lee",
        "Wonbin Ahn",
        "Suhwan Park",
        "Jaehoon Lee",
        "Minjae Kim",
        "Sungdong Yoo",
        "Taeyoon Lim",
        "Woohyung Lim",
        "Yongjae Lee"
      ],
      "abstract": "Thematic investing, which aims to construct portfolios aligned with structural trends, remains a challenging endeavor due to overlapping sector boundaries and evolving market dynamics. A promising direction is to build semantic representations of investment themes from textual data. However, despite their power, general-purpose LLM embedding models are not well-suited to capture the nuanced characteristics of financial assets, since the semantic representation of investment assets may differ fundamentally from that of general financial text. To address this, we introduce THEME, a framework that fine-tunes embeddings using hierarchical contrastive learning. THEME aligns themes and their constituent stocks using their hierarchical relationship, and subsequently refines these embeddings by incorporating stock returns. This process yields representations effective for retrieving thematically aligned assets with strong return potential. Empirical results demonstrate that THEME excels in two key areas. For thematic asset retrieval, it significantly outperforms leading large language models. Furthermore, its constructed portfolios demonstrate compelling performance. By jointly modeling thematic relationships from text and market dynamics from returns, THEME generates stock embeddings specifically tailored for a wide range of practical investment applications.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† THEME æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä¸»é¢˜æŠ•èµ„ï¼ˆThematic Investingï¼‰ä¸­å› è¡Œä¸šç•Œé™é‡å å’Œé€šç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åµŒå…¥éš¾ä»¥æ•æ‰é‡‘èèµ„äº§ç‰¹å¾è€Œå¯¼è‡´çš„éš¾é¢˜ã€‚è¯¥æ¡†æ¶é‡‡ç”¨å±‚æ¬¡åŒ–å¯¹æ¯”å­¦ä¹ ï¼ˆHierarchical Contrastive Learningï¼‰æ–¹æ³•ï¼Œé€šè¿‡å±‚çº§å…³ç³»å¯¹é½ä¸»é¢˜åŠå…¶æ„æˆè‚¡ç¥¨ï¼Œå¹¶ç»“åˆè‚¡ç¥¨æ”¶ç›Šï¼ˆStock Returnsï¼‰æ•°æ®å¯¹åµŒå…¥è¿›è¡Œè¿›ä¸€æ­¥ç²¾ç‚¼ã€‚è¿™ç§æ–¹æ³•ç”Ÿæˆçš„è¯­ä¹‰è¡¨å¾èƒ½å¤Ÿæ›´ç²¾å‡†åœ°æ£€ç´¢å‡ºä¸ç‰¹å®šä¸»é¢˜é«˜åº¦å¥‘åˆä¸”å…·å¤‡é«˜æ”¶ç›Šæ½œåŠ›çš„èµ„äº§ã€‚å®éªŒè¯æ˜ï¼ŒTHEME åœ¨ä¸»é¢˜èµ„äº§æ£€ç´¢ä»»åŠ¡ä¸­æ˜¾è‘—è¶…è¶Šäº†ç°æœ‰çš„ä¸»æµ LLM è¡¨ç°ï¼Œä¸”å…¶æ„å»ºçš„æŠ•èµ„ç»„åˆå±•ç°äº†æå…·ç«äº‰åŠ›çš„ä¸šç»©ã€‚é€šè¿‡æ•´åˆæ–‡æœ¬è¯­ä¹‰ä¸å¸‚åœºå›æŠ¥åŠ¨æ€ï¼ŒTHEME ä¸ºé‡åŒ–æŠ•èµ„å’Œèµ„äº§é…ç½®æä¾›äº†æ›´å…·é’ˆå¯¹æ€§çš„è‚¡ç¥¨è¡¨ç¤ºæ–¹æ¡ˆã€‚",
      "categories": [
        "q-fin.PM",
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "primary_category": "q-fin.PM",
      "comment": "Accepted at ACM International Conference on Information and Knowledge Management (CIKM)",
      "pdf_url": "https://arxiv.org/pdf/2508.16936v2",
      "published_date": "2025-08-23 08:05:37 UTC",
      "updated_date": "2025-08-29 08:56:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:39:16.953747+00:00"
    },
    {
      "arxiv_id": "2508.18308v1",
      "title": "CoPE: A Lightweight Complex Positional Encoding",
      "title_zh": "CoPEï¼šè½»é‡çº§å¤æ•°ä½ç½®ç¼–ç ",
      "authors": [
        "Avinash Amballa"
      ],
      "abstract": "Recent studies have demonstrated the effectiveness of position encoding in transformer architectures. By incorporating positional information, this approach provides essential guidance for modeling dependencies between elements across different sequence positions. We introduce CoPE (a lightweight Complex Positional Encoding), a novel architecture that leverages complex-valued encoding to encode both content and positional information. Our approach replaces traditional positional encodings with complex embeddings where the real part captures semantic content and the imaginary part encodes positional information. We introduce phase-aware attention in the first layer of the transformer model to capture position-dependent patterns, followed by standard attention layers for higher-levels. We show that CoPE doesn't exhibit long term decay and is compatible with linear attention. Experimental evaluation on the GLUE benchmark suggest that our approach achieves superior performance with less computational complexity, compared to RoPE, Sinusoidal and Learned positional encodings.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† CoPEï¼ˆä¸€ç§è½»é‡çº§çš„ Complex Positional Encodingï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ä¸º Transformer æ¶æ„è®¾è®¡çš„åˆ›æ–°ä½ç½®ç¼–ç æ–¹æ³•ï¼Œæ—¨åœ¨æ›´é«˜æ•ˆåœ°å»ºæ¨¡åºåˆ—å…ƒç´ é—´çš„ä¾èµ–å…³ç³»ã€‚è¯¥æ–¹æ³•é‡‡ç”¨å¤æ•°åµŒå…¥ï¼ˆcomplex-valued encodingï¼‰æ¥åŒæ—¶è¡¨ç¤ºå†…å®¹ä¸ä½ç½®ï¼Œå…¶ä¸­å®éƒ¨ç”¨äºæ•æ‰è¯­ä¹‰å†…å®¹ï¼Œè™šéƒ¨åˆ™ç”¨äºç¼–ç ä½ç½®ä¿¡æ¯ã€‚æ¶æ„åœ¨æ¨¡å‹ç¬¬ä¸€å±‚å¼•å…¥äº†ç›¸ä½æ„ŸçŸ¥æ³¨æ„åŠ›ï¼ˆphase-aware attentionï¼‰ä»¥è¯†åˆ«ç‰¹å®šä½ç½®æ¨¡å¼ï¼Œå¹¶åœ¨åç»­å±‚çº§è¡”æ¥æ ‡å‡†æ³¨æ„åŠ›æœºåˆ¶ã€‚å®éªŒè¯æ˜ CoPE ä¸ä»…ä¸å­˜åœ¨é•¿æœŸè¡°å‡é—®é¢˜ï¼Œè¿˜è¡¨ç°å‡ºä¸çº¿æ€§æ³¨æ„åŠ›ï¼ˆlinear attentionï¼‰çš„è‰¯å¥½å…¼å®¹æ€§ã€‚åœ¨ GLUE åŸºå‡†æµ‹è¯•ä¸­çš„è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œç›¸è¾ƒäº RoPEã€Sinusoidal å’Œ Learned positional encodingsï¼ŒCoPE åœ¨é™ä½è®¡ç®—å¤æ‚åº¦çš„åŒæ—¶å®ç°äº†æ›´ä¼˜çš„æ€§èƒ½è¡¨ç°ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.18308v1",
      "published_date": "2025-08-23 08:02:07 UTC",
      "updated_date": "2025-08-23 08:02:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:39:20.751083+00:00"
    },
    {
      "arxiv_id": "2508.16931v1",
      "title": "Degree of Staleness-Aware Data Updating in Federated Learning",
      "title_zh": "è”é‚¦å­¦ä¹ ä¸­æ„ŸçŸ¥é™ˆæ—§ç¨‹åº¦çš„æ•°æ®æ›´æ–°",
      "authors": [
        "Tao Liu",
        "Xuehe Wang"
      ],
      "abstract": "Handling data staleness remains a significant challenge in federated learning with highly time-sensitive tasks, where data is generated continuously and data staleness largely affects model performance. Although recent works attempt to optimize data staleness by determining local data update frequency or client selection strategy, none of them explore taking both data staleness and data volume into consideration. In this paper, we propose DUFL(Data Updating in Federated Learning), an incentive mechanism featuring an innovative local data update scheme manipulated by three knobs: the server's payment, outdated data conservation rate, and clients' fresh data collection volume, to coordinate staleness and volume of local data for best utilities. To this end, we introduce a novel metric called DoS(the Degree of Staleness) to quantify data staleness and conduct a theoretic analysis illustrating the quantitative relationship between DoS and model performance. We model DUFL as a two-stage Stackelberg game with dynamic constraint, deriving the optimal local data update strategy for each client in closed-form and the approximately optimal strategy for the server. Experimental results on real-world datasets demonstrate the significant performance of our approach.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é«˜åº¦æ—¶é—´æ•æ„Ÿçš„è”é‚¦å­¦ä¹ (Federated Learning)ä»»åŠ¡ä¸­æ•°æ®é™ˆæ—§æ€§(Data Staleness)ä¸¥é‡å½±å“æ¨¡å‹æ€§èƒ½çš„é—®é¢˜ï¼Œæå‡ºäº†DUFL(Data Updating in Federated Learning)æ¿€åŠ±æœºåˆ¶ã€‚è¯¥æœºåˆ¶åˆ›æ–°åœ°é€šè¿‡æœåŠ¡å™¨æ”¯ä»˜ã€è¿‡æœŸæ•°æ®ä¿ç•™ç‡å’Œæ–°é²œæ•°æ®é‡‡é›†é‡ä¸‰ä¸ªå˜é‡æ¥åè°ƒæœ¬åœ°æ•°æ®çš„é™ˆæ—§æ€§ä¸æ•°æ®é‡(Data Volume)ï¼Œä»¥å®ç°æ•ˆç”¨æœ€å¤§åŒ–ã€‚ç ”ç©¶å¼•å…¥äº†æ–°æŒ‡æ ‡é™ˆæ—§ç¨‹åº¦(Degree of Staleness, DoS)æ¥é‡åŒ–æ•°æ®é™ˆæ—§æ€§ï¼Œå¹¶ä»ç†è®ºä¸Šé˜æ˜äº†DoSä¸æ¨¡å‹æ€§èƒ½ä¹‹é—´çš„å®šé‡å…³ç³»ã€‚é€šè¿‡å°†DUFLå»ºæ¨¡ä¸ºå…·æœ‰åŠ¨æ€çº¦æŸçš„ä¸¤é˜¶æ®µStackelberg gameï¼Œç ”ç©¶å¾—å‡ºäº†å®¢æˆ·ç«¯çš„é—­å¼æœ€ä¼˜ç­–ç•¥åŠæœåŠ¡å™¨çš„è¿‘ä¼¼æœ€ä¼˜ç­–ç•¥ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨çœŸå®æ•°æ®é›†ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä¸ºä¼˜åŒ–è”é‚¦å­¦ä¹ ä¸­çš„æ•°æ®æ—¶æ•ˆæ€§æä¾›äº†æœ‰åŠ›æ”¯æ’‘ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "accepted by European Conference on Artificial Intelligence",
      "pdf_url": "https://arxiv.org/pdf/2508.16931v1",
      "published_date": "2025-08-23 07:31:39 UTC",
      "updated_date": "2025-08-23 07:31:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:41:09.048751+00:00"
    },
    {
      "arxiv_id": "2508.16926v1",
      "title": "TextOnly: A Unified Function Portal for Text-Related Functions on Smartphones",
      "title_zh": "TextOnlyï¼šé¢å‘æ™ºèƒ½æ‰‹æœºæ–‡æœ¬ç›¸å…³åŠŸèƒ½çš„ç»Ÿä¸€åŠŸèƒ½é—¨æˆ·",
      "authors": [
        "Minghao Tu",
        "Chun Yu",
        "Xiyuan Shen",
        "Zhi Zheng",
        "Li Chen",
        "Yuanchun Shi"
      ],
      "abstract": "Text boxes serve as portals to diverse functionalities in today's smartphone applications. However, when it comes to specific functionalities, users always need to navigate through multiple steps to access particular text boxes for input. We propose TextOnly, a unified function portal that enables users to access text-related functions from various applications by simply inputting text into a sole text box. For instance, entering a restaurant name could trigger a Google Maps search, while a greeting could initiate a conversation in WhatsApp. Despite their brevity, TextOnly maximizes the utilization of these raw text inputs, which contain rich information, to interpret user intentions effectively. TextOnly integrates large language models(LLM) and a BERT model. The LLM consistently provides general knowledge, while the BERT model can continuously learn user-specific preferences and enable quicker predictions. Real-world user studies demonstrated TextOnly's effectiveness with a top-1 accuracy of 71.35%, and its ability to continuously improve both its accuracy and inference speed. Participants perceived TextOnly as having satisfactory usability and expressed a preference for TextOnly over manual executions. Compared with voice assistants, TextOnly supports a greater range of text-related functions and allows for more concise inputs.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†TextOnlyï¼Œä¸€ç§é¢å‘æ™ºèƒ½æ‰‹æœºæ–‡æœ¬ç›¸å…³åŠŸèƒ½çš„ç»Ÿä¸€åŠŸèƒ½å…¥å£(Unified Function Portal)ï¼Œæ—¨åœ¨è§£å†³ç”¨æˆ·åœ¨è°ƒç”¨ä¸åŒåº”ç”¨åŠŸèƒ½æ—¶éœ€ç»å†å¤šæ­¥å¯¼èˆªçš„ç—›ç‚¹ã€‚TextOnlyå…è®¸ç”¨æˆ·åœ¨å•ä¸€æ–‡æœ¬æ¡†å†…è¾“å…¥åŸå§‹æ–‡æœ¬ï¼Œç³»ç»Ÿé€šè¿‡è§£æç”¨æˆ·æ„å›¾ç›´æ¥è§¦å‘è·¨åº”ç”¨çš„ç‰¹å®šåŠŸèƒ½ï¼Œå¦‚é€šè¿‡è¾“å…¥é¤å…åç§°è§¦å‘Google Mapsæœç´¢æˆ–è¾“å…¥é—®å€™è¯­å¯åŠ¨WhatsAppä¼šè¯ã€‚è¯¥æ¶æ„é›†æˆäº†å¤§è¯­è¨€æ¨¡å‹(LLM)ä»¥è·å–é€šç”¨çŸ¥è¯†ï¼Œå¹¶ç»“åˆBERTæ¨¡å‹æ¥æŒç»­å­¦ä¹ ç”¨æˆ·åå¥½å¹¶åŠ é€Ÿæ¨ç†è¿‡ç¨‹ã€‚çœŸå®ä¸–ç•Œç”¨æˆ·ç ”ç©¶æ˜¾ç¤ºï¼ŒTextOnlyå®ç°äº†71.35%çš„é¦–é€‰å‡†ç¡®ç‡(Top-1 Accuracy)ï¼Œä¸”åœ¨å¯ç”¨æ€§å’Œæ“ä½œæ•ˆç‡ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ‰‹åŠ¨æ‰§è¡Œå’Œè¯­éŸ³åŠ©æ‰‹ã€‚å®éªŒè¯æ˜TextOnlyèƒ½å¤Ÿæœ‰æ•ˆæœ€å¤§åŒ–åŸå§‹æ–‡æœ¬è¾“å…¥çš„åˆ©ç”¨ç‡ï¼Œä¸ºç§»åŠ¨ç«¯å¤šåŠŸèƒ½äº¤äº’æä¾›äº†ä¸€ç§æ›´ç®€æ´ä¸”å¯è¿›åŒ–çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "27 pages, 9 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.16926v1",
      "published_date": "2025-08-23 07:17:02 UTC",
      "updated_date": "2025-08-23 07:17:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:39:46.247311+00:00"
    },
    {
      "arxiv_id": "2508.16905v2",
      "title": "Tri-Accel: Curvature-Aware Precision-Adaptive and Memory-Elastic Optimization for Efficient GPU Usage",
      "title_zh": "Tri-Accelï¼šé¢å‘é«˜æ•ˆ GPU åˆ©ç”¨çš„æ›²ç‡æ„ŸçŸ¥ã€ç²¾åº¦è‡ªé€‚åº”ä¸å†…å­˜å¼¹æ€§ä¼˜åŒ–",
      "authors": [
        "Mohsen Sheibanian",
        "Pouya Shaeri",
        "Alimohammad Beigi",
        "Ryan T. Woo",
        "Aryan Keluskar"
      ],
      "abstract": "Deep neural networks are increasingly bottlenecked by the cost of optimization, both in terms of GPU memory and compute time. Existing acceleration techniques, such as mixed precision, second-order methods, and batch size scaling, are typically used in isolation. We present Tri-Accel, a unified optimization framework that co-adapts three acceleration strategies along with adaptive parameters during training: (1) Precision-Adaptive Updates that dynamically assign mixed-precision levels to layers based on curvature and gradient variance; (2) Sparse Second-Order Signals that exploit Hessian/Fisher sparsity patterns to guide precision and step size decisions; and (3) Memory-Elastic Batch Scaling that adjusts batch size in real time according to VRAM availability. On CIFAR-10 with ResNet-18 and EfficientNet-B0, Tri-Accel achieves up to 9.9% reduction in training time and 13.3% lower memory usage, while improving accuracy by +1.1 percentage points over FP32 baselines. Tested on CIFAR-10/100, our approach demonstrates adaptive learning behavior, with efficiency gradually improving over the course of training as the system learns to allocate resources more effectively. Compared to static mixed-precision training, Tri-Accel maintains 78.1% accuracy while reducing memory footprint from 0.35GB to 0.31GB on standard hardware. The framework is implemented with custom Triton kernels, whose hardware-aware adaptation enables automatic optimization without manual hyperparameter tuning, making it practical for deployment across diverse computational environments. This work demonstrates how algorithmic adaptivity and hardware awareness can be combined to improve scalability in resource-constrained settings, paving the way for more efficient neural network training on edge devices and cost-sensitive cloud deployments.",
      "tldr_zh": "é’ˆå¯¹æ·±åº¦ç¥ç»ç½‘ç»œä¼˜åŒ–ä¸­é¢ä¸´çš„ GPU æ˜¾å­˜å’Œè®¡ç®—æ—¶é—´ç“¶é¢ˆï¼Œè¯¥ç ”ç©¶æå‡ºäº† Tri-Accel ç»Ÿä¸€ä¼˜åŒ–æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡ç®—æ³•è‡ªé€‚åº”æ€§æå‡ GPU åˆ©ç”¨ç‡ã€‚è¯¥æ¡†æ¶ååŒé›†æˆäº†ä¸‰ç§æ ¸å¿ƒåŠ é€Ÿç­–ç•¥ï¼šåŸºäºæ›²ç‡å’Œæ¢¯åº¦æ–¹å·®åŠ¨æ€åˆ†é…æ··åˆç²¾åº¦çš„ Precision-Adaptive Updatesï¼Œåˆ©ç”¨ Hessian/Fisher ç¨€ç–æ¨¡å¼æŒ‡å¯¼å†³ç­–çš„ Sparse Second-Order Signalsï¼Œä»¥åŠæ ¹æ®æ˜¾å­˜å¯ç”¨æ€§å®æ—¶è°ƒæ•´æ‰¹æ¬¡å¤§å°çš„ Memory-Elastic Batch Scalingã€‚Tri-Accel é‡‡ç”¨è‡ªå®šä¹‰çš„ Triton å†…æ ¸å®ç°ï¼Œå…¶ç¡¬ä»¶æ„ŸçŸ¥ç‰¹æ€§å®ç°äº†è‡ªåŠ¨ä¼˜åŒ–è€Œæ— éœ€æ‰‹åŠ¨è°ƒèŠ‚è¶…å‚æ•°ï¼Œå…·æœ‰æå¼ºçš„å®ç”¨æ€§ã€‚åœ¨ ResNet-18 å’Œ EfficientNet-B0 ç­‰æ¨¡å‹ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒTri-Accel ç›¸æ¯” FP32 åŸºçº¿å‡å°‘äº† 9.9% çš„è®­ç»ƒæ—¶é—´å’Œ 13.3% çš„å†…å­˜å ç”¨ï¼ŒåŒæ—¶å°†å‡†ç¡®ç‡æå‡äº† 1.1 ä¸ªç™¾åˆ†ç‚¹ã€‚åœ¨é•¿æœŸçš„è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œè¯¥ç³»ç»Ÿèƒ½å¤Ÿé€šè¿‡å­¦ä¹ æ›´æœ‰æ•ˆåœ°åˆ†é…èµ„æºï¼ŒæŒç»­ä¼˜åŒ–æ•ˆç‡ã€‚è¯¥ç ”ç©¶è¯æ˜äº†ç»“åˆç®—æ³•è‡ªé€‚åº”ä¸ç¡¬ä»¶æ„ŸçŸ¥èƒ½å¤Ÿæ˜¾è‘—æ”¹å–„èµ„æºå—é™åœºæ™¯ä¸‹çš„å¯æ‰©å±•æ€§ï¼Œä¸ºè¾¹ç¼˜è®¾å¤‡å’Œæˆæœ¬æ•æ„Ÿå‹äº‘éƒ¨ç½²çš„é«˜æ•ˆæ¨¡å‹è®­ç»ƒå¼€è¾Ÿäº†æ–°è·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.16905v2",
      "published_date": "2025-08-23 05:38:42 UTC",
      "updated_date": "2025-08-30 01:28:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:39:33.595267+00:00"
    },
    {
      "arxiv_id": "2508.18306v1",
      "title": "SALMAN: Stability Analysis of Language Models Through the Maps Between Graph-based Manifolds",
      "title_zh": "SALMANï¼šåŸºäºå›¾æµå½¢æ˜ å°„çš„è¯­è¨€æ¨¡å‹ç¨³å®šæ€§åˆ†æ",
      "authors": [
        "Wuxinlin Cheng",
        "Yupeng Cao",
        "Jinwen Wu",
        "Koduvayur Subbalakshmi",
        "Tian Han",
        "Zhuo Feng"
      ],
      "abstract": "Recent strides in pretrained transformer-based language models have propelled state-of-the-art performance in numerous NLP tasks. Yet, as these models grow in size and deployment, their robustness under input perturbations becomes an increasingly urgent question. Existing robustness methods often diverge between small-parameter and large-scale models (LLMs), and they typically rely on labor-intensive, sample-specific adversarial designs. In this paper, we propose a unified, local (sample-level) robustness framework (SALMAN) that evaluates model stability without modifying internal parameters or resorting to complex perturbation heuristics. Central to our approach is a novel Distance Mapping Distortion (DMD) measure, which ranks each sample's susceptibility by comparing input-to-output distance mappings in a near-linear complexity manner. By demonstrating significant gains in attack efficiency and robust training, we position our framework as a practical, model-agnostic tool for advancing the reliability of transformer-based NLP systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é¢„è®­ç»ƒ Transformer è¯­è¨€æ¨¡å‹åœ¨é¢ä¸´è¾“å…¥æ‰°åŠ¨æ—¶çš„é²æ£’æ€§æŒ‘æˆ˜ï¼Œæå‡ºäº†åä¸º SALMAN çš„ç»Ÿä¸€å±€éƒ¨é²æ£’æ€§è¯„ä¼°æ¡†æ¶ã€‚è¯¥æ¡†æ¶æ— éœ€ä¿®æ”¹æ¨¡å‹å†…éƒ¨å‚æ•°æˆ–ä¾èµ–å¤æ‚çš„æ‰°åŠ¨å¯å‘å¼æ–¹æ³•ï¼Œå³å¯åœ¨æ ·æœ¬å±‚é¢è¯„ä¼°æ¨¡å‹çš„ç¨³å®šæ€§ã€‚å…¶æ ¸å¿ƒåœ¨äºå¼•å…¥äº†ä¸€ç§åä¸º Distance Mapping Distortion (DMD) çš„æ–°é¢–åº¦é‡æŒ‡æ ‡ï¼Œé€šè¿‡è¿‘çº¿æ€§å¤æ‚åº¦çš„è®¡ç®—æ¥æ¯”è¾ƒè¾“å…¥ä¸è¾“å‡ºä¹‹é—´çš„è·ç¦»æ˜ å°„ï¼Œä»è€Œè¯†åˆ«æ ·æœ¬çš„æ˜“æ„Ÿæ€§ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒSALMAN åœ¨æå‡æ”»å‡»æ•ˆç‡å’Œå¢å¼ºé²æ£’è®­ç»ƒæ–¹é¢å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚ä½œä¸ºä¸€ç§æ¨¡å‹æ— å…³ (model-agnostic) çš„å®ç”¨å·¥å…·ï¼Œè¯¥æ¡†æ¶ä¸ºæ¨åŠ¨ Transformer ç³»ç»Ÿåœ¨ NLP ä»»åŠ¡ä¸­çš„å¯é æ€§æä¾›äº†é‡è¦æ”¯æŒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.18306v1",
      "published_date": "2025-08-23 02:50:55 UTC",
      "updated_date": "2025-08-23 02:50:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:39:39.593020+00:00"
    },
    {
      "arxiv_id": "2508.16876v3",
      "title": "Dream to Chat: Model-based Reinforcement Learning on Dialogues with User Belief Modeling",
      "title_zh": "Dream to Chatï¼šç»“åˆç”¨æˆ·ä¿¡å¿µå»ºæ¨¡çš„å¯¹è¯å¼åŸºäºæ¨¡å‹å¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Yue Zhao",
        "Xiaoyu Wang",
        "Dan Wang",
        "Zhonglin Jiang",
        "Qingqing Gu",
        "Teng Chen",
        "Ningyuan Xi",
        "Jinxian Qu",
        "Yong Chen",
        "Luo Ji"
      ],
      "abstract": "World models have been widely utilized in robotics, gaming, and auto-driving. However, their applications on natural language tasks are relatively limited. In this paper, we construct the dialogue world model, which could predict the user's emotion, sentiment, and intention, and future utterances. By defining a POMDP, we argue emotion, sentiment and intention can be modeled as the user belief and solved by maximizing the information bottleneck. By this user belief modeling, we apply the model-based reinforcement learning framework to the dialogue system, and propose a framework called DreamCUB. Experiments show that the pretrained dialogue world model can achieve state-of-the-art performances on emotion classification and sentiment identification, while dialogue quality is also enhanced by joint training of the policy, critic and dialogue world model. Further analysis shows that this manner holds a reasonable exploration-exploitation balance and also transfers well to out-of-domain scenarios such as empathetic dialogues.",
      "tldr_zh": "è¯¥ç ”ç©¶æ„å»ºäº†ä¸€ä¸ªå¯¹è¯ä¸–ç•Œæ¨¡å‹ (dialogue world model)ï¼Œæ—¨åœ¨è§£å†³ä¸–ç•Œæ¨¡å‹åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­åº”ç”¨å—é™çš„é—®é¢˜ã€‚ä½œè€…é€šè¿‡å®šä¹‰éƒ¨åˆ†å¯è§‚æµ‹é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ (POMDP)ï¼Œå°†ç”¨æˆ·çš„æƒ…ç»ªã€æƒ…æ„Ÿå’Œæ„å›¾å»ºæ¨¡ä¸ºç”¨æˆ·ä¿¡å¿µ (user belief)ï¼Œå¹¶åˆ©ç”¨ä¿¡æ¯ç“¶é¢ˆ (information bottleneck) æœ€å¤§åŒ–æ¥æ±‚è§£ã€‚åŸºäºè¯¥å»ºæ¨¡æ–¹æ³•ï¼Œç ”ç©¶æå‡ºäº†ä¸€ç§åä¸º DreamCUB çš„åŸºäºæ¨¡å‹çš„å¼ºåŒ–å­¦ä¹  (model-based reinforcement learning) æ¡†æ¶ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥é¢„è®­ç»ƒæ¨¡å‹åœ¨æƒ…ç»ªåˆ†ç±»å’Œæƒ…æ„Ÿè¯†åˆ«ä»»åŠ¡ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿› (SOTA) æ€§èƒ½ï¼Œä¸”é€šè¿‡ç­–ç•¥ã€è¯„è®ºå®¶ä¸ä¸–ç•Œæ¨¡å‹çš„è”åˆè®­ç»ƒæ˜¾è‘—æå‡äº†å¯¹è¯è´¨é‡ã€‚åˆ†æè¿˜è¡¨æ˜ DreamCUB åœ¨æ¢ç´¢ä¸åˆ©ç”¨ (exploration-exploitation) ä¹‹é—´å®ç°äº†è‰¯å¥½å¹³è¡¡ï¼Œå¹¶å±•ç°å‡ºä¼˜ç§€çš„åŸŸå¤–è¿ç§»èƒ½åŠ›ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EMNLP 2025 Findings",
      "pdf_url": "https://arxiv.org/pdf/2508.16876v3",
      "published_date": "2025-08-23 02:24:03 UTC",
      "updated_date": "2025-09-26 02:30:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:39:46.456804+00:00"
    },
    {
      "arxiv_id": "2508.18304v1",
      "title": "scI2CL: Effectively Integrating Single-cell Multi-omics by Intra- and Inter-omics Contrastive Learning",
      "title_zh": "scI2CLï¼šé€šè¿‡ç»„å­¦å†…ä¸ç»„å­¦é—´å¯¹æ¯”å­¦ä¹ æœ‰æ•ˆæ•´åˆå•ç»†èƒå¤šç»„å­¦",
      "authors": [
        "Wuchao Liu",
        "Han Peng",
        "Wengen Li",
        "Yichao Zhang",
        "Jihong Guan",
        "Shuigeng Zhou"
      ],
      "abstract": "Single-cell multi-omics data contain huge information of cellular states, and analyzing these data can reveal valuable insights into cellular heterogeneity, diseases, and biological processes. However, as cell differentiation \\& development is a continuous and dynamic process, it remains challenging to computationally model and infer cell interaction patterns based on single-cell multi-omics data. This paper presents scI2CL, a new single-cell multi-omics fusion framework based on intra- and inter-omics contrastive learning, to learn comprehensive and discriminative cellular representations from complementary multi-omics data for various downstream tasks. Extensive experiments of four downstream tasks validate the effectiveness of scI2CL and its superiority over existing peers. Concretely, in cell clustering, scI2CL surpasses eight state-of-the-art methods on four widely-used real-world datasets. In cell subtyping, scI2CL effectively distinguishes three latent monocyte cell subpopulations, which are not discovered by existing methods. Simultaneously, scI2CL is the only method that correctly constructs the cell developmental trajectory from hematopoietic stem and progenitor cells to Memory B cells. In addition, scI2CL resolves the misclassification of cell types between two subpopulations of CD4+ T cells, while existing methods fail to precisely distinguish the mixed cells. In summary, scI2CL can accurately characterize cross-omics relationships among cells, thus effectively fuses multi-omics data and learns discriminative cellular representations to support various downstream analysis tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†scI2CLï¼Œä¸€ç§åŸºäºç»„å­¦å†…å’Œç»„å­¦é—´å¯¹æ¯”å­¦ä¹ (Intra- and Inter-omics Contrastive Learning)çš„æ–°å‹å•ç»†èƒå¤šç»„å­¦èåˆæ¡†æ¶ï¼Œæ—¨åœ¨ä»äº’è¡¥çš„å¤šç»„å­¦æ•°æ®ä¸­å­¦ä¹ å…¨é¢ä¸”å…·æœ‰è¾¨åˆ«åŠ›çš„ç»†èƒè¡¨ç¤º(Cellular Representations)ã€‚ä¸ºäº†åº”å¯¹ç»†èƒåˆ†åŒ–ä¸å‘è‚²è¿™ä¸€è¿ç»­åŠ¨æ€è¿‡ç¨‹ä¸­çš„å»ºæ¨¡æŒ‘æˆ˜ï¼ŒscI2CLé€šè¿‡æ•æ‰å¤æ‚çš„è·¨ç»„å­¦å…³ç³»ï¼Œåœ¨å¤šé¡¹ä¸‹æ¸¸ä»»åŠ¡ä¸­å±•ç°å‡ºæ˜¾è‘—ä¼˜åŠ¿ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨ç»†èƒèšç±»(Cell Clustering)ä»»åŠ¡ä¸Šä¼˜äºå…«ç§æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œå¹¶æˆåŠŸè¯†åˆ«äº†ç°æœ‰æ–¹æ³•æœªèƒ½å‘ç°çš„ä¸‰ç§æ½œåœ¨å•æ ¸ç»†èƒäºšç¾¤ã€‚åŒæ—¶ï¼ŒscI2CLæ˜¯å”¯ä¸€èƒ½å¤Ÿå‡†ç¡®æ„å»ºä»é€ è¡€å¹²ç¥–ç»†èƒåˆ°è®°å¿†Bç»†èƒçš„å‘è‚²è½¨è¿¹(Cell Developmental Trajectory)çš„æ–¹æ³•ï¼Œå¹¶æœ‰æ•ˆè§£å†³äº†CD4+ Tç»†èƒäºšç¾¤é—´çš„è¯¯åˆ†ç±»é—®é¢˜ã€‚ç»¼ä¸Šæ‰€è¿°ï¼ŒscI2CLé€šè¿‡æœ‰æ•ˆèåˆå¤šç»„å­¦æ•°æ®å¹¶å­¦ä¹ åˆ¤åˆ«æ€§ç‰¹å¾ï¼Œä¸ºè§£æç»†èƒå¼‚è´¨æ€§åŠå¤æ‚çš„ç”Ÿç‰©å­¦è¿‡ç¨‹æä¾›äº†å¼ºæœ‰åŠ›çš„æ”¯æŒã€‚",
      "categories": [
        "q-bio.GN",
        "cs.AI",
        "cs.LG",
        "q-bio.CB"
      ],
      "primary_category": "q-bio.GN",
      "comment": "22 pages, 6figures",
      "pdf_url": "https://arxiv.org/pdf/2508.18304v1",
      "published_date": "2025-08-23 01:42:28 UTC",
      "updated_date": "2025-08-23 01:42:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:41:21.153528+00:00"
    },
    {
      "arxiv_id": "2508.16860v1",
      "title": "TriagerX: Dual Transformers for Bug Triaging Tasks with Content and Interaction Based Rankings",
      "title_zh": "TriagerXï¼šåŸºäºå†…å®¹ä¸äº¤äº’æ’åçš„åŒ Transformer ç¼ºé™·åˆ†æ´¾æ¨¡å‹",
      "authors": [
        "Md Afif Al Mamun",
        "Gias Uddin",
        "Lan Xia",
        "Longyu Zhang"
      ],
      "abstract": "Pretrained Language Models or PLMs are transformer-based architectures that can be used in bug triaging tasks. PLMs can better capture token semantics than traditional Machine Learning (ML) models that rely on statistical features (e.g., TF-IDF, bag of words). However, PLMs may still attend to less relevant tokens in a bug report, which can impact their effectiveness. In addition, the model can be sub-optimal with its recommendations when the interaction history of developers around similar bugs is not taken into account. We designed TriagerX to address these limitations. First, to assess token semantics more reliably, we leverage a dual-transformer architecture. Unlike current state-of-the-art (SOTA) baselines that employ a single transformer architecture, TriagerX collects recommendations from two transformers with each offering recommendations via its last three layers. This setup generates a robust content-based ranking of candidate developers. TriagerX then refines this ranking by employing a novel interaction-based ranking methodology, which considers developers' historical interactions with similar fixed bugs. Across five datasets, TriagerX surpasses all nine transformer-based methods, including SOTA baselines, often improving Top-1 and Top-3 developer recommendation accuracy by over 10%. We worked with our large industry partner to successfully deploy TriagerX in their development environment. The partner required both developer and component recommendations, with components acting as proxies for team assignments-particularly useful in cases of developer turnover or team changes. We trained TriagerX on the partner's dataset for both tasks, and it outperformed SOTA baselines by up to 10% for component recommendations and 54% for developer recommendations.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹(PLMs)åœ¨ç¼ºé™·åˆ†æ‹£(Bug Triaging)ä»»åŠ¡ä¸­å®¹æ˜“å—åˆ°æ— å…³Tokenå¹²æ‰°ä¸”å¿½è§†äº¤äº’å†å²çš„é—®é¢˜ï¼Œæå‡ºäº†TriagerXæ¡†æ¶ã€‚è¯¥æ¡†æ¶é‡‡ç”¨äº†ç‹¬ç‰¹çš„åŒTransformeræ¶æ„(Dual-Transformer Architecture)ï¼Œåˆ©ç”¨ä¸¤ä¸ªæ¨¡å‹æœ€åä¸‰å±‚çš„è¾“å‡ºç”Ÿæˆé²æ£’çš„åŸºäºå†…å®¹çš„å€™é€‰å¼€å‘è€…æ’åã€‚TriagerXè¿›ä¸€æ­¥å¼•å…¥äº†åŸºäºäº¤äº’çš„æ’åºæ–¹æ³•ï¼Œé€šè¿‡åˆ†æå¼€å‘è€…ä¸ç›¸ä¼¼å·²ä¿®å¤ç¼ºé™·çš„å†å²äº¤äº’è®°å½•æ¥ä¼˜åŒ–æ¨èç»“æœã€‚åœ¨äº”ä¸ªå…¬å¼€æ•°æ®é›†çš„æµ‹è¯•ä¸­ï¼ŒTriagerXåœ¨Top-1å’ŒTop-3å‡†ç¡®ç‡ä¸Šæ™®éæ¯”ç°æœ‰SOTAåŸºçº¿æå‡äº†10%ä»¥ä¸Šã€‚æ­¤å¤–ï¼Œè¯¥ç³»ç»Ÿå·²æˆåŠŸéƒ¨ç½²äºå¤§å‹å·¥ä¸šåˆä½œä¼™ä¼´çš„å¼€å‘ç¯å¢ƒï¼Œåœ¨ç»„ä»¶æ¨èå’Œå¼€å‘è€…æ¨èä»»åŠ¡ä¸­åˆ†åˆ«å®ç°äº†10%å’Œ54%çš„æ€§èƒ½æå‡ï¼Œæœ‰æ•ˆè§£å†³äº†å›¢é˜Ÿå˜æ›´å’Œäººå‘˜æµåŠ¨å¸¦æ¥çš„æŒ‘æˆ˜ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "This work is currently under review at IEEE Transactions on Software Engineering. The replication package will be made publicly available upon acceptance",
      "pdf_url": "https://arxiv.org/pdf/2508.16860v1",
      "published_date": "2025-08-23 01:10:42 UTC",
      "updated_date": "2025-08-23 01:10:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:41:30.161377+00:00"
    },
    {
      "arxiv_id": "2508.16858v1",
      "title": "WildSpoof Challenge Evaluation Plan",
      "title_zh": "WildSpoof æŒ‘æˆ˜èµ›æµ‹è¯„æ–¹æ¡ˆ",
      "authors": [
        "Yihan Wu",
        "Jee-weon Jung",
        "Hye-jin Shim",
        "Xin Cheng",
        "Xin Wang"
      ],
      "abstract": "The WildSpoof Challenge aims to advance the use of in-the-wild data in two intertwined speech processing tasks. It consists of two parallel tracks: (1) Text-to-Speech (TTS) synthesis for generating spoofed speech, and (2) Spoofing-robust Automatic Speaker Verification (SASV) for detecting spoofed speech. While the organizers coordinate both tracks and define the data protocols, participants treat them as separate and independent tasks. The primary objectives of the challenge are: (i) to promote the use of in-the-wild data for both TTS and SASV, moving beyond conventional clean and controlled datasets and considering real-world scenarios; and (ii) to encourage interdisciplinary collaboration between the spoofing generation (TTS) and spoofing detection (SASV) communities, thereby fostering the development of more integrated, robust, and realistic systems.",
      "tldr_zh": "WildSpoof Challenge æ—¨åœ¨æ¨åŠ¨ in-the-wild æ•°æ®åœ¨è¯­éŸ³å¤„ç†ä»»åŠ¡ä¸­çš„åº”ç”¨ï¼Œä¸»è¦åŒ…å«ä¸¤ä¸ªå¹¶è¡Œçš„èµ›é“ï¼šç”¨äºç”Ÿæˆä¼ªé€ è¯­éŸ³çš„ Text-to-Speech (TTS) åˆæˆä»¥åŠç”¨äºæ£€æµ‹ä¼ªé€ è¯­éŸ³çš„ Spoofing-robust Automatic Speaker Verification (SASV)ã€‚è¯¥æŒ‘æˆ˜èµ›è¦æ±‚å‚ä¸è€…å°†è¿™ä¸¤ä¸ªä»»åŠ¡è§†ä¸ºç‹¬ç«‹çš„ç ”ç©¶æ–¹å‘ï¼Œç”±ç»„ç»‡è€…ç»Ÿä¸€å®šä¹‰æ•°æ®åè®®ã€‚å…¶æ ¸å¿ƒç›®æ ‡æ˜¯ä¿ƒä½¿ç ”ç©¶ä»ä¼ ç»Ÿçš„æ¸…æ´å—æ§æ•°æ®é›†è½¬å‘å¤æ‚çš„ real-world åœºæ™¯ï¼Œæå‡è¯­éŸ³ç³»ç»Ÿåœ¨ç°å®ç¯å¢ƒä¸‹çš„è¡¨ç°ã€‚æ­¤å¤–ï¼Œè¯¥è®¡åˆ’å¼ºè°ƒä¼ªé€ ç”Ÿæˆ (TTS) ä¸ä¼ªé€ æ£€æµ‹ (SASV) ç¤¾åŒºä¹‹é—´çš„è·¨å­¦ç§‘åä½œï¼Œæ—¨åœ¨é€šè¿‡æŠ€æœ¯èåˆæå‡ç³»ç»Ÿçš„æ•´ä½“é›†æˆåº¦ã€é²æ£’æ€§ä¸çœŸå®æ„Ÿã€‚",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "comment": "ICASSP 2026 challenge",
      "pdf_url": "https://arxiv.org/pdf/2508.16858v1",
      "published_date": "2025-08-23 01:08:24 UTC",
      "updated_date": "2025-08-23 01:08:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:41:32.854596+00:00"
    },
    {
      "arxiv_id": "2508.16856v1",
      "title": "A Workflow for Map Creation in Autonomous Vehicle Simulations",
      "title_zh": "è‡ªåŠ¨é©¾é©¶ä»¿çœŸä¸­çš„åœ°å›¾æ„å»ºå·¥ä½œæµ",
      "authors": [
        "Zubair Islam",
        "Ahmaad Ansari",
        "George Daoud",
        "Mohamed El-Darieby"
      ],
      "abstract": "The fast development of technology and artificial intelligence has significantly advanced Autonomous Vehicle (AV) research, emphasizing the need for extensive simulation testing. Accurate and adaptable maps are critical in AV development, serving as the foundation for localization, path planning, and scenario testing. However, creating simulation-ready maps is often difficult and resource-intensive, especially with simulators like CARLA (CAR Learning to Act). Many existing workflows require significant computational resources or rely on specific simulators, limiting flexibility for developers. This paper presents a custom workflow to streamline map creation for AV development, demonstrated through the generation of a 3D map of a parking lot at Ontario Tech University. Future work will focus on incorporating SLAM technologies, optimizing the workflow for broader simulator compatibility, and exploring more flexible handling of latitude and longitude values to enhance map generation accuracy.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è‡ªåŠ¨é©¾é©¶è½¦è¾† Autonomous Vehicle (AV) å¼€å‘ä¸­é«˜ç²¾åº¦ä»¿çœŸåœ°å›¾åˆ›å»ºè¿‡ç¨‹å¤æ‚ä¸”è€—è´¹èµ„æºçš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§è‡ªå®šä¹‰çš„å·¥ä½œæµã€‚ç°æœ‰çš„åœ°å›¾ç”Ÿæˆæ–¹æ³•å¾€å¾€é«˜åº¦ä¾èµ–ç‰¹å®šæ¨¡æ‹Ÿå™¨ï¼ˆå¦‚ CARLAï¼‰æˆ–æ¶ˆè€—å¤§é‡è®¡ç®—èµ„æºï¼Œé™åˆ¶äº†å¼€å‘è€…çš„çµæ´»æ€§ã€‚è¯¥å·¥ä½œæµæ—¨åœ¨ç®€åŒ–ä»¿çœŸåœ°å›¾çš„åˆ¶ä½œæµç¨‹ï¼Œå¹¶é€šè¿‡ä¸º Ontario Tech University åœè½¦åœºåˆ›å»º 3D åœ°å›¾å±•ç¤ºäº†å…¶å®é™…åº”ç”¨æ•ˆæœã€‚é€šè¿‡è¯¥æµç¨‹ï¼Œç ”ç©¶è€…èƒ½å¤Ÿä¸ºå®šä½ã€è·¯å¾„è§„åˆ’å’Œåœºæ™¯æµ‹è¯•æä¾›æ›´å…·é€‚åº”æ€§çš„åœ°å›¾åŸºç¡€ã€‚è¯¥æ–¹æ¡ˆä¸ºè§£å†³æ¨¡æ‹Ÿåœ°å›¾åˆ›å»ºä¸­çš„èµ„æºç“¶é¢ˆæä¾›äº†å‚è€ƒã€‚æœªæ¥çš„æ”¹è¿›æ–¹å‘å°†é›†ä¸­åœ¨å¼•å…¥ SLAM æŠ€æœ¯ã€ä¼˜åŒ–è·¨æ¨¡æ‹Ÿå™¨çš„å…¼å®¹æ€§ä»¥åŠå¢å¼ºç»çº¬åº¦å¤„ç†çš„çµæ´»æ€§ï¼Œä»¥è¿›ä¸€æ­¥æå‡åœ°å›¾ç”Ÿæˆçš„ç²¾ç¡®åº¦å’Œé€šç”¨æ€§ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.RO",
      "comment": "6 pages, 12 figures. Published in the Proceedings of GEOProcessing 2025: The Seventeenth International Conference on Advanced Geographic Information Systems, Applications, and Services (IARIA)",
      "pdf_url": "https://arxiv.org/pdf/2508.16856v1",
      "published_date": "2025-08-23 00:58:09 UTC",
      "updated_date": "2025-08-23 00:58:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:41:32.455460+00:00"
    },
    {
      "arxiv_id": "2508.16853v1",
      "title": "DevLicOps: A Framework for Mitigating Licensing Risks in AI-Generated Code",
      "title_zh": "DevLicOpsï¼šä¸€ç§è§„é¿AIç”Ÿæˆä»£ç è®¸å¯é£é™©çš„æ¡†æ¶",
      "authors": [
        "Pratyush Nidhi Sharma",
        "Lauren Wright",
        "Anne Herfurth",
        "Munsif Sokiyna",
        "Pratyaksh Nidhi Sharma",
        "Sethu Das",
        "Mikko Siponen"
      ],
      "abstract": "Generative AI coding assistants (ACAs) are widely adopted yet pose serious legal and compliance risks. ACAs can generate code governed by restrictive open-source licenses (e.g., GPL), potentially exposing companies to litigation or forced open-sourcing. Few developers are trained in these risks, and legal standards vary globally, especially with outsourcing. Our article introduces DevLicOps, a practical framework that helps IT leaders manage ACA-related licensing risks through governance, incident response, and informed tradeoffs. As ACA adoption grows and legal frameworks evolve, proactive license compliance is essential for responsible, risk-aware software development in the AI era.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç”Ÿæˆå¼ AI ç¼–ç¨‹åŠ©æ‰‹ (Generative AI coding assistants, ACAs) å¹¿æ³›åº”ç”¨èƒŒåéšè—çš„ä¸¥é‡æ³•å¾‹ä¸åˆè§„é£é™©ï¼ŒæŒ‡å‡ºå…¶ç”Ÿæˆçš„å—é™åˆ¶æ€§å¼€æºè®¸å¯è¯ (open-source licenses, å¦‚ GPL) ä»£ç å¯èƒ½å¯¼è‡´ä¼ä¸šé¢ä¸´æ³•å¾‹è¯‰è®¼æˆ–å¼ºåˆ¶å¼€æºçš„é£é™©ã€‚é’ˆå¯¹å¼€å‘è€…æ™®éç¼ºä¹é£é™©æ„è¯†ä»¥åŠå…¨çƒæ³•å¾‹æ ‡å‡†ä¸ä¸€çš„ç°çŠ¶ï¼Œæ–‡ç« æå‡ºäº†åä¸º DevLicOps çš„å®ç”¨æ¡†æ¶ï¼Œæ—¨åœ¨æŒ‡å¯¼ IT é¢†å¯¼è€…é€šè¿‡æ²»ç†ã€äº‹ä»¶å“åº”å’ŒçŸ¥æƒ…æƒè¡¡ (informed tradeoffs) æ¥æœ‰æ•ˆç®¡ç†è®¸å¯é£é™©ã€‚éšç€ ACA æŠ€æœ¯çš„æŒç»­æ™®åŠå’Œæ³•å¾‹æ¡†æ¶çš„ä¸æ–­æ¼”è¿›ï¼Œè¯¥æ¡†æ¶ä¸º AI æ—¶ä»£ä¸‹å®ç°è´Ÿè´£ä»»ä¸”å…·å¤‡é£é™©æ„è¯†çš„è½¯ä»¶å¼€å‘æä¾›äº†å…³é”®çš„åˆè§„è·¯å¾„ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "18 pages, 1 figure, 2 Tables",
      "pdf_url": "https://arxiv.org/pdf/2508.16853v1",
      "published_date": "2025-08-23 00:51:29 UTC",
      "updated_date": "2025-08-23 00:51:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:41:37.604997+00:00"
    },
    {
      "arxiv_id": "2508.16852v1",
      "title": "Gaussian Primitive Optimized Deformable Retinal Image Registration",
      "title_zh": "åŸºäºé«˜æ–¯åŸºå…ƒä¼˜åŒ–çš„å¯å˜å½¢è§†ç½‘è†œå›¾åƒé…å‡†",
      "authors": [
        "Xin Tian",
        "Jiazheng Wang",
        "Yuxi Zhang",
        "Xiang Chen",
        "Renjiu Hu",
        "Gaolei Li",
        "Min Liu",
        "Hang Zhang"
      ],
      "abstract": "Deformable retinal image registration is notoriously difficult due to large homogeneous regions and sparse but critical vascular features, which cause limited gradient signals in standard learning-based frameworks. In this paper, we introduce Gaussian Primitive Optimization (GPO), a novel iterative framework that performs structured message passing to overcome these challenges. After an initial coarse alignment, we extract keypoints at salient anatomical structures (e.g., major vessels) to serve as a minimal set of descriptor-based control nodes (DCN). Each node is modelled as a Gaussian primitive with trainable position, displacement, and radius, thus adapting its spatial influence to local deformation scales. A K-Nearest Neighbors (KNN) Gaussian interpolation then blends and propagates displacement signals from these information-rich nodes to construct a globally coherent displacement field; focusing interpolation on the top (K) neighbors reduces computational overhead while preserving local detail. By strategically anchoring nodes in high-gradient regions, GPO ensures robust gradient flow, mitigating vanishing gradient signal in textureless areas. The framework is optimized end-to-end via a multi-term loss that enforces both keypoint consistency and intensity alignment. Experiments on the FIRE dataset show that GPO reduces the target registration error from 6.2\\,px to ~2.4\\,px and increases the AUC at 25\\,px from 0.770 to 0.938, substantially outperforming existing methods. The source code can be accessed via https://github.com/xintian-99/GPOreg.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è§†ç½‘è†œå›¾åƒå½¢å˜é…å‡†ï¼ˆDeformable retinal image registrationï¼‰ä¸­å› å¤§é¢ç§¯åŒè´¨åŒºåŸŸå’Œç¨€ç–è¡€ç®¡ç‰¹å¾å¯¼è‡´çš„æ¢¯åº¦ä¿¡å·æ¶ˆå¤±é—®é¢˜ï¼Œæå‡ºäº†Gaussian Primitive Optimization (GPO) è¿­ä»£æ¡†æ¶ã€‚è¯¥æ¡†æ¶åœ¨åˆå§‹ç²—å¯¹é½åï¼Œæå–æ˜¾è‘—è§£å‰–ç»“æ„çš„å…³é”®ç‚¹ä½œä¸ºåŸºäºæè¿°ç¬¦çš„æ§åˆ¶èŠ‚ç‚¹ï¼ˆDescriptor-based Control Nodes, DCNï¼‰ï¼Œå¹¶å°†æ¯ä¸ªèŠ‚ç‚¹å»ºæ¨¡ä¸ºå…·æœ‰å¯è®­ç»ƒä½ç½®ã€ä½ç§»å’ŒåŠå¾„çš„é«˜æ–¯åŸè¯­ï¼ˆGaussian primitiveï¼‰ã€‚é€šè¿‡K-Nearest Neighbors (KNN) é«˜æ–¯æ’å€¼ï¼Œä½ç§»ä¿¡å·ä»è¿™äº›ä¿¡æ¯ä¸°å¯Œçš„èŠ‚ç‚¹ä¼ æ’­å¹¶æ„å»ºå‡ºå…¨å±€ä¸€è‡´çš„ä½ç§»åœºï¼Œç¡®ä¿äº†æ— çº¹ç†åŒºåŸŸçš„æ¢¯åº¦æµç¨³å¥æ€§ã€‚GPOé€šè¿‡å¼ºåˆ¶æ‰§è¡Œå…³é”®ç‚¹ä¸€è‡´æ€§å’Œå¼ºåº¦å¯¹é½çš„å¤šé¡¹æŸå¤±å‡½æ•°å®ç°ç«¯åˆ°ç«¯ä¼˜åŒ–ã€‚åœ¨FIREæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒGPOå°†ç›®æ ‡é…å‡†è¯¯å·®ï¼ˆTarget Registration Errorï¼‰ä»6.2åƒç´ æ˜¾è‘—é™ä½è‡³çº¦2.4åƒç´ ï¼ŒAUCä»0.770æå‡è‡³0.938ã€‚è¯¥æ–¹æ³•åœ¨æ€§èƒ½ä¸Šå¤§å¹…è¶…è¶Šäº†ç°æœ‰æŠ€æœ¯ï¼Œä¸ºé«˜ç²¾åº¦çš„çœ¼ç§‘å›¾åƒåˆ†ææä¾›äº†æœ‰æ•ˆæ”¯æŒã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages, 4 figures, MICCAI 2025 (Early accept)",
      "pdf_url": "https://arxiv.org/pdf/2508.16852v1",
      "published_date": "2025-08-23 00:44:50 UTC",
      "updated_date": "2025-08-23 00:44:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:41:41.891778+00:00"
    },
    {
      "arxiv_id": "2508.16850v1",
      "title": "RADAR: A Reasoning-Guided Attribution Framework for Explainable Visual Data Analysis",
      "title_zh": "RADARï¼šé¢å‘å¯è§£é‡Šè§†è§‰æ•°æ®åˆ†æçš„æ¨ç†å¼•å¯¼å½’å› æ¡†æ¶",
      "authors": [
        "Anku Rani",
        "Aparna Garimella",
        "Apoorv Saxena",
        "Balaji Vasan Srinivasan",
        "Paul Pu Liang"
      ],
      "abstract": "Data visualizations like charts are fundamental tools for quantitative analysis and decision-making across fields, requiring accurate interpretation and mathematical reasoning. The emergence of Multimodal Large Language Models (MLLMs) offers promising capabilities for automated visual data analysis, such as processing charts, answering questions, and generating summaries. However, they provide no visibility into which parts of the visual data informed their conclusions; this black-box nature poses significant challenges to real-world trust and adoption. In this paper, we take the first major step towards evaluating and enhancing the capabilities of MLLMs to attribute their reasoning process by highlighting the specific regions in charts and graphs that justify model answers. To this end, we contribute RADAR, a semi-automatic approach to obtain a benchmark dataset comprising 17,819 diverse samples with charts, questions, reasoning steps, and attribution annotations. We also introduce a method that provides attribution for chart-based mathematical reasoning. Experimental results demonstrate that our reasoning-guided approach improves attribution accuracy by 15% compared to baseline methods, and enhanced attribution capabilities translate to stronger answer generation, achieving an average BERTScore of $\\sim$ 0.90, indicating high alignment with ground truth responses. This advancement represents a significant step toward more interpretable and trustworthy chart analysis systems, enabling users to verify and understand model decisions through reasoning and attribution.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ (MLLMs) åœ¨è§†è§‰æ•°æ®åˆ†æä¸­å­˜åœ¨çš„â€œé»‘ç›’â€é—®é¢˜ï¼Œæå‡ºäº† RADAR æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡çªå‡ºæ˜¾ç¤ºå›¾è¡¨ä¸­æ”¯æ’‘æ¨¡å‹ç»“è®ºçš„ç‰¹å®šåŒºåŸŸï¼Œå¢å¼ºæ¨¡å‹æ¨ç†è¿‡ç¨‹çš„å¯è§£é‡Šæ€§ä¸å½’å›  (Attribution) èƒ½åŠ›ã€‚ä¸ºæ­¤ï¼Œä½œè€…é€šè¿‡åŠè‡ªåŠ¨æ–¹æ³•æ„å»ºäº†ä¸€ä¸ªåŒ…å« 17,819 ä¸ªæ ·æœ¬çš„å¤§è§„æ¨¡åŸºå‡†æ•°æ®é›†ï¼Œå…¶ä¸­æ•´åˆäº†å›¾è¡¨ã€é—®é¢˜ã€æ¨ç†æ­¥éª¤åŠå½’å› æ ‡æ³¨ã€‚è¯¥æ¡†æ¶è¿˜å¼•å…¥äº†ä¸€ç§ä¸“é—¨é’ˆå¯¹å›¾è¡¨æ•°å­¦æ¨ç†çš„å½’å› æ–¹æ³•ï¼Œç¡®ä¿æ¨¡å‹çš„æ¯ä¸€ä¸ªç»“è®ºéƒ½æœ‰æ®å¯ä¾ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¿™ç§æ¨ç†å¼•å¯¼çš„æ–¹æ³•å°†å½’å› å‡†ç¡®ç‡è¾ƒåŸºçº¿æ¨¡å‹æå‡äº† 15%ï¼Œä¸”ç”Ÿæˆçš„ç­”æ¡ˆä¸ ground truth é«˜åº¦å¯¹é½ï¼Œå¹³å‡ BERTScore è¾¾åˆ°çº¦ 0.90ã€‚è¯¥ç ”ç©¶æ˜¾è‘—æ¨è¿›äº†å¯è§£é‡Šä¸”å¯ä¿¡çš„å›¾è¡¨åˆ†æç³»ç»Ÿå‘å±•ï¼Œä½¿ç”¨æˆ·èƒ½å¤Ÿé€šè¿‡è§†è§‰å½’å› è·¯å¾„ç›´è§‚åœ°éªŒè¯å’Œç†è§£æ¨¡å‹çš„å†³ç­–é€»è¾‘ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.16850v1",
      "published_date": "2025-08-23 00:42:43 UTC",
      "updated_date": "2025-08-23 00:42:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:41:47.898524+00:00"
    },
    {
      "arxiv_id": "2508.16846v3",
      "title": "BASIL: Bayesian Assessment of Sycophancy in LLMs",
      "title_zh": "BASILï¼šå¤§è¯­è¨€æ¨¡å‹é˜¿è°€å¥‰æ‰¿è¡Œä¸ºçš„è´å¶æ–¯è¯„ä¼°",
      "authors": [
        "Katherine Atwell",
        "Pedram Heydari",
        "Anthony Sicilia",
        "Malihe Alikhani"
      ],
      "abstract": "Sycophancy (overly agreeable or flattering behavior) poses a fundamental challenge for human-AI collaboration, particularly in high-stakes decision-making domains such as health, law, and education. A central difficulty in studying sycophancy in large language models (LLMs) is disentangling sycophantic belief shifts from rational changes in behavior driven by new evidence or user-provided information. Existing approaches either measure descriptive behavior changes or apply normative evaluations that rely on objective ground truth, limiting their applicability to subjective or uncertain tasks. We introduce a Bayesian probabilistic framework, grounded in behavioral economics and rational decision theory, that explicitly separates sycophancy from rational belief updating. Within this framework, we achieve three objectives: (i) a descriptive metric that measures sycophancy while controlling for rational responses to evidence; (ii) a normative metric that quantifies how sycophancy leads models astray from Bayesian-consistent belief updating; and (iii) the ability to apply both metrics in settings without ground-truth labels. Applying our framework across multiple LLMs and three uncertainty-driven tasks, we find robust evidence of sycophantic belief shifts and show that their impact on rationality depends on whether models systematically over- or under-update their beliefs. Finally, we demonstrate that a post-hoc calibration method and two fine-tuning strategies (SFT and DPO) substantially reduce Bayesian inconsistency, with particularly strong improvements under explicit sycophancy prompting.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† BASILï¼Œä¸€ç§åŸºäºè´å¶æ–¯æ¦‚ç‡æ¡†æ¶ (Bayesian probabilistic framework) çš„è¯„ä¼°æ–¹æ³•ï¼Œæ—¨åœ¨åŒºåˆ†å¤§è¯­è¨€æ¨¡å‹ (LLMs) ä¸­çš„è°„åªšè¡Œä¸º (Sycophancy) ä¸åŸºäºæ–°è¯æ®çš„ç†æ€§ä¿¡å¿µæ›´æ–° (rational belief updating)ã€‚BASIL æ¡†æ¶å¼•å…¥äº†æè¿°æ€§æŒ‡æ ‡ä»¥åœ¨æ§åˆ¶ç†æ€§å“åº”çš„åŒæ—¶è¡¡é‡æ¨¡å‹è°„åªšç¨‹åº¦ï¼Œå¹¶æå‡ºäº†è§„èŒƒæ€§æŒ‡æ ‡æ¥é‡åŒ–æ¨¡å‹åç¦»è´å¶æ–¯ä¸€è‡´æ€§æ›´æ–°çš„ç¨‹åº¦ã€‚é€šè¿‡åœ¨å¤šä¸ªæ¨¡å‹å’Œä¸ç¡®å®šæ€§é©±åŠ¨ä»»åŠ¡ä¸Šçš„å®éªŒï¼Œç ”ç©¶è¯å®äº† LLMs ä¸­æ™®éå­˜åœ¨ç”±è°„åªšå¼•å‘çš„ä¿¡å¿µåç§»ï¼Œä¸”è¿™ç§åç§»å¯¹ç†æ€§çš„å½±å“å–å†³äºæ¨¡å‹è¿‡åº¦æˆ–ä¸è¶³çš„æ›´æ–°è¡Œä¸ºã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¯æ˜äº†äº‹åæ ¡å‡†æ–¹æ³•ä»¥åŠ SFT å’Œ DPO ä¸¤ç§å¾®è°ƒç­–ç•¥èƒ½å¤Ÿæ˜¾è‘—å‡å°‘è´å¶æ–¯ä¸ä¸€è‡´æ€§ï¼Œåœ¨åº”å¯¹æ˜¾å¼è°„åªšæç¤ºæ—¶è¡¨ç°å‡ºæ›´å¼ºçš„é²æ£’æ€§ã€‚è¯¥æ¡†æ¶å³ä½¿åœ¨ç¼ºä¹åœ°é¢çœŸå€¼æ ‡ç­¾ (ground-truth labels) çš„æƒ…å†µä¸‹ä¹Ÿèƒ½æœ‰æ•ˆé€‚ç”¨ï¼Œä¸ºç†è§£å’Œç¼“è§£ LLMs çš„è°„åªšè¡Œä¸ºæä¾›äº†ç³»ç»Ÿæ€§çš„ç†è®ºä¸å®è·µå·¥å…·ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.16846v3",
      "published_date": "2025-08-23 00:11:00 UTC",
      "updated_date": "2026-01-15 18:31:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:41:56.084974+00:00"
    },
    {
      "arxiv_id": "2508.16845v2",
      "title": "NinA: Normalizing Flows in Action. Training VLA Models with Normalizing Flows",
      "title_zh": "NinAï¼šå½’ä¸€åŒ–æµåœ¨è¡ŒåŠ¨â€”â€”åˆ©ç”¨å½’ä¸€åŒ–æµè®­ç»ƒ VLA æ¨¡å‹",
      "authors": [
        "Denis Tarasov",
        "Alexander Nikulin",
        "Ilya Zisman",
        "Albina Klepach",
        "Nikita Lyubaykin",
        "Andrei Polubarov",
        "Alexander Derevyagin",
        "Vladislav Kurenkov"
      ],
      "abstract": "Recent advances in Vision-Language-Action (VLA) models have established a two-component architecture, where a pre-trained Vision-Language Model (VLM) encodes visual observations and task descriptions, and an action decoder maps these representations to continuous actions. Diffusion models have been widely adopted as action decoders due to their ability to model complex, multimodal action distributions. However, they require multiple iterative denoising steps at inference time or downstream techniques to speed up sampling, limiting their practicality in real-world settings where high-frequency control is crucial. In this work, we present NinA (Normalizing Flows in Action), a fast and expressive alternative to diffusion-based decoders for VLAs. NinA replaces the diffusion action decoder with a Normalizing Flow (NF) that enables one-shot sampling through an invertible transformation, significantly reducing inference time. We integrate NinA into the FLOWER VLA architecture and fine-tune on the LIBERO benchmark. Our experiments show that NinA matches the performance of its diffusion-based counterpart under the same training regime, while achieving substantially faster inference. These results suggest that NinA offers a promising path toward efficient, high-frequency VLA control without compromising performance.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è§†è§‰è¯­è¨€åŠ¨ä½œ (Vision-Language-Action, VLA) æ¨¡å‹ä¸­æ‰©æ•£æ¨¡å‹ (Diffusion models) è§£ç å™¨æ¨ç†é€Ÿåº¦æ…¢çš„é—®é¢˜ï¼Œæå‡ºäº† NinA (Normalizing Flows in Action) æ¡†æ¶ã€‚NinA é‡‡ç”¨æ­£è§„åŒ–æµ (Normalizing Flow, NF) æ›¿ä»£ä¼ ç»Ÿçš„æ‰©æ•£è§£ç å™¨ï¼Œé€šè¿‡å¯é€†å˜æ¢å®ç°å•æ¬¡é‡‡æ · (one-shot sampling)ï¼Œä»è€Œæ˜¾è‘—é™ä½äº†æ¨ç†å»¶è¿Ÿå¹¶æ»¡è¶³é«˜é¢‘æ§åˆ¶éœ€æ±‚ã€‚ç ”ç©¶äººå‘˜å°† NinA é›†æˆè‡³ FLOWER VLA æ¶æ„ï¼Œå¹¶åœ¨ LIBERO åŸºå‡†æµ‹è¯•ä¸Šè¿›è¡Œäº†å¾®è°ƒä¸è¯„ä¼°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒNinA åœ¨ä¿æŒä¸æ‰©æ•£æ¨¡å‹è§£ç å™¨ç›¸å½“çš„æ€§èƒ½æ°´å¹³çš„åŒæ—¶ï¼Œå®ç°äº†å¤§å¹…åº¦çš„æ¨ç†åŠ é€Ÿã€‚è¯¥ç ”ç©¶è¯æ˜äº† NinA ä¸ºæ„å»ºé«˜æ•ˆä¸”å…·å¤‡é«˜æ€§èƒ½çš„é«˜é¢‘ VLA æ§åˆ¶ç³»ç»Ÿæä¾›äº†ä¸€ç§æå…·æ½œåŠ›çš„æŠ€æœ¯æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "https://github.com/dunnolab/NinA/",
      "pdf_url": "https://arxiv.org/pdf/2508.16845v2",
      "published_date": "2025-08-23 00:02:15 UTC",
      "updated_date": "2025-10-14 10:06:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:41:58.093130+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 59,
  "processed_papers_count": 59,
  "failed_papers_count": 0,
  "llm_backup_calls": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-01-24T13:42:49.841117+00:00"
}