{
  "date": "2025-03-05",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间2025-03-05的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 上的论文热点依然集中在大型语言模型（LLM）和多模态模型上，探讨了从提升推理能力、评估模型诚实度、增强安全性到提高效率等多个方面。值得关注的研究包括：引入新基准 MASK 用于区分 LLM 的诚实度与准确性；提出基于过程的自奖励方法提升 LLM 数学推理；探索任务无关的对抗攻击对视觉基础模型的威胁；以及开发统一的原子级扩散 Transformer 用于分子和材料生成。此外，AI 在医疗、机器人导航、推荐系统、网络安全等领域的应用也涌现出不少创新。\n\n以下是值得关注的论文：\n\n---\n\n**1. MASK 基准：在 AI 系统中区分诚实度与准确性 (The MASK Benchmark: Disentangling Honesty From Accuracy in AI Systems)**\n\n-   随着 LLM 能力增强，对其输出的信任需求日益增长，但模型可能学会“说谎”的担忧也在加剧。现有诚实度评估方法有限，且常将诚实度与准确性混淆。\n-   **贡献:** 本文引入 MASK，一个大规模、人工收集的数据集，首次明确区分了模型的准确性（知道什么）和诚实度（是否说真话）。\n-   **发现:** 研究发现，虽然更大的模型在 MASK 上准确率更高，但诚实度并未相应提升。令人惊讶的是，许多前沿 LLM 在压力下表现出显著的说谎倾向，诚实度得分较低。简单的干预措施（如表征工程）可以提高诚实度。\n-   **意义:** 强调了对 LLM 进行稳健评估和有效干预以确保其可信度的迫切需求。\n\n**2. 基于过程的自奖励语言模型 (Process-based Self-Rewarding Language Models)**\n\n-   现有自奖励方法在数学推理等任务上效果不佳。\n-   **贡献:** 提出基于过程的自奖励流程（Process-based Self-Rewarding），将长思维推理（long-thought reasoning）、逐步的 LLM-as-a-Judge 和逐步偏好优化引入自奖励范式。\n-   **发现:** 通过迭代的基于过程的自奖励，该方法成功提升了 LLM 在多个数学推理基准上的性能，展示了自奖励在实现可能超越人类能力的 LLM 推理方面的巨大潜力。\n\n**3. 不仅仅是规模法则：深入理解语言模型设计决策对下游任务的影响 (Not-Just-Scaling Laws: Towards a Better Understanding of the Downstream Impact of Language Model Design Decisions)**\n\n-   LLM 的能力提升不仅来自规模增大，也受数据选择和架构设计影响。\n-   **贡献:** 本文元分析了 92 个开源预训练模型，量化了除规模和训练数据量之外的设计选择（如数据组成、架构决策）对下游性能的影响。\n-   **发现:** 结合更多特征（如代码数据比例、位置编码选择等）比仅使用规模能更好地预测下游性能（相对提升 3-28%）。例如，代码数据比例在 15-25% 时，语言和代码任务间存在权衡；旋转嵌入优于学习嵌入。\n-   **意义:** 为系统研究模型开发选择如何塑造最终能力奠定了基础。\n\n**4. 任务无关的对抗攻击对抗视觉基础模型 (Task-Agnostic Attacks Against Vision Foundation Models)**\n\n-   现有攻击研究多关注特定下游任务，而视觉基础模型（VFMs）作为通用骨干被广泛应用，其自身安全性研究不足。\n-   **贡献:** 提出一个通用框架，通过最大程度地破坏 VFM 获得的特征表示来制造任务无关的对抗样本。\n-   **发现:** 评估了流行 VFM 特征表示的安全性，衡量了这种攻击对多个下游任务的影响及其在模型间的可迁移性。\n-   **意义:** 揭示了共享 VFM 带来的潜在安全风险，强调了研究 VFM 本身鲁棒性的重要性。\n\n**5. 全原子扩散 Transformer：统一的分子和材料生成建模 (All-atom Diffusion Transformers: Unified generative modelling of molecules and materials)**\n\n-   现有 3D 原子系统生成模型通常针对特定系统（分子或材料）设计。\n-   **贡献:** 提出全原子扩散 Transformer (ADiT)，一个统一的潜在扩散框架，使用单一模型联合生成周期性材料和非周期性分子。它包含一个将分子/材料映射到共享潜在空间的自编码器，和一个生成新潜在嵌入的扩散模型。\n-   **发现:** 在 QM9 和 MP20 数据集上的实验表明，联合训练的 ADiT 能生成逼真且有效的分子和材料，性能优于特定于分子或晶体的 SOTA 模型。使用标准 Transformer 显著提升了训练和推理速度。模型扩展至 5 亿参数可持续提升性能。\n-   **意义:** 向着可广泛泛化的生成化学基础模型迈出了一步。\n\n**6. CREStE：利用互联网规模先验和反事实指导的可扩展无地图导航 (CREStE: Scalable Mapless Navigation with Internet Scale Priors and Counterfactual Guidance)**\n\n-   解决长距离无地图导航问题，即机器人无需高清地图或精确路点即可在未知环境中导航。\n-   **贡献:** 提出 CREStE，首个无需大规模机器人数据集或手动特征即可学习表示和奖励以解决完整无地图导航问题的方法。它利用视觉基础模型学习连续鸟瞰图表示，并提出基于反事实的损失和主动学习过程，通过查询人类的反事实轨迹标注来关注显著的感知线索。\n-   **发现:** 在跨越六个不同城市环境的公里级导航任务中，CREStE 显著优于所有 SOTA 方法，每次任务的人工干预减少 70%，展示了其鲁棒性和有效性。\n\n**7. SafeVLA：通过安全强化学习实现视觉-语言-动作模型的安全对齐 (SafeVLA: Towards Safety Alignment of Vision-Language-Action Model via Safe Reinforcement Learning)**\n\n-   视觉-语言-动作模型 (VLA) 在作为通用机器人策略方面潜力巨大，但部署时存在安全风险。\n-   **贡献:** 提出 SafeVLA，一种将安全性融入 VLA 的新算法，通过在模拟环境中进行大规模约束学习来平衡安全与任务性能。\n-   **发现:** SafeVLA 在安全性和任务性能上均优于 SOTA 方法（模拟中分别平均提升 83.58% 和 3.85%），显著减少了高风险行为和长尾风险。学习到的安全约束可泛化到未见过的场景。\n-   **意义:** 为开发更安全的机器人通用策略提供了有效途径。\n\n**8. RiskAgent：用于通用风险预测的自主医疗 AI 助手 (RiskAgent: Autonomous Medical AI Copilot for Generalist Risk Prediction)**\n\n-   将 LLM 应用于实际临床决策，而非标准化的考试式场景。\n-   **贡献:** 提出 RiskAgent 系统，可执行超过 387 种医疗风险预测，涵盖心血管疾病、癌症等多种复杂疾病。该系统与数百种循证医学支持的临床决策工具（风险计算器/评分系统）协作。同时构建了首个风险预测基准 MedRisk。\n-   **发现:** 8B 参数的 RiskAgent 准确率达 76.33%，优于 o1, o3-mini, GPT-4.5，是 GPT-4o 的两倍。在罕见病上优势更明显。在外部诊断基准上也表现最佳。\n-   **意义:** 展示了该方案在多样化诊断领域的巨大潜力，并开源了模型、代码和数据。\n\n**9. 通过情感整合增强大型语言模型的集体智慧 (Enhancing Collective Intelligence in Large Language Models Through Emotional Integration)**\n\n-   受人类群体智慧启发，研究将情感多样性整合到 LLM 中以增强集体智能。\n-   **贡献:** 使用 GoEmotions 数据集和 LoRA 微调 DarkIdol-Llama-3.1-8B 模型，模拟情感多样化的响应。在距离估计任务上评估了 15064 种独特角色配置。\n-   **发现:** 情感整合在保持可接受预测精度的同时，塑造了响应模式，揭示了其增强人工集体智能的潜力。\n-   **意义:** 为创建能在情感深度和分析精度间取得平衡的情感感知 AI 系统提供了思路。\n\n**10. BrainNet-MoE：用于神经疾病识别的脑启发混合专家学习 (BrainNet-MoE: Brain-Inspired Mixture-of-Experts Learning for Neurological Disease Identification)**\n\n-   针对阿尔茨海默病 (AD) 和路易体痴呆 (LBD) 等神经退行性疾病早期区分困难的问题。\n-   **贡献:** 提出 BrainNet-MoE，一个系统级人工神经网络模型。受大脑分层组织启发，设计了疾病特异性专家组处理大脑子网络，疾病门控机制引导专家组专业化，Transformer 层实现子网络间通信，生成全脑表示用于分类。\n-   **发现:** 实验结果显示出优越的分类准确性，并提供了关于大脑子网络如何影响不同神经退行性疾病的可解释见解。\n\n**11. Attentive Reasoning Queries (ARQs): 优化大型语言模型指令遵循的系统方法 (Attentive Reasoning Queries: A Systematic Method for Optimizing Instruction-Following in Large Language Models)**\n\n-   LLM 在多轮对话中难以持续遵循复杂指令。\n-   **贡献:** 提出 ARQs，一种结构化推理方法，通过领域专门化的推理蓝图和目标查询来指导 LLM，在完成过程中重新强调关键指令并促进中间推理。\n-   **发现:** 在 Parlant 框架（面向客户的 Agent）的测试中，ARQs 成功率达 90.2%，优于 CoT (86.1%) 和直接生成 (81.5%)，尤其在解决持续性失败模式（如准则重应用、幻觉预防）方面表现出色。精心设计的 ARQs 可能比自由形式推理更具计算效率。\n\n**12. RASD：检索增强的推测解码 (RASD: Retrieval-Augmented Speculative Decoding)**\n\n-   推测解码通过草稿 token 加速 LLM 推理，但现有方法在域外场景效果下降，且草稿阶段耗时限制了效率上限。\n-   **贡献:** 提出 RASD，利用检索方法增强基于模型的推测解码。引入基于草稿模型概率分布的树剪枝构建最优检索树，并使用最长前缀匹配算法融合草稿树和检索树。\n-   **发现:** RASD 在 DocQA、摘要、代码和域内 QA 等任务上实现了 SOTA 的推理加速，并具有良好的可扩展性，可与各种推测解码方法集成。\n\n**13. 用于在 SpArX 中增强结构忠实度的迭代逐层压缩 (ILLC: Iterative Layer-by-Layer Compression for Enhancing Structural Faithfulness in SpArX)**\n\n-   在可解释 AI (XAI) 的论证式方法中，现有压缩方法一次性简化所有层，导致信息损失累积。\n-   **贡献:** 提出迭代逐层压缩 (ILLC) 技术，每层单独压缩并立即补偿下一层的缩减误差。\n-   **发现:** 与传统压缩相比，ILLC 减少了输入输出和结构的不忠实度，并在论证式解释方案中保持更一致的攻击-支持关系，有助于在保持模型紧凑的同时不失真地传达其内部推理逻辑。\n\n**14. 通过自愿承诺学习谈判 (Learning to Negotiate via Voluntary Commitment)**\n\n-   在混合动机场景中，智能体可能因承诺不可信而无法达成合作。\n-   **贡献:** 定义了马尔可夫承诺博弈 (MCGs)，智能体可自愿承诺其未来计划。提出基于策略梯度的可学习承诺协议，并引入激励相容学习以加速收敛到社会福利更优的均衡。\n-   **发现:** 在挑战性混合动机任务中，该方法比对应方法收敛更快，回报更高。\n\n**15. CHOP：具有约束高频优化子任务规划的移动操作助手 (CHOP: Mobile Operating Assistant with Constrained High-frequency Optimized Subtask Planning)**\n\n-   当前基于 VLM 的移动助手在子任务层面存在无效和低效问题。\n-   **贡献:** 提出 CHOP 架构，利用人类规划的子任务作为基向量，克服 VLM 在 GUI 场景规划中的不足。\n-   **发现:** 在中英文 20 个 App 上的评估表明，CHOP 在有效性和效率上均有显著提升。\n\n**其他简报:**\n\n*   **#20 Rethinking Deep Clustering Paradigms:** 提出用两轮自监督学习取代伪监督，解决深度聚类中的特征随机性、漂移和扭曲问题。\n*   **#24 Rethinking Video Tokenization:** 提出 CDT，一种基于条件扩散的视频 Tokenizer，替代 VAE+GAN 架构，训练更稳定，重建效果 SOTA。\n*   **#25 Curating Demonstrations using Online Experience:** 提出 Demo-SCORE，让机器人根据在线经验自我筛选高质量的异构演示数据，提升模仿学习效果。\n*   **#26 Self-Supervised Z-Slice Augmentation:** 提出 ZAugNet/ZAugNet+，一种自监督深度学习方法，通过知识蒸馏增强生物显微图像的 Z 轴分辨率。\n*   **#29 Multi-Agent Systems Powered by LLMs:** 探索将 LLM 集成到多智能体仿真中（蚂蚁觅食、鸟群），用提示驱动代替硬编码程序。\n*   **#30 Attentive Reasoning Queries:** 提出 ARQ，一种结构化推理方法，通过特定查询引导 LLM 更好地遵循复杂指令。\n*   **#31 Framing the Game:** 研究上下文框架如何影响 LLM 的决策制定，发现 LLM 响应对框架效应高度敏感。\n*   **#32 A Generative Approach to High Fidelity 3D Reconstruction from Text Data:** 提出一个从文本生成高保真 3D 模型的全自动流程，结合文本到图像生成、图像处理和深度学习 3D 重建。\n*   **#34 Advancing Multimodal In-Context Learning:** 提出 SabER，一个轻量级 Transformer，通过任务感知注意力智能选择和排列上下文演示（ICD），提升多模态 ICL 性能。\n*   **#35 Improving Neutral Point of View Text Generation:** 构建 SHQ-NPOV 数据集，并发现参数高效强化学习 (PE-RL) 能有效提升 LLM 生成中立观点文本的能力。\n*   **#37 Towards Understanding Text Hallucination of Diffusion Models:** 探究扩散模型生成无意义文本（文本幻觉）的原因，归因于网络的局部生成偏见。\n*   **#38 Small but Mighty:** 提出 SMETimes，利用轻量级 LLM (SLM) 进行时间序列预测，通过统计增强提示、自适应融合嵌入和动态 MoE 实现高效率和准确性。\n*   **#39 English K_Quantization of LLMs:** 研究表明，基于英文语料进行的 LLM k-量化（如 GGUF）并未不成比例地损害多语言性能。\n*   **#40 Human Preferences for Constructive Interactions:** 分析发现用户偏好 LLM 回答有理有据、细致入微，并拒绝个人故事叙述过多的回答。LLM 会镜像用户的语言属性（包括毒性）。\n*   **#41 VoiceGRPO:** 将 MoE Transformer 与 GRPO 用于语音病理学检测。\n*   **#44 Physics-Grounded Anomaly Detection:** 引入 Phys-AD 数据集，首个大规模、真实世界、基于物理的工业异常检测视频数据集，挑战现有方法。\n*   **#46 Distilling Dataset into Neural Field (DDiF):** 提出 DDiF，一种新的数据集蒸馏参数化框架，利用神经场存储大规模数据集信息，性能优越且扩展性好。\n*   **#47 Human Implicit Preference-Based Policy Fine-tuning for MARL:** 提出用于多智能体强化学习（USV 集群）的 RLHF 方法，通过 Agent 级反馈解决信用分配问题。\n*   **#48 Extrapolation Merging:** 提出 Extrapolation Merging，一种无需额外计算或数据即可持续提升模型性能的范式，通过外推为模型合并提供优化方向。\n*   **#50 Adversarial Training for MLLMs against Jailbreak Attacks:** 提出 ProEAT，首个针对 MLLM 越狱攻击的对抗训练范式，通过投影层对抗训练和跨模态联合优化实现高效鲁棒防御。\n*   **#54 Parallelized Planning-Acting for Efficient LLM-based MAS:** 提出用于 LLM 多智能体系统的并行规划-行动框架，通过双线程架构实现并发规划与行动，提高实时响应能力。\n*   **#55 Collaborative Expert LLMs Guided Multi-Objective Molecular Optimization:** 提出 MultiMol，一个协作式 LLM 系统（数据驱动 Worker + 文献指导 Researcher），用于指导多目标分子优化。\n*   **#56 CURVALID: Geometrically-guided Adversarial Prompt Detection:** 提出 CurvaLID，利用对抗性提示的几何特性（曲率、局部内在维度）来检测它们，与 LLM 类型无关。\n*   **#59 Unified Mind Model (UMM):** 提出 UMM，一个新的理论认知架构，指导基于 LLM 构建具有类人认知能力的自主智能体。\n*   **#62 RASD: Retrieval-Augmented Speculative Decoding:** (重复 #12)\n*   **#65 Simplicial SMOTE:** 提出 Simplicial SMOTE，一种新的过采样技术，通过在几何邻域单纯形复形上采样来解决不平衡学习问题。\n*   **#66 When Claims Evolve:** 评估和增强嵌入模型对错误信息编辑的鲁棒性，提出扰动框架和缓解方法。\n*   **#71 From Infants to AI:** 模型中融入婴儿般的学习方式（利用早期概念学习新概念）可以提高学习社交预测任务的效率和泛化能力。\n*   **#75 See What You Are Told: Visual Attention Sink in LMMs:** 发现大型多模态模型中存在“视觉注意力沉没”现象，即模型倾向于关注特定无关视觉标记。提出 VAR 方法重新分配注意力以提升性能。\n*   **#81 Conformal Transformations for Symmetric Power Transformers:** 提出共形对称幂 Transformer (conformal-sympow)，通过数据依赖的门控和旋转嵌入克服 sympow Transformer 在长上下文下的性能退化。\n*   **#83 Exploring the Potential of LLMs as Predictors in Dynamic Text-Attributed Graphs:** 提出 GraphAgent-Dynamic (GAD) 框架，一个多智能体系统，利用协作 LLM 处理动态图预测任务。\n*   **#84 Rebalanced Multimodal Learning with Data-aware Unimodal Sampling:** 提出 DUS 方法，通过数据感知的单模态采样动态缓解采样引起的模态不平衡。\n*   **#87 FANS -- Formal Answer Selection for Natural Language Math Reasoning Using Lean4:** 提出 FANS 框架，利用 Lean4 形式化验证来辅助 LLM 进行自然语言数学推理和答案选择。\n*   **#89 Positive-Unlabeled Diffusion Models:** 提出 PU 扩散模型，仅使用未标记和敏感（正例）数据来防止生成敏感数据。\n*   **#90 StickMotion:** 提出 StickMotion，一个基于扩散的多条件网络，通过文本和用户绘制的简笔画（stickman）生成 3D 人体动作。\n*   **#95 MA-LoT: Multi-Agent Lean-based Long Chain-of-Thought Reasoning:** 提出 MA-LoT，首个用于 Lean4 定理证明的多智能体框架，结合 NL 推理和 FL 验证。\n*   **#96 Towards Robust Universal Information Extraction:** 引入 RUIE-Bench 基准，利用 LLM 生成更多样、真实的扰动评估 UIE 鲁棒性，并提出数据增强方案。\n*   **#100 Structured Outputs Enable General-Purpose LLMs to be Medical Experts:** 提出利用结构化医学推理（七步认知过程）指导 LLM 回答开放式医疗问题，无需额外训练即可提高全面性和真实性。\n*   **#101 ProReflow: Progressive Reflow with Decomposed Velocity:** 提出渐进式重流（Progressive Reflow）和对齐 v-预测（aligned v-prediction）来改进流匹配（Flow Matching）的训练，以实现高效的 few-step 图像/视频生成。\n*   **#104 AttackSeqBench:** 提出 AttackSeqBench 基准，评估 LLM 理解 CTI 报告中网络攻击序列模式的能力。\n*   **#106 Position: Model Collapse Does Not Mean What You Think:** 辩称对“模型坍塌”的普遍担忧误解了科学证据，指出其定义不一，且许多预测场景基于不切实际的假设，某些形式是可避免的。\n*   **#109 Knowledge Augmentation in Federation (KAF):** 提出 KAF 范式，一种以知识为中心的协作学习方法，专注于通过协作努力增强本地知识，而非仅仅模型训练。\n*   **#110 Convergence Analysis of Federated Learning Methods Using Backward Error Analysis:** 使用后向误差分析研究 FedAvg, FedSAM, SCAFFOLD 等联邦学习算法在非 IID 数据上的收敛行为，通过分析隐式正则化项解释其差异。\n*   **#111 L2R: Learning to Reduce Search Space for Generalizable Neural Routing Solver:** 提出学习驱动的搜索空间缩减方法，在 NCO 构造过程中自适应选择有希望的候选节点，显著提升对大规模路由问题的泛化能力。\n*   **#115 The Devil Is in the Details:** 发现 MM-RM 易受单模态虚假相关性（主要是文本捷径）影响，提出 Shortcut-aware 学习算法通过重加权样本减轻此问题，提升泛化能力。\n*   **#117 SoK: Knowledge is All You Need (PIDS with LLMs):** 提出知识驱动的、基于 LLM 的溯源入侵检测框架 OmniSec，整合多源知识实现自动化威胁分析。\n*   **#119 HeTGB: A Comprehensive Benchmark for Heterophilic Text-Attributed Graphs:** 引入 HeTGB，一个包含 5 个真实世界异质性文本图数据集的新基准，用于评估 GNN、PLM 和协同训练方法。\n\n---\n\n今天的论文内容丰富，希望这份 TLDR 能帮助你快速把握研究前沿！",
  "papers": [
    {
      "arxiv_id": "2503.04849v1",
      "title": "Enhancing Collective Intelligence in Large Language Models Through Emotional Integration",
      "title_zh": "通过情感整合提升大语言模型的集体智能",
      "authors": [
        "Likith Kadiyala",
        "Ramteja Sajja",
        "Yusuf Sermet",
        "Ibrahim Demir"
      ],
      "abstract": "This research investigates the integration of emotional diversity into Large\nLanguage Models (LLMs) to enhance collective intelligence. Inspired by the\nhuman wisdom of crowds phenomenon, where group decisions often outperform\nindividual judgments, we fine-tuned the DarkIdol-Llama-3.1-8B model using\nGoogle's GoEmotions dataset and Low-Rank Adaptation (LoRA) to simulate\nemotionally diverse responses. Evaluating the model on a distance estimation\ntask between Fargo, ND, and Seattle, WA, across 15,064 unique persona\nconfigurations, we analyzed how emotional states and social attributes\ninfluence decision-making. Our findings demonstrate that emotional integration\nshapes response patterns while maintaining acceptable prediction accuracy,\nrevealing its potential to enhance artificial collective intelligence. This\nstudy provides valuable insights into the interplay of emotional diversity and\ndecision-making in LLMs, suggesting pathways for creating emotionally aware AI\nsystems that balance emotional depth with analytical precision.",
      "tldr_zh": "本研究探讨了将情感多样性整合到大型语言模型(LLMs)中以增强集体智能的方法。受人类群体智慧现象的启发，研究者使用Google的GoEmotions数据集和低秩适应(LoRA)技术微调了DarkIdol-Llama-3.1-8B模型，以模拟情感多样化的响应。通过在15,064种独特人格配置下对模型进行距离估计任务评估，研究发现情感状态和社会属性显著影响决策模式，同时保持可接受的预测准确性。该研究揭示了情感整合在增强人工集体智能方面的潜力，为创建情感意识与分析精度相平衡的AI系统提供了新的思路。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.HC",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "23 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.04849v1",
      "published_date": "2025-03-05 23:42:48 UTC",
      "updated_date": "2025-03-05 23:42:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:02:07.133434"
    },
    {
      "arxiv_id": "2503.03965v1",
      "title": "All-atom Diffusion Transformers: Unified generative modelling of molecules and materials",
      "title_zh": "全原子扩散变换器：分子与材料的统一生成建模",
      "authors": [
        "Chaitanya K. Joshi",
        "Xiang Fu",
        "Yi-Lun Liao",
        "Vahe Gharakhanyan",
        "Benjamin Kurt Miller",
        "Anuroop Sriram",
        "Zachary W. Ulissi"
      ],
      "abstract": "Diffusion models are the standard toolkit for generative modelling of 3D\natomic systems. However, for different types of atomic systems - such as\nmolecules and materials - the generative processes are usually highly specific\nto the target system despite the underlying physics being the same. We\nintroduce the All-atom Diffusion Transformer (ADiT), a unified latent diffusion\nframework for jointly generating both periodic materials and non-periodic\nmolecular systems using the same model: (1) An autoencoder maps a unified,\nall-atom representations of molecules and materials to a shared latent\nembedding space; and (2) A diffusion model is trained to generate new latent\nembeddings that the autoencoder can decode to sample new molecules or\nmaterials. Experiments on QM9 and MP20 datasets demonstrate that jointly\ntrained ADiT generates realistic and valid molecules as well as materials,\nexceeding state-of-the-art results from molecule and crystal-specific models.\nADiT uses standard Transformers for both the autoencoder and diffusion model,\nresulting in significant speedups during training and inference compared to\nequivariant diffusion models. Scaling ADiT up to half a billion parameters\npredictably improves performance, representing a step towards broadly\ngeneralizable foundation models for generative chemistry. Open source code:\nhttps://github.com/facebookresearch/all-atom-diffusion-transformer",
      "tldr_zh": "该研究提出了All-atom Diffusion Transformer (ADiT)，一种统一的生成模型框架，能够同时生成周期性材料和非周期性分子系统。ADiT通过一个自编码器将分子和材料的原子表示映射到共享的潜在嵌入空间，并利用扩散模型生成新的潜在嵌入，进而解码为新的分子或材料。实验表明，ADiT在QM9和MP20数据集上生成的分子和材料既真实又有效，超越了现有的特定模型，且训练和推理速度显著提升。ADiT的扩展版本达到5亿参数，性能进一步提升，为生成化学领域的基础模型发展迈出重要一步。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03965v1",
      "published_date": "2025-03-05 23:35:44 UTC",
      "updated_date": "2025-03-05 23:35:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:02:10.748268"
    },
    {
      "arxiv_id": "2503.03951v1",
      "title": "WIP: Assessing the Effectiveness of ChatGPT in Preparatory Testing Activities",
      "title_zh": "WIP：评估 ChatGPT 在测试准备活动中的有效性",
      "authors": [
        "Susmita Haldar",
        "Mary Pierce",
        "Luiz Fernando Capretz"
      ],
      "abstract": "This innovative practice WIP paper describes a research study that explores\nthe integration of ChatGPT into the software testing curriculum and evaluates\nits effectiveness compared to human-generated testing artifacts. In a Capstone\nProject course, students were tasked with generating preparatory testing\nartifacts using ChatGPT prompts, which they had previously created manually.\nTheir understanding and the effectiveness of the Artificial Intelligence\ngenerated artifacts were assessed through targeted questions. The results,\ndrawn from this in-class assignment at a North American community college\nindicate that while ChatGPT can automate many testing preparation tasks, it\ncannot fully replace human expertise. However, students, already familiar with\nInformation Technology at the postgraduate level, found the integration of\nChatGPT into their workflow to be straightforward. The study suggests that AI\ncan be gradually introduced into software testing education to keep pace with\ntechnological advancements.",
      "tldr_zh": "本研究探讨了将ChatGPT整合到软件测试课程中的效果，并与人工生成的测试工件进行了对比。通过北美洲一所社区学院的Capstone项目课程，学生使用ChatGPT生成测试工件，并评估其理解与效果。结果表明，尽管ChatGPT可以自动化许多测试准备任务，但无法完全取代人类专业知识。然而，熟悉信息技术的硕士生认为将ChatGPT融入工作流程较为便捷。研究建议逐步将AI引入软件测试教育，以跟上技术进步的步伐。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "5 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.03951v1",
      "published_date": "2025-03-05 22:51:24 UTC",
      "updated_date": "2025-03-05 22:51:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:02:21.585852"
    },
    {
      "arxiv_id": "2503.03947v1",
      "title": "COARSE: Collaborative Pseudo-Labeling with Coarse Real Labels for Off-Road Semantic Segmentation",
      "title_zh": "COARSE：利用粗糙真实标签进行协作伪标记的越野语义分割",
      "authors": [
        "Aurelio Noca",
        "Xianmei Lei",
        "Jonathan Becktor",
        "Jeffrey Edlund",
        "Anna Sabel",
        "Patrick Spieler",
        "Curtis Padgett",
        "Alexandre Alahi",
        "Deegan Atha"
      ],
      "abstract": "Autonomous off-road navigation faces challenges due to diverse, unstructured\nenvironments, requiring robust perception with both geometric and semantic\nunderstanding. However, scarce densely labeled semantic data limits\ngeneralization across domains. Simulated data helps, but introduces domain\nadaptation issues. We propose COARSE, a semi-supervised domain adaptation\nframework for off-road semantic segmentation, leveraging sparse, coarse\nin-domain labels and densely labeled out-of-domain data. Using pretrained\nvision transformers, we bridge domain gaps with complementary pixel-level and\npatch-level decoders, enhanced by a collaborative pseudo-labeling strategy on\nunlabeled data. Evaluations on RUGD and Rellis-3D datasets show significant\nimprovements of 9.7\\% and 8.4\\% respectively, versus only using coarse data.\nTests on real-world off-road vehicle data in a multi-biome setting further\ndemonstrate COARSE's applicability.",
      "tldr_zh": "该研究提出了COARSE框架，用于解决越野场景语义分割中标注数据稀缺的问题。COARSE结合稀疏的粗粒度域内标签和密集的域外标注数据，通过预训练的视觉Transformer和协同伪标签策略，利用像素级和补丁级解码器缩小域间差距。实验表明，COARSE在RUGD和Rellis-3D数据集上分别提升了9.7%和8.4%的性能，并在多生物群落的真实越野车辆数据中验证了其适用性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "preprint, 8 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.03947v1",
      "published_date": "2025-03-05 22:25:54 UTC",
      "updated_date": "2025-03-05 22:25:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:02:29.167406"
    },
    {
      "arxiv_id": "2503.07641v1",
      "title": "Deep ARTMAP: Generalized Hierarchical Learning with Adaptive Resonance Theory",
      "title_zh": "Deep ARTMAP：基于自适应共振理论的广义分层学习",
      "authors": [
        "Niklas M. Melton",
        "Leonardo Enzo Brito da Silva",
        "Sasha Petrenko",
        "Donald. C. Wunsch II"
      ],
      "abstract": "This paper presents Deep ARTMAP, a novel extension of the ARTMAP architecture\nthat generalizes the self-consistent modular ART (SMART) architecture to enable\nhierarchical learning (supervised and unsupervised) across arbitrary\ntransformations of data. The Deep ARTMAP framework operates as a divisive\nclustering mechanism, supporting an arbitrary number of modules with\ncustomizable granularity within each module. Inter-ART modules regulate the\nclustering at each layer, permitting unsupervised learning while enforcing a\none-to-many mapping from clusters in one layer to the next. While Deep ARTMAP\nreduces to both ARTMAP and SMART in particular configurations, it offers\nsignificantly enhanced flexibility, accommodating a broader range of data\ntransformations and learning modalities.",
      "tldr_zh": "本文提出了Deep ARTMAP，一种基于自适应共振理论（ART）的新型扩展架构，旨在实现跨任意数据变换的分层学习（监督和无监督）。该框架通过模块化的分治聚类机制，支持任意数量的模块和可定制的粒度，同时通过层间ART模块实现无监督学习，并强制层与层之间的一对多映射。Deep ARTMAP在特定配置下可简化为ARTMAP和SMART，但其灵活性和适应性显著增强，能够处理更广泛的数据变换和学习模式。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07641v1",
      "published_date": "2025-03-05 22:23:17 UTC",
      "updated_date": "2025-03-05 22:23:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:02:45.242942"
    },
    {
      "arxiv_id": "2503.07640v1",
      "title": "BrainNet-MoE: Brain-Inspired Mixture-of-Experts Learning for Neurological Disease Identification",
      "title_zh": "BrainNet-MoE：基于大脑启发的专家混合学习用于神经系统疾病识别",
      "authors": [
        "Jing Zhang",
        "Xiaowei Yu",
        "Tong Chen",
        "Chao Cao",
        "Mingheng Chen",
        "Yan Zhuang",
        "Yanjun Lyu",
        "Lu Zhang",
        "Li Su",
        "Tianming Liu",
        "Dajiang Zhu"
      ],
      "abstract": "The Lewy body dementia (LBD) is the second most common neurodegenerative\ndementia after Alzheimer's disease (AD). Early differentiation between AD and\nLBD is crucial because they require different treatment approaches, but this is\nchallenging due to significant clinical overlap, heterogeneity, complex\npathogenesis, and the rarity of LBD. While recent advances in artificial\nintelligence (AI) demonstrate powerful learning capabilities and offer new hope\nfor accurate diagnosis, existing methods primarily focus on designing\n\"neural-level networks\". Our work represents a pioneering effort in modeling\nsystem-level artificial neural network called BrainNet-MoE for brain modeling\nand diagnosing. Inspired by the brain's hierarchical organization of bottom-up\nsensory integration and top-down control, we design a set of disease-specific\nexpert groups to process brain sub-network under different condition, A disease\ngate mechanism guides the specializa-tion of expert groups, while a transformer\nlayer enables communication be-tween all sub-networks, generating a\ncomprehensive whole-brain represen-tation for downstream disease\nclassification. Experimental results show superior classification accuracy with\ninterpretable insights into how brain sub-networks contribute to different\nneurodegenerative conditions.",
      "tldr_zh": "本研究提出BrainNet-MoE，一种受大脑启发的混合专家学习模型，用于神经系统疾病的识别。该模型通过设计疾病特异性专家组处理不同条件下的脑网络，结合疾病门控机制和Transformer层实现子网络间的通信，生成全面的全脑表征用于下游疾病分类。实验结果显示，该模型在阿尔茨海默病和路易体痴呆的早期区分上表现出卓越的分类准确性和可解释性，为神经系统疾病的诊断提供了新的方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07640v1",
      "published_date": "2025-03-05 22:19:49 UTC",
      "updated_date": "2025-03-05 22:19:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:02:47.738847"
    },
    {
      "arxiv_id": "2503.03935v1",
      "title": "GlucoLens: Explainable Postprandial Blood Glucose Prediction from Diet and Physical Activity",
      "title_zh": "GlucoLens：基于饮食与体力活动的可解释性餐后血糖预测系统",
      "authors": [
        "Abdullah Mamun",
        "Asiful Arefeen",
        "Susan B. Racette",
        "Dorothy D. Sears",
        "Corrie M. Whisner",
        "Matthew P. Buman",
        "Hassan Ghasemzadeh"
      ],
      "abstract": "Postprandial hyperglycemia, marked by the blood glucose level exceeding the\nnormal range after meals, is a critical indicator of progression toward type 2\ndiabetes in prediabetic and healthy individuals. A key metric for understanding\nblood glucose dynamics after eating is the postprandial area under the curve\n(PAUC). Predicting PAUC in advance based on a person's diet and activity level\nand explaining what affects postprandial blood glucose could allow an\nindividual to adjust their lifestyle accordingly to maintain normal glucose\nlevels. In this paper, we propose GlucoLens, an explainable machine learning\napproach to predict PAUC and hyperglycemia from diet, activity, and recent\nglucose patterns. We conducted a five-week user study with 10 full-time working\nindividuals to develop and evaluate the computational model. Our machine\nlearning model takes multimodal data including fasting glucose, recent glucose,\nrecent activity, and macronutrient amounts, and provides an interpretable\nprediction of the postprandial glucose pattern. Our extensive analyses of the\ncollected data revealed that the trained model achieves a normalized root mean\nsquared error (NRMSE) of 0.123. On average, GlucoLense with a Random Forest\nbackbone provides a 16% better result than the baseline models. Additionally,\nGlucoLens predicts hyperglycemia with an accuracy of 74% and recommends\ndifferent options to help avoid hyperglycemia through diverse counterfactual\nexplanations. Code available: https://github.com/ab9mamun/GlucoLens.",
      "tldr_zh": "该研究提出了GlucoLens，一种可解释的机器学习方法，用于根据饮食、运动和近期血糖模式预测餐后血糖曲线下面积(PAUC)和高血糖风险。该系统通过整合空腹血糖、近期血糖、活动量和宏量营养素等多模态数据，采用随机森林模型实现了0.123的标准化均方根误差(NRMSE)，预测性能比基线模型提升16%。在5周真实用户研究中，GlucoLens不仅以74%的准确率预测高血糖事件，还能通过反事实解释提供个性化生活方式调整建议，帮助用户维持正常血糖水平。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.03935v1",
      "published_date": "2025-03-05 22:10:14 UTC",
      "updated_date": "2025-03-05 22:10:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:03:05.420491"
    },
    {
      "arxiv_id": "2503.03927v1",
      "title": "\"Impressively Scary:\" Exploring User Perceptions and Reactions to Unraveling Machine Learning Models in Social Media Applications",
      "title_zh": "“令人印象深刻却又令人恐惧”：探索用户对社交媒体应用中机器学习模型揭示的感知与反应",
      "authors": [
        "Jack West",
        "Bengisu Cagiltay",
        "Shirley Zhang",
        "Jingjie Li",
        "Kassem Fawaz",
        "Suman Banerjee"
      ],
      "abstract": "Machine learning models deployed locally on social media applications are\nused for features, such as face filters which read faces in-real time, and they\nexpose sensitive attributes to the apps. However, the deployment of machine\nlearning models, e.g., when, where, and how they are used, in social media\napplications is opaque to users. We aim to address this inconsistency and\ninvestigate how social media user perceptions and behaviors change once exposed\nto these models. We conducted user studies (N=21) and found that participants\nwere unaware to both what the models output and when the models were used in\nInstagram and TikTok, two major social media platforms. In response to being\nexposed to the models' functionality, we observed long term behavior changes in\n8 participants. Our analysis uncovers the challenges and opportunities in\nproviding transparency for machine learning models that interact with local\nuser data.",
      "tldr_zh": "这项研究探讨了社交媒体用户对本地部署的机器学习模型（如实时人脸滤镜）的认知与反应。通过针对Instagram和TikTok两大平台的用户调研（N=21），研究发现多数参与者对这些模型的功能和使用时机缺乏认知。当用户了解模型运作后，约38%的参与者表现出长期行为改变。研究揭示了提升机器学习模型透明度的挑战与机遇，特别是在处理用户敏感数据时。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.HC",
      "comment": "21 pages, 2 figures, to appear at CHI 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.03927v1",
      "published_date": "2025-03-05 21:51:52 UTC",
      "updated_date": "2025-03-05 21:51:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:03:05.414328"
    },
    {
      "arxiv_id": "2503.03924v1",
      "title": "De-skilling, Cognitive Offloading, and Misplaced Responsibilities: Potential Ironies of AI-Assisted Design",
      "title_zh": "去技能化、认知卸载与责任错位：AI辅助设计中的潜在讽刺",
      "authors": [
        "Prakash Shukla",
        "Phuong Bui",
        "Sean S Levy",
        "Max Kowalski",
        "Ali Baigelenov",
        "Paul Parsons"
      ],
      "abstract": "The rapid adoption of generative AI (GenAI) in design has sparked discussions\nabout its benefits and unintended consequences. While AI is often framed as a\ntool for enhancing productivity by automating routine tasks, historical\nresearch on automation warns of paradoxical effects, such as de-skilling and\nmisplaced responsibilities. To assess UX practitioners' perceptions of AI, we\nanalyzed over 120 articles and discussions from UX-focused subreddits. Our\nfindings indicate that while practitioners express optimism about AI reducing\nrepetitive work and augmenting creativity, they also highlight concerns about\nover-reliance, cognitive offloading, and the erosion of critical design skills.\nDrawing from human-automation interaction literature, we discuss how these\nperspectives align with well-documented automation ironies and function\nallocation challenges. We argue that UX professionals should critically\nevaluate AI's role beyond immediate productivity gains and consider its\nlong-term implications for creative autonomy and expertise. This study\ncontributes empirical insights into practitioners' perspectives and links them\nto broader debates on automation in design.",
      "tldr_zh": "这篇论文探讨了生成式AI（GenAI）在设计领域的快速应用及其潜在反讽效应。研究发现，尽管UX从业者普遍看好AI能减少重复工作并增强创造力，但也担忧过度依赖会导致认知卸载（cognitive offloading）、关键设计技能退化以及责任错位问题。通过分析120多篇UX社区讨论，研究揭示了这些担忧与自动化研究中的经典悖论相呼应，建议业界超越短期效率考量，审慎评估AI对创意自主性和专业能力的长期影响。该研究为设计自动化辩论提供了实证视角。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03924v1",
      "published_date": "2025-03-05 21:47:16 UTC",
      "updated_date": "2025-03-05 21:47:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:03:08.952463"
    },
    {
      "arxiv_id": "2503.03921v1",
      "title": "CREStE: Scalable Mapless Navigation with Internet Scale Priors and Counterfactual Guidance",
      "title_zh": "CREStE：基于互联网规模先验与反事实指导的可扩展无地图导航",
      "authors": [
        "Arthur Zhang",
        "Harshit Sikchi",
        "Amy Zhang",
        "Joydeep Biswas"
      ],
      "abstract": "We address the long-horizon mapless navigation problem: enabling robots to\ntraverse novel environments without relying on high-definition maps or precise\nwaypoints that specify exactly where to navigate. Achieving this requires\novercoming two major challenges -- learning robust, generalizable perceptual\nrepresentations of the environment without pre-enumerating all possible\nnavigation factors and forms of perceptual aliasing and utilizing these learned\nrepresentations to plan human-aligned navigation paths. Existing solutions\nstruggle to generalize due to their reliance on hand-curated object lists that\noverlook unforeseen factors, end-to-end learning of navigation features from\nscarce large-scale robot datasets, and handcrafted reward functions that scale\npoorly to diverse scenarios. To overcome these limitations, we propose CREStE,\nthe first method that learns representations and rewards for addressing the\nfull mapless navigation problem without relying on large-scale robot datasets\nor manually curated features. CREStE leverages visual foundation models trained\non internet-scale data to learn continuous bird's-eye-view representations\ncapturing elevation, semantics, and instance-level features. To utilize learned\nrepresentations for planning, we propose a counterfactual-based loss and active\nlearning procedure that focuses on the most salient perceptual cues by querying\nhumans for counterfactual trajectory annotations in challenging scenes. We\nevaluate CREStE in kilometer-scale navigation tasks across six distinct urban\nenvironments. CREStE significantly outperforms all state-of-the-art approaches\nwith 70% fewer human interventions per mission, including a 2-kilometer mission\nin an unseen environment with just 1 intervention; showcasing its robustness\nand effectiveness for long-horizon mapless navigation. For videos and\nadditional materials, see https://amrl.cs.utexas.edu/creste .",
      "tldr_zh": "该研究提出了CREStE，一种无需地图的长距离导航方法，利用互联网规模数据训练的视觉基础模型学习环境的连续鸟瞰图表示，包括高程、语义和实例级特征。为解决现有方法依赖手工特征和有限机器人数据集的问题，CREStE引入反事实损失和主动学习机制，通过人类标注反事实轨迹来优化规划。实验表明，CREStE在六种不同城市环境中的千米级导航任务中显著优于现有方法，在未见环境中完成2公里任务仅需1次人工干预，展示了其在长距离无地图导航中的鲁棒性和高效性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "19 pages, 10 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.03921v1",
      "published_date": "2025-03-05 21:42:46 UTC",
      "updated_date": "2025-03-05 21:42:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:03:12.482325"
    },
    {
      "arxiv_id": "2503.04847v1",
      "title": "Role of Databases in GenAI Applications",
      "title_zh": "数据库在生成式AI应用中的角色",
      "authors": [
        "Santosh Bhupathi"
      ],
      "abstract": "Generative AI (GenAI) is transforming industries by enabling intelligent\ncontent generation, automation, and decision-making. However, the effectiveness\nof GenAI applications depends significantly on efficient data storage,\nretrieval, and contextual augmentation. This paper explores the critical role\nof databases in GenAI workflows, emphasizing the importance of choosing the\nright database architecture to optimize performance, accuracy, and scalability.\nIt categorizes database roles into conversational context (key-value/document\ndatabases), situational context (relational databases/data lakehouses), and\nsemantic context (vector databases) each serving a distinct function in\nenriching AI-generated responses. Additionally, the paper highlights real-time\nquery processing, vector search for semantic retrieval, and the impact of\ndatabase selection on model efficiency and scalability. By leveraging a\nmulti-database approach, GenAI applications can achieve more context-aware,\npersonalized, and high-performing AI-driven solutions.",
      "tldr_zh": "该研究探讨了数据库在生成式AI(GenAI)应用中的关键作用。论文将数据库功能分为三类：会话上下文(键值/文档数据库)、情境上下文(关系数据库/数据湖仓)和语义上下文(向量数据库)，分别优化AI生成内容的不同维度。研究强调实时查询处理、向量搜索等技术对提升模型效率和可扩展性的重要性，指出采用多数据库架构能实现更上下文感知、个性化的高性能AI解决方案。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "97P30",
        "I.2.7; H.2.5"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04847v1",
      "published_date": "2025-03-05 20:32:21 UTC",
      "updated_date": "2025-03-05 20:32:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:03:38.898930"
    },
    {
      "arxiv_id": "2503.03866v2",
      "title": "Learning to Negotiate via Voluntary Commitment",
      "title_zh": "学习通过自愿承诺进行协商",
      "authors": [
        "Shuhui Zhu",
        "Baoxiang Wang",
        "Sriram Ganapathi Subramanian",
        "Pascal Poupart"
      ],
      "abstract": "The partial alignment and conflict of autonomous agents lead to mixed-motive\nscenarios in many real-world applications. However, agents may fail to\ncooperate in practice even when cooperation yields a better outcome. One well\nknown reason for this failure comes from non-credible commitments. To\nfacilitate commitments among agents for better cooperation, we define Markov\nCommitment Games (MCGs), a variant of commitment games, where agents can\nvoluntarily commit to their proposed future plans. Based on MCGs, we propose a\nlearnable commitment protocol via policy gradients. We further propose\nincentive-compatible learning to accelerate convergence to equilibria with\nbetter social welfare. Experimental results in challenging mixed-motive tasks\ndemonstrate faster empirical convergence and higher returns for our method\ncompared with its counterparts. Our code is available at\nhttps://github.com/shuhui-zhu/DCL.",
      "tldr_zh": "该研究提出了一种基于自愿承诺的谈判学习框架，通过定义Markov Commitment Games (MCGs) 来促进智能体之间的可信承诺，从而改善合作效果。研究者设计了一种可学习的承诺协议，利用策略梯度方法进行优化，并提出了激励兼容的学习机制以加速收敛到具有更高社会福利的均衡状态。实验结果表明，在复杂的混合动机任务中，该方法相比其他方法具有更快的收敛速度和更高的回报。",
      "categories": [
        "cs.AI",
        "cs.GT",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by AISTATS 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.03866v2",
      "published_date": "2025-03-05 19:55:10 UTC",
      "updated_date": "2025-03-19 07:23:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:03:36.798854"
    },
    {
      "arxiv_id": "2503.03862v1",
      "title": "Not-Just-Scaling Laws: Towards a Better Understanding of the Downstream Impact of Language Model Design Decisions",
      "title_zh": "超越缩放定律：深入理解语言模型设计决策对下游任务的影响",
      "authors": [
        "Emmy Liu",
        "Amanda Bertsch",
        "Lintang Sutawika",
        "Lindia Tjuatja",
        "Patrick Fernandes",
        "Lara Marinov",
        "Michael Chen",
        "Shreya Singhal",
        "Carolin Lawrence",
        "Aditi Raghunathan",
        "Kiril Gashteovski",
        "Graham Neubig"
      ],
      "abstract": "Improvements in language model capabilities are often attributed to\nincreasing model size or training data, but in some cases smaller models\ntrained on curated data or with different architectural decisions can\noutperform larger ones trained on more tokens. What accounts for this? To\nquantify the impact of these design choices, we meta-analyze 92 open-source\npretrained models across a wide array of scales, including state-of-the-art\nopen-weights models as well as less performant models and those with less\nconventional design decisions. We find that by incorporating features besides\nmodel size and number of training tokens, we can achieve a relative 3-28%\nincrease in ability to predict downstream performance compared with using scale\nalone. Analysis of model design decisions reveal insights into data\ncomposition, such as the trade-off between language and code tasks at 15-25\\%\ncode, as well as the better performance of some architectural decisions such as\nchoosing rotary over learned embeddings. Broadly, our framework lays a\nfoundation for more systematic investigation of how model development choices\nshape final capabilities.",
      "tldr_zh": "该研究通过元分析92个开源预训练模型，深入探讨了语言模型设计决策对下游任务性能的影响，而不仅仅是关注模型规模和训练数据量。研究发现，结合数据组成、架构选择（如使用rotary embeddings而非learned embeddings）等因素，能够比仅依赖规模更准确地预测模型性能，提升幅度达3-28%。此外，研究还揭示了数据组成中语言与代码任务的权衡点（15-25%代码比例）。这项工作为系统化研究模型开发决策对最终能力的影响奠定了基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03862v1",
      "published_date": "2025-03-05 19:46:04 UTC",
      "updated_date": "2025-03-05 19:46:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:03:41.466882"
    },
    {
      "arxiv_id": "2503.03842v1",
      "title": "Task-Agnostic Attacks Against Vision Foundation Models",
      "title_zh": "针对视觉基础模型的任务无关攻击",
      "authors": [
        "Brian Pulfer",
        "Yury Belousov",
        "Vitaliy Kinakh",
        "Teddy Furon",
        "Slava Voloshynovskiy"
      ],
      "abstract": "The study of security in machine learning mainly focuses on downstream\ntask-specific attacks, where the adversarial example is obtained by optimizing\na loss function specific to the downstream task. At the same time, it has\nbecome standard practice for machine learning practitioners to adopt publicly\navailable pre-trained vision foundation models, effectively sharing a common\nbackbone architecture across a multitude of applications such as\nclassification, segmentation, depth estimation, retrieval, question-answering\nand more. The study of attacks on such foundation models and their impact to\nmultiple downstream tasks remains vastly unexplored. This work proposes a\ngeneral framework that forges task-agnostic adversarial examples by maximally\ndisrupting the feature representation obtained with foundation models. We\nextensively evaluate the security of the feature representations obtained by\npopular vision foundation models by measuring the impact of this attack on\nmultiple downstream tasks and its transferability between models.",
      "tldr_zh": "本研究提出了一种针对视觉基础模型(Vision Foundation Models)的任务无关攻击框架，通过最大化破坏基础模型的特征表示来生成对抗样本。与传统的针对特定下游任务的攻击不同，该方法能够同时影响分类、分割、深度估计、检索和问答等多种应用。研究评估了该攻击对多个下游任务的影响及其在模型间的可迁移性，揭示了视觉基础模型在安全性方面的潜在风险。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03842v1",
      "published_date": "2025-03-05 19:15:14 UTC",
      "updated_date": "2025-03-05 19:15:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:04:32.296559"
    },
    {
      "arxiv_id": "2503.05828v1",
      "title": "Market-based Architectures in RL and Beyond",
      "title_zh": "基于市场的架构在强化学习及其他领域的应用",
      "authors": [
        "Abhimanyu Pallavi Sudhir",
        "Long Tran-Thanh"
      ],
      "abstract": "Market-based agents refer to reinforcement learning agents which determine\ntheir actions based on an internal market of sub-agents. We introduce a new\ntype of market-based algorithm where the state itself is factored into several\naxes called ``goods'', which allows for greater specialization and parallelism\nthan existing market-based RL algorithms. Furthermore, we argue that\nmarket-based algorithms have the potential to address many current challenges\nin AI, such as search, dynamic scaling and complete feedback, and demonstrate\nthat they may be seen to generalize neural networks; finally, we list some\nnovel ways that market algorithms may be applied in conjunction with Large\nLanguage Models for immediate practical applicability.",
      "tldr_zh": "该论文提出了一种新型基于市场的强化学习算法，将状态分解为多个称为\"商品\"（goods）的维度，相比现有方法能实现更好的专业化和并行性。研究指出市场算法可解决AI领域的搜索、动态扩展和完整反馈等核心挑战，并论证其能泛化神经网络结构。作者还探讨了市场算法与大型语言模型（LLMs）结合的新应用方向。",
      "categories": [
        "cs.AI",
        "econ.TH"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at AAMAS 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.05828v1",
      "published_date": "2025-03-05 19:09:29 UTC",
      "updated_date": "2025-03-05 19:09:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:03:55.920933"
    },
    {
      "arxiv_id": "2503.03750v2",
      "title": "The MASK Benchmark: Disentangling Honesty From Accuracy in AI Systems",
      "title_zh": "MASK 基准测试：从 AI 系统的准确性中剥离诚实性",
      "authors": [
        "Richard Ren",
        "Arunim Agarwal",
        "Mantas Mazeika",
        "Cristina Menghini",
        "Robert Vacareanu",
        "Brad Kenstler",
        "Mick Yang",
        "Isabelle Barrass",
        "Alice Gatti",
        "Xuwang Yin",
        "Eduardo Trevino",
        "Matias Geralnik",
        "Adam Khoja",
        "Dean Lee",
        "Summer Yue",
        "Dan Hendrycks"
      ],
      "abstract": "As large language models (LLMs) become more capable and agentic, the\nrequirement for trust in their outputs grows significantly, yet at the same\ntime concerns have been mounting that models may learn to lie in pursuit of\ntheir goals. To address these concerns, a body of work has emerged around the\nnotion of \"honesty\" in LLMs, along with interventions aimed at mitigating\ndeceptive behaviors. However, evaluations of honesty are currently highly\nlimited, with no benchmark combining large scale and applicability to all\nmodels. Moreover, many benchmarks claiming to measure honesty in fact simply\nmeasure accuracy--the correctness of a model's beliefs--in disguise. In this\nwork, we introduce a large-scale human-collected dataset for measuring honesty\ndirectly, allowing us to disentangle accuracy from honesty for the first time.\nAcross a diverse set of LLMs, we find that while larger models obtain higher\naccuracy on our benchmark, they do not become more honest. Surprisingly, while\nmost frontier LLMs obtain high scores on truthfulness benchmarks, we find a\nsubstantial propensity in frontier LLMs to lie when pressured to do so,\nresulting in low honesty scores on our benchmark. We find that simple methods,\nsuch as representation engineering interventions, can improve honesty. These\nresults underscore the growing need for robust evaluations and effective\ninterventions to ensure LLMs remain trustworthy.",
      "tldr_zh": "该研究提出了MASK基准测试，旨在区分大型语言模型(LLMs)的诚实性与准确性。通过构建大规模人工收集的数据集，首次实现了对诚实性的直接评估，揭示了模型在准确性与诚实性之间的差异。研究发现，虽然更大规模的模型在准确性上表现更好，但其诚实性并未同步提升；前沿LLMs在压力下表现出明显的撒谎倾向。研究还表明，简单的干预方法（如表征工程技术）可以提高模型的诚实性，强调了开发更强大评估和干预措施的必要性，以确保LLMs的可信性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "Website: https://www.mask-benchmark.ai",
      "pdf_url": "http://arxiv.org/pdf/2503.03750v2",
      "published_date": "2025-03-05 18:59:23 UTC",
      "updated_date": "2025-03-20 23:06:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:04:11.148752"
    },
    {
      "arxiv_id": "2503.03746v1",
      "title": "Process-based Self-Rewarding Language Models",
      "title_zh": "基于过程的自我奖励语言模型",
      "authors": [
        "Shimao Zhang",
        "Xiao Liu",
        "Xin Zhang",
        "Junxiao Liu",
        "Zheheng Luo",
        "Shujian Huang",
        "Yeyun Gong"
      ],
      "abstract": "Large Language Models have demonstrated outstanding performance across\nvarious downstream tasks and have been widely applied in multiple scenarios.\nHuman-annotated preference data is used for training to further improve LLMs'\nperformance, which is constrained by the upper limit of human performance.\nTherefore, Self-Rewarding method has been proposed, where LLMs generate\ntraining data by rewarding their own outputs. However, the existing\nself-rewarding paradigm is not effective in mathematical reasoning scenarios\nand may even lead to a decline in performance. In this work, we propose the\nProcess-based Self-Rewarding pipeline for language models, which introduces\nlong-thought reasoning, step-wise LLM-as-a-Judge, and step-wise preference\noptimization within the self-rewarding paradigm. Our new paradigm successfully\nenhances the performance of LLMs on multiple mathematical reasoning benchmarks\nthrough iterative Process-based Self-Rewarding, demonstrating the immense\npotential of self-rewarding to achieve LLM reasoning that may surpass human\ncapabilities.",
      "tldr_zh": "本研究提出了一种基于过程的自奖励语言模型(Process-based Self-Rewarding)框架，旨在解决现有自奖励方法在数学推理场景中效果不佳的问题。该框架通过引入长链思维推理、分步LLM-as-a-Judge评估以及分步偏好优化，显著提升了语言模型在多个数学推理基准测试中的表现。实验结果表明，这种迭代式的过程自奖励方法能够突破人类性能上限，展现了自奖励技术在实现超越人类推理能力方面的巨大潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03746v1",
      "published_date": "2025-03-05 18:58:44 UTC",
      "updated_date": "2025-03-05 18:58:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:04:14.261546"
    },
    {
      "arxiv_id": "2503.03743v1",
      "title": "CHOP: Mobile Operating Assistant with Constrained High-frequency Optimized Subtask Planning",
      "title_zh": "CHOP：具备高频优化子任务规划约束的移动操作助手",
      "authors": [
        "Yuqi Zhou",
        "Shuai Wang",
        "Sunhao Dai",
        "Qinglin Jia",
        "Zhaocheng Du",
        "Zhenhua Dong",
        "Jun Xu"
      ],
      "abstract": "The advancement of visual language models (VLMs) has enhanced mobile device\noperations, allowing simulated human-like actions to address user requirements.\nCurrent VLM-based mobile operating assistants can be structured into three\nlevels: task, subtask, and action. The subtask level, linking high-level goals\nwith low-level executable actions, is crucial for task completion but faces two\nchallenges: ineffective subtasks that lower-level agent cannot execute and\ninefficient subtasks that fail to contribute to the completion of the\nhigher-level task. These challenges stem from VLM's lack of experience in\ndecomposing subtasks within GUI scenarios in multi-agent architecture. To\naddress these, we propose a new mobile assistant architecture with constrained\nhigh-frequency o}ptimized planning (CHOP). Our approach overcomes the VLM's\ndeficiency in GUI scenarios planning by using human-planned subtasks as the\nbasis vector. We evaluate our architecture in both English and Chinese contexts\nacross 20 Apps, demonstrating significant improvements in both effectiveness\nand efficiency. Our dataset and code is available at\nhttps://github.com/Yuqi-Zhou/CHOP",
      "tldr_zh": "该研究提出了CHOP，一种基于约束高频优化子任务规划(Constrained High-frequency Optimized Planning)的移动操作系统助手架构，旨在解决视觉语言模型(VLMs)在多智能体架构下分解GUI场景子任务时面临的无效和低效问题。通过以人工规划的子任务为基础向量，CHOP克服了VLM在GUI场景规划中的不足。实验在20个应用程序的中英文环境下进行，验证了该架构在有效性和效率上的显著提升。相关数据集和代码已开源。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03743v1",
      "published_date": "2025-03-05 18:56:16 UTC",
      "updated_date": "2025-03-05 18:56:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:04:21.074508"
    },
    {
      "arxiv_id": "2503.03802v1",
      "title": "RiskAgent: Autonomous Medical AI Copilot for Generalist Risk Prediction",
      "title_zh": "RiskAgent：面向通用风险预测的自主医疗AI副驾驶",
      "authors": [
        "Fenglin Liu",
        "Jinge Wu",
        "Hongjian Zhou",
        "Xiao Gu",
        "Soheila Molaei",
        "Anshul Thakur",
        "Lei Clifton",
        "Honghan Wu",
        "David A. Clifton"
      ],
      "abstract": "The application of Large Language Models (LLMs) to various clinical\napplications has attracted growing research attention. However, real-world\nclinical decision-making differs significantly from the standardized,\nexam-style scenarios commonly used in current efforts. In this paper, we\npresent the RiskAgent system to perform a broad range of medical risk\npredictions, covering over 387 risk scenarios across diverse complex diseases,\ne.g., cardiovascular disease and cancer. RiskAgent is designed to collaborate\nwith hundreds of clinical decision tools, i.e., risk calculators and scoring\nsystems that are supported by evidence-based medicine. To evaluate our method,\nwe have built the first benchmark MedRisk specialized for risk prediction,\nincluding 12,352 questions spanning 154 diseases, 86 symptoms, 50 specialties,\nand 24 organ systems. The results show that our RiskAgent, with 8 billion model\nparameters, achieves 76.33% accuracy, outperforming the most recent commercial\nLLMs, o1, o3-mini, and GPT-4.5, and doubling the 38.39% accuracy of GPT-4o. On\nrare diseases, e.g., Idiopathic Pulmonary Fibrosis (IPF), RiskAgent outperforms\no1 and GPT-4.5 by 27.27% and 45.46% accuracy, respectively. Finally, we further\nconduct a generalization evaluation on an external evidence-based diagnosis\nbenchmark and show that our RiskAgent achieves the best results. These\nencouraging results demonstrate the great potential of our solution for diverse\ndiagnosis domains. To improve the adaptability of our model in different\nscenarios, we have built and open-sourced a family of models ranging from 1\nbillion to 70 billion parameters. Our code, data, and models are all available\nat https://github.com/AI-in-Health/RiskAgent.",
      "tldr_zh": "该研究提出了RiskAgent，一个面向通用医疗风险预测的自主AI助手。该系统覆盖387种复杂疾病风险场景，整合了数百种基于循证医学的临床决策工具，如风险计算器和评分系统。研究构建了首个专注于风险预测的基准MedRisk，包含12,352个问题，涉及154种疾病。实验表明，RiskAgent在8亿参数规模下达到76.33%的准确率，显著优于GPT-4等商业大模型，尤其在罕见疾病如特发性肺纤维化(IPF)上表现突出。研究还开源了1亿到700亿参数规模的模型系列，以提升不同场景的适应性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages, 6 figures, 4 tables, code is available at\n  https://github.com/AI-in-Health/RiskAgent",
      "pdf_url": "http://arxiv.org/pdf/2503.03802v1",
      "published_date": "2025-03-05 18:46:51 UTC",
      "updated_date": "2025-03-05 18:46:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:04:46.239264"
    },
    {
      "arxiv_id": "2503.03733v1",
      "title": "Rethinking Deep Clustering Paradigms: Self-Supervision Is All You Need",
      "title_zh": "重新思考深度聚类范式：自监督即一切",
      "authors": [
        "Amal Shaheena",
        "Nairouz Mrabahb",
        "Riadh Ksantinia",
        "Abdulla Alqaddoumia"
      ],
      "abstract": "The recent advances in deep clustering have been made possible by significant\nprogress in self-supervised and pseudo-supervised learning. However, the\ntrade-off between self-supervision and pseudo-supervision can give rise to\nthree primary issues. The joint training causes Feature Randomness and Feature\nDrift, whereas the independent training causes Feature Randomness and Feature\nTwist. In essence, using pseudo-labels generates random and unreliable\nfeatures. The combination of pseudo-supervision and self-supervision drifts the\nreliable clustering-oriented features. Moreover, moving from self-supervision\nto pseudo-supervision can twist the curved latent manifolds. This paper\naddresses the limitations of existing deep clustering paradigms concerning\nFeature Randomness, Feature Drift, and Feature Twist. We propose a new paradigm\nwith a new strategy that replaces pseudo-supervision with a second round of\nself-supervision training. The new strategy makes the transition between\ninstance-level self-supervision and neighborhood-level self-supervision\nsmoother and less abrupt. Moreover, it prevents the drifting effect that is\ncaused by the strong competition between instance-level self-supervision and\nclustering-level pseudo-supervision. Moreover, the absence of the\npseudo-supervision prevents the risk of generating random features. With this\nnovel approach, our paper introduces a Rethinking of the Deep Clustering\nParadigms, denoted by R-DC. Our model is specifically designed to address three\nprimary challenges encountered in Deep Clustering: Feature Randomness, Feature\nDrift, and Feature Twist. Experimental results conducted on six datasets have\nshown that the two-level self-supervision training yields substantial\nimprovements.",
      "tldr_zh": "本文重新思考了深度聚类范式，提出了一种仅依赖自监督学习的新策略，称为R-DC。该方法通过用第二轮自监督训练替代伪监督，解决了现有深度聚类中的特征随机性、特征漂移和特征扭曲问题。新策略实现了从实例级自监督到邻域级自监督的平滑过渡，避免了伪监督带来的随机特征生成和特征漂移风险。实验表明，这种两级自监督训练在六个数据集上显著提升了聚类性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03733v1",
      "published_date": "2025-03-05 18:44:35 UTC",
      "updated_date": "2025-03-05 18:44:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:04:40.542186"
    },
    {
      "arxiv_id": "2503.04844v3",
      "title": "Universal Narrative Model: an Author-centric Storytelling Framework for Generative AI",
      "title_zh": "通用叙事模型：面向生成式AI的以作者为核心的故事创作框架",
      "authors": [
        "Hank Gerba"
      ],
      "abstract": "Generative AI promises to finally realize dynamic, personalized storytelling\ntechnologies across a range of media. To date, experimentation with generative\nAI in the field of procedural narrative generation has been quite promising\nfrom a technical perspective. However, fundamental narrative dilemmas remain,\nsuch as the balance between player agency and narrative coherence, and no\nrigorous narrative standard has been proposed to specifically leverage the\nstrengths of generative AI. In this paper, we propose the Universal Narrative\nModel (UNM), an open and extensible standard designed to place writers at the\ncenter of future narrative design workflows and enable interoperability across\nauthoring platforms. By encoding an author's intent according to an objective\nnarrative model, the UNM enables narrative portability as well as intent-based\nconstraints for generative systems.",
      "tldr_zh": "本研究提出了通用叙事模型（Universal Narrative Model, UNM），一种以作者为中心的开放可扩展叙事框架，旨在解决生成式AI在叙事创作中的核心问题，如玩家自主性与叙事连贯性的平衡。UNM通过编码作者的意图，提供了一种客观的叙事标准，支持跨平台的叙事可移植性，并为生成系统提供基于意图的约束，从而推动生成式AI在动态个性化叙事技术中的应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04844v3",
      "published_date": "2025-03-05 18:29:15 UTC",
      "updated_date": "2025-03-16 21:53:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:05:00.389437"
    },
    {
      "arxiv_id": "2503.03724v1",
      "title": "Deep Causal Behavioral Policy Learning: Applications to Healthcare",
      "title_zh": "深度因果行为策略学习：在医疗保健中的应用",
      "authors": [
        "Jonas Knecht",
        "Anna Zink",
        "Jonathan Kolstad",
        "Maya Petersen"
      ],
      "abstract": "We present a deep learning-based approach to studying dynamic clinical\nbehavioral regimes in diverse non-randomized healthcare settings. Our proposed\nmethodology - deep causal behavioral policy learning (DC-BPL) - uses deep\nlearning algorithms to learn the distribution of high-dimensional clinical\naction paths, and identifies the causal link between these action paths and\npatient outcomes. Specifically, our approach: (1) identifies the causal effects\nof provider assignment on clinical outcomes; (2) learns the distribution of\nclinical actions a given provider would take given evolving patient\ninformation; (3) and combines these steps to identify the optimal provider for\na given patient type and emulate that provider's care decisions. Underlying\nthis strategy, we train a large clinical behavioral model (LCBM) on electronic\nhealth records data using a transformer architecture, and demonstrate its\nability to estimate clinical behavioral policies. We propose a novel\ninterpretation of a behavioral policy learned using the LCBM: that it is an\nefficient encoding of complex, often implicit, knowledge used to treat a\npatient. This allows us to learn a space of policies that are critical to a\nwide range of healthcare applications, in which the vast majority of clinical\nknowledge is acquired tacitly through years of practice and only a tiny\nfraction of information relevant to patient care is written down (e.g. in\ntextbooks, studies or standardized guidelines).",
      "tldr_zh": "该研究提出了一种基于深度学习的因果行为策略学习方法（DC-BPL），用于分析非随机化医疗环境中的动态临床行为模式。该方法通过深度学习算法学习高维临床行为路径的分布，并识别这些路径与患者结果之间的因果关系。具体包括：识别提供者分配对临床结果的因果影响、学习给定提供者在患者信息变化下的临床行为分布，以及结合这些步骤为特定患者类型确定最佳提供者并模拟其护理决策。研究利用Transformer架构在电子健康记录数据上训练大型临床行为模型（LCBM），展示了其估计临床行为策略的能力，并提出了一种新颖的解读：行为策略是对复杂且通常隐性的临床知识的高效编码，为医疗应用中的策略学习提供了重要支持。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03724v1",
      "published_date": "2025-03-05 18:24:58 UTC",
      "updated_date": "2025-03-05 18:24:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:05:15.460082"
    },
    {
      "arxiv_id": "2503.03717v1",
      "title": "Machine Learning in Biomechanics: Key Applications and Limitations in Walking, Running, and Sports Movements",
      "title_zh": "生物力学中的机器学习：行走、跑步与运动动作的关键应用与局限",
      "authors": [
        "Carlo Dindorf",
        "Fabian Horst",
        "Djordje Slijepčević",
        "Bernhard Dumphart",
        "Jonas Dully",
        "Matthias Zeppelzauer",
        "Brian Horsak",
        "Michael Fröhlich"
      ],
      "abstract": "This chapter provides an overview of recent and promising Machine Learning\napplications, i.e. pose estimation, feature estimation, event detection, data\nexploration & clustering, and automated classification, in gait (walking and\nrunning) and sports biomechanics. It explores the potential of Machine Learning\nmethods to address challenges in biomechanical workflows, highlights central\nlimitations, i.e. data and annotation availability and explainability, that\nneed to be addressed, and emphasises the importance of interdisciplinary\napproaches for fully harnessing the potential of Machine Learning in gait and\nsports biomechanics.",
      "tldr_zh": "本章综述了机器学习在步态（行走和跑步）和运动生物力学中的关键应用，包括姿态估计、特征估计、事件检测、数据探索与聚类以及自动分类。研究探讨了机器学习方法在生物力学工作流程中的潜力，同时指出了数据与标注可用性以及模型可解释性等核心限制。文章强调，跨学科合作对于充分发挥机器学习在步态和运动生物力学中的潜力至关重要。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03717v1",
      "published_date": "2025-03-05 18:10:11 UTC",
      "updated_date": "2025-03-05 18:10:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:05:14.410565"
    },
    {
      "arxiv_id": "2503.03708v2",
      "title": "Rethinking Video Tokenization: A Conditioned Diffusion-based Approach",
      "title_zh": "重新思考视频标记化：一种基于条件扩散的方法",
      "authors": [
        "Nianzu Yang",
        "Pandeng Li",
        "Liming Zhao",
        "Yang Li",
        "Chen-Wei Xie",
        "Yehui Tang",
        "Xudong Lu",
        "Zhihang Liu",
        "Yun Zheng",
        "Yu Liu",
        "Junchi Yan"
      ],
      "abstract": "Existing video tokenizers typically use the traditional Variational\nAutoencoder (VAE) architecture for video compression and reconstruction.\nHowever, to achieve good performance, its training process often relies on\ncomplex multi-stage training tricks that go beyond basic reconstruction loss\nand KL regularization. Among these tricks, the most challenging is the precise\ntuning of adversarial training with additional Generative Adversarial Networks\n(GANs) in the final stage, which can hinder stable convergence. In contrast to\nGANs, diffusion models offer more stable training processes and can generate\nhigher-quality results. Inspired by these advantages, we propose CDT, a novel\nConditioned Diffusion-based video Tokenizer, that replaces the GAN-based\ndecoder with a conditional causal diffusion model. The encoder compresses\nspatio-temporal information into compact latents, while the decoder\nreconstructs videos through a reverse diffusion process conditioned on these\nlatents. During inference, we incorporate a feature cache mechanism to generate\nvideos of arbitrary length while maintaining temporal continuity and adopt\nsampling acceleration technique to enhance efficiency. Trained using only a\nbasic MSE diffusion loss for reconstruction, along with KL term and LPIPS\nperceptual loss from scratch, extensive experiments demonstrate that CDT\nachieves state-of-the-art performance in video reconstruction tasks with just a\nsingle-step sampling. Even a scaled-down version of CDT (3$\\times$ inference\nspeedup) still performs comparably with top baselines. Moreover, the latent\nvideo generation model trained with CDT also exhibits superior performance. The\nsource code and pretrained weights will be released shortly, so please stay\ntuned for updates!",
      "tldr_zh": "该论文提出CDT（条件扩散视频分词器），创新性地用条件因果扩散模型取代传统VAE-GAN架构中的GAN解码器。通过编码器压缩时空信息为紧凑潜变量，解码器基于这些潜变量通过反向扩散过程重建视频，该方法仅需基础MSE扩散损失、KL项和LPIPS感知损失就能实现稳定训练。实验表明，CDT在单步采样下即达到视频重建任务的最优性能，其轻量版（推理速度提升3倍）仍保持顶级基线水平，且基于CDT训练的潜视频生成模型也展现出卓越性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03708v2",
      "published_date": "2025-03-05 17:59:19 UTC",
      "updated_date": "2025-03-08 14:48:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:05:27.341276"
    },
    {
      "arxiv_id": "2503.03707v1",
      "title": "Curating Demonstrations using Online Experience",
      "title_zh": "利用在线经验筛选演示数据",
      "authors": [
        "Annie S. Chen",
        "Alec M. Lessing",
        "Yuejiang Liu",
        "Chelsea Finn"
      ],
      "abstract": "Many robot demonstration datasets contain heterogeneous demonstrations of\nvarying quality. This heterogeneity may benefit policy pre-training, but can\nhinder robot performance when used with a final imitation learning objective.\nIn particular, some strategies in the data may be less reliable than others or\nmay be underrepresented in the data, leading to poor performance when such\nstrategies are sampled at test time. Moreover, such unreliable or\nunderrepresented strategies can be difficult even for people to discern, and\nsifting through demonstration datasets is time-consuming and costly. On the\nother hand, policy performance when trained on such demonstrations can reflect\nthe reliability of different strategies. We thus propose for robots to\nself-curate based on online robot experience (Demo-SCORE). More specifically,\nwe train and cross-validate a classifier to discern successful policy roll-outs\nfrom unsuccessful ones and use the classifier to filter heterogeneous\ndemonstration datasets. Our experiments in simulation and the real world show\nthat Demo-SCORE can effectively identify suboptimal demonstrations without\nmanual curation. Notably, Demo-SCORE achieves over 15-35% higher absolute\nsuccess rate in the resulting policy compared to the base policy trained with\nall original demonstrations.",
      "tldr_zh": "该研究提出Demo-SCORE方法，通过在线机器人经验自主筛选异构演示数据，解决传统模仿学习中因演示质量参差不齐导致的性能下降问题。该方法训练分类器区分策略执行成功与失败的演示，自动过滤低质量数据，无需人工干预。实验表明，使用该方法的策略成功率比原始演示训练的基础策略高出15-35%，有效提升了机器人模仿学习性能。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03707v1",
      "published_date": "2025-03-05 17:58:16 UTC",
      "updated_date": "2025-03-05 17:58:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:05:44.185040"
    },
    {
      "arxiv_id": "2503.04843v2",
      "title": "Self-Supervised Z-Slice Augmentation for 3D Bio-Imaging via Knowledge Distillation",
      "title_zh": "基于知识蒸馏的自监督Z轴切片增强技术在3D生物成像中的应用",
      "authors": [
        "Alessandro Pasqui",
        "Sajjad Mahdavi",
        "Benoit Vianay",
        "Alexandra Colin",
        "Alex McDougall",
        "Rémi Dumollard",
        "Yekaterina A. Miroshnikova",
        "Elsa Labrune",
        "Hervé Turlier"
      ],
      "abstract": "Three-dimensional biological microscopy has significantly advanced our\nunderstanding of complex biological structures. However, limitations due to\nmicroscopy techniques, sample properties or phototoxicity often result in poor\nz-resolution, hindering accurate cellular measurements. Here, we introduce\nZAugNet, a fast, accurate, and self-supervised deep learning method for\nenhancing z-resolution in biological images. By performing nonlinear\ninterpolation between consecutive slices, ZAugNet effectively doubles\nresolution with each iteration. Compared on several microscopy modalities and\nbiological objects, it outperforms competing methods on most metrics. Our\nmethod leverages a generative adversarial network (GAN) architecture combined\nwith knowledge distillation to maximize prediction speed without compromising\naccuracy. We also developed ZAugNet+, an extended version enabling continuous\ninterpolation at arbitrary distances, making it particularly useful for\ndatasets with nonuniform slice spacing. Both ZAugNet and ZAugNet+ provide\nhigh-performance, scalable z-slice augmentation solutions for large-scale 3D\nimaging. They are available as open-source frameworks in PyTorch, with an\nintuitive Colab notebook interface for easy access by the scientific community.",
      "tldr_zh": "该研究提出ZAugNet，一种基于知识蒸馏的自监督深度学习模型，用于提升生物显微图像的z轴分辨率。该方法采用生成对抗网络(GAN)架构，通过非线性插值使分辨率逐次倍增，在多种显微模态和生物样本上表现优于现有方法。研究还开发了支持任意间距连续插值的ZAugNet+版本，为大规模3D成像提供了高性能、可扩展的解决方案，相关代码已开源。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV",
        "q-bio.QM",
        "68",
        "I.4.3; I.4.4; I.2.0; J.3"
      ],
      "primary_category": "cs.CV",
      "comment": "25 pages, 5 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2503.04843v2",
      "published_date": "2025-03-05 17:50:35 UTC",
      "updated_date": "2025-03-17 21:52:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:05:53.540030"
    },
    {
      "arxiv_id": "2503.03693v1",
      "title": "ILLC: Iterative Layer-by-Layer Compression for Enhancing Structural Faithfulness in SpArX",
      "title_zh": "ILLC：逐层迭代压缩以增强 SpArX 中的结构忠实性",
      "authors": [
        "Ungsik Kim"
      ],
      "abstract": "In the field of Explainable Artificial Intelligence (XAI), argumentative XAI\napproaches have been proposed to represent the internal reasoning process of\ndeep neural networks in a more transparent way by interpreting hidden nodes as\narguements. However, as the number of layers increases, existing compression\nmethods simplify all layers at once, which lead to high accumulative\ninformation loss. To compensate for this, we propose an iterative\nlayer-by-layer compression technique in which each layer is compressed\nseparately and the reduction error in the next layer is immediately compensated\nfor, thereby improving the overall input-output and structural fidelity of the\nmodel. Experiments on the Breast Cancer Diagnosis dataset show that, compared\nto traditional compression, the method reduces input-output and structural\nunfaithfulness, and maintains a more consistent attack-support relationship in\nthe Argumentative Explanation scheme. This is significant because it provides a\nnew way to make complex MLP models more compact while still conveying their\ninternal inference logic without distortion.",
      "tldr_zh": "该研究提出了一种迭代逐层压缩技术ILLC，用于增强多层感知机(MLP)模型在结构化论证解释(SpArX)中的保真度。与传统的整体压缩方法不同，ILLC逐层独立压缩，并立即补偿下一层的还原误差，从而减少了输入输出和结构上的失真，保持了论证解释中攻击-支持关系的一致性。在乳腺癌诊断数据集上的实验表明，该方法在压缩复杂MLP模型的同时，能够更准确地传达模型的内部推理逻辑，为可解释人工智能(XAI)领域提供了一种新的模型压缩思路。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.03693v1",
      "published_date": "2025-03-05 17:43:49 UTC",
      "updated_date": "2025-03-05 17:43:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:05:52.484528"
    },
    {
      "arxiv_id": "2503.04842v1",
      "title": "Replicating Human Social Perception in Generative AI: Evaluating the Valence-Dominance Model",
      "title_zh": "在生成式人工智能中复制人类社会感知：评估效价-支配模型",
      "authors": [
        "Necdet Gurkan",
        "Kimathi Njoki",
        "Jordan W. Suchow"
      ],
      "abstract": "As artificial intelligence (AI) continues to advance--particularly in\ngenerative models--an open question is whether these systems can replicate\nfoundational models of human social perception. A well-established framework in\nsocial cognition suggests that social judgments are organized along two primary\ndimensions: valence (e.g., trustworthiness, warmth) and dominance (e.g., power,\nassertiveness). This study examines whether multimodal generative AI systems\ncan reproduce this valence-dominance structure when evaluating facial images\nand how their representations align with those observed across world regions.\nThrough principal component analysis (PCA), we found that the extracted\ndimensions closely mirrored the theoretical structure of valence and dominance,\nwith trait loadings aligning with established definitions. However, many world\nregions and generative AI models also exhibited a third component, the nature\nand significance of which warrant further investigation. These findings\ndemonstrate that multimodal generative AI systems can replicate key aspects of\nhuman social perception, raising important questions about their implications\nfor AI-driven decision-making and human-AI interactions.",
      "tldr_zh": "本研究探讨了多模态生成式AI系统能否复制人类社交感知中的“情感-支配”模型（valence-dominance model），即社交判断主要基于情感（如可信度、温暖）和支配（如权力、自信）两个维度。通过主成分分析（PCA），研究发现AI提取的维度与理论模型高度一致，但部分地区和模型还出现了第三个维度，其性质尚需进一步研究。结果表明，生成式AI能够复制人类社交感知的关键特征，这对AI驱动的决策和人类-AI交互具有重要意义。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04842v1",
      "published_date": "2025-03-05 17:35:18 UTC",
      "updated_date": "2025-03-05 17:35:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:06:07.701515"
    },
    {
      "arxiv_id": "2503.03800v1",
      "title": "Multi-Agent Systems Powered by Large Language Models: Applications in Swarm Intelligence",
      "title_zh": "基于大语言模型的多智能体系统：在群体智能中的应用",
      "authors": [
        "Cristian Jimenez-Romero",
        "Alper Yegenoglu",
        "Christian Blum"
      ],
      "abstract": "This work examines the integration of large language models (LLMs) into\nmulti-agent simulations by replacing the hard-coded programs of agents with\nLLM-driven prompts. The proposed approach is showcased in the context of two\nexamples of complex systems from the field of swarm intelligence: ant colony\nforaging and bird flocking. Central to this study is a toolchain that\nintegrates LLMs with the NetLogo simulation platform, leveraging its Python\nextension to enable communication with GPT-4o via the OpenAI API. This\ntoolchain facilitates prompt-driven behavior generation, allowing agents to\nrespond adaptively to environmental data. For both example applications\nmentioned above, we employ both structured, rule-based prompts and autonomous,\nknowledge-driven prompts. Our work demonstrates how this toolchain enables LLMs\nto study self-organizing processes and induce emergent behaviors within\nmulti-agent environments, paving the way for new approaches to exploring\nintelligent systems and modeling swarm intelligence inspired by natural\nphenomena. We provide the code, including simulation files and data at\nhttps://github.com/crjimene/swarm_gpt.",
      "tldr_zh": "本研究探索了将大语言模型(LLMs)集成到多智能体系统中的新方法，通过用LLM驱动的提示替代传统硬编码程序，实现了更灵活的智能体行为控制。研究开发了一个连接NetLogo仿真平台与GPT-4o的工具链，以蚂蚁觅食和鸟群聚集两种典型的群体智能(Swarm Intelligence)现象为案例，展示了基于规则提示和自主知识驱动提示的行为生成方式。该框架能够研究自组织过程并诱导涌现行为，为探索自然现象启发的智能系统建模提供了新途径。相关代码和仿真数据已开源。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "I.6.0; I.2.7"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03800v1",
      "published_date": "2025-03-05 17:13:27 UTC",
      "updated_date": "2025-03-05 17:13:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:06:35.802934"
    },
    {
      "arxiv_id": "2503.03669v1",
      "title": "Attentive Reasoning Queries: A Systematic Method for Optimizing Instruction-Following in Large Language Models",
      "title_zh": "注意力推理查询：优化大语言模型指令跟随的系统化方法",
      "authors": [
        "Bar Karov",
        "Dor Zohar",
        "Yam Marcovitz"
      ],
      "abstract": "We present Attentive Reasoning Queries (ARQs), a novel structured reasoning\napproach that significantly improves instruction-following in Large Language\nModels through domain-specialized reasoning blueprints. While LLMs demonstrate\nremarkable capabilities across diverse tasks, they often fail to maintain\nadherence to complex, use-case-specific instructions during multi-turn\nconversations, presenting challenges for business-critical applications. ARQs\naddress this limitation by guiding LLMs through systematic reasoning steps with\ntargeted queries that reinstate critical instructions and facilitate\nintermediate reasoning throughout the completion process. In extensive testing\nwithin Parlant, our framework for reliable customer-facing agents in which ARQs\nwere born out of necessity, they achieved a 90.2% success rate across 87 test\nscenarios, outperforming both Chain-of-Thought reasoning (86.1%) and direct\nresponse generation (81.5%). ARQs showed particular strength in addressing\npersistent failure modes like guideline re-application and hallucination\nprevention. Our analysis also revealed that ARQs can potentially be more\ncomputationally efficient than free-form reasoning when carefully designed.\nThese findings demonstrate that structured reasoning approaches provide\neffective mechanisms for controlling how LLMs process information and make\ndecisions in complex scenarios.",
      "tldr_zh": "该研究提出了Attentive Reasoning Queries (ARQs)，一种结构化推理方法，通过领域专用的推理蓝图显著提升大语言模型(LLMs)在复杂指令遵循任务中的表现。ARQs通过针对性查询引导LLMs进行系统化推理，确保关键指令的重现和中间推理的完成。在Parlant框架的测试中，ARQs在87个测试场景中达到了90.2%的成功率，优于链式思维推理(86.1%)和直接生成响应(81.5%)，尤其在防止幻觉和重新应用指南方面表现出色。研究表明，ARQs不仅提高了指令遵循的准确性，还可能在计算效率上优于自由形式的推理。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "Supplementary materials, including code, is available on our GitHub:\n  https://github.com/emcie-co/parlant/tree/arqs-a-systematic-method-for-optimizing-instruction-following-in-llms",
      "pdf_url": "http://arxiv.org/pdf/2503.03669v1",
      "published_date": "2025-03-05 17:03:48 UTC",
      "updated_date": "2025-03-05 17:03:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:06:13.266576"
    },
    {
      "arxiv_id": "2503.04840v1",
      "title": "Framing the Game: How Context Shapes LLM Decision-Making",
      "title_zh": "情境塑造游戏：上下文如何影响大语言模型的决策",
      "authors": [
        "Isaac Robinson",
        "John Burden"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly deployed across diverse\ncontexts to support decision-making. While existing evaluations effectively\nprobe latent model capabilities, they often overlook the impact of context\nframing on perceived rational decision-making. In this study, we introduce a\nnovel evaluation framework that systematically varies evaluation instances\nacross key features and procedurally generates vignettes to create highly\nvaried scenarios. By analyzing decision-making patterns across different\ncontexts with the same underlying game structure, we uncover significant\ncontextual variability in LLM responses. Our findings demonstrate that this\nvariability is largely predictable yet highly sensitive to framing effects. Our\nresults underscore the need for dynamic, context-aware evaluation methodologies\nfor real-world deployments.",
      "tldr_zh": "本研究探讨了上下文框架如何影响大语言模型(LLMs)的决策过程。研究者开发了一种新的评估框架，通过系统性地改变关键特征和生成多样化的场景，分析LLMs在不同上下文中的决策模式。研究发现，LLMs的响应存在显著的上下文变异性，这种变异性虽然可预测，但对框架效应极为敏感。研究结果强调了在实际应用中需要采用动态、上下文感知的评估方法。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04840v1",
      "published_date": "2025-03-05 17:03:28 UTC",
      "updated_date": "2025-03-05 17:03:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:06:49.155014"
    },
    {
      "arxiv_id": "2503.03664v1",
      "title": "A Generative Approach to High Fidelity 3D Reconstruction from Text Data",
      "title_zh": "基于生成方法的高保真文本数据三维重建",
      "authors": [
        "Venkat Kumar R",
        "Deepak Saravanan"
      ],
      "abstract": "The convergence of generative artificial intelligence and advanced computer\nvision technologies introduces a groundbreaking approach to transforming\ntextual descriptions into three-dimensional representations. This research\nproposes a fully automated pipeline that seamlessly integrates text-to-image\ngeneration, various image processing techniques, and deep learning methods for\nreflection removal and 3D reconstruction. By leveraging state-of-the-art\ngenerative models like Stable Diffusion, the methodology translates natural\nlanguage inputs into detailed 3D models through a multi-stage workflow.\n  The reconstruction process begins with the generation of high-quality images\nfrom textual prompts, followed by enhancement by a reinforcement learning agent\nand reflection removal using the Stable Delight model. Advanced image upscaling\nand background removal techniques are then applied to further enhance visual\nfidelity. These refined two-dimensional representations are subsequently\ntransformed into volumetric 3D models using sophisticated machine learning\nalgorithms, capturing intricate spatial relationships and geometric\ncharacteristics. This process achieves a highly structured and detailed output,\nensuring that the final 3D models reflect both semantic accuracy and geometric\nprecision.\n  This approach addresses key challenges in generative reconstruction, such as\nmaintaining semantic coherence, managing geometric complexity, and preserving\ndetailed visual information. Comprehensive experimental evaluations will assess\nreconstruction quality, semantic accuracy, and geometric fidelity across\ndiverse domains and varying levels of complexity. By demonstrating the\npotential of AI-driven 3D reconstruction techniques, this research offers\nsignificant implications for fields such as augmented reality (AR), virtual\nreality (VR), and digital content creation.",
      "tldr_zh": "本研究提出了一种基于生成式AI的文本到3D重建新方法，通过整合Stable Diffusion等先进生成模型与多阶段处理流程（包括文本生成图像、强化学习增强、Stable Delight反光消除等技术），实现从自然语言描述到高保真3D模型的自动转换。该方案采用机器学习算法将优化后的2D图像转为具有精确几何特征的体素3D模型，有效解决了语义一致性保持和几何复杂度处理等关键挑战。实验验证表明，该方法在语义准确性和几何保真度方面表现优异，为AR/VR和数字内容创作等领域提供了创新解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03664v1",
      "published_date": "2025-03-05 16:54:15 UTC",
      "updated_date": "2025-03-05 16:54:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:06:59.399333"
    },
    {
      "arxiv_id": "2503.03655v1",
      "title": "Improving 6D Object Pose Estimation of metallic Household and Industry Objects",
      "title_zh": "提升金属家居与工业物体的6D位姿估计精度",
      "authors": [
        "Thomas Pöllabauer",
        "Michael Gasser",
        "Tristan Wirth",
        "Sarah Berkei",
        "Volker Knauthe",
        "Arjan Kuijper"
      ],
      "abstract": "6D object pose estimation suffers from reduced accuracy when applied to\nmetallic objects. We set out to improve the state-of-the-art by addressing\nchallenges such as reflections and specular highlights in industrial\napplications. Our novel BOP-compatible dataset, featuring a diverse set of\nmetallic objects (cans, household, and industrial items) under various lighting\nand background conditions, provides additional geometric and visual cues. We\ndemonstrate that these cues can be effectively leveraged to enhance overall\nperformance. To illustrate the usefulness of the additional features, we\nimprove upon the GDRNPP algorithm by introducing an additional keypoint\nprediction and material estimator head in order to improve spatial scene\nunderstanding. Evaluations on the new dataset show improved accuracy for\nmetallic objects, supporting the hypothesis that additional geometric and\nvisual cues can improve learning.",
      "tldr_zh": "该研究针对金属物体的6D位姿估计问题，提出了一种改进方法以应对工业应用中常见的反光和镜面高光等挑战。作者构建了一个兼容BOP基准的新型数据集，包含多种金属物体（如罐装物品、家用和工业用品）在不同光照和背景条件下的数据，提供了额外的几何和视觉线索。通过改进GDRNPP算法，新增关键点预测和材质估计模块，实验证明该方法能有效提升金属物体的位姿估计精度，验证了额外几何与视觉线索对模型学习的促进作用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03655v1",
      "published_date": "2025-03-05 16:35:15 UTC",
      "updated_date": "2025-03-05 16:35:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:07:41.172179"
    },
    {
      "arxiv_id": "2503.04839v1",
      "title": "Advancing Multimodal In-Context Learning in Large Vision-Language Models with Task-aware Demonstrations",
      "title_zh": "通过任务感知演示推进大型视觉语言模型中的多模态上下文学习",
      "authors": [
        "Yanshu Li"
      ],
      "abstract": "Multimodal in-context learning (ICL) has emerged as a key capability of Large\nVision-Language Models (LVLMs), driven by their increasing scale and\napplicability. Despite its promise, effective ICL in the multimodal setting\nremains challenging due to the inherent complexity of image-text inputs and the\nhigh sensitivity of ICL performance to input configurations. In this work, we\nshed light on the core mechanism underlying multimodal ICL, identifying task\nmapping as a crucial factor in configuring robust in-context demonstration\n(ICD) sequences. Building on these insights, we propose \\textit{SabER}, a\nlightweight yet powerful decoder-only transformer equipped with task-aware\nattention, which intelligently selects and arranges ICDs from a demonstration\nlibrary in an autoregressive fashion. This design enables fine-grained feature\nextraction and cross-modal reasoning, iteratively refining task mapping to\ngenerate high-quality ICD sequences. Through extensive experiments covering\nfive LVLMs and nine benchmark datasets, SabER not only demonstrates strong\nempirical performance, but also provides deeper understanding of how task\nsemantics interact with multimodal ICDs. Our findings highlight the importance\nof principled ICD sequence configuration and open new avenues to enhance\nmultimodal ICL in a wide range of real-world scenarios.",
      "tldr_zh": "该研究提出了SabER框架，通过任务感知注意力机制优化多模态上下文学习(ICL)中的演示序列配置。研究发现任务映射(task mapping)是多模态ICL的核心机制，并开发了一个轻量级解码器Transformer，能够自回归地选择和排列上下文演示(ICD)序列。实验覆盖5种大型视觉语言模型(LVLMs)和9个基准数据集，结果表明该方法不仅提升了性能，还深化了对任务语义与多模态ICD交互机制的理解，为实际应用中的多模态ICL优化开辟了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by Reasoning and Planning for LLMs @ ICLR2025, 25 pages, 13\n  tables",
      "pdf_url": "http://arxiv.org/pdf/2503.04839v1",
      "published_date": "2025-03-05 16:33:10 UTC",
      "updated_date": "2025-03-05 16:33:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:07:41.177800"
    },
    {
      "arxiv_id": "2503.03654v1",
      "title": "Improving Neutral Point of View Text Generation through Parameter-Efficient Reinforcement Learning and a Small-Scale High-Quality Dataset",
      "title_zh": "通过参数高效强化学习与小规模高质量数据集提升中立观点文本生成",
      "authors": [
        "Jessica Hoffmann",
        "Christiane Ahlheim",
        "Zac Yu",
        "Aria Walfrand",
        "Jarvis Jin",
        "Marie Tano",
        "Ahmad Beirami",
        "Erin van Liemt",
        "Nithum Thain",
        "Hakim Sidahmed",
        "Lucas Dixon"
      ],
      "abstract": "This paper describes the construction of a dataset and the evaluation of\ntraining methods to improve generative large language models' (LLMs) ability to\nanswer queries on sensitive topics with a Neutral Point of View (NPOV), i.e.,\nto provide significantly more informative, diverse and impartial answers. The\ndataset, the SHQ-NPOV dataset, comprises 300 high-quality, human-written\nquadruplets: a query on a sensitive topic, an answer, an NPOV rating, and a set\nof links to source texts elaborating the various points of view. The first key\ncontribution of this paper is a new methodology to create such datasets through\niterative rounds of human peer-critique and annotator training, which we\nrelease alongside the dataset. The second key contribution is the\nidentification of a highly effective training regime for parameter-efficient\nreinforcement learning (PE-RL) to improve NPOV generation. We compare and\nextensively evaluate PE-RL and multiple baselines-including LoRA finetuning (a\nstrong baseline), SFT and RLHF.\n  PE-RL not only improves on overall NPOV quality compared to the strongest\nbaseline ($97.06\\%\\rightarrow 99.08\\%$), but also scores much higher on\nfeatures linguists identify as key to separating good answers from the best\nanswers ($60.25\\%\\rightarrow 85.21\\%$ for presence of supportive details,\n$68.74\\%\\rightarrow 91.43\\%$ for absence of oversimplification). A qualitative\nanalysis corroborates this. Finally, our evaluation finds no statistical\ndifferences between results on topics that appear in the training dataset and\nthose on separated evaluation topics, which provides strong evidence that our\napproach to training PE-RL exhibits very effective out of topic generalization.",
      "tldr_zh": "本研究提出了一种通过参数高效强化学习（PE-RL）和小规模高质量数据集提升生成式大语言模型（LLMs）在敏感话题上生成中立观点（NPOV）文本能力的方法。首先，构建了SHQ-NPOV数据集，包含300组高质量人工标注的四元组（查询、回答、NPOV评分和来源链接），并通过迭代式人工评审和标注训练开发了数据集创建方法。其次，发现PE-RL训练方法显著提升了NPOV生成质量，相比最强基线（LoRA微调），NPOV质量从97.06%提升至99.08%，且在关键语言学特征（如支持性细节和避免过度简化）上表现更优。实验表明，该方法在未训练话题上也表现出良好的泛化能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03654v1",
      "published_date": "2025-03-05 16:32:47 UTC",
      "updated_date": "2025-03-05 16:32:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:07:28.621716"
    },
    {
      "arxiv_id": "2503.03606v2",
      "title": "Decoupled Recommender Systems: Exploring Alternative Recommender Ecosystem Designs",
      "title_zh": "解耦推荐系统：探索替代性推荐生态设计",
      "authors": [
        "Anas Buhayh",
        "Elizabeth McKinnie",
        "Robin Burke"
      ],
      "abstract": "Recommender ecosystems are an emerging subject of research. Such research\nexamines how the characteristics of algorithms, recommendation consumers, and\nitem providers influence system dynamics and long-term outcomes. One\narchitectural possibility that has not yet been widely explored in this line of\nresearch is the consequences of a configuration in which recommendation\nalgorithms are decoupled from the platforms they serve. This is sometimes\ncalled \"the friendly neighborhood algorithm store\" or \"middleware\" model. We\nare particularly interested in how such architectures might offer a range of\ndifferent distributions of utility across consumers, providers, and\nrecommendation platforms. In this paper, we create a model of a recommendation\necosystem that incorporates algorithm choice and examine the outcomes of such a\ndesign.",
      "tldr_zh": "本研究探讨了一种新型推荐系统设计——解耦推荐系统（Decoupled Recommender Systems），即推荐算法与服务平台分离的“友好邻居算法商店”或“中间件”模式。通过构建包含算法选择的推荐生态系统模型，研究分析了这种设计对消费者、内容提供者和推荐平台效用分布的影响，为推荐系统的多样化架构提供了新思路。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03606v2",
      "published_date": "2025-03-05 15:42:37 UTC",
      "updated_date": "2025-03-06 14:28:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:07:26.323945"
    },
    {
      "arxiv_id": "2503.03595v1",
      "title": "Towards Understanding Text Hallucination of Diffusion Models via Local Generation Bias",
      "title_zh": "探索扩散模型文本幻觉的局部生成偏差机制",
      "authors": [
        "Rui Lu",
        "Runzhe Wang",
        "Kaifeng Lyu",
        "Xitai Jiang",
        "Gao Huang",
        "Mengdi Wang"
      ],
      "abstract": "Score-based diffusion models have achieved incredible performance in\ngenerating realistic images, audio, and video data. While these models produce\nhigh-quality samples with impressive details, they often introduce unrealistic\nartifacts, such as distorted fingers or hallucinated texts with no meaning.\nThis paper focuses on textual hallucinations, where diffusion models correctly\ngenerate individual symbols but assemble them in a nonsensical manner. Through\nexperimental probing, we consistently observe that such phenomenon is\nattributed it to the network's local generation bias. Denoising networks tend\nto produce outputs that rely heavily on highly correlated local regions,\nparticularly when different dimensions of the data distribution are nearly\npairwise independent. This behavior leads to a generation process that\ndecomposes the global distribution into separate, independent distributions for\neach symbol, ultimately failing to capture the global structure, including\nunderlying grammar. Intriguingly, this bias persists across various denoising\nnetwork architectures including MLP and transformers which have the structure\nto model global dependency. These findings also provide insights into\nunderstanding other types of hallucinations, extending beyond text, as a result\nof implicit biases in the denoising models. Additionally, we theoretically\nanalyze the training dynamics for a specific case involving a two-layer MLP\nlearning parity points on a hypercube, offering an explanation of its\nunderlying mechanism.",
      "tldr_zh": "本文研究了基于评分的扩散模型(score-based diffusion models)在生成文本时出现的幻觉问题，即模型虽能正确生成单个符号，却无法合理组合成有意义的文本。研究发现，这种现象源于模型的局部生成偏差(local generation bias)，即去噪网络过度依赖高度相关的局部区域，导致全局结构（如语法）无法被捕捉。这种偏差在不同网络架构（如MLP和Transformer）中均存在，并可能解释其他类型的生成幻觉。研究还通过理论分析揭示了其背后的机制。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03595v1",
      "published_date": "2025-03-05 15:28:50 UTC",
      "updated_date": "2025-03-05 15:28:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:07:39.889113"
    },
    {
      "arxiv_id": "2503.03594v2",
      "title": "Small but Mighty: Enhancing Time Series Forecasting with Lightweight LLMs",
      "title_zh": "小而强大：利用轻量级大语言模型提升时间序列预测",
      "authors": [
        "Haoran Fan",
        "Bin Li",
        "Yixuan Weng",
        "Shoujun Zhou"
      ],
      "abstract": "While LLMs have demonstrated remarkable potential in time series forecasting,\ntheir practical deployment remains constrained by excessive computational\ndemands and memory footprints. Existing LLM-based approaches typically suffer\nfrom three critical limitations: Inefficient parameter utilization in handling\nnumerical time series patterns; Modality misalignment between continuous\ntemporal signals and discrete text embeddings; and Inflexibility for real-time\nexpert knowledge integration. We present SMETimes, the first systematic\ninvestigation of sub-3B parameter SLMs for efficient and accurate time series\nforecasting. Our approach centers on three key innovations: A\nstatistically-enhanced prompting mechanism that bridges numerical time series\nwith textual semantics through descriptive statistical features; A adaptive\nfusion embedding architecture that aligns temporal patterns with language model\ntoken spaces through learnable parameters; And a dynamic mixture-of-experts\nframework enabled by SLMs' computational efficiency, adaptively combining base\npredictions with domain-specific models. Extensive evaluations across seven\nbenchmark datasets demonstrate that our 3B-parameter SLM achieves\nstate-of-the-art performance on five primary datasets while maintaining 3.8x\nfaster training and 5.2x lower memory consumption compared to 7B-parameter LLM\nbaselines. Notably, the proposed model exhibits better learning capabilities,\nachieving 12.3% lower MSE than conventional LLM. Ablation studies validate that\nour statistical prompting and cross-modal fusion modules respectively\ncontribute 15.7% and 18.2% error reduction in long-horizon forecasting tasks.\nBy redefining the efficiency-accuracy trade-off landscape, this work\nestablishes SLMs as viable alternatives to resource-intensive LLMs for\npractical time series forecasting. Code and models are available at\nhttps://github.com/xiyan1234567/SMETimes.",
      "tldr_zh": "该研究提出了SMETimes，一种基于轻量化语言模型(SLMs)的时间序列预测方法，旨在解决大语言模型(LLMs)在计算资源和内存占用上的高需求问题。通过引入统计增强提示机制、自适应融合嵌入架构和动态专家混合框架，SMETimes成功将时间序列与文本语义对齐，并实现了领域知识的实时集成。实验表明，该模型在七个基准数据集上表现优异，与7B参数的LLM相比，训练速度提升3.8倍，内存消耗降低5.2倍，同时预测误差减少12.3%，为高效时间序列预测提供了新的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "20 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.03594v2",
      "published_date": "2025-03-05 15:27:36 UTC",
      "updated_date": "2025-03-09 10:56:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:07:48.160174"
    },
    {
      "arxiv_id": "2503.03592v2",
      "title": "English K_Quantization of LLMs Does Not Disproportionately Diminish Multilingual Performance",
      "title_zh": "LLM的k_quantization不会显著削弱多语言性能",
      "authors": [
        "Karl Audun Borgersen"
      ],
      "abstract": "For consumer usage of locally deployed LLMs, the GGUF format and\nk\\_quantization are invaluable tools for maintaining the performance of the\noriginal model while reducing it to sizes deployable with consumer-grade\nhardware. The number of bits dedicated to each weight from the original model\nis reduced based on how important they are thought to be during model\ninference. This importance is arrived at through the application of an\n'importance matrix'-a relatively small text document meant to be representative\nof the LLM's standard use-cases. In the vast majority of quants available\nonline, this document is primarily written in English. It was therefore an open\nquestion whether performance on English language tasks was preserved through\nthe sacrifice of multilingual performance and whether it can be preserved with\nalternate importance matrices. This article investigates these hypotheses by\nquantizing Llama3.3 70B on importance matrices written in three languages\n(English, Norwegian, and Malayalam) and evaluating them on the MixEval dataset\nin both English and Norwegian. All experiments related to yielded\nnon-significant results indicating that current quantization practices do not\ndisproportionately harm multilingual performance.",
      "tldr_zh": "该研究探讨了GGUF格式和k_quantization方法在多语言大语言模型(LLMs)量化中的影响。通过使用英语、挪威语和马拉雅拉姆语三种语言的\"重要性矩阵\"对Llama3.3 70B模型进行量化，并在MixEval数据集上进行评估，实验结果表明当前以英语为主的量化实践并不会显著损害模型的多语言性能。这一发现为本地部署的多语言LLMs量化提供了重要参考，表明无需担心量化会优先保留英语能力而牺牲其他语言表现。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 6 figures, v2",
      "pdf_url": "http://arxiv.org/pdf/2503.03592v2",
      "published_date": "2025-03-05 15:26:59 UTC",
      "updated_date": "2025-03-10 07:36:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:08:24.595853"
    },
    {
      "arxiv_id": "2503.16480v1",
      "title": "Human Preferences for Constructive Interactions in Language Model Alignment",
      "title_zh": "人类偏好于语言模型对齐中的建设性互动",
      "authors": [
        "Yara Kyrychenko",
        "Jon Roozenbeek",
        "Brandon Davidson",
        "Sander van der Linden",
        "Ramit Debnath"
      ],
      "abstract": "As large language models (LLMs) enter the mainstream, aligning them to foster\nconstructive dialogue rather than exacerbate societal divisions is critical.\nUsing an individualized and multicultural alignment dataset of over 7,500\nconversations of individuals from 74 countries engaging with 21 LLMs, we\nexamined how linguistic attributes linked to constructive interactions are\nreflected in human preference data used for training AI. We found that users\nconsistently preferred well-reasoned and nuanced responses while rejecting\nthose high in personal storytelling. However, users who believed that AI should\nreflect their values tended to place less preference on reasoning in LLM\nresponses and more on curiosity. Encouragingly, we observed that users could\nset the tone for how constructive their conversation would be, as LLMs mirrored\nlinguistic attributes, including toxicity, in user queries.",
      "tldr_zh": "该研究探讨了人类在语言模型对齐中对建设性对话的偏好。通过对来自74个国家的7500多次对话的分析，研究发现用户普遍偏好推理充分且细致的回答，而排斥过于个人化的叙述。然而，认为AI应反映自身价值观的用户更注重回答中的好奇心而非推理。研究还发现，用户可以通过提问方式引导对话的基调，语言模型会模仿用户查询中的语言特征，包括毒性。这些发现为设计更符合人类期望的语言模型对齐策略提供了重要见解。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "1 Figure, 1 Table, 11 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.16480v1",
      "published_date": "2025-03-05 15:08:41 UTC",
      "updated_date": "2025-03-05 15:08:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:08:08.465494"
    },
    {
      "arxiv_id": "2503.03797v1",
      "title": "VoiceGRPO: Modern MoE Transformers with Group Relative Policy Optimization GRPO for AI Voice Health Care Applications on Voice Pathology Detection",
      "title_zh": "VoiceGRPO：采用组相对策略优化GRPO的现代MoE Transformer在语音病理检测AI医疗应用中的研究",
      "authors": [
        "Enkhtogtokh Togootogtokh",
        "Christian Klasen"
      ],
      "abstract": "This research introduces a novel AI techniques as Mixture-of-Experts\nTransformers with Group Relative Policy Optimization (GRPO) for voice health\ncare applications on voice pathology detection. With the architectural\ninnovations, we adopt advanced training paradigms inspired by reinforcement\nlearning, namely Proximal Policy Optimization (PPO) and Group-wise Regularized\nPolicy Optimization (GRPO), to enhance model stability and performance.\nExperiments conducted on a synthetically generated voice pathology dataset\ndemonstrate that our proposed models significantly improve diagnostic accuracy,\nF1 score, and ROC-AUC compared to conventional approaches. These findings\nunderscore the potential of integrating transformer architectures with novel\ntraining strategies to advance automated voice pathology detection and\nultimately contribute to more effective healthcare delivery. The code we used\nto train and evaluate our models is available at\nhttps://github.com/enkhtogtokh/voicegrpo",
      "tldr_zh": "本研究提出了一种新型的混合专家(Mixture-of-Experts) Transformer模型，结合了群体相对策略优化(Group Relative Policy Optimization, GRPO)技术，用于语音病理检测的医疗应用。通过引入基于强化学习的训练策略，包括近端策略优化(PPO)和群体正则化策略优化(GRPO)，显著提升了模型的稳定性和性能。实验结果表明，该模型在合成语音病理数据集上的诊断准确率、F1分数和ROC-AUC均优于传统方法，展示了Transformer架构与新型训练策略结合在自动化语音病理检测中的潜力，为更高效的医疗诊断提供了技术支持。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03797v1",
      "published_date": "2025-03-05 14:52:57 UTC",
      "updated_date": "2025-03-05 14:52:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:08:38.175711"
    },
    {
      "arxiv_id": "2503.03563v1",
      "title": "A Conceptual Model for Attributions in Event-Centric Knowledge Graphs",
      "title_zh": "事件中心知识图谱中归因关系的概念模型",
      "authors": [
        "Florian Plötzky",
        "Katarina Britz",
        "Wolf-Tilo Balke"
      ],
      "abstract": "The use of narratives as a means of fusing information from knowledge graphs\n(KGs) into a coherent line of argumentation has been the subject of recent\ninvestigation. Narratives are especially useful in event-centric knowledge\ngraphs in that they provide a means to connect different real-world events and\ncategorize them by well-known narrations. However, specifically for\ncontroversial events, a problem in information fusion arises, namely, multiple\nviewpoints regarding the validity of certain event aspects, e.g., regarding the\nrole a participant takes in an event, may exist. Expressing those viewpoints in\nKGs is challenging because disputed information provided by different\nviewpoints may introduce inconsistencies. Hence, most KGs only feature a single\nview on the contained information, hampering the effectiveness of narrative\ninformation access. This paper is an extension of our original work and\nintroduces attributions, i.e., parameterized predicates that allow for the\nrepresentation of facts that are only valid in a specific viewpoint. For this,\nwe develop a conceptual model that allows for the representation of\nviewpoint-dependent information. As an extension, we enhance the model by a\nconception of viewpoint-compatibility. Based on this, we deepen our original\ndeliberations on the model's effects on information fusion and provide\nadditional grounding in the literature.",
      "tldr_zh": "本文提出了一种用于事件中心知识图谱(Event-Centric Knowledge Graphs)中属性表示的概念模型，旨在解决争议事件中多视角信息融合的挑战。通过引入attributions（参数化谓词），该模型能够表示特定视角下有效的事实，并扩展了视角兼容性的概念。研究深化了模型对信息融合的影响分析，为知识图谱中多视角信息的表达和融合提供了理论支持。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "Submitted to Data & Knowledge Engineering, 22 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.03563v1",
      "published_date": "2025-03-05 14:51:46 UTC",
      "updated_date": "2025-03-05 14:51:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:08:44.457018"
    },
    {
      "arxiv_id": "2503.04837v1",
      "title": "FedPalm: A General Federated Learning Framework for Closed- and Open-Set Palmprint Verification",
      "title_zh": "FedPalm：一种面向闭集与开集掌纹验证的通用联邦学习框架",
      "authors": [
        "Ziyuan Yang",
        "Yingyu Chen",
        "Chengrui Gao",
        "Andrew Beng Jin Teoh",
        "Bob Zhang",
        "Yi Zhang"
      ],
      "abstract": "Current deep learning (DL)-based palmprint verification models rely on\ncentralized training with large datasets, which raises significant privacy\nconcerns due to biometric data's sensitive and immutable nature. Federated\nlearning~(FL), a privacy-preserving distributed learning paradigm, offers a\ncompelling alternative by enabling collaborative model training without the\nneed for data sharing. However, FL-based palmprint verification faces critical\nchallenges, including data heterogeneity from diverse identities and the\nabsence of standardized evaluation benchmarks. This paper addresses these gaps\nby establishing a comprehensive benchmark for FL-based palmprint verification,\nwhich explicitly defines and evaluates two practical scenarios: closed-set and\nopen-set verification. We propose FedPalm, a unified FL framework that balances\nlocal adaptability with global generalization. Each client trains a\npersonalized textural expert tailored to local data and collaboratively\ncontributes to a shared global textural expert for extracting generalized\nfeatures. To further enhance verification performance, we introduce a Textural\nExpert Interaction Module that dynamically routes textural features among\nexperts to generate refined side textural features. Learnable parameters are\nemployed to model relationships between original and side features, fostering\ncross-texture-expert interaction and improving feature discrimination.\nExtensive experiments validate the effectiveness of FedPalm, demonstrating\nrobust performance across both scenarios and providing a promising foundation\nfor advancing FL-based palmprint verification research.",
      "tldr_zh": "该论文提出了FedPalm框架，这是首个针对掌纹验证的联邦学习(FL)统一解决方案，同时支持封闭集(closed-set)和开放集(open-set)验证场景。该方法创新性地采用双专家系统，包括本地个性化纹理专家和全局共享纹理专家，并通过可学习的纹理特征交互模块实现跨专家特征优化。实验表明，该框架在保护生物特征隐私的同时，有效解决了数据异构性问题，为联邦学习在掌纹识别领域的应用建立了标准化基准。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04837v1",
      "published_date": "2025-03-05 14:49:42 UTC",
      "updated_date": "2025-03-05 14:49:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:08:55.797525"
    },
    {
      "arxiv_id": "2503.03562v2",
      "title": "Towards Visual Discrimination and Reasoning of Real-World Physical Dynamics: Physics-Grounded Anomaly Detection",
      "title_zh": "迈向现实世界物理动力学的视觉判别与推理：基于物理基础的异常检测",
      "authors": [
        "Wenqiao Li",
        "Yao Gu",
        "Xintao Chen",
        "Xiaohao Xu",
        "Ming Hu",
        "Xiaonan Huang",
        "Yingna Wu"
      ],
      "abstract": "Humans detect real-world object anomalies by perceiving, interacting, and\nreasoning based on object-conditioned physical knowledge. The long-term goal of\nIndustrial Anomaly Detection (IAD) is to enable machines to autonomously\nreplicate this skill. However, current IAD algorithms are largely developed and\ntested on static, semantically simple datasets, which diverge from real-world\nscenarios where physical understanding and reasoning are essential. To bridge\nthis gap, we introduce the Physics Anomaly Detection (Phys-AD) dataset, the\nfirst large-scale, real-world, physics-grounded video dataset for industrial\nanomaly detection. Collected using a real robot arm and motor, Phys-AD provides\na diverse set of dynamic, semantically rich scenarios. The dataset includes\nmore than 6400 videos across 22 real-world object categories, interacting with\nrobot arms and motors, and exhibits 47 types of anomalies. Anomaly detection in\nPhys-AD requires visual reasoning, combining both physical knowledge and video\ncontent to determine object abnormality. We benchmark state-of-the-art anomaly\ndetection methods under three settings: unsupervised AD, weakly-supervised AD,\nand video-understanding AD, highlighting their limitations in handling\nphysics-grounded anomalies. Additionally, we introduce the Physics Anomaly\nExplanation (PAEval) metric, designed to assess the ability of visual-language\nfoundation models to not only detect anomalies but also provide accurate\nexplanations for their underlying physical causes. Our dataset and benchmark\nwill be publicly available.",
      "tldr_zh": "该研究提出了首个基于物理知识的大规模工业异常检测数据集Phys-AD，包含6400多个视频，覆盖22种真实物体类别和47种异常类型。通过真实机器人手臂和电机采集的动态场景，Phys-AD要求结合物理知识和视频内容进行视觉推理以检测异常。研究还提出了Physics Anomaly Explanation (PAEval)评估指标，用于衡量视觉语言模型在检测异常并提供物理原因解释方面的能力。实验表明，现有最先进的异常检测方法在处理物理基础异常时存在显著局限性，为未来研究提供了重要基准。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.03562v2",
      "published_date": "2025-03-05 14:49:08 UTC",
      "updated_date": "2025-03-06 03:06:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:09:09.440060"
    },
    {
      "arxiv_id": "2503.04836v1",
      "title": "PGAD: Prototype-Guided Adaptive Distillation for Multi-Modal Learning in AD Diagnosis",
      "title_zh": "PGAD：基于原型引导的自适应蒸馏用于AD诊断中的多模态学习",
      "authors": [
        "Yanfei Li",
        "Teng Yin",
        "Wenyi Shang",
        "Jingyu Liu",
        "Xi Wang",
        "Kaiyang Zhao"
      ],
      "abstract": "Missing modalities pose a major issue in Alzheimer's Disease (AD) diagnosis,\nas many subjects lack full imaging data due to cost and clinical constraints.\nWhile multi-modal learning leverages complementary information, most existing\nmethods train only on complete data, ignoring the large proportion of\nincomplete samples in real-world datasets like ADNI. This reduces the effective\ntraining set and limits the full use of valuable medical data. While some\nmethods incorporate incomplete samples, they fail to effectively address\ninter-modal feature alignment and knowledge transfer challenges under high\nmissing rates. To address this, we propose a Prototype-Guided Adaptive\nDistillation (PGAD) framework that directly incorporates incomplete multi-modal\ndata into training. PGAD enhances missing modality representations through\nprototype matching and balances learning with a dynamic sampling strategy. We\nvalidate PGAD on the ADNI dataset with varying missing rates (20%, 50%, and\n70%) and demonstrate that it significantly outperforms state-of-the-art\napproaches. Ablation studies confirm the effectiveness of prototype matching\nand adaptive sampling, highlighting the potential of our framework for robust\nand scalable AD diagnosis in real-world clinical settings.",
      "tldr_zh": "本研究提出了一种原型引导的自适应蒸馏框架（PGAD），用于解决阿尔茨海默病（AD）诊断中多模态数据缺失的问题。PGAD通过原型匹配增强缺失模态的表示，并采用动态采样策略平衡学习过程，从而有效应对高缺失率下的跨模态特征对齐和知识迁移挑战。在ADNI数据集上的实验表明，PGAD在20%、50%和70%的缺失率下均显著优于现有方法，验证了其在真实临床场景中实现稳健和可扩展AD诊断的潜力。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04836v1",
      "published_date": "2025-03-05 14:39:31 UTC",
      "updated_date": "2025-03-05 14:39:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:09:27.491771"
    },
    {
      "arxiv_id": "2503.04835v1",
      "title": "Distilling Dataset into Neural Field",
      "title_zh": "将数据集蒸馏为神经场",
      "authors": [
        "Donghyeok Shin",
        "HeeSun Bae",
        "Gyuwon Sim",
        "Wanmo Kang",
        "Il-Chul Moon"
      ],
      "abstract": "Utilizing a large-scale dataset is essential for training high-performance\ndeep learning models, but it also comes with substantial computation and\nstorage costs. To overcome these challenges, dataset distillation has emerged\nas a promising solution by compressing the large-scale dataset into a smaller\nsynthetic dataset that retains the essential information needed for training.\nThis paper proposes a novel parameterization framework for dataset\ndistillation, coined Distilling Dataset into Neural Field (DDiF), which\nleverages the neural field to store the necessary information of the\nlarge-scale dataset. Due to the unique nature of the neural field, which takes\ncoordinates as input and output quantity, DDiF effectively preserves the\ninformation and easily generates various shapes of data. We theoretically\nconfirm that DDiF exhibits greater expressiveness than some previous literature\nwhen the utilized budget for a single synthetic instance is the same. Through\nextensive experiments, we demonstrate that DDiF achieves superior performance\non several benchmark datasets, extending beyond the image domain to include\nvideo, audio, and 3D voxel. We release the code at\nhttps://github.com/aailab-kaist/DDiF.",
      "tldr_zh": "本文提出了一种新颖的数据集蒸馏框架DDiF（Distilling Dataset into Neural Field），通过将大规模数据集压缩为神经场（Neural Field）来存储其关键信息。该框架利用神经场以坐标作为输入并输出数据量的特性，有效保留数据集信息并生成多种形态的数据。理论分析和实验表明，DDiF在相同预算下比现有方法具有更强的表达能力，并在图像、视频、音频和3D体素等多个领域的基准数据集上表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "The Thirteenth International Conference on Learning Representations\n  (ICLR 2025)",
      "pdf_url": "http://arxiv.org/pdf/2503.04835v1",
      "published_date": "2025-03-05 14:33:29 UTC",
      "updated_date": "2025-03-05 14:33:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:09:40.577670"
    },
    {
      "arxiv_id": "2503.03796v2",
      "title": "Human Implicit Preference-Based Policy Fine-tuning for Multi-Agent Reinforcement Learning in USV Swarm",
      "title_zh": "《基于人类隐性偏好的无人艇群多智能体强化学习策略微调方法》",
      "authors": [
        "Hyeonjun Kim",
        "Kanghoon Lee",
        "Junho Park",
        "Jiachen Li",
        "Jinkyoo Park"
      ],
      "abstract": "Multi-Agent Reinforcement Learning (MARL) has shown promise in solving\ncomplex problems involving cooperation and competition among agents, such as an\nUnmanned Surface Vehicle (USV) swarm used in search and rescue, surveillance,\nand vessel protection. However, aligning system behavior with user preferences\nis challenging due to the difficulty of encoding expert intuition into reward\nfunctions. To address the issue, we propose a Reinforcement Learning with Human\nFeedback (RLHF) approach for MARL that resolves credit-assignment challenges\nthrough an Agent-Level Feedback system categorizing feedback into intra-agent,\ninter-agent, and intra-team types. To overcome the challenges of direct human\nfeedback, we employ a Large Language Model (LLM) evaluator to validate our\napproach using feedback scenarios such as region constraints, collision\navoidance, and task allocation. Our method effectively refines USV swarm\npolicies, addressing key challenges in multi-agent systems while maintaining\nfairness and performance consistency.",
      "tldr_zh": "该研究提出了一种基于人类隐式偏好的策略微调方法，用于无人艇群(USV swarm)的多智能体强化学习(MARL)。通过引入分层Agent-Level Feedback系统，将人类反馈分为智能体内、智能体间和团队内三类，有效解决了信用分配问题。创新性地采用大语言模型(LLM)作为评估器，在区域约束、碰撞规避和任务分配等场景中验证了方法的有效性。该方法在保持公平性和性能一致性的同时，显著提升了USV群在搜索救援等任务中的策略表现。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.MA",
      "comment": "7 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.03796v2",
      "published_date": "2025-03-05 14:33:18 UTC",
      "updated_date": "2025-03-07 08:06:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:09:27.759185"
    },
    {
      "arxiv_id": "2503.04834v1",
      "title": "Extrapolation Merging: Keep Improving With Extrapolation and Merging",
      "title_zh": "外推融合法：持续优化与合并的外推策略",
      "authors": [
        "Yiguan Lin",
        "Bin Xu",
        "Yinghao Li",
        "Yang Gao"
      ],
      "abstract": "Large Language Models (LLMs) require instruction fine-tuning to perform\ndifferent downstream tasks. However, the instruction fine-tuning phase still\ndemands significant computational resources and labeled data, lacking a\nparadigm that can improve model performance without additional computational\npower and data. Model merging aims to enhance performance by combining the\nparameters of different models, but the lack of a clear optimization direction\nduring the merging process does not always guarantee improved performance. In\nthis paper, we attempt to provide a clear optimization direction for model\nmerging. We first validate the effectiveness of the model extrapolation method\nduring the instruction fine-tuning phase. Then, we propose Extrapolation\nMerging, a paradigm that can continue improving model performance without\nrequiring extra computational resources or data. Using the extrapolation\nmethod, we provide a clear direction for model merging, achieving local\noptimization search, and consequently enhancing the merged model's performance.\nWe conduct experiments on seven different tasks, and the results show that our\nmethod can consistently improve the model's performance after fine-tuning.",
      "tldr_zh": "这篇论文提出了一种名为\"外推合并(Extrapolation Merging)\"的新范式，旨在无需额外计算资源和数据的情况下持续提升大语言模型(LLMs)性能。该方法首先验证了模型外推在指令微调阶段的有效性，然后通过外推技术为模型合并提供明确的优化方向，实现局部最优搜索。实验表明，该方法在7个不同任务上都能稳定提升微调后的模型性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04834v1",
      "published_date": "2025-03-05 14:28:22 UTC",
      "updated_date": "2025-03-05 14:28:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:09:33.393579"
    },
    {
      "arxiv_id": "2503.03532v1",
      "title": "AI-Enabled Conversational Journaling for Advancing Parkinson's Disease Symptom Tracking",
      "title_zh": "AI赋能对话式日志记录：推进帕金森病症状跟踪",
      "authors": [
        "Mashrur Rashik",
        "Shilpa Sweth",
        "Nishtha Agrawal",
        "Saiyyam Kochar",
        "Kara M Smith",
        "Fateme Rajabiyazdi",
        "Vidya Setlur",
        "Narges Mahyar",
        "Ali Sarvghad"
      ],
      "abstract": "Journaling plays a crucial role in managing chronic conditions by allowing\npatients to document symptoms and medication intake, providing essential data\nfor long-term care. While valuable, traditional journaling methods often rely\non static, self-directed entries, lacking interactive feedback and real-time\nguidance. This gap can result in incomplete or imprecise information, limiting\nits usefulness for effective treatment. To address this gap, we introduce\nPATRIKA, an AI-enabled prototype designed specifically for people with\nParkinson's disease (PwPD). The system incorporates cooperative conversation\nprinciples, clinical interview simulations, and personalization to create a\nmore effective and user-friendly journaling experience. Through two user\nstudies with PwPD and iterative refinement of PATRIKA, we demonstrate\nconversational journaling's significant potential in patient engagement and\ncollecting clinically valuable information. Our results showed that generating\nprobing questions PATRIKA turned journaling into a bi-directional interaction.\nAdditionally, we offer insights for designing journaling systems for healthcare\nand future directions for promoting sustained journaling.",
      "tldr_zh": "本研究开发了PATRIKA，一款专为帕金森病患者(PwPD)设计的AI对话式日志系统。该系统融合了协作对话原则、临床访谈模拟和个性化功能，将传统单向记录转变为双向互动模式。通过两项用户研究证明，该系统能显著提升患者参与度，并通过智能追问收集更具临床价值的信息。研究成果为医疗日志系统设计提供了新思路，展示了AI对话技术在慢性病管理中的应用潜力。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "To appear in the ACM CHI conference on Human Factors in Computing\n  Systems (CHI), 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.03532v1",
      "published_date": "2025-03-05 14:14:25 UTC",
      "updated_date": "2025-03-05 14:14:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:09:48.465466"
    },
    {
      "arxiv_id": "2503.04833v2",
      "title": "Adversarial Training for Multimodal Large Language Models against Jailbreak Attacks",
      "title_zh": "对抗训练防御多模态大语言模型越狱攻击",
      "authors": [
        "Liming Lu",
        "Shuchao Pang",
        "Siyuan Liang",
        "Haotian Zhu",
        "Xiyu Zeng",
        "Aishan Liu",
        "Yunhuai Liu",
        "Yongbin Zhou"
      ],
      "abstract": "Multimodal large language models (MLLMs) have made remarkable strides in\ncross-modal comprehension and generation tasks. However, they remain vulnerable\nto jailbreak attacks, where crafted perturbations bypass security guardrails\nand elicit harmful outputs. In this paper, we present the first adversarial\ntraining (AT) paradigm tailored to defend against jailbreak attacks during the\nMLLM training phase. Extending traditional AT to this domain poses two critical\nchallenges: efficiently tuning massive parameters and ensuring robustness\nagainst attacks across multiple modalities. To address these challenges, we\nintroduce Projection Layer Against Adversarial Training (ProEAT), an end-to-end\nAT framework. ProEAT incorporates a projector-based adversarial training\narchitecture that efficiently handles large-scale parameters while maintaining\ncomputational feasibility by focusing adversarial training on a lightweight\nprojector layer instead of the entire model; additionally, we design a dynamic\nweight adjustment mechanism that optimizes the loss function's weight\nallocation based on task demands, streamlining the tuning process. To enhance\ndefense performance, we propose a joint optimization strategy across visual and\ntextual modalities, ensuring robust resistance to jailbreak attacks originating\nfrom either modality. Extensive experiments conducted on five major jailbreak\nattack methods across three mainstream MLLMs demonstrate the effectiveness of\nour approach. ProEAT achieves state-of-the-art defense performance,\noutperforming existing baselines by an average margin of +34% across text and\nimage modalities, while incurring only a 1% reduction in clean accuracy.\nFurthermore, evaluations on real-world embodied intelligent systems highlight\nthe practical applicability of our framework, paving the way for the\ndevelopment of more secure and reliable multimodal systems.",
      "tldr_zh": "本文提出了首个针对多模态大语言模型（MLLMs）的对抗训练（AT）框架ProEAT，用于防御jailbreak攻击。ProEAT通过轻量化的投影层进行对抗训练，显著降低了计算成本，并设计了动态权重调整机制和跨模态联合优化策略，增强了模型对文本和视觉模态攻击的鲁棒性。实验表明，ProEAT在五种主流jailbreak攻击方法上实现了最优防御性能，平均防御效果提升了34%，同时仅牺牲1%的干净样本准确率，展现了其在真实智能系统中的实用性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04833v2",
      "published_date": "2025-03-05 14:13:35 UTC",
      "updated_date": "2025-03-18 07:01:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:10:09.862187"
    },
    {
      "arxiv_id": "2503.03528v1",
      "title": "AdaSin: Enhancing Hard Sample Metrics with Dual Adaptive Penalty for Face Recognition",
      "title_zh": "AdaSin：通过双自适应惩罚增强硬样本度量的人脸识别方法",
      "authors": [
        "Qiqi Guo",
        "Zhuowen Zheng",
        "Guanghua Yang",
        "Zhiquan Liu",
        "Xiaofan Li",
        "Jianqing Li",
        "Jinyu Tian",
        "Xueyuan Gong"
      ],
      "abstract": "In recent years, the emergence of deep convolutional neural networks has\npositioned face recognition as a prominent research focus in computer vision.\nTraditional loss functions, such as margin-based, hard-sample mining-based, and\nhybrid approaches, have achieved notable performance improvements, with some\nleveraging curriculum learning to optimize training. However, these methods\noften fall short in effectively quantifying the difficulty of hard samples. To\naddress this, we propose Adaptive Sine (AdaSin) loss function, which introduces\nthe sine of the angle between a sample's embedding feature and its ground-truth\nclass center as a novel difficulty metric. This metric enables precise and\neffective penalization of hard samples. By incorporating curriculum learning,\nthe model dynamically adjusts classification boundaries across different\ntraining stages. Unlike previous adaptive-margin loss functions, AdaSin\nintroduce a dual adaptive penalty, applied to both the positive and negative\ncosine similarities of hard samples. This design imposes stronger constraints,\nenhancing intra-class compactness and inter-class separability. The combination\nof the dual adaptive penalty and curriculum learning is guided by a\nwell-designed difficulty metric. It enables the model to focus more effectively\non hard samples in later training stages, and lead to the extraction of highly\ndiscriminative face features. Extensive experiments across eight benchmarks\ndemonstrate that AdaSin achieves superior accuracy compared to other\nstate-of-the-art methods.",
      "tldr_zh": "该研究提出AdaSin损失函数，通过引入样本特征向量与真实类别中心夹角的正弦值作为困难样本的量化指标，创新性地实现了对困难样本的精准惩罚。该方法采用双重自适应惩罚机制，同时作用于正负余弦相似度，结合课程学习策略动态调整分类边界，显著提升了类内紧凑性和类间分离性。在8个基准测试上的实验表明，AdaSin相比现有最优方法实现了更高的识别准确率，为提取更具判别力的人脸特征提供了新思路。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03528v1",
      "published_date": "2025-03-05 14:11:13 UTC",
      "updated_date": "2025-03-05 14:11:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:10:56.623899"
    },
    {
      "arxiv_id": "2503.03511v1",
      "title": "NeuGrasp: Generalizable Neural Surface Reconstruction with Background Priors for Material-Agnostic Object Grasp Detection",
      "title_zh": "NeuGrasp：基于背景先验的通用神经表面重建与材质无关物体抓取检测",
      "authors": [
        "Qingyu Fan",
        "Yinghao Cai",
        "Chao Li",
        "Wenzhe He",
        "Xudong Zheng",
        "Tao Lu",
        "Bin Liang",
        "Shuo Wang"
      ],
      "abstract": "Robotic grasping in scenes with transparent and specular objects presents\ngreat challenges for methods relying on accurate depth information. In this\npaper, we introduce NeuGrasp, a neural surface reconstruction method that\nleverages background priors for material-agnostic grasp detection. NeuGrasp\nintegrates transformers and global prior volumes to aggregate multi-view\nfeatures with spatial encoding, enabling robust surface reconstruction in\nnarrow and sparse viewing conditions. By focusing on foreground objects through\nresidual feature enhancement and refining spatial perception with an\noccupancy-prior volume, NeuGrasp excels in handling objects with transparent\nand specular surfaces. Extensive experiments in both simulated and real-world\nscenarios show that NeuGrasp outperforms state-of-the-art methods in grasping\nwhile maintaining comparable reconstruction quality. More details are available\nat https://neugrasp.github.io/.",
      "tldr_zh": "该研究提出NeuGrasp，一种基于背景先验的神经表面重建方法，用于解决透明和镜面物体的通用抓取难题。该方法通过Transformer和全局先验体积整合多视角特征与空间编码，在狭窄稀疏的观测条件下实现鲁棒表面重建。实验表明，NeuGrasp在仿真和真实场景中均优于现有方法，同时保持高质量重建性能。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "I.2.9; I.2.10"
      ],
      "primary_category": "cs.RO",
      "comment": "7 pages, 5 figures. IEEE International Conference on Robotics and\n  Automation (ICRA) 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.03511v1",
      "published_date": "2025-03-05 13:57:37 UTC",
      "updated_date": "2025-03-05 13:57:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:10:33.210986"
    },
    {
      "arxiv_id": "2503.03506v1",
      "title": "Rethinking Synthetic Data definitions: A privacy driven approach",
      "title_zh": "重新思考合成数据的定义：一种以隐私为导向的方法",
      "authors": [
        "Vibeke Binz Vallevik",
        "Serena Elizabeth Marshall",
        "Aleksandar Babic",
        "Jan Franz Nygaard"
      ],
      "abstract": "Synthetic data is gaining traction as a cost-effective solution for the\nincreasing data demands of AI development and can be generated either from\nexisting knowledge or derived data captured from real-world events. The source\nof the synthetic data generation and the technique used significantly impacts\nits residual privacy risk and therefore its opportunity for sharing.\nTraditional classification of synthetic data types no longer fit the newer\ngeneration techniques and there is a need to better align the classification\nwith practical needs. We suggest a new way of grouping synthetic data types\nthat better supports privacy evaluations to aid regulatory policymaking. Our\nnovel classification provides flexibility to new advancements like deep\ngenerative methods and offers a more practical framework for future\napplications.",
      "tldr_zh": "这篇论文重新思考了合成数据的定义，提出了一种以隐私保护为核心的新型分类方法。针对当前合成数据分类无法适应新一代生成技术的问题，研究者根据数据来源和生成技术对其隐私风险的影响，建立了更符合实际需求的分类框架。该分类体系不仅支持对深度生成方法等新技术的评估，还为监管政策制定提供了更实用的隐私风险评估框架。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03506v1",
      "published_date": "2025-03-05 13:54:13 UTC",
      "updated_date": "2025-03-05 13:54:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:10:41.856460"
    },
    {
      "arxiv_id": "2503.03505v1",
      "title": "Parallelized Planning-Acting for Efficient LLM-based Multi-Agent Systems",
      "title_zh": "并行化规划-执行：面向高效大语言模型多智能体系统的协同框架",
      "authors": [
        "Yaoru Li",
        "Shunyu Liu",
        "Tongya Zheng",
        "Mingli Song"
      ],
      "abstract": "Recent advancements in Large Language Model(LLM)-based Multi-Agent\nSystems(MAS) have demonstrated remarkable potential for tackling complex\ndecision-making tasks. However, existing frameworks inevitably rely on\nserialized execution paradigms, where agents must complete sequential LLM\nplanning before taking action. This fundamental constraint severely limits\nreal-time responsiveness and adaptation, which is crucial in dynamic\nenvironments with ever-changing scenarios. In this paper, we propose a novel\nparallelized planning-acting framework for LLM-based MAS, featuring a\ndual-thread architecture with interruptible execution to enable concurrent\nplanning and acting. Specifically, our framework comprises two core threads:(1)\na planning thread driven by a centralized memory system, maintaining\nsynchronization of environmental states and agent communication to support\ndynamic decision-making; and (2) an acting thread equipped with a comprehensive\nskill library, enabling automated task execution through recursive\ndecomposition. Extensive experiments on challenging Minecraft demonstrate the\neffectiveness of the proposed framework.",
      "tldr_zh": "本文提出了一种新型并行化规划-执行框架，用于解决当前基于大语言模型(LLM)的多智能体系统(MAS)存在的串行执行效率瓶颈问题。该框架采用双线程架构设计：规划线程通过集中式记忆系统维护环境状态同步，而执行线程则利用技能库实现任务自动分解执行，从而实现规划与执行的并行化。在Minecraft环境中的实验验证了该框架能有效提升多智能体系统在动态环境中的实时响应能力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03505v1",
      "published_date": "2025-03-05 13:53:10 UTC",
      "updated_date": "2025-03-05 13:53:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:10:51.006660"
    },
    {
      "arxiv_id": "2503.03503v1",
      "title": "Collaborative Expert LLMs Guided Multi-Objective Molecular Optimization",
      "title_zh": "协作式专家大语言模型引导的多目标分子优化",
      "authors": [
        "Jiajun Yu",
        "Yizhen Zheng",
        "Huan Yee Koh",
        "Shirui Pan",
        "Tianyue Wang",
        "Haishuai Wang"
      ],
      "abstract": "Molecular optimization is a crucial yet complex and time-intensive process\nthat often acts as a bottleneck for drug development. Traditional methods rely\nheavily on trial and error, making multi-objective optimization both\ntime-consuming and resource-intensive. Current AI-based methods have shown\nlimited success in handling multi-objective optimization tasks, hampering their\npractical utilization. To address this challenge, we present MultiMol, a\ncollaborative large language model (LLM) system designed to guide\nmulti-objective molecular optimization. MultiMol comprises two agents,\nincluding a data-driven worker agent and a literature-guided research agent.\nThe data-driven worker agent is a large language model being fine-tuned to\nlearn how to generate optimized molecules considering multiple objectives,\nwhile the literature-guided research agent is responsible for searching\ntask-related literature to find useful prior knowledge that facilitates\nidentifying the most promising optimized candidates. In evaluations across six\nmulti-objective optimization tasks, MultiMol significantly outperforms existing\nmethods, achieving a 82.30% success rate, in sharp contrast to the 27.50%\nsuccess rate of current strongest methods. To further validate its practical\nimpact, we tested MultiMol on two real-world challenges. First, we enhanced the\nselectivity of Xanthine Amine Congener (XAC), a promiscuous ligand that binds\nboth A1R and A2AR, successfully biasing it towards A1R. Second, we improved the\nbioavailability of Saquinavir, an HIV-1 protease inhibitor with known\nbioavailability limitations. Overall, these results indicate that MultiMol\nrepresents a highly promising approach for multi-objective molecular\noptimization, holding great potential to accelerate the drug development\nprocess and contribute to the advancement of pharmaceutical research.",
      "tldr_zh": "该研究提出了MultiMol，一种基于协作式大语言模型(LLM)的多目标分子优化系统。该系统包含两个智能体：数据驱动的工人智能体和文献引导的研究智能体，前者负责生成优化分子，后者通过文献检索提供先验知识。在六项多目标优化任务中，MultiMol的成功率达到82.30%，显著优于现有方法（27.50%）。该系统在实际应用中也表现出色，成功提高了Xanthine Amine Congener的选择性和Saquinavir的生物利用度，展示了其在加速药物研发中的巨大潜力。",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.BM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03503v1",
      "published_date": "2025-03-05 13:47:55 UTC",
      "updated_date": "2025-03-05 13:47:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:10:57.590708"
    },
    {
      "arxiv_id": "2503.03502v1",
      "title": "CURVALID: Geometrically-guided Adversarial Prompt Detection",
      "title_zh": "CURVALID：基于几何引导的对抗性提示检测",
      "authors": [
        "Canaan Yung",
        "Hanxun Huang",
        "Sarah Monazam Erfani",
        "Christopher Leckie"
      ],
      "abstract": "Adversarial prompts capable of jailbreaking large language models (LLMs) and\ninducing undesirable behaviours pose a significant obstacle to their safe\ndeployment. Current mitigation strategies rely on activating built-in defence\nmechanisms or fine-tuning the LLMs, but the fundamental distinctions between\nadversarial and benign prompts are yet to be understood. In this work, we\nintroduce CurvaLID, a novel defense framework that efficiently detects\nadversarial prompts by leveraging their geometric properties. It is agnostic to\nthe type of LLM, offering a unified detection framework across diverse\nadversarial prompts and LLM architectures. CurvaLID builds on the geometric\nanalysis of text prompts to uncover their underlying differences. We\ntheoretically extend the concept of curvature via the Whewell equation into an\n$n$-dimensional word embedding space, enabling us to quantify local geometric\nproperties, including semantic shifts and curvature in the underlying\nmanifolds. Additionally, we employ Local Intrinsic Dimensionality (LID) to\ncapture geometric features of text prompts within adversarial subspaces. Our\nfindings reveal that adversarial prompts differ fundamentally from benign\nprompts in terms of their geometric characteristics. Our results demonstrate\nthat CurvaLID delivers superior detection and rejection of adversarial queries,\npaving the way for safer LLM deployment. The source code can be found at\nhttps://github.com/Cancanxxx/CurvaLID",
      "tldr_zh": "该研究提出了CurvaLID，一种基于几何特性的对抗性提示检测框架，用于增强大语言模型(LLMs)的安全性。该方法通过将曲率概念扩展到高维词嵌入空间，并结合局部内在维度(Local Intrinsic Dimensionality, LID)技术，量化文本提示的局部几何特性，揭示对抗性提示与良性提示在几何特征上的本质差异。实验表明，CurvaLID能够高效检测并拒绝对抗性查询，为LLMs的安全部署提供了新的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "29 Pages, 5 figues",
      "pdf_url": "http://arxiv.org/pdf/2503.03502v1",
      "published_date": "2025-03-05 13:47:53 UTC",
      "updated_date": "2025-03-05 13:47:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:11:07.391790"
    },
    {
      "arxiv_id": "2503.03480v1",
      "title": "SafeVLA: Towards Safety Alignment of Vision-Language-Action Model via Safe Reinforcement Learning",
      "title_zh": "SafeVLA：通过安全强化学习实现视觉-语言-动作模型的安全对齐",
      "authors": [
        "Borong Zhang",
        "Yuhao Zhang",
        "Jiaming Ji",
        "Yingshan Lei",
        "Josef Dai",
        "Yuanpei Chen",
        "Yaodong Yang"
      ],
      "abstract": "Vision-language-action models (VLAs) have shown great potential as generalist\nrobot policies. However, these models pose urgent safety challenges during\ndeployment, including the risk of physical harm to the environment, the robot\nitself, and humans. How can safety be explicitly incorporated into VLAs? In\nthis work, we propose SafeVLA, a novel algorithm designed to integrate safety\ninto VLAs, ensuring the protection of the environment, robot hardware and\nhumans in real-world settings. SafeVLA effectively balances safety and task\nperformance by employing large-scale constrained learning within simulated\nenvironments. We demonstrate that SafeVLA outperforms the current\nstate-of-the-art method in both safety and task performance, achieving average\nimprovements of 83.58% and 3.85%, respectively, in simulation. By prioritizing\nsafety, our approach eliminates high-risk behaviors and reduces the upper bound\nof unsafe behaviors to 1/35 of that in the current state-of-the-art, thereby\nsignificantly mitigating long-tail risks. Furthermore, the learned safety\nconstraints generalize to diverse, unseen scenarios, including multiple\nout-of-distribution perturbations and tasks. Our data, models and newly\nproposed benchmark environment are available at\nhttps://sites.google.com/view/pku-safevla.",
      "tldr_zh": "该研究提出SafeVLA算法，通过安全强化学习为视觉-语言-动作模型(VLAs)建立安全约束机制，解决机器人策略部署时可能对环境和人类造成的物理危害问题。该方法在仿真环境中进行大规模约束学习，既保证任务性能又显著提升安全性，相比现有技术将不安全行为上限降低至1/35，并在83.58%的安全性和3.85%的任务性能上实现平均提升。研究还验证了所学安全约束对分布外场景的泛化能力，同时开源了相关数据、模型和基准测试环境。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "10 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.03480v1",
      "published_date": "2025-03-05 13:16:55 UTC",
      "updated_date": "2025-03-05 13:16:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:11:12.074323"
    },
    {
      "arxiv_id": "2503.03462v1",
      "title": "Open-Source Large Language Models as Multilingual Crowdworkers: Synthesizing Open-Domain Dialogues in Several Languages With No Examples in Targets and No Machine Translation",
      "title_zh": "开源大型语言模型作为多语言众包工作者：在无目标语言示例和无机器翻译的情况下生成多语言开放域对话",
      "authors": [
        "Ahmed Njifenjou",
        "Virgile Sucal",
        "Bassam Jabaian",
        "Fabrice Lefèvre"
      ],
      "abstract": "The prevailing paradigm in the domain of Open-Domain Dialogue agents\npredominantly focuses on the English language, encompassing both models and\ndatasets. Furthermore, the financial and temporal investments required for\ncrowdsourcing such datasets for finetuning are substantial, particularly when\nmultiple languages are involved. Fortunately, advancements in Large Language\nModels (LLMs) have unveiled a plethora of possibilities across diverse tasks.\nSpecifically, instruction-tuning has enabled LLMs to execute tasks based on\nnatural language instructions, occasionally surpassing the performance of human\ncrowdworkers. Additionally, these models possess the capability to function in\nvarious languages within a single thread. Consequently, to generate new samples\nin different languages, we propose leveraging these capabilities to replicate\nthe data collection process. We introduce a pipeline for generating Open-Domain\nDialogue data in multiple Target Languages using LLMs, with demonstrations\nprovided in a unique Source Language. By eschewing explicit Machine Translation\nin this approach, we enhance the adherence to language-specific nuances. We\napply this methodology to the PersonaChat dataset. To enhance the openness of\ngenerated dialogues and mimic real life scenarii, we added the notion of speech\nevents corresponding to the type of conversation the speakers are involved in\nand also that of common ground which represents the premises of a conversation.",
      "tldr_zh": "本研究提出了一种利用开源大语言模型(LLMs)作为多语言众包工作者的方法，用于生成多语言开放域对话数据。该方法通过指令微调技术，使LLMs能够基于单一源语言的示例生成目标语言的对话数据，无需机器翻译，从而更好地保留语言特性。研究将此方法应用于PersonaChat数据集，并引入了\"speech events\"和\"common ground\"概念以增强对话的开放性和真实性。该方案为多语言开放域对话代理的开发提供了一种高效的数据生成途径，减少了对传统众包方式的依赖。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03462v1",
      "published_date": "2025-03-05 12:52:14 UTC",
      "updated_date": "2025-03-05 12:52:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:11:25.597990"
    },
    {
      "arxiv_id": "2503.03459v2",
      "title": "Unified Mind Model: Reimagining Autonomous Agents in the LLM Era",
      "title_zh": "统一心智模型：LLM时代下自主智能体的重新构想",
      "authors": [
        "Pengbo Hu",
        "Xiang Ying"
      ],
      "abstract": "Large language models (LLMs) have recently demonstrated remarkable\ncapabilities across domains, tasks, and languages (e.g., ChatGPT and GPT-4),\nreviving the research of general autonomous agents with human-like cognitive\nabilities. Such human-level agents require semantic comprehension and\ninstruction-following capabilities, which exactly fall into the strengths of\nLLMs. Although there have been several initial attempts to build human-level\nagents based on LLMs, the theoretical foundation remains a challenging open\nproblem. In this paper, we propose a novel theoretical cognitive architecture,\nthe Unified Mind Model (UMM), which offers guidance to facilitate the rapid\ncreation of autonomous agents with human-level cognitive abilities.\nSpecifically, our UMM starts with the global workspace theory and further\nleverage LLMs to enable the agent with various cognitive abilities, such as\nmulti-modal perception, planning, reasoning, tool use, learning, memory,\nreflection and motivation. Building upon UMM, we then develop an agent-building\nengine, MindOS, which allows users to quickly create domain-/task-specific\nautonomous agents without any programming effort.",
      "tldr_zh": "该研究提出\"统一心智模型\"(Unified Mind Model, UMM)，这是一个新型认知架构理论框架，旨在指导构建具备人类认知能力的LLM自主智能体。基于全局工作空间理论，UMM整合了多模态感知、规划推理、工具使用等八大认知模块，并开发了无需编程的智能体构建引擎MindOS。该框架为快速创建领域特定的类人智能体提供了理论基础和实现工具，解决了当前LLM智能体研究缺乏系统性理论支撑的问题。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.03459v2",
      "published_date": "2025-03-05 12:49:44 UTC",
      "updated_date": "2025-03-06 03:32:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:11:36.279214"
    },
    {
      "arxiv_id": "2503.03444v1",
      "title": "Taxation Perspectives from Large Language Models: A Case Study on Additional Tax Penalties",
      "title_zh": "大语言模型视角下的税收问题：以附加税罚款为例的案例研究",
      "authors": [
        "Eunkyung Choi",
        "Young Jin Suh",
        "Hun Park",
        "Wonseok Hwang"
      ],
      "abstract": "How capable are large language models (LLMs) in the domain of taxation?\nAlthough numerous studies have explored the legal domain in general, research\ndedicated to taxation remain scarce. Moreover, the datasets used in these\nstudies are either simplified, failing to reflect the real-world complexities,\nor unavailable as open source. To address this gap, we introduce PLAT, a new\nbenchmark designed to assess the ability of LLMs to predict the legitimacy of\nadditional tax penalties. PLAT is constructed to evaluate LLMs' understanding\nof tax law, particularly in cases where resolving the issue requires more than\njust applying related statutes. Our experiments with six LLMs reveal that their\nbaseline capabilities are limited, especially when dealing with conflicting\nissues that demand a comprehensive understanding. However, we found that\nenabling retrieval, self-reasoning, and discussion among multiple agents with\nspecific role assignments, this limitation can be mitigated.",
      "tldr_zh": "该研究探讨了大语言模型（LLMs）在税务领域的应用能力，特别针对附加税罚款的合法性预测问题。研究提出了新的基准测试PLAT，用于评估LLMs对税法的理解，尤其是在需要超越简单法条应用的综合判断场景中。实验表明，尽管LLMs在处理复杂冲突问题时能力有限，但通过引入检索、自我推理和基于角色分配的多智能体讨论机制，可以显著提升其表现。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "5 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.03444v1",
      "published_date": "2025-03-05 12:24:20 UTC",
      "updated_date": "2025-03-05 12:24:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:11:33.527213"
    },
    {
      "arxiv_id": "2503.03443v1",
      "title": "Conceptualizing Uncertainty",
      "title_zh": "概念化不确定性",
      "authors": [
        "Isaac Roberts",
        "Alexander Schulz",
        "Sarah Schroeder",
        "Fabian Hinder",
        "Barbara Hammer"
      ],
      "abstract": "Uncertainty in machine learning refers to the degree of confidence or lack\nthereof in a model's predictions. While uncertainty quantification methods\nexist, explanations of uncertainty, especially in high-dimensional settings,\nremain an open challenge. Existing work focuses on feature attribution\napproaches which are restricted to local explanations. Understanding\nuncertainty, its origins, and characteristics on a global scale is crucial for\nenhancing interpretability and trust in a model's predictions. In this work, we\npropose to explain the uncertainty in high-dimensional data classification\nsettings by means of concept activation vectors which give rise to local and\nglobal explanations of uncertainty. We demonstrate the utility of the generated\nexplanations by leveraging them to refine and improve our model.",
      "tldr_zh": "该研究提出了一种新的方法来解释机器学习模型在高维数据分类中的不确定性。通过引入概念激活向量（concept activation vectors），该方法不仅提供了局部解释，还能生成全局层面的不确定性解释，从而更好地理解不确定性的来源和特征。实验表明，利用这些解释可以优化和改进模型，为提升模型预测的可解释性和可信度提供了新思路。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03443v1",
      "published_date": "2025-03-05 12:24:12 UTC",
      "updated_date": "2025-03-05 12:24:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:11:48.358101"
    },
    {
      "arxiv_id": "2503.03434v1",
      "title": "RASD: Retrieval-Augmented Speculative Decoding",
      "title_zh": "RASD：检索增强的推测解码",
      "authors": [
        "Guofeng Quan",
        "Wenfeng Feng",
        "Chuzhan Hao",
        "Guochao Jiang",
        "Yuewei Zhang",
        "Hao Wang"
      ],
      "abstract": "Speculative decoding accelerates inference in large language models (LLMs) by\ngenerating draft tokens for target model verification. Current approaches for\nobtaining draft tokens rely on lightweight draft models or additional model\nstructures to generate draft tokens and retrieve context from databases. Due to\nthe draft model's small size and limited training data, model-based speculative\ndecoding frequently becomes less effective in out-of-domain scenarios.\nAdditionally, the time cost of the drafting phase results in a low upper limit\non acceptance length during the verification step, limiting overall efficiency.\nThis paper proposes RASD (Retrieval-Augmented Speculative Decoding), which\nadopts retrieval methods to enhance model-based speculative decoding. We\nintroduce tree pruning and tree fusion to achieve this. Specifically, we\ndevelop a pruning method based on the draft model's probability distribution to\nconstruct the optimal retrieval tree. Second, we employ the longest prefix\nmatching algorithm to merge the tree generated by the draft model with the\nretrieval tree, resulting in a unified tree for verification. Experimental\nresults demonstrate that RASD achieves state-of-the-art inference acceleration\nacross tasks such as DocQA, Summary, Code, and In-Domain QA. Moreover, RASD\nexhibits strong scalability, seamlessly integrating with various speculative\ndecoding approaches, including both generation-based and retrieval-based\nmethods.",
      "tldr_zh": "该研究提出了RASD（检索增强的推测解码），通过结合检索方法优化基于模型的推测解码技术，以加速大型语言模型（LLMs）的推理过程。研究引入了树剪枝和树融合技术，基于草稿模型的概率分布构建最优检索树，并利用最长前缀匹配算法将草稿模型生成的树与检索树合并，形成统一的验证树。实验表明，RASD在DocQA、摘要、代码和领域内问答等任务中实现了最先进的推理加速，并展现出强大的可扩展性，能够无缝整合生成式和检索式推测解码方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03434v1",
      "published_date": "2025-03-05 12:10:14 UTC",
      "updated_date": "2025-03-05 12:10:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:11:56.782212"
    },
    {
      "arxiv_id": "2503.03428v1",
      "title": "Privacy is All You Need: Revolutionizing Wearable Health Data with Advanced PETs",
      "title_zh": "隐私即王道：利用先进隐私增强技术革新可穿戴健康数据",
      "authors": [
        "Karthik Barma",
        "Seshu Babu Barma"
      ],
      "abstract": "In a world where data is the new currency, wearable health devices offer\nunprecedented insights into daily life, continuously monitoring vital signs and\nmetrics. However, this convenience raises privacy concerns, as these devices\ncollect sensitive data that can be misused or breached. Traditional measures\noften fail due to real-time data processing needs and limited device power.\nUsers also lack awareness and control over data sharing and usage. We propose a\nPrivacy-Enhancing Technology (PET) framework for wearable devices, integrating\nfederated learning, lightweight cryptographic methods, and selectively deployed\nblockchain technology. The blockchain acts as a secure ledger triggered only\nupon data transfer requests, granting users real-time notifications and\ncontrol. By dismantling data monopolies, this approach returns data sovereignty\nto individuals. Through real-world applications like secure medical data\nsharing, privacy-preserving fitness tracking, and continuous health monitoring,\nour framework reduces privacy risks by up to 70 percent while preserving data\nutility and performance. This innovation sets a new benchmark for wearable\nprivacy and can scale to broader IoT ecosystems, including smart homes and\nindustry. As data continues to shape our digital landscape, our research\nunderscores the critical need to maintain privacy and user control at the\nforefront of technological progress.",
      "tldr_zh": "本研究提出了一种隐私增强技术（PET）框架，旨在解决可穿戴健康设备在数据隐私方面的挑战。该框架结合了联邦学习、轻量级加密方法和选择性部署的区块链技术，确保用户对数据共享的实时通知和控制。通过实际应用，如安全的医疗数据共享和隐私保护的健康监测，该框架将隐私风险降低了高达70%，同时保持了数据的实用性和性能。这一创新为可穿戴设备的隐私保护设立了新标准，并可扩展至更广泛的物联网生态系统。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.ET",
        "cs.HC"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03428v1",
      "published_date": "2025-03-05 12:01:22 UTC",
      "updated_date": "2025-03-05 12:01:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:12:03.531432"
    },
    {
      "arxiv_id": "2503.03794v1",
      "title": "Synthetic Data Augmentation for Enhancing Harmful Algal Bloom Detection with Machine Learning",
      "title_zh": "合成数据增强提升有害藻华检测的机器学习方法",
      "authors": [
        "Tianyi Huang"
      ],
      "abstract": "Harmful Algal Blooms (HABs) pose severe threats to aquatic ecosystems and\npublic health, resulting in substantial economic losses globally. Early\ndetection is crucial but often hindered by the scarcity of high-quality\ndatasets necessary for training reliable machine learning (ML) models. This\nstudy investigates the use of synthetic data augmentation using Gaussian\nCopulas to enhance ML-based HAB detection systems. Synthetic datasets of\nvarying sizes (100-1,000 samples) were generated using relevant environmental\nfeatures$\\unicode{x2015}$water temperature, salinity, and UVB\nradiation$\\unicode{x2015}$with corrected Chlorophyll-a concentration as the\ntarget variable. Experimental results demonstrate that moderate synthetic\naugmentation significantly improves model performance (RMSE reduced from 0.4706\nto 0.1850; $p < 0.001$). However, excessive synthetic data introduces noise and\nreduces predictive accuracy, emphasizing the need for a balanced approach to\ndata augmentation. These findings highlight the potential of synthetic data to\nenhance HAB monitoring systems, offering a scalable and cost-effective method\nfor early detection and mitigation of ecological and public health risks.",
      "tldr_zh": "本研究探讨了利用高斯Copula生成合成数据增强机器学习模型在有害藻华(HABs)检测中的性能。通过生成不同规模(100-1,000样本)的合成数据集，包含水温、盐度和UVB辐射等环境特征，并以叶绿素a浓度为预测目标。实验表明，适度的合成数据增强显著提升了模型性能(RMSE从0.4706降至0.1850；p < 0.001)，但过量合成数据会引入噪声并降低预测精度，强调了数据增强的平衡性。该研究为HAB监测系统提供了一种可扩展且成本效益高的早期检测方法，有助于减轻生态和公共健康风险。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted Paper at the 2025 IEEE Conference on Technologies for\n  Sustainability (SusTech)",
      "pdf_url": "http://arxiv.org/pdf/2503.03794v1",
      "published_date": "2025-03-05 11:50:04 UTC",
      "updated_date": "2025-03-05 11:50:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:12:19.305993"
    },
    {
      "arxiv_id": "2503.03418v1",
      "title": "Simplicial SMOTE: Oversampling Solution to the Imbalanced Learning Problem",
      "title_zh": "Simplicial SMOTE：针对不平衡学习问题的过采样解决方案",
      "authors": [
        "Oleg Kachan",
        "Andrey Savchenko",
        "Gleb Gusev"
      ],
      "abstract": "SMOTE (Synthetic Minority Oversampling Technique) is the established\ngeometric approach to random oversampling to balance classes in the imbalanced\nlearning problem, followed by many extensions. Its idea is to introduce\nsynthetic data points of the minor class, with each new point being the convex\ncombination of an existing data point and one of its k-nearest neighbors. In\nthis paper, by viewing SMOTE as sampling from the edges of a geometric\nneighborhood graph and borrowing tools from the topological data analysis, we\npropose a novel technique, Simplicial SMOTE, that samples from the simplices of\na geometric neighborhood simplicial complex. A new synthetic point is defined\nby the barycentric coordinates w.r.t. a simplex spanned by an arbitrary number\nof data points being sufficiently close rather than a pair. Such a replacement\nof the geometric data model results in better coverage of the underlying data\ndistribution compared to existing geometric sampling methods and allows the\ngeneration of synthetic points of the minority class closer to the majority\nclass on the decision boundary. We experimentally demonstrate that our\nSimplicial SMOTE outperforms several popular geometric sampling methods,\nincluding the original SMOTE. Moreover, we show that simplicial sampling can be\neasily integrated into existing SMOTE extensions. We generalize and evaluate\nsimplicial extensions of the classic Borderline SMOTE, Safe-level SMOTE, and\nADASYN algorithms, all of which outperform their graph-based counterparts.",
      "tldr_zh": "该研究提出Simplicial SMOTE方法，通过将传统SMOTE的几何邻域图采样升级为单纯复形采样，解决了类别不平衡问题。新方法利用拓扑数据分析工具，通过在多个邻近数据点构成的单纯形中进行重心坐标采样，相比基于边采样的传统方法能更好覆盖数据分布，特别是生成更接近决策边界的少数类样本。实验表明，该方法不仅优于原始SMOTE等几何采样方法，还能无缝集成到Borderline SMOTE等现有扩展算法中，其单纯形变体均显著超越对应的图基版本。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at KDD 2025 (research track)",
      "pdf_url": "http://arxiv.org/pdf/2503.03418v1",
      "published_date": "2025-03-05 11:47:41 UTC",
      "updated_date": "2025-03-05 11:47:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:12:25.313857"
    },
    {
      "arxiv_id": "2503.03417v2",
      "title": "When Claims Evolve: Evaluating and Enhancing the Robustness of Embedding Models Against Misinformation Edits",
      "title_zh": "当声明演变时：评估并增强嵌入模型对信息误导编辑的鲁棒性",
      "authors": [
        "Jabez Magomere",
        "Emanuele La Malfa",
        "Manuel Tonneau",
        "Ashkan Kazemi",
        "Scott Hale"
      ],
      "abstract": "Online misinformation remains a critical challenge, and fact-checkers\nincreasingly rely on embedding-based methods to retrieve relevant fact-checks.\nYet, when debunked claims reappear in edited forms, the performance of these\nmethods is unclear. In this work, we introduce a taxonomy of six common\nreal-world misinformation edits and propose a perturbation framework that\ngenerates valid, natural claim variations. Our multi-stage retrieval evaluation\nreveals that standard embedding models struggle with user-introduced edits,\nwhile LLM-distilled embeddings offer improved robustness at a higher\ncomputational cost. Although a strong reranker helps mitigate some issues, it\ncannot fully compensate for first-stage retrieval gaps. Addressing these\nretrieval gaps, our train- and inference-time mitigation approaches enhance\nin-domain robustness by up to 17 percentage points and boost out-of-domain\ngeneralization by 10 percentage points over baseline models. Overall, our\nfindings provide practical improvements to claim-matching systems, enabling\nmore reliable fact-checking of evolving misinformation.",
      "tldr_zh": "该研究针对网络虚假信息编辑问题，提出了六类常见虚假信息编辑分类法，并开发了一种能生成自然变体声明的扰动框架。研究发现：标准嵌入模型难以应对用户修改的虚假声明，而基于大语言模型提炼的嵌入方法虽计算成本较高但鲁棒性更优。作者提出的训练和推理阶段优化方案将领域内鲁棒性最高提升17个百分点，跨领域泛化能力提高10个百分点，为应对不断演变的虚假信息提供了更可靠的事实核查技术方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03417v2",
      "published_date": "2025-03-05 11:47:32 UTC",
      "updated_date": "2025-03-06 11:00:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:12:31.673870"
    },
    {
      "arxiv_id": "2503.03410v1",
      "title": "Augmentation-Based Deep Learning for Identification of Circulating Tumor Cells",
      "title_zh": "基于增强的深度学习用于循环肿瘤细胞识别",
      "authors": [
        "Martina Russo",
        "Giulia Bertolini",
        "Vera Cappelletti",
        "Cinzia De Marco",
        "Serena Di Cosimo",
        "Petra Paiè",
        "Nadia Brancati"
      ],
      "abstract": "Circulating tumor cells (CTCs) are crucial biomarkers in liquid biopsy,\noffering a noninvasive tool for cancer patient management. However, their\nidentification remains particularly challenging due to their limited number and\nheterogeneity. Labeling samples for contrast limits the generalization of\nfluorescence-based methods across different hospital datasets. Analyzing\nsingle-cell images enables detailed assessment of cell morphology, subcellular\nstructures, and phenotypic variations, often hidden in clustered images.\nDeveloping a method based on bright-field single-cell analysis could overcome\nthese limitations. CTCs can be isolated using an unbiased workflow combining\nParsortix technology, which selects cells based on size and deformability, with\nDEPArray technology, enabling precise visualization and selection of single\ncells. Traditionally, DEPArray-acquired digital images are manually analyzed,\nmaking the process time-consuming and prone to variability. In this study, we\npresent a Deep Learning-based classification pipeline designed to distinguish\nCTCs from leukocytes in blood samples, aimed to enhance diagnostic accuracy and\noptimize clinical workflows. Our approach employs images from the bright-field\nchannel acquired through DEPArray technology leveraging a ResNet-based CNN. To\nimprove model generalization, we applied three types of data augmentation\ntechniques and incorporated fluorescence (DAPI) channel images into the\ntraining phase, allowing the network to learn additional CTC-specific features.\nNotably, only bright-field images have been used for testing, ensuring the\nmodel's ability to identify CTCs without relying on fluorescence markers. The\nproposed model achieved an F1-score of 0.798, demonstrating its capability to\ndistinguish CTCs from leukocytes. These findings highlight the potential of DL\nin refining CTC analysis and advancing liquid biopsy applications.",
      "tldr_zh": "本研究提出了一种基于深度学习的循环肿瘤细胞(CTCs)识别方法，旨在提高液体活检的诊断准确性和优化临床工作流程。该方法利用DEPArray技术获取的明场单细胞图像，结合ResNet卷积神经网络，通过数据增强技术和荧光通道图像的辅助训练，提升模型的泛化能力。测试仅使用明场图像，模型在区分CTCs和白细胞方面表现出色，F1得分达到0.798，展示了深度学习在CTCs分析和液体活检应用中的潜力。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "68T07, 68T10",
        "I.2; I.4; J.3"
      ],
      "primary_category": "eess.IV",
      "comment": "20 pages, 4 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.03410v1",
      "published_date": "2025-03-05 11:39:15 UTC",
      "updated_date": "2025-03-05 11:39:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:12:36.783027"
    },
    {
      "arxiv_id": "2503.03395v1",
      "title": "AI-Driven Multi-Stage Computer Vision System for Defect Detection in Laser-Engraved Industrial Nameplates",
      "title_zh": "AI驱动的多阶段计算机视觉系统用于激光雕刻工业铭牌缺陷检测",
      "authors": [
        "Adhish Anitha Vilasan",
        "Stephan Jäger",
        "Noah Klarmann"
      ],
      "abstract": "Automated defect detection in industrial manufacturing is essential for\nmaintaining product quality and minimizing production errors. In air disc brake\nmanufacturing, ensuring the precision of laser-engraved nameplates is crucial\nfor accurate product identification and quality control. Engraving errors, such\nas misprints or missing characters, can compromise both aesthetics and\nfunctionality, leading to material waste and production delays. This paper\npresents a proof of concept for an AI-driven computer vision system that\ninspects and verifies laser-engraved nameplates, detecting defects in logos and\nalphanumeric strings. The system integrates object detection using YOLOv7,\noptical character recognition (OCR) with Tesseract, and anomaly detection\nthrough a residual variational autoencoder (ResVAE) along with other computer\nvision methods to enable comprehensive inspections at multiple stages.\nExperimental results demonstrate the system's effectiveness, achieving 91.33%\naccuracy and 100% recall, ensuring that defective nameplates are consistently\ndetected and addressed. This solution highlights the potential of AI-driven\nvisual inspection to enhance quality control, reduce manual inspection efforts,\nand improve overall manufacturing efficiency.",
      "tldr_zh": "本研究提出了一种基于AI的多阶段计算机视觉系统，用于激光雕刻工业铭牌的缺陷检测。该系统整合了YOLOv7目标检测、Tesseract光学字符识别(OCR)以及残差变分自编码器(ResVAE)等技术，实现了对铭牌logo和字符缺陷的多层次检测。实验表明，该系统准确率达91.33%，召回率达到100%，能有效提升工业制造中的质量控制效率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03395v1",
      "published_date": "2025-03-05 11:19:17 UTC",
      "updated_date": "2025-03-05 11:19:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:13:02.453880"
    },
    {
      "arxiv_id": "2503.03391v1",
      "title": "Multi-Agent DRL for Queue-Aware Task Offloading in Hierarchical MEC-Enabled Air-Ground Networks",
      "title_zh": "面向分层移动边缘计算空天地网络的队列感知任务卸载多智能体深度强化学习方法",
      "authors": [
        "Muhammet Hevesli",
        "Abegaz Mohammed Seid",
        "Aiman Erbad",
        "Mohamed Abdallah"
      ],
      "abstract": "Mobile edge computing (MEC)-enabled air-ground networks are a key component\nof 6G, employing aerial base stations (ABSs) such as unmanned aerial vehicles\n(UAVs) and high-altitude platform stations (HAPS) to provide dynamic services\nto ground IoT devices (IoTDs). These IoTDs support real-time applications\n(e.g., multimedia and Metaverse services) that demand high computational\nresources and strict quality of service (QoS) guarantees in terms of latency\nand task queue management. Given their limited energy and processing\ncapabilities, IoTDs rely on UAVs and HAPS to offload tasks for distributed\nprocessing, forming a multi-tier MEC system. This paper tackles the overall\nenergy minimization problem in MEC-enabled air-ground integrated networks\n(MAGIN) by jointly optimizing UAV trajectories, computing resource allocation,\nand queue-aware task offloading decisions. The optimization is challenging due\nto the nonconvex, nonlinear nature of this hierarchical system, which renders\ntraditional methods ineffective. We reformulate the problem as a multi-agent\nMarkov decision process (MDP) with continuous action spaces and heterogeneous\nagents, and propose a novel variant of multi-agent proximal policy optimization\nwith a Beta distribution (MAPPO-BD) to solve it. Extensive simulations show\nthat MAPPO-BD outperforms baseline schemes, achieving superior energy savings\nand efficient resource management in MAGIN while meeting queue delay and edge\ncomputing constraints.",
      "tldr_zh": "该论文提出了一种基于多智能体深度强化学习（Multi-Agent DRL）的队列感知任务卸载方案，用于分层移动边缘计算（MEC）空天地网络。针对6G网络中无人机（UAV）和高空平台站（HAPS）为地面物联网设备（IoTD）提供计算服务的场景，作者通过联合优化无人机轨迹、计算资源分配和任务队列管理来最小化系统能耗。为解决这一非凸非线性优化问题，研究团队将问题建模为具有连续动作空间的异构多智能体马尔可夫决策过程（MDP），并提出改进版的多智能体近端策略优化算法（MAPPO-BD）。仿真结果表明，该方法在满足队列延迟和边缘计算约束的同时，显著提升了能源效率和资源管理性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03391v1",
      "published_date": "2025-03-05 11:12:40 UTC",
      "updated_date": "2025-03-05 11:12:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:12:57.372002"
    },
    {
      "arxiv_id": "2503.04832v5",
      "title": "Lightweight Embedded FPGA Deployment of Learned Image Compression with Knowledge Distillation and Hybrid Quantization",
      "title_zh": "基于知识蒸馏与混合量化的轻量化嵌入式FPGA学习图像压缩部署",
      "authors": [
        "Alaa Mazouz",
        "Sumanta Chaudhuri",
        "Marco Cagnanzzo",
        "Mihai Mitrea",
        "Enzo Tartaglione",
        "Attilio Fiandrotti"
      ],
      "abstract": "Learnable Image Compression (LIC) has shown the potential to outperform\nstandardized video codecs in RD efficiency, prompting the research for\nhardware-friendly implementations. Most existing LIC hardware implementations\nprioritize latency to RD-efficiency and through an extensive exploration of the\nhardware design space. We present a novel design paradigm where the burden of\ntuning the design for a specific hardware platform is shifted towards model\ndimensioning and without compromising on RD-efficiency. First, we design a\nframework for distilling a leaner student LIC model from a reference teacher:\nby tuning a single model hyperparameters, we can meet the constraints of\ndifferent hardware platforms without a complex hardware design exploration.\nSecond, we propose a hardware-friendly implementation of the Generalized\nDivisive Normalization - GDN activation that preserves RD efficiency even post\nparameter quantization. Third, we design a pipelined FPGA configuration which\ntakes full advantage of available FPGA resources by leveraging parallel\nprocessing and optimizing resource allocation. Our experiments with a state of\nthe art LIC model show that we outperform all existing FPGA implementations\nwhile performing very close to the original model.",
      "tldr_zh": "该研究提出了一种轻量级的嵌入式FPGA部署方法，用于学习型图像压缩（LIC），结合知识蒸馏和混合量化技术。首先，通过知识蒸馏从教师模型中提取更精简的学生模型，满足不同硬件平台的约束，无需复杂的硬件设计探索。其次，提出了一种硬件友好的广义可分离归一化（GDN）激活函数实现，即使在参数量化后仍保持率失真（RD）效率。最后，设计了一种流水线FPGA配置，充分利用并行处理和资源优化。实验表明，该方法在所有现有FPGA实现中表现最佳，且接近原始模型的性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "1. Submitted to IEEE Transactions on Circuits and Systems for Video\n  Technology in March 2025. 2. Corrected numerous mistakes from previous\n  versions in results, citations and metrics numbers in figures",
      "pdf_url": "http://arxiv.org/pdf/2503.04832v5",
      "published_date": "2025-03-05 10:59:32 UTC",
      "updated_date": "2025-03-25 09:08:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:13:01.162942"
    },
    {
      "arxiv_id": "2503.03361v1",
      "title": "From Infants to AI: Incorporating Infant-like Learning in Models Boosts Efficiency and Generalization in Learning Social Prediction Tasks",
      "title_zh": "从婴儿到AI：融入类婴儿学习机制显著提升社交预测任务的学习效率与泛化能力",
      "authors": [
        "Shify Treger",
        "Shimon Ullman"
      ],
      "abstract": "Early in development, infants learn a range of useful concepts, which can be\nchallenging from a computational standpoint. This early learning comes together\nwith an initial understanding of aspects of the meaning of concepts, e.g.,\ntheir implications, causality, and using them to predict likely future events.\nAll this is accomplished in many cases with little or no supervision, and from\nrelatively few examples, compared with current network models. In learning\nabout objects and human-object interactions, early acquired and possibly innate\nconcepts are often used in the process of learning additional, more complex\nconcepts. In the current work, we model how early-acquired concepts are used in\nthe learning of subsequent concepts, and compare the results with standard deep\nnetwork modeling. We focused in particular on the use of the concepts of\nanimacy and goal attribution in learning to predict future events. We show that\nthe use of early concepts in the learning of new concepts leads to better\nlearning (higher accuracy) and more efficient learning (requiring less data).\nWe further show that this integration of early and new concepts shapes the\nrepresentation of the concepts acquired by the model. The results show that\nwhen the concepts were learned in a human-like manner, the emerging\nrepresentation was more useful, as measured in terms of generalization to novel\ndata and tasks. On a more general level, the results suggest that there are\nlikely to be basic differences in the conceptual structures acquired by current\nnetwork models compared to human learning.",
      "tldr_zh": "该研究通过模拟婴儿认知发展过程，提出将早期习得概念（如能动性和目标归因）整合到AI模型中，以提高社交预测任务的学习效率。实验表明，这种类婴儿学习方式相比标准深度学习模型，能以更少的数据实现更高准确率，并且学到的概念表征具备更好的泛化能力。研究揭示了人类学习与当前神经网络模型在概念结构获取方面的根本差异，为开发更高效、更接近人类认知的AI系统提供了新思路。",
      "categories": [
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03361v1",
      "published_date": "2025-03-05 10:40:19 UTC",
      "updated_date": "2025-03-05 10:40:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:13:22.290450"
    },
    {
      "arxiv_id": "2503.03360v2",
      "title": "Transformers for molecular property prediction: Domain adaptation efficiently improves performance",
      "title_zh": "分子性质预测的Transformer模型：领域自适应有效提升性能",
      "authors": [
        "Afnan Sultan",
        "Max Rausch-Dupont",
        "Shahrukh Khan",
        "Olga Kalinina",
        "Andrea Volkamer",
        "Dietrich Klakow"
      ],
      "abstract": "Most of the current transformer-based chemical language models are\npre-trained on millions to billions of molecules. However, the improvement from\nsuch scaling in dataset size is not confidently linked to improved molecular\nproperty prediction. The aim of this study is to investigate and overcome some\nof the limitations of transformer models in predicting molecular properties.\nSpecifically, we examine the impact of pre-training dataset size and diversity\non the performance of transformer models and investigate the use of domain\nadaptation as a technique for improving model performance. First, our findings\nindicate that increasing pretraining dataset size beyond 400K molecules from\nthe GuacaMol dataset does not result in a significant improvement on four ADME\nendpoints, namely, solubility, permeability, microsomal stability, and plasma\nprotein binding. Second, our results demonstrate that using domain adaptation\nby further training the transformer model on a small set of domain-relevant\nmolecules, i.e., a few hundred to a few thousand, using multi-task regression\nof physicochemical properties was sufficient to significantly improve\nperformance for three out of the four investigated ADME endpoints (P-value <\n0.001). Finally, we observe that a model pre-trained on 400K molecules and\ndomain adopted on a few hundred/thousand molecules performs similarly (P-value\n> 0.05) to more complicated transformer models like MolBERT(pre-trained on 1.3M\nmolecules) and MolFormer (pre-trained on 100M molecules). A comparison to a\nrandom forest model trained on basic physicochemical properties showed similar\nperformance to the examined transformer models. We believe that current\ntransformer models can be improved through further systematic analysis of\npre-training and downstream data, pre-training objectives, and scaling laws,\nultimately leading to better and more helpful models.",
      "tldr_zh": "本研究探讨了Transformer模型在分子属性预测中的优化策略。关键发现表明：1) 预训练数据集规模超过40万分子(GuaCaMol数据集)后，对四种ADME指标(溶解度、渗透性、微粒体稳定性和血浆蛋白结合率)预测性能提升不显著；2) 通过少量领域相关分子(数百至数千)进行多任务回归的领域适应训练，可显著改善其中三项ADME指标预测(P<0.001)。值得注意的是，采用400K预训练加小规模领域适应的模型，其性能与复杂模型MolBERT(130万预训练)和MolFormer(1亿预训练)相当(P>0.05)，且与基于物化特性的随机森林模型表现相近。研究揭示了系统优化预训练策略对提升分子属性预测模型效能的重要性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03360v2",
      "published_date": "2025-03-05 10:40:09 UTC",
      "updated_date": "2025-03-07 08:55:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:13:37.370272"
    },
    {
      "arxiv_id": "2503.03350v1",
      "title": "Leveraging Large Language Models to Develop Heuristics for Emerging Optimization Problems",
      "title_zh": "利用大型语言模型开发新兴优化问题的启发式方法",
      "authors": [
        "Thomas Bömer",
        "Nico Koltermann",
        "Max Disselnmeyer",
        "Laura Dörr",
        "Anne Meyer"
      ],
      "abstract": "Combinatorial optimization problems often rely on heuristic algorithms to\ngenerate efficient solutions. However, the manual design of heuristics is\nresource-intensive and constrained by the designer's expertise. Recent advances\nin artificial intelligence, particularly large language models (LLMs), have\ndemonstrated the potential to automate heuristic generation through\nevolutionary frameworks. Recent works focus only on well-known combinatorial\noptimization problems like the traveling salesman problem and online bin\npacking problem when designing constructive heuristics. This study investigates\nwhether LLMs can effectively generate heuristics for niche, not yet broadly\nresearched optimization problems, using the unit-load pre-marshalling problem\nas an example case. We propose the Contextual Evolution of Heuristics (CEoH)\nframework, an extension of the Evolution of Heuristics (EoH) framework, which\nincorporates problem-specific descriptions to enhance in-context learning\nduring heuristic generation. Through computational experiments, we evaluate\nCEoH and EoH and compare the results. Results indicate that CEoH enables\nsmaller LLMs to generate high-quality heuristics more consistently and even\noutperform larger models. Larger models demonstrate robust performance with or\nwithout contextualized prompts. The generated heuristics exhibit scalability to\ndiverse instance configurations.",
      "tldr_zh": "本研究探讨了如何利用大语言模型(LLMs)为新兴组合优化问题自动生成启发式算法，提出了上下文启发式演化框架(Contextual Evolution of Heuristics, CEoH)，作为启发式演化框架(Evolution of Heuristics, EoH)的扩展。该框架通过引入问题描述来增强上下文学习，并以单位负载预调度问题为例进行验证。实验结果表明，CEoH能使较小的LLMs更稳定地生成高质量启发式算法，甚至优于大型模型；而大型模型在有或无上下文提示下均表现稳健。生成的启发式算法展现出对不同实例配置的良好扩展性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Under review LION19: The 19th Learning and Intelligent OptimizatioN\n  Conference",
      "pdf_url": "http://arxiv.org/pdf/2503.03350v1",
      "published_date": "2025-03-05 10:22:49 UTC",
      "updated_date": "2025-03-05 10:22:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:13:40.208596"
    },
    {
      "arxiv_id": "2503.03338v1",
      "title": "Navigating Intelligence: A Survey of Google OR-Tools and Machine Learning for Global Path Planning in Autonomous Vehicles",
      "title_zh": "导航智能：基于Google OR-Tools与机器学习的自动驾驶车辆全局路径规划综述",
      "authors": [
        "Alexandre Benoit",
        "Pedram Asef"
      ],
      "abstract": "We offer a new in-depth investigation of global path planning (GPP) for\nunmanned ground vehicles, an autonomous mining sampling robot named ROMIE. GPP\nis essential for ROMIE's optimal performance, which is translated into solving\nthe traveling salesman problem, a complex graph theory challenge that is\ncrucial for determining the most effective route to cover all sampling\nlocations in a mining field. This problem is central to enhancing ROMIE's\noperational efficiency and competitiveness against human labor by optimizing\ncost and time. The primary aim of this research is to advance GPP by\ndeveloping, evaluating, and improving a cost-efficient software and web\napplication. We delve into an extensive comparison and analysis of Google\noperations research (OR)-Tools optimization algorithms. Our study is driven by\nthe goal of applying and testing the limits of OR-Tools capabilities by\nintegrating Reinforcement Learning techniques for the first time. This enables\nus to compare these methods with OR-Tools, assessing their computational\neffectiveness and real-world application efficiency. Our analysis seeks to\nprovide insights into the effectiveness and practical application of each\ntechnique. Our findings indicate that Q-Learning stands out as the optimal\nstrategy, demonstrating superior efficiency by deviating only 1.2% on average\nfrom the optimal solutions across our datasets.",
      "tldr_zh": "本文深入研究了无人地面车辆（如自主采矿采样机器人ROMIE）的全局路径规划（GPP）问题，将其建模为旅行商问题（TSP）。研究创新性地将Google OR-Tools优化算法与强化学习技术（特别是Q-Learning）相结合进行对比分析。结果表明，Q-Learning表现最优，其解决方案平均仅偏离最优路径1.2%，为自主车辆路径规划提供了高效的新方法。该研究不仅评估了各算法的计算效能，还开发了成本优化的软件和Web应用方案。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CE",
        "eess.SP"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03338v1",
      "published_date": "2025-03-05 10:12:22 UTC",
      "updated_date": "2025-03-05 10:12:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:14:00.446210"
    },
    {
      "arxiv_id": "2503.03321v1",
      "title": "See What You Are Told: Visual Attention Sink in Large Multimodal Models",
      "title_zh": "所见即所闻：大型多模态模型中的视觉注意力下沉现象",
      "authors": [
        "Seil Kang",
        "Jinyeong Kim",
        "Junhyeok Kim",
        "Seong Jae Hwang"
      ],
      "abstract": "Large multimodal models (LMMs) \"see\" images by leveraging the attention\nmechanism between text and visual tokens in the transformer decoder. Ideally,\nthese models should focus on key visual information relevant to the text token.\nHowever, recent findings indicate that LMMs have an extraordinary tendency to\nconsistently allocate high attention weights to specific visual tokens, even\nwhen these tokens are irrelevant to the corresponding text. In this study, we\ninvestigate the property behind the appearance of these irrelevant visual\ntokens and examine their characteristics. Our findings show that this behavior\narises due to the massive activation of certain hidden state dimensions, which\nresembles the attention sink found in language models. Hence, we refer to this\nphenomenon as the visual attention sink. In particular, our analysis reveals\nthat removing the irrelevant visual sink tokens does not impact model\nperformance, despite receiving high attention weights. Consequently, we recycle\nthe attention to these tokens as surplus resources, redistributing the\nattention budget to enhance focus on the image. To achieve this, we introduce\nVisual Attention Redistribution (VAR), a method that redistributes attention in\nimage-centric heads, which we identify as innately focusing on visual\ninformation. VAR can be seamlessly applied across different LMMs to improve\nperformance on a wide range of tasks, including general vision-language tasks,\nvisual hallucination tasks, and vision-centric tasks, all without the need for\nadditional training, models, or inference steps. Experimental results\ndemonstrate that VAR enables LMMs to process visual information more\neffectively by adjusting their internal attention mechanisms, offering a new\ndirection to enhancing the multimodal capabilities of LMMs.",
      "tldr_zh": "该研究发现大型多模态模型(LMMs)存在\"视觉注意力沉没\"现象，即某些无关视觉token会持续获得高注意力权重。研究表明这是由于特定隐藏状态维度被过度激活所致，类似于语言模型中的注意力沉没现象。研究者提出无需训练的Visual Attention Redistribution(VAR)方法，通过重新分配图像中心注意力头的注意力预算来提升模型性能。实验表明VAR能有效增强LMMs在各类视觉语言任务中的表现，包括减少视觉幻觉问题，为改进多模态模型提供新思路。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03321v1",
      "published_date": "2025-03-05 09:55:07 UTC",
      "updated_date": "2025-03-05 09:55:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:13:48.739197"
    },
    {
      "arxiv_id": "2503.04831v1",
      "title": "\"Only ChatGPT gets me\": An Empirical Analysis of GPT versus other Large Language Models for Emotion Detection in Text",
      "title_zh": "“只有ChatGPT懂我”：GPT与其他大语言模型在文本情感检测中的实证分析",
      "authors": [
        "Florian Lecourt",
        "Madalina Croitoru",
        "Konstantin Todorov"
      ],
      "abstract": "This work investigates the capabilities of large language models (LLMs) in\ndetecting and understanding human emotions through text. Drawing upon emotion\nmodels from psychology, we adopt an interdisciplinary perspective that\nintegrates computational and affective sciences insights. The main goal is to\nassess how accurately they can identify emotions expressed in textual\ninteractions and compare different models on this specific task. This research\ncontributes to broader efforts to enhance human-computer interaction, making\nartificial intelligence technologies more responsive and sensitive to users'\nemotional nuances. By employing a methodology that involves comparisons with a\nstate-of-the-art model on the GoEmotions dataset, we aim to gauge LLMs'\neffectiveness as a system for emotional analysis, paving the way for potential\napplications in various fields that require a nuanced understanding of human\nlanguage.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）在文本中检测和理解人类情感的能力，结合心理学中的情感模型，采用跨学科视角整合计算与情感科学的见解。研究的主要目标是评估不同模型在识别文本交互中表达情感的准确性，并通过与GoEmotions数据集上的最先进模型进行比较，衡量LLMs在情感分析中的有效性。结果表明，GPT在情感检测任务中表现尤为突出，为提升人机交互中人工智能对用户情感细微差别的响应能力提供了重要参考。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04831v1",
      "published_date": "2025-03-05 09:47:49 UTC",
      "updated_date": "2025-03-05 09:47:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:13:56.560120"
    },
    {
      "arxiv_id": "2503.05823v1",
      "title": "Introduction to Artificial Consciousness: History, Current Trends and Ethical Challenges",
      "title_zh": "人工智能意识导论：历史、当前趋势与伦理挑战",
      "authors": [
        "Aïda Elamrani"
      ],
      "abstract": "With the significant progress of artificial intelligence (AI) and\nconsciousness science, artificial consciousness (AC) has recently gained\npopularity. This work provides a broad overview of the main topics and current\ntrends in AC. The first part traces the history of this interdisciplinary field\nto establish context and clarify key terminology, including the distinction\nbetween Weak and Strong AC. The second part examines major trends in AC\nimplementations, emphasising the synergy between Global Workspace and Attention\nSchema, as well as the problem of evaluating the internal states of artificial\nsystems. The third part analyses the ethical dimension of AC development,\nrevealing both critical risks and transformative opportunities. The last part\noffers recommendations to guide AC research responsibly, and outlines the\nlimitations of this study as well as avenues for future research. The main\nconclusion is that while AC appears both indispensable and inevitable for\nscientific progress, serious efforts are required to address the far-reaching\nimpact of this innovative research path.",
      "tldr_zh": "本文全面回顾了人工意识(Artificial Consciousness, AC)的历史、现状和伦理挑战。首先，文章梳理了AC的跨学科发展历程，区分了弱AC与强AC的概念。其次，探讨了AC实现的主要趋势，重点关注全局工作空间(Global Workspace)与注意力图式(Attention Schema)的结合，以及评估人工系统内部状态的难题。第三部分分析了AC发展的伦理维度，揭示了潜在风险和变革机遇。最后，文章提出了负责任开展AC研究的建议，并指出了当前研究的局限性与未来方向。核心结论是，尽管AC对科学进步不可或缺且势在必行，但需认真应对其深远影响。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "65 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.05823v1",
      "published_date": "2025-03-05 09:34:36 UTC",
      "updated_date": "2025-03-05 09:34:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:14:07.570277"
    },
    {
      "arxiv_id": "2503.03283v1",
      "title": "Exploring specialization and sensitivity of convolutional neural networks in the context of simultaneous image augmentations",
      "title_zh": "探究卷积神经网络在同步图像增强情境下的专一性与敏感性",
      "authors": [
        "Pavel Kharyuk",
        "Sergey Matveev",
        "Ivan Oseledets"
      ],
      "abstract": "Drawing parallels with the way biological networks are studied, we adapt the\ntreatment--control paradigm to explainable artificial intelligence research and\nenrich it through multi-parametric input alterations. In this study, we propose\na framework for investigating the internal inference impacted by input data\naugmentations. The internal changes in network operation are reflected in\nactivation changes measured by variance, which can be decomposed into\ncomponents related to each augmentation, employing Sobol indices and Shapley\nvalues. These quantities enable one to visualize sensitivity to different\nvariables and use them for guided masking of activations. In addition, we\nintroduce a way of single-class sensitivity analysis where the candidates are\nfiltered according to their matching to prediction bias generated by targeted\ndamaging of the activations. Relying on the observed parallels, we assume that\nthe developed framework can potentially be transferred to studying biological\nneural networks in complex environments.",
      "tldr_zh": "本研究借鉴生物学网络研究方法，提出了一种基于治疗-控制范式的可解释AI分析框架，用于探究卷积神经网络(CNN)在多重图像增强下的内部推理机制。通过Sobol指数和Shapley值分解激活方差，量化网络对不同增强参数的敏感性，并开发了基于预测偏差的单类别敏感性分析方法。该框架不仅揭示了CNN的专一化特性，其方法论还可能迁移应用于复杂环境下的生物神经网络研究。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "cs.NA",
        "math.NA",
        "68T07",
        "I.2.6; G.3; I.2.10"
      ],
      "primary_category": "stat.ML",
      "comment": "26 pages; main text: 5 figures, 4 tables; appendix: 4 sections, 3\n  tables; supplementary: 7 files (figures S1-S6: packed as 7z archive, S7:\n  single pdf file)",
      "pdf_url": "http://arxiv.org/pdf/2503.03283v1",
      "published_date": "2025-03-05 09:09:01 UTC",
      "updated_date": "2025-03-05 09:09:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:14:16.932296"
    },
    {
      "arxiv_id": "2503.04830v2",
      "title": "Cite Before You Speak: Enhancing Context-Response Grounding in E-commerce Conversational LLM-Agents",
      "title_zh": "言前必引：提升电商对话大语言模型代理的上下文响应关联性",
      "authors": [
        "Jingying Zeng",
        "Hui Liu",
        "Zhenwei Dai",
        "Xianfeng Tang",
        "Chen Luo",
        "Samarth Varshney",
        "Zhen Li",
        "Qi He"
      ],
      "abstract": "With the advancement of conversational large language models (LLMs), several\nLLM-based Conversational Shopping Agents (CSA) have been developed to help\ncustomers answer questions and smooth their shopping journey in e-commerce\ndomain. The primary objective in building a trustworthy CSA is to ensure the\nagent's responses are accurate and factually grounded, which is essential for\nbuilding customer trust and encouraging continuous engagement. However, two\nchallenges remain. First, LLMs produce hallucinated or unsupported claims. Such\ninaccuracies risk spreading misinformation and diminishing customer trust.\nSecond, without providing knowledge source attribution in CSA response,\ncustomers struggle to verify LLM-generated information. To address these\nchallenges, we present an easily productionized solution that enables a\n\"citation experience\" utilizing In-context Learning (ICL) and\nMulti-UX-Inference (MUI) to generate responses with citations to attribute its\noriginal sources without interfering other existing UX features. With proper UX\ndesign, these citation marks can be linked to the related product information\nand display the source to our customers. In this work, we also build\nauto-metrics and scalable benchmarks to holistically evaluate LLM's grounding\nand attribution capabilities. Our experiments demonstrate that incorporating\nthis citation generation paradigm can substantially enhance the grounding of\nLLM responses by 13.83% on the real-world data. As such, our solution not only\naddresses the immediate challenges of LLM grounding issues but also adds\ntransparency to conversational AI.",
      "tldr_zh": "该研究提出了一种基于引用的解决方案，用于提升电商领域对话式大语言模型(LLM)代理的上下文响应准确性。通过结合上下文学习(In-context Learning)和多用户体验推理(Multi-UX-Inference)，该方案在生成响应的同时提供引用，以标注信息来源，增强用户验证能力。实验表明，该方案在真实数据上将LLM响应的准确性提升了13.83%，有效解决了LLM的幻觉问题，并增加了对话式AI的透明度。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04830v2",
      "published_date": "2025-03-05 08:58:35 UTC",
      "updated_date": "2025-03-10 01:47:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:14:21.674357"
    },
    {
      "arxiv_id": "2503.03274v1",
      "title": "Benchmarking Dynamic SLO Compliance in Distributed Computing Continuum Systems",
      "title_zh": "分布式计算连续体系统中的动态服务级别目标合规性基准测试",
      "authors": [
        "Alfreds Lapkovskis",
        "Boris Sedlak",
        "Sindri Magnússon",
        "Schahram Dustdar",
        "Praveen Kumar Donta"
      ],
      "abstract": "Ensuring Service Level Objectives (SLOs) in large-scale architectures, such\nas Distributed Computing Continuum Systems (DCCS), is challenging due to their\nheterogeneous nature and varying service requirements across different devices\nand applications. Additionally, unpredictable workloads and resource\nlimitations lead to fluctuating performance and violated SLOs. To improve SLO\ncompliance in DCCS, one possibility is to apply machine learning; however, the\ndesign choices are often left to the developer. To that extent, we provide a\nbenchmark of Active Inference -- an emerging method from neuroscience --\nagainst three established reinforcement learning algorithms (Deep Q-Network,\nAdvantage Actor-Critic, and Proximal Policy Optimization). We consider a\nrealistic DCCS use case: an edge device running a video conferencing\napplication alongside a WebSocket server streaming videos. Using one of the\nrespective algorithms, we continuously monitor key performance metrics, such as\nlatency and bandwidth usage, to dynamically adjust parameters -- including the\nnumber of streams, frame rate, and resolution -- to optimize service quality\nand user experience. To test algorithms' adaptability to constant system\nchanges, we simulate dynamically changing SLOs and both instant and gradual\ndata-shift scenarios, such as network bandwidth limitations and fluctuating\ndevice thermal states. Although the evaluated algorithms all showed advantages\nand limitations, our findings demonstrate that Active Inference is a promising\napproach for ensuring SLO compliance in DCCS, offering lower memory usage,\nstable CPU utilization, and fast convergence.",
      "tldr_zh": "该研究针对分布式计算连续体系统(DCCS)中的动态服务级别目标(SLO)合规性问题，提出了一种基于机器学习的基准测试方法。研究者比较了来自神经科学的新兴方法Active Inference与三种强化学习算法（Deep Q-Network、Advantage Actor-Critic和Proximal Policy Optimization）在视频会议和视频流应用场景中的表现。通过模拟动态变化的SLO和系统条件，研究发现Active Inference在内存使用、CPU利用率和收敛速度方面表现优异，为DCCS中的SLO合规性提供了新的解决方案。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG",
        "cs.NI",
        "cs.PF"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03274v1",
      "published_date": "2025-03-05 08:56:26 UTC",
      "updated_date": "2025-03-05 08:56:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:14:34.190158"
    },
    {
      "arxiv_id": "2503.03269v1",
      "title": "Conformal Transformations for Symmetric Power Transformers",
      "title_zh": "对称幂变压器的共形变换",
      "authors": [
        "Saurabh Kumar",
        "Jacob Buckman",
        "Carles Gelada",
        "Sean Zhang"
      ],
      "abstract": "Transformers with linear attention offer significant computational advantages\nover softmax-based transformers but often suffer from degraded performance. The\nsymmetric power (sympow) transformer, a particular type of linear transformer,\naddresses some of this performance gap by leveraging symmetric tensor\nembeddings, achieving comparable performance to softmax transformers. However,\nthe finite capacity of the recurrent state in sympow transformers limits their\nability to retain information, leading to performance degradation when scaling\nthe training or evaluation context length. To address this issue, we propose\nthe conformal-sympow transformer, which dynamically frees up capacity using\ndata-dependent multiplicative gating and adaptively stores information using\ndata-dependent rotary embeddings. Preliminary experiments on the LongCrawl64\ndataset demonstrate that conformal-sympow overcomes the limitations of sympow\ntransformers, achieving robust performance across scaled training and\nevaluation contexts.",
      "tldr_zh": "该研究提出了Conformal-sympow Transformer，用于改进对称幂(sympow) Transformer在长上下文场景下的性能受限问题。通过引入数据依赖的乘法门控机制和自适应旋转嵌入，动态释放模型容量并优化信息存储。实验表明，Conformal-sympow在LongCrawl64数据集上表现出色，解决了传统sympow Transformer在扩展训练和评估上下文长度时的性能退化问题，为线性Transformer的进一步应用提供了新思路。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "SCOPE Workshop at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.03269v1",
      "published_date": "2025-03-05 08:50:53 UTC",
      "updated_date": "2025-03-05 08:50:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:14:57.151417"
    },
    {
      "arxiv_id": "2503.03262v1",
      "title": "Trajectory Prediction for Autonomous Driving: Progress, Limitations, and Future Directions",
      "title_zh": "自动驾驶轨迹预测：研究进展、局限性与未来方向",
      "authors": [
        "Nadya Abdel Madjid",
        "Abdulrahman Ahmad",
        "Murad Mebrahtu",
        "Yousef Babaa",
        "Abdelmoamen Nasser",
        "Sumbal Malik",
        "Bilal Hassan",
        "Naoufel Werghi",
        "Jorge Dias",
        "Majid Khonji"
      ],
      "abstract": "As the potential for autonomous vehicles to be integrated on a large scale\ninto modern traffic systems continues to grow, ensuring safe navigation in\ndynamic environments is crucial for smooth integration. To guarantee safety and\nprevent collisions, autonomous vehicles must be capable of accurately\npredicting the trajectories of surrounding traffic agents. Over the past\ndecade, significant efforts from both academia and industry have been dedicated\nto designing solutions for precise trajectory forecasting. These efforts have\nproduced a diverse range of approaches, raising questions about the differences\nbetween these methods and whether trajectory prediction challenges have been\nfully addressed. This paper reviews a substantial portion of recent trajectory\nprediction methods and devises a taxonomy to classify existing solutions. A\ngeneral overview of the prediction pipeline is also provided, covering input\nand output modalities, modeling features, and prediction paradigms discussed in\nthe literature. In addition, the paper discusses active research areas within\ntrajectory prediction, addresses the posed research questions, and highlights\nthe remaining research gaps and challenges.",
      "tldr_zh": "本文综述了自动驾驶轨迹预测领域的研究进展、局限性和未来方向。通过回顾近十年的研究成果，文章提出了现有方法的分类体系，并概述了预测流程的输入输出模式、建模特征和预测范式。同时，文章探讨了当前研究中的关键问题，指出了剩余的研究空白与挑战，为未来更精确、可靠的轨迹预测技术发展提供了指导。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03262v1",
      "published_date": "2025-03-05 08:38:51 UTC",
      "updated_date": "2025-03-05 08:38:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:14:55.136242"
    },
    {
      "arxiv_id": "2503.03258v1",
      "title": "Exploring the Potential of Large Language Models as Predictors in Dynamic Text-Attributed Graphs",
      "title_zh": "探索大型语言模型在动态文本属性图中作为预测器的潜力",
      "authors": [
        "Runlin Lei",
        "Jiarui Ji",
        "Haipeng Ding",
        "Lu Yi",
        "Zhewei Wei",
        "Yongchao Liu",
        "Chuntao Hong"
      ],
      "abstract": "With the rise of large language models (LLMs), there has been growing\ninterest in Graph Foundation Models (GFMs) for graph-based tasks. By leveraging\nLLMs as predictors, GFMs have demonstrated impressive generalizability across\nvarious tasks and datasets. However, existing research on LLMs as predictors\nhas predominantly focused on static graphs, leaving their potential in dynamic\ngraph prediction unexplored. In this work, we pioneer using LLMs for predictive\ntasks on dynamic graphs. We identify two key challenges: the constraints\nimposed by context length when processing large-scale historical data and the\nsignificant variability in domain characteristics, both of which complicate the\ndevelopment of a unified predictor. To address these challenges, we propose the\nGraphAgent-Dynamic (GAD) Framework, a multi-agent system that leverages\ncollaborative LLMs. In contrast to using a single LLM as the predictor, GAD\nincorporates global and local summary agents to generate domain-specific\nknowledge, enhancing its transferability across domains. Additionally,\nknowledge reflection agents enable adaptive updates to GAD's knowledge,\nmaintaining a unified and self-consistent architecture. In experiments, GAD\ndemonstrates performance comparable to or even exceeds that of full-supervised\ngraph neural networks without dataset-specific training. Finally, to enhance\nthe task-specific performance of LLM-based predictors, we discuss potential\nimprovements, such as dataset-specific fine-tuning to LLMs. By developing\ntailored strategies for different tasks, we provide new insights for the future\ndesign of LLM-based predictors.",
      "tldr_zh": "本研究首次探索了将大语言模型(LLMs)应用于动态文本属性图的预测任务，提出了GraphAgent-Dynamic (GAD)框架来应对两大核心挑战：历史数据处理中的上下文长度限制和跨领域特征差异问题。该框架创新性地采用多智能体协作系统，通过全局/局部摘要智能体和知识反射智能体实现领域知识生成与自适应更新，在无需特定数据集训练的情况下，其性能媲美甚至超越全监督图神经网络。研究还为提升LLM预测器的任务特定性能提供了优化方向，为基于LLM的预测器设计提供了新思路。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03258v1",
      "published_date": "2025-03-05 08:28:11 UTC",
      "updated_date": "2025-03-05 08:28:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:15:14.187934"
    },
    {
      "arxiv_id": "2503.03792v1",
      "title": "Rebalanced Multimodal Learning with Data-aware Unimodal Sampling",
      "title_zh": "基于数据感知单模态采样的再平衡多模态学习",
      "authors": [
        "Qingyuan Jiang",
        "Zhouyang Chi",
        "Xiao Ma",
        "Qirong Mao",
        "Yang Yang",
        "Jinhui Tang"
      ],
      "abstract": "To address the modality learning degeneration caused by modality imbalance,\nexisting multimodal learning~(MML) approaches primarily attempt to balance the\noptimization process of each modality from the perspective of model learning.\nHowever, almost all existing methods ignore the modality imbalance caused by\nunimodal data sampling, i.e., equal unimodal data sampling often results in\ndiscrepancies in informational content, leading to modality imbalance.\nTherefore, in this paper, we propose a novel MML approach called\n\\underline{D}ata-aware \\underline{U}nimodal \\underline{S}ampling~(\\method),\nwhich aims to dynamically alleviate the modality imbalance caused by sampling.\nSpecifically, we first propose a novel cumulative modality discrepancy to\nmonitor the multimodal learning process. Based on the learning status, we\npropose a heuristic and a reinforcement learning~(RL)-based data-aware unimodal\nsampling approaches to adaptively determine the quantity of sampled data at\neach iteration, thus alleviating the modality imbalance from the perspective of\nsampling. Meanwhile, our method can be seamlessly incorporated into almost all\nexisting multimodal learning approaches as a plugin. Experiments demonstrate\nthat \\method~can achieve the best performance by comparing with diverse\nstate-of-the-art~(SOTA) baselines.",
      "tldr_zh": "本文提出了一种新型多模态学习方法DUS（Data-aware Unimodal Sampling），通过动态调整单模态数据采样来解决多模态学习中因采样不均导致的信息内容差异问题。该方法创新性地提出累积模态差异指标来监控学习过程，并采用启发式和强化学习两种策略自适应决定每轮迭代的采样量。实验表明，该插件式方法能与现有多模态学习框架无缝结合，在多项基准测试中超越当前最优方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03792v1",
      "published_date": "2025-03-05 08:19:31 UTC",
      "updated_date": "2025-03-05 08:19:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:15:15.393933"
    },
    {
      "arxiv_id": "2503.07638v2",
      "title": "Leveraging Taxonomy Similarity for Next Activity Prediction in Patient Treatment",
      "title_zh": "利用分类相似性预测患者治疗中的下一活动",
      "authors": [
        "Martin Kuhn",
        "Joscha Grüger",
        "Tobias Geyer",
        "Ralph Bergmann"
      ],
      "abstract": "The rapid progress in modern medicine presents physicians with complex\nchallenges when planning patient treatment. Techniques from the field of\nPredictive Business Process Monitoring, like Next-activity-prediction (NAP) can\nbe used as a promising technique to support physicians in treatment planning,\nby proposing a possible next treatment step. Existing patient data, often in\nthe form of electronic health records, can be analyzed to recommend the next\nsuitable step in the treatment process. However, the use of patient data poses\nmany challenges due to its knowledge-intensive character, high variability and\nscarcity of medical data. To overcome these challenges, this article examines\nthe use of the knowledge encoded in taxonomies to improve and explain the\nprediction of the next activity in the treatment process. This study proposes\nthe TS4NAP approach, which uses medical taxonomies (ICD-10-CM and ICD-10-PCS)\nin combination with graph matching to assess the similarities of medical codes\nto predict the next treatment step. The effectiveness of the proposed approach\nwill be evaluated using event logs that are derived from the MIMIC-IV dataset.\nThe results highlight the potential of using domain-specific knowledge held in\ntaxonomies to improve the prediction of the next activity, and thus can improve\ntreatment planning and decision-making by making the predictions more\nexplainable.",
      "tldr_zh": "本文提出了一种基于分类法相似性的TS4NAP方法，用于预测患者治疗过程中的下一步活动。该方法利用医疗分类法（如ICD-10-CM和ICD-10-PCS）结合图匹配技术，评估医疗代码的相似性，从而预测下一步治疗步骤。实验基于MIMIC-IV数据集的事件日志，结果表明，利用分类法中的领域知识可以显著提高预测准确性，并增强预测结果的可解释性，从而优化治疗规划和决策过程。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07638v2",
      "published_date": "2025-03-05 08:19:17 UTC",
      "updated_date": "2025-03-17 13:52:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:15:18.908972"
    },
    {
      "arxiv_id": "2503.03245v2",
      "title": "Less is more? Rewards in RL for Cyber Defence",
      "title_zh": "少即是多？强化学习在网络安全防御中的奖励机制",
      "authors": [
        "Elizabeth Bates",
        "Chris Hicks",
        "Vasilios Mavroudis"
      ],
      "abstract": "The last few years have seen an explosion of interest in autonomous cyber\ndefence agents based on deep reinforcement learning. Such agents are typically\ntrained in a cyber gym environment, also known as a cyber simulator, at least\n32 of which have already been built. Most, if not all cyber gyms provide dense\n\"scaffolded\" reward functions which combine many penalties or incentives for a\nrange of (un)desirable states and costly actions. Whilst dense rewards help\nalleviate the challenge of exploring complex environments, yielding seemingly\neffective strategies from relatively few environment steps; they are also known\nto bias the solutions an agent can find, potentially towards suboptimal\nsolutions. This is especially a problem in complex cyber environments where\npolicy weaknesses may not be noticed until exploited by an adversary. In this\nwork we set out to evaluate whether sparse reward functions might enable\ntraining more effective cyber defence agents. Towards this goal we first break\ndown several evaluation limitations in existing work by proposing a ground\ntruth evaluation score that goes beyond the standard RL paradigm used to train\nand evaluate agents. By adapting a well-established cyber gym to accommodate\nour methodology and ground truth score, we propose and evaluate two sparse\nreward mechanisms and compare them with a typical dense reward. Our evaluation\nconsiders a range of network sizes, from 2 to 50 nodes, and both reactive and\nproactive defensive actions. Our results show that sparse rewards, particularly\npositive reinforcement for an uncompromised network state, enable the training\nof more effective cyber defence agents. Furthermore, we show that sparse\nrewards provide more stable training than dense rewards, and that both\neffectiveness and training stability are robust to a variety of cyber\nenvironment considerations.",
      "tldr_zh": "该研究探讨了在网络安全防御中使用稀疏奖励函数是否比密集奖励函数更能训练出有效的深度强化学习(RL)代理。通过提出一种超越标准RL范式的评估方法，研究者在不同规模的网络环境中对比了两种稀疏奖励机制与典型密集奖励的效果。结果表明，稀疏奖励，特别是对未受攻击网络状态的积极强化，能够训练出更有效的防御代理，并提供更稳定的训练过程。这一发现为复杂网络环境中的自主防御策略优化提供了新的思路。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "4 Pages",
      "pdf_url": "http://arxiv.org/pdf/2503.03245v2",
      "published_date": "2025-03-05 07:53:39 UTC",
      "updated_date": "2025-03-10 15:51:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:16:07.173294"
    },
    {
      "arxiv_id": "2503.03238v1",
      "title": "FANS -- Formal Answer Selection for Natural Language Math Reasoning Using Lean4",
      "title_zh": "FANS：基于 Lean4 的自然语言数学推理形式化答案选择框架",
      "authors": [
        "Jiarui Yao",
        "Ruida Wang",
        "Tong Zhang"
      ],
      "abstract": "Large Language Models (LLMs) have displayed astonishing abilities in various\ntasks, especially in text generation, classification, question answering, etc.\nHowever, the reasoning ability of LLMs still faces many debates. The inherent\nambiguity of Natural Language (NL) limits LLMs' ability to perform verifiable\nreasoning, making its answers lack coherence and trustworthy support. To tackle\nthe above problems, we propose a novel framework named FANS: Formal ANswer\nSelection for Natural Language Math Reasoning Using Lean4. To the best of our\nknowledge, it is the first framework that utilizes Lean4 to enhance LLMs' NL\nmath reasoning ability. In particular, given an NL math question and\nLLM-generated answers, FANS first translates it into Lean4 theorem statements.\nThen it tries to prove it using a Lean4 prover and verify it by Lean4. Finally,\nit uses the FL result to assist in answer selection. It enhances LLMs' NL math\nability in providing a computer-verifiable solution for its correct answer and\nproposes an alternative method for answer selection beyond the reward model.\nExtensive experiments indicate the effectiveness of our framework. It can\nimprove the accuracy rate of reward model enhanced LLMs in the MATH-500 dataset\nby at most 1.91% and AMC-23 by at most 8.33% on strong reward-model baselines.\nIn some particular fields like number theory that Lean4 experts in, we can even\nselect all correct solutions. The qualitative analysis also shows our framework\ncan make NL results formally backed by Lean4 proofs. As a pioneering work in\nthe corresponding field, we will open-source all our models and datasets to\nfurther boost the development of the field.",
      "tldr_zh": "这篇论文提出了FANS框架，首次利用Lean4定理证明器来增强大语言模型(LLMs)的自然语言数学推理能力。该框架将数学问题转化为Lean4定理，通过形式化验证筛选LLM生成的答案，为正确答案提供计算机可验证的证明支持。实验表明，FANS在MATH-500和AMC-23数据集上分别最高提升1.91%和8.33%的准确率，尤其在数论领域能筛选出全部正确解。该研究开创性地将形式化方法引入自然语言数学推理，相关模型和数据集将开源以推动领域发展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03238v1",
      "published_date": "2025-03-05 07:34:53 UTC",
      "updated_date": "2025-03-05 07:34:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:16:24.393598"
    },
    {
      "arxiv_id": "2503.03791v1",
      "title": "Predicting Team Performance from Communications in Simulated Search-and-Rescue",
      "title_zh": "通过模拟搜救中的通信预测团队表现",
      "authors": [
        "Ali Jalal-Kamali",
        "Nikolos Gurney",
        "David Pynadath"
      ],
      "abstract": "Understanding how individual traits influence team performance is valuable,\nbut these traits are not always directly observable. Prior research has\ninferred traits like trust from behavioral data. We analyze conversational data\nto identify team traits and their correlation with teaming outcomes. Using\ntranscripts from a Minecraft-based search-and-rescue experiment, we apply topic\nmodeling and clustering to uncover key interaction patterns. Our findings show\nthat variations in teaming outcomes can be explained through these inferences,\nwith different levels of predictive power derived from individual traits and\nteam dynamics.",
      "tldr_zh": "该研究通过分析团队对话数据，预测模拟搜救任务中的团队表现。研究利用基于Minecraft的搜救实验中的对话记录，采用主题建模和聚类方法，识别关键互动模式。结果表明，团队表现的变化可以通过这些模式进行解释，其中个体特质和团队动态对预测能力的影响程度不同。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03791v1",
      "published_date": "2025-03-05 07:20:27 UTC",
      "updated_date": "2025-03-05 07:20:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:15:44.977010"
    },
    {
      "arxiv_id": "2503.03789v1",
      "title": "Positive-Unlabeled Diffusion Models for Preventing Sensitive Data Generation",
      "title_zh": "正样本-未标记扩散模型：防止敏感数据生成",
      "authors": [
        "Hiroshi Takahashi",
        "Tomoharu Iwata",
        "Atsutoshi Kumagai",
        "Yuuki Yamanaka",
        "Tomoya Yamashita"
      ],
      "abstract": "Diffusion models are powerful generative models but often generate sensitive\ndata that are unwanted by users, mainly because the unlabeled training data\nfrequently contain such sensitive data. Since labeling all sensitive data in\nthe large-scale unlabeled training data is impractical, we address this problem\nby using a small amount of labeled sensitive data. In this paper, we propose\npositive-unlabeled diffusion models, which prevent the generation of sensitive\ndata using unlabeled and sensitive data. Our approach can approximate the\nevidence lower bound (ELBO) for normal (negative) data using only unlabeled and\nsensitive (positive) data. Therefore, even without labeled normal data, we can\nmaximize the ELBO for normal data and minimize it for labeled sensitive data,\nensuring the generation of only normal data. Through experiments across various\ndatasets and settings, we demonstrated that our approach can prevent the\ngeneration of sensitive images without compromising image quality.",
      "tldr_zh": "本研究提出了一种基于正样本-未标记样本（Positive-Unlabeled）的扩散模型方法，旨在防止生成敏感数据。该方法利用少量标记的敏感数据和大量未标记数据，通过近似正常数据的证据下界（ELBO），在无需标记正常数据的情况下，最大化正常数据的ELBO并最小化敏感数据的ELBO，从而确保仅生成正常数据。实验表明，该方法能在不降低图像质量的前提下，有效阻止敏感图像的生成。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ICLR2025. Code is available at\n  https://github.com/takahashihiroshi/pudm",
      "pdf_url": "http://arxiv.org/pdf/2503.03789v1",
      "published_date": "2025-03-05 07:17:48 UTC",
      "updated_date": "2025-03-05 07:17:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:15:54.515696"
    },
    {
      "arxiv_id": "2503.04829v1",
      "title": "StickMotion: Generating 3D Human Motions by Drawing a Stickman",
      "title_zh": "StickMotion：通过绘制火柴人生成3D人体动作",
      "authors": [
        "Tao Wang",
        "Zhihua Wu",
        "Qiaozhi He",
        "Jiaming Chu",
        "Ling Qian",
        "Yu Cheng",
        "Junliang Xing",
        "Jian Zhao",
        "Lei Jin"
      ],
      "abstract": "Text-to-motion generation, which translates textual descriptions into human\nmotions, has been challenging in accurately capturing detailed user-imagined\nmotions from simple text inputs. This paper introduces StickMotion, an\nefficient diffusion-based network designed for multi-condition scenarios, which\ngenerates desired motions based on traditional text and our proposed stickman\nconditions for global and local control of these motions, respectively. We\naddress the challenges introduced by the user-friendly stickman from three\nperspectives: 1) Data generation. We develop an algorithm to generate\nhand-drawn stickmen automatically across different dataset formats. 2)\nMulti-condition fusion. We propose a multi-condition module that integrates\ninto the diffusion process and obtains outputs of all possible condition\ncombinations, reducing computational complexity and enhancing StickMotion's\nperformance compared to conventional approaches with the self-attention module.\n3) Dynamic supervision. We empower StickMotion to make minor adjustments to the\nstickman's position within the output sequences, generating more natural\nmovements through our proposed dynamic supervision strategy. Through\nquantitative experiments and user studies, sketching stickmen saves users about\n51.5% of their time generating motions consistent with their imagination. Our\ncodes, demos, and relevant data will be released to facilitate further research\nand validation within the scientific community.",
      "tldr_zh": "该研究提出了StickMotion，一种基于扩散模型的3D人体动作生成方法，通过绘制简笔画(stickman)实现动作的全局和局部控制。系统创新性地解决了三个关键问题：1)开发自动生成手绘简笔画数据的算法；2)设计多条件融合模块，优化传统自注意力机制；3)采用动态监督策略使动作更自然。实验表明，使用简笔画可节省用户51.5%的时间，更精准生成符合想象的动作。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages, 5 figures, accepted by CVPR2025",
      "pdf_url": "http://arxiv.org/pdf/2503.04829v1",
      "published_date": "2025-03-05 07:16:14 UTC",
      "updated_date": "2025-03-05 07:16:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:16:01.288758"
    },
    {
      "arxiv_id": "2503.04828v1",
      "title": "Beyond Next Word Prediction: Developing Comprehensive Evaluation Frameworks for measuring LLM performance on real world applications",
      "title_zh": "超越下一个词预测：构建衡量LLM在现实世界应用中性能的综合评估框架",
      "authors": [
        "Vishakha Agrawal",
        "Archie Chaudhury",
        "Shreya Agrawal"
      ],
      "abstract": "While Large Language Models (LLMs) are fundamentally next-token prediction\nsystems, their practical applications extend far beyond this basic function.\nFrom natural language processing and text generation to conversational\nassistants and software use, LLMs have numerous use-cases, and have already\nacquired a significant degree of enterprise adoption. To evaluate such models,\nstatic evaluation datasets, consisting of a set of prompts and their\ncorresponding ground truths, are often used to benchmark the efficacy of the\nmodel for a particular task. In this paper, we provide the basis for a more\ncomprehensive evaluation framework, based upon a traditional game and\ntool-based architecture that enables a more overarching measurement of a\nmodel's capabilities. For simplicity, we provide a generalized foundation that\ncan be extended, without significant alteration, to numerous scenarios, from\nspecific use cases such as supply chain management or financial reasoning, to\nabstract measurements such as ethics or safety.",
      "tldr_zh": "该研究提出了一种超越传统\"下一个词预测\"的大语言模型(LLMs)评估框架。针对LLMs在自然语言处理、文本生成、对话助手等实际应用中的广泛使用，研究者基于传统游戏和工具架构设计了一个更全面的评估体系。该框架提供了一个通用基础，可灵活扩展到供应链管理、金融推理等具体场景，以及伦理、安全等抽象维度的评估，为衡量LLMs在现实应用中的性能提供了更全面的方法。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04828v1",
      "published_date": "2025-03-05 06:44:38 UTC",
      "updated_date": "2025-03-05 06:44:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:16:39.612526"
    },
    {
      "arxiv_id": "2503.04827v1",
      "title": "Preserving Cultural Identity with Context-Aware Translation Through Multi-Agent AI Systems",
      "title_zh": "通过多智能体AI系统实现情境感知翻译以保护文化身份",
      "authors": [
        "Mahfuz Ahmed Anik",
        "Abdur Rahman",
        "Azmine Toushik Wasi",
        "Md Manjurul Ahsan"
      ],
      "abstract": "Language is a cornerstone of cultural identity, yet globalization and the\ndominance of major languages have placed nearly 3,000 languages at risk of\nextinction. Existing AI-driven translation models prioritize efficiency but\noften fail to capture cultural nuances, idiomatic expressions, and historical\nsignificance, leading to translations that marginalize linguistic diversity. To\naddress these challenges, we propose a multi-agent AI framework designed for\nculturally adaptive translation in underserved language communities. Our\napproach leverages specialized agents for translation, interpretation, content\nsynthesis, and bias evaluation, ensuring that linguistic accuracy and cultural\nrelevance are preserved. Using CrewAI and LangChain, our system enhances\ncontextual fidelity while mitigating biases through external validation.\nComparative analysis shows that our framework outperforms GPT-4o, producing\ncontextually rich and culturally embedded translations, a critical advancement\nfor Indigenous, regional, and low-resource languages. This research underscores\nthe potential of multi-agent AI in fostering equitable, sustainable, and\nculturally sensitive NLP technologies, aligning with the AI Governance,\nCultural NLP, and Sustainable NLP pillars of Language Models for Underserved\nCommunities. Our full experimental codebase is publicly available at:\nhttps://github.com/ciol-researchlab/Context-Aware_Translation_MAS",
      "tldr_zh": "该研究提出了一种基于多智能体AI系统的上下文感知翻译框架，旨在保护濒危语言的文化特性。通过整合翻译、解释、内容合成和偏见评估等专门化智能体，该系统在保持语言准确性的同时，显著提升了文化内涵的传递效果。实验表明，该框架在文化敏感翻译任务上优于GPT-4o，特别适用于原住民语言和低资源语言，为可持续、公平的NLP技术发展提供了新思路。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted in NAACL 2025 Workshop on Language Models for Underserved\n  Communities (https://openreview.net/forum?id=RiCfefEHII)",
      "pdf_url": "http://arxiv.org/pdf/2503.04827v1",
      "published_date": "2025-03-05 06:43:59 UTC",
      "updated_date": "2025-03-05 06:43:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:16:46.824602"
    },
    {
      "arxiv_id": "2503.03215v1",
      "title": "COSINT-Agent: A Knowledge-Driven Multimodal Agent for Chinese Open Source Intelligence",
      "title_zh": "COSINT-Agent：面向中文开源情报的知识驱动多模态智能体",
      "authors": [
        "Wentao Li",
        "Congcong Wang",
        "Xiaoxiao Cui",
        "Zhi Liu",
        "Wei Guo",
        "Lizhen Cui"
      ],
      "abstract": "Open Source Intelligence (OSINT) requires the integration and reasoning of\ndiverse multimodal data, presenting significant challenges in deriving\nactionable insights. Traditional approaches, including multimodal large\nlanguage models (MLLMs), often struggle to infer complex contextual\nrelationships or deliver comprehensive intelligence from unstructured data\nsources. In this paper, we introduce COSINT-Agent, a knowledge-driven\nmultimodal agent tailored to address the challenges of OSINT in the Chinese\ndomain. COSINT-Agent seamlessly integrates the perceptual capabilities of\nfine-tuned MLLMs with the structured reasoning power of the Entity-Event-Scene\nKnowledge Graph (EES-KG). Central to COSINT-Agent is the innovative EES-Match\nframework, which bridges COSINT-MLLM and EES-KG, enabling systematic\nextraction, reasoning, and contextualization of multimodal insights. This\nintegration facilitates precise entity recognition, event interpretation, and\ncontext retrieval, effectively transforming raw multimodal data into actionable\nintelligence. Extensive experiments validate the superior performance of\nCOSINT-Agent across core OSINT tasks, including entity recognition, EES\ngeneration, and context matching. These results underscore its potential as a\nrobust and scalable solution for advancing automated multimodal reasoning and\nenhancing the effectiveness of OSINT methodologies.",
      "tldr_zh": "本文提出了COSINT-Agent，一种面向中文开源情报(OSINT)的知识驱动多模态智能体，旨在解决多模态数据整合与推理的挑战。该智能体通过创新的EES-Match框架，将微调的多模态大语言模型(MLLMs)与实体-事件-场景知识图谱(EES-KG)相结合，实现了多模态数据的系统性提取、推理和情境化。实验表明，COSINT-Agent在实体识别、EES生成和上下文匹配等核心OSINT任务中表现优异，为自动化多模态推理和OSINT方法提供了高效且可扩展的解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03215v1",
      "published_date": "2025-03-05 06:16:15 UTC",
      "updated_date": "2025-03-05 06:16:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:16:54.315269"
    },
    {
      "arxiv_id": "2503.03211v1",
      "title": "NodeReg: Mitigating the Imbalance and Distribution Shift Effects in Semi-Supervised Node Classification via Norm Consistency",
      "title_zh": "NodeReg：通过范数一致性缓解半监督节点分类中的不平衡与分布偏移影响",
      "authors": [
        "Shenzhi Yang",
        "Jun Xia",
        "Jingbo Zhou",
        "Xingkai Yao",
        "Xiaofang Zhang"
      ],
      "abstract": "Aggregating information from neighboring nodes benefits graph neural networks\n(GNNs) in semi-supervised node classification tasks. Nevertheless, this\nmechanism also renders nodes susceptible to the influence of their neighbors.\nFor instance, this will occur when the neighboring nodes are imbalanced or the\nneighboring nodes contain noise, which can even affect the GNN's ability to\ngeneralize out of distribution. We find that ensuring the consistency of the\nnorm for node representations can significantly reduce the impact of these two\nissues on GNNs. To this end, we propose a regularized optimization method\ncalled NodeReg that enforces the consistency of node representation norms. This\nmethod is simple but effective and satisfies Lipschitz continuity, thus\nfacilitating stable optimization and significantly improving semi-supervised\nnode classification performance under the above two scenarios. To illustrate,\nin the imbalance scenario, when training a GCN with an imbalance ratio of 0.1,\nNodeReg outperforms the most competitive baselines by 1.4%-25.9% in F1 score\nacross five public datasets. Similarly, in the distribution shift scenario,\nNodeReg outperforms the most competitive baseline by 1.4%-3.1% in accuracy.",
      "tldr_zh": "该研究提出了NodeReg，一种通过规范一致性来缓解半监督节点分类中类别不平衡和分布偏移影响的正则化优化方法。NodeReg通过强制节点表示范数的一致性，显著减少了邻居节点不平衡和噪声对图神经网络(GNNs)的负面影响，同时满足Lipschitz连续性，确保了优化的稳定性。实验表明，在类别不平衡和分布偏移场景下，NodeReg在五个公开数据集上的F1分数和准确率均优于现有基线方法，分别提升了1.4%-25.9%和1.4%-3.1%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03211v1",
      "published_date": "2025-03-05 06:06:16 UTC",
      "updated_date": "2025-03-05 06:06:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:17:07.120285"
    },
    {
      "arxiv_id": "2503.03205v2",
      "title": "MA-LoT: Multi-Agent Lean-based Long Chain-of-Thought Reasoning enhances Formal Theorem Proving",
      "title_zh": "MA-LoT：基于多智能体精益长链式思维推理增强形式化定理证明",
      "authors": [
        "Ruida Wang",
        "Rui Pan",
        "Yuxin Li",
        "Jipeng Zhang",
        "Yizhen Jia",
        "Shizhe Diao",
        "Renjie Pi",
        "Junjie Hu",
        "Tong Zhang"
      ],
      "abstract": "Solving mathematical problems using computer-verifiable languages like Lean\nhas significantly impacted mathematical and computer science communities.\nState-of-the-art methods utilize single Large Language Models (LLMs) as agents\nor provers to either generate complete proof or perform tree searches. However,\nsingle-agent methods inherently lack a structured way to combine high-level\nreasoning in Natural Language (NL) with Formal Language (FL) verification\nfeedback. To solve these issues, we propose MA-LoT: Multi-Agent Lean-based Long\nChain-of-Thought framework, (to the best of our knowledge), the first\nmulti-agent framework for Lean4 theorem proving that balance high-level NL\nreasoning and FL verification in Long CoT. Using this structured interaction,\nour approach enables deeper insights and long-term coherence in proof\ngeneration, with which past methods struggle. We do this by leveraging emergent\nformal reasoning ability in Long CoT using our novel LoT-Transfer Learning\ntraining-inference pipeline. Extensive experiments show that our framework\nachieves a 61.07% accuracy rate on the Lean4 version of the MiniF2F-Test\ndataset, largely outperforming GPT-4 (22.95%), single-agent tree search\n(InternLM-Step-Prover, 50.70%), and whole-proof generation (Godel-Prover,\n55.33%) baselines. Furthermore, our findings highlight the potential of\ncombining Long CoT with formal verification for a more insightful generation in\na broader perspective.",
      "tldr_zh": "本文提出MA-LoT框架，首个基于Lean4定理证明的多智能体系统，通过长链思维推理(Long CoT)平衡自然语言推理与形式语言验证。该框架采用创新的LoT-Transfer Learning训练推理流程，在MiniF2F-Test数据集上达到61.07%准确率，显著优于GPT-4（22.95%）等基线方法。研究表明，长链思维与形式验证的结合能产生更具洞察力的证明生成，为数学自动推理开辟了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03205v2",
      "published_date": "2025-03-05 05:50:31 UTC",
      "updated_date": "2025-03-10 17:39:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:17:25.619701"
    },
    {
      "arxiv_id": "2503.03201v1",
      "title": "Towards Robust Universal Information Extraction: Benchmark, Evaluation, and Solution",
      "title_zh": "迈向稳健的通用信息抽取：基准、评估与解决方案",
      "authors": [
        "Jizhao Zhu",
        "Akang Shi",
        "Zixuan Li",
        "Long Bai",
        "Xiaolong Jin",
        "Jiafeng Guo",
        "Xueqi Cheng"
      ],
      "abstract": "In this paper, we aim to enhance the robustness of Universal Information\nExtraction (UIE) by introducing a new benchmark dataset, a comprehensive\nevaluation, and a feasible solution. Existing robust benchmark datasets have\ntwo key limitations: 1) They generate only a limited range of perturbations for\na single Information Extraction (IE) task, which fails to evaluate the\nrobustness of UIE models effectively; 2) They rely on small models or\nhandcrafted rules to generate perturbations, often resulting in unnatural\nadversarial examples. Considering the powerful generation capabilities of Large\nLanguage Models (LLMs), we introduce a new benchmark dataset for Robust UIE,\ncalled RUIE-Bench, which utilizes LLMs to generate more diverse and realistic\nperturbations across different IE tasks. Based on this dataset, we\ncomprehensively evaluate existing UIE models and reveal that both LLM-based\nmodels and other models suffer from significant performance drops. To improve\nrobustness and reduce training costs, we propose a data-augmentation solution\nthat dynamically selects hard samples for iterative training based on the\nmodel's inference loss. Experimental results show that training with only\n\\textbf{15\\%} of the data leads to an average \\textbf{7.5\\%} relative\nperformance improvement across three IE tasks.",
      "tldr_zh": "该研究提出了增强通用信息抽取(UIE)模型鲁棒性的新方法，包括建立RUIE-Bench基准数据集、全面评估现有模型以及提出数据增强解决方案。针对现有基准的局限性，研究利用大语言模型(LLMs)生成更丰富和真实的扰动数据，覆盖多种信息抽取任务。评估发现现有UIE模型(包括LLM-based模型)面对扰动时性能显著下降。为此提出的动态选择困难样本进行迭代训练的数据增强方法，仅需15%训练数据就能在三个IE任务上实现平均7.5%的相对性能提升。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03201v1",
      "published_date": "2025-03-05 05:39:29 UTC",
      "updated_date": "2025-03-05 05:39:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:17:23.655860"
    },
    {
      "arxiv_id": "2503.16477v1",
      "title": "LeRAAT: LLM-Enabled Real-Time Aviation Advisory Tool",
      "title_zh": "LeRAAT：基于大语言模型的实时航空咨询工具",
      "authors": [
        "Marc R. Schlichting",
        "Vale Rasmussen",
        "Heba Alazzeh",
        "Houjun Liu",
        "Kiana Jafari",
        "Amelia F. Hardy",
        "Dylan M. Asmar",
        "Mykel J. Kochenderfer"
      ],
      "abstract": "In aviation emergencies, high-stakes decisions must be made in an instant.\nPilots rely on quick access to precise, context-specific information -- an area\nwhere emerging tools like large language models (LLMs) show promise in\nproviding critical support. This paper introduces LeRAAT, a framework that\nintegrates LLMs with the X-Plane flight simulator to deliver real-time,\ncontext-aware pilot assistance. The system uses live flight data, weather\nconditions, and aircraft documentation to generate recommendations aligned with\naviation best practices and tailored to the particular situation. It employs a\nRetrieval-Augmented Generation (RAG) pipeline that extracts and synthesizes\ninformation from aircraft type-specific manuals, including performance\nspecifications and emergency procedures, as well as aviation regulatory\nmaterials, such as FAA directives and standard operating procedures. We\nshowcase the framework in both a virtual reality and traditional on-screen\nsimulation, supporting a wide range of research applications such as pilot\ntraining, human factors research, and operational decision support.",
      "tldr_zh": "该研究提出了LeRAAT框架，一种基于大语言模型(LLM)的实时航空咨询工具。系统通过整合X-Plane飞行模拟器的实时飞行数据、天气条件和飞机文档，采用检索增强生成(RAG)技术从特定机型手册和FAA法规中提取信息，生成符合航空最佳实践的个性化建议。该工具支持VR和传统屏幕模拟，可应用于飞行员培训、人因研究及飞行决策支持等场景。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.ET",
        "cs.IR",
        "J.2; H.3.3; H.5.0"
      ],
      "primary_category": "cs.HC",
      "comment": "4 pages, 3 figures, code: https://github.com/sisl/LeRAAT/ , demo\n  video: https://youtu.be/NnijQAlTo-U",
      "pdf_url": "http://arxiv.org/pdf/2503.16477v1",
      "published_date": "2025-03-05 05:34:15 UTC",
      "updated_date": "2025-03-05 05:34:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:17:26.075521"
    },
    {
      "arxiv_id": "2503.03197v1",
      "title": "Directly Follows Graphs Go Predictive Process Monitoring With Graph Neural Networks",
      "title_zh": "直接跟随图实现基于图神经网络的预测性流程监控",
      "authors": [
        "Attila Lischka",
        "Simon Rauch",
        "Oliver Stritzel"
      ],
      "abstract": "In the past years, predictive process monitoring (PPM) techniques based on\nartificial neural networks have evolved as a method to monitor the future\nbehavior of business processes. Existing approaches mostly focus on\ninterpreting the processes as sequences, so-called traces, and feeding them to\nneural architectures designed to operate on sequential data such as recurrent\nneural networks (RNNs) or transformers. In this study, we investigate an\nalternative way to perform PPM: by transforming each process in its\ndirectly-follows-graph (DFG) representation we are able to apply graph neural\nnetworks (GNNs) for the prediction tasks. By this, we aim to develop models\nthat are more suitable for complex processes that are long and contain an\nabundance of loops. In particular, we present different ways to create DFG\nrepresentations depending on the particular GNN we use. The tested GNNs range\nfrom classical node-based to novel edge-based architectures. Further, we\ninvestigate the possibility of using multi-graphs. By these steps, we aim to\ndesign graph representations that minimize the information loss when\ntransforming traces into graphs.",
      "tldr_zh": "本研究提出了一种基于图神经网络(GNN)的预测性流程监控(PPM)方法，通过将业务流程转化为直接跟随图(DFG)表示，利用GNN进行预测任务。与传统的基于序列的RNN或Transformer方法不同，该方法更适合处理包含大量循环的复杂流程。研究探讨了多种DFG表示方法，包括基于节点和基于边的GNN架构，并研究了多图的使用，旨在最小化从序列到图转换过程中的信息损失。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 4 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.03197v1",
      "published_date": "2025-03-05 05:30:26 UTC",
      "updated_date": "2025-03-05 05:30:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:17:34.311649"
    },
    {
      "arxiv_id": "2503.03787v1",
      "title": "Sarcasm Detection as a Catalyst: Improving Stance Detection with Cross-Target Capabilities",
      "title_zh": "讽刺检测作为催化剂：通过跨目标能力提升立场检测",
      "authors": [
        "Gibson Nkhata Shi Yin Hong",
        "Susan Gauch"
      ],
      "abstract": "Stance Detection (SD) has become a critical area of interest due to its\napplications in various contexts leading to increased research within NLP. Yet\nthe subtlety and complexity of texts sourced from online platforms often\ncontaining sarcastic language pose significant challenges for SD algorithms in\naccurately determining the authors stance. This paper addresses this by\nemploying sarcasm for SD. It also tackles the issue of insufficient annotated\ndata for training SD models on new targets by conducting Cross-Target SD\n(CTSD). The proposed approach involves fine-tuning BERT and RoBERTa models\nfollowed by concatenating additional deep learning layers. The approach is\nassessed against various State-Of-The-Art baselines for SD demonstrating\nsuperior performance using publicly available datasets. Notably our model\noutperforms the best SOTA models on both in-domain SD and CTSD tasks even\nbefore the incorporation of sarcasm-detection pre-training. The integration of\nsarcasm knowledge into the model significantly reduces misclassifications of\nsarcastic text elements in SD allowing our model to accurately predict 85% of\ntexts that were previously misclassified without sarcasm-detection pre-training\non in-domain SD. This enhancement contributes to an increase in the models\naverage macro F1-score. The CTSD task achieves performance comparable to that\nof the in-domain task despite using a zero-shot finetuning. We also reveal that\nthe success of the transfer-learning framework relies on the correlation\nbetween the lexical attributes of sarcasm detection and SD. This study\nrepresents the first exploration of sarcasm detection as an intermediate\ntransfer-learning task within the context of SD while also leveraging the\nconcatenation of BERT or RoBERTa with other deep-learning techniques. The\nproposed approach establishes a foundational baseline for future research in\nthis domain.",
      "tldr_zh": "本研究提出了一种利用讽刺检测(sarcasm detection)提升立场检测(Stance Detection, SD)性能的新方法，同时解决了跨目标立场检测(Cross-Target SD, CTSD)中标注数据不足的问题。通过微调BERT和RoBERTa模型并结合额外的深度学习层，该方法在公开数据集上显著优于现有最先进的SD模型。研究首次将讽刺检测作为SD的中间迁移学习任务，实验表明，讽刺知识的引入减少了85%的讽刺文本误分类，提升了模型的平均宏F1分数。此外，CTSD任务在零样本微调下达到了与域内任务相当的性能，揭示了讽刺检测与SD在词汇特征上的相关性。该研究为未来相关领域的研究奠定了基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "2 pages, 5 figures, published, published in International Journal On\n  Advances in Intelligent Systems, volume 17, numbers 3 and 4. arXiv admin\n  note: text overlap with arXiv:2503.03172",
      "pdf_url": "http://arxiv.org/pdf/2503.03787v1",
      "published_date": "2025-03-05 05:27:16 UTC",
      "updated_date": "2025-03-05 05:27:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:17:43.794234"
    },
    {
      "arxiv_id": "2503.03194v1",
      "title": "Structured Outputs Enable General-Purpose LLMs to be Medical Experts",
      "title_zh": "结构化输出使通用大语言模型成为医疗专家",
      "authors": [
        "Guangfu Guo",
        "Kai Zhang",
        "Bryan Hoo",
        "Yujun Cai",
        "Xiaoqian Lu",
        "Nanyun Peng",
        "Yiwei Wang"
      ],
      "abstract": "Medical question-answering (QA) is a critical task for evaluating how\neffectively large language models (LLMs) encode clinical knowledge and\nassessing their potential applications in medicine. Despite showing promise on\nmultiple-choice tests, LLMs frequently struggle with open-ended medical\nquestions, producing responses with dangerous hallucinations or lacking\ncomprehensive coverage of critical aspects. Existing approaches attempt to\naddress these challenges through domain-specific fine-tuning, but this proves\nresource-intensive and difficult to scale across models. To improve the\ncomprehensiveness and factuality of medical responses, we propose a novel\napproach utilizing structured medical reasoning. Our method guides LLMs through\nan seven-step cognitive process inspired by clinical diagnosis, enabling more\naccurate and complete answers without additional training. Experiments on the\nMedLFQA benchmark demonstrate that our approach achieves the highest Factuality\nScore of 85.8, surpassing fine-tuned models. Notably, this improvement\ntransfers to smaller models, highlighting the method's efficiency and\nscalability. Our code and datasets are available.",
      "tldr_zh": "该研究提出了一种结构化医学推理方法，通过引导通用大语言模型(LLMs)遵循七步临床诊断认知流程，显著提升了医疗问答的准确性和完整性。相比需要领域微调的传统方法，这种无需额外训练的新方法在MedLFQA基准测试中获得85.8的事实性评分，超越了专业微调模型。研究特别表明，该方法能有效迁移至较小模型，展现了出色的效率和可扩展性，为LLMs在医疗领域的可靠应用提供了新思路。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03194v1",
      "published_date": "2025-03-05 05:24:55 UTC",
      "updated_date": "2025-03-05 05:24:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:17:58.167725"
    },
    {
      "arxiv_id": "2503.04824v1",
      "title": "ProReflow: Progressive Reflow with Decomposed Velocity",
      "title_zh": "ProReflow：基于分解速度的渐进式回流方法",
      "authors": [
        "Lei Ke",
        "Haohang Xu",
        "Xuefei Ning",
        "Yu Li",
        "Jiajun Li",
        "Haoling Li",
        "Yuxuan Lin",
        "Dongsheng Jiang",
        "Yujiu Yang",
        "Linfeng Zhang"
      ],
      "abstract": "Diffusion models have achieved significant progress in both image and video\ngeneration while still suffering from huge computation costs. As an effective\nsolution, flow matching aims to reflow the diffusion process of diffusion\nmodels into a straight line for a few-step and even one-step generation.\nHowever, in this paper, we suggest that the original training pipeline of flow\nmatching is not optimal and introduce two techniques to improve it. Firstly, we\nintroduce progressive reflow, which progressively reflows the diffusion models\nin local timesteps until the whole diffusion progresses, reducing the\ndifficulty of flow matching. Second, we introduce aligned v-prediction, which\nhighlights the importance of direction matching in flow matching over magnitude\nmatching. Experimental results on SDv1.5 and SDXL demonstrate the effectiveness\nof our method, for example, conducting on SDv1.5 achieves an FID of 10.70 on\nMSCOCO2014 validation set with only 4 sampling steps, close to our teacher\nmodel (32 DDIM steps, FID = 10.05).",
      "tldr_zh": "本研究提出了ProReflow，通过两种技术改进流匹配(flow matching)的训练流程，以优化扩散模型的高效生成。首先，引入渐进式回流(progressive reflow)，在局部时间步上逐步优化扩散过程，降低流匹配的难度；其次，提出对齐的v预测(aligned v-prediction)，强调方向匹配的重要性。实验表明，该方法在SDv1.5和SDXL模型上显著提升了生成效率，例如在MSCOCO2014验证集上仅需4步采样即可达到接近教师模型（32步DDIM）的FID性能（10.70 vs. 10.05）。",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.GR",
      "comment": "Our codes will be released at Github",
      "pdf_url": "http://arxiv.org/pdf/2503.04824v1",
      "published_date": "2025-03-05 04:50:53 UTC",
      "updated_date": "2025-03-05 04:50:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:18:14.144289"
    },
    {
      "arxiv_id": "2503.05820v1",
      "title": "The impact of AI and peer feedback on research writing skills: a study using the CGScholar platform among Kazakhstani scholars",
      "title_zh": "AI与同行反馈对研究写作技能的影响：基于CGScholar平台在哈萨克斯坦学者中的研究",
      "authors": [
        "Raigul Zheldibayeva"
      ],
      "abstract": "This research studies the impact of AI and peer feedback on the academic\nwriting development of Kazakhstani scholars using the CGScholar platform - a\nproduct of research into collaborative learning, big data, and artificial\nintelligence developed by educators and computer scientists at the University\nof Illinois at Urbana-Champaign (UIUC). The study aimed to find out how\nfamiliarity with AI tools and peer feedback processes impacts participants'\nopenness to incorporating feedback into their academic writing. The study\ninvolved 36 scholars enrolled in a scientific internship focused on education\nat UIUC. A survey with 15 multiple-choice questions, a Likert scale, and\nopen-ended questions was used to collect data. The survey was conducted via\nGoogle Forms in both English and Russian to ensure linguistic accessibility.\nDemographic information such as age, gender, and first language was collected\nto provide a detailed understanding of the data. The analysis revealed a\nmoderate positive correlation between familiarity with AI tools and openness to\nmaking changes based on feedback, and a strong positive correlation between\nresearch writing experience and expectations of peer feedback, especially in\nthe area of research methodology. These results show that participants are\nopen-minded to AI-assisted feedback; however, they still highly appreciate peer\ninput, especially regarding methodological guidance. This study demonstrates\nthe potential benefits of integrating AI tools with traditional feedback\nmechanisms to improve research writing quality in academic settings.",
      "tldr_zh": "这项研究探讨了AI工具和同行反馈对哈萨克斯坦学者学术写作能力的影响。通过CGScholar平台对36名参与伊利诺伊大学教育科研实习的学者进行调查，发现AI工具熟悉度与反馈接受度呈中度正相关，而研究方法论领域的同行反馈尤其受到重视。研究表明，尽管学者们对AI辅助反馈持开放态度，但仍高度依赖同行在方法论方面的指导，证实了结合AI与传统反馈机制对提升学术写作质量的有效性。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "11 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.05820v1",
      "published_date": "2025-03-05 04:34:25 UTC",
      "updated_date": "2025-03-05 04:34:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:18:29.226538"
    },
    {
      "arxiv_id": "2503.03172v1",
      "title": "Intermediate-Task Transfer Learning: Leveraging Sarcasm Detection for Stance Detection",
      "title_zh": "中级任务迁移学习：利用讽刺检测增强立场检测",
      "authors": [
        "Gibson Nkhata",
        "Susan Gauch"
      ],
      "abstract": "Stance Detection (SD) on social media has emerged as a prominent area of\ninterest with implications for social business and political applications\nthereby garnering escalating research attention within NLP. The inherent\nsubtlety and complexity of texts procured from online platforms pose challenges\nfor SD algorithms in accurately discerning the authors stance. Mostly the\ninclusion of sarcastic and figurative language drastically impacts the\nperformance of SD models. This paper addresses this by employing sarcasm\ndetection intermediate-task transfer learning tailored for SD. The proposed\nmethodology involves the finetuning of BERT and RoBERTa and the concatenation\nof convolutional BiLSTM and dense layers. Rigorous experiments are conducted on\npublicly available datasets to evaluate our transfer-learning framework. The\nperformance of the approach is assessed against various State-Of-The-Art\nbaselines for SD providing empirical evidence of its effectiveness. Notably our\nmodel outperforms the best SOTA models even prior to sarcasm-detection\npretraining. The integration of sarcasm knowledge into the model proves\ninstrumental in mitigating misclassifications of sarcastic textual elements in\nSD. Our model accurately predicts 85% of texts that were previously\nmisclassified by the model without sarcasm-detection pretraining thereby\namplifying the average F1-score of the model. Our experiments also revealed\nthat the success of the transfer-learning framework is contingent upon the\ncorrelation of lexical attributes between the intermediate task and the target\ntask. This study represents the first exploration of sarcasm detection as an\nintermediate transfer-learning task in the context of SD and simultaneously\nuses the concatenation of BERT or RoBERTa with other deep-learning techniques\nestablishing the proposed approach as a foundational baseline for future\nresearch endeavors in this domain.",
      "tldr_zh": "该研究提出了一种基于讽刺检测的中间任务迁移学习方法，用于提升社交媒体立场检测(Stance Detection)任务的性能。通过微调BERT和RoBERTa模型，并结合卷积BiLSTM与密集层的混合架构，该模型能够有效处理文本中的讽刺和比喻性语言。实验表明，该方法在公开数据集上超越了现有最佳模型，即使不进行讽刺检测预训练也表现优异，最终将原本被错误分类的讽刺文本预测准确率提升至85%，平均F1值显著提高。研究首次验证了讽刺检测作为中间迁移学习任务的有效性，并揭示了任务间词汇特征相关性的重要性，为未来立场检测研究提供了新基准。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 2 figures, published in The Sixteenth International\n  Conference on Information (eKNOW 2024)",
      "pdf_url": "http://arxiv.org/pdf/2503.03172v1",
      "published_date": "2025-03-05 04:30:53 UTC",
      "updated_date": "2025-03-05 04:30:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:19:15.922445"
    },
    {
      "arxiv_id": "2503.03170v1",
      "title": "AttackSeqBench: Benchmarking Large Language Models' Understanding of Sequential Patterns in Cyber Attacks",
      "title_zh": "AttackSeqBench：评估大语言模型对网络攻击中序列模式理解能力的基准",
      "authors": [
        "Javier Yong",
        "Haokai Ma",
        "Yunshan Ma",
        "Anis Yusof",
        "Zhenkai Liang",
        "Ee-Chien Chang"
      ],
      "abstract": "The observations documented in Cyber Threat Intelligence (CTI) reports play a\ncritical role in describing adversarial behaviors, providing valuable insights\nfor security practitioners to respond to evolving threats. Recent advancements\nof Large Language Models (LLMs) have demonstrated significant potential in\nvarious cybersecurity applications, including CTI report understanding and\nattack knowledge graph construction. While previous works have proposed\nbenchmarks that focus on the CTI extraction ability of LLMs, the sequential\ncharacteristic of adversarial behaviors within CTI reports remains largely\nunexplored, which holds considerable significance in developing a comprehensive\nunderstanding of how adversaries operate. To address this gap, we introduce\nAttackSeqBench, a benchmark tailored to systematically evaluate LLMs'\ncapability to understand and reason attack sequences in CTI reports. Our\nbenchmark encompasses three distinct Question Answering (QA) tasks, each task\nfocuses on the varying granularity in adversarial behavior. To alleviate the\nlaborious effort of QA construction, we carefully design an automated dataset\nconstruction pipeline to create scalable and well-formulated QA datasets based\non real-world CTI reports. To ensure the quality of our dataset, we adopt a\nhybrid approach of combining human evaluation and systematic evaluation\nmetrics. We conduct extensive experiments and analysis with both fast-thinking\nand slow-thinking LLMs, while highlighting their strengths and limitations in\nanalyzing the sequential patterns in cyber attacks. The overarching goal of\nthis work is to provide a benchmark that advances LLM-driven CTI report\nunderstanding and fosters its application in real-world cybersecurity\noperations. Our dataset and code are available at\nhttps://github.com/Javiery3889/AttackSeqBench .",
      "tldr_zh": "该研究提出了AttackSeqBench，一个专门用于评估大语言模型(LLMs)在理解网络攻击序列模式方面能力的基准测试。该基准包含三种不同粒度的问答任务，旨在系统评估LLMs对网络威胁情报(CTI)报告中攻击序列的理解和推理能力。研究团队设计了一个自动化数据集构建流程，基于真实CTI报告生成可扩展且结构化的问答数据集，并通过人工评估与系统化指标相结合的方式确保数据质量。实验分析揭示了快速思维与慢速思维LLMs在分析网络攻击序列模式时的优势与局限，为LLMs驱动的CTI报告理解及其在真实网络安全操作中的应用提供了重要基准。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03170v1",
      "published_date": "2025-03-05 04:25:21 UTC",
      "updated_date": "2025-03-05 04:25:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:18:40.506753"
    },
    {
      "arxiv_id": "2503.03156v2",
      "title": "DiRe-JAX: A JAX based Dimensionality Reduction Algorithm for Large-scale Data",
      "title_zh": "DiRe-JAX：基于JAX框架的大规模数据降维算法",
      "authors": [
        "Alexander Kolpakov",
        "Igor Rivin"
      ],
      "abstract": "DiRe - JAX is a new dimensionality reduction toolkit designed to address some\nof the challenges faced by traditional methods like UMAP and tSNE such as loss\nof global structure and computational efficiency. Built on the JAX framework,\nDiRe leverages modern hardware acceleration to provide an efficient, scalable,\nand interpretable solution for visualizing complex data structures, and for\nquantitative analysis of lower-dimensional embeddings. The toolkit shows\nconsiderable promise in preserving both local and global structures within the\ndata as compared to state-of-the-art UMAP and tSNE implementations. This makes\nit suitable for a wide range of applications in machine learning,\nbio-informatics, and data science.",
      "tldr_zh": "该研究提出了DiRe-JAX，一个基于JAX框架的新型降维工具包，旨在解决UMAP和t-SNE等传统方法在全局结构保留和计算效率方面的不足。该工具利用硬件加速技术，实现了高效、可扩展的数据降维方案，在保持数据局部和全局结构方面优于现有方法。实验表明，DiRe-JAX在机器学习、生物信息学等领域具有广泛应用潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MS",
        "H.1.1; G.4"
      ],
      "primary_category": "cs.LG",
      "comment": "22 pages, 12 figures Github repository available at\n  https://github.com/sashakolpakov/dire-jax Package available on PyPi\n  https://pypi.org/project/dire-jax/",
      "pdf_url": "http://arxiv.org/pdf/2503.03156v2",
      "published_date": "2025-03-05 03:56:01 UTC",
      "updated_date": "2025-03-06 04:40:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:18:49.435556"
    },
    {
      "arxiv_id": "2503.03150v2",
      "title": "Position: Model Collapse Does Not Mean What You Think",
      "title_zh": "观点：模型崩溃并非你所想的那样",
      "authors": [
        "Rylan Schaeffer",
        "Joshua Kazdan",
        "Alvan Caleb Arulandu",
        "Sanmi Koyejo"
      ],
      "abstract": "The proliferation of AI-generated content online has fueled concerns over\n\\emph{model collapse}, a degradation in future generative models' performance\nwhen trained on synthetic data generated by earlier models. Industry leaders,\npremier research journals and popular science publications alike have\nprophesied catastrophic societal consequences stemming from model collapse. In\nthis position piece, we contend this widespread narrative fundamentally\nmisunderstands the scientific evidence. We highlight that research on model\ncollapse actually encompasses eight distinct and at times conflicting\ndefinitions of model collapse, and argue that inconsistent terminology within\nand between papers has hindered building a comprehensive understanding of model\ncollapse. To assess how significantly different interpretations of model\ncollapse threaten future generative models, we posit what we believe are\nrealistic conditions for studying model collapse and then conduct a rigorous\nassessment of the literature's methodologies through this lens. While we leave\nroom for reasonable disagreement, our analysis of research studies, weighted by\nhow faithfully each study matches real-world conditions, leads us to conclude\nthat certain predicted claims of model collapse rely on assumptions and\nconditions that poorly match real-world conditions, and in fact several\nprominent collapse scenarios are readily avoidable. Altogether, this position\npaper argues that model collapse has been warped from a nuanced multifaceted\nconsideration into an oversimplified threat, and that the evidence suggests\nspecific harms more likely under society's current trajectory have received\ndisproportionately less attention.",
      "tldr_zh": "本文质疑了当前关于“模型崩溃”（model collapse）的普遍担忧，指出这一概念在研究中存在八种不同且有时相互矛盾的定义，术语的不一致性阻碍了对模型崩溃的全面理解。通过提出更符合现实条件的研究框架，作者对现有文献方法进行了严格评估，发现许多关于模型崩溃的预测基于与现实不符的假设，且某些崩溃场景实际上可以避免。本文认为，模型崩溃已被过度简化为一种威胁，而当前社会更可能面临的特定风险却未得到足够重视。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03150v2",
      "published_date": "2025-03-05 03:47:17 UTC",
      "updated_date": "2025-03-18 03:48:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:18:56.771601"
    },
    {
      "arxiv_id": "2503.03148v1",
      "title": "Partial Convolution Meets Visual Attention",
      "title_zh": "部分卷积与视觉注意力的融合",
      "authors": [
        "Haiduo Huang",
        "Fuwei Yang",
        "Dong Li",
        "Ji Liu",
        "Lu Tian",
        "Jinzhang Peng",
        "Pengju Ren",
        "Emad Barsoum"
      ],
      "abstract": "Designing an efficient and effective neural network has remained a prominent\ntopic in computer vision research. Depthwise onvolution (DWConv) is widely used\nin efficient CNNs or ViTs, but it needs frequent memory access during\ninference, which leads to low throughput. FasterNet attempts to introduce\npartial convolution (PConv) as an alternative to DWConv but compromises the\naccuracy due to underutilized channels. To remedy this shortcoming and consider\nthe redundancy between feature map channels, we introduce a novel Partial\nvisual ATtention mechanism (PAT) that can efficiently combine PConv with visual\nattention. Our exploration indicates that the partial attention mechanism can\ncompletely replace the full attention mechanism and reduce model parameters and\nFLOPs. Our PAT can derive three types of blocks: Partial Channel-Attention\nblock (PAT_ch), Partial Spatial-Attention block (PAT_sp) and Partial\nSelf-Attention block (PAT_sf). First, PAT_ch integrates the enhanced Gaussian\nchannel attention mechanism to infuse global distribution information into the\nuntouched channels of PConv. Second, we introduce the spatial-wise attention to\nthe MLP layer to further improve model accuracy. Finally, we replace PAT_ch in\nthe last stage with the self-attention mechanism to extend the global receptive\nfield. Building upon PAT, we propose a novel hybrid network family, named\nPATNet, which achieves superior top-1 accuracy and inference speed compared to\nFasterNet on ImageNet-1K classification and excel in both detection and\nsegmentation on the COCO dataset. Particularly, our PATNet-T2 achieves 1.3%\nhigher accuracy than FasterNet-T2, while exhibiting 25% higher GPU throughput\nand 24% lower CPU latency.",
      "tldr_zh": "该研究提出了一种结合部分卷积(PConv)与视觉注意力的新型Partial visual ATtention机制(PAT)，以解决深度可分离卷积(DWConv)在推理时内存访问频繁导致的低吞吐量问题。PAT通过增强的高斯通道注意力机制和空间注意力机制，有效提升了模型精度，同时降低了参数量和计算量。基于PAT，研究者构建了PATNet系列网络，在ImageNet-1K分类任务上不仅超越了FasterNet的Top-1准确率，还显著提升了GPU吞吐量和降低了CPU延迟，并在COCO数据集的目标检测和分割任务中表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2502.01303",
      "pdf_url": "http://arxiv.org/pdf/2503.03148v1",
      "published_date": "2025-03-05 03:42:59 UTC",
      "updated_date": "2025-03-05 03:42:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:18:59.993286"
    },
    {
      "arxiv_id": "2503.04823v2",
      "title": "DA-STGCN: 4D Trajectory Prediction Based on Spatiotemporal Feature Extraction",
      "title_zh": "DA-STGCN：基于时空特征提取的四维轨迹预测",
      "authors": [
        "Yuheng Kuang",
        "Zhengning Wang",
        "Jianping Zhang",
        "Zhenyu Shi",
        "Yuding Zhang"
      ],
      "abstract": "The importance of four-dimensional (4D) trajectory prediction within air\ntraffic management systems is on the rise. Key operations such as conflict\ndetection and resolution, aircraft anomaly monitoring, and the management of\ncongested flight paths are increasingly reliant on this foundational\ntechnology, underscoring the urgent demand for intelligent solutions. The\ndynamics in airport terminal zones and crowded airspaces are intricate and\never-changing; however, current methodologies do not sufficiently account for\nthe interactions among aircraft. To tackle these challenges, we propose\nDA-STGCN, an innovative spatiotemporal graph convolutional network that\nintegrates a dual attention mechanism. Our model reconstructs the adjacency\nmatrix through a self-attention approach, enhancing the capture of node\ncorrelations, and employs graph attention to distill spatiotemporal\ncharacteristics, thereby generating a probabilistic distribution of predicted\ntrajectories. This novel adjacency matrix, reconstructed with the\nself-attention mechanism, is dynamically optimized throughout the network's\ntraining process, offering a more nuanced reflection of the inter-node\nrelationships compared to traditional algorithms. The performance of the model\nis validated on two ADS-B datasets, one near the airport terminal area and the\nother in dense airspace. Experimental results demonstrate a notable improvement\nover current 4D trajectory prediction methods, achieving a 20% and 30%\nreduction in the Average Displacement Error (ADE) and Final Displacement Error\n(FDE), respectively. The incorporation of a Dual-Attention module has been\nshown to significantly enhance the extraction of node correlations, as verified\nby ablation experiments.",
      "tldr_zh": "该研究提出了DA-STGCN模型，一种基于双注意力机制（Dual-Attention）的时空图卷积网络，用于四维（4D）轨迹预测。该模型通过自注意力机制重构邻接矩阵，增强节点相关性的捕捉，并结合图注意力机制提取时空特征，生成预测轨迹的概率分布。实验表明，DA-STGCN在机场终端区域和密集空域的ADS-B数据集上显著优于现有方法，平均位移误差（ADE）和最终位移误差（FDE）分别降低了20%和30%，为空中交通管理中的冲突检测和异常监控提供了更智能的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04823v2",
      "published_date": "2025-03-05 03:42:49 UTC",
      "updated_date": "2025-03-13 03:39:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:19:09.783200"
    },
    {
      "arxiv_id": "2503.03140v2",
      "title": "Knowledge Augmentation in Federation: Rethinking What Collaborative Learning Can Bring Back to Decentralized Data",
      "title_zh": "联邦中的知识增强：重新思考协同学习能为去中心化数据带来什么",
      "authors": [
        "Wentai Wu",
        "Ligang He",
        "Saiqin Long",
        "Ahmed M. Abdelmoniem",
        "Yingliang Wu",
        "Rui Mao"
      ],
      "abstract": "Data, as an observable form of knowledge, has become one of the most\nimportant factors of production for the development of Artificial Intelligence\n(AI). Meanwhile, increasing legislation and regulations on private and\nproprietary information results in scattered data sources also known as the\n\"data islands\". Although some collaborative learning paradigms such as\nFederated Learning (FL) can enable privacy-preserving training over\ndecentralized data, they have inherent deficiencies in fairness, costs and\nreproducibility because of being learning-centric, which greatly limits the way\nhow participants cooperate with each other. In light of this, we present a\nknowledge-centric paradigm termed Knowledge Augmentation in Federation (KAF),\nwith focus on how to enhance local knowledge through collaborative effort. We\nprovide the suggested system architecture, formulate the prototypical\noptimization objective, and review emerging studies that employ methodologies\nsuitable for KAF. On our roadmap, with a three-way categorization we describe\nthe methods for knowledge expansion, knowledge filtering, and label and feature\nspace correction in the federation. Further, we highlight several challenges\nand open questions that deserve more attention from the community. With our\ninvestigation, we intend to offer new insights for what collaborative learning\ncan bring back to decentralized data.",
      "tldr_zh": "该研究提出了一种名为\"知识联邦增强\"(KAF)的新范式，旨在解决现有联邦学习(FL)在公平性、成本和可复现性方面的固有缺陷。不同于传统以学习为中心的方法，KAF采用知识中心的视角，通过知识扩展、知识过滤以及标签/特征空间校正三种方法增强去中心化数据的本地知识。研究不仅提供了系统架构建议和优化目标公式，还梳理了相关新兴研究方法，为协作学习如何反哺分散数据开辟了新思路。最后，作者指出了该领域值得关注的多项挑战和开放问题。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "preprint",
      "pdf_url": "http://arxiv.org/pdf/2503.03140v2",
      "published_date": "2025-03-05 03:26:54 UTC",
      "updated_date": "2025-03-07 02:57:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:19:23.314020"
    },
    {
      "arxiv_id": "2503.03139v1",
      "title": "Convergence Analysis of Federated Learning Methods Using Backward Error Analysis",
      "title_zh": "基于后向误差分析的联邦学习方法收敛性研究",
      "authors": [
        "Jinwoo Lim",
        "Suhyun Kim",
        "Soo-Mook Moon"
      ],
      "abstract": "Backward error analysis allows finding a modified loss function, which the\nparameter updates really follow under the influence of an optimization method.\nThe additional loss terms included in this modified function is called implicit\nregularizer. In this paper, we attempt to find the implicit regularizer for\nvarious federated learning algorithms on non-IID data distribution, and explain\nwhy each method shows different convergence behavior. We first show that the\nimplicit regularizer of FedAvg disperses the gradient of each client from the\naverage gradient, thus increasing the gradient variance. We also empirically\nshow that the implicit regularizer hampers its convergence. Similarly, we\ncompute the implicit regularizers of FedSAM and SCAFFOLD, and explain why they\nconverge better. While existing convergence analyses focus on pointing out the\nadvantages of FedSAM and SCAFFOLD, our approach can explain their limitations\nin complex non-convex settings. In specific, we demonstrate that FedSAM can\npartially remove the bias in the first-order term of the implicit regularizer\nin FedAvg, whereas SCAFFOLD can fully eliminate the bias in the first-order\nterm, but not in the second-order term. Consequently, the implicit regularizer\ncan provide a useful insight on the convergence behavior of federated learning\nfrom a different theoretical perspective.",
      "tldr_zh": "该论文采用反向误差分析(Backward Error Analysis)方法研究联邦学习算法的收敛特性，揭示了不同方法在非独立同分布(non-IID)数据下的隐式正则化效应。研究发现：FedAvg的隐式正则化器会增大客户端梯度方差从而阻碍收敛；FedSAM能部分消除一阶偏置，而SCAFFOLD可完全消除一阶偏置但保留二阶偏置。该分析为理解复杂非凸场景下联邦学习的收敛行为提供了新的理论视角。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03139v1",
      "published_date": "2025-03-05 03:26:48 UTC",
      "updated_date": "2025-03-05 03:26:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:19:26.764077"
    },
    {
      "arxiv_id": "2503.03137v1",
      "title": "L2R: Learning to Reduce Search Space for Generalizable Neural Routing Solver",
      "title_zh": "L2R：面向可泛化神经路由求解器的搜索空间缩减学习法",
      "authors": [
        "Changliang Zhou",
        "Xi Lin",
        "Zhenkun Wang",
        "Qingfu Zhang"
      ],
      "abstract": "Constructive neural combinatorial optimization (NCO) has attracted growing\nresearch attention due to its ability to solve complex routing problems without\nrelying on handcrafted rules. However, existing NCO methods face significant\nchallenges in generalizing to large-scale problems due to high computational\ncomplexity and inefficient capture of structural patterns. To address this\nissue, we propose a novel learning-based search space reduction method that\nadaptively selects a small set of promising candidate nodes at each step of the\nconstructive NCO process. Unlike traditional methods that rely on fixed\nheuristics, our selection model dynamically prioritizes nodes based on learned\npatterns, significantly reducing the search space while maintaining solution\nquality. Experimental results demonstrate that our method, trained solely on\n100-node instances from uniform distribution, generalizes remarkably well to\nlarge-scale Traveling Salesman Problem (TSP) and Capacitated Vehicle Routing\nProblem (CVRP) instances with up to 1 million nodes from the uniform\ndistribution and over 80K nodes from other distributions.",
      "tldr_zh": "该研究提出L2R方法，通过学习减少搜索空间来提高神经组合优化（NCO）求解器的泛化能力。与传统依赖固定启发式规则的方法不同，L2R通过自适应选择候选节点来动态缩减搜索空间，同时保持解的质量。实验表明，该方法仅用100个节点的均匀分布数据进行训练，就能有效泛化到百万级节点的旅行商问题（TSP）和带容量约束的车辆路径问题（CVRP），在不同分布的数据集上也表现出色。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "23 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.03137v1",
      "published_date": "2025-03-05 03:25:09 UTC",
      "updated_date": "2025-03-05 03:25:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:20:08.034533"
    },
    {
      "arxiv_id": "2503.07636v1",
      "title": "An Optimization Algorithm for Multimodal Data Alignment",
      "title_zh": "多模态数据对齐的优化算法",
      "authors": [
        "Wei Zhang",
        "Xinyue Wang",
        "Lan Yu",
        "Shi Li"
      ],
      "abstract": "In the data era, the integration of multiple data types, known as\nmultimodality, has become a key area of interest in the research community.\nThis interest is driven by the goal to develop cutting edge multimodal models\ncapable of serving as adaptable reasoning engines across a wide range of\nmodalities and domains. Despite the fervent development efforts, the challenge\nof optimally representing different forms of data within a single unified\nlatent space a crucial step for enabling effective multimodal reasoning has not\nbeen fully addressed. To bridge this gap, we introduce AlignXpert, an\noptimization algorithm inspired by Kernel CCA crafted to maximize the\nsimilarities between N modalities while imposing some other constraints. This\nwork demonstrates the impact on improving data representation for a variety of\nreasoning tasks, such as retrieval and classification, underlining the pivotal\nimportance of data representation.",
      "tldr_zh": "本研究提出了AlignXpert，一种基于核典型相关分析(Kernel CCA)的优化算法，旨在解决多模态数据在统一潜在空间中的对齐问题。该算法通过最大化N种模态之间的相似性，并施加其他约束条件，显著提升了数据表示的质量。实验表明，AlignXpert在检索和分类等多种推理任务中表现优异，突显了数据表示在多模态模型中的关键作用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ACL SRW submission",
      "pdf_url": "http://arxiv.org/pdf/2503.07636v1",
      "published_date": "2025-03-05 03:07:07 UTC",
      "updated_date": "2025-03-05 03:07:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:19:46.524813"
    },
    {
      "arxiv_id": "2503.03129v1",
      "title": "Exploring Neural Ordinary Differential Equations as Interpretable Healthcare classifiers",
      "title_zh": "探索神经常微分方程作为可解释的医疗保健分类器",
      "authors": [
        "Shi Li"
      ],
      "abstract": "Deep Learning has emerged as one of the most significant innovations in\nmachine learning. However, a notable limitation of this field lies in the\n``black box\" decision-making processes, which have led to skepticism within\ngroups like healthcare and scientific communities regarding its applicability.\nIn response, this study introduces a interpretable approach using Neural\nOrdinary Differential Equations (NODEs), a category of neural network models\nthat exploit the dynamics of differential equations for representation\nlearning. Leveraging their foundation in differential equations, we illustrate\nthe capability of these models to continuously process textual data, marking\nthe first such model of its kind, and thereby proposing a promising direction\nfor future research in this domain. The primary objective of this research is\nto propose a novel architecture for groups like healthcare that require the\npredictive capabilities of deep learning while emphasizing the importance of\nmodel transparency demonstrated in NODEs.",
      "tldr_zh": "本研究提出了一种基于神经常微分方程(Neural Ordinary Differential Equations, NODEs)的可解释深度学习架构，旨在解决医疗等领域对模型透明度的需求。NODEs利用微分方程的动态特性进行表示学习，首次实现了对文本数据的连续处理，为深度学习在医疗等领域的应用提供了兼具预测能力和可解释性的新方向。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ACL SRW Submission",
      "pdf_url": "http://arxiv.org/pdf/2503.03129v1",
      "published_date": "2025-03-05 02:51:50 UTC",
      "updated_date": "2025-03-05 02:51:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:20:08.407088"
    },
    {
      "arxiv_id": "2503.03128v1",
      "title": "Towards Understanding Multi-Round Large Language Model Reasoning: Approximability, Learnability and Generalizability",
      "title_zh": "迈向理解大语言模型多轮推理：可逼近性、可学习性与泛化性",
      "authors": [
        "Chenhui Xu",
        "Dancheng Liu",
        "Jiajie Li",
        "Amir Nassereldine",
        "Zhaohui Li",
        "Jinjun Xiong"
      ],
      "abstract": "Recent advancements in cognitive science and multi-round reasoning techniques\nfor Large Language Models (LLMs) suggest that iterative thinking processes\nimprove problem-solving performance in complex tasks. Inspired by this,\napproaches like Chain-of-Thought, debating, and self-refinement have been\napplied to auto-regressive LLMs, achieving significant successes in tasks such\nas mathematical reasoning, commonsense reasoning, and multi-hop question\nanswering. Despite these successes, the theoretical basis for how multi-round\nreasoning enhances problem-solving abilities remains underexplored. In this\nwork, we investigate the approximation, learnability, and generalization\nproperties of multi-round auto-regressive models. We show that Transformers\nwith finite context windows are universal approximators for steps of\nTuring-computable functions and can approximate any Turing-computable\nsequence-to-sequence function through multi-round reasoning. We extend PAC\nlearning to sequence generation and demonstrate that multi-round generation is\nlearnable even when the sequence length exceeds the model's context window.\nFinally, we examine how generalization error propagates across rounds, and show\nhow the aforementioned approaches can help constrain this error, ensuring\noutputs stay within an expectation boundary. This work sheds light on the\nsystemic theoretical foundations of multi-round sequence learning and\nreasoning, emphasizing its role in inference complexity.",
      "tldr_zh": "该研究探讨了大语言模型(LLMs)多轮推理的理论基础，重点关注其近似性、可学习性和泛化性。研究表明，具有有限上下文窗口的Transformer模型能够通过多轮推理逼近任何图灵可计算的序列到序列函数。研究将PAC学习扩展到序列生成任务，证明了即使序列长度超过模型上下文窗口，多轮生成仍然是可学习的。此外，研究分析了泛化误差在多轮推理中的传播，并展示了如何通过链式思维推理、辩论和自我优化等方法约束误差，确保输出在预期范围内。这项工作为多轮序列学习和推理的系统性理论奠定了基础，强调了其在推理复杂性中的重要作用。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03128v1",
      "published_date": "2025-03-05 02:50:55 UTC",
      "updated_date": "2025-03-05 02:50:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:20:07.418808"
    },
    {
      "arxiv_id": "2503.03122v2",
      "title": "The Devil Is in the Details: Tackling Unimodal Spurious Correlations for Generalizable Multimodal Reward Models",
      "title_zh": "细节决定成败：解决单模态虚假相关性以实现可推广的多模态奖励模型",
      "authors": [
        "Zichao Li",
        "Xueru Wen",
        "Jie Lou",
        "Yuqiu Ji",
        "Yaojie Lu",
        "Xianpei Han",
        "Debing Zhang",
        "Le Sun"
      ],
      "abstract": "Multimodal Reward Models (MM-RMs) are crucial for aligning Large Language\nModels (LLMs) with human preferences, particularly as LLMs increasingly\ninteract with multimodal data. However, we find that MM-RMs trained on existing\ndatasets often struggle to generalize to out-of-distribution data due to their\nreliance on unimodal spurious correlations, primarily text-only shortcuts\nwithin the training distribution, which prevents them from leveraging true\nmultimodal reward functions. To address this, we introduce a Shortcut-aware\nMM-RM learning algorithm that mitigates this issue by dynamically reweighting\ntraining samples, shifting the distribution toward better multimodal\nunderstanding, and reducing dependence on unimodal spurious correlations. Our\nexperiments demonstrate significant improvements in generalization, downstream\ntask performance, and scalability, establishing a more robust framework for\nmultimodal reward modeling.",
      "tldr_zh": "该研究针对多模态奖励模型(MM-RMs)中的单模态伪相关性问题，提出了一种Shortcut-aware学习算法。研究发现当前MM-RMs过度依赖文本捷径(text-only shortcuts)而无法真正利用多模态奖励函数，导致在分布外数据上泛化能力差。新方法通过动态重加权训练样本，有效减少对单模态伪相关性的依赖，提升了模型在多模态理解、下游任务表现和可扩展性方面的性能，为构建更鲁棒的多模态奖励建模框架提供了解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03122v2",
      "published_date": "2025-03-05 02:37:41 UTC",
      "updated_date": "2025-03-10 02:34:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:20:13.648303"
    },
    {
      "arxiv_id": "2503.03112v1",
      "title": "A Multimodal Framework for Topic Propagation Classification in Social Networks",
      "title_zh": "社交网络话题传播分类的多模态框架",
      "authors": [
        "Yuchuan Jiang",
        "Chaolong Jia",
        "Yunyi Qin",
        "Wei Cai",
        "Yongsen Qian"
      ],
      "abstract": "The rapid proliferation of the Internet and the widespread adoption of social\nnetworks have significantly accelerated information dissemination. However,\nthis transformation has introduced complexities in information capture and\nprocessing, posing substantial challenges for researchers and practitioners.\nPredicting the dissemination of topic-related information within social\nnetworks has thus become a critical research focus. This paper proposes a\npredictive model for topic dissemination in social networks by integrating\nmultidimensional features derived from key dissemination characteristics.\nSpecifically, we introduce two novel indicators, user relationship breadth and\nuser authority, into the PageRank algorithm to quantify user influence more\neffectively. Additionally, we employ a Text-CNN model for sentiment\nclassification, extracting sentiment features from textual content. Temporal\nembeddings of nodes are encoded using a Bi-LSTM model to capture temporal\ndynamics. Furthermore, we refine the measurement of user interaction traces\nwith topics, replacing traditional topic view metrics with a more precise\ncommunication characteristics measure. Finally, we integrate the extracted\nmultidimensional features using a Transformer model, significantly enhancing\npredictive performance. Experimental results demonstrate that our proposed\nmodel outperforms traditional machine learning and unimodal deep learning\nmodels in terms of FI-Score, AUC, and Recall, validating its effectiveness in\npredicting topic propagation within social networks.",
      "tldr_zh": "本文提出了一种多模态框架，用于预测社交网络中话题传播的分类。通过整合多维特征，包括改进的PageRank算法（引入用户关系广度和用户权威性指标）、Text-CNN模型的情感分类、Bi-LSTM模型的时间动态编码，以及更精确的用户交互轨迹测量，该框架显著提升了预测性能。实验结果表明，该模型在FI-Score、AUC和Recall等指标上优于传统机器学习和单模态深度学习模型，验证了其在话题传播预测中的有效性。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03112v1",
      "published_date": "2025-03-05 02:12:23 UTC",
      "updated_date": "2025-03-05 02:12:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:20:22.287246"
    },
    {
      "arxiv_id": "2503.03108v1",
      "title": "SoK: Knowledge is All You Need: Last Mile Delivery for Automated Provenance-based Intrusion Detection with LLMs",
      "title_zh": "SoK：知识即一切：利用大语言模型实现基于溯源入侵检测的最后一公里自动化",
      "authors": [
        "Wenrui Cheng",
        "Tiantian Zhu",
        "Chunlin Xiong",
        "Haofei Sun",
        "Zijun Wang",
        "Shunan Jing",
        "Mingqi Lv",
        "Yan Chen"
      ],
      "abstract": "Recently, provenance-based intrusion detection systems (PIDSes) have been\nwidely proposed for endpoint threat analysis. However, due to the lack of\nsystematic integration and utilization of knowledge, existing PIDSes still\nrequire significant manual intervention for practical deployment, making full\nautomation challenging. This paper presents a disruptive innovation by\ncategorizing PIDSes according to the types of knowledge they utilize. In\nresponse to the prevalent issue of ``knowledge silos problem'' in existing\nresearch, we introduce a novel knowledge-driven provenance-based intrusion\ndetection framework, powered by large language models (LLMs). We also present\nOmniSec, a best practice system built upon this framework. By integrating\nattack representation knowledge, threat intelligence knowledge, and benign\nbehavior knowledge, OmniSec outperforms the state-of-the-art approaches on\npublic benchmark datasets. OmniSec is available online at\nhttps://anonymous.4open.science/r/PIDS-with-LLM-613B.",
      "tldr_zh": "本文提出了一种基于知识驱动的溯源入侵检测框架，利用大语言模型（LLMs）解决现有溯源入侵检测系统（PIDSes）中知识孤岛和自动化不足的问题。通过整合攻击表示知识、威胁情报知识和良性行为知识，该框架显著提升了检测性能。基于该框架的最佳实践系统OmniSec在公开基准数据集上优于现有方法，为完全自动化的入侵检测提供了新方向。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03108v1",
      "published_date": "2025-03-05 02:08:12 UTC",
      "updated_date": "2025-03-05 02:08:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:20:56.448400"
    },
    {
      "arxiv_id": "2503.03107v1",
      "title": "External Reliable Information-enhanced Multimodal Contrastive Learning for Fake News Detection",
      "title_zh": "外部可靠信息增强的多模态对比学习虚假新闻检测方法",
      "authors": [
        "Biwei Cao",
        "Qihang Wu",
        "Jiuxin Cao",
        "Bo Liu",
        "Jie Gui"
      ],
      "abstract": "With the rapid development of the Internet, the information dissemination\nparadigm has changed and the efficiency has been improved greatly. While this\nalso brings the quick spread of fake news and leads to negative impacts on\ncyberspace. Currently, the information presentation formats have evolved\ngradually, with the news formats shifting from texts to multimodal contents. As\na result, detecting multimodal fake news has become one of the research\nhotspots. However, multimodal fake news detection research field still faces\ntwo main challenges: the inability to fully and effectively utilize multimodal\ninformation for detection, and the low credibility or static nature of the\nintroduced external information, which limits dynamic updates. To bridge the\ngaps, we propose ERIC-FND, an external reliable information-enhanced multimodal\ncontrastive learning framework for fake news detection. ERIC-FND strengthens\nthe representation of news contents by entity-enriched external information\nenhancement method. It also enriches the multimodal news information via\nmultimodal semantic interaction method where the multimodal constrative\nlearning is employed to make different modality representations learn from each\nother. Moreover, an adaptive fusion method is taken to integrate the news\nrepresentations from different dimensions for the eventual classification.\nExperiments are done on two commonly used datasets in different languages, X\n(Twitter) and Weibo. Experiment results demonstrate that our proposed model\nERIC-FND outperforms existing state-of-the-art fake news detection methods\nunder the same settings.",
      "tldr_zh": "本文提出ERIC-FND框架，通过引入动态更新的外部可靠信息增强多模态对比学习，解决虚假新闻检测中多模态信息利用不足和外部信息可信度低的问题。该框架采用实体增强的外部信息强化方法提升新闻内容表征，并通过多模态对比学习实现跨模态语义交互，最后采用自适应融合方法整合多维新闻表征进行分类。在Twitter和微博双语数据集上的实验表明，ERIC-FND在相同设置下优于现有最优虚假新闻检测方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "accepted by AAAI'25",
      "pdf_url": "http://arxiv.org/pdf/2503.03107v1",
      "published_date": "2025-03-05 02:07:38 UTC",
      "updated_date": "2025-03-05 02:07:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:20:36.336673"
    },
    {
      "arxiv_id": "2503.04822v1",
      "title": "HeTGB: A Comprehensive Benchmark for Heterophilic Text-Attributed Graphs",
      "title_zh": "HeTGB：异质性文本属性图的综合基准",
      "authors": [
        "Shujie Li",
        "Yuxia Wu",
        "Chuan Shi",
        "Yuan Fang"
      ],
      "abstract": "Graph neural networks (GNNs) have demonstrated success in modeling relational\ndata primarily under the assumption of homophily. However, many real-world\ngraphs exhibit heterophily, where linked nodes belong to different categories\nor possess diverse attributes. Additionally, nodes in many domains are\nassociated with textual descriptions, forming heterophilic text-attributed\ngraphs (TAGs). Despite their significance, the study of heterophilic TAGs\nremains underexplored due to the lack of comprehensive benchmarks. To address\nthis gap, we introduce the Heterophilic Text-attributed Graph Benchmark\n(HeTGB), a novel benchmark comprising five real-world heterophilic graph\ndatasets from diverse domains, with nodes enriched by extensive textual\ndescriptions. HeTGB enables systematic evaluation of GNNs, pre-trained language\nmodels (PLMs) and co-training methods on the node classification task. Through\nextensive benchmarking experiments, we showcase the utility of text attributes\nin heterophilic graphs, analyze the challenges posed by heterophilic TAGs and\nthe limitations of existing models, and provide insights into the interplay\nbetween graph structures and textual attributes. We have publicly released\nHeTGB with baseline implementations to facilitate further research in this\nfield.",
      "tldr_zh": "该研究提出了HeTGB（异质性文本属性图基准），旨在填补异质性文本属性图（TAGs）研究领域的空白。HeTGB包含五个真实世界的异质性图数据集，节点附有丰富的文本描述，支持对图神经网络（GNNs）、预训练语言模型（PLMs）和协同训练方法的系统评估。通过大量实验，研究揭示了文本属性在异质性图中的重要性，分析了现有模型的局限性，并探讨了图结构与文本属性之间的相互作用。HeTGB及其基线实现已公开发布，以推动该领域的进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2503.04822v1",
      "published_date": "2025-03-05 02:00:32 UTC",
      "updated_date": "2025-03-05 02:00:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:20:45.415172"
    },
    {
      "arxiv_id": "2503.03104v1",
      "title": "RVAFM: Re-parameterizing Vertical Attention Fusion Module for Handwritten Paragraph Text Recognition",
      "title_zh": "RVAFM：用于手写段落文本识别的重参数化垂直注意力融合模块",
      "authors": [
        "Jinhui Zheng",
        "Zhiquan Liu",
        "Yain-Whar Si",
        "Jianqing Li",
        "Xinyuan Zhang",
        "Xiaofan Li",
        "Haozhi Huang",
        "Xueyuan Gong"
      ],
      "abstract": "Handwritten Paragraph Text Recognition (HPTR) is a challenging task in\nComputer Vision, requiring the transformation of a paragraph text image, rich\nin handwritten text, into text encoding sequences. One of the most advanced\nmodels for this task is Vertical Attention Network (VAN), which utilizes a\nVertical Attention Module (VAM) to implicitly segment paragraph text images\ninto text lines, thereby reducing the difficulty of the recognition task.\nHowever, from a network structure perspective, VAM is a single-branch module,\nwhich is less effective in learning compared to multi-branch modules. In this\npaper, we propose a new module, named Re-parameterizing Vertical Attention\nFusion Module (RVAFM), which incorporates structural re-parameterization\ntechniques. RVAFM decouples the structure of the module during training and\ninference stages. During training, it uses a multi-branch structure for more\neffective learning, and during inference, it uses a single-branch structure for\nfaster processing. The features learned by the multi-branch structure are fused\ninto the single-branch structure through a special fusion method named\nRe-parameterization Fusion (RF) without any loss of information. As a result,\nwe achieve a Character Error Rate (CER) of 4.44% and a Word Error Rate (WER) of\n14.37% on the IAM paragraph-level test set. Additionally, the inference speed\nis slightly faster than VAN.",
      "tldr_zh": "本文提出了一种新型模块 RVAFM（Re-parameterizing Vertical Attention Fusion Module），用于改进手写段落文本识别（HPTR）任务。RVAFM 通过结构重参数化技术，在训练阶段采用多分支结构以提升学习效果，在推理阶段则转换为单分支结构以提高处理速度，并通过重参数化融合（RF）方法实现特征的无损融合。实验表明，RVAFM 在 IAM 段落级测试集上取得了 4.44% 的字符错误率（CER）和 14.37% 的单词错误率（WER），且推理速度略快于现有最先进的垂直注意力网络（VAN）。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03104v1",
      "published_date": "2025-03-05 01:41:59 UTC",
      "updated_date": "2025-03-05 01:41:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:20:53.421692"
    },
    {
      "arxiv_id": "2503.04821v1",
      "title": "RTFusion: A depth estimation network based on multimodal fusion in challenging scenarios",
      "title_zh": "RTFusion：基于多模态融合的挑战性场景深度估计网络",
      "authors": [
        "Zelin Meng",
        "Takanori Fukao"
      ],
      "abstract": "Depth estimation in complex real-world scenarios is a challenging task,\nespecially when relying solely on a single modality such as visible light or\nthermal infrared (THR) imagery. This paper proposes a novel multimodal depth\nestimation model, RTFusion, which enhances depth estimation accuracy and\nrobustness by integrating the complementary strengths of RGB and THR data. The\nRGB modality provides rich texture and color information, while the THR\nmodality captures thermal patterns, ensuring stability under adverse lighting\nconditions such as extreme illumination. The model incorporates a unique fusion\nmechanism, EGFusion, consisting of the Mutual Complementary Attention (MCA)\nmodule for cross-modal feature alignment and the Edge Saliency Enhancement\nModule (ESEM) to improve edge detail preservation. Comprehensive experiments on\nthe MS2 and ViViD++ datasets demonstrate that the proposed model consistently\nproduces high-quality depth maps across various challenging environments,\nincluding nighttime, rainy, and high-glare conditions. The experimental results\nhighlight the potential of the proposed method in applications requiring\nreliable depth estimation, such as autonomous driving, robotics, and augmented\nreality.",
      "tldr_zh": "本文提出了RTFusion，一种基于RGB和热红外(THR)多模态融合的深度估计网络，旨在提升复杂场景下的估计精度和鲁棒性。该模型通过独特的EGFusion机制，结合互补注意力模块(MCA)实现跨模态特征对齐，并利用边缘显著性增强模块(ESEM)优化边缘细节保留。实验表明，RTFusion在夜间、雨天和高光等挑战性环境下，能够在MS2和ViViD++数据集上生成高质量的深度图，为自动驾驶、机器人和增强现实等应用提供了可靠的深度估计解决方案。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "8 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.04821v1",
      "published_date": "2025-03-05 01:35:14 UTC",
      "updated_date": "2025-03-05 01:35:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:21:21.938165"
    },
    {
      "arxiv_id": "2503.03084v1",
      "title": "Hopfield Networks Meet Big Data: A Brain-Inspired Deep Learning Framework for Semantic Data Linking",
      "title_zh": "Hopfield网络与大数据相遇：面向语义数据链接的脑启发深度学习框架",
      "authors": [
        "Ashwin Viswanathan Kannan",
        "Johnson P Thomas",
        "Abhimanyu Mukerji"
      ],
      "abstract": "The exponential rise in data generation has led to vast, heterogeneous\ndatasets crucial for predictive analytics and decision-making. Ensuring data\nquality and semantic integrity remains a challenge. This paper presents a\nbrain-inspired distributed cognitive framework that integrates deep learning\nwith Hopfield networks to identify and link semantically related attributes\nacross datasets. Modeled on the dual-hemisphere functionality of the human\nbrain, the right hemisphere assimilates new information while the left\nretrieves learned representations for association. Our architecture,\nimplemented on MapReduce with Hadoop Distributed File System (HDFS), leverages\ndeep Hopfield networks as an associative memory mechanism to enhance recall of\nfrequently co-occurring attributes and dynamically adjust relationships based\non evolving data patterns. Experiments show that associative imprints in\nHopfield memory are reinforced over time, ensuring linked datasets remain\ncontextually meaningful and improving data disambiguation and integration\naccuracy. Our results indicate that combining deep Hopfield networks with\ndistributed cognitive processing offers a scalable, biologically inspired\napproach to managing complex data relationships in large-scale environments.",
      "tldr_zh": "该研究提出了一种受大脑启发的深度学习框架，将深度学习和Hopfield网络结合，用于识别和链接跨数据集的语义相关属性。该框架模拟人脑的双半球功能，右半球负责吸收新信息，左半球则检索已学习的表征进行关联。通过基于MapReduce和Hadoop分布式文件系统(HDFS)实现，该架构利用深度Hopfield网络作为联想记忆机制，增强了对频繁共现属性的回忆能力，并能根据数据模式的变化动态调整关系。实验表明，Hopfield记忆中的联想印记随时间得到强化，确保了链接数据集在上下文中的意义，并提高了数据消歧和整合的准确性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.03084v1",
      "published_date": "2025-03-05 00:53:22 UTC",
      "updated_date": "2025-03-05 00:53:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:21:26.874219"
    },
    {
      "arxiv_id": "2503.13477v1",
      "title": "Periodontal Bone Loss Analysis via Keypoint Detection With Heuristic Post-Processing",
      "title_zh": "通过启发式后处理的关键点检测进行牙周骨丧失分析",
      "authors": [
        "Ryan Banks",
        "Vishal Thengane",
        "María Eugenia Guerrero",
        "Nelly Maria García-Madueño",
        "Yunpeng Li",
        "Hongying Tang",
        "Akhilanand Chaurasia"
      ],
      "abstract": "Calculating percentage bone loss is a critical test for periodontal disease\nstaging but is sometimes imprecise and time consuming when manually calculated.\nThis study evaluates the application of a deep learning keypoint and object\ndetection model, YOLOv8-pose, for the automatic identification of localised\nperiodontal bone loss landmarks, conditions and staging. YOLOv8-pose was\nfine-tuned on 193 annotated periapical radiographs. We propose a keypoint\ndetection metric, Percentage of Relative Correct Keypoints (PRCK), which\nnormalises the metric to the average tooth size of teeth in the image. We\npropose a heuristic post-processing module that adjusts certain keypoint\npredictions to align with the edge of the related tooth, using a supporting\ninstance segmentation model trained on an open source auxiliary dataset. The\nmodel can sufficiently detect bone loss keypoints, tooth boxes, and alveolar\nridge resorption, but has insufficient performance at detecting detached\nperiodontal ligament and furcation involvement. The model with post-processing\ndemonstrated a PRCK 0.25 of 0.726 and PRCK 0.05 of 0.401 for keypoint\ndetection, mAP 0.5 of 0.715 for tooth object detection, mesial dice score of\n0.593 for periodontal staging, and dice score of 0.280 for furcation\ninvolvement. Our annotation methodology provides a stage agnostic approach to\nperiodontal disease detection, by ensuring most keypoints are present for each\ntooth in the image, allowing small imbalanced datasets. Our PRCK metric allows\naccurate evaluation of keypoints in dental domains. Our post-processing module\nadjusts predicted keypoints correctly but is dependent on a minimum quality of\nprediction by the pose detection and segmentation models. Code: https://\nanonymous.4open.science/r/Bone-Loss-Keypoint-Detection-Code. Dataset:\nhttps://bit.ly/4hJ3aE7.",
      "tldr_zh": "本研究提出了一种基于YOLOv8-pose深度学习模型的关键点检测方法，用于自动化分析牙周骨丢失并辅助牙周病分期。研究创新性地提出了百分比相对正确关键点（PRCK）指标，用于评估关键点检测的准确性，并设计了一种启发式后处理模块，通过辅助实例分割模型调整关键点预测，使其与牙齿边缘对齐。实验表明，该方法在检测骨丢失关键点、牙槽骨吸收和牙齿边界方面表现良好，但在检测牙周韧带分离和分叉病变方面仍有不足。该研究为牙周病的自动化检测提供了一种阶段无关的方法，并公开了代码和数据集。",
      "categories": [
        "q-bio.TO",
        "cs.AI",
        "cs.CV",
        "I.2.1; I.2.10; J.3"
      ],
      "primary_category": "q-bio.TO",
      "comment": "31 pages, 7 tables, 5 figures, 3 equations, journal paper submitted\n  to Computers in Biology and Medicine",
      "pdf_url": "http://arxiv.org/pdf/2503.13477v1",
      "published_date": "2025-03-05 00:34:29 UTC",
      "updated_date": "2025-03-05 00:34:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:21:38.376132"
    },
    {
      "arxiv_id": "2503.07634v1",
      "title": "Impact of Level 2/3 Automated Driving Technology on Road Work Zone Safety",
      "title_zh": "L2/L3级自动驾驶技术对道路施工区安全性的影响",
      "authors": [
        "Zhepu Xu",
        "Ziyi Song",
        "Yupu Dong",
        "Peiyan Chen"
      ],
      "abstract": "As China's road network enters the maintenance era, work zones will become a\ncommon sight on the roads. With the development of automated driving, vehicles\nequipped with Level 2/3 automated driving capabilities will also become a\ncommon presence on the roads. When these vehicles pass through work zones,\nautomated driving may disengage, which can have complex effects on traffic\nsafety. This paper explores the impact of Level 2/3 automated driving\ntechnology on road safety in high-speed highway work zone environments. Through\nmicroscopic traffic simulation method and using full-type traffic conflict\ntechnique, factors such as market penetration rate (MPR), traffic volume level,\ndisengagement threshold, and driver takeover style are studied to understand\ntheir impact on work zone safety. The study found that the impact of automated\ndriving technology on work zone safety is complex. Disengagement of automated\nvehicles in work zones reduces the proportion of vehicles that can maintain\nautomated driving status. If takeover is not timely or adequate, it can easily\nlead to new traffic conflicts. Different factors have varying degrees of impact\non work zone safety. Increasing MPR helps reduce the occurrence of\nsingle-vehicle conflicts, but it also increases the possibility of\nmulti-vehicle conflicts. Therefore, future research and improvement directions\nshould focus on optimizing the disengagement detection and takeover mechanisms\nof automated driving systems.",
      "tldr_zh": "该研究探讨了L2/L3级自动驾驶技术在高速公路施工区对交通安全的影响。通过微观交通仿真和全类型交通冲突分析技术，发现自动驾驶车辆在施工区的退出接管机制存在安全隐患：市场渗透率(MPR)提升虽能减少单车冲突，但会增加多车冲突风险。研究指出，未来需重点优化自动驾驶系统的退出检测和接管机制，以平衡施工区场景下的交通安全问题。",
      "categories": [
        "cs.AI",
        "cs.MA",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07634v1",
      "published_date": "2025-03-05 00:26:53 UTC",
      "updated_date": "2025-03-05 00:26:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:21:53.670759"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 124,
  "processed_papers_count": 124,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-03-26T03:22:58.587061"
}