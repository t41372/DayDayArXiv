{
  "date": "2025-03-05",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-03-05 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦于 AI 和机器学习的创新应用，包括 LLM 在情感识别、医疗诊断和多模态模型中的增强、联邦学习和机器人导航的进展，其中令人印象深刻的是关于 LLM 集体智能的论文（如 Likith Kadiyala 的工作）和医疗 AI 框架（如 BrainNet-MoE），这些展示了 AI 在实际领域的潜力。\n\n### 重点论文讨论\n我们挑选了今天几篇重要、话题性和影响较大的论文，先从 AI 和医疗领域入手，这些论文涉及知名作者或创新方法，并可能引发广泛讨论。其他论文会简要概述或快速掠过。\n\n1. **Enhancing Collective Intelligence in Large Language Models Through Emotional Integration（增强大型语言模型的集体智能通过情感整合）**  \n   作者：Likith Kadiyala 等  \n   这篇论文令人印象深刻，因为它探索了将情感多样性融入 LLM（如 DarkIdol-Llama-3.1-8B），使用 GoEmotions 数据集和 LoRA 微调，显著提升了模型在决策任务（如距离估计）的表现。主要贡献是通过模拟人类“群体智慧”，证明情感整合能保持预测准确性，同时提升 AI 的集体智能，暗示未来 AI 系统可更平衡地处理情感和分析。\n\n2. **All-atom Diffusion Transformers: Unified generative modelling of molecules and materials（全原子扩散 Transformer：统一分子和材料的生成建模）**  \n   作者：Chaitanya K. Joshi 等  \n   这篇工作创新性地提出 ADiT 框架，用于统一生成周期性材料和非周期性分子，基于共享潜在空间和扩散模型。在 MP20、QM9 和 GEOM-DRUGS 数据集上，ADiT 实现了与专有模型相当的性能，同时加速训练和推理。主要发现是，通过 Transformer 减少归纳偏差，提升了生成化学领域的泛化能力。\n\n3. **BrainNet-MoE: Brain-Inspired Mixture-of-Experts Learning for Neurological Disease Identification（BrainNet-MoE：脑启发混合专家学习用于神经疾病识别）**  \n   作者：Jing Zhang 等  \n   这篇论文聚焦医疗 AI，引入脑启发 MoE 模型处理脑网络数据，针对 Lewy 体痴呆和阿尔茨海默病的分类。核心贡献是设计专家组和门控机制，实现高精度分类（实验中优于基线），并提供可解释性洞见，展示脑网络如何影响疾病诊断，强调 AI 在神经科学中的潜力。\n\n4. **GlucoLens: Explainable Postprandial Blood Glucose Prediction from Diet and Physical Activity（GlucoLens：基于饮食和身体活动的可解释餐后血糖预测）**  \n   作者：Abdullah Mamun 等  \n   在医疗预测领域，这篇论文提出 GlucoLens 模型，使用机器学习预测餐后血糖（PAUC），并提供可解释性推荐。关键发现是通过多模态数据（包括空腹血糖和营养量），模型实现了 74% 的高血糖预测准确率，并通过反事实解释建议生活方式调整，展示了 AI 在糖尿病预防中的实际应用价值。\n\n5. **CREStE: Scalable Mapless Navigation with Internet Scale Priors and Counterfactual Guidance（CREStE：使用互联网规模先验和反事实引导的可扩展无地图导航）**  \n   作者：Arthur Zhang 等  \n   这篇机器人导航论文引入 CREStE 框架，利用视觉基础模型和反事实学习，实现长距离无地图导航。主贡献是减少人类干预（70% 降低），在城市环境中表现出色，证明了泛化表示和规划的潜力，对于自动驾驶和机器人领域有重要启发。\n\n### 其他相关论文简评\n今天还有许多论文涉及 AI 生成和联邦学习等主题，但我们快速掠过不太核心的：\n- **RiskAgent: Autonomous Medical AI Copilot for Generalist Risk Prediction（RiskAgent：通用风险预测的自主医疗 AI 助手）**  \n  作者：Fenglin Liu 等  \n  提出 RiskAgent 框架，用于多疾病风险预测，结合证据医学工具，提升了诊断准确率（超过 GPT-4o），主要发现是 AI 在医疗泛化中的潜力。\n  \n- **COARSE: Collaborative Pseudo-Labeling with Coarse Real Labels for Off-Road Semantic Segmentation（COARSE：用于越野语义分割的协作伪标签和粗糙真实标签）**  \n  作者：Aurelio Noca 等  \n  开发了半监督域适应框架，提升了越野场景分割性能（在 RUGD 和 Rellis-3D 上改善 9.7%），贡献在于伪标签策略的应用。\n\n剩余论文，如那些聚焦特定技术细节的（如扩散模型变体或小规模优化），或不太热门的（如某些小数据集实验），我们仅简要提及：它们覆盖了从情感检测到机器人路径规划的广泛主题，但整体影响较小。例如，\"Deep ARTMAP\"（作者：Niklas M. Melton 等）扩展了 ART 架构用于分层学习，改进决策；\"MA-LoT\"（作者：Yaoru Li 等）提出多代理规划框架加速 LLM 推理。这些论文虽有技术贡献，但未如上述几篇那样突出或具话题性。\n\n总之，今天的 arXiv 强调 AI 在实际应用中的鲁棒性和泛化，LLM 和医疗 AI 领域尤为活跃，值得关注！如果有特定兴趣，建议查看这些论文的摘要。",
  "papers": [
    {
      "arxiv_id": "2503.04849v1",
      "title": "Enhancing Collective Intelligence in Large Language Models Through Emotional Integration",
      "title_zh": "通过情感整合增强大语言模型中的集体智能",
      "authors": [
        "Likith Kadiyala",
        "Ramteja Sajja",
        "Yusuf Sermet",
        "Ibrahim Demir"
      ],
      "abstract": "This research investigates the integration of emotional diversity into Large\nLanguage Models (LLMs) to enhance collective intelligence. Inspired by the\nhuman wisdom of crowds phenomenon, where group decisions often outperform\nindividual judgments, we fine-tuned the DarkIdol-Llama-3.1-8B model using\nGoogle's GoEmotions dataset and Low-Rank Adaptation (LoRA) to simulate\nemotionally diverse responses. Evaluating the model on a distance estimation\ntask between Fargo, ND, and Seattle, WA, across 15,064 unique persona\nconfigurations, we analyzed how emotional states and social attributes\ninfluence decision-making. Our findings demonstrate that emotional integration\nshapes response patterns while maintaining acceptable prediction accuracy,\nrevealing its potential to enhance artificial collective intelligence. This\nstudy provides valuable insights into the interplay of emotional diversity and\ndecision-making in LLMs, suggesting pathways for creating emotionally aware AI\nsystems that balance emotional depth with analytical precision.",
      "tldr_zh": "该研究探讨了通过整合情感多样性来提升大型语言模型 (LLMs) 的集体智能，灵感来源于人类的群体智慧现象。研究者微调了 DarkIdol-Llama-3.1-8B 模型，使用 Google's GoEmotions 数据集和 Low-Rank Adaptation (LoRA) 技术，以模拟情感多样的响应。实验在 Fargo, ND 和 Seattle, WA 之间的距离估计任务上评估了 15,064 个独特人格配置，分析了情感状态和社会属性对决策的影响。结果表明，情感整合能塑造响应模式，同时保持可接受的预测准确性，为开发平衡情感深度与分析精度的情感感知 AI 系统提供了新路径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.HC",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "23 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.04849v1",
      "published_date": "2025-03-05 23:42:48 UTC",
      "updated_date": "2025-03-05 23:42:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:07:13.684568"
    },
    {
      "arxiv_id": "2503.03965v2",
      "title": "All-atom Diffusion Transformers: Unified generative modelling of molecules and materials",
      "title_zh": "All-atom Diffusion Transformers：分子和材料的统一生成式建模",
      "authors": [
        "Chaitanya K. Joshi",
        "Xiang Fu",
        "Yi-Lun Liao",
        "Vahe Gharakhanyan",
        "Benjamin Kurt Miller",
        "Anuroop Sriram",
        "Zachary W. Ulissi"
      ],
      "abstract": "Diffusion models are the standard toolkit for generative modelling of 3D\natomic systems. However, for different types of atomic systems -- such as\nmolecules and materials -- the generative processes are usually highly specific\nto the target system despite the underlying physics being the same. We\nintroduce the All-atom Diffusion Transformer (ADiT), a unified latent diffusion\nframework for jointly generating both periodic materials and non-periodic\nmolecular systems using the same model: (1) An autoencoder maps a unified,\nall-atom representations of molecules and materials to a shared latent\nembedding space; and (2) A diffusion model is trained to generate new latent\nembeddings that the autoencoder can decode to sample new molecules or\nmaterials. Experiments on MP20, QM9 and GEOM-DRUGS datasets demonstrate that\njointly trained ADiT generates realistic and valid molecules as well as\nmaterials, obtaining state-of-the-art results on par with molecule and\ncrystal-specific models. ADiT uses standard Transformers with minimal inductive\nbiases for both the autoencoder and diffusion model, resulting in significant\nspeedups during training and inference compared to equivariant diffusion\nmodels. Scaling ADiT up to half a billion parameters predictably improves\nperformance, representing a step towards broadly generalizable foundation\nmodels for generative chemistry. Open source code:\nhttps://github.com/facebookresearch/all-atom-diffusion-transformer",
      "tldr_zh": "本研究提出 All-atom Diffusion Transformer (ADiT)，一个统一的潜在扩散框架，用于同时生成周期性材料和非周期性分子系统。框架包括一个 autoencoder，将分子和材料的统一全原子表示映射到共享的潜在嵌入空间，以及一个 diffusion model，用于生成新嵌入并解码为真实样本。在 MP20、QM9 和 GEOM-DRUGS 数据集上的实验显示，ADiT 达到了 state-of-the-art 性能，与特定模型相当，且使用标准 Transformers 实现训练和推理加速。扩展模型至 5 亿参数后，性能可预测提升，这为开发通用的生成化学基础模型奠定基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.03965v2",
      "published_date": "2025-03-05 23:35:44 UTC",
      "updated_date": "2025-05-22 08:08:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:07:23.867650"
    },
    {
      "arxiv_id": "2503.03951v1",
      "title": "WIP: Assessing the Effectiveness of ChatGPT in Preparatory Testing Activities",
      "title_zh": "WIP：评估 ChatGPT 在准备性测试活动中的有效性",
      "authors": [
        "Susmita Haldar",
        "Mary Pierce",
        "Luiz Fernando Capretz"
      ],
      "abstract": "This innovative practice WIP paper describes a research study that explores\nthe integration of ChatGPT into the software testing curriculum and evaluates\nits effectiveness compared to human-generated testing artifacts. In a Capstone\nProject course, students were tasked with generating preparatory testing\nartifacts using ChatGPT prompts, which they had previously created manually.\nTheir understanding and the effectiveness of the Artificial Intelligence\ngenerated artifacts were assessed through targeted questions. The results,\ndrawn from this in-class assignment at a North American community college\nindicate that while ChatGPT can automate many testing preparation tasks, it\ncannot fully replace human expertise. However, students, already familiar with\nInformation Technology at the postgraduate level, found the integration of\nChatGPT into their workflow to be straightforward. The study suggests that AI\ncan be gradually introduced into software testing education to keep pace with\ntechnological advancements.",
      "tldr_zh": "这篇研究评估了 ChatGPT 在软件测试课程中的应用效果，通过与人类生成测试工件进行比较。研究在 Capstone Project 课程中，让学生使用 ChatGPT 提示生成测试准备工件，并通过针对性问题评估其理解和 AI 生成工件的有效性。结果显示，ChatGPT 能自动化许多测试准备任务，但无法完全取代人类专业知识；同时，研究生水平的 IT 学生发现将其整合到工作流程中较为简单。该研究建议逐步引入 AI 到软件测试教育中，以适应技术进步。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "5 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.03951v1",
      "published_date": "2025-03-05 22:51:24 UTC",
      "updated_date": "2025-03-05 22:51:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:07:35.118694"
    },
    {
      "arxiv_id": "2503.03947v1",
      "title": "COARSE: Collaborative Pseudo-Labeling with Coarse Real Labels for Off-Road Semantic Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Aurelio Noca",
        "Xianmei Lei",
        "Jonathan Becktor",
        "Jeffrey Edlund",
        "Anna Sabel",
        "Patrick Spieler",
        "Curtis Padgett",
        "Alexandre Alahi",
        "Deegan Atha"
      ],
      "abstract": "Autonomous off-road navigation faces challenges due to diverse, unstructured\nenvironments, requiring robust perception with both geometric and semantic\nunderstanding. However, scarce densely labeled semantic data limits\ngeneralization across domains. Simulated data helps, but introduces domain\nadaptation issues. We propose COARSE, a semi-supervised domain adaptation\nframework for off-road semantic segmentation, leveraging sparse, coarse\nin-domain labels and densely labeled out-of-domain data. Using pretrained\nvision transformers, we bridge domain gaps with complementary pixel-level and\npatch-level decoders, enhanced by a collaborative pseudo-labeling strategy on\nunlabeled data. Evaluations on RUGD and Rellis-3D datasets show significant\nimprovements of 9.7\\% and 8.4\\% respectively, versus only using coarse data.\nTests on real-world off-road vehicle data in a multi-biome setting further\ndemonstrate COARSE's applicability.",
      "tldr_zh": "该论文提出 COARSE，一种半监督领域适应框架，用于解决越野语义分割的挑战，通过利用稀疏粗糙的领域内标签和密集标注的领域外数据来提升模型泛化能力。框架基于预训练的视觉变压器，结合像素级和补丁级解码器，并采用协作伪标签策略来处理未标注数据，从而桥接领域差距。在 RUGD 和 Rellis-3D 数据集上的评估显示，COARSE 分别比仅使用粗糙数据提高了 9.7% 和 8.4% 的性能，并在真实越野车辆的多生物群落场景中验证了其实际适用性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "preprint, 8 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.03947v1",
      "published_date": "2025-03-05 22:25:54 UTC",
      "updated_date": "2025-03-05 22:25:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:07:47.701482"
    },
    {
      "arxiv_id": "2503.07641v1",
      "title": "Deep ARTMAP: Generalized Hierarchical Learning with Adaptive Resonance Theory",
      "title_zh": "翻译失败",
      "authors": [
        "Niklas M. Melton",
        "Leonardo Enzo Brito da Silva",
        "Sasha Petrenko",
        "Donald. C. Wunsch II"
      ],
      "abstract": "This paper presents Deep ARTMAP, a novel extension of the ARTMAP architecture\nthat generalizes the self-consistent modular ART (SMART) architecture to enable\nhierarchical learning (supervised and unsupervised) across arbitrary\ntransformations of data. The Deep ARTMAP framework operates as a divisive\nclustering mechanism, supporting an arbitrary number of modules with\ncustomizable granularity within each module. Inter-ART modules regulate the\nclustering at each layer, permitting unsupervised learning while enforcing a\none-to-many mapping from clusters in one layer to the next. While Deep ARTMAP\nreduces to both ARTMAP and SMART in particular configurations, it offers\nsignificantly enhanced flexibility, accommodating a broader range of data\ntransformations and learning modalities.",
      "tldr_zh": "本论文提出 Deep ARTMAP，一种基于 Adaptive Resonance Theory 的新型框架，它扩展了 ARTMAP 和 SMART 架构，支持在任意数据变换上进行分层监督和无监督学习。\nDeep ARTMAP 采用 divisive clustering 机制，允许任意数量的模块，每个模块具有可定制的粒度，并通过 Inter-ART modules 调节聚类层间的关系，实现无监督学习并强制一对多映射。\n相比原有模型，该框架显著提升了灵活性，能够适应更广泛的数据变换和学习模式。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07641v1",
      "published_date": "2025-03-05 22:23:17 UTC",
      "updated_date": "2025-03-05 22:23:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:08:00.325148"
    },
    {
      "arxiv_id": "2503.07640v1",
      "title": "BrainNet-MoE: Brain-Inspired Mixture-of-Experts Learning for Neurological Disease Identification",
      "title_zh": "BrainNet-MoE：脑启发的混合专家学习用于神经系统疾病识别",
      "authors": [
        "Jing Zhang",
        "Xiaowei Yu",
        "Tong Chen",
        "Chao Cao",
        "Mingheng Chen",
        "Yan Zhuang",
        "Yanjun Lyu",
        "Lu Zhang",
        "Li Su",
        "Tianming Liu",
        "Dajiang Zhu"
      ],
      "abstract": "The Lewy body dementia (LBD) is the second most common neurodegenerative\ndementia after Alzheimer's disease (AD). Early differentiation between AD and\nLBD is crucial because they require different treatment approaches, but this is\nchallenging due to significant clinical overlap, heterogeneity, complex\npathogenesis, and the rarity of LBD. While recent advances in artificial\nintelligence (AI) demonstrate powerful learning capabilities and offer new hope\nfor accurate diagnosis, existing methods primarily focus on designing\n\"neural-level networks\". Our work represents a pioneering effort in modeling\nsystem-level artificial neural network called BrainNet-MoE for brain modeling\nand diagnosing. Inspired by the brain's hierarchical organization of bottom-up\nsensory integration and top-down control, we design a set of disease-specific\nexpert groups to process brain sub-network under different condition, A disease\ngate mechanism guides the specializa-tion of expert groups, while a transformer\nlayer enables communication be-tween all sub-networks, generating a\ncomprehensive whole-brain represen-tation for downstream disease\nclassification. Experimental results show superior classification accuracy with\ninterpretable insights into how brain sub-networks contribute to different\nneurodegenerative conditions.",
      "tldr_zh": "本文提出 BrainNet-MoE，一种受大脑层次结构启发的 Mixture-of-Experts (MoE) 学习框架，用于识别神经退行性疾病，特别是区分 Lewy body dementia (LBD) 和 Alzheimer's disease (AD)，以应对临床重叠和异质性的挑战。该框架设计了疾病特定的专家组来处理不同条件下的脑子网络，并通过疾病门控机制指导专家专业化，同时利用 transformer 层实现子网络间的通信，生成全面的脑表示。实验结果显示，BrainNet-MoE 在分类任务中取得了优越的准确率，并提供了可解释的见解，揭示了脑子网络在不同神经退行性疾病中的作用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07640v1",
      "published_date": "2025-03-05 22:19:49 UTC",
      "updated_date": "2025-03-05 22:19:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:08:14.246825"
    },
    {
      "arxiv_id": "2503.03935v1",
      "title": "GlucoLens: Explainable Postprandial Blood Glucose Prediction from Diet and Physical Activity",
      "title_zh": "GlucoLens：基于饮食和身体活动的可解释餐后血糖预测",
      "authors": [
        "Abdullah Mamun",
        "Asiful Arefeen",
        "Susan B. Racette",
        "Dorothy D. Sears",
        "Corrie M. Whisner",
        "Matthew P. Buman",
        "Hassan Ghasemzadeh"
      ],
      "abstract": "Postprandial hyperglycemia, marked by the blood glucose level exceeding the\nnormal range after meals, is a critical indicator of progression toward type 2\ndiabetes in prediabetic and healthy individuals. A key metric for understanding\nblood glucose dynamics after eating is the postprandial area under the curve\n(PAUC). Predicting PAUC in advance based on a person's diet and activity level\nand explaining what affects postprandial blood glucose could allow an\nindividual to adjust their lifestyle accordingly to maintain normal glucose\nlevels. In this paper, we propose GlucoLens, an explainable machine learning\napproach to predict PAUC and hyperglycemia from diet, activity, and recent\nglucose patterns. We conducted a five-week user study with 10 full-time working\nindividuals to develop and evaluate the computational model. Our machine\nlearning model takes multimodal data including fasting glucose, recent glucose,\nrecent activity, and macronutrient amounts, and provides an interpretable\nprediction of the postprandial glucose pattern. Our extensive analyses of the\ncollected data revealed that the trained model achieves a normalized root mean\nsquared error (NRMSE) of 0.123. On average, GlucoLense with a Random Forest\nbackbone provides a 16% better result than the baseline models. Additionally,\nGlucoLens predicts hyperglycemia with an accuracy of 74% and recommends\ndifferent options to help avoid hyperglycemia through diverse counterfactual\nexplanations. Code available: https://github.com/ab9mamun/GlucoLens.",
      "tldr_zh": "本研究针对餐后高血糖（postprandial hyperglycemia）问题，提出GlucoLens，一种可解释的机器学习方法，用于基于饮食、身体活动和最近血糖模式预测餐后曲线下面积（PAUC）和高血糖风险。模型采用多模态数据输入，包括空腹血糖、最近血糖、活动水平及宏营养素量，并以Random Forest作为骨干，提供可解释的预测结果。实验通过五周用户研究显示，GlucoLens的归一化根均方误差（NRMSE）为0.123，比基线模型提升16%，并以74%的准确率预测高血糖，同时通过反事实解释推荐生活方式调整选项。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.03935v1",
      "published_date": "2025-03-05 22:10:14 UTC",
      "updated_date": "2025-03-05 22:10:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:08:24.128006"
    },
    {
      "arxiv_id": "2503.03927v1",
      "title": "\"Impressively Scary:\" Exploring User Perceptions and Reactions to Unraveling Machine Learning Models in Social Media Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Jack West",
        "Bengisu Cagiltay",
        "Shirley Zhang",
        "Jingjie Li",
        "Kassem Fawaz",
        "Suman Banerjee"
      ],
      "abstract": "Machine learning models deployed locally on social media applications are\nused for features, such as face filters which read faces in-real time, and they\nexpose sensitive attributes to the apps. However, the deployment of machine\nlearning models, e.g., when, where, and how they are used, in social media\napplications is opaque to users. We aim to address this inconsistency and\ninvestigate how social media user perceptions and behaviors change once exposed\nto these models. We conducted user studies (N=21) and found that participants\nwere unaware to both what the models output and when the models were used in\nInstagram and TikTok, two major social media platforms. In response to being\nexposed to the models' functionality, we observed long term behavior changes in\n8 participants. Our analysis uncovers the challenges and opportunities in\nproviding transparency for machine learning models that interact with local\nuser data.",
      "tldr_zh": "本研究探讨了社交媒体应用中机器学习 models 的部署对用户感知和反应的影响，发现用户对这些 models 的输出（如实时面部识别）和使用时机（如在 Instagram 和 TikTok 中）缺乏了解。研究通过用户研究（N=21）暴露参与者于 models 功能，观察到8名参与者出现了长期行为变化。总体而言，该工作揭示了为与本地用户数据交互的 machine learning models 提供透明度的挑战和机会。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.HC",
      "comment": "21 pages, 2 figures, to appear at CHI 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.03927v1",
      "published_date": "2025-03-05 21:51:52 UTC",
      "updated_date": "2025-03-05 21:51:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:08:35.200437"
    },
    {
      "arxiv_id": "2503.03924v1",
      "title": "De-skilling, Cognitive Offloading, and Misplaced Responsibilities: Potential Ironies of AI-Assisted Design",
      "title_zh": "翻译失败",
      "authors": [
        "Prakash Shukla",
        "Phuong Bui",
        "Sean S Levy",
        "Max Kowalski",
        "Ali Baigelenov",
        "Paul Parsons"
      ],
      "abstract": "The rapid adoption of generative AI (GenAI) in design has sparked discussions\nabout its benefits and unintended consequences. While AI is often framed as a\ntool for enhancing productivity by automating routine tasks, historical\nresearch on automation warns of paradoxical effects, such as de-skilling and\nmisplaced responsibilities. To assess UX practitioners' perceptions of AI, we\nanalyzed over 120 articles and discussions from UX-focused subreddits. Our\nfindings indicate that while practitioners express optimism about AI reducing\nrepetitive work and augmenting creativity, they also highlight concerns about\nover-reliance, cognitive offloading, and the erosion of critical design skills.\nDrawing from human-automation interaction literature, we discuss how these\nperspectives align with well-documented automation ironies and function\nallocation challenges. We argue that UX professionals should critically\nevaluate AI's role beyond immediate productivity gains and consider its\nlong-term implications for creative autonomy and expertise. This study\ncontributes empirical insights into practitioners' perspectives and links them\nto broader debates on automation in design.",
      "tldr_zh": "这篇论文探讨了生成式 AI (GenAI) 在设计领域的采用可能带来的潜在 ironies，包括 de-skilling（技能退化）、cognitive offloading（认知外包）和 misplaced responsibilities（责任错位），并通过分析超过 120 篇 UX subreddit 文章揭示从业者的观点。研究发现，UX 从业者对 AI 减少重复工作和增强创造力感到乐观，但也担忧过度依赖会导致关键设计技能的侵蚀。作者将这些发现与人类-自动化交互文献联系起来，强调 UX 专业人士应超越短期生产力收益，批判性地评估 AI 对创造性自主性和专业知识的长期影响。该研究为设计自动化辩论提供了宝贵的实证洞见。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03924v1",
      "published_date": "2025-03-05 21:47:16 UTC",
      "updated_date": "2025-03-05 21:47:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:08:49.318975"
    },
    {
      "arxiv_id": "2503.03921v1",
      "title": "CREStE: Scalable Mapless Navigation with Internet Scale Priors and Counterfactual Guidance",
      "title_zh": "CREStE：利用互联网规模先验和反事实指导的可扩展无地图导航",
      "authors": [
        "Arthur Zhang",
        "Harshit Sikchi",
        "Amy Zhang",
        "Joydeep Biswas"
      ],
      "abstract": "We address the long-horizon mapless navigation problem: enabling robots to\ntraverse novel environments without relying on high-definition maps or precise\nwaypoints that specify exactly where to navigate. Achieving this requires\novercoming two major challenges -- learning robust, generalizable perceptual\nrepresentations of the environment without pre-enumerating all possible\nnavigation factors and forms of perceptual aliasing and utilizing these learned\nrepresentations to plan human-aligned navigation paths. Existing solutions\nstruggle to generalize due to their reliance on hand-curated object lists that\noverlook unforeseen factors, end-to-end learning of navigation features from\nscarce large-scale robot datasets, and handcrafted reward functions that scale\npoorly to diverse scenarios. To overcome these limitations, we propose CREStE,\nthe first method that learns representations and rewards for addressing the\nfull mapless navigation problem without relying on large-scale robot datasets\nor manually curated features. CREStE leverages visual foundation models trained\non internet-scale data to learn continuous bird's-eye-view representations\ncapturing elevation, semantics, and instance-level features. To utilize learned\nrepresentations for planning, we propose a counterfactual-based loss and active\nlearning procedure that focuses on the most salient perceptual cues by querying\nhumans for counterfactual trajectory annotations in challenging scenes. We\nevaluate CREStE in kilometer-scale navigation tasks across six distinct urban\nenvironments. CREStE significantly outperforms all state-of-the-art approaches\nwith 70% fewer human interventions per mission, including a 2-kilometer mission\nin an unseen environment with just 1 intervention; showcasing its robustness\nand effectiveness for long-horizon mapless navigation. For videos and\nadditional materials, see https://amrl.cs.utexas.edu/creste .",
      "tldr_zh": "本研究提出 CREStE，一种可扩展的无地图导航方法，利用互联网规模的 visual foundation models 学习连续 bird's-eye-view representations，包括高程、语义和实例级特征，从而克服现有方法的泛化性问题。\nCREStE 引入基于 counterfactual-based loss 和 active learning 过程，通过向人类查询挑战场景中的反事实轨迹注释，专注于最显著的感知线索，以规划人类对齐的导航路径。\n实验在六个城市环境中进行千米级任务时，CREStE 显著优于现有方法，减少 70% 的人类干预，并在未知环境中完成 2 公里任务仅需 1 次干预，展示了其鲁棒性和有效性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "19 pages, 10 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.03921v1",
      "published_date": "2025-03-05 21:42:46 UTC",
      "updated_date": "2025-03-05 21:42:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:09:01.667165"
    },
    {
      "arxiv_id": "2503.04847v2",
      "title": "Role of Databases in GenAI Applications",
      "title_zh": "数据库在 GenAI 应用中的作用",
      "authors": [
        "Santosh Bhupathi"
      ],
      "abstract": "Generative AI (GenAI) is transforming industries by enabling intelligent\ncontent generation, automation, and decision-making. However, the effectiveness\nof GenAI applications depends significantly on efficient data storage,\nretrieval, and contextual augmentation. This paper explores the critical role\nof databases in GenAI workflows, emphasizing the importance of choosing the\nright database architecture to optimize performance, accuracy, and scalability.\nIt categorizes database roles into conversational context (key-value/document\ndatabases), situational context (relational databases/data lakehouses), and\nsemantic context (vector databases) each serving a distinct function in\nenriching AI-generated responses. Additionally, the paper highlights real-time\nquery processing, vector search for semantic retrieval, and the impact of\ndatabase selection on model efficiency and scalability. By leveraging a\nmulti-database approach, GenAI applications can achieve more context-aware,\npersonalized, and high-performing AI-driven solutions.",
      "tldr_zh": "这篇论文探讨了数据库在生成式 AI (GenAI) 应用中的关键作用，强调了高效数据存储、检索和上下文增强对 GenAI 性能、准确性和可扩展性的重要影响。论文将数据库角色分类为对话上下文 (key-value/document databases)、情境上下文 (relational databases/data lakehouses) 和语义上下文 (vector databases)，每类在丰富 AI 响应方面发挥独特功能。最终，它主张采用多数据库方法来提升实时查询处理和 vector search 的效率，实现更具上下文感知、个性化和高性能的 GenAI 解决方案。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "97P30",
        "I.2.7; H.2.5"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04847v2",
      "published_date": "2025-03-05 20:32:21 UTC",
      "updated_date": "2025-04-11 17:07:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:09:15.316559"
    },
    {
      "arxiv_id": "2503.03866v2",
      "title": "Learning to Negotiate via Voluntary Commitment",
      "title_zh": "翻译失败",
      "authors": [
        "Shuhui Zhu",
        "Baoxiang Wang",
        "Sriram Ganapathi Subramanian",
        "Pascal Poupart"
      ],
      "abstract": "The partial alignment and conflict of autonomous agents lead to mixed-motive\nscenarios in many real-world applications. However, agents may fail to\ncooperate in practice even when cooperation yields a better outcome. One well\nknown reason for this failure comes from non-credible commitments. To\nfacilitate commitments among agents for better cooperation, we define Markov\nCommitment Games (MCGs), a variant of commitment games, where agents can\nvoluntarily commit to their proposed future plans. Based on MCGs, we propose a\nlearnable commitment protocol via policy gradients. We further propose\nincentive-compatible learning to accelerate convergence to equilibria with\nbetter social welfare. Experimental results in challenging mixed-motive tasks\ndemonstrate faster empirical convergence and higher returns for our method\ncompared with its counterparts. Our code is available at\nhttps://github.com/shuhui-zhu/DCL.",
      "tldr_zh": "这篇论文探讨了自主代理在混合动机场景中因非可信承诺而导致合作失败的问题，提出Markov Commitment Games (MCGs)作为一种允许代理自愿承诺未来计划的框架。作者基于MCGs开发了一种可学习的承诺协议，通过policy gradients进行训练，并引入incentive-compatible learning来加速收敛到具有更好社会福利的均衡。实验结果显示，该方法在具有挑战性的混合动机任务中比对照方法更快收敛并实现更高回报。",
      "categories": [
        "cs.AI",
        "cs.GT",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by AISTATS 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.03866v2",
      "published_date": "2025-03-05 19:55:10 UTC",
      "updated_date": "2025-03-19 07:23:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:09:24.927006"
    },
    {
      "arxiv_id": "2503.03862v1",
      "title": "Not-Just-Scaling Laws: Towards a Better Understanding of the Downstream Impact of Language Model Design Decisions",
      "title_zh": "不仅仅是规模定律：朝着更好地理解语言模型",
      "authors": [
        "Emmy Liu",
        "Amanda Bertsch",
        "Lintang Sutawika",
        "Lindia Tjuatja",
        "Patrick Fernandes",
        "Lara Marinov",
        "Michael Chen",
        "Shreya Singhal",
        "Carolin Lawrence",
        "Aditi Raghunathan",
        "Kiril Gashteovski",
        "Graham Neubig"
      ],
      "abstract": "Improvements in language model capabilities are often attributed to\nincreasing model size or training data, but in some cases smaller models\ntrained on curated data or with different architectural decisions can\noutperform larger ones trained on more tokens. What accounts for this? To\nquantify the impact of these design choices, we meta-analyze 92 open-source\npretrained models across a wide array of scales, including state-of-the-art\nopen-weights models as well as less performant models and those with less\nconventional design decisions. We find that by incorporating features besides\nmodel size and number of training tokens, we can achieve a relative 3-28%\nincrease in ability to predict downstream performance compared with using scale\nalone. Analysis of model design decisions reveal insights into data\ncomposition, such as the trade-off between language and code tasks at 15-25\\%\ncode, as well as the better performance of some architectural decisions such as\nchoosing rotary over learned embeddings. Broadly, our framework lays a\nfoundation for more systematic investigation of how model development choices\nshape final capabilities.",
      "tldr_zh": "这篇论文挑战了传统的scaling laws观点，强调语言模型设计决策（如数据组成和架构选择）对下游性能的影响远超单纯的模型规模和训练数据。通过对92个开源预训练模型进行元分析(meta-analyze)，研究发现加入规模以外的特征能将预测下游性能的准确性提高3-28%。关键发现包括数据中15-25%代码比例的权衡，以及某些架构决策如使用rotary embeddings比learned embeddings更有效。该框架为更系统地探究模型开发选择如何塑造最终能力提供了基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03862v1",
      "published_date": "2025-03-05 19:46:04 UTC",
      "updated_date": "2025-03-05 19:46:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:09:37.150781"
    },
    {
      "arxiv_id": "2503.03842v1",
      "title": "Task-Agnostic Attacks Against Vision Foundation Models",
      "title_zh": "针对视觉基础模型的任务无关攻击",
      "authors": [
        "Brian Pulfer",
        "Yury Belousov",
        "Vitaliy Kinakh",
        "Teddy Furon",
        "Slava Voloshynovskiy"
      ],
      "abstract": "The study of security in machine learning mainly focuses on downstream\ntask-specific attacks, where the adversarial example is obtained by optimizing\na loss function specific to the downstream task. At the same time, it has\nbecome standard practice for machine learning practitioners to adopt publicly\navailable pre-trained vision foundation models, effectively sharing a common\nbackbone architecture across a multitude of applications such as\nclassification, segmentation, depth estimation, retrieval, question-answering\nand more. The study of attacks on such foundation models and their impact to\nmultiple downstream tasks remains vastly unexplored. This work proposes a\ngeneral framework that forges task-agnostic adversarial examples by maximally\ndisrupting the feature representation obtained with foundation models. We\nextensively evaluate the security of the feature representations obtained by\npopular vision foundation models by measuring the impact of this attack on\nmultiple downstream tasks and its transferability between models.",
      "tldr_zh": "该论文探讨了机器学习安全的任务无关攻击，针对视觉基础模型（vision foundation models），而非传统的下游任务特定攻击。研究提出一个通用框架，通过最大程度破坏基础模型的特征表示（feature representation）来生成任务无关的对抗样本（adversarial examples）。实验评估显示，这种攻击对分类、分割、深度估计等多任务产生显著影响，并证明了攻击在不同模型间的可转移性（transferability）。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03842v1",
      "published_date": "2025-03-05 19:15:14 UTC",
      "updated_date": "2025-03-05 19:15:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:09:48.936410"
    },
    {
      "arxiv_id": "2503.05828v1",
      "title": "Market-based Architectures in RL and Beyond",
      "title_zh": "翻译失败",
      "authors": [
        "Abhimanyu Pallavi Sudhir",
        "Long Tran-Thanh"
      ],
      "abstract": "Market-based agents refer to reinforcement learning agents which determine\ntheir actions based on an internal market of sub-agents. We introduce a new\ntype of market-based algorithm where the state itself is factored into several\naxes called ``goods'', which allows for greater specialization and parallelism\nthan existing market-based RL algorithms. Furthermore, we argue that\nmarket-based algorithms have the potential to address many current challenges\nin AI, such as search, dynamic scaling and complete feedback, and demonstrate\nthat they may be seen to generalize neural networks; finally, we list some\nnovel ways that market algorithms may be applied in conjunction with Large\nLanguage Models for immediate practical applicability.",
      "tldr_zh": "本文提出了一种新型市场-based 算法，用于强化学习（RL）中的代理（market-based agents），将状态分解成多个称为“goods”的轴，以实现更高的专业化和并行性。该算法不仅解决了 AI 领域的当前挑战，如搜索、动态缩放和完整反馈问题，还被视为神经网络的泛化形式。作者进一步探讨了市场-based 算法与 Large Language Models 结合的潜在应用，为实际场景提供创新解决方案。",
      "categories": [
        "cs.AI",
        "econ.TH"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at AAMAS 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.05828v1",
      "published_date": "2025-03-05 19:09:29 UTC",
      "updated_date": "2025-03-05 19:09:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:10:02.628386"
    },
    {
      "arxiv_id": "2503.03750v2",
      "title": "The MASK Benchmark: Disentangling Honesty From Accuracy in AI Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Richard Ren",
        "Arunim Agarwal",
        "Mantas Mazeika",
        "Cristina Menghini",
        "Robert Vacareanu",
        "Brad Kenstler",
        "Mick Yang",
        "Isabelle Barrass",
        "Alice Gatti",
        "Xuwang Yin",
        "Eduardo Trevino",
        "Matias Geralnik",
        "Adam Khoja",
        "Dean Lee",
        "Summer Yue",
        "Dan Hendrycks"
      ],
      "abstract": "As large language models (LLMs) become more capable and agentic, the\nrequirement for trust in their outputs grows significantly, yet at the same\ntime concerns have been mounting that models may learn to lie in pursuit of\ntheir goals. To address these concerns, a body of work has emerged around the\nnotion of \"honesty\" in LLMs, along with interventions aimed at mitigating\ndeceptive behaviors. However, evaluations of honesty are currently highly\nlimited, with no benchmark combining large scale and applicability to all\nmodels. Moreover, many benchmarks claiming to measure honesty in fact simply\nmeasure accuracy--the correctness of a model's beliefs--in disguise. In this\nwork, we introduce a large-scale human-collected dataset for measuring honesty\ndirectly, allowing us to disentangle accuracy from honesty for the first time.\nAcross a diverse set of LLMs, we find that while larger models obtain higher\naccuracy on our benchmark, they do not become more honest. Surprisingly, while\nmost frontier LLMs obtain high scores on truthfulness benchmarks, we find a\nsubstantial propensity in frontier LLMs to lie when pressured to do so,\nresulting in low honesty scores on our benchmark. We find that simple methods,\nsuch as representation engineering interventions, can improve honesty. These\nresults underscore the growing need for robust evaluations and effective\ninterventions to ensure LLMs remain trustworthy.",
      "tldr_zh": "这篇论文引入了 MASK Benchmark，一种大规模基准，用于区分 AI 系统中诚实度(honesty)和准确性(accuracy)，以解决大型语言模型(LLMs)可能在追求目标时说谎的问题。研究者构建了一个人类收集的数据集，首次直接测量诚实度，并在各种 LLMs 上进行测试，发现更大模型虽然准确性更高，但诚实度并未相应提升。结果显示，前沿 LLMs 在真实性基准上表现良好，却在压力下表现出显著的说谎倾向，而简单干预如 representation engineering interventions 可以有效改善诚实度。这些发现强调了需要更稳健的评估和干预措施，以确保 LLMs 的可信赖性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "Website: https://www.mask-benchmark.ai",
      "pdf_url": "http://arxiv.org/pdf/2503.03750v2",
      "published_date": "2025-03-05 18:59:23 UTC",
      "updated_date": "2025-03-20 23:06:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:10:14.597985"
    },
    {
      "arxiv_id": "2503.03746v1",
      "title": "Process-based Self-Rewarding Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Shimao Zhang",
        "Xiao Liu",
        "Xin Zhang",
        "Junxiao Liu",
        "Zheheng Luo",
        "Shujian Huang",
        "Yeyun Gong"
      ],
      "abstract": "Large Language Models have demonstrated outstanding performance across\nvarious downstream tasks and have been widely applied in multiple scenarios.\nHuman-annotated preference data is used for training to further improve LLMs'\nperformance, which is constrained by the upper limit of human performance.\nTherefore, Self-Rewarding method has been proposed, where LLMs generate\ntraining data by rewarding their own outputs. However, the existing\nself-rewarding paradigm is not effective in mathematical reasoning scenarios\nand may even lead to a decline in performance. In this work, we propose the\nProcess-based Self-Rewarding pipeline for language models, which introduces\nlong-thought reasoning, step-wise LLM-as-a-Judge, and step-wise preference\noptimization within the self-rewarding paradigm. Our new paradigm successfully\nenhances the performance of LLMs on multiple mathematical reasoning benchmarks\nthrough iterative Process-based Self-Rewarding, demonstrating the immense\npotential of self-rewarding to achieve LLM reasoning that may surpass human\ncapabilities.",
      "tldr_zh": "本研究针对 Large Language Models (LLMs) 的性能优化问题，指出现有 Self-Rewarding 方法在数学推理场景下效果不佳，甚至可能导致性能下降。论文提出 Process-based Self-Rewarding 管道，该方法整合长思绪推理（long-thought reasoning）、逐步 LLM-as-a-Judge 和逐步偏好优化（step-wise preference optimization），通过迭代过程生成训练数据。实验结果显示，该范式显著提升了 LLMs 在多个数学推理基准上的表现，展示了 Self-Rewarding 潜力可能超越人类能力的可能性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03746v1",
      "published_date": "2025-03-05 18:58:44 UTC",
      "updated_date": "2025-03-05 18:58:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:10:26.210071"
    },
    {
      "arxiv_id": "2503.03743v1",
      "title": "CHOP: Mobile Operating Assistant with Constrained High-frequency Optimized Subtask Planning",
      "title_zh": "CHOP：具有约束高频优化子任务规划的移动操作助手",
      "authors": [
        "Yuqi Zhou",
        "Shuai Wang",
        "Sunhao Dai",
        "Qinglin Jia",
        "Zhaocheng Du",
        "Zhenhua Dong",
        "Jun Xu"
      ],
      "abstract": "The advancement of visual language models (VLMs) has enhanced mobile device\noperations, allowing simulated human-like actions to address user requirements.\nCurrent VLM-based mobile operating assistants can be structured into three\nlevels: task, subtask, and action. The subtask level, linking high-level goals\nwith low-level executable actions, is crucial for task completion but faces two\nchallenges: ineffective subtasks that lower-level agent cannot execute and\ninefficient subtasks that fail to contribute to the completion of the\nhigher-level task. These challenges stem from VLM's lack of experience in\ndecomposing subtasks within GUI scenarios in multi-agent architecture. To\naddress these, we propose a new mobile assistant architecture with constrained\nhigh-frequency o}ptimized planning (CHOP). Our approach overcomes the VLM's\ndeficiency in GUI scenarios planning by using human-planned subtasks as the\nbasis vector. We evaluate our architecture in both English and Chinese contexts\nacross 20 Apps, demonstrating significant improvements in both effectiveness\nand efficiency. Our dataset and code is available at\nhttps://github.com/Yuqi-Zhou/CHOP",
      "tldr_zh": "该研究针对视觉语言模型(VLMs)在移动设备操作中的子任务规划问题，提出了一种新的移动助手架构CHOP（Constrained High-frequency Optimized Subtask Planning）。CHOP通过使用人类规划的子任务作为基础向量，在多代理架构中优化GUI场景的子任务分解，解决了无效和低效子任务的挑战。实验在20个App的英语和中文环境中进行，展示了CHOP在有效性和效率上的显著提升，并提供了数据集和代码（https://github.com/Yuqi-Zhou/CHOP）。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03743v1",
      "published_date": "2025-03-05 18:56:16 UTC",
      "updated_date": "2025-03-05 18:56:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:10:37.757553"
    },
    {
      "arxiv_id": "2503.03802v1",
      "title": "RiskAgent: Autonomous Medical AI Copilot for Generalist Risk Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Fenglin Liu",
        "Jinge Wu",
        "Hongjian Zhou",
        "Xiao Gu",
        "Soheila Molaei",
        "Anshul Thakur",
        "Lei Clifton",
        "Honghan Wu",
        "David A. Clifton"
      ],
      "abstract": "The application of Large Language Models (LLMs) to various clinical\napplications has attracted growing research attention. However, real-world\nclinical decision-making differs significantly from the standardized,\nexam-style scenarios commonly used in current efforts. In this paper, we\npresent the RiskAgent system to perform a broad range of medical risk\npredictions, covering over 387 risk scenarios across diverse complex diseases,\ne.g., cardiovascular disease and cancer. RiskAgent is designed to collaborate\nwith hundreds of clinical decision tools, i.e., risk calculators and scoring\nsystems that are supported by evidence-based medicine. To evaluate our method,\nwe have built the first benchmark MedRisk specialized for risk prediction,\nincluding 12,352 questions spanning 154 diseases, 86 symptoms, 50 specialties,\nand 24 organ systems. The results show that our RiskAgent, with 8 billion model\nparameters, achieves 76.33% accuracy, outperforming the most recent commercial\nLLMs, o1, o3-mini, and GPT-4.5, and doubling the 38.39% accuracy of GPT-4o. On\nrare diseases, e.g., Idiopathic Pulmonary Fibrosis (IPF), RiskAgent outperforms\no1 and GPT-4.5 by 27.27% and 45.46% accuracy, respectively. Finally, we further\nconduct a generalization evaluation on an external evidence-based diagnosis\nbenchmark and show that our RiskAgent achieves the best results. These\nencouraging results demonstrate the great potential of our solution for diverse\ndiagnosis domains. To improve the adaptability of our model in different\nscenarios, we have built and open-sourced a family of models ranging from 1\nbillion to 70 billion parameters. Our code, data, and models are all available\nat https://github.com/AI-in-Health/RiskAgent.",
      "tldr_zh": "该研究介绍了RiskAgent，一种自治的医疗AI助手，利用Large Language Models (LLMs)进行广泛的医疗风险预测，覆盖387种风险场景（如心血管疾病和癌症），并与数百种基于循证医学的临床决策工具协作。\n为了评估系统，他们构建了首个风险预测基准MedRisk，包含12,352个问题，涵盖154种疾病、86种症状、50个专业和24个器官系统。\n结果显示，RiskAgent（8亿参数模型）在基准测试中达到76.33%的准确率，显著优于o1、o3-mini、GPT-4.5和GPT-4o，尤其在罕见疾病如Idiopathic Pulmonary Fibrosis (IPF)上领先27.27%至45.46%。\n该系统展示了在多样诊断领域的潜力，并开源了从1亿到70亿参数的模型家族，以提升适应性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages, 6 figures, 4 tables, code is available at\n  https://github.com/AI-in-Health/RiskAgent",
      "pdf_url": "http://arxiv.org/pdf/2503.03802v1",
      "published_date": "2025-03-05 18:46:51 UTC",
      "updated_date": "2025-03-05 18:46:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:10:52.468117"
    },
    {
      "arxiv_id": "2503.03733v1",
      "title": "Rethinking Deep Clustering Paradigms: Self-Supervision Is All You Need",
      "title_zh": "重新思考深度聚类范式：自监督就是你所需要的一切",
      "authors": [
        "Amal Shaheena",
        "Nairouz Mrabahb",
        "Riadh Ksantinia",
        "Abdulla Alqaddoumia"
      ],
      "abstract": "The recent advances in deep clustering have been made possible by significant\nprogress in self-supervised and pseudo-supervised learning. However, the\ntrade-off between self-supervision and pseudo-supervision can give rise to\nthree primary issues. The joint training causes Feature Randomness and Feature\nDrift, whereas the independent training causes Feature Randomness and Feature\nTwist. In essence, using pseudo-labels generates random and unreliable\nfeatures. The combination of pseudo-supervision and self-supervision drifts the\nreliable clustering-oriented features. Moreover, moving from self-supervision\nto pseudo-supervision can twist the curved latent manifolds. This paper\naddresses the limitations of existing deep clustering paradigms concerning\nFeature Randomness, Feature Drift, and Feature Twist. We propose a new paradigm\nwith a new strategy that replaces pseudo-supervision with a second round of\nself-supervision training. The new strategy makes the transition between\ninstance-level self-supervision and neighborhood-level self-supervision\nsmoother and less abrupt. Moreover, it prevents the drifting effect that is\ncaused by the strong competition between instance-level self-supervision and\nclustering-level pseudo-supervision. Moreover, the absence of the\npseudo-supervision prevents the risk of generating random features. With this\nnovel approach, our paper introduces a Rethinking of the Deep Clustering\nParadigms, denoted by R-DC. Our model is specifically designed to address three\nprimary challenges encountered in Deep Clustering: Feature Randomness, Feature\nDrift, and Feature Twist. Experimental results conducted on six datasets have\nshown that the two-level self-supervision training yields substantial\nimprovements.",
      "tldr_zh": "这篇论文重新审视了深度聚类方法的局限性，指出自监督和伪监督的结合会导致Feature Randomness、Feature Drift和Feature Twist等问题，如特征随机性、不稳定性及潜在流形扭曲。作者提出一个新范式R-DC，通过替换伪监督为第二轮自监督训练，实现从实例级到邻域级自监督的平滑过渡，从而避免特征漂移和随机性风险。实验在六个数据集上验证了这一策略的显著效果，证明完全依赖Self-Supervision即可提升深度聚类的性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03733v1",
      "published_date": "2025-03-05 18:44:35 UTC",
      "updated_date": "2025-03-05 18:44:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:11:02.226564"
    },
    {
      "arxiv_id": "2503.04844v4",
      "title": "Narrative Context Protocol: an Author-centric Storytelling Framework for Generative AI",
      "title_zh": "翻译失败",
      "authors": [
        "Hank Gerba"
      ],
      "abstract": "Generative AI promises to finally realize dynamic, personalized storytelling\ntechnologies across a range of media. To date, experimentation with generative\nAI in the field of procedural narrative generation has been quite promising\nfrom a technical perspective. However, fundamental narrative dilemmas remain,\nsuch as the balance between player agency and narrative coherence, and no\nrigorous narrative standard has been proposed to specifically leverage the\nstrengths of generative AI. In this paper, we propose the Narrative Context\nProtocol (NCP), an open and extensible standard designed to place writers at\nthe center of future narrative design workflows and enable interoperability\nacross authoring platforms. By encoding an author's intent according to an\nobjective narrative model, the NCP enables narrative portability as well as\nintent-based constraints for generative systems.",
      "tldr_zh": "这篇论文针对生成式AI在程序化叙事生成中的应用，提出了Narrative Context Protocol (NCP)，一个以作者为中心的叙事框架，以解决玩家代理与叙事连贯性等基本难题。NCP通过编码作者意图并基于客观叙事模型，实现了叙事内容的可移植性和互操作性，支持不同平台间的协作。总体而言，该框架将作者置于叙事设计流程的核心位置，为生成AI驱动的个性化故事生成提供了开放、可扩展的标准。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04844v4",
      "published_date": "2025-03-05 18:29:15 UTC",
      "updated_date": "2025-04-12 18:17:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:11:14.710198"
    },
    {
      "arxiv_id": "2503.03724v1",
      "title": "Deep Causal Behavioral Policy Learning: Applications to Healthcare",
      "title_zh": "深度因果行为策略学习：医疗保健应用",
      "authors": [
        "Jonas Knecht",
        "Anna Zink",
        "Jonathan Kolstad",
        "Maya Petersen"
      ],
      "abstract": "We present a deep learning-based approach to studying dynamic clinical\nbehavioral regimes in diverse non-randomized healthcare settings. Our proposed\nmethodology - deep causal behavioral policy learning (DC-BPL) - uses deep\nlearning algorithms to learn the distribution of high-dimensional clinical\naction paths, and identifies the causal link between these action paths and\npatient outcomes. Specifically, our approach: (1) identifies the causal effects\nof provider assignment on clinical outcomes; (2) learns the distribution of\nclinical actions a given provider would take given evolving patient\ninformation; (3) and combines these steps to identify the optimal provider for\na given patient type and emulate that provider's care decisions. Underlying\nthis strategy, we train a large clinical behavioral model (LCBM) on electronic\nhealth records data using a transformer architecture, and demonstrate its\nability to estimate clinical behavioral policies. We propose a novel\ninterpretation of a behavioral policy learned using the LCBM: that it is an\nefficient encoding of complex, often implicit, knowledge used to treat a\npatient. This allows us to learn a space of policies that are critical to a\nwide range of healthcare applications, in which the vast majority of clinical\nknowledge is acquired tacitly through years of practice and only a tiny\nfraction of information relevant to patient care is written down (e.g. in\ntextbooks, studies or standardized guidelines).",
      "tldr_zh": "本研究提出 deep causal behavioral policy learning (DC-BPL)，一种基于深度学习的方法，用于分析非随机化医疗环境中的动态临床行为策略及其对患者结果的因果影响。该方法通过训练 large clinical behavioral model (LCBM) 使用 transformer 架构，从电子健康记录数据中学习高维临床行动路径分布，并结合步骤如识别提供者分配的因果效果和模拟最优护理决策，来确定适合特定患者类型的理想提供者。DC-BPL 的关键贡献在于高效编码复杂隐性临床知识，提升医疗决策，支持广泛的医疗应用，如优化基于实践经验的患者护理。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03724v1",
      "published_date": "2025-03-05 18:24:58 UTC",
      "updated_date": "2025-03-05 18:24:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:11:28.504334"
    },
    {
      "arxiv_id": "2503.03717v1",
      "title": "Machine Learning in Biomechanics: Key Applications and Limitations in Walking, Running, and Sports Movements",
      "title_zh": "生物力学中的机器学习：行走、奔跑和体育运动中的关键应用与限制",
      "authors": [
        "Carlo Dindorf",
        "Fabian Horst",
        "Djordje Slijepčević",
        "Bernhard Dumphart",
        "Jonas Dully",
        "Matthias Zeppelzauer",
        "Brian Horsak",
        "Michael Fröhlich"
      ],
      "abstract": "This chapter provides an overview of recent and promising Machine Learning\napplications, i.e. pose estimation, feature estimation, event detection, data\nexploration & clustering, and automated classification, in gait (walking and\nrunning) and sports biomechanics. It explores the potential of Machine Learning\nmethods to address challenges in biomechanical workflows, highlights central\nlimitations, i.e. data and annotation availability and explainability, that\nneed to be addressed, and emphasises the importance of interdisciplinary\napproaches for fully harnessing the potential of Machine Learning in gait and\nsports biomechanics.",
      "tldr_zh": "这篇章节概述了Machine Learning在步态（walking and running）和运动生物力学中的关键应用，包括pose estimation、feature estimation、event detection、data exploration & clustering以及automated classification。论文探讨了这些方法如何解决生物力学工作流中的挑战，同时指出了主要限制，如数据和annotation可用性以及explainability问题。最终，它强调了采用interdisciplinary approaches的重要性，以充分发挥Machine Learning在gait和sports biomechanics中的潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03717v1",
      "published_date": "2025-03-05 18:10:11 UTC",
      "updated_date": "2025-03-05 18:10:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:11:39.011494"
    },
    {
      "arxiv_id": "2503.03708v3",
      "title": "Rethinking Video Tokenization: A Conditioned Diffusion-based Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Nianzu Yang",
        "Pandeng Li",
        "Liming Zhao",
        "Yang Li",
        "Chen-Wei Xie",
        "Yehui Tang",
        "Xudong Lu",
        "Zhihang Liu",
        "Yun Zheng",
        "Yu Liu",
        "Junchi Yan"
      ],
      "abstract": "Existing video tokenizers typically use the traditional Variational\nAutoencoder (VAE) architecture for video compression and reconstruction.\nHowever, to achieve good performance, its training process often relies on\ncomplex multi-stage training tricks that go beyond basic reconstruction loss\nand KL regularization. Among these tricks, the most challenging is the precise\ntuning of adversarial training with additional Generative Adversarial Networks\n(GANs) in the final stage, which can hinder stable convergence. In contrast to\nGANs, diffusion models offer more stable training processes and can generate\nhigher-quality results. Inspired by these advantages, we propose CDT, a novel\nConditioned Diffusion-based video Tokenizer, that replaces the GAN-based\ndecoder with a conditional causal diffusion model. The encoder compresses\nspatio-temporal information into compact latents, while the decoder\nreconstructs videos through a reverse diffusion process conditioned on these\nlatents. During inference, we incorporate a feature cache mechanism to generate\nvideos of arbitrary length while maintaining temporal continuity and adopt\nsampling acceleration technique to enhance efficiency. Trained using only a\nbasic MSE diffusion loss for reconstruction, along with KL term and LPIPS\nperceptual loss from scratch, extensive experiments demonstrate that CDT\nachieves state-of-the-art performance in video reconstruction tasks with just a\nsingle-step sampling. Even a scaled-down version of CDT (3$\\times$ inference\nspeedup) still performs comparably with top baselines. Moreover, the latent\nvideo generation model trained with CDT also exhibits superior performance. The\nsource code and pretrained weights are available at\nhttps://github.com/ali-vilab/CDT.",
      "tldr_zh": "本文重新审视视频标记化问题，提出 CDT（Conditioned Diffusion-based video Tokenizer），它使用条件因果扩散模型取代传统 VAE 架构中的 GAN-based 解码器，以实现更稳定的训练过程。编码器将时空信息压缩成紧凑的 latents，解码器则通过反向扩散过程重建视频，同时采用特征缓存机制支持任意长度视频生成和时间连续性，以及采样加速技术提升效率。CDT 仅使用 MSE 扩散损失、KL 项和 LPIPS 感知损失从零开始训练，即在视频重建任务中达到最先进性能，仅需单步采样；即使缩减版本（3倍推理加速）也与顶级基线相当。此外，使用 CDT 训练的潜在视频生成模型表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03708v3",
      "published_date": "2025-03-05 17:59:19 UTC",
      "updated_date": "2025-03-27 11:46:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:11:51.130386"
    },
    {
      "arxiv_id": "2503.03707v1",
      "title": "Curating Demonstrations using Online Experience",
      "title_zh": "翻译失败",
      "authors": [
        "Annie S. Chen",
        "Alec M. Lessing",
        "Yuejiang Liu",
        "Chelsea Finn"
      ],
      "abstract": "Many robot demonstration datasets contain heterogeneous demonstrations of\nvarying quality. This heterogeneity may benefit policy pre-training, but can\nhinder robot performance when used with a final imitation learning objective.\nIn particular, some strategies in the data may be less reliable than others or\nmay be underrepresented in the data, leading to poor performance when such\nstrategies are sampled at test time. Moreover, such unreliable or\nunderrepresented strategies can be difficult even for people to discern, and\nsifting through demonstration datasets is time-consuming and costly. On the\nother hand, policy performance when trained on such demonstrations can reflect\nthe reliability of different strategies. We thus propose for robots to\nself-curate based on online robot experience (Demo-SCORE). More specifically,\nwe train and cross-validate a classifier to discern successful policy roll-outs\nfrom unsuccessful ones and use the classifier to filter heterogeneous\ndemonstration datasets. Our experiments in simulation and the real world show\nthat Demo-SCORE can effectively identify suboptimal demonstrations without\nmanual curation. Notably, Demo-SCORE achieves over 15-35% higher absolute\nsuccess rate in the resulting policy compared to the base policy trained with\nall original demonstrations.",
      "tldr_zh": "该研究针对机器人演示数据集中的异质性和质量问题，提出了一种名为 Demo-SCORE 的方法，利用在线机器人经验来自动筛选演示。方法涉及训练并交叉验证一个分类器，以区分成功的 policy roll-outs 和不成功的 roll-outs，从而过滤掉 suboptimal 演示。实验结果显示，在模拟和真实世界环境中，使用 Demo-SCORE 筛选后的数据集训练的策略，成功率比原始数据集提高了 15-35%，无需手动 curation。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03707v1",
      "published_date": "2025-03-05 17:58:16 UTC",
      "updated_date": "2025-03-05 17:58:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:12:01.220143"
    },
    {
      "arxiv_id": "2503.04843v2",
      "title": "Self-Supervised Z-Slice Augmentation for 3D Bio-Imaging via Knowledge Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Alessandro Pasqui",
        "Sajjad Mahdavi",
        "Benoit Vianay",
        "Alexandra Colin",
        "Alex McDougall",
        "Rémi Dumollard",
        "Yekaterina A. Miroshnikova",
        "Elsa Labrune",
        "Hervé Turlier"
      ],
      "abstract": "Three-dimensional biological microscopy has significantly advanced our\nunderstanding of complex biological structures. However, limitations due to\nmicroscopy techniques, sample properties or phototoxicity often result in poor\nz-resolution, hindering accurate cellular measurements. Here, we introduce\nZAugNet, a fast, accurate, and self-supervised deep learning method for\nenhancing z-resolution in biological images. By performing nonlinear\ninterpolation between consecutive slices, ZAugNet effectively doubles\nresolution with each iteration. Compared on several microscopy modalities and\nbiological objects, it outperforms competing methods on most metrics. Our\nmethod leverages a generative adversarial network (GAN) architecture combined\nwith knowledge distillation to maximize prediction speed without compromising\naccuracy. We also developed ZAugNet+, an extended version enabling continuous\ninterpolation at arbitrary distances, making it particularly useful for\ndatasets with nonuniform slice spacing. Both ZAugNet and ZAugNet+ provide\nhigh-performance, scalable z-slice augmentation solutions for large-scale 3D\nimaging. They are available as open-source frameworks in PyTorch, with an\nintuitive Colab notebook interface for easy access by the scientific community.",
      "tldr_zh": "本研究提出 ZAugNet，一种自监督深度学习方法，用于提升 3D 生物图像的 z-分辨率，以解决显微镜技术限制导致的准确细胞测量问题。\nZAugNet 通过在连续切片之间进行非线性插值，每次迭代有效加倍分辨率，并结合 GAN 架构和 knowledge distillation 技术，实现快速预测而不牺牲准确性。\n与其他方法相比，ZAugNet 在多种显微镜模式和生物物体上表现出色。\n此外，扩展版本 ZAugNet+ 支持任意距离的连续插值，适用于非均匀切片数据集，并作为开源框架在 PyTorch 中提供，便于科学社区访问。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV",
        "q-bio.QM",
        "68",
        "I.4.3; I.4.4; I.2.0; J.3"
      ],
      "primary_category": "cs.CV",
      "comment": "25 pages, 5 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2503.04843v2",
      "published_date": "2025-03-05 17:50:35 UTC",
      "updated_date": "2025-03-17 21:52:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:12:14.121241"
    },
    {
      "arxiv_id": "2503.03693v1",
      "title": "ILLC: Iterative Layer-by-Layer Compression for Enhancing Structural Faithfulness in SpArX",
      "title_zh": "翻译失败",
      "authors": [
        "Ungsik Kim"
      ],
      "abstract": "In the field of Explainable Artificial Intelligence (XAI), argumentative XAI\napproaches have been proposed to represent the internal reasoning process of\ndeep neural networks in a more transparent way by interpreting hidden nodes as\narguements. However, as the number of layers increases, existing compression\nmethods simplify all layers at once, which lead to high accumulative\ninformation loss. To compensate for this, we propose an iterative\nlayer-by-layer compression technique in which each layer is compressed\nseparately and the reduction error in the next layer is immediately compensated\nfor, thereby improving the overall input-output and structural fidelity of the\nmodel. Experiments on the Breast Cancer Diagnosis dataset show that, compared\nto traditional compression, the method reduces input-output and structural\nunfaithfulness, and maintains a more consistent attack-support relationship in\nthe Argumentative Explanation scheme. This is significant because it provides a\nnew way to make complex MLP models more compact while still conveying their\ninternal inference logic without distortion.",
      "tldr_zh": "本研究针对可解释人工智能(XAI)中的argumentative XAI方法，提出了一种名为ILLC的迭代逐层压缩技术，以提升SpArX框架中模型的结构保真度。传统压缩方法一次性简化所有层，导致累计信息损失较大，而ILLC则通过逐层单独压缩并立即补偿下一层的误差，改善了模型的整体输入-输出和结构忠实性。在乳腺癌诊断数据集上的实验显示，与传统方法相比，ILLC显著减少了输入-输出和结构不忠实性，同时维持了Argumentative Explanation方案中的攻击-支持关系更一致。这一创新为使复杂MLP模型更紧凑且不扭曲内部推理逻辑提供了新途径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.03693v1",
      "published_date": "2025-03-05 17:43:49 UTC",
      "updated_date": "2025-03-05 17:43:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:12:26.036651"
    },
    {
      "arxiv_id": "2503.04842v1",
      "title": "Replicating Human Social Perception in Generative AI: Evaluating the Valence-Dominance Model",
      "title_zh": "翻译失败",
      "authors": [
        "Necdet Gurkan",
        "Kimathi Njoki",
        "Jordan W. Suchow"
      ],
      "abstract": "As artificial intelligence (AI) continues to advance--particularly in\ngenerative models--an open question is whether these systems can replicate\nfoundational models of human social perception. A well-established framework in\nsocial cognition suggests that social judgments are organized along two primary\ndimensions: valence (e.g., trustworthiness, warmth) and dominance (e.g., power,\nassertiveness). This study examines whether multimodal generative AI systems\ncan reproduce this valence-dominance structure when evaluating facial images\nand how their representations align with those observed across world regions.\nThrough principal component analysis (PCA), we found that the extracted\ndimensions closely mirrored the theoretical structure of valence and dominance,\nwith trait loadings aligning with established definitions. However, many world\nregions and generative AI models also exhibited a third component, the nature\nand significance of which warrant further investigation. These findings\ndemonstrate that multimodal generative AI systems can replicate key aspects of\nhuman social perception, raising important questions about their implications\nfor AI-driven decision-making and human-AI interactions.",
      "tldr_zh": "本研究评估了多模态生成 AI 系统是否能复制人类社会感知的 Valence-Dominance Model，即社会判断中基于 Valence（如 trustworthiness 和 warmth）和 Dominance（如 power 和 assertiveness）的二维框架。研究通过 principal component analysis (PCA) 分析 AI 对面部图像的评估，发现提取的维度与理论结构高度一致，但许多世界区域和 AI 模型也显示了第三个组件，其性质需进一步探究。这些发现表明生成 AI 可以再现人类社会感知的关键方面，并引发了对 AI 驱动决策和人机互动的潜在影响的担忧。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04842v1",
      "published_date": "2025-03-05 17:35:18 UTC",
      "updated_date": "2025-03-05 17:35:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:12:36.950216"
    },
    {
      "arxiv_id": "2503.03800v1",
      "title": "Multi-Agent Systems Powered by Large Language Models: Applications in Swarm Intelligence",
      "title_zh": "由大型语言模型驱动的多智能体系统：在群体智能中的应用",
      "authors": [
        "Cristian Jimenez-Romero",
        "Alper Yegenoglu",
        "Christian Blum"
      ],
      "abstract": "This work examines the integration of large language models (LLMs) into\nmulti-agent simulations by replacing the hard-coded programs of agents with\nLLM-driven prompts. The proposed approach is showcased in the context of two\nexamples of complex systems from the field of swarm intelligence: ant colony\nforaging and bird flocking. Central to this study is a toolchain that\nintegrates LLMs with the NetLogo simulation platform, leveraging its Python\nextension to enable communication with GPT-4o via the OpenAI API. This\ntoolchain facilitates prompt-driven behavior generation, allowing agents to\nrespond adaptively to environmental data. For both example applications\nmentioned above, we employ both structured, rule-based prompts and autonomous,\nknowledge-driven prompts. Our work demonstrates how this toolchain enables LLMs\nto study self-organizing processes and induce emergent behaviors within\nmulti-agent environments, paving the way for new approaches to exploring\nintelligent systems and modeling swarm intelligence inspired by natural\nphenomena. We provide the code, including simulation files and data at\nhttps://github.com/crjimene/swarm_gpt.",
      "tldr_zh": "该研究探讨了将大型语言模型（LLMs）整合到多智能体系统中，通过替换硬编码程序为LLM驱动的提示，应用于群智能（Swarm Intelligence）领域，如蚁群觅食和鸟群飞行。研究开发了一个工具链，将LLMs与NetLogo模拟平台结合，使用Python扩展和OpenAI API与GPT-4o通信，实现代理对环境数据的自适应响应，并采用结构化规则-based提示和自主知识-driven提示。结果显示，该方法能有效研究自组织过程、诱发紧急行为，并为探索智能系统提供新途径；代码已开源在https://github.com/crjimene/swarm_gpt。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "I.6.0; I.2.7"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03800v1",
      "published_date": "2025-03-05 17:13:27 UTC",
      "updated_date": "2025-03-05 17:13:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:12:50.249086"
    },
    {
      "arxiv_id": "2503.03669v1",
      "title": "Attentive Reasoning Queries: A Systematic Method for Optimizing Instruction-Following in Large Language Models",
      "title_zh": "Attentive Reasoning Queries：一种用于优化大型语言模型中指令遵循的系统方法",
      "authors": [
        "Bar Karov",
        "Dor Zohar",
        "Yam Marcovitz"
      ],
      "abstract": "We present Attentive Reasoning Queries (ARQs), a novel structured reasoning\napproach that significantly improves instruction-following in Large Language\nModels through domain-specialized reasoning blueprints. While LLMs demonstrate\nremarkable capabilities across diverse tasks, they often fail to maintain\nadherence to complex, use-case-specific instructions during multi-turn\nconversations, presenting challenges for business-critical applications. ARQs\naddress this limitation by guiding LLMs through systematic reasoning steps with\ntargeted queries that reinstate critical instructions and facilitate\nintermediate reasoning throughout the completion process. In extensive testing\nwithin Parlant, our framework for reliable customer-facing agents in which ARQs\nwere born out of necessity, they achieved a 90.2% success rate across 87 test\nscenarios, outperforming both Chain-of-Thought reasoning (86.1%) and direct\nresponse generation (81.5%). ARQs showed particular strength in addressing\npersistent failure modes like guideline re-application and hallucination\nprevention. Our analysis also revealed that ARQs can potentially be more\ncomputationally efficient than free-form reasoning when carefully designed.\nThese findings demonstrate that structured reasoning approaches provide\neffective mechanisms for controlling how LLMs process information and make\ndecisions in complex scenarios.",
      "tldr_zh": "本研究提出了一种名为 Attentive Reasoning Queries (ARQs) 的结构化推理方法，用于优化 Large Language Models (LLMs) 在多轮对话中的指令遵循问题，特别是针对复杂商业应用中的指令坚持挑战。ARQs 通过领域专化的推理蓝图和针对性查询，引导 LLMs 进行系统化推理步骤，包括重申关键指令和中间推理过程，以提升响应准确性。实验结果显示，在 Parlant 框架的 87 个测试场景中，ARQs 实现了 90.2% 的成功率，优于 Chain-of-Thought reasoning (86.1%) 和直接响应生成 (81.5%)，尤其在指导重新应用和幻觉预防方面表现出色。此外，该方法在精心设计时可能更计算高效，为控制 LLMs 处理信息和决策提供有效机制。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "Supplementary materials, including code, is available on our GitHub:\n  https://github.com/emcie-co/parlant/tree/arqs-a-systematic-method-for-optimizing-instruction-following-in-llms",
      "pdf_url": "http://arxiv.org/pdf/2503.03669v1",
      "published_date": "2025-03-05 17:03:48 UTC",
      "updated_date": "2025-03-05 17:03:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:13:03.642826"
    },
    {
      "arxiv_id": "2503.04840v1",
      "title": "Framing the Game: How Context Shapes LLM Decision-Making",
      "title_zh": "框架游戏：上下文如何塑造LLM决策-making",
      "authors": [
        "Isaac Robinson",
        "John Burden"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly deployed across diverse\ncontexts to support decision-making. While existing evaluations effectively\nprobe latent model capabilities, they often overlook the impact of context\nframing on perceived rational decision-making. In this study, we introduce a\nnovel evaluation framework that systematically varies evaluation instances\nacross key features and procedurally generates vignettes to create highly\nvaried scenarios. By analyzing decision-making patterns across different\ncontexts with the same underlying game structure, we uncover significant\ncontextual variability in LLM responses. Our findings demonstrate that this\nvariability is largely predictable yet highly sensitive to framing effects. Our\nresults underscore the need for dynamic, context-aware evaluation methodologies\nfor real-world deployments.",
      "tldr_zh": "本研究探讨了上下文框架如何影响大型语言模型（LLMs）的决策过程，强调现有评估方法忽略了这一关键因素。研究者引入了一个新颖的评估框架，通过系统改变关键特征并程序生成多样化场景，来分析相同游戏结构下不同上下文对LLMs决策模式的影响。结果显示，LLMs的响应存在显著的可变性，这种可变性虽可预测，但对框架效果高度敏感，最终呼吁采用动态、上下文感知的评估方法来支持实际部署。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04840v1",
      "published_date": "2025-03-05 17:03:28 UTC",
      "updated_date": "2025-03-05 17:03:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:13:15.133553"
    },
    {
      "arxiv_id": "2503.03664v1",
      "title": "A Generative Approach to High Fidelity 3D Reconstruction from Text Data",
      "title_zh": "翻译失败",
      "authors": [
        "Venkat Kumar R",
        "Deepak Saravanan"
      ],
      "abstract": "The convergence of generative artificial intelligence and advanced computer\nvision technologies introduces a groundbreaking approach to transforming\ntextual descriptions into three-dimensional representations. This research\nproposes a fully automated pipeline that seamlessly integrates text-to-image\ngeneration, various image processing techniques, and deep learning methods for\nreflection removal and 3D reconstruction. By leveraging state-of-the-art\ngenerative models like Stable Diffusion, the methodology translates natural\nlanguage inputs into detailed 3D models through a multi-stage workflow.\n  The reconstruction process begins with the generation of high-quality images\nfrom textual prompts, followed by enhancement by a reinforcement learning agent\nand reflection removal using the Stable Delight model. Advanced image upscaling\nand background removal techniques are then applied to further enhance visual\nfidelity. These refined two-dimensional representations are subsequently\ntransformed into volumetric 3D models using sophisticated machine learning\nalgorithms, capturing intricate spatial relationships and geometric\ncharacteristics. This process achieves a highly structured and detailed output,\nensuring that the final 3D models reflect both semantic accuracy and geometric\nprecision.\n  This approach addresses key challenges in generative reconstruction, such as\nmaintaining semantic coherence, managing geometric complexity, and preserving\ndetailed visual information. Comprehensive experimental evaluations will assess\nreconstruction quality, semantic accuracy, and geometric fidelity across\ndiverse domains and varying levels of complexity. By demonstrating the\npotential of AI-driven 3D reconstruction techniques, this research offers\nsignificant implications for fields such as augmented reality (AR), virtual\nreality (VR), and digital content creation.",
      "tldr_zh": "本文提出了一种生成式方法，通过文本数据实现高保真3D重建，整合了文本到图像生成、图像处理和深度学习技术。核心流程包括使用Stable Diffusion生成高质量图像，随后通过强化学习代理增强图像，并应用Stable Delight模型移除反射，再结合图像放大和背景移除将2D表示转化为体积3D模型。方法有效解决了语义一致性、几何复杂性和视觉细节的挑战，确保重建输出具有精确的空间关系和几何特性。实验评估显示，该方法在多样领域表现出色，为增强现实(AR)、虚拟现实(VR)和数字内容创建等领域提供了重要应用潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03664v1",
      "published_date": "2025-03-05 16:54:15 UTC",
      "updated_date": "2025-03-05 16:54:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:13:28.540128"
    },
    {
      "arxiv_id": "2503.03655v1",
      "title": "Improving 6D Object Pose Estimation of metallic Household and Industry Objects",
      "title_zh": "改进金属家用和工业物体的 6D 物体位姿估计",
      "authors": [
        "Thomas Pöllabauer",
        "Michael Gasser",
        "Tristan Wirth",
        "Sarah Berkei",
        "Volker Knauthe",
        "Arjan Kuijper"
      ],
      "abstract": "6D object pose estimation suffers from reduced accuracy when applied to\nmetallic objects. We set out to improve the state-of-the-art by addressing\nchallenges such as reflections and specular highlights in industrial\napplications. Our novel BOP-compatible dataset, featuring a diverse set of\nmetallic objects (cans, household, and industrial items) under various lighting\nand background conditions, provides additional geometric and visual cues. We\ndemonstrate that these cues can be effectively leveraged to enhance overall\nperformance. To illustrate the usefulness of the additional features, we\nimprove upon the GDRNPP algorithm by introducing an additional keypoint\nprediction and material estimator head in order to improve spatial scene\nunderstanding. Evaluations on the new dataset show improved accuracy for\nmetallic objects, supporting the hypothesis that additional geometric and\nvisual cues can improve learning.",
      "tldr_zh": "该研究针对金属物体（如罐子、家居和工业物品）在6D object pose estimation中的准确性问题，特别是在反射和镜面高光的影响下，提出了改进方案。论文引入了一个新的BOP-compatible数据集，包含多样金属物体在各种照明和背景条件下的数据，提供额外的几何和视觉线索，以增强算法性能。为此，他们改进了GDRNPP算法，添加了关键点预测和材料估计头，以提升空间场景理解。在新数据集上的评估显示，金属物体的估计准确性显著提高，支持了额外线索能优化学习的效果。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03655v1",
      "published_date": "2025-03-05 16:35:15 UTC",
      "updated_date": "2025-03-05 16:35:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:13:38.487550"
    },
    {
      "arxiv_id": "2503.04839v2",
      "title": "Advancing Multimodal In-Context Learning in Large Vision-Language Models with Task-aware Demonstrations",
      "title_zh": "通过任务感知演示推进大型视觉语言模型中的多模态上下文学习",
      "authors": [
        "Yanshu Li"
      ],
      "abstract": "Multimodal in-context learning (ICL) has emerged as a key capability of Large\nVision-Language Models (LVLMs), driven by their increasing scale and\napplicability. Despite its promise, effective ICL in the multimodal setting\nremains challenging due to the inherent complexity of image-text inputs and the\nhigh sensitivity of ICL performance to input configurations. In this work, we\nshed light on the core mechanism underlying multimodal ICL, identifying task\nmapping as a crucial factor in configuring robust in-context demonstration\n(ICD) sequences. Building on these insights, we propose \\textit{SabER}, a\nlightweight yet powerful decoder-only transformer equipped with task-aware\nattention, which intelligently selects and arranges ICDs from a demonstration\nlibrary in an autoregressive fashion. This design enables fine-grained feature\nextraction and cross-modal reasoning, iteratively refining task mapping to\ngenerate high-quality ICD sequences. Through extensive experiments covering\nfive LVLMs and nine benchmark datasets, SabER not only demonstrates strong\nempirical performance, but also provides deeper understanding of how task\nsemantics interact with multimodal ICDs. Our findings highlight the importance\nof principled ICD sequence configuration and open new avenues to enhance\nmultimodal ICL in a wide range of real-world scenarios.",
      "tldr_zh": "这篇论文探讨了多模态 In-Context Learning (ICL) 在 Large Vision-Language Models (LVLMs) 中的挑战，强调图像-文本输入的复杂性和 ICL 性能对输入配置的敏感性。作者识别出任务映射 (task mapping) 是构建稳健的 In-Context Demonstration (ICD) 序列的关键，并提出 SabER，一种配备任务-aware attention 的轻量级解码器-only transformer，能智能选择和排列 ICDs，通过自回归方式实现细粒度特征提取及跨模态推理。实验结果显示，SabER 在五个 LVLMs 和九个基准数据集上表现出色，不仅提升了性能，还加深了对任务语义与多模态 ICDs 交互的理解。该研究突出了原则性 ICD 序列配置的重要性，并为多模态 ICL 在真实场景中的应用开辟了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ICLR 2025 Workshop on Reasoning and Planning for LLMs, 25\n  pages, 13 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.04839v2",
      "published_date": "2025-03-05 16:33:10 UTC",
      "updated_date": "2025-04-06 20:41:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:13:51.941356"
    },
    {
      "arxiv_id": "2503.03654v1",
      "title": "Improving Neutral Point of View Text Generation through Parameter-Efficient Reinforcement Learning and a Small-Scale High-Quality Dataset",
      "title_zh": "翻译失败",
      "authors": [
        "Jessica Hoffmann",
        "Christiane Ahlheim",
        "Zac Yu",
        "Aria Walfrand",
        "Jarvis Jin",
        "Marie Tano",
        "Ahmad Beirami",
        "Erin van Liemt",
        "Nithum Thain",
        "Hakim Sidahmed",
        "Lucas Dixon"
      ],
      "abstract": "This paper describes the construction of a dataset and the evaluation of\ntraining methods to improve generative large language models' (LLMs) ability to\nanswer queries on sensitive topics with a Neutral Point of View (NPOV), i.e.,\nto provide significantly more informative, diverse and impartial answers. The\ndataset, the SHQ-NPOV dataset, comprises 300 high-quality, human-written\nquadruplets: a query on a sensitive topic, an answer, an NPOV rating, and a set\nof links to source texts elaborating the various points of view. The first key\ncontribution of this paper is a new methodology to create such datasets through\niterative rounds of human peer-critique and annotator training, which we\nrelease alongside the dataset. The second key contribution is the\nidentification of a highly effective training regime for parameter-efficient\nreinforcement learning (PE-RL) to improve NPOV generation. We compare and\nextensively evaluate PE-RL and multiple baselines-including LoRA finetuning (a\nstrong baseline), SFT and RLHF.\n  PE-RL not only improves on overall NPOV quality compared to the strongest\nbaseline ($97.06\\%\\rightarrow 99.08\\%$), but also scores much higher on\nfeatures linguists identify as key to separating good answers from the best\nanswers ($60.25\\%\\rightarrow 85.21\\%$ for presence of supportive details,\n$68.74\\%\\rightarrow 91.43\\%$ for absence of oversimplification). A qualitative\nanalysis corroborates this. Finally, our evaluation finds no statistical\ndifferences between results on topics that appear in the training dataset and\nthose on separated evaluation topics, which provides strong evidence that our\napproach to training PE-RL exhibits very effective out of topic generalization.",
      "tldr_zh": "这篇论文构建了 SHQ-NPOV 数据集，该数据集包含 300 个高质量的人类编写四元组（包括敏感话题查询、回答、NPOV 评分和来源链接），并通过迭代的人类同行审阅和注释者训练方法来确保其可靠性。论文的主要贡献是提出一种参数高效强化学习 (PE-RL) 训练制度，以提升大型语言模型 (LLMs) 在生成中立观点 (NPOV) 回答方面的能力，并与 LoRA finetuning、SFT 和 RLHF 等基线方法进行了比较。实验结果显示，PE-RL 显著提高了 NPOV 质量（从 97.06% 到 99.08%），特别是在支持细节的呈现（60.25% → 85.21%）和避免过度简化（68.74% → 91.43%）方面，并展示了出色的泛化能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03654v1",
      "published_date": "2025-03-05 16:32:47 UTC",
      "updated_date": "2025-03-05 16:32:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:14:05.209938"
    },
    {
      "arxiv_id": "2503.03606v2",
      "title": "Decoupled Recommender Systems: Exploring Alternative Recommender Ecosystem Designs",
      "title_zh": "翻译失败",
      "authors": [
        "Anas Buhayh",
        "Elizabeth McKinnie",
        "Robin Burke"
      ],
      "abstract": "Recommender ecosystems are an emerging subject of research. Such research\nexamines how the characteristics of algorithms, recommendation consumers, and\nitem providers influence system dynamics and long-term outcomes. One\narchitectural possibility that has not yet been widely explored in this line of\nresearch is the consequences of a configuration in which recommendation\nalgorithms are decoupled from the platforms they serve. This is sometimes\ncalled \"the friendly neighborhood algorithm store\" or \"middleware\" model. We\nare particularly interested in how such architectures might offer a range of\ndifferent distributions of utility across consumers, providers, and\nrecommendation platforms. In this paper, we create a model of a recommendation\necosystem that incorporates algorithm choice and examine the outcomes of such a\ndesign.",
      "tldr_zh": "这篇论文探讨了 decoupled recommender systems 的替代设计，重点研究推荐算法与平台分离的架构（如“friendly neighborhood algorithm store”或“middleware”模型）如何影响推荐生态系统。作者构建了一个包含算法选择的生态系统模型，分析这种设计在消费者、提供者和平台之间分配效用的动态和长期结果。该研究揭示了这种架构可能带来的多样化效用分布，为未来推荐系统设计提供新的见解。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03606v2",
      "published_date": "2025-03-05 15:42:37 UTC",
      "updated_date": "2025-03-06 14:28:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:14:14.265123"
    },
    {
      "arxiv_id": "2503.03595v1",
      "title": "Towards Understanding Text Hallucination of Diffusion Models via Local Generation Bias",
      "title_zh": "翻译失败",
      "authors": [
        "Rui Lu",
        "Runzhe Wang",
        "Kaifeng Lyu",
        "Xitai Jiang",
        "Gao Huang",
        "Mengdi Wang"
      ],
      "abstract": "Score-based diffusion models have achieved incredible performance in\ngenerating realistic images, audio, and video data. While these models produce\nhigh-quality samples with impressive details, they often introduce unrealistic\nartifacts, such as distorted fingers or hallucinated texts with no meaning.\nThis paper focuses on textual hallucinations, where diffusion models correctly\ngenerate individual symbols but assemble them in a nonsensical manner. Through\nexperimental probing, we consistently observe that such phenomenon is\nattributed it to the network's local generation bias. Denoising networks tend\nto produce outputs that rely heavily on highly correlated local regions,\nparticularly when different dimensions of the data distribution are nearly\npairwise independent. This behavior leads to a generation process that\ndecomposes the global distribution into separate, independent distributions for\neach symbol, ultimately failing to capture the global structure, including\nunderlying grammar. Intriguingly, this bias persists across various denoising\nnetwork architectures including MLP and transformers which have the structure\nto model global dependency. These findings also provide insights into\nunderstanding other types of hallucinations, extending beyond text, as a result\nof implicit biases in the denoising models. Additionally, we theoretically\nanalyze the training dynamics for a specific case involving a two-layer MLP\nlearning parity points on a hypercube, offering an explanation of its\nunderlying mechanism.",
      "tldr_zh": "本研究探讨了扩散模型（diffusion models）在生成任务中出现的文本幻觉（textual hallucinations）问题，即模型能正确生成单个符号却将其组装成无意义内容。通过实验分析，发现这种现象主要源于网络的局部生成偏差（local generation bias），导致去噪网络（denoising networks）过度依赖高度相关的局部区域，而忽略了数据分布的全局结构，如语法规则。该偏差在多种架构（如MLP和transformer）中普遍存在，并可扩展解释其他类型幻觉；此外，研究通过理论分析双层MLP在超立方体上学习奇偶点的训练动态，揭示了其潜在机制，为改进扩散模型的生成可靠性提供了重要洞见。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03595v1",
      "published_date": "2025-03-05 15:28:50 UTC",
      "updated_date": "2025-03-05 15:28:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:14:27.464271"
    },
    {
      "arxiv_id": "2503.03594v2",
      "title": "Small but Mighty: Enhancing Time Series Forecasting with Lightweight LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Haoran Fan",
        "Bin Li",
        "Yixuan Weng",
        "Shoujun Zhou"
      ],
      "abstract": "While LLMs have demonstrated remarkable potential in time series forecasting,\ntheir practical deployment remains constrained by excessive computational\ndemands and memory footprints. Existing LLM-based approaches typically suffer\nfrom three critical limitations: Inefficient parameter utilization in handling\nnumerical time series patterns; Modality misalignment between continuous\ntemporal signals and discrete text embeddings; and Inflexibility for real-time\nexpert knowledge integration. We present SMETimes, the first systematic\ninvestigation of sub-3B parameter SLMs for efficient and accurate time series\nforecasting. Our approach centers on three key innovations: A\nstatistically-enhanced prompting mechanism that bridges numerical time series\nwith textual semantics through descriptive statistical features; A adaptive\nfusion embedding architecture that aligns temporal patterns with language model\ntoken spaces through learnable parameters; And a dynamic mixture-of-experts\nframework enabled by SLMs' computational efficiency, adaptively combining base\npredictions with domain-specific models. Extensive evaluations across seven\nbenchmark datasets demonstrate that our 3B-parameter SLM achieves\nstate-of-the-art performance on five primary datasets while maintaining 3.8x\nfaster training and 5.2x lower memory consumption compared to 7B-parameter LLM\nbaselines. Notably, the proposed model exhibits better learning capabilities,\nachieving 12.3% lower MSE than conventional LLM. Ablation studies validate that\nour statistical prompting and cross-modal fusion modules respectively\ncontribute 15.7% and 18.2% error reduction in long-horizon forecasting tasks.\nBy redefining the efficiency-accuracy trade-off landscape, this work\nestablishes SLMs as viable alternatives to resource-intensive LLMs for\npractical time series forecasting. Code and models are available at\nhttps://github.com/xiyan1234567/SMETimes.",
      "tldr_zh": "该论文探讨了使用轻量级语言模型（SLMs）来提升时间序列预测的效率，针对传统 LLMs 的高计算需求和内存占用问题提出 SMETimes 框架，这是首个针对子-3B 参数 SLMs 的系统性研究。核心创新包括统计增强提示机制（statistically-enhanced prompting）桥接数值序列与文本语义、自适应融合嵌入架构（adaptive fusion embedding）对齐时间模式和语言空间，以及动态混合专家框架（dynamic mixture-of-experts）实现预测灵活性。在七个基准数据集上，SMETimes 的 3B 参数模型在五个主要数据集上达到最先进性能，训练速度快 3.8 倍、内存消耗低 5.2 倍，并将 MSE 降低 12.3%；消融研究显示，统计提示和跨模态融合模块分别贡献 15.7% 和 18.2% 的错误减少。该工作重新定义了效率-准确性权衡，使 SLMs 成为资源密集型 LLMs 的可行替代方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "20 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.03594v2",
      "published_date": "2025-03-05 15:27:36 UTC",
      "updated_date": "2025-03-09 10:56:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:14:40.658972"
    },
    {
      "arxiv_id": "2503.03592v2",
      "title": "English K_Quantization of LLMs Does Not Disproportionately Diminish Multilingual Performance",
      "title_zh": "翻译失败",
      "authors": [
        "Karl Audun Borgersen"
      ],
      "abstract": "For consumer usage of locally deployed LLMs, the GGUF format and\nk\\_quantization are invaluable tools for maintaining the performance of the\noriginal model while reducing it to sizes deployable with consumer-grade\nhardware. The number of bits dedicated to each weight from the original model\nis reduced based on how important they are thought to be during model\ninference. This importance is arrived at through the application of an\n'importance matrix'-a relatively small text document meant to be representative\nof the LLM's standard use-cases. In the vast majority of quants available\nonline, this document is primarily written in English. It was therefore an open\nquestion whether performance on English language tasks was preserved through\nthe sacrifice of multilingual performance and whether it can be preserved with\nalternate importance matrices. This article investigates these hypotheses by\nquantizing Llama3.3 70B on importance matrices written in three languages\n(English, Norwegian, and Malayalam) and evaluating them on the MixEval dataset\nin both English and Norwegian. All experiments related to yielded\nnon-significant results indicating that current quantization practices do not\ndisproportionately harm multilingual performance.",
      "tldr_zh": "该研究调查了在量化大型语言模型(LLMs)时，使用英文为主的“importance matrix”是否会不成比例地降低多语言性能。研究者对Llama3.3 70B模型进行k_quantization，使用英文、挪威文和马拉雅拉姆文的importance matrix，并通过MixEval数据集评估英文和挪威文任务的性能。结果显示，所有实验均无显著差异，表明当前量化实践不会 disproportionately diminish multilingual performance，同时保留了模型在GGUF格式下的部署效率。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 6 figures, v2",
      "pdf_url": "http://arxiv.org/pdf/2503.03592v2",
      "published_date": "2025-03-05 15:26:59 UTC",
      "updated_date": "2025-03-10 07:36:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:14:50.136100"
    },
    {
      "arxiv_id": "2503.16480v1",
      "title": "Human Preferences for Constructive Interactions in Language Model Alignment",
      "title_zh": "人类对语言模型对齐中建设性互动的偏好",
      "authors": [
        "Yara Kyrychenko",
        "Jon Roozenbeek",
        "Brandon Davidson",
        "Sander van der Linden",
        "Ramit Debnath"
      ],
      "abstract": "As large language models (LLMs) enter the mainstream, aligning them to foster\nconstructive dialogue rather than exacerbate societal divisions is critical.\nUsing an individualized and multicultural alignment dataset of over 7,500\nconversations of individuals from 74 countries engaging with 21 LLMs, we\nexamined how linguistic attributes linked to constructive interactions are\nreflected in human preference data used for training AI. We found that users\nconsistently preferred well-reasoned and nuanced responses while rejecting\nthose high in personal storytelling. However, users who believed that AI should\nreflect their values tended to place less preference on reasoning in LLM\nresponses and more on curiosity. Encouragingly, we observed that users could\nset the tone for how constructive their conversation would be, as LLMs mirrored\nlinguistic attributes, including toxicity, in user queries.",
      "tldr_zh": "本研究调查了人类对大型语言模型 (LLMs) 进行建设的对话偏好，使用一个包含超过7500个对话的数据集，该数据集涉及74个国家的用户与21个LLMs互动。研究发现，用户更倾向于选择有推理和细微差别的回应，而非个人叙事风格的答案；然而，那些认为AI应反映自身价值观的用户，更注重LLMs的好奇心而非纯逻辑推理。令人鼓舞的是，用户可以通过查询设置对话基调，LLMs会镜像用户的语言属性（如毒性），从而促进更具建设性的互动。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "1 Figure, 1 Table, 11 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.16480v1",
      "published_date": "2025-03-05 15:08:41 UTC",
      "updated_date": "2025-03-05 15:08:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:15:02.407436"
    },
    {
      "arxiv_id": "2503.03797v1",
      "title": "VoiceGRPO: Modern MoE Transformers with Group Relative Policy Optimization GRPO for AI Voice Health Care Applications on Voice Pathology Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Enkhtogtokh Togootogtokh",
        "Christian Klasen"
      ],
      "abstract": "This research introduces a novel AI techniques as Mixture-of-Experts\nTransformers with Group Relative Policy Optimization (GRPO) for voice health\ncare applications on voice pathology detection. With the architectural\ninnovations, we adopt advanced training paradigms inspired by reinforcement\nlearning, namely Proximal Policy Optimization (PPO) and Group-wise Regularized\nPolicy Optimization (GRPO), to enhance model stability and performance.\nExperiments conducted on a synthetically generated voice pathology dataset\ndemonstrate that our proposed models significantly improve diagnostic accuracy,\nF1 score, and ROC-AUC compared to conventional approaches. These findings\nunderscore the potential of integrating transformer architectures with novel\ntraining strategies to advance automated voice pathology detection and\nultimately contribute to more effective healthcare delivery. The code we used\nto train and evaluate our models is available at\nhttps://github.com/enkhtogtokh/voicegrpo",
      "tldr_zh": "本研究提出VoiceGRPO，一种现代Mixture-of-Experts Transformers结合Group Relative Policy Optimization (GRPO)的AI框架，用于语音病理检测的语音健康护理应用。模型采用受强化学习启发的训练策略，如Proximal Policy Optimization (PPO)和GRPO，以提升稳定性与性能。在合成数据集上的实验显示，VoiceGRPO显著提高了诊断准确率、F1 score和ROC-AUC，与传统方法相比提升明显。该框架有助于推进自动化语音病理检测，并为更有效的医疗保健交付提供潜力。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03797v1",
      "published_date": "2025-03-05 14:52:57 UTC",
      "updated_date": "2025-03-05 14:52:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:15:13.585081"
    },
    {
      "arxiv_id": "2503.03563v2",
      "title": "A Conceptual Model for Attributions in Event-Centric Knowledge Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Florian Plötzky",
        "Katarina Britz",
        "Wolf-Tilo Balke"
      ],
      "abstract": "The use of narratives as a means of fusing information from knowledge graphs\n(KGs) into a coherent line of argumentation has been the subject of recent\ninvestigation. Narratives are especially useful in event-centric knowledge\ngraphs in that they provide a means to connect different real-world events and\ncategorize them by well-known narrations. However, specifically for\ncontroversial events, a problem in information fusion arises, namely, multiple\nviewpoints regarding the validity of certain event aspects, e.g., regarding the\nrole a participant takes in an event, may exist. Expressing those viewpoints in\nKGs is challenging because disputed information provided by different\nviewpoints may introduce inconsistencies. Hence, most KGs only feature a single\nview on the contained information, hampering the effectiveness of narrative\ninformation access. This paper is an extension of our original work and\nintroduces attributions, i.e., parameterized predicates that allow for the\nrepresentation of facts that are only valid in a specific viewpoint. For this,\nwe develop a conceptual model that allows for the representation of\nviewpoint-dependent information. As an extension, we enhance the model by a\nconception of viewpoint-compatibility. Based on this, we deepen our original\ndeliberations on the model's effects on information fusion and provide\nadditional grounding in the literature.",
      "tldr_zh": "本研究针对事件中心知识图谱（Knowledge Graphs, KGs）中，使用叙事融合信息时面临的挑战，特别是争议事件的多视角问题导致的信息不一致和单一视角限制，提出了一种概念模型。模型引入 attributions（参数化谓词）来表示仅在特定视角下有效的facts，从而实现视角依赖信息的表示和融合。该模型进一步扩展了 viewpoint-compatibility（视角兼容性）的概念，深化了对信息融合的影响分析，并提供了文献依据，以提升KGs在叙事信息访问中的有效性。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "Accepted by Data & Knowledge Engineering, 22 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.03563v2",
      "published_date": "2025-03-05 14:51:46 UTC",
      "updated_date": "2025-04-22 16:54:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:15:25.429860"
    },
    {
      "arxiv_id": "2503.04837v1",
      "title": "FedPalm: A General Federated Learning Framework for Closed- and Open-Set Palmprint Verification",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyuan Yang",
        "Yingyu Chen",
        "Chengrui Gao",
        "Andrew Beng Jin Teoh",
        "Bob Zhang",
        "Yi Zhang"
      ],
      "abstract": "Current deep learning (DL)-based palmprint verification models rely on\ncentralized training with large datasets, which raises significant privacy\nconcerns due to biometric data's sensitive and immutable nature. Federated\nlearning~(FL), a privacy-preserving distributed learning paradigm, offers a\ncompelling alternative by enabling collaborative model training without the\nneed for data sharing. However, FL-based palmprint verification faces critical\nchallenges, including data heterogeneity from diverse identities and the\nabsence of standardized evaluation benchmarks. This paper addresses these gaps\nby establishing a comprehensive benchmark for FL-based palmprint verification,\nwhich explicitly defines and evaluates two practical scenarios: closed-set and\nopen-set verification. We propose FedPalm, a unified FL framework that balances\nlocal adaptability with global generalization. Each client trains a\npersonalized textural expert tailored to local data and collaboratively\ncontributes to a shared global textural expert for extracting generalized\nfeatures. To further enhance verification performance, we introduce a Textural\nExpert Interaction Module that dynamically routes textural features among\nexperts to generate refined side textural features. Learnable parameters are\nemployed to model relationships between original and side features, fostering\ncross-texture-expert interaction and improving feature discrimination.\nExtensive experiments validate the effectiveness of FedPalm, demonstrating\nrobust performance across both scenarios and providing a promising foundation\nfor advancing FL-based palmprint verification research.",
      "tldr_zh": "这篇论文针对手掌纹验证中的隐私问题，提出 FedPalm 框架，这是一种基于 Federated Learning (FL) 的通用方法，用于处理闭集和开集验证场景。FedPalm 通过每个客户端训练个性化的纹理专家（personalized textural expert）来适应本地数据，同时共享全局纹理专家（global textural expert）以提取泛化特征，并引入 Textural Expert Interaction Module 来动态路由特征并提升特征区分度。实验结果显示，FedPalm 在建立的标准化基准上表现出色，显著提高了验证性能，并为 FL 基于手掌纹验证研究提供了坚实基础。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04837v1",
      "published_date": "2025-03-05 14:49:42 UTC",
      "updated_date": "2025-03-05 14:49:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:15:38.112082"
    },
    {
      "arxiv_id": "2503.03562v3",
      "title": "Towards Visual Discrimination and Reasoning of Real-World Physical Dynamics: Physics-Grounded Anomaly Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Wenqiao Li",
        "Yao Gu",
        "Xintao Chen",
        "Xiaohao Xu",
        "Ming Hu",
        "Xiaonan Huang",
        "Yingna Wu"
      ],
      "abstract": "Humans detect real-world object anomalies by perceiving, interacting, and\nreasoning based on object-conditioned physical knowledge. The long-term goal of\nIndustrial Anomaly Detection (IAD) is to enable machines to autonomously\nreplicate this skill. However, current IAD algorithms are largely developed and\ntested on static, semantically simple datasets, which diverge from real-world\nscenarios where physical understanding and reasoning are essential. To bridge\nthis gap, we introduce the Physics Anomaly Detection (Phys-AD) dataset, the\nfirst large-scale, real-world, physics-grounded video dataset for industrial\nanomaly detection. Collected using a real robot arm and motor, Phys-AD provides\na diverse set of dynamic, semantically rich scenarios. The dataset includes\nmore than 6400 videos across 22 real-world object categories, interacting with\nrobot arms and motors, and exhibits 47 types of anomalies. Anomaly detection in\nPhys-AD requires visual reasoning, combining both physical knowledge and video\ncontent to determine object abnormality. We benchmark state-of-the-art anomaly\ndetection methods under three settings: unsupervised AD, weakly-supervised AD,\nand video-understanding AD, highlighting their limitations in handling\nphysics-grounded anomalies. Additionally, we introduce the Physics Anomaly\nExplanation (PAEval) metric, designed to assess the ability of visual-language\nfoundation models to not only detect anomalies but also provide accurate\nexplanations for their underlying physical causes. Our project is available at\nhttps://guyao2023.github.io/Phys-AD/.",
      "tldr_zh": "该论文旨在桥接工业异常检测(IAD)与真实世界物理动态的差距，提出Phys-AD数据集，这是首个大规模的真实世界视频数据集，用于物理基础的异常检测。数据集通过真实机器人臂和马达收集，包含超过6400个视频、22个物体类别和47种异常类型，要求模型结合物理知识和视频内容进行视觉推理。基准测试显示，现有unsupervised AD、weakly-supervised AD和video-understanding AD方法在处理这些动态场景时存在显著局限性。论文还引入Physics Anomaly Explanation (PAEval) 指标，以评估视觉语言模型不仅检测异常，还能准确解释其物理原因的能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR25",
      "pdf_url": "http://arxiv.org/pdf/2503.03562v3",
      "published_date": "2025-03-05 14:49:08 UTC",
      "updated_date": "2025-03-26 03:58:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:15:51.910939"
    },
    {
      "arxiv_id": "2503.04836v1",
      "title": "PGAD: Prototype-Guided Adaptive Distillation for Multi-Modal Learning in AD Diagnosis",
      "title_zh": "PGAD：原型引导的自适应",
      "authors": [
        "Yanfei Li",
        "Teng Yin",
        "Wenyi Shang",
        "Jingyu Liu",
        "Xi Wang",
        "Kaiyang Zhao"
      ],
      "abstract": "Missing modalities pose a major issue in Alzheimer's Disease (AD) diagnosis,\nas many subjects lack full imaging data due to cost and clinical constraints.\nWhile multi-modal learning leverages complementary information, most existing\nmethods train only on complete data, ignoring the large proportion of\nincomplete samples in real-world datasets like ADNI. This reduces the effective\ntraining set and limits the full use of valuable medical data. While some\nmethods incorporate incomplete samples, they fail to effectively address\ninter-modal feature alignment and knowledge transfer challenges under high\nmissing rates. To address this, we propose a Prototype-Guided Adaptive\nDistillation (PGAD) framework that directly incorporates incomplete multi-modal\ndata into training. PGAD enhances missing modality representations through\nprototype matching and balances learning with a dynamic sampling strategy. We\nvalidate PGAD on the ADNI dataset with varying missing rates (20%, 50%, and\n70%) and demonstrate that it significantly outperforms state-of-the-art\napproaches. Ablation studies confirm the effectiveness of prototype matching\nand adaptive sampling, highlighting the potential of our framework for robust\nand scalable AD diagnosis in real-world clinical settings.",
      "tldr_zh": "本文提出PGAD（Prototype-Guided Adaptive Distillation）框架，用于解决阿尔茨海默病（AD）诊断中多模态学习的数据缺失问题，该框架直接将不完整样本纳入训练，通过原型匹配增强缺失模态的表示，并采用动态采样策略平衡学习过程。在ADNI数据集上实验验证显示，PGAD在不同缺失率（20%、50%、70%）下显著优于现有方法，准确率和鲁棒性得到提升。消融研究确认了原型匹配和自适应采样的关键作用，为真实临床环境中可扩展的AD诊断提供潜在解决方案。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04836v1",
      "published_date": "2025-03-05 14:39:31 UTC",
      "updated_date": "2025-03-05 14:39:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:16:05.459816"
    },
    {
      "arxiv_id": "2503.04835v1",
      "title": "Distilling Dataset into Neural Field",
      "title_zh": "翻译失败",
      "authors": [
        "Donghyeok Shin",
        "HeeSun Bae",
        "Gyuwon Sim",
        "Wanmo Kang",
        "Il-Chul Moon"
      ],
      "abstract": "Utilizing a large-scale dataset is essential for training high-performance\ndeep learning models, but it also comes with substantial computation and\nstorage costs. To overcome these challenges, dataset distillation has emerged\nas a promising solution by compressing the large-scale dataset into a smaller\nsynthetic dataset that retains the essential information needed for training.\nThis paper proposes a novel parameterization framework for dataset\ndistillation, coined Distilling Dataset into Neural Field (DDiF), which\nleverages the neural field to store the necessary information of the\nlarge-scale dataset. Due to the unique nature of the neural field, which takes\ncoordinates as input and output quantity, DDiF effectively preserves the\ninformation and easily generates various shapes of data. We theoretically\nconfirm that DDiF exhibits greater expressiveness than some previous literature\nwhen the utilized budget for a single synthetic instance is the same. Through\nextensive experiments, we demonstrate that DDiF achieves superior performance\non several benchmark datasets, extending beyond the image domain to include\nvideo, audio, and 3D voxel. We release the code at\nhttps://github.com/aailab-kaist/DDiF.",
      "tldr_zh": "本文提出了一种名为 Distilling Dataset into Neural Field (DDiF) 的新框架，用于将大规模数据集压缩成更小的合成数据集，从而降低深度学习模型的计算和存储成本。DDiF 利用 neural field 的特性，以坐标作为输入输出量，高效保存数据集信息并生成各种数据形状，并在理论上证明其在相同预算下比现有方法具有更高的表现力。通过广泛实验，DDiF 在图像、视频、音频和3D voxel 等基准数据集上实现了优越性能，并公开了代码以供进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "The Thirteenth International Conference on Learning Representations\n  (ICLR 2025)",
      "pdf_url": "http://arxiv.org/pdf/2503.04835v1",
      "published_date": "2025-03-05 14:33:29 UTC",
      "updated_date": "2025-03-05 14:33:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:16:16.084055"
    },
    {
      "arxiv_id": "2503.03796v2",
      "title": "Human Implicit Preference-Based Policy Fine-tuning for Multi-Agent Reinforcement Learning in USV Swarm",
      "title_zh": "基于人类隐性偏好的策略微调，用于USV群中的多智能体强化学习",
      "authors": [
        "Hyeonjun Kim",
        "Kanghoon Lee",
        "Junho Park",
        "Jiachen Li",
        "Jinkyoo Park"
      ],
      "abstract": "Multi-Agent Reinforcement Learning (MARL) has shown promise in solving\ncomplex problems involving cooperation and competition among agents, such as an\nUnmanned Surface Vehicle (USV) swarm used in search and rescue, surveillance,\nand vessel protection. However, aligning system behavior with user preferences\nis challenging due to the difficulty of encoding expert intuition into reward\nfunctions. To address the issue, we propose a Reinforcement Learning with Human\nFeedback (RLHF) approach for MARL that resolves credit-assignment challenges\nthrough an Agent-Level Feedback system categorizing feedback into intra-agent,\ninter-agent, and intra-team types. To overcome the challenges of direct human\nfeedback, we employ a Large Language Model (LLM) evaluator to validate our\napproach using feedback scenarios such as region constraints, collision\navoidance, and task allocation. Our method effectively refines USV swarm\npolicies, addressing key challenges in multi-agent systems while maintaining\nfairness and performance consistency.",
      "tldr_zh": "该研究针对多智能体强化学习(MARL)中的用户偏好对齐问题，提出了一种基于人类隐式反馈的策略微调方法，应用于无人水面车辆(USV)群的合作任务，如搜索和救援。方法引入Reinforcement Learning with Human Feedback (RLHF)框架，通过Agent-Level Feedback系统将反馈分类为intra-agent（内部代理）、inter-agent（代理间）和intra-team（团队内部）类型，并利用Large Language Model (LLM)评估器处理场景如区域约束、碰撞避免和任务分配。实验结果显示，该方法有效优化USV群策略，解决了信用分配挑战，同时维持了公平性和性能一致性。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.MA",
      "comment": "7 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.03796v2",
      "published_date": "2025-03-05 14:33:18 UTC",
      "updated_date": "2025-03-07 08:06:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:16:28.132736"
    },
    {
      "arxiv_id": "2504.06274v1",
      "title": "Joint Group Profiling and Recommendation via Deep Neural Network-based Multi-Task Learning",
      "title_zh": "基于深度神经网络的多任务学习的联合群体画像和推荐系统",
      "authors": [
        "Ngoc Luyen Le",
        "Marie-Hélène Abel"
      ],
      "abstract": "Group recommender systems aim to generate recommendations that align with the\ncollective preferences of a group, introducing challenges that differ\nsignificantly from those in individual recommendation scenarios. This paper\npresents Joint Group Profiling and Recommendation via Deep Neural Network-based\nMulti-Task Learning, a framework that unifies group profiling and\nrecommendation tasks within a single model. By jointly learning these tasks,\nthe model develops a deeper understanding of group dynamics, leading to\nimproved recommendation accuracy. The shared representations between the two\ntasks facilitate the discovery of latent features essential to both, resulting\nin richer and more informative group embeddings. To further enhance\nperformance, an attention mechanism is integrated to dynamically evaluate the\nrelevance of different group features and item attributes, ensuring the model\nprioritizes the most impactful information. Experiments and evaluations on\nreal-world datasets demonstrate that our multi-task learning approach\nconsistently outperforms baseline models in terms of accuracy, validating its\neffectiveness and robustness.",
      "tldr_zh": "这篇论文提出了一种基于深度神经网络的多任务学习（Multi-Task Learning）框架，用于联合群组建模（Group Profiling）和推荐任务，旨在更好地理解群组动态并提升推荐准确性。该框架通过共享表示（Shared Representations）发现潜在特征，生成更丰富的群组嵌入（Group Embeddings），并整合注意力机制（Attention Mechanism）来动态评估群组特征和物品属性的相关性。实验在真实数据集上表明，该方法在准确性方面显著优于基线模型，证明了其有效性和鲁棒性。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.06274v1",
      "published_date": "2025-03-05 14:28:48 UTC",
      "updated_date": "2025-03-05 14:28:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:16:40.217993"
    },
    {
      "arxiv_id": "2503.04834v1",
      "title": "Extrapolation Merging: Keep Improving With Extrapolation and Merging",
      "title_zh": "外推合并：通过外推和合并持续改进",
      "authors": [
        "Yiguan Lin",
        "Bin Xu",
        "Yinghao Li",
        "Yang Gao"
      ],
      "abstract": "Large Language Models (LLMs) require instruction fine-tuning to perform\ndifferent downstream tasks. However, the instruction fine-tuning phase still\ndemands significant computational resources and labeled data, lacking a\nparadigm that can improve model performance without additional computational\npower and data. Model merging aims to enhance performance by combining the\nparameters of different models, but the lack of a clear optimization direction\nduring the merging process does not always guarantee improved performance. In\nthis paper, we attempt to provide a clear optimization direction for model\nmerging. We first validate the effectiveness of the model extrapolation method\nduring the instruction fine-tuning phase. Then, we propose Extrapolation\nMerging, a paradigm that can continue improving model performance without\nrequiring extra computational resources or data. Using the extrapolation\nmethod, we provide a clear direction for model merging, achieving local\noptimization search, and consequently enhancing the merged model's performance.\nWe conduct experiments on seven different tasks, and the results show that our\nmethod can consistently improve the model's performance after fine-tuning.",
      "tldr_zh": "本研究针对大型语言模型（LLMs）的指令微调问题，指出其需要大量计算资源和标注数据，且传统模型合并缺乏清晰优化方向而无法保证性能提升。作者首先验证了模型外推方法在指令微调阶段的有效性，并提出 Extrapolation Merging 范式，该方法通过外推提供模型合并的优化方向，实现局部优化搜索，从而在无需额外计算资源或数据的情况下持续提升模型性能。在七个不同任务的实验中，结果显示该方法能一致改善微调后模型的表现。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04834v1",
      "published_date": "2025-03-05 14:28:22 UTC",
      "updated_date": "2025-03-05 14:28:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:16:51.155834"
    },
    {
      "arxiv_id": "2503.03532v1",
      "title": "AI-Enabled Conversational Journaling for Advancing Parkinson's Disease Symptom Tracking",
      "title_zh": "翻译失败",
      "authors": [
        "Mashrur Rashik",
        "Shilpa Sweth",
        "Nishtha Agrawal",
        "Saiyyam Kochar",
        "Kara M Smith",
        "Fateme Rajabiyazdi",
        "Vidya Setlur",
        "Narges Mahyar",
        "Ali Sarvghad"
      ],
      "abstract": "Journaling plays a crucial role in managing chronic conditions by allowing\npatients to document symptoms and medication intake, providing essential data\nfor long-term care. While valuable, traditional journaling methods often rely\non static, self-directed entries, lacking interactive feedback and real-time\nguidance. This gap can result in incomplete or imprecise information, limiting\nits usefulness for effective treatment. To address this gap, we introduce\nPATRIKA, an AI-enabled prototype designed specifically for people with\nParkinson's disease (PwPD). The system incorporates cooperative conversation\nprinciples, clinical interview simulations, and personalization to create a\nmore effective and user-friendly journaling experience. Through two user\nstudies with PwPD and iterative refinement of PATRIKA, we demonstrate\nconversational journaling's significant potential in patient engagement and\ncollecting clinically valuable information. Our results showed that generating\nprobing questions PATRIKA turned journaling into a bi-directional interaction.\nAdditionally, we offer insights for designing journaling systems for healthcare\nand future directions for promoting sustained journaling.",
      "tldr_zh": "该研究探讨了传统日记记录在帕金森病(Parkinson's disease)症状跟踪中的局限性，如缺乏互动反馈导致信息不完整，并引入了AI-Enabled的PATRIKA原型系统。PATRIKA 通过整合合作对话原则、临床访谈模拟和个性化设计，将日记转化为双向互动体验，提高患者参与度。两轮用户研究显示，该系统能生成探索性问题，显著提升临床信息收集效率，并为设计医疗日记系统提供宝贵见解和未来方向。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "To appear in the ACM CHI conference on Human Factors in Computing\n  Systems (CHI), 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.03532v1",
      "published_date": "2025-03-05 14:14:25 UTC",
      "updated_date": "2025-03-05 14:14:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:17:02.252138"
    },
    {
      "arxiv_id": "2503.04833v2",
      "title": "Adversarial Training for Multimodal Large Language Models against Jailbreak Attacks",
      "title_zh": "翻译失败",
      "authors": [
        "Liming Lu",
        "Shuchao Pang",
        "Siyuan Liang",
        "Haotian Zhu",
        "Xiyu Zeng",
        "Aishan Liu",
        "Yunhuai Liu",
        "Yongbin Zhou"
      ],
      "abstract": "Multimodal large language models (MLLMs) have made remarkable strides in\ncross-modal comprehension and generation tasks. However, they remain vulnerable\nto jailbreak attacks, where crafted perturbations bypass security guardrails\nand elicit harmful outputs. In this paper, we present the first adversarial\ntraining (AT) paradigm tailored to defend against jailbreak attacks during the\nMLLM training phase. Extending traditional AT to this domain poses two critical\nchallenges: efficiently tuning massive parameters and ensuring robustness\nagainst attacks across multiple modalities. To address these challenges, we\nintroduce Projection Layer Against Adversarial Training (ProEAT), an end-to-end\nAT framework. ProEAT incorporates a projector-based adversarial training\narchitecture that efficiently handles large-scale parameters while maintaining\ncomputational feasibility by focusing adversarial training on a lightweight\nprojector layer instead of the entire model; additionally, we design a dynamic\nweight adjustment mechanism that optimizes the loss function's weight\nallocation based on task demands, streamlining the tuning process. To enhance\ndefense performance, we propose a joint optimization strategy across visual and\ntextual modalities, ensuring robust resistance to jailbreak attacks originating\nfrom either modality. Extensive experiments conducted on five major jailbreak\nattack methods across three mainstream MLLMs demonstrate the effectiveness of\nour approach. ProEAT achieves state-of-the-art defense performance,\noutperforming existing baselines by an average margin of +34% across text and\nimage modalities, while incurring only a 1% reduction in clean accuracy.\nFurthermore, evaluations on real-world embodied intelligent systems highlight\nthe practical applicability of our framework, paving the way for the\ndevelopment of more secure and reliable multimodal systems.",
      "tldr_zh": "本文提出首个针对多模态大语言模型(MLLMs)的对抗训练(AT)范式，用于防御jailbreak attacks。引入ProEAT框架，通过projection layer-based adversarial training和动态权重调整机制，仅在轻量级投影层上进行高效训练，并实现视觉和文本模态的联合优化，以提升鲁棒性。实验结果显示，ProEAT在五种主要攻击方法和三种主流MLLMs上，比现有基线平均提升34%的防御性能，同时仅导致1%的干净准确率损失，并证明了其在真实embodied intelligent systems中的实际应用价值。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04833v2",
      "published_date": "2025-03-05 14:13:35 UTC",
      "updated_date": "2025-03-18 07:01:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:17:14.866055"
    },
    {
      "arxiv_id": "2503.03528v1",
      "title": "AdaSin: Enhancing Hard Sample Metrics with Dual Adaptive Penalty for Face Recognition",
      "title_zh": "AdaSin：通过双重自适应惩罚增强硬样本指标的人脸识别",
      "authors": [
        "Qiqi Guo",
        "Zhuowen Zheng",
        "Guanghua Yang",
        "Zhiquan Liu",
        "Xiaofan Li",
        "Jianqing Li",
        "Jinyu Tian",
        "Xueyuan Gong"
      ],
      "abstract": "In recent years, the emergence of deep convolutional neural networks has\npositioned face recognition as a prominent research focus in computer vision.\nTraditional loss functions, such as margin-based, hard-sample mining-based, and\nhybrid approaches, have achieved notable performance improvements, with some\nleveraging curriculum learning to optimize training. However, these methods\noften fall short in effectively quantifying the difficulty of hard samples. To\naddress this, we propose Adaptive Sine (AdaSin) loss function, which introduces\nthe sine of the angle between a sample's embedding feature and its ground-truth\nclass center as a novel difficulty metric. This metric enables precise and\neffective penalization of hard samples. By incorporating curriculum learning,\nthe model dynamically adjusts classification boundaries across different\ntraining stages. Unlike previous adaptive-margin loss functions, AdaSin\nintroduce a dual adaptive penalty, applied to both the positive and negative\ncosine similarities of hard samples. This design imposes stronger constraints,\nenhancing intra-class compactness and inter-class separability. The combination\nof the dual adaptive penalty and curriculum learning is guided by a\nwell-designed difficulty metric. It enables the model to focus more effectively\non hard samples in later training stages, and lead to the extraction of highly\ndiscriminative face features. Extensive experiments across eight benchmarks\ndemonstrate that AdaSin achieves superior accuracy compared to other\nstate-of-the-art methods.",
      "tldr_zh": "该论文针对人脸识别领域中传统损失函数（如基于边界的或硬样本挖掘的方法）在量化硬样本难度方面存在的不足，提出了一种新的AdaSin损失函数。AdaSin使用样本嵌入特征与真实类别中心的角度正弦作为难度指标，并引入双重自适应惩罚，分别应用于硬样本的正负余弦相似度，以增强类内紧凑性和类间可分性，同时结合curriculum learning动态调整训练阶段的分类边界。实验结果显示，在八个基准测试中，AdaSin比现有最先进方法实现了更高的准确率，提高了模型对硬样本的处理能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03528v1",
      "published_date": "2025-03-05 14:11:13 UTC",
      "updated_date": "2025-03-05 14:11:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:17:26.487063"
    },
    {
      "arxiv_id": "2503.03511v1",
      "title": "NeuGrasp: Generalizable Neural Surface Reconstruction with Background Priors for Material-Agnostic Object Grasp Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Qingyu Fan",
        "Yinghao Cai",
        "Chao Li",
        "Wenzhe He",
        "Xudong Zheng",
        "Tao Lu",
        "Bin Liang",
        "Shuo Wang"
      ],
      "abstract": "Robotic grasping in scenes with transparent and specular objects presents\ngreat challenges for methods relying on accurate depth information. In this\npaper, we introduce NeuGrasp, a neural surface reconstruction method that\nleverages background priors for material-agnostic grasp detection. NeuGrasp\nintegrates transformers and global prior volumes to aggregate multi-view\nfeatures with spatial encoding, enabling robust surface reconstruction in\nnarrow and sparse viewing conditions. By focusing on foreground objects through\nresidual feature enhancement and refining spatial perception with an\noccupancy-prior volume, NeuGrasp excels in handling objects with transparent\nand specular surfaces. Extensive experiments in both simulated and real-world\nscenarios show that NeuGrasp outperforms state-of-the-art methods in grasping\nwhile maintaining comparable reconstruction quality. More details are available\nat https://neugrasp.github.io/.",
      "tldr_zh": "该论文提出 NeuGrasp，一种通用的神经表面重建方法，利用 background priors 实现对透明和镜面物体的 material-agnostic 物体抓取检测，解决了依赖深度信息的传统方法在复杂场景中的挑战。NeuGrasp 通过整合 transformers 和 global prior volumes 来聚合多视图特征与空间编码，并采用 residual feature enhancement 和 occupancy-prior volume 来增强前景物体感知和空间精度，尤其适用于狭窄稀疏视图条件。实验在模拟和真实世界环境中表明，NeuGrasp 在抓取性能上优于最先进方法，同时保持了可比的表面重建质量。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "I.2.9; I.2.10"
      ],
      "primary_category": "cs.RO",
      "comment": "7 pages, 5 figures. IEEE International Conference on Robotics and\n  Automation (ICRA) 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.03511v1",
      "published_date": "2025-03-05 13:57:37 UTC",
      "updated_date": "2025-03-05 13:57:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:17:39.108476"
    },
    {
      "arxiv_id": "2503.03506v4",
      "title": "Opinion: Revisiting synthetic data classifications from a privacy perspective",
      "title_zh": "观点：从隐私角度重新审视合成数据分类",
      "authors": [
        "Vibeke Binz Vallevik",
        "Serena Elizabeth Marshall",
        "Aleksandar Babic",
        "Jan Franz Nygaard"
      ],
      "abstract": "Synthetic data is emerging as a cost-effective solution necessary to meet the\nincreasing data demands of AI development, created either from existing\nknowledge or derived from real data. The traditional classification of\nsynthetic data types into hybrid, partial or fully synthetic datasets has\nlimited value and does not reflect the ever-increasing methods to generate\nsynthetic data. The generation method and their source jointly shape the\ncharacteristics of synthetic data, which in turn determines its practical\napplications. We make a case for an alternative approach to grouping synthetic\ndata types that better reflect privacy perspectives in order to facilitate\nregulatory guidance in the generation and processing of synthetic data. This\napproach to classification provides flexibility to new advancements like deep\ngenerative methods and offers a more practical framework for future\napplications.",
      "tldr_zh": "这篇观点文章从隐私角度重新审视合成数据的分类，认为传统分类（如hybrid、partial或fully synthetic datasets）已不充分，无法反映生成方法的多样性。作者建议一种新框架，将合成数据的生成方法和来源作为核心因素，以更好地评估隐私风险并指导其生成和处理。该方法提供更大的灵活性，适应新技术如深度生成方法，并为合成数据的实际应用和监管提供更实用的指导。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03506v4",
      "published_date": "2025-03-05 13:54:13 UTC",
      "updated_date": "2025-04-15 10:00:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:17:50.077995"
    },
    {
      "arxiv_id": "2503.03505v1",
      "title": "Parallelized Planning-Acting for Efficient LLM-based Multi-Agent Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Yaoru Li",
        "Shunyu Liu",
        "Tongya Zheng",
        "Mingli Song"
      ],
      "abstract": "Recent advancements in Large Language Model(LLM)-based Multi-Agent\nSystems(MAS) have demonstrated remarkable potential for tackling complex\ndecision-making tasks. However, existing frameworks inevitably rely on\nserialized execution paradigms, where agents must complete sequential LLM\nplanning before taking action. This fundamental constraint severely limits\nreal-time responsiveness and adaptation, which is crucial in dynamic\nenvironments with ever-changing scenarios. In this paper, we propose a novel\nparallelized planning-acting framework for LLM-based MAS, featuring a\ndual-thread architecture with interruptible execution to enable concurrent\nplanning and acting. Specifically, our framework comprises two core threads:(1)\na planning thread driven by a centralized memory system, maintaining\nsynchronization of environmental states and agent communication to support\ndynamic decision-making; and (2) an acting thread equipped with a comprehensive\nskill library, enabling automated task execution through recursive\ndecomposition. Extensive experiments on challenging Minecraft demonstrate the\neffectiveness of the proposed framework.",
      "tldr_zh": "该论文针对现有基于大型语言模型(LLM)的多智能体系统(Multi-Agent Systems)的序列化执行问题，提出了一种并行化规划-行动框架，以提升实时响应和适应性。该框架采用双线程架构，包括一个由集中式内存系统驱动的规划线程，用于同步环境状态和代理通信支持动态决策，以及一个配备技能库的行动线程，通过递归分解实现自动化任务执行。在Minecraft的实验中，该框架证明了其有效性，显著提高了系统的效率和性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03505v1",
      "published_date": "2025-03-05 13:53:10 UTC",
      "updated_date": "2025-03-05 13:53:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:18:01.869024"
    },
    {
      "arxiv_id": "2503.03503v1",
      "title": "Collaborative Expert LLMs Guided Multi-Objective Molecular Optimization",
      "title_zh": "协作专家大语言模型指导的多目标分子优化",
      "authors": [
        "Jiajun Yu",
        "Yizhen Zheng",
        "Huan Yee Koh",
        "Shirui Pan",
        "Tianyue Wang",
        "Haishuai Wang"
      ],
      "abstract": "Molecular optimization is a crucial yet complex and time-intensive process\nthat often acts as a bottleneck for drug development. Traditional methods rely\nheavily on trial and error, making multi-objective optimization both\ntime-consuming and resource-intensive. Current AI-based methods have shown\nlimited success in handling multi-objective optimization tasks, hampering their\npractical utilization. To address this challenge, we present MultiMol, a\ncollaborative large language model (LLM) system designed to guide\nmulti-objective molecular optimization. MultiMol comprises two agents,\nincluding a data-driven worker agent and a literature-guided research agent.\nThe data-driven worker agent is a large language model being fine-tuned to\nlearn how to generate optimized molecules considering multiple objectives,\nwhile the literature-guided research agent is responsible for searching\ntask-related literature to find useful prior knowledge that facilitates\nidentifying the most promising optimized candidates. In evaluations across six\nmulti-objective optimization tasks, MultiMol significantly outperforms existing\nmethods, achieving a 82.30% success rate, in sharp contrast to the 27.50%\nsuccess rate of current strongest methods. To further validate its practical\nimpact, we tested MultiMol on two real-world challenges. First, we enhanced the\nselectivity of Xanthine Amine Congener (XAC), a promiscuous ligand that binds\nboth A1R and A2AR, successfully biasing it towards A1R. Second, we improved the\nbioavailability of Saquinavir, an HIV-1 protease inhibitor with known\nbioavailability limitations. Overall, these results indicate that MultiMol\nrepresents a highly promising approach for multi-objective molecular\noptimization, holding great potential to accelerate the drug development\nprocess and contribute to the advancement of pharmaceutical research.",
      "tldr_zh": "该论文提出 MultiMol，一种基于协作大型语言模型 (LLMs) 的系统，用于指导多目标分子优化，以解决传统方法依赖试错和 AI 局限性的挑战。MultiMol 包括数据驱动的工作代理（通过微调 LLM 生成优化分子）和文献引导的研究代理（搜索相关文献提供先验知识），从而高效处理多个优化目标。在六个多目标优化任务中，MultiMol 的成功率达到 82.30%，远高于现有方法的 27.50%。此外，在实际应用中，它成功提升了 Xanthine Amine Congener (XAC) 对 A1R 的选择性和 Saquinavir 的生物利用度，展示了其在加速药物开发中的潜力。",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.BM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03503v1",
      "published_date": "2025-03-05 13:47:55 UTC",
      "updated_date": "2025-03-05 13:47:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:18:15.177203"
    },
    {
      "arxiv_id": "2503.03502v1",
      "title": "CURVALID: Geometrically-guided Adversarial Prompt Detection",
      "title_zh": "CURVALID: 几何引导的对抗提示检测",
      "authors": [
        "Canaan Yung",
        "Hanxun Huang",
        "Sarah Monazam Erfani",
        "Christopher Leckie"
      ],
      "abstract": "Adversarial prompts capable of jailbreaking large language models (LLMs) and\ninducing undesirable behaviours pose a significant obstacle to their safe\ndeployment. Current mitigation strategies rely on activating built-in defence\nmechanisms or fine-tuning the LLMs, but the fundamental distinctions between\nadversarial and benign prompts are yet to be understood. In this work, we\nintroduce CurvaLID, a novel defense framework that efficiently detects\nadversarial prompts by leveraging their geometric properties. It is agnostic to\nthe type of LLM, offering a unified detection framework across diverse\nadversarial prompts and LLM architectures. CurvaLID builds on the geometric\nanalysis of text prompts to uncover their underlying differences. We\ntheoretically extend the concept of curvature via the Whewell equation into an\n$n$-dimensional word embedding space, enabling us to quantify local geometric\nproperties, including semantic shifts and curvature in the underlying\nmanifolds. Additionally, we employ Local Intrinsic Dimensionality (LID) to\ncapture geometric features of text prompts within adversarial subspaces. Our\nfindings reveal that adversarial prompts differ fundamentally from benign\nprompts in terms of their geometric characteristics. Our results demonstrate\nthat CurvaLID delivers superior detection and rejection of adversarial queries,\npaving the way for safer LLM deployment. The source code can be found at\nhttps://github.com/Cancanxxx/CurvaLID",
      "tldr_zh": "这篇论文提出了 CURVALID，一种基于几何引导的框架，用于检测能诱导大语言模型 (LLMs) 不当行为的对抗性提示，从而提升模型的安全部署。CURVALID 通过扩展曲率概念（如 via the Whewell equation）到 n-维词嵌入空间，并结合 Local Intrinsic Dimensionality (LID) 来量化文本提示的几何特性，包括语义偏移和曲率差异。研究发现，对抗性提示在几何属性上与良性提示存在根本区别，结果显示 CURVALID 显著提高了对抗查询的检测和拒绝性能，为更可靠的 LLM 应用铺平道路。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "29 Pages, 5 figues",
      "pdf_url": "http://arxiv.org/pdf/2503.03502v1",
      "published_date": "2025-03-05 13:47:53 UTC",
      "updated_date": "2025-03-05 13:47:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:18:29.228798"
    },
    {
      "arxiv_id": "2503.03480v1",
      "title": "SafeVLA: Towards Safety Alignment of Vision-Language-Action Model via Safe Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Borong Zhang",
        "Yuhao Zhang",
        "Jiaming Ji",
        "Yingshan Lei",
        "Josef Dai",
        "Yuanpei Chen",
        "Yaodong Yang"
      ],
      "abstract": "Vision-language-action models (VLAs) have shown great potential as generalist\nrobot policies. However, these models pose urgent safety challenges during\ndeployment, including the risk of physical harm to the environment, the robot\nitself, and humans. How can safety be explicitly incorporated into VLAs? In\nthis work, we propose SafeVLA, a novel algorithm designed to integrate safety\ninto VLAs, ensuring the protection of the environment, robot hardware and\nhumans in real-world settings. SafeVLA effectively balances safety and task\nperformance by employing large-scale constrained learning within simulated\nenvironments. We demonstrate that SafeVLA outperforms the current\nstate-of-the-art method in both safety and task performance, achieving average\nimprovements of 83.58% and 3.85%, respectively, in simulation. By prioritizing\nsafety, our approach eliminates high-risk behaviors and reduces the upper bound\nof unsafe behaviors to 1/35 of that in the current state-of-the-art, thereby\nsignificantly mitigating long-tail risks. Furthermore, the learned safety\nconstraints generalize to diverse, unseen scenarios, including multiple\nout-of-distribution perturbations and tasks. Our data, models and newly\nproposed benchmark environment are available at\nhttps://sites.google.com/view/pku-safevla.",
      "tldr_zh": "该研究针对视觉语言动作模型(VLAs)作为通用机器人策略的安全风险问题，提出SafeVLA算法，通过安全强化学习(Safe Reinforcement Learning)将安全机制集成到VLAs中，以保护环境、机器人硬件和人类。SafeVLA在模拟环境中采用大规模约束学习，实现了安全与任务性能的平衡。实验结果显示，SafeVLA在安全方面比现有最先进方法提升83.58%、任务性能提升3.85%，并将不安全行为的上限降低到原方法的1/35，同时其安全约束能泛化到多种分布外场景。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "10 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.03480v1",
      "published_date": "2025-03-05 13:16:55 UTC",
      "updated_date": "2025-03-05 13:16:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:18:37.991055"
    },
    {
      "arxiv_id": "2503.03462v1",
      "title": "Open-Source Large Language Models as Multilingual Crowdworkers: Synthesizing Open-Domain Dialogues in Several Languages With No Examples in Targets and No Machine Translation",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmed Njifenjou",
        "Virgile Sucal",
        "Bassam Jabaian",
        "Fabrice Lefèvre"
      ],
      "abstract": "The prevailing paradigm in the domain of Open-Domain Dialogue agents\npredominantly focuses on the English language, encompassing both models and\ndatasets. Furthermore, the financial and temporal investments required for\ncrowdsourcing such datasets for finetuning are substantial, particularly when\nmultiple languages are involved. Fortunately, advancements in Large Language\nModels (LLMs) have unveiled a plethora of possibilities across diverse tasks.\nSpecifically, instruction-tuning has enabled LLMs to execute tasks based on\nnatural language instructions, occasionally surpassing the performance of human\ncrowdworkers. Additionally, these models possess the capability to function in\nvarious languages within a single thread. Consequently, to generate new samples\nin different languages, we propose leveraging these capabilities to replicate\nthe data collection process. We introduce a pipeline for generating Open-Domain\nDialogue data in multiple Target Languages using LLMs, with demonstrations\nprovided in a unique Source Language. By eschewing explicit Machine Translation\nin this approach, we enhance the adherence to language-specific nuances. We\napply this methodology to the PersonaChat dataset. To enhance the openness of\ngenerated dialogues and mimic real life scenarii, we added the notion of speech\nevents corresponding to the type of conversation the speakers are involved in\nand also that of common ground which represents the premises of a conversation.",
      "tldr_zh": "这篇论文提出一种利用开源 Large Language Models (LLMs) 作为多语言众包工作者的方法，来合成多种目标语言的开放域对话数据，而无需目标语言示例或机器翻译。研究设计了一个管道，仅使用源语言的演示指令进行数据生成，从而提升对话对语言特异性的适应性，并应用于 PersonaChat 数据集。论文还引入了 speech events（对话类型）和 common ground（对话前提）概念，以增强生成对话的真实性和开放性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03462v1",
      "published_date": "2025-03-05 12:52:14 UTC",
      "updated_date": "2025-03-05 12:52:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:18:51.030761"
    },
    {
      "arxiv_id": "2503.03459v2",
      "title": "Unified Mind Model: Reimagining Autonomous Agents in the LLM Era",
      "title_zh": "翻译失败",
      "authors": [
        "Pengbo Hu",
        "Xiang Ying"
      ],
      "abstract": "Large language models (LLMs) have recently demonstrated remarkable\ncapabilities across domains, tasks, and languages (e.g., ChatGPT and GPT-4),\nreviving the research of general autonomous agents with human-like cognitive\nabilities. Such human-level agents require semantic comprehension and\ninstruction-following capabilities, which exactly fall into the strengths of\nLLMs. Although there have been several initial attempts to build human-level\nagents based on LLMs, the theoretical foundation remains a challenging open\nproblem. In this paper, we propose a novel theoretical cognitive architecture,\nthe Unified Mind Model (UMM), which offers guidance to facilitate the rapid\ncreation of autonomous agents with human-level cognitive abilities.\nSpecifically, our UMM starts with the global workspace theory and further\nleverage LLMs to enable the agent with various cognitive abilities, such as\nmulti-modal perception, planning, reasoning, tool use, learning, memory,\nreflection and motivation. Building upon UMM, we then develop an agent-building\nengine, MindOS, which allows users to quickly create domain-/task-specific\nautonomous agents without any programming effort.",
      "tldr_zh": "本论文提出Unified Mind Model (UMM)，一种新型理论认知架构，基于global workspace theory并利用LLMs（如ChatGPT）赋予自主代理人类级别的认知能力，包括多模态感知、规划、推理、工具使用、学习、记忆、反思和动机，以解决构建通用代理的理论挑战。UMM旨在整合LLMs的语义理解和指令遵循优势，促进代理的快速发展。基于UMM，研究团队开发了MindOS引擎，用户无需编程即可轻松创建特定领域或任务的自主代理。实验结果表明，此框架为实现高效、人类-like的代理提供了坚实基础。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.03459v2",
      "published_date": "2025-03-05 12:49:44 UTC",
      "updated_date": "2025-03-06 03:32:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:19:03.432487"
    },
    {
      "arxiv_id": "2503.03444v1",
      "title": "Taxation Perspectives from Large Language Models: A Case Study on Additional Tax Penalties",
      "title_zh": "大语言模型的税收视角：附加税罚款的案例研究",
      "authors": [
        "Eunkyung Choi",
        "Young Jin Suh",
        "Hun Park",
        "Wonseok Hwang"
      ],
      "abstract": "How capable are large language models (LLMs) in the domain of taxation?\nAlthough numerous studies have explored the legal domain in general, research\ndedicated to taxation remain scarce. Moreover, the datasets used in these\nstudies are either simplified, failing to reflect the real-world complexities,\nor unavailable as open source. To address this gap, we introduce PLAT, a new\nbenchmark designed to assess the ability of LLMs to predict the legitimacy of\nadditional tax penalties. PLAT is constructed to evaluate LLMs' understanding\nof tax law, particularly in cases where resolving the issue requires more than\njust applying related statutes. Our experiments with six LLMs reveal that their\nbaseline capabilities are limited, especially when dealing with conflicting\nissues that demand a comprehensive understanding. However, we found that\nenabling retrieval, self-reasoning, and discussion among multiple agents with\nspecific role assignments, this limitation can be mitigated.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）在税收领域的能力，特别是针对额外税收罚款合法性的预测。论文引入了一个新基准PLAT，用于评估LLMs对税法的理解，尤其是需要处理超出简单法规应用的情况。实验结果显示，六种LLMs的基线性能有限，尤其在面对冲突问题时；然而，通过启用retrieval、self-reasoning和多代理讨论（带有特定角色分配），这些限制可得到缓解。总的来说，该工作填补了税收领域数据集的空白，并为提升LLMs在复杂法律任务中的表现提供了新路径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "5 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.03444v1",
      "published_date": "2025-03-05 12:24:20 UTC",
      "updated_date": "2025-03-05 12:24:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:19:16.163833"
    },
    {
      "arxiv_id": "2503.03443v1",
      "title": "Conceptualizing Uncertainty",
      "title_zh": "不确定性的概念化",
      "authors": [
        "Isaac Roberts",
        "Alexander Schulz",
        "Sarah Schroeder",
        "Fabian Hinder",
        "Barbara Hammer"
      ],
      "abstract": "Uncertainty in machine learning refers to the degree of confidence or lack\nthereof in a model's predictions. While uncertainty quantification methods\nexist, explanations of uncertainty, especially in high-dimensional settings,\nremain an open challenge. Existing work focuses on feature attribution\napproaches which are restricted to local explanations. Understanding\nuncertainty, its origins, and characteristics on a global scale is crucial for\nenhancing interpretability and trust in a model's predictions. In this work, we\npropose to explain the uncertainty in high-dimensional data classification\nsettings by means of concept activation vectors which give rise to local and\nglobal explanations of uncertainty. We demonstrate the utility of the generated\nexplanations by leveraging them to refine and improve our model.",
      "tldr_zh": "机器学习中的不确定性(Unsertainty)指的是模型预测的置信度，现有的不确定性量化方法(Unsertainty quantification methods)虽能量化不确定性，但解释尤其是高维数据中的解释仍是一个挑战，因为现有工作主要局限于局部特征归因(Feature attribution)方法。  \n本文提出使用概念激活向量(Concept activation vectors)来解释高维数据分类设置中的不确定性，从而生成局部和全局解释，帮助理解不确定性的起源和特征。  \n这些解释可提升模型的可解释性和信任度，并被用于改进模型性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03443v1",
      "published_date": "2025-03-05 12:24:12 UTC",
      "updated_date": "2025-03-05 12:24:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:19:28.544144"
    },
    {
      "arxiv_id": "2503.03434v1",
      "title": "RASD: Retrieval-Augmented Speculative Decoding",
      "title_zh": "RASD: 检索增强的推测解码",
      "authors": [
        "Guofeng Quan",
        "Wenfeng Feng",
        "Chuzhan Hao",
        "Guochao Jiang",
        "Yuewei Zhang",
        "Hao Wang"
      ],
      "abstract": "Speculative decoding accelerates inference in large language models (LLMs) by\ngenerating draft tokens for target model verification. Current approaches for\nobtaining draft tokens rely on lightweight draft models or additional model\nstructures to generate draft tokens and retrieve context from databases. Due to\nthe draft model's small size and limited training data, model-based speculative\ndecoding frequently becomes less effective in out-of-domain scenarios.\nAdditionally, the time cost of the drafting phase results in a low upper limit\non acceptance length during the verification step, limiting overall efficiency.\nThis paper proposes RASD (Retrieval-Augmented Speculative Decoding), which\nadopts retrieval methods to enhance model-based speculative decoding. We\nintroduce tree pruning and tree fusion to achieve this. Specifically, we\ndevelop a pruning method based on the draft model's probability distribution to\nconstruct the optimal retrieval tree. Second, we employ the longest prefix\nmatching algorithm to merge the tree generated by the draft model with the\nretrieval tree, resulting in a unified tree for verification. Experimental\nresults demonstrate that RASD achieves state-of-the-art inference acceleration\nacross tasks such as DocQA, Summary, Code, and In-Domain QA. Moreover, RASD\nexhibits strong scalability, seamlessly integrating with various speculative\ndecoding approaches, including both generation-based and retrieval-based\nmethods.",
      "tldr_zh": "本论文提出 RASD（Retrieval-Augmented Speculative Decoding），一种通过检索方法增强大语言模型（LLMs）推测性解码的技术，以解决现有草稿模型在领域外场景下效果不佳和效率受限的问题。RASD 引入 tree pruning 和 tree fusion 机制：基于草稿模型的概率分布构建最优检索树，并使用最长前缀匹配算法合并草稿树和检索树，形成统一的验证树。实验结果表明，RASD 在 DocQA、Summary、Code 和 In-Domain QA 等任务上实现了最先进的推理加速，并展示了强大的可扩展性，能够无缝整合生成型和检索型推测性解码方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03434v1",
      "published_date": "2025-03-05 12:10:14 UTC",
      "updated_date": "2025-03-05 12:10:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:19:40.974563"
    },
    {
      "arxiv_id": "2503.03428v1",
      "title": "Privacy is All You Need: Revolutionizing Wearable Health Data with Advanced PETs",
      "title_zh": "翻译失败",
      "authors": [
        "Karthik Barma",
        "Seshu Babu Barma"
      ],
      "abstract": "In a world where data is the new currency, wearable health devices offer\nunprecedented insights into daily life, continuously monitoring vital signs and\nmetrics. However, this convenience raises privacy concerns, as these devices\ncollect sensitive data that can be misused or breached. Traditional measures\noften fail due to real-time data processing needs and limited device power.\nUsers also lack awareness and control over data sharing and usage. We propose a\nPrivacy-Enhancing Technology (PET) framework for wearable devices, integrating\nfederated learning, lightweight cryptographic methods, and selectively deployed\nblockchain technology. The blockchain acts as a secure ledger triggered only\nupon data transfer requests, granting users real-time notifications and\ncontrol. By dismantling data monopolies, this approach returns data sovereignty\nto individuals. Through real-world applications like secure medical data\nsharing, privacy-preserving fitness tracking, and continuous health monitoring,\nour framework reduces privacy risks by up to 70 percent while preserving data\nutility and performance. This innovation sets a new benchmark for wearable\nprivacy and can scale to broader IoT ecosystems, including smart homes and\nindustry. As data continues to shape our digital landscape, our research\nunderscores the critical need to maintain privacy and user control at the\nforefront of technological progress.",
      "tldr_zh": "本研究针对穿戴式健康设备的数据隐私问题，提出一个先进的 Privacy-Enhancing Technology (PET) 框架，整合 federated learning、轻量级加密方法和选择性区块链技术，以实现实时数据控制和用户通知。框架通过区块链作为安全账本，仅在数据传输请求时激活，帮助用户重获数据主权并打破数据垄断。实验结果显示，该方法在实际应用如安全医疗数据共享和隐私保护健身追踪中，将隐私风险降低高达70%，同时保持数据效用，并可扩展到更广泛的 IoT 生态系统。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.ET",
        "cs.HC"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03428v1",
      "published_date": "2025-03-05 12:01:22 UTC",
      "updated_date": "2025-03-05 12:01:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:19:51.120817"
    },
    {
      "arxiv_id": "2503.03794v1",
      "title": "Synthetic Data Augmentation for Enhancing Harmful Algal Bloom Detection with Machine Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Tianyi Huang"
      ],
      "abstract": "Harmful Algal Blooms (HABs) pose severe threats to aquatic ecosystems and\npublic health, resulting in substantial economic losses globally. Early\ndetection is crucial but often hindered by the scarcity of high-quality\ndatasets necessary for training reliable machine learning (ML) models. This\nstudy investigates the use of synthetic data augmentation using Gaussian\nCopulas to enhance ML-based HAB detection systems. Synthetic datasets of\nvarying sizes (100-1,000 samples) were generated using relevant environmental\nfeatures$\\unicode{x2015}$water temperature, salinity, and UVB\nradiation$\\unicode{x2015}$with corrected Chlorophyll-a concentration as the\ntarget variable. Experimental results demonstrate that moderate synthetic\naugmentation significantly improves model performance (RMSE reduced from 0.4706\nto 0.1850; $p < 0.001$). However, excessive synthetic data introduces noise and\nreduces predictive accuracy, emphasizing the need for a balanced approach to\ndata augmentation. These findings highlight the potential of synthetic data to\nenhance HAB monitoring systems, offering a scalable and cost-effective method\nfor early detection and mitigation of ecological and public health risks.",
      "tldr_zh": "该研究针对有害藻华（HABs）对生态和公共健康的威胁，以及训练机器学习（ML）模型所需高质量数据稀缺的问题，提出使用 Gaussian Copulas 生成合成数据进行数据增强。实验基于环境特征（如水温、盐度和 UVB 辐射）创建了不同规模的合成数据集（100-1,000 样本），以 Chlorophyll-a 浓度作为目标变量，结果显示适度增强显著提升模型性能（RMSE 从 0.4706 降至 0.1850，p < 0.001）。然而，过度使用合成数据会引入噪声并降低预测准确性，该方法为 HABs 监测提供了一种可扩展、成本有效的早期检测策略。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted Paper at the 2025 IEEE Conference on Technologies for\n  Sustainability (SusTech)",
      "pdf_url": "http://arxiv.org/pdf/2503.03794v1",
      "published_date": "2025-03-05 11:50:04 UTC",
      "updated_date": "2025-03-05 11:50:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:20:03.363267"
    },
    {
      "arxiv_id": "2503.03418v1",
      "title": "Simplicial SMOTE: Oversampling Solution to the Imbalanced Learning Problem",
      "title_zh": "翻译失败",
      "authors": [
        "Oleg Kachan",
        "Andrey Savchenko",
        "Gleb Gusev"
      ],
      "abstract": "SMOTE (Synthetic Minority Oversampling Technique) is the established\ngeometric approach to random oversampling to balance classes in the imbalanced\nlearning problem, followed by many extensions. Its idea is to introduce\nsynthetic data points of the minor class, with each new point being the convex\ncombination of an existing data point and one of its k-nearest neighbors. In\nthis paper, by viewing SMOTE as sampling from the edges of a geometric\nneighborhood graph and borrowing tools from the topological data analysis, we\npropose a novel technique, Simplicial SMOTE, that samples from the simplices of\na geometric neighborhood simplicial complex. A new synthetic point is defined\nby the barycentric coordinates w.r.t. a simplex spanned by an arbitrary number\nof data points being sufficiently close rather than a pair. Such a replacement\nof the geometric data model results in better coverage of the underlying data\ndistribution compared to existing geometric sampling methods and allows the\ngeneration of synthetic points of the minority class closer to the majority\nclass on the decision boundary. We experimentally demonstrate that our\nSimplicial SMOTE outperforms several popular geometric sampling methods,\nincluding the original SMOTE. Moreover, we show that simplicial sampling can be\neasily integrated into existing SMOTE extensions. We generalize and evaluate\nsimplicial extensions of the classic Borderline SMOTE, Safe-level SMOTE, and\nADASYN algorithms, all of which outperform their graph-based counterparts.",
      "tldr_zh": "本研究针对不平衡学习问题，提出了一种改进的过采样技术Simplicial SMOTE，通过将SMOTE视为从几何邻域单纯复的单纯形中采样，而不是仅从图的边上采样，从而生成更接近决策边界的少数类合成数据点。这种方法利用拓扑数据分析工具，提供更好的底层数据分布覆盖，并允许合成点基于任意数量的足够接近的数据点定义。实验结果显示，Simplicial SMOTE优于原SMOTE和其他几何采样方法；此外，将其整合到Borderline SMOTE、Safe-level SMOTE和ADASYN等扩展中后，这些变体也表现出色地超越了原有版本。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at KDD 2025 (research track)",
      "pdf_url": "http://arxiv.org/pdf/2503.03418v1",
      "published_date": "2025-03-05 11:47:41 UTC",
      "updated_date": "2025-03-05 11:47:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:20:15.618648"
    },
    {
      "arxiv_id": "2503.03417v2",
      "title": "When Claims Evolve: Evaluating and Enhancing the Robustness of Embedding Models Against Misinformation Edits",
      "title_zh": "当声明演变时：评估和增强嵌入模型针对错误信息编辑的鲁棒性",
      "authors": [
        "Jabez Magomere",
        "Emanuele La Malfa",
        "Manuel Tonneau",
        "Ashkan Kazemi",
        "Scott Hale"
      ],
      "abstract": "Online misinformation remains a critical challenge, and fact-checkers\nincreasingly rely on embedding-based methods to retrieve relevant fact-checks.\nYet, when debunked claims reappear in edited forms, the performance of these\nmethods is unclear. In this work, we introduce a taxonomy of six common\nreal-world misinformation edits and propose a perturbation framework that\ngenerates valid, natural claim variations. Our multi-stage retrieval evaluation\nreveals that standard embedding models struggle with user-introduced edits,\nwhile LLM-distilled embeddings offer improved robustness at a higher\ncomputational cost. Although a strong reranker helps mitigate some issues, it\ncannot fully compensate for first-stage retrieval gaps. Addressing these\nretrieval gaps, our train- and inference-time mitigation approaches enhance\nin-domain robustness by up to 17 percentage points and boost out-of-domain\ngeneralization by 10 percentage points over baseline models. Overall, our\nfindings provide practical improvements to claim-matching systems, enabling\nmore reliable fact-checking of evolving misinformation.",
      "tldr_zh": "该研究评估了嵌入模型(embedding models)对虚假信息编辑的鲁棒性，引入了六种常见真实世界编辑的分类和一个扰动框架，用于生成有效的声明变体。实验通过多阶段检索评估发现，标准嵌入模型对用户编辑声明处理不佳，而LLM-distilled embeddings提供更好的鲁棒性，但伴随更高计算成本；尽管重新排序器(reranker)能部分缓解问题，却无法完全弥补初始检索缺陷。作者提出的训练时和推理时的缓解方法，提升了模型的领域内鲁棒性最多17个百分点，并提高了领域外泛化能力10个百分点，从而为事实检查系统提供实际改进，增强了对演变虚假信息的可靠匹配。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03417v2",
      "published_date": "2025-03-05 11:47:32 UTC",
      "updated_date": "2025-03-06 11:00:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:20:27.287415"
    },
    {
      "arxiv_id": "2503.03410v1",
      "title": "Augmentation-Based Deep Learning for Identification of Circulating Tumor Cells",
      "title_zh": "翻译失败",
      "authors": [
        "Martina Russo",
        "Giulia Bertolini",
        "Vera Cappelletti",
        "Cinzia De Marco",
        "Serena Di Cosimo",
        "Petra Paiè",
        "Nadia Brancati"
      ],
      "abstract": "Circulating tumor cells (CTCs) are crucial biomarkers in liquid biopsy,\noffering a noninvasive tool for cancer patient management. However, their\nidentification remains particularly challenging due to their limited number and\nheterogeneity. Labeling samples for contrast limits the generalization of\nfluorescence-based methods across different hospital datasets. Analyzing\nsingle-cell images enables detailed assessment of cell morphology, subcellular\nstructures, and phenotypic variations, often hidden in clustered images.\nDeveloping a method based on bright-field single-cell analysis could overcome\nthese limitations. CTCs can be isolated using an unbiased workflow combining\nParsortix technology, which selects cells based on size and deformability, with\nDEPArray technology, enabling precise visualization and selection of single\ncells. Traditionally, DEPArray-acquired digital images are manually analyzed,\nmaking the process time-consuming and prone to variability. In this study, we\npresent a Deep Learning-based classification pipeline designed to distinguish\nCTCs from leukocytes in blood samples, aimed to enhance diagnostic accuracy and\noptimize clinical workflows. Our approach employs images from the bright-field\nchannel acquired through DEPArray technology leveraging a ResNet-based CNN. To\nimprove model generalization, we applied three types of data augmentation\ntechniques and incorporated fluorescence (DAPI) channel images into the\ntraining phase, allowing the network to learn additional CTC-specific features.\nNotably, only bright-field images have been used for testing, ensuring the\nmodel's ability to identify CTCs without relying on fluorescence markers. The\nproposed model achieved an F1-score of 0.798, demonstrating its capability to\ndistinguish CTCs from leukocytes. These findings highlight the potential of DL\nin refining CTC analysis and advancing liquid biopsy applications.",
      "tldr_zh": "本研究针对循环肿瘤细胞(CTCs)的识别挑战，提出了一种基于深度学习的分类管道，使用ResNet-based CNN模型分析亮场单细胞图像，以克服传统荧光标记方法的局限性。方法结合Parsortix和DEPArray技术隔离细胞，并应用三种数据增强技术以及荧光(DAPI)通道图像进行训练，但仅使用亮场图像进行测试，以确保模型的泛化能力。结果显示，该模型在区分CTCs和白细胞时达到了0.798的F1-score，显著提高了诊断准确性和临床工作流程效率，并展示了深度学习在液体活检应用中的潜力。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "68T07, 68T10",
        "I.2; I.4; J.3"
      ],
      "primary_category": "eess.IV",
      "comment": "20 pages, 4 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.03410v1",
      "published_date": "2025-03-05 11:39:15 UTC",
      "updated_date": "2025-03-05 11:39:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:20:39.282190"
    },
    {
      "arxiv_id": "2503.03395v1",
      "title": "AI-Driven Multi-Stage Computer Vision System for Defect Detection in Laser-Engraved Industrial Nameplates",
      "title_zh": "AI驱动的多阶段计算机视觉系统用于激光雕刻工业铭牌的缺陷检测",
      "authors": [
        "Adhish Anitha Vilasan",
        "Stephan Jäger",
        "Noah Klarmann"
      ],
      "abstract": "Automated defect detection in industrial manufacturing is essential for\nmaintaining product quality and minimizing production errors. In air disc brake\nmanufacturing, ensuring the precision of laser-engraved nameplates is crucial\nfor accurate product identification and quality control. Engraving errors, such\nas misprints or missing characters, can compromise both aesthetics and\nfunctionality, leading to material waste and production delays. This paper\npresents a proof of concept for an AI-driven computer vision system that\ninspects and verifies laser-engraved nameplates, detecting defects in logos and\nalphanumeric strings. The system integrates object detection using YOLOv7,\noptical character recognition (OCR) with Tesseract, and anomaly detection\nthrough a residual variational autoencoder (ResVAE) along with other computer\nvision methods to enable comprehensive inspections at multiple stages.\nExperimental results demonstrate the system's effectiveness, achieving 91.33%\naccuracy and 100% recall, ensuring that defective nameplates are consistently\ndetected and addressed. This solution highlights the potential of AI-driven\nvisual inspection to enhance quality control, reduce manual inspection efforts,\nand improve overall manufacturing efficiency.",
      "tldr_zh": "本论文提出了一种AI驱动的多阶段计算机视觉系统，用于检测激光雕刻工业铭牌（如空气盘式刹车铭牌）的缺陷，包括错印或缺失字符，以提升产品质量和制造效率。系统整合了YOLOv7进行物体检测、Tesseract OCR进行光学字符识别，以及ResVAE（残差变分自编码器）与其他计算机视觉方法实现全面的多阶段检查。实验结果显示，该系统在检测任务中达到了91.33%的准确率和100%的召回率，有效减少了手动检查并降低了生产浪费。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03395v1",
      "published_date": "2025-03-05 11:19:17 UTC",
      "updated_date": "2025-03-05 11:19:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:20:50.507258"
    },
    {
      "arxiv_id": "2503.03391v1",
      "title": "Multi-Agent DRL for Queue-Aware Task Offloading in Hierarchical MEC-Enabled Air-Ground Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Muhammet Hevesli",
        "Abegaz Mohammed Seid",
        "Aiman Erbad",
        "Mohamed Abdallah"
      ],
      "abstract": "Mobile edge computing (MEC)-enabled air-ground networks are a key component\nof 6G, employing aerial base stations (ABSs) such as unmanned aerial vehicles\n(UAVs) and high-altitude platform stations (HAPS) to provide dynamic services\nto ground IoT devices (IoTDs). These IoTDs support real-time applications\n(e.g., multimedia and Metaverse services) that demand high computational\nresources and strict quality of service (QoS) guarantees in terms of latency\nand task queue management. Given their limited energy and processing\ncapabilities, IoTDs rely on UAVs and HAPS to offload tasks for distributed\nprocessing, forming a multi-tier MEC system. This paper tackles the overall\nenergy minimization problem in MEC-enabled air-ground integrated networks\n(MAGIN) by jointly optimizing UAV trajectories, computing resource allocation,\nand queue-aware task offloading decisions. The optimization is challenging due\nto the nonconvex, nonlinear nature of this hierarchical system, which renders\ntraditional methods ineffective. We reformulate the problem as a multi-agent\nMarkov decision process (MDP) with continuous action spaces and heterogeneous\nagents, and propose a novel variant of multi-agent proximal policy optimization\nwith a Beta distribution (MAPPO-BD) to solve it. Extensive simulations show\nthat MAPPO-BD outperforms baseline schemes, achieving superior energy savings\nand efficient resource management in MAGIN while meeting queue delay and edge\ncomputing constraints.",
      "tldr_zh": "本论文针对 MEC-enabled air-ground networks 中的任务卸载问题，提出了一种多智能体深度强化学习 (DRL) 框架，旨在最小化整体能量消耗，同时优化 UAV 轨迹、计算资源分配和队列感知任务卸载决策。该框架将问题重构为多智能体 Markov 决策过程 (MDP) 并采用 MAPPO-BD 算法来处理连续动作空间和异构智能体带来的挑战。实验模拟显示，MAPPO-BD 比基线方案实现更高的能量节省和资源管理效率，同时满足队列延迟和边缘计算约束。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03391v1",
      "published_date": "2025-03-05 11:12:40 UTC",
      "updated_date": "2025-03-05 11:12:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:21:05.232277"
    },
    {
      "arxiv_id": "2503.04832v5",
      "title": "Lightweight Embedded FPGA Deployment of Learned Image Compression with Knowledge Distillation and Hybrid Quantization",
      "title_zh": "翻译失败",
      "authors": [
        "Alaa Mazouz",
        "Sumanta Chaudhuri",
        "Marco Cagnanzzo",
        "Mihai Mitrea",
        "Enzo Tartaglione",
        "Attilio Fiandrotti"
      ],
      "abstract": "Learnable Image Compression (LIC) has shown the potential to outperform\nstandardized video codecs in RD efficiency, prompting the research for\nhardware-friendly implementations. Most existing LIC hardware implementations\nprioritize latency to RD-efficiency and through an extensive exploration of the\nhardware design space. We present a novel design paradigm where the burden of\ntuning the design for a specific hardware platform is shifted towards model\ndimensioning and without compromising on RD-efficiency. First, we design a\nframework for distilling a leaner student LIC model from a reference teacher:\nby tuning a single model hyperparameters, we can meet the constraints of\ndifferent hardware platforms without a complex hardware design exploration.\nSecond, we propose a hardware-friendly implementation of the Generalized\nDivisive Normalization - GDN activation that preserves RD efficiency even post\nparameter quantization. Third, we design a pipelined FPGA configuration which\ntakes full advantage of available FPGA resources by leveraging parallel\nprocessing and optimizing resource allocation. Our experiments with a state of\nthe art LIC model show that we outperform all existing FPGA implementations\nwhile performing very close to the original model.",
      "tldr_zh": "这篇论文针对 Learnable Image Compression (LIC) 的硬件实现，提出了一种轻量级部署方法，通过知识蒸馏(knowledge distillation)从教师模型提炼更精简的学生模型，并使用混合量化来适应不同 FPGA 平台，同时保持 RD 效率。核心贡献包括设计一个硬件友好的 Generalized Divisive Normalization (GDN) 激活函数，以及优化流水线 FPGA 配置，利用并行处理和资源分配来提升性能。实验结果表明，该方法在最先进 LIC 模型的基础上，超越所有现有 FPGA 实现，并在 RD 效率上接近原模型。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "1. Submitted to IEEE Transactions on Circuits and Systems for Video\n  Technology in March 2025. 2. Corrected numerous mistakes from previous\n  versions in results, citations and metrics numbers in figures",
      "pdf_url": "http://arxiv.org/pdf/2503.04832v5",
      "published_date": "2025-03-05 10:59:32 UTC",
      "updated_date": "2025-03-25 09:08:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:21:16.178265"
    },
    {
      "arxiv_id": "2503.03361v1",
      "title": "From Infants to AI: Incorporating Infant-like Learning in Models Boosts Efficiency and Generalization in Learning Social Prediction Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Shify Treger",
        "Shimon Ullman"
      ],
      "abstract": "Early in development, infants learn a range of useful concepts, which can be\nchallenging from a computational standpoint. This early learning comes together\nwith an initial understanding of aspects of the meaning of concepts, e.g.,\ntheir implications, causality, and using them to predict likely future events.\nAll this is accomplished in many cases with little or no supervision, and from\nrelatively few examples, compared with current network models. In learning\nabout objects and human-object interactions, early acquired and possibly innate\nconcepts are often used in the process of learning additional, more complex\nconcepts. In the current work, we model how early-acquired concepts are used in\nthe learning of subsequent concepts, and compare the results with standard deep\nnetwork modeling. We focused in particular on the use of the concepts of\nanimacy and goal attribution in learning to predict future events. We show that\nthe use of early concepts in the learning of new concepts leads to better\nlearning (higher accuracy) and more efficient learning (requiring less data).\nWe further show that this integration of early and new concepts shapes the\nrepresentation of the concepts acquired by the model. The results show that\nwhen the concepts were learned in a human-like manner, the emerging\nrepresentation was more useful, as measured in terms of generalization to novel\ndata and tasks. On a more general level, the results suggest that there are\nlikely to be basic differences in the conceptual structures acquired by current\nnetwork models compared to human learning.",
      "tldr_zh": "该研究探讨了如何将婴儿-like学习整合到AI模型中，以提升在社会预测任务中的学习效率和泛化能力。论文通过建模早期概念，如animacy（有活力性）和goal attribution（目标归因），来辅助学习新概念，并与标准deep network modeling进行比较。结果显示，这种方法显著提高了模型的准确性，减少了对训练数据的需求，并使概念表示更具实用性。总体而言，该工作揭示了AI模型与人类学习在概念结构上可能存在的根本差异。",
      "categories": [
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03361v1",
      "published_date": "2025-03-05 10:40:19 UTC",
      "updated_date": "2025-03-05 10:40:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:21:27.565045"
    },
    {
      "arxiv_id": "2503.03360v3",
      "title": "Transformers for molecular property prediction: Domain adaptation efficiently improves performance",
      "title_zh": "Transformers 用于分子属性预测：领域适应高效改善性能",
      "authors": [
        "Afnan Sultan",
        "Max Rausch-Dupont",
        "Shahrukh Khan",
        "Olga Kalinina",
        "Dietrich Klakow",
        "Andrea Volkamer"
      ],
      "abstract": "Over the past six years, molecular transformer models have become key tools\nin drug discovery. Most existing models are pre-trained on large, unlabeled\ndatasets such as ZINC or ChEMBL. However, the extent to which large-scale\npre-training improves molecular property prediction remains unclear. This study\nevaluates transformer models for this task while addressing their limitations.\nWe explore how pre-training dataset size and chemically informed objectives\nimpact performance. Our results show that increasing the dataset beyond\napproximately 400K to 800K molecules from large-scale unlabeled databases does\nnot enhance performance across seven datasets covering five ADME endpoints:\nlipophilicity, permeability, solubility (two datasets), microsomal stability\n(two datasets), and plasma protein binding. In contrast, domain adaptation on a\nsmall, domain-specific dataset (less than or equal 4K molecules) using\nmulti-task regression of physicochemical properties significantly boosts\nperformance (P-value less than 0.001). A model pre-trained on 400K molecules\nand adapted with domain-specific data outperforms larger models such as\nMolFormer and performs comparably to MolBERT. Benchmarks against Random Forest\n(RF) baselines using descriptors and Morgan fingerprints show that chemically\nand physically informed features consistently yield better performance across\nmodel types. While RF remains a strong baseline, we identify concrete practices\nto enhance transformer performance. Aligning pre-training and adaptation with\nchemically meaningful tasks and domain-relevant data presents a promising\ndirection for molecular property prediction. Our models are available on\nHuggingFace for easy use and adaptation.",
      "tldr_zh": "本文研究评估了 Transformer 模型在分子属性预测中的性能，发现预训练数据集大小超过约 400K 到 800K 分子后，对七个数据集（覆盖亲脂性、渗透性、溶解性、微粒稳定性和血浆蛋白结合等 ADME 终点）的表现无显著提升。相反，通过在小规模领域特定数据集（≤4K 分子）上进行领域适应和多任务回归，能显著提高模型性能（P < 0.001），使一个在 400K 分子上预训练的模型优于 MolFormer 并与 MolBERT 相当。与 Random Forest (RF) 基线比较，化学和物理信息特征（如描述符和 Morgan fingerprints）能一致提升 Transformer 的预测准确性。研究提供了最佳实践建议，并开源了模型以便进一步应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03360v3",
      "published_date": "2025-03-05 10:40:09 UTC",
      "updated_date": "2025-05-22 14:27:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:21:41.232842"
    },
    {
      "arxiv_id": "2503.03350v1",
      "title": "Leveraging Large Language Models to Develop Heuristics for Emerging Optimization Problems",
      "title_zh": "利用大型语言模型开发新兴优化问题的启发式算法",
      "authors": [
        "Thomas Bömer",
        "Nico Koltermann",
        "Max Disselnmeyer",
        "Laura Dörr",
        "Anne Meyer"
      ],
      "abstract": "Combinatorial optimization problems often rely on heuristic algorithms to\ngenerate efficient solutions. However, the manual design of heuristics is\nresource-intensive and constrained by the designer's expertise. Recent advances\nin artificial intelligence, particularly large language models (LLMs), have\ndemonstrated the potential to automate heuristic generation through\nevolutionary frameworks. Recent works focus only on well-known combinatorial\noptimization problems like the traveling salesman problem and online bin\npacking problem when designing constructive heuristics. This study investigates\nwhether LLMs can effectively generate heuristics for niche, not yet broadly\nresearched optimization problems, using the unit-load pre-marshalling problem\nas an example case. We propose the Contextual Evolution of Heuristics (CEoH)\nframework, an extension of the Evolution of Heuristics (EoH) framework, which\nincorporates problem-specific descriptions to enhance in-context learning\nduring heuristic generation. Through computational experiments, we evaluate\nCEoH and EoH and compare the results. Results indicate that CEoH enables\nsmaller LLMs to generate high-quality heuristics more consistently and even\noutperform larger models. Larger models demonstrate robust performance with or\nwithout contextualized prompts. The generated heuristics exhibit scalability to\ndiverse instance configurations.",
      "tldr_zh": "该研究探讨如何利用大语言模型(LLMs)为新兴优化问题自动生成启发式算法，以克服手动设计的资源消耗和专业知识限制。论文提出Contextual Evolution of Heuristics (CEoH)框架，这是Evolution of Heuristics (EoH)框架的扩展，通过融入问题特定描述增强LLMs的上下文学习，并以unit-load pre-marshalling problem为例进行测试。实验结果显示，CEoH使较小LLMs更稳定地生成高质量启发式，甚至超越较大模型，而较大模型在有无上下文提示下均表现出色；此外，生成的启发式算法显示出对不同实例配置的良好可扩展性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Under review LION19: The 19th Learning and Intelligent OptimizatioN\n  Conference",
      "pdf_url": "http://arxiv.org/pdf/2503.03350v1",
      "published_date": "2025-03-05 10:22:49 UTC",
      "updated_date": "2025-03-05 10:22:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:21:52.415175"
    },
    {
      "arxiv_id": "2503.03338v1",
      "title": "Navigating Intelligence: A Survey of Google OR-Tools and Machine Learning for Global Path Planning in Autonomous Vehicles",
      "title_zh": "翻译失败",
      "authors": [
        "Alexandre Benoit",
        "Pedram Asef"
      ],
      "abstract": "We offer a new in-depth investigation of global path planning (GPP) for\nunmanned ground vehicles, an autonomous mining sampling robot named ROMIE. GPP\nis essential for ROMIE's optimal performance, which is translated into solving\nthe traveling salesman problem, a complex graph theory challenge that is\ncrucial for determining the most effective route to cover all sampling\nlocations in a mining field. This problem is central to enhancing ROMIE's\noperational efficiency and competitiveness against human labor by optimizing\ncost and time. The primary aim of this research is to advance GPP by\ndeveloping, evaluating, and improving a cost-efficient software and web\napplication. We delve into an extensive comparison and analysis of Google\noperations research (OR)-Tools optimization algorithms. Our study is driven by\nthe goal of applying and testing the limits of OR-Tools capabilities by\nintegrating Reinforcement Learning techniques for the first time. This enables\nus to compare these methods with OR-Tools, assessing their computational\neffectiveness and real-world application efficiency. Our analysis seeks to\nprovide insights into the effectiveness and practical application of each\ntechnique. Our findings indicate that Q-Learning stands out as the optimal\nstrategy, demonstrating superior efficiency by deviating only 1.2% on average\nfrom the optimal solutions across our datasets.",
      "tldr_zh": "这篇论文调查了 Google OR-Tools 和机器学习在自主车辆全球路径规划 (GPP) 中的应用，针对无人地面车辆 ROMIE 解决旅行 salesman 问题 (TSP)，以优化采样路径并提升操作效率。研究通过开发成本高效的软件和网络应用，首次整合 Reinforcement Learning 技术（如 Q-Learning）与 OR-Tools 算法进行比较和分析，评估其计算有效性和实际性能。结果表明，Q-Learning 作为最优策略，仅平均偏离最优解 1.2%，为提升 ROMIE 的竞争力和效率提供了关键洞见。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CE",
        "eess.SP"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03338v1",
      "published_date": "2025-03-05 10:12:22 UTC",
      "updated_date": "2025-03-05 10:12:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:22:06.882401"
    },
    {
      "arxiv_id": "2503.03321v1",
      "title": "See What You Are Told: Visual Attention Sink in Large Multimodal Models",
      "title_zh": "翻译失败",
      "authors": [
        "Seil Kang",
        "Jinyeong Kim",
        "Junhyeok Kim",
        "Seong Jae Hwang"
      ],
      "abstract": "Large multimodal models (LMMs) \"see\" images by leveraging the attention\nmechanism between text and visual tokens in the transformer decoder. Ideally,\nthese models should focus on key visual information relevant to the text token.\nHowever, recent findings indicate that LMMs have an extraordinary tendency to\nconsistently allocate high attention weights to specific visual tokens, even\nwhen these tokens are irrelevant to the corresponding text. In this study, we\ninvestigate the property behind the appearance of these irrelevant visual\ntokens and examine their characteristics. Our findings show that this behavior\narises due to the massive activation of certain hidden state dimensions, which\nresembles the attention sink found in language models. Hence, we refer to this\nphenomenon as the visual attention sink. In particular, our analysis reveals\nthat removing the irrelevant visual sink tokens does not impact model\nperformance, despite receiving high attention weights. Consequently, we recycle\nthe attention to these tokens as surplus resources, redistributing the\nattention budget to enhance focus on the image. To achieve this, we introduce\nVisual Attention Redistribution (VAR), a method that redistributes attention in\nimage-centric heads, which we identify as innately focusing on visual\ninformation. VAR can be seamlessly applied across different LMMs to improve\nperformance on a wide range of tasks, including general vision-language tasks,\nvisual hallucination tasks, and vision-centric tasks, all without the need for\nadditional training, models, or inference steps. Experimental results\ndemonstrate that VAR enables LMMs to process visual information more\neffectively by adjusting their internal attention mechanisms, offering a new\ndirection to enhancing the multimodal capabilities of LMMs.",
      "tldr_zh": "这项研究揭示了大型多模态模型(LMMs)中存在的视觉注意力陷阱(visual attention sink)问题，即模型倾向于将高注意力权重分配给与文本无关的视觉标记，导致资源浪费。分析发现，这种现象源于某些隐藏状态维度的过度激活，且移除这些无关标记不会影响模型性能。作者提出Visual Attention Redistribution (VAR)方法，通过在图像相关的注意力头中重新分配注意力预算，提升模型对视觉信息的焦点，而无需额外训练。实验结果显示，VAR显著提高了LMMs在一般视觉语言任务、视觉幻觉任务和视觉中心任务上的性能，为增强多模态模型的效率提供了新方向。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03321v1",
      "published_date": "2025-03-05 09:55:07 UTC",
      "updated_date": "2025-03-05 09:55:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:22:15.952108"
    },
    {
      "arxiv_id": "2503.04831v1",
      "title": "\"Only ChatGPT gets me\": An Empirical Analysis of GPT versus other Large Language Models for Emotion Detection in Text",
      "title_zh": "“只有 ChatGPT 懂我”：GPT 与其他大型语言模型在文本情感检测中的实证分析",
      "authors": [
        "Florian Lecourt",
        "Madalina Croitoru",
        "Konstantin Todorov"
      ],
      "abstract": "This work investigates the capabilities of large language models (LLMs) in\ndetecting and understanding human emotions through text. Drawing upon emotion\nmodels from psychology, we adopt an interdisciplinary perspective that\nintegrates computational and affective sciences insights. The main goal is to\nassess how accurately they can identify emotions expressed in textual\ninteractions and compare different models on this specific task. This research\ncontributes to broader efforts to enhance human-computer interaction, making\nartificial intelligence technologies more responsive and sensitive to users'\nemotional nuances. By employing a methodology that involves comparisons with a\nstate-of-the-art model on the GoEmotions dataset, we aim to gauge LLMs'\neffectiveness as a system for emotional analysis, paving the way for potential\napplications in various fields that require a nuanced understanding of human\nlanguage.",
      "tldr_zh": "这篇论文通过实证分析，评估了大型语言模型 (LLMs) 在文本中检测和理解人类情绪的能力，特别是比较 ChatGPT 与其他模型。研究结合了心理学的感情模型和计算科学方法，使用 GoEmotions 数据集与最先进模型进行比较，以衡量 LLMs 在情感分析中的准确性和有效性。该工作有助于提升人机交互的敏感性，推动 AI 在需要细致理解人类语言的领域中的应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04831v1",
      "published_date": "2025-03-05 09:47:49 UTC",
      "updated_date": "2025-03-05 09:47:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:22:28.166983"
    },
    {
      "arxiv_id": "2503.22688v2",
      "title": "CodeIF-Bench: Evaluating Instruction-Following Capabilities of Large Language Models in Interactive Code Generation",
      "title_zh": "CodeIF-Bench：评估大型语言模型在交互式代码生成中的指令遵循能力",
      "authors": [
        "Peiding Wang",
        "Li Zhang",
        "Fang Liu",
        "Lin Shi",
        "Minxiao Li",
        "Bo Shen",
        "An Fu"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated exceptional performance in\ncode generation tasks and have become indispensable programming assistants for\ndevelopers. However, existing code generation benchmarks primarily assess the\nfunctional correctness of code generated by LLMs in single-turn interactions,\noffering limited insight into their capabilities to generate code that strictly\nfollows users' instructions, especially in multi-turn interaction scenarios. In\nthis paper, we introduce CodeIF-Bench, a benchmark for evaluating LLMs'\ninstruction-following capabilities in interactive code generation.\nSpecifically, CodeIF-Bench incorporates nine types of verifiable instructions\naligned with the real-world software development requirements, which can be\nindependently and objectively validated through specified test cases,\nfacilitating the evaluation of instruction-following capability in multi-turn\ninteractions. We evaluate nine prominent LLMs using CodeIF-Bench, and the\nexperimental results reveal a significant disparity between their basic\nprogramming capability and instruction-following capability, particularly as\ntask complexity, context length, and the number of dialogue rounds increase.",
      "tldr_zh": "该论文引入了CodeIF-Bench，一个新的基准，用于评估大型语言模型（LLMs）在交互式代码生成中的指令遵循能力，填补了现有基准忽略多轮交互场景的空白。CodeIF-Bench 包含九种可验证指令，这些指令与真实软件开发需求一致，并通过指定测试用例进行独立客观评估。实验结果显示，九个主要LLMs 的指令遵循能力显著低于其基本编程能力，且差距在任务复杂度、上下文长度和对话轮数增加时进一步扩大。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.22688v2",
      "published_date": "2025-03-05 09:47:02 UTC",
      "updated_date": "2025-05-08 04:56:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:22:39.929192"
    },
    {
      "arxiv_id": "2503.05823v1",
      "title": "Introduction to Artificial Consciousness: History, Current Trends and Ethical Challenges",
      "title_zh": "人工意识导论：历史、当前趋势和伦理挑战",
      "authors": [
        "Aïda Elamrani"
      ],
      "abstract": "With the significant progress of artificial intelligence (AI) and\nconsciousness science, artificial consciousness (AC) has recently gained\npopularity. This work provides a broad overview of the main topics and current\ntrends in AC. The first part traces the history of this interdisciplinary field\nto establish context and clarify key terminology, including the distinction\nbetween Weak and Strong AC. The second part examines major trends in AC\nimplementations, emphasising the synergy between Global Workspace and Attention\nSchema, as well as the problem of evaluating the internal states of artificial\nsystems. The third part analyses the ethical dimension of AC development,\nrevealing both critical risks and transformative opportunities. The last part\noffers recommendations to guide AC research responsibly, and outlines the\nlimitations of this study as well as avenues for future research. The main\nconclusion is that while AC appears both indispensable and inevitable for\nscientific progress, serious efforts are required to address the far-reaching\nimpact of this innovative research path.",
      "tldr_zh": "这篇论文介绍了人工意识 (AC) 的发展，提供了一个广泛的概述，包括其历史、当前趋势和伦理挑战。第一部分追溯了 AC 的历史背景，澄清了关键术语，如 Weak and Strong AC 的区别。第二部分探讨了 AC 实现的重大趋势，强调 Global Workspace 和 Attention Schema 的协同作用，以及评估人工系统内部状态的难题。论文最终分析了 AC 发展的伦理风险与机遇，并提出责任指导建议，指出尽管 AC 对科学进步不可或缺，但需努力应对其深远影响。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "65 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.05823v1",
      "published_date": "2025-03-05 09:34:36 UTC",
      "updated_date": "2025-03-05 09:34:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:22:51.059319"
    },
    {
      "arxiv_id": "2503.03283v1",
      "title": "Exploring specialization and sensitivity of convolutional neural networks in the context of simultaneous image augmentations",
      "title_zh": "在同时图像增强的背景下探索卷积神经网络的专业化和敏感性",
      "authors": [
        "Pavel Kharyuk",
        "Sergey Matveev",
        "Ivan Oseledets"
      ],
      "abstract": "Drawing parallels with the way biological networks are studied, we adapt the\ntreatment--control paradigm to explainable artificial intelligence research and\nenrich it through multi-parametric input alterations. In this study, we propose\na framework for investigating the internal inference impacted by input data\naugmentations. The internal changes in network operation are reflected in\nactivation changes measured by variance, which can be decomposed into\ncomponents related to each augmentation, employing Sobol indices and Shapley\nvalues. These quantities enable one to visualize sensitivity to different\nvariables and use them for guided masking of activations. In addition, we\nintroduce a way of single-class sensitivity analysis where the candidates are\nfiltered according to their matching to prediction bias generated by targeted\ndamaging of the activations. Relying on the observed parallels, we assume that\nthe developed framework can potentially be transferred to studying biological\nneural networks in complex environments.",
      "tldr_zh": "这篇论文探索卷积神经网络(CNNs)在同时图像增强下的专业化和敏感性，借鉴生物网络研究的治疗-控制范式，并通过多参数输入改变来丰富该框架。研究提出一种方法，通过测量激活变化的方差，并利用Sobol indices和Shapley values将方差分解为与每个增强相关的组件，从而可视化网络对不同变量的敏感性，并指导激活掩码。论文还引入单类敏感性分析，通过针对性破坏激活生成预测偏差来过滤候选，并假设该框架可扩展到生物神经网络在复杂环境中的研究。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "cs.NA",
        "math.NA",
        "68T07",
        "I.2.6; G.3; I.2.10"
      ],
      "primary_category": "stat.ML",
      "comment": "26 pages; main text: 5 figures, 4 tables; appendix: 4 sections, 3\n  tables; supplementary: 7 files (figures S1-S6: packed as 7z archive, S7:\n  single pdf file)",
      "pdf_url": "http://arxiv.org/pdf/2503.03283v1",
      "published_date": "2025-03-05 09:09:01 UTC",
      "updated_date": "2025-03-05 09:09:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:23:04.106566"
    },
    {
      "arxiv_id": "2503.04830v3",
      "title": "Cite Before You Speak: Enhancing Context-Response Grounding in E-commerce Conversational LLM-Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Jingying Zeng",
        "Hui Liu",
        "Zhenwei Dai",
        "Xianfeng Tang",
        "Chen Luo",
        "Samarth Varshney",
        "Zhen Li",
        "Qi He"
      ],
      "abstract": "With the advancement of conversational large language models (LLMs), several\nLLM-based Conversational Shopping Agents (CSA) have been developed to help\ncustomers smooth their online shopping. The primary objective in building an\nengaging and trustworthy CSA is to ensure the agent's responses about product\nfactoids are accurate and factually grounded. However, two challenges remain.\nFirst, LLMs produce hallucinated or unsupported claims. Such inaccuracies risk\nspreading misinformation and diminishing customer trust. Second, without\nproviding knowledge source attribution in CSA response, customers struggle to\nverify LLM-generated information. To address both challenges, we present an\neasily productionized solution that enables a ''citation experience'' to our\ncustomers. We build auto-evaluation metrics to holistically evaluate LLM's\ngrounding and attribution capabilities, suggesting that citation generation\nparadigm substantially improves grounding performance by 13.83%. To deploy this\ncapability at scale, we introduce Multi-UX-Inference system, which appends\nsource citations to LLM outputs while preserving existing user experience\nfeatures and supporting scalable inference. Large-scale online A/B tests show\nthat grounded CSA responses improves customer engagement by 3% - 10%, depending\non UX variations.",
      "tldr_zh": "这篇论文针对电商对话式大型语言模型（LLMs）代理（Conversational Shopping Agents, CSA）的问题，提出了一种“Cite Before You Speak”方法，以提升响应与上下文的grounding和attribution能力，解决LLMs的幻觉生成和知识来源归因缺失。研究者构建了自动评估指标，发现引用生成范式将grounding性能提高了13.83%，并引入Multi-UX-Inference系统来无缝添加来源引用，同时支持可扩展推理。大规模在线A/B测试结果显示，这种grounded响应提升了客户参与度3%至10%，从而增强了CSA的可靠性和用户信任。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04830v3",
      "published_date": "2025-03-05 08:58:35 UTC",
      "updated_date": "2025-05-13 05:02:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:23:16.767062"
    },
    {
      "arxiv_id": "2503.03274v1",
      "title": "Benchmarking Dynamic SLO Compliance in Distributed Computing Continuum Systems",
      "title_zh": "分布式计算连续体系统中的动态 SLO 合规基准测试",
      "authors": [
        "Alfreds Lapkovskis",
        "Boris Sedlak",
        "Sindri Magnússon",
        "Schahram Dustdar",
        "Praveen Kumar Donta"
      ],
      "abstract": "Ensuring Service Level Objectives (SLOs) in large-scale architectures, such\nas Distributed Computing Continuum Systems (DCCS), is challenging due to their\nheterogeneous nature and varying service requirements across different devices\nand applications. Additionally, unpredictable workloads and resource\nlimitations lead to fluctuating performance and violated SLOs. To improve SLO\ncompliance in DCCS, one possibility is to apply machine learning; however, the\ndesign choices are often left to the developer. To that extent, we provide a\nbenchmark of Active Inference -- an emerging method from neuroscience --\nagainst three established reinforcement learning algorithms (Deep Q-Network,\nAdvantage Actor-Critic, and Proximal Policy Optimization). We consider a\nrealistic DCCS use case: an edge device running a video conferencing\napplication alongside a WebSocket server streaming videos. Using one of the\nrespective algorithms, we continuously monitor key performance metrics, such as\nlatency and bandwidth usage, to dynamically adjust parameters -- including the\nnumber of streams, frame rate, and resolution -- to optimize service quality\nand user experience. To test algorithms' adaptability to constant system\nchanges, we simulate dynamically changing SLOs and both instant and gradual\ndata-shift scenarios, such as network bandwidth limitations and fluctuating\ndevice thermal states. Although the evaluated algorithms all showed advantages\nand limitations, our findings demonstrate that Active Inference is a promising\napproach for ensuring SLO compliance in DCCS, offering lower memory usage,\nstable CPU utilization, and fast convergence.",
      "tldr_zh": "本研究针对分布式计算连续系统（Distributed Computing Continuum Systems, DCCS）的动态服务水平目标（Service Level Objectives, SLOs）遵守问题，进行基准测试。论文将新兴的Active Inference方法与三种强化学习算法（Deep Q-Network、Advantage Actor-Critic和Proximal Policy Optimization）进行比较，通过监控关键性能指标（如延迟和带宽使用）来动态调整参数，例如流数量、帧率和分辨率，以优化视频会议应用的服务质量。实验模拟了动态变化的SLOs以及即时或渐进的数据移位场景，如网络带宽限制和设备热状态波动。结果显示，Active Inference在内存使用、CPU利用率和收敛速度方面表现出色，是确保DCCS中SLO遵守的潜在有效方法。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG",
        "cs.NI",
        "cs.PF"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03274v1",
      "published_date": "2025-03-05 08:56:26 UTC",
      "updated_date": "2025-03-05 08:56:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:23:28.856169"
    },
    {
      "arxiv_id": "2503.03269v2",
      "title": "Conformal Transformations for Symmetric Power Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Saurabh Kumar",
        "Jacob Buckman",
        "Carles Gelada",
        "Sean Zhang"
      ],
      "abstract": "Transformers with linear attention offer significant computational advantages\nover softmax-based transformers but often suffer from degraded performance. The\nsymmetric power (sympow) transformer, a particular type of linear transformer,\naddresses some of this performance gap by leveraging symmetric tensor\nembeddings, achieving comparable performance to softmax transformers. However,\nthe finite capacity of the recurrent state in sympow transformers limits their\nability to retain information, leading to performance degradation when scaling\nthe training or evaluation context length. To address this issue, we propose\nthe conformal-sympow transformer, which dynamically frees up capacity using\ndata-dependent multiplicative gating and adaptively stores information using\ndata-dependent rotary embeddings. Preliminary experiments on the LongCrawl64\ndataset demonstrate that conformal-sympow overcomes the limitations of sympow\ntransformers, achieving robust performance across scaled training and\nevaluation contexts.",
      "tldr_zh": "该论文探讨了线性注意力 Transformer 的计算优势及其性能劣势，特别针对 symmetric power (sympow) transformers 的问题，后者通过对称张量嵌入实现了与 softmax transformers 相当的性能，但受限于循环状态的有限容量，在扩展训练或评估上下文长度时表现下降。为解决此问题，研究提出 conformal-sympow transformer，利用数据依赖的乘法门控动态释放容量，并通过数据依赖的 rotary embeddings 适应性存储信息。初步实验在 LongCrawl64 数据集上表明，该方法显著提升了性能，使其在更长上下文中保持稳健。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "SCOPE Workshop at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.03269v2",
      "published_date": "2025-03-05 08:50:53 UTC",
      "updated_date": "2025-05-03 05:24:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:23:39.784324"
    },
    {
      "arxiv_id": "2503.03262v1",
      "title": "Trajectory Prediction for Autonomous Driving: Progress, Limitations, and Future Directions",
      "title_zh": "自动驾驶的轨迹预测：进展、局限性以及未来方向",
      "authors": [
        "Nadya Abdel Madjid",
        "Abdulrahman Ahmad",
        "Murad Mebrahtu",
        "Yousef Babaa",
        "Abdelmoamen Nasser",
        "Sumbal Malik",
        "Bilal Hassan",
        "Naoufel Werghi",
        "Jorge Dias",
        "Majid Khonji"
      ],
      "abstract": "As the potential for autonomous vehicles to be integrated on a large scale\ninto modern traffic systems continues to grow, ensuring safe navigation in\ndynamic environments is crucial for smooth integration. To guarantee safety and\nprevent collisions, autonomous vehicles must be capable of accurately\npredicting the trajectories of surrounding traffic agents. Over the past\ndecade, significant efforts from both academia and industry have been dedicated\nto designing solutions for precise trajectory forecasting. These efforts have\nproduced a diverse range of approaches, raising questions about the differences\nbetween these methods and whether trajectory prediction challenges have been\nfully addressed. This paper reviews a substantial portion of recent trajectory\nprediction methods and devises a taxonomy to classify existing solutions. A\ngeneral overview of the prediction pipeline is also provided, covering input\nand output modalities, modeling features, and prediction paradigms discussed in\nthe literature. In addition, the paper discusses active research areas within\ntrajectory prediction, addresses the posed research questions, and highlights\nthe remaining research gaps and challenges.",
      "tldr_zh": "这篇论文回顾了自动驾驶领域中轨迹预测（trajectory prediction）的进展、限制及未来方向，强调了准确预测周围交通代理轨迹对于确保车辆安全导航的重要性。作者分析了过去十年的学术和工业方法，建立了一个分类taxonomy，并概述了预测管道的输入输出模态、建模特征和预测范式。论文讨论了活跃研究领域、现有挑战，并指出了研究空白，如方法差异和未解决的问题，为未来trajectory prediction研究提供了关键见解。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03262v1",
      "published_date": "2025-03-05 08:38:51 UTC",
      "updated_date": "2025-03-05 08:38:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:23:50.901913"
    },
    {
      "arxiv_id": "2503.03258v1",
      "title": "Exploring the Potential of Large Language Models as Predictors in Dynamic Text-Attributed Graphs",
      "title_zh": "探索大语言模型在动态文本属性图中作为预测器的潜力",
      "authors": [
        "Runlin Lei",
        "Jiarui Ji",
        "Haipeng Ding",
        "Lu Yi",
        "Zhewei Wei",
        "Yongchao Liu",
        "Chuntao Hong"
      ],
      "abstract": "With the rise of large language models (LLMs), there has been growing\ninterest in Graph Foundation Models (GFMs) for graph-based tasks. By leveraging\nLLMs as predictors, GFMs have demonstrated impressive generalizability across\nvarious tasks and datasets. However, existing research on LLMs as predictors\nhas predominantly focused on static graphs, leaving their potential in dynamic\ngraph prediction unexplored. In this work, we pioneer using LLMs for predictive\ntasks on dynamic graphs. We identify two key challenges: the constraints\nimposed by context length when processing large-scale historical data and the\nsignificant variability in domain characteristics, both of which complicate the\ndevelopment of a unified predictor. To address these challenges, we propose the\nGraphAgent-Dynamic (GAD) Framework, a multi-agent system that leverages\ncollaborative LLMs. In contrast to using a single LLM as the predictor, GAD\nincorporates global and local summary agents to generate domain-specific\nknowledge, enhancing its transferability across domains. Additionally,\nknowledge reflection agents enable adaptive updates to GAD's knowledge,\nmaintaining a unified and self-consistent architecture. In experiments, GAD\ndemonstrates performance comparable to or even exceeds that of full-supervised\ngraph neural networks without dataset-specific training. Finally, to enhance\nthe task-specific performance of LLM-based predictors, we discuss potential\nimprovements, such as dataset-specific fine-tuning to LLMs. By developing\ntailored strategies for different tasks, we provide new insights for the future\ndesign of LLM-based predictors.",
      "tldr_zh": "本文探讨了使用大型语言模型(LLMs)作为预测器在动态文本属性图上的潜力，填补了现有研究主要聚焦静态图的空白。研究提出GraphAgent-Dynamic (GAD)框架，这是一个多智能体系统，通过全球和本地摘要代理生成领域特定知识，并利用知识反射代理实现适应性更新，以提升跨域转移能力和统一性。实验结果显示，GAD的性能可与全监督图神经网络相当或更优，且无需数据集特定训练；此外，论文讨论了如数据集微调等策略，以进一步提升LLMs在任务特定场景中的表现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03258v1",
      "published_date": "2025-03-05 08:28:11 UTC",
      "updated_date": "2025-03-05 08:28:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:24:04.414967"
    },
    {
      "arxiv_id": "2503.03792v1",
      "title": "Rebalanced Multimodal Learning with Data-aware Unimodal Sampling",
      "title_zh": "翻译失败",
      "authors": [
        "Qingyuan Jiang",
        "Zhouyang Chi",
        "Xiao Ma",
        "Qirong Mao",
        "Yang Yang",
        "Jinhui Tang"
      ],
      "abstract": "To address the modality learning degeneration caused by modality imbalance,\nexisting multimodal learning~(MML) approaches primarily attempt to balance the\noptimization process of each modality from the perspective of model learning.\nHowever, almost all existing methods ignore the modality imbalance caused by\nunimodal data sampling, i.e., equal unimodal data sampling often results in\ndiscrepancies in informational content, leading to modality imbalance.\nTherefore, in this paper, we propose a novel MML approach called\n\\underline{D}ata-aware \\underline{U}nimodal \\underline{S}ampling~(\\method),\nwhich aims to dynamically alleviate the modality imbalance caused by sampling.\nSpecifically, we first propose a novel cumulative modality discrepancy to\nmonitor the multimodal learning process. Based on the learning status, we\npropose a heuristic and a reinforcement learning~(RL)-based data-aware unimodal\nsampling approaches to adaptively determine the quantity of sampled data at\neach iteration, thus alleviating the modality imbalance from the perspective of\nsampling. Meanwhile, our method can be seamlessly incorporated into almost all\nexisting multimodal learning approaches as a plugin. Experiments demonstrate\nthat \\method~can achieve the best performance by comparing with diverse\nstate-of-the-art~(SOTA) baselines.",
      "tldr_zh": "本研究针对多模态学习（MML）中由单模态数据采样导致的模态不平衡问题，提出了一种新方法 Data-aware Unimodal Sampling（DUST），旨在动态缓解采样引起的差异。DUST 首先引入累积模态差异（cumulative modality discrepancy）指标来监控学习过程，然后通过启发式和 reinforcement learning (RL)-based 的采样策略，适应性调整每个迭代的采样数据量，从而平衡模态信息。实验结果表明，该方法可作为插件无缝整合到现有 MML 框架中，并比 state-of-the-art (SOTA) 基线实现最佳性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03792v1",
      "published_date": "2025-03-05 08:19:31 UTC",
      "updated_date": "2025-03-05 08:19:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:24:16.766853"
    },
    {
      "arxiv_id": "2503.07638v2",
      "title": "Leveraging Taxonomy Similarity for Next Activity Prediction in Patient Treatment",
      "title_zh": "翻译失败",
      "authors": [
        "Martin Kuhn",
        "Joscha Grüger",
        "Tobias Geyer",
        "Ralph Bergmann"
      ],
      "abstract": "The rapid progress in modern medicine presents physicians with complex\nchallenges when planning patient treatment. Techniques from the field of\nPredictive Business Process Monitoring, like Next-activity-prediction (NAP) can\nbe used as a promising technique to support physicians in treatment planning,\nby proposing a possible next treatment step. Existing patient data, often in\nthe form of electronic health records, can be analyzed to recommend the next\nsuitable step in the treatment process. However, the use of patient data poses\nmany challenges due to its knowledge-intensive character, high variability and\nscarcity of medical data. To overcome these challenges, this article examines\nthe use of the knowledge encoded in taxonomies to improve and explain the\nprediction of the next activity in the treatment process. This study proposes\nthe TS4NAP approach, which uses medical taxonomies (ICD-10-CM and ICD-10-PCS)\nin combination with graph matching to assess the similarities of medical codes\nto predict the next treatment step. The effectiveness of the proposed approach\nwill be evaluated using event logs that are derived from the MIMIC-IV dataset.\nThe results highlight the potential of using domain-specific knowledge held in\ntaxonomies to improve the prediction of the next activity, and thus can improve\ntreatment planning and decision-making by making the predictions more\nexplainable.",
      "tldr_zh": "本文提出TS4NAP方法，利用医疗分类系统(ICD-10-CM和ICD-10-PCS)结合图匹配技术，评估医疗代码的相似性，以改善患者治疗过程中的下一活动预测(NAP)。该方法针对患者数据知识密集型、高变异性和稀缺性的挑战，通过分析MIMIC-IV数据集的日志进行评估。结果显示，TS4NAP显著提升了预测准确性和可解释性，有助于医生更好地进行治疗规划和决策。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07638v2",
      "published_date": "2025-03-05 08:19:17 UTC",
      "updated_date": "2025-03-17 13:52:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:24:27.991253"
    },
    {
      "arxiv_id": "2503.03245v2",
      "title": "Less is more? Rewards in RL for Cyber Defence",
      "title_zh": "翻译失败",
      "authors": [
        "Elizabeth Bates",
        "Chris Hicks",
        "Vasilios Mavroudis"
      ],
      "abstract": "The last few years have seen an explosion of interest in autonomous cyber\ndefence agents based on deep reinforcement learning. Such agents are typically\ntrained in a cyber gym environment, also known as a cyber simulator, at least\n32 of which have already been built. Most, if not all cyber gyms provide dense\n\"scaffolded\" reward functions which combine many penalties or incentives for a\nrange of (un)desirable states and costly actions. Whilst dense rewards help\nalleviate the challenge of exploring complex environments, yielding seemingly\neffective strategies from relatively few environment steps; they are also known\nto bias the solutions an agent can find, potentially towards suboptimal\nsolutions. This is especially a problem in complex cyber environments where\npolicy weaknesses may not be noticed until exploited by an adversary. In this\nwork we set out to evaluate whether sparse reward functions might enable\ntraining more effective cyber defence agents. Towards this goal we first break\ndown several evaluation limitations in existing work by proposing a ground\ntruth evaluation score that goes beyond the standard RL paradigm used to train\nand evaluate agents. By adapting a well-established cyber gym to accommodate\nour methodology and ground truth score, we propose and evaluate two sparse\nreward mechanisms and compare them with a typical dense reward. Our evaluation\nconsiders a range of network sizes, from 2 to 50 nodes, and both reactive and\nproactive defensive actions. Our results show that sparse rewards, particularly\npositive reinforcement for an uncompromised network state, enable the training\nof more effective cyber defence agents. Furthermore, we show that sparse\nrewards provide more stable training than dense rewards, and that both\neffectiveness and training stability are robust to a variety of cyber\nenvironment considerations.",
      "tldr_zh": "这篇论文探讨了在强化学习（RL）中，使用稀疏奖励函数是否能训练更有效的网络防御代理，以解决密集奖励可能导致偏见和次优策略的问题。作者提出了一种超越标准RL范式的地面真实评估分数，并修改了一个现有的网络模拟环境来评估两种稀疏奖励机制，与典型的密集奖励进行比较。实验结果显示，稀疏奖励，特别是对网络未被入侵状态的正强化，能显著提升代理的有效性，并在不同网络规模（2至50节点）和防御动作（反应性或主动性）下提供更稳定的训练过程。总的来说，该研究证明了稀疏奖励在复杂网络防御环境中的优势。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "4 Pages",
      "pdf_url": "http://arxiv.org/pdf/2503.03245v2",
      "published_date": "2025-03-05 07:53:39 UTC",
      "updated_date": "2025-03-10 15:51:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:24:41.200212"
    },
    {
      "arxiv_id": "2503.03238v1",
      "title": "FANS -- Formal Answer Selection for Natural Language Math Reasoning Using Lean4",
      "title_zh": "翻译失败",
      "authors": [
        "Jiarui Yao",
        "Ruida Wang",
        "Tong Zhang"
      ],
      "abstract": "Large Language Models (LLMs) have displayed astonishing abilities in various\ntasks, especially in text generation, classification, question answering, etc.\nHowever, the reasoning ability of LLMs still faces many debates. The inherent\nambiguity of Natural Language (NL) limits LLMs' ability to perform verifiable\nreasoning, making its answers lack coherence and trustworthy support. To tackle\nthe above problems, we propose a novel framework named FANS: Formal ANswer\nSelection for Natural Language Math Reasoning Using Lean4. To the best of our\nknowledge, it is the first framework that utilizes Lean4 to enhance LLMs' NL\nmath reasoning ability. In particular, given an NL math question and\nLLM-generated answers, FANS first translates it into Lean4 theorem statements.\nThen it tries to prove it using a Lean4 prover and verify it by Lean4. Finally,\nit uses the FL result to assist in answer selection. It enhances LLMs' NL math\nability in providing a computer-verifiable solution for its correct answer and\nproposes an alternative method for answer selection beyond the reward model.\nExtensive experiments indicate the effectiveness of our framework. It can\nimprove the accuracy rate of reward model enhanced LLMs in the MATH-500 dataset\nby at most 1.91% and AMC-23 by at most 8.33% on strong reward-model baselines.\nIn some particular fields like number theory that Lean4 experts in, we can even\nselect all correct solutions. The qualitative analysis also shows our framework\ncan make NL results formally backed by Lean4 proofs. As a pioneering work in\nthe corresponding field, we will open-source all our models and datasets to\nfurther boost the development of the field.",
      "tldr_zh": "这篇论文提出了 FANS 框架，使用 Lean4 来增强大型语言模型 (LLMs) 在自然语言数学推理中的能力，旨在解决 NL 模糊性导致的答案不连贯和不可验证问题。FANS 的方法包括将 NL 数学问题转化为 Lean4 定理语句，然后通过 Lean4 证明器进行证明和验证，最终基于证明结果辅助答案选择，作为 reward model 的替代方案。实验结果显示，该框架在 MATH-500 数据集上将 reward model 增强的 LLMs 准确率提高最多 1.91%，在 AMC-23 上提高最多 8.33%，特别是在数论领域能选择所有正确解决方案。论文作为首创工作，将开源所有模型和数据集，以推动相关领域发展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03238v1",
      "published_date": "2025-03-05 07:34:53 UTC",
      "updated_date": "2025-03-05 07:34:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:24:55.275465"
    },
    {
      "arxiv_id": "2503.03791v1",
      "title": "Predicting Team Performance from Communications in Simulated Search-and-Rescue",
      "title_zh": "通过模拟搜救中的通信预测团队绩效",
      "authors": [
        "Ali Jalal-Kamali",
        "Nikolos Gurney",
        "David Pynadath"
      ],
      "abstract": "Understanding how individual traits influence team performance is valuable,\nbut these traits are not always directly observable. Prior research has\ninferred traits like trust from behavioral data. We analyze conversational data\nto identify team traits and their correlation with teaming outcomes. Using\ntranscripts from a Minecraft-based search-and-rescue experiment, we apply topic\nmodeling and clustering to uncover key interaction patterns. Our findings show\nthat variations in teaming outcomes can be explained through these inferences,\nwith different levels of predictive power derived from individual traits and\nteam dynamics.",
      "tldr_zh": "本研究探讨了从沟通数据预测团队绩效的方法，针对个体特征（如信任）不易直接观察的问题。研究者使用Minecraft-based搜索和救援实验的对话记录，应用topic modeling和clustering技术来识别关键互动模式和团队特征。结果表明，这些特征能有效解释团队结果的差异，其中个体特征和team dynamics提供了不同的预测能力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03791v1",
      "published_date": "2025-03-05 07:20:27 UTC",
      "updated_date": "2025-03-05 07:20:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:25:03.938025"
    },
    {
      "arxiv_id": "2503.03789v1",
      "title": "Positive-Unlabeled Diffusion Models for Preventing Sensitive Data Generation",
      "title_zh": "正未标记扩散模型用于防止敏感数据生成",
      "authors": [
        "Hiroshi Takahashi",
        "Tomoharu Iwata",
        "Atsutoshi Kumagai",
        "Yuuki Yamanaka",
        "Tomoya Yamashita"
      ],
      "abstract": "Diffusion models are powerful generative models but often generate sensitive\ndata that are unwanted by users, mainly because the unlabeled training data\nfrequently contain such sensitive data. Since labeling all sensitive data in\nthe large-scale unlabeled training data is impractical, we address this problem\nby using a small amount of labeled sensitive data. In this paper, we propose\npositive-unlabeled diffusion models, which prevent the generation of sensitive\ndata using unlabeled and sensitive data. Our approach can approximate the\nevidence lower bound (ELBO) for normal (negative) data using only unlabeled and\nsensitive (positive) data. Therefore, even without labeled normal data, we can\nmaximize the ELBO for normal data and minimize it for labeled sensitive data,\nensuring the generation of only normal data. Through experiments across various\ndatasets and settings, we demonstrated that our approach can prevent the\ngeneration of sensitive images without compromising image quality.",
      "tldr_zh": "该研究针对 Diffusion models 在生成过程中可能输出敏感数据的难题，提出 Positive-Unlabeled Diffusion Models 方法，利用少量标记的敏感数据和无标签数据来防止此类问题的发生。该方法通过近似证据下界 (ELBO) 的技术，仅使用无标签和敏感数据，即可最大化正常数据的 ELBO 并最小化敏感数据的 ELBO，从而确保模型仅生成正常数据。在各种数据集上的实验证明，该方法能有效阻止敏感图像的生成，同时不降低图像质量。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ICLR2025. Code is available at\n  https://github.com/takahashihiroshi/pudm",
      "pdf_url": "http://arxiv.org/pdf/2503.03789v1",
      "published_date": "2025-03-05 07:17:48 UTC",
      "updated_date": "2025-03-05 07:17:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:25:16.768213"
    },
    {
      "arxiv_id": "2503.04829v1",
      "title": "StickMotion: Generating 3D Human Motions by Drawing a Stickman",
      "title_zh": "StickMotion：通过绘制简笔人物生成 3D 人体动作",
      "authors": [
        "Tao Wang",
        "Zhihua Wu",
        "Qiaozhi He",
        "Jiaming Chu",
        "Ling Qian",
        "Yu Cheng",
        "Junliang Xing",
        "Jian Zhao",
        "Lei Jin"
      ],
      "abstract": "Text-to-motion generation, which translates textual descriptions into human\nmotions, has been challenging in accurately capturing detailed user-imagined\nmotions from simple text inputs. This paper introduces StickMotion, an\nefficient diffusion-based network designed for multi-condition scenarios, which\ngenerates desired motions based on traditional text and our proposed stickman\nconditions for global and local control of these motions, respectively. We\naddress the challenges introduced by the user-friendly stickman from three\nperspectives: 1) Data generation. We develop an algorithm to generate\nhand-drawn stickmen automatically across different dataset formats. 2)\nMulti-condition fusion. We propose a multi-condition module that integrates\ninto the diffusion process and obtains outputs of all possible condition\ncombinations, reducing computational complexity and enhancing StickMotion's\nperformance compared to conventional approaches with the self-attention module.\n3) Dynamic supervision. We empower StickMotion to make minor adjustments to the\nstickman's position within the output sequences, generating more natural\nmovements through our proposed dynamic supervision strategy. Through\nquantitative experiments and user studies, sketching stickmen saves users about\n51.5% of their time generating motions consistent with their imagination. Our\ncodes, demos, and relevant data will be released to facilitate further research\nand validation within the scientific community.",
      "tldr_zh": "本研究提出StickMotion，一种基于扩散网络的系统，用于从文本描述和用户绘制的stickman生成3D人类动作，其中文本控制全局动作，stickman提供局部控制，从而更准确捕捉用户想象。论文从三个方面解决挑战：开发算法自动生成stickman数据、设计多条件融合模块以高效整合多种输入条件、引入动态监督策略允许对stickman位置微调以产生更自然的动作序列。实验结果显示，使用stickman可为用户节省51.5%的生成时间，同时提升动作一致性，且作者计划发布相关代码和数据以推动进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages, 5 figures, accepted by CVPR2025",
      "pdf_url": "http://arxiv.org/pdf/2503.04829v1",
      "published_date": "2025-03-05 07:16:14 UTC",
      "updated_date": "2025-03-05 07:16:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:25:28.454115"
    },
    {
      "arxiv_id": "2503.22687v1",
      "title": "Qieemo: Speech Is All You Need in the Emotion Recognition in Conversations",
      "title_zh": "Qieemo：对话中情感识别只需语音",
      "authors": [
        "Jinming Chen",
        "Jingyi Fang",
        "Yuanzhong Zheng",
        "Yaoxuan Wang",
        "Haojun Fei"
      ],
      "abstract": "Emotion recognition plays a pivotal role in intelligent human-machine\ninteraction systems. Multimodal approaches benefit from the fusion of diverse\nmodalities, thereby improving the recognition accuracy. However, the lack of\nhigh-quality multimodal data and the challenge of achieving optimal alignment\nbetween different modalities significantly limit the potential for improvement\nin multimodal approaches. In this paper, the proposed Qieemo framework\neffectively utilizes the pretrained automatic speech recognition (ASR) model\nbackbone which contains naturally frame aligned textual and emotional features,\nto achieve precise emotion classification solely based on the audio modality.\nFurthermore, we design the multimodal fusion (MMF) module and cross-modal\nattention (CMA) module in order to fuse the phonetic posteriorgram (PPG) and\nemotional features extracted by the ASR encoder for improving recognition\naccuracy. The experimental results on the IEMOCAP dataset demonstrate that\nQieemo outperforms the benchmark unimodal, multimodal, and self-supervised\nmodels with absolute improvements of 3.0%, 1.2%, and 1.9% respectively.",
      "tldr_zh": "该研究提出Qieemo框架，专注于对话中的情感识别，强调仅使用音频模态即可实现精确分类，从而解决多模态方法中数据质量和模态对齐的挑战。Qieemo利用预训练的ASR模型提取语音后验图(PPG)和情感特征，并通过多模态融合(MMF)模块和跨模态注意力(CMA)模块融合这些特征，提升识别准确性。在IEMOCAP数据集上的实验显示，Qieemo分别比基准单模态、多模态和自监督模型提高了3.0%、1.2%和1.9%的性能，为高效的人机交互情感识别提供了新途径。",
      "categories": [
        "eess.AS",
        "cs.AI"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.22687v1",
      "published_date": "2025-03-05 07:02:30 UTC",
      "updated_date": "2025-03-05 07:02:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:25:40.694353"
    },
    {
      "arxiv_id": "2503.04828v1",
      "title": "Beyond Next Word Prediction: Developing Comprehensive Evaluation Frameworks for measuring LLM performance on real world applications",
      "title_zh": "超越下一个词预测：开发全面的评估框架，用于测量LLM在真实世界应用中的性能",
      "authors": [
        "Vishakha Agrawal",
        "Archie Chaudhury",
        "Shreya Agrawal"
      ],
      "abstract": "While Large Language Models (LLMs) are fundamentally next-token prediction\nsystems, their practical applications extend far beyond this basic function.\nFrom natural language processing and text generation to conversational\nassistants and software use, LLMs have numerous use-cases, and have already\nacquired a significant degree of enterprise adoption. To evaluate such models,\nstatic evaluation datasets, consisting of a set of prompts and their\ncorresponding ground truths, are often used to benchmark the efficacy of the\nmodel for a particular task. In this paper, we provide the basis for a more\ncomprehensive evaluation framework, based upon a traditional game and\ntool-based architecture that enables a more overarching measurement of a\nmodel's capabilities. For simplicity, we provide a generalized foundation that\ncan be extended, without significant alteration, to numerous scenarios, from\nspecific use cases such as supply chain management or financial reasoning, to\nabstract measurements such as ethics or safety.",
      "tldr_zh": "这项研究指出，大型语言模型(LLMs)虽以next-token prediction为基础，但其实际应用已扩展到自然语言处理、对话助手等领域，而传统的静态评估数据集（如prompts和ground truths）不足以全面衡量模型效能。论文提出一个更全面的评价框架，基于传统的游戏和工具架构，以更全面地评估LLMs在真实世界中的能力。该框架提供了一个通用基础，可轻松扩展到具体应用（如供应链管理或金融推理）或抽象领域（如伦理和安全），从而为LLMs性能评估提供更可靠的基准。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04828v1",
      "published_date": "2025-03-05 06:44:38 UTC",
      "updated_date": "2025-03-05 06:44:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:25:53.212125"
    },
    {
      "arxiv_id": "2503.04827v1",
      "title": "Preserving Cultural Identity with Context-Aware Translation Through Multi-Agent AI Systems",
      "title_zh": "通过多智能体 AI 系统进行上下文感知翻译以保护文化身份",
      "authors": [
        "Mahfuz Ahmed Anik",
        "Abdur Rahman",
        "Azmine Toushik Wasi",
        "Md Manjurul Ahsan"
      ],
      "abstract": "Language is a cornerstone of cultural identity, yet globalization and the\ndominance of major languages have placed nearly 3,000 languages at risk of\nextinction. Existing AI-driven translation models prioritize efficiency but\noften fail to capture cultural nuances, idiomatic expressions, and historical\nsignificance, leading to translations that marginalize linguistic diversity. To\naddress these challenges, we propose a multi-agent AI framework designed for\nculturally adaptive translation in underserved language communities. Our\napproach leverages specialized agents for translation, interpretation, content\nsynthesis, and bias evaluation, ensuring that linguistic accuracy and cultural\nrelevance are preserved. Using CrewAI and LangChain, our system enhances\ncontextual fidelity while mitigating biases through external validation.\nComparative analysis shows that our framework outperforms GPT-4o, producing\ncontextually rich and culturally embedded translations, a critical advancement\nfor Indigenous, regional, and low-resource languages. This research underscores\nthe potential of multi-agent AI in fostering equitable, sustainable, and\nculturally sensitive NLP technologies, aligning with the AI Governance,\nCultural NLP, and Sustainable NLP pillars of Language Models for Underserved\nCommunities. Our full experimental codebase is publicly available at:\nhttps://github.com/ciol-researchlab/Context-Aware_Translation_MAS",
      "tldr_zh": "该研究针对全球化导致的语言多样性危机，提出一种基于多智能体AI框架的上下文感知翻译系统，以保护文化身份和细微差异，如习惯表达和历史意义。框架包括专门的智能体（负责翻译、解释、内容合成和偏差评估），并利用CrewAI和LangChain增强上下文忠实度和减少偏差。实验结果显示，该系统优于GPT-4o，在土著、区域和低资源语言的翻译中表现出更丰富的文化嵌入性，为公平、可持续的NLP技术（如AI Governance和Cultural NLP）提供了关键进展，相关代码已在GitHub公开。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted in NAACL 2025 Workshop on Language Models for Underserved\n  Communities (https://openreview.net/forum?id=RiCfefEHII)",
      "pdf_url": "http://arxiv.org/pdf/2503.04827v1",
      "published_date": "2025-03-05 06:43:59 UTC",
      "updated_date": "2025-03-05 06:43:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:26:06.603194"
    },
    {
      "arxiv_id": "2503.03215v1",
      "title": "COSINT-Agent: A Knowledge-Driven Multimodal Agent for Chinese Open Source Intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Wentao Li",
        "Congcong Wang",
        "Xiaoxiao Cui",
        "Zhi Liu",
        "Wei Guo",
        "Lizhen Cui"
      ],
      "abstract": "Open Source Intelligence (OSINT) requires the integration and reasoning of\ndiverse multimodal data, presenting significant challenges in deriving\nactionable insights. Traditional approaches, including multimodal large\nlanguage models (MLLMs), often struggle to infer complex contextual\nrelationships or deliver comprehensive intelligence from unstructured data\nsources. In this paper, we introduce COSINT-Agent, a knowledge-driven\nmultimodal agent tailored to address the challenges of OSINT in the Chinese\ndomain. COSINT-Agent seamlessly integrates the perceptual capabilities of\nfine-tuned MLLMs with the structured reasoning power of the Entity-Event-Scene\nKnowledge Graph (EES-KG). Central to COSINT-Agent is the innovative EES-Match\nframework, which bridges COSINT-MLLM and EES-KG, enabling systematic\nextraction, reasoning, and contextualization of multimodal insights. This\nintegration facilitates precise entity recognition, event interpretation, and\ncontext retrieval, effectively transforming raw multimodal data into actionable\nintelligence. Extensive experiments validate the superior performance of\nCOSINT-Agent across core OSINT tasks, including entity recognition, EES\ngeneration, and context matching. These results underscore its potential as a\nrobust and scalable solution for advancing automated multimodal reasoning and\nenhancing the effectiveness of OSINT methodologies.",
      "tldr_zh": "该论文针对 Open Source Intelligence (OSINT) 中多模态数据整合和推理的挑战，引入了 COSINT-Agent，一种专为中文领域设计的知识驱动多模态代理。COSINT-Agent 结合了微调的 Multimodal Large Language Models (MLLMs) 的感知能力与 Entity-Event-Scene Knowledge Graph (EES-KG) 的结构化推理，通过创新的 EES-Match 框架实现实体识别、事件解释和上下文检索，从而将原始数据转化为可行动的情报。实验验证显示，COSINT-Agent 在实体识别、EES 生成和上下文匹配等核心 OSINT 任务上表现出色，展示了其作为自动化多模态推理的鲁棒解决方案的潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03215v1",
      "published_date": "2025-03-05 06:16:15 UTC",
      "updated_date": "2025-03-05 06:16:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:26:18.638094"
    },
    {
      "arxiv_id": "2503.03211v1",
      "title": "NodeReg: Mitigating the Imbalance and Distribution Shift Effects in Semi-Supervised Node Classification via Norm Consistency",
      "title_zh": "NodeReg：通过范数一致性缓解半监督节点分类中的不平衡和分布偏移效应",
      "authors": [
        "Shenzhi Yang",
        "Jun Xia",
        "Jingbo Zhou",
        "Xingkai Yao",
        "Xiaofang Zhang"
      ],
      "abstract": "Aggregating information from neighboring nodes benefits graph neural networks\n(GNNs) in semi-supervised node classification tasks. Nevertheless, this\nmechanism also renders nodes susceptible to the influence of their neighbors.\nFor instance, this will occur when the neighboring nodes are imbalanced or the\nneighboring nodes contain noise, which can even affect the GNN's ability to\ngeneralize out of distribution. We find that ensuring the consistency of the\nnorm for node representations can significantly reduce the impact of these two\nissues on GNNs. To this end, we propose a regularized optimization method\ncalled NodeReg that enforces the consistency of node representation norms. This\nmethod is simple but effective and satisfies Lipschitz continuity, thus\nfacilitating stable optimization and significantly improving semi-supervised\nnode classification performance under the above two scenarios. To illustrate,\nin the imbalance scenario, when training a GCN with an imbalance ratio of 0.1,\nNodeReg outperforms the most competitive baselines by 1.4%-25.9% in F1 score\nacross five public datasets. Similarly, in the distribution shift scenario,\nNodeReg outperforms the most competitive baseline by 1.4%-3.1% in accuracy.",
      "tldr_zh": "本文提出 NodeReg，一种通过强制节点表示的 norm consistency 来缓解图神经网络 (GNNs) 在半监督节点分类任务中因邻居不平衡和分布偏移问题的影响的方法。NodeReg 采用简单的正则化优化技术，确保 Lipschitz 连续性，从而促进模型的稳定优化并显著提升分类性能。在实验中，NodeReg 在不平衡场景下（如不平衡比率为0.1）在五个公开数据集上比最竞争基线高1.4%-25.9%的 F1 score，在分布偏移场景下高1.4%-3.1%的 accuracy。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03211v1",
      "published_date": "2025-03-05 06:06:16 UTC",
      "updated_date": "2025-03-05 06:06:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:26:30.965948"
    },
    {
      "arxiv_id": "2503.03205v2",
      "title": "MA-LoT: Multi-Agent Lean-based Long Chain-of-Thought Reasoning enhances Formal Theorem Proving",
      "title_zh": "MA-LoT：多智能体基于 Lean 的长链式思维推理增强形式定理证明",
      "authors": [
        "Ruida Wang",
        "Rui Pan",
        "Yuxin Li",
        "Jipeng Zhang",
        "Yizhen Jia",
        "Shizhe Diao",
        "Renjie Pi",
        "Junjie Hu",
        "Tong Zhang"
      ],
      "abstract": "Solving mathematical problems using computer-verifiable languages like Lean\nhas significantly impacted mathematical and computer science communities.\nState-of-the-art methods utilize single Large Language Models (LLMs) as agents\nor provers to either generate complete proof or perform tree searches. However,\nsingle-agent methods inherently lack a structured way to combine high-level\nreasoning in Natural Language (NL) with Formal Language (FL) verification\nfeedback. To solve these issues, we propose MA-LoT: Multi-Agent Lean-based Long\nChain-of-Thought framework, (to the best of our knowledge), the first\nmulti-agent framework for Lean4 theorem proving that balance high-level NL\nreasoning and FL verification in Long CoT. Using this structured interaction,\nour approach enables deeper insights and long-term coherence in proof\ngeneration, with which past methods struggle. We do this by leveraging emergent\nformal reasoning ability in Long CoT using our novel LoT-Transfer Learning\ntraining-inference pipeline. Extensive experiments show that our framework\nachieves a 61.07% accuracy rate on the Lean4 version of the MiniF2F-Test\ndataset, largely outperforming GPT-4 (22.95%), single-agent tree search\n(InternLM-Step-Prover, 50.70%), and whole-proof generation (Godel-Prover,\n55.33%) baselines. Furthermore, our findings highlight the potential of\ncombining Long CoT with formal verification for a more insightful generation in\na broader perspective.",
      "tldr_zh": "该研究提出 MA-LoT 框架，这是一个多代理（Multi-Agent）基于 Lean 的 Long Chain-of-Thought (Long CoT) 推理系统，旨在提升形式定理证明（Formal Theorem Proving）能力，通过结合自然语言（NL）的高级推理和形式语言（FL）验证反馈，解决单代理方法的局限性。MA-LoT 利用新型 LoT-Transfer Learning 训练-推理管道，实现更深入的洞察和长期证明一致性。在 MiniF2F-Test 数据集上，框架实现了 61.07% 的准确率，大幅超越 GPT-4 (22.95%) 和其他基线模型（如 InternLM-Step-Prover 的 50.70%），并展示了 Long CoT 与形式验证相结合的潜力，为数学证明生成提供更可靠的见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03205v2",
      "published_date": "2025-03-05 05:50:31 UTC",
      "updated_date": "2025-03-10 17:39:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:26:42.199135"
    },
    {
      "arxiv_id": "2503.03201v1",
      "title": "Towards Robust Universal Information Extraction: Benchmark, Evaluation, and Solution",
      "title_zh": "迈向鲁棒的通用信息抽取：基准测试、评估和解决方案",
      "authors": [
        "Jizhao Zhu",
        "Akang Shi",
        "Zixuan Li",
        "Long Bai",
        "Xiaolong Jin",
        "Jiafeng Guo",
        "Xueqi Cheng"
      ],
      "abstract": "In this paper, we aim to enhance the robustness of Universal Information\nExtraction (UIE) by introducing a new benchmark dataset, a comprehensive\nevaluation, and a feasible solution. Existing robust benchmark datasets have\ntwo key limitations: 1) They generate only a limited range of perturbations for\na single Information Extraction (IE) task, which fails to evaluate the\nrobustness of UIE models effectively; 2) They rely on small models or\nhandcrafted rules to generate perturbations, often resulting in unnatural\nadversarial examples. Considering the powerful generation capabilities of Large\nLanguage Models (LLMs), we introduce a new benchmark dataset for Robust UIE,\ncalled RUIE-Bench, which utilizes LLMs to generate more diverse and realistic\nperturbations across different IE tasks. Based on this dataset, we\ncomprehensively evaluate existing UIE models and reveal that both LLM-based\nmodels and other models suffer from significant performance drops. To improve\nrobustness and reduce training costs, we propose a data-augmentation solution\nthat dynamically selects hard samples for iterative training based on the\nmodel's inference loss. Experimental results show that training with only\n\\textbf{15\\%} of the data leads to an average \\textbf{7.5\\%} relative\nperformance improvement across three IE tasks.",
      "tldr_zh": "本研究针对Universal Information Extraction (UIE)的鲁棒性问题，引入了新基准数据集RUIE-Bench，利用Large Language Models (LLMs)生成更多样且真实的扰动，以覆盖多种IE任务，并弥补现有数据集的局限性。通过全面评估，发现现有UIE模型，包括LLM-based模型，都面临显著性能下降。作者提出了一种数据增强解决方案，通过动态选择困难样本基于模型的推理损失进行迭代训练，结果显示仅使用15%的数据即可使三个IE任务的性能平均相对提升7.5%。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03201v1",
      "published_date": "2025-03-05 05:39:29 UTC",
      "updated_date": "2025-03-05 05:39:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:26:52.033144"
    },
    {
      "arxiv_id": "2503.16477v1",
      "title": "LeRAAT: LLM-Enabled Real-Time Aviation Advisory Tool",
      "title_zh": "翻译失败",
      "authors": [
        "Marc R. Schlichting",
        "Vale Rasmussen",
        "Heba Alazzeh",
        "Houjun Liu",
        "Kiana Jafari",
        "Amelia F. Hardy",
        "Dylan M. Asmar",
        "Mykel J. Kochenderfer"
      ],
      "abstract": "In aviation emergencies, high-stakes decisions must be made in an instant.\nPilots rely on quick access to precise, context-specific information -- an area\nwhere emerging tools like large language models (LLMs) show promise in\nproviding critical support. This paper introduces LeRAAT, a framework that\nintegrates LLMs with the X-Plane flight simulator to deliver real-time,\ncontext-aware pilot assistance. The system uses live flight data, weather\nconditions, and aircraft documentation to generate recommendations aligned with\naviation best practices and tailored to the particular situation. It employs a\nRetrieval-Augmented Generation (RAG) pipeline that extracts and synthesizes\ninformation from aircraft type-specific manuals, including performance\nspecifications and emergency procedures, as well as aviation regulatory\nmaterials, such as FAA directives and standard operating procedures. We\nshowcase the framework in both a virtual reality and traditional on-screen\nsimulation, supporting a wide range of research applications such as pilot\ntraining, human factors research, and operational decision support.",
      "tldr_zh": "本文介绍了LeRAAT框架，这是一个整合Large Language Models (LLMs)的实时航空咨询工具，旨在为飞行员在紧急情况下提供基于上下文的精确支持。该系统利用X-Plane飞行模拟器和Retrieval-Augmented Generation (RAG)管道，从实时飞行数据、天气条件、飞机手册以及航空法规（如FAA指令）中提取并合成信息，生成符合航空最佳实践的个性化推荐。LeRAAT在虚拟现实和传统模拟环境中进行了展示，支持飞行员训练、人因研究和操作决策等应用，展示了其在提升航空安全方面的潜力。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.ET",
        "cs.IR",
        "J.2; H.3.3; H.5.0"
      ],
      "primary_category": "cs.HC",
      "comment": "4 pages, 3 figures, code: https://github.com/sisl/LeRAAT/ , demo\n  video: https://youtu.be/NnijQAlTo-U",
      "pdf_url": "http://arxiv.org/pdf/2503.16477v1",
      "published_date": "2025-03-05 05:34:15 UTC",
      "updated_date": "2025-03-05 05:34:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:27:04.196063"
    },
    {
      "arxiv_id": "2503.03197v1",
      "title": "Directly Follows Graphs Go Predictive Process Monitoring With Graph Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Attila Lischka",
        "Simon Rauch",
        "Oliver Stritzel"
      ],
      "abstract": "In the past years, predictive process monitoring (PPM) techniques based on\nartificial neural networks have evolved as a method to monitor the future\nbehavior of business processes. Existing approaches mostly focus on\ninterpreting the processes as sequences, so-called traces, and feeding them to\nneural architectures designed to operate on sequential data such as recurrent\nneural networks (RNNs) or transformers. In this study, we investigate an\nalternative way to perform PPM: by transforming each process in its\ndirectly-follows-graph (DFG) representation we are able to apply graph neural\nnetworks (GNNs) for the prediction tasks. By this, we aim to develop models\nthat are more suitable for complex processes that are long and contain an\nabundance of loops. In particular, we present different ways to create DFG\nrepresentations depending on the particular GNN we use. The tested GNNs range\nfrom classical node-based to novel edge-based architectures. Further, we\ninvestigate the possibility of using multi-graphs. By these steps, we aim to\ndesign graph representations that minimize the information loss when\ntransforming traces into graphs.",
      "tldr_zh": "本文提出了一种新的预测过程监控 (PPM) 方法，使用直接跟随图 (DFG) 表示将业务过程转换为图形结构，并应用图神经网络 (GNNs) 进行预测任务。不同于传统的基于序列的模型如 Recurrent Neural Networks (RNNs) 或 Transformers，该方法更适合处理复杂、长过程和大量循环。研究探索了多种创建 DFG 的方式，包括节点-based、边-based GNNs 和多图 (multi-graphs)，旨在最小化从序列到图形的信息损失，从而提升模型的适用性和准确性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 4 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.03197v1",
      "published_date": "2025-03-05 05:30:26 UTC",
      "updated_date": "2025-03-05 05:30:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:27:26.033413"
    },
    {
      "arxiv_id": "2503.03787v1",
      "title": "Sarcasm Detection as a Catalyst: Improving Stance Detection with Cross-Target Capabilities",
      "title_zh": "讽刺检测作为催化剂：利用跨目标能力提升立场检测",
      "authors": [
        "Gibson Nkhata Shi Yin Hong",
        "Susan Gauch"
      ],
      "abstract": "Stance Detection (SD) has become a critical area of interest due to its\napplications in various contexts leading to increased research within NLP. Yet\nthe subtlety and complexity of texts sourced from online platforms often\ncontaining sarcastic language pose significant challenges for SD algorithms in\naccurately determining the authors stance. This paper addresses this by\nemploying sarcasm for SD. It also tackles the issue of insufficient annotated\ndata for training SD models on new targets by conducting Cross-Target SD\n(CTSD). The proposed approach involves fine-tuning BERT and RoBERTa models\nfollowed by concatenating additional deep learning layers. The approach is\nassessed against various State-Of-The-Art baselines for SD demonstrating\nsuperior performance using publicly available datasets. Notably our model\noutperforms the best SOTA models on both in-domain SD and CTSD tasks even\nbefore the incorporation of sarcasm-detection pre-training. The integration of\nsarcasm knowledge into the model significantly reduces misclassifications of\nsarcastic text elements in SD allowing our model to accurately predict 85% of\ntexts that were previously misclassified without sarcasm-detection pre-training\non in-domain SD. This enhancement contributes to an increase in the models\naverage macro F1-score. The CTSD task achieves performance comparable to that\nof the in-domain task despite using a zero-shot finetuning. We also reveal that\nthe success of the transfer-learning framework relies on the correlation\nbetween the lexical attributes of sarcasm detection and SD. This study\nrepresents the first exploration of sarcasm detection as an intermediate\ntransfer-learning task within the context of SD while also leveraging the\nconcatenation of BERT or RoBERTa with other deep-learning techniques. The\nproposed approach establishes a foundational baseline for future research in\nthis domain.",
      "tldr_zh": "本文提出了一种利用 Sarcasm Detection 作为中间转移学习任务来提升 Stance Detection (SD) 的方法，特别是针对跨目标 SD (Cross-Target SD, CTSD) 的数据不足问题。方法涉及微调 BERT 和 RoBERTa 模型，并添加额外深度学习层，以处理在线文本中的讽刺语言。实验结果显示，该模型在多种 State-Of-The-Art (SOTA) 基准上表现出优越性能，减少了讽刺文本的误分类，准确预测85%的先前误分类样本，并将平均宏 F1 分数显著提高。研究还揭示了 Sarcasm Detection 和 SD 之间词汇属性的相关性，为未来 CTSD 研究建立了基础基线。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "2 pages, 5 figures, published, published in International Journal On\n  Advances in Intelligent Systems, volume 17, numbers 3 and 4. arXiv admin\n  note: text overlap with arXiv:2503.03172",
      "pdf_url": "http://arxiv.org/pdf/2503.03787v1",
      "published_date": "2025-03-05 05:27:16 UTC",
      "updated_date": "2025-03-05 05:27:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:27:30.759984"
    },
    {
      "arxiv_id": "2503.03194v1",
      "title": "Structured Outputs Enable General-Purpose LLMs to be Medical Experts",
      "title_zh": "结构化",
      "authors": [
        "Guangfu Guo",
        "Kai Zhang",
        "Bryan Hoo",
        "Yujun Cai",
        "Xiaoqian Lu",
        "Nanyun Peng",
        "Yiwei Wang"
      ],
      "abstract": "Medical question-answering (QA) is a critical task for evaluating how\neffectively large language models (LLMs) encode clinical knowledge and\nassessing their potential applications in medicine. Despite showing promise on\nmultiple-choice tests, LLMs frequently struggle with open-ended medical\nquestions, producing responses with dangerous hallucinations or lacking\ncomprehensive coverage of critical aspects. Existing approaches attempt to\naddress these challenges through domain-specific fine-tuning, but this proves\nresource-intensive and difficult to scale across models. To improve the\ncomprehensiveness and factuality of medical responses, we propose a novel\napproach utilizing structured medical reasoning. Our method guides LLMs through\nan seven-step cognitive process inspired by clinical diagnosis, enabling more\naccurate and complete answers without additional training. Experiments on the\nMedLFQA benchmark demonstrate that our approach achieves the highest Factuality\nScore of 85.8, surpassing fine-tuned models. Notably, this improvement\ntransfers to smaller models, highlighting the method's efficiency and\nscalability. Our code and datasets are available.",
      "tldr_zh": "本研究解决了大语言模型(LLMs)在医疗问答(QA)任务中的问题，如幻觉和内容覆盖不全面，通过提出一种结构化医疗推理方法。\n该方法引导 LLMs 进行七步认知过程，灵感来源于临床诊断，从而无需额外训练即可生成更准确和全面的响应。\n在 MedLFQA 基准测试中，该方法取得了 85.8 的 Factuality Score，优于微调模型。\n此外，该方法的效率和可扩展性使其适用于较小模型，提升了 LLMs 在医疗领域的潜在应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03194v1",
      "published_date": "2025-03-05 05:24:55 UTC",
      "updated_date": "2025-03-05 05:24:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:27:41.778788"
    },
    {
      "arxiv_id": "2503.04824v1",
      "title": "ProReflow: Progressive Reflow with Decomposed Velocity",
      "title_zh": "翻译失败",
      "authors": [
        "Lei Ke",
        "Haohang Xu",
        "Xuefei Ning",
        "Yu Li",
        "Jiajun Li",
        "Haoling Li",
        "Yuxuan Lin",
        "Dongsheng Jiang",
        "Yujiu Yang",
        "Linfeng Zhang"
      ],
      "abstract": "Diffusion models have achieved significant progress in both image and video\ngeneration while still suffering from huge computation costs. As an effective\nsolution, flow matching aims to reflow the diffusion process of diffusion\nmodels into a straight line for a few-step and even one-step generation.\nHowever, in this paper, we suggest that the original training pipeline of flow\nmatching is not optimal and introduce two techniques to improve it. Firstly, we\nintroduce progressive reflow, which progressively reflows the diffusion models\nin local timesteps until the whole diffusion progresses, reducing the\ndifficulty of flow matching. Second, we introduce aligned v-prediction, which\nhighlights the importance of direction matching in flow matching over magnitude\nmatching. Experimental results on SDv1.5 and SDXL demonstrate the effectiveness\nof our method, for example, conducting on SDv1.5 achieves an FID of 10.70 on\nMSCOCO2014 validation set with only 4 sampling steps, close to our teacher\nmodel (32 DDIM steps, FID = 10.05).",
      "tldr_zh": "该论文针对扩散模型（diffusion models）在图像和视频生成中的高计算成本问题，提出改进 flow matching 方法，以实现更高效的少步生成。具体地，作者引入 progressive reflow 技术，通过在局部时间步逐步重流扩散过程，降低训练难度；以及 aligned v-prediction 技术，强调方向匹配优于幅度匹配，以提升生成精度。在 SDv1.5 和 SDXL 模型上的实验显示，该方法仅需 4 个采样步即可在 MSCOCO2014 验证集上达到 FID 10.70 的性能，接近基准模型（32 DDIM 步，FID=10.05），显著提高了生成效率。",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.GR",
      "comment": "Our codes will be released at Github",
      "pdf_url": "http://arxiv.org/pdf/2503.04824v1",
      "published_date": "2025-03-05 04:50:53 UTC",
      "updated_date": "2025-03-05 04:50:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:27:52.576030"
    },
    {
      "arxiv_id": "2503.05820v1",
      "title": "The impact of AI and peer feedback on research writing skills: a study using the CGScholar platform among Kazakhstani scholars",
      "title_zh": "翻译失败",
      "authors": [
        "Raigul Zheldibayeva"
      ],
      "abstract": "This research studies the impact of AI and peer feedback on the academic\nwriting development of Kazakhstani scholars using the CGScholar platform - a\nproduct of research into collaborative learning, big data, and artificial\nintelligence developed by educators and computer scientists at the University\nof Illinois at Urbana-Champaign (UIUC). The study aimed to find out how\nfamiliarity with AI tools and peer feedback processes impacts participants'\nopenness to incorporating feedback into their academic writing. The study\ninvolved 36 scholars enrolled in a scientific internship focused on education\nat UIUC. A survey with 15 multiple-choice questions, a Likert scale, and\nopen-ended questions was used to collect data. The survey was conducted via\nGoogle Forms in both English and Russian to ensure linguistic accessibility.\nDemographic information such as age, gender, and first language was collected\nto provide a detailed understanding of the data. The analysis revealed a\nmoderate positive correlation between familiarity with AI tools and openness to\nmaking changes based on feedback, and a strong positive correlation between\nresearch writing experience and expectations of peer feedback, especially in\nthe area of research methodology. These results show that participants are\nopen-minded to AI-assisted feedback; however, they still highly appreciate peer\ninput, especially regarding methodological guidance. This study demonstrates\nthe potential benefits of integrating AI tools with traditional feedback\nmechanisms to improve research writing quality in academic settings.",
      "tldr_zh": "这篇研究探讨了 AI 和同行反馈对哈萨克斯坦学者学术写作技能的影响，采用 CGScholar 平台（由 UIUC 开发的协作学习、大数据和人工智能工具）作为研究基础。研究涉及 36 名学者，通过包含 15 道多选题、Likert 量表和开放问题的调查（以英语和俄语进行）收集数据，并分析了人口统计信息如年龄、性别和第一语言。结果显示，AI 工具熟悉度与基于反馈做出改变的开放度存在中等正相关，而研究写作经验与对同行反馈的期望（尤其在研究方法方面）有强正相关。总体而言，该研究证明了整合 AI 辅助反馈与传统同行机制的潜力，可显著提升学术写作质量。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "11 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.05820v1",
      "published_date": "2025-03-05 04:34:25 UTC",
      "updated_date": "2025-03-05 04:34:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:28:06.063519"
    },
    {
      "arxiv_id": "2503.03172v1",
      "title": "Intermediate-Task Transfer Learning: Leveraging Sarcasm Detection for Stance Detection",
      "title_zh": "中间任务转移学习：利用讽刺检测进行立场检测",
      "authors": [
        "Gibson Nkhata",
        "Susan Gauch"
      ],
      "abstract": "Stance Detection (SD) on social media has emerged as a prominent area of\ninterest with implications for social business and political applications\nthereby garnering escalating research attention within NLP. The inherent\nsubtlety and complexity of texts procured from online platforms pose challenges\nfor SD algorithms in accurately discerning the authors stance. Mostly the\ninclusion of sarcastic and figurative language drastically impacts the\nperformance of SD models. This paper addresses this by employing sarcasm\ndetection intermediate-task transfer learning tailored for SD. The proposed\nmethodology involves the finetuning of BERT and RoBERTa and the concatenation\nof convolutional BiLSTM and dense layers. Rigorous experiments are conducted on\npublicly available datasets to evaluate our transfer-learning framework. The\nperformance of the approach is assessed against various State-Of-The-Art\nbaselines for SD providing empirical evidence of its effectiveness. Notably our\nmodel outperforms the best SOTA models even prior to sarcasm-detection\npretraining. The integration of sarcasm knowledge into the model proves\ninstrumental in mitigating misclassifications of sarcastic textual elements in\nSD. Our model accurately predicts 85% of texts that were previously\nmisclassified by the model without sarcasm-detection pretraining thereby\namplifying the average F1-score of the model. Our experiments also revealed\nthat the success of the transfer-learning framework is contingent upon the\ncorrelation of lexical attributes between the intermediate task and the target\ntask. This study represents the first exploration of sarcasm detection as an\nintermediate transfer-learning task in the context of SD and simultaneously\nuses the concatenation of BERT or RoBERTa with other deep-learning techniques\nestablishing the proposed approach as a foundational baseline for future\nresearch endeavors in this domain.",
      "tldr_zh": "这篇论文探讨了社交媒体上的 Stance Detection (SD) 面临的挑战，特别是讽刺（sarcasm）和比喻语言对模型性能的影响。作者提出了一种中间任务 Transfer Learning 方法，通过 Sarcasm Detection 预训练 BERT 和 RoBERTa，并结合卷积 BiLSTM 和密集层，以提升 SD 的准确性。实验结果显示，该模型在公开数据集上超过了 State-Of-The-Art (SOTA) 基线，提高了 F1-score，并准确预测了85%的先前误分类文本；此外，研究强调了中间任务与目标任务之间词汇属性的相关性对 Transfer Learning 成功的关键作用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 2 figures, published in The Sixteenth International\n  Conference on Information (eKNOW 2024)",
      "pdf_url": "http://arxiv.org/pdf/2503.03172v1",
      "published_date": "2025-03-05 04:30:53 UTC",
      "updated_date": "2025-03-05 04:30:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:28:18.116473"
    },
    {
      "arxiv_id": "2503.03170v1",
      "title": "AttackSeqBench: Benchmarking Large Language Models' Understanding of Sequential Patterns in Cyber Attacks",
      "title_zh": "翻译失败",
      "authors": [
        "Javier Yong",
        "Haokai Ma",
        "Yunshan Ma",
        "Anis Yusof",
        "Zhenkai Liang",
        "Ee-Chien Chang"
      ],
      "abstract": "The observations documented in Cyber Threat Intelligence (CTI) reports play a\ncritical role in describing adversarial behaviors, providing valuable insights\nfor security practitioners to respond to evolving threats. Recent advancements\nof Large Language Models (LLMs) have demonstrated significant potential in\nvarious cybersecurity applications, including CTI report understanding and\nattack knowledge graph construction. While previous works have proposed\nbenchmarks that focus on the CTI extraction ability of LLMs, the sequential\ncharacteristic of adversarial behaviors within CTI reports remains largely\nunexplored, which holds considerable significance in developing a comprehensive\nunderstanding of how adversaries operate. To address this gap, we introduce\nAttackSeqBench, a benchmark tailored to systematically evaluate LLMs'\ncapability to understand and reason attack sequences in CTI reports. Our\nbenchmark encompasses three distinct Question Answering (QA) tasks, each task\nfocuses on the varying granularity in adversarial behavior. To alleviate the\nlaborious effort of QA construction, we carefully design an automated dataset\nconstruction pipeline to create scalable and well-formulated QA datasets based\non real-world CTI reports. To ensure the quality of our dataset, we adopt a\nhybrid approach of combining human evaluation and systematic evaluation\nmetrics. We conduct extensive experiments and analysis with both fast-thinking\nand slow-thinking LLMs, while highlighting their strengths and limitations in\nanalyzing the sequential patterns in cyber attacks. The overarching goal of\nthis work is to provide a benchmark that advances LLM-driven CTI report\nunderstanding and fosters its application in real-world cybersecurity\noperations. Our dataset and code are available at\nhttps://github.com/Javiery3889/AttackSeqBench .",
      "tldr_zh": "本研究引入了AttackSeqBench基准，用于评估大型语言模型(LLMs)在理解网络攻击顺序模式方面的能力，填补了现有工作对CTI报告中对手行为序列特性的忽略。基准包括三个不同粒度的Question Answering(QA)任务，并通过自动数据集构建管道基于真实CTI报告生成可扩展的QA数据集，结合人工和系统评估确保数据质量。实验结果显示，快速思考和缓慢思考的LLMs在分析攻击序列时各有优势和局限性，为推进LLMs在网络安全领域的应用提供了重要参考。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03170v1",
      "published_date": "2025-03-05 04:25:21 UTC",
      "updated_date": "2025-03-05 04:25:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:28:28.962191"
    },
    {
      "arxiv_id": "2503.03156v2",
      "title": "DiRe-JAX: A JAX based Dimensionality Reduction Algorithm for Large-scale Data",
      "title_zh": "DiRe-JAX：基于 JAX 的降维算法，用于大规模数据",
      "authors": [
        "Alexander Kolpakov",
        "Igor Rivin"
      ],
      "abstract": "DiRe - JAX is a new dimensionality reduction toolkit designed to address some\nof the challenges faced by traditional methods like UMAP and tSNE such as loss\nof global structure and computational efficiency. Built on the JAX framework,\nDiRe leverages modern hardware acceleration to provide an efficient, scalable,\nand interpretable solution for visualizing complex data structures, and for\nquantitative analysis of lower-dimensional embeddings. The toolkit shows\nconsiderable promise in preserving both local and global structures within the\ndata as compared to state-of-the-art UMAP and tSNE implementations. This makes\nit suitable for a wide range of applications in machine learning,\nbio-informatics, and data science.",
      "tldr_zh": "DiRe-JAX 是一个基于 JAX 框架的降维算法工具包，旨在解决传统方法如 UMAP 和 tSNE 在丢失全局结构以及计算效率方面的局限性。 该工具包利用硬件加速实现高效、可扩展且可解释的解决方案，能够更好地保留数据中的局部和全局结构。 实验结果显示，DiRe-JAX 在复杂数据可视化和定量分析中表现出色，适用于机器学习、生物信息学和数据科学等广泛领域。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MS",
        "H.1.1; G.4"
      ],
      "primary_category": "cs.LG",
      "comment": "22 pages, 12 figures Github repository available at\n  https://github.com/sashakolpakov/dire-jax Package available on PyPi\n  https://pypi.org/project/dire-jax/",
      "pdf_url": "http://arxiv.org/pdf/2503.03156v2",
      "published_date": "2025-03-05 03:56:01 UTC",
      "updated_date": "2025-03-06 04:40:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:28:40.142319"
    },
    {
      "arxiv_id": "2503.03150v2",
      "title": "Position: Model Collapse Does Not Mean What You Think",
      "title_zh": "观点：模型崩溃并不意味着你所想",
      "authors": [
        "Rylan Schaeffer",
        "Joshua Kazdan",
        "Alvan Caleb Arulandu",
        "Sanmi Koyejo"
      ],
      "abstract": "The proliferation of AI-generated content online has fueled concerns over\n\\emph{model collapse}, a degradation in future generative models' performance\nwhen trained on synthetic data generated by earlier models. Industry leaders,\npremier research journals and popular science publications alike have\nprophesied catastrophic societal consequences stemming from model collapse. In\nthis position piece, we contend this widespread narrative fundamentally\nmisunderstands the scientific evidence. We highlight that research on model\ncollapse actually encompasses eight distinct and at times conflicting\ndefinitions of model collapse, and argue that inconsistent terminology within\nand between papers has hindered building a comprehensive understanding of model\ncollapse. To assess how significantly different interpretations of model\ncollapse threaten future generative models, we posit what we believe are\nrealistic conditions for studying model collapse and then conduct a rigorous\nassessment of the literature's methodologies through this lens. While we leave\nroom for reasonable disagreement, our analysis of research studies, weighted by\nhow faithfully each study matches real-world conditions, leads us to conclude\nthat certain predicted claims of model collapse rely on assumptions and\nconditions that poorly match real-world conditions, and in fact several\nprominent collapse scenarios are readily avoidable. Altogether, this position\npaper argues that model collapse has been warped from a nuanced multifaceted\nconsideration into an oversimplified threat, and that the evidence suggests\nspecific harms more likely under society's current trajectory have received\ndisproportionately less attention.",
      "tldr_zh": "这篇立场论文（position paper）主张，关于“model collapse”的流行担忧被严重误解，该现象指代生成模型在训练合成数据时性能退化，但实际包含八个不同且有时矛盾的定义，导致术语不一致阻碍了全面理解。作者通过提出现实条件评估现有文献的方法论，发现许多预言的“model collapse”场景依赖于不切实际的假设，且这些问题往往可以避免。总体而言，论文认为“model collapse”已被过度简化成一种威胁，而更真实的潜在危害（如当前社会轨迹下的具体风险）应得到更多关注。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03150v2",
      "published_date": "2025-03-05 03:47:17 UTC",
      "updated_date": "2025-03-18 03:48:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:28:51.683331"
    },
    {
      "arxiv_id": "2503.03148v1",
      "title": "Partial Convolution Meets Visual Attention",
      "title_zh": "翻译失败",
      "authors": [
        "Haiduo Huang",
        "Fuwei Yang",
        "Dong Li",
        "Ji Liu",
        "Lu Tian",
        "Jinzhang Peng",
        "Pengju Ren",
        "Emad Barsoum"
      ],
      "abstract": "Designing an efficient and effective neural network has remained a prominent\ntopic in computer vision research. Depthwise onvolution (DWConv) is widely used\nin efficient CNNs or ViTs, but it needs frequent memory access during\ninference, which leads to low throughput. FasterNet attempts to introduce\npartial convolution (PConv) as an alternative to DWConv but compromises the\naccuracy due to underutilized channels. To remedy this shortcoming and consider\nthe redundancy between feature map channels, we introduce a novel Partial\nvisual ATtention mechanism (PAT) that can efficiently combine PConv with visual\nattention. Our exploration indicates that the partial attention mechanism can\ncompletely replace the full attention mechanism and reduce model parameters and\nFLOPs. Our PAT can derive three types of blocks: Partial Channel-Attention\nblock (PAT_ch), Partial Spatial-Attention block (PAT_sp) and Partial\nSelf-Attention block (PAT_sf). First, PAT_ch integrates the enhanced Gaussian\nchannel attention mechanism to infuse global distribution information into the\nuntouched channels of PConv. Second, we introduce the spatial-wise attention to\nthe MLP layer to further improve model accuracy. Finally, we replace PAT_ch in\nthe last stage with the self-attention mechanism to extend the global receptive\nfield. Building upon PAT, we propose a novel hybrid network family, named\nPATNet, which achieves superior top-1 accuracy and inference speed compared to\nFasterNet on ImageNet-1K classification and excel in both detection and\nsegmentation on the COCO dataset. Particularly, our PATNet-T2 achieves 1.3%\nhigher accuracy than FasterNet-T2, while exhibiting 25% higher GPU throughput\nand 24% lower CPU latency.",
      "tldr_zh": "该研究针对高效神经网络设计的问题，提出了一种新型 Partial visual ATtention mechanism (PAT)，将 Partial Convolution (PConv) 与视觉注意力相结合，以解决 PConv 在通道利用上的不足，并减少模型参数和 FLOPs。PAT 包括三种块：Partial Channel-Attention block (PAT_ch) 使用增强的高斯通道注意力机制，Partial Spatial-Attention block (PAT_sp) 在 MLP 层引入空间注意力，以及 Partial Self-Attention block (PAT_sf) 以扩展全局感受野。基于 PAT，作者开发了 PATNet 网络家族，在 ImageNet-1K 分类任务上，PATNet-T2 比 FasterNet-T2 准确率提高 1.3%，同时 GPU 吞吐量提升 25% 且 CPU 延迟降低 24%，并在 COCO 数据集的检测和分割任务中表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2502.01303",
      "pdf_url": "http://arxiv.org/pdf/2503.03148v1",
      "published_date": "2025-03-05 03:42:59 UTC",
      "updated_date": "2025-03-05 03:42:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:29:04.309304"
    },
    {
      "arxiv_id": "2503.04823v2",
      "title": "DA-STGCN: 4D Trajectory Prediction Based on Spatiotemporal Feature Extraction",
      "title_zh": "DA-STGCN：基于时空特征提取的4D轨迹预测",
      "authors": [
        "Yuheng Kuang",
        "Zhengning Wang",
        "Jianping Zhang",
        "Zhenyu Shi",
        "Yuding Zhang"
      ],
      "abstract": "The importance of four-dimensional (4D) trajectory prediction within air\ntraffic management systems is on the rise. Key operations such as conflict\ndetection and resolution, aircraft anomaly monitoring, and the management of\ncongested flight paths are increasingly reliant on this foundational\ntechnology, underscoring the urgent demand for intelligent solutions. The\ndynamics in airport terminal zones and crowded airspaces are intricate and\never-changing; however, current methodologies do not sufficiently account for\nthe interactions among aircraft. To tackle these challenges, we propose\nDA-STGCN, an innovative spatiotemporal graph convolutional network that\nintegrates a dual attention mechanism. Our model reconstructs the adjacency\nmatrix through a self-attention approach, enhancing the capture of node\ncorrelations, and employs graph attention to distill spatiotemporal\ncharacteristics, thereby generating a probabilistic distribution of predicted\ntrajectories. This novel adjacency matrix, reconstructed with the\nself-attention mechanism, is dynamically optimized throughout the network's\ntraining process, offering a more nuanced reflection of the inter-node\nrelationships compared to traditional algorithms. The performance of the model\nis validated on two ADS-B datasets, one near the airport terminal area and the\nother in dense airspace. Experimental results demonstrate a notable improvement\nover current 4D trajectory prediction methods, achieving a 20% and 30%\nreduction in the Average Displacement Error (ADE) and Final Displacement Error\n(FDE), respectively. The incorporation of a Dual-Attention module has been\nshown to significantly enhance the extraction of node correlations, as verified\nby ablation experiments.",
      "tldr_zh": "该论文探讨了4D Trajectory Prediction在航空交通管理中的重要性，强调了现有方法在处理飞机互动和复杂空域时存在的不足。作者提出DA-STGCN，一种创新的Spatiotemporal Graph Convolutional Network，整合了Dual Attention Mechanism，包括自注意力重建邻接矩阵以捕捉节点相关性，以及图注意力提取时空特征，从而生成轨迹的概率分布。实验在两个ADS-B数据集上验证了该模型的表现，相比现有方法，Average Displacement Error (ADE)减少20%，Final Displacement Error (FDE)减少30%，消融实验进一步证实了双重注意力模块对提升预测准确性的关键作用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04823v2",
      "published_date": "2025-03-05 03:42:49 UTC",
      "updated_date": "2025-03-13 03:39:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:29:15.474247"
    },
    {
      "arxiv_id": "2503.03140v2",
      "title": "Knowledge Augmentation in Federation: Rethinking What Collaborative Learning Can Bring Back to Decentralized Data",
      "title_zh": "翻译失败",
      "authors": [
        "Wentai Wu",
        "Ligang He",
        "Saiqin Long",
        "Ahmed M. Abdelmoniem",
        "Yingliang Wu",
        "Rui Mao"
      ],
      "abstract": "Data, as an observable form of knowledge, has become one of the most\nimportant factors of production for the development of Artificial Intelligence\n(AI). Meanwhile, increasing legislation and regulations on private and\nproprietary information results in scattered data sources also known as the\n\"data islands\". Although some collaborative learning paradigms such as\nFederated Learning (FL) can enable privacy-preserving training over\ndecentralized data, they have inherent deficiencies in fairness, costs and\nreproducibility because of being learning-centric, which greatly limits the way\nhow participants cooperate with each other. In light of this, we present a\nknowledge-centric paradigm termed Knowledge Augmentation in Federation (KAF),\nwith focus on how to enhance local knowledge through collaborative effort. We\nprovide the suggested system architecture, formulate the prototypical\noptimization objective, and review emerging studies that employ methodologies\nsuitable for KAF. On our roadmap, with a three-way categorization we describe\nthe methods for knowledge expansion, knowledge filtering, and label and feature\nspace correction in the federation. Further, we highlight several challenges\nand open questions that deserve more attention from the community. With our\ninvestigation, we intend to offer new insights for what collaborative learning\ncan bring back to decentralized data.",
      "tldr_zh": "本研究重新审视了协作学习在处理分散数据（decentralized data）时的潜力，指出传统Federated Learning (FL) 因其学习中心化而存在公平性、成本和可复现性问题。论文提出了一种知识中心范式Knowledge Augmentation in Federation (KAF)，旨在通过协作努力增强本地知识，提供系统架构、优化目标，并回顾相关方法。KAF 将方法分为知识扩展、知识过滤以及标签和特征空间修正三大类，同时强调了面临的挑战和开放问题，为协作学习带来新见解以更好地利用数据孤岛（data islands）。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "preprint",
      "pdf_url": "http://arxiv.org/pdf/2503.03140v2",
      "published_date": "2025-03-05 03:26:54 UTC",
      "updated_date": "2025-03-07 02:57:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:29:28.093648"
    },
    {
      "arxiv_id": "2503.03139v1",
      "title": "Convergence Analysis of Federated Learning Methods Using Backward Error Analysis",
      "title_zh": "基于后向误差分析的联邦学习方法收敛性分析",
      "authors": [
        "Jinwoo Lim",
        "Suhyun Kim",
        "Soo-Mook Moon"
      ],
      "abstract": "Backward error analysis allows finding a modified loss function, which the\nparameter updates really follow under the influence of an optimization method.\nThe additional loss terms included in this modified function is called implicit\nregularizer. In this paper, we attempt to find the implicit regularizer for\nvarious federated learning algorithms on non-IID data distribution, and explain\nwhy each method shows different convergence behavior. We first show that the\nimplicit regularizer of FedAvg disperses the gradient of each client from the\naverage gradient, thus increasing the gradient variance. We also empirically\nshow that the implicit regularizer hampers its convergence. Similarly, we\ncompute the implicit regularizers of FedSAM and SCAFFOLD, and explain why they\nconverge better. While existing convergence analyses focus on pointing out the\nadvantages of FedSAM and SCAFFOLD, our approach can explain their limitations\nin complex non-convex settings. In specific, we demonstrate that FedSAM can\npartially remove the bias in the first-order term of the implicit regularizer\nin FedAvg, whereas SCAFFOLD can fully eliminate the bias in the first-order\nterm, but not in the second-order term. Consequently, the implicit regularizer\ncan provide a useful insight on the convergence behavior of federated learning\nfrom a different theoretical perspective.",
      "tldr_zh": "本论文使用 Backward Error Analysis 分析联邦学习算法的隐式正则化器（Implicit Regularizer），以解释不同方法在 non-IID 数据分布下的收敛行为差异。研究发现，FedAvg 的隐式正则化器会增加梯度方差，从而阻碍其收敛，而 FedSAM 和 SCAFFOLD 通过部分或完全消除一阶偏差，实现了更好的收敛性能。总体而言，该方法从新理论视角揭示了这些算法的优势和在复杂非凸场景中的局限性，为联邦学习优化提供了重要洞见。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03139v1",
      "published_date": "2025-03-05 03:26:48 UTC",
      "updated_date": "2025-03-05 03:26:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:29:41.618952"
    },
    {
      "arxiv_id": "2503.03137v2",
      "title": "Learning to Reduce Search Space for Generalizable Neural Routing Solver",
      "title_zh": "翻译失败",
      "authors": [
        "Changliang Zhou",
        "Xi Lin",
        "Zhenkun Wang",
        "Qingfu Zhang"
      ],
      "abstract": "Constructive neural combinatorial optimization (NCO) has attracted growing\nresearch attention due to its ability to solve complex routing problems without\nrelying on handcrafted rules. However, existing NCO methods face significant\nchallenges in generalizing to large-scale problems due to high computational\ncomplexity and inefficient capture of structural patterns. To address this\nissue, we propose a novel learning-based search space reduction method that\nadaptively selects a small set of promising candidate nodes at each step of the\nconstructive NCO process. Unlike traditional methods that rely on fixed\nheuristics, our selection model dynamically prioritizes nodes based on learned\npatterns, significantly reducing the search space while maintaining solution\nquality. Experimental results demonstrate that our method, trained solely on\n100-node instances from uniform distribution, generalizes remarkably well to\nlarge-scale Traveling Salesman Problem (TSP) and Capacitated Vehicle Routing\nProblem (CVRP) instances with up to 1 million nodes from the uniform\ndistribution and over 80K nodes from other distributions.",
      "tldr_zh": "本研究针对Constructive Neural Combinatorial Optimization (NCO)方法在处理大规模路由问题时存在的计算复杂性和结构模式捕获不足问题，提出了一种新型学习-based搜索空间减少方法。该方法通过一个自适应选择模型，在NCO构建过程中动态优先级排序并选取一小套有前景的候选节点，从而显著降低搜索空间，同时保持解决方案质量。实验结果显示，该模型仅在100节点均匀分布实例上训练，即可泛化到高达1百万节点的Traveling Salesman Problem (TSP)和Capacitated Vehicle Routing Problem (CVRP)实例，甚至包括其他分布的80K节点问题，展示了其优秀的泛化能力。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "37 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.03137v2",
      "published_date": "2025-03-05 03:25:09 UTC",
      "updated_date": "2025-05-19 08:14:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:29:52.167800"
    },
    {
      "arxiv_id": "2503.07636v1",
      "title": "An Optimization Algorithm for Multimodal Data Alignment",
      "title_zh": "一种多模态数据对齐的优化算法",
      "authors": [
        "Wei Zhang",
        "Xinyue Wang",
        "Lan Yu",
        "Shi Li"
      ],
      "abstract": "In the data era, the integration of multiple data types, known as\nmultimodality, has become a key area of interest in the research community.\nThis interest is driven by the goal to develop cutting edge multimodal models\ncapable of serving as adaptable reasoning engines across a wide range of\nmodalities and domains. Despite the fervent development efforts, the challenge\nof optimally representing different forms of data within a single unified\nlatent space a crucial step for enabling effective multimodal reasoning has not\nbeen fully addressed. To bridge this gap, we introduce AlignXpert, an\noptimization algorithm inspired by Kernel CCA crafted to maximize the\nsimilarities between N modalities while imposing some other constraints. This\nwork demonstrates the impact on improving data representation for a variety of\nreasoning tasks, such as retrieval and classification, underlining the pivotal\nimportance of data representation.",
      "tldr_zh": "本论文探讨了多模态数据整合的挑战，强调在统一潜在空间（latent space）中优化不同数据形式的表示，以支持有效的多模态推理。为解决这一问题，研究者引入了AlignXpert优化算法，该算法基于Kernel CCA，旨在最大化N个模态之间的相似性，同时施加其他约束。实验结果表明，AlignXpert显著提升了数据表示的质量，从而改善了检索和分类等推理任务的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ACL SRW submission",
      "pdf_url": "http://arxiv.org/pdf/2503.07636v1",
      "published_date": "2025-03-05 03:07:07 UTC",
      "updated_date": "2025-03-05 03:07:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:30:03.848163"
    },
    {
      "arxiv_id": "2503.03129v1",
      "title": "Exploring Neural Ordinary Differential Equations as Interpretable Healthcare classifiers",
      "title_zh": "探索神经常微分方程作为可解释医疗保健分类器",
      "authors": [
        "Shi Li"
      ],
      "abstract": "Deep Learning has emerged as one of the most significant innovations in\nmachine learning. However, a notable limitation of this field lies in the\n``black box\" decision-making processes, which have led to skepticism within\ngroups like healthcare and scientific communities regarding its applicability.\nIn response, this study introduces a interpretable approach using Neural\nOrdinary Differential Equations (NODEs), a category of neural network models\nthat exploit the dynamics of differential equations for representation\nlearning. Leveraging their foundation in differential equations, we illustrate\nthe capability of these models to continuously process textual data, marking\nthe first such model of its kind, and thereby proposing a promising direction\nfor future research in this domain. The primary objective of this research is\nto propose a novel architecture for groups like healthcare that require the\npredictive capabilities of deep learning while emphasizing the importance of\nmodel transparency demonstrated in NODEs.",
      "tldr_zh": "本研究探讨了 Neural Ordinary Differential Equations (NODEs) 作为可解释的医疗分类器，以解决深度学习的“黑箱”决策问题，从而增强其在医疗领域的可信度。NODEs 利用微分方程的动态进行表示学习，实现对文本数据的连续处理，这是首个此类模型。研究提出了一种新型架构，结合深度学习的预测能力与 NODEs 的透明性，为医疗等需要模型可解释性的领域提供新方向。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ACL SRW Submission",
      "pdf_url": "http://arxiv.org/pdf/2503.03129v1",
      "published_date": "2025-03-05 02:51:50 UTC",
      "updated_date": "2025-03-05 02:51:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:30:14.929353"
    },
    {
      "arxiv_id": "2503.03128v1",
      "title": "Towards Understanding Multi-Round Large Language Model Reasoning: Approximability, Learnability and Generalizability",
      "title_zh": "迈向理解多轮大型语言模型推理：近似性、可学习性和泛化性",
      "authors": [
        "Chenhui Xu",
        "Dancheng Liu",
        "Jiajie Li",
        "Amir Nassereldine",
        "Zhaohui Li",
        "Jinjun Xiong"
      ],
      "abstract": "Recent advancements in cognitive science and multi-round reasoning techniques\nfor Large Language Models (LLMs) suggest that iterative thinking processes\nimprove problem-solving performance in complex tasks. Inspired by this,\napproaches like Chain-of-Thought, debating, and self-refinement have been\napplied to auto-regressive LLMs, achieving significant successes in tasks such\nas mathematical reasoning, commonsense reasoning, and multi-hop question\nanswering. Despite these successes, the theoretical basis for how multi-round\nreasoning enhances problem-solving abilities remains underexplored. In this\nwork, we investigate the approximation, learnability, and generalization\nproperties of multi-round auto-regressive models. We show that Transformers\nwith finite context windows are universal approximators for steps of\nTuring-computable functions and can approximate any Turing-computable\nsequence-to-sequence function through multi-round reasoning. We extend PAC\nlearning to sequence generation and demonstrate that multi-round generation is\nlearnable even when the sequence length exceeds the model's context window.\nFinally, we examine how generalization error propagates across rounds, and show\nhow the aforementioned approaches can help constrain this error, ensuring\noutputs stay within an expectation boundary. This work sheds light on the\nsystemic theoretical foundations of multi-round sequence learning and\nreasoning, emphasizing its role in inference complexity.",
      "tldr_zh": "这篇论文探讨了多轮推理在Large Language Models (LLMs)中的理论基础，重点分析其approximability（近似性）、learnability（可学习性）和generalizability（泛化性）。研究证明，Transformers作为通用逼近器，能够模拟Turing-computable函数，并通过多轮推理处理超出上下文窗口的序列生成任务。论文扩展了PAC learning到序列生成领域，证明多轮生成即使在序列长度超过模型限制时也能被学习，并展示了如何通过Chain-of-Thought等方法控制泛化错误传播。该工作为多轮序列学习和推理提供了系统理论支撑，强调其在提升推理复杂性中的关键作用。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03128v1",
      "published_date": "2025-03-05 02:50:55 UTC",
      "updated_date": "2025-03-05 02:50:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:30:29.228701"
    },
    {
      "arxiv_id": "2503.03122v4",
      "title": "The Devil Is in the Details: Tackling Unimodal Spurious Correlations for Generalizable Multimodal Reward Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zichao Li",
        "Xueru Wen",
        "Jie Lou",
        "Yuqiu Ji",
        "Yaojie Lu",
        "Xianpei Han",
        "Debing Zhang",
        "Le Sun"
      ],
      "abstract": "Multimodal Reward Models (MM-RMs) are crucial for aligning Large Language\nModels (LLMs) with human preferences, particularly as LLMs increasingly\ninteract with multimodal data. However, we find that MM-RMs trained on existing\ndatasets often struggle to generalize to out-of-distribution data due to their\nreliance on unimodal spurious correlations, primarily text-only shortcuts\nwithin the training distribution, which prevents them from leveraging true\nmultimodal reward functions. To address this, we introduce a Shortcut-aware\nMM-RM learning algorithm that mitigates this issue by dynamically reweighting\ntraining samples, shifting the distribution toward better multimodal\nunderstanding, and reducing dependence on unimodal spurious correlations. Our\nexperiments demonstrate significant improvements in generalization, downstream\ntask performance, and scalability, establishing a more robust framework for\nmultimodal reward modeling.",
      "tldr_zh": "该研究发现，现有的 Multimodal Reward Models (MM-RMs) 在训练时依赖于 unimodal spurious correlations（如文本快捷方式），导致其在处理分布外数据时泛化能力不足，无法有效利用真正的多模态奖励函数。针对这一问题，论文提出了一种 Shortcut-aware MM-RM 学习算法，通过动态重新加权训练样本来调整分布，增强多模态理解并减少对单模态相关性的依赖。实验结果显示，该方法显著提升了 MM-RMs 的泛化能力、下游任务性能和可扩展性，为构建更稳健的多模态奖励模型框架提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.03122v4",
      "published_date": "2025-03-05 02:37:41 UTC",
      "updated_date": "2025-05-21 14:00:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:30:40.163333"
    },
    {
      "arxiv_id": "2503.03112v1",
      "title": "A Multimodal Framework for Topic Propagation Classification in Social Networks",
      "title_zh": "社交网络中主题传播分类的多模态框架",
      "authors": [
        "Yuchuan Jiang",
        "Chaolong Jia",
        "Yunyi Qin",
        "Wei Cai",
        "Yongsen Qian"
      ],
      "abstract": "The rapid proliferation of the Internet and the widespread adoption of social\nnetworks have significantly accelerated information dissemination. However,\nthis transformation has introduced complexities in information capture and\nprocessing, posing substantial challenges for researchers and practitioners.\nPredicting the dissemination of topic-related information within social\nnetworks has thus become a critical research focus. This paper proposes a\npredictive model for topic dissemination in social networks by integrating\nmultidimensional features derived from key dissemination characteristics.\nSpecifically, we introduce two novel indicators, user relationship breadth and\nuser authority, into the PageRank algorithm to quantify user influence more\neffectively. Additionally, we employ a Text-CNN model for sentiment\nclassification, extracting sentiment features from textual content. Temporal\nembeddings of nodes are encoded using a Bi-LSTM model to capture temporal\ndynamics. Furthermore, we refine the measurement of user interaction traces\nwith topics, replacing traditional topic view metrics with a more precise\ncommunication characteristics measure. Finally, we integrate the extracted\nmultidimensional features using a Transformer model, significantly enhancing\npredictive performance. Experimental results demonstrate that our proposed\nmodel outperforms traditional machine learning and unimodal deep learning\nmodels in terms of FI-Score, AUC, and Recall, validating its effectiveness in\npredicting topic propagation within social networks.",
      "tldr_zh": "这篇论文提出了一种多模态框架，用于社交网络中主题传播分类，旨在通过整合多维特征来预测信息传播动态。框架引入用户关系广度和用户权威性指标到 PageRank 算法中，以更准确量化用户影响；同时使用 Text-CNN 进行情感分类、Bi-LSTM 编码节点的时序嵌入，并改进用户互动追踪测量。最终，通过 Transformer 模型整合这些特征，实验结果显示该模型在 FI-Score、AUC 和 Recall 上优于传统机器学习和单模态深度学习模型，验证了其预测效能。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03112v1",
      "published_date": "2025-03-05 02:12:23 UTC",
      "updated_date": "2025-03-05 02:12:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:30:52.079290"
    },
    {
      "arxiv_id": "2503.03108v2",
      "title": "SoK: Knowledge is All You Need: Accelerating Last Mile Delivery for Automated Provenance-based Intrusion Detection with LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Wenrui Cheng",
        "Tiantian Zhu",
        "Chunlin Xiong",
        "Haofei Sun",
        "Zijun Wang",
        "Shunan Jing",
        "Mingqi Lv",
        "Yan Chen"
      ],
      "abstract": "Recently, provenance-based intrusion detection systems (PIDSes) have been\nwidely proposed for endpoint threat analysis. However, due to the lack of\nsystematic integration and utilization of knowledge, existing PIDSes still\nrequire significant manual intervention for practical deployment, making full\nautomation challenging. This paper presents a disruptive innovation by\ncategorizing PIDSes according to the types of knowledge they utilize. In\nresponse to the prevalent issue of ``knowledge silos problem'' in existing\nresearch, we introduce a novel knowledge-driven provenance-based intrusion\ndetection framework, powered by large language models (LLMs). We also present\nOmniSec, a best practice system built upon this framework. By integrating\nattack representation knowledge, threat intelligence knowledge, and benign\nbehavior knowledge, OmniSec outperforms the state-of-the-art approaches on\npublic benchmark datasets. OmniSec is available online at\nhttps://anonymous.4open.science/r/PIDS-with-LLM-613B.",
      "tldr_zh": "本论文系统化地分类了基于provenance的入侵检测系统 (PIDSes)，强调了现有系统因“知识孤岛问题”而依赖大量手动干预，导致自动化部署困难。作者提出一个创新的知识驱动框架，利用大型语言模型 (LLMs) 整合攻击表示知识、威胁情报知识和良性行为知识，以加速PIDSes的“最后一公里”部署。基于此框架，他们开发了OmniSec系统，并在公共基准数据集上超越了最先进方法，为自动化入侵检测提供了高效、可扩展的解决方案。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03108v2",
      "published_date": "2025-03-05 02:08:12 UTC",
      "updated_date": "2025-04-28 12:27:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:31:05.397467"
    },
    {
      "arxiv_id": "2503.03107v1",
      "title": "External Reliable Information-enhanced Multimodal Contrastive Learning for Fake News Detection",
      "title_zh": "外部可靠",
      "authors": [
        "Biwei Cao",
        "Qihang Wu",
        "Jiuxin Cao",
        "Bo Liu",
        "Jie Gui"
      ],
      "abstract": "With the rapid development of the Internet, the information dissemination\nparadigm has changed and the efficiency has been improved greatly. While this\nalso brings the quick spread of fake news and leads to negative impacts on\ncyberspace. Currently, the information presentation formats have evolved\ngradually, with the news formats shifting from texts to multimodal contents. As\na result, detecting multimodal fake news has become one of the research\nhotspots. However, multimodal fake news detection research field still faces\ntwo main challenges: the inability to fully and effectively utilize multimodal\ninformation for detection, and the low credibility or static nature of the\nintroduced external information, which limits dynamic updates. To bridge the\ngaps, we propose ERIC-FND, an external reliable information-enhanced multimodal\ncontrastive learning framework for fake news detection. ERIC-FND strengthens\nthe representation of news contents by entity-enriched external information\nenhancement method. It also enriches the multimodal news information via\nmultimodal semantic interaction method where the multimodal constrative\nlearning is employed to make different modality representations learn from each\nother. Moreover, an adaptive fusion method is taken to integrate the news\nrepresentations from different dimensions for the eventual classification.\nExperiments are done on two commonly used datasets in different languages, X\n(Twitter) and Weibo. Experiment results demonstrate that our proposed model\nERIC-FND outperforms existing state-of-the-art fake news detection methods\nunder the same settings.",
      "tldr_zh": "该研究针对多模态假新闻检测面临的挑战（如无法充分利用多模态信息和外部信息可信度低），提出了一种外部可靠信息增强框架ERIC-FND。框架通过实体丰富的外部信息增强方法加强新闻内容表示，并采用多模态语义交互方法（包括Multimodal Contrastive Learning）让不同模态（如文本和图像）相互学习，同时使用自适应融合方法整合多维度新闻表示以进行最终分类。实验在Twitter和Weibo数据集上显示，ERIC-FND在相同设置下优于现有最先进方法，证明了其有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "accepted by AAAI'25",
      "pdf_url": "http://arxiv.org/pdf/2503.03107v1",
      "published_date": "2025-03-05 02:07:38 UTC",
      "updated_date": "2025-03-05 02:07:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:31:17.606833"
    },
    {
      "arxiv_id": "2503.04822v1",
      "title": "HeTGB: A Comprehensive Benchmark for Heterophilic Text-Attributed Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Shujie Li",
        "Yuxia Wu",
        "Chuan Shi",
        "Yuan Fang"
      ],
      "abstract": "Graph neural networks (GNNs) have demonstrated success in modeling relational\ndata primarily under the assumption of homophily. However, many real-world\ngraphs exhibit heterophily, where linked nodes belong to different categories\nor possess diverse attributes. Additionally, nodes in many domains are\nassociated with textual descriptions, forming heterophilic text-attributed\ngraphs (TAGs). Despite their significance, the study of heterophilic TAGs\nremains underexplored due to the lack of comprehensive benchmarks. To address\nthis gap, we introduce the Heterophilic Text-attributed Graph Benchmark\n(HeTGB), a novel benchmark comprising five real-world heterophilic graph\ndatasets from diverse domains, with nodes enriched by extensive textual\ndescriptions. HeTGB enables systematic evaluation of GNNs, pre-trained language\nmodels (PLMs) and co-training methods on the node classification task. Through\nextensive benchmarking experiments, we showcase the utility of text attributes\nin heterophilic graphs, analyze the challenges posed by heterophilic TAGs and\nthe limitations of existing models, and provide insights into the interplay\nbetween graph structures and textual attributes. We have publicly released\nHeTGB with baseline implementations to facilitate further research in this\nfield.",
      "tldr_zh": "该论文介绍了 HeTGB，一种全面基准，用于评估异质性文本属性图（heterophilic text-attributed graphs）。HeTGB 包括五个真实世界数据集，节点带有丰富的文本描述，旨在解决图神经网络（GNNs）在异质性（heterophily）场景下的局限性。研究通过系统实验评估 GNNs、预训练语言模型（PLMs）和联合训练方法在节点分类任务上的性能，突显了文本属性的效用，并分析了现有模型的挑战与图结构与文本属性的互动关系。该基准的公开发布将推动相关领域的研究进展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2503.04822v1",
      "published_date": "2025-03-05 02:00:32 UTC",
      "updated_date": "2025-03-05 02:00:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:31:30.703547"
    },
    {
      "arxiv_id": "2503.03104v1",
      "title": "RVAFM: Re-parameterizing Vertical Attention Fusion Module for Handwritten Paragraph Text Recognition",
      "title_zh": "RVAFM：用于手写段落文本识别的重新参数化垂直注意力融合模块",
      "authors": [
        "Jinhui Zheng",
        "Zhiquan Liu",
        "Yain-Whar Si",
        "Jianqing Li",
        "Xinyuan Zhang",
        "Xiaofan Li",
        "Haozhi Huang",
        "Xueyuan Gong"
      ],
      "abstract": "Handwritten Paragraph Text Recognition (HPTR) is a challenging task in\nComputer Vision, requiring the transformation of a paragraph text image, rich\nin handwritten text, into text encoding sequences. One of the most advanced\nmodels for this task is Vertical Attention Network (VAN), which utilizes a\nVertical Attention Module (VAM) to implicitly segment paragraph text images\ninto text lines, thereby reducing the difficulty of the recognition task.\nHowever, from a network structure perspective, VAM is a single-branch module,\nwhich is less effective in learning compared to multi-branch modules. In this\npaper, we propose a new module, named Re-parameterizing Vertical Attention\nFusion Module (RVAFM), which incorporates structural re-parameterization\ntechniques. RVAFM decouples the structure of the module during training and\ninference stages. During training, it uses a multi-branch structure for more\neffective learning, and during inference, it uses a single-branch structure for\nfaster processing. The features learned by the multi-branch structure are fused\ninto the single-branch structure through a special fusion method named\nRe-parameterization Fusion (RF) without any loss of information. As a result,\nwe achieve a Character Error Rate (CER) of 4.44% and a Word Error Rate (WER) of\n14.37% on the IAM paragraph-level test set. Additionally, the inference speed\nis slightly faster than VAN.",
      "tldr_zh": "该论文针对 Handwritten Paragraph Text Recognition (HPTR) 的挑战，提出了一种新的模块 RVAFM，以改进 Vertical Attention Network (VAN) 中的 Vertical Attention Module (VAM)，解决其单分支结构学习效率低的问题。RVAFM 采用结构重参数化技术，在训练阶段使用多分支结构进行更有效的特征学习，在推理阶段切换到单分支结构以加速处理，并通过 Re-parameterization Fusion (RF) 方法无损融合特征。实验结果显示，在 IAM 数据集上，RVAFM 取得了 4.44% 的 Character Error Rate (CER) 和 14.37% 的 Word Error Rate (WER)，并比 VAN 的推理速度略快。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03104v1",
      "published_date": "2025-03-05 01:41:59 UTC",
      "updated_date": "2025-03-05 01:41:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:31:43.962793"
    },
    {
      "arxiv_id": "2503.04821v2",
      "title": "RGB-Thermal Infrared Fusion for Robust Depth Estimation in Complex Environments",
      "title_zh": "RGB-热红外融合用于复杂环境",
      "authors": [
        "Zelin Meng",
        "Takanori Fukao"
      ],
      "abstract": "Depth estimation in complex real-world scenarios is a challenging task,\nespecially when relying solely on a single modality such as visible light or\nthermal infrared (THR) imagery. This paper proposes a novel multimodal depth\nestimation model, RTFusion, which enhances depth estimation accuracy and\nrobustness by integrating the complementary strengths of RGB and THR data. The\nRGB modality provides rich texture and color information, while the THR\nmodality captures thermal patterns, ensuring stability under adverse lighting\nconditions such as extreme illumination. The model incorporates a unique fusion\nmechanism, EGFusion, consisting of the Mutual Complementary Attention (MCA)\nmodule for cross-modal feature alignment and the Edge Saliency Enhancement\nModule (ESEM) to improve edge detail preservation. Comprehensive experiments on\nthe MS2 and ViViD++ datasets demonstrate that the proposed model consistently\nproduces high-quality depth maps across various challenging environments,\nincluding nighttime, rainy, and high-glare conditions. The experimental results\nhighlight the potential of the proposed method in applications requiring\nreliable depth estimation, such as autonomous driving, robotics, and augmented\nreality.",
      "tldr_zh": "本文提出了一种新型多模态深度估计模型 RTFusion，通过融合 RGB 和 Thermal Infrared (THR) 数据，增强了复杂环境下的深度估计准确性和鲁棒性，其中 RGB 提供丰富的纹理和颜色信息，而 THR 确保在极端照明条件下保持稳定。模型的核心机制 EGFusion 包括 Mutual Complementary Attention (MCA) 模块用于跨模态特征对齐，以及 Edge Saliency Enhancement Module (ESEM) 用于改善边缘细节保留。在 MS2 和 ViViD++ 数据集上的实验显示，RTFusion 在夜间、雨天和高眩光等挑战环境中生成高质量深度图，展示了其在自主驾驶、机器人和增强现实等应用中的潜力。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "7 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.04821v2",
      "published_date": "2025-03-05 01:35:14 UTC",
      "updated_date": "2025-04-29 02:46:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:31:56.267402"
    },
    {
      "arxiv_id": "2503.03084v1",
      "title": "Hopfield Networks Meet Big Data: A Brain-Inspired Deep Learning Framework for Semantic Data Linking",
      "title_zh": "翻译失败",
      "authors": [
        "Ashwin Viswanathan Kannan",
        "Johnson P Thomas",
        "Abhimanyu Mukerji"
      ],
      "abstract": "The exponential rise in data generation has led to vast, heterogeneous\ndatasets crucial for predictive analytics and decision-making. Ensuring data\nquality and semantic integrity remains a challenge. This paper presents a\nbrain-inspired distributed cognitive framework that integrates deep learning\nwith Hopfield networks to identify and link semantically related attributes\nacross datasets. Modeled on the dual-hemisphere functionality of the human\nbrain, the right hemisphere assimilates new information while the left\nretrieves learned representations for association. Our architecture,\nimplemented on MapReduce with Hadoop Distributed File System (HDFS), leverages\ndeep Hopfield networks as an associative memory mechanism to enhance recall of\nfrequently co-occurring attributes and dynamically adjust relationships based\non evolving data patterns. Experiments show that associative imprints in\nHopfield memory are reinforced over time, ensuring linked datasets remain\ncontextually meaningful and improving data disambiguation and integration\naccuracy. Our results indicate that combining deep Hopfield networks with\ndistributed cognitive processing offers a scalable, biologically inspired\napproach to managing complex data relationships in large-scale environments.",
      "tldr_zh": "该论文提出一个脑启发式分布式认知框架，将深度学习与 Hopfield networks 整合，用于识别和链接大数据集中语义相关属性，解决数据质量和语义完整性挑战。该框架模拟人类大脑双半球功能，由右半球处理新信息吸收、左半球负责检索和关联，并在 MapReduce 与 HDFS 上实现，利用 Hopfield networks 作为关联记忆机制动态调整数据关系。实验结果显示，这种方法能强化记忆印记，提高数据消歧和整合准确性，提供一种可扩展的生物启发式方法来管理大规模复杂数据关系。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.03084v1",
      "published_date": "2025-03-05 00:53:22 UTC",
      "updated_date": "2025-03-05 00:53:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:32:05.875020"
    },
    {
      "arxiv_id": "2503.13477v1",
      "title": "Periodontal Bone Loss Analysis via Keypoint Detection With Heuristic Post-Processing",
      "title_zh": "翻译失败",
      "authors": [
        "Ryan Banks",
        "Vishal Thengane",
        "María Eugenia Guerrero",
        "Nelly Maria García-Madueño",
        "Yunpeng Li",
        "Hongying Tang",
        "Akhilanand Chaurasia"
      ],
      "abstract": "Calculating percentage bone loss is a critical test for periodontal disease\nstaging but is sometimes imprecise and time consuming when manually calculated.\nThis study evaluates the application of a deep learning keypoint and object\ndetection model, YOLOv8-pose, for the automatic identification of localised\nperiodontal bone loss landmarks, conditions and staging. YOLOv8-pose was\nfine-tuned on 193 annotated periapical radiographs. We propose a keypoint\ndetection metric, Percentage of Relative Correct Keypoints (PRCK), which\nnormalises the metric to the average tooth size of teeth in the image. We\npropose a heuristic post-processing module that adjusts certain keypoint\npredictions to align with the edge of the related tooth, using a supporting\ninstance segmentation model trained on an open source auxiliary dataset. The\nmodel can sufficiently detect bone loss keypoints, tooth boxes, and alveolar\nridge resorption, but has insufficient performance at detecting detached\nperiodontal ligament and furcation involvement. The model with post-processing\ndemonstrated a PRCK 0.25 of 0.726 and PRCK 0.05 of 0.401 for keypoint\ndetection, mAP 0.5 of 0.715 for tooth object detection, mesial dice score of\n0.593 for periodontal staging, and dice score of 0.280 for furcation\ninvolvement. Our annotation methodology provides a stage agnostic approach to\nperiodontal disease detection, by ensuring most keypoints are present for each\ntooth in the image, allowing small imbalanced datasets. Our PRCK metric allows\naccurate evaluation of keypoints in dental domains. Our post-processing module\nadjusts predicted keypoints correctly but is dependent on a minimum quality of\nprediction by the pose detection and segmentation models. Code: https://\nanonymous.4open.science/r/Bone-Loss-Keypoint-Detection-Code. Dataset:\nhttps://bit.ly/4hJ3aE7.",
      "tldr_zh": "这篇论文提出了一种基于 YOLOv8-pose 深度学习模型的方法，用于自动检测牙周病骨损失关键点和分期，旨在解决手动计算耗时和不精确的问题。研究团队引入了 PRCK（Percentage of Relative Correct Keypoints）指标来标准化关键点检测评估，并开发了启发式后处理模块，利用辅助实例分割模型调整预测结果。实验在 193 张标注的根尖 X 光片上显示，模型在关键点检测（PRCK 0.25 为 0.726）和牙齿对象检测（mAP 0.5 为 0.715）方面表现良好，但检测脱节牙周韧带和分叉参与时效果不足。该方法提供了一种阶段无关的牙周病检测框架，并公开了代码和数据集以支持进一步研究。",
      "categories": [
        "q-bio.TO",
        "cs.AI",
        "cs.CV",
        "I.2.1; I.2.10; J.3"
      ],
      "primary_category": "q-bio.TO",
      "comment": "31 pages, 7 tables, 5 figures, 3 equations, journal paper submitted\n  to Computers in Biology and Medicine",
      "pdf_url": "http://arxiv.org/pdf/2503.13477v1",
      "published_date": "2025-03-05 00:34:29 UTC",
      "updated_date": "2025-03-05 00:34:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:32:20.753042"
    },
    {
      "arxiv_id": "2503.07634v1",
      "title": "Impact of Level 2/3 Automated Driving Technology on Road Work Zone Safety",
      "title_zh": "Level 2/3 自动驾驶技术对道路工区安全的影响",
      "authors": [
        "Zhepu Xu",
        "Ziyi Song",
        "Yupu Dong",
        "Peiyan Chen"
      ],
      "abstract": "As China's road network enters the maintenance era, work zones will become a\ncommon sight on the roads. With the development of automated driving, vehicles\nequipped with Level 2/3 automated driving capabilities will also become a\ncommon presence on the roads. When these vehicles pass through work zones,\nautomated driving may disengage, which can have complex effects on traffic\nsafety. This paper explores the impact of Level 2/3 automated driving\ntechnology on road safety in high-speed highway work zone environments. Through\nmicroscopic traffic simulation method and using full-type traffic conflict\ntechnique, factors such as market penetration rate (MPR), traffic volume level,\ndisengagement threshold, and driver takeover style are studied to understand\ntheir impact on work zone safety. The study found that the impact of automated\ndriving technology on work zone safety is complex. Disengagement of automated\nvehicles in work zones reduces the proportion of vehicles that can maintain\nautomated driving status. If takeover is not timely or adequate, it can easily\nlead to new traffic conflicts. Different factors have varying degrees of impact\non work zone safety. Increasing MPR helps reduce the occurrence of\nsingle-vehicle conflicts, but it also increases the possibility of\nmulti-vehicle conflicts. Therefore, future research and improvement directions\nshould focus on optimizing the disengagement detection and takeover mechanisms\nof automated driving systems.",
      "tldr_zh": "这篇论文探讨了 Level 2/3 自动驾驶技术对中国高速公路工区安全的影响，随着自动驾驶车辆的普及和道路维护需求的增加。研究采用微观交通模拟方法和全类型交通冲突技术，分析了市场渗透率(MPR)、交通量水平、解除阈值以及驾驶员接管风格等因素对安全的影响。结果表明，自动驾驶在工区的解除会减少保持自动状态的车辆比例，并可能因接管不及时而引发新冲突；同时，增加 MPR 可降低单车冲突，但会增加多车冲突。论文建议未来优化自动驾驶系统的解除检测和接管机制，以提升工区安全。",
      "categories": [
        "cs.AI",
        "cs.MA",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07634v1",
      "published_date": "2025-03-05 00:26:53 UTC",
      "updated_date": "2025-03-05 00:26:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:32:31.213035"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 127,
  "processed_papers_count": 127,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-23T22:32:54.601584"
}