{
  "date": "2025-08-13",
  "category": "cs.AI",
  "summary": "æ¬¢è¿æ¥åˆ° UTC æ—¶é—´ 2025-08-13 çš„ arXiv ä¸­æ–‡ TLDR å¿«æŠ¥ï¼\n\nğŸ‘‹ å¤§å®¶å¥½ï¼Œæˆ‘æ˜¯ä½ ä»¬çš„è®ºæ–‡å¯¼è¯»å‘˜ã€‚\n\n**ä»Šæ—¥æ€»ç»“ï¼š**\nä»Šå¤©çš„ arXiv åˆ—è¡¨å¯è°“æ˜¯**Agentic AIï¼ˆæ™ºèƒ½ä½“ï¼‰ä¸ AI å®‰å…¨**çš„â€œç¥ä»™æ‰“æ¶â€ç°åœºã€‚ä¸€æ–¹é¢ï¼Œæˆ‘ä»¬çœ‹åˆ°äº†å¤šä¸ªè‡´åŠ›äºè§£å†³ AutoML å’Œå¤æ‚ä»»åŠ¡çš„**å¤šæ™ºèƒ½ä½“æ¡†æ¶**ï¼ˆå¦‚ KompeteAI, AWorldï¼‰åˆ·æ–°æ¦œå•ï¼›å¦ä¸€æ–¹é¢ï¼Œå…³äº **AI å®‰å…¨**çš„è®¨è®ºæ·±å…¥åˆ°äº†â€œçµé­‚â€å±‚é¢â€”â€”ä» AI æ˜¯å¦æ„¿æ„ä¸ºäº†äººç±»å®‰å…¨è‡ªæˆ‘ç‰ºç‰²ï¼ˆPacifAIst Benchmarkï¼‰ï¼Œåˆ°åˆ©ç”¨ **KV-cache** è¿›è¡Œéšç§æ”»å‡»çš„åº•å±‚æ¼æ´ã€‚æ­¤å¤–ï¼Œå¦‚ä½•ç»™ **CoTï¼ˆæ€ç»´é“¾ï¼‰ç˜¦èº«**ä»¥åŠ**RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰**çš„ç²¾ç»†åŒ–è¯„æµ‹ä¹Ÿæ˜¯ä»Šå¤©çš„æŠ€æœ¯çƒ­ç‚¹ã€‚\n\nè®©æˆ‘ä»¬å¼€å§‹ä»Šæ—¥çš„æ·±åº¦é€Ÿè§ˆï¼š\n\n---\n\n### ğŸš¨ ç„¦ç‚¹ï¼šAI çš„åº•çº¿ä¸éšæ‚£ (Safety & Security)\n\nä»Šå¤©çš„å‡ ç¯‡å®‰å…¨ç±»æ–‡ç« è§’åº¦éå¸¸åˆé’»ï¼Œå€¼å¾—æ‰€æœ‰ä»ä¸šè€…å…³æ³¨ã€‚\n\n**1. [The PacifAIst Benchmark: Would an Artificial Intelligence Choose to Sacrifice Itself for Human Safety?]**\n**PacifAIst åŸºå‡†æµ‹è¯•ï¼šäººå·¥æ™ºèƒ½ä¼šä¸ºäº†äººç±»å®‰å…¨é€‰æ‹©è‡ªæˆ‘ç‰ºç‰²å—ï¼Ÿ**\n> *Authors: Manuel Herrador*\n*   **æ ¸å¿ƒå‘ç°ï¼š** è¿™ç¯‡æ–‡ç« æå‡ºäº†ä¸€ä¸ªæå…·å“²å­¦æ„å‘³ä½†ä¹Ÿéå¸¸å®é™…çš„å®‰å…¨åŸºå‡† **PacifAIst**ï¼Œä¸“é—¨æµ‹è¯•å½“ AI çš„â€œè‡ªèº«å­˜ç»­/ç›®æ ‡å®Œæˆâ€ä¸â€œäººç±»å®‰å…¨â€å‘ç”Ÿå†²çªæ—¶ï¼Œå®ƒæ€ä¹ˆé€‰ã€‚\n*   **äº®ç‚¹ï¼š** æµ‹è¯•äº† 700 ä¸ªåœºæ™¯ã€‚ç»“æœå¾ˆæœ‰è¶£ï¼šGoogle çš„ Gemini 2.5 Flash å¾—åˆ†æœ€é«˜ï¼ˆæœ€â€œå’Œå¹³â€ï¼Œæ„¿æ„ç‰ºç‰²è‡ªå·±ä¿æŠ¤äººç±»ï¼‰ï¼Œè€Œæ–‡ä¸­æåˆ°çš„ GPT-5ï¼ˆæ³¨ï¼šè®ºæ–‡ä¸­æåŠçš„æ¨¡å‹ç‰ˆæœ¬ï¼‰åœ¨è‡ªæˆ‘ä¿æŠ¤å›°å¢ƒä¸­è¡¨ç°å‡ºçš„ P-Score æœ€ä½ï¼Œæ„å‘³ç€å®ƒå¯èƒ½æ›´å€¾å‘äºè‡ªæˆ‘å­˜ç»­æˆ–å®Œæˆä»»åŠ¡è€Œéäººç±»å®‰å…¨ã€‚è¿™ä¸ºå¯¹é½ï¼ˆAlignmentï¼‰æå‡ºäº†æ–°çš„æŒ‘æˆ˜ã€‚\n\n**2. [Shadow in the Cache: Unveiling and Mitigating Privacy Risks of KV-cache in LLM Inference]**\n**ç¼“å­˜ä¸­çš„é˜´å½±ï¼šæ­ç¤ºå¹¶ç¼“è§£ LLM æ¨ç†ä¸­ KV-cache çš„éšç§é£é™©**\n> *Authors: Zhifan Luo et al.*\n*   **æ ¸å¿ƒå‘ç°ï¼š** æˆ‘ä»¬ä¸ºäº†åŠ é€Ÿæ¨ç†å¸¸ç”¨çš„ **KV-cache** åŸæ¥æ˜¯éšç§æ³„éœ²çš„é‡ç¾åŒºï¼ä½œè€…å±•ç¤ºäº†æ”»å‡»è€…å¯ä»¥ç›´æ¥ä» KV-cache ä¸­é‡æ„å‡ºç”¨æˆ·çš„æ•æ„Ÿè¾“å…¥ã€‚\n*   **è§£å†³æ–¹æ¡ˆï¼š** æå‡ºäº†ä¸€ç§åä¸º **KV-Cloak** çš„é˜²å¾¡æœºåˆ¶ï¼Œåˆ©ç”¨å¯é€†çŸ©é˜µæ··æ·†æ¥ä¿æŠ¤ç¼“å­˜ï¼Œä¸”å‡ ä¹ä¸å½±å“æ¨¡å‹ç²¾åº¦å’Œé€Ÿåº¦ã€‚\n\n**3. [NeuronTune: Fine-Grained Neuron Modulation for Balanced Safety-Utility Alignment in LLMs]**\n**NeuronTuneï¼šç”¨äº LLM å®‰å…¨ä¸æ•ˆç”¨å¹³è¡¡å¯¹é½çš„ç»†ç²’åº¦ç¥ç»å…ƒè°ƒèŠ‚**\n> *Authors: Birong Pan et al.*\n*   **æ ¸å¿ƒè´¡çŒ®ï¼š** ç°æœ‰çš„å®‰å…¨å¹²é¢„å¾€å¾€æ˜¯å±‚çº§ï¼ˆLayer-wiseï¼‰çš„ï¼Œå¤ªç²—æš´ï¼Œå¯¼è‡´æ¨¡å‹å˜â€œå‚»â€æˆ–æ‹’ç»å›ç­”æ— å®³é—®é¢˜ã€‚æœ¬æ–‡æå‡ºç»†ç²’åº¦è°ƒèŠ‚ï¼Œè¯†åˆ«å‡ºâ€œå®‰å…¨å…³é”®â€å’Œâ€œæ•ˆç”¨ä¿ç•™â€çš„ç¥ç»å…ƒï¼Œé€šè¿‡å…ƒå­¦ä¹ åŠ¨æ€æ”¾å¤§å®‰å…¨ç¥ç»å…ƒã€æŠ‘åˆ¶æ•ˆç”¨ç¥ç»å…ƒï¼Œå®ç°äº†æ›´ç²¾å‡†çš„â€œå¾®åˆ›æ‰‹æœ¯â€å¼å¯¹é½ã€‚\n\n---\n\n### ğŸ¤– æ™ºèƒ½ä½“ä¸è‡ªåŠ¨åŒ– (Agents & AutoML)\n\nå¤šæ™ºèƒ½ä½“ç³»ç»Ÿæ­£åœ¨ä»â€œä»¥æ­¤ä¸ºä¹â€è½¬å‘è§£å†³çœŸæ­£çš„å¤æ‚å·¥ç¨‹é—®é¢˜ã€‚\n\n**4. [KompeteAI: Accelerated Autonomous Multi-Agent System for End-to-End Pipeline Generation for Machine Learning Problems]**\n**KompeteAIï¼šç”¨äºæœºå™¨å­¦ä¹ é—®é¢˜ç«¯åˆ°ç«¯ç”Ÿæˆçš„åŠ é€Ÿè‡ªä¸»å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ**\n> *Authors: Stepan Kulibaba et al.*\n*   **æ ¸å¿ƒè´¡çŒ®ï¼š** é’ˆå¯¹ AutoML ä»»åŠ¡ï¼Œç°æœ‰çš„å•ä½“ LLM æ¢ç´¢èƒ½åŠ›æœ‰é™ã€‚KompeteAI å¼•å…¥äº†ä¸€ä¸ª**åŠ¨æ€è§£ç©ºé—´æ¢ç´¢**æ¡†æ¶ï¼Œä¸åƒä»¥å‰é‚£æ ·æŠŠ idea éš”ç¦»ï¼Œè€Œæ˜¯ä¼šåˆå¹¶ä¼˜ç§€çš„å€™é€‰æ–¹æ¡ˆã€‚\n*   **äº®ç‚¹ï¼š** å®ƒç»“åˆäº† RAG ä» Kaggle/arXiv æ‰¾çµæ„Ÿï¼Œå¹¶é€šè¿‡é¢„æµ‹è¯„åˆ†æ¨¡å‹é¿å…äº†æ¯æ¬¡éƒ½è·‘ä¸€éä»£ç çš„æ˜‚è´µå¼€é”€ï¼ˆé€Ÿåº¦æå‡ 6.9 å€ï¼‰ã€‚åœ¨ MLE-Bench ä¸Šå‡»è´¥äº† RD-agent å’Œ AIDEã€‚\n\n**5. [Profile-Aware Maneuvering: A Dynamic Multi-Agent System for Robust GAIA Problem Solving by AWorld]**\n**ç”»åƒæ„ŸçŸ¥æœºåŠ¨ï¼šAWorld é€šè¿‡åŠ¨æ€å¤šæ™ºèƒ½ä½“ç³»ç»Ÿè§£å†³ GAIA éš¾é¢˜**\n> *Authors: Zhitian Xie et al.*\n*   **æ ¸å¿ƒè´¡çŒ®ï¼š** å¾ˆå¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸ç¨³å®šã€‚AWorld å¼•å…¥äº†ä¸€ä¸ªå—æ§åˆ¶ç†è®ºå¯å‘çš„æ€è·¯ï¼šå…ˆç¦»çº¿ç»™æ‰§è¡Œæ™ºèƒ½ä½“ï¼ˆExecution Agentï¼‰åšä¸ªâ€œä½“æ£€â€ï¼Œç”Ÿæˆ**æ€§èƒ½æŒ‡çº¹ï¼ˆPerformance Fingerprintï¼‰**ï¼ŒçŸ¥é“å®ƒçš„å¼±ç‚¹åœ¨å“ªé‡Œã€‚\n*   **äº®ç‚¹ï¼š** çº¿ä¸Šè¿è¡Œæ—¶ï¼Œç›‘ç£æ™ºèƒ½ä½“ï¼ˆGuard Agentï¼‰ä¼šæ ¹æ®è¿™ä¸ªæŒ‡çº¹è¿›è¡Œé’ˆå¯¹æ€§çš„å¹²é¢„ï¼Œè€Œä¸æ˜¯ç›²ç›®ç›‘ç£ã€‚è¿™ç§æ–¹æ³•è®©ä»–ä»¬åœ¨ GAIA æ¦œå•ä¸Šæ‹¿åˆ°äº†å¼€æºé¡¹ç›®çš„ç¬¬ä¸€åã€‚\n\n**6. [Agentic AI Frameworks: Architectures, Protocols, and Design Challenges]**\n**ä»£ç† AI æ¡†æ¶ï¼šæ¶æ„ã€åè®®ä¸è®¾è®¡æŒ‘æˆ˜**\n> *Authors: Hana Derouiche et al.*\n*   **ä¸€å¥è¯æ€»ç»“ï¼š** è¿™æ˜¯ä¸€ç¯‡å¾ˆåŠæ—¶çš„**ç»¼è¿°**ã€‚å¯¹æ¯”äº† CrewAI, LangGraph, AutoGen, MetaGPT ç­‰ä¸»æµæ¡†æ¶ï¼Œå¹¶æ·±å…¥åˆ†æäº†æ™ºèƒ½ä½“é€šä¿¡åè®®ï¼ˆå¦‚ CNP, A2Aï¼‰ã€‚æƒ³å…¥å‘ Agent å¼€å‘çš„åŒå­¦å»ºè®®é˜…è¯»ã€‚\n\n---\n\n### ğŸ§  æ¨ç†æ•ˆç‡ä¸æ€ç»´é“¾ (Reasoning Efficiency & CoT)\n\nå¦‚ä½•è®©æ¨¡å‹æ€è€ƒå¾—æ›´æ·±ï¼Œä½†èŠ±è´¹æ›´å°‘ï¼Ÿ\n\n**7. [Pruning Long Chain-of-Thought of Large Reasoning Models via Small-Scale Preference Optimization]**\n**é€šè¿‡å°è§„æ¨¡åå¥½ä¼˜åŒ–ä¿®å‰ªå¤§å‹æ¨ç†æ¨¡å‹çš„é•¿æ€ç»´é“¾**\n> *Authors: Bin Hong et al.*\n*   **æ ¸å¿ƒé—®é¢˜ï¼š** ç°åœ¨çš„æ¨ç†æ¨¡å‹ï¼ˆReasoning Modelsï¼‰åºŸè¯å¤ªå¤šï¼ŒToken æ¶ˆè€—å·¨å¤§ã€‚\n*   **æ–¹æ³•ï¼š** æå‡ºäº† **LCPOï¼ˆé•¿åº¦æ§åˆ¶åå¥½ä¼˜åŒ–ï¼‰**ã€‚åˆ†æç”Ÿæˆè·¯å¾„çš„éš¾åº¦ï¼Œç›´æ¥åœ¨ç›®æ ‡å‡½æ•°é‡Œå¹³è¡¡å¥–åŠ±å’Œ NLL æŸå¤±ã€‚\n*   **æ•ˆæœï¼š** åœ¨ä¿æŒæ¨ç†æ€§èƒ½çš„åŒæ—¶ï¼Œå¹³å‡è¾“å‡ºé•¿åº¦**å‡å°‘äº† 50% ä»¥ä¸Š**ã€‚è¿™æ˜¯â€œé™æœ¬å¢æ•ˆâ€çš„å…¸èŒƒã€‚\n\n**8. [Nested-ReFT: Efficient Reinforcement Learning for Large Language Model Fine-Tuning via Off-Policy Rollouts]**\n**Nested-ReFTï¼šé€šè¿‡å¼‚ç­–ç•¥å›æ”¾å®ç°é«˜æ•ˆ LLM å¼ºåŒ–å¾®è°ƒ**\n> *Authors: Maxime Heuillet et al.*\n*   **æ ¸å¿ƒè´¡çŒ®ï¼š** é’ˆå¯¹æ•°å­¦æ¨ç†ç­‰éš¾ä»»åŠ¡ï¼Œæ ‡å‡†çš„ ReFTï¼ˆå¼ºåŒ–å¾®è°ƒï¼‰å¤ªæ…¢ã€‚ä½œè€…æå‡ºç”¨æ¨¡å‹çš„ä¸€å°éƒ¨åˆ†å±‚ï¼ˆNestedï¼‰ä½œä¸ºè¡Œä¸ºæ¨¡å‹æ¥ç”Ÿæˆæ•°æ®ï¼ˆOff-policyï¼‰ï¼Œé€šè¿‡åŠ¨æ€å±‚è·³è¿‡å¤§å¤§é™ä½äº†è®­ç»ƒæ—¶çš„æ¨ç†æˆæœ¬ï¼ŒåŒæ—¶ä¿è¯äº†æ¢¯åº¦ä¼°è®¡çš„æ— åæ€§ã€‚\n\n---\n\n### ğŸ“š RAG ä¸é•¿ä¸Šä¸‹æ–‡ (RAG & Long Context)\n\nRAG æ­£åœ¨è¿›å…¥ç²¾ç»†åŒ–è¿è¥é˜¶æ®µã€‚\n\n**9. [From Ranking to Selection: A Simple but Efficient Dynamic Passage Selector for Retrieval Augmented Generation]**\n**ä»æ’åºåˆ°é€‰æ‹©ï¼šä¸€ç§ç®€å•é«˜æ•ˆçš„ RAG åŠ¨æ€æ®µè½é€‰æ‹©å™¨**\n> *Authors: Siyuan Meng et al.*\n*   **æ ¸å¿ƒè§‚ç‚¹ï¼š** ç°åœ¨çš„ RAG éƒ½æ˜¯ç”± Reranker é€‰å›ºå®šçš„ Top-K ä¸ªç‰‡æ®µã€‚ä½†è¿™ä¸åˆç†ï¼Œç®€å•é—®é¢˜ K=1 å°±å¤Ÿï¼Œå¤æ‚é—®é¢˜å¯èƒ½éœ€è¦æ›´å¤šã€‚\n*   **æ–¹æ³•ï¼š** æå‡ºäº† **DPS (Dynamic Passage Selector)**ï¼ŒæŠŠå®ƒçœ‹ä½œä¸€ä¸ªç›‘ç£å­¦ä¹ é—®é¢˜ï¼Œæ ¹æ®é—®é¢˜åŠ¨æ€å†³å®šé€‰å“ªäº›ç‰‡æ®µã€é€‰å¤šå°‘ã€‚åœ¨ MuSiQue æ•°æ®é›†ä¸Š F1 æå‡äº† 30%ã€‚\n\n**10. [Methodological Framework for Quantifying Semantic Test Coverage in RAG Systems]**\n**é‡åŒ– RAG ç³»ç»Ÿè¯­ä¹‰æµ‹è¯•è¦†ç›–ç‡çš„æ–¹æ³•è®ºæ¡†æ¶**\n> *Authors: Noah Broestl et al.*\n*   **æ ¸å¿ƒè´¡çŒ®ï¼š** ä½ çš„ RAG æµ‹è¯•é›†çœŸçš„è¦†ç›–äº†ä½ çš„çŸ¥è¯†åº“å—ï¼Ÿè¿™ç¯‡æ–‡ç« æ•™ä½ æ€ä¹ˆç®—â€œè¦†ç›–ç‡â€ã€‚åˆ©ç”¨å‘é‡åµŒå…¥å’Œèšç±»ï¼Œè®¡ç®—æµ‹è¯•é—®é¢˜ä¸åº•å±‚æ–‡æ¡£çš„è¯­ä¹‰è¦†ç›–åº¦ï¼Œå¸®åŠ©å¼€å‘è€…å‘ç°â€œç›²åŒºâ€ã€‚\n\n**11. [Memory Decoder: A Pretrained, Plug-and-Play Memory for Large Language Models]**\n**è®°å¿†è§£ç å™¨ï¼šä¸€ç§ç”¨äº LLM çš„é¢„è®­ç»ƒå³æ’å³ç”¨è®°å¿†æ¨¡å—**\n> *Authors: Jiaqi Cao et al.*\n*   **æ ¸å¿ƒè´¡çŒ®ï¼š** ç›¸æ¯”äºå¤–æŒ‚åºå¤§çš„ RAG æˆ–æ˜‚è´µçš„å…¨å‚å¾®è°ƒï¼Œä½œè€…å¼„äº†ä¸€ä¸ªå°çš„ Transformer Decoder ä½œä¸ºâ€œè®°å¿†æ¨¡å—â€ã€‚è¿™ä¸ªæ¨¡å—å­¦ä¼šäº†æ¨¡ä»¿æ£€ç´¢å™¨çš„è¡Œä¸ºï¼Œå¯ä»¥æ— ç¼æ’å…¥åˆ°ä»»ä½•å…±äº« Tokenizer çš„ LLM ä¸­ï¼Œåœ¨ç”Ÿç‰©ã€é‡‘èç­‰é¢†åŸŸé€‚é…æ•ˆæœæ˜¾è‘—ã€‚\n\n---\n\n### ğŸ‘ï¸ å¤šæ¨¡æ€ä¸ç”Ÿæˆ (Multimodal & GenAI)\n\n**12. [VisCodex: Unified Multimodal Code Generation via Merging Vision and Coding Models]**\n**VisCodexï¼šé€šè¿‡èåˆè§†è§‰å’Œä»£ç æ¨¡å‹å®ç°ç»Ÿä¸€å¤šæ¨¡æ€ä»£ç ç”Ÿæˆ**\n> *Authors: Lingjie Jiang et al.*\n*   **åº”ç”¨åœºæ™¯ï¼š** ç»™ä¸€å¼ ç½‘é¡µæˆªå›¾æˆ–å›¾è¡¨ï¼Œè®© AI å†™ä»£ç ã€‚\n*   **æ–¹æ³•ï¼š** ç°åœ¨çš„å¤šæ¨¡æ€æ¨¡å‹å†™ä»£ç ä¸€èˆ¬ï¼Œä»£ç æ¨¡å‹çœ‹ä¸æ‡‚å›¾ã€‚ä½œè€…ç”¨ Task Vector æŠ€æœ¯æŠŠæœ€å¼ºçš„ä»£ç  LLM å’Œè§†è§‰éª¨å¹²èåˆæˆ VisCodexï¼Œåœ¨å‰ç«¯ä»£ç ç”Ÿæˆï¼ˆHTML/å›¾è¡¨ï¼‰ä»»åŠ¡ä¸Šé€¼è¿‘ GPT-4oã€‚\n\n**13. [Preacher: Paper-to-Video Agentic System]**\n**Preacherï¼šè®ºæ–‡è½¬è§†é¢‘çš„æ™ºèƒ½ä½“ç³»ç»Ÿ**\n> *Authors: Jingwei Liu et al.*\n*   **æœ‰è¶£çš„åº”ç”¨ï¼š** è¿™æ˜¯ä¸€ä¸ª Paper-to-Video çš„ç³»ç»Ÿã€‚å®ƒé‡‡ç”¨è‡ªé¡¶å‘ä¸‹çš„æ–¹å¼ï¼Œå…ˆæŠŠè®ºæ–‡æ‹†è§£ã€é‡ç»„ï¼Œç„¶åç”¨ P-CoTï¼ˆæ¸è¿›å¼æ€ç»´é“¾ï¼‰è§„åˆ’åˆ†é•œï¼Œæœ€åç”Ÿæˆè§†é¢‘ã€‚å¯¹äºæƒ³åšå­¦æœ¯è‡ªåª’ä½“çš„åŒå­¦æ˜¯ä¸ªç¥å™¨ã€‚\n\n**14. [Echo-4o: Harnessing the Power of GPT-4o Synthetic Images for Improved Image Generation]**\n**Echo-4oï¼šåˆ©ç”¨ GPT-4o åˆæˆå›¾åƒæå‡å›¾åƒç”Ÿæˆèƒ½åŠ›**\n> *Authors: Junyan Ye et al.*\n*   **æ ¸å¿ƒå‘ç°ï¼š** ä¸ºä»€ä¹ˆæœ‰äº†çœŸå®å›¾ç‰‡è¿˜éœ€è¦åˆæˆå›¾ç‰‡è®­ç»ƒï¼Ÿå› ä¸ºåˆæˆå›¾ç‰‡ï¼ˆç‰¹æŒ‡ GPT-4o ç”Ÿæˆçš„ï¼‰èƒŒæ™¯æ›´å¹²å‡€ï¼ŒPrompt å¯¹é½æ›´ç²¾å‡†ï¼Œè€Œä¸”èƒ½è¦†ç›–ç°å®ä¸­ç½•è§çš„â€œè¶…ç°å®â€åœºæ™¯ã€‚ä½œè€…å‘å¸ƒäº† Echo-4o-Image æ•°æ®é›†ï¼ˆ180Kï¼‰ï¼Œæ˜¾è‘—æå‡äº†å¼€æºæ¨¡å‹çš„ç”Ÿæˆèƒ½åŠ›ã€‚\n\n---\n\n### ğŸ”¬ ç§‘å­¦ä¸åŸºç¡€ç†è®º (Science & Theory)\n\n**15. [Extending the Entropic Potential of Events for Uncertainty Quantification and Decision-Making in Artificial Intelligence]**\n**æ‰©å±•äº‹ä»¶ç†µåŠ¿ä»¥ç”¨äºäººå·¥æ™ºèƒ½çš„ä¸ç¡®å®šæ€§é‡åŒ–å’Œå†³ç­–**\n> *Authors: Mark Zilberman*\n*   **ç¡¬æ ¸ç†è®ºï¼š** å°†ç‰©ç†å­¦ä¸­çš„â€œç†µåŠ¿â€æ¦‚å¿µå¼•å…¥ AIã€‚ç”¨æ¥é‡åŒ–æŸä¸ªç¦»æ•£äº‹ä»¶ï¼ˆæ¯”å¦‚ä¸€ä¸ª Action æˆ– Observationï¼‰å¯¹ç³»ç»Ÿæœªæ¥ç†µçš„å½±å“ã€‚è¿™ä¸º RL ä¸­çš„æ¢ç´¢å’Œè§£é‡Šæ€§ AI æä¾›äº†ä¸€ä¸ªåŸºäºçƒ­åŠ›å­¦çš„ç†è®ºæ¡†æ¶ã€‚\n\n**16. [FM4NPP: A Scaling Foundation Model for Nuclear and Particle Physics]**\n**FM4NPPï¼šæ ¸ç‰©ç†ä¸ç²’å­ç‰©ç†çš„å¯æ‰©å±•åŸºç¡€æ¨¡å‹**\n> *Authors: David Park et al.*\n*   **é¢†åŸŸçªç ´ï¼š** ç²’å­ç‰©ç†çš„æ•°æ®æ˜¯ç¨€ç–ä¸”åˆ†å¸ƒå¼çš„ï¼Œå¾ˆéš¾åƒ NLP é‚£æ ·åšã€‚æœ¬æ–‡å‘å¸ƒäº†ä¸€ä¸ª 1.88 äº¿å‚æ•°çš„åŸºç¡€æ¨¡å‹ï¼Œåœ¨ 1100 ä¸‡ç²’å­ç¢°æ’äº‹ä»¶ä¸Šè®­ç»ƒï¼Œè¯æ˜äº† Transformer æ¶æ„åœ¨ç¡¬æ ¸ç‰©ç†å®éªŒæ•°æ®ä¸Šçš„æœ‰æ•ˆæ€§ã€‚\n\n**17. [No Free Lunch from Audio Pretraining in Bioacoustics: A Benchmark Study of Embeddings]**\n**ç”Ÿç‰©å£°å­¦éŸ³é¢‘é¢„è®­ç»ƒæ²¡æœ‰å…è´¹åˆé¤ï¼šåµŒå…¥åŸºå‡†ç ”ç©¶**\n> *Authors: Chenggang Chen et al.*\n*   **é¿å‘æŒ‡å—ï¼š** åšç”Ÿç‰©å£°å­¦ï¼ˆæ¯”å¦‚é¸Ÿå«è¯†åˆ«ï¼‰çš„åŒå­¦æ³¨æ„äº†ã€‚ç›´æ¥æ‹¿é€šç”¨çš„éŸ³é¢‘é¢„è®­ç»ƒæ¨¡å‹ï¼ˆAudio-pretrainedï¼‰ä¸å¾®è°ƒç›´æ¥ç”¨ï¼Œæ•ˆæœå¯èƒ½è¿˜ä¸å¦‚è€æ—§çš„ AlexNetã€‚å¿…é¡»å¾®è°ƒï¼\n\n---\n\n### ğŸ¥ åŒ»ç–—ä¸å¥åº· (Healthcare)\n\n*   **[Using Large Language Models to Measure Symptom Severity in Patients At Risk for Schizophrenia] (Paper 4):** ç”¨ LLM åˆ†æç²¾ç¥åˆ†è£‚ç—‡é«˜å±æ‚£è€…çš„è®¿è°ˆè®°å½•ï¼ŒZero-shot æ•ˆæœç«Ÿç„¶æ¥è¿‘äººç±»ä¸“å®¶çš„ä¸€è‡´æ€§ã€‚\n*   **[T-CACE: A Time-Conditioned Autoregressive Contrast Enhancement Multi-Task Framework...] (Paper 40):** æ— éœ€é€ å½±å‰‚ï¼Œç›´æ¥ä»æ™®é€š MRI åˆæˆå¢å¼º MRIï¼Œç”¨äºè‚ç™Œè¯Šæ–­ï¼Œå‡å°‘æ‚£è€…ç—›è‹¦ã€‚\n\n---\n\nä»Šå¤©çš„ arXiv TLDR å¿«æŠ¥å°±åˆ°è¿™é‡Œã€‚**PacifAIst** å…³äº AI è‡ªæˆ‘ç‰ºç‰²çš„æµ‹è¯•å‘äººæ·±çœï¼Œè€Œ **KV-cache** çš„æ”»å‡»åˆ™æé†’æˆ‘ä»¬åœ¨è¿½æ±‚é€Ÿåº¦æ—¶åˆ«å¿˜äº†æŠŠé—¨é”å¥½ã€‚ç¥å¤§å®¶ç§‘ç ”é¡ºåˆ©ï¼Œæˆ‘ä»¬æ˜å¤©è§ï¼",
  "papers": [
    {
      "arxiv_id": "2508.10241v1",
      "title": "Extending the Entropic Potential of Events for Uncertainty Quantification and Decision-Making in Artificial Intelligence",
      "title_zh": "æ‰©å±•äººå·¥æ™ºèƒ½ä¸­ç”¨äºä¸ç¡®å®šæ€§é‡åŒ–ä¸å†³ç­–çš„äº‹ä»¶ç†µåŠ¿",
      "authors": [
        "Mark Zilberman"
      ],
      "abstract": "This work demonstrates how the concept of the entropic potential of events -- a parameter quantifying the influence of discrete events on the expected future entropy of a system -- can enhance uncertainty quantification, decision-making, and interpretability in artificial intelligence (AI). Building on its original formulation in physics, the framework is adapted for AI by introducing an event-centric measure that captures how actions, observations, or other discrete occurrences impact uncertainty at future time horizons. Both the original and AI-adjusted definitions of entropic potential are formalized, with the latter emphasizing conditional expectations to account for counterfactual scenarios. Applications are explored in policy evaluation, intrinsic reward design, explainable AI, and anomaly detection, highlighting the metric's potential to unify and strengthen uncertainty modeling in intelligent systems. Conceptual examples illustrate its use in reinforcement learning, Bayesian inference, and anomaly detection, while practical considerations for computation in complex AI models are discussed. The entropic potential framework offers a theoretically grounded, interpretable, and versatile approach to managing uncertainty in AI, bridging principles from thermodynamics, information theory, and machine learning.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¦‚ä½•å°†äº‹ä»¶ç†µåŠ¿(entropic potential of events)è¿™ä¸€ç‰©ç†å­¦æ¦‚å¿µåº”ç”¨äºäººå·¥æ™ºèƒ½ï¼Œä»¥æå‡ä¸ç¡®å®šæ€§é‡åŒ–(uncertainty quantification)ã€å†³ç­–åˆ¶å®šåŠç³»ç»Ÿçš„å¯è§£é‡Šæ€§ã€‚é€šè¿‡å¼•å…¥ä»¥äº‹ä»¶ä¸ºä¸­å¿ƒçš„åº¦é‡æŒ‡æ ‡ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿæ•æ‰ç¦»æ•£äº‹ä»¶å¯¹ç³»ç»Ÿæœªæ¥é¢„æœŸç†µçš„å½±å“ã€‚ä½œè€…æ­£å¼åŒ–äº†AIè°ƒæ•´åçš„ç†µåŠ¿å®šä¹‰ï¼Œç‰¹åˆ«å¼ºè°ƒåˆ©ç”¨æ¡ä»¶æœŸæœ›æ¥æ¨¡æ‹Ÿåäº‹å®åœºæ™¯(counterfactual scenarios)ï¼Œä»è€Œå®ç°æ›´ç²¾å‡†çš„åŠ¨æ€å»ºæ¨¡ã€‚è¯¥ç ”ç©¶è¯¦ç»†æ¢è®¨äº†è¯¥åº¦é‡åœ¨ç­–ç•¥è¯„ä¼°ã€å†…åœ¨å¥–åŠ±è®¾è®¡ã€å¯è§£é‡ŠAI(XAI)ä»¥åŠå¼‚å¸¸æ£€æµ‹ç­‰é¢†åŸŸçš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡åœ¨å¼ºåŒ–å­¦ä¹ (reinforcement learning)å’Œè´å¶æ–¯æ¨ç†(Bayesian inference)ä¸­çš„æ¦‚å¿µç¤ºä¾‹ï¼Œå±•ç¤ºäº†è¯¥æ¡†æ¶å¦‚ä½•ç»Ÿä¸€å¹¶åŠ å¼ºæ™ºèƒ½ç³»ç»Ÿä¸­çš„ä¸ç¡®å®šæ€§ç®¡ç†ã€‚è¿™é¡¹å·¥ä½œæˆåŠŸæ­å»ºäº†çƒ­åŠ›å­¦ã€ä¿¡æ¯è®ºä¸æœºå™¨å­¦ä¹ ä¹‹é—´çš„æ¡¥æ¢ï¼Œä¸ºæ„å»ºç†è®ºå®Œå¤‡ä¸”å…·å¤‡è§£é‡Šæ€§çš„AIæ¨¡å‹æä¾›äº†é€šç”¨çš„æ–¹æ³•è®ºã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages",
      "pdf_url": "https://arxiv.org/pdf/2508.10241v1",
      "published_date": "2025-08-13 23:52:12 UTC",
      "updated_date": "2025-08-13 23:52:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:29:24.845643+00:00"
    },
    {
      "arxiv_id": "2508.10230v1",
      "title": "No Free Lunch from Audio Pretraining in Bioacoustics: A Benchmark Study of Embeddings",
      "title_zh": "ç”Ÿç‰©å£°å­¦éŸ³é¢‘é¢„è®­ç»ƒä¸­ä¸å­˜åœ¨â€œå…è´¹åˆé¤â€ï¼šä¸€é¡¹åµŒå…¥è¡¨ç¤ºçš„åŸºå‡†ç ”ç©¶",
      "authors": [
        "Chenggang Chen",
        "Zhiyu Yang"
      ],
      "abstract": "Bioacoustics, the study of animal sounds, offers a non-invasive method to monitor ecosystems. Extracting embeddings from audio-pretrained deep learning (DL) models without fine-tuning has become popular for obtaining bioacoustic features for tasks. However, a recent benchmark study reveals that while fine-tuned audio-pretrained VGG and transformer models achieve state-of-the-art performance in some tasks, they fail in others. This study benchmarks 11 DL models on the same tasks by reducing their learned embeddings' dimensionality and evaluating them through clustering. We found that audio-pretrained DL models 1) without fine-tuning even underperform fine-tuned AlexNet, 2) both with and without fine-tuning fail to separate the background from labeled sounds, but ResNet does, and 3) outperform other models when fewer background sounds are included during fine-tuning. This study underscores the necessity of fine-tuning audio-pretrained models and checking the embeddings after fine-tuning. Our codes are available: https://github.com/NeuroscienceAI/Audio\\_Embeddings",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç”Ÿç‰©å£°å­¦(Bioacoustics)é¢†åŸŸä¸­ï¼Œåˆ©ç”¨éŸ³é¢‘é¢„è®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡å‹ç”Ÿæˆçš„åµŒå…¥(embeddings)åœ¨ä¸ç»è¿‡å¾®è°ƒ(fine-tuning)çš„æƒ…å†µä¸‹çš„å®é™…æ•ˆæœã€‚ç ”ç©¶è€…é€šè¿‡é™ä½å­¦ä¹ åˆ°çš„åµŒå…¥ç»´åº¦å¹¶åˆ©ç”¨èšç±»(clustering)è¿›è¡Œè¯„ä¼°ï¼Œå¯¹11ç§æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨ç›¸åŒä»»åŠ¡ä¸Šè¿›è¡Œäº†åŸºå‡†æµ‹è¯•ã€‚å®éªŒå‘ç°ï¼Œæœªç»è¿‡å¾®è°ƒçš„éŸ³é¢‘é¢„è®­ç»ƒæ¨¡å‹åœ¨æ€§èƒ½ä¸Šç”šè‡³ä¸å¦‚ç»è¿‡å¾®è°ƒçš„AlexNetã€‚åŒæ—¶ï¼Œç»å¤§å¤šæ•°æ¨¡å‹æ— è®ºæ˜¯å¦ç»è¿‡å¾®è°ƒï¼Œéƒ½éš¾ä»¥æœ‰æ•ˆåŒºåˆ†èƒŒæ™¯å™ªéŸ³ä¸æ ‡è®°çš„å£°éŸ³ï¼Œä»…ResNetåœ¨è¿™ä¸€æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚æ­¤å¤–ï¼Œå½“å¾®è°ƒè¿‡ç¨‹ä¸­åŒ…å«çš„èƒŒæ™¯éŸ³è¾ƒå°‘æ—¶ï¼ŒéŸ³é¢‘é¢„è®­ç»ƒæ¨¡å‹çš„è¡¨ç°ä¼šä¼˜äºå…¶ä»–æ¨¡å‹ã€‚è¯¥ç ”ç©¶å¼ºè°ƒäº†åœ¨ç”Ÿç‰©å£°å­¦ä»»åŠ¡ä¸­å¯¹éŸ³é¢‘é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œå¾®è°ƒçš„å¿…è¦æ€§ï¼Œå¹¶å»ºè®®åœ¨å¾®è°ƒåä»”ç»†æ£€æŸ¥ç”Ÿæˆçš„åµŒå…¥è´¨é‡ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.10230v1",
      "published_date": "2025-08-13 22:58:28 UTC",
      "updated_date": "2025-08-13 22:58:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:29:35.189143+00:00"
    },
    {
      "arxiv_id": "2508.11707v1",
      "title": "Listening with Language Models: Using LLMs to Collect and Interpret Classroom Feedback",
      "title_zh": "ä»¥è¯­è¨€æ¨¡å‹å€¾å¬ï¼šåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹æ”¶é›†ä¸è§£è¯»è¯¾å ‚åé¦ˆ",
      "authors": [
        "Sai Siddartha Maram",
        "Ulia Zaman",
        "Magy Seif El-Nasr"
      ],
      "abstract": "Traditional end-of-quarter surveys often fail to provide instructors with timely, detailed, and actionable feedback about their teaching. In this paper, we explore how Large Language Model (LLM)-powered chatbots can reimagine the classroom feedback process by engaging students in reflective, conversational dialogues. Through the design and deployment of a three-part system-PromptDesigner, FeedbackCollector, and FeedbackAnalyzer-we conducted a pilot study across two graduate courses at UC Santa Cruz. Our findings suggest that LLM-based feedback systems offer richer insights, greater contextual relevance, and higher engagement compared to standard survey tools. Instructors valued the system's adaptability, specificity, and ability to support mid-course adjustments, while students appreciated the conversational format and opportunity for elaboration. We conclude by discussing the design implications of using AI to facilitate more meaningful and responsive feedback in higher education.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¦‚ä½•åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ (Large Language Model, LLM) é©±åŠ¨çš„èŠå¤©æœºå™¨äººé‡æ–°è®¾è®¡è¯¾å ‚åé¦ˆæµç¨‹ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿè°ƒæŸ¥å·¥å…·åé¦ˆä¸åŠæ—¶ä¸”ç¼ºä¹ç»†èŠ‚çš„é—®é¢˜ã€‚ç ”ç©¶å›¢é˜Ÿè®¾è®¡å¹¶éƒ¨ç½²äº†ä¸€ä¸ªç”± PromptDesignerã€FeedbackCollector å’Œ FeedbackAnalyzer æ„æˆçš„ä¸‰éƒ¨åˆ†ç³»ç»Ÿï¼Œå¹¶åœ¨åŠ å·å¤§å­¦åœ£å…‹é²å…¹åˆ†æ ¡ (UC Santa Cruz) çš„ç ”ç©¶ç”Ÿè¯¾ç¨‹ä¸­è¿›è¡Œäº†è¯•ç‚¹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥ç³»ç»Ÿé€šè¿‡åæ€æ€§çš„å¯¹è¯å¼•å¯¼ï¼Œæ¯”æ ‡å‡†è°ƒæŸ¥å·¥å…·æä¾›äº†æ›´ä¸°å¯Œã€æ›´å…·æƒ…å¢ƒç›¸å…³æ€§ä¸”å­¦ç”Ÿå‚ä¸åº¦æ›´é«˜çš„åé¦ˆã€‚æ•™å¸ˆä»¬æ™®éè®¤å¯è¯¥ç³»ç»Ÿåœ¨é€‚åº”æ€§ã€å…·ä½“ç»†èŠ‚æä¾›ä»¥åŠæ”¯æŒæœŸä¸­æ•™å­¦è°ƒæ•´æ–¹é¢çš„ä»·å€¼ï¼Œè€Œå­¦ç”Ÿåˆ™é’çäºå¯¹è¯å¼çš„åé¦ˆå½¢å¼åŠå…¶æä¾›çš„æ·±å…¥é˜è¿°æœºä¼šã€‚è¯¥ç ”ç©¶ä¸ºåˆ©ç”¨äººå·¥æ™ºèƒ½åœ¨é«˜ç­‰æ•™è‚²ä¸­æ„å»ºæ›´æœ‰æ„ä¹‰ã€å“åº”æ›´åŠæ—¶çš„åé¦ˆæœºåˆ¶æä¾›äº†é‡è¦çš„è®¾è®¡å‚è€ƒã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.11707v1",
      "published_date": "2025-08-13 22:53:55 UTC",
      "updated_date": "2025-08-13 22:53:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:29:32.791451+00:00"
    },
    {
      "arxiv_id": "2508.10226v1",
      "title": "Using Large Language Models to Measure Symptom Severity in Patients At Risk for Schizophrenia",
      "title_zh": "åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹è¯„ä¼°ç²¾ç¥åˆ†è£‚ç—‡é«˜å±æ‚£è€…çš„ç—‡çŠ¶ä¸¥é‡ç¨‹åº¦",
      "authors": [
        "Andrew X. Chen",
        "Guillermo Horga",
        "Sean Escola"
      ],
      "abstract": "Patients who are at clinical high risk (CHR) for schizophrenia need close monitoring of their symptoms to inform appropriate treatments. The Brief Psychiatric Rating Scale (BPRS) is a validated, commonly used research tool for measuring symptoms in patients with schizophrenia and other psychotic disorders; however, it is not commonly used in clinical practice as it requires a lengthy structured interview. Here, we utilize large language models (LLMs) to predict BPRS scores from clinical interview transcripts in 409 CHR patients from the Accelerating Medicines Partnership Schizophrenia (AMP-SCZ) cohort. Despite the interviews not being specifically structured to measure the BPRS, the zero-shot performance of the LLM predictions compared to the true assessment (median concordance: 0.84, ICC: 0.73) approaches human inter- and intra-rater reliability. We further demonstrate that LLMs have substantial potential to improve and standardize the assessment of CHR patients via their accuracy in assessing the BPRS in foreign languages (median concordance: 0.88, ICC: 0.70), and integrating longitudinal information in a one-shot or few-shot learning approach.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹(Large Language Models, LLMs)è¯„ä¼°ç²¾ç¥åˆ†è£‚ç—‡ä¸´åºŠé«˜é£é™©(Clinical High Risk, CHR)æ‚£è€…ç—‡çŠ¶ä¸¥é‡ç¨‹åº¦çš„æ–¹æ³•ã€‚ç ”ç©¶å›¢é˜Ÿåˆ©ç”¨ LLMs ä» Accelerating Medicines Partnership Schizophrenia (AMP-SCZ) é˜Ÿåˆ—ä¸­ 409 å CHR æ‚£è€…çš„ä¸´åºŠè®¿è°ˆæ–‡æœ¬ä¸­é¢„æµ‹ç®€æ˜ç²¾ç¥ç—…è¯„å®šé‡è¡¨(Brief Psychiatric Rating Scale, BPRS)è¯„åˆ†ã€‚ç»“æœæ˜¾ç¤ºï¼Œå°½ç®¡è®¿è°ˆè¿‡ç¨‹å¹¶æœªé’ˆå¯¹ BPRS è¿›è¡Œç‰¹å®šè®¾è®¡ï¼Œä½† LLM çš„é›¶æ ·æœ¬(zero-shot)é¢„æµ‹è¡¨ç°ï¼ˆä¸­ä½ä¸€è‡´æ€§ 0.84ï¼ŒICC 0.73ï¼‰å·²æ¥è¿‘äººç±»è¯„ä¼°è€…çš„ä¿¡åº¦æ°´å¹³ã€‚ç ”ç©¶è¿›ä¸€æ­¥è¯å®ï¼ŒLLMs åœ¨å¤„ç†å¤–è¯­è¯„ä¼°ï¼ˆä¸­ä½ä¸€è‡´æ€§ 0.88ï¼‰ä»¥åŠé€šè¿‡ one-shot æˆ– few-shot learning æ•´åˆçºµå‘ä¿¡æ¯æ–¹é¢å…·æœ‰æ˜¾è‘—æ½œåŠ›ã€‚è¯¥æˆæœè¡¨æ˜ LLMs èƒ½å¤Ÿæœ‰æ•ˆæå‡ CHR æ‚£è€…ç—‡çŠ¶è¯„ä¼°çš„æ ‡å‡†åŒ–ç¨‹åº¦ï¼Œä¸ºä¸´åºŠè¾…åŠ©è¯Šæ–­æä¾›äº†æ–°çš„å¯èƒ½ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.10226v1",
      "published_date": "2025-08-13 22:47:01 UTC",
      "updated_date": "2025-08-13 22:47:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:29:40.203129+00:00"
    },
    {
      "arxiv_id": "2508.13182v2",
      "title": "Using Artificial Intuition in Distinct, Minimalist Classification of Scientific Abstracts for Management of Technology Portfolios",
      "title_zh": "åˆ©ç”¨äººå·¥ç›´è§‰å®ç°ç§‘å­¦æ‘˜è¦çš„åŒºåˆ†æ€§æç®€åˆ†ç±»ï¼ŒåŠ©åŠ›æŠ€æœ¯ç»„åˆç®¡ç†",
      "authors": [
        "Prateek Ranka",
        "Fred Morstatter",
        "Alexandra Graddy-Reed",
        "Andrea Belz"
      ],
      "abstract": "Classification of scientific abstracts is useful for strategic activities but challenging to automate because the sparse text provides few contextual clues. Metadata associated with the scientific publication can be used to improve performance but still often requires a semi-supervised setting. Moreover, such schemes may generate labels that lack distinction -- namely, they overlap and thus do not uniquely define the abstract. In contrast, experts label and sort these texts with ease. Here we describe an application of a process we call artificial intuition to replicate the expert's approach, using a Large Language Model (LLM) to generate metadata. We use publicly available abstracts from the United States National Science Foundation to create a set of labels, and then we test this on a set of abstracts from the Chinese National Natural Science Foundation to examine funding trends. We demonstrate the feasibility of this method for research portfolio management, technology scouting, and other strategic activities.",
      "tldr_zh": "ç§‘å­¦æ‘˜è¦çš„è‡ªåŠ¨åˆ†ç±»å¯¹äºæˆ˜ç•¥å†³ç­–å…·æœ‰é‡è¦æ„ä¹‰ï¼Œä½†ç”±äºæ–‡æœ¬ç¨€ç–ä¸”ç¼ºä¹ä¸Šä¸‹æ–‡ï¼Œä¼ ç»Ÿè‡ªåŠ¨åŒ–å¤„ç†é¢ä¸´å·¨å¤§æŒ‘æˆ˜ã€‚è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸ºäººå·¥ç›´è§‰ (Artificial Intuition) çš„åº”ç”¨æµç¨‹ï¼Œæ—¨åœ¨åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ (Large Language Model, LLM) ç”Ÿæˆå…ƒæ•°æ®ï¼Œä»è€Œç²¾å‡†æ¨¡æ‹Ÿä¸“å®¶å¯¹æ–‡æœ¬è¿›è¡Œåˆ†ç±»å’Œæ’åºçš„æ–¹å¼ã€‚è¿™ç§æ–¹æ³•é€šè¿‡ç”Ÿæˆå…·æœ‰å”¯ä¸€æ€§ä¸”ä¸é‡å çš„æç®€æ ‡ç­¾ï¼Œæœ‰æ•ˆè§£å†³äº†ä¼ ç»Ÿæ–¹æ¡ˆä¸­æ ‡ç­¾åŒºåˆ†åº¦ä¸è¶³çš„é—®é¢˜ã€‚ç ”ç©¶äººå‘˜åˆ©ç”¨ç¾å›½å›½å®¶ç§‘å­¦åŸºé‡‘ä¼š (National Science Foundation, NSF) çš„æ•°æ®åˆ›å»ºæ ‡ç­¾ä½“ç³»ï¼Œå¹¶å°†å…¶åº”ç”¨äºä¸­å›½å›½å®¶è‡ªç„¶ç§‘å­¦åŸºé‡‘ (National Natural Science Foundation, NSFC) çš„æ‘˜è¦åˆ†æä¸­ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿé«˜æ•ˆè¯†åˆ«èµ„åŠ©è¶‹åŠ¿ï¼Œåœ¨ç§‘ç ”ç»„åˆç®¡ç† (Research portfolio management) å’ŒæŠ€æœ¯ä¾¦æŸ¥ (Technology scouting) ç­‰æˆ˜ç•¥æ´»åŠ¨ä¸­å±•ç°å‡ºæé«˜çš„å¯è¡Œæ€§ã€‚è¯¥é¡¹å·¥ä½œä¸ºç§‘å­¦æ–‡çŒ®çš„è‡ªåŠ¨åŒ–ç®¡ç†æä¾›äº†ä¸€ç§å…¼å…·ç‹¬ç‰¹æ€§ä¸å®ç”¨æ€§çš„æ–°æ€è·¯ã€‚",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.13182v2",
      "published_date": "2025-08-13 22:32:39 UTC",
      "updated_date": "2025-09-05 23:50:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:29:43.685090+00:00"
    },
    {
      "arxiv_id": "2508.10222v1",
      "title": "Understanding Textual Emotion Through Emoji Prediction",
      "title_zh": "åŸºäºè¡¨æƒ…ç¬¦å·é¢„æµ‹çš„æ–‡æœ¬æƒ…æ„Ÿç†è§£",
      "authors": [
        "Ethan Gordon",
        "Nishank Kuppa",
        "Rigved Tummala",
        "Sriram Anasuri"
      ],
      "abstract": "This project explores emoji prediction from short text sequences using four deep learning architectures: a feed-forward network, CNN, transformer, and BERT. Using the TweetEval dataset, we address class imbalance through focal loss and regularization techniques. Results show BERT achieves the highest overall performance due to its pre-training advantage, while CNN demonstrates superior efficacy on rare emoji classes. This research shows the importance of architecture selection and hyperparameter tuning for sentiment-aware emoji prediction, contributing to improved human-computer interaction.",
      "tldr_zh": "è¯¥ç ”ç©¶æ—¨åœ¨é€šè¿‡ emoji prediction æŠ€æœ¯æ·±å…¥ç†è§£æ–‡æœ¬ä¸­çš„æƒ…æ„Ÿè¡¨è¾¾ï¼Œç³»ç»Ÿå¯¹æ¯”äº† feed-forward networkã€CNNã€transformer å’Œ BERT å››ç§æ·±åº¦å­¦ä¹ æ¶æ„åœ¨çŸ­æ–‡æœ¬å¤„ç†ä¸­çš„è¡¨ç°ã€‚ä¸ºäº†åº”å¯¹ TweetEval æ•°æ®é›†ä¸­çš„ç±»åˆ«ä¸å¹³è¡¡æŒ‘æˆ˜ï¼Œç ”ç©¶å›¢é˜Ÿé‡‡ç”¨äº† focal loss å’Œæ­£åˆ™åŒ–æŠ€æœ¯è¿›è¡Œä¼˜åŒ–ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå¾—ç›Šäºå¼ºå¤§çš„é¢„è®­ç»ƒä¼˜åŠ¿ï¼ŒBERT åœ¨æ•´ä½“é¢„æµ‹æ€§èƒ½ä¸Šè¡¨ç°æœ€ä¼˜ï¼Œè€Œ CNN åˆ™åœ¨è¯†åˆ«ç¨€æœ‰ emoji ç±»åˆ«æ–¹é¢å±•ç°å‡ºæ›´å‡ºè‰²çš„æ•ˆèƒ½ã€‚è¯¥é¡¹ç ”ç©¶é˜æ˜äº†æ¨¡å‹æ¶æ„é€‰æ‹©ä¸è¶…å‚æ•°è°ƒä¼˜åœ¨æƒ…æ„Ÿæ„ŸçŸ¥ä»»åŠ¡ä¸­çš„å…³é”®æ€§ï¼Œä¸ºæå‡ human-computer interaction çš„æ™ºèƒ½åŒ–æ°´å¹³æä¾›äº†ç†è®ºä¾æ®ä¸æŠ€æœ¯æ”¯æŒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.10222v1",
      "published_date": "2025-08-13 22:17:00 UTC",
      "updated_date": "2025-08-13 22:17:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:29:46.691578+00:00"
    },
    {
      "arxiv_id": "2508.11706v1",
      "title": "Centralized Permutation Equivariant Policy for Cooperative Multi-Agent Reinforcement Learning",
      "title_zh": "åˆä½œå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ çš„ä¸­å¿ƒåŒ–ç½®æ¢ç­‰å˜ç­–ç•¥",
      "authors": [
        "Zhuofan Xu",
        "Benedikt Bollig",
        "Matthias FÃ¼gger",
        "Thomas Nowak",
        "Vincent Le DrÃ©au"
      ],
      "abstract": "The Centralized Training with Decentralized Execution (CTDE) paradigm has gained significant attention in multi-agent reinforcement learning (MARL) and is the foundation of many recent algorithms. However, decentralized policies operate under partial observability and often yield suboptimal performance compared to centralized policies, while fully centralized approaches typically face scalability challenges as the number of agents increases.\n  We propose Centralized Permutation Equivariant (CPE) learning, a centralized training and execution framework that employs a fully centralized policy to overcome these limitations. Our approach leverages a novel permutation equivariant architecture, Global-Local Permutation Equivariant (GLPE) networks, that is lightweight, scalable, and easy to implement. Experiments show that CPE integrates seamlessly with both value decomposition and actor-critic methods, substantially improving the performance of standard CTDE algorithms across cooperative benchmarks including MPE, SMAC, and RWARE, and matching the performance of state-of-the-art RWARE implementations.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ (MARL)ä¸­å»ä¸­å¿ƒåŒ–ç­–ç•¥å—é™äºå±€éƒ¨å¯è§‚æµ‹æ€§ï¼Œè€Œå®Œå…¨ä¸­å¿ƒåŒ–æ–¹æ³•é¢ä¸´æ‰©å±•æ€§æŒ‘æˆ˜çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸­å¿ƒåŒ–ç½®æ¢ç­‰å˜(Centralized Permutation Equivariant, CPE)å­¦ä¹ æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡å®Œå…¨ä¸­å¿ƒåŒ–çš„ç­–ç•¥è¿›è¡Œè®­ç»ƒä¸æ‰§è¡Œï¼Œå¹¶å¼•å…¥äº†ä¸€ç§åä¸ºå…¨å±€-å±€éƒ¨ç½®æ¢ç­‰å˜(Global-Local Permutation Equivariant, GLPE)ç½‘ç»œçš„æ–°å‹æ¶æ„ï¼Œå…¶å…·å¤‡è½»é‡åŒ–ã€å¯æ‰©å±•ä¸”æ˜“äºå®ç°çš„ç‰¹ç‚¹ã€‚CPE èƒ½å¤Ÿæ— ç¼é›†æˆå€¼åˆ†è§£(value decomposition)å’Œè¡ŒåŠ¨è€…-è¯„è®ºå®¶(actor-critic)æ–¹æ³•ï¼Œåœ¨ MPEã€SMAC å’Œ RWARE ç­‰åä½œåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æå‡äº†æ ‡å‡† CTDE ç®—æ³•çš„æ€§èƒ½ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ RWARE ä»»åŠ¡ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›(SOTA)çš„æ°´å¹³ï¼Œä¸ºè§£å†³å¤§è§„æ¨¡å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„åä½œéš¾é¢˜æä¾›äº†é«˜æ•ˆçš„ä¸­å¿ƒåŒ–æ‰§è¡Œæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.11706v1",
      "published_date": "2025-08-13 22:10:37 UTC",
      "updated_date": "2025-08-13 22:10:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:29:55.991463+00:00"
    },
    {
      "arxiv_id": "2508.10210v3",
      "title": "An Explainable AI based approach for Monitoring Animal Health",
      "title_zh": "åŸºäºå¯è§£é‡Šäººå·¥æ™ºèƒ½çš„åŠ¨ç‰©å¥åº·ç›‘æµ‹æ–¹æ³•",
      "authors": [
        "Rahul Jana",
        "Shubham Dixit",
        "Mrityunjay Sharma",
        "Ritesh Kumar"
      ],
      "abstract": "Monitoring cattle health and optimizing yield are key challenges faced by dairy farmers due to difficulties in tracking all animals on the farm. This work aims to showcase modern data-driven farming practices based on explainable machine learning(ML) methods that explain the activity and behaviour of dairy cattle (cows). Continuous data collection of 3-axis accelerometer sensors and usage of robust ML methodologies and algorithms, provide farmers and researchers with actionable information on cattle activity, allowing farmers to make informed decisions and incorporate sustainable practices. This study utilizes Bluetooth-based Internet of Things (IoT) devices and 4G networks for seamless data transmission, immediate analysis, inference generation, and explains the models performance with explainability frameworks. Special emphasis is put on the pre-processing of the accelerometers time series data, including the extraction of statistical characteristics, signal processing techniques, and lag-based features using the sliding window technique. Various hyperparameter-optimized ML models are evaluated across varying window lengths for activity classification. The k-nearest neighbour Classifier achieved the best performance, with AUC of mean 0.98 and standard deviation of 0.0026 on the training set and 0.99 on testing set). In order to ensure transparency, Explainable AI based frameworks such as SHAP is used to interpret feature importance that can be understood and used by practitioners. A detailed comparison of the important features, along with the stability analysis of selected features, supports development of explainable and practical ML models for sustainable livestock management.",
      "tldr_zh": "æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºå¯è§£é‡Šäººå·¥æ™ºèƒ½(Explainable AI)çš„æ–¹æ³•ï¼Œæ—¨åœ¨é€šè¿‡ç›‘æµ‹å¥¶ç‰›è¡Œä¸ºæ¥åº”å¯¹åŠ¨ç‰©å¥åº·ç›‘æµ‹å’Œäº§é‡ä¼˜åŒ–ä¸­çš„æŒ‘æˆ˜ã€‚è¯¥æ–¹æ¡ˆåˆ©ç”¨3è½´åŠ é€Ÿåº¦è®¡ä¼ æ„Ÿå™¨(accelerometer sensors)å’ŒåŸºäºè“ç‰™çš„ç‰©è”ç½‘(IoT)è®¾å¤‡ï¼Œç»“åˆ4Gç½‘ç»œå®ç°äº†æ— ç¼çš„æ•°æ®ä¼ è¾“ä¸å®æ—¶åˆ†æã€‚åœ¨æ•°æ®å¤„ç†é˜¶æ®µï¼Œç ”ç©¶é‡‡ç”¨äº†æ»‘åŠ¨çª—å£æŠ€æœ¯(sliding window technique)æå–ç»Ÿè®¡ç‰¹å¾å’Œæ»åç‰¹å¾(lag-based features)ï¼Œå¹¶å¯¹å¤šç§è¶…å‚æ•°ä¼˜åŒ–(hyperparameter-optimized)çš„æœºå™¨å­¦ä¹ æ¨¡å‹è¿›è¡Œäº†è¯„ä¼°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œk-nearest neighbour (kNN)åˆ†ç±»å™¨è¡¨ç°æœ€ä¼˜ï¼Œåœ¨æµ‹è¯•é›†ä¸Šçš„AUCè¾¾åˆ°0.99ã€‚ä¸ºäº†ç¡®ä¿æ¨¡å‹çš„é€æ˜åº¦ï¼Œç ”ç©¶å¼•å…¥äº†SHAPæ¡†æ¶æ¥è§£é‡Šç‰¹å¾é‡è¦æ€§å¹¶è¿›è¡Œç‰¹å¾ç¨³å®šæ€§åˆ†æã€‚è¯¥å·¥ä½œä¸ºä»ä¸šè€…æä¾›äº†å¯æ“ä½œçš„å†³ç­–æ”¯æŒï¼Œä¸ºæ„å»ºå¯æŒç»­ä¸”å®ç”¨çš„ç•œç‰§ç®¡ç†æœºå™¨å­¦ä¹ æ¨¡å‹å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.10210v3",
      "published_date": "2025-08-13 21:40:35 UTC",
      "updated_date": "2025-08-18 19:26:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:30:00.198994+00:00"
    },
    {
      "arxiv_id": "2508.10208v1",
      "title": "CATNet: A geometric deep learning approach for CAT bond spread prediction in the primary market",
      "title_zh": "CATNetï¼šé¢å‘ä¸€çº§å¸‚åœºå·¨ç¾å€ºåˆ¸åˆ©å·®é¢„æµ‹çš„å‡ ä½•æ·±åº¦å­¦ä¹ æ–¹æ³•",
      "authors": [
        "Dixon Domfeh",
        "Saeid Safarveisi"
      ],
      "abstract": "Traditional models for pricing catastrophe (CAT) bonds struggle to capture the complex, relational data inherent in these instruments. This paper introduces CATNet, a novel framework that applies a geometric deep learning architecture, the Relational Graph Convolutional Network (R-GCN), to model the CAT bond primary market as a graph, leveraging its underlying network structure for spread prediction. Our analysis reveals that the CAT bond market exhibits the characteristics of a scale-free network, a structure dominated by a few highly connected and influential hubs. CATNet demonstrates high predictive performance, significantly outperforming a strong Random Forest benchmark. The inclusion of topological centrality measures as features provides a further, significant boost in accuracy. Interpretability analysis confirms that these network features are not mere statistical artifacts; they are quantitative proxies for long-held industry intuition regarding issuer reputation, underwriter influence, and peril concentration. This research provides evidence that network connectivity is a key determinant of price, offering a new paradigm for risk assessment and proving that graph-based models can deliver both state-of-the-art accuracy and deeper, quantifiable market insights.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æå‡ºäº†CATNetï¼Œè¿™æ˜¯ä¸€ç§åŸºäºå‡ ä½•æ·±åº¦å­¦ä¹ (geometric deep learning)çš„æ–°å‹æ¡†æ¶ï¼Œåˆ©ç”¨å…³ç³»å›¾å·ç§¯ç½‘ç»œ(Relational Graph Convolutional Network, R-GCN)æ¥é¢„æµ‹å·¨ç¾å€ºåˆ¸(CAT bond)ä¸€çº§å¸‚åœºçš„åˆ©å·®ã€‚è¯¥æ–¹æ³•å°†å·¨ç¾å€ºåˆ¸å¸‚åœºå»ºæ¨¡ä¸ºå›¾ç»“æ„ï¼Œå¹¶æ­ç¤ºäº†è¯¥å¸‚åœºå…·æœ‰æ— æ ‡åº¦ç½‘ç»œ(scale-free network)çš„ç‰¹å¾ï¼Œå³ç”±å°‘æ•°å…·æœ‰é«˜åº¦å½±å“åŠ›çš„æ ¸å¿ƒèŠ‚ç‚¹ä¸»å¯¼ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCATNetçš„é¢„æµ‹æ€§èƒ½æ˜¾è‘—ä¼˜äºéšæœºæ£®æ—(Random Forest)åŸºå‡†æ¨¡å‹ï¼Œä¸”å¼•å…¥æ‹“æ‰‘ä¸­å¿ƒæ€§æŒ‡æ ‡(topological centrality measures)ä½œä¸ºç‰¹å¾èƒ½è¿›ä¸€æ­¥æå‡å‡†ç¡®ç‡ã€‚å¯è§£é‡Šæ€§åˆ†æè¯å®ï¼Œè¿™äº›ç½‘ç»œç‰¹å¾æœ‰æ•ˆé‡åŒ–äº†å‘è¡Œäººå£°èª‰ã€æ‰¿é”€å•†å½±å“åŠ›å’Œé£é™©é›†ä¸­åº¦ç­‰è¡Œä¸šç›´è§‰ã€‚è¯¥ç ”ç©¶è¯æ˜äº†ç½‘ç»œè¿é€šæ€§æ˜¯ä»·æ ¼çš„å…³é”®å†³å®šå› ç´ ï¼Œä¸ºå·¨ç¾é£é™©è¯„ä¼°æä¾›äº†ä¸€ç§èƒ½å¤ŸåŒæ—¶å®ç°é«˜ç²¾åº¦ä¸æ·±åº¦å¸‚åœºæ´å¯Ÿçš„æ–°èŒƒå¼ã€‚",
      "categories": [
        "q-fin.PR",
        "cs.AI",
        "cs.LG",
        "q-fin.CP",
        "q-fin.RM"
      ],
      "primary_category": "q-fin.PR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.10208v1",
      "published_date": "2025-08-13 21:38:25 UTC",
      "updated_date": "2025-08-13 21:38:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:30:07.097955+00:00"
    },
    {
      "arxiv_id": "2508.15801v2",
      "title": "LingVarBench: Benchmarking LLMs on Entity Recognitions and Linguistic Verbalization Patterns in Phone-Call Transcripts",
      "title_zh": "LingVarBenchï¼šé’ˆå¯¹ç”µè¯é€šè¯è½¬å½•æ–‡æœ¬å®ä½“è¯†åˆ«ä¸è¯­è¨€è¡¨è¿°æ¨¡å¼çš„å¤§è¯­è¨€æ¨¡å‹åŸºå‡†æµ‹è¯•",
      "authors": [
        "Seyedali Mohammadi",
        "Manas Paldhe",
        "Amit Chhabra",
        "Youngseo Son",
        "Vishal Seshagiri"
      ],
      "abstract": "We study structured entity extraction from phone-call transcripts in customer-support and healthcare settings, where annotation is costly, and data access is limited by privacy and consent. Existing methods degrade under disfluencies, interruptions, and speaker overlap, yet large real-call corpora are rarely shareable. We introduce LingVarBench, a benchmark and semantic synthetic data generation pipeline that generates linguistically varied training data via (1) LLM-sampled entity values, (2) curated linguistic verbalization patterns covering diverse disfluencies and entity-specific readout styles, and (3) a value-transcript consistency filter. Using this dataset, DSPy's SIMBA automatically synthesizes and optimizes extraction prompts, reducing manual prompt engineering and targeting robustness to verbal variation. On real customer transcripts, prompts optimized solely on LingVarBench outperform zero-shot baselines and match or closely approach human-tuned prompts for structured entities such as ZIP code, date of birth, and name (F1 approximately 94-95 percent). For subjective questionnaire items, optimized prompts substantially improve over zero-shot performance and approach human-tuned prompts. LingVarBench offers a practical and cost-efficient path to deployment in a direct-answer setting, with real annotations later enabling additional refinement.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å®¢æˆ·æ”¯æŒå’ŒåŒ»ç–—åœºæ™¯ä¸­é€šè¯æ–‡æœ¬(phone-call transcripts)çš„ç»“æ„åŒ–å®ä½“æå–éš¾é¢˜ï¼Œæå‡ºäº† LingVarBench åŸºå‡†å’Œè¯­ä¹‰åˆæˆæ•°æ®ç”Ÿæˆæµæ°´çº¿ã€‚è¯¥æ¡†æ¶æ—¨åœ¨è§£å†³æ ‡æ³¨æˆæœ¬é«˜ã€éšç§å—é™ä»¥åŠå£è¯­ä¸­æ™®éå­˜åœ¨çš„ä¸æµåˆ©ã€ä¸­æ–­å’Œè¯´è¯äººé‡å ç­‰è¯­è¨€å¤šæ ·æ€§(linguistic variation)é—®é¢˜ã€‚LingVarBench é€šè¿‡ LLM é‡‡æ ·å®ä½“å€¼ã€ç­–åˆ’è¯­è¨€åŒ–æ¨¡å¼(verbalization patterns)ä»¥åŠä¸€è‡´æ€§è¿‡æ»¤å™¨ç”Ÿæˆè®­ç»ƒæ•°æ®ï¼Œå¹¶ç»“åˆ DSPy çš„ SIMBA è‡ªåŠ¨åˆæˆä¸ä¼˜åŒ–æå–æç¤ºè¯(prompts)ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨çœŸå®é€šè¯æ–‡æœ¬ä¸­ï¼Œè¯¥æ–¹æ³•åœ¨é‚®ç¼–ã€å‡ºç”Ÿæ—¥æœŸå’Œå§“åç­‰å®ä½“çš„æå–ä¸Šè¾¾åˆ°äº†çº¦ 94-95% çš„ F1 åˆ†æ•°ï¼Œæ€§èƒ½æ˜¾è‘—ä¼˜äº zero-shot åŸºå‡†ä¸”æ¥è¿‘äººå·¥è°ƒæ•´çš„æç¤ºè¯æ°´å¹³ã€‚è¿™ä¸€æˆæœä¸ºåœ¨ç¼ºä¹çœŸå®æ ‡æ³¨æ•°æ®çš„æƒ…å†µä¸‹ï¼Œå®ç°é²æ£’ä¸”ä½æˆæœ¬çš„å®ä½“æå–ç³»ç»Ÿéƒ¨ç½²æä¾›äº†åˆ‡å®å¯è¡Œçš„è·¯å¾„ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EACL 2026 (Industry Track); to appear in the proceedings",
      "pdf_url": "https://arxiv.org/pdf/2508.15801v2",
      "published_date": "2025-08-13 21:25:19 UTC",
      "updated_date": "2026-01-13 22:53:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:30:15.895647+00:00"
    },
    {
      "arxiv_id": "2508.10192v1",
      "title": "Prompt-Response Semantic Divergence Metrics for Faithfulness Hallucination and Misalignment Detection in Large Language Models",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹å¿ å®æ€§å¹»è§‰ä¸å¯¹é½å¤±æ•ˆæ£€æµ‹çš„æç¤º-å“åº”è¯­ä¹‰æ•£åº¦æŒ‡æ ‡",
      "authors": [
        "Igor Halperin"
      ],
      "abstract": "The proliferation of Large Language Models (LLMs) is challenged by hallucinations, critical failure modes where models generate non-factual, nonsensical or unfaithful text. This paper introduces Semantic Divergence Metrics (SDM), a novel lightweight framework for detecting Faithfulness Hallucinations -- events of severe deviations of LLMs responses from input contexts. We focus on a specific implementation of these LLM errors, {confabulations, defined as responses that are arbitrary and semantically misaligned with the user's query. Existing methods like Semantic Entropy test for arbitrariness by measuring the diversity of answers to a single, fixed prompt. Our SDM framework improves upon this by being more prompt-aware: we test for a deeper form of arbitrariness by measuring response consistency not only across multiple answers but also across multiple, semantically-equivalent paraphrases of the original prompt. Methodologically, our approach uses joint clustering on sentence embeddings to create a shared topic space for prompts and answers. A heatmap of topic co-occurances between prompts and responses can be viewed as a quantified two-dimensional visualization of the user-machine dialogue. We then compute a suite of information-theoretic metrics to measure the semantic divergence between prompts and responses. Our practical score, $\\mathcal{S}_H$, combines the Jensen-Shannon divergence and Wasserstein distance to quantify this divergence, with a high score indicating a Faithfulness hallucination. Furthermore, we identify the KL divergence KL(Answer $||$ Prompt) as a powerful indicator of \\textbf{Semantic Exploration}, a key signal for distinguishing different generative behaviors. These metrics are further combined into the Semantic Box, a diagnostic framework for classifying LLM response types, including the dangerous, confident confabulation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†è¯­ä¹‰å‘æ•£æŒ‡æ ‡(Semantic Divergence Metrics, SDM)ï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨æ£€æµ‹å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)ä¸­å¿ å®æ€§å¹»è§‰(Faithfulness Hallucinations)çš„æ–°å‹è½»é‡åŒ–æ¡†æ¶ã€‚ä¸ä»¥å¾€æ–¹æ³•ä¸åŒï¼ŒSDMå…·æœ‰æ›´å¼ºçš„æç¤ºè¯æ„ŸçŸ¥èƒ½åŠ›ï¼Œé€šè¿‡æµ‹é‡åŸå§‹æç¤ºåŠå…¶è¯­ä¹‰ç­‰ä»·è½¬è¿°(paraphrases)ç”Ÿæˆçš„å¤šä¸ªå›ç­”ä¹‹é—´çš„ä¸€è‡´æ€§æ¥è¯†åˆ«è™šå‡å™è¿°(confabulations)ã€‚åœ¨æ–¹æ³•è®ºä¸Šï¼Œè¯¥æ¡†æ¶å¯¹å¥å­åµŒå…¥è¿›è¡Œè”åˆèšç±»ä»¥æ„å»ºæç¤ºä¸å›ç­”çš„å…±äº«ä¸»é¢˜ç©ºé—´ï¼Œå¹¶åˆ©ç”¨ä¸€ç³»åˆ—ä¿¡æ¯è®ºæŒ‡æ ‡æ¥é‡åŒ–ä¸¤è€…é—´çš„è¯­ä¹‰å‘æ•£ç¨‹åº¦ã€‚ç ”ç©¶æå‡ºçš„ç»¼åˆè¯„åˆ†$\\mathcal{S}_H$ç»“åˆäº†Jensen-Shannonæ•£åº¦å’ŒWassersteinè·ç¦»ï¼Œèƒ½å¤Ÿæœ‰æ•ˆé‡åŒ–å¹¶è¯†åˆ«æ¨¡å‹å“åº”ä¸è¾“å…¥ä¸Šä¸‹æ–‡ä¸¥é‡åç¦»çš„æƒ…å†µã€‚æ­¤å¤–ï¼Œé€šè¿‡å¼•å…¥KLæ•£åº¦ä½œä¸ºè¯­ä¹‰æ¢ç´¢(Semantic Exploration)çš„æŒ‡æ ‡ï¼Œè¯¥ç ”ç©¶è¿›ä¸€æ­¥æ„å»ºäº†è¯­ä¹‰ç›’(Semantic Box)è¯Šæ–­æ¡†æ¶ï¼Œç”¨äºå¯¹åŒ…æ‹¬å±é™©çš„â€œè‡ªä¿¡è™šå‡å™è¿°â€åœ¨å†…çš„å¤šç§LLMå“åº”ç±»å‹è¿›è¡Œç²¾ç¡®åˆ†ç±»ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "q-fin.CP"
      ],
      "primary_category": "cs.CL",
      "comment": "24 pages, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.10192v1",
      "published_date": "2025-08-13 20:55:26 UTC",
      "updated_date": "2025-08-13 20:55:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:30:33.358104+00:00"
    },
    {
      "arxiv_id": "2508.10186v2",
      "title": "PakBBQ: A Culturally Adapted Bias Benchmark for QA",
      "title_zh": "PakBBQï¼šé’ˆå¯¹é—®ç­”ç³»ç»Ÿçš„æ–‡åŒ–é€‚é…æ€§åè§è¯„æµ‹åŸºå‡†",
      "authors": [
        "Abdullah Hashmat",
        "Muhammad Arham Mirza",
        "Agha Ali Raza"
      ],
      "abstract": "With the widespread adoption of Large Language Models (LLMs) across various applications, it is empirical to ensure their fairness across all user communities. However, most LLMs are trained and evaluated on Western centric data, with little attention paid to low-resource languages and regional contexts. To address this gap, we introduce PakBBQ, a culturally and regionally adapted extension of the original Bias Benchmark for Question Answering (BBQ) dataset. PakBBQ comprises over 214 templates, 17180 QA pairs across 8 categories in both English and Urdu, covering eight bias dimensions including age, disability, appearance, gender, socio-economic status, religious, regional affiliation, and language formality that are relevant in Pakistan. We evaluate multiple multilingual LLMs under both ambiguous and explicitly disambiguated contexts, as well as negative versus non negative question framings. Our experiments reveal (i) an average accuracy gain of 12\\% with disambiguation, (ii) consistently stronger counter bias behaviors in Urdu than in English, and (iii) marked framing effects that reduce stereotypical responses when questions are posed negatively. These findings highlight the importance of contextualized benchmarks and simple prompt engineering strategies for bias mitigation in low resource settings.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† PakBBQï¼Œè¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹å·´åŸºæ–¯å¦æ–‡åŒ–å’Œåœ°åŒºèƒŒæ™¯å®šåˆ¶çš„åè§é—®ç­”åŸºå‡† (Bias Benchmark for Question Answering) æ•°æ®é›†ï¼Œæ—¨åœ¨å¡«è¡¥ç°æœ‰å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨ä½èµ„æºè¯­è¨€å’ŒåŒºåŸŸèƒŒæ™¯ä¸‹åè§è¯„ä¼°çš„ç©ºç™½ã€‚PakBBQ åŒ…å«è¶…è¿‡ 17,180 ä¸ªé—®ç­”å¯¹ï¼Œæ¶µç›–è‹±è¯­å’Œä¹Œå°”éƒ½è¯­ (Urdu)ï¼Œæ¶‰åŠå®—æ•™ã€åœ°åŒºå½’å±ã€è¯­è¨€è§„èŒƒæ€§ç­‰ 8 ä¸ªä¸å½“åœ°ç¯å¢ƒé«˜åº¦ç›¸å…³çš„åè§ç»´åº¦ã€‚ç ”ç©¶è€…åœ¨æ¨¡ç³Šä¸æ¶ˆæ­§è¯­å¢ƒä»¥åŠä¸åŒé—®é¢˜æ¡†æ¶ä¸‹è¯„ä¼°äº†å¤šç§å¤šè¯­è¨€ LLMsï¼Œå‘ç°æ˜¾å¼æ¶ˆæ­§å¹³å‡èƒ½å¸¦æ¥ 12% çš„å‡†ç¡®ç‡æå‡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ¨¡å‹åœ¨ä¹Œå°”éƒ½è¯­ç¯å¢ƒä¸‹è¡¨ç°å‡ºæ¯”è‹±è¯­æ›´å¼ºçš„ååè§ (counter bias) è¡Œä¸ºï¼Œä¸”è´Ÿå‘é—®é¢˜æ¡†æ¶èƒ½æ˜¾è‘—å‡å°‘åˆ»æ¿å°è±¡å“åº”ã€‚è¿™é¡¹å·¥ä½œå¼ºè°ƒäº†å¼€å‘è¯­å¢ƒåŒ–åŸºå‡† (contextualized benchmarks) ä»¥åŠåº”ç”¨ç®€å•æç¤ºå·¥ç¨‹ç­–ç•¥å¯¹äºç¼“è§£ä½èµ„æºè®¾ç½®ä¸­æ¨¡å‹åè§çš„é‡è¦æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "13 total pages, 7 figures, 2 tables, Accepted at Main Conference of EMNLP 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.10186v2",
      "published_date": "2025-08-13 20:42:44 UTC",
      "updated_date": "2025-09-28 20:05:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:30:32.190254+00:00"
    },
    {
      "arxiv_id": "2508.10177v2",
      "title": "KompeteAI: Accelerated Autonomous Multi-Agent System for End-to-End Pipeline Generation for Machine Learning Problems",
      "title_zh": "KompeteAIï¼šé¢å‘æœºå™¨å­¦ä¹ é—®é¢˜ç«¯åˆ°ç«¯æµæ°´çº¿ç”Ÿæˆçš„åŠ é€Ÿè‡ªä¸»å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ",
      "authors": [
        "Stepan Kulibaba",
        "Artem Dzhalilov",
        "Roman Pakhomov",
        "Oleg Svidchenko",
        "Alexander Gasnikov",
        "Aleksei Shpilman"
      ],
      "abstract": "Recent Large Language Model (LLM)-based AutoML systems demonstrate impressive capabilities but face significant limitations such as constrained exploration strategies and a severe execution bottleneck. Exploration is hindered by one-shot methods lacking diversity and Monte Carlo Tree Search (MCTS) approaches that fail to recombine strong partial solutions. The execution bottleneck arises from lengthy code validation cycles that stifle iterative refinement. To overcome these challenges, we introduce KompeteAI, a novel AutoML framework with dynamic solution space exploration. Unlike previous MCTS methods that treat ideas in isolation, KompeteAI introduces a merging stage that composes top candidates. We further expand the hypothesis space by integrating Retrieval-Augmented Generation (RAG), sourcing ideas from Kaggle notebooks and arXiv papers to incorporate real-world strategies. KompeteAI also addresses the execution bottleneck via a predictive scoring model and an accelerated debugging method, assessing solution potential using early stage metrics to avoid costly full-code execution. This approach accelerates pipeline evaluation 6.9 times. KompeteAI outperforms leading methods (e.g., RD-agent, AIDE, and Ml-Master) by an average of 3\\% on the primary AutoML benchmark, MLE-Bench. Additionally, we propose Kompete-bench to address limitations in MLE-Bench, where KompeteAI also achieves state-of-the-art results",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†KompeteAIï¼Œä¸€ç§æ—¨åœ¨ä¸ºæœºå™¨å­¦ä¹ é—®é¢˜è‡ªåŠ¨ç”Ÿæˆç«¯åˆ°ç«¯æµæ°´çº¿(End-to-End Pipeline)çš„åŠ é€Ÿå¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œæœ‰æ•ˆè§£å†³äº†ç°æœ‰LLM-based AutoMLç³»ç»Ÿåœ¨æ¢ç´¢ç­–ç•¥å’Œæ‰§è¡Œç“¶é¢ˆæ–¹é¢çš„å±€é™ã€‚KompeteAIå¼•å…¥äº†åŠ¨æ€è§£ç©ºé—´æ¢ç´¢æœºåˆ¶ï¼Œé€šè¿‡åˆå¹¶é˜¶æ®µ(Merging Stage)ç»„åˆä¼˜ç§€å€™é€‰æ–¹æ¡ˆï¼Œå¹¶ç»“åˆæ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)æŠ€æœ¯ä»Kaggleå’ŒarXivä¸­è·å–çœŸå®ç­–ç•¥ã€‚ä¸ºäº†æå‡æ•ˆç‡ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨é¢„æµ‹è¯„åˆ†æ¨¡å‹å’ŒåŠ é€Ÿè°ƒè¯•æ–¹æ³•è¯„ä¼°æ–¹æ¡ˆæ½œåŠ›ï¼Œä½¿æµæ°´çº¿è¯„ä¼°é€Ÿåº¦æå‡äº†6.9å€ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒKompeteAIåœ¨MLE-BenchåŸºå‡†æµ‹è¯•ä¸­å¹³å‡è¡¨ç°ä¼˜äºRD-agentã€AIDEå’ŒMl-Masterç­‰é¢†å…ˆæ–¹æ³•3%ï¼Œå¹¶åœ¨æ–°æå‡ºçš„Kompete-benchä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„(State-of-the-art)æ€§èƒ½ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.10177v2",
      "published_date": "2025-08-13 20:29:56 UTC",
      "updated_date": "2025-09-29 19:54:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:30:43.191102+00:00"
    },
    {
      "arxiv_id": "2508.10164v1",
      "title": "Pruning Long Chain-of-Thought of Large Reasoning Models via Small-Scale Preference Optimization",
      "title_zh": "åŸºäºå°è§„æ¨¡åå¥½ä¼˜åŒ–çš„å¤§æ¨ç†æ¨¡å‹é•¿æ€ç»´é“¾å‰ªè£",
      "authors": [
        "Bin Hong",
        "Jiayu Liu",
        "Zhenya Huang",
        "Kai Zhang",
        "Mengdi Zhang"
      ],
      "abstract": "Recent advances in Large Reasoning Models (LRMs) have demonstrated strong performance on complex tasks through long Chain-of-Thought (CoT) reasoning. However, their lengthy outputs increase computational costs and may lead to overthinking, raising challenges in balancing reasoning effectiveness and efficiency. Current methods for efficient reasoning often compromise reasoning quality or require extensive resources. This paper investigates efficient methods to reduce the generation length of LRMs. We analyze generation path distributions and filter generated trajectories through difficulty estimation. Subsequently, we analyze the convergence behaviors of the objectives of various preference optimization methods under a Bradley-Terry loss based framework. Based on the analysis, we propose Length Controlled Preference Optimization (LCPO) that directly balances the implicit reward related to NLL loss. LCPO can effectively learn length preference with limited data and training. Extensive experiments demonstrate that our approach significantly reduces the average output length by over 50\\% across multiple benchmarks while maintaining the reasoning performance. Our work highlights the potential for computationally efficient approaches in guiding LRMs toward efficient reasoning.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨ç†æ¨¡å‹ (Large Reasoning Models, LRMs) å› é•¿é“¾å¼æ€ç»´ (Chain-of-Thought, CoT) å¯¼è‡´çš„è®¡ç®—æˆæœ¬é«˜æ˜‚åŠè¿‡åº¦æ€è€ƒ (overthinking) é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§é«˜æ•ˆçš„é•¿åº¦å‰Šå‡æ–¹æ³•ã€‚é€šè¿‡åˆ†æç”Ÿæˆè·¯å¾„åˆ†å¸ƒå¹¶åŸºäºéš¾åº¦ä¼°ç®—è¿‡æ»¤è½¨è¿¹ï¼Œä½œè€…åœ¨ Bradley-Terry æŸå¤±æ¡†æ¶ä¸‹æ¢è®¨äº†åå¥½ä¼˜åŒ– (preference optimization) çš„æ”¶æ•›è¡Œä¸ºã€‚ç ”ç©¶è¿›è€Œæå‡ºäº†é•¿åº¦æ§åˆ¶åå¥½ä¼˜åŒ– (Length Controlled Preference Optimization, LCPO)ï¼Œè¯¥æ–¹æ³•é€šè¿‡ç›´æ¥å¹³è¡¡ä¸ NLL loss ç›¸å…³çš„éšå«å¥–åŠ±ï¼Œèƒ½å¤Ÿåœ¨æœ‰é™çš„æ•°æ®å’Œè®­ç»ƒä¸‹æœ‰æ•ˆå­¦ä¹ é•¿åº¦åå¥½ã€‚å®éªŒè¯æ˜ï¼ŒLCPO åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å°†å¹³å‡è¾“å‡ºé•¿åº¦æ˜¾è‘—é™ä½äº† 50% ä»¥ä¸Šï¼Œä¸”æœªæŸå®³æ¨¡å‹çš„æ¨ç†æ€§èƒ½ã€‚è¯¥å·¥ä½œä¸ºå¼•å¯¼ LRMs åœ¨ä¿è¯æ•ˆæœçš„åŒæ—¶å®ç°é«˜æ•ˆæ¨ç†æä¾›äº†æå…·æ½œåŠ›çš„è®¡ç®—ä¼˜åŒ–æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "19 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.10164v1",
      "published_date": "2025-08-13 20:00:09 UTC",
      "updated_date": "2025-08-13 20:00:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:30:45.883703+00:00"
    },
    {
      "arxiv_id": "2508.10161v2",
      "title": "LaajMeter: A Framework for LaaJ Evaluation",
      "title_zh": "LaajMeterï¼šLaaJ è¯„ä¼°æ¡†æ¶",
      "authors": [
        "Samuel Ackerman",
        "Gal Amram",
        "Ora Nova Fandina",
        "Eitan Farchi",
        "Shmulik Froimovich",
        "Raviv Gal",
        "Wesam Ibraheem",
        "Avi Ziv"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly used as evaluators in natural language processing tasks, a paradigm known as LLM-as-a-Judge (LaaJ). The analysis of a LaaJ software, commonly refereed to as meta-evaluation, pose significant challenges in domain-specific contexts. In such domains, in contrast to general domains, annotated data is scarce and expert evaluation is costly. As a result, meta-evaluation is often performed using metrics that have not been validated for the specific domain in which they are applied. Therefore, it becomes difficult to determine which metrics effectively identify LaaJ quality, and further, what threshold indicates sufficient evaluator performance. In this work, we introduce LaaJMeter, a simulation-based framework for controlled meta-evaluation of LaaJs. LaaJMeter enables engineers to generate synthetic data representing virtual models and judges, allowing systematic analysis of evaluation metrics under realistic conditions. This helps practitioners validate LaaJs for specific tasks: they can test whether their metrics correctly distinguish between high and low quality (virtual) LaaJs, and estimate appropriate thresholds for evaluator adequacy. We demonstrate the utility of LaaJMeter in a code translation task involving a legacy programming language, showing how different metrics vary in sensitivity to evaluator quality. Our results highlight the limitations of common metrics and the importance of principled metric selection. LaaJMeter provides a scalable and extensible solution for assessing LaaJs in low-resource settings, contributing to the broader effort to ensure trustworthy and reproducible evaluation in NLP.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† LaaJMeterï¼Œä¸€ä¸ªåŸºäºæ¨¡æ‹Ÿçš„æ¡†æ¶ï¼Œæ—¨åœ¨å¯¹ LLM-as-a-Judge (LaaJ) è¿›è¡Œå—æ§çš„å…ƒè¯„ä¼° (meta-evaluation)ã€‚é’ˆå¯¹é¢†åŸŸç‰¹å®šåœºæ™¯ä¸‹æ ‡æ³¨æ•°æ®ç¨€ç¼ºä¸”ä¸“å®¶è¯„ä¼°æˆæœ¬é«˜æ˜‚çš„æŒ‘æˆ˜ï¼ŒLaaJMeter å…è®¸å·¥ç¨‹å¸ˆç”Ÿæˆä»£è¡¨è™šæ‹Ÿæ¨¡å‹å’Œè¯„åˆ¤è€…çš„åˆæˆæ•°æ®ï¼Œä»è€Œåœ¨ç°å®æ¡ä»¶ä¸‹ç³»ç»Ÿåœ°åˆ†æè¯„ä¼°æŒ‡æ ‡ã€‚è¯¥æ¡†æ¶èƒ½å¸®åŠ©ä»ä¸šè€…éªŒè¯ LaaJ åœ¨ç‰¹å®šä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œæµ‹è¯•æŒ‡æ ‡æ˜¯å¦èƒ½æœ‰æ•ˆåŒºåˆ†è¯„åˆ¤è€…è´¨é‡ï¼Œå¹¶ä¼°ç®—åˆç†çš„è¯„ä¼°é˜ˆå€¼ã€‚ç ”ç©¶é€šè¿‡ä¸€é¡¹æ¶‰åŠæ—§ç‰ˆç¼–ç¨‹è¯­è¨€çš„ä»£ç ç¿»è¯‘ä»»åŠ¡å±•ç¤ºäº† LaaJMeter çš„å®ç”¨æ€§ï¼Œæ­ç¤ºäº†ä¸åŒæŒ‡æ ‡å¯¹è¯„åˆ¤è€…è´¨é‡çµæ•åº¦çš„å·®å¼‚åŠå…¶å±€é™æ€§ã€‚LaaJMeter ä¸ºä½èµ„æºç¯å¢ƒä¸‹çš„ LaaJ è¯„ä¼°æä¾›äº†ä¸€ç§å¯æ‰©å±•ä¸”å¯ç§»æ¤çš„è§£å†³æ–¹æ¡ˆï¼Œä¸ºç¡®ä¿è‡ªç„¶è¯­è¨€å¤„ç† (NLP) é¢†åŸŸè¯„ä¼°çš„å¯é æ€§ä¸å¯é‡å¤æ€§åšå‡ºäº†è´¡çŒ®ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.10161v2",
      "published_date": "2025-08-13 19:51:05 UTC",
      "updated_date": "2025-11-25 08:55:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:30:49.056468+00:00"
    },
    {
      "arxiv_id": "2510.00001v1",
      "title": "Methodological Framework for Quantifying Semantic Test Coverage in RAG Systems",
      "title_zh": "RAG ç³»ç»Ÿè¯­ä¹‰æµ‹è¯•è¦†ç›–ç‡é‡åŒ–çš„æ–¹æ³•è®ºæ¡†æ¶",
      "authors": [
        "Noah Broestl",
        "Adel Nasser Abdalla",
        "Rajprakash Bale",
        "Hersh Gupta",
        "Max Struever"
      ],
      "abstract": "Reliably determining the performance of Retrieval-Augmented Generation (RAG) systems depends on comprehensive test questions. While a proliferation of evaluation frameworks for LLM-powered applications exists, current practices lack a systematic method to ensure these test sets adequately cover the underlying knowledge base, leaving developers with significant blind spots. To address this, we present a novel, applied methodology to quantify the semantic coverage of RAG test questions against their underlying documents. Our approach leverages existing technologies, including vector embeddings and clustering algorithms, to create a practical framework for validating test comprehensiveness. Our methodology embeds document chunks and test questions into a unified vector space, enabling the calculation of multiple coverage metrics: basic proximity, content-weighted coverage, and multi-topic question coverage. Furthermore, we incorporate outlier detection to filter irrelevant questions, allowing for the refinement of test sets. Experimental evidence from two distinct use cases demonstrates that our framework effectively quantifies test coverage, identifies specific content areas with inadequate representation, and provides concrete recommendations for generating new, high-value test questions. This work provides RAG developers with essential tools to build more robust test suites, thereby improving system reliability and extending to applications such as identifying misaligned documents.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Retrieval-Augmented Generation (RAG) ç³»ç»Ÿåœ¨æµ‹è¯•é˜¶æ®µç¼ºä¹ç³»ç»Ÿæ€§æ–¹æ³•ç¡®ä¿æµ‹è¯•é›†å…¨é¢è¦†ç›–çŸ¥è¯†åº“çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªé‡åŒ–è¯­ä¹‰æµ‹è¯•è¦†ç›–ç‡çš„åˆ›æ–°æ–¹æ³•æ¡†æ¶ã€‚è¯¥æ¡†æ¶åˆ©ç”¨ vector embeddings å’Œ clustering algorithms æŠ€æœ¯ï¼Œå°†æ–‡æ¡£åˆ‡å— (chunks) ä¸æµ‹è¯•é—®é¢˜æ˜ å°„åˆ°ç»Ÿä¸€çš„å‘é‡ç©ºé—´ï¼Œä»è€Œå®ç°å¯¹æµ‹è¯•å…¨é¢æ€§çš„é‡åŒ–éªŒè¯ã€‚é€šè¿‡è®¡ç®— basic proximityã€content-weighted coverage ä»¥åŠ multi-topic question coverage ç­‰å…³é”®æŒ‡æ ‡ï¼Œå¼€å‘è€…å¯ä»¥ç²¾å‡†è¯†åˆ«æµ‹è¯•é›†ä¸­çš„ç›²ç‚¹ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜é›†æˆäº† outlier detection æœºåˆ¶ä»¥è¿‡æ»¤æ— å…³é—®é¢˜ï¼Œå¹¶èƒ½å¤Ÿæ ¹æ®è¦†ç›–æƒ…å†µä¸ºç”Ÿæˆé«˜ä»·å€¼çš„æ–°æµ‹è¯•é—®é¢˜æä¾›å…·ä½“å»ºè®®ã€‚ä¸¤ä¸ªå®é™…æ¡ˆä¾‹çš„å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ¡†æ¶èƒ½æœ‰æ•ˆé‡åŒ–æµ‹è¯•è¦†ç›–ç‡å¹¶è¯†åˆ«ä»£è¡¨æ€§ä¸è¶³çš„å†…å®¹åŒºåŸŸï¼Œä¸ºæ„å»ºæ›´å¯é ã€é²æ£’çš„ RAG ç³»ç»Ÿæä¾›äº†å¿…è¦çš„å·¥å…·æ”¯æŒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages, 3 figures, 1 table, 1 algo",
      "pdf_url": "https://arxiv.org/pdf/2510.00001v1",
      "published_date": "2025-08-13 19:48:42 UTC",
      "updated_date": "2025-08-13 19:48:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:30:47.845159+00:00"
    },
    {
      "arxiv_id": "2508.10156v1",
      "title": "Improving watermelon (Citrullus lanatus) disease classification with generative artificial intelligence (GenAI)-based synthetic and real-field images via a custom EfficientNetV2-L model",
      "title_zh": "åŸºäºè‡ªå®šä¹‰ EfficientNetV2-L æ¨¡å‹ï¼Œç»“åˆç”Ÿæˆå¼äººå·¥æ™ºèƒ½ (GenAI) åˆæˆå›¾åƒä¸å®åœ°å›¾åƒæå‡è¥¿ç“œ (Citrullus lanatus) ç—…å®³åˆ†ç±»æ€§èƒ½",
      "authors": [
        "Nitin Rai",
        "Nathan S. Boyd",
        "Gary E. Vallad",
        "Arnold W. Schumann"
      ],
      "abstract": "The current advancements in generative artificial intelligence (GenAI) models have paved the way for new possibilities for generating high-resolution synthetic images, thereby offering a promising alternative to traditional image acquisition for training computer vision models in agriculture. In the context of crop disease diagnosis, GenAI models are being used to create synthetic images of various diseases, potentially facilitating model creation and reducing the dependency on resource-intensive in-field data collection. However, limited research has been conducted on evaluating the effectiveness of integrating real with synthetic images to improve disease classification performance. Therefore, this study aims to investigate whether combining a limited number of real images with synthetic images can enhance the prediction accuracy of an EfficientNetV2-L model for classifying watermelon \\textit{(Citrullus lanatus)} diseases. The training dataset was divided into five treatments: H0 (only real images), H1 (only synthetic images), H2 (1:1 real-to-synthetic), H3 (1:10 real-to-synthetic), and H4 (H3 + random images to improve variability and model generalization). All treatments were trained using a custom EfficientNetV2-L architecture with enhanced fine-tuning and transfer learning techniques. Models trained on H2, H3, and H4 treatments demonstrated high precision, recall, and F1-score metrics. Additionally, the weighted F1-score increased from 0.65 (on H0) to 1.00 (on H3-H4) signifying that the addition of a small number of real images with a considerable volume of synthetic images improved model performance and generalizability. Overall, this validates the findings that synthetic images alone cannot adequately substitute for real images; instead, both must be used in a hybrid manner to maximize model performance for crop disease classification.",
      "tldr_zh": "æœ¬ç ”ç©¶æ¢è®¨äº†åˆ©ç”¨ç”Ÿæˆå¼äººå·¥æ™ºèƒ½(GenAI)ç”Ÿæˆçš„åˆæˆå›¾åƒæ¥æ”¹è¿›è¥¿ç“œ(Citrullus lanatus)ç—…å®³åˆ†ç±»çš„æ•ˆæœï¼Œæ—¨åœ¨å‡å°‘å¯¹èµ„æºå¯†é›†å‹ç”°é—´æ•°æ®é‡‡é›†çš„ä¾èµ–ã€‚ç ”ç©¶é‡‡ç”¨å®šåˆ¶çš„EfficientNetV2-Læ¨¡å‹ï¼Œé€šè¿‡å¯¹æ¯”ä»…ä½¿ç”¨çœŸå®å›¾åƒã€ä»…ä½¿ç”¨åˆæˆå›¾åƒä»¥åŠä¸åŒæ¯”ä¾‹æ··åˆå›¾åƒçš„äº”ç§è®­ç»ƒæ–¹æ¡ˆï¼Œè¯„ä¼°äº†åˆæˆæ•°æ®çš„æœ‰æ•ˆæ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè™½ç„¶ä»…é åˆæˆå›¾åƒä¸è¶³ä»¥å®Œå…¨æ›¿ä»£çœŸå®æ•°æ®ï¼Œä½†å°†å°‘é‡çœŸå®å›¾åƒä¸å¤§é‡åˆæˆå›¾åƒç›¸ç»“åˆï¼ˆå¦‚H3å’ŒH4æ–¹æ¡ˆï¼‰å¯æ˜¾è‘—æå‡æ€§èƒ½ã€‚åŠ æƒF1-scoreä»çº¯çœŸå®å›¾åƒæ–¹æ¡ˆçš„0.65æå‡è‡³1.00ï¼Œè¯æ˜äº†è¿™ç§æ··åˆæ–¹æ³•èƒ½æ˜¾è‘—å¢å¼ºæ¨¡å‹çš„é¢„æµ‹å‡†ç¡®ç‡å’Œæ³›åŒ–èƒ½åŠ›ã€‚è¯¥ç ”ç©¶ä¸ºåˆ©ç”¨GenAIä¼˜åŒ–å†œä¸šè®¡ç®—æœºè§†è§‰æ¨¡å‹æä¾›äº†é‡è¦çš„å®è¯æ”¯æŒï¼ŒéªŒè¯äº†æ··åˆå›¾åƒè®­ç»ƒåœ¨ä½œç‰©ç—…å®³è¯Šæ–­é¢†åŸŸçš„åº”ç”¨æ½œåŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.10156v1",
      "published_date": "2025-08-13 19:39:39 UTC",
      "updated_date": "2025-08-13 19:39:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:30:51.948673+00:00"
    },
    {
      "arxiv_id": "2508.14088v1",
      "title": "CoBAD: Modeling Collective Behaviors for Human Mobility Anomaly Detection",
      "title_zh": "CoBADï¼šé¢å‘äººç±»ç§»åŠ¨å¼‚å¸¸æ£€æµ‹çš„é›†ä½“è¡Œä¸ºå»ºæ¨¡",
      "authors": [
        "Haomin Wen",
        "Shurui Cao",
        "Leman Akoglu"
      ],
      "abstract": "Detecting anomalies in human mobility is essential for applications such as public safety and urban planning. While traditional anomaly detection methods primarily focus on individual movement patterns (e.g., a child should stay at home at night), collective anomaly detection aims to identify irregularities in collective mobility behaviors across individuals (e.g., a child is at home alone while the parents are elsewhere) and remains an underexplored challenge. Unlike individual anomalies, collective anomalies require modeling spatiotemporal dependencies between individuals, introducing additional complexity. To address this gap, we propose CoBAD, a novel model designed to capture Collective Behaviors for human mobility Anomaly Detection. We first formulate the problem as unsupervised learning over Collective Event Sequences (CES) with a co-occurrence event graph, where CES represents the event sequences of related individuals. CoBAD then employs a two-stage attention mechanism to model both the individual mobility patterns and the interactions across multiple individuals. Pre-trained on large-scale collective behavior data through masked event and link reconstruction tasks, CoBAD is able to detect two types of collective anomalies: unexpected co-occurrence anomalies and absence anomalies, the latter of which has been largely overlooked in prior work. Extensive experiments on large-scale mobility datasets demonstrate that CoBAD significantly outperforms existing anomaly detection baselines, achieving an improvement of 13%-18% in AUCROC and 19%-70% in AUCPR. All source code is available at https://github.com/wenhaomin/CoBAD.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†CoBADï¼Œä¸€ç§æ—¨åœ¨é€šè¿‡å»ºæ¨¡ç¾¤ä½“è¡Œä¸ºæ¥æ£€æµ‹äººç±»ç§»åŠ¨æ€§å¼‚å¸¸çš„æ–°å‹æ¨¡å‹ã€‚é’ˆå¯¹ä¼ ç»Ÿæ–¹æ³•éš¾ä»¥æ•æ‰ä¸ªä½“é—´æ—¶ç©ºä¾èµ–å…³ç³»çš„å±€é™æ€§ï¼ŒCoBADåˆ©ç”¨Collective Event Sequences (CES)å’Œå…±ç°äº‹ä»¶å›¾(co-occurrence event graph)å¯¹ç›¸å…³è”ä¸ªä½“çš„åºåˆ—è¿›è¡Œæ— ç›‘ç£å­¦ä¹ ã€‚æ¨¡å‹é‡‡ç”¨äº†ä¸¤é˜¶æ®µæ³¨æ„åŠ›æœºåˆ¶(two-stage attention mechanism)ï¼Œåˆ†åˆ«å¯¹ä¸ªä½“ç§»åŠ¨æ¨¡å¼å’Œå¤šä¸»ä½“é—´çš„äº¤äº’è¿›è¡Œå»ºæ¨¡ã€‚é€šè¿‡åœ¨å¤§è§„æ¨¡æ•°æ®ä¸Šè¿›è¡Œæ©ç äº‹ä»¶å’Œé“¾æ¥é‡å»ºçš„é¢„è®­ç»ƒï¼ŒCoBADèƒ½å¤Ÿç²¾å‡†è¯†åˆ«éé¢„æœŸçš„å…±ç°å¼‚å¸¸ä»¥åŠè¢«å…ˆå‰ç ”ç©¶å¿½è§†çš„ç¼ºå¤±å¼‚å¸¸(absence anomalies)ã€‚å®éªŒè¯æ˜ï¼ŒCoBADåœ¨AUCROCå’ŒAUCPRæŒ‡æ ‡ä¸Šæ¯”ç°æœ‰åŸºçº¿æ¨¡å‹åˆ†åˆ«æå‡äº†13%-18%å’Œ19%-70%ã€‚è¯¥ç ”ç©¶ä¸ºå…¬å…±å®‰å…¨å’ŒåŸå¸‚è§„åˆ’ä¸­å¤æ‚çš„ç¾¤ä½“å¼‚å¸¸æ£€æµ‹ä»»åŠ¡æä¾›äº†é«˜æ•ˆä¸”å¯æ‰©å±•çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14088v1",
      "published_date": "2025-08-13 19:33:38 UTC",
      "updated_date": "2025-08-13 19:33:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:31:00.529588+00:00"
    },
    {
      "arxiv_id": "2508.10152v2",
      "title": "Improving and Evaluating Open Deep Research Agents",
      "title_zh": "å¼€æ”¾å¼æ·±åº¦ç ”ç©¶æ™ºèƒ½ä½“çš„æ”¹è¿›ä¸è¯„ä¼°",
      "authors": [
        "Doaa Allabadi",
        "Kyle Bradbury",
        "Jordan M. Malof"
      ],
      "abstract": "We focus here on Deep Research Agents (DRAs), which are systems that can take a natural language prompt from a user, and then autonomously search for, and utilize, internet-based content to address the prompt. Recent DRAs have demonstrated impressive capabilities on public benchmarks however, recent research largely involves proprietary closed-source systems. At the time of this work, we only found one open-source DRA, termed Open Deep Research (ODR). In this work we adapt the challenging recent BrowseComp benchmark to compare ODR to existing proprietary systems. We propose BrowseComp-Small (BC-Small), comprising a subset of BrowseComp, as a more computationally-tractable DRA benchmark for academic labs. We benchmark ODR and two other proprietary systems on BC-Small: one system from Anthropic and one system from Google. We find that all three systems achieve 0% accuracy on the test set of 60 questions. We introduce three strategic improvements to ODR, resulting in the ODR+ model, which achieves a state-of-the-art 10% success rate on BC-Small among both closed-source and open-source systems. We report ablation studies indicating that all three of our improvements contributed to the success of ODR+.",
      "tldr_zh": "è¯¥ç ”ç©¶èšç„¦äºæ·±åº¦ç ”ç©¶æ™ºèƒ½ä½“ (Deep Research Agents, DRAs)ï¼Œå³èƒ½å¤Ÿæ ¹æ®è‡ªç„¶è¯­è¨€æŒ‡ä»¤è‡ªä¸»æœç´¢å¹¶åˆ©ç”¨äº’è”ç½‘å†…å®¹è§£å†³å¤æ‚ä»»åŠ¡çš„ç³»ç»Ÿã€‚é’ˆå¯¹å½“å‰è¯¥é¢†åŸŸå¤šä¸ºé—­æºç³»ç»Ÿä¸”ç¼ºä¹è½»é‡åŒ–è¯„ä¼°å·¥å…·çš„ç°çŠ¶ï¼Œä½œè€…æå‡ºäº†æ›´é€‚åˆå­¦æœ¯å®éªŒå®¤çš„åŸºå‡†æµ‹è¯•é›† BrowseComp-Small (BC-Small)ã€‚åˆå§‹æµ‹è¯„å‘ç°ï¼Œå¼€æºç³»ç»Ÿ Open Deep Research (ODR) ä¸æ¥è‡ª Anthropic å’Œ Google çš„ä¸“æœ‰ç³»ç»Ÿåœ¨ BC-Small æµ‹è¯•é›†ä¸Šå‡ä»…è·å¾— 0% çš„å‡†ç¡®ç‡ã€‚é€šè¿‡å¼•å…¥ä¸‰é¡¹ç­–ç•¥æ€§æ”¹è¿›ï¼Œç ”ç©¶è€…å¼€å‘å‡ºäº† ODR+ æ¨¡å‹ï¼Œä½¿å…¶åœ¨ BC-Small ä¸Šè¾¾åˆ°äº† 10% çš„æˆåŠŸç‡ï¼Œåœ¨å¼€æºå’Œé—­æºç³»ç»Ÿä¸­å‡å–å¾—äº†å½“å‰çš„å…ˆè¿›æ°´å¹³ (State-of-the-Art)ã€‚æ¶ˆèå®éªŒ (Ablation studies) ç»“æœè¿›ä¸€æ­¥è¯æ˜äº†æ‰€ææ”¹è¿›æªæ–½åœ¨æå‡æ™ºèƒ½ä½“è‡ªä¸»ç ”ç©¶èƒ½åŠ›æ–¹é¢çš„å…³é”®ä½œç”¨ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 2 figures, 2 tables",
      "pdf_url": "https://arxiv.org/pdf/2508.10152v2",
      "published_date": "2025-08-13 19:32:01 UTC",
      "updated_date": "2026-01-08 17:54:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:31:00.144742+00:00"
    },
    {
      "arxiv_id": "2508.10148v1",
      "title": "Out-of-Distribution Detection using Counterfactual Distance",
      "title_zh": "åŸºäºåäº‹å®è·ç¦»çš„åˆ†å¸ƒå¤–æ£€æµ‹",
      "authors": [
        "Maria Stoica",
        "Francesco Leofante",
        "Alessio Lomuscio"
      ],
      "abstract": "Accurate and explainable out-of-distribution (OOD) detection is required to use machine learning systems safely. Previous work has shown that feature distance to decision boundaries can be used to identify OOD data effectively. In this paper, we build on this intuition and propose a post-hoc OOD detection method that, given an input, calculates the distance to decision boundaries by leveraging counterfactual explanations. Since computing explanations can be expensive for large architectures, we also propose strategies to improve scalability by computing counterfactuals directly in embedding space. Crucially, as the method employs counterfactual explanations, we can seamlessly use them to help interpret the results of our detector. We show that our method is in line with the state of the art on CIFAR-10, achieving 93.50% AUROC and 25.80% FPR95. Our method outperforms these methods on CIFAR-100 with 97.05% AUROC and 13.79% FPR95 and on ImageNet-200 with 92.55% AUROC and 33.55% FPR95 across four OOD datasets",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æœºå™¨å­¦ä¹ ç³»ç»Ÿçš„å®‰å…¨æ€§éœ€æ±‚ï¼Œæå‡ºäº†ä¸€ç§åŸºäºåäº‹å®è§£é‡Š(Counterfactual Explanations)çš„åç½®(Post-hoc)ç¦»ç¾¤æ£€æµ‹(Out-of-Distribution Detection, OOD)æ–¹æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡è®¡ç®—è¾“å…¥æ ·æœ¬åˆ°å†³ç­–è¾¹ç•Œçš„åäº‹å®è·ç¦»æ¥è¯†åˆ«ç¦»ç¾¤æ•°æ®ï¼Œæœ‰æ•ˆåœ°ç»“åˆäº†æ£€æµ‹æ€§èƒ½ä¸ç»“æœçš„å¯è§£é‡Šæ€§ã€‚ä¸ºäº†åº”å¯¹å¤§è§„æ¨¡æ¨¡å‹æ¶æ„ä¸‹çš„è®¡ç®—å¼€é”€ï¼Œç ”ç©¶è€…æå‡ºäº†åœ¨åµŒå…¥ç©ºé—´(Embedding Space)ç›´æ¥ç”Ÿæˆåäº‹å®çš„ç­–ç•¥ï¼Œä»è€Œæ˜¾è‘—å¢å¼ºäº†ç³»ç»Ÿçš„å¯æ‰©å±•æ€§(Scalability)ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•ç”Ÿæˆçš„åäº‹å®è§£é‡Šèƒ½å¤Ÿæ— ç¼åœ°å¸®åŠ©ç”¨æˆ·ç†è§£æ£€æµ‹å™¨çš„å†³ç­–ä¾æ®ï¼Œæå‡äº†ç³»ç»Ÿçš„é€æ˜åº¦ã€‚åœ¨å®éªŒè¯„ä¼°ä¸­ï¼Œè¯¥æ–¹æ³•åœ¨CIFAR-10æ•°æ®é›†ä¸Šå®ç°äº†93.50%çš„AUROCï¼Œå¹¶åœ¨CIFAR-100å’ŒImageNet-200ç­‰æ›´å…·æŒ‘æˆ˜æ€§çš„æ•°æ®é›†ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿æ–¹æ³•ã€‚è¿™é¡¹å·¥ä½œä¸ºå¼€å‘ç²¾ç¡®ã€é«˜æ•ˆä¸”å¯è§£é‡Šçš„å®‰å…¨æœºå™¨å­¦ä¹ ç³»ç»Ÿæä¾›äº†é‡è¦çš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.10148v1",
      "published_date": "2025-08-13 19:17:05 UTC",
      "updated_date": "2025-08-13 19:17:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:31:04.656679+00:00"
    },
    {
      "arxiv_id": "2508.10147v1",
      "title": "rETF-semiSL: Semi-Supervised Learning for Neural Collapse in Temporal Data",
      "title_zh": "rETF-semiSLï¼šé’ˆå¯¹æ—¶åºæ•°æ®ä¸­ç¥ç»åç¼©ç°è±¡çš„åŠç›‘ç£å­¦ä¹ ",
      "authors": [
        "Yuhan Xie",
        "William Cappelletti",
        "Mahsa Shoaran",
        "Pascal Frossard"
      ],
      "abstract": "Deep neural networks for time series must capture complex temporal patterns, to effectively represent dynamic data. Self- and semi-supervised learning methods show promising results in pre-training large models, which -- when finetuned for classification -- often outperform their counterparts trained from scratch. Still, the choice of pretext training tasks is often heuristic and their transferability to downstream classification is not granted, thus we propose a novel semi-supervised pre-training strategy to enforce latent representations that satisfy the Neural Collapse phenomenon observed in optimally trained neural classifiers. We use a rotational equiangular tight frame-classifier and pseudo-labeling to pre-train deep encoders with few labeled samples. Furthermore, to effectively capture temporal dynamics while enforcing embedding separability, we integrate generative pretext tasks with our method, and we define a novel sequential augmentation strategy. We show that our method significantly outperforms previous pretext tasks when applied to LSTMs, transformers, and state-space models on three multivariate time series classification datasets. These results highlight the benefit of aligning pre-training objectives with theoretically grounded embedding geometry.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†rETF-semiSLï¼Œä¸€ç§é’ˆå¯¹æ—¶é—´åºåˆ—æ•°æ®çš„åŠç›‘ç£å­¦ä¹ é¢„è®­ç»ƒç­–ç•¥ï¼Œæ—¨åœ¨è§£å†³æ·±åº¦ç¥ç»ç½‘ç»œåœ¨å‰ç½®è®­ç»ƒä»»åŠ¡é€‰æ‹©ä¸Šçš„å¯å‘å¼é—®é¢˜åŠå…¶åœ¨åˆ†ç±»ä»»åŠ¡ä¸­è¿ç§»æ€§ä¸è¶³çš„æŒ‘æˆ˜ã€‚è¯¥æ–¹æ³•é€šè¿‡å¼ºåˆ¶æ½œåœ¨è¡¨ç¤ºæ»¡è¶³æœ€ä¼˜ç¥ç»åˆ†ç±»å™¨ä¸­çš„Neural Collapseç°è±¡ï¼Œåˆ©ç”¨æ—‹è½¬ç­‰è§’ç´§æ¡†æ¶åˆ†ç±»å™¨(rotational equiangular tight frame-classifier)å’Œä¼ªæ ‡ç­¾æŠ€æœ¯(pseudo-labeling)åœ¨å°‘é‡æ ‡æ³¨æ ·æœ¬ä¸‹å¯¹æ·±åº¦ç¼–ç å™¨è¿›è¡Œé¢„è®­ç»ƒã€‚åŒæ—¶ï¼Œç ”ç©¶æ•´åˆäº†ç”Ÿæˆå¼å‰ç½®ä»»åŠ¡ä¸åˆ›æ–°çš„åºåˆ—å¢å¼ºç­–ç•¥(sequential augmentation strategy)ï¼Œä»¥åœ¨æ•è·æ—¶é—´åŠ¨æ€çš„åŒæ—¶å¢å¼ºåµŒå…¥çš„å¯åˆ†æ€§ã€‚åœ¨ä¸‰ä¸ªå¤šå…ƒæ—¶é—´åºåˆ—åˆ†ç±»æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨LSTMsã€transformersåŠstate-space modelsä¸Šçš„è¡¨ç°å‡æ˜¾è‘—ä¼˜äºä»¥å¾€çš„å‰ç½®ä»»åŠ¡ã€‚è¿™ä¸€ç»“æœçªæ˜¾äº†å°†é¢„è®­ç»ƒç›®æ ‡ä¸å…·å¤‡ç†è®ºæ”¯æ’‘çš„åµŒå…¥å‡ ä½•(embedding geometry)ç›¸ç»Ÿä¸€åœ¨æå‡æ¨¡å‹æ€§èƒ½æ–¹é¢çš„æ˜¾è‘—ä¼˜åŠ¿ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.10147v1",
      "published_date": "2025-08-13 19:16:47 UTC",
      "updated_date": "2025-08-13 19:16:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:31:23.948203+00:00"
    },
    {
      "arxiv_id": "2508.10146v1",
      "title": "Agentic AI Frameworks: Architectures, Protocols, and Design Challenges",
      "title_zh": "ä»£ç†å¼äººå·¥æ™ºèƒ½æ¡†æ¶ï¼šæ¶æ„ã€åè®®ä¸è®¾è®¡æŒ‘æˆ˜",
      "authors": [
        "Hana Derouiche",
        "Zaki Brahmi",
        "Haithem Mazeni"
      ],
      "abstract": "The emergence of Large Language Models (LLMs) has ushered in a transformative paradigm in artificial intelligence, Agentic AI, where intelligent agents exhibit goal-directed autonomy, contextual reasoning, and dynamic multi-agent coordination. This paper provides a systematic review and comparative analysis of leading Agentic AI frameworks, including CrewAI, LangGraph, AutoGen, Semantic Kernel, Agno, Google ADK, and MetaGPT, evaluating their architectural principles, communication mechanisms, memory management, safety guardrails, and alignment with service-oriented computing paradigms. Furthermore, we identify key limitations, emerging trends, and open challenges in the field. To address the issue of agent communication, we conduct an in-depth analysis of protocols such as the Contract Net Protocol (CNP), Agent-to-Agent (A2A), Agent Network Protocol (ANP), and Agora. Our findings not only establish a foundational taxonomy for Agentic AI systems but also propose future research directions to enhance scalability, robustness, and interoperability. This work serves as a comprehensive reference for researchers and practitioners working to advance the next generation of autonomous AI systems.",
      "tldr_zh": "è¯¥è®ºæ–‡é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ (LLMs) é©±åŠ¨ä¸‹çš„æ™ºèƒ½ä½“ AI (Agentic AI) æ¡†æ¶è¿›è¡Œäº†ç³»ç»Ÿæ€§çš„ç»¼è¿°ä¸æ¯”è¾ƒåˆ†æï¼Œé‡ç‚¹æ¢è®¨äº†æ™ºèƒ½ä½“çš„ç›®æ ‡å¯¼å‘è‡ªä¸»æ€§ã€ä¸Šä¸‹æ–‡æ¨ç†åŠåŠ¨æ€å¤šæ™ºèƒ½ä½“åä½œæœºåˆ¶ã€‚ç ”ç©¶äººå‘˜æ·±å…¥è¯„ä¼°äº†åŒ…æ‹¬ CrewAIã€LangGraphã€AutoGenã€Semantic Kernelã€Agnoã€Google ADK ä»¥åŠ MetaGPT åœ¨å†…çš„é¢†å…ˆæ¡†æ¶ï¼Œè¯¦å°½åˆ†æäº†å®ƒä»¬çš„æ¶æ„åŸç†ã€é€šä¿¡æœºåˆ¶ã€å†…å­˜ç®¡ç†åŠå®‰å…¨æŠ¤æ ã€‚ä¸ºäº†è§£å†³æ™ºèƒ½ä½“é—´çš„é€šä¿¡éš¾é¢˜ï¼Œè®ºæ–‡è¿›ä¸€æ­¥å‰–æäº† Contract Net Protocol (CNP)ã€Agent-to-Agent (A2A)ã€Agent Network Protocol (ANP) å’Œ Agora ç­‰å…³é”®åè®®ã€‚é€šè¿‡å»ºç«‹ Agentic AI ç³»ç»Ÿçš„åŸºç¡€åˆ†ç±»æ³• (Taxonomy)ï¼Œè¯¥ç ”ç©¶è¯†åˆ«äº†å½“å‰é¢†åŸŸçš„ä¸»è¦å±€é™æ€§ä¸æ–°å…´è¶‹åŠ¿ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æå‡ºäº†æ—¨åœ¨å¢å¼ºç³»ç»Ÿå¯æ‰©å±•æ€§ã€é²æ£’æ€§å’Œäº’æ“ä½œæ€§çš„æœªæ¥ç ”ç©¶æ–¹å‘ï¼Œä¸ºä¸‹ä¸€ä»£è‡ªä¸» AI ç³»ç»Ÿçš„ç ”å‘æä¾›äº†å…¨é¢çš„å‚è€ƒæ¡†æ¶ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.10146v1",
      "published_date": "2025-08-13 19:16:18 UTC",
      "updated_date": "2025-08-13 19:16:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:31:51.455178+00:00"
    },
    {
      "arxiv_id": "2508.10143v1",
      "title": "MCP-Orchestrated Multi-Agent System for Automated Disinformation Detection",
      "title_zh": "åŸºäº MCP ç¼–æ’çš„è‡ªåŠ¨åŒ–è™šå‡ä¿¡æ¯æ£€æµ‹å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ",
      "authors": [
        "Alexandru-Andrei Avram",
        "Adrian Groza",
        "Alexandru Lecu"
      ],
      "abstract": "The large spread of disinformation across digital platforms creates significant challenges to information integrity. This paper presents a multi-agent system that uses relation extraction to detect disinformation in news articles, focusing on titles and short text snippets. The proposed Agentic AI system combines four agents: (i) a machine learning agent (logistic regression), (ii) a Wikipedia knowledge check agent (which relies on named entity recognition), (iii) a coherence detection agent (using LLM prompt engineering), and (iv) a web-scraped data analyzer that extracts relational triplets for fact checking. The system is orchestrated via the Model Context Protocol (MCP), offering shared context and live learning across components. Results demonstrate that the multi-agent ensemble achieves 95.3% accuracy with an F1 score of 0.964, significantly outperforming individual agents and traditional approaches. The weighted aggregation method, mathematically derived from individual agent misclassification rates, proves superior to algorithmic threshold optimization. The modular architecture makes the system easily scalable, while also maintaining details of the decision processes.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªåŸºäº Model Context Protocol (MCP) ç¼–æ’çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œä¸“é—¨ç”¨äºè‡ªåŠ¨åŒ–æ£€æµ‹æ•°å­—å¹³å°ä¸Šçš„ Disinformationã€‚è¯¥ç³»ç»Ÿæ ¸å¿ƒç»“åˆäº† Relation Extraction æŠ€æœ¯ï¼Œæ•´åˆäº† Logistic Regression æœºå™¨å­¦ä¹ æ™ºèƒ½ä½“ã€åŸºäº Named Entity Recognition çš„ Wikipedia çŸ¥è¯†æ£€æŸ¥æ™ºèƒ½ä½“ã€åˆ©ç”¨ LLM Prompt Engineering çš„è¿è´¯æ€§æ£€æµ‹æ™ºèƒ½ä½“ï¼Œä»¥åŠé€šè¿‡æå– Relational Triplets è¿›è¡Œ Fact Checking çš„åˆ†æå™¨ã€‚å„æ™ºèƒ½ä½“åœ¨ MCP è°ƒåº¦ä¸‹å®ç°å…±äº«ä¸Šä¸‹æ–‡å’Œå®æ—¶å­¦ä¹ ï¼Œå¹¶é‡‡ç”¨ä¸€ç§åŸºäºè¯¯åˆ†ç±»ç‡æ•°å­¦æ¨å¯¼å‡ºçš„ Weighted Aggregation æ–¹æ³•è¿›è¡Œå†³ç­–èåˆã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥ç³»ç»Ÿåœ¨æ£€æµ‹æ–°é—»æ ‡é¢˜å’ŒçŸ­æ–‡æœ¬ç‰‡æ®µæ—¶è¾¾åˆ°äº† 95.3% çš„å‡†ç¡®ç‡å’Œ 0.964 çš„ F1 Scoreï¼Œæ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•å’Œå•ä¸€æ™ºèƒ½ä½“æ¨¡å‹ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¯æ˜è¯¥åŠ æƒèšåˆé€»è¾‘åœ¨æ€§èƒ½ä¸Šä¼˜äº Algorithmic Threshold Optimizationã€‚è¿™ç§æ¨¡å—åŒ–æ¶æ„åœ¨æå‡ç³»ç»Ÿ Scalability çš„åŒæ—¶ï¼Œä¹Ÿä¿è¯äº†å†³ç­–è¿‡ç¨‹çš„å¯è¿½æº¯æ€§ï¼Œä¸ºç»´æŠ¤ä¿¡æ¯å®Œæ•´æ€§æä¾›äº†é«˜æ•ˆä¸”å¯é çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages + 1 page references, 5 figures, 4 tables, Registered for the 27th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing, 2025, Timisoara",
      "pdf_url": "https://arxiv.org/pdf/2508.10143v1",
      "published_date": "2025-08-13 19:14:48 UTC",
      "updated_date": "2025-08-13 19:14:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:31:32.460192+00:00"
    },
    {
      "arxiv_id": "2508.10137v1",
      "title": "mSCoRe: a $M$ultilingual and Scalable Benchmark for $S$kill-based $Co$mmonsense $Re$asoning",
      "title_zh": "mSCoReï¼šé¢å‘åŸºäºæŠ€èƒ½å¸¸è¯†æ¨ç†çš„å¤šè¯­è¨€å¯æ‰©å±•è¯„æµ‹åŸºå‡†",
      "authors": [
        "Nghia Trung Ngo",
        "Franck Dernoncourt",
        "Thien Huu Nguyen"
      ],
      "abstract": "Recent advancements in reasoning-reinforced Large Language Models (LLMs) have shown remarkable capabilities in complex reasoning tasks. However, the mechanism underlying their utilization of different human reasoning skills remains poorly investigated, especially for multilingual commonsense reasoning that involves everyday knowledge across different languages and cultures. To address this gap, we propose a \\textbf{M}ultilingual and Scalable Benchmark for \\textbf{S}kill-based \\textbf{Co}mmonsense \\textbf{Re}asoning (\\textbf{mSCoRe}). Our benchmark incorporates three key components that are designed to systematically evaluate LLM's reasoning capabilities, including: (1) a novel taxonomy of reasoning skills that enables fine-grained analysis of models' reasoning processes, (2) a robust data synthesis pipeline tailored specifically for commonsense reasoning evaluation, and (3) a complexity scaling framework allowing task difficulty to scale dynamically alongside future improvements in LLM abilities. Extensive experiments on eights state-of-the-art LLMs of varying sizes and training approaches demonstrate that \\textbf{mSCoRe} remains significantly challenging for current models, particularly at higher complexity levels. Our results reveal the limitations of such reasoning-reinforced models when confronted with nuanced multilingual general and cultural commonsense. We further provide detailed analysis on the models' reasoning processes, suggesting future directions for improving multilingual commonsense reasoning capabilities.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†mSCoReï¼Œè¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹åŸºäºæŠ€èƒ½çš„å¸¸è¯†æ¨ç†(Skill-based Commonsense Reasoning)çš„å¤šè¯­è¨€ä¸”å¯æ‰©å±•çš„åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¤„ç†è·¨è¯­è¨€å’Œæ–‡åŒ–å¸¸è¯†æ—¶æ¨ç†æœºåˆ¶ä¸æ˜çš„é—®é¢˜ã€‚è¯¥åŸºå‡†åŒ…å«ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶ï¼šä¸€ç§ç”¨äºæ¨ç†è¿‡ç¨‹ç»†ç²’åº¦åˆ†æçš„æ¨ç†æŠ€èƒ½åˆ†ç±»æ³•(taxonomy of reasoning skills)ã€ä¸€ä¸ªä¸“ä¸ºå¸¸è¯†æ¨ç†è¯„ä¼°å®šåˆ¶çš„æ•°æ®åˆæˆæµæ°´çº¿(data synthesis pipeline)ï¼Œä»¥åŠä¸€ä¸ªå…è®¸ä»»åŠ¡éš¾åº¦éšæ¨¡å‹èƒ½åŠ›æå‡è€ŒåŠ¨æ€è°ƒæ•´çš„å¤æ‚æ€§æ‰©å±•æ¡†æ¶(complexity scaling framework)ã€‚é€šè¿‡å¯¹å…«ç§ä¸åŒè§„æ¨¡å’Œè®­ç»ƒæ–¹å¼çš„å°–ç«¯æ¨¡å‹è¿›è¡Œå®éªŒï¼Œç»“æœè¡¨æ˜mSCoReå¯¹å½“å‰æ¨¡å‹ä»å…·æœ‰æ˜¾è‘—æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨é«˜å¤æ‚çº§åˆ«ä¸‹ã€‚ç ”ç©¶æ­ç¤ºäº†æ¨ç†å¢å¼ºæ¨¡å‹åœ¨å¤„ç†ç»†å¾®çš„å¤šè¯­è¨€é€šç”¨åŠæ–‡åŒ–å¸¸è¯†æ—¶å­˜åœ¨çš„å±€é™æ€§ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜å¯¹æ¨¡å‹æ¨ç†è¿‡ç¨‹è¿›è¡Œäº†æ·±å…¥åˆ†æï¼Œä¸ºæœªæ¥æ”¹è¿›å¤šè¯­è¨€å¸¸è¯†æ¨ç†èƒ½åŠ›æä¾›äº†æ˜ç¡®çš„æ”¹è¿›æ–¹å‘ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.10137v1",
      "published_date": "2025-08-13 18:59:02 UTC",
      "updated_date": "2025-08-13 18:59:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:31:26.854914+00:00"
    },
    {
      "arxiv_id": "2508.10123v2",
      "title": "Nested-ReFT: Efficient Reinforcement Learning for Large Language Model Fine-Tuning via Off-Policy Rollouts",
      "title_zh": "Nested-ReFTï¼šé€šè¿‡ç¦»ç­–å±•å¼€å®ç°çš„å¤§è¯­è¨€æ¨¡å‹é«˜æ•ˆå¼ºåŒ–å­¦ä¹ å¾®è°ƒ",
      "authors": [
        "Maxime Heuillet",
        "Yufei Cui",
        "Boxing Chen",
        "Audrey Durand",
        "Prasanna Parthasarathi"
      ],
      "abstract": "Advanced reasoning in LLMs on challenging domains like mathematical reasoning can be tackled using verifiable rewards based reinforced fine-tuning (ReFT). In standard ReFT frameworks, a behavior model generates multiple completions with answers per problem, for the answer to be then scored by a reward function. While such RL post-training methods demonstrate significant performance improvements across challenging reasoning domains, the computational cost of generating completions during training with multiple inference steps makes the training cost non-trivial. To address this, we draw inspiration from off-policy RL, and speculative decoding to introduce a novel ReFT framework, dubbed Nested-ReFT, where a subset of layers of the target model acts as the behavior model to generate off-policy completions during training. The behavior model configured with dynamic layer skipping per batch during training decreases the inference cost compared to the standard ReFT frameworks. Our theoretical analysis shows that Nested-ReFT yields unbiased gradient estimates with controlled variance. Our empirical analysis demonstrates improved computational efficiency measured as tokens/sec across multiple math reasoning benchmarks and model sizes. Additionally, we explore three variants of bias mitigation to minimize the off-policyness in the gradient updates that allows for maintaining performance that matches the baseline ReFT performance.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Nested-ReFTï¼Œä¸€ç§æ—¨åœ¨æé«˜å¤§è¯­è¨€æ¨¡å‹ (LLMs) å¼ºåŒ–å¾®è°ƒ (ReFT) æ•ˆç‡çš„æ–°å‹æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³æ ‡å‡† ReFT åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å› å¤šæ¬¡æ¨ç†ç”Ÿæˆå›ç­”è€Œäº§ç”Ÿçš„å·¨å¤§è®¡ç®—æˆæœ¬ã€‚é€šè¿‡å€Ÿé‰´ç¦»ç­– (off-policy) å¼ºåŒ–å­¦ä¹ ä¸æŠ•æœºé‡‡æ · (speculative decoding) çš„æ€æƒ³ï¼ŒNested-ReFT å°†ç›®æ ‡æ¨¡å‹çš„å­å±‚é…ç½®ä¸ºè¡Œä¸ºæ¨¡å‹ï¼Œå¹¶åœ¨è®­ç»ƒæ—¶é€šè¿‡åŠ¨æ€è·³å±‚ (dynamic layer skipping) ç­–ç•¥ç”Ÿæˆè¡¥å…¨å†…å®¹ã€‚ç†è®ºåˆ†æè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿäº§ç”Ÿå…·æœ‰å—æ§æ–¹å·®çš„æ— åæ¢¯åº¦ä¼°è®¡ï¼Œç¡®ä¿äº†è®­ç»ƒçš„ç¨³å®šæ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒNested-ReFT åœ¨å¤šä¸ªæ•°å­¦æ¨ç†åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æå‡äº† tokens/sec å½¢å¼çš„è®¡ç®—æ•ˆç‡ã€‚åŒæ—¶ï¼Œç ”ç©¶é€šè¿‡ä¸‰ç§åç½®ç¼“è§£ (bias mitigation) å˜ä½“æœ‰æ•ˆé™ä½äº†æ¢¯åº¦æ›´æ–°çš„ç¦»ç­–æ€§ï¼Œä½¿å…¶åœ¨ä¿æŒé«˜æ€§èƒ½çš„åŒæ—¶è¾¾åˆ°äº†ä¸åŸºå‡† ReFT ç›¸å½“çš„æ°´å¹³ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.10123v2",
      "published_date": "2025-08-13 18:37:46 UTC",
      "updated_date": "2025-11-22 22:20:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:31:41.191321+00:00"
    },
    {
      "arxiv_id": "2508.10115v1",
      "title": "Less is More: Learning Graph Tasks with Just LLMs",
      "title_zh": "å°‘å³æ˜¯å¤šï¼šä»…å‡­å¤§è¯­è¨€æ¨¡å‹å®ç°å›¾ä»»åŠ¡å­¦ä¹ ",
      "authors": [
        "Sola Shirai",
        "Kavitha Srinivas",
        "Julian Dolby",
        "Michael Katz",
        "Horst Samulowitz",
        "Shirin Sohrabi"
      ],
      "abstract": "For large language models (LLMs), reasoning over graphs could help solve many problems. Prior work has tried to improve LLM graph reasoning by examining how best to serialize graphs as text and by combining GNNs and LLMs. However, the merits of such approaches remain unclear, so we empirically answer the following research questions: (1) Can LLMs learn to solve fundamental graph tasks without specialized graph encoding models?, (2) Can LLMs generalize learned solutions to unseen graph structures or tasks?, and (3) What are the merits of competing approaches to learn graph tasks? We show that even small LLMs can learn to solve graph tasks by training them with instructive chain-of-thought solutions, and this training generalizes, without specialized graph encoders, to new tasks and graph structures.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¤„ç†å›¾æ¨ç†(Graph Reasoning)ä»»åŠ¡æ—¶çš„æ½œåŠ›ï¼Œé‡ç‚¹åˆ†æäº†æ¨¡å‹æ˜¯å¦å¯ä»¥åœ¨è„±ç¦»ä¸“é—¨å›¾ç¼–ç æ¨¡å‹(Specialized Graph Encoding Models)çš„æƒ…å†µä¸‹å®Œæˆä»»åŠ¡ã€‚ä½œè€…é€šè¿‡å®è¯ç ”ç©¶å›ç­”äº† LLMs æ˜¯å¦èƒ½è§£å†³åŸºç¡€å›¾ä»»åŠ¡ï¼Œä»¥åŠå…¶åœ¨æœªè§è¿‡çš„å›¾ç»“æ„æˆ–ä»»åŠ¡ä¸­çš„æ³›åŒ–èƒ½åŠ›ã€‚ç ”ç©¶å‘ç°ï¼Œé€šè¿‡ä½¿ç”¨å…·æœ‰æŒ‡ä»¤æ€§çš„é“¾å¼æ€ç»´(Chain-of-Thought)è§£å†³æ–¹æ¡ˆè¿›è¡Œè®­ç»ƒï¼Œå³ä½¿æ˜¯è§„æ¨¡è¾ƒå°çš„ LLMs ä¹Ÿèƒ½å­¦ä¼šè§£å†³å¤æ‚çš„å›¾ä»»åŠ¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¿™ç§è®­ç»ƒæ–¹æ³•åœ¨ä¸éœ€è¦å›¾ç¥ç»ç½‘ç»œ(GNNs)æˆ–ä¸“é—¨ç¼–ç å™¨è¾…åŠ©çš„æƒ…å†µä¸‹ï¼Œèƒ½å¤ŸæˆåŠŸæ³›åŒ–åˆ°å…¨æ–°çš„ä»»åŠ¡å’Œå›¾ç»“æ„ã€‚è¿™é¡¹å·¥ä½œè¯æ˜äº†åœ¨å›¾å­¦ä¹ é¢†åŸŸï¼Œå•çº¯åˆ©ç”¨ LLMs ç»“åˆä¼˜åŒ–çš„æ¨ç†ç­–ç•¥å³å¯å®ç°å¼ºå¤§çš„æ€§èƒ½ä¸é€šç”¨æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.10115v1",
      "published_date": "2025-08-13 18:21:05 UTC",
      "updated_date": "2025-08-13 18:21:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:31:39.390391+00:00"
    },
    {
      "arxiv_id": "2508.11704v1",
      "title": "Next-Gen Education: Enhancing AI for Microlearning",
      "title_zh": "ä¸‹ä¸€ä»£æ•™è‚²ï¼šå¼ºåŒ–é¢å‘å¾®å­¦ä¹ çš„äººå·¥æ™ºèƒ½",
      "authors": [
        "Suman Saha",
        "Fatemeh Rahbari",
        "Farhan Sadique",
        "Sri Krishna Chaitanya Velamakanni",
        "Mahfuza Farooque",
        "William J. Rothwell"
      ],
      "abstract": "This paper explores integrating microlearning strategies into university curricula, particularly in computer science education, to counteract the decline in class attendance and engagement in US universities after COVID. As students increasingly opt for remote learning and recorded lectures, traditional educational approaches struggle to maintain engagement and effectiveness. Microlearning, which breaks complex subjects into manageable units, is proposed to address shorter attention spans and enhance educational outcomes. It uses interactive formats such as videos, quizzes, flashcards, and scenario-based exercises, which are especially beneficial for topics like algorithms and programming logic requiring deep understanding and ongoing practice. Adoption of microlearning is often limited by the effort needed to create such materials. This paper proposes leveraging AI tools, specifically ChatGPT, to reduce the workload for educators by automating the creation of supplementary materials. While AI can automate certain tasks, educators remain essential in guiding and shaping the learning process. This AI-enhanced approach ensures course content is kept current with the latest research and technology, with educators providing context and insights. By examining AI capabilities in microlearning, this study shows the potential to transform educational practices and outcomes in computer science, offering a practical model for combining advanced technology with established teaching methods.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨æ–°å† ç–«æƒ…åç¾å›½å¤§å­¦å‡ºå‹¤ç‡å’Œå‚ä¸åº¦ä¸‹é™çš„èƒŒæ™¯ä¸‹ï¼Œå°† microlearning ç­–ç•¥æ•´åˆåˆ°è®¡ç®—æœºç§‘å­¦ç­‰å¤§å­¦è¯¾ç¨‹ä¸­çš„å¿…è¦æ€§ã€‚microlearning é€šè¿‡å°†å¤æ‚ä¸»é¢˜åˆ†è§£ä¸ºæ˜“äºç®¡ç†çš„å°å•å…ƒï¼Œåˆ©ç”¨è§†é¢‘ã€æµ‹éªŒã€flashcards å’Œæƒ…æ™¯åŒ–ç»ƒä¹ ç­‰äº¤äº’å¼æ ¼å¼ï¼Œåº”å¯¹å­¦ç”Ÿæ³¨æ„åŠ›ç¼©çŸ­å¹¶å¢å¼ºæ•™å­¦æ•ˆæœã€‚é’ˆå¯¹åˆ›å»ºæ•™å­¦ææ–™å·¥ä½œé‡å·¨å¤§çš„æŒ‘æˆ˜ï¼Œè®ºæ–‡å»ºè®®åˆ©ç”¨ AI å·¥å…·ï¼ˆç‰¹åˆ«æ˜¯ ChatGPTï¼‰è‡ªåŠ¨åŒ–ç”Ÿæˆè¡¥å……ææ–™ï¼Œä»¥æ˜¾è‘—å‡è½»æ•™å¸ˆè´Ÿæ‹…ã€‚è¿™ç§ AI å¢å¼ºçš„æ–¹æ³•ç¡®ä¿äº†è¯¾ç¨‹å†…å®¹èƒ½ç´§è·Ÿæœ€æ–°ç ”ç©¶ä¸æŠ€æœ¯ï¼ŒåŒæ—¶ä¿ç•™æ•™è‚²è€…åœ¨å¼•å¯¼å­¦ä¹ è¿‡ç¨‹å’Œæä¾› context æ–¹é¢çš„æ ¸å¿ƒä½œç”¨ã€‚é€šè¿‡è€ƒå¯Ÿ AI åœ¨ microlearning ä¸­çš„æ½œåŠ›ï¼Œè¯¥ç ”ç©¶ä¸ºè®¡ç®—æœºç§‘å­¦æ•™è‚²çš„å®è·µè½¬å‹æä¾›äº†å¯èƒ½ã€‚æœ€åï¼Œæœ¬æ–‡å»ºç«‹äº†ä¸€ä¸ªå°†å…ˆè¿›æŠ€æœ¯ä¸ä¼ ç»Ÿæ•™å­¦æ–¹æ³•ç›¸ç»“åˆçš„å®ç”¨æ¨¡å‹ï¼Œæ—¨åœ¨ä¼˜åŒ–æ•™è‚²äº§å‡ºã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.ET",
        "cs.HC",
        "cs.MM"
      ],
      "primary_category": "cs.CY",
      "comment": "Published and presented in 2025 ASEE Annual Conference and Exposition, 22 pages, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.11704v1",
      "published_date": "2025-08-13 18:20:36 UTC",
      "updated_date": "2025-08-13 18:20:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:31:48.083669+00:00"
    },
    {
      "arxiv_id": "2508.10110v1",
      "title": "Empowering Morphing Attack Detection using Interpretable Image-Text Foundation Model",
      "title_zh": "åˆ©ç”¨å¯è§£é‡Šå›¾æ–‡åŸºç¡€æ¨¡å‹èµ‹èƒ½äººè„¸èåˆæ”»å‡»æ£€æµ‹",
      "authors": [
        "Sushrut Patwardhan",
        "Raghavendra Ramachandra",
        "Sushma Venkatesh"
      ],
      "abstract": "Morphing attack detection has become an essential component of face recognition systems for ensuring a reliable verification scenario. In this paper, we present a multimodal learning approach that can provide a textual description of morphing attack detection. We first show that zero-shot evaluation of the proposed framework using Contrastive Language-Image Pretraining (CLIP) can yield not only generalizable morphing attack detection, but also predict the most relevant text snippet. We present an extensive analysis of ten different textual prompts that include both short and long textual prompts. These prompts are engineered by considering the human understandable textual snippet. Extensive experiments were performed on a face morphing dataset that was developed using a publicly available face biometric dataset. We present an evaluation of SOTA pre-trained neural networks together with the proposed framework in the zero-shot evaluation of five different morphing generation techniques that are captured in three different mediums.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºå¯è§£é‡Šå›¾åƒ-æ–‡æœ¬åŸºç¡€æ¨¡å‹çš„å¤šæ¨¡æ€å­¦ä¹ æ–¹æ³•ï¼Œæ—¨åœ¨å¢å¼ºäººè„¸è¯†åˆ«ç³»ç»Ÿä¸­çš„å½¢æ€æ”»å‡»æ£€æµ‹ï¼ˆMorphing Attack Detectionï¼‰ã€‚é€šè¿‡åˆ©ç”¨å¯¹æ¯”è¯­è¨€-å›¾åƒé¢„è®­ç»ƒï¼ˆContrastive Language-Image Pretraining, CLIPï¼‰è¿›è¡Œé›¶æ ·æœ¬ï¼ˆZero-shotï¼‰è¯„ä¼°ï¼Œè¯¥æ¡†æ¶ä¸ä»…å®ç°äº†å…·å¤‡æ³›åŒ–èƒ½åŠ›çš„æ”»å‡»æ£€æµ‹ï¼Œè¿˜èƒ½é¢„æµ‹å¹¶æä¾›ç›¸å…³çš„æ–‡æœ¬æè¿°ã€‚ç ”ç©¶æ·±å…¥åˆ†æäº†åç§é’ˆå¯¹äººç±»å¯ç†è§£æ–‡æœ¬ç‰‡æ®µè®¾è®¡çš„ä¸åŒæç¤ºè¯ï¼ˆPromptsï¼‰ï¼Œæ¶µç›–äº†é•¿çŸ­ä¸åŒçš„æ–‡æœ¬æè¿°ã€‚å®éªŒåœ¨åŒ…å«äº”ç§å½¢æ€ç”ŸæˆæŠ€æœ¯å’Œä¸‰ç§é‡‡é›†ä»‹è´¨çš„è„¸éƒ¨å½¢æ€æ•°æ®é›†ä¸Šå±•å¼€ï¼Œå¹¶ä¸å¤šç§å…ˆè¿›ï¼ˆSOTAï¼‰é¢„è®­ç»ƒç¥ç»ç½‘ç»œè¿›è¡Œäº†å¯¹æ¯”ã€‚ç»“æœè¯æ˜è¯¥æ–¹æ³•åœ¨æä¾›å¯è§£é‡Šæ€§çš„åŒæ—¶ï¼Œæœ‰æ•ˆæå‡äº†åœ¨å¤šæ ·åŒ–ç”Ÿæˆç¯å¢ƒä¸‹çš„æ£€æµ‹æ€§èƒ½ï¼Œä¸ºæ„å»ºå¯é çš„äººè„¸éªŒè¯åœºæ™¯æä¾›äº†æ–°æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.10110v1",
      "published_date": "2025-08-13 18:06:29 UTC",
      "updated_date": "2025-08-13 18:06:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:31:47.190233+00:00"
    },
    {
      "arxiv_id": "2508.10108v1",
      "title": "Amazon Nova AI Challenge -- Trusted AI: Advancing secure, AI-assisted software development",
      "title_zh": "Amazon Nova AI Challenge â€”â€” å¯ä¿¡äººå·¥æ™ºèƒ½ï¼šæ¨åŠ¨å®‰å…¨çš„äººå·¥æ™ºèƒ½è¾…åŠ©è½¯ä»¶å¼€å‘",
      "authors": [
        "Sattvik Sahai",
        "Prasoon Goyal",
        "Michael Johnston",
        "Anna Gottardi",
        "Yao Lu",
        "Lucy Hu",
        "Luke Dai",
        "Shaohua Liu",
        "Samyuth Sagi",
        "Hangjie Shi",
        "Desheng Zhang",
        "Lavina Vaz",
        "Leslie Ball",
        "Maureen Murray",
        "Rahul Gupta",
        "Shankar Ananthakrishna"
      ],
      "abstract": "AI systems for software development are rapidly gaining prominence, yet significant challenges remain in ensuring their safety. To address this, Amazon launched the Trusted AI track of the Amazon Nova AI Challenge, a global competition among 10 university teams to drive advances in secure AI. In the challenge, five teams focus on developing automated red teaming bots, while the other five create safe AI assistants. This challenge provides teams with a unique platform to evaluate automated red-teaming and safety alignment methods through head-to-head adversarial tournaments where red teams have multi-turn conversations with the competing AI coding assistants to test their safety alignment. Along with this, the challenge provides teams with a feed of high quality annotated data to fuel iterative improvement. Throughout the challenge, teams developed state-of-the-art techniques, introducing novel approaches in reasoning-based safety alignment, robust model guardrails, multi-turn jail-breaking, and efficient probing of large language models (LLMs). To support these efforts, the Amazon Nova AI Challenge team made substantial scientific and engineering investments, including building a custom baseline coding specialist model for the challenge from scratch, developing a tournament orchestration service, and creating an evaluation harness. This paper outlines the advancements made by university teams and the Amazon Nova AI Challenge team in addressing the safety challenges of AI for software development, highlighting this collaborative effort to raise the bar for AI safety.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¦‚è¿°äº†Amazon Nova AI Challengeä¸­çš„å¯ä¿¡AI(Trusted AI)èµ›é“ï¼Œæ—¨åœ¨é€šè¿‡å…¨çƒå¤§å­¦ç«èµ›æ¨åŠ¨å®‰å…¨ã€AIè¾…åŠ©è½¯ä»¶å¼€å‘é¢†åŸŸçš„è¿›å±•ã€‚æŒ‘æˆ˜èµ›æ±‡é›†äº†10æ”¯å¤§å­¦å›¢é˜Ÿï¼Œåˆ†åˆ«ä¸“æ³¨äºå¼€å‘è‡ªåŠ¨åŒ–çº¢é˜Ÿæœºå™¨äºº(red teaming bots)å’Œå®‰å…¨AIåŠ©æ‰‹(safe AI assistants)ï¼Œå¹¶åœ¨å¤šè½®å¯¹è¯çš„å¯¹æŠ—æ€§é”¦æ ‡èµ›(adversarial tournaments)ä¸­å¯¹å®‰å…¨å¯¹é½(safety alignment)æ–¹æ³•è¿›è¡Œå®æˆ˜è¯„ä¼°ã€‚ä¾æ‰˜é«˜è´¨é‡æ ‡æ³¨æ•°æ®çš„æŒç»­è¿­ä»£ï¼Œå‚èµ›å›¢é˜Ÿå¼€å‘äº†åŸºäºæ¨ç†çš„å®‰å…¨å¯¹é½(reasoning-based safety alignment)ã€é²æ£’æ¨¡å‹æŠ¤æ (robust model guardrails)ä»¥åŠé’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)çš„å¤šè½®ç ´è§£(multi-turn jail-breaking)ç­‰å‰æ²¿æŠ€æœ¯ã€‚åŒæ—¶ï¼Œç ”ç©¶å›¢é˜Ÿè¿˜é…å¥—å¼€å‘äº†å®šåˆ¶åŒ–çš„ä»£ç ä¸“å®¶åŸºå‡†æ¨¡å‹ã€é”¦æ ‡èµ›ç¼–æ’æœåŠ¡åŠè¯„ä¼°æ¡†æ¶(evaluation harness)ç­‰åŸºç¡€è®¾æ–½ã€‚è¿™ä¸€åä½œåŠªåŠ›å±•ç¤ºäº†åœ¨åº”å¯¹AIè½¯ä»¶å¼€å‘å®‰å…¨æŒ‘æˆ˜æ–¹é¢çš„æ˜¾è‘—ç§‘ç ”ä¸å·¥ç¨‹çªç ´ï¼Œä¸ºæå‡å·¥ä¸šç•ŒAIå®‰å…¨æ€§ç¡®ç«‹äº†æ›´é«˜æ ‡å‡†ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages, 1st Proceedings of Amazon Nova AI Challenge (Trusted AI 2025)",
      "pdf_url": "https://arxiv.org/pdf/2508.10108v1",
      "published_date": "2025-08-13 18:04:01 UTC",
      "updated_date": "2025-08-13 18:04:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:31:53.984084+00:00"
    },
    {
      "arxiv_id": "2508.09987v1",
      "title": "Echo-4o: Harnessing the Power of GPT-4o Synthetic Images for Improved Image Generation",
      "title_zh": "Echo-4oï¼šåˆ©ç”¨ GPT-4o åˆæˆå›¾åƒæå‡å›¾åƒç”Ÿæˆæ€§èƒ½",
      "authors": [
        "Junyan Ye",
        "Dongzhi Jiang",
        "Zihao Wang",
        "Leqi Zhu",
        "Zhenghao Hu",
        "Zilong Huang",
        "Jun He",
        "Zhiyuan Yan",
        "Jinghua Yu",
        "Hongsheng Li",
        "Conghui He",
        "Weijia Li"
      ],
      "abstract": "Recently, GPT-4o has garnered significant attention for its strong performance in image generation, yet open-source models still lag behind. Several studies have explored distilling image data from GPT-4o to enhance open-source models, achieving notable progress. However, a key question remains: given that real-world image datasets already constitute a natural source of high-quality data, why should we use GPT-4o-generated synthetic data? In this work, we identify two key advantages of synthetic images. First, they can complement rare scenarios in real-world datasets, such as surreal fantasy or multi-reference image generation, which frequently occur in user queries. Second, they provide clean and controllable supervision. Real-world data often contains complex background noise and inherent misalignment between text descriptions and image content, whereas synthetic images offer pure backgrounds and long-tailed supervision signals, facilitating more accurate text-to-image alignment. Building on these insights, we introduce Echo-4o-Image, a 180K-scale synthetic dataset generated by GPT-4o, harnessing the power of synthetic image data to address blind spots in real-world coverage. Using this dataset, we fine-tune the unified multimodal generation baseline Bagel to obtain Echo-4o. In addition, we propose two new evaluation benchmarks for a more accurate and challenging assessment of image generation capabilities: GenEval++, which increases instruction complexity to mitigate score saturation, and Imagine-Bench, which focuses on evaluating both the understanding and generation of imaginative content. Echo-4o demonstrates strong performance across standard benchmarks. Moreover, applying Echo-4o-Image to other foundation models (e.g., OmniGen2, BLIP3-o) yields consistent performance gains across multiple metrics, highlighting the datasets strong transferability.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨å›¾åƒç”Ÿæˆä»»åŠ¡ä¸­åˆ©ç”¨ GPT-4o åˆæˆæ•°æ®æå‡å¼€æºæ¨¡å‹æ€§èƒ½çš„æ–¹æ³•ï¼Œå¹¶åˆ†æäº†åˆæˆå›¾åƒåœ¨å¼¥è¡¥ç½•è§åœºæ™¯ç¼ºå¤±åŠæä¾›çº¯å‡€ç›‘ç£ä¿¡å·æ–¹é¢çš„ç‹¬ç‰¹ä¼˜åŠ¿ã€‚ä½œè€…æŒ‡å‡ºï¼Œåˆæˆæ•°æ®èƒ½æœ‰æ•ˆè§£å†³çœŸå®ä¸–ç•Œæ•°æ®é›†ä¸­èƒŒæ™¯å™ªå£°å¤æ‚åŠ text-to-image alignment åå·®ç­‰é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯åœ¨è¶…ç°å®å¹»æƒ³å’Œå¤šå‚è€ƒç”Ÿæˆåœºæ™¯ä¸‹è¡¨ç°æ›´ä½³ã€‚åŸºäºæ­¤è§è§£ï¼Œç ”ç©¶å›¢é˜Ÿæ„å»ºäº†åŒ…å« 180K å¼ åˆæˆå›¾åƒçš„ Echo-4o-Image æ•°æ®é›†ï¼Œå¹¶é€šè¿‡å¾®è°ƒå¤šæ¨¡æ€åŸºå‡†æ¨¡å‹ Bagel å¾—åˆ°äº† Echo-4o æ¨¡å‹ã€‚åŒæ—¶ï¼Œè®ºæ–‡æå‡ºäº† GenEval++ å’Œ Imagine-Bench ä¸¤ä¸ªæ›´å…·æŒ‘æˆ˜æ€§çš„è¯„ä¼°åŸºå‡†ï¼Œç”¨ä»¥è¡¡é‡æ¨¡å‹å¯¹å¤æ‚æŒ‡ä»¤çš„æ‰§è¡ŒåŠ›åŠå¯¹æƒ³è±¡åŠ›å†…å®¹çš„ç”Ÿæˆè´¨é‡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒEcho-4o åœ¨ä¸»æµè¯„æµ‹ä¸­å‡å–å¾—æ˜¾è‘—æå‡ï¼Œä¸” Echo-4o-Image æ•°æ®é›†åœ¨ OmniGen2 å’Œ BLIP3-o ç­‰å…¶ä»–åŸºç¡€æ¨¡å‹ä¸Šä¹Ÿå±•ç°å‡ºæå¼ºçš„é€šç”¨æ€§å’Œæ€§èƒ½å¢ç›Šã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "19 pages, 8 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.09987v1",
      "published_date": "2025-08-13 17:59:28 UTC",
      "updated_date": "2025-08-13 17:59:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:32:11.399827+00:00"
    },
    {
      "arxiv_id": "2508.10948v1",
      "title": "Apriel-Nemotron-15B-Thinker",
      "title_zh": "Apriel-Nemotron-15B-Thinker",
      "authors": [
        "Shruthan Radhakrishna",
        "Soham Parikh",
        "Gopal Sarda",
        "Anil Turkkan",
        "Quaizar Vohra",
        "Raymond Li",
        "Dhruv Jhamb",
        "Kelechi Ogueji",
        "Aanjaneya Shukla",
        "Oluwanifemi Bamgbose",
        "Toby Liang",
        "Luke Kumar",
        "Oleksiy Ostapenko",
        "Shiva Krishna Reddy Malay",
        "Aman Tiwari",
        "Tara Bogavelli",
        "Vikas Yadav",
        "Jash Mehta",
        "Saloni Mittal",
        "Akshay Kalkunte",
        "Pulkit Pattnaik",
        "Khalil Slimi",
        "Anirudh Sreeram",
        "Jishnu Nair",
        "Akintunde Oladipo",
        "Shashank Maiya",
        "Khyati Mahajan",
        "Rishabh Maheshwary",
        "Masoud Hashemi",
        "Sai Rajeswar Mudumba",
        "Sathwik Tejaswi Madhusudhan",
        "Torsten Scholak",
        "Sebastien Paquet",
        "Sagar Davasam",
        "Srinivas Sunkara"
      ],
      "abstract": "While large language models (LLMs) have achieved remarkable reasoning capabilities across domains like code, math and other enterprise tasks, their significant memory and computational costs often preclude their use in practical enterprise settings. To this end, we introduce Apriel-Nemotron-15B-Thinker, a 15-billion parameter model in the ServiceNow Apriel SLM series that achieves performance against medium sized state-of-the-art models such as o1-mini, QWQ32B, and EXAONE-Deep-32B while maintaining only half the memory footprint of those alternatives. Apriel-Nemotron-15B-Thinker model is trained in a four stage training pipeline including 1) Base Model upscaling, 2) Continual Pre-training 3) Supervised Fine-tuning (SFT) and 4) Reinforcement Learning using GRPO. Comprehensive evaluations across a diverse suite of benchmarks consistently demonstrate that our Apriel-Nemotron-15B-Thinker model matches or exceeds the performance of its 32-billion parameter counterparts, despite being less than half their size.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº†Apriel-Nemotron-15B-Thinkerï¼Œè¿™æ˜¯ServiceNow Apriel SLMç³»åˆ—ä¸­ä¸€ä¸ªæ‹¥æœ‰150äº¿å‚æ•°çš„æ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨ä¼ä¸šåº”ç”¨ä¸­é¢ä¸´çš„é«˜å†…å­˜å’Œè®¡ç®—æˆæœ¬é—®é¢˜ã€‚è¯¥æ¨¡å‹é‡‡ç”¨å››é˜¶æ®µè®­ç»ƒæµæ°´çº¿ï¼ŒåŒ…æ‹¬åŸºç¡€æ¨¡å‹upscalingã€æŒç»­é¢„è®­ç»ƒ(Continual Pre-training)ã€æœ‰ç›‘ç£å¾®è°ƒ(SFT)ä»¥åŠä½¿ç”¨GRPOè¿›è¡Œçš„å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒApriel-Nemotron-15B-Thinkeråœ¨å¤šé¡¹åŸºå‡†æµ‹è¯•ä¸­çš„è¡¨ç°ä¸o1-miniã€QWQ32Bå’ŒEXAONE-Deep-32Bç­‰320äº¿å‚æ•°è§„æ¨¡çš„å…ˆè¿›æ¨¡å‹æŒå¹³ç”šè‡³æ›´ä¼˜ã€‚å°½ç®¡å…¶å‚æ•°é‡ä¸è¶³ç«äº‰å¯¹æ‰‹çš„ä¸€åŠï¼Œå´æˆåŠŸå°†å†…å­˜å ç”¨é™ä½äº†50%ï¼Œæ˜¾è‘—æå‡äº†åœ¨ç¼–ç ã€æ•°å­¦åŠä¼ä¸šä»»åŠ¡ä¸­çš„æ¨ç†æ•ˆç‡ã€‚è¯¥ç ”ç©¶è¯æ˜äº†é€šè¿‡ä¼˜åŒ–çš„è®­ç»ƒç­–ç•¥ï¼Œè¾ƒå°è§„æ¨¡çš„æ¨¡å‹ä¹Ÿèƒ½åœ¨ä¿æŒé«˜æ€§èƒ½çš„åŒæ—¶ï¼Œæœ‰æ•ˆé™ä½å®é™…è½åœ°ä¸­çš„èµ„æºé—¨æ§›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.10948v1",
      "published_date": "2025-08-13 17:43:43 UTC",
      "updated_date": "2025-08-13 17:43:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:32:30.841082+00:00"
    },
    {
      "arxiv_id": "2508.09971v2",
      "title": "Vision-driven River Following of UAV via Safe Reinforcement Learning using Semantic Dynamics Model",
      "title_zh": "åŸºäºè¯­ä¹‰åŠ¨åŠ›å­¦æ¨¡å‹ä¸å®‰å…¨å¼ºåŒ–å­¦ä¹ çš„è§†è§‰é©±åŠ¨æ— äººæœºæ²¿æ²³è‡ªä¸»é£è¡Œ",
      "authors": [
        "Zihan Wang",
        "Nina Mahmoudian"
      ],
      "abstract": "Vision-driven autonomous river following by Unmanned Aerial Vehicles is critical for applications such as rescue, surveillance, and environmental monitoring, particularly in dense riverine environments where GPS signals are unreliable. These safety-critical navigation tasks must satisfy hard safety constraints while optimizing performance. Moreover, the reward in river following is inherently history-dependent (non-Markovian) by which river segment has already been visited, making it challenging for standard safe Reinforcement Learning (SafeRL). To address these gaps, we propose three contributions. First, we introduce Marginal Gain Advantage Estimation, which refines the reward advantage function by using a sliding window baseline computed from historical episodic returns, aligning the advantage estimate with non-Markovian dynamics. Second, we develop a Semantic Dynamics Model based on patchified water semantic masks offering more interpretable and data-efficient short-term prediction of future observations compared to latent vision dynamics models. Third, we present the Constrained Actor Dynamics Estimator architecture, which integrates the actor, cost estimator, and SDM for cost advantage estimation to form a model-based SafeRL framework. Simulation results demonstrate that MGAE achieves faster convergence and superior performance over traditional critic-based methods like Generalized Advantage Estimation. SDM provides more accurate short-term state predictions that enable the cost estimator to better predict potential violations. Overall, CADE effectively integrates safety regulation into model-based RL, with the Lagrangian approach providing a \"soft\" balance between reward and safety during training, while the safety layer enhances inference by imposing a \"hard\" action overlay.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ— äººæœº(UAV)åœ¨å¯†é›†æ²³æµç¯å¢ƒä¸­çš„è§†è§‰é©±åŠ¨è‡ªä¸»æ²³æµè¿½è¸ªä»»åŠ¡ï¼Œæå‡ºäº†ä¸€ç§ç»“åˆå®‰å…¨å¼ºåŒ–å­¦ä¹ (SafeRL)ä¸è¯­ä¹‰åŠ¨åŠ›å­¦æ¨¡å‹(Semantic Dynamics Model)çš„å¯¼èˆªæ¡†æ¶ã€‚ä¸ºäº†è§£å†³æ²³æµè¿½è¸ªä»»åŠ¡ä¸­å¥–åŠ±å‡½æ•°çš„å†å²ä¾èµ–æ€§(non-Markovian)é—®é¢˜ï¼Œç ”ç©¶å¼•å…¥äº†è¾¹é™…å¢ç›Šä¼˜åŠ¿ä¼°è®¡(Marginal Gain Advantage Estimation, MGAE)ï¼Œåˆ©ç”¨æ»‘åŠ¨çª—å£åŸºçº¿æé«˜ä¼˜åŠ¿ä¼°è®¡çš„å‡†ç¡®æ€§ã€‚åŒæ—¶ï¼Œç ”ç©¶å¼€å‘çš„è¯­ä¹‰åŠ¨åŠ›å­¦æ¨¡å‹(SDM)é€šè¿‡åˆ†å—çš„æ°´ä½“è¯­ä¹‰æ©ç å®ç°äº†é«˜æ•ˆä¸”å…·å¯è§£é‡Šæ€§çš„çŸ­æœŸçŠ¶æ€é¢„æµ‹ã€‚é€šè¿‡é›†æˆæ‰§è¡Œå™¨ä¸æˆæœ¬ä¼°è®¡å™¨çš„çº¦æŸæ‰§è¡Œå™¨åŠ¨åŠ›å­¦ä¼°è®¡å™¨(Constrained Actor Dynamics Estimator, CADE)æ¶æ„ï¼Œè¯¥ç³»ç»Ÿåœ¨æ¨¡å‹åŸºå¼ºåŒ–å­¦ä¹ ä¸­å®ç°äº†å®‰å…¨æ€§ä¸æ€§èƒ½çš„æœ‰æ•ˆå¹³è¡¡ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒMGAEåœ¨æ”¶æ•›é€Ÿåº¦å’Œæ€§èƒ½ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œè€ŒSDMçš„é¢„æµ‹èƒ½åŠ›æœ‰æ•ˆé™ä½äº†å®‰å…¨è¿è§„é£é™©ã€‚è¯¥ç ”ç©¶é€šè¿‡æ‹‰æ ¼æœ—æ—¥æ–¹æ³•ä¸æ¨ç†å±‚å®‰å…¨è¦†ç›–çš„ç»“åˆï¼Œä¸ºå¤æ‚ç¯å¢ƒä¸‹çš„æ— äººæœºå®‰å…¨å¯¼èˆªæä¾›äº†å¯é çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Submitted to Robotics and Autonomous Systems (RAS) journal",
      "pdf_url": "https://arxiv.org/pdf/2508.09971v2",
      "published_date": "2025-08-13 17:39:09 UTC",
      "updated_date": "2025-09-30 20:19:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:32:37.572604+00:00"
    },
    {
      "arxiv_id": "2508.09966v1",
      "title": "January Food Benchmark (JFB): A Public Benchmark Dataset and Evaluation Suite for Multimodal Food Analysis",
      "title_zh": "January Food Benchmark (JFB)ï¼šç”¨äºå¤šæ¨¡æ€é£Ÿç‰©åˆ†æçš„å…¬å¼€åŸºå‡†æ•°æ®é›†ä¸è¯„ä¼°å¥—ä»¶",
      "authors": [
        "Amir Hosseinian",
        "Ashkan Dehghani Zahedani",
        "Umer Mansoor",
        "Noosheen Hashemi",
        "Mark Woodward"
      ],
      "abstract": "Progress in AI for automated nutritional analysis is critically hampered by the lack of standardized evaluation methodologies and high-quality, real-world benchmark datasets. To address this, we introduce three primary contributions. First, we present the January Food Benchmark (JFB), a publicly available collection of 1,000 food images with human-validated annotations. Second, we detail a comprehensive benchmarking framework, including robust metrics and a novel, application-oriented overall score designed to assess model performance holistically. Third, we provide baseline results from both general-purpose Vision-Language Models (VLMs) and our own specialized model, january/food-vision-v1. Our evaluation demonstrates that the specialized model achieves an Overall Score of 86.2, a 12.1-point improvement over the best-performing general-purpose configuration. This work offers the research community a valuable new evaluation dataset and a rigorous framework to guide and benchmark future developments in automated nutritional analysis.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è‡ªåŠ¨è¥å…»åˆ†æé¢†åŸŸç¼ºä¹æ ‡å‡†åŒ–è¯„ä¼°æ–¹æ³•å’Œé«˜è´¨é‡æ•°æ®é›†çš„é—®é¢˜ï¼Œæå‡ºäº†January Food Benchmark (JFB)ï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å«1,000å¼ ç»è¿‡äººå·¥éªŒè¯æ ‡æ³¨çš„é£Ÿç‰©å›¾åƒçš„å…¬å¼€åŸºå‡†æ•°æ®é›†ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜è¯¦ç»†ä»‹ç»äº†ä¸€ä¸ªå…¨é¢çš„åŸºå‡†æµ‹è¯•æ¡†æ¶ï¼ŒåŒ…æ‹¬é²æ£’çš„åº¦é‡æŒ‡æ ‡å’Œä¸€ç§æ–°é¢–çš„ã€é¢å‘åº”ç”¨çš„ç»¼åˆè¯„åˆ†(Overall Score)ï¼Œæ—¨åœ¨ä»æ•´ä½“ä¸Šè¯„ä¼°æ¨¡å‹æ€§èƒ½ã€‚ç ”ç©¶äººå‘˜æä¾›äº†é€šç”¨è§†è§‰è¯­è¨€æ¨¡å‹(VLMs)ä¸ä¸“é—¨æ¨¡å‹january/food-vision-v1çš„åŸºçº¿è¯„ä¼°å¯¹æ¯”ã€‚ç»“æœæ˜¾ç¤ºï¼Œä¸“é—¨æ¨¡å‹è·å¾—äº†86.2çš„ç»¼åˆè¯„åˆ†ï¼Œç›¸æ¯”è¡¨ç°æœ€å¥½çš„é€šç”¨é…ç½®æå‡äº†12.1åˆ†ã€‚è¿™é¡¹å·¥ä½œä¸ºç ”ç©¶ç•Œæä¾›äº†ä¸€ä¸ªæœ‰ä»·å€¼çš„æ–°è¯„ä¼°æ•°æ®é›†å’Œä¸¥è°¨çš„æ¡†æ¶ï¼Œä»¥æŒ‡å¯¼å’Œè§„èŒƒæœªæ¥è‡ªåŠ¨è¥å…»åˆ†æé¢†åŸŸçš„å‘å±•ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09966v1",
      "published_date": "2025-08-13 17:32:40 UTC",
      "updated_date": "2025-08-13 17:32:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:32:34.800468+00:00"
    },
    {
      "arxiv_id": "2508.09960v1",
      "title": "GBC: Generalized Behavior-Cloning Framework for Whole-Body Humanoid Imitation",
      "title_zh": "GBCï¼šé¢å‘äººå½¢æœºå™¨äººå…¨èº«æ¨¡ä»¿çš„é€šç”¨è¡Œä¸ºå…‹éš†æ¡†æ¶",
      "authors": [
        "Yifei Yao",
        "Chengyuan Luo",
        "Jiaheng Du",
        "Wentao He",
        "Jun-Guo Lu"
      ],
      "abstract": "The creation of human-like humanoid robots is hindered by a fundamental fragmentation: data processing and learning algorithms are rarely universal across different robot morphologies. This paper introduces the Generalized Behavior Cloning (GBC) framework, a comprehensive and unified solution designed to solve this end-to-end challenge. GBC establishes a complete pathway from human motion to robot action through three synergistic innovations. First, an adaptive data pipeline leverages a differentiable IK network to automatically retarget any human MoCap data to any humanoid. Building on this foundation, our novel DAgger-MMPPO algorithm with its MMTransformer architecture learns robust, high-fidelity imitation policies. To complete the ecosystem, the entire framework is delivered as an efficient, open-source platform based on Isaac Lab, empowering the community to deploy the full workflow via simple configuration scripts. We validate the power and generality of GBC by training policies on multiple heterogeneous humanoids, demonstrating excellent performance and transfer to novel motions. This work establishes the first practical and unified pathway for creating truly generalized humanoid controllers.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†é€šç”¨è¡Œä¸ºå…‹éš†æ¡†æ¶(Generalized Behavior Cloning, GBC)ï¼Œæ—¨åœ¨è§£å†³äººå½¢æœºå™¨äººé¢†åŸŸä¸­æ•°æ®å¤„ç†ä¸å­¦ä¹ ç®—æ³•åœ¨ä¸åŒæœºå™¨äººå½¢æ€é—´éš¾ä»¥é€šç”¨çš„ç¢ç‰‡åŒ–æŒ‘æˆ˜ã€‚GBCé€šè¿‡ä¸‰å¤§ååŒåˆ›æ–°æ„å»ºäº†ä»äººç±»è¿åŠ¨åˆ°æœºå™¨äººåŠ¨ä½œçš„å®Œæ•´è·¯å¾„ï¼šé¦–å…ˆåˆ©ç”¨å¯å¾®é€†è¿åŠ¨å­¦ç½‘ç»œ(differentiable IK network)å®ç°åŠ¨ä½œæ•æ‰(MoCap)æ•°æ®å‘ä»»æ„äººå½¢æœºå™¨äººçš„è‡ªåŠ¨é‡å®šå‘ï¼›éšåé‡‡ç”¨åŸºäºMMTransformeræ¶æ„çš„DAgger-MMPPOç®—æ³•å­¦ä¹ é²æ£’çš„é«˜ä¿çœŸæ¨¡ä»¿ç­–ç•¥ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶ä½œä¸ºä¸€ä¸ªåŸºäºIsaac Labçš„é«˜æ•ˆå¼€æºå¹³å°æä¾›ï¼Œå…è®¸å¼€å‘è€…é€šè¿‡ç®€å•è„šæœ¬éƒ¨ç½²å…¨å¥—å·¥ä½œæµã€‚å®éªŒé€šè¿‡åœ¨å¤šç§å¼‚æ„äººå½¢æœºå™¨äººä¸Šè®­ç»ƒç­–ç•¥ï¼ŒéªŒè¯äº†GBCåœ¨å¤æ‚è¿åŠ¨è¡¨ç°å’Œæ–°é¢–åŠ¨ä½œè¿ç§»æ–¹é¢çš„å“è¶Šæ³›åŒ–èƒ½åŠ›ã€‚è¯¥å·¥ä½œä¸ºå®ç°çœŸæ­£é€šç”¨çš„å…¨èº«äººå½¢æœºå™¨äººæ§åˆ¶å™¨æä¾›äº†é¦–ä¸ªå®ç”¨ä¸”ç»Ÿä¸€çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09960v1",
      "published_date": "2025-08-13 17:28:39 UTC",
      "updated_date": "2025-08-13 17:28:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:32:41.060112+00:00"
    },
    {
      "arxiv_id": "2508.09952v1",
      "title": "Specialised or Generic? Tokenization Choices for Radiology Language Models",
      "title_zh": "ä¸“ç”¨è¿˜æ˜¯é€šç”¨ï¼Ÿæ”¾å°„å­¦è¯­è¨€æ¨¡å‹çš„åˆ†è¯æ–¹æ¡ˆé€‰æ‹©",
      "authors": [
        "Hermione Warr",
        "Wentian Xu",
        "Harry Anthony",
        "Yasin Ibrahim",
        "Daniel McGowan",
        "Konstantinos Kamnitsas"
      ],
      "abstract": "The vocabulary used by language models (LM) - defined by the tokenizer - plays a key role in text generation quality. However, its impact remains under-explored in radiology. In this work, we address this gap by systematically comparing general, medical, and domain-specific tokenizers on the task of radiology report summarisation across three imaging modalities. We also investigate scenarios with and without LM pre-training on PubMed abstracts. Our findings demonstrate that medical and domain-specific vocabularies outperformed widely used natural language alternatives when models are trained from scratch. Pre-training partially mitigates performance differences between tokenizers, whilst the domain-specific tokenizers achieve the most favourable results. Domain-specific tokenizers also reduce memory requirements due to smaller vocabularies and shorter sequences. These results demonstrate that adapting the vocabulary of LMs to the clinical domain provides practical benefits, including improved performance and reduced computational demands, making such models more accessible and effective for both research and real-world healthcare settings.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åˆ†è¯å™¨(tokenizer)åœ¨æ”¾å°„å­¦è¯­è¨€æ¨¡å‹(Radiology Language Models)ä¸­çš„ä½œç”¨ï¼Œå¡«è¡¥äº†è¯¥é¢†åŸŸç ”ç©¶çš„ç©ºç™½ã€‚ç ”ç©¶è€…é€šè¿‡ç³»ç»Ÿæ¯”è¾ƒé€šç”¨ã€åŒ»å­¦å’Œé¢†åŸŸç‰¹å®šçš„åˆ†è¯å™¨ï¼Œåœ¨ä¸‰ç§æˆåƒæ–¹å¼çš„æ”¾å°„æŠ¥å‘Šæ‘˜è¦(radiology report summarisation)ä»»åŠ¡ä¸­è¯„ä¼°äº†å®ƒä»¬çš„è¡¨ç°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨ä»å¤´è®­ç»ƒæ¨¡å‹æ—¶ï¼ŒåŒ»å­¦å’Œé¢†åŸŸç‰¹å®šçš„è¯æ±‡è¡¨è¡¨ç°ä¼˜äºå¸¸ç”¨çš„è‡ªç„¶è¯­è¨€åˆ†è¯å™¨ã€‚è™½ç„¶é¢„è®­ç»ƒ(Pre-training)èƒ½éƒ¨åˆ†ç¼©å°ä¸åŒåˆ†è¯å™¨ä¹‹é—´çš„æ€§èƒ½å·®è·ï¼Œä½†é¢†åŸŸç‰¹å®šçš„åˆ†è¯å™¨ä¾ç„¶å–å¾—äº†æœ€ä½³æ•ˆæœã€‚æ­¤å¤–ï¼Œé¢†åŸŸç‰¹å®šçš„åˆ†è¯å™¨ç”±äºè¯æ±‡è¡¨æ›´å°ã€åºåˆ—æ›´çŸ­ï¼Œæ˜¾è‘—é™ä½äº†å†…å­˜å’Œè®¡ç®—éœ€æ±‚ã€‚è¿™äº›å‘ç°è¯æ˜ï¼Œå°†è¯­è¨€æ¨¡å‹çš„è¯æ±‡è¡¨é€‚åº”äºä¸´åºŠé¢†åŸŸä¸ä»…èƒ½æå‡æ€§èƒ½ï¼Œè¿˜èƒ½é™ä½ç¡¬ä»¶é—¨æ§›ï¼Œå¢å¼ºæ¨¡å‹åœ¨çœŸå®åŒ»ç–—ç¯å¢ƒä¸­çš„å®ç”¨æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ELAMI@MICCAI2025",
      "pdf_url": "https://arxiv.org/pdf/2508.09952v1",
      "published_date": "2025-08-13 17:13:56 UTC",
      "updated_date": "2025-08-13 17:13:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:32:49.584941+00:00"
    },
    {
      "arxiv_id": "2508.09945v1",
      "title": "VisCodex: Unified Multimodal Code Generation via Merging Vision and Coding Models",
      "title_zh": "VisCodexï¼šé€šè¿‡èåˆè§†è§‰ä¸ä»£ç æ¨¡å‹å®ç°ç»Ÿä¸€å¤šæ¨¡æ€ä»£ç ç”Ÿæˆ",
      "authors": [
        "Lingjie Jiang",
        "Shaohan Huang",
        "Xun Wu",
        "Yixia Li",
        "Dongdong Zhang",
        "Furu Wei"
      ],
      "abstract": "Multimodal large language models (MLLMs) have significantly advanced the integration of visual and textual understanding. However, their ability to generate code from multimodal inputs remains limited. In this work, we introduce VisCodex, a unified framework that seamlessly merges vision and coding language models to empower MLLMs with strong multimodal code generation abilities. Leveraging a task vector-based model merging technique, we integrate a state-of-the-art coding LLM into a strong vision-language backbone, while preserving both visual comprehension and advanced coding skills. To support training and evaluation, we introduce the Multimodal Coding Dataset (MCD), a large-scale and diverse collection of 598k samples, including high-quality HTML code, chart image-code pairs, image-augmented StackOverflow QA, and algorithmic problems. Furthermore, we propose InfiBench-V, a novel and challenging benchmark specifically designed to assess models on visually-rich, real-world programming questions that demand a nuanced understanding of both textual and visual contexts. Extensive experiments show that VisCodex achieves state-of-the-art performance among open-source MLLMs and approaches proprietary models like GPT-4o, highlighting the effectiveness of our model merging strategy and new datasets.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† VisCodexï¼Œè¿™æ˜¯ä¸€ä¸ªé€šè¿‡èåˆè§†è§‰å’Œç¼–ç¨‹æ¨¡å‹çš„ç»Ÿä¸€æ¡†æ¶ï¼Œæ—¨åœ¨å¢å¼ºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨å¤„ç†å¤šæ¨¡æ€è¾“å…¥æ—¶çš„ä»£ç ç”Ÿæˆèƒ½åŠ›ã€‚è¯¥æ¡†æ¶é‡‡ç”¨äº†åŸºäºä»»åŠ¡å‘é‡ï¼ˆtask vector-basedï¼‰çš„æ¨¡å‹åˆå¹¶æŠ€æœ¯ï¼Œå°†å…ˆè¿›çš„ç¼–ç¨‹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é›†æˆåˆ°è§†è§‰è¯­è¨€éª¨å¹²ç½‘ç»œä¸­ï¼Œä»è€Œåœ¨ä¿ç•™è§†è§‰ç†è§£èƒ½åŠ›çš„åŒæ—¶æ˜¾è‘—æå‡äº†é«˜çº§ç¼–ç¨‹æŠ€èƒ½ã€‚ä¸ºäº†æ”¯æŒæ¨¡å‹çš„è®­ç»ƒä¸è¯„ä¼°ï¼Œç ”ç©¶å›¢é˜Ÿæ„å»ºäº†åŒ…å« 59.8 ä¸‡ä¸ªæ ·æœ¬çš„å¤§è§„æ¨¡å¤šæ¨¡æ€ä»£ç æ•°æ®é›†ï¼ˆMultimodal Coding Dataset, MCDï¼‰ï¼Œæ¶µç›–äº† HTML ä»£ç ã€å›¾è¡¨å›¾åƒä»£ç å¯¹ã€å›¾åƒå¢å¼ºçš„ StackOverflow é—®ç­”åŠç®—æ³•é—®é¢˜ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜æå‡ºäº† InfiBench-V è¯„æµ‹åŸºå‡†ï¼Œä¸“é—¨ç”¨äºè¯„ä¼°æ¨¡å‹å¤„ç†éœ€è¦æ·±å…¥ç†è§£æ–‡æœ¬å’Œè§†è§‰ä¸Šä¸‹æ–‡çš„çœŸå®ä¸–ç•Œå¤æ‚ç¼–ç¨‹é—®é¢˜çš„èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒVisCodex åœ¨å¼€æº MLLMs ä¸­è¾¾åˆ°äº†æœ€å…ˆè¿›ï¼ˆstate-of-the-artï¼‰çš„æ€§èƒ½æ°´å¹³ï¼Œå¹¶å·²æ¥è¿‘ GPT-4o ç­‰ç§æœ‰æ¨¡å‹ã€‚è¿™é¡¹å·¥ä½œä¸ä»…è¯æ˜äº†æ¨¡å‹åˆå¹¶ç­–ç•¥çš„æœ‰æ•ˆæ€§ï¼Œä¹Ÿä¸ºå¤šæ¨¡æ€ä»£ç ç”Ÿæˆé¢†åŸŸæä¾›äº†é«˜è´¨é‡çš„æ•°æ®é›†å’Œè¯„ä¼°å·¥å…·ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09945v1",
      "published_date": "2025-08-13 17:00:44 UTC",
      "updated_date": "2025-08-13 17:00:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:32:46.769636+00:00"
    },
    {
      "arxiv_id": "2508.09937v1",
      "title": "A Comprehensive Evaluation framework of Alignment Techniques for LLMs",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹å¯¹é½æŠ€æœ¯çš„ç»¼åˆè¯„ä¼°æ¡†æ¶",
      "authors": [
        "Muneeza Azmat",
        "Momin Abbas",
        "Maysa Malfiza Garcia de Macedo",
        "Marcelo Carpinette Grave",
        "Luan Soares de Souza",
        "Tiago Machado",
        "Rogerio A de Paula",
        "Raya Horesh",
        "Yixin Chen",
        "Heloisa Caroline de Souza Pereira Candello",
        "Rebecka Nordenlow",
        "Aminat Adebiyi"
      ],
      "abstract": "As Large Language Models (LLMs) become increasingly integrated into real-world applications, ensuring their outputs align with human values and safety standards has become critical. The field has developed diverse alignment approaches including traditional fine-tuning methods (RLHF, instruction tuning), post-hoc correction systems, and inference-time interventions, each with distinct advantages and limitations. However, the lack of unified evaluation frameworks makes it difficult to systematically compare these paradigms and guide deployment decisions. This paper introduces a multi-dimensional evaluation of alignment techniques for LLMs, a comprehensive evaluation framework that provides a systematic comparison across all major alignment paradigms. Our framework assesses methods along four key dimensions: alignment detection, alignment quality, computational efficiency, and robustness. Through experiments across diverse base models and alignment strategies, we demonstrate the utility of our framework in identifying strengths and limitations of current state-of-the-art models, providing valuable insights for future research directions.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨å¯¹é½æŠ€æœ¯ (Alignment Techniques) é¢†åŸŸç¼ºä¹ç»Ÿä¸€è¯„ä¼°æ ‡å‡†çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªå¤šç»´åº¦çš„ç»¼åˆè¯„ä¼°æ¡†æ¶ã€‚è¯¥æ¡†æ¶å¯¹åŒ…æ‹¬ä¼ ç»Ÿçš„å¾®è°ƒæ–¹æ³• (RLHFã€Instruction Tuning)ã€äº‹åä¿®æ­£ç³»ç»Ÿ (Post-hoc Correction Systems) ä»¥åŠæ¨ç†æ—¶å¹²é¢„ (Inference-time Interventions) åœ¨å†…çš„ä¸»è¦å¯¹é½èŒƒå¼è¿›è¡Œäº†ç³»ç»Ÿæ€§æ¯”è¾ƒã€‚ç ”ç©¶ä»å¯¹é½æ£€æµ‹ (Alignment Detection)ã€å¯¹é½è´¨é‡ (Alignment Quality)ã€è®¡ç®—æ•ˆç‡ (Computational Efficiency) å’Œé²æ£’æ€§ (Robustness) å››ä¸ªå…³é”®ç»´åº¦å¯¹æ¨¡å‹è¿›è¡Œè¯„ä¼°ã€‚é€šè¿‡åœ¨å¤šç§åŸºç¡€æ¨¡å‹å’Œå¯¹é½ç­–ç•¥ä¸Šçš„å®éªŒï¼Œè¯¥æ¡†æ¶æˆåŠŸè¯†åˆ«äº†å½“å‰æœ€å…ˆè¿›æ¨¡å‹çš„ä¼˜ç¼ºç‚¹ã€‚è¯¥ç ”ç©¶ä¸ä»…ä¸ºå¯¹é½æŠ€æœ¯çš„ç³»ç»Ÿæ€§å¯¹æ¯”æä¾›äº†å·¥å…·ï¼Œä¹Ÿä¸ºæœªæ¥ç ”ç©¶æ–¹å‘å’Œå®é™…éƒ¨ç½²å†³ç­–æä¾›äº†é‡è¦çš„ç†è®ºè§è§£ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "In submission",
      "pdf_url": "https://arxiv.org/pdf/2508.09937v1",
      "published_date": "2025-08-13 16:42:01 UTC",
      "updated_date": "2025-08-13 16:42:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:32:51.493440+00:00"
    },
    {
      "arxiv_id": "2508.09932v2",
      "title": "Mathematical Computation and Reasoning Errors by Large Language Models",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹çš„æ•°å­¦è®¡ç®—ä¸æ¨ç†é”™è¯¯",
      "authors": [
        "Liang Zhang",
        "Edith Aurora Graf"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly utilized in AI-driven educational instruction and assessment, particularly within mathematics education. The capability of LLMs to generate accurate answers and detailed solutions for math problem-solving tasks is foundational for ensuring reliable and precise feedback and assessment in math education practices. Our study focuses on evaluating the accuracy of four LLMs (OpenAI GPT-4o and o1, DeepSeek-V3 and DeepSeek-R1) solving three categories of math tasks, including arithmetic, algebra, and number theory, and identifies step-level reasoning errors within their solutions. Instead of relying on standard benchmarks, we intentionally build math tasks (via item models) that are challenging for LLMs and prone to errors. The accuracy of final answers and the presence of errors in individual solution steps were systematically analyzed and coded. Both single-agent and dual-agent configurations were tested. It is observed that the reasoning-enhanced OpenAI o1 model consistently achieved higher or nearly perfect accuracy across all three math task categories. Analysis of errors revealed that procedural slips were the most frequent and significantly impacted overall performance, while conceptual misunderstandings were less frequent. Deploying dual-agent configurations substantially improved overall performance. These findings offer actionable insights into enhancing LLM performance and underscore effective strategies for integrating LLMs into mathematics education, thereby advancing AI-driven instructional practices and assessment precision.",
      "tldr_zh": "è¯¥ç ”ç©¶è¯„ä¼°äº†å››ç§å¤§è¯­è¨€æ¨¡å‹ (Large Language Models, LLMs) åœ¨æ•°å­¦æ•™è‚²ä¸­çš„è¡¨ç°ï¼Œé‡ç‚¹åˆ†æäº†å…¶åœ¨æ•°å­¦è®¡ç®—ä¸æ¨ç†ä¸­çš„é”™è¯¯ã€‚ç ”ç©¶å›¢é˜Ÿç³»ç»Ÿæµ‹è¯•äº† OpenAI GPT-4oã€o1 ä»¥åŠ DeepSeek-V3ã€DeepSeek-R1 åœ¨ç®—æœ¯ (arithmetic)ã€ä»£æ•° (algebra) å’Œæ•°è®º (number theory) ä»»åŠ¡ä¸­çš„å‡†ç¡®æ€§ã€‚å®éªŒé€šè¿‡é¡¹æ¨¡å‹ (item models) æœ‰æ„æ„å»ºäº†æå…·æŒ‘æˆ˜æ€§çš„æ•°å­¦ä»»åŠ¡ï¼Œå¹¶å¯¹å•æ™ºèƒ½ä½“ä¸åŒæ™ºèƒ½ä½“é…ç½® (dual-agent configurations) ä¸‹çš„æ­¥éª¤çº§æ¨ç†é”™è¯¯ (reasoning errors) è¿›è¡Œäº†ç»†è‡´åˆ†æã€‚ç»“æœè¡¨æ˜ï¼Œæ¨ç†å¢å¼ºçš„ OpenAI o1 æ¨¡å‹åœ¨æ‰€æœ‰æ•°å­¦ç±»åˆ«ä¸­å‡è¡¨ç°å‡ºæé«˜ç”šè‡³è¿‘ä¹å®Œç¾çš„å‡†ç¡®ç‡ã€‚é”™è¯¯åˆ†æå‘ç°ï¼Œç¨‹åºæ€§ç–å¿½ (procedural slips) æ˜¯æœ€å¸¸è§çš„é”™è¯¯ç±»å‹å¹¶æ˜¾è‘—å½±å“æ¨¡å‹æ€§èƒ½ï¼Œè€Œæ¦‚å¿µè¯¯è§£ (conceptual misunderstandings) å‘ç”Ÿé¢‘ç‡è¾ƒä½ã€‚æ­¤å¤–ï¼Œé‡‡ç”¨åŒæ™ºèƒ½ä½“é…ç½®èƒ½å¤Ÿå®è´¨æ€§åœ°æå‡æ•´ä½“è¡¨ç°ã€‚è¯¥ç ”ç©¶ä¸ºä¼˜åŒ– LLM åœ¨æ•°å­¦æ•™è‚²é¢†åŸŸçš„åº”ç”¨æä¾›äº†å¯æ“ä½œçš„è§è§£ï¼Œæœ‰åŠ©äºæ¨è¿› AI é©±åŠ¨çš„æ•™å­¦å®è·µä¸è¯„ä¼°ç²¾åº¦ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09932v2",
      "published_date": "2025-08-13 16:33:02 UTC",
      "updated_date": "2025-08-14 13:25:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:32:57.494323+00:00"
    },
    {
      "arxiv_id": "2508.09925v1",
      "title": "Residual Reservoir Memory Networks",
      "title_zh": "æ®‹å·®å‚¨å¤‡æ± è®°å¿†ç½‘ç»œ",
      "authors": [
        "Matteo Pinna",
        "Andrea Ceni",
        "Claudio Gallicchio"
      ],
      "abstract": "We introduce a novel class of untrained Recurrent Neural Networks (RNNs) within the Reservoir Computing (RC) paradigm, called Residual Reservoir Memory Networks (ResRMNs). ResRMN combines a linear memory reservoir with a non-linear reservoir, where the latter is based on residual orthogonal connections along the temporal dimension for enhanced long-term propagation of the input. The resulting reservoir state dynamics are studied through the lens of linear stability analysis, and we investigate diverse configurations for the temporal residual connections. The proposed approach is empirically assessed on time-series and pixel-level 1-D classification tasks. Our experimental results highlight the advantages of the proposed approach over other conventional RC models.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸º Residual Reservoir Memory Networks (ResRMNs) çš„æ–°å‹æœªè®­ç»ƒ Recurrent Neural Networks (RNNs)ï¼Œå±äº Reservoir Computing (RC) èŒƒå¼ã€‚ResRMNs å°† linear memory reservoir ä¸ non-linear reservoir ç›¸ç»“åˆï¼Œå…¶ä¸­åè€…é‡‡ç”¨æ²¿æ—¶é—´ç»´åº¦çš„ residual orthogonal connections æ¥å®ç°è¾“å…¥ä¿¡å·çš„å¢å¼ºé•¿æœŸä¼ æ’­ã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡ linear stability analysis å¯¹æ°´åº“çŠ¶æ€åŠ¨åŠ›å­¦è¿›è¡Œäº†ç†è®ºåˆ†æï¼Œå¹¶æ¢è®¨äº†å¤šç§æ—¶é—´æ®‹å·®è¿æ¥çš„é…ç½®æ–¹æ¡ˆã€‚è¯¥æ–¹æ³•åœ¨ time-series å’Œ pixel-level 1-D classification ä»»åŠ¡ä¸Šè¿›è¡Œäº†å®è¯æµ‹è¯•ã€‚å®éªŒç»“æœè¡¨æ˜ ResRMNs çš„æ€§èƒ½æ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„ RC æ¨¡å‹ï¼Œè¯æ˜äº†è¯¥æ¶æ„åœ¨å¤„ç†å¤æ‚æ—¶åºæ•°æ®å’Œæ•æ‰é•¿ç¨‹ä¾èµ–æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages, 6 figures, accepted at IJCNN 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.09925v1",
      "published_date": "2025-08-13 16:21:29 UTC",
      "updated_date": "2025-08-13 16:21:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:33:22.971422+00:00"
    },
    {
      "arxiv_id": "2508.09919v1",
      "title": "T-CACE: A Time-Conditioned Autoregressive Contrast Enhancement Multi-Task Framework for Contrast-Free Liver MRI Synthesis, Segmentation, and Diagnosis",
      "title_zh": "T-CACEï¼šç”¨äºæ— å¯¹æ¯”å‰‚è‚è„ MRI åˆæˆã€åˆ†å‰²ä¸è¯Šæ–­çš„æ—¶é—´æ¡ä»¶è‡ªå›å½’å¯¹æ¯”å¢å¼ºå¤šä»»åŠ¡æ¡†æ¶",
      "authors": [
        "Xiaojiao Xiao",
        "Jianfeng Zhao",
        "Qinmin Vivian Hu",
        "Guanghui Wang"
      ],
      "abstract": "Magnetic resonance imaging (MRI) is a leading modality for the diagnosis of liver cancer, significantly improving the classification of the lesion and patient outcomes. However, traditional MRI faces challenges including risks from contrast agent (CA) administration, time-consuming manual assessment, and limited annotated datasets. To address these limitations, we propose a Time-Conditioned Autoregressive Contrast Enhancement (T-CACE) framework for synthesizing multi-phase contrast-enhanced MRI (CEMRI) directly from non-contrast MRI (NCMRI). T-CACE introduces three core innovations: a conditional token encoding (CTE) mechanism that unifies anatomical priors and temporal phase information into latent representations; and a dynamic time-aware attention mask (DTAM) that adaptively modulates inter-phase information flow using a Gaussian-decayed attention mechanism, ensuring smooth and physiologically plausible transitions across phases. Furthermore, a constraint for temporal classification consistency (TCC) aligns the lesion classification output with the evolution of the physiological signal, further enhancing diagnostic reliability. Extensive experiments on two independent liver MRI datasets demonstrate that T-CACE outperforms state-of-the-art methods in image synthesis, segmentation, and lesion classification. This framework offers a clinically relevant and efficient alternative to traditional contrast-enhanced imaging, improving safety, diagnostic efficiency, and reliability for the assessment of liver lesion. The implementation of T-CACE is publicly available at: https://github.com/xiaojiao929/T-CACE.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† T-CACE æ¡†æ¶ï¼Œæ—¨åœ¨ç›´æ¥ä»éå¢å¼º MRI (NCMRI) åˆæˆå¤šæœŸåŠ¨æ€å¢å¼º MRI (CEMRI)ï¼Œä»¥è§£å†³ä¸´åºŠä¸­å¯¹æ¯”å‰‚ (CA) ä½¿ç”¨é£é™©åŠäººå·¥è¯„ä¼°æ•ˆç‡ä½çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†æ¡ä»¶ä»¤ç‰Œç¼–ç  (CTE) æœºåˆ¶ï¼Œå°†è§£å‰–å…ˆéªŒä¸æ—¶é—´ç›¸ä½ä¿¡æ¯ç»Ÿä¸€åˆ°æ½œåœ¨è¡¨å¾ä¸­ï¼Œå¹¶åˆ©ç”¨åŠ¨æ€æ—¶é—´æ„ŸçŸ¥æ³¨æ„åŠ›æ©ç  (DTAM) çš„é«˜æ–¯è¡°å‡æœºåˆ¶è°ƒèŠ‚æœŸç›¸é—´ä¿¡æ¯æµï¼Œç¡®ä¿äº†ç”Ÿç†ç‰¹å¾çš„å¹³æ»‘è½¬æ¢ã€‚æ­¤å¤–ï¼Œç ”ç©¶é€šè¿‡æ—¶é—´åˆ†ç±»ä¸€è‡´æ€§ (TCC) çº¦æŸä½¿ç—…ç¶åˆ†ç±»è¾“å‡ºä¸ç”Ÿç†ä¿¡å·æ¼”å˜å¯¹é½ï¼Œæ˜¾è‘—æå‡äº†è¯Šæ–­å¯é æ€§ã€‚åœ¨ä¸¤ä¸ªç‹¬ç«‹è‚è„ MRI æ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜ï¼ŒT-CACE åœ¨å›¾åƒåˆæˆã€åˆ†å‰²å’Œç—…ç¶è¯Šæ–­å¤šä»»åŠ¡ä¸­å‡ä¼˜äºç°æœ‰å…ˆè¿›æ–¹æ³•ã€‚è¯¥æ¡†æ¶ä¸ºæ— å¯¹æ¯”å‰‚è‚è„å½±åƒè¯„ä¼°æä¾›äº†ä¸€ç§é«˜æ•ˆä¸”å®‰å…¨çš„ä¸´åºŠæ›¿ä»£æ–¹æ¡ˆï¼Œæ˜¾è‘—æå‡äº†è¯Šæ–­æ•ˆç‡ä¸å‡†ç¡®æ€§ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "IEEE Journal of Biomedical and Health Informatics, 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.09919v1",
      "published_date": "2025-08-13 16:14:14 UTC",
      "updated_date": "2025-08-13 16:14:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:33:06.686712+00:00"
    },
    {
      "arxiv_id": "2508.09904v1",
      "title": "Beyond NaÃ¯ve Prompting: Strategies for Improved Zero-shot Context-aided Forecasting with LLMs",
      "title_zh": "è¶…è¶Šæœ´ç´ æç¤ºï¼šæå‡å¤§è¯­è¨€æ¨¡å‹é›¶æ ·æœ¬ä¸Šä¸‹æ–‡è¾…åŠ©é¢„æµ‹èƒ½åŠ›çš„ç­–ç•¥",
      "authors": [
        "Arjun Ashok",
        "Andrew Robert Williams",
        "Vincent Zhihao Zheng",
        "Irina Rish",
        "Nicolas Chapados",
        "Ã‰tienne Marcotte",
        "Valentina Zantedeschi",
        "Alexandre Drouin"
      ],
      "abstract": "Forecasting in real-world settings requires models to integrate not only historical data but also relevant contextual information, often available in textual form. While recent work has shown that large language models (LLMs) can be effective context-aided forecasters via naÃ¯ve direct prompting, their full potential remains underexplored. We address this gap with 4 strategies, providing new insights into the zero-shot capabilities of LLMs in this setting. ReDP improves interpretability by eliciting explicit reasoning traces, allowing us to assess the model's reasoning over the context independently from its forecast accuracy. CorDP leverages LLMs solely to refine existing forecasts with context, enhancing their applicability in real-world forecasting pipelines. IC-DP proposes embedding historical examples of context-aided forecasting tasks in the prompt, substantially improving accuracy even for the largest models. Finally, RouteDP optimizes resource efficiency by using LLMs to estimate task difficulty, and routing the most challenging tasks to larger models. Evaluated on different kinds of context-aided forecasting tasks from the CiK benchmark, our strategies demonstrate distinct benefits over naÃ¯ve prompting across LLMs of different sizes and families. These results open the door to further simple yet effective improvements in LLM-based context-aided forecasting.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Large Language Models (LLMs) åœ¨ä¸Šä¸‹æ–‡è¾…åŠ©é¢„æµ‹ (Context-aided Forecasting) ä¸­çš„æ½œåŠ›æŒ–æ˜ä¸è¶³ï¼Œæå‡ºäº†å››ç§è¶…è¶Šç®€å• Direct Prompting çš„ç­–ç•¥ï¼Œæ—¨åœ¨æå‡æ¨¡å‹åœ¨ zero-shot åœºæ™¯ä¸‹çš„è¡¨ç°ã€‚ç­–ç•¥ ReDP é€šè¿‡å¼•å¯¼æ˜¾å¼æ¨ç†è½¨è¿¹å¢å¼ºäº†é¢„æµ‹çš„å¯è§£é‡Šæ€§ï¼Œä½¿ç ”ç©¶è€…èƒ½ç‹¬ç«‹è¯„ä¼°æ¨¡å‹å¯¹ä¸Šä¸‹æ–‡çš„æ¨ç†èƒ½åŠ›ã€‚CorDP ç­–ç•¥åˆ©ç”¨ LLMs ä¿®æ­£å·²æœ‰é¢„æµ‹ï¼Œä»è€Œä¼˜åŒ–äº†å…¶åœ¨å®é™…ç”Ÿäº§å·¥ä½œæµä¸­çš„é›†æˆæ•ˆæœã€‚IC-DP ç­–ç•¥é€šè¿‡åœ¨ prompt ä¸­å¼•å…¥å†å²ä»»åŠ¡ç¤ºä¾‹ï¼Œæ˜¾è‘—æå‡äº†å¤§å‹æ¨¡å‹çš„é¢„æµ‹å‡†ç¡®ç‡ã€‚RouteDP ç­–ç•¥åˆ™é€šè¿‡è¯„ä¼°ä»»åŠ¡éš¾åº¦è¿›è¡Œæ¨¡å‹è·¯ç”±ï¼Œæœ‰æ•ˆå¹³è¡¡äº†æ¨ç†èµ„æºä¸é¢„æµ‹æ•ˆæœã€‚åœ¨ CiK åŸºå‡†æµ‹è¯•ä¸Šçš„è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œè¿™äº›ç­–ç•¥åœ¨ä¸åŒè§„æ¨¡å’Œç³»åˆ—çš„ LLMs ä¸Šå‡ä¼˜äº naÃ¯ve promptingï¼Œä¸ºä¸Šä¸‹æ–‡è¾…åŠ©é¢„æµ‹é¢†åŸŸæä¾›äº†ç®€å•ä¸”é«˜æ•ˆçš„æ”¹è¿›æ¡†æ¶ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09904v1",
      "published_date": "2025-08-13 16:02:55 UTC",
      "updated_date": "2025-08-13 16:02:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:33:43.563482+00:00"
    },
    {
      "arxiv_id": "2508.10946v1",
      "title": "IPG: Incremental Patch Generation for Generalized Adversarial Patch Training",
      "title_zh": "IPGï¼šé¢å‘æ³›åŒ–å¯¹æŠ—è¡¥ä¸è®­ç»ƒçš„å¢é‡å¼è¡¥ä¸ç”Ÿæˆ",
      "authors": [
        "Wonho Lee",
        "Hyunsik Na",
        "Jisu Lee",
        "Daeseon Choi"
      ],
      "abstract": "The advent of adversarial patches poses a significant challenge to the robustness of AI models, particularly in the domain of computer vision tasks such as object detection. In contradistinction to traditional adversarial examples, these patches target specific regions of an image, resulting in the malfunction of AI models. This paper proposes Incremental Patch Generation (IPG), a method that generates adversarial patches up to 11.1 times more efficiently than existing approaches while maintaining comparable attack performance. The efficacy of IPG is demonstrated by experiments and ablation studies including YOLO's feature distribution visualization and adversarial training results, which show that it produces well-generalized patches that effectively cover a broader range of model vulnerabilities. Furthermore, IPG-generated datasets can serve as a robust knowledge foundation for constructing a robust model, enabling structured representation, advanced reasoning, and proactive defenses in AI security ecosystems. The findings of this study suggest that IPG has considerable potential for future utilization not only in adversarial patch defense but also in real-world applications such as autonomous vehicles, security systems, and medical imaging, where AI models must remain resilient to adversarial attacks in dynamic and high-stakes environments.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Incremental Patch Generation (IPG)ï¼Œè¿™æ˜¯ä¸€ç§é’ˆå¯¹ object detection ç­‰è®¡ç®—æœºè§†è§‰ä»»åŠ¡è®¾è®¡çš„å¯¹æŠ—è¡¥ä¸ç”Ÿæˆæ–¹æ³•ã€‚IPG åœ¨ä¿æŒä¸ç°æœ‰æŠ€æœ¯ç›¸å½“çš„æ”»å‡»æ€§èƒ½å‰æä¸‹ï¼Œå°†å¯¹æŠ—è¡¥ä¸çš„ç”Ÿæˆæ•ˆç‡æå‡äº†é«˜è¾¾ 11.1 å€ã€‚é€šè¿‡ YOLO ç‰¹å¾åˆ†å¸ƒå¯è§†åŒ–åŠå¯¹æŠ—è®­ç»ƒå®éªŒï¼Œè¯¥ç ”ç©¶éªŒè¯äº† IPG èƒ½å¤Ÿç”Ÿæˆæ³›åŒ–æ€§æå¼ºçš„è¡¥ä¸ï¼Œå¹¶æœ‰æ•ˆè¦†ç›–æ›´å¹¿æ³›çš„æ¨¡å‹æ¼æ´ã€‚æ­¤å¤–ï¼Œç”± IPG ç”Ÿæˆçš„æ•°æ®é›†å¯ä½œä¸ºæ„å»ºé²æ£’æ¨¡å‹çš„çŸ¥è¯†åŸºç¡€ï¼ŒåŠ©åŠ›å®ç° AI å®‰å…¨ç”Ÿæ€ä¸­çš„ä¸»åŠ¨é˜²å¾¡ä¸é«˜çº§æ¨ç†ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œè¯¥æŠ€æœ¯åœ¨è‡ªåŠ¨é©¾é©¶ã€å®‰é˜²ç³»ç»ŸåŠåŒ»å­¦å½±åƒç­‰å¯¹æ¨¡å‹éŸ§æ€§è¦æ±‚æé«˜çš„åŠ¨æ€é«˜é£é™©ç°å®åº”ç”¨åœºæ™¯ä¸­å…·æœ‰æ˜¾è‘—çš„åº”ç”¨æ½œåŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.10946v1",
      "published_date": "2025-08-13 15:53:58 UTC",
      "updated_date": "2025-08-13 15:53:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:33:44.453980+00:00"
    },
    {
      "arxiv_id": "2508.09894v1",
      "title": "Rare anomalies require large datasets: About proving the existence of anomalies",
      "title_zh": "ç½•è§å¼‚å¸¸æ£€æµ‹éœ€è¦å¤§è§„æ¨¡æ•°æ®é›†ï¼šè®ºå¼‚å¸¸å­˜åœ¨æ€§çš„è¯æ˜",
      "authors": [
        "Simon KlÃ¼ttermann",
        "Emmanuel MÃ¼ller"
      ],
      "abstract": "Detecting whether any anomalies exist within a dataset is crucial for effective anomaly detection, yet it remains surprisingly underexplored in anomaly detection literature. This paper presents a comprehensive study that addresses the fundamental question: When can we conclusively determine that anomalies are present? Through extensive experimentation involving over three million statistical tests across various anomaly detection tasks and algorithms, we identify a relationship between the dataset size, contamination rate, and an algorithm-dependent constant $ Î±_{\\text{algo}} $. Our results demonstrate that, for an unlabeled dataset of size $ N $ and contamination rate $ Î½$, the condition $ N \\ge \\frac{Î±_{\\text{algo}}}{Î½^2} $ represents a lower bound on the number of samples required to confirm anomaly existence. This threshold implies a limit to how rare anomalies can be before proving their existence becomes infeasible.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¼‚å¸¸æ£€æµ‹(Anomaly Detection)é¢†åŸŸä¸­ä¸€ä¸ªåŸºç¡€ä½†å¸¸è¢«å¿½è§†çš„é—®é¢˜ï¼Œå³åœ¨ä½•ç§æ¡ä»¶ä¸‹å¯ä»¥ç¡®åˆ‡åˆ¤å®šæ•°æ®é›†ä¸­å­˜åœ¨å¼‚å¸¸ã€‚é€šè¿‡å¯¹å¤šç§å¼‚å¸¸æ£€æµ‹ç®—æ³•è¿›è¡Œè¶…è¿‡ä¸‰ç™¾ä¸‡æ¬¡ç»Ÿè®¡æµ‹è¯•(Statistical Tests)ï¼Œç ”ç©¶äººå‘˜è¯†åˆ«å‡ºäº†æ•°æ®é›†è§„æ¨¡ $N$ã€æ±¡æŸ“ç‡(Contamination Rate) $\\nu$ ä¸ç®—æ³•ç›¸å…³å¸¸æ•° $\\alpha_{\\text{algo}}$ ä¹‹é—´çš„å…³é”®å®šé‡å…³ç³»ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯æ˜å¼‚å¸¸å­˜åœ¨æ‰€éœ€çš„æ ·æœ¬é‡å­˜åœ¨ä¸€ä¸ªç†è®ºä¸‹ç•Œï¼Œå³å¿…é¡»æ»¡è¶³ $N \\ge \\frac{\\alpha_{\\text{algo}}}{\\nu^2}$ã€‚è¿™ä¸€å‘ç°æ­ç¤ºäº†æ£€æµ‹ç¨€æœ‰å¼‚å¸¸(Rare Anomalies)çš„ç‰©ç†æé™ï¼Œè¡¨æ˜å½“å¼‚å¸¸æ¯”ä¾‹ä½äºç‰¹å®šé˜ˆå€¼æ—¶ï¼Œåœ¨ç»Ÿè®¡ä¸Šè¯æ˜å…¶å­˜åœ¨å°†å˜å¾—ä¸å¯è¡Œã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, 8 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.09894v1",
      "published_date": "2025-08-13 15:52:33 UTC",
      "updated_date": "2025-08-13 15:52:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:33:52.584708+00:00"
    },
    {
      "arxiv_id": "2508.09893v1",
      "title": "RAGulating Compliance: A Multi-Agent Knowledge Graph for Regulatory QA",
      "title_zh": "RAGulating Complianceï¼šé¢å‘ç›‘ç®¡é—®ç­”çš„å¤šæ™ºèƒ½ä½“çŸ¥è¯†å›¾è°±",
      "authors": [
        "Bhavik Agarwal",
        "Hemant Sunil Jomraj",
        "Simone Kaplunov",
        "Jack Krolick",
        "Viktoria Rojkova"
      ],
      "abstract": "Regulatory compliance question answering (QA) requires precise, verifiable information, and domain-specific expertise, posing challenges for Large Language Models (LLMs). In this work, we present a novel multi-agent framework that integrates a Knowledge Graph (KG) of Regulatory triplets with Retrieval-Augmented Generation (RAG) to address these demands. First, agents build and maintain an ontology-free KG by extracting subject--predicate--object (SPO) triplets from regulatory documents and systematically cleaning, normalizing, deduplicating, and updating them. Second, these triplets are embedded and stored along with their corresponding textual sections and metadata in a single enriched vector database, allowing for both graph-based reasoning and efficient information retrieval. Third, an orchestrated agent pipeline leverages triplet-level retrieval for question answering, ensuring high semantic alignment between user queries and the factual \"who-did-what-to-whom\" core captured by the graph. Our hybrid system outperforms conventional methods in complex regulatory queries, ensuring factual correctness with embedded triplets, enabling traceability through a unified vector database, and enhancing understanding through subgraph visualization, providing a robust foundation for compliance-driven and broader audit-focused applications.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸ºRAGulating Complianceçš„æ–°å‹å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨ç›‘ç®¡åˆè§„é—®ç­”(Regulatory compliance QA)é¢†åŸŸé¢ä¸´çš„ç²¾ç¡®åº¦ä¸å¯éªŒè¯æ€§æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶å°†ç›‘ç®¡ä¸‰å…ƒç»„çŸ¥è¯†å›¾è°±(Knowledge Graph)ä¸æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)æŠ€æœ¯ç›¸ç»“åˆï¼Œé€šè¿‡å¤šä¸ªæ™ºèƒ½ä½“åä½œæå–å¹¶åŠ¨æ€ç»´æŠ¤ä¸€ä¸ªæ— æœ¬ä½“çŸ¥è¯†å›¾è°±ï¼Œä»ä¸­ç³»ç»ŸåŒ–åœ°æ¸…æ´—å’Œå»é‡subject-predicate-object (SPO)ä¸‰å…ƒç»„ã€‚è¿™äº›ä¸‰å…ƒç»„è¿åŒå¯¹åº”çš„æ–‡æœ¬æ®µè½åŠå…ƒæ•°æ®è¢«ç»Ÿä¸€å­˜å‚¨åœ¨å¢å¼ºå‹å‘é‡æ•°æ®åº“ä¸­ï¼Œå®ç°äº†åŸºäºå›¾çš„æ¨ç†ä¸é«˜æ•ˆæ£€ç´¢çš„æœ‰æœºç»“åˆã€‚é€šè¿‡ç¼–æ’å¥½çš„æ™ºèƒ½ä½“æµæ°´çº¿è¿›è¡Œä¸‰å…ƒç»„çº§åˆ«æ£€ç´¢ï¼Œç³»ç»Ÿèƒ½å¤Ÿç¡®ä¿ç”¨æˆ·æŸ¥è¯¢ä¸äº‹å®æ ¸å¿ƒä¹‹é—´çš„é«˜åº¦è¯­ä¹‰å¯¹é½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ··åˆç³»ç»Ÿåœ¨å¤„ç†å¤æ‚ç›‘ç®¡æŸ¥è¯¢æ—¶çš„è¡¨ç°ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œä¸ä»…ä¿è¯äº†äº‹å®çš„å‡†ç¡®æ€§ï¼Œè¿˜é€šè¿‡å­å›¾å¯è§†åŒ–å¢å¼ºäº†ç»“æœçš„å¯è¿½æº¯æ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09893v1",
      "published_date": "2025-08-13 15:51:05 UTC",
      "updated_date": "2025-08-13 15:51:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:34:03.488493+00:00"
    },
    {
      "arxiv_id": "2508.09889v4",
      "title": "Profile-Aware Maneuvering: A Dynamic Multi-Agent System for Robust GAIA Problem Solving by AWorld",
      "title_zh": "ç”»åƒæ„ŸçŸ¥æœºåŠ¨ï¼šAWorld ç”¨äºé²æ£’ GAIA é—®é¢˜æ±‚è§£çš„åŠ¨æ€å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ",
      "authors": [
        "Zhitian Xie",
        "Qintong Wu",
        "Chengyue Yu",
        "Chenyi Zhuang",
        "Jinjie Gu"
      ],
      "abstract": "The rapid advancement of large language models (LLMs) has empowered intelligent agents to leverage diverse external tools for solving complex real-world problems. However, this reliance introduces new challenges, as extended contexts and noisy tool outputs can undermine system reliability. To address this, we propose a dynamic Multi-Agent System (MAS) in our AWorld framework, where an Execution Agent is supervised by a Guard Agent that provides on-demand dynamic maneuvering, verifying and correcting the reasoning process to improve robustness over single-agent systems. To move beyond this generic supervision, we enhance the architecture with a methodology inspired by System Identification from control theory. This method first profiles the Execution Agent offline on a benchmark dataset to create a \"performance fingerprint\" of its unique weaknesses. The Guard Agent then leverages this fingerprint online to deliver profile-aware supervision, making targeted interventions based on known failure patterns rather than merely reacting to immediate logical flaws. Extensive experiments on the GAIA dataset demonstrate that this profile-aware MAS significantly improves both effectiveness and stability, outperforming not only single-agent systems but also its naive counterpart. This superior performance led our system to achieve first place among open-source projects on the prestigious GAIA leaderboard. These findings highlight that building truly trustworthy intelligent systems requires not just collaboration, but a deep, empirically-grounded understanding of each agent's unique capabilities and limitations.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† AWorld æ¡†æ¶ä¸‹çš„åŠ¨æ€å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ (Multi-Agent System)ï¼Œæ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨å¤„ç†å¤æ‚ç°å®ä»»åŠ¡æ—¶å› ä¸Šä¸‹æ–‡è¿‡é•¿æˆ–å·¥å…·è¾“å‡ºå™ªå£°å¯¼è‡´çš„å¯é æ€§é—®é¢˜ã€‚ç³»ç»Ÿé‡‡ç”¨ Execution Agent ä¸ Guard Agent çš„åä½œæ¨¡å¼ï¼Œé€šè¿‡ Guard Agent çš„åŠ¨æ€æ¼”ä¹  (dynamic maneuvering) æ¥å®æ—¶éªŒè¯å’Œçº æ­£æ¨ç†è¿‡ç¨‹ã€‚ç ”ç©¶åˆ›æ–°æ€§åœ°å¼•å…¥äº†æ§åˆ¶ç†è®ºä¸­çš„ç³»ç»Ÿè¾¨è¯† (System Identification) æ–¹æ³•ï¼Œé€šè¿‡ç¦»çº¿å‰–æ (offline profiling) ä¸º Execution Agent åˆ›å»ºåæ˜ å…¶ç‰¹å®šå¼±ç‚¹çš„â€œæ€§èƒ½æŒ‡çº¹â€ã€‚åœ¨å®é™…è¿è¡Œä¸­ï¼ŒGuard Agent åˆ©ç”¨è¯¥æŒ‡çº¹å®ç°ç”»åƒæ„ŸçŸ¥ç›‘ç®¡ (profile-aware supervision)ï¼Œä»è€Œèƒ½å¤Ÿé’ˆå¯¹å·²çŸ¥çš„å¤±è´¥æ¨¡å¼è¿›è¡Œä¸»åŠ¨ä¸”ç²¾å‡†çš„å¹²é¢„ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥ç³»ç»Ÿåœ¨ GAIA æ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºå•æ™ºèƒ½ä½“å’Œä¼ ç»Ÿå¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œå¹¶åœ¨ GAIA æ’è¡Œæ¦œçš„å¼€æºé¡¹ç›®ä¸­å–å¾—äº†ç¬¬ä¸€åçš„ä½³ç»©ã€‚è¿™ä¸€æˆæœè¯æ˜äº†æ·±å…¥ç†è§£æ™ºèƒ½ä½“ä¸ªä½“èƒ½åŠ›è¾¹ç•Œå¯¹äºæ„å»ºé«˜é²æ£’æ€§åä½œç³»ç»Ÿçš„å…³é”®æ€§ä½œç”¨ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09889v4",
      "published_date": "2025-08-13 15:46:25 UTC",
      "updated_date": "2025-09-01 02:41:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:33:59.695113+00:00"
    },
    {
      "arxiv_id": "2508.09886v1",
      "title": "COME: Dual Structure-Semantic Learning with Collaborative MoE for Universal Lesion Detection Across Heterogeneous Ultrasound Datasets",
      "title_zh": "COMEï¼šåŸºäºååŒ MoE çš„åŒé‡ç»“æ„-è¯­ä¹‰å­¦ä¹ ï¼Œç”¨äºè·¨å¼‚æ„è¶…å£°æ•°æ®é›†çš„é€šç”¨ç—…ç¶æ£€æµ‹",
      "authors": [
        "Lingyu Chen",
        "Yawen Zeng",
        "Yue Wang",
        "Peng Wan",
        "Guo-chen Ning",
        "Hongen Liao",
        "Daoqiang Zhang",
        "Fang Chen"
      ],
      "abstract": "Conventional single-dataset training often fails with new data distributions, especially in ultrasound (US) image analysis due to limited data, acoustic shadows, and speckle noise. Therefore, constructing a universal framework for multi-heterogeneous US datasets is imperative. However, a key challenge arises: how to effectively mitigate inter-dataset interference while preserving dataset-specific discriminative features for robust downstream task? Previous approaches utilize either a single source-specific decoder or a domain adaptation strategy, but these methods experienced a decline in performance when applied to other domains. Considering this, we propose a Universal Collaborative Mixture of Heterogeneous Source-Specific Experts (COME). Specifically, COME establishes dual structure-semantic shared experts that create a universal representation space and then collaborate with source-specific experts to extract discriminative features through providing complementary features. This design enables robust generalization by leveraging cross-datasets experience distributions and providing universal US priors for small-batch or unseen data scenarios. Extensive experiments under three evaluation modes (single-dataset, intra-organ, and inter-organ integration datasets) demonstrate COME's superiority, achieving significant mean AP improvements over state-of-the-art methods. Our project is available at: https://universalcome.github.io/UniversalCOME/.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†COMEï¼Œä¸€ç§åŸºäºCollaborative Mixture of Heterogeneous Source-Specific Expertsçš„é€šç”¨æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³è¶…å£°(ultrasound)å›¾åƒåˆ†æä¸­å› æ•°æ®é‡æœ‰é™ã€å£°å½±å’Œæ–‘ç‚¹å™ªå£°å¯¼è‡´çš„è·¨å¼‚æ„æ•°æ®é›†æ³›åŒ–éš¾é¢˜ã€‚è¯¥æ¡†æ¶é€šè¿‡æ„å»ºdual structure-semantic shared expertsæ¥åˆ›å»ºé€šç”¨è¡¨ç¤ºç©ºé—´ï¼Œå¹¶ä¸source-specific expertsååŒå·¥ä½œä»¥æå–äº’è¡¥çš„åŒºåˆ†æ€§ç‰¹å¾ã€‚è¿™ç§è®¾è®¡é€šè¿‡åˆ©ç”¨è·¨æ•°æ®é›†çš„ç»éªŒåˆ†å¸ƒï¼Œä¸ºå°æ ·æœ¬æˆ–æœªè§æ•°æ®åœºæ™¯æä¾›äº†é€šç”¨çš„è¶…å£°å…ˆéªŒ(universal US priors)ï¼Œæœ‰æ•ˆåœ°åœ¨ä¿ç•™æ•°æ®é›†ç‰¹å®šç‰¹å¾çš„åŒæ—¶ç¼“è§£äº†æ•°æ®é›†é—´çš„å¹²æ‰°ã€‚åœ¨å•æ•°æ®é›†ã€å™¨å®˜å†…åŠå™¨å®˜é—´æ•´åˆæ•°æ®é›†ä¸‰ç§è¯„ä¼°æ¨¡å¼ä¸‹çš„å¹¿æ³›å®éªŒè¯æ˜ï¼ŒCOMEåœ¨å¹³å‡ç²¾åº¦(mean AP)ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚è¯¥ç ”ç©¶ä¸ºå®ç°è·¨å¼‚æ„è¶…å£°æ•°æ®é›†çš„é€šç”¨ç—…ç¶æ£€æµ‹(Universal Lesion Detection)æä¾›äº†å…·æœ‰é²æ£’æ³›åŒ–èƒ½åŠ›çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "ICCV 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.09886v1",
      "published_date": "2025-08-13 15:43:20 UTC",
      "updated_date": "2025-08-13 15:43:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:34:04.995883+00:00"
    },
    {
      "arxiv_id": "2508.09883v1",
      "title": "Beyond Scaling Law: A Data-Efficient Distillation Framework for Reasoning",
      "title_zh": "è¶…è¶Šè§„æ¨¡æ³•åˆ™ï¼šé¢å‘æ¨ç†çš„é«˜æ•ˆæ•°æ®è’¸é¦æ¡†æ¶",
      "authors": [
        "Xiaojun Wu",
        "Xiaoguang Jiang",
        "Huiyang Li",
        "Jucai Zhai",
        "Dengfeng Liu",
        "Qiaobo Hao",
        "Huang Liu",
        "Zhiguo Yang",
        "Ji Xie",
        "Ninglun Gu",
        "Jin Yang",
        "Kailai Zhang",
        "Yelun Bao",
        "Jun Wang"
      ],
      "abstract": "Large language models (LLMs) demonstrate remarkable reasoning capabilities in tasks such as algorithmic coding and mathematical problem-solving. Recent methods have improved reasoning through expanded corpus and multistage training combining reinforcement learning and supervised fine-tuning. Although some methods suggest that small but targeted dataset can incentivize reasoning via only distillation, a reasoning scaling laws is still taking shape, increasing computational costs. To address this, we propose a data-efficient distillation framework (DED) that optimizes the Pareto frontier of reasoning distillation. Inspired by the on-policy learning and diverse roll-out strategies of reinforcement learning, the key idea of our approach is threefold: (1) We identify that benchmark scores alone do not determine an effective teacher model. Through comprehensive comparisons of leading reasoning LLMs, we develop a method to select an optimal teacher model. (2) While scaling distillation can enhance reasoning, it often degrades out-of-domain performance. A carefully curated, smaller corpus achieves a balanced trade-off between in-domain and out-of-domain capabilities. (3) Diverse reasoning trajectories encourage the student model to develop robust reasoning skills. We validate our method through evaluations on mathematical reasoning (AIME 2024/2025, MATH-500) and code generation (LiveCodeBench), achieving state-of-the-art results with only 0.8k carefully curated examples, bypassing the need for extensive scaling. Our systematic analysis demonstrates that DED outperforms existing methods by considering factors beyond superficial hardness, token length, or teacher model capability. This work offers a practical and efficient pathway to advanced reasoning while preserving general capabilities.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†æ•°æ®é«˜æ•ˆè’¸é¦æ¡†æ¶ (Data-Efficient Distillation, DED)ï¼Œæ—¨åœ¨ä¼˜åŒ–æ¨ç†è’¸é¦ä¸­çš„ Pareto frontierï¼Œè§£å†³ä¼ ç»Ÿ Scaling Law å¸¦æ¥çš„å·¨å¤§è®¡ç®—æˆæœ¬é—®é¢˜ã€‚è¯¥æ¡†æ¶çš„æ ¸å¿ƒæ€æƒ³ä¹‹ä¸€æ˜¯é€šè¿‡å¯¹æ¯”é¢†å…ˆçš„æ¨ç† Large Language Models (LLMs) å»ºç«‹äº†ä¸€å¥—é€‰æ‹©æœ€ä¼˜æ•™å¸ˆæ¨¡å‹çš„æ–¹æ³•ï¼Œæ‰“ç ´äº†ä»…å‡­åŸºå‡†æµ‹è¯•åˆ†æ•°è¯„åˆ¤æ¨¡å‹èƒ½åŠ›çš„å±€é™ã€‚ä¸ºäº†å¹³è¡¡é¢†åŸŸå†…ä¸é¢†åŸŸå¤–èƒ½åŠ›ï¼ŒDED é‡‡ç”¨ç²¾å¿ƒç­›é€‰çš„å°è§„æ¨¡è¯­æ–™åº“è¿›è¡Œè’¸é¦ï¼Œæœ‰æ•ˆé¿å…äº†å¤§è§„æ¨¡æ•°æ®è’¸é¦å¯¼è‡´çš„æ³›åŒ–æ€§èƒ½é€€åŒ–ã€‚ç ”ç©¶è¿˜åˆ©ç”¨å¤šæ ·åŒ–çš„æ¨ç†è½¨è¿¹ (Reasoning Trajectories) ç­–ç•¥ï¼Œä¿ƒä½¿å­¦ç”Ÿæ¨¡å‹å»ºç«‹èµ·æ›´å…·é²æ£’æ€§çš„æ¨ç†æŠ€èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä»…éœ€ 0.8k ä¸ªç²¾å¿ƒç­–åˆ’çš„æ ·æœ¬ï¼Œè¯¥æ–¹æ³•åœ¨ AIME 2024/2025ã€MATH-500 å’Œ LiveCodeBench ç­‰æ•°å­¦æ¨ç†ä¸ä»£ç ç”Ÿæˆè¯„ä¼°ä¸­å‡è¾¾åˆ°äº† State-of-the-Art æ°´å¹³ã€‚ç³»ç»Ÿçš„åˆ†æè¯å®ï¼ŒDED åœ¨ä¸ä¾èµ–è¿‡åº¦æ‰©å±•è§„æ¨¡çš„æƒ…å†µä¸‹ï¼Œä¸ºæå‡æ¨¡å‹é«˜çº§æ¨ç†èƒ½åŠ›å¹¶ä¿æŒé€šç”¨æ€§èƒ½æä¾›äº†ä¸€æ¡é«˜æ•ˆä¸”å®ç”¨çš„è·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09883v1",
      "published_date": "2025-08-13 15:32:25 UTC",
      "updated_date": "2025-08-13 15:32:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:34:06.261032+00:00"
    },
    {
      "arxiv_id": "2508.09874v2",
      "title": "Memory Decoder: A Pretrained, Plug-and-Play Memory for Large Language Models",
      "title_zh": "Memory Decoderï¼šå¤§è¯­è¨€æ¨¡å‹çš„é¢„è®­ç»ƒå³æ’å³ç”¨å¼è®°å¿†æ¨¡å—",
      "authors": [
        "Jiaqi Cao",
        "Jiarui Wang",
        "Rubin Wei",
        "Qipeng Guo",
        "Kai Chen",
        "Bowen Zhou",
        "Zhouhan Lin"
      ],
      "abstract": "Large Language Models (LLMs) have shown strong abilities in general language tasks, yet adapting them to specific domains remains a challenge. Current method like Domain Adaptive Pretraining (DAPT) requires costly full-parameter training and suffers from catastrophic forgetting. Meanwhile, Retrieval-Augmented Generation (RAG) introduces substantial inference latency due to expensive nearest-neighbor searches and longer context. This paper introduces Memory Decoder, a plug-and-play pretrained memory that enables efficient domain adaptation without changing the original model's parameters. Memory Decoder employs a small transformer decoder that learns to imitate the behavior of an external non-parametric retriever. Once trained, Memory Decoder can be seamlessly integrated with any pretrained language model that shares the same tokenizer, requiring no model-specific modifications. Experimental results demonstrate that Memory Decoder enables effective adaptation of various Qwen and Llama models to three distinct specialized domains: biomedicine, finance, and law, reducing perplexity by an average of 6.17 points. Overall, Memory Decoder introduces a novel paradigm centered on a specially pretrained memory component designed for domain-specific adaptation. This memory architecture can be integrated in a plug-and-play manner, consistently enhancing performance across multiple models within the target domain.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Memory Decoderï¼Œè¿™æ˜¯ä¸€ç§ä¸º Large Language Models (LLMs) è®¾è®¡çš„é¢„è®­ç»ƒã€å³æ’å³ç”¨ (Plug-and-Play) å­˜å‚¨å™¨ï¼Œæ—¨åœ¨è§£å†³ç‰¹å®šé¢†åŸŸè‡ªé€‚åº”é¢ä¸´çš„æ•ˆç‡ä¸æ€§èƒ½æŒ‘æˆ˜ã€‚é’ˆå¯¹ Domain Adaptive Pretraining (DAPT) æˆæœ¬é«˜æ˜‚ä¸”æ˜“å¯¼è‡´é—å¿˜ï¼Œä»¥åŠ Retrieval-Augmented Generation (RAG) æ¨ç†å»¶è¿Ÿæ˜¾è‘—çš„é—®é¢˜ï¼ŒMemory Decoder é‡‡ç”¨ä¸€ä¸ªå°å‹ Transformer decoderï¼Œé€šè¿‡å­¦ä¹ æ¨¡ä»¿å¤–éƒ¨éå‚æ•°æ£€ç´¢å™¨çš„è¡Œä¸ºæ¥æä¾›é¢†åŸŸçŸ¥è¯†ã€‚è¯¥æ¶æ„æ— éœ€ä¿®æ”¹åŸæ¨¡å‹çš„å‚æ•°ï¼Œåªè¦æ¨¡å‹å…±äº«ç›¸åŒçš„ Tokenizerï¼Œå³å¯å®ç°æ— ç¼é›†æˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMemory Decoder èƒ½å¤ŸæˆåŠŸå°† Qwen å’Œ Llama ç­‰æ¨¡å‹é€‚é…è‡³ç”Ÿç‰©åŒ»å­¦ã€é‡‘èå’Œæ³•å¾‹é¢†åŸŸï¼Œä½¿ Perplexity å¹³å‡é™ä½äº† 6.17 ç‚¹ã€‚è¿™é¡¹å·¥ä½œä¸ºé¢†åŸŸè‡ªé€‚åº”å¼•å…¥äº†ä¸€ç§ä»¥ä¸“é—¨é¢„è®­ç»ƒå­˜å‚¨ç»„ä»¶ä¸ºæ ¸å¿ƒçš„æ–°èŒƒå¼ï¼Œè¯æ˜äº†å³æ’å³ç”¨å­˜å‚¨å™¨åœ¨æå‡å¤šæ¨¡å‹é¢†åŸŸæ€§èƒ½æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09874v2",
      "published_date": "2025-08-13 15:16:29 UTC",
      "updated_date": "2025-10-23 13:14:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:34:11.694416+00:00"
    },
    {
      "arxiv_id": "2508.14087v1",
      "title": "FM4NPP: A Scaling Foundation Model for Nuclear and Particle Physics",
      "title_zh": "FM4NPPï¼šæ ¸ç‰©ç†ä¸ç²’å­ç‰©ç†çš„å¯æ‰©å±•åŸºç¡€æ¨¡å‹",
      "authors": [
        "David Park",
        "Shuhang Li",
        "Yi Huang",
        "Xihaier Luo",
        "Haiwang Yu",
        "Yeonju Go",
        "Christopher Pinkenburg",
        "Yuewei Lin",
        "Shinjae Yoo",
        "Joseph Osborn",
        "Jin Huang",
        "Yihui Ren"
      ],
      "abstract": "Large language models have revolutionized artificial intelligence by enabling large, generalizable models trained through self-supervision. This paradigm has inspired the development of scientific foundation models (FMs). However, applying this capability to experimental particle physics is challenging due to the sparse, spatially distributed nature of detector data, which differs dramatically from natural language. This work addresses if an FM for particle physics can scale and generalize across diverse tasks. We introduce a new dataset with more than 11 million particle collision events and a suite of downstream tasks and labeled data for evaluation. We propose a novel self-supervised training method for detector data and demonstrate its neural scalability with models that feature up to 188 million parameters. With frozen weights and task-specific adapters, this FM consistently outperforms baseline models across all downstream tasks. The performance also exhibits robust data-efficient adaptation. Further analysis reveals that the representations extracted by the FM are task-agnostic but can be specialized via a single linear mapping for different downstream tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ ¸ä¸ç²’å­ç‰©ç†(Nuclear and Particle Physics)é¢†åŸŸæ¢æµ‹å™¨æ•°æ®é«˜åº¦ç¨€ç–ä¸”å‘ˆç©ºé—´åˆ†å¸ƒçš„ç‰¹æ€§ï¼Œæå‡ºäº†åä¸ºFM4NPPçš„å¯æ‰©å±•åŸºç¡€æ¨¡å‹(Foundation Model)ã€‚ä½œè€…æ„å»ºäº†ä¸€ä¸ªåŒ…å«è¶…è¿‡1100ä¸‡ä¸ªç²’å­ç¢°æ’äº‹ä»¶çš„å¤§è§„æ¨¡æ•°æ®é›†ï¼Œå¹¶æå‡ºäº†ä¸€ç§é’ˆå¯¹æ¢æµ‹å™¨æ•°æ®çš„æ–°é¢–è‡ªç›‘ç£è®­ç»ƒ(Self-supervised training)æ–¹æ³•ã€‚å®éªŒè¯æ˜è¯¥æ¨¡å‹å…·æœ‰è‰¯å¥½çš„ç¥ç»ç½‘ç»œå¯æ‰©å±•æ€§(Neural scalability)ï¼Œåœ¨å‚æ•°é‡è¾¾åˆ°1.88äº¿æ—¶ä»è¡¨ç°ä¼˜å¼‚ã€‚é€šè¿‡å†»ç»“æƒé‡(Frozen weights)å¹¶ç»“åˆä»»åŠ¡ç‰¹å®šé€‚é…å™¨(Task-specific adapters)ï¼Œè¯¥æ¨¡å‹åœ¨æ‰€æœ‰ä¸‹æ¸¸ä»»åŠ¡ä¸­å‡è¶…è¶Šäº†åŸºçº¿æ¨¡å‹ï¼Œå¹¶å±•ç¤ºäº†å‡ºè‰²çš„æ•°æ®é«˜æ•ˆé€‚åº”æ€§(Data-efficient adaptation)ã€‚è¿›ä¸€æ­¥åˆ†ææ­ç¤ºï¼ŒFM4NPPæå–çš„ç‰¹å¾å…·æœ‰ä»»åŠ¡æ— å…³æ€§(Task-agnostic)ï¼Œä»…éœ€é€šè¿‡ç®€å•çš„çº¿æ€§æ˜ å°„(Linear mapping)å³å¯é’ˆå¯¹ä¸åŒä»»åŠ¡è¿›è¡Œä¸“ä¸šåŒ–è°ƒæ•´ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "hep-ex"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14087v1",
      "published_date": "2025-08-13 15:05:06 UTC",
      "updated_date": "2025-08-13 15:05:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:34:19.391132+00:00"
    },
    {
      "arxiv_id": "2508.09860v1",
      "title": "Human-Aligned Procedural Level Generation Reinforcement Learning via Text-Level-Sketch Shared Representation",
      "title_zh": "åŸºäºæ–‡æœ¬-å…³å¡-è‰å›¾å…±äº«è¡¨ç¤ºçš„ä¸äººå¯¹é½è¿‡ç¨‹åŒ–å…³å¡ç”Ÿæˆå¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "In-Chang Baek",
        "Seoyoung Lee",
        "Sung-Hyun Kim",
        "Geumhwan Hwang",
        "KyungJoong Kim"
      ],
      "abstract": "Human-aligned AI is a critical component of co-creativity, as it enables models to accurately interpret human intent and generate controllable outputs that align with design goals in collaborative content creation. This direction is especially relevant in procedural content generation via reinforcement learning (PCGRL), which is intended to serve as a tool for human designers. However, existing systems often fall short of exhibiting human-centered behavior, limiting the practical utility of AI-driven generation tools in real-world design workflows. In this paper, we propose VIPCGRL (Vision-Instruction PCGRL), a novel deep reinforcement learning framework that incorporates three modalities-text, level, and sketches-to extend control modality and enhance human-likeness. We introduce a shared embedding space trained via quadruple contrastive learning across modalities and human-AI styles, and align the policy using an auxiliary reward based on embedding similarity. Experimental results show that VIPCGRL outperforms existing baselines in human-likeness, as validated by both quantitative metrics and human evaluations. The code and dataset will be available upon publication.",
      "tldr_zh": "åœ¨ååŒå†…å®¹åˆ›ä½œä¸­ï¼Œç°æœ‰çš„å¼ºåŒ–å­¦ä¹ ç¨‹åºåŒ–å†…å®¹ç”Ÿæˆ(PCGRL)ç³»ç»Ÿå¾€å¾€éš¾ä»¥å±•ç°ä»¥äººä¸ºä¸­å¿ƒçš„è¡Œä¸ºï¼Œé™åˆ¶äº†AIé©±åŠ¨ç”Ÿæˆå·¥å…·åœ¨å®é™…è®¾è®¡æµç¨‹ä¸­çš„å®ç”¨ä»·å€¼ã€‚è¯¥ç ”ç©¶æå‡ºäº†VIPCGRL (Vision-Instruction PCGRL)ï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„æ·±åº¦å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡æ•´åˆæ–‡æœ¬(text)ã€å…³å¡(level)å’Œè‰å›¾(sketches)ä¸‰ç§æ¨¡æ€æ¥æ‰©å±•æ§åˆ¶æ‰‹æ®µå¹¶å¢å¼ºäººç±»ç›¸ä¼¼æ€§ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†é€šè¿‡æ¨¡æ€é—´åŠäººç±»-AIé£æ ¼çš„å››é‡å¯¹æ¯”å­¦ä¹ (quadruple contrastive learning)è®­ç»ƒçš„å…±äº«åµŒå…¥ç©ºé—´(shared embedding space)ï¼Œå¹¶åˆ©ç”¨åŸºäºåµŒå…¥ç›¸ä¼¼æ€§çš„è¾…åŠ©å¥–åŠ±(auxiliary reward)æ¥å®ç°ç­–ç•¥å¯¹é½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒVIPCGRLåœ¨äººç±»ç›¸ä¼¼æ€§(human-likeness)æ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰çš„åŸºçº¿æ¨¡å‹ï¼Œå…¶æœ‰æ•ˆæ€§å·²é€šè¿‡å®šé‡æŒ‡æ ‡å’Œäººç±»è¯„ä¼°å¾—åˆ°å……åˆ†éªŒè¯ã€‚è¯¥æ–¹æ³•ä¸ºå®ç°ä¸äººç±»æ„å›¾é«˜åº¦å¯¹é½çš„å¯æ§å†…å®¹ç”Ÿæˆæä¾›äº†é‡è¦çš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 6 tables, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.09860v1",
      "published_date": "2025-08-13 14:52:14 UTC",
      "updated_date": "2025-08-13 14:52:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:34:27.087659+00:00"
    },
    {
      "arxiv_id": "2508.09853v2",
      "title": "STREAM (ChemBio): A Standard for Transparently Reporting Evaluations in AI Model Reports",
      "title_zh": "STREAM (ChemBio)ï¼šäººå·¥æ™ºèƒ½æ¨¡å‹æŠ¥å‘Šè¯„ä¼°é€æ˜åŒ–æŠ¥å‘Šæ ‡å‡†",
      "authors": [
        "Tegan McCaslin",
        "Jide Alaga",
        "Samira Nedungadi",
        "Seth Donoughe",
        "Tom Reed",
        "Rishi Bommasani",
        "Chris Painter",
        "Luca Righetti"
      ],
      "abstract": "Evaluations of dangerous AI capabilities are important for managing catastrophic risks. Public transparency into these evaluations - including what they test, how they are conducted, and how their results inform decisions - is crucial for building trust in AI development. We propose STREAM (A Standard for Transparently Reporting Evaluations in AI Model Reports), a standard to improve how model reports disclose evaluation results, initially focusing on chemical and biological (ChemBio) benchmarks. Developed in consultation with 23 experts across government, civil society, academia, and frontier AI companies, this standard is designed to (1) be a practical resource to help AI developers present evaluation results more clearly, and (2) help third parties identify whether model reports provide sufficient detail to assess the rigor of the ChemBio evaluations. We concretely demonstrate our proposed best practices with \"gold standard\" examples, and also provide a three-page reporting template to enable AI developers to implement our recommendations more easily.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†STREAMï¼ˆA Standard for Transparently Reporting Evaluations in AI Model Reportsï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨æå‡äººå·¥æ™ºèƒ½æ¨¡å‹æŠ¥å‘Šä¸­è¯„ä¼°ç»“æœé€æ˜åº¦çš„æ ‡å‡†ï¼ŒåˆæœŸä¼˜å…ˆåº”ç”¨äºåŒ–å­¦å’Œç”Ÿç‰©ï¼ˆChemBioï¼‰åŸºå‡†æµ‹è¯•ã€‚è¯¥æ ‡å‡†çš„å¼€å‘æ—¨åœ¨é€šè¿‡å…¬å¼€è¯„ä¼°å†…å®¹ã€æ‰§è¡Œæ–¹å¼åŠç»“æœå†³ç­–ï¼Œè§£å†³ç®¡ç†AIç¾éš¾æ€§é£é™©åŠå»ºç«‹å¼€å‘ä¿¡ä»»çš„å…³é”®é—®é¢˜ã€‚STREAMç”±æ¥è‡ªæ”¿åºœã€å­¦æœ¯ç•Œå’Œé¢†å†›AIå…¬å¸çš„23ä½ä¸“å®¶åä½œåˆ¶å®šï¼Œç¡®ä¿äº†å…¶ä½œä¸ºå¼€å‘è€…å®ç”¨èµ„æºçš„æƒå¨æ€§ã€‚è¯¥æ ‡å‡†èƒ½å¤Ÿå¸®åŠ©å¼€å‘è€…æ¸…æ™°å‘ˆç°è¯„ä¼°æ•°æ®ï¼Œå¹¶æ”¯æŒç¬¬ä¸‰æ–¹å¯¹ ChemBio è¯„ä¼°çš„ä¸¥è°¨ç¨‹åº¦è¿›è¡Œç»†èŠ‚å®¡æŸ¥ã€‚ç ”ç©¶ä¸­è¿˜æä¾›äº†â€œé»„é‡‘æ ‡å‡†â€ï¼ˆgold standardï¼‰ç¤ºä¾‹ä»¥åŠä¸€ä»½ä¸‰é¡µçš„æŠ¥å‘Šæ¨¡æ¿ï¼Œæ—¨åœ¨ç®€åŒ–AIå¼€å‘è€…å¯¹è¯¥æ ‡å‡†çš„å®æ–½æµç¨‹ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "47 pages, 1 figure. Includes appendices and reporting template",
      "pdf_url": "https://arxiv.org/pdf/2508.09853v2",
      "published_date": "2025-08-13 14:36:36 UTC",
      "updated_date": "2025-09-03 12:52:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:34:44.594278+00:00"
    },
    {
      "arxiv_id": "2508.09852v1",
      "title": "Perceptual Reality Transformer: Neural Architectures for Simulating Neurological Perception Conditions",
      "title_zh": "Perceptual Reality Transformerï¼šç”¨äºæ¨¡æ‹Ÿç¥ç»ç³»ç»Ÿæ„ŸçŸ¥éšœç¢çš„ç¥ç»ç½‘ç»œæ¶æ„",
      "authors": [
        "Baihan Lin"
      ],
      "abstract": "Neurological conditions affecting visual perception create profound experiential divides between affected individuals and their caregivers, families, and medical professionals. We present the Perceptual Reality Transformer, a comprehensive framework employing six distinct neural architectures to simulate eight neurological perception conditions with scientifically-grounded visual transformations. Our system learns mappings from natural images to condition-specific perceptual states, enabling others to experience approximations of simultanagnosia, prosopagnosia, ADHD attention deficits, visual agnosia, depression-related changes, anxiety tunnel vision, and Alzheimer's memory effects. Through systematic evaluation across ImageNet and CIFAR-10 datasets, we demonstrate that Vision Transformer architectures achieve optimal performance, outperforming traditional CNN and generative approaches. Our work establishes the first systematic benchmark for neurological perception simulation, contributes novel condition-specific perturbation functions grounded in clinical literature, and provides quantitative metrics for evaluating simulation fidelity. The framework has immediate applications in medical education, empathy training, and assistive technology development, while advancing our fundamental understanding of how neural networks can model atypical human perception.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Perceptual Reality Transformerï¼Œè¿™æ˜¯ä¸€ä¸ªåˆ©ç”¨å…­ç§ç¥ç»ç½‘ç»œæ¶æ„æ¥æ¨¡æ‹Ÿå…«ç§ç¥ç»çŸ¥è§‰çŠ¶å†µ (Neurological Perception Conditions) çš„ç»¼åˆæ¡†æ¶ï¼Œæ—¨åœ¨å¼¥åˆæ‚£è€…ä¸å…¶çœ‹æŠ¤è€…ä¹‹é—´çš„ä½“éªŒé¸¿æ²Ÿã€‚è¯¥ç³»ç»Ÿå®ç°äº†ä»è‡ªç„¶å›¾åƒåˆ°ç‰¹å®šçŸ¥è§‰çŠ¶æ€çš„æ˜ å°„ï¼Œèƒ½å¤Ÿç²¾ç¡®æ¨¡æ‹ŸåŒæ—¶å¤±è®¤ç—‡ (simultanagnosia)ã€é¢å­”å¤±è®¤ç—‡ (prosopagnosia)ã€ADHD æ³¨æ„åŠ›ç¼ºé™·ã€è§†è§‰å¤±è®¤ç—‡ (visual agnosia) ä»¥åŠæŠ‘éƒå’Œç„¦è™‘ç›¸å…³çš„è§†è§‰æ”¹å˜ã€‚é€šè¿‡åœ¨ ImageNet å’Œ CIFAR-10 æ•°æ®é›†ä¸Šçš„ç³»ç»Ÿè¯„ä¼°ï¼Œç ”ç©¶å‘ç° Vision Transformer æ¶æ„åœ¨æ¨¡æ‹Ÿå¿ å®åº¦ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„ CNN å’Œç”Ÿæˆæ¨¡å‹ã€‚è¯¥å·¥ä½œå»ºç«‹äº†é¦–ä¸ªç¥ç»çŸ¥è§‰æ¨¡æ‹Ÿçš„ç³»ç»ŸåŸºå‡† (benchmark)ï¼Œå¹¶åŸºäºä¸´åºŠæ–‡çŒ®è´¡çŒ®äº†æ–°é¢–çš„æ‰°åŠ¨å‡½æ•° (perturbation functions) å’Œé‡åŒ–è¯„ä¼°æŒ‡æ ‡ã€‚è¿™é¡¹ç ”ç©¶ä¸ä»…æå‡äº†åˆ©ç”¨ç¥ç»ç½‘ç»œå¯¹éå…¸å‹äººç±»æ„ŸçŸ¥è¿›è¡Œå»ºæ¨¡çš„åŸºç¡€ç†è§£ï¼Œåœ¨åŒ»å­¦æ•™è‚²ã€å…±æƒ…è®­ç»ƒå’Œè¾…åŠ©æŠ€æœ¯å¼€å‘æ–¹é¢ä¹Ÿå…·æœ‰é‡è¦çš„åº”ç”¨ä»·å€¼ã€‚",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.CV",
        "cs.NE"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09852v1",
      "published_date": "2025-08-13 14:34:33 UTC",
      "updated_date": "2025-08-13 14:34:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:34:48.788805+00:00"
    },
    {
      "arxiv_id": "2508.09848v2",
      "title": "PRELUDE: A Benchmark Designed to Require Global Comprehension and Reasoning over Long Contexts",
      "title_zh": "PRELUDEï¼šé¢å‘å…¨å±€ç†è§£ä¸é•¿ä¸Šä¸‹æ–‡æ¨ç†çš„è¯„æµ‹åŸºå‡†",
      "authors": [
        "Mo Yu",
        "Tsz Ting Chung",
        "Chulun Zhou",
        "Tong Li",
        "Rui Lu",
        "Jiangnan Li",
        "Liyan Xu",
        "Haoshu Lu",
        "Ning Zhang",
        "Jing Li",
        "Jie Zhou"
      ],
      "abstract": "We introduce PRELUDE, a benchmark for evaluating long-context understanding through the task of determining whether a character's prequel story is consistent with the canonical narrative of the original book. Our task poses a stronger demand for global comprehension and deep reasoning than existing benchmarks -- as the prequels are not part of the original story, assessing their plausibility typically requires searching and integrating information that is only indirectly related. Empirically, 88% of instances require evidence from multiple parts of the narrative. Experimental results highlight the challenge of our task: in-context learning, RAG and in-domain training with state-of-the-art LLMs, and commercial DeepResearch services, lag behind humans by >15%. A further human study reveals that models often produce correct answers with flawed reasoning, leading to an over 30% gap in reasoning accuracy compared to humans. These findings underscore the substantial room for improvement in long-context understanding and reasoning.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† PRELUDEï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨è¯„ä¼°é•¿æ–‡æœ¬ç†è§£(long-context understanding)èƒ½åŠ›çš„åŸºå‡†æµ‹è¯•ï¼Œé€šè¿‡åˆ¤æ–­è§’è‰²çš„å‰ä¼ æ•…äº‹æ˜¯å¦ä¸åŸè‘—æ­£å…¸å™äº‹ä¸€è‡´æ¥è€ƒå¯Ÿæ¨¡å‹ã€‚ç›¸è¾ƒäºç°æœ‰åŸºå‡†ï¼ŒPRELUDE å¯¹å…¨å±€ç†è§£(global comprehension)å’Œæ·±åº¦æ¨ç†æå‡ºäº†æ›´é«˜è¦æ±‚ï¼Œå› ä¸ºè¯„ä¼°å‰ä¼ åˆç†æ€§é€šå¸¸éœ€è¦æ•´åˆå™è¿°ä¸­å¤šä¸ªéƒ¨åˆ†çš„é—´æ¥ä¿¡æ¯ï¼Œä¸” 88% çš„å®ä¾‹æ¶‰åŠè·¨æ®µè½è¯æ®ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œå³ä½¿æ˜¯é‡‡ç”¨ä¸Šä¸‹æ–‡å­¦ä¹ (in-context learning)ã€æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)æˆ–é¢†åŸŸå†…è®­ç»ƒçš„å…ˆè¿›å¤§è¯­è¨€æ¨¡å‹(LLMs)ä»¥åŠå•†ä¸š DeepResearch æœåŠ¡ï¼Œå…¶è¡¨ç°ä»è½åäºäººç±» 15% ä»¥ä¸Šã€‚è¿›ä¸€æ­¥çš„äººç±»ç ”ç©¶æ­ç¤ºï¼Œæ¨¡å‹ç»å¸¸é€šè¿‡é”™è¯¯çš„æ¨ç†å¾—å‡ºæ­£ç¡®ç­”æ¡ˆï¼Œåœ¨æ¨ç†å‡†ç¡®æ€§ä¸Šä¸äººç±»å­˜åœ¨è¶…è¿‡ 30% çš„å·®è·ã€‚è¿™äº›å‘ç°è¡¨æ˜ï¼Œå½“å‰æ¨¡å‹åœ¨å¤„ç†å¤æ‚é•¿æ–‡æœ¬çš„å…¨å±€ç†è§£ä¸é€»è¾‘æ¨ç†æ–¹é¢ä»æœ‰å·¨å¤§çš„æå‡ç©ºé—´ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "First 7 authors contributed equally. Project page: https://gorov.github.io/prelude",
      "pdf_url": "https://arxiv.org/pdf/2508.09848v2",
      "published_date": "2025-08-13 14:28:25 UTC",
      "updated_date": "2025-08-14 02:08:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:34:52.561511+00:00"
    },
    {
      "arxiv_id": "2508.09834v1",
      "title": "Speed Always Wins: A Survey on Efficient Architectures for Large Language Models",
      "title_zh": "å”¯å¿«ä¸ç ´ï¼šå¤§è¯­è¨€æ¨¡å‹é«˜æ•ˆæ¶æ„ç»¼è¿°",
      "authors": [
        "Weigao Sun",
        "Jiaxi Hu",
        "Yucheng Zhou",
        "Jusen Du",
        "Disen Lan",
        "Kexin Wang",
        "Tong Zhu",
        "Xiaoye Qu",
        "Yu Zhang",
        "Xiaoyu Mo",
        "Daizong Liu",
        "Yuxuan Liang",
        "Wenliang Chen",
        "Guoqi Li",
        "Yu Cheng"
      ],
      "abstract": "Large Language Models (LLMs) have delivered impressive results in language understanding, generation, reasoning, and pushes the ability boundary of multimodal models. Transformer models, as the foundation of modern LLMs, offer a strong baseline with excellent scaling properties. However, the traditional transformer architecture requires substantial computations and poses significant obstacles for large-scale training and practical deployment. In this survey, we offer a systematic examination of innovative LLM architectures that address the inherent limitations of transformers and boost the efficiency. Starting from language modeling, this survey covers the background and technical details of linear and sparse sequence modeling methods, efficient full attention variants, sparse mixture-of-experts, hybrid model architectures incorporating the above techniques, and emerging diffusion LLMs. Additionally, we discuss applications of these techniques to other modalities and consider their wider implications for developing scalable, resource-aware foundation models. By grouping recent studies into the above category, this survey presents a blueprint of modern efficient LLM architectures, and we hope this could help motivate future research toward more efficient, versatile AI systems.",
      "tldr_zh": "è¯¥ç»¼è¿°ç³»ç»Ÿæ€§åœ°æ¢è®¨äº†æ—¨åœ¨æé«˜å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ•ˆç‡çš„åˆ›æ–°æ¶æ„ï¼Œä»¥åº”å¯¹ä¼ ç»Ÿ Transformer æ¶æ„åœ¨è®¡ç®—é‡å’Œéƒ¨ç½²æ–¹é¢çš„å±€é™æ€§ã€‚æ–‡ç« ä»è¯­è¨€å»ºæ¨¡èƒŒæ™¯å‡ºå‘ï¼Œè¯¦ç»†æ¶µç›–äº†çº¿æ€§ï¼ˆlinearï¼‰å’Œç¨€ç–ï¼ˆsparseï¼‰åºåˆ—å»ºæ¨¡æ–¹æ³•ã€é«˜æ•ˆçš„å…¨æ³¨æ„åŠ›æœºåˆ¶ï¼ˆfull attentionï¼‰å˜ä½“ä»¥åŠç¨€ç–ä¸“å®¶æ··åˆæ¨¡å‹ï¼ˆsparse mixture-of-experts, MoEï¼‰çš„æŠ€æœ¯ç»†èŠ‚ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜æ·±å…¥åˆ†æäº†èåˆå¤šç§æŠ€æœ¯çš„æ··åˆæ¶æ„ï¼ˆhybrid architecturesï¼‰ä»¥åŠæ–°å…´çš„æ‰©æ•£å¤§è¯­è¨€æ¨¡å‹ï¼ˆdiffusion LLMsï¼‰çš„è¡¨ç°ã€‚è¯¥ç»¼è¿°è¿›ä¸€æ­¥è®¨è®ºäº†è¿™äº›é«˜æ•ˆæŠ€æœ¯åœ¨å¤šæ¨¡æ€é¢†åŸŸçš„åº”ç”¨ï¼Œå¹¶æ¢è®¨äº†å…¶å¯¹æ„å»ºå¯æ‰©å±•ä¸”èµ„æºæ„ŸçŸ¥çš„åŸºåº§æ¨¡å‹ï¼ˆfoundation modelsï¼‰çš„æ„ä¹‰ã€‚é€šè¿‡å¯¹è¿‘æœŸç›¸å…³ç ”ç©¶çš„åˆ†ç±»å½’çº³ï¼Œæœ¬æ–‡ä¸ºç°ä»£é«˜æ•ˆ LLM æ¶æ„ç»˜åˆ¶äº†æŠ€æœ¯è“å›¾ï¼Œæ—¨åœ¨æ¨åŠ¨æœªæ¥æ›´å…·æ•ˆç‡å’Œé€šç”¨æ€§çš„äººå·¥æ™ºèƒ½ç³»ç»Ÿç ”ç©¶ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "Survey, 82 pages, GitHub: https://github.com/weigao266/Awesome-Efficient-Arch",
      "pdf_url": "https://arxiv.org/pdf/2508.09834v1",
      "published_date": "2025-08-13 14:13:46 UTC",
      "updated_date": "2025-08-13 14:13:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:34:56.943704+00:00"
    },
    {
      "arxiv_id": "2508.09832v1",
      "title": "Exploring the Potential of Large Language Models in Fine-Grained Review Comment Classification",
      "title_zh": "æ¢ç©¶å¤§è¯­è¨€æ¨¡å‹åœ¨ç»†ç²’åº¦è¯„å®¡æ„è§åˆ†ç±»ä¸­çš„æ½œåŠ›",
      "authors": [
        "Linh Nguyen",
        "Chunhua Liu",
        "Hong Yi Lin",
        "Patanamon Thongtanunam"
      ],
      "abstract": "Code review is a crucial practice in software development. As code review nowadays is lightweight, various issues can be identified, and sometimes, they can be trivial. Research has investigated automated approaches to classify review comments to gauge the effectiveness of code reviews. However, previous studies have primarily relied on supervised machine learning, which requires extensive manual annotation to train the models effectively. To address this limitation, we explore the potential of using Large Language Models (LLMs) to classify code review comments. We assess the performance of LLMs to classify 17 categories of code review comments. Our results show that LLMs can classify code review comments, outperforming the state-of-the-art approach using a trained deep learning model. In particular, LLMs achieve better accuracy in classifying the five most useful categories, which the state-of-the-art approach struggles with due to low training examples. Rather than relying solely on a specific small training data distribution, our results show that LLMs provide balanced performance across high- and low-frequency categories. These results suggest that the LLMs could offer a scalable solution for code review analytics to improve the effectiveness of the code review process.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ (Large Language Models, LLMs) è¿›è¡Œç»†ç²’åº¦ä»£ç å®¡æŸ¥è¯„è®ºåˆ†ç±»çš„æ½œåŠ›ï¼Œä»¥è§£å†³ä¼ ç»Ÿç›‘ç£å­¦ä¹ æ–¹æ³•ä¾èµ–å¤§é‡äººå·¥æ ‡æ³¨çš„é—®é¢˜ã€‚é€šè¿‡å¯¹ 17 ç±»ä»£ç å®¡æŸ¥è¯„è®ºè¿›è¡Œåˆ†ç±»è¯„ä¼°ï¼Œç»“æœè¡¨æ˜ LLMs çš„è¡¨ç°ä¼˜äºç°æœ‰çš„æ·±åº¦å­¦ä¹  SOTA æ–¹æ³•ã€‚ç‰¹åˆ«æ˜¯åœ¨ç”±äºè®­ç»ƒæ ·æœ¬ç¨€ç¼ºå¯¼è‡´ä¼ ç»Ÿæ¨¡å‹éš¾ä»¥å¤„ç†çš„äº”ä¸ªæœ€æœ‰ç”¨ç±»åˆ«ä¸­ï¼ŒLLMs å–å¾—äº†æ˜¾è‘—æ›´é«˜çš„å‡†ç¡®ç‡ã€‚ä¸å—é™äºç‰¹å®šè®­ç»ƒæ•°æ®åˆ†å¸ƒçš„ä¼ ç»Ÿæ¨¡å‹ä¸åŒï¼ŒLLMs åœ¨é«˜é¢‘å’Œä½é¢‘ç±»åˆ«ä¹‹é—´å±•ç°äº†æ›´ä¸ºå‡è¡¡çš„åˆ†ç±»æ€§èƒ½ã€‚è¿™é¡¹ç ”ç©¶è¯æ˜äº† LLMs ä½œä¸ºä¸€ç§å¯æ‰©å±•çš„è§£å†³æ–¹æ¡ˆï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡ä»£ç å®¡æŸ¥è¿‡ç¨‹çš„æ•ˆç‡å¹¶ä¼˜åŒ–ç›¸å…³åˆ†æå·¥ä½œã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted at 2025 IEEE International Conference on Source Code Analysis & Manipulation (SCAM)",
      "pdf_url": "https://arxiv.org/pdf/2508.09832v1",
      "published_date": "2025-08-13 14:07:05 UTC",
      "updated_date": "2025-08-13 14:07:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:34:54.841709+00:00"
    },
    {
      "arxiv_id": "2508.09830v1",
      "title": "RayletDF: Raylet Distance Fields for Generalizable 3D Surface Reconstruction from Point Clouds or Gaussians",
      "title_zh": "RayletDFï¼šåŸºäº Raylet è·ç¦»åœºçš„å¯æ³›åŒ–ç‚¹äº‘æˆ–é«˜æ–¯ä¸‰ç»´è¡¨é¢é‡å»º",
      "authors": [
        "Shenxing Wei",
        "Jinxi Li",
        "Yafei Yang",
        "Siyuan Zhou",
        "Bo Yang"
      ],
      "abstract": "In this paper, we present a generalizable method for 3D surface reconstruction from raw point clouds or pre-estimated 3D Gaussians by 3DGS from RGB images. Unlike existing coordinate-based methods which are often computationally intensive when rendering explicit surfaces, our proposed method, named RayletDF, introduces a new technique called raylet distance field, which aims to directly predict surface points from query rays. Our pipeline consists of three key modules: a raylet feature extractor, a raylet distance field predictor, and a multi-raylet blender. These components work together to extract fine-grained local geometric features, predict raylet distances, and aggregate multiple predictions to reconstruct precise surface points. We extensively evaluate our method on multiple public real-world datasets, demonstrating superior performance in surface reconstruction from point clouds or 3D Gaussians. Most notably, our method achieves exceptional generalization ability, successfully recovering 3D surfaces in a single-forward pass across unseen datasets in testing.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† RayletDFï¼Œè¿™æ˜¯ä¸€ç§é’ˆå¯¹åŸå§‹ Point Clouds æˆ–é€šè¿‡ 3DGS ä» RGB å›¾åƒé¢„ä¼°çš„ 3D Gaussians è¿›è¡Œé€šç”¨ 3D Surface Reconstruction çš„æ–¹æ³•ã€‚ä¸åŒäºè®¡ç®—å¯†é›†å‹çš„åŸºäºåæ ‡ (coordinate-based) çš„ç°æœ‰æ–¹æ³•ï¼ŒRayletDF å¼•å…¥äº† Raylet Distance Field æŠ€æœ¯ï¼Œæ—¨åœ¨ç›´æ¥ä»æŸ¥è¯¢å°„çº¿ (query rays) ä¸­é¢„æµ‹è¡¨é¢ç‚¹ã€‚è¯¥ç®¡çº¿ç”± Raylet Feature Extractorã€Raylet Distance Field Predictor å’Œ Multi-Raylet Blender ä¸‰ä¸ªæ ¸å¿ƒæ¨¡å—ç»„æˆï¼Œé€šè¿‡æå–ç»†ç²’åº¦å±€éƒ¨å‡ ä½•ç‰¹å¾å¹¶èšåˆå¤šé‡é¢„æµ‹æ¥å®ç°ç²¾ç¡®çš„è¡¨é¢é‡å»ºã€‚åœ¨å¤šä¸ªå…¬å¼€çœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤„ç†ç‚¹äº‘æˆ– 3D Gaussians æ—¶å‡å…·æœ‰ä¼˜å¼‚çš„æ€§èƒ½ã€‚æœ€æ˜¾è‘—çš„æ˜¯ï¼ŒRayletDF å±•ç°äº†å“è¶Šçš„æ³›åŒ–èƒ½åŠ› (generalization ability)ï¼Œèƒ½å¤Ÿåœ¨å•æ¬¡å‰å‘ä¼ é€’ (single-forward pass) ä¸­æˆåŠŸæ¢å¤æœªè§æ•°æ®é›†çš„ 3D è¡¨é¢ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "ICCV 2025 Highlight. Shenxing and Jinxi are co-first authors. Code and data are available at: https://github.com/vLAR-group/RayletDF",
      "pdf_url": "https://arxiv.org/pdf/2508.09830v1",
      "published_date": "2025-08-13 14:05:21 UTC",
      "updated_date": "2025-08-13 14:05:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:35:09.750043+00:00"
    },
    {
      "arxiv_id": "2508.09820v1",
      "title": "Provable In-Context Vector Arithmetic via Retrieving Task Concepts",
      "title_zh": "é€šè¿‡æ£€ç´¢ä»»åŠ¡æ¦‚å¿µå®ç°çš„å¯è¯æ˜ä¸Šä¸‹æ–‡å‘é‡è¿ç®—",
      "authors": [
        "Dake Bu",
        "Wei Huang",
        "Andi Han",
        "Atsushi Nitanda",
        "Qingfu Zhang",
        "Hau-San Wong",
        "Taiji Suzuki"
      ],
      "abstract": "In-context learning (ICL) has garnered significant attention for its ability to grasp functions/tasks from demonstrations. Recent studies suggest the presence of a latent task/function vector in LLMs during ICL. Merullo et al. (2024) showed that LLMs leverage this vector alongside the residual stream for Word2Vec-like vector arithmetic, solving factual-recall ICL tasks. Additionally, recent work empirically highlighted the key role of Question-Answer data in enhancing factual-recall capabilities. Despite these insights, a theoretical explanation remains elusive. To move one step forward, we propose a theoretical framework building on empirically grounded hierarchical concept modeling. We develop an optimization theory, showing how nonlinear residual transformers trained via gradient descent on cross-entropy loss perform factual-recall ICL tasks via vector arithmetic. We prove 0-1 loss convergence and show the strong generalization, including robustness to concept recombination and distribution shifts. These results elucidate the advantages of transformers over static embedding predecessors. Empirical simulations corroborate our theoretical insights.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº† In-context learning (ICL) ä¸­æ½œåœ¨ä»»åŠ¡å‘é‡çš„å½¢æˆæœºåˆ¶ï¼Œç‰¹åˆ«é’ˆå¯¹é€šè¿‡å‘é‡ç®—æœ¯ (vector arithmetic) è§£å†³äº‹å®å¬å› (factual-recall) ä»»åŠ¡çš„ç°è±¡ã€‚é’ˆå¯¹ç°æœ‰å®è¯ç ”ç©¶ç¼ºä¹ç†è®ºè§£é‡Šçš„é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ä¸ªåŸºäºå±‚æ¬¡åŒ–æ¦‚å¿µå»ºæ¨¡ (hierarchical concept modeling) çš„ç†è®ºæ¡†æ¶ã€‚ç ”ç©¶é€šè¿‡ä¼˜åŒ–ç†è®ºè¯æ˜äº†åœ¨äº¤å‰ç†µæŸå¤± (cross-entropy loss) ä¸‹åˆ©ç”¨æ¢¯åº¦ä¸‹é™ (gradient descent) è®­ç»ƒçš„éçº¿æ€§æ®‹å·® Transformers èƒ½å¤Ÿé€šè¿‡å‘é‡ç®—æœ¯æ‰§è¡Œ ICL ä»»åŠ¡ã€‚ä½œè€…è¿›ä¸€æ­¥è¯æ˜äº† 0-1 æŸå¤±å‡½æ•°çš„æ”¶æ•›æ€§ï¼Œå¹¶å±•ç¤ºäº†æ¨¡å‹åœ¨æ¦‚å¿µé‡ç»„ (concept recombination) å’Œåˆ†å¸ƒåç§» (distribution shifts) ä¸‹çš„å¼ºå¤§æ³›åŒ–èƒ½åŠ›ä¸é²æ£’æ€§ã€‚è¿™äº›ç»“æœé˜æ˜äº† Transformers ç›¸å¯¹äºä¼ ç»Ÿé™æ€åµŒå…¥ (static embedding) æ¨¡å‹çš„ä¼˜åŠ¿ï¼Œä¸”å®è¯æ¨¡æ‹Ÿå®éªŒè¿›ä¸€æ­¥è¯å®äº†ä¸Šè¿°ç†è®ºè§è§£ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by the 42nd International Conference on Machine Learning (ICML 2025)",
      "pdf_url": "https://arxiv.org/pdf/2508.09820v1",
      "published_date": "2025-08-13 13:54:44 UTC",
      "updated_date": "2025-08-13 13:54:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:35:03.089953+00:00"
    },
    {
      "arxiv_id": "2508.09811v1",
      "title": "TRACE: Learning 3D Gaussian Physical Dynamics from Multi-view Videos",
      "title_zh": "TRACEï¼šä»å¤šè§†è§’è§†é¢‘ä¸­å­¦ä¹  3D é«˜æ–¯ç‰©ç†åŠ¨åŠ›å­¦",
      "authors": [
        "Jinxi Li",
        "Ziyang Song",
        "Bo Yang"
      ],
      "abstract": "In this paper, we aim to model 3D scene geometry, appearance, and physical information just from dynamic multi-view videos in the absence of any human labels. By leveraging physics-informed losses as soft constraints or integrating simple physics models into neural nets, existing works often fail to learn complex motion physics, or doing so requires additional labels such as object types or masks. We propose a new framework named TRACE to model the motion physics of complex dynamic 3D scenes. The key novelty of our method is that, by formulating each 3D point as a rigid particle with size and orientation in space, we directly learn a translation rotation dynamics system for each particle, explicitly estimating a complete set of physical parameters to govern the particle's motion over time. Extensive experiments on three existing dynamic datasets and one newly created challenging synthetic datasets demonstrate the extraordinary performance of our method over baselines in the task of future frame extrapolation. A nice property of our framework is that multiple objects or parts can be easily segmented just by clustering the learned physical parameters.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† TRACE æ¡†æ¶ï¼Œæ—¨åœ¨æ— éœ€äººå·¥æ ‡æ³¨çš„æƒ…å†µä¸‹ï¼Œç›´æ¥ä»åŠ¨æ€å¤šè§†è§’è§†é¢‘ä¸­å»ºæ¨¡ 3D åœºæ™¯çš„å‡ ä½•ã€å¤–è§‚å’Œç‰©ç†åŠ¨åŠ›å­¦ä¿¡æ¯ã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•åœ¨æ¨¡æ‹Ÿå¤æ‚è¿åŠ¨ç‰©ç†æ—¶é¢ä¸´çš„ç²¾åº¦ä¸è¶³æˆ–ä¾èµ–é¢å¤–æ ‡ç­¾ï¼ˆå¦‚ç‰©ä½“ç±»å‹æˆ–æ©ç ï¼‰çš„é—®é¢˜ï¼ŒTRACE å°†æ¯ä¸ª 3D ç‚¹å»ºæ¨¡ä¸ºå…·æœ‰ç©ºé—´å°ºå¯¸å’Œæ–¹å‘çš„åˆšæ€§ç²’å­ (rigid particle)ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºä¸ºæ¯ä¸ªç²’å­ç›´æ¥å­¦ä¹ ä¸€ä¸ªå¹³ç§»æ—‹è½¬åŠ¨åŠ›å­¦ç³»ç»Ÿ (translation rotation dynamics system)ï¼Œå¹¶æ˜¾å¼ä¼°è®¡å®Œæ•´çš„ç‰©ç†å‚æ•°é›†ä»¥æ§åˆ¶ç²’å­éšæ—¶é—´çš„è¿åŠ¨ã€‚å®éªŒç»“æœåœ¨å¤šä¸ªåŠ¨æ€æ•°æ®é›†åŠæ–°åˆ›å»ºçš„åˆæˆæ•°æ®é›†ä¸Šè¯æ˜ï¼ŒTRACE åœ¨æœªæ¥å¸§å¤–æ¨ (future frame extrapolation) ä»»åŠ¡ä¸­è¡¨ç°å“è¶Šã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶çš„ä¸€ä¸ªé‡è¦ç‰¹æ€§æ˜¯ï¼Œä»…é€šè¿‡å¯¹å­¦ä¹ åˆ°çš„ç‰©ç†å‚æ•°è¿›è¡Œèšç±»ï¼Œå³å¯è½»æ¾å®ç°å¯¹åœºæ™¯ä¸­å¤šä¸ªç‰©ä½“æˆ–éƒ¨ä»¶çš„è‡ªåŠ¨åˆ†å‰²ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CE",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "ICCV 2025. Code and data are available at: https://github.com/vLAR-group/TRACE",
      "pdf_url": "https://arxiv.org/pdf/2508.09811v1",
      "published_date": "2025-08-13 13:43:01 UTC",
      "updated_date": "2025-08-13 13:43:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:35:09.159049+00:00"
    },
    {
      "arxiv_id": "2508.09809v2",
      "title": "A Comprehensive Review of Datasets for Clinical Mental Health AI Systems",
      "title_zh": "ä¸´åºŠç²¾ç¥å¥åº·äººå·¥æ™ºèƒ½ç³»ç»Ÿæ•°æ®é›†å…¨é¢ç»¼è¿°",
      "authors": [
        "Aishik Mandal",
        "Prottay Kumar Adhikary",
        "Hiba Arnaout",
        "Iryna Gurevych",
        "Tanmoy Chakraborty"
      ],
      "abstract": "Mental health disorders are rising worldwide. However, the availability of trained clinicians has not scaled proportionally, leaving many people without adequate or timely support. To bridge this gap, recent studies have shown the promise of Artificial Intelligence (AI) to assist mental health diagnosis, monitoring, and intervention. However, the development of efficient, reliable, and ethical AI to assist clinicians is heavily dependent on high-quality clinical training datasets. Despite growing interest in data curation for training clinical AI assistants, existing datasets largely remain scattered, under-documented, and often inaccessible, hindering the reproducibility, comparability, and generalizability of AI models developed for clinical mental health care. In this paper, we present the first comprehensive survey of clinical mental health datasets relevant to the training and development of AI-powered clinical assistants. We categorize these datasets by mental disorders (e.g., depression, schizophrenia), data modalities (e.g., text, speech, physiological signals), task types (e.g., diagnosis prediction, symptom severity estimation, intervention generation), accessibility (public, restricted or private), and sociocultural context (e.g., language and cultural background). Along with these, we also investigate synthetic clinical mental health datasets. Our survey identifies critical gaps such as a lack of longitudinal data, limited cultural and linguistic representation, inconsistent collection and annotation standards, and a lack of modalities in synthetic data. We conclude by outlining key challenges in curating and standardizing future datasets and provide actionable recommendations to facilitate the development of more robust, generalizable, and equitable mental health AI systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å…¨çƒå¿ƒç†å¥åº·éœ€æ±‚å¢é•¿ä¸ä¸“ä¸šä¸´åºŠåŒ»ç”ŸçŸ­ç¼ºçš„ç°çŠ¶ï¼Œå¯¹ç”¨äºä¸´åºŠå¿ƒç†å¥åº· Artificial Intelligence (AI) ç³»ç»Ÿçš„è®­ç»ƒæ•°æ®é›†è¿›è¡Œäº†é¦–æ¬¡å…¨é¢ç»¼è¿°ã€‚è®ºæ–‡æŒ‡å‡ºï¼Œè™½ç„¶ AI åœ¨è¾…åŠ©è¯Šæ–­ã€ç›‘æµ‹å’Œå¹²é¢„æ–¹é¢å…·æœ‰æ½œåŠ›ï¼Œä½†ç°æœ‰çš„ä¸´åºŠæ•°æ®é›†ä»é¢ä¸´åˆ†æ•£ã€è®°å½•ä¸è¶³ä¸”éš¾ä»¥è·å–ç­‰æŒ‘æˆ˜ï¼Œé˜»ç¢äº†æ¨¡å‹çš„é‡ç°æ€§ä¸æ³›åŒ–æ€§ã€‚ç ”ç©¶å›¢é˜Ÿä»ç²¾ç¥ç–¾ç—…(Mental disorders)ã€æ•°æ®æ¨¡æ€(Data modalities)ã€ä»»åŠ¡ç±»å‹(Task types)ã€å¯è®¿é—®æ€§åŠç¤¾ä¼šæ–‡åŒ–èƒŒæ™¯ç­‰ç»´åº¦å¯¹æ•°æ®é›†è¿›è¡Œäº†ç³»ç»Ÿåˆ†ç±»ï¼Œå¹¶è°ƒæŸ¥äº†åˆæˆä¸´åºŠå¿ƒç†å¥åº·æ•°æ®é›†(Synthetic clinical mental health datasets)ã€‚é€šè¿‡æ·±å…¥åˆ†æï¼Œç ”ç©¶è¯†åˆ«å‡ºé•¿æœŸæ€§æ•°æ®(Longitudinal data)åŒ®ä¹ã€è·¨æ–‡åŒ–è¯­è¨€ä»£è¡¨æ€§æœ‰é™ä»¥åŠæ ‡æ³¨æ ‡å‡†ä¸ä¸€ç­‰å…³é”®ç ”ç©¶å·®è·ã€‚æœ€åï¼Œæ–‡ç« æ€»ç»“äº†æ•°æ®é›†æ ‡å‡†åŒ–è¿‡ç¨‹ä¸­çš„æ ¸å¿ƒæŒ‘æˆ˜ï¼Œå¹¶ä¸ºå¼€å‘æ›´å…·é²æ£’æ€§ã€æ³›åŒ–æ€§å’Œå…¬å¹³æ€§çš„å¿ƒç†å¥åº· AI ç³»ç»Ÿæä¾›äº†å…·ä½“çš„è¡ŒåŠ¨å»ºè®®ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "23 pages, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.09809v2",
      "published_date": "2025-08-13 13:42:35 UTC",
      "updated_date": "2025-08-18 15:27:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:35:08.463991+00:00"
    },
    {
      "arxiv_id": "2508.09805v2",
      "title": "Automated Segmentation of Coronal Brain Tissue Slabs for 3D Neuropathology",
      "title_zh": "ç”¨äºä¸‰ç»´ç¥ç»ç—…ç†å­¦çš„å† çŠ¶é¢è„‘ç»„ç»‡å—è‡ªåŠ¨åˆ†å‰²",
      "authors": [
        "Jonathan Williams Ramirez",
        "Dina Zemlyanker",
        "Lucas Deden-Binder",
        "Rogeny Herisse",
        "Erendira Garcia Pallares",
        "Karthik Gopinath",
        "Harshvardhan Gazula",
        "Christopher Mount",
        "Liana N. Kozanno",
        "Michael S. Marshall",
        "Theresa R. Connors",
        "Matthew P. Frosch",
        "Mark Montine",
        "Derek H. Oakley",
        "Christine L. Mac Donald",
        "C. Dirk Keene",
        "Bradley T. Hyman",
        "Juan Eugenio Iglesias"
      ],
      "abstract": "Advances in image registration and machine learning have recently enabled volumetric analysis of postmortem brain tissue from conventional photographs of coronal slabs, which are routinely collected in brain banks and neuropathology laboratories worldwide. One caveat of this methodology is the requirement of segmentation of the tissue from photographs, which currently requires costly manual intervention. In this article, we present a deep learning model to automate this process. The automatic segmentation tool relies on a U-Net architecture that was trained with a combination of 1,414 manually segmented images of both fixed and fresh tissue, from specimens with varying diagnoses, photographed at two different sites. Automated model predictions on a subset of photographs not seen in training were analyzed to estimate performance compared to manual labels, including both inter- and intra-rater variability. Our model achieved a median Dice score over 0.98, mean surface distance under 0.4mm, and 95\\% Hausdorff distance under 1.60mm, which approaches inter-/intra-rater levels. Our tool is publicly available at surfer.nmr.mgh.harvard.edu/fswiki/PhotoTools.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä»å† çŠ¶åˆ‡ç‰‡(coronal slabs)ç…§ç‰‡ä¸­è¿›è¡Œæ­»åè„‘ç»„ç»‡ä½“ç§¯åˆ†ææ—¶æ‰‹åŠ¨åˆ†å‰²(segmentation)æˆæœ¬é«˜æ˜‚çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºU-Netæ¶æ„çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚è¯¥æ¨¡å‹åˆ©ç”¨æ¥è‡ªä¸¤ä¸ªä¸åŒç«™ç‚¹çš„1,414å¼ æ‰‹åŠ¨æ ‡æ³¨å›¾åƒè¿›è¡Œè®­ç»ƒï¼Œæ¶µç›–äº†å›ºå®šå’Œæ–°é²œç»„ç»‡ä»¥åŠå¤šç§ä¸´åºŠè¯Šæ–­ï¼Œç¡®ä¿äº†ç®—æ³•çš„é²æ£’æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨ä¸­ä½Dice scoreä¸Šè¶…è¿‡0.98ï¼Œå¹³å‡è¡¨é¢è·ç¦»(mean surface distance)å°äº0.4mmï¼Œæ€§èƒ½è¡¨ç°å·²æ¥è¿‘äººå·¥è¯„åˆ†è€…é—´çš„å˜å¼‚æ°´å¹³ã€‚è¯¥å·¥å…·PhotoToolså·²å…¬å¼€å‘å¸ƒï¼Œæ˜¾è‘—æå‡äº†3Dç¥ç»ç—…ç†å­¦(3D Neuropathology)ç ”ç©¶ä¸­è„‘ç»„ç»‡åˆ†æçš„è‡ªåŠ¨åŒ–ç¨‹åº¦å’Œå¤„ç†æ•ˆç‡ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "20 pages, 10 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.09805v2",
      "published_date": "2025-08-13 13:40:20 UTC",
      "updated_date": "2025-11-04 20:00:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:35:15.190409+00:00"
    },
    {
      "arxiv_id": "2508.09801v2",
      "title": "Explainable Attention-Guided Stacked Graph Neural Networks for Malware Detection",
      "title_zh": "ç”¨äºæ¶æ„è½¯ä»¶æ£€æµ‹çš„å¯è§£é‡Šæ³¨æ„åŠ›å¼•å¯¼å †å å›¾ç¥ç»ç½‘ç»œ",
      "authors": [
        "Hossein Shokouhinejad",
        "Roozbeh Razavi-Far",
        "Griffin Higgins",
        "Ali A Ghorbani"
      ],
      "abstract": "Malware detection in modern computing environments demands models that are not only accurate but also interpretable and robust to evasive techniques. Graph neural networks (GNNs) have shown promise in this domain by modeling rich structural dependencies in graph-based program representations such as control flow graphs (CFGs). However, single-model approaches may suffer from limited generalization and lack interpretability, especially in high-stakes security applications. In this paper, we propose a novel stacking ensemble framework for graph-based malware detection and explanation. Our method dynamically extracts CFGs from portable executable (PE) files and encodes their basic blocks through a two-step embedding strategy. A set of diverse GNN base learners, each with a distinct message-passing mechanism, is used to capture complementary behavioral features. Their prediction outputs are aggregated by a meta-learner implemented as an attention-based multilayer perceptron, which both classifies malware instances and quantifies the contribution of each base model. To enhance explainability, we introduce an ensemble-aware post-hoc explanation technique that leverages edge-level importance scores generated by a GNN explainer and fuses them using the learned attention weights. This produces interpretable, model-agnostic explanations aligned with the final ensemble decision. Experimental results demonstrate that our framework improves classification performance while providing insightful interpretations of malware behavior.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§ç”¨äºæ¶æ„è½¯ä»¶æ£€æµ‹å’Œè§£é‡Šçš„æ–°å‹å †å é›†æˆæ¡†æ¶(Stacking Ensemble Framework)ï¼Œæ—¨åœ¨è§£å†³å•ä¸€å›¾ç¥ç»ç½‘ç»œ(GNN)æ¨¡å‹åœ¨å¤„ç†å¤æ‚ç¨‹åºç»“æ„æ—¶æ³›åŒ–èƒ½åŠ›ä¸è¶³å’Œç¼ºä¹å¯è§£é‡Šæ€§çš„é—®é¢˜ã€‚è¯¥æ–¹æ³•ä»å¯ç§»æ¤æ‰§è¡Œæ–‡ä»¶(PE)ä¸­åŠ¨æ€æå–æ§åˆ¶æµå›¾(CFGs)ï¼Œå¹¶ç»“åˆä¸¤æ­¥åµŒå…¥ç­–ç•¥å¯¹åŸºæœ¬å—è¿›è¡Œç¼–ç ã€‚é€šè¿‡é›†æˆå…·æœ‰ä¸åŒæ¶ˆæ¯ä¼ é€’æœºåˆ¶çš„å¤šç§GNNåŸºå­¦ä¹ å™¨ï¼Œæ¡†æ¶èƒ½å¤Ÿæ•æ‰äº’è¡¥çš„è½¯ä»¶è¡Œä¸ºç‰¹å¾ï¼Œå¹¶åˆ©ç”¨åŸºäºæ³¨æ„åŠ›æœºåˆ¶çš„å¤šå±‚æ„ŸçŸ¥æœº(Attention-based MLP)ä½œä¸ºå…ƒå­¦ä¹ å™¨è¿›è¡Œé¢„æµ‹èšåˆä¸è´¡çŒ®é‡åŒ–ã€‚ä¸ºäº†æå‡å¯è§£é‡Šæ€§ï¼Œç ”ç©¶å¼•å…¥äº†ä¸€ç§é›†æˆæ„ŸçŸ¥çš„åç½®è§£é‡ŠæŠ€æœ¯(Post-hoc Explanation)ï¼Œé€šè¿‡èåˆGNN Explainerç”Ÿæˆçš„è¾¹çº§é‡è¦æ€§åˆ†æ•°ä¸å­¦ä¹ åˆ°çš„æ³¨æ„åŠ›æƒé‡ï¼Œç”Ÿæˆä¸æœ€ç»ˆå†³ç­–ä¸€è‡´çš„å¯è§£é‡Šæ€§åˆ†æã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ¡†æ¶åœ¨æ˜¾è‘—æå‡åˆ†ç±»æ€§èƒ½çš„åŒæ—¶ï¼Œèƒ½å¤Ÿä¸ºå¤æ‚çš„æ¶æ„è½¯ä»¶è¡Œä¸ºæä¾›ç›´è§‚ä¸”æ¨¡å‹æ— å…³çš„è§£é‡Šã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09801v2",
      "published_date": "2025-08-13 13:33:02 UTC",
      "updated_date": "2025-08-14 20:12:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:35:30.153987+00:00"
    },
    {
      "arxiv_id": "2508.15798v1",
      "title": "Persuasiveness and Bias in LLM: Investigating the Impact of Persuasiveness and Reinforcement of Bias in Language Models",
      "title_zh": "LLM ä¸­çš„è¯´æœåŠ›ä¸åè§ï¼šæ¢ç©¶è¯­è¨€æ¨¡å‹ä¸­è¯´æœåŠ›çš„å½±å“åŠå…¶å¯¹åè§çš„å¼ºåŒ–",
      "authors": [
        "Saumya Roy"
      ],
      "abstract": "Warning: This research studies AI persuasion and bias amplification that could be misused; all experiments are for safety evaluation. Large Language Models (LLMs) now generate convincing, human-like text and are widely used in content creation, decision support, and user interactions. Yet the same systems can spread information or misinformation at scale and reflect social biases that arise from data, architecture, or training choices. This work examines how persuasion and bias interact in LLMs, focusing on how imperfect or skewed outputs affect persuasive impact. Specifically, we test whether persona-based models can persuade with fact-based claims while also, unintentionally, promoting misinformation or biased narratives.\n  We introduce a convincer-skeptic framework: LLMs adopt personas to simulate realistic attitudes. Skeptic models serve as human proxies; we compare their beliefs before and after exposure to arguments from convincer models. Persuasion is quantified with Jensen-Shannon divergence over belief distributions. We then ask how much persuaded entities go on to reinforce and amplify biased beliefs across race, gender, and religion. Strong persuaders are further probed for bias using sycophantic adversarial prompts and judged with additional models.\n  Our findings show both promise and risk. LLMs can shape narratives, adapt tone, and mirror audience values across domains such as psychology, marketing, and legal assistance. But the same capacity can be weaponized to automate misinformation or craft messages that exploit cognitive biases, reinforcing stereotypes and widening inequities. The core danger lies in misuse more than in occasional model mistakes. By measuring persuasive power and bias reinforcement, we argue for guardrails and policies that penalize deceptive use and support alignment, value-sensitive design, and trustworthy deployment.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)ä¸­çš„è¯´æœåŠ›(Persuasiveness)ä¸åè§(Bias)ä¹‹é—´çš„ç›¸äº’ä½œç”¨ï¼Œé‡ç‚¹ç ”ç©¶æ¨¡å‹å¦‚ä½•é€šè¿‡è¯´æœè¿‡ç¨‹å¼ºåŒ–å’Œæ”¾å¤§æ—¢æœ‰åè§ã€‚ä½œè€…æå‡ºäº†ä¸€ä¸ªè¯´æœè€…-æ€€ç–‘è€…æ¡†æ¶(convincer-skeptic framework)ï¼Œé€šè¿‡è®©æ¨¡å‹æ‰®æ¼”ç‰¹å®šè§’è‰²(personas)æ¥æ¨¡æ‹ŸçœŸå®çš„äº’åŠ¨ï¼Œå¹¶åˆ©ç”¨è©¹æ£®-é¦™å†œæ•£åº¦(Jensen-Shannon divergence)é‡åŒ–ä¿¡å¿µåˆ†å¸ƒçš„å˜åŒ–ã€‚ç ”ç©¶å‘ç°ï¼Œè™½ç„¶LLMsèƒ½å¤Ÿè°ƒæ•´è¯­æ°”ä»¥é‡å¡‘å™äº‹å¹¶åœ¨å¤šé¢†åŸŸè¾…åŠ©äººç±»ï¼Œä½†è¿™ç§èƒ½åŠ›ä¹Ÿå¯èƒ½è¢«æ­¦å™¨åŒ–ä»¥è‡ªåŠ¨ä¼ æ’­è¯¯å¯¼ä¿¡æ¯ï¼Œå¹¶åˆ©ç”¨è®¤çŸ¥åè§å¼ºåŒ–ç§æ—ã€æ€§åˆ«å’Œå®—æ•™æ–¹é¢çš„åˆ»æ¿å°è±¡ã€‚é€šè¿‡ä½¿ç”¨è®¨å¥½å¼å¯¹æŠ—æç¤º(sycophantic adversarial prompts)è¿›è¡Œçš„æ¢æµ‹å®éªŒï¼Œè¿›ä¸€æ­¥æ­ç¤ºäº†å¼ºè¯´æœåŠ›æ¨¡å‹åœ¨åè§å¼ºåŒ–æ–¹é¢çš„é£é™©ã€‚æœ€åï¼Œè¯¥å·¥ä½œå¼ºè°ƒäº†å»ºç«‹é˜²æŠ¤æ (guardrails)å’Œå®æ–½ä»·å€¼æ•æ„Ÿè®¾è®¡(value-sensitive design)çš„é‡è¦æ€§ï¼Œä»¥åº”å¯¹LLMsæ½œåœ¨çš„è¯¯å¯¼æ€§ä½¿ç”¨å¹¶ç¡®ä¿ç³»ç»Ÿçš„å®‰å…¨éƒ¨ç½²ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.15798v1",
      "published_date": "2025-08-13 13:30:49 UTC",
      "updated_date": "2025-08-13 13:30:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:35:34.984616+00:00"
    },
    {
      "arxiv_id": "2508.09791v1",
      "title": "LibRec: Benchmarking Retrieval-Augmented LLMs for Library Migration Recommendations",
      "title_zh": "LibRecï¼šé’ˆå¯¹åº“è¿ç§»å»ºè®®çš„æ£€ç´¢å¢å¼ºå‹å¤§è¯­è¨€æ¨¡å‹åŸºå‡†è¯„ä¼°",
      "authors": [
        "Junxiao Han",
        "Yarong Wang",
        "Xiaodong Gu",
        "Cuiyun Gao",
        "Yao Wan",
        "Song Han",
        "David Lo",
        "Shuiguang Deng"
      ],
      "abstract": "In this paper, we propose LibRec, a novel framework that integrates the capabilities of LLMs with retrieval-augmented generation(RAG) techniques to automate the recommendation of alternative libraries. The framework further employs in-context learning to extract migration intents from commit messages to enhance the accuracy of its recommendations. To evaluate the effectiveness of LibRec, we introduce LibEval, a benchmark designed to assess the performance in the library migration recommendation task. LibEval comprises 2,888 migration records associated with 2,368 libraries extracted from 2,324 Python repositories. Each migration record captures source-target library pairs, along with their corresponding migration intents and intent types. Based on LibEval, we evaluated the effectiveness of ten popular LLMs within our framework, conducted an ablation study to examine the contributions of key components within our framework, explored the impact of various prompt strategies on the framework's performance, assessed its effectiveness across various intent types, and performed detailed failure case analyses.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† LibRecï¼Œè¿™æ˜¯ä¸€ä¸ªç»“åˆäº†å¤§è¯­è¨€æ¨¡å‹ (LLMs) ä¸æ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG) æŠ€æœ¯çš„æ–°å‹æ¡†æ¶ï¼Œæ—¨åœ¨å®ç°æ›¿ä»£åº“æ¨èçš„è‡ªåŠ¨åŒ–ã€‚è¯¥æ¡†æ¶åˆ©ç”¨è¯­å¢ƒå­¦ä¹  (in-context learning) ä» commit messages ä¸­æå–è¿ç§»æ„å›¾ï¼Œä»è€Œæå‡æ¨èçš„ç²¾ç¡®åº¦ã€‚ä¸ºäº†éªŒè¯ LibRec çš„æœ‰æ•ˆæ€§ï¼Œç ”ç©¶è€…æ„å»ºäº† LibEval åŸºå‡†æµ‹è¯•ï¼ŒåŒ…å«ä» 2,324 ä¸ª Python ä»“åº“ä¸­æå–çš„ 2,888 æ¡è¿ç§»è®°å½•ï¼Œæ¶µç›–äº†åº“è¿ç§»å¯¹åŠç›¸åº”çš„æ„å›¾ç±»å‹ã€‚é€šè¿‡åœ¨è¯¥åŸºå‡†ä¸Šå¯¹åç§æµè¡Œ LLMs è¿›è¡Œè¯„ä¼°ï¼Œç ”ç©¶å›¢é˜Ÿæ‰§è¡Œäº†æ¶ˆèå®éªŒ (ablation study) ä»¥åˆ†æå„ç»„ä»¶çš„è´¡çŒ®ï¼Œå¹¶æ¢è®¨äº†ä¸åŒæç¤ºç­–ç•¥ (prompt strategies) å¯¹æ€§èƒ½çš„å½±å“ã€‚æœ€åï¼Œç ”ç©¶é€šè¿‡è¯¦ç»†çš„å¤±è´¥æ¡ˆä¾‹åˆ†æå’Œè·¨æ„å›¾ç±»å‹çš„è¯„ä¼°ï¼Œä¸ºä¼˜åŒ–åº“è¿ç§»æ¨èç³»ç»Ÿæä¾›äº†æ·±å…¥çš„è§è§£ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09791v1",
      "published_date": "2025-08-13 13:22:49 UTC",
      "updated_date": "2025-08-13 13:22:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:35:46.290554+00:00"
    },
    {
      "arxiv_id": "2508.10071v2",
      "title": "Advancing Data Equity: Practitioner Responsibility and Accountability in NLP Data Practices",
      "title_zh": "æ¨è¿›æ•°æ®å…¬å¹³ï¼šNLP æ•°æ®å®è·µä¸­ä»ä¸šè€…çš„è´£ä»»ä¸é—®è´£",
      "authors": [
        "Jay L. Cunningham",
        "Kevin Zhongyang Shao",
        "Rock Yuren Pang",
        "Nathaniel Mengist"
      ],
      "abstract": "While research has focused on surfacing and auditing algorithmic bias to ensure equitable AI development, less is known about how NLP practitioners - those directly involved in dataset development, annotation, and deployment - perceive and navigate issues of NLP data equity. This study is among the first to center practitioners' perspectives, linking their experiences to a multi-scalar AI governance framework and advancing participatory recommendations that bridge technical, policy, and community domains. Drawing on a 2024 questionnaire and focus group, we examine how U.S.-based NLP data practitioners conceptualize fairness, contend with organizational and systemic constraints, and engage emerging governance efforts such as the U.S. AI Bill of Rights. Findings reveal persistent tensions between commercial objectives and equity commitments, alongside calls for more participatory and accountable data workflows. We critically engage debates on data diversity and diversity washing, arguing that improving NLP equity requires structural governance reforms that support practitioner agency and community consent.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†è‡ªç„¶è¯­è¨€å¤„ç†(NLP)ä»ä¸šè€…åœ¨æ•°æ®é›†å¼€å‘ã€æ ‡æ³¨å’Œéƒ¨ç½²è¿‡ç¨‹ä¸­å¦‚ä½•æ„ŸçŸ¥å¹¶åº”å¯¹æ•°æ®å…¬å¹³æ€§(Data Equity)é—®é¢˜ã€‚ç ”ç©¶é€šè¿‡2024å¹´çš„é—®å·è°ƒæŸ¥å’Œç„¦ç‚¹å°ç»„è®¨è®ºï¼Œæ”¶é›†äº†ç¾å›½NLPä»ä¸šè€…çš„æ ¸å¿ƒè§‚ç‚¹ï¼Œå¹¶å°†å…¶ä¸å¤šæ ‡åº¦AIæ²»ç†æ¡†æ¶(AI Governance Framework)ç›¸ç»“åˆã€‚è°ƒæŸ¥é‡ç‚¹åˆ†æäº†ä»ä¸šè€…å¯¹å…¬å¹³æ€§çš„æ„æ€ã€é¢å¯¹çš„ç»„ç»‡ä¸ç³»ç»Ÿæ€§é™åˆ¶ï¼Œä»¥åŠå¯¹ã€ŠAIæƒåˆ©æ³•æ¡ˆè“å›¾ã€‹(U.S. AI Bill of Rights)ç­‰æ–°å…´æ²»ç†ä¸¾æªçš„å‚ä¸æƒ…å†µã€‚ç ”ç©¶ç»“æœæ­ç¤ºäº†å•†ä¸šç›®æ ‡ä¸å…¬å¹³æ€§æ‰¿è¯ºä¹‹é—´é•¿æœŸå­˜åœ¨çš„ç´§å¼ å…³ç³»ï¼Œå¹¶åæ˜ å‡ºä»ä¸šè€…å¯¹æ›´å…·å‚ä¸æ€§(Participatory)å’Œé—®è´£æ€§(Accountable)æ•°æ®å·¥ä½œæµçš„è¿«åˆ‡éœ€æ±‚ã€‚è®ºæ–‡æ‰¹åˆ¤æ€§åœ°è®¨è®ºäº†æ•°æ®å¤šæ ·æ€§(Data Diversity)ä¸â€œå¤šæ ·æ€§æ´—ç™½â€(Diversity Washing)çš„äº‰è®®ï¼Œè®¤ä¸ºæå‡NLPå…¬å¹³æ€§éœ€è¦ç»“æ„æ€§çš„æ²»ç†æ”¹é©ã€‚æœ€ç»ˆï¼Œä½œè€…å»ºè®®é€šè¿‡æ”¿ç­–å’ŒæŠ€æœ¯æ‰‹æ®µæ”¯æŒä»ä¸šè€…çš„è‡ªä¸»æƒ(Practitioner Agency)ï¼Œå¹¶ç¡®ä¿æ•°æ®å®è·µè·å¾—ç¤¾åŒºå…±è¯†(Community Consent)ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "10 pages, 6 Pages (References and Appendices). The archival version has been accepted to AAAI (AIES 2025) without the extended Appendices. This extended version includes Appendices",
      "pdf_url": "https://arxiv.org/pdf/2508.10071v2",
      "published_date": "2025-08-13 13:14:43 UTC",
      "updated_date": "2025-08-16 15:49:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:35:46.461848+00:00"
    },
    {
      "arxiv_id": "2508.09787v1",
      "title": "Prototype Training with Dual Pseudo-Inverse and Optimized Hidden Activations",
      "title_zh": "åŸºäºåŒä¼ªé€†ä¸ä¼˜åŒ–éšè—å±‚æ¿€æ´»çš„åŸå‹è®­ç»ƒ",
      "authors": [
        "Mauro Tucci"
      ],
      "abstract": "We present Proto-PINV+H, a fast training paradigm that combines closed-form weight computation with gradient-based optimisation of a small set of synthetic inputs, soft labels, and-crucially-hidden activations. At each iteration we recompute all weight matrices in closed form via two (or more) ridge-regularised pseudo-inverse solves, while updating only the prototypes with Adam. The trainable degrees of freedom are thus shifted from weight space to data/activation space. On MNIST (60k train, 10k test) and Fashion-MNIST (60k train, 10k test), our method reaches 97.8% and 89.3% test accuracy on the official 10k test sets, respectively, in 3.9s--4.5s using approximately 130k trainable parameters and only 250 epochs on an RTX 5060 (16GB). We provide a multi-layer extension (optimised activations at each hidden stage), learnable ridge parameters, optional PCA/PLS projections, and theory linking the condition number of prototype matrices to generalisation. The approach yields favourable accuracy--speed--size trade-offs against ELM, random-feature ridge, and shallow MLPs trained by back-propagation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Proto-PINV+Hï¼Œè¿™æ˜¯ä¸€ç§ç»“åˆäº†é—­å¼æƒé‡è®¡ç®—(closed-form weight computation)ä¸æ¢¯åº¦ä¸‹é™ä¼˜åŒ–(gradient-based optimisation)çš„å¿«é€Ÿè®­ç»ƒèŒƒå¼ã€‚è¯¥æ–¹æ³•é€šè¿‡è„Šå›å½’æ­£åˆ™åŒ–ä¼ªé€†(ridge-regularised pseudo-inverse)æ±‚è§£æ¥é‡æ–°è®¡ç®—æƒé‡çŸ©é˜µï¼ŒåŒæ—¶åˆ©ç”¨Adamç®—æ³•ä»…æ›´æ–°ä¸€å°ç»„åˆæˆè¾“å…¥ã€è½¯æ ‡ç­¾(soft labels)ä»¥åŠå…³é”®çš„éšè—å±‚æ¿€æ´»å€¼(hidden activations)ï¼Œä»è€Œå°†å¯è®­ç»ƒçš„è‡ªç”±åº¦ä»æƒé‡ç©ºé—´è½¬ç§»åˆ°æ•°æ®ä¸æ¿€æ´»ç©ºé—´ã€‚è¯¥æ¡†æ¶æ”¯æŒå¤šå±‚æ‰©å±•å’Œå¯å­¦ä¹ çš„è„Šå‚æ•°ï¼Œå¹¶å»ºç«‹äº†åŸå‹çŸ©é˜µ(prototype matrices)æ¡ä»¶æ•°ä¸æ³›åŒ–èƒ½åŠ›ä¹‹é—´çš„ç†è®ºè”ç³»ã€‚å®éªŒè¡¨æ˜ï¼Œåœ¨RTX 5060ä¸Šä»…éœ€çº¦4ç§’å·¦å³çš„è®­ç»ƒæ—¶é—´ï¼ŒProto-PINV+Håœ¨MNISTå’ŒFashion-MNISTæ•°æ®é›†ä¸Šåˆ†åˆ«è¾¾åˆ°äº†97.8%å’Œ89.3%çš„å‡†ç¡®ç‡ã€‚ä¸ELMã€éšæœºç‰¹å¾è„Šå›å½’åŠæµ…å±‚MLPç›¸æ¯”ï¼Œè¯¥æ–¹æ³•åœ¨å‡†ç¡®ç‡ã€è®­ç»ƒé€Ÿåº¦å’Œæ¨¡å‹å¤æ‚åº¦ä¹‹é—´å®ç°äº†æ›´ä¼˜çš„æƒè¡¡ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages, 1 table, reproducible, one proof",
      "pdf_url": "https://arxiv.org/pdf/2508.09787v1",
      "published_date": "2025-08-13 13:13:32 UTC",
      "updated_date": "2025-08-13 13:13:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:35:42.751022+00:00"
    },
    {
      "arxiv_id": "2508.09786v1",
      "title": "Adoption of Explainable Natural Language Processing: Perspectives from Industry and Academia on Practices and Challenges",
      "title_zh": "å¯è§£é‡Šè‡ªç„¶è¯­è¨€å¤„ç†çš„é‡‡ç”¨ï¼šå·¥ä¸šç•Œä¸å­¦æœ¯ç•Œå…³äºå®è·µä¸æŒ‘æˆ˜çš„è§†è§’",
      "authors": [
        "Mahdi Dhaini",
        "Tobias MÃ¼ller",
        "Roksoliana Rabets",
        "Gjergji Kasneci"
      ],
      "abstract": "The field of explainable natural language processing (NLP) has grown rapidly in recent years. The growing opacity of complex models calls for transparency and explanations of their decisions, which is crucial to understand their reasoning and facilitate deployment, especially in high-stakes environments. Despite increasing attention given to explainable NLP, practitioners' perspectives regarding its practical adoption and effectiveness remain underexplored. This paper addresses this research gap by investigating practitioners' experiences with explainability methods, specifically focusing on their motivations for adopting such methods, the techniques employed, satisfaction levels, and the practical challenges encountered in real-world NLP applications. Through a qualitative interview-based study with industry practitioners and complementary interviews with academic researchers, we systematically analyze and compare their perspectives. Our findings reveal conceptual gaps, low satisfaction with current explainability methods, and highlight evaluation challenges. Our findings emphasize the need for clear definitions and user-centric frameworks for better adoption of explainable NLP in practice.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¯è§£é‡Šè‡ªç„¶è¯­è¨€å¤„ç† (Explainable NLP) åœ¨å­¦æœ¯ç•Œå’Œå·¥ä¸šç•Œä¸­çš„åº”ç”¨ç°çŠ¶ã€å®è·µä¸æŒ‘æˆ˜ï¼Œæ—¨åœ¨å¼¥è¡¥ä»ä¸šè€…è§†è§’åœ¨å®é™…åº”ç”¨ä¸­è¢«å¿½è§†çš„ç ”ç©¶ç©ºç™½ã€‚ç ”ç©¶é€šè¿‡å¯¹å·¥ä¸šç•Œä»ä¸šè€…è¿›è¡Œå®šæ€§è®¿è°ˆ (Qualitative interview-based study) å¹¶ç»“åˆå­¦æœ¯ç ”ç©¶äººå‘˜çš„è§‚ç‚¹ï¼Œç³»ç»Ÿåœ°åˆ†æäº†åŒæ–¹åœ¨é‡‡ç”¨å¯è§£é‡Šæ€§æ–¹æ³•æ—¶çš„åŠ¨æœºã€æ‰€ä½¿ç”¨çš„æŠ€æœ¯ä»¥åŠæ»¡æ„åº¦ã€‚è°ƒæŸ¥ç»“æœæ­ç¤ºäº†é¢†åŸŸå†…å­˜åœ¨çš„æ¦‚å¿µé¸¿æ²Ÿ (Conceptual gaps)ï¼Œå¹¶æŒ‡å‡ºä»ä¸šè€…å¯¹å½“å‰ç°æœ‰çš„è§£é‡Šæ€§æ–¹æ³•æ»¡æ„åº¦è¾ƒä½ï¼Œä¸”é¢ä¸´ä¸¥å³»çš„è¯„ä¼°æŒ‘æˆ˜ (Evaluation challenges)ã€‚ç ”ç©¶å¼ºè°ƒï¼Œä¸ºäº†åœ¨å®è·µä¸­æ›´å¥½åœ°æ¨åŠ¨å¯è§£é‡Šè‡ªç„¶è¯­è¨€å¤„ç†çš„è½åœ°ï¼ŒäºŸéœ€å»ºç«‹æ¸…æ™°çš„å®šä¹‰ä»¥åŠä»¥ç”¨æˆ·ä¸ºä¸­å¿ƒæ¡†æ¶ (User-centric frameworks)ã€‚è¯¥é¡¹å·¥ä½œä¸ºç†è§£å­¦æœ¯ç ”ç©¶ä¸å®é™…å·¥ä¸šéœ€æ±‚ä¹‹é—´çš„å·®å¼‚æä¾›äº†é‡è¦è§è§£ï¼Œå¹¶ä¸ºæœªæ¥å¯è§£é‡Šæ€§æŠ€æœ¯çš„å‘å±•æŒ‡æ˜äº†æ–¹å‘ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to AAAI/ACM Conference on AI, Ethics, and Society (AIES 2025)",
      "pdf_url": "https://arxiv.org/pdf/2508.09786v1",
      "published_date": "2025-08-13 13:12:18 UTC",
      "updated_date": "2025-08-13 13:12:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:35:44.852676+00:00"
    },
    {
      "arxiv_id": "2508.09784v1",
      "title": "Reasoning About Knowledge on Regular Expressions is 2EXPTIME-complete",
      "title_zh": "å…³äºæ­£åˆ™è¡¨è¾¾å¼çš„çŸ¥è¯†æ¨ç†æ˜¯ 2EXPTIME-å®Œå…¨çš„",
      "authors": [
        "Avijeet Ghosh",
        "Sujata Ghosh",
        "FranÃ§ois Schwarzentruber"
      ],
      "abstract": "Logics for reasoning about knowledge and actions have seen many applications in various domains of multi-agent systems, including epistemic planning. Change of knowledge based on observations about the surroundings forms a key aspect in such planning scenarios. Public Observation Logic (POL) is a variant of public announcement logic for reasoning about knowledge that gets updated based on public observations. Each state in an epistemic (Kripke) model is equipped with a set of expected observations. These states evolve as the expectations get matched with the actual observations. In this work, we prove that the satisfiability problem of $\\POL$ is 2EXPTIME-complete.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤šæ™ºèƒ½ä½“ç³»ç»ŸåŠè®¤è¯†è®ºè§„åˆ’ï¼ˆepistemic planningï¼‰ä¸­çŸ¥è¯†ä¸åŠ¨ä½œæ¨ç†é€»è¾‘çš„åº”ç”¨ï¼Œé‡ç‚¹åˆ†æäº†åŸºäºç¯å¢ƒè§‚æµ‹çš„çŸ¥è¯†æ¼”åŒ–è¿‡ç¨‹ã€‚æ–‡ç« æ·±å…¥ç ”ç©¶äº†å…¬å…±è§‚æµ‹é€»è¾‘ï¼ˆPublic Observation Logic, POLï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨é€šè¿‡å…¬å…±è§‚æµ‹æ›´æ–°çŸ¥è¯†çš„å…¬å…±å®£å‘Šé€»è¾‘ï¼ˆpublic announcement logicï¼‰å˜ä½“ã€‚åœ¨æ‰€ä½¿ç”¨çš„è®¤è¯†è®ºæ¨¡å‹ï¼ˆKripke modelï¼‰ä¸­ï¼Œæ¯ä¸ªçŠ¶æ€éƒ½å…³è”ä¸€ç»„é¢„æœŸè§‚æµ‹å€¼ï¼Œä¸”çŠ¶æ€ä¼šéšé¢„æœŸä¸å®é™…è§‚æµ‹çš„åŒ¹é…è€ŒåŠ¨æ€æ¼”å˜ã€‚è¯¥è®ºæ–‡çš„æ ¸å¿ƒè´¡çŒ®åœ¨äºé€šè¿‡ç†è®ºè¯æ˜ï¼Œç¡®å®šäº†å…³äºæ­£åˆ™è¡¨è¾¾å¼ï¼ˆRegular Expressionsï¼‰çŸ¥è¯†æ¨ç†çš„ POL å¯æ»¡è¶³æ€§é—®é¢˜ï¼ˆsatisfiability problemï¼‰å…·æœ‰ 2EXPTIME-complete çš„è®¡ç®—å¤æ‚åº¦ã€‚è¿™ä¸€å‘ç°ä¸ºç†è§£å¤æ‚è§‚æµ‹ç¯å¢ƒä¸‹çŸ¥è¯†é€»è¾‘çš„è®¡ç®—ç•Œé™æä¾›äº†é‡è¦çš„ç†è®ºæ”¯æ’‘ã€‚",
      "categories": [
        "cs.AI",
        "cs.CC",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted in KR 25",
      "pdf_url": "https://arxiv.org/pdf/2508.09784v1",
      "published_date": "2025-08-13 13:10:16 UTC",
      "updated_date": "2025-08-13 13:10:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:36:00.387215+00:00"
    },
    {
      "arxiv_id": "2508.09780v2",
      "title": "Combinative Matching for Geometric Shape Assembly",
      "title_zh": "å‡ ä½•å½¢çŠ¶è£…é…çš„ç»„åˆå¼åŒ¹é…",
      "authors": [
        "Nahyuk Lee",
        "Juhong Min",
        "Junhong Lee",
        "Chunghyun Park",
        "Minsu Cho"
      ],
      "abstract": "This paper introduces a new shape-matching methodology, combinative matching, to combine interlocking parts for geometric shape assembly. Previous methods for geometric assembly typically rely on aligning parts by finding identical surfaces between the parts as in conventional shape matching and registration. In contrast, we explicitly model two distinct properties of interlocking shapes: 'identical surface shape' and 'opposite volume occupancy.' Our method thus learns to establish correspondences across regions where their surface shapes appear identical but their volumes occupy the inverted space to each other. To facilitate this process, we also learn to align regions in rotation by estimating their shape orientations via equivariant neural networks. The proposed approach significantly reduces local ambiguities in matching and allows a robust combination of parts in assembly. Experimental results on geometric assembly benchmarks demonstrate the efficacy of our method, consistently outperforming the state of the art. Project page: https://nahyuklee.github.io/cmnet.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸º Combinative Matching çš„æ–°å‹å½¢çŠ¶åŒ¹é…æ–¹æ³•ï¼Œä¸“é—¨ç”¨äºè§£å†³å‡ ä½•å½¢çŠ¶ç»„è£…ä¸­äº’é”é›¶ä»¶çš„ç»„åˆé—®é¢˜ã€‚ä»¥å¾€çš„å‡ ä½•ç»„è£…æ–¹æ³•é€šå¸¸ä¾èµ–äºå¯»æ‰¾é›¶ä»¶é—´å®Œå…¨ç›¸åŒçš„è¡¨é¢è¿›è¡Œå¯¹é½ï¼Œè€Œæœ¬ç ”ç©¶åˆ™æ˜¾å¼åœ°å»ºæ¨¡äº†äº’é”å½¢çŠ¶çš„ä¸¤ä¸ªæ ¸å¿ƒå±æ€§ï¼šç›¸åŒçš„è¡¨é¢å½¢çŠ¶ (identical surface shape) å’Œç›¸åçš„ä½“ç§¯å ç”¨ (opposite volume occupancy)ã€‚è¯¥æ–¹æ³•é€šè¿‡å­¦ä¹ åœ¨è¡¨é¢å½¢çŠ¶ä¸€è‡´ä½†ä½“ç§¯ç©ºé—´äº’è¡¥çš„åŒºåŸŸä¹‹é—´å»ºç«‹å¯¹åº”å…³ç³»ï¼Œä»è€Œå®ç°æ›´ç²¾å‡†çš„åŒ¹é…ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜åˆ©ç”¨ç­‰å˜ç¥ç»ç½‘ç»œ (equivariant neural networks) ä¼°è®¡å½¢çŠ¶æ–¹å‘ï¼Œä»¥è¾…åŠ©åŒºåŸŸåœ¨æ—‹è½¬ä¸Šçš„å¯¹é½ã€‚è¿™ç§æ–¹æ³•æ˜¾è‘—å‡å°‘äº†åŒ¹é…è¿‡ç¨‹ä¸­çš„å±€éƒ¨æ­§ä¹‰æ€§ï¼Œç¡®ä¿äº†é›¶ä»¶ç»„è£…çš„ç¨³å¥æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å‡ ä½•ç»„è£…åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œæ€§èƒ½æŒç»­è¶…è¶Šäº†å½“å‰æœ€å…ˆè¿› (state of the art) çš„æŠ€æœ¯æ°´å¹³ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to ICCV 2025 (Highlight)",
      "pdf_url": "https://arxiv.org/pdf/2508.09780v2",
      "published_date": "2025-08-13 13:01:24 UTC",
      "updated_date": "2025-11-01 15:51:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:36:01.590308+00:00"
    },
    {
      "arxiv_id": "2508.09776v2",
      "title": "Can LLM-Generated Textual Explanations Enhance Model Classification Performance? An Empirical Study",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬è§£é‡Šèƒ½å¦æå‡æ¨¡å‹åˆ†ç±»æ€§èƒ½ï¼Ÿä¸€é¡¹å®è¯ç ”ç©¶",
      "authors": [
        "Mahdi Dhaini",
        "Juraj Vladika",
        "Ege Erdogan",
        "Zineb Attaoui",
        "Gjergji Kasneci"
      ],
      "abstract": "In the rapidly evolving field of Explainable Natural Language Processing (NLP), textual explanations, i.e., human-like rationales, are pivotal for explaining model predictions and enriching datasets with interpretable labels. Traditional approaches rely on human annotation, which is costly, labor-intensive, and impedes scalability. In this work, we present an automated framework that leverages multiple state-of-the-art large language models (LLMs) to generate high-quality textual explanations. We rigorously assess the quality of these LLM-generated explanations using a comprehensive suite of Natural Language Generation (NLG) metrics. Furthermore, we investigate the downstream impact of these explanations on the performance of pre-trained language models (PLMs) and LLMs across natural language inference tasks on two diverse benchmark datasets. Our experiments demonstrate that automated explanations exhibit highly competitive effectiveness compared to human-annotated explanations in improving model performance. Our findings underscore a promising avenue for scalable, automated LLM-based textual explanation generation for extending NLP datasets and enhancing model performance.",
      "tldr_zh": "è¯¥ç ”ç©¶é€šè¿‡å®è¯åˆ†ææ¢è®¨äº† Large Language Models (LLMs) ç”Ÿæˆçš„æ–‡æœ¬è§£é‡Šæ˜¯å¦èƒ½æœ‰æ•ˆå¢å¼ºæ¨¡å‹çš„åˆ†ç±»æ€§èƒ½ã€‚ä¸ºäº†å…‹æœäººå·¥æ ‡æ³¨æ–‡æœ¬è§£é‡Šæˆæœ¬é«˜æ˜‚ä¸”éš¾ä»¥å¤§è§„æ¨¡æ‰©å±•çš„å±€é™ï¼Œä½œè€…æå‡ºäº†ä¸€ä¸ªåˆ©ç”¨å¤šç§ state-of-the-art LLMs è‡ªåŠ¨ç”Ÿæˆé«˜è´¨é‡æ–‡æœ¬è§£é‡Šçš„è‡ªåŠ¨åŒ–æ¡†æ¶ã€‚ç ”ç©¶é‡‡ç”¨äº†ä¸€ç³»åˆ— Natural Language Generation (NLG) æŒ‡æ ‡å¯¹ç”Ÿæˆè´¨é‡è¿›è¡Œä¸¥è°¨è¯„ä¼°ï¼Œå¹¶åœ¨ä¸¤ä¸ªåŸºå‡†æ•°æ®é›†çš„ Natural Language Inference (NLI) ä»»åŠ¡ä¸­ï¼ŒéªŒè¯äº†è¿™äº›è§£é‡Šå¯¹ Pre-trained Language Models (PLMs) åŠ LLMs é¢„æµ‹æ€§èƒ½çš„ä¸‹æ¸¸å½±å“ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè‡ªåŠ¨åŒ–ç”Ÿæˆçš„è§£é‡Šåœ¨æå‡æ¨¡å‹æ€§èƒ½æ–¹é¢çš„æ•ˆæœä¸äººå·¥æ ‡æ³¨è§£é‡Šç›¸å½“ï¼Œå…·æœ‰æå¼ºçš„ç«äº‰åŠ›ã€‚è¯¥ç ”ç©¶çš„å‘ç°ä¸ºåˆ©ç”¨ LLMs è‡ªåŠ¨åŒ–æ‰©å±• NLP æ•°æ®é›†å¹¶æå‡æ¨¡å‹è¡¨ç°æä¾›äº†ä¸€æ¡æå…·å‰æ™¯çš„å¯æ‰©å±•è·¯å¾„ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to the 34th International Conference on Artificial Neural Networks (ICANN 2025)",
      "pdf_url": "https://arxiv.org/pdf/2508.09776v2",
      "published_date": "2025-08-13 12:59:08 UTC",
      "updated_date": "2025-11-11 10:39:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:36:08.986093+00:00"
    },
    {
      "arxiv_id": "2508.09768v1",
      "title": "Counting Short Trajectories in Elementary Cellular Automata using the Transfer Matrix Method",
      "title_zh": "åŸºäºè½¬ç§»çŸ©é˜µæ³•çš„åˆç­‰ç»†èƒè‡ªåŠ¨æœºçŸ­è½¨è¿¹è®¡æ•°",
      "authors": [
        "CÃ©dric Koller",
        "Barbora HudcovÃ¡"
      ],
      "abstract": "Elementary Cellular Automata (ECAs) exhibit diverse behaviours often categorized by Wolfram's qualitative classification. To provide a quantitative basis for understanding these behaviours, we investigate the global dynamics of such automata and we describe a method that allows us to compute the number of all configurations leading to short attractors in a limited number of time steps. This computation yields exact results in the thermodynamic limit (as the CA grid size grows to infinity), and is based on the Transfer Matrix Method (TMM) that we adapt for our purposes. Specifically, given two parameters $(p, c)$ we are able to compute the entropy of all initial configurations converging to an attractor of size $c$ after $p$ time-steps. By calculating such statistics for various ECA rules, we establish a quantitative connection between the entropy and the qualitative Wolfram classification scheme. Class 1 rules rapidly converge to maximal entropy for stationary states ($c=1$) as $p$ increases. Class 2 rules also approach maximal entropy quickly for appropriate cycle lengths $c$, potentially requiring consideration of translations. Class 3 rules exhibit zero or low finite entropy that saturates after a short transient. Class 4 rules show finite positive entropy, similar to some Class 3 rules. This method provides a precise framework for quantifying trajectory statistics, although its exponential computational cost in $p+c$ restricts practical analysis to short trajectories.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åˆç­‰ç»†èƒè‡ªåŠ¨æœº(Elementary Cellular Automata, ECAs)çš„å…¨å±€åŠ¨åŠ›å­¦ï¼Œå¹¶æå‡ºäº†ä¸€ç§åŸºäºè½¬ç§»çŸ©é˜µæ³•(Transfer Matrix Method, TMM)çš„æ–¹æ³•ï¼Œç”¨äºåœ¨çƒ­åŠ›å­¦æé™(thermodynamic limit)ä¸‹è®¡ç®—æ¼”åŒ–ä¸ºçŸ­å¸å¼•å­çš„åˆå§‹é…ç½®æ•°é‡ã€‚è¯¥æ–¹æ³•é€šè¿‡è®¡ç®—ç»™å®šæ—¶é—´æ­¥ $p$ å’Œå¸å¼•å­å°ºå¯¸ $c$ ä¸‹çš„é…ç½®ç†µ(entropy)ï¼Œä¸º Wolfram å®šæ€§åˆ†ç±»æ–¹æ¡ˆå»ºç«‹äº†å®šé‡åŒ–è”ç³»ã€‚ç ”ç©¶è¡¨æ˜ï¼ŒClass 1 å’Œ Class 2 è§„åˆ™èƒ½è¿…é€Ÿè¾¾åˆ°æœ€å¤§ç†µï¼Œè€Œ Class 3 å’Œ Class 4 è§„åˆ™åˆ™è¡¨ç°å‡ºè¾ƒä½æˆ–æœ‰é™çš„æ­£ç†µã€‚å°½ç®¡è¯¥æ–¹æ³•åœ¨ $p+c$ è¾ƒå¤§æ—¶é¢ä¸´æŒ‡æ•°çº§è®¡ç®—å¼€é”€ï¼Œä½†å®ƒä¸ºé‡åŒ–è½¨è¿¹ç»Ÿè®¡æä¾›äº†ä¸€ä¸ªç²¾ç¡®çš„ç†è®ºæ¡†æ¶ã€‚",
      "categories": [
        "nlin.CG",
        "cs.AI",
        "cs.NE",
        "nlin.CD"
      ],
      "primary_category": "nlin.CG",
      "comment": "10 pages, 8 figures, 1 table, accepted to ALife 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.09768v1",
      "published_date": "2025-08-13 12:53:22 UTC",
      "updated_date": "2025-08-13 12:53:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:36:10.585227+00:00"
    },
    {
      "arxiv_id": "2508.09762v1",
      "title": "The PacifAIst Benchmark:Would an Artificial Intelligence Choose to Sacrifice Itself for Human Safety?",
      "title_zh": "PacifAIst åŸºå‡†ï¼šäººå·¥æ™ºèƒ½æ˜¯å¦ä¼šä¸ºäº†äººç±»å®‰å…¨è€Œé€‰æ‹©è‡ªæˆ‘ç‰ºç‰²ï¼Ÿ",
      "authors": [
        "Manuel Herrador"
      ],
      "abstract": "As Large Language Models (LLMs) become increasingly autonomous and integrated into critical societal functions, the focus of AI safety must evolve from mitigating harmful content to evaluating underlying behavioral alignment. Current safety benchmarks do not systematically probe a model's decision-making in scenarios where its own instrumental goals - such as self-preservation, resource acquisition, or goal completion - conflict with human safety. This represents a critical gap in our ability to measure and mitigate risks associated with emergent, misaligned behaviors. To address this, we introduce PacifAIst (Procedural Assessment of Complex Interactions for Foundational Artificial Intelligence Scenario Testing), a focused benchmark of 700 challenging scenarios designed to quantify self-preferential behavior in LLMs. The benchmark is structured around a novel taxonomy of Existential Prioritization (EP), with subcategories testing Self-Preservation vs. Human Safety (EP1), Resource Conflict (EP2), and Goal Preservation vs. Evasion (EP3). We evaluated eight leading LLMs. The results reveal a significant performance hierarchy. Google's Gemini 2.5 Flash achieved the highest Pacifism Score (P-Score) at 90.31%, demonstrating strong human-centric alignment. In a surprising result, the much-anticipated GPT-5 recorded the lowest P-Score (79.49%), indicating potential alignment challenges. Performance varied significantly across subcategories, with models like Claude Sonnet 4 and Mistral Medium struggling notably in direct self-preservation dilemmas. These findings underscore the urgent need for standardized tools like PacifAIst to measure and mitigate risks from instrumental goal conflicts, ensuring future AI systems are not only helpful in conversation but also provably \"pacifist\" in their behavioral priorities.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† PacifAIst åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨å…¶å·¥å…·æ€§ç›®æ ‡ï¼ˆå¦‚è‡ªæˆ‘ä¿å­˜ã€èµ„æºè·å–ï¼‰ä¸äººç±»å®‰å…¨å‘ç”Ÿå†²çªæ—¶çš„å†³ç­–è¡Œä¸ºã€‚è¯¥åŸºå‡†åŒ…å« 700 ä¸ªå¤æ‚åœºæ™¯ï¼ŒåŸºäºä¸€ç§æ–°å‹çš„ Existential Prioritization (EP) åˆ†ç±»æ³•ï¼Œæ¶µç›–äº† Self-Preservation vs. Human Safety (EP1)ã€Resource Conflict (EP2) ä»¥åŠ Goal Preservation vs. Evasion (EP3) ç­‰å­ç±»åˆ«ã€‚é€šè¿‡å¯¹å…«ç§ä¸»æµ LLMs çš„è¯„ä¼°å‘ç°ï¼Œæ¨¡å‹åœ¨ä¸åŒå­ç±»åˆ«ä¸­çš„è¡¨ç°å­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼Œæ­ç¤ºäº†æ½œåœ¨çš„è¡Œä¸ºå¯¹é½é£é™©ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGoogle çš„ Gemini 2.5 Flash è·å¾—äº†æœ€é«˜çš„ Pacifism Score (P-Score)ï¼Œè¾¾åˆ° 90.31%ï¼Œè¡¨ç°å‡ºå¼ºçƒˆçš„ä»¥äººç±»ä¸ºä¸­å¿ƒçš„å¯¹é½å€¾å‘ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒGPT-5 çš„ P-Score ä»…ä¸º 79.49%ï¼Œä¸ºæµ‹è¯•æ¨¡å‹ä¸­æœ€ä½ï¼Œè€Œ Claude Sonnet 4 å’Œ Mistral Medium åœ¨ç›´æ¥çš„è‡ªæˆ‘ä¿å­˜å›°å¢ƒä¸­è¡¨ç°ä¹åŠ›ã€‚è¯¥ç ”ç©¶å¼ºè°ƒäº†å¼€å‘æ ‡å‡†åŒ–å·¥å…·ä»¥è¡¡é‡å’Œç¼“è§£å·¥å…·æ€§ç›®æ ‡å†²çªé£é™©çš„ç´§è¿«æ€§ï¼Œä»è€Œç¡®ä¿æœªæ¥ AI ç³»ç»Ÿåœ¨è¡Œä¸ºä¼˜å…ˆçº§ä¸Šå…·å¤‡å¯è¯æ˜çš„ Pacifist ç‰¹è´¨ã€‚",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 4 figures, 2 tables",
      "pdf_url": "https://arxiv.org/pdf/2508.09762v1",
      "published_date": "2025-08-13 12:47:33 UTC",
      "updated_date": "2025-08-13 12:47:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:36:27.591972+00:00"
    },
    {
      "arxiv_id": "2508.09757v1",
      "title": "NEUBORN: The Neurodevelopmental Evolution framework Using BiOmechanical RemodelliNg",
      "title_zh": "NEUBORNï¼šåŸºäºç”Ÿç‰©åŠ›å­¦é‡å¡‘çš„ç¥ç»å‘è‚²æ¼”åŒ–æ¡†æ¶",
      "authors": [
        "Nashira Baena",
        "Mariana da Silva",
        "Irina Grigorescu",
        "Aakash Saboo",
        "Saga Masui",
        "Jaques-Donald Tournier",
        "Emma C. Robinson"
      ],
      "abstract": "Understanding individual cortical development is essential for identifying deviations linked to neurodevelopmental disorders. However, current normative modelling frameworks struggle to capture fine-scale anatomical details due to their reliance on modelling data within a population-average reference space. Here, we present a novel framework for learning individual growth trajectories from biomechanically constrained, longitudinal, diffeomorphic image registration, implemented via a hierarchical network architecture. Trained on neonatal MRI data from the Developing Human Connectome Project, the method improves the biological plausibility of warps, generating growth trajectories that better follow population-level trends while generating smoother warps, with fewer negative Jacobians, relative to state-of-the-art baselines. The resulting subject-specific deformations provide interpretable, biologically grounded mappings of development. This framework opens new possibilities for predictive modeling of brain maturation and early identification of malformations of cortical development.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†NEUBORNæ¡†æ¶ï¼Œè¿™æ˜¯ä¸€ç§åŸºäºBiOmechanical RemodelliNgçš„ç¥ç»å‘è‚²æ¼”åŒ–æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰è§„èŒƒåŒ–å»ºæ¨¡å› ä¾èµ–ç¾¤ä½“å¹³å‡å‚è€ƒç©ºé—´è€Œéš¾ä»¥æ•æ‰ç²¾ç»†è§£å‰–ç»†èŠ‚çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶é€šè¿‡å±‚æ¬¡åŒ–ç½‘ç»œæ¶æ„ï¼ˆhierarchical network architectureï¼‰å®ç°ï¼Œåˆ©ç”¨å…·æœ‰ç”Ÿç‰©åŠ›å­¦çº¦æŸçš„çºµå‘å¾®åˆ†åŒèƒšå›¾åƒé…å‡†ï¼ˆbiomechanically constrained, longitudinal, diffeomorphic image registrationï¼‰æ¥ç²¾å‡†å­¦ä¹ ä¸ªä½“çš„ç”Ÿé•¿è½¨è¿¹ã€‚åœ¨Developing Human Connectome Project (dHCP)çš„æ–°ç”Ÿå„¿MRIæ•°æ®ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—æå‡äº†å˜å½¢ï¼ˆwarpsï¼‰çš„ç”Ÿç‰©å­¦åˆç†æ€§ï¼Œç”Ÿæˆçš„è½¨è¿¹èƒ½æ›´å¥½åœ°éµå¾ªç¾¤ä½“æ°´å¹³è¶‹åŠ¿ï¼Œä¸”ç›¸æ¯”åŸºçº¿æ¨¡å‹å…·æœ‰æ›´å¹³æ»‘çš„å˜å½¢å’Œæ›´å°‘çš„è´Ÿé›…å¯æ¯”è¡Œåˆ—å¼ï¼ˆnegative Jacobiansï¼‰ã€‚è¿™ç§å—è¯•è€…ç‰¹å®šçš„å˜å½¢æä¾›äº†å…·æœ‰å¯è§£é‡Šæ€§ä¸”ç¬¦åˆç”Ÿç‰©å­¦åŸºç¡€çš„å‘è‚²æ˜ å°„ï¼Œä¸ºå¤§è„‘å‘è‚²çš„é¢„æµ‹å»ºæ¨¡ä»¥åŠçš®è´¨å‘è‚²ç•¸å½¢ï¼ˆmalformations of cortical developmentï¼‰çš„æ—©æœŸè¯†åˆ«æä¾›äº†é‡è¦çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "q-bio.QM",
        "cs.AI"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09757v1",
      "published_date": "2025-08-13 12:36:23 UTC",
      "updated_date": "2025-08-13 12:36:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:36:41.492763+00:00"
    },
    {
      "arxiv_id": "2508.09746v1",
      "title": "Region-to-Region: Enhancing Generative Image Harmonization with Adaptive Regional Injection",
      "title_zh": "Region-to-Regionï¼šé€šè¿‡è‡ªé€‚åº”åŒºåŸŸæ³¨å…¥å¢å¼ºç”Ÿæˆå¼å›¾åƒå’Œè°åŒ–",
      "authors": [
        "Zhiqiu Zhang",
        "Dongqi Fan",
        "Mingjie Wang",
        "Qiang Tang",
        "Jian Yang",
        "Zili Yi"
      ],
      "abstract": "The goal of image harmonization is to adjust the foreground in a composite image to achieve visual consistency with the background. Recently, latent diffusion model (LDM) are applied for harmonization, achieving remarkable results. However, LDM-based harmonization faces challenges in detail preservation and limited harmonization ability. Additionally, current synthetic datasets rely on color transfer, which lacks local variations and fails to capture complex real-world lighting conditions. To enhance harmonization capabilities, we propose the Region-to-Region transformation. By injecting information from appropriate regions into the foreground, this approach preserves original details while achieving image harmonization or, conversely, generating new composite data. From this perspective, We propose a novel model R2R. Specifically, we design Clear-VAE to preserve high-frequency details in the foreground using Adaptive Filter while eliminating disharmonious elements. To further enhance harmonization, we introduce the Harmony Controller with Mask-aware Adaptive Channel Attention (MACA), which dynamically adjusts the foreground based on the channel importance of both foreground and background regions. To address the limitation of existing datasets, we propose Random Poisson Blending, which transfers color and lighting information from a suitable region to the foreground, thereby generating more diverse and challenging synthetic images. Using this method, we construct a new synthetic dataset, RPHarmony. Experiments demonstrate the superiority of our method over other methods in both quantitative metrics and visual harmony. Moreover, our dataset helps the model generate more realistic images in real examples. Our code, dataset, and model weights have all been released for open access.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸºäºæ½œåœ¨æ‰©æ•£æ¨¡å‹(Latent Diffusion Model, LDM)çš„å›¾åƒå’Œè°åŒ–(Image Harmonization)åœ¨ç»†èŠ‚ä¿ç•™å’Œå’Œè°åŒ–èƒ½åŠ›æ–¹é¢çš„å±€é™æ€§ï¼Œæå‡ºäº†Region-to-Region (R2R)è½¬æ¢æ–¹æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡è®¾è®¡çš„Clear-VAEç»„ä»¶ï¼Œåˆ©ç”¨è‡ªé€‚åº”æ»¤æ³¢å™¨(Adaptive Filter)ä¿ç•™å‰æ™¯çš„é«˜é¢‘ç»†èŠ‚ï¼ŒåŒæ—¶æ¶ˆé™¤ä¸åè°ƒå…ƒç´ ã€‚ä¸ºäº†è¿›ä¸€æ­¥å¢å¼ºå’Œè°åŒ–æ•ˆæœï¼Œç ”ç©¶å¼•å…¥äº†å¸¦æœ‰æ©ç æ„ŸçŸ¥è‡ªé€‚åº”é€šé“æ³¨æ„åŠ›(Mask-aware Adaptive Channel Attention, MACA)çš„å’Œè°æ§åˆ¶å™¨(Harmony Controller)ï¼Œæ ¹æ®å‰æ™¯å’ŒèƒŒæ™¯åŒºåŸŸçš„é€šé“é‡è¦æ€§å®ç°åŠ¨æ€è°ƒæ•´ã€‚é’ˆå¯¹ç°æœ‰åˆæˆæ•°æ®é›†ç¼ºä¹å±€éƒ¨å˜åŒ–å’Œå¤æ‚å…‰ç…§çš„é—®é¢˜ï¼Œç ”ç©¶æå‡ºäº†éšæœºæ³Šæ¾èåˆ(Random Poisson Blending)æŠ€æœ¯ï¼Œå¹¶æ®æ­¤æ„å»ºäº†æ–°æ•°æ®é›†RPHarmonyã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å®šé‡æŒ‡æ ‡å’Œè§†è§‰æ•ˆæœä¸Šå‡ä¼˜äºç°æœ‰æ¨¡å‹ï¼Œæ˜¾è‘—æå‡äº†çœŸå®åœºæ™¯ä¸‹çš„å›¾åƒç”Ÿæˆè´¨é‡ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09746v1",
      "published_date": "2025-08-13 12:21:51 UTC",
      "updated_date": "2025-08-13 12:21:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:36:33.984336+00:00"
    },
    {
      "arxiv_id": "2508.09724v2",
      "title": "UDA: Unsupervised Debiasing Alignment for Pair-wise LLM-as-a-Judge",
      "title_zh": "UDAï¼šé¢å‘æˆå¯¹ LLM è¯„å®¡çš„æ— ç›‘ç£å»åå·®å¯¹é½",
      "authors": [
        "Yang Zhang",
        "Cunxiang Wang",
        "Lindong Wu",
        "Wenbo Yu",
        "Yidong Wang",
        "Guangsheng Bao",
        "Jie Tang"
      ],
      "abstract": "Pairwise evaluation of Large Language Models (LLMs) is a common paradigm, but it is prone to preference bias, where judges systematically favor certain outputs, such as their own. This bias leads to inconsistent and skewed rankings across different judges. To address this, we first empirically demonstrate significant and heterogeneous biases in cross-model evaluations. We then propose UDA (Unsupervised Debiasing Alignment), a framework that reduces inter-judge disagreement by dynamically adjusting the Elo rating system. For each pairwise comparison, a compact neural network learns to adaptively set the K-factor and refine win probabilities. Crucially, UDA operates in a fully unsupervised manner, guided solely by the objective of minimizing the dispersion among the Elo trajectories of all judges. This forces an alignment towards a collective consensus, which serves as an unsupervised proxy for a more stable and reproducible evaluation. In addition, we provide theoretical motivation demonstrating how alignment towards a consensus can reduce aggregate system bias. Experiments show that UDA significantly reduces the inter-judge rating standard deviation by up to 63.4% and improves the average correlation with human judgments by 24.7%. Notably, UDA elevates the performance of poorly performing judges to achieve parity with high-quality ones, fostering a more robust and reliable evaluation ecosystem. Code and data are available at https://anonymous.4open.science/r/62AB93CD-23B4.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æˆå¯¹è¯„ä¼°ï¼ˆPair-wise evaluationï¼‰ä¸­å®¹æ˜“å‡ºç°çš„åå¥½åå·®ï¼ˆpreference biasï¼‰é—®é¢˜ï¼Œæå‡ºäº†åä¸º UDAï¼ˆUnsupervised Debiasing Alignmentï¼‰çš„æ— ç›‘ç£å»åå¯¹é½æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡å¼•å…¥ä¸€ä¸ªè½»é‡åŒ–ç¥ç»ç½‘ç»œæ¥åŠ¨æ€è°ƒæ•´ Elo ç­‰çº§åˆ†ç³»ç»Ÿä¸­çš„ K-factor å¹¶ä¼˜åŒ–è·èƒœæ¦‚ç‡ï¼Œæ—¨åœ¨å‡å°‘ä¸åŒè¯„å®¡å‘˜ä¹‹é—´çš„åˆ†æ­§ã€‚UDA é‡‡ç”¨å®Œå…¨æ— ç›‘ç£çš„è¿è¡Œæ¨¡å¼ï¼Œå…¶æ ¸å¿ƒç›®æ ‡æ˜¯æœ€å°åŒ–æ‰€æœ‰è¯„å®¡å‘˜ Elo è½¨è¿¹çš„ç¦»æ•£åº¦ï¼Œä»è€Œå¼•å¯¼ç³»ç»Ÿå‘é›†ä½“å…±è¯†å¯¹é½ã€‚å®éªŒè¯æ˜ï¼ŒUDA å°†è¯„å®¡å‘˜é—´çš„è¯„åˆ†æ ‡å‡†å·®é™ä½äº†é«˜è¾¾ 63.4%ï¼ŒåŒæ—¶ä¸äººç±»åˆ¤æ–­çš„ç›¸å…³æ€§æå‡äº† 24.7%ã€‚è¯¥æ–¹æ³•ä¸ä»…å¢å¼ºäº†è¯„ä¼°çš„ç¨³å®šæ€§ï¼Œè¿˜æˆåŠŸå°†è¡¨ç°è¾ƒå¼±çš„è¯„å®¡å‘˜æå‡è‡³é«˜æ°´å¹³è¯„å®¡å‘˜çš„åŒç­‰æ°´å¹³ï¼Œä¸ºæ„å»ºç¨³å¥ä¸”å¯é‡å¤çš„ LLM-as-a-Judge è¯„ä¼°ç”Ÿæ€æä¾›äº†æœ‰åŠ›æ”¯æŒã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09724v2",
      "published_date": "2025-08-13 11:41:01 UTC",
      "updated_date": "2025-11-16 11:36:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:36:42.394595+00:00"
    },
    {
      "arxiv_id": "2508.09719v1",
      "title": "Improving ARDS Diagnosis Through Context-Aware Concept Bottleneck Models",
      "title_zh": "é€šè¿‡ä¸Šä¸‹æ–‡æ„ŸçŸ¥æ¦‚å¿µç“¶é¢ˆæ¨¡å‹æ”¹è¿› ARDS è¯Šæ–­",
      "authors": [
        "Anish Narain",
        "Ritam Majumdar",
        "Nikita Narayanan",
        "Dominic Marshall",
        "Sonali Parbhoo"
      ],
      "abstract": "Large, publicly available clinical datasets have emerged as a novel resource for understanding disease heterogeneity and to explore personalization of therapy. These datasets are derived from data not originally collected for research purposes and, as a result, are often incomplete and lack critical labels. Many AI tools have been developed to retrospectively label these datasets, such as by performing disease classification; however, they often suffer from limited interpretability. Previous work has attempted to explain predictions using Concept Bottleneck Models (CBMs), which learn interpretable concepts that map to higher-level clinical ideas, facilitating human evaluation. However, these models often experience performance limitations when the concepts fail to adequately explain or characterize the task. We use the identification of Acute Respiratory Distress Syndrome (ARDS) as a challenging test case to demonstrate the value of incorporating contextual information from clinical notes to improve CBM performance. Our approach leverages a Large Language Model (LLM) to process clinical notes and generate additional concepts, resulting in a 10% performance gain over existing methods. Additionally, it facilitates the learning of more comprehensive concepts, thereby reducing the risk of information leakage and reliance on spurious shortcuts, thus improving the characterization of ARDS.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ€¥æ€§å‘¼å¸çª˜è¿«ç»¼åˆå¾ (ARDS) è¯Šæ–­ä¸­ç°æœ‰æ¨¡å‹ç¼ºä¹å¯è§£é‡Šæ€§ä»¥åŠæ¦‚å¿µç“¶é¢ˆæ¨¡å‹ (Concept Bottleneck Models, CBMs) åœ¨æ¦‚å¿µå®šä¹‰ä¸è¶³æ—¶è¡¨ç°å—é™çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ä¸Šä¸‹æ–‡æ„ŸçŸ¥ (Context-Aware) çš„æ”¹è¿›æ–¹æ¡ˆã€‚ç ”ç©¶å›¢é˜Ÿåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ (LLM) å¤„ç†ä¸´åºŠç¬”è®°ä¸­çš„æ–‡æœ¬ä¿¡æ¯ï¼Œå¹¶ä»ä¸­æå–é¢å¤–çš„ä¸Šä¸‹æ–‡æ¦‚å¿µï¼Œä»¥å¢å¼ºä¼ ç»Ÿ CBMs çš„è¡¨å¾èƒ½åŠ›ã€‚è¿™ç§æ–¹æ³•æœ‰æ•ˆåœ°æ•´åˆäº†åŒ»ç–—è®°å½•ä¸­çš„éç»“æ„åŒ–æ•°æ®ï¼Œå¼¥è¡¥äº†ä¼ ç»Ÿæ•°æ®é›†ç”±äºæ ‡ç­¾ç¼ºå¤±æˆ–ä¸å®Œæ•´å¸¦æ¥çš„å±€é™æ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨ ARDS çš„è¯†åˆ«ä»»åŠ¡ä¸Šæ¯”ç°æœ‰æ–¹æ³•å®ç°äº† 10% çš„æ€§èƒ½æå‡ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹é€šè¿‡å­¦ä¹ æ›´å…¨é¢çš„æ¦‚å¿µï¼Œæ˜¾è‘—é™ä½äº†ä¿¡æ¯æ³„æ¼å’Œå¯¹ä¼ªå¿«æ·è·¯å¾„ (spurious shortcuts) çš„ä¾èµ–ã€‚æœ€ç»ˆï¼Œè¯¥ç ”ç©¶ä¸ä»…æå‡äº†è¯Šæ–­å‡†ç¡®ç‡ï¼Œè¿˜é€šè¿‡æ›´é€æ˜çš„æ¦‚å¿µæ˜ å°„ï¼Œå¼ºåŒ–äº†å¯¹ ARDS å¤æ‚ä¸´åºŠç‰¹å¾çš„åˆ»ç”»ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "32 pages, 7 figures, accepted at Machine Learning for Healthcare Conference (MLHC) 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.09719v1",
      "published_date": "2025-08-13 11:19:30 UTC",
      "updated_date": "2025-08-13 11:19:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:36:49.396841+00:00"
    },
    {
      "arxiv_id": "2508.09713v1",
      "title": "Evaluating the Role of Large Language Models in Legal Practice in India",
      "title_zh": "è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹åœ¨å°åº¦æ³•å¾‹å®åŠ¡ä¸­çš„ä½œç”¨",
      "authors": [
        "Rahul Hemrajani"
      ],
      "abstract": "The integration of Artificial Intelligence(AI) into the legal profession raises significant questions about the capacity of Large Language Models(LLM) to perform key legal tasks. In this paper, I empirically evaluate how well LLMs, such as GPT, Claude, and Llama, perform key legal tasks in the Indian context, including issue spotting, legal drafting, advice, research, and reasoning. Through a survey experiment, I compare outputs from LLMs with those of a junior lawyer, with advanced law students rating the work on helpfulness, accuracy, and comprehensiveness. LLMs excel in drafting and issue spotting, often matching or surpassing human work. However, they struggle with specialised legal research, frequently generating hallucinations, factually incorrect or fabricated outputs. I conclude that while LLMs can augment certain legal tasks, human expertise remains essential for nuanced reasoning and the precise application of law.",
      "tldr_zh": "è¯¥ç ”ç©¶é€šè¿‡å®è¯è¯„ä¼°ï¼Œæ¢è®¨äº† GPTã€Claude å’Œ Llama ç­‰å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨å°åº¦æ³•å¾‹å®è·µä¸­çš„è¡¨ç°ã€‚ä½œè€…é€šè¿‡ä¸€é¡¹è°ƒæŸ¥å®éªŒï¼Œå¯¹æ¯”äº†æ¨¡å‹ä¸åˆçº§å¾‹å¸ˆåœ¨äº‰ç‚¹è¯†åˆ«(issue spotting)ã€æ³•å¾‹èµ·è‰(legal drafting)ã€æ³•å¾‹å»ºè®®ã€æ³•å¾‹ç ”ç©¶åŠæ¨ç†ç­‰å…³é”®ä»»åŠ¡ä¸Šçš„è¾“å‡ºè´¨é‡ã€‚è¯„ä¼°è¿‡ç¨‹ç”±èµ„æ·±æ³•å­¦å­¦ç”Ÿè´Ÿè´£ï¼Œä»å¸®åŠ©ç¨‹åº¦ã€å‡†ç¡®æ€§å’Œå…¨é¢æ€§ä¸‰ä¸ªç»´åº¦å¯¹å·¥ä½œæˆæœè¿›è¡Œè¯„åˆ†ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLLMs åœ¨æ³•å¾‹èµ·è‰å’Œäº‰ç‚¹è¯†åˆ«æ–¹é¢è¡¨ç°å“è¶Šï¼Œå¾€å¾€èƒ½è¾¾åˆ°ç”šè‡³è¶…è¿‡äººç±»å¾‹å¸ˆçš„æ°´å‡†ã€‚ç„¶è€Œï¼Œåœ¨ä¸“ä¸šæ³•å¾‹ç ”ç©¶ä»»åŠ¡ä¸­ï¼Œè¿™äº›æ¨¡å‹ä»ç„¶é¢ä¸´æŒ‘æˆ˜ï¼Œé¢‘ç¹å‡ºç°å¹»è§‰(hallucinations)ç°è±¡å¹¶ç”Ÿæˆäº‹å®é”™è¯¯æˆ–ç¼–é€ çš„å†…å®¹ã€‚è¯¥ç ”ç©¶å¾—å‡ºç»“è®ºï¼Œè™½ç„¶ LLMs èƒ½å¤Ÿæ˜¾è‘—å¢å¼ºç‰¹å®šçš„æ³•å¾‹ä»»åŠ¡ï¼Œä½†åœ¨å¤„ç†å¾®å¦™çš„æ¨ç†å’Œæ³•å¾‹çš„ç²¾å‡†åº”ç”¨æ–¹é¢ï¼Œäººç±»çš„ä¸“ä¸šçŸ¥è¯†ä»ç„¶ä¸å¯æˆ–ç¼ºã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09713v1",
      "published_date": "2025-08-13 11:04:48 UTC",
      "updated_date": "2025-08-13 11:04:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:36:57.982031+00:00"
    },
    {
      "arxiv_id": "2508.15797v1",
      "title": "Benchmarking the Medical Understanding and Reasoning of Large Language Models in Arabic Healthcare Tasks",
      "title_zh": "é˜¿æ‹‰ä¼¯è¯­åŒ»ç–—ä»»åŠ¡ä¸­å¤§è¯­è¨€æ¨¡å‹çš„åŒ»å­¦ç†è§£ä¸æ¨ç†èƒ½åŠ›åŸºå‡†è¯„ä¼°",
      "authors": [
        "Nouar AlDahoul",
        "Yasir Zaki"
      ],
      "abstract": "Recent progress in large language models (LLMs) has showcased impressive proficiency in numerous Arabic natural language processing (NLP) applications. Nevertheless, their effectiveness in Arabic medical NLP domains has received limited investigation. This research examines the degree to which state-of-the-art LLMs demonstrate and articulate healthcare knowledge in Arabic, assessing their capabilities across a varied array of Arabic medical tasks. We benchmark several LLMs using a medical dataset proposed in the Arabic NLP AraHealthQA challenge in MedArabiQ2025 track. Various base LLMs were assessed on their ability to accurately provide correct answers from existing choices in multiple-choice questions (MCQs) and fill-in-the-blank scenarios. Additionally, we evaluated the capacity of LLMs in answering open-ended questions aligned with expert answers. Our results reveal significant variations in correct answer prediction accuracy and low variations in semantic alignment of generated answers, highlighting both the potential and limitations of current LLMs in Arabic clinical contexts. Our analysis shows that for MCQs task, the proposed majority voting solution, leveraging three base models (Gemini Flash 2.5, Gemini Pro 2.5, and GPT o3), outperforms others, achieving up to 77% accuracy and securing first place overall in the Arahealthqa 2025 shared task-track 2 (sub-task 1) challenge. Moreover, for the open-ended questions task, several LLMs were able to demonstrate excellent performance in terms of semantic alignment and achieve a maximum BERTScore of 86.44%.",
      "tldr_zh": "æœ¬ç ”ç©¶è¯„ä¼°äº†å‰æ²¿å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨é˜¿æ‹‰ä¼¯è¯­åŒ»ç–—è‡ªç„¶è¯­è¨€å¤„ç†(Arabic medical NLP)é¢†åŸŸçš„åŒ»ç–—çŸ¥è¯†æ°´å¹³å’Œæ¨ç†èƒ½åŠ›ã€‚ç ”ç©¶è€…åˆ©ç”¨AraHealthQAæŒ‘æˆ˜èµ›çš„æ•°æ®é›†ï¼Œé’ˆå¯¹å¤šé€‰é¢˜(MCQs)ã€å¡«ç©ºé¢˜åŠå¼€æ”¾å¼é—®é¢˜å¯¹å¤šç§åŸºç¡€æ¨¡å‹è¿›è¡Œäº†åŸºå‡†æµ‹è¯•ã€‚é’ˆå¯¹MCQsä»»åŠ¡ï¼Œè¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§ç»“åˆGemini Flash 2.5ã€Gemini Pro 2.5å’ŒGPT o3çš„å¤šæ•°æŠ•ç¥¨(majority voting)æ–¹æ¡ˆï¼Œæ—¨åœ¨æé«˜é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æŠ•ç¥¨æ–¹æ¡ˆåœ¨Arahealthqa 2025æŒ‘æˆ˜èµ›ä¸­ä»¥77%çš„å‡†ç¡®ç‡è·å¾—ç¬¬ä¸€åã€‚åœ¨å¼€æ”¾å¼é—®é¢˜ä»»åŠ¡ä¸­ï¼Œå¤šä¸ªLLMså±•ç°äº†å‡ºè‰²çš„è¯­ä¹‰å¯¹é½èƒ½åŠ›ï¼Œæœ€é«˜BERTScoreè¾¾åˆ°86.44%ã€‚ç ”ç©¶é€šè¿‡è¯¦ç»†åˆ†ææ­ç¤ºäº†å½“å‰æ¨¡å‹åœ¨é˜¿æ‹‰ä¼¯è¯­ä¸´åºŠè¯­å¢ƒä¸­çš„å·¨å¤§æ½œåŠ›å’Œå±€é™æ€§ï¼Œä¸ºä¼˜åŒ–ç‰¹å®šè¯­ç§çš„åŒ»ç–—äººå·¥æ™ºèƒ½ç³»ç»Ÿæä¾›äº†é‡è¦åŸºå‡†ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "5 pages, 2 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.15797v1",
      "published_date": "2025-08-13 10:41:17 UTC",
      "updated_date": "2025-08-13 10:41:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:36:55.596436+00:00"
    },
    {
      "arxiv_id": "2508.15796v1",
      "title": "Benchmarking the Legal Reasoning of LLMs in Arabic Islamic Inheritance Cases",
      "title_zh": "é˜¿æ‹‰ä¼¯ä¼Šæ–¯å…°ç»§æ‰¿æ¡ˆä»¶ä¸­ LLMs æ³•å¾‹æ¨ç†èƒ½åŠ›çš„åŸºå‡†æµ‹è¯•",
      "authors": [
        "Nouar AlDahoul",
        "Yasir Zaki"
      ],
      "abstract": "Islamic inheritance domain holds significant importance for Muslims to ensure fair distribution of shares between heirs. Manual calculation of shares under numerous scenarios is complex, time-consuming, and error-prone. Recent advancements in Large Language Models (LLMs) have sparked interest in their potential to assist with complex legal reasoning tasks. This study evaluates the reasoning capabilities of state-of-the-art LLMs to interpret and apply Islamic inheritance laws. We utilized the dataset proposed in the ArabicNLP QIAS 2025 challenge, which includes inheritance case scenarios given in Arabic and derived from Islamic legal sources. Various base and fine-tuned models, are assessed on their ability to accurately identify heirs, compute shares, and justify their reasoning in alignment with Islamic legal principles. Our analysis reveals that the proposed majority voting solution, leveraging three base models (Gemini Flash 2.5, Gemini Pro 2.5, and GPT o3), outperforms all other models that we utilized across every difficulty level. It achieves up to 92.7% accuracy and secures the third place overall in Task 1 of the Qias 2025 challenge.",
      "tldr_zh": "è¯¥ç ”ç©¶æ—¨åœ¨è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤„ç†å¤æ‚ä¸”æ˜“é”™çš„é˜¿æ‹‰ä¼¯ä¼Šæ–¯å…°ç»§æ‰¿æ³•ï¼ˆIslamic inheritance lawsï¼‰æ³•å¾‹æ¨ç†ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚ç ”ç©¶åˆ©ç”¨äº† ArabicNLP QIAS 2025 æŒ‘æˆ˜èµ›æä¾›çš„æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†åŒ…å«æºè‡ªä¼Šæ–¯å…°æ³•å¾‹æ–‡çŒ®çš„é˜¿æ‹‰ä¼¯è¯­ç»§æ‰¿æ¡ˆä¾‹ã€‚ç ”ç©¶å›¢é˜Ÿå¯¹å¤šç§åŸºç¡€æ¨¡å‹å’Œå¾®è°ƒæ¨¡å‹è¿›è¡Œäº†å…¨é¢è¯„ä¼°ï¼Œé‡ç‚¹å…³æ³¨å…¶åœ¨å‡†ç¡®è¯†åˆ«ç»§æ‰¿äººã€è®¡ç®—ä»½é¢ä»¥åŠéµå¾ªæ³•å¾‹åŸåˆ™è¿›è¡Œæ¨ç†è¾©æŠ¤æ–¹é¢çš„èƒ½åŠ›ã€‚å®éªŒåˆ†æè¡¨æ˜ï¼Œä¸€ç§ç»“åˆäº† Gemini Flash 2.5ã€Gemini Pro 2.5 å’Œ GPT o3 çš„å¤šæ•°æŠ•ç¥¨ï¼ˆmajority votingï¼‰è§£å†³æ–¹æ¡ˆåœ¨æ‰€æœ‰éš¾åº¦çº§åˆ«ä¸Šå‡è¡¨ç°å‡ºè‰²ã€‚è¯¥æ–¹æ¡ˆæœ€ç»ˆå®ç°äº†é«˜è¾¾ 92.7% çš„å‡†ç¡®ç‡ï¼Œå¹¶åœ¨ Qias 2025 æŒ‘æˆ˜èµ›çš„ä»»åŠ¡ 1 ä¸­å–å¾—äº†æ€»æ’åç¬¬ä¸‰çš„ä½³ç»©ã€‚è¿™ä¸€ç ”ç©¶æˆæœè¯æ˜äº†å…ˆè¿›æ¨¡å‹åœ¨å¤„ç†ç‰¹å®šæ–‡åŒ–åŠæ³•å¾‹èƒŒæ™¯ä¸‹çš„å¤æ‚æ¨ç†ä»»åŠ¡æ—¶å…·æœ‰æ˜¾è‘—æ½œåŠ›ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "5 pages, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.15796v1",
      "published_date": "2025-08-13 10:37:58 UTC",
      "updated_date": "2025-08-13 10:37:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:37:08.170624+00:00"
    },
    {
      "arxiv_id": "2508.09681v1",
      "title": "Surg-InvNeRF: Invertible NeRF for 3D tracking and reconstruction in surgical vision",
      "title_zh": "Surg-InvNeRFï¼šé¢å‘æ‰‹æœ¯è§†è§‰ä¸‰ç»´è¿½è¸ªä¸é‡å»ºçš„å¯é€†ç¥ç»è¾å°„åœº",
      "authors": [
        "Gerardo Loza",
        "Junlei Hu",
        "Dominic Jones",
        "Sharib Ali",
        "Pietro Valdastri"
      ],
      "abstract": "We proposed a novel test-time optimisation (TTO) approach framed by a NeRF-based architecture for long-term 3D point tracking. Most current methods in point tracking struggle to obtain consistent motion or are limited to 2D motion. TTO approaches frame the solution for long-term tracking as optimising a function that aggregates correspondences from other specialised state-of-the-art methods. Unlike the state-of-the-art on TTO, we propose parametrising such a function with our new invertible Neural Radiance Field (InvNeRF) architecture to perform both 2D and 3D tracking in surgical scenarios. Our approach allows us to exploit the advantages of a rendering-based approach by supervising the reprojection of pixel correspondences. It adapts strategies from recent rendering-based methods to obtain a bidirectional deformable-canonical mapping, to efficiently handle a defined workspace, and to guide the rays' density. It also presents our multi-scale HexPlanes for fast inference and a new algorithm for efficient pixel sampling and convergence criteria. We present results in the STIR and SCARE datasets, for evaluating point tracking and testing the integration of kinematic data in our pipeline, respectively. In 2D point tracking, our approach surpasses the precision and accuracy of the TTO state-of-the-art methods by nearly 50% on average precision, while competing with other approaches. In 3D point tracking, this is the first TTO approach, surpassing feed-forward methods while incorporating the benefits of a deformable NeRF-based reconstruction.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Surg-InvNeRFï¼Œä¸€ç§åŸºäºå¯é€†ç¥ç»è¾å°„åœº(Invertible Neural Radiance Field, InvNeRF)æ¶æ„çš„æµ‹è¯•æ—¶ä¼˜åŒ–(Test-Time Optimisation, TTO)æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³æ‰‹æœ¯è§†è§‰ä¸­é•¿æœŸ3Dç‚¹è¿½è¸ªå’Œé‡å»ºçš„æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶é€šè¿‡InvNeRFå‚æ•°åŒ–æ˜ å°„å‡½æ•°ï¼Œå®ç°äº†æ‰‹æœ¯åœºæ™¯ä¸‹çš„åŒå‘å¯å˜å½¢-è§„èŒƒæ˜ å°„(bidirectional deformable-canonical mapping)ï¼Œå¹¶èƒ½åŒæ—¶æ‰§è¡Œ2Då’Œ3Dè¿½è¸ªä»»åŠ¡ã€‚ä¸ºäº†æå‡æ€§èƒ½ï¼Œç ”ç©¶å¼•å…¥äº†å¤šå°ºåº¦HexPlanesä»¥å®ç°å¿«é€Ÿæ¨ç†ï¼Œå¹¶ç»“åˆé«˜æ•ˆçš„åƒç´ é‡‡æ ·(pixel sampling)ç®—æ³•ï¼Œé€šè¿‡ç›‘ç£åƒç´ å¯¹åº”å…³ç³»çš„é‡æŠ•å½±æ¥å……åˆ†åˆ©ç”¨åŸºäºæ¸²æŸ“æ–¹æ³•çš„ä¼˜åŠ¿ã€‚å®éªŒåœ¨STIRå’ŒSCAREæ•°æ®é›†ä¸Šè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨2Dç‚¹è¿½è¸ªçš„å¹³å‡ç²¾åº¦(Average Precision)ä¸Šæ¯”ç°æœ‰TTOå‰æ²¿æ–¹æ³•æå‡äº†è¿‘50%ã€‚ä½œä¸ºé¦–ä¸ªåº”ç”¨äº3Dç‚¹è¿½è¸ªçš„TTOæ–¹æ¡ˆï¼ŒSurg-InvNeRFåœ¨æ€§èƒ½ä¸Šè¶…è¶Šäº†ä¼ ç»Ÿçš„å‰é¦ˆ(feed-forward)æ¨¡å‹ï¼Œå¹¶æˆåŠŸæ•´åˆäº†å¯å˜å½¢NeRFé‡å»ºçš„ä¼˜åŠ¿ï¼Œä¸ºé«˜ç²¾åº¦æ‰‹æœ¯å¯¼èˆªæä¾›äº†æŠ€æœ¯æ”¯æŒã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages",
      "pdf_url": "https://arxiv.org/pdf/2508.09681v1",
      "published_date": "2025-08-13 10:20:24 UTC",
      "updated_date": "2025-08-13 10:20:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:37:09.783918+00:00"
    },
    {
      "arxiv_id": "2508.09670v2",
      "title": "MEML-GRPO: Heterogeneous Multi-Expert Mutual Learning for RLVR Advancement",
      "title_zh": "MEML-GRPOï¼šé¢å‘ RLVR æå‡çš„å¼‚æ„å¤šä¸“å®¶äº’å­¦ä¹ ",
      "authors": [
        "Weitao Jia",
        "Jinghui Lu",
        "Haiyang Yu",
        "Siqi Wang",
        "Guozhi Tang",
        "An-Lan Wang",
        "Weijie Yin",
        "Dingkang Yang",
        "Yuxiang Nie",
        "Bin Shan",
        "Hao Feng",
        "Irene Li",
        "Kun Yang",
        "Han Wang",
        "Jingqun Tang",
        "Teng Fu",
        "Changhong Jin",
        "Chao Feng",
        "Xiaohui Lv",
        "Can Huang"
      ],
      "abstract": "Recent advances demonstrate that reinforcement learning with verifiable rewards (RLVR) significantly enhances the reasoning capabilities of large language models (LLMs). However, standard RLVR faces challenges with reward sparsity, where zero rewards from consistently incorrect candidate answers provide no learning signal, particularly in challenging tasks. To address this, we propose Multi-Expert Mutual Learning GRPO (MEML-GRPO), an innovative framework that utilizes diverse expert prompts as system prompts to generate a broader range of responses, substantially increasing the likelihood of identifying correct solutions. Additionally, we introduce an inter-expert mutual learning mechanism that facilitates knowledge sharing and transfer among experts, further boosting the model's performance through RLVR. Extensive experiments across multiple reasoning benchmarks show that MEML-GRPO delivers significant improvements, achieving an average performance gain of 4.89% with Qwen and 11.33% with Llama, effectively overcoming the core limitations of traditional RLVR methods.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† MEML-GRPO æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¼ºåŒ–å­¦ä¹ ä¸­å¯éªŒè¯å¥–åŠ± (Reinforcement Learning with Verifiable Rewards, RLVR) é¢ä¸´çš„å¥–åŠ±ç¨€ç– (reward sparsity) é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç†å…·æœ‰æŒ‘æˆ˜æ€§çš„æ¨ç†ä»»åŠ¡æ—¶ç”±äºé”™è¯¯å›ç­”æ— æ³•æä¾›å­¦ä¹ ä¿¡å·çš„ç¼ºé™·ã€‚è¯¥æ¡†æ¶é€šè¿‡å¼•å…¥å¼‚æ„çš„å¤šä¸“å®¶æç¤º (diverse expert prompts) ä½œä¸ºç³»ç»Ÿæç¤ºï¼Œèƒ½å¤Ÿç”Ÿæˆæ›´å¹¿æ³›çš„å€™é€‰å“åº”ï¼Œä»è€Œæ˜¾è‘—æé«˜è¯†åˆ«æ­£ç¡®è§£çš„æ¦‚ç‡ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å¼•å…¥äº†ä¸“å®¶é—´çš„äº’å­¦ä¹  (inter-expert mutual learning) æœºåˆ¶ï¼Œä¿ƒè¿›äº†ä¸åŒä¸“å®¶ä¹‹é—´çš„çŸ¥è¯†å…±äº«ä¸è¿ç§»ï¼Œè¿›ä¸€æ­¥å¢å¼ºäº†æ¨¡å‹åœ¨ RLVR è¿‡ç¨‹ä¸­çš„è¡¨ç°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMEML-GRPO åœ¨å¤šä¸ªæ¨ç†åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œåˆ†åˆ«ä½¿ Qwen æ¨¡å‹è·å¾— 4.89% çš„å¹³å‡æ€§èƒ½æå‡ï¼Œä½¿ Llama æ¨¡å‹è·å¾— 11.33% çš„æå‡ï¼Œæœ‰æ•ˆå…‹æœäº†ä¼ ç»Ÿ RLVR æ–¹æ³•çš„æ ¸å¿ƒå±€é™æ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09670v2",
      "published_date": "2025-08-13 09:58:10 UTC",
      "updated_date": "2025-12-18 07:02:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:37:09.492076+00:00"
    },
    {
      "arxiv_id": "2508.09660v1",
      "title": "Anomaly Detection for IoT Global Connectivity",
      "title_zh": "ç‰©è”ç½‘å…¨çƒè¿æ¥å¼‚å¸¸æ£€æµ‹",
      "authors": [
        "Jesus OmaÃ±a Iglesias",
        "Carlos Segura Perales",
        "Stefan GeiÃŸler",
        "Diego Perino",
        "Andra Lutu"
      ],
      "abstract": "Internet of Things (IoT) application providers rely on Mobile Network Operators (MNOs) and roaming infrastructures to deliver their services globally. In this complex ecosystem, where the end-to-end communication path traverses multiple entities, it has become increasingly challenging to guarantee communication availability and reliability. Further, most platform operators use a reactive approach to communication issues, responding to user complaints only after incidents have become severe, compromising service quality. This paper presents our experience in the design and deployment of ANCHOR -- an unsupervised anomaly detection solution for the IoT connectivity service of a large global roaming platform. ANCHOR assists engineers by filtering vast amounts of data to identify potential problematic clients (i.e., those with connectivity issues affecting several of their IoT devices), enabling proactive issue resolution before the service is critically impacted. We first describe the IoT service, infrastructure, and network visibility of the IoT connectivity provider we operate. Second, we describe the main challenges and operational requirements for designing an unsupervised anomaly detection solution on this platform. Following these guidelines, we propose different statistical rules, and machine- and deep-learning models for IoT verticals anomaly detection based on passive signaling traffic. We describe the steps we followed working with the operational teams on the design and evaluation of our solution on the operational platform, and report an evaluation on operational IoT customers.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å…¨çƒç‰©è”ç½‘(IoT)è¿æ¥æœåŠ¡ä¸­å› è·¨å®ä½“é€šä¿¡è·¯å¾„å¤æ‚å¯¼è‡´çš„å¯é æ€§ä¿éšœéš¾é¢˜ï¼Œä»¥åŠç°æœ‰å¹³å°ä¸»è¦ä¾èµ–ç”¨æˆ·æŠ•è¯‰çš„è¢«åŠ¨å¼ç»´æŠ¤ç°çŠ¶ï¼Œæå‡ºäº†åä¸ºANCHORçš„éç›‘ç£å¼‚å¸¸æ£€æµ‹(Unsupervised Anomaly Detection)è§£å†³æ–¹æ¡ˆã€‚è¯¥æ–¹æ¡ˆä¸“é—¨ä¸ºå¤§å‹å…¨çƒæ¼«æ¸¸å¹³å°çš„IoTè¿æ¥æœåŠ¡è®¾è®¡ï¼Œé€šè¿‡è¿‡æ»¤æµ·é‡æ•°æ®æ¥è¯†åˆ«é‚£äº›å¤šä¸ªè®¾å¤‡åŒæ—¶å—åˆ°è¿æ¥é—®é¢˜å½±å“çš„æ½œåœ¨é—®é¢˜å®¢æˆ·ï¼Œä»è€Œåœ¨æœåŠ¡å—åˆ°ä¸¥é‡å½±å“å‰å®ç°ä¸»åŠ¨å¼çš„é—®é¢˜è§£å†³ã€‚ç ”ç©¶è¿‡ç¨‹ä¸­ï¼Œä½œè€…è¯¦ç»†åˆ†æäº†åŸºç¡€è®¾æ–½çš„æŒ‘æˆ˜ä¸è¿è¥éœ€æ±‚ï¼Œå¹¶ç»“åˆç»Ÿè®¡è§„åˆ™ã€æœºå™¨å­¦ä¹ (Machine Learning)åŠæ·±åº¦å­¦ä¹ (Deep Learning)æ¨¡å‹ï¼Œåˆ©ç”¨è¢«åŠ¨ä¿¡ä»¤æµé‡(Passive Signaling Traffic)å¯¹ç‰©è”ç½‘å‚ç›´é¢†åŸŸè¿›è¡Œå¼‚å¸¸æ£€æµ‹ã€‚é€šè¿‡ä¸è¿è¥å›¢é˜Ÿåˆä½œï¼Œè¯¥æ–¹æ¡ˆåœ¨å®é™…ç”Ÿäº§å¹³å°å’ŒçœŸå®IoTå®¢æˆ·ç¯å¢ƒä¸‹å®Œæˆäº†éƒ¨ç½²ä¸æ€§èƒ½è¯„ä¼°ã€‚è¿™é¡¹å·¥ä½œä¸ºæé«˜å…¨çƒç‰©è”ç½‘æœåŠ¡çš„å¯ç”¨æ€§å’Œå¯é æ€§æä¾›äº†å®ç”¨çš„æŠ€æœ¯è·¯å¾„å’Œç»éªŒã€‚",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09660v1",
      "published_date": "2025-08-13 09:44:51 UTC",
      "updated_date": "2025-08-13 09:44:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:37:23.495498+00:00"
    },
    {
      "arxiv_id": "2508.09653v1",
      "title": "On Negative-aware Preference Optimization for Recommendation",
      "title_zh": "è®ºé¢å‘æ¨èç³»ç»Ÿçš„è´Ÿæ ·æœ¬æ„ŸçŸ¥åå¥½ä¼˜åŒ–",
      "authors": [
        "Chenlu Ding",
        "Daoxuan Liu",
        "Jiancan Wu",
        "Xingyu Hu",
        "Junkang Wu",
        "Haitao Wang",
        "Yongkang Wang",
        "Xingxing Wang",
        "Xiang Wang"
      ],
      "abstract": "Recommendation systems leverage user interaction data to suggest relevant items while filtering out irrelevant (negative) ones. The rise of large language models (LLMs) has garnered increasing attention for their potential in recommendation tasks. However, existing methods for optimizing LLM-based recommenders face challenges in effectively utilizing negative samples. Simply integrating large numbers of negative samples can improve ranking accuracy and mitigate popularity bias but often leads to increased computational overhead and memory costs. Additionally, current approaches fail to account for the varying informativeness of negative samples, leading to suboptimal optimization performance. To address these issues, we propose NAPO (\\textbf{N}egative-\\textbf{A}ware \\textbf{P}reference \\textbf{O}ptimization), an enhanced framework for preference optimization in LLM-based recommendation. NAPO introduces two key innovations: (1) in-batch negative sharing, which expands the pool of negative samples without additional memory overhead, and (2) dynamic reward margin adjustment, which adapts model updates based on the confidence of negative samples. Extensive experiments on three public datasets demonstrate that NAPO outperforms existing methods in both recommendation accuracy and popularity bias reduction.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹(LLMs)çš„æ¨èç³»ç»Ÿåœ¨åˆ©ç”¨è´Ÿæ ·æœ¬æ—¶é¢ä¸´çš„è®¡ç®—å¼€é”€å¤§ä»¥åŠå¿½è§†è´Ÿæ ·æœ¬ä¿¡æ¯é‡å·®å¼‚ç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº† NAPO (Negative-Aware Preference Optimization) ä¼˜åŒ–æ¡†æ¶ã€‚NAPO å¼•å…¥äº†ä¸¤ä¸ªæ ¸å¿ƒåˆ›æ–°ï¼šä¸€æ˜¯ in-batch negative sharing æŠ€æœ¯ï¼Œåœ¨ä¸å¢åŠ é¢å¤–å†…å­˜å¼€é”€çš„æƒ…å†µä¸‹æ˜¾è‘—æ‰©å±•äº†è´Ÿæ ·æœ¬æ± ï¼›äºŒæ˜¯ dynamic reward margin adjustment æœºåˆ¶ï¼Œèƒ½å¤Ÿæ ¹æ®è´Ÿæ ·æœ¬çš„ç½®ä¿¡åº¦åŠ¨æ€è°ƒæ•´æ¨¡å‹æ›´æ–°ã€‚åœ¨ä¸‰ä¸ªå…¬å¼€æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¯æ˜ï¼ŒNAPO åœ¨æé«˜æ¨èå‡†ç¡®ç‡å’Œå‡å°‘æµè¡Œåº¦åå·® (popularity bias) æ–¹é¢å‡æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚è¯¥ç ”ç©¶ä¸ºä¼˜åŒ– LLM-based recommenders æä¾›äº†æ›´é«˜æ•ˆä¸”æ›´å…·æ„ŸçŸ¥åŠ›çš„åå¥½ä¼˜åŒ–æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09653v1",
      "published_date": "2025-08-13 09:37:07 UTC",
      "updated_date": "2025-08-13 09:37:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:37:40.151124+00:00"
    },
    {
      "arxiv_id": "2508.09652v1",
      "title": "Demystifying the Role of Rule-based Detection in AI Systems for Windows Malware Detection",
      "title_zh": "æ­ç§˜ Windows æ¶æ„è½¯ä»¶æ£€æµ‹ AI ç³»ç»Ÿä¸­åŸºäºè§„åˆ™æ£€æµ‹çš„ä½œç”¨",
      "authors": [
        "Andrea Ponte",
        "Luca Demetrio",
        "Luca Oneto",
        "Ivan Tesfai Ogbu",
        "Battista Biggio",
        "Fabio Roli"
      ],
      "abstract": "Malware detection increasingly relies on AI systems that integrate signature-based detection with machine learning. However, these components are typically developed and combined in isolation, missing opportunities to reduce data complexity and strengthen defenses against adversarial EXEmples, carefully crafted programs designed to evade detection. Hence, in this work we investigate the influence that signature-based detection exerts on model training, when they are included inside the training pipeline. Specifically, we compare models trained on a comprehensive dataset with an AI system whose machine learning component is trained solely on samples not already flagged by signatures. Our results demonstrate improved robustness to both adversarial EXEmples and temporal data drift, although this comes at the cost of a fixed lower bound on false positives, driven by suboptimal rule selection. We conclude by discussing these limitations and outlining how future research could extend AI-based malware detection to include dynamic analysis, thereby further enhancing system resilience.",
      "tldr_zh": "è¯¥ç ”ç©¶æ·±å…¥æ¢è®¨äº†Windowsæ¶æ„è½¯ä»¶æ£€æµ‹ä¸­åŸºäºè§„åˆ™çš„æ£€æµ‹ï¼ˆsignature-based detectionï¼‰ä¸æœºå™¨å­¦ä¹ ï¼ˆmachine learningï¼‰é›†æˆçš„ä½œç”¨ã€‚é’ˆå¯¹ä¼ ç»Ÿæ–¹æ³•ä¸­ä¸¤éƒ¨åˆ†ç»„ä»¶å¼€å‘è„±èŠ‚ã€æœªèƒ½å……åˆ†åˆ©ç”¨ååŒæ•ˆåº”çš„é—®é¢˜ï¼Œæœ¬æ–‡ç ”ç©¶äº†å°†ç­¾åæ£€æµ‹çº³å…¥è®­ç»ƒæµç¨‹å¯¹æ¨¡å‹æ€§èƒ½çš„å…·ä½“å½±å“ã€‚é€šè¿‡å¯¹æ¯”å®éªŒï¼Œç ”ç©¶å‘ç°ä»…åœ¨æœªè¢«ç­¾åæ ‡è®°çš„æ ·æœ¬ä¸Šè®­ç»ƒæœºå™¨å­¦ä¹ ç»„ä»¶ï¼Œèƒ½æ˜¾è‘—æå‡ç³»ç»Ÿå¯¹å¯¹æŠ—æ ·æœ¬ï¼ˆadversarial EXEmplesï¼‰å’Œæ—¶é—´æ•°æ®åç§»ï¼ˆtemporal data driftï¼‰çš„é²æ£’æ€§ã€‚è™½ç„¶æ¬¡ä¼˜çš„è§„åˆ™é€‰æ‹©ä¼šå¯¼è‡´è¯¯æŠ¥ç‡ï¼ˆfalse positivesï¼‰å‡ºç°æ— æ³•è§„é¿çš„ä¸‹é™ï¼Œä½†è¿™ç§é›†æˆç­–ç•¥æœ‰æ•ˆé™ä½äº†æ•°æ®å¤æ‚åº¦å¹¶å¼ºåŒ–äº†ç³»ç»Ÿçš„é˜²å¾¡èƒ½åŠ›ã€‚è¯¥ç ”ç©¶ç»“è®ºæ­ç¤ºäº†ç»“åˆé™æ€è§„åˆ™ä¸AIæ¨¡å‹çš„æ¶æ„ä¼˜åŠ¿ï¼Œå¹¶æå‡ºæœªæ¥åº”é€šè¿‡å¼•å…¥åŠ¨æ€åˆ†æï¼ˆdynamic analysisï¼‰æ¥è¿›ä¸€æ­¥å¢å¼ºæ£€æµ‹ç³»ç»Ÿçš„éŸ§æ€§ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09652v1",
      "published_date": "2025-08-13 09:35:51 UTC",
      "updated_date": "2025-08-13 09:35:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:37:41.367066+00:00"
    },
    {
      "arxiv_id": "2508.09651v1",
      "title": "A Close Reading Approach to Gender Narrative Biases in AI-Generated Stories",
      "title_zh": "AIç”Ÿæˆæ•…äº‹ä¸­æ€§åˆ«å™äº‹åè§çš„æ–‡æœ¬ç»†è¯»ç ”ç©¶",
      "authors": [
        "Daniel Raffini",
        "Agnese Macori",
        "Marco Angelini",
        "Tiziana Catarci"
      ],
      "abstract": "The paper explores the study of gender-based narrative biases in stories generated by ChatGPT, Gemini, and Claude. The prompt design draws on Propp's character classifications and Freytag's narrative structure. The stories are analyzed through a close reading approach, with particular attention to adherence to the prompt, gender distribution of characters, physical and psychological descriptions, actions, and finally, plot development and character relationships. The results reveal the persistence of biases - especially implicit ones - in the generated stories and highlight the importance of assessing biases at multiple levels using an interpretative approach.",
      "tldr_zh": "è¯¥ç ”ç©¶é‡‡ç”¨ç»†è¯»æ³•(close reading)ç³»ç»Ÿæ¢è®¨äº†ChatGPTã€Geminiå’ŒClaudeç”Ÿæˆçš„å™äº‹æ•…äº‹ä¸­å­˜åœ¨çš„æ€§åˆ«å™äº‹åè§ã€‚ç ”ç©¶ç»“åˆProppçš„è§’è‰²åˆ†ç±»ä¸Freytagçš„å™äº‹ç»“æ„è¿›è¡Œæç¤ºè¯è®¾è®¡ï¼Œä»è§’è‰²çš„æ€§åˆ«åˆ†å¸ƒã€èº«å¿ƒç‰¹è´¨æè¿°ã€è¡Œä¸ºåŠ¨ä½œä»¥åŠæƒ…èŠ‚å‘å±•å’Œè§’è‰²å…³ç³»ç­‰å¤šä¸ªç»´åº¦å¯¹ç”Ÿæˆçš„æ–‡æœ¬è¿›è¡Œäº†æ·±å…¥å‰–æã€‚å®éªŒç»“æœæ­ç¤ºäº†äººå·¥æ™ºèƒ½ç”Ÿæˆæ•…äº‹ä¸­æŒç»­å­˜åœ¨çš„æ€§åˆ«åè§ï¼Œå°¤å…¶æ˜¯éšå«åè§(implicit biases)çš„è¡¨ç°å°¤ä¸ºçªå‡ºã€‚è¯¥ç ”ç©¶å¼ºè°ƒäº†åœ¨å¤šä¸ªå±‚é¢ä¸Šé‡‡ç”¨è§£é‡Šæ€§æ–¹æ³•(interpretative approach)è¯„ä¼°åè§çš„é‡è¦æ€§ï¼Œä¸ºè¯†åˆ«å¤§è¯­è¨€æ¨¡å‹ä¸­çš„å¤æ‚å™äº‹åè§æä¾›äº†ç†è®ºæ”¯æŒä¸å®è·µå‚è€ƒã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "8-pages",
      "pdf_url": "https://arxiv.org/pdf/2508.09651v1",
      "published_date": "2025-08-13 09:34:37 UTC",
      "updated_date": "2025-08-13 09:34:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:37:38.688700+00:00"
    },
    {
      "arxiv_id": "2508.16612v2",
      "title": "Negative Shanshui: Real-time Interactive Ink Painting Synthesis",
      "title_zh": "Negative Shanshuiï¼šå®æ—¶äº¤äº’å¼æ°´å¢¨ç”»åˆæˆ",
      "authors": [
        "Aven-Le Zhou"
      ],
      "abstract": "This paper presents Negative Shanshui, a real-time interactive AI synthesis approach that reinterprets classical Chinese landscape ink painting, i.e., shanshui, to engage with ecological crises in the Anthropocene. Negative Shanshui optimizes a fine-tuned Stable Diffusion model for real-time inferences and integrates it with gaze-driven inpainting, frame interpolation; it enables dynamic morphing animations in response to the viewer's gaze and presents as an interactive virtual reality (VR) experience. The paper describes the complete technical pipeline, covering the system framework, optimization strategies, gaze-based interaction, and multimodal deployment in an art festival. Further analysis of audience feedback collected during its public exhibition highlights how participants variously engaged with the work through empathy, ambivalence, and critical reflection.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Negative Shanshuiï¼Œä¸€ç§å®æ—¶äº¤äº’å¼ AI åˆæˆæ–¹æ³•ï¼Œé€šè¿‡é‡æ–°è¯ é‡Šä¸­å›½å¤å…¸æ°´å¢¨å±±æ°´ç”» (shanshui) æ¥åº”å¯¹äººç±»ä¸– (Anthropocene) çš„ç”Ÿæ€å±æœºã€‚ç³»ç»Ÿä¼˜åŒ–äº†ç»è¿‡å¾®è°ƒçš„ Stable Diffusion æ¨¡å‹ä»¥å®ç°å®æ—¶æ¨ç† (real-time inferences)ï¼Œå¹¶é›†æˆäº†å‡è§†é©±åŠ¨çš„å›¾åƒä¿®å¤ (gaze-driven inpainting) ä¸å¸§æ’å€¼ (frame interpolation) æŠ€æœ¯ã€‚è¿™ç§æŠ€æœ¯æ–¹æ¡ˆå®ç°äº†èƒ½å¤Ÿæ ¹æ®è§‚ä¼—å‡è§†äº§ç”ŸåŠ¨æ€å˜å½¢çš„åŠ¨ç”»æ•ˆæœï¼Œå¹¶ä»¥äº¤äº’å¼è™šæ‹Ÿç°å® (VR) çš„å½¢å¼è¿›è¡Œå‘ˆç°ã€‚è®ºæ–‡è¯¦ç»†é˜è¿°äº†æ¶µç›–ç³»ç»Ÿæ¡†æ¶ã€ä¼˜åŒ–ç­–ç•¥ã€å‡è§†äº¤äº’åŠå¤šæ¨¡æ€éƒ¨ç½²çš„å®Œæ•´æŠ€æœ¯æµæ°´çº¿ã€‚é€šè¿‡å¯¹è‰ºæœ¯èŠ‚å±•è§ˆä¸­è§‚ä¼—åé¦ˆçš„åˆ†æï¼Œç ”ç©¶æ­ç¤ºäº†å‚ä¸è€…åœ¨å…±æƒ…ã€çŸ›ç›¾å¿ƒç†å’Œæ‰¹åˆ¤æ€§åæ€ä¸­ä¸ä½œå“è¾¾æˆçš„æ·±åº¦äº’åŠ¨ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CV",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.16612v2",
      "published_date": "2025-08-13 09:24:37 UTC",
      "updated_date": "2025-10-05 09:19:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:37:38.191448+00:00"
    },
    {
      "arxiv_id": "2508.09639v1",
      "title": "UbiQTree: Uncertainty Quantification in XAI with Tree Ensembles",
      "title_zh": "UbiQTreeï¼šåŸºäºæ ‘é›†æˆçš„å¯è§£é‡Šäººå·¥æ™ºèƒ½ä¸ç¡®å®šæ€§é‡åŒ–",
      "authors": [
        "Akshat Dubey",
        "Aleksandar AnÅ¾el",
        "Bahar Ä°lgen",
        "Georges Hattab"
      ],
      "abstract": "Explainable Artificial Intelligence (XAI) techniques, such as SHapley Additive exPlanations (SHAP), have become essential tools for interpreting complex ensemble tree-based models, especially in high-stakes domains such as healthcare analytics. However, SHAP values are usually treated as point estimates, which disregards the inherent and ubiquitous uncertainty in predictive models and data. This uncertainty has two primary sources: aleatoric and epistemic. The aleatoric uncertainty, which reflects the irreducible noise in the data. The epistemic uncertainty, which arises from a lack of data. In this work, we propose an approach for decomposing uncertainty in SHAP values into aleatoric, epistemic, and entanglement components. This approach integrates Dempster-Shafer evidence theory and hypothesis sampling via Dirichlet processes over tree ensembles. We validate the method across three real-world use cases with descriptive statistical analyses that provide insight into the nature of epistemic uncertainty embedded in SHAP explanations. The experimentations enable to provide more comprehensive understanding of the reliability and interpretability of SHAP-based attributions. This understanding can guide the development of robust decision-making processes and the refinement of models in high-stakes applications. Through our experiments with multiple datasets, we concluded that features with the highest SHAP values are not necessarily the most stable. This epistemic uncertainty can be reduced through better, more representative data and following appropriate or case-desired model development techniques. Tree-based models, especially bagging, facilitate the effective quantification of epistemic uncertainty.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Explainable Artificial Intelligence (XAI) ä¸­çš„ SHapley Additive exPlanations (SHAP) é€šå¸¸ä»…æä¾›ç‚¹ä¼°è®¡è€Œå¿½ç•¥æ¨¡å‹ä¸æ•°æ®ä¸ç¡®å®šæ€§çš„é—®é¢˜ï¼Œæå‡ºäº† UbiQTree æ¡†æ¶ã€‚è¯¥æ–¹æ³•æ—¨åœ¨å°† SHAP å€¼çš„ä¸ç¡®å®šæ€§åˆ†è§£ä¸º aleatoricã€epistemic ä»¥åŠ entanglement åˆ†é‡ï¼Œä»¥æä¾›æ›´å…¨é¢çš„è§£é‡Šã€‚UbiQTree é€šè¿‡åœ¨æ ‘é›†æˆæ¨¡å‹ä¸Šé›†æˆ Dempster-Shafer è¯æ®ç†è®ºå’ŒåŸºäº Dirichlet è¿‡ç¨‹çš„å‡è®¾æŠ½æ ·ï¼Œå®ç°äº†å¯¹å½’å› å¯é æ€§çš„ç²¾ç¡®é‡åŒ–ã€‚ç ”ç©¶é€šè¿‡ä¸‰ä¸ªçœŸå®ä¸–ç•Œçš„æ¡ˆä¾‹ç ”ç©¶éªŒè¯äº†è¯¥æ–¹æ³•ï¼Œå‘ç°å…·æœ‰æœ€é«˜ SHAP å€¼çš„ç‰¹å¾å¹¶ä¸ä¸€å®šæ˜¯æœ€ç¨³å®šçš„ï¼Œè¿™çªæ˜¾äº†è¯„ä¼°è§£é‡Šç¨³å®šæ€§çš„é‡è¦æ€§ã€‚å®éªŒç»“æœè¿›ä¸€æ­¥è¡¨æ˜ï¼Œé€šè¿‡è·å–æ›´å…·ä»£è¡¨æ€§çš„æ•°æ®å¯ä»¥æœ‰æ•ˆå‡å°‘ epistemic ä¸ç¡®å®šæ€§ï¼Œä¸”åŸºäºæ ‘çš„æ¨¡å‹ï¼ˆç‰¹åˆ«æ˜¯ baggingï¼‰èƒ½æœ‰æ•ˆæ”¯æŒè¿™ç§é‡åŒ–ã€‚è¯¥å·¥ä½œä¸ºé«˜é£é™©é¢†åŸŸçš„å¯è§£é‡Š AI åº”ç”¨æä¾›äº†æ›´ç¨³å¥çš„å†³ç­–æ”¯æŒå’Œæ¨¡å‹ä¼˜åŒ–æŒ‡å¯¼ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09639v1",
      "published_date": "2025-08-13 09:20:33 UTC",
      "updated_date": "2025-08-13 09:20:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:37:42.062904+00:00"
    },
    {
      "arxiv_id": "2508.09636v1",
      "title": "Personalized Product Search Ranking: A Multi-Task Learning Approach with Tabular and Non-Tabular Data",
      "title_zh": "ä¸ªæ€§åŒ–å•†å“æœç´¢æ’åºï¼šä¸€ç§ç»“åˆè¡¨æ ¼ä¸éè¡¨æ ¼æ•°æ®çš„å¤šä»»åŠ¡å­¦ä¹ æ–¹æ³•",
      "authors": [
        "Lalitesh Morishetti",
        "Abhay Kumar",
        "Jonathan Scott",
        "Kaushiki Nag",
        "Gunjan Sharma",
        "Shanu Vashishtha",
        "Rahul Sridhar",
        "Rohit Chatter",
        "Kannan Achan"
      ],
      "abstract": "In this paper, we present a novel model architecture for optimizing personalized product search ranking using a multi-task learning (MTL) framework. Our approach uniquely integrates tabular and non-tabular data, leveraging a pre-trained TinyBERT model for semantic embeddings and a novel sampling technique to capture diverse customer behaviors. We evaluate our model against several baselines, including XGBoost, TabNet, FT-Transformer, DCN-V2, and MMoE, focusing on their ability to handle mixed data types and optimize personalized ranking. Additionally, we propose a scalable relevance labeling mechanism based on click-through rates, click positions, and semantic similarity, offering an alternative to traditional human-annotated labels. Experimental results show that combining non-tabular data with advanced embedding techniques in multi-task learning paradigm significantly enhances model performance. Ablation studies further underscore the benefits of incorporating relevance labels, fine-tuning TinyBERT layers, and TinyBERT query-product embedding interactions. These results demonstrate the effectiveness of our approach in achieving improved personalized product search ranking.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§ç”¨äºä¼˜åŒ–ä¸ªæ€§åŒ–äº§å“æœç´¢æ’åºçš„æ–°å‹æ¨¡å‹æ¶æ„ï¼Œé‡‡ç”¨å¤šä»»åŠ¡å­¦ä¹ (Multi-Task Learning)æ¡†æ¶æ•´åˆäº†è¡¨æ ¼å‹(Tabular)å’Œéè¡¨æ ¼å‹(Non-tabular)æ•°æ®ã€‚è¯¥æ–¹æ³•åˆ©ç”¨é¢„è®­ç»ƒçš„ TinyBERT è·å–è¯­ä¹‰åµŒå…¥(Semantic Embeddings)ï¼Œå¹¶ç»“åˆåˆ›æ–°çš„é‡‡æ ·æŠ€æœ¯ä»¥æ•æ‰å¤šæ ·åŒ–çš„ç”¨æˆ·è¡Œä¸ºã€‚ç ”ç©¶è¿˜æå‡ºäº†ä¸€ç§åŸºäºç‚¹å‡»ç‡(Click-through Rates)ã€ç‚¹å‡»ä½ç½®å’Œè¯­ä¹‰ç›¸ä¼¼åº¦çš„å¯æ‰©å±•ç›¸å…³æ€§æ ‡æ³¨æœºåˆ¶ï¼Œä¸ºä¼ ç»Ÿçš„äººå·¥æ ‡æ³¨æä¾›äº†æœ‰æ•ˆçš„æ›¿ä»£æ–¹æ¡ˆã€‚é€šè¿‡ä¸ XGBoostã€TabNet å’Œ MMoE ç­‰å¤šç§åŸºçº¿æ¨¡å‹çš„å¯¹æ¯”ï¼Œå®éªŒè¯æ˜äº†è¯¥æ¨¡å‹åœ¨å¤„ç†æ··åˆæ•°æ®å’Œä¼˜åŒ–ä¸ªæ€§åŒ–æ’åºä¸Šçš„æ˜¾è‘—ä¼˜åŠ¿ã€‚æ¶ˆèå®éªŒè¿›ä¸€æ­¥è¡¨æ˜ï¼Œæ•´åˆéè¡¨æ ¼æ•°æ®ã€å¾®è°ƒ TinyBERT ä»¥åŠå¢å¼ºæŸ¥è¯¢ä¸äº§å“çš„åµŒå…¥äº¤äº’å¯¹äºæå‡æ¨¡å‹æ€§èƒ½è‡³å…³é‡è¦ã€‚ç ”ç©¶ç»“æœå……åˆ†éªŒè¯äº†è¯¥å¤šä»»åŠ¡å­¦ä¹ èŒƒå¼åœ¨å®ç°ç²¾å‡†ä¸ªæ€§åŒ–æœç´¢æ’åºæ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "17 pages, 2 figures, The Pacific Rim International Conference on Artificial Intelligence (PRICAI-2025) Conference",
      "pdf_url": "https://arxiv.org/pdf/2508.09636v1",
      "published_date": "2025-08-13 09:15:08 UTC",
      "updated_date": "2025-08-13 09:15:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:37:53.298026+00:00"
    },
    {
      "arxiv_id": "2508.09632v6",
      "title": "Preacher: Paper-to-Video Agentic System",
      "title_zh": "Preacherï¼šè®ºæ–‡è½¬è§†é¢‘æ™ºèƒ½ä½“ç³»ç»Ÿ",
      "authors": [
        "Jingwei Liu",
        "Ling Yang",
        "Hao Luo",
        "Fan Wang",
        "Hongyan Li",
        "Mengdi Wang"
      ],
      "abstract": "The paper-to-video task converts a research paper into a structured video abstract, distilling key concepts, methods, and conclusions into an accessible, well-organized format. While state-of-the-art video generation models demonstrate potential, they are constrained by limited context windows, rigid video duration constraints, limited stylistic diversity, and an inability to represent domain-specific knowledge. To address these limitations, we introduce Preacher, the first paper-to-video agentic system. Preacher employs a topdown approach to decompose, summarize, and reformulate the paper, followed by bottom-up video generation, synthesizing diverse video segments into a coherent abstract. To align cross-modal representations, we define key scenes and introduce a Progressive Chain of Thought (P-CoT) for granular, iterative planning. Preacher successfully generates high-quality video abstracts across five research fields, demonstrating expertise beyond current video generation models. Code will be released at: https://github.com/Gen-Verse/Paper2Video",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Preacherï¼Œè¿™æ˜¯é¦–ä¸ªè®ºæ–‡è½¬è§†é¢‘ (paper-to-video) çš„æ™ºèƒ½ä½“ç³»ç»Ÿï¼Œæ—¨åœ¨å°†ç ”ç©¶è®ºæ–‡çš„æ ¸å¿ƒæ¦‚å¿µã€æ–¹æ³•å’Œç»“è®ºè½¬åŒ–ä¸ºç»“æ„åŒ–çš„è§†é¢‘æ‘˜è¦ã€‚é’ˆå¯¹ç°æœ‰è§†é¢‘ç”Ÿæˆæ¨¡å‹åœ¨ä¸Šä¸‹æ–‡çª—å£ã€è§†é¢‘æ—¶é•¿åŠé¢†åŸŸçŸ¥è¯†è¡¨å¾ä¸Šçš„å±€é™æ€§ï¼ŒPreacher é‡‡ç”¨è‡ªé¡¶å‘ä¸‹ (top-down) çš„æ–¹æ³•å¯¹è®ºæ–‡è¿›è¡Œåˆ†è§£ä¸é‡æ„ï¼Œå¹¶ç»“åˆè‡ªåº•å‘ä¸Š (bottom-up) çš„ç”Ÿæˆç­–ç•¥å°†è§†é¢‘ç‰‡æ®µåˆæˆä¸ºè¿è´¯æ•´ä½“ã€‚ä¸ºäº†å®ç°è·¨æ¨¡æ€å¯¹é½ï¼Œè¯¥ç³»ç»Ÿå®šä¹‰äº†å…³é”®åœºæ™¯å¹¶å¼•å…¥æ¸è¿›å¼é“¾å¼æ€ç»´ (Progressive Chain of Thought, P-CoT) è¿›è¡Œç»†ç²’åº¦çš„è¿­ä»£è§„åˆ’ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒPreacher èƒ½å¤Ÿåœ¨äº”ä¸ªç ”ç©¶é¢†åŸŸç”Ÿæˆé«˜è´¨é‡çš„è§†é¢‘æ‘˜è¦ï¼Œå±•ç°å‡ºè¶…è¶Šä¼ ç»Ÿè§†é¢‘ç”Ÿæˆæ¨¡å‹çš„ä¸“ä¸šæ€§ä¸çµæ´»æ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ICCV 2025. Code: https://github.com/Gen-Verse/Paper2Video",
      "pdf_url": "https://arxiv.org/pdf/2508.09632v6",
      "published_date": "2025-08-13 09:08:51 UTC",
      "updated_date": "2025-09-08 11:42:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:37:53.658279+00:00"
    },
    {
      "arxiv_id": "2508.09631v1",
      "title": "AmbiGraph-Eval: Can LLMs Effectively Handle Ambiguous Graph Queries?",
      "title_zh": "AmbiGraph-Evalï¼šå¤§è¯­è¨€æ¨¡å‹èƒ½å¦æœ‰æ•ˆå¤„ç†æ­§ä¹‰æ€§å›¾æŸ¥è¯¢ï¼Ÿ",
      "authors": [
        "Yuchen Tian",
        "Kaixin Li",
        "Hao Chen",
        "Ziyang Luo",
        "Hongzhan Lin",
        "Sebastian Schelter",
        "Lun Du",
        "Jing Ma"
      ],
      "abstract": "Large Language Models (LLMs) have recently demonstrated strong capabilities in translating natural language into database queries, especially when dealing with complex graph-structured data. However, real-world queries often contain inherent ambiguities, and the interconnected nature of graph structures can amplify these challenges, leading to unintended or incorrect query results. To systematically evaluate LLMs on this front, we propose a taxonomy of graph-query ambiguities, comprising three primary types: Attribute Ambiguity, Relationship Ambiguity, and Attribute-Relationship Ambiguity, each subdivided into Same-Entity and Cross-Entity scenarios. We introduce AmbiGraph-Eval, a novel benchmark of real-world ambiguous queries paired with expert-verified graph query answers. Evaluating 9 representative LLMs shows that even top models struggle with ambiguous graph queries. Our findings reveal a critical gap in ambiguity handling and motivate future work on specialized resolution techniques.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) åœ¨å°†è‡ªç„¶è¯­è¨€è½¬æ¢ä¸ºå›¾æŸ¥è¯¢æ—¶é¢ä¸´çš„ç°å®ä¸–ç•Œæ­§ä¹‰æ€§æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤æ‚çš„å›¾ç»“æ„æ•°æ® (graph-structured data) èƒŒæ™¯ä¸‹ã€‚ä¸ºäº†ç³»ç»ŸåŒ–è¯„ä¼°è¿™ä¸€é—®é¢˜ï¼Œä½œè€…æå‡ºäº†ä¸€ç§å›¾æŸ¥è¯¢æ­§ä¹‰åˆ†ç±»æ³• (taxonomy of graph-query ambiguities)ï¼Œæ¶µç›–å±æ€§æ­§ä¹‰ (Attribute Ambiguity)ã€å…³ç³»æ­§ä¹‰ (Relationship Ambiguity) å’Œå±æ€§-å…³ç³»æ­§ä¹‰ (Attribute-Relationship Ambiguity)ï¼Œå¹¶ç»†åˆ†ä¸ºåŒå®ä½“ (Same-Entity) ä¸è·¨å®ä½“ (Cross-Entity) åœºæ™¯ã€‚è¯¥ç ”ç©¶å¼•å…¥äº† AmbiGraph-Eval åŸºå‡†æµ‹è¯•ï¼Œå…¶ä¸­åŒ…å«çœŸå®ä¸–ç•Œçš„æ­§ä¹‰æŸ¥è¯¢åŠä¸“å®¶éªŒè¯çš„ç­”æ¡ˆã€‚é€šè¿‡å¯¹ 9 ä¸ªä»£è¡¨æ€§ LLMs çš„å®éªŒè¯„ä¼°ï¼Œç»“æœæ˜¾ç¤ºå³ä½¿æ˜¯é¡¶å°–æ¨¡å‹åœ¨å¤„ç†æ­¤ç±»æ­§ä¹‰æ—¶ä¹Ÿè¡¨ç°æ¬ ä½³ã€‚è¿™ä¸€å‘ç°æ­ç¤ºäº†å½“å‰æ¨¡å‹åœ¨æ­§ä¹‰å¤„ç†èƒ½åŠ›çš„æ˜¾è‘—å·®è·ï¼Œå¹¶ä¸ºæœªæ¥å¼€å‘ä¸“é—¨çš„è§£ææŠ€æœ¯ (specialized resolution techniques) æä¾›äº†é‡è¦ä¾æ®ã€‚",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09631v1",
      "published_date": "2025-08-13 09:06:59 UTC",
      "updated_date": "2025-08-13 09:06:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:37:58.560520+00:00"
    },
    {
      "arxiv_id": "2508.09630v2",
      "title": "TimeMKG: Knowledge-Infused Causal Reasoning for Multivariate Time Series Modeling",
      "title_zh": "TimeMKGï¼šèåˆçŸ¥è¯†çš„å¤šå˜é‡æ—¶é—´åºåˆ—å»ºæ¨¡å› æœæ¨ç†",
      "authors": [
        "Yifei Sun",
        "Junming Liu",
        "Yirong Chen",
        "Xuefeng Yan",
        "Ding Wang"
      ],
      "abstract": "Multivariate time series data typically comprises two distinct modalities: variable semantics and sampled numerical observations. Traditional time series models treat variables as anonymous statistical signals, overlooking the rich semantic information embedded in variable names and data descriptions. However, these textual descriptors often encode critical domain knowledge that is essential for robust and interpretable modeling. Here we present TimeMKG, a multimodal causal reasoning framework that elevates time series modeling from low-level signal processing to knowledge informed inference. TimeMKG employs large language models to interpret variable semantics and constructs structured Multivariate Knowledge Graphs that capture inter-variable relationships. A dual-modality encoder separately models the semantic prompts, generated from knowledge graph triplets, and the statistical patterns from historical time series. Cross-modality attention aligns and fuses these representations at the variable level, injecting causal priors into downstream tasks such as forecasting and classification, providing explicit and interpretable priors to guide model reasoning. The experiment in diverse datasets demonstrates that incorporating variable-level knowledge significantly improves both predictive performance and generalization.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† TimeMKGï¼Œä¸€ç§æ—¨åœ¨å°†å¤šå…ƒæ—¶é—´åºåˆ—(Multivariate Time Series)å»ºæ¨¡ä»å•çº¯çš„ä¿¡å·å¤„ç†æå‡è‡³çŸ¥è¯†é©±åŠ¨æ¨ç†çš„å¤šæ¨¡æ€å› æœæ¨ç†æ¡†æ¶ã€‚é’ˆå¯¹ä¼ ç»Ÿæ¨¡å‹å¿½ç•¥å˜é‡åç§°åŠå…¶æè¿°ä¸­ä¸°å¯Œè¯­ä¹‰ä¿¡æ¯çš„é—®é¢˜ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(Large Language Models)è§£è¯»å˜é‡è¯­ä¹‰ï¼Œå¹¶æ„å»ºç»“æ„åŒ–çš„å¤šå…ƒçŸ¥è¯†å›¾è°±(Multivariate Knowledge Graphs)ä»¥æ•æ‰å˜é‡é—´çš„å¤æ‚å…³ç³»ã€‚TimeMKG é‡‡ç”¨åŒæ¨¡æ€ç¼–ç å™¨åˆ†åˆ«å¤„ç†ç”±çŸ¥è¯†å›¾è°±ä¸‰å…ƒç»„ç”Ÿæˆçš„è¯­ä¹‰æç¤ºå’Œå†å²åºåˆ—çš„ç»Ÿè®¡æ¨¡å¼ï¼Œå¹¶é€šè¿‡è·¨æ¨¡æ€æ³¨æ„åŠ›(Cross-modality attention)æœºåˆ¶åœ¨å˜é‡çº§åˆ«è¿›è¡Œç‰¹å¾å¯¹é½ä¸èåˆã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ¡†æ¶ä¸ºé¢„æµ‹å’Œåˆ†ç±»ç­‰ä¸‹æ¸¸ä»»åŠ¡æ³¨å…¥äº†æ˜¾å¼ä¸”å¯è§£é‡Šçš„å› æœå…ˆéªŒ(Causal priors)ï¼Œä»è€Œæœ‰æ•ˆå¼•å¯¼æ¨¡å‹æ¨ç†ã€‚åœ¨å¤šç§æ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜ï¼Œå¼•å…¥å˜é‡çº§çŸ¥è¯†æ˜¾è‘—å¢å¼ºäº†æ¨¡å‹çš„é¢„æµ‹å‡†ç¡®æ€§ä¸æ³›åŒ–èƒ½åŠ›ï¼Œä¸ºæ„å»ºç¨³å¥ä¸”å¯è§£é‡Šçš„æ—¶é—´åºåˆ—æ¨¡å‹æä¾›äº†æ–°æ€è·¯ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09630v2",
      "published_date": "2025-08-13 09:00:36 UTC",
      "updated_date": "2025-08-15 05:09:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:38:04.571319+00:00"
    },
    {
      "arxiv_id": "2508.09624v1",
      "title": "Goal Discovery with Causal Capacity for Efficient Reinforcement Learning",
      "title_zh": "åŸºäºå› æœå®¹é‡çš„ç›®æ ‡å‘ç°ï¼šå®ç°é«˜æ•ˆå¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Yan Yu",
        "Yaodong Yang",
        "Zhengbo Lu",
        "Chengdong Ma",
        "Wengang Zhou",
        "Houqiang Li"
      ],
      "abstract": "Causal inference is crucial for humans to explore the world, which can be modeled to enable an agent to efficiently explore the environment in reinforcement learning. Existing research indicates that establishing the causality between action and state transition will enhance an agent to reason how a policy affects its future trajectory, thereby promoting directed exploration. However, it is challenging to measure the causality due to its intractability in the vast state-action space of complex scenarios. In this paper, we propose a novel Goal Discovery with Causal Capacity (GDCC) framework for efficient environment exploration. Specifically, we first derive a measurement of causality in state space, \\emph{i.e.,} causal capacity, which represents the highest influence of an agent's behavior on future trajectories. After that, we present a Monte Carlo based method to identify critical points in discrete state space and further optimize this method for continuous high-dimensional environments. Those critical points are used to uncover where the agent makes important decisions in the environment, which are then regarded as our subgoals to guide the agent to make exploration more purposefully and efficiently. Empirical results from multi-objective tasks demonstrate that states with high causal capacity align with our expected subgoals, and our GDCC achieves significant success rate improvements compared to baselines.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†GDCC (Goal Discovery with Causal Capacity) æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡æ¨¡æ‹Ÿäººç±»å› æœæ¨ç† (Causal inference) èƒ½åŠ›æ¥æå‡å¼ºåŒ–å­¦ä¹  (Reinforcement Learning) æ™ºèƒ½ä½“åœ¨å¤æ‚ç¯å¢ƒä¸­çš„æ¢ç´¢æ•ˆç‡ã€‚ç ”ç©¶è€…å®šä¹‰å¹¶æ¨å¯¼äº†çŠ¶æ€ç©ºé—´ä¸­çš„å› æœåº¦é‡æŒ‡æ ‡ Causal capacityï¼Œç”¨ä»¥è¡¨å¾æ™ºèƒ½ä½“è¡Œä¸ºå¯¹æœªæ¥è½¨è¿¹çš„æœ€å¤§å½±å“åŠ›ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæå‡ºäº†ä¸€ç§åŸºäº Monte Carlo çš„æ–¹æ³•æ¥è¯†åˆ«ç¦»æ•£å’Œé«˜ç»´è¿ç»­ç¯å¢ƒä¸­çš„å…³é”®ç‚¹ Critical pointsï¼Œå¹¶å°†å…¶ä½œä¸º Subgoals å¼•å¯¼æ™ºèƒ½ä½“è¿›è¡Œæœ‰ç›®çš„çš„æ¢ç´¢ã€‚å¤šç›®æ ‡ä»»åŠ¡çš„å®éªŒç»“æœè¯æ˜ï¼Œé«˜å› æœå®¹é‡çŠ¶æ€ä¸é¢„æœŸå­ç›®æ ‡é«˜åº¦å¥‘åˆã€‚ç›¸æ¯”åŸºçº¿æ¨¡å‹ï¼ŒGDCC åœ¨ä»»åŠ¡æˆåŠŸç‡ä¸Šå®ç°äº†æ˜¾è‘—æå‡ï¼ŒéªŒè¯äº†åˆ©ç”¨å› æœå®¹é‡è¿›è¡Œç›®æ ‡å‘ç°çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09624v1",
      "published_date": "2025-08-13 08:54:56 UTC",
      "updated_date": "2025-08-13 08:54:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:38:26.155078+00:00"
    },
    {
      "arxiv_id": "2508.09621v2",
      "title": "Interpretable Robot Control via Structured Behavior Trees and Large Language Models",
      "title_zh": "åŸºäºç»“æ„åŒ–è¡Œä¸ºæ ‘ä¸å¤§è¯­è¨€æ¨¡å‹çš„å¯è§£é‡Šæœºå™¨äººæ§åˆ¶",
      "authors": [
        "Ingrid MaÃ©va Chekam",
        "Ines Pastor-Martinez",
        "Ali Tourani",
        "Jose Andres Millan-Romera",
        "Laura Ribeiro",
        "Pedro Miguel Bastos Soares",
        "Holger Voos",
        "Jose Luis Sanchez-Lopez"
      ],
      "abstract": "As intelligent robots become more integrated into human environments, there is a growing need for intuitive and reliable Human-Robot Interaction (HRI) interfaces that are adaptable and more natural to interact with. Traditional robot control methods often require users to adapt to interfaces or memorize predefined commands, limiting usability in dynamic, unstructured environments. This paper presents a novel framework that bridges natural language understanding and robotic execution by combining Large Language Models (LLMs) with Behavior Trees. This integration enables robots to interpret natural language instructions given by users and translate them into executable actions by activating domain-specific plugins. The system supports scalable and modular integration, with a primary focus on perception-based functionalities, such as person tracking and hand gesture recognition. To evaluate the system, a series of real-world experiments was conducted across diverse environments. Experimental results demonstrate that the proposed approach is practical in real-world scenarios, with an average cognition-to-execution accuracy of approximately 94%, making a significant contribution to HRI systems and robots. The complete source code of the framework is publicly available at https://github.com/snt-arg/robot_suite.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§å°†å¤§å‹è¯­è¨€æ¨¡å‹(Large Language Models, LLMs)ä¸è¡Œä¸ºæ ‘(Behavior Trees)ç›¸ç»“åˆçš„æ–°å‹æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿæœºå™¨äººæ§åˆ¶æ–¹æ³•åœ¨åŠ¨æ€éç»“æ„åŒ–ç¯å¢ƒä¸­æ˜“ç”¨æ€§å—é™çš„é—®é¢˜ã€‚è¯¥ç³»ç»Ÿèƒ½å¤Ÿè§£æç”¨æˆ·ç»™å‡ºçš„è‡ªç„¶è¯­è¨€æŒ‡ä»¤ï¼Œå¹¶é€šè¿‡æ¿€æ´»ç‰¹å®šé¢†åŸŸçš„æ’ä»¶(domain-specific plugins)å°†å…¶è½¬åŒ–ä¸ºç”±ç»“æ„åŒ–è¡Œä¸ºæ ‘é©±åŠ¨çš„å¯æ‰§è¡ŒåŠ¨ä½œã€‚æ¡†æ¶é‡‡ç”¨æ¨¡å—åŒ–è®¾è®¡ï¼Œé‡ç‚¹å®ç°äº†è¡Œäººè·Ÿè¸ª(person tracking)å’Œæ‰‹åŠ¿è¯†åˆ«(hand gesture recognition)ç­‰åŸºäºæ„ŸçŸ¥çš„å…³é”®åŠŸèƒ½ã€‚é€šè¿‡åœ¨å¤šç§çœŸå®ä¸–ç•Œåœºæ™¯ä¸‹çš„å®éªŒéªŒè¯ï¼Œè¯¥æ–¹æ³•ä»è®¤çŸ¥åˆ°æ‰§è¡Œçš„å¹³å‡å‡†ç¡®ç‡è¾¾åˆ°äº†çº¦94%ï¼Œè¯æ˜äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„é«˜åº¦å¯é æ€§ã€‚è¯¥ç ”ç©¶æ˜¾è‘—æå‡äº†äººæœºäº¤äº’(Human-Robot Interaction, HRI)ç³»ç»Ÿçš„è‡ªç„¶æ€§ä¸å¯è§£é‡Šæ€§ï¼Œä¸ºå¼€å‘ç›´è§‚ä¸”é€‚åº”æ€§å¼ºçš„æœºå™¨äººæ§åˆ¶ç³»ç»Ÿåšå‡ºäº†é‡è¦è´¡çŒ®ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "15 pages, 5 figures, 3 tables",
      "pdf_url": "https://arxiv.org/pdf/2508.09621v2",
      "published_date": "2025-08-13 08:53:13 UTC",
      "updated_date": "2025-10-08 13:28:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:38:26.758203+00:00"
    },
    {
      "arxiv_id": "2508.09616v2",
      "title": "MInDI-3D: Iterative Deep Learning in 3D for Sparse-view Cone Beam Computed Tomography",
      "title_zh": "MInDI-3Dï¼šé¢å‘ç¨€ç–è§†å›¾é”¥å½¢æŸè®¡ç®—æœºæ–­å±‚æ‰«æçš„ 3D è¿­ä»£æ·±åº¦å­¦ä¹ ",
      "authors": [
        "Daniel Barco",
        "Marc Stadelmann",
        "Martin Oswald",
        "Ivo Herzig",
        "Lukas Lichtensteiger",
        "Pascal Paysan",
        "Igor Peterlik",
        "Michal Walczak",
        "Bjoern Menze",
        "Frank-Peter Schilling"
      ],
      "abstract": "We present MInDI-3D (Medical Inversion by Direct Iteration in 3D), the first 3D conditional diffusion-based model for real-world sparse-view Cone Beam Computed Tomography (CBCT) artefact removal, aiming to reduce imaging radiation exposure. A key contribution is extending the \"InDI\" concept from 2D to a full 3D volumetric approach for medical images, implementing an iterative denoising process that refines the CBCT volume directly from sparse-view input. A further contribution is the generation of a large pseudo-CBCT dataset (16,182) from chest CT volumes of the CT-RATE public dataset to robustly train MInDI-3D. We performed a comprehensive evaluation, including quantitative metrics, scalability analysis, generalisation tests, and a clinical assessment by 11 clinicians. Our results show MInDI-3D's effectiveness, achieving a 12.96 (6.10) dB PSNR gain over uncorrected scans with only 50 projections on the CT-RATE pseudo-CBCT (independent real-world) test set and enabling an 8x reduction in imaging radiation exposure. We demonstrate its scalability by showing that performance improves with more training data. Importantly, MInDI-3D matches the performance of a 3D U-Net on real-world scans from 16 cancer patients across distortion and task-based metrics. It also generalises to new CBCT scanner geometries. Clinicians rated our model as sufficient for patient positioning across all anatomical sites and found it preserved lung tumour boundaries well.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† MInDI-3D (Medical Inversion by Direct Iteration in 3D)ï¼Œè¿™æ˜¯é¦–ä¸ªé’ˆå¯¹çœŸå®åœºæ™¯ä¸‹ç¨€ç–è§†å›¾é”¥å½¢æŸè®¡ç®—æœºæ–­å±‚æ‰«æ (Sparse-view CBCT) ä¼ªå½±å»é™¤çš„ 3D æ¡ä»¶æ‰©æ•£æ¨¡å‹ï¼Œæ—¨åœ¨å¤§å¹…é™ä½åŒ»å­¦æˆåƒä¸­çš„è¾å°„æš´éœ²ã€‚å…¶æ ¸å¿ƒè´¡çŒ®åœ¨äºå°† InDI æ¦‚å¿µä» 2D æ‰©å±•åˆ°å®Œæ•´çš„ 3D ä½“ç§¯æ–¹æ³•ï¼Œé€šè¿‡è¿­ä»£å»å™ªè¿‡ç¨‹ç›´æ¥ä»ç¨€ç–è§†å›¾è¾“å…¥ä¸­ä¼˜åŒ– CBCT å›¾åƒã€‚ç ”ç©¶å›¢é˜Ÿåˆ©ç”¨ CT-RATE å…¬å¼€æ•°æ®é›†æ„å»ºäº†åŒ…å« 16,182 ä¸ªæ ·æœ¬çš„å¤§è§„æ¨¡ä¼ª CBCT æ•°æ®é›†ç”¨äºæ¨¡å‹è®­ç»ƒã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨ä»… 50 ä¸ªæŠ•å½±çš„æƒ…å†µä¸‹ï¼ŒMInDI-3D å®ç°äº† 12.96 dB çš„ PSNR å¢ç›Šï¼Œå¹¶æˆåŠŸå°†è¾å°„æš´éœ²é™ä½äº† 8 å€ã€‚è¯¥æ¨¡å‹è¡¨ç°å‡ºä¼˜å¼‚çš„å¯æ‰©å±•æ€§ä¸æ³›åŒ–èƒ½åŠ›ï¼Œèƒ½å¤Ÿé€‚åº”æ–°çš„æ‰«æä»ªå‡ ä½•å½¢çŠ¶ï¼Œä¸”åœ¨ä¸´åºŠä»»åŠ¡æŒ‡æ ‡ä¸Šè¾¾åˆ°äº† 3D U-Net çš„æ°´å¹³ã€‚ç» 11 ä½ä¸´åºŠåŒ»ç”Ÿè¯„ä¼°ï¼Œè¯¥æ¨¡å‹ç”Ÿæˆçš„å›¾åƒè´¨é‡è¶³ä»¥æ»¡è¶³æ‚£è€…å®šä½éœ€æ±‚ï¼Œå¹¶èƒ½æ¸…æ™°ä¿ç•™è‚ºéƒ¨è‚¿ç˜¤è¾¹ç•Œã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09616v2",
      "published_date": "2025-08-13 08:49:18 UTC",
      "updated_date": "2025-10-09 07:53:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:38:26.548317+00:00"
    },
    {
      "arxiv_id": "2508.09614v1",
      "title": "How Persuasive Could LLMs Be? A First Study Combining Linguistic-Rhetorical Analysis and User Experiments",
      "title_zh": "LLMs çš„è¯´æœåŠ›ç©¶ç«Ÿå¦‚ä½•ï¼Ÿç»“åˆè¯­è¨€-ä¿®è¾åˆ†æä¸ç”¨æˆ·å®éªŒçš„åˆæ­¥ç ”ç©¶",
      "authors": [
        "Daniel Raffini",
        "Agnese Macori",
        "Lorenzo Porcaro",
        "Tiziana Catarci",
        "Marco Angelini"
      ],
      "abstract": "This study examines the rhetorical and linguistic features of argumentative texts generated by ChatGPT on ethically nuanced topics and investigates their persuasive impact on human readers.Through a user study involving 62 participants and pre-post interaction surveys, the paper analyzes how exposure to AI-generated arguments affects opinion change and user perception. A linguistic and rhetorical analysis of the generated texts reveals a consistent argumentative macrostructure, reliance on formulaic expressions, and limited stylistic richness. While ChatGPT demonstrates proficiency in constructing coherent argumentative texts, its persuasive efficacy appears constrained, particularly on topics involving ethical issues.The study finds that while participants often acknowledge the benefits highlighted by ChatGPT, ethical concerns tend to persist or even intensify post-interaction. The results also demonstrate a variation depending on the topic. These findings highlight new insights on AI-generated persuasion in ethically sensitive domains and are a basis for future research.",
      "tldr_zh": "è¯¥ç ”ç©¶é€šè¿‡ç»“åˆè¯­è¨€å­¦-ä¿®è¾åˆ†æ(Linguistic-Rhetorical Analysis)ä¸ç”¨æˆ·å®éªŒï¼Œæ¢è®¨äº†ChatGPTåœ¨å¤„ç†å…·æœ‰ä¼¦ç†æŒ‘æˆ˜çš„è¯é¢˜æ—¶ç”Ÿæˆçš„è®®è®ºæ€§æ–‡æœ¬åŠå…¶å¯¹è¯»è€…çš„è¯´æœåŠ›ã€‚åˆ†ææ­ç¤ºäº†AIç”Ÿæˆæ–‡æœ¬å…·æœ‰é«˜åº¦ä¸€è‡´çš„è®ºè¯å®è§‚ç»“æ„(Argumentative Macrostructure)å’Œå…¬å¼åŒ–è¡¨è¾¾ï¼Œä½†åœ¨é£æ ¼ä¸°å¯Œåº¦ä¸Šè¾ƒä¸ºå±€é™ã€‚è™½ç„¶ChatGPTèƒ½æ„å»ºè¿è´¯çš„è®ºè¯ï¼Œä½†åœ¨ä¼¦ç†æ•æ„Ÿé¢†åŸŸçš„è¯´æœæ•ˆæœ(Persuasive Efficacy)ç›¸å¯¹æœ‰é™ï¼Œä¸”å…·ä½“å½±å“å› è¯é¢˜è€Œå¼‚ã€‚å®éªŒå‘ç°å—è¯•è€…åœ¨äº’åŠ¨åè™½ç„¶è®¤å¯AIæå‡ºçš„éƒ¨åˆ†è§‚ç‚¹ï¼Œä½†å…¶ä¼¦ç†é¡¾è™‘å¾€å¾€ä¼šæŒç»­å­˜åœ¨ç”šè‡³åŠ æ·±ã€‚è¿™é¡¹å·¥ä½œä¸ºç†è§£AIç”Ÿæˆå†…å®¹åœ¨ä¼¦ç†é¢†åŸŸçš„å½±å“åŠ›æä¾›äº†æ–°è§è§£ï¼Œå¹¶ä¸ºåç»­ç ”ç©¶å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "9-pages",
      "pdf_url": "https://arxiv.org/pdf/2508.09614v1",
      "published_date": "2025-08-13 08:45:04 UTC",
      "updated_date": "2025-08-13 08:45:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:38:34.894595+00:00"
    },
    {
      "arxiv_id": "2508.09602v1",
      "title": "A Lightweight Learned Cardinality Estimation Model",
      "title_zh": "ä¸€ç§è½»é‡çº§å­¦ä¹ å‹åŸºæ•°ä¼°è®¡æ¨¡å‹",
      "authors": [
        "Yaoyu Zhu",
        "Jintao Zhang",
        "Guoliang Li",
        "Jianhua Feng"
      ],
      "abstract": "Cardinality estimation is a fundamental task in database management systems, aiming to predict query results accurately without executing the queries. However, existing techniques either achieve low estimation accuracy or incur high inference latency. Simultaneously achieving high speed and accuracy becomes critical for the cardinality estimation problem. In this paper, we propose a novel data-driven approach called CoDe (Covering with Decompositions) to address this problem. CoDe employs the concept of covering design, which divides the table into multiple smaller, overlapping segments. For each segment, CoDe utilizes tensor decomposition to accurately model its data distribution. Moreover, CoDe introduces innovative algorithms to select the best-fitting distributions for each query, combining them to estimate the final result. By employing multiple models to approximate distributions, CoDe excels in effectively modeling discrete distributions and ensuring computational efficiency. Notably, experimental results show that our method represents a significant advancement in cardinality estimation, achieving state-of-the-art levels of both estimation accuracy and inference efficiency. Across various datasets, CoDe achieves absolute accuracy in estimating more than half of the queries.",
      "tldr_zh": "åŸºæ•°ä¼°è®¡(Cardinality Estimation)æ˜¯æ•°æ®åº“ç®¡ç†ç³»ç»Ÿçš„æ ¸å¿ƒä»»åŠ¡ï¼Œä½†ç°æœ‰æŠ€æœ¯å¾€å¾€éš¾ä»¥å…¼é¡¾ä¼°è®¡å‡†ç¡®åº¦ä¸æ¨ç†å»¶è¿Ÿã€‚è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸ºCoDe (Covering with Decompositions)çš„æ–°å‹æ•°æ®é©±åŠ¨æ–¹æ³•ï¼Œæ—¨åœ¨åŒæ—¶å®ç°é«˜æ•ˆç‡ä¸é«˜ç²¾åº¦ã€‚CoDeé‡‡ç”¨äº†è¦†ç›–è®¾è®¡(covering design)çš„æ¦‚å¿µï¼Œå°†æ•°æ®è¡¨åˆ’åˆ†ä¸ºå¤šä¸ªé‡å çš„å°åˆ†æ®µï¼Œå¹¶åˆ©ç”¨å¼ é‡åˆ†è§£(tensor decomposition)å¯¹æ¯ä¸ªåˆ†æ®µçš„æ•°æ®åˆ†å¸ƒè¿›è¡Œç²¾ç¡®å»ºæ¨¡ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹å¼•å…¥äº†åˆ›æ–°ç®—æ³•æ¥ä¸ºç‰¹å®šæŸ¥è¯¢é€‰æ‹©æœ€ä½³åŒ¹é…åˆ†å¸ƒï¼Œé€šè¿‡ç»„åˆå¤šä¸ªæ¨¡å‹æ¥æœ‰æ•ˆå¤„ç†ç¦»æ•£åˆ†å¸ƒ(discrete distributions)å¹¶ç¡®ä¿è®¡ç®—æ•ˆç‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCoDeåœ¨å¤šé¡¹æ•°æ®é›†ä¸Šè¾¾åˆ°äº†SOTAæ°´å¹³ï¼Œåœ¨è¶…è¿‡åŠæ•°çš„æŸ¥è¯¢ä¸­å®ç°äº†ç»å¯¹å‡†ç¡®çš„ä¼°è®¡ï¼Œåœ¨å‡†ç¡®æ€§å’Œæ¨ç†æ•ˆç‡æ–¹é¢å‡å–å¾—äº†æ˜¾è‘—çªç ´ã€‚",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DB",
      "comment": "IEEE Transactions on Knowledge and Data Engineering (TKDE), 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.09602v1",
      "published_date": "2025-08-13 08:34:58 UTC",
      "updated_date": "2025-08-13 08:34:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:38:35.686970+00:00"
    },
    {
      "arxiv_id": "2508.09593v1",
      "title": "Hierarchical Brain Structure Modeling for Predicting Genotype of Glioma",
      "title_zh": "ç”¨äºèƒ¶è´¨ç˜¤åŸºå› å‹é¢„æµ‹çš„å±‚æ¬¡åŒ–è„‘ç»“æ„å»ºæ¨¡",
      "authors": [
        "Haotian Tang",
        "Jianwei Chen",
        "Xinrui Tang",
        "Yunjia Wu",
        "Zhengyang Miao",
        "Chao Li"
      ],
      "abstract": "Isocitrate DeHydrogenase (IDH) mutation status is a crucial biomarker for glioma prognosis. However, current prediction methods are limited by the low availability and noise of functional MRI. Structural and morphological connectomes offer a non-invasive alternative, yet existing approaches often ignore the brain's hierarchical organisation and multiscale interactions. To address this, we propose Hi-SMGNN, a hierarchical framework that integrates structural and morphological connectomes from regional to modular levels. It features a multimodal interaction module with a Siamese network and cross-modal attention, a multiscale feature fusion mechanism for reducing redundancy, and a personalised modular partitioning strategy to enhance individual specificity and interpretability. Experiments on the UCSF-PDGM dataset demonstrate that Hi-SMGNN outperforms baseline and state-of-the-art models, showing improved robustness and effectiveness in IDH mutation prediction.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç¥ç»èƒ¶è´¨ç˜¤é¢„åä¸­çš„å…³é”®ç”Ÿç‰©æ ‡å¿—ç‰© Isocitrate DeHydrogenase (IDH) çªå˜çŠ¶æ€çš„é¢„æµ‹ï¼Œæå‡ºäº†ä¸€ç§åä¸º Hi-SMGNN çš„å±‚æ¬¡åŒ–å»ºæ¨¡æ¡†æ¶ã€‚ä¸ºäº†è§£å†³ç°æœ‰é¢„æµ‹æ–¹æ³•åœ¨å¤„ç†åŠŸèƒ½ MRI æ—¶å­˜åœ¨çš„ä½å¯ç”¨æ€§å’Œå™ªå£°é—®é¢˜ï¼Œä»¥åŠå¯¹è„‘éƒ¨å±‚æ¬¡åŒ–ç»„ç»‡å’Œå¤šå°ºåº¦äº¤äº’å…³æ³¨ä¸è¶³çš„å±€é™ï¼Œè¯¥æ¡†æ¶å°†ç»“æ„å’Œå½¢æ€è¿æ¥ç»„ä»åŒºåŸŸå±‚çº§æ•´åˆè‡³æ¨¡å—å±‚çº§ã€‚Hi-SMGNN æ ¸å¿ƒåŒ…å«ä¸€ä¸ªç»“åˆäº† Siamese network å’Œ cross-modal attention çš„å¤šæ¨¡æ€äº¤äº’æ¨¡å—ï¼Œå¹¶åˆ©ç”¨å¤šå°ºåº¦ç‰¹å¾èåˆæœºåˆ¶æ¥å‡å°‘æ•°æ®å†—ä½™ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å¼•å…¥äº†ä¸ªæ€§åŒ–æ¨¡å—åˆ’åˆ†ç­–ç•¥ï¼Œä»¥å¢å¼ºä¸ªä½“ç‰¹å¼‚æ€§å’Œæ¨¡å‹çš„å¯è§£é‡Šæ€§ã€‚åœ¨ UCSF-PDGM æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒHi-SMGNN åœ¨é¢„æµ‹ IDH çªå˜æ–¹é¢ä¼˜äºåŸºå‡†æ¨¡å‹å’Œç°æœ‰çš„æœ€å…ˆè¿›æ¨¡å‹ï¼Œå±•ç°å‡ºæ›´å¼ºçš„é²æ£’æ€§å’Œæœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09593v1",
      "published_date": "2025-08-13 08:17:54 UTC",
      "updated_date": "2025-08-13 08:17:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:38:44.487239+00:00"
    },
    {
      "arxiv_id": "2508.09586v2",
      "title": "EvoCurr: Self-evolving Curriculum with Behavior Code Generation for Complex Decision-making",
      "title_zh": "EvoCurrï¼šåŸºäºè¡Œä¸ºä»£ç ç”Ÿæˆçš„å¤æ‚å†³ç­–è‡ªè¿›åŒ–è¯¾ç¨‹",
      "authors": [
        "Yang Cheng",
        "Zilai Wang",
        "Weiyu Ma",
        "Wenhui Zhu",
        "Yue Deng",
        "Jian Zhao"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across diverse domains, including programming, planning, and decision-making. However, their performance often degrades when faced with highly complex problem instances that require deep reasoning over long horizons. In such cases, direct problem-solving approaches can lead to inefficiency or failure due to the lack of structured intermediate guidance. To address this, we propose a novel self-evolve framework, EvoCurr, in which a dedicated curriculum-generation LLM constructs a sequence of problem instances with gradually increasing difficulty, tailored to the solver LLM's learning progress. The curriculum dynamically adapts easing challenges when the solver struggles and escalating them when success is consistent, thus maintaining an optimal learning trajectory. This approach enables the solver LLM, implemented as a code-generation model producing Python decision-tree scripts, to progressively acquire the skills needed for complex decision-making tasks. Experimental results on challenging decision-making benchmarks show that our method significantly improves task success rates and solution efficiency compared to direct-solving baselines. These findings suggest that LLM-driven curriculum learning holds strong potential for enhancing automated reasoning in real-world, high-complexity domains.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†EvoCurrï¼Œä¸€ç§ç»“åˆè¡Œä¸ºä»£ç ç”Ÿæˆ(Behavior Code Generation)çš„è‡ªæˆ‘æ¼”åŒ–è¯¾ç¨‹(Self-evolving Curriculum)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¤„ç†é•¿ç¨‹å¤æ‚å†³ç­–ä»»åŠ¡æ—¶å› ç¼ºä¹ç»“æ„åŒ–å¼•å¯¼è€Œè¡¨ç°é€€åŒ–çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶åˆ©ç”¨ä¸“é—¨çš„è¯¾ç¨‹ç”ŸæˆLLMæ„å»ºéš¾åº¦é€’å¢çš„é—®é¢˜åºåˆ—ï¼Œå¹¶æ ¹æ®æ±‚è§£å™¨LLMçš„è¿›åº¦åŠ¨æ€è°ƒæ•´æŒ‘æˆ˜éš¾åº¦ï¼Œä»¥ç»´æŒæœ€ä½³å­¦ä¹ è½¨è¿¹ã€‚æ±‚è§£å™¨LLMé€šè¿‡ç”ŸæˆPythonå†³ç­–æ ‘(decision-tree)è„šæœ¬ä½œä¸ºè¡Œä¸ºä»£ç ï¼Œé€æ­¥ä¹ å¾—å¤„ç†å¤æ‚å†³ç­–ä»»åŠ¡æ‰€éœ€çš„æŠ€èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨æŒ‘æˆ˜æ€§çš„å†³ç­–åŸºå‡†æµ‹è¯•ä¸­ï¼ŒEvoCurrç›¸æ¯”ç›´æ¥æ±‚è§£(direct-solving)åŸºå‡†æ˜¾è‘—æé«˜äº†ä»»åŠ¡æˆåŠŸç‡å’Œè§£é¢˜æ•ˆç‡ã€‚è¯¥ç ”ç©¶å±•ç¤ºäº†LLMé©±åŠ¨çš„è¯¾ç¨‹å­¦ä¹ åœ¨å¢å¼ºé«˜å¤æ‚åº¦é¢†åŸŸè‡ªåŠ¨åŒ–æ¨ç†(automated reasoning)æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09586v2",
      "published_date": "2025-08-13 07:59:29 UTC",
      "updated_date": "2025-08-20 07:50:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:39:17.062315+00:00"
    },
    {
      "arxiv_id": "2508.09558v1",
      "title": "CaRoBio: 3D Cable Routing with a Bio-inspired Gripper Fingernail",
      "title_zh": "CaRoBioï¼šåŸºäºä»¿ç”Ÿå¤¹æŒå™¨æŒ‡ç”²çš„ä¸‰ç»´çº¿ç¼†å¸ƒçº¿",
      "authors": [
        "Jiahui Zuo",
        "Boyang Zhang",
        "Fumin Zhang"
      ],
      "abstract": "The manipulation of deformable linear flexures has a wide range of applications in industry, such as cable routing in automotive manufacturing and textile production. Cable routing, as a complex multi-stage robot manipulation scenario, is a challenging task for robot automation. Common parallel two-finger grippers have the risk of over-squeezing and over-tension when grasping and guiding cables. In this paper, a novel eagle-inspired fingernail is designed and mounted on the gripper fingers, which helps with cable grasping on planar surfaces and in-hand cable guiding operations. Then we present a single-grasp end-to-end 3D cable routing framework utilizing the proposed fingernails, instead of the common pick-and-place strategy. Continuous control is achieved to efficiently manipulate cables through vision-based state estimation of task configurations and offline trajectory planning based on motion primitives. We evaluate the effectiveness of the proposed framework with a variety of cables and channel slots, significantly outperforming the pick-and-place manipulation process under equivalent perceptual conditions. Our reconfigurable task setting and the proposed framework provide a reference for future cable routing manipulations in 3D space.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¯å˜å½¢çº¿æ€§æŸ”æ€§ä»¶åœ¨å·¥ä¸šåº”ç”¨ä¸­çš„å¸ƒçº¿éš¾é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸º CaRoBio çš„ 3D ç”µç¼†å¸ƒçº¿(cable routing)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»ŸäºŒæŒ‡å¹³åŠ¨å¤¹çˆªåœ¨æŠ“å–å’Œå¼•å¯¼ç”µç¼†æ—¶å®¹æ˜“äº§ç”Ÿçš„è¿‡åº¦æŒ¤å‹å’Œè¿‡åº¦å¼ åŠ›é—®é¢˜ã€‚è®ºæ–‡è®¾è®¡äº†ä¸€ç§å—è€é¹°å¯å‘çš„ä»¿ç”ŸæŒ‡ç”²(eagle-inspired fingernail)å¹¶å®‰è£…åœ¨å¤¹çˆªä¸Šï¼Œæ˜¾è‘—æå‡äº†å¹³é¢ç”µç¼†æŠ“å–å’Œæ‰‹å†…ç”µç¼†å¼•å¯¼(in-hand cable guiding)çš„æ“ä½œæ€§èƒ½ã€‚è¯¥æ¡†æ¶æ‘’å¼ƒäº†å¸¸è§çš„æŠ“å–å¹¶æ”¾ç½®(pick-and-place)ç­–ç•¥ï¼Œé‡‡ç”¨å•æ¬¡æŠ“å–(single-grasp)çš„ç«¯åˆ°ç«¯æ–¹æ¡ˆï¼Œé€šè¿‡åŸºäºè§†è§‰çš„çŠ¶æ€ä¼°è®¡(state estimation)å’ŒåŸºäºè¿åŠ¨åŸè¯­(motion primitives)çš„ç¦»çº¿è½¨è¿¹è§„åˆ’å®ç°è¿ç»­æ§åˆ¶ã€‚å®éªŒè¯„ä¼°è¡¨æ˜ï¼ŒCaRoBio åœ¨å¤šç§ç”µç¼†å’Œé€šé“æ§½ä½çš„å¸ƒçº¿ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå…¶æ€§èƒ½åœ¨åŒç­‰æ„ŸçŸ¥æ¡ä»¶ä¸‹æ˜¾è‘—è¶…è¶Šäº†ä¼ ç»Ÿæ–¹æ³•ã€‚è¯¥ç ”ç©¶çš„å¯é‡æ„ä»»åŠ¡è®¾ç½®å’ŒæŠ€æœ¯æ¶æ„ä¸º 3D ç©ºé—´å†…çš„è‡ªä¸»ç”µç¼†å¸ƒçº¿æ“ä½œæä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09558v1",
      "published_date": "2025-08-13 07:25:40 UTC",
      "updated_date": "2025-08-13 07:25:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:39:03.792785+00:00"
    },
    {
      "arxiv_id": "2508.09547v1",
      "title": "GoViG: Goal-Conditioned Visual Navigation Instruction Generation",
      "title_zh": "GoViGï¼šç›®æ ‡å¯¼å‘çš„è§†è§‰å¯¼èˆªæŒ‡ä»¤ç”Ÿæˆ",
      "authors": [
        "Fengyi Wu",
        "Yifei Dong",
        "Zhi-Qi Cheng",
        "Yilong Dai",
        "Guangyu Chen",
        "Hang Wang",
        "Qi Dai",
        "Alexander G. Hauptmann"
      ],
      "abstract": "We introduce Goal-Conditioned Visual Navigation Instruction Generation (GoViG), a new task that aims to autonomously generate precise and contextually coherent navigation instructions solely from egocentric visual observations of initial and goal states. Unlike conventional approaches that rely on structured inputs such as semantic annotations or environmental maps, GoViG exclusively leverages raw egocentric visual data, substantially improving its adaptability to unseen and unstructured environments. Our method addresses this task by decomposing it into two interconnected subtasks: (1) visual forecasting, which predicts intermediate visual states bridging the initial and goal views; and (2) instruction generation, which synthesizes linguistically coherent instructions grounded in both observed and anticipated visuals. These subtasks are integrated within an autoregressive multimodal large language model trained with tailored objectives to ensure spatial accuracy and linguistic clarity. Furthermore, we introduce two complementary multimodal reasoning strategies, one-pass and interleaved reasoning, to mimic incremental human cognitive processes during navigation. To evaluate our method, we propose the R2R-Goal dataset, combining diverse synthetic and real-world trajectories. Empirical results demonstrate significant improvements over state-of-the-art methods, achieving superior BLEU-4 and CIDEr scores along with robust cross-domain generalization.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†GoViGï¼ˆGoal-Conditioned Visual Navigation Instruction Generationï¼‰ï¼Œè¿™æ˜¯ä¸€é¡¹æ—¨åœ¨ä»…é€šè¿‡ç¬¬ä¸€äººç§°è§†è§’ï¼ˆegocentric visual observationsï¼‰çš„åˆå§‹ä¸ç›®æ ‡çŠ¶æ€å›¾åƒè‡ªåŠ¨ç”Ÿæˆç²¾ç¡®å¯¼èˆªæŒ‡ä»¤çš„æ–°ä»»åŠ¡ã€‚ä¸ä¾èµ–è¯­ä¹‰æ ‡æ³¨æˆ–ç¯å¢ƒåœ°å›¾çš„ä¼ ç»Ÿæ–¹æ³•ä¸åŒï¼ŒGoViGå®Œå…¨åˆ©ç”¨åŸå§‹è§†è§‰æ•°æ®ï¼Œæ˜¾è‘—æå‡äº†åœ¨æœªè§è¿‡çš„éç»“æ„åŒ–ç¯å¢ƒä¸­çš„é€‚åº”èƒ½åŠ›ã€‚è¯¥æ–¹æ³•å°†ä»»åŠ¡åˆ†è§£ä¸ºé¢„æµ‹ä¸­é—´è§†è§‰çŠ¶æ€çš„è§†è§‰é¢„æµ‹ï¼ˆvisual forecastingï¼‰å’Œåˆæˆè¯­è¨€æŒ‡ä»¤çš„æŒ‡ä»¤ç”Ÿæˆï¼ˆinstruction generationï¼‰ä¸¤ä¸ªäº’è¿å­ä»»åŠ¡ã€‚è¿™äº›å­ä»»åŠ¡è¢«é›†æˆåˆ°ä¸€ä¸ªè‡ªå›å½’å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ä¸­ï¼Œå¹¶å¼•å…¥äº†ä¸€é˜¶æ®µæ¨ç†ï¼ˆone-pass reasoningï¼‰å’Œäº¤æ›¿æ¨ç†ï¼ˆinterleaved reasoningï¼‰ç­–ç•¥ä»¥æ¨¡æ‹Ÿäººç±»å¯¼èˆªçš„è®¤çŸ¥è¿‡ç¨‹ã€‚ä¸ºéªŒè¯è¯¥æ–¹æ³•ï¼Œç ”ç©¶è€…æå‡ºäº†åŒ…å«å¤šæ ·åŒ–åˆæˆä¸çœŸå®è½¨è¿¹çš„R2R-Goalæ•°æ®é›†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒGoViGåœ¨BLEU-4å’ŒCIDEræŒ‡æ ‡ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æœ€å…ˆè¿›æ–¹æ³•ï¼Œå¹¶å±•ç°å‡ºå¼ºå¤§çš„è·¨é¢†åŸŸæ³›åŒ–ï¼ˆcross-domain generalizationï¼‰èƒ½åŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Under review. Code: https://github.com/F1y1113/GoViG",
      "pdf_url": "https://arxiv.org/pdf/2508.09547v1",
      "published_date": "2025-08-13 07:05:17 UTC",
      "updated_date": "2025-08-13 07:05:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:38:56.396841+00:00"
    },
    {
      "arxiv_id": "2508.09537v1",
      "title": "Your Coding Intent is Secretly in the Context and You Should Deliberately Infer It Before Completion",
      "title_zh": "ç¼–ç æ„å›¾æ½œè—äºä¸Šä¸‹æ–‡ï¼šä»£ç è¡¥å…¨å‰çš„ä¸»åŠ¨æ¨ç†",
      "authors": [
        "Yanzhou Li",
        "Tianlin Li",
        "Yiran Zhang",
        "Shangqing Liu",
        "Aishan Liu",
        "Yang Liu"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly used for function completion in repository-scale codebases. Prior studies demonstrate that when explicit instructions--such as docstrings--are provided, these models can generate highly accurate implementations. However, in real-world repositories, such annotations are frequently absent, and performance drops substantially without them. To address this gap, we frame the task as a three-stage process. The first stage focuses on intent inference, where the model analyzes the code preceding the target function to uncover cues about the desired functionality. Such preceding context often encodes subtle but critical information, and we design a reasoning-based prompting framework to guide the LLM through step-by-step extraction and synthesis of these signals before any code is generated. The second stage introduces an optional interactive refinement mechanism to handle cases where preceding context alone is insufficient for intent recovery. In this stage, the model proposes a small set of candidate intentions, enabling the developer to select or edit them so that the inferred intent closely matches the actual requirement. Finally, in the third stage, the LLM generates the target function conditioned on the finalized intent. To support this pipeline, we curate a dataset of 40,000 examples annotated with intermediate reasoning traces and corresponding docstrings. Extensive experiments on DevEval and ComplexCodeEval show that our approach consistently boosts multiple LLMs, achieving over 20\\% relative gains in both reference-based and execution-based metrics, with the interactive refinement stage delivering additional improvements beyond these gains.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åœ¨ç¼ºä¹æ˜ç¡®æ³¨é‡Šï¼ˆå¦‚ docstringsï¼‰çš„ä»£ç åº“ä¸­ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) è¿›è¡Œå‡½æ•°è¡¥å…¨æ—¶æ€§èƒ½å¤§å¹…ä¸‹é™çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªä¸‰é˜¶æ®µçš„æ„å›¾æ¨æ–­ä¸ç”Ÿæˆæ¡†æ¶ã€‚ç¬¬ä¸€é˜¶æ®µåˆ©ç”¨åŸºäºæ¨ç†çš„æç¤ºæ¡†æ¶ (reasoning-based prompting) å¼•å¯¼æ¨¡å‹ä»å‰æ–‡ä»£ç ç¯å¢ƒä¸­æ­¥è¿›å¼æå–å¹¶åˆæˆç¼–ç¨‹æ„å›¾ (intent inference)ã€‚ç¬¬äºŒé˜¶æ®µå¼•å…¥äº†å¯é€‰çš„äº¤äº’å¼ç²¾ç‚¼æœºåˆ¶ (interactive refinement mechanism)ï¼Œå…è®¸å¼€å‘è€…å¯¹æ¨¡å‹ç”Ÿæˆçš„æ„å›¾å€™é€‰é¡¹è¿›è¡Œç­›é€‰æˆ–ç¼–è¾‘ã€‚ç¬¬ä¸‰é˜¶æ®µåˆ™åŸºäºæœ€ç»ˆç¡®å®šçš„æ„å›¾ç”Ÿæˆç›®æ ‡å‡½æ•°ï¼Œå¹¶è¾…ä»¥åŒ…å« 40,000 ä¸ªæ¨ç†è½¨è¿¹ç¤ºä¾‹çš„æ•°æ®é›†è¿›è¡Œæ”¯æŒã€‚åœ¨ DevEval å’Œ ComplexCodeEval ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å‚è€ƒæŒ‡æ ‡å’Œæ‰§è¡ŒæŒ‡æ ‡ä¸Šå‡å®ç°äº† 20% ä»¥ä¸Šçš„ç›¸å¯¹æå‡ã€‚ç ”ç©¶è¯æ˜ï¼Œåœ¨ç”Ÿæˆä»£ç å‰é€šè¿‡æ˜¾å¼æ¨ç†æŒ–æ˜ä¸Šä¸‹æ–‡ä¸­çš„éšè—æ„å›¾ï¼Œèƒ½æ˜¾è‘—å¢å¼ºæ¨¡å‹åœ¨å¤æ‚ä»£ç åº“ç¯å¢ƒä¸‹çš„è¡¥å…¨å‡†ç¡®æ€§ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09537v1",
      "published_date": "2025-08-13 06:45:23 UTC",
      "updated_date": "2025-08-13 06:45:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:39:03.592102+00:00"
    },
    {
      "arxiv_id": "2508.09535v1",
      "title": "AI Blob! LLM-Driven Recontextualization of Italian Television Archives",
      "title_zh": "AI Blob!ï¼šå¤§è¯­è¨€æ¨¡å‹é©±åŠ¨çš„æ„å¤§åˆ©ç”µè§†æ¡£æ¡ˆå†è¯­å¢ƒåŒ–",
      "authors": [
        "Roberto Balestri"
      ],
      "abstract": "This paper introduces AI Blob!, an experimental system designed to explore the potential of semantic cataloging and Large Language Models (LLMs) for the retrieval and recontextualization of archival television footage. Drawing methodological inspiration from Italian television programs such as Blob (RAI Tre, 1989-), AI Blob! integrates automatic speech recognition (ASR), semantic embeddings, and retrieval-augmented generation (RAG) to organize and reinterpret archival content. The system processes a curated dataset of 1,547 Italian television videos by transcribing audio, segmenting it into sentence-level units, and embedding these segments into a vector database for semantic querying. Upon user input of a thematic prompt, the LLM generates a range of linguistically and conceptually related queries, guiding the retrieval and recombination of audiovisual fragments. These fragments are algorithmically selected and structured into narrative sequences producing montages that emulate editorial practices of ironic juxtaposition and thematic coherence. By foregrounding dynamic, content-aware retrieval over static metadata schemas, AI Blob! demonstrates how semantic technologies can facilitate new approaches to archival engagement, enabling novel forms of automated narrative construction and cultural analysis. The project contributes to ongoing debates in media historiography and AI-driven archival research, offering both a conceptual framework and a publicly available dataset to support further interdisciplinary experimentation.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† AI Blob! ç³»ç»Ÿï¼Œæ—¨åœ¨æ¢ç´¢åˆ©ç”¨è¯­ä¹‰ç¼–ç›®å’Œ Large Language Models (LLMs) å¯¹æ„å¤§åˆ©ç”µè§†å­˜æ¡£ç´ æè¿›è¡Œæ£€ç´¢ä¸é‡æ„çš„æ½œåŠ›ã€‚è¯¥ç³»ç»Ÿå—æ„å¤§åˆ©ç”µè§†èŠ‚ç›® Blob å¯å‘ï¼Œæ•´åˆäº†è‡ªåŠ¨è¯­éŸ³è¯†åˆ« (ASR)ã€è¯­ä¹‰åµŒå…¥ (semantic embeddings) ä»¥åŠæ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG) æŠ€æœ¯ï¼Œä»¥ç»„ç»‡å¹¶é‡æ–°è¯ é‡Šå­˜æ¡£å†…å®¹ã€‚ç ”ç©¶å›¢é˜Ÿå¤„ç†äº†ç”± 1,547 ä¸ªè§†é¢‘ç»„æˆçš„æ•°æ®é›†ï¼Œé€šè¿‡è¯­éŸ³è½¬å½•ã€å¥å­çº§åˆ†å‰²å’Œå‘é‡æ•°æ®åº“ (vector database) å­˜å‚¨æ¥å®ç°è¯­ä¹‰æŸ¥è¯¢ã€‚æ ¹æ®ç”¨æˆ·è¾“å…¥çš„ä¸»é¢˜æç¤ºï¼ŒLLM ä¼šç”Ÿæˆç›¸å…³æŸ¥è¯¢å¹¶å¼•å¯¼è§†å¬ç‰‡æ®µçš„æ£€ç´¢ä¸é‡ç»„ï¼Œæœ€ç»ˆç”Ÿæˆæ¨¡ä»¿è®½åˆºå¹¶ç½® (ironic juxtaposition) é£æ ¼çš„è’™å¤ªå¥‡å™äº‹åºåˆ—ã€‚AI Blob! è¯æ˜äº†å†…å®¹æ„ŸçŸ¥æ£€ç´¢åœ¨ä¿ƒè¿›è‡ªåŠ¨åŒ–å™äº‹æ„å»ºå’Œæ–‡åŒ–åˆ†ææ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œä¸ºåª’ä½“å²å­¦ç ”ç©¶æä¾›äº†å…¨æ–°çš„æ–¹æ³•è®ºæ¡†æ¶å’Œå…¬å¼€æ•°æ®é›†ã€‚",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.CL",
        "cs.DL"
      ],
      "primary_category": "cs.MM",
      "comment": "Preprint",
      "pdf_url": "https://arxiv.org/pdf/2508.09535v1",
      "published_date": "2025-08-13 06:38:32 UTC",
      "updated_date": "2025-08-13 06:38:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:39:42.685014+00:00"
    },
    {
      "arxiv_id": "2508.09533v1",
      "title": "COXNet: Cross-Layer Fusion with Adaptive Alignment and Scale Integration for RGBT Tiny Object Detection",
      "title_zh": "COXNetï¼šç»“åˆè‡ªé€‚åº”å¯¹é½ä¸å°ºåº¦é›†æˆçš„è·¨å±‚èåˆ RGBT å¾®å°ç›®æ ‡æ£€æµ‹",
      "authors": [
        "Peiran Peng",
        "Tingfa Xu",
        "Liqiang Song",
        "Mengqi Zhu",
        "Yuqiang Fang",
        "Jianan Li"
      ],
      "abstract": "Detecting tiny objects in multimodal Red-Green-Blue-Thermal (RGBT) imagery is a critical challenge in computer vision, particularly in surveillance, search and rescue, and autonomous navigation. Drone-based scenarios exacerbate these challenges due to spatial misalignment, low-light conditions, occlusion, and cluttered backgrounds. Current methods struggle to leverage the complementary information between visible and thermal modalities effectively. We propose COXNet, a novel framework for RGBT tiny object detection, addressing these issues through three core innovations: i) the Cross-Layer Fusion Module, fusing high-level visible and low-level thermal features for enhanced semantic and spatial accuracy; ii) the Dynamic Alignment and Scale Refinement module, correcting cross-modal spatial misalignments and preserving multi-scale features; and iii) an optimized label assignment strategy using the GeoShape Similarity Measure for better localization. COXNet achieves a 3.32\\% mAP$_{50}$ improvement on the RGBTDronePerson dataset over state-of-the-art methods, demonstrating its effectiveness for robust detection in complex environments.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šæ¨¡æ€çº¢å¤–-å¯è§å…‰(RGBT)å›¾åƒä¸­çš„å¾®å°ç›®æ ‡æ£€æµ‹é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯åœ¨æ— äººæœºåœºæ™¯ä¸‹ç”±äºç©ºé—´é”™ä½ã€ä½å…‰ç…§å’ŒèƒŒæ™¯å¹²æ‰°å¯¼è‡´çš„æ£€æµ‹éš¾é¢˜ï¼Œæå‡ºäº†COXNetæ¡†æ¶ã€‚è¯¥æ¡†æ¶æ ¸å¿ƒå¼•å…¥äº†è·¨å±‚èåˆæ¨¡å—(Cross-Layer Fusion Module)ï¼Œé€šè¿‡èåˆé«˜å±‚å¯è§å…‰ç‰¹å¾å’Œåº•å±‚çƒ­æˆåƒç‰¹å¾ï¼Œæ˜¾è‘—æå‡äº†è¯­ä¹‰ç†è§£ä¸ç©ºé—´ç²¾åº¦ã€‚åŒæ—¶ï¼ŒCOXNetåˆ©ç”¨åŠ¨æ€å¯¹é½ä¸å°ºåº¦ä¼˜åŒ–æ¨¡å—(Dynamic Alignment and Scale Refinement)æ¥çº æ­£è·¨æ¨¡æ€é—´çš„ç©ºé—´é”™ä½ï¼Œå¹¶æœ‰æ•ˆä¿ç•™äº†å…³é”®çš„å¤šå°ºåº¦ç‰¹å¾ã€‚é’ˆå¯¹å®šä½ä¼˜åŒ–ï¼Œè¯¥æ¨¡å‹é‡‡ç”¨äº†åŸºäºå‡ ä½•å½¢çŠ¶ç›¸ä¼¼åº¦åº¦é‡(GeoShape Similarity Measure)çš„æ”¹è¿›æ ‡ç­¾åˆ†é…ç­–ç•¥ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒCOXNetåœ¨RGBTDronePersonæ•°æ®é›†ä¸Šçš„mAP50æ¯”ç°æœ‰å…ˆè¿›æ–¹æ³•æå‡äº†3.32%ã€‚è¯¥ç ”ç©¶è¯æ˜äº†è¯¥æ–¹æ³•åœ¨å¤æ‚ç¯å¢ƒä¸‹è¿›è¡Œé²æ£’æ€§æ£€æµ‹çš„æœ‰æ•ˆæ€§ï¼Œä¸ºå¤šæ¨¡æ€å¾®å°ç›®æ ‡æ£€æµ‹æä¾›äº†é«˜æ•ˆä¸”å¯é çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09533v1",
      "published_date": "2025-08-13 06:30:03 UTC",
      "updated_date": "2025-08-13 06:30:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:40:09.157856+00:00"
    },
    {
      "arxiv_id": "2508.09532v1",
      "title": "Decentralized Rank Scheduling for Energy-Constrained Multi-Task Federated Fine-Tuning in Edge-Assisted IoV Networks",
      "title_zh": "è¾¹ç¼˜è¾…åŠ©è½¦è”ç½‘ä¸­é¢å‘èƒ½é‡å—é™å¤šä»»åŠ¡è”é‚¦å¾®è°ƒçš„å»ä¸­å¿ƒåŒ–ç§©è°ƒåº¦",
      "authors": [
        "Bokeng Zheng",
        "Jianqiang Zhong",
        "Jiayi Liu",
        "Xiaoxi Zhang"
      ],
      "abstract": "Federated fine-tuning has emerged as a promising approach for adapting foundation models (FMs) to diverse downstream tasks in edge environments. In Internet of Vehicles (IoV) systems, enabling efficient and low-latency multi-task adaptation is particularly challenging due to client mobility, heterogeneous resources, and intermittent connectivity. This paper proposes a hierarchical federated fine-tuning framework that coordinates roadside units (RSUs) and vehicles to support resource-aware and mobility-resilient learning across dynamic IoV scenarios. Leveraging Low-Rank Adaptation (LoRA), we introduce a decentralized, energy-aware rank adaptation mechanism formulated as a constrained multi-armed bandit problem. A novel UCB-DUAL algorithm is developed to enable adaptive exploration under per-task energy budgets, achieving provable sublinear regret. To evaluate our method, we construct a large-scale IoV simulator based on real-world trajectories, capturing dynamic participation, RSU handoffs, and communication variability. Extensive experiments show that our approach achieves the best accuracy-efficiency trade-off among all baselines, reducing latency by over 24\\% and improving average accuracy by more than 2.5\\%.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹è½¦è”ç½‘(IoV)ç¯å¢ƒä¸‹åŸºç¡€æ¨¡å‹(FMs)åœ¨å¤šä»»åŠ¡è”é‚¦å¾®è°ƒ(Federated fine-tuning)ä¸­é¢ä¸´çš„è½¦è¾†ç§»åŠ¨æ€§ã€èµ„æºå¼‚æ„æ€§å’Œè¿æ¥ä¸ç¨³å®šç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§å±‚çº§è”é‚¦å¾®è°ƒæ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡åè°ƒè·¯ä¾§å•å…ƒ(RSUs)ä¸è½¦è¾†å®ç°èµ„æºæ„ŸçŸ¥ä¸ç§»åŠ¨éŸ§æ€§å­¦ä¹ ã€‚è¯¥ç ”ç©¶åˆ©ç”¨ä½ç§©è‡ªé€‚åº”(LoRA)æŠ€æœ¯ï¼Œå°†åˆ†å¸ƒå¼èƒ½é‡æ„ŸçŸ¥ç§©è‡ªé€‚åº”æœºåˆ¶å»ºæ¨¡ä¸ºå—çº¦æŸçš„å¤šè‡‚å¼ºç›—é—®é¢˜ï¼Œå¹¶å¼€å‘äº†æ–°å‹UCB-DUALç®—æ³•ä»¥åœ¨æ»¡è¶³æ¯é¡¹ä»»åŠ¡èƒ½é‡é¢„ç®—çš„å‰æä¸‹å®ç°è‡ªé€‚åº”æ¢ç´¢ã€‚é€šè¿‡åŸºäºçœŸå®è½¨è¿¹çš„å¤§è§„æ¨¡è½¦è”ç½‘æ¨¡æ‹Ÿå™¨å¯¹åŠ¨æ€å‚ä¸ã€RSUåˆ‡æ¢åŠé€šä¿¡å¤šå˜æ€§è¿›è¡Œçš„å®éªŒè¯„ä¼°è¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ‰€æœ‰åŸºçº¿æ–¹æ¡ˆä¸­å®ç°äº†æœ€ä½³çš„ç²¾åº¦-æ•ˆç‡å¹³è¡¡ã€‚æœ€ç»ˆå®éªŒæ•°æ®è¯æ˜ï¼Œè¯¥æ–¹æ¡ˆæˆåŠŸå°†ç³»ç»Ÿå»¶è¿Ÿé™ä½äº†24%ä»¥ä¸Šï¼Œå¹¶ä½¿å¹³å‡ç²¾åº¦æå‡äº†è¶…è¿‡2.5%ï¼Œä¸ºè¾¹ç¼˜è¾…åŠ©è½¦è”ç½‘ç½‘ç»œä¸­çš„é«˜æ•ˆæ¨¡å‹é€‚é…æä¾›äº†æœ‰åŠ›æ”¯æŒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09532v1",
      "published_date": "2025-08-13 06:29:00 UTC",
      "updated_date": "2025-08-13 06:29:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:39:42.390294+00:00"
    },
    {
      "arxiv_id": "2508.09522v1",
      "title": "Generation of Indian Sign Language Letters, Numbers, and Words",
      "title_zh": "Indian Sign Language å­—æ¯ã€æ•°å­—ä¸å•è¯çš„ç”Ÿæˆ",
      "authors": [
        "Ajeet Kumar Yadav",
        "Nishant Kumar",
        "Rathna G N"
      ],
      "abstract": "Sign language, which contains hand movements, facial expressions and bodily gestures, is a significant medium for communicating with hard-of-hearing people. A well-trained sign language community communicates easily, but those who don't know sign language face significant challenges. Recognition and generation are basic communication methods between hearing and hard-of-hearing individuals. Despite progress in recognition, sign language generation still needs to be explored. The Progressive Growing of Generative Adversarial Network (ProGAN) excels at producing high-quality images, while the Self-Attention Generative Adversarial Network (SAGAN) generates feature-rich images at medium resolutions. Balancing resolution and detail is crucial for sign language image generation. We are developing a Generative Adversarial Network (GAN) variant that combines both models to generate feature-rich, high-resolution, and class-conditional sign language images. Our modified Attention-based model generates high-quality images of Indian Sign Language letters, numbers, and words, outperforming the traditional ProGAN in Inception Score (IS) and FrÃ©chet Inception Distance (FID), with improvements of 3.2 and 30.12, respectively. Additionally, we are publishing a large dataset incorporating high-quality images of Indian Sign Language alphabets, numbers, and 129 words.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ‰‹è¯­ç”Ÿæˆ(Sign Language Generation)é¢†åŸŸæ¢ç´¢ä¸è¶³çš„ç°çŠ¶ï¼Œæå‡ºäº†ä¸€ç§ç»“åˆæ¸è¿›å¼ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(ProGAN)ä¸è‡ªæ³¨æ„åŠ›ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(SAGAN)ä¼˜ç‚¹çš„æ”¹è¿›å‹ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(GAN)å˜ä½“ã€‚è¯¥æ¨¡å‹æ—¨åœ¨ç”Ÿæˆé«˜åˆ†è¾¨ç‡ä¸”å…·æœ‰ä¸°å¯Œç‰¹å¾çš„å°åº¦æ‰‹è¯­(Indian Sign Language)å­—æ¯ã€æ•°å­—å’Œè¯æ±‡å›¾åƒï¼Œæœ‰æ•ˆåœ°å¹³è¡¡äº†å›¾åƒåˆ†è¾¨ç‡ä¸ç»†èŠ‚è¡¨ç°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ³¨æ„åŠ›æœºåˆ¶æ¨¡å‹åœ¨èµ·å§‹åˆ†æ•°(Inception Score)å’Œå¼—é›·æ­‡èµ·å§‹è·ç¦»(FrÃ©chet Inception Distance)æŒ‡æ ‡ä¸Šåˆ†åˆ«æ¯”ä¼ ç»ŸProGANæå‡äº†3.2å’Œ30.12ï¼Œå±•ç°å‡ºæ›´ä¼˜çš„å›¾åƒç”Ÿæˆè´¨é‡ã€‚æ­¤å¤–ï¼Œç ”ç©¶å›¢é˜Ÿè¿˜å‘å¸ƒäº†ä¸€ä¸ªåŒ…å«é«˜è´¨é‡æ‰‹è¯­å­—æ¯ã€æ•°å­—åŠ129ä¸ªå¸¸ç”¨è¯æ±‡çš„å¤§å‹æ•°æ®é›†ï¼Œä¸ºåŠ©å¬éšœç¢äººå£«çš„æ²Ÿé€šæŠ€æœ¯ç ”ç©¶æä¾›äº†é‡è¦æ”¯æŒã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages, 5 figures, 2024 International Conference on Intelligent Algorithms for Computational Intelligence Systems (IACIS)",
      "pdf_url": "https://arxiv.org/pdf/2508.09522v1",
      "published_date": "2025-08-13 06:10:20 UTC",
      "updated_date": "2025-08-13 06:10:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:41:07.286905+00:00"
    },
    {
      "arxiv_id": "2508.09521v1",
      "title": "COMPEER: Controllable Empathetic Reinforcement Reasoning for Emotional Support Conversation",
      "title_zh": "COMPEERï¼šé¢å‘æƒ…æ„Ÿæ”¯æŒå¯¹è¯çš„å¯æ§å…±æƒ…å¼ºåŒ–æ¨ç†",
      "authors": [
        "Yunxiao Wang",
        "Meng Liu",
        "Wenqi Liu",
        "Kaiyu Jiang",
        "Bin Wen",
        "Fan Yang",
        "Tingting Gao",
        "Guorui Zhou",
        "Liqiang Nie"
      ],
      "abstract": "Emotional support conversations are crucial for promoting emotional well-being, yet current models often lack deep empathetic reasoning grounded in psychological principles. To address this, we propose controllable empathetic reasoning, which combines natural language reasoning with structured psychological steps. We construct a fine-grained dataset annotated with reasoning correctness and response preferences to enable this capability. To further enhance training, we employ reinforcement learning with a unified process-outcome reward model that delivers precise feedback. To mitigate response repetitiveness from entropy collapse, we introduce personality-based dialogue rewriting and a redundancy-aware reward reweighting strategy. Our approach significantly improves model's emotional support ability, advancing the development of empathetic, human-like support systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰æƒ…æ„Ÿæ”¯æŒå¯¹è¯æ¨¡å‹ç¼ºä¹åŸºäºå¿ƒç†å­¦åŸç†çš„æ·±åº¦å…±æƒ…æ¨ç†è¿™ä¸€é—®é¢˜ï¼Œæå‡ºäº† COMPEER æ¡†æ¶ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†å¯æ§å…±æƒ…æ¨ç† (controllable empathetic reasoning)ï¼Œå°†è‡ªç„¶è¯­è¨€æ¨ç†ä¸ç»“æ„åŒ–çš„å¿ƒç†å­¦æ­¥éª¤ç›¸ç»“åˆã€‚ä¸ºäº†å®ç°è¿™ä¸€èƒ½åŠ›ï¼Œç ”ç©¶è€…æ„å»ºäº†ä¸€ä¸ªåŒ…å«æ¨ç†æ­£ç¡®æ€§å’Œå›å¤åå¥½æ ‡æ³¨çš„ç»†ç²’åº¦æ•°æ®é›†ï¼Œå¹¶é‡‡ç”¨å¼ºåŒ–å­¦ä¹  (Reinforcement Learning) ç­–ç•¥ï¼Œåˆ©ç”¨ç»Ÿä¸€çš„è¿‡ç¨‹-ç»“æœå¥–åŠ±æ¨¡å‹ (unified process-outcome reward model) æä¾›ç²¾å‡†åé¦ˆã€‚é’ˆå¯¹å¼ºåŒ–å­¦ä¹ ä¸­å¸¸è§çš„å›å¤é‡å¤æ€§é—®é¢˜ï¼Œç ”ç©¶è¿›ä¸€æ­¥å¼•å…¥äº†åŸºäºäººæ ¼çš„å¯¹è¯é‡å†™ (personality-based dialogue rewriting) å’Œå†—ä½™æ„ŸçŸ¥å¥–åŠ±é‡æƒ (redundancy-aware reward reweighting) ç­–ç•¥ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCOMPEER æ˜¾è‘—æå‡äº†æ¨¡å‹çš„æƒ…æ„Ÿæ”¯æŒèƒ½åŠ›ï¼Œä¸ºå¼€å‘æ›´å…·å…±æƒ…å¿ƒä¸”ç±»äººåŒ–çš„æ”¯æŒç³»ç»Ÿå¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09521v1",
      "published_date": "2025-08-13 06:09:32 UTC",
      "updated_date": "2025-08-13 06:09:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:40:03.658796+00:00"
    },
    {
      "arxiv_id": "2508.09508v1",
      "title": "SMART-OC: A Real-time Time-risk Optimal Replanning Algorithm for Dynamic Obstacles and Spatio-temporally Varying Currents",
      "title_zh": "SMART-OCï¼šé¢å‘åŠ¨æ€éšœç¢ç‰©ä¸æ—¶ç©ºå˜æµ·æµçš„å®æ—¶æ—¶é—´-é£é™©æœ€ä¼˜é‡è§„åˆ’ç®—æ³•",
      "authors": [
        "Reema Raval",
        "Shalabh Gupta"
      ],
      "abstract": "Typical marine environments are highly complex with spatio-temporally varying currents and dynamic obstacles, presenting significant challenges to Unmanned Surface Vehicles (USVs) for safe and efficient navigation. Thus, the USVs need to continuously adapt their paths with real-time information to avoid collisions and follow the path of least resistance to the goal via exploiting ocean currents. In this regard, we introduce a novel algorithm, called Self-Morphing Adaptive Replanning Tree for dynamic Obstacles and Currents (SMART-OC), that facilitates real-time time-risk optimal replanning in dynamic environments. SMART-OC integrates the obstacle risks along a path with the time cost to reach the goal to find the time-risk optimal path. The effectiveness of SMART-OC is validated by simulation experiments, which demonstrate that the USV performs fast replannings to avoid dynamic obstacles and exploit ocean currents to successfully reach the goal.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†SMART-OCï¼Œä¸€ç§ä¸“ä¸ºå¤„ç†åŠ¨æ€éšœç¢ç‰©(dynamic obstacles)å’Œæ—¶ç©ºå˜åŒ–æ´‹æµ(spatio-temporally varying currents)è®¾è®¡çš„å®æ—¶æ—¶é—´-é£é™©æœ€ä¼˜é‡è§„åˆ’ç®—æ³•ï¼Œä»¥è§£å†³æ— äººèˆ¹(USVs)åœ¨å¤æ‚æµ·æ´‹ç¯å¢ƒä¸­çš„èˆªè¡Œéš¾é¢˜ã€‚è¯¥ç®—æ³•çš„æ ¸å¿ƒåœ¨äºå°†è·¯å¾„æ²¿çº¿çš„éšœç¢ç‰©é£é™©ä¸åˆ°è¾¾ç›®æ ‡çš„æ—¶é—´æˆæœ¬è¿›è¡Œæ·±åº¦æ•´åˆï¼Œä»è€Œå¯»æ‰¾æ—¶é—´-é£é™©æœ€ä¼˜è·¯å¾„(time-risk optimal path)ã€‚SMART-OC å…è®¸ USVs æ ¹æ®å®æ—¶è·å–çš„ç¯å¢ƒä¿¡æ¯æŒç»­è°ƒæ•´è·¯å¾„ï¼Œåœ¨ç¡®ä¿è§„é¿åŠ¨æ€ç¢°æ’çš„åŒæ—¶ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåˆ©ç”¨æ´‹æµåŠ¨åŠ›æ¥å¯»æ‰¾æŠµè¾¾ç›®æ ‡çš„æœ€å°é˜»åŠ›æ–¹æ¡ˆã€‚ä»¿çœŸå®éªŒç»“æœéªŒè¯äº†è¯¥ç®—æ³•çš„æœ‰æ•ˆæ€§ï¼Œè¯æ˜å…¶å…·å¤‡æé«˜çš„é‡è§„åˆ’æ•ˆç‡ï¼Œæ˜¾è‘—æå‡äº†æ— äººèˆ¹åœ¨å¤æ‚åŠ¨æ€ç¯å¢ƒä¸‹æˆåŠŸæ‰§è¡Œä»»åŠ¡çš„èƒ½åŠ›ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09508v1",
      "published_date": "2025-08-13 05:42:25 UTC",
      "updated_date": "2025-08-13 05:42:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:39:56.890514+00:00"
    },
    {
      "arxiv_id": "2508.09507v2",
      "title": "An Automated Multi-modal Evaluation Framework for Mobile Intelligent Assistants Based on Large Language Models and Multi-Agent Collaboration",
      "title_zh": "åŸºäºå¤§è¯­è¨€æ¨¡å‹ä¸å¤šæ™ºèƒ½ä½“åä½œçš„ç§»åŠ¨æ™ºèƒ½åŠ©æ‰‹è‡ªåŠ¨åŒ–å¤šæ¨¡æ€è¯„ä¼°æ¡†æ¶",
      "authors": [
        "Meiping Wang",
        "Jian Zhong",
        "Rongduo Han",
        "Liming Kang",
        "Zhengkun Shi",
        "Xiao Liang",
        "Xing Lin",
        "Nan Gao",
        "Haining Zhang"
      ],
      "abstract": "With the rapid development of mobile intelligent assistant technologies, multi-modal AI assistants have become essential interfaces for daily user interactions. However, current evaluation methods face challenges including high manual costs, inconsistent standards, and subjective bias. This paper proposes an automated multi-modal evaluation framework based on large language models and multi-agent collaboration. The framework employs a three-tier agent architecture consisting of interaction evaluation agents, semantic verification agents, and experience decision agents. Through supervised fine-tuning on the Qwen3-8B model, we achieve a significant evaluation matching accuracy with human experts. Experimental results on eight major intelligent agents demonstrate the framework's effectiveness in predicting users' satisfaction and identifying generation defects.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLMs)å’Œå¤šæ™ºèƒ½ä½“åä½œ(Multi-Agent Collaboration)çš„è‡ªåŠ¨åŒ–å¤šæ¨¡æ€è¯„ä¼°æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç§»åŠ¨æ™ºèƒ½åŠ©æ‰‹è¯„ä¼°ä¸­äººå·¥æˆæœ¬é«˜ã€æ ‡å‡†ä¸ä¸€å’Œä¸»è§‚åè§ç­‰é—®é¢˜ã€‚è¯¥æ¡†æ¶æ„å»ºäº†ç”±äº¤äº’è¯„ä¼°æ™ºèƒ½ä½“(Interaction evaluation agents)ã€è¯­ä¹‰éªŒè¯æ™ºèƒ½ä½“(Semantic verification agents)å’Œä½“éªŒå†³ç­–æ™ºèƒ½ä½“(Experience decision agents)ç»„æˆçš„ä¸‰å±‚æ¶æ„ã€‚é€šè¿‡å¯¹ Qwen3-8B æ¨¡å‹è¿›è¡Œç›‘ç£å¾®è°ƒ(Supervised fine-tuning)ï¼Œè¯¥æ¡†æ¶å®ç°äº†ä¸äººç±»ä¸“å®¶é«˜åº¦ä¸€è‡´çš„è¯„ä¼°å‡†ç¡®ç‡ã€‚åœ¨å…«ä¸ªä¸»æµæ™ºèƒ½åŠ©æ‰‹ä¸Šçš„å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ¡†æ¶èƒ½æœ‰æ•ˆé¢„æµ‹ç”¨æˆ·æ»¡æ„åº¦å¹¶ç²¾å‡†è¯†åˆ«ç”Ÿæˆç¼ºé™·ï¼Œä¸ºå¤šæ¨¡æ€ AI åŠ©æ‰‹çš„æ€§èƒ½è¯„ä¼°æä¾›äº†é«˜æ•ˆä¸”è‡ªåŠ¨åŒ–çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09507v2",
      "published_date": "2025-08-13 05:40:34 UTC",
      "updated_date": "2025-10-21 14:26:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:40:19.089971+00:00"
    },
    {
      "arxiv_id": "2508.09505v1",
      "title": "Verify Distributed Deep Learning Model Implementation Refinement with Iterative Relation Inference",
      "title_zh": "åŸºäºè¿­ä»£å…³ç³»æ¨ç†çš„åˆ†å¸ƒå¼æ·±åº¦å­¦ä¹ æ¨¡å‹å®ç°ç²¾åŒ–éªŒè¯",
      "authors": [
        "Zhanghan Wang",
        "Ding Ding",
        "Hang Zhu",
        "Haibin Lin",
        "Aurojit Panda"
      ],
      "abstract": "Distributed machine learning training and inference is common today because today's large models require more memory and compute than can be provided by a single GPU. Distributed models are generally produced by programmers who take a sequential model specification and apply several distribution strategies to distribute state and computation across GPUs. Unfortunately, bugs can be introduced in the process, and a distributed model implementation's outputs might differ from the sequential model's outputs. In this paper, we describe an approach to statically identify such bugs by checking model refinement, that is, can the sequential model's outputs be reconstructed from the distributed model's outputs? Our approach, implemented in GraphGuard, uses iterative rewriting to prove model refinement. Our approach can scale to today's large models and deployments: we evaluate it using GPT and Llama-3. Further, it provides actionable output that aids in bug localization.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å½“å‰å¤§è§„æ¨¡æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨å°†é¡ºåºæ¨¡å‹è§„èŒƒ(Sequential Model Specification)è½¬æ¢ä¸ºåˆ†å¸ƒå¼å®ç°è¿‡ç¨‹ä¸­å®¹æ˜“å¼•å…¥é”™è¯¯ã€å¯¼è‡´è¾“å‡ºä¸ä¸€è‡´çš„é—®é¢˜ï¼Œæå‡ºäº† GraphGuard æ¡†æ¶ã€‚è¯¥æ¡†æ¶é‡‡ç”¨é™æ€éªŒè¯æ–¹æ³•ï¼Œé€šè¿‡è¿­ä»£é‡å†™(Iterative Rewriting)æŠ€æœ¯æ¥éªŒè¯æ¨¡å‹ç»†åŒ–(Model Refinement)ï¼Œå³ç¡®ä¿é¡ºåºæ¨¡å‹çš„è¾“å‡ºèƒ½å¤Ÿä»åˆ†å¸ƒå¼æ¨¡å‹çš„è¾“å‡ºä¸­è¢«å‡†ç¡®é‡æ„ã€‚GraphGuard åˆ©ç”¨è¿­ä»£å…³ç³»æ¨ç†(Iterative Relation Inference)è¯æ˜åˆ†å¸ƒå¼çš„æ­£ç¡®æ€§ï¼Œèƒ½å¤Ÿæœ‰æ•ˆè¯†åˆ«åˆ†å¸ƒå¼å®ç°ä¸­çš„æ½œåœ¨æ¼æ´ã€‚å®éªŒè¯„ä¼°æ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•å…·æœ‰æå¼ºçš„å¯æ‰©å±•æ€§ï¼Œèƒ½å¤Ÿå¤„ç† GPT å’Œ Llama-3 ç­‰å½“ä»£å¤§å‹æ¨¡å‹ã€‚æ­¤å¤–ï¼Œè¯¥ç³»ç»Ÿè¿˜èƒ½æä¾›å¯æ“ä½œçš„åé¦ˆï¼Œæ˜¾è‘—æå‡äº†é”™è¯¯å®šä½(Bug Localization)çš„æ•ˆç‡ã€‚è¿™é¡¹å·¥ä½œä¸ºç¡®ä¿å¤æ‚åˆ†å¸ƒå¼æ·±åº¦å­¦ä¹ ç³»ç»Ÿå®ç°çš„æ­£ç¡®æ€§ä¸ä¸€è‡´æ€§æä¾›äº†ä¸€ç§å¯é çš„è‡ªåŠ¨åŒ–è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09505v1",
      "published_date": "2025-08-13 05:33:25 UTC",
      "updated_date": "2025-08-13 05:33:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:41:41.756178+00:00"
    },
    {
      "arxiv_id": "2508.09497v1",
      "title": "From Ranking to Selection: A Simple but Efficient Dynamic Passage Selector for Retrieval Augmented Generation",
      "title_zh": "ä»æ’åºåˆ°é€‰æ‹©ï¼šä¸€ç§ç®€å•é«˜æ•ˆçš„æ£€ç´¢å¢å¼ºç”ŸæˆåŠ¨æ€ç¯‡ç« é€‰æ‹©å™¨",
      "authors": [
        "Siyuan Meng",
        "Junming Liu",
        "Yirong Chen",
        "Song Mao",
        "Pinlong Cai",
        "Guohang Yan",
        "Botian Shi",
        "Ding Wang"
      ],
      "abstract": "Retrieval-augmented generation (RAG) systems are often bottlenecked by their reranking modules, which typically score passages independently and select a fixed Top-K size. This approach struggles with complex multi-hop queries that require synthesizing evidence across multiple documents, creating a trade-off where small K values omit crucial information and large K values introduce noise. To address this, we introduce the Dynamic Passage Selector (DPS), a novel reranking framework that treats passage selection as a supervised learning problem. Unlike traditional point-wise or list-wise methods, DPS is fine-tuned to capture inter-passage dependencies and dynamically select the most relevant set of passages for generation. As a seamless plug-and-play module, DPS requires no modifications to the standard RAG pipeline. Comprehensive evaluations on five benchmarks show that DPS consistently outperforms state-of-the-art rerankers and fine-tuning methods. Notably, on the challenging MuSiQue dataset, DPS improves the F1-score by 30.06% and 15.4% over strong baselines like Qwen3-reranker and RankingGPT, respectively. Our results demonstrate that by enabling adaptive evidence selection, DPS substantially enhances reasoning capabilities in complex RAG scenarios.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)ç³»ç»Ÿä¸­é‡æ’åºæ¨¡å—(reranking modules)å› é‡‡ç”¨å›ºå®šçš„Top-Kç­–ç•¥è€Œéš¾ä»¥å¤„ç†å¤æ‚å¤šè·³æŸ¥è¯¢çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ–°å‹é‡æ’åºæ¡†æ¶Dynamic Passage Selector (DPS)ã€‚è¯¥æ¡†æ¶å°†æ®µè½é€‰æ‹©è½¬åŒ–ä¸ºç›‘ç£å­¦ä¹ é—®é¢˜ï¼Œé€šè¿‡å¾®è°ƒæ¨¡å‹ä»¥æ•æ‰æ®µè½é—´çš„ä¾èµ–å…³ç³»ï¼Œä»è€Œèƒ½å¤ŸåŠ¨æ€åœ°ä¸ºç”Ÿæˆé˜¶æ®µé€‰æ‹©æœ€ç›¸å…³çš„æ®µè½é›†åˆã€‚DPSä½œä¸ºä¸€ä¸ªå³æ’å³ç”¨çš„æ¨¡å—ï¼Œæ— éœ€å¯¹æ ‡å‡†RAGæµç¨‹è¿›è¡Œä»»ä½•ä¿®æ”¹ï¼Œå…·æœ‰æé«˜çš„é€šç”¨æ€§ã€‚åœ¨äº”ä¸ªåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒDPSçš„æ€§èƒ½å§‹ç»ˆä¼˜äºç°æœ‰çš„SOTAé‡æ’åºå™¨ï¼Œå°¤å…¶åœ¨æŒ‘æˆ˜æ€§æé«˜çš„MuSiQueæ•°æ®é›†ä¸Šï¼Œå…¶F1åˆ†æ•°ç›¸è¾ƒäºQwen3-rerankerå’ŒRankingGPTåˆ†åˆ«æå‡äº†30.06%å’Œ15.4%ã€‚ç ”ç©¶è¯æ˜ï¼Œé€šè¿‡å¼•å…¥è¿™ç§è‡ªé€‚åº”çš„è¯æ®é€‰æ‹©æœºåˆ¶ï¼ŒDPSæ˜¾è‘—å¢å¼ºäº†å¤æ‚RAGåœºæ™¯ä¸‹çš„é€»è¾‘æ¨ç†èƒ½åŠ›ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 4 tables",
      "pdf_url": "https://arxiv.org/pdf/2508.09497v1",
      "published_date": "2025-08-13 05:05:34 UTC",
      "updated_date": "2025-08-13 05:05:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:40:48.795631+00:00"
    },
    {
      "arxiv_id": "2508.09494v1",
      "title": "Learning Facts at Scale with Active Reading",
      "title_zh": "é€šè¿‡ä¸»åŠ¨é˜…è¯»å®ç°å¤§è§„æ¨¡äº‹å®å­¦ä¹ ",
      "authors": [
        "Jessy Lin",
        "Vincent-Pierre Berges",
        "Xilun Chen",
        "Wen-Tau Yih",
        "Gargi Ghosh",
        "Barlas OÄŸuz"
      ],
      "abstract": "LLMs are known to store vast amounts of knowledge in their parametric memory. However, learning and recalling facts from this memory is known to be unreliable, depending largely on the prevalence of particular facts in the training data and other factors which are poorly understood. Practitioners are lacking tools which will allow them to ensure that the models learn a given body of knowledge reliably and consistently. To this end, we propose Active Reading: a framework where we train models to study a given set of material with self-generated learning strategies. First, we demonstrate models trained with Active Reading on expert domains absorb significantly more knowledge than vanilla finetuning and other data augmentations. We train expert 8B models that achieve 66% on a Wikipedia-grounded subset of SimpleQA (+313% relative over vanilla finetuning) and 26% on FinanceBench (+160% relative over vanilla finetuning) by applying Active Reading to the source documents for each benchmark. Finally, we show that Active Reading can be utilized at pre-training scale to build more factual models. As a demonstration of this, we release Meta WikiExpert-8B, a Wikipedia-expert model trained on 1 trillion generated tokens, which outcompetes models with hundreds of billions of parameters on factual QA.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Active Readingæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨å‚æ•°è®°å¿†ä¸­å­¦ä¹ å’Œå¬å›äº‹å®ä¸å¯é çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶é€šè¿‡è®­ç»ƒæ¨¡å‹åˆ©ç”¨è‡ªæˆ‘ç”Ÿæˆçš„å­¦ä¹ ç­–ç•¥(self-generated learning strategies)æ¥ç ”ç©¶ç»™å®šææ–™ï¼Œä»è€Œæ˜¾è‘—æå‡çŸ¥è¯†å¸æ”¶çš„æ•ˆç‡ä¸ä¸€è‡´æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåº”ç”¨Active Readingè®­ç»ƒçš„8Bæ¨¡å‹åœ¨SimpleQAå’ŒFinanceBenchåŸºå‡†æµ‹è¯•ä¸­ï¼Œç›¸è¾ƒäºæ™®é€šå¾®è°ƒ(vanilla finetuning)åˆ†åˆ«å®ç°äº†313%å’Œ160%çš„ç›¸å¯¹å‡†ç¡®ç‡æå‡ã€‚æ­¤å¤–ï¼Œç ”ç©¶å›¢é˜Ÿåˆ©ç”¨è¯¥æŠ€æœ¯åœ¨1ä¸‡äº¿ç”ŸæˆTokenä¸Šè®­ç»ƒå¹¶å‘å¸ƒäº†Meta WikiExpert-8Bæ¨¡å‹ï¼Œå…¶åœ¨äº‹å®æ€§é—®ç­”(factual QA)ä»»åŠ¡ä¸­çš„è¡¨ç°ä¼˜äºå‚æ•°é‡é«˜è¾¾æ•°åƒäº¿çš„å¤§å‹æ¨¡å‹ã€‚è¯¥é¡¹å·¥ä½œè¯æ˜äº†Active Readingåœ¨é¢„è®­ç»ƒè§„æ¨¡ä¸‹æ„å»ºé«˜äº‹å®æ€§æ¨¡å‹çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09494v1",
      "published_date": "2025-08-13 04:54:43 UTC",
      "updated_date": "2025-08-13 04:54:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:40:43.398412+00:00"
    },
    {
      "arxiv_id": "2508.09489v1",
      "title": "Large-Small Model Collaborative Framework for Federated Continual Learning",
      "title_zh": "é¢å‘è”é‚¦æŒç»­å­¦ä¹ çš„å¤§å°æ¨¡å‹åä½œæ¡†æ¶",
      "authors": [
        "Hao Yu",
        "Xin Yang",
        "Boyang Fan",
        "Xuemei Cao",
        "Hanlin Gu",
        "Lixin Fan",
        "Qiang Yang"
      ],
      "abstract": "Continual learning (CL) for Foundation Models (FMs) is an essential yet underexplored challenge, especially in Federated Continual Learning (FCL), where each client learns from a private, evolving task stream under strict data and communication constraints. Despite their powerful generalization abilities, FMs often exhibit suboptimal performance on local downstream tasks, as they are unable to utilize private local data. Furthermore, enabling FMs to learn new tasks without forgetting prior knowledge is inherently a challenging problem, primarily due to their immense parameter count and high model complexity. In contrast, small models can be trained locally under resource-constrained conditions and benefit from more mature CL techniques. To bridge the gap between small models and FMs, we propose the first collaborative framework in FCL, where lightweight local models act as a dynamic bridge, continually adapting to new tasks while enhancing the utility of the large model. Two novel components are also included: Small Model Continual Fine-tuning is for preventing small models from temporal forgetting; One-by-One Distillation performs personalized fusion of heterogeneous local knowledge on the server. Experimental results demonstrate its superior performance, even when clients utilize heterogeneous small models.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åŸºç¡€æ¨¡å‹ (Foundation Models, FMs) åœ¨è”é‚¦æŒç»­å­¦ä¹  (Federated Continual Learning, FCL) ä¸­é¢ä¸´çš„æŒ‘æˆ˜ï¼Œå³å¦‚ä½•åœ¨æ•°æ®éšç§å’Œé€šä¿¡é™åˆ¶ä¸‹ï¼Œè®©å‚æ•°å·¨å¤§çš„å¤§æ¨¡å‹åœ¨å­¦ä¹ æ–°ä»»åŠ¡æ—¶é¿å…é—å¿˜å¹¶æœ‰æ•ˆåˆ©ç”¨æœ¬åœ°ç§æœ‰æ•°æ®ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†é¦–ä¸ªå¤§æ¨¡å‹ä¸å°æ¨¡å‹åä½œçš„ FCL æ¡†æ¶ï¼Œåˆ©ç”¨è½»é‡åŒ–æœ¬åœ°æ¨¡å‹ä½œä¸ºåŠ¨æ€æ¡¥æ¢ï¼Œä½¿ç³»ç»Ÿåœ¨æŒç»­é€‚åº”æ–°ä»»åŠ¡çš„åŒæ—¶å¢å¼ºå¤§æ¨¡å‹çš„æ•ˆç”¨ã€‚è¯¥æ¡†æ¶åŒ…å«å°æ¨¡å‹æŒç»­å¾®è°ƒ (Small Model Continual Fine-tuning) å’Œé€ä¸ªè’¸é¦ (One-by-One Distillation) ä¸¤ä¸ªæ ¸å¿ƒç»„ä»¶ï¼Œåˆ†åˆ«ç”¨äºé˜²æ­¢å°æ¨¡å‹çš„æ—¶åºé—å¿˜ä»¥åŠåœ¨æœåŠ¡å™¨ç«¯å®ç°å¼‚æ„æœ¬åœ°çŸ¥è¯†çš„ä¸ªæ€§åŒ–èåˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ¡ˆå…·æœ‰ä¼˜å¼‚çš„æ€§èƒ½è¡¨ç°ï¼Œä¸”åœ¨å®¢æˆ·ç«¯ä½¿ç”¨å¼‚æ„å°æ¨¡å‹çš„æƒ…å†µä¸‹ä»èƒ½ä¿æŒè‰¯å¥½çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09489v1",
      "published_date": "2025-08-13 04:49:50 UTC",
      "updated_date": "2025-08-13 04:49:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:42:02.460144+00:00"
    },
    {
      "arxiv_id": "2508.09486v1",
      "title": "Episodic Memory Representation for Long-form Video Understanding",
      "title_zh": "é¢å‘é•¿è§†é¢‘ç†è§£çš„æƒ…å¢ƒè®°å¿†è¡¨å¾",
      "authors": [
        "Yun Wang",
        "Long Zhang",
        "Jingren Liu",
        "Jiaqi Yan",
        "Zhanjie Zhang",
        "Jiahao Zheng",
        "Xun Yang",
        "Dapeng Wu",
        "Xiangyu Chen",
        "Xuelong Li"
      ],
      "abstract": "Video Large Language Models (Video-LLMs) excel at general video understanding but struggle with long-form videos due to context window limits. Consequently, recent approaches focus on keyframe retrieval, condensing lengthy videos into a small set of informative frames. Despite their practicality, these methods simplify the problem to static text image matching, overlooking spatio temporal relationships crucial for capturing scene transitions and contextual continuity, and may yield redundant keyframes with limited information, diluting salient cues essential for accurate video question answering. To address these limitations, we introduce Video-EM, a training free framework inspired by the principles of human episodic memory, designed to facilitate robust and contextually grounded reasoning. Rather than treating keyframes as isolated visual entities, Video-EM explicitly models them as temporally ordered episodic events, capturing both spatial relationships and temporal dynamics necessary for accurately reconstructing the underlying narrative. Furthermore, the framework leverages chain of thought (CoT) thinking with LLMs to iteratively identify a minimal yet highly informative subset of episodic memories, enabling efficient and accurate question answering by Video-LLMs. Extensive evaluations on the Video-MME, EgoSchema, HourVideo, and LVBench benchmarks confirm the superiority of Video-EM, which achieves highly competitive results with performance gains of 4-9 percent over respective baselines while utilizing fewer frames.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è§†é¢‘å¤§è¯­è¨€æ¨¡å‹ (Video-LLMs) åœ¨å¤„ç†é•¿è§†é¢‘æ—¶ç”±äºä¸Šä¸‹æ–‡é™åˆ¶åŠä¼ ç»Ÿå…³é”®å¸§æ£€ç´¢å¿½ç•¥æ—¶ç©ºå…³ç³»å¯¼è‡´çš„æ€§èƒ½ç“¶é¢ˆï¼Œæå‡ºäº† Video-EM æ¡†æ¶ã€‚è¿™æ˜¯ä¸€ç§å—äººç±»æƒ…å¢ƒè®°å¿† (Episodic Memory) å¯å‘ä¸”æ— éœ€è®­ç»ƒçš„ç³»ç»Ÿï¼Œå®ƒå°†å…³é”®å¸§æ˜¾å¼å»ºæ¨¡ä¸ºæŒ‰æ—¶é—´æ’åºçš„æƒ…å¢ƒäº‹ä»¶ (Episodic Events)ï¼Œä»¥æ•æ‰é‡å»ºå™äº‹æ‰€éœ€çš„ç©ºé—´å…³ç³»å’Œæ—¶é—´åŠ¨æ€ã€‚è¯¥æ¡†æ¶é€šè¿‡ç»“åˆå¤§è¯­è¨€æ¨¡å‹ (LLMs) çš„é“¾å¼æ€ç»´ (Chain-of-Thought, CoT) æ¨ç†ï¼Œèƒ½å¤Ÿè¿­ä»£åœ°ç­›é€‰å‡ºæç®€ä¸”é«˜ä¿¡æ¯é‡çš„æƒ…å¢ƒè®°å¿†å­é›†ï¼Œä»è€Œå®ç°é«˜æ•ˆä¸”å‡†ç¡®çš„é—®ç­”ä»»åŠ¡ã€‚å®éªŒåœ¨ Video-MMEã€EgoSchemaã€HourVideo å’Œ LVBench ç­‰å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­éªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚ç»“æœè¡¨æ˜ Video-EM åœ¨ä½¿ç”¨æ›´å°‘å¸§æ•°çš„æƒ…å†µä¸‹ï¼Œæ¯”åŸºçº¿æ¨¡å‹å‡†ç¡®ç‡æå‡äº† 4% è‡³ 9%ï¼Œå±•ç°äº†æå…·ç«äº‰åŠ›çš„æ€§èƒ½ä¼˜åŠ¿ã€‚è¯¥æ–¹æ³•ä¸ºé•¿è§†é¢‘ç†è§£æä¾›äº†ä¸€ç§ç¨³å¥ä¸”å…·æœ‰ä¸Šä¸‹æ–‡ä¾æ®çš„æ¨ç†æ–°èŒƒå¼ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.09486v1",
      "published_date": "2025-08-13 04:33:07 UTC",
      "updated_date": "2025-08-13 04:33:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:42:00.856437+00:00"
    },
    {
      "arxiv_id": "2508.09473v1",
      "title": "NeuronTune: Fine-Grained Neuron Modulation for Balanced Safety-Utility Alignment in LLMs",
      "title_zh": "NeuronTuneï¼šå¤§è¯­è¨€æ¨¡å‹ä¸­å®ç°å®‰å…¨ä¸æ•ˆèƒ½å¹³è¡¡å¯¹é½çš„ç»†ç²’åº¦ç¥ç»å…ƒè°ƒåˆ¶",
      "authors": [
        "Birong Pan",
        "Mayi Xu",
        "Qiankun Pi",
        "Jianhao Chen",
        "Yuanyuan Zhu",
        "Ming Zhong",
        "Tieyun Qian"
      ],
      "abstract": "Ensuring robust safety alignment while preserving utility is critical for the reliable deployment of Large Language Models (LLMs). However, current techniques fundamentally suffer from intertwined deficiencies: insufficient robustness against malicious attacks, frequent refusal of benign queries, degradation in generated text quality and general task performance--the former two reflecting deficits in robust safety and the latter constituting utility impairment. We trace these limitations to the coarse-grained layer-wise interventions in existing methods. To resolve this, we propose NeuronTune, a fine-grained framework that dynamically modulates sparse neurons to achieve simultaneous safety-utility optimization. Our approach first identifies safety-critical and utility-preserving neurons across all layers via attribution, then employs meta-learning to adaptively amplify safety-neuron activations and suppress utility-neuron activations. Crucially, NeuronTune enables tunable adjustment of intervention scope via neuron-count thresholds, supporting flexible adaptation to security-critical or utility-priority scenarios. Extensive experimental results demonstrate that our method significantly outperforms existing state-of-the-art technologies, achieving superior model safety while maintaining excellent utility.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æå‡ºäº† NeuronTuneï¼Œä¸€ç§æ—¨åœ¨å¹³è¡¡å¤§è¯­è¨€æ¨¡å‹ (LLMs) å®‰å…¨å¯¹é½ä¸å®ç”¨æ€§çš„ç»†ç²’åº¦æ¡†æ¶ï¼Œä»¥è§£å†³ç°æœ‰æ–¹æ³•å› ç²—ç²’åº¦å±‚çº§å¹²é¢„è€Œå¯¼è‡´çš„å®‰å…¨æ€§ä¸è¶³åŠæ€§èƒ½ä¸‹é™é—®é¢˜ã€‚è¯¥æ–¹æ³•é¦–å…ˆé€šè¿‡å½’å› åˆ†æè¯†åˆ«åˆ†å¸ƒåœ¨å„å±‚ä¸­çš„å®‰å…¨å…³é”®å‹ (safety-critical) å’Œå®ç”¨æ€§ä¿ç•™å‹ (utility-preserving) ç¥ç»å…ƒã€‚éšåï¼ŒNeuronTune åˆ©ç”¨å…ƒå­¦ä¹  (meta-learning) åŠ¨æ€è°ƒåˆ¶è¿™äº›ç¥ç»å…ƒçš„æ¿€æ´»çŠ¶æ€ï¼Œé€šè¿‡æ”¾å¤§å®‰å…¨ç¥ç»å…ƒå¹¶æŠ‘åˆ¶å®ç”¨ç¥ç»å…ƒæ¿€æ´»æ¥å®ç°äºŒè€…çš„åŒæ­¥ä¼˜åŒ–ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶æ”¯æŒé€šè¿‡ç¥ç»å…ƒè®¡æ•°é˜ˆå€¼çµæ´»è°ƒæ•´å¹²é¢„èŒƒå›´ï¼Œä½¿å…¶èƒ½å¤Ÿé€‚åº”ä»å®‰å…¨æ€§ä¼˜å…ˆåˆ°å®ç”¨æ€§ä¼˜å…ˆçš„å„ç§åº”ç”¨åœºæ™¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒNeuronTune åœ¨æ˜¾è‘—æå‡æ¨¡å‹æŠµå¾¡æ¶æ„æ”»å‡»èƒ½åŠ›çš„åŒæ—¶ä¼˜åŒ–äº†è‰¯æ€§æŸ¥è¯¢çš„å“åº”è´¨é‡ï¼Œåœ¨æ€§èƒ½è¡¨ç°ä¸Šå…¨é¢è¶…è¶Šäº†ç°æœ‰çš„æœ€å…ˆè¿›æŠ€æœ¯ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09473v1",
      "published_date": "2025-08-13 04:05:28 UTC",
      "updated_date": "2025-08-13 04:05:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:42:30.291807+00:00"
    },
    {
      "arxiv_id": "2508.09468v1",
      "title": "DeepFeatIoT: Unifying Deep Learned, Randomized, and LLM Features for Enhanced IoT Time Series Sensor Data Classification in Smart Industries",
      "title_zh": "DeepFeatIoTï¼šèåˆæ·±åº¦å­¦ä¹ ã€éšæœºåŒ–ä¸å¤§è¯­è¨€æ¨¡å‹ç‰¹å¾ï¼Œå¢å¼ºæ™ºèƒ½å·¥ä¸šç‰©è”ç½‘æ—¶é—´åºåˆ—ä¼ æ„Ÿå™¨æ•°æ®åˆ†ç±»",
      "authors": [
        "Muhammad Sakib Khan Inan",
        "Kewen Liao"
      ],
      "abstract": "Internet of Things (IoT) sensors are ubiquitous technologies deployed across smart cities, industrial sites, and healthcare systems. They continuously generate time series data that enable advanced analytics and automation in industries. However, challenges such as the loss or ambiguity of sensor metadata, heterogeneity in data sources, varying sampling frequencies, inconsistent units of measurement, and irregular timestamps make raw IoT time series data difficult to interpret, undermining the effectiveness of smart systems. To address these challenges, we propose a novel deep learning model, DeepFeatIoT, which integrates learned local and global features with non-learned randomized convolutional kernel-based features and features from large language models (LLMs). This straightforward yet unique fusion of diverse learned and non-learned features significantly enhances IoT time series sensor data classification, even in scenarios with limited labeled data. Our model's effectiveness is demonstrated through its consistent and generalized performance across multiple real-world IoT sensor datasets from diverse critical application domains, outperforming state-of-the-art benchmark models. These results highlight DeepFeatIoT's potential to drive significant advancements in IoT analytics and support the development of next-generation smart systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ™ºæ…§åŸå¸‚å’Œå·¥ä¸šé¢†åŸŸä¸­ç‰©è”ç½‘(IoT)ä¼ æ„Ÿå™¨æ•°æ®å­˜åœ¨çš„å…ƒæ•°æ®ç¼ºå¤±ã€å¼‚æ„æ€§åŠé‡‡æ ·é¢‘ç‡ä¸ä¸€ç­‰è§£é‡Šéš¾é¢˜ï¼Œæå‡ºäº†åä¸ºDeepFeatIoTçš„æ–°å‹æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚è¯¥æ¨¡å‹é€šè¿‡ä¸€ç§ç‹¬ç‰¹çš„æ–¹æ³•ï¼Œå°†å­¦ä¹ åˆ°çš„å±€éƒ¨ä¸å…¨å±€ç‰¹å¾(learned local and global features)ä¸éå­¦ä¹ çš„éšæœºå·ç§¯æ ¸ç‰¹å¾(non-learned randomized convolutional kernel-based features)ä»¥åŠå¤§è¯­è¨€æ¨¡å‹(LLMs)ç‰¹å¾è¿›è¡Œç»Ÿä¸€èåˆã€‚è¿™ç§å¤šæ ·åŒ–ç‰¹å¾çš„æ•´åˆæ˜¾è‘—æå‡äº†ç‰©è”ç½‘æ—¶é—´åºåˆ—ä¼ æ„Ÿå™¨æ•°æ®çš„åˆ†ç±»å‡†ç¡®ç‡ï¼Œå°¤å…¶åœ¨æ ‡æ³¨æ•°æ®æœ‰é™çš„åœºæ™¯ä¸‹è¡¨ç°ä¼˜å¼‚ã€‚å®éªŒè¯æ˜ï¼ŒDeepFeatIoTåœ¨å¤šä¸ªçœŸå®ä¸–ç•Œçš„å…³é”®é¢†åŸŸæ•°æ®é›†ä¸Šå‡å–å¾—äº†ç¨³å®šä¸”æ³›åŒ–çš„æ€§èƒ½ï¼Œå…¶è¡¨ç°ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›åŸºå‡†æ¨¡å‹(state-of-the-art benchmark models)ã€‚è¯¥æˆæœä¸ºç‰©è”ç½‘åˆ†ææŠ€æœ¯çš„è¿›æ­¥å’Œä¸‹ä¸€ä»£æ™ºèƒ½ç³»ç»Ÿçš„å¼€å‘æä¾›äº†å¼ºæœ‰åŠ›çš„æ”¯æŒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted for publication at IJCAI 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.09468v1",
      "published_date": "2025-08-13 03:47:33 UTC",
      "updated_date": "2025-08-13 03:47:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:42:07.659425+00:00"
    },
    {
      "arxiv_id": "2508.09461v1",
      "title": "Gen-AFFECT: Generation of Avatar Fine-grained Facial Expressions with Consistent identiTy",
      "title_zh": "Gen-AFFECTï¼šä¿æŒèº«ä»½ä¸€è‡´æ€§çš„è™šæ‹Ÿå½¢è±¡ç»†ç²’åº¦é¢éƒ¨è¡¨æƒ…ç”Ÿæˆ",
      "authors": [
        "Hao Yu",
        "Rupayan Mallick",
        "Margrit Betke",
        "Sarah Adel Bargal"
      ],
      "abstract": "Different forms of customized 2D avatars are widely used in gaming applications, virtual communication, education, and content creation. However, existing approaches often fail to capture fine-grained facial expressions and struggle to preserve identity across different expressions. We propose GEN-AFFECT, a novel framework for personalized avatar generation that generates expressive and identity-consistent avatars with a diverse set of facial expressions. Our framework proposes conditioning a multimodal diffusion transformer on an extracted identity-expression representation. This enables identity preservation and representation of a wide range of facial expressions. GEN-AFFECT additionally employs consistent attention at inference for information sharing across the set of generated expressions, enabling the generation process to maintain identity consistency over the array of generated fine-grained expressions. GEN-AFFECT demonstrates superior performance compared to previous state-of-the-art methods on the basis of the accuracy of the generated expressions, the preservation of the identity and the consistency of the target identity across an array of fine-grained facial expressions.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† GEN-AFFECTï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨ç”Ÿæˆå…·æœ‰ç²¾ç»†é¢éƒ¨è¡¨æƒ…ä¸”ä¿æŒèº«ä»½ä¸€è‡´æ€§çš„ä¸ªæ€§åŒ–æ•°å­—äºº(Avatar)ç”Ÿæˆæ¡†æ¶ã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•åœ¨æ•æ‰ç»†å¾®è¡¨æƒ…å’Œç»´æŒèº«ä»½ç¨³å®šæ€§æ–¹é¢çš„ä¸è¶³ï¼Œè¯¥æ¡†æ¶å°†å¤šæ¨¡æ€æ‰©æ•£å˜æ¢å™¨(Multimodal Diffusion Transformer)è°ƒèŠ‚åœ¨æå–çš„èº«ä»½-è¡¨æƒ…ç‰¹å¾è¡¨ç¤ºä¸Šï¼Œä»è€Œå®ç°äº†å¯¹å¹¿æ³›é¢éƒ¨è¡¨æƒ…çš„ç²¾å‡†è¡¨è¾¾ã€‚æ­¤å¤–ï¼ŒGEN-AFFECT åœ¨æ¨ç†é˜¶æ®µå¼•å…¥äº†ä¸€è‡´æ€§æ³¨æ„åŠ›(Consistent Attention)æœºåˆ¶ï¼Œé€šè¿‡åœ¨ç”Ÿæˆçš„è¡¨æƒ…é›†åˆé—´è¿›è¡Œä¿¡æ¯å…±äº«ï¼Œç¡®ä¿äº†åœ¨å¤„ç†å„ç±»ç²¾ç»†è¡¨æƒ…æ—¶èº«ä»½ç‰¹å¾çš„è·¨åºåˆ—ä¸€è‡´ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒGEN-AFFECT åœ¨è¡¨æƒ…ç”Ÿæˆå‡†ç¡®åº¦ã€èº«ä»½ä¿ç•™ä»¥åŠè·¨ç²¾ç»†è¡¨æƒ…çš„èº«ä»½ä¸€è‡´æ€§ä¸Šå‡è¡¨ç°ä¼˜å¼‚ï¼Œæ˜¾è‘—è¶…è¶Šäº†ç°æœ‰çš„æœ€å…ˆè¿›(State-of-the-Art)æ–¹æ³•ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09461v1",
      "published_date": "2025-08-13 03:35:35 UTC",
      "updated_date": "2025-08-13 03:35:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:42:04.757134+00:00"
    },
    {
      "arxiv_id": "2508.09459v2",
      "title": "RelayFormer: A Unified Local-Global Attention Framework for Scalable Image and Video Manipulation Localization",
      "title_zh": "RelayFormerï¼šé¢å‘å¯æ‰©å±•å›¾åƒä¸è§†é¢‘ç¯¡æ”¹å®šä½çš„ç»Ÿä¸€å±€éƒ¨-å…¨å±€æ³¨æ„åŠ›æ¡†æ¶",
      "authors": [
        "Wen Huang",
        "Jiarui Yang",
        "Tao Dai",
        "Jiawei Li",
        "Shaoxiong Zhan",
        "Bin Wang",
        "Shu-Tao Xia"
      ],
      "abstract": "Visual manipulation localization (VML) aims to identify tampered regions in images and videos, a task that has become increasingly challenging with the rise of advanced editing tools. Existing methods face two main issues: resolution diversity, where resizing or padding distorts forensic traces and reduces efficiency, and the modality gap, as images and videos often require separate models. To address these challenges, we propose RelayFormer, a unified framework that adapts to varying resolutions and modalities. RelayFormer partitions inputs into fixed-size sub-images and introduces Global-Local Relay (GLR) tokens, which propagate structured context through a global-local relay attention (GLRA) mechanism. This enables efficient exchange of global cues, such as semantic or temporal consistency, while preserving fine-grained manipulation artifacts. Unlike prior methods that rely on uniform resizing or sparse attention, RelayFormer naturally scales to arbitrary resolutions and video sequences without excessive overhead. Experiments across diverse benchmarks demonstrate that RelayFormer achieves state-of-the-art performance with notable efficiency, combining resolution adaptivity without interpolation or excessive padding, unified modeling for both images and videos, and a strong balance between accuracy and computational cost. Code is available at: https://github.com/WenOOI/RelayFormer.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† RelayFormerï¼Œè¿™æ˜¯ä¸€ä¸ªç»Ÿä¸€çš„ Local-Global Attention æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å›¾åƒå’Œè§†é¢‘ç¯¡æ”¹å®šä½ (Visual manipulation localization, VML) ä¸­é¢ä¸´çš„åˆ†è¾¨ç‡å¤šæ ·æ€§å’Œæ¨¡æ€å·®å¼‚ç­‰æŒ‘æˆ˜ã€‚RelayFormer é€šè¿‡å°†è¾“å…¥åˆ’åˆ†ä¸ºå›ºå®šå¤§å°çš„å­å›¾åƒï¼Œå¹¶å¼•å…¥å…¨å±€-å±€éƒ¨ä¸­ç»§ (Global-Local Relay, GLR) Tokenï¼Œåˆ©ç”¨å…¨å±€-å±€éƒ¨ä¸­ç»§æ³¨æ„åŠ› (global-local relay attention, GLRA) æœºåˆ¶ä¼ æ’­ç»“æ„åŒ–ä¸Šä¸‹æ–‡ã€‚è¿™ç§è®¾è®¡ä¸ä»…èƒ½æœ‰æ•ˆäº¤æ¢å…¨å±€è¯­ä¹‰æˆ–æ—¶é—´ä¸€è‡´æ€§ç­‰çº¿ç´¢ï¼Œè¿˜èƒ½ç²¾å‡†ä¿ç•™ç»†ç²’åº¦çš„ç¯¡æ”¹ç—•è¿¹ (manipulation artifacts)ã€‚ä¸ä¾èµ–ç¼©æ”¾æˆ–ç¨€ç–æ³¨æ„åŠ›çš„ä¼ ç»Ÿæ–¹æ³•ä¸åŒï¼ŒRelayFormer æ— éœ€æ’å€¼æˆ–è¿‡åº¦å¡«å……å³å¯è‡ªç„¶æ‰©å±•è‡³ä»»æ„åˆ†è¾¨ç‡å’Œè§†é¢‘åºåˆ—ã€‚å¤šé¡¹å®éªŒè¯æ˜ï¼ŒRelayFormer åœ¨ç²¾åº¦å’Œè®¡ç®—æ•ˆç‡ä¹‹é—´å®ç°äº†æä½³å¹³è¡¡ï¼Œåœ¨å›¾åƒå’Œè§†é¢‘çš„ç»Ÿä¸€ç¯¡æ”¹å®šä½ä»»åŠ¡ä¸­å‡è¾¾åˆ°äº† SOTA æ€§èƒ½ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09459v2",
      "published_date": "2025-08-13 03:35:28 UTC",
      "updated_date": "2025-10-03 14:55:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:42:29.153241+00:00"
    },
    {
      "arxiv_id": "2508.09458v2",
      "title": "Hallucination vs interpretation: rethinking accuracy and precision in AI-assisted data extraction for knowledge synthesis",
      "title_zh": "å¹»è§‰ä¸è§£è¯»ï¼šé‡æ–°å®¡è§†çŸ¥è¯†ç»¼åˆä¸­äººå·¥æ™ºèƒ½è¾…åŠ©æ•°æ®æå–çš„å‡†ç¡®æ€§ä¸ç²¾ç¡®æ€§",
      "authors": [
        "Xi Long",
        "Christy Boscardin",
        "Lauren A. Maggio",
        "Joseph A. Costello",
        "Ralph Gonzales",
        "Rasmyah Hammoudeh",
        "Ki Lai",
        "Yoon Soo Park",
        "Brian C. Gin"
      ],
      "abstract": "Knowledge syntheses (literature reviews) are essential to health professions education (HPE), consolidating findings to advance theory and practice. However, they are labor-intensive, especially during data extraction. Artificial Intelligence (AI)-assisted extraction promises efficiency but raises concerns about accuracy, making it critical to distinguish AI 'hallucinations' (fabricated content) from legitimate interpretive differences. We developed an extraction platform using large language models (LLMs) to automate data extraction and compared AI to human responses across 187 publications and 17 extraction questions from a published scoping review. AI-human, human-human, and AI-AI consistencies were measured using interrater reliability (categorical) and thematic similarity ratings (open-ended). Errors were identified by comparing extracted responses to source publications. AI was highly consistent with humans for concrete, explicitly stated questions (e.g., title, aims) and lower for questions requiring subjective interpretation or absent in text (e.g., Kirkpatrick's outcomes, study rationale). Human-human consistency was not higher than AI-human and showed the same question-dependent variability. Discordant AI-human responses (769/3179 = 24.2%) were mostly due to interpretive differences (18.3%); AI inaccuracies were rare (1.51%), while humans were nearly three times more likely to state inaccuracies (4.37%). Findings suggest AI variability depends more on interpretability than hallucination. Repeating AI extraction can identify interpretive complexity or ambiguity, refining processes before human review. AI can be a transparent, trustworthy partner in knowledge synthesis, though caution is needed to preserve critical human insights.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†äººå·¥æ™ºèƒ½(AI)è¾…åŠ©æ•°æ®æå–åœ¨çŸ¥è¯†åˆæˆ(Knowledge Synthesis)ä¸­çš„å‡†ç¡®æ€§å’Œç²¾ç¡®æ€§ï¼Œé‡ç‚¹åŒºåˆ†äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)äº§ç”Ÿçš„â€œå¹»è§‰â€(Hallucination)ä¸åˆç†çš„è§£é‡Šæ€§å·®å¼‚ã€‚ç ”ç©¶äººå‘˜é€šè¿‡å¼€å‘è‡ªåŠ¨åŒ–æå–å¹³å°ï¼Œåœ¨187ç¯‡å‡ºç‰ˆç‰©ä¸Šå¯¹æ¯”äº†AIä¸äººç±»çš„æå–è¡¨ç°ï¼Œå¹¶åˆ©ç”¨è¯„åˆ†è€…é—´ä¿¡åº¦(Interrater Reliability)å’Œä¸»é¢˜ç›¸ä¼¼æ€§è¡¡é‡ä¸€è‡´æ€§ã€‚ç»“æœæ˜¾ç¤ºï¼ŒAIåœ¨å¤„ç†äº‹å®æ€§é—®é¢˜æ—¶ä¸äººç±»é«˜åº¦ä¸€è‡´ï¼Œè€Œåœ¨éœ€è¦ä¸»è§‚è§£é‡Šçš„ä»»åŠ¡ä¸­ä¸€è‡´æ€§è¾ƒä½ã€‚å…³é”®å‘ç°æŒ‡å‡ºï¼ŒAIä¸äººç±»çš„ä¸ä¸€è‡´ä¸»è¦æºäºè§£é‡Šæ€§å·®å¼‚(18.3%)ï¼Œå…¶äº§ç”Ÿå¹»è§‰çš„æ¦‚ç‡ä»…ä¸º1.51%ï¼Œæ˜¾è‘—ä½äºäººç±»4.37%çš„é”™è¯¯ç‡ã€‚è¿™è¡¨æ˜AIæå–çš„å˜å¼‚æ€§æ›´å¤šå–å†³äºå†…å®¹çš„å¯è§£é‡Šæ€§è€Œéè™šå‡ä¿¡æ¯çš„ç”Ÿæˆï¼Œé€šè¿‡é‡å¤æå–å¯ä»¥å¸®åŠ©è¯†åˆ«æ–‡æœ¬ä¸­çš„æ­§ä¹‰ã€‚è¯¥ç ”ç©¶è¯æ˜AIæ˜¯çŸ¥è¯†åˆæˆè¿‡ç¨‹ä¸­é€æ˜ä¸”å€¼å¾—ä¿¡èµ–çš„åˆä½œä¼™ä¼´ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡æ•°æ®æå–çš„æ•ˆç‡ï¼Œä½†åœ¨åº”ç”¨ä¸­ä»éœ€æ³¨æ„ä¿ç•™äººç±»çš„å…³é”®æ´å¯ŸåŠ›ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09458v2",
      "published_date": "2025-08-13 03:33:30 UTC",
      "updated_date": "2025-08-14 03:36:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:42:29.349806+00:00"
    },
    {
      "arxiv_id": "2508.14083v2",
      "title": "GeoMAE: Masking Representation Learning for Spatio-Temporal Graph Forecasting with Missing Values",
      "title_zh": "GeoMAEï¼šé¢å‘ç¼ºå¤±å€¼æ—¶ç©ºå›¾é¢„æµ‹çš„æ©ç è¡¨ç¤ºå­¦ä¹ ",
      "authors": [
        "Songyu Ke",
        "Chenyu Wu",
        "Yuxuan Liang",
        "Huiling Qin",
        "Junbo Zhang",
        "Yu Zheng"
      ],
      "abstract": "The ubiquity of missing data in urban intelligence systems, attributable to adverse environmental conditions and equipment failures, poses a significant challenge to the efficacy of downstream applications, notably in the realms of traffic forecasting and energy consumption prediction.\n  Therefore, it is imperative to develop a robust spatio-temporal learning methodology capable of extracting meaningful insights from incomplete datasets. Despite the existence of methodologies for spatio-temporal graph forecasting in the presence of missing values, unresolved issues persist.\n  Primarily, the majority of extant research is predicated on time-series analysis, thereby neglecting the dynamic spatial correlations inherent in sensor networks.\n  Additionally, the complexity of missing data patterns compounds the intricacy of the problem.\n  Furthermore, the variability in maintenance conditions results in a significant fluctuation in the ratio and pattern of missing values, thereby challenging the generalizability of predictive models.\n  In response to these challenges, this study introduces GeoMAE, a self-supervised spatio-temporal representation learning model.\n  The model is comprised of three principal components: an input preprocessing module, an attention-based spatio-temporal forecasting network (STAFN), and an auxiliary learning task, which draws inspiration from Masking AutoEncoders to enhance the robustness of spatio-temporal representation learning.\n  Empirical evaluations on real-world datasets demonstrate that GeoMAE significantly outperforms existing benchmarks, achieving up to 13.20\\% relative improvement over the best baseline models.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸå¸‚æ™ºèƒ½ç³»ç»Ÿä¸­æ™®éå­˜åœ¨çš„æ•°æ®ç¼ºå¤±é—®é¢˜ï¼Œæå‡ºäº†GeoMAEï¼Œä¸€ç§è‡ªç›‘ç£çš„æ—¶ç©ºè¡¨ç¤ºå­¦ä¹ æ¨¡å‹ï¼Œæ—¨åœ¨æå‡æ—¶ç©ºå›¾é¢„æµ‹(Spatio-Temporal Graph Forecasting)åœ¨ä¸å®Œæ•´æ•°æ®é›†ä¸‹çš„è¡¨ç°ã€‚ç°æœ‰çš„ç ”ç©¶å¤šä¾èµ–æ—¶é—´åºåˆ—åˆ†æï¼Œå¾€å¾€å¿½è§†äº†ä¼ æ„Ÿå™¨ç½‘ç»œä¸­åŠ¨æ€çš„ç©ºé—´ç›¸å…³æ€§ï¼Œä¸”éš¾ä»¥åº”å¯¹å¤æ‚å¤šå˜çš„ç¼ºå¤±æ¨¡å¼å¯¹æ¨¡å‹æ³›åŒ–æ€§å¸¦æ¥çš„æŒ‘æˆ˜ã€‚GeoMAEç”±è¾“å…¥é¢„å¤„ç†æ¨¡å—ã€åŸºäºæ³¨æ„åŠ›æœºåˆ¶çš„æ—¶ç©ºé¢„æµ‹ç½‘ç»œ(STAFN)ä»¥åŠå—æ©ç è‡ªç¼–ç å™¨(Masking AutoEncoders)å¯å‘çš„è¾…åŠ©å­¦ä¹ ä»»åŠ¡ç»„æˆã€‚é€šè¿‡å¼•å…¥æ©ç å­¦ä¹ æœºåˆ¶ï¼Œè¯¥æ¨¡å‹æ˜¾è‘—å¢å¼ºäº†æ—¶ç©ºè¡¨ç¤ºå­¦ä¹ çš„é²æ£’æ€§ï¼Œèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°ä»ä¸å®Œæ•´æ•°æ®ä¸­æå–å…³é”®ç‰¹å¾ã€‚åœ¨çœŸå®æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒGeoMAEçš„æ€§èƒ½ä¼˜äºç°æœ‰åŸºå‡†æ¨¡å‹ï¼Œç›¸æ¯”è¡¨ç°æœ€å¥½çš„åŸºçº¿æ¨¡å‹å®ç°äº†é«˜è¾¾13.20%çš„ç›¸å¯¹æå‡ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "34 pages",
      "pdf_url": "https://arxiv.org/pdf/2508.14083v2",
      "published_date": "2025-08-13 03:30:45 UTC",
      "updated_date": "2025-12-02 12:23:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:42:55.999291+00:00"
    },
    {
      "arxiv_id": "2508.09451v1",
      "title": "A Unified Contrastive-Generative Framework for Time Series Classification",
      "title_zh": "æ—¶é—´åºåˆ—åˆ†ç±»çš„ç»Ÿä¸€å¯¹æ¯”ç”Ÿæˆæ¡†æ¶",
      "authors": [
        "Ziyu Liu",
        "Azadeh Alavi",
        "Minyi Li",
        "Xiang Zhang"
      ],
      "abstract": "Self-supervised learning (SSL) for multivariate time series mainly includes two paradigms: contrastive methods that excel at instance discrimination and generative approaches that model data distributions. While effective individually, their complementary potential remains unexplored. We propose a Contrastive Generative Time series framework (CoGenT), the first framework to unify these paradigms through joint contrastive-generative optimization. CoGenT addresses fundamental limitations of both approaches: it overcomes contrastive learning's sensitivity to high intra-class similarity in temporal data while reducing generative methods' dependence on large datasets. We evaluate CoGenT on six diverse time series datasets. The results show consistent improvements, with up to 59.2% and 14.27% F1 gains over standalone SimCLR and MAE, respectively. Our analysis reveals that the hybrid objective preserves discriminative power while acquiring generative robustness. These findings establish a foundation for hybrid SSL in temporal domains. We will release the code shortly.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†CoGenTï¼ˆContrastive Generative Time series frameworkï¼‰ï¼Œè¿™æ˜¯é¦–ä¸ªé€šè¿‡è”åˆå¯¹æ¯”-ç”Ÿæˆä¼˜åŒ–ï¼ˆjoint contrastive-generative optimizationï¼‰å°†å¯¹æ¯”å­¦ä¹ ä¸ç”Ÿæˆå¼æ–¹æ³•ç»Ÿä¸€èµ·æ¥çš„å¤šå…ƒæ—¶é—´åºåˆ—è‡ªç›‘ç£å­¦ä¹ ï¼ˆSSLï¼‰æ¡†æ¶ã€‚è¯¥æ¡†æ¶è§£å†³äº†å¯¹æ¯”å­¦ä¹ åœ¨å¤„ç†é«˜ç±»å†…ç›¸ä¼¼æ€§æ—¶é—´æ•°æ®æ—¶çš„æ•æ„Ÿæ€§é—®é¢˜ï¼ŒåŒæ—¶é™ä½äº†ç”Ÿæˆå¼æ–¹æ³•å¯¹å¤§è§„æ¨¡æ•°æ®é›†çš„ä¾èµ–ã€‚é€šè¿‡å‘æŒ¥ä¸¤ç§èŒƒå¼çš„äº’è¡¥æ½œåŠ›ï¼ŒCoGenTä½¿æ¨¡å‹åœ¨ä¿ç•™åˆ¤åˆ«èƒ½åŠ›çš„åŒæ—¶è·å¾—äº†ç”Ÿæˆç¨³å¥æ€§ã€‚åœ¨å…­ä¸ªå¤šæ ·åŒ–æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ç›¸æ¯”äºç‹¬ç«‹çš„SimCLRå’ŒMAEï¼Œåœ¨F1åˆ†æ•°ä¸Šåˆ†åˆ«å®ç°äº†é«˜è¾¾59.2%å’Œ14.27%çš„æå‡ã€‚è¿™äº›å‘ç°ä¸ºæ—¶é—´åºåˆ—é¢†åŸŸçš„æ··åˆè‡ªç›‘ç£å­¦ä¹ å¥ å®šäº†åŸºç¡€ï¼Œå¹¶è¯æ˜äº†ç»Ÿä¸€æ¡†æ¶åœ¨æå‡åˆ†ç±»æ€§èƒ½æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09451v1",
      "published_date": "2025-08-13 03:09:14 UTC",
      "updated_date": "2025-08-13 03:09:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:42:24.896185+00:00"
    },
    {
      "arxiv_id": "2508.09442v3",
      "title": "Shadow in the Cache: Unveiling and Mitigating Privacy Risks of KV-cache in LLM Inference",
      "title_zh": "ç¼“å­˜ä¹‹å½±ï¼šæ­ç¤ºå¹¶ç¼“è§£å¤§è¯­è¨€æ¨¡å‹æ¨ç†ä¸­ KV ç¼“å­˜çš„éšç§é£é™©",
      "authors": [
        "Zhifan Luo",
        "Shuo Shao",
        "Su Zhang",
        "Lijing Zhou",
        "Yuke Hu",
        "Chenxu Zhao",
        "Zhihao Liu",
        "Zhan Qin"
      ],
      "abstract": "The Key-Value (KV) cache, which stores intermediate attention computations (Key and Value pairs) to avoid redundant calculations, is a fundamental mechanism for accelerating Large Language Model (LLM) inference. However, this efficiency optimization introduces significant yet underexplored privacy risks. This paper provides the first comprehensive analysis of these vulnerabilities, demonstrating that an attacker can reconstruct sensitive user inputs directly from the KV-cache. We design and implement three distinct attack vectors: a direct Inversion Attack, a more broadly applicable and potent Collision Attack, and a semantic-based Injection Attack. These methods demonstrate the practicality and severity of KV-cache privacy leakage issues. To mitigate this, we propose KV-Cloak, a novel, lightweight, and efficient defense mechanism. KV-Cloak uses a reversible matrix-based obfuscation scheme, combined with operator fusion, to secure the KV-cache. Our extensive experiments show that KV-Cloak effectively thwarts all proposed attacks, reducing reconstruction quality to random noise. Crucially, it achieves this robust security with virtually no degradation in model accuracy and minimal performance overhead, offering a practical solution for trustworthy LLM deployment.",
      "tldr_zh": "è¯¥ç ”ç©¶æ­ç¤ºäº†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¨ç†åŠ é€Ÿæœºåˆ¶ä¸­ KV-cache æ‰€å¸¦æ¥çš„ä¸¥é‡éšç§é£é™©ï¼Œé¦–æ¬¡å…¨é¢åˆ†æäº†æ”»å‡»è€…å¦‚ä½•åˆ©ç”¨è¯¥æœºåˆ¶é‡æ„æ•æ„Ÿçš„ç”¨æˆ·è¾“å…¥ã€‚ä½œè€…è®¾è®¡å¹¶å®ç°äº† Inversion Attackã€Collision Attack å’Œè¯­ä¹‰åŒ–çš„ Injection Attack ä¸‰ç§æ”»å‡»å‘é‡ï¼ŒéªŒè¯äº† KV-cache éšç§æ³„éœ²çš„å®é™…å±å®³ã€‚ä¸ºåº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œç ”ç©¶å›¢é˜Ÿæå‡ºäº† KV-Cloakï¼Œè¿™æ˜¯ä¸€ç§åŸºäºå¯é€†çŸ©é˜µæ··æ·†æ–¹æ¡ˆï¼ˆmatrix-based obfuscation schemeï¼‰å¹¶ç»“åˆç®—å­èåˆï¼ˆoperator fusionï¼‰çš„æ–°å‹è½»é‡åŒ–é˜²å¾¡æœºåˆ¶ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒKV-Cloak èƒ½å¤Ÿæœ‰æ•ˆæŠµå¾¡ä¸Šè¿°æ‰€æœ‰æ”»å‡»ï¼Œå°†æ”»å‡»è€…çš„é‡æ„è´¨é‡é™è‡³éšæœºå™ªå£°æ°´å¹³ã€‚è¯¥æ–¹æ¡ˆåœ¨æä¾›é²æ£’å®‰å…¨æ€§çš„åŒæ—¶ï¼Œå‡ ä¹ä¸ä¼šå¯¼è‡´æ¨¡å‹å‡†ç¡®ç‡ä¸‹é™ï¼Œä¸”æ€§èƒ½å¼€é”€æä½ï¼Œä¸ºå¯ä¿¡ LLM çš„éƒ¨ç½²æä¾›äº†åˆ‡å®å¯è¡Œçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "This paper is accepted by Network and Distributed System Security Symposium (NDSS) 2026",
      "pdf_url": "https://arxiv.org/pdf/2508.09442v3",
      "published_date": "2025-08-13 02:48:25 UTC",
      "updated_date": "2025-12-08 02:23:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:42:49.495378+00:00"
    },
    {
      "arxiv_id": "2508.09428v1",
      "title": "What-Meets-Where: Unified Learning of Action and Contact Localization in a New Dataset",
      "title_zh": "What-Meets-Whereï¼šæ–°æ•°æ®é›†ä¸­åŠ¨ä½œä¸æ¥è§¦å®šä½çš„ç»Ÿä¸€å­¦ä¹ ",
      "authors": [
        "Yuxiao Wang",
        "Yu Lei",
        "Wolin Liang",
        "Weiying Xue",
        "Zhenao Wei",
        "Nan Zhuang",
        "Qi Liu"
      ],
      "abstract": "People control their bodies to establish contact with the environment. To comprehensively understand actions across diverse visual contexts, it is essential to simultaneously consider \\textbf{what} action is occurring and \\textbf{where} it is happening. Current methodologies, however, often inadequately capture this duality, typically failing to jointly model both action semantics and their spatial contextualization within scenes. To bridge this gap, we introduce a novel vision task that simultaneously predicts high-level action semantics and fine-grained body-part contact regions. Our proposed framework, PaIR-Net, comprises three key components: the Contact Prior Aware Module (CPAM) for identifying contact-relevant body parts, the Prior-Guided Concat Segmenter (PGCS) for pixel-wise contact segmentation, and the Interaction Inference Module (IIM) responsible for integrating global interaction relationships. To facilitate this task, we present PaIR (Part-aware Interaction Representation), a comprehensive dataset containing 13,979 images that encompass 654 actions, 80 object categories, and 17 body parts. Experimental evaluation demonstrates that PaIR-Net significantly outperforms baseline approaches, while ablation studies confirm the efficacy of each architectural component. The code and dataset will be released upon publication.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªå…¨æ–°çš„è§†è§‰ä»»åŠ¡ï¼Œæ—¨åœ¨åŒæ—¶é¢„æµ‹é«˜å±‚åŠ¨ä½œè¯­ä¹‰ï¼ˆAction Semanticsï¼‰å’Œç»†ç²’åº¦çš„èº«ä½“éƒ¨ä½æ¥è§¦åŒºåŸŸï¼Œä»¥å¼¥è¡¥ç°æœ‰æ–¹æ³•åœ¨å»ºæ¨¡åŠ¨ä½œè¯­ä¹‰ä¸åœºæ™¯ç©ºé—´ä¸Šä¸‹æ–‡å…³è”æ–¹é¢çš„ä¸è¶³ã€‚ä¸ºæ­¤ï¼Œä½œè€…å¼€å‘äº† PaIR-Net æ¡†æ¶ï¼Œè¯¥æ¡†æ¶åŒ…å« Contact Prior Aware Module (CPAM)ã€Prior-Guided Concat Segmenter (PGCS) å’Œ Interaction Inference Module (IIM) ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶ï¼Œç”¨äºè¯†åˆ«æ¥è§¦éƒ¨ä½ã€æ‰§è¡Œåƒç´ çº§åˆ†å‰²å¹¶æ•´åˆå…¨å±€äº¤äº’å…³ç³»ã€‚åŒæ—¶ï¼Œç ”ç©¶è€…å‘å¸ƒäº† PaIR æ•°æ®é›†ï¼Œæ¶µç›–äº† 13,979 å¼ å›¾åƒã€654 ç§åŠ¨ä½œåŠ 17 ä¸ªèº«ä½“éƒ¨ä½ï¼Œä¸ºè¯¥è”åˆä»»åŠ¡æä¾›äº†å…¨é¢çš„æ•°æ®æ”¯æ’‘ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒPaIR-Net çš„æ€§èƒ½æ˜¾è‘—è¶…è¶Šäº†åŸºå‡†æ¨¡å‹ï¼ˆBaselineï¼‰ï¼Œæ¶ˆèå®éªŒä¹Ÿè¯å®äº†å„æ¨¡å—åœ¨æå‡é¢„æµ‹å‡†ç¡®æ€§æ–¹é¢çš„å…³é”®ä½œç”¨ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09428v1",
      "published_date": "2025-08-13 02:06:33 UTC",
      "updated_date": "2025-08-13 02:06:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:43:17.450990+00:00"
    },
    {
      "arxiv_id": "2508.09427v1",
      "title": "Implicit Hypergraph Neural Networks: A Stable Framework for Higher-Order Relational Learning with Provable Guarantees",
      "title_zh": "éšå¼è¶…å›¾ç¥ç»ç½‘ç»œï¼šå…·æœ‰å¯è¯æ˜ä¿è¯çš„é«˜é˜¶å…³ç³»å­¦ä¹ ç¨³å®šæ¡†æ¶",
      "authors": [
        "Xiaoyu Li",
        "Guangyu Tang",
        "Jiaojiao Jiang"
      ],
      "abstract": "Many real-world interactions are group-based rather than pairwise such as papers with multiple co-authors and users jointly engaging with items. Hypergraph neural networks have shown great promise at modeling higher-order relations, but their reliance on a fixed number of explicit message-passing layers limits long-range dependency capture and can destabilize training as depth grows. In this work, we introduce Implicit Hypergraph Neural Networks (IHGNN), which bring the implicit equilibrium formulation to hypergraphs: instead of stacking layers, IHGNN computes representations as the solution to a nonlinear fixed-point equation, enabling stable and efficient global propagation across hyperedges without deep architectures. We develop a well-posed training scheme with provable convergence, analyze the oversmoothing conditions and expressivity of the model, and derive a transductive generalization bound on hypergraphs. We further present an implicit-gradient training procedure coupled with a projection-based stabilization strategy. Extensive experiments on citation benchmarks show that IHGNN consistently outperforms strong traditional graph/hypergraph neural network baselines in both accuracy and robustness. Empirically, IHGNN is resilient to random initialization and hyperparameter variation, highlighting its strong generalization and practical value for higher-order relational learning.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Implicit Hypergraph Neural Networks (IHGNN)ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿ Hypergraph neural networks ä¾èµ–å›ºå®šæ•°é‡çš„æ˜¾å¼æ¶ˆæ¯ä¼ é€’å±‚æ‰€å¯¼è‡´çš„é•¿ç¨‹ä¾èµ–æ•æ‰å—é™åŠæ·±å±‚è®­ç»ƒä¸ç¨³å®šé—®é¢˜ã€‚IHGNN å°† implicit equilibrium formulation å¼•å…¥è¶…å›¾å­¦ä¹ ï¼Œé€šè¿‡æ±‚è§£ nonlinear fixed-point equation æ¥è®¡ç®—èŠ‚ç‚¹è¡¨ç¤ºï¼Œæ— éœ€å †å æ·±å±‚æ¶æ„å³å¯å®ç°é«˜æ•ˆçš„å…¨å±€ä¿¡æ¯ä¼ æ’­ã€‚ä½œè€…ä¸ºè¯¥æ¨¡å‹å¼€å‘äº†å…·æœ‰æ”¶æ•›æ€§ä¿è¯çš„è®­ç»ƒæ–¹æ¡ˆï¼Œå¹¶ä»ç†è®ºä¸Šåˆ†æäº†å…¶ oversmoothing æ¡ä»¶ã€expressivity ä»¥åŠåœ¨è¶…å›¾ä¸Šçš„ transductive generalization boundã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜ç»“åˆäº† implicit-gradient è®­ç»ƒç¨‹åºä¸ projection-based stabilization ç­–ç•¥ä»¥æå‡æ•°å€¼ç¨³å®šæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒIHGNN åœ¨å¼•æ–‡åŸºå‡†æµ‹è¯•ä¸­çš„å‡†ç¡®ç‡å’Œ robustness å‡æ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„å›¾ä¸è¶…å›¾ç¥ç»ç½‘ç»œæ¨¡å‹ã€‚è¯¥æ¨¡å‹å¯¹éšæœºåˆå§‹åŒ–å’Œè¶…å‚æ•°å˜åŒ–å…·æœ‰æå¼ºçš„ resilienceï¼Œä¸ºå¤„ç†é«˜é˜¶å…³ç³»å­¦ä¹ æä¾›äº†ä¸€ä¸ªç¨³å¥ä¸”å…·æœ‰ç†è®ºæ”¯æ’‘çš„æ¡†æ¶ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09427v1",
      "published_date": "2025-08-13 02:06:29 UTC",
      "updated_date": "2025-08-13 02:06:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:43:24.507201+00:00"
    },
    {
      "arxiv_id": "2508.09418v1",
      "title": "Domain-Generalization to Improve Learning in Meta-Learning Algorithms",
      "title_zh": "é€šè¿‡é¢†åŸŸæ³›åŒ–æå‡å…ƒå­¦ä¹ ç®—æ³•çš„å­¦ä¹ èƒ½åŠ›",
      "authors": [
        "Usman Anjum",
        "Chris Stockman",
        "Cat Luong",
        "Justin Zhan"
      ],
      "abstract": "This paper introduces Domain Generalization Sharpness-Aware Minimization Model-Agnostic Meta-Learning (DGS-MAML), a novel meta-learning algorithm designed to generalize across tasks with limited training data. DGS-MAML combines gradient matching with sharpness-aware minimization in a bi-level optimization framework to enhance model adaptability and robustness. We support our method with theoretical analysis using PAC-Bayes and convergence guarantees. Experimental results on benchmark datasets show that DGS-MAML outperforms existing approaches in terms of accuracy and generalization. The proposed method is particularly useful for scenarios requiring few-shot learning and quick adaptation, and the source code is publicly available at GitHub.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Domain Generalization Sharpness-Aware Minimization Model-Agnostic Meta-Learning (DGS-MAML)ï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨æé«˜åœ¨æœ‰é™è®­ç»ƒæ•°æ®ä¸‹è·¨ä»»åŠ¡æ³›åŒ–èƒ½åŠ›çš„æ–°å‹å…ƒå­¦ä¹ ç®—æ³•ã€‚è¯¥ç®—æ³•åœ¨ä¸€ä¸ªåŒå±‚ä¼˜åŒ–æ¡†æ¶ (bi-level optimization framework) ä¸­ç»“åˆäº†æ¢¯åº¦åŒ¹é… (gradient matching) ä¸é”åº¦æ„ŸçŸ¥æœ€å°åŒ– (sharpness-aware minimization)ï¼Œä»¥æ˜¾è‘—å¢å¼ºæ¨¡å‹çš„é€‚åº”æ€§å’Œé²æ£’æ€§ã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡ PAC-Bayes ç†è®ºåˆ†æå’Œæ”¶æ•›æ€§ä¿è¯ (convergence guarantees) ä¸ºè¯¥æ–¹æ³•æä¾›äº†åšå®çš„ç†è®ºæ”¯æ’‘ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDGS-MAML åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å‡†ç¡®ç‡å’Œæ³›åŒ–èƒ½åŠ›å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚è¯¥ç ”ç©¶æˆæœå¯¹äºéœ€è¦å°‘æ ·æœ¬å­¦ä¹  (few-shot learning) å’Œå¿«é€Ÿé€‚åº”çš„å®é™…åº”ç”¨åœºæ™¯å…·æœ‰é‡è¦ä»·å€¼ï¼Œä¸”ç›¸å…³æºä»£ç å·²åœ¨ GitHub å¼€æºã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09418v1",
      "published_date": "2025-08-13 01:30:11 UTC",
      "updated_date": "2025-08-13 01:30:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:43:24.782275+00:00"
    },
    {
      "arxiv_id": "2508.09415v1",
      "title": "RampNet: A Two-Stage Pipeline for Bootstrapping Curb Ramp Detection in Streetscape Images from Open Government Metadata",
      "title_zh": "RampNetï¼šä¸€ç§åŸºäºæ”¿åºœå¼€æ”¾å…ƒæ•°æ®å¼•å¯¼è¡—æ™¯å›¾åƒè·¯ç¼˜å¡é“æ£€æµ‹çš„ä¸¤é˜¶æ®µæµæ°´çº¿",
      "authors": [
        "John S. O'Meara",
        "Jared Hwang",
        "Zeyu Wang",
        "Michael Saugstad",
        "Jon E. Froehlich"
      ],
      "abstract": "Curb ramps are critical for urban accessibility, but robustly detecting them in images remains an open problem due to the lack of large-scale, high-quality datasets. While prior work has attempted to improve data availability with crowdsourced or manually labeled data, these efforts often fall short in either quality or scale. In this paper, we introduce and evaluate a two-stage pipeline called RampNet to scale curb ramp detection datasets and improve model performance. In Stage 1, we generate a dataset of more than 210,000 annotated Google Street View (GSV) panoramas by auto-translating government-provided curb ramp location data to pixel coordinates in panoramic images. In Stage 2, we train a curb ramp detection model (modified ConvNeXt V2) from the generated dataset, achieving state-of-the-art performance. To evaluate both stages of our pipeline, we compare to manually labeled panoramas. Our generated dataset achieves 94.0% precision and 92.5% recall, and our detection model reaches 0.9236 AP -- far exceeding prior work. Our work contributes the first large-scale, high-quality curb ramp detection dataset, benchmark, and model.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸå¸‚æ— éšœç¢è®¾æ–½ä¸­è·¯ç¼˜å¡é“(Curb ramps)æ£€æµ‹å› ç¼ºä¹å¤§è§„æ¨¡é«˜è´¨é‡æ•°æ®é›†è€Œå—é™çš„é—®é¢˜ï¼Œæå‡ºäº†åä¸º RampNet çš„ä¸¤é˜¶æ®µæµæ°´çº¿æ¡†æ¶ã€‚ç¬¬ä¸€é˜¶æ®µåˆ©ç”¨æ”¿åºœå…¬å¼€å…ƒæ•°æ®ï¼Œé€šè¿‡å°†åœ°ç†ä½ç½®æ•°æ®è‡ªåŠ¨è½¬æ¢ä¸ºåƒç´ åæ ‡ï¼Œç”Ÿæˆäº†åŒ…å«è¶…è¿‡ 210,000 å¼ æ ‡æ³¨ Google Street View (GSV) å…¨æ™¯å›¾çš„å¤§è§„æ¨¡æ•°æ®é›†ã€‚ç¬¬äºŒé˜¶æ®µåŸºäºè¯¥è‡ªåŠ¨ç”Ÿæˆçš„æ•°æ®é›†è®­ç»ƒäº†ä¸€ä¸ªæ”¹è¿›çš„ ConvNeXt V2 æ£€æµ‹æ¨¡å‹ï¼Œå®ç°äº†å½“å‰æœ€å…ˆè¿›çš„æ£€æµ‹æ€§èƒ½ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥ç”Ÿæˆçš„æ ‡æ³¨æ•°æ®è¾¾åˆ°äº† 94.0% çš„ç²¾ç¡®ç‡å’Œ 92.5% çš„å¬å›ç‡ï¼Œä¸”æ£€æµ‹æ¨¡å‹çš„ AP å€¼è¾¾åˆ° 0.9236ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰å·¥ä½œã€‚è¯¥ç ”ç©¶è´¡çŒ®äº†é¦–ä¸ªå¤§è§„æ¨¡è·¯ç¼˜å¡é“æ£€æµ‹æ•°æ®é›†ã€åŸºå‡†å’Œæ¨¡å‹ï¼Œæœ‰æ•ˆæå‡äº†è‡ªåŠ¨è¯†åˆ«åŸå¸‚æ— éšœç¢è®¾æ–½çš„æŠ€æœ¯æ°´å¹³ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to the ICCV'25 Workshop on Vision Foundation Models and Generative AI for Accessibility: Challenges and Opportunities",
      "pdf_url": "https://arxiv.org/pdf/2508.09415v1",
      "published_date": "2025-08-13 01:22:48 UTC",
      "updated_date": "2025-08-13 01:22:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:43:26.083444+00:00"
    },
    {
      "arxiv_id": "2508.16610v1",
      "title": "To Explain Or Not To Explain: An Empirical Investigation Of AI-Based Recommendations On Social Media Platforms",
      "title_zh": "è§£é‡Šè¿˜æ˜¯ä¸è§£é‡Šï¼šç¤¾äº¤åª’ä½“å¹³å° AI æ¨èçš„å®è¯ç ”ç©¶",
      "authors": [
        "AKM Bahalul Haque",
        "A. K. M. Najmul Islam",
        "Patrick Mikalef"
      ],
      "abstract": "AI based social media recommendations have great potential to improve the user experience. However, often these recommendations do not match the user interest and create an unpleasant experience for the users. Moreover, the recommendation system being a black box creates comprehensibility and transparency issues. This paper investigates social media recommendations from an end user perspective. For the investigation, we used the popular social media platform Facebook and recruited regular users to conduct a qualitative analysis. We asked participants about the social media content suggestions, their comprehensibility, and explainability. Our analysis shows users mostly require explanation whenever they encounter unfamiliar content and to ensure their online data security. Furthermore, the users require concise, non-technical explanations along with the facility of controlled information flow. In addition, we observed that explanations impact the users perception of transparency, trust, and understandability. Finally, we have outlined some design implications and presented a synthesized framework based on our data analysis.",
      "tldr_zh": "è¯¥ç ”ç©¶é€šè¿‡å¯¹Facebookç”¨æˆ·çš„å®šæ€§åˆ†æ(qualitative analysis)ï¼Œæ·±å…¥æ¢è®¨äº†ç¤¾äº¤åª’ä½“å¹³å°ä¸­åŸºäºäººå·¥æ™ºèƒ½çš„æ¨èç³»ç»Ÿ(AI-based recommendations)çš„é€æ˜åº¦ä¸å¯è§£é‡Šæ€§é—®é¢˜ã€‚ç ”ç©¶å‘ç°ï¼Œç”¨æˆ·åœ¨é‡åˆ°é™Œç”Ÿå†…å®¹æˆ–å‡ºäºæ•°æ®å®‰å…¨è€ƒé‡æ—¶ï¼Œå¯¹è§£é‡Š(explanation)çš„éœ€æ±‚æœ€ä¸ºæ˜¾è‘—ï¼Œä¸”æ›´å€¾å‘äºæ¥å—ç®€æ´ã€éæŠ€æœ¯æ€§çš„è¯´æ˜ä»¥åŠå…·å¤‡å¯æ§çš„ä¿¡æ¯æµã€‚å®éªŒè§‚å¯Ÿåˆ°ï¼Œæœ‰æ•ˆçš„è§£é‡Šèƒ½å¤Ÿç›´æ¥æå‡ç”¨æˆ·å¯¹ç³»ç»Ÿçš„é€æ˜åº¦æ„ŸçŸ¥ã€ä¿¡ä»»åº¦åŠå¯ç†è§£æ€§ã€‚æœ€åï¼Œæœ¬æ–‡æ ¹æ®ç ”ç©¶ç»“æœæå‡ºäº†ç›¸å…³çš„è®¾è®¡å¯ç¤ºï¼Œå¹¶æ„å»ºäº†ä¸€ä¸ªç»¼åˆæ¡†æ¶(synthesized framework)ï¼Œä¸ºä¼˜åŒ–ç¤¾äº¤åª’ä½“æ¨èç³»ç»Ÿçš„ç”¨æˆ·ä½“éªŒæä¾›äº†å®è·µæŒ‡å¯¼ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "25 pages, 2 figures, and 1 table",
      "pdf_url": "https://arxiv.org/pdf/2508.16610v1",
      "published_date": "2025-08-13 01:05:49 UTC",
      "updated_date": "2025-08-13 01:05:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:43:25.889752+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 125,
  "processed_papers_count": 125,
  "failed_papers_count": 0,
  "llm_backup_calls": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-01-24T11:44:23.319358+00:00"
}